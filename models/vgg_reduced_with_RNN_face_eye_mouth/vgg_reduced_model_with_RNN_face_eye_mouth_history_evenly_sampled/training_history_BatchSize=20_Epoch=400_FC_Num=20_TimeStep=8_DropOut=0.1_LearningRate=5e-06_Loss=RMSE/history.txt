Epoch: 1| Step: 0
Training loss: 6.4111833138957275
Validation loss: 5.826891763710863

Epoch: 5| Step: 1
Training loss: 5.907914184566922
Validation loss: 5.822664962677083

Epoch: 5| Step: 2
Training loss: 5.5809686502281215
Validation loss: 5.818567410778645

Epoch: 5| Step: 3
Training loss: 5.671884079602753
Validation loss: 5.814244874990268

Epoch: 5| Step: 4
Training loss: 6.636816463009345
Validation loss: 5.810372630059418

Epoch: 5| Step: 5
Training loss: 5.513456701876491
Validation loss: 5.806170979079354

Epoch: 5| Step: 6
Training loss: 5.345645144632133
Validation loss: 5.802362944693415

Epoch: 5| Step: 7
Training loss: 4.953278837011159
Validation loss: 5.7981301260620315

Epoch: 5| Step: 8
Training loss: 5.880493517555288
Validation loss: 5.79422338602942

Epoch: 5| Step: 9
Training loss: 6.0765774284055825
Validation loss: 5.78982691014793

Epoch: 5| Step: 10
Training loss: 6.105887664071438
Validation loss: 5.785571858902736

Epoch: 2| Step: 0
Training loss: 5.48641642862365
Validation loss: 5.781584411900002

Epoch: 5| Step: 1
Training loss: 5.8349438578463415
Validation loss: 5.777337200388472

Epoch: 5| Step: 2
Training loss: 5.317480109159198
Validation loss: 5.772707962700412

Epoch: 5| Step: 3
Training loss: 4.899228654211804
Validation loss: 5.768323370318155

Epoch: 5| Step: 4
Training loss: 5.967059310411188
Validation loss: 5.763697758333424

Epoch: 5| Step: 5
Training loss: 5.297309610096866
Validation loss: 5.758434581345814

Epoch: 5| Step: 6
Training loss: 6.0901397182930115
Validation loss: 5.753501289771797

Epoch: 5| Step: 7
Training loss: 6.219689073058825
Validation loss: 5.748051244034329

Epoch: 5| Step: 8
Training loss: 5.952406632140942
Validation loss: 5.742509061576818

Epoch: 5| Step: 9
Training loss: 6.178013783497252
Validation loss: 5.7369333636772755

Epoch: 5| Step: 10
Training loss: 6.364246648778954
Validation loss: 5.730782124218028

Epoch: 3| Step: 0
Training loss: 5.5987146605466265
Validation loss: 5.7234149825645515

Epoch: 5| Step: 1
Training loss: 5.7403609711924775
Validation loss: 5.717207703067906

Epoch: 5| Step: 2
Training loss: 6.139229885352484
Validation loss: 5.709688559159144

Epoch: 5| Step: 3
Training loss: 5.655882091043201
Validation loss: 5.70230142892644

Epoch: 5| Step: 4
Training loss: 4.903034881872292
Validation loss: 5.694215147876192

Epoch: 5| Step: 5
Training loss: 5.178857244863089
Validation loss: 5.686146247450723

Epoch: 5| Step: 6
Training loss: 6.579677226489546
Validation loss: 5.677349935162676

Epoch: 5| Step: 7
Training loss: 4.174963104633241
Validation loss: 5.669046855169472

Epoch: 5| Step: 8
Training loss: 6.090702175005698
Validation loss: 5.659927712644191

Epoch: 5| Step: 9
Training loss: 5.645810604636225
Validation loss: 5.649931995978284

Epoch: 5| Step: 10
Training loss: 6.89182511516135
Validation loss: 5.6395054729019485

Epoch: 4| Step: 0
Training loss: 4.17511317847799
Validation loss: 5.628735352793939

Epoch: 5| Step: 1
Training loss: 5.459745306984445
Validation loss: 5.616604008761324

Epoch: 5| Step: 2
Training loss: 5.556863736733432
Validation loss: 5.605872886906942

Epoch: 5| Step: 3
Training loss: 5.682227405029713
Validation loss: 5.593251283840656

Epoch: 5| Step: 4
Training loss: 6.198871066770256
Validation loss: 5.580970596051602

Epoch: 5| Step: 5
Training loss: 5.589194888583102
Validation loss: 5.567454763096699

Epoch: 5| Step: 6
Training loss: 5.791252761797346
Validation loss: 5.552936689310168

Epoch: 5| Step: 7
Training loss: 6.135406062360406
Validation loss: 5.538120249279318

Epoch: 5| Step: 8
Training loss: 4.83806350146563
Validation loss: 5.5227396810639355

Epoch: 5| Step: 9
Training loss: 5.726579486566723
Validation loss: 5.507266897900038

Epoch: 5| Step: 10
Training loss: 6.2391024379278335
Validation loss: 5.491151401933604

Epoch: 5| Step: 0
Training loss: 6.218043608298133
Validation loss: 5.474110793275085

Epoch: 5| Step: 1
Training loss: 5.520090516219002
Validation loss: 5.456382415340857

Epoch: 5| Step: 2
Training loss: 4.6619267006393175
Validation loss: 5.437485912334451

Epoch: 5| Step: 3
Training loss: 6.281196859713801
Validation loss: 5.41767260705625

Epoch: 5| Step: 4
Training loss: 6.285719159359714
Validation loss: 5.398330098787402

Epoch: 5| Step: 5
Training loss: 5.352560888565015
Validation loss: 5.377914493252065

Epoch: 5| Step: 6
Training loss: 4.853323452558695
Validation loss: 5.355223512333512

Epoch: 5| Step: 7
Training loss: 5.110280927785543
Validation loss: 5.33330450255282

Epoch: 5| Step: 8
Training loss: 4.457236015303448
Validation loss: 5.309508077740273

Epoch: 5| Step: 9
Training loss: 4.801809152759652
Validation loss: 5.286229731863916

Epoch: 5| Step: 10
Training loss: 5.775722851452198
Validation loss: 5.2626001362681265

Epoch: 6| Step: 0
Training loss: 4.338756517797183
Validation loss: 5.2379966474325945

Epoch: 5| Step: 1
Training loss: 5.5393541525605885
Validation loss: 5.212563364765103

Epoch: 5| Step: 2
Training loss: 5.244064608969542
Validation loss: 5.187320437772485

Epoch: 5| Step: 3
Training loss: 5.814778855400008
Validation loss: 5.16065020706429

Epoch: 5| Step: 4
Training loss: 5.803201107744227
Validation loss: 5.1337454127166

Epoch: 5| Step: 5
Training loss: 4.791501691991297
Validation loss: 5.109198753455856

Epoch: 5| Step: 6
Training loss: 5.55186251069373
Validation loss: 5.079528650949763

Epoch: 5| Step: 7
Training loss: 3.90757399437098
Validation loss: 5.053252694789636

Epoch: 5| Step: 8
Training loss: 5.837145331838158
Validation loss: 5.026052338031311

Epoch: 5| Step: 9
Training loss: 5.174456824945739
Validation loss: 4.998300201909434

Epoch: 5| Step: 10
Training loss: 4.198988456621176
Validation loss: 4.9735590155056055

Epoch: 7| Step: 0
Training loss: 5.662544920618939
Validation loss: 4.947582912965217

Epoch: 5| Step: 1
Training loss: 5.195708983931175
Validation loss: 4.92024633256636

Epoch: 5| Step: 2
Training loss: 4.623001697933571
Validation loss: 4.896622446209919

Epoch: 5| Step: 3
Training loss: 5.5440756167805
Validation loss: 4.871496628210461

Epoch: 5| Step: 4
Training loss: 4.567209608746843
Validation loss: 4.846326791348619

Epoch: 5| Step: 5
Training loss: 4.803489870745486
Validation loss: 4.819177587530256

Epoch: 5| Step: 6
Training loss: 5.594154726869315
Validation loss: 4.791404789014378

Epoch: 5| Step: 7
Training loss: 4.681240327262307
Validation loss: 4.765943618040405

Epoch: 5| Step: 8
Training loss: 4.202847950252821
Validation loss: 4.7347407094672365

Epoch: 5| Step: 9
Training loss: 4.262585797383287
Validation loss: 4.702750532348205

Epoch: 5| Step: 10
Training loss: 4.352724533117856
Validation loss: 4.670456344432451

Epoch: 8| Step: 0
Training loss: 4.649574358748261
Validation loss: 4.639874739034642

Epoch: 5| Step: 1
Training loss: 4.92357710213955
Validation loss: 4.611649342757172

Epoch: 5| Step: 2
Training loss: 4.295514699451409
Validation loss: 4.581516730703941

Epoch: 5| Step: 3
Training loss: 4.5093570489453425
Validation loss: 4.555557227882647

Epoch: 5| Step: 4
Training loss: 4.712438543510906
Validation loss: 4.530124975846223

Epoch: 5| Step: 5
Training loss: 4.498682676989684
Validation loss: 4.503530418636522

Epoch: 5| Step: 6
Training loss: 3.9767031541692166
Validation loss: 4.480731421600895

Epoch: 5| Step: 7
Training loss: 5.530783423449123
Validation loss: 4.455752821500315

Epoch: 5| Step: 8
Training loss: 3.897513301060793
Validation loss: 4.432060803194254

Epoch: 5| Step: 9
Training loss: 3.779969179744313
Validation loss: 4.408517947819725

Epoch: 5| Step: 10
Training loss: 5.645600298849981
Validation loss: 4.387163488889965

Epoch: 9| Step: 0
Training loss: 4.137623515979354
Validation loss: 4.36342879275855

Epoch: 5| Step: 1
Training loss: 4.363997876118703
Validation loss: 4.34498821701823

Epoch: 5| Step: 2
Training loss: 5.445143315274351
Validation loss: 4.32579032348522

Epoch: 5| Step: 3
Training loss: 3.471627768599119
Validation loss: 4.306900233790719

Epoch: 5| Step: 4
Training loss: 4.107597169568395
Validation loss: 4.290136073701157

Epoch: 5| Step: 5
Training loss: 4.6654146876525
Validation loss: 4.273273217475554

Epoch: 5| Step: 6
Training loss: 5.145719004402166
Validation loss: 4.258398863152134

Epoch: 5| Step: 7
Training loss: 4.740592675799797
Validation loss: 4.241348545329566

Epoch: 5| Step: 8
Training loss: 4.034211010189161
Validation loss: 4.226455407801455

Epoch: 5| Step: 9
Training loss: 4.711673508270194
Validation loss: 4.214240044636337

Epoch: 5| Step: 10
Training loss: 2.5621673554160007
Validation loss: 4.202085309757699

Epoch: 10| Step: 0
Training loss: 3.5396810163760337
Validation loss: 4.188515437330327

Epoch: 5| Step: 1
Training loss: 4.239574885379457
Validation loss: 4.178938590236848

Epoch: 5| Step: 2
Training loss: 4.696277792114517
Validation loss: 4.167392635885081

Epoch: 5| Step: 3
Training loss: 4.983862393128215
Validation loss: 4.154716900395508

Epoch: 5| Step: 4
Training loss: 4.154561553113445
Validation loss: 4.14552286714641

Epoch: 5| Step: 5
Training loss: 4.612228906619938
Validation loss: 4.135988313697412

Epoch: 5| Step: 6
Training loss: 4.53727836803228
Validation loss: 4.126168106466834

Epoch: 5| Step: 7
Training loss: 3.659559398666813
Validation loss: 4.11658011734864

Epoch: 5| Step: 8
Training loss: 4.189986899635393
Validation loss: 4.108834519222063

Epoch: 5| Step: 9
Training loss: 3.5994598142338896
Validation loss: 4.098245541578322

Epoch: 5| Step: 10
Training loss: 4.553831461686446
Validation loss: 4.091534244513171

Epoch: 11| Step: 0
Training loss: 4.259907562255881
Validation loss: 4.083011303513609

Epoch: 5| Step: 1
Training loss: 3.7667222066739905
Validation loss: 4.071341744350674

Epoch: 5| Step: 2
Training loss: 4.1159904810106775
Validation loss: 4.066155136478295

Epoch: 5| Step: 3
Training loss: 4.565917107169272
Validation loss: 4.0581182218473275

Epoch: 5| Step: 4
Training loss: 3.898311880530251
Validation loss: 4.048067111871329

Epoch: 5| Step: 5
Training loss: 4.001087517721012
Validation loss: 4.041223808529436

Epoch: 5| Step: 6
Training loss: 3.817801619669796
Validation loss: 4.032685528154832

Epoch: 5| Step: 7
Training loss: 3.2105803279431107
Validation loss: 4.026776918258617

Epoch: 5| Step: 8
Training loss: 4.5114598055425885
Validation loss: 4.021329700033177

Epoch: 5| Step: 9
Training loss: 4.918723608234569
Validation loss: 4.0123365729095735

Epoch: 5| Step: 10
Training loss: 4.780086600185549
Validation loss: 4.00377846246544

Epoch: 12| Step: 0
Training loss: 4.287485746576845
Validation loss: 3.9990360921360293

Epoch: 5| Step: 1
Training loss: 4.192491431776286
Validation loss: 3.9952565442084764

Epoch: 5| Step: 2
Training loss: 4.120002725100311
Validation loss: 3.982562447111687

Epoch: 5| Step: 3
Training loss: 3.6580017327689878
Validation loss: 3.9750980286942834

Epoch: 5| Step: 4
Training loss: 4.176496253610304
Validation loss: 3.969354963392822

Epoch: 5| Step: 5
Training loss: 3.5517800985690693
Validation loss: 3.958071257761873

Epoch: 5| Step: 6
Training loss: 3.2277975974365383
Validation loss: 3.953711538864826

Epoch: 5| Step: 7
Training loss: 4.280201581682104
Validation loss: 3.946613620223078

Epoch: 5| Step: 8
Training loss: 4.36632571648648
Validation loss: 3.940507249879121

Epoch: 5| Step: 9
Training loss: 5.195590959701526
Validation loss: 3.9361207274600036

Epoch: 5| Step: 10
Training loss: 3.8270047786972876
Validation loss: 3.9250365778933385

Epoch: 13| Step: 0
Training loss: 3.428548636814838
Validation loss: 3.9195185515336814

Epoch: 5| Step: 1
Training loss: 4.583261986379463
Validation loss: 3.914787094577173

Epoch: 5| Step: 2
Training loss: 4.61229300512627
Validation loss: 3.907086735190688

Epoch: 5| Step: 3
Training loss: 3.4317338612743122
Validation loss: 3.8985673279158615

Epoch: 5| Step: 4
Training loss: 4.39540334228633
Validation loss: 3.8948989141508275

Epoch: 5| Step: 5
Training loss: 4.10334829055535
Validation loss: 3.8886857919255506

Epoch: 5| Step: 6
Training loss: 3.700610888801656
Validation loss: 3.879722153913174

Epoch: 5| Step: 7
Training loss: 3.2996061321218675
Validation loss: 3.875355306287472

Epoch: 5| Step: 8
Training loss: 3.993762278649882
Validation loss: 3.8693338860759536

Epoch: 5| Step: 9
Training loss: 4.926495227299969
Validation loss: 3.86492471480978

Epoch: 5| Step: 10
Training loss: 3.6298343387350553
Validation loss: 3.857156448754834

Epoch: 14| Step: 0
Training loss: 4.226769405243505
Validation loss: 3.849909853775482

Epoch: 5| Step: 1
Training loss: 3.8835912648824022
Validation loss: 3.8438414569375214

Epoch: 5| Step: 2
Training loss: 3.855655128434257
Validation loss: 3.837961954093101

Epoch: 5| Step: 3
Training loss: 2.937327927764384
Validation loss: 3.8322041164918383

Epoch: 5| Step: 4
Training loss: 3.8645656753232593
Validation loss: 3.826865111164113

Epoch: 5| Step: 5
Training loss: 4.337924921071089
Validation loss: 3.8206569075922374

Epoch: 5| Step: 6
Training loss: 4.095472366606769
Validation loss: 3.815694514557458

Epoch: 5| Step: 7
Training loss: 3.96525323566622
Validation loss: 3.809588521068644

Epoch: 5| Step: 8
Training loss: 4.982709743986927
Validation loss: 3.80374901336632

Epoch: 5| Step: 9
Training loss: 4.335589530660062
Validation loss: 3.7965575480102616

Epoch: 5| Step: 10
Training loss: 2.753665042351068
Validation loss: 3.79384258696738

Epoch: 15| Step: 0
Training loss: 4.520445471560579
Validation loss: 3.788157528992398

Epoch: 5| Step: 1
Training loss: 4.40860852907101
Validation loss: 3.7819927546787597

Epoch: 5| Step: 2
Training loss: 3.3196130352400037
Validation loss: 3.77931606377627

Epoch: 5| Step: 3
Training loss: 3.412861558254027
Validation loss: 3.7753793529218744

Epoch: 5| Step: 4
Training loss: 4.346850050546772
Validation loss: 3.7688232423465022

Epoch: 5| Step: 5
Training loss: 3.802166426634641
Validation loss: 3.76347309535295

Epoch: 5| Step: 6
Training loss: 4.313085986144602
Validation loss: 3.7575585978342954

Epoch: 5| Step: 7
Training loss: 3.329709244598461
Validation loss: 3.7534795539964487

Epoch: 5| Step: 8
Training loss: 3.618081429344856
Validation loss: 3.7493112116096445

Epoch: 5| Step: 9
Training loss: 3.6945780695664805
Validation loss: 3.745405316500188

Epoch: 5| Step: 10
Training loss: 4.358936137323829
Validation loss: 3.7410154790080914

Epoch: 16| Step: 0
Training loss: 4.115016531372237
Validation loss: 3.7350447971340306

Epoch: 5| Step: 1
Training loss: 3.6238464624751625
Validation loss: 3.7353254685819905

Epoch: 5| Step: 2
Training loss: 2.980540103483206
Validation loss: 3.7401040231981795

Epoch: 5| Step: 3
Training loss: 3.332374832309573
Validation loss: 3.7424523393898745

Epoch: 5| Step: 4
Training loss: 4.099172946040791
Validation loss: 3.727280862747189

Epoch: 5| Step: 5
Training loss: 3.9784827851338562
Validation loss: 3.713488127856898

Epoch: 5| Step: 6
Training loss: 4.864139294286169
Validation loss: 3.7127030581530907

Epoch: 5| Step: 7
Training loss: 4.163094986098834
Validation loss: 3.709226703683246

Epoch: 5| Step: 8
Training loss: 3.975279115678091
Validation loss: 3.705224315051597

Epoch: 5| Step: 9
Training loss: 3.9824671347507836
Validation loss: 3.7005570594584896

Epoch: 5| Step: 10
Training loss: 3.360218598657194
Validation loss: 3.696695108259807

Epoch: 17| Step: 0
Training loss: 3.9032847632153387
Validation loss: 3.6911123597705595

Epoch: 5| Step: 1
Training loss: 3.9336325407719914
Validation loss: 3.689060511554224

Epoch: 5| Step: 2
Training loss: 3.462191868922265
Validation loss: 3.6849401121379093

Epoch: 5| Step: 3
Training loss: 4.7437829942523315
Validation loss: 3.691174336206287

Epoch: 5| Step: 4
Training loss: 4.226747519344532
Validation loss: 3.678074680292618

Epoch: 5| Step: 5
Training loss: 3.290227035990717
Validation loss: 3.676818071639709

Epoch: 5| Step: 6
Training loss: 3.7416947265343157
Validation loss: 3.6726999320110036

Epoch: 5| Step: 7
Training loss: 3.8301210765774334
Validation loss: 3.671123984112577

Epoch: 5| Step: 8
Training loss: 3.2807875534428
Validation loss: 3.667660317533021

Epoch: 5| Step: 9
Training loss: 3.36950094314202
Validation loss: 3.66513712761617

Epoch: 5| Step: 10
Training loss: 4.544748969368944
Validation loss: 3.6616752626882745

Epoch: 18| Step: 0
Training loss: 3.409396896501781
Validation loss: 3.6595561608037346

Epoch: 5| Step: 1
Training loss: 4.055430908261731
Validation loss: 3.6612177818093903

Epoch: 5| Step: 2
Training loss: 2.8714562842435503
Validation loss: 3.6488679108188546

Epoch: 5| Step: 3
Training loss: 4.1804136982306535
Validation loss: 3.6462841536898436

Epoch: 5| Step: 4
Training loss: 4.276751082655857
Validation loss: 3.638730825960409

Epoch: 5| Step: 5
Training loss: 3.7457631654429724
Validation loss: 3.6356537895512036

Epoch: 5| Step: 6
Training loss: 3.793304899899115
Validation loss: 3.632718270771525

Epoch: 5| Step: 7
Training loss: 3.5877228989953482
Validation loss: 3.632373037230575

Epoch: 5| Step: 8
Training loss: 3.8641089930592925
Validation loss: 3.6261397003309446

Epoch: 5| Step: 9
Training loss: 4.069771230955673
Validation loss: 3.6214130265856217

Epoch: 5| Step: 10
Training loss: 4.093655883639017
Validation loss: 3.620459063551004

Epoch: 19| Step: 0
Training loss: 3.369569436026523
Validation loss: 3.6176971705129

Epoch: 5| Step: 1
Training loss: 3.768616307356098
Validation loss: 3.6150017813194784

Epoch: 5| Step: 2
Training loss: 3.3373703034878432
Validation loss: 3.615685002175485

Epoch: 5| Step: 3
Training loss: 3.1809367507167674
Validation loss: 3.6102756796483626

Epoch: 5| Step: 4
Training loss: 3.643360600021907
Validation loss: 3.6020110569046335

Epoch: 5| Step: 5
Training loss: 3.3338838281649386
Validation loss: 3.6041224928228273

Epoch: 5| Step: 6
Training loss: 3.7712026734839097
Validation loss: 3.603545547522523

Epoch: 5| Step: 7
Training loss: 3.927127436517553
Validation loss: 3.6012268130628375

Epoch: 5| Step: 8
Training loss: 4.254535498900129
Validation loss: 3.5994182639629257

Epoch: 5| Step: 9
Training loss: 4.845920396428876
Validation loss: 3.5952606464541423

Epoch: 5| Step: 10
Training loss: 4.094898324898893
Validation loss: 3.589530964315706

Epoch: 20| Step: 0
Training loss: 3.651288962412607
Validation loss: 3.5866320313210402

Epoch: 5| Step: 1
Training loss: 4.25093472243509
Validation loss: 3.5872068228974276

Epoch: 5| Step: 2
Training loss: 4.31998932166016
Validation loss: 3.583505343529531

Epoch: 5| Step: 3
Training loss: 3.249195145936069
Validation loss: 3.585409858174089

Epoch: 5| Step: 4
Training loss: 3.658100149127933
Validation loss: 3.580921004033022

Epoch: 5| Step: 5
Training loss: 3.5639246718712307
Validation loss: 3.5851330931860463

Epoch: 5| Step: 6
Training loss: 3.9174367404642987
Validation loss: 3.5736577979517206

Epoch: 5| Step: 7
Training loss: 3.8366541921333814
Validation loss: 3.569608922268659

Epoch: 5| Step: 8
Training loss: 3.483469892559803
Validation loss: 3.5642259558596714

Epoch: 5| Step: 9
Training loss: 4.061130703729374
Validation loss: 3.5633063404974

Epoch: 5| Step: 10
Training loss: 3.274681419427343
Validation loss: 3.55739696201934

Epoch: 21| Step: 0
Training loss: 4.355122998117889
Validation loss: 3.553161874991883

Epoch: 5| Step: 1
Training loss: 3.0291319063720503
Validation loss: 3.5498386838045928

Epoch: 5| Step: 2
Training loss: 3.204626410695778
Validation loss: 3.5541345028464857

Epoch: 5| Step: 3
Training loss: 3.9596224375592253
Validation loss: 3.550228378775681

Epoch: 5| Step: 4
Training loss: 3.948451479851958
Validation loss: 3.5503630612354313

Epoch: 5| Step: 5
Training loss: 3.6111275517668155
Validation loss: 3.538797817534166

Epoch: 5| Step: 6
Training loss: 3.471672682614241
Validation loss: 3.539102097511408

Epoch: 5| Step: 7
Training loss: 4.090384461257102
Validation loss: 3.537710109123545

Epoch: 5| Step: 8
Training loss: 3.5133669234762617
Validation loss: 3.5374689163204227

Epoch: 5| Step: 9
Training loss: 4.081925649052727
Validation loss: 3.537956476597711

Epoch: 5| Step: 10
Training loss: 3.7489529737452068
Validation loss: 3.5343092258150723

Epoch: 22| Step: 0
Training loss: 3.7647368464002957
Validation loss: 3.5310341270557437

Epoch: 5| Step: 1
Training loss: 4.119085059191363
Validation loss: 3.527738446493416

Epoch: 5| Step: 2
Training loss: 3.911994433416607
Validation loss: 3.5226576019991094

Epoch: 5| Step: 3
Training loss: 2.8538792226426892
Validation loss: 3.5243600501089922

Epoch: 5| Step: 4
Training loss: 2.9584273918851958
Validation loss: 3.5234700248666266

Epoch: 5| Step: 5
Training loss: 3.424780043618563
Validation loss: 3.5310710455448144

Epoch: 5| Step: 6
Training loss: 4.423552609384032
Validation loss: 3.5274750045049283

Epoch: 5| Step: 7
Training loss: 3.8634447886660426
Validation loss: 3.5090289272930124

Epoch: 5| Step: 8
Training loss: 3.7068130863095776
Validation loss: 3.513501704832987

Epoch: 5| Step: 9
Training loss: 4.121593571585624
Validation loss: 3.5149470083203744

Epoch: 5| Step: 10
Training loss: 3.5550190865263165
Validation loss: 3.517923652146147

Epoch: 23| Step: 0
Training loss: 3.535236100617521
Validation loss: 3.5136140617290263

Epoch: 5| Step: 1
Training loss: 4.217977269364197
Validation loss: 3.5097282895655546

Epoch: 5| Step: 2
Training loss: 3.8344053483304523
Validation loss: 3.5052747795870856

Epoch: 5| Step: 3
Training loss: 2.882129122984461
Validation loss: 3.4977168079444154

Epoch: 5| Step: 4
Training loss: 3.2002033586258323
Validation loss: 3.496723556138666

Epoch: 5| Step: 5
Training loss: 3.6492525615689684
Validation loss: 3.503197123875189

Epoch: 5| Step: 6
Training loss: 3.7481426725723126
Validation loss: 3.5044324337599204

Epoch: 5| Step: 7
Training loss: 3.9455184429541585
Validation loss: 3.493351532775106

Epoch: 5| Step: 8
Training loss: 3.1196352877561315
Validation loss: 3.486730851044753

Epoch: 5| Step: 9
Training loss: 4.709732027955146
Validation loss: 3.4879141775197926

Epoch: 5| Step: 10
Training loss: 3.60026172640215
Validation loss: 3.4834336367994827

Epoch: 24| Step: 0
Training loss: 3.7107991082336267
Validation loss: 3.4839473811267156

Epoch: 5| Step: 1
Training loss: 3.04737122236237
Validation loss: 3.483923166634838

Epoch: 5| Step: 2
Training loss: 3.8680325288085284
Validation loss: 3.4809436829686597

Epoch: 5| Step: 3
Training loss: 3.844240979106843
Validation loss: 3.4796576583011998

Epoch: 5| Step: 4
Training loss: 3.6980378180344884
Validation loss: 3.47825790089596

Epoch: 5| Step: 5
Training loss: 3.6233951041376202
Validation loss: 3.476594792366184

Epoch: 5| Step: 6
Training loss: 3.5447870906710994
Validation loss: 3.4734826706049846

Epoch: 5| Step: 7
Training loss: 3.2175670042374893
Validation loss: 3.475650801189349

Epoch: 5| Step: 8
Training loss: 4.34078483095032
Validation loss: 3.475206983906853

Epoch: 5| Step: 9
Training loss: 3.2950964012573443
Validation loss: 3.4666345248929153

Epoch: 5| Step: 10
Training loss: 4.290635562225255
Validation loss: 3.467515938213389

Epoch: 25| Step: 0
Training loss: 4.198829469601608
Validation loss: 3.4692975644637434

Epoch: 5| Step: 1
Training loss: 3.7650552532300887
Validation loss: 3.4660975750722933

Epoch: 5| Step: 2
Training loss: 4.111722210551579
Validation loss: 3.4651314159257964

Epoch: 5| Step: 3
Training loss: 3.7804239174631644
Validation loss: 3.4651303461179057

Epoch: 5| Step: 4
Training loss: 3.879388477664015
Validation loss: 3.4635019301784964

Epoch: 5| Step: 5
Training loss: 3.525968940619705
Validation loss: 3.459292567260185

Epoch: 5| Step: 6
Training loss: 3.1838664868315756
Validation loss: 3.464888676484836

Epoch: 5| Step: 7
Training loss: 3.165685468211044
Validation loss: 3.4620387812821334

Epoch: 5| Step: 8
Training loss: 2.9750719718882497
Validation loss: 3.4578913319596123

Epoch: 5| Step: 9
Training loss: 4.186576399791833
Validation loss: 3.45433460602531

Epoch: 5| Step: 10
Training loss: 3.3976974207632913
Validation loss: 3.449780191472873

Epoch: 26| Step: 0
Training loss: 4.400251918863611
Validation loss: 3.44818021781146

Epoch: 5| Step: 1
Training loss: 3.2708749140791435
Validation loss: 3.4449193378228524

Epoch: 5| Step: 2
Training loss: 3.2949240457813684
Validation loss: 3.441832367946571

Epoch: 5| Step: 3
Training loss: 3.5251432295033323
Validation loss: 3.4456385977006248

Epoch: 5| Step: 4
Training loss: 4.3006131644322405
Validation loss: 3.4425807407541824

Epoch: 5| Step: 5
Training loss: 3.200148674372167
Validation loss: 3.4424762582761166

Epoch: 5| Step: 6
Training loss: 3.62874541321457
Validation loss: 3.439072269702139

Epoch: 5| Step: 7
Training loss: 3.0834611058609807
Validation loss: 3.437894604240552

Epoch: 5| Step: 8
Training loss: 3.6177651127471973
Validation loss: 3.4399773360233383

Epoch: 5| Step: 9
Training loss: 2.854803046867046
Validation loss: 3.4376669506650077

Epoch: 5| Step: 10
Training loss: 4.785858526272595
Validation loss: 3.435150365188607

Epoch: 27| Step: 0
Training loss: 4.030601271838834
Validation loss: 3.43295980449207

Epoch: 5| Step: 1
Training loss: 4.18343691349346
Validation loss: 3.4366153895120184

Epoch: 5| Step: 2
Training loss: 3.8566354766041675
Validation loss: 3.4326083776787786

Epoch: 5| Step: 3
Training loss: 3.632389954634791
Validation loss: 3.430907128156546

Epoch: 5| Step: 4
Training loss: 3.3328976505381025
Validation loss: 3.4300261344405527

Epoch: 5| Step: 5
Training loss: 3.7482954601807372
Validation loss: 3.4285552871500418

Epoch: 5| Step: 6
Training loss: 3.262636852682644
Validation loss: 3.4260915774994833

Epoch: 5| Step: 7
Training loss: 3.630397330152758
Validation loss: 3.4234282614569715

Epoch: 5| Step: 8
Training loss: 3.4315794850842622
Validation loss: 3.4247865261098793

Epoch: 5| Step: 9
Training loss: 3.357675237676953
Validation loss: 3.4312440552923267

Epoch: 5| Step: 10
Training loss: 3.5549630194563413
Validation loss: 3.4228972049171076

Epoch: 28| Step: 0
Training loss: 4.2941262070649655
Validation loss: 3.421565418452387

Epoch: 5| Step: 1
Training loss: 4.261037966219093
Validation loss: 3.422145891033044

Epoch: 5| Step: 2
Training loss: 4.204222581918153
Validation loss: 3.4236652603753313

Epoch: 5| Step: 3
Training loss: 3.187758192189319
Validation loss: 3.4225442190467312

Epoch: 5| Step: 4
Training loss: 4.398564772178956
Validation loss: 3.417534395854323

Epoch: 5| Step: 5
Training loss: 2.8551105321542054
Validation loss: 3.4175519514136075

Epoch: 5| Step: 6
Training loss: 3.187850035353042
Validation loss: 3.419746083175022

Epoch: 5| Step: 7
Training loss: 3.9127238834175624
Validation loss: 3.4181802029926294

Epoch: 5| Step: 8
Training loss: 3.3305092451410814
Validation loss: 3.416781523840137

Epoch: 5| Step: 9
Training loss: 3.0501284712953076
Validation loss: 3.4162179475664023

Epoch: 5| Step: 10
Training loss: 2.6847481944465907
Validation loss: 3.4179074930306643

Epoch: 29| Step: 0
Training loss: 3.443575397364487
Validation loss: 3.4128222688104497

Epoch: 5| Step: 1
Training loss: 3.5354481276260814
Validation loss: 3.4089087347289793

Epoch: 5| Step: 2
Training loss: 4.199970408744111
Validation loss: 3.411019890077335

Epoch: 5| Step: 3
Training loss: 3.8777409365657944
Validation loss: 3.40782366103819

Epoch: 5| Step: 4
Training loss: 3.0716184988262367
Validation loss: 3.4077336479356917

Epoch: 5| Step: 5
Training loss: 3.4112889526871784
Validation loss: 3.4038240679335505

Epoch: 5| Step: 6
Training loss: 2.955002283911944
Validation loss: 3.4061746264379686

Epoch: 5| Step: 7
Training loss: 3.622385463338672
Validation loss: 3.4038992404869104

Epoch: 5| Step: 8
Training loss: 4.203679044716226
Validation loss: 3.4048279496455813

Epoch: 5| Step: 9
Training loss: 3.517904669957209
Validation loss: 3.407228038733454

Epoch: 5| Step: 10
Training loss: 3.9410399010551753
Validation loss: 3.411967447681751

Epoch: 30| Step: 0
Training loss: 4.061596814038731
Validation loss: 3.4088845324454256

Epoch: 5| Step: 1
Training loss: 2.999297059674625
Validation loss: 3.403747947723916

Epoch: 5| Step: 2
Training loss: 3.377303008822768
Validation loss: 3.4028155927389467

Epoch: 5| Step: 3
Training loss: 4.237843349353786
Validation loss: 3.4049008804084453

Epoch: 5| Step: 4
Training loss: 3.0153852772674554
Validation loss: 3.403625943660662

Epoch: 5| Step: 5
Training loss: 3.6449569666118347
Validation loss: 3.4004461104361456

Epoch: 5| Step: 6
Training loss: 3.7602709938357526
Validation loss: 3.4047820055198628

Epoch: 5| Step: 7
Training loss: 3.9077016345697806
Validation loss: 3.401526329405967

Epoch: 5| Step: 8
Training loss: 2.9123754450151256
Validation loss: 3.4000428048684017

Epoch: 5| Step: 9
Training loss: 4.450450428658242
Validation loss: 3.3999763162814696

Epoch: 5| Step: 10
Training loss: 3.0040827626130584
Validation loss: 3.3993257498261853

Epoch: 31| Step: 0
Training loss: 3.422748610924978
Validation loss: 3.3987477580657117

Epoch: 5| Step: 1
Training loss: 4.016977757691238
Validation loss: 3.395999263955008

Epoch: 5| Step: 2
Training loss: 3.6330008509220435
Validation loss: 3.396201734240229

Epoch: 5| Step: 3
Training loss: 4.201455163914613
Validation loss: 3.395315453282526

Epoch: 5| Step: 4
Training loss: 4.461934046826826
Validation loss: 3.3926982413124795

Epoch: 5| Step: 5
Training loss: 3.407497072729363
Validation loss: 3.393113130443341

Epoch: 5| Step: 6
Training loss: 3.834164708968947
Validation loss: 3.3892966936278315

Epoch: 5| Step: 7
Training loss: 2.9401895101283437
Validation loss: 3.388112014320776

Epoch: 5| Step: 8
Training loss: 3.0140044448505883
Validation loss: 3.3863669107646253

Epoch: 5| Step: 9
Training loss: 3.373108793131027
Validation loss: 3.3843565285111876

Epoch: 5| Step: 10
Training loss: 3.051256833879506
Validation loss: 3.3844648738756815

Epoch: 32| Step: 0
Training loss: 3.4882152247828313
Validation loss: 3.3819836911298315

Epoch: 5| Step: 1
Training loss: 2.904171764600996
Validation loss: 3.3807744358713285

Epoch: 5| Step: 2
Training loss: 4.071265052437297
Validation loss: 3.381803762171933

Epoch: 5| Step: 3
Training loss: 3.453501270904241
Validation loss: 3.3827260093087523

Epoch: 5| Step: 4
Training loss: 3.257951545949822
Validation loss: 3.3831293923474677

Epoch: 5| Step: 5
Training loss: 3.4323536583141
Validation loss: 3.3837740054422443

Epoch: 5| Step: 6
Training loss: 3.74925148169253
Validation loss: 3.385805367367389

Epoch: 5| Step: 7
Training loss: 4.085714126228687
Validation loss: 3.38005991757686

Epoch: 5| Step: 8
Training loss: 3.603736337244847
Validation loss: 3.3748769931413296

Epoch: 5| Step: 9
Training loss: 3.644328186331124
Validation loss: 3.3780555672352612

Epoch: 5| Step: 10
Training loss: 3.8691836359058764
Validation loss: 3.3742857982157415

Epoch: 33| Step: 0
Training loss: 3.720828973839496
Validation loss: 3.3749889189774858

Epoch: 5| Step: 1
Training loss: 3.3454927555359837
Validation loss: 3.3734123463828953

Epoch: 5| Step: 2
Training loss: 3.882423795896685
Validation loss: 3.373027631566745

Epoch: 5| Step: 3
Training loss: 4.049910301816423
Validation loss: 3.3785113379209646

Epoch: 5| Step: 4
Training loss: 3.830509486362077
Validation loss: 3.3740202386685776

Epoch: 5| Step: 5
Training loss: 3.4730586879702234
Validation loss: 3.3728602807402552

Epoch: 5| Step: 6
Training loss: 3.2441691397941588
Validation loss: 3.373156648406706

Epoch: 5| Step: 7
Training loss: 2.603660859895553
Validation loss: 3.3780985159639902

Epoch: 5| Step: 8
Training loss: 3.6326001176997593
Validation loss: 3.37520827969004

Epoch: 5| Step: 9
Training loss: 3.9912664915007565
Validation loss: 3.372829936725588

Epoch: 5| Step: 10
Training loss: 3.6046250039029313
Validation loss: 3.3702340986341013

Epoch: 34| Step: 0
Training loss: 3.645741416135768
Validation loss: 3.368702408022178

Epoch: 5| Step: 1
Training loss: 3.670637465991198
Validation loss: 3.3663578492667794

Epoch: 5| Step: 2
Training loss: 3.45771063901524
Validation loss: 3.3642043881922423

Epoch: 5| Step: 3
Training loss: 3.2860347194683244
Validation loss: 3.365321187256979

Epoch: 5| Step: 4
Training loss: 3.762531576942933
Validation loss: 3.362237824728533

Epoch: 5| Step: 5
Training loss: 3.703125643830706
Validation loss: 3.361972744047703

Epoch: 5| Step: 6
Training loss: 3.339773219741388
Validation loss: 3.360790003328116

Epoch: 5| Step: 7
Training loss: 3.4490999955225665
Validation loss: 3.359583053384858

Epoch: 5| Step: 8
Training loss: 3.608290075757905
Validation loss: 3.3592504044683853

Epoch: 5| Step: 9
Training loss: 3.619176198472633
Validation loss: 3.359626509153145

Epoch: 5| Step: 10
Training loss: 3.99003324968065
Validation loss: 3.3586328425483285

Epoch: 35| Step: 0
Training loss: 4.0344112332561535
Validation loss: 3.362730989894676

Epoch: 5| Step: 1
Training loss: 3.264672391383105
Validation loss: 3.362179683565972

Epoch: 5| Step: 2
Training loss: 3.65779381135764
Validation loss: 3.370918023426309

Epoch: 5| Step: 3
Training loss: 4.015035504365853
Validation loss: 3.3570488620392007

Epoch: 5| Step: 4
Training loss: 2.7058005790110373
Validation loss: 3.3493432565815366

Epoch: 5| Step: 5
Training loss: 3.4795482372958912
Validation loss: 3.346880884072389

Epoch: 5| Step: 6
Training loss: 3.964747535778405
Validation loss: 3.3476141750620654

Epoch: 5| Step: 7
Training loss: 3.671109903043908
Validation loss: 3.3474179562131674

Epoch: 5| Step: 8
Training loss: 2.8421180150376175
Validation loss: 3.3486991109249766

Epoch: 5| Step: 9
Training loss: 3.4093180147298554
Validation loss: 3.34683704374039

Epoch: 5| Step: 10
Training loss: 4.208886491031181
Validation loss: 3.343824532780014

Epoch: 36| Step: 0
Training loss: 2.9984468572250913
Validation loss: 3.341230137402223

Epoch: 5| Step: 1
Training loss: 4.117302851354925
Validation loss: 3.3417326536596916

Epoch: 5| Step: 2
Training loss: 3.6838513443037724
Validation loss: 3.337695433673415

Epoch: 5| Step: 3
Training loss: 3.3918210218642657
Validation loss: 3.336908016233988

Epoch: 5| Step: 4
Training loss: 3.104687862463413
Validation loss: 3.3351043293193405

Epoch: 5| Step: 5
Training loss: 3.578150986489628
Validation loss: 3.3372436050719143

Epoch: 5| Step: 6
Training loss: 4.425210402491981
Validation loss: 3.3441893356327363

Epoch: 5| Step: 7
Training loss: 3.218159000989829
Validation loss: 3.339884059134797

Epoch: 5| Step: 8
Training loss: 3.165534084630047
Validation loss: 3.3423091899698316

Epoch: 5| Step: 9
Training loss: 3.446056467294355
Validation loss: 3.3378231625694568

Epoch: 5| Step: 10
Training loss: 3.9397405879795855
Validation loss: 3.3336658578542995

Epoch: 37| Step: 0
Training loss: 3.9203223084273473
Validation loss: 3.3316065673877175

Epoch: 5| Step: 1
Training loss: 2.6130793426473793
Validation loss: 3.3315259884136275

Epoch: 5| Step: 2
Training loss: 3.2345707783440427
Validation loss: 3.3321475186015155

Epoch: 5| Step: 3
Training loss: 3.47510256169959
Validation loss: 3.3302720553720806

Epoch: 5| Step: 4
Training loss: 3.813192961205505
Validation loss: 3.327582905644896

Epoch: 5| Step: 5
Training loss: 3.926226629547742
Validation loss: 3.3265201085069935

Epoch: 5| Step: 6
Training loss: 4.031717435956845
Validation loss: 3.327944157368734

Epoch: 5| Step: 7
Training loss: 3.6910835569107183
Validation loss: 3.32968469762273

Epoch: 5| Step: 8
Training loss: 3.5607122653835743
Validation loss: 3.3304590220233017

Epoch: 5| Step: 9
Training loss: 3.361894381414608
Validation loss: 3.3281836266952785

Epoch: 5| Step: 10
Training loss: 3.3338507886425597
Validation loss: 3.3270003352772175

Epoch: 38| Step: 0
Training loss: 3.430111383125477
Validation loss: 3.321760197727471

Epoch: 5| Step: 1
Training loss: 3.5558540861318186
Validation loss: 3.322536785610021

Epoch: 5| Step: 2
Training loss: 3.0623309030365062
Validation loss: 3.3217073278557008

Epoch: 5| Step: 3
Training loss: 3.94979995993604
Validation loss: 3.3220454153373677

Epoch: 5| Step: 4
Training loss: 4.012691866366554
Validation loss: 3.3227886080509244

Epoch: 5| Step: 5
Training loss: 3.658213422427779
Validation loss: 3.3235080894874414

Epoch: 5| Step: 6
Training loss: 3.6581225694380755
Validation loss: 3.32287255748217

Epoch: 5| Step: 7
Training loss: 3.9647163859238392
Validation loss: 3.3220312915537384

Epoch: 5| Step: 8
Training loss: 3.566067966825444
Validation loss: 3.321167394810691

Epoch: 5| Step: 9
Training loss: 2.9058808122991016
Validation loss: 3.318389852458046

Epoch: 5| Step: 10
Training loss: 3.1176976142662496
Validation loss: 3.3195604632526443

Epoch: 39| Step: 0
Training loss: 3.161175953520881
Validation loss: 3.3218656571176335

Epoch: 5| Step: 1
Training loss: 3.4103732569842156
Validation loss: 3.321751952108006

Epoch: 5| Step: 2
Training loss: 2.7264746184518676
Validation loss: 3.3190298777658747

Epoch: 5| Step: 3
Training loss: 3.6572131331111914
Validation loss: 3.322347586796331

Epoch: 5| Step: 4
Training loss: 3.455474882489118
Validation loss: 3.3234296005428754

Epoch: 5| Step: 5
Training loss: 3.862260118461242
Validation loss: 3.316758070331564

Epoch: 5| Step: 6
Training loss: 4.245385076627624
Validation loss: 3.3133678154710826

Epoch: 5| Step: 7
Training loss: 3.617179458642182
Validation loss: 3.3133514023692103

Epoch: 5| Step: 8
Training loss: 3.338540984266254
Validation loss: 3.3129327034427885

Epoch: 5| Step: 9
Training loss: 3.8565148013807806
Validation loss: 3.311949390258128

Epoch: 5| Step: 10
Training loss: 3.4989979535685856
Validation loss: 3.311603617567721

Epoch: 40| Step: 0
Training loss: 2.778776118695868
Validation loss: 3.3133623533440293

Epoch: 5| Step: 1
Training loss: 3.692034761721874
Validation loss: 3.311502419831909

Epoch: 5| Step: 2
Training loss: 3.544061157990526
Validation loss: 3.312655152928226

Epoch: 5| Step: 3
Training loss: 3.2745213865035216
Validation loss: 3.3122841951822433

Epoch: 5| Step: 4
Training loss: 3.5628283165342314
Validation loss: 3.30870303824743

Epoch: 5| Step: 5
Training loss: 2.9910998247502696
Validation loss: 3.3082042770483797

Epoch: 5| Step: 6
Training loss: 4.189942060629901
Validation loss: 3.310343756654625

Epoch: 5| Step: 7
Training loss: 3.7911466863775973
Validation loss: 3.3107010624723068

Epoch: 5| Step: 8
Training loss: 3.6855098720486117
Validation loss: 3.309532604058929

Epoch: 5| Step: 9
Training loss: 3.389672774104151
Validation loss: 3.3102800062355136

Epoch: 5| Step: 10
Training loss: 3.948394719606489
Validation loss: 3.310139405263314

Epoch: 41| Step: 0
Training loss: 3.754956466686588
Validation loss: 3.314707360528186

Epoch: 5| Step: 1
Training loss: 3.500020844533702
Validation loss: 3.3189723854987094

Epoch: 5| Step: 2
Training loss: 3.3608060405848534
Validation loss: 3.311541740080536

Epoch: 5| Step: 3
Training loss: 2.5050836374783416
Validation loss: 3.304935801776446

Epoch: 5| Step: 4
Training loss: 3.8454423605805568
Validation loss: 3.3045030302531035

Epoch: 5| Step: 5
Training loss: 4.166597035144085
Validation loss: 3.30584733214777

Epoch: 5| Step: 6
Training loss: 3.8125893003917843
Validation loss: 3.306535461547145

Epoch: 5| Step: 7
Training loss: 3.543004549932829
Validation loss: 3.305447946331182

Epoch: 5| Step: 8
Training loss: 3.6624223824566617
Validation loss: 3.3030413905072793

Epoch: 5| Step: 9
Training loss: 3.0919717629588033
Validation loss: 3.3031570170843305

Epoch: 5| Step: 10
Training loss: 3.443872821369225
Validation loss: 3.304688606231961

Epoch: 42| Step: 0
Training loss: 4.0401234515373545
Validation loss: 3.302494192113726

Epoch: 5| Step: 1
Training loss: 3.4307877637461934
Validation loss: 3.303127589651478

Epoch: 5| Step: 2
Training loss: 3.329103567761203
Validation loss: 3.303004487688285

Epoch: 5| Step: 3
Training loss: 3.52609619519187
Validation loss: 3.304293716852168

Epoch: 5| Step: 4
Training loss: 3.4119000253285434
Validation loss: 3.304166572547109

Epoch: 5| Step: 5
Training loss: 3.481171919051496
Validation loss: 3.30116328769803

Epoch: 5| Step: 6
Training loss: 2.7374859360982464
Validation loss: 3.3019689232996927

Epoch: 5| Step: 7
Training loss: 3.434993454261995
Validation loss: 3.300991328209924

Epoch: 5| Step: 8
Training loss: 3.6641228839640547
Validation loss: 3.3003476183219833

Epoch: 5| Step: 9
Training loss: 3.4948711964198953
Validation loss: 3.303038950304998

Epoch: 5| Step: 10
Training loss: 4.285596882256547
Validation loss: 3.300543342177032

Epoch: 43| Step: 0
Training loss: 3.7220321404300813
Validation loss: 3.300459236465905

Epoch: 5| Step: 1
Training loss: 4.30750527211651
Validation loss: 3.2980991274624114

Epoch: 5| Step: 2
Training loss: 3.635216620915657
Validation loss: 3.2978859126095457

Epoch: 5| Step: 3
Training loss: 3.203680074094615
Validation loss: 3.296223080511877

Epoch: 5| Step: 4
Training loss: 2.9636001089509234
Validation loss: 3.2981191570881894

Epoch: 5| Step: 5
Training loss: 4.0134413901279515
Validation loss: 3.2952652670511267

Epoch: 5| Step: 6
Training loss: 3.327489944545992
Validation loss: 3.291983703780878

Epoch: 5| Step: 7
Training loss: 3.500730165884817
Validation loss: 3.293261317116318

Epoch: 5| Step: 8
Training loss: 2.87168859431005
Validation loss: 3.2921394599470486

Epoch: 5| Step: 9
Training loss: 3.6887877204023827
Validation loss: 3.2912463948836104

Epoch: 5| Step: 10
Training loss: 3.356536517709044
Validation loss: 3.292272357555772

Epoch: 44| Step: 0
Training loss: 3.413543172833449
Validation loss: 3.2901628677380796

Epoch: 5| Step: 1
Training loss: 3.3878291684512924
Validation loss: 3.2898437781780085

Epoch: 5| Step: 2
Training loss: 3.6909411909430365
Validation loss: 3.298444096054468

Epoch: 5| Step: 3
Training loss: 3.2518312723510627
Validation loss: 3.302214477849828

Epoch: 5| Step: 4
Training loss: 3.2377480135739187
Validation loss: 3.2948494650058464

Epoch: 5| Step: 5
Training loss: 3.5241004337110375
Validation loss: 3.2904097910753642

Epoch: 5| Step: 6
Training loss: 3.554539671119113
Validation loss: 3.288165309085479

Epoch: 5| Step: 7
Training loss: 3.857409760661357
Validation loss: 3.2900395409366405

Epoch: 5| Step: 8
Training loss: 3.288096233880894
Validation loss: 3.2907899961492424

Epoch: 5| Step: 9
Training loss: 3.871863049110768
Validation loss: 3.289813410311506

Epoch: 5| Step: 10
Training loss: 3.7641359289599268
Validation loss: 3.2931332315081785

Epoch: 45| Step: 0
Training loss: 4.0631441045880266
Validation loss: 3.2887520888538044

Epoch: 5| Step: 1
Training loss: 4.083992081009588
Validation loss: 3.2907835940332584

Epoch: 5| Step: 2
Training loss: 2.3965219807180866
Validation loss: 3.291377323674356

Epoch: 5| Step: 3
Training loss: 3.9462151127536735
Validation loss: 3.290391959192426

Epoch: 5| Step: 4
Training loss: 3.2261831139034927
Validation loss: 3.2876842068961314

Epoch: 5| Step: 5
Training loss: 3.9872851944707817
Validation loss: 3.2895794958724673

Epoch: 5| Step: 6
Training loss: 3.1805096437415665
Validation loss: 3.292653258512994

Epoch: 5| Step: 7
Training loss: 3.218111585988063
Validation loss: 3.289820856971584

Epoch: 5| Step: 8
Training loss: 3.293179578808488
Validation loss: 3.291579029748956

Epoch: 5| Step: 9
Training loss: 3.6534920748683017
Validation loss: 3.2958405961795343

Epoch: 5| Step: 10
Training loss: 3.41461596160127
Validation loss: 3.2927671228273945

Epoch: 46| Step: 0
Training loss: 3.14764409445174
Validation loss: 3.2914133349550694

Epoch: 5| Step: 1
Training loss: 3.3388639027751466
Validation loss: 3.28824278735266

Epoch: 5| Step: 2
Training loss: 2.9958852523811004
Validation loss: 3.2884874054223157

Epoch: 5| Step: 3
Training loss: 4.060370958415781
Validation loss: 3.2905765040264585

Epoch: 5| Step: 4
Training loss: 3.087526786162905
Validation loss: 3.292445028596458

Epoch: 5| Step: 5
Training loss: 4.0647722198744285
Validation loss: 3.2888483563281947

Epoch: 5| Step: 6
Training loss: 2.7136992093344974
Validation loss: 3.2859496806696127

Epoch: 5| Step: 7
Training loss: 4.026508707228231
Validation loss: 3.2851893375633545

Epoch: 5| Step: 8
Training loss: 3.761705313368396
Validation loss: 3.287160932708217

Epoch: 5| Step: 9
Training loss: 3.4848981387605322
Validation loss: 3.2847983024193708

Epoch: 5| Step: 10
Training loss: 3.806019011505642
Validation loss: 3.2849549081145915

Epoch: 47| Step: 0
Training loss: 3.7789695736017785
Validation loss: 3.285406093440073

Epoch: 5| Step: 1
Training loss: 3.998366260676553
Validation loss: 3.279180300771112

Epoch: 5| Step: 2
Training loss: 3.4287655922997238
Validation loss: 3.279255244167877

Epoch: 5| Step: 3
Training loss: 4.183006722718668
Validation loss: 3.2788906836612313

Epoch: 5| Step: 4
Training loss: 3.527863625777641
Validation loss: 3.279965144351628

Epoch: 5| Step: 5
Training loss: 2.607151934762817
Validation loss: 3.2819036720412567

Epoch: 5| Step: 6
Training loss: 3.254209726384939
Validation loss: 3.2801826456011276

Epoch: 5| Step: 7
Training loss: 3.1835503136415646
Validation loss: 3.2797877009071814

Epoch: 5| Step: 8
Training loss: 4.166443221140813
Validation loss: 3.278688633301133

Epoch: 5| Step: 9
Training loss: 3.1366308824671543
Validation loss: 3.2808436550849733

Epoch: 5| Step: 10
Training loss: 3.0339340439569638
Validation loss: 3.2821125637124426

Epoch: 48| Step: 0
Training loss: 3.2081720551087445
Validation loss: 3.2878155683848154

Epoch: 5| Step: 1
Training loss: 3.4206259202668403
Validation loss: 3.3050686828209326

Epoch: 5| Step: 2
Training loss: 3.375257976703671
Validation loss: 3.278093001197961

Epoch: 5| Step: 3
Training loss: 2.817688627520819
Validation loss: 3.274779705362131

Epoch: 5| Step: 4
Training loss: 3.1470835308847795
Validation loss: 3.2769276422770637

Epoch: 5| Step: 5
Training loss: 4.339461810235255
Validation loss: 3.275379476235306

Epoch: 5| Step: 6
Training loss: 3.5557490849145426
Validation loss: 3.2790702036869557

Epoch: 5| Step: 7
Training loss: 3.451418493814652
Validation loss: 3.280196228985593

Epoch: 5| Step: 8
Training loss: 3.454841980915791
Validation loss: 3.2783026236526345

Epoch: 5| Step: 9
Training loss: 4.062012628517824
Validation loss: 3.2781441579772106

Epoch: 5| Step: 10
Training loss: 3.6107348237875905
Validation loss: 3.280377557873063

Epoch: 49| Step: 0
Training loss: 3.6346972754773943
Validation loss: 3.280211991268244

Epoch: 5| Step: 1
Training loss: 3.2734080748043524
Validation loss: 3.2733800653310885

Epoch: 5| Step: 2
Training loss: 3.5411932385733316
Validation loss: 3.275517047019891

Epoch: 5| Step: 3
Training loss: 3.364171210559885
Validation loss: 3.2775185083133405

Epoch: 5| Step: 4
Training loss: 3.6308123589108976
Validation loss: 3.274319706980774

Epoch: 5| Step: 5
Training loss: 3.869553583898234
Validation loss: 3.274804106509106

Epoch: 5| Step: 6
Training loss: 3.709756570937343
Validation loss: 3.271310458873732

Epoch: 5| Step: 7
Training loss: 3.0160479471356862
Validation loss: 3.2686472737545635

Epoch: 5| Step: 8
Training loss: 2.959286997210705
Validation loss: 3.2686240125342048

Epoch: 5| Step: 9
Training loss: 3.5359310755247786
Validation loss: 3.26800965655159

Epoch: 5| Step: 10
Training loss: 4.025795728796979
Validation loss: 3.267213248641149

Epoch: 50| Step: 0
Training loss: 3.2760567394368745
Validation loss: 3.2673992540542627

Epoch: 5| Step: 1
Training loss: 3.4164654897372984
Validation loss: 3.2736865854479515

Epoch: 5| Step: 2
Training loss: 3.130299156932073
Validation loss: 3.276877399058703

Epoch: 5| Step: 3
Training loss: 3.3040873386117258
Validation loss: 3.2768411748335193

Epoch: 5| Step: 4
Training loss: 3.0021295936156376
Validation loss: 3.273675372930039

Epoch: 5| Step: 5
Training loss: 3.681039743944173
Validation loss: 3.271771019818129

Epoch: 5| Step: 6
Training loss: 3.1429210260017024
Validation loss: 3.2572107820490572

Epoch: 5| Step: 7
Training loss: 3.545851505171715
Validation loss: 3.248192080010327

Epoch: 5| Step: 8
Training loss: 4.166032107034907
Validation loss: 3.252524201048334

Epoch: 5| Step: 9
Training loss: 3.7161852543358838
Validation loss: 3.2538485540943034

Epoch: 5| Step: 10
Training loss: 4.020751767821832
Validation loss: 3.253292295121284

Epoch: 51| Step: 0
Training loss: 3.907470146353151
Validation loss: 3.2534023441758158

Epoch: 5| Step: 1
Training loss: 2.7277488422952483
Validation loss: 3.2492399920465513

Epoch: 5| Step: 2
Training loss: 3.247646653503232
Validation loss: 3.2435672422188095

Epoch: 5| Step: 3
Training loss: 3.1024803513881456
Validation loss: 3.2401234878413985

Epoch: 5| Step: 4
Training loss: 3.752796020827403
Validation loss: 3.2362831039268274

Epoch: 5| Step: 5
Training loss: 3.133636898864995
Validation loss: 3.2364762653695136

Epoch: 5| Step: 6
Training loss: 3.9692805378659304
Validation loss: 3.2388854636075575

Epoch: 5| Step: 7
Training loss: 3.7190372131734244
Validation loss: 3.2427019636474133

Epoch: 5| Step: 8
Training loss: 3.8600403988162046
Validation loss: 3.2386845911292994

Epoch: 5| Step: 9
Training loss: 3.526217089543049
Validation loss: 3.235687140299379

Epoch: 5| Step: 10
Training loss: 3.128242336515315
Validation loss: 3.2304748700956836

Epoch: 52| Step: 0
Training loss: 3.1938434385602217
Validation loss: 3.2279932457704974

Epoch: 5| Step: 1
Training loss: 3.521954480199269
Validation loss: 3.22704331486474

Epoch: 5| Step: 2
Training loss: 3.3669881031448194
Validation loss: 3.224248899885012

Epoch: 5| Step: 3
Training loss: 3.034521480839406
Validation loss: 3.2222890714934693

Epoch: 5| Step: 4
Training loss: 3.5245803366759305
Validation loss: 3.222087804852264

Epoch: 5| Step: 5
Training loss: 3.8425195476801677
Validation loss: 3.21958989957951

Epoch: 5| Step: 6
Training loss: 4.0289607682163115
Validation loss: 3.217431007342447

Epoch: 5| Step: 7
Training loss: 3.8984812885034503
Validation loss: 3.212805258828084

Epoch: 5| Step: 8
Training loss: 3.8187454847942823
Validation loss: 3.2086252725072364

Epoch: 5| Step: 9
Training loss: 2.832273528160349
Validation loss: 3.20649303420378

Epoch: 5| Step: 10
Training loss: 2.660453970181332
Validation loss: 3.2052667524085505

Epoch: 53| Step: 0
Training loss: 3.385543038381566
Validation loss: 3.2109751974468352

Epoch: 5| Step: 1
Training loss: 3.3500799710421734
Validation loss: 3.2209173309495682

Epoch: 5| Step: 2
Training loss: 3.150639750592361
Validation loss: 3.227725546506287

Epoch: 5| Step: 3
Training loss: 3.3368889124198557
Validation loss: 3.2267818752268567

Epoch: 5| Step: 4
Training loss: 3.2231999718876976
Validation loss: 3.2096416015139417

Epoch: 5| Step: 5
Training loss: 3.368808435842677
Validation loss: 3.2054025527907135

Epoch: 5| Step: 6
Training loss: 3.628007101924721
Validation loss: 3.204457723836385

Epoch: 5| Step: 7
Training loss: 3.873567008576731
Validation loss: 3.2004235121335434

Epoch: 5| Step: 8
Training loss: 3.611261708632436
Validation loss: 3.1987211105393096

Epoch: 5| Step: 9
Training loss: 3.7101421588076664
Validation loss: 3.201397354415762

Epoch: 5| Step: 10
Training loss: 3.2618810190736225
Validation loss: 3.199874615776453

Epoch: 54| Step: 0
Training loss: 2.890996795663077
Validation loss: 3.200525313631176

Epoch: 5| Step: 1
Training loss: 4.279845069861932
Validation loss: 3.200176637463311

Epoch: 5| Step: 2
Training loss: 3.335320230233974
Validation loss: 3.201936432353149

Epoch: 5| Step: 3
Training loss: 3.8679000043991265
Validation loss: 3.20730484734471

Epoch: 5| Step: 4
Training loss: 3.665067295013495
Validation loss: 3.201913495958915

Epoch: 5| Step: 5
Training loss: 2.9910995059129113
Validation loss: 3.199916563913905

Epoch: 5| Step: 6
Training loss: 3.280761973100991
Validation loss: 3.199422115526473

Epoch: 5| Step: 7
Training loss: 3.182525492983327
Validation loss: 3.1981264231105984

Epoch: 5| Step: 8
Training loss: 3.9667463876956988
Validation loss: 3.1998701829048053

Epoch: 5| Step: 9
Training loss: 2.6505899600335145
Validation loss: 3.19432318883688

Epoch: 5| Step: 10
Training loss: 3.531436881462545
Validation loss: 3.1977701129836817

Epoch: 55| Step: 0
Training loss: 3.7180992005787363
Validation loss: 3.192400374335827

Epoch: 5| Step: 1
Training loss: 2.37859654407178
Validation loss: 3.191677597133422

Epoch: 5| Step: 2
Training loss: 3.714455312482924
Validation loss: 3.1930286878618164

Epoch: 5| Step: 3
Training loss: 3.6571613708308472
Validation loss: 3.19269295432978

Epoch: 5| Step: 4
Training loss: 3.677186152215696
Validation loss: 3.189713932735983

Epoch: 5| Step: 5
Training loss: 3.6203138381896265
Validation loss: 3.1935123391539184

Epoch: 5| Step: 6
Training loss: 3.0545264004034602
Validation loss: 3.1923714750305026

Epoch: 5| Step: 7
Training loss: 3.784328122088824
Validation loss: 3.1907959388861173

Epoch: 5| Step: 8
Training loss: 3.0431845200398633
Validation loss: 3.1940790820511946

Epoch: 5| Step: 9
Training loss: 3.3181903834250224
Validation loss: 3.1914638184191637

Epoch: 5| Step: 10
Training loss: 3.709082338506823
Validation loss: 3.189560481794084

Epoch: 56| Step: 0
Training loss: 4.133237070582889
Validation loss: 3.190914621307535

Epoch: 5| Step: 1
Training loss: 3.257278215612134
Validation loss: 3.188772362198154

Epoch: 5| Step: 2
Training loss: 3.8328719621626446
Validation loss: 3.1876024973292605

Epoch: 5| Step: 3
Training loss: 3.5536590094361444
Validation loss: 3.1888095756119186

Epoch: 5| Step: 4
Training loss: 2.940456606901022
Validation loss: 3.188963979948619

Epoch: 5| Step: 5
Training loss: 3.220165645058684
Validation loss: 3.1840473290048164

Epoch: 5| Step: 6
Training loss: 3.327554143383461
Validation loss: 3.1861395686353995

Epoch: 5| Step: 7
Training loss: 3.528448157973051
Validation loss: 3.1867083685022983

Epoch: 5| Step: 8
Training loss: 3.1489499718625207
Validation loss: 3.185324334744318

Epoch: 5| Step: 9
Training loss: 3.5032337780958467
Validation loss: 3.1835294262917846

Epoch: 5| Step: 10
Training loss: 3.173365501139256
Validation loss: 3.1816040480934102

Epoch: 57| Step: 0
Training loss: 3.175660829032251
Validation loss: 3.1832521248382766

Epoch: 5| Step: 1
Training loss: 3.6884067519704162
Validation loss: 3.184114060876119

Epoch: 5| Step: 2
Training loss: 3.336525644097204
Validation loss: 3.18223522236854

Epoch: 5| Step: 3
Training loss: 3.29377405494433
Validation loss: 3.1827597062027055

Epoch: 5| Step: 4
Training loss: 2.7797334801235927
Validation loss: 3.1811579418201585

Epoch: 5| Step: 5
Training loss: 4.18980549217453
Validation loss: 3.1836309192630936

Epoch: 5| Step: 6
Training loss: 2.3897588818917113
Validation loss: 3.1806682037663365

Epoch: 5| Step: 7
Training loss: 4.152020589861965
Validation loss: 3.1803015397486085

Epoch: 5| Step: 8
Training loss: 2.823814014859183
Validation loss: 3.182759921265132

Epoch: 5| Step: 9
Training loss: 3.742020318551614
Validation loss: 3.1827962239167173

Epoch: 5| Step: 10
Training loss: 3.7925690775284115
Validation loss: 3.1858345681903586

Epoch: 58| Step: 0
Training loss: 3.480189799252098
Validation loss: 3.18012407352451

Epoch: 5| Step: 1
Training loss: 3.016328561568353
Validation loss: 3.1783096639115116

Epoch: 5| Step: 2
Training loss: 4.534408205359013
Validation loss: 3.1798542800640743

Epoch: 5| Step: 3
Training loss: 3.2598378863133584
Validation loss: 3.1771315723121196

Epoch: 5| Step: 4
Training loss: 2.9341177440646713
Validation loss: 3.174533411509912

Epoch: 5| Step: 5
Training loss: 3.208674243468134
Validation loss: 3.1766833530501644

Epoch: 5| Step: 6
Training loss: 3.201552586612275
Validation loss: 3.178931092353625

Epoch: 5| Step: 7
Training loss: 4.183351653972089
Validation loss: 3.1757057101342605

Epoch: 5| Step: 8
Training loss: 2.388713695942924
Validation loss: 3.176947620276459

Epoch: 5| Step: 9
Training loss: 3.2325272004177212
Validation loss: 3.1802484269973292

Epoch: 5| Step: 10
Training loss: 3.8625748068469523
Validation loss: 3.1800106682852882

Epoch: 59| Step: 0
Training loss: 3.511068553371553
Validation loss: 3.1796720101809983

Epoch: 5| Step: 1
Training loss: 2.9406153614887534
Validation loss: 3.176788488000965

Epoch: 5| Step: 2
Training loss: 3.304090946543728
Validation loss: 3.1771360062473035

Epoch: 5| Step: 3
Training loss: 3.4849777726678215
Validation loss: 3.1730655036520186

Epoch: 5| Step: 4
Training loss: 3.753949183953881
Validation loss: 3.1766870346641314

Epoch: 5| Step: 5
Training loss: 3.257202384041475
Validation loss: 3.1770451444404793

Epoch: 5| Step: 6
Training loss: 3.1585965639866576
Validation loss: 3.172937484887405

Epoch: 5| Step: 7
Training loss: 3.796369982127497
Validation loss: 3.175916871097753

Epoch: 5| Step: 8
Training loss: 3.6903827842927748
Validation loss: 3.1740664708051454

Epoch: 5| Step: 9
Training loss: 3.4432614680936866
Validation loss: 3.173461979371089

Epoch: 5| Step: 10
Training loss: 3.298784037736407
Validation loss: 3.170766435774788

Epoch: 60| Step: 0
Training loss: 2.7816248437546034
Validation loss: 3.17481054183729

Epoch: 5| Step: 1
Training loss: 3.75898239102391
Validation loss: 3.1716006095800027

Epoch: 5| Step: 2
Training loss: 3.2809632675593505
Validation loss: 3.1768229265710324

Epoch: 5| Step: 3
Training loss: 3.6401228005791095
Validation loss: 3.1985056841970265

Epoch: 5| Step: 4
Training loss: 3.2456749233885067
Validation loss: 3.1780769353141154

Epoch: 5| Step: 5
Training loss: 3.306471467127343
Validation loss: 3.1708271868746447

Epoch: 5| Step: 6
Training loss: 2.9531104677841844
Validation loss: 3.1710828835385163

Epoch: 5| Step: 7
Training loss: 3.973287676627842
Validation loss: 3.1709687883117077

Epoch: 5| Step: 8
Training loss: 3.8852926580498783
Validation loss: 3.171420291217485

Epoch: 5| Step: 9
Training loss: 3.282029413569172
Validation loss: 3.1722757686510783

Epoch: 5| Step: 10
Training loss: 3.420943320609072
Validation loss: 3.1751921212164644

Epoch: 61| Step: 0
Training loss: 3.1946567151589167
Validation loss: 3.1762834020344246

Epoch: 5| Step: 1
Training loss: 4.159498049823951
Validation loss: 3.172275393674433

Epoch: 5| Step: 2
Training loss: 3.347904797010541
Validation loss: 3.172823227688407

Epoch: 5| Step: 3
Training loss: 3.1184873237150392
Validation loss: 3.1737439149550095

Epoch: 5| Step: 4
Training loss: 3.14454550414083
Validation loss: 3.174364355484086

Epoch: 5| Step: 5
Training loss: 3.4588062621773634
Validation loss: 3.1736563681296373

Epoch: 5| Step: 6
Training loss: 3.5847018238387025
Validation loss: 3.1794538030837214

Epoch: 5| Step: 7
Training loss: 3.434132539140957
Validation loss: 3.1862199365685107

Epoch: 5| Step: 8
Training loss: 3.218080024990244
Validation loss: 3.1775211419221354

Epoch: 5| Step: 9
Training loss: 3.554808092691742
Validation loss: 3.172675061299599

Epoch: 5| Step: 10
Training loss: 3.3457484467705254
Validation loss: 3.169595732451762

Epoch: 62| Step: 0
Training loss: 3.351410406614208
Validation loss: 3.1725110815945863

Epoch: 5| Step: 1
Training loss: 3.4282566987631986
Validation loss: 3.180973111247935

Epoch: 5| Step: 2
Training loss: 4.00344366611348
Validation loss: 3.185749275300894

Epoch: 5| Step: 3
Training loss: 3.9135003514258626
Validation loss: 3.173863526606738

Epoch: 5| Step: 4
Training loss: 3.353138657512741
Validation loss: 3.169724331017439

Epoch: 5| Step: 5
Training loss: 3.073051492782853
Validation loss: 3.169012187646061

Epoch: 5| Step: 6
Training loss: 2.957386313000263
Validation loss: 3.167263761345793

Epoch: 5| Step: 7
Training loss: 2.23189316143166
Validation loss: 3.1678879999681517

Epoch: 5| Step: 8
Training loss: 3.351104207038794
Validation loss: 3.1654470185827264

Epoch: 5| Step: 9
Training loss: 3.6357263179968595
Validation loss: 3.167176282275891

Epoch: 5| Step: 10
Training loss: 4.043532239188943
Validation loss: 3.1663162791036155

Epoch: 63| Step: 0
Training loss: 3.11154421183472
Validation loss: 3.1641213858596613

Epoch: 5| Step: 1
Training loss: 3.9430274313529514
Validation loss: 3.161579682314965

Epoch: 5| Step: 2
Training loss: 3.1758141322386697
Validation loss: 3.1638943308331986

Epoch: 5| Step: 3
Training loss: 3.743088520182481
Validation loss: 3.1630501283522428

Epoch: 5| Step: 4
Training loss: 3.3139204902204473
Validation loss: 3.162927018042358

Epoch: 5| Step: 5
Training loss: 3.4630783038802564
Validation loss: 3.1606439306205867

Epoch: 5| Step: 6
Training loss: 3.530600428969283
Validation loss: 3.1643505666664296

Epoch: 5| Step: 7
Training loss: 3.3802580670585716
Validation loss: 3.1620077085051626

Epoch: 5| Step: 8
Training loss: 2.919320034913534
Validation loss: 3.1619630691698237

Epoch: 5| Step: 9
Training loss: 2.8450934621681023
Validation loss: 3.1637106706547446

Epoch: 5| Step: 10
Training loss: 4.061559245416508
Validation loss: 3.161462046732937

Epoch: 64| Step: 0
Training loss: 3.19371623340531
Validation loss: 3.1619421284035516

Epoch: 5| Step: 1
Training loss: 2.744329849181027
Validation loss: 3.158824787047734

Epoch: 5| Step: 2
Training loss: 3.5225619224157603
Validation loss: 3.163547973849107

Epoch: 5| Step: 3
Training loss: 3.543940737803606
Validation loss: 3.160390127915024

Epoch: 5| Step: 4
Training loss: 3.4079614941655856
Validation loss: 3.160573586839548

Epoch: 5| Step: 5
Training loss: 3.2099848538335536
Validation loss: 3.161228575751169

Epoch: 5| Step: 6
Training loss: 3.6489307143704943
Validation loss: 3.158683391949673

Epoch: 5| Step: 7
Training loss: 3.9149898564973387
Validation loss: 3.1616879369160014

Epoch: 5| Step: 8
Training loss: 3.711488188991899
Validation loss: 3.162163356684635

Epoch: 5| Step: 9
Training loss: 3.338337876660713
Validation loss: 3.1607624182780114

Epoch: 5| Step: 10
Training loss: 3.1431526905902527
Validation loss: 3.1588905828177025

Epoch: 65| Step: 0
Training loss: 3.649151293180712
Validation loss: 3.158341757453344

Epoch: 5| Step: 1
Training loss: 3.0715803096207184
Validation loss: 3.1589287325693745

Epoch: 5| Step: 2
Training loss: 3.6080100380869955
Validation loss: 3.158078835379161

Epoch: 5| Step: 3
Training loss: 3.183114119832641
Validation loss: 3.157720105853691

Epoch: 5| Step: 4
Training loss: 3.667361728217338
Validation loss: 3.1599592248366157

Epoch: 5| Step: 5
Training loss: 3.7838724673678152
Validation loss: 3.1589930637845196

Epoch: 5| Step: 6
Training loss: 3.357024466099586
Validation loss: 3.1571596813126823

Epoch: 5| Step: 7
Training loss: 3.2020955734333363
Validation loss: 3.156063372003264

Epoch: 5| Step: 8
Training loss: 3.4505511741983654
Validation loss: 3.1560426000394783

Epoch: 5| Step: 9
Training loss: 3.4999629427446712
Validation loss: 3.1599065279217275

Epoch: 5| Step: 10
Training loss: 2.8975883124176347
Validation loss: 3.1567975534545143

Epoch: 66| Step: 0
Training loss: 3.6259143596957246
Validation loss: 3.15618024708564

Epoch: 5| Step: 1
Training loss: 2.863442618076039
Validation loss: 3.1603773420930845

Epoch: 5| Step: 2
Training loss: 3.402809014901443
Validation loss: 3.1567766320213893

Epoch: 5| Step: 3
Training loss: 4.11366657071636
Validation loss: 3.1555125307911647

Epoch: 5| Step: 4
Training loss: 3.734152049029144
Validation loss: 3.1543400607500107

Epoch: 5| Step: 5
Training loss: 3.3867660571955476
Validation loss: 3.154248542279467

Epoch: 5| Step: 6
Training loss: 2.830972997323052
Validation loss: 3.1542842627898966

Epoch: 5| Step: 7
Training loss: 3.6069507466785353
Validation loss: 3.154841387002061

Epoch: 5| Step: 8
Training loss: 2.4411232257824653
Validation loss: 3.1527829877538007

Epoch: 5| Step: 9
Training loss: 3.519706831774576
Validation loss: 3.15629459830036

Epoch: 5| Step: 10
Training loss: 3.6776523023818273
Validation loss: 3.166457751128565

Epoch: 67| Step: 0
Training loss: 3.3853868375588916
Validation loss: 3.1581959524548906

Epoch: 5| Step: 1
Training loss: 3.347371502120069
Validation loss: 3.156670746100966

Epoch: 5| Step: 2
Training loss: 3.862795777091398
Validation loss: 3.1527518054689305

Epoch: 5| Step: 3
Training loss: 3.2302978175190233
Validation loss: 3.1546882153224454

Epoch: 5| Step: 4
Training loss: 3.1211275139463606
Validation loss: 3.152278767476218

Epoch: 5| Step: 5
Training loss: 3.7118594660629034
Validation loss: 3.1544045213065353

Epoch: 5| Step: 6
Training loss: 3.6905922289886464
Validation loss: 3.1522664651798706

Epoch: 5| Step: 7
Training loss: 3.3862035374852812
Validation loss: 3.150552398249185

Epoch: 5| Step: 8
Training loss: 3.2212217155165113
Validation loss: 3.1516739779940384

Epoch: 5| Step: 9
Training loss: 3.3999727135853606
Validation loss: 3.1497235851238234

Epoch: 5| Step: 10
Training loss: 2.9911012595179622
Validation loss: 3.1495083278200147

Epoch: 68| Step: 0
Training loss: 3.9445869005175767
Validation loss: 3.1507822796280887

Epoch: 5| Step: 1
Training loss: 3.8439620044827105
Validation loss: 3.1499640567719243

Epoch: 5| Step: 2
Training loss: 2.8599701142250167
Validation loss: 3.151602223604573

Epoch: 5| Step: 3
Training loss: 3.4231055150531806
Validation loss: 3.1502317926351733

Epoch: 5| Step: 4
Training loss: 2.7768476984818533
Validation loss: 3.1490507361982027

Epoch: 5| Step: 5
Training loss: 3.3262547355540732
Validation loss: 3.1485779710397135

Epoch: 5| Step: 6
Training loss: 2.6398261854000036
Validation loss: 3.1503484478862993

Epoch: 5| Step: 7
Training loss: 3.7116665093967613
Validation loss: 3.1504044921387524

Epoch: 5| Step: 8
Training loss: 3.944464201422509
Validation loss: 3.150528987683104

Epoch: 5| Step: 9
Training loss: 3.591688277909004
Validation loss: 3.149493054239341

Epoch: 5| Step: 10
Training loss: 3.0292125028546892
Validation loss: 3.1500087839483637

Epoch: 69| Step: 0
Training loss: 3.2002835207747276
Validation loss: 3.1473443560523564

Epoch: 5| Step: 1
Training loss: 3.1125256089225566
Validation loss: 3.147964461952505

Epoch: 5| Step: 2
Training loss: 3.8812311586669037
Validation loss: 3.1513239252151894

Epoch: 5| Step: 3
Training loss: 3.4395837190390237
Validation loss: 3.1493559908061965

Epoch: 5| Step: 4
Training loss: 2.9422760142313127
Validation loss: 3.147961163710057

Epoch: 5| Step: 5
Training loss: 3.0237021318094777
Validation loss: 3.150201971816176

Epoch: 5| Step: 6
Training loss: 3.9482766073737743
Validation loss: 3.1481512899367714

Epoch: 5| Step: 7
Training loss: 3.428300511919049
Validation loss: 3.147660315261275

Epoch: 5| Step: 8
Training loss: 3.084681774524797
Validation loss: 3.145020195999041

Epoch: 5| Step: 9
Training loss: 3.7038876033974186
Validation loss: 3.1464637092706127

Epoch: 5| Step: 10
Training loss: 3.4881907554926093
Validation loss: 3.1441686240908746

Epoch: 70| Step: 0
Training loss: 3.300677235787188
Validation loss: 3.1447496156330357

Epoch: 5| Step: 1
Training loss: 3.5423884983861575
Validation loss: 3.142620014831857

Epoch: 5| Step: 2
Training loss: 3.6582435324616993
Validation loss: 3.1431514100553843

Epoch: 5| Step: 3
Training loss: 3.537696423148945
Validation loss: 3.1437744860548813

Epoch: 5| Step: 4
Training loss: 3.4763586777506243
Validation loss: 3.1420123430207036

Epoch: 5| Step: 5
Training loss: 3.2184326608015676
Validation loss: 3.1441180426033397

Epoch: 5| Step: 6
Training loss: 3.3124513442586676
Validation loss: 3.1452613614287976

Epoch: 5| Step: 7
Training loss: 3.6404733257869917
Validation loss: 3.1426935438006716

Epoch: 5| Step: 8
Training loss: 2.9912337334362347
Validation loss: 3.144350465298512

Epoch: 5| Step: 9
Training loss: 3.4510577473878445
Validation loss: 3.146067749060389

Epoch: 5| Step: 10
Training loss: 3.2361465983339204
Validation loss: 3.1458935801449623

Epoch: 71| Step: 0
Training loss: 4.061404740804336
Validation loss: 3.149574301934978

Epoch: 5| Step: 1
Training loss: 3.65364869005015
Validation loss: 3.1469600207961057

Epoch: 5| Step: 2
Training loss: 3.4734804357568287
Validation loss: 3.1465787680099147

Epoch: 5| Step: 3
Training loss: 3.3021901752182754
Validation loss: 3.1471428158954833

Epoch: 5| Step: 4
Training loss: 2.688116224745135
Validation loss: 3.1497123553724036

Epoch: 5| Step: 5
Training loss: 3.7266177767126774
Validation loss: 3.1451242276961553

Epoch: 5| Step: 6
Training loss: 3.196939292104613
Validation loss: 3.146983131243541

Epoch: 5| Step: 7
Training loss: 3.5889811844139885
Validation loss: 3.142359786319554

Epoch: 5| Step: 8
Training loss: 3.223681477546558
Validation loss: 3.14502477709836

Epoch: 5| Step: 9
Training loss: 3.0871137863952094
Validation loss: 3.14306493114748

Epoch: 5| Step: 10
Training loss: 3.172067720919374
Validation loss: 3.143452654150981

Epoch: 72| Step: 0
Training loss: 3.339662424262702
Validation loss: 3.1460738019193357

Epoch: 5| Step: 1
Training loss: 3.6983815648660188
Validation loss: 3.1398688834499797

Epoch: 5| Step: 2
Training loss: 2.4784384761313447
Validation loss: 3.1383756581042586

Epoch: 5| Step: 3
Training loss: 3.2218473771813874
Validation loss: 3.1381663383388423

Epoch: 5| Step: 4
Training loss: 3.296899009002478
Validation loss: 3.1381558065483097

Epoch: 5| Step: 5
Training loss: 3.3609090451818764
Validation loss: 3.138036294554474

Epoch: 5| Step: 6
Training loss: 4.03949975721923
Validation loss: 3.1397255683163796

Epoch: 5| Step: 7
Training loss: 3.3796356295953807
Validation loss: 3.1397960182824356

Epoch: 5| Step: 8
Training loss: 3.3776908320257033
Validation loss: 3.136669763917028

Epoch: 5| Step: 9
Training loss: 3.645593224747812
Validation loss: 3.1404812883541715

Epoch: 5| Step: 10
Training loss: 3.3211424743911664
Validation loss: 3.1436331610209876

Epoch: 73| Step: 0
Training loss: 3.611099689824228
Validation loss: 3.1447791441381576

Epoch: 5| Step: 1
Training loss: 2.899725203813181
Validation loss: 3.1415732232877307

Epoch: 5| Step: 2
Training loss: 3.7204643593418956
Validation loss: 3.1456374512364245

Epoch: 5| Step: 3
Training loss: 3.920325835757571
Validation loss: 3.1438635157214185

Epoch: 5| Step: 4
Training loss: 2.9829286595662197
Validation loss: 3.136354467987707

Epoch: 5| Step: 5
Training loss: 3.7885818648528495
Validation loss: 3.14161441167966

Epoch: 5| Step: 6
Training loss: 3.088185710669218
Validation loss: 3.1381442666323736

Epoch: 5| Step: 7
Training loss: 3.548525388461544
Validation loss: 3.1363401128628845

Epoch: 5| Step: 8
Training loss: 3.196815491660369
Validation loss: 3.136955699241846

Epoch: 5| Step: 9
Training loss: 3.0540763067918784
Validation loss: 3.1347775249212524

Epoch: 5| Step: 10
Training loss: 3.34767348508727
Validation loss: 3.136127348182766

Epoch: 74| Step: 0
Training loss: 3.1796600565557864
Validation loss: 3.136212952458606

Epoch: 5| Step: 1
Training loss: 3.5515701206593753
Validation loss: 3.1402625475405896

Epoch: 5| Step: 2
Training loss: 2.991260036223712
Validation loss: 3.1392941382257145

Epoch: 5| Step: 3
Training loss: 3.5573664034155117
Validation loss: 3.1451002371147045

Epoch: 5| Step: 4
Training loss: 3.5984308690793902
Validation loss: 3.1538706115659796

Epoch: 5| Step: 5
Training loss: 3.443893036407464
Validation loss: 3.1611668981399856

Epoch: 5| Step: 6
Training loss: 3.3140400599358877
Validation loss: 3.161585330853515

Epoch: 5| Step: 7
Training loss: 3.3602327892860875
Validation loss: 3.152587822622312

Epoch: 5| Step: 8
Training loss: 2.8771646063225162
Validation loss: 3.139231141150094

Epoch: 5| Step: 9
Training loss: 4.021037094935541
Validation loss: 3.131635401641516

Epoch: 5| Step: 10
Training loss: 3.349086887548109
Validation loss: 3.1314149491484007

Epoch: 75| Step: 0
Training loss: 3.3894150504408977
Validation loss: 3.1343530931842993

Epoch: 5| Step: 1
Training loss: 3.0308225664631583
Validation loss: 3.1335608118222593

Epoch: 5| Step: 2
Training loss: 2.9228646137571963
Validation loss: 3.135727561413036

Epoch: 5| Step: 3
Training loss: 3.48926396213249
Validation loss: 3.1352634040207032

Epoch: 5| Step: 4
Training loss: 3.7467114334101823
Validation loss: 3.1328121039334795

Epoch: 5| Step: 5
Training loss: 3.3565046956123092
Validation loss: 3.135052783147057

Epoch: 5| Step: 6
Training loss: 3.253930136420055
Validation loss: 3.132583180562637

Epoch: 5| Step: 7
Training loss: 2.9572520003570415
Validation loss: 3.131196292191198

Epoch: 5| Step: 8
Training loss: 4.346585233506721
Validation loss: 3.1309128195582114

Epoch: 5| Step: 9
Training loss: 3.2186340014842094
Validation loss: 3.1308811934600995

Epoch: 5| Step: 10
Training loss: 3.3955024760887027
Validation loss: 3.129594653258563

Epoch: 76| Step: 0
Training loss: 3.0290708279217253
Validation loss: 3.1283385468832003

Epoch: 5| Step: 1
Training loss: 3.698985687615931
Validation loss: 3.1300741482266745

Epoch: 5| Step: 2
Training loss: 3.121901081881242
Validation loss: 3.128880991259022

Epoch: 5| Step: 3
Training loss: 3.3776561034049415
Validation loss: 3.128403730858508

Epoch: 5| Step: 4
Training loss: 3.736172805963738
Validation loss: 3.127309588068606

Epoch: 5| Step: 5
Training loss: 2.6661283923323413
Validation loss: 3.1271377028054235

Epoch: 5| Step: 6
Training loss: 2.8297436544827606
Validation loss: 3.128758858584398

Epoch: 5| Step: 7
Training loss: 3.2754137724193257
Validation loss: 3.12791390694665

Epoch: 5| Step: 8
Training loss: 3.2843829502405115
Validation loss: 3.127980482408402

Epoch: 5| Step: 9
Training loss: 4.361754065631478
Validation loss: 3.1256264647263476

Epoch: 5| Step: 10
Training loss: 3.592194726512753
Validation loss: 3.125847354981397

Epoch: 77| Step: 0
Training loss: 3.0546609628602748
Validation loss: 3.128043366765439

Epoch: 5| Step: 1
Training loss: 3.4867179075697785
Validation loss: 3.126321968289091

Epoch: 5| Step: 2
Training loss: 3.391002862504422
Validation loss: 3.133410694783588

Epoch: 5| Step: 3
Training loss: 3.186447568195403
Validation loss: 3.1358695942649017

Epoch: 5| Step: 4
Training loss: 3.2556767403879077
Validation loss: 3.1327071249003704

Epoch: 5| Step: 5
Training loss: 3.856598136928231
Validation loss: 3.134585520215644

Epoch: 5| Step: 6
Training loss: 3.9112597269904668
Validation loss: 3.136338075904421

Epoch: 5| Step: 7
Training loss: 3.430078158363939
Validation loss: 3.1266890426070515

Epoch: 5| Step: 8
Training loss: 3.164219680461245
Validation loss: 3.1275612243281956

Epoch: 5| Step: 9
Training loss: 3.2513339899544924
Validation loss: 3.1227568748713606

Epoch: 5| Step: 10
Training loss: 3.089361449745771
Validation loss: 3.1216370927702872

Epoch: 78| Step: 0
Training loss: 3.6985632246120432
Validation loss: 3.1231861026647456

Epoch: 5| Step: 1
Training loss: 3.115083141901197
Validation loss: 3.124057461921175

Epoch: 5| Step: 2
Training loss: 3.494682223126619
Validation loss: 3.1225196404471878

Epoch: 5| Step: 3
Training loss: 3.6014049437642703
Validation loss: 3.120720906231919

Epoch: 5| Step: 4
Training loss: 2.5268798591063204
Validation loss: 3.1230899510995904

Epoch: 5| Step: 5
Training loss: 3.190705576149174
Validation loss: 3.1226507368139185

Epoch: 5| Step: 6
Training loss: 3.1323905527489977
Validation loss: 3.1202694648915426

Epoch: 5| Step: 7
Training loss: 2.3351398241544445
Validation loss: 3.122292488895734

Epoch: 5| Step: 8
Training loss: 3.717174292368954
Validation loss: 3.120702228782168

Epoch: 5| Step: 9
Training loss: 4.100071110922837
Validation loss: 3.1216989798219417

Epoch: 5| Step: 10
Training loss: 3.9408911981903434
Validation loss: 3.12131111882711

Epoch: 79| Step: 0
Training loss: 3.595646100936341
Validation loss: 3.1211503433780043

Epoch: 5| Step: 1
Training loss: 3.424877504260474
Validation loss: 3.120708702154433

Epoch: 5| Step: 2
Training loss: 3.1938410497776992
Validation loss: 3.1232274925001877

Epoch: 5| Step: 3
Training loss: 3.5492548415716674
Validation loss: 3.129394145810267

Epoch: 5| Step: 4
Training loss: 3.50222176469788
Validation loss: 3.1374715892258944

Epoch: 5| Step: 5
Training loss: 3.3807514775081207
Validation loss: 3.1484750159027035

Epoch: 5| Step: 6
Training loss: 2.944862553962571
Validation loss: 3.1349863276178827

Epoch: 5| Step: 7
Training loss: 3.4658661272595284
Validation loss: 3.136536844774396

Epoch: 5| Step: 8
Training loss: 3.0901435870539804
Validation loss: 3.137205429182078

Epoch: 5| Step: 9
Training loss: 3.109179006562445
Validation loss: 3.136563135464786

Epoch: 5| Step: 10
Training loss: 3.9105658531014242
Validation loss: 3.121903067492228

Epoch: 80| Step: 0
Training loss: 3.46837208381745
Validation loss: 3.122646250964019

Epoch: 5| Step: 1
Training loss: 3.2476307963166886
Validation loss: 3.1182438113383295

Epoch: 5| Step: 2
Training loss: 3.5074685656660907
Validation loss: 3.1197990436430105

Epoch: 5| Step: 3
Training loss: 3.986835512861825
Validation loss: 3.118577159955476

Epoch: 5| Step: 4
Training loss: 3.1393673024889144
Validation loss: 3.1169327167032326

Epoch: 5| Step: 5
Training loss: 3.2171145237727896
Validation loss: 3.1163306826782478

Epoch: 5| Step: 6
Training loss: 2.8747450674060966
Validation loss: 3.1155792025937274

Epoch: 5| Step: 7
Training loss: 3.1945529771878975
Validation loss: 3.1171241918514974

Epoch: 5| Step: 8
Training loss: 3.1788363430523825
Validation loss: 3.118656931933646

Epoch: 5| Step: 9
Training loss: 3.7016481440351363
Validation loss: 3.11426160577903

Epoch: 5| Step: 10
Training loss: 3.5131994399507986
Validation loss: 3.1171030477274337

Epoch: 81| Step: 0
Training loss: 2.580081359260605
Validation loss: 3.11481963503561

Epoch: 5| Step: 1
Training loss: 3.592483164536138
Validation loss: 3.117243723486032

Epoch: 5| Step: 2
Training loss: 4.194423815835804
Validation loss: 3.117095971416921

Epoch: 5| Step: 3
Training loss: 3.350619665880588
Validation loss: 3.1182519834236655

Epoch: 5| Step: 4
Training loss: 3.6201040156052517
Validation loss: 3.124957785372525

Epoch: 5| Step: 5
Training loss: 2.5212011673169443
Validation loss: 3.1285919449044295

Epoch: 5| Step: 6
Training loss: 3.807237589078515
Validation loss: 3.1287258226703187

Epoch: 5| Step: 7
Training loss: 3.4438326678591493
Validation loss: 3.121157663479902

Epoch: 5| Step: 8
Training loss: 3.180746815875426
Validation loss: 3.124577670528541

Epoch: 5| Step: 9
Training loss: 2.9805079466315942
Validation loss: 3.1169714030219877

Epoch: 5| Step: 10
Training loss: 3.5477444427556386
Validation loss: 3.112995910476138

Epoch: 82| Step: 0
Training loss: 3.547222372513259
Validation loss: 3.113452396698015

Epoch: 5| Step: 1
Training loss: 3.4197499544076884
Validation loss: 3.113778590680511

Epoch: 5| Step: 2
Training loss: 3.575067938312474
Validation loss: 3.115574186522917

Epoch: 5| Step: 3
Training loss: 3.171038136695912
Validation loss: 3.1149717483762895

Epoch: 5| Step: 4
Training loss: 2.7455447259947787
Validation loss: 3.113861152258746

Epoch: 5| Step: 5
Training loss: 3.691309496706565
Validation loss: 3.1139902701276605

Epoch: 5| Step: 6
Training loss: 2.946281617698582
Validation loss: 3.1138145284534513

Epoch: 5| Step: 7
Training loss: 3.908465192206706
Validation loss: 3.113130475407346

Epoch: 5| Step: 8
Training loss: 3.0828342721192503
Validation loss: 3.110907475600249

Epoch: 5| Step: 9
Training loss: 3.3606928170136507
Validation loss: 3.1147561824613277

Epoch: 5| Step: 10
Training loss: 3.54821657864582
Validation loss: 3.1137239315378125

Epoch: 83| Step: 0
Training loss: 2.9767606574153125
Validation loss: 3.111656019715918

Epoch: 5| Step: 1
Training loss: 2.1724823027176394
Validation loss: 3.113365511153398

Epoch: 5| Step: 2
Training loss: 3.5325622820914946
Validation loss: 3.1161112782434492

Epoch: 5| Step: 3
Training loss: 3.5323603411993694
Validation loss: 3.114808925539329

Epoch: 5| Step: 4
Training loss: 3.2829576680814876
Validation loss: 3.119104028595314

Epoch: 5| Step: 5
Training loss: 4.045418613496365
Validation loss: 3.1183118231537104

Epoch: 5| Step: 6
Training loss: 2.5606435238124186
Validation loss: 3.1148475131336015

Epoch: 5| Step: 7
Training loss: 3.98217461357675
Validation loss: 3.1135604736683185

Epoch: 5| Step: 8
Training loss: 3.350064741049951
Validation loss: 3.1098009043407786

Epoch: 5| Step: 9
Training loss: 3.443686172807724
Validation loss: 3.1151641382084065

Epoch: 5| Step: 10
Training loss: 3.801394563062939
Validation loss: 3.1115527343754943

Epoch: 84| Step: 0
Training loss: 2.962884509407828
Validation loss: 3.112214689146198

Epoch: 5| Step: 1
Training loss: 3.603032075026115
Validation loss: 3.1097065515965805

Epoch: 5| Step: 2
Training loss: 3.6076970679583495
Validation loss: 3.1123671365480057

Epoch: 5| Step: 3
Training loss: 2.3388999092504883
Validation loss: 3.1113734182941593

Epoch: 5| Step: 4
Training loss: 2.816351817288873
Validation loss: 3.116496000760344

Epoch: 5| Step: 5
Training loss: 3.410144364553672
Validation loss: 3.1142269170251393

Epoch: 5| Step: 6
Training loss: 4.12897461804797
Validation loss: 3.1215558406441333

Epoch: 5| Step: 7
Training loss: 3.2040875733083825
Validation loss: 3.118025363723844

Epoch: 5| Step: 8
Training loss: 4.223766142223589
Validation loss: 3.1134403090497105

Epoch: 5| Step: 9
Training loss: 3.348979532620662
Validation loss: 3.108119327464956

Epoch: 5| Step: 10
Training loss: 2.879248920890604
Validation loss: 3.1081716981785656

Epoch: 85| Step: 0
Training loss: 2.7488819797363595
Validation loss: 3.1065047260612766

Epoch: 5| Step: 1
Training loss: 3.5841251356043498
Validation loss: 3.1076763103541323

Epoch: 5| Step: 2
Training loss: 3.6594061637613433
Validation loss: 3.107260511253256

Epoch: 5| Step: 3
Training loss: 3.5194079581797038
Validation loss: 3.1069308423350672

Epoch: 5| Step: 4
Training loss: 3.885749918509839
Validation loss: 3.1063295009017415

Epoch: 5| Step: 5
Training loss: 3.1219704247783833
Validation loss: 3.107270552077323

Epoch: 5| Step: 6
Training loss: 3.3465253773788164
Validation loss: 3.1069626000089623

Epoch: 5| Step: 7
Training loss: 2.8400412048789287
Validation loss: 3.1069761576512

Epoch: 5| Step: 8
Training loss: 3.0083700084476064
Validation loss: 3.103877054399921

Epoch: 5| Step: 9
Training loss: 3.0113764270229475
Validation loss: 3.1054005691804702

Epoch: 5| Step: 10
Training loss: 4.171830880721181
Validation loss: 3.1060627670577063

Epoch: 86| Step: 0
Training loss: 3.695638307560032
Validation loss: 3.1056235856488077

Epoch: 5| Step: 1
Training loss: 3.784478944820418
Validation loss: 3.1044412081188706

Epoch: 5| Step: 2
Training loss: 3.1065966591157594
Validation loss: 3.102777056210244

Epoch: 5| Step: 3
Training loss: 3.518598460428871
Validation loss: 3.10318398445973

Epoch: 5| Step: 4
Training loss: 3.8667842770371355
Validation loss: 3.1095281777485697

Epoch: 5| Step: 5
Training loss: 3.0469814184139943
Validation loss: 3.1047481130777963

Epoch: 5| Step: 6
Training loss: 3.677236724910469
Validation loss: 3.10790353867489

Epoch: 5| Step: 7
Training loss: 2.8534591429001037
Validation loss: 3.1134806485109725

Epoch: 5| Step: 8
Training loss: 3.0608798042534153
Validation loss: 3.1059789813077927

Epoch: 5| Step: 9
Training loss: 2.881885079585665
Validation loss: 3.1076126401532895

Epoch: 5| Step: 10
Training loss: 3.3428260738899236
Validation loss: 3.104633684051773

Epoch: 87| Step: 0
Training loss: 3.425231819939303
Validation loss: 3.100891460584422

Epoch: 5| Step: 1
Training loss: 3.288089708009421
Validation loss: 3.100478279764615

Epoch: 5| Step: 2
Training loss: 3.729554069187451
Validation loss: 3.1024148268492153

Epoch: 5| Step: 3
Training loss: 2.8073110396944063
Validation loss: 3.1041156681747175

Epoch: 5| Step: 4
Training loss: 3.411119951933243
Validation loss: 3.099279499379072

Epoch: 5| Step: 5
Training loss: 3.869812477161967
Validation loss: 3.099922945134712

Epoch: 5| Step: 6
Training loss: 3.8398457369018257
Validation loss: 3.1032361699744953

Epoch: 5| Step: 7
Training loss: 3.4049320295946686
Validation loss: 3.10232750326796

Epoch: 5| Step: 8
Training loss: 3.045692566533738
Validation loss: 3.101280650280163

Epoch: 5| Step: 9
Training loss: 2.922358345403622
Validation loss: 3.105887282546762

Epoch: 5| Step: 10
Training loss: 3.0629077562072724
Validation loss: 3.1022649339319974

Epoch: 88| Step: 0
Training loss: 3.383238732529684
Validation loss: 3.103549832121897

Epoch: 5| Step: 1
Training loss: 3.4202511910441413
Validation loss: 3.109584257764847

Epoch: 5| Step: 2
Training loss: 3.6433024895547046
Validation loss: 3.10373846881708

Epoch: 5| Step: 3
Training loss: 3.0634776520658726
Validation loss: 3.1003918839690674

Epoch: 5| Step: 4
Training loss: 2.668766913259903
Validation loss: 3.099789252512422

Epoch: 5| Step: 5
Training loss: 3.5606035237453924
Validation loss: 3.099200582751786

Epoch: 5| Step: 6
Training loss: 3.4874024517677484
Validation loss: 3.1001951903130056

Epoch: 5| Step: 7
Training loss: 3.434451051517339
Validation loss: 3.0964563803891108

Epoch: 5| Step: 8
Training loss: 2.9213504422393544
Validation loss: 3.0992203559380083

Epoch: 5| Step: 9
Training loss: 3.9430129195177495
Validation loss: 3.1000605997704866

Epoch: 5| Step: 10
Training loss: 3.280972568954209
Validation loss: 3.0974769719893422

Epoch: 89| Step: 0
Training loss: 3.3897470489023207
Validation loss: 3.1006488152173652

Epoch: 5| Step: 1
Training loss: 2.9752585290726143
Validation loss: 3.101662433312342

Epoch: 5| Step: 2
Training loss: 3.875805801778276
Validation loss: 3.0978593015803013

Epoch: 5| Step: 3
Training loss: 2.8639777820833543
Validation loss: 3.0974548636044648

Epoch: 5| Step: 4
Training loss: 3.0737716950794636
Validation loss: 3.0985845331909814

Epoch: 5| Step: 5
Training loss: 3.517769121558482
Validation loss: 3.099528269149868

Epoch: 5| Step: 6
Training loss: 3.7933690088758834
Validation loss: 3.0932436988978367

Epoch: 5| Step: 7
Training loss: 3.7133647489560007
Validation loss: 3.096424586163381

Epoch: 5| Step: 8
Training loss: 2.6766521735014726
Validation loss: 3.0961763693537923

Epoch: 5| Step: 9
Training loss: 3.2031513492151764
Validation loss: 3.0953224886752797

Epoch: 5| Step: 10
Training loss: 3.6645428112942144
Validation loss: 3.0968878577336416

Epoch: 90| Step: 0
Training loss: 3.892459666607292
Validation loss: 3.096673395700205

Epoch: 5| Step: 1
Training loss: 2.794369219742208
Validation loss: 3.0949546811097512

Epoch: 5| Step: 2
Training loss: 3.721543489004496
Validation loss: 3.0935027569680797

Epoch: 5| Step: 3
Training loss: 3.10321723362975
Validation loss: 3.0945490665617084

Epoch: 5| Step: 4
Training loss: 2.832066776447428
Validation loss: 3.096596258851369

Epoch: 5| Step: 5
Training loss: 3.094743357233933
Validation loss: 3.092296173811386

Epoch: 5| Step: 6
Training loss: 3.805628603367972
Validation loss: 3.0939685043746064

Epoch: 5| Step: 7
Training loss: 3.299739515254238
Validation loss: 3.092562180105533

Epoch: 5| Step: 8
Training loss: 3.5246496039936535
Validation loss: 3.0915415216760267

Epoch: 5| Step: 9
Training loss: 2.701929699116634
Validation loss: 3.088745844755172

Epoch: 5| Step: 10
Training loss: 3.9413335394603313
Validation loss: 3.0878531766931343

Epoch: 91| Step: 0
Training loss: 3.8783842505793054
Validation loss: 3.0897679651828307

Epoch: 5| Step: 1
Training loss: 3.409220948484556
Validation loss: 3.0885079617935123

Epoch: 5| Step: 2
Training loss: 3.328555943343712
Validation loss: 3.0829785488474526

Epoch: 5| Step: 3
Training loss: 3.1978002437974387
Validation loss: 3.0839621715516214

Epoch: 5| Step: 4
Training loss: 3.5212352154644475
Validation loss: 3.0802407429570837

Epoch: 5| Step: 5
Training loss: 2.9775308951081
Validation loss: 3.0823790435110903

Epoch: 5| Step: 6
Training loss: 3.0762357384243777
Validation loss: 3.075562905753034

Epoch: 5| Step: 7
Training loss: 3.355624780368922
Validation loss: 3.0766325266596675

Epoch: 5| Step: 8
Training loss: 2.954810736157433
Validation loss: 3.0810736743539655

Epoch: 5| Step: 9
Training loss: 3.259427701646524
Validation loss: 3.0825685698965763

Epoch: 5| Step: 10
Training loss: 3.7687783868078033
Validation loss: 3.0773563594445386

Epoch: 92| Step: 0
Training loss: 4.1631971537235035
Validation loss: 3.075782727148412

Epoch: 5| Step: 1
Training loss: 2.164067567895126
Validation loss: 3.0759150611779003

Epoch: 5| Step: 2
Training loss: 3.467904202555986
Validation loss: 3.0751118937164144

Epoch: 5| Step: 3
Training loss: 3.526105390881007
Validation loss: 3.074963195204355

Epoch: 5| Step: 4
Training loss: 3.2818665424761733
Validation loss: 3.0745702205582495

Epoch: 5| Step: 5
Training loss: 3.019379329437456
Validation loss: 3.076671659722217

Epoch: 5| Step: 6
Training loss: 3.127169199524326
Validation loss: 3.0732733039669213

Epoch: 5| Step: 7
Training loss: 3.2898246987433715
Validation loss: 3.075196814739314

Epoch: 5| Step: 8
Training loss: 3.583232715583899
Validation loss: 3.080027995036267

Epoch: 5| Step: 9
Training loss: 3.116236797477705
Validation loss: 3.0701818767433533

Epoch: 5| Step: 10
Training loss: 3.687694609081152
Validation loss: 3.0691105899172455

Epoch: 93| Step: 0
Training loss: 2.4789745245667465
Validation loss: 3.0711039362493753

Epoch: 5| Step: 1
Training loss: 3.9208986807285107
Validation loss: 3.068478171996625

Epoch: 5| Step: 2
Training loss: 2.848202416223991
Validation loss: 3.068363252592947

Epoch: 5| Step: 3
Training loss: 3.0443329991024024
Validation loss: 3.0694783831777035

Epoch: 5| Step: 4
Training loss: 3.631799700259525
Validation loss: 3.070240036492005

Epoch: 5| Step: 5
Training loss: 3.7104364639145326
Validation loss: 3.072226268088907

Epoch: 5| Step: 6
Training loss: 3.2994003386842383
Validation loss: 3.069437891385312

Epoch: 5| Step: 7
Training loss: 3.351321907566805
Validation loss: 3.0680118472416353

Epoch: 5| Step: 8
Training loss: 3.333196796164008
Validation loss: 3.0706931307777667

Epoch: 5| Step: 9
Training loss: 3.4472912147155736
Validation loss: 3.0771139743746305

Epoch: 5| Step: 10
Training loss: 3.3996471839055036
Validation loss: 3.0736719442527094

Epoch: 94| Step: 0
Training loss: 3.3192763203954105
Validation loss: 3.0702912864984455

Epoch: 5| Step: 1
Training loss: 3.7036557360474567
Validation loss: 3.066078101489141

Epoch: 5| Step: 2
Training loss: 3.1917866324910618
Validation loss: 3.0692576324919103

Epoch: 5| Step: 3
Training loss: 3.936488188063155
Validation loss: 3.068647219275407

Epoch: 5| Step: 4
Training loss: 2.5962887025243298
Validation loss: 3.0662627084730047

Epoch: 5| Step: 5
Training loss: 3.0584914773769603
Validation loss: 3.0686331455855713

Epoch: 5| Step: 6
Training loss: 3.315227033800933
Validation loss: 3.0663992255774235

Epoch: 5| Step: 7
Training loss: 3.533739275975075
Validation loss: 3.0649048213857895

Epoch: 5| Step: 8
Training loss: 2.8947131142259805
Validation loss: 3.0670354348779223

Epoch: 5| Step: 9
Training loss: 3.3304628569452173
Validation loss: 3.0684969216973372

Epoch: 5| Step: 10
Training loss: 3.6012007724054804
Validation loss: 3.070788909323188

Epoch: 95| Step: 0
Training loss: 2.813581046984942
Validation loss: 3.0723620888138647

Epoch: 5| Step: 1
Training loss: 2.8579683439665224
Validation loss: 3.073757674878342

Epoch: 5| Step: 2
Training loss: 3.383148810956325
Validation loss: 3.075285085433135

Epoch: 5| Step: 3
Training loss: 3.026241923986765
Validation loss: 3.0712845684094083

Epoch: 5| Step: 4
Training loss: 3.4078564136864262
Validation loss: 3.070184639798894

Epoch: 5| Step: 5
Training loss: 2.9353808611781367
Validation loss: 3.0748154308099784

Epoch: 5| Step: 6
Training loss: 3.7734378791003302
Validation loss: 3.065188938682194

Epoch: 5| Step: 7
Training loss: 3.594898736877822
Validation loss: 3.067906231859218

Epoch: 5| Step: 8
Training loss: 3.2218115607009072
Validation loss: 3.0668158533578453

Epoch: 5| Step: 9
Training loss: 3.3818847229732683
Validation loss: 3.0654833612202697

Epoch: 5| Step: 10
Training loss: 4.133246992091307
Validation loss: 3.0666681988093902

Epoch: 96| Step: 0
Training loss: 3.297972003972935
Validation loss: 3.0640913173417736

Epoch: 5| Step: 1
Training loss: 3.7360352213422536
Validation loss: 3.0656777972334655

Epoch: 5| Step: 2
Training loss: 3.6356175903643524
Validation loss: 3.0671226499080837

Epoch: 5| Step: 3
Training loss: 3.2669599077084217
Validation loss: 3.0623648008631514

Epoch: 5| Step: 4
Training loss: 3.3285135391599496
Validation loss: 3.0641678953362557

Epoch: 5| Step: 5
Training loss: 2.8711543693111574
Validation loss: 3.0620492097374927

Epoch: 5| Step: 6
Training loss: 2.7124771890691917
Validation loss: 3.0644040152254424

Epoch: 5| Step: 7
Training loss: 3.553686248282607
Validation loss: 3.0646852185415745

Epoch: 5| Step: 8
Training loss: 3.6687161757617472
Validation loss: 3.0656938655318893

Epoch: 5| Step: 9
Training loss: 3.028773761298679
Validation loss: 3.0646627280441425

Epoch: 5| Step: 10
Training loss: 3.387586365897344
Validation loss: 3.062977830360063

Epoch: 97| Step: 0
Training loss: 3.581716808632588
Validation loss: 3.06292162184673

Epoch: 5| Step: 1
Training loss: 2.3357882755037873
Validation loss: 3.065939793229629

Epoch: 5| Step: 2
Training loss: 3.4286355597311062
Validation loss: 3.0634049749972285

Epoch: 5| Step: 3
Training loss: 3.7001398987998977
Validation loss: 3.0625304872905166

Epoch: 5| Step: 4
Training loss: 3.3637140684501636
Validation loss: 3.0629814243352858

Epoch: 5| Step: 5
Training loss: 4.226378826444589
Validation loss: 3.064475997673908

Epoch: 5| Step: 6
Training loss: 2.8936609769437927
Validation loss: 3.0624268995831216

Epoch: 5| Step: 7
Training loss: 3.2692876836733356
Validation loss: 3.0636583573130043

Epoch: 5| Step: 8
Training loss: 2.647228223703348
Validation loss: 3.0636246654262336

Epoch: 5| Step: 9
Training loss: 3.023416839450161
Validation loss: 3.067426613462376

Epoch: 5| Step: 10
Training loss: 3.729616077699705
Validation loss: 3.0693369381206694

Epoch: 98| Step: 0
Training loss: 2.6804253365923825
Validation loss: 3.066447489941675

Epoch: 5| Step: 1
Training loss: 3.5760106665518325
Validation loss: 3.0735112108176246

Epoch: 5| Step: 2
Training loss: 2.5942001871291427
Validation loss: 3.081360796006137

Epoch: 5| Step: 3
Training loss: 3.470147478558976
Validation loss: 3.0744281942467406

Epoch: 5| Step: 4
Training loss: 2.9739201549388747
Validation loss: 3.07734537295188

Epoch: 5| Step: 5
Training loss: 3.791864299164891
Validation loss: 3.0802462826463968

Epoch: 5| Step: 6
Training loss: 3.4166820959967845
Validation loss: 3.072489830866751

Epoch: 5| Step: 7
Training loss: 3.91313918867404
Validation loss: 3.070612586125515

Epoch: 5| Step: 8
Training loss: 3.69607671533375
Validation loss: 3.0584418619869997

Epoch: 5| Step: 9
Training loss: 2.8025589625530496
Validation loss: 3.05807562602306

Epoch: 5| Step: 10
Training loss: 3.3366541215608057
Validation loss: 3.0567252934634577

Epoch: 99| Step: 0
Training loss: 3.5231346118600313
Validation loss: 3.0582502594965484

Epoch: 5| Step: 1
Training loss: 3.1487508385972514
Validation loss: 3.0590490134558928

Epoch: 5| Step: 2
Training loss: 3.904490448435784
Validation loss: 3.0594209013484748

Epoch: 5| Step: 3
Training loss: 3.2750059753829373
Validation loss: 3.0609685430908384

Epoch: 5| Step: 4
Training loss: 3.6486967921779963
Validation loss: 3.059732097503002

Epoch: 5| Step: 5
Training loss: 3.4359610146918755
Validation loss: 3.0591503221489065

Epoch: 5| Step: 6
Training loss: 3.1031783576672853
Validation loss: 3.059056644743396

Epoch: 5| Step: 7
Training loss: 2.6221818783003905
Validation loss: 3.0611786041458022

Epoch: 5| Step: 8
Training loss: 3.6742325377159974
Validation loss: 3.0558528439186343

Epoch: 5| Step: 9
Training loss: 3.2388049761671387
Validation loss: 3.056956651214022

Epoch: 5| Step: 10
Training loss: 2.6960398701512767
Validation loss: 3.0572730715768706

Epoch: 100| Step: 0
Training loss: 3.638302303594872
Validation loss: 3.059255522489973

Epoch: 5| Step: 1
Training loss: 2.8513800575733588
Validation loss: 3.055494412705067

Epoch: 5| Step: 2
Training loss: 2.9671948023541
Validation loss: 3.0564821311948105

Epoch: 5| Step: 3
Training loss: 3.400094165619977
Validation loss: 3.054906374773207

Epoch: 5| Step: 4
Training loss: 3.481065897978919
Validation loss: 3.055036822077435

Epoch: 5| Step: 5
Training loss: 3.413035781775612
Validation loss: 3.054825495284947

Epoch: 5| Step: 6
Training loss: 3.05171515595188
Validation loss: 3.058891690381547

Epoch: 5| Step: 7
Training loss: 3.2728917798205597
Validation loss: 3.054771023345315

Epoch: 5| Step: 8
Training loss: 3.7030360215196887
Validation loss: 3.0547939701920943

Epoch: 5| Step: 9
Training loss: 3.6157723412458176
Validation loss: 3.0572719278103837

Epoch: 5| Step: 10
Training loss: 2.9373535769067027
Validation loss: 3.0592262746509085

Epoch: 101| Step: 0
Training loss: 2.8148708099750093
Validation loss: 3.059150347289619

Epoch: 5| Step: 1
Training loss: 3.6587273445640016
Validation loss: 3.0586767040165808

Epoch: 5| Step: 2
Training loss: 3.4119475424022117
Validation loss: 3.054933855537589

Epoch: 5| Step: 3
Training loss: 3.1795684267285433
Validation loss: 3.05243774179646

Epoch: 5| Step: 4
Training loss: 2.730559297078095
Validation loss: 3.0560777925150826

Epoch: 5| Step: 5
Training loss: 3.1635105734862923
Validation loss: 3.0552009222593446

Epoch: 5| Step: 6
Training loss: 3.4848542161876805
Validation loss: 3.06021712641737

Epoch: 5| Step: 7
Training loss: 3.483681785153805
Validation loss: 3.0584169819028637

Epoch: 5| Step: 8
Training loss: 3.639012450303565
Validation loss: 3.057840799871033

Epoch: 5| Step: 9
Training loss: 3.220124182823951
Validation loss: 3.0564770047180208

Epoch: 5| Step: 10
Training loss: 3.6501677696654027
Validation loss: 3.058664177786626

Epoch: 102| Step: 0
Training loss: 3.63639421992012
Validation loss: 3.0538330662352635

Epoch: 5| Step: 1
Training loss: 3.3812477774621565
Validation loss: 3.053640007608478

Epoch: 5| Step: 2
Training loss: 3.343488023424155
Validation loss: 3.054128272917895

Epoch: 5| Step: 3
Training loss: 3.0203422059454827
Validation loss: 3.052134699509799

Epoch: 5| Step: 4
Training loss: 3.06570049352366
Validation loss: 3.054604077601206

Epoch: 5| Step: 5
Training loss: 3.374448095336498
Validation loss: 3.0525177909560584

Epoch: 5| Step: 6
Training loss: 3.410750469509429
Validation loss: 3.050611555563144

Epoch: 5| Step: 7
Training loss: 3.308104567861962
Validation loss: 3.0528385519148293

Epoch: 5| Step: 8
Training loss: 3.5741704551894307
Validation loss: 3.0529909168683043

Epoch: 5| Step: 9
Training loss: 2.987264303063494
Validation loss: 3.050881245077928

Epoch: 5| Step: 10
Training loss: 3.346421075095126
Validation loss: 3.056174024062882

Epoch: 103| Step: 0
Training loss: 3.990110211487509
Validation loss: 3.0501141541419527

Epoch: 5| Step: 1
Training loss: 3.6246863920109953
Validation loss: 3.054161073204783

Epoch: 5| Step: 2
Training loss: 2.4542451475728266
Validation loss: 3.0554406843348167

Epoch: 5| Step: 3
Training loss: 3.6924149684116214
Validation loss: 3.055455651115186

Epoch: 5| Step: 4
Training loss: 3.0051184541075537
Validation loss: 3.051250659304529

Epoch: 5| Step: 5
Training loss: 3.0514923322025913
Validation loss: 3.051864104331739

Epoch: 5| Step: 6
Training loss: 2.7477562160274127
Validation loss: 3.053185037566371

Epoch: 5| Step: 7
Training loss: 3.036973249813137
Validation loss: 3.0530615755037567

Epoch: 5| Step: 8
Training loss: 4.045835619270053
Validation loss: 3.045760445982199

Epoch: 5| Step: 9
Training loss: 3.074442097985777
Validation loss: 3.0439177300034075

Epoch: 5| Step: 10
Training loss: 3.3741408773428905
Validation loss: 3.04674681758575

Epoch: 104| Step: 0
Training loss: 4.0528861511489325
Validation loss: 3.0462230135195663

Epoch: 5| Step: 1
Training loss: 3.1487446296770276
Validation loss: 3.0463745210984827

Epoch: 5| Step: 2
Training loss: 2.9074048444768574
Validation loss: 3.0467304171241736

Epoch: 5| Step: 3
Training loss: 3.202122824596407
Validation loss: 3.047897183389766

Epoch: 5| Step: 4
Training loss: 2.8221630671785394
Validation loss: 3.046642609919065

Epoch: 5| Step: 5
Training loss: 3.538306149129589
Validation loss: 3.047798449698588

Epoch: 5| Step: 6
Training loss: 3.5028527758928263
Validation loss: 3.0469021585882707

Epoch: 5| Step: 7
Training loss: 3.5177264227311174
Validation loss: 3.0460892405855287

Epoch: 5| Step: 8
Training loss: 3.137703670866941
Validation loss: 3.046232027670565

Epoch: 5| Step: 9
Training loss: 3.3881644185061406
Validation loss: 3.045427761282068

Epoch: 5| Step: 10
Training loss: 3.0625104320114893
Validation loss: 3.0458368805177183

Epoch: 105| Step: 0
Training loss: 3.6797530700932026
Validation loss: 3.0431756678737196

Epoch: 5| Step: 1
Training loss: 3.6906158731397785
Validation loss: 3.0433131296404414

Epoch: 5| Step: 2
Training loss: 3.163403854575567
Validation loss: 3.0422034105394604

Epoch: 5| Step: 3
Training loss: 2.727687570781369
Validation loss: 3.0428503623925316

Epoch: 5| Step: 4
Training loss: 3.9837296505549844
Validation loss: 3.0404988934060055

Epoch: 5| Step: 5
Training loss: 3.579397716473445
Validation loss: 3.041015480000351

Epoch: 5| Step: 6
Training loss: 3.511878972116625
Validation loss: 3.0398776791120414

Epoch: 5| Step: 7
Training loss: 2.511936872393714
Validation loss: 3.0370144234678635

Epoch: 5| Step: 8
Training loss: 2.3206013201125173
Validation loss: 3.040753214057078

Epoch: 5| Step: 9
Training loss: 3.4404446560666426
Validation loss: 3.0375788943217916

Epoch: 5| Step: 10
Training loss: 3.390848038189093
Validation loss: 3.038118210609117

Epoch: 106| Step: 0
Training loss: 2.9957018898118135
Validation loss: 3.0376565137104774

Epoch: 5| Step: 1
Training loss: 3.5772997308385848
Validation loss: 3.0359183821503897

Epoch: 5| Step: 2
Training loss: 3.275516987537163
Validation loss: 3.0327079860138655

Epoch: 5| Step: 3
Training loss: 2.451011378896471
Validation loss: 3.029758967494586

Epoch: 5| Step: 4
Training loss: 3.589549653435308
Validation loss: 3.030199402289236

Epoch: 5| Step: 5
Training loss: 3.972721185594232
Validation loss: 3.027734314239434

Epoch: 5| Step: 6
Training loss: 2.548266539695234
Validation loss: 3.0249654212818764

Epoch: 5| Step: 7
Training loss: 3.292592670871521
Validation loss: 3.028314051370468

Epoch: 5| Step: 8
Training loss: 3.6953201132568907
Validation loss: 3.024061261554967

Epoch: 5| Step: 9
Training loss: 3.3259264350871214
Validation loss: 3.0224347179376316

Epoch: 5| Step: 10
Training loss: 3.247457096324486
Validation loss: 3.0265721495099696

Epoch: 107| Step: 0
Training loss: 3.13724970332117
Validation loss: 3.024070718164507

Epoch: 5| Step: 1
Training loss: 2.988191092134637
Validation loss: 3.0228493339304987

Epoch: 5| Step: 2
Training loss: 3.5341129006797414
Validation loss: 3.025465448142054

Epoch: 5| Step: 3
Training loss: 3.9961571115073884
Validation loss: 3.0226635292177675

Epoch: 5| Step: 4
Training loss: 3.839996986785342
Validation loss: 3.0219620075249995

Epoch: 5| Step: 5
Training loss: 3.2440999101429884
Validation loss: 3.0212316898918288

Epoch: 5| Step: 6
Training loss: 2.359829486247385
Validation loss: 3.021270320347681

Epoch: 5| Step: 7
Training loss: 3.444588029254613
Validation loss: 3.019647222126058

Epoch: 5| Step: 8
Training loss: 3.241485887469972
Validation loss: 3.022347330477056

Epoch: 5| Step: 9
Training loss: 2.9217055980513456
Validation loss: 3.0186331111461806

Epoch: 5| Step: 10
Training loss: 3.196958383794641
Validation loss: 3.0199653623216682

Epoch: 108| Step: 0
Training loss: 3.1248490869322114
Validation loss: 3.018687278078803

Epoch: 5| Step: 1
Training loss: 3.162195026634918
Validation loss: 3.023741965154741

Epoch: 5| Step: 2
Training loss: 3.6718607151484104
Validation loss: 3.022846657365267

Epoch: 5| Step: 3
Training loss: 3.391924912152416
Validation loss: 3.0186829290317037

Epoch: 5| Step: 4
Training loss: 2.9616963966550442
Validation loss: 3.0201538524012825

Epoch: 5| Step: 5
Training loss: 3.347989825763078
Validation loss: 3.0188417980935394

Epoch: 5| Step: 6
Training loss: 3.1876241622378596
Validation loss: 3.0201982695547285

Epoch: 5| Step: 7
Training loss: 3.407022791001093
Validation loss: 3.016282413911058

Epoch: 5| Step: 8
Training loss: 3.876988423760906
Validation loss: 3.0187420274683614

Epoch: 5| Step: 9
Training loss: 3.1013288049552745
Validation loss: 3.018728770781362

Epoch: 5| Step: 10
Training loss: 2.7797949767496255
Validation loss: 3.015853911403146

Epoch: 109| Step: 0
Training loss: 3.335960370237763
Validation loss: 3.019959054158768

Epoch: 5| Step: 1
Training loss: 3.0858671928798693
Validation loss: 3.0186595641551066

Epoch: 5| Step: 2
Training loss: 3.1383209127246876
Validation loss: 3.0158871908590044

Epoch: 5| Step: 3
Training loss: 3.0313019108997397
Validation loss: 3.013776544738725

Epoch: 5| Step: 4
Training loss: 3.2662414261026185
Validation loss: 3.01732724366076

Epoch: 5| Step: 5
Training loss: 3.353959655691952
Validation loss: 3.0176556395236624

Epoch: 5| Step: 6
Training loss: 3.3791261105312453
Validation loss: 3.0149211398984472

Epoch: 5| Step: 7
Training loss: 3.4412351256138107
Validation loss: 3.015305974204524

Epoch: 5| Step: 8
Training loss: 2.9575539936931583
Validation loss: 3.017340455527219

Epoch: 5| Step: 9
Training loss: 3.511737624002047
Validation loss: 3.0155681196898403

Epoch: 5| Step: 10
Training loss: 3.697181406487654
Validation loss: 3.0162823680146276

Epoch: 110| Step: 0
Training loss: 3.344939403583787
Validation loss: 3.0150999495936435

Epoch: 5| Step: 1
Training loss: 3.0077484520372413
Validation loss: 3.013802965519406

Epoch: 5| Step: 2
Training loss: 3.3476616626815927
Validation loss: 3.016967078641537

Epoch: 5| Step: 3
Training loss: 3.3705127697238564
Validation loss: 3.0242526150202598

Epoch: 5| Step: 4
Training loss: 2.7063002266749034
Validation loss: 3.0282330787983955

Epoch: 5| Step: 5
Training loss: 2.912058450520952
Validation loss: 3.023699877380075

Epoch: 5| Step: 6
Training loss: 3.859535739037876
Validation loss: 3.0204366240304084

Epoch: 5| Step: 7
Training loss: 3.67886259061579
Validation loss: 3.0160316134922196

Epoch: 5| Step: 8
Training loss: 3.0164404838731733
Validation loss: 3.017067818004417

Epoch: 5| Step: 9
Training loss: 3.098916565856705
Validation loss: 3.0132929729143973

Epoch: 5| Step: 10
Training loss: 3.712389081845722
Validation loss: 3.013425997484395

Epoch: 111| Step: 0
Training loss: 3.072381407246939
Validation loss: 3.012913441173538

Epoch: 5| Step: 1
Training loss: 2.8815789620368073
Validation loss: 3.0164375092589895

Epoch: 5| Step: 2
Training loss: 3.455513796770375
Validation loss: 3.0190402476260534

Epoch: 5| Step: 3
Training loss: 3.709599496657037
Validation loss: 3.0137984350439755

Epoch: 5| Step: 4
Training loss: 2.7340289959657067
Validation loss: 3.0160911268245783

Epoch: 5| Step: 5
Training loss: 3.094337792863406
Validation loss: 3.0173487352172583

Epoch: 5| Step: 6
Training loss: 3.948250037673064
Validation loss: 3.0147938565650256

Epoch: 5| Step: 7
Training loss: 3.783704733298974
Validation loss: 3.0132193202413355

Epoch: 5| Step: 8
Training loss: 3.3093132668879925
Validation loss: 3.0101394437678333

Epoch: 5| Step: 9
Training loss: 2.8349072815603593
Validation loss: 3.0139228458387204

Epoch: 5| Step: 10
Training loss: 3.0457562862589063
Validation loss: 3.0097701870990297

Epoch: 112| Step: 0
Training loss: 3.8947228601701225
Validation loss: 3.009133417804118

Epoch: 5| Step: 1
Training loss: 3.091409279390653
Validation loss: 3.0074424853795017

Epoch: 5| Step: 2
Training loss: 3.508776288071653
Validation loss: 3.0092266319601912

Epoch: 5| Step: 3
Training loss: 2.817452795789176
Validation loss: 3.009535965995263

Epoch: 5| Step: 4
Training loss: 3.76065761537437
Validation loss: 3.0096583574629565

Epoch: 5| Step: 5
Training loss: 2.8957157980213037
Validation loss: 3.0085983453697946

Epoch: 5| Step: 6
Training loss: 3.9567059969748297
Validation loss: 3.009528763686417

Epoch: 5| Step: 7
Training loss: 2.2631968147031576
Validation loss: 3.008770295174152

Epoch: 5| Step: 8
Training loss: 3.0376772040023168
Validation loss: 3.008622844982895

Epoch: 5| Step: 9
Training loss: 3.1077158733093264
Validation loss: 3.009617477382111

Epoch: 5| Step: 10
Training loss: 3.392699279554446
Validation loss: 3.0160517704330845

Epoch: 113| Step: 0
Training loss: 3.438676528728178
Validation loss: 3.01797429291858

Epoch: 5| Step: 1
Training loss: 2.713174122662468
Validation loss: 3.01326826369398

Epoch: 5| Step: 2
Training loss: 3.212922533798616
Validation loss: 3.015179286133365

Epoch: 5| Step: 3
Training loss: 3.104718579548059
Validation loss: 3.0106052635249125

Epoch: 5| Step: 4
Training loss: 3.4030966905549587
Validation loss: 3.017468239753142

Epoch: 5| Step: 5
Training loss: 3.114431286080618
Validation loss: 3.0043453156664066

Epoch: 5| Step: 6
Training loss: 3.482516900957424
Validation loss: 3.0081044795158287

Epoch: 5| Step: 7
Training loss: 3.2762411488424736
Validation loss: 3.0032793429372773

Epoch: 5| Step: 8
Training loss: 3.471847663174331
Validation loss: 3.002575105825082

Epoch: 5| Step: 9
Training loss: 3.7018327349482147
Validation loss: 3.004560867922671

Epoch: 5| Step: 10
Training loss: 2.9872585566170917
Validation loss: 3.000780731220008

Epoch: 114| Step: 0
Training loss: 3.421206195566202
Validation loss: 3.002823748363518

Epoch: 5| Step: 1
Training loss: 2.358164495708126
Validation loss: 3.0023983457573284

Epoch: 5| Step: 2
Training loss: 3.5411870444667173
Validation loss: 3.001266931501421

Epoch: 5| Step: 3
Training loss: 3.384783939019265
Validation loss: 3.001706458383685

Epoch: 5| Step: 4
Training loss: 3.5054065635067317
Validation loss: 3.0037851160243045

Epoch: 5| Step: 5
Training loss: 3.0866417189950033
Validation loss: 3.0051753837681607

Epoch: 5| Step: 6
Training loss: 3.7261609514889944
Validation loss: 3.0020034946683842

Epoch: 5| Step: 7
Training loss: 3.8830207753496344
Validation loss: 3.002427377001741

Epoch: 5| Step: 8
Training loss: 3.079433724501736
Validation loss: 2.9987529688868246

Epoch: 5| Step: 9
Training loss: 2.792912580018656
Validation loss: 3.000311479840015

Epoch: 5| Step: 10
Training loss: 2.916597710657153
Validation loss: 3.001804477372535

Epoch: 115| Step: 0
Training loss: 3.251211380778691
Validation loss: 3.00190437197191

Epoch: 5| Step: 1
Training loss: 3.4889671275065472
Validation loss: 3.0041803814997627

Epoch: 5| Step: 2
Training loss: 3.1293978453743763
Validation loss: 3.003564748801534

Epoch: 5| Step: 3
Training loss: 3.2601617260468028
Validation loss: 3.0046402865011412

Epoch: 5| Step: 4
Training loss: 2.8572882036296363
Validation loss: 3.010349403365388

Epoch: 5| Step: 5
Training loss: 3.283868235538525
Validation loss: 3.007205540827197

Epoch: 5| Step: 6
Training loss: 3.3009261421138945
Validation loss: 3.0070290034991882

Epoch: 5| Step: 7
Training loss: 3.259788151978034
Validation loss: 3.002858265006478

Epoch: 5| Step: 8
Training loss: 2.89052618734193
Validation loss: 3.0031502925404476

Epoch: 5| Step: 9
Training loss: 3.3382611724728264
Validation loss: 3.0071079621735426

Epoch: 5| Step: 10
Training loss: 3.9307295704944982
Validation loss: 3.0009864788358027

Epoch: 116| Step: 0
Training loss: 3.8335751719828273
Validation loss: 3.0000897388982675

Epoch: 5| Step: 1
Training loss: 3.2699352092332057
Validation loss: 2.9993890777777805

Epoch: 5| Step: 2
Training loss: 3.175933045985927
Validation loss: 3.00417189228479

Epoch: 5| Step: 3
Training loss: 2.7788674082386158
Validation loss: 2.9979413277063958

Epoch: 5| Step: 4
Training loss: 2.9449747635645753
Validation loss: 2.999690609021593

Epoch: 5| Step: 5
Training loss: 3.554404714885077
Validation loss: 2.999458691425892

Epoch: 5| Step: 6
Training loss: 3.5988707837700877
Validation loss: 3.0005957992846426

Epoch: 5| Step: 7
Training loss: 3.306503626536618
Validation loss: 2.9985051190648244

Epoch: 5| Step: 8
Training loss: 3.2852249047615785
Validation loss: 2.9988836327183708

Epoch: 5| Step: 9
Training loss: 3.1044794390171555
Validation loss: 2.999038213971

Epoch: 5| Step: 10
Training loss: 2.9433566209239768
Validation loss: 2.998491037627997

Epoch: 117| Step: 0
Training loss: 3.931340076766997
Validation loss: 2.9985648383276184

Epoch: 5| Step: 1
Training loss: 2.803361754694807
Validation loss: 2.9968964031181935

Epoch: 5| Step: 2
Training loss: 2.7110555221855117
Validation loss: 2.996274066577374

Epoch: 5| Step: 3
Training loss: 3.4552648481995725
Validation loss: 2.9989320091381293

Epoch: 5| Step: 4
Training loss: 3.0299727118242195
Validation loss: 2.9951636732412035

Epoch: 5| Step: 5
Training loss: 3.497767417560612
Validation loss: 2.99496902233136

Epoch: 5| Step: 6
Training loss: 3.7505002006080126
Validation loss: 2.9971386157021334

Epoch: 5| Step: 7
Training loss: 2.8751993524846795
Validation loss: 2.9951254421740816

Epoch: 5| Step: 8
Training loss: 2.7641616656864145
Validation loss: 2.9942615207077115

Epoch: 5| Step: 9
Training loss: 3.518051734062482
Validation loss: 2.9961922075845457

Epoch: 5| Step: 10
Training loss: 3.388703957881266
Validation loss: 2.993642097827177

Epoch: 118| Step: 0
Training loss: 3.047323966571124
Validation loss: 2.9973754939141704

Epoch: 5| Step: 1
Training loss: 2.7375839150861974
Validation loss: 2.994920091412318

Epoch: 5| Step: 2
Training loss: 3.3530147936113788
Validation loss: 2.9964681450456077

Epoch: 5| Step: 3
Training loss: 3.7905566229003327
Validation loss: 2.9929041364555005

Epoch: 5| Step: 4
Training loss: 3.017706118341348
Validation loss: 2.993162131951679

Epoch: 5| Step: 5
Training loss: 2.976327000710966
Validation loss: 2.9942248988993883

Epoch: 5| Step: 6
Training loss: 3.3547012819203395
Validation loss: 2.9951140479103975

Epoch: 5| Step: 7
Training loss: 3.6020249340882495
Validation loss: 2.993084708571795

Epoch: 5| Step: 8
Training loss: 3.1500259822197765
Validation loss: 2.9927227139517845

Epoch: 5| Step: 9
Training loss: 3.020251584215793
Validation loss: 2.9917151509537785

Epoch: 5| Step: 10
Training loss: 3.772873356509308
Validation loss: 2.9925452434335194

Epoch: 119| Step: 0
Training loss: 3.1774917256677493
Validation loss: 2.9911306438203322

Epoch: 5| Step: 1
Training loss: 3.625029728208516
Validation loss: 2.9936175835148746

Epoch: 5| Step: 2
Training loss: 3.342289971291729
Validation loss: 2.991987824635182

Epoch: 5| Step: 3
Training loss: 3.1141653301374634
Validation loss: 2.994213160441792

Epoch: 5| Step: 4
Training loss: 3.495476797213215
Validation loss: 2.9951092092725404

Epoch: 5| Step: 5
Training loss: 3.5329217245164175
Validation loss: 2.996683233895763

Epoch: 5| Step: 6
Training loss: 2.841794190290828
Validation loss: 2.9956508305395535

Epoch: 5| Step: 7
Training loss: 3.0403188741489515
Validation loss: 2.991645495941703

Epoch: 5| Step: 8
Training loss: 3.2714546407230825
Validation loss: 2.9909139196611023

Epoch: 5| Step: 9
Training loss: 3.0737639385216067
Validation loss: 2.988782690513642

Epoch: 5| Step: 10
Training loss: 3.3330319904173598
Validation loss: 2.9911379401402565

Epoch: 120| Step: 0
Training loss: 3.327022029444894
Validation loss: 2.988764030872493

Epoch: 5| Step: 1
Training loss: 3.4585204629175514
Validation loss: 2.9906456441868916

Epoch: 5| Step: 2
Training loss: 3.420696595619054
Validation loss: 2.9884279023560665

Epoch: 5| Step: 3
Training loss: 3.2826211153625278
Validation loss: 2.9922897392941215

Epoch: 5| Step: 4
Training loss: 3.1910839501709405
Validation loss: 2.986181878614411

Epoch: 5| Step: 5
Training loss: 3.422365475693493
Validation loss: 2.986198867445731

Epoch: 5| Step: 6
Training loss: 3.2179899336786053
Validation loss: 2.9881950248553286

Epoch: 5| Step: 7
Training loss: 3.223214321944097
Validation loss: 2.9862879883322493

Epoch: 5| Step: 8
Training loss: 2.9598691114921833
Validation loss: 2.9860466212674397

Epoch: 5| Step: 9
Training loss: 3.4381699342743723
Validation loss: 2.986405675473691

Epoch: 5| Step: 10
Training loss: 2.872408984728553
Validation loss: 2.9865938818192443

Epoch: 121| Step: 0
Training loss: 3.4994885207150217
Validation loss: 2.9927605945193845

Epoch: 5| Step: 1
Training loss: 2.2850716338834456
Validation loss: 2.987376686091586

Epoch: 5| Step: 2
Training loss: 3.2145390789144503
Validation loss: 2.9912208802108973

Epoch: 5| Step: 3
Training loss: 4.224222660221628
Validation loss: 2.9915996085256427

Epoch: 5| Step: 4
Training loss: 3.045519718109465
Validation loss: 2.9891894072659277

Epoch: 5| Step: 5
Training loss: 3.3966345904641693
Validation loss: 2.994264188577771

Epoch: 5| Step: 6
Training loss: 3.076161799338658
Validation loss: 2.987927371840841

Epoch: 5| Step: 7
Training loss: 2.4592347082042862
Validation loss: 2.98735641633534

Epoch: 5| Step: 8
Training loss: 3.587362700170994
Validation loss: 2.9889290703876514

Epoch: 5| Step: 9
Training loss: 3.776347868332081
Validation loss: 2.989735544611855

Epoch: 5| Step: 10
Training loss: 2.7109973032398664
Validation loss: 2.984952716416826

Epoch: 122| Step: 0
Training loss: 3.5482908943425175
Validation loss: 2.9887504885353824

Epoch: 5| Step: 1
Training loss: 3.0671426265502495
Validation loss: 2.986771724843846

Epoch: 5| Step: 2
Training loss: 3.06780344238685
Validation loss: 2.985217109994132

Epoch: 5| Step: 3
Training loss: 3.3868829143999784
Validation loss: 2.9827362115595215

Epoch: 5| Step: 4
Training loss: 2.8548232574002985
Validation loss: 2.9827797084597125

Epoch: 5| Step: 5
Training loss: 2.8419344629493515
Validation loss: 2.983778355465764

Epoch: 5| Step: 6
Training loss: 3.5603213424525935
Validation loss: 2.986341633682271

Epoch: 5| Step: 7
Training loss: 2.767113409014377
Validation loss: 2.9818375416600067

Epoch: 5| Step: 8
Training loss: 3.327277420360896
Validation loss: 2.981654579112738

Epoch: 5| Step: 9
Training loss: 4.106718531896206
Validation loss: 2.982227936341621

Epoch: 5| Step: 10
Training loss: 3.0492008037659657
Validation loss: 2.984156073918087

Epoch: 123| Step: 0
Training loss: 3.7272022266021843
Validation loss: 2.9834467805869216

Epoch: 5| Step: 1
Training loss: 3.6264847970220733
Validation loss: 2.981578805280871

Epoch: 5| Step: 2
Training loss: 2.830715110390632
Validation loss: 2.9816920233725197

Epoch: 5| Step: 3
Training loss: 2.882861790843005
Validation loss: 2.9896247972086454

Epoch: 5| Step: 4
Training loss: 3.227227611201973
Validation loss: 2.9972919133096485

Epoch: 5| Step: 5
Training loss: 2.6036901622970956
Validation loss: 2.9942606225699198

Epoch: 5| Step: 6
Training loss: 2.7923934237258603
Validation loss: 3.0024532538502164

Epoch: 5| Step: 7
Training loss: 3.3583443413515375
Validation loss: 2.9909612284322593

Epoch: 5| Step: 8
Training loss: 3.4754464061711507
Validation loss: 2.990186144221871

Epoch: 5| Step: 9
Training loss: 3.316037430491019
Validation loss: 2.9819167805052196

Epoch: 5| Step: 10
Training loss: 3.8133391410498865
Validation loss: 2.982607341565155

Epoch: 124| Step: 0
Training loss: 3.5473162002747154
Validation loss: 2.9821445948564835

Epoch: 5| Step: 1
Training loss: 3.54994895253619
Validation loss: 2.9777691798478085

Epoch: 5| Step: 2
Training loss: 2.540583979239105
Validation loss: 2.979615813053944

Epoch: 5| Step: 3
Training loss: 3.1644436076903695
Validation loss: 2.9836384378062104

Epoch: 5| Step: 4
Training loss: 3.009831055877442
Validation loss: 2.9813848487558747

Epoch: 5| Step: 5
Training loss: 3.104390658974059
Validation loss: 2.985762388912622

Epoch: 5| Step: 6
Training loss: 3.778228940078277
Validation loss: 2.9858419108276117

Epoch: 5| Step: 7
Training loss: 2.7818248883278165
Validation loss: 2.986345865863625

Epoch: 5| Step: 8
Training loss: 3.842708415507709
Validation loss: 2.9848143723330907

Epoch: 5| Step: 9
Training loss: 3.1683034849357865
Validation loss: 2.9817240178517475

Epoch: 5| Step: 10
Training loss: 3.171358865170698
Validation loss: 2.9821639028344986

Epoch: 125| Step: 0
Training loss: 2.527130919844707
Validation loss: 2.982626852833457

Epoch: 5| Step: 1
Training loss: 3.516710986781652
Validation loss: 2.9857638666003505

Epoch: 5| Step: 2
Training loss: 2.922841447735589
Validation loss: 2.9826457915345457

Epoch: 5| Step: 3
Training loss: 3.636103232769987
Validation loss: 2.984637147934805

Epoch: 5| Step: 4
Training loss: 3.394337392875069
Validation loss: 2.9828668584970215

Epoch: 5| Step: 5
Training loss: 3.894291019969845
Validation loss: 2.985476120130514

Epoch: 5| Step: 6
Training loss: 2.5890502634720454
Validation loss: 2.984592011725586

Epoch: 5| Step: 7
Training loss: 3.2242236955150463
Validation loss: 2.9847990771007193

Epoch: 5| Step: 8
Training loss: 2.948160994865774
Validation loss: 2.9872101138748386

Epoch: 5| Step: 9
Training loss: 3.568278394760511
Validation loss: 2.978753960062761

Epoch: 5| Step: 10
Training loss: 3.385959069254168
Validation loss: 2.9756238837299405

Epoch: 126| Step: 0
Training loss: 3.3517976691696756
Validation loss: 2.9761491683988037

Epoch: 5| Step: 1
Training loss: 3.0038091001439193
Validation loss: 2.9790346039055366

Epoch: 5| Step: 2
Training loss: 3.042151599705514
Validation loss: 2.978371710673574

Epoch: 5| Step: 3
Training loss: 3.52328132232513
Validation loss: 2.978657227500071

Epoch: 5| Step: 4
Training loss: 3.40186973099
Validation loss: 2.982155620879186

Epoch: 5| Step: 5
Training loss: 3.5297883646258246
Validation loss: 2.9786987046153928

Epoch: 5| Step: 6
Training loss: 3.738005720645452
Validation loss: 2.9769353796931886

Epoch: 5| Step: 7
Training loss: 2.8989035342254197
Validation loss: 2.977487056339632

Epoch: 5| Step: 8
Training loss: 2.634020067154456
Validation loss: 2.977998437492626

Epoch: 5| Step: 9
Training loss: 3.728423032015555
Validation loss: 2.9839499089807933

Epoch: 5| Step: 10
Training loss: 2.664786232109772
Validation loss: 2.981222105533163

Epoch: 127| Step: 0
Training loss: 3.4639569408832807
Validation loss: 2.979558331362882

Epoch: 5| Step: 1
Training loss: 2.6726895702418183
Validation loss: 2.975108620065408

Epoch: 5| Step: 2
Training loss: 3.1450514842854562
Validation loss: 2.975716774306771

Epoch: 5| Step: 3
Training loss: 3.6648130644499837
Validation loss: 2.977996491947707

Epoch: 5| Step: 4
Training loss: 3.5170136146487976
Validation loss: 2.9770733252308834

Epoch: 5| Step: 5
Training loss: 3.919759597802578
Validation loss: 2.978766625242865

Epoch: 5| Step: 6
Training loss: 3.466627141531567
Validation loss: 2.9768029024548857

Epoch: 5| Step: 7
Training loss: 2.8698865779036877
Validation loss: 2.977784655823792

Epoch: 5| Step: 8
Training loss: 3.0750334264907826
Validation loss: 2.9767077462787976

Epoch: 5| Step: 9
Training loss: 2.697039595406993
Validation loss: 2.9768784499347714

Epoch: 5| Step: 10
Training loss: 3.0591262607162695
Validation loss: 2.9776626821864074

Epoch: 128| Step: 0
Training loss: 2.840401826826936
Validation loss: 2.9807872332991625

Epoch: 5| Step: 1
Training loss: 2.7989777912977405
Validation loss: 2.978420876445575

Epoch: 5| Step: 2
Training loss: 3.0966607474882
Validation loss: 2.9853677600088946

Epoch: 5| Step: 3
Training loss: 3.3691058082440146
Validation loss: 2.987341019123756

Epoch: 5| Step: 4
Training loss: 3.3628127849554987
Validation loss: 2.9858602968082453

Epoch: 5| Step: 5
Training loss: 2.8117900376161105
Validation loss: 2.983543011580575

Epoch: 5| Step: 6
Training loss: 3.356423292179367
Validation loss: 2.979309481045951

Epoch: 5| Step: 7
Training loss: 4.076156901326115
Validation loss: 2.976740902725303

Epoch: 5| Step: 8
Training loss: 3.3470424236233796
Validation loss: 2.977114671134489

Epoch: 5| Step: 9
Training loss: 3.3948798840135543
Validation loss: 2.9750226990683553

Epoch: 5| Step: 10
Training loss: 3.101892256803086
Validation loss: 2.9743023179155346

Epoch: 129| Step: 0
Training loss: 3.5709680669078363
Validation loss: 2.9715166327458635

Epoch: 5| Step: 1
Training loss: 2.644913300677931
Validation loss: 2.9727541609450125

Epoch: 5| Step: 2
Training loss: 3.1038146022014375
Validation loss: 2.969153384926175

Epoch: 5| Step: 3
Training loss: 3.3420929412519795
Validation loss: 2.9712215616629187

Epoch: 5| Step: 4
Training loss: 3.251282952246896
Validation loss: 2.96972675932285

Epoch: 5| Step: 5
Training loss: 3.0132140963377716
Validation loss: 2.970936455474541

Epoch: 5| Step: 6
Training loss: 3.6730796623450215
Validation loss: 2.973019237519384

Epoch: 5| Step: 7
Training loss: 2.5326538902289135
Validation loss: 2.968369016180732

Epoch: 5| Step: 8
Training loss: 3.843912384820988
Validation loss: 2.970207278958177

Epoch: 5| Step: 9
Training loss: 3.204912682354025
Validation loss: 2.971198375771688

Epoch: 5| Step: 10
Training loss: 3.3431348858778254
Validation loss: 2.9693347236336676

Epoch: 130| Step: 0
Training loss: 3.177426745923186
Validation loss: 2.9678902901609727

Epoch: 5| Step: 1
Training loss: 3.178380299144325
Validation loss: 2.9705671084969016

Epoch: 5| Step: 2
Training loss: 2.708776134581415
Validation loss: 2.9870735419111507

Epoch: 5| Step: 3
Training loss: 3.4734796120805935
Validation loss: 2.9872980683619486

Epoch: 5| Step: 4
Training loss: 2.9853323953629056
Validation loss: 3.016415063575669

Epoch: 5| Step: 5
Training loss: 3.553078356380505
Validation loss: 3.030965504363966

Epoch: 5| Step: 6
Training loss: 3.732994686389639
Validation loss: 2.989505957334284

Epoch: 5| Step: 7
Training loss: 3.266765194659104
Validation loss: 2.9703400115228695

Epoch: 5| Step: 8
Training loss: 2.979717995017982
Validation loss: 2.9679123772466536

Epoch: 5| Step: 9
Training loss: 3.3746737569731713
Validation loss: 2.9671363940083215

Epoch: 5| Step: 10
Training loss: 3.2898445558784783
Validation loss: 2.9681643259668733

Epoch: 131| Step: 0
Training loss: 3.2880476520825734
Validation loss: 2.9690410615975957

Epoch: 5| Step: 1
Training loss: 2.8056727302011084
Validation loss: 2.9700580644751198

Epoch: 5| Step: 2
Training loss: 3.2822143590780275
Validation loss: 2.968659241200596

Epoch: 5| Step: 3
Training loss: 3.172594561959917
Validation loss: 2.9697937551638764

Epoch: 5| Step: 4
Training loss: 3.324267376948615
Validation loss: 2.971361126172177

Epoch: 5| Step: 5
Training loss: 3.326426327750644
Validation loss: 2.967135720943111

Epoch: 5| Step: 6
Training loss: 3.7345683155540264
Validation loss: 2.9674203059103395

Epoch: 5| Step: 7
Training loss: 2.5437143759142673
Validation loss: 2.9672794760842582

Epoch: 5| Step: 8
Training loss: 3.2794757223973994
Validation loss: 2.9663900385234507

Epoch: 5| Step: 9
Training loss: 3.389381286063776
Validation loss: 2.967264009251883

Epoch: 5| Step: 10
Training loss: 3.5116971601898213
Validation loss: 2.9651569014792845

Epoch: 132| Step: 0
Training loss: 3.1000113271690894
Validation loss: 2.9683496970651917

Epoch: 5| Step: 1
Training loss: 3.9264839720093456
Validation loss: 2.9667628962483046

Epoch: 5| Step: 2
Training loss: 3.3132042765924012
Validation loss: 2.964502870150054

Epoch: 5| Step: 3
Training loss: 2.9567587158714583
Validation loss: 2.9637588348452826

Epoch: 5| Step: 4
Training loss: 3.2341845175265127
Validation loss: 2.963516916626948

Epoch: 5| Step: 5
Training loss: 3.420863450568661
Validation loss: 2.964134179712542

Epoch: 5| Step: 6
Training loss: 3.2595434187390446
Validation loss: 2.96342843971553

Epoch: 5| Step: 7
Training loss: 3.0300444732524463
Validation loss: 2.961923706276577

Epoch: 5| Step: 8
Training loss: 3.4261566269630626
Validation loss: 2.9598944821544766

Epoch: 5| Step: 9
Training loss: 3.345791772669
Validation loss: 2.96164123845923

Epoch: 5| Step: 10
Training loss: 2.3574546426109184
Validation loss: 2.959804897419196

Epoch: 133| Step: 0
Training loss: 2.6199893358610518
Validation loss: 2.9633344026350894

Epoch: 5| Step: 1
Training loss: 2.716421774687356
Validation loss: 2.9603588224826884

Epoch: 5| Step: 2
Training loss: 3.473473846341478
Validation loss: 2.9620208909764107

Epoch: 5| Step: 3
Training loss: 3.2729682677094663
Validation loss: 2.963320851360317

Epoch: 5| Step: 4
Training loss: 4.226453740947041
Validation loss: 2.9613163804923768

Epoch: 5| Step: 5
Training loss: 3.4760596436715963
Validation loss: 2.9589594539931876

Epoch: 5| Step: 6
Training loss: 3.2777598393123593
Validation loss: 2.9620748364778073

Epoch: 5| Step: 7
Training loss: 2.1104244306094526
Validation loss: 2.9586096453600033

Epoch: 5| Step: 8
Training loss: 3.5770440613611325
Validation loss: 2.9596392585565567

Epoch: 5| Step: 9
Training loss: 3.5854021059162107
Validation loss: 2.9592040604844865

Epoch: 5| Step: 10
Training loss: 2.6907056275802437
Validation loss: 2.960608034340377

Epoch: 134| Step: 0
Training loss: 3.3081675573624514
Validation loss: 2.963391575286334

Epoch: 5| Step: 1
Training loss: 3.473223302005044
Validation loss: 2.967070014700998

Epoch: 5| Step: 2
Training loss: 3.6708455692106097
Validation loss: 2.958703349115699

Epoch: 5| Step: 3
Training loss: 3.2918192349257644
Validation loss: 2.9616673175886

Epoch: 5| Step: 4
Training loss: 2.827794008222999
Validation loss: 2.960427897355663

Epoch: 5| Step: 5
Training loss: 3.4957138792838682
Validation loss: 2.955236484494236

Epoch: 5| Step: 6
Training loss: 3.1958857910413325
Validation loss: 2.9578543172232297

Epoch: 5| Step: 7
Training loss: 2.699016381280803
Validation loss: 2.958062001919464

Epoch: 5| Step: 8
Training loss: 3.1595825127163693
Validation loss: 2.959310331003051

Epoch: 5| Step: 9
Training loss: 2.795335825635674
Validation loss: 2.960498259149426

Epoch: 5| Step: 10
Training loss: 3.6071728350352728
Validation loss: 2.960262119282798

Epoch: 135| Step: 0
Training loss: 3.182384500018348
Validation loss: 2.956356490963851

Epoch: 5| Step: 1
Training loss: 3.5746026838705
Validation loss: 2.959188263821884

Epoch: 5| Step: 2
Training loss: 3.733303027938274
Validation loss: 2.954416362817282

Epoch: 5| Step: 3
Training loss: 2.37730035306626
Validation loss: 2.9547044755980942

Epoch: 5| Step: 4
Training loss: 1.904640769228767
Validation loss: 2.953316144936506

Epoch: 5| Step: 5
Training loss: 3.1677372444503553
Validation loss: 2.9541708105831055

Epoch: 5| Step: 6
Training loss: 3.7774879088798414
Validation loss: 2.9526621511222912

Epoch: 5| Step: 7
Training loss: 3.243524556052464
Validation loss: 2.9557097782339166

Epoch: 5| Step: 8
Training loss: 3.1201766365130665
Validation loss: 2.95565523950757

Epoch: 5| Step: 9
Training loss: 3.3222618932775925
Validation loss: 2.956107049034595

Epoch: 5| Step: 10
Training loss: 3.7504204832210957
Validation loss: 2.9544091979482197

Epoch: 136| Step: 0
Training loss: 3.4751953179884647
Validation loss: 2.961112543834121

Epoch: 5| Step: 1
Training loss: 2.9852878312934825
Validation loss: 2.959458480482041

Epoch: 5| Step: 2
Training loss: 3.6085951982467597
Validation loss: 2.960942590154838

Epoch: 5| Step: 3
Training loss: 2.8533189354589736
Validation loss: 2.96548762100149

Epoch: 5| Step: 4
Training loss: 3.2198736211013403
Validation loss: 2.9629256483759727

Epoch: 5| Step: 5
Training loss: 3.075235007385122
Validation loss: 2.9559951969691456

Epoch: 5| Step: 6
Training loss: 3.497540699829017
Validation loss: 2.954489917779595

Epoch: 5| Step: 7
Training loss: 3.1355446486264986
Validation loss: 2.9508915072901782

Epoch: 5| Step: 8
Training loss: 3.938119264376601
Validation loss: 2.952055252551501

Epoch: 5| Step: 9
Training loss: 2.7297165780137247
Validation loss: 2.949994951761444

Epoch: 5| Step: 10
Training loss: 2.8350909522266585
Validation loss: 2.953334677851083

Epoch: 137| Step: 0
Training loss: 3.703754355472781
Validation loss: 2.9507552951965548

Epoch: 5| Step: 1
Training loss: 3.3544862172435956
Validation loss: 2.951024809805923

Epoch: 5| Step: 2
Training loss: 3.6071699268237207
Validation loss: 2.9512147078408115

Epoch: 5| Step: 3
Training loss: 2.9585896949548887
Validation loss: 2.951083626512224

Epoch: 5| Step: 4
Training loss: 3.3021901752182754
Validation loss: 2.947472706773903

Epoch: 5| Step: 5
Training loss: 2.811997008380411
Validation loss: 2.9475694651418536

Epoch: 5| Step: 6
Training loss: 2.956762425084422
Validation loss: 2.9477774239566705

Epoch: 5| Step: 7
Training loss: 3.400355567291278
Validation loss: 2.9439086040172127

Epoch: 5| Step: 8
Training loss: 3.4817538816181544
Validation loss: 2.9450795715391553

Epoch: 5| Step: 9
Training loss: 2.4910691002963308
Validation loss: 2.942059870360115

Epoch: 5| Step: 10
Training loss: 3.2819169592804
Validation loss: 2.949555675414924

Epoch: 138| Step: 0
Training loss: 3.370562992328419
Validation loss: 2.9690090953671135

Epoch: 5| Step: 1
Training loss: 1.9334661268251694
Validation loss: 2.9483757106603963

Epoch: 5| Step: 2
Training loss: 3.2247621256313987
Validation loss: 2.944998232518195

Epoch: 5| Step: 3
Training loss: 3.233544284454191
Validation loss: 2.9481654792493357

Epoch: 5| Step: 4
Training loss: 3.0910092939362372
Validation loss: 2.9413064535735702

Epoch: 5| Step: 5
Training loss: 3.029909761803617
Validation loss: 2.9374912770634225

Epoch: 5| Step: 6
Training loss: 3.0995586081026887
Validation loss: 2.9399084351582667

Epoch: 5| Step: 7
Training loss: 3.7651664486348135
Validation loss: 2.9377154635842664

Epoch: 5| Step: 8
Training loss: 3.7830866617011836
Validation loss: 2.938353851436387

Epoch: 5| Step: 9
Training loss: 3.1780610294711864
Validation loss: 2.934977968846044

Epoch: 5| Step: 10
Training loss: 3.4008188607966456
Validation loss: 2.9362305634470824

Epoch: 139| Step: 0
Training loss: 2.5735592264964793
Validation loss: 2.9335942236487837

Epoch: 5| Step: 1
Training loss: 3.120915146397477
Validation loss: 2.9311605454753304

Epoch: 5| Step: 2
Training loss: 3.74785260069231
Validation loss: 2.9290138560688694

Epoch: 5| Step: 3
Training loss: 3.1813098414700325
Validation loss: 2.9267755045197603

Epoch: 5| Step: 4
Training loss: 3.199197585113904
Validation loss: 2.9270885684835415

Epoch: 5| Step: 5
Training loss: 2.368614043911264
Validation loss: 2.92927185654142

Epoch: 5| Step: 6
Training loss: 3.3075657207853713
Validation loss: 2.9267601512373336

Epoch: 5| Step: 7
Training loss: 3.3951447769779457
Validation loss: 2.9309298038812077

Epoch: 5| Step: 8
Training loss: 3.746590272140438
Validation loss: 2.9314508022425656

Epoch: 5| Step: 9
Training loss: 3.4174359238707326
Validation loss: 2.9406758675605453

Epoch: 5| Step: 10
Training loss: 2.982192754531991
Validation loss: 2.9413101465374707

Epoch: 140| Step: 0
Training loss: 3.758220182577767
Validation loss: 2.9561757809760154

Epoch: 5| Step: 1
Training loss: 3.252811976020559
Validation loss: 2.93592554896467

Epoch: 5| Step: 2
Training loss: 2.408133525105605
Validation loss: 2.9250732732429277

Epoch: 5| Step: 3
Training loss: 2.7068180148869545
Validation loss: 2.922022372443457

Epoch: 5| Step: 4
Training loss: 3.196856062936489
Validation loss: 2.927089227109851

Epoch: 5| Step: 5
Training loss: 3.059644184992321
Validation loss: 2.9287891995491937

Epoch: 5| Step: 6
Training loss: 3.853320852037255
Validation loss: 2.930750026962612

Epoch: 5| Step: 7
Training loss: 3.537210480936948
Validation loss: 2.9312083043810313

Epoch: 5| Step: 8
Training loss: 2.6976066224642516
Validation loss: 2.9296333160311976

Epoch: 5| Step: 9
Training loss: 3.0760735971404216
Validation loss: 2.926635461521714

Epoch: 5| Step: 10
Training loss: 3.580522691726961
Validation loss: 2.9230228933270452

Epoch: 141| Step: 0
Training loss: 3.6902065366096943
Validation loss: 2.921614187744659

Epoch: 5| Step: 1
Training loss: 3.1003669337025563
Validation loss: 2.923322335708011

Epoch: 5| Step: 2
Training loss: 3.3272842993063643
Validation loss: 2.9242452926566225

Epoch: 5| Step: 3
Training loss: 3.2940996248689887
Validation loss: 2.9235681323728224

Epoch: 5| Step: 4
Training loss: 3.2966755449608134
Validation loss: 2.9218755352113437

Epoch: 5| Step: 5
Training loss: 3.3890409504973453
Validation loss: 2.9225504446915207

Epoch: 5| Step: 6
Training loss: 2.9523046252203815
Validation loss: 2.9195817159425967

Epoch: 5| Step: 7
Training loss: 2.9139155537472456
Validation loss: 2.9213420475527054

Epoch: 5| Step: 8
Training loss: 3.1093964695788308
Validation loss: 2.9191989125624067

Epoch: 5| Step: 9
Training loss: 3.0191376936685215
Validation loss: 2.918340496850138

Epoch: 5| Step: 10
Training loss: 3.1321069393779815
Validation loss: 2.920574232761523

Epoch: 142| Step: 0
Training loss: 2.8439341055832172
Validation loss: 2.9212798071226533

Epoch: 5| Step: 1
Training loss: 3.123465199273752
Validation loss: 2.91817061738307

Epoch: 5| Step: 2
Training loss: 3.198055815180416
Validation loss: 2.925457560094445

Epoch: 5| Step: 3
Training loss: 3.4978388517326566
Validation loss: 2.922537370978606

Epoch: 5| Step: 4
Training loss: 2.5801049230369286
Validation loss: 2.9260811215240228

Epoch: 5| Step: 5
Training loss: 2.9782661908876076
Validation loss: 2.9252346312474597

Epoch: 5| Step: 6
Training loss: 3.3646794513086373
Validation loss: 2.9175705073282043

Epoch: 5| Step: 7
Training loss: 3.443096668004279
Validation loss: 2.9155371827276895

Epoch: 5| Step: 8
Training loss: 3.1436816471624565
Validation loss: 2.918889371030092

Epoch: 5| Step: 9
Training loss: 3.944131504474079
Validation loss: 2.917479615954711

Epoch: 5| Step: 10
Training loss: 2.9612164126963543
Validation loss: 2.9164144931424865

Epoch: 143| Step: 0
Training loss: 3.764889847155991
Validation loss: 2.9185636044493544

Epoch: 5| Step: 1
Training loss: 3.1693721724738113
Validation loss: 2.921952311578934

Epoch: 5| Step: 2
Training loss: 2.9881472090035626
Validation loss: 2.9195983397987026

Epoch: 5| Step: 3
Training loss: 2.567826387633157
Validation loss: 2.9186619738239554

Epoch: 5| Step: 4
Training loss: 3.652645845210322
Validation loss: 2.9201091005455804

Epoch: 5| Step: 5
Training loss: 3.1574790752137374
Validation loss: 2.9194636857741996

Epoch: 5| Step: 6
Training loss: 3.1735360442525185
Validation loss: 2.9189311818775985

Epoch: 5| Step: 7
Training loss: 2.4475565111067477
Validation loss: 2.9200622900169493

Epoch: 5| Step: 8
Training loss: 3.180396148670097
Validation loss: 2.917208661350557

Epoch: 5| Step: 9
Training loss: 3.760793031295815
Validation loss: 2.9239086571011748

Epoch: 5| Step: 10
Training loss: 3.1282871505371466
Validation loss: 2.922076718597775

Epoch: 144| Step: 0
Training loss: 3.074152983334012
Validation loss: 2.9319697660389212

Epoch: 5| Step: 1
Training loss: 3.0373092340289745
Validation loss: 2.922172241288307

Epoch: 5| Step: 2
Training loss: 3.378540866037273
Validation loss: 2.9276308672964086

Epoch: 5| Step: 3
Training loss: 3.4392658206470172
Validation loss: 2.9265136100071456

Epoch: 5| Step: 4
Training loss: 2.8048300534204484
Validation loss: 2.926037402085602

Epoch: 5| Step: 5
Training loss: 2.946018771783155
Validation loss: 2.928430065193158

Epoch: 5| Step: 6
Training loss: 3.16719032441791
Validation loss: 2.9214448101612516

Epoch: 5| Step: 7
Training loss: 3.3221080278427473
Validation loss: 2.9195499958311526

Epoch: 5| Step: 8
Training loss: 3.810119636239268
Validation loss: 2.9249122060945565

Epoch: 5| Step: 9
Training loss: 3.1876053138239606
Validation loss: 2.920545572891658

Epoch: 5| Step: 10
Training loss: 2.9269143776420674
Validation loss: 2.915384008515295

Epoch: 145| Step: 0
Training loss: 3.354741507292255
Validation loss: 2.9183234845757617

Epoch: 5| Step: 1
Training loss: 2.679656893274553
Validation loss: 2.9178129138273285

Epoch: 5| Step: 2
Training loss: 3.5180636615729233
Validation loss: 2.9132477922562954

Epoch: 5| Step: 3
Training loss: 3.6442161824557906
Validation loss: 2.917849300653494

Epoch: 5| Step: 4
Training loss: 3.5613022514090424
Validation loss: 2.9191997310447397

Epoch: 5| Step: 5
Training loss: 2.922667696720601
Validation loss: 2.916805010618816

Epoch: 5| Step: 6
Training loss: 2.723788973987687
Validation loss: 2.914903451169183

Epoch: 5| Step: 7
Training loss: 3.4023908399439318
Validation loss: 2.91161773865744

Epoch: 5| Step: 8
Training loss: 2.5406980909881405
Validation loss: 2.9124205578680065

Epoch: 5| Step: 9
Training loss: 3.137530268184971
Validation loss: 2.9117261104631087

Epoch: 5| Step: 10
Training loss: 3.5494931678561135
Validation loss: 2.9113681645775706

Epoch: 146| Step: 0
Training loss: 3.3464216450617945
Validation loss: 2.9119119348964255

Epoch: 5| Step: 1
Training loss: 2.1137823332259877
Validation loss: 2.9101970561006856

Epoch: 5| Step: 2
Training loss: 2.8780138555515298
Validation loss: 2.9120450101341713

Epoch: 5| Step: 3
Training loss: 3.0335335536174397
Validation loss: 2.910321035411341

Epoch: 5| Step: 4
Training loss: 2.774435460170257
Validation loss: 2.91034389236945

Epoch: 5| Step: 5
Training loss: 3.7274496434044835
Validation loss: 2.9098613969819027

Epoch: 5| Step: 6
Training loss: 3.1526042164117136
Validation loss: 2.9091311333831493

Epoch: 5| Step: 7
Training loss: 3.1996303940945237
Validation loss: 2.9131369108996634

Epoch: 5| Step: 8
Training loss: 3.876716233710415
Validation loss: 2.914741328618039

Epoch: 5| Step: 9
Training loss: 3.277013605196069
Validation loss: 2.9111818809766214

Epoch: 5| Step: 10
Training loss: 3.536356381878919
Validation loss: 2.909580185314211

Epoch: 147| Step: 0
Training loss: 3.496906957403613
Validation loss: 2.9140161597857657

Epoch: 5| Step: 1
Training loss: 3.0602009765846825
Validation loss: 2.922146004443008

Epoch: 5| Step: 2
Training loss: 3.8544821670204814
Validation loss: 2.9231106050210696

Epoch: 5| Step: 3
Training loss: 2.9378733296259956
Validation loss: 2.914742143954382

Epoch: 5| Step: 4
Training loss: 3.4753233340663647
Validation loss: 2.9166291376561935

Epoch: 5| Step: 5
Training loss: 3.261683225152724
Validation loss: 2.9150773202250964

Epoch: 5| Step: 6
Training loss: 2.7311250391816144
Validation loss: 2.9121749180698884

Epoch: 5| Step: 7
Training loss: 3.052059203867306
Validation loss: 2.9067414479426286

Epoch: 5| Step: 8
Training loss: 3.158139409240549
Validation loss: 2.9094020137275347

Epoch: 5| Step: 9
Training loss: 2.6066633742849072
Validation loss: 2.907406271168272

Epoch: 5| Step: 10
Training loss: 3.3885531094101164
Validation loss: 2.908047140174187

Epoch: 148| Step: 0
Training loss: 2.917897010340094
Validation loss: 2.904808480833703

Epoch: 5| Step: 1
Training loss: 3.862489501543808
Validation loss: 2.905861084799407

Epoch: 5| Step: 2
Training loss: 3.359673633165388
Validation loss: 2.905992967396182

Epoch: 5| Step: 3
Training loss: 3.122655065029016
Validation loss: 2.91175857437866

Epoch: 5| Step: 4
Training loss: 3.424743843245171
Validation loss: 2.9102317807414444

Epoch: 5| Step: 5
Training loss: 3.002761523492629
Validation loss: 2.906886879247611

Epoch: 5| Step: 6
Training loss: 2.6476613035404246
Validation loss: 2.9075070759901207

Epoch: 5| Step: 7
Training loss: 2.6204749569379526
Validation loss: 2.9118103545962186

Epoch: 5| Step: 8
Training loss: 4.021208328918131
Validation loss: 2.9116918341906897

Epoch: 5| Step: 9
Training loss: 3.3889160068309425
Validation loss: 2.905679995075119

Epoch: 5| Step: 10
Training loss: 2.188873513754577
Validation loss: 2.911970093389183

Epoch: 149| Step: 0
Training loss: 3.6277284548413253
Validation loss: 2.911431697324661

Epoch: 5| Step: 1
Training loss: 2.478215288824042
Validation loss: 2.9064469479680968

Epoch: 5| Step: 2
Training loss: 3.5621565268393387
Validation loss: 2.9048687875417882

Epoch: 5| Step: 3
Training loss: 3.3873608606345282
Validation loss: 2.903962455772193

Epoch: 5| Step: 4
Training loss: 3.295498528979249
Validation loss: 2.905108376365116

Epoch: 5| Step: 5
Training loss: 3.457583212026982
Validation loss: 2.9013415825002387

Epoch: 5| Step: 6
Training loss: 2.7934160207862964
Validation loss: 2.903581265254426

Epoch: 5| Step: 7
Training loss: 2.714760670660013
Validation loss: 2.9054999943430815

Epoch: 5| Step: 8
Training loss: 3.456194587801381
Validation loss: 2.8997939301084066

Epoch: 5| Step: 9
Training loss: 3.275441432642983
Validation loss: 2.9020546076129357

Epoch: 5| Step: 10
Training loss: 2.7612289577112357
Validation loss: 2.9004870421944755

Epoch: 150| Step: 0
Training loss: 3.220956138911473
Validation loss: 2.902546346364942

Epoch: 5| Step: 1
Training loss: 2.670146896378959
Validation loss: 2.900774298422342

Epoch: 5| Step: 2
Training loss: 3.4712009877861325
Validation loss: 2.904644936062714

Epoch: 5| Step: 3
Training loss: 2.995799302574141
Validation loss: 2.9022752775321807

Epoch: 5| Step: 4
Training loss: 3.1696244697881766
Validation loss: 2.9026924956904256

Epoch: 5| Step: 5
Training loss: 3.027485505753715
Validation loss: 2.9012170179950716

Epoch: 5| Step: 6
Training loss: 3.0924154158105717
Validation loss: 2.90245248044373

Epoch: 5| Step: 7
Training loss: 3.4048349783592156
Validation loss: 2.9015324950368298

Epoch: 5| Step: 8
Training loss: 3.313091441202025
Validation loss: 2.8999071931681115

Epoch: 5| Step: 9
Training loss: 3.624574570520069
Validation loss: 2.906385851033642

Epoch: 5| Step: 10
Training loss: 2.9357788237955007
Validation loss: 2.9079463963905425

Epoch: 151| Step: 0
Training loss: 3.9502575995552793
Validation loss: 2.913564963555236

Epoch: 5| Step: 1
Training loss: 3.620217819194122
Validation loss: 2.9191056093414542

Epoch: 5| Step: 2
Training loss: 2.5653754128014006
Validation loss: 2.911273617083373

Epoch: 5| Step: 3
Training loss: 2.9052964153503105
Validation loss: 2.910875709047005

Epoch: 5| Step: 4
Training loss: 2.736786046399961
Validation loss: 2.904338024702541

Epoch: 5| Step: 5
Training loss: 3.021937113836572
Validation loss: 2.9047769621310646

Epoch: 5| Step: 6
Training loss: 3.4301079077470815
Validation loss: 2.900085656368891

Epoch: 5| Step: 7
Training loss: 3.3531166154769063
Validation loss: 2.9000599498867645

Epoch: 5| Step: 8
Training loss: 3.3175874904660727
Validation loss: 2.8984387267881604

Epoch: 5| Step: 9
Training loss: 3.284643834052202
Validation loss: 2.898505358206647

Epoch: 5| Step: 10
Training loss: 2.4390046781813335
Validation loss: 2.8968790615030438

Epoch: 152| Step: 0
Training loss: 3.45243559294558
Validation loss: 2.898925250202826

Epoch: 5| Step: 1
Training loss: 3.1944752088161854
Validation loss: 2.8969345306659626

Epoch: 5| Step: 2
Training loss: 3.486365874270419
Validation loss: 2.899400698781323

Epoch: 5| Step: 3
Training loss: 3.4988491346046393
Validation loss: 2.8994189503129104

Epoch: 5| Step: 4
Training loss: 3.056884443899856
Validation loss: 2.8993186123311023

Epoch: 5| Step: 5
Training loss: 3.4052259673257814
Validation loss: 2.898817730823011

Epoch: 5| Step: 6
Training loss: 3.111557697607742
Validation loss: 2.8990031968056376

Epoch: 5| Step: 7
Training loss: 3.1765359542495557
Validation loss: 2.8974644315283866

Epoch: 5| Step: 8
Training loss: 2.602844655487174
Validation loss: 2.8958097946639767

Epoch: 5| Step: 9
Training loss: 2.711748073444612
Validation loss: 2.8992946604328576

Epoch: 5| Step: 10
Training loss: 3.2375228232974775
Validation loss: 2.8996632296642413

Epoch: 153| Step: 0
Training loss: 2.829008354360759
Validation loss: 2.898875165959379

Epoch: 5| Step: 1
Training loss: 3.2290592462864214
Validation loss: 2.9011931630656767

Epoch: 5| Step: 2
Training loss: 3.782575768961808
Validation loss: 2.8974583388744843

Epoch: 5| Step: 3
Training loss: 3.419645654491517
Validation loss: 2.8964533011992923

Epoch: 5| Step: 4
Training loss: 2.6708727289667658
Validation loss: 2.8951576142738076

Epoch: 5| Step: 5
Training loss: 3.5566994810393093
Validation loss: 2.8950898538163172

Epoch: 5| Step: 6
Training loss: 3.1895275773038607
Validation loss: 2.893484526531402

Epoch: 5| Step: 7
Training loss: 3.2724570032709117
Validation loss: 2.893938894269806

Epoch: 5| Step: 8
Training loss: 2.877807904564043
Validation loss: 2.8927622230072445

Epoch: 5| Step: 9
Training loss: 3.2226893937689587
Validation loss: 2.8971074216217567

Epoch: 5| Step: 10
Training loss: 2.7486224625695583
Validation loss: 2.8967589903133177

Epoch: 154| Step: 0
Training loss: 2.5966234032483646
Validation loss: 2.8962784097047614

Epoch: 5| Step: 1
Training loss: 3.1831972589086486
Validation loss: 2.8963838282579255

Epoch: 5| Step: 2
Training loss: 3.4265192991943683
Validation loss: 2.894887556543002

Epoch: 5| Step: 3
Training loss: 3.081623857887504
Validation loss: 2.894605655374517

Epoch: 5| Step: 4
Training loss: 3.355673662707806
Validation loss: 2.8936133770852073

Epoch: 5| Step: 5
Training loss: 3.47232187933429
Validation loss: 2.8938493885786545

Epoch: 5| Step: 6
Training loss: 3.888072574558214
Validation loss: 2.893093546150801

Epoch: 5| Step: 7
Training loss: 2.337366489942663
Validation loss: 2.892016803056886

Epoch: 5| Step: 8
Training loss: 2.8842288623956787
Validation loss: 2.894557779663373

Epoch: 5| Step: 9
Training loss: 3.535541593509548
Validation loss: 2.8900714427379137

Epoch: 5| Step: 10
Training loss: 2.921649128552416
Validation loss: 2.8909962813381553

Epoch: 155| Step: 0
Training loss: 3.6871523935738675
Validation loss: 2.8901620243008446

Epoch: 5| Step: 1
Training loss: 3.3422330463546404
Validation loss: 2.8903468873193843

Epoch: 5| Step: 2
Training loss: 3.6230656954952543
Validation loss: 2.8920315651421196

Epoch: 5| Step: 3
Training loss: 2.8953101877119916
Validation loss: 2.891341218515924

Epoch: 5| Step: 4
Training loss: 3.328754634130549
Validation loss: 2.8916543685889406

Epoch: 5| Step: 5
Training loss: 2.570191725470353
Validation loss: 2.889425226608286

Epoch: 5| Step: 6
Training loss: 2.684083585719602
Validation loss: 2.890366604515681

Epoch: 5| Step: 7
Training loss: 2.955956932848478
Validation loss: 2.8947907987504733

Epoch: 5| Step: 8
Training loss: 3.0360582108778593
Validation loss: 2.893830259429977

Epoch: 5| Step: 9
Training loss: 2.7352093976633967
Validation loss: 2.897626508583587

Epoch: 5| Step: 10
Training loss: 3.9562376531375145
Validation loss: 2.8944238534825484

Epoch: 156| Step: 0
Training loss: 3.1566781235204666
Validation loss: 2.90141801688141

Epoch: 5| Step: 1
Training loss: 3.1919001707179224
Validation loss: 2.90699246956859

Epoch: 5| Step: 2
Training loss: 2.5244239792177074
Validation loss: 2.9201046599908795

Epoch: 5| Step: 3
Training loss: 3.296750902488922
Validation loss: 2.919715081700515

Epoch: 5| Step: 4
Training loss: 3.60987024914154
Validation loss: 2.91049731509837

Epoch: 5| Step: 5
Training loss: 2.460271642310068
Validation loss: 2.899823924028016

Epoch: 5| Step: 6
Training loss: 3.4615600577112757
Validation loss: 2.902768006913212

Epoch: 5| Step: 7
Training loss: 3.1744997786910725
Validation loss: 2.8884952840107596

Epoch: 5| Step: 8
Training loss: 3.5625104402087975
Validation loss: 2.8878593590903936

Epoch: 5| Step: 9
Training loss: 3.1251785227327726
Validation loss: 2.8894212322089805

Epoch: 5| Step: 10
Training loss: 3.323762568765313
Validation loss: 2.887466204457507

Epoch: 157| Step: 0
Training loss: 3.4697977494104704
Validation loss: 2.8878816765472113

Epoch: 5| Step: 1
Training loss: 3.3121426947440957
Validation loss: 2.885437558651838

Epoch: 5| Step: 2
Training loss: 2.769340045822866
Validation loss: 2.8908087842984966

Epoch: 5| Step: 3
Training loss: 3.0087759085135217
Validation loss: 2.8955307084785344

Epoch: 5| Step: 4
Training loss: 3.383009836550763
Validation loss: 2.8963950276307195

Epoch: 5| Step: 5
Training loss: 2.946931024951265
Validation loss: 2.9082236872741913

Epoch: 5| Step: 6
Training loss: 3.261216980491739
Validation loss: 2.9175067585358607

Epoch: 5| Step: 7
Training loss: 2.818156170938081
Validation loss: 2.947135921623501

Epoch: 5| Step: 8
Training loss: 3.5744478079352104
Validation loss: 2.941938919129423

Epoch: 5| Step: 9
Training loss: 3.4610327025121976
Validation loss: 2.931225266363077

Epoch: 5| Step: 10
Training loss: 2.816116550905465
Validation loss: 2.899963502579988

Epoch: 158| Step: 0
Training loss: 3.695903577570674
Validation loss: 2.8985642871811357

Epoch: 5| Step: 1
Training loss: 2.4391156246404124
Validation loss: 2.885718805198149

Epoch: 5| Step: 2
Training loss: 2.9358116329999797
Validation loss: 2.8889253461265905

Epoch: 5| Step: 3
Training loss: 3.947898334604879
Validation loss: 2.885956228032796

Epoch: 5| Step: 4
Training loss: 3.529380235811663
Validation loss: 2.889220745663646

Epoch: 5| Step: 5
Training loss: 3.063931811637182
Validation loss: 2.8884497424562925

Epoch: 5| Step: 6
Training loss: 2.9725019337204275
Validation loss: 2.8868319674751146

Epoch: 5| Step: 7
Training loss: 2.7987542685049815
Validation loss: 2.8895157405940965

Epoch: 5| Step: 8
Training loss: 3.134974772764001
Validation loss: 2.8921671940910554

Epoch: 5| Step: 9
Training loss: 3.5294510301574924
Validation loss: 2.8903345327376946

Epoch: 5| Step: 10
Training loss: 2.5688598609319704
Validation loss: 2.8866192814163503

Epoch: 159| Step: 0
Training loss: 2.807176086273482
Validation loss: 2.887478034164052

Epoch: 5| Step: 1
Training loss: 3.1884933120731573
Validation loss: 2.88560499766714

Epoch: 5| Step: 2
Training loss: 3.412539773227181
Validation loss: 2.883601514683181

Epoch: 5| Step: 3
Training loss: 3.325385313725495
Validation loss: 2.8848343762112045

Epoch: 5| Step: 4
Training loss: 2.8489610484852426
Validation loss: 2.884780219795254

Epoch: 5| Step: 5
Training loss: 3.5823138509279575
Validation loss: 2.8852658778620537

Epoch: 5| Step: 6
Training loss: 2.879307381208786
Validation loss: 2.888731038297257

Epoch: 5| Step: 7
Training loss: 3.664777283400216
Validation loss: 2.8899524583698195

Epoch: 5| Step: 8
Training loss: 2.5963891631853926
Validation loss: 2.898595444484535

Epoch: 5| Step: 9
Training loss: 3.0342496207643164
Validation loss: 2.909171413670694

Epoch: 5| Step: 10
Training loss: 3.511571963831231
Validation loss: 2.8925209459357966

Epoch: 160| Step: 0
Training loss: 3.4300595301141574
Validation loss: 2.893193012785246

Epoch: 5| Step: 1
Training loss: 3.6926670403944923
Validation loss: 2.8897077981581516

Epoch: 5| Step: 2
Training loss: 3.5213063089772616
Validation loss: 2.8911398436074056

Epoch: 5| Step: 3
Training loss: 2.571991994984748
Validation loss: 2.88531722723764

Epoch: 5| Step: 4
Training loss: 3.4110910154807588
Validation loss: 2.88077959904408

Epoch: 5| Step: 5
Training loss: 3.0439136688281434
Validation loss: 2.8861286094567467

Epoch: 5| Step: 6
Training loss: 3.281098861846582
Validation loss: 2.8873257678258346

Epoch: 5| Step: 7
Training loss: 2.822646255961151
Validation loss: 2.881810861743365

Epoch: 5| Step: 8
Training loss: 2.4881975049069744
Validation loss: 2.8836400854789557

Epoch: 5| Step: 9
Training loss: 3.1810359860363113
Validation loss: 2.8835225169536165

Epoch: 5| Step: 10
Training loss: 3.2736743486249096
Validation loss: 2.882408715190208

Epoch: 161| Step: 0
Training loss: 3.39100904970528
Validation loss: 2.883164418218797

Epoch: 5| Step: 1
Training loss: 2.9551065245661117
Validation loss: 2.882746519666554

Epoch: 5| Step: 2
Training loss: 2.8575768992572113
Validation loss: 2.881410729436244

Epoch: 5| Step: 3
Training loss: 3.8645070660546637
Validation loss: 2.8834095020560357

Epoch: 5| Step: 4
Training loss: 2.2203219580667
Validation loss: 2.8832069685336292

Epoch: 5| Step: 5
Training loss: 2.3991483448844337
Validation loss: 2.880246553781403

Epoch: 5| Step: 6
Training loss: 3.4284941176371957
Validation loss: 2.879739426152754

Epoch: 5| Step: 7
Training loss: 2.8442565131524025
Validation loss: 2.879059680213993

Epoch: 5| Step: 8
Training loss: 3.2800268890860393
Validation loss: 2.878495845008912

Epoch: 5| Step: 9
Training loss: 3.9143463458237155
Validation loss: 2.880739976325052

Epoch: 5| Step: 10
Training loss: 3.3396978335266643
Validation loss: 2.878603675471971

Epoch: 162| Step: 0
Training loss: 3.35806674766886
Validation loss: 2.8786354477994194

Epoch: 5| Step: 1
Training loss: 3.4208389176862504
Validation loss: 2.877689070593525

Epoch: 5| Step: 2
Training loss: 2.9296261386803204
Validation loss: 2.878943879240047

Epoch: 5| Step: 3
Training loss: 2.8285650258728046
Validation loss: 2.8787279093686577

Epoch: 5| Step: 4
Training loss: 3.5840728499382584
Validation loss: 2.879409386982694

Epoch: 5| Step: 5
Training loss: 3.068491155270079
Validation loss: 2.8759608524533498

Epoch: 5| Step: 6
Training loss: 3.032974539137068
Validation loss: 2.878486161301512

Epoch: 5| Step: 7
Training loss: 3.055136254950983
Validation loss: 2.884991805372296

Epoch: 5| Step: 8
Training loss: 3.319721770750204
Validation loss: 2.8847457646558383

Epoch: 5| Step: 9
Training loss: 2.8819512628885726
Validation loss: 2.8828061789584427

Epoch: 5| Step: 10
Training loss: 3.376437269692632
Validation loss: 2.8755543527913763

Epoch: 163| Step: 0
Training loss: 3.0862136137846434
Validation loss: 2.8803256030874653

Epoch: 5| Step: 1
Training loss: 3.7239119662441573
Validation loss: 2.8805244463845554

Epoch: 5| Step: 2
Training loss: 3.186605440160769
Validation loss: 2.8841915856534786

Epoch: 5| Step: 3
Training loss: 3.540733094682275
Validation loss: 2.8798538856560083

Epoch: 5| Step: 4
Training loss: 3.1721452870330356
Validation loss: 2.8829214655344866

Epoch: 5| Step: 5
Training loss: 3.3646468559071425
Validation loss: 2.8811375386114673

Epoch: 5| Step: 6
Training loss: 2.9779382765235716
Validation loss: 2.880571732994605

Epoch: 5| Step: 7
Training loss: 2.5193625223602667
Validation loss: 2.8773409554028735

Epoch: 5| Step: 8
Training loss: 3.03742054022949
Validation loss: 2.879101824607191

Epoch: 5| Step: 9
Training loss: 2.9846718525668585
Validation loss: 2.8786074720324057

Epoch: 5| Step: 10
Training loss: 3.145871766384038
Validation loss: 2.8764158635177464

Epoch: 164| Step: 0
Training loss: 3.5909869643218824
Validation loss: 2.8755228334957414

Epoch: 5| Step: 1
Training loss: 3.0142914190219003
Validation loss: 2.883284253536053

Epoch: 5| Step: 2
Training loss: 2.840988662992507
Validation loss: 2.879282906693231

Epoch: 5| Step: 3
Training loss: 3.1631721656778717
Validation loss: 2.875772594420793

Epoch: 5| Step: 4
Training loss: 3.384605161778144
Validation loss: 2.8767910764604885

Epoch: 5| Step: 5
Training loss: 2.913742088722804
Validation loss: 2.8761713906113595

Epoch: 5| Step: 6
Training loss: 2.581513091712278
Validation loss: 2.879596922943477

Epoch: 5| Step: 7
Training loss: 3.04842771433751
Validation loss: 2.883358307198648

Epoch: 5| Step: 8
Training loss: 3.8484258976032346
Validation loss: 2.8906870011916985

Epoch: 5| Step: 9
Training loss: 3.163688430337749
Validation loss: 2.8926224281376043

Epoch: 5| Step: 10
Training loss: 3.130483013336688
Validation loss: 2.89440174944277

Epoch: 165| Step: 0
Training loss: 3.1722133813019626
Validation loss: 2.887406664535186

Epoch: 5| Step: 1
Training loss: 3.7142719907821493
Validation loss: 2.882207929421683

Epoch: 5| Step: 2
Training loss: 3.3050194972584204
Validation loss: 2.8874316313207395

Epoch: 5| Step: 3
Training loss: 3.0438107462936865
Validation loss: 2.875254945655353

Epoch: 5| Step: 4
Training loss: 2.422822434705
Validation loss: 2.8789024725339187

Epoch: 5| Step: 5
Training loss: 2.533526680076543
Validation loss: 2.8738963312437784

Epoch: 5| Step: 6
Training loss: 2.2161974125801835
Validation loss: 2.8745472744620413

Epoch: 5| Step: 7
Training loss: 3.440545137814197
Validation loss: 2.8720170981286994

Epoch: 5| Step: 8
Training loss: 3.8385633505109995
Validation loss: 2.8720413846273902

Epoch: 5| Step: 9
Training loss: 3.0690199288485296
Validation loss: 2.8696791985252226

Epoch: 5| Step: 10
Training loss: 3.6908988159829335
Validation loss: 2.8699974044525667

Epoch: 166| Step: 0
Training loss: 3.0541601481938416
Validation loss: 2.87139412315526

Epoch: 5| Step: 1
Training loss: 2.9582986068478334
Validation loss: 2.872411028565276

Epoch: 5| Step: 2
Training loss: 3.124722125096858
Validation loss: 2.8714103028097115

Epoch: 5| Step: 3
Training loss: 3.0393632676221514
Validation loss: 2.8721985367323675

Epoch: 5| Step: 4
Training loss: 3.094681570653542
Validation loss: 2.8716997284086725

Epoch: 5| Step: 5
Training loss: 2.852671284861376
Validation loss: 2.8677615800047644

Epoch: 5| Step: 6
Training loss: 3.758089241734466
Validation loss: 2.8691390166597195

Epoch: 5| Step: 7
Training loss: 3.0516273409609806
Validation loss: 2.868769355043941

Epoch: 5| Step: 8
Training loss: 3.424887110945014
Validation loss: 2.870067650982844

Epoch: 5| Step: 9
Training loss: 3.1743796095389323
Validation loss: 2.875086543638476

Epoch: 5| Step: 10
Training loss: 3.204154988744229
Validation loss: 2.8711869901677436

Epoch: 167| Step: 0
Training loss: 2.99878365972025
Validation loss: 2.8707836223319028

Epoch: 5| Step: 1
Training loss: 3.1242162103015434
Validation loss: 2.8745161615100954

Epoch: 5| Step: 2
Training loss: 2.8157667050283117
Validation loss: 2.889028899748246

Epoch: 5| Step: 3
Training loss: 3.2487347414099457
Validation loss: 2.8839661354470794

Epoch: 5| Step: 4
Training loss: 3.2449739179459383
Validation loss: 2.8902147812954855

Epoch: 5| Step: 5
Training loss: 2.5608758198616735
Validation loss: 2.8884927367842126

Epoch: 5| Step: 6
Training loss: 3.455283754568496
Validation loss: 2.8794670089250745

Epoch: 5| Step: 7
Training loss: 4.002752310849588
Validation loss: 2.869635934830579

Epoch: 5| Step: 8
Training loss: 2.4730761323679538
Validation loss: 2.8675216261503653

Epoch: 5| Step: 9
Training loss: 2.8751877433180204
Validation loss: 2.8680072640882948

Epoch: 5| Step: 10
Training loss: 3.80418376995363
Validation loss: 2.8712691147966694

Epoch: 168| Step: 0
Training loss: 3.2338679556609726
Validation loss: 2.8697004272281115

Epoch: 5| Step: 1
Training loss: 3.252239922601061
Validation loss: 2.866032862394552

Epoch: 5| Step: 2
Training loss: 3.249682777768921
Validation loss: 2.868332643922526

Epoch: 5| Step: 3
Training loss: 2.99289019826849
Validation loss: 2.8699501562133305

Epoch: 5| Step: 4
Training loss: 3.2671499387897978
Validation loss: 2.866059158520688

Epoch: 5| Step: 5
Training loss: 3.606979698257274
Validation loss: 2.865603097011645

Epoch: 5| Step: 6
Training loss: 2.9968017378236342
Validation loss: 2.8681984620948913

Epoch: 5| Step: 7
Training loss: 2.9205387752383802
Validation loss: 2.877125330333014

Epoch: 5| Step: 8
Training loss: 2.5706934313264562
Validation loss: 2.8791581393456736

Epoch: 5| Step: 9
Training loss: 3.801399078807678
Validation loss: 2.8991329145071894

Epoch: 5| Step: 10
Training loss: 2.657914750757846
Validation loss: 2.8935378909830933

Epoch: 169| Step: 0
Training loss: 2.624315626758736
Validation loss: 2.8789144523026122

Epoch: 5| Step: 1
Training loss: 3.7260905672738747
Validation loss: 2.867884819340206

Epoch: 5| Step: 2
Training loss: 3.539275645054339
Validation loss: 2.8655057333011933

Epoch: 5| Step: 3
Training loss: 3.714775590241226
Validation loss: 2.8633203335784145

Epoch: 5| Step: 4
Training loss: 2.7272787383042183
Validation loss: 2.8644219958083896

Epoch: 5| Step: 5
Training loss: 3.2021030191293325
Validation loss: 2.867017706687759

Epoch: 5| Step: 6
Training loss: 3.256137627769527
Validation loss: 2.8682447604773995

Epoch: 5| Step: 7
Training loss: 2.984963244239032
Validation loss: 2.8662489346544175

Epoch: 5| Step: 8
Training loss: 2.3409355049292846
Validation loss: 2.867378260035558

Epoch: 5| Step: 9
Training loss: 3.037986898447984
Validation loss: 2.865960257428443

Epoch: 5| Step: 10
Training loss: 3.3614674283852173
Validation loss: 2.870660869128817

Epoch: 170| Step: 0
Training loss: 3.4794295586648882
Validation loss: 2.866084674423603

Epoch: 5| Step: 1
Training loss: 3.281614737447737
Validation loss: 2.8662384841902484

Epoch: 5| Step: 2
Training loss: 3.428266713248187
Validation loss: 2.8677550809677914

Epoch: 5| Step: 3
Training loss: 2.522085483091522
Validation loss: 2.8704877294032602

Epoch: 5| Step: 4
Training loss: 3.4017121772269823
Validation loss: 2.871928425849777

Epoch: 5| Step: 5
Training loss: 3.270440744217511
Validation loss: 2.872439440422619

Epoch: 5| Step: 6
Training loss: 2.8917491479666118
Validation loss: 2.879785635134588

Epoch: 5| Step: 7
Training loss: 3.344574300822624
Validation loss: 2.8761033611138034

Epoch: 5| Step: 8
Training loss: 3.054450218565579
Validation loss: 2.87138298787162

Epoch: 5| Step: 9
Training loss: 3.322425511015276
Validation loss: 2.877067418232011

Epoch: 5| Step: 10
Training loss: 2.444252540058768
Validation loss: 2.8782670378944366

Epoch: 171| Step: 0
Training loss: 3.389391978152923
Validation loss: 2.875724143078508

Epoch: 5| Step: 1
Training loss: 2.9162031804531483
Validation loss: 2.86743939240374

Epoch: 5| Step: 2
Training loss: 2.9318730454691475
Validation loss: 2.866695563365539

Epoch: 5| Step: 3
Training loss: 2.977579098410734
Validation loss: 2.8657898564531896

Epoch: 5| Step: 4
Training loss: 3.312108718506687
Validation loss: 2.861932700935113

Epoch: 5| Step: 5
Training loss: 3.3031875416763485
Validation loss: 2.862418723744837

Epoch: 5| Step: 6
Training loss: 3.2103995733447617
Validation loss: 2.8634017634476656

Epoch: 5| Step: 7
Training loss: 3.1652184906040404
Validation loss: 2.862712649481886

Epoch: 5| Step: 8
Training loss: 2.7940844034868726
Validation loss: 2.8612584075727514

Epoch: 5| Step: 9
Training loss: 3.3643262703938377
Validation loss: 2.860696034785003

Epoch: 5| Step: 10
Training loss: 3.3047848950907266
Validation loss: 2.8604525808380057

Epoch: 172| Step: 0
Training loss: 2.764413255654945
Validation loss: 2.86050733943844

Epoch: 5| Step: 1
Training loss: 3.29137131214953
Validation loss: 2.860377979867635

Epoch: 5| Step: 2
Training loss: 3.183590454848755
Validation loss: 2.8600211701920824

Epoch: 5| Step: 3
Training loss: 2.878550451852012
Validation loss: 2.859074478679091

Epoch: 5| Step: 4
Training loss: 3.240275432747333
Validation loss: 2.858946666556813

Epoch: 5| Step: 5
Training loss: 3.0972507591434453
Validation loss: 2.861660526327409

Epoch: 5| Step: 6
Training loss: 3.44214621305705
Validation loss: 2.8644394812537253

Epoch: 5| Step: 7
Training loss: 3.2089347440813536
Validation loss: 2.8619543660070073

Epoch: 5| Step: 8
Training loss: 3.7885989819983488
Validation loss: 2.862697135304897

Epoch: 5| Step: 9
Training loss: 2.5848621541204944
Validation loss: 2.863656278859803

Epoch: 5| Step: 10
Training loss: 3.041005119251683
Validation loss: 2.863096420387884

Epoch: 173| Step: 0
Training loss: 3.390290555852195
Validation loss: 2.876935098968073

Epoch: 5| Step: 1
Training loss: 3.4002933039095766
Validation loss: 2.8638308118181306

Epoch: 5| Step: 2
Training loss: 3.473560605975694
Validation loss: 2.858583335905811

Epoch: 5| Step: 3
Training loss: 2.7206600977226256
Validation loss: 2.861841665710265

Epoch: 5| Step: 4
Training loss: 3.528358423368766
Validation loss: 2.863014285186417

Epoch: 5| Step: 5
Training loss: 3.007440400329763
Validation loss: 2.872625660811177

Epoch: 5| Step: 6
Training loss: 2.4007291004240874
Validation loss: 2.860429450685293

Epoch: 5| Step: 7
Training loss: 2.855395774065356
Validation loss: 2.860804998565778

Epoch: 5| Step: 8
Training loss: 3.1222062401986594
Validation loss: 2.854306580380887

Epoch: 5| Step: 9
Training loss: 3.4096016449249897
Validation loss: 2.858986830727228

Epoch: 5| Step: 10
Training loss: 3.1791012385190593
Validation loss: 2.858553898466488

Epoch: 174| Step: 0
Training loss: 2.83524837475619
Validation loss: 2.859733935127243

Epoch: 5| Step: 1
Training loss: 2.822322646888273
Validation loss: 2.8648094778579374

Epoch: 5| Step: 2
Training loss: 3.4269117101734223
Validation loss: 2.8643250546777357

Epoch: 5| Step: 3
Training loss: 2.9655661123878794
Validation loss: 2.8665980708652317

Epoch: 5| Step: 4
Training loss: 3.3322406090349275
Validation loss: 2.8669704773016003

Epoch: 5| Step: 5
Training loss: 3.6350715422378554
Validation loss: 2.8642849859479194

Epoch: 5| Step: 6
Training loss: 3.337888910729519
Validation loss: 2.862051594350607

Epoch: 5| Step: 7
Training loss: 2.6840230051524334
Validation loss: 2.8608533746018994

Epoch: 5| Step: 8
Training loss: 3.1483725264213116
Validation loss: 2.862114902429761

Epoch: 5| Step: 9
Training loss: 3.304180421997019
Validation loss: 2.8613954861974418

Epoch: 5| Step: 10
Training loss: 3.167677784832755
Validation loss: 2.8582489236794206

Epoch: 175| Step: 0
Training loss: 2.944768961731306
Validation loss: 2.8562616022712253

Epoch: 5| Step: 1
Training loss: 3.1285764446579147
Validation loss: 2.857009521609208

Epoch: 5| Step: 2
Training loss: 3.3152710462321706
Validation loss: 2.8579945313041053

Epoch: 5| Step: 3
Training loss: 3.2696050455568275
Validation loss: 2.858947323843775

Epoch: 5| Step: 4
Training loss: 2.8720115388409986
Validation loss: 2.8598027233568746

Epoch: 5| Step: 5
Training loss: 2.8622268879630615
Validation loss: 2.8607365919991867

Epoch: 5| Step: 6
Training loss: 3.6371296487627687
Validation loss: 2.8621445800170324

Epoch: 5| Step: 7
Training loss: 2.9720711852901722
Validation loss: 2.8627269814834007

Epoch: 5| Step: 8
Training loss: 3.478633238203277
Validation loss: 2.867306127243159

Epoch: 5| Step: 9
Training loss: 3.0961391587143674
Validation loss: 2.8593137256985948

Epoch: 5| Step: 10
Training loss: 2.9941159400992388
Validation loss: 2.8538120415637933

Epoch: 176| Step: 0
Training loss: 2.8515568145277226
Validation loss: 2.8517182059712396

Epoch: 5| Step: 1
Training loss: 3.475535723330714
Validation loss: 2.852442023100155

Epoch: 5| Step: 2
Training loss: 2.782163148627969
Validation loss: 2.8543898292593743

Epoch: 5| Step: 3
Training loss: 3.248192211026082
Validation loss: 2.850052478895767

Epoch: 5| Step: 4
Training loss: 3.7521071553819927
Validation loss: 2.84513730089781

Epoch: 5| Step: 5
Training loss: 2.7237106317596043
Validation loss: 2.8437570172673707

Epoch: 5| Step: 6
Training loss: 3.219336150787926
Validation loss: 2.842105191023643

Epoch: 5| Step: 7
Training loss: 2.9271678618221024
Validation loss: 2.8387671710812836

Epoch: 5| Step: 8
Training loss: 2.650822558588481
Validation loss: 2.8375278128032044

Epoch: 5| Step: 9
Training loss: 3.2635283972239777
Validation loss: 2.841144835661035

Epoch: 5| Step: 10
Training loss: 3.582149457905062
Validation loss: 2.844879284961776

Epoch: 177| Step: 0
Training loss: 3.223474978859159
Validation loss: 2.842541925408976

Epoch: 5| Step: 1
Training loss: 2.8505954722669418
Validation loss: 2.835516310053663

Epoch: 5| Step: 2
Training loss: 2.922325058816977
Validation loss: 2.8472660671259433

Epoch: 5| Step: 3
Training loss: 3.2725861018010165
Validation loss: 2.83243911108894

Epoch: 5| Step: 4
Training loss: 3.1907710326847365
Validation loss: 2.8374237023545845

Epoch: 5| Step: 5
Training loss: 3.15022170482504
Validation loss: 2.839594305654932

Epoch: 5| Step: 6
Training loss: 3.4878357264218156
Validation loss: 2.8481127198687632

Epoch: 5| Step: 7
Training loss: 2.9128204234931894
Validation loss: 2.8474698218584984

Epoch: 5| Step: 8
Training loss: 3.204618524472162
Validation loss: 2.850343149032952

Epoch: 5| Step: 9
Training loss: 2.9882421553304614
Validation loss: 2.850409429731994

Epoch: 5| Step: 10
Training loss: 3.3005651279097976
Validation loss: 2.850571762097099

Epoch: 178| Step: 0
Training loss: 2.8501636993509942
Validation loss: 2.842831632487324

Epoch: 5| Step: 1
Training loss: 3.170710307544686
Validation loss: 2.8442525950270623

Epoch: 5| Step: 2
Training loss: 2.718886097976436
Validation loss: 2.836693523548753

Epoch: 5| Step: 3
Training loss: 3.011279518169619
Validation loss: 2.839858136028699

Epoch: 5| Step: 4
Training loss: 3.2898944156018297
Validation loss: 2.8369289640169724

Epoch: 5| Step: 5
Training loss: 3.152297765308962
Validation loss: 2.8382692020935387

Epoch: 5| Step: 6
Training loss: 3.1174613048412674
Validation loss: 2.831660177201224

Epoch: 5| Step: 7
Training loss: 3.0278231727237976
Validation loss: 2.829264860092167

Epoch: 5| Step: 8
Training loss: 3.5397331494977586
Validation loss: 2.835390014648553

Epoch: 5| Step: 9
Training loss: 3.2458666413295383
Validation loss: 2.8368924420580073

Epoch: 5| Step: 10
Training loss: 3.323501886157503
Validation loss: 2.838780870808051

Epoch: 179| Step: 0
Training loss: 2.951837491118813
Validation loss: 2.852230011087909

Epoch: 5| Step: 1
Training loss: 2.5233380088443687
Validation loss: 2.85355519360817

Epoch: 5| Step: 2
Training loss: 3.2313765480746404
Validation loss: 2.8719191083040747

Epoch: 5| Step: 3
Training loss: 2.7759222371150836
Validation loss: 2.871040317511721

Epoch: 5| Step: 4
Training loss: 3.216199290131184
Validation loss: 2.853497149040069

Epoch: 5| Step: 5
Training loss: 2.9526999838832624
Validation loss: 2.840140179911365

Epoch: 5| Step: 6
Training loss: 3.3194512899657194
Validation loss: 2.8338769997948745

Epoch: 5| Step: 7
Training loss: 3.288000229754289
Validation loss: 2.8258455760813974

Epoch: 5| Step: 8
Training loss: 2.9406667643549707
Validation loss: 2.8297331579858627

Epoch: 5| Step: 9
Training loss: 3.8067671401019476
Validation loss: 2.8283186085785443

Epoch: 5| Step: 10
Training loss: 3.2966308503347634
Validation loss: 2.827340144435707

Epoch: 180| Step: 0
Training loss: 3.538265584859201
Validation loss: 2.8271216960247765

Epoch: 5| Step: 1
Training loss: 2.2243034815618974
Validation loss: 2.8260463984361204

Epoch: 5| Step: 2
Training loss: 3.098572642370023
Validation loss: 2.8242945811173703

Epoch: 5| Step: 3
Training loss: 2.5638324715728324
Validation loss: 2.829691878272405

Epoch: 5| Step: 4
Training loss: 3.090235862495297
Validation loss: 2.82213820246345

Epoch: 5| Step: 5
Training loss: 3.4644881176705553
Validation loss: 2.820083922957984

Epoch: 5| Step: 6
Training loss: 2.840768613636659
Validation loss: 2.821837477581672

Epoch: 5| Step: 7
Training loss: 3.2134667155440058
Validation loss: 2.8354577407007153

Epoch: 5| Step: 8
Training loss: 3.6814888272751234
Validation loss: 2.835740695968789

Epoch: 5| Step: 9
Training loss: 3.039252032569933
Validation loss: 2.8311963859772873

Epoch: 5| Step: 10
Training loss: 3.4750670227613027
Validation loss: 2.8259640727035333

Epoch: 181| Step: 0
Training loss: 3.2728726939924724
Validation loss: 2.8349935787397538

Epoch: 5| Step: 1
Training loss: 2.827592999912954
Validation loss: 2.8280432397009143

Epoch: 5| Step: 2
Training loss: 3.167407267115545
Validation loss: 2.8297439969364313

Epoch: 5| Step: 3
Training loss: 2.4486535011738666
Validation loss: 2.827703036216858

Epoch: 5| Step: 4
Training loss: 2.514206954570884
Validation loss: 2.82475574006238

Epoch: 5| Step: 5
Training loss: 3.4469792838761997
Validation loss: 2.822012554724361

Epoch: 5| Step: 6
Training loss: 3.274888474989737
Validation loss: 2.822011401000127

Epoch: 5| Step: 7
Training loss: 3.1971173773473085
Validation loss: 2.8185998086670407

Epoch: 5| Step: 8
Training loss: 2.9305220165613464
Validation loss: 2.823486198625788

Epoch: 5| Step: 9
Training loss: 3.585333480328034
Validation loss: 2.8232815375044806

Epoch: 5| Step: 10
Training loss: 3.597026890017611
Validation loss: 2.8227109400828887

Epoch: 182| Step: 0
Training loss: 2.8053820076909184
Validation loss: 2.8216590751586192

Epoch: 5| Step: 1
Training loss: 3.125346965601661
Validation loss: 2.8223689784247235

Epoch: 5| Step: 2
Training loss: 3.471615132135385
Validation loss: 2.81892175795293

Epoch: 5| Step: 3
Training loss: 3.1840789986783022
Validation loss: 2.8307335946719867

Epoch: 5| Step: 4
Training loss: 3.0368024174161077
Validation loss: 2.8281062856447177

Epoch: 5| Step: 5
Training loss: 3.2848846649871994
Validation loss: 2.830912244781466

Epoch: 5| Step: 6
Training loss: 2.749493812444467
Validation loss: 2.8278157553428094

Epoch: 5| Step: 7
Training loss: 3.5556255737669
Validation loss: 2.832780758492944

Epoch: 5| Step: 8
Training loss: 3.2053411493232544
Validation loss: 2.815885604844569

Epoch: 5| Step: 9
Training loss: 2.906847656488841
Validation loss: 2.8180065588978453

Epoch: 5| Step: 10
Training loss: 2.9552751413690483
Validation loss: 2.8141270004842416

Epoch: 183| Step: 0
Training loss: 3.73729537352674
Validation loss: 2.8159429320889258

Epoch: 5| Step: 1
Training loss: 3.6267847074437642
Validation loss: 2.8171791157570896

Epoch: 5| Step: 2
Training loss: 3.184375952363925
Validation loss: 2.818828615191386

Epoch: 5| Step: 3
Training loss: 2.6950383585958435
Validation loss: 2.8198597485273553

Epoch: 5| Step: 4
Training loss: 3.075914857814568
Validation loss: 2.8184204617974777

Epoch: 5| Step: 5
Training loss: 3.1619164995319227
Validation loss: 2.8167416443966258

Epoch: 5| Step: 6
Training loss: 3.2395810600509924
Validation loss: 2.823165305624822

Epoch: 5| Step: 7
Training loss: 2.859231080148987
Validation loss: 2.820710467571918

Epoch: 5| Step: 8
Training loss: 2.604992321098271
Validation loss: 2.814066900942781

Epoch: 5| Step: 9
Training loss: 3.0929505827761163
Validation loss: 2.825673692308396

Epoch: 5| Step: 10
Training loss: 2.846716203668022
Validation loss: 2.8257624969336

Epoch: 184| Step: 0
Training loss: 3.1652120126882677
Validation loss: 2.8239225815699145

Epoch: 5| Step: 1
Training loss: 3.656625581671064
Validation loss: 2.833208878212909

Epoch: 5| Step: 2
Training loss: 3.1409744903296124
Validation loss: 2.827315308022158

Epoch: 5| Step: 3
Training loss: 2.801438513850912
Validation loss: 2.8182776306671724

Epoch: 5| Step: 4
Training loss: 3.2773580084798595
Validation loss: 2.819618361243242

Epoch: 5| Step: 5
Training loss: 3.081342535583189
Validation loss: 2.8156954233666696

Epoch: 5| Step: 6
Training loss: 3.440364129954806
Validation loss: 2.8128205111054028

Epoch: 5| Step: 7
Training loss: 3.0476908838513697
Validation loss: 2.8163718640942585

Epoch: 5| Step: 8
Training loss: 3.313209025956952
Validation loss: 2.8132432837344297

Epoch: 5| Step: 9
Training loss: 2.6515228394401036
Validation loss: 2.8150692105526525

Epoch: 5| Step: 10
Training loss: 2.5207656557020126
Validation loss: 2.8133136442846847

Epoch: 185| Step: 0
Training loss: 3.834734011182971
Validation loss: 2.814664270947471

Epoch: 5| Step: 1
Training loss: 3.237263886667849
Validation loss: 2.815549388245966

Epoch: 5| Step: 2
Training loss: 2.9178788708756467
Validation loss: 2.817361622719287

Epoch: 5| Step: 3
Training loss: 2.738743981024406
Validation loss: 2.81642332810433

Epoch: 5| Step: 4
Training loss: 3.719216325516542
Validation loss: 2.816840516159742

Epoch: 5| Step: 5
Training loss: 2.2721180446073594
Validation loss: 2.817672159402004

Epoch: 5| Step: 6
Training loss: 3.207976449380555
Validation loss: 2.818039989660087

Epoch: 5| Step: 7
Training loss: 2.994701793261961
Validation loss: 2.819941934281438

Epoch: 5| Step: 8
Training loss: 2.6425057659970466
Validation loss: 2.8138248244730204

Epoch: 5| Step: 9
Training loss: 3.031710874777981
Validation loss: 2.814118289587508

Epoch: 5| Step: 10
Training loss: 3.4190711112960375
Validation loss: 2.812980675497786

Epoch: 186| Step: 0
Training loss: 2.3976719532263138
Validation loss: 2.811402330666511

Epoch: 5| Step: 1
Training loss: 3.017419152871575
Validation loss: 2.8116059261993454

Epoch: 5| Step: 2
Training loss: 2.8806491581141143
Validation loss: 2.8091931407830844

Epoch: 5| Step: 3
Training loss: 3.459352427394316
Validation loss: 2.8080369602043063

Epoch: 5| Step: 4
Training loss: 3.0622461953383593
Validation loss: 2.810832652606386

Epoch: 5| Step: 5
Training loss: 3.1574417734704854
Validation loss: 2.8096163606901867

Epoch: 5| Step: 6
Training loss: 3.5950581698957365
Validation loss: 2.8095749222802957

Epoch: 5| Step: 7
Training loss: 3.642332928870436
Validation loss: 2.810736626830091

Epoch: 5| Step: 8
Training loss: 2.980425553115047
Validation loss: 2.8094511527119903

Epoch: 5| Step: 9
Training loss: 2.949452857016318
Validation loss: 2.811147370480796

Epoch: 5| Step: 10
Training loss: 2.897282208213546
Validation loss: 2.8070323450740458

Epoch: 187| Step: 0
Training loss: 3.1262936775362493
Validation loss: 2.8100576298957938

Epoch: 5| Step: 1
Training loss: 3.2776293442589215
Validation loss: 2.809749619349211

Epoch: 5| Step: 2
Training loss: 3.0198326996700633
Validation loss: 2.80906114253753

Epoch: 5| Step: 3
Training loss: 2.8620342958582703
Validation loss: 2.8119327579300486

Epoch: 5| Step: 4
Training loss: 3.0751401109486594
Validation loss: 2.815048972332426

Epoch: 5| Step: 5
Training loss: 2.679808499910284
Validation loss: 2.814751997534724

Epoch: 5| Step: 6
Training loss: 2.962577426075674
Validation loss: 2.81514030499295

Epoch: 5| Step: 7
Training loss: 3.3819691793976343
Validation loss: 2.819445590463139

Epoch: 5| Step: 8
Training loss: 2.8783394036802403
Validation loss: 2.8217770843675805

Epoch: 5| Step: 9
Training loss: 4.110364439462189
Validation loss: 2.820285959135651

Epoch: 5| Step: 10
Training loss: 2.5432485025173297
Validation loss: 2.8115619001882903

Epoch: 188| Step: 0
Training loss: 3.226622352322068
Validation loss: 2.815674950188915

Epoch: 5| Step: 1
Training loss: 3.181058470950427
Validation loss: 2.812248109318661

Epoch: 5| Step: 2
Training loss: 2.9986448406116644
Validation loss: 2.809186778200714

Epoch: 5| Step: 3
Training loss: 2.9524580590921596
Validation loss: 2.8071718396791803

Epoch: 5| Step: 4
Training loss: 3.2686598697876708
Validation loss: 2.8070144737161558

Epoch: 5| Step: 5
Training loss: 3.1879083708418894
Validation loss: 2.8072678549768035

Epoch: 5| Step: 6
Training loss: 2.4890162461862912
Validation loss: 2.809950133216824

Epoch: 5| Step: 7
Training loss: 3.2135415017959
Validation loss: 2.807680008209065

Epoch: 5| Step: 8
Training loss: 3.4002022907440312
Validation loss: 2.8102771064288845

Epoch: 5| Step: 9
Training loss: 3.0626094565001973
Validation loss: 2.8064141499073703

Epoch: 5| Step: 10
Training loss: 3.2789682356542715
Validation loss: 2.8078070204494714

Epoch: 189| Step: 0
Training loss: 3.10748033930113
Validation loss: 2.8078263229656297

Epoch: 5| Step: 1
Training loss: 3.148203952352889
Validation loss: 2.805732063852633

Epoch: 5| Step: 2
Training loss: 3.0151572383537597
Validation loss: 2.8122069293865146

Epoch: 5| Step: 3
Training loss: 2.953367193069566
Validation loss: 2.8090028064591555

Epoch: 5| Step: 4
Training loss: 3.2794757223973994
Validation loss: 2.8082917773757705

Epoch: 5| Step: 5
Training loss: 3.2225127217091245
Validation loss: 2.8064782499164993

Epoch: 5| Step: 6
Training loss: 2.806608174666702
Validation loss: 2.811827736271054

Epoch: 5| Step: 7
Training loss: 3.571410963832503
Validation loss: 2.8418076462875073

Epoch: 5| Step: 8
Training loss: 3.4201685164578133
Validation loss: 2.8253726713779197

Epoch: 5| Step: 9
Training loss: 2.7871962856543893
Validation loss: 2.8207688187281903

Epoch: 5| Step: 10
Training loss: 2.822138398678631
Validation loss: 2.807931137301732

Epoch: 190| Step: 0
Training loss: 3.784257937699026
Validation loss: 2.811945480682409

Epoch: 5| Step: 1
Training loss: 2.4473451204167618
Validation loss: 2.805403763143756

Epoch: 5| Step: 2
Training loss: 2.8720812701678082
Validation loss: 2.807946757772281

Epoch: 5| Step: 3
Training loss: 2.985423757611674
Validation loss: 2.8053588411054347

Epoch: 5| Step: 4
Training loss: 3.2065356448946547
Validation loss: 2.807214495285567

Epoch: 5| Step: 5
Training loss: 2.7971300403095927
Validation loss: 2.8042265705543152

Epoch: 5| Step: 6
Training loss: 3.2223557210723093
Validation loss: 2.8074191670613677

Epoch: 5| Step: 7
Training loss: 3.5079330729469316
Validation loss: 2.805168257586073

Epoch: 5| Step: 8
Training loss: 2.74811602127937
Validation loss: 2.8029064160965964

Epoch: 5| Step: 9
Training loss: 3.492605163039495
Validation loss: 2.805132586965043

Epoch: 5| Step: 10
Training loss: 2.902375622827177
Validation loss: 2.805483471078967

Epoch: 191| Step: 0
Training loss: 3.446513202455448
Validation loss: 2.8049049052098445

Epoch: 5| Step: 1
Training loss: 3.2516711413497545
Validation loss: 2.8041434305179096

Epoch: 5| Step: 2
Training loss: 3.1699394747374177
Validation loss: 2.8054635374539525

Epoch: 5| Step: 3
Training loss: 2.637216930656874
Validation loss: 2.8110286095102017

Epoch: 5| Step: 4
Training loss: 3.6028604216758957
Validation loss: 2.8091270493492817

Epoch: 5| Step: 5
Training loss: 2.6644941858366704
Validation loss: 2.8123732799207626

Epoch: 5| Step: 6
Training loss: 3.49976906695766
Validation loss: 2.8147563492735266

Epoch: 5| Step: 7
Training loss: 2.984444981897905
Validation loss: 2.809808927128358

Epoch: 5| Step: 8
Training loss: 2.768530230271162
Validation loss: 2.8127537575279655

Epoch: 5| Step: 9
Training loss: 3.1526456591408443
Validation loss: 2.8091168445129924

Epoch: 5| Step: 10
Training loss: 2.82017580160731
Validation loss: 2.824361728171688

Epoch: 192| Step: 0
Training loss: 3.114725082046722
Validation loss: 2.818081065251206

Epoch: 5| Step: 1
Training loss: 2.8142819163910247
Validation loss: 2.8120550498705565

Epoch: 5| Step: 2
Training loss: 3.4168335168307924
Validation loss: 2.805490019336173

Epoch: 5| Step: 3
Training loss: 3.3558157584866346
Validation loss: 2.8092908801739807

Epoch: 5| Step: 4
Training loss: 3.23546534049485
Validation loss: 2.803858518165757

Epoch: 5| Step: 5
Training loss: 3.1330546525704994
Validation loss: 2.80469329510724

Epoch: 5| Step: 6
Training loss: 3.457871846733921
Validation loss: 2.7995132319826226

Epoch: 5| Step: 7
Training loss: 2.9307735617143718
Validation loss: 2.7980450668842547

Epoch: 5| Step: 8
Training loss: 3.0165384915205697
Validation loss: 2.8009698786286537

Epoch: 5| Step: 9
Training loss: 2.895417894893892
Validation loss: 2.8000386866813605

Epoch: 5| Step: 10
Training loss: 2.7135218194295514
Validation loss: 2.799254968035729

Epoch: 193| Step: 0
Training loss: 3.6935633578321507
Validation loss: 2.8011746241217432

Epoch: 5| Step: 1
Training loss: 2.849962428330505
Validation loss: 2.8024884655477167

Epoch: 5| Step: 2
Training loss: 2.873064965580791
Validation loss: 2.799324459409497

Epoch: 5| Step: 3
Training loss: 3.7454627244444225
Validation loss: 2.806219789247516

Epoch: 5| Step: 4
Training loss: 3.0114036622830747
Validation loss: 2.8091069234637427

Epoch: 5| Step: 5
Training loss: 3.221839977114749
Validation loss: 2.801340256144751

Epoch: 5| Step: 6
Training loss: 3.0873113350619583
Validation loss: 2.8008107189119515

Epoch: 5| Step: 7
Training loss: 2.4410957810403784
Validation loss: 2.803379892590777

Epoch: 5| Step: 8
Training loss: 2.919542003404567
Validation loss: 2.807394705055357

Epoch: 5| Step: 9
Training loss: 3.3551484244839873
Validation loss: 2.8005245868767914

Epoch: 5| Step: 10
Training loss: 2.6508615928501893
Validation loss: 2.8149974859283966

Epoch: 194| Step: 0
Training loss: 2.912894416265385
Validation loss: 2.8071343305569525

Epoch: 5| Step: 1
Training loss: 3.1126129313743913
Validation loss: 2.8118542165660783

Epoch: 5| Step: 2
Training loss: 2.935073499652821
Validation loss: 2.810227233953016

Epoch: 5| Step: 3
Training loss: 3.2441664941021564
Validation loss: 2.8113728040780246

Epoch: 5| Step: 4
Training loss: 2.994075329013227
Validation loss: 2.8079613903009415

Epoch: 5| Step: 5
Training loss: 3.1108048568336466
Validation loss: 2.8036363747877804

Epoch: 5| Step: 6
Training loss: 2.7826582525857524
Validation loss: 2.8041170730548517

Epoch: 5| Step: 7
Training loss: 3.1930230853127015
Validation loss: 2.801127126565338

Epoch: 5| Step: 8
Training loss: 3.397088565798212
Validation loss: 2.798998968211358

Epoch: 5| Step: 9
Training loss: 3.3046880771645477
Validation loss: 2.79972830203505

Epoch: 5| Step: 10
Training loss: 3.1891010227895147
Validation loss: 2.7980151711980983

Epoch: 195| Step: 0
Training loss: 2.9461396773427233
Validation loss: 2.793155745655781

Epoch: 5| Step: 1
Training loss: 3.1383447672479825
Validation loss: 2.796915645811593

Epoch: 5| Step: 2
Training loss: 2.675042934607938
Validation loss: 2.801375212745899

Epoch: 5| Step: 3
Training loss: 3.331224601033274
Validation loss: 2.8074911565185428

Epoch: 5| Step: 4
Training loss: 3.3427867036601353
Validation loss: 2.8040800350522908

Epoch: 5| Step: 5
Training loss: 3.0762366684644524
Validation loss: 2.807248112100579

Epoch: 5| Step: 6
Training loss: 3.0491060353899253
Validation loss: 2.8047644167336414

Epoch: 5| Step: 7
Training loss: 3.4281623942614243
Validation loss: 2.8054450082119438

Epoch: 5| Step: 8
Training loss: 3.1782173675947893
Validation loss: 2.8019942186241535

Epoch: 5| Step: 9
Training loss: 3.285921096216634
Validation loss: 2.798063054168227

Epoch: 5| Step: 10
Training loss: 2.6611723226711432
Validation loss: 2.8015716252624077

Epoch: 196| Step: 0
Training loss: 2.8975015861763618
Validation loss: 2.8003931504185435

Epoch: 5| Step: 1
Training loss: 2.9033052025128168
Validation loss: 2.80378641989375

Epoch: 5| Step: 2
Training loss: 3.1860012944201506
Validation loss: 2.801593329778595

Epoch: 5| Step: 3
Training loss: 3.3760524097912383
Validation loss: 2.803636001713205

Epoch: 5| Step: 4
Training loss: 2.992391474770848
Validation loss: 2.8011881095908424

Epoch: 5| Step: 5
Training loss: 3.2194373128433678
Validation loss: 2.8000507740538594

Epoch: 5| Step: 6
Training loss: 3.495736522645034
Validation loss: 2.7977195477953853

Epoch: 5| Step: 7
Training loss: 2.546043400648512
Validation loss: 2.7945904898073266

Epoch: 5| Step: 8
Training loss: 3.1474348795655738
Validation loss: 2.7914164404530686

Epoch: 5| Step: 9
Training loss: 3.2133928178950684
Validation loss: 2.795175605875351

Epoch: 5| Step: 10
Training loss: 3.0581919672946767
Validation loss: 2.7894731284070713

Epoch: 197| Step: 0
Training loss: 3.414781158718444
Validation loss: 2.7921087741119863

Epoch: 5| Step: 1
Training loss: 3.106835636679199
Validation loss: 2.798855071771085

Epoch: 5| Step: 2
Training loss: 3.5923992769885165
Validation loss: 2.798132130787496

Epoch: 5| Step: 3
Training loss: 3.8285168505603333
Validation loss: 2.796187313926109

Epoch: 5| Step: 4
Training loss: 3.19349883821991
Validation loss: 2.7989238971113006

Epoch: 5| Step: 5
Training loss: 3.043406855296418
Validation loss: 2.798212555248422

Epoch: 5| Step: 6
Training loss: 3.041095592939411
Validation loss: 2.7936018724362683

Epoch: 5| Step: 7
Training loss: 2.573465564160168
Validation loss: 2.790124809626152

Epoch: 5| Step: 8
Training loss: 2.860849469349846
Validation loss: 2.7917070644530857

Epoch: 5| Step: 9
Training loss: 2.908352327330321
Validation loss: 2.792880208839105

Epoch: 5| Step: 10
Training loss: 2.0900202311216516
Validation loss: 2.7886129239658923

Epoch: 198| Step: 0
Training loss: 3.325986649826517
Validation loss: 2.7890374238338747

Epoch: 5| Step: 1
Training loss: 2.9402313520269767
Validation loss: 2.78942973278376

Epoch: 5| Step: 2
Training loss: 3.437025002693554
Validation loss: 2.7905683828857746

Epoch: 5| Step: 3
Training loss: 3.142097545457247
Validation loss: 2.791116327493995

Epoch: 5| Step: 4
Training loss: 2.693966382888129
Validation loss: 2.7899565187193764

Epoch: 5| Step: 5
Training loss: 2.907543427790007
Validation loss: 2.791628388418067

Epoch: 5| Step: 6
Training loss: 3.244788025455463
Validation loss: 2.787995796692487

Epoch: 5| Step: 7
Training loss: 3.1386424017556753
Validation loss: 2.7920356139972045

Epoch: 5| Step: 8
Training loss: 3.0765238823895995
Validation loss: 2.7930497169017166

Epoch: 5| Step: 9
Training loss: 3.2494381639050283
Validation loss: 2.7954282609090257

Epoch: 5| Step: 10
Training loss: 2.84162823678112
Validation loss: 2.795062386750246

Epoch: 199| Step: 0
Training loss: 2.9653178402658336
Validation loss: 2.7955457945879543

Epoch: 5| Step: 1
Training loss: 3.5390417506807577
Validation loss: 2.7883517371135587

Epoch: 5| Step: 2
Training loss: 2.769175432642668
Validation loss: 2.789487118016615

Epoch: 5| Step: 3
Training loss: 3.3211848291127097
Validation loss: 2.7871885649102817

Epoch: 5| Step: 4
Training loss: 3.245512284808783
Validation loss: 2.7915974478174803

Epoch: 5| Step: 5
Training loss: 2.5257615291298725
Validation loss: 2.7889831215476244

Epoch: 5| Step: 6
Training loss: 3.0955703466201543
Validation loss: 2.7904243851957915

Epoch: 5| Step: 7
Training loss: 3.156051780595001
Validation loss: 2.790126432273293

Epoch: 5| Step: 8
Training loss: 2.874967326102971
Validation loss: 2.786542266296161

Epoch: 5| Step: 9
Training loss: 3.3972297714813546
Validation loss: 2.7851352218830288

Epoch: 5| Step: 10
Training loss: 3.075912532470595
Validation loss: 2.792477310192333

Epoch: 200| Step: 0
Training loss: 3.1597814160811994
Validation loss: 2.7945224228311014

Epoch: 5| Step: 1
Training loss: 3.335202853140156
Validation loss: 2.795780411562908

Epoch: 5| Step: 2
Training loss: 2.9592634717797868
Validation loss: 2.808758009882053

Epoch: 5| Step: 3
Training loss: 3.2376540511901495
Validation loss: 2.8033819730367044

Epoch: 5| Step: 4
Training loss: 2.6034465760606373
Validation loss: 2.799206549536221

Epoch: 5| Step: 5
Training loss: 3.0076155957261683
Validation loss: 2.7988656336914537

Epoch: 5| Step: 6
Training loss: 4.119225824450787
Validation loss: 2.8017131504324184

Epoch: 5| Step: 7
Training loss: 2.3709933968286743
Validation loss: 2.7930967028981115

Epoch: 5| Step: 8
Training loss: 3.162827992675998
Validation loss: 2.788835036829288

Epoch: 5| Step: 9
Training loss: 2.5203326229798604
Validation loss: 2.793149127179689

Epoch: 5| Step: 10
Training loss: 3.2612918414483634
Validation loss: 2.791192572983175

Epoch: 201| Step: 0
Training loss: 2.6426640149105456
Validation loss: 2.7860174830685787

Epoch: 5| Step: 1
Training loss: 3.261312895782804
Validation loss: 2.784751432927758

Epoch: 5| Step: 2
Training loss: 3.1378680982128975
Validation loss: 2.786539728913478

Epoch: 5| Step: 3
Training loss: 3.0751963979138286
Validation loss: 2.7838134032062913

Epoch: 5| Step: 4
Training loss: 3.189165764668894
Validation loss: 2.7827051395017257

Epoch: 5| Step: 5
Training loss: 3.137013042701309
Validation loss: 2.787493471137708

Epoch: 5| Step: 6
Training loss: 2.982222494819251
Validation loss: 2.7880823275468365

Epoch: 5| Step: 7
Training loss: 3.557306083921797
Validation loss: 2.800648944997686

Epoch: 5| Step: 8
Training loss: 3.1609294685718066
Validation loss: 2.790876071510966

Epoch: 5| Step: 9
Training loss: 2.730555891793913
Validation loss: 2.7870852222458637

Epoch: 5| Step: 10
Training loss: 3.1238746142556395
Validation loss: 2.79410253004026

Epoch: 202| Step: 0
Training loss: 2.7918337776688227
Validation loss: 2.7820213467738

Epoch: 5| Step: 1
Training loss: 2.524401501268313
Validation loss: 2.7845069238681313

Epoch: 5| Step: 2
Training loss: 2.8633248818938553
Validation loss: 2.781546265032983

Epoch: 5| Step: 3
Training loss: 3.46454895210449
Validation loss: 2.7846475800085697

Epoch: 5| Step: 4
Training loss: 3.0374106499987903
Validation loss: 2.7831290546686693

Epoch: 5| Step: 5
Training loss: 2.8370772664436696
Validation loss: 2.785006130894634

Epoch: 5| Step: 6
Training loss: 3.800439237004723
Validation loss: 2.782778699687951

Epoch: 5| Step: 7
Training loss: 3.451064517775228
Validation loss: 2.7823129991217805

Epoch: 5| Step: 8
Training loss: 2.67408848143493
Validation loss: 2.7812281136817063

Epoch: 5| Step: 9
Training loss: 3.2121748941580344
Validation loss: 2.782232419134017

Epoch: 5| Step: 10
Training loss: 3.1523249931675554
Validation loss: 2.7784098066808958

Epoch: 203| Step: 0
Training loss: 3.7762969814233016
Validation loss: 2.7818501207436155

Epoch: 5| Step: 1
Training loss: 3.6020997281838585
Validation loss: 2.7842036886695642

Epoch: 5| Step: 2
Training loss: 2.9603754078734665
Validation loss: 2.7814947087239266

Epoch: 5| Step: 3
Training loss: 3.198513526180661
Validation loss: 2.780078506178648

Epoch: 5| Step: 4
Training loss: 3.0813289175702088
Validation loss: 2.7829338710602256

Epoch: 5| Step: 5
Training loss: 2.747559331334871
Validation loss: 2.7827930674981327

Epoch: 5| Step: 6
Training loss: 3.249037673501649
Validation loss: 2.7850189094581213

Epoch: 5| Step: 7
Training loss: 2.516384602417754
Validation loss: 2.781090777343346

Epoch: 5| Step: 8
Training loss: 2.6081454183957105
Validation loss: 2.781614070751377

Epoch: 5| Step: 9
Training loss: 3.1475236574576164
Validation loss: 2.781725841050025

Epoch: 5| Step: 10
Training loss: 2.8541846355977096
Validation loss: 2.782158861090384

Epoch: 204| Step: 0
Training loss: 2.8716352925179867
Validation loss: 2.7830063566358634

Epoch: 5| Step: 1
Training loss: 3.5202732129704817
Validation loss: 2.7885112521593456

Epoch: 5| Step: 2
Training loss: 3.26194636298824
Validation loss: 2.78759513224339

Epoch: 5| Step: 3
Training loss: 3.1990287081547337
Validation loss: 2.7934206829216404

Epoch: 5| Step: 4
Training loss: 2.9820998541975876
Validation loss: 2.782508087159718

Epoch: 5| Step: 5
Training loss: 3.042127617872138
Validation loss: 2.783988156904269

Epoch: 5| Step: 6
Training loss: 3.523052186049398
Validation loss: 2.77939751876172

Epoch: 5| Step: 7
Training loss: 3.1383172661573786
Validation loss: 2.7833478554998976

Epoch: 5| Step: 8
Training loss: 2.552408771136227
Validation loss: 2.7818487043061766

Epoch: 5| Step: 9
Training loss: 2.7531420357531067
Validation loss: 2.7839403698084038

Epoch: 5| Step: 10
Training loss: 3.099488609956409
Validation loss: 2.78037716059139

Epoch: 205| Step: 0
Training loss: 3.0988022366914647
Validation loss: 2.781140304896469

Epoch: 5| Step: 1
Training loss: 3.4003694501871577
Validation loss: 2.776858642307194

Epoch: 5| Step: 2
Training loss: 2.5021723845487327
Validation loss: 2.7768405065906943

Epoch: 5| Step: 3
Training loss: 3.075234852327974
Validation loss: 2.782330522370994

Epoch: 5| Step: 4
Training loss: 3.2813698882952886
Validation loss: 2.7810586050244566

Epoch: 5| Step: 5
Training loss: 3.0717189372750653
Validation loss: 2.780162366792603

Epoch: 5| Step: 6
Training loss: 3.4451537495756748
Validation loss: 2.785091218343174

Epoch: 5| Step: 7
Training loss: 3.0355970536363843
Validation loss: 2.786550388113232

Epoch: 5| Step: 8
Training loss: 2.965523502393719
Validation loss: 2.7919732594143722

Epoch: 5| Step: 9
Training loss: 2.6326284825342867
Validation loss: 2.777420812934694

Epoch: 5| Step: 10
Training loss: 3.4093476655390544
Validation loss: 2.7763221336002935

Epoch: 206| Step: 0
Training loss: 3.280336961417887
Validation loss: 2.777791234944332

Epoch: 5| Step: 1
Training loss: 3.025612376627428
Validation loss: 2.7802729561730524

Epoch: 5| Step: 2
Training loss: 2.873565149920461
Validation loss: 2.786676770031165

Epoch: 5| Step: 3
Training loss: 3.164525730461815
Validation loss: 2.7813337838141057

Epoch: 5| Step: 4
Training loss: 3.4148930078504534
Validation loss: 2.787865923188808

Epoch: 5| Step: 5
Training loss: 3.0273092550958136
Validation loss: 2.787774552198046

Epoch: 5| Step: 6
Training loss: 3.6987368824717493
Validation loss: 2.7898748381087928

Epoch: 5| Step: 7
Training loss: 2.7467937852399498
Validation loss: 2.786505169494493

Epoch: 5| Step: 8
Training loss: 2.8707647225901782
Validation loss: 2.7882712461353774

Epoch: 5| Step: 9
Training loss: 3.1614501718397965
Validation loss: 2.7830011307954896

Epoch: 5| Step: 10
Training loss: 2.554924630175075
Validation loss: 2.782580162784724

Epoch: 207| Step: 0
Training loss: 2.8466130191592898
Validation loss: 2.787816721108649

Epoch: 5| Step: 1
Training loss: 3.1979286284745916
Validation loss: 2.785921099792471

Epoch: 5| Step: 2
Training loss: 3.5147716249424357
Validation loss: 2.7828999190800463

Epoch: 5| Step: 3
Training loss: 2.9513801385089082
Validation loss: 2.7803280039447005

Epoch: 5| Step: 4
Training loss: 3.3522587121984997
Validation loss: 2.7823968218728945

Epoch: 5| Step: 5
Training loss: 2.347788878390192
Validation loss: 2.7846843922276876

Epoch: 5| Step: 6
Training loss: 3.1827521773976515
Validation loss: 2.788780990755432

Epoch: 5| Step: 7
Training loss: 2.9153738880676285
Validation loss: 2.796772508409821

Epoch: 5| Step: 8
Training loss: 2.9391033585510553
Validation loss: 2.792410622984156

Epoch: 5| Step: 9
Training loss: 3.209861853648352
Validation loss: 2.7853926993023896

Epoch: 5| Step: 10
Training loss: 3.405189419041652
Validation loss: 2.784032492805101

Epoch: 208| Step: 0
Training loss: 3.141068005039094
Validation loss: 2.7865106988095296

Epoch: 5| Step: 1
Training loss: 2.5486013728159866
Validation loss: 2.781564735043139

Epoch: 5| Step: 2
Training loss: 3.253712807500288
Validation loss: 2.7771681581853933

Epoch: 5| Step: 3
Training loss: 3.5616439326168727
Validation loss: 2.7767115516207395

Epoch: 5| Step: 4
Training loss: 3.200622176243781
Validation loss: 2.775065366837424

Epoch: 5| Step: 5
Training loss: 3.2091118664760843
Validation loss: 2.7765090038936506

Epoch: 5| Step: 6
Training loss: 2.452255775353857
Validation loss: 2.7780731887698775

Epoch: 5| Step: 7
Training loss: 3.1899031013911143
Validation loss: 2.7747385312948976

Epoch: 5| Step: 8
Training loss: 2.640540939889157
Validation loss: 2.778749875810833

Epoch: 5| Step: 9
Training loss: 3.3759327765095133
Validation loss: 2.7781859024920563

Epoch: 5| Step: 10
Training loss: 3.22248830646675
Validation loss: 2.775043610039185

Epoch: 209| Step: 0
Training loss: 2.7257441738206
Validation loss: 2.768876409768786

Epoch: 5| Step: 1
Training loss: 2.8952813663033643
Validation loss: 2.771341374579728

Epoch: 5| Step: 2
Training loss: 3.041401803664792
Validation loss: 2.776060314901181

Epoch: 5| Step: 3
Training loss: 3.3969932556624416
Validation loss: 2.770759089922683

Epoch: 5| Step: 4
Training loss: 3.008006537978189
Validation loss: 2.7687796649803387

Epoch: 5| Step: 5
Training loss: 3.4816700652820973
Validation loss: 2.7710108015905974

Epoch: 5| Step: 6
Training loss: 3.208631889686884
Validation loss: 2.7680230654009716

Epoch: 5| Step: 7
Training loss: 2.962142497836698
Validation loss: 2.768500348303875

Epoch: 5| Step: 8
Training loss: 2.9083100267877326
Validation loss: 2.771026618156595

Epoch: 5| Step: 9
Training loss: 3.0168130540543596
Validation loss: 2.7696666853636036

Epoch: 5| Step: 10
Training loss: 3.2470001167224503
Validation loss: 2.7727292621804636

Epoch: 210| Step: 0
Training loss: 3.223687394219454
Validation loss: 2.7724651068813526

Epoch: 5| Step: 1
Training loss: 2.8903993260724645
Validation loss: 2.777629664447673

Epoch: 5| Step: 2
Training loss: 3.195624972783071
Validation loss: 2.7749465508945756

Epoch: 5| Step: 3
Training loss: 2.987500855513574
Validation loss: 2.7796958516075394

Epoch: 5| Step: 4
Training loss: 2.6813923831294604
Validation loss: 2.7711970059551922

Epoch: 5| Step: 5
Training loss: 3.011823402496353
Validation loss: 2.7690926983641493

Epoch: 5| Step: 6
Training loss: 2.780809431864038
Validation loss: 2.774531955080092

Epoch: 5| Step: 7
Training loss: 3.370814942890135
Validation loss: 2.7722761135935183

Epoch: 5| Step: 8
Training loss: 2.974721264002855
Validation loss: 2.775002357476735

Epoch: 5| Step: 9
Training loss: 3.499117467512721
Validation loss: 2.768310716692504

Epoch: 5| Step: 10
Training loss: 3.2565978642370057
Validation loss: 2.769678775699625

Epoch: 211| Step: 0
Training loss: 3.493832194499374
Validation loss: 2.770753775290319

Epoch: 5| Step: 1
Training loss: 3.5092196966032665
Validation loss: 2.767853319518831

Epoch: 5| Step: 2
Training loss: 2.8446563282503026
Validation loss: 2.76709976396743

Epoch: 5| Step: 3
Training loss: 2.950828345430201
Validation loss: 2.7695764995291636

Epoch: 5| Step: 4
Training loss: 2.811550827926452
Validation loss: 2.7657947343359335

Epoch: 5| Step: 5
Training loss: 3.242552219696845
Validation loss: 2.7651910512670694

Epoch: 5| Step: 6
Training loss: 3.5168332884548534
Validation loss: 2.769122115670602

Epoch: 5| Step: 7
Training loss: 2.6377720516245877
Validation loss: 2.7694391472813877

Epoch: 5| Step: 8
Training loss: 2.800513601882014
Validation loss: 2.769266428606984

Epoch: 5| Step: 9
Training loss: 2.6903588813561554
Validation loss: 2.7699495578155093

Epoch: 5| Step: 10
Training loss: 3.29326413821941
Validation loss: 2.7686121128019225

Epoch: 212| Step: 0
Training loss: 3.1118517648749235
Validation loss: 2.770074449146349

Epoch: 5| Step: 1
Training loss: 2.9950046275617357
Validation loss: 2.770006207321863

Epoch: 5| Step: 2
Training loss: 3.184342559559366
Validation loss: 2.7733155859970173

Epoch: 5| Step: 3
Training loss: 3.3261809066139127
Validation loss: 2.769700891196084

Epoch: 5| Step: 4
Training loss: 2.69741341353808
Validation loss: 2.771355909916312

Epoch: 5| Step: 5
Training loss: 2.9404034165216326
Validation loss: 2.772712646305076

Epoch: 5| Step: 6
Training loss: 3.0658003481802827
Validation loss: 2.7695558909243907

Epoch: 5| Step: 7
Training loss: 3.004697777248983
Validation loss: 2.7685400605993165

Epoch: 5| Step: 8
Training loss: 3.230826379983179
Validation loss: 2.766907741336669

Epoch: 5| Step: 9
Training loss: 3.17435257085277
Validation loss: 2.773695187091983

Epoch: 5| Step: 10
Training loss: 3.1528043162330133
Validation loss: 2.7802853387894255

Epoch: 213| Step: 0
Training loss: 3.2928517457712707
Validation loss: 2.7743880490975688

Epoch: 5| Step: 1
Training loss: 3.599561155910081
Validation loss: 2.769610472290539

Epoch: 5| Step: 2
Training loss: 3.377690549680633
Validation loss: 2.770914947346526

Epoch: 5| Step: 3
Training loss: 3.3796689269763154
Validation loss: 2.780165703017266

Epoch: 5| Step: 4
Training loss: 2.6647850689987624
Validation loss: 2.773376423499621

Epoch: 5| Step: 5
Training loss: 2.7625613727915517
Validation loss: 2.767674853432975

Epoch: 5| Step: 6
Training loss: 3.063797189449493
Validation loss: 2.775924258716133

Epoch: 5| Step: 7
Training loss: 3.288635951130405
Validation loss: 2.7715144375432086

Epoch: 5| Step: 8
Training loss: 2.857593085373974
Validation loss: 2.7717867560291447

Epoch: 5| Step: 9
Training loss: 2.950375038488635
Validation loss: 2.7662037667394666

Epoch: 5| Step: 10
Training loss: 2.2877394462294496
Validation loss: 2.7690502804188393

Epoch: 214| Step: 0
Training loss: 2.8906096586902863
Validation loss: 2.7686243040432084

Epoch: 5| Step: 1
Training loss: 3.3451506631218235
Validation loss: 2.7673232533575294

Epoch: 5| Step: 2
Training loss: 2.891423790339174
Validation loss: 2.76587525654832

Epoch: 5| Step: 3
Training loss: 3.4739805084542597
Validation loss: 2.7701999937565573

Epoch: 5| Step: 4
Training loss: 3.329009175941974
Validation loss: 2.7675213164852064

Epoch: 5| Step: 5
Training loss: 3.2082670295766915
Validation loss: 2.7699620550688664

Epoch: 5| Step: 6
Training loss: 2.781825059739448
Validation loss: 2.7671307264906524

Epoch: 5| Step: 7
Training loss: 2.6734918531982537
Validation loss: 2.7720384585398077

Epoch: 5| Step: 8
Training loss: 2.9884341132266377
Validation loss: 2.7660132955285093

Epoch: 5| Step: 9
Training loss: 2.9783596911026313
Validation loss: 2.7686217497761145

Epoch: 5| Step: 10
Training loss: 3.244020830729593
Validation loss: 2.7711003102663705

Epoch: 215| Step: 0
Training loss: 3.3928788951664077
Validation loss: 2.7706574522887886

Epoch: 5| Step: 1
Training loss: 2.8200756195426684
Validation loss: 2.7699926820324197

Epoch: 5| Step: 2
Training loss: 3.6385113388415347
Validation loss: 2.767510258850629

Epoch: 5| Step: 3
Training loss: 3.1626989369903735
Validation loss: 2.763657329861227

Epoch: 5| Step: 4
Training loss: 3.059324993157367
Validation loss: 2.767719295043004

Epoch: 5| Step: 5
Training loss: 2.4998571355053496
Validation loss: 2.763386038789903

Epoch: 5| Step: 6
Training loss: 3.633186042203281
Validation loss: 2.7669882478365726

Epoch: 5| Step: 7
Training loss: 2.50706475539507
Validation loss: 2.765947901843129

Epoch: 5| Step: 8
Training loss: 2.902004627731493
Validation loss: 2.767269177169245

Epoch: 5| Step: 9
Training loss: 2.7577964198694622
Validation loss: 2.771543479500279

Epoch: 5| Step: 10
Training loss: 3.2179942308543703
Validation loss: 2.764565178268545

Epoch: 216| Step: 0
Training loss: 3.0544909635963724
Validation loss: 2.7696219575110668

Epoch: 5| Step: 1
Training loss: 2.6599847007254125
Validation loss: 2.772144025823355

Epoch: 5| Step: 2
Training loss: 3.4455303374125545
Validation loss: 2.7747585054822994

Epoch: 5| Step: 3
Training loss: 2.845020722915452
Validation loss: 2.7739259563844207

Epoch: 5| Step: 4
Training loss: 2.7435298579367386
Validation loss: 2.784447655364529

Epoch: 5| Step: 5
Training loss: 3.284987147057877
Validation loss: 2.7872978288331414

Epoch: 5| Step: 6
Training loss: 3.279410000747532
Validation loss: 2.778598601435566

Epoch: 5| Step: 7
Training loss: 2.926455899978929
Validation loss: 2.7699234663896446

Epoch: 5| Step: 8
Training loss: 3.071119673140877
Validation loss: 2.7665262201715026

Epoch: 5| Step: 9
Training loss: 2.8382206073207756
Validation loss: 2.7700092670230427

Epoch: 5| Step: 10
Training loss: 3.6247766360164513
Validation loss: 2.7707252894643064

Epoch: 217| Step: 0
Training loss: 2.8471969003766073
Validation loss: 2.7630521601194347

Epoch: 5| Step: 1
Training loss: 3.7349333405578533
Validation loss: 2.765608190345558

Epoch: 5| Step: 2
Training loss: 2.67117835884616
Validation loss: 2.761767144381174

Epoch: 5| Step: 3
Training loss: 2.3009522249848207
Validation loss: 2.7636257727691946

Epoch: 5| Step: 4
Training loss: 3.383505100594215
Validation loss: 2.7611392084172457

Epoch: 5| Step: 5
Training loss: 3.0813352623337447
Validation loss: 2.76304450366179

Epoch: 5| Step: 6
Training loss: 3.2666228745567856
Validation loss: 2.7629554860421632

Epoch: 5| Step: 7
Training loss: 2.8150842450072497
Validation loss: 2.761425942843072

Epoch: 5| Step: 8
Training loss: 3.0851538327039307
Validation loss: 2.7613922472428687

Epoch: 5| Step: 9
Training loss: 3.296360210707093
Validation loss: 2.7625008353615947

Epoch: 5| Step: 10
Training loss: 3.098967035532468
Validation loss: 2.7610947286760092

Epoch: 218| Step: 0
Training loss: 3.23527167970353
Validation loss: 2.76614956486553

Epoch: 5| Step: 1
Training loss: 3.392432930605949
Validation loss: 2.7622737557459787

Epoch: 5| Step: 2
Training loss: 3.4637094251499443
Validation loss: 2.766362803684283

Epoch: 5| Step: 3
Training loss: 2.559631789370448
Validation loss: 2.7679645757352036

Epoch: 5| Step: 4
Training loss: 3.0352468980289937
Validation loss: 2.7651134629920264

Epoch: 5| Step: 5
Training loss: 3.243400034465273
Validation loss: 2.7679765438409247

Epoch: 5| Step: 6
Training loss: 3.3104463365080266
Validation loss: 2.773663673959461

Epoch: 5| Step: 7
Training loss: 3.1703534164533274
Validation loss: 2.7715156381881627

Epoch: 5| Step: 8
Training loss: 2.891475078234595
Validation loss: 2.7727592465058044

Epoch: 5| Step: 9
Training loss: 2.898269360541715
Validation loss: 2.774238426640107

Epoch: 5| Step: 10
Training loss: 2.308001705360774
Validation loss: 2.7708462626873915

Epoch: 219| Step: 0
Training loss: 3.2755774010830274
Validation loss: 2.7759081505137706

Epoch: 5| Step: 1
Training loss: 2.8205970345887343
Validation loss: 2.7695482695709877

Epoch: 5| Step: 2
Training loss: 3.007819158373312
Validation loss: 2.7586628805654247

Epoch: 5| Step: 3
Training loss: 3.324073869033598
Validation loss: 2.7571226266490516

Epoch: 5| Step: 4
Training loss: 2.9616556630299584
Validation loss: 2.759032523313025

Epoch: 5| Step: 5
Training loss: 2.4982820330088993
Validation loss: 2.760708428765877

Epoch: 5| Step: 6
Training loss: 3.3403802451959144
Validation loss: 2.7624219530088943

Epoch: 5| Step: 7
Training loss: 2.933917031590088
Validation loss: 2.761831579792666

Epoch: 5| Step: 8
Training loss: 3.1498577994084336
Validation loss: 2.754508531733025

Epoch: 5| Step: 9
Training loss: 3.090009489569552
Validation loss: 2.7560401856549843

Epoch: 5| Step: 10
Training loss: 3.343406873549004
Validation loss: 2.7538882740568322

Epoch: 220| Step: 0
Training loss: 2.6110880819166367
Validation loss: 2.7549465639814548

Epoch: 5| Step: 1
Training loss: 3.036674443837608
Validation loss: 2.7529361726537758

Epoch: 5| Step: 2
Training loss: 3.2607920535177
Validation loss: 2.7537933617381345

Epoch: 5| Step: 3
Training loss: 3.2946231618448345
Validation loss: 2.75816261513674

Epoch: 5| Step: 4
Training loss: 2.775611219021885
Validation loss: 2.7535882921477004

Epoch: 5| Step: 5
Training loss: 3.2219790955237726
Validation loss: 2.7563855658336034

Epoch: 5| Step: 6
Training loss: 2.937006807521351
Validation loss: 2.762054621122795

Epoch: 5| Step: 7
Training loss: 3.1105798275246563
Validation loss: 2.7603976124628073

Epoch: 5| Step: 8
Training loss: 3.3511848859426583
Validation loss: 2.7619962259735082

Epoch: 5| Step: 9
Training loss: 2.903654847180983
Validation loss: 2.763093249660431

Epoch: 5| Step: 10
Training loss: 3.1937555003258806
Validation loss: 2.7633944281234055

Epoch: 221| Step: 0
Training loss: 3.3607234643718447
Validation loss: 2.7566651447116013

Epoch: 5| Step: 1
Training loss: 3.7065519418960844
Validation loss: 2.762994606271144

Epoch: 5| Step: 2
Training loss: 2.2997283858096234
Validation loss: 2.7612578070354115

Epoch: 5| Step: 3
Training loss: 3.2502257928908493
Validation loss: 2.7529597217166835

Epoch: 5| Step: 4
Training loss: 3.0325692049260833
Validation loss: 2.756195253244198

Epoch: 5| Step: 5
Training loss: 2.556109391428165
Validation loss: 2.7597477132328914

Epoch: 5| Step: 6
Training loss: 3.2809546928126063
Validation loss: 2.756508768030902

Epoch: 5| Step: 7
Training loss: 3.416502056963645
Validation loss: 2.758760822052503

Epoch: 5| Step: 8
Training loss: 3.2405907801087714
Validation loss: 2.757002027611492

Epoch: 5| Step: 9
Training loss: 2.7921174572664595
Validation loss: 2.7503186784233624

Epoch: 5| Step: 10
Training loss: 2.439009663549019
Validation loss: 2.75748223241504

Epoch: 222| Step: 0
Training loss: 3.754432982645875
Validation loss: 2.7536933462300244

Epoch: 5| Step: 1
Training loss: 2.726124550697926
Validation loss: 2.754945082530946

Epoch: 5| Step: 2
Training loss: 2.5066997400428632
Validation loss: 2.753365206510744

Epoch: 5| Step: 3
Training loss: 3.3221327156872658
Validation loss: 2.75799407960794

Epoch: 5| Step: 4
Training loss: 3.0621828187450664
Validation loss: 2.7576606636879193

Epoch: 5| Step: 5
Training loss: 3.4643323105837145
Validation loss: 2.755340622000809

Epoch: 5| Step: 6
Training loss: 3.257396351240467
Validation loss: 2.7484984488901265

Epoch: 5| Step: 7
Training loss: 3.0390684622973327
Validation loss: 2.7498893603668417

Epoch: 5| Step: 8
Training loss: 2.227219227093433
Validation loss: 2.7480524443806478

Epoch: 5| Step: 9
Training loss: 3.1877553500948133
Validation loss: 2.749277882373857

Epoch: 5| Step: 10
Training loss: 2.9244428968119496
Validation loss: 2.750084945619676

Epoch: 223| Step: 0
Training loss: 2.891965812871477
Validation loss: 2.748711260720178

Epoch: 5| Step: 1
Training loss: 3.573021593397494
Validation loss: 2.749240947611943

Epoch: 5| Step: 2
Training loss: 3.3021184075034093
Validation loss: 2.7531298551039063

Epoch: 5| Step: 3
Training loss: 3.516089379052298
Validation loss: 2.7538011202545345

Epoch: 5| Step: 4
Training loss: 2.9065922361287666
Validation loss: 2.755960279327229

Epoch: 5| Step: 5
Training loss: 2.7159833313903787
Validation loss: 2.7635736567215

Epoch: 5| Step: 6
Training loss: 3.537758155272595
Validation loss: 2.760379244147693

Epoch: 5| Step: 7
Training loss: 2.8925613104043695
Validation loss: 2.7702493254924807

Epoch: 5| Step: 8
Training loss: 2.6413532584605615
Validation loss: 2.7674593275768147

Epoch: 5| Step: 9
Training loss: 3.234458295698643
Validation loss: 2.7711413484685177

Epoch: 5| Step: 10
Training loss: 2.0574109264203417
Validation loss: 2.7684277949896208

Epoch: 224| Step: 0
Training loss: 3.18188550555852
Validation loss: 2.7598299631607293

Epoch: 5| Step: 1
Training loss: 2.814398908655455
Validation loss: 2.756681915901484

Epoch: 5| Step: 2
Training loss: 3.103551884818073
Validation loss: 2.748985533169838

Epoch: 5| Step: 3
Training loss: 2.935363317094619
Validation loss: 2.7505785649491155

Epoch: 5| Step: 4
Training loss: 3.3369593607457304
Validation loss: 2.746385873091616

Epoch: 5| Step: 5
Training loss: 3.4974857563985786
Validation loss: 2.7464213499332515

Epoch: 5| Step: 6
Training loss: 3.614591981435905
Validation loss: 2.747387944132264

Epoch: 5| Step: 7
Training loss: 3.0016686249478943
Validation loss: 2.745792276036059

Epoch: 5| Step: 8
Training loss: 2.900043053143006
Validation loss: 2.743569652281106

Epoch: 5| Step: 9
Training loss: 2.9244911598962857
Validation loss: 2.747966029084479

Epoch: 5| Step: 10
Training loss: 2.02782926827933
Validation loss: 2.7451129457631387

Epoch: 225| Step: 0
Training loss: 3.338180038378387
Validation loss: 2.7496117600269447

Epoch: 5| Step: 1
Training loss: 2.790197232429226
Validation loss: 2.748187825368991

Epoch: 5| Step: 2
Training loss: 2.7024461191401152
Validation loss: 2.7478741962101707

Epoch: 5| Step: 3
Training loss: 3.2181126231987003
Validation loss: 2.7531346012894273

Epoch: 5| Step: 4
Training loss: 2.983915123783246
Validation loss: 2.7476789891455518

Epoch: 5| Step: 5
Training loss: 3.2068990663894112
Validation loss: 2.750403742829991

Epoch: 5| Step: 6
Training loss: 2.7853594648317186
Validation loss: 2.749235997948744

Epoch: 5| Step: 7
Training loss: 3.157307664777615
Validation loss: 2.7473437288529374

Epoch: 5| Step: 8
Training loss: 3.2067001116059988
Validation loss: 2.7472638831241403

Epoch: 5| Step: 9
Training loss: 3.151034587925718
Validation loss: 2.750757642547869

Epoch: 5| Step: 10
Training loss: 3.1250169372099603
Validation loss: 2.7441631854703545

Epoch: 226| Step: 0
Training loss: 2.889983894804856
Validation loss: 2.749656225066975

Epoch: 5| Step: 1
Training loss: 3.201688118551162
Validation loss: 2.748488515167181

Epoch: 5| Step: 2
Training loss: 3.0393620125243834
Validation loss: 2.7490207125462773

Epoch: 5| Step: 3
Training loss: 2.9487267090062343
Validation loss: 2.7513710344390496

Epoch: 5| Step: 4
Training loss: 3.283287796117823
Validation loss: 2.751834759795874

Epoch: 5| Step: 5
Training loss: 2.934338268176067
Validation loss: 2.7524161054192064

Epoch: 5| Step: 6
Training loss: 2.706943615132046
Validation loss: 2.7501376398195747

Epoch: 5| Step: 7
Training loss: 3.416086535320333
Validation loss: 2.7469581633692983

Epoch: 5| Step: 8
Training loss: 2.526575835599131
Validation loss: 2.746412841544475

Epoch: 5| Step: 9
Training loss: 3.288407285399789
Validation loss: 2.7443769714968806

Epoch: 5| Step: 10
Training loss: 3.3431383090379216
Validation loss: 2.7437359661537872

Epoch: 227| Step: 0
Training loss: 3.6202993498897986
Validation loss: 2.749160844591992

Epoch: 5| Step: 1
Training loss: 2.897531866601082
Validation loss: 2.7453420928948167

Epoch: 5| Step: 2
Training loss: 3.0688064414620047
Validation loss: 2.747375188362218

Epoch: 5| Step: 3
Training loss: 3.290334858651269
Validation loss: 2.744419071132307

Epoch: 5| Step: 4
Training loss: 1.9204655883455155
Validation loss: 2.7566015575955496

Epoch: 5| Step: 5
Training loss: 2.8758941586772733
Validation loss: 2.7523657466292875

Epoch: 5| Step: 6
Training loss: 3.1710567828399285
Validation loss: 2.7564546656938047

Epoch: 5| Step: 7
Training loss: 2.754104152629801
Validation loss: 2.7477575949925064

Epoch: 5| Step: 8
Training loss: 3.65769851552598
Validation loss: 2.7535283022717367

Epoch: 5| Step: 9
Training loss: 2.630386819857969
Validation loss: 2.751273002269125

Epoch: 5| Step: 10
Training loss: 3.4629572707560268
Validation loss: 2.747511144839752

Epoch: 228| Step: 0
Training loss: 2.9879565093668408
Validation loss: 2.743492546768901

Epoch: 5| Step: 1
Training loss: 3.507037716538995
Validation loss: 2.7451764020972242

Epoch: 5| Step: 2
Training loss: 3.330479321965246
Validation loss: 2.7434088660166376

Epoch: 5| Step: 3
Training loss: 2.951448802464535
Validation loss: 2.742214788336112

Epoch: 5| Step: 4
Training loss: 3.2232453888576327
Validation loss: 2.7475356044226036

Epoch: 5| Step: 5
Training loss: 2.682230729580612
Validation loss: 2.748166286764518

Epoch: 5| Step: 6
Training loss: 2.6508828186129954
Validation loss: 2.746458720256845

Epoch: 5| Step: 7
Training loss: 3.244669871649313
Validation loss: 2.748219559730973

Epoch: 5| Step: 8
Training loss: 2.752304671976788
Validation loss: 2.74089120200707

Epoch: 5| Step: 9
Training loss: 3.3176865190220997
Validation loss: 2.744301686008701

Epoch: 5| Step: 10
Training loss: 2.8639010269922434
Validation loss: 2.743052395729276

Epoch: 229| Step: 0
Training loss: 2.8947192091153817
Validation loss: 2.7476357423752025

Epoch: 5| Step: 1
Training loss: 3.298054850115831
Validation loss: 2.7506940139333156

Epoch: 5| Step: 2
Training loss: 3.2045301379213447
Validation loss: 2.7551275890041254

Epoch: 5| Step: 3
Training loss: 2.5941801518785064
Validation loss: 2.753892073125341

Epoch: 5| Step: 4
Training loss: 2.9789483228223994
Validation loss: 2.7532739699336224

Epoch: 5| Step: 5
Training loss: 3.266879776082143
Validation loss: 2.758791255559838

Epoch: 5| Step: 6
Training loss: 3.267703914102264
Validation loss: 2.7582670432896563

Epoch: 5| Step: 7
Training loss: 2.693503571675951
Validation loss: 2.762201834275595

Epoch: 5| Step: 8
Training loss: 2.7206787634071734
Validation loss: 2.753904042809983

Epoch: 5| Step: 9
Training loss: 3.410986870178165
Validation loss: 2.7513661482411282

Epoch: 5| Step: 10
Training loss: 3.166297255267708
Validation loss: 2.7503386407386508

Epoch: 230| Step: 0
Training loss: 2.639743093359274
Validation loss: 2.7439220603154397

Epoch: 5| Step: 1
Training loss: 2.957284248847074
Validation loss: 2.7526073726853824

Epoch: 5| Step: 2
Training loss: 3.7520678858604066
Validation loss: 2.7456878962942732

Epoch: 5| Step: 3
Training loss: 3.135863229036487
Validation loss: 2.7454422370854425

Epoch: 5| Step: 4
Training loss: 2.581261686063088
Validation loss: 2.7486080271311355

Epoch: 5| Step: 5
Training loss: 3.0365079916050037
Validation loss: 2.7368757980998173

Epoch: 5| Step: 6
Training loss: 3.6001064973549552
Validation loss: 2.7420889992720547

Epoch: 5| Step: 7
Training loss: 2.908960206715267
Validation loss: 2.742918941788735

Epoch: 5| Step: 8
Training loss: 2.8776760086596664
Validation loss: 2.7433634736306733

Epoch: 5| Step: 9
Training loss: 3.1835925517635784
Validation loss: 2.741831963947733

Epoch: 5| Step: 10
Training loss: 2.65372966799896
Validation loss: 2.745952825647448

Epoch: 231| Step: 0
Training loss: 3.333855794651846
Validation loss: 2.7378943848792265

Epoch: 5| Step: 1
Training loss: 3.617596267442157
Validation loss: 2.7453044935247157

Epoch: 5| Step: 2
Training loss: 3.1229647302947625
Validation loss: 2.74639847010188

Epoch: 5| Step: 3
Training loss: 2.9538841281033252
Validation loss: 2.7500997061007846

Epoch: 5| Step: 4
Training loss: 3.0932354740032055
Validation loss: 2.761535317255547

Epoch: 5| Step: 5
Training loss: 2.561887900586858
Validation loss: 2.7540217996520413

Epoch: 5| Step: 6
Training loss: 2.8691259997925407
Validation loss: 2.7544745942204223

Epoch: 5| Step: 7
Training loss: 2.7289044397382525
Validation loss: 2.7491094409485144

Epoch: 5| Step: 8
Training loss: 3.1624806158504564
Validation loss: 2.7389184915598443

Epoch: 5| Step: 9
Training loss: 3.0014298528366483
Validation loss: 2.7428982319665143

Epoch: 5| Step: 10
Training loss: 3.065674829418313
Validation loss: 2.741658036263637

Epoch: 232| Step: 0
Training loss: 2.7065829171376423
Validation loss: 2.7373674510542294

Epoch: 5| Step: 1
Training loss: 3.4891080314374765
Validation loss: 2.7423368276067457

Epoch: 5| Step: 2
Training loss: 3.1302709758327816
Validation loss: 2.739289607264793

Epoch: 5| Step: 3
Training loss: 3.106509321045595
Validation loss: 2.742533547856598

Epoch: 5| Step: 4
Training loss: 2.634458847793097
Validation loss: 2.743943390253732

Epoch: 5| Step: 5
Training loss: 3.0438709023528627
Validation loss: 2.745534159707885

Epoch: 5| Step: 6
Training loss: 3.3561307633742015
Validation loss: 2.7427913455626625

Epoch: 5| Step: 7
Training loss: 3.478869960414883
Validation loss: 2.7479292324902453

Epoch: 5| Step: 8
Training loss: 2.641363097196307
Validation loss: 2.7473577281644324

Epoch: 5| Step: 9
Training loss: 2.9373949722019486
Validation loss: 2.7466755215756673

Epoch: 5| Step: 10
Training loss: 2.941764657727167
Validation loss: 2.7565950978049902

Epoch: 233| Step: 0
Training loss: 2.95028760122325
Validation loss: 2.7611437514273454

Epoch: 5| Step: 1
Training loss: 2.986772463008954
Validation loss: 2.754626374414011

Epoch: 5| Step: 2
Training loss: 3.4686129431238855
Validation loss: 2.76173728949064

Epoch: 5| Step: 3
Training loss: 3.4172736458370183
Validation loss: 2.762813259736761

Epoch: 5| Step: 4
Training loss: 3.691142465360144
Validation loss: 2.7553618114417335

Epoch: 5| Step: 5
Training loss: 2.5660519057723046
Validation loss: 2.75617497803182

Epoch: 5| Step: 6
Training loss: 2.1906441027887227
Validation loss: 2.7580314306939577

Epoch: 5| Step: 7
Training loss: 3.2142526261579354
Validation loss: 2.7557256202812077

Epoch: 5| Step: 8
Training loss: 3.1177199441982695
Validation loss: 2.74852962002672

Epoch: 5| Step: 9
Training loss: 2.7850331497274077
Validation loss: 2.746363926432044

Epoch: 5| Step: 10
Training loss: 2.9530226270904865
Validation loss: 2.7442326014982124

Epoch: 234| Step: 0
Training loss: 3.041958642471545
Validation loss: 2.7396981670546494

Epoch: 5| Step: 1
Training loss: 2.5271782798782865
Validation loss: 2.7409387659840627

Epoch: 5| Step: 2
Training loss: 3.311789526411444
Validation loss: 2.739557059692429

Epoch: 5| Step: 3
Training loss: 2.719468295917421
Validation loss: 2.737914008933457

Epoch: 5| Step: 4
Training loss: 2.719993394675369
Validation loss: 2.739837922562464

Epoch: 5| Step: 5
Training loss: 3.1375045837125692
Validation loss: 2.7445631510983817

Epoch: 5| Step: 6
Training loss: 3.634896941685192
Validation loss: 2.739074995501674

Epoch: 5| Step: 7
Training loss: 3.222572501279215
Validation loss: 2.7421213137420946

Epoch: 5| Step: 8
Training loss: 3.0435224820117135
Validation loss: 2.7424310324169965

Epoch: 5| Step: 9
Training loss: 2.983523901566036
Validation loss: 2.7550142241038316

Epoch: 5| Step: 10
Training loss: 3.149588324878497
Validation loss: 2.763391186687604

Epoch: 235| Step: 0
Training loss: 2.5911958366949466
Validation loss: 2.762144085435714

Epoch: 5| Step: 1
Training loss: 3.3712511788360153
Validation loss: 2.7743806577058825

Epoch: 5| Step: 2
Training loss: 2.949214707933902
Validation loss: 2.774516871821307

Epoch: 5| Step: 3
Training loss: 3.1751969704392238
Validation loss: 2.779344444002433

Epoch: 5| Step: 4
Training loss: 2.9923549834307415
Validation loss: 2.7747606175508817

Epoch: 5| Step: 5
Training loss: 2.6789518631116507
Validation loss: 2.763719472689403

Epoch: 5| Step: 6
Training loss: 3.1087244014506665
Validation loss: 2.7466305415929595

Epoch: 5| Step: 7
Training loss: 3.137915965922589
Validation loss: 2.742008447973192

Epoch: 5| Step: 8
Training loss: 2.9597402280795526
Validation loss: 2.7390667647341127

Epoch: 5| Step: 9
Training loss: 3.448030053125033
Validation loss: 2.7361012962105167

Epoch: 5| Step: 10
Training loss: 3.0910298112254235
Validation loss: 2.7382302272684917

Epoch: 236| Step: 0
Training loss: 3.0996964459848284
Validation loss: 2.73071837929776

Epoch: 5| Step: 1
Training loss: 3.1891554479216437
Validation loss: 2.7368619039442637

Epoch: 5| Step: 2
Training loss: 2.9179573109924712
Validation loss: 2.7355495891592225

Epoch: 5| Step: 3
Training loss: 3.0850697516619667
Validation loss: 2.7396877934396895

Epoch: 5| Step: 4
Training loss: 2.559012388967836
Validation loss: 2.7442111785195284

Epoch: 5| Step: 5
Training loss: 3.103431119542549
Validation loss: 2.743006123584195

Epoch: 5| Step: 6
Training loss: 3.064967348755609
Validation loss: 2.7427307849085976

Epoch: 5| Step: 7
Training loss: 2.9169596570311134
Validation loss: 2.743287905206264

Epoch: 5| Step: 8
Training loss: 3.2479922622062327
Validation loss: 2.737887895932554

Epoch: 5| Step: 9
Training loss: 3.287556137940069
Validation loss: 2.7400211597462727

Epoch: 5| Step: 10
Training loss: 3.2141622792112554
Validation loss: 2.7385451088024735

Epoch: 237| Step: 0
Training loss: 2.503545059600086
Validation loss: 2.7342102404294173

Epoch: 5| Step: 1
Training loss: 3.6011998455311547
Validation loss: 2.7338496290332377

Epoch: 5| Step: 2
Training loss: 3.114616079168936
Validation loss: 2.7350113791798027

Epoch: 5| Step: 3
Training loss: 2.9418272246579624
Validation loss: 2.7438038457263874

Epoch: 5| Step: 4
Training loss: 3.1342879552345098
Validation loss: 2.735307804038867

Epoch: 5| Step: 5
Training loss: 3.1404336899521264
Validation loss: 2.742931501446792

Epoch: 5| Step: 6
Training loss: 2.946247792168277
Validation loss: 2.7460097536081816

Epoch: 5| Step: 7
Training loss: 2.5535541785359688
Validation loss: 2.7521246293904476

Epoch: 5| Step: 8
Training loss: 3.632950712466579
Validation loss: 2.7629959015474648

Epoch: 5| Step: 9
Training loss: 2.309851392614498
Validation loss: 2.7570621018373296

Epoch: 5| Step: 10
Training loss: 3.395288450995925
Validation loss: 2.7602735779899326

Epoch: 238| Step: 0
Training loss: 2.7113239111879266
Validation loss: 2.7636660578813

Epoch: 5| Step: 1
Training loss: 3.11826498965616
Validation loss: 2.7569902796677215

Epoch: 5| Step: 2
Training loss: 3.0281656835320927
Validation loss: 2.757083933583567

Epoch: 5| Step: 3
Training loss: 2.456048474768484
Validation loss: 2.7489644829615765

Epoch: 5| Step: 4
Training loss: 3.1222219707749863
Validation loss: 2.7366010511001218

Epoch: 5| Step: 5
Training loss: 2.9070102148568773
Validation loss: 2.7379229725793386

Epoch: 5| Step: 6
Training loss: 3.2991888956809925
Validation loss: 2.733487342869589

Epoch: 5| Step: 7
Training loss: 3.160139199341749
Validation loss: 2.731156481819654

Epoch: 5| Step: 8
Training loss: 2.8381399634529014
Validation loss: 2.7312439470887444

Epoch: 5| Step: 9
Training loss: 3.6188217656689985
Validation loss: 2.7344986219924907

Epoch: 5| Step: 10
Training loss: 3.1117662599055573
Validation loss: 2.7377272057925928

Epoch: 239| Step: 0
Training loss: 3.3303978551146183
Validation loss: 2.7276476885297543

Epoch: 5| Step: 1
Training loss: 3.03334649331169
Validation loss: 2.734975884625515

Epoch: 5| Step: 2
Training loss: 2.8198710172658807
Validation loss: 2.728430228658278

Epoch: 5| Step: 3
Training loss: 2.896186880214983
Validation loss: 2.7271715931771543

Epoch: 5| Step: 4
Training loss: 3.084739587757739
Validation loss: 2.7289981068254394

Epoch: 5| Step: 5
Training loss: 2.8809788772883835
Validation loss: 2.7283023504208046

Epoch: 5| Step: 6
Training loss: 3.5824643937103056
Validation loss: 2.72745714437303

Epoch: 5| Step: 7
Training loss: 2.459948240991699
Validation loss: 2.7295657306614944

Epoch: 5| Step: 8
Training loss: 3.420013897070061
Validation loss: 2.7265722108477557

Epoch: 5| Step: 9
Training loss: 2.997162748808726
Validation loss: 2.743220871706361

Epoch: 5| Step: 10
Training loss: 2.7926653503805836
Validation loss: 2.7375021551991563

Epoch: 240| Step: 0
Training loss: 2.7096977807194094
Validation loss: 2.737231734391911

Epoch: 5| Step: 1
Training loss: 2.660066443452408
Validation loss: 2.743992062627412

Epoch: 5| Step: 2
Training loss: 2.6568408982002687
Validation loss: 2.7454574147129835

Epoch: 5| Step: 3
Training loss: 3.521279902982915
Validation loss: 2.7531574716990654

Epoch: 5| Step: 4
Training loss: 2.954027310533773
Validation loss: 2.7630444238682514

Epoch: 5| Step: 5
Training loss: 3.08657868882673
Validation loss: 2.745165060210483

Epoch: 5| Step: 6
Training loss: 2.73614226859781
Validation loss: 2.739543952098937

Epoch: 5| Step: 7
Training loss: 3.2285153296090305
Validation loss: 2.7361507470853628

Epoch: 5| Step: 8
Training loss: 2.695209445918247
Validation loss: 2.728120988797465

Epoch: 5| Step: 9
Training loss: 3.753484759847471
Validation loss: 2.7289480876274577

Epoch: 5| Step: 10
Training loss: 3.3239096151519685
Validation loss: 2.733355818282575

Epoch: 241| Step: 0
Training loss: 3.5599851599394707
Validation loss: 2.729666406686022

Epoch: 5| Step: 1
Training loss: 3.2256221555546882
Validation loss: 2.7276342314042905

Epoch: 5| Step: 2
Training loss: 3.0750863039884813
Validation loss: 2.730939704522924

Epoch: 5| Step: 3
Training loss: 2.9300567801119786
Validation loss: 2.7308663607692947

Epoch: 5| Step: 4
Training loss: 3.110156857131864
Validation loss: 2.732608212416539

Epoch: 5| Step: 5
Training loss: 2.7068404753867368
Validation loss: 2.7287144690636533

Epoch: 5| Step: 6
Training loss: 3.3095981194888924
Validation loss: 2.733278317714422

Epoch: 5| Step: 7
Training loss: 2.5796717772071114
Validation loss: 2.7333747630527356

Epoch: 5| Step: 8
Training loss: 2.698868945540905
Validation loss: 2.7402954361392564

Epoch: 5| Step: 9
Training loss: 3.214414324533797
Validation loss: 2.7413856117551476

Epoch: 5| Step: 10
Training loss: 2.972874075770069
Validation loss: 2.739671143733638

Epoch: 242| Step: 0
Training loss: 2.9500102414745424
Validation loss: 2.7331272936232764

Epoch: 5| Step: 1
Training loss: 3.3750087596638347
Validation loss: 2.7372561940453846

Epoch: 5| Step: 2
Training loss: 3.308752855530974
Validation loss: 2.738375748800463

Epoch: 5| Step: 3
Training loss: 3.1926177583990722
Validation loss: 2.739053420804698

Epoch: 5| Step: 4
Training loss: 2.322903095656184
Validation loss: 2.734763933170374

Epoch: 5| Step: 5
Training loss: 3.093947895540949
Validation loss: 2.7349112786114427

Epoch: 5| Step: 6
Training loss: 2.6562164304519373
Validation loss: 2.7307721268928007

Epoch: 5| Step: 7
Training loss: 3.224868144807102
Validation loss: 2.737420328250481

Epoch: 5| Step: 8
Training loss: 2.54234510236855
Validation loss: 2.735305398142026

Epoch: 5| Step: 9
Training loss: 3.2158309885375473
Validation loss: 2.7364025861935724

Epoch: 5| Step: 10
Training loss: 3.437014736256045
Validation loss: 2.732747528420732

Epoch: 243| Step: 0
Training loss: 3.0258397851901626
Validation loss: 2.729639292503661

Epoch: 5| Step: 1
Training loss: 3.03391156885856
Validation loss: 2.7325779226150524

Epoch: 5| Step: 2
Training loss: 3.367525371407793
Validation loss: 2.72985619936097

Epoch: 5| Step: 3
Training loss: 2.6941079806838615
Validation loss: 2.727681789704963

Epoch: 5| Step: 4
Training loss: 2.7357799299475385
Validation loss: 2.727618562670082

Epoch: 5| Step: 5
Training loss: 3.2423225098960637
Validation loss: 2.7297356438344065

Epoch: 5| Step: 6
Training loss: 3.373262028549937
Validation loss: 2.7257166857900907

Epoch: 5| Step: 7
Training loss: 2.836361519717158
Validation loss: 2.727698964663442

Epoch: 5| Step: 8
Training loss: 3.118953653845537
Validation loss: 2.7250035338140393

Epoch: 5| Step: 9
Training loss: 3.078589234950202
Validation loss: 2.7278670665907736

Epoch: 5| Step: 10
Training loss: 2.830453662163503
Validation loss: 2.7250593245762955

Epoch: 244| Step: 0
Training loss: 3.4926986832243165
Validation loss: 2.732064592357974

Epoch: 5| Step: 1
Training loss: 3.193460314727315
Validation loss: 2.7313918184292385

Epoch: 5| Step: 2
Training loss: 3.400962295112352
Validation loss: 2.7313743785444142

Epoch: 5| Step: 3
Training loss: 2.7592587231581716
Validation loss: 2.7281837587764497

Epoch: 5| Step: 4
Training loss: 2.550331064312564
Validation loss: 2.7258438821474877

Epoch: 5| Step: 5
Training loss: 3.2117427363853603
Validation loss: 2.7325584441232813

Epoch: 5| Step: 6
Training loss: 2.8198825159693497
Validation loss: 2.7199913720326445

Epoch: 5| Step: 7
Training loss: 3.2009739049427615
Validation loss: 2.7293770561919763

Epoch: 5| Step: 8
Training loss: 3.432946258008706
Validation loss: 2.7274462138120312

Epoch: 5| Step: 9
Training loss: 2.316342846676547
Validation loss: 2.727431592978532

Epoch: 5| Step: 10
Training loss: 2.7744742161729485
Validation loss: 2.728443066420897

Epoch: 245| Step: 0
Training loss: 2.718549348288905
Validation loss: 2.7283739082861937

Epoch: 5| Step: 1
Training loss: 3.6022675790140064
Validation loss: 2.720255742061675

Epoch: 5| Step: 2
Training loss: 3.2503041345169392
Validation loss: 2.722855636827001

Epoch: 5| Step: 3
Training loss: 2.886635000952345
Validation loss: 2.720718722373124

Epoch: 5| Step: 4
Training loss: 2.591873961209985
Validation loss: 2.720929952769439

Epoch: 5| Step: 5
Training loss: 3.360689695507782
Validation loss: 2.7174618137007673

Epoch: 5| Step: 6
Training loss: 3.058170606006855
Validation loss: 2.7148769326763094

Epoch: 5| Step: 7
Training loss: 2.6616656576627262
Validation loss: 2.711639026990806

Epoch: 5| Step: 8
Training loss: 3.071387027700316
Validation loss: 2.714635858951609

Epoch: 5| Step: 9
Training loss: 3.1017840327940616
Validation loss: 2.71712548803858

Epoch: 5| Step: 10
Training loss: 2.934896086066889
Validation loss: 2.717134162674508

Epoch: 246| Step: 0
Training loss: 3.2153405956249834
Validation loss: 2.716290403440789

Epoch: 5| Step: 1
Training loss: 2.5964206596489343
Validation loss: 2.715729480734254

Epoch: 5| Step: 2
Training loss: 3.187148430079221
Validation loss: 2.715175853101314

Epoch: 5| Step: 3
Training loss: 3.2876533153450676
Validation loss: 2.7276582348169747

Epoch: 5| Step: 4
Training loss: 2.9424785873165513
Validation loss: 2.7237578030206286

Epoch: 5| Step: 5
Training loss: 3.3135665040382953
Validation loss: 2.740383274862481

Epoch: 5| Step: 6
Training loss: 3.463794502074293
Validation loss: 2.7386313317863684

Epoch: 5| Step: 7
Training loss: 2.6010988297684694
Validation loss: 2.7597947580801843

Epoch: 5| Step: 8
Training loss: 2.9349207816407645
Validation loss: 2.7688625641605897

Epoch: 5| Step: 9
Training loss: 2.744129503981024
Validation loss: 2.7513082698025304

Epoch: 5| Step: 10
Training loss: 3.0666214594065844
Validation loss: 2.7650608520689075

Epoch: 247| Step: 0
Training loss: 3.2790418188296697
Validation loss: 2.7433271171285982

Epoch: 5| Step: 1
Training loss: 2.5863588110931626
Validation loss: 2.7251519817754093

Epoch: 5| Step: 2
Training loss: 2.895267531925314
Validation loss: 2.712717994393577

Epoch: 5| Step: 3
Training loss: 3.520794268208913
Validation loss: 2.7170717318513615

Epoch: 5| Step: 4
Training loss: 2.8463332631191958
Validation loss: 2.716248686123026

Epoch: 5| Step: 5
Training loss: 2.6923119691668065
Validation loss: 2.7179336359438997

Epoch: 5| Step: 6
Training loss: 3.0237630033114886
Validation loss: 2.7175103787838704

Epoch: 5| Step: 7
Training loss: 3.2782350767144024
Validation loss: 2.7155226487669646

Epoch: 5| Step: 8
Training loss: 2.831969288115273
Validation loss: 2.71804021146866

Epoch: 5| Step: 9
Training loss: 3.162563241921855
Validation loss: 2.7138357306445124

Epoch: 5| Step: 10
Training loss: 3.2219972988711683
Validation loss: 2.7208990105105553

Epoch: 248| Step: 0
Training loss: 2.614739118294267
Validation loss: 2.7192598533611783

Epoch: 5| Step: 1
Training loss: 2.6623486686288125
Validation loss: 2.712225884660385

Epoch: 5| Step: 2
Training loss: 3.492138070731699
Validation loss: 2.716094023210462

Epoch: 5| Step: 3
Training loss: 3.3354560451021675
Validation loss: 2.71776037482879

Epoch: 5| Step: 4
Training loss: 2.724637814171694
Validation loss: 2.722690721589838

Epoch: 5| Step: 5
Training loss: 3.0108429146100466
Validation loss: 2.76250326954237

Epoch: 5| Step: 6
Training loss: 3.44902326606652
Validation loss: 2.7463911854058427

Epoch: 5| Step: 7
Training loss: 2.8562705275050444
Validation loss: 2.7849191905536106

Epoch: 5| Step: 8
Training loss: 3.2863517699620375
Validation loss: 2.7502988483258815

Epoch: 5| Step: 9
Training loss: 2.7965408210796503
Validation loss: 2.715951729139056

Epoch: 5| Step: 10
Training loss: 3.1343451577436543
Validation loss: 2.7135851746356328

Epoch: 249| Step: 0
Training loss: 2.7589485919030228
Validation loss: 2.720254485807087

Epoch: 5| Step: 1
Training loss: 3.1322669412753203
Validation loss: 2.727956448256635

Epoch: 5| Step: 2
Training loss: 3.0041637136697914
Validation loss: 2.7376527815636775

Epoch: 5| Step: 3
Training loss: 3.140118458451125
Validation loss: 2.7515063816539107

Epoch: 5| Step: 4
Training loss: 3.1425424672172944
Validation loss: 2.739457046615637

Epoch: 5| Step: 5
Training loss: 3.0101271405410235
Validation loss: 2.725738321844721

Epoch: 5| Step: 6
Training loss: 3.5521225614796093
Validation loss: 2.720032525824176

Epoch: 5| Step: 7
Training loss: 2.6669159315752884
Validation loss: 2.7203823988557443

Epoch: 5| Step: 8
Training loss: 2.8389123703727233
Validation loss: 2.7189505350726026

Epoch: 5| Step: 9
Training loss: 3.058048360438447
Validation loss: 2.7278369844703603

Epoch: 5| Step: 10
Training loss: 3.2896029284334323
Validation loss: 2.726072414563543

Epoch: 250| Step: 0
Training loss: 3.446255301885501
Validation loss: 2.73332329044653

Epoch: 5| Step: 1
Training loss: 3.0698027442410374
Validation loss: 2.7379278574871315

Epoch: 5| Step: 2
Training loss: 3.1677507920552093
Validation loss: 2.742610748566371

Epoch: 5| Step: 3
Training loss: 3.44006751149488
Validation loss: 2.7558124769326002

Epoch: 5| Step: 4
Training loss: 2.835560839311599
Validation loss: 2.743172355738061

Epoch: 5| Step: 5
Training loss: 2.8524594921074287
Validation loss: 2.7247912629625035

Epoch: 5| Step: 6
Training loss: 3.065111409289225
Validation loss: 2.7306936808289035

Epoch: 5| Step: 7
Training loss: 2.949969184843855
Validation loss: 2.7194539762786007

Epoch: 5| Step: 8
Training loss: 3.3948416792931333
Validation loss: 2.721964297535704

Epoch: 5| Step: 9
Training loss: 2.594194121427392
Validation loss: 2.7149239354225876

Epoch: 5| Step: 10
Training loss: 2.4094304455662305
Validation loss: 2.7164660761424995

Epoch: 251| Step: 0
Training loss: 2.5995692042937804
Validation loss: 2.7183342581486007

Epoch: 5| Step: 1
Training loss: 3.35620421763758
Validation loss: 2.7136302328348343

Epoch: 5| Step: 2
Training loss: 3.066631099936963
Validation loss: 2.7138438981261808

Epoch: 5| Step: 3
Training loss: 3.0162398744200543
Validation loss: 2.7116001689615166

Epoch: 5| Step: 4
Training loss: 3.458680805690143
Validation loss: 2.712958249165513

Epoch: 5| Step: 5
Training loss: 3.206869922813094
Validation loss: 2.711760391757636

Epoch: 5| Step: 6
Training loss: 2.987824528517029
Validation loss: 2.7211576217813684

Epoch: 5| Step: 7
Training loss: 2.999712294452137
Validation loss: 2.723209168360963

Epoch: 5| Step: 8
Training loss: 2.825516989334703
Validation loss: 2.719284419518042

Epoch: 5| Step: 9
Training loss: 2.96594491244069
Validation loss: 2.7146179506647337

Epoch: 5| Step: 10
Training loss: 2.822549286945028
Validation loss: 2.723747981428476

Epoch: 252| Step: 0
Training loss: 3.2960160569290586
Validation loss: 2.7193960860840414

Epoch: 5| Step: 1
Training loss: 3.3413550811124777
Validation loss: 2.712959719524944

Epoch: 5| Step: 2
Training loss: 2.8053957754112977
Validation loss: 2.7125055938250195

Epoch: 5| Step: 3
Training loss: 2.9083124861384495
Validation loss: 2.7114060709082577

Epoch: 5| Step: 4
Training loss: 3.1815527991062753
Validation loss: 2.713717548797957

Epoch: 5| Step: 5
Training loss: 2.288391535723348
Validation loss: 2.714274906205858

Epoch: 5| Step: 6
Training loss: 2.962907201410041
Validation loss: 2.7091713441047873

Epoch: 5| Step: 7
Training loss: 2.901770143571935
Validation loss: 2.7115313744852227

Epoch: 5| Step: 8
Training loss: 3.534326074398187
Validation loss: 2.7121157977875097

Epoch: 5| Step: 9
Training loss: 3.0493589008873485
Validation loss: 2.7092132129837356

Epoch: 5| Step: 10
Training loss: 2.9332928661965196
Validation loss: 2.7078556280010058

Epoch: 253| Step: 0
Training loss: 3.2719816553025964
Validation loss: 2.7133924260441566

Epoch: 5| Step: 1
Training loss: 3.1760645666117404
Validation loss: 2.7160627554371657

Epoch: 5| Step: 2
Training loss: 2.560608700864955
Validation loss: 2.721093311379085

Epoch: 5| Step: 3
Training loss: 3.7110508309174803
Validation loss: 2.734138516514528

Epoch: 5| Step: 4
Training loss: 3.4191970449225115
Validation loss: 2.727142249782278

Epoch: 5| Step: 5
Training loss: 2.7109700401617842
Validation loss: 2.7205026060343007

Epoch: 5| Step: 6
Training loss: 3.3246086062337556
Validation loss: 2.719740325509387

Epoch: 5| Step: 7
Training loss: 2.816668832842052
Validation loss: 2.7098798786675866

Epoch: 5| Step: 8
Training loss: 2.7456985124089868
Validation loss: 2.708473929517714

Epoch: 5| Step: 9
Training loss: 2.9720748753928468
Validation loss: 2.7095235558352404

Epoch: 5| Step: 10
Training loss: 2.26255611539769
Validation loss: 2.7069190548885924

Epoch: 254| Step: 0
Training loss: 3.034809971599656
Validation loss: 2.7144221247205405

Epoch: 5| Step: 1
Training loss: 3.757443733123994
Validation loss: 2.708564168844117

Epoch: 5| Step: 2
Training loss: 1.937018426912855
Validation loss: 2.7083910542309364

Epoch: 5| Step: 3
Training loss: 3.173268881017704
Validation loss: 2.709106540031702

Epoch: 5| Step: 4
Training loss: 2.7913005835548965
Validation loss: 2.7056630875511214

Epoch: 5| Step: 5
Training loss: 2.7132711342783105
Validation loss: 2.71169504828228

Epoch: 5| Step: 6
Training loss: 3.3833847442880125
Validation loss: 2.7127987151581583

Epoch: 5| Step: 7
Training loss: 3.485743643013928
Validation loss: 2.7180411348559397

Epoch: 5| Step: 8
Training loss: 2.467074731202847
Validation loss: 2.7309284987679963

Epoch: 5| Step: 9
Training loss: 3.020545542370642
Validation loss: 2.7159124108187593

Epoch: 5| Step: 10
Training loss: 3.1809028720891557
Validation loss: 2.7104350997452995

Epoch: 255| Step: 0
Training loss: 3.2224424349050604
Validation loss: 2.7117625387119157

Epoch: 5| Step: 1
Training loss: 2.2568084701920035
Validation loss: 2.707401711430225

Epoch: 5| Step: 2
Training loss: 2.2898906993185153
Validation loss: 2.702916917077413

Epoch: 5| Step: 3
Training loss: 3.453946253267266
Validation loss: 2.712977456381516

Epoch: 5| Step: 4
Training loss: 3.0292172252383396
Validation loss: 2.7084343644474753

Epoch: 5| Step: 5
Training loss: 3.2571028341257993
Validation loss: 2.703834680950366

Epoch: 5| Step: 6
Training loss: 2.673334002205376
Validation loss: 2.702253838738755

Epoch: 5| Step: 7
Training loss: 2.869780737180488
Validation loss: 2.7085376829637084

Epoch: 5| Step: 8
Training loss: 3.2342163636745993
Validation loss: 2.708635720031113

Epoch: 5| Step: 9
Training loss: 3.521459053612859
Validation loss: 2.7083248901866632

Epoch: 5| Step: 10
Training loss: 3.2211727172438933
Validation loss: 2.7055110895427616

Epoch: 256| Step: 0
Training loss: 2.992319925828985
Validation loss: 2.7060182570091293

Epoch: 5| Step: 1
Training loss: 3.2721466214035844
Validation loss: 2.70789399160831

Epoch: 5| Step: 2
Training loss: 2.8279863186549816
Validation loss: 2.708371792718197

Epoch: 5| Step: 3
Training loss: 2.6359860454763036
Validation loss: 2.7007417867995254

Epoch: 5| Step: 4
Training loss: 2.52003764896425
Validation loss: 2.69963280905254

Epoch: 5| Step: 5
Training loss: 3.2515038165580856
Validation loss: 2.7052570266533444

Epoch: 5| Step: 6
Training loss: 3.3901829585213443
Validation loss: 2.70567219499411

Epoch: 5| Step: 7
Training loss: 2.880771979606565
Validation loss: 2.7062636242390736

Epoch: 5| Step: 8
Training loss: 3.009010294426613
Validation loss: 2.7033695582383923

Epoch: 5| Step: 9
Training loss: 3.0308563920714473
Validation loss: 2.6998242733891065

Epoch: 5| Step: 10
Training loss: 3.433108211901994
Validation loss: 2.7075278981611937

Epoch: 257| Step: 0
Training loss: 2.7194344546903375
Validation loss: 2.7012415577908793

Epoch: 5| Step: 1
Training loss: 2.68775069376032
Validation loss: 2.699922360983054

Epoch: 5| Step: 2
Training loss: 3.2810083209452268
Validation loss: 2.7010685936390257

Epoch: 5| Step: 3
Training loss: 3.316442195126905
Validation loss: 2.705013473068068

Epoch: 5| Step: 4
Training loss: 3.4049139639898174
Validation loss: 2.7003719857491286

Epoch: 5| Step: 5
Training loss: 2.7658753362601907
Validation loss: 2.703583120333526

Epoch: 5| Step: 6
Training loss: 2.820521465812896
Validation loss: 2.7006387196636523

Epoch: 5| Step: 7
Training loss: 3.145909811610251
Validation loss: 2.703866883722469

Epoch: 5| Step: 8
Training loss: 2.9307934110596308
Validation loss: 2.7054346201747865

Epoch: 5| Step: 9
Training loss: 2.9372228938134564
Validation loss: 2.6990377726003807

Epoch: 5| Step: 10
Training loss: 3.206510810580426
Validation loss: 2.7002448702802413

Epoch: 258| Step: 0
Training loss: 3.0485437762780756
Validation loss: 2.693334656616787

Epoch: 5| Step: 1
Training loss: 3.7476242169030454
Validation loss: 2.699922460683055

Epoch: 5| Step: 2
Training loss: 2.8145834940908645
Validation loss: 2.6936276541901045

Epoch: 5| Step: 3
Training loss: 2.4737746856521787
Validation loss: 2.699072599027063

Epoch: 5| Step: 4
Training loss: 3.091157077082191
Validation loss: 2.696664103611947

Epoch: 5| Step: 5
Training loss: 3.1413072442858767
Validation loss: 2.698615100908108

Epoch: 5| Step: 6
Training loss: 2.7276208785392915
Validation loss: 2.6978928731259595

Epoch: 5| Step: 7
Training loss: 3.0820453290533147
Validation loss: 2.695355445884679

Epoch: 5| Step: 8
Training loss: 2.571888727311387
Validation loss: 2.696457511065196

Epoch: 5| Step: 9
Training loss: 3.4781175200321073
Validation loss: 2.6947206793545

Epoch: 5| Step: 10
Training loss: 2.818964501316073
Validation loss: 2.696158333380141

Epoch: 259| Step: 0
Training loss: 3.308857192323273
Validation loss: 2.6977142500042612

Epoch: 5| Step: 1
Training loss: 2.8914942078919093
Validation loss: 2.6956817026918074

Epoch: 5| Step: 2
Training loss: 2.9274275137301915
Validation loss: 2.706668787765015

Epoch: 5| Step: 3
Training loss: 3.355323655141112
Validation loss: 2.6999649088108653

Epoch: 5| Step: 4
Training loss: 2.9453084525730646
Validation loss: 2.6996307284218783

Epoch: 5| Step: 5
Training loss: 2.9718019558727664
Validation loss: 2.703312078476631

Epoch: 5| Step: 6
Training loss: 3.3900206418379524
Validation loss: 2.700647678877637

Epoch: 5| Step: 7
Training loss: 2.887529850264657
Validation loss: 2.7013102707677024

Epoch: 5| Step: 8
Training loss: 2.1364673417780415
Validation loss: 2.697431237412385

Epoch: 5| Step: 9
Training loss: 3.001285277655407
Validation loss: 2.696598298306021

Epoch: 5| Step: 10
Training loss: 3.221796020368576
Validation loss: 2.6964984241187397

Epoch: 260| Step: 0
Training loss: 3.3909009126829095
Validation loss: 2.7026270333566838

Epoch: 5| Step: 1
Training loss: 2.771476976789368
Validation loss: 2.700319390375198

Epoch: 5| Step: 2
Training loss: 2.548936068415915
Validation loss: 2.6997651988198132

Epoch: 5| Step: 3
Training loss: 3.208302848638062
Validation loss: 2.6990731157306054

Epoch: 5| Step: 4
Training loss: 3.0719151475830504
Validation loss: 2.691760651018702

Epoch: 5| Step: 5
Training loss: 2.714856659563506
Validation loss: 2.6924730817259857

Epoch: 5| Step: 6
Training loss: 3.0365654657656993
Validation loss: 2.6964458606237987

Epoch: 5| Step: 7
Training loss: 3.346169140322918
Validation loss: 2.6953672475130745

Epoch: 5| Step: 8
Training loss: 3.0868073215391365
Validation loss: 2.69683895582971

Epoch: 5| Step: 9
Training loss: 2.698715582624156
Validation loss: 2.6900330940053183

Epoch: 5| Step: 10
Training loss: 3.1966600631099378
Validation loss: 2.697506844532993

Epoch: 261| Step: 0
Training loss: 3.2714826259323684
Validation loss: 2.6953293409708645

Epoch: 5| Step: 1
Training loss: 3.558796614089389
Validation loss: 2.6916485327673607

Epoch: 5| Step: 2
Training loss: 3.1407695376410887
Validation loss: 2.6891758800042314

Epoch: 5| Step: 3
Training loss: 3.2170444154717797
Validation loss: 2.692112114266464

Epoch: 5| Step: 4
Training loss: 2.85993476766607
Validation loss: 2.6875107534374196

Epoch: 5| Step: 5
Training loss: 2.5738927145579877
Validation loss: 2.688389500487564

Epoch: 5| Step: 6
Training loss: 3.1682726318013397
Validation loss: 2.6989533708392304

Epoch: 5| Step: 7
Training loss: 2.744323420290737
Validation loss: 2.6954030743837043

Epoch: 5| Step: 8
Training loss: 3.0386881070599046
Validation loss: 2.7094309791992575

Epoch: 5| Step: 9
Training loss: 2.6156274501556624
Validation loss: 2.700523402490631

Epoch: 5| Step: 10
Training loss: 2.6900681046724224
Validation loss: 2.702169725280196

Epoch: 262| Step: 0
Training loss: 2.7153537627957256
Validation loss: 2.687394852905301

Epoch: 5| Step: 1
Training loss: 3.1334024002363057
Validation loss: 2.6929312815395936

Epoch: 5| Step: 2
Training loss: 3.3679167274274673
Validation loss: 2.6849825745108387

Epoch: 5| Step: 3
Training loss: 2.752549117063255
Validation loss: 2.6856149805406853

Epoch: 5| Step: 4
Training loss: 3.0227977460258413
Validation loss: 2.6897548479748186

Epoch: 5| Step: 5
Training loss: 3.092911886110191
Validation loss: 2.6847848075646588

Epoch: 5| Step: 6
Training loss: 2.702076703144097
Validation loss: 2.6841967582391866

Epoch: 5| Step: 7
Training loss: 2.6823448595618116
Validation loss: 2.6820502681010163

Epoch: 5| Step: 8
Training loss: 3.5233690208665553
Validation loss: 2.6814131014242903

Epoch: 5| Step: 9
Training loss: 3.236412254441743
Validation loss: 2.6840580130281544

Epoch: 5| Step: 10
Training loss: 2.6248798342856947
Validation loss: 2.6792223667279798

Epoch: 263| Step: 0
Training loss: 3.2961961671080964
Validation loss: 2.6744768031836634

Epoch: 5| Step: 1
Training loss: 3.0103151684890492
Validation loss: 2.6770007497132378

Epoch: 5| Step: 2
Training loss: 3.430145441647408
Validation loss: 2.6885697319411754

Epoch: 5| Step: 3
Training loss: 2.976317868730606
Validation loss: 2.702891287349301

Epoch: 5| Step: 4
Training loss: 3.3206772547810064
Validation loss: 2.7147143606008557

Epoch: 5| Step: 5
Training loss: 2.6035842142420966
Validation loss: 2.7021405126497835

Epoch: 5| Step: 6
Training loss: 3.044097103560154
Validation loss: 2.68817674644633

Epoch: 5| Step: 7
Training loss: 3.2265197898864355
Validation loss: 2.680316460067763

Epoch: 5| Step: 8
Training loss: 2.9316715287136974
Validation loss: 2.6774074603536957

Epoch: 5| Step: 9
Training loss: 2.3613838586784963
Validation loss: 2.681808550191168

Epoch: 5| Step: 10
Training loss: 2.665892031533067
Validation loss: 2.6780081616227775

Epoch: 264| Step: 0
Training loss: 2.956494866002678
Validation loss: 2.68221506992452

Epoch: 5| Step: 1
Training loss: 2.6374858729268893
Validation loss: 2.6820160962073465

Epoch: 5| Step: 2
Training loss: 3.0478529705519817
Validation loss: 2.6797038957695816

Epoch: 5| Step: 3
Training loss: 2.6612475785172296
Validation loss: 2.680313408928689

Epoch: 5| Step: 4
Training loss: 3.1874931185778967
Validation loss: 2.679814896069127

Epoch: 5| Step: 5
Training loss: 2.840446481666212
Validation loss: 2.6747918232832166

Epoch: 5| Step: 6
Training loss: 2.695870604299196
Validation loss: 2.684419459938714

Epoch: 5| Step: 7
Training loss: 3.045302234552109
Validation loss: 2.6932177169042752

Epoch: 5| Step: 8
Training loss: 3.287199312680791
Validation loss: 2.6919539656737927

Epoch: 5| Step: 9
Training loss: 3.2233826714427836
Validation loss: 2.689706079593688

Epoch: 5| Step: 10
Training loss: 3.4664506594289457
Validation loss: 2.687564752728246

Epoch: 265| Step: 0
Training loss: 2.454721016658065
Validation loss: 2.6913163774538185

Epoch: 5| Step: 1
Training loss: 3.5025472908176503
Validation loss: 2.689174466709449

Epoch: 5| Step: 2
Training loss: 2.611300825662511
Validation loss: 2.681164186382158

Epoch: 5| Step: 3
Training loss: 2.907554579769463
Validation loss: 2.68423858498043

Epoch: 5| Step: 4
Training loss: 2.8323876728838506
Validation loss: 2.6814165672055577

Epoch: 5| Step: 5
Training loss: 3.1875270767557833
Validation loss: 2.691581271385393

Epoch: 5| Step: 6
Training loss: 2.7068180148869545
Validation loss: 2.69179535826123

Epoch: 5| Step: 7
Training loss: 3.632330487175748
Validation loss: 2.6845684904475213

Epoch: 5| Step: 8
Training loss: 3.6491605707887023
Validation loss: 2.6864221438023743

Epoch: 5| Step: 9
Training loss: 2.6582289560647947
Validation loss: 2.682417344278073

Epoch: 5| Step: 10
Training loss: 2.391559193906813
Validation loss: 2.676507027770775

Epoch: 266| Step: 0
Training loss: 2.673951262487126
Validation loss: 2.6756482656481047

Epoch: 5| Step: 1
Training loss: 2.881234747790433
Validation loss: 2.672555973530413

Epoch: 5| Step: 2
Training loss: 2.6311119315196954
Validation loss: 2.679855011862918

Epoch: 5| Step: 3
Training loss: 2.9851769772818093
Validation loss: 2.677683321601504

Epoch: 5| Step: 4
Training loss: 2.8649457852491715
Validation loss: 2.675256996663161

Epoch: 5| Step: 5
Training loss: 3.182199446636912
Validation loss: 2.6797960825556313

Epoch: 5| Step: 6
Training loss: 3.2304646170242606
Validation loss: 2.6789648824744003

Epoch: 5| Step: 7
Training loss: 3.2954842042933645
Validation loss: 2.687237415043916

Epoch: 5| Step: 8
Training loss: 3.0448811585234736
Validation loss: 2.6747636429372266

Epoch: 5| Step: 9
Training loss: 3.0855470048127107
Validation loss: 2.68720546042273

Epoch: 5| Step: 10
Training loss: 3.0383687539127666
Validation loss: 2.6726906426258643

Epoch: 267| Step: 0
Training loss: 3.2448180040951
Validation loss: 2.67151041067453

Epoch: 5| Step: 1
Training loss: 3.057234772776141
Validation loss: 2.6736566590217454

Epoch: 5| Step: 2
Training loss: 2.947381949483327
Validation loss: 2.678096961596191

Epoch: 5| Step: 3
Training loss: 2.2247475170083493
Validation loss: 2.6841962615940544

Epoch: 5| Step: 4
Training loss: 3.1216417196824513
Validation loss: 2.6913863206527355

Epoch: 5| Step: 5
Training loss: 2.3752799622011356
Validation loss: 2.698251395049687

Epoch: 5| Step: 6
Training loss: 2.826652522891425
Validation loss: 2.6961804519490356

Epoch: 5| Step: 7
Training loss: 3.544486565042337
Validation loss: 2.703609297268955

Epoch: 5| Step: 8
Training loss: 3.189254726539477
Validation loss: 2.69073049492757

Epoch: 5| Step: 9
Training loss: 2.9823112342362195
Validation loss: 2.693820870076799

Epoch: 5| Step: 10
Training loss: 3.310542697960123
Validation loss: 2.6786278543813644

Epoch: 268| Step: 0
Training loss: 2.928665186215252
Validation loss: 2.6783998403754508

Epoch: 5| Step: 1
Training loss: 3.0776382293770093
Validation loss: 2.6713656439082873

Epoch: 5| Step: 2
Training loss: 2.8200929508717256
Validation loss: 2.6715245497102664

Epoch: 5| Step: 3
Training loss: 2.962390070296089
Validation loss: 2.6755329895660034

Epoch: 5| Step: 4
Training loss: 2.9171402864563607
Validation loss: 2.6728585028328693

Epoch: 5| Step: 5
Training loss: 2.8010391691193677
Validation loss: 2.6687791965347007

Epoch: 5| Step: 6
Training loss: 3.4230680432612477
Validation loss: 2.6731182162015625

Epoch: 5| Step: 7
Training loss: 2.843640671189963
Validation loss: 2.6731802359626142

Epoch: 5| Step: 8
Training loss: 3.3839994466975054
Validation loss: 2.6697760618511412

Epoch: 5| Step: 9
Training loss: 2.9655460134103144
Validation loss: 2.675990672726486

Epoch: 5| Step: 10
Training loss: 2.82628837508781
Validation loss: 2.6696806059735616

Epoch: 269| Step: 0
Training loss: 3.246563341531875
Validation loss: 2.675325047928692

Epoch: 5| Step: 1
Training loss: 2.524290903064355
Validation loss: 2.678777064503284

Epoch: 5| Step: 2
Training loss: 2.863913514403142
Validation loss: 2.6804048296868617

Epoch: 5| Step: 3
Training loss: 3.365871092460252
Validation loss: 2.6795678608459887

Epoch: 5| Step: 4
Training loss: 3.2681704005496424
Validation loss: 2.6807421106212534

Epoch: 5| Step: 5
Training loss: 2.595691551716581
Validation loss: 2.6772786579878938

Epoch: 5| Step: 6
Training loss: 2.8449945765545848
Validation loss: 2.6692382231050202

Epoch: 5| Step: 7
Training loss: 2.7060190926024172
Validation loss: 2.6717772960999233

Epoch: 5| Step: 8
Training loss: 3.083957471482557
Validation loss: 2.669074311464126

Epoch: 5| Step: 9
Training loss: 3.2221737032193443
Validation loss: 2.6681255011724443

Epoch: 5| Step: 10
Training loss: 3.1642079261043485
Validation loss: 2.6662770375688423

Epoch: 270| Step: 0
Training loss: 2.6939837290181163
Validation loss: 2.663835640411876

Epoch: 5| Step: 1
Training loss: 3.619649951090936
Validation loss: 2.665960886319428

Epoch: 5| Step: 2
Training loss: 2.8729077894826553
Validation loss: 2.6621558316902347

Epoch: 5| Step: 3
Training loss: 3.5832199404022615
Validation loss: 2.6650625147955282

Epoch: 5| Step: 4
Training loss: 3.0705255720834437
Validation loss: 2.668844416923845

Epoch: 5| Step: 5
Training loss: 2.4646869494685557
Validation loss: 2.665233531390988

Epoch: 5| Step: 6
Training loss: 2.999597045539269
Validation loss: 2.66656585536132

Epoch: 5| Step: 7
Training loss: 3.010086428646587
Validation loss: 2.667971557736783

Epoch: 5| Step: 8
Training loss: 2.756367853460657
Validation loss: 2.663633568060428

Epoch: 5| Step: 9
Training loss: 2.5834776827773154
Validation loss: 2.6682960409076024

Epoch: 5| Step: 10
Training loss: 3.0744681541938834
Validation loss: 2.666785166078961

Epoch: 271| Step: 0
Training loss: 3.341443701430066
Validation loss: 2.66573078578581

Epoch: 5| Step: 1
Training loss: 2.0384147462886357
Validation loss: 2.6688316498142415

Epoch: 5| Step: 2
Training loss: 3.0227740838890766
Validation loss: 2.6639055184111986

Epoch: 5| Step: 3
Training loss: 3.475625861362789
Validation loss: 2.6660568119332226

Epoch: 5| Step: 4
Training loss: 3.0785224774103725
Validation loss: 2.666947138236765

Epoch: 5| Step: 5
Training loss: 3.1644481282653274
Validation loss: 2.6712718571429694

Epoch: 5| Step: 6
Training loss: 2.8197813088591213
Validation loss: 2.665312681576423

Epoch: 5| Step: 7
Training loss: 3.5409663386841643
Validation loss: 2.6795862511737405

Epoch: 5| Step: 8
Training loss: 2.9731722370121685
Validation loss: 2.6761804335474912

Epoch: 5| Step: 9
Training loss: 2.282725967135332
Validation loss: 2.6746145415188907

Epoch: 5| Step: 10
Training loss: 2.77618426922272
Validation loss: 2.67227473252541

Epoch: 272| Step: 0
Training loss: 3.132294191021796
Validation loss: 2.6720526755572407

Epoch: 5| Step: 1
Training loss: 2.788561864206676
Validation loss: 2.671827652526151

Epoch: 5| Step: 2
Training loss: 3.2566675603026534
Validation loss: 2.669728930662071

Epoch: 5| Step: 3
Training loss: 2.500161070403306
Validation loss: 2.672883529987757

Epoch: 5| Step: 4
Training loss: 3.599695743843108
Validation loss: 2.67193357150027

Epoch: 5| Step: 5
Training loss: 2.967888797527587
Validation loss: 2.6654315976952105

Epoch: 5| Step: 6
Training loss: 3.327229697285129
Validation loss: 2.6728964988217405

Epoch: 5| Step: 7
Training loss: 2.501227840266324
Validation loss: 2.6591189464150338

Epoch: 5| Step: 8
Training loss: 2.7111560392652403
Validation loss: 2.6652170225560283

Epoch: 5| Step: 9
Training loss: 3.381901924619722
Validation loss: 2.6666202066845255

Epoch: 5| Step: 10
Training loss: 2.3577219243534433
Validation loss: 2.6643197867594512

Epoch: 273| Step: 0
Training loss: 3.4312167918225964
Validation loss: 2.6627410102500306

Epoch: 5| Step: 1
Training loss: 2.9836672597790854
Validation loss: 2.6657615370156713

Epoch: 5| Step: 2
Training loss: 3.068618112748344
Validation loss: 2.6629785989843286

Epoch: 5| Step: 3
Training loss: 3.3081708725660963
Validation loss: 2.6663829482054386

Epoch: 5| Step: 4
Training loss: 2.309905891152855
Validation loss: 2.6661822477650214

Epoch: 5| Step: 5
Training loss: 3.0436092774996646
Validation loss: 2.6735892240383703

Epoch: 5| Step: 6
Training loss: 2.719189663118634
Validation loss: 2.672663777261558

Epoch: 5| Step: 7
Training loss: 2.583247326885595
Validation loss: 2.6755095389802235

Epoch: 5| Step: 8
Training loss: 3.1693643489802357
Validation loss: 2.678220219652658

Epoch: 5| Step: 9
Training loss: 3.0353306311512873
Validation loss: 2.6689428342941413

Epoch: 5| Step: 10
Training loss: 3.0585859549509546
Validation loss: 2.68117643007225

Epoch: 274| Step: 0
Training loss: 2.9421055179140057
Validation loss: 2.675264070663967

Epoch: 5| Step: 1
Training loss: 3.360219024376933
Validation loss: 2.6698281325798616

Epoch: 5| Step: 2
Training loss: 2.9502177788473434
Validation loss: 2.670732026899028

Epoch: 5| Step: 3
Training loss: 2.51574820459653
Validation loss: 2.6791565951937253

Epoch: 5| Step: 4
Training loss: 2.8032812136667147
Validation loss: 2.680868188557741

Epoch: 5| Step: 5
Training loss: 3.1969445124999303
Validation loss: 2.6699824394547926

Epoch: 5| Step: 6
Training loss: 3.1077585283735787
Validation loss: 2.6696142248396537

Epoch: 5| Step: 7
Training loss: 2.8324055181032843
Validation loss: 2.66394197049816

Epoch: 5| Step: 8
Training loss: 3.5487460272304205
Validation loss: 2.6665618501593156

Epoch: 5| Step: 9
Training loss: 2.5963472897442674
Validation loss: 2.660334909620113

Epoch: 5| Step: 10
Training loss: 2.8879231791013957
Validation loss: 2.665557965084173

Epoch: 275| Step: 0
Training loss: 3.18263546615647
Validation loss: 2.662979608371598

Epoch: 5| Step: 1
Training loss: 2.256424421083122
Validation loss: 2.674968606440516

Epoch: 5| Step: 2
Training loss: 2.8464165227306464
Validation loss: 2.668673220569837

Epoch: 5| Step: 3
Training loss: 3.1517590591495335
Validation loss: 2.6711139651760405

Epoch: 5| Step: 4
Training loss: 2.9061656652540244
Validation loss: 2.6769684938148726

Epoch: 5| Step: 5
Training loss: 3.362655953686938
Validation loss: 2.684073964708341

Epoch: 5| Step: 6
Training loss: 3.6222428984984782
Validation loss: 2.685322832861982

Epoch: 5| Step: 7
Training loss: 2.2657039233963587
Validation loss: 2.680794457974648

Epoch: 5| Step: 8
Training loss: 3.1495050556138047
Validation loss: 2.675944945296298

Epoch: 5| Step: 9
Training loss: 3.0458954630375827
Validation loss: 2.6764239337087106

Epoch: 5| Step: 10
Training loss: 2.757795382438466
Validation loss: 2.6685354359166773

Epoch: 276| Step: 0
Training loss: 2.9333868245825125
Validation loss: 2.6711359456145503

Epoch: 5| Step: 1
Training loss: 2.853479697166446
Validation loss: 2.6693114334888484

Epoch: 5| Step: 2
Training loss: 3.2508309109100284
Validation loss: 2.6675982383087358

Epoch: 5| Step: 3
Training loss: 2.954076543024215
Validation loss: 2.659260486109475

Epoch: 5| Step: 4
Training loss: 3.231427162375365
Validation loss: 2.657466014114979

Epoch: 5| Step: 5
Training loss: 2.70946750856929
Validation loss: 2.6582972378253484

Epoch: 5| Step: 6
Training loss: 2.9351488809338226
Validation loss: 2.656288763411269

Epoch: 5| Step: 7
Training loss: 3.0527225037757026
Validation loss: 2.6555912974526055

Epoch: 5| Step: 8
Training loss: 2.9930938065266126
Validation loss: 2.6586055380042333

Epoch: 5| Step: 9
Training loss: 3.1419829663859686
Validation loss: 2.6601333996646646

Epoch: 5| Step: 10
Training loss: 2.698875836066457
Validation loss: 2.6621596581449536

Epoch: 277| Step: 0
Training loss: 3.1878968534068703
Validation loss: 2.65964628247011

Epoch: 5| Step: 1
Training loss: 2.9436396292630276
Validation loss: 2.662045852109932

Epoch: 5| Step: 2
Training loss: 3.1812284517588916
Validation loss: 2.65854473172907

Epoch: 5| Step: 3
Training loss: 2.778906617206145
Validation loss: 2.657074309970896

Epoch: 5| Step: 4
Training loss: 3.3350697445189454
Validation loss: 2.6575270360770054

Epoch: 5| Step: 5
Training loss: 2.474489710442822
Validation loss: 2.65835545946263

Epoch: 5| Step: 6
Training loss: 3.548032328134745
Validation loss: 2.6568975770344383

Epoch: 5| Step: 7
Training loss: 2.704576752950017
Validation loss: 2.653747105178791

Epoch: 5| Step: 8
Training loss: 2.7436632494583266
Validation loss: 2.6552712381122823

Epoch: 5| Step: 9
Training loss: 2.670343149543878
Validation loss: 2.658832598934171

Epoch: 5| Step: 10
Training loss: 3.144894862032323
Validation loss: 2.6567934690324155

Epoch: 278| Step: 0
Training loss: 2.890622690560733
Validation loss: 2.658647653571938

Epoch: 5| Step: 1
Training loss: 2.8717802511531216
Validation loss: 2.653822683643791

Epoch: 5| Step: 2
Training loss: 2.624999545869334
Validation loss: 2.6585683232786566

Epoch: 5| Step: 3
Training loss: 2.988567822247611
Validation loss: 2.6584791815120004

Epoch: 5| Step: 4
Training loss: 2.536891913253067
Validation loss: 2.6667290828947596

Epoch: 5| Step: 5
Training loss: 3.284060918161656
Validation loss: 2.6581542715438813

Epoch: 5| Step: 6
Training loss: 3.141994045074667
Validation loss: 2.665869717438737

Epoch: 5| Step: 7
Training loss: 3.1430992893965937
Validation loss: 2.654642344138083

Epoch: 5| Step: 8
Training loss: 3.002306369506109
Validation loss: 2.6647924488284955

Epoch: 5| Step: 9
Training loss: 3.3559692151700298
Validation loss: 2.6563466854945212

Epoch: 5| Step: 10
Training loss: 2.8961562564382715
Validation loss: 2.6586558922385484

Epoch: 279| Step: 0
Training loss: 2.6402404324546302
Validation loss: 2.658567329091685

Epoch: 5| Step: 1
Training loss: 2.8451514511155915
Validation loss: 2.652539893832068

Epoch: 5| Step: 2
Training loss: 3.036146162070603
Validation loss: 2.654348724942244

Epoch: 5| Step: 3
Training loss: 3.287333054165457
Validation loss: 2.6508290014765965

Epoch: 5| Step: 4
Training loss: 2.477075180754682
Validation loss: 2.656949687881024

Epoch: 5| Step: 5
Training loss: 3.011050376498542
Validation loss: 2.6670670542030077

Epoch: 5| Step: 6
Training loss: 2.759691155057259
Validation loss: 2.6559544755395565

Epoch: 5| Step: 7
Training loss: 3.2145785364859774
Validation loss: 2.6547721520522436

Epoch: 5| Step: 8
Training loss: 3.1999314181608045
Validation loss: 2.659551384541375

Epoch: 5| Step: 9
Training loss: 3.177598421626933
Validation loss: 2.6553330095116223

Epoch: 5| Step: 10
Training loss: 3.092924990613027
Validation loss: 2.6607440887275837

Epoch: 280| Step: 0
Training loss: 3.0077062810993125
Validation loss: 2.670024965105094

Epoch: 5| Step: 1
Training loss: 2.906792046645478
Validation loss: 2.668824905535843

Epoch: 5| Step: 2
Training loss: 3.3110529779996147
Validation loss: 2.6638746129483835

Epoch: 5| Step: 3
Training loss: 2.91202750241214
Validation loss: 2.690644773067826

Epoch: 5| Step: 4
Training loss: 3.065021333355737
Validation loss: 2.6581453716408014

Epoch: 5| Step: 5
Training loss: 3.1723710597704584
Validation loss: 2.654827534727549

Epoch: 5| Step: 6
Training loss: 3.015044319497668
Validation loss: 2.6532761306608137

Epoch: 5| Step: 7
Training loss: 2.06624690633128
Validation loss: 2.653301199043749

Epoch: 5| Step: 8
Training loss: 2.612405536166674
Validation loss: 2.6545491495771936

Epoch: 5| Step: 9
Training loss: 3.405268816538663
Validation loss: 2.656017036042295

Epoch: 5| Step: 10
Training loss: 3.146065473938614
Validation loss: 2.6633084908494893

Epoch: 281| Step: 0
Training loss: 2.4417643292091467
Validation loss: 2.6576136187585115

Epoch: 5| Step: 1
Training loss: 3.1223633896788874
Validation loss: 2.6611379838351152

Epoch: 5| Step: 2
Training loss: 3.116015374034323
Validation loss: 2.659334387631265

Epoch: 5| Step: 3
Training loss: 2.6646672342754893
Validation loss: 2.666100332921825

Epoch: 5| Step: 4
Training loss: 2.950625699169849
Validation loss: 2.6777858644660735

Epoch: 5| Step: 5
Training loss: 3.108383864195731
Validation loss: 2.6687682965360295

Epoch: 5| Step: 6
Training loss: 3.6541389826759345
Validation loss: 2.65841967903799

Epoch: 5| Step: 7
Training loss: 2.5659122543198736
Validation loss: 2.6573406752638213

Epoch: 5| Step: 8
Training loss: 2.8670611028849353
Validation loss: 2.6579732527650375

Epoch: 5| Step: 9
Training loss: 2.7710193676748367
Validation loss: 2.652995212337728

Epoch: 5| Step: 10
Training loss: 3.4070254501856736
Validation loss: 2.65388313346734

Epoch: 282| Step: 0
Training loss: 2.5791170927921283
Validation loss: 2.650369668067433

Epoch: 5| Step: 1
Training loss: 2.959981235496223
Validation loss: 2.6511682899626234

Epoch: 5| Step: 2
Training loss: 3.5833805583828644
Validation loss: 2.6579332050615383

Epoch: 5| Step: 3
Training loss: 2.4606855959863956
Validation loss: 2.653962847230569

Epoch: 5| Step: 4
Training loss: 2.4957516813428247
Validation loss: 2.6590197045825907

Epoch: 5| Step: 5
Training loss: 3.0382009819808133
Validation loss: 2.656346118015561

Epoch: 5| Step: 6
Training loss: 3.463595986000076
Validation loss: 2.6565468194632724

Epoch: 5| Step: 7
Training loss: 2.757604488492433
Validation loss: 2.659703901066736

Epoch: 5| Step: 8
Training loss: 3.170615260829063
Validation loss: 2.6662721848450333

Epoch: 5| Step: 9
Training loss: 3.0705712284634243
Validation loss: 2.6617586608458628

Epoch: 5| Step: 10
Training loss: 3.0187516680410766
Validation loss: 2.6587687258455786

Epoch: 283| Step: 0
Training loss: 2.7306685258640475
Validation loss: 2.657419966475545

Epoch: 5| Step: 1
Training loss: 3.0111971748630677
Validation loss: 2.6529274415627744

Epoch: 5| Step: 2
Training loss: 3.5094432141407856
Validation loss: 2.650922549248475

Epoch: 5| Step: 3
Training loss: 3.1399662978192024
Validation loss: 2.6540967809769302

Epoch: 5| Step: 4
Training loss: 3.3205620885052225
Validation loss: 2.649288684295932

Epoch: 5| Step: 5
Training loss: 3.427739104786623
Validation loss: 2.651106996893935

Epoch: 5| Step: 6
Training loss: 2.6471903967726114
Validation loss: 2.6581447910435747

Epoch: 5| Step: 7
Training loss: 2.8268500557675442
Validation loss: 2.6563998812831975

Epoch: 5| Step: 8
Training loss: 3.086044271046494
Validation loss: 2.663864419475525

Epoch: 5| Step: 9
Training loss: 2.2706790720021544
Validation loss: 2.6774811922872397

Epoch: 5| Step: 10
Training loss: 2.428543852000385
Validation loss: 2.6659537491681053

Epoch: 284| Step: 0
Training loss: 3.1370668515009577
Validation loss: 2.6588530977011233

Epoch: 5| Step: 1
Training loss: 2.5867619885581314
Validation loss: 2.6574168625180725

Epoch: 5| Step: 2
Training loss: 2.0289319236168044
Validation loss: 2.656592292133138

Epoch: 5| Step: 3
Training loss: 2.816128996219091
Validation loss: 2.6608719418258673

Epoch: 5| Step: 4
Training loss: 2.456838530485952
Validation loss: 2.653561336807938

Epoch: 5| Step: 5
Training loss: 3.0486823565809744
Validation loss: 2.6540374845222963

Epoch: 5| Step: 6
Training loss: 3.7702169318483256
Validation loss: 2.6555498004971736

Epoch: 5| Step: 7
Training loss: 3.271226668954283
Validation loss: 2.655593278400738

Epoch: 5| Step: 8
Training loss: 3.088918747593701
Validation loss: 2.654417984430814

Epoch: 5| Step: 9
Training loss: 3.349666601643078
Validation loss: 2.6507144488065824

Epoch: 5| Step: 10
Training loss: 2.8471781430024223
Validation loss: 2.6509154692837433

Epoch: 285| Step: 0
Training loss: 3.360118411112075
Validation loss: 2.645989107664401

Epoch: 5| Step: 1
Training loss: 3.03639084144993
Validation loss: 2.6521975813343355

Epoch: 5| Step: 2
Training loss: 3.1497200372201672
Validation loss: 2.6526954373378326

Epoch: 5| Step: 3
Training loss: 2.8325408687488207
Validation loss: 2.654983475288419

Epoch: 5| Step: 4
Training loss: 2.441428124902001
Validation loss: 2.650481384228931

Epoch: 5| Step: 5
Training loss: 3.095191388598719
Validation loss: 2.651036897585668

Epoch: 5| Step: 6
Training loss: 3.449602773161359
Validation loss: 2.6600635512352797

Epoch: 5| Step: 7
Training loss: 2.4470211798994934
Validation loss: 2.6471091900365575

Epoch: 5| Step: 8
Training loss: 2.676268595845143
Validation loss: 2.6523146535839146

Epoch: 5| Step: 9
Training loss: 2.900768730615322
Validation loss: 2.6482382720684075

Epoch: 5| Step: 10
Training loss: 3.2338959712351594
Validation loss: 2.6453550269922843

Epoch: 286| Step: 0
Training loss: 3.60035801272932
Validation loss: 2.6481733631767095

Epoch: 5| Step: 1
Training loss: 2.809950032859002
Validation loss: 2.6541016917009954

Epoch: 5| Step: 2
Training loss: 3.075617354534083
Validation loss: 2.667353920925029

Epoch: 5| Step: 3
Training loss: 2.609469109397149
Validation loss: 2.665355274037843

Epoch: 5| Step: 4
Training loss: 3.066322898946794
Validation loss: 2.6851369070172306

Epoch: 5| Step: 5
Training loss: 2.521646909550203
Validation loss: 2.677043706856728

Epoch: 5| Step: 6
Training loss: 3.1111107970040783
Validation loss: 2.67548313311015

Epoch: 5| Step: 7
Training loss: 2.9778711841256005
Validation loss: 2.6659656674885275

Epoch: 5| Step: 8
Training loss: 2.7531327696743637
Validation loss: 2.64984272269365

Epoch: 5| Step: 9
Training loss: 3.279735688050438
Validation loss: 2.648859749588114

Epoch: 5| Step: 10
Training loss: 2.8632314555377736
Validation loss: 2.6478161334741777

Epoch: 287| Step: 0
Training loss: 3.5931958642070554
Validation loss: 2.652060806362663

Epoch: 5| Step: 1
Training loss: 2.6283722061575605
Validation loss: 2.654253160473665

Epoch: 5| Step: 2
Training loss: 2.6270932525358766
Validation loss: 2.64901826055446

Epoch: 5| Step: 3
Training loss: 3.2939626838594713
Validation loss: 2.6597843256804157

Epoch: 5| Step: 4
Training loss: 2.818171229859986
Validation loss: 2.6529132401326754

Epoch: 5| Step: 5
Training loss: 2.7440025647821478
Validation loss: 2.6523220352481762

Epoch: 5| Step: 6
Training loss: 2.809935863210918
Validation loss: 2.6549507375298624

Epoch: 5| Step: 7
Training loss: 2.996477761458368
Validation loss: 2.651774168501133

Epoch: 5| Step: 8
Training loss: 2.6692400873165743
Validation loss: 2.6545444608388897

Epoch: 5| Step: 9
Training loss: 3.2018602805215353
Validation loss: 2.6566910775017916

Epoch: 5| Step: 10
Training loss: 3.3324223386124547
Validation loss: 2.66227680364403

Epoch: 288| Step: 0
Training loss: 2.6491352613742922
Validation loss: 2.6553621838814188

Epoch: 5| Step: 1
Training loss: 2.6914787116628793
Validation loss: 2.657003084831459

Epoch: 5| Step: 2
Training loss: 3.1831088767550595
Validation loss: 2.6583994855225646

Epoch: 5| Step: 3
Training loss: 3.264199269644585
Validation loss: 2.661820014912122

Epoch: 5| Step: 4
Training loss: 3.161617436351649
Validation loss: 2.6619789907095233

Epoch: 5| Step: 5
Training loss: 2.9258950062373077
Validation loss: 2.6561826037471232

Epoch: 5| Step: 6
Training loss: 2.76710806699763
Validation loss: 2.660545338133468

Epoch: 5| Step: 7
Training loss: 3.126122845150003
Validation loss: 2.6575222976062927

Epoch: 5| Step: 8
Training loss: 2.9562148626388636
Validation loss: 2.6593910933340283

Epoch: 5| Step: 9
Training loss: 2.7348997647958186
Validation loss: 2.663912445481688

Epoch: 5| Step: 10
Training loss: 3.2585138165244087
Validation loss: 2.661421970847644

Epoch: 289| Step: 0
Training loss: 3.662152864325105
Validation loss: 2.657971897628748

Epoch: 5| Step: 1
Training loss: 2.765413955136142
Validation loss: 2.66209830805448

Epoch: 5| Step: 2
Training loss: 2.922447760435691
Validation loss: 2.6670713710426455

Epoch: 5| Step: 3
Training loss: 3.1736917037988612
Validation loss: 2.669313892144261

Epoch: 5| Step: 4
Training loss: 3.0314186285248015
Validation loss: 2.6719333249164174

Epoch: 5| Step: 5
Training loss: 3.05821831787483
Validation loss: 2.6773826961945715

Epoch: 5| Step: 6
Training loss: 1.7018330424639183
Validation loss: 2.673639954811474

Epoch: 5| Step: 7
Training loss: 3.619570908801591
Validation loss: 2.6564153080556707

Epoch: 5| Step: 8
Training loss: 2.0779073500846685
Validation loss: 2.666934519692605

Epoch: 5| Step: 9
Training loss: 2.8877620231345764
Validation loss: 2.6626343914991346

Epoch: 5| Step: 10
Training loss: 3.339157801452044
Validation loss: 2.650580379937473

Epoch: 290| Step: 0
Training loss: 2.4956343680305544
Validation loss: 2.655956175331385

Epoch: 5| Step: 1
Training loss: 2.596068575401516
Validation loss: 2.6503912479211498

Epoch: 5| Step: 2
Training loss: 3.122934498056338
Validation loss: 2.662262507643325

Epoch: 5| Step: 3
Training loss: 2.988981516449419
Validation loss: 2.6514417102829815

Epoch: 5| Step: 4
Training loss: 3.311512493991797
Validation loss: 2.653264546659315

Epoch: 5| Step: 5
Training loss: 3.0243166254081624
Validation loss: 2.657150214455229

Epoch: 5| Step: 6
Training loss: 3.067002392788138
Validation loss: 2.6678310798317324

Epoch: 5| Step: 7
Training loss: 2.6423498535807597
Validation loss: 2.6578761914304385

Epoch: 5| Step: 8
Training loss: 2.7027289480790833
Validation loss: 2.6553870983734136

Epoch: 5| Step: 9
Training loss: 3.6471612891473795
Validation loss: 2.6560412600569587

Epoch: 5| Step: 10
Training loss: 2.8899523803061204
Validation loss: 2.6490688667045257

Epoch: 291| Step: 0
Training loss: 2.552702806506697
Validation loss: 2.652828655203513

Epoch: 5| Step: 1
Training loss: 3.4399169747735137
Validation loss: 2.6505988079299243

Epoch: 5| Step: 2
Training loss: 2.9875878420887942
Validation loss: 2.6516394677415986

Epoch: 5| Step: 3
Training loss: 3.1674275906181473
Validation loss: 2.651396537005991

Epoch: 5| Step: 4
Training loss: 3.231333606457356
Validation loss: 2.6602644347901854

Epoch: 5| Step: 5
Training loss: 2.837078947176946
Validation loss: 2.650842950053281

Epoch: 5| Step: 6
Training loss: 2.8994234366954386
Validation loss: 2.653309785719649

Epoch: 5| Step: 7
Training loss: 2.460117845426314
Validation loss: 2.653886751120097

Epoch: 5| Step: 8
Training loss: 2.9471387791623553
Validation loss: 2.6558006625592046

Epoch: 5| Step: 9
Training loss: 3.1113996958477994
Validation loss: 2.6650265253453056

Epoch: 5| Step: 10
Training loss: 2.90768282445899
Validation loss: 2.6639997512018825

Epoch: 292| Step: 0
Training loss: 3.237876286971361
Validation loss: 2.6709264887366495

Epoch: 5| Step: 1
Training loss: 2.6153027480676676
Validation loss: 2.650996164868261

Epoch: 5| Step: 2
Training loss: 2.758535403852976
Validation loss: 2.648940175841823

Epoch: 5| Step: 3
Training loss: 3.1856983553422737
Validation loss: 2.645350598154797

Epoch: 5| Step: 4
Training loss: 3.250489418152216
Validation loss: 2.6417381482558726

Epoch: 5| Step: 5
Training loss: 3.073192846958545
Validation loss: 2.6436335868284453

Epoch: 5| Step: 6
Training loss: 3.261165658804011
Validation loss: 2.649605850546085

Epoch: 5| Step: 7
Training loss: 2.654295437821539
Validation loss: 2.644536723295144

Epoch: 5| Step: 8
Training loss: 2.8643552007288453
Validation loss: 2.6453082670101087

Epoch: 5| Step: 9
Training loss: 3.0991565972171697
Validation loss: 2.6443967736097727

Epoch: 5| Step: 10
Training loss: 2.572901294574814
Validation loss: 2.6464748294456717

Epoch: 293| Step: 0
Training loss: 3.1370309790704107
Validation loss: 2.6493690965609322

Epoch: 5| Step: 1
Training loss: 2.6123831763909613
Validation loss: 2.6548213767549202

Epoch: 5| Step: 2
Training loss: 2.8589463876805796
Validation loss: 2.6652730173238033

Epoch: 5| Step: 3
Training loss: 2.8664386821252235
Validation loss: 2.6609409525253134

Epoch: 5| Step: 4
Training loss: 2.9989254934551823
Validation loss: 2.6716342595207667

Epoch: 5| Step: 5
Training loss: 2.6093589188314352
Validation loss: 2.6972754555804688

Epoch: 5| Step: 6
Training loss: 3.042326363566804
Validation loss: 2.717451785862188

Epoch: 5| Step: 7
Training loss: 3.248324329043403
Validation loss: 2.7464400766967487

Epoch: 5| Step: 8
Training loss: 2.8844222869799188
Validation loss: 2.737275313182744

Epoch: 5| Step: 9
Training loss: 3.256634323079245
Validation loss: 2.7254693835679644

Epoch: 5| Step: 10
Training loss: 3.314516857031268
Validation loss: 2.7023075538590904

Epoch: 294| Step: 0
Training loss: 2.9751011422539277
Validation loss: 2.668220955996549

Epoch: 5| Step: 1
Training loss: 2.650292930967081
Validation loss: 2.659141918747761

Epoch: 5| Step: 2
Training loss: 2.859098160479938
Validation loss: 2.653664435507498

Epoch: 5| Step: 3
Training loss: 3.0814423475911927
Validation loss: 2.641166267956034

Epoch: 5| Step: 4
Training loss: 3.1265643972441612
Validation loss: 2.6424866014822874

Epoch: 5| Step: 5
Training loss: 3.002994155812047
Validation loss: 2.6465957950531047

Epoch: 5| Step: 6
Training loss: 3.1713030820981762
Validation loss: 2.6417588369228144

Epoch: 5| Step: 7
Training loss: 2.7662902721536673
Validation loss: 2.641088833440748

Epoch: 5| Step: 8
Training loss: 3.0667666861214746
Validation loss: 2.64336913533492

Epoch: 5| Step: 9
Training loss: 2.938059489759976
Validation loss: 2.6391017865358797

Epoch: 5| Step: 10
Training loss: 3.0209011903354304
Validation loss: 2.6431598548564907

Epoch: 295| Step: 0
Training loss: 3.1879910857436164
Validation loss: 2.641284240693592

Epoch: 5| Step: 1
Training loss: 2.923904937774832
Validation loss: 2.635535756006816

Epoch: 5| Step: 2
Training loss: 3.546948133882581
Validation loss: 2.6404022901498947

Epoch: 5| Step: 3
Training loss: 2.3937683383647568
Validation loss: 2.641160557632399

Epoch: 5| Step: 4
Training loss: 3.2751763216266907
Validation loss: 2.6419316375883524

Epoch: 5| Step: 5
Training loss: 2.778418481899205
Validation loss: 2.6365045927363338

Epoch: 5| Step: 6
Training loss: 2.9815663807612505
Validation loss: 2.6382708952971403

Epoch: 5| Step: 7
Training loss: 2.911893881404764
Validation loss: 2.638244683223997

Epoch: 5| Step: 8
Training loss: 2.682794043644654
Validation loss: 2.6402277455005896

Epoch: 5| Step: 9
Training loss: 2.592955410133705
Validation loss: 2.638729624178037

Epoch: 5| Step: 10
Training loss: 3.317054640220154
Validation loss: 2.6425536582432647

Epoch: 296| Step: 0
Training loss: 3.203440283168573
Validation loss: 2.6609981943329157

Epoch: 5| Step: 1
Training loss: 2.935908759089631
Validation loss: 2.6532293257278705

Epoch: 5| Step: 2
Training loss: 2.580209525124361
Validation loss: 2.6552696102938604

Epoch: 5| Step: 3
Training loss: 3.3927373678534276
Validation loss: 2.6547595442012875

Epoch: 5| Step: 4
Training loss: 2.589730791070946
Validation loss: 2.674786283465841

Epoch: 5| Step: 5
Training loss: 2.6788771046198616
Validation loss: 2.67148819244988

Epoch: 5| Step: 6
Training loss: 3.220079906490988
Validation loss: 2.6621088376398028

Epoch: 5| Step: 7
Training loss: 3.3942835885362816
Validation loss: 2.6729985860886654

Epoch: 5| Step: 8
Training loss: 2.3428126177228674
Validation loss: 2.6686383202033976

Epoch: 5| Step: 9
Training loss: 3.0328317821426256
Validation loss: 2.6842780234265127

Epoch: 5| Step: 10
Training loss: 3.1959035462015333
Validation loss: 2.663680012122954

Epoch: 297| Step: 0
Training loss: 2.744438356151683
Validation loss: 2.655671673333252

Epoch: 5| Step: 1
Training loss: 2.969616733315201
Validation loss: 2.660634436691425

Epoch: 5| Step: 2
Training loss: 3.295700804259806
Validation loss: 2.649489538150029

Epoch: 5| Step: 3
Training loss: 2.966491000371591
Validation loss: 2.64945486888879

Epoch: 5| Step: 4
Training loss: 2.5603246992545285
Validation loss: 2.647838030408841

Epoch: 5| Step: 5
Training loss: 2.548812690775827
Validation loss: 2.6456892907586425

Epoch: 5| Step: 6
Training loss: 3.4853976677655907
Validation loss: 2.6558280141539146

Epoch: 5| Step: 7
Training loss: 2.953221233757738
Validation loss: 2.6603734381291724

Epoch: 5| Step: 8
Training loss: 3.289602058716512
Validation loss: 2.655945529655264

Epoch: 5| Step: 9
Training loss: 3.010439669159299
Validation loss: 2.6398061400244566

Epoch: 5| Step: 10
Training loss: 2.6101494285222615
Validation loss: 2.643348967955403

Epoch: 298| Step: 0
Training loss: 3.2482224518465
Validation loss: 2.645397279861149

Epoch: 5| Step: 1
Training loss: 3.1060775064204553
Validation loss: 2.6429887465965436

Epoch: 5| Step: 2
Training loss: 3.08516480634734
Validation loss: 2.6481134413219185

Epoch: 5| Step: 3
Training loss: 2.5802287448347263
Validation loss: 2.6434478399359254

Epoch: 5| Step: 4
Training loss: 2.637061067188722
Validation loss: 2.6479170654505184

Epoch: 5| Step: 5
Training loss: 3.303548702323834
Validation loss: 2.64526450473274

Epoch: 5| Step: 6
Training loss: 2.808694681149976
Validation loss: 2.6424812946896816

Epoch: 5| Step: 7
Training loss: 2.6398252822397077
Validation loss: 2.6402839672942906

Epoch: 5| Step: 8
Training loss: 2.8878389696258595
Validation loss: 2.6343407202365468

Epoch: 5| Step: 9
Training loss: 2.7318792670117777
Validation loss: 2.636694319295482

Epoch: 5| Step: 10
Training loss: 3.5026405455485725
Validation loss: 2.6301535340047333

Epoch: 299| Step: 0
Training loss: 3.250162707437413
Validation loss: 2.6323745639364207

Epoch: 5| Step: 1
Training loss: 2.8655726903303105
Validation loss: 2.6443560578558545

Epoch: 5| Step: 2
Training loss: 3.1734870610013166
Validation loss: 2.643082876424217

Epoch: 5| Step: 3
Training loss: 2.887161241616965
Validation loss: 2.6424386148834533

Epoch: 5| Step: 4
Training loss: 2.8952314634145586
Validation loss: 2.654914159096021

Epoch: 5| Step: 5
Training loss: 2.8993586390058965
Validation loss: 2.644767971782686

Epoch: 5| Step: 6
Training loss: 2.924922720385455
Validation loss: 2.6409020649580595

Epoch: 5| Step: 7
Training loss: 3.173495174843639
Validation loss: 2.639311855516854

Epoch: 5| Step: 8
Training loss: 2.796476026667243
Validation loss: 2.631517830710014

Epoch: 5| Step: 9
Training loss: 2.876408273519119
Validation loss: 2.630757458235004

Epoch: 5| Step: 10
Training loss: 2.825802012339055
Validation loss: 2.6320460847678175

Epoch: 300| Step: 0
Training loss: 2.906339582477718
Validation loss: 2.627611232691032

Epoch: 5| Step: 1
Training loss: 2.7323374104618514
Validation loss: 2.634002008844272

Epoch: 5| Step: 2
Training loss: 3.323746644327192
Validation loss: 2.6282354495942104

Epoch: 5| Step: 3
Training loss: 2.7127814713799565
Validation loss: 2.6248680146022116

Epoch: 5| Step: 4
Training loss: 3.401627930628242
Validation loss: 2.6365350780981824

Epoch: 5| Step: 5
Training loss: 3.007032734252849
Validation loss: 2.6325893726862106

Epoch: 5| Step: 6
Training loss: 2.8734360463074933
Validation loss: 2.63648395229712

Epoch: 5| Step: 7
Training loss: 2.756274175213521
Validation loss: 2.6276968059508627

Epoch: 5| Step: 8
Training loss: 3.0726006986599743
Validation loss: 2.629228538855279

Epoch: 5| Step: 9
Training loss: 3.0028769685413024
Validation loss: 2.6253918727845162

Epoch: 5| Step: 10
Training loss: 2.737600462302476
Validation loss: 2.6279346159044423

Epoch: 301| Step: 0
Training loss: 3.074731960864971
Validation loss: 2.6316739172737766

Epoch: 5| Step: 1
Training loss: 2.779776021867677
Validation loss: 2.628759710441712

Epoch: 5| Step: 2
Training loss: 3.0320708746263376
Validation loss: 2.630649304449721

Epoch: 5| Step: 3
Training loss: 3.3690518840215273
Validation loss: 2.642240793633259

Epoch: 5| Step: 4
Training loss: 2.6365737988224343
Validation loss: 2.6361542201067962

Epoch: 5| Step: 5
Training loss: 3.095101725889396
Validation loss: 2.6396944819431756

Epoch: 5| Step: 6
Training loss: 3.5473438910881794
Validation loss: 2.642611400201723

Epoch: 5| Step: 7
Training loss: 2.460060181230508
Validation loss: 2.639766540224668

Epoch: 5| Step: 8
Training loss: 2.760838218505787
Validation loss: 2.6478179052969013

Epoch: 5| Step: 9
Training loss: 3.1327478111989446
Validation loss: 2.6421715264020573

Epoch: 5| Step: 10
Training loss: 2.508193608022213
Validation loss: 2.633336893247745

Epoch: 302| Step: 0
Training loss: 2.527871219831567
Validation loss: 2.633028454056155

Epoch: 5| Step: 1
Training loss: 3.26819783027287
Validation loss: 2.6423390667371005

Epoch: 5| Step: 2
Training loss: 2.850032197201542
Validation loss: 2.633361397935452

Epoch: 5| Step: 3
Training loss: 2.7608354550702843
Validation loss: 2.6355329779145453

Epoch: 5| Step: 4
Training loss: 3.181426301578889
Validation loss: 2.6360573463877643

Epoch: 5| Step: 5
Training loss: 2.919087595070643
Validation loss: 2.6373821417863432

Epoch: 5| Step: 6
Training loss: 3.2822976029484727
Validation loss: 2.631971746259392

Epoch: 5| Step: 7
Training loss: 3.104903950702955
Validation loss: 2.6359326672433276

Epoch: 5| Step: 8
Training loss: 2.6794450388840123
Validation loss: 2.633269718606886

Epoch: 5| Step: 9
Training loss: 2.767987034646027
Validation loss: 2.6285594192180035

Epoch: 5| Step: 10
Training loss: 3.096346449568329
Validation loss: 2.6332680382453497

Epoch: 303| Step: 0
Training loss: 2.7322932575050074
Validation loss: 2.6312822055012464

Epoch: 5| Step: 1
Training loss: 2.6913607168567624
Validation loss: 2.6351587919288013

Epoch: 5| Step: 2
Training loss: 2.8882783179336617
Validation loss: 2.626541858774095

Epoch: 5| Step: 3
Training loss: 3.1514573676862963
Validation loss: 2.62928533271817

Epoch: 5| Step: 4
Training loss: 3.6074660236030214
Validation loss: 2.6328935615254294

Epoch: 5| Step: 5
Training loss: 2.3729596659644145
Validation loss: 2.6317665386370486

Epoch: 5| Step: 6
Training loss: 2.936341726949838
Validation loss: 2.638585381000233

Epoch: 5| Step: 7
Training loss: 2.940348279137101
Validation loss: 2.63843931489434

Epoch: 5| Step: 8
Training loss: 2.8009592422685063
Validation loss: 2.644104150697441

Epoch: 5| Step: 9
Training loss: 3.155243968206162
Validation loss: 2.6632995610037247

Epoch: 5| Step: 10
Training loss: 3.1273181709350815
Validation loss: 2.666968590682199

Epoch: 304| Step: 0
Training loss: 2.796996811925976
Validation loss: 2.6514778290130017

Epoch: 5| Step: 1
Training loss: 3.034285922564894
Validation loss: 2.64661916958544

Epoch: 5| Step: 2
Training loss: 2.892313036468863
Validation loss: 2.635495104715398

Epoch: 5| Step: 3
Training loss: 2.5675577631528497
Validation loss: 2.6337531976134207

Epoch: 5| Step: 4
Training loss: 3.1235474834762416
Validation loss: 2.62596332728527

Epoch: 5| Step: 5
Training loss: 2.9047677146502124
Validation loss: 2.6259595920860974

Epoch: 5| Step: 6
Training loss: 2.9078071278517847
Validation loss: 2.62017144367195

Epoch: 5| Step: 7
Training loss: 2.9334432306799583
Validation loss: 2.6234806554761834

Epoch: 5| Step: 8
Training loss: 3.0915039849129924
Validation loss: 2.6224908121210966

Epoch: 5| Step: 9
Training loss: 3.3243924553892144
Validation loss: 2.626495956613843

Epoch: 5| Step: 10
Training loss: 2.9330504786780662
Validation loss: 2.625566664560005

Epoch: 305| Step: 0
Training loss: 2.5589047774337255
Validation loss: 2.624250540365408

Epoch: 5| Step: 1
Training loss: 3.52022729356561
Validation loss: 2.622964594825829

Epoch: 5| Step: 2
Training loss: 3.117655248133735
Validation loss: 2.622053784155459

Epoch: 5| Step: 3
Training loss: 3.4740903143950135
Validation loss: 2.621106977527047

Epoch: 5| Step: 4
Training loss: 2.5828261544108404
Validation loss: 2.6220627371439

Epoch: 5| Step: 5
Training loss: 2.8838128729333654
Validation loss: 2.6224454627468243

Epoch: 5| Step: 6
Training loss: 2.915658467745684
Validation loss: 2.6228061665422873

Epoch: 5| Step: 7
Training loss: 2.9582064068568386
Validation loss: 2.6225807098785525

Epoch: 5| Step: 8
Training loss: 2.8083762560845984
Validation loss: 2.632365011041872

Epoch: 5| Step: 9
Training loss: 2.9857559604043886
Validation loss: 2.6294553237833984

Epoch: 5| Step: 10
Training loss: 2.4550509333716923
Validation loss: 2.630511439762321

Epoch: 306| Step: 0
Training loss: 2.88802852004702
Validation loss: 2.6330658437883234

Epoch: 5| Step: 1
Training loss: 2.5560713353478066
Validation loss: 2.6615790767639615

Epoch: 5| Step: 2
Training loss: 2.673253289480673
Validation loss: 2.6854753931102575

Epoch: 5| Step: 3
Training loss: 3.2222185427180654
Validation loss: 2.700511596814516

Epoch: 5| Step: 4
Training loss: 2.759122801992439
Validation loss: 2.7081197996813713

Epoch: 5| Step: 5
Training loss: 2.9186388341739278
Validation loss: 2.7186763189089

Epoch: 5| Step: 6
Training loss: 3.2312940583462697
Validation loss: 2.700904479956235

Epoch: 5| Step: 7
Training loss: 3.09039031739403
Validation loss: 2.679332053168606

Epoch: 5| Step: 8
Training loss: 2.99024362394471
Validation loss: 2.6465046274640582

Epoch: 5| Step: 9
Training loss: 2.9614044867974094
Validation loss: 2.6240962260391925

Epoch: 5| Step: 10
Training loss: 3.309003748255544
Validation loss: 2.623166356517346

Epoch: 307| Step: 0
Training loss: 3.1970049193114423
Validation loss: 2.6336123205646063

Epoch: 5| Step: 1
Training loss: 2.6277608430929233
Validation loss: 2.6387572129548063

Epoch: 5| Step: 2
Training loss: 2.881104498311019
Validation loss: 2.6370927467188743

Epoch: 5| Step: 3
Training loss: 2.799868979113383
Validation loss: 2.6384725354126335

Epoch: 5| Step: 4
Training loss: 2.964654285674695
Validation loss: 2.641307230316176

Epoch: 5| Step: 5
Training loss: 2.7863462241368566
Validation loss: 2.6446054002626296

Epoch: 5| Step: 6
Training loss: 3.393918033605916
Validation loss: 2.6469249335486404

Epoch: 5| Step: 7
Training loss: 2.984682556601972
Validation loss: 2.6405560107708155

Epoch: 5| Step: 8
Training loss: 3.107046511053638
Validation loss: 2.6404629947862768

Epoch: 5| Step: 9
Training loss: 3.5246321520047736
Validation loss: 2.639070561460549

Epoch: 5| Step: 10
Training loss: 2.345151151816386
Validation loss: 2.6384235410744727

Epoch: 308| Step: 0
Training loss: 3.248716687878927
Validation loss: 2.6330746356825117

Epoch: 5| Step: 1
Training loss: 2.6161777655138505
Validation loss: 2.639577610429787

Epoch: 5| Step: 2
Training loss: 2.9575065926150237
Validation loss: 2.6469745821473216

Epoch: 5| Step: 3
Training loss: 3.0267996612883374
Validation loss: 2.6490411462826455

Epoch: 5| Step: 4
Training loss: 2.787653633981549
Validation loss: 2.6460256961202346

Epoch: 5| Step: 5
Training loss: 3.080935826253238
Validation loss: 2.6419862278747814

Epoch: 5| Step: 6
Training loss: 2.904046648812061
Validation loss: 2.649749035211323

Epoch: 5| Step: 7
Training loss: 3.2299717217497776
Validation loss: 2.6503794472161006

Epoch: 5| Step: 8
Training loss: 2.8116491938215606
Validation loss: 2.654980967635194

Epoch: 5| Step: 9
Training loss: 2.9298167289206805
Validation loss: 2.6622136304564012

Epoch: 5| Step: 10
Training loss: 3.0425371640144645
Validation loss: 2.6681302294599196

Epoch: 309| Step: 0
Training loss: 3.0548357915372204
Validation loss: 2.6690582999138313

Epoch: 5| Step: 1
Training loss: 2.767380152091318
Validation loss: 2.6758363808345496

Epoch: 5| Step: 2
Training loss: 2.484240738221776
Validation loss: 2.683492807143489

Epoch: 5| Step: 3
Training loss: 3.2460840548704497
Validation loss: 2.666990491858168

Epoch: 5| Step: 4
Training loss: 3.3034518481671835
Validation loss: 2.6658214064576193

Epoch: 5| Step: 5
Training loss: 2.906714617599062
Validation loss: 2.684176230482157

Epoch: 5| Step: 6
Training loss: 2.1537547393410157
Validation loss: 2.679733667735625

Epoch: 5| Step: 7
Training loss: 3.179846157455264
Validation loss: 2.66953541538625

Epoch: 5| Step: 8
Training loss: 3.2514391427056206
Validation loss: 2.6703706027536973

Epoch: 5| Step: 9
Training loss: 3.4522433298927617
Validation loss: 2.665141221807284

Epoch: 5| Step: 10
Training loss: 2.6275215753455288
Validation loss: 2.6516742993834934

Epoch: 310| Step: 0
Training loss: 2.688888545951436
Validation loss: 2.6406068004552083

Epoch: 5| Step: 1
Training loss: 2.871821761442062
Validation loss: 2.6324623332455737

Epoch: 5| Step: 2
Training loss: 3.277329927945004
Validation loss: 2.6278988808606374

Epoch: 5| Step: 3
Training loss: 2.7551022793430215
Validation loss: 2.623304728885375

Epoch: 5| Step: 4
Training loss: 2.9013798423550172
Validation loss: 2.6254479670111315

Epoch: 5| Step: 5
Training loss: 2.334033713357961
Validation loss: 2.624950472925572

Epoch: 5| Step: 6
Training loss: 3.2359846597032056
Validation loss: 2.626397684173229

Epoch: 5| Step: 7
Training loss: 2.6375629797191316
Validation loss: 2.629679527151449

Epoch: 5| Step: 8
Training loss: 2.9825609695585085
Validation loss: 2.6288129495612163

Epoch: 5| Step: 9
Training loss: 3.6163546631241124
Validation loss: 2.6375239449849586

Epoch: 5| Step: 10
Training loss: 3.039521405794297
Validation loss: 2.6501253236951077

Epoch: 311| Step: 0
Training loss: 2.9750660416140904
Validation loss: 2.6470301831721668

Epoch: 5| Step: 1
Training loss: 2.7828959191749245
Validation loss: 2.6523161324314843

Epoch: 5| Step: 2
Training loss: 3.7634335547843616
Validation loss: 2.641375811696457

Epoch: 5| Step: 3
Training loss: 3.055534381985755
Validation loss: 2.634498674312802

Epoch: 5| Step: 4
Training loss: 2.4496593900309382
Validation loss: 2.6318149126938146

Epoch: 5| Step: 5
Training loss: 2.4374365186983487
Validation loss: 2.6324576071155867

Epoch: 5| Step: 6
Training loss: 3.0164468070432933
Validation loss: 2.623774326833917

Epoch: 5| Step: 7
Training loss: 3.0459724850229035
Validation loss: 2.6259470479870557

Epoch: 5| Step: 8
Training loss: 2.9895010658845407
Validation loss: 2.6169984134843856

Epoch: 5| Step: 9
Training loss: 3.034337938673644
Validation loss: 2.6235643299956832

Epoch: 5| Step: 10
Training loss: 2.6917870505450794
Validation loss: 2.626462551424377

Epoch: 312| Step: 0
Training loss: 2.8570483805158777
Validation loss: 2.635270912633732

Epoch: 5| Step: 1
Training loss: 2.6376329433689807
Validation loss: 2.6423743086417524

Epoch: 5| Step: 2
Training loss: 3.1719005564895615
Validation loss: 2.6372378939268772

Epoch: 5| Step: 3
Training loss: 3.2335189202390553
Validation loss: 2.635882940990305

Epoch: 5| Step: 4
Training loss: 3.0619822473192015
Validation loss: 2.644255924565578

Epoch: 5| Step: 5
Training loss: 3.046432541241069
Validation loss: 2.6246020488604622

Epoch: 5| Step: 6
Training loss: 2.703763324142125
Validation loss: 2.6170281200217036

Epoch: 5| Step: 7
Training loss: 3.1604450409800933
Validation loss: 2.6223650069799214

Epoch: 5| Step: 8
Training loss: 2.91024063295237
Validation loss: 2.622180856630228

Epoch: 5| Step: 9
Training loss: 2.039286283293018
Validation loss: 2.6204773068409843

Epoch: 5| Step: 10
Training loss: 3.467945177342306
Validation loss: 2.621983522129242

Epoch: 313| Step: 0
Training loss: 2.7032141698341148
Validation loss: 2.6217843149126665

Epoch: 5| Step: 1
Training loss: 3.320118330719625
Validation loss: 2.6171579686523496

Epoch: 5| Step: 2
Training loss: 2.9782410541990223
Validation loss: 2.6187230216390525

Epoch: 5| Step: 3
Training loss: 3.0534101776659046
Validation loss: 2.6197895288239526

Epoch: 5| Step: 4
Training loss: 3.2550361933651657
Validation loss: 2.6195046915111435

Epoch: 5| Step: 5
Training loss: 3.173411631326125
Validation loss: 2.612669481873006

Epoch: 5| Step: 6
Training loss: 2.875242471836173
Validation loss: 2.6222219724294673

Epoch: 5| Step: 7
Training loss: 2.6377230617697607
Validation loss: 2.62729617497565

Epoch: 5| Step: 8
Training loss: 2.712340769510935
Validation loss: 2.623276335532023

Epoch: 5| Step: 9
Training loss: 2.3952757034411727
Validation loss: 2.6284657368152557

Epoch: 5| Step: 10
Training loss: 3.205150131541837
Validation loss: 2.634382102658074

Epoch: 314| Step: 0
Training loss: 3.0069228404744432
Validation loss: 2.6453642238324404

Epoch: 5| Step: 1
Training loss: 3.1035051771771904
Validation loss: 2.6553260600595667

Epoch: 5| Step: 2
Training loss: 3.0022607867818785
Validation loss: 2.670494030226781

Epoch: 5| Step: 3
Training loss: 2.5315007215118737
Validation loss: 2.689148855200668

Epoch: 5| Step: 4
Training loss: 2.714164286600611
Validation loss: 2.718217363092931

Epoch: 5| Step: 5
Training loss: 3.0653884656455044
Validation loss: 2.7060337059693866

Epoch: 5| Step: 6
Training loss: 2.907991113357923
Validation loss: 2.676172273737356

Epoch: 5| Step: 7
Training loss: 2.9004790732515406
Validation loss: 2.658329194691537

Epoch: 5| Step: 8
Training loss: 3.0256109582251693
Validation loss: 2.653662406747825

Epoch: 5| Step: 9
Training loss: 2.9515517146255266
Validation loss: 2.643302520666816

Epoch: 5| Step: 10
Training loss: 3.2602461180194715
Validation loss: 2.6293318847812923

Epoch: 315| Step: 0
Training loss: 3.008762120538252
Validation loss: 2.612686707382512

Epoch: 5| Step: 1
Training loss: 3.057803074934775
Validation loss: 2.629383230572112

Epoch: 5| Step: 2
Training loss: 2.963256571933723
Validation loss: 2.6214156263034982

Epoch: 5| Step: 3
Training loss: 2.6605330997122185
Validation loss: 2.621993812912731

Epoch: 5| Step: 4
Training loss: 2.9614999684777064
Validation loss: 2.626847758987483

Epoch: 5| Step: 5
Training loss: 3.2442094128393544
Validation loss: 2.6209265281144085

Epoch: 5| Step: 6
Training loss: 3.0662987951415346
Validation loss: 2.623027542902233

Epoch: 5| Step: 7
Training loss: 3.0038333879025036
Validation loss: 2.624901902045106

Epoch: 5| Step: 8
Training loss: 2.634995277299214
Validation loss: 2.623168728442022

Epoch: 5| Step: 9
Training loss: 2.588250085589528
Validation loss: 2.6263305428897477

Epoch: 5| Step: 10
Training loss: 3.389041935395336
Validation loss: 2.633501199091818

Epoch: 316| Step: 0
Training loss: 2.8332594319597812
Validation loss: 2.6231869013990154

Epoch: 5| Step: 1
Training loss: 2.756879524429611
Validation loss: 2.6332032782808334

Epoch: 5| Step: 2
Training loss: 3.097972262066858
Validation loss: 2.638999026241234

Epoch: 5| Step: 3
Training loss: 2.7474911255905767
Validation loss: 2.6456572810221397

Epoch: 5| Step: 4
Training loss: 3.631032593829024
Validation loss: 2.6747551270508354

Epoch: 5| Step: 5
Training loss: 3.007371904874912
Validation loss: 2.6665693298643784

Epoch: 5| Step: 6
Training loss: 2.3604312578666664
Validation loss: 2.65734818864185

Epoch: 5| Step: 7
Training loss: 2.7421741104885893
Validation loss: 2.6421090271526015

Epoch: 5| Step: 8
Training loss: 3.0412511323988656
Validation loss: 2.6300399308869844

Epoch: 5| Step: 9
Training loss: 3.1713707433801828
Validation loss: 2.6244083300270624

Epoch: 5| Step: 10
Training loss: 2.9550615046727753
Validation loss: 2.6211914926504094

Epoch: 317| Step: 0
Training loss: 2.127422858878153
Validation loss: 2.6184057587191654

Epoch: 5| Step: 1
Training loss: 2.782604616294338
Validation loss: 2.6174767344328633

Epoch: 5| Step: 2
Training loss: 3.4902259045259556
Validation loss: 2.6156168941931317

Epoch: 5| Step: 3
Training loss: 3.1682982173487355
Validation loss: 2.612410313292978

Epoch: 5| Step: 4
Training loss: 2.3897647681252345
Validation loss: 2.6238404294544826

Epoch: 5| Step: 5
Training loss: 3.615011462856918
Validation loss: 2.6211163513863083

Epoch: 5| Step: 6
Training loss: 3.1532006972028945
Validation loss: 2.6241442002655315

Epoch: 5| Step: 7
Training loss: 2.9235022598343985
Validation loss: 2.6308467392778985

Epoch: 5| Step: 8
Training loss: 3.1249584958181345
Validation loss: 2.6368299419941437

Epoch: 5| Step: 9
Training loss: 2.6128024131562864
Validation loss: 2.6458145633800734

Epoch: 5| Step: 10
Training loss: 2.6139099550856564
Validation loss: 2.642464273104739

Epoch: 318| Step: 0
Training loss: 2.509973658389288
Validation loss: 2.643241852146375

Epoch: 5| Step: 1
Training loss: 2.995832568625263
Validation loss: 2.6504420696686752

Epoch: 5| Step: 2
Training loss: 3.0304422777145206
Validation loss: 2.6594303315110954

Epoch: 5| Step: 3
Training loss: 3.244363445275369
Validation loss: 2.6458285015728387

Epoch: 5| Step: 4
Training loss: 2.794674993736781
Validation loss: 2.6338603197117187

Epoch: 5| Step: 5
Training loss: 3.158010765922223
Validation loss: 2.6260636904687193

Epoch: 5| Step: 6
Training loss: 2.805798493831708
Validation loss: 2.617930098757357

Epoch: 5| Step: 7
Training loss: 2.7270342137338055
Validation loss: 2.6149702783897557

Epoch: 5| Step: 8
Training loss: 2.96965719717165
Validation loss: 2.615497233449471

Epoch: 5| Step: 9
Training loss: 3.279579827448097
Validation loss: 2.6156770807408876

Epoch: 5| Step: 10
Training loss: 2.934741734021949
Validation loss: 2.6168553755823285

Epoch: 319| Step: 0
Training loss: 3.0661644323938417
Validation loss: 2.6101980352528633

Epoch: 5| Step: 1
Training loss: 2.2862822537991376
Validation loss: 2.611352454323329

Epoch: 5| Step: 2
Training loss: 2.5039108204911487
Validation loss: 2.6089586212239824

Epoch: 5| Step: 3
Training loss: 3.0391385968642015
Validation loss: 2.6076802406738837

Epoch: 5| Step: 4
Training loss: 3.0254262450493483
Validation loss: 2.6095641329638952

Epoch: 5| Step: 5
Training loss: 3.4176555381044813
Validation loss: 2.60659619283642

Epoch: 5| Step: 6
Training loss: 3.0909957185121355
Validation loss: 2.621733497944005

Epoch: 5| Step: 7
Training loss: 3.1228063895155147
Validation loss: 2.6246495069051887

Epoch: 5| Step: 8
Training loss: 2.4487449272847077
Validation loss: 2.6285388548838475

Epoch: 5| Step: 9
Training loss: 3.259533763614075
Validation loss: 2.6438968061176897

Epoch: 5| Step: 10
Training loss: 2.9343439557563107
Validation loss: 2.6493005188895453

Epoch: 320| Step: 0
Training loss: 2.574921067889145
Validation loss: 2.6638551248266413

Epoch: 5| Step: 1
Training loss: 2.5476284667801417
Validation loss: 2.6716451459074975

Epoch: 5| Step: 2
Training loss: 3.1352715104848587
Validation loss: 2.6625070736552456

Epoch: 5| Step: 3
Training loss: 3.17372851406185
Validation loss: 2.6266130510199606

Epoch: 5| Step: 4
Training loss: 3.3300116837213505
Validation loss: 2.6227986568454402

Epoch: 5| Step: 5
Training loss: 2.3890964383396103
Validation loss: 2.6111303934720445

Epoch: 5| Step: 6
Training loss: 3.1699733201116578
Validation loss: 2.6068783181101813

Epoch: 5| Step: 7
Training loss: 3.027541261198076
Validation loss: 2.6083519172602694

Epoch: 5| Step: 8
Training loss: 2.9964339996865506
Validation loss: 2.606948385416084

Epoch: 5| Step: 9
Training loss: 3.0164422227462775
Validation loss: 2.612277217793781

Epoch: 5| Step: 10
Training loss: 2.9486105992903773
Validation loss: 2.6094173128065927

Epoch: 321| Step: 0
Training loss: 2.914861083867399
Validation loss: 2.6125502896177624

Epoch: 5| Step: 1
Training loss: 2.748809556788572
Validation loss: 2.610854222482714

Epoch: 5| Step: 2
Training loss: 3.1832597241371112
Validation loss: 2.6156785063045844

Epoch: 5| Step: 3
Training loss: 2.9989041870218216
Validation loss: 2.624821162150272

Epoch: 5| Step: 4
Training loss: 2.9469326430313054
Validation loss: 2.6313545068140525

Epoch: 5| Step: 5
Training loss: 3.08952165894912
Validation loss: 2.622715531676357

Epoch: 5| Step: 6
Training loss: 3.02982855434521
Validation loss: 2.6297776603800656

Epoch: 5| Step: 7
Training loss: 2.657643928541882
Validation loss: 2.6143559460478825

Epoch: 5| Step: 8
Training loss: 2.8126787764632226
Validation loss: 2.6267309912621757

Epoch: 5| Step: 9
Training loss: 3.1490576348698247
Validation loss: 2.631912209458094

Epoch: 5| Step: 10
Training loss: 2.7582119660505255
Validation loss: 2.6236367091508694

Epoch: 322| Step: 0
Training loss: 2.934669916934834
Validation loss: 2.621307177055131

Epoch: 5| Step: 1
Training loss: 3.132836396466296
Validation loss: 2.6055722246296353

Epoch: 5| Step: 2
Training loss: 2.90966760001938
Validation loss: 2.6167324443779583

Epoch: 5| Step: 3
Training loss: 3.278110564484645
Validation loss: 2.6073780864366087

Epoch: 5| Step: 4
Training loss: 3.296718647942066
Validation loss: 2.608814963662255

Epoch: 5| Step: 5
Training loss: 2.7664009341964775
Validation loss: 2.6073463949195363

Epoch: 5| Step: 6
Training loss: 2.8897573457636576
Validation loss: 2.6078875406809585

Epoch: 5| Step: 7
Training loss: 2.7838899748699473
Validation loss: 2.608906290746154

Epoch: 5| Step: 8
Training loss: 2.6511054090669672
Validation loss: 2.604545769118255

Epoch: 5| Step: 9
Training loss: 2.678462780156756
Validation loss: 2.61050999291621

Epoch: 5| Step: 10
Training loss: 3.091161704832797
Validation loss: 2.6067265158720696

Epoch: 323| Step: 0
Training loss: 3.07583052421558
Validation loss: 2.6101442671530646

Epoch: 5| Step: 1
Training loss: 2.3869670732494104
Validation loss: 2.6116821923753046

Epoch: 5| Step: 2
Training loss: 3.4656157208826692
Validation loss: 2.6058427387562615

Epoch: 5| Step: 3
Training loss: 3.1955211170246685
Validation loss: 2.6196399368255587

Epoch: 5| Step: 4
Training loss: 2.439270257013205
Validation loss: 2.616416879165321

Epoch: 5| Step: 5
Training loss: 2.9625257595568004
Validation loss: 2.627649315135857

Epoch: 5| Step: 6
Training loss: 2.957039796522078
Validation loss: 2.6334735581724824

Epoch: 5| Step: 7
Training loss: 2.9904893483614976
Validation loss: 2.6397482512407917

Epoch: 5| Step: 8
Training loss: 2.8577165640719673
Validation loss: 2.624675417168364

Epoch: 5| Step: 9
Training loss: 2.7931591049095923
Validation loss: 2.637450948676174

Epoch: 5| Step: 10
Training loss: 3.106458513411121
Validation loss: 2.625562760853038

Epoch: 324| Step: 0
Training loss: 3.205889146512487
Validation loss: 2.6339094067186473

Epoch: 5| Step: 1
Training loss: 3.03294136602951
Validation loss: 2.6244238989394093

Epoch: 5| Step: 2
Training loss: 2.72203917331242
Validation loss: 2.6071217026972144

Epoch: 5| Step: 3
Training loss: 2.829281228114524
Validation loss: 2.610361185151987

Epoch: 5| Step: 4
Training loss: 2.1148031962931
Validation loss: 2.6115226531104394

Epoch: 5| Step: 5
Training loss: 3.1597790015479004
Validation loss: 2.611318266366146

Epoch: 5| Step: 6
Training loss: 2.679382395821987
Validation loss: 2.609644503986501

Epoch: 5| Step: 7
Training loss: 3.4639422115765157
Validation loss: 2.609185583126667

Epoch: 5| Step: 8
Training loss: 3.2858002130159947
Validation loss: 2.6121789639518744

Epoch: 5| Step: 9
Training loss: 2.8622263881733327
Validation loss: 2.602415230428143

Epoch: 5| Step: 10
Training loss: 2.8883446849226457
Validation loss: 2.6120227753685343

Epoch: 325| Step: 0
Training loss: 2.798490089931938
Validation loss: 2.60779665716517

Epoch: 5| Step: 1
Training loss: 3.2297789126573346
Validation loss: 2.607509149068861

Epoch: 5| Step: 2
Training loss: 2.841111184994866
Validation loss: 2.6169541474242526

Epoch: 5| Step: 3
Training loss: 2.491584154716959
Validation loss: 2.6188090018268073

Epoch: 5| Step: 4
Training loss: 3.507316299380677
Validation loss: 2.6194292493541633

Epoch: 5| Step: 5
Training loss: 3.141387087847239
Validation loss: 2.621929848072197

Epoch: 5| Step: 6
Training loss: 2.833835463814743
Validation loss: 2.6329998598315534

Epoch: 5| Step: 7
Training loss: 2.584454713489223
Validation loss: 2.6279374771452986

Epoch: 5| Step: 8
Training loss: 2.877652478855378
Validation loss: 2.6292958089421044

Epoch: 5| Step: 9
Training loss: 2.9217215921041446
Validation loss: 2.627753054875219

Epoch: 5| Step: 10
Training loss: 3.039119768951487
Validation loss: 2.6369658639584648

Epoch: 326| Step: 0
Training loss: 2.9385805780339993
Validation loss: 2.6194771651869506

Epoch: 5| Step: 1
Training loss: 3.268008735589033
Validation loss: 2.6142971740336294

Epoch: 5| Step: 2
Training loss: 3.0447442845301
Validation loss: 2.613741510018199

Epoch: 5| Step: 3
Training loss: 3.0498936493889435
Validation loss: 2.6029013267259202

Epoch: 5| Step: 4
Training loss: 2.9800009104068055
Validation loss: 2.610963397523178

Epoch: 5| Step: 5
Training loss: 2.3427242832028172
Validation loss: 2.612974417928283

Epoch: 5| Step: 6
Training loss: 2.5422233743135174
Validation loss: 2.602227513736156

Epoch: 5| Step: 7
Training loss: 3.1064242830257225
Validation loss: 2.6062161495528313

Epoch: 5| Step: 8
Training loss: 2.7158618362802307
Validation loss: 2.603260701911445

Epoch: 5| Step: 9
Training loss: 3.1695284878458048
Validation loss: 2.603826704579638

Epoch: 5| Step: 10
Training loss: 3.075879822445751
Validation loss: 2.603142954448515

Epoch: 327| Step: 0
Training loss: 3.1116629765765706
Validation loss: 2.6049331055646863

Epoch: 5| Step: 1
Training loss: 2.606644715349237
Validation loss: 2.601538612241025

Epoch: 5| Step: 2
Training loss: 2.4007914668622092
Validation loss: 2.599816082490989

Epoch: 5| Step: 3
Training loss: 3.271194454271071
Validation loss: 2.5999779581582314

Epoch: 5| Step: 4
Training loss: 2.9903257469404467
Validation loss: 2.602474866746119

Epoch: 5| Step: 5
Training loss: 2.9678672682805995
Validation loss: 2.608967901163843

Epoch: 5| Step: 6
Training loss: 2.836080416186254
Validation loss: 2.604081999027903

Epoch: 5| Step: 7
Training loss: 3.1326386743585535
Validation loss: 2.5995998900593578

Epoch: 5| Step: 8
Training loss: 3.135895617499495
Validation loss: 2.6018399410265256

Epoch: 5| Step: 9
Training loss: 3.1101307932835502
Validation loss: 2.596396457002145

Epoch: 5| Step: 10
Training loss: 2.6961459875227742
Validation loss: 2.5968609846134822

Epoch: 328| Step: 0
Training loss: 2.5745652100229273
Validation loss: 2.6035324719070445

Epoch: 5| Step: 1
Training loss: 3.2432600706110692
Validation loss: 2.60591224560711

Epoch: 5| Step: 2
Training loss: 3.363127276255531
Validation loss: 2.614257596759624

Epoch: 5| Step: 3
Training loss: 2.745198132255549
Validation loss: 2.6309295403033106

Epoch: 5| Step: 4
Training loss: 3.287689864909272
Validation loss: 2.629632332443671

Epoch: 5| Step: 5
Training loss: 2.848220497189491
Validation loss: 2.6152779594837545

Epoch: 5| Step: 6
Training loss: 2.6547718198608603
Validation loss: 2.6127309957017624

Epoch: 5| Step: 7
Training loss: 2.8578729071471605
Validation loss: 2.607844361071571

Epoch: 5| Step: 8
Training loss: 3.100632227754848
Validation loss: 2.608467676247314

Epoch: 5| Step: 9
Training loss: 2.8301974127292837
Validation loss: 2.6083377542320334

Epoch: 5| Step: 10
Training loss: 2.664963108544575
Validation loss: 2.6130493282857357

Epoch: 329| Step: 0
Training loss: 2.6401932944713784
Validation loss: 2.6133498860586903

Epoch: 5| Step: 1
Training loss: 3.291881377223211
Validation loss: 2.6079345720168035

Epoch: 5| Step: 2
Training loss: 2.420631236987521
Validation loss: 2.6147138233483163

Epoch: 5| Step: 3
Training loss: 3.29181532383284
Validation loss: 2.6112731902781094

Epoch: 5| Step: 4
Training loss: 2.746404204312759
Validation loss: 2.6142787421737284

Epoch: 5| Step: 5
Training loss: 2.551541879527392
Validation loss: 2.6180353526656432

Epoch: 5| Step: 6
Training loss: 2.2797344869643674
Validation loss: 2.6109410411073086

Epoch: 5| Step: 7
Training loss: 3.3799289456635586
Validation loss: 2.6206311984006367

Epoch: 5| Step: 8
Training loss: 3.4824813007583884
Validation loss: 2.614437722988405

Epoch: 5| Step: 9
Training loss: 3.096140544806285
Validation loss: 2.6135261619902272

Epoch: 5| Step: 10
Training loss: 2.848840872640477
Validation loss: 2.6157087619833783

Epoch: 330| Step: 0
Training loss: 2.8758576813821044
Validation loss: 2.611610422311764

Epoch: 5| Step: 1
Training loss: 2.7233684380026304
Validation loss: 2.602005640185613

Epoch: 5| Step: 2
Training loss: 3.0882425318828153
Validation loss: 2.609386767053283

Epoch: 5| Step: 3
Training loss: 3.096299017224425
Validation loss: 2.601893545733795

Epoch: 5| Step: 4
Training loss: 2.9350848719528377
Validation loss: 2.602687944177343

Epoch: 5| Step: 5
Training loss: 3.16097924982276
Validation loss: 2.6146533778391534

Epoch: 5| Step: 6
Training loss: 2.6343766724930746
Validation loss: 2.6087170295053443

Epoch: 5| Step: 7
Training loss: 2.8422906505621395
Validation loss: 2.61067818127198

Epoch: 5| Step: 8
Training loss: 3.160051077659272
Validation loss: 2.61140106418616

Epoch: 5| Step: 9
Training loss: 2.7209452393337283
Validation loss: 2.6067474066850624

Epoch: 5| Step: 10
Training loss: 3.0022433158678763
Validation loss: 2.63056690099428

Epoch: 331| Step: 0
Training loss: 2.267937157831711
Validation loss: 2.623816366393948

Epoch: 5| Step: 1
Training loss: 3.031497591269705
Validation loss: 2.6134066213282923

Epoch: 5| Step: 2
Training loss: 2.78413652796695
Validation loss: 2.629090730817222

Epoch: 5| Step: 3
Training loss: 3.2857370849671343
Validation loss: 2.6421837266481827

Epoch: 5| Step: 4
Training loss: 3.227327787146964
Validation loss: 2.6265441661592908

Epoch: 5| Step: 5
Training loss: 2.656125503315228
Validation loss: 2.6289569517251867

Epoch: 5| Step: 6
Training loss: 2.8054349535545264
Validation loss: 2.614565318088478

Epoch: 5| Step: 7
Training loss: 3.3350284240060417
Validation loss: 2.61316046397402

Epoch: 5| Step: 8
Training loss: 2.9120990591806724
Validation loss: 2.6039211828548314

Epoch: 5| Step: 9
Training loss: 2.6124286258566594
Validation loss: 2.605204781298054

Epoch: 5| Step: 10
Training loss: 3.293198257358349
Validation loss: 2.6026707401573876

Epoch: 332| Step: 0
Training loss: 2.9267371211626783
Validation loss: 2.6030581871985468

Epoch: 5| Step: 1
Training loss: 2.6269496761710633
Validation loss: 2.5978442091770897

Epoch: 5| Step: 2
Training loss: 3.040782608385539
Validation loss: 2.6002465707417883

Epoch: 5| Step: 3
Training loss: 3.191013867689105
Validation loss: 2.6052240891877343

Epoch: 5| Step: 4
Training loss: 2.746218508929215
Validation loss: 2.606834252923223

Epoch: 5| Step: 5
Training loss: 2.8959629569556102
Validation loss: 2.6111296904941512

Epoch: 5| Step: 6
Training loss: 2.915681363753832
Validation loss: 2.6084198780858436

Epoch: 5| Step: 7
Training loss: 3.234560458998261
Validation loss: 2.617925318972988

Epoch: 5| Step: 8
Training loss: 2.823877253271932
Validation loss: 2.635268628454602

Epoch: 5| Step: 9
Training loss: 3.2824026353956106
Validation loss: 2.6481777853572237

Epoch: 5| Step: 10
Training loss: 2.51886337062992
Validation loss: 2.6429941202685656

Epoch: 333| Step: 0
Training loss: 2.8522374856630686
Validation loss: 2.6416384698722832

Epoch: 5| Step: 1
Training loss: 2.907573767634004
Validation loss: 2.6387845546762296

Epoch: 5| Step: 2
Training loss: 2.8192068030100996
Validation loss: 2.636649615780237

Epoch: 5| Step: 3
Training loss: 2.4701785047021954
Validation loss: 2.6194880814065864

Epoch: 5| Step: 4
Training loss: 2.9406609268507213
Validation loss: 2.604029922997001

Epoch: 5| Step: 5
Training loss: 3.1330301489817667
Validation loss: 2.605931078996093

Epoch: 5| Step: 6
Training loss: 3.2897891875094967
Validation loss: 2.600384323090619

Epoch: 5| Step: 7
Training loss: 2.880638398569489
Validation loss: 2.605878974987094

Epoch: 5| Step: 8
Training loss: 3.1945080478988968
Validation loss: 2.601488777457978

Epoch: 5| Step: 9
Training loss: 2.67159613330788
Validation loss: 2.6015863895104663

Epoch: 5| Step: 10
Training loss: 3.155643669280209
Validation loss: 2.6013422978159264

Epoch: 334| Step: 0
Training loss: 3.201365662272378
Validation loss: 2.607533337054705

Epoch: 5| Step: 1
Training loss: 2.9842765751930727
Validation loss: 2.614818481204392

Epoch: 5| Step: 2
Training loss: 3.2232933200797143
Validation loss: 2.6008713632648535

Epoch: 5| Step: 3
Training loss: 3.1435216195060987
Validation loss: 2.6032717102581047

Epoch: 5| Step: 4
Training loss: 3.295519364774839
Validation loss: 2.608345469701087

Epoch: 5| Step: 5
Training loss: 2.757779302208119
Validation loss: 2.6135872505486333

Epoch: 5| Step: 6
Training loss: 2.8441648075944523
Validation loss: 2.6181244624076494

Epoch: 5| Step: 7
Training loss: 3.07220943954902
Validation loss: 2.617837301223891

Epoch: 5| Step: 8
Training loss: 2.7848951476817834
Validation loss: 2.6127706088557017

Epoch: 5| Step: 9
Training loss: 2.200744316595544
Validation loss: 2.617394453010916

Epoch: 5| Step: 10
Training loss: 2.644926821988986
Validation loss: 2.6219054936991903

Epoch: 335| Step: 0
Training loss: 3.2769754814415744
Validation loss: 2.6300913817726226

Epoch: 5| Step: 1
Training loss: 2.6931063704024476
Validation loss: 2.6378823469027934

Epoch: 5| Step: 2
Training loss: 2.8179564211083656
Validation loss: 2.622966676161802

Epoch: 5| Step: 3
Training loss: 2.811758494646074
Validation loss: 2.616814086311384

Epoch: 5| Step: 4
Training loss: 3.061702546594898
Validation loss: 2.618233154130386

Epoch: 5| Step: 5
Training loss: 2.698412806624901
Validation loss: 2.610439646056462

Epoch: 5| Step: 6
Training loss: 3.175749568616959
Validation loss: 2.6029623036736367

Epoch: 5| Step: 7
Training loss: 2.9129343584851446
Validation loss: 2.600814821770845

Epoch: 5| Step: 8
Training loss: 3.0660389285369014
Validation loss: 2.6020973269492558

Epoch: 5| Step: 9
Training loss: 2.83623963315035
Validation loss: 2.603303986105698

Epoch: 5| Step: 10
Training loss: 2.8129306039722475
Validation loss: 2.5978093677870944

Epoch: 336| Step: 0
Training loss: 3.054004173240983
Validation loss: 2.592885044783296

Epoch: 5| Step: 1
Training loss: 3.3836787218211013
Validation loss: 2.5910213897960483

Epoch: 5| Step: 2
Training loss: 2.460283368080031
Validation loss: 2.59820555273896

Epoch: 5| Step: 3
Training loss: 2.7509170217032413
Validation loss: 2.595784236288469

Epoch: 5| Step: 4
Training loss: 3.519891345774692
Validation loss: 2.5985873052432145

Epoch: 5| Step: 5
Training loss: 2.998955385808014
Validation loss: 2.5908939002675195

Epoch: 5| Step: 6
Training loss: 3.379307576419306
Validation loss: 2.5946410726979354

Epoch: 5| Step: 7
Training loss: 2.838117449963979
Validation loss: 2.5943010755168103

Epoch: 5| Step: 8
Training loss: 2.5621391600575656
Validation loss: 2.5915280187269274

Epoch: 5| Step: 9
Training loss: 2.43735024407876
Validation loss: 2.5928214553827673

Epoch: 5| Step: 10
Training loss: 2.585890755130046
Validation loss: 2.59293008756768

Epoch: 337| Step: 0
Training loss: 3.3104293397277154
Validation loss: 2.5924236841826005

Epoch: 5| Step: 1
Training loss: 3.1607478357832806
Validation loss: 2.597589287614542

Epoch: 5| Step: 2
Training loss: 2.6667266680007105
Validation loss: 2.5981086504170268

Epoch: 5| Step: 3
Training loss: 3.059407599707012
Validation loss: 2.594684488333297

Epoch: 5| Step: 4
Training loss: 2.6421607252464163
Validation loss: 2.592223976603191

Epoch: 5| Step: 5
Training loss: 3.3022106799931823
Validation loss: 2.593000565393664

Epoch: 5| Step: 6
Training loss: 2.930144007401986
Validation loss: 2.5889560436046746

Epoch: 5| Step: 7
Training loss: 3.254439329739018
Validation loss: 2.5876637470447923

Epoch: 5| Step: 8
Training loss: 3.018815798466883
Validation loss: 2.591637182910466

Epoch: 5| Step: 9
Training loss: 1.8757514719285544
Validation loss: 2.5963486632212267

Epoch: 5| Step: 10
Training loss: 2.6547031161885726
Validation loss: 2.5986066761129796

Epoch: 338| Step: 0
Training loss: 2.7228085271429165
Validation loss: 2.5965414621598697

Epoch: 5| Step: 1
Training loss: 3.347620070271968
Validation loss: 2.610029545598968

Epoch: 5| Step: 2
Training loss: 2.9916891375222874
Validation loss: 2.6023391785704955

Epoch: 5| Step: 3
Training loss: 2.593611564159087
Validation loss: 2.613215402187139

Epoch: 5| Step: 4
Training loss: 2.754884456835516
Validation loss: 2.629647922096786

Epoch: 5| Step: 5
Training loss: 2.9190271544126207
Validation loss: 2.6337879723298925

Epoch: 5| Step: 6
Training loss: 3.079737207175117
Validation loss: 2.6313065919496568

Epoch: 5| Step: 7
Training loss: 3.0205951114425296
Validation loss: 2.6190398878684733

Epoch: 5| Step: 8
Training loss: 3.0339298004196658
Validation loss: 2.622613324828252

Epoch: 5| Step: 9
Training loss: 2.778178715910671
Validation loss: 2.6203403652197457

Epoch: 5| Step: 10
Training loss: 2.7601327618167217
Validation loss: 2.616794183055171

Epoch: 339| Step: 0
Training loss: 3.1496667473729403
Validation loss: 2.625928432351624

Epoch: 5| Step: 1
Training loss: 2.7453212818228923
Validation loss: 2.608088625687643

Epoch: 5| Step: 2
Training loss: 3.1346783111866556
Validation loss: 2.635715583588252

Epoch: 5| Step: 3
Training loss: 3.1478669286131438
Validation loss: 2.6202248504435888

Epoch: 5| Step: 4
Training loss: 2.433550349012319
Validation loss: 2.633017315509263

Epoch: 5| Step: 5
Training loss: 2.901309336031283
Validation loss: 2.6216329817015382

Epoch: 5| Step: 6
Training loss: 2.445188379032147
Validation loss: 2.6198507482639584

Epoch: 5| Step: 7
Training loss: 2.905643522909609
Validation loss: 2.6132415072439654

Epoch: 5| Step: 8
Training loss: 2.5424839852727987
Validation loss: 2.5951746499679635

Epoch: 5| Step: 9
Training loss: 2.949765671297292
Validation loss: 2.599949218358205

Epoch: 5| Step: 10
Training loss: 3.712335391521497
Validation loss: 2.5991388514245557

Epoch: 340| Step: 0
Training loss: 2.904469590736943
Validation loss: 2.59832618050735

Epoch: 5| Step: 1
Training loss: 2.847400711378226
Validation loss: 2.599325332476577

Epoch: 5| Step: 2
Training loss: 3.6589025021366175
Validation loss: 2.610181267707676

Epoch: 5| Step: 3
Training loss: 2.099622547197053
Validation loss: 2.6123064726136374

Epoch: 5| Step: 4
Training loss: 2.8533186012256144
Validation loss: 2.598225256995734

Epoch: 5| Step: 5
Training loss: 2.6295569692889957
Validation loss: 2.609195389883711

Epoch: 5| Step: 6
Training loss: 2.961872043934152
Validation loss: 2.6036350043877414

Epoch: 5| Step: 7
Training loss: 3.14214216187261
Validation loss: 2.6100086378382774

Epoch: 5| Step: 8
Training loss: 2.4823168020273805
Validation loss: 2.6064402018269552

Epoch: 5| Step: 9
Training loss: 2.989853867752184
Validation loss: 2.6097941414144366

Epoch: 5| Step: 10
Training loss: 3.3611722175220784
Validation loss: 2.6335719218828375

Epoch: 341| Step: 0
Training loss: 3.0606394195684357
Validation loss: 2.59725376378554

Epoch: 5| Step: 1
Training loss: 2.7272519002465985
Validation loss: 2.5997778280132255

Epoch: 5| Step: 2
Training loss: 3.1043158544409266
Validation loss: 2.600706986177741

Epoch: 5| Step: 3
Training loss: 2.7857168952175115
Validation loss: 2.5966082333729883

Epoch: 5| Step: 4
Training loss: 2.8160716795901775
Validation loss: 2.5905773647168293

Epoch: 5| Step: 5
Training loss: 2.9987917692289527
Validation loss: 2.59167788509424

Epoch: 5| Step: 6
Training loss: 2.847011665891135
Validation loss: 2.6008011647684453

Epoch: 5| Step: 7
Training loss: 2.844221977219901
Validation loss: 2.58674718800093

Epoch: 5| Step: 8
Training loss: 2.4585396847085104
Validation loss: 2.5914978784172193

Epoch: 5| Step: 9
Training loss: 3.3174256464337977
Validation loss: 2.5948895114519024

Epoch: 5| Step: 10
Training loss: 3.1561424312579303
Validation loss: 2.6003483385902486

Epoch: 342| Step: 0
Training loss: 3.199593732793531
Validation loss: 2.612207261036837

Epoch: 5| Step: 1
Training loss: 2.9740203654984296
Validation loss: 2.6053334420999597

Epoch: 5| Step: 2
Training loss: 2.798724963888455
Validation loss: 2.634388535150876

Epoch: 5| Step: 3
Training loss: 3.1940602131365026
Validation loss: 2.632980431393765

Epoch: 5| Step: 4
Training loss: 3.163169301492923
Validation loss: 2.6277006606332973

Epoch: 5| Step: 5
Training loss: 2.7523786487905983
Validation loss: 2.6546255415263564

Epoch: 5| Step: 6
Training loss: 2.9527505304182493
Validation loss: 2.6440942358692814

Epoch: 5| Step: 7
Training loss: 2.6183100328515536
Validation loss: 2.6240673039155045

Epoch: 5| Step: 8
Training loss: 2.5191055766261496
Validation loss: 2.6240706734902335

Epoch: 5| Step: 9
Training loss: 2.972101829047343
Validation loss: 2.6133187245932623

Epoch: 5| Step: 10
Training loss: 2.9754356193570994
Validation loss: 2.602344772128785

Epoch: 343| Step: 0
Training loss: 3.049582818688811
Validation loss: 2.6007999562853854

Epoch: 5| Step: 1
Training loss: 2.722450106245044
Validation loss: 2.6011966141439986

Epoch: 5| Step: 2
Training loss: 2.878723387170735
Validation loss: 2.5976255156143506

Epoch: 5| Step: 3
Training loss: 3.2717301097074927
Validation loss: 2.591226266441292

Epoch: 5| Step: 4
Training loss: 2.649612121265669
Validation loss: 2.5993205589178716

Epoch: 5| Step: 5
Training loss: 3.030907680413163
Validation loss: 2.593431496959141

Epoch: 5| Step: 6
Training loss: 3.371371402555964
Validation loss: 2.592300211487959

Epoch: 5| Step: 7
Training loss: 2.5433767433844836
Validation loss: 2.59626324658042

Epoch: 5| Step: 8
Training loss: 3.0243163100726718
Validation loss: 2.6016063214107494

Epoch: 5| Step: 9
Training loss: 2.7679978014104853
Validation loss: 2.6018637964597158

Epoch: 5| Step: 10
Training loss: 2.6649274121216586
Validation loss: 2.6197723500168704

Epoch: 344| Step: 0
Training loss: 2.728719213559313
Validation loss: 2.60305626672627

Epoch: 5| Step: 1
Training loss: 2.8718732333670776
Validation loss: 2.6127196273653084

Epoch: 5| Step: 2
Training loss: 3.5263666466179315
Validation loss: 2.6087727393558913

Epoch: 5| Step: 3
Training loss: 2.9743544831903956
Validation loss: 2.623831441495332

Epoch: 5| Step: 4
Training loss: 2.7097716009308654
Validation loss: 2.614635184789976

Epoch: 5| Step: 5
Training loss: 3.0919777774481028
Validation loss: 2.6160508620279472

Epoch: 5| Step: 6
Training loss: 2.518478197146919
Validation loss: 2.6206452597732004

Epoch: 5| Step: 7
Training loss: 2.5911153257992585
Validation loss: 2.6256786002533175

Epoch: 5| Step: 8
Training loss: 2.7616336275225892
Validation loss: 2.6348791080437453

Epoch: 5| Step: 9
Training loss: 3.4620792064365924
Validation loss: 2.6471173086916444

Epoch: 5| Step: 10
Training loss: 2.6960066191821244
Validation loss: 2.6377726299027637

Epoch: 345| Step: 0
Training loss: 3.187626555679269
Validation loss: 2.6243013056634075

Epoch: 5| Step: 1
Training loss: 2.8319135549358485
Validation loss: 2.623542054574663

Epoch: 5| Step: 2
Training loss: 2.88510941798743
Validation loss: 2.597128155617635

Epoch: 5| Step: 3
Training loss: 2.7481183637200974
Validation loss: 2.591330543761672

Epoch: 5| Step: 4
Training loss: 2.8981903875665256
Validation loss: 2.592712843365944

Epoch: 5| Step: 5
Training loss: 2.5440408113972803
Validation loss: 2.591861852534008

Epoch: 5| Step: 6
Training loss: 3.2155373845893775
Validation loss: 2.596039385463974

Epoch: 5| Step: 7
Training loss: 3.061146651206118
Validation loss: 2.5956150895151375

Epoch: 5| Step: 8
Training loss: 3.087299751243523
Validation loss: 2.5899293941953148

Epoch: 5| Step: 9
Training loss: 2.8650837594083165
Validation loss: 2.592376297771399

Epoch: 5| Step: 10
Training loss: 2.8974464552427084
Validation loss: 2.5948443060733446

Epoch: 346| Step: 0
Training loss: 3.443180730884196
Validation loss: 2.5924356537672044

Epoch: 5| Step: 1
Training loss: 2.6788206783766233
Validation loss: 2.5911331586218074

Epoch: 5| Step: 2
Training loss: 2.813145372731839
Validation loss: 2.593246972589214

Epoch: 5| Step: 3
Training loss: 3.7036056528534655
Validation loss: 2.5899147384403243

Epoch: 5| Step: 4
Training loss: 2.9532615993333
Validation loss: 2.601979227811988

Epoch: 5| Step: 5
Training loss: 2.399397269699834
Validation loss: 2.5984706004663205

Epoch: 5| Step: 6
Training loss: 2.819204773344184
Validation loss: 2.597751675078278

Epoch: 5| Step: 7
Training loss: 2.5640947915228387
Validation loss: 2.5922324995621926

Epoch: 5| Step: 8
Training loss: 2.9442590099299535
Validation loss: 2.598916887308001

Epoch: 5| Step: 9
Training loss: 2.8659449075327137
Validation loss: 2.6009208353245685

Epoch: 5| Step: 10
Training loss: 2.7116394013775187
Validation loss: 2.5889231403066213

Epoch: 347| Step: 0
Training loss: 3.130021143101466
Validation loss: 2.5951181177185454

Epoch: 5| Step: 1
Training loss: 2.946654320197613
Validation loss: 2.5894217584678385

Epoch: 5| Step: 2
Training loss: 2.735874745658486
Validation loss: 2.5844602396168956

Epoch: 5| Step: 3
Training loss: 3.069157273872608
Validation loss: 2.5913249012008186

Epoch: 5| Step: 4
Training loss: 2.9760616812312817
Validation loss: 2.590718684939417

Epoch: 5| Step: 5
Training loss: 3.1041140114502146
Validation loss: 2.5922752840369405

Epoch: 5| Step: 6
Training loss: 2.6422624195018862
Validation loss: 2.5894357408169184

Epoch: 5| Step: 7
Training loss: 3.153946593118478
Validation loss: 2.5885453482376977

Epoch: 5| Step: 8
Training loss: 3.0770754501321
Validation loss: 2.5888599516910746

Epoch: 5| Step: 9
Training loss: 2.953153256881595
Validation loss: 2.586503748605513

Epoch: 5| Step: 10
Training loss: 2.0910503006170593
Validation loss: 2.5887627956041888

Epoch: 348| Step: 0
Training loss: 3.3484226270978166
Validation loss: 2.5953317981531034

Epoch: 5| Step: 1
Training loss: 3.1196735000945823
Validation loss: 2.58688509729042

Epoch: 5| Step: 2
Training loss: 2.3819721678766146
Validation loss: 2.5952659177062247

Epoch: 5| Step: 3
Training loss: 2.976158935743053
Validation loss: 2.6017705835434928

Epoch: 5| Step: 4
Training loss: 3.2291096015728122
Validation loss: 2.6011077711080315

Epoch: 5| Step: 5
Training loss: 3.042111002896323
Validation loss: 2.6181874235514666

Epoch: 5| Step: 6
Training loss: 2.931943467348499
Validation loss: 2.588137243325779

Epoch: 5| Step: 7
Training loss: 3.0588121591978066
Validation loss: 2.59144486393935

Epoch: 5| Step: 8
Training loss: 2.576150403862382
Validation loss: 2.5980204615943174

Epoch: 5| Step: 9
Training loss: 2.5993597195931275
Validation loss: 2.5871891662724598

Epoch: 5| Step: 10
Training loss: 2.676551964021468
Validation loss: 2.5987036160951025

Epoch: 349| Step: 0
Training loss: 3.0348140567838633
Validation loss: 2.5818787554046447

Epoch: 5| Step: 1
Training loss: 2.7682738469496333
Validation loss: 2.592776338531501

Epoch: 5| Step: 2
Training loss: 2.7066221161951494
Validation loss: 2.6016590253611542

Epoch: 5| Step: 3
Training loss: 2.8319071564946072
Validation loss: 2.5912277292010897

Epoch: 5| Step: 4
Training loss: 2.76548033944802
Validation loss: 2.58893647872902

Epoch: 5| Step: 5
Training loss: 2.9653856990887966
Validation loss: 2.600816640399099

Epoch: 5| Step: 6
Training loss: 2.9248410434405714
Validation loss: 2.613160023482608

Epoch: 5| Step: 7
Training loss: 3.3131032430427005
Validation loss: 2.6122784538435364

Epoch: 5| Step: 8
Training loss: 3.113140337541896
Validation loss: 2.62239301525176

Epoch: 5| Step: 9
Training loss: 2.56281390244625
Validation loss: 2.633226613976418

Epoch: 5| Step: 10
Training loss: 3.1244297270189305
Validation loss: 2.6136737635823004

Epoch: 350| Step: 0
Training loss: 2.8369727228767427
Validation loss: 2.6116986106510867

Epoch: 5| Step: 1
Training loss: 3.268247874334323
Validation loss: 2.6292849607429574

Epoch: 5| Step: 2
Training loss: 3.2065078363981607
Validation loss: 2.6349252494506175

Epoch: 5| Step: 3
Training loss: 2.618077915229958
Validation loss: 2.6253555445763657

Epoch: 5| Step: 4
Training loss: 2.9124469932349535
Validation loss: 2.618349114148653

Epoch: 5| Step: 5
Training loss: 2.395711536352275
Validation loss: 2.6055033285859124

Epoch: 5| Step: 6
Training loss: 3.0339602908891035
Validation loss: 2.6059668053957212

Epoch: 5| Step: 7
Training loss: 3.4228230038484067
Validation loss: 2.598450773757967

Epoch: 5| Step: 8
Training loss: 2.6387260877572984
Validation loss: 2.585597145586328

Epoch: 5| Step: 9
Training loss: 2.8631320305592025
Validation loss: 2.586861490226353

Epoch: 5| Step: 10
Training loss: 2.7167256151914394
Validation loss: 2.5883192536832076

Epoch: 351| Step: 0
Training loss: 3.275333119696821
Validation loss: 2.590899083164518

Epoch: 5| Step: 1
Training loss: 2.9589568184051007
Validation loss: 2.5813435828417233

Epoch: 5| Step: 2
Training loss: 2.8845947049695693
Validation loss: 2.580104016856467

Epoch: 5| Step: 3
Training loss: 3.236221007817295
Validation loss: 2.578341541413106

Epoch: 5| Step: 4
Training loss: 2.9564976078399883
Validation loss: 2.5796991131224623

Epoch: 5| Step: 5
Training loss: 2.913852060200612
Validation loss: 2.5902250038339805

Epoch: 5| Step: 6
Training loss: 2.969504651976958
Validation loss: 2.5850157351939322

Epoch: 5| Step: 7
Training loss: 3.129891953477291
Validation loss: 2.5902891924095224

Epoch: 5| Step: 8
Training loss: 2.1603940863856277
Validation loss: 2.604489972790388

Epoch: 5| Step: 9
Training loss: 2.6404409852326904
Validation loss: 2.5941962213990557

Epoch: 5| Step: 10
Training loss: 2.7920760428667393
Validation loss: 2.5926891627990343

Epoch: 352| Step: 0
Training loss: 2.773591287136999
Validation loss: 2.606095595807717

Epoch: 5| Step: 1
Training loss: 2.3440310500435175
Validation loss: 2.624048770688661

Epoch: 5| Step: 2
Training loss: 2.507454439549891
Validation loss: 2.632275487369907

Epoch: 5| Step: 3
Training loss: 2.9125766596712803
Validation loss: 2.645826856317619

Epoch: 5| Step: 4
Training loss: 2.9425469728413733
Validation loss: 2.637514005906771

Epoch: 5| Step: 5
Training loss: 3.2140763804980264
Validation loss: 2.622419834480285

Epoch: 5| Step: 6
Training loss: 3.1681725451750533
Validation loss: 2.62092373942756

Epoch: 5| Step: 7
Training loss: 2.6877467907104124
Validation loss: 2.6131185590754784

Epoch: 5| Step: 8
Training loss: 3.306462958531757
Validation loss: 2.6133664213837435

Epoch: 5| Step: 9
Training loss: 2.8817002546633907
Validation loss: 2.6006492897314923

Epoch: 5| Step: 10
Training loss: 3.2319999488603948
Validation loss: 2.5905810490025907

Epoch: 353| Step: 0
Training loss: 2.9191205918747563
Validation loss: 2.5923135987929933

Epoch: 5| Step: 1
Training loss: 2.5527451156705467
Validation loss: 2.58914845238828

Epoch: 5| Step: 2
Training loss: 3.5296336838198332
Validation loss: 2.5911261992448313

Epoch: 5| Step: 3
Training loss: 2.8468904027930435
Validation loss: 2.5866339362576762

Epoch: 5| Step: 4
Training loss: 3.0697110972700874
Validation loss: 2.592218798333143

Epoch: 5| Step: 5
Training loss: 2.8357395912241024
Validation loss: 2.5960144820669

Epoch: 5| Step: 6
Training loss: 2.67964817385274
Validation loss: 2.5929215787661453

Epoch: 5| Step: 7
Training loss: 2.574820788174789
Validation loss: 2.593607746784289

Epoch: 5| Step: 8
Training loss: 2.8395186583182546
Validation loss: 2.599164675710794

Epoch: 5| Step: 9
Training loss: 2.6130613682135926
Validation loss: 2.6041620873851916

Epoch: 5| Step: 10
Training loss: 3.5302472336510204
Validation loss: 2.621178739903555

Epoch: 354| Step: 0
Training loss: 2.2117117345032344
Validation loss: 2.626355158826515

Epoch: 5| Step: 1
Training loss: 2.9481652001168754
Validation loss: 2.6182698504231805

Epoch: 5| Step: 2
Training loss: 3.0944804860848234
Validation loss: 2.621971739254767

Epoch: 5| Step: 3
Training loss: 3.011347133008906
Validation loss: 2.597102175846396

Epoch: 5| Step: 4
Training loss: 3.100663600159253
Validation loss: 2.5916865077777813

Epoch: 5| Step: 5
Training loss: 2.796369794684796
Validation loss: 2.581099297092122

Epoch: 5| Step: 6
Training loss: 3.199389554449124
Validation loss: 2.5822262487347216

Epoch: 5| Step: 7
Training loss: 3.1127342595566483
Validation loss: 2.5757350291112626

Epoch: 5| Step: 8
Training loss: 2.7964035574537767
Validation loss: 2.5835050320074

Epoch: 5| Step: 9
Training loss: 3.1202767344771263
Validation loss: 2.577153544585719

Epoch: 5| Step: 10
Training loss: 2.5010675058509
Validation loss: 2.580690913698488

Epoch: 355| Step: 0
Training loss: 2.1852348588995656
Validation loss: 2.577077130225757

Epoch: 5| Step: 1
Training loss: 2.8390252404295206
Validation loss: 2.5729215034943245

Epoch: 5| Step: 2
Training loss: 3.2171428334570815
Validation loss: 2.5776905328892603

Epoch: 5| Step: 3
Training loss: 2.2821815365490496
Validation loss: 2.5863547074550266

Epoch: 5| Step: 4
Training loss: 2.6859330333164393
Validation loss: 2.587058936203639

Epoch: 5| Step: 5
Training loss: 2.55121761871527
Validation loss: 2.5834135353375474

Epoch: 5| Step: 6
Training loss: 3.285054498972317
Validation loss: 2.5968802706275493

Epoch: 5| Step: 7
Training loss: 3.4509639277953665
Validation loss: 2.5868509189566358

Epoch: 5| Step: 8
Training loss: 3.2472852959846423
Validation loss: 2.593585605504281

Epoch: 5| Step: 9
Training loss: 2.8554989751841675
Validation loss: 2.6006529912931655

Epoch: 5| Step: 10
Training loss: 3.2205633592323686
Validation loss: 2.611789331395954

Epoch: 356| Step: 0
Training loss: 2.7579418292532787
Validation loss: 2.5984731596950192

Epoch: 5| Step: 1
Training loss: 2.665753317424388
Validation loss: 2.59079851351976

Epoch: 5| Step: 2
Training loss: 2.9308143991555253
Validation loss: 2.59923245362495

Epoch: 5| Step: 3
Training loss: 3.5645699092598098
Validation loss: 2.598567103546223

Epoch: 5| Step: 4
Training loss: 2.7472835475641304
Validation loss: 2.59834592035516

Epoch: 5| Step: 5
Training loss: 2.946587324613385
Validation loss: 2.5991492671785474

Epoch: 5| Step: 6
Training loss: 2.6024529476841014
Validation loss: 2.5936233710996914

Epoch: 5| Step: 7
Training loss: 3.013212039104208
Validation loss: 2.59942363033119

Epoch: 5| Step: 8
Training loss: 2.684657700810295
Validation loss: 2.5968190960742903

Epoch: 5| Step: 9
Training loss: 3.0824542124024514
Validation loss: 2.590345739984583

Epoch: 5| Step: 10
Training loss: 2.825466866864142
Validation loss: 2.586974132464756

Epoch: 357| Step: 0
Training loss: 2.218862396402147
Validation loss: 2.597551106932561

Epoch: 5| Step: 1
Training loss: 2.355639702965368
Validation loss: 2.5961136315820554

Epoch: 5| Step: 2
Training loss: 3.3393311581240583
Validation loss: 2.6025549198455504

Epoch: 5| Step: 3
Training loss: 3.291252512570475
Validation loss: 2.6086283787159665

Epoch: 5| Step: 4
Training loss: 2.6987657622335988
Validation loss: 2.606566667385579

Epoch: 5| Step: 5
Training loss: 3.0162349736281646
Validation loss: 2.5969690312392126

Epoch: 5| Step: 6
Training loss: 3.0366874769763035
Validation loss: 2.604041607879024

Epoch: 5| Step: 7
Training loss: 2.828264433231919
Validation loss: 2.59822807991182

Epoch: 5| Step: 8
Training loss: 2.480624841299362
Validation loss: 2.6298223023148495

Epoch: 5| Step: 9
Training loss: 3.1225852792179705
Validation loss: 2.63091382279878

Epoch: 5| Step: 10
Training loss: 3.3799931360208912
Validation loss: 2.6288577951150702

Epoch: 358| Step: 0
Training loss: 3.1608596226465275
Validation loss: 2.6241870672195065

Epoch: 5| Step: 1
Training loss: 2.843717134725953
Validation loss: 2.6334913377983167

Epoch: 5| Step: 2
Training loss: 3.2926778246246475
Validation loss: 2.620099863095055

Epoch: 5| Step: 3
Training loss: 2.897328784218716
Validation loss: 2.6162384864305244

Epoch: 5| Step: 4
Training loss: 2.2043380103429633
Validation loss: 2.6169274289233955

Epoch: 5| Step: 5
Training loss: 2.8684644635948082
Validation loss: 2.6135597492013396

Epoch: 5| Step: 6
Training loss: 3.1446941072928514
Validation loss: 2.6252315622242874

Epoch: 5| Step: 7
Training loss: 2.2655517566285903
Validation loss: 2.624489472371488

Epoch: 5| Step: 8
Training loss: 2.84974089666071
Validation loss: 2.623246941139216

Epoch: 5| Step: 9
Training loss: 3.119914532737933
Validation loss: 2.6206795256154662

Epoch: 5| Step: 10
Training loss: 3.083906756167784
Validation loss: 2.6001587009191796

Epoch: 359| Step: 0
Training loss: 3.1754175707546284
Validation loss: 2.6008488018164697

Epoch: 5| Step: 1
Training loss: 2.669557335837485
Validation loss: 2.5777748772569242

Epoch: 5| Step: 2
Training loss: 2.9835226229779606
Validation loss: 2.574499938337612

Epoch: 5| Step: 3
Training loss: 2.91573009894395
Validation loss: 2.571536001882062

Epoch: 5| Step: 4
Training loss: 2.8318731434853253
Validation loss: 2.574212561527456

Epoch: 5| Step: 5
Training loss: 3.1990024740406904
Validation loss: 2.573075404723005

Epoch: 5| Step: 6
Training loss: 3.24219073559703
Validation loss: 2.576974207595475

Epoch: 5| Step: 7
Training loss: 3.0374106499987903
Validation loss: 2.5809131063095934

Epoch: 5| Step: 8
Training loss: 3.0752122139004423
Validation loss: 2.5850316801982336

Epoch: 5| Step: 9
Training loss: 2.5714710720273875
Validation loss: 2.5804978425074263

Epoch: 5| Step: 10
Training loss: 2.008174759657617
Validation loss: 2.582554673716635

Epoch: 360| Step: 0
Training loss: 2.650675590336373
Validation loss: 2.5901451239259177

Epoch: 5| Step: 1
Training loss: 3.2567315446631313
Validation loss: 2.60425069923591

Epoch: 5| Step: 2
Training loss: 2.7873245081378255
Validation loss: 2.6296084169503793

Epoch: 5| Step: 3
Training loss: 2.9457021602218783
Validation loss: 2.643914546678363

Epoch: 5| Step: 4
Training loss: 3.317510593975202
Validation loss: 2.648693166633698

Epoch: 5| Step: 5
Training loss: 2.376387642491535
Validation loss: 2.6234240188520497

Epoch: 5| Step: 6
Training loss: 2.9890059246924685
Validation loss: 2.6214678107281926

Epoch: 5| Step: 7
Training loss: 2.9633576258324106
Validation loss: 2.592308730240552

Epoch: 5| Step: 8
Training loss: 2.587473156923386
Validation loss: 2.5776710366631663

Epoch: 5| Step: 9
Training loss: 2.831726815533677
Validation loss: 2.5789330313462373

Epoch: 5| Step: 10
Training loss: 3.407942325265201
Validation loss: 2.576649647099475

Epoch: 361| Step: 0
Training loss: 2.866189809068207
Validation loss: 2.568843136426248

Epoch: 5| Step: 1
Training loss: 2.469468217508117
Validation loss: 2.576349526472913

Epoch: 5| Step: 2
Training loss: 2.5340581317186075
Validation loss: 2.575512649578043

Epoch: 5| Step: 3
Training loss: 3.0970867927566506
Validation loss: 2.580744637826772

Epoch: 5| Step: 4
Training loss: 3.0438850012572596
Validation loss: 2.5769578973735463

Epoch: 5| Step: 5
Training loss: 3.013384683587832
Validation loss: 2.571839389572684

Epoch: 5| Step: 6
Training loss: 2.8237209699201506
Validation loss: 2.5770903887014525

Epoch: 5| Step: 7
Training loss: 3.049113854674353
Validation loss: 2.589737970000966

Epoch: 5| Step: 8
Training loss: 3.2137970083590375
Validation loss: 2.593779877916694

Epoch: 5| Step: 9
Training loss: 2.78097104163046
Validation loss: 2.593737284311279

Epoch: 5| Step: 10
Training loss: 3.0088839913720764
Validation loss: 2.588963071199037

Epoch: 362| Step: 0
Training loss: 2.780622004213475
Validation loss: 2.5955166977964717

Epoch: 5| Step: 1
Training loss: 2.968479184296656
Validation loss: 2.5960204388374333

Epoch: 5| Step: 2
Training loss: 3.253047541301731
Validation loss: 2.5969530529142957

Epoch: 5| Step: 3
Training loss: 3.2174677100113716
Validation loss: 2.5986915461476783

Epoch: 5| Step: 4
Training loss: 2.761844184325472
Validation loss: 2.5985018220949745

Epoch: 5| Step: 5
Training loss: 2.645262038261638
Validation loss: 2.592548986301956

Epoch: 5| Step: 6
Training loss: 2.8105642650880083
Validation loss: 2.5846232545718966

Epoch: 5| Step: 7
Training loss: 3.0584980254217573
Validation loss: 2.5914363643583407

Epoch: 5| Step: 8
Training loss: 2.6466381520994124
Validation loss: 2.629348715453476

Epoch: 5| Step: 9
Training loss: 2.642361312734758
Validation loss: 2.638880905681884

Epoch: 5| Step: 10
Training loss: 3.0902199690956405
Validation loss: 2.6450580303647357

Epoch: 363| Step: 0
Training loss: 2.7782251432239344
Validation loss: 2.612488990364441

Epoch: 5| Step: 1
Training loss: 2.645049592330214
Validation loss: 2.5970441150192825

Epoch: 5| Step: 2
Training loss: 2.7553585038006494
Validation loss: 2.5846657613147372

Epoch: 5| Step: 3
Training loss: 2.8705658926963378
Validation loss: 2.58532681262198

Epoch: 5| Step: 4
Training loss: 2.819305832017996
Validation loss: 2.5921505739560207

Epoch: 5| Step: 5
Training loss: 2.575646891400234
Validation loss: 2.587392704574848

Epoch: 5| Step: 6
Training loss: 3.2636875081444106
Validation loss: 2.584892850832905

Epoch: 5| Step: 7
Training loss: 3.702054154612555
Validation loss: 2.585989156207767

Epoch: 5| Step: 8
Training loss: 2.9933988743540154
Validation loss: 2.5889848608782398

Epoch: 5| Step: 9
Training loss: 2.6054160414458645
Validation loss: 2.588332657616605

Epoch: 5| Step: 10
Training loss: 2.7683913194469296
Validation loss: 2.5826847279034886

Epoch: 364| Step: 0
Training loss: 2.4615013808657817
Validation loss: 2.5912621411662395

Epoch: 5| Step: 1
Training loss: 2.823390137402367
Validation loss: 2.5797381592427624

Epoch: 5| Step: 2
Training loss: 2.772714611996712
Validation loss: 2.5848848134490714

Epoch: 5| Step: 3
Training loss: 2.962090179811783
Validation loss: 2.589241592962408

Epoch: 5| Step: 4
Training loss: 2.9552381917157526
Validation loss: 2.5993608656252594

Epoch: 5| Step: 5
Training loss: 3.2177639534192553
Validation loss: 2.589322360135213

Epoch: 5| Step: 6
Training loss: 3.2078075886431896
Validation loss: 2.618536005056209

Epoch: 5| Step: 7
Training loss: 2.959538997629734
Validation loss: 2.614934479903117

Epoch: 5| Step: 8
Training loss: 2.7839397325679145
Validation loss: 2.6203359547615226

Epoch: 5| Step: 9
Training loss: 2.6057375836406402
Validation loss: 2.612235527391958

Epoch: 5| Step: 10
Training loss: 3.245887501908966
Validation loss: 2.637946304913941

Epoch: 365| Step: 0
Training loss: 2.673858976778273
Validation loss: 2.626791739547048

Epoch: 5| Step: 1
Training loss: 3.3646763335012824
Validation loss: 2.5922398555119366

Epoch: 5| Step: 2
Training loss: 3.028647022897624
Validation loss: 2.5933705089466943

Epoch: 5| Step: 3
Training loss: 3.092746456258611
Validation loss: 2.5836608390006317

Epoch: 5| Step: 4
Training loss: 2.6962433465372406
Validation loss: 2.5737499833711737

Epoch: 5| Step: 5
Training loss: 2.9661989193330807
Validation loss: 2.577888215876375

Epoch: 5| Step: 6
Training loss: 2.915235840563078
Validation loss: 2.567546724495656

Epoch: 5| Step: 7
Training loss: 2.6055102938381163
Validation loss: 2.5759754814615974

Epoch: 5| Step: 8
Training loss: 2.0889817786474336
Validation loss: 2.580422293168548

Epoch: 5| Step: 9
Training loss: 3.4673813877845183
Validation loss: 2.5722129696105123

Epoch: 5| Step: 10
Training loss: 2.7523316988652753
Validation loss: 2.5805909148213777

Epoch: 366| Step: 0
Training loss: 2.8586209663123454
Validation loss: 2.5798818261091783

Epoch: 5| Step: 1
Training loss: 2.639401665999319
Validation loss: 2.592100990883898

Epoch: 5| Step: 2
Training loss: 3.104980276785357
Validation loss: 2.592372943368464

Epoch: 5| Step: 3
Training loss: 2.6626522325147755
Validation loss: 2.5901219959329613

Epoch: 5| Step: 4
Training loss: 2.7568574716049246
Validation loss: 2.603150495243722

Epoch: 5| Step: 5
Training loss: 2.714166834027671
Validation loss: 2.6210630204873158

Epoch: 5| Step: 6
Training loss: 3.397177135854209
Validation loss: 2.604342220828963

Epoch: 5| Step: 7
Training loss: 2.3147520491956306
Validation loss: 2.5915214373113757

Epoch: 5| Step: 8
Training loss: 3.274009345095469
Validation loss: 2.5741877347876048

Epoch: 5| Step: 9
Training loss: 2.791436560717396
Validation loss: 2.571317689932394

Epoch: 5| Step: 10
Training loss: 3.404892117083813
Validation loss: 2.563512716558926

Epoch: 367| Step: 0
Training loss: 2.879617880001904
Validation loss: 2.567870616038264

Epoch: 5| Step: 1
Training loss: 2.992164233244234
Validation loss: 2.567759912308057

Epoch: 5| Step: 2
Training loss: 2.993044419254396
Validation loss: 2.56676542736404

Epoch: 5| Step: 3
Training loss: 2.787092779547211
Validation loss: 2.5688114121094134

Epoch: 5| Step: 4
Training loss: 2.5861863307573643
Validation loss: 2.5688181574953237

Epoch: 5| Step: 5
Training loss: 3.1235563376768334
Validation loss: 2.5741228210281064

Epoch: 5| Step: 6
Training loss: 2.714897407715018
Validation loss: 2.585302436705215

Epoch: 5| Step: 7
Training loss: 2.628368305642069
Validation loss: 2.5771631479485593

Epoch: 5| Step: 8
Training loss: 3.2840671616445944
Validation loss: 2.585916593743659

Epoch: 5| Step: 9
Training loss: 3.3047468031303535
Validation loss: 2.585723856231233

Epoch: 5| Step: 10
Training loss: 2.513709150273593
Validation loss: 2.577339959219592

Epoch: 368| Step: 0
Training loss: 2.8734821791128615
Validation loss: 2.5880401997788063

Epoch: 5| Step: 1
Training loss: 2.6660930692162914
Validation loss: 2.5823925368038463

Epoch: 5| Step: 2
Training loss: 3.216436499100609
Validation loss: 2.591421423557265

Epoch: 5| Step: 3
Training loss: 2.8720030713503255
Validation loss: 2.5828262546605996

Epoch: 5| Step: 4
Training loss: 2.9163560611096337
Validation loss: 2.581859379176781

Epoch: 5| Step: 5
Training loss: 2.9450502152363502
Validation loss: 2.5921881033217704

Epoch: 5| Step: 6
Training loss: 3.230378708974159
Validation loss: 2.591652313628974

Epoch: 5| Step: 7
Training loss: 2.3370308757173914
Validation loss: 2.6016360430817502

Epoch: 5| Step: 8
Training loss: 3.303157948426169
Validation loss: 2.6234983054334267

Epoch: 5| Step: 9
Training loss: 2.795829108548182
Validation loss: 2.6111951049183064

Epoch: 5| Step: 10
Training loss: 2.575416668263067
Validation loss: 2.61531819180128

Epoch: 369| Step: 0
Training loss: 2.29244984046699
Validation loss: 2.5960954058777173

Epoch: 5| Step: 1
Training loss: 2.7193611598117444
Validation loss: 2.588112598696575

Epoch: 5| Step: 2
Training loss: 3.0045249510154535
Validation loss: 2.601000495674265

Epoch: 5| Step: 3
Training loss: 3.575426441714653
Validation loss: 2.6062219108656866

Epoch: 5| Step: 4
Training loss: 3.1552864341267464
Validation loss: 2.5982937855993007

Epoch: 5| Step: 5
Training loss: 2.0146201534384542
Validation loss: 2.6066095647460283

Epoch: 5| Step: 6
Training loss: 3.183723007105694
Validation loss: 2.6110563794644763

Epoch: 5| Step: 7
Training loss: 2.5285467147389116
Validation loss: 2.613562694842239

Epoch: 5| Step: 8
Training loss: 3.023069216355696
Validation loss: 2.6025761061644013

Epoch: 5| Step: 9
Training loss: 3.1299603576099746
Validation loss: 2.6098131000302773

Epoch: 5| Step: 10
Training loss: 2.8157883811569535
Validation loss: 2.605620871487122

Epoch: 370| Step: 0
Training loss: 3.1819656796142026
Validation loss: 2.598705442119863

Epoch: 5| Step: 1
Training loss: 3.0707465488656998
Validation loss: 2.586336980456438

Epoch: 5| Step: 2
Training loss: 3.049536066260143
Validation loss: 2.5764448153208246

Epoch: 5| Step: 3
Training loss: 3.270610599263783
Validation loss: 2.571105560397155

Epoch: 5| Step: 4
Training loss: 2.295602147346658
Validation loss: 2.5718466234279562

Epoch: 5| Step: 5
Training loss: 2.667662752400849
Validation loss: 2.574144853845885

Epoch: 5| Step: 6
Training loss: 2.5139297554623856
Validation loss: 2.5980160467953897

Epoch: 5| Step: 7
Training loss: 3.183442169512564
Validation loss: 2.6041478041099047

Epoch: 5| Step: 8
Training loss: 3.1352806357512866
Validation loss: 2.589776858825767

Epoch: 5| Step: 9
Training loss: 2.8044605216411673
Validation loss: 2.5824946716975994

Epoch: 5| Step: 10
Training loss: 2.527966854397255
Validation loss: 2.5743384971018695

Epoch: 371| Step: 0
Training loss: 3.079112867436827
Validation loss: 2.578100646479767

Epoch: 5| Step: 1
Training loss: 2.957402920262283
Validation loss: 2.5826953698275035

Epoch: 5| Step: 2
Training loss: 2.6427366402302517
Validation loss: 2.588169593998097

Epoch: 5| Step: 3
Training loss: 3.043531255675299
Validation loss: 2.579194885981653

Epoch: 5| Step: 4
Training loss: 2.865683179158678
Validation loss: 2.587054670169387

Epoch: 5| Step: 5
Training loss: 3.068981085815019
Validation loss: 2.5869489009899937

Epoch: 5| Step: 6
Training loss: 3.371366310814768
Validation loss: 2.591977967678952

Epoch: 5| Step: 7
Training loss: 2.158659321482467
Validation loss: 2.5999300556855793

Epoch: 5| Step: 8
Training loss: 2.8193795729650586
Validation loss: 2.6047042278727512

Epoch: 5| Step: 9
Training loss: 2.9596951175592072
Validation loss: 2.5893305055243925

Epoch: 5| Step: 10
Training loss: 2.7918289099467666
Validation loss: 2.58796578692649

Epoch: 372| Step: 0
Training loss: 2.9024873392517323
Validation loss: 2.579587676730787

Epoch: 5| Step: 1
Training loss: 3.400545715967047
Validation loss: 2.566799355784569

Epoch: 5| Step: 2
Training loss: 2.9958854115451223
Validation loss: 2.566369731135862

Epoch: 5| Step: 3
Training loss: 2.688798989701358
Validation loss: 2.5688164030380207

Epoch: 5| Step: 4
Training loss: 2.8687443884834143
Validation loss: 2.564504616163904

Epoch: 5| Step: 5
Training loss: 2.7472057017605445
Validation loss: 2.5660033409906333

Epoch: 5| Step: 6
Training loss: 2.5363775053729607
Validation loss: 2.567763883923359

Epoch: 5| Step: 7
Training loss: 2.8587589121330597
Validation loss: 2.571458941051787

Epoch: 5| Step: 8
Training loss: 2.920993121062331
Validation loss: 2.5703801510458137

Epoch: 5| Step: 9
Training loss: 2.9251101937689317
Validation loss: 2.5710504123864695

Epoch: 5| Step: 10
Training loss: 2.9321392735687866
Validation loss: 2.5720472174961877

Epoch: 373| Step: 0
Training loss: 2.808433984448864
Validation loss: 2.579904121764665

Epoch: 5| Step: 1
Training loss: 2.6685973469942073
Validation loss: 2.590525352690869

Epoch: 5| Step: 2
Training loss: 2.937042525360565
Validation loss: 2.5927151076870802

Epoch: 5| Step: 3
Training loss: 3.0275097610732082
Validation loss: 2.5797846459237275

Epoch: 5| Step: 4
Training loss: 2.695538232168853
Validation loss: 2.5746532752334965

Epoch: 5| Step: 5
Training loss: 3.3674967683523143
Validation loss: 2.5733904280118303

Epoch: 5| Step: 6
Training loss: 2.779104283751259
Validation loss: 2.564184693020212

Epoch: 5| Step: 7
Training loss: 3.083758161678577
Validation loss: 2.569853420647772

Epoch: 5| Step: 8
Training loss: 2.840267858096716
Validation loss: 2.5633205377665367

Epoch: 5| Step: 9
Training loss: 2.653278438952342
Validation loss: 2.565574350464509

Epoch: 5| Step: 10
Training loss: 2.8829860066455684
Validation loss: 2.570099228167941

Epoch: 374| Step: 0
Training loss: 2.823868050440103
Validation loss: 2.5761350198852435

Epoch: 5| Step: 1
Training loss: 3.0446247888163973
Validation loss: 2.578754901720376

Epoch: 5| Step: 2
Training loss: 3.129354875765381
Validation loss: 2.5794651092278857

Epoch: 5| Step: 3
Training loss: 2.2016307552199397
Validation loss: 2.5839068500263136

Epoch: 5| Step: 4
Training loss: 3.158552330966453
Validation loss: 2.5937285290810506

Epoch: 5| Step: 5
Training loss: 2.9006000687214692
Validation loss: 2.609526301376773

Epoch: 5| Step: 6
Training loss: 2.918209612402602
Validation loss: 2.621661874942116

Epoch: 5| Step: 7
Training loss: 3.326896906538193
Validation loss: 2.644204134610115

Epoch: 5| Step: 8
Training loss: 2.9138509146857765
Validation loss: 2.6682020194191756

Epoch: 5| Step: 9
Training loss: 2.446756052607051
Validation loss: 2.6481273180418556

Epoch: 5| Step: 10
Training loss: 2.812825162952519
Validation loss: 2.635594475593487

Epoch: 375| Step: 0
Training loss: 2.867123137954804
Validation loss: 2.625390889469747

Epoch: 5| Step: 1
Training loss: 2.4879349448110206
Validation loss: 2.6119533162894917

Epoch: 5| Step: 2
Training loss: 3.144764463886794
Validation loss: 2.6172484972229055

Epoch: 5| Step: 3
Training loss: 3.067375506149767
Validation loss: 2.6168469367376574

Epoch: 5| Step: 4
Training loss: 2.9616046244559926
Validation loss: 2.5918728405515306

Epoch: 5| Step: 5
Training loss: 2.7921974664391764
Validation loss: 2.5910081026736402

Epoch: 5| Step: 6
Training loss: 2.9658913753010996
Validation loss: 2.581253821110367

Epoch: 5| Step: 7
Training loss: 2.255481718083552
Validation loss: 2.572716684795214

Epoch: 5| Step: 8
Training loss: 3.5618191787942797
Validation loss: 2.57924139935142

Epoch: 5| Step: 9
Training loss: 2.9572911822265
Validation loss: 2.583445133432386

Epoch: 5| Step: 10
Training loss: 2.5952934360894875
Validation loss: 2.579703827587029

Epoch: 376| Step: 0
Training loss: 2.656731326306716
Validation loss: 2.582258697287252

Epoch: 5| Step: 1
Training loss: 3.1231099325736102
Validation loss: 2.5785616438124177

Epoch: 5| Step: 2
Training loss: 2.55642258637427
Validation loss: 2.5789967166653396

Epoch: 5| Step: 3
Training loss: 3.164891414617696
Validation loss: 2.5860115826076786

Epoch: 5| Step: 4
Training loss: 3.1385544361488193
Validation loss: 2.60258694945819

Epoch: 5| Step: 5
Training loss: 2.7777616934840457
Validation loss: 2.5862510517576798

Epoch: 5| Step: 6
Training loss: 2.981436356132142
Validation loss: 2.5919067281390133

Epoch: 5| Step: 7
Training loss: 3.1272789846704474
Validation loss: 2.5996273349529155

Epoch: 5| Step: 8
Training loss: 2.569066821234943
Validation loss: 2.6003581954352395

Epoch: 5| Step: 9
Training loss: 2.89633390276293
Validation loss: 2.6278913476707166

Epoch: 5| Step: 10
Training loss: 2.7598158176444594
Validation loss: 2.63377413151044

Epoch: 377| Step: 0
Training loss: 2.9523191614028
Validation loss: 2.6282164404870216

Epoch: 5| Step: 1
Training loss: 2.975215256540929
Validation loss: 2.607385749684932

Epoch: 5| Step: 2
Training loss: 2.9833720654010345
Validation loss: 2.5928532038075014

Epoch: 5| Step: 3
Training loss: 2.8648898613815295
Validation loss: 2.5953742707641823

Epoch: 5| Step: 4
Training loss: 2.868932541169494
Validation loss: 2.6025228011833357

Epoch: 5| Step: 5
Training loss: 2.99840042067477
Validation loss: 2.6011998211608924

Epoch: 5| Step: 6
Training loss: 2.7916758712692724
Validation loss: 2.5963417425092987

Epoch: 5| Step: 7
Training loss: 3.199895952440534
Validation loss: 2.5979928966077037

Epoch: 5| Step: 8
Training loss: 2.2757467490559278
Validation loss: 2.5886268363194573

Epoch: 5| Step: 9
Training loss: 2.857552369606539
Validation loss: 2.582346078207041

Epoch: 5| Step: 10
Training loss: 2.832162746139013
Validation loss: 2.5877266726157733

Epoch: 378| Step: 0
Training loss: 3.3131275662158757
Validation loss: 2.567500333259881

Epoch: 5| Step: 1
Training loss: 3.009932922426971
Validation loss: 2.57520902266974

Epoch: 5| Step: 2
Training loss: 2.9415138903777347
Validation loss: 2.5711990873550947

Epoch: 5| Step: 3
Training loss: 3.2606418682157092
Validation loss: 2.5762698243461455

Epoch: 5| Step: 4
Training loss: 3.0990056565889503
Validation loss: 2.5597621779473716

Epoch: 5| Step: 5
Training loss: 3.001886092798283
Validation loss: 2.567136169662997

Epoch: 5| Step: 6
Training loss: 2.6475613475460347
Validation loss: 2.573970098927538

Epoch: 5| Step: 7
Training loss: 2.388654008550568
Validation loss: 2.5749683633452416

Epoch: 5| Step: 8
Training loss: 2.9722080369018626
Validation loss: 2.5784316108380008

Epoch: 5| Step: 9
Training loss: 2.4732920716572098
Validation loss: 2.5699068376393086

Epoch: 5| Step: 10
Training loss: 2.4769329191140836
Validation loss: 2.5740885947436882

Epoch: 379| Step: 0
Training loss: 3.3884417980701236
Validation loss: 2.5765058069706783

Epoch: 5| Step: 1
Training loss: 3.026214664698851
Validation loss: 2.5858688461865644

Epoch: 5| Step: 2
Training loss: 2.907367942481018
Validation loss: 2.5769796980336612

Epoch: 5| Step: 3
Training loss: 2.8433093054390834
Validation loss: 2.5852214383314993

Epoch: 5| Step: 4
Training loss: 3.006314784123212
Validation loss: 2.6066869156088774

Epoch: 5| Step: 5
Training loss: 2.6191903265348566
Validation loss: 2.601333808646129

Epoch: 5| Step: 6
Training loss: 2.6775766850735505
Validation loss: 2.6014392196228546

Epoch: 5| Step: 7
Training loss: 2.688469290593598
Validation loss: 2.604057771108214

Epoch: 5| Step: 8
Training loss: 2.558542871333346
Validation loss: 2.613384055776694

Epoch: 5| Step: 9
Training loss: 3.3409003833853084
Validation loss: 2.626464433308195

Epoch: 5| Step: 10
Training loss: 2.470825674764548
Validation loss: 2.5993793835408563

Epoch: 380| Step: 0
Training loss: 2.7543494767438395
Validation loss: 2.5970059855514225

Epoch: 5| Step: 1
Training loss: 2.452209496203178
Validation loss: 2.5838828903217523

Epoch: 5| Step: 2
Training loss: 3.000599801184776
Validation loss: 2.5889236542382004

Epoch: 5| Step: 3
Training loss: 2.659138802821029
Validation loss: 2.580763777062884

Epoch: 5| Step: 4
Training loss: 2.806758360493767
Validation loss: 2.5820341829583584

Epoch: 5| Step: 5
Training loss: 2.80084100763264
Validation loss: 2.594976797019709

Epoch: 5| Step: 6
Training loss: 2.8822338484927728
Validation loss: 2.589308603903793

Epoch: 5| Step: 7
Training loss: 3.1732938252188174
Validation loss: 2.593202655010022

Epoch: 5| Step: 8
Training loss: 2.8356842684589805
Validation loss: 2.591253631834451

Epoch: 5| Step: 9
Training loss: 3.3160775496890538
Validation loss: 2.587549861700793

Epoch: 5| Step: 10
Training loss: 2.9126405084468137
Validation loss: 2.5976877646547303

Epoch: 381| Step: 0
Training loss: 3.0854465528676767
Validation loss: 2.576213564878227

Epoch: 5| Step: 1
Training loss: 2.871583650274263
Validation loss: 2.586582856879906

Epoch: 5| Step: 2
Training loss: 3.2173595202766574
Validation loss: 2.5830672051268535

Epoch: 5| Step: 3
Training loss: 2.576297459061103
Validation loss: 2.595907585733201

Epoch: 5| Step: 4
Training loss: 3.106584840223559
Validation loss: 2.6177836596723503

Epoch: 5| Step: 5
Training loss: 3.08714081686546
Validation loss: 2.6170480058252914

Epoch: 5| Step: 6
Training loss: 2.7076911067001306
Validation loss: 2.6114723187292452

Epoch: 5| Step: 7
Training loss: 2.287391026303626
Validation loss: 2.599229411853009

Epoch: 5| Step: 8
Training loss: 2.851730049123039
Validation loss: 2.6001786684122337

Epoch: 5| Step: 9
Training loss: 3.2402184815387787
Validation loss: 2.6037661894635042

Epoch: 5| Step: 10
Training loss: 2.290865659886928
Validation loss: 2.5924510863803985

Epoch: 382| Step: 0
Training loss: 2.7444360105699825
Validation loss: 2.6002893584242335

Epoch: 5| Step: 1
Training loss: 2.860455084920349
Validation loss: 2.599363537397003

Epoch: 5| Step: 2
Training loss: 2.7062687756457517
Validation loss: 2.58605113119213

Epoch: 5| Step: 3
Training loss: 3.0803075498138868
Validation loss: 2.578844611256902

Epoch: 5| Step: 4
Training loss: 2.519230503792337
Validation loss: 2.5859636563755695

Epoch: 5| Step: 5
Training loss: 3.3304196179833174
Validation loss: 2.5836989580347853

Epoch: 5| Step: 6
Training loss: 3.009791290550044
Validation loss: 2.591028549319348

Epoch: 5| Step: 7
Training loss: 2.6365164672117376
Validation loss: 2.6003075571976657

Epoch: 5| Step: 8
Training loss: 2.746239084492079
Validation loss: 2.616837913002155

Epoch: 5| Step: 9
Training loss: 2.844888647813308
Validation loss: 2.5952605805403866

Epoch: 5| Step: 10
Training loss: 3.0315001079767563
Validation loss: 2.630420183007838

Epoch: 383| Step: 0
Training loss: 2.6887053514619224
Validation loss: 2.6535977213477326

Epoch: 5| Step: 1
Training loss: 2.989042935504287
Validation loss: 2.685252792350607

Epoch: 5| Step: 2
Training loss: 2.2765415669816065
Validation loss: 2.677350677577312

Epoch: 5| Step: 3
Training loss: 3.3447527941489614
Validation loss: 2.6885788972871563

Epoch: 5| Step: 4
Training loss: 2.68021683427807
Validation loss: 2.6658590950025793

Epoch: 5| Step: 5
Training loss: 2.837762082805893
Validation loss: 2.661316488926024

Epoch: 5| Step: 6
Training loss: 2.761036746837846
Validation loss: 2.6584134233077528

Epoch: 5| Step: 7
Training loss: 2.713577260511867
Validation loss: 2.622182393534857

Epoch: 5| Step: 8
Training loss: 3.2632851134631937
Validation loss: 2.5897722121938003

Epoch: 5| Step: 9
Training loss: 2.8941162470819197
Validation loss: 2.5682756677083955

Epoch: 5| Step: 10
Training loss: 3.118903201818231
Validation loss: 2.5702607860637237

Epoch: 384| Step: 0
Training loss: 2.629572745599911
Validation loss: 2.5558670580684315

Epoch: 5| Step: 1
Training loss: 2.884663470918939
Validation loss: 2.5637155506557443

Epoch: 5| Step: 2
Training loss: 2.4011243252927774
Validation loss: 2.5607512104454493

Epoch: 5| Step: 3
Training loss: 3.3944132513294223
Validation loss: 2.5687549503690796

Epoch: 5| Step: 4
Training loss: 2.7320169799187655
Validation loss: 2.556828637473069

Epoch: 5| Step: 5
Training loss: 2.8140401226130423
Validation loss: 2.5585749899996726

Epoch: 5| Step: 6
Training loss: 3.1447634024843554
Validation loss: 2.5619591002766486

Epoch: 5| Step: 7
Training loss: 2.975202434929192
Validation loss: 2.568283160151198

Epoch: 5| Step: 8
Training loss: 3.0460283717075844
Validation loss: 2.5650395610679904

Epoch: 5| Step: 9
Training loss: 2.9918139351501445
Validation loss: 2.568414668628039

Epoch: 5| Step: 10
Training loss: 2.909668911061372
Validation loss: 2.5714701618074205

Epoch: 385| Step: 0
Training loss: 2.9964564376203024
Validation loss: 2.5744051640393906

Epoch: 5| Step: 1
Training loss: 2.5268761793384353
Validation loss: 2.5749612527543078

Epoch: 5| Step: 2
Training loss: 2.7876606471551573
Validation loss: 2.5984680718196063

Epoch: 5| Step: 3
Training loss: 3.643970573122231
Validation loss: 2.6038161480358535

Epoch: 5| Step: 4
Training loss: 2.9563463191336
Validation loss: 2.6373868036855144

Epoch: 5| Step: 5
Training loss: 2.894194013175495
Validation loss: 2.668014230744222

Epoch: 5| Step: 6
Training loss: 2.3981696858441963
Validation loss: 2.6999870977925218

Epoch: 5| Step: 7
Training loss: 2.663087459461657
Validation loss: 2.7659340184039554

Epoch: 5| Step: 8
Training loss: 3.3170008760945056
Validation loss: 2.7201184836280947

Epoch: 5| Step: 9
Training loss: 2.8631340290852365
Validation loss: 2.64860312724119

Epoch: 5| Step: 10
Training loss: 2.667995380140248
Validation loss: 2.5839823203041905

Epoch: 386| Step: 0
Training loss: 3.1777829926751067
Validation loss: 2.582772470602308

Epoch: 5| Step: 1
Training loss: 2.993684956714075
Validation loss: 2.5663741094712145

Epoch: 5| Step: 2
Training loss: 2.407915207976334
Validation loss: 2.5585722225297753

Epoch: 5| Step: 3
Training loss: 2.811854563933668
Validation loss: 2.5521846524272083

Epoch: 5| Step: 4
Training loss: 2.8897063574057573
Validation loss: 2.5590906991483955

Epoch: 5| Step: 5
Training loss: 3.069077726372393
Validation loss: 2.556934644959979

Epoch: 5| Step: 6
Training loss: 2.8095451939918177
Validation loss: 2.5573706854757634

Epoch: 5| Step: 7
Training loss: 2.4870870889678054
Validation loss: 2.5566159194224767

Epoch: 5| Step: 8
Training loss: 3.076067861584771
Validation loss: 2.5621351396997665

Epoch: 5| Step: 9
Training loss: 3.215622502836661
Validation loss: 2.5639569072413977

Epoch: 5| Step: 10
Training loss: 2.797198484670042
Validation loss: 2.558733673640756

Epoch: 387| Step: 0
Training loss: 3.0326085143396133
Validation loss: 2.5701513812479413

Epoch: 5| Step: 1
Training loss: 2.5682452854591125
Validation loss: 2.5725758545080946

Epoch: 5| Step: 2
Training loss: 2.2798584129474264
Validation loss: 2.5641989489551706

Epoch: 5| Step: 3
Training loss: 2.9141642780274166
Validation loss: 2.567795628669943

Epoch: 5| Step: 4
Training loss: 3.0317951773958387
Validation loss: 2.5821441347212266

Epoch: 5| Step: 5
Training loss: 2.8189406505993633
Validation loss: 2.5823033967741362

Epoch: 5| Step: 6
Training loss: 2.872378273452294
Validation loss: 2.593305440700462

Epoch: 5| Step: 7
Training loss: 2.8941328878836043
Validation loss: 2.59257187114374

Epoch: 5| Step: 8
Training loss: 3.206946795858148
Validation loss: 2.600520320287229

Epoch: 5| Step: 9
Training loss: 3.0188511801876086
Validation loss: 2.6031501968425506

Epoch: 5| Step: 10
Training loss: 3.0181164505158695
Validation loss: 2.5903841792793676

Epoch: 388| Step: 0
Training loss: 2.6985185656273787
Validation loss: 2.5795638140566983

Epoch: 5| Step: 1
Training loss: 2.956876924587116
Validation loss: 2.5792861734921324

Epoch: 5| Step: 2
Training loss: 3.066980937389814
Validation loss: 2.5583328050128724

Epoch: 5| Step: 3
Training loss: 3.0907285173473804
Validation loss: 2.5628684874679335

Epoch: 5| Step: 4
Training loss: 3.035436511754863
Validation loss: 2.5586626907926324

Epoch: 5| Step: 5
Training loss: 2.8742459178987483
Validation loss: 2.55538462381827

Epoch: 5| Step: 6
Training loss: 2.9941097290276466
Validation loss: 2.5683464936775153

Epoch: 5| Step: 7
Training loss: 2.9549567783247825
Validation loss: 2.5540054603513984

Epoch: 5| Step: 8
Training loss: 2.68979901296799
Validation loss: 2.555658557365281

Epoch: 5| Step: 9
Training loss: 2.5004964335598654
Validation loss: 2.557275225229335

Epoch: 5| Step: 10
Training loss: 2.7527204408992625
Validation loss: 2.571027146526994

Epoch: 389| Step: 0
Training loss: 2.7479908279310297
Validation loss: 2.573310743820724

Epoch: 5| Step: 1
Training loss: 2.7203053377376007
Validation loss: 2.589493721762557

Epoch: 5| Step: 2
Training loss: 3.5427355032356327
Validation loss: 2.606313376026117

Epoch: 5| Step: 3
Training loss: 2.972091079702532
Validation loss: 2.6213177149930593

Epoch: 5| Step: 4
Training loss: 2.7670951427209056
Validation loss: 2.6562604620460277

Epoch: 5| Step: 5
Training loss: 3.0231149585203005
Validation loss: 2.6481736148771997

Epoch: 5| Step: 6
Training loss: 2.5231505428643746
Validation loss: 2.6277462890679595

Epoch: 5| Step: 7
Training loss: 2.8653595213807947
Validation loss: 2.5929990635925053

Epoch: 5| Step: 8
Training loss: 3.3257905178106717
Validation loss: 2.592685971952426

Epoch: 5| Step: 9
Training loss: 2.817900749213104
Validation loss: 2.582740106920421

Epoch: 5| Step: 10
Training loss: 1.9709167667119158
Validation loss: 2.5867319711083487

Epoch: 390| Step: 0
Training loss: 2.9910276072205955
Validation loss: 2.605077460382481

Epoch: 5| Step: 1
Training loss: 2.297143829598997
Validation loss: 2.6038132770266156

Epoch: 5| Step: 2
Training loss: 3.2741000795442377
Validation loss: 2.6196475328884694

Epoch: 5| Step: 3
Training loss: 2.5169683625055765
Validation loss: 2.6444555165022363

Epoch: 5| Step: 4
Training loss: 3.2105892391637827
Validation loss: 2.686680156699647

Epoch: 5| Step: 5
Training loss: 2.9361890749012294
Validation loss: 2.671967682367048

Epoch: 5| Step: 6
Training loss: 3.275990658086515
Validation loss: 2.6761702639563993

Epoch: 5| Step: 7
Training loss: 2.775110046679086
Validation loss: 2.6233925544011663

Epoch: 5| Step: 8
Training loss: 2.769032421303863
Validation loss: 2.620461265433545

Epoch: 5| Step: 9
Training loss: 2.9103341886666003
Validation loss: 2.5937510279270297

Epoch: 5| Step: 10
Training loss: 2.547705017764801
Validation loss: 2.5939638949306034

Epoch: 391| Step: 0
Training loss: 2.4910475656017845
Validation loss: 2.569606655787105

Epoch: 5| Step: 1
Training loss: 2.9910451436463754
Validation loss: 2.571192842758604

Epoch: 5| Step: 2
Training loss: 3.2146353486048014
Validation loss: 2.5694130400519923

Epoch: 5| Step: 3
Training loss: 2.6287736561681703
Validation loss: 2.5761893186748552

Epoch: 5| Step: 4
Training loss: 2.7980815480027887
Validation loss: 2.5734179785860865

Epoch: 5| Step: 5
Training loss: 2.7841986980344484
Validation loss: 2.5936837037765472

Epoch: 5| Step: 6
Training loss: 3.1340545703492078
Validation loss: 2.6156573780870884

Epoch: 5| Step: 7
Training loss: 3.098494465622169
Validation loss: 2.6285766946948383

Epoch: 5| Step: 8
Training loss: 3.0458048188161584
Validation loss: 2.644233354205368

Epoch: 5| Step: 9
Training loss: 2.7908698885476992
Validation loss: 2.651571142156576

Epoch: 5| Step: 10
Training loss: 2.440266335444316
Validation loss: 2.635558885262191

Epoch: 392| Step: 0
Training loss: 2.581835302169148
Validation loss: 2.619229068764517

Epoch: 5| Step: 1
Training loss: 2.8663363739587857
Validation loss: 2.6224603844296155

Epoch: 5| Step: 2
Training loss: 2.8939552712190295
Validation loss: 2.6226404829526775

Epoch: 5| Step: 3
Training loss: 2.7218836121800645
Validation loss: 2.634028205714273

Epoch: 5| Step: 4
Training loss: 3.1710534746610874
Validation loss: 2.6516934753231394

Epoch: 5| Step: 5
Training loss: 2.390676759645709
Validation loss: 2.6604839402175884

Epoch: 5| Step: 6
Training loss: 3.0792508462661754
Validation loss: 2.6746056005371353

Epoch: 5| Step: 7
Training loss: 2.8113351740979953
Validation loss: 2.626559408124958

Epoch: 5| Step: 8
Training loss: 3.3434619244700334
Validation loss: 2.6377273002844066

Epoch: 5| Step: 9
Training loss: 2.588927231951742
Validation loss: 2.5805683807133586

Epoch: 5| Step: 10
Training loss: 3.051849842362358
Validation loss: 2.5736882147028957

Epoch: 393| Step: 0
Training loss: 2.9591405241905524
Validation loss: 2.5579804763313145

Epoch: 5| Step: 1
Training loss: 3.022235168011682
Validation loss: 2.5635031730649676

Epoch: 5| Step: 2
Training loss: 3.1184957335643078
Validation loss: 2.563360326425806

Epoch: 5| Step: 3
Training loss: 2.9261205499395135
Validation loss: 2.5643070751270844

Epoch: 5| Step: 4
Training loss: 3.035318691860416
Validation loss: 2.557634275592685

Epoch: 5| Step: 5
Training loss: 2.3712998729522545
Validation loss: 2.567092865342867

Epoch: 5| Step: 6
Training loss: 3.0850037526211413
Validation loss: 2.562104662620969

Epoch: 5| Step: 7
Training loss: 3.265047889346581
Validation loss: 2.5700218170214844

Epoch: 5| Step: 8
Training loss: 2.478247325134219
Validation loss: 2.571067504926345

Epoch: 5| Step: 9
Training loss: 2.756377541149439
Validation loss: 2.56380845525747

Epoch: 5| Step: 10
Training loss: 2.782509764922385
Validation loss: 2.5626756841470524

Epoch: 394| Step: 0
Training loss: 2.6735251166535616
Validation loss: 2.564627216414466

Epoch: 5| Step: 1
Training loss: 3.2723714690470436
Validation loss: 2.580213175529082

Epoch: 5| Step: 2
Training loss: 2.800961540516513
Validation loss: 2.5763954165684386

Epoch: 5| Step: 3
Training loss: 3.153323488065527
Validation loss: 2.5883945299390425

Epoch: 5| Step: 4
Training loss: 3.5846051169695796
Validation loss: 2.583162821786762

Epoch: 5| Step: 5
Training loss: 2.7056193226952754
Validation loss: 2.5907803775783584

Epoch: 5| Step: 6
Training loss: 3.2543747142237036
Validation loss: 2.5890289001266953

Epoch: 5| Step: 7
Training loss: 2.0859142973677356
Validation loss: 2.5845482811105835

Epoch: 5| Step: 8
Training loss: 2.3811920158955977
Validation loss: 2.5948773457143446

Epoch: 5| Step: 9
Training loss: 2.6504886752427996
Validation loss: 2.6295422341174137

Epoch: 5| Step: 10
Training loss: 2.873403520575073
Validation loss: 2.6263163606553515

Epoch: 395| Step: 0
Training loss: 2.631373071397373
Validation loss: 2.658237161310176

Epoch: 5| Step: 1
Training loss: 2.740988618745664
Validation loss: 2.649824105622673

Epoch: 5| Step: 2
Training loss: 2.682964223349464
Validation loss: 2.614579491015379

Epoch: 5| Step: 3
Training loss: 3.531283893253758
Validation loss: 2.5963257672357947

Epoch: 5| Step: 4
Training loss: 2.8298385234365555
Validation loss: 2.5686565627587106

Epoch: 5| Step: 5
Training loss: 2.936577022914814
Validation loss: 2.5694259748947075

Epoch: 5| Step: 6
Training loss: 2.959574282420785
Validation loss: 2.5672301597841263

Epoch: 5| Step: 7
Training loss: 2.9949906169763483
Validation loss: 2.575245183738466

Epoch: 5| Step: 8
Training loss: 2.7397960004950392
Validation loss: 2.5726196435135265

Epoch: 5| Step: 9
Training loss: 2.731184225796209
Validation loss: 2.570626338027937

Epoch: 5| Step: 10
Training loss: 2.7171856117351654
Validation loss: 2.573927102807663

Epoch: 396| Step: 0
Training loss: 2.8113012514238536
Validation loss: 2.5640477714213787

Epoch: 5| Step: 1
Training loss: 3.058564596414778
Validation loss: 2.5725370474709974

Epoch: 5| Step: 2
Training loss: 2.983920237459525
Validation loss: 2.5749853900543145

Epoch: 5| Step: 3
Training loss: 2.1580186307596065
Validation loss: 2.586597407622871

Epoch: 5| Step: 4
Training loss: 2.8559998984991317
Validation loss: 2.5764766481332564

Epoch: 5| Step: 5
Training loss: 2.5962941205202084
Validation loss: 2.574514078402838

Epoch: 5| Step: 6
Training loss: 2.973514949172797
Validation loss: 2.568507217612006

Epoch: 5| Step: 7
Training loss: 3.119206360355378
Validation loss: 2.582511389692285

Epoch: 5| Step: 8
Training loss: 2.9113635944563807
Validation loss: 2.589460957960424

Epoch: 5| Step: 9
Training loss: 2.88509255986346
Validation loss: 2.5762358435197035

Epoch: 5| Step: 10
Training loss: 3.0378074898515126
Validation loss: 2.58544633676508

Epoch: 397| Step: 0
Training loss: 3.0862873120561205
Validation loss: 2.5866412486622683

Epoch: 5| Step: 1
Training loss: 3.005862389080279
Validation loss: 2.5914939738424576

Epoch: 5| Step: 2
Training loss: 3.298823354931054
Validation loss: 2.591212089945928

Epoch: 5| Step: 3
Training loss: 2.113026037688534
Validation loss: 2.625740376573586

Epoch: 5| Step: 4
Training loss: 3.0885743283651013
Validation loss: 2.6307440463273823

Epoch: 5| Step: 5
Training loss: 2.8555018139971846
Validation loss: 2.6255106275497355

Epoch: 5| Step: 6
Training loss: 2.826210849495859
Validation loss: 2.6194130136164304

Epoch: 5| Step: 7
Training loss: 2.8707559192187504
Validation loss: 2.6071432727636554

Epoch: 5| Step: 8
Training loss: 2.657576644811373
Validation loss: 2.623196216029057

Epoch: 5| Step: 9
Training loss: 2.8722281984930706
Validation loss: 2.6482993169211095

Epoch: 5| Step: 10
Training loss: 2.429834097705151
Validation loss: 2.6426716146401166

Epoch: 398| Step: 0
Training loss: 3.1947994053393156
Validation loss: 2.6489204742921357

Epoch: 5| Step: 1
Training loss: 2.6754198261839
Validation loss: 2.6506897157434404

Epoch: 5| Step: 2
Training loss: 3.0474192597831795
Validation loss: 2.619581633716044

Epoch: 5| Step: 3
Training loss: 2.705092932044312
Validation loss: 2.621546263886401

Epoch: 5| Step: 4
Training loss: 3.0714255298079833
Validation loss: 2.615946803259326

Epoch: 5| Step: 5
Training loss: 2.7163323362452165
Validation loss: 2.5788124249396374

Epoch: 5| Step: 6
Training loss: 2.7280627825831525
Validation loss: 2.574030280735609

Epoch: 5| Step: 7
Training loss: 2.555184132310665
Validation loss: 2.562856517834833

Epoch: 5| Step: 8
Training loss: 2.8526288272742897
Validation loss: 2.569842517048615

Epoch: 5| Step: 9
Training loss: 2.7850875953034553
Validation loss: 2.5966737549491925

Epoch: 5| Step: 10
Training loss: 3.036665336309896
Validation loss: 2.5868055047186185

Epoch: 399| Step: 0
Training loss: 2.7460612787576126
Validation loss: 2.588203804443694

Epoch: 5| Step: 1
Training loss: 2.805447446253047
Validation loss: 2.633406753056522

Epoch: 5| Step: 2
Training loss: 2.6427643365656057
Validation loss: 2.6352144817393395

Epoch: 5| Step: 3
Training loss: 2.571803440289681
Validation loss: 2.6510576306959255

Epoch: 5| Step: 4
Training loss: 2.8508172720559175
Validation loss: 2.652705275562344

Epoch: 5| Step: 5
Training loss: 3.4188291327821805
Validation loss: 2.6650080922635784

Epoch: 5| Step: 6
Training loss: 3.016228650013961
Validation loss: 2.6408228097770166

Epoch: 5| Step: 7
Training loss: 3.037597303048625
Validation loss: 2.611274808216238

Epoch: 5| Step: 8
Training loss: 3.082506807912222
Validation loss: 2.594310698411564

Epoch: 5| Step: 9
Training loss: 2.342276351495464
Validation loss: 2.5718267061041855

Epoch: 5| Step: 10
Training loss: 2.9115368736378273
Validation loss: 2.5609133660792875

Epoch: 400| Step: 0
Training loss: 2.850038722260417
Validation loss: 2.5584941419725613

Epoch: 5| Step: 1
Training loss: 2.8099426510752035
Validation loss: 2.5603720320400774

Epoch: 5| Step: 2
Training loss: 3.1836632469408372
Validation loss: 2.5685650701372706

Epoch: 5| Step: 3
Training loss: 2.7200059291831074
Validation loss: 2.567332457509248

Epoch: 5| Step: 4
Training loss: 3.203938599511307
Validation loss: 2.5616333339031216

Epoch: 5| Step: 5
Training loss: 3.3099773085816153
Validation loss: 2.5565208852547676

Epoch: 5| Step: 6
Training loss: 2.6569455302049523
Validation loss: 2.5553293677748545

Epoch: 5| Step: 7
Training loss: 2.600338392978038
Validation loss: 2.5541243725125002

Epoch: 5| Step: 8
Training loss: 2.9350169624215376
Validation loss: 2.5645486109595796

Epoch: 5| Step: 9
Training loss: 2.5306814991717634
Validation loss: 2.5612961437120654

Epoch: 5| Step: 10
Training loss: 2.6047536163085296
Validation loss: 2.5803295774117183

Testing loss: 2.7524608814163396
