Epoch: 1| Step: 0
Training loss: 5.676718753225551
Validation loss: 5.81800066324135

Epoch: 5| Step: 1
Training loss: 5.672116108963607
Validation loss: 5.80860894664874

Epoch: 5| Step: 2
Training loss: 6.384885416339525
Validation loss: 5.799034014447971

Epoch: 5| Step: 3
Training loss: 6.214493871751041
Validation loss: 5.789352355930389

Epoch: 5| Step: 4
Training loss: 5.109734478824882
Validation loss: 5.779113364059432

Epoch: 5| Step: 5
Training loss: 6.08389784749866
Validation loss: 5.768914403852397

Epoch: 5| Step: 6
Training loss: 5.354555860492518
Validation loss: 5.757810063615604

Epoch: 5| Step: 7
Training loss: 5.851190573022397
Validation loss: 5.746721346819407

Epoch: 5| Step: 8
Training loss: 5.969722009573145
Validation loss: 5.73383810118346

Epoch: 5| Step: 9
Training loss: 5.166855511239253
Validation loss: 5.720755208669849

Epoch: 5| Step: 10
Training loss: 6.248426620805889
Validation loss: 5.706039004761593

Epoch: 2| Step: 0
Training loss: 5.215255389593737
Validation loss: 5.690961345009433

Epoch: 5| Step: 1
Training loss: 6.155320460439336
Validation loss: 5.6746273054095075

Epoch: 5| Step: 2
Training loss: 5.49080652535018
Validation loss: 5.656595108417187

Epoch: 5| Step: 3
Training loss: 5.768558572587358
Validation loss: 5.637027698156823

Epoch: 5| Step: 4
Training loss: 5.468029563316008
Validation loss: 5.616762962524853

Epoch: 5| Step: 5
Training loss: 6.501340874504574
Validation loss: 5.594671874974662

Epoch: 5| Step: 6
Training loss: 6.571574014037479
Validation loss: 5.569735802104256

Epoch: 5| Step: 7
Training loss: 5.755946194628558
Validation loss: 5.545053910409529

Epoch: 5| Step: 8
Training loss: 4.687785228952283
Validation loss: 5.5180173645671635

Epoch: 5| Step: 9
Training loss: 4.545913856881744
Validation loss: 5.488552975255025

Epoch: 5| Step: 10
Training loss: 5.331457086188093
Validation loss: 5.458858904615726

Epoch: 3| Step: 0
Training loss: 5.218725512784055
Validation loss: 5.425947795360016

Epoch: 5| Step: 1
Training loss: 5.950558407008926
Validation loss: 5.3935046945250456

Epoch: 5| Step: 2
Training loss: 5.626356681824252
Validation loss: 5.356439633327688

Epoch: 5| Step: 3
Training loss: 5.128315109271792
Validation loss: 5.3181566923566725

Epoch: 5| Step: 4
Training loss: 5.8205032214976775
Validation loss: 5.279782824358359

Epoch: 5| Step: 5
Training loss: 4.551809877377353
Validation loss: 5.2392407755478265

Epoch: 5| Step: 6
Training loss: 5.025540352231706
Validation loss: 5.199707400780164

Epoch: 5| Step: 7
Training loss: 4.426795405580227
Validation loss: 5.157958073015296

Epoch: 5| Step: 8
Training loss: 5.550374734960363
Validation loss: 5.117847039977323

Epoch: 5| Step: 9
Training loss: 5.494013909954491
Validation loss: 5.0754894733215155

Epoch: 5| Step: 10
Training loss: 5.187098659938383
Validation loss: 5.03510542860889

Epoch: 4| Step: 0
Training loss: 4.193600211048085
Validation loss: 4.994718218907776

Epoch: 5| Step: 1
Training loss: 6.610499798091397
Validation loss: 4.955630288030467

Epoch: 5| Step: 2
Training loss: 3.8832451255068805
Validation loss: 4.917839070411855

Epoch: 5| Step: 3
Training loss: 4.9340617123298225
Validation loss: 4.881546780254877

Epoch: 5| Step: 4
Training loss: 4.172963204063249
Validation loss: 4.846322164831946

Epoch: 5| Step: 5
Training loss: 5.300780350439773
Validation loss: 4.814982644984367

Epoch: 5| Step: 6
Training loss: 4.825591672681711
Validation loss: 4.7832661532714935

Epoch: 5| Step: 7
Training loss: 4.393060083608391
Validation loss: 4.7553103306553375

Epoch: 5| Step: 8
Training loss: 5.048624497223461
Validation loss: 4.7293208747033875

Epoch: 5| Step: 9
Training loss: 5.603793882240298
Validation loss: 4.704980671302966

Epoch: 5| Step: 10
Training loss: 4.206008999454377
Validation loss: 4.6815882724831495

Epoch: 5| Step: 0
Training loss: 4.703451253024229
Validation loss: 4.658752174324657

Epoch: 5| Step: 1
Training loss: 4.505560300745872
Validation loss: 4.639802714804692

Epoch: 5| Step: 2
Training loss: 5.75356116104935
Validation loss: 4.619771332668345

Epoch: 5| Step: 3
Training loss: 3.13301416827717
Validation loss: 4.599943257499512

Epoch: 5| Step: 4
Training loss: 4.16016129327746
Validation loss: 4.581642577727083

Epoch: 5| Step: 5
Training loss: 4.129575792375723
Validation loss: 4.563793806369569

Epoch: 5| Step: 6
Training loss: 4.951084041380681
Validation loss: 4.549197759337179

Epoch: 5| Step: 7
Training loss: 4.655315330961854
Validation loss: 4.531232578808453

Epoch: 5| Step: 8
Training loss: 5.439925781753491
Validation loss: 4.516556000705606

Epoch: 5| Step: 9
Training loss: 4.335123401544206
Validation loss: 4.4981211906924825

Epoch: 5| Step: 10
Training loss: 5.087130686409134
Validation loss: 4.483608531789416

Epoch: 6| Step: 0
Training loss: 3.258660441676228
Validation loss: 4.466179058040221

Epoch: 5| Step: 1
Training loss: 4.826398719881262
Validation loss: 4.455943449866878

Epoch: 5| Step: 2
Training loss: 4.582849557949811
Validation loss: 4.444224633828002

Epoch: 5| Step: 3
Training loss: 3.509445116356607
Validation loss: 4.4328032032681906

Epoch: 5| Step: 4
Training loss: 3.950346441407527
Validation loss: 4.419624820819156

Epoch: 5| Step: 5
Training loss: 3.8867116343370793
Validation loss: 4.408496971186283

Epoch: 5| Step: 6
Training loss: 4.222216728831504
Validation loss: 4.394900858112714

Epoch: 5| Step: 7
Training loss: 5.120927262382403
Validation loss: 4.384711666648983

Epoch: 5| Step: 8
Training loss: 4.406291339220418
Validation loss: 4.3702081845552465

Epoch: 5| Step: 9
Training loss: 6.231073332245912
Validation loss: 4.356614825262925

Epoch: 5| Step: 10
Training loss: 4.981897964357611
Validation loss: 4.340442948718597

Epoch: 7| Step: 0
Training loss: 5.209130106697841
Validation loss: 4.326458296829757

Epoch: 5| Step: 1
Training loss: 4.01363789713416
Validation loss: 4.313827555232436

Epoch: 5| Step: 2
Training loss: 4.526843644860044
Validation loss: 4.304287872277194

Epoch: 5| Step: 3
Training loss: 4.046716164082488
Validation loss: 4.292327523336743

Epoch: 5| Step: 4
Training loss: 3.8328072698334297
Validation loss: 4.281093454728711

Epoch: 5| Step: 5
Training loss: 4.172771000458283
Validation loss: 4.26889983479214

Epoch: 5| Step: 6
Training loss: 4.975434419460628
Validation loss: 4.25796027031066

Epoch: 5| Step: 7
Training loss: 3.6093722256736496
Validation loss: 4.249938650731986

Epoch: 5| Step: 8
Training loss: 4.0096923702514555
Validation loss: 4.2401848532319075

Epoch: 5| Step: 9
Training loss: 4.875664103341041
Validation loss: 4.233524510300519

Epoch: 5| Step: 10
Training loss: 4.871128207576602
Validation loss: 4.222178082936137

Epoch: 8| Step: 0
Training loss: 4.074484416898635
Validation loss: 4.211666271731833

Epoch: 5| Step: 1
Training loss: 5.1243482966215215
Validation loss: 4.2023475599813755

Epoch: 5| Step: 2
Training loss: 3.7256628586013942
Validation loss: 4.192840090239139

Epoch: 5| Step: 3
Training loss: 4.529180646147761
Validation loss: 4.185873473338192

Epoch: 5| Step: 4
Training loss: 4.3737012842893535
Validation loss: 4.1793487267397476

Epoch: 5| Step: 5
Training loss: 3.683632713912762
Validation loss: 4.171503652474451

Epoch: 5| Step: 6
Training loss: 4.406520537600048
Validation loss: 4.163255555737815

Epoch: 5| Step: 7
Training loss: 3.7258077372951073
Validation loss: 4.151703968506334

Epoch: 5| Step: 8
Training loss: 5.019828579776098
Validation loss: 4.145099845645653

Epoch: 5| Step: 9
Training loss: 3.997825985440497
Validation loss: 4.1354085638495315

Epoch: 5| Step: 10
Training loss: 4.4186540606711615
Validation loss: 4.127682121826642

Epoch: 9| Step: 0
Training loss: 4.2827063540721495
Validation loss: 4.121335698785632

Epoch: 5| Step: 1
Training loss: 3.3489869365192457
Validation loss: 4.112131677122063

Epoch: 5| Step: 2
Training loss: 4.377434189594233
Validation loss: 4.104303981811109

Epoch: 5| Step: 3
Training loss: 4.541623783200758
Validation loss: 4.09566656026489

Epoch: 5| Step: 4
Training loss: 4.197172466538299
Validation loss: 4.090825257012553

Epoch: 5| Step: 5
Training loss: 4.342544058936949
Validation loss: 4.083830376049938

Epoch: 5| Step: 6
Training loss: 3.9317883436761667
Validation loss: 4.070604487821401

Epoch: 5| Step: 7
Training loss: 3.793146131239477
Validation loss: 4.066743244816512

Epoch: 5| Step: 8
Training loss: 4.662796845587182
Validation loss: 4.056274695211988

Epoch: 5| Step: 9
Training loss: 4.307072416704226
Validation loss: 4.046000956520582

Epoch: 5| Step: 10
Training loss: 4.57254406823832
Validation loss: 4.041797088220367

Epoch: 10| Step: 0
Training loss: 4.1552985687033805
Validation loss: 4.035782719443345

Epoch: 5| Step: 1
Training loss: 3.7189482307492754
Validation loss: 4.029349134973762

Epoch: 5| Step: 2
Training loss: 3.7524074456112064
Validation loss: 4.020187419562432

Epoch: 5| Step: 3
Training loss: 4.348802002554482
Validation loss: 4.013461431927476

Epoch: 5| Step: 4
Training loss: 4.3100517068049236
Validation loss: 4.005284425785097

Epoch: 5| Step: 5
Training loss: 4.036657919922815
Validation loss: 3.99781380150691

Epoch: 5| Step: 6
Training loss: 3.5051768028953494
Validation loss: 3.9905771663563714

Epoch: 5| Step: 7
Training loss: 4.841416122773639
Validation loss: 3.9840532906882973

Epoch: 5| Step: 8
Training loss: 3.9593176303913324
Validation loss: 3.976731750108626

Epoch: 5| Step: 9
Training loss: 4.12023974785861
Validation loss: 3.967829430782033

Epoch: 5| Step: 10
Training loss: 4.819760678946553
Validation loss: 3.9634977052075766

Epoch: 11| Step: 0
Training loss: 4.328839515071125
Validation loss: 3.951340935836496

Epoch: 5| Step: 1
Training loss: 4.978822108308514
Validation loss: 3.9457881829573194

Epoch: 5| Step: 2
Training loss: 3.6635598689930386
Validation loss: 3.935579708353961

Epoch: 5| Step: 3
Training loss: 2.8604944257916936
Validation loss: 3.929684275947905

Epoch: 5| Step: 4
Training loss: 4.956013219500161
Validation loss: 3.9247588816761168

Epoch: 5| Step: 5
Training loss: 4.041993485178881
Validation loss: 3.9184530517876865

Epoch: 5| Step: 6
Training loss: 2.9771192936007917
Validation loss: 3.9085895343021777

Epoch: 5| Step: 7
Training loss: 4.0770280904768255
Validation loss: 3.9034140463578204

Epoch: 5| Step: 8
Training loss: 3.657699167352687
Validation loss: 3.898318542300331

Epoch: 5| Step: 9
Training loss: 3.7984084811998917
Validation loss: 3.887287220880405

Epoch: 5| Step: 10
Training loss: 5.015113305345563
Validation loss: 3.8820635735079003

Epoch: 12| Step: 0
Training loss: 3.8633582683172163
Validation loss: 3.869360998994513

Epoch: 5| Step: 1
Training loss: 4.234631520063791
Validation loss: 3.8604540509394414

Epoch: 5| Step: 2
Training loss: 4.237592424943263
Validation loss: 3.848213125102926

Epoch: 5| Step: 3
Training loss: 3.455651511168073
Validation loss: 3.8389548100804376

Epoch: 5| Step: 4
Training loss: 3.6676159121262732
Validation loss: 3.8319784639569305

Epoch: 5| Step: 5
Training loss: 4.0874695103059375
Validation loss: 3.8237096212185904

Epoch: 5| Step: 6
Training loss: 4.675062642213274
Validation loss: 3.8165806423483413

Epoch: 5| Step: 7
Training loss: 3.8829217968300433
Validation loss: 3.8067435802995684

Epoch: 5| Step: 8
Training loss: 3.224893872784445
Validation loss: 3.796912721748427

Epoch: 5| Step: 9
Training loss: 4.084908758893085
Validation loss: 3.788923950842221

Epoch: 5| Step: 10
Training loss: 4.350323211238026
Validation loss: 3.7825227387209774

Epoch: 13| Step: 0
Training loss: 4.072005902613951
Validation loss: 3.774473839785145

Epoch: 5| Step: 1
Training loss: 3.530304503666906
Validation loss: 3.767162307557913

Epoch: 5| Step: 2
Training loss: 4.11904986712486
Validation loss: 3.7575265477430024

Epoch: 5| Step: 3
Training loss: 3.734460550389707
Validation loss: 3.7506061187169966

Epoch: 5| Step: 4
Training loss: 4.701555059749742
Validation loss: 3.7442150396255935

Epoch: 5| Step: 5
Training loss: 3.461096077551797
Validation loss: 3.735202574895697

Epoch: 5| Step: 6
Training loss: 3.592834886884459
Validation loss: 3.7264353450387904

Epoch: 5| Step: 7
Training loss: 3.6741210561130324
Validation loss: 3.7187798335911584

Epoch: 5| Step: 8
Training loss: 4.034328024876595
Validation loss: 3.7090586226896267

Epoch: 5| Step: 9
Training loss: 3.7648708490558875
Validation loss: 3.7012953735876897

Epoch: 5| Step: 10
Training loss: 4.257077326869147
Validation loss: 3.693064310155105

Epoch: 14| Step: 0
Training loss: 4.294893008799084
Validation loss: 3.688148540225938

Epoch: 5| Step: 1
Training loss: 3.7089913173809435
Validation loss: 3.6750703647114493

Epoch: 5| Step: 2
Training loss: 3.64663762984725
Validation loss: 3.6690680805471025

Epoch: 5| Step: 3
Training loss: 2.7856232624763204
Validation loss: 3.657948985052052

Epoch: 5| Step: 4
Training loss: 3.6660039187179905
Validation loss: 3.653251852585428

Epoch: 5| Step: 5
Training loss: 4.597242001237735
Validation loss: 3.6443706230373243

Epoch: 5| Step: 6
Training loss: 3.72525532506679
Validation loss: 3.6345894283676516

Epoch: 5| Step: 7
Training loss: 4.116699189792507
Validation loss: 3.631631854776616

Epoch: 5| Step: 8
Training loss: 3.2946612261216885
Validation loss: 3.620122071003208

Epoch: 5| Step: 9
Training loss: 4.271369168542402
Validation loss: 3.6135298789128076

Epoch: 5| Step: 10
Training loss: 3.7554358185510055
Validation loss: 3.606298345591242

Epoch: 15| Step: 0
Training loss: 4.113861767558327
Validation loss: 3.6003691705603935

Epoch: 5| Step: 1
Training loss: 4.430864773080883
Validation loss: 3.5906761716766935

Epoch: 5| Step: 2
Training loss: 3.9199761280967813
Validation loss: 3.584780809692522

Epoch: 5| Step: 3
Training loss: 3.1907170834456315
Validation loss: 3.577815649553622

Epoch: 5| Step: 4
Training loss: 3.9917945145830434
Validation loss: 3.568920728843953

Epoch: 5| Step: 5
Training loss: 3.6063961270508704
Validation loss: 3.5645490566981004

Epoch: 5| Step: 6
Training loss: 3.510357789282576
Validation loss: 3.5605969270835898

Epoch: 5| Step: 7
Training loss: 3.668961428215205
Validation loss: 3.555241919653441

Epoch: 5| Step: 8
Training loss: 3.9131501556450656
Validation loss: 3.5403872186973206

Epoch: 5| Step: 9
Training loss: 3.955178914610821
Validation loss: 3.5370262354883457

Epoch: 5| Step: 10
Training loss: 2.7484276351187815
Validation loss: 3.5340071040592558

Epoch: 16| Step: 0
Training loss: 3.4409015818065343
Validation loss: 3.526604733576846

Epoch: 5| Step: 1
Training loss: 3.8714520609036978
Validation loss: 3.5221899066780256

Epoch: 5| Step: 2
Training loss: 3.122614293201914
Validation loss: 3.5123146417819804

Epoch: 5| Step: 3
Training loss: 2.6854129050390996
Validation loss: 3.5082632310988764

Epoch: 5| Step: 4
Training loss: 3.6832175522870743
Validation loss: 3.507405858953443

Epoch: 5| Step: 5
Training loss: 4.278970153119681
Validation loss: 3.500352387626866

Epoch: 5| Step: 6
Training loss: 3.3720520708401036
Validation loss: 3.495694763291592

Epoch: 5| Step: 7
Training loss: 3.935522400280597
Validation loss: 3.494434354133797

Epoch: 5| Step: 8
Training loss: 4.101185110986237
Validation loss: 3.483857610721346

Epoch: 5| Step: 9
Training loss: 4.153182654630028
Validation loss: 3.4807133063026625

Epoch: 5| Step: 10
Training loss: 3.8799501610533995
Validation loss: 3.4745430707984832

Epoch: 17| Step: 0
Training loss: 3.763655531352358
Validation loss: 3.470927357628364

Epoch: 5| Step: 1
Training loss: 3.099646449693601
Validation loss: 3.4671066546483953

Epoch: 5| Step: 2
Training loss: 4.2861313662349465
Validation loss: 3.465251679167071

Epoch: 5| Step: 3
Training loss: 4.083876956382629
Validation loss: 3.462458272223251

Epoch: 5| Step: 4
Training loss: 4.266508912110596
Validation loss: 3.453529123046524

Epoch: 5| Step: 5
Training loss: 2.8628090837348115
Validation loss: 3.4469996428298613

Epoch: 5| Step: 6
Training loss: 3.6169393961044984
Validation loss: 3.451114135677402

Epoch: 5| Step: 7
Training loss: 2.8613969501641487
Validation loss: 3.4485094521070563

Epoch: 5| Step: 8
Training loss: 3.874860945636948
Validation loss: 3.4420106537787087

Epoch: 5| Step: 9
Training loss: 3.436330977977814
Validation loss: 3.438459026541733

Epoch: 5| Step: 10
Training loss: 3.9029795879951306
Validation loss: 3.4322043712510117

Epoch: 18| Step: 0
Training loss: 3.296869503938695
Validation loss: 3.4316384271494704

Epoch: 5| Step: 1
Training loss: 4.604926390416814
Validation loss: 3.426098708502633

Epoch: 5| Step: 2
Training loss: 3.5015469266042154
Validation loss: 3.422581930273265

Epoch: 5| Step: 3
Training loss: 3.81670610388047
Validation loss: 3.420855530759528

Epoch: 5| Step: 4
Training loss: 3.9535541527646707
Validation loss: 3.418231933211835

Epoch: 5| Step: 5
Training loss: 3.420269315054006
Validation loss: 3.417013424360474

Epoch: 5| Step: 6
Training loss: 3.9261371204529563
Validation loss: 3.4129975294093984

Epoch: 5| Step: 7
Training loss: 3.6164063502089396
Validation loss: 3.4127583023090216

Epoch: 5| Step: 8
Training loss: 3.2899090545050123
Validation loss: 3.405474547888497

Epoch: 5| Step: 9
Training loss: 2.8007156172847303
Validation loss: 3.4042272824854027

Epoch: 5| Step: 10
Training loss: 3.5170145637095698
Validation loss: 3.4025268543091403

Epoch: 19| Step: 0
Training loss: 3.667369399498492
Validation loss: 3.398668754346463

Epoch: 5| Step: 1
Training loss: 3.4247157180755585
Validation loss: 3.3973680962856996

Epoch: 5| Step: 2
Training loss: 2.5904363584227608
Validation loss: 3.3955425336990888

Epoch: 5| Step: 3
Training loss: 3.7870446564061346
Validation loss: 3.3932530842201634

Epoch: 5| Step: 4
Training loss: 4.754855836112888
Validation loss: 3.3925159697618836

Epoch: 5| Step: 5
Training loss: 4.091235604405099
Validation loss: 3.3914617492018735

Epoch: 5| Step: 6
Training loss: 4.036397796505055
Validation loss: 3.3884401941117974

Epoch: 5| Step: 7
Training loss: 3.024212562911441
Validation loss: 3.3848240659160576

Epoch: 5| Step: 8
Training loss: 2.7346830358023086
Validation loss: 3.384795245490868

Epoch: 5| Step: 9
Training loss: 2.9556515497219937
Validation loss: 3.3842721983258857

Epoch: 5| Step: 10
Training loss: 4.189972560310192
Validation loss: 3.3846920482998764

Epoch: 20| Step: 0
Training loss: 3.8539490646931895
Validation loss: 3.379430701175831

Epoch: 5| Step: 1
Training loss: 4.3456513339610465
Validation loss: 3.3772666456946085

Epoch: 5| Step: 2
Training loss: 3.225960959456651
Validation loss: 3.374875643287593

Epoch: 5| Step: 3
Training loss: 3.834348019082946
Validation loss: 3.37571269736397

Epoch: 5| Step: 4
Training loss: 3.4221684578254403
Validation loss: 3.371347165008216

Epoch: 5| Step: 5
Training loss: 3.612447908547302
Validation loss: 3.371439060542328

Epoch: 5| Step: 6
Training loss: 2.9624344959340783
Validation loss: 3.368696248342942

Epoch: 5| Step: 7
Training loss: 2.9360565534960577
Validation loss: 3.368407770353744

Epoch: 5| Step: 8
Training loss: 3.6163475429065755
Validation loss: 3.367381954771427

Epoch: 5| Step: 9
Training loss: 3.9549291059889353
Validation loss: 3.366470717818854

Epoch: 5| Step: 10
Training loss: 3.6528651553792386
Validation loss: 3.3674806761719918

Epoch: 21| Step: 0
Training loss: 4.214277595345941
Validation loss: 3.363168693656999

Epoch: 5| Step: 1
Training loss: 3.7339242319961565
Validation loss: 3.364367851342434

Epoch: 5| Step: 2
Training loss: 3.8679252768461834
Validation loss: 3.364341220940683

Epoch: 5| Step: 3
Training loss: 2.86133779061934
Validation loss: 3.3626077888663484

Epoch: 5| Step: 4
Training loss: 3.1344215275514444
Validation loss: 3.3595687943861035

Epoch: 5| Step: 5
Training loss: 3.2664923725211374
Validation loss: 3.3569251485261558

Epoch: 5| Step: 6
Training loss: 4.015463027952993
Validation loss: 3.355746700689647

Epoch: 5| Step: 7
Training loss: 3.3496338601510334
Validation loss: 3.355249033969231

Epoch: 5| Step: 8
Training loss: 3.787449066524665
Validation loss: 3.3541149873496785

Epoch: 5| Step: 9
Training loss: 3.167993133865006
Validation loss: 3.351281370348974

Epoch: 5| Step: 10
Training loss: 3.8963123101889914
Validation loss: 3.350039727960021

Epoch: 22| Step: 0
Training loss: 3.5742663771160816
Validation loss: 3.347803377172192

Epoch: 5| Step: 1
Training loss: 4.242725429536369
Validation loss: 3.3483004554016347

Epoch: 5| Step: 2
Training loss: 3.294775850489417
Validation loss: 3.347974713373732

Epoch: 5| Step: 3
Training loss: 4.00285952400237
Validation loss: 3.3461798747209186

Epoch: 5| Step: 4
Training loss: 2.5961185349674074
Validation loss: 3.3445569830782356

Epoch: 5| Step: 5
Training loss: 3.391096091175383
Validation loss: 3.3421506394739646

Epoch: 5| Step: 6
Training loss: 4.569019832548838
Validation loss: 3.342782238665186

Epoch: 5| Step: 7
Training loss: 3.512355657577949
Validation loss: 3.341700488057886

Epoch: 5| Step: 8
Training loss: 3.392084326244703
Validation loss: 3.338884772009934

Epoch: 5| Step: 9
Training loss: 3.3284426255509456
Validation loss: 3.339220464673662

Epoch: 5| Step: 10
Training loss: 2.9522563322782545
Validation loss: 3.338469779905511

Epoch: 23| Step: 0
Training loss: 3.6388718472794355
Validation loss: 3.337572224091974

Epoch: 5| Step: 1
Training loss: 3.6754674341748936
Validation loss: 3.335456315650319

Epoch: 5| Step: 2
Training loss: 3.6482109963399756
Validation loss: 3.33372776763932

Epoch: 5| Step: 3
Training loss: 3.8222803457655976
Validation loss: 3.334268296284512

Epoch: 5| Step: 4
Training loss: 3.814117338730994
Validation loss: 3.333352966148231

Epoch: 5| Step: 5
Training loss: 3.131231275186497
Validation loss: 3.332006798609176

Epoch: 5| Step: 6
Training loss: 3.4820589998648845
Validation loss: 3.3310064721039883

Epoch: 5| Step: 7
Training loss: 2.771994287790465
Validation loss: 3.3296697246640083

Epoch: 5| Step: 8
Training loss: 3.8754748391890006
Validation loss: 3.3282322696612985

Epoch: 5| Step: 9
Training loss: 3.3987993420424605
Validation loss: 3.3270028087616033

Epoch: 5| Step: 10
Training loss: 3.9068095302390167
Validation loss: 3.3263804344373344

Epoch: 24| Step: 0
Training loss: 4.508862140171538
Validation loss: 3.3259103144328512

Epoch: 5| Step: 1
Training loss: 3.71595877390681
Validation loss: 3.321740912639342

Epoch: 5| Step: 2
Training loss: 2.601094705033014
Validation loss: 3.321219158657806

Epoch: 5| Step: 3
Training loss: 3.925642658273489
Validation loss: 3.319424015776983

Epoch: 5| Step: 4
Training loss: 3.757077722228309
Validation loss: 3.3194387476510596

Epoch: 5| Step: 5
Training loss: 3.064835416970653
Validation loss: 3.317589100860916

Epoch: 5| Step: 6
Training loss: 3.4314335786109784
Validation loss: 3.316893169006641

Epoch: 5| Step: 7
Training loss: 3.3730560638355587
Validation loss: 3.3143043324897863

Epoch: 5| Step: 8
Training loss: 3.139572650475269
Validation loss: 3.3146082197625244

Epoch: 5| Step: 9
Training loss: 3.4622015097959844
Validation loss: 3.312296092776396

Epoch: 5| Step: 10
Training loss: 3.8656085249134193
Validation loss: 3.312385032362898

Epoch: 25| Step: 0
Training loss: 3.6174408595293417
Validation loss: 3.310678511781246

Epoch: 5| Step: 1
Training loss: 2.9196328112561476
Validation loss: 3.310765885755074

Epoch: 5| Step: 2
Training loss: 3.864584430101484
Validation loss: 3.311194574556669

Epoch: 5| Step: 3
Training loss: 3.5532579167314804
Validation loss: 3.3125043479316645

Epoch: 5| Step: 4
Training loss: 4.1744413447515925
Validation loss: 3.3091240007460527

Epoch: 5| Step: 5
Training loss: 3.7302679357353794
Validation loss: 3.3053352293100184

Epoch: 5| Step: 6
Training loss: 3.6473209216348796
Validation loss: 3.3030033265614747

Epoch: 5| Step: 7
Training loss: 3.0111517267275842
Validation loss: 3.302710122767454

Epoch: 5| Step: 8
Training loss: 3.602514840280117
Validation loss: 3.30450506983639

Epoch: 5| Step: 9
Training loss: 3.100734186908605
Validation loss: 3.3021207365898455

Epoch: 5| Step: 10
Training loss: 3.6248495136463297
Validation loss: 3.298661440494312

Epoch: 26| Step: 0
Training loss: 3.659289409050207
Validation loss: 3.29993362975289

Epoch: 5| Step: 1
Training loss: 3.5328065935411983
Validation loss: 3.2974925378221185

Epoch: 5| Step: 2
Training loss: 3.4454767789189678
Validation loss: 3.2976773359835856

Epoch: 5| Step: 3
Training loss: 4.311805779791293
Validation loss: 3.297083961728097

Epoch: 5| Step: 4
Training loss: 3.411299296547431
Validation loss: 3.295519002265483

Epoch: 5| Step: 5
Training loss: 3.5628190817904737
Validation loss: 3.295551582829053

Epoch: 5| Step: 6
Training loss: 3.1562055830143536
Validation loss: 3.295627835740314

Epoch: 5| Step: 7
Training loss: 3.6121506360348854
Validation loss: 3.2931769709338417

Epoch: 5| Step: 8
Training loss: 3.121967370057636
Validation loss: 3.290430710515988

Epoch: 5| Step: 9
Training loss: 3.23938573171261
Validation loss: 3.293064430222909

Epoch: 5| Step: 10
Training loss: 3.764752678720555
Validation loss: 3.290645600399246

Epoch: 27| Step: 0
Training loss: 3.645290283449365
Validation loss: 3.2885471519286145

Epoch: 5| Step: 1
Training loss: 3.8423831649421
Validation loss: 3.287430573492272

Epoch: 5| Step: 2
Training loss: 3.2581358092813124
Validation loss: 3.2869795319065087

Epoch: 5| Step: 3
Training loss: 2.92235181865181
Validation loss: 3.28726893392413

Epoch: 5| Step: 4
Training loss: 3.6156776523300693
Validation loss: 3.286286142138851

Epoch: 5| Step: 5
Training loss: 3.4963981623755727
Validation loss: 3.286075844690166

Epoch: 5| Step: 6
Training loss: 3.4567035067099376
Validation loss: 3.284693490185374

Epoch: 5| Step: 7
Training loss: 4.155376830198694
Validation loss: 3.2854328439750056

Epoch: 5| Step: 8
Training loss: 3.769905285239959
Validation loss: 3.2849090800409297

Epoch: 5| Step: 9
Training loss: 3.0226093902860023
Validation loss: 3.2818048979715857

Epoch: 5| Step: 10
Training loss: 3.472734242304726
Validation loss: 3.2821482767287247

Epoch: 28| Step: 0
Training loss: 3.902102045739733
Validation loss: 3.2805917293451508

Epoch: 5| Step: 1
Training loss: 3.333451427910899
Validation loss: 3.2805264926848716

Epoch: 5| Step: 2
Training loss: 3.562994002507141
Validation loss: 3.279732866253941

Epoch: 5| Step: 3
Training loss: 2.5026986815156564
Validation loss: 3.281660519344709

Epoch: 5| Step: 4
Training loss: 3.637528834277831
Validation loss: 3.279437203566581

Epoch: 5| Step: 5
Training loss: 3.684995285507354
Validation loss: 3.2807341850409384

Epoch: 5| Step: 6
Training loss: 3.6655312138337934
Validation loss: 3.2788120477108578

Epoch: 5| Step: 7
Training loss: 3.747933772191016
Validation loss: 3.2762010097594096

Epoch: 5| Step: 8
Training loss: 2.806908793104763
Validation loss: 3.276998029366211

Epoch: 5| Step: 9
Training loss: 3.4677873255054905
Validation loss: 3.276115640582767

Epoch: 5| Step: 10
Training loss: 4.267268161297671
Validation loss: 3.2780868714651925

Epoch: 29| Step: 0
Training loss: 3.2758501944006513
Validation loss: 3.2763595928918794

Epoch: 5| Step: 1
Training loss: 3.6996728443158675
Validation loss: 3.274865749713308

Epoch: 5| Step: 2
Training loss: 3.6449433611955127
Validation loss: 3.2745872939525467

Epoch: 5| Step: 3
Training loss: 2.8153319618076624
Validation loss: 3.273946363990295

Epoch: 5| Step: 4
Training loss: 3.623326145318232
Validation loss: 3.273619586989302

Epoch: 5| Step: 5
Training loss: 3.257794496774671
Validation loss: 3.271321740623787

Epoch: 5| Step: 6
Training loss: 4.219867925520642
Validation loss: 3.2715790442414026

Epoch: 5| Step: 7
Training loss: 2.583581133206928
Validation loss: 3.2701513142238423

Epoch: 5| Step: 8
Training loss: 3.4933778240438
Validation loss: 3.2699664328073625

Epoch: 5| Step: 9
Training loss: 3.784287044848101
Validation loss: 3.2699636119885023

Epoch: 5| Step: 10
Training loss: 4.059552810921199
Validation loss: 3.266799355269598

Epoch: 30| Step: 0
Training loss: 4.093248409380202
Validation loss: 3.2673978150755536

Epoch: 5| Step: 1
Training loss: 3.626900404966531
Validation loss: 3.268982534431909

Epoch: 5| Step: 2
Training loss: 3.6923279272649845
Validation loss: 3.266214860603474

Epoch: 5| Step: 3
Training loss: 3.301996673184896
Validation loss: 3.2693192976657826

Epoch: 5| Step: 4
Training loss: 2.9826660056331598
Validation loss: 3.272876500827448

Epoch: 5| Step: 5
Training loss: 3.8243137616676623
Validation loss: 3.2686948843086308

Epoch: 5| Step: 6
Training loss: 3.4364707099357883
Validation loss: 3.272144863288256

Epoch: 5| Step: 7
Training loss: 3.7068985009819233
Validation loss: 3.273211370617461

Epoch: 5| Step: 8
Training loss: 3.388855643882348
Validation loss: 3.2622099904075097

Epoch: 5| Step: 9
Training loss: 3.4920555960303097
Validation loss: 3.262207019855018

Epoch: 5| Step: 10
Training loss: 2.807740656252539
Validation loss: 3.262273438562412

Epoch: 31| Step: 0
Training loss: 3.8264672251531042
Validation loss: 3.2622206372226303

Epoch: 5| Step: 1
Training loss: 3.2627569864718695
Validation loss: 3.2616609234811476

Epoch: 5| Step: 2
Training loss: 3.6418922412648156
Validation loss: 3.259883852936211

Epoch: 5| Step: 3
Training loss: 3.688579078160685
Validation loss: 3.260610655202803

Epoch: 5| Step: 4
Training loss: 3.395407964046378
Validation loss: 3.26049635982818

Epoch: 5| Step: 5
Training loss: 3.395714662190656
Validation loss: 3.260209117674526

Epoch: 5| Step: 6
Training loss: 3.793658994183313
Validation loss: 3.262336940491397

Epoch: 5| Step: 7
Training loss: 4.123386182968023
Validation loss: 3.255508857620415

Epoch: 5| Step: 8
Training loss: 3.1821576395650157
Validation loss: 3.2576032148208833

Epoch: 5| Step: 9
Training loss: 3.22972207163932
Validation loss: 3.2573629939546676

Epoch: 5| Step: 10
Training loss: 2.7225185890368806
Validation loss: 3.255202738832978

Epoch: 32| Step: 0
Training loss: 3.0324890121424426
Validation loss: 3.2519215219229496

Epoch: 5| Step: 1
Training loss: 3.7453429232409277
Validation loss: 3.2607620063182416

Epoch: 5| Step: 2
Training loss: 3.298676202142986
Validation loss: 3.2620605462580716

Epoch: 5| Step: 3
Training loss: 3.4925513707330738
Validation loss: 3.2548667385242873

Epoch: 5| Step: 4
Training loss: 4.0836123676069045
Validation loss: 3.251648364188677

Epoch: 5| Step: 5
Training loss: 3.271493120324132
Validation loss: 3.2525653968656827

Epoch: 5| Step: 6
Training loss: 3.294065028259216
Validation loss: 3.2545907149934186

Epoch: 5| Step: 7
Training loss: 3.59982158430703
Validation loss: 3.2583673515733396

Epoch: 5| Step: 8
Training loss: 3.5127546333519715
Validation loss: 3.2560355486131436

Epoch: 5| Step: 9
Training loss: 3.920526645082863
Validation loss: 3.255535373461627

Epoch: 5| Step: 10
Training loss: 3.071728251338852
Validation loss: 3.255158652174645

Epoch: 33| Step: 0
Training loss: 3.025225758600989
Validation loss: 3.255390404644389

Epoch: 5| Step: 1
Training loss: 3.1468770062194915
Validation loss: 3.2586383474663605

Epoch: 5| Step: 2
Training loss: 2.6333548782368634
Validation loss: 3.2572703167693238

Epoch: 5| Step: 3
Training loss: 4.209499814364385
Validation loss: 3.2579646334328025

Epoch: 5| Step: 4
Training loss: 3.352632934073936
Validation loss: 3.2549838511517195

Epoch: 5| Step: 5
Training loss: 3.2109881394748476
Validation loss: 3.2521274929715775

Epoch: 5| Step: 6
Training loss: 3.797479149746741
Validation loss: 3.249045567109646

Epoch: 5| Step: 7
Training loss: 3.7661993451388387
Validation loss: 3.2452931535157905

Epoch: 5| Step: 8
Training loss: 3.209320626545775
Validation loss: 3.245822264368523

Epoch: 5| Step: 9
Training loss: 3.928772230094526
Validation loss: 3.246338546374016

Epoch: 5| Step: 10
Training loss: 3.934150360941991
Validation loss: 3.246780727370058

Epoch: 34| Step: 0
Training loss: 2.4655822518127644
Validation loss: 3.24661004410787

Epoch: 5| Step: 1
Training loss: 3.9489173660964108
Validation loss: 3.2608296384651285

Epoch: 5| Step: 2
Training loss: 3.772586955691921
Validation loss: 3.2418940814990713

Epoch: 5| Step: 3
Training loss: 3.460413908263563
Validation loss: 3.2427794909233882

Epoch: 5| Step: 4
Training loss: 3.355804533138995
Validation loss: 3.2465163224204825

Epoch: 5| Step: 5
Training loss: 4.102802082030817
Validation loss: 3.2441615646380053

Epoch: 5| Step: 6
Training loss: 3.358909681163788
Validation loss: 3.23650162225021

Epoch: 5| Step: 7
Training loss: 3.10517914579269
Validation loss: 3.239036002347365

Epoch: 5| Step: 8
Training loss: 2.9567248489291984
Validation loss: 3.2427726762122555

Epoch: 5| Step: 9
Training loss: 3.8958899481972478
Validation loss: 3.2492112211432373

Epoch: 5| Step: 10
Training loss: 3.67279378880545
Validation loss: 3.269444088241987

Epoch: 35| Step: 0
Training loss: 3.3552861369382465
Validation loss: 3.268409267055767

Epoch: 5| Step: 1
Training loss: 3.5747260729008112
Validation loss: 3.2496079286485466

Epoch: 5| Step: 2
Training loss: 3.473775848369373
Validation loss: 3.2469881283054893

Epoch: 5| Step: 3
Training loss: 3.6191902960113436
Validation loss: 3.2790167314962524

Epoch: 5| Step: 4
Training loss: 3.204714199421781
Validation loss: 3.2610165252788588

Epoch: 5| Step: 5
Training loss: 3.3281189824439434
Validation loss: 3.278686400164362

Epoch: 5| Step: 6
Training loss: 3.6002637130786597
Validation loss: 3.2675040200446435

Epoch: 5| Step: 7
Training loss: 3.458667708322
Validation loss: 3.2420842723224954

Epoch: 5| Step: 8
Training loss: 3.073941093421472
Validation loss: 3.232048222996023

Epoch: 5| Step: 9
Training loss: 4.08743707917574
Validation loss: 3.2418713495188687

Epoch: 5| Step: 10
Training loss: 3.7334435230978293
Validation loss: 3.254626265269131

Epoch: 36| Step: 0
Training loss: 3.482621508667262
Validation loss: 3.27437277984821

Epoch: 5| Step: 1
Training loss: 3.749571330682935
Validation loss: 3.2537357530040114

Epoch: 5| Step: 2
Training loss: 3.464819253277975
Validation loss: 3.2375196733065845

Epoch: 5| Step: 3
Training loss: 2.93546906734251
Validation loss: 3.2329349951366626

Epoch: 5| Step: 4
Training loss: 3.0730516479501673
Validation loss: 3.231599457514966

Epoch: 5| Step: 5
Training loss: 3.9843631519814653
Validation loss: 3.232735975763983

Epoch: 5| Step: 6
Training loss: 3.7272544234475564
Validation loss: 3.2331708874462604

Epoch: 5| Step: 7
Training loss: 3.653222419999608
Validation loss: 3.2306090363133775

Epoch: 5| Step: 8
Training loss: 3.539298279173424
Validation loss: 3.228743971602966

Epoch: 5| Step: 9
Training loss: 3.43580072190559
Validation loss: 3.2297814740911894

Epoch: 5| Step: 10
Training loss: 3.081463392811174
Validation loss: 3.2284644838446286

Epoch: 37| Step: 0
Training loss: 3.28398759264815
Validation loss: 3.2286852495944562

Epoch: 5| Step: 1
Training loss: 3.667701719596437
Validation loss: 3.2292484750748645

Epoch: 5| Step: 2
Training loss: 3.5592986328935194
Validation loss: 3.2268376319381407

Epoch: 5| Step: 3
Training loss: 3.275775375015227
Validation loss: 3.2240952081298033

Epoch: 5| Step: 4
Training loss: 3.5377386113761817
Validation loss: 3.223549911475299

Epoch: 5| Step: 5
Training loss: 3.0234926992498248
Validation loss: 3.2231299402778513

Epoch: 5| Step: 6
Training loss: 3.8788570773570017
Validation loss: 3.2241142805511913

Epoch: 5| Step: 7
Training loss: 3.9728223677780976
Validation loss: 3.2206832252416553

Epoch: 5| Step: 8
Training loss: 3.4554174762244805
Validation loss: 3.2238546518430415

Epoch: 5| Step: 9
Training loss: 3.672921279209044
Validation loss: 3.2219691464176337

Epoch: 5| Step: 10
Training loss: 2.5086650409387405
Validation loss: 3.2214342094217514

Epoch: 38| Step: 0
Training loss: 3.5492600811603343
Validation loss: 3.2202760714800136

Epoch: 5| Step: 1
Training loss: 3.5795823506797344
Validation loss: 3.2204979398535043

Epoch: 5| Step: 2
Training loss: 3.3024373792303456
Validation loss: 3.2207717018092707

Epoch: 5| Step: 3
Training loss: 3.1960057483568884
Validation loss: 3.2198228084633516

Epoch: 5| Step: 4
Training loss: 3.344001261459916
Validation loss: 3.2227135879323052

Epoch: 5| Step: 5
Training loss: 3.368767246067723
Validation loss: 3.2195346814450345

Epoch: 5| Step: 6
Training loss: 3.2016568424591094
Validation loss: 3.216138176495619

Epoch: 5| Step: 7
Training loss: 3.6056864332816527
Validation loss: 3.2194509168181704

Epoch: 5| Step: 8
Training loss: 3.720175974590636
Validation loss: 3.217495815799202

Epoch: 5| Step: 9
Training loss: 3.5685591451247403
Validation loss: 3.2193431472993472

Epoch: 5| Step: 10
Training loss: 3.666731458149293
Validation loss: 3.2137037991436155

Epoch: 39| Step: 0
Training loss: 2.8590778133854915
Validation loss: 3.213555205718788

Epoch: 5| Step: 1
Training loss: 3.8955143000619707
Validation loss: 3.219089364722238

Epoch: 5| Step: 2
Training loss: 2.943643516995794
Validation loss: 3.215771936659301

Epoch: 5| Step: 3
Training loss: 3.635330476076155
Validation loss: 3.2168436845769333

Epoch: 5| Step: 4
Training loss: 3.2786463989225005
Validation loss: 3.216193892148228

Epoch: 5| Step: 5
Training loss: 4.017278546043815
Validation loss: 3.2173010470631023

Epoch: 5| Step: 6
Training loss: 3.6062685326376056
Validation loss: 3.2156753565913108

Epoch: 5| Step: 7
Training loss: 3.4153480466364017
Validation loss: 3.2161743327537047

Epoch: 5| Step: 8
Training loss: 2.700436263689945
Validation loss: 3.2177485592562385

Epoch: 5| Step: 9
Training loss: 3.672414926643314
Validation loss: 3.2194341316199417

Epoch: 5| Step: 10
Training loss: 3.828633551002092
Validation loss: 3.2300989785257492

Epoch: 40| Step: 0
Training loss: 4.505357096720495
Validation loss: 3.213949234320003

Epoch: 5| Step: 1
Training loss: 3.5031485700537495
Validation loss: 3.2110475603584603

Epoch: 5| Step: 2
Training loss: 3.443799160088941
Validation loss: 3.2089235961128155

Epoch: 5| Step: 3
Training loss: 3.4518579428253258
Validation loss: 3.2067622805057883

Epoch: 5| Step: 4
Training loss: 2.6381642088318213
Validation loss: 3.205182301363742

Epoch: 5| Step: 5
Training loss: 3.34100714158063
Validation loss: 3.2085299906383935

Epoch: 5| Step: 6
Training loss: 2.999783031247111
Validation loss: 3.2075058395049583

Epoch: 5| Step: 7
Training loss: 2.9624032692870856
Validation loss: 3.2072849092178966

Epoch: 5| Step: 8
Training loss: 3.491723219626732
Validation loss: 3.2115544135029475

Epoch: 5| Step: 9
Training loss: 3.5596209487139148
Validation loss: 3.223183409033943

Epoch: 5| Step: 10
Training loss: 3.8769712048932963
Validation loss: 3.2428199511970317

Epoch: 41| Step: 0
Training loss: 3.456607771113928
Validation loss: 3.206977499154601

Epoch: 5| Step: 1
Training loss: 3.474414770671059
Validation loss: 3.2067010181978124

Epoch: 5| Step: 2
Training loss: 3.577296931636675
Validation loss: 3.213898012934853

Epoch: 5| Step: 3
Training loss: 4.009013510959359
Validation loss: 3.222140071992361

Epoch: 5| Step: 4
Training loss: 3.3766509362695687
Validation loss: 3.22659465338067

Epoch: 5| Step: 5
Training loss: 2.8165631931718433
Validation loss: 3.2317128860905258

Epoch: 5| Step: 6
Training loss: 3.3260018467075088
Validation loss: 3.220778376018574

Epoch: 5| Step: 7
Training loss: 3.3471831763079947
Validation loss: 3.2187635941362225

Epoch: 5| Step: 8
Training loss: 3.4560200564720835
Validation loss: 3.2104080666320014

Epoch: 5| Step: 9
Training loss: 3.4635877257226872
Validation loss: 3.207880945251039

Epoch: 5| Step: 10
Training loss: 3.7776786395385047
Validation loss: 3.208596348352788

Epoch: 42| Step: 0
Training loss: 3.5248659203102393
Validation loss: 3.2108668576124355

Epoch: 5| Step: 1
Training loss: 2.953306485205462
Validation loss: 3.2196806691083775

Epoch: 5| Step: 2
Training loss: 3.1061214121063596
Validation loss: 3.232890696801494

Epoch: 5| Step: 3
Training loss: 4.0695645456019385
Validation loss: 3.2407189536416245

Epoch: 5| Step: 4
Training loss: 3.842091520459516
Validation loss: 3.217909654943364

Epoch: 5| Step: 5
Training loss: 3.4225435344192654
Validation loss: 3.199747588697

Epoch: 5| Step: 6
Training loss: 3.0351301705161737
Validation loss: 3.1999020733257173

Epoch: 5| Step: 7
Training loss: 3.7427848068452403
Validation loss: 3.194712136995079

Epoch: 5| Step: 8
Training loss: 3.703508960760933
Validation loss: 3.2019503404695975

Epoch: 5| Step: 9
Training loss: 3.586937592447666
Validation loss: 3.2020936647704135

Epoch: 5| Step: 10
Training loss: 2.6835516380770605
Validation loss: 3.2010720626020976

Epoch: 43| Step: 0
Training loss: 4.008397347830639
Validation loss: 3.2010576853624917

Epoch: 5| Step: 1
Training loss: 3.3411158944163963
Validation loss: 3.1966324638319574

Epoch: 5| Step: 2
Training loss: 3.7584293993212934
Validation loss: 3.1974446726417995

Epoch: 5| Step: 3
Training loss: 3.641394276037624
Validation loss: 3.195480581749338

Epoch: 5| Step: 4
Training loss: 3.7668793041558466
Validation loss: 3.193169629925901

Epoch: 5| Step: 5
Training loss: 3.361212081723674
Validation loss: 3.196557227442327

Epoch: 5| Step: 6
Training loss: 2.247084211814629
Validation loss: 3.196188833730295

Epoch: 5| Step: 7
Training loss: 3.333235707442855
Validation loss: 3.1987179912632384

Epoch: 5| Step: 8
Training loss: 3.854160260719268
Validation loss: 3.199534613597787

Epoch: 5| Step: 9
Training loss: 3.182078819003634
Validation loss: 3.1975320820809396

Epoch: 5| Step: 10
Training loss: 3.0087182204719993
Validation loss: 3.1975991835462376

Epoch: 44| Step: 0
Training loss: 3.1494953659563723
Validation loss: 3.1991564040562497

Epoch: 5| Step: 1
Training loss: 3.1033281734217417
Validation loss: 3.197617740548089

Epoch: 5| Step: 2
Training loss: 3.3325508311831396
Validation loss: 3.195622575705455

Epoch: 5| Step: 3
Training loss: 2.9550894203146654
Validation loss: 3.194678824144339

Epoch: 5| Step: 4
Training loss: 3.950477889885182
Validation loss: 3.1937828322835435

Epoch: 5| Step: 5
Training loss: 3.9480572812177344
Validation loss: 3.1924350391840632

Epoch: 5| Step: 6
Training loss: 3.132411103444739
Validation loss: 3.1909644184199153

Epoch: 5| Step: 7
Training loss: 3.4912695307583124
Validation loss: 3.1899830337573682

Epoch: 5| Step: 8
Training loss: 3.699855213940942
Validation loss: 3.1907084927489766

Epoch: 5| Step: 9
Training loss: 3.6221015128660925
Validation loss: 3.189820283367738

Epoch: 5| Step: 10
Training loss: 3.215632289807775
Validation loss: 3.1881050277199425

Epoch: 45| Step: 0
Training loss: 2.9853432567557014
Validation loss: 3.1881063770443965

Epoch: 5| Step: 1
Training loss: 4.147909184667385
Validation loss: 3.1880988182468872

Epoch: 5| Step: 2
Training loss: 3.4156010214198633
Validation loss: 3.1871521864761934

Epoch: 5| Step: 3
Training loss: 4.1417741440477815
Validation loss: 3.1873064426734325

Epoch: 5| Step: 4
Training loss: 2.4555040231344347
Validation loss: 3.187026665722577

Epoch: 5| Step: 5
Training loss: 2.1138530528767827
Validation loss: 3.187674560850079

Epoch: 5| Step: 6
Training loss: 2.9544363188427614
Validation loss: 3.1854289165007423

Epoch: 5| Step: 7
Training loss: 4.22657197679737
Validation loss: 3.1856261795175898

Epoch: 5| Step: 8
Training loss: 4.3078608231018585
Validation loss: 3.184766697348592

Epoch: 5| Step: 9
Training loss: 2.8732242905473817
Validation loss: 3.1855416375360335

Epoch: 5| Step: 10
Training loss: 3.2746349684561395
Validation loss: 3.1837923884948207

Epoch: 46| Step: 0
Training loss: 3.6893620073366615
Validation loss: 3.1853297262876206

Epoch: 5| Step: 1
Training loss: 3.5427036038981927
Validation loss: 3.1838312383203227

Epoch: 5| Step: 2
Training loss: 3.741365410133193
Validation loss: 3.1822416124609387

Epoch: 5| Step: 3
Training loss: 3.2832446620476303
Validation loss: 3.181914107729578

Epoch: 5| Step: 4
Training loss: 2.8384668929491084
Validation loss: 3.18142100092423

Epoch: 5| Step: 5
Training loss: 3.174089232047979
Validation loss: 3.1823709293193243

Epoch: 5| Step: 6
Training loss: 3.2180924716178976
Validation loss: 3.1839491569734424

Epoch: 5| Step: 7
Training loss: 3.8929141254179265
Validation loss: 3.1807661877143705

Epoch: 5| Step: 8
Training loss: 3.7823279239419416
Validation loss: 3.1840293499199914

Epoch: 5| Step: 9
Training loss: 2.8051154785049053
Validation loss: 3.181057502248801

Epoch: 5| Step: 10
Training loss: 3.6531563737107793
Validation loss: 3.1769279604716645

Epoch: 47| Step: 0
Training loss: 2.94981933945742
Validation loss: 3.1745676060313506

Epoch: 5| Step: 1
Training loss: 3.7216941655041795
Validation loss: 3.1776715526725017

Epoch: 5| Step: 2
Training loss: 4.499197782430198
Validation loss: 3.176843763195382

Epoch: 5| Step: 3
Training loss: 3.455702428228006
Validation loss: 3.1779699424241663

Epoch: 5| Step: 4
Training loss: 3.3940052814611144
Validation loss: 3.177501615562269

Epoch: 5| Step: 5
Training loss: 2.938783730362405
Validation loss: 3.1806394896396064

Epoch: 5| Step: 6
Training loss: 3.516972398048187
Validation loss: 3.186937945727972

Epoch: 5| Step: 7
Training loss: 3.151167601703902
Validation loss: 3.1834942497459013

Epoch: 5| Step: 8
Training loss: 3.3571236096789856
Validation loss: 3.1774362455158234

Epoch: 5| Step: 9
Training loss: 3.2130903837027014
Validation loss: 3.1754305511356256

Epoch: 5| Step: 10
Training loss: 3.173898887432308
Validation loss: 3.1741221544298037

Epoch: 48| Step: 0
Training loss: 3.8754574905562307
Validation loss: 3.171069125420996

Epoch: 5| Step: 1
Training loss: 3.236943059317339
Validation loss: 3.173150888637394

Epoch: 5| Step: 2
Training loss: 3.933696787146667
Validation loss: 3.1718607943176482

Epoch: 5| Step: 3
Training loss: 3.3256474258994446
Validation loss: 3.1709626228954586

Epoch: 5| Step: 4
Training loss: 2.761954938185344
Validation loss: 3.171150196236599

Epoch: 5| Step: 5
Training loss: 2.964509364635277
Validation loss: 3.1696503307417583

Epoch: 5| Step: 6
Training loss: 4.442382275809211
Validation loss: 3.170708362201005

Epoch: 5| Step: 7
Training loss: 3.603717548119716
Validation loss: 3.1696998504739273

Epoch: 5| Step: 8
Training loss: 3.1099960243714855
Validation loss: 3.1698162146746904

Epoch: 5| Step: 9
Training loss: 2.5302129434224505
Validation loss: 3.1683096021226618

Epoch: 5| Step: 10
Training loss: 3.341624217029335
Validation loss: 3.169970754830955

Epoch: 49| Step: 0
Training loss: 3.6819005575929693
Validation loss: 3.1726276582296786

Epoch: 5| Step: 1
Training loss: 3.3345851613877495
Validation loss: 3.1830779577240738

Epoch: 5| Step: 2
Training loss: 3.5757262339244575
Validation loss: 3.165594860828665

Epoch: 5| Step: 3
Training loss: 3.8515688139765056
Validation loss: 3.1648796659957306

Epoch: 5| Step: 4
Training loss: 2.4333396031895513
Validation loss: 3.1662402357033606

Epoch: 5| Step: 5
Training loss: 2.8723608425818576
Validation loss: 3.173329473531741

Epoch: 5| Step: 6
Training loss: 3.850421728840777
Validation loss: 3.1725855181611182

Epoch: 5| Step: 7
Training loss: 3.466315162395611
Validation loss: 3.1660315136235204

Epoch: 5| Step: 8
Training loss: 3.1936475524595784
Validation loss: 3.155475566525083

Epoch: 5| Step: 9
Training loss: 3.4500295997123853
Validation loss: 3.151730202841097

Epoch: 5| Step: 10
Training loss: 3.720244035407274
Validation loss: 3.1518758351890495

Epoch: 50| Step: 0
Training loss: 3.453129142655179
Validation loss: 3.1532662867461854

Epoch: 5| Step: 1
Training loss: 3.0380660043845444
Validation loss: 3.157060734897092

Epoch: 5| Step: 2
Training loss: 2.7009046840296187
Validation loss: 3.1656850924537756

Epoch: 5| Step: 3
Training loss: 3.5577643523981215
Validation loss: 3.1824603131307088

Epoch: 5| Step: 4
Training loss: 3.3368791952926693
Validation loss: 3.183483689136577

Epoch: 5| Step: 5
Training loss: 3.863503660891203
Validation loss: 3.1773857304967863

Epoch: 5| Step: 6
Training loss: 3.2610048163740193
Validation loss: 3.1559845463382854

Epoch: 5| Step: 7
Training loss: 3.9959512724325448
Validation loss: 3.1501383546446027

Epoch: 5| Step: 8
Training loss: 3.4294384842063526
Validation loss: 3.1477379680933115

Epoch: 5| Step: 9
Training loss: 3.6083377817550857
Validation loss: 3.1462554670145377

Epoch: 5| Step: 10
Training loss: 3.003784335952577
Validation loss: 3.1456567679010807

Epoch: 51| Step: 0
Training loss: 3.826081645343698
Validation loss: 3.1447360096993378

Epoch: 5| Step: 1
Training loss: 3.1268973122166104
Validation loss: 3.143367491707574

Epoch: 5| Step: 2
Training loss: 3.7797057726553582
Validation loss: 3.144766435061801

Epoch: 5| Step: 3
Training loss: 3.5286732952930837
Validation loss: 3.141159532101343

Epoch: 5| Step: 4
Training loss: 3.100846599525533
Validation loss: 3.1402923223306183

Epoch: 5| Step: 5
Training loss: 3.7311654443920457
Validation loss: 3.140345936160349

Epoch: 5| Step: 6
Training loss: 3.107632556153469
Validation loss: 3.139595187372949

Epoch: 5| Step: 7
Training loss: 2.6214032736567696
Validation loss: 3.1376476783709117

Epoch: 5| Step: 8
Training loss: 3.5773417186043996
Validation loss: 3.137433391014828

Epoch: 5| Step: 9
Training loss: 3.559402323710903
Validation loss: 3.1402453496787253

Epoch: 5| Step: 10
Training loss: 3.176515238682867
Validation loss: 3.1390344376256194

Epoch: 52| Step: 0
Training loss: 4.024336690327878
Validation loss: 3.139954962139945

Epoch: 5| Step: 1
Training loss: 3.415089188803196
Validation loss: 3.139968678600571

Epoch: 5| Step: 2
Training loss: 3.3791887639299625
Validation loss: 3.1444546805804268

Epoch: 5| Step: 3
Training loss: 3.5240162714518672
Validation loss: 3.1419341415242292

Epoch: 5| Step: 4
Training loss: 3.149085647847716
Validation loss: 3.146666239624071

Epoch: 5| Step: 5
Training loss: 4.156517536472793
Validation loss: 3.141478768825355

Epoch: 5| Step: 6
Training loss: 2.8277180415774046
Validation loss: 3.135123064181294

Epoch: 5| Step: 7
Training loss: 3.382840268767738
Validation loss: 3.1334368153460543

Epoch: 5| Step: 8
Training loss: 3.44257479517845
Validation loss: 3.1339439296788907

Epoch: 5| Step: 9
Training loss: 2.8387667412140347
Validation loss: 3.132481618068683

Epoch: 5| Step: 10
Training loss: 2.8559010565899756
Validation loss: 3.1321651737268863

Epoch: 53| Step: 0
Training loss: 3.7689600694605385
Validation loss: 3.1307723403816983

Epoch: 5| Step: 1
Training loss: 3.18373918259651
Validation loss: 3.132305285972904

Epoch: 5| Step: 2
Training loss: 3.819452419080019
Validation loss: 3.131125650369823

Epoch: 5| Step: 3
Training loss: 3.717290255203468
Validation loss: 3.1307884831974953

Epoch: 5| Step: 4
Training loss: 2.3459132066299406
Validation loss: 3.130403315873343

Epoch: 5| Step: 5
Training loss: 3.634394869171961
Validation loss: 3.129593062448272

Epoch: 5| Step: 6
Training loss: 3.2163659312603055
Validation loss: 3.129356787832134

Epoch: 5| Step: 7
Training loss: 3.6641068771049983
Validation loss: 3.129581918561958

Epoch: 5| Step: 8
Training loss: 3.6829412697576887
Validation loss: 3.1283363449141013

Epoch: 5| Step: 9
Training loss: 3.015018224202459
Validation loss: 3.1292122834129072

Epoch: 5| Step: 10
Training loss: 2.7978313665010615
Validation loss: 3.1287170486504867

Epoch: 54| Step: 0
Training loss: 2.8684706142570047
Validation loss: 3.1285617293496535

Epoch: 5| Step: 1
Training loss: 3.0074228009520914
Validation loss: 3.130521286528337

Epoch: 5| Step: 2
Training loss: 3.200820763949029
Validation loss: 3.128919439720838

Epoch: 5| Step: 3
Training loss: 3.5770343300971894
Validation loss: 3.127393941786545

Epoch: 5| Step: 4
Training loss: 3.9964243881649786
Validation loss: 3.1275229608160435

Epoch: 5| Step: 5
Training loss: 3.341717539056801
Validation loss: 3.1256681503225905

Epoch: 5| Step: 6
Training loss: 4.059862659931353
Validation loss: 3.1252319922524157

Epoch: 5| Step: 7
Training loss: 2.772083048447545
Validation loss: 3.1234366002987177

Epoch: 5| Step: 8
Training loss: 3.1571010537514685
Validation loss: 3.124347070553058

Epoch: 5| Step: 9
Training loss: 3.5740785331529885
Validation loss: 3.1240307114800427

Epoch: 5| Step: 10
Training loss: 3.377972318320179
Validation loss: 3.122028252049072

Epoch: 55| Step: 0
Training loss: 3.551356236534771
Validation loss: 3.121647189186388

Epoch: 5| Step: 1
Training loss: 3.2354363068530843
Validation loss: 3.121314841113031

Epoch: 5| Step: 2
Training loss: 3.127640790934
Validation loss: 3.121978767763905

Epoch: 5| Step: 3
Training loss: 3.5172644289433728
Validation loss: 3.121785448657261

Epoch: 5| Step: 4
Training loss: 3.4111339308078614
Validation loss: 3.1207194834111265

Epoch: 5| Step: 5
Training loss: 3.009304716848265
Validation loss: 3.1218519733287646

Epoch: 5| Step: 6
Training loss: 3.5516236903721508
Validation loss: 3.1221346444655946

Epoch: 5| Step: 7
Training loss: 3.308799980428832
Validation loss: 3.121003025963397

Epoch: 5| Step: 8
Training loss: 2.965263326958597
Validation loss: 3.1201112124639896

Epoch: 5| Step: 9
Training loss: 3.9820707951244176
Validation loss: 3.118508002203053

Epoch: 5| Step: 10
Training loss: 3.369908342105449
Validation loss: 3.1199355945376332

Epoch: 56| Step: 0
Training loss: 3.783877760132519
Validation loss: 3.119428694709107

Epoch: 5| Step: 1
Training loss: 3.4722379726476538
Validation loss: 3.11738618237114

Epoch: 5| Step: 2
Training loss: 3.4123004058484385
Validation loss: 3.1155627324726822

Epoch: 5| Step: 3
Training loss: 3.233562570160287
Validation loss: 3.117313992371314

Epoch: 5| Step: 4
Training loss: 3.2869268809821204
Validation loss: 3.1155527809095056

Epoch: 5| Step: 5
Training loss: 3.304235260593385
Validation loss: 3.1158645490891006

Epoch: 5| Step: 6
Training loss: 3.368421854941373
Validation loss: 3.11530439789517

Epoch: 5| Step: 7
Training loss: 3.237235458347255
Validation loss: 3.112728736505877

Epoch: 5| Step: 8
Training loss: 3.0375676339865225
Validation loss: 3.1145316312518636

Epoch: 5| Step: 9
Training loss: 3.7303957627431292
Validation loss: 3.114176086300719

Epoch: 5| Step: 10
Training loss: 3.134799698023546
Validation loss: 3.1122035752917028

Epoch: 57| Step: 0
Training loss: 3.3615255879681256
Validation loss: 3.112326700283754

Epoch: 5| Step: 1
Training loss: 3.7727190364400953
Validation loss: 3.11259322185188

Epoch: 5| Step: 2
Training loss: 3.5500334402309246
Validation loss: 3.1126352220103466

Epoch: 5| Step: 3
Training loss: 3.0325747082746517
Validation loss: 3.11042303878074

Epoch: 5| Step: 4
Training loss: 3.238654360196428
Validation loss: 3.1114798108599198

Epoch: 5| Step: 5
Training loss: 3.8172187994393205
Validation loss: 3.112260320444075

Epoch: 5| Step: 6
Training loss: 3.2177337227253235
Validation loss: 3.112965156478526

Epoch: 5| Step: 7
Training loss: 2.834827552677229
Validation loss: 3.11194635161892

Epoch: 5| Step: 8
Training loss: 3.464258946693167
Validation loss: 3.113623239224838

Epoch: 5| Step: 9
Training loss: 3.2778170110937146
Validation loss: 3.112527621929508

Epoch: 5| Step: 10
Training loss: 3.334634352146005
Validation loss: 3.1137905913905186

Epoch: 58| Step: 0
Training loss: 3.183075171050106
Validation loss: 3.1110070205547924

Epoch: 5| Step: 1
Training loss: 3.1415739381362418
Validation loss: 3.1121904877133764

Epoch: 5| Step: 2
Training loss: 3.677907330887325
Validation loss: 3.111006440420076

Epoch: 5| Step: 3
Training loss: 3.0230188991752116
Validation loss: 3.1124942490053886

Epoch: 5| Step: 4
Training loss: 3.6512226199566906
Validation loss: 3.1119142633789765

Epoch: 5| Step: 5
Training loss: 2.5386665857192168
Validation loss: 3.1088352783077484

Epoch: 5| Step: 6
Training loss: 3.6173522779861735
Validation loss: 3.109324052030187

Epoch: 5| Step: 7
Training loss: 3.759699801574778
Validation loss: 3.1069094423579724

Epoch: 5| Step: 8
Training loss: 3.519677433276232
Validation loss: 3.1094521314923735

Epoch: 5| Step: 9
Training loss: 3.718974900056597
Validation loss: 3.106801511119692

Epoch: 5| Step: 10
Training loss: 2.8554866179652145
Validation loss: 3.105301130975432

Epoch: 59| Step: 0
Training loss: 2.7324996184604444
Validation loss: 3.1038017452116047

Epoch: 5| Step: 1
Training loss: 2.867244210578887
Validation loss: 3.1049581285270142

Epoch: 5| Step: 2
Training loss: 3.161730248176059
Validation loss: 3.102497024822264

Epoch: 5| Step: 3
Training loss: 3.849217813475061
Validation loss: 3.1040611874077886

Epoch: 5| Step: 4
Training loss: 2.8676103908904484
Validation loss: 3.102725704100579

Epoch: 5| Step: 5
Training loss: 3.5275628749507724
Validation loss: 3.102449638585489

Epoch: 5| Step: 6
Training loss: 3.868235189915043
Validation loss: 3.102050686623291

Epoch: 5| Step: 7
Training loss: 3.68924245237915
Validation loss: 3.1019820141435535

Epoch: 5| Step: 8
Training loss: 3.418591182165011
Validation loss: 3.1005918889775455

Epoch: 5| Step: 9
Training loss: 3.705859369853154
Validation loss: 3.1011915108242083

Epoch: 5| Step: 10
Training loss: 2.955529742578331
Validation loss: 3.106982091937434

Epoch: 60| Step: 0
Training loss: 2.6723922318086286
Validation loss: 3.1072973379000373

Epoch: 5| Step: 1
Training loss: 3.105814212801287
Validation loss: 3.1094391362165417

Epoch: 5| Step: 2
Training loss: 3.7055497741527024
Validation loss: 3.1131150101735234

Epoch: 5| Step: 3
Training loss: 3.5101646234755037
Validation loss: 3.111688508550294

Epoch: 5| Step: 4
Training loss: 2.9227388298402674
Validation loss: 3.0989965684489342

Epoch: 5| Step: 5
Training loss: 3.3772082698490795
Validation loss: 3.098972442476261

Epoch: 5| Step: 6
Training loss: 2.986854681443596
Validation loss: 3.0991526233174578

Epoch: 5| Step: 7
Training loss: 3.67259072977878
Validation loss: 3.099114331670493

Epoch: 5| Step: 8
Training loss: 3.6892979005114594
Validation loss: 3.0995118303603735

Epoch: 5| Step: 9
Training loss: 3.6856336881584655
Validation loss: 3.0987910052395415

Epoch: 5| Step: 10
Training loss: 3.4330669602203994
Validation loss: 3.097564376033236

Epoch: 61| Step: 0
Training loss: 2.9006077951629146
Validation loss: 3.0990171486717735

Epoch: 5| Step: 1
Training loss: 3.1859104456554985
Validation loss: 3.096182476691496

Epoch: 5| Step: 2
Training loss: 3.610211692372778
Validation loss: 3.0953733681160283

Epoch: 5| Step: 3
Training loss: 4.145380247779646
Validation loss: 3.0931660463685176

Epoch: 5| Step: 4
Training loss: 3.0068184931695994
Validation loss: 3.0938719154384593

Epoch: 5| Step: 5
Training loss: 4.072688077607986
Validation loss: 3.089690811095263

Epoch: 5| Step: 6
Training loss: 3.1354546190839634
Validation loss: 3.093890323980402

Epoch: 5| Step: 7
Training loss: 3.0568821040796106
Validation loss: 3.099861139395466

Epoch: 5| Step: 8
Training loss: 2.946609818469735
Validation loss: 3.104470835949984

Epoch: 5| Step: 9
Training loss: 3.3709538542362365
Validation loss: 3.1044767238263287

Epoch: 5| Step: 10
Training loss: 3.1695430808990124
Validation loss: 3.1059967007065734

Epoch: 62| Step: 0
Training loss: 3.9962801325822106
Validation loss: 3.0989879038347725

Epoch: 5| Step: 1
Training loss: 3.2864032787098636
Validation loss: 3.092657753872217

Epoch: 5| Step: 2
Training loss: 3.8100301528097944
Validation loss: 3.085364638491153

Epoch: 5| Step: 3
Training loss: 2.8480745068565967
Validation loss: 3.0862935203669166

Epoch: 5| Step: 4
Training loss: 3.558962755720611
Validation loss: 3.085152695949906

Epoch: 5| Step: 5
Training loss: 3.46400154139284
Validation loss: 3.0868324478460423

Epoch: 5| Step: 6
Training loss: 2.4960380631564556
Validation loss: 3.0862320547155693

Epoch: 5| Step: 7
Training loss: 2.887978326721444
Validation loss: 3.0861413018440595

Epoch: 5| Step: 8
Training loss: 2.927067839195721
Validation loss: 3.08581903951208

Epoch: 5| Step: 9
Training loss: 3.490165107778316
Validation loss: 3.085971170088302

Epoch: 5| Step: 10
Training loss: 3.802181099806091
Validation loss: 3.085242140924687

Epoch: 63| Step: 0
Training loss: 3.4772094124680986
Validation loss: 3.084078818087901

Epoch: 5| Step: 1
Training loss: 3.9667775216093006
Validation loss: 3.083623395766105

Epoch: 5| Step: 2
Training loss: 3.2489161518110965
Validation loss: 3.0830583596665724

Epoch: 5| Step: 3
Training loss: 3.1792408772444394
Validation loss: 3.0842618306412417

Epoch: 5| Step: 4
Training loss: 3.3782108715904826
Validation loss: 3.082356351094751

Epoch: 5| Step: 5
Training loss: 3.010045557786249
Validation loss: 3.0899575461167856

Epoch: 5| Step: 6
Training loss: 2.7451401162996536
Validation loss: 3.095604455204258

Epoch: 5| Step: 7
Training loss: 3.705985594094075
Validation loss: 3.0977848424935055

Epoch: 5| Step: 8
Training loss: 3.3077003687042117
Validation loss: 3.0925028468522706

Epoch: 5| Step: 9
Training loss: 2.756181185808347
Validation loss: 3.0843054118491677

Epoch: 5| Step: 10
Training loss: 3.888653849507758
Validation loss: 3.080452360998557

Epoch: 64| Step: 0
Training loss: 3.217148613937907
Validation loss: 3.080234235307527

Epoch: 5| Step: 1
Training loss: 3.3324485240260207
Validation loss: 3.0795526087611846

Epoch: 5| Step: 2
Training loss: 3.6520703544901085
Validation loss: 3.0787089004169133

Epoch: 5| Step: 3
Training loss: 3.221495707225885
Validation loss: 3.079287564980597

Epoch: 5| Step: 4
Training loss: 3.96807651362175
Validation loss: 3.077954051174924

Epoch: 5| Step: 5
Training loss: 3.4636089270617116
Validation loss: 3.079269791792132

Epoch: 5| Step: 6
Training loss: 2.7269204678046504
Validation loss: 3.076753245607491

Epoch: 5| Step: 7
Training loss: 4.2338925470367705
Validation loss: 3.078765637568128

Epoch: 5| Step: 8
Training loss: 2.598974183262953
Validation loss: 3.074864503529904

Epoch: 5| Step: 9
Training loss: 2.972301727689301
Validation loss: 3.075676250022306

Epoch: 5| Step: 10
Training loss: 2.9349142828256807
Validation loss: 3.0751035561320794

Epoch: 65| Step: 0
Training loss: 3.5202538429110866
Validation loss: 3.0768264072604925

Epoch: 5| Step: 1
Training loss: 3.3011774852318174
Validation loss: 3.0777930049485747

Epoch: 5| Step: 2
Training loss: 3.305639395910555
Validation loss: 3.07700158288035

Epoch: 5| Step: 3
Training loss: 3.1937586356865575
Validation loss: 3.073986272075106

Epoch: 5| Step: 4
Training loss: 3.1822565371275178
Validation loss: 3.0736916147667976

Epoch: 5| Step: 5
Training loss: 2.9953440458082254
Validation loss: 3.0725390508668515

Epoch: 5| Step: 6
Training loss: 3.7775016680650038
Validation loss: 3.0712236588101853

Epoch: 5| Step: 7
Training loss: 3.2409158074055116
Validation loss: 3.076094732429001

Epoch: 5| Step: 8
Training loss: 3.214523651762304
Validation loss: 3.0759740776488744

Epoch: 5| Step: 9
Training loss: 3.324920687769267
Validation loss: 3.0754947304723923

Epoch: 5| Step: 10
Training loss: 3.617719771768662
Validation loss: 3.078364472302821

Epoch: 66| Step: 0
Training loss: 2.764979227826144
Validation loss: 3.0756091175111493

Epoch: 5| Step: 1
Training loss: 3.2949152179282186
Validation loss: 3.072809488976469

Epoch: 5| Step: 2
Training loss: 3.2045596003758208
Validation loss: 3.070455189261321

Epoch: 5| Step: 3
Training loss: 3.524297165299541
Validation loss: 3.0711655469048194

Epoch: 5| Step: 4
Training loss: 3.472365960430896
Validation loss: 3.0691025509401326

Epoch: 5| Step: 5
Training loss: 3.5196268997997424
Validation loss: 3.0667050431014014

Epoch: 5| Step: 6
Training loss: 3.6121560484085125
Validation loss: 3.065650904491873

Epoch: 5| Step: 7
Training loss: 3.563911024701962
Validation loss: 3.0680407288960296

Epoch: 5| Step: 8
Training loss: 2.705837674698922
Validation loss: 3.068115019109962

Epoch: 5| Step: 9
Training loss: 3.643361254413783
Validation loss: 3.066652308662727

Epoch: 5| Step: 10
Training loss: 3.1647192002730904
Validation loss: 3.065900467161888

Epoch: 67| Step: 0
Training loss: 3.1216424834425855
Validation loss: 3.066245879810486

Epoch: 5| Step: 1
Training loss: 3.4854928862056282
Validation loss: 3.0646477560370253

Epoch: 5| Step: 2
Training loss: 3.39446073224006
Validation loss: 3.0641400497748394

Epoch: 5| Step: 3
Training loss: 3.002575563469346
Validation loss: 3.061529119915818

Epoch: 5| Step: 4
Training loss: 3.4115919868359925
Validation loss: 3.0644443694080143

Epoch: 5| Step: 5
Training loss: 2.9392509923233883
Validation loss: 3.0626411966300697

Epoch: 5| Step: 6
Training loss: 3.34427374900204
Validation loss: 3.062657526119873

Epoch: 5| Step: 7
Training loss: 3.881876105334632
Validation loss: 3.0619060048294835

Epoch: 5| Step: 8
Training loss: 3.1505819358372236
Validation loss: 3.064203473734319

Epoch: 5| Step: 9
Training loss: 3.6385340109081237
Validation loss: 3.062334301877302

Epoch: 5| Step: 10
Training loss: 3.0951120480174406
Validation loss: 3.061235199743453

Epoch: 68| Step: 0
Training loss: 3.3032624619391138
Validation loss: 3.0609344723449317

Epoch: 5| Step: 1
Training loss: 2.9294444886192768
Validation loss: 3.060281667931308

Epoch: 5| Step: 2
Training loss: 3.0565248705118724
Validation loss: 3.062790669988204

Epoch: 5| Step: 3
Training loss: 2.9253633452794023
Validation loss: 3.0598812463011664

Epoch: 5| Step: 4
Training loss: 3.6573040086926754
Validation loss: 3.057316414477031

Epoch: 5| Step: 5
Training loss: 3.0795210562542166
Validation loss: 3.058091855821492

Epoch: 5| Step: 6
Training loss: 3.6846130190673705
Validation loss: 3.058907588994965

Epoch: 5| Step: 7
Training loss: 3.338915315489267
Validation loss: 3.057005411005448

Epoch: 5| Step: 8
Training loss: 2.7761535240287145
Validation loss: 3.058383793054295

Epoch: 5| Step: 9
Training loss: 3.7487890195580733
Validation loss: 3.0562539225165457

Epoch: 5| Step: 10
Training loss: 3.916871302243647
Validation loss: 3.0581170487243443

Epoch: 69| Step: 0
Training loss: 3.4735055577881764
Validation loss: 3.059268011941003

Epoch: 5| Step: 1
Training loss: 3.3174500816516423
Validation loss: 3.063809431117348

Epoch: 5| Step: 2
Training loss: 2.554621331060845
Validation loss: 3.070710811680012

Epoch: 5| Step: 3
Training loss: 2.700576551126832
Validation loss: 3.068999204271826

Epoch: 5| Step: 4
Training loss: 3.528770589089402
Validation loss: 3.0622895691470635

Epoch: 5| Step: 5
Training loss: 3.7745685659273325
Validation loss: 3.0572029312342286

Epoch: 5| Step: 6
Training loss: 3.383930823148862
Validation loss: 3.053648332855607

Epoch: 5| Step: 7
Training loss: 3.455414992278042
Validation loss: 3.0545916916145956

Epoch: 5| Step: 8
Training loss: 3.2404259733701064
Validation loss: 3.0564078853499947

Epoch: 5| Step: 9
Training loss: 3.6183492224467577
Validation loss: 3.055199829741769

Epoch: 5| Step: 10
Training loss: 3.2764620771467747
Validation loss: 3.057002963935403

Epoch: 70| Step: 0
Training loss: 3.5978640683733714
Validation loss: 3.0561663050486065

Epoch: 5| Step: 1
Training loss: 3.171692340270501
Validation loss: 3.0549914487851955

Epoch: 5| Step: 2
Training loss: 2.738966046738803
Validation loss: 3.0529709148042166

Epoch: 5| Step: 3
Training loss: 3.534230282735726
Validation loss: 3.051674624202201

Epoch: 5| Step: 4
Training loss: 3.4108096061631215
Validation loss: 3.0539343565620447

Epoch: 5| Step: 5
Training loss: 3.5700503196696185
Validation loss: 3.0522016805900503

Epoch: 5| Step: 6
Training loss: 2.7031676007921543
Validation loss: 3.0519821338926536

Epoch: 5| Step: 7
Training loss: 3.535316084309719
Validation loss: 3.0519552389096765

Epoch: 5| Step: 8
Training loss: 3.0606747851880693
Validation loss: 3.053225028682219

Epoch: 5| Step: 9
Training loss: 3.579374003742413
Validation loss: 3.056316234311212

Epoch: 5| Step: 10
Training loss: 3.475148391299677
Validation loss: 3.055125670212269

Epoch: 71| Step: 0
Training loss: 3.098477075644333
Validation loss: 3.052231124250207

Epoch: 5| Step: 1
Training loss: 3.377812802888855
Validation loss: 3.0580671304940203

Epoch: 5| Step: 2
Training loss: 3.7941358442344146
Validation loss: 3.054537367416887

Epoch: 5| Step: 3
Training loss: 3.5969803596662446
Validation loss: 3.05274586575697

Epoch: 5| Step: 4
Training loss: 3.4277268629725377
Validation loss: 3.051338701059493

Epoch: 5| Step: 5
Training loss: 3.3293612337767713
Validation loss: 3.048168690858135

Epoch: 5| Step: 6
Training loss: 2.597672862523243
Validation loss: 3.0470197527008955

Epoch: 5| Step: 7
Training loss: 3.4764146409042125
Validation loss: 3.047670017598942

Epoch: 5| Step: 8
Training loss: 3.334311310035619
Validation loss: 3.0462384623660896

Epoch: 5| Step: 9
Training loss: 3.132671705016913
Validation loss: 3.045071485694537

Epoch: 5| Step: 10
Training loss: 3.1100142698788535
Validation loss: 3.0462464312371176

Epoch: 72| Step: 0
Training loss: 3.3935295356531947
Validation loss: 3.0472863040926805

Epoch: 5| Step: 1
Training loss: 3.465560684088873
Validation loss: 3.046645755310558

Epoch: 5| Step: 2
Training loss: 3.5914688167968167
Validation loss: 3.045874856346789

Epoch: 5| Step: 3
Training loss: 3.3193645245992447
Validation loss: 3.0449986572494363

Epoch: 5| Step: 4
Training loss: 3.109163209996227
Validation loss: 3.044562289944194

Epoch: 5| Step: 5
Training loss: 3.603100098840667
Validation loss: 3.043203348919349

Epoch: 5| Step: 6
Training loss: 2.846479175238835
Validation loss: 3.0441139317111108

Epoch: 5| Step: 7
Training loss: 2.813039261723961
Validation loss: 3.0413399685395204

Epoch: 5| Step: 8
Training loss: 3.2715737219609
Validation loss: 3.0427832689818097

Epoch: 5| Step: 9
Training loss: 3.7128476015474825
Validation loss: 3.0427743364501403

Epoch: 5| Step: 10
Training loss: 3.147978264041686
Validation loss: 3.042690629552291

Epoch: 73| Step: 0
Training loss: 3.523558350243515
Validation loss: 3.0422818961794027

Epoch: 5| Step: 1
Training loss: 2.859142690091253
Validation loss: 3.0399719761942228

Epoch: 5| Step: 2
Training loss: 2.7719438856095664
Validation loss: 3.043121262036663

Epoch: 5| Step: 3
Training loss: 3.4743232287581107
Validation loss: 3.0428792452821543

Epoch: 5| Step: 4
Training loss: 2.9034032517900235
Validation loss: 3.047788640249014

Epoch: 5| Step: 5
Training loss: 3.5366488345958307
Validation loss: 3.0618264514678435

Epoch: 5| Step: 6
Training loss: 3.4536427933866474
Validation loss: 3.0437920390868722

Epoch: 5| Step: 7
Training loss: 3.3546607717827137
Validation loss: 3.038339689768535

Epoch: 5| Step: 8
Training loss: 3.4687018863674717
Validation loss: 3.0406145868606935

Epoch: 5| Step: 9
Training loss: 3.1255335543046843
Validation loss: 3.038529048059907

Epoch: 5| Step: 10
Training loss: 3.8182030218947562
Validation loss: 3.03713252534838

Epoch: 74| Step: 0
Training loss: 3.224893724923093
Validation loss: 3.037877499941726

Epoch: 5| Step: 1
Training loss: 3.8760787938851617
Validation loss: 3.040410970316567

Epoch: 5| Step: 2
Training loss: 3.3633087546966225
Validation loss: 3.0390406900225324

Epoch: 5| Step: 3
Training loss: 3.218922582647587
Validation loss: 3.0384468880512356

Epoch: 5| Step: 4
Training loss: 2.320414223030636
Validation loss: 3.0382895377298347

Epoch: 5| Step: 5
Training loss: 3.555502192441189
Validation loss: 3.037749704994597

Epoch: 5| Step: 6
Training loss: 2.7828485416946362
Validation loss: 3.035786162452967

Epoch: 5| Step: 7
Training loss: 3.3612089607000386
Validation loss: 3.0356598671412898

Epoch: 5| Step: 8
Training loss: 3.6472439171548623
Validation loss: 3.032065896270264

Epoch: 5| Step: 9
Training loss: 3.8779376800078174
Validation loss: 3.0341523204014047

Epoch: 5| Step: 10
Training loss: 2.7099399105321633
Validation loss: 3.0310815507037314

Epoch: 75| Step: 0
Training loss: 2.9791419999673123
Validation loss: 3.03289149580153

Epoch: 5| Step: 1
Training loss: 3.16815388205588
Validation loss: 3.0318417248036003

Epoch: 5| Step: 2
Training loss: 2.542167853881476
Validation loss: 3.031218871639846

Epoch: 5| Step: 3
Training loss: 3.620509819675969
Validation loss: 3.0301142142966926

Epoch: 5| Step: 4
Training loss: 4.06117062459102
Validation loss: 3.0311610821240715

Epoch: 5| Step: 5
Training loss: 3.0258077945820383
Validation loss: 3.0326250630276204

Epoch: 5| Step: 6
Training loss: 3.5233928398465357
Validation loss: 3.033710032505618

Epoch: 5| Step: 7
Training loss: 3.5070802735734588
Validation loss: 3.0329048241374674

Epoch: 5| Step: 8
Training loss: 3.460768443643697
Validation loss: 3.0357313134107176

Epoch: 5| Step: 9
Training loss: 2.672410788550295
Validation loss: 3.0375282233283443

Epoch: 5| Step: 10
Training loss: 3.4877469976867657
Validation loss: 3.043089862529873

Epoch: 76| Step: 0
Training loss: 3.0199654922029624
Validation loss: 3.036232786776437

Epoch: 5| Step: 1
Training loss: 3.106497194827668
Validation loss: 3.0265274510766242

Epoch: 5| Step: 2
Training loss: 4.303442690223388
Validation loss: 3.0264445772936166

Epoch: 5| Step: 3
Training loss: 3.439685612218198
Validation loss: 3.025597326616868

Epoch: 5| Step: 4
Training loss: 3.3262110118165076
Validation loss: 3.024818752075708

Epoch: 5| Step: 5
Training loss: 3.4116372719153585
Validation loss: 3.0243389793894817

Epoch: 5| Step: 6
Training loss: 3.19865887671992
Validation loss: 3.025936444624258

Epoch: 5| Step: 7
Training loss: 3.612481303975126
Validation loss: 3.0234299933329294

Epoch: 5| Step: 8
Training loss: 2.7946662066140173
Validation loss: 3.0235591218590714

Epoch: 5| Step: 9
Training loss: 2.690249699770086
Validation loss: 3.0235362940741326

Epoch: 5| Step: 10
Training loss: 3.0436877673169027
Validation loss: 3.0237947374670266

Epoch: 77| Step: 0
Training loss: 2.9868800649302663
Validation loss: 3.0215285477530527

Epoch: 5| Step: 1
Training loss: 2.8947244803607317
Validation loss: 3.02216357403555

Epoch: 5| Step: 2
Training loss: 3.5019788597510217
Validation loss: 3.0233862002545018

Epoch: 5| Step: 3
Training loss: 3.179165284109419
Validation loss: 3.0217851903647057

Epoch: 5| Step: 4
Training loss: 3.399299038828932
Validation loss: 3.019824322371253

Epoch: 5| Step: 5
Training loss: 3.220845697600471
Validation loss: 3.0218671526852954

Epoch: 5| Step: 6
Training loss: 3.387174898995728
Validation loss: 3.019593406071157

Epoch: 5| Step: 7
Training loss: 3.6472715029873917
Validation loss: 3.0215548956587335

Epoch: 5| Step: 8
Training loss: 3.3102936504370764
Validation loss: 3.0190356723620364

Epoch: 5| Step: 9
Training loss: 3.368220973895819
Validation loss: 3.0189519156981035

Epoch: 5| Step: 10
Training loss: 3.2465216289242176
Validation loss: 3.020005829836776

Epoch: 78| Step: 0
Training loss: 3.5804032314964
Validation loss: 3.020161475863071

Epoch: 5| Step: 1
Training loss: 3.481976149484458
Validation loss: 3.0192853639678514

Epoch: 5| Step: 2
Training loss: 3.6570811834840056
Validation loss: 3.020018106400996

Epoch: 5| Step: 3
Training loss: 2.846110276188123
Validation loss: 3.0182090169060296

Epoch: 5| Step: 4
Training loss: 3.0175253459178824
Validation loss: 3.0148494929832266

Epoch: 5| Step: 5
Training loss: 2.878063062898128
Validation loss: 3.0165709390670927

Epoch: 5| Step: 6
Training loss: 3.086728846814194
Validation loss: 3.018084376344326

Epoch: 5| Step: 7
Training loss: 3.61542944482334
Validation loss: 3.0179380548477766

Epoch: 5| Step: 8
Training loss: 2.585700447765075
Validation loss: 3.016322663111655

Epoch: 5| Step: 9
Training loss: 3.6729660685753363
Validation loss: 3.015408563792864

Epoch: 5| Step: 10
Training loss: 3.564919302777405
Validation loss: 3.0146589071144616

Epoch: 79| Step: 0
Training loss: 3.1643631403755608
Validation loss: 3.015272251321456

Epoch: 5| Step: 1
Training loss: 3.518137936523421
Validation loss: 3.0138443655492604

Epoch: 5| Step: 2
Training loss: 3.520610343297175
Validation loss: 3.01366115823869

Epoch: 5| Step: 3
Training loss: 3.329207982907801
Validation loss: 3.0148532905896723

Epoch: 5| Step: 4
Training loss: 3.3626226296451787
Validation loss: 3.013189212055233

Epoch: 5| Step: 5
Training loss: 2.711826409587923
Validation loss: 3.011370168122409

Epoch: 5| Step: 6
Training loss: 3.429711691525587
Validation loss: 3.012018002583506

Epoch: 5| Step: 7
Training loss: 2.481515642450804
Validation loss: 3.0134117713842907

Epoch: 5| Step: 8
Training loss: 3.838021700807162
Validation loss: 3.0128504070078908

Epoch: 5| Step: 9
Training loss: 3.2493656713165073
Validation loss: 3.0108657918032

Epoch: 5| Step: 10
Training loss: 3.329768961317646
Validation loss: 3.0108765900368266

Epoch: 80| Step: 0
Training loss: 3.4978830202236533
Validation loss: 3.0102520662898313

Epoch: 5| Step: 1
Training loss: 3.547286896168742
Validation loss: 3.0110921779215882

Epoch: 5| Step: 2
Training loss: 3.098812854247874
Validation loss: 3.011771571253961

Epoch: 5| Step: 3
Training loss: 2.7296368337120454
Validation loss: 3.0231626478484475

Epoch: 5| Step: 4
Training loss: 2.9717504497305343
Validation loss: 3.023963301886991

Epoch: 5| Step: 5
Training loss: 3.4786472199280127
Validation loss: 3.0256240424100302

Epoch: 5| Step: 6
Training loss: 3.540371616922874
Validation loss: 3.0204174554627357

Epoch: 5| Step: 7
Training loss: 2.955595567459498
Validation loss: 3.01797538107333

Epoch: 5| Step: 8
Training loss: 3.2883298515485713
Validation loss: 3.0120485974067055

Epoch: 5| Step: 9
Training loss: 3.2683500026943726
Validation loss: 3.0050106709040874

Epoch: 5| Step: 10
Training loss: 3.646606247126502
Validation loss: 3.0077582539936683

Epoch: 81| Step: 0
Training loss: 3.4486051642273217
Validation loss: 3.006673472810847

Epoch: 5| Step: 1
Training loss: 3.346091048092389
Validation loss: 3.006192783550323

Epoch: 5| Step: 2
Training loss: 3.424637885337794
Validation loss: 3.006705933880084

Epoch: 5| Step: 3
Training loss: 2.26540978823622
Validation loss: 3.006860165000378

Epoch: 5| Step: 4
Training loss: 4.079294322077986
Validation loss: 3.0070411514504007

Epoch: 5| Step: 5
Training loss: 2.911693765928665
Validation loss: 3.0076607529378125

Epoch: 5| Step: 6
Training loss: 3.5657918344394663
Validation loss: 3.005048963039917

Epoch: 5| Step: 7
Training loss: 2.7822144796980086
Validation loss: 3.005720434046922

Epoch: 5| Step: 8
Training loss: 3.223956739253737
Validation loss: 3.004190821460436

Epoch: 5| Step: 9
Training loss: 3.328796891997009
Validation loss: 3.0053105300232708

Epoch: 5| Step: 10
Training loss: 3.3735143429236554
Validation loss: 3.0034974674818278

Epoch: 82| Step: 0
Training loss: 3.6390584432170656
Validation loss: 3.003104900187716

Epoch: 5| Step: 1
Training loss: 2.4000422672682395
Validation loss: 3.004550253477752

Epoch: 5| Step: 2
Training loss: 2.9390134767766556
Validation loss: 3.0022016875472204

Epoch: 5| Step: 3
Training loss: 2.9532415780767827
Validation loss: 3.0014801134170677

Epoch: 5| Step: 4
Training loss: 2.975690578802905
Validation loss: 3.0021331596698673

Epoch: 5| Step: 5
Training loss: 3.1414118298317613
Validation loss: 3.0028202480139763

Epoch: 5| Step: 6
Training loss: 3.6441081006862714
Validation loss: 3.0071332275566482

Epoch: 5| Step: 7
Training loss: 3.3722226052979685
Validation loss: 3.005385125464179

Epoch: 5| Step: 8
Training loss: 3.674968309330702
Validation loss: 3.005255194719288

Epoch: 5| Step: 9
Training loss: 3.777681290260751
Validation loss: 3.0074677223795674

Epoch: 5| Step: 10
Training loss: 3.23283076624552
Validation loss: 3.004088871140174

Epoch: 83| Step: 0
Training loss: 3.618983438766461
Validation loss: 3.0001247603955217

Epoch: 5| Step: 1
Training loss: 3.4339059247309534
Validation loss: 2.9999132707836416

Epoch: 5| Step: 2
Training loss: 3.3437609806058752
Validation loss: 2.9983200322376424

Epoch: 5| Step: 3
Training loss: 3.1474724514023036
Validation loss: 2.9986707501013097

Epoch: 5| Step: 4
Training loss: 3.8191752545063693
Validation loss: 2.9959975670234638

Epoch: 5| Step: 5
Training loss: 3.2852937032313716
Validation loss: 2.9985436319270216

Epoch: 5| Step: 6
Training loss: 3.4354726188055973
Validation loss: 2.998685651418919

Epoch: 5| Step: 7
Training loss: 2.8883327984098575
Validation loss: 2.9974324012901215

Epoch: 5| Step: 8
Training loss: 3.610998671973805
Validation loss: 2.998732076713064

Epoch: 5| Step: 9
Training loss: 2.4939280205000998
Validation loss: 2.995000494925207

Epoch: 5| Step: 10
Training loss: 2.5332055720521143
Validation loss: 2.9962940432820053

Epoch: 84| Step: 0
Training loss: 3.260834753431178
Validation loss: 2.9926507874388375

Epoch: 5| Step: 1
Training loss: 3.5939697198457266
Validation loss: 2.996461925160776

Epoch: 5| Step: 2
Training loss: 3.709312581129275
Validation loss: 2.994814332053227

Epoch: 5| Step: 3
Training loss: 2.688320123490643
Validation loss: 2.9960481976836286

Epoch: 5| Step: 4
Training loss: 3.039744950186219
Validation loss: 2.9939769919057184

Epoch: 5| Step: 5
Training loss: 2.707850828961588
Validation loss: 2.992023387370881

Epoch: 5| Step: 6
Training loss: 3.1820743234755016
Validation loss: 2.995813550696517

Epoch: 5| Step: 7
Training loss: 3.562637058767003
Validation loss: 2.9917024780354873

Epoch: 5| Step: 8
Training loss: 3.1497379012285367
Validation loss: 2.9915054474828024

Epoch: 5| Step: 9
Training loss: 3.352579740504746
Validation loss: 2.9908141397058334

Epoch: 5| Step: 10
Training loss: 3.5245722193230247
Validation loss: 2.9894788055708927

Epoch: 85| Step: 0
Training loss: 3.1645291961465865
Validation loss: 2.990202475009027

Epoch: 5| Step: 1
Training loss: 3.5353677422924745
Validation loss: 2.9881065167970666

Epoch: 5| Step: 2
Training loss: 3.639753376497319
Validation loss: 2.990088769794868

Epoch: 5| Step: 3
Training loss: 3.6002719246632684
Validation loss: 2.988211476337609

Epoch: 5| Step: 4
Training loss: 2.934333393098512
Validation loss: 2.98800036698532

Epoch: 5| Step: 5
Training loss: 2.698498156318084
Validation loss: 2.9898272044675576

Epoch: 5| Step: 6
Training loss: 3.4241704339899237
Validation loss: 2.987267356502291

Epoch: 5| Step: 7
Training loss: 2.9518886985679034
Validation loss: 2.9874490931374997

Epoch: 5| Step: 8
Training loss: 3.136191811962543
Validation loss: 2.987807728258417

Epoch: 5| Step: 9
Training loss: 3.378641918625653
Validation loss: 2.9877688247432888

Epoch: 5| Step: 10
Training loss: 3.3150820475417486
Validation loss: 2.9853037423244446

Epoch: 86| Step: 0
Training loss: 2.7609879580314236
Validation loss: 2.987943001121565

Epoch: 5| Step: 1
Training loss: 3.1811701436690227
Validation loss: 2.988546731914443

Epoch: 5| Step: 2
Training loss: 2.880283145496286
Validation loss: 2.987783581367833

Epoch: 5| Step: 3
Training loss: 3.512893904458883
Validation loss: 2.9865740462450505

Epoch: 5| Step: 4
Training loss: 3.313275372428691
Validation loss: 2.9847773348548485

Epoch: 5| Step: 5
Training loss: 3.403793429049654
Validation loss: 2.9871502714527742

Epoch: 5| Step: 6
Training loss: 2.5581667478255157
Validation loss: 2.9852837144034625

Epoch: 5| Step: 7
Training loss: 3.762479616027567
Validation loss: 2.9831108693534603

Epoch: 5| Step: 8
Training loss: 3.6298778206516658
Validation loss: 2.9844762339014843

Epoch: 5| Step: 9
Training loss: 3.365796715793076
Validation loss: 2.980689628371971

Epoch: 5| Step: 10
Training loss: 3.2884986375988885
Validation loss: 2.981853885499749

Epoch: 87| Step: 0
Training loss: 3.2756880350494777
Validation loss: 2.982876073562171

Epoch: 5| Step: 1
Training loss: 3.509006764224673
Validation loss: 2.979456775485348

Epoch: 5| Step: 2
Training loss: 3.6496373558176285
Validation loss: 2.982610396333386

Epoch: 5| Step: 3
Training loss: 3.3235374675972813
Validation loss: 2.9806143839164307

Epoch: 5| Step: 4
Training loss: 3.1882577631187403
Validation loss: 2.981154072299704

Epoch: 5| Step: 5
Training loss: 3.1118296993012993
Validation loss: 2.9842953711320708

Epoch: 5| Step: 6
Training loss: 3.376425548002084
Validation loss: 2.990057332955056

Epoch: 5| Step: 7
Training loss: 3.1765147883429607
Validation loss: 2.984803521040305

Epoch: 5| Step: 8
Training loss: 3.1216820459620074
Validation loss: 2.9778990873913376

Epoch: 5| Step: 9
Training loss: 2.917825922604709
Validation loss: 2.9760210029529337

Epoch: 5| Step: 10
Training loss: 3.059951500352461
Validation loss: 2.9778630021484207

Epoch: 88| Step: 0
Training loss: 4.001790837897243
Validation loss: 2.9774558084677194

Epoch: 5| Step: 1
Training loss: 2.9119479200505825
Validation loss: 2.9791472793133

Epoch: 5| Step: 2
Training loss: 3.147969478531924
Validation loss: 2.9757886724827163

Epoch: 5| Step: 3
Training loss: 3.383310188878265
Validation loss: 2.9768864356849885

Epoch: 5| Step: 4
Training loss: 2.9598848993243867
Validation loss: 2.976007461206273

Epoch: 5| Step: 5
Training loss: 3.3475807564234157
Validation loss: 2.974425223157886

Epoch: 5| Step: 6
Training loss: 3.1411105108048756
Validation loss: 2.9759862732454367

Epoch: 5| Step: 7
Training loss: 2.689746716001385
Validation loss: 2.9746686725244644

Epoch: 5| Step: 8
Training loss: 3.5097592395688295
Validation loss: 2.974405899421218

Epoch: 5| Step: 9
Training loss: 3.200248654956712
Validation loss: 2.972003075419501

Epoch: 5| Step: 10
Training loss: 3.3281741429672107
Validation loss: 2.9758431049731557

Epoch: 89| Step: 0
Training loss: 3.3924693352052007
Validation loss: 2.9723697617173173

Epoch: 5| Step: 1
Training loss: 2.9411239995202854
Validation loss: 2.9718634444420413

Epoch: 5| Step: 2
Training loss: 2.8716801258671367
Validation loss: 2.9724228897938585

Epoch: 5| Step: 3
Training loss: 3.9275130518278143
Validation loss: 2.972328484361107

Epoch: 5| Step: 4
Training loss: 2.6709025437011396
Validation loss: 2.9716250251847396

Epoch: 5| Step: 5
Training loss: 3.434111433528421
Validation loss: 2.9719346275673892

Epoch: 5| Step: 6
Training loss: 3.4869525766913902
Validation loss: 2.9713246483348685

Epoch: 5| Step: 7
Training loss: 3.4033804189007193
Validation loss: 2.9708601666495555

Epoch: 5| Step: 8
Training loss: 3.11725388841037
Validation loss: 2.969833171240511

Epoch: 5| Step: 9
Training loss: 3.820553387807441
Validation loss: 2.969113316565048

Epoch: 5| Step: 10
Training loss: 2.1320516605595365
Validation loss: 2.9729386974153416

Epoch: 90| Step: 0
Training loss: 3.2295289523440287
Validation loss: 2.9723484822759163

Epoch: 5| Step: 1
Training loss: 3.175609175746436
Validation loss: 2.975089557554733

Epoch: 5| Step: 2
Training loss: 3.1602564396200754
Validation loss: 2.9821501070132688

Epoch: 5| Step: 3
Training loss: 3.4989551619507497
Validation loss: 3.0085158059729102

Epoch: 5| Step: 4
Training loss: 2.7754204337058175
Validation loss: 3.0078894863283017

Epoch: 5| Step: 5
Training loss: 3.6593940454210565
Validation loss: 3.0178532003350034

Epoch: 5| Step: 6
Training loss: 3.0124085028591563
Validation loss: 3.0064382754111048

Epoch: 5| Step: 7
Training loss: 2.719932825016331
Validation loss: 3.0059491675391725

Epoch: 5| Step: 8
Training loss: 4.018517072462169
Validation loss: 2.986662271822532

Epoch: 5| Step: 9
Training loss: 3.1233264256431164
Validation loss: 2.968103969987313

Epoch: 5| Step: 10
Training loss: 3.1658386519881843
Validation loss: 2.9676136719877504

Epoch: 91| Step: 0
Training loss: 2.9478878024320294
Validation loss: 2.9665091329543

Epoch: 5| Step: 1
Training loss: 3.381788984342332
Validation loss: 2.9704776902833583

Epoch: 5| Step: 2
Training loss: 3.0497352672814877
Validation loss: 2.9756147668227557

Epoch: 5| Step: 3
Training loss: 3.0630912988439816
Validation loss: 2.9735966099626774

Epoch: 5| Step: 4
Training loss: 3.5030845946024365
Validation loss: 2.972854331472324

Epoch: 5| Step: 5
Training loss: 3.302910798344589
Validation loss: 2.9696560110270203

Epoch: 5| Step: 6
Training loss: 3.074550974246045
Validation loss: 2.965413092200597

Epoch: 5| Step: 7
Training loss: 3.426029278988053
Validation loss: 2.964751801978174

Epoch: 5| Step: 8
Training loss: 3.5150516296762344
Validation loss: 2.962070013108486

Epoch: 5| Step: 9
Training loss: 3.6196175439610716
Validation loss: 2.9619356177081277

Epoch: 5| Step: 10
Training loss: 2.652467165787783
Validation loss: 2.963419844140906

Epoch: 92| Step: 0
Training loss: 3.1617714204729954
Validation loss: 2.9605701078016042

Epoch: 5| Step: 1
Training loss: 3.679333582742688
Validation loss: 2.9778286262347695

Epoch: 5| Step: 2
Training loss: 3.2207388057548254
Validation loss: 3.018592672788157

Epoch: 5| Step: 3
Training loss: 3.0661565010753957
Validation loss: 2.964522801515725

Epoch: 5| Step: 4
Training loss: 3.69447546223277
Validation loss: 2.9591699105133267

Epoch: 5| Step: 5
Training loss: 3.550836980233375
Validation loss: 2.9634201105902522

Epoch: 5| Step: 6
Training loss: 3.2246092271256024
Validation loss: 2.9741130656642123

Epoch: 5| Step: 7
Training loss: 2.0872188447305517
Validation loss: 2.9887922870512136

Epoch: 5| Step: 8
Training loss: 3.794060814080014
Validation loss: 3.005911536755186

Epoch: 5| Step: 9
Training loss: 2.9082775631633604
Validation loss: 2.976470378259469

Epoch: 5| Step: 10
Training loss: 3.1782250192633135
Validation loss: 2.978311880033178

Epoch: 93| Step: 0
Training loss: 3.5874586681151563
Validation loss: 2.971619056974223

Epoch: 5| Step: 1
Training loss: 3.2711622392706055
Validation loss: 2.9677976573619103

Epoch: 5| Step: 2
Training loss: 3.4870074125954487
Validation loss: 2.9633124406107294

Epoch: 5| Step: 3
Training loss: 3.7385692585142793
Validation loss: 2.9618374097181457

Epoch: 5| Step: 4
Training loss: 2.953189586760654
Validation loss: 2.9568563070273024

Epoch: 5| Step: 5
Training loss: 3.489278311232818
Validation loss: 2.966370540586325

Epoch: 5| Step: 6
Training loss: 3.0413220005629786
Validation loss: 2.9792953648138085

Epoch: 5| Step: 7
Training loss: 3.2988295704740764
Validation loss: 3.007943842470247

Epoch: 5| Step: 8
Training loss: 2.7715224840744526
Validation loss: 3.0072611505477314

Epoch: 5| Step: 9
Training loss: 2.968639492186667
Validation loss: 2.981572662673628

Epoch: 5| Step: 10
Training loss: 3.017348039367323
Validation loss: 2.9673900207225974

Epoch: 94| Step: 0
Training loss: 3.1610095707459753
Validation loss: 2.9579890505926625

Epoch: 5| Step: 1
Training loss: 3.2565874682674445
Validation loss: 2.9609036037959378

Epoch: 5| Step: 2
Training loss: 3.317253301168201
Validation loss: 2.957820872790253

Epoch: 5| Step: 3
Training loss: 3.542886651043687
Validation loss: 2.956497508988213

Epoch: 5| Step: 4
Training loss: 3.4725139919188615
Validation loss: 2.9520477927653523

Epoch: 5| Step: 5
Training loss: 2.6399118035929745
Validation loss: 2.9535358484112844

Epoch: 5| Step: 6
Training loss: 3.2869846186589893
Validation loss: 2.9543613724143145

Epoch: 5| Step: 7
Training loss: 3.137019578847689
Validation loss: 2.953399928409781

Epoch: 5| Step: 8
Training loss: 3.0586904069577283
Validation loss: 2.9551531243869507

Epoch: 5| Step: 9
Training loss: 3.282763177645529
Validation loss: 2.9556477740621685

Epoch: 5| Step: 10
Training loss: 3.4378029429720125
Validation loss: 2.954851722046044

Epoch: 95| Step: 0
Training loss: 3.152631441623627
Validation loss: 2.955146111384708

Epoch: 5| Step: 1
Training loss: 3.1333179399098707
Validation loss: 2.958886533457268

Epoch: 5| Step: 2
Training loss: 3.3854134584069335
Validation loss: 2.9597076390890136

Epoch: 5| Step: 3
Training loss: 3.2029594564691504
Validation loss: 2.957401444874056

Epoch: 5| Step: 4
Training loss: 2.8444439387155454
Validation loss: 2.955464469647621

Epoch: 5| Step: 5
Training loss: 3.201972270190262
Validation loss: 2.955192068628497

Epoch: 5| Step: 6
Training loss: 3.3331873543881576
Validation loss: 2.953115346588627

Epoch: 5| Step: 7
Training loss: 3.577830739810699
Validation loss: 2.953093337213574

Epoch: 5| Step: 8
Training loss: 3.036270545836561
Validation loss: 2.9503459599289505

Epoch: 5| Step: 9
Training loss: 2.945666385508025
Validation loss: 2.9478524508095503

Epoch: 5| Step: 10
Training loss: 3.792610442251459
Validation loss: 2.9488797039709995

Epoch: 96| Step: 0
Training loss: 3.5070366288124966
Validation loss: 2.9489245470026204

Epoch: 5| Step: 1
Training loss: 3.4378564823146944
Validation loss: 2.9441182346733403

Epoch: 5| Step: 2
Training loss: 3.9521814961861743
Validation loss: 2.9463283849398607

Epoch: 5| Step: 3
Training loss: 2.7866906945623953
Validation loss: 2.9461478151558405

Epoch: 5| Step: 4
Training loss: 3.1963954293617562
Validation loss: 2.94668152377722

Epoch: 5| Step: 5
Training loss: 3.010594575018263
Validation loss: 2.9469167353520787

Epoch: 5| Step: 6
Training loss: 2.6471460845377046
Validation loss: 2.9477253675742703

Epoch: 5| Step: 7
Training loss: 3.2531371014724484
Validation loss: 2.9473728061036693

Epoch: 5| Step: 8
Training loss: 3.46121979330706
Validation loss: 2.945866591601484

Epoch: 5| Step: 9
Training loss: 2.8491096712094293
Validation loss: 2.9439427272491523

Epoch: 5| Step: 10
Training loss: 3.267636058633539
Validation loss: 2.945546203795786

Epoch: 97| Step: 0
Training loss: 3.1714319380075855
Validation loss: 2.9446202638600085

Epoch: 5| Step: 1
Training loss: 3.317370738405316
Validation loss: 2.94042897257538

Epoch: 5| Step: 2
Training loss: 3.174137905555057
Validation loss: 2.944837266210919

Epoch: 5| Step: 3
Training loss: 3.3462083282554937
Validation loss: 2.9496438418535416

Epoch: 5| Step: 4
Training loss: 3.612027469340456
Validation loss: 2.9518293429366347

Epoch: 5| Step: 5
Training loss: 2.967332360948472
Validation loss: 2.952637682078405

Epoch: 5| Step: 6
Training loss: 2.8949170389625305
Validation loss: 2.959315049717159

Epoch: 5| Step: 7
Training loss: 3.190283364174033
Validation loss: 2.9501973823934153

Epoch: 5| Step: 8
Training loss: 3.130854805926953
Validation loss: 2.941490891276003

Epoch: 5| Step: 9
Training loss: 3.5480139159969357
Validation loss: 2.9430939998359067

Epoch: 5| Step: 10
Training loss: 3.065195726676271
Validation loss: 2.9422177228756996

Epoch: 98| Step: 0
Training loss: 2.670908256666137
Validation loss: 2.943865927867743

Epoch: 5| Step: 1
Training loss: 3.4307738649521866
Validation loss: 2.9445173514821796

Epoch: 5| Step: 2
Training loss: 3.1375307241204515
Validation loss: 2.942693120968101

Epoch: 5| Step: 3
Training loss: 3.007599582815059
Validation loss: 2.951571736921999

Epoch: 5| Step: 4
Training loss: 3.440843932404242
Validation loss: 2.9498653049492676

Epoch: 5| Step: 5
Training loss: 3.17000024572907
Validation loss: 2.943670818071316

Epoch: 5| Step: 6
Training loss: 3.3681106894962967
Validation loss: 2.946175759566674

Epoch: 5| Step: 7
Training loss: 2.6330437714284773
Validation loss: 2.9432708025541827

Epoch: 5| Step: 8
Training loss: 3.6040553404679794
Validation loss: 2.9413871660473996

Epoch: 5| Step: 9
Training loss: 2.869975633949761
Validation loss: 2.938187041672802

Epoch: 5| Step: 10
Training loss: 4.029451664046936
Validation loss: 2.9368104389340544

Epoch: 99| Step: 0
Training loss: 3.142324718360615
Validation loss: 2.938397320442866

Epoch: 5| Step: 1
Training loss: 3.07507606970505
Validation loss: 2.937798191034676

Epoch: 5| Step: 2
Training loss: 3.0985952640137526
Validation loss: 2.936202548833086

Epoch: 5| Step: 3
Training loss: 3.5222291756476736
Validation loss: 2.9364602197706375

Epoch: 5| Step: 4
Training loss: 2.326969961092988
Validation loss: 2.93788009589682

Epoch: 5| Step: 5
Training loss: 3.110369192699249
Validation loss: 2.9368165581925174

Epoch: 5| Step: 6
Training loss: 3.300883816361341
Validation loss: 2.9346211887759908

Epoch: 5| Step: 7
Training loss: 3.6472618283589804
Validation loss: 2.936769601068428

Epoch: 5| Step: 8
Training loss: 3.052472103906831
Validation loss: 2.9346997859003436

Epoch: 5| Step: 9
Training loss: 3.382434709345959
Validation loss: 2.9371365802592506

Epoch: 5| Step: 10
Training loss: 3.6469813837193907
Validation loss: 2.9358763474085556

Epoch: 100| Step: 0
Training loss: 2.9492575535526733
Validation loss: 2.933555499549622

Epoch: 5| Step: 1
Training loss: 3.7866502771784027
Validation loss: 2.9344793972865166

Epoch: 5| Step: 2
Training loss: 3.0289614188557277
Validation loss: 2.9324523926029173

Epoch: 5| Step: 3
Training loss: 3.1994853857618435
Validation loss: 2.9336879888719127

Epoch: 5| Step: 4
Training loss: 3.2530529648191937
Validation loss: 2.933656622274902

Epoch: 5| Step: 5
Training loss: 2.587958614967721
Validation loss: 2.931858567056953

Epoch: 5| Step: 6
Training loss: 3.477486956837242
Validation loss: 2.9293567609149496

Epoch: 5| Step: 7
Training loss: 3.8227927926736722
Validation loss: 2.9300010350400627

Epoch: 5| Step: 8
Training loss: 2.764003817300327
Validation loss: 2.931805782067435

Epoch: 5| Step: 9
Training loss: 3.258201960055915
Validation loss: 2.930896856932277

Epoch: 5| Step: 10
Training loss: 2.974866969876864
Validation loss: 2.93144155407696

Epoch: 101| Step: 0
Training loss: 3.26596987422731
Validation loss: 2.9308139600462813

Epoch: 5| Step: 1
Training loss: 2.708705279901355
Validation loss: 2.927390315920524

Epoch: 5| Step: 2
Training loss: 3.5404452891923297
Validation loss: 2.9281730227754013

Epoch: 5| Step: 3
Training loss: 2.9888532502493126
Validation loss: 2.9267305218373805

Epoch: 5| Step: 4
Training loss: 3.320403692451743
Validation loss: 2.9245825907302825

Epoch: 5| Step: 5
Training loss: 3.0942975725269526
Validation loss: 2.9245028407123255

Epoch: 5| Step: 6
Training loss: 3.7778654477910893
Validation loss: 2.927122800214488

Epoch: 5| Step: 7
Training loss: 3.3857652846594632
Validation loss: 2.924104332412327

Epoch: 5| Step: 8
Training loss: 3.070287650980869
Validation loss: 2.9280635830319732

Epoch: 5| Step: 9
Training loss: 3.1969449599619897
Validation loss: 2.926968452535654

Epoch: 5| Step: 10
Training loss: 2.7794958004563775
Validation loss: 2.9261427954864185

Epoch: 102| Step: 0
Training loss: 3.4419911955876543
Validation loss: 2.9241404770047383

Epoch: 5| Step: 1
Training loss: 2.9612714835756746
Validation loss: 2.929196076335998

Epoch: 5| Step: 2
Training loss: 3.129720250994856
Validation loss: 2.9247516130457525

Epoch: 5| Step: 3
Training loss: 2.9914259775686345
Validation loss: 2.9292907402430375

Epoch: 5| Step: 4
Training loss: 3.1706453392117875
Validation loss: 2.9284350604024216

Epoch: 5| Step: 5
Training loss: 2.8971490592492457
Validation loss: 2.927483433909981

Epoch: 5| Step: 6
Training loss: 3.352573340152104
Validation loss: 2.935180150355997

Epoch: 5| Step: 7
Training loss: 3.483047437723204
Validation loss: 2.9463226195609717

Epoch: 5| Step: 8
Training loss: 3.19996151900996
Validation loss: 2.939859603725681

Epoch: 5| Step: 9
Training loss: 3.4449577581420794
Validation loss: 2.932344659144206

Epoch: 5| Step: 10
Training loss: 3.1820728249647128
Validation loss: 2.9230697897537197

Epoch: 103| Step: 0
Training loss: 3.581250953341319
Validation loss: 2.9213115312681928

Epoch: 5| Step: 1
Training loss: 2.9819223601418705
Validation loss: 2.9199631714981233

Epoch: 5| Step: 2
Training loss: 3.405771764378106
Validation loss: 2.918971909221542

Epoch: 5| Step: 3
Training loss: 2.479815635903954
Validation loss: 2.9176985288040402

Epoch: 5| Step: 4
Training loss: 3.322409293125602
Validation loss: 2.919597186001478

Epoch: 5| Step: 5
Training loss: 3.3921889113146966
Validation loss: 2.919235791462422

Epoch: 5| Step: 6
Training loss: 3.45354365922198
Validation loss: 2.9160613576001064

Epoch: 5| Step: 7
Training loss: 3.07691691746462
Validation loss: 2.9181792777169564

Epoch: 5| Step: 8
Training loss: 2.8100258010820083
Validation loss: 2.9153216364877204

Epoch: 5| Step: 9
Training loss: 3.269728131672985
Validation loss: 2.9172648143213467

Epoch: 5| Step: 10
Training loss: 3.375285383803737
Validation loss: 2.916133403518436

Epoch: 104| Step: 0
Training loss: 3.28538311006047
Validation loss: 2.9150199958907526

Epoch: 5| Step: 1
Training loss: 2.9996846351168736
Validation loss: 2.91579507265498

Epoch: 5| Step: 2
Training loss: 2.994288730131022
Validation loss: 2.9154795438453

Epoch: 5| Step: 3
Training loss: 3.547398465553748
Validation loss: 2.917800848630885

Epoch: 5| Step: 4
Training loss: 2.357414390975589
Validation loss: 2.9169982384752284

Epoch: 5| Step: 5
Training loss: 3.1033266368866106
Validation loss: 2.9167368090819448

Epoch: 5| Step: 6
Training loss: 4.095214581765298
Validation loss: 2.9171320466303032

Epoch: 5| Step: 7
Training loss: 3.1034268173849786
Validation loss: 2.91625048455894

Epoch: 5| Step: 8
Training loss: 3.172832476041007
Validation loss: 2.915121853055157

Epoch: 5| Step: 9
Training loss: 3.1197512989691076
Validation loss: 2.919344030635699

Epoch: 5| Step: 10
Training loss: 3.2178662021909235
Validation loss: 2.918865746604461

Epoch: 105| Step: 0
Training loss: 2.0859411575342466
Validation loss: 2.918313528053573

Epoch: 5| Step: 1
Training loss: 3.441091984267415
Validation loss: 2.9203906783250195

Epoch: 5| Step: 2
Training loss: 3.7320848409611265
Validation loss: 2.918457721251415

Epoch: 5| Step: 3
Training loss: 3.125505635362792
Validation loss: 2.921155785663159

Epoch: 5| Step: 4
Training loss: 2.98515717007968
Validation loss: 2.915433057322484

Epoch: 5| Step: 5
Training loss: 3.4696842344554373
Validation loss: 2.9164913288860372

Epoch: 5| Step: 6
Training loss: 3.0591688139251625
Validation loss: 2.9119435357208054

Epoch: 5| Step: 7
Training loss: 3.33535082480265
Validation loss: 2.911682443143604

Epoch: 5| Step: 8
Training loss: 3.3168717811328774
Validation loss: 2.9091302151316714

Epoch: 5| Step: 9
Training loss: 3.1261094222098027
Validation loss: 2.910926962460713

Epoch: 5| Step: 10
Training loss: 3.3334119469591337
Validation loss: 2.9148807865159188

Epoch: 106| Step: 0
Training loss: 2.860513095846406
Validation loss: 2.923067891844831

Epoch: 5| Step: 1
Training loss: 1.7635725126443587
Validation loss: 2.936833255584984

Epoch: 5| Step: 2
Training loss: 2.908793659087468
Validation loss: 2.9354172564327725

Epoch: 5| Step: 3
Training loss: 3.1812206574231565
Validation loss: 2.93365366858576

Epoch: 5| Step: 4
Training loss: 3.1294362432491774
Validation loss: 2.9255706646921706

Epoch: 5| Step: 5
Training loss: 3.853301052455478
Validation loss: 2.9283527600481896

Epoch: 5| Step: 6
Training loss: 3.025912747725576
Validation loss: 2.9198660611118994

Epoch: 5| Step: 7
Training loss: 3.4043881988969855
Validation loss: 2.9118512836656825

Epoch: 5| Step: 8
Training loss: 3.648168778580799
Validation loss: 2.9094116042270795

Epoch: 5| Step: 9
Training loss: 3.495946034981718
Validation loss: 2.9067168022426557

Epoch: 5| Step: 10
Training loss: 3.4559387894702276
Validation loss: 2.907409550439642

Epoch: 107| Step: 0
Training loss: 2.7470014002754413
Validation loss: 2.9068181530832486

Epoch: 5| Step: 1
Training loss: 2.9553235463293643
Validation loss: 2.905767369185953

Epoch: 5| Step: 2
Training loss: 3.4350774378147837
Validation loss: 2.9079554045481455

Epoch: 5| Step: 3
Training loss: 3.3132573827357468
Validation loss: 2.905299685531899

Epoch: 5| Step: 4
Training loss: 2.80871038499779
Validation loss: 2.9045475315375677

Epoch: 5| Step: 5
Training loss: 3.278425472369451
Validation loss: 2.905498672596548

Epoch: 5| Step: 6
Training loss: 3.4187309418030263
Validation loss: 2.9035259124759074

Epoch: 5| Step: 7
Training loss: 3.7063040306437243
Validation loss: 2.9022011376889196

Epoch: 5| Step: 8
Training loss: 3.149304140523592
Validation loss: 2.8991269332418743

Epoch: 5| Step: 9
Training loss: 3.1745469438401788
Validation loss: 2.905403969392464

Epoch: 5| Step: 10
Training loss: 2.983538924934877
Validation loss: 2.9007148761131445

Epoch: 108| Step: 0
Training loss: 3.245991215193937
Validation loss: 2.9043893193410346

Epoch: 5| Step: 1
Training loss: 3.297227596573885
Validation loss: 2.9103111413617797

Epoch: 5| Step: 2
Training loss: 3.3411915340652905
Validation loss: 2.9180103306781757

Epoch: 5| Step: 3
Training loss: 3.2383604695715684
Validation loss: 2.920831562093367

Epoch: 5| Step: 4
Training loss: 3.2937930196598364
Validation loss: 2.9109370182259706

Epoch: 5| Step: 5
Training loss: 3.101624610720981
Validation loss: 2.9007543762292634

Epoch: 5| Step: 6
Training loss: 3.2348984741599787
Validation loss: 2.9004644664122043

Epoch: 5| Step: 7
Training loss: 2.943162695091842
Validation loss: 2.902335305638394

Epoch: 5| Step: 8
Training loss: 3.277873309048991
Validation loss: 2.901647085299378

Epoch: 5| Step: 9
Training loss: 2.8421852921303787
Validation loss: 2.900520661594356

Epoch: 5| Step: 10
Training loss: 3.3000971519734654
Validation loss: 2.9022718308116793

Epoch: 109| Step: 0
Training loss: 2.7158128504425982
Validation loss: 2.9045178450102025

Epoch: 5| Step: 1
Training loss: 2.9848370419083263
Validation loss: 2.9049852212294827

Epoch: 5| Step: 2
Training loss: 2.847573528998287
Validation loss: 2.901247056405873

Epoch: 5| Step: 3
Training loss: 2.792684132405796
Validation loss: 2.9001426305975126

Epoch: 5| Step: 4
Training loss: 3.640854725936751
Validation loss: 2.897092610183863

Epoch: 5| Step: 5
Training loss: 2.8807003067843286
Validation loss: 2.8973102222157365

Epoch: 5| Step: 6
Training loss: 3.3314934103034797
Validation loss: 2.8988952832433204

Epoch: 5| Step: 7
Training loss: 3.2195824592885027
Validation loss: 2.8983712800880657

Epoch: 5| Step: 8
Training loss: 3.543699212357902
Validation loss: 2.8986319708399875

Epoch: 5| Step: 9
Training loss: 3.157472430401044
Validation loss: 2.905386297236942

Epoch: 5| Step: 10
Training loss: 3.921392768301351
Validation loss: 2.91400494895725

Epoch: 110| Step: 0
Training loss: 2.8972338210406385
Validation loss: 2.9075974238518474

Epoch: 5| Step: 1
Training loss: 3.5641515818512945
Validation loss: 2.9062142168696448

Epoch: 5| Step: 2
Training loss: 3.0363168743459545
Validation loss: 2.9068269416069774

Epoch: 5| Step: 3
Training loss: 3.4608721931444206
Validation loss: 2.896730976290287

Epoch: 5| Step: 4
Training loss: 2.584009933056946
Validation loss: 2.9016092459916276

Epoch: 5| Step: 5
Training loss: 3.1319039946709633
Validation loss: 2.8948884624862927

Epoch: 5| Step: 6
Training loss: 3.310441727220295
Validation loss: 2.8964549881927013

Epoch: 5| Step: 7
Training loss: 3.741051105141021
Validation loss: 2.894124584325087

Epoch: 5| Step: 8
Training loss: 3.5177355047473173
Validation loss: 2.893513439818452

Epoch: 5| Step: 9
Training loss: 2.5011972421613526
Validation loss: 2.8919202851921533

Epoch: 5| Step: 10
Training loss: 3.0318411024625047
Validation loss: 2.9044384072993528

Epoch: 111| Step: 0
Training loss: 3.332425629686667
Validation loss: 2.9157057191411844

Epoch: 5| Step: 1
Training loss: 3.271827028463915
Validation loss: 2.92142341339267

Epoch: 5| Step: 2
Training loss: 3.143193044299524
Validation loss: 2.8874197650215945

Epoch: 5| Step: 3
Training loss: 3.4229475456852527
Validation loss: 2.8938675271789958

Epoch: 5| Step: 4
Training loss: 3.3100075611592854
Validation loss: 2.897229150756148

Epoch: 5| Step: 5
Training loss: 3.4338834291022584
Validation loss: 2.90423434695595

Epoch: 5| Step: 6
Training loss: 3.14002613032457
Validation loss: 2.9250605710228696

Epoch: 5| Step: 7
Training loss: 2.962810638494745
Validation loss: 2.9300286469722763

Epoch: 5| Step: 8
Training loss: 2.672857984898203
Validation loss: 2.915784152656996

Epoch: 5| Step: 9
Training loss: 3.26538114230431
Validation loss: 2.903797522291383

Epoch: 5| Step: 10
Training loss: 3.2108733456182232
Validation loss: 2.8964166376155536

Epoch: 112| Step: 0
Training loss: 3.363355682293753
Validation loss: 2.8929138806325163

Epoch: 5| Step: 1
Training loss: 3.1570413938121957
Validation loss: 2.8904517088842745

Epoch: 5| Step: 2
Training loss: 3.3277329764714163
Validation loss: 2.886353229938469

Epoch: 5| Step: 3
Training loss: 3.492542632818277
Validation loss: 2.887585111934342

Epoch: 5| Step: 4
Training loss: 3.1564525879154752
Validation loss: 2.8890832409534886

Epoch: 5| Step: 5
Training loss: 3.272781779817913
Validation loss: 2.8910027919754997

Epoch: 5| Step: 6
Training loss: 2.7520413191709743
Validation loss: 2.890934301854881

Epoch: 5| Step: 7
Training loss: 3.442916625277301
Validation loss: 2.8942292212395406

Epoch: 5| Step: 8
Training loss: 3.237837996937027
Validation loss: 2.8947047822204044

Epoch: 5| Step: 9
Training loss: 3.222034445220368
Validation loss: 2.893375857797139

Epoch: 5| Step: 10
Training loss: 2.3018578696565104
Validation loss: 2.898417701053221

Epoch: 113| Step: 0
Training loss: 3.6367074738849086
Validation loss: 2.8970649763583864

Epoch: 5| Step: 1
Training loss: 3.6934528470125985
Validation loss: 2.8825142683334124

Epoch: 5| Step: 2
Training loss: 2.816049328328621
Validation loss: 2.8802999792557475

Epoch: 5| Step: 3
Training loss: 3.0609527104590337
Validation loss: 2.8817874617770625

Epoch: 5| Step: 4
Training loss: 3.239455650896233
Validation loss: 2.8830534362465325

Epoch: 5| Step: 5
Training loss: 2.700793810112581
Validation loss: 2.8831582757843726

Epoch: 5| Step: 6
Training loss: 3.335622732423666
Validation loss: 2.884865438310674

Epoch: 5| Step: 7
Training loss: 2.9213680704762695
Validation loss: 2.8823696645282992

Epoch: 5| Step: 8
Training loss: 2.7740792405101544
Validation loss: 2.881392165427433

Epoch: 5| Step: 9
Training loss: 3.466653963823765
Validation loss: 2.882323670413143

Epoch: 5| Step: 10
Training loss: 3.2136219247515942
Validation loss: 2.8822702548767287

Epoch: 114| Step: 0
Training loss: 2.866844884374537
Validation loss: 2.8808869578197034

Epoch: 5| Step: 1
Training loss: 2.990568435118065
Validation loss: 2.8802954034521604

Epoch: 5| Step: 2
Training loss: 3.1038032336054187
Validation loss: 2.8782993804097456

Epoch: 5| Step: 3
Training loss: 3.2347949948570838
Validation loss: 2.8797955103199016

Epoch: 5| Step: 4
Training loss: 2.6770835213469404
Validation loss: 2.879950663703451

Epoch: 5| Step: 5
Training loss: 3.172070276422326
Validation loss: 2.878767365644893

Epoch: 5| Step: 6
Training loss: 3.340581372995864
Validation loss: 2.882026564117547

Epoch: 5| Step: 7
Training loss: 3.24621743380869
Validation loss: 2.876816280630184

Epoch: 5| Step: 8
Training loss: 3.5815587787760284
Validation loss: 2.8813158546619873

Epoch: 5| Step: 9
Training loss: 3.507824462326485
Validation loss: 2.8799647817372533

Epoch: 5| Step: 10
Training loss: 3.0713868724489046
Validation loss: 2.8813835244255293

Epoch: 115| Step: 0
Training loss: 3.054251949547299
Validation loss: 2.8777239193505317

Epoch: 5| Step: 1
Training loss: 3.2665843375853783
Validation loss: 2.8785725591619906

Epoch: 5| Step: 2
Training loss: 3.259141682862555
Validation loss: 2.879295453826073

Epoch: 5| Step: 3
Training loss: 3.419379731085936
Validation loss: 2.8802223248989254

Epoch: 5| Step: 4
Training loss: 3.3400207829542627
Validation loss: 2.8828301620264716

Epoch: 5| Step: 5
Training loss: 3.287058892771893
Validation loss: 2.8801571379483804

Epoch: 5| Step: 6
Training loss: 3.228155523342353
Validation loss: 2.88193983748176

Epoch: 5| Step: 7
Training loss: 3.3136637820579296
Validation loss: 2.8755004076373014

Epoch: 5| Step: 8
Training loss: 2.777330272443345
Validation loss: 2.876688364712543

Epoch: 5| Step: 9
Training loss: 2.699715730042845
Validation loss: 2.8751975228403266

Epoch: 5| Step: 10
Training loss: 3.1331121819821988
Validation loss: 2.876097873011162

Epoch: 116| Step: 0
Training loss: 3.370855258890776
Validation loss: 2.875822216307254

Epoch: 5| Step: 1
Training loss: 2.1351316928672643
Validation loss: 2.8737702220667765

Epoch: 5| Step: 2
Training loss: 2.616389366407529
Validation loss: 2.876096620649095

Epoch: 5| Step: 3
Training loss: 2.902921185355577
Validation loss: 2.8763139993610016

Epoch: 5| Step: 4
Training loss: 3.4072143869354683
Validation loss: 2.8726772164985537

Epoch: 5| Step: 5
Training loss: 3.435406411461978
Validation loss: 2.8781910468731393

Epoch: 5| Step: 6
Training loss: 3.787256561614062
Validation loss: 2.878861614673869

Epoch: 5| Step: 7
Training loss: 2.7678120042486696
Validation loss: 2.8886650245280925

Epoch: 5| Step: 8
Training loss: 3.296026762548143
Validation loss: 2.8934107984902955

Epoch: 5| Step: 9
Training loss: 3.1262306841803036
Validation loss: 2.8737724701142455

Epoch: 5| Step: 10
Training loss: 3.698432879169061
Validation loss: 2.8705889554624613

Epoch: 117| Step: 0
Training loss: 3.0277132461001575
Validation loss: 2.8711995083922544

Epoch: 5| Step: 1
Training loss: 3.193102681053412
Validation loss: 2.872990478841929

Epoch: 5| Step: 2
Training loss: 2.8892560036836086
Validation loss: 2.8714249074542746

Epoch: 5| Step: 3
Training loss: 3.4174590858851155
Validation loss: 2.8726235332379186

Epoch: 5| Step: 4
Training loss: 3.270354865647706
Validation loss: 2.8698375733890886

Epoch: 5| Step: 5
Training loss: 3.739444754892113
Validation loss: 2.8676228013568092

Epoch: 5| Step: 6
Training loss: 2.4788293902927645
Validation loss: 2.867658447400526

Epoch: 5| Step: 7
Training loss: 3.330118790990702
Validation loss: 2.8686089640287036

Epoch: 5| Step: 8
Training loss: 2.9183583031469724
Validation loss: 2.868510828287742

Epoch: 5| Step: 9
Training loss: 3.581772456913681
Validation loss: 2.8695128243061165

Epoch: 5| Step: 10
Training loss: 2.646674365441618
Validation loss: 2.885360408625597

Epoch: 118| Step: 0
Training loss: 3.1842140763550457
Validation loss: 2.906491995836585

Epoch: 5| Step: 1
Training loss: 3.383947591659863
Validation loss: 2.902063629642033

Epoch: 5| Step: 2
Training loss: 2.973514307726942
Validation loss: 2.8965485439810204

Epoch: 5| Step: 3
Training loss: 2.7577798209266904
Validation loss: 2.8836615136734673

Epoch: 5| Step: 4
Training loss: 2.893624229252089
Validation loss: 2.8872050356243806

Epoch: 5| Step: 5
Training loss: 2.6030333430718944
Validation loss: 2.8730484936449456

Epoch: 5| Step: 6
Training loss: 3.615768780565444
Validation loss: 2.876517373813596

Epoch: 5| Step: 7
Training loss: 3.65893834063634
Validation loss: 2.866138509675293

Epoch: 5| Step: 8
Training loss: 2.8142495541673456
Validation loss: 2.8648437262324573

Epoch: 5| Step: 9
Training loss: 3.302390452321615
Validation loss: 2.865451526502775

Epoch: 5| Step: 10
Training loss: 3.515678981790421
Validation loss: 2.868835026837994

Epoch: 119| Step: 0
Training loss: 2.5821423297482813
Validation loss: 2.864316142011513

Epoch: 5| Step: 1
Training loss: 3.157669956589595
Validation loss: 2.8659817068915325

Epoch: 5| Step: 2
Training loss: 3.5461777325199195
Validation loss: 2.86580002855491

Epoch: 5| Step: 3
Training loss: 2.427572525779595
Validation loss: 2.868797352578506

Epoch: 5| Step: 4
Training loss: 3.7130082627011105
Validation loss: 2.8681368256939233

Epoch: 5| Step: 5
Training loss: 4.111910309878412
Validation loss: 2.876239590524011

Epoch: 5| Step: 6
Training loss: 3.2672770578669588
Validation loss: 2.8735092581929047

Epoch: 5| Step: 7
Training loss: 3.4601585596610462
Validation loss: 2.873214680083083

Epoch: 5| Step: 8
Training loss: 2.3761558731596346
Validation loss: 2.8747458004493005

Epoch: 5| Step: 9
Training loss: 3.2182193059359134
Validation loss: 2.8667164323063776

Epoch: 5| Step: 10
Training loss: 2.16315901312089
Validation loss: 2.879987290333262

Epoch: 120| Step: 0
Training loss: 3.0747476241588525
Validation loss: 2.873012089082501

Epoch: 5| Step: 1
Training loss: 3.2821745523623957
Validation loss: 2.865621764199479

Epoch: 5| Step: 2
Training loss: 3.215089661102885
Validation loss: 2.861069327280069

Epoch: 5| Step: 3
Training loss: 3.039712007834981
Validation loss: 2.8602535405065033

Epoch: 5| Step: 4
Training loss: 3.141776258208185
Validation loss: 2.8615139934017333

Epoch: 5| Step: 5
Training loss: 2.733450597092994
Validation loss: 2.8606828755450078

Epoch: 5| Step: 6
Training loss: 3.41570837646801
Validation loss: 2.860562695653331

Epoch: 5| Step: 7
Training loss: 3.734700081055314
Validation loss: 2.862077971842088

Epoch: 5| Step: 8
Training loss: 3.482408182285195
Validation loss: 2.861484695412822

Epoch: 5| Step: 9
Training loss: 2.474915832475548
Validation loss: 2.8574381804228652

Epoch: 5| Step: 10
Training loss: 2.8980329287746556
Validation loss: 2.8572347184362066

Epoch: 121| Step: 0
Training loss: 3.3615508374250083
Validation loss: 2.8592127280943767

Epoch: 5| Step: 1
Training loss: 3.1144282239652665
Validation loss: 2.8586222361954032

Epoch: 5| Step: 2
Training loss: 3.4920725280815454
Validation loss: 2.858636823667526

Epoch: 5| Step: 3
Training loss: 3.0316091108459804
Validation loss: 2.8603554030043954

Epoch: 5| Step: 4
Training loss: 3.1148594932646256
Validation loss: 2.8652011298369153

Epoch: 5| Step: 5
Training loss: 2.386332928678767
Validation loss: 2.861629062735935

Epoch: 5| Step: 6
Training loss: 3.4036953646911643
Validation loss: 2.8623698134962945

Epoch: 5| Step: 7
Training loss: 3.2045008239983117
Validation loss: 2.862583137913733

Epoch: 5| Step: 8
Training loss: 3.021354805671683
Validation loss: 2.871253662924189

Epoch: 5| Step: 9
Training loss: 3.06775525785264
Validation loss: 2.866557884107822

Epoch: 5| Step: 10
Training loss: 3.4143893087646933
Validation loss: 2.8654919528884726

Epoch: 122| Step: 0
Training loss: 2.4842073395974054
Validation loss: 2.8542158174844863

Epoch: 5| Step: 1
Training loss: 3.5140461406946075
Validation loss: 2.8565168077194705

Epoch: 5| Step: 2
Training loss: 3.0416426113344497
Validation loss: 2.854451073642095

Epoch: 5| Step: 3
Training loss: 2.97617768130504
Validation loss: 2.8521413285584587

Epoch: 5| Step: 4
Training loss: 3.227103051818405
Validation loss: 2.852189173819518

Epoch: 5| Step: 5
Training loss: 3.3254162864810706
Validation loss: 2.8507594640078633

Epoch: 5| Step: 6
Training loss: 3.6148723006744103
Validation loss: 2.850639756983182

Epoch: 5| Step: 7
Training loss: 3.1635577517441664
Validation loss: 2.850268640542255

Epoch: 5| Step: 8
Training loss: 2.9194902285990363
Validation loss: 2.8495187215945608

Epoch: 5| Step: 9
Training loss: 2.424944894695459
Validation loss: 2.8509993359618444

Epoch: 5| Step: 10
Training loss: 3.7493522084531117
Validation loss: 2.849124548531994

Epoch: 123| Step: 0
Training loss: 3.33016804772285
Validation loss: 2.851249109640927

Epoch: 5| Step: 1
Training loss: 2.9506046903881296
Validation loss: 2.851999873390178

Epoch: 5| Step: 2
Training loss: 2.8684365360978608
Validation loss: 2.848275171429874

Epoch: 5| Step: 3
Training loss: 3.5248680847591465
Validation loss: 2.854313749531529

Epoch: 5| Step: 4
Training loss: 3.7358358550433715
Validation loss: 2.8529069918824534

Epoch: 5| Step: 5
Training loss: 3.6641014113322323
Validation loss: 2.8544504611239416

Epoch: 5| Step: 6
Training loss: 2.6853794337005517
Validation loss: 2.8446499395457363

Epoch: 5| Step: 7
Training loss: 3.2083967788830408
Validation loss: 2.8453650654404408

Epoch: 5| Step: 8
Training loss: 2.7378333319907853
Validation loss: 2.844139652090431

Epoch: 5| Step: 9
Training loss: 2.7327001183218083
Validation loss: 2.8431807737903867

Epoch: 5| Step: 10
Training loss: 2.8678368604859337
Validation loss: 2.8452081521992336

Epoch: 124| Step: 0
Training loss: 2.3902559681213327
Validation loss: 2.843582828137657

Epoch: 5| Step: 1
Training loss: 3.5718383199789185
Validation loss: 2.8463445918726347

Epoch: 5| Step: 2
Training loss: 3.163069807142801
Validation loss: 2.8436422515797886

Epoch: 5| Step: 3
Training loss: 3.7162177175382913
Validation loss: 2.839804201586592

Epoch: 5| Step: 4
Training loss: 2.691366297808738
Validation loss: 2.8412339327021123

Epoch: 5| Step: 5
Training loss: 3.3051402546126742
Validation loss: 2.838317028292645

Epoch: 5| Step: 6
Training loss: 3.2002029116193724
Validation loss: 2.838625267102018

Epoch: 5| Step: 7
Training loss: 2.8462597178953764
Validation loss: 2.8377518074901587

Epoch: 5| Step: 8
Training loss: 3.502625978914812
Validation loss: 2.8382275804508215

Epoch: 5| Step: 9
Training loss: 2.7082384728667317
Validation loss: 2.835849318657003

Epoch: 5| Step: 10
Training loss: 3.1823957377313654
Validation loss: 2.8430751273345676

Epoch: 125| Step: 0
Training loss: 3.204505436866923
Validation loss: 2.8364910264768515

Epoch: 5| Step: 1
Training loss: 3.2780848177909974
Validation loss: 2.8394548653966547

Epoch: 5| Step: 2
Training loss: 3.3120043401735773
Validation loss: 2.840170506843401

Epoch: 5| Step: 3
Training loss: 2.6467830024954035
Validation loss: 2.8422261116800973

Epoch: 5| Step: 4
Training loss: 2.7425896765375053
Validation loss: 2.8386649565702573

Epoch: 5| Step: 5
Training loss: 3.3176468504633894
Validation loss: 2.83941360332435

Epoch: 5| Step: 6
Training loss: 3.1254061625699583
Validation loss: 2.835804994622633

Epoch: 5| Step: 7
Training loss: 3.159548254196043
Validation loss: 2.8341272829380646

Epoch: 5| Step: 8
Training loss: 3.13342096598482
Validation loss: 2.835778291385363

Epoch: 5| Step: 9
Training loss: 3.6465709412428278
Validation loss: 2.835128271423146

Epoch: 5| Step: 10
Training loss: 2.7847093648975725
Validation loss: 2.8377750149795586

Epoch: 126| Step: 0
Training loss: 3.0224465808928014
Validation loss: 2.8329156251622454

Epoch: 5| Step: 1
Training loss: 3.076377721287359
Validation loss: 2.830045570193031

Epoch: 5| Step: 2
Training loss: 3.394316882705521
Validation loss: 2.8361871990744163

Epoch: 5| Step: 3
Training loss: 3.404629663166105
Validation loss: 2.8327933821820306

Epoch: 5| Step: 4
Training loss: 3.6746709040472942
Validation loss: 2.8346525579851987

Epoch: 5| Step: 5
Training loss: 3.0082119763131043
Validation loss: 2.8358806705094537

Epoch: 5| Step: 6
Training loss: 2.5838660849601562
Validation loss: 2.830353538646458

Epoch: 5| Step: 7
Training loss: 2.6686683731639067
Validation loss: 2.8324486716440904

Epoch: 5| Step: 8
Training loss: 2.965290020915676
Validation loss: 2.835136432190921

Epoch: 5| Step: 9
Training loss: 3.108912754683758
Validation loss: 2.834078618954682

Epoch: 5| Step: 10
Training loss: 3.478106963598436
Validation loss: 2.83308601265103

Epoch: 127| Step: 0
Training loss: 3.5944046087741914
Validation loss: 2.8350966906129336

Epoch: 5| Step: 1
Training loss: 3.630615882855521
Validation loss: 2.8332081624732353

Epoch: 5| Step: 2
Training loss: 3.1360044889417944
Validation loss: 2.842221496227537

Epoch: 5| Step: 3
Training loss: 2.893187670520284
Validation loss: 2.848019506510836

Epoch: 5| Step: 4
Training loss: 2.562771201320196
Validation loss: 2.857873486638179

Epoch: 5| Step: 5
Training loss: 3.365843042024527
Validation loss: 2.8488160211967664

Epoch: 5| Step: 6
Training loss: 2.999916393386584
Validation loss: 2.8406362920987664

Epoch: 5| Step: 7
Training loss: 2.6274299273960597
Validation loss: 2.8342252614685743

Epoch: 5| Step: 8
Training loss: 3.6176443779532717
Validation loss: 2.827957500981129

Epoch: 5| Step: 9
Training loss: 2.5827349513251234
Validation loss: 2.8277325863022806

Epoch: 5| Step: 10
Training loss: 3.191583149931972
Validation loss: 2.8261712400249435

Epoch: 128| Step: 0
Training loss: 2.864612888992888
Validation loss: 2.8236129638212666

Epoch: 5| Step: 1
Training loss: 3.5162507581116706
Validation loss: 2.8228237450270344

Epoch: 5| Step: 2
Training loss: 3.467404078646834
Validation loss: 2.8259417543249743

Epoch: 5| Step: 3
Training loss: 3.2088125952576876
Validation loss: 2.8265608765384598

Epoch: 5| Step: 4
Training loss: 2.7744058986867306
Validation loss: 2.8220912366956954

Epoch: 5| Step: 5
Training loss: 3.701008123232758
Validation loss: 2.82375755601423

Epoch: 5| Step: 6
Training loss: 2.603463884255888
Validation loss: 2.8237091018987814

Epoch: 5| Step: 7
Training loss: 2.3209599577388764
Validation loss: 2.8226077880960636

Epoch: 5| Step: 8
Training loss: 2.8070888599373247
Validation loss: 2.8226892553549

Epoch: 5| Step: 9
Training loss: 3.0925861057391972
Validation loss: 2.8243449495000905

Epoch: 5| Step: 10
Training loss: 3.822560154283733
Validation loss: 2.8272255737679104

Epoch: 129| Step: 0
Training loss: 3.5203922755399915
Validation loss: 2.824941617141169

Epoch: 5| Step: 1
Training loss: 2.7634169390201553
Validation loss: 2.8238298461568005

Epoch: 5| Step: 2
Training loss: 3.4906925696899846
Validation loss: 2.834168736850363

Epoch: 5| Step: 3
Training loss: 2.9742552458175053
Validation loss: 2.845889941823152

Epoch: 5| Step: 4
Training loss: 3.3295920993379404
Validation loss: 2.8699384981217024

Epoch: 5| Step: 5
Training loss: 3.254974373102754
Validation loss: 2.895643817799589

Epoch: 5| Step: 6
Training loss: 3.2324751281961532
Validation loss: 2.8880009397463655

Epoch: 5| Step: 7
Training loss: 2.6099460913399968
Validation loss: 2.8392996977155027

Epoch: 5| Step: 8
Training loss: 3.043741816014248
Validation loss: 2.8252873543093657

Epoch: 5| Step: 9
Training loss: 2.8414070622356724
Validation loss: 2.8186387541639

Epoch: 5| Step: 10
Training loss: 3.22758899828995
Validation loss: 2.8202010045109684

Epoch: 130| Step: 0
Training loss: 2.963486995539122
Validation loss: 2.82880190594828

Epoch: 5| Step: 1
Training loss: 3.5463419106116163
Validation loss: 2.839912231033079

Epoch: 5| Step: 2
Training loss: 2.9286575337953646
Validation loss: 2.84463345898289

Epoch: 5| Step: 3
Training loss: 2.795655394878643
Validation loss: 2.8509785327151578

Epoch: 5| Step: 4
Training loss: 2.6973377524751574
Validation loss: 2.835809804035354

Epoch: 5| Step: 5
Training loss: 3.6552834822781435
Validation loss: 2.831089082515815

Epoch: 5| Step: 6
Training loss: 3.3485886689639224
Validation loss: 2.8247106847009915

Epoch: 5| Step: 7
Training loss: 3.600124907975742
Validation loss: 2.820757268197949

Epoch: 5| Step: 8
Training loss: 3.20114685011573
Validation loss: 2.8204301074381366

Epoch: 5| Step: 9
Training loss: 2.7601998777852894
Validation loss: 2.816947934642651

Epoch: 5| Step: 10
Training loss: 2.778685255167259
Validation loss: 2.820953484462268

Epoch: 131| Step: 0
Training loss: 3.2912426607055196
Validation loss: 2.862894415390506

Epoch: 5| Step: 1
Training loss: 3.3297274318182017
Validation loss: 2.9135386755973176

Epoch: 5| Step: 2
Training loss: 3.126447876254618
Validation loss: 2.9596769726805903

Epoch: 5| Step: 3
Training loss: 3.272568908385557
Validation loss: 2.8731083971434734

Epoch: 5| Step: 4
Training loss: 2.913462559200359
Validation loss: 2.842705270691785

Epoch: 5| Step: 5
Training loss: 2.825878536710653
Validation loss: 2.8315819738876784

Epoch: 5| Step: 6
Training loss: 2.770480790811562
Validation loss: 2.8238010459843275

Epoch: 5| Step: 7
Training loss: 2.9361929724990707
Validation loss: 2.8210652610036484

Epoch: 5| Step: 8
Training loss: 3.6710157322391925
Validation loss: 2.8222798335725465

Epoch: 5| Step: 9
Training loss: 3.2240913293837568
Validation loss: 2.820607262421854

Epoch: 5| Step: 10
Training loss: 2.8805125916809526
Validation loss: 2.811592863628692

Epoch: 132| Step: 0
Training loss: 2.598358380643724
Validation loss: 2.813105006985331

Epoch: 5| Step: 1
Training loss: 3.391255403620531
Validation loss: 2.81613915015598

Epoch: 5| Step: 2
Training loss: 3.6024605713274296
Validation loss: 2.820211053793514

Epoch: 5| Step: 3
Training loss: 3.250541201792899
Validation loss: 2.826503592770997

Epoch: 5| Step: 4
Training loss: 3.2005670521903467
Validation loss: 2.8234662613511348

Epoch: 5| Step: 5
Training loss: 2.9846149767513133
Validation loss: 2.8251245473198763

Epoch: 5| Step: 6
Training loss: 3.3225591261907876
Validation loss: 2.8250504390748596

Epoch: 5| Step: 7
Training loss: 3.094951203782765
Validation loss: 2.8209987216067502

Epoch: 5| Step: 8
Training loss: 2.847528985925094
Validation loss: 2.82231683983731

Epoch: 5| Step: 9
Training loss: 3.3010856172078045
Validation loss: 2.8164780352328718

Epoch: 5| Step: 10
Training loss: 2.737858934255795
Validation loss: 2.8161803517870743

Epoch: 133| Step: 0
Training loss: 2.488870931127266
Validation loss: 2.8155317348456492

Epoch: 5| Step: 1
Training loss: 3.400437040850282
Validation loss: 2.813865404928906

Epoch: 5| Step: 2
Training loss: 3.161294362038599
Validation loss: 2.8107009101284515

Epoch: 5| Step: 3
Training loss: 3.2098285774258977
Validation loss: 2.815023816193977

Epoch: 5| Step: 4
Training loss: 2.875823359140988
Validation loss: 2.8167057681101637

Epoch: 5| Step: 5
Training loss: 2.954947418932734
Validation loss: 2.8248160541660177

Epoch: 5| Step: 6
Training loss: 2.679003836833717
Validation loss: 2.81781288137863

Epoch: 5| Step: 7
Training loss: 3.61802713029515
Validation loss: 2.8206719033234227

Epoch: 5| Step: 8
Training loss: 3.366771698877618
Validation loss: 2.8157286530403733

Epoch: 5| Step: 9
Training loss: 3.239005344915264
Validation loss: 2.805240036127759

Epoch: 5| Step: 10
Training loss: 3.165791808965012
Validation loss: 2.8078312159100696

Epoch: 134| Step: 0
Training loss: 3.222510354178569
Validation loss: 2.8084348242581836

Epoch: 5| Step: 1
Training loss: 3.136258710329892
Validation loss: 2.8050363934747047

Epoch: 5| Step: 2
Training loss: 3.5112962988479373
Validation loss: 2.804732526937095

Epoch: 5| Step: 3
Training loss: 2.991405095926831
Validation loss: 2.8056184163688602

Epoch: 5| Step: 4
Training loss: 3.3072260492178334
Validation loss: 2.8044703960527264

Epoch: 5| Step: 5
Training loss: 3.249758784806009
Validation loss: 2.803704803871899

Epoch: 5| Step: 6
Training loss: 3.146460885280492
Validation loss: 2.8057572603557643

Epoch: 5| Step: 7
Training loss: 2.9490143761968377
Validation loss: 2.802940231834888

Epoch: 5| Step: 8
Training loss: 2.4396127201159636
Validation loss: 2.8025548040967494

Epoch: 5| Step: 9
Training loss: 3.169005049273247
Validation loss: 2.8033509838346564

Epoch: 5| Step: 10
Training loss: 2.991766758114833
Validation loss: 2.802394188376697

Epoch: 135| Step: 0
Training loss: 3.559652026668387
Validation loss: 2.8003027621887755

Epoch: 5| Step: 1
Training loss: 2.9793515092465026
Validation loss: 2.7996720671341793

Epoch: 5| Step: 2
Training loss: 2.733733358031639
Validation loss: 2.8007513130391124

Epoch: 5| Step: 3
Training loss: 3.1851603579313403
Validation loss: 2.802689541894076

Epoch: 5| Step: 4
Training loss: 3.291731596358643
Validation loss: 2.7990604289887444

Epoch: 5| Step: 5
Training loss: 3.59733535379231
Validation loss: 2.8097386831945284

Epoch: 5| Step: 6
Training loss: 2.954375471547224
Validation loss: 2.8095385265267803

Epoch: 5| Step: 7
Training loss: 3.130858004278786
Validation loss: 2.8293631139223283

Epoch: 5| Step: 8
Training loss: 2.8537910010007
Validation loss: 2.8302351053309653

Epoch: 5| Step: 9
Training loss: 2.6991945478179624
Validation loss: 2.8203881161873134

Epoch: 5| Step: 10
Training loss: 3.143647973773115
Validation loss: 2.8078260590988187

Epoch: 136| Step: 0
Training loss: 2.1395432460735275
Validation loss: 2.799151976520278

Epoch: 5| Step: 1
Training loss: 2.9120635266343857
Validation loss: 2.799122071591255

Epoch: 5| Step: 2
Training loss: 2.2278250343889434
Validation loss: 2.7995796419482053

Epoch: 5| Step: 3
Training loss: 3.349650515645674
Validation loss: 2.7997291746729926

Epoch: 5| Step: 4
Training loss: 2.915987171767579
Validation loss: 2.799959344722558

Epoch: 5| Step: 5
Training loss: 3.690093857726793
Validation loss: 2.801474296480242

Epoch: 5| Step: 6
Training loss: 2.8977596179156504
Validation loss: 2.802045305345277

Epoch: 5| Step: 7
Training loss: 3.7994614570872542
Validation loss: 2.7982517084498135

Epoch: 5| Step: 8
Training loss: 2.879315827218948
Validation loss: 2.798333624600517

Epoch: 5| Step: 9
Training loss: 3.7008845637989616
Validation loss: 2.7958858517028577

Epoch: 5| Step: 10
Training loss: 3.206989915328173
Validation loss: 2.798238827238953

Epoch: 137| Step: 0
Training loss: 2.890476037388528
Validation loss: 2.7953465943633824

Epoch: 5| Step: 1
Training loss: 3.213956800919432
Validation loss: 2.7937620750860575

Epoch: 5| Step: 2
Training loss: 3.4907416096251604
Validation loss: 2.7975160770683196

Epoch: 5| Step: 3
Training loss: 3.332039263985087
Validation loss: 2.7971930204741757

Epoch: 5| Step: 4
Training loss: 3.1165749466671517
Validation loss: 2.798131562745216

Epoch: 5| Step: 5
Training loss: 3.1337530003865397
Validation loss: 2.7917939302335864

Epoch: 5| Step: 6
Training loss: 2.9752586893400803
Validation loss: 2.7978915289085404

Epoch: 5| Step: 7
Training loss: 3.3986141465854294
Validation loss: 2.7923906456143106

Epoch: 5| Step: 8
Training loss: 2.735365072569055
Validation loss: 2.7918911052241273

Epoch: 5| Step: 9
Training loss: 2.69373653612069
Validation loss: 2.792059800137652

Epoch: 5| Step: 10
Training loss: 3.071817664914292
Validation loss: 2.7949504985406914

Epoch: 138| Step: 0
Training loss: 2.8264615556986237
Validation loss: 2.79340160482723

Epoch: 5| Step: 1
Training loss: 3.212129617557902
Validation loss: 2.7980541906443146

Epoch: 5| Step: 2
Training loss: 2.874568906888763
Validation loss: 2.7982763548232783

Epoch: 5| Step: 3
Training loss: 3.8056579229566205
Validation loss: 2.797742434015941

Epoch: 5| Step: 4
Training loss: 2.7382545197797072
Validation loss: 2.8021903123770584

Epoch: 5| Step: 5
Training loss: 3.319609731463335
Validation loss: 2.812588287207466

Epoch: 5| Step: 6
Training loss: 3.1222633586117916
Validation loss: 2.799427073691095

Epoch: 5| Step: 7
Training loss: 3.5240621414854165
Validation loss: 2.7996195855186974

Epoch: 5| Step: 8
Training loss: 2.7932762990362354
Validation loss: 2.796285686689957

Epoch: 5| Step: 9
Training loss: 2.585875357719629
Validation loss: 2.7934871670617714

Epoch: 5| Step: 10
Training loss: 3.0811353186260044
Validation loss: 2.7930772738057854

Epoch: 139| Step: 0
Training loss: 2.5330475441032005
Validation loss: 2.790871615479837

Epoch: 5| Step: 1
Training loss: 3.2517491548739033
Validation loss: 2.793146659129327

Epoch: 5| Step: 2
Training loss: 3.4025839579564208
Validation loss: 2.7931847434092827

Epoch: 5| Step: 3
Training loss: 2.9789175894236544
Validation loss: 2.793184897603027

Epoch: 5| Step: 4
Training loss: 3.0304007372854236
Validation loss: 2.797733091153193

Epoch: 5| Step: 5
Training loss: 2.5081110981513888
Validation loss: 2.8002928886446106

Epoch: 5| Step: 6
Training loss: 3.0511771322548644
Validation loss: 2.814018818381196

Epoch: 5| Step: 7
Training loss: 2.4592982085089323
Validation loss: 2.8210450421715323

Epoch: 5| Step: 8
Training loss: 3.4337715042157453
Validation loss: 2.8281615191508362

Epoch: 5| Step: 9
Training loss: 3.567815997130441
Validation loss: 2.8216341078771476

Epoch: 5| Step: 10
Training loss: 3.6753401618320694
Validation loss: 2.7948701113807686

Epoch: 140| Step: 0
Training loss: 2.6770623252034462
Validation loss: 2.788567233155843

Epoch: 5| Step: 1
Training loss: 3.5346551192200653
Validation loss: 2.7906295718454044

Epoch: 5| Step: 2
Training loss: 2.126490126589796
Validation loss: 2.790761828236629

Epoch: 5| Step: 3
Training loss: 2.960989355272344
Validation loss: 2.795403079521757

Epoch: 5| Step: 4
Training loss: 3.273618561100475
Validation loss: 2.796535117251485

Epoch: 5| Step: 5
Training loss: 3.2788799627494187
Validation loss: 2.795227581201621

Epoch: 5| Step: 6
Training loss: 3.5125602418342448
Validation loss: 2.7980394797347166

Epoch: 5| Step: 7
Training loss: 3.4745049377836703
Validation loss: 2.7986883674948686

Epoch: 5| Step: 8
Training loss: 2.9702170511689356
Validation loss: 2.795330323865487

Epoch: 5| Step: 9
Training loss: 3.19696300754617
Validation loss: 2.7944446664050875

Epoch: 5| Step: 10
Training loss: 2.914001627841094
Validation loss: 2.7915632246820463

Epoch: 141| Step: 0
Training loss: 2.8445205482924893
Validation loss: 2.7898203058499695

Epoch: 5| Step: 1
Training loss: 3.1685925867832974
Validation loss: 2.7903588221677245

Epoch: 5| Step: 2
Training loss: 3.0109149736037857
Validation loss: 2.7875835886431335

Epoch: 5| Step: 3
Training loss: 2.9688129619145815
Validation loss: 2.7870017226361057

Epoch: 5| Step: 4
Training loss: 2.9636355062867525
Validation loss: 2.7856338524786066

Epoch: 5| Step: 5
Training loss: 2.5901318788276475
Validation loss: 2.7832868951533256

Epoch: 5| Step: 6
Training loss: 3.015287548416202
Validation loss: 2.7836246195353374

Epoch: 5| Step: 7
Training loss: 3.139974650140958
Validation loss: 2.7843544412272414

Epoch: 5| Step: 8
Training loss: 3.742594846085507
Validation loss: 2.7821525629225037

Epoch: 5| Step: 9
Training loss: 3.168927556768439
Validation loss: 2.780654087544352

Epoch: 5| Step: 10
Training loss: 3.3947642853249
Validation loss: 2.7823401049193226

Epoch: 142| Step: 0
Training loss: 3.344200603035028
Validation loss: 2.7840150636047802

Epoch: 5| Step: 1
Training loss: 2.8455137714755883
Validation loss: 2.782312147742259

Epoch: 5| Step: 2
Training loss: 3.2535712354736845
Validation loss: 2.793406101792142

Epoch: 5| Step: 3
Training loss: 3.404552071527069
Validation loss: 2.802321864890749

Epoch: 5| Step: 4
Training loss: 2.779343540982084
Validation loss: 2.8147035996981176

Epoch: 5| Step: 5
Training loss: 2.9725036982969693
Validation loss: 2.8244885974810763

Epoch: 5| Step: 6
Training loss: 2.988762152378675
Validation loss: 2.8124993528230897

Epoch: 5| Step: 7
Training loss: 3.2005444063581296
Validation loss: 2.7950123950507963

Epoch: 5| Step: 8
Training loss: 3.3105500437853568
Validation loss: 2.7868740491991906

Epoch: 5| Step: 9
Training loss: 2.6207016766769176
Validation loss: 2.7832479302700706

Epoch: 5| Step: 10
Training loss: 3.2561631086767777
Validation loss: 2.7827377884253273

Epoch: 143| Step: 0
Training loss: 3.0793587782571703
Validation loss: 2.779664531013086

Epoch: 5| Step: 1
Training loss: 2.9510371179317847
Validation loss: 2.777615871701553

Epoch: 5| Step: 2
Training loss: 3.3702916398903877
Validation loss: 2.776066794964041

Epoch: 5| Step: 3
Training loss: 2.9613317061134525
Validation loss: 2.781578840923885

Epoch: 5| Step: 4
Training loss: 2.9257761976863086
Validation loss: 2.7798763928289363

Epoch: 5| Step: 5
Training loss: 3.435057448527261
Validation loss: 2.776459330014523

Epoch: 5| Step: 6
Training loss: 3.251467153534339
Validation loss: 2.778304376900153

Epoch: 5| Step: 7
Training loss: 3.2938794452631015
Validation loss: 2.7779402156902395

Epoch: 5| Step: 8
Training loss: 2.8977553395154723
Validation loss: 2.7782203568532315

Epoch: 5| Step: 9
Training loss: 2.7513317871416
Validation loss: 2.7780519012498086

Epoch: 5| Step: 10
Training loss: 3.033827482223492
Validation loss: 2.776532796220189

Epoch: 144| Step: 0
Training loss: 3.055175898306395
Validation loss: 2.7763470503661285

Epoch: 5| Step: 1
Training loss: 2.5772498292625965
Validation loss: 2.7780705587530377

Epoch: 5| Step: 2
Training loss: 3.380060569852496
Validation loss: 2.778678591152873

Epoch: 5| Step: 3
Training loss: 3.08109043783736
Validation loss: 2.783103376960369

Epoch: 5| Step: 4
Training loss: 3.080271016372059
Validation loss: 2.782236806994282

Epoch: 5| Step: 5
Training loss: 2.885025952782744
Validation loss: 2.7849476794034307

Epoch: 5| Step: 6
Training loss: 3.412825650616918
Validation loss: 2.7981726850435003

Epoch: 5| Step: 7
Training loss: 2.6099903957146386
Validation loss: 2.816325869922319

Epoch: 5| Step: 8
Training loss: 3.1311462994305295
Validation loss: 2.820629925670044

Epoch: 5| Step: 9
Training loss: 3.6534890730117437
Validation loss: 2.8285479222855594

Epoch: 5| Step: 10
Training loss: 3.0882382085663536
Validation loss: 2.7770544052294386

Epoch: 145| Step: 0
Training loss: 3.3954283271901717
Validation loss: 2.7746773596247505

Epoch: 5| Step: 1
Training loss: 3.130024951676922
Validation loss: 2.7692493994349263

Epoch: 5| Step: 2
Training loss: 3.005659963079601
Validation loss: 2.777783920903403

Epoch: 5| Step: 3
Training loss: 3.39222166377171
Validation loss: 2.779303623315478

Epoch: 5| Step: 4
Training loss: 2.826543544960887
Validation loss: 2.7806359526112927

Epoch: 5| Step: 5
Training loss: 2.7388474862574066
Validation loss: 2.7824568029673213

Epoch: 5| Step: 6
Training loss: 3.247506285346382
Validation loss: 2.783274789321833

Epoch: 5| Step: 7
Training loss: 2.783662414132154
Validation loss: 2.780729769879959

Epoch: 5| Step: 8
Training loss: 2.604220844976789
Validation loss: 2.778422145007077

Epoch: 5| Step: 9
Training loss: 3.405174995664486
Validation loss: 2.7796344376395266

Epoch: 5| Step: 10
Training loss: 3.464228940001321
Validation loss: 2.7758148648031558

Epoch: 146| Step: 0
Training loss: 3.5246458159724017
Validation loss: 2.7722256518034

Epoch: 5| Step: 1
Training loss: 2.652278039761559
Validation loss: 2.774885147298768

Epoch: 5| Step: 2
Training loss: 2.6971331210947844
Validation loss: 2.7686830149612662

Epoch: 5| Step: 3
Training loss: 3.106509321045595
Validation loss: 2.76713421091091

Epoch: 5| Step: 4
Training loss: 3.4967025482499223
Validation loss: 2.765693624303324

Epoch: 5| Step: 5
Training loss: 3.1949679088622576
Validation loss: 2.7699506452999896

Epoch: 5| Step: 6
Training loss: 3.4120491428659876
Validation loss: 2.7700981838319243

Epoch: 5| Step: 7
Training loss: 2.8287654594103464
Validation loss: 2.7673241575210916

Epoch: 5| Step: 8
Training loss: 2.671509210186917
Validation loss: 2.7786120017974554

Epoch: 5| Step: 9
Training loss: 3.0308129693613597
Validation loss: 2.7808632585791706

Epoch: 5| Step: 10
Training loss: 3.1402106320142806
Validation loss: 2.7826731857668294

Epoch: 147| Step: 0
Training loss: 2.7242539915797916
Validation loss: 2.7865370811273444

Epoch: 5| Step: 1
Training loss: 2.9635499083678694
Validation loss: 2.779063800855609

Epoch: 5| Step: 2
Training loss: 3.9975902928406835
Validation loss: 2.7815960840101788

Epoch: 5| Step: 3
Training loss: 3.1294584894214075
Validation loss: 2.7727748127085463

Epoch: 5| Step: 4
Training loss: 3.385379513267684
Validation loss: 2.7625734608161605

Epoch: 5| Step: 5
Training loss: 2.5550946485751735
Validation loss: 2.761706667517124

Epoch: 5| Step: 6
Training loss: 3.1539951239181105
Validation loss: 2.7602852265139277

Epoch: 5| Step: 7
Training loss: 2.870418713161407
Validation loss: 2.7592802067657596

Epoch: 5| Step: 8
Training loss: 2.8802717223731076
Validation loss: 2.7663962228186265

Epoch: 5| Step: 9
Training loss: 2.815971012849518
Validation loss: 2.7670081121269154

Epoch: 5| Step: 10
Training loss: 3.1904664541040364
Validation loss: 2.7600030485073646

Epoch: 148| Step: 0
Training loss: 2.8811748370712356
Validation loss: 2.76251610486881

Epoch: 5| Step: 1
Training loss: 2.4111254951919143
Validation loss: 2.7647224567886317

Epoch: 5| Step: 2
Training loss: 2.6439540125992633
Validation loss: 2.7614213250986723

Epoch: 5| Step: 3
Training loss: 2.938503175249213
Validation loss: 2.7689660054942307

Epoch: 5| Step: 4
Training loss: 2.8342478529097686
Validation loss: 2.773686347368634

Epoch: 5| Step: 5
Training loss: 3.5726416271585313
Validation loss: 2.784305162362948

Epoch: 5| Step: 6
Training loss: 3.2120056603216747
Validation loss: 2.8030850755050127

Epoch: 5| Step: 7
Training loss: 3.572110781225802
Validation loss: 2.7943739004706796

Epoch: 5| Step: 8
Training loss: 3.265105867874758
Validation loss: 2.7822797250996847

Epoch: 5| Step: 9
Training loss: 3.3990574764499715
Validation loss: 2.773464166587273

Epoch: 5| Step: 10
Training loss: 2.863553855169747
Validation loss: 2.7607709861950416

Epoch: 149| Step: 0
Training loss: 2.6937249414822904
Validation loss: 2.758447392220243

Epoch: 5| Step: 1
Training loss: 3.117570667093025
Validation loss: 2.7565797229589664

Epoch: 5| Step: 2
Training loss: 3.3373761614851736
Validation loss: 2.7567368079601975

Epoch: 5| Step: 3
Training loss: 2.3367930602945193
Validation loss: 2.7572617156130637

Epoch: 5| Step: 4
Training loss: 3.053784171001861
Validation loss: 2.7583518802366385

Epoch: 5| Step: 5
Training loss: 2.521842712422551
Validation loss: 2.755530710785907

Epoch: 5| Step: 6
Training loss: 3.2380871685846473
Validation loss: 2.7576460794059696

Epoch: 5| Step: 7
Training loss: 3.474932685035401
Validation loss: 2.760256952149077

Epoch: 5| Step: 8
Training loss: 3.0942157433320934
Validation loss: 2.753242395323403

Epoch: 5| Step: 9
Training loss: 3.5524206961492046
Validation loss: 2.755609742030553

Epoch: 5| Step: 10
Training loss: 3.200087581866504
Validation loss: 2.753971742508554

Epoch: 150| Step: 0
Training loss: 3.1590064070522814
Validation loss: 2.7541787159281528

Epoch: 5| Step: 1
Training loss: 2.854592247487207
Validation loss: 2.7563168027962437

Epoch: 5| Step: 2
Training loss: 3.4114586439448016
Validation loss: 2.769280159255378

Epoch: 5| Step: 3
Training loss: 2.702443031324607
Validation loss: 2.778037803299606

Epoch: 5| Step: 4
Training loss: 2.8534019912350215
Validation loss: 2.8032882160936325

Epoch: 5| Step: 5
Training loss: 3.6344074644703572
Validation loss: 2.8235093345134117

Epoch: 5| Step: 6
Training loss: 2.9278366549429196
Validation loss: 2.775869951110976

Epoch: 5| Step: 7
Training loss: 3.143410581311744
Validation loss: 2.75282185700791

Epoch: 5| Step: 8
Training loss: 3.338631964467638
Validation loss: 2.752033218474367

Epoch: 5| Step: 9
Training loss: 2.728016987308626
Validation loss: 2.7540001865907926

Epoch: 5| Step: 10
Training loss: 3.0015717203930965
Validation loss: 2.7571657469309145

Epoch: 151| Step: 0
Training loss: 3.281577829605419
Validation loss: 2.7630403877967304

Epoch: 5| Step: 1
Training loss: 2.9672066943535635
Validation loss: 2.76282447535597

Epoch: 5| Step: 2
Training loss: 3.086633376840752
Validation loss: 2.7680895853353085

Epoch: 5| Step: 3
Training loss: 2.6273897283264582
Validation loss: 2.7602356684003824

Epoch: 5| Step: 4
Training loss: 3.1631067410167995
Validation loss: 2.763647638006873

Epoch: 5| Step: 5
Training loss: 2.9113259237043874
Validation loss: 2.7613419458492414

Epoch: 5| Step: 6
Training loss: 3.3713332143095465
Validation loss: 2.7571147221982044

Epoch: 5| Step: 7
Training loss: 3.2856244673210586
Validation loss: 2.756735543221375

Epoch: 5| Step: 8
Training loss: 2.958254441476449
Validation loss: 2.755268753096124

Epoch: 5| Step: 9
Training loss: 3.056439377859837
Validation loss: 2.751251579134715

Epoch: 5| Step: 10
Training loss: 3.172598469726332
Validation loss: 2.7496083130729025

Epoch: 152| Step: 0
Training loss: 3.3058684563379637
Validation loss: 2.749704649009457

Epoch: 5| Step: 1
Training loss: 3.1719185962405714
Validation loss: 2.749188117796432

Epoch: 5| Step: 2
Training loss: 2.9947094361446145
Validation loss: 2.7496578081959884

Epoch: 5| Step: 3
Training loss: 3.130255895032192
Validation loss: 2.7483880892748487

Epoch: 5| Step: 4
Training loss: 3.2422183851126833
Validation loss: 2.7489682701830973

Epoch: 5| Step: 5
Training loss: 2.3738950869638558
Validation loss: 2.7517168897970605

Epoch: 5| Step: 6
Training loss: 3.142756407844918
Validation loss: 2.7610478415400235

Epoch: 5| Step: 7
Training loss: 3.254554491626288
Validation loss: 2.7677097934035757

Epoch: 5| Step: 8
Training loss: 2.730454779113042
Validation loss: 2.7676504838368374

Epoch: 5| Step: 9
Training loss: 3.408750823426156
Validation loss: 2.783211185635788

Epoch: 5| Step: 10
Training loss: 2.8984643158610433
Validation loss: 2.7751212449337714

Epoch: 153| Step: 0
Training loss: 2.768856509810092
Validation loss: 2.766422921138158

Epoch: 5| Step: 1
Training loss: 2.3219155062894017
Validation loss: 2.7513050215818096

Epoch: 5| Step: 2
Training loss: 2.9810987134250637
Validation loss: 2.745527532881013

Epoch: 5| Step: 3
Training loss: 3.0653771100938627
Validation loss: 2.7478494112384406

Epoch: 5| Step: 4
Training loss: 3.3947925181747234
Validation loss: 2.744314554151857

Epoch: 5| Step: 5
Training loss: 2.6477494597947255
Validation loss: 2.744308314861524

Epoch: 5| Step: 6
Training loss: 3.502224623904666
Validation loss: 2.7450245794241104

Epoch: 5| Step: 7
Training loss: 3.4142564941040585
Validation loss: 2.7436785929685668

Epoch: 5| Step: 8
Training loss: 3.2323712762750487
Validation loss: 2.742458050043254

Epoch: 5| Step: 9
Training loss: 3.1748913483539147
Validation loss: 2.7457081658482902

Epoch: 5| Step: 10
Training loss: 3.0263134587538625
Validation loss: 2.7459898121047934

Epoch: 154| Step: 0
Training loss: 2.859275274153188
Validation loss: 2.7433638492948806

Epoch: 5| Step: 1
Training loss: 3.1490764111636236
Validation loss: 2.745439432940939

Epoch: 5| Step: 2
Training loss: 3.4583135091067883
Validation loss: 2.7417903341760934

Epoch: 5| Step: 3
Training loss: 2.9840559064828422
Validation loss: 2.7410880091706957

Epoch: 5| Step: 4
Training loss: 2.802358441278442
Validation loss: 2.742934131509295

Epoch: 5| Step: 5
Training loss: 3.431544190182432
Validation loss: 2.7488172500978294

Epoch: 5| Step: 6
Training loss: 3.05895573019646
Validation loss: 2.754528841548391

Epoch: 5| Step: 7
Training loss: 3.1852299703937286
Validation loss: 2.7526626859322754

Epoch: 5| Step: 8
Training loss: 3.021362065488664
Validation loss: 2.741610848513502

Epoch: 5| Step: 9
Training loss: 2.5915206152515324
Validation loss: 2.7427046990734567

Epoch: 5| Step: 10
Training loss: 3.1000936186405625
Validation loss: 2.7484955909663777

Epoch: 155| Step: 0
Training loss: 2.931527742351214
Validation loss: 2.7489730804411754

Epoch: 5| Step: 1
Training loss: 3.3315084389355416
Validation loss: 2.74095713457017

Epoch: 5| Step: 2
Training loss: 2.880012786095105
Validation loss: 2.7400981210891806

Epoch: 5| Step: 3
Training loss: 3.3830072994395866
Validation loss: 2.7400910788056536

Epoch: 5| Step: 4
Training loss: 3.1679764264221886
Validation loss: 2.7439800954847393

Epoch: 5| Step: 5
Training loss: 2.67290936352829
Validation loss: 2.7419717490725364

Epoch: 5| Step: 6
Training loss: 2.630089140857203
Validation loss: 2.7397995898568146

Epoch: 5| Step: 7
Training loss: 3.125705791879283
Validation loss: 2.739052774057221

Epoch: 5| Step: 8
Training loss: 2.529109379362051
Validation loss: 2.7384431564762943

Epoch: 5| Step: 9
Training loss: 3.3013279930414607
Validation loss: 2.739071169330337

Epoch: 5| Step: 10
Training loss: 3.611904298446017
Validation loss: 2.737836107406989

Epoch: 156| Step: 0
Training loss: 3.3213604159767702
Validation loss: 2.740192250365863

Epoch: 5| Step: 1
Training loss: 3.241108248222632
Validation loss: 2.7381258813336546

Epoch: 5| Step: 2
Training loss: 3.322713544770019
Validation loss: 2.73851586387208

Epoch: 5| Step: 3
Training loss: 3.460279828481223
Validation loss: 2.745370660937429

Epoch: 5| Step: 4
Training loss: 3.053109856746606
Validation loss: 2.7473021611384625

Epoch: 5| Step: 5
Training loss: 2.85190377479431
Validation loss: 2.7656399213331477

Epoch: 5| Step: 6
Training loss: 2.970349653835393
Validation loss: 2.768731393170319

Epoch: 5| Step: 7
Training loss: 3.0832905293835715
Validation loss: 2.76021220556142

Epoch: 5| Step: 8
Training loss: 2.5234788826303944
Validation loss: 2.751656036455798

Epoch: 5| Step: 9
Training loss: 2.625973021596023
Validation loss: 2.7432290358069973

Epoch: 5| Step: 10
Training loss: 3.0589396742739416
Validation loss: 2.7384707625033378

Epoch: 157| Step: 0
Training loss: 3.4652941560496218
Validation loss: 2.744724863547078

Epoch: 5| Step: 1
Training loss: 2.924830283433493
Validation loss: 2.741395193411933

Epoch: 5| Step: 2
Training loss: 2.721406888070847
Validation loss: 2.740345823558569

Epoch: 5| Step: 3
Training loss: 3.1661466539627336
Validation loss: 2.7349633296769764

Epoch: 5| Step: 4
Training loss: 2.7112095940877996
Validation loss: 2.738444604726555

Epoch: 5| Step: 5
Training loss: 3.122887011474797
Validation loss: 2.7353995423902115

Epoch: 5| Step: 6
Training loss: 3.4511340171063076
Validation loss: 2.7342375249334276

Epoch: 5| Step: 7
Training loss: 3.1795813240488493
Validation loss: 2.734669428617887

Epoch: 5| Step: 8
Training loss: 2.7241093221117096
Validation loss: 2.7380118948888277

Epoch: 5| Step: 9
Training loss: 3.1750962010024386
Validation loss: 2.7451264516845337

Epoch: 5| Step: 10
Training loss: 2.812862966216347
Validation loss: 2.755649360998946

Epoch: 158| Step: 0
Training loss: 3.5676181902484467
Validation loss: 2.7651473839670135

Epoch: 5| Step: 1
Training loss: 2.506597587093518
Validation loss: 2.76246707213431

Epoch: 5| Step: 2
Training loss: 2.895067914255107
Validation loss: 2.757726299439187

Epoch: 5| Step: 3
Training loss: 3.0448305753731275
Validation loss: 2.7608366575736403

Epoch: 5| Step: 4
Training loss: 2.969591041691603
Validation loss: 2.7640162969165507

Epoch: 5| Step: 5
Training loss: 3.590190949528611
Validation loss: 2.7663166610397667

Epoch: 5| Step: 6
Training loss: 2.5180981722624254
Validation loss: 2.7325515606639086

Epoch: 5| Step: 7
Training loss: 3.2664855115316063
Validation loss: 2.730611769088124

Epoch: 5| Step: 8
Training loss: 3.158434272568955
Validation loss: 2.7328111302293157

Epoch: 5| Step: 9
Training loss: 3.140274256009195
Validation loss: 2.7359960969905366

Epoch: 5| Step: 10
Training loss: 2.653845562716857
Validation loss: 2.739604741345092

Epoch: 159| Step: 0
Training loss: 2.3041549843278726
Validation loss: 2.7485150068807256

Epoch: 5| Step: 1
Training loss: 2.538465505988126
Validation loss: 2.749761151543597

Epoch: 5| Step: 2
Training loss: 3.4088514001114794
Validation loss: 2.751963309850515

Epoch: 5| Step: 3
Training loss: 2.7349802273832338
Validation loss: 2.7482614419233133

Epoch: 5| Step: 4
Training loss: 2.950822204838901
Validation loss: 2.747067833847536

Epoch: 5| Step: 5
Training loss: 3.3411181779025623
Validation loss: 2.7383421112787256

Epoch: 5| Step: 6
Training loss: 3.0241288373032944
Validation loss: 2.7358484023559333

Epoch: 5| Step: 7
Training loss: 2.898463822319829
Validation loss: 2.7340096140791785

Epoch: 5| Step: 8
Training loss: 3.1972720379727226
Validation loss: 2.7308863056889088

Epoch: 5| Step: 9
Training loss: 3.662860469850611
Validation loss: 2.72872407830293

Epoch: 5| Step: 10
Training loss: 3.5080419520584902
Validation loss: 2.728981265080104

Epoch: 160| Step: 0
Training loss: 3.4745410314210305
Validation loss: 2.7320493656636144

Epoch: 5| Step: 1
Training loss: 2.3022779379591163
Validation loss: 2.72762190488979

Epoch: 5| Step: 2
Training loss: 3.070629462656808
Validation loss: 2.7414205192734347

Epoch: 5| Step: 3
Training loss: 2.9208442379416426
Validation loss: 2.7436951632278745

Epoch: 5| Step: 4
Training loss: 2.439725984289623
Validation loss: 2.7556652936437955

Epoch: 5| Step: 5
Training loss: 3.8467900109528594
Validation loss: 2.744577433139337

Epoch: 5| Step: 6
Training loss: 2.841535271732605
Validation loss: 2.729709108863985

Epoch: 5| Step: 7
Training loss: 3.3177593872038695
Validation loss: 2.7323700710684156

Epoch: 5| Step: 8
Training loss: 3.0950501147328002
Validation loss: 2.7274199282136298

Epoch: 5| Step: 9
Training loss: 3.12189619421805
Validation loss: 2.722303799323599

Epoch: 5| Step: 10
Training loss: 2.8025057922085637
Validation loss: 2.7247865953638293

Epoch: 161| Step: 0
Training loss: 2.640165390556006
Validation loss: 2.721978752777469

Epoch: 5| Step: 1
Training loss: 2.9376895924521302
Validation loss: 2.726188440553499

Epoch: 5| Step: 2
Training loss: 3.7673854907175275
Validation loss: 2.7250359492862612

Epoch: 5| Step: 3
Training loss: 2.9117548500977675
Validation loss: 2.723020226684063

Epoch: 5| Step: 4
Training loss: 3.1454546028854837
Validation loss: 2.721355364320804

Epoch: 5| Step: 5
Training loss: 3.174771194023187
Validation loss: 2.7246604025191434

Epoch: 5| Step: 6
Training loss: 3.3011871630037373
Validation loss: 2.725104745276273

Epoch: 5| Step: 7
Training loss: 2.7391725142690895
Validation loss: 2.7263677078319835

Epoch: 5| Step: 8
Training loss: 3.3102690183451733
Validation loss: 2.7248948437730665

Epoch: 5| Step: 9
Training loss: 2.157849699745252
Validation loss: 2.7237315693607136

Epoch: 5| Step: 10
Training loss: 3.1922119318941595
Validation loss: 2.726836228662845

Epoch: 162| Step: 0
Training loss: 3.3528525263992357
Validation loss: 2.7268054986802017

Epoch: 5| Step: 1
Training loss: 3.5000456398304287
Validation loss: 2.725754829049462

Epoch: 5| Step: 2
Training loss: 2.855449378995513
Validation loss: 2.728568141008852

Epoch: 5| Step: 3
Training loss: 3.015200728381791
Validation loss: 2.7300566773794968

Epoch: 5| Step: 4
Training loss: 3.156223410314978
Validation loss: 2.734743972471535

Epoch: 5| Step: 5
Training loss: 2.4018892680172934
Validation loss: 2.733278925497002

Epoch: 5| Step: 6
Training loss: 3.318542870561181
Validation loss: 2.7405246362231734

Epoch: 5| Step: 7
Training loss: 2.7139080383586554
Validation loss: 2.7455432618811004

Epoch: 5| Step: 8
Training loss: 3.121208179271618
Validation loss: 2.7434342975727493

Epoch: 5| Step: 9
Training loss: 3.1579998944157492
Validation loss: 2.741118865223298

Epoch: 5| Step: 10
Training loss: 2.704243334921126
Validation loss: 2.723162252135518

Epoch: 163| Step: 0
Training loss: 3.005945354419285
Validation loss: 2.723824479729845

Epoch: 5| Step: 1
Training loss: 2.979089020115127
Validation loss: 2.72818858406836

Epoch: 5| Step: 2
Training loss: 3.6511466119605838
Validation loss: 2.7290042186022325

Epoch: 5| Step: 3
Training loss: 3.337323439139029
Validation loss: 2.7353126917425286

Epoch: 5| Step: 4
Training loss: 3.0959769816762748
Validation loss: 2.733562771453955

Epoch: 5| Step: 5
Training loss: 3.3024123997588575
Validation loss: 2.734123966161283

Epoch: 5| Step: 6
Training loss: 2.7492187430622157
Validation loss: 2.731303533792213

Epoch: 5| Step: 7
Training loss: 2.4588654044703273
Validation loss: 2.730265239316539

Epoch: 5| Step: 8
Training loss: 2.728317089681055
Validation loss: 2.7280131080380365

Epoch: 5| Step: 9
Training loss: 3.6622667934916247
Validation loss: 2.7267772795527754

Epoch: 5| Step: 10
Training loss: 2.136230078124964
Validation loss: 2.7281671563242056

Epoch: 164| Step: 0
Training loss: 2.815919450442323
Validation loss: 2.7310305589021824

Epoch: 5| Step: 1
Training loss: 2.7967309328620864
Validation loss: 2.73374305278472

Epoch: 5| Step: 2
Training loss: 3.0107006920186183
Validation loss: 2.737403284524792

Epoch: 5| Step: 3
Training loss: 3.1402640823304817
Validation loss: 2.734910088143459

Epoch: 5| Step: 4
Training loss: 2.933100713551685
Validation loss: 2.7519954962642283

Epoch: 5| Step: 5
Training loss: 3.3340564579202328
Validation loss: 2.7458459927934644

Epoch: 5| Step: 6
Training loss: 2.942003896112929
Validation loss: 2.736458901524259

Epoch: 5| Step: 7
Training loss: 3.0431050770770036
Validation loss: 2.7462562703506195

Epoch: 5| Step: 8
Training loss: 3.3550227871389606
Validation loss: 2.7373683576200336

Epoch: 5| Step: 9
Training loss: 2.904338248906711
Validation loss: 2.7458810191310348

Epoch: 5| Step: 10
Training loss: 3.125928206875682
Validation loss: 2.7513069280250724

Epoch: 165| Step: 0
Training loss: 3.355828262627137
Validation loss: 2.7362652757698394

Epoch: 5| Step: 1
Training loss: 2.8644584119897
Validation loss: 2.723513368972103

Epoch: 5| Step: 2
Training loss: 2.8677751734036665
Validation loss: 2.7207166880201585

Epoch: 5| Step: 3
Training loss: 2.986361496553648
Validation loss: 2.7191854148773715

Epoch: 5| Step: 4
Training loss: 2.9616712803358367
Validation loss: 2.71899088055425

Epoch: 5| Step: 5
Training loss: 3.3811954571455027
Validation loss: 2.717769756791227

Epoch: 5| Step: 6
Training loss: 3.2750607200992343
Validation loss: 2.7216972460213626

Epoch: 5| Step: 7
Training loss: 3.0409488266387106
Validation loss: 2.715997368222245

Epoch: 5| Step: 8
Training loss: 2.82828862681111
Validation loss: 2.7150442695471995

Epoch: 5| Step: 9
Training loss: 2.647598178617269
Validation loss: 2.719036390368758

Epoch: 5| Step: 10
Training loss: 3.1912849244456596
Validation loss: 2.719543397841685

Epoch: 166| Step: 0
Training loss: 3.268739374263845
Validation loss: 2.7252218622960545

Epoch: 5| Step: 1
Training loss: 3.0755582845390332
Validation loss: 2.741631713932636

Epoch: 5| Step: 2
Training loss: 3.068251988542948
Validation loss: 2.769122491543526

Epoch: 5| Step: 3
Training loss: 3.550126790750961
Validation loss: 2.7743525482454934

Epoch: 5| Step: 4
Training loss: 3.1128532852612123
Validation loss: 2.7832876467576533

Epoch: 5| Step: 5
Training loss: 3.101287291493628
Validation loss: 2.7823119957101743

Epoch: 5| Step: 6
Training loss: 2.765019237320324
Validation loss: 2.7796254351115586

Epoch: 5| Step: 7
Training loss: 2.8524604951093835
Validation loss: 2.736095826651627

Epoch: 5| Step: 8
Training loss: 2.7952903648596066
Validation loss: 2.7086376962583536

Epoch: 5| Step: 9
Training loss: 2.6138207487421887
Validation loss: 2.7099273956863

Epoch: 5| Step: 10
Training loss: 3.2246290422344663
Validation loss: 2.716823276588385

Epoch: 167| Step: 0
Training loss: 3.2324289558079546
Validation loss: 2.7201374668708502

Epoch: 5| Step: 1
Training loss: 2.875099346268843
Validation loss: 2.7247225296235404

Epoch: 5| Step: 2
Training loss: 3.265837009976527
Validation loss: 2.730615149892498

Epoch: 5| Step: 3
Training loss: 3.4004046479822856
Validation loss: 2.7275219767665364

Epoch: 5| Step: 4
Training loss: 2.866145555312619
Validation loss: 2.7289231439146926

Epoch: 5| Step: 5
Training loss: 3.075237023127337
Validation loss: 2.727352197335412

Epoch: 5| Step: 6
Training loss: 3.5502310180715346
Validation loss: 2.7206874757122357

Epoch: 5| Step: 7
Training loss: 2.8747568442308555
Validation loss: 2.719296833321017

Epoch: 5| Step: 8
Training loss: 2.7834859710992172
Validation loss: 2.7140126962180013

Epoch: 5| Step: 9
Training loss: 2.993058438949986
Validation loss: 2.7151522388182694

Epoch: 5| Step: 10
Training loss: 2.484287476347437
Validation loss: 2.7152002640679065

Epoch: 168| Step: 0
Training loss: 3.0518279679436144
Validation loss: 2.7127860424519126

Epoch: 5| Step: 1
Training loss: 2.99626642597456
Validation loss: 2.712077608277084

Epoch: 5| Step: 2
Training loss: 3.1143310002375353
Validation loss: 2.740810922303024

Epoch: 5| Step: 3
Training loss: 2.9286956328793177
Validation loss: 2.8041355333615976

Epoch: 5| Step: 4
Training loss: 3.0409919478144567
Validation loss: 2.808877854387969

Epoch: 5| Step: 5
Training loss: 2.9797027923559636
Validation loss: 2.7777126446816283

Epoch: 5| Step: 6
Training loss: 3.3561159870805706
Validation loss: 2.7186252469662695

Epoch: 5| Step: 7
Training loss: 2.9542979983759268
Validation loss: 2.7073888780543225

Epoch: 5| Step: 8
Training loss: 3.2632478521865
Validation loss: 2.7034874670152838

Epoch: 5| Step: 9
Training loss: 2.9645217499510133
Validation loss: 2.704264120834812

Epoch: 5| Step: 10
Training loss: 2.798753842567985
Validation loss: 2.710458425029747

Epoch: 169| Step: 0
Training loss: 3.045791824691154
Validation loss: 2.7215713027326567

Epoch: 5| Step: 1
Training loss: 2.841583600512857
Validation loss: 2.728716543489701

Epoch: 5| Step: 2
Training loss: 3.2013912812336893
Validation loss: 2.728038024361641

Epoch: 5| Step: 3
Training loss: 3.315579260709267
Validation loss: 2.7153214564427497

Epoch: 5| Step: 4
Training loss: 2.987188321378954
Validation loss: 2.7207944747903006

Epoch: 5| Step: 5
Training loss: 2.9013160744719384
Validation loss: 2.709620702881698

Epoch: 5| Step: 6
Training loss: 3.3229695538145716
Validation loss: 2.709014665521961

Epoch: 5| Step: 7
Training loss: 2.7871282800088073
Validation loss: 2.7063482792311984

Epoch: 5| Step: 8
Training loss: 2.7687256237188356
Validation loss: 2.7048072452752434

Epoch: 5| Step: 9
Training loss: 3.105671272631716
Validation loss: 2.703862897744742

Epoch: 5| Step: 10
Training loss: 3.180253861808726
Validation loss: 2.7070334016520023

Epoch: 170| Step: 0
Training loss: 2.9688683737193857
Validation loss: 2.7144464234655494

Epoch: 5| Step: 1
Training loss: 2.7119345466738527
Validation loss: 2.7202202830399034

Epoch: 5| Step: 2
Training loss: 3.0359496818765344
Validation loss: 2.7165712238514343

Epoch: 5| Step: 3
Training loss: 3.642100808622806
Validation loss: 2.7158657678335136

Epoch: 5| Step: 4
Training loss: 3.28988571919286
Validation loss: 2.7108599183663733

Epoch: 5| Step: 5
Training loss: 2.8051648597073076
Validation loss: 2.7051708818733053

Epoch: 5| Step: 6
Training loss: 2.8632444454809716
Validation loss: 2.7022821915755584

Epoch: 5| Step: 7
Training loss: 2.841227827745046
Validation loss: 2.699883309633859

Epoch: 5| Step: 8
Training loss: 2.6938424787113786
Validation loss: 2.7025989412037275

Epoch: 5| Step: 9
Training loss: 3.1083573252661356
Validation loss: 2.7018070131622807

Epoch: 5| Step: 10
Training loss: 3.331943381113534
Validation loss: 2.703834933158233

Epoch: 171| Step: 0
Training loss: 3.135752071720252
Validation loss: 2.7030778793409436

Epoch: 5| Step: 1
Training loss: 2.348949615620227
Validation loss: 2.704229571725714

Epoch: 5| Step: 2
Training loss: 3.1274206323104936
Validation loss: 2.714398891108878

Epoch: 5| Step: 3
Training loss: 2.963344752915831
Validation loss: 2.721433243993843

Epoch: 5| Step: 4
Training loss: 3.0724470566362116
Validation loss: 2.7136779477584274

Epoch: 5| Step: 5
Training loss: 2.909868346444584
Validation loss: 2.7062460555760914

Epoch: 5| Step: 6
Training loss: 2.916377643615563
Validation loss: 2.703523025073361

Epoch: 5| Step: 7
Training loss: 2.717933532188432
Validation loss: 2.6952763856260957

Epoch: 5| Step: 8
Training loss: 2.998610651643345
Validation loss: 2.699657597967417

Epoch: 5| Step: 9
Training loss: 3.0777641898206056
Validation loss: 2.698360552142743

Epoch: 5| Step: 10
Training loss: 3.9551820491747605
Validation loss: 2.700609149679927

Epoch: 172| Step: 0
Training loss: 3.0514088863025632
Validation loss: 2.702021294595556

Epoch: 5| Step: 1
Training loss: 3.1854052672962894
Validation loss: 2.697038767487618

Epoch: 5| Step: 2
Training loss: 2.720200425785812
Validation loss: 2.7020230982376043

Epoch: 5| Step: 3
Training loss: 3.0740976079510633
Validation loss: 2.7109505198942285

Epoch: 5| Step: 4
Training loss: 2.8827021714681536
Validation loss: 2.704437752718047

Epoch: 5| Step: 5
Training loss: 2.5183404518530073
Validation loss: 2.7070440907534765

Epoch: 5| Step: 6
Training loss: 2.997908658000825
Validation loss: 2.709289186323229

Epoch: 5| Step: 7
Training loss: 2.674153209956345
Validation loss: 2.7121810394384047

Epoch: 5| Step: 8
Training loss: 3.051839530155913
Validation loss: 2.701550380434513

Epoch: 5| Step: 9
Training loss: 3.4252745580960138
Validation loss: 2.7088043850791017

Epoch: 5| Step: 10
Training loss: 3.57164126988963
Validation loss: 2.711332408661132

Epoch: 173| Step: 0
Training loss: 3.2607006562756458
Validation loss: 2.7035899210889287

Epoch: 5| Step: 1
Training loss: 2.6874233501060663
Validation loss: 2.7188982557157666

Epoch: 5| Step: 2
Training loss: 3.059674419211088
Validation loss: 2.705083719350449

Epoch: 5| Step: 3
Training loss: 2.7970664528899425
Validation loss: 2.701786986417393

Epoch: 5| Step: 4
Training loss: 2.9916266570608063
Validation loss: 2.690639473600799

Epoch: 5| Step: 5
Training loss: 2.7566672046142693
Validation loss: 2.6927797511102045

Epoch: 5| Step: 6
Training loss: 3.1651240322403376
Validation loss: 2.700098277331126

Epoch: 5| Step: 7
Training loss: 3.4765742955382763
Validation loss: 2.7058937658846025

Epoch: 5| Step: 8
Training loss: 3.242059985491312
Validation loss: 2.703543346192077

Epoch: 5| Step: 9
Training loss: 2.812712512994461
Validation loss: 2.70090514343197

Epoch: 5| Step: 10
Training loss: 2.808669130377508
Validation loss: 2.7034259974488233

Epoch: 174| Step: 0
Training loss: 2.3564125308536203
Validation loss: 2.692248812287094

Epoch: 5| Step: 1
Training loss: 3.0609634593040043
Validation loss: 2.6936457220141876

Epoch: 5| Step: 2
Training loss: 3.6977269226967566
Validation loss: 2.692046588133882

Epoch: 5| Step: 3
Training loss: 3.1114288141369864
Validation loss: 2.6905856798943955

Epoch: 5| Step: 4
Training loss: 3.1867323306300013
Validation loss: 2.6928674794410097

Epoch: 5| Step: 5
Training loss: 2.5645803055382546
Validation loss: 2.6929694507872526

Epoch: 5| Step: 6
Training loss: 3.187542634566662
Validation loss: 2.6924566199389606

Epoch: 5| Step: 7
Training loss: 2.817301910666865
Validation loss: 2.6941109847984075

Epoch: 5| Step: 8
Training loss: 2.8253234138020598
Validation loss: 2.700054380498939

Epoch: 5| Step: 9
Training loss: 3.08562751854911
Validation loss: 2.7011806502219815

Epoch: 5| Step: 10
Training loss: 3.163042973282228
Validation loss: 2.707913820765832

Epoch: 175| Step: 0
Training loss: 2.5690555919781244
Validation loss: 2.697066701784203

Epoch: 5| Step: 1
Training loss: 3.048037106856304
Validation loss: 2.6877896524119214

Epoch: 5| Step: 2
Training loss: 3.0709336601303967
Validation loss: 2.68996559590412

Epoch: 5| Step: 3
Training loss: 2.488848036286967
Validation loss: 2.689998723316572

Epoch: 5| Step: 4
Training loss: 3.1515187976778276
Validation loss: 2.687749541540898

Epoch: 5| Step: 5
Training loss: 3.3382171774691645
Validation loss: 2.6902788633205024

Epoch: 5| Step: 6
Training loss: 3.1430785051640093
Validation loss: 2.6958501074251138

Epoch: 5| Step: 7
Training loss: 2.6506836854949927
Validation loss: 2.6930743093106506

Epoch: 5| Step: 8
Training loss: 2.879712430584229
Validation loss: 2.6921999081563452

Epoch: 5| Step: 9
Training loss: 3.0277408068749416
Validation loss: 2.6942839436381294

Epoch: 5| Step: 10
Training loss: 3.70181753520684
Validation loss: 2.693185811345633

Epoch: 176| Step: 0
Training loss: 2.778820133671237
Validation loss: 2.6951983160889648

Epoch: 5| Step: 1
Training loss: 3.0073176782000846
Validation loss: 2.691296720351518

Epoch: 5| Step: 2
Training loss: 3.2882131172964963
Validation loss: 2.6849819118745755

Epoch: 5| Step: 3
Training loss: 3.176238117458511
Validation loss: 2.6896648840291295

Epoch: 5| Step: 4
Training loss: 2.9361172932159034
Validation loss: 2.684969202403009

Epoch: 5| Step: 5
Training loss: 3.2321936581540154
Validation loss: 2.681595056055505

Epoch: 5| Step: 6
Training loss: 2.647715512330322
Validation loss: 2.689162298997133

Epoch: 5| Step: 7
Training loss: 3.193732806194927
Validation loss: 2.685208455201292

Epoch: 5| Step: 8
Training loss: 3.0085012464782253
Validation loss: 2.687009728048534

Epoch: 5| Step: 9
Training loss: 2.6137379245853105
Validation loss: 2.686634967132157

Epoch: 5| Step: 10
Training loss: 3.175721940991777
Validation loss: 2.684543936546326

Epoch: 177| Step: 0
Training loss: 3.096071701491089
Validation loss: 2.685932866284306

Epoch: 5| Step: 1
Training loss: 3.028152141311624
Validation loss: 2.695278806328671

Epoch: 5| Step: 2
Training loss: 3.2931423661879444
Validation loss: 2.6964194382553717

Epoch: 5| Step: 3
Training loss: 2.750705715140195
Validation loss: 2.706559947751109

Epoch: 5| Step: 4
Training loss: 2.985405708997431
Validation loss: 2.7326518640025426

Epoch: 5| Step: 5
Training loss: 2.7602926454334216
Validation loss: 2.717431086671238

Epoch: 5| Step: 6
Training loss: 3.676381044980325
Validation loss: 2.7271759436622607

Epoch: 5| Step: 7
Training loss: 2.632115755793843
Validation loss: 2.7260976674228448

Epoch: 5| Step: 8
Training loss: 2.986437658942016
Validation loss: 2.7000646927533785

Epoch: 5| Step: 9
Training loss: 3.0575741448383686
Validation loss: 2.693132847169541

Epoch: 5| Step: 10
Training loss: 2.6884603337062396
Validation loss: 2.681818406841828

Epoch: 178| Step: 0
Training loss: 3.6796363130479715
Validation loss: 2.68323653046583

Epoch: 5| Step: 1
Training loss: 3.466142929079753
Validation loss: 2.6835640007968884

Epoch: 5| Step: 2
Training loss: 2.722014298142909
Validation loss: 2.6802556747926363

Epoch: 5| Step: 3
Training loss: 2.563735849982187
Validation loss: 2.681300691040868

Epoch: 5| Step: 4
Training loss: 3.0157348929033705
Validation loss: 2.6802314630246613

Epoch: 5| Step: 5
Training loss: 3.0947017554326823
Validation loss: 2.6801574671851265

Epoch: 5| Step: 6
Training loss: 2.3668110866091627
Validation loss: 2.6830530551702467

Epoch: 5| Step: 7
Training loss: 3.321697350216902
Validation loss: 2.6774005011722375

Epoch: 5| Step: 8
Training loss: 3.2147989559645107
Validation loss: 2.6813975163481136

Epoch: 5| Step: 9
Training loss: 2.8274212377828456
Validation loss: 2.677063449463216

Epoch: 5| Step: 10
Training loss: 2.502155804967541
Validation loss: 2.681631213192127

Epoch: 179| Step: 0
Training loss: 3.304729921325686
Validation loss: 2.6829605302410027

Epoch: 5| Step: 1
Training loss: 2.9155905963793685
Validation loss: 2.68894018746027

Epoch: 5| Step: 2
Training loss: 3.0622289109429977
Validation loss: 2.689007809498675

Epoch: 5| Step: 3
Training loss: 3.1802393179037054
Validation loss: 2.691211088924884

Epoch: 5| Step: 4
Training loss: 2.2445936949156584
Validation loss: 2.6926062652982172

Epoch: 5| Step: 5
Training loss: 2.725357795114095
Validation loss: 2.6918483106585653

Epoch: 5| Step: 6
Training loss: 2.916594931310683
Validation loss: 2.68693046325245

Epoch: 5| Step: 7
Training loss: 3.3129787458986764
Validation loss: 2.6890211882175525

Epoch: 5| Step: 8
Training loss: 2.9070779584962807
Validation loss: 2.6875299135848474

Epoch: 5| Step: 9
Training loss: 3.1825846752040627
Validation loss: 2.6822170627508224

Epoch: 5| Step: 10
Training loss: 3.184654761127303
Validation loss: 2.6774867226988297

Epoch: 180| Step: 0
Training loss: 3.0449414500352985
Validation loss: 2.68684691535137

Epoch: 5| Step: 1
Training loss: 3.319889966221378
Validation loss: 2.685735463312053

Epoch: 5| Step: 2
Training loss: 3.1328383751464166
Validation loss: 2.680126515734066

Epoch: 5| Step: 3
Training loss: 2.5043521192517892
Validation loss: 2.6862744930494458

Epoch: 5| Step: 4
Training loss: 2.9833736637166988
Validation loss: 2.6869230469063874

Epoch: 5| Step: 5
Training loss: 2.787557842526922
Validation loss: 2.691995282389031

Epoch: 5| Step: 6
Training loss: 3.2418398015744496
Validation loss: 2.6840661861151043

Epoch: 5| Step: 7
Training loss: 3.2525415019994757
Validation loss: 2.6822041872507856

Epoch: 5| Step: 8
Training loss: 2.9952636523733607
Validation loss: 2.6852159373852653

Epoch: 5| Step: 9
Training loss: 2.7762025615927928
Validation loss: 2.6843567553259318

Epoch: 5| Step: 10
Training loss: 2.8567808296541055
Validation loss: 2.6788336505270016

Epoch: 181| Step: 0
Training loss: 3.3629830789812427
Validation loss: 2.6853715968353318

Epoch: 5| Step: 1
Training loss: 2.42123887106288
Validation loss: 2.68639566292528

Epoch: 5| Step: 2
Training loss: 2.7387404118086702
Validation loss: 2.6828676323191782

Epoch: 5| Step: 3
Training loss: 2.7963435344715357
Validation loss: 2.6874772300051326

Epoch: 5| Step: 4
Training loss: 2.7086769375103663
Validation loss: 2.692502801999771

Epoch: 5| Step: 5
Training loss: 3.152006412499581
Validation loss: 2.696103987983664

Epoch: 5| Step: 6
Training loss: 3.795209857028557
Validation loss: 2.6949955627135784

Epoch: 5| Step: 7
Training loss: 3.116881238381534
Validation loss: 2.686460419368996

Epoch: 5| Step: 8
Training loss: 2.8191548769309023
Validation loss: 2.6809212449021365

Epoch: 5| Step: 9
Training loss: 2.9903619441272933
Validation loss: 2.681474305028425

Epoch: 5| Step: 10
Training loss: 2.87913000927199
Validation loss: 2.68124805812458

Epoch: 182| Step: 0
Training loss: 2.7482270681249856
Validation loss: 2.6785514320217008

Epoch: 5| Step: 1
Training loss: 3.0511347801523407
Validation loss: 2.682589205949132

Epoch: 5| Step: 2
Training loss: 2.8114516105632723
Validation loss: 2.6779571153584585

Epoch: 5| Step: 3
Training loss: 3.553323672736552
Validation loss: 2.6858062185763707

Epoch: 5| Step: 4
Training loss: 3.2253298864273927
Validation loss: 2.6845727648202518

Epoch: 5| Step: 5
Training loss: 3.1505937410304914
Validation loss: 2.6795661425465105

Epoch: 5| Step: 6
Training loss: 2.9853875005503694
Validation loss: 2.6852279468341114

Epoch: 5| Step: 7
Training loss: 2.489937750409742
Validation loss: 2.68452184815692

Epoch: 5| Step: 8
Training loss: 2.762132238704251
Validation loss: 2.6899650050202175

Epoch: 5| Step: 9
Training loss: 2.468054951233779
Validation loss: 2.6916668186500736

Epoch: 5| Step: 10
Training loss: 3.557853077291456
Validation loss: 2.688624043693011

Epoch: 183| Step: 0
Training loss: 2.8931650909461144
Validation loss: 2.6833345594602687

Epoch: 5| Step: 1
Training loss: 3.531173570194039
Validation loss: 2.69030096971763

Epoch: 5| Step: 2
Training loss: 3.2005378509557407
Validation loss: 2.6740629377897567

Epoch: 5| Step: 3
Training loss: 2.5518694625820575
Validation loss: 2.6787950520941237

Epoch: 5| Step: 4
Training loss: 2.797740525310836
Validation loss: 2.6874501156213513

Epoch: 5| Step: 5
Training loss: 2.677305803567125
Validation loss: 2.6899544882180804

Epoch: 5| Step: 6
Training loss: 3.513186545831369
Validation loss: 2.68170420283284

Epoch: 5| Step: 7
Training loss: 2.4843302788697956
Validation loss: 2.6841670816210574

Epoch: 5| Step: 8
Training loss: 2.94795881225509
Validation loss: 2.6830020169819675

Epoch: 5| Step: 9
Training loss: 3.07368761294836
Validation loss: 2.689216502497717

Epoch: 5| Step: 10
Training loss: 3.124453687598404
Validation loss: 2.6881492366643696

Epoch: 184| Step: 0
Training loss: 3.0862976636639883
Validation loss: 2.6784200965451217

Epoch: 5| Step: 1
Training loss: 3.302364172961452
Validation loss: 2.6698982339803408

Epoch: 5| Step: 2
Training loss: 3.237050447218788
Validation loss: 2.67027425798671

Epoch: 5| Step: 3
Training loss: 3.1438794331231357
Validation loss: 2.6656635369108526

Epoch: 5| Step: 4
Training loss: 2.5231310773525415
Validation loss: 2.666623690730574

Epoch: 5| Step: 5
Training loss: 2.742134637132915
Validation loss: 2.6631661122164707

Epoch: 5| Step: 6
Training loss: 3.008814736380239
Validation loss: 2.6650790178540205

Epoch: 5| Step: 7
Training loss: 3.111716610780632
Validation loss: 2.6655235596390385

Epoch: 5| Step: 8
Training loss: 3.0261519516475786
Validation loss: 2.6704999514225336

Epoch: 5| Step: 9
Training loss: 3.0945636950773245
Validation loss: 2.670946786226211

Epoch: 5| Step: 10
Training loss: 2.4726841158147925
Validation loss: 2.662115846426115

Epoch: 185| Step: 0
Training loss: 2.7336266065674186
Validation loss: 2.6624451567251803

Epoch: 5| Step: 1
Training loss: 2.823218372921438
Validation loss: 2.669133033747109

Epoch: 5| Step: 2
Training loss: 3.064718260518807
Validation loss: 2.6766731391967116

Epoch: 5| Step: 3
Training loss: 2.915641132077055
Validation loss: 2.670948158775146

Epoch: 5| Step: 4
Training loss: 3.277364410226149
Validation loss: 2.668884084772688

Epoch: 5| Step: 5
Training loss: 2.38197457010578
Validation loss: 2.6643373316764194

Epoch: 5| Step: 6
Training loss: 3.2332779502713556
Validation loss: 2.6767680459427496

Epoch: 5| Step: 7
Training loss: 3.334849553182032
Validation loss: 2.679117984667855

Epoch: 5| Step: 8
Training loss: 2.905884094174166
Validation loss: 2.6752716189912586

Epoch: 5| Step: 9
Training loss: 2.8018777102972736
Validation loss: 2.6854312391099024

Epoch: 5| Step: 10
Training loss: 3.3519417786014407
Validation loss: 2.692710034995135

Epoch: 186| Step: 0
Training loss: 2.972435841553745
Validation loss: 2.683357612053157

Epoch: 5| Step: 1
Training loss: 2.7463796366400306
Validation loss: 2.712829693580321

Epoch: 5| Step: 2
Training loss: 3.495626987434203
Validation loss: 2.708043896249461

Epoch: 5| Step: 3
Training loss: 2.695056317082464
Validation loss: 2.6917400428459812

Epoch: 5| Step: 4
Training loss: 3.297975184840574
Validation loss: 2.715691273128626

Epoch: 5| Step: 5
Training loss: 2.7462918683534134
Validation loss: 2.7156858866002977

Epoch: 5| Step: 6
Training loss: 2.4521013784811427
Validation loss: 2.6853193597113614

Epoch: 5| Step: 7
Training loss: 3.178855993474082
Validation loss: 2.677812539146221

Epoch: 5| Step: 8
Training loss: 3.3051533832825255
Validation loss: 2.678685474302019

Epoch: 5| Step: 9
Training loss: 3.101063878026079
Validation loss: 2.669485521824437

Epoch: 5| Step: 10
Training loss: 2.7070124902116475
Validation loss: 2.667326155055937

Epoch: 187| Step: 0
Training loss: 2.490059353530844
Validation loss: 2.666826549731015

Epoch: 5| Step: 1
Training loss: 3.2201055246441457
Validation loss: 2.6631227791244956

Epoch: 5| Step: 2
Training loss: 2.9735694715647187
Validation loss: 2.6613400298964502

Epoch: 5| Step: 3
Training loss: 3.37173218941738
Validation loss: 2.6635672229447778

Epoch: 5| Step: 4
Training loss: 3.2684033999664286
Validation loss: 2.663002608531099

Epoch: 5| Step: 5
Training loss: 2.815460681248497
Validation loss: 2.662571299009069

Epoch: 5| Step: 6
Training loss: 2.6720701447548096
Validation loss: 2.6588826104413266

Epoch: 5| Step: 7
Training loss: 3.1127102087650242
Validation loss: 2.659076450739906

Epoch: 5| Step: 8
Training loss: 3.2163906894814276
Validation loss: 2.6608301476159477

Epoch: 5| Step: 9
Training loss: 2.7613673654310604
Validation loss: 2.6795223284077667

Epoch: 5| Step: 10
Training loss: 2.8911031791460267
Validation loss: 2.692474533755698

Epoch: 188| Step: 0
Training loss: 3.303504822402005
Validation loss: 2.709395518547348

Epoch: 5| Step: 1
Training loss: 2.914537324649053
Validation loss: 2.69200525411207

Epoch: 5| Step: 2
Training loss: 3.1610509032773186
Validation loss: 2.6722263905572268

Epoch: 5| Step: 3
Training loss: 2.566259649958168
Validation loss: 2.6682396387887373

Epoch: 5| Step: 4
Training loss: 2.9406207126176738
Validation loss: 2.67319540190521

Epoch: 5| Step: 5
Training loss: 2.5740901006061963
Validation loss: 2.6600796275279674

Epoch: 5| Step: 6
Training loss: 3.3578332956272776
Validation loss: 2.6600564859625537

Epoch: 5| Step: 7
Training loss: 2.7632556831055
Validation loss: 2.6625925816264218

Epoch: 5| Step: 8
Training loss: 2.9678121591234206
Validation loss: 2.662899483396564

Epoch: 5| Step: 9
Training loss: 2.750049070440661
Validation loss: 2.658620205629641

Epoch: 5| Step: 10
Training loss: 3.537217760452879
Validation loss: 2.6580500796644135

Epoch: 189| Step: 0
Training loss: 2.748976256810934
Validation loss: 2.666040536093318

Epoch: 5| Step: 1
Training loss: 3.381696768135223
Validation loss: 2.6692464867098544

Epoch: 5| Step: 2
Training loss: 2.717819756275257
Validation loss: 2.6614227193003566

Epoch: 5| Step: 3
Training loss: 3.087146222931109
Validation loss: 2.6710477050852846

Epoch: 5| Step: 4
Training loss: 2.4649296426694507
Validation loss: 2.689590253646543

Epoch: 5| Step: 5
Training loss: 3.0514557663025648
Validation loss: 2.696452814386047

Epoch: 5| Step: 6
Training loss: 3.224501129126532
Validation loss: 2.7031086049793984

Epoch: 5| Step: 7
Training loss: 2.811649024228151
Validation loss: 2.690539683126177

Epoch: 5| Step: 8
Training loss: 3.1198806028261905
Validation loss: 2.6742006523848136

Epoch: 5| Step: 9
Training loss: 3.102407037785433
Validation loss: 2.667274189266827

Epoch: 5| Step: 10
Training loss: 3.111584209241127
Validation loss: 2.665291247544302

Epoch: 190| Step: 0
Training loss: 3.461640504001372
Validation loss: 2.663884581187838

Epoch: 5| Step: 1
Training loss: 2.5675049263406384
Validation loss: 2.6619251176529874

Epoch: 5| Step: 2
Training loss: 3.089144428654385
Validation loss: 2.6574927900175216

Epoch: 5| Step: 3
Training loss: 2.494039104788331
Validation loss: 2.6646057639295195

Epoch: 5| Step: 4
Training loss: 3.4012188634039564
Validation loss: 2.6617427064188055

Epoch: 5| Step: 5
Training loss: 3.58396322051829
Validation loss: 2.6584042880057512

Epoch: 5| Step: 6
Training loss: 3.2187953316172218
Validation loss: 2.6664889651997283

Epoch: 5| Step: 7
Training loss: 2.7167170147433097
Validation loss: 2.6564991090421377

Epoch: 5| Step: 8
Training loss: 2.9578759462188766
Validation loss: 2.6566402392342154

Epoch: 5| Step: 9
Training loss: 2.6953791955629427
Validation loss: 2.665310692462407

Epoch: 5| Step: 10
Training loss: 2.260473880541825
Validation loss: 2.6621408171237655

Epoch: 191| Step: 0
Training loss: 2.947074383395276
Validation loss: 2.674347562503824

Epoch: 5| Step: 1
Training loss: 3.1939870608264154
Validation loss: 2.66876345506645

Epoch: 5| Step: 2
Training loss: 3.1730959191453962
Validation loss: 2.67561314869692

Epoch: 5| Step: 3
Training loss: 3.406098248662392
Validation loss: 2.692345553328784

Epoch: 5| Step: 4
Training loss: 2.8680335519442806
Validation loss: 2.673343022239205

Epoch: 5| Step: 5
Training loss: 3.309245544149326
Validation loss: 2.671477180671125

Epoch: 5| Step: 6
Training loss: 2.45564102117138
Validation loss: 2.6789862970592737

Epoch: 5| Step: 7
Training loss: 3.0839605638528216
Validation loss: 2.668154763381955

Epoch: 5| Step: 8
Training loss: 2.9745245737973844
Validation loss: 2.6582864288976444

Epoch: 5| Step: 9
Training loss: 2.7697481788720855
Validation loss: 2.6579239957694663

Epoch: 5| Step: 10
Training loss: 2.365483441772434
Validation loss: 2.6561601279760767

Epoch: 192| Step: 0
Training loss: 2.969644993844438
Validation loss: 2.649095395546314

Epoch: 5| Step: 1
Training loss: 2.740048261481948
Validation loss: 2.6501973469705704

Epoch: 5| Step: 2
Training loss: 2.654439600909983
Validation loss: 2.6589852444252675

Epoch: 5| Step: 3
Training loss: 3.4316089435432833
Validation loss: 2.653709440726814

Epoch: 5| Step: 4
Training loss: 3.0327407474667556
Validation loss: 2.661858591268664

Epoch: 5| Step: 5
Training loss: 3.2480336623115207
Validation loss: 2.655178568663498

Epoch: 5| Step: 6
Training loss: 3.1438224040921394
Validation loss: 2.6556805641502033

Epoch: 5| Step: 7
Training loss: 2.7204491578230776
Validation loss: 2.673726320618889

Epoch: 5| Step: 8
Training loss: 2.6557326766746074
Validation loss: 2.675146188652469

Epoch: 5| Step: 9
Training loss: 2.9439862652541167
Validation loss: 2.695769813028768

Epoch: 5| Step: 10
Training loss: 3.127914900302621
Validation loss: 2.6812603463699167

Epoch: 193| Step: 0
Training loss: 2.849456762105951
Validation loss: 2.700740491092426

Epoch: 5| Step: 1
Training loss: 2.7406607613573764
Validation loss: 2.7019765807762632

Epoch: 5| Step: 2
Training loss: 3.469270959172716
Validation loss: 2.6758476889200145

Epoch: 5| Step: 3
Training loss: 3.0206603077412035
Validation loss: 2.67754886531784

Epoch: 5| Step: 4
Training loss: 2.9996455301042513
Validation loss: 2.6930350663193976

Epoch: 5| Step: 5
Training loss: 3.503000199666672
Validation loss: 2.7009321350812896

Epoch: 5| Step: 6
Training loss: 2.622213610493084
Validation loss: 2.658507682978923

Epoch: 5| Step: 7
Training loss: 3.162715220007361
Validation loss: 2.6624937735378884

Epoch: 5| Step: 8
Training loss: 2.354716470257928
Validation loss: 2.6521671126463273

Epoch: 5| Step: 9
Training loss: 3.0161230436972692
Validation loss: 2.648815789507718

Epoch: 5| Step: 10
Training loss: 2.852574333539643
Validation loss: 2.6530162519257248

Epoch: 194| Step: 0
Training loss: 2.6907106782428336
Validation loss: 2.6512369392247637

Epoch: 5| Step: 1
Training loss: 2.9838603110152215
Validation loss: 2.6509747301618805

Epoch: 5| Step: 2
Training loss: 3.5211046704956015
Validation loss: 2.6490913339304076

Epoch: 5| Step: 3
Training loss: 2.3989692620378937
Validation loss: 2.643794408680414

Epoch: 5| Step: 4
Training loss: 3.4157629601205417
Validation loss: 2.6461505042526334

Epoch: 5| Step: 5
Training loss: 2.9936403576995616
Validation loss: 2.65107498391379

Epoch: 5| Step: 6
Training loss: 2.8530717591982797
Validation loss: 2.6460614164637435

Epoch: 5| Step: 7
Training loss: 2.864441432328174
Validation loss: 2.6604233214181363

Epoch: 5| Step: 8
Training loss: 2.946843970935361
Validation loss: 2.65925041184427

Epoch: 5| Step: 9
Training loss: 3.157438753067131
Validation loss: 2.667008821843008

Epoch: 5| Step: 10
Training loss: 2.808514207925932
Validation loss: 2.6576950958345966

Epoch: 195| Step: 0
Training loss: 2.986463844303989
Validation loss: 2.6543644862199276

Epoch: 5| Step: 1
Training loss: 3.455327639026085
Validation loss: 2.660301738537857

Epoch: 5| Step: 2
Training loss: 3.059426770342107
Validation loss: 2.6627842860121445

Epoch: 5| Step: 3
Training loss: 3.2963803177823534
Validation loss: 2.656749404779091

Epoch: 5| Step: 4
Training loss: 2.234239374059307
Validation loss: 2.651081391375829

Epoch: 5| Step: 5
Training loss: 2.9444434707767946
Validation loss: 2.655827061413847

Epoch: 5| Step: 6
Training loss: 2.992131882591378
Validation loss: 2.6657311685434784

Epoch: 5| Step: 7
Training loss: 2.6731196844990404
Validation loss: 2.6576239046958663

Epoch: 5| Step: 8
Training loss: 2.756589018371225
Validation loss: 2.6735524815739735

Epoch: 5| Step: 9
Training loss: 3.3694692434845113
Validation loss: 2.6656023915294322

Epoch: 5| Step: 10
Training loss: 2.64083373920714
Validation loss: 2.6552305355938097

Epoch: 196| Step: 0
Training loss: 2.7200875335521
Validation loss: 2.667376791579932

Epoch: 5| Step: 1
Training loss: 3.037144700608465
Validation loss: 2.6636589441586396

Epoch: 5| Step: 2
Training loss: 2.893981963844223
Validation loss: 2.6694470633680876

Epoch: 5| Step: 3
Training loss: 3.1013038969449696
Validation loss: 2.6598920846529706

Epoch: 5| Step: 4
Training loss: 2.57445454422026
Validation loss: 2.6582591787863348

Epoch: 5| Step: 5
Training loss: 2.8143171585987514
Validation loss: 2.6438043236633106

Epoch: 5| Step: 6
Training loss: 2.897515739022955
Validation loss: 2.6484740730229004

Epoch: 5| Step: 7
Training loss: 3.7865685504192217
Validation loss: 2.6513328638104086

Epoch: 5| Step: 8
Training loss: 2.800408885256148
Validation loss: 2.6649071101510273

Epoch: 5| Step: 9
Training loss: 2.8904415587908288
Validation loss: 2.670491950893251

Epoch: 5| Step: 10
Training loss: 2.979388800033513
Validation loss: 2.676309412336677

Epoch: 197| Step: 0
Training loss: 3.052806538554453
Validation loss: 2.6670634092508054

Epoch: 5| Step: 1
Training loss: 3.0537911975781453
Validation loss: 2.6701630425371636

Epoch: 5| Step: 2
Training loss: 2.7705425788706894
Validation loss: 2.6569329751222885

Epoch: 5| Step: 3
Training loss: 2.901495870011089
Validation loss: 2.6522464159538557

Epoch: 5| Step: 4
Training loss: 2.9203888892831444
Validation loss: 2.6539563481963677

Epoch: 5| Step: 5
Training loss: 3.0438002501927963
Validation loss: 2.6446277861742007

Epoch: 5| Step: 6
Training loss: 2.6359961755866643
Validation loss: 2.6535208882382966

Epoch: 5| Step: 7
Training loss: 3.1638569329441353
Validation loss: 2.651817483055714

Epoch: 5| Step: 8
Training loss: 3.086460194805475
Validation loss: 2.6540660037438717

Epoch: 5| Step: 9
Training loss: 3.2040124175632365
Validation loss: 2.6617581291936916

Epoch: 5| Step: 10
Training loss: 2.7616638437125083
Validation loss: 2.64661816994119

Epoch: 198| Step: 0
Training loss: 3.206100644802732
Validation loss: 2.654236740779321

Epoch: 5| Step: 1
Training loss: 2.782767406957172
Validation loss: 2.647673103772864

Epoch: 5| Step: 2
Training loss: 3.05364956990824
Validation loss: 2.650735344984694

Epoch: 5| Step: 3
Training loss: 2.708421754616313
Validation loss: 2.6547490366474036

Epoch: 5| Step: 4
Training loss: 2.6943741643944605
Validation loss: 2.6638554145029767

Epoch: 5| Step: 5
Training loss: 2.769619400924351
Validation loss: 2.6492231547201457

Epoch: 5| Step: 6
Training loss: 2.667845336383105
Validation loss: 2.6592560891071257

Epoch: 5| Step: 7
Training loss: 2.8680325543885004
Validation loss: 2.663802983535603

Epoch: 5| Step: 8
Training loss: 3.2147117392967695
Validation loss: 2.668389051262156

Epoch: 5| Step: 9
Training loss: 3.3966230788599066
Validation loss: 2.6815109246061626

Epoch: 5| Step: 10
Training loss: 3.2371307280278003
Validation loss: 2.658967471363339

Epoch: 199| Step: 0
Training loss: 3.2828834464292753
Validation loss: 2.642786682779071

Epoch: 5| Step: 1
Training loss: 2.6585793547754837
Validation loss: 2.644653468716582

Epoch: 5| Step: 2
Training loss: 3.469181343271764
Validation loss: 2.642960683047373

Epoch: 5| Step: 3
Training loss: 3.0021929673015757
Validation loss: 2.640212239680081

Epoch: 5| Step: 4
Training loss: 2.5886300351405542
Validation loss: 2.636887084011422

Epoch: 5| Step: 5
Training loss: 3.0244886360175687
Validation loss: 2.6345870851469435

Epoch: 5| Step: 6
Training loss: 2.8025236575568404
Validation loss: 2.6324927008386183

Epoch: 5| Step: 7
Training loss: 2.761081476348872
Validation loss: 2.6334917914380975

Epoch: 5| Step: 8
Training loss: 2.8508261369980303
Validation loss: 2.6356456244845483

Epoch: 5| Step: 9
Training loss: 2.9995638212373112
Validation loss: 2.6444174802550453

Epoch: 5| Step: 10
Training loss: 3.1435569628078905
Validation loss: 2.6412526609381564

Epoch: 200| Step: 0
Training loss: 3.2412131442539187
Validation loss: 2.6374443321649914

Epoch: 5| Step: 1
Training loss: 2.715811006872317
Validation loss: 2.6314781899665864

Epoch: 5| Step: 2
Training loss: 2.3891664930205407
Validation loss: 2.6331885104532433

Epoch: 5| Step: 3
Training loss: 3.233089910435143
Validation loss: 2.631729951634927

Epoch: 5| Step: 4
Training loss: 3.0535137136003674
Validation loss: 2.634177123682633

Epoch: 5| Step: 5
Training loss: 3.228996485665997
Validation loss: 2.637730709751919

Epoch: 5| Step: 6
Training loss: 2.6153235331259426
Validation loss: 2.63613913864745

Epoch: 5| Step: 7
Training loss: 3.1096381454683684
Validation loss: 2.6350993728603007

Epoch: 5| Step: 8
Training loss: 2.649876926371214
Validation loss: 2.634099886633755

Epoch: 5| Step: 9
Training loss: 3.246072890746006
Validation loss: 2.6329808208596974

Epoch: 5| Step: 10
Training loss: 2.9857703337294397
Validation loss: 2.6385729056701517

Epoch: 201| Step: 0
Training loss: 2.963801063667249
Validation loss: 2.63593333151156

Epoch: 5| Step: 1
Training loss: 3.0336105750965943
Validation loss: 2.642257734186941

Epoch: 5| Step: 2
Training loss: 2.746966249167645
Validation loss: 2.63909307203376

Epoch: 5| Step: 3
Training loss: 2.8896499226402907
Validation loss: 2.633576206989617

Epoch: 5| Step: 4
Training loss: 2.5524117602303527
Validation loss: 2.652495660333624

Epoch: 5| Step: 5
Training loss: 3.2397341350688293
Validation loss: 2.6427123165726703

Epoch: 5| Step: 6
Training loss: 2.597954616764
Validation loss: 2.6567436594375016

Epoch: 5| Step: 7
Training loss: 3.160128636940933
Validation loss: 2.65768382530144

Epoch: 5| Step: 8
Training loss: 3.1461170060212593
Validation loss: 2.6563801163540126

Epoch: 5| Step: 9
Training loss: 2.9969934656875754
Validation loss: 2.6590138850876155

Epoch: 5| Step: 10
Training loss: 3.2152093468550387
Validation loss: 2.6619271285584

Epoch: 202| Step: 0
Training loss: 3.280525926898866
Validation loss: 2.642351306958559

Epoch: 5| Step: 1
Training loss: 2.576767812752993
Validation loss: 2.639771179460891

Epoch: 5| Step: 2
Training loss: 3.5881242587752076
Validation loss: 2.632999926040277

Epoch: 5| Step: 3
Training loss: 3.050819699561644
Validation loss: 2.636529734045175

Epoch: 5| Step: 4
Training loss: 2.933562053808878
Validation loss: 2.62773426861962

Epoch: 5| Step: 5
Training loss: 2.6729332685264713
Validation loss: 2.628098831260101

Epoch: 5| Step: 6
Training loss: 2.936389956851564
Validation loss: 2.6286196220027698

Epoch: 5| Step: 7
Training loss: 2.9788820535360903
Validation loss: 2.6351304727943057

Epoch: 5| Step: 8
Training loss: 3.1594231395279997
Validation loss: 2.6291226692263305

Epoch: 5| Step: 9
Training loss: 2.6116163484180563
Validation loss: 2.624694730291601

Epoch: 5| Step: 10
Training loss: 2.597314981400959
Validation loss: 2.6281467587601335

Epoch: 203| Step: 0
Training loss: 2.6873043787532076
Validation loss: 2.641609865975859

Epoch: 5| Step: 1
Training loss: 3.092989278957904
Validation loss: 2.6762350053502186

Epoch: 5| Step: 2
Training loss: 3.6428607411727443
Validation loss: 2.7428747713006962

Epoch: 5| Step: 3
Training loss: 2.542840207274666
Validation loss: 2.7107304801976055

Epoch: 5| Step: 4
Training loss: 2.9414983281570604
Validation loss: 2.691498253136537

Epoch: 5| Step: 5
Training loss: 2.4721240394421837
Validation loss: 2.662113785586768

Epoch: 5| Step: 6
Training loss: 2.84136628234796
Validation loss: 2.6399237559686064

Epoch: 5| Step: 7
Training loss: 3.0259675866588944
Validation loss: 2.6389313681622686

Epoch: 5| Step: 8
Training loss: 3.280284630590832
Validation loss: 2.6359528937955465

Epoch: 5| Step: 9
Training loss: 2.9987971755559046
Validation loss: 2.6345233560016257

Epoch: 5| Step: 10
Training loss: 2.9649582590699897
Validation loss: 2.6292611444694436

Epoch: 204| Step: 0
Training loss: 3.5198416281965654
Validation loss: 2.6247704303477906

Epoch: 5| Step: 1
Training loss: 2.7252692623271297
Validation loss: 2.6264582644723875

Epoch: 5| Step: 2
Training loss: 3.1045003280700914
Validation loss: 2.625436290496009

Epoch: 5| Step: 3
Training loss: 3.1553795246789544
Validation loss: 2.6311515047055205

Epoch: 5| Step: 4
Training loss: 2.765540601229192
Validation loss: 2.626495445153766

Epoch: 5| Step: 5
Training loss: 2.42984086806822
Validation loss: 2.625367878627222

Epoch: 5| Step: 6
Training loss: 2.623050328960403
Validation loss: 2.6228056357912837

Epoch: 5| Step: 7
Training loss: 2.685519353552162
Validation loss: 2.621980189960003

Epoch: 5| Step: 8
Training loss: 3.100007789355921
Validation loss: 2.6351119531668603

Epoch: 5| Step: 9
Training loss: 3.048981706073312
Validation loss: 2.6321715421278213

Epoch: 5| Step: 10
Training loss: 3.3810840446092767
Validation loss: 2.6584646008626667

Epoch: 205| Step: 0
Training loss: 2.588821784865688
Validation loss: 2.666102762806722

Epoch: 5| Step: 1
Training loss: 3.034508595535995
Validation loss: 2.6795972315418015

Epoch: 5| Step: 2
Training loss: 2.796189378636349
Validation loss: 2.674303506612047

Epoch: 5| Step: 3
Training loss: 2.7416238667433537
Validation loss: 2.6567786832482643

Epoch: 5| Step: 4
Training loss: 2.7368834406515017
Validation loss: 2.6469423283881914

Epoch: 5| Step: 5
Training loss: 3.11620741807816
Validation loss: 2.643458507818099

Epoch: 5| Step: 6
Training loss: 2.9878570853989244
Validation loss: 2.6496156005846223

Epoch: 5| Step: 7
Training loss: 3.4542467875711775
Validation loss: 2.634041736184638

Epoch: 5| Step: 8
Training loss: 2.9162236195077034
Validation loss: 2.6319958935259953

Epoch: 5| Step: 9
Training loss: 3.3181067466557113
Validation loss: 2.6299392788385463

Epoch: 5| Step: 10
Training loss: 2.819140584405743
Validation loss: 2.6270439171600453

Epoch: 206| Step: 0
Training loss: 3.157093048812446
Validation loss: 2.6211588932628325

Epoch: 5| Step: 1
Training loss: 2.7175692921273282
Validation loss: 2.6261330682247537

Epoch: 5| Step: 2
Training loss: 3.253551010395579
Validation loss: 2.619412223798905

Epoch: 5| Step: 3
Training loss: 2.9313086335066467
Validation loss: 2.6186689684559736

Epoch: 5| Step: 4
Training loss: 2.9028344541752924
Validation loss: 2.6228497982082213

Epoch: 5| Step: 5
Training loss: 2.6138794902759113
Validation loss: 2.617918560082511

Epoch: 5| Step: 6
Training loss: 2.813133761738301
Validation loss: 2.628438066350833

Epoch: 5| Step: 7
Training loss: 3.0018973708326886
Validation loss: 2.619286592802685

Epoch: 5| Step: 8
Training loss: 3.498727022009024
Validation loss: 2.632463954716198

Epoch: 5| Step: 9
Training loss: 2.8635861597435657
Validation loss: 2.6294842480658303

Epoch: 5| Step: 10
Training loss: 2.6153314642230585
Validation loss: 2.6289815684239004

Epoch: 207| Step: 0
Training loss: 2.811404375084043
Validation loss: 2.6517371353687205

Epoch: 5| Step: 1
Training loss: 2.7821297272218986
Validation loss: 2.6564255214272796

Epoch: 5| Step: 2
Training loss: 3.1531796771054514
Validation loss: 2.651006254544747

Epoch: 5| Step: 3
Training loss: 2.950566550986735
Validation loss: 2.654131024491391

Epoch: 5| Step: 4
Training loss: 3.293195795850087
Validation loss: 2.6354137983058883

Epoch: 5| Step: 5
Training loss: 3.2790527252863013
Validation loss: 2.6383925907274746

Epoch: 5| Step: 6
Training loss: 3.168205205369065
Validation loss: 2.649502366532543

Epoch: 5| Step: 7
Training loss: 2.5320053857260945
Validation loss: 2.6444144448933837

Epoch: 5| Step: 8
Training loss: 3.1685676055722
Validation loss: 2.6461754221575626

Epoch: 5| Step: 9
Training loss: 2.6890841406173633
Validation loss: 2.6484095038678084

Epoch: 5| Step: 10
Training loss: 2.501736038164474
Validation loss: 2.6476816951455753

Epoch: 208| Step: 0
Training loss: 2.871274607664622
Validation loss: 2.642371438778428

Epoch: 5| Step: 1
Training loss: 2.496755592823497
Validation loss: 2.6493534749035

Epoch: 5| Step: 2
Training loss: 2.639893650600477
Validation loss: 2.6495941179424727

Epoch: 5| Step: 3
Training loss: 3.3108818852432997
Validation loss: 2.6454258243932305

Epoch: 5| Step: 4
Training loss: 3.0864697733699367
Validation loss: 2.647372536323732

Epoch: 5| Step: 5
Training loss: 2.9217987866585267
Validation loss: 2.648113173157994

Epoch: 5| Step: 6
Training loss: 3.047775370272816
Validation loss: 2.645894088092796

Epoch: 5| Step: 7
Training loss: 3.295979310350387
Validation loss: 2.627429991793697

Epoch: 5| Step: 8
Training loss: 3.0294443631991723
Validation loss: 2.629420397193246

Epoch: 5| Step: 9
Training loss: 2.793895818331271
Validation loss: 2.6244241831996558

Epoch: 5| Step: 10
Training loss: 2.8596237991569935
Validation loss: 2.625641439249283

Epoch: 209| Step: 0
Training loss: 2.940763892239134
Validation loss: 2.62697000311706

Epoch: 5| Step: 1
Training loss: 2.8928262113501924
Validation loss: 2.63215983700102

Epoch: 5| Step: 2
Training loss: 2.9348465318214236
Validation loss: 2.6456356141041497

Epoch: 5| Step: 3
Training loss: 2.8914823343264056
Validation loss: 2.6520133526072946

Epoch: 5| Step: 4
Training loss: 2.881228293380561
Validation loss: 2.6657915041210254

Epoch: 5| Step: 5
Training loss: 3.0521759088600198
Validation loss: 2.6740833524009995

Epoch: 5| Step: 6
Training loss: 2.771663990612042
Validation loss: 2.660925293788577

Epoch: 5| Step: 7
Training loss: 2.8181739370733685
Validation loss: 2.6462466945958196

Epoch: 5| Step: 8
Training loss: 2.799582593323222
Validation loss: 2.635932830635822

Epoch: 5| Step: 9
Training loss: 3.6492985560895193
Validation loss: 2.6320810544360276

Epoch: 5| Step: 10
Training loss: 2.760519196147675
Validation loss: 2.6185456250448453

Epoch: 210| Step: 0
Training loss: 3.6222031425748478
Validation loss: 2.6207266995992007

Epoch: 5| Step: 1
Training loss: 2.564694558114498
Validation loss: 2.615588681042403

Epoch: 5| Step: 2
Training loss: 2.507553990430335
Validation loss: 2.6087735422215625

Epoch: 5| Step: 3
Training loss: 3.6132073472172026
Validation loss: 2.6119002880757995

Epoch: 5| Step: 4
Training loss: 2.6352518706130965
Validation loss: 2.6152927250308515

Epoch: 5| Step: 5
Training loss: 2.7256079809212514
Validation loss: 2.6167082728452415

Epoch: 5| Step: 6
Training loss: 3.34066187782023
Validation loss: 2.6126978962983087

Epoch: 5| Step: 7
Training loss: 3.1453265019733823
Validation loss: 2.616739749090345

Epoch: 5| Step: 8
Training loss: 2.872500784585844
Validation loss: 2.6085678501792535

Epoch: 5| Step: 9
Training loss: 2.399695051210914
Validation loss: 2.618482112493971

Epoch: 5| Step: 10
Training loss: 2.6521234210136804
Validation loss: 2.6201011419308506

Epoch: 211| Step: 0
Training loss: 2.9533452350500067
Validation loss: 2.63495117055706

Epoch: 5| Step: 1
Training loss: 3.577298931066834
Validation loss: 2.6190771797348713

Epoch: 5| Step: 2
Training loss: 2.5289547722008883
Validation loss: 2.632684391410728

Epoch: 5| Step: 3
Training loss: 2.545235322516341
Validation loss: 2.626612034977488

Epoch: 5| Step: 4
Training loss: 2.784847204923988
Validation loss: 2.618218167231374

Epoch: 5| Step: 5
Training loss: 2.358513883367471
Validation loss: 2.6321002182560824

Epoch: 5| Step: 6
Training loss: 2.8208212776621413
Validation loss: 2.622386332397736

Epoch: 5| Step: 7
Training loss: 3.3839915557647755
Validation loss: 2.625587305875548

Epoch: 5| Step: 8
Training loss: 2.972429424760269
Validation loss: 2.6297909358636096

Epoch: 5| Step: 9
Training loss: 2.987389125921304
Validation loss: 2.6341099986933663

Epoch: 5| Step: 10
Training loss: 3.3360995894279077
Validation loss: 2.63132549981665

Epoch: 212| Step: 0
Training loss: 2.786442912882029
Validation loss: 2.6221660946740433

Epoch: 5| Step: 1
Training loss: 2.913641114231728
Validation loss: 2.6152792455786704

Epoch: 5| Step: 2
Training loss: 2.9019275638996582
Validation loss: 2.6143999285845245

Epoch: 5| Step: 3
Training loss: 2.9993701909498265
Validation loss: 2.63621941909857

Epoch: 5| Step: 4
Training loss: 3.559863403142829
Validation loss: 2.630706196762079

Epoch: 5| Step: 5
Training loss: 2.725785196552388
Validation loss: 2.6203297930219653

Epoch: 5| Step: 6
Training loss: 2.6804278271363353
Validation loss: 2.6140266678586643

Epoch: 5| Step: 7
Training loss: 2.8143150406900777
Validation loss: 2.627921104718181

Epoch: 5| Step: 8
Training loss: 2.9977055358414137
Validation loss: 2.6261908139394334

Epoch: 5| Step: 9
Training loss: 3.1277374484810676
Validation loss: 2.6292320431981566

Epoch: 5| Step: 10
Training loss: 2.7676432513729288
Validation loss: 2.6168008547187607

Epoch: 213| Step: 0
Training loss: 2.8676750745598696
Validation loss: 2.610969349644848

Epoch: 5| Step: 1
Training loss: 3.0884903404426916
Validation loss: 2.6080712017223475

Epoch: 5| Step: 2
Training loss: 2.690400886727651
Validation loss: 2.60423748945509

Epoch: 5| Step: 3
Training loss: 3.133249761265017
Validation loss: 2.6054373058469444

Epoch: 5| Step: 4
Training loss: 2.705000827387262
Validation loss: 2.6079127391466606

Epoch: 5| Step: 5
Training loss: 2.312687324978553
Validation loss: 2.605514938969122

Epoch: 5| Step: 6
Training loss: 2.093268951268267
Validation loss: 2.60901411416364

Epoch: 5| Step: 7
Training loss: 3.4820123026201593
Validation loss: 2.622468449376124

Epoch: 5| Step: 8
Training loss: 3.5738721335517223
Validation loss: 2.6164031732840374

Epoch: 5| Step: 9
Training loss: 3.2328921249709555
Validation loss: 2.6319233546300107

Epoch: 5| Step: 10
Training loss: 2.897367295261742
Validation loss: 2.64549171839777

Epoch: 214| Step: 0
Training loss: 2.9040100325418994
Validation loss: 2.639710172416181

Epoch: 5| Step: 1
Training loss: 3.03388092072878
Validation loss: 2.6260026432047763

Epoch: 5| Step: 2
Training loss: 2.737549078514464
Validation loss: 2.610297110074522

Epoch: 5| Step: 3
Training loss: 2.681740911043579
Validation loss: 2.6121090418584245

Epoch: 5| Step: 4
Training loss: 2.998705266672133
Validation loss: 2.6070214422217

Epoch: 5| Step: 5
Training loss: 3.021157521358306
Validation loss: 2.6045683782697275

Epoch: 5| Step: 6
Training loss: 2.8381754134353994
Validation loss: 2.607841252666544

Epoch: 5| Step: 7
Training loss: 2.900277841346728
Validation loss: 2.605512397480339

Epoch: 5| Step: 8
Training loss: 3.167323563019169
Validation loss: 2.602003721399619

Epoch: 5| Step: 9
Training loss: 2.8737475113362225
Validation loss: 2.6112036415530633

Epoch: 5| Step: 10
Training loss: 3.2242012158400737
Validation loss: 2.611454995875631

Epoch: 215| Step: 0
Training loss: 3.035263550578791
Validation loss: 2.617956187158228

Epoch: 5| Step: 1
Training loss: 2.750389331654246
Validation loss: 2.6434437104841586

Epoch: 5| Step: 2
Training loss: 3.0033763323834224
Validation loss: 2.6674119900535125

Epoch: 5| Step: 3
Training loss: 2.4606993544867253
Validation loss: 2.6767037857864078

Epoch: 5| Step: 4
Training loss: 3.2265155040652806
Validation loss: 2.6739494763423424

Epoch: 5| Step: 5
Training loss: 2.671090172505556
Validation loss: 2.6421416901882258

Epoch: 5| Step: 6
Training loss: 3.0894566810733104
Validation loss: 2.6192924535828657

Epoch: 5| Step: 7
Training loss: 3.136759186480487
Validation loss: 2.6210891999656534

Epoch: 5| Step: 8
Training loss: 3.1101818475577807
Validation loss: 2.616757808963671

Epoch: 5| Step: 9
Training loss: 2.7510024757776246
Validation loss: 2.6217982664521036

Epoch: 5| Step: 10
Training loss: 3.1079630497389252
Validation loss: 2.616050640555645

Epoch: 216| Step: 0
Training loss: 2.5792100877039217
Validation loss: 2.61186426003805

Epoch: 5| Step: 1
Training loss: 2.768748787563222
Validation loss: 2.6094971362272172

Epoch: 5| Step: 2
Training loss: 2.2224144561061228
Validation loss: 2.608617588051943

Epoch: 5| Step: 3
Training loss: 2.8635765017132946
Validation loss: 2.616078007922481

Epoch: 5| Step: 4
Training loss: 2.656449074858559
Validation loss: 2.610916286227261

Epoch: 5| Step: 5
Training loss: 3.351211636191005
Validation loss: 2.6114908234074

Epoch: 5| Step: 6
Training loss: 3.044020347416929
Validation loss: 2.618402680475517

Epoch: 5| Step: 7
Training loss: 3.386638354410889
Validation loss: 2.613954075566584

Epoch: 5| Step: 8
Training loss: 2.631731937880241
Validation loss: 2.6169457088980903

Epoch: 5| Step: 9
Training loss: 3.363112247133064
Validation loss: 2.6504091839249346

Epoch: 5| Step: 10
Training loss: 3.3266707274183465
Validation loss: 2.6638747029302445

Epoch: 217| Step: 0
Training loss: 2.6509159160734987
Validation loss: 2.684877722222865

Epoch: 5| Step: 1
Training loss: 3.022362333054332
Validation loss: 2.68130376591553

Epoch: 5| Step: 2
Training loss: 3.2789368241515944
Validation loss: 2.7153317900234377

Epoch: 5| Step: 3
Training loss: 2.8069362285614785
Validation loss: 2.7215874273406553

Epoch: 5| Step: 4
Training loss: 2.3452960192300165
Validation loss: 2.6824113447373525

Epoch: 5| Step: 5
Training loss: 2.90484552389627
Validation loss: 2.647904764789613

Epoch: 5| Step: 6
Training loss: 3.017297310710077
Validation loss: 2.6274277388511704

Epoch: 5| Step: 7
Training loss: 3.2099282565076543
Validation loss: 2.616331006539098

Epoch: 5| Step: 8
Training loss: 3.194365195429292
Validation loss: 2.6058120674768217

Epoch: 5| Step: 9
Training loss: 2.9674411498535633
Validation loss: 2.600540107557748

Epoch: 5| Step: 10
Training loss: 2.7985184598678186
Validation loss: 2.597532859238388

Epoch: 218| Step: 0
Training loss: 3.0606976869352103
Validation loss: 2.6008293569614547

Epoch: 5| Step: 1
Training loss: 2.8284281362703734
Validation loss: 2.5997879946832336

Epoch: 5| Step: 2
Training loss: 2.8809391540860245
Validation loss: 2.596013297031344

Epoch: 5| Step: 3
Training loss: 3.5080767491643257
Validation loss: 2.6030169745373

Epoch: 5| Step: 4
Training loss: 2.7638200807765703
Validation loss: 2.6060833977830833

Epoch: 5| Step: 5
Training loss: 2.5310817709697666
Validation loss: 2.625769890480569

Epoch: 5| Step: 6
Training loss: 3.2201175192007168
Validation loss: 2.6307396620814703

Epoch: 5| Step: 7
Training loss: 3.046606276961913
Validation loss: 2.65588986816496

Epoch: 5| Step: 8
Training loss: 2.7465410153187455
Validation loss: 2.660654975534383

Epoch: 5| Step: 9
Training loss: 2.3633033436144437
Validation loss: 2.6885763732920616

Epoch: 5| Step: 10
Training loss: 3.242388689164378
Validation loss: 2.700459513003303

Epoch: 219| Step: 0
Training loss: 2.516464093457502
Validation loss: 2.674069978518595

Epoch: 5| Step: 1
Training loss: 2.412616877121244
Validation loss: 2.6397581212089065

Epoch: 5| Step: 2
Training loss: 2.9419815291208047
Validation loss: 2.614420615898624

Epoch: 5| Step: 3
Training loss: 3.377741230242697
Validation loss: 2.6043106183699383

Epoch: 5| Step: 4
Training loss: 2.7148903822152874
Validation loss: 2.5941710685678747

Epoch: 5| Step: 5
Training loss: 3.263920973671925
Validation loss: 2.593305584041804

Epoch: 5| Step: 6
Training loss: 3.0233658971858834
Validation loss: 2.5979459014031057

Epoch: 5| Step: 7
Training loss: 3.290216601352178
Validation loss: 2.5964889001822384

Epoch: 5| Step: 8
Training loss: 2.587386909261735
Validation loss: 2.604594621175404

Epoch: 5| Step: 9
Training loss: 3.322552955038954
Validation loss: 2.6039084311805363

Epoch: 5| Step: 10
Training loss: 2.6992098287829687
Validation loss: 2.6039375841019687

Epoch: 220| Step: 0
Training loss: 3.1125389372446826
Validation loss: 2.6159418365898746

Epoch: 5| Step: 1
Training loss: 3.0022109149946132
Validation loss: 2.618641926761084

Epoch: 5| Step: 2
Training loss: 3.1981072550257656
Validation loss: 2.6704217863573736

Epoch: 5| Step: 3
Training loss: 3.3286956154667022
Validation loss: 2.7227393854853172

Epoch: 5| Step: 4
Training loss: 2.9483308175440857
Validation loss: 2.6670095514255125

Epoch: 5| Step: 5
Training loss: 3.018398610389889
Validation loss: 2.639183476672783

Epoch: 5| Step: 6
Training loss: 2.3369565036106397
Validation loss: 2.6130151134747557

Epoch: 5| Step: 7
Training loss: 2.9870072984021996
Validation loss: 2.6057234713366673

Epoch: 5| Step: 8
Training loss: 2.8991504213982333
Validation loss: 2.5888684233388894

Epoch: 5| Step: 9
Training loss: 2.5973833672164615
Validation loss: 2.5875280470574165

Epoch: 5| Step: 10
Training loss: 2.755169777459188
Validation loss: 2.5878759765210417

Epoch: 221| Step: 0
Training loss: 2.8416819336183683
Validation loss: 2.5903891801065537

Epoch: 5| Step: 1
Training loss: 3.1425851047739455
Validation loss: 2.590831843225501

Epoch: 5| Step: 2
Training loss: 2.7951414393906315
Validation loss: 2.591586436589544

Epoch: 5| Step: 3
Training loss: 3.2460401326329245
Validation loss: 2.596080238842079

Epoch: 5| Step: 4
Training loss: 2.7867091746335526
Validation loss: 2.5897399468760223

Epoch: 5| Step: 5
Training loss: 3.415709214075406
Validation loss: 2.5960950543281838

Epoch: 5| Step: 6
Training loss: 2.8885558274631946
Validation loss: 2.599097148536857

Epoch: 5| Step: 7
Training loss: 2.98707817643002
Validation loss: 2.6171119783121277

Epoch: 5| Step: 8
Training loss: 2.2954966243385884
Validation loss: 2.6216883437537835

Epoch: 5| Step: 9
Training loss: 2.884092796134318
Validation loss: 2.645143132243746

Epoch: 5| Step: 10
Training loss: 2.805407333445372
Validation loss: 2.6464936841587505

Epoch: 222| Step: 0
Training loss: 2.8824128491608922
Validation loss: 2.639122515297824

Epoch: 5| Step: 1
Training loss: 3.1788222426749346
Validation loss: 2.6471211263781766

Epoch: 5| Step: 2
Training loss: 2.5034181116058325
Validation loss: 2.6203157984424768

Epoch: 5| Step: 3
Training loss: 3.007092991762709
Validation loss: 2.588910729669706

Epoch: 5| Step: 4
Training loss: 3.0625822095152095
Validation loss: 2.5924789283384913

Epoch: 5| Step: 5
Training loss: 3.823641896211499
Validation loss: 2.596196447732891

Epoch: 5| Step: 6
Training loss: 2.4091971048468497
Validation loss: 2.6092123818870534

Epoch: 5| Step: 7
Training loss: 2.628340094764671
Validation loss: 2.6150849831849876

Epoch: 5| Step: 8
Training loss: 2.860671119643211
Validation loss: 2.6106784152293323

Epoch: 5| Step: 9
Training loss: 2.7479198564728295
Validation loss: 2.614636162344799

Epoch: 5| Step: 10
Training loss: 3.188643157018404
Validation loss: 2.60048803453605

Epoch: 223| Step: 0
Training loss: 3.8092895498228603
Validation loss: 2.5974784292440893

Epoch: 5| Step: 1
Training loss: 2.94784056943844
Validation loss: 2.593690246099322

Epoch: 5| Step: 2
Training loss: 3.057210597317846
Validation loss: 2.5861846812631546

Epoch: 5| Step: 3
Training loss: 2.9139744640480334
Validation loss: 2.591333019519788

Epoch: 5| Step: 4
Training loss: 2.628069581525915
Validation loss: 2.602472130198104

Epoch: 5| Step: 5
Training loss: 2.945385514626727
Validation loss: 2.620727312941481

Epoch: 5| Step: 6
Training loss: 2.812376061993614
Validation loss: 2.6464101504818927

Epoch: 5| Step: 7
Training loss: 2.99020678746051
Validation loss: 2.6855672662730856

Epoch: 5| Step: 8
Training loss: 3.0618895876043095
Validation loss: 2.682369251047102

Epoch: 5| Step: 9
Training loss: 2.2672783442357662
Validation loss: 2.6607832558872073

Epoch: 5| Step: 10
Training loss: 2.862122596615428
Validation loss: 2.641044104327764

Epoch: 224| Step: 0
Training loss: 2.542008038301762
Validation loss: 2.6254528307457545

Epoch: 5| Step: 1
Training loss: 2.9570123830619215
Validation loss: 2.5978218030176126

Epoch: 5| Step: 2
Training loss: 3.1808698925475447
Validation loss: 2.5997997055333792

Epoch: 5| Step: 3
Training loss: 2.836650664138333
Validation loss: 2.5916941590623734

Epoch: 5| Step: 4
Training loss: 2.3853562082239006
Validation loss: 2.5914369111794904

Epoch: 5| Step: 5
Training loss: 3.308606720846033
Validation loss: 2.5917464404224266

Epoch: 5| Step: 6
Training loss: 3.0007877904954268
Validation loss: 2.5932114327762465

Epoch: 5| Step: 7
Training loss: 3.3396532863271866
Validation loss: 2.588611454193267

Epoch: 5| Step: 8
Training loss: 3.0159851807855045
Validation loss: 2.5860122745693603

Epoch: 5| Step: 9
Training loss: 2.934561863028601
Validation loss: 2.596620471959471

Epoch: 5| Step: 10
Training loss: 2.4971713275789122
Validation loss: 2.594404401681916

Epoch: 225| Step: 0
Training loss: 2.78335731480788
Validation loss: 2.592275481827704

Epoch: 5| Step: 1
Training loss: 3.5260771275835654
Validation loss: 2.602083811654034

Epoch: 5| Step: 2
Training loss: 2.632469086931952
Validation loss: 2.59953507734445

Epoch: 5| Step: 3
Training loss: 2.82238498950111
Validation loss: 2.6036277052484085

Epoch: 5| Step: 4
Training loss: 2.560927955558452
Validation loss: 2.603840713939173

Epoch: 5| Step: 5
Training loss: 3.2141668782140576
Validation loss: 2.616804150377141

Epoch: 5| Step: 6
Training loss: 3.329411647473914
Validation loss: 2.6142760287686104

Epoch: 5| Step: 7
Training loss: 3.176381935282894
Validation loss: 2.6222265029004066

Epoch: 5| Step: 8
Training loss: 2.6276147626065214
Validation loss: 2.6158924447638188

Epoch: 5| Step: 9
Training loss: 2.8237116821445127
Validation loss: 2.634675320786499

Epoch: 5| Step: 10
Training loss: 2.370144247019254
Validation loss: 2.6279269462417476

Epoch: 226| Step: 0
Training loss: 2.999262719156244
Validation loss: 2.6280211170676866

Epoch: 5| Step: 1
Training loss: 3.0878566520506228
Validation loss: 2.6145333258884724

Epoch: 5| Step: 2
Training loss: 3.4339167559070245
Validation loss: 2.6144524167968024

Epoch: 5| Step: 3
Training loss: 2.5979908663124416
Validation loss: 2.6123256563746775

Epoch: 5| Step: 4
Training loss: 2.7888496381810053
Validation loss: 2.6049271061893946

Epoch: 5| Step: 5
Training loss: 3.108154824238649
Validation loss: 2.6006732985286547

Epoch: 5| Step: 6
Training loss: 3.0507346722396678
Validation loss: 2.594752879255942

Epoch: 5| Step: 7
Training loss: 3.205223624154009
Validation loss: 2.6024536943793777

Epoch: 5| Step: 8
Training loss: 2.2119308774195305
Validation loss: 2.5888559718390063

Epoch: 5| Step: 9
Training loss: 2.6014154066137407
Validation loss: 2.596248379719761

Epoch: 5| Step: 10
Training loss: 2.8763008491832363
Validation loss: 2.601739285854222

Epoch: 227| Step: 0
Training loss: 3.057022958067195
Validation loss: 2.6002129190299184

Epoch: 5| Step: 1
Training loss: 3.0656542979793464
Validation loss: 2.6043048892511442

Epoch: 5| Step: 2
Training loss: 2.751989858475562
Validation loss: 2.616641992988621

Epoch: 5| Step: 3
Training loss: 2.313366907885666
Validation loss: 2.612132254885873

Epoch: 5| Step: 4
Training loss: 2.9091890302279486
Validation loss: 2.6134388024195125

Epoch: 5| Step: 5
Training loss: 3.4365219111871435
Validation loss: 2.6029369159502584

Epoch: 5| Step: 6
Training loss: 2.971611009619643
Validation loss: 2.606507438440839

Epoch: 5| Step: 7
Training loss: 3.176452640823491
Validation loss: 2.609773565757691

Epoch: 5| Step: 8
Training loss: 2.929903800608947
Validation loss: 2.599437911950249

Epoch: 5| Step: 9
Training loss: 2.445990422764242
Validation loss: 2.5996333524758284

Epoch: 5| Step: 10
Training loss: 2.857768623761904
Validation loss: 2.6171502948357808

Epoch: 228| Step: 0
Training loss: 2.904138926332964
Validation loss: 2.6175083405146853

Epoch: 5| Step: 1
Training loss: 2.823206212208097
Validation loss: 2.611996439259747

Epoch: 5| Step: 2
Training loss: 2.016477064672409
Validation loss: 2.626078003905479

Epoch: 5| Step: 3
Training loss: 2.8529820083601747
Validation loss: 2.642861757920965

Epoch: 5| Step: 4
Training loss: 3.037349895017962
Validation loss: 2.651567425627401

Epoch: 5| Step: 5
Training loss: 2.98873518942909
Validation loss: 2.647221430196852

Epoch: 5| Step: 6
Training loss: 2.573388482410417
Validation loss: 2.6189833950336743

Epoch: 5| Step: 7
Training loss: 3.206123251389532
Validation loss: 2.6158419024135844

Epoch: 5| Step: 8
Training loss: 3.054775227021142
Validation loss: 2.622928733914887

Epoch: 5| Step: 9
Training loss: 3.1455861851362643
Validation loss: 2.6197422029197455

Epoch: 5| Step: 10
Training loss: 3.3379747660273367
Validation loss: 2.602876802680363

Epoch: 229| Step: 0
Training loss: 3.117824556270619
Validation loss: 2.5902324506018815

Epoch: 5| Step: 1
Training loss: 2.8955244453042512
Validation loss: 2.5946349349108515

Epoch: 5| Step: 2
Training loss: 3.3276570309014146
Validation loss: 2.5863937502354046

Epoch: 5| Step: 3
Training loss: 3.1073181403568295
Validation loss: 2.5830736453167615

Epoch: 5| Step: 4
Training loss: 2.7674076348168213
Validation loss: 2.5900232312295355

Epoch: 5| Step: 5
Training loss: 3.0344014254046954
Validation loss: 2.590409494073953

Epoch: 5| Step: 6
Training loss: 2.730892295895429
Validation loss: 2.597008828548716

Epoch: 5| Step: 7
Training loss: 2.4450352910777133
Validation loss: 2.6068958395385446

Epoch: 5| Step: 8
Training loss: 2.711613727405294
Validation loss: 2.611847620974854

Epoch: 5| Step: 9
Training loss: 3.0769874290926094
Validation loss: 2.61346804816048

Epoch: 5| Step: 10
Training loss: 2.7445093307683988
Validation loss: 2.616824238716367

Epoch: 230| Step: 0
Training loss: 2.9666435397957596
Validation loss: 2.6140312586271612

Epoch: 5| Step: 1
Training loss: 3.120794289059903
Validation loss: 2.606962130187904

Epoch: 5| Step: 2
Training loss: 2.9303335876129157
Validation loss: 2.598490278048535

Epoch: 5| Step: 3
Training loss: 3.025738926952745
Validation loss: 2.596920578684722

Epoch: 5| Step: 4
Training loss: 3.6103479964734215
Validation loss: 2.60578869582972

Epoch: 5| Step: 5
Training loss: 2.3782850935957356
Validation loss: 2.596307116949744

Epoch: 5| Step: 6
Training loss: 2.5438728659010126
Validation loss: 2.5870912636951964

Epoch: 5| Step: 7
Training loss: 2.9474500594628137
Validation loss: 2.601672067909031

Epoch: 5| Step: 8
Training loss: 2.8992463086153992
Validation loss: 2.5956140001023713

Epoch: 5| Step: 9
Training loss: 2.7894265500928745
Validation loss: 2.5917952033589415

Epoch: 5| Step: 10
Training loss: 2.5340778896341014
Validation loss: 2.6047668884298076

Epoch: 231| Step: 0
Training loss: 2.309108618625348
Validation loss: 2.6381606201502397

Epoch: 5| Step: 1
Training loss: 3.243251396181839
Validation loss: 2.658264623816044

Epoch: 5| Step: 2
Training loss: 2.9076751168177193
Validation loss: 2.6234739558488758

Epoch: 5| Step: 3
Training loss: 3.06945571398692
Validation loss: 2.6044512623151794

Epoch: 5| Step: 4
Training loss: 3.038280867058908
Validation loss: 2.596185824614442

Epoch: 5| Step: 5
Training loss: 3.1393603155607943
Validation loss: 2.5942241898948653

Epoch: 5| Step: 6
Training loss: 2.3721809722605545
Validation loss: 2.590972787428948

Epoch: 5| Step: 7
Training loss: 2.797412160085817
Validation loss: 2.5884285304132133

Epoch: 5| Step: 8
Training loss: 3.405111560086292
Validation loss: 2.5826937766684583

Epoch: 5| Step: 9
Training loss: 2.5989561112775967
Validation loss: 2.5883512014423844

Epoch: 5| Step: 10
Training loss: 3.0248066170410968
Validation loss: 2.5838377265327703

Epoch: 232| Step: 0
Training loss: 2.799875110157024
Validation loss: 2.589909085370966

Epoch: 5| Step: 1
Training loss: 2.8115745717334644
Validation loss: 2.591123066826518

Epoch: 5| Step: 2
Training loss: 3.5286042420961388
Validation loss: 2.6060026641110694

Epoch: 5| Step: 3
Training loss: 3.0637973450854954
Validation loss: 2.6143360633018986

Epoch: 5| Step: 4
Training loss: 2.668404986126152
Validation loss: 2.6179095380822726

Epoch: 5| Step: 5
Training loss: 2.686238103514503
Validation loss: 2.6201175123437292

Epoch: 5| Step: 6
Training loss: 2.8221911146630565
Validation loss: 2.625799620800552

Epoch: 5| Step: 7
Training loss: 3.1303613067840494
Validation loss: 2.6271028275275716

Epoch: 5| Step: 8
Training loss: 2.7779960885621144
Validation loss: 2.6225875398433

Epoch: 5| Step: 9
Training loss: 2.8154755852246516
Validation loss: 2.6135933202866255

Epoch: 5| Step: 10
Training loss: 2.831355489150881
Validation loss: 2.6038235766098783

Epoch: 233| Step: 0
Training loss: 2.5181324469143074
Validation loss: 2.597378059076893

Epoch: 5| Step: 1
Training loss: 2.65677341465294
Validation loss: 2.5943742725553123

Epoch: 5| Step: 2
Training loss: 2.7178837064687715
Validation loss: 2.5891341447075042

Epoch: 5| Step: 3
Training loss: 3.1219756177967946
Validation loss: 2.5923572818489706

Epoch: 5| Step: 4
Training loss: 2.558902541301905
Validation loss: 2.6004040719614863

Epoch: 5| Step: 5
Training loss: 2.9142946861567087
Validation loss: 2.6001905194786965

Epoch: 5| Step: 6
Training loss: 3.1401682659184442
Validation loss: 2.601555340888949

Epoch: 5| Step: 7
Training loss: 2.897560336494391
Validation loss: 2.61279339213251

Epoch: 5| Step: 8
Training loss: 3.051796718501999
Validation loss: 2.6316572300607333

Epoch: 5| Step: 9
Training loss: 2.987023740977396
Validation loss: 2.64933820828271

Epoch: 5| Step: 10
Training loss: 3.3269338849317447
Validation loss: 2.6569771800970226

Epoch: 234| Step: 0
Training loss: 2.4196334802489106
Validation loss: 2.655198374398917

Epoch: 5| Step: 1
Training loss: 2.7882165988428853
Validation loss: 2.640192298220159

Epoch: 5| Step: 2
Training loss: 3.0249931020106335
Validation loss: 2.627830873576895

Epoch: 5| Step: 3
Training loss: 3.479496024678631
Validation loss: 2.612849695998559

Epoch: 5| Step: 4
Training loss: 2.966568155117546
Validation loss: 2.590575450825784

Epoch: 5| Step: 5
Training loss: 2.6484675672956786
Validation loss: 2.5806597234490702

Epoch: 5| Step: 6
Training loss: 2.669120662775903
Validation loss: 2.5864686513701582

Epoch: 5| Step: 7
Training loss: 2.941916858382599
Validation loss: 2.5828335292094486

Epoch: 5| Step: 8
Training loss: 3.2699217933378617
Validation loss: 2.5808069900691404

Epoch: 5| Step: 9
Training loss: 3.2432847705536547
Validation loss: 2.581310651533852

Epoch: 5| Step: 10
Training loss: 2.333179900256397
Validation loss: 2.5811893502390957

Epoch: 235| Step: 0
Training loss: 3.065769552231168
Validation loss: 2.580033969733421

Epoch: 5| Step: 1
Training loss: 2.9002896789040946
Validation loss: 2.5883495766034597

Epoch: 5| Step: 2
Training loss: 2.3775776377295013
Validation loss: 2.580650561753898

Epoch: 5| Step: 3
Training loss: 2.947379199166059
Validation loss: 2.5983836749740057

Epoch: 5| Step: 4
Training loss: 3.322425798056858
Validation loss: 2.608852905796961

Epoch: 5| Step: 5
Training loss: 2.538534068358556
Validation loss: 2.620432242533928

Epoch: 5| Step: 6
Training loss: 3.08398638502349
Validation loss: 2.6314851975270552

Epoch: 5| Step: 7
Training loss: 2.718839271219807
Validation loss: 2.6516263074446007

Epoch: 5| Step: 8
Training loss: 3.26507081800598
Validation loss: 2.657111062245139

Epoch: 5| Step: 9
Training loss: 2.813308514836597
Validation loss: 2.638921090969227

Epoch: 5| Step: 10
Training loss: 2.88453883142861
Validation loss: 2.6253786805169685

Epoch: 236| Step: 0
Training loss: 2.8724792044130028
Validation loss: 2.6108050653200494

Epoch: 5| Step: 1
Training loss: 2.869038080781112
Validation loss: 2.6095417606306324

Epoch: 5| Step: 2
Training loss: 3.038858205798074
Validation loss: 2.6003942014882657

Epoch: 5| Step: 3
Training loss: 2.6966750971501634
Validation loss: 2.592487100398287

Epoch: 5| Step: 4
Training loss: 3.0229375066023514
Validation loss: 2.6038152540456623

Epoch: 5| Step: 5
Training loss: 2.780816805246185
Validation loss: 2.5948914913180396

Epoch: 5| Step: 6
Training loss: 3.1576729767717975
Validation loss: 2.6049445733281718

Epoch: 5| Step: 7
Training loss: 2.324863068845001
Validation loss: 2.602976040931828

Epoch: 5| Step: 8
Training loss: 2.629274339682759
Validation loss: 2.5957892800435785

Epoch: 5| Step: 9
Training loss: 3.3416767288272142
Validation loss: 2.591835149350465

Epoch: 5| Step: 10
Training loss: 3.091401104347973
Validation loss: 2.5953448300228676

Epoch: 237| Step: 0
Training loss: 2.5006135187741187
Validation loss: 2.5780631278262054

Epoch: 5| Step: 1
Training loss: 3.5993591320961844
Validation loss: 2.5846321457846058

Epoch: 5| Step: 2
Training loss: 2.929217898561563
Validation loss: 2.5823438028083348

Epoch: 5| Step: 3
Training loss: 2.6346916035631627
Validation loss: 2.598563116856889

Epoch: 5| Step: 4
Training loss: 3.3169568866162398
Validation loss: 2.5867433852727797

Epoch: 5| Step: 5
Training loss: 2.815970758849826
Validation loss: 2.596794584188248

Epoch: 5| Step: 6
Training loss: 2.6142653820340076
Validation loss: 2.606126816588433

Epoch: 5| Step: 7
Training loss: 2.5469815284589394
Validation loss: 2.6011059704240633

Epoch: 5| Step: 8
Training loss: 2.6455794585571053
Validation loss: 2.615332500331732

Epoch: 5| Step: 9
Training loss: 3.1041186198840784
Validation loss: 2.6241436697851537

Epoch: 5| Step: 10
Training loss: 2.9955552871841076
Validation loss: 2.6271867311444774

Epoch: 238| Step: 0
Training loss: 2.597800435818656
Validation loss: 2.6216133448336914

Epoch: 5| Step: 1
Training loss: 3.178119994753157
Validation loss: 2.616755482172404

Epoch: 5| Step: 2
Training loss: 2.8445720113355084
Validation loss: 2.594953949193841

Epoch: 5| Step: 3
Training loss: 2.798538736102218
Validation loss: 2.5915436076031257

Epoch: 5| Step: 4
Training loss: 2.8402351204161964
Validation loss: 2.5846451830005917

Epoch: 5| Step: 5
Training loss: 2.8496446823014008
Validation loss: 2.579904478501536

Epoch: 5| Step: 6
Training loss: 3.1986809396090083
Validation loss: 2.576340863404231

Epoch: 5| Step: 7
Training loss: 2.8356933488652873
Validation loss: 2.5792672896679045

Epoch: 5| Step: 8
Training loss: 3.5031066458473936
Validation loss: 2.5769975311826987

Epoch: 5| Step: 9
Training loss: 2.3817108108917737
Validation loss: 2.5724927438318135

Epoch: 5| Step: 10
Training loss: 2.8073055193859475
Validation loss: 2.574152718608873

Epoch: 239| Step: 0
Training loss: 3.3379017677366676
Validation loss: 2.577209033503995

Epoch: 5| Step: 1
Training loss: 2.989100524692388
Validation loss: 2.57656877619755

Epoch: 5| Step: 2
Training loss: 2.920700081811809
Validation loss: 2.584150209657379

Epoch: 5| Step: 3
Training loss: 3.4323863053576216
Validation loss: 2.6010546913099963

Epoch: 5| Step: 4
Training loss: 3.164740897084422
Validation loss: 2.603938556812102

Epoch: 5| Step: 5
Training loss: 2.6452273378222535
Validation loss: 2.6172247653659637

Epoch: 5| Step: 6
Training loss: 2.8624687759495533
Validation loss: 2.614988442637784

Epoch: 5| Step: 7
Training loss: 3.0236365279896913
Validation loss: 2.6403266974648143

Epoch: 5| Step: 8
Training loss: 3.0361783578523376
Validation loss: 2.612503505743098

Epoch: 5| Step: 9
Training loss: 1.8211807341485127
Validation loss: 2.5774034919326603

Epoch: 5| Step: 10
Training loss: 2.338207456046924
Validation loss: 2.572318638097156

Epoch: 240| Step: 0
Training loss: 2.936064349038409
Validation loss: 2.5668203987706613

Epoch: 5| Step: 1
Training loss: 2.4736363787047426
Validation loss: 2.574204875212712

Epoch: 5| Step: 2
Training loss: 3.322317151046274
Validation loss: 2.5660203752349204

Epoch: 5| Step: 3
Training loss: 3.244486607171651
Validation loss: 2.572270669025162

Epoch: 5| Step: 4
Training loss: 2.9208084852728025
Validation loss: 2.5716206158958865

Epoch: 5| Step: 5
Training loss: 2.7781125492121603
Validation loss: 2.5693750123946755

Epoch: 5| Step: 6
Training loss: 2.931860522232627
Validation loss: 2.5751763907132372

Epoch: 5| Step: 7
Training loss: 3.2556434930491096
Validation loss: 2.567794051226083

Epoch: 5| Step: 8
Training loss: 2.3753238256440663
Validation loss: 2.5733234219671304

Epoch: 5| Step: 9
Training loss: 2.698770974498694
Validation loss: 2.5714750189687305

Epoch: 5| Step: 10
Training loss: 3.0065219240669143
Validation loss: 2.5767509948144465

Epoch: 241| Step: 0
Training loss: 2.9927679947986143
Validation loss: 2.591992116742513

Epoch: 5| Step: 1
Training loss: 3.0251322882864646
Validation loss: 2.597551768679244

Epoch: 5| Step: 2
Training loss: 2.2736161938471118
Validation loss: 2.61610382374887

Epoch: 5| Step: 3
Training loss: 3.4034475294551543
Validation loss: 2.6519256522753265

Epoch: 5| Step: 4
Training loss: 3.1705402140200434
Validation loss: 2.657440555727148

Epoch: 5| Step: 5
Training loss: 3.204682655275013
Validation loss: 2.653662317868794

Epoch: 5| Step: 6
Training loss: 1.8332523920513608
Validation loss: 2.6062559374685588

Epoch: 5| Step: 7
Training loss: 3.3184618291368047
Validation loss: 2.582839026051026

Epoch: 5| Step: 8
Training loss: 3.069325528687012
Validation loss: 2.5699249862152467

Epoch: 5| Step: 9
Training loss: 2.7618517809908543
Validation loss: 2.5627952423607603

Epoch: 5| Step: 10
Training loss: 2.5609317725945524
Validation loss: 2.5724495615740612

Epoch: 242| Step: 0
Training loss: 2.903432649504293
Validation loss: 2.5643477537296104

Epoch: 5| Step: 1
Training loss: 3.2419512926945866
Validation loss: 2.569277458747551

Epoch: 5| Step: 2
Training loss: 2.5931331406560014
Validation loss: 2.5700771726376748

Epoch: 5| Step: 3
Training loss: 3.1489131748008043
Validation loss: 2.567657958101509

Epoch: 5| Step: 4
Training loss: 2.710774705379703
Validation loss: 2.570499325479976

Epoch: 5| Step: 5
Training loss: 2.6142255277353716
Validation loss: 2.574855054508751

Epoch: 5| Step: 6
Training loss: 3.1605132364612363
Validation loss: 2.5745051651918973

Epoch: 5| Step: 7
Training loss: 2.9007494977368533
Validation loss: 2.580760126443605

Epoch: 5| Step: 8
Training loss: 2.794935950157824
Validation loss: 2.5705613941718166

Epoch: 5| Step: 9
Training loss: 2.7589852322400623
Validation loss: 2.5817064504174922

Epoch: 5| Step: 10
Training loss: 3.190682710878508
Validation loss: 2.582979210416601

Epoch: 243| Step: 0
Training loss: 2.993748031328864
Validation loss: 2.590331122214282

Epoch: 5| Step: 1
Training loss: 2.9117178394673418
Validation loss: 2.5906760469419594

Epoch: 5| Step: 2
Training loss: 2.6607135743444705
Validation loss: 2.5875408358623857

Epoch: 5| Step: 3
Training loss: 3.1694152013432793
Validation loss: 2.598162350855003

Epoch: 5| Step: 4
Training loss: 2.668294191408949
Validation loss: 2.6018623273631123

Epoch: 5| Step: 5
Training loss: 2.7845996016862866
Validation loss: 2.6034114571159526

Epoch: 5| Step: 6
Training loss: 2.556305818950941
Validation loss: 2.5938471056772627

Epoch: 5| Step: 7
Training loss: 2.967807499701698
Validation loss: 2.591050133638647

Epoch: 5| Step: 8
Training loss: 3.0122014511138335
Validation loss: 2.592913239006195

Epoch: 5| Step: 9
Training loss: 2.9468106373041527
Validation loss: 2.5798112184508772

Epoch: 5| Step: 10
Training loss: 3.195467994096318
Validation loss: 2.5994392670283215

Epoch: 244| Step: 0
Training loss: 2.6357227393977296
Validation loss: 2.5929738230195074

Epoch: 5| Step: 1
Training loss: 3.129522179642761
Validation loss: 2.6104221886797383

Epoch: 5| Step: 2
Training loss: 2.75586473882141
Validation loss: 2.6220571572954596

Epoch: 5| Step: 3
Training loss: 2.8030385560110256
Validation loss: 2.6242834647516284

Epoch: 5| Step: 4
Training loss: 2.8642539834934344
Validation loss: 2.615882823838291

Epoch: 5| Step: 5
Training loss: 3.2548119061996146
Validation loss: 2.602131587780038

Epoch: 5| Step: 6
Training loss: 2.9069158960228436
Validation loss: 2.6005912657082475

Epoch: 5| Step: 7
Training loss: 2.863579998590086
Validation loss: 2.5865372139358844

Epoch: 5| Step: 8
Training loss: 2.770623469232902
Validation loss: 2.586298510746661

Epoch: 5| Step: 9
Training loss: 3.177049146791395
Validation loss: 2.5904293506598273

Epoch: 5| Step: 10
Training loss: 2.836113369955653
Validation loss: 2.6314569099768708

Epoch: 245| Step: 0
Training loss: 2.9829110754239254
Validation loss: 2.651933262198369

Epoch: 5| Step: 1
Training loss: 2.9582890968418156
Validation loss: 2.641448474375761

Epoch: 5| Step: 2
Training loss: 3.158552029032446
Validation loss: 2.659524405728914

Epoch: 5| Step: 3
Training loss: 3.304000602740586
Validation loss: 2.657437981898539

Epoch: 5| Step: 4
Training loss: 3.3240314076726674
Validation loss: 2.6293829302730334

Epoch: 5| Step: 5
Training loss: 2.733123580126216
Validation loss: 2.5971525913102833

Epoch: 5| Step: 6
Training loss: 2.948034672795901
Validation loss: 2.5632858181963254

Epoch: 5| Step: 7
Training loss: 2.057298285236255
Validation loss: 2.5634818908354764

Epoch: 5| Step: 8
Training loss: 2.6628826135081463
Validation loss: 2.564935015984405

Epoch: 5| Step: 9
Training loss: 2.608451451398741
Validation loss: 2.561818967531271

Epoch: 5| Step: 10
Training loss: 3.031882308608293
Validation loss: 2.567955103243072

Epoch: 246| Step: 0
Training loss: 3.236619106326989
Validation loss: 2.566884054026785

Epoch: 5| Step: 1
Training loss: 2.4785344789718273
Validation loss: 2.573116136497414

Epoch: 5| Step: 2
Training loss: 3.1452964846738163
Validation loss: 2.5802303424965127

Epoch: 5| Step: 3
Training loss: 3.0889568768100326
Validation loss: 2.579079257918512

Epoch: 5| Step: 4
Training loss: 2.8089507702390346
Validation loss: 2.584692807359975

Epoch: 5| Step: 5
Training loss: 2.6403627886178023
Validation loss: 2.5864977679354726

Epoch: 5| Step: 6
Training loss: 2.919703365047238
Validation loss: 2.5895885140750448

Epoch: 5| Step: 7
Training loss: 2.2994846388570633
Validation loss: 2.589907452105765

Epoch: 5| Step: 8
Training loss: 2.7206320551389274
Validation loss: 2.582322977654691

Epoch: 5| Step: 9
Training loss: 2.960324991530652
Validation loss: 2.575620329658797

Epoch: 5| Step: 10
Training loss: 3.541801285522717
Validation loss: 2.59467535491617

Epoch: 247| Step: 0
Training loss: 2.9408780417787153
Validation loss: 2.607070993261779

Epoch: 5| Step: 1
Training loss: 2.774678728906289
Validation loss: 2.6032023623626217

Epoch: 5| Step: 2
Training loss: 3.5052376113432167
Validation loss: 2.619978376719052

Epoch: 5| Step: 3
Training loss: 3.0691299296519605
Validation loss: 2.64492615707165

Epoch: 5| Step: 4
Training loss: 2.3010111825033825
Validation loss: 2.666208120755351

Epoch: 5| Step: 5
Training loss: 3.082552750902597
Validation loss: 2.7150651011864313

Epoch: 5| Step: 6
Training loss: 2.8593488181327795
Validation loss: 2.692045734871393

Epoch: 5| Step: 7
Training loss: 3.3460579865989497
Validation loss: 2.6402463894566375

Epoch: 5| Step: 8
Training loss: 2.786499812212571
Validation loss: 2.594118135897344

Epoch: 5| Step: 9
Training loss: 2.7781329743793295
Validation loss: 2.585998631588684

Epoch: 5| Step: 10
Training loss: 2.1233267086450702
Validation loss: 2.5736203154188035

Epoch: 248| Step: 0
Training loss: 2.741810742875911
Validation loss: 2.566301009371777

Epoch: 5| Step: 1
Training loss: 3.09948537923457
Validation loss: 2.5683606326847466

Epoch: 5| Step: 2
Training loss: 2.302044921370416
Validation loss: 2.5650093273876062

Epoch: 5| Step: 3
Training loss: 2.8943800172410157
Validation loss: 2.565014957375652

Epoch: 5| Step: 4
Training loss: 2.605091439397721
Validation loss: 2.5658305624047615

Epoch: 5| Step: 5
Training loss: 2.8431878844338456
Validation loss: 2.575723674652632

Epoch: 5| Step: 6
Training loss: 2.6682563057082165
Validation loss: 2.568547459903853

Epoch: 5| Step: 7
Training loss: 2.9167021794654886
Validation loss: 2.5661920081686325

Epoch: 5| Step: 8
Training loss: 3.201946506956455
Validation loss: 2.5805550775199637

Epoch: 5| Step: 9
Training loss: 3.504094861928199
Validation loss: 2.593237729318938

Epoch: 5| Step: 10
Training loss: 3.0870663666556037
Validation loss: 2.598530101388332

Epoch: 249| Step: 0
Training loss: 2.933883551088082
Validation loss: 2.6165941658332454

Epoch: 5| Step: 1
Training loss: 3.121457495279477
Validation loss: 2.604244593941261

Epoch: 5| Step: 2
Training loss: 3.1402987030725344
Validation loss: 2.611681668198113

Epoch: 5| Step: 3
Training loss: 2.815368122402883
Validation loss: 2.610269521027516

Epoch: 5| Step: 4
Training loss: 2.904124477377397
Validation loss: 2.6063802588642435

Epoch: 5| Step: 5
Training loss: 3.0941345284133064
Validation loss: 2.6173146089197883

Epoch: 5| Step: 6
Training loss: 2.8094912223834947
Validation loss: 2.6039951791392455

Epoch: 5| Step: 7
Training loss: 2.9722112455393126
Validation loss: 2.5874260761706096

Epoch: 5| Step: 8
Training loss: 2.8777802334369538
Validation loss: 2.5846733689114454

Epoch: 5| Step: 9
Training loss: 2.6281735446361028
Validation loss: 2.583067756945265

Epoch: 5| Step: 10
Training loss: 2.3589381135566247
Validation loss: 2.5760389672165576

Epoch: 250| Step: 0
Training loss: 2.2832780993758415
Validation loss: 2.5673994611437156

Epoch: 5| Step: 1
Training loss: 3.4132280180995878
Validation loss: 2.5671741306220266

Epoch: 5| Step: 2
Training loss: 3.0317121330432415
Validation loss: 2.571845587742884

Epoch: 5| Step: 3
Training loss: 2.968738756660453
Validation loss: 2.5691505840746323

Epoch: 5| Step: 4
Training loss: 2.9561861511174485
Validation loss: 2.569226102153825

Epoch: 5| Step: 5
Training loss: 3.0292063637449385
Validation loss: 2.571784074378902

Epoch: 5| Step: 6
Training loss: 3.370930938502134
Validation loss: 2.5662151919909237

Epoch: 5| Step: 7
Training loss: 2.5612854288907925
Validation loss: 2.5645204167901925

Epoch: 5| Step: 8
Training loss: 2.5939560773861787
Validation loss: 2.572553354828917

Epoch: 5| Step: 9
Training loss: 2.714470926935393
Validation loss: 2.5804548915713084

Epoch: 5| Step: 10
Training loss: 2.645882603544515
Validation loss: 2.5791229543994554

Epoch: 251| Step: 0
Training loss: 3.076522642451871
Validation loss: 2.589321657177124

Epoch: 5| Step: 1
Training loss: 2.635320357622311
Validation loss: 2.6011488967347076

Epoch: 5| Step: 2
Training loss: 3.1269833183856153
Validation loss: 2.625778533016094

Epoch: 5| Step: 3
Training loss: 2.6851140453761038
Validation loss: 2.625239314954845

Epoch: 5| Step: 4
Training loss: 3.1630598575356608
Validation loss: 2.6183781738456267

Epoch: 5| Step: 5
Training loss: 2.7706172734588894
Validation loss: 2.629671956167369

Epoch: 5| Step: 6
Training loss: 2.573893455594453
Validation loss: 2.5959428782848746

Epoch: 5| Step: 7
Training loss: 2.663600490031417
Validation loss: 2.595750442777668

Epoch: 5| Step: 8
Training loss: 3.0305758640981417
Validation loss: 2.5730065292748003

Epoch: 5| Step: 9
Training loss: 2.838394823854924
Validation loss: 2.5731328038388845

Epoch: 5| Step: 10
Training loss: 3.0504525333570034
Validation loss: 2.564767962386831

Epoch: 252| Step: 0
Training loss: 2.706017330466611
Validation loss: 2.5665321990343237

Epoch: 5| Step: 1
Training loss: 2.2919859461461676
Validation loss: 2.575877923003619

Epoch: 5| Step: 2
Training loss: 2.8836958030763538
Validation loss: 2.5747615100042354

Epoch: 5| Step: 3
Training loss: 2.965367046107387
Validation loss: 2.570389745804345

Epoch: 5| Step: 4
Training loss: 3.2699023985222886
Validation loss: 2.5871133020073698

Epoch: 5| Step: 5
Training loss: 2.7713881967213236
Validation loss: 2.571500674438267

Epoch: 5| Step: 6
Training loss: 3.1418765786331853
Validation loss: 2.5894130252778487

Epoch: 5| Step: 7
Training loss: 2.9512323036293417
Validation loss: 2.5995603483910092

Epoch: 5| Step: 8
Training loss: 2.2764965333197944
Validation loss: 2.6323128566321388

Epoch: 5| Step: 9
Training loss: 3.4365385618362128
Validation loss: 2.6465904219133654

Epoch: 5| Step: 10
Training loss: 2.7281147820105485
Validation loss: 2.5992103878756296

Epoch: 253| Step: 0
Training loss: 2.8492469060294785
Validation loss: 2.5679414262242672

Epoch: 5| Step: 1
Training loss: 2.71065068995128
Validation loss: 2.5480536582110087

Epoch: 5| Step: 2
Training loss: 3.1223331516179345
Validation loss: 2.5546343257453232

Epoch: 5| Step: 3
Training loss: 2.764384966941631
Validation loss: 2.55620755191639

Epoch: 5| Step: 4
Training loss: 3.039030491677519
Validation loss: 2.5516381390038263

Epoch: 5| Step: 5
Training loss: 2.9899529063621024
Validation loss: 2.5530836832324226

Epoch: 5| Step: 6
Training loss: 3.0157397945079265
Validation loss: 2.5516671386106604

Epoch: 5| Step: 7
Training loss: 2.91530470156907
Validation loss: 2.5486697369537374

Epoch: 5| Step: 8
Training loss: 2.755047673887747
Validation loss: 2.559865952845026

Epoch: 5| Step: 9
Training loss: 3.1137463690063916
Validation loss: 2.5584059403911246

Epoch: 5| Step: 10
Training loss: 2.290691121852718
Validation loss: 2.579493868545178

Epoch: 254| Step: 0
Training loss: 3.2677074162817656
Validation loss: 2.5871071582521656

Epoch: 5| Step: 1
Training loss: 2.8192857051400506
Validation loss: 2.599005589215945

Epoch: 5| Step: 2
Training loss: 2.916613078760412
Validation loss: 2.6397928624650238

Epoch: 5| Step: 3
Training loss: 2.6403271208015284
Validation loss: 2.676457434668308

Epoch: 5| Step: 4
Training loss: 2.4198526121607693
Validation loss: 2.6647228990625735

Epoch: 5| Step: 5
Training loss: 2.9952384991327503
Validation loss: 2.6455430393261983

Epoch: 5| Step: 6
Training loss: 2.886349707360269
Validation loss: 2.6137750017746617

Epoch: 5| Step: 7
Training loss: 2.816626594378791
Validation loss: 2.58408075933143

Epoch: 5| Step: 8
Training loss: 3.206547095381938
Validation loss: 2.5647841787046324

Epoch: 5| Step: 9
Training loss: 2.687686204004305
Validation loss: 2.5672468413728478

Epoch: 5| Step: 10
Training loss: 3.0302537677112977
Validation loss: 2.549823726180914

Epoch: 255| Step: 0
Training loss: 3.122740424546081
Validation loss: 2.5491585398176264

Epoch: 5| Step: 1
Training loss: 2.888243317812858
Validation loss: 2.5506007743701122

Epoch: 5| Step: 2
Training loss: 2.8080517666384095
Validation loss: 2.5497369651082997

Epoch: 5| Step: 3
Training loss: 2.87799380787282
Validation loss: 2.5485369903160247

Epoch: 5| Step: 4
Training loss: 2.628770391119406
Validation loss: 2.546868206563446

Epoch: 5| Step: 5
Training loss: 3.069635602964194
Validation loss: 2.551654857220948

Epoch: 5| Step: 6
Training loss: 2.842967502125138
Validation loss: 2.5349994156298314

Epoch: 5| Step: 7
Training loss: 2.5876704284268475
Validation loss: 2.5489680788218188

Epoch: 5| Step: 8
Training loss: 3.2133957857048885
Validation loss: 2.5424145966989706

Epoch: 5| Step: 9
Training loss: 3.1275737082305572
Validation loss: 2.5671440653849897

Epoch: 5| Step: 10
Training loss: 2.5157883869446853
Validation loss: 2.5618415304647173

Epoch: 256| Step: 0
Training loss: 2.989497875804309
Validation loss: 2.58552057027818

Epoch: 5| Step: 1
Training loss: 3.068955138394742
Validation loss: 2.623827619233996

Epoch: 5| Step: 2
Training loss: 2.777161582842157
Validation loss: 2.64314271640124

Epoch: 5| Step: 3
Training loss: 3.3622481014244365
Validation loss: 2.664938747257178

Epoch: 5| Step: 4
Training loss: 3.0422954867358434
Validation loss: 2.656284662608066

Epoch: 5| Step: 5
Training loss: 3.3619593416078106
Validation loss: 2.6280254268332994

Epoch: 5| Step: 6
Training loss: 2.26674703240508
Validation loss: 2.5928367690283816

Epoch: 5| Step: 7
Training loss: 2.8641459368067577
Validation loss: 2.572897877914566

Epoch: 5| Step: 8
Training loss: 2.851916147537555
Validation loss: 2.56288955772754

Epoch: 5| Step: 9
Training loss: 2.564518854325917
Validation loss: 2.5551485657429844

Epoch: 5| Step: 10
Training loss: 2.353419283719263
Validation loss: 2.561609431076046

Epoch: 257| Step: 0
Training loss: 3.4482683231008266
Validation loss: 2.5551710230344895

Epoch: 5| Step: 1
Training loss: 2.8970552423363345
Validation loss: 2.5666109909530856

Epoch: 5| Step: 2
Training loss: 2.634869595364525
Validation loss: 2.566472911220261

Epoch: 5| Step: 3
Training loss: 2.7428629768684196
Validation loss: 2.5880983546278267

Epoch: 5| Step: 4
Training loss: 2.4855096493190105
Validation loss: 2.6129735829952985

Epoch: 5| Step: 5
Training loss: 2.8744907757459637
Validation loss: 2.5979502975721567

Epoch: 5| Step: 6
Training loss: 2.836218113322798
Validation loss: 2.5902196612299977

Epoch: 5| Step: 7
Training loss: 3.032986802089714
Validation loss: 2.5834598993212166

Epoch: 5| Step: 8
Training loss: 3.133786932260105
Validation loss: 2.579550130013937

Epoch: 5| Step: 9
Training loss: 2.706747725530458
Validation loss: 2.573018311702314

Epoch: 5| Step: 10
Training loss: 2.696820796275971
Validation loss: 2.573689237195276

Epoch: 258| Step: 0
Training loss: 2.958285873104024
Validation loss: 2.575868278024837

Epoch: 5| Step: 1
Training loss: 2.1454803645618523
Validation loss: 2.5688804209920257

Epoch: 5| Step: 2
Training loss: 2.900914370325322
Validation loss: 2.5558351039767664

Epoch: 5| Step: 3
Training loss: 2.985718908847403
Validation loss: 2.556839806626944

Epoch: 5| Step: 4
Training loss: 3.468385694463856
Validation loss: 2.5618169871232706

Epoch: 5| Step: 5
Training loss: 2.732390724642623
Validation loss: 2.551346101101998

Epoch: 5| Step: 6
Training loss: 2.6280737546444684
Validation loss: 2.5564944316512586

Epoch: 5| Step: 7
Training loss: 2.9716952521260973
Validation loss: 2.558383468908141

Epoch: 5| Step: 8
Training loss: 2.9844814101816293
Validation loss: 2.5665156236763007

Epoch: 5| Step: 9
Training loss: 2.898304239587342
Validation loss: 2.5799193044025324

Epoch: 5| Step: 10
Training loss: 2.7015127324141925
Validation loss: 2.589504958421614

Epoch: 259| Step: 0
Training loss: 2.554652969173644
Validation loss: 2.598284462602818

Epoch: 5| Step: 1
Training loss: 2.925215662643292
Validation loss: 2.600265036997697

Epoch: 5| Step: 2
Training loss: 2.8106414588139237
Validation loss: 2.6022187841159923

Epoch: 5| Step: 3
Training loss: 2.7961760771814874
Validation loss: 2.577373396323717

Epoch: 5| Step: 4
Training loss: 2.9737270997982828
Validation loss: 2.5940229576445275

Epoch: 5| Step: 5
Training loss: 3.1551989325484815
Validation loss: 2.598294236504304

Epoch: 5| Step: 6
Training loss: 2.743838256250693
Validation loss: 2.579537209165845

Epoch: 5| Step: 7
Training loss: 2.454039482184598
Validation loss: 2.5743736023701143

Epoch: 5| Step: 8
Training loss: 2.8352078426541083
Validation loss: 2.563596927377741

Epoch: 5| Step: 9
Training loss: 3.0150971420099943
Validation loss: 2.5550457280300405

Epoch: 5| Step: 10
Training loss: 3.218855920919144
Validation loss: 2.5497042876769798

Epoch: 260| Step: 0
Training loss: 2.7909181549799396
Validation loss: 2.556811961608427

Epoch: 5| Step: 1
Training loss: 2.7658942140056744
Validation loss: 2.556864445370232

Epoch: 5| Step: 2
Training loss: 3.199204292311273
Validation loss: 2.5591703342475003

Epoch: 5| Step: 3
Training loss: 2.688409429641076
Validation loss: 2.55248131192682

Epoch: 5| Step: 4
Training loss: 2.9946791829532384
Validation loss: 2.5659198206042917

Epoch: 5| Step: 5
Training loss: 2.309658882749374
Validation loss: 2.551546108984254

Epoch: 5| Step: 6
Training loss: 2.8438717323490015
Validation loss: 2.5603534232466063

Epoch: 5| Step: 7
Training loss: 2.9752473103285357
Validation loss: 2.5703301440207897

Epoch: 5| Step: 8
Training loss: 3.1173121683148963
Validation loss: 2.564768536634249

Epoch: 5| Step: 9
Training loss: 2.816025622251293
Validation loss: 2.5726087705723377

Epoch: 5| Step: 10
Training loss: 2.92259134089493
Validation loss: 2.581710768981207

Epoch: 261| Step: 0
Training loss: 2.711839069762309
Validation loss: 2.5942633701849744

Epoch: 5| Step: 1
Training loss: 3.324957688141262
Validation loss: 2.5891544655512124

Epoch: 5| Step: 2
Training loss: 2.5805745827537208
Validation loss: 2.598011666525919

Epoch: 5| Step: 3
Training loss: 2.5321787319528215
Validation loss: 2.604651976289744

Epoch: 5| Step: 4
Training loss: 2.7023275444910158
Validation loss: 2.6066560767411087

Epoch: 5| Step: 5
Training loss: 3.4200745466261377
Validation loss: 2.602000622766618

Epoch: 5| Step: 6
Training loss: 2.8568622826005465
Validation loss: 2.5934693152120767

Epoch: 5| Step: 7
Training loss: 2.576673341753145
Validation loss: 2.5773780563568875

Epoch: 5| Step: 8
Training loss: 2.739770938459464
Validation loss: 2.5611713755734082

Epoch: 5| Step: 9
Training loss: 3.025182255070197
Validation loss: 2.5554190364104667

Epoch: 5| Step: 10
Training loss: 2.7732942785973296
Validation loss: 2.5422468321787584

Epoch: 262| Step: 0
Training loss: 2.891514326877711
Validation loss: 2.5531298850731186

Epoch: 5| Step: 1
Training loss: 2.6054794562947667
Validation loss: 2.5481824027471713

Epoch: 5| Step: 2
Training loss: 2.9865507014218067
Validation loss: 2.559462487036675

Epoch: 5| Step: 3
Training loss: 3.0091256582050003
Validation loss: 2.5620392355863015

Epoch: 5| Step: 4
Training loss: 2.84619002408452
Validation loss: 2.567555890014237

Epoch: 5| Step: 5
Training loss: 2.793656185887721
Validation loss: 2.583385961858555

Epoch: 5| Step: 6
Training loss: 3.0505608590168185
Validation loss: 2.601962507800968

Epoch: 5| Step: 7
Training loss: 2.46282218335836
Validation loss: 2.61673139020909

Epoch: 5| Step: 8
Training loss: 2.70839728255456
Validation loss: 2.6602245266213056

Epoch: 5| Step: 9
Training loss: 3.0163938500841834
Validation loss: 2.627117270944229

Epoch: 5| Step: 10
Training loss: 3.20011365807866
Validation loss: 2.5952626658197024

Epoch: 263| Step: 0
Training loss: 3.047926031912241
Validation loss: 2.5836514066432583

Epoch: 5| Step: 1
Training loss: 2.776405315425848
Validation loss: 2.5585300818697716

Epoch: 5| Step: 2
Training loss: 2.6633527151396414
Validation loss: 2.551753469365301

Epoch: 5| Step: 3
Training loss: 2.4970695486653116
Validation loss: 2.5472352898979485

Epoch: 5| Step: 4
Training loss: 3.125470698193492
Validation loss: 2.5509219519086628

Epoch: 5| Step: 5
Training loss: 3.367348085189747
Validation loss: 2.5483606231854368

Epoch: 5| Step: 6
Training loss: 2.8115838148041146
Validation loss: 2.54610488595607

Epoch: 5| Step: 7
Training loss: 3.0183967146668804
Validation loss: 2.5451743621347007

Epoch: 5| Step: 8
Training loss: 3.000771264434782
Validation loss: 2.542910991111239

Epoch: 5| Step: 9
Training loss: 2.534195587167126
Validation loss: 2.544291706289064

Epoch: 5| Step: 10
Training loss: 2.6053220601802694
Validation loss: 2.5531062229508437

Epoch: 264| Step: 0
Training loss: 2.6810423870670155
Validation loss: 2.570810341032087

Epoch: 5| Step: 1
Training loss: 2.6003498538928143
Validation loss: 2.5885228734722703

Epoch: 5| Step: 2
Training loss: 2.5199931822790536
Validation loss: 2.611588761527914

Epoch: 5| Step: 3
Training loss: 2.690652993795376
Validation loss: 2.6435073331955707

Epoch: 5| Step: 4
Training loss: 3.3164552790563837
Validation loss: 2.7058081217378778

Epoch: 5| Step: 5
Training loss: 2.936484628058726
Validation loss: 2.6483477307036214

Epoch: 5| Step: 6
Training loss: 3.047126642252629
Validation loss: 2.5870806091345093

Epoch: 5| Step: 7
Training loss: 2.820498219976893
Validation loss: 2.5687203381847334

Epoch: 5| Step: 8
Training loss: 2.774487277941015
Validation loss: 2.544330256958154

Epoch: 5| Step: 9
Training loss: 3.2599831354840068
Validation loss: 2.5510785791801855

Epoch: 5| Step: 10
Training loss: 3.018767463838913
Validation loss: 2.5502936849789664

Epoch: 265| Step: 0
Training loss: 2.5534859260931633
Validation loss: 2.5481043207394207

Epoch: 5| Step: 1
Training loss: 2.3760201120520796
Validation loss: 2.549966996341482

Epoch: 5| Step: 2
Training loss: 2.914037300389534
Validation loss: 2.5542687674416453

Epoch: 5| Step: 3
Training loss: 3.14860924188459
Validation loss: 2.5484817382037432

Epoch: 5| Step: 4
Training loss: 3.0367567244015845
Validation loss: 2.545423169254635

Epoch: 5| Step: 5
Training loss: 3.1299237943397316
Validation loss: 2.5522298469869864

Epoch: 5| Step: 6
Training loss: 2.4533703918180523
Validation loss: 2.549532598599467

Epoch: 5| Step: 7
Training loss: 2.738372931802597
Validation loss: 2.5586310090789577

Epoch: 5| Step: 8
Training loss: 2.9850873646179696
Validation loss: 2.5752782075405776

Epoch: 5| Step: 9
Training loss: 3.1485862223520193
Validation loss: 2.5749705546617325

Epoch: 5| Step: 10
Training loss: 3.1767301936433894
Validation loss: 2.586119343990983

Epoch: 266| Step: 0
Training loss: 2.9070226811172755
Validation loss: 2.5911295928586293

Epoch: 5| Step: 1
Training loss: 2.8341220057250465
Validation loss: 2.583539387572739

Epoch: 5| Step: 2
Training loss: 2.6651070524260585
Validation loss: 2.597311293835807

Epoch: 5| Step: 3
Training loss: 3.0009268282671075
Validation loss: 2.5992255879342694

Epoch: 5| Step: 4
Training loss: 3.144140145757589
Validation loss: 2.6228479332794423

Epoch: 5| Step: 5
Training loss: 2.209082374456369
Validation loss: 2.6078297981325473

Epoch: 5| Step: 6
Training loss: 3.484325733606302
Validation loss: 2.5930516715937846

Epoch: 5| Step: 7
Training loss: 2.4971713275789122
Validation loss: 2.5799013264960524

Epoch: 5| Step: 8
Training loss: 2.780885565380294
Validation loss: 2.559167912022646

Epoch: 5| Step: 9
Training loss: 3.1285109061840113
Validation loss: 2.5571988203808007

Epoch: 5| Step: 10
Training loss: 2.3433187469455317
Validation loss: 2.5420171098334103

Epoch: 267| Step: 0
Training loss: 2.8315324857135873
Validation loss: 2.5436868881140864

Epoch: 5| Step: 1
Training loss: 2.6863682160208637
Validation loss: 2.540697394757334

Epoch: 5| Step: 2
Training loss: 2.3248727086815455
Validation loss: 2.5364511029931154

Epoch: 5| Step: 3
Training loss: 3.048150993582059
Validation loss: 2.5370903722692475

Epoch: 5| Step: 4
Training loss: 3.1966628972874265
Validation loss: 2.5485555717207147

Epoch: 5| Step: 5
Training loss: 2.819328326593901
Validation loss: 2.5551566836206336

Epoch: 5| Step: 6
Training loss: 3.066921701054324
Validation loss: 2.553061909476649

Epoch: 5| Step: 7
Training loss: 2.712939136310326
Validation loss: 2.570068967225885

Epoch: 5| Step: 8
Training loss: 3.3900235956771816
Validation loss: 2.575611687030561

Epoch: 5| Step: 9
Training loss: 2.5086051662664066
Validation loss: 2.579016552771301

Epoch: 5| Step: 10
Training loss: 2.635895686787464
Validation loss: 2.5965544050232214

Epoch: 268| Step: 0
Training loss: 2.3344773031386765
Validation loss: 2.5988517527462744

Epoch: 5| Step: 1
Training loss: 2.9092913065508017
Validation loss: 2.611015942054547

Epoch: 5| Step: 2
Training loss: 3.3444419929126474
Validation loss: 2.6041522193425903

Epoch: 5| Step: 3
Training loss: 2.5114447887745786
Validation loss: 2.5878646168840445

Epoch: 5| Step: 4
Training loss: 2.2891203056041096
Validation loss: 2.5758131862010423

Epoch: 5| Step: 5
Training loss: 3.4919653358880094
Validation loss: 2.569887450952094

Epoch: 5| Step: 6
Training loss: 2.519285204798225
Validation loss: 2.5719648692066377

Epoch: 5| Step: 7
Training loss: 3.1047608150432344
Validation loss: 2.5652134402890137

Epoch: 5| Step: 8
Training loss: 2.6437047571229417
Validation loss: 2.555616500071914

Epoch: 5| Step: 9
Training loss: 2.699249841535839
Validation loss: 2.5561955671394148

Epoch: 5| Step: 10
Training loss: 3.1869808597043803
Validation loss: 2.5676663030111357

Epoch: 269| Step: 0
Training loss: 2.2924111515245857
Validation loss: 2.575349962805441

Epoch: 5| Step: 1
Training loss: 2.849124231802578
Validation loss: 2.567392270676339

Epoch: 5| Step: 2
Training loss: 2.7442889299059683
Validation loss: 2.583384129967246

Epoch: 5| Step: 3
Training loss: 3.3677131260276236
Validation loss: 2.5908879297314757

Epoch: 5| Step: 4
Training loss: 2.946282265073365
Validation loss: 2.606598711631051

Epoch: 5| Step: 5
Training loss: 2.4216653056271067
Validation loss: 2.6086342260972226

Epoch: 5| Step: 6
Training loss: 2.7485699836935624
Validation loss: 2.5882483353898236

Epoch: 5| Step: 7
Training loss: 3.4241669525817273
Validation loss: 2.585788945723537

Epoch: 5| Step: 8
Training loss: 2.714201970708715
Validation loss: 2.583232244193467

Epoch: 5| Step: 9
Training loss: 3.008217048687099
Validation loss: 2.589969409547065

Epoch: 5| Step: 10
Training loss: 2.5411134857873128
Validation loss: 2.565137386820042

Epoch: 270| Step: 0
Training loss: 3.0838303723818856
Validation loss: 2.570989038044138

Epoch: 5| Step: 1
Training loss: 3.1941467994200137
Validation loss: 2.547321720531146

Epoch: 5| Step: 2
Training loss: 2.6864407248263213
Validation loss: 2.542292984911877

Epoch: 5| Step: 3
Training loss: 2.6483578290180576
Validation loss: 2.5452805175899127

Epoch: 5| Step: 4
Training loss: 2.4279992226877494
Validation loss: 2.5362730969112524

Epoch: 5| Step: 5
Training loss: 3.1705081794704246
Validation loss: 2.5480292215190534

Epoch: 5| Step: 6
Training loss: 2.6458937770717705
Validation loss: 2.542807099436174

Epoch: 5| Step: 7
Training loss: 2.7385300810288187
Validation loss: 2.5563415850315643

Epoch: 5| Step: 8
Training loss: 3.299377504070681
Validation loss: 2.5475869149158177

Epoch: 5| Step: 9
Training loss: 2.7361926331830166
Validation loss: 2.5698757793656446

Epoch: 5| Step: 10
Training loss: 2.3935026912574466
Validation loss: 2.5573142448163577

Epoch: 271| Step: 0
Training loss: 3.245913210185109
Validation loss: 2.589676058499741

Epoch: 5| Step: 1
Training loss: 2.7481361488530833
Validation loss: 2.6073729038498215

Epoch: 5| Step: 2
Training loss: 2.8507714415381757
Validation loss: 2.5898722267790872

Epoch: 5| Step: 3
Training loss: 2.962569056482686
Validation loss: 2.604121335199054

Epoch: 5| Step: 4
Training loss: 2.692623931526123
Validation loss: 2.5960934802546904

Epoch: 5| Step: 5
Training loss: 2.4333733080711446
Validation loss: 2.5690346820590646

Epoch: 5| Step: 6
Training loss: 2.6779755665274867
Validation loss: 2.5699198398256233

Epoch: 5| Step: 7
Training loss: 2.9676362207090605
Validation loss: 2.581431779293417

Epoch: 5| Step: 8
Training loss: 2.7198355250558284
Validation loss: 2.5616971550799748

Epoch: 5| Step: 9
Training loss: 2.6262846028709643
Validation loss: 2.574553386380362

Epoch: 5| Step: 10
Training loss: 3.1403929971055424
Validation loss: 2.6011993342938005

Epoch: 272| Step: 0
Training loss: 2.176042140475511
Validation loss: 2.622750961020383

Epoch: 5| Step: 1
Training loss: 3.2557347393379774
Validation loss: 2.6079312641668664

Epoch: 5| Step: 2
Training loss: 2.5638461415134715
Validation loss: 2.596272034735115

Epoch: 5| Step: 3
Training loss: 2.7851439230968444
Validation loss: 2.6111855442469634

Epoch: 5| Step: 4
Training loss: 2.98095475180349
Validation loss: 2.616369269830144

Epoch: 5| Step: 5
Training loss: 3.069896718378524
Validation loss: 2.597679331637843

Epoch: 5| Step: 6
Training loss: 2.650610828177379
Validation loss: 2.587871511725041

Epoch: 5| Step: 7
Training loss: 2.920488324288787
Validation loss: 2.575428240082028

Epoch: 5| Step: 8
Training loss: 2.717513581551704
Validation loss: 2.55610304176681

Epoch: 5| Step: 9
Training loss: 2.972590321675696
Validation loss: 2.5440497456871163

Epoch: 5| Step: 10
Training loss: 3.156235798718825
Validation loss: 2.5395029195595553

Epoch: 273| Step: 0
Training loss: 3.125850714283758
Validation loss: 2.536746882921464

Epoch: 5| Step: 1
Training loss: 2.564797278827692
Validation loss: 2.5287131958085425

Epoch: 5| Step: 2
Training loss: 2.4688744815394976
Validation loss: 2.5392896617811322

Epoch: 5| Step: 3
Training loss: 2.6039632081979263
Validation loss: 2.543526556178688

Epoch: 5| Step: 4
Training loss: 2.3317204305009693
Validation loss: 2.5592213506988863

Epoch: 5| Step: 5
Training loss: 2.571177792052173
Validation loss: 2.5779139775748154

Epoch: 5| Step: 6
Training loss: 3.0166655805666602
Validation loss: 2.6033029215753514

Epoch: 5| Step: 7
Training loss: 3.1312614273197794
Validation loss: 2.6263207903545176

Epoch: 5| Step: 8
Training loss: 3.1307433184782636
Validation loss: 2.661108768742495

Epoch: 5| Step: 9
Training loss: 2.9788020162006723
Validation loss: 2.667864247625148

Epoch: 5| Step: 10
Training loss: 3.174273406263998
Validation loss: 2.664487801007711

Epoch: 274| Step: 0
Training loss: 2.8135064761350135
Validation loss: 2.616825731742592

Epoch: 5| Step: 1
Training loss: 2.681384736345958
Validation loss: 2.588164478934017

Epoch: 5| Step: 2
Training loss: 2.6712800194459696
Validation loss: 2.5725503532623666

Epoch: 5| Step: 3
Training loss: 2.742713117082198
Validation loss: 2.5638823643538795

Epoch: 5| Step: 4
Training loss: 3.036683237286722
Validation loss: 2.552423389139185

Epoch: 5| Step: 5
Training loss: 3.1696850963825245
Validation loss: 2.5445118423014916

Epoch: 5| Step: 6
Training loss: 2.7230723431153723
Validation loss: 2.542989808720246

Epoch: 5| Step: 7
Training loss: 2.7899947117854493
Validation loss: 2.5424426740154793

Epoch: 5| Step: 8
Training loss: 2.7892166223336776
Validation loss: 2.5464919040142155

Epoch: 5| Step: 9
Training loss: 2.6896521356845446
Validation loss: 2.535707538038092

Epoch: 5| Step: 10
Training loss: 2.901847375906286
Validation loss: 2.540829761957208

Epoch: 275| Step: 0
Training loss: 2.8221194747517244
Validation loss: 2.547739323781834

Epoch: 5| Step: 1
Training loss: 2.676473129927175
Validation loss: 2.554786056298844

Epoch: 5| Step: 2
Training loss: 3.117625270305879
Validation loss: 2.582714721916473

Epoch: 5| Step: 3
Training loss: 2.488215039867986
Validation loss: 2.6107212921630976

Epoch: 5| Step: 4
Training loss: 3.071979720386484
Validation loss: 2.625460447095863

Epoch: 5| Step: 5
Training loss: 2.5139445503025417
Validation loss: 2.638445358552953

Epoch: 5| Step: 6
Training loss: 2.525689221731226
Validation loss: 2.644420674603462

Epoch: 5| Step: 7
Training loss: 2.834354684035601
Validation loss: 2.646284619299144

Epoch: 5| Step: 8
Training loss: 3.0972667704192927
Validation loss: 2.6217774075628886

Epoch: 5| Step: 9
Training loss: 2.760598998375893
Validation loss: 2.623761169913683

Epoch: 5| Step: 10
Training loss: 3.171402017440486
Validation loss: 2.5987998885663126

Epoch: 276| Step: 0
Training loss: 2.842795746380603
Validation loss: 2.5680295668434465

Epoch: 5| Step: 1
Training loss: 2.8059892529032338
Validation loss: 2.540981001199238

Epoch: 5| Step: 2
Training loss: 3.1382443339213806
Validation loss: 2.538190283005819

Epoch: 5| Step: 3
Training loss: 2.6764999426876113
Validation loss: 2.534987465089484

Epoch: 5| Step: 4
Training loss: 2.533213854364807
Validation loss: 2.5380835537372395

Epoch: 5| Step: 5
Training loss: 3.175862028589055
Validation loss: 2.5383402499047443

Epoch: 5| Step: 6
Training loss: 2.7660343707715036
Validation loss: 2.5350095700558666

Epoch: 5| Step: 7
Training loss: 2.8964078228146692
Validation loss: 2.55664354096036

Epoch: 5| Step: 8
Training loss: 2.166173463097774
Validation loss: 2.5618675445888544

Epoch: 5| Step: 9
Training loss: 3.0614614477376465
Validation loss: 2.561699018491939

Epoch: 5| Step: 10
Training loss: 2.8447446655577435
Validation loss: 2.578827860544272

Epoch: 277| Step: 0
Training loss: 2.9867442048884216
Validation loss: 2.594030600061019

Epoch: 5| Step: 1
Training loss: 2.7581758340853066
Validation loss: 2.6153395580147105

Epoch: 5| Step: 2
Training loss: 2.847837591480373
Validation loss: 2.6446764348673204

Epoch: 5| Step: 3
Training loss: 2.6971013863714317
Validation loss: 2.674905350591655

Epoch: 5| Step: 4
Training loss: 2.958524420212738
Validation loss: 2.678436289502015

Epoch: 5| Step: 5
Training loss: 2.9378515804188163
Validation loss: 2.6471773576868824

Epoch: 5| Step: 6
Training loss: 2.781568016129919
Validation loss: 2.621192555784031

Epoch: 5| Step: 7
Training loss: 2.748800709782732
Validation loss: 2.603849059559128

Epoch: 5| Step: 8
Training loss: 2.609614561128484
Validation loss: 2.5727250481727317

Epoch: 5| Step: 9
Training loss: 3.0081344630340032
Validation loss: 2.5728857387201542

Epoch: 5| Step: 10
Training loss: 2.681582745443519
Validation loss: 2.5573859978799036

Epoch: 278| Step: 0
Training loss: 2.759925270727452
Validation loss: 2.544271082549629

Epoch: 5| Step: 1
Training loss: 3.0940542360470324
Validation loss: 2.5458534920518683

Epoch: 5| Step: 2
Training loss: 2.5284665663268067
Validation loss: 2.536933045087785

Epoch: 5| Step: 3
Training loss: 2.704788137378421
Validation loss: 2.528500583833509

Epoch: 5| Step: 4
Training loss: 2.63917826911858
Validation loss: 2.5222170838875932

Epoch: 5| Step: 5
Training loss: 2.704493270061665
Validation loss: 2.5342937173770976

Epoch: 5| Step: 6
Training loss: 3.3696372199691855
Validation loss: 2.535983488911482

Epoch: 5| Step: 7
Training loss: 2.8301081158909525
Validation loss: 2.5628287832018675

Epoch: 5| Step: 8
Training loss: 2.452025343199251
Validation loss: 2.5800905532825107

Epoch: 5| Step: 9
Training loss: 2.7980668070018115
Validation loss: 2.617833312543518

Epoch: 5| Step: 10
Training loss: 3.278158711713722
Validation loss: 2.609438492531376

Epoch: 279| Step: 0
Training loss: 3.2280793030745816
Validation loss: 2.6028809698982793

Epoch: 5| Step: 1
Training loss: 2.6738118964650863
Validation loss: 2.5958071419884465

Epoch: 5| Step: 2
Training loss: 2.8117586642328805
Validation loss: 2.577670843719112

Epoch: 5| Step: 3
Training loss: 3.1363680252728017
Validation loss: 2.5909177248847337

Epoch: 5| Step: 4
Training loss: 2.636314078466108
Validation loss: 2.594924885030201

Epoch: 5| Step: 5
Training loss: 2.5740725022770357
Validation loss: 2.5770596517738373

Epoch: 5| Step: 6
Training loss: 2.2169704554150256
Validation loss: 2.5928891608267417

Epoch: 5| Step: 7
Training loss: 2.346447828810621
Validation loss: 2.60500416305934

Epoch: 5| Step: 8
Training loss: 3.3711398619927073
Validation loss: 2.606510143212744

Epoch: 5| Step: 9
Training loss: 2.826135599553388
Validation loss: 2.6188670079064407

Epoch: 5| Step: 10
Training loss: 2.7712265443131865
Validation loss: 2.600869341623545

Epoch: 280| Step: 0
Training loss: 2.943773105150003
Validation loss: 2.5885911994024906

Epoch: 5| Step: 1
Training loss: 2.724811417939998
Validation loss: 2.5629260051465663

Epoch: 5| Step: 2
Training loss: 2.6025769887597705
Validation loss: 2.544579420147884

Epoch: 5| Step: 3
Training loss: 2.682732634113753
Validation loss: 2.5595826039858736

Epoch: 5| Step: 4
Training loss: 2.8952711552211925
Validation loss: 2.5561041109100726

Epoch: 5| Step: 5
Training loss: 2.6217663238881483
Validation loss: 2.551350984516898

Epoch: 5| Step: 6
Training loss: 2.584081992498984
Validation loss: 2.5748515080200987

Epoch: 5| Step: 7
Training loss: 2.346278746504521
Validation loss: 2.5840667251884266

Epoch: 5| Step: 8
Training loss: 3.403372713011232
Validation loss: 2.5918128861014833

Epoch: 5| Step: 9
Training loss: 2.650351044057802
Validation loss: 2.6397098810613797

Epoch: 5| Step: 10
Training loss: 3.2707641173083357
Validation loss: 2.64343714582574

Epoch: 281| Step: 0
Training loss: 2.2273836462113277
Validation loss: 2.6324231868435364

Epoch: 5| Step: 1
Training loss: 2.7201622988861334
Validation loss: 2.584641466448536

Epoch: 5| Step: 2
Training loss: 2.8966738535356935
Validation loss: 2.5674526565963145

Epoch: 5| Step: 3
Training loss: 3.1079498552182705
Validation loss: 2.559116245360401

Epoch: 5| Step: 4
Training loss: 2.9357473136202836
Validation loss: 2.5515641078345213

Epoch: 5| Step: 5
Training loss: 3.3509428434036743
Validation loss: 2.5395061923723254

Epoch: 5| Step: 6
Training loss: 2.6153080355104383
Validation loss: 2.53085391197855

Epoch: 5| Step: 7
Training loss: 2.829464421360192
Validation loss: 2.5425541574136483

Epoch: 5| Step: 8
Training loss: 2.7147994881733584
Validation loss: 2.5317321646264612

Epoch: 5| Step: 9
Training loss: 3.1557415845447947
Validation loss: 2.5461790723304243

Epoch: 5| Step: 10
Training loss: 2.3766201917679632
Validation loss: 2.5445309266295757

Epoch: 282| Step: 0
Training loss: 2.871787224923597
Validation loss: 2.549384639089962

Epoch: 5| Step: 1
Training loss: 3.246394578419121
Validation loss: 2.563038613063554

Epoch: 5| Step: 2
Training loss: 2.809502254400318
Validation loss: 2.5781042352351657

Epoch: 5| Step: 3
Training loss: 2.7381570001511615
Validation loss: 2.6083732235780053

Epoch: 5| Step: 4
Training loss: 2.7822069386318726
Validation loss: 2.6429156111920595

Epoch: 5| Step: 5
Training loss: 2.739290103280041
Validation loss: 2.6746941923849774

Epoch: 5| Step: 6
Training loss: 2.932084631287811
Validation loss: 2.6855080986020203

Epoch: 5| Step: 7
Training loss: 2.9593267966577304
Validation loss: 2.673683113613427

Epoch: 5| Step: 8
Training loss: 2.8970430623739483
Validation loss: 2.6300498411871773

Epoch: 5| Step: 9
Training loss: 2.131424784275286
Validation loss: 2.5586592245597375

Epoch: 5| Step: 10
Training loss: 2.909166410940249
Validation loss: 2.5465313958794313

Epoch: 283| Step: 0
Training loss: 2.7314504624046463
Validation loss: 2.5400550516506084

Epoch: 5| Step: 1
Training loss: 3.277416205713524
Validation loss: 2.5382510131808123

Epoch: 5| Step: 2
Training loss: 2.5011847549766952
Validation loss: 2.541400015561302

Epoch: 5| Step: 3
Training loss: 2.697847981603493
Validation loss: 2.5339475523299604

Epoch: 5| Step: 4
Training loss: 2.9721984109687294
Validation loss: 2.525730285295797

Epoch: 5| Step: 5
Training loss: 2.7353737015459836
Validation loss: 2.5181530312319493

Epoch: 5| Step: 6
Training loss: 3.3082152671469522
Validation loss: 2.523350510348236

Epoch: 5| Step: 7
Training loss: 2.682754674164999
Validation loss: 2.5311548080177833

Epoch: 5| Step: 8
Training loss: 2.8511835551933995
Validation loss: 2.5604624457218286

Epoch: 5| Step: 9
Training loss: 2.9152919435957085
Validation loss: 2.6110933268390943

Epoch: 5| Step: 10
Training loss: 2.5938139758205696
Validation loss: 2.61064333563118

Epoch: 284| Step: 0
Training loss: 2.680449263508254
Validation loss: 2.626891413308912

Epoch: 5| Step: 1
Training loss: 2.668515061483037
Validation loss: 2.6162400150672465

Epoch: 5| Step: 2
Training loss: 2.3350538540823513
Validation loss: 2.586604578400292

Epoch: 5| Step: 3
Training loss: 2.3047330172941636
Validation loss: 2.5957291148233113

Epoch: 5| Step: 4
Training loss: 3.139277382574087
Validation loss: 2.5685427608934823

Epoch: 5| Step: 5
Training loss: 2.825646088573566
Validation loss: 2.572884952555133

Epoch: 5| Step: 6
Training loss: 2.4290258359135755
Validation loss: 2.573727760905951

Epoch: 5| Step: 7
Training loss: 3.0095431810644295
Validation loss: 2.5667813908566224

Epoch: 5| Step: 8
Training loss: 3.0818527034586567
Validation loss: 2.5843049569812266

Epoch: 5| Step: 9
Training loss: 3.2006685095110803
Validation loss: 2.575103376220822

Epoch: 5| Step: 10
Training loss: 2.852772077311023
Validation loss: 2.582454038210459

Epoch: 285| Step: 0
Training loss: 3.104926986941606
Validation loss: 2.625207159381311

Epoch: 5| Step: 1
Training loss: 3.0310404596954075
Validation loss: 2.6371911572229503

Epoch: 5| Step: 2
Training loss: 2.4796867038891386
Validation loss: 2.6188166051945583

Epoch: 5| Step: 3
Training loss: 2.829553232951787
Validation loss: 2.641739779560088

Epoch: 5| Step: 4
Training loss: 3.009953675531438
Validation loss: 2.667487627284758

Epoch: 5| Step: 5
Training loss: 2.7343165800120883
Validation loss: 2.6386905037171573

Epoch: 5| Step: 6
Training loss: 2.3900996609582505
Validation loss: 2.5753619450490146

Epoch: 5| Step: 7
Training loss: 3.348909337153534
Validation loss: 2.552780990889872

Epoch: 5| Step: 8
Training loss: 2.503764846308281
Validation loss: 2.5331242169283894

Epoch: 5| Step: 9
Training loss: 2.6838408999069197
Validation loss: 2.532121038266333

Epoch: 5| Step: 10
Training loss: 2.40703886898213
Validation loss: 2.523550197856085

Epoch: 286| Step: 0
Training loss: 2.7905009858362577
Validation loss: 2.5352056888338277

Epoch: 5| Step: 1
Training loss: 3.1494679622325727
Validation loss: 2.5478798042812785

Epoch: 5| Step: 2
Training loss: 2.655609143309231
Validation loss: 2.5515879284354264

Epoch: 5| Step: 3
Training loss: 2.3722354459232697
Validation loss: 2.565275542436886

Epoch: 5| Step: 4
Training loss: 2.576907523553907
Validation loss: 2.5740258486934784

Epoch: 5| Step: 5
Training loss: 3.2201614988592344
Validation loss: 2.5879069881653254

Epoch: 5| Step: 6
Training loss: 2.9629487224960736
Validation loss: 2.623937936426814

Epoch: 5| Step: 7
Training loss: 2.7085302036820287
Validation loss: 2.655566712141475

Epoch: 5| Step: 8
Training loss: 2.8246945815277718
Validation loss: 2.6595065003526734

Epoch: 5| Step: 9
Training loss: 2.432471737672945
Validation loss: 2.6551103032547476

Epoch: 5| Step: 10
Training loss: 3.0041554599364226
Validation loss: 2.6643615887723393

Epoch: 287| Step: 0
Training loss: 2.766223303954344
Validation loss: 2.6705957111169747

Epoch: 5| Step: 1
Training loss: 2.756836629361408
Validation loss: 2.6054472851289154

Epoch: 5| Step: 2
Training loss: 3.0608192035429576
Validation loss: 2.5729490964540536

Epoch: 5| Step: 3
Training loss: 2.7949247753413498
Validation loss: 2.5479490852730167

Epoch: 5| Step: 4
Training loss: 3.024427148472255
Validation loss: 2.547747460236331

Epoch: 5| Step: 5
Training loss: 2.7740265556500026
Validation loss: 2.5463657158091326

Epoch: 5| Step: 6
Training loss: 2.839127860946601
Validation loss: 2.54802730384054

Epoch: 5| Step: 7
Training loss: 2.4707233895537533
Validation loss: 2.5416635876063176

Epoch: 5| Step: 8
Training loss: 2.8157199653081038
Validation loss: 2.546205866189724

Epoch: 5| Step: 9
Training loss: 2.476465746797693
Validation loss: 2.5613211604682427

Epoch: 5| Step: 10
Training loss: 2.85893371178553
Validation loss: 2.562285324496552

Epoch: 288| Step: 0
Training loss: 2.700700322914761
Validation loss: 2.5799327211732805

Epoch: 5| Step: 1
Training loss: 2.325131738683614
Validation loss: 2.5812009547770773

Epoch: 5| Step: 2
Training loss: 2.8734959524327612
Validation loss: 2.5930130909153317

Epoch: 5| Step: 3
Training loss: 3.1637306321906618
Validation loss: 2.5704923167214253

Epoch: 5| Step: 4
Training loss: 3.0598177939128663
Validation loss: 2.5738611784777916

Epoch: 5| Step: 5
Training loss: 2.6048562217763016
Validation loss: 2.5620340163207302

Epoch: 5| Step: 6
Training loss: 2.4172890837221406
Validation loss: 2.541750361010861

Epoch: 5| Step: 7
Training loss: 2.790808977681641
Validation loss: 2.5482919459299676

Epoch: 5| Step: 8
Training loss: 2.476295240163232
Validation loss: 2.5384306292589796

Epoch: 5| Step: 9
Training loss: 3.0570858177191256
Validation loss: 2.5643324723990513

Epoch: 5| Step: 10
Training loss: 3.0126418147600167
Validation loss: 2.6133406256031324

Epoch: 289| Step: 0
Training loss: 2.5526934666409415
Validation loss: 2.659656114261022

Epoch: 5| Step: 1
Training loss: 2.270603366604899
Validation loss: 2.6747916277604458

Epoch: 5| Step: 2
Training loss: 2.6912545879801524
Validation loss: 2.6528150330756355

Epoch: 5| Step: 3
Training loss: 2.852281788027864
Validation loss: 2.709060653321315

Epoch: 5| Step: 4
Training loss: 2.961430571474382
Validation loss: 2.685410055394882

Epoch: 5| Step: 5
Training loss: 2.858043089459726
Validation loss: 2.616776088653736

Epoch: 5| Step: 6
Training loss: 2.8158076863185393
Validation loss: 2.5559496110598716

Epoch: 5| Step: 7
Training loss: 3.2043335658252277
Validation loss: 2.5385635842473495

Epoch: 5| Step: 8
Training loss: 3.1109625822518963
Validation loss: 2.5282904965399693

Epoch: 5| Step: 9
Training loss: 2.697429146529954
Validation loss: 2.5375599150749943

Epoch: 5| Step: 10
Training loss: 2.914721212518292
Validation loss: 2.534132972229963

Epoch: 290| Step: 0
Training loss: 2.9146192903370727
Validation loss: 2.555415416799815

Epoch: 5| Step: 1
Training loss: 2.6751398139138103
Validation loss: 2.5666449533776494

Epoch: 5| Step: 2
Training loss: 2.731891572439894
Validation loss: 2.6029573309416403

Epoch: 5| Step: 3
Training loss: 2.9393462202839857
Validation loss: 2.634254183291967

Epoch: 5| Step: 4
Training loss: 2.923139492322792
Validation loss: 2.631115270636811

Epoch: 5| Step: 5
Training loss: 2.727467034382821
Validation loss: 2.6361114349449175

Epoch: 5| Step: 6
Training loss: 3.07832297061263
Validation loss: 2.5965484475030127

Epoch: 5| Step: 7
Training loss: 2.945314604659808
Validation loss: 2.5992358228467842

Epoch: 5| Step: 8
Training loss: 2.5722349450346242
Validation loss: 2.5932164054135987

Epoch: 5| Step: 9
Training loss: 2.8025235724840236
Validation loss: 2.618613200895457

Epoch: 5| Step: 10
Training loss: 2.7279169167147104
Validation loss: 2.633575129386183

Epoch: 291| Step: 0
Training loss: 2.7946711547059624
Validation loss: 2.64862126990477

Epoch: 5| Step: 1
Training loss: 2.9832924681977904
Validation loss: 2.663749459191929

Epoch: 5| Step: 2
Training loss: 2.8530306446396487
Validation loss: 2.649530089869621

Epoch: 5| Step: 3
Training loss: 2.310121085886521
Validation loss: 2.658744423508466

Epoch: 5| Step: 4
Training loss: 2.7714305224573295
Validation loss: 2.621868163837692

Epoch: 5| Step: 5
Training loss: 2.782200854347706
Validation loss: 2.6106248347658743

Epoch: 5| Step: 6
Training loss: 2.502026118360967
Validation loss: 2.5865253013032

Epoch: 5| Step: 7
Training loss: 2.933048365217921
Validation loss: 2.5629174367437533

Epoch: 5| Step: 8
Training loss: 2.789315690374406
Validation loss: 2.5412013715481248

Epoch: 5| Step: 9
Training loss: 2.9261544451781987
Validation loss: 2.5311095404991972

Epoch: 5| Step: 10
Training loss: 3.117976879853862
Validation loss: 2.5285560951308286

Epoch: 292| Step: 0
Training loss: 2.934706638108452
Validation loss: 2.5262568772975915

Epoch: 5| Step: 1
Training loss: 2.798022498323244
Validation loss: 2.5302506974245103

Epoch: 5| Step: 2
Training loss: 2.583546619429505
Validation loss: 2.529544070633607

Epoch: 5| Step: 3
Training loss: 3.2572969536432916
Validation loss: 2.534380506413399

Epoch: 5| Step: 4
Training loss: 2.8538541599535496
Validation loss: 2.543083188216989

Epoch: 5| Step: 5
Training loss: 2.6232712820809954
Validation loss: 2.5693338880521686

Epoch: 5| Step: 6
Training loss: 2.5732748011453173
Validation loss: 2.6090750907237754

Epoch: 5| Step: 7
Training loss: 2.729362034296259
Validation loss: 2.6480635652691595

Epoch: 5| Step: 8
Training loss: 2.9423084268621773
Validation loss: 2.7489610743644883

Epoch: 5| Step: 9
Training loss: 2.965521412076365
Validation loss: 2.740504433102152

Epoch: 5| Step: 10
Training loss: 2.275006254418128
Validation loss: 2.6957047134144787

Epoch: 293| Step: 0
Training loss: 2.957577210270581
Validation loss: 2.6455862872887783

Epoch: 5| Step: 1
Training loss: 2.849196866293719
Validation loss: 2.6385229221439257

Epoch: 5| Step: 2
Training loss: 1.9033007084955964
Validation loss: 2.591043728116124

Epoch: 5| Step: 3
Training loss: 2.862208895477851
Validation loss: 2.582484405181101

Epoch: 5| Step: 4
Training loss: 3.1993323225605472
Validation loss: 2.554859580189292

Epoch: 5| Step: 5
Training loss: 2.6211284060965685
Validation loss: 2.548467437603907

Epoch: 5| Step: 6
Training loss: 3.0371238192984493
Validation loss: 2.532260862573212

Epoch: 5| Step: 7
Training loss: 2.6494618463196935
Validation loss: 2.5312495523439957

Epoch: 5| Step: 8
Training loss: 2.8350606776611516
Validation loss: 2.5283370936457685

Epoch: 5| Step: 9
Training loss: 2.5169714884122594
Validation loss: 2.5306718278148885

Epoch: 5| Step: 10
Training loss: 2.894151176179056
Validation loss: 2.540219656738753

Epoch: 294| Step: 0
Training loss: 3.044831358400434
Validation loss: 2.5420032206447223

Epoch: 5| Step: 1
Training loss: 2.768676712065061
Validation loss: 2.544966399716447

Epoch: 5| Step: 2
Training loss: 3.3500576242074187
Validation loss: 2.5733204581596207

Epoch: 5| Step: 3
Training loss: 2.5101489060143405
Validation loss: 2.587998007993814

Epoch: 5| Step: 4
Training loss: 2.301377120519014
Validation loss: 2.604300770577887

Epoch: 5| Step: 5
Training loss: 2.9202278920954887
Validation loss: 2.6005816897124685

Epoch: 5| Step: 6
Training loss: 2.9292520835291493
Validation loss: 2.610345685574052

Epoch: 5| Step: 7
Training loss: 2.2098638401117605
Validation loss: 2.5889098315226846

Epoch: 5| Step: 8
Training loss: 2.7331403288115887
Validation loss: 2.566091828911145

Epoch: 5| Step: 9
Training loss: 2.846265078887065
Validation loss: 2.5542359733469446

Epoch: 5| Step: 10
Training loss: 2.552431189256845
Validation loss: 2.543504154317953

Epoch: 295| Step: 0
Training loss: 2.445532060705098
Validation loss: 2.5589580192353707

Epoch: 5| Step: 1
Training loss: 2.403988456622193
Validation loss: 2.565164198026437

Epoch: 5| Step: 2
Training loss: 2.83121149234816
Validation loss: 2.581027623196941

Epoch: 5| Step: 3
Training loss: 2.534015134198669
Validation loss: 2.585982720304632

Epoch: 5| Step: 4
Training loss: 2.892905825250717
Validation loss: 2.5790926919814026

Epoch: 5| Step: 5
Training loss: 2.655968236003661
Validation loss: 2.563061125251271

Epoch: 5| Step: 6
Training loss: 2.9575489956561234
Validation loss: 2.5678563395545626

Epoch: 5| Step: 7
Training loss: 3.2529291011520036
Validation loss: 2.554536455048216

Epoch: 5| Step: 8
Training loss: 3.1852780245608074
Validation loss: 2.5434902137821225

Epoch: 5| Step: 9
Training loss: 2.1264392242465013
Validation loss: 2.551374188648489

Epoch: 5| Step: 10
Training loss: 2.902032396499817
Validation loss: 2.5665119777624086

Epoch: 296| Step: 0
Training loss: 2.571697105661042
Validation loss: 2.580850859937433

Epoch: 5| Step: 1
Training loss: 2.408044715491521
Validation loss: 2.601704726217258

Epoch: 5| Step: 2
Training loss: 2.8356760288058718
Validation loss: 2.630845463716553

Epoch: 5| Step: 3
Training loss: 3.0268355798290956
Validation loss: 2.697804620218144

Epoch: 5| Step: 4
Training loss: 2.929522944597356
Validation loss: 2.653025142944747

Epoch: 5| Step: 5
Training loss: 2.663010106897316
Validation loss: 2.62206890361057

Epoch: 5| Step: 6
Training loss: 3.0125816682374427
Validation loss: 2.5525581090683844

Epoch: 5| Step: 7
Training loss: 2.8213558222133397
Validation loss: 2.5456630214461873

Epoch: 5| Step: 8
Training loss: 2.947286334006104
Validation loss: 2.5307036447885616

Epoch: 5| Step: 9
Training loss: 2.0049734266998307
Validation loss: 2.5217338308920474

Epoch: 5| Step: 10
Training loss: 3.0138497142521317
Validation loss: 2.5198401217667934

Epoch: 297| Step: 0
Training loss: 2.7927597714650076
Validation loss: 2.5251388602593337

Epoch: 5| Step: 1
Training loss: 2.7780068165343264
Validation loss: 2.5160480098521134

Epoch: 5| Step: 2
Training loss: 2.6104597018612457
Validation loss: 2.532249689790468

Epoch: 5| Step: 3
Training loss: 2.9367962257940845
Validation loss: 2.5594402687296314

Epoch: 5| Step: 4
Training loss: 3.075437970489268
Validation loss: 2.5717144800017464

Epoch: 5| Step: 5
Training loss: 2.727575775128864
Validation loss: 2.5891762318366753

Epoch: 5| Step: 6
Training loss: 2.4747965680912603
Validation loss: 2.569331762771045

Epoch: 5| Step: 7
Training loss: 2.9038197190203268
Validation loss: 2.576871615129193

Epoch: 5| Step: 8
Training loss: 2.388784260885891
Validation loss: 2.565323278549768

Epoch: 5| Step: 9
Training loss: 2.8898146034620997
Validation loss: 2.56177867258187

Epoch: 5| Step: 10
Training loss: 2.733078741994571
Validation loss: 2.5905739040761966

Epoch: 298| Step: 0
Training loss: 3.2387207616489624
Validation loss: 2.6210126321291343

Epoch: 5| Step: 1
Training loss: 2.4475884616595427
Validation loss: 2.654491529189447

Epoch: 5| Step: 2
Training loss: 2.7109891243452298
Validation loss: 2.6849887797955194

Epoch: 5| Step: 3
Training loss: 2.6216360972231496
Validation loss: 2.6621334925384645

Epoch: 5| Step: 4
Training loss: 2.94645980223911
Validation loss: 2.626309864465561

Epoch: 5| Step: 5
Training loss: 2.6984662609412013
Validation loss: 2.600787567823072

Epoch: 5| Step: 6
Training loss: 2.387184909180455
Validation loss: 2.5841223493929895

Epoch: 5| Step: 7
Training loss: 2.989905540479701
Validation loss: 2.595760429671558

Epoch: 5| Step: 8
Training loss: 3.0850734611680193
Validation loss: 2.603369769494391

Epoch: 5| Step: 9
Training loss: 2.364037662231913
Validation loss: 2.598961478337946

Epoch: 5| Step: 10
Training loss: 2.592018468679164
Validation loss: 2.59078845505419

Epoch: 299| Step: 0
Training loss: 2.819423715132087
Validation loss: 2.6007208891245432

Epoch: 5| Step: 1
Training loss: 2.480631184703588
Validation loss: 2.590930356453949

Epoch: 5| Step: 2
Training loss: 2.557448921625778
Validation loss: 2.588718707264702

Epoch: 5| Step: 3
Training loss: 2.402206094411059
Validation loss: 2.624972059586562

Epoch: 5| Step: 4
Training loss: 2.7650918392774355
Validation loss: 2.6458571034640195

Epoch: 5| Step: 5
Training loss: 3.084495342654915
Validation loss: 2.6466658976895667

Epoch: 5| Step: 6
Training loss: 2.6635503640229916
Validation loss: 2.6168921166664316

Epoch: 5| Step: 7
Training loss: 2.848113349051939
Validation loss: 2.5543955256964077

Epoch: 5| Step: 8
Training loss: 2.8724875044986664
Validation loss: 2.546285071121918

Epoch: 5| Step: 9
Training loss: 3.339811483305391
Validation loss: 2.5280452217025733

Epoch: 5| Step: 10
Training loss: 2.446518378255185
Validation loss: 2.5181675131489434

Epoch: 300| Step: 0
Training loss: 2.949071130152795
Validation loss: 2.5327882406025877

Epoch: 5| Step: 1
Training loss: 2.771471557157419
Validation loss: 2.5478280656789716

Epoch: 5| Step: 2
Training loss: 2.19341100698217
Validation loss: 2.591820811001263

Epoch: 5| Step: 3
Training loss: 2.962357716423064
Validation loss: 2.597569903236173

Epoch: 5| Step: 4
Training loss: 2.9135375176405773
Validation loss: 2.6288330197623693

Epoch: 5| Step: 5
Training loss: 2.5271214854690576
Validation loss: 2.6195425385112956

Epoch: 5| Step: 6
Training loss: 2.88164482142249
Validation loss: 2.6356436197896413

Epoch: 5| Step: 7
Training loss: 2.600815124382789
Validation loss: 2.5880398530785182

Epoch: 5| Step: 8
Training loss: 2.5181803549000787
Validation loss: 2.6134027887248137

Epoch: 5| Step: 9
Training loss: 2.9698193682062466
Validation loss: 2.646748184455547

Epoch: 5| Step: 10
Training loss: 2.8199577636802347
Validation loss: 2.648655658738643

Epoch: 301| Step: 0
Training loss: 2.5993843927050917
Validation loss: 2.692338440415354

Epoch: 5| Step: 1
Training loss: 2.5317148794271622
Validation loss: 2.6977034811714744

Epoch: 5| Step: 2
Training loss: 2.6342216365605386
Validation loss: 2.676562282538613

Epoch: 5| Step: 3
Training loss: 2.7598784491821835
Validation loss: 2.6748855364689663

Epoch: 5| Step: 4
Training loss: 2.556803255904587
Validation loss: 2.6613183981818143

Epoch: 5| Step: 5
Training loss: 2.381463641497629
Validation loss: 2.59013559838906

Epoch: 5| Step: 6
Training loss: 3.2001747500865183
Validation loss: 2.5539864919906257

Epoch: 5| Step: 7
Training loss: 2.9292890354025647
Validation loss: 2.534348081122065

Epoch: 5| Step: 8
Training loss: 2.3466256366018277
Validation loss: 2.523834977447131

Epoch: 5| Step: 9
Training loss: 3.2187116305832757
Validation loss: 2.5292012106495454

Epoch: 5| Step: 10
Training loss: 2.837559427991818
Validation loss: 2.5327530756653864

Epoch: 302| Step: 0
Training loss: 2.848389414738723
Validation loss: 2.5327743787431487

Epoch: 5| Step: 1
Training loss: 3.148648011243247
Validation loss: 2.5403635755161984

Epoch: 5| Step: 2
Training loss: 2.7665612311744345
Validation loss: 2.544733722273505

Epoch: 5| Step: 3
Training loss: 2.8945467352613785
Validation loss: 2.5587765433374883

Epoch: 5| Step: 4
Training loss: 2.497289618871075
Validation loss: 2.5617396799651377

Epoch: 5| Step: 5
Training loss: 2.9756096543811963
Validation loss: 2.606173726736307

Epoch: 5| Step: 6
Training loss: 2.7366568499291093
Validation loss: 2.681459570246907

Epoch: 5| Step: 7
Training loss: 2.5532255043222545
Validation loss: 2.7066499998910176

Epoch: 5| Step: 8
Training loss: 3.310880733073557
Validation loss: 2.6616767437441724

Epoch: 5| Step: 9
Training loss: 2.4627858804426572
Validation loss: 2.586962129682424

Epoch: 5| Step: 10
Training loss: 2.599797013501934
Validation loss: 2.551268077735508

Epoch: 303| Step: 0
Training loss: 2.7831291108579705
Validation loss: 2.520303655463069

Epoch: 5| Step: 1
Training loss: 2.373212643708587
Validation loss: 2.515866273063568

Epoch: 5| Step: 2
Training loss: 2.7764627639469146
Validation loss: 2.511366258185207

Epoch: 5| Step: 3
Training loss: 3.189387790924145
Validation loss: 2.5132029078126084

Epoch: 5| Step: 4
Training loss: 2.15700805165252
Validation loss: 2.516300705559606

Epoch: 5| Step: 5
Training loss: 2.5394631407170105
Validation loss: 2.539501541584996

Epoch: 5| Step: 6
Training loss: 2.502631900142789
Validation loss: 2.5481285222927585

Epoch: 5| Step: 7
Training loss: 2.8401825714528584
Validation loss: 2.551191425653826

Epoch: 5| Step: 8
Training loss: 3.201118101048881
Validation loss: 2.5638325430674818

Epoch: 5| Step: 9
Training loss: 3.0691697029832756
Validation loss: 2.570465299785533

Epoch: 5| Step: 10
Training loss: 3.122582530510775
Validation loss: 2.5708284473304617

Epoch: 304| Step: 0
Training loss: 2.938349986369054
Validation loss: 2.573843797711296

Epoch: 5| Step: 1
Training loss: 2.5982274395511875
Validation loss: 2.599763247499336

Epoch: 5| Step: 2
Training loss: 2.8849271136354155
Validation loss: 2.6379200186710166

Epoch: 5| Step: 3
Training loss: 2.877438216221399
Validation loss: 2.6184541602958418

Epoch: 5| Step: 4
Training loss: 2.4267892509281497
Validation loss: 2.6399184362552934

Epoch: 5| Step: 5
Training loss: 3.1397141991071726
Validation loss: 2.5986759098839673

Epoch: 5| Step: 6
Training loss: 2.395221156539185
Validation loss: 2.5775507849614776

Epoch: 5| Step: 7
Training loss: 2.611798286196842
Validation loss: 2.5661150336192313

Epoch: 5| Step: 8
Training loss: 3.0270806967366535
Validation loss: 2.5584217576395525

Epoch: 5| Step: 9
Training loss: 2.40060754079908
Validation loss: 2.552383754410478

Epoch: 5| Step: 10
Training loss: 3.145558140993675
Validation loss: 2.529631027692626

Epoch: 305| Step: 0
Training loss: 2.8742727935595944
Validation loss: 2.5409812715891595

Epoch: 5| Step: 1
Training loss: 3.170716774227197
Validation loss: 2.546619680554061

Epoch: 5| Step: 2
Training loss: 2.3582164623116504
Validation loss: 2.5973934060651134

Epoch: 5| Step: 3
Training loss: 2.980971547684249
Validation loss: 2.6241556021484205

Epoch: 5| Step: 4
Training loss: 3.1034046919089837
Validation loss: 2.6788382833542705

Epoch: 5| Step: 5
Training loss: 3.0485475302293357
Validation loss: 2.583125213895924

Epoch: 5| Step: 6
Training loss: 2.496376272340175
Validation loss: 2.5441159306062606

Epoch: 5| Step: 7
Training loss: 2.119831194184952
Validation loss: 2.5312798368031624

Epoch: 5| Step: 8
Training loss: 3.015799878045449
Validation loss: 2.5271735536533955

Epoch: 5| Step: 9
Training loss: 3.008351146472665
Validation loss: 2.511892534805352

Epoch: 5| Step: 10
Training loss: 2.213290522670745
Validation loss: 2.5076228760663946

Epoch: 306| Step: 0
Training loss: 2.9683137271953988
Validation loss: 2.504331792070837

Epoch: 5| Step: 1
Training loss: 3.0111724714320105
Validation loss: 2.5174975983636063

Epoch: 5| Step: 2
Training loss: 2.774752968454977
Validation loss: 2.5253004154693333

Epoch: 5| Step: 3
Training loss: 2.606503488485262
Validation loss: 2.543657602002351

Epoch: 5| Step: 4
Training loss: 2.4883360564755024
Validation loss: 2.564454562543999

Epoch: 5| Step: 5
Training loss: 2.4017496010065367
Validation loss: 2.5686019849627093

Epoch: 5| Step: 6
Training loss: 2.8331789834858334
Validation loss: 2.583641228072971

Epoch: 5| Step: 7
Training loss: 2.6638339215882434
Validation loss: 2.5764340759365063

Epoch: 5| Step: 8
Training loss: 3.305391998590071
Validation loss: 2.6065783340110844

Epoch: 5| Step: 9
Training loss: 1.9904770034078718
Validation loss: 2.6147531407601403

Epoch: 5| Step: 10
Training loss: 2.7914025670477556
Validation loss: 2.6357187437408434

Epoch: 307| Step: 0
Training loss: 3.013482948853739
Validation loss: 2.6413506602206875

Epoch: 5| Step: 1
Training loss: 2.6754721358574742
Validation loss: 2.6346301743304146

Epoch: 5| Step: 2
Training loss: 2.573629169934861
Validation loss: 2.640520181485053

Epoch: 5| Step: 3
Training loss: 2.3841974954790826
Validation loss: 2.6203687365768826

Epoch: 5| Step: 4
Training loss: 2.4291876864518973
Validation loss: 2.6031842517785333

Epoch: 5| Step: 5
Training loss: 2.956994322290475
Validation loss: 2.590723863239213

Epoch: 5| Step: 6
Training loss: 2.5882386632122203
Validation loss: 2.5926537923365727

Epoch: 5| Step: 7
Training loss: 2.9720299520921407
Validation loss: 2.5939488132751096

Epoch: 5| Step: 8
Training loss: 2.5761291176441303
Validation loss: 2.573780291675579

Epoch: 5| Step: 9
Training loss: 2.6961219346179663
Validation loss: 2.5720801418207144

Epoch: 5| Step: 10
Training loss: 3.0970051912258687
Validation loss: 2.593377001644347

Epoch: 308| Step: 0
Training loss: 2.6887868417426417
Validation loss: 2.5810405663816858

Epoch: 5| Step: 1
Training loss: 3.0434761065125984
Validation loss: 2.6005672862206635

Epoch: 5| Step: 2
Training loss: 2.8515688543379545
Validation loss: 2.6212799762654866

Epoch: 5| Step: 3
Training loss: 2.446598969890696
Validation loss: 2.619455976101279

Epoch: 5| Step: 4
Training loss: 2.7097479329295315
Validation loss: 2.5994336198787957

Epoch: 5| Step: 5
Training loss: 2.624312083613709
Validation loss: 2.5913909708756484

Epoch: 5| Step: 6
Training loss: 2.9430936757978814
Validation loss: 2.5821067453127973

Epoch: 5| Step: 7
Training loss: 2.887750959843854
Validation loss: 2.56815946217294

Epoch: 5| Step: 8
Training loss: 2.5196536958497444
Validation loss: 2.5927972784642406

Epoch: 5| Step: 9
Training loss: 2.3313471878697483
Validation loss: 2.6031035552356374

Epoch: 5| Step: 10
Training loss: 3.027791045584661
Validation loss: 2.5904824512364044

Epoch: 309| Step: 0
Training loss: 2.6083431373712562
Validation loss: 2.599866164299091

Epoch: 5| Step: 1
Training loss: 2.6369399140463035
Validation loss: 2.5883556777915855

Epoch: 5| Step: 2
Training loss: 2.568722496906445
Validation loss: 2.615906273863504

Epoch: 5| Step: 3
Training loss: 3.0909113335728797
Validation loss: 2.5943481362513645

Epoch: 5| Step: 4
Training loss: 2.6996186728876927
Validation loss: 2.6002143022961994

Epoch: 5| Step: 5
Training loss: 2.249571759478613
Validation loss: 2.594640495675428

Epoch: 5| Step: 6
Training loss: 2.715870966159453
Validation loss: 2.58334928706784

Epoch: 5| Step: 7
Training loss: 3.0297116180766275
Validation loss: 2.5829458974929747

Epoch: 5| Step: 8
Training loss: 2.476996254466509
Validation loss: 2.5907130484675647

Epoch: 5| Step: 9
Training loss: 2.8975797551050815
Validation loss: 2.565719818612972

Epoch: 5| Step: 10
Training loss: 2.7643883305538046
Validation loss: 2.5673784268979647

Epoch: 310| Step: 0
Training loss: 1.978375172878303
Validation loss: 2.55612901098976

Epoch: 5| Step: 1
Training loss: 2.6164156102867056
Validation loss: 2.554976160853991

Epoch: 5| Step: 2
Training loss: 2.5369279075607176
Validation loss: 2.535565116272836

Epoch: 5| Step: 3
Training loss: 2.8751175897848653
Validation loss: 2.5345077576378987

Epoch: 5| Step: 4
Training loss: 2.9691674189995316
Validation loss: 2.5256164260509504

Epoch: 5| Step: 5
Training loss: 2.6698831194037043
Validation loss: 2.526943245234532

Epoch: 5| Step: 6
Training loss: 2.74059925654466
Validation loss: 2.5498343041698557

Epoch: 5| Step: 7
Training loss: 3.099847352976493
Validation loss: 2.5510723988887847

Epoch: 5| Step: 8
Training loss: 2.902926277446611
Validation loss: 2.573488983301388

Epoch: 5| Step: 9
Training loss: 2.45712362579728
Validation loss: 2.601788546313827

Epoch: 5| Step: 10
Training loss: 2.6087094674573876
Validation loss: 2.6804546280738633

Epoch: 311| Step: 0
Training loss: 2.3784636287735066
Validation loss: 2.7738208062762775

Epoch: 5| Step: 1
Training loss: 2.4959146498062452
Validation loss: 2.8074353939800165

Epoch: 5| Step: 2
Training loss: 2.8613571217600695
Validation loss: 2.8069651716318846

Epoch: 5| Step: 3
Training loss: 3.0411082935362788
Validation loss: 2.7198603739662555

Epoch: 5| Step: 4
Training loss: 2.511945224832945
Validation loss: 2.6313048226488185

Epoch: 5| Step: 5
Training loss: 2.8408936628442936
Validation loss: 2.598046756825993

Epoch: 5| Step: 6
Training loss: 2.869218070878691
Validation loss: 2.5626003426815274

Epoch: 5| Step: 7
Training loss: 1.6992517226955342
Validation loss: 2.541208634106208

Epoch: 5| Step: 8
Training loss: 2.8936357644522044
Validation loss: 2.537497634215752

Epoch: 5| Step: 9
Training loss: 3.13594275504044
Validation loss: 2.5325407623553398

Epoch: 5| Step: 10
Training loss: 2.8300718908984996
Validation loss: 2.5066176944186833

Epoch: 312| Step: 0
Training loss: 2.552485832600969
Validation loss: 2.5232906224517424

Epoch: 5| Step: 1
Training loss: 2.680372856735243
Validation loss: 2.5128303076029876

Epoch: 5| Step: 2
Training loss: 3.1053670998497265
Validation loss: 2.5306876026329093

Epoch: 5| Step: 3
Training loss: 2.633392903905593
Validation loss: 2.554236491246797

Epoch: 5| Step: 4
Training loss: 2.7495895426214196
Validation loss: 2.5724844374996594

Epoch: 5| Step: 5
Training loss: 3.0908485447466525
Validation loss: 2.6230091381827307

Epoch: 5| Step: 6
Training loss: 1.9303407374214605
Validation loss: 2.676439289125547

Epoch: 5| Step: 7
Training loss: 2.8612218010322352
Validation loss: 2.75186253471801

Epoch: 5| Step: 8
Training loss: 2.7237159713573207
Validation loss: 2.7439097462414055

Epoch: 5| Step: 9
Training loss: 2.5642777765760663
Validation loss: 2.645539257155051

Epoch: 5| Step: 10
Training loss: 2.7469362184822246
Validation loss: 2.5942446833316763

Epoch: 313| Step: 0
Training loss: 2.393578792654528
Validation loss: 2.570848701462894

Epoch: 5| Step: 1
Training loss: 2.5195872692415753
Validation loss: 2.5423746798911435

Epoch: 5| Step: 2
Training loss: 2.8591950573610045
Validation loss: 2.5464550451928365

Epoch: 5| Step: 3
Training loss: 2.978020258499626
Validation loss: 2.536641842851604

Epoch: 5| Step: 4
Training loss: 2.306804964443664
Validation loss: 2.5621481743212002

Epoch: 5| Step: 5
Training loss: 2.9188219735463203
Validation loss: 2.587089906113173

Epoch: 5| Step: 6
Training loss: 2.2775087378592844
Validation loss: 2.6092805403830694

Epoch: 5| Step: 7
Training loss: 3.399139822813145
Validation loss: 2.626375350789567

Epoch: 5| Step: 8
Training loss: 2.5160662341110167
Validation loss: 2.64619885078082

Epoch: 5| Step: 9
Training loss: 2.9782617079268436
Validation loss: 2.6445840106975274

Epoch: 5| Step: 10
Training loss: 2.4116559424839634
Validation loss: 2.582678340345723

Epoch: 314| Step: 0
Training loss: 2.6532805955460446
Validation loss: 2.553276820286596

Epoch: 5| Step: 1
Training loss: 2.7222280069752514
Validation loss: 2.5394855004928014

Epoch: 5| Step: 2
Training loss: 2.744574483329512
Validation loss: 2.5417878498443582

Epoch: 5| Step: 3
Training loss: 2.53691963737334
Validation loss: 2.5310670914948084

Epoch: 5| Step: 4
Training loss: 2.9815746970267565
Validation loss: 2.5291992543685193

Epoch: 5| Step: 5
Training loss: 2.8510671525029108
Validation loss: 2.5367671221603647

Epoch: 5| Step: 6
Training loss: 2.7731168319791637
Validation loss: 2.563867153742983

Epoch: 5| Step: 7
Training loss: 2.318364825479324
Validation loss: 2.5514071863226135

Epoch: 5| Step: 8
Training loss: 2.2082960977354094
Validation loss: 2.6059654812571464

Epoch: 5| Step: 9
Training loss: 2.6951421269182725
Validation loss: 2.637243388191089

Epoch: 5| Step: 10
Training loss: 3.094009234423872
Validation loss: 2.6995220338941346

Epoch: 315| Step: 0
Training loss: 2.3400363237871042
Validation loss: 2.68170358527329

Epoch: 5| Step: 1
Training loss: 2.852765391354991
Validation loss: 2.6589747159685104

Epoch: 5| Step: 2
Training loss: 2.972522948154838
Validation loss: 2.6333522789199497

Epoch: 5| Step: 3
Training loss: 2.391520712604668
Validation loss: 2.6125051729653777

Epoch: 5| Step: 4
Training loss: 2.714890645671855
Validation loss: 2.5900849592393427

Epoch: 5| Step: 5
Training loss: 3.2573000278412354
Validation loss: 2.586057556020363

Epoch: 5| Step: 6
Training loss: 2.434177383804976
Validation loss: 2.566074505416261

Epoch: 5| Step: 7
Training loss: 2.7182132585747936
Validation loss: 2.567405429386095

Epoch: 5| Step: 8
Training loss: 2.7407173932811797
Validation loss: 2.540521448089074

Epoch: 5| Step: 9
Training loss: 2.6250241596381705
Validation loss: 2.5553662992398536

Epoch: 5| Step: 10
Training loss: 2.332176318999928
Validation loss: 2.574347198775732

Epoch: 316| Step: 0
Training loss: 2.3692385408777064
Validation loss: 2.5907446535188714

Epoch: 5| Step: 1
Training loss: 2.7354537143992412
Validation loss: 2.589019354639859

Epoch: 5| Step: 2
Training loss: 2.4025480850282275
Validation loss: 2.628593636509036

Epoch: 5| Step: 3
Training loss: 2.710307287129584
Validation loss: 2.6284553718854915

Epoch: 5| Step: 4
Training loss: 3.0117196999633715
Validation loss: 2.674624417971713

Epoch: 5| Step: 5
Training loss: 3.5185563137485834
Validation loss: 2.6742208205304854

Epoch: 5| Step: 6
Training loss: 2.010564795325834
Validation loss: 2.633533586318187

Epoch: 5| Step: 7
Training loss: 2.6131929345596396
Validation loss: 2.6178710808822014

Epoch: 5| Step: 8
Training loss: 2.514563294978499
Validation loss: 2.5999759496265917

Epoch: 5| Step: 9
Training loss: 2.5916111411701706
Validation loss: 2.611674907873483

Epoch: 5| Step: 10
Training loss: 2.6853732188172317
Validation loss: 2.5925649502383035

Epoch: 317| Step: 0
Training loss: 2.849639829665054
Validation loss: 2.58611618865589

Epoch: 5| Step: 1
Training loss: 3.089319466769539
Validation loss: 2.5810056620466275

Epoch: 5| Step: 2
Training loss: 2.6350841287288183
Validation loss: 2.563222119588846

Epoch: 5| Step: 3
Training loss: 2.856146652388699
Validation loss: 2.5573319093469142

Epoch: 5| Step: 4
Training loss: 2.8737801991021277
Validation loss: 2.5329152266845196

Epoch: 5| Step: 5
Training loss: 2.4850019707470454
Validation loss: 2.549731612071003

Epoch: 5| Step: 6
Training loss: 2.326122882368727
Validation loss: 2.558176884449203

Epoch: 5| Step: 7
Training loss: 2.5425439060737465
Validation loss: 2.561570120628499

Epoch: 5| Step: 8
Training loss: 2.1510148558589113
Validation loss: 2.553738275240965

Epoch: 5| Step: 9
Training loss: 2.749678332849693
Validation loss: 2.5531002935792433

Epoch: 5| Step: 10
Training loss: 2.657071603604869
Validation loss: 2.5706370548032367

Epoch: 318| Step: 0
Training loss: 2.2830914942436378
Validation loss: 2.5887655753626944

Epoch: 5| Step: 1
Training loss: 2.7078790039066707
Validation loss: 2.603090193876388

Epoch: 5| Step: 2
Training loss: 2.821849288062886
Validation loss: 2.5962646131898

Epoch: 5| Step: 3
Training loss: 2.7284036011250836
Validation loss: 2.55184883277555

Epoch: 5| Step: 4
Training loss: 2.6062008859960324
Validation loss: 2.5654235557717304

Epoch: 5| Step: 5
Training loss: 2.0888668450867534
Validation loss: 2.561562514474133

Epoch: 5| Step: 6
Training loss: 3.1878588605339884
Validation loss: 2.567347992091296

Epoch: 5| Step: 7
Training loss: 2.570056659059081
Validation loss: 2.5707525170955323

Epoch: 5| Step: 8
Training loss: 2.54667999831633
Validation loss: 2.596259859676905

Epoch: 5| Step: 9
Training loss: 2.9049558321669573
Validation loss: 2.6076471784219315

Epoch: 5| Step: 10
Training loss: 2.5635572903955426
Validation loss: 2.6196944020274953

Epoch: 319| Step: 0
Training loss: 2.811454493852283
Validation loss: 2.646219841713275

Epoch: 5| Step: 1
Training loss: 2.4486337355488508
Validation loss: 2.608052568586315

Epoch: 5| Step: 2
Training loss: 2.7688674454073845
Validation loss: 2.6120111998015303

Epoch: 5| Step: 3
Training loss: 2.5503080668140345
Validation loss: 2.5681454957529453

Epoch: 5| Step: 4
Training loss: 2.4612735579386653
Validation loss: 2.5767798560567083

Epoch: 5| Step: 5
Training loss: 2.5871527544774002
Validation loss: 2.591624551818713

Epoch: 5| Step: 6
Training loss: 2.7218600494990257
Validation loss: 2.590830746853912

Epoch: 5| Step: 7
Training loss: 2.5749872707311563
Validation loss: 2.6149555041593042

Epoch: 5| Step: 8
Training loss: 2.4862738496260772
Validation loss: 2.5979573264932108

Epoch: 5| Step: 9
Training loss: 2.9186324624813254
Validation loss: 2.5496088350044515

Epoch: 5| Step: 10
Training loss: 2.8645686108759927
Validation loss: 2.548865219058138

Epoch: 320| Step: 0
Training loss: 2.6117342031867836
Validation loss: 2.5285519473634674

Epoch: 5| Step: 1
Training loss: 3.1408752038083967
Validation loss: 2.532638415134616

Epoch: 5| Step: 2
Training loss: 2.1532959536604097
Validation loss: 2.543178386832759

Epoch: 5| Step: 3
Training loss: 2.602427204297598
Validation loss: 2.541158235621207

Epoch: 5| Step: 4
Training loss: 2.6738535376177777
Validation loss: 2.5495331556650083

Epoch: 5| Step: 5
Training loss: 2.771479729614236
Validation loss: 2.582559883276232

Epoch: 5| Step: 6
Training loss: 2.098149360649405
Validation loss: 2.6596566376582844

Epoch: 5| Step: 7
Training loss: 3.206624868388852
Validation loss: 2.6965510426810155

Epoch: 5| Step: 8
Training loss: 2.4461298055071863
Validation loss: 2.660971455630188

Epoch: 5| Step: 9
Training loss: 2.851947413554923
Validation loss: 2.6142599846123376

Epoch: 5| Step: 10
Training loss: 2.7149241922659604
Validation loss: 2.5356553812135023

Epoch: 321| Step: 0
Training loss: 2.281997558177875
Validation loss: 2.5045718218305106

Epoch: 5| Step: 1
Training loss: 2.7728334440663245
Validation loss: 2.4970559546274234

Epoch: 5| Step: 2
Training loss: 2.5742024492086317
Validation loss: 2.501183756655211

Epoch: 5| Step: 3
Training loss: 2.757730369317486
Validation loss: 2.507011702034364

Epoch: 5| Step: 4
Training loss: 2.661599192216921
Validation loss: 2.515807986713952

Epoch: 5| Step: 5
Training loss: 2.8944277931494264
Validation loss: 2.5185269841399656

Epoch: 5| Step: 6
Training loss: 2.7545235449282712
Validation loss: 2.5706036447647076

Epoch: 5| Step: 7
Training loss: 2.677719416670474
Validation loss: 2.5704588669024315

Epoch: 5| Step: 8
Training loss: 2.5746644810720474
Validation loss: 2.6187911744027805

Epoch: 5| Step: 9
Training loss: 2.4567401270793687
Validation loss: 2.621903408098598

Epoch: 5| Step: 10
Training loss: 3.18999637759012
Validation loss: 2.645869311907719

Epoch: 322| Step: 0
Training loss: 2.660233147807876
Validation loss: 2.6169983125844425

Epoch: 5| Step: 1
Training loss: 2.9335531137956172
Validation loss: 2.5819354375329513

Epoch: 5| Step: 2
Training loss: 2.6411339985928297
Validation loss: 2.6046258973498504

Epoch: 5| Step: 3
Training loss: 2.276699387225393
Validation loss: 2.6055660427348992

Epoch: 5| Step: 4
Training loss: 2.452167299745754
Validation loss: 2.579605018796389

Epoch: 5| Step: 5
Training loss: 2.810075180839946
Validation loss: 2.573058293638508

Epoch: 5| Step: 6
Training loss: 2.724205419203116
Validation loss: 2.556373541817915

Epoch: 5| Step: 7
Training loss: 2.918301605482045
Validation loss: 2.540482808845023

Epoch: 5| Step: 8
Training loss: 2.8646430176961752
Validation loss: 2.5562716028270622

Epoch: 5| Step: 9
Training loss: 2.4266119132135353
Validation loss: 2.553334778936009

Epoch: 5| Step: 10
Training loss: 2.2725136049574703
Validation loss: 2.5777184447677346

Epoch: 323| Step: 0
Training loss: 2.4503837868734792
Validation loss: 2.58851503949548

Epoch: 5| Step: 1
Training loss: 2.3114087391008744
Validation loss: 2.5783433927958934

Epoch: 5| Step: 2
Training loss: 2.3536191545564087
Validation loss: 2.5999255080551826

Epoch: 5| Step: 3
Training loss: 2.4071900154109542
Validation loss: 2.599516490517823

Epoch: 5| Step: 4
Training loss: 2.6204404741676552
Validation loss: 2.5740346450446947

Epoch: 5| Step: 5
Training loss: 2.5148406138642008
Validation loss: 2.573481207162005

Epoch: 5| Step: 6
Training loss: 2.5289241324644816
Validation loss: 2.581146762408931

Epoch: 5| Step: 7
Training loss: 3.120809262789367
Validation loss: 2.605343286972667

Epoch: 5| Step: 8
Training loss: 2.679345823698156
Validation loss: 2.605532619121938

Epoch: 5| Step: 9
Training loss: 2.427566436581317
Validation loss: 2.6038985139342197

Epoch: 5| Step: 10
Training loss: 3.5145344717039566
Validation loss: 2.643422157317913

Epoch: 324| Step: 0
Training loss: 3.150335227446134
Validation loss: 2.623155077385121

Epoch: 5| Step: 1
Training loss: 2.369533270417763
Validation loss: 2.5877035210261394

Epoch: 5| Step: 2
Training loss: 2.2808730976771856
Validation loss: 2.5850274326364158

Epoch: 5| Step: 3
Training loss: 2.800805595856094
Validation loss: 2.573505946081939

Epoch: 5| Step: 4
Training loss: 2.494619492315008
Validation loss: 2.59483704642478

Epoch: 5| Step: 5
Training loss: 2.6619336524336017
Validation loss: 2.5940385043496437

Epoch: 5| Step: 6
Training loss: 3.022689529673508
Validation loss: 2.5622990257033087

Epoch: 5| Step: 7
Training loss: 2.8667494103961784
Validation loss: 2.570937016630165

Epoch: 5| Step: 8
Training loss: 2.3929754931497795
Validation loss: 2.5713021733512464

Epoch: 5| Step: 9
Training loss: 2.595605117864997
Validation loss: 2.5398645741749446

Epoch: 5| Step: 10
Training loss: 2.4390757431462524
Validation loss: 2.565577299238598

Epoch: 325| Step: 0
Training loss: 2.6618280521004687
Validation loss: 2.596263781770017

Epoch: 5| Step: 1
Training loss: 2.6734654561670705
Validation loss: 2.640357131900322

Epoch: 5| Step: 2
Training loss: 2.4885098578388303
Validation loss: 2.6402389895667104

Epoch: 5| Step: 3
Training loss: 2.823441141165247
Validation loss: 2.625913440557677

Epoch: 5| Step: 4
Training loss: 2.447911255742579
Validation loss: 2.5999911856363855

Epoch: 5| Step: 5
Training loss: 2.814528179028313
Validation loss: 2.5811740409887545

Epoch: 5| Step: 6
Training loss: 2.3414493713379367
Validation loss: 2.5318968055505358

Epoch: 5| Step: 7
Training loss: 2.5572221879915134
Validation loss: 2.524059816667019

Epoch: 5| Step: 8
Training loss: 2.5189509233552885
Validation loss: 2.524575731113269

Epoch: 5| Step: 9
Training loss: 3.0003882792656986
Validation loss: 2.5200686520849547

Epoch: 5| Step: 10
Training loss: 2.565010515752879
Validation loss: 2.519310434186265

Epoch: 326| Step: 0
Training loss: 2.3614159655265423
Validation loss: 2.5447780890960106

Epoch: 5| Step: 1
Training loss: 2.864656833514917
Validation loss: 2.591323199575778

Epoch: 5| Step: 2
Training loss: 2.613986206765475
Validation loss: 2.6085809525300756

Epoch: 5| Step: 3
Training loss: 2.8614549419955577
Validation loss: 2.630694011502932

Epoch: 5| Step: 4
Training loss: 2.678072962928622
Validation loss: 2.6104577092509667

Epoch: 5| Step: 5
Training loss: 2.6856507437299744
Validation loss: 2.576151454734239

Epoch: 5| Step: 6
Training loss: 2.426606705871487
Validation loss: 2.5697689205346683

Epoch: 5| Step: 7
Training loss: 1.9983932478287474
Validation loss: 2.5442629964424004

Epoch: 5| Step: 8
Training loss: 2.2163583464583905
Validation loss: 2.5471596970468466

Epoch: 5| Step: 9
Training loss: 2.6864560783369864
Validation loss: 2.5264037609907546

Epoch: 5| Step: 10
Training loss: 3.3660937876246053
Validation loss: 2.545549366920762

Epoch: 327| Step: 0
Training loss: 2.7462675601222446
Validation loss: 2.5452941924894636

Epoch: 5| Step: 1
Training loss: 2.0289515475922055
Validation loss: 2.556207530855325

Epoch: 5| Step: 2
Training loss: 2.61274747999612
Validation loss: 2.581507990271964

Epoch: 5| Step: 3
Training loss: 2.377718323511924
Validation loss: 2.5994048908265053

Epoch: 5| Step: 4
Training loss: 2.5923176682747644
Validation loss: 2.578150703647592

Epoch: 5| Step: 5
Training loss: 2.920483915911982
Validation loss: 2.559044529791517

Epoch: 5| Step: 6
Training loss: 3.1361750871477336
Validation loss: 2.5350987019426863

Epoch: 5| Step: 7
Training loss: 2.5418611566726113
Validation loss: 2.5211344103275413

Epoch: 5| Step: 8
Training loss: 2.6509830091141318
Validation loss: 2.513804895291095

Epoch: 5| Step: 9
Training loss: 2.613616237638281
Validation loss: 2.526940581097191

Epoch: 5| Step: 10
Training loss: 2.4812567953405846
Validation loss: 2.5337649498538584

Epoch: 328| Step: 0
Training loss: 2.5302355582001588
Validation loss: 2.552753852788571

Epoch: 5| Step: 1
Training loss: 3.307223453969705
Validation loss: 2.6050866980548126

Epoch: 5| Step: 2
Training loss: 2.677045938153952
Validation loss: 2.6164804712419025

Epoch: 5| Step: 3
Training loss: 2.4916517106269715
Validation loss: 2.6343736693540043

Epoch: 5| Step: 4
Training loss: 2.2614438115489337
Validation loss: 2.626741389347614

Epoch: 5| Step: 5
Training loss: 2.5872491466164367
Validation loss: 2.625182446742902

Epoch: 5| Step: 6
Training loss: 2.680798536586106
Validation loss: 2.6422289856344103

Epoch: 5| Step: 7
Training loss: 2.312477730308733
Validation loss: 2.6280269583689475

Epoch: 5| Step: 8
Training loss: 2.354122352745663
Validation loss: 2.659296326083089

Epoch: 5| Step: 9
Training loss: 2.922824480955394
Validation loss: 2.5371714244018237

Epoch: 5| Step: 10
Training loss: 2.3227356867289166
Validation loss: 2.505849677410084

Epoch: 329| Step: 0
Training loss: 2.3027299228977847
Validation loss: 2.4839130920788994

Epoch: 5| Step: 1
Training loss: 2.151610316989756
Validation loss: 2.47760150697878

Epoch: 5| Step: 2
Training loss: 3.303109876874158
Validation loss: 2.478147029381801

Epoch: 5| Step: 3
Training loss: 2.4074117655048974
Validation loss: 2.4703214251400016

Epoch: 5| Step: 4
Training loss: 2.7751947557995256
Validation loss: 2.4881700879302184

Epoch: 5| Step: 5
Training loss: 2.533961221616513
Validation loss: 2.4860175047090127

Epoch: 5| Step: 6
Training loss: 2.4410691173477543
Validation loss: 2.5046978423709096

Epoch: 5| Step: 7
Training loss: 2.2186334068933853
Validation loss: 2.547941857020083

Epoch: 5| Step: 8
Training loss: 2.710431758086999
Validation loss: 2.603114709510146

Epoch: 5| Step: 9
Training loss: 3.1658309703823777
Validation loss: 2.640750334235398

Epoch: 5| Step: 10
Training loss: 3.1690993919591293
Validation loss: 2.7157789202420632

Epoch: 330| Step: 0
Training loss: 2.560563262724065
Validation loss: 2.6565229667724037

Epoch: 5| Step: 1
Training loss: 3.0832220177704133
Validation loss: 2.563777462098982

Epoch: 5| Step: 2
Training loss: 2.2777470907092865
Validation loss: 2.5162178002988744

Epoch: 5| Step: 3
Training loss: 2.302020582721872
Validation loss: 2.4955348337297063

Epoch: 5| Step: 4
Training loss: 2.7971657543255515
Validation loss: 2.500401996778721

Epoch: 5| Step: 5
Training loss: 2.4488188251288956
Validation loss: 2.5083470720860555

Epoch: 5| Step: 6
Training loss: 2.7119479096566663
Validation loss: 2.5444476434733776

Epoch: 5| Step: 7
Training loss: 2.493623803944401
Validation loss: 2.564576051094137

Epoch: 5| Step: 8
Training loss: 3.2378957263539556
Validation loss: 2.6057238884889684

Epoch: 5| Step: 9
Training loss: 2.5705746224269257
Validation loss: 2.6014855087137865

Epoch: 5| Step: 10
Training loss: 2.317161501264665
Validation loss: 2.64352752215676

Epoch: 331| Step: 0
Training loss: 2.940998510137892
Validation loss: 2.6375961364338667

Epoch: 5| Step: 1
Training loss: 2.41231495834436
Validation loss: 2.6027790252853227

Epoch: 5| Step: 2
Training loss: 2.8439932918228035
Validation loss: 2.5887414566247413

Epoch: 5| Step: 3
Training loss: 1.8977736580069675
Validation loss: 2.573130362875664

Epoch: 5| Step: 4
Training loss: 2.2912450807209557
Validation loss: 2.5746967451311655

Epoch: 5| Step: 5
Training loss: 3.0325135419249176
Validation loss: 2.5916442062021394

Epoch: 5| Step: 6
Training loss: 2.490821392208952
Validation loss: 2.5783793652376565

Epoch: 5| Step: 7
Training loss: 2.6556767462188833
Validation loss: 2.5793173664362157

Epoch: 5| Step: 8
Training loss: 2.548625601837882
Validation loss: 2.578036834611358

Epoch: 5| Step: 9
Training loss: 2.9824887051492373
Validation loss: 2.561049684474159

Epoch: 5| Step: 10
Training loss: 2.548179807094599
Validation loss: 2.5519801715210773

Epoch: 332| Step: 0
Training loss: 2.3540349490245993
Validation loss: 2.5411796594122493

Epoch: 5| Step: 1
Training loss: 2.522417458732913
Validation loss: 2.5495767642682616

Epoch: 5| Step: 2
Training loss: 2.8316037190763836
Validation loss: 2.5720628591569974

Epoch: 5| Step: 3
Training loss: 2.5528247820161454
Validation loss: 2.5685428626988105

Epoch: 5| Step: 4
Training loss: 2.3209175322878037
Validation loss: 2.572307631331768

Epoch: 5| Step: 5
Training loss: 2.345993189223762
Validation loss: 2.5890863614315154

Epoch: 5| Step: 6
Training loss: 2.474253832920972
Validation loss: 2.610408101701526

Epoch: 5| Step: 7
Training loss: 3.0236499327320367
Validation loss: 2.6716359843611106

Epoch: 5| Step: 8
Training loss: 2.7906677584560184
Validation loss: 2.6890556000016836

Epoch: 5| Step: 9
Training loss: 2.6495431938156386
Validation loss: 2.6447849727253283

Epoch: 5| Step: 10
Training loss: 2.7092964416167398
Validation loss: 2.614819065539274

Epoch: 333| Step: 0
Training loss: 2.199955276554856
Validation loss: 2.5481478179747294

Epoch: 5| Step: 1
Training loss: 2.6402977735027675
Validation loss: 2.4974050282479476

Epoch: 5| Step: 2
Training loss: 3.026962236545036
Validation loss: 2.49060136497654

Epoch: 5| Step: 3
Training loss: 2.8960447897424406
Validation loss: 2.4805330254757925

Epoch: 5| Step: 4
Training loss: 2.7585713582519693
Validation loss: 2.4845827500406776

Epoch: 5| Step: 5
Training loss: 2.38346018509193
Validation loss: 2.4880679459565473

Epoch: 5| Step: 6
Training loss: 2.4366557297502465
Validation loss: 2.5106286420765116

Epoch: 5| Step: 7
Training loss: 2.576512890413901
Validation loss: 2.5788824823779897

Epoch: 5| Step: 8
Training loss: 2.8085559741624633
Validation loss: 2.588654242561477

Epoch: 5| Step: 9
Training loss: 2.8559666733066207
Validation loss: 2.637678692539093

Epoch: 5| Step: 10
Training loss: 2.5728669155319834
Validation loss: 2.611984138253796

Epoch: 334| Step: 0
Training loss: 2.5696502110567185
Validation loss: 2.6357220079634263

Epoch: 5| Step: 1
Training loss: 2.683621913090257
Validation loss: 2.59717003324961

Epoch: 5| Step: 2
Training loss: 2.532546005960869
Validation loss: 2.5874970596040754

Epoch: 5| Step: 3
Training loss: 2.4182045964845456
Validation loss: 2.53718423463357

Epoch: 5| Step: 4
Training loss: 2.862124262641265
Validation loss: 2.512996223622923

Epoch: 5| Step: 5
Training loss: 2.01955486114099
Validation loss: 2.5233489183275766

Epoch: 5| Step: 6
Training loss: 2.2566768337604857
Validation loss: 2.533635568832227

Epoch: 5| Step: 7
Training loss: 3.0821556385307596
Validation loss: 2.550474547212899

Epoch: 5| Step: 8
Training loss: 2.6746809653295824
Validation loss: 2.597350829275542

Epoch: 5| Step: 9
Training loss: 2.885315839380666
Validation loss: 2.616672479521037

Epoch: 5| Step: 10
Training loss: 2.7273626601679
Validation loss: 2.6156965009778785

Epoch: 335| Step: 0
Training loss: 2.8034624489871196
Validation loss: 2.6416710717642715

Epoch: 5| Step: 1
Training loss: 2.890235998424162
Validation loss: 2.6476692239451243

Epoch: 5| Step: 2
Training loss: 2.461483558744003
Validation loss: 2.654596725074876

Epoch: 5| Step: 3
Training loss: 2.7439117662018004
Validation loss: 2.6442849448405603

Epoch: 5| Step: 4
Training loss: 2.340399827299501
Validation loss: 2.6052142851943594

Epoch: 5| Step: 5
Training loss: 2.474566789725823
Validation loss: 2.5596365157568917

Epoch: 5| Step: 6
Training loss: 2.5642027431260628
Validation loss: 2.525628799546178

Epoch: 5| Step: 7
Training loss: 2.284026768308732
Validation loss: 2.5028678805719555

Epoch: 5| Step: 8
Training loss: 2.7926516052729955
Validation loss: 2.5080778466951816

Epoch: 5| Step: 9
Training loss: 3.2669355327222758
Validation loss: 2.4927309883590096

Epoch: 5| Step: 10
Training loss: 1.9334650170214869
Validation loss: 2.5318849294695407

Epoch: 336| Step: 0
Training loss: 1.428723286323085
Validation loss: 2.552424311173393

Epoch: 5| Step: 1
Training loss: 2.4095486906110732
Validation loss: 2.6053486408753312

Epoch: 5| Step: 2
Training loss: 2.451705910917276
Validation loss: 2.7028678825344237

Epoch: 5| Step: 3
Training loss: 2.054604532285504
Validation loss: 2.7336494638778612

Epoch: 5| Step: 4
Training loss: 2.830624987601602
Validation loss: 2.7331651524331924

Epoch: 5| Step: 5
Training loss: 3.183671185072454
Validation loss: 2.629198429980647

Epoch: 5| Step: 6
Training loss: 2.8841726511096195
Validation loss: 2.5724977455562583

Epoch: 5| Step: 7
Training loss: 2.97368749308305
Validation loss: 2.5810077300380865

Epoch: 5| Step: 8
Training loss: 2.9226965743655473
Validation loss: 2.5353467323561336

Epoch: 5| Step: 9
Training loss: 2.8792780683930816
Validation loss: 2.5110356214559055

Epoch: 5| Step: 10
Training loss: 2.1743160224672633
Validation loss: 2.5123612501622423

Epoch: 337| Step: 0
Training loss: 2.924937881723042
Validation loss: 2.5197019961308467

Epoch: 5| Step: 1
Training loss: 2.3572720888555097
Validation loss: 2.5458256748989827

Epoch: 5| Step: 2
Training loss: 2.2342728811549852
Validation loss: 2.5525733569390368

Epoch: 5| Step: 3
Training loss: 2.95865351775475
Validation loss: 2.5828821656277885

Epoch: 5| Step: 4
Training loss: 2.5689158253850626
Validation loss: 2.543545923056204

Epoch: 5| Step: 5
Training loss: 2.8704052573195233
Validation loss: 2.54267406184856

Epoch: 5| Step: 6
Training loss: 2.688347084150564
Validation loss: 2.5262921839057646

Epoch: 5| Step: 7
Training loss: 2.8649429557939916
Validation loss: 2.515731323172077

Epoch: 5| Step: 8
Training loss: 2.115075328197891
Validation loss: 2.5316334439948207

Epoch: 5| Step: 9
Training loss: 2.015477966150301
Validation loss: 2.5574644721362625

Epoch: 5| Step: 10
Training loss: 2.7422251467823995
Validation loss: 2.5969503885343537

Epoch: 338| Step: 0
Training loss: 2.504330222765069
Validation loss: 2.5843087504014144

Epoch: 5| Step: 1
Training loss: 2.6060142575135252
Validation loss: 2.604589160405025

Epoch: 5| Step: 2
Training loss: 2.343144046017176
Validation loss: 2.6201454272282203

Epoch: 5| Step: 3
Training loss: 2.658593434331821
Validation loss: 2.610897502054111

Epoch: 5| Step: 4
Training loss: 2.4905346020000936
Validation loss: 2.590977770299432

Epoch: 5| Step: 5
Training loss: 2.8640288955040636
Validation loss: 2.596733048255156

Epoch: 5| Step: 6
Training loss: 2.8274664349170044
Validation loss: 2.611096008205903

Epoch: 5| Step: 7
Training loss: 2.294821931001908
Validation loss: 2.5537944957828933

Epoch: 5| Step: 8
Training loss: 2.782759524681317
Validation loss: 2.5694118706847235

Epoch: 5| Step: 9
Training loss: 2.432219238074172
Validation loss: 2.5504468447919106

Epoch: 5| Step: 10
Training loss: 2.3274079313004887
Validation loss: 2.546658994270875

Epoch: 339| Step: 0
Training loss: 2.058943601120243
Validation loss: 2.549726931673249

Epoch: 5| Step: 1
Training loss: 2.778064231937415
Validation loss: 2.547372911879784

Epoch: 5| Step: 2
Training loss: 2.646796244020465
Validation loss: 2.5532890004975792

Epoch: 5| Step: 3
Training loss: 2.8891825608207897
Validation loss: 2.552433595778162

Epoch: 5| Step: 4
Training loss: 2.7647865015696014
Validation loss: 2.556200166492269

Epoch: 5| Step: 5
Training loss: 2.291017914467633
Validation loss: 2.5693535323514625

Epoch: 5| Step: 6
Training loss: 2.14567138159491
Validation loss: 2.61142569273979

Epoch: 5| Step: 7
Training loss: 2.4052770059352335
Validation loss: 2.627080234706846

Epoch: 5| Step: 8
Training loss: 2.8976406431253503
Validation loss: 2.6502303136964467

Epoch: 5| Step: 9
Training loss: 2.936805643032703
Validation loss: 2.6313054695739324

Epoch: 5| Step: 10
Training loss: 2.244143812212162
Validation loss: 2.565431736069575

Epoch: 340| Step: 0
Training loss: 2.262614808936909
Validation loss: 2.5484414446297685

Epoch: 5| Step: 1
Training loss: 2.65962946713171
Validation loss: 2.518427888387797

Epoch: 5| Step: 2
Training loss: 2.405518457754616
Validation loss: 2.494298678952775

Epoch: 5| Step: 3
Training loss: 2.6701870767725957
Validation loss: 2.4965059315371043

Epoch: 5| Step: 4
Training loss: 2.9384530327343907
Validation loss: 2.5008213365519123

Epoch: 5| Step: 5
Training loss: 2.553405066529174
Validation loss: 2.5055600644409632

Epoch: 5| Step: 6
Training loss: 2.239481499301048
Validation loss: 2.530400264080821

Epoch: 5| Step: 7
Training loss: 2.2044475724961194
Validation loss: 2.547260987212378

Epoch: 5| Step: 8
Training loss: 2.7221372703566127
Validation loss: 2.6111981857679734

Epoch: 5| Step: 9
Training loss: 2.778002267879167
Validation loss: 2.653110974871419

Epoch: 5| Step: 10
Training loss: 3.4247659812112725
Validation loss: 2.697772652972894

Epoch: 341| Step: 0
Training loss: 2.6158639778156183
Validation loss: 2.6574854024575822

Epoch: 5| Step: 1
Training loss: 2.343004540465478
Validation loss: 2.620034425398621

Epoch: 5| Step: 2
Training loss: 2.5819413116073093
Validation loss: 2.5806594547329658

Epoch: 5| Step: 3
Training loss: 2.3273693112765272
Validation loss: 2.573660773604883

Epoch: 5| Step: 4
Training loss: 2.4666365256487035
Validation loss: 2.539001534789435

Epoch: 5| Step: 5
Training loss: 2.584675921964305
Validation loss: 2.5506865833984085

Epoch: 5| Step: 6
Training loss: 2.5188577860825707
Validation loss: 2.574514600189675

Epoch: 5| Step: 7
Training loss: 2.937636027331696
Validation loss: 2.600422406966022

Epoch: 5| Step: 8
Training loss: 2.8178835736191545
Validation loss: 2.6350246427917448

Epoch: 5| Step: 9
Training loss: 2.712064569216614
Validation loss: 2.6288675031317803

Epoch: 5| Step: 10
Training loss: 2.4714369818609696
Validation loss: 2.6065096386500524

Epoch: 342| Step: 0
Training loss: 3.1671057112323555
Validation loss: 2.609289323995391

Epoch: 5| Step: 1
Training loss: 2.2773708649422995
Validation loss: 2.5710610341639835

Epoch: 5| Step: 2
Training loss: 2.5409749032935136
Validation loss: 2.608273269709786

Epoch: 5| Step: 3
Training loss: 2.50116997998303
Validation loss: 2.604576501570827

Epoch: 5| Step: 4
Training loss: 2.1665118846871065
Validation loss: 2.5867544981032453

Epoch: 5| Step: 5
Training loss: 2.9027956871279272
Validation loss: 2.5726932725745244

Epoch: 5| Step: 6
Training loss: 2.815005140418446
Validation loss: 2.5888444590501045

Epoch: 5| Step: 7
Training loss: 2.9784885692931016
Validation loss: 2.541707346358837

Epoch: 5| Step: 8
Training loss: 2.2925896144311904
Validation loss: 2.5323119341973466

Epoch: 5| Step: 9
Training loss: 2.4458040468541036
Validation loss: 2.5454745971904438

Epoch: 5| Step: 10
Training loss: 1.5302261510772033
Validation loss: 2.5451558064079705

Epoch: 343| Step: 0
Training loss: 2.11561385226447
Validation loss: 2.556193425920206

Epoch: 5| Step: 1
Training loss: 2.75142147432823
Validation loss: 2.5804600566894305

Epoch: 5| Step: 2
Training loss: 2.6682382561993414
Validation loss: 2.609970650623211

Epoch: 5| Step: 3
Training loss: 2.7932887607590207
Validation loss: 2.619493822337265

Epoch: 5| Step: 4
Training loss: 2.841158849661312
Validation loss: 2.6475979714033793

Epoch: 5| Step: 5
Training loss: 2.5061934999865834
Validation loss: 2.6193961670603767

Epoch: 5| Step: 6
Training loss: 1.7131588246326575
Validation loss: 2.5706187516888406

Epoch: 5| Step: 7
Training loss: 2.2970668167672788
Validation loss: 2.552563105663617

Epoch: 5| Step: 8
Training loss: 3.01490340222025
Validation loss: 2.534780683605107

Epoch: 5| Step: 9
Training loss: 2.5825278862096606
Validation loss: 2.518642810782081

Epoch: 5| Step: 10
Training loss: 2.5262680948506926
Validation loss: 2.5229491257742396

Epoch: 344| Step: 0
Training loss: 2.2890868722705284
Validation loss: 2.5338407227625006

Epoch: 5| Step: 1
Training loss: 2.513632227919169
Validation loss: 2.5481285273231973

Epoch: 5| Step: 2
Training loss: 2.8139463308567016
Validation loss: 2.5915288190211703

Epoch: 5| Step: 3
Training loss: 2.9638510991120186
Validation loss: 2.6183360626366685

Epoch: 5| Step: 4
Training loss: 2.621559431433715
Validation loss: 2.6379931808140107

Epoch: 5| Step: 5
Training loss: 2.644610315039686
Validation loss: 2.6130307384967772

Epoch: 5| Step: 6
Training loss: 2.2919110485744505
Validation loss: 2.564306991148914

Epoch: 5| Step: 7
Training loss: 2.082899188264497
Validation loss: 2.5751654529073527

Epoch: 5| Step: 8
Training loss: 2.900582149873798
Validation loss: 2.5631523652524315

Epoch: 5| Step: 9
Training loss: 2.0406066192687096
Validation loss: 2.551960956049405

Epoch: 5| Step: 10
Training loss: 2.610830392244324
Validation loss: 2.559057665307273

Epoch: 345| Step: 0
Training loss: 2.2147604306004776
Validation loss: 2.566542681189935

Epoch: 5| Step: 1
Training loss: 2.734824181855949
Validation loss: 2.5816969582903444

Epoch: 5| Step: 2
Training loss: 2.7403166820430265
Validation loss: 2.586541524434018

Epoch: 5| Step: 3
Training loss: 2.5289354456411526
Validation loss: 2.5923736291820347

Epoch: 5| Step: 4
Training loss: 2.375339082303916
Validation loss: 2.605750618564049

Epoch: 5| Step: 5
Training loss: 2.5714122889018363
Validation loss: 2.5790265229538667

Epoch: 5| Step: 6
Training loss: 2.6011563004020144
Validation loss: 2.58192886840354

Epoch: 5| Step: 7
Training loss: 2.8919412451404054
Validation loss: 2.584805504434097

Epoch: 5| Step: 8
Training loss: 2.3915624837303384
Validation loss: 2.5702421950044516

Epoch: 5| Step: 9
Training loss: 1.983783002842073
Validation loss: 2.5757654220474597

Epoch: 5| Step: 10
Training loss: 2.7217586137697145
Validation loss: 2.5842830593940294

Epoch: 346| Step: 0
Training loss: 2.3976123894054107
Validation loss: 2.565377814175302

Epoch: 5| Step: 1
Training loss: 2.0988636484553087
Validation loss: 2.5810161033006884

Epoch: 5| Step: 2
Training loss: 3.1017128550024897
Validation loss: 2.6134186988482284

Epoch: 5| Step: 3
Training loss: 2.706752658176429
Validation loss: 2.6445491142661397

Epoch: 5| Step: 4
Training loss: 2.6081127837256304
Validation loss: 2.6331671036009134

Epoch: 5| Step: 5
Training loss: 1.8121949958679133
Validation loss: 2.6380878824597715

Epoch: 5| Step: 6
Training loss: 2.0961176452525887
Validation loss: 2.6073806605197096

Epoch: 5| Step: 7
Training loss: 2.6944237169689815
Validation loss: 2.5614172315892745

Epoch: 5| Step: 8
Training loss: 2.7063258629576876
Validation loss: 2.532507117990203

Epoch: 5| Step: 9
Training loss: 2.394077276660533
Validation loss: 2.547601231527598

Epoch: 5| Step: 10
Training loss: 3.00588031486371
Validation loss: 2.5406022071106067

Epoch: 347| Step: 0
Training loss: 2.325756942422103
Validation loss: 2.569048616701908

Epoch: 5| Step: 1
Training loss: 2.6851063203983676
Validation loss: 2.5693402304593045

Epoch: 5| Step: 2
Training loss: 2.1041644130984283
Validation loss: 2.5934283930266018

Epoch: 5| Step: 3
Training loss: 2.981643305332134
Validation loss: 2.5901771704094294

Epoch: 5| Step: 4
Training loss: 1.9952912331734516
Validation loss: 2.608428216426067

Epoch: 5| Step: 5
Training loss: 2.6225795485774963
Validation loss: 2.6194317597235806

Epoch: 5| Step: 6
Training loss: 2.6770169933921144
Validation loss: 2.5949410141548555

Epoch: 5| Step: 7
Training loss: 1.8232886089346765
Validation loss: 2.564693208668905

Epoch: 5| Step: 8
Training loss: 2.9222661536830326
Validation loss: 2.561551278341352

Epoch: 5| Step: 9
Training loss: 2.836822791937566
Validation loss: 2.5531695483831385

Epoch: 5| Step: 10
Training loss: 2.417448859951026
Validation loss: 2.54151994620289

Epoch: 348| Step: 0
Training loss: 3.026915922390429
Validation loss: 2.5481403287039734

Epoch: 5| Step: 1
Training loss: 2.6221978808295163
Validation loss: 2.555536542559866

Epoch: 5| Step: 2
Training loss: 2.2050682858297423
Validation loss: 2.56157702719726

Epoch: 5| Step: 3
Training loss: 2.8346583316258176
Validation loss: 2.606578446624944

Epoch: 5| Step: 4
Training loss: 2.110967642387498
Validation loss: 2.6348034065207586

Epoch: 5| Step: 5
Training loss: 1.917057419073699
Validation loss: 2.6618007717909644

Epoch: 5| Step: 6
Training loss: 2.808406563623797
Validation loss: 2.637160476271918

Epoch: 5| Step: 7
Training loss: 2.637749093392623
Validation loss: 2.572493123520741

Epoch: 5| Step: 8
Training loss: 2.109434338900611
Validation loss: 2.5351269543310138

Epoch: 5| Step: 9
Training loss: 2.832841849240804
Validation loss: 2.539688761601747

Epoch: 5| Step: 10
Training loss: 2.426924922723381
Validation loss: 2.518269160118616

Epoch: 349| Step: 0
Training loss: 2.593708819326704
Validation loss: 2.5374452004808883

Epoch: 5| Step: 1
Training loss: 2.426286580253669
Validation loss: 2.5390964845918225

Epoch: 5| Step: 2
Training loss: 2.4561665139800626
Validation loss: 2.5946385867575885

Epoch: 5| Step: 3
Training loss: 2.7991936305902216
Validation loss: 2.676004517931179

Epoch: 5| Step: 4
Training loss: 2.8563541652124416
Validation loss: 2.7055500321828343

Epoch: 5| Step: 5
Training loss: 2.8343064002301768
Validation loss: 2.624170019778432

Epoch: 5| Step: 6
Training loss: 2.16784227706829
Validation loss: 2.5888556608973325

Epoch: 5| Step: 7
Training loss: 2.517563256810974
Validation loss: 2.5358309315482543

Epoch: 5| Step: 8
Training loss: 2.4921136444532617
Validation loss: 2.504474498558817

Epoch: 5| Step: 9
Training loss: 2.3749022212731012
Validation loss: 2.48740832227412

Epoch: 5| Step: 10
Training loss: 2.705610246342726
Validation loss: 2.493404916971808

Epoch: 350| Step: 0
Training loss: 2.0627569558730583
Validation loss: 2.521349962205246

Epoch: 5| Step: 1
Training loss: 2.5884354158287404
Validation loss: 2.5665890023358395

Epoch: 5| Step: 2
Training loss: 2.5693526403390954
Validation loss: 2.5782244392476663

Epoch: 5| Step: 3
Training loss: 2.2098079532361057
Validation loss: 2.6567440367352564

Epoch: 5| Step: 4
Training loss: 2.353275625567765
Validation loss: 2.6301994103461372

Epoch: 5| Step: 5
Training loss: 2.5954359159573857
Validation loss: 2.613496863929698

Epoch: 5| Step: 6
Training loss: 2.4166990036828864
Validation loss: 2.606499469674714

Epoch: 5| Step: 7
Training loss: 2.4136497366896714
Validation loss: 2.561393446850823

Epoch: 5| Step: 8
Training loss: 2.9271522233306904
Validation loss: 2.5179714071768795

Epoch: 5| Step: 9
Training loss: 3.1096942680192465
Validation loss: 2.471340930487085

Epoch: 5| Step: 10
Training loss: 2.6471441931453183
Validation loss: 2.4939350897224344

Epoch: 351| Step: 0
Training loss: 3.033195264699249
Validation loss: 2.494128428320368

Epoch: 5| Step: 1
Training loss: 2.6804046116190228
Validation loss: 2.501852045792534

Epoch: 5| Step: 2
Training loss: 2.4078834241042335
Validation loss: 2.5209248247444993

Epoch: 5| Step: 3
Training loss: 2.6305072778203393
Validation loss: 2.521666178106456

Epoch: 5| Step: 4
Training loss: 2.253302799145883
Validation loss: 2.536270863063365

Epoch: 5| Step: 5
Training loss: 2.268974616751453
Validation loss: 2.5575201065635893

Epoch: 5| Step: 6
Training loss: 2.2537614322992314
Validation loss: 2.6126063956024996

Epoch: 5| Step: 7
Training loss: 2.3870733469068735
Validation loss: 2.6394470678753366

Epoch: 5| Step: 8
Training loss: 2.788211895824865
Validation loss: 2.673353928518434

Epoch: 5| Step: 9
Training loss: 2.8419331206600704
Validation loss: 2.708691096439081

Epoch: 5| Step: 10
Training loss: 2.0045273322137667
Validation loss: 2.686675970603955

Epoch: 352| Step: 0
Training loss: 2.036740555845882
Validation loss: 2.6494964767858153

Epoch: 5| Step: 1
Training loss: 2.2856851601447983
Validation loss: 2.5656228074561827

Epoch: 5| Step: 2
Training loss: 2.3902641472830197
Validation loss: 2.5642459652847527

Epoch: 5| Step: 3
Training loss: 2.7452687398411424
Validation loss: 2.5526158299438584

Epoch: 5| Step: 4
Training loss: 2.7976850476736232
Validation loss: 2.5339899227302833

Epoch: 5| Step: 5
Training loss: 2.329958814330642
Validation loss: 2.5307500424741445

Epoch: 5| Step: 6
Training loss: 2.4072683582198158
Validation loss: 2.5288219882047147

Epoch: 5| Step: 7
Training loss: 2.977365460563146
Validation loss: 2.5120677383718166

Epoch: 5| Step: 8
Training loss: 2.7407406198608477
Validation loss: 2.523084632022481

Epoch: 5| Step: 9
Training loss: 2.2889230314607385
Validation loss: 2.5069858140573076

Epoch: 5| Step: 10
Training loss: 2.359661868005062
Validation loss: 2.5159295377429394

Epoch: 353| Step: 0
Training loss: 2.940540282501693
Validation loss: 2.545290127394789

Epoch: 5| Step: 1
Training loss: 1.739555663233304
Validation loss: 2.560919040109193

Epoch: 5| Step: 2
Training loss: 2.773805233928482
Validation loss: 2.584609095421139

Epoch: 5| Step: 3
Training loss: 2.2108587783440083
Validation loss: 2.577549232385187

Epoch: 5| Step: 4
Training loss: 2.737278034843933
Validation loss: 2.558136267562836

Epoch: 5| Step: 5
Training loss: 2.604362653351042
Validation loss: 2.5405002478150602

Epoch: 5| Step: 6
Training loss: 1.896728122812781
Validation loss: 2.5192687561553986

Epoch: 5| Step: 7
Training loss: 2.461272589258751
Validation loss: 2.5333744200233537

Epoch: 5| Step: 8
Training loss: 2.9054607016853775
Validation loss: 2.527731581715839

Epoch: 5| Step: 9
Training loss: 2.1693861718138785
Validation loss: 2.5342386564839243

Epoch: 5| Step: 10
Training loss: 2.6409333178859824
Validation loss: 2.5237470801587665

Epoch: 354| Step: 0
Training loss: 2.579954850444959
Validation loss: 2.5390411148874548

Epoch: 5| Step: 1
Training loss: 2.599237542963039
Validation loss: 2.53922198202545

Epoch: 5| Step: 2
Training loss: 2.3565100650293163
Validation loss: 2.5219213422067233

Epoch: 5| Step: 3
Training loss: 2.563905842032636
Validation loss: 2.507354215013225

Epoch: 5| Step: 4
Training loss: 1.810390428617076
Validation loss: 2.528266812855336

Epoch: 5| Step: 5
Training loss: 2.6549442447763556
Validation loss: 2.5013582662174163

Epoch: 5| Step: 6
Training loss: 2.0191621719837216
Validation loss: 2.516082559005987

Epoch: 5| Step: 7
Training loss: 2.8512930964884196
Validation loss: 2.499992647980575

Epoch: 5| Step: 8
Training loss: 2.4216182449586077
Validation loss: 2.5062088161518927

Epoch: 5| Step: 9
Training loss: 2.7849149238289286
Validation loss: 2.533953651971121

Epoch: 5| Step: 10
Training loss: 2.3917506939773454
Validation loss: 2.557980894253995

Epoch: 355| Step: 0
Training loss: 2.2302302618847705
Validation loss: 2.5782298713403207

Epoch: 5| Step: 1
Training loss: 3.0028934830134597
Validation loss: 2.6078275449690627

Epoch: 5| Step: 2
Training loss: 2.3166556264307796
Validation loss: 2.596834650719949

Epoch: 5| Step: 3
Training loss: 2.3466886281300763
Validation loss: 2.58780186208947

Epoch: 5| Step: 4
Training loss: 2.421927765302218
Validation loss: 2.5877925191259172

Epoch: 5| Step: 5
Training loss: 2.2815064586553837
Validation loss: 2.523603975267936

Epoch: 5| Step: 6
Training loss: 2.0900771536571914
Validation loss: 2.523285562811346

Epoch: 5| Step: 7
Training loss: 1.7388946479618037
Validation loss: 2.508910835049483

Epoch: 5| Step: 8
Training loss: 3.0042957703198137
Validation loss: 2.526723418080451

Epoch: 5| Step: 9
Training loss: 2.646098766879655
Validation loss: 2.508487686555387

Epoch: 5| Step: 10
Training loss: 2.941484386931124
Validation loss: 2.533627497350213

Epoch: 356| Step: 0
Training loss: 1.8684138017942138
Validation loss: 2.582892665796754

Epoch: 5| Step: 1
Training loss: 2.5766952711773685
Validation loss: 2.609993398424889

Epoch: 5| Step: 2
Training loss: 3.1349081512089176
Validation loss: 2.6877556851157385

Epoch: 5| Step: 3
Training loss: 2.424330321979825
Validation loss: 2.6983020877914683

Epoch: 5| Step: 4
Training loss: 2.2532945460681195
Validation loss: 2.6096393995786973

Epoch: 5| Step: 5
Training loss: 2.2384082165668846
Validation loss: 2.5545360355584608

Epoch: 5| Step: 6
Training loss: 2.4473928553943387
Validation loss: 2.517861665873604

Epoch: 5| Step: 7
Training loss: 2.845658720215922
Validation loss: 2.5028931448535596

Epoch: 5| Step: 8
Training loss: 2.0946088708924835
Validation loss: 2.4908940180909642

Epoch: 5| Step: 9
Training loss: 2.6589020896924356
Validation loss: 2.494194158734606

Epoch: 5| Step: 10
Training loss: 2.572563970899246
Validation loss: 2.490477543764503

Epoch: 357| Step: 0
Training loss: 2.7047560517313647
Validation loss: 2.5281473618545167

Epoch: 5| Step: 1
Training loss: 2.196640319010164
Validation loss: 2.5477280206477695

Epoch: 5| Step: 2
Training loss: 2.1301660012762302
Validation loss: 2.5693383461478936

Epoch: 5| Step: 3
Training loss: 2.4479930676380808
Validation loss: 2.5904249496443787

Epoch: 5| Step: 4
Training loss: 2.6387638553199615
Validation loss: 2.5350776110433593

Epoch: 5| Step: 5
Training loss: 2.8611041401240125
Validation loss: 2.515492642599045

Epoch: 5| Step: 6
Training loss: 2.2727816445175737
Validation loss: 2.501557823597417

Epoch: 5| Step: 7
Training loss: 2.155412373042284
Validation loss: 2.50502484080914

Epoch: 5| Step: 8
Training loss: 2.6795570630950043
Validation loss: 2.5192064225175743

Epoch: 5| Step: 9
Training loss: 2.13836071241675
Validation loss: 2.5514537812457148

Epoch: 5| Step: 10
Training loss: 2.7869636053768825
Validation loss: 2.6037319373415615

Epoch: 358| Step: 0
Training loss: 2.4991279988627446
Validation loss: 2.624303374705066

Epoch: 5| Step: 1
Training loss: 2.0389977221960316
Validation loss: 2.6530846031030983

Epoch: 5| Step: 2
Training loss: 1.5472025668944454
Validation loss: 2.6177955926255687

Epoch: 5| Step: 3
Training loss: 2.7630557610224384
Validation loss: 2.6050585479987527

Epoch: 5| Step: 4
Training loss: 2.4056011167249
Validation loss: 2.5973332681329078

Epoch: 5| Step: 5
Training loss: 2.699805718955529
Validation loss: 2.5818815693840333

Epoch: 5| Step: 6
Training loss: 2.5140324639991234
Validation loss: 2.5545477842562616

Epoch: 5| Step: 7
Training loss: 2.3221120310329493
Validation loss: 2.5218614590006028

Epoch: 5| Step: 8
Training loss: 3.092743989390511
Validation loss: 2.5119149389438564

Epoch: 5| Step: 9
Training loss: 2.209360699425242
Validation loss: 2.5046760748022288

Epoch: 5| Step: 10
Training loss: 2.683246084733753
Validation loss: 2.5152997047537613

Epoch: 359| Step: 0
Training loss: 2.243060643125052
Validation loss: 2.5201426573197843

Epoch: 5| Step: 1
Training loss: 2.5728535715209837
Validation loss: 2.5173585361066317

Epoch: 5| Step: 2
Training loss: 2.572455628719562
Validation loss: 2.5306150844587405

Epoch: 5| Step: 3
Training loss: 2.7391295159906357
Validation loss: 2.541273826716341

Epoch: 5| Step: 4
Training loss: 2.4929193360904525
Validation loss: 2.5223522869463864

Epoch: 5| Step: 5
Training loss: 2.7535375037090515
Validation loss: 2.5301744502147936

Epoch: 5| Step: 6
Training loss: 2.218040890274608
Validation loss: 2.5161817012763987

Epoch: 5| Step: 7
Training loss: 2.1842851175526428
Validation loss: 2.5007704603803793

Epoch: 5| Step: 8
Training loss: 1.973395422504266
Validation loss: 2.5159674958888694

Epoch: 5| Step: 9
Training loss: 2.785212576404925
Validation loss: 2.516632159732069

Epoch: 5| Step: 10
Training loss: 2.297881859394405
Validation loss: 2.549972351900728

Epoch: 360| Step: 0
Training loss: 2.103264442117672
Validation loss: 2.581359939838045

Epoch: 5| Step: 1
Training loss: 2.276350010660205
Validation loss: 2.631315188045775

Epoch: 5| Step: 2
Training loss: 2.5514949717231974
Validation loss: 2.6500686267457465

Epoch: 5| Step: 3
Training loss: 2.5191207196429226
Validation loss: 2.629298106110296

Epoch: 5| Step: 4
Training loss: 2.5501505377222666
Validation loss: 2.5627202125207695

Epoch: 5| Step: 5
Training loss: 2.2329538801105326
Validation loss: 2.538656281316787

Epoch: 5| Step: 6
Training loss: 2.7861704644975998
Validation loss: 2.523326549670733

Epoch: 5| Step: 7
Training loss: 2.3230780871860115
Validation loss: 2.502212057477077

Epoch: 5| Step: 8
Training loss: 2.2974099295376913
Validation loss: 2.504115556422575

Epoch: 5| Step: 9
Training loss: 2.512326275337505
Validation loss: 2.5199002442715224

Epoch: 5| Step: 10
Training loss: 2.7107302012049015
Validation loss: 2.5046799837052784

Epoch: 361| Step: 0
Training loss: 2.0873804709197596
Validation loss: 2.4893088209795016

Epoch: 5| Step: 1
Training loss: 2.89876404436862
Validation loss: 2.505458504538498

Epoch: 5| Step: 2
Training loss: 2.200427195947534
Validation loss: 2.5273795455556005

Epoch: 5| Step: 3
Training loss: 2.7080035864779504
Validation loss: 2.5438414766721773

Epoch: 5| Step: 4
Training loss: 2.380812509152149
Validation loss: 2.565713170995754

Epoch: 5| Step: 5
Training loss: 2.084679270530655
Validation loss: 2.5600342511217407

Epoch: 5| Step: 6
Training loss: 2.200142539348514
Validation loss: 2.562589500258882

Epoch: 5| Step: 7
Training loss: 2.280509724106785
Validation loss: 2.5437597703470187

Epoch: 5| Step: 8
Training loss: 2.911200460206551
Validation loss: 2.5489386502233837

Epoch: 5| Step: 9
Training loss: 2.326344468434421
Validation loss: 2.538810721788208

Epoch: 5| Step: 10
Training loss: 2.572343389194447
Validation loss: 2.533347593166435

Epoch: 362| Step: 0
Training loss: 2.5811468736493106
Validation loss: 2.509623461486323

Epoch: 5| Step: 1
Training loss: 2.177122623752222
Validation loss: 2.526639924385817

Epoch: 5| Step: 2
Training loss: 3.0744903328160897
Validation loss: 2.5375560376255524

Epoch: 5| Step: 3
Training loss: 2.7346764970500748
Validation loss: 2.552555802094381

Epoch: 5| Step: 4
Training loss: 2.3545613478475325
Validation loss: 2.540399170460114

Epoch: 5| Step: 5
Training loss: 2.281181125384993
Validation loss: 2.5222738748930835

Epoch: 5| Step: 6
Training loss: 2.283282798244991
Validation loss: 2.5100469914876262

Epoch: 5| Step: 7
Training loss: 2.2469650568840427
Validation loss: 2.5078746466069313

Epoch: 5| Step: 8
Training loss: 2.248508912967782
Validation loss: 2.4838363177995397

Epoch: 5| Step: 9
Training loss: 2.1328650387731067
Validation loss: 2.498030759618357

Epoch: 5| Step: 10
Training loss: 2.5786533623476755
Validation loss: 2.515395243486284

Epoch: 363| Step: 0
Training loss: 2.8204979663848984
Validation loss: 2.511723318523068

Epoch: 5| Step: 1
Training loss: 2.222834735803657
Validation loss: 2.5192426593348594

Epoch: 5| Step: 2
Training loss: 2.418780903778976
Validation loss: 2.5597635620409527

Epoch: 5| Step: 3
Training loss: 2.410064744989795
Validation loss: 2.5666811886576224

Epoch: 5| Step: 4
Training loss: 2.411122924240558
Validation loss: 2.5698233064503335

Epoch: 5| Step: 5
Training loss: 2.5997485002509158
Validation loss: 2.6121796342605914

Epoch: 5| Step: 6
Training loss: 2.677123152341471
Validation loss: 2.5522606780308603

Epoch: 5| Step: 7
Training loss: 2.5855197165642405
Validation loss: 2.535523922814797

Epoch: 5| Step: 8
Training loss: 1.644867416418854
Validation loss: 2.541761614073197

Epoch: 5| Step: 9
Training loss: 2.404736625065497
Validation loss: 2.529885619500835

Epoch: 5| Step: 10
Training loss: 2.16711683976344
Validation loss: 2.5118298711487967

Epoch: 364| Step: 0
Training loss: 2.398207165719987
Validation loss: 2.4922029341296508

Epoch: 5| Step: 1
Training loss: 2.5353866495964
Validation loss: 2.48694418674414

Epoch: 5| Step: 2
Training loss: 2.4408189723342426
Validation loss: 2.4671838563505633

Epoch: 5| Step: 3
Training loss: 2.3668561143224913
Validation loss: 2.484175747536408

Epoch: 5| Step: 4
Training loss: 1.6519354999041294
Validation loss: 2.513064746365689

Epoch: 5| Step: 5
Training loss: 2.7932294390468027
Validation loss: 2.519962006300563

Epoch: 5| Step: 6
Training loss: 2.2439709525378757
Validation loss: 2.5396523329935747

Epoch: 5| Step: 7
Training loss: 2.2675547832697216
Validation loss: 2.5398508306762992

Epoch: 5| Step: 8
Training loss: 2.8208607486836983
Validation loss: 2.5599248018183074

Epoch: 5| Step: 9
Training loss: 2.685201859940047
Validation loss: 2.5229501246284056

Epoch: 5| Step: 10
Training loss: 2.1973219393825176
Validation loss: 2.5224937300359875

Epoch: 365| Step: 0
Training loss: 1.8947857557990635
Validation loss: 2.5098029010874665

Epoch: 5| Step: 1
Training loss: 2.9309245435202813
Validation loss: 2.5007047864661414

Epoch: 5| Step: 2
Training loss: 2.7916558868048247
Validation loss: 2.506807355014992

Epoch: 5| Step: 3
Training loss: 2.2967558330321887
Validation loss: 2.4933017561119764

Epoch: 5| Step: 4
Training loss: 2.1944914127372184
Validation loss: 2.4832106777253107

Epoch: 5| Step: 5
Training loss: 2.8443004368879112
Validation loss: 2.48150894695508

Epoch: 5| Step: 6
Training loss: 2.2338969112643157
Validation loss: 2.4928882853274765

Epoch: 5| Step: 7
Training loss: 2.328123975919972
Validation loss: 2.5204697009970802

Epoch: 5| Step: 8
Training loss: 2.0858169120765
Validation loss: 2.5777877313555857

Epoch: 5| Step: 9
Training loss: 2.384183895507059
Validation loss: 2.6149080495899657

Epoch: 5| Step: 10
Training loss: 2.3585702900637466
Validation loss: 2.639968407926034

Epoch: 366| Step: 0
Training loss: 2.206471383980031
Validation loss: 2.620418836479416

Epoch: 5| Step: 1
Training loss: 2.4640576156345255
Validation loss: 2.604854557531779

Epoch: 5| Step: 2
Training loss: 2.286030502669849
Validation loss: 2.568904130423049

Epoch: 5| Step: 3
Training loss: 2.1534323596131824
Validation loss: 2.535102796525884

Epoch: 5| Step: 4
Training loss: 2.2341357549881136
Validation loss: 2.501187910858931

Epoch: 5| Step: 5
Training loss: 2.8718049913575663
Validation loss: 2.4823622384596895

Epoch: 5| Step: 6
Training loss: 2.239335322878969
Validation loss: 2.4540705094804998

Epoch: 5| Step: 7
Training loss: 2.3703642324637486
Validation loss: 2.464079156276831

Epoch: 5| Step: 8
Training loss: 2.8137981385934916
Validation loss: 2.4797614030437556

Epoch: 5| Step: 9
Training loss: 2.415425332565867
Validation loss: 2.480633822099854

Epoch: 5| Step: 10
Training loss: 2.695288085826928
Validation loss: 2.537724437534446

Epoch: 367| Step: 0
Training loss: 2.1008168993131453
Validation loss: 2.56608755099785

Epoch: 5| Step: 1
Training loss: 2.5658623570478096
Validation loss: 2.6196256924356343

Epoch: 5| Step: 2
Training loss: 2.4280473380022545
Validation loss: 2.636156415994313

Epoch: 5| Step: 3
Training loss: 3.2814406566633387
Validation loss: 2.702476788403364

Epoch: 5| Step: 4
Training loss: 2.6332514818564556
Validation loss: 2.650073069948254

Epoch: 5| Step: 5
Training loss: 1.7224975651251826
Validation loss: 2.5426001301366634

Epoch: 5| Step: 6
Training loss: 2.9832355660840837
Validation loss: 2.4986163853335377

Epoch: 5| Step: 7
Training loss: 2.8102114373208167
Validation loss: 2.4636839225229408

Epoch: 5| Step: 8
Training loss: 2.0575526462276224
Validation loss: 2.4337055741102094

Epoch: 5| Step: 9
Training loss: 1.999055818370955
Validation loss: 2.452010651513363

Epoch: 5| Step: 10
Training loss: 2.015758776106637
Validation loss: 2.4494414855871036

Epoch: 368| Step: 0
Training loss: 2.420181174314003
Validation loss: 2.4592304977263857

Epoch: 5| Step: 1
Training loss: 2.1651881626461673
Validation loss: 2.4595984270902993

Epoch: 5| Step: 2
Training loss: 2.815885921670966
Validation loss: 2.4634675094105094

Epoch: 5| Step: 3
Training loss: 3.1057655432566342
Validation loss: 2.5144702459962907

Epoch: 5| Step: 4
Training loss: 2.247384564550857
Validation loss: 2.5362702515345275

Epoch: 5| Step: 5
Training loss: 2.2791976057204058
Validation loss: 2.5642609077129825

Epoch: 5| Step: 6
Training loss: 2.3412046725665947
Validation loss: 2.627451007780797

Epoch: 5| Step: 7
Training loss: 2.8927287926028793
Validation loss: 2.6815941440186273

Epoch: 5| Step: 8
Training loss: 2.341787406641357
Validation loss: 2.6368311116027527

Epoch: 5| Step: 9
Training loss: 2.1927047934847157
Validation loss: 2.5755740166575354

Epoch: 5| Step: 10
Training loss: 2.071329924860666
Validation loss: 2.550613132197951

Epoch: 369| Step: 0
Training loss: 2.3715914309218964
Validation loss: 2.5263899260002165

Epoch: 5| Step: 1
Training loss: 2.3211149632663552
Validation loss: 2.503803494679242

Epoch: 5| Step: 2
Training loss: 2.7263013829457403
Validation loss: 2.4733305390474887

Epoch: 5| Step: 3
Training loss: 2.2978417055475475
Validation loss: 2.4757060937534954

Epoch: 5| Step: 4
Training loss: 2.441213957270964
Validation loss: 2.4797968785129054

Epoch: 5| Step: 5
Training loss: 2.720664128820271
Validation loss: 2.4923580447056835

Epoch: 5| Step: 6
Training loss: 2.623240289779021
Validation loss: 2.535971042607672

Epoch: 5| Step: 7
Training loss: 1.7718710682335883
Validation loss: 2.561053583411667

Epoch: 5| Step: 8
Training loss: 2.46868094818506
Validation loss: 2.603784625835074

Epoch: 5| Step: 9
Training loss: 2.5377992275056784
Validation loss: 2.633815510667238

Epoch: 5| Step: 10
Training loss: 2.516999242504371
Validation loss: 2.6430590574182675

Epoch: 370| Step: 0
Training loss: 2.2503434025121
Validation loss: 2.6524464301640265

Epoch: 5| Step: 1
Training loss: 2.0073551592232026
Validation loss: 2.6178648800452513

Epoch: 5| Step: 2
Training loss: 1.9907491241035418
Validation loss: 2.5902783609773192

Epoch: 5| Step: 3
Training loss: 2.3010707601835243
Validation loss: 2.55562009130989

Epoch: 5| Step: 4
Training loss: 2.4865630489098027
Validation loss: 2.541992155227477

Epoch: 5| Step: 5
Training loss: 2.9133748324629822
Validation loss: 2.5224055766421203

Epoch: 5| Step: 6
Training loss: 2.9953930767844548
Validation loss: 2.496323538167631

Epoch: 5| Step: 7
Training loss: 2.547805709689452
Validation loss: 2.4950498178953326

Epoch: 5| Step: 8
Training loss: 2.646612207907806
Validation loss: 2.483427110817232

Epoch: 5| Step: 9
Training loss: 1.5418782303818417
Validation loss: 2.517945866054779

Epoch: 5| Step: 10
Training loss: 2.699979241609248
Validation loss: 2.545045838136124

Epoch: 371| Step: 0
Training loss: 2.4873694840892493
Validation loss: 2.55629490068952

Epoch: 5| Step: 1
Training loss: 2.6940945292131873
Validation loss: 2.573297661135516

Epoch: 5| Step: 2
Training loss: 2.168569340725509
Validation loss: 2.555511529366992

Epoch: 5| Step: 3
Training loss: 2.670442074242991
Validation loss: 2.604339173212568

Epoch: 5| Step: 4
Training loss: 1.9985239423320253
Validation loss: 2.605044338526141

Epoch: 5| Step: 5
Training loss: 2.5911924322848683
Validation loss: 2.5805647566405865

Epoch: 5| Step: 6
Training loss: 1.545468934012562
Validation loss: 2.5766349854570088

Epoch: 5| Step: 7
Training loss: 2.8454048455978214
Validation loss: 2.5533679440454997

Epoch: 5| Step: 8
Training loss: 2.340759302011814
Validation loss: 2.5424084487890766

Epoch: 5| Step: 9
Training loss: 2.229231135306602
Validation loss: 2.525998256975527

Epoch: 5| Step: 10
Training loss: 2.543427456738574
Validation loss: 2.536356905217083

Epoch: 372| Step: 0
Training loss: 2.5479078012490506
Validation loss: 2.520820109828381

Epoch: 5| Step: 1
Training loss: 1.8425934607146812
Validation loss: 2.5396813988011617

Epoch: 5| Step: 2
Training loss: 2.3582020047917975
Validation loss: 2.547887149427479

Epoch: 5| Step: 3
Training loss: 2.43614295939621
Validation loss: 2.5714868348326925

Epoch: 5| Step: 4
Training loss: 2.2446517959765306
Validation loss: 2.6236743138247394

Epoch: 5| Step: 5
Training loss: 2.948343432552737
Validation loss: 2.617676517237123

Epoch: 5| Step: 6
Training loss: 2.5838896142216807
Validation loss: 2.6011450386784762

Epoch: 5| Step: 7
Training loss: 2.2920991200556027
Validation loss: 2.556280797740806

Epoch: 5| Step: 8
Training loss: 2.3378563593980135
Validation loss: 2.5374012712328007

Epoch: 5| Step: 9
Training loss: 2.404537037088831
Validation loss: 2.513021716096929

Epoch: 5| Step: 10
Training loss: 2.0179646242744194
Validation loss: 2.486935322538329

Epoch: 373| Step: 0
Training loss: 2.908953649902362
Validation loss: 2.511838944503783

Epoch: 5| Step: 1
Training loss: 2.118729933922195
Validation loss: 2.526689125020425

Epoch: 5| Step: 2
Training loss: 2.389847971977004
Validation loss: 2.5462960403589756

Epoch: 5| Step: 3
Training loss: 1.961418123351369
Validation loss: 2.547379662708654

Epoch: 5| Step: 4
Training loss: 2.2401225187650717
Validation loss: 2.5838217374494614

Epoch: 5| Step: 5
Training loss: 2.8491551937360597
Validation loss: 2.5758490715608073

Epoch: 5| Step: 6
Training loss: 2.3425194116396755
Validation loss: 2.5654341578764233

Epoch: 5| Step: 7
Training loss: 2.2990917485709805
Validation loss: 2.5450452619568713

Epoch: 5| Step: 8
Training loss: 2.3305293219505288
Validation loss: 2.5392496584941657

Epoch: 5| Step: 9
Training loss: 2.3485295707233
Validation loss: 2.525769336475524

Epoch: 5| Step: 10
Training loss: 2.287643669911431
Validation loss: 2.5234259650829265

Epoch: 374| Step: 0
Training loss: 2.576140316067832
Validation loss: 2.479204424884833

Epoch: 5| Step: 1
Training loss: 2.4094208471782466
Validation loss: 2.4913469619453723

Epoch: 5| Step: 2
Training loss: 2.7534892747267343
Validation loss: 2.467816084424636

Epoch: 5| Step: 3
Training loss: 1.9098724591278047
Validation loss: 2.475990619378514

Epoch: 5| Step: 4
Training loss: 2.614044397340468
Validation loss: 2.4974043425313095

Epoch: 5| Step: 5
Training loss: 2.6784018944267585
Validation loss: 2.4998473797634686

Epoch: 5| Step: 6
Training loss: 2.4667165566459595
Validation loss: 2.502530900596968

Epoch: 5| Step: 7
Training loss: 2.217791605530218
Validation loss: 2.512740895940546

Epoch: 5| Step: 8
Training loss: 2.068755287555495
Validation loss: 2.52910914622173

Epoch: 5| Step: 9
Training loss: 2.122199513223434
Validation loss: 2.5449551578027285

Epoch: 5| Step: 10
Training loss: 2.1338326386425734
Validation loss: 2.5613693426086543

Epoch: 375| Step: 0
Training loss: 2.4717529961224547
Validation loss: 2.577813103218921

Epoch: 5| Step: 1
Training loss: 2.384431282869064
Validation loss: 2.5888329234338205

Epoch: 5| Step: 2
Training loss: 2.244517534574568
Validation loss: 2.5772270540645232

Epoch: 5| Step: 3
Training loss: 2.7533765351028863
Validation loss: 2.585360269388429

Epoch: 5| Step: 4
Training loss: 2.0527342588531723
Validation loss: 2.5460472873243236

Epoch: 5| Step: 5
Training loss: 2.4974675703568465
Validation loss: 2.522727850014566

Epoch: 5| Step: 6
Training loss: 2.2561817021481025
Validation loss: 2.508746936834505

Epoch: 5| Step: 7
Training loss: 2.0024833758517806
Validation loss: 2.501630791600252

Epoch: 5| Step: 8
Training loss: 2.61451735292951
Validation loss: 2.5033115399133536

Epoch: 5| Step: 9
Training loss: 2.382508205307624
Validation loss: 2.514695512693567

Epoch: 5| Step: 10
Training loss: 2.134393574087887
Validation loss: 2.5255549027927584

Epoch: 376| Step: 0
Training loss: 2.7240233744824147
Validation loss: 2.548088595391581

Epoch: 5| Step: 1
Training loss: 2.838019833442361
Validation loss: 2.5477821752152447

Epoch: 5| Step: 2
Training loss: 2.4051017498611276
Validation loss: 2.5396536806029686

Epoch: 5| Step: 3
Training loss: 2.467119475206632
Validation loss: 2.5115728402099413

Epoch: 5| Step: 4
Training loss: 2.0385177878604197
Validation loss: 2.4958486339565673

Epoch: 5| Step: 5
Training loss: 2.7154263756284647
Validation loss: 2.48220774417339

Epoch: 5| Step: 6
Training loss: 1.7229879669725716
Validation loss: 2.496962858991648

Epoch: 5| Step: 7
Training loss: 2.5796443277093277
Validation loss: 2.499661318080049

Epoch: 5| Step: 8
Training loss: 2.048970438448417
Validation loss: 2.522647918146871

Epoch: 5| Step: 9
Training loss: 2.0710408782829575
Validation loss: 2.5547937518670794

Epoch: 5| Step: 10
Training loss: 2.1743072502719585
Validation loss: 2.527612372169614

Epoch: 377| Step: 0
Training loss: 2.6808265511716796
Validation loss: 2.4993117328454897

Epoch: 5| Step: 1
Training loss: 2.1640948902556842
Validation loss: 2.470227339601151

Epoch: 5| Step: 2
Training loss: 2.4789959717872088
Validation loss: 2.4509482004801018

Epoch: 5| Step: 3
Training loss: 2.3072862359550634
Validation loss: 2.4565105361531354

Epoch: 5| Step: 4
Training loss: 2.113821922987088
Validation loss: 2.4357669676043394

Epoch: 5| Step: 5
Training loss: 1.99179408358827
Validation loss: 2.453921577807515

Epoch: 5| Step: 6
Training loss: 2.5694720624751084
Validation loss: 2.487351104201317

Epoch: 5| Step: 7
Training loss: 2.1908571912013732
Validation loss: 2.5247703604990677

Epoch: 5| Step: 8
Training loss: 2.789403899853177
Validation loss: 2.5681440273328504

Epoch: 5| Step: 9
Training loss: 2.281938527334906
Validation loss: 2.6048468002289695

Epoch: 5| Step: 10
Training loss: 2.2087631047307505
Validation loss: 2.6309528347780495

Epoch: 378| Step: 0
Training loss: 2.2718520256465484
Validation loss: 2.671357358068562

Epoch: 5| Step: 1
Training loss: 2.2656240529025498
Validation loss: 2.614738544726554

Epoch: 5| Step: 2
Training loss: 2.4221366494877006
Validation loss: 2.5666397889246446

Epoch: 5| Step: 3
Training loss: 2.3225185811559084
Validation loss: 2.521780336681707

Epoch: 5| Step: 4
Training loss: 2.6037210210322055
Validation loss: 2.503630006474678

Epoch: 5| Step: 5
Training loss: 2.028093203161642
Validation loss: 2.4717978130889535

Epoch: 5| Step: 6
Training loss: 2.165380854420289
Validation loss: 2.4702216788291063

Epoch: 5| Step: 7
Training loss: 2.3742751973086293
Validation loss: 2.4772186740200444

Epoch: 5| Step: 8
Training loss: 2.496407789077184
Validation loss: 2.4775045532517175

Epoch: 5| Step: 9
Training loss: 2.640159791676621
Validation loss: 2.5068237197521803

Epoch: 5| Step: 10
Training loss: 2.339578400151211
Validation loss: 2.5356211209926145

Epoch: 379| Step: 0
Training loss: 2.2256594248645234
Validation loss: 2.56310172110653

Epoch: 5| Step: 1
Training loss: 2.357060086254405
Validation loss: 2.6447820104844464

Epoch: 5| Step: 2
Training loss: 2.896128925267316
Validation loss: 2.6624789106046127

Epoch: 5| Step: 3
Training loss: 2.364121569836575
Validation loss: 2.547831191960009

Epoch: 5| Step: 4
Training loss: 2.2166063941084775
Validation loss: 2.4861366494619075

Epoch: 5| Step: 5
Training loss: 2.2179546811261264
Validation loss: 2.4581808432588645

Epoch: 5| Step: 6
Training loss: 2.5161343645263345
Validation loss: 2.4517219104452765

Epoch: 5| Step: 7
Training loss: 2.5198872159514845
Validation loss: 2.447687626799037

Epoch: 5| Step: 8
Training loss: 2.1592045320611
Validation loss: 2.442020663614582

Epoch: 5| Step: 9
Training loss: 1.9419967398100495
Validation loss: 2.47436704790308

Epoch: 5| Step: 10
Training loss: 2.7160098418842593
Validation loss: 2.4840489407852773

Epoch: 380| Step: 0
Training loss: 2.2872146595242597
Validation loss: 2.516193402873394

Epoch: 5| Step: 1
Training loss: 2.2749543782784505
Validation loss: 2.5473678859827493

Epoch: 5| Step: 2
Training loss: 2.652001607454253
Validation loss: 2.5721967757087403

Epoch: 5| Step: 3
Training loss: 2.899262097630084
Validation loss: 2.58756248989563

Epoch: 5| Step: 4
Training loss: 1.9583627887972588
Validation loss: 2.5796568982063697

Epoch: 5| Step: 5
Training loss: 1.9532737370123703
Validation loss: 2.5734275963871864

Epoch: 5| Step: 6
Training loss: 2.2937619658529638
Validation loss: 2.565797483448235

Epoch: 5| Step: 7
Training loss: 2.651151183938339
Validation loss: 2.544117746434982

Epoch: 5| Step: 8
Training loss: 1.9543498966665267
Validation loss: 2.4900555086733585

Epoch: 5| Step: 9
Training loss: 2.2086918617805
Validation loss: 2.5207312815901495

Epoch: 5| Step: 10
Training loss: 2.3346440743610093
Validation loss: 2.483238576862494

Epoch: 381| Step: 0
Training loss: 2.4369842766218155
Validation loss: 2.494760147324811

Epoch: 5| Step: 1
Training loss: 2.3850598352951717
Validation loss: 2.5061047548114055

Epoch: 5| Step: 2
Training loss: 2.081280714386903
Validation loss: 2.509255946419527

Epoch: 5| Step: 3
Training loss: 1.9514247360044192
Validation loss: 2.5268600317190697

Epoch: 5| Step: 4
Training loss: 2.1289728836690696
Validation loss: 2.5493136000690515

Epoch: 5| Step: 5
Training loss: 2.161485259719487
Validation loss: 2.544078451894172

Epoch: 5| Step: 6
Training loss: 2.8732979753565395
Validation loss: 2.565207657830056

Epoch: 5| Step: 7
Training loss: 2.4995709051005623
Validation loss: 2.531547338517272

Epoch: 5| Step: 8
Training loss: 2.1657793967074848
Validation loss: 2.509536330104401

Epoch: 5| Step: 9
Training loss: 2.175052650954415
Validation loss: 2.4741663682878223

Epoch: 5| Step: 10
Training loss: 2.562406584734976
Validation loss: 2.474466457721049

Epoch: 382| Step: 0
Training loss: 2.225733338279193
Validation loss: 2.4846982719166046

Epoch: 5| Step: 1
Training loss: 2.4811239984070106
Validation loss: 2.505623118691367

Epoch: 5| Step: 2
Training loss: 2.420714167837034
Validation loss: 2.5445156567605203

Epoch: 5| Step: 3
Training loss: 2.3218399312180695
Validation loss: 2.5594816822486224

Epoch: 5| Step: 4
Training loss: 2.2684010302970967
Validation loss: 2.5687445670621494

Epoch: 5| Step: 5
Training loss: 2.620779823116796
Validation loss: 2.558709634515723

Epoch: 5| Step: 6
Training loss: 1.9761121636422052
Validation loss: 2.5223643197101073

Epoch: 5| Step: 7
Training loss: 2.125203066828285
Validation loss: 2.511634549284667

Epoch: 5| Step: 8
Training loss: 1.6540421939528087
Validation loss: 2.472356552113058

Epoch: 5| Step: 9
Training loss: 2.73108226339619
Validation loss: 2.458280263139862

Epoch: 5| Step: 10
Training loss: 2.6186196124044048
Validation loss: 2.443339477362564

Epoch: 383| Step: 0
Training loss: 2.4823069091875296
Validation loss: 2.4496975796850697

Epoch: 5| Step: 1
Training loss: 2.5556387807129806
Validation loss: 2.4584448375271823

Epoch: 5| Step: 2
Training loss: 1.97326886324129
Validation loss: 2.448137309425084

Epoch: 5| Step: 3
Training loss: 2.1649449060843593
Validation loss: 2.4664133316237677

Epoch: 5| Step: 4
Training loss: 2.21466365129073
Validation loss: 2.475482037693894

Epoch: 5| Step: 5
Training loss: 2.4688972718941264
Validation loss: 2.4826519465794488

Epoch: 5| Step: 6
Training loss: 1.9969902041161076
Validation loss: 2.517455191225639

Epoch: 5| Step: 7
Training loss: 2.576493642984606
Validation loss: 2.5420809878289696

Epoch: 5| Step: 8
Training loss: 2.4609198675583603
Validation loss: 2.5955197755264248

Epoch: 5| Step: 9
Training loss: 1.8421042904815401
Validation loss: 2.5953125529854044

Epoch: 5| Step: 10
Training loss: 2.5262233603241735
Validation loss: 2.5589790595802584

Epoch: 384| Step: 0
Training loss: 2.6439185735828876
Validation loss: 2.5408238473228937

Epoch: 5| Step: 1
Training loss: 2.060965227080828
Validation loss: 2.489648844280531

Epoch: 5| Step: 2
Training loss: 2.095798344506499
Validation loss: 2.4429576860293256

Epoch: 5| Step: 3
Training loss: 2.042955445926447
Validation loss: 2.4451274868014963

Epoch: 5| Step: 4
Training loss: 2.5062112895611146
Validation loss: 2.439411413056711

Epoch: 5| Step: 5
Training loss: 2.772602912086686
Validation loss: 2.434907279986542

Epoch: 5| Step: 6
Training loss: 2.0254319424953335
Validation loss: 2.4483999877873073

Epoch: 5| Step: 7
Training loss: 2.08087114431391
Validation loss: 2.4846565044271673

Epoch: 5| Step: 8
Training loss: 2.2750600157146974
Validation loss: 2.5198880664670136

Epoch: 5| Step: 9
Training loss: 2.0635182728051933
Validation loss: 2.5932079193006867

Epoch: 5| Step: 10
Training loss: 2.809491307245328
Validation loss: 2.624151922992583

Epoch: 385| Step: 0
Training loss: 2.1184616477795375
Validation loss: 2.5896939210319836

Epoch: 5| Step: 1
Training loss: 2.612647100806393
Validation loss: 2.5653130702296645

Epoch: 5| Step: 2
Training loss: 2.00625656934952
Validation loss: 2.504177917626638

Epoch: 5| Step: 3
Training loss: 2.3115092036554783
Validation loss: 2.5168453928361827

Epoch: 5| Step: 4
Training loss: 2.533846241911479
Validation loss: 2.474378848818887

Epoch: 5| Step: 5
Training loss: 2.687294708217898
Validation loss: 2.489628879993583

Epoch: 5| Step: 6
Training loss: 2.1013611197151336
Validation loss: 2.4722222795248707

Epoch: 5| Step: 7
Training loss: 2.2553052874039228
Validation loss: 2.4830991472151434

Epoch: 5| Step: 8
Training loss: 2.1869317542836786
Validation loss: 2.5066574841510922

Epoch: 5| Step: 9
Training loss: 2.0510137517013307
Validation loss: 2.4837053226670727

Epoch: 5| Step: 10
Training loss: 2.287082584005928
Validation loss: 2.5175591754517597

Epoch: 386| Step: 0
Training loss: 2.3748641728159847
Validation loss: 2.526614454657834

Epoch: 5| Step: 1
Training loss: 2.5382570837953944
Validation loss: 2.510356682460868

Epoch: 5| Step: 2
Training loss: 1.9309572065798295
Validation loss: 2.536249930499032

Epoch: 5| Step: 3
Training loss: 2.557201396853565
Validation loss: 2.564881643376616

Epoch: 5| Step: 4
Training loss: 2.4462034899579033
Validation loss: 2.5551567608762977

Epoch: 5| Step: 5
Training loss: 2.3470551646396847
Validation loss: 2.5554119587024773

Epoch: 5| Step: 6
Training loss: 2.513003861496824
Validation loss: 2.545995942448647

Epoch: 5| Step: 7
Training loss: 2.0742105889743523
Validation loss: 2.5297215601095377

Epoch: 5| Step: 8
Training loss: 2.188118874335084
Validation loss: 2.5189491870878644

Epoch: 5| Step: 9
Training loss: 1.9975577582649193
Validation loss: 2.4727028328150493

Epoch: 5| Step: 10
Training loss: 1.9705172281893875
Validation loss: 2.484984044813434

Epoch: 387| Step: 0
Training loss: 2.2124406537216394
Validation loss: 2.4738368520826954

Epoch: 5| Step: 1
Training loss: 1.8561929995843462
Validation loss: 2.4828284060881876

Epoch: 5| Step: 2
Training loss: 2.314438806159557
Validation loss: 2.486375320866026

Epoch: 5| Step: 3
Training loss: 2.5660814518120785
Validation loss: 2.4940904143018923

Epoch: 5| Step: 4
Training loss: 2.690468235743579
Validation loss: 2.517981412392348

Epoch: 5| Step: 5
Training loss: 2.721804076364562
Validation loss: 2.573234426555164

Epoch: 5| Step: 6
Training loss: 2.031018287940733
Validation loss: 2.582980104174469

Epoch: 5| Step: 7
Training loss: 2.3912415550868484
Validation loss: 2.584929716952952

Epoch: 5| Step: 8
Training loss: 2.2223705785291004
Validation loss: 2.5088844434943645

Epoch: 5| Step: 9
Training loss: 1.711620525430313
Validation loss: 2.4701251987848982

Epoch: 5| Step: 10
Training loss: 2.228856454340471
Validation loss: 2.453394595792846

Epoch: 388| Step: 0
Training loss: 2.097208497407423
Validation loss: 2.443097207166695

Epoch: 5| Step: 1
Training loss: 2.3743841477047436
Validation loss: 2.425766425787358

Epoch: 5| Step: 2
Training loss: 2.654279449158674
Validation loss: 2.4294315178624797

Epoch: 5| Step: 3
Training loss: 2.0793506191832005
Validation loss: 2.4545520336240005

Epoch: 5| Step: 4
Training loss: 2.2061637321226524
Validation loss: 2.455590194468723

Epoch: 5| Step: 5
Training loss: 2.443996770160495
Validation loss: 2.500142224685973

Epoch: 5| Step: 6
Training loss: 2.424542539255231
Validation loss: 2.50531545706812

Epoch: 5| Step: 7
Training loss: 1.8734821533786545
Validation loss: 2.5671163326341166

Epoch: 5| Step: 8
Training loss: 2.548243336440829
Validation loss: 2.575425654967068

Epoch: 5| Step: 9
Training loss: 2.171059215115873
Validation loss: 2.5556934768517747

Epoch: 5| Step: 10
Training loss: 2.274117594192164
Validation loss: 2.527191330461967

Epoch: 389| Step: 0
Training loss: 2.3508862508420507
Validation loss: 2.5125483222583336

Epoch: 5| Step: 1
Training loss: 2.315084302121142
Validation loss: 2.492920025097499

Epoch: 5| Step: 2
Training loss: 2.2986787732919978
Validation loss: 2.4966183761875427

Epoch: 5| Step: 3
Training loss: 2.1733870697204125
Validation loss: 2.4891798461578114

Epoch: 5| Step: 4
Training loss: 1.7501245181879481
Validation loss: 2.4721527864903603

Epoch: 5| Step: 5
Training loss: 2.36639773851226
Validation loss: 2.4831175461866684

Epoch: 5| Step: 6
Training loss: 2.5511750973103022
Validation loss: 2.5069441980319342

Epoch: 5| Step: 7
Training loss: 2.1614142233396025
Validation loss: 2.53129570202048

Epoch: 5| Step: 8
Training loss: 2.7997189346662394
Validation loss: 2.541778447681937

Epoch: 5| Step: 9
Training loss: 1.8975640944761956
Validation loss: 2.5451511659442527

Epoch: 5| Step: 10
Training loss: 2.1479509392220035
Validation loss: 2.5845943113003895

Epoch: 390| Step: 0
Training loss: 2.3264746224720243
Validation loss: 2.573550560012004

Epoch: 5| Step: 1
Training loss: 2.60124841575446
Validation loss: 2.5394929617837194

Epoch: 5| Step: 2
Training loss: 2.1558557785786614
Validation loss: 2.5238169768892034

Epoch: 5| Step: 3
Training loss: 2.096430414996958
Validation loss: 2.4748537905205006

Epoch: 5| Step: 4
Training loss: 2.1700121897693476
Validation loss: 2.4939174675129125

Epoch: 5| Step: 5
Training loss: 2.2678796533211902
Validation loss: 2.497090087934492

Epoch: 5| Step: 6
Training loss: 2.8775513979301035
Validation loss: 2.4965514568148146

Epoch: 5| Step: 7
Training loss: 1.9001440846872695
Validation loss: 2.499032887676628

Epoch: 5| Step: 8
Training loss: 1.9592099425959613
Validation loss: 2.498389787895665

Epoch: 5| Step: 9
Training loss: 2.2953791515834427
Validation loss: 2.5333634170997663

Epoch: 5| Step: 10
Training loss: 2.0182084671107514
Validation loss: 2.510604283259357

Epoch: 391| Step: 0
Training loss: 2.409676428319117
Validation loss: 2.4905498744718972

Epoch: 5| Step: 1
Training loss: 2.7715086341102664
Validation loss: 2.482725664358562

Epoch: 5| Step: 2
Training loss: 1.5513530609052466
Validation loss: 2.470072026641745

Epoch: 5| Step: 3
Training loss: 2.390966253919191
Validation loss: 2.450028902167554

Epoch: 5| Step: 4
Training loss: 2.322554920807785
Validation loss: 2.4640702316653225

Epoch: 5| Step: 5
Training loss: 2.3671681620497256
Validation loss: 2.4552062578403224

Epoch: 5| Step: 6
Training loss: 2.3158052896799144
Validation loss: 2.4904865296959806

Epoch: 5| Step: 7
Training loss: 2.2727521669584987
Validation loss: 2.5169419983991657

Epoch: 5| Step: 8
Training loss: 1.795530794980659
Validation loss: 2.54219413890731

Epoch: 5| Step: 9
Training loss: 2.5112547260427935
Validation loss: 2.5428331177430357

Epoch: 5| Step: 10
Training loss: 1.876949314268374
Validation loss: 2.543700428467826

Epoch: 392| Step: 0
Training loss: 2.473110163337833
Validation loss: 2.505717720367793

Epoch: 5| Step: 1
Training loss: 2.315378820020645
Validation loss: 2.4914736966833297

Epoch: 5| Step: 2
Training loss: 2.5991810389157353
Validation loss: 2.474139042953834

Epoch: 5| Step: 3
Training loss: 2.069811720831724
Validation loss: 2.458558178841258

Epoch: 5| Step: 4
Training loss: 2.068049853456298
Validation loss: 2.4388222506511794

Epoch: 5| Step: 5
Training loss: 2.019246241751278
Validation loss: 2.430248795902094

Epoch: 5| Step: 6
Training loss: 2.1579377576533023
Validation loss: 2.4600764328018956

Epoch: 5| Step: 7
Training loss: 2.427622810187967
Validation loss: 2.491795636121219

Epoch: 5| Step: 8
Training loss: 2.456199420281994
Validation loss: 2.5351714973668087

Epoch: 5| Step: 9
Training loss: 2.414082844966353
Validation loss: 2.5344516868435263

Epoch: 5| Step: 10
Training loss: 1.6050346140233658
Validation loss: 2.5116778023527484

Epoch: 393| Step: 0
Training loss: 2.9800210719035625
Validation loss: 2.4769620460839814

Epoch: 5| Step: 1
Training loss: 1.8995580309754194
Validation loss: 2.4359559542381772

Epoch: 5| Step: 2
Training loss: 2.0241865148889087
Validation loss: 2.458948898486313

Epoch: 5| Step: 3
Training loss: 1.841381167668654
Validation loss: 2.469573431775304

Epoch: 5| Step: 4
Training loss: 2.3565335373817993
Validation loss: 2.4773724296082387

Epoch: 5| Step: 5
Training loss: 2.2031268397113886
Validation loss: 2.4811890256322635

Epoch: 5| Step: 6
Training loss: 2.0673989577782415
Validation loss: 2.4848283191722613

Epoch: 5| Step: 7
Training loss: 2.2791095254582268
Validation loss: 2.5036450987148817

Epoch: 5| Step: 8
Training loss: 2.3836936447131167
Validation loss: 2.5159369751473104

Epoch: 5| Step: 9
Training loss: 2.1101355417839174
Validation loss: 2.579009817657566

Epoch: 5| Step: 10
Training loss: 2.5676715118264766
Validation loss: 2.518347860250577

Epoch: 394| Step: 0
Training loss: 2.3244444152527306
Validation loss: 2.5363722605917784

Epoch: 5| Step: 1
Training loss: 2.256182864556118
Validation loss: 2.489599153627421

Epoch: 5| Step: 2
Training loss: 2.350366028220662
Validation loss: 2.511190300754966

Epoch: 5| Step: 3
Training loss: 2.341118314169
Validation loss: 2.5010565750289953

Epoch: 5| Step: 4
Training loss: 2.4287136861665184
Validation loss: 2.46299587720736

Epoch: 5| Step: 5
Training loss: 2.5691887622352887
Validation loss: 2.450549321541209

Epoch: 5| Step: 6
Training loss: 1.6888246635235307
Validation loss: 2.435316597722797

Epoch: 5| Step: 7
Training loss: 2.2295388122041095
Validation loss: 2.4627154944607983

Epoch: 5| Step: 8
Training loss: 2.4895749165114704
Validation loss: 2.4908017759412324

Epoch: 5| Step: 9
Training loss: 1.6664159188792615
Validation loss: 2.5161257284790617

Epoch: 5| Step: 10
Training loss: 2.204412746814691
Validation loss: 2.576154644167506

Epoch: 395| Step: 0
Training loss: 1.7748079088529627
Validation loss: 2.599349205069921

Epoch: 5| Step: 1
Training loss: 2.5287307635946052
Validation loss: 2.587060562348642

Epoch: 5| Step: 2
Training loss: 2.20836551810749
Validation loss: 2.5243473325891586

Epoch: 5| Step: 3
Training loss: 1.9516426259337472
Validation loss: 2.517442462885758

Epoch: 5| Step: 4
Training loss: 2.311466914180067
Validation loss: 2.478047204424258

Epoch: 5| Step: 5
Training loss: 2.4748521548724
Validation loss: 2.4566689876707333

Epoch: 5| Step: 6
Training loss: 2.4106369652029587
Validation loss: 2.458896511621631

Epoch: 5| Step: 7
Training loss: 2.2328875732614573
Validation loss: 2.435870613328517

Epoch: 5| Step: 8
Training loss: 1.8778067244543908
Validation loss: 2.4434924638261224

Epoch: 5| Step: 9
Training loss: 2.1285924277728174
Validation loss: 2.4420138524831745

Epoch: 5| Step: 10
Training loss: 2.627642709066903
Validation loss: 2.462865647263673

Epoch: 396| Step: 0
Training loss: 1.6880460491452933
Validation loss: 2.4859145678718964

Epoch: 5| Step: 1
Training loss: 2.535268349072074
Validation loss: 2.5299408663310725

Epoch: 5| Step: 2
Training loss: 2.3583388927200986
Validation loss: 2.5468900886318697

Epoch: 5| Step: 3
Training loss: 2.566165999920494
Validation loss: 2.5655006090259875

Epoch: 5| Step: 4
Training loss: 1.6116863060707642
Validation loss: 2.494834041670169

Epoch: 5| Step: 5
Training loss: 2.4107764140201797
Validation loss: 2.4497827413487427

Epoch: 5| Step: 6
Training loss: 1.9594560475599692
Validation loss: 2.415740091857475

Epoch: 5| Step: 7
Training loss: 2.396384090199998
Validation loss: 2.4071480468639943

Epoch: 5| Step: 8
Training loss: 2.518211693425327
Validation loss: 2.3973072271141893

Epoch: 5| Step: 9
Training loss: 2.506905555129931
Validation loss: 2.4223814435769193

Epoch: 5| Step: 10
Training loss: 2.1616918476003777
Validation loss: 2.4433545086765154

Epoch: 397| Step: 0
Training loss: 2.6152496907225165
Validation loss: 2.4658821253347787

Epoch: 5| Step: 1
Training loss: 2.747637514208318
Validation loss: 2.480335961520275

Epoch: 5| Step: 2
Training loss: 1.7828230353536418
Validation loss: 2.563925236952883

Epoch: 5| Step: 3
Training loss: 2.2191603375166875
Validation loss: 2.5828350021815063

Epoch: 5| Step: 4
Training loss: 1.942489229857291
Validation loss: 2.6272053573800633

Epoch: 5| Step: 5
Training loss: 2.2365655364905663
Validation loss: 2.6484619472482573

Epoch: 5| Step: 6
Training loss: 1.4868563341313636
Validation loss: 2.6147625903419818

Epoch: 5| Step: 7
Training loss: 1.9229260803631458
Validation loss: 2.551128872126566

Epoch: 5| Step: 8
Training loss: 2.4888557956497412
Validation loss: 2.5145077592220173

Epoch: 5| Step: 9
Training loss: 1.8623000146400146
Validation loss: 2.483978835307234

Epoch: 5| Step: 10
Training loss: 3.0144519797502523
Validation loss: 2.4314688391127905

Epoch: 398| Step: 0
Training loss: 2.3386771680377927
Validation loss: 2.4130469580616167

Epoch: 5| Step: 1
Training loss: 2.016502839782365
Validation loss: 2.404219674414853

Epoch: 5| Step: 2
Training loss: 1.9923868117017933
Validation loss: 2.4047091834872343

Epoch: 5| Step: 3
Training loss: 2.725877998364746
Validation loss: 2.4116969938751294

Epoch: 5| Step: 4
Training loss: 2.421241332803239
Validation loss: 2.4347054548834506

Epoch: 5| Step: 5
Training loss: 1.7526994049208808
Validation loss: 2.4553698939384003

Epoch: 5| Step: 6
Training loss: 1.8970135030190471
Validation loss: 2.506630323291005

Epoch: 5| Step: 7
Training loss: 2.1797804727175447
Validation loss: 2.5384876745894855

Epoch: 5| Step: 8
Training loss: 1.9991146154439876
Validation loss: 2.5646197217877127

Epoch: 5| Step: 9
Training loss: 2.5725431183963274
Validation loss: 2.621901456452097

Epoch: 5| Step: 10
Training loss: 2.4771121404933587
Validation loss: 2.713733862720193

Epoch: 399| Step: 0
Training loss: 2.111749739283693
Validation loss: 2.6801941707542616

Epoch: 5| Step: 1
Training loss: 2.696954729972537
Validation loss: 2.6026763379281084

Epoch: 5| Step: 2
Training loss: 1.7824850652638844
Validation loss: 2.483617418266579

Epoch: 5| Step: 3
Training loss: 2.399219298541231
Validation loss: 2.429526232518578

Epoch: 5| Step: 4
Training loss: 2.1676297859309326
Validation loss: 2.4059186962246653

Epoch: 5| Step: 5
Training loss: 2.2605199716989786
Validation loss: 2.3841875223889044

Epoch: 5| Step: 6
Training loss: 1.850108932174829
Validation loss: 2.3700468618075456

Epoch: 5| Step: 7
Training loss: 2.1295178576023184
Validation loss: 2.4143398407152468

Epoch: 5| Step: 8
Training loss: 2.528317012025897
Validation loss: 2.4125156349586394

Epoch: 5| Step: 9
Training loss: 2.3706515809592186
Validation loss: 2.456772258726244

Epoch: 5| Step: 10
Training loss: 2.3602096395000416
Validation loss: 2.540753528510464

Epoch: 400| Step: 0
Training loss: 2.9039849099011508
Validation loss: 2.598256219116358

Epoch: 5| Step: 1
Training loss: 2.317206773529873
Validation loss: 2.6259367209532387

Epoch: 5| Step: 2
Training loss: 2.0377929944896547
Validation loss: 2.6194662195611778

Epoch: 5| Step: 3
Training loss: 1.7818122110372943
Validation loss: 2.6073756460697632

Epoch: 5| Step: 4
Training loss: 2.395732236194246
Validation loss: 2.591088081631869

Epoch: 5| Step: 5
Training loss: 2.292709413903996
Validation loss: 2.510615763740752

Epoch: 5| Step: 6
Training loss: 2.2585842833028646
Validation loss: 2.480092647565538

Epoch: 5| Step: 7
Training loss: 1.9706553972285095
Validation loss: 2.439858873081193

Epoch: 5| Step: 8
Training loss: 1.9573562565395826
Validation loss: 2.4070985850862767

Epoch: 5| Step: 9
Training loss: 2.246822020180649
Validation loss: 2.39984604698929

Epoch: 5| Step: 10
Training loss: 2.125846021198894
Validation loss: 2.4081378132130453

Epoch: 401| Step: 0
Training loss: 2.431332929515814
Validation loss: 2.410941804557132

Epoch: 5| Step: 1
Training loss: 2.312081788883414
Validation loss: 2.391510028246737

Epoch: 5| Step: 2
Training loss: 1.779776381901382
Validation loss: 2.4510468531530702

Epoch: 5| Step: 3
Training loss: 2.374536368641975
Validation loss: 2.4922531273075093

Epoch: 5| Step: 4
Training loss: 2.2269104802776445
Validation loss: 2.5299355565267185

Epoch: 5| Step: 5
Training loss: 1.995053552181286
Validation loss: 2.566880280797751

Epoch: 5| Step: 6
Training loss: 2.1593647450094546
Validation loss: 2.5720751686874483

Epoch: 5| Step: 7
Training loss: 2.2010047395578023
Validation loss: 2.5878303167583603

Epoch: 5| Step: 8
Training loss: 2.506677768949853
Validation loss: 2.6114815151289212

Epoch: 5| Step: 9
Training loss: 1.9233110226681986
Validation loss: 2.642522233359623

Epoch: 5| Step: 10
Training loss: 2.5916475714402223
Validation loss: 2.6478604538596073

Epoch: 402| Step: 0
Training loss: 2.121969755189092
Validation loss: 2.5612184875180346

Epoch: 5| Step: 1
Training loss: 2.393903092949382
Validation loss: 2.4974658417368736

Epoch: 5| Step: 2
Training loss: 2.6598660258922444
Validation loss: 2.4226458828075472

Epoch: 5| Step: 3
Training loss: 2.16402889735165
Validation loss: 2.4252994256928013

Epoch: 5| Step: 4
Training loss: 2.3110872025455413
Validation loss: 2.4079667333059445

Epoch: 5| Step: 5
Training loss: 1.813448822022953
Validation loss: 2.3923887528862804

Epoch: 5| Step: 6
Training loss: 2.3238491245282162
Validation loss: 2.41128080406427

Epoch: 5| Step: 7
Training loss: 2.4108999332213257
Validation loss: 2.4338606555362836

Epoch: 5| Step: 8
Training loss: 2.1530470348133717
Validation loss: 2.4409829207075395

Epoch: 5| Step: 9
Training loss: 1.8228684191903815
Validation loss: 2.4718621211278236

Epoch: 5| Step: 10
Training loss: 2.0432964229931976
Validation loss: 2.5140573779803668

Epoch: 403| Step: 0
Training loss: 1.5276563865908928
Validation loss: 2.5523077324729027

Epoch: 5| Step: 1
Training loss: 2.4397484605926807
Validation loss: 2.578673846311371

Epoch: 5| Step: 2
Training loss: 2.2432586556976224
Validation loss: 2.638468180526745

Epoch: 5| Step: 3
Training loss: 1.6467570195654357
Validation loss: 2.6030609841915333

Epoch: 5| Step: 4
Training loss: 1.8515772436657523
Validation loss: 2.5849133875045682

Epoch: 5| Step: 5
Training loss: 2.697863358568697
Validation loss: 2.523372175749706

Epoch: 5| Step: 6
Training loss: 2.0707660682033624
Validation loss: 2.5110697117502263

Epoch: 5| Step: 7
Training loss: 2.0247572199962045
Validation loss: 2.44983904638222

Epoch: 5| Step: 8
Training loss: 2.454662642908537
Validation loss: 2.436967180955463

Epoch: 5| Step: 9
Training loss: 2.3459809938329195
Validation loss: 2.382133510066822

Epoch: 5| Step: 10
Training loss: 2.5028894892280174
Validation loss: 2.378505455674937

Epoch: 404| Step: 0
Training loss: 2.5358203082878905
Validation loss: 2.3754349856945005

Epoch: 5| Step: 1
Training loss: 2.495410330137967
Validation loss: 2.410031167284383

Epoch: 5| Step: 2
Training loss: 1.9444751086163496
Validation loss: 2.411775119062851

Epoch: 5| Step: 3
Training loss: 2.110670581943321
Validation loss: 2.4742419340125177

Epoch: 5| Step: 4
Training loss: 2.555104539527935
Validation loss: 2.5193978543560323

Epoch: 5| Step: 5
Training loss: 2.2212473823905468
Validation loss: 2.563916868868205

Epoch: 5| Step: 6
Training loss: 2.358748599134392
Validation loss: 2.518854138359884

Epoch: 5| Step: 7
Training loss: 1.4173758452066683
Validation loss: 2.511291251143296

Epoch: 5| Step: 8
Training loss: 2.2188871099526146
Validation loss: 2.463874187938084

Epoch: 5| Step: 9
Training loss: 2.19777272794165
Validation loss: 2.4509113514047693

Epoch: 5| Step: 10
Training loss: 2.000699516989369
Validation loss: 2.4411893720874516

Epoch: 405| Step: 0
Training loss: 2.4322191400490514
Validation loss: 2.4081213772006937

Epoch: 5| Step: 1
Training loss: 2.332144014069899
Validation loss: 2.4083329629910204

Epoch: 5| Step: 2
Training loss: 2.328738343009501
Validation loss: 2.430920090965072

Epoch: 5| Step: 3
Training loss: 2.4647600791501425
Validation loss: 2.4204915361494175

Epoch: 5| Step: 4
Training loss: 2.0709752587461945
Validation loss: 2.4558478807916733

Epoch: 5| Step: 5
Training loss: 1.7517112811668305
Validation loss: 2.4629758217824476

Epoch: 5| Step: 6
Training loss: 2.1809457954831646
Validation loss: 2.5795333322031095

Epoch: 5| Step: 7
Training loss: 2.132405560136343
Validation loss: 2.599821040523563

Epoch: 5| Step: 8
Training loss: 1.9726033722994971
Validation loss: 2.689718605604257

Epoch: 5| Step: 9
Training loss: 2.5363416912562644
Validation loss: 2.693224479105525

Epoch: 5| Step: 10
Training loss: 1.9157404181852964
Validation loss: 2.648239843221412

Epoch: 406| Step: 0
Training loss: 1.6412806336216217
Validation loss: 2.5601669133109177

Epoch: 5| Step: 1
Training loss: 1.9380292477246082
Validation loss: 2.4960105433173663

Epoch: 5| Step: 2
Training loss: 2.449608390028057
Validation loss: 2.470103476309268

Epoch: 5| Step: 3
Training loss: 2.638010931922178
Validation loss: 2.443820774486625

Epoch: 5| Step: 4
Training loss: 1.981171312183526
Validation loss: 2.431680043317754

Epoch: 5| Step: 5
Training loss: 1.8722398150881783
Validation loss: 2.4478589489445937

Epoch: 5| Step: 6
Training loss: 2.3580849259462333
Validation loss: 2.450228222615614

Epoch: 5| Step: 7
Training loss: 2.3089580732514836
Validation loss: 2.4829467704915045

Epoch: 5| Step: 8
Training loss: 2.7555996497362356
Validation loss: 2.5058800089811455

Epoch: 5| Step: 9
Training loss: 1.9953387301281
Validation loss: 2.5151800527604604

Epoch: 5| Step: 10
Training loss: 1.8796992224678957
Validation loss: 2.509013895153283

Epoch: 407| Step: 0
Training loss: 2.374444796266095
Validation loss: 2.5102008380785668

Epoch: 5| Step: 1
Training loss: 2.796610388145967
Validation loss: 2.5116018660635873

Epoch: 5| Step: 2
Training loss: 1.8719922419085686
Validation loss: 2.5077835841392333

Epoch: 5| Step: 3
Training loss: 1.9358521498861612
Validation loss: 2.512670408479976

Epoch: 5| Step: 4
Training loss: 2.0660210811133997
Validation loss: 2.489931317973608

Epoch: 5| Step: 5
Training loss: 2.674024286312498
Validation loss: 2.485111399082592

Epoch: 5| Step: 6
Training loss: 2.0487591174552953
Validation loss: 2.4062769142140454

Epoch: 5| Step: 7
Training loss: 2.3959647985684187
Validation loss: 2.3899687616248957

Epoch: 5| Step: 8
Training loss: 1.9855665098994733
Validation loss: 2.412868126903517

Epoch: 5| Step: 9
Training loss: 1.7484339109764047
Validation loss: 2.388441760587981

Epoch: 5| Step: 10
Training loss: 1.7871465960519382
Validation loss: 2.4034524217025375

Epoch: 408| Step: 0
Training loss: 2.387701303673465
Validation loss: 2.411998165217872

Epoch: 5| Step: 1
Training loss: 1.924730985595868
Validation loss: 2.4528685749845853

Epoch: 5| Step: 2
Training loss: 2.214494304237095
Validation loss: 2.504707631420395

Epoch: 5| Step: 3
Training loss: 2.2034100287281317
Validation loss: 2.5678461642668244

Epoch: 5| Step: 4
Training loss: 2.2792114137189015
Validation loss: 2.648438985852421

Epoch: 5| Step: 5
Training loss: 2.0466705686095046
Validation loss: 2.616263333035845

Epoch: 5| Step: 6
Training loss: 2.0671003650572874
Validation loss: 2.608250775236808

Epoch: 5| Step: 7
Training loss: 2.6034769797980504
Validation loss: 2.544953247881269

Epoch: 5| Step: 8
Training loss: 1.7625835858809071
Validation loss: 2.461813495997166

Epoch: 5| Step: 9
Training loss: 2.2851532243235844
Validation loss: 2.442086717376239

Epoch: 5| Step: 10
Training loss: 2.093979780199717
Validation loss: 2.404933083782072

Epoch: 409| Step: 0
Training loss: 1.6905200918651502
Validation loss: 2.3977586622546734

Epoch: 5| Step: 1
Training loss: 2.347166495881195
Validation loss: 2.385703988474401

Epoch: 5| Step: 2
Training loss: 2.610263513292419
Validation loss: 2.4285193148424833

Epoch: 5| Step: 3
Training loss: 2.174865639581428
Validation loss: 2.4213114484706697

Epoch: 5| Step: 4
Training loss: 2.6739417219865818
Validation loss: 2.473481449781

Epoch: 5| Step: 5
Training loss: 1.9714759846133314
Validation loss: 2.518257100661206

Epoch: 5| Step: 6
Training loss: 1.9095831325241517
Validation loss: 2.570067845039523

Epoch: 5| Step: 7
Training loss: 2.2516122975292636
Validation loss: 2.610052042421719

Epoch: 5| Step: 8
Training loss: 1.5871919828750805
Validation loss: 2.6546144298609162

Epoch: 5| Step: 9
Training loss: 2.4506512457549547
Validation loss: 2.5900080909939955

Epoch: 5| Step: 10
Training loss: 2.14951810537319
Validation loss: 2.5117206948894664

Epoch: 410| Step: 0
Training loss: 2.241451235586001
Validation loss: 2.4888473749940787

Epoch: 5| Step: 1
Training loss: 1.9404450460593115
Validation loss: 2.428033304731313

Epoch: 5| Step: 2
Training loss: 2.336207957861519
Validation loss: 2.386752110023845

Epoch: 5| Step: 3
Training loss: 2.1419137013180625
Validation loss: 2.3546873085560875

Epoch: 5| Step: 4
Training loss: 2.263641646860565
Validation loss: 2.408246069427607

Epoch: 5| Step: 5
Training loss: 2.0954391725668713
Validation loss: 2.3863209265541427

Epoch: 5| Step: 6
Training loss: 1.6116015393031786
Validation loss: 2.3820207103016515

Epoch: 5| Step: 7
Training loss: 2.539704884182939
Validation loss: 2.43051900313668

Epoch: 5| Step: 8
Training loss: 2.046659501940253
Validation loss: 2.4809108560731437

Epoch: 5| Step: 9
Training loss: 2.420402916240811
Validation loss: 2.525770757466676

Epoch: 5| Step: 10
Training loss: 2.264573372752005
Validation loss: 2.5435786110678826

Epoch: 411| Step: 0
Training loss: 1.701700227065866
Validation loss: 2.554090665168864

Epoch: 5| Step: 1
Training loss: 2.630776996639697
Validation loss: 2.5594201356637916

Epoch: 5| Step: 2
Training loss: 1.6950135560745494
Validation loss: 2.526203396872547

Epoch: 5| Step: 3
Training loss: 2.533565733522681
Validation loss: 2.461212319952826

Epoch: 5| Step: 4
Training loss: 2.1722032038297034
Validation loss: 2.4106501628323227

Epoch: 5| Step: 5
Training loss: 1.8401182581382414
Validation loss: 2.3987415427375347

Epoch: 5| Step: 6
Training loss: 2.001926209803826
Validation loss: 2.384573575799419

Epoch: 5| Step: 7
Training loss: 2.262247027169773
Validation loss: 2.4375018447688093

Epoch: 5| Step: 8
Training loss: 2.2419176105398546
Validation loss: 2.435159063442391

Epoch: 5| Step: 9
Training loss: 2.5930606891254575
Validation loss: 2.5137091910681395

Epoch: 5| Step: 10
Training loss: 1.9743856874993597
Validation loss: 2.4717183023722216

Epoch: 412| Step: 0
Training loss: 2.271828622882467
Validation loss: 2.424321663453873

Epoch: 5| Step: 1
Training loss: 2.196070204330042
Validation loss: 2.3985503902564838

Epoch: 5| Step: 2
Training loss: 2.3552963674548777
Validation loss: 2.431140637233496

Epoch: 5| Step: 3
Training loss: 2.2034685665110576
Validation loss: 2.4601840140378757

Epoch: 5| Step: 4
Training loss: 1.9294324698630214
Validation loss: 2.4796740236046735

Epoch: 5| Step: 5
Training loss: 1.7590764905380318
Validation loss: 2.4674841149744506

Epoch: 5| Step: 6
Training loss: 1.8327392641543219
Validation loss: 2.491208493447831

Epoch: 5| Step: 7
Training loss: 2.190213291807636
Validation loss: 2.5197174031478333

Epoch: 5| Step: 8
Training loss: 2.4352559250083115
Validation loss: 2.507448498331918

Epoch: 5| Step: 9
Training loss: 2.0970236394420216
Validation loss: 2.5039389968114705

Epoch: 5| Step: 10
Training loss: 2.2719011391837376
Validation loss: 2.478323508628096

Epoch: 413| Step: 0
Training loss: 2.0669346153721535
Validation loss: 2.439952679684101

Epoch: 5| Step: 1
Training loss: 2.0894947366641343
Validation loss: 2.460575181391616

Epoch: 5| Step: 2
Training loss: 2.4355003762414245
Validation loss: 2.492356950274552

Epoch: 5| Step: 3
Training loss: 2.540281877421116
Validation loss: 2.453810899596535

Epoch: 5| Step: 4
Training loss: 2.081539131678231
Validation loss: 2.421303871815836

Epoch: 5| Step: 5
Training loss: 2.424801934402384
Validation loss: 2.4174715836719964

Epoch: 5| Step: 6
Training loss: 2.411234659212394
Validation loss: 2.441966916258566

Epoch: 5| Step: 7
Training loss: 1.591589716437616
Validation loss: 2.445970112613383

Epoch: 5| Step: 8
Training loss: 1.9352397039819864
Validation loss: 2.4458414445495804

Epoch: 5| Step: 9
Training loss: 1.7270153711780205
Validation loss: 2.5295675872987164

Epoch: 5| Step: 10
Training loss: 2.123260683806038
Validation loss: 2.586465368599587

Epoch: 414| Step: 0
Training loss: 2.0484535012976886
Validation loss: 2.63843235786825

Epoch: 5| Step: 1
Training loss: 1.491117483232176
Validation loss: 2.5790478608043075

Epoch: 5| Step: 2
Training loss: 2.258498671650575
Validation loss: 2.5499960893492015

Epoch: 5| Step: 3
Training loss: 1.9017243365816197
Validation loss: 2.5110343473105696

Epoch: 5| Step: 4
Training loss: 1.8732034977733825
Validation loss: 2.4567177290109568

Epoch: 5| Step: 5
Training loss: 2.98535427783447
Validation loss: 2.458589191863253

Epoch: 5| Step: 6
Training loss: 2.1521131111539384
Validation loss: 2.4488676850285613

Epoch: 5| Step: 7
Training loss: 2.2441619792350527
Validation loss: 2.474972297030312

Epoch: 5| Step: 8
Training loss: 2.242265972399127
Validation loss: 2.525794804575712

Epoch: 5| Step: 9
Training loss: 1.8016889357388917
Validation loss: 2.515749391264898

Epoch: 5| Step: 10
Training loss: 2.2105349116887245
Validation loss: 2.4996819755330977

Epoch: 415| Step: 0
Training loss: 2.5591562366262703
Validation loss: 2.518503195407512

Epoch: 5| Step: 1
Training loss: 2.626967192544815
Validation loss: 2.5060027914154865

Epoch: 5| Step: 2
Training loss: 2.315314976663458
Validation loss: 2.515280279388485

Epoch: 5| Step: 3
Training loss: 2.2024971358143155
Validation loss: 2.483989181789853

Epoch: 5| Step: 4
Training loss: 2.101022189996785
Validation loss: 2.5065767207150382

Epoch: 5| Step: 5
Training loss: 1.7018370351714074
Validation loss: 2.46771102482166

Epoch: 5| Step: 6
Training loss: 2.076897739190636
Validation loss: 2.393752776130697

Epoch: 5| Step: 7
Training loss: 1.4980904026993946
Validation loss: 2.3583926153810677

Epoch: 5| Step: 8
Training loss: 1.9529366364247183
Validation loss: 2.3424610140149764

Epoch: 5| Step: 9
Training loss: 1.8631396609717723
Validation loss: 2.33617095159348

Epoch: 5| Step: 10
Training loss: 2.4300540757932314
Validation loss: 2.3264323311977266

Epoch: 416| Step: 0
Training loss: 2.466903768777116
Validation loss: 2.3806918515147935

Epoch: 5| Step: 1
Training loss: 2.087947719781794
Validation loss: 2.417244835314172

Epoch: 5| Step: 2
Training loss: 1.9853311472911255
Validation loss: 2.470034546401487

Epoch: 5| Step: 3
Training loss: 2.0007919889174537
Validation loss: 2.5612528617646437

Epoch: 5| Step: 4
Training loss: 2.507424487938495
Validation loss: 2.6262319967897207

Epoch: 5| Step: 5
Training loss: 2.180249213576462
Validation loss: 2.580186837653804

Epoch: 5| Step: 6
Training loss: 1.8272903362816313
Validation loss: 2.4834924813568073

Epoch: 5| Step: 7
Training loss: 1.9270850791579577
Validation loss: 2.4210514305071453

Epoch: 5| Step: 8
Training loss: 2.3803088433366684
Validation loss: 2.3966608345649587

Epoch: 5| Step: 9
Training loss: 1.674586014332191
Validation loss: 2.3913874650523943

Epoch: 5| Step: 10
Training loss: 2.477125711508985
Validation loss: 2.382937603185825

Epoch: 417| Step: 0
Training loss: 2.1551660217979616
Validation loss: 2.4233883366716316

Epoch: 5| Step: 1
Training loss: 2.388204708251708
Validation loss: 2.4743425838762168

Epoch: 5| Step: 2
Training loss: 2.088957468501046
Validation loss: 2.496223425925761

Epoch: 5| Step: 3
Training loss: 2.220743600011809
Validation loss: 2.4990963246013354

Epoch: 5| Step: 4
Training loss: 2.343946219813538
Validation loss: 2.455194618504601

Epoch: 5| Step: 5
Training loss: 1.879463668269123
Validation loss: 2.5058020590288264

Epoch: 5| Step: 6
Training loss: 2.028905483828853
Validation loss: 2.562588235239891

Epoch: 5| Step: 7
Training loss: 1.9378348030488746
Validation loss: 2.550823590030668

Epoch: 5| Step: 8
Training loss: 1.704131292832527
Validation loss: 2.488239131563364

Epoch: 5| Step: 9
Training loss: 2.3276217127853034
Validation loss: 2.462213792414915

Epoch: 5| Step: 10
Training loss: 1.933532528919546
Validation loss: 2.4680503081100857

Epoch: 418| Step: 0
Training loss: 2.206215496711989
Validation loss: 2.4191498708893446

Epoch: 5| Step: 1
Training loss: 1.858795011446132
Validation loss: 2.3812141295822697

Epoch: 5| Step: 2
Training loss: 2.405753146311726
Validation loss: 2.407769430760896

Epoch: 5| Step: 3
Training loss: 2.1861605221653595
Validation loss: 2.4185122545505737

Epoch: 5| Step: 4
Training loss: 2.1284158964381112
Validation loss: 2.4295704334678336

Epoch: 5| Step: 5
Training loss: 2.2135089707297273
Validation loss: 2.468869224193912

Epoch: 5| Step: 6
Training loss: 1.9935366381858415
Validation loss: 2.4556795165960086

Epoch: 5| Step: 7
Training loss: 1.7333837202280151
Validation loss: 2.5106441297909243

Epoch: 5| Step: 8
Training loss: 2.224111392421899
Validation loss: 2.481150888794607

Epoch: 5| Step: 9
Training loss: 1.8130660652962722
Validation loss: 2.503902997205855

Epoch: 5| Step: 10
Training loss: 2.1747768419159215
Validation loss: 2.4655418854971005

Epoch: 419| Step: 0
Training loss: 1.8287296436399745
Validation loss: 2.467677798552983

Epoch: 5| Step: 1
Training loss: 1.700358953165653
Validation loss: 2.4902783713977277

Epoch: 5| Step: 2
Training loss: 2.0567730084856373
Validation loss: 2.508410900465923

Epoch: 5| Step: 3
Training loss: 1.481573975620592
Validation loss: 2.4987232065235805

Epoch: 5| Step: 4
Training loss: 2.1532317335806046
Validation loss: 2.497557913721048

Epoch: 5| Step: 5
Training loss: 2.623598269454774
Validation loss: 2.463369639311439

Epoch: 5| Step: 6
Training loss: 1.9702061914114537
Validation loss: 2.5251836434398096

Epoch: 5| Step: 7
Training loss: 2.5344033085644924
Validation loss: 2.5488749772806005

Epoch: 5| Step: 8
Training loss: 2.1758444758051634
Validation loss: 2.557393786871249

Epoch: 5| Step: 9
Training loss: 1.8430282990657594
Validation loss: 2.5012631557928513

Epoch: 5| Step: 10
Training loss: 2.3552310754104577
Validation loss: 2.4933048942103944

Epoch: 420| Step: 0
Training loss: 1.7600677264794198
Validation loss: 2.446914512398965

Epoch: 5| Step: 1
Training loss: 2.2220305784028764
Validation loss: 2.4306128537816822

Epoch: 5| Step: 2
Training loss: 2.1801071583370106
Validation loss: 2.4282596717342253

Epoch: 5| Step: 3
Training loss: 1.9057047329865644
Validation loss: 2.4238696291643596

Epoch: 5| Step: 4
Training loss: 1.9136721465995739
Validation loss: 2.461600009479159

Epoch: 5| Step: 5
Training loss: 2.4422648880717874
Validation loss: 2.4872860958401843

Epoch: 5| Step: 6
Training loss: 1.64526314656863
Validation loss: 2.4962669794011063

Epoch: 5| Step: 7
Training loss: 2.0514235880207172
Validation loss: 2.4985399915411004

Epoch: 5| Step: 8
Training loss: 2.0601633881151225
Validation loss: 2.519383785520365

Epoch: 5| Step: 9
Training loss: 2.5457214364175704
Validation loss: 2.5416321176338963

Epoch: 5| Step: 10
Training loss: 1.8457741698462944
Validation loss: 2.50596156213387

Epoch: 421| Step: 0
Training loss: 2.167828749526625
Validation loss: 2.456278695448719

Epoch: 5| Step: 1
Training loss: 2.1681268857726153
Validation loss: 2.483126686256904

Epoch: 5| Step: 2
Training loss: 1.9920132429915987
Validation loss: 2.4603424879086844

Epoch: 5| Step: 3
Training loss: 2.3603074208157837
Validation loss: 2.416792753478466

Epoch: 5| Step: 4
Training loss: 1.842854104351103
Validation loss: 2.411669860576255

Epoch: 5| Step: 5
Training loss: 2.269235929883637
Validation loss: 2.413696414226971

Epoch: 5| Step: 6
Training loss: 2.1174692339503007
Validation loss: 2.430152932106405

Epoch: 5| Step: 7
Training loss: 1.7725993457065163
Validation loss: 2.483485317376322

Epoch: 5| Step: 8
Training loss: 2.059933423753455
Validation loss: 2.5405453717233586

Epoch: 5| Step: 9
Training loss: 1.70116521788038
Validation loss: 2.527177835558744

Epoch: 5| Step: 10
Training loss: 2.4728433981124107
Validation loss: 2.4956008404168206

Epoch: 422| Step: 0
Training loss: 2.2860815017202087
Validation loss: 2.4534597383357526

Epoch: 5| Step: 1
Training loss: 2.060010158550807
Validation loss: 2.4449046004191204

Epoch: 5| Step: 2
Training loss: 1.9275651758952843
Validation loss: 2.3859281228496343

Epoch: 5| Step: 3
Training loss: 1.9884638674347357
Validation loss: 2.3930147620335354

Epoch: 5| Step: 4
Training loss: 2.164734663704909
Validation loss: 2.3720445135183756

Epoch: 5| Step: 5
Training loss: 1.9064812441787928
Validation loss: 2.4288772679173674

Epoch: 5| Step: 6
Training loss: 1.6810741290030518
Validation loss: 2.4306142481345274

Epoch: 5| Step: 7
Training loss: 2.3487230565107717
Validation loss: 2.4264471480858174

Epoch: 5| Step: 8
Training loss: 1.8626005900824951
Validation loss: 2.423779073419191

Epoch: 5| Step: 9
Training loss: 2.175463339901552
Validation loss: 2.43363026610803

Epoch: 5| Step: 10
Training loss: 2.202733539405931
Validation loss: 2.4392850348926465

Epoch: 423| Step: 0
Training loss: 2.419745413417117
Validation loss: 2.518841932088719

Epoch: 5| Step: 1
Training loss: 2.6248941854312324
Validation loss: 2.5357601598585924

Epoch: 5| Step: 2
Training loss: 1.6431340241937091
Validation loss: 2.4738356271741173

Epoch: 5| Step: 3
Training loss: 2.073257712163672
Validation loss: 2.4204421828760094

Epoch: 5| Step: 4
Training loss: 1.7788560407050529
Validation loss: 2.4296618802087893

Epoch: 5| Step: 5
Training loss: 2.054834280826894
Validation loss: 2.443927618975591

Epoch: 5| Step: 6
Training loss: 1.6054470682652433
Validation loss: 2.4067574722221647

Epoch: 5| Step: 7
Training loss: 2.0942472180642553
Validation loss: 2.413762492195355

Epoch: 5| Step: 8
Training loss: 1.8625568765238105
Validation loss: 2.4347977932669425

Epoch: 5| Step: 9
Training loss: 2.3085523366037477
Validation loss: 2.4653250666678703

Epoch: 5| Step: 10
Training loss: 1.940656981765202
Validation loss: 2.549677996619907

Epoch: 424| Step: 0
Training loss: 2.187616835607551
Validation loss: 2.5358554655695134

Epoch: 5| Step: 1
Training loss: 2.059705748791911
Validation loss: 2.557634293634956

Epoch: 5| Step: 2
Training loss: 1.8333152062069
Validation loss: 2.456154009741113

Epoch: 5| Step: 3
Training loss: 2.1034188279289587
Validation loss: 2.4003083601379203

Epoch: 5| Step: 4
Training loss: 1.8573629568484724
Validation loss: 2.3890522676174446

Epoch: 5| Step: 5
Training loss: 1.973339906576309
Validation loss: 2.405336945902773

Epoch: 5| Step: 6
Training loss: 1.7253527653767753
Validation loss: 2.396466095031762

Epoch: 5| Step: 7
Training loss: 2.35811687549978
Validation loss: 2.4030261423408716

Epoch: 5| Step: 8
Training loss: 2.4049804112514965
Validation loss: 2.4315159927454277

Epoch: 5| Step: 9
Training loss: 2.040818901255015
Validation loss: 2.452749172976012

Epoch: 5| Step: 10
Training loss: 2.2569264716060387
Validation loss: 2.543641551844542

Epoch: 425| Step: 0
Training loss: 1.9240207633763837
Validation loss: 2.5306571469750243

Epoch: 5| Step: 1
Training loss: 2.3226583933122678
Validation loss: 2.4685983503521656

Epoch: 5| Step: 2
Training loss: 2.527511850512274
Validation loss: 2.4047788457109425

Epoch: 5| Step: 3
Training loss: 1.8621422187176555
Validation loss: 2.350590413478088

Epoch: 5| Step: 4
Training loss: 1.7973746890343627
Validation loss: 2.3129510237364617

Epoch: 5| Step: 5
Training loss: 2.408675618470837
Validation loss: 2.338717811218137

Epoch: 5| Step: 6
Training loss: 2.1711551927984836
Validation loss: 2.3973110843771335

Epoch: 5| Step: 7
Training loss: 1.886474972726484
Validation loss: 2.4672440972000564

Epoch: 5| Step: 8
Training loss: 2.086097739704938
Validation loss: 2.560482788860857

Epoch: 5| Step: 9
Training loss: 2.0484693302151915
Validation loss: 2.599092714853225

Epoch: 5| Step: 10
Training loss: 1.4305807356279834
Validation loss: 2.4945306056703926

Epoch: 426| Step: 0
Training loss: 2.217937481892577
Validation loss: 2.469995541417634

Epoch: 5| Step: 1
Training loss: 2.031126752195413
Validation loss: 2.414604611724053

Epoch: 5| Step: 2
Training loss: 2.2460536256606303
Validation loss: 2.400118119655566

Epoch: 5| Step: 3
Training loss: 1.9346209639302396
Validation loss: 2.3596790266970404

Epoch: 5| Step: 4
Training loss: 1.7246894169828058
Validation loss: 2.3645699884506923

Epoch: 5| Step: 5
Training loss: 2.7240012307129264
Validation loss: 2.3773486458082087

Epoch: 5| Step: 6
Training loss: 2.069108260097667
Validation loss: 2.3867706545067167

Epoch: 5| Step: 7
Training loss: 1.7019937940724212
Validation loss: 2.4181178265328755

Epoch: 5| Step: 8
Training loss: 1.8093687172683453
Validation loss: 2.4884357762113285

Epoch: 5| Step: 9
Training loss: 1.9519998590242615
Validation loss: 2.6046093665762178

Epoch: 5| Step: 10
Training loss: 2.0849454999794412
Validation loss: 2.6463024494473433

Epoch: 427| Step: 0
Training loss: 1.8759895256742383
Validation loss: 2.6455001928153212

Epoch: 5| Step: 1
Training loss: 2.144455649566804
Validation loss: 2.509779888712815

Epoch: 5| Step: 2
Training loss: 1.7370350002788095
Validation loss: 2.4713069124991436

Epoch: 5| Step: 3
Training loss: 2.341162308467707
Validation loss: 2.4221150332562873

Epoch: 5| Step: 4
Training loss: 2.1443411320697168
Validation loss: 2.4182258448204332

Epoch: 5| Step: 5
Training loss: 2.3260787061198527
Validation loss: 2.419709440004088

Epoch: 5| Step: 6
Training loss: 1.6410468149614938
Validation loss: 2.4333933546266477

Epoch: 5| Step: 7
Training loss: 2.2057158474630763
Validation loss: 2.4046637691487387

Epoch: 5| Step: 8
Training loss: 1.971711852371989
Validation loss: 2.43013266576639

Epoch: 5| Step: 9
Training loss: 1.9078448768511547
Validation loss: 2.452671466571848

Epoch: 5| Step: 10
Training loss: 2.1179052733868424
Validation loss: 2.455262719373576

Epoch: 428| Step: 0
Training loss: 2.0261505672995797
Validation loss: 2.430262312146264

Epoch: 5| Step: 1
Training loss: 1.8926554094248307
Validation loss: 2.413469933649559

Epoch: 5| Step: 2
Training loss: 1.6594410511384154
Validation loss: 2.4090458087245197

Epoch: 5| Step: 3
Training loss: 1.9008538837094067
Validation loss: 2.3912983460206925

Epoch: 5| Step: 4
Training loss: 2.380501749218733
Validation loss: 2.3797871459862616

Epoch: 5| Step: 5
Training loss: 1.7758441341626021
Validation loss: 2.382048474061964

Epoch: 5| Step: 6
Training loss: 1.8164032310542788
Validation loss: 2.3927035709901054

Epoch: 5| Step: 7
Training loss: 2.243699577423789
Validation loss: 2.402974216619818

Epoch: 5| Step: 8
Training loss: 2.1367681800940987
Validation loss: 2.5419308730016406

Epoch: 5| Step: 9
Training loss: 2.3375628376230715
Validation loss: 2.655651069884835

Epoch: 5| Step: 10
Training loss: 2.29345739509591
Validation loss: 2.6480885387489748

Epoch: 429| Step: 0
Training loss: 2.197254231741295
Validation loss: 2.548628777938074

Epoch: 5| Step: 1
Training loss: 1.9805808251926629
Validation loss: 2.4433034767483712

Epoch: 5| Step: 2
Training loss: 1.537830770004571
Validation loss: 2.3316082297882894

Epoch: 5| Step: 3
Training loss: 1.965147870835958
Validation loss: 2.308370980864632

Epoch: 5| Step: 4
Training loss: 2.2482149672780443
Validation loss: 2.3022853785112596

Epoch: 5| Step: 5
Training loss: 2.196207753156708
Validation loss: 2.303599391310523

Epoch: 5| Step: 6
Training loss: 2.4475046879817963
Validation loss: 2.295248696875315

Epoch: 5| Step: 7
Training loss: 1.5648357480663948
Validation loss: 2.328364392773831

Epoch: 5| Step: 8
Training loss: 2.2696273704567274
Validation loss: 2.391451824617862

Epoch: 5| Step: 9
Training loss: 2.107811694643448
Validation loss: 2.49211886922187

Epoch: 5| Step: 10
Training loss: 1.9442624241541215
Validation loss: 2.5766657533190185

Epoch: 430| Step: 0
Training loss: 2.3437892656216057
Validation loss: 2.649949205027445

Epoch: 5| Step: 1
Training loss: 2.2245413189559846
Validation loss: 2.628303459089726

Epoch: 5| Step: 2
Training loss: 2.04425650103621
Validation loss: 2.567113363657635

Epoch: 5| Step: 3
Training loss: 1.7333320024680872
Validation loss: 2.472492576969626

Epoch: 5| Step: 4
Training loss: 2.1978663458344347
Validation loss: 2.3947103478521967

Epoch: 5| Step: 5
Training loss: 2.0698837124138785
Validation loss: 2.3849491109501244

Epoch: 5| Step: 6
Training loss: 2.2150381497441027
Validation loss: 2.3873314719241403

Epoch: 5| Step: 7
Training loss: 1.8127082178942742
Validation loss: 2.3869862443565824

Epoch: 5| Step: 8
Training loss: 1.836974869512066
Validation loss: 2.42101725123466

Epoch: 5| Step: 9
Training loss: 1.8965923620372505
Validation loss: 2.4690160331519984

Epoch: 5| Step: 10
Training loss: 2.044943444139173
Validation loss: 2.4836261002574274

Epoch: 431| Step: 0
Training loss: 2.3632293947694216
Validation loss: 2.486931314616317

Epoch: 5| Step: 1
Training loss: 2.1830240506198546
Validation loss: 2.520272925810479

Epoch: 5| Step: 2
Training loss: 2.0413896281882855
Validation loss: 2.6096692419507717

Epoch: 5| Step: 3
Training loss: 2.05356442468053
Validation loss: 2.685586338144802

Epoch: 5| Step: 4
Training loss: 1.7886513316667374
Validation loss: 2.6736147022121095

Epoch: 5| Step: 5
Training loss: 2.351857315795817
Validation loss: 2.632102545605379

Epoch: 5| Step: 6
Training loss: 1.9072971282108544
Validation loss: 2.488640534145151

Epoch: 5| Step: 7
Training loss: 1.2336151585040922
Validation loss: 2.43510237686336

Epoch: 5| Step: 8
Training loss: 2.1035529144863907
Validation loss: 2.380396753484699

Epoch: 5| Step: 9
Training loss: 2.336332868205455
Validation loss: 2.3416146650493426

Epoch: 5| Step: 10
Training loss: 1.7837033024685418
Validation loss: 2.326121525672326

Epoch: 432| Step: 0
Training loss: 1.9443682481580464
Validation loss: 2.349836414877423

Epoch: 5| Step: 1
Training loss: 2.177530841981243
Validation loss: 2.36403981483059

Epoch: 5| Step: 2
Training loss: 2.3295611361971753
Validation loss: 2.394907830823779

Epoch: 5| Step: 3
Training loss: 1.9290934895532583
Validation loss: 2.4595539923769127

Epoch: 5| Step: 4
Training loss: 1.7337985068688502
Validation loss: 2.5807149199253168

Epoch: 5| Step: 5
Training loss: 1.5589269602159712
Validation loss: 2.6569190845697577

Epoch: 5| Step: 6
Training loss: 2.4010744789071574
Validation loss: 2.678311652513691

Epoch: 5| Step: 7
Training loss: 2.0961229911638517
Validation loss: 2.5678777592420996

Epoch: 5| Step: 8
Training loss: 1.8884574508055
Validation loss: 2.420516177987046

Epoch: 5| Step: 9
Training loss: 1.9499877146798499
Validation loss: 2.3717065642860677

Epoch: 5| Step: 10
Training loss: 2.374851222146672
Validation loss: 2.3303874551019708

Epoch: 433| Step: 0
Training loss: 2.206435077458115
Validation loss: 2.3352480974122223

Epoch: 5| Step: 1
Training loss: 1.5787625677313786
Validation loss: 2.337512402438245

Epoch: 5| Step: 2
Training loss: 2.095341319683187
Validation loss: 2.35381472047007

Epoch: 5| Step: 3
Training loss: 1.9231753408483947
Validation loss: 2.420028054254336

Epoch: 5| Step: 4
Training loss: 2.2466374808923972
Validation loss: 2.479903202633883

Epoch: 5| Step: 5
Training loss: 2.0289714063920523
Validation loss: 2.54732108246947

Epoch: 5| Step: 6
Training loss: 2.1068559086380785
Validation loss: 2.5490349315703695

Epoch: 5| Step: 7
Training loss: 1.6811766654545113
Validation loss: 2.483330948189763

Epoch: 5| Step: 8
Training loss: 1.7847395061970441
Validation loss: 2.4709215791264376

Epoch: 5| Step: 9
Training loss: 2.165555583507385
Validation loss: 2.4316060695308876

Epoch: 5| Step: 10
Training loss: 2.4458553211408733
Validation loss: 2.454294091643461

Epoch: 434| Step: 0
Training loss: 1.6587440138754095
Validation loss: 2.4072329890944077

Epoch: 5| Step: 1
Training loss: 1.9694255093822703
Validation loss: 2.4199172994909777

Epoch: 5| Step: 2
Training loss: 1.9324728442969936
Validation loss: 2.4089048900546306

Epoch: 5| Step: 3
Training loss: 1.6633893294582573
Validation loss: 2.4152644066843822

Epoch: 5| Step: 4
Training loss: 1.8838046930039396
Validation loss: 2.441418609259711

Epoch: 5| Step: 5
Training loss: 2.3856734313925787
Validation loss: 2.46178688174796

Epoch: 5| Step: 6
Training loss: 2.1171948197016572
Validation loss: 2.4503939697120183

Epoch: 5| Step: 7
Training loss: 1.9303188758264336
Validation loss: 2.421909317477392

Epoch: 5| Step: 8
Training loss: 2.245649051595852
Validation loss: 2.3980494461152824

Epoch: 5| Step: 9
Training loss: 2.1486764116096824
Validation loss: 2.4021714367559945

Epoch: 5| Step: 10
Training loss: 1.8144391308789933
Validation loss: 2.4392323665458537

Epoch: 435| Step: 0
Training loss: 1.2184111784415317
Validation loss: 2.4959755786951177

Epoch: 5| Step: 1
Training loss: 2.1460203688011275
Validation loss: 2.61127963944421

Epoch: 5| Step: 2
Training loss: 2.224853502229816
Validation loss: 2.5709349245834883

Epoch: 5| Step: 3
Training loss: 2.3096731279968856
Validation loss: 2.5789772710697507

Epoch: 5| Step: 4
Training loss: 1.7862462695478563
Validation loss: 2.479087777320384

Epoch: 5| Step: 5
Training loss: 2.23348960139969
Validation loss: 2.3987898655108406

Epoch: 5| Step: 6
Training loss: 2.0312096224953193
Validation loss: 2.3734304771899204

Epoch: 5| Step: 7
Training loss: 2.240323238722203
Validation loss: 2.3276605654183573

Epoch: 5| Step: 8
Training loss: 2.0333362136361823
Validation loss: 2.332795059799048

Epoch: 5| Step: 9
Training loss: 2.0977460390903
Validation loss: 2.3504934931227153

Epoch: 5| Step: 10
Training loss: 1.3230036108727459
Validation loss: 2.3928969363073187

Epoch: 436| Step: 0
Training loss: 1.4050011917869427
Validation loss: 2.4607263607635232

Epoch: 5| Step: 1
Training loss: 2.235083621037429
Validation loss: 2.470311262177348

Epoch: 5| Step: 2
Training loss: 2.447680804205259
Validation loss: 2.5824626430489874

Epoch: 5| Step: 3
Training loss: 1.9912018974514323
Validation loss: 2.6024311476339084

Epoch: 5| Step: 4
Training loss: 1.646958759067146
Validation loss: 2.5703431061648816

Epoch: 5| Step: 5
Training loss: 1.9037655759238084
Validation loss: 2.4890240513737045

Epoch: 5| Step: 6
Training loss: 1.7695214142852338
Validation loss: 2.4544126852542436

Epoch: 5| Step: 7
Training loss: 1.6757466772821359
Validation loss: 2.4326539195514663

Epoch: 5| Step: 8
Training loss: 2.202144972973993
Validation loss: 2.394567101689674

Epoch: 5| Step: 9
Training loss: 2.0017132573524723
Validation loss: 2.4020399529651986

Epoch: 5| Step: 10
Training loss: 2.2649878296514614
Validation loss: 2.424152003824909

Epoch: 437| Step: 0
Training loss: 1.8500011959587561
Validation loss: 2.4300966472599534

Epoch: 5| Step: 1
Training loss: 2.406566549509998
Validation loss: 2.4391698016344385

Epoch: 5| Step: 2
Training loss: 2.0855925199719128
Validation loss: 2.4640341234891707

Epoch: 5| Step: 3
Training loss: 1.8255561973930268
Validation loss: 2.4753701113210833

Epoch: 5| Step: 4
Training loss: 1.9550784908450582
Validation loss: 2.497397544893017

Epoch: 5| Step: 5
Training loss: 1.7984848771868638
Validation loss: 2.527291911529412

Epoch: 5| Step: 6
Training loss: 2.446493235460414
Validation loss: 2.5133638568124788

Epoch: 5| Step: 7
Training loss: 1.4477006307387779
Validation loss: 2.5235175810846573

Epoch: 5| Step: 8
Training loss: 1.4326524684646829
Validation loss: 2.508352418136095

Epoch: 5| Step: 9
Training loss: 1.8730981081895957
Validation loss: 2.5256447053365574

Epoch: 5| Step: 10
Training loss: 2.077195727012231
Validation loss: 2.4657953353294233

Epoch: 438| Step: 0
Training loss: 1.8545166142579024
Validation loss: 2.377775280562076

Epoch: 5| Step: 1
Training loss: 1.4561393401050304
Validation loss: 2.345339032279593

Epoch: 5| Step: 2
Training loss: 2.612543432431379
Validation loss: 2.347224911869058

Epoch: 5| Step: 3
Training loss: 2.1295810015128316
Validation loss: 2.314279539501685

Epoch: 5| Step: 4
Training loss: 1.8466358552811346
Validation loss: 2.3668019652815193

Epoch: 5| Step: 5
Training loss: 1.6904777815316872
Validation loss: 2.4172027008967834

Epoch: 5| Step: 6
Training loss: 1.7728951586962602
Validation loss: 2.4943507113081638

Epoch: 5| Step: 7
Training loss: 2.294551166867509
Validation loss: 2.5701834525973837

Epoch: 5| Step: 8
Training loss: 2.100391160774411
Validation loss: 2.524277413474988

Epoch: 5| Step: 9
Training loss: 1.6370157413925923
Validation loss: 2.4504185896592308

Epoch: 5| Step: 10
Training loss: 1.879757313688357
Validation loss: 2.3718611803870466

Epoch: 439| Step: 0
Training loss: 1.5501543214330529
Validation loss: 2.342499422436701

Epoch: 5| Step: 1
Training loss: 1.7581218532041831
Validation loss: 2.3156902088663562

Epoch: 5| Step: 2
Training loss: 1.9483024568724436
Validation loss: 2.3262516051218207

Epoch: 5| Step: 3
Training loss: 1.7359269904943884
Validation loss: 2.3306331389024457

Epoch: 5| Step: 4
Training loss: 2.0266971916903174
Validation loss: 2.35162344224585

Epoch: 5| Step: 5
Training loss: 2.158997816606825
Validation loss: 2.397059885215011

Epoch: 5| Step: 6
Training loss: 1.839131276052751
Validation loss: 2.4771743204491914

Epoch: 5| Step: 7
Training loss: 1.673690095816641
Validation loss: 2.5631823387859596

Epoch: 5| Step: 8
Training loss: 2.1790729052745035
Validation loss: 2.640025756824645

Epoch: 5| Step: 9
Training loss: 2.401160666826066
Validation loss: 2.6597197771192786

Epoch: 5| Step: 10
Training loss: 2.1852070371190147
Validation loss: 2.604968450028992

Epoch: 440| Step: 0
Training loss: 1.942032588264949
Validation loss: 2.464124015017203

Epoch: 5| Step: 1
Training loss: 1.9329353213316312
Validation loss: 2.4011080996529954

Epoch: 5| Step: 2
Training loss: 1.7389656005624652
Validation loss: 2.3653037750998123

Epoch: 5| Step: 3
Training loss: 2.276838557380767
Validation loss: 2.3553043784904526

Epoch: 5| Step: 4
Training loss: 2.1656525757370195
Validation loss: 2.401024431821605

Epoch: 5| Step: 5
Training loss: 1.7642121865597495
Validation loss: 2.5407263355993535

Epoch: 5| Step: 6
Training loss: 2.0053339402793076
Validation loss: 2.6315549681574337

Epoch: 5| Step: 7
Training loss: 2.5149866087843296
Validation loss: 2.6166518423416743

Epoch: 5| Step: 8
Training loss: 1.6187569194631084
Validation loss: 2.539990775502012

Epoch: 5| Step: 9
Training loss: 1.6525819575174647
Validation loss: 2.433998660068283

Epoch: 5| Step: 10
Training loss: 2.1572450194080846
Validation loss: 2.3883024994683346

Epoch: 441| Step: 0
Training loss: 1.9091178708422607
Validation loss: 2.3426460477314723

Epoch: 5| Step: 1
Training loss: 2.115671776574199
Validation loss: 2.329359054684084

Epoch: 5| Step: 2
Training loss: 1.885554426299425
Validation loss: 2.365467413839566

Epoch: 5| Step: 3
Training loss: 2.1909567632060942
Validation loss: 2.3543007515079712

Epoch: 5| Step: 4
Training loss: 2.106622892701597
Validation loss: 2.4154803264112883

Epoch: 5| Step: 5
Training loss: 2.3138476388568687
Validation loss: 2.4555174243755205

Epoch: 5| Step: 6
Training loss: 1.9357547898546739
Validation loss: 2.500612915953705

Epoch: 5| Step: 7
Training loss: 1.8092545358881138
Validation loss: 2.5400132598236933

Epoch: 5| Step: 8
Training loss: 1.9397533603092887
Validation loss: 2.5118218418657046

Epoch: 5| Step: 9
Training loss: 1.4094136996147306
Validation loss: 2.5111086264535776

Epoch: 5| Step: 10
Training loss: 1.7771088497331977
Validation loss: 2.495686646294704

Epoch: 442| Step: 0
Training loss: 2.0072641774307702
Validation loss: 2.4156634755975848

Epoch: 5| Step: 1
Training loss: 1.8443991601254155
Validation loss: 2.4001862814692694

Epoch: 5| Step: 2
Training loss: 1.8096239356851844
Validation loss: 2.3742716978131067

Epoch: 5| Step: 3
Training loss: 1.9956151459424039
Validation loss: 2.362729750126151

Epoch: 5| Step: 4
Training loss: 1.833313255489109
Validation loss: 2.3532798033839986

Epoch: 5| Step: 5
Training loss: 1.7188537566338609
Validation loss: 2.3810979900611695

Epoch: 5| Step: 6
Training loss: 2.2295371012230274
Validation loss: 2.435646569346187

Epoch: 5| Step: 7
Training loss: 1.6416994482081884
Validation loss: 2.434525013451419

Epoch: 5| Step: 8
Training loss: 1.5773034553992547
Validation loss: 2.4753981920341896

Epoch: 5| Step: 9
Training loss: 2.2169420640091926
Validation loss: 2.526717616529764

Epoch: 5| Step: 10
Training loss: 2.196537314192031
Validation loss: 2.5571871329865363

Epoch: 443| Step: 0
Training loss: 1.9011360737251535
Validation loss: 2.593368090986015

Epoch: 5| Step: 1
Training loss: 1.924909971039281
Validation loss: 2.571765077153457

Epoch: 5| Step: 2
Training loss: 1.2436552672993955
Validation loss: 2.5568781906648126

Epoch: 5| Step: 3
Training loss: 2.1832747934467505
Validation loss: 2.484530419737854

Epoch: 5| Step: 4
Training loss: 1.8232140071511607
Validation loss: 2.4160224393917504

Epoch: 5| Step: 5
Training loss: 1.7143444820389904
Validation loss: 2.395477057276769

Epoch: 5| Step: 6
Training loss: 2.5674838470277734
Validation loss: 2.388117406502239

Epoch: 5| Step: 7
Training loss: 1.658023101056706
Validation loss: 2.3965014524379806

Epoch: 5| Step: 8
Training loss: 1.3970988595617246
Validation loss: 2.3609118113490393

Epoch: 5| Step: 9
Training loss: 1.9537489237815935
Validation loss: 2.3959082739310578

Epoch: 5| Step: 10
Training loss: 2.4989469217599316
Validation loss: 2.446607886980223

Epoch: 444| Step: 0
Training loss: 2.0575414063376574
Validation loss: 2.449013077035529

Epoch: 5| Step: 1
Training loss: 1.7592496973004663
Validation loss: 2.4920532476372603

Epoch: 5| Step: 2
Training loss: 1.8268711322087035
Validation loss: 2.507021060232999

Epoch: 5| Step: 3
Training loss: 1.8314925257774763
Validation loss: 2.473799132496153

Epoch: 5| Step: 4
Training loss: 1.6887605691913647
Validation loss: 2.479886410075434

Epoch: 5| Step: 5
Training loss: 1.6399158216597969
Validation loss: 2.433278117337948

Epoch: 5| Step: 6
Training loss: 1.9647716107027582
Validation loss: 2.4251878609183923

Epoch: 5| Step: 7
Training loss: 2.167808623027923
Validation loss: 2.4272687368406825

Epoch: 5| Step: 8
Training loss: 1.919612886822212
Validation loss: 2.4247490307620096

Epoch: 5| Step: 9
Training loss: 1.8665726419451456
Validation loss: 2.4439912725854382

Epoch: 5| Step: 10
Training loss: 2.0798048529413427
Validation loss: 2.4645445823006766

Epoch: 445| Step: 0
Training loss: 1.972929197256167
Validation loss: 2.482740897096991

Epoch: 5| Step: 1
Training loss: 1.6564109292210285
Validation loss: 2.5069170857851044

Epoch: 5| Step: 2
Training loss: 1.6842468835802706
Validation loss: 2.477641452284206

Epoch: 5| Step: 3
Training loss: 1.9923217129844204
Validation loss: 2.4740155226482723

Epoch: 5| Step: 4
Training loss: 2.5150659544166865
Validation loss: 2.423653848616819

Epoch: 5| Step: 5
Training loss: 1.767729593605079
Validation loss: 2.4425185197343953

Epoch: 5| Step: 6
Training loss: 1.8774591214419416
Validation loss: 2.4445128478092073

Epoch: 5| Step: 7
Training loss: 2.0632221229340417
Validation loss: 2.452261724839757

Epoch: 5| Step: 8
Training loss: 1.5038978477342395
Validation loss: 2.4404623490356547

Epoch: 5| Step: 9
Training loss: 1.6194864784894036
Validation loss: 2.423249827325661

Epoch: 5| Step: 10
Training loss: 1.953104308972433
Validation loss: 2.3990559402067078

Epoch: 446| Step: 0
Training loss: 2.1644895937769264
Validation loss: 2.383251467273362

Epoch: 5| Step: 1
Training loss: 1.7036070535184606
Validation loss: 2.386729208758149

Epoch: 5| Step: 2
Training loss: 2.148622484046226
Validation loss: 2.416493695709326

Epoch: 5| Step: 3
Training loss: 2.0006941544397474
Validation loss: 2.4148171889883083

Epoch: 5| Step: 4
Training loss: 1.7977916867108832
Validation loss: 2.423440113784103

Epoch: 5| Step: 5
Training loss: 2.0630070612125975
Validation loss: 2.457429400219735

Epoch: 5| Step: 6
Training loss: 1.633411206445591
Validation loss: 2.4999799255877715

Epoch: 5| Step: 7
Training loss: 1.4247541516697522
Validation loss: 2.518097149085732

Epoch: 5| Step: 8
Training loss: 1.753765550844902
Validation loss: 2.5432360796713813

Epoch: 5| Step: 9
Training loss: 1.8631802897421763
Validation loss: 2.516959447182461

Epoch: 5| Step: 10
Training loss: 1.9173035254652813
Validation loss: 2.44806434397096

Epoch: 447| Step: 0
Training loss: 1.8732876906259182
Validation loss: 2.4211897484960163

Epoch: 5| Step: 1
Training loss: 1.8189067078291532
Validation loss: 2.4021619769168714

Epoch: 5| Step: 2
Training loss: 1.6412930536252257
Validation loss: 2.3691902537900167

Epoch: 5| Step: 3
Training loss: 2.088825184389527
Validation loss: 2.3808246294957

Epoch: 5| Step: 4
Training loss: 1.7409487027800876
Validation loss: 2.3877277816885636

Epoch: 5| Step: 5
Training loss: 1.7917180238800294
Validation loss: 2.4035162864756905

Epoch: 5| Step: 6
Training loss: 1.8463408160747012
Validation loss: 2.3924477416745096

Epoch: 5| Step: 7
Training loss: 2.0768301235221416
Validation loss: 2.4730492827228163

Epoch: 5| Step: 8
Training loss: 2.2369074841443153
Validation loss: 2.4579134496138395

Epoch: 5| Step: 9
Training loss: 1.68414375543779
Validation loss: 2.4781448486569393

Epoch: 5| Step: 10
Training loss: 1.7117800793440325
Validation loss: 2.4859895563221137

Epoch: 448| Step: 0
Training loss: 2.149297146908265
Validation loss: 2.4997024102649448

Epoch: 5| Step: 1
Training loss: 2.0193576996421423
Validation loss: 2.45614236863406

Epoch: 5| Step: 2
Training loss: 2.0307876060617067
Validation loss: 2.445420024685438

Epoch: 5| Step: 3
Training loss: 1.680844711179464
Validation loss: 2.437529198508737

Epoch: 5| Step: 4
Training loss: 1.9194840856649085
Validation loss: 2.455091985931506

Epoch: 5| Step: 5
Training loss: 2.0378203719381482
Validation loss: 2.4630710107382203

Epoch: 5| Step: 6
Training loss: 2.0194117733940398
Validation loss: 2.473883481061808

Epoch: 5| Step: 7
Training loss: 1.79003706462143
Validation loss: 2.4764957964395964

Epoch: 5| Step: 8
Training loss: 1.2922066000987873
Validation loss: 2.477104135287606

Epoch: 5| Step: 9
Training loss: 1.878670025288919
Validation loss: 2.4256166007228663

Epoch: 5| Step: 10
Training loss: 1.4320986900952768
Validation loss: 2.4530681851466545

Epoch: 449| Step: 0
Training loss: 1.8050024244973761
Validation loss: 2.4441899075118205

Epoch: 5| Step: 1
Training loss: 1.842473638959323
Validation loss: 2.4519108906305127

Epoch: 5| Step: 2
Training loss: 1.989138315438511
Validation loss: 2.4668762959660255

Epoch: 5| Step: 3
Training loss: 1.6105234437246996
Validation loss: 2.4403784105703665

Epoch: 5| Step: 4
Training loss: 2.1937269682368026
Validation loss: 2.4155387210432284

Epoch: 5| Step: 5
Training loss: 1.6171883108533218
Validation loss: 2.380950376572769

Epoch: 5| Step: 6
Training loss: 1.9135796385520658
Validation loss: 2.4027103800934237

Epoch: 5| Step: 7
Training loss: 1.9237345561398465
Validation loss: 2.4267573867684904

Epoch: 5| Step: 8
Training loss: 1.9641796529300406
Validation loss: 2.3916204906475285

Epoch: 5| Step: 9
Training loss: 1.8481431122022294
Validation loss: 2.4374833780862573

Epoch: 5| Step: 10
Training loss: 1.6485798851097575
Validation loss: 2.5035324571487774

Epoch: 450| Step: 0
Training loss: 1.7941923599541445
Validation loss: 2.5455844311243547

Epoch: 5| Step: 1
Training loss: 1.5932986050309907
Validation loss: 2.530640952568612

Epoch: 5| Step: 2
Training loss: 1.8721534101642352
Validation loss: 2.494756168415469

Epoch: 5| Step: 3
Training loss: 2.1020466413468233
Validation loss: 2.4545830930848838

Epoch: 5| Step: 4
Training loss: 2.1666941151958814
Validation loss: 2.393906489854775

Epoch: 5| Step: 5
Training loss: 1.4002230875200632
Validation loss: 2.3668748991750377

Epoch: 5| Step: 6
Training loss: 1.8314243767424416
Validation loss: 2.3610890977602605

Epoch: 5| Step: 7
Training loss: 1.9695814284424447
Validation loss: 2.3575250231416236

Epoch: 5| Step: 8
Training loss: 1.626725674377132
Validation loss: 2.411778208046918

Epoch: 5| Step: 9
Training loss: 1.9456680156830963
Validation loss: 2.4692106584308675

Epoch: 5| Step: 10
Training loss: 2.0580947531786586
Validation loss: 2.4833302188417976

Testing loss: 2.5614028639215016
