Epoch: 1| Step: 0
Training loss: 4.360821723937988
Validation loss: 5.1720942784381165

Epoch: 5| Step: 1
Training loss: 5.7341742515563965
Validation loss: 5.166935930969895

Epoch: 5| Step: 2
Training loss: 4.71733283996582
Validation loss: 5.161309570394536

Epoch: 5| Step: 3
Training loss: 4.712214469909668
Validation loss: 5.156059418955157

Epoch: 5| Step: 4
Training loss: 4.642426490783691
Validation loss: 5.149991235425396

Epoch: 5| Step: 5
Training loss: 5.04625940322876
Validation loss: 5.143562019512218

Epoch: 5| Step: 6
Training loss: 5.534289360046387
Validation loss: 5.137124635839975

Epoch: 5| Step: 7
Training loss: 4.8232421875
Validation loss: 5.130832000445294

Epoch: 5| Step: 8
Training loss: 4.0966339111328125
Validation loss: 5.1240181974185415

Epoch: 5| Step: 9
Training loss: 4.932713031768799
Validation loss: 5.1173528548209894

Epoch: 5| Step: 10
Training loss: 5.869396686553955
Validation loss: 5.109889958494453

Epoch: 2| Step: 0
Training loss: 5.402106285095215
Validation loss: 5.102770610522199

Epoch: 5| Step: 1
Training loss: 5.253437042236328
Validation loss: 5.0948105114762505

Epoch: 5| Step: 2
Training loss: 5.502256870269775
Validation loss: 5.086790456566759

Epoch: 5| Step: 3
Training loss: 5.039135932922363
Validation loss: 5.078724589399112

Epoch: 5| Step: 4
Training loss: 4.939675331115723
Validation loss: 5.06935985626713

Epoch: 5| Step: 5
Training loss: 4.724843978881836
Validation loss: 5.0604054543279835

Epoch: 5| Step: 6
Training loss: 4.693078517913818
Validation loss: 5.051311292955952

Epoch: 5| Step: 7
Training loss: 4.327560901641846
Validation loss: 5.041226771570021

Epoch: 5| Step: 8
Training loss: 4.767360210418701
Validation loss: 5.031074441889281

Epoch: 5| Step: 9
Training loss: 3.5652644634246826
Validation loss: 5.0200138963678835

Epoch: 5| Step: 10
Training loss: 5.243492603302002
Validation loss: 5.00840970008604

Epoch: 3| Step: 0
Training loss: 4.630612373352051
Validation loss: 4.996460063483125

Epoch: 5| Step: 1
Training loss: 4.705235481262207
Validation loss: 4.9835333824157715

Epoch: 5| Step: 2
Training loss: 4.322793483734131
Validation loss: 4.970931622289842

Epoch: 5| Step: 3
Training loss: 4.328456878662109
Validation loss: 4.956740210133214

Epoch: 5| Step: 4
Training loss: 4.0520758628845215
Validation loss: 4.942922310162616

Epoch: 5| Step: 5
Training loss: 5.881680488586426
Validation loss: 4.928435069258495

Epoch: 5| Step: 6
Training loss: 5.698650360107422
Validation loss: 4.9121584123180755

Epoch: 5| Step: 7
Training loss: 4.265860080718994
Validation loss: 4.895191418227329

Epoch: 5| Step: 8
Training loss: 4.126832008361816
Validation loss: 4.878565175558931

Epoch: 5| Step: 9
Training loss: 5.025674343109131
Validation loss: 4.8602475504721365

Epoch: 5| Step: 10
Training loss: 4.837711811065674
Validation loss: 4.842616173528856

Epoch: 4| Step: 0
Training loss: 4.307911396026611
Validation loss: 4.8231428361708115

Epoch: 5| Step: 1
Training loss: 4.230139255523682
Validation loss: 4.803084096600933

Epoch: 5| Step: 2
Training loss: 5.024797439575195
Validation loss: 4.78310094341155

Epoch: 5| Step: 3
Training loss: 4.5889716148376465
Validation loss: 4.76108673567413

Epoch: 5| Step: 4
Training loss: 4.169220924377441
Validation loss: 4.738889427595241

Epoch: 5| Step: 5
Training loss: 4.637469291687012
Validation loss: 4.716701353749921

Epoch: 5| Step: 6
Training loss: 3.789099931716919
Validation loss: 4.694593526983774

Epoch: 5| Step: 7
Training loss: 4.511408805847168
Validation loss: 4.671236438135947

Epoch: 5| Step: 8
Training loss: 4.798347473144531
Validation loss: 4.648513845218125

Epoch: 5| Step: 9
Training loss: 4.720522403717041
Validation loss: 4.6248060785314085

Epoch: 5| Step: 10
Training loss: 4.748771667480469
Validation loss: 4.5995318556344635

Epoch: 5| Step: 0
Training loss: 4.815948009490967
Validation loss: 4.575395286724132

Epoch: 5| Step: 1
Training loss: 3.729306697845459
Validation loss: 4.548825628014021

Epoch: 5| Step: 2
Training loss: 4.060240745544434
Validation loss: 4.523094438737439

Epoch: 5| Step: 3
Training loss: 4.057501792907715
Validation loss: 4.49601722532703

Epoch: 5| Step: 4
Training loss: 4.643767356872559
Validation loss: 4.469491138253161

Epoch: 5| Step: 5
Training loss: 5.6576385498046875
Validation loss: 4.441865695420132

Epoch: 5| Step: 6
Training loss: 3.7209267616271973
Validation loss: 4.416681320436539

Epoch: 5| Step: 7
Training loss: 3.6872048377990723
Validation loss: 4.390414812231577

Epoch: 5| Step: 8
Training loss: 4.446492671966553
Validation loss: 4.366097224655972

Epoch: 5| Step: 9
Training loss: 3.652345657348633
Validation loss: 4.340521607347714

Epoch: 5| Step: 10
Training loss: 4.166851043701172
Validation loss: 4.316256717969012

Epoch: 6| Step: 0
Training loss: 3.4396376609802246
Validation loss: 4.2925203384891635

Epoch: 5| Step: 1
Training loss: 4.312257289886475
Validation loss: 4.269767781739594

Epoch: 5| Step: 2
Training loss: 5.079497337341309
Validation loss: 4.246240733772196

Epoch: 5| Step: 3
Training loss: 3.8097662925720215
Validation loss: 4.223543356823665

Epoch: 5| Step: 4
Training loss: 4.131007194519043
Validation loss: 4.202227982141638

Epoch: 5| Step: 5
Training loss: 4.606529712677002
Validation loss: 4.181681168976651

Epoch: 5| Step: 6
Training loss: 2.733668804168701
Validation loss: 4.160230775033274

Epoch: 5| Step: 7
Training loss: 3.915172576904297
Validation loss: 4.138425309170959

Epoch: 5| Step: 8
Training loss: 4.767453193664551
Validation loss: 4.116974840882004

Epoch: 5| Step: 9
Training loss: 3.742990493774414
Validation loss: 4.096516073391002

Epoch: 5| Step: 10
Training loss: 3.384828805923462
Validation loss: 4.07538039197204

Epoch: 7| Step: 0
Training loss: 4.081031799316406
Validation loss: 4.055220701361216

Epoch: 5| Step: 1
Training loss: 3.7507147789001465
Validation loss: 4.03600936807612

Epoch: 5| Step: 2
Training loss: 4.328354835510254
Validation loss: 4.0172042026314685

Epoch: 5| Step: 3
Training loss: 3.3296351432800293
Validation loss: 3.9972823307078373

Epoch: 5| Step: 4
Training loss: 2.9035282135009766
Validation loss: 3.977717753379576

Epoch: 5| Step: 5
Training loss: 4.7973246574401855
Validation loss: 3.9607006760053736

Epoch: 5| Step: 6
Training loss: 3.3264992237091064
Validation loss: 3.9411832337738364

Epoch: 5| Step: 7
Training loss: 4.197078704833984
Validation loss: 3.9218676038967666

Epoch: 5| Step: 8
Training loss: 3.9742660522460938
Validation loss: 3.9024482363013813

Epoch: 5| Step: 9
Training loss: 3.631955623626709
Validation loss: 3.884708389159172

Epoch: 5| Step: 10
Training loss: 3.603262424468994
Validation loss: 3.864479031614078

Epoch: 8| Step: 0
Training loss: 3.646378755569458
Validation loss: 3.846736149121356

Epoch: 5| Step: 1
Training loss: 3.6857123374938965
Validation loss: 3.8245401484991914

Epoch: 5| Step: 2
Training loss: 4.136839389801025
Validation loss: 3.806856842451198

Epoch: 5| Step: 3
Training loss: 2.7090089321136475
Validation loss: 3.7883686660438456

Epoch: 5| Step: 4
Training loss: 2.779526472091675
Validation loss: 3.771344846294772

Epoch: 5| Step: 5
Training loss: 5.037009239196777
Validation loss: 3.7534545057563373

Epoch: 5| Step: 6
Training loss: 4.757534980773926
Validation loss: 3.7351041429786274

Epoch: 5| Step: 7
Training loss: 2.809566020965576
Validation loss: 3.71775423583164

Epoch: 5| Step: 8
Training loss: 3.3462929725646973
Validation loss: 3.7071476982485865

Epoch: 5| Step: 9
Training loss: 3.422314405441284
Validation loss: 3.691823959350586

Epoch: 5| Step: 10
Training loss: 3.8961710929870605
Validation loss: 3.6797076758518013

Epoch: 9| Step: 0
Training loss: 2.5868632793426514
Validation loss: 3.6650540264703895

Epoch: 5| Step: 1
Training loss: 3.8964526653289795
Validation loss: 3.6558021422355407

Epoch: 5| Step: 2
Training loss: 4.118659973144531
Validation loss: 3.6430952369525866

Epoch: 5| Step: 3
Training loss: 2.542464256286621
Validation loss: 3.627836360726305

Epoch: 5| Step: 4
Training loss: 4.219376564025879
Validation loss: 3.6174128799028296

Epoch: 5| Step: 5
Training loss: 4.151965618133545
Validation loss: 3.606173079500916

Epoch: 5| Step: 6
Training loss: 2.719769239425659
Validation loss: 3.5956632168062272

Epoch: 5| Step: 7
Training loss: 4.216426849365234
Validation loss: 3.5821807102490495

Epoch: 5| Step: 8
Training loss: 3.312716245651245
Validation loss: 3.57485689655427

Epoch: 5| Step: 9
Training loss: 3.3693346977233887
Validation loss: 3.56209155308303

Epoch: 5| Step: 10
Training loss: 3.5995073318481445
Validation loss: 3.554439067840576

Epoch: 10| Step: 0
Training loss: 3.7921245098114014
Validation loss: 3.5402146949562976

Epoch: 5| Step: 1
Training loss: 2.829897165298462
Validation loss: 3.5318585621413363

Epoch: 5| Step: 2
Training loss: 4.120004177093506
Validation loss: 3.5203886006468084

Epoch: 5| Step: 3
Training loss: 3.6996707916259766
Validation loss: 3.509582714367938

Epoch: 5| Step: 4
Training loss: 3.5833277702331543
Validation loss: 3.5008133842099096

Epoch: 5| Step: 5
Training loss: 2.928342580795288
Validation loss: 3.491095217325354

Epoch: 5| Step: 6
Training loss: 3.3967690467834473
Validation loss: 3.4819068498508905

Epoch: 5| Step: 7
Training loss: 3.340363025665283
Validation loss: 3.472569978365334

Epoch: 5| Step: 8
Training loss: 2.6120002269744873
Validation loss: 3.4616921383847474

Epoch: 5| Step: 9
Training loss: 3.7514774799346924
Validation loss: 3.456828386552872

Epoch: 5| Step: 10
Training loss: 3.689880847930908
Validation loss: 3.4472440212003645

Epoch: 11| Step: 0
Training loss: 3.5190529823303223
Validation loss: 3.437722816262194

Epoch: 5| Step: 1
Training loss: 3.152186155319214
Validation loss: 3.4311061725821546

Epoch: 5| Step: 2
Training loss: 3.7260031700134277
Validation loss: 3.42835646547297

Epoch: 5| Step: 3
Training loss: 3.399991273880005
Validation loss: 3.4204277453884

Epoch: 5| Step: 4
Training loss: 3.7049083709716797
Validation loss: 3.413690261943366

Epoch: 5| Step: 5
Training loss: 4.227675914764404
Validation loss: 3.406640560396256

Epoch: 5| Step: 6
Training loss: 3.475116014480591
Validation loss: 3.400034140515071

Epoch: 5| Step: 7
Training loss: 2.403934955596924
Validation loss: 3.3942267894744873

Epoch: 5| Step: 8
Training loss: 2.73289155960083
Validation loss: 3.38919412192478

Epoch: 5| Step: 9
Training loss: 3.1376819610595703
Validation loss: 3.382061973694832

Epoch: 5| Step: 10
Training loss: 3.4358484745025635
Validation loss: 3.3745655270032984

Epoch: 12| Step: 0
Training loss: 2.925123929977417
Validation loss: 3.3712834978616364

Epoch: 5| Step: 1
Training loss: 2.799359083175659
Validation loss: 3.362152309827907

Epoch: 5| Step: 2
Training loss: 3.5135657787323
Validation loss: 3.3566741943359375

Epoch: 5| Step: 3
Training loss: 3.544618606567383
Validation loss: 3.3521500454154065

Epoch: 5| Step: 4
Training loss: 3.546902894973755
Validation loss: 3.344453957773024

Epoch: 5| Step: 5
Training loss: 3.7612814903259277
Validation loss: 3.3403360151475474

Epoch: 5| Step: 6
Training loss: 3.6292285919189453
Validation loss: 3.3338130674054547

Epoch: 5| Step: 7
Training loss: 3.5667147636413574
Validation loss: 3.328396394688596

Epoch: 5| Step: 8
Training loss: 3.1546998023986816
Validation loss: 3.3228211992530414

Epoch: 5| Step: 9
Training loss: 2.546086549758911
Validation loss: 3.3161505576102965

Epoch: 5| Step: 10
Training loss: 3.339881658554077
Validation loss: 3.311359069680655

Epoch: 13| Step: 0
Training loss: 3.305790424346924
Validation loss: 3.3063697609850156

Epoch: 5| Step: 1
Training loss: 2.984304904937744
Validation loss: 3.2990659667599584

Epoch: 5| Step: 2
Training loss: 3.5577239990234375
Validation loss: 3.2968254012446248

Epoch: 5| Step: 3
Training loss: 3.683131456375122
Validation loss: 3.2877944310506186

Epoch: 5| Step: 4
Training loss: 2.6653101444244385
Validation loss: 3.283126605454312

Epoch: 5| Step: 5
Training loss: 2.8860526084899902
Validation loss: 3.2797725354471514

Epoch: 5| Step: 6
Training loss: 2.872231960296631
Validation loss: 3.2733035215767483

Epoch: 5| Step: 7
Training loss: 3.716904878616333
Validation loss: 3.2672511762188328

Epoch: 5| Step: 8
Training loss: 3.2902908325195312
Validation loss: 3.2608907222747803

Epoch: 5| Step: 9
Training loss: 2.557462215423584
Validation loss: 3.2580686897359867

Epoch: 5| Step: 10
Training loss: 4.455468654632568
Validation loss: 3.2524674272024505

Epoch: 14| Step: 0
Training loss: 3.6362881660461426
Validation loss: 3.2473426762447564

Epoch: 5| Step: 1
Training loss: 3.7836384773254395
Validation loss: 3.2400608575472267

Epoch: 5| Step: 2
Training loss: 3.247412919998169
Validation loss: 3.236288878225511

Epoch: 5| Step: 3
Training loss: 3.1573171615600586
Validation loss: 3.229103111451672

Epoch: 5| Step: 4
Training loss: 2.644575595855713
Validation loss: 3.2225556911960727

Epoch: 5| Step: 5
Training loss: 2.413217067718506
Validation loss: 3.220699889685518

Epoch: 5| Step: 6
Training loss: 4.153304576873779
Validation loss: 3.215135566649898

Epoch: 5| Step: 7
Training loss: 3.5977821350097656
Validation loss: 3.2107363772648636

Epoch: 5| Step: 8
Training loss: 2.5079174041748047
Validation loss: 3.206129212533274

Epoch: 5| Step: 9
Training loss: 3.3655853271484375
Validation loss: 3.2008226251089447

Epoch: 5| Step: 10
Training loss: 2.7397146224975586
Validation loss: 3.1972265858804025

Epoch: 15| Step: 0
Training loss: 2.991163730621338
Validation loss: 3.190746645773611

Epoch: 5| Step: 1
Training loss: 3.110224485397339
Validation loss: 3.1847730682742212

Epoch: 5| Step: 2
Training loss: 3.8367080688476562
Validation loss: 3.1805438021177888

Epoch: 5| Step: 3
Training loss: 3.3345019817352295
Validation loss: 3.1776023423799904

Epoch: 5| Step: 4
Training loss: 2.632599115371704
Validation loss: 3.1695941391811577

Epoch: 5| Step: 5
Training loss: 3.3026180267333984
Validation loss: 3.165809690311391

Epoch: 5| Step: 6
Training loss: 3.3863418102264404
Validation loss: 3.1591544253851778

Epoch: 5| Step: 7
Training loss: 2.851433515548706
Validation loss: 3.1564194079368346

Epoch: 5| Step: 8
Training loss: 3.5469303131103516
Validation loss: 3.152456519424274

Epoch: 5| Step: 9
Training loss: 2.5734705924987793
Validation loss: 3.1461194766465055

Epoch: 5| Step: 10
Training loss: 3.370595932006836
Validation loss: 3.139997031099053

Epoch: 16| Step: 0
Training loss: 2.7782623767852783
Validation loss: 3.1348975243106967

Epoch: 5| Step: 1
Training loss: 2.707494020462036
Validation loss: 3.13189261703081

Epoch: 5| Step: 2
Training loss: 3.198495388031006
Validation loss: 3.1259969280612085

Epoch: 5| Step: 3
Training loss: 3.2896294593811035
Validation loss: 3.121139713512954

Epoch: 5| Step: 4
Training loss: 3.6787219047546387
Validation loss: 3.1165900153498494

Epoch: 5| Step: 5
Training loss: 3.4427897930145264
Validation loss: 3.114126938645558

Epoch: 5| Step: 6
Training loss: 3.4000496864318848
Validation loss: 3.1056860493075464

Epoch: 5| Step: 7
Training loss: 3.808615207672119
Validation loss: 3.103384512726979

Epoch: 5| Step: 8
Training loss: 2.6271700859069824
Validation loss: 3.099730458310855

Epoch: 5| Step: 9
Training loss: 2.9122629165649414
Validation loss: 3.094933881554552

Epoch: 5| Step: 10
Training loss: 2.526296615600586
Validation loss: 3.092260140244679

Epoch: 17| Step: 0
Training loss: 2.667886257171631
Validation loss: 3.086100962854201

Epoch: 5| Step: 1
Training loss: 3.2067947387695312
Validation loss: 3.08028079617408

Epoch: 5| Step: 2
Training loss: 3.0291123390197754
Validation loss: 3.0756584854536158

Epoch: 5| Step: 3
Training loss: 2.9971344470977783
Validation loss: 3.070677313753354

Epoch: 5| Step: 4
Training loss: 3.4406418800354004
Validation loss: 3.0659836979322534

Epoch: 5| Step: 5
Training loss: 3.3746705055236816
Validation loss: 3.064690469413675

Epoch: 5| Step: 6
Training loss: 3.441084623336792
Validation loss: 3.057176718147852

Epoch: 5| Step: 7
Training loss: 2.70426607131958
Validation loss: 3.053632628533148

Epoch: 5| Step: 8
Training loss: 3.0403850078582764
Validation loss: 3.054213326464417

Epoch: 5| Step: 9
Training loss: 3.592669725418091
Validation loss: 3.0513618658947688

Epoch: 5| Step: 10
Training loss: 2.5365374088287354
Validation loss: 3.04681227027729

Epoch: 18| Step: 0
Training loss: 3.9001076221466064
Validation loss: 3.0381685123648694

Epoch: 5| Step: 1
Training loss: 2.228160858154297
Validation loss: 3.0353802788642144

Epoch: 5| Step: 2
Training loss: 2.491530656814575
Validation loss: 3.0314740852643083

Epoch: 5| Step: 3
Training loss: 3.4536547660827637
Validation loss: 3.027752161026001

Epoch: 5| Step: 4
Training loss: 3.7423431873321533
Validation loss: 3.022618998763382

Epoch: 5| Step: 5
Training loss: 3.02160382270813
Validation loss: 3.0184489962875203

Epoch: 5| Step: 6
Training loss: 2.56626296043396
Validation loss: 3.015058030364334

Epoch: 5| Step: 7
Training loss: 2.7649435997009277
Validation loss: 3.0104441488942792

Epoch: 5| Step: 8
Training loss: 3.5677363872528076
Validation loss: 3.006704233025992

Epoch: 5| Step: 9
Training loss: 2.9765114784240723
Validation loss: 3.0017032187472106

Epoch: 5| Step: 10
Training loss: 3.104426860809326
Validation loss: 2.9988943812667683

Epoch: 19| Step: 0
Training loss: 2.6101365089416504
Validation loss: 3.0010945258602018

Epoch: 5| Step: 1
Training loss: 3.762798309326172
Validation loss: 2.996013379866077

Epoch: 5| Step: 2
Training loss: 2.7290918827056885
Validation loss: 2.9873372816270396

Epoch: 5| Step: 3
Training loss: 2.404162645339966
Validation loss: 2.9837507278688493

Epoch: 5| Step: 4
Training loss: 2.657334089279175
Validation loss: 2.98035825708861

Epoch: 5| Step: 5
Training loss: 2.9846692085266113
Validation loss: 2.9768483869491087

Epoch: 5| Step: 6
Training loss: 3.895556926727295
Validation loss: 2.9765050693224837

Epoch: 5| Step: 7
Training loss: 2.446410894393921
Validation loss: 2.974692003701323

Epoch: 5| Step: 8
Training loss: 3.2976670265197754
Validation loss: 2.9700211504454255

Epoch: 5| Step: 9
Training loss: 3.2415974140167236
Validation loss: 2.9686837427077757

Epoch: 5| Step: 10
Training loss: 3.5672688484191895
Validation loss: 2.9685902287883144

Epoch: 20| Step: 0
Training loss: 2.665950298309326
Validation loss: 2.9672901245855514

Epoch: 5| Step: 1
Training loss: 3.99064564704895
Validation loss: 2.971890808433615

Epoch: 5| Step: 2
Training loss: 3.1789441108703613
Validation loss: 2.9560275436729513

Epoch: 5| Step: 3
Training loss: 2.833765745162964
Validation loss: 2.953023064521051

Epoch: 5| Step: 4
Training loss: 2.997076988220215
Validation loss: 2.9520061913356987

Epoch: 5| Step: 5
Training loss: 3.3424880504608154
Validation loss: 2.951200092992475

Epoch: 5| Step: 6
Training loss: 2.189772844314575
Validation loss: 2.950695724897487

Epoch: 5| Step: 7
Training loss: 3.5638465881347656
Validation loss: 2.944394214178926

Epoch: 5| Step: 8
Training loss: 2.403794765472412
Validation loss: 2.943555232017271

Epoch: 5| Step: 9
Training loss: 2.9154810905456543
Validation loss: 2.936497357583815

Epoch: 5| Step: 10
Training loss: 3.2880990505218506
Validation loss: 2.9334874588956117

Epoch: 21| Step: 0
Training loss: 2.3033554553985596
Validation loss: 2.932357467630858

Epoch: 5| Step: 1
Training loss: 2.9142215251922607
Validation loss: 2.9323674299383677

Epoch: 5| Step: 2
Training loss: 3.110020160675049
Validation loss: 2.9260074733405985

Epoch: 5| Step: 3
Training loss: 2.6404178142547607
Validation loss: 2.9271990176170104

Epoch: 5| Step: 4
Training loss: 3.441911220550537
Validation loss: 2.922597800531695

Epoch: 5| Step: 5
Training loss: 3.275240421295166
Validation loss: 2.9151242445873957

Epoch: 5| Step: 6
Training loss: 2.768679141998291
Validation loss: 2.9172206130079044

Epoch: 5| Step: 7
Training loss: 2.6477015018463135
Validation loss: 2.913988951713808

Epoch: 5| Step: 8
Training loss: 2.7165355682373047
Validation loss: 2.908017261053926

Epoch: 5| Step: 9
Training loss: 4.036881923675537
Validation loss: 2.910326332174322

Epoch: 5| Step: 10
Training loss: 3.2679264545440674
Validation loss: 2.906352404625185

Epoch: 22| Step: 0
Training loss: 3.213407039642334
Validation loss: 2.9060019652048745

Epoch: 5| Step: 1
Training loss: 2.778693675994873
Validation loss: 2.9019214773690827

Epoch: 5| Step: 2
Training loss: 2.69767689704895
Validation loss: 2.9052381130956833

Epoch: 5| Step: 3
Training loss: 3.555035352706909
Validation loss: 2.9032124345020582

Epoch: 5| Step: 4
Training loss: 3.3117363452911377
Validation loss: 2.8969206912543184

Epoch: 5| Step: 5
Training loss: 3.2673606872558594
Validation loss: 2.8971272668530865

Epoch: 5| Step: 6
Training loss: 2.716606616973877
Validation loss: 2.896255031708748

Epoch: 5| Step: 7
Training loss: 2.7896780967712402
Validation loss: 2.893984704889277

Epoch: 5| Step: 8
Training loss: 2.967237949371338
Validation loss: 2.8958883618795745

Epoch: 5| Step: 9
Training loss: 2.248922824859619
Validation loss: 2.885954508217432

Epoch: 5| Step: 10
Training loss: 3.4082095623016357
Validation loss: 2.8861672493719284

Epoch: 23| Step: 0
Training loss: 2.6354713439941406
Validation loss: 2.8829628267595844

Epoch: 5| Step: 1
Training loss: 3.2517127990722656
Validation loss: 2.881981549724456

Epoch: 5| Step: 2
Training loss: 3.080691337585449
Validation loss: 2.8766017395962953

Epoch: 5| Step: 3
Training loss: 2.7938690185546875
Validation loss: 2.8748284668050785

Epoch: 5| Step: 4
Training loss: 3.1598103046417236
Validation loss: 2.8748619043698875

Epoch: 5| Step: 5
Training loss: 2.6674435138702393
Validation loss: 2.872041412579116

Epoch: 5| Step: 6
Training loss: 3.2172417640686035
Validation loss: 2.8719551460717314

Epoch: 5| Step: 7
Training loss: 2.726656436920166
Validation loss: 2.8664887797447944

Epoch: 5| Step: 8
Training loss: 4.075984954833984
Validation loss: 2.868020183296614

Epoch: 5| Step: 9
Training loss: 2.90114164352417
Validation loss: 2.865154497085079

Epoch: 5| Step: 10
Training loss: 2.1031832695007324
Validation loss: 2.867323006353071

Epoch: 24| Step: 0
Training loss: 2.5964298248291016
Validation loss: 2.8699207946818364

Epoch: 5| Step: 1
Training loss: 3.269510269165039
Validation loss: 2.878493429512106

Epoch: 5| Step: 2
Training loss: 3.253864288330078
Validation loss: 2.861442171117311

Epoch: 5| Step: 3
Training loss: 2.6958885192871094
Validation loss: 2.8559670909758537

Epoch: 5| Step: 4
Training loss: 3.634824275970459
Validation loss: 2.8578457268335486

Epoch: 5| Step: 5
Training loss: 3.012526035308838
Validation loss: 2.8553780535215973

Epoch: 5| Step: 6
Training loss: 3.163102626800537
Validation loss: 2.861469819981565

Epoch: 5| Step: 7
Training loss: 2.944505214691162
Validation loss: 2.8619030675580426

Epoch: 5| Step: 8
Training loss: 2.4628617763519287
Validation loss: 2.862232738925565

Epoch: 5| Step: 9
Training loss: 2.7710793018341064
Validation loss: 2.8540883320634083

Epoch: 5| Step: 10
Training loss: 2.827463150024414
Validation loss: 2.8545579782096286

Epoch: 25| Step: 0
Training loss: 3.4742655754089355
Validation loss: 2.846857927178824

Epoch: 5| Step: 1
Training loss: 2.823637008666992
Validation loss: 2.843419841540757

Epoch: 5| Step: 2
Training loss: 2.4094982147216797
Validation loss: 2.8425464040489605

Epoch: 5| Step: 3
Training loss: 2.7988028526306152
Validation loss: 2.8415600253689672

Epoch: 5| Step: 4
Training loss: 3.8758292198181152
Validation loss: 2.853462714020924

Epoch: 5| Step: 5
Training loss: 1.6306393146514893
Validation loss: 2.8437433499161915

Epoch: 5| Step: 6
Training loss: 3.3927218914031982
Validation loss: 2.838239492908601

Epoch: 5| Step: 7
Training loss: 3.204533338546753
Validation loss: 2.8347633961708314

Epoch: 5| Step: 8
Training loss: 3.224346876144409
Validation loss: 2.830232817639587

Epoch: 5| Step: 9
Training loss: 2.8071603775024414
Validation loss: 2.8297456849005913

Epoch: 5| Step: 10
Training loss: 2.8339548110961914
Validation loss: 2.8256527326440297

Epoch: 26| Step: 0
Training loss: 3.405956983566284
Validation loss: 2.8263589566753757

Epoch: 5| Step: 1
Training loss: 2.1437149047851562
Validation loss: 2.8218257222124326

Epoch: 5| Step: 2
Training loss: 3.1545779705047607
Validation loss: 2.8200683491204375

Epoch: 5| Step: 3
Training loss: 3.1449177265167236
Validation loss: 2.8195603752648957

Epoch: 5| Step: 4
Training loss: 1.937434434890747
Validation loss: 2.8189844316051853

Epoch: 5| Step: 5
Training loss: 2.710801362991333
Validation loss: 2.8280700304174937

Epoch: 5| Step: 6
Training loss: 3.631139039993286
Validation loss: 2.83244445759763

Epoch: 5| Step: 7
Training loss: 2.4110183715820312
Validation loss: 2.8169754961485505

Epoch: 5| Step: 8
Training loss: 2.7885141372680664
Validation loss: 2.8129291252423356

Epoch: 5| Step: 9
Training loss: 3.308086395263672
Validation loss: 2.819463127402849

Epoch: 5| Step: 10
Training loss: 3.9310240745544434
Validation loss: 2.826792937453075

Epoch: 27| Step: 0
Training loss: 3.5652518272399902
Validation loss: 2.82247418485662

Epoch: 5| Step: 1
Training loss: 2.4211959838867188
Validation loss: 2.823566259876374

Epoch: 5| Step: 2
Training loss: 3.291693925857544
Validation loss: 2.8169323936585458

Epoch: 5| Step: 3
Training loss: 3.5742874145507812
Validation loss: 2.8197731023193686

Epoch: 5| Step: 4
Training loss: 2.839524745941162
Validation loss: 2.8125885327657065

Epoch: 5| Step: 5
Training loss: 2.4621007442474365
Validation loss: 2.812392242493168

Epoch: 5| Step: 6
Training loss: 3.000124454498291
Validation loss: 2.809543317364108

Epoch: 5| Step: 7
Training loss: 2.787750244140625
Validation loss: 2.810955406517111

Epoch: 5| Step: 8
Training loss: 2.2391371726989746
Validation loss: 2.805345819842431

Epoch: 5| Step: 9
Training loss: 3.2572147846221924
Validation loss: 2.806638668942195

Epoch: 5| Step: 10
Training loss: 2.890653610229492
Validation loss: 2.805777370288808

Epoch: 28| Step: 0
Training loss: 3.5449225902557373
Validation loss: 2.8014005102137083

Epoch: 5| Step: 1
Training loss: 2.794159412384033
Validation loss: 2.801045097330565

Epoch: 5| Step: 2
Training loss: 3.477708101272583
Validation loss: 2.7979397978833926

Epoch: 5| Step: 3
Training loss: 2.6840457916259766
Validation loss: 2.7946129409215783

Epoch: 5| Step: 4
Training loss: 2.771658420562744
Validation loss: 2.7902359859917754

Epoch: 5| Step: 5
Training loss: 3.651190996170044
Validation loss: 2.791854243124685

Epoch: 5| Step: 6
Training loss: 2.1386947631835938
Validation loss: 2.787169530827512

Epoch: 5| Step: 7
Training loss: 2.7610867023468018
Validation loss: 2.7869260029126237

Epoch: 5| Step: 8
Training loss: 2.3614237308502197
Validation loss: 2.7846667715298232

Epoch: 5| Step: 9
Training loss: 3.1473021507263184
Validation loss: 2.785219156613914

Epoch: 5| Step: 10
Training loss: 2.8148927688598633
Validation loss: 2.781522079180646

Epoch: 29| Step: 0
Training loss: 2.3096587657928467
Validation loss: 2.783053575023528

Epoch: 5| Step: 1
Training loss: 3.5152573585510254
Validation loss: 2.782669049437328

Epoch: 5| Step: 2
Training loss: 2.937833309173584
Validation loss: 2.7815926587709816

Epoch: 5| Step: 3
Training loss: 3.5687217712402344
Validation loss: 2.7824155156330397

Epoch: 5| Step: 4
Training loss: 2.4757962226867676
Validation loss: 2.7811933025237052

Epoch: 5| Step: 5
Training loss: 2.7495617866516113
Validation loss: 2.7807263251273864

Epoch: 5| Step: 6
Training loss: 2.679924249649048
Validation loss: 2.777701195850167

Epoch: 5| Step: 7
Training loss: 2.200059175491333
Validation loss: 2.7777391684952604

Epoch: 5| Step: 8
Training loss: 2.4731268882751465
Validation loss: 2.7756262081925587

Epoch: 5| Step: 9
Training loss: 3.016785144805908
Validation loss: 2.771841997741371

Epoch: 5| Step: 10
Training loss: 4.381616115570068
Validation loss: 2.774398890874719

Epoch: 30| Step: 0
Training loss: 3.773470401763916
Validation loss: 2.7711479612576064

Epoch: 5| Step: 1
Training loss: 2.9509968757629395
Validation loss: 2.7724983025622625

Epoch: 5| Step: 2
Training loss: 2.9883623123168945
Validation loss: 2.7721790549575642

Epoch: 5| Step: 3
Training loss: 3.076140880584717
Validation loss: 2.767560097479051

Epoch: 5| Step: 4
Training loss: 2.5348994731903076
Validation loss: 2.764439813552364

Epoch: 5| Step: 5
Training loss: 3.1198995113372803
Validation loss: 2.7636141828311387

Epoch: 5| Step: 6
Training loss: 2.626269817352295
Validation loss: 2.7615665851100797

Epoch: 5| Step: 7
Training loss: 3.2965798377990723
Validation loss: 2.762523530631937

Epoch: 5| Step: 8
Training loss: 2.615138530731201
Validation loss: 2.764536767877558

Epoch: 5| Step: 9
Training loss: 2.725551128387451
Validation loss: 2.7625449037039154

Epoch: 5| Step: 10
Training loss: 2.195526361465454
Validation loss: 2.760585954112391

Epoch: 31| Step: 0
Training loss: 3.215773344039917
Validation loss: 2.7559328745770197

Epoch: 5| Step: 1
Training loss: 2.6282620429992676
Validation loss: 2.7596826758435977

Epoch: 5| Step: 2
Training loss: 3.8574001789093018
Validation loss: 2.754297620506697

Epoch: 5| Step: 3
Training loss: 2.849710464477539
Validation loss: 2.758146242428851

Epoch: 5| Step: 4
Training loss: 2.2618167400360107
Validation loss: 2.755686608693933

Epoch: 5| Step: 5
Training loss: 3.7632203102111816
Validation loss: 2.758909971483292

Epoch: 5| Step: 6
Training loss: 3.0040290355682373
Validation loss: 2.7589186904250935

Epoch: 5| Step: 7
Training loss: 2.6617488861083984
Validation loss: 2.7551723731461393

Epoch: 5| Step: 8
Training loss: 2.5729618072509766
Validation loss: 2.7509460987583285

Epoch: 5| Step: 9
Training loss: 2.267130136489868
Validation loss: 2.7459030664095314

Epoch: 5| Step: 10
Training loss: 2.802001714706421
Validation loss: 2.7453628509275374

Epoch: 32| Step: 0
Training loss: 2.6811599731445312
Validation loss: 2.7467067062213855

Epoch: 5| Step: 1
Training loss: 2.931107997894287
Validation loss: 2.7470611077482983

Epoch: 5| Step: 2
Training loss: 2.0716564655303955
Validation loss: 2.747963838679816

Epoch: 5| Step: 3
Training loss: 2.839977979660034
Validation loss: 2.746552400691535

Epoch: 5| Step: 4
Training loss: 2.64239239692688
Validation loss: 2.7479483542903775

Epoch: 5| Step: 5
Training loss: 2.800856113433838
Validation loss: 2.7451078507208053

Epoch: 5| Step: 6
Training loss: 3.364408493041992
Validation loss: 2.742607649936471

Epoch: 5| Step: 7
Training loss: 2.5790820121765137
Validation loss: 2.741197575805008

Epoch: 5| Step: 8
Training loss: 2.8378219604492188
Validation loss: 2.739482487401655

Epoch: 5| Step: 9
Training loss: 3.3487982749938965
Validation loss: 2.7412370533071537

Epoch: 5| Step: 10
Training loss: 3.890838623046875
Validation loss: 2.7379842419778146

Epoch: 33| Step: 0
Training loss: 2.0988121032714844
Validation loss: 2.738400556707895

Epoch: 5| Step: 1
Training loss: 2.7529265880584717
Validation loss: 2.7332918438860165

Epoch: 5| Step: 2
Training loss: 2.910132884979248
Validation loss: 2.7360392488459104

Epoch: 5| Step: 3
Training loss: 2.5334925651550293
Validation loss: 2.7417669039900585

Epoch: 5| Step: 4
Training loss: 1.7356107234954834
Validation loss: 2.742210042092108

Epoch: 5| Step: 5
Training loss: 2.7912774085998535
Validation loss: 2.734203515514251

Epoch: 5| Step: 6
Training loss: 3.714684247970581
Validation loss: 2.7310276774949926

Epoch: 5| Step: 7
Training loss: 3.138134241104126
Validation loss: 2.732876895576395

Epoch: 5| Step: 8
Training loss: 3.578599452972412
Validation loss: 2.7294305293790755

Epoch: 5| Step: 9
Training loss: 3.220043659210205
Validation loss: 2.728756866147441

Epoch: 5| Step: 10
Training loss: 3.3306024074554443
Validation loss: 2.7342922277348016

Epoch: 34| Step: 0
Training loss: 2.3738527297973633
Validation loss: 2.7292036548737557

Epoch: 5| Step: 1
Training loss: 3.2009215354919434
Validation loss: 2.7279457533231346

Epoch: 5| Step: 2
Training loss: 2.388627529144287
Validation loss: 2.724757722629014

Epoch: 5| Step: 3
Training loss: 2.692547082901001
Validation loss: 2.7268364301291843

Epoch: 5| Step: 4
Training loss: 2.6994998455047607
Validation loss: 2.7272275673445834

Epoch: 5| Step: 5
Training loss: 3.013291835784912
Validation loss: 2.7326703020321426

Epoch: 5| Step: 6
Training loss: 3.175959348678589
Validation loss: 2.730533935690439

Epoch: 5| Step: 7
Training loss: 3.438931941986084
Validation loss: 2.7280122439066568

Epoch: 5| Step: 8
Training loss: 3.3138556480407715
Validation loss: 2.718718026273994

Epoch: 5| Step: 9
Training loss: 2.7943477630615234
Validation loss: 2.718930616173693

Epoch: 5| Step: 10
Training loss: 2.598465919494629
Validation loss: 2.7171726918989614

Epoch: 35| Step: 0
Training loss: 3.2312521934509277
Validation loss: 2.722042691323065

Epoch: 5| Step: 1
Training loss: 2.7900753021240234
Validation loss: 2.7254061724549983

Epoch: 5| Step: 2
Training loss: 2.7255358695983887
Validation loss: 2.7197143339341685

Epoch: 5| Step: 3
Training loss: 2.5587997436523438
Validation loss: 2.715684413909912

Epoch: 5| Step: 4
Training loss: 3.4979941844940186
Validation loss: 2.7157500174737748

Epoch: 5| Step: 5
Training loss: 2.794790744781494
Validation loss: 2.7171182017172537

Epoch: 5| Step: 6
Training loss: 2.9926540851593018
Validation loss: 2.71541327814902

Epoch: 5| Step: 7
Training loss: 2.920767307281494
Validation loss: 2.715706056164157

Epoch: 5| Step: 8
Training loss: 2.4036238193511963
Validation loss: 2.7200295771321943

Epoch: 5| Step: 9
Training loss: 2.8682761192321777
Validation loss: 2.7138587018494964

Epoch: 5| Step: 10
Training loss: 2.849485397338867
Validation loss: 2.71483721528002

Epoch: 36| Step: 0
Training loss: 2.6858348846435547
Validation loss: 2.7133202655341035

Epoch: 5| Step: 1
Training loss: 3.381622314453125
Validation loss: 2.7086382142959105

Epoch: 5| Step: 2
Training loss: 3.0120158195495605
Validation loss: 2.7074621518452964

Epoch: 5| Step: 3
Training loss: 2.122650623321533
Validation loss: 2.7069230464196976

Epoch: 5| Step: 4
Training loss: 2.9894185066223145
Validation loss: 2.707398053138487

Epoch: 5| Step: 5
Training loss: 2.9836080074310303
Validation loss: 2.705504217455464

Epoch: 5| Step: 6
Training loss: 2.605090379714966
Validation loss: 2.7052457383883897

Epoch: 5| Step: 7
Training loss: 2.46962571144104
Validation loss: 2.70346333647287

Epoch: 5| Step: 8
Training loss: 3.1072068214416504
Validation loss: 2.7103139969610397

Epoch: 5| Step: 9
Training loss: 3.595078229904175
Validation loss: 2.717046240324615

Epoch: 5| Step: 10
Training loss: 2.5814859867095947
Validation loss: 2.7192976320943525

Epoch: 37| Step: 0
Training loss: 2.8698742389678955
Validation loss: 2.7042855267883628

Epoch: 5| Step: 1
Training loss: 3.3320679664611816
Validation loss: 2.708670436695058

Epoch: 5| Step: 2
Training loss: 2.8654356002807617
Validation loss: 2.7132990514078448

Epoch: 5| Step: 3
Training loss: 3.2288765907287598
Validation loss: 2.7205639885317896

Epoch: 5| Step: 4
Training loss: 3.338644027709961
Validation loss: 2.716996249332223

Epoch: 5| Step: 5
Training loss: 2.9263408184051514
Validation loss: 2.7182028473064466

Epoch: 5| Step: 6
Training loss: 2.348353385925293
Validation loss: 2.7184606598269556

Epoch: 5| Step: 7
Training loss: 2.242849349975586
Validation loss: 2.716905329817085

Epoch: 5| Step: 8
Training loss: 2.2884809970855713
Validation loss: 2.7198267572669574

Epoch: 5| Step: 9
Training loss: 2.868368148803711
Validation loss: 2.714182074351977

Epoch: 5| Step: 10
Training loss: 3.4150614738464355
Validation loss: 2.707762154199744

Epoch: 38| Step: 0
Training loss: 3.494819164276123
Validation loss: 2.706484417761526

Epoch: 5| Step: 1
Training loss: 3.6484527587890625
Validation loss: 2.7054909147242063

Epoch: 5| Step: 2
Training loss: 2.722623348236084
Validation loss: 2.7013661733237644

Epoch: 5| Step: 3
Training loss: 2.8299994468688965
Validation loss: 2.6988311121540685

Epoch: 5| Step: 4
Training loss: 2.611138343811035
Validation loss: 2.698748570616527

Epoch: 5| Step: 5
Training loss: 2.2253406047821045
Validation loss: 2.6976756998287734

Epoch: 5| Step: 6
Training loss: 2.9832653999328613
Validation loss: 2.6997032806437504

Epoch: 5| Step: 7
Training loss: 3.661792755126953
Validation loss: 2.7011250295946674

Epoch: 5| Step: 8
Training loss: 2.5309877395629883
Validation loss: 2.7024097878445863

Epoch: 5| Step: 9
Training loss: 2.408630847930908
Validation loss: 2.708377497170561

Epoch: 5| Step: 10
Training loss: 2.341855764389038
Validation loss: 2.7070103999107116

Epoch: 39| Step: 0
Training loss: 2.6760973930358887
Validation loss: 2.705244425804384

Epoch: 5| Step: 1
Training loss: 2.6628689765930176
Validation loss: 2.7029907216307936

Epoch: 5| Step: 2
Training loss: 2.999997854232788
Validation loss: 2.706538102960074

Epoch: 5| Step: 3
Training loss: 3.208266496658325
Validation loss: 2.703886419214228

Epoch: 5| Step: 4
Training loss: 2.087538242340088
Validation loss: 2.696435272052724

Epoch: 5| Step: 5
Training loss: 2.5343589782714844
Validation loss: 2.693239253054383

Epoch: 5| Step: 6
Training loss: 2.946523904800415
Validation loss: 2.6882224108583186

Epoch: 5| Step: 7
Training loss: 3.2091217041015625
Validation loss: 2.6886086899747133

Epoch: 5| Step: 8
Training loss: 2.9728400707244873
Validation loss: 2.6892895698547363

Epoch: 5| Step: 9
Training loss: 3.227151870727539
Validation loss: 2.6858389787776495

Epoch: 5| Step: 10
Training loss: 2.975433111190796
Validation loss: 2.687095293434717

Epoch: 40| Step: 0
Training loss: 3.428436279296875
Validation loss: 2.6856482131506807

Epoch: 5| Step: 1
Training loss: 2.6790060997009277
Validation loss: 2.683313126205116

Epoch: 5| Step: 2
Training loss: 3.6749091148376465
Validation loss: 2.686112778161162

Epoch: 5| Step: 3
Training loss: 2.763664484024048
Validation loss: 2.6854860039167505

Epoch: 5| Step: 4
Training loss: 3.7701306343078613
Validation loss: 2.6847807873961744

Epoch: 5| Step: 5
Training loss: 3.037259340286255
Validation loss: 2.6839725817403486

Epoch: 5| Step: 6
Training loss: 2.0418589115142822
Validation loss: 2.6851879396746234

Epoch: 5| Step: 7
Training loss: 2.3365790843963623
Validation loss: 2.683470731140465

Epoch: 5| Step: 8
Training loss: 2.501878261566162
Validation loss: 2.682210883786601

Epoch: 5| Step: 9
Training loss: 2.7609405517578125
Validation loss: 2.6832674293107885

Epoch: 5| Step: 10
Training loss: 2.3736636638641357
Validation loss: 2.6815270813562537

Epoch: 41| Step: 0
Training loss: 3.165323257446289
Validation loss: 2.6807678079092376

Epoch: 5| Step: 1
Training loss: 2.902618885040283
Validation loss: 2.682680591460197

Epoch: 5| Step: 2
Training loss: 3.384554386138916
Validation loss: 2.678896580972979

Epoch: 5| Step: 3
Training loss: 2.3502798080444336
Validation loss: 2.678757116358767

Epoch: 5| Step: 4
Training loss: 2.4486968517303467
Validation loss: 2.675893642569101

Epoch: 5| Step: 5
Training loss: 2.318591594696045
Validation loss: 2.676834511500533

Epoch: 5| Step: 6
Training loss: 3.222245454788208
Validation loss: 2.6787906769783265

Epoch: 5| Step: 7
Training loss: 2.7365269660949707
Validation loss: 2.678339676190448

Epoch: 5| Step: 8
Training loss: 2.4528024196624756
Validation loss: 2.6785299726711806

Epoch: 5| Step: 9
Training loss: 3.586430311203003
Validation loss: 2.6776236308518278

Epoch: 5| Step: 10
Training loss: 2.8021929264068604
Validation loss: 2.6740062775150424

Epoch: 42| Step: 0
Training loss: 2.4238338470458984
Validation loss: 2.675753355026245

Epoch: 5| Step: 1
Training loss: 2.538134813308716
Validation loss: 2.676841246184482

Epoch: 5| Step: 2
Training loss: 2.7422966957092285
Validation loss: 2.6782027265076995

Epoch: 5| Step: 3
Training loss: 3.146932601928711
Validation loss: 2.6777247510930544

Epoch: 5| Step: 4
Training loss: 3.2075035572052
Validation loss: 2.6722359644469393

Epoch: 5| Step: 5
Training loss: 2.2593142986297607
Validation loss: 2.6706755622740714

Epoch: 5| Step: 6
Training loss: 2.407442808151245
Validation loss: 2.6733561664499264

Epoch: 5| Step: 7
Training loss: 3.49519419670105
Validation loss: 2.6708922206714587

Epoch: 5| Step: 8
Training loss: 3.423072099685669
Validation loss: 2.6750001522802536

Epoch: 5| Step: 9
Training loss: 3.044144868850708
Validation loss: 2.6737974766762025

Epoch: 5| Step: 10
Training loss: 2.619781970977783
Validation loss: 2.6732357317401516

Epoch: 43| Step: 0
Training loss: 2.6297900676727295
Validation loss: 2.670912801578481

Epoch: 5| Step: 1
Training loss: 3.403388500213623
Validation loss: 2.6689949702191096

Epoch: 5| Step: 2
Training loss: 2.5068211555480957
Validation loss: 2.6715965706815004

Epoch: 5| Step: 3
Training loss: 3.52410888671875
Validation loss: 2.6711982475814

Epoch: 5| Step: 4
Training loss: 2.581991195678711
Validation loss: 2.6706038444272933

Epoch: 5| Step: 5
Training loss: 3.0469963550567627
Validation loss: 2.671325114465529

Epoch: 5| Step: 6
Training loss: 2.8083863258361816
Validation loss: 2.6676439546769664

Epoch: 5| Step: 7
Training loss: 2.4864566326141357
Validation loss: 2.666187263304187

Epoch: 5| Step: 8
Training loss: 3.022948741912842
Validation loss: 2.6680832832090315

Epoch: 5| Step: 9
Training loss: 2.205763816833496
Validation loss: 2.6712261092278267

Epoch: 5| Step: 10
Training loss: 3.096327543258667
Validation loss: 2.6702075978761077

Epoch: 44| Step: 0
Training loss: 2.4453325271606445
Validation loss: 2.6786953249285297

Epoch: 5| Step: 1
Training loss: 2.6839325428009033
Validation loss: 2.676841910167407

Epoch: 5| Step: 2
Training loss: 2.604921340942383
Validation loss: 2.692053207787134

Epoch: 5| Step: 3
Training loss: 3.6382102966308594
Validation loss: 2.6764016997429634

Epoch: 5| Step: 4
Training loss: 3.1417975425720215
Validation loss: 2.663844229072653

Epoch: 5| Step: 5
Training loss: 2.581272840499878
Validation loss: 2.663557191048899

Epoch: 5| Step: 6
Training loss: 2.026285409927368
Validation loss: 2.6662728222467567

Epoch: 5| Step: 7
Training loss: 3.8360939025878906
Validation loss: 2.669428330595775

Epoch: 5| Step: 8
Training loss: 2.894280195236206
Validation loss: 2.66942532344531

Epoch: 5| Step: 9
Training loss: 2.9268887042999268
Validation loss: 2.6698401461365404

Epoch: 5| Step: 10
Training loss: 2.4454469680786133
Validation loss: 2.6728235572896977

Epoch: 45| Step: 0
Training loss: 3.1121039390563965
Validation loss: 2.678366663635418

Epoch: 5| Step: 1
Training loss: 2.2203421592712402
Validation loss: 2.681762110802435

Epoch: 5| Step: 2
Training loss: 2.4002397060394287
Validation loss: 2.6928086127004316

Epoch: 5| Step: 3
Training loss: 2.865659236907959
Validation loss: 2.710685240325107

Epoch: 5| Step: 4
Training loss: 3.0755443572998047
Validation loss: 2.699816419232276

Epoch: 5| Step: 5
Training loss: 2.798142910003662
Validation loss: 2.6864946862702728

Epoch: 5| Step: 6
Training loss: 2.4459240436553955
Validation loss: 2.674213905488291

Epoch: 5| Step: 7
Training loss: 2.82812762260437
Validation loss: 2.665769987208869

Epoch: 5| Step: 8
Training loss: 3.357753038406372
Validation loss: 2.6666472650343374

Epoch: 5| Step: 9
Training loss: 2.858398199081421
Validation loss: 2.665527915441862

Epoch: 5| Step: 10
Training loss: 3.5407721996307373
Validation loss: 2.6646342687709357

Epoch: 46| Step: 0
Training loss: 2.6515910625457764
Validation loss: 2.66589214212151

Epoch: 5| Step: 1
Training loss: 2.7870466709136963
Validation loss: 2.671058947040189

Epoch: 5| Step: 2
Training loss: 3.065594434738159
Validation loss: 2.667918533407232

Epoch: 5| Step: 3
Training loss: 2.4556260108947754
Validation loss: 2.6710567500001643

Epoch: 5| Step: 4
Training loss: 2.9403083324432373
Validation loss: 2.674367709826398

Epoch: 5| Step: 5
Training loss: 3.059507369995117
Validation loss: 2.665524249435753

Epoch: 5| Step: 6
Training loss: 2.5802886486053467
Validation loss: 2.6622330604061

Epoch: 5| Step: 7
Training loss: 3.0909411907196045
Validation loss: 2.6616782731907342

Epoch: 5| Step: 8
Training loss: 3.108438014984131
Validation loss: 2.661695598274149

Epoch: 5| Step: 9
Training loss: 2.8384082317352295
Validation loss: 2.662565167232226

Epoch: 5| Step: 10
Training loss: 2.647784948348999
Validation loss: 2.659677392692976

Epoch: 47| Step: 0
Training loss: 2.5749783515930176
Validation loss: 2.6626499160643546

Epoch: 5| Step: 1
Training loss: 3.086308002471924
Validation loss: 2.668859494629727

Epoch: 5| Step: 2
Training loss: 3.050048828125
Validation loss: 2.669860578352405

Epoch: 5| Step: 3
Training loss: 2.8894073963165283
Validation loss: 2.683014192888814

Epoch: 5| Step: 4
Training loss: 2.2908263206481934
Validation loss: 2.697303725827125

Epoch: 5| Step: 5
Training loss: 2.6282527446746826
Validation loss: 2.7187863370423675

Epoch: 5| Step: 6
Training loss: 3.564110517501831
Validation loss: 2.7133202604068223

Epoch: 5| Step: 7
Training loss: 2.6631720066070557
Validation loss: 2.6843600683314826

Epoch: 5| Step: 8
Training loss: 3.115631580352783
Validation loss: 2.6687000156730734

Epoch: 5| Step: 9
Training loss: 2.7316348552703857
Validation loss: 2.664736460613948

Epoch: 5| Step: 10
Training loss: 2.685352325439453
Validation loss: 2.659239817691106

Epoch: 48| Step: 0
Training loss: 2.6983745098114014
Validation loss: 2.6509636345730034

Epoch: 5| Step: 1
Training loss: 2.7487542629241943
Validation loss: 2.6558946999170447

Epoch: 5| Step: 2
Training loss: 2.9486448764801025
Validation loss: 2.656936084070513

Epoch: 5| Step: 3
Training loss: 2.965914487838745
Validation loss: 2.658163719279792

Epoch: 5| Step: 4
Training loss: 3.096667766571045
Validation loss: 2.6647010926277406

Epoch: 5| Step: 5
Training loss: 2.507704496383667
Validation loss: 2.668176425400601

Epoch: 5| Step: 6
Training loss: 2.732451915740967
Validation loss: 2.6674969016864734

Epoch: 5| Step: 7
Training loss: 3.7444159984588623
Validation loss: 2.6626721915378364

Epoch: 5| Step: 8
Training loss: 2.7575652599334717
Validation loss: 2.655794120603992

Epoch: 5| Step: 9
Training loss: 2.6970741748809814
Validation loss: 2.651884909599058

Epoch: 5| Step: 10
Training loss: 2.2208454608917236
Validation loss: 2.652072442475186

Epoch: 49| Step: 0
Training loss: 3.4260964393615723
Validation loss: 2.650966933978501

Epoch: 5| Step: 1
Training loss: 2.8359503746032715
Validation loss: 2.6491448443423034

Epoch: 5| Step: 2
Training loss: 2.887748956680298
Validation loss: 2.6480400305922314

Epoch: 5| Step: 3
Training loss: 2.712169885635376
Validation loss: 2.6454675864147883

Epoch: 5| Step: 4
Training loss: 2.3180339336395264
Validation loss: 2.648166900040001

Epoch: 5| Step: 5
Training loss: 3.1188347339630127
Validation loss: 2.6499735129776822

Epoch: 5| Step: 6
Training loss: 2.847306728363037
Validation loss: 2.6512276421311083

Epoch: 5| Step: 7
Training loss: 2.8794949054718018
Validation loss: 2.6549214983499176

Epoch: 5| Step: 8
Training loss: 2.9147183895111084
Validation loss: 2.6606711982398905

Epoch: 5| Step: 9
Training loss: 3.0925803184509277
Validation loss: 2.6511333604012766

Epoch: 5| Step: 10
Training loss: 1.9949287176132202
Validation loss: 2.6497118703780638

Epoch: 50| Step: 0
Training loss: 2.3453900814056396
Validation loss: 2.649830343902752

Epoch: 5| Step: 1
Training loss: 2.6500184535980225
Validation loss: 2.6525834478357786

Epoch: 5| Step: 2
Training loss: 3.284553050994873
Validation loss: 2.6568725442373626

Epoch: 5| Step: 3
Training loss: 2.7368710041046143
Validation loss: 2.655148257491409

Epoch: 5| Step: 4
Training loss: 3.0307748317718506
Validation loss: 2.652567099499446

Epoch: 5| Step: 5
Training loss: 2.9213509559631348
Validation loss: 2.6547061627910984

Epoch: 5| Step: 6
Training loss: 3.1655704975128174
Validation loss: 2.6489859986048874

Epoch: 5| Step: 7
Training loss: 3.21966290473938
Validation loss: 2.6506286436511624

Epoch: 5| Step: 8
Training loss: 2.0058960914611816
Validation loss: 2.6537661578065608

Epoch: 5| Step: 9
Training loss: 2.9269840717315674
Validation loss: 2.6453890364657164

Epoch: 5| Step: 10
Training loss: 2.857407569885254
Validation loss: 2.648805469594976

Epoch: 51| Step: 0
Training loss: 2.635258197784424
Validation loss: 2.6462994160190707

Epoch: 5| Step: 1
Training loss: 2.8094334602355957
Validation loss: 2.6456778023832586

Epoch: 5| Step: 2
Training loss: 3.1421494483947754
Validation loss: 2.644205088256508

Epoch: 5| Step: 3
Training loss: 3.0284767150878906
Validation loss: 2.6422924610876266

Epoch: 5| Step: 4
Training loss: 3.1172595024108887
Validation loss: 2.640654574158371

Epoch: 5| Step: 5
Training loss: 2.7098329067230225
Validation loss: 2.639926984745969

Epoch: 5| Step: 6
Training loss: 2.507459878921509
Validation loss: 2.640700347961918

Epoch: 5| Step: 7
Training loss: 2.892378330230713
Validation loss: 2.6404989252808275

Epoch: 5| Step: 8
Training loss: 2.7007386684417725
Validation loss: 2.642292873833769

Epoch: 5| Step: 9
Training loss: 2.593397378921509
Validation loss: 2.64084384774649

Epoch: 5| Step: 10
Training loss: 2.9469985961914062
Validation loss: 2.6426468382599535

Epoch: 52| Step: 0
Training loss: 2.408024787902832
Validation loss: 2.641049151779503

Epoch: 5| Step: 1
Training loss: 2.6829593181610107
Validation loss: 2.6471211884611394

Epoch: 5| Step: 2
Training loss: 2.7105393409729004
Validation loss: 2.642229349382462

Epoch: 5| Step: 3
Training loss: 3.049222230911255
Validation loss: 2.6399496088745775

Epoch: 5| Step: 4
Training loss: 2.6673197746276855
Validation loss: 2.6395567770927184

Epoch: 5| Step: 5
Training loss: 2.765352487564087
Validation loss: 2.6388601590228338

Epoch: 5| Step: 6
Training loss: 3.1114068031311035
Validation loss: 2.6360063629765667

Epoch: 5| Step: 7
Training loss: 2.608250379562378
Validation loss: 2.639439639224801

Epoch: 5| Step: 8
Training loss: 3.1184279918670654
Validation loss: 2.639054185600691

Epoch: 5| Step: 9
Training loss: 3.270472764968872
Validation loss: 2.6423817142363517

Epoch: 5| Step: 10
Training loss: 2.5870118141174316
Validation loss: 2.6424239322703373

Epoch: 53| Step: 0
Training loss: 2.5686917304992676
Validation loss: 2.6469100777820875

Epoch: 5| Step: 1
Training loss: 3.026176929473877
Validation loss: 2.6467329712324243

Epoch: 5| Step: 2
Training loss: 2.1130757331848145
Validation loss: 2.6433460814978487

Epoch: 5| Step: 3
Training loss: 3.1480534076690674
Validation loss: 2.6354566850969867

Epoch: 5| Step: 4
Training loss: 2.8591482639312744
Validation loss: 2.631849701686572

Epoch: 5| Step: 5
Training loss: 2.918300151824951
Validation loss: 2.6317065864480953

Epoch: 5| Step: 6
Training loss: 3.5297608375549316
Validation loss: 2.638330582649477

Epoch: 5| Step: 7
Training loss: 3.1321003437042236
Validation loss: 2.639778660189721

Epoch: 5| Step: 8
Training loss: 1.845960259437561
Validation loss: 2.6416211333326114

Epoch: 5| Step: 9
Training loss: 2.906445026397705
Validation loss: 2.635714138707807

Epoch: 5| Step: 10
Training loss: 3.0625858306884766
Validation loss: 2.632908195577642

Epoch: 54| Step: 0
Training loss: 2.6161513328552246
Validation loss: 2.6348652480750956

Epoch: 5| Step: 1
Training loss: 2.813377857208252
Validation loss: 2.6309861444657847

Epoch: 5| Step: 2
Training loss: 3.192963123321533
Validation loss: 2.6371354467125347

Epoch: 5| Step: 3
Training loss: 2.5404515266418457
Validation loss: 2.6406065264055805

Epoch: 5| Step: 4
Training loss: 2.9917471408843994
Validation loss: 2.63947977301895

Epoch: 5| Step: 5
Training loss: 2.478868246078491
Validation loss: 2.64024640411459

Epoch: 5| Step: 6
Training loss: 3.2449791431427
Validation loss: 2.637020669957643

Epoch: 5| Step: 7
Training loss: 2.4409592151641846
Validation loss: 2.641630588039275

Epoch: 5| Step: 8
Training loss: 3.089146137237549
Validation loss: 2.6436085829170803

Epoch: 5| Step: 9
Training loss: 2.8642666339874268
Validation loss: 2.6454219792478826

Epoch: 5| Step: 10
Training loss: 2.759932279586792
Validation loss: 2.6360153998098066

Epoch: 55| Step: 0
Training loss: 2.9096968173980713
Validation loss: 2.6337575220292613

Epoch: 5| Step: 1
Training loss: 2.8575639724731445
Validation loss: 2.6298116791632866

Epoch: 5| Step: 2
Training loss: 3.7924301624298096
Validation loss: 2.630247195561727

Epoch: 5| Step: 3
Training loss: 1.9033164978027344
Validation loss: 2.634543526557184

Epoch: 5| Step: 4
Training loss: 3.0099167823791504
Validation loss: 2.6331809912958453

Epoch: 5| Step: 5
Training loss: 2.8519091606140137
Validation loss: 2.632813302419519

Epoch: 5| Step: 6
Training loss: 2.3091087341308594
Validation loss: 2.6343668455718667

Epoch: 5| Step: 7
Training loss: 3.012049436569214
Validation loss: 2.6315598564763225

Epoch: 5| Step: 8
Training loss: 2.6289315223693848
Validation loss: 2.6281170639940488

Epoch: 5| Step: 9
Training loss: 2.404358386993408
Validation loss: 2.6290276486386537

Epoch: 5| Step: 10
Training loss: 3.3526220321655273
Validation loss: 2.6307175159454346

Epoch: 56| Step: 0
Training loss: 2.209012508392334
Validation loss: 2.6344248376866823

Epoch: 5| Step: 1
Training loss: 3.491447925567627
Validation loss: 2.6322273926068376

Epoch: 5| Step: 2
Training loss: 2.586408853530884
Validation loss: 2.63021243515835

Epoch: 5| Step: 3
Training loss: 3.061058759689331
Validation loss: 2.632212200472432

Epoch: 5| Step: 4
Training loss: 3.126600980758667
Validation loss: 2.6360264337191017

Epoch: 5| Step: 5
Training loss: 2.692758798599243
Validation loss: 2.6369810206915743

Epoch: 5| Step: 6
Training loss: 3.074556827545166
Validation loss: 2.632562311746741

Epoch: 5| Step: 7
Training loss: 2.7204062938690186
Validation loss: 2.6417421217887633

Epoch: 5| Step: 8
Training loss: 2.9357669353485107
Validation loss: 2.643779029128372

Epoch: 5| Step: 9
Training loss: 2.0126898288726807
Validation loss: 2.6502786503043225

Epoch: 5| Step: 10
Training loss: 3.0667340755462646
Validation loss: 2.634566935159827

Epoch: 57| Step: 0
Training loss: 2.9739108085632324
Validation loss: 2.631422483792869

Epoch: 5| Step: 1
Training loss: 3.3664231300354004
Validation loss: 2.626190108637656

Epoch: 5| Step: 2
Training loss: 2.2545013427734375
Validation loss: 2.625865918333812

Epoch: 5| Step: 3
Training loss: 2.9177849292755127
Validation loss: 2.626640437751688

Epoch: 5| Step: 4
Training loss: 3.209585666656494
Validation loss: 2.6306726137797036

Epoch: 5| Step: 5
Training loss: 3.156601667404175
Validation loss: 2.6272825964035524

Epoch: 5| Step: 6
Training loss: 2.535404920578003
Validation loss: 2.633155643299062

Epoch: 5| Step: 7
Training loss: 2.28084135055542
Validation loss: 2.632288622599776

Epoch: 5| Step: 8
Training loss: 2.4307308197021484
Validation loss: 2.6337477878857682

Epoch: 5| Step: 9
Training loss: 2.4389889240264893
Validation loss: 2.6339940306960896

Epoch: 5| Step: 10
Training loss: 3.542175054550171
Validation loss: 2.6330573328079714

Epoch: 58| Step: 0
Training loss: 2.7199883460998535
Validation loss: 2.6334619470821914

Epoch: 5| Step: 1
Training loss: 3.056483030319214
Validation loss: 2.6293981511105775

Epoch: 5| Step: 2
Training loss: 2.829246997833252
Validation loss: 2.630594616295189

Epoch: 5| Step: 3
Training loss: 2.768263578414917
Validation loss: 2.6363109593750327

Epoch: 5| Step: 4
Training loss: 3.029386043548584
Validation loss: 2.631720232707198

Epoch: 5| Step: 5
Training loss: 2.2048707008361816
Validation loss: 2.635717343258601

Epoch: 5| Step: 6
Training loss: 3.734304428100586
Validation loss: 2.635481165301415

Epoch: 5| Step: 7
Training loss: 2.351167917251587
Validation loss: 2.627656644390475

Epoch: 5| Step: 8
Training loss: 2.909715414047241
Validation loss: 2.6212885636155323

Epoch: 5| Step: 9
Training loss: 3.073392629623413
Validation loss: 2.616416505587998

Epoch: 5| Step: 10
Training loss: 2.161172389984131
Validation loss: 2.6215894914442495

Epoch: 59| Step: 0
Training loss: 2.68074893951416
Validation loss: 2.6213042043870494

Epoch: 5| Step: 1
Training loss: 2.880516290664673
Validation loss: 2.623913598316972

Epoch: 5| Step: 2
Training loss: 2.821971893310547
Validation loss: 2.6256464578772105

Epoch: 5| Step: 3
Training loss: 3.2112412452697754
Validation loss: 2.624506176158946

Epoch: 5| Step: 4
Training loss: 3.205920457839966
Validation loss: 2.6243378449511785

Epoch: 5| Step: 5
Training loss: 2.3316006660461426
Validation loss: 2.6256275023183515

Epoch: 5| Step: 6
Training loss: 3.1365036964416504
Validation loss: 2.6271644176975375

Epoch: 5| Step: 7
Training loss: 3.3546650409698486
Validation loss: 2.6185904754105436

Epoch: 5| Step: 8
Training loss: 2.323303461074829
Validation loss: 2.6218145355101554

Epoch: 5| Step: 9
Training loss: 1.9087880849838257
Validation loss: 2.6200509814805883

Epoch: 5| Step: 10
Training loss: 3.045725107192993
Validation loss: 2.621812084669708

Epoch: 60| Step: 0
Training loss: 3.338576078414917
Validation loss: 2.6253883813017156

Epoch: 5| Step: 1
Training loss: 3.512840986251831
Validation loss: 2.626386724492555

Epoch: 5| Step: 2
Training loss: 2.6438193321228027
Validation loss: 2.6205650503917406

Epoch: 5| Step: 3
Training loss: 2.3173136711120605
Validation loss: 2.6265946536935787

Epoch: 5| Step: 4
Training loss: 3.6846377849578857
Validation loss: 2.6212510396075506

Epoch: 5| Step: 5
Training loss: 2.4138264656066895
Validation loss: 2.612382778557398

Epoch: 5| Step: 6
Training loss: 2.922309398651123
Validation loss: 2.615640224949006

Epoch: 5| Step: 7
Training loss: 2.457554340362549
Validation loss: 2.610382587678971

Epoch: 5| Step: 8
Training loss: 2.4177088737487793
Validation loss: 2.616075467037898

Epoch: 5| Step: 9
Training loss: 2.715759754180908
Validation loss: 2.6124581367738786

Epoch: 5| Step: 10
Training loss: 2.3224313259124756
Validation loss: 2.613826408181139

Epoch: 61| Step: 0
Training loss: 3.8116989135742188
Validation loss: 2.6152607061529674

Epoch: 5| Step: 1
Training loss: 2.6956164836883545
Validation loss: 2.6141243314230316

Epoch: 5| Step: 2
Training loss: 2.647576093673706
Validation loss: 2.6142170941957863

Epoch: 5| Step: 3
Training loss: 3.3224480152130127
Validation loss: 2.6107455991929576

Epoch: 5| Step: 4
Training loss: 2.4723892211914062
Validation loss: 2.6114711633292575

Epoch: 5| Step: 5
Training loss: 2.392091989517212
Validation loss: 2.612292233333793

Epoch: 5| Step: 6
Training loss: 3.299806594848633
Validation loss: 2.6121341336158013

Epoch: 5| Step: 7
Training loss: 2.6230628490448
Validation loss: 2.6102557797585764

Epoch: 5| Step: 8
Training loss: 2.4627339839935303
Validation loss: 2.6100158178678123

Epoch: 5| Step: 9
Training loss: 2.3554129600524902
Validation loss: 2.610370497549734

Epoch: 5| Step: 10
Training loss: 2.687575101852417
Validation loss: 2.6116048776975243

Epoch: 62| Step: 0
Training loss: 2.6445670127868652
Validation loss: 2.608130342216902

Epoch: 5| Step: 1
Training loss: 2.6510140895843506
Validation loss: 2.6113145966683664

Epoch: 5| Step: 2
Training loss: 3.0502376556396484
Validation loss: 2.616956259614678

Epoch: 5| Step: 3
Training loss: 2.4763336181640625
Validation loss: 2.6214506164673836

Epoch: 5| Step: 4
Training loss: 2.8619096279144287
Validation loss: 2.620641503282773

Epoch: 5| Step: 5
Training loss: 3.3105874061584473
Validation loss: 2.620109188941217

Epoch: 5| Step: 6
Training loss: 2.818032741546631
Validation loss: 2.6164727287907756

Epoch: 5| Step: 7
Training loss: 2.7885162830352783
Validation loss: 2.6114931721841135

Epoch: 5| Step: 8
Training loss: 2.1356239318847656
Validation loss: 2.613003623101019

Epoch: 5| Step: 9
Training loss: 2.655287265777588
Validation loss: 2.6153044290440057

Epoch: 5| Step: 10
Training loss: 3.473658323287964
Validation loss: 2.61214199373799

Epoch: 63| Step: 0
Training loss: 2.3019747734069824
Validation loss: 2.6115725783891577

Epoch: 5| Step: 1
Training loss: 2.2780563831329346
Validation loss: 2.6091477358213035

Epoch: 5| Step: 2
Training loss: 1.9720211029052734
Validation loss: 2.6139344374338784

Epoch: 5| Step: 3
Training loss: 2.662508249282837
Validation loss: 2.6132519245147705

Epoch: 5| Step: 4
Training loss: 3.327465057373047
Validation loss: 2.621892483003678

Epoch: 5| Step: 5
Training loss: 3.621955394744873
Validation loss: 2.619441750229046

Epoch: 5| Step: 6
Training loss: 2.2665412425994873
Validation loss: 2.61744204900598

Epoch: 5| Step: 7
Training loss: 3.390397548675537
Validation loss: 2.6151794746357906

Epoch: 5| Step: 8
Training loss: 3.2995877265930176
Validation loss: 2.6147831639935895

Epoch: 5| Step: 9
Training loss: 3.1469788551330566
Validation loss: 2.609031443954796

Epoch: 5| Step: 10
Training loss: 2.4117796421051025
Validation loss: 2.608923937684746

Epoch: 64| Step: 0
Training loss: 2.404646396636963
Validation loss: 2.614698415161461

Epoch: 5| Step: 1
Training loss: 2.7892916202545166
Validation loss: 2.618389529566611

Epoch: 5| Step: 2
Training loss: 2.6303658485412598
Validation loss: 2.6152536099956882

Epoch: 5| Step: 3
Training loss: 2.7934913635253906
Validation loss: 2.6234355562476703

Epoch: 5| Step: 4
Training loss: 2.4056923389434814
Validation loss: 2.6251464120803343

Epoch: 5| Step: 5
Training loss: 3.3726248741149902
Validation loss: 2.6207507784648607

Epoch: 5| Step: 6
Training loss: 2.650413990020752
Validation loss: 2.619376410720169

Epoch: 5| Step: 7
Training loss: 2.1155848503112793
Validation loss: 2.606280506298106

Epoch: 5| Step: 8
Training loss: 2.8934810161590576
Validation loss: 2.600274565399334

Epoch: 5| Step: 9
Training loss: 3.7084007263183594
Validation loss: 2.6012916423941173

Epoch: 5| Step: 10
Training loss: 2.9653635025024414
Validation loss: 2.6079488492781118

Epoch: 65| Step: 0
Training loss: 3.5940983295440674
Validation loss: 2.6098189251397246

Epoch: 5| Step: 1
Training loss: 2.79862904548645
Validation loss: 2.609496057674449

Epoch: 5| Step: 2
Training loss: 2.5382113456726074
Validation loss: 2.613370433930428

Epoch: 5| Step: 3
Training loss: 3.274350643157959
Validation loss: 2.6124481360117593

Epoch: 5| Step: 4
Training loss: 2.6200098991394043
Validation loss: 2.61028483862518

Epoch: 5| Step: 5
Training loss: 2.4080393314361572
Validation loss: 2.610226228672971

Epoch: 5| Step: 6
Training loss: 2.551945447921753
Validation loss: 2.614252290418071

Epoch: 5| Step: 7
Training loss: 2.723977565765381
Validation loss: 2.620656572362428

Epoch: 5| Step: 8
Training loss: 3.1042869091033936
Validation loss: 2.616836276105655

Epoch: 5| Step: 9
Training loss: 2.4420762062072754
Validation loss: 2.6081764262209655

Epoch: 5| Step: 10
Training loss: 2.648183584213257
Validation loss: 2.6054824731683217

Epoch: 66| Step: 0
Training loss: 2.9186458587646484
Validation loss: 2.6041480366901686

Epoch: 5| Step: 1
Training loss: 3.382567882537842
Validation loss: 2.6043288630823933

Epoch: 5| Step: 2
Training loss: 3.60127329826355
Validation loss: 2.6029166098563903

Epoch: 5| Step: 3
Training loss: 2.4039700031280518
Validation loss: 2.6037225120811054

Epoch: 5| Step: 4
Training loss: 2.4360721111297607
Validation loss: 2.603366704397304

Epoch: 5| Step: 5
Training loss: 2.6184253692626953
Validation loss: 2.613555118601809

Epoch: 5| Step: 6
Training loss: 3.014132022857666
Validation loss: 2.615774179017672

Epoch: 5| Step: 7
Training loss: 2.129983425140381
Validation loss: 2.613705112088111

Epoch: 5| Step: 8
Training loss: 2.920936107635498
Validation loss: 2.61750707831434

Epoch: 5| Step: 9
Training loss: 2.9676084518432617
Validation loss: 2.6075996942417596

Epoch: 5| Step: 10
Training loss: 2.2069814205169678
Validation loss: 2.597901677572599

Epoch: 67| Step: 0
Training loss: 3.1013646125793457
Validation loss: 2.5975782589245866

Epoch: 5| Step: 1
Training loss: 2.5059010982513428
Validation loss: 2.5947588028446322

Epoch: 5| Step: 2
Training loss: 2.9179916381835938
Validation loss: 2.6128194229577177

Epoch: 5| Step: 3
Training loss: 2.113246440887451
Validation loss: 2.62181277941632

Epoch: 5| Step: 4
Training loss: 2.557216167449951
Validation loss: 2.613704699341969

Epoch: 5| Step: 5
Training loss: 2.749302625656128
Validation loss: 2.609776326405105

Epoch: 5| Step: 6
Training loss: 2.8644182682037354
Validation loss: 2.5991669957355787

Epoch: 5| Step: 7
Training loss: 2.3393771648406982
Validation loss: 2.5929316115635697

Epoch: 5| Step: 8
Training loss: 3.1343371868133545
Validation loss: 2.5956282231115524

Epoch: 5| Step: 9
Training loss: 3.3960704803466797
Validation loss: 2.595771215295279

Epoch: 5| Step: 10
Training loss: 2.9973032474517822
Validation loss: 2.5984484508473384

Epoch: 68| Step: 0
Training loss: 2.9007675647735596
Validation loss: 2.595261714791739

Epoch: 5| Step: 1
Training loss: 2.985630512237549
Validation loss: 2.593102732012349

Epoch: 5| Step: 2
Training loss: 2.6234121322631836
Validation loss: 2.595856189727783

Epoch: 5| Step: 3
Training loss: 2.940955638885498
Validation loss: 2.5942709138316493

Epoch: 5| Step: 4
Training loss: 3.175132989883423
Validation loss: 2.5940184798291934

Epoch: 5| Step: 5
Training loss: 2.957897186279297
Validation loss: 2.59541154420504

Epoch: 5| Step: 6
Training loss: 2.76910400390625
Validation loss: 2.5970752213590886

Epoch: 5| Step: 7
Training loss: 2.4210362434387207
Validation loss: 2.600747980097289

Epoch: 5| Step: 8
Training loss: 2.6397876739501953
Validation loss: 2.6026942704313543

Epoch: 5| Step: 9
Training loss: 3.0650737285614014
Validation loss: 2.600185486578172

Epoch: 5| Step: 10
Training loss: 2.043546199798584
Validation loss: 2.590114975488314

Epoch: 69| Step: 0
Training loss: 3.5390937328338623
Validation loss: 2.587101400539439

Epoch: 5| Step: 1
Training loss: 2.05311918258667
Validation loss: 2.591481154964816

Epoch: 5| Step: 2
Training loss: 2.619875431060791
Validation loss: 2.5914433028108332

Epoch: 5| Step: 3
Training loss: 2.7327499389648438
Validation loss: 2.589902267661146

Epoch: 5| Step: 4
Training loss: 2.7777583599090576
Validation loss: 2.5911146748450493

Epoch: 5| Step: 5
Training loss: 2.53633975982666
Validation loss: 2.592394249413603

Epoch: 5| Step: 6
Training loss: 2.405643939971924
Validation loss: 2.5894601755244757

Epoch: 5| Step: 7
Training loss: 2.781785726547241
Validation loss: 2.5963464693356584

Epoch: 5| Step: 8
Training loss: 3.3218071460723877
Validation loss: 2.5962542641547417

Epoch: 5| Step: 9
Training loss: 2.9851858615875244
Validation loss: 2.5952374858240925

Epoch: 5| Step: 10
Training loss: 2.8572139739990234
Validation loss: 2.594775487017888

Epoch: 70| Step: 0
Training loss: 2.432310104370117
Validation loss: 2.5951799679827947

Epoch: 5| Step: 1
Training loss: 3.444608688354492
Validation loss: 2.5925054883444183

Epoch: 5| Step: 2
Training loss: 2.613452911376953
Validation loss: 2.5993582099996586

Epoch: 5| Step: 3
Training loss: 2.869440793991089
Validation loss: 2.597813767771567

Epoch: 5| Step: 4
Training loss: 2.806968927383423
Validation loss: 2.59601733761449

Epoch: 5| Step: 5
Training loss: 2.3428587913513184
Validation loss: 2.597492161617484

Epoch: 5| Step: 6
Training loss: 2.638235569000244
Validation loss: 2.593090118900422

Epoch: 5| Step: 7
Training loss: 2.9682018756866455
Validation loss: 2.5833605643241637

Epoch: 5| Step: 8
Training loss: 2.5600905418395996
Validation loss: 2.5829916948913247

Epoch: 5| Step: 9
Training loss: 3.9609291553497314
Validation loss: 2.5838233629862466

Epoch: 5| Step: 10
Training loss: 1.7376230955123901
Validation loss: 2.5818189959372244

Epoch: 71| Step: 0
Training loss: 3.3066813945770264
Validation loss: 2.5823548852756457

Epoch: 5| Step: 1
Training loss: 2.9037880897521973
Validation loss: 2.584008515522044

Epoch: 5| Step: 2
Training loss: 2.404358148574829
Validation loss: 2.587816789586057

Epoch: 5| Step: 3
Training loss: 3.2936408519744873
Validation loss: 2.5820001453481694

Epoch: 5| Step: 4
Training loss: 2.6969199180603027
Validation loss: 2.5896884984867548

Epoch: 5| Step: 5
Training loss: 3.1636080741882324
Validation loss: 2.6003328241327757

Epoch: 5| Step: 6
Training loss: 2.61503005027771
Validation loss: 2.6070883017714306

Epoch: 5| Step: 7
Training loss: 2.2648491859436035
Validation loss: 2.619024638206728

Epoch: 5| Step: 8
Training loss: 3.2533962726593018
Validation loss: 2.6062593203718945

Epoch: 5| Step: 9
Training loss: 2.237046480178833
Validation loss: 2.601424447951778

Epoch: 5| Step: 10
Training loss: 2.325251340866089
Validation loss: 2.6022659834995063

Epoch: 72| Step: 0
Training loss: 2.526737689971924
Validation loss: 2.605058470079976

Epoch: 5| Step: 1
Training loss: 2.9838180541992188
Validation loss: 2.6097588103304625

Epoch: 5| Step: 2
Training loss: 2.323881149291992
Validation loss: 2.621406375720937

Epoch: 5| Step: 3
Training loss: 2.375016450881958
Validation loss: 2.6246040303220033

Epoch: 5| Step: 4
Training loss: 2.714679718017578
Validation loss: 2.6120630028427287

Epoch: 5| Step: 5
Training loss: 3.070662021636963
Validation loss: 2.603272925141037

Epoch: 5| Step: 6
Training loss: 2.623898983001709
Validation loss: 2.5906027260647027

Epoch: 5| Step: 7
Training loss: 2.9761838912963867
Validation loss: 2.5836167566237913

Epoch: 5| Step: 8
Training loss: 3.2620983123779297
Validation loss: 2.576985231009863

Epoch: 5| Step: 9
Training loss: 2.2961156368255615
Validation loss: 2.5865351384685886

Epoch: 5| Step: 10
Training loss: 3.4984679222106934
Validation loss: 2.5883464454322733

Epoch: 73| Step: 0
Training loss: 2.924821138381958
Validation loss: 2.594833602187454

Epoch: 5| Step: 1
Training loss: 2.7703559398651123
Validation loss: 2.5961167376528502

Epoch: 5| Step: 2
Training loss: 2.2250075340270996
Validation loss: 2.5862666560757543

Epoch: 5| Step: 3
Training loss: 2.76460337638855
Validation loss: 2.5793655610853627

Epoch: 5| Step: 4
Training loss: 2.261798858642578
Validation loss: 2.58404476411881

Epoch: 5| Step: 5
Training loss: 2.2340073585510254
Validation loss: 2.5761282213272585

Epoch: 5| Step: 6
Training loss: 3.2119717597961426
Validation loss: 2.578091916217599

Epoch: 5| Step: 7
Training loss: 3.324737548828125
Validation loss: 2.5742654954233477

Epoch: 5| Step: 8
Training loss: 2.6531972885131836
Validation loss: 2.5751569424906084

Epoch: 5| Step: 9
Training loss: 2.8500561714172363
Validation loss: 2.5757420447564896

Epoch: 5| Step: 10
Training loss: 3.334707260131836
Validation loss: 2.578395034677239

Epoch: 74| Step: 0
Training loss: 2.6878254413604736
Validation loss: 2.592771050750568

Epoch: 5| Step: 1
Training loss: 3.026641607284546
Validation loss: 2.6155708092515186

Epoch: 5| Step: 2
Training loss: 2.708552598953247
Validation loss: 2.6224434068126063

Epoch: 5| Step: 3
Training loss: 3.620696544647217
Validation loss: 2.6319270967155375

Epoch: 5| Step: 4
Training loss: 2.2007484436035156
Validation loss: 2.634229152433334

Epoch: 5| Step: 5
Training loss: 2.7583730220794678
Validation loss: 2.613522491147441

Epoch: 5| Step: 6
Training loss: 2.552060604095459
Validation loss: 2.6001023528396443

Epoch: 5| Step: 7
Training loss: 2.9066877365112305
Validation loss: 2.5809648421502884

Epoch: 5| Step: 8
Training loss: 2.4635345935821533
Validation loss: 2.5720987140491443

Epoch: 5| Step: 9
Training loss: 2.1854209899902344
Validation loss: 2.5707010979293496

Epoch: 5| Step: 10
Training loss: 3.588935375213623
Validation loss: 2.576540193250102

Epoch: 75| Step: 0
Training loss: 3.11724591255188
Validation loss: 2.5735216012565036

Epoch: 5| Step: 1
Training loss: 2.5608980655670166
Validation loss: 2.574127366465907

Epoch: 5| Step: 2
Training loss: 2.7969911098480225
Validation loss: 2.579322473977202

Epoch: 5| Step: 3
Training loss: 3.3202834129333496
Validation loss: 2.576024763045772

Epoch: 5| Step: 4
Training loss: 2.1521518230438232
Validation loss: 2.5780606346745647

Epoch: 5| Step: 5
Training loss: 2.8803489208221436
Validation loss: 2.579239135147423

Epoch: 5| Step: 6
Training loss: 2.6679916381835938
Validation loss: 2.5807900480044785

Epoch: 5| Step: 7
Training loss: 2.7229671478271484
Validation loss: 2.5838170000301894

Epoch: 5| Step: 8
Training loss: 2.5071358680725098
Validation loss: 2.5858811511788318

Epoch: 5| Step: 9
Training loss: 2.820067882537842
Validation loss: 2.583937147612213

Epoch: 5| Step: 10
Training loss: 3.0158164501190186
Validation loss: 2.576999843761485

Epoch: 76| Step: 0
Training loss: 3.338235378265381
Validation loss: 2.575007461732434

Epoch: 5| Step: 1
Training loss: 2.708749294281006
Validation loss: 2.5776883094541487

Epoch: 5| Step: 2
Training loss: 2.5111680030822754
Validation loss: 2.5801766252004974

Epoch: 5| Step: 3
Training loss: 3.058887004852295
Validation loss: 2.5811450558324016

Epoch: 5| Step: 4
Training loss: 2.590430736541748
Validation loss: 2.5833803428116666

Epoch: 5| Step: 5
Training loss: 2.244518995285034
Validation loss: 2.5859802794712845

Epoch: 5| Step: 6
Training loss: 2.1285059452056885
Validation loss: 2.580943179386918

Epoch: 5| Step: 7
Training loss: 2.978113889694214
Validation loss: 2.5843640783781647

Epoch: 5| Step: 8
Training loss: 2.9219584465026855
Validation loss: 2.5791024033741285

Epoch: 5| Step: 9
Training loss: 2.735521078109741
Validation loss: 2.584004609815536

Epoch: 5| Step: 10
Training loss: 3.2158823013305664
Validation loss: 2.5780540050998813

Epoch: 77| Step: 0
Training loss: 2.5180249214172363
Validation loss: 2.5802934323587725

Epoch: 5| Step: 1
Training loss: 3.162487506866455
Validation loss: 2.5873519246296217

Epoch: 5| Step: 2
Training loss: 2.8907666206359863
Validation loss: 2.581739018040319

Epoch: 5| Step: 3
Training loss: 2.059601306915283
Validation loss: 2.572172946827386

Epoch: 5| Step: 4
Training loss: 2.9153218269348145
Validation loss: 2.5791325210243143

Epoch: 5| Step: 5
Training loss: 2.600588321685791
Validation loss: 2.5786286759120163

Epoch: 5| Step: 6
Training loss: 2.371903657913208
Validation loss: 2.5801152311345583

Epoch: 5| Step: 7
Training loss: 2.9762682914733887
Validation loss: 2.5693243703534527

Epoch: 5| Step: 8
Training loss: 3.363831043243408
Validation loss: 2.5764737744485178

Epoch: 5| Step: 9
Training loss: 3.2181873321533203
Validation loss: 2.5711608984137095

Epoch: 5| Step: 10
Training loss: 2.3145227432250977
Validation loss: 2.570757791560183

Epoch: 78| Step: 0
Training loss: 3.368748426437378
Validation loss: 2.5621597830967238

Epoch: 5| Step: 1
Training loss: 2.849417209625244
Validation loss: 2.5685260244595107

Epoch: 5| Step: 2
Training loss: 3.415069103240967
Validation loss: 2.5687949734349407

Epoch: 5| Step: 3
Training loss: 2.4594204425811768
Validation loss: 2.5650518683977026

Epoch: 5| Step: 4
Training loss: 1.7174774408340454
Validation loss: 2.5673878295447237

Epoch: 5| Step: 5
Training loss: 2.590907335281372
Validation loss: 2.5721739415199525

Epoch: 5| Step: 6
Training loss: 2.9834306240081787
Validation loss: 2.5738438560116674

Epoch: 5| Step: 7
Training loss: 2.2949442863464355
Validation loss: 2.58448705878309

Epoch: 5| Step: 8
Training loss: 3.340419292449951
Validation loss: 2.588699920203096

Epoch: 5| Step: 9
Training loss: 3.172905445098877
Validation loss: 2.585763177564067

Epoch: 5| Step: 10
Training loss: 2.046252965927124
Validation loss: 2.5961820207616335

Epoch: 79| Step: 0
Training loss: 2.763615846633911
Validation loss: 2.5865533556989444

Epoch: 5| Step: 1
Training loss: 2.006849765777588
Validation loss: 2.588015233316729

Epoch: 5| Step: 2
Training loss: 3.116835355758667
Validation loss: 2.5850457606777066

Epoch: 5| Step: 3
Training loss: 3.8332037925720215
Validation loss: 2.576156703374719

Epoch: 5| Step: 4
Training loss: 2.3608651161193848
Validation loss: 2.57303665273933

Epoch: 5| Step: 5
Training loss: 3.06331467628479
Validation loss: 2.562850708602577

Epoch: 5| Step: 6
Training loss: 2.2797932624816895
Validation loss: 2.5636682894922074

Epoch: 5| Step: 7
Training loss: 3.2424957752227783
Validation loss: 2.5615880335530927

Epoch: 5| Step: 8
Training loss: 1.8646628856658936
Validation loss: 2.566673460827079

Epoch: 5| Step: 9
Training loss: 2.767038345336914
Validation loss: 2.5584447383880615

Epoch: 5| Step: 10
Training loss: 2.9644031524658203
Validation loss: 2.5550979670657905

Epoch: 80| Step: 0
Training loss: 3.0982985496520996
Validation loss: 2.5556781958508235

Epoch: 5| Step: 1
Training loss: 3.0791208744049072
Validation loss: 2.5579310540230042

Epoch: 5| Step: 2
Training loss: 2.164884328842163
Validation loss: 2.5604609853477887

Epoch: 5| Step: 3
Training loss: 2.983747720718384
Validation loss: 2.559214325361354

Epoch: 5| Step: 4
Training loss: 2.3622190952301025
Validation loss: 2.5609391607264036

Epoch: 5| Step: 5
Training loss: 2.2866246700286865
Validation loss: 2.566670069130518

Epoch: 5| Step: 6
Training loss: 2.640913486480713
Validation loss: 2.5670450810463197

Epoch: 5| Step: 7
Training loss: 3.256992816925049
Validation loss: 2.570715388944072

Epoch: 5| Step: 8
Training loss: 3.5102601051330566
Validation loss: 2.5758245324575775

Epoch: 5| Step: 9
Training loss: 2.214367628097534
Validation loss: 2.5789401531219482

Epoch: 5| Step: 10
Training loss: 2.5292420387268066
Validation loss: 2.5821146811208417

Epoch: 81| Step: 0
Training loss: 2.174973726272583
Validation loss: 2.5735759863289456

Epoch: 5| Step: 1
Training loss: 3.2769699096679688
Validation loss: 2.5669278021781676

Epoch: 5| Step: 2
Training loss: 3.2212250232696533
Validation loss: 2.5632219724757697

Epoch: 5| Step: 3
Training loss: 2.6477320194244385
Validation loss: 2.5627616092722905

Epoch: 5| Step: 4
Training loss: 2.2036020755767822
Validation loss: 2.5539147161668345

Epoch: 5| Step: 5
Training loss: 3.703561782836914
Validation loss: 2.560892105102539

Epoch: 5| Step: 6
Training loss: 2.18336820602417
Validation loss: 2.556638240814209

Epoch: 5| Step: 7
Training loss: 3.034363031387329
Validation loss: 2.5579207276785247

Epoch: 5| Step: 8
Training loss: 3.1200084686279297
Validation loss: 2.555337377773818

Epoch: 5| Step: 9
Training loss: 2.469163656234741
Validation loss: 2.553388918599775

Epoch: 5| Step: 10
Training loss: 2.0310685634613037
Validation loss: 2.5474538956919024

Epoch: 82| Step: 0
Training loss: 3.1398298740386963
Validation loss: 2.554088600220219

Epoch: 5| Step: 1
Training loss: 2.4287047386169434
Validation loss: 2.557085193613524

Epoch: 5| Step: 2
Training loss: 3.7589492797851562
Validation loss: 2.5652059201271302

Epoch: 5| Step: 3
Training loss: 2.9917566776275635
Validation loss: 2.5719180901845298

Epoch: 5| Step: 4
Training loss: 2.836981773376465
Validation loss: 2.5743797902138

Epoch: 5| Step: 5
Training loss: 2.690321922302246
Validation loss: 2.592638005492508

Epoch: 5| Step: 6
Training loss: 2.2876405715942383
Validation loss: 2.587853265065019

Epoch: 5| Step: 7
Training loss: 2.3532462120056152
Validation loss: 2.5816669130838044

Epoch: 5| Step: 8
Training loss: 2.897636890411377
Validation loss: 2.5689354019780315

Epoch: 5| Step: 9
Training loss: 2.269460439682007
Validation loss: 2.5663173890882924

Epoch: 5| Step: 10
Training loss: 2.4328503608703613
Validation loss: 2.5626407207981234

Epoch: 83| Step: 0
Training loss: 3.1850697994232178
Validation loss: 2.563925304720479

Epoch: 5| Step: 1
Training loss: 2.5866305828094482
Validation loss: 2.57567863054173

Epoch: 5| Step: 2
Training loss: 2.5275039672851562
Validation loss: 2.5827645460764566

Epoch: 5| Step: 3
Training loss: 3.1088643074035645
Validation loss: 2.5757296162266887

Epoch: 5| Step: 4
Training loss: 2.3353404998779297
Validation loss: 2.5654580234199442

Epoch: 5| Step: 5
Training loss: 2.838829755783081
Validation loss: 2.560340904420422

Epoch: 5| Step: 6
Training loss: 3.16231632232666
Validation loss: 2.5623240778523106

Epoch: 5| Step: 7
Training loss: 2.529141426086426
Validation loss: 2.5586455124680714

Epoch: 5| Step: 8
Training loss: 3.2544631958007812
Validation loss: 2.5591148740501812

Epoch: 5| Step: 9
Training loss: 2.716789484024048
Validation loss: 2.558522096244238

Epoch: 5| Step: 10
Training loss: 1.8675018548965454
Validation loss: 2.555591283305999

Epoch: 84| Step: 0
Training loss: 2.5866708755493164
Validation loss: 2.5532072974789526

Epoch: 5| Step: 1
Training loss: 2.2689716815948486
Validation loss: 2.550994929446969

Epoch: 5| Step: 2
Training loss: 2.791196584701538
Validation loss: 2.552266067074191

Epoch: 5| Step: 3
Training loss: 3.5930893421173096
Validation loss: 2.5507414879337436

Epoch: 5| Step: 4
Training loss: 2.9803106784820557
Validation loss: 2.5520016326699206

Epoch: 5| Step: 5
Training loss: 1.9485927820205688
Validation loss: 2.549584663042458

Epoch: 5| Step: 6
Training loss: 2.8892970085144043
Validation loss: 2.5549564912755

Epoch: 5| Step: 7
Training loss: 2.045811414718628
Validation loss: 2.556170440489246

Epoch: 5| Step: 8
Training loss: 2.2903313636779785
Validation loss: 2.553393307552543

Epoch: 5| Step: 9
Training loss: 3.2214977741241455
Validation loss: 2.5587265517122004

Epoch: 5| Step: 10
Training loss: 3.5702648162841797
Validation loss: 2.563903018992434

Epoch: 85| Step: 0
Training loss: 2.930205821990967
Validation loss: 2.561735781290198

Epoch: 5| Step: 1
Training loss: 1.869368314743042
Validation loss: 2.5621263673228603

Epoch: 5| Step: 2
Training loss: 2.8652796745300293
Validation loss: 2.5604271709278064

Epoch: 5| Step: 3
Training loss: 2.859790086746216
Validation loss: 2.5541916893374537

Epoch: 5| Step: 4
Training loss: 3.8505802154541016
Validation loss: 2.562079260426183

Epoch: 5| Step: 5
Training loss: 2.8622050285339355
Validation loss: 2.5637447603287233

Epoch: 5| Step: 6
Training loss: 2.5273022651672363
Validation loss: 2.56071142483783

Epoch: 5| Step: 7
Training loss: 2.5528831481933594
Validation loss: 2.5604644001171155

Epoch: 5| Step: 8
Training loss: 2.088641405105591
Validation loss: 2.5655150105876308

Epoch: 5| Step: 9
Training loss: 2.5180954933166504
Validation loss: 2.560508102499029

Epoch: 5| Step: 10
Training loss: 3.1533658504486084
Validation loss: 2.5606035083852787

Epoch: 86| Step: 0
Training loss: 2.771897792816162
Validation loss: 2.5504593233908377

Epoch: 5| Step: 1
Training loss: 2.968468189239502
Validation loss: 2.5531151986891225

Epoch: 5| Step: 2
Training loss: 3.0190744400024414
Validation loss: 2.5456718911406813

Epoch: 5| Step: 3
Training loss: 2.753302574157715
Validation loss: 2.54468806071948

Epoch: 5| Step: 4
Training loss: 2.9706645011901855
Validation loss: 2.548520503505584

Epoch: 5| Step: 5
Training loss: 2.3852720260620117
Validation loss: 2.5450965973638717

Epoch: 5| Step: 6
Training loss: 2.463818311691284
Validation loss: 2.5560325294412594

Epoch: 5| Step: 7
Training loss: 3.0739877223968506
Validation loss: 2.5513355834509737

Epoch: 5| Step: 8
Training loss: 2.381972312927246
Validation loss: 2.5564116944548902

Epoch: 5| Step: 9
Training loss: 1.9864933490753174
Validation loss: 2.5449060445190756

Epoch: 5| Step: 10
Training loss: 3.3393375873565674
Validation loss: 2.549617334078717

Epoch: 87| Step: 0
Training loss: 2.1679630279541016
Validation loss: 2.54803664453568

Epoch: 5| Step: 1
Training loss: 2.8109068870544434
Validation loss: 2.550723329667122

Epoch: 5| Step: 2
Training loss: 2.871502637863159
Validation loss: 2.555175758177234

Epoch: 5| Step: 3
Training loss: 2.0596795082092285
Validation loss: 2.5567081410397767

Epoch: 5| Step: 4
Training loss: 2.5888235569000244
Validation loss: 2.560748533536029

Epoch: 5| Step: 5
Training loss: 2.8975038528442383
Validation loss: 2.555196803103211

Epoch: 5| Step: 6
Training loss: 2.7006099224090576
Validation loss: 2.552468107592675

Epoch: 5| Step: 7
Training loss: 3.038447618484497
Validation loss: 2.5542996698810208

Epoch: 5| Step: 8
Training loss: 2.8859424591064453
Validation loss: 2.5478660060513403

Epoch: 5| Step: 9
Training loss: 2.801205635070801
Validation loss: 2.5448306542570873

Epoch: 5| Step: 10
Training loss: 3.1234254837036133
Validation loss: 2.5462152240096882

Epoch: 88| Step: 0
Training loss: 2.511894464492798
Validation loss: 2.5494116736996557

Epoch: 5| Step: 1
Training loss: 2.990208148956299
Validation loss: 2.55124831199646

Epoch: 5| Step: 2
Training loss: 2.753016471862793
Validation loss: 2.5520243413986696

Epoch: 5| Step: 3
Training loss: 2.2207608222961426
Validation loss: 2.552020001155074

Epoch: 5| Step: 4
Training loss: 2.8822638988494873
Validation loss: 2.55344485211116

Epoch: 5| Step: 5
Training loss: 3.064657688140869
Validation loss: 2.555157592219691

Epoch: 5| Step: 6
Training loss: 2.383849859237671
Validation loss: 2.5572679324816634

Epoch: 5| Step: 7
Training loss: 2.8303444385528564
Validation loss: 2.549628947370796

Epoch: 5| Step: 8
Training loss: 3.3466708660125732
Validation loss: 2.5626540184020996

Epoch: 5| Step: 9
Training loss: 2.554150104522705
Validation loss: 2.5544304693898847

Epoch: 5| Step: 10
Training loss: 2.3893871307373047
Validation loss: 2.5498641639627437

Epoch: 89| Step: 0
Training loss: 2.361565351486206
Validation loss: 2.5494593497245543

Epoch: 5| Step: 1
Training loss: 2.9533138275146484
Validation loss: 2.5407343961859263

Epoch: 5| Step: 2
Training loss: 2.914092779159546
Validation loss: 2.5393313233570387

Epoch: 5| Step: 3
Training loss: 2.601733684539795
Validation loss: 2.5389859086723736

Epoch: 5| Step: 4
Training loss: 2.435210943222046
Validation loss: 2.5360544573876167

Epoch: 5| Step: 5
Training loss: 2.566561460494995
Validation loss: 2.533048450305898

Epoch: 5| Step: 6
Training loss: 3.1777939796447754
Validation loss: 2.5359501889956895

Epoch: 5| Step: 7
Training loss: 3.0868568420410156
Validation loss: 2.537693597937143

Epoch: 5| Step: 8
Training loss: 2.4493894577026367
Validation loss: 2.5373776510197628

Epoch: 5| Step: 9
Training loss: 2.931530237197876
Validation loss: 2.535928549305085

Epoch: 5| Step: 10
Training loss: 2.5065009593963623
Validation loss: 2.530413161041916

Epoch: 90| Step: 0
Training loss: 2.3273098468780518
Validation loss: 2.542030393436391

Epoch: 5| Step: 1
Training loss: 2.4429383277893066
Validation loss: 2.544505739724764

Epoch: 5| Step: 2
Training loss: 3.419956922531128
Validation loss: 2.5463621590727117

Epoch: 5| Step: 3
Training loss: 2.8854503631591797
Validation loss: 2.5515446637266423

Epoch: 5| Step: 4
Training loss: 2.4712235927581787
Validation loss: 2.5715657549519695

Epoch: 5| Step: 5
Training loss: 3.5198421478271484
Validation loss: 2.572306235631307

Epoch: 5| Step: 6
Training loss: 2.6726810932159424
Validation loss: 2.569623367760771

Epoch: 5| Step: 7
Training loss: 2.449800968170166
Validation loss: 2.5600809281872166

Epoch: 5| Step: 8
Training loss: 2.938575029373169
Validation loss: 2.558318389359341

Epoch: 5| Step: 9
Training loss: 2.2195076942443848
Validation loss: 2.5529253123908915

Epoch: 5| Step: 10
Training loss: 2.5697712898254395
Validation loss: 2.549366363915064

Epoch: 91| Step: 0
Training loss: 2.511054515838623
Validation loss: 2.5458068463110153

Epoch: 5| Step: 1
Training loss: 3.10296893119812
Validation loss: 2.536190399559595

Epoch: 5| Step: 2
Training loss: 2.592120409011841
Validation loss: 2.54437328410405

Epoch: 5| Step: 3
Training loss: 2.6471445560455322
Validation loss: 2.541156430398264

Epoch: 5| Step: 4
Training loss: 2.4482309818267822
Validation loss: 2.529818529723793

Epoch: 5| Step: 5
Training loss: 2.5601043701171875
Validation loss: 2.5381664101795485

Epoch: 5| Step: 6
Training loss: 3.0331740379333496
Validation loss: 2.535254613045723

Epoch: 5| Step: 7
Training loss: 2.8796660900115967
Validation loss: 2.550616705289451

Epoch: 5| Step: 8
Training loss: 3.0249240398406982
Validation loss: 2.568062569505425

Epoch: 5| Step: 9
Training loss: 2.2896981239318848
Validation loss: 2.5666978320767804

Epoch: 5| Step: 10
Training loss: 2.908404588699341
Validation loss: 2.5702685233085387

Epoch: 92| Step: 0
Training loss: 2.8374972343444824
Validation loss: 2.5743670873744513

Epoch: 5| Step: 1
Training loss: 2.6689743995666504
Validation loss: 2.556891200362995

Epoch: 5| Step: 2
Training loss: 2.1637978553771973
Validation loss: 2.572817264064666

Epoch: 5| Step: 3
Training loss: 2.466604232788086
Validation loss: 2.58442436879681

Epoch: 5| Step: 4
Training loss: 2.9926083087921143
Validation loss: 2.5876031844846663

Epoch: 5| Step: 5
Training loss: 2.742051601409912
Validation loss: 2.5872618485522527

Epoch: 5| Step: 6
Training loss: 2.990513563156128
Validation loss: 2.571573313846383

Epoch: 5| Step: 7
Training loss: 3.6439876556396484
Validation loss: 2.555733250033471

Epoch: 5| Step: 8
Training loss: 2.4441659450531006
Validation loss: 2.546550909678141

Epoch: 5| Step: 9
Training loss: 2.718985080718994
Validation loss: 2.5370432484534478

Epoch: 5| Step: 10
Training loss: 2.2585854530334473
Validation loss: 2.5340739014328166

Epoch: 93| Step: 0
Training loss: 2.4129796028137207
Validation loss: 2.5296106364137385

Epoch: 5| Step: 1
Training loss: 2.458850145339966
Validation loss: 2.5336672054824008

Epoch: 5| Step: 2
Training loss: 2.803738832473755
Validation loss: 2.534770988648938

Epoch: 5| Step: 3
Training loss: 2.8051950931549072
Validation loss: 2.5289332841032293

Epoch: 5| Step: 4
Training loss: 2.823878049850464
Validation loss: 2.5290359835470877

Epoch: 5| Step: 5
Training loss: 2.476945638656616
Validation loss: 2.5303879335362423

Epoch: 5| Step: 6
Training loss: 3.1077423095703125
Validation loss: 2.523299168514949

Epoch: 5| Step: 7
Training loss: 3.2737648487091064
Validation loss: 2.5293279360699397

Epoch: 5| Step: 8
Training loss: 2.784796714782715
Validation loss: 2.531148749013101

Epoch: 5| Step: 9
Training loss: 2.3891074657440186
Validation loss: 2.5325914403443694

Epoch: 5| Step: 10
Training loss: 2.5300402641296387
Validation loss: 2.5352534247982885

Epoch: 94| Step: 0
Training loss: 3.0165083408355713
Validation loss: 2.5352036440244285

Epoch: 5| Step: 1
Training loss: 3.041367530822754
Validation loss: 2.5437856745976273

Epoch: 5| Step: 2
Training loss: 2.8235912322998047
Validation loss: 2.5417610188966155

Epoch: 5| Step: 3
Training loss: 2.369555711746216
Validation loss: 2.5406621476655364

Epoch: 5| Step: 4
Training loss: 3.108185291290283
Validation loss: 2.544439305541336

Epoch: 5| Step: 5
Training loss: 2.2156386375427246
Validation loss: 2.548058899500037

Epoch: 5| Step: 6
Training loss: 2.6255087852478027
Validation loss: 2.546258641827491

Epoch: 5| Step: 7
Training loss: 2.1821465492248535
Validation loss: 2.535105546315511

Epoch: 5| Step: 8
Training loss: 3.314826250076294
Validation loss: 2.5382269736259215

Epoch: 5| Step: 9
Training loss: 1.9619722366333008
Validation loss: 2.529699784453197

Epoch: 5| Step: 10
Training loss: 3.306697130203247
Validation loss: 2.5328685416970202

Epoch: 95| Step: 0
Training loss: 2.2193405628204346
Validation loss: 2.5358832472114154

Epoch: 5| Step: 1
Training loss: 2.6012425422668457
Validation loss: 2.5534318749622633

Epoch: 5| Step: 2
Training loss: 3.1580252647399902
Validation loss: 2.57945401694185

Epoch: 5| Step: 3
Training loss: 2.6391983032226562
Validation loss: 2.6051227559325514

Epoch: 5| Step: 4
Training loss: 2.711740016937256
Validation loss: 2.5898363615876887

Epoch: 5| Step: 5
Training loss: 2.186717987060547
Validation loss: 2.5773323094973

Epoch: 5| Step: 6
Training loss: 2.569108247756958
Validation loss: 2.5715060439161075

Epoch: 5| Step: 7
Training loss: 2.3888957500457764
Validation loss: 2.5645054527508315

Epoch: 5| Step: 8
Training loss: 4.330426216125488
Validation loss: 2.5484347702354513

Epoch: 5| Step: 9
Training loss: 2.8320021629333496
Validation loss: 2.5440485605629544

Epoch: 5| Step: 10
Training loss: 2.3490102291107178
Validation loss: 2.5287655809874177

Epoch: 96| Step: 0
Training loss: 2.610647201538086
Validation loss: 2.533541433272823

Epoch: 5| Step: 1
Training loss: 2.9553513526916504
Validation loss: 2.5347522099812827

Epoch: 5| Step: 2
Training loss: 3.4429633617401123
Validation loss: 2.552830519214753

Epoch: 5| Step: 3
Training loss: 2.504621982574463
Validation loss: 2.5661392019641016

Epoch: 5| Step: 4
Training loss: 3.0410313606262207
Validation loss: 2.558633629993726

Epoch: 5| Step: 5
Training loss: 2.252242088317871
Validation loss: 2.560785203851679

Epoch: 5| Step: 6
Training loss: 2.5435290336608887
Validation loss: 2.5678421605017876

Epoch: 5| Step: 7
Training loss: 2.6999049186706543
Validation loss: 2.546887669512021

Epoch: 5| Step: 8
Training loss: 2.703002452850342
Validation loss: 2.533785258570025

Epoch: 5| Step: 9
Training loss: 2.784489154815674
Validation loss: 2.534853007203789

Epoch: 5| Step: 10
Training loss: 2.497560501098633
Validation loss: 2.5288074862572456

Epoch: 97| Step: 0
Training loss: 2.8683319091796875
Validation loss: 2.52348147156418

Epoch: 5| Step: 1
Training loss: 2.1546661853790283
Validation loss: 2.526778595421904

Epoch: 5| Step: 2
Training loss: 2.7711987495422363
Validation loss: 2.5261972104349444

Epoch: 5| Step: 3
Training loss: 2.6877856254577637
Validation loss: 2.5292983414024435

Epoch: 5| Step: 4
Training loss: 2.257136344909668
Validation loss: 2.5267814987449237

Epoch: 5| Step: 5
Training loss: 2.7487285137176514
Validation loss: 2.5247815039850052

Epoch: 5| Step: 6
Training loss: 2.37579083442688
Validation loss: 2.5234459010503625

Epoch: 5| Step: 7
Training loss: 3.1985387802124023
Validation loss: 2.5277773282861196

Epoch: 5| Step: 8
Training loss: 3.1511828899383545
Validation loss: 2.5402390803060224

Epoch: 5| Step: 9
Training loss: 2.8982510566711426
Validation loss: 2.5363654167421403

Epoch: 5| Step: 10
Training loss: 2.731299877166748
Validation loss: 2.5241637306828655

Epoch: 98| Step: 0
Training loss: 2.8419711589813232
Validation loss: 2.525724308465117

Epoch: 5| Step: 1
Training loss: 2.929461717605591
Validation loss: 2.5283637777451546

Epoch: 5| Step: 2
Training loss: 3.0592546463012695
Validation loss: 2.5252348966495965

Epoch: 5| Step: 3
Training loss: 3.3781096935272217
Validation loss: 2.524725683273808

Epoch: 5| Step: 4
Training loss: 1.994391679763794
Validation loss: 2.529175848089239

Epoch: 5| Step: 5
Training loss: 2.4164230823516846
Validation loss: 2.5301453451956473

Epoch: 5| Step: 6
Training loss: 2.6485190391540527
Validation loss: 2.5357249962386263

Epoch: 5| Step: 7
Training loss: 2.5290989875793457
Validation loss: 2.5348935101621892

Epoch: 5| Step: 8
Training loss: 2.33122181892395
Validation loss: 2.5388295650482178

Epoch: 5| Step: 9
Training loss: 2.7209486961364746
Validation loss: 2.547880664948494

Epoch: 5| Step: 10
Training loss: 2.9816341400146484
Validation loss: 2.553950048262073

Epoch: 99| Step: 0
Training loss: 3.124642848968506
Validation loss: 2.558517776509767

Epoch: 5| Step: 1
Training loss: 2.0882112979888916
Validation loss: 2.566578193377423

Epoch: 5| Step: 2
Training loss: 3.3165957927703857
Validation loss: 2.5783731450316725

Epoch: 5| Step: 3
Training loss: 2.4968066215515137
Validation loss: 2.5445158225233837

Epoch: 5| Step: 4
Training loss: 1.837697982788086
Validation loss: 2.540246107245004

Epoch: 5| Step: 5
Training loss: 2.7346277236938477
Validation loss: 2.5384388662153676

Epoch: 5| Step: 6
Training loss: 2.566455125808716
Validation loss: 2.53303482455592

Epoch: 5| Step: 7
Training loss: 3.4578697681427
Validation loss: 2.527530698366063

Epoch: 5| Step: 8
Training loss: 2.6502811908721924
Validation loss: 2.527143463011711

Epoch: 5| Step: 9
Training loss: 2.970458507537842
Validation loss: 2.5260330989796627

Epoch: 5| Step: 10
Training loss: 2.380770444869995
Validation loss: 2.525311957123459

Epoch: 100| Step: 0
Training loss: 2.5151877403259277
Validation loss: 2.5285675961484193

Epoch: 5| Step: 1
Training loss: 3.1564860343933105
Validation loss: 2.539715423378893

Epoch: 5| Step: 2
Training loss: 2.875915288925171
Validation loss: 2.5315006573994956

Epoch: 5| Step: 3
Training loss: 2.0490872859954834
Validation loss: 2.5375786930002193

Epoch: 5| Step: 4
Training loss: 2.473614454269409
Validation loss: 2.5341252947366364

Epoch: 5| Step: 5
Training loss: 2.638866901397705
Validation loss: 2.539479440258395

Epoch: 5| Step: 6
Training loss: 2.7496161460876465
Validation loss: 2.532407517074257

Epoch: 5| Step: 7
Training loss: 2.7040278911590576
Validation loss: 2.528626298391691

Epoch: 5| Step: 8
Training loss: 3.0478615760803223
Validation loss: 2.5356059664039203

Epoch: 5| Step: 9
Training loss: 2.7238047122955322
Validation loss: 2.539966347397015

Epoch: 5| Step: 10
Training loss: 2.722230911254883
Validation loss: 2.5347173265231553

Epoch: 101| Step: 0
Training loss: 2.860192060470581
Validation loss: 2.5430882848719114

Epoch: 5| Step: 1
Training loss: 2.697936773300171
Validation loss: 2.543033371689499

Epoch: 5| Step: 2
Training loss: 3.3840014934539795
Validation loss: 2.5485034783681235

Epoch: 5| Step: 3
Training loss: 2.5583882331848145
Validation loss: 2.550906942736718

Epoch: 5| Step: 4
Training loss: 1.9413478374481201
Validation loss: 2.5531308907334522

Epoch: 5| Step: 5
Training loss: 2.3666837215423584
Validation loss: 2.55696718154415

Epoch: 5| Step: 6
Training loss: 3.1658084392547607
Validation loss: 2.5492341415856474

Epoch: 5| Step: 7
Training loss: 2.907928705215454
Validation loss: 2.5520190064625075

Epoch: 5| Step: 8
Training loss: 2.6422951221466064
Validation loss: 2.551245766301309

Epoch: 5| Step: 9
Training loss: 2.4880075454711914
Validation loss: 2.54469330592822

Epoch: 5| Step: 10
Training loss: 2.6107544898986816
Validation loss: 2.530732818829116

Epoch: 102| Step: 0
Training loss: 2.7242090702056885
Validation loss: 2.5321649659064507

Epoch: 5| Step: 1
Training loss: 2.4912655353546143
Validation loss: 2.530005775472169

Epoch: 5| Step: 2
Training loss: 2.95076060295105
Validation loss: 2.5265185217703543

Epoch: 5| Step: 3
Training loss: 2.703585624694824
Validation loss: 2.5248780891459477

Epoch: 5| Step: 4
Training loss: 3.306687593460083
Validation loss: 2.525776691334222

Epoch: 5| Step: 5
Training loss: 2.989619016647339
Validation loss: 2.5188785624760452

Epoch: 5| Step: 6
Training loss: 2.33133602142334
Validation loss: 2.516652548184959

Epoch: 5| Step: 7
Training loss: 2.5923423767089844
Validation loss: 2.5235409070086736

Epoch: 5| Step: 8
Training loss: 2.1091885566711426
Validation loss: 2.5183903222442954

Epoch: 5| Step: 9
Training loss: 2.839526891708374
Validation loss: 2.5209452670107604

Epoch: 5| Step: 10
Training loss: 2.711435317993164
Validation loss: 2.5232300989089476

Epoch: 103| Step: 0
Training loss: 2.453463315963745
Validation loss: 2.5276381892542683

Epoch: 5| Step: 1
Training loss: 2.770611524581909
Validation loss: 2.5236203209046395

Epoch: 5| Step: 2
Training loss: 2.7397494316101074
Validation loss: 2.525715794614566

Epoch: 5| Step: 3
Training loss: 2.6453309059143066
Validation loss: 2.5175957833566973

Epoch: 5| Step: 4
Training loss: 2.763140916824341
Validation loss: 2.527724632652857

Epoch: 5| Step: 5
Training loss: 2.4924731254577637
Validation loss: 2.5251391613355247

Epoch: 5| Step: 6
Training loss: 2.884148120880127
Validation loss: 2.5261619731944096

Epoch: 5| Step: 7
Training loss: 2.9613699913024902
Validation loss: 2.5278184080636628

Epoch: 5| Step: 8
Training loss: 2.759361982345581
Validation loss: 2.52646122183851

Epoch: 5| Step: 9
Training loss: 2.7619223594665527
Validation loss: 2.5197933245730657

Epoch: 5| Step: 10
Training loss: 2.478097915649414
Validation loss: 2.5239368407957015

Epoch: 104| Step: 0
Training loss: 2.2544853687286377
Validation loss: 2.522907680080783

Epoch: 5| Step: 1
Training loss: 2.6053478717803955
Validation loss: 2.5249564698947373

Epoch: 5| Step: 2
Training loss: 3.0065102577209473
Validation loss: 2.5301247027612503

Epoch: 5| Step: 3
Training loss: 3.0818722248077393
Validation loss: 2.5187070702993744

Epoch: 5| Step: 4
Training loss: 2.4439964294433594
Validation loss: 2.520063054177069

Epoch: 5| Step: 5
Training loss: 1.938985824584961
Validation loss: 2.5187236160360356

Epoch: 5| Step: 6
Training loss: 3.6102821826934814
Validation loss: 2.511859063179262

Epoch: 5| Step: 7
Training loss: 2.0839931964874268
Validation loss: 2.5142560312824864

Epoch: 5| Step: 8
Training loss: 3.222963333129883
Validation loss: 2.520898372896256

Epoch: 5| Step: 9
Training loss: 2.5797972679138184
Validation loss: 2.5163998706366426

Epoch: 5| Step: 10
Training loss: 2.833944797515869
Validation loss: 2.5143048071092173

Epoch: 105| Step: 0
Training loss: 3.310229778289795
Validation loss: 2.5146197990704606

Epoch: 5| Step: 1
Training loss: 2.5049519538879395
Validation loss: 2.5163378894969983

Epoch: 5| Step: 2
Training loss: 3.4318604469299316
Validation loss: 2.529765098325668

Epoch: 5| Step: 3
Training loss: 2.84871506690979
Validation loss: 2.528960858621905

Epoch: 5| Step: 4
Training loss: 2.958077907562256
Validation loss: 2.533982697353568

Epoch: 5| Step: 5
Training loss: 2.837974786758423
Validation loss: 2.5190091286936114

Epoch: 5| Step: 6
Training loss: 2.470839738845825
Validation loss: 2.5165787307165

Epoch: 5| Step: 7
Training loss: 2.8228416442871094
Validation loss: 2.5190678693914927

Epoch: 5| Step: 8
Training loss: 2.1897616386413574
Validation loss: 2.521041429170998

Epoch: 5| Step: 9
Training loss: 2.3539485931396484
Validation loss: 2.5200585178149644

Epoch: 5| Step: 10
Training loss: 1.79103422164917
Validation loss: 2.5246343510125273

Epoch: 106| Step: 0
Training loss: 2.7143146991729736
Validation loss: 2.5223203653930337

Epoch: 5| Step: 1
Training loss: 2.6611602306365967
Validation loss: 2.523170327627531

Epoch: 5| Step: 2
Training loss: 2.185152769088745
Validation loss: 2.516434015766267

Epoch: 5| Step: 3
Training loss: 2.6275582313537598
Validation loss: 2.5273574142045874

Epoch: 5| Step: 4
Training loss: 2.4194376468658447
Validation loss: 2.5171727493245113

Epoch: 5| Step: 5
Training loss: 3.4539928436279297
Validation loss: 2.5105384293422905

Epoch: 5| Step: 6
Training loss: 2.2460432052612305
Validation loss: 2.5170356406960437

Epoch: 5| Step: 7
Training loss: 2.9097676277160645
Validation loss: 2.5127606750816427

Epoch: 5| Step: 8
Training loss: 2.7543020248413086
Validation loss: 2.5155863146628104

Epoch: 5| Step: 9
Training loss: 3.0207648277282715
Validation loss: 2.516221761703491

Epoch: 5| Step: 10
Training loss: 2.595242977142334
Validation loss: 2.5174384476036153

Epoch: 107| Step: 0
Training loss: 2.817079782485962
Validation loss: 2.5169755899777977

Epoch: 5| Step: 1
Training loss: 2.6305084228515625
Validation loss: 2.5182975902352283

Epoch: 5| Step: 2
Training loss: 2.5150442123413086
Validation loss: 2.510290438129056

Epoch: 5| Step: 3
Training loss: 2.291511058807373
Validation loss: 2.5148647087876514

Epoch: 5| Step: 4
Training loss: 2.8425047397613525
Validation loss: 2.5094079843131443

Epoch: 5| Step: 5
Training loss: 2.6333587169647217
Validation loss: 2.5122276659934752

Epoch: 5| Step: 6
Training loss: 3.017080307006836
Validation loss: 2.511695187578919

Epoch: 5| Step: 7
Training loss: 3.3994743824005127
Validation loss: 2.5098936403951337

Epoch: 5| Step: 8
Training loss: 2.193897008895874
Validation loss: 2.514116325686055

Epoch: 5| Step: 9
Training loss: 3.067793607711792
Validation loss: 2.5118585350692912

Epoch: 5| Step: 10
Training loss: 1.9691945314407349
Validation loss: 2.5177472381181616

Epoch: 108| Step: 0
Training loss: 2.6294662952423096
Validation loss: 2.5219501859398297

Epoch: 5| Step: 1
Training loss: 2.511225938796997
Validation loss: 2.5189463348798853

Epoch: 5| Step: 2
Training loss: 2.2750542163848877
Validation loss: 2.541172881280222

Epoch: 5| Step: 3
Training loss: 3.279750108718872
Validation loss: 2.541741991555819

Epoch: 5| Step: 4
Training loss: 2.8626205921173096
Validation loss: 2.536589371260776

Epoch: 5| Step: 5
Training loss: 2.773933172225952
Validation loss: 2.5303335830729496

Epoch: 5| Step: 6
Training loss: 2.549578905105591
Validation loss: 2.528726908468431

Epoch: 5| Step: 7
Training loss: 2.742827892303467
Validation loss: 2.523789798059771

Epoch: 5| Step: 8
Training loss: 2.7659459114074707
Validation loss: 2.5265681615439792

Epoch: 5| Step: 9
Training loss: 2.0046603679656982
Validation loss: 2.516121397736252

Epoch: 5| Step: 10
Training loss: 3.2102158069610596
Validation loss: 2.51631990555794

Epoch: 109| Step: 0
Training loss: 2.972027540206909
Validation loss: 2.505915444384339

Epoch: 5| Step: 1
Training loss: 3.294113874435425
Validation loss: 2.50793106068847

Epoch: 5| Step: 2
Training loss: 2.5409739017486572
Validation loss: 2.503868987483363

Epoch: 5| Step: 3
Training loss: 2.692338228225708
Validation loss: 2.5030492582628803

Epoch: 5| Step: 4
Training loss: 2.78820538520813
Validation loss: 2.5124383741809475

Epoch: 5| Step: 5
Training loss: 2.867581605911255
Validation loss: 2.5141065966698433

Epoch: 5| Step: 6
Training loss: 2.432699203491211
Validation loss: 2.5156167348225913

Epoch: 5| Step: 7
Training loss: 2.569270610809326
Validation loss: 2.528920445390927

Epoch: 5| Step: 8
Training loss: 2.4407622814178467
Validation loss: 2.538899747274255

Epoch: 5| Step: 9
Training loss: 2.37988543510437
Validation loss: 2.5389807967729467

Epoch: 5| Step: 10
Training loss: 2.6021437644958496
Validation loss: 2.538944213621078

Epoch: 110| Step: 0
Training loss: 2.692692995071411
Validation loss: 2.5372639292029926

Epoch: 5| Step: 1
Training loss: 1.48414945602417
Validation loss: 2.544746602735212

Epoch: 5| Step: 2
Training loss: 2.4926645755767822
Validation loss: 2.5452958768413914

Epoch: 5| Step: 3
Training loss: 3.039522647857666
Validation loss: 2.5338695151831514

Epoch: 5| Step: 4
Training loss: 2.95735502243042
Validation loss: 2.540293647396949

Epoch: 5| Step: 5
Training loss: 2.316588878631592
Validation loss: 2.5402665086971816

Epoch: 5| Step: 6
Training loss: 3.5096020698547363
Validation loss: 2.5378789645369335

Epoch: 5| Step: 7
Training loss: 2.9090328216552734
Validation loss: 2.5374878119396906

Epoch: 5| Step: 8
Training loss: 2.909144401550293
Validation loss: 2.528455562489007

Epoch: 5| Step: 9
Training loss: 2.51507568359375
Validation loss: 2.511998645720943

Epoch: 5| Step: 10
Training loss: 2.660005569458008
Validation loss: 2.5155316373353362

Epoch: 111| Step: 0
Training loss: 3.0471818447113037
Validation loss: 2.5017516382278933

Epoch: 5| Step: 1
Training loss: 2.9138221740722656
Validation loss: 2.5028274879660657

Epoch: 5| Step: 2
Training loss: 2.394113063812256
Validation loss: 2.5013786054426626

Epoch: 5| Step: 3
Training loss: 2.3482720851898193
Validation loss: 2.5040062524939097

Epoch: 5| Step: 4
Training loss: 2.9929702281951904
Validation loss: 2.4999087318297355

Epoch: 5| Step: 5
Training loss: 2.201378583908081
Validation loss: 2.501868078785558

Epoch: 5| Step: 6
Training loss: 2.7214243412017822
Validation loss: 2.4979434397912796

Epoch: 5| Step: 7
Training loss: 2.406175136566162
Validation loss: 2.5014110636967484

Epoch: 5| Step: 8
Training loss: 2.5864343643188477
Validation loss: 2.4944656689961753

Epoch: 5| Step: 9
Training loss: 3.240973949432373
Validation loss: 2.4974498902597735

Epoch: 5| Step: 10
Training loss: 2.813220262527466
Validation loss: 2.501106100697671

Epoch: 112| Step: 0
Training loss: 3.1736693382263184
Validation loss: 2.5020538812042563

Epoch: 5| Step: 1
Training loss: 1.6369493007659912
Validation loss: 2.49692157647943

Epoch: 5| Step: 2
Training loss: 2.6406495571136475
Validation loss: 2.5050079027811685

Epoch: 5| Step: 3
Training loss: 2.6701340675354004
Validation loss: 2.5068389805414344

Epoch: 5| Step: 4
Training loss: 3.0410027503967285
Validation loss: 2.5137355609606673

Epoch: 5| Step: 5
Training loss: 2.8546485900878906
Validation loss: 2.518879093149657

Epoch: 5| Step: 6
Training loss: 2.636204957962036
Validation loss: 2.5179543930997133

Epoch: 5| Step: 7
Training loss: 2.768079996109009
Validation loss: 2.529992845750624

Epoch: 5| Step: 8
Training loss: 3.1335184574127197
Validation loss: 2.5275814225596767

Epoch: 5| Step: 9
Training loss: 2.441072463989258
Validation loss: 2.5322623919415217

Epoch: 5| Step: 10
Training loss: 2.4744105339050293
Validation loss: 2.5279170954099266

Epoch: 113| Step: 0
Training loss: 3.357008457183838
Validation loss: 2.5241820068769556

Epoch: 5| Step: 1
Training loss: 2.1037540435791016
Validation loss: 2.5270184675852456

Epoch: 5| Step: 2
Training loss: 2.7595369815826416
Validation loss: 2.522565039255286

Epoch: 5| Step: 3
Training loss: 2.147761821746826
Validation loss: 2.5256786730981644

Epoch: 5| Step: 4
Training loss: 2.867149829864502
Validation loss: 2.5304784851689495

Epoch: 5| Step: 5
Training loss: 2.4750428199768066
Validation loss: 2.5187633434931436

Epoch: 5| Step: 6
Training loss: 2.977781295776367
Validation loss: 2.519689272808772

Epoch: 5| Step: 7
Training loss: 2.389547348022461
Validation loss: 2.517863347966184

Epoch: 5| Step: 8
Training loss: 2.5811870098114014
Validation loss: 2.5090038622579267

Epoch: 5| Step: 9
Training loss: 2.6739697456359863
Validation loss: 2.518000392503636

Epoch: 5| Step: 10
Training loss: 3.109711170196533
Validation loss: 2.5129588137390795

Epoch: 114| Step: 0
Training loss: 2.2590084075927734
Validation loss: 2.51778721040295

Epoch: 5| Step: 1
Training loss: 2.4532887935638428
Validation loss: 2.5141541060581

Epoch: 5| Step: 2
Training loss: 2.893611431121826
Validation loss: 2.5160406866381244

Epoch: 5| Step: 3
Training loss: 2.5171332359313965
Validation loss: 2.50385727677294

Epoch: 5| Step: 4
Training loss: 3.0084497928619385
Validation loss: 2.507682666983656

Epoch: 5| Step: 5
Training loss: 2.6189403533935547
Validation loss: 2.5158120816753757

Epoch: 5| Step: 6
Training loss: 2.4675495624542236
Validation loss: 2.51395845413208

Epoch: 5| Step: 7
Training loss: 2.3508076667785645
Validation loss: 2.520686795634608

Epoch: 5| Step: 8
Training loss: 3.604762554168701
Validation loss: 2.523565310303883

Epoch: 5| Step: 9
Training loss: 2.6694138050079346
Validation loss: 2.5110433716927805

Epoch: 5| Step: 10
Training loss: 2.614938735961914
Validation loss: 2.5108395032985236

Epoch: 115| Step: 0
Training loss: 2.6506712436676025
Validation loss: 2.5114270461502897

Epoch: 5| Step: 1
Training loss: 2.9938931465148926
Validation loss: 2.5112277436000046

Epoch: 5| Step: 2
Training loss: 2.1004886627197266
Validation loss: 2.5119715095848165

Epoch: 5| Step: 3
Training loss: 2.7497804164886475
Validation loss: 2.5150273333313646

Epoch: 5| Step: 4
Training loss: 2.254558801651001
Validation loss: 2.5148002204074653

Epoch: 5| Step: 5
Training loss: 3.156252384185791
Validation loss: 2.5184485245776433

Epoch: 5| Step: 6
Training loss: 2.193803310394287
Validation loss: 2.513606879018968

Epoch: 5| Step: 7
Training loss: 2.766292095184326
Validation loss: 2.5203494820543515

Epoch: 5| Step: 8
Training loss: 2.5983710289001465
Validation loss: 2.520038225317514

Epoch: 5| Step: 9
Training loss: 2.81355357170105
Validation loss: 2.5177851902541293

Epoch: 5| Step: 10
Training loss: 3.122540235519409
Validation loss: 2.513777158593619

Epoch: 116| Step: 0
Training loss: 3.062509059906006
Validation loss: 2.511277409010036

Epoch: 5| Step: 1
Training loss: 2.7635703086853027
Validation loss: 2.5043124280950075

Epoch: 5| Step: 2
Training loss: 3.4116082191467285
Validation loss: 2.503940725839266

Epoch: 5| Step: 3
Training loss: 2.561561107635498
Validation loss: 2.5027598565624607

Epoch: 5| Step: 4
Training loss: 2.6923413276672363
Validation loss: 2.4941758160950034

Epoch: 5| Step: 5
Training loss: 2.678978681564331
Validation loss: 2.4951682013850056

Epoch: 5| Step: 6
Training loss: 2.4967262744903564
Validation loss: 2.4877691012556835

Epoch: 5| Step: 7
Training loss: 2.604005813598633
Validation loss: 2.4907605263494674

Epoch: 5| Step: 8
Training loss: 2.238793134689331
Validation loss: 2.4919067813504125

Epoch: 5| Step: 9
Training loss: 2.5485541820526123
Validation loss: 2.4963216473979335

Epoch: 5| Step: 10
Training loss: 2.3127193450927734
Validation loss: 2.497177795697284

Epoch: 117| Step: 0
Training loss: 3.0127780437469482
Validation loss: 2.504368838443551

Epoch: 5| Step: 1
Training loss: 1.9651683568954468
Validation loss: 2.5057337130269697

Epoch: 5| Step: 2
Training loss: 2.6808524131774902
Validation loss: 2.508626271319646

Epoch: 5| Step: 3
Training loss: 3.2783820629119873
Validation loss: 2.512194105373916

Epoch: 5| Step: 4
Training loss: 3.2472572326660156
Validation loss: 2.515613353380593

Epoch: 5| Step: 5
Training loss: 3.0715835094451904
Validation loss: 2.5209413087496193

Epoch: 5| Step: 6
Training loss: 2.2703919410705566
Validation loss: 2.5162087332817817

Epoch: 5| Step: 7
Training loss: 2.9071333408355713
Validation loss: 2.5125013500131588

Epoch: 5| Step: 8
Training loss: 2.1159229278564453
Validation loss: 2.5287250677744546

Epoch: 5| Step: 9
Training loss: 2.3184568881988525
Validation loss: 2.5271021422519477

Epoch: 5| Step: 10
Training loss: 2.394597053527832
Validation loss: 2.5282265960529284

Epoch: 118| Step: 0
Training loss: 3.2615370750427246
Validation loss: 2.54177604183074

Epoch: 5| Step: 1
Training loss: 2.96207857131958
Validation loss: 2.5365378446476434

Epoch: 5| Step: 2
Training loss: 2.1502814292907715
Validation loss: 2.5301612730949157

Epoch: 5| Step: 3
Training loss: 2.2595527172088623
Validation loss: 2.5321393397546585

Epoch: 5| Step: 4
Training loss: 3.0829920768737793
Validation loss: 2.5291369909881265

Epoch: 5| Step: 5
Training loss: 2.440967082977295
Validation loss: 2.5257872048244683

Epoch: 5| Step: 6
Training loss: 2.6109414100646973
Validation loss: 2.5292407671610513

Epoch: 5| Step: 7
Training loss: 2.4799399375915527
Validation loss: 2.521451089971809

Epoch: 5| Step: 8
Training loss: 2.5833845138549805
Validation loss: 2.509571865040769

Epoch: 5| Step: 9
Training loss: 2.5293402671813965
Validation loss: 2.5050424606569353

Epoch: 5| Step: 10
Training loss: 3.0892562866210938
Validation loss: 2.506804022737729

Epoch: 119| Step: 0
Training loss: 2.9230005741119385
Validation loss: 2.505749015397923

Epoch: 5| Step: 1
Training loss: 3.440317153930664
Validation loss: 2.509670970260456

Epoch: 5| Step: 2
Training loss: 2.1629302501678467
Validation loss: 2.5105721309620845

Epoch: 5| Step: 3
Training loss: 2.4982171058654785
Validation loss: 2.520922745427778

Epoch: 5| Step: 4
Training loss: 2.8695309162139893
Validation loss: 2.5170730429310955

Epoch: 5| Step: 5
Training loss: 2.2032930850982666
Validation loss: 2.5098534886555006

Epoch: 5| Step: 6
Training loss: 3.117652177810669
Validation loss: 2.5140207044539915

Epoch: 5| Step: 7
Training loss: 2.930650472640991
Validation loss: 2.4995767993311726

Epoch: 5| Step: 8
Training loss: 2.046926259994507
Validation loss: 2.4971127997162523

Epoch: 5| Step: 9
Training loss: 2.7096107006073
Validation loss: 2.492095890865531

Epoch: 5| Step: 10
Training loss: 2.584977388381958
Validation loss: 2.4931377698016424

Epoch: 120| Step: 0
Training loss: 2.939434289932251
Validation loss: 2.498382153049592

Epoch: 5| Step: 1
Training loss: 2.981607675552368
Validation loss: 2.4944528956567087

Epoch: 5| Step: 2
Training loss: 2.98382830619812
Validation loss: 2.502227226893107

Epoch: 5| Step: 3
Training loss: 2.7962708473205566
Validation loss: 2.500247081120809

Epoch: 5| Step: 4
Training loss: 2.2730774879455566
Validation loss: 2.503095878067837

Epoch: 5| Step: 5
Training loss: 2.6696391105651855
Validation loss: 2.501807948594452

Epoch: 5| Step: 6
Training loss: 2.964186191558838
Validation loss: 2.5101903023258334

Epoch: 5| Step: 7
Training loss: 2.5614285469055176
Validation loss: 2.504263613813667

Epoch: 5| Step: 8
Training loss: 2.0975182056427
Validation loss: 2.513212493670884

Epoch: 5| Step: 9
Training loss: 2.779087781906128
Validation loss: 2.514055564839353

Epoch: 5| Step: 10
Training loss: 2.350259780883789
Validation loss: 2.5121117971276723

Epoch: 121| Step: 0
Training loss: 2.5776190757751465
Validation loss: 2.506494904077181

Epoch: 5| Step: 1
Training loss: 2.7258429527282715
Validation loss: 2.4992780249605895

Epoch: 5| Step: 2
Training loss: 2.3010056018829346
Validation loss: 2.505272590985862

Epoch: 5| Step: 3
Training loss: 2.6082115173339844
Validation loss: 2.504462913800311

Epoch: 5| Step: 4
Training loss: 2.954834222793579
Validation loss: 2.5104312050727104

Epoch: 5| Step: 5
Training loss: 2.6500630378723145
Validation loss: 2.5043284636671825

Epoch: 5| Step: 6
Training loss: 2.8330345153808594
Validation loss: 2.5094099416527698

Epoch: 5| Step: 7
Training loss: 2.703254461288452
Validation loss: 2.5025291468507502

Epoch: 5| Step: 8
Training loss: 3.070237159729004
Validation loss: 2.5004841742977018

Epoch: 5| Step: 9
Training loss: 2.29496431350708
Validation loss: 2.501127243041992

Epoch: 5| Step: 10
Training loss: 2.652132034301758
Validation loss: 2.4946113196752404

Epoch: 122| Step: 0
Training loss: 2.679945230484009
Validation loss: 2.4972092233678347

Epoch: 5| Step: 1
Training loss: 3.306184768676758
Validation loss: 2.490269612240535

Epoch: 5| Step: 2
Training loss: 2.7662720680236816
Validation loss: 2.4908251121479976

Epoch: 5| Step: 3
Training loss: 2.541694402694702
Validation loss: 2.4930434380808184

Epoch: 5| Step: 4
Training loss: 2.872145175933838
Validation loss: 2.493999240218952

Epoch: 5| Step: 5
Training loss: 2.660231351852417
Validation loss: 2.496350021772487

Epoch: 5| Step: 6
Training loss: 2.3768417835235596
Validation loss: 2.498559785145585

Epoch: 5| Step: 7
Training loss: 2.8195457458496094
Validation loss: 2.503958994342435

Epoch: 5| Step: 8
Training loss: 2.046875
Validation loss: 2.4995719130321215

Epoch: 5| Step: 9
Training loss: 3.0718472003936768
Validation loss: 2.495025272010475

Epoch: 5| Step: 10
Training loss: 2.178694486618042
Validation loss: 2.495719681503952

Epoch: 123| Step: 0
Training loss: 2.2373640537261963
Validation loss: 2.490595772702207

Epoch: 5| Step: 1
Training loss: 2.6470947265625
Validation loss: 2.483646108258155

Epoch: 5| Step: 2
Training loss: 2.6360647678375244
Validation loss: 2.488393247768443

Epoch: 5| Step: 3
Training loss: 2.646894931793213
Validation loss: 2.489091293786162

Epoch: 5| Step: 4
Training loss: 2.3309504985809326
Validation loss: 2.4840625998794392

Epoch: 5| Step: 5
Training loss: 3.079399585723877
Validation loss: 2.4883360350003807

Epoch: 5| Step: 6
Training loss: 2.482743740081787
Validation loss: 2.4822992022319506

Epoch: 5| Step: 7
Training loss: 2.480623722076416
Validation loss: 2.4900138865235033

Epoch: 5| Step: 8
Training loss: 3.2738709449768066
Validation loss: 2.4974695123651975

Epoch: 5| Step: 9
Training loss: 2.8692193031311035
Validation loss: 2.495200211001981

Epoch: 5| Step: 10
Training loss: 2.664926528930664
Validation loss: 2.500431799119519

Epoch: 124| Step: 0
Training loss: 2.675165891647339
Validation loss: 2.4913109887030815

Epoch: 5| Step: 1
Training loss: 2.465531349182129
Validation loss: 2.4966351139929985

Epoch: 5| Step: 2
Training loss: 3.2164394855499268
Validation loss: 2.5037837387413107

Epoch: 5| Step: 3
Training loss: 2.0885415077209473
Validation loss: 2.4997522420780633

Epoch: 5| Step: 4
Training loss: 2.301475763320923
Validation loss: 2.502029158735788

Epoch: 5| Step: 5
Training loss: 2.364588975906372
Validation loss: 2.5086783183518278

Epoch: 5| Step: 6
Training loss: 3.2541282176971436
Validation loss: 2.5101378399838685

Epoch: 5| Step: 7
Training loss: 2.238386869430542
Validation loss: 2.508889457230927

Epoch: 5| Step: 8
Training loss: 3.088900327682495
Validation loss: 2.509461200365456

Epoch: 5| Step: 9
Training loss: 2.420977830886841
Validation loss: 2.492787386781426

Epoch: 5| Step: 10
Training loss: 3.2484302520751953
Validation loss: 2.481471946162562

Epoch: 125| Step: 0
Training loss: 2.440973997116089
Validation loss: 2.4747949159273537

Epoch: 5| Step: 1
Training loss: 2.6410999298095703
Validation loss: 2.4734736027256137

Epoch: 5| Step: 2
Training loss: 2.547839641571045
Validation loss: 2.4743906990174325

Epoch: 5| Step: 3
Training loss: 2.4115562438964844
Validation loss: 2.4720541584876274

Epoch: 5| Step: 4
Training loss: 3.099979877471924
Validation loss: 2.47145317703165

Epoch: 5| Step: 5
Training loss: 2.4801900386810303
Validation loss: 2.468927603895946

Epoch: 5| Step: 6
Training loss: 2.1854748725891113
Validation loss: 2.4709116361474477

Epoch: 5| Step: 7
Training loss: 2.6694352626800537
Validation loss: 2.4709031863879134

Epoch: 5| Step: 8
Training loss: 3.1677463054656982
Validation loss: 2.4748592312617967

Epoch: 5| Step: 9
Training loss: 2.8568100929260254
Validation loss: 2.47928253809611

Epoch: 5| Step: 10
Training loss: 2.933741807937622
Validation loss: 2.4800613900666595

Epoch: 126| Step: 0
Training loss: 2.852909803390503
Validation loss: 2.478377401187856

Epoch: 5| Step: 1
Training loss: 2.3513779640197754
Validation loss: 2.4846563646870274

Epoch: 5| Step: 2
Training loss: 2.385162830352783
Validation loss: 2.4818595865721345

Epoch: 5| Step: 3
Training loss: 2.3256561756134033
Validation loss: 2.485101276828397

Epoch: 5| Step: 4
Training loss: 3.0157477855682373
Validation loss: 2.4824277918825866

Epoch: 5| Step: 5
Training loss: 2.8893351554870605
Validation loss: 2.478124769785071

Epoch: 5| Step: 6
Training loss: 2.9232423305511475
Validation loss: 2.4754790977765153

Epoch: 5| Step: 7
Training loss: 3.07047963142395
Validation loss: 2.4771739308552077

Epoch: 5| Step: 8
Training loss: 2.349858045578003
Validation loss: 2.486135482788086

Epoch: 5| Step: 9
Training loss: 2.448707103729248
Validation loss: 2.495054991014542

Epoch: 5| Step: 10
Training loss: 2.848897933959961
Validation loss: 2.501430224346858

Epoch: 127| Step: 0
Training loss: 2.670988082885742
Validation loss: 2.499193381237727

Epoch: 5| Step: 1
Training loss: 3.0666556358337402
Validation loss: 2.497525066457769

Epoch: 5| Step: 2
Training loss: 2.585566997528076
Validation loss: 2.4877805017655894

Epoch: 5| Step: 3
Training loss: 2.667667865753174
Validation loss: 2.4871600930408766

Epoch: 5| Step: 4
Training loss: 2.8580374717712402
Validation loss: 2.4928396107048116

Epoch: 5| Step: 5
Training loss: 2.2541911602020264
Validation loss: 2.4906072308940272

Epoch: 5| Step: 6
Training loss: 2.8829503059387207
Validation loss: 2.5002205089856218

Epoch: 5| Step: 7
Training loss: 2.651948928833008
Validation loss: 2.5006859943430912

Epoch: 5| Step: 8
Training loss: 2.736923933029175
Validation loss: 2.5126008372153006

Epoch: 5| Step: 9
Training loss: 2.14919376373291
Validation loss: 2.514469623565674

Epoch: 5| Step: 10
Training loss: 2.822469711303711
Validation loss: 2.5179217118088917

Epoch: 128| Step: 0
Training loss: 2.3819775581359863
Validation loss: 2.5184439792427966

Epoch: 5| Step: 1
Training loss: 2.5409083366394043
Validation loss: 2.5197112508999404

Epoch: 5| Step: 2
Training loss: 2.7947936058044434
Validation loss: 2.5142486274883313

Epoch: 5| Step: 3
Training loss: 3.0450997352600098
Validation loss: 2.525788632772302

Epoch: 5| Step: 4
Training loss: 2.8126320838928223
Validation loss: 2.5268051649934504

Epoch: 5| Step: 5
Training loss: 1.81219482421875
Validation loss: 2.5203341335378666

Epoch: 5| Step: 6
Training loss: 2.8628315925598145
Validation loss: 2.5107188327338106

Epoch: 5| Step: 7
Training loss: 2.2134335041046143
Validation loss: 2.5065055534403813

Epoch: 5| Step: 8
Training loss: 3.461557388305664
Validation loss: 2.507548265559699

Epoch: 5| Step: 9
Training loss: 2.6890158653259277
Validation loss: 2.493861900862827

Epoch: 5| Step: 10
Training loss: 2.778719186782837
Validation loss: 2.490376603218817

Epoch: 129| Step: 0
Training loss: 2.3951289653778076
Validation loss: 2.481811292709843

Epoch: 5| Step: 1
Training loss: 2.4854652881622314
Validation loss: 2.4775320560701433

Epoch: 5| Step: 2
Training loss: 2.911125659942627
Validation loss: 2.478356333189113

Epoch: 5| Step: 3
Training loss: 3.095869779586792
Validation loss: 2.4789602243772118

Epoch: 5| Step: 4
Training loss: 2.617556095123291
Validation loss: 2.4768330102325766

Epoch: 5| Step: 5
Training loss: 1.9300415515899658
Validation loss: 2.4698491352860645

Epoch: 5| Step: 6
Training loss: 2.898449659347534
Validation loss: 2.465601472444432

Epoch: 5| Step: 7
Training loss: 1.591534972190857
Validation loss: 2.474671668903802

Epoch: 5| Step: 8
Training loss: 2.991837978363037
Validation loss: 2.474810192661901

Epoch: 5| Step: 9
Training loss: 2.7666869163513184
Validation loss: 2.477322534848285

Epoch: 5| Step: 10
Training loss: 3.760281562805176
Validation loss: 2.4761907208350395

Epoch: 130| Step: 0
Training loss: 2.3351972103118896
Validation loss: 2.4824153018254105

Epoch: 5| Step: 1
Training loss: 2.794785737991333
Validation loss: 2.489387689098235

Epoch: 5| Step: 2
Training loss: 2.3523001670837402
Validation loss: 2.4905168048797117

Epoch: 5| Step: 3
Training loss: 3.105645179748535
Validation loss: 2.5076499267291

Epoch: 5| Step: 4
Training loss: 3.4719531536102295
Validation loss: 2.495185379059084

Epoch: 5| Step: 5
Training loss: 2.376253604888916
Validation loss: 2.491762358655212

Epoch: 5| Step: 6
Training loss: 2.8425793647766113
Validation loss: 2.4866562248558126

Epoch: 5| Step: 7
Training loss: 2.0831387042999268
Validation loss: 2.4798664841600644

Epoch: 5| Step: 8
Training loss: 2.3790454864501953
Validation loss: 2.468757455066968

Epoch: 5| Step: 9
Training loss: 2.6365890502929688
Validation loss: 2.4681478315784084

Epoch: 5| Step: 10
Training loss: 3.040586471557617
Validation loss: 2.4648984734730055

Epoch: 131| Step: 0
Training loss: 2.8435521125793457
Validation loss: 2.463135944899692

Epoch: 5| Step: 1
Training loss: 2.566434621810913
Validation loss: 2.467000130684145

Epoch: 5| Step: 2
Training loss: 2.8606228828430176
Validation loss: 2.465211929813508

Epoch: 5| Step: 3
Training loss: 2.490142345428467
Validation loss: 2.467336103480349

Epoch: 5| Step: 4
Training loss: 2.2213568687438965
Validation loss: 2.4642298657407045

Epoch: 5| Step: 5
Training loss: 2.621053695678711
Validation loss: 2.46448685789621

Epoch: 5| Step: 6
Training loss: 3.136432647705078
Validation loss: 2.4606726451586654

Epoch: 5| Step: 7
Training loss: 2.505430221557617
Validation loss: 2.4690572548938055

Epoch: 5| Step: 8
Training loss: 2.8896632194519043
Validation loss: 2.4782649881096295

Epoch: 5| Step: 9
Training loss: 2.2876474857330322
Validation loss: 2.4820299481832855

Epoch: 5| Step: 10
Training loss: 2.841266393661499
Validation loss: 2.479413301714005

Epoch: 132| Step: 0
Training loss: 2.8662495613098145
Validation loss: 2.481041576272698

Epoch: 5| Step: 1
Training loss: 3.063734769821167
Validation loss: 2.498083186405961

Epoch: 5| Step: 2
Training loss: 2.1541926860809326
Validation loss: 2.497933821011615

Epoch: 5| Step: 3
Training loss: 2.5151491165161133
Validation loss: 2.503444343484858

Epoch: 5| Step: 4
Training loss: 3.1308555603027344
Validation loss: 2.51236133421621

Epoch: 5| Step: 5
Training loss: 2.4127402305603027
Validation loss: 2.5179678291402836

Epoch: 5| Step: 6
Training loss: 2.381554126739502
Validation loss: 2.513945778210958

Epoch: 5| Step: 7
Training loss: 2.7666964530944824
Validation loss: 2.5151912396953953

Epoch: 5| Step: 8
Training loss: 2.6742146015167236
Validation loss: 2.5049121533670733

Epoch: 5| Step: 9
Training loss: 2.2962381839752197
Validation loss: 2.4972049267061296

Epoch: 5| Step: 10
Training loss: 2.9244284629821777
Validation loss: 2.4832243304098807

Epoch: 133| Step: 0
Training loss: 2.7458202838897705
Validation loss: 2.4880048228848364

Epoch: 5| Step: 1
Training loss: 2.1371147632598877
Validation loss: 2.4783603478503484

Epoch: 5| Step: 2
Training loss: 2.639744997024536
Validation loss: 2.4762363331292265

Epoch: 5| Step: 3
Training loss: 2.1362144947052
Validation loss: 2.472542542283253

Epoch: 5| Step: 4
Training loss: 2.299190044403076
Validation loss: 2.4731003187036

Epoch: 5| Step: 5
Training loss: 2.254931926727295
Validation loss: 2.4775111752171672

Epoch: 5| Step: 6
Training loss: 3.3082432746887207
Validation loss: 2.476978614766111

Epoch: 5| Step: 7
Training loss: 2.871356725692749
Validation loss: 2.480227662670997

Epoch: 5| Step: 8
Training loss: 3.5861008167266846
Validation loss: 2.4895384465494463

Epoch: 5| Step: 9
Training loss: 2.62785005569458
Validation loss: 2.487672021312098

Epoch: 5| Step: 10
Training loss: 2.5533599853515625
Validation loss: 2.4957552315086446

Epoch: 134| Step: 0
Training loss: 3.184438705444336
Validation loss: 2.487585034421695

Epoch: 5| Step: 1
Training loss: 2.479140520095825
Validation loss: 2.5028238655418478

Epoch: 5| Step: 2
Training loss: 2.419909954071045
Validation loss: 2.5138455667803363

Epoch: 5| Step: 3
Training loss: 2.3769643306732178
Validation loss: 2.5133225379451627

Epoch: 5| Step: 4
Training loss: 3.13274884223938
Validation loss: 2.5077440841223604

Epoch: 5| Step: 5
Training loss: 2.6322710514068604
Validation loss: 2.506107566177204

Epoch: 5| Step: 6
Training loss: 2.6081900596618652
Validation loss: 2.503407529605332

Epoch: 5| Step: 7
Training loss: 2.292076349258423
Validation loss: 2.5065736296356365

Epoch: 5| Step: 8
Training loss: 3.51458477973938
Validation loss: 2.5046866760458997

Epoch: 5| Step: 9
Training loss: 2.1607487201690674
Validation loss: 2.491107097236059

Epoch: 5| Step: 10
Training loss: 2.338900566101074
Validation loss: 2.4967224546658096

Epoch: 135| Step: 0
Training loss: 1.690473198890686
Validation loss: 2.482992882369667

Epoch: 5| Step: 1
Training loss: 3.2916417121887207
Validation loss: 2.4856884838432394

Epoch: 5| Step: 2
Training loss: 2.305349349975586
Validation loss: 2.4762424781758297

Epoch: 5| Step: 3
Training loss: 2.1825685501098633
Validation loss: 2.473378171202957

Epoch: 5| Step: 4
Training loss: 2.6302740573883057
Validation loss: 2.475147144768828

Epoch: 5| Step: 5
Training loss: 2.9306719303131104
Validation loss: 2.477219937950052

Epoch: 5| Step: 6
Training loss: 2.2526628971099854
Validation loss: 2.480598311270437

Epoch: 5| Step: 7
Training loss: 2.5709433555603027
Validation loss: 2.4902402303552114

Epoch: 5| Step: 8
Training loss: 3.2130935192108154
Validation loss: 2.4980319494842202

Epoch: 5| Step: 9
Training loss: 2.8620896339416504
Validation loss: 2.4872989295631327

Epoch: 5| Step: 10
Training loss: 3.2605366706848145
Validation loss: 2.4787699330237603

Epoch: 136| Step: 0
Training loss: 2.621342420578003
Validation loss: 2.4723461263923237

Epoch: 5| Step: 1
Training loss: 2.6241447925567627
Validation loss: 2.473576350878644

Epoch: 5| Step: 2
Training loss: 2.7452354431152344
Validation loss: 2.475102680985646

Epoch: 5| Step: 3
Training loss: 2.195282459259033
Validation loss: 2.486920793851217

Epoch: 5| Step: 4
Training loss: 2.7333614826202393
Validation loss: 2.4900597551817536

Epoch: 5| Step: 5
Training loss: 3.082296133041382
Validation loss: 2.4989738797628753

Epoch: 5| Step: 6
Training loss: 2.4661471843719482
Validation loss: 2.493321620007997

Epoch: 5| Step: 7
Training loss: 2.740354299545288
Validation loss: 2.4935167476695073

Epoch: 5| Step: 8
Training loss: 2.909071445465088
Validation loss: 2.48808398554402

Epoch: 5| Step: 9
Training loss: 2.317951202392578
Validation loss: 2.4838347358088337

Epoch: 5| Step: 10
Training loss: 2.6434483528137207
Validation loss: 2.473386181298123

Epoch: 137| Step: 0
Training loss: 2.5128369331359863
Validation loss: 2.472843805948893

Epoch: 5| Step: 1
Training loss: 2.628831148147583
Validation loss: 2.477200681163419

Epoch: 5| Step: 2
Training loss: 2.1902058124542236
Validation loss: 2.478812681731357

Epoch: 5| Step: 3
Training loss: 2.536267042160034
Validation loss: 2.4817880481802006

Epoch: 5| Step: 4
Training loss: 3.1104705333709717
Validation loss: 2.478238287792411

Epoch: 5| Step: 5
Training loss: 3.4115188121795654
Validation loss: 2.481433271079935

Epoch: 5| Step: 6
Training loss: 2.688520908355713
Validation loss: 2.481738111024262

Epoch: 5| Step: 7
Training loss: 2.72898530960083
Validation loss: 2.4777142796465146

Epoch: 5| Step: 8
Training loss: 2.0749595165252686
Validation loss: 2.4862027681002052

Epoch: 5| Step: 9
Training loss: 3.101501703262329
Validation loss: 2.496039544382403

Epoch: 5| Step: 10
Training loss: 2.0649988651275635
Validation loss: 2.5034133285604496

Epoch: 138| Step: 0
Training loss: 2.4646174907684326
Validation loss: 2.501889632594201

Epoch: 5| Step: 1
Training loss: 3.0288445949554443
Validation loss: 2.492348599177535

Epoch: 5| Step: 2
Training loss: 2.481564998626709
Validation loss: 2.505324109908073

Epoch: 5| Step: 3
Training loss: 3.417681932449341
Validation loss: 2.5005405769553235

Epoch: 5| Step: 4
Training loss: 2.5375163555145264
Validation loss: 2.4932468065651516

Epoch: 5| Step: 5
Training loss: 2.583070755004883
Validation loss: 2.483550456262404

Epoch: 5| Step: 6
Training loss: 2.3568053245544434
Validation loss: 2.490726594002016

Epoch: 5| Step: 7
Training loss: 1.9623305797576904
Validation loss: 2.4854639243054133

Epoch: 5| Step: 8
Training loss: 3.0381171703338623
Validation loss: 2.4857334885545956

Epoch: 5| Step: 9
Training loss: 2.956768035888672
Validation loss: 2.4760039467965402

Epoch: 5| Step: 10
Training loss: 2.219599962234497
Validation loss: 2.461202703496461

Epoch: 139| Step: 0
Training loss: 2.182248592376709
Validation loss: 2.4710921190118276

Epoch: 5| Step: 1
Training loss: 2.2371833324432373
Validation loss: 2.4780290716437885

Epoch: 5| Step: 2
Training loss: 3.2627272605895996
Validation loss: 2.4659629252649125

Epoch: 5| Step: 3
Training loss: 2.760941982269287
Validation loss: 2.468699324515558

Epoch: 5| Step: 4
Training loss: 1.9762407541275024
Validation loss: 2.4683600600047777

Epoch: 5| Step: 5
Training loss: 2.4507317543029785
Validation loss: 2.4621812758907193

Epoch: 5| Step: 6
Training loss: 2.578134298324585
Validation loss: 2.468509107507685

Epoch: 5| Step: 7
Training loss: 2.6094307899475098
Validation loss: 2.4684673560562955

Epoch: 5| Step: 8
Training loss: 2.892205238342285
Validation loss: 2.4837176748501357

Epoch: 5| Step: 9
Training loss: 3.2952322959899902
Validation loss: 2.4803880260836695

Epoch: 5| Step: 10
Training loss: 2.9006402492523193
Validation loss: 2.483025827715474

Epoch: 140| Step: 0
Training loss: 2.0554656982421875
Validation loss: 2.488965008848457

Epoch: 5| Step: 1
Training loss: 2.840162754058838
Validation loss: 2.4839174362920944

Epoch: 5| Step: 2
Training loss: 2.2492265701293945
Validation loss: 2.475971214232906

Epoch: 5| Step: 3
Training loss: 1.828473448753357
Validation loss: 2.489319339875252

Epoch: 5| Step: 4
Training loss: 2.5404648780822754
Validation loss: 2.477770023448493

Epoch: 5| Step: 5
Training loss: 2.9079208374023438
Validation loss: 2.462960462416372

Epoch: 5| Step: 6
Training loss: 2.9795477390289307
Validation loss: 2.4768305491375666

Epoch: 5| Step: 7
Training loss: 2.4853639602661133
Validation loss: 2.470641492515482

Epoch: 5| Step: 8
Training loss: 2.969738006591797
Validation loss: 2.4723963429850917

Epoch: 5| Step: 9
Training loss: 3.3336498737335205
Validation loss: 2.480766119495515

Epoch: 5| Step: 10
Training loss: 2.867457628250122
Validation loss: 2.4750874811603176

Epoch: 141| Step: 0
Training loss: 2.9711475372314453
Validation loss: 2.4691957914701073

Epoch: 5| Step: 1
Training loss: 2.6331868171691895
Validation loss: 2.46680175617177

Epoch: 5| Step: 2
Training loss: 2.543191909790039
Validation loss: 2.480268737321259

Epoch: 5| Step: 3
Training loss: 2.5625462532043457
Validation loss: 2.4704433154034358

Epoch: 5| Step: 4
Training loss: 2.348684787750244
Validation loss: 2.4722229793507564

Epoch: 5| Step: 5
Training loss: 2.743061065673828
Validation loss: 2.4737907276358655

Epoch: 5| Step: 6
Training loss: 3.016746997833252
Validation loss: 2.4751150813153995

Epoch: 5| Step: 7
Training loss: 1.9071928262710571
Validation loss: 2.4767548294477564

Epoch: 5| Step: 8
Training loss: 2.310473918914795
Validation loss: 2.4784773165179836

Epoch: 5| Step: 9
Training loss: 2.863654375076294
Validation loss: 2.4796223281532206

Epoch: 5| Step: 10
Training loss: 3.2079758644104004
Validation loss: 2.483151435852051

Epoch: 142| Step: 0
Training loss: 2.9261202812194824
Validation loss: 2.492585507772302

Epoch: 5| Step: 1
Training loss: 2.866913318634033
Validation loss: 2.490720433573569

Epoch: 5| Step: 2
Training loss: 2.5493173599243164
Validation loss: 2.4958400880136797

Epoch: 5| Step: 3
Training loss: 2.705872058868408
Validation loss: 2.50056456494075

Epoch: 5| Step: 4
Training loss: 2.9782543182373047
Validation loss: 2.4977937770146195

Epoch: 5| Step: 5
Training loss: 2.504666805267334
Validation loss: 2.4875659737535702

Epoch: 5| Step: 6
Training loss: 2.498872995376587
Validation loss: 2.494398419575025

Epoch: 5| Step: 7
Training loss: 2.143012285232544
Validation loss: 2.482778872213056

Epoch: 5| Step: 8
Training loss: 2.561992645263672
Validation loss: 2.473747025253952

Epoch: 5| Step: 9
Training loss: 2.3561336994171143
Validation loss: 2.475541648044381

Epoch: 5| Step: 10
Training loss: 2.999384880065918
Validation loss: 2.4792127352888866

Epoch: 143| Step: 0
Training loss: 3.0238962173461914
Validation loss: 2.47431638163905

Epoch: 5| Step: 1
Training loss: 2.4207568168640137
Validation loss: 2.4797953277505855

Epoch: 5| Step: 2
Training loss: 3.1281332969665527
Validation loss: 2.4868649205853863

Epoch: 5| Step: 3
Training loss: 3.2177677154541016
Validation loss: 2.4881391973905664

Epoch: 5| Step: 4
Training loss: 2.1628317832946777
Validation loss: 2.494384329806092

Epoch: 5| Step: 5
Training loss: 2.8343377113342285
Validation loss: 2.4893483820781914

Epoch: 5| Step: 6
Training loss: 2.967944383621216
Validation loss: 2.4886621787983882

Epoch: 5| Step: 7
Training loss: 2.444451332092285
Validation loss: 2.484818604684645

Epoch: 5| Step: 8
Training loss: 1.8958591222763062
Validation loss: 2.477372430985974

Epoch: 5| Step: 9
Training loss: 2.3311493396759033
Validation loss: 2.477419825010402

Epoch: 5| Step: 10
Training loss: 2.525494337081909
Validation loss: 2.470114625910277

Epoch: 144| Step: 0
Training loss: 2.801532506942749
Validation loss: 2.472177114537967

Epoch: 5| Step: 1
Training loss: 2.6905808448791504
Validation loss: 2.4863001402988227

Epoch: 5| Step: 2
Training loss: 2.4307215213775635
Validation loss: 2.4864196392797653

Epoch: 5| Step: 3
Training loss: 2.194972515106201
Validation loss: 2.4954700675061954

Epoch: 5| Step: 4
Training loss: 3.225841999053955
Validation loss: 2.5028418879355154

Epoch: 5| Step: 5
Training loss: 2.4820334911346436
Validation loss: 2.503042931197792

Epoch: 5| Step: 6
Training loss: 2.8010311126708984
Validation loss: 2.501014183926326

Epoch: 5| Step: 7
Training loss: 3.0149786472320557
Validation loss: 2.4796929769618536

Epoch: 5| Step: 8
Training loss: 2.523871660232544
Validation loss: 2.4846151862093198

Epoch: 5| Step: 9
Training loss: 2.795117139816284
Validation loss: 2.473534486627066

Epoch: 5| Step: 10
Training loss: 2.369781255722046
Validation loss: 2.4640881553772958

Epoch: 145| Step: 0
Training loss: 2.939058780670166
Validation loss: 2.454974202699559

Epoch: 5| Step: 1
Training loss: 2.445453405380249
Validation loss: 2.4565378568505727

Epoch: 5| Step: 2
Training loss: 2.51770281791687
Validation loss: 2.4508716521724576

Epoch: 5| Step: 3
Training loss: 2.196821689605713
Validation loss: 2.454227516728063

Epoch: 5| Step: 4
Training loss: 2.8443048000335693
Validation loss: 2.465192517926616

Epoch: 5| Step: 5
Training loss: 1.8276163339614868
Validation loss: 2.464554707209269

Epoch: 5| Step: 6
Training loss: 3.3522162437438965
Validation loss: 2.481360166303573

Epoch: 5| Step: 7
Training loss: 2.7185187339782715
Validation loss: 2.4795725832703295

Epoch: 5| Step: 8
Training loss: 3.3593735694885254
Validation loss: 2.481154682815716

Epoch: 5| Step: 9
Training loss: 2.4870152473449707
Validation loss: 2.4944651331952823

Epoch: 5| Step: 10
Training loss: 2.2726972103118896
Validation loss: 2.4898772778049594

Epoch: 146| Step: 0
Training loss: 2.9967334270477295
Validation loss: 2.4893673876280427

Epoch: 5| Step: 1
Training loss: 2.111835241317749
Validation loss: 2.4865533818480787

Epoch: 5| Step: 2
Training loss: 2.219264268875122
Validation loss: 2.47897332970814

Epoch: 5| Step: 3
Training loss: 2.716339111328125
Validation loss: 2.4649506204871723

Epoch: 5| Step: 4
Training loss: 3.558361530303955
Validation loss: 2.479252464027815

Epoch: 5| Step: 5
Training loss: 3.122955560684204
Validation loss: 2.4685670252769225

Epoch: 5| Step: 6
Training loss: 2.8472983837127686
Validation loss: 2.4761424782455608

Epoch: 5| Step: 7
Training loss: 2.1955463886260986
Validation loss: 2.477078522405317

Epoch: 5| Step: 8
Training loss: 2.2680110931396484
Validation loss: 2.4776830724490586

Epoch: 5| Step: 9
Training loss: 2.265378952026367
Validation loss: 2.462789040739818

Epoch: 5| Step: 10
Training loss: 2.7409396171569824
Validation loss: 2.467250954720282

Epoch: 147| Step: 0
Training loss: 2.2733094692230225
Validation loss: 2.472166943293746

Epoch: 5| Step: 1
Training loss: 2.9909613132476807
Validation loss: 2.472705720573343

Epoch: 5| Step: 2
Training loss: 2.6454737186431885
Validation loss: 2.4706128028131302

Epoch: 5| Step: 3
Training loss: 2.452636241912842
Validation loss: 2.4641571198740313

Epoch: 5| Step: 4
Training loss: 3.1536831855773926
Validation loss: 2.4626888511001424

Epoch: 5| Step: 5
Training loss: 2.1029019355773926
Validation loss: 2.4749797108352825

Epoch: 5| Step: 6
Training loss: 2.441154956817627
Validation loss: 2.471928147859471

Epoch: 5| Step: 7
Training loss: 2.512711524963379
Validation loss: 2.4811411134658323

Epoch: 5| Step: 8
Training loss: 2.34483003616333
Validation loss: 2.49260526575068

Epoch: 5| Step: 9
Training loss: 3.476871967315674
Validation loss: 2.4966863022055676

Epoch: 5| Step: 10
Training loss: 2.5297131538391113
Validation loss: 2.494768278573149

Epoch: 148| Step: 0
Training loss: 3.0624465942382812
Validation loss: 2.4836554732373965

Epoch: 5| Step: 1
Training loss: 2.751547336578369
Validation loss: 2.4677201086475002

Epoch: 5| Step: 2
Training loss: 1.876413345336914
Validation loss: 2.4609131556685253

Epoch: 5| Step: 3
Training loss: 3.1371588706970215
Validation loss: 2.4497631724162767

Epoch: 5| Step: 4
Training loss: 2.7972028255462646
Validation loss: 2.4540128143884803

Epoch: 5| Step: 5
Training loss: 2.9658961296081543
Validation loss: 2.4472232557112172

Epoch: 5| Step: 6
Training loss: 2.55704927444458
Validation loss: 2.4461842352344143

Epoch: 5| Step: 7
Training loss: 2.7494914531707764
Validation loss: 2.4488395593499623

Epoch: 5| Step: 8
Training loss: 2.7322816848754883
Validation loss: 2.4561978488840084

Epoch: 5| Step: 9
Training loss: 1.9536060094833374
Validation loss: 2.452181177754556

Epoch: 5| Step: 10
Training loss: 2.4749538898468018
Validation loss: 2.463464452374366

Epoch: 149| Step: 0
Training loss: 1.8715702295303345
Validation loss: 2.45897497669343

Epoch: 5| Step: 1
Training loss: 3.301755428314209
Validation loss: 2.471467561619256

Epoch: 5| Step: 2
Training loss: 2.6746387481689453
Validation loss: 2.484585318514096

Epoch: 5| Step: 3
Training loss: 2.524158477783203
Validation loss: 2.49140808146487

Epoch: 5| Step: 4
Training loss: 3.238132953643799
Validation loss: 2.526437331271428

Epoch: 5| Step: 5
Training loss: 3.3951938152313232
Validation loss: 2.5389271641290314

Epoch: 5| Step: 6
Training loss: 1.8199713230133057
Validation loss: 2.5339991572082683

Epoch: 5| Step: 7
Training loss: 2.6417858600616455
Validation loss: 2.5437688212240896

Epoch: 5| Step: 8
Training loss: 2.2096378803253174
Validation loss: 2.5149789087234007

Epoch: 5| Step: 9
Training loss: 2.8705108165740967
Validation loss: 2.5089736625712407

Epoch: 5| Step: 10
Training loss: 2.519937753677368
Validation loss: 2.4860160889164096

Epoch: 150| Step: 0
Training loss: 2.394984722137451
Validation loss: 2.479876261885448

Epoch: 5| Step: 1
Training loss: 3.0989460945129395
Validation loss: 2.4790656976802374

Epoch: 5| Step: 2
Training loss: 3.140601873397827
Validation loss: 2.472797465580766

Epoch: 5| Step: 3
Training loss: 2.6902878284454346
Validation loss: 2.4792301577906453

Epoch: 5| Step: 4
Training loss: 2.295401096343994
Validation loss: 2.48871325677441

Epoch: 5| Step: 5
Training loss: 2.2664341926574707
Validation loss: 2.487669111579977

Epoch: 5| Step: 6
Training loss: 1.9160358905792236
Validation loss: 2.4969722147910827

Epoch: 5| Step: 7
Training loss: 2.4106030464172363
Validation loss: 2.486606172336045

Epoch: 5| Step: 8
Training loss: 3.336648464202881
Validation loss: 2.4764585418085896

Epoch: 5| Step: 9
Training loss: 3.0051872730255127
Validation loss: 2.46240303080569

Epoch: 5| Step: 10
Training loss: 2.70607590675354
Validation loss: 2.4643167270127164

Epoch: 151| Step: 0
Training loss: 2.4040093421936035
Validation loss: 2.450447387592767

Epoch: 5| Step: 1
Training loss: 2.598154067993164
Validation loss: 2.457288444683116

Epoch: 5| Step: 2
Training loss: 2.814926862716675
Validation loss: 2.451660925342191

Epoch: 5| Step: 3
Training loss: 2.195145606994629
Validation loss: 2.4469618540938183

Epoch: 5| Step: 4
Training loss: 2.7301058769226074
Validation loss: 2.4570788337338354

Epoch: 5| Step: 5
Training loss: 2.111936092376709
Validation loss: 2.4616233430882937

Epoch: 5| Step: 6
Training loss: 1.9476858377456665
Validation loss: 2.4803508122762046

Epoch: 5| Step: 7
Training loss: 2.627671003341675
Validation loss: 2.4805556702357467

Epoch: 5| Step: 8
Training loss: 3.3682377338409424
Validation loss: 2.502112677020411

Epoch: 5| Step: 9
Training loss: 3.1110634803771973
Validation loss: 2.514122191295829

Epoch: 5| Step: 10
Training loss: 3.1655454635620117
Validation loss: 2.5290642169214066

Epoch: 152| Step: 0
Training loss: 3.2694411277770996
Validation loss: 2.511159284140474

Epoch: 5| Step: 1
Training loss: 2.666302442550659
Validation loss: 2.487444031623102

Epoch: 5| Step: 2
Training loss: 2.0439586639404297
Validation loss: 2.4680125405711513

Epoch: 5| Step: 3
Training loss: 2.5875654220581055
Validation loss: 2.4690195078490884

Epoch: 5| Step: 4
Training loss: 2.6676344871520996
Validation loss: 2.458621355795091

Epoch: 5| Step: 5
Training loss: 2.790771484375
Validation loss: 2.4692195602642593

Epoch: 5| Step: 6
Training loss: 3.137300491333008
Validation loss: 2.4607270533038723

Epoch: 5| Step: 7
Training loss: 2.9282143115997314
Validation loss: 2.458370672759189

Epoch: 5| Step: 8
Training loss: 1.5145851373672485
Validation loss: 2.4562161712236303

Epoch: 5| Step: 9
Training loss: 2.8185667991638184
Validation loss: 2.453063864861765

Epoch: 5| Step: 10
Training loss: 2.469752311706543
Validation loss: 2.4510193050548597

Epoch: 153| Step: 0
Training loss: 2.5599422454833984
Validation loss: 2.4552540394567672

Epoch: 5| Step: 1
Training loss: 2.7713027000427246
Validation loss: 2.452544322577856

Epoch: 5| Step: 2
Training loss: 3.0625758171081543
Validation loss: 2.4537466367085776

Epoch: 5| Step: 3
Training loss: 2.68938946723938
Validation loss: 2.4488359728167133

Epoch: 5| Step: 4
Training loss: 2.573720932006836
Validation loss: 2.4496861452697427

Epoch: 5| Step: 5
Training loss: 2.6217947006225586
Validation loss: 2.441504955291748

Epoch: 5| Step: 6
Training loss: 1.9418303966522217
Validation loss: 2.4379420562457015

Epoch: 5| Step: 7
Training loss: 2.8624579906463623
Validation loss: 2.4377598967603458

Epoch: 5| Step: 8
Training loss: 2.557420253753662
Validation loss: 2.443249143579955

Epoch: 5| Step: 9
Training loss: 2.2983672618865967
Validation loss: 2.4412297869241364

Epoch: 5| Step: 10
Training loss: 3.0477375984191895
Validation loss: 2.443374518425234

Epoch: 154| Step: 0
Training loss: 2.1083016395568848
Validation loss: 2.442077080408732

Epoch: 5| Step: 1
Training loss: 2.0036838054656982
Validation loss: 2.4551872771273375

Epoch: 5| Step: 2
Training loss: 2.094850540161133
Validation loss: 2.459893561178638

Epoch: 5| Step: 3
Training loss: 2.5709807872772217
Validation loss: 2.474779657138291

Epoch: 5| Step: 4
Training loss: 3.438051700592041
Validation loss: 2.4815307432605374

Epoch: 5| Step: 5
Training loss: 2.524604558944702
Validation loss: 2.5040956902247604

Epoch: 5| Step: 6
Training loss: 3.0629384517669678
Validation loss: 2.505620038637551

Epoch: 5| Step: 7
Training loss: 2.247465133666992
Validation loss: 2.5084564044911373

Epoch: 5| Step: 8
Training loss: 2.4867935180664062
Validation loss: 2.5020920550951393

Epoch: 5| Step: 9
Training loss: 3.205040454864502
Validation loss: 2.503811856751801

Epoch: 5| Step: 10
Training loss: 3.3791568279266357
Validation loss: 2.4761298651336343

Epoch: 155| Step: 0
Training loss: 1.7846345901489258
Validation loss: 2.4652549143760436

Epoch: 5| Step: 1
Training loss: 2.7068443298339844
Validation loss: 2.457207259311471

Epoch: 5| Step: 2
Training loss: 2.6202220916748047
Validation loss: 2.4619921638119604

Epoch: 5| Step: 3
Training loss: 2.783742904663086
Validation loss: 2.459276214722664

Epoch: 5| Step: 4
Training loss: 2.8716063499450684
Validation loss: 2.4577846860372894

Epoch: 5| Step: 5
Training loss: 2.9045064449310303
Validation loss: 2.455556382415115

Epoch: 5| Step: 6
Training loss: 2.644951343536377
Validation loss: 2.4476704482109315

Epoch: 5| Step: 7
Training loss: 2.6454873085021973
Validation loss: 2.45026203637482

Epoch: 5| Step: 8
Training loss: 2.609135627746582
Validation loss: 2.450730618610177

Epoch: 5| Step: 9
Training loss: 2.969644784927368
Validation loss: 2.4541866189690045

Epoch: 5| Step: 10
Training loss: 2.4713168144226074
Validation loss: 2.4484250135319208

Epoch: 156| Step: 0
Training loss: 2.730367660522461
Validation loss: 2.4545766589462117

Epoch: 5| Step: 1
Training loss: 2.6729209423065186
Validation loss: 2.45373511058028

Epoch: 5| Step: 2
Training loss: 3.5110466480255127
Validation loss: 2.449442058481196

Epoch: 5| Step: 3
Training loss: 3.004369020462036
Validation loss: 2.4419423200750865

Epoch: 5| Step: 4
Training loss: 2.863913059234619
Validation loss: 2.451891650435745

Epoch: 5| Step: 5
Training loss: 3.261913299560547
Validation loss: 2.4514010747273765

Epoch: 5| Step: 6
Training loss: 1.7556654214859009
Validation loss: 2.462629456673899

Epoch: 5| Step: 7
Training loss: 2.431865930557251
Validation loss: 2.4611534200688845

Epoch: 5| Step: 8
Training loss: 1.9931942224502563
Validation loss: 2.4721194339054886

Epoch: 5| Step: 9
Training loss: 2.4922571182250977
Validation loss: 2.4753009298796296

Epoch: 5| Step: 10
Training loss: 1.9440218210220337
Validation loss: 2.4810771378137733

Epoch: 157| Step: 0
Training loss: 2.008408308029175
Validation loss: 2.4829643157220658

Epoch: 5| Step: 1
Training loss: 2.6590583324432373
Validation loss: 2.4852653139381

Epoch: 5| Step: 2
Training loss: 3.1911580562591553
Validation loss: 2.488770995088803

Epoch: 5| Step: 3
Training loss: 3.163663625717163
Validation loss: 2.484024606725221

Epoch: 5| Step: 4
Training loss: 2.4618544578552246
Validation loss: 2.4792163936040734

Epoch: 5| Step: 5
Training loss: 2.6850485801696777
Validation loss: 2.4640559996328046

Epoch: 5| Step: 6
Training loss: 2.7665934562683105
Validation loss: 2.4829063671891407

Epoch: 5| Step: 7
Training loss: 2.248076915740967
Validation loss: 2.4687409529121975

Epoch: 5| Step: 8
Training loss: 2.088744640350342
Validation loss: 2.466695567613007

Epoch: 5| Step: 9
Training loss: 2.54312801361084
Validation loss: 2.4667051761381087

Epoch: 5| Step: 10
Training loss: 3.08539080619812
Validation loss: 2.47280179813344

Epoch: 158| Step: 0
Training loss: 2.5869059562683105
Validation loss: 2.4532530666679464

Epoch: 5| Step: 1
Training loss: 2.8166873455047607
Validation loss: 2.451601918025683

Epoch: 5| Step: 2
Training loss: 1.871582269668579
Validation loss: 2.4536007732473393

Epoch: 5| Step: 3
Training loss: 3.6322388648986816
Validation loss: 2.444224649860013

Epoch: 5| Step: 4
Training loss: 3.1923136711120605
Validation loss: 2.4413369906845914

Epoch: 5| Step: 5
Training loss: 2.496314525604248
Validation loss: 2.4391753545371433

Epoch: 5| Step: 6
Training loss: 2.222144842147827
Validation loss: 2.4419121203884

Epoch: 5| Step: 7
Training loss: 2.556626558303833
Validation loss: 2.4425122712248113

Epoch: 5| Step: 8
Training loss: 2.8286399841308594
Validation loss: 2.44731471871817

Epoch: 5| Step: 9
Training loss: 2.242079019546509
Validation loss: 2.4363380503910843

Epoch: 5| Step: 10
Training loss: 2.6124281883239746
Validation loss: 2.432621325215986

Epoch: 159| Step: 0
Training loss: 2.8117823600769043
Validation loss: 2.427858619279759

Epoch: 5| Step: 1
Training loss: 2.6977334022521973
Validation loss: 2.4366329485370266

Epoch: 5| Step: 2
Training loss: 2.3651223182678223
Validation loss: 2.4400876337482083

Epoch: 5| Step: 3
Training loss: 2.5244133472442627
Validation loss: 2.4450553488987747

Epoch: 5| Step: 4
Training loss: 2.672105073928833
Validation loss: 2.445274160754296

Epoch: 5| Step: 5
Training loss: 2.730827808380127
Validation loss: 2.4431366561561503

Epoch: 5| Step: 6
Training loss: 2.132035732269287
Validation loss: 2.4502475594961517

Epoch: 5| Step: 7
Training loss: 2.6349880695343018
Validation loss: 2.452508852046023

Epoch: 5| Step: 8
Training loss: 3.0401859283447266
Validation loss: 2.4563036503330355

Epoch: 5| Step: 9
Training loss: 2.288724422454834
Validation loss: 2.4619422266560216

Epoch: 5| Step: 10
Training loss: 3.126006841659546
Validation loss: 2.4650839067274526

Epoch: 160| Step: 0
Training loss: 2.7304792404174805
Validation loss: 2.4680832906435897

Epoch: 5| Step: 1
Training loss: 2.6005167961120605
Validation loss: 2.4670505831318517

Epoch: 5| Step: 2
Training loss: 2.8554606437683105
Validation loss: 2.4678782775837886

Epoch: 5| Step: 3
Training loss: 2.234440326690674
Validation loss: 2.4693698331873906

Epoch: 5| Step: 4
Training loss: 2.7321219444274902
Validation loss: 2.4791598999372093

Epoch: 5| Step: 5
Training loss: 2.927039623260498
Validation loss: 2.4748282124919276

Epoch: 5| Step: 6
Training loss: 3.1313133239746094
Validation loss: 2.471389232143279

Epoch: 5| Step: 7
Training loss: 2.6051175594329834
Validation loss: 2.4661364093903573

Epoch: 5| Step: 8
Training loss: 2.550511121749878
Validation loss: 2.461447259431244

Epoch: 5| Step: 9
Training loss: 2.1819281578063965
Validation loss: 2.449381015634024

Epoch: 5| Step: 10
Training loss: 2.1756880283355713
Validation loss: 2.4473891181330525

Epoch: 161| Step: 0
Training loss: 2.3533902168273926
Validation loss: 2.443463256282191

Epoch: 5| Step: 1
Training loss: 2.5923266410827637
Validation loss: 2.4448225959654777

Epoch: 5| Step: 2
Training loss: 2.5879764556884766
Validation loss: 2.4430646050360894

Epoch: 5| Step: 3
Training loss: 2.9836978912353516
Validation loss: 2.4352670920792447

Epoch: 5| Step: 4
Training loss: 2.238325595855713
Validation loss: 2.437722944444226

Epoch: 5| Step: 5
Training loss: 2.6585116386413574
Validation loss: 2.4351726757582797

Epoch: 5| Step: 6
Training loss: 2.9411330223083496
Validation loss: 2.4387863271979877

Epoch: 5| Step: 7
Training loss: 2.096492052078247
Validation loss: 2.451599590239986

Epoch: 5| Step: 8
Training loss: 3.1971230506896973
Validation loss: 2.435712863040227

Epoch: 5| Step: 9
Training loss: 2.7777037620544434
Validation loss: 2.443385442097982

Epoch: 5| Step: 10
Training loss: 2.334887742996216
Validation loss: 2.440574151213451

Epoch: 162| Step: 0
Training loss: 2.5597822666168213
Validation loss: 2.4357116953019173

Epoch: 5| Step: 1
Training loss: 3.12811017036438
Validation loss: 2.4454965078702537

Epoch: 5| Step: 2
Training loss: 2.3038642406463623
Validation loss: 2.4408050121799594

Epoch: 5| Step: 3
Training loss: 2.3730573654174805
Validation loss: 2.4557317328709427

Epoch: 5| Step: 4
Training loss: 2.9691219329833984
Validation loss: 2.457997711755896

Epoch: 5| Step: 5
Training loss: 3.0776114463806152
Validation loss: 2.4761725805139028

Epoch: 5| Step: 6
Training loss: 2.5756497383117676
Validation loss: 2.481123332054384

Epoch: 5| Step: 7
Training loss: 2.7875783443450928
Validation loss: 2.507330779106386

Epoch: 5| Step: 8
Training loss: 1.7580459117889404
Validation loss: 2.502366327470349

Epoch: 5| Step: 9
Training loss: 2.548292636871338
Validation loss: 2.498370309029856

Epoch: 5| Step: 10
Training loss: 2.7273166179656982
Validation loss: 2.4803391784750004

Epoch: 163| Step: 0
Training loss: 2.4236321449279785
Validation loss: 2.489299428078436

Epoch: 5| Step: 1
Training loss: 2.4592463970184326
Validation loss: 2.4981336055263395

Epoch: 5| Step: 2
Training loss: 2.823164463043213
Validation loss: 2.487440827072308

Epoch: 5| Step: 3
Training loss: 2.0182318687438965
Validation loss: 2.4789766060408724

Epoch: 5| Step: 4
Training loss: 3.2060325145721436
Validation loss: 2.4861813078644457

Epoch: 5| Step: 5
Training loss: 3.22218656539917
Validation loss: 2.4755945718416603

Epoch: 5| Step: 6
Training loss: 2.658599376678467
Validation loss: 2.461643639431205

Epoch: 5| Step: 7
Training loss: 2.5628662109375
Validation loss: 2.45311810124305

Epoch: 5| Step: 8
Training loss: 2.1577601432800293
Validation loss: 2.4450745146761657

Epoch: 5| Step: 9
Training loss: 2.7411980628967285
Validation loss: 2.446122507895193

Epoch: 5| Step: 10
Training loss: 2.4471702575683594
Validation loss: 2.448189009902298

Epoch: 164| Step: 0
Training loss: 2.4885973930358887
Validation loss: 2.436690153614167

Epoch: 5| Step: 1
Training loss: 2.6200201511383057
Validation loss: 2.4325607976605816

Epoch: 5| Step: 2
Training loss: 2.6159160137176514
Validation loss: 2.4272060855742423

Epoch: 5| Step: 3
Training loss: 2.9054248332977295
Validation loss: 2.4391692556360716

Epoch: 5| Step: 4
Training loss: 2.750204563140869
Validation loss: 2.437382305822065

Epoch: 5| Step: 5
Training loss: 2.269448757171631
Validation loss: 2.4349703788757324

Epoch: 5| Step: 6
Training loss: 2.258815288543701
Validation loss: 2.4326018800017652

Epoch: 5| Step: 7
Training loss: 2.9194304943084717
Validation loss: 2.434142594696373

Epoch: 5| Step: 8
Training loss: 2.420078754425049
Validation loss: 2.4473372146647465

Epoch: 5| Step: 9
Training loss: 2.9538164138793945
Validation loss: 2.4589136723549134

Epoch: 5| Step: 10
Training loss: 2.479414224624634
Validation loss: 2.4574459932183705

Epoch: 165| Step: 0
Training loss: 2.2545714378356934
Validation loss: 2.4584983548810406

Epoch: 5| Step: 1
Training loss: 2.1473476886749268
Validation loss: 2.4749685820712837

Epoch: 5| Step: 2
Training loss: 2.2406039237976074
Validation loss: 2.478157881767519

Epoch: 5| Step: 3
Training loss: 2.6475799083709717
Validation loss: 2.4887585806590256

Epoch: 5| Step: 4
Training loss: 3.2187252044677734
Validation loss: 2.4963058092260875

Epoch: 5| Step: 5
Training loss: 2.6482462882995605
Validation loss: 2.4918232963931177

Epoch: 5| Step: 6
Training loss: 3.4084231853485107
Validation loss: 2.483229003926759

Epoch: 5| Step: 7
Training loss: 2.0503578186035156
Validation loss: 2.460301753013365

Epoch: 5| Step: 8
Training loss: 3.295537233352661
Validation loss: 2.464173501537692

Epoch: 5| Step: 9
Training loss: 2.3437464237213135
Validation loss: 2.448691160448136

Epoch: 5| Step: 10
Training loss: 2.4930262565612793
Validation loss: 2.4379467246352986

Epoch: 166| Step: 0
Training loss: 2.407022714614868
Validation loss: 2.4286695347037366

Epoch: 5| Step: 1
Training loss: 2.682281970977783
Validation loss: 2.420705182577974

Epoch: 5| Step: 2
Training loss: 2.7972218990325928
Validation loss: 2.4153417028406614

Epoch: 5| Step: 3
Training loss: 2.4321036338806152
Validation loss: 2.417163073375661

Epoch: 5| Step: 4
Training loss: 2.603480815887451
Validation loss: 2.419248257913897

Epoch: 5| Step: 5
Training loss: 2.9927303791046143
Validation loss: 2.4169658435288297

Epoch: 5| Step: 6
Training loss: 2.3627591133117676
Validation loss: 2.417276285027945

Epoch: 5| Step: 7
Training loss: 3.117946147918701
Validation loss: 2.4211946277208227

Epoch: 5| Step: 8
Training loss: 2.583162546157837
Validation loss: 2.4171519792208107

Epoch: 5| Step: 9
Training loss: 2.7218713760375977
Validation loss: 2.419992143107999

Epoch: 5| Step: 10
Training loss: 2.294830560684204
Validation loss: 2.4162828024997505

Epoch: 167| Step: 0
Training loss: 2.9418768882751465
Validation loss: 2.4172644512627715

Epoch: 5| Step: 1
Training loss: 2.1541907787323
Validation loss: 2.4211165161542993

Epoch: 5| Step: 2
Training loss: 2.5259158611297607
Validation loss: 2.4280370563589115

Epoch: 5| Step: 3
Training loss: 1.8319263458251953
Validation loss: 2.4276897958529893

Epoch: 5| Step: 4
Training loss: 2.5137698650360107
Validation loss: 2.437769853940574

Epoch: 5| Step: 5
Training loss: 3.238556385040283
Validation loss: 2.442093687672769

Epoch: 5| Step: 6
Training loss: 2.9730758666992188
Validation loss: 2.4565148481758694

Epoch: 5| Step: 7
Training loss: 2.525336503982544
Validation loss: 2.465010917314919

Epoch: 5| Step: 8
Training loss: 2.900639057159424
Validation loss: 2.467705367713846

Epoch: 5| Step: 9
Training loss: 2.693561553955078
Validation loss: 2.471624287225867

Epoch: 5| Step: 10
Training loss: 2.530132293701172
Validation loss: 2.472157145059237

Epoch: 168| Step: 0
Training loss: 1.9020023345947266
Validation loss: 2.4623311847768803

Epoch: 5| Step: 1
Training loss: 3.028491497039795
Validation loss: 2.483509889212988

Epoch: 5| Step: 2
Training loss: 2.992907762527466
Validation loss: 2.482664531277072

Epoch: 5| Step: 3
Training loss: 3.4032390117645264
Validation loss: 2.4680278147420576

Epoch: 5| Step: 4
Training loss: 2.740110397338867
Validation loss: 2.4599838641382035

Epoch: 5| Step: 5
Training loss: 2.495448350906372
Validation loss: 2.4615807199990876

Epoch: 5| Step: 6
Training loss: 1.977781891822815
Validation loss: 2.4522210116027505

Epoch: 5| Step: 7
Training loss: 2.5603561401367188
Validation loss: 2.4485675673330984

Epoch: 5| Step: 8
Training loss: 2.876720905303955
Validation loss: 2.443897831824518

Epoch: 5| Step: 9
Training loss: 2.4895548820495605
Validation loss: 2.437253790517007

Epoch: 5| Step: 10
Training loss: 2.1087095737457275
Validation loss: 2.4345619883588565

Epoch: 169| Step: 0
Training loss: 2.337886333465576
Validation loss: 2.448988127452071

Epoch: 5| Step: 1
Training loss: 2.354215145111084
Validation loss: 2.444422609062605

Epoch: 5| Step: 2
Training loss: 2.1912312507629395
Validation loss: 2.4471734364827475

Epoch: 5| Step: 3
Training loss: 2.820451021194458
Validation loss: 2.4454736132775583

Epoch: 5| Step: 4
Training loss: 2.923614740371704
Validation loss: 2.459094839711343

Epoch: 5| Step: 5
Training loss: 3.076216459274292
Validation loss: 2.46131068916731

Epoch: 5| Step: 6
Training loss: 2.41374135017395
Validation loss: 2.453903152096656

Epoch: 5| Step: 7
Training loss: 2.6143832206726074
Validation loss: 2.4457838278944775

Epoch: 5| Step: 8
Training loss: 1.9702030420303345
Validation loss: 2.4412084010339554

Epoch: 5| Step: 9
Training loss: 2.547722339630127
Validation loss: 2.442409076998311

Epoch: 5| Step: 10
Training loss: 3.597243547439575
Validation loss: 2.4377814005779963

Epoch: 170| Step: 0
Training loss: 2.5195152759552
Validation loss: 2.433084782733712

Epoch: 5| Step: 1
Training loss: 2.220451831817627
Validation loss: 2.4406241909150155

Epoch: 5| Step: 2
Training loss: 2.6646437644958496
Validation loss: 2.4360051231999553

Epoch: 5| Step: 3
Training loss: 2.54136323928833
Validation loss: 2.4390246483587448

Epoch: 5| Step: 4
Training loss: 2.3750243186950684
Validation loss: 2.437934975470266

Epoch: 5| Step: 5
Training loss: 2.4874274730682373
Validation loss: 2.454463715194374

Epoch: 5| Step: 6
Training loss: 3.0807552337646484
Validation loss: 2.4332053071709088

Epoch: 5| Step: 7
Training loss: 2.6233389377593994
Validation loss: 2.4409077808421147

Epoch: 5| Step: 8
Training loss: 2.202932834625244
Validation loss: 2.4408498707637993

Epoch: 5| Step: 9
Training loss: 2.723148822784424
Validation loss: 2.4431075921622654

Epoch: 5| Step: 10
Training loss: 3.222184896469116
Validation loss: 2.4439707827824417

Epoch: 171| Step: 0
Training loss: 2.6617159843444824
Validation loss: 2.442743650046728

Epoch: 5| Step: 1
Training loss: 2.9018750190734863
Validation loss: 2.4450442098802134

Epoch: 5| Step: 2
Training loss: 2.550403118133545
Validation loss: 2.439529429199875

Epoch: 5| Step: 3
Training loss: 2.58184814453125
Validation loss: 2.438845137114166

Epoch: 5| Step: 4
Training loss: 2.3859479427337646
Validation loss: 2.4505354819759244

Epoch: 5| Step: 5
Training loss: 2.058684825897217
Validation loss: 2.4504884032792944

Epoch: 5| Step: 6
Training loss: 1.922568678855896
Validation loss: 2.4558236957878194

Epoch: 5| Step: 7
Training loss: 2.9308574199676514
Validation loss: 2.44960892328652

Epoch: 5| Step: 8
Training loss: 3.386979341506958
Validation loss: 2.4396996626289944

Epoch: 5| Step: 9
Training loss: 3.10127592086792
Validation loss: 2.4476548881940943

Epoch: 5| Step: 10
Training loss: 1.9972177743911743
Validation loss: 2.4495588989667993

Epoch: 172| Step: 0
Training loss: 2.5542352199554443
Validation loss: 2.450032182919082

Epoch: 5| Step: 1
Training loss: 2.389958620071411
Validation loss: 2.471718599719386

Epoch: 5| Step: 2
Training loss: 2.9395010471343994
Validation loss: 2.471962146861579

Epoch: 5| Step: 3
Training loss: 2.1643261909484863
Validation loss: 2.4904892854793097

Epoch: 5| Step: 4
Training loss: 2.9809792041778564
Validation loss: 2.477067526950631

Epoch: 5| Step: 5
Training loss: 2.0945019721984863
Validation loss: 2.480589794856246

Epoch: 5| Step: 6
Training loss: 3.368943691253662
Validation loss: 2.490770327147617

Epoch: 5| Step: 7
Training loss: 1.8204797506332397
Validation loss: 2.468145360228836

Epoch: 5| Step: 8
Training loss: 2.466029644012451
Validation loss: 2.463178485952398

Epoch: 5| Step: 9
Training loss: 3.2693848609924316
Validation loss: 2.439334754020937

Epoch: 5| Step: 10
Training loss: 2.634169101715088
Validation loss: 2.437223785667009

Epoch: 173| Step: 0
Training loss: 1.9493074417114258
Validation loss: 2.4267618527976413

Epoch: 5| Step: 1
Training loss: 3.220855712890625
Validation loss: 2.425258887711392

Epoch: 5| Step: 2
Training loss: 1.9621740579605103
Validation loss: 2.4238251947587535

Epoch: 5| Step: 3
Training loss: 3.1160807609558105
Validation loss: 2.4291401473424767

Epoch: 5| Step: 4
Training loss: 2.4584033489227295
Validation loss: 2.4355395352968605

Epoch: 5| Step: 5
Training loss: 2.4506747722625732
Validation loss: 2.4257033883884387

Epoch: 5| Step: 6
Training loss: 2.551896572113037
Validation loss: 2.4334744689285115

Epoch: 5| Step: 7
Training loss: 3.048323392868042
Validation loss: 2.445567064387824

Epoch: 5| Step: 8
Training loss: 2.213305950164795
Validation loss: 2.4394812071195213

Epoch: 5| Step: 9
Training loss: 2.344670534133911
Validation loss: 2.440555190527311

Epoch: 5| Step: 10
Training loss: 3.2384955883026123
Validation loss: 2.429909316442346

Epoch: 174| Step: 0
Training loss: 2.521057605743408
Validation loss: 2.4407027049731185

Epoch: 5| Step: 1
Training loss: 2.313175916671753
Validation loss: 2.4370276825402373

Epoch: 5| Step: 2
Training loss: 2.715749740600586
Validation loss: 2.460889306119693

Epoch: 5| Step: 3
Training loss: 3.0883212089538574
Validation loss: 2.4537314650832966

Epoch: 5| Step: 4
Training loss: 2.83742618560791
Validation loss: 2.44906569809042

Epoch: 5| Step: 5
Training loss: 2.298943281173706
Validation loss: 2.4579785793058333

Epoch: 5| Step: 6
Training loss: 2.070497512817383
Validation loss: 2.4558039890822543

Epoch: 5| Step: 7
Training loss: 2.5838570594787598
Validation loss: 2.4638246208108883

Epoch: 5| Step: 8
Training loss: 2.8473756313323975
Validation loss: 2.452604824496854

Epoch: 5| Step: 9
Training loss: 3.2735629081726074
Validation loss: 2.4568120253983365

Epoch: 5| Step: 10
Training loss: 1.9247459173202515
Validation loss: 2.44534537869115

Epoch: 175| Step: 0
Training loss: 2.5097155570983887
Validation loss: 2.433468587936894

Epoch: 5| Step: 1
Training loss: 3.0199313163757324
Validation loss: 2.4475978189899075

Epoch: 5| Step: 2
Training loss: 2.2341182231903076
Validation loss: 2.4469953326768774

Epoch: 5| Step: 3
Training loss: 2.4842638969421387
Validation loss: 2.4404276878603044

Epoch: 5| Step: 4
Training loss: 2.8808963298797607
Validation loss: 2.4351460626048427

Epoch: 5| Step: 5
Training loss: 2.502018451690674
Validation loss: 2.4258416493733725

Epoch: 5| Step: 6
Training loss: 2.7164883613586426
Validation loss: 2.4262541135152182

Epoch: 5| Step: 7
Training loss: 2.2342047691345215
Validation loss: 2.420045527078772

Epoch: 5| Step: 8
Training loss: 2.789361000061035
Validation loss: 2.4266344142216507

Epoch: 5| Step: 9
Training loss: 3.3690688610076904
Validation loss: 2.4278190469229095

Epoch: 5| Step: 10
Training loss: 1.5988149642944336
Validation loss: 2.4216998110535326

Epoch: 176| Step: 0
Training loss: 2.728681802749634
Validation loss: 2.434720141913301

Epoch: 5| Step: 1
Training loss: 2.844569206237793
Validation loss: 2.4266044119352936

Epoch: 5| Step: 2
Training loss: 1.9889755249023438
Validation loss: 2.4197097747556624

Epoch: 5| Step: 3
Training loss: 2.7063446044921875
Validation loss: 2.4295320421136837

Epoch: 5| Step: 4
Training loss: 2.838273763656616
Validation loss: 2.423534493292532

Epoch: 5| Step: 5
Training loss: 2.559282064437866
Validation loss: 2.430743867351163

Epoch: 5| Step: 6
Training loss: 2.388784408569336
Validation loss: 2.4319228818339687

Epoch: 5| Step: 7
Training loss: 2.0283565521240234
Validation loss: 2.4318552376121603

Epoch: 5| Step: 8
Training loss: 3.379732608795166
Validation loss: 2.429540011190599

Epoch: 5| Step: 9
Training loss: 2.6917474269866943
Validation loss: 2.444052239899994

Epoch: 5| Step: 10
Training loss: 2.245718479156494
Validation loss: 2.4390916119339647

Epoch: 177| Step: 0
Training loss: 2.108132839202881
Validation loss: 2.4430931665564097

Epoch: 5| Step: 1
Training loss: 2.937718152999878
Validation loss: 2.4635478988770516

Epoch: 5| Step: 2
Training loss: 2.3180599212646484
Validation loss: 2.463010372654084

Epoch: 5| Step: 3
Training loss: 2.995138168334961
Validation loss: 2.453369632844002

Epoch: 5| Step: 4
Training loss: 3.7984275817871094
Validation loss: 2.4586215813954673

Epoch: 5| Step: 5
Training loss: 2.067852258682251
Validation loss: 2.4624920506631174

Epoch: 5| Step: 6
Training loss: 2.9854114055633545
Validation loss: 2.4364455053883214

Epoch: 5| Step: 7
Training loss: 2.2106616497039795
Validation loss: 2.442560277959352

Epoch: 5| Step: 8
Training loss: 2.518233060836792
Validation loss: 2.4382775932229976

Epoch: 5| Step: 9
Training loss: 2.146848201751709
Validation loss: 2.432372969965781

Epoch: 5| Step: 10
Training loss: 2.479207992553711
Validation loss: 2.425737186144757

Epoch: 178| Step: 0
Training loss: 2.1779448986053467
Validation loss: 2.4240931772416636

Epoch: 5| Step: 1
Training loss: 2.8078196048736572
Validation loss: 2.436493273704283

Epoch: 5| Step: 2
Training loss: 2.8987860679626465
Validation loss: 2.4392638565391622

Epoch: 5| Step: 3
Training loss: 2.6510589122772217
Validation loss: 2.4358542632031184

Epoch: 5| Step: 4
Training loss: 2.653355836868286
Validation loss: 2.443924114268313

Epoch: 5| Step: 5
Training loss: 2.5162699222564697
Validation loss: 2.424609876448108

Epoch: 5| Step: 6
Training loss: 2.449643135070801
Validation loss: 2.43061686331226

Epoch: 5| Step: 7
Training loss: 2.466172695159912
Validation loss: 2.4252940557336293

Epoch: 5| Step: 8
Training loss: 2.266634941101074
Validation loss: 2.425930179575438

Epoch: 5| Step: 9
Training loss: 3.140392541885376
Validation loss: 2.4305243979218187

Epoch: 5| Step: 10
Training loss: 2.4452168941497803
Validation loss: 2.4296282875922417

Epoch: 179| Step: 0
Training loss: 2.9592156410217285
Validation loss: 2.4287723495114233

Epoch: 5| Step: 1
Training loss: 2.0924792289733887
Validation loss: 2.4481181213932652

Epoch: 5| Step: 2
Training loss: 2.332465648651123
Validation loss: 2.443315598272508

Epoch: 5| Step: 3
Training loss: 2.384398937225342
Validation loss: 2.452558776383759

Epoch: 5| Step: 4
Training loss: 2.903848171234131
Validation loss: 2.458223248040804

Epoch: 5| Step: 5
Training loss: 2.5845980644226074
Validation loss: 2.4710854381643315

Epoch: 5| Step: 6
Training loss: 2.784437417984009
Validation loss: 2.457885191004763

Epoch: 5| Step: 7
Training loss: 2.442737102508545
Validation loss: 2.4546580853000766

Epoch: 5| Step: 8
Training loss: 2.6997694969177246
Validation loss: 2.4463861680799917

Epoch: 5| Step: 9
Training loss: 3.1172935962677
Validation loss: 2.453181425730387

Epoch: 5| Step: 10
Training loss: 2.031374216079712
Validation loss: 2.4578098430428454

Epoch: 180| Step: 0
Training loss: 3.213961362838745
Validation loss: 2.4485719280858196

Epoch: 5| Step: 1
Training loss: 2.382512092590332
Validation loss: 2.4553507758725073

Epoch: 5| Step: 2
Training loss: 1.9836986064910889
Validation loss: 2.44438410318026

Epoch: 5| Step: 3
Training loss: 2.7100305557250977
Validation loss: 2.430642540736865

Epoch: 5| Step: 4
Training loss: 2.9406638145446777
Validation loss: 2.431928066797154

Epoch: 5| Step: 5
Training loss: 1.6826900243759155
Validation loss: 2.4375517035043366

Epoch: 5| Step: 6
Training loss: 2.734628438949585
Validation loss: 2.4371563747364986

Epoch: 5| Step: 7
Training loss: 2.8885953426361084
Validation loss: 2.4167942154792046

Epoch: 5| Step: 8
Training loss: 2.4485068321228027
Validation loss: 2.416384352150784

Epoch: 5| Step: 9
Training loss: 2.906879186630249
Validation loss: 2.419119473426573

Epoch: 5| Step: 10
Training loss: 2.5963165760040283
Validation loss: 2.4255105398034535

Epoch: 181| Step: 0
Training loss: 2.929218292236328
Validation loss: 2.4245755044362878

Epoch: 5| Step: 1
Training loss: 2.033870220184326
Validation loss: 2.422247694384667

Epoch: 5| Step: 2
Training loss: 3.161344051361084
Validation loss: 2.4274181371094077

Epoch: 5| Step: 3
Training loss: 2.639556884765625
Validation loss: 2.433776145340294

Epoch: 5| Step: 4
Training loss: 2.3590402603149414
Validation loss: 2.4374621427187355

Epoch: 5| Step: 5
Training loss: 2.1908202171325684
Validation loss: 2.449017051727541

Epoch: 5| Step: 6
Training loss: 3.1792221069335938
Validation loss: 2.452177324602681

Epoch: 5| Step: 7
Training loss: 2.935047149658203
Validation loss: 2.4639253283059723

Epoch: 5| Step: 8
Training loss: 3.010432720184326
Validation loss: 2.4502712757356706

Epoch: 5| Step: 9
Training loss: 1.9730072021484375
Validation loss: 2.446583970900505

Epoch: 5| Step: 10
Training loss: 1.9167393445968628
Validation loss: 2.4511139444125596

Epoch: 182| Step: 0
Training loss: 2.4630324840545654
Validation loss: 2.446795407161918

Epoch: 5| Step: 1
Training loss: 2.211601972579956
Validation loss: 2.4398053076959427

Epoch: 5| Step: 2
Training loss: 3.0909361839294434
Validation loss: 2.4361515686076176

Epoch: 5| Step: 3
Training loss: 2.125795364379883
Validation loss: 2.424572424222064

Epoch: 5| Step: 4
Training loss: 3.10010027885437
Validation loss: 2.4324954504607827

Epoch: 5| Step: 5
Training loss: 2.8151841163635254
Validation loss: 2.433673240805185

Epoch: 5| Step: 6
Training loss: 2.5772881507873535
Validation loss: 2.427368871627315

Epoch: 5| Step: 7
Training loss: 2.3263065814971924
Validation loss: 2.428523640478811

Epoch: 5| Step: 8
Training loss: 2.513201951980591
Validation loss: 2.4367342379785355

Epoch: 5| Step: 9
Training loss: 2.0102245807647705
Validation loss: 2.4391435141204507

Epoch: 5| Step: 10
Training loss: 3.2134039402008057
Validation loss: 2.4469465747956307

Epoch: 183| Step: 0
Training loss: 3.2841835021972656
Validation loss: 2.438537659183625

Epoch: 5| Step: 1
Training loss: 2.533858060836792
Validation loss: 2.446921266535277

Epoch: 5| Step: 2
Training loss: 2.2923378944396973
Validation loss: 2.44761759491377

Epoch: 5| Step: 3
Training loss: 1.9309965372085571
Validation loss: 2.4708203654135428

Epoch: 5| Step: 4
Training loss: 2.911665439605713
Validation loss: 2.459758917490641

Epoch: 5| Step: 5
Training loss: 2.4908227920532227
Validation loss: 2.4713196293000252

Epoch: 5| Step: 6
Training loss: 2.6443562507629395
Validation loss: 2.459648688634237

Epoch: 5| Step: 7
Training loss: 3.1406280994415283
Validation loss: 2.454698988186416

Epoch: 5| Step: 8
Training loss: 2.207613706588745
Validation loss: 2.44516154514846

Epoch: 5| Step: 9
Training loss: 2.566450357437134
Validation loss: 2.429962385085321

Epoch: 5| Step: 10
Training loss: 2.411297082901001
Validation loss: 2.431641863238427

Epoch: 184| Step: 0
Training loss: 3.0183520317077637
Validation loss: 2.428371614025485

Epoch: 5| Step: 1
Training loss: 2.622763156890869
Validation loss: 2.4275291248034407

Epoch: 5| Step: 2
Training loss: 2.6974663734436035
Validation loss: 2.4231761527317826

Epoch: 5| Step: 3
Training loss: 2.3684194087982178
Validation loss: 2.4241099742151078

Epoch: 5| Step: 4
Training loss: 2.6140804290771484
Validation loss: 2.4278765532278244

Epoch: 5| Step: 5
Training loss: 1.5592200756072998
Validation loss: 2.4256739052393104

Epoch: 5| Step: 6
Training loss: 2.7061591148376465
Validation loss: 2.4321172288669053

Epoch: 5| Step: 7
Training loss: 3.0607590675354004
Validation loss: 2.4260292822314846

Epoch: 5| Step: 8
Training loss: 2.1541600227355957
Validation loss: 2.4301345104812295

Epoch: 5| Step: 9
Training loss: 3.2709927558898926
Validation loss: 2.421900826115762

Epoch: 5| Step: 10
Training loss: 2.3372249603271484
Validation loss: 2.4125288007079915

Epoch: 185| Step: 0
Training loss: 2.0949602127075195
Validation loss: 2.416536413213258

Epoch: 5| Step: 1
Training loss: 2.6045570373535156
Validation loss: 2.429506940226401

Epoch: 5| Step: 2
Training loss: 2.663127899169922
Validation loss: 2.427709899922853

Epoch: 5| Step: 3
Training loss: 1.8978580236434937
Validation loss: 2.427022578895733

Epoch: 5| Step: 4
Training loss: 2.613837957382202
Validation loss: 2.4402708212534585

Epoch: 5| Step: 5
Training loss: 3.122412919998169
Validation loss: 2.431983132516184

Epoch: 5| Step: 6
Training loss: 2.7042934894561768
Validation loss: 2.427829191248904

Epoch: 5| Step: 7
Training loss: 2.643864393234253
Validation loss: 2.4320635872502483

Epoch: 5| Step: 8
Training loss: 2.771435022354126
Validation loss: 2.4218912252815823

Epoch: 5| Step: 9
Training loss: 2.3064568042755127
Validation loss: 2.4159365905228483

Epoch: 5| Step: 10
Training loss: 3.1357898712158203
Validation loss: 2.408428510030111

Epoch: 186| Step: 0
Training loss: 2.8208649158477783
Validation loss: 2.4119087855021157

Epoch: 5| Step: 1
Training loss: 2.6363329887390137
Validation loss: 2.406388182793894

Epoch: 5| Step: 2
Training loss: 2.6672561168670654
Validation loss: 2.418034771437286

Epoch: 5| Step: 3
Training loss: 3.0131611824035645
Validation loss: 2.413100614342638

Epoch: 5| Step: 4
Training loss: 2.3616559505462646
Validation loss: 2.4147975137156825

Epoch: 5| Step: 5
Training loss: 2.6506807804107666
Validation loss: 2.422035050648515

Epoch: 5| Step: 6
Training loss: 2.4111168384552
Validation loss: 2.415366752173311

Epoch: 5| Step: 7
Training loss: 2.4419028759002686
Validation loss: 2.4264675289072017

Epoch: 5| Step: 8
Training loss: 2.511359691619873
Validation loss: 2.4238378078706804

Epoch: 5| Step: 9
Training loss: 2.4983084201812744
Validation loss: 2.4135947970933813

Epoch: 5| Step: 10
Training loss: 2.2405025959014893
Validation loss: 2.407720394031976

Epoch: 187| Step: 0
Training loss: 2.7747280597686768
Validation loss: 2.4241577938038814

Epoch: 5| Step: 1
Training loss: 3.0520052909851074
Validation loss: 2.4295768917247815

Epoch: 5| Step: 2
Training loss: 2.201948881149292
Validation loss: 2.424277461985106

Epoch: 5| Step: 3
Training loss: 2.203402280807495
Validation loss: 2.4370632556176957

Epoch: 5| Step: 4
Training loss: 2.4072861671447754
Validation loss: 2.4402997032288583

Epoch: 5| Step: 5
Training loss: 2.8341031074523926
Validation loss: 2.4321714703754713

Epoch: 5| Step: 6
Training loss: 2.0138771533966064
Validation loss: 2.4406505118134203

Epoch: 5| Step: 7
Training loss: 2.7152466773986816
Validation loss: 2.439760208129883

Epoch: 5| Step: 8
Training loss: 3.058168411254883
Validation loss: 2.441394152179841

Epoch: 5| Step: 9
Training loss: 2.2128491401672363
Validation loss: 2.43025565403764

Epoch: 5| Step: 10
Training loss: 2.8796496391296387
Validation loss: 2.4334229884609098

Epoch: 188| Step: 0
Training loss: 2.803678035736084
Validation loss: 2.428296373736474

Epoch: 5| Step: 1
Training loss: 2.684699535369873
Validation loss: 2.419620672861735

Epoch: 5| Step: 2
Training loss: 3.0237908363342285
Validation loss: 2.41173521677653

Epoch: 5| Step: 3
Training loss: 1.891920804977417
Validation loss: 2.416030787652539

Epoch: 5| Step: 4
Training loss: 2.334127902984619
Validation loss: 2.4209338823954263

Epoch: 5| Step: 5
Training loss: 2.946566343307495
Validation loss: 2.4210212307591594

Epoch: 5| Step: 6
Training loss: 2.13864803314209
Validation loss: 2.4150087320676414

Epoch: 5| Step: 7
Training loss: 2.1185083389282227
Validation loss: 2.4270165710039038

Epoch: 5| Step: 8
Training loss: 2.309964656829834
Validation loss: 2.42047425752045

Epoch: 5| Step: 9
Training loss: 3.6727073192596436
Validation loss: 2.4357756773630777

Epoch: 5| Step: 10
Training loss: 2.397874593734741
Validation loss: 2.4273138405174337

Epoch: 189| Step: 0
Training loss: 2.193286895751953
Validation loss: 2.43305875409034

Epoch: 5| Step: 1
Training loss: 2.2591233253479004
Validation loss: 2.4528038706830753

Epoch: 5| Step: 2
Training loss: 2.7146623134613037
Validation loss: 2.4418633137979815

Epoch: 5| Step: 3
Training loss: 3.0004711151123047
Validation loss: 2.4466616133207917

Epoch: 5| Step: 4
Training loss: 2.6040000915527344
Validation loss: 2.459460278993012

Epoch: 5| Step: 5
Training loss: 2.111431837081909
Validation loss: 2.447715392676733

Epoch: 5| Step: 6
Training loss: 2.632209300994873
Validation loss: 2.4395901003191547

Epoch: 5| Step: 7
Training loss: 2.6079492568969727
Validation loss: 2.420603370153776

Epoch: 5| Step: 8
Training loss: 2.9955601692199707
Validation loss: 2.422204191966723

Epoch: 5| Step: 9
Training loss: 2.559356451034546
Validation loss: 2.406942972572901

Epoch: 5| Step: 10
Training loss: 2.672910451889038
Validation loss: 2.389143043948758

Epoch: 190| Step: 0
Training loss: 2.994713544845581
Validation loss: 2.3937412769563737

Epoch: 5| Step: 1
Training loss: 3.2840735912323
Validation loss: 2.393418865819131

Epoch: 5| Step: 2
Training loss: 2.4456655979156494
Validation loss: 2.3931052659147527

Epoch: 5| Step: 3
Training loss: 2.272890567779541
Validation loss: 2.3901112976894585

Epoch: 5| Step: 4
Training loss: 2.223226308822632
Validation loss: 2.395029349993634

Epoch: 5| Step: 5
Training loss: 2.405338764190674
Validation loss: 2.4039035843264673

Epoch: 5| Step: 6
Training loss: 2.883441209793091
Validation loss: 2.4023912568246164

Epoch: 5| Step: 7
Training loss: 2.368018388748169
Validation loss: 2.4009107723030993

Epoch: 5| Step: 8
Training loss: 2.707256555557251
Validation loss: 2.3950530828968173

Epoch: 5| Step: 9
Training loss: 2.424903392791748
Validation loss: 2.409416546103775

Epoch: 5| Step: 10
Training loss: 2.366234302520752
Validation loss: 2.4136122734315935

Epoch: 191| Step: 0
Training loss: 2.5451831817626953
Validation loss: 2.418290312572192

Epoch: 5| Step: 1
Training loss: 2.256967067718506
Validation loss: 2.438335157209827

Epoch: 5| Step: 2
Training loss: 3.211695432662964
Validation loss: 2.438240938289191

Epoch: 5| Step: 3
Training loss: 3.1598002910614014
Validation loss: 2.4486455609721522

Epoch: 5| Step: 4
Training loss: 1.9863914251327515
Validation loss: 2.455501889669767

Epoch: 5| Step: 5
Training loss: 2.3371517658233643
Validation loss: 2.4270604759134273

Epoch: 5| Step: 6
Training loss: 2.5656418800354004
Validation loss: 2.435549236113025

Epoch: 5| Step: 7
Training loss: 2.2218544483184814
Validation loss: 2.428793135509696

Epoch: 5| Step: 8
Training loss: 2.958073377609253
Validation loss: 2.4236211199914255

Epoch: 5| Step: 9
Training loss: 2.2238967418670654
Validation loss: 2.4066345717317317

Epoch: 5| Step: 10
Training loss: 2.953948736190796
Validation loss: 2.402956344748056

Epoch: 192| Step: 0
Training loss: 2.230720043182373
Validation loss: 2.402548449013823

Epoch: 5| Step: 1
Training loss: 2.1439900398254395
Validation loss: 2.3926604332462436

Epoch: 5| Step: 2
Training loss: 2.5992989540100098
Validation loss: 2.3858050069501324

Epoch: 5| Step: 3
Training loss: 2.7026805877685547
Validation loss: 2.400163640258133

Epoch: 5| Step: 4
Training loss: 2.852675199508667
Validation loss: 2.390376619113389

Epoch: 5| Step: 5
Training loss: 3.0536580085754395
Validation loss: 2.387988672461561

Epoch: 5| Step: 6
Training loss: 2.4554760456085205
Validation loss: 2.3921860905103784

Epoch: 5| Step: 7
Training loss: 3.0258758068084717
Validation loss: 2.3878025393332205

Epoch: 5| Step: 8
Training loss: 2.4737749099731445
Validation loss: 2.3939952517068512

Epoch: 5| Step: 9
Training loss: 3.056159019470215
Validation loss: 2.394179344177246

Epoch: 5| Step: 10
Training loss: 1.6085675954818726
Validation loss: 2.3973938803518973

Epoch: 193| Step: 0
Training loss: 2.729046583175659
Validation loss: 2.406853296423471

Epoch: 5| Step: 1
Training loss: 3.232445240020752
Validation loss: 2.412675937016805

Epoch: 5| Step: 2
Training loss: 2.429375648498535
Validation loss: 2.429704035482099

Epoch: 5| Step: 3
Training loss: 2.2417190074920654
Validation loss: 2.431861395476967

Epoch: 5| Step: 4
Training loss: 2.443934202194214
Validation loss: 2.4328792889912925

Epoch: 5| Step: 5
Training loss: 2.3760831356048584
Validation loss: 2.4239251664889756

Epoch: 5| Step: 6
Training loss: 2.2236380577087402
Validation loss: 2.4384283583651305

Epoch: 5| Step: 7
Training loss: 3.024381160736084
Validation loss: 2.4352897674806657

Epoch: 5| Step: 8
Training loss: 2.2125649452209473
Validation loss: 2.4253593311514905

Epoch: 5| Step: 9
Training loss: 2.513965606689453
Validation loss: 2.4246575268366004

Epoch: 5| Step: 10
Training loss: 2.950354814529419
Validation loss: 2.4302600327358452

Epoch: 194| Step: 0
Training loss: 2.193899154663086
Validation loss: 2.421094386808334

Epoch: 5| Step: 1
Training loss: 2.5411951541900635
Validation loss: 2.4151817111558813

Epoch: 5| Step: 2
Training loss: 2.657108783721924
Validation loss: 2.404346150736655

Epoch: 5| Step: 3
Training loss: 2.8932976722717285
Validation loss: 2.4072799785162813

Epoch: 5| Step: 4
Training loss: 2.7997469902038574
Validation loss: 2.4085124692609234

Epoch: 5| Step: 5
Training loss: 3.085716962814331
Validation loss: 2.3959875516994025

Epoch: 5| Step: 6
Training loss: 1.9313859939575195
Validation loss: 2.4089774188174995

Epoch: 5| Step: 7
Training loss: 2.5940146446228027
Validation loss: 2.405524020553917

Epoch: 5| Step: 8
Training loss: 2.6701366901397705
Validation loss: 2.4218315437275875

Epoch: 5| Step: 9
Training loss: 2.138500928878784
Validation loss: 2.413322517948766

Epoch: 5| Step: 10
Training loss: 2.7321226596832275
Validation loss: 2.420005998303813

Epoch: 195| Step: 0
Training loss: 2.1978278160095215
Validation loss: 2.424125979023595

Epoch: 5| Step: 1
Training loss: 1.9462312459945679
Validation loss: 2.426629509977115

Epoch: 5| Step: 2
Training loss: 2.6018571853637695
Validation loss: 2.423717357779062

Epoch: 5| Step: 3
Training loss: 2.125046968460083
Validation loss: 2.430119922084193

Epoch: 5| Step: 4
Training loss: 2.8980560302734375
Validation loss: 2.419790429453696

Epoch: 5| Step: 5
Training loss: 3.2120234966278076
Validation loss: 2.4117408465313654

Epoch: 5| Step: 6
Training loss: 2.368218421936035
Validation loss: 2.407507058112852

Epoch: 5| Step: 7
Training loss: 2.441910982131958
Validation loss: 2.4015881784500612

Epoch: 5| Step: 8
Training loss: 2.883587598800659
Validation loss: 2.407418635583693

Epoch: 5| Step: 9
Training loss: 3.1116161346435547
Validation loss: 2.4095565862553094

Epoch: 5| Step: 10
Training loss: 2.3793890476226807
Validation loss: 2.4043357756830033

Epoch: 196| Step: 0
Training loss: 2.684359312057495
Validation loss: 2.405167950096951

Epoch: 5| Step: 1
Training loss: 1.6364519596099854
Validation loss: 2.418742213197934

Epoch: 5| Step: 2
Training loss: 2.6303253173828125
Validation loss: 2.4094850658088602

Epoch: 5| Step: 3
Training loss: 3.033327579498291
Validation loss: 2.41204301516215

Epoch: 5| Step: 4
Training loss: 2.710899829864502
Validation loss: 2.4146691432563205

Epoch: 5| Step: 5
Training loss: 2.316638469696045
Validation loss: 2.4055301168913483

Epoch: 5| Step: 6
Training loss: 3.003068447113037
Validation loss: 2.413917156957811

Epoch: 5| Step: 7
Training loss: 2.0374457836151123
Validation loss: 2.4268548052798034

Epoch: 5| Step: 8
Training loss: 2.486157178878784
Validation loss: 2.4130214183561263

Epoch: 5| Step: 9
Training loss: 2.7575840950012207
Validation loss: 2.418003935967722

Epoch: 5| Step: 10
Training loss: 2.92253041267395
Validation loss: 2.4218005211122575

Epoch: 197| Step: 0
Training loss: 3.658557176589966
Validation loss: 2.4144342407103507

Epoch: 5| Step: 1
Training loss: 1.4128329753875732
Validation loss: 2.4085416460549958

Epoch: 5| Step: 2
Training loss: 2.3681585788726807
Validation loss: 2.4257777557578137

Epoch: 5| Step: 3
Training loss: 2.698577404022217
Validation loss: 2.4314984993268083

Epoch: 5| Step: 4
Training loss: 2.215446949005127
Validation loss: 2.44324492895475

Epoch: 5| Step: 5
Training loss: 2.679037094116211
Validation loss: 2.4426692352500012

Epoch: 5| Step: 6
Training loss: 2.768775463104248
Validation loss: 2.456319773068992

Epoch: 5| Step: 7
Training loss: 2.903532028198242
Validation loss: 2.451475589506088

Epoch: 5| Step: 8
Training loss: 2.6494650840759277
Validation loss: 2.4412906887710735

Epoch: 5| Step: 9
Training loss: 2.4536867141723633
Validation loss: 2.4287197487328642

Epoch: 5| Step: 10
Training loss: 2.3762710094451904
Validation loss: 2.4136410618341095

Epoch: 198| Step: 0
Training loss: 2.424821138381958
Validation loss: 2.4102279575922156

Epoch: 5| Step: 1
Training loss: 3.4269516468048096
Validation loss: 2.395884903528357

Epoch: 5| Step: 2
Training loss: 2.634427309036255
Validation loss: 2.405057309776224

Epoch: 5| Step: 3
Training loss: 2.132047176361084
Validation loss: 2.386224856940649

Epoch: 5| Step: 4
Training loss: 2.4999186992645264
Validation loss: 2.392110360566006

Epoch: 5| Step: 5
Training loss: 2.8214163780212402
Validation loss: 2.394704562361522

Epoch: 5| Step: 6
Training loss: 2.6235287189483643
Validation loss: 2.385589599609375

Epoch: 5| Step: 7
Training loss: 2.139124631881714
Validation loss: 2.390739679336548

Epoch: 5| Step: 8
Training loss: 2.110696315765381
Validation loss: 2.3899915090171238

Epoch: 5| Step: 9
Training loss: 2.880632162094116
Validation loss: 2.39698508093434

Epoch: 5| Step: 10
Training loss: 2.4524073600769043
Validation loss: 2.389205132761309

Epoch: 199| Step: 0
Training loss: 2.940687894821167
Validation loss: 2.401133177100971

Epoch: 5| Step: 1
Training loss: 2.8732352256774902
Validation loss: 2.3994093889831216

Epoch: 5| Step: 2
Training loss: 2.443638324737549
Validation loss: 2.404006693952827

Epoch: 5| Step: 3
Training loss: 2.410611391067505
Validation loss: 2.4128656694965978

Epoch: 5| Step: 4
Training loss: 2.556051254272461
Validation loss: 2.4126300555403515

Epoch: 5| Step: 5
Training loss: 1.8505338430404663
Validation loss: 2.4122094415849253

Epoch: 5| Step: 6
Training loss: 2.7961325645446777
Validation loss: 2.409243259378659

Epoch: 5| Step: 7
Training loss: 2.808692455291748
Validation loss: 2.407741620976438

Epoch: 5| Step: 8
Training loss: 2.8898017406463623
Validation loss: 2.3997453720338884

Epoch: 5| Step: 9
Training loss: 2.5490424633026123
Validation loss: 2.4011879403104066

Epoch: 5| Step: 10
Training loss: 1.9899818897247314
Validation loss: 2.3929785887400308

Epoch: 200| Step: 0
Training loss: 2.666058301925659
Validation loss: 2.4058855502836165

Epoch: 5| Step: 1
Training loss: 2.754138231277466
Validation loss: 2.411638629051947

Epoch: 5| Step: 2
Training loss: 2.8236632347106934
Validation loss: 2.4189874228610786

Epoch: 5| Step: 3
Training loss: 2.064877510070801
Validation loss: 2.414497139633343

Epoch: 5| Step: 4
Training loss: 3.1843819618225098
Validation loss: 2.418999775763481

Epoch: 5| Step: 5
Training loss: 1.975782036781311
Validation loss: 2.4117023688490673

Epoch: 5| Step: 6
Training loss: 2.616699695587158
Validation loss: 2.4156866201790432

Epoch: 5| Step: 7
Training loss: 2.7495064735412598
Validation loss: 2.421886956819924

Epoch: 5| Step: 8
Training loss: 2.6584129333496094
Validation loss: 2.4190996282844135

Epoch: 5| Step: 9
Training loss: 2.4607396125793457
Validation loss: 2.4113571490010908

Epoch: 5| Step: 10
Training loss: 2.1859381198883057
Validation loss: 2.4179981934126986

Epoch: 201| Step: 0
Training loss: 2.550240993499756
Validation loss: 2.4298119083527596

Epoch: 5| Step: 1
Training loss: 2.5139925479888916
Validation loss: 2.422761150585708

Epoch: 5| Step: 2
Training loss: 1.7213070392608643
Validation loss: 2.4216623357547227

Epoch: 5| Step: 3
Training loss: 2.351081371307373
Validation loss: 2.42530930683177

Epoch: 5| Step: 4
Training loss: 2.6588706970214844
Validation loss: 2.4252767896139495

Epoch: 5| Step: 5
Training loss: 2.5512664318084717
Validation loss: 2.4152154768666914

Epoch: 5| Step: 6
Training loss: 2.7053894996643066
Validation loss: 2.403410550086729

Epoch: 5| Step: 7
Training loss: 2.458979368209839
Validation loss: 2.4132227513097946

Epoch: 5| Step: 8
Training loss: 2.748264789581299
Validation loss: 2.4161217738223333

Epoch: 5| Step: 9
Training loss: 2.9282994270324707
Validation loss: 2.415983497455556

Epoch: 5| Step: 10
Training loss: 3.0016262531280518
Validation loss: 2.4206975634380052

Epoch: 202| Step: 0
Training loss: 2.509969472885132
Validation loss: 2.4142531784631873

Epoch: 5| Step: 1
Training loss: 2.6498425006866455
Validation loss: 2.4015263280560895

Epoch: 5| Step: 2
Training loss: 3.1304712295532227
Validation loss: 2.3843529890942317

Epoch: 5| Step: 3
Training loss: 2.3996875286102295
Validation loss: 2.37949417227058

Epoch: 5| Step: 4
Training loss: 2.138197660446167
Validation loss: 2.373126172250317

Epoch: 5| Step: 5
Training loss: 2.13098406791687
Validation loss: 2.3659790946591284

Epoch: 5| Step: 6
Training loss: 3.4271228313446045
Validation loss: 2.3719731941018054

Epoch: 5| Step: 7
Training loss: 2.7798705101013184
Validation loss: 2.3670066479713685

Epoch: 5| Step: 8
Training loss: 2.434105634689331
Validation loss: 2.3729344362853677

Epoch: 5| Step: 9
Training loss: 2.4580636024475098
Validation loss: 2.3742607690954722

Epoch: 5| Step: 10
Training loss: 2.1723949909210205
Validation loss: 2.3660723214508383

Epoch: 203| Step: 0
Training loss: 2.4814293384552
Validation loss: 2.378897249057729

Epoch: 5| Step: 1
Training loss: 3.155860424041748
Validation loss: 2.3806640563472623

Epoch: 5| Step: 2
Training loss: 2.0859546661376953
Validation loss: 2.394028961017568

Epoch: 5| Step: 3
Training loss: 3.0981457233428955
Validation loss: 2.404637359803723

Epoch: 5| Step: 4
Training loss: 2.8842387199401855
Validation loss: 2.402109928028558

Epoch: 5| Step: 5
Training loss: 2.430346965789795
Validation loss: 2.417249325783022

Epoch: 5| Step: 6
Training loss: 2.4379024505615234
Validation loss: 2.4313525179381013

Epoch: 5| Step: 7
Training loss: 2.3305094242095947
Validation loss: 2.4282004217947684

Epoch: 5| Step: 8
Training loss: 1.9566148519515991
Validation loss: 2.421173652013143

Epoch: 5| Step: 9
Training loss: 2.9094510078430176
Validation loss: 2.421107610066732

Epoch: 5| Step: 10
Training loss: 2.3712193965911865
Validation loss: 2.418160323173769

Epoch: 204| Step: 0
Training loss: 2.2397778034210205
Validation loss: 2.4208989245917207

Epoch: 5| Step: 1
Training loss: 2.1912479400634766
Validation loss: 2.4065679734753025

Epoch: 5| Step: 2
Training loss: 2.3110148906707764
Validation loss: 2.420753338003671

Epoch: 5| Step: 3
Training loss: 2.4235730171203613
Validation loss: 2.4126801106237594

Epoch: 5| Step: 4
Training loss: 2.2751145362854004
Validation loss: 2.4225479300304125

Epoch: 5| Step: 5
Training loss: 2.767228603363037
Validation loss: 2.41538308769144

Epoch: 5| Step: 6
Training loss: 3.1856467723846436
Validation loss: 2.4019899368286133

Epoch: 5| Step: 7
Training loss: 2.5401673316955566
Validation loss: 2.392859197431995

Epoch: 5| Step: 8
Training loss: 2.5988402366638184
Validation loss: 2.377541918908396

Epoch: 5| Step: 9
Training loss: 2.450329065322876
Validation loss: 2.369159416485858

Epoch: 5| Step: 10
Training loss: 3.1816041469573975
Validation loss: 2.373995165671072

Epoch: 205| Step: 0
Training loss: 2.718137741088867
Validation loss: 2.3783721488009215

Epoch: 5| Step: 1
Training loss: 3.1811459064483643
Validation loss: 2.371369141404347

Epoch: 5| Step: 2
Training loss: 1.9472577571868896
Validation loss: 2.3736995420148297

Epoch: 5| Step: 3
Training loss: 1.7307894229888916
Validation loss: 2.384348525795885

Epoch: 5| Step: 4
Training loss: 3.307603359222412
Validation loss: 2.38624668634066

Epoch: 5| Step: 5
Training loss: 2.805943489074707
Validation loss: 2.390784502029419

Epoch: 5| Step: 6
Training loss: 2.824399471282959
Validation loss: 2.3910304397665043

Epoch: 5| Step: 7
Training loss: 2.5599746704101562
Validation loss: 2.389563447685652

Epoch: 5| Step: 8
Training loss: 1.8134849071502686
Validation loss: 2.38646500854082

Epoch: 5| Step: 9
Training loss: 2.70902943611145
Validation loss: 2.3979662695238666

Epoch: 5| Step: 10
Training loss: 2.4209184646606445
Validation loss: 2.4107613871174474

Epoch: 206| Step: 0
Training loss: 2.606736421585083
Validation loss: 2.4239486109825874

Epoch: 5| Step: 1
Training loss: 2.7228381633758545
Validation loss: 2.442727542692615

Epoch: 5| Step: 2
Training loss: 2.738281011581421
Validation loss: 2.4483849258833033

Epoch: 5| Step: 3
Training loss: 2.5700011253356934
Validation loss: 2.4577741212742303

Epoch: 5| Step: 4
Training loss: 2.9939064979553223
Validation loss: 2.422374750978203

Epoch: 5| Step: 5
Training loss: 3.0620505809783936
Validation loss: 2.4154074371501966

Epoch: 5| Step: 6
Training loss: 2.154654026031494
Validation loss: 2.408587492922301

Epoch: 5| Step: 7
Training loss: 1.4732215404510498
Validation loss: 2.396580673033191

Epoch: 5| Step: 8
Training loss: 2.3333468437194824
Validation loss: 2.3677236854389148

Epoch: 5| Step: 9
Training loss: 2.964268922805786
Validation loss: 2.3868521798041558

Epoch: 5| Step: 10
Training loss: 2.4789881706237793
Validation loss: 2.3873017090623097

Epoch: 207| Step: 0
Training loss: 2.939922332763672
Validation loss: 2.3893889945040465

Epoch: 5| Step: 1
Training loss: 2.4395554065704346
Validation loss: 2.383678856716361

Epoch: 5| Step: 2
Training loss: 2.307339906692505
Validation loss: 2.382785786864578

Epoch: 5| Step: 3
Training loss: 2.1755893230438232
Validation loss: 2.3820449716301373

Epoch: 5| Step: 4
Training loss: 2.1662566661834717
Validation loss: 2.3960170694576797

Epoch: 5| Step: 5
Training loss: 3.3802356719970703
Validation loss: 2.388417141411894

Epoch: 5| Step: 6
Training loss: 2.8313870429992676
Validation loss: 2.405088979710815

Epoch: 5| Step: 7
Training loss: 2.149401903152466
Validation loss: 2.399489245107097

Epoch: 5| Step: 8
Training loss: 2.9296391010284424
Validation loss: 2.427687273230604

Epoch: 5| Step: 9
Training loss: 2.512284755706787
Validation loss: 2.417060089367692

Epoch: 5| Step: 10
Training loss: 2.229327440261841
Validation loss: 2.431848613164758

Epoch: 208| Step: 0
Training loss: 2.288069009780884
Validation loss: 2.409199273714455

Epoch: 5| Step: 1
Training loss: 2.1713271141052246
Validation loss: 2.4074975726425007

Epoch: 5| Step: 2
Training loss: 3.5129456520080566
Validation loss: 2.39029267526442

Epoch: 5| Step: 3
Training loss: 2.517097234725952
Validation loss: 2.396254047270744

Epoch: 5| Step: 4
Training loss: 2.242661714553833
Validation loss: 2.383979300016998

Epoch: 5| Step: 5
Training loss: 2.4263932704925537
Validation loss: 2.3775406217062347

Epoch: 5| Step: 6
Training loss: 2.3998353481292725
Validation loss: 2.3827903193812214

Epoch: 5| Step: 7
Training loss: 2.07521653175354
Validation loss: 2.38397277298794

Epoch: 5| Step: 8
Training loss: 3.1029019355773926
Validation loss: 2.3863801058902534

Epoch: 5| Step: 9
Training loss: 3.0986487865448
Validation loss: 2.3775261845639957

Epoch: 5| Step: 10
Training loss: 2.098869800567627
Validation loss: 2.3891913711383777

Epoch: 209| Step: 0
Training loss: 2.7879245281219482
Validation loss: 2.3960134188334146

Epoch: 5| Step: 1
Training loss: 2.228572368621826
Validation loss: 2.3910027498840005

Epoch: 5| Step: 2
Training loss: 2.8370089530944824
Validation loss: 2.38930146924911

Epoch: 5| Step: 3
Training loss: 2.4623911380767822
Validation loss: 2.3860714717577864

Epoch: 5| Step: 4
Training loss: 3.11445951461792
Validation loss: 2.386521226616316

Epoch: 5| Step: 5
Training loss: 2.569042921066284
Validation loss: 2.3772881671946537

Epoch: 5| Step: 6
Training loss: 2.6057305335998535
Validation loss: 2.3902744682886268

Epoch: 5| Step: 7
Training loss: 2.298776149749756
Validation loss: 2.3897337323875836

Epoch: 5| Step: 8
Training loss: 2.178335666656494
Validation loss: 2.411978639582152

Epoch: 5| Step: 9
Training loss: 2.550908327102661
Validation loss: 2.4130801103448354

Epoch: 5| Step: 10
Training loss: 2.256589651107788
Validation loss: 2.407396267819148

Epoch: 210| Step: 0
Training loss: 3.027832508087158
Validation loss: 2.407097662648847

Epoch: 5| Step: 1
Training loss: 2.702518939971924
Validation loss: 2.4155330734868206

Epoch: 5| Step: 2
Training loss: 2.7267000675201416
Validation loss: 2.411689201990763

Epoch: 5| Step: 3
Training loss: 2.4710869789123535
Validation loss: 2.403738596106088

Epoch: 5| Step: 4
Training loss: 2.2437071800231934
Validation loss: 2.4061365358291136

Epoch: 5| Step: 5
Training loss: 2.0185487270355225
Validation loss: 2.414355683070357

Epoch: 5| Step: 6
Training loss: 2.0627293586730957
Validation loss: 2.3972951160964144

Epoch: 5| Step: 7
Training loss: 2.741619825363159
Validation loss: 2.3937872481602493

Epoch: 5| Step: 8
Training loss: 2.501616954803467
Validation loss: 2.4018442118039696

Epoch: 5| Step: 9
Training loss: 2.6311440467834473
Validation loss: 2.4028360792385635

Epoch: 5| Step: 10
Training loss: 3.0195016860961914
Validation loss: 2.3958060587606123

Epoch: 211| Step: 0
Training loss: 2.62379789352417
Validation loss: 2.4285448417868665

Epoch: 5| Step: 1
Training loss: 3.0392889976501465
Validation loss: 2.4273010274415374

Epoch: 5| Step: 2
Training loss: 2.5360679626464844
Validation loss: 2.419174999319097

Epoch: 5| Step: 3
Training loss: 2.4338293075561523
Validation loss: 2.430939410322456

Epoch: 5| Step: 4
Training loss: 1.8464666604995728
Validation loss: 2.4151980594922136

Epoch: 5| Step: 5
Training loss: 2.955533504486084
Validation loss: 2.407398562277517

Epoch: 5| Step: 6
Training loss: 2.424285888671875
Validation loss: 2.3951078512335338

Epoch: 5| Step: 7
Training loss: 3.264888286590576
Validation loss: 2.38981395383035

Epoch: 5| Step: 8
Training loss: 2.1068131923675537
Validation loss: 2.3803408043358916

Epoch: 5| Step: 9
Training loss: 2.0286219120025635
Validation loss: 2.394334318817303

Epoch: 5| Step: 10
Training loss: 2.6699929237365723
Validation loss: 2.3843487847235894

Epoch: 212| Step: 0
Training loss: 2.684572696685791
Validation loss: 2.389544738236294

Epoch: 5| Step: 1
Training loss: 2.9070675373077393
Validation loss: 2.393787166123749

Epoch: 5| Step: 2
Training loss: 2.469852924346924
Validation loss: 2.3832276944191224

Epoch: 5| Step: 3
Training loss: 2.385779857635498
Validation loss: 2.382566390498992

Epoch: 5| Step: 4
Training loss: 2.3410370349884033
Validation loss: 2.382335885878532

Epoch: 5| Step: 5
Training loss: 3.245786666870117
Validation loss: 2.3926324972542385

Epoch: 5| Step: 6
Training loss: 2.030068874359131
Validation loss: 2.4028893337454846

Epoch: 5| Step: 7
Training loss: 2.2427358627319336
Validation loss: 2.385714905236357

Epoch: 5| Step: 8
Training loss: 2.1881165504455566
Validation loss: 2.400400048942976

Epoch: 5| Step: 9
Training loss: 2.7803094387054443
Validation loss: 2.3947845658948346

Epoch: 5| Step: 10
Training loss: 2.7015833854675293
Validation loss: 2.396015872237503

Epoch: 213| Step: 0
Training loss: 2.7486677169799805
Validation loss: 2.3977888271372807

Epoch: 5| Step: 1
Training loss: 2.090557813644409
Validation loss: 2.393344863768547

Epoch: 5| Step: 2
Training loss: 3.0249924659729004
Validation loss: 2.391593799796156

Epoch: 5| Step: 3
Training loss: 1.9105110168457031
Validation loss: 2.375268131174067

Epoch: 5| Step: 4
Training loss: 2.664726734161377
Validation loss: 2.37709443799911

Epoch: 5| Step: 5
Training loss: 2.352789878845215
Validation loss: 2.376037020837107

Epoch: 5| Step: 6
Training loss: 3.1035842895507812
Validation loss: 2.3858787423820904

Epoch: 5| Step: 7
Training loss: 2.17938232421875
Validation loss: 2.379803790841051

Epoch: 5| Step: 8
Training loss: 2.6433043479919434
Validation loss: 2.389442173383569

Epoch: 5| Step: 9
Training loss: 2.783400774002075
Validation loss: 2.3922779226815827

Epoch: 5| Step: 10
Training loss: 2.447096586227417
Validation loss: 2.394135828941099

Epoch: 214| Step: 0
Training loss: 1.8906805515289307
Validation loss: 2.3988954226175943

Epoch: 5| Step: 1
Training loss: 2.470923900604248
Validation loss: 2.4081754376811366

Epoch: 5| Step: 2
Training loss: 3.357367753982544
Validation loss: 2.4163800183162896

Epoch: 5| Step: 3
Training loss: 2.216456651687622
Validation loss: 2.4211668737473024

Epoch: 5| Step: 4
Training loss: 2.5894601345062256
Validation loss: 2.399046408232822

Epoch: 5| Step: 5
Training loss: 2.1912739276885986
Validation loss: 2.3831891603367303

Epoch: 5| Step: 6
Training loss: 2.8983802795410156
Validation loss: 2.3960120062674246

Epoch: 5| Step: 7
Training loss: 2.8409159183502197
Validation loss: 2.3818126801521546

Epoch: 5| Step: 8
Training loss: 2.4045987129211426
Validation loss: 2.381940352019443

Epoch: 5| Step: 9
Training loss: 2.689383029937744
Validation loss: 2.371972026363496

Epoch: 5| Step: 10
Training loss: 2.2958672046661377
Validation loss: 2.3718738607181016

Epoch: 215| Step: 0
Training loss: 2.6682045459747314
Validation loss: 2.392836614321637

Epoch: 5| Step: 1
Training loss: 2.6468160152435303
Validation loss: 2.3824718947051675

Epoch: 5| Step: 2
Training loss: 2.178266763687134
Validation loss: 2.3872404431784027

Epoch: 5| Step: 3
Training loss: 2.6860172748565674
Validation loss: 2.388165056064565

Epoch: 5| Step: 4
Training loss: 3.1917972564697266
Validation loss: 2.3715001793317896

Epoch: 5| Step: 5
Training loss: 1.9563617706298828
Validation loss: 2.3832216032089724

Epoch: 5| Step: 6
Training loss: 2.683022975921631
Validation loss: 2.373784424156271

Epoch: 5| Step: 7
Training loss: 2.142761707305908
Validation loss: 2.3765424246429117

Epoch: 5| Step: 8
Training loss: 2.685389995574951
Validation loss: 2.378131256308607

Epoch: 5| Step: 9
Training loss: 2.9645497798919678
Validation loss: 2.4038365194874425

Epoch: 5| Step: 10
Training loss: 2.064419746398926
Validation loss: 2.394954696778328

Epoch: 216| Step: 0
Training loss: 2.660231113433838
Validation loss: 2.4204695276034776

Epoch: 5| Step: 1
Training loss: 3.016188144683838
Validation loss: 2.4391369947823147

Epoch: 5| Step: 2
Training loss: 1.8556888103485107
Validation loss: 2.4202844045495473

Epoch: 5| Step: 3
Training loss: 2.619549512863159
Validation loss: 2.427703365202873

Epoch: 5| Step: 4
Training loss: 2.7490830421447754
Validation loss: 2.4230431664374565

Epoch: 5| Step: 5
Training loss: 2.803494453430176
Validation loss: 2.4200211545472503

Epoch: 5| Step: 6
Training loss: 2.6864895820617676
Validation loss: 2.4119167225335234

Epoch: 5| Step: 7
Training loss: 2.3112893104553223
Validation loss: 2.399868857476019

Epoch: 5| Step: 8
Training loss: 2.209135055541992
Validation loss: 2.3862274436540503

Epoch: 5| Step: 9
Training loss: 2.1250720024108887
Validation loss: 2.3797968690113356

Epoch: 5| Step: 10
Training loss: 2.9812841415405273
Validation loss: 2.360433768200618

Epoch: 217| Step: 0
Training loss: 3.2050271034240723
Validation loss: 2.373136751113399

Epoch: 5| Step: 1
Training loss: 2.1696014404296875
Validation loss: 2.380587931602232

Epoch: 5| Step: 2
Training loss: 2.624094009399414
Validation loss: 2.376656522033035

Epoch: 5| Step: 3
Training loss: 2.411297559738159
Validation loss: 2.38505289118777

Epoch: 5| Step: 4
Training loss: 2.524737596511841
Validation loss: 2.3727477955561813

Epoch: 5| Step: 5
Training loss: 2.2958755493164062
Validation loss: 2.3693859936088644

Epoch: 5| Step: 6
Training loss: 3.0249381065368652
Validation loss: 2.368850720826016

Epoch: 5| Step: 7
Training loss: 2.7712864875793457
Validation loss: 2.370593155584028

Epoch: 5| Step: 8
Training loss: 3.0206634998321533
Validation loss: 2.377737088869977

Epoch: 5| Step: 9
Training loss: 2.0150692462921143
Validation loss: 2.368210820741551

Epoch: 5| Step: 10
Training loss: 2.051109790802002
Validation loss: 2.3771648073709137

Epoch: 218| Step: 0
Training loss: 2.0934321880340576
Validation loss: 2.378077627510153

Epoch: 5| Step: 1
Training loss: 2.5789027214050293
Validation loss: 2.3851148184909614

Epoch: 5| Step: 2
Training loss: 2.354726552963257
Validation loss: 2.3851675987243652

Epoch: 5| Step: 3
Training loss: 3.2514724731445312
Validation loss: 2.383069920283492

Epoch: 5| Step: 4
Training loss: 2.820190906524658
Validation loss: 2.386156625645135

Epoch: 5| Step: 5
Training loss: 2.4986555576324463
Validation loss: 2.3816059584258706

Epoch: 5| Step: 6
Training loss: 1.9643217325210571
Validation loss: 2.374321540196737

Epoch: 5| Step: 7
Training loss: 2.8223633766174316
Validation loss: 2.3623524891432894

Epoch: 5| Step: 8
Training loss: 2.7496612071990967
Validation loss: 2.3640266823512253

Epoch: 5| Step: 9
Training loss: 2.5173823833465576
Validation loss: 2.357539289741106

Epoch: 5| Step: 10
Training loss: 2.344236135482788
Validation loss: 2.3487739844988753

Epoch: 219| Step: 0
Training loss: 2.451122283935547
Validation loss: 2.3572029964898222

Epoch: 5| Step: 1
Training loss: 3.1334824562072754
Validation loss: 2.3698097505877094

Epoch: 5| Step: 2
Training loss: 3.2133331298828125
Validation loss: 2.372768391845047

Epoch: 5| Step: 3
Training loss: 2.1953322887420654
Validation loss: 2.363176853426041

Epoch: 5| Step: 4
Training loss: 2.704758644104004
Validation loss: 2.380627432177144

Epoch: 5| Step: 5
Training loss: 2.7239508628845215
Validation loss: 2.3782334558425413

Epoch: 5| Step: 6
Training loss: 1.9606012105941772
Validation loss: 2.384096872422003

Epoch: 5| Step: 7
Training loss: 2.519437313079834
Validation loss: 2.39407701646128

Epoch: 5| Step: 8
Training loss: 1.8684217929840088
Validation loss: 2.4034070250808552

Epoch: 5| Step: 9
Training loss: 2.3502581119537354
Validation loss: 2.392287882425452

Epoch: 5| Step: 10
Training loss: 2.7943859100341797
Validation loss: 2.4124489035657657

Epoch: 220| Step: 0
Training loss: 2.2569541931152344
Validation loss: 2.3967019486170944

Epoch: 5| Step: 1
Training loss: 1.9679415225982666
Validation loss: 2.3971002537717103

Epoch: 5| Step: 2
Training loss: 2.3371214866638184
Validation loss: 2.4091969356741956

Epoch: 5| Step: 3
Training loss: 3.005199909210205
Validation loss: 2.411038855070709

Epoch: 5| Step: 4
Training loss: 2.728637218475342
Validation loss: 2.397928412242602

Epoch: 5| Step: 5
Training loss: 2.42936372756958
Validation loss: 2.3938196218141945

Epoch: 5| Step: 6
Training loss: 2.706484794616699
Validation loss: 2.3864259771121445

Epoch: 5| Step: 7
Training loss: 1.7455612421035767
Validation loss: 2.376520146605789

Epoch: 5| Step: 8
Training loss: 3.328720808029175
Validation loss: 2.3785748353568454

Epoch: 5| Step: 9
Training loss: 2.6125919818878174
Validation loss: 2.376360580485354

Epoch: 5| Step: 10
Training loss: 2.6506967544555664
Validation loss: 2.3786442305452082

Epoch: 221| Step: 0
Training loss: 2.756786346435547
Validation loss: 2.38070204693784

Epoch: 5| Step: 1
Training loss: 2.7264487743377686
Validation loss: 2.393384051579301

Epoch: 5| Step: 2
Training loss: 2.480297327041626
Validation loss: 2.383510084562404

Epoch: 5| Step: 3
Training loss: 2.302475690841675
Validation loss: 2.3785613890617125

Epoch: 5| Step: 4
Training loss: 2.1979031562805176
Validation loss: 2.3754588173281763

Epoch: 5| Step: 5
Training loss: 2.3467724323272705
Validation loss: 2.3567289562635523

Epoch: 5| Step: 6
Training loss: 2.5617170333862305
Validation loss: 2.350381848632648

Epoch: 5| Step: 7
Training loss: 2.6583504676818848
Validation loss: 2.3538797593885854

Epoch: 5| Step: 8
Training loss: 2.2484068870544434
Validation loss: 2.35889002584642

Epoch: 5| Step: 9
Training loss: 2.8277010917663574
Validation loss: 2.360979903128839

Epoch: 5| Step: 10
Training loss: 2.915381669998169
Validation loss: 2.3566553182499383

Epoch: 222| Step: 0
Training loss: 2.8428778648376465
Validation loss: 2.3663581225179855

Epoch: 5| Step: 1
Training loss: 2.2905688285827637
Validation loss: 2.3728717142535793

Epoch: 5| Step: 2
Training loss: 2.55141019821167
Validation loss: 2.3821743560093704

Epoch: 5| Step: 3
Training loss: 2.3075804710388184
Validation loss: 2.380460818608602

Epoch: 5| Step: 4
Training loss: 2.7359161376953125
Validation loss: 2.4059125402922272

Epoch: 5| Step: 5
Training loss: 2.274271011352539
Validation loss: 2.4216353406188307

Epoch: 5| Step: 6
Training loss: 2.415951728820801
Validation loss: 2.4321996704224618

Epoch: 5| Step: 7
Training loss: 2.6060497760772705
Validation loss: 2.4041264339159896

Epoch: 5| Step: 8
Training loss: 2.3126580715179443
Validation loss: 2.3818904917727233

Epoch: 5| Step: 9
Training loss: 2.759951114654541
Validation loss: 2.3824190978080995

Epoch: 5| Step: 10
Training loss: 2.8873910903930664
Validation loss: 2.386989633242289

Epoch: 223| Step: 0
Training loss: 2.193673849105835
Validation loss: 2.3757963154905584

Epoch: 5| Step: 1
Training loss: 2.4365756511688232
Validation loss: 2.363224926815238

Epoch: 5| Step: 2
Training loss: 2.966700553894043
Validation loss: 2.370221245673395

Epoch: 5| Step: 3
Training loss: 2.49630069732666
Validation loss: 2.358475628719535

Epoch: 5| Step: 4
Training loss: 2.084164619445801
Validation loss: 2.35846846847124

Epoch: 5| Step: 5
Training loss: 2.414829730987549
Validation loss: 2.3620488182190926

Epoch: 5| Step: 6
Training loss: 3.2143287658691406
Validation loss: 2.344353031086665

Epoch: 5| Step: 7
Training loss: 2.20711350440979
Validation loss: 2.349213703986137

Epoch: 5| Step: 8
Training loss: 3.1207833290100098
Validation loss: 2.353214697171283

Epoch: 5| Step: 9
Training loss: 1.858669638633728
Validation loss: 2.35437878998377

Epoch: 5| Step: 10
Training loss: 2.8193390369415283
Validation loss: 2.35219233523133

Epoch: 224| Step: 0
Training loss: 2.322234630584717
Validation loss: 2.36566262860452

Epoch: 5| Step: 1
Training loss: 2.680400848388672
Validation loss: 2.3563682622807

Epoch: 5| Step: 2
Training loss: 1.971726417541504
Validation loss: 2.372950792312622

Epoch: 5| Step: 3
Training loss: 3.2502169609069824
Validation loss: 2.3949776541802192

Epoch: 5| Step: 4
Training loss: 2.8495795726776123
Validation loss: 2.3800620443077496

Epoch: 5| Step: 5
Training loss: 2.7745203971862793
Validation loss: 2.3949602162966164

Epoch: 5| Step: 6
Training loss: 3.298917293548584
Validation loss: 2.3888781019436416

Epoch: 5| Step: 7
Training loss: 1.4198623895645142
Validation loss: 2.4007758555873746

Epoch: 5| Step: 8
Training loss: 2.365831136703491
Validation loss: 2.3938369238248436

Epoch: 5| Step: 9
Training loss: 2.291370391845703
Validation loss: 2.3851791658709125

Epoch: 5| Step: 10
Training loss: 2.4592559337615967
Validation loss: 2.3842752159282727

Epoch: 225| Step: 0
Training loss: 2.4094417095184326
Validation loss: 2.381588110359766

Epoch: 5| Step: 1
Training loss: 2.741910457611084
Validation loss: 2.4015929109306744

Epoch: 5| Step: 2
Training loss: 1.9419786930084229
Validation loss: 2.3717204704079577

Epoch: 5| Step: 3
Training loss: 2.1363863945007324
Validation loss: 2.387235951680009

Epoch: 5| Step: 4
Training loss: 2.784926414489746
Validation loss: 2.38801916696692

Epoch: 5| Step: 5
Training loss: 2.7350006103515625
Validation loss: 2.396909624017695

Epoch: 5| Step: 6
Training loss: 2.199852466583252
Validation loss: 2.403832661208286

Epoch: 5| Step: 7
Training loss: 2.5934226512908936
Validation loss: 2.3870597347136466

Epoch: 5| Step: 8
Training loss: 2.4822475910186768
Validation loss: 2.4044504165649414

Epoch: 5| Step: 9
Training loss: 2.6128833293914795
Validation loss: 2.3880210102245374

Epoch: 5| Step: 10
Training loss: 3.2159347534179688
Validation loss: 2.3637628811661915

Epoch: 226| Step: 0
Training loss: 2.675150156021118
Validation loss: 2.338102315061836

Epoch: 5| Step: 1
Training loss: 2.374702215194702
Validation loss: 2.342596164313696

Epoch: 5| Step: 2
Training loss: 1.7594578266143799
Validation loss: 2.3429050343011015

Epoch: 5| Step: 3
Training loss: 3.1580028533935547
Validation loss: 2.341048789280717

Epoch: 5| Step: 4
Training loss: 2.243028163909912
Validation loss: 2.3314443557493147

Epoch: 5| Step: 5
Training loss: 2.8293399810791016
Validation loss: 2.335141033254644

Epoch: 5| Step: 6
Training loss: 2.9059786796569824
Validation loss: 2.338375573517174

Epoch: 5| Step: 7
Training loss: 2.372262716293335
Validation loss: 2.3436035827923845

Epoch: 5| Step: 8
Training loss: 2.192420721054077
Validation loss: 2.336918184834142

Epoch: 5| Step: 9
Training loss: 2.1674952507019043
Validation loss: 2.333340093653689

Epoch: 5| Step: 10
Training loss: 3.3422164916992188
Validation loss: 2.3494075011181574

Epoch: 227| Step: 0
Training loss: 2.428621292114258
Validation loss: 2.360021020776482

Epoch: 5| Step: 1
Training loss: 2.7403573989868164
Validation loss: 2.364973768111198

Epoch: 5| Step: 2
Training loss: 2.9614880084991455
Validation loss: 2.3640249134391866

Epoch: 5| Step: 3
Training loss: 2.5865211486816406
Validation loss: 2.369224509885234

Epoch: 5| Step: 4
Training loss: 2.571516990661621
Validation loss: 2.374152998770437

Epoch: 5| Step: 5
Training loss: 3.073035717010498
Validation loss: 2.349318447933402

Epoch: 5| Step: 6
Training loss: 2.0594353675842285
Validation loss: 2.349388168704125

Epoch: 5| Step: 7
Training loss: 1.4304779767990112
Validation loss: 2.3577226515739196

Epoch: 5| Step: 8
Training loss: 3.0848045349121094
Validation loss: 2.3666555881500244

Epoch: 5| Step: 9
Training loss: 2.7820117473602295
Validation loss: 2.3578963894997873

Epoch: 5| Step: 10
Training loss: 1.993213415145874
Validation loss: 2.363048090729662

Epoch: 228| Step: 0
Training loss: 2.1818461418151855
Validation loss: 2.3631136250752274

Epoch: 5| Step: 1
Training loss: 2.5816752910614014
Validation loss: 2.3548959788455757

Epoch: 5| Step: 2
Training loss: 2.6915817260742188
Validation loss: 2.3563240061524096

Epoch: 5| Step: 3
Training loss: 1.7878395318984985
Validation loss: 2.3778935247851956

Epoch: 5| Step: 4
Training loss: 3.4463963508605957
Validation loss: 2.3765880087370514

Epoch: 5| Step: 5
Training loss: 2.0458340644836426
Validation loss: 2.37592424115827

Epoch: 5| Step: 6
Training loss: 2.36279559135437
Validation loss: 2.3820731691134873

Epoch: 5| Step: 7
Training loss: 2.928239583969116
Validation loss: 2.3823536031989643

Epoch: 5| Step: 8
Training loss: 2.2669200897216797
Validation loss: 2.3745663422410206

Epoch: 5| Step: 9
Training loss: 3.050386428833008
Validation loss: 2.3792713662629486

Epoch: 5| Step: 10
Training loss: 2.3720576763153076
Validation loss: 2.3731262709504817

Epoch: 229| Step: 0
Training loss: 3.2977499961853027
Validation loss: 2.3716081906390447

Epoch: 5| Step: 1
Training loss: 2.9883313179016113
Validation loss: 2.3762672050024873

Epoch: 5| Step: 2
Training loss: 2.531670093536377
Validation loss: 2.3876488413862003

Epoch: 5| Step: 3
Training loss: 2.4917609691619873
Validation loss: 2.397067444298857

Epoch: 5| Step: 4
Training loss: 2.9031553268432617
Validation loss: 2.406362077241303

Epoch: 5| Step: 5
Training loss: 2.109699249267578
Validation loss: 2.4033134880886284

Epoch: 5| Step: 6
Training loss: 2.1506075859069824
Validation loss: 2.397615599375899

Epoch: 5| Step: 7
Training loss: 3.0191001892089844
Validation loss: 2.391397471069008

Epoch: 5| Step: 8
Training loss: 1.5628905296325684
Validation loss: 2.396454877750848

Epoch: 5| Step: 9
Training loss: 2.1020798683166504
Validation loss: 2.388397391124438

Epoch: 5| Step: 10
Training loss: 2.5573065280914307
Validation loss: 2.3585983553240375

Epoch: 230| Step: 0
Training loss: 2.650191307067871
Validation loss: 2.3676160356049896

Epoch: 5| Step: 1
Training loss: 2.959932804107666
Validation loss: 2.3734193002024004

Epoch: 5| Step: 2
Training loss: 3.09285306930542
Validation loss: 2.3644798955609723

Epoch: 5| Step: 3
Training loss: 1.5668988227844238
Validation loss: 2.3885135035361014

Epoch: 5| Step: 4
Training loss: 2.1677699089050293
Validation loss: 2.4093316165349816

Epoch: 5| Step: 5
Training loss: 3.0030100345611572
Validation loss: 2.4091159195028324

Epoch: 5| Step: 6
Training loss: 2.5296809673309326
Validation loss: 2.37876957719044

Epoch: 5| Step: 7
Training loss: 2.3765640258789062
Validation loss: 2.369482291642056

Epoch: 5| Step: 8
Training loss: 1.8133354187011719
Validation loss: 2.3550357459693827

Epoch: 5| Step: 9
Training loss: 2.7708916664123535
Validation loss: 2.3593208661643406

Epoch: 5| Step: 10
Training loss: 3.0786306858062744
Validation loss: 2.3695657445538427

Epoch: 231| Step: 0
Training loss: 2.612914800643921
Validation loss: 2.3804664381088747

Epoch: 5| Step: 1
Training loss: 2.2881884574890137
Validation loss: 2.3872365310627925

Epoch: 5| Step: 2
Training loss: 1.943368911743164
Validation loss: 2.378997971934657

Epoch: 5| Step: 3
Training loss: 2.6048359870910645
Validation loss: 2.3689429426705964

Epoch: 5| Step: 4
Training loss: 2.8790993690490723
Validation loss: 2.3502155657737487

Epoch: 5| Step: 5
Training loss: 2.363502025604248
Validation loss: 2.366507814776513

Epoch: 5| Step: 6
Training loss: 3.3449020385742188
Validation loss: 2.3743522705570346

Epoch: 5| Step: 7
Training loss: 2.870594024658203
Validation loss: 2.3735316004804385

Epoch: 5| Step: 8
Training loss: 2.237236261367798
Validation loss: 2.3613493186171337

Epoch: 5| Step: 9
Training loss: 2.378028154373169
Validation loss: 2.3557387090498403

Epoch: 5| Step: 10
Training loss: 2.1314852237701416
Validation loss: 2.3388439737340456

Epoch: 232| Step: 0
Training loss: 2.306286573410034
Validation loss: 2.339722853834911

Epoch: 5| Step: 1
Training loss: 2.732783555984497
Validation loss: 2.332582653209727

Epoch: 5| Step: 2
Training loss: 2.2597899436950684
Validation loss: 2.3309802701396327

Epoch: 5| Step: 3
Training loss: 2.0978212356567383
Validation loss: 2.334620677014833

Epoch: 5| Step: 4
Training loss: 1.847080945968628
Validation loss: 2.3399601059575237

Epoch: 5| Step: 5
Training loss: 2.8139941692352295
Validation loss: 2.337687425715949

Epoch: 5| Step: 6
Training loss: 3.3106689453125
Validation loss: 2.359917317667315

Epoch: 5| Step: 7
Training loss: 2.6178107261657715
Validation loss: 2.3712712949322117

Epoch: 5| Step: 8
Training loss: 2.2011897563934326
Validation loss: 2.392922851347154

Epoch: 5| Step: 9
Training loss: 3.4414381980895996
Validation loss: 2.411919447683519

Epoch: 5| Step: 10
Training loss: 1.9825599193572998
Validation loss: 2.4202885961019867

Epoch: 233| Step: 0
Training loss: 1.7153352499008179
Validation loss: 2.4064310263561945

Epoch: 5| Step: 1
Training loss: 2.6465911865234375
Validation loss: 2.4089145147672264

Epoch: 5| Step: 2
Training loss: 2.04689621925354
Validation loss: 2.3859120466375865

Epoch: 5| Step: 3
Training loss: 2.3969521522521973
Validation loss: 2.3825026583927933

Epoch: 5| Step: 4
Training loss: 2.789992570877075
Validation loss: 2.371995126047442

Epoch: 5| Step: 5
Training loss: 2.3468525409698486
Validation loss: 2.343513506715016

Epoch: 5| Step: 6
Training loss: 2.4723222255706787
Validation loss: 2.348845422908824

Epoch: 5| Step: 7
Training loss: 2.470649480819702
Validation loss: 2.347551016397374

Epoch: 5| Step: 8
Training loss: 3.1588759422302246
Validation loss: 2.3610427379608154

Epoch: 5| Step: 9
Training loss: 3.075294017791748
Validation loss: 2.357591834119571

Epoch: 5| Step: 10
Training loss: 2.724500894546509
Validation loss: 2.3499660158670075

Epoch: 234| Step: 0
Training loss: 2.5295417308807373
Validation loss: 2.3406326911782704

Epoch: 5| Step: 1
Training loss: 2.668405771255493
Validation loss: 2.340606394634452

Epoch: 5| Step: 2
Training loss: 2.2602264881134033
Validation loss: 2.3451846184269076

Epoch: 5| Step: 3
Training loss: 2.8733971118927
Validation loss: 2.35874774635479

Epoch: 5| Step: 4
Training loss: 3.1215555667877197
Validation loss: 2.368767229459619

Epoch: 5| Step: 5
Training loss: 2.562157154083252
Validation loss: 2.3879686247917915

Epoch: 5| Step: 6
Training loss: 2.0019943714141846
Validation loss: 2.3947459267031763

Epoch: 5| Step: 7
Training loss: 2.336338996887207
Validation loss: 2.400630533054311

Epoch: 5| Step: 8
Training loss: 2.7417807579040527
Validation loss: 2.4048387158301567

Epoch: 5| Step: 9
Training loss: 2.4031484127044678
Validation loss: 2.394549459539434

Epoch: 5| Step: 10
Training loss: 2.0574791431427
Validation loss: 2.3831222364979405

Epoch: 235| Step: 0
Training loss: 2.1841752529144287
Validation loss: 2.3744314050161712

Epoch: 5| Step: 1
Training loss: 2.638139247894287
Validation loss: 2.3759269611809843

Epoch: 5| Step: 2
Training loss: 2.5924832820892334
Validation loss: 2.361541958265407

Epoch: 5| Step: 3
Training loss: 3.0850677490234375
Validation loss: 2.354611612135364

Epoch: 5| Step: 4
Training loss: 2.590179920196533
Validation loss: 2.3647405203952583

Epoch: 5| Step: 5
Training loss: 2.9049267768859863
Validation loss: 2.3603224754333496

Epoch: 5| Step: 6
Training loss: 2.721377372741699
Validation loss: 2.3398249662050636

Epoch: 5| Step: 7
Training loss: 1.7698554992675781
Validation loss: 2.3488672369269916

Epoch: 5| Step: 8
Training loss: 1.5642876625061035
Validation loss: 2.342572242982926

Epoch: 5| Step: 9
Training loss: 2.8979885578155518
Validation loss: 2.3658910156578146

Epoch: 5| Step: 10
Training loss: 2.564607858657837
Validation loss: 2.3579328829242336

Epoch: 236| Step: 0
Training loss: 2.82582688331604
Validation loss: 2.3790388158572617

Epoch: 5| Step: 1
Training loss: 1.6961348056793213
Validation loss: 2.367054182996032

Epoch: 5| Step: 2
Training loss: 2.481682062149048
Validation loss: 2.3953885724467616

Epoch: 5| Step: 3
Training loss: 2.8532638549804688
Validation loss: 2.388533438405683

Epoch: 5| Step: 4
Training loss: 2.563567638397217
Validation loss: 2.379997786655221

Epoch: 5| Step: 5
Training loss: 2.2690341472625732
Validation loss: 2.384944515843545

Epoch: 5| Step: 6
Training loss: 2.848327159881592
Validation loss: 2.387831275181104

Epoch: 5| Step: 7
Training loss: 2.6721346378326416
Validation loss: 2.3800456934077765

Epoch: 5| Step: 8
Training loss: 2.8522021770477295
Validation loss: 2.383617902314791

Epoch: 5| Step: 9
Training loss: 1.943713903427124
Validation loss: 2.3702561316951627

Epoch: 5| Step: 10
Training loss: 2.5105676651000977
Validation loss: 2.365971465264597

Epoch: 237| Step: 0
Training loss: 2.284529685974121
Validation loss: 2.3424454107079455

Epoch: 5| Step: 1
Training loss: 2.2532126903533936
Validation loss: 2.3472915528922953

Epoch: 5| Step: 2
Training loss: 2.3673999309539795
Validation loss: 2.332692494956396

Epoch: 5| Step: 3
Training loss: 2.2298598289489746
Validation loss: 2.3311917551102175

Epoch: 5| Step: 4
Training loss: 2.204411745071411
Validation loss: 2.3461459887925016

Epoch: 5| Step: 5
Training loss: 2.986959934234619
Validation loss: 2.3505800744538665

Epoch: 5| Step: 6
Training loss: 3.056460380554199
Validation loss: 2.3519131137478735

Epoch: 5| Step: 7
Training loss: 2.5834743976593018
Validation loss: 2.367187105199342

Epoch: 5| Step: 8
Training loss: 2.514936923980713
Validation loss: 2.3495825465007494

Epoch: 5| Step: 9
Training loss: 2.4898529052734375
Validation loss: 2.3523003491022254

Epoch: 5| Step: 10
Training loss: 2.4599218368530273
Validation loss: 2.3605410206702446

Epoch: 238| Step: 0
Training loss: 2.728018045425415
Validation loss: 2.351765619811191

Epoch: 5| Step: 1
Training loss: 2.4294726848602295
Validation loss: 2.3643201730584584

Epoch: 5| Step: 2
Training loss: 2.9461469650268555
Validation loss: 2.3802008949300295

Epoch: 5| Step: 3
Training loss: 2.9339680671691895
Validation loss: 2.3739401935249247

Epoch: 5| Step: 4
Training loss: 2.752051591873169
Validation loss: 2.3689304808134675

Epoch: 5| Step: 5
Training loss: 2.015352249145508
Validation loss: 2.365911517091977

Epoch: 5| Step: 6
Training loss: 2.271970272064209
Validation loss: 2.3670266110409974

Epoch: 5| Step: 7
Training loss: 2.0887153148651123
Validation loss: 2.3489339402926865

Epoch: 5| Step: 8
Training loss: 2.4476964473724365
Validation loss: 2.345748019474809

Epoch: 5| Step: 9
Training loss: 2.453775644302368
Validation loss: 2.34167823227503

Epoch: 5| Step: 10
Training loss: 2.5881128311157227
Validation loss: 2.328179403017926

Epoch: 239| Step: 0
Training loss: 2.4583797454833984
Validation loss: 2.3357529204378844

Epoch: 5| Step: 1
Training loss: 2.652623414993286
Validation loss: 2.336061595588602

Epoch: 5| Step: 2
Training loss: 2.276043653488159
Validation loss: 2.334064104223764

Epoch: 5| Step: 3
Training loss: 1.7787601947784424
Validation loss: 2.3644127717582126

Epoch: 5| Step: 4
Training loss: 2.6495420932769775
Validation loss: 2.379259540188697

Epoch: 5| Step: 5
Training loss: 1.907708764076233
Validation loss: 2.3786896608209096

Epoch: 5| Step: 6
Training loss: 2.9356768131256104
Validation loss: 2.3720660107110136

Epoch: 5| Step: 7
Training loss: 3.120002031326294
Validation loss: 2.3717278101110972

Epoch: 5| Step: 8
Training loss: 2.4454407691955566
Validation loss: 2.3565784141581547

Epoch: 5| Step: 9
Training loss: 2.701906204223633
Validation loss: 2.354780435562134

Epoch: 5| Step: 10
Training loss: 2.640491247177124
Validation loss: 2.345237692197164

Epoch: 240| Step: 0
Training loss: 2.1781795024871826
Validation loss: 2.3638384162738757

Epoch: 5| Step: 1
Training loss: 2.3295764923095703
Validation loss: 2.3661557423171176

Epoch: 5| Step: 2
Training loss: 2.7757644653320312
Validation loss: 2.3629868594549035

Epoch: 5| Step: 3
Training loss: 2.7699520587921143
Validation loss: 2.3677278744277133

Epoch: 5| Step: 4
Training loss: 3.16148042678833
Validation loss: 2.369262436384796

Epoch: 5| Step: 5
Training loss: 2.4340767860412598
Validation loss: 2.3683839844119166

Epoch: 5| Step: 6
Training loss: 2.5076065063476562
Validation loss: 2.360475432488226

Epoch: 5| Step: 7
Training loss: 2.682326316833496
Validation loss: 2.346519613778719

Epoch: 5| Step: 8
Training loss: 2.8703246116638184
Validation loss: 2.3420762349200506

Epoch: 5| Step: 9
Training loss: 2.033142566680908
Validation loss: 2.336293840921053

Epoch: 5| Step: 10
Training loss: 1.6510732173919678
Validation loss: 2.347528676832876

Epoch: 241| Step: 0
Training loss: 2.881533145904541
Validation loss: 2.3421179914987214

Epoch: 5| Step: 1
Training loss: 2.5637729167938232
Validation loss: 2.3590311773361696

Epoch: 5| Step: 2
Training loss: 2.0240402221679688
Validation loss: 2.359277340673631

Epoch: 5| Step: 3
Training loss: 2.454160690307617
Validation loss: 2.3775410729069866

Epoch: 5| Step: 4
Training loss: 2.4298458099365234
Validation loss: 2.383254225536059

Epoch: 5| Step: 5
Training loss: 2.4557204246520996
Validation loss: 2.3729026702142533

Epoch: 5| Step: 6
Training loss: 2.6069400310516357
Validation loss: 2.3766055363480763

Epoch: 5| Step: 7
Training loss: 2.335554838180542
Validation loss: 2.3873362156652633

Epoch: 5| Step: 8
Training loss: 2.8252742290496826
Validation loss: 2.3655500565805743

Epoch: 5| Step: 9
Training loss: 2.0008363723754883
Validation loss: 2.3774054050445557

Epoch: 5| Step: 10
Training loss: 3.023242473602295
Validation loss: 2.352568164948494

Epoch: 242| Step: 0
Training loss: 2.017404556274414
Validation loss: 2.3371915753169725

Epoch: 5| Step: 1
Training loss: 2.5095808506011963
Validation loss: 2.3456679313413558

Epoch: 5| Step: 2
Training loss: 2.7949700355529785
Validation loss: 2.342064485755018

Epoch: 5| Step: 3
Training loss: 2.3854892253875732
Validation loss: 2.32487424214681

Epoch: 5| Step: 4
Training loss: 3.189483165740967
Validation loss: 2.331707318623861

Epoch: 5| Step: 5
Training loss: 2.158168315887451
Validation loss: 2.3278458605530443

Epoch: 5| Step: 6
Training loss: 2.568554639816284
Validation loss: 2.324658942478959

Epoch: 5| Step: 7
Training loss: 3.4172966480255127
Validation loss: 2.325442434639059

Epoch: 5| Step: 8
Training loss: 2.069093704223633
Validation loss: 2.318308743097449

Epoch: 5| Step: 9
Training loss: 1.674858808517456
Validation loss: 2.316872740304598

Epoch: 5| Step: 10
Training loss: 2.790518045425415
Validation loss: 2.3194812702876266

Epoch: 243| Step: 0
Training loss: 2.8634848594665527
Validation loss: 2.33129886914325

Epoch: 5| Step: 1
Training loss: 3.06962251663208
Validation loss: 2.341303474159651

Epoch: 5| Step: 2
Training loss: 2.7328672409057617
Validation loss: 2.3420316480821177

Epoch: 5| Step: 3
Training loss: 2.8053832054138184
Validation loss: 2.3629674270588863

Epoch: 5| Step: 4
Training loss: 2.5322906970977783
Validation loss: 2.368903995842062

Epoch: 5| Step: 5
Training loss: 1.9594780206680298
Validation loss: 2.37684537518409

Epoch: 5| Step: 6
Training loss: 1.9888805150985718
Validation loss: 2.378224762537146

Epoch: 5| Step: 7
Training loss: 2.7592856884002686
Validation loss: 2.3727352516625517

Epoch: 5| Step: 8
Training loss: 2.2086496353149414
Validation loss: 2.3872568607330322

Epoch: 5| Step: 9
Training loss: 2.332080364227295
Validation loss: 2.3505246677706317

Epoch: 5| Step: 10
Training loss: 2.150123119354248
Validation loss: 2.3320669743322555

Epoch: 244| Step: 0
Training loss: 1.824035406112671
Validation loss: 2.3343177328827562

Epoch: 5| Step: 1
Training loss: 2.4372153282165527
Validation loss: 2.3192256522435013

Epoch: 5| Step: 2
Training loss: 2.55414080619812
Validation loss: 2.317589239407611

Epoch: 5| Step: 3
Training loss: 2.6017966270446777
Validation loss: 2.3127711639609387

Epoch: 5| Step: 4
Training loss: 2.513895273208618
Validation loss: 2.334914166440246

Epoch: 5| Step: 5
Training loss: 1.8210951089859009
Validation loss: 2.327496508116363

Epoch: 5| Step: 6
Training loss: 2.5847043991088867
Validation loss: 2.3263466153093564

Epoch: 5| Step: 7
Training loss: 3.4473724365234375
Validation loss: 2.334850334352063

Epoch: 5| Step: 8
Training loss: 2.867964506149292
Validation loss: 2.3450319946453138

Epoch: 5| Step: 9
Training loss: 2.4051425457000732
Validation loss: 2.343035344154604

Epoch: 5| Step: 10
Training loss: 2.3107922077178955
Validation loss: 2.3480102926172237

Epoch: 245| Step: 0
Training loss: 1.7935845851898193
Validation loss: 2.3460165685222996

Epoch: 5| Step: 1
Training loss: 1.9119676351547241
Validation loss: 2.346388771969785

Epoch: 5| Step: 2
Training loss: 2.6120941638946533
Validation loss: 2.3436553990969093

Epoch: 5| Step: 3
Training loss: 2.6709413528442383
Validation loss: 2.345675055698682

Epoch: 5| Step: 4
Training loss: 3.1429131031036377
Validation loss: 2.3515572740185644

Epoch: 5| Step: 5
Training loss: 2.9937021732330322
Validation loss: 2.3618495310506513

Epoch: 5| Step: 6
Training loss: 3.12640118598938
Validation loss: 2.341872638271701

Epoch: 5| Step: 7
Training loss: 1.6045513153076172
Validation loss: 2.3321096897125244

Epoch: 5| Step: 8
Training loss: 2.6333160400390625
Validation loss: 2.335072737868114

Epoch: 5| Step: 9
Training loss: 2.0987162590026855
Validation loss: 2.316618114389399

Epoch: 5| Step: 10
Training loss: 2.816145896911621
Validation loss: 2.323332376377557

Epoch: 246| Step: 0
Training loss: 2.8084073066711426
Validation loss: 2.3399751852917414

Epoch: 5| Step: 1
Training loss: 2.5635993480682373
Validation loss: 2.317717485530402

Epoch: 5| Step: 2
Training loss: 2.97878360748291
Validation loss: 2.3379879843804146

Epoch: 5| Step: 3
Training loss: 2.942075729370117
Validation loss: 2.3339698058302685

Epoch: 5| Step: 4
Training loss: 2.895820140838623
Validation loss: 2.329669588355608

Epoch: 5| Step: 5
Training loss: 2.328439235687256
Validation loss: 2.330986979187176

Epoch: 5| Step: 6
Training loss: 2.414884328842163
Validation loss: 2.3328686798772504

Epoch: 5| Step: 7
Training loss: 1.3011772632598877
Validation loss: 2.3363750416745424

Epoch: 5| Step: 8
Training loss: 2.284374952316284
Validation loss: 2.3443001008802846

Epoch: 5| Step: 9
Training loss: 2.1481213569641113
Validation loss: 2.3540897523203204

Epoch: 5| Step: 10
Training loss: 2.6815216541290283
Validation loss: 2.3678691361540105

Epoch: 247| Step: 0
Training loss: 2.028874635696411
Validation loss: 2.3555806042045675

Epoch: 5| Step: 1
Training loss: 2.4364795684814453
Validation loss: 2.3692263018700386

Epoch: 5| Step: 2
Training loss: 2.2102370262145996
Validation loss: 2.38799621212867

Epoch: 5| Step: 3
Training loss: 2.7104763984680176
Validation loss: 2.3949976915954263

Epoch: 5| Step: 4
Training loss: 2.9096522331237793
Validation loss: 2.366627085593439

Epoch: 5| Step: 5
Training loss: 1.8537750244140625
Validation loss: 2.36819492232415

Epoch: 5| Step: 6
Training loss: 2.666778087615967
Validation loss: 2.356060794604722

Epoch: 5| Step: 7
Training loss: 2.540109872817993
Validation loss: 2.3458180043005172

Epoch: 5| Step: 8
Training loss: 2.2414238452911377
Validation loss: 2.3295103837085027

Epoch: 5| Step: 9
Training loss: 3.0494511127471924
Validation loss: 2.33079780045376

Epoch: 5| Step: 10
Training loss: 2.6973483562469482
Validation loss: 2.322821209507604

Epoch: 248| Step: 0
Training loss: 2.0988621711730957
Validation loss: 2.3173616240101476

Epoch: 5| Step: 1
Training loss: 2.797891616821289
Validation loss: 2.3023835792336413

Epoch: 5| Step: 2
Training loss: 2.5502867698669434
Validation loss: 2.3144665918042584

Epoch: 5| Step: 3
Training loss: 2.3769567012786865
Validation loss: 2.3026341956148864

Epoch: 5| Step: 4
Training loss: 2.6513028144836426
Validation loss: 2.3060066802527315

Epoch: 5| Step: 5
Training loss: 1.9412529468536377
Validation loss: 2.316936351919687

Epoch: 5| Step: 6
Training loss: 2.2072815895080566
Validation loss: 2.3211445782774236

Epoch: 5| Step: 7
Training loss: 3.241532802581787
Validation loss: 2.3334789455577893

Epoch: 5| Step: 8
Training loss: 2.591886281967163
Validation loss: 2.331597089767456

Epoch: 5| Step: 9
Training loss: 2.354261636734009
Validation loss: 2.3352904319763184

Epoch: 5| Step: 10
Training loss: 2.4500796794891357
Validation loss: 2.369637793110263

Epoch: 249| Step: 0
Training loss: 1.7321125268936157
Validation loss: 2.363864214189591

Epoch: 5| Step: 1
Training loss: 2.2668066024780273
Validation loss: 2.3869269817106185

Epoch: 5| Step: 2
Training loss: 2.7207207679748535
Validation loss: 2.377871301866347

Epoch: 5| Step: 3
Training loss: 2.626465320587158
Validation loss: 2.372083117884974

Epoch: 5| Step: 4
Training loss: 1.9543125629425049
Validation loss: 2.348464265946419

Epoch: 5| Step: 5
Training loss: 3.1288437843322754
Validation loss: 2.3514016597501692

Epoch: 5| Step: 6
Training loss: 3.2486133575439453
Validation loss: 2.344007284410538

Epoch: 5| Step: 7
Training loss: 2.423096179962158
Validation loss: 2.32526546396235

Epoch: 5| Step: 8
Training loss: 2.4850308895111084
Validation loss: 2.3249826251819568

Epoch: 5| Step: 9
Training loss: 2.3028666973114014
Validation loss: 2.3244381976383988

Epoch: 5| Step: 10
Training loss: 2.530302047729492
Validation loss: 2.308573451093448

Epoch: 250| Step: 0
Training loss: 2.765263795852661
Validation loss: 2.316497154133294

Epoch: 5| Step: 1
Training loss: 2.9951577186584473
Validation loss: 2.3153529372266544

Epoch: 5| Step: 2
Training loss: 2.1989798545837402
Validation loss: 2.3125792523866058

Epoch: 5| Step: 3
Training loss: 2.682096004486084
Validation loss: 2.317903167457991

Epoch: 5| Step: 4
Training loss: 2.2055792808532715
Validation loss: 2.319232189527122

Epoch: 5| Step: 5
Training loss: 2.38118052482605
Validation loss: 2.3393327190030004

Epoch: 5| Step: 6
Training loss: 2.651482105255127
Validation loss: 2.3412241807547947

Epoch: 5| Step: 7
Training loss: 2.11738920211792
Validation loss: 2.341568357201033

Epoch: 5| Step: 8
Training loss: 2.6514687538146973
Validation loss: 2.3387516698529645

Epoch: 5| Step: 9
Training loss: 2.8155243396759033
Validation loss: 2.343318062443887

Epoch: 5| Step: 10
Training loss: 1.6867297887802124
Validation loss: 2.3213769787101337

Epoch: 251| Step: 0
Training loss: 3.1146373748779297
Validation loss: 2.32137724661058

Epoch: 5| Step: 1
Training loss: 1.7438907623291016
Validation loss: 2.33048625018007

Epoch: 5| Step: 2
Training loss: 2.419353485107422
Validation loss: 2.3357103037577804

Epoch: 5| Step: 3
Training loss: 2.3736352920532227
Validation loss: 2.3527495425234557

Epoch: 5| Step: 4
Training loss: 3.237793445587158
Validation loss: 2.3343383368625434

Epoch: 5| Step: 5
Training loss: 1.9807541370391846
Validation loss: 2.3490907222993913

Epoch: 5| Step: 6
Training loss: 2.599726438522339
Validation loss: 2.3532386338838966

Epoch: 5| Step: 7
Training loss: 2.8303942680358887
Validation loss: 2.3494781165994625

Epoch: 5| Step: 8
Training loss: 2.175060749053955
Validation loss: 2.3535012301578315

Epoch: 5| Step: 9
Training loss: 2.4867775440216064
Validation loss: 2.3514852498167302

Epoch: 5| Step: 10
Training loss: 2.4874191284179688
Validation loss: 2.339248111171107

Epoch: 252| Step: 0
Training loss: 2.3547463417053223
Validation loss: 2.3493267156744517

Epoch: 5| Step: 1
Training loss: 2.494847536087036
Validation loss: 2.342924394915181

Epoch: 5| Step: 2
Training loss: 2.15556001663208
Validation loss: 2.3257627512819026

Epoch: 5| Step: 3
Training loss: 2.9517319202423096
Validation loss: 2.3407833858202864

Epoch: 5| Step: 4
Training loss: 2.6037895679473877
Validation loss: 2.339462826328893

Epoch: 5| Step: 5
Training loss: 1.9204362630844116
Validation loss: 2.350271286502961

Epoch: 5| Step: 6
Training loss: 2.2336905002593994
Validation loss: 2.3463464654901975

Epoch: 5| Step: 7
Training loss: 3.3041603565216064
Validation loss: 2.347311435207244

Epoch: 5| Step: 8
Training loss: 3.048779249191284
Validation loss: 2.348273302919121

Epoch: 5| Step: 9
Training loss: 2.267719030380249
Validation loss: 2.3211310653276342

Epoch: 5| Step: 10
Training loss: 2.011470317840576
Validation loss: 2.3310832259475545

Epoch: 253| Step: 0
Training loss: 2.0314137935638428
Validation loss: 2.3237589841247885

Epoch: 5| Step: 1
Training loss: 2.850353717803955
Validation loss: 2.329619094889651

Epoch: 5| Step: 2
Training loss: 2.3181302547454834
Validation loss: 2.3315088774568293

Epoch: 5| Step: 3
Training loss: 2.026705503463745
Validation loss: 2.334673455966416

Epoch: 5| Step: 4
Training loss: 2.8054099082946777
Validation loss: 2.3417298306701

Epoch: 5| Step: 5
Training loss: 2.1337382793426514
Validation loss: 2.3526005386024393

Epoch: 5| Step: 6
Training loss: 3.112689733505249
Validation loss: 2.3230953293461956

Epoch: 5| Step: 7
Training loss: 2.4015867710113525
Validation loss: 2.3267170588175454

Epoch: 5| Step: 8
Training loss: 2.213033676147461
Validation loss: 2.3117708775304977

Epoch: 5| Step: 9
Training loss: 2.807915449142456
Validation loss: 2.3077786712236303

Epoch: 5| Step: 10
Training loss: 2.389439821243286
Validation loss: 2.3121112802977204

Epoch: 254| Step: 0
Training loss: 2.014500141143799
Validation loss: 2.3100667025453303

Epoch: 5| Step: 1
Training loss: 2.605651378631592
Validation loss: 2.3077041513176373

Epoch: 5| Step: 2
Training loss: 2.682117462158203
Validation loss: 2.3033600622607815

Epoch: 5| Step: 3
Training loss: 2.94425106048584
Validation loss: 2.3225211020438903

Epoch: 5| Step: 4
Training loss: 2.768770456314087
Validation loss: 2.3389439377733456

Epoch: 5| Step: 5
Training loss: 2.0777769088745117
Validation loss: 2.332182958561887

Epoch: 5| Step: 6
Training loss: 2.5460314750671387
Validation loss: 2.347828536905268

Epoch: 5| Step: 7
Training loss: 2.491835355758667
Validation loss: 2.348112993342902

Epoch: 5| Step: 8
Training loss: 1.844024896621704
Validation loss: 2.313629819500831

Epoch: 5| Step: 9
Training loss: 2.370656967163086
Validation loss: 2.3161415464134625

Epoch: 5| Step: 10
Training loss: 2.8889496326446533
Validation loss: 2.314377615528722

Epoch: 255| Step: 0
Training loss: 2.005631923675537
Validation loss: 2.2984679911726262

Epoch: 5| Step: 1
Training loss: 2.2963802814483643
Validation loss: 2.3136961613931963

Epoch: 5| Step: 2
Training loss: 2.0053672790527344
Validation loss: 2.3101157552452496

Epoch: 5| Step: 3
Training loss: 2.9086644649505615
Validation loss: 2.3296283957778767

Epoch: 5| Step: 4
Training loss: 2.6243884563446045
Validation loss: 2.3280479395261375

Epoch: 5| Step: 5
Training loss: 2.4477322101593018
Validation loss: 2.3392383949730986

Epoch: 5| Step: 6
Training loss: 2.937251091003418
Validation loss: 2.3358987018626225

Epoch: 5| Step: 7
Training loss: 2.3782687187194824
Validation loss: 2.345498387531568

Epoch: 5| Step: 8
Training loss: 2.2253921031951904
Validation loss: 2.321237861469228

Epoch: 5| Step: 9
Training loss: 2.4853904247283936
Validation loss: 2.324500221078114

Epoch: 5| Step: 10
Training loss: 2.8338279724121094
Validation loss: 2.321261006016885

Epoch: 256| Step: 0
Training loss: 3.0263965129852295
Validation loss: 2.3306308151573263

Epoch: 5| Step: 1
Training loss: 2.0649571418762207
Validation loss: 2.3247617675412084

Epoch: 5| Step: 2
Training loss: 2.7212986946105957
Validation loss: 2.3326494924483763

Epoch: 5| Step: 3
Training loss: 2.582714557647705
Validation loss: 2.3434775901097122

Epoch: 5| Step: 4
Training loss: 2.257159471511841
Validation loss: 2.326351809245284

Epoch: 5| Step: 5
Training loss: 2.532665967941284
Validation loss: 2.3470834737182944

Epoch: 5| Step: 6
Training loss: 2.370837450027466
Validation loss: 2.3470719757900445

Epoch: 5| Step: 7
Training loss: 1.7735637426376343
Validation loss: 2.3600589216396375

Epoch: 5| Step: 8
Training loss: 2.6612648963928223
Validation loss: 2.3467662847170265

Epoch: 5| Step: 9
Training loss: 2.728015422821045
Validation loss: 2.340748010143157

Epoch: 5| Step: 10
Training loss: 2.3846323490142822
Validation loss: 2.3180972119813323

Epoch: 257| Step: 0
Training loss: 2.2931714057922363
Validation loss: 2.334322626872729

Epoch: 5| Step: 1
Training loss: 2.9793472290039062
Validation loss: 2.3365675557044243

Epoch: 5| Step: 2
Training loss: 2.3075428009033203
Validation loss: 2.3295263218623337

Epoch: 5| Step: 3
Training loss: 2.280568838119507
Validation loss: 2.347148267171716

Epoch: 5| Step: 4
Training loss: 2.366608142852783
Validation loss: 2.336785098557831

Epoch: 5| Step: 5
Training loss: 2.430657148361206
Validation loss: 2.3316708303266958

Epoch: 5| Step: 6
Training loss: 2.1280856132507324
Validation loss: 2.3205910446823284

Epoch: 5| Step: 7
Training loss: 2.7616333961486816
Validation loss: 2.3236716716520247

Epoch: 5| Step: 8
Training loss: 2.133456230163574
Validation loss: 2.320194349494032

Epoch: 5| Step: 9
Training loss: 2.6389317512512207
Validation loss: 2.3253192619610856

Epoch: 5| Step: 10
Training loss: 2.8876864910125732
Validation loss: 2.3255748620597263

Epoch: 258| Step: 0
Training loss: 3.4501266479492188
Validation loss: 2.335137298030238

Epoch: 5| Step: 1
Training loss: 2.8042919635772705
Validation loss: 2.321153994529478

Epoch: 5| Step: 2
Training loss: 2.6664719581604004
Validation loss: 2.3052806162065074

Epoch: 5| Step: 3
Training loss: 2.032104253768921
Validation loss: 2.3047669318414505

Epoch: 5| Step: 4
Training loss: 2.2090632915496826
Validation loss: 2.291115983839958

Epoch: 5| Step: 5
Training loss: 1.8540828227996826
Validation loss: 2.2952117073920464

Epoch: 5| Step: 6
Training loss: 2.327213764190674
Validation loss: 2.3086351784326697

Epoch: 5| Step: 7
Training loss: 2.581613540649414
Validation loss: 2.319943651076286

Epoch: 5| Step: 8
Training loss: 2.3357913494110107
Validation loss: 2.3110055077460503

Epoch: 5| Step: 9
Training loss: 2.445641279220581
Validation loss: 2.328138187367429

Epoch: 5| Step: 10
Training loss: 2.317154884338379
Validation loss: 2.3344654011470016

Epoch: 259| Step: 0
Training loss: 2.0862274169921875
Validation loss: 2.34381010711834

Epoch: 5| Step: 1
Training loss: 2.5810770988464355
Validation loss: 2.353368402809225

Epoch: 5| Step: 2
Training loss: 2.5121681690216064
Validation loss: 2.3578034254812423

Epoch: 5| Step: 3
Training loss: 2.21808123588562
Validation loss: 2.3597685649830806

Epoch: 5| Step: 4
Training loss: 1.984403371810913
Validation loss: 2.3662232083659016

Epoch: 5| Step: 5
Training loss: 2.8679895401000977
Validation loss: 2.364504316801666

Epoch: 5| Step: 6
Training loss: 2.566007614135742
Validation loss: 2.3538821410107356

Epoch: 5| Step: 7
Training loss: 2.6552679538726807
Validation loss: 2.351603264449745

Epoch: 5| Step: 8
Training loss: 2.7165865898132324
Validation loss: 2.3324447024253105

Epoch: 5| Step: 9
Training loss: 2.9121928215026855
Validation loss: 2.313469038214735

Epoch: 5| Step: 10
Training loss: 2.1812961101531982
Validation loss: 2.317455432748282

Epoch: 260| Step: 0
Training loss: 2.906567096710205
Validation loss: 2.3067400686202513

Epoch: 5| Step: 1
Training loss: 2.28475022315979
Validation loss: 2.2891330052447576

Epoch: 5| Step: 2
Training loss: 2.279879093170166
Validation loss: 2.2886676249965543

Epoch: 5| Step: 3
Training loss: 2.281419515609741
Validation loss: 2.302495002746582

Epoch: 5| Step: 4
Training loss: 2.4294703006744385
Validation loss: 2.3001401142407487

Epoch: 5| Step: 5
Training loss: 2.791186809539795
Validation loss: 2.3170577787583873

Epoch: 5| Step: 6
Training loss: 1.936926245689392
Validation loss: 2.320515645447598

Epoch: 5| Step: 7
Training loss: 2.6814486980438232
Validation loss: 2.303549676813105

Epoch: 5| Step: 8
Training loss: 2.1454761028289795
Validation loss: 2.3220114579764743

Epoch: 5| Step: 9
Training loss: 2.9982686042785645
Validation loss: 2.3230535496947584

Epoch: 5| Step: 10
Training loss: 2.2864925861358643
Validation loss: 2.3294167723706973

Epoch: 261| Step: 0
Training loss: 2.7793917655944824
Validation loss: 2.3245425916487172

Epoch: 5| Step: 1
Training loss: 2.963068723678589
Validation loss: 2.325813936930831

Epoch: 5| Step: 2
Training loss: 2.461416244506836
Validation loss: 2.3259177156673965

Epoch: 5| Step: 3
Training loss: 2.1953670978546143
Validation loss: 2.316759160769883

Epoch: 5| Step: 4
Training loss: 1.7546513080596924
Validation loss: 2.2997050054611696

Epoch: 5| Step: 5
Training loss: 2.7623062133789062
Validation loss: 2.299619474718648

Epoch: 5| Step: 6
Training loss: 2.2009568214416504
Validation loss: 2.3009422620137534

Epoch: 5| Step: 7
Training loss: 2.3500404357910156
Validation loss: 2.3080590104544036

Epoch: 5| Step: 8
Training loss: 2.509899854660034
Validation loss: 2.312692024374521

Epoch: 5| Step: 9
Training loss: 2.6805381774902344
Validation loss: 2.320854176757156

Epoch: 5| Step: 10
Training loss: 2.456592082977295
Validation loss: 2.3485722234172206

Epoch: 262| Step: 0
Training loss: 2.61662220954895
Validation loss: 2.323311892888879

Epoch: 5| Step: 1
Training loss: 2.728853225708008
Validation loss: 2.3338809936277327

Epoch: 5| Step: 2
Training loss: 2.7080931663513184
Validation loss: 2.319831285425412

Epoch: 5| Step: 3
Training loss: 1.389373540878296
Validation loss: 2.3197448997087378

Epoch: 5| Step: 4
Training loss: 2.6531589031219482
Validation loss: 2.3194748611860376

Epoch: 5| Step: 5
Training loss: 3.516982316970825
Validation loss: 2.3181098148386967

Epoch: 5| Step: 6
Training loss: 2.1500296592712402
Validation loss: 2.2924863446143364

Epoch: 5| Step: 7
Training loss: 2.7667653560638428
Validation loss: 2.2979582176413587

Epoch: 5| Step: 8
Training loss: 2.2274937629699707
Validation loss: 2.2976337658461703

Epoch: 5| Step: 9
Training loss: 1.9732933044433594
Validation loss: 2.298535370057629

Epoch: 5| Step: 10
Training loss: 2.231698751449585
Validation loss: 2.325989851387598

Epoch: 263| Step: 0
Training loss: 2.433372974395752
Validation loss: 2.32576512264949

Epoch: 5| Step: 1
Training loss: 2.377350330352783
Validation loss: 2.313966356297975

Epoch: 5| Step: 2
Training loss: 2.342771530151367
Validation loss: 2.320720895644157

Epoch: 5| Step: 3
Training loss: 2.705535888671875
Validation loss: 2.338840664073985

Epoch: 5| Step: 4
Training loss: 2.84089994430542
Validation loss: 2.3405661582946777

Epoch: 5| Step: 5
Training loss: 2.307476282119751
Validation loss: 2.3310492807818997

Epoch: 5| Step: 6
Training loss: 2.1799817085266113
Validation loss: 2.3541923774186

Epoch: 5| Step: 7
Training loss: 2.906214475631714
Validation loss: 2.342377242221627

Epoch: 5| Step: 8
Training loss: 2.064563035964966
Validation loss: 2.340240647715907

Epoch: 5| Step: 9
Training loss: 2.4025638103485107
Validation loss: 2.3119537907262004

Epoch: 5| Step: 10
Training loss: 2.3252272605895996
Validation loss: 2.294306539720105

Epoch: 264| Step: 0
Training loss: 2.071021318435669
Validation loss: 2.293133515183644

Epoch: 5| Step: 1
Training loss: 2.97218918800354
Validation loss: 2.280345127146731

Epoch: 5| Step: 2
Training loss: 2.4428606033325195
Validation loss: 2.2910938955122426

Epoch: 5| Step: 3
Training loss: 2.4557411670684814
Validation loss: 2.282994293397473

Epoch: 5| Step: 4
Training loss: 2.1697258949279785
Validation loss: 2.2813383968927528

Epoch: 5| Step: 5
Training loss: 2.234800338745117
Validation loss: 2.2864777977748583

Epoch: 5| Step: 6
Training loss: 2.474525213241577
Validation loss: 2.3004773483481458

Epoch: 5| Step: 7
Training loss: 2.804243564605713
Validation loss: 2.31968161623965

Epoch: 5| Step: 8
Training loss: 2.7489755153656006
Validation loss: 2.3373444541808097

Epoch: 5| Step: 9
Training loss: 2.0829451084136963
Validation loss: 2.3447539165455806

Epoch: 5| Step: 10
Training loss: 2.61196231842041
Validation loss: 2.33798171371542

Epoch: 265| Step: 0
Training loss: 2.813560962677002
Validation loss: 2.3476729034095682

Epoch: 5| Step: 1
Training loss: 3.0134923458099365
Validation loss: 2.342385768890381

Epoch: 5| Step: 2
Training loss: 2.681461811065674
Validation loss: 2.3231636862601004

Epoch: 5| Step: 3
Training loss: 2.1616129875183105
Validation loss: 2.3147732891062254

Epoch: 5| Step: 4
Training loss: 2.6489875316619873
Validation loss: 2.297154729084302

Epoch: 5| Step: 5
Training loss: 2.3083925247192383
Validation loss: 2.296083573372133

Epoch: 5| Step: 6
Training loss: 2.331285238265991
Validation loss: 2.299036677165698

Epoch: 5| Step: 7
Training loss: 2.388796806335449
Validation loss: 2.3057509570993404

Epoch: 5| Step: 8
Training loss: 2.3832905292510986
Validation loss: 2.303632923351821

Epoch: 5| Step: 9
Training loss: 2.340327739715576
Validation loss: 2.307224222408828

Epoch: 5| Step: 10
Training loss: 1.927943468093872
Validation loss: 2.2984588505119405

Epoch: 266| Step: 0
Training loss: 2.438230514526367
Validation loss: 2.3032529507913897

Epoch: 5| Step: 1
Training loss: 2.6030073165893555
Validation loss: 2.330582595640613

Epoch: 5| Step: 2
Training loss: 2.9054787158966064
Validation loss: 2.321290103338098

Epoch: 5| Step: 3
Training loss: 2.2061972618103027
Validation loss: 2.3231172433463474

Epoch: 5| Step: 4
Training loss: 2.5897271633148193
Validation loss: 2.3245805130209973

Epoch: 5| Step: 5
Training loss: 2.128763198852539
Validation loss: 2.302090753791153

Epoch: 5| Step: 6
Training loss: 2.4369466304779053
Validation loss: 2.3159204016449633

Epoch: 5| Step: 7
Training loss: 1.9469406604766846
Validation loss: 2.3062827612764094

Epoch: 5| Step: 8
Training loss: 2.9696364402770996
Validation loss: 2.299315062902307

Epoch: 5| Step: 9
Training loss: 2.4438083171844482
Validation loss: 2.290729171486311

Epoch: 5| Step: 10
Training loss: 2.2204089164733887
Validation loss: 2.2854749951311337

Epoch: 267| Step: 0
Training loss: 2.3541781902313232
Validation loss: 2.290762988469934

Epoch: 5| Step: 1
Training loss: 2.5201239585876465
Validation loss: 2.2915475368499756

Epoch: 5| Step: 2
Training loss: 2.3083982467651367
Validation loss: 2.285884318813201

Epoch: 5| Step: 3
Training loss: 1.9047075510025024
Validation loss: 2.3009636235493485

Epoch: 5| Step: 4
Training loss: 2.7968311309814453
Validation loss: 2.2897699340697257

Epoch: 5| Step: 5
Training loss: 2.175630569458008
Validation loss: 2.2940425847166326

Epoch: 5| Step: 6
Training loss: 3.349109172821045
Validation loss: 2.32453340612432

Epoch: 5| Step: 7
Training loss: 2.519962787628174
Validation loss: 2.3201545207731185

Epoch: 5| Step: 8
Training loss: 2.0580132007598877
Validation loss: 2.314221356504707

Epoch: 5| Step: 9
Training loss: 2.3768296241760254
Validation loss: 2.321125343281736

Epoch: 5| Step: 10
Training loss: 2.5756866931915283
Validation loss: 2.3227699597676597

Epoch: 268| Step: 0
Training loss: 2.7078044414520264
Validation loss: 2.3286039649799304

Epoch: 5| Step: 1
Training loss: 1.9802039861679077
Validation loss: 2.336459413651497

Epoch: 5| Step: 2
Training loss: 2.6821343898773193
Validation loss: 2.3269939063697733

Epoch: 5| Step: 3
Training loss: 2.1238038539886475
Validation loss: 2.3159790218517347

Epoch: 5| Step: 4
Training loss: 2.2130656242370605
Validation loss: 2.333564345554639

Epoch: 5| Step: 5
Training loss: 1.889007568359375
Validation loss: 2.3368676247135287

Epoch: 5| Step: 6
Training loss: 2.015451431274414
Validation loss: 2.325115267948438

Epoch: 5| Step: 7
Training loss: 2.542577028274536
Validation loss: 2.326879806416009

Epoch: 5| Step: 8
Training loss: 3.023716449737549
Validation loss: 2.3148102862860567

Epoch: 5| Step: 9
Training loss: 2.82834792137146
Validation loss: 2.319870238663048

Epoch: 5| Step: 10
Training loss: 2.9479787349700928
Validation loss: 2.3199414822363083

Epoch: 269| Step: 0
Training loss: 2.7100729942321777
Validation loss: 2.3019564510673605

Epoch: 5| Step: 1
Training loss: 2.527536630630493
Validation loss: 2.2864278157552085

Epoch: 5| Step: 2
Training loss: 1.4362454414367676
Validation loss: 2.2836445249536985

Epoch: 5| Step: 3
Training loss: 2.4380834102630615
Validation loss: 2.2813843680966284

Epoch: 5| Step: 4
Training loss: 2.3581526279449463
Validation loss: 2.279927175532105

Epoch: 5| Step: 5
Training loss: 2.099047899246216
Validation loss: 2.272815864573243

Epoch: 5| Step: 6
Training loss: 2.7766222953796387
Validation loss: 2.2857542550691994

Epoch: 5| Step: 7
Training loss: 2.6179795265197754
Validation loss: 2.277975164433961

Epoch: 5| Step: 8
Training loss: 2.3921666145324707
Validation loss: 2.284258488685854

Epoch: 5| Step: 9
Training loss: 2.9113144874572754
Validation loss: 2.2922476876166558

Epoch: 5| Step: 10
Training loss: 2.5348575115203857
Validation loss: 2.287278018971925

Epoch: 270| Step: 0
Training loss: 2.7670531272888184
Validation loss: 2.298468215491182

Epoch: 5| Step: 1
Training loss: 1.8890174627304077
Validation loss: 2.303185006623627

Epoch: 5| Step: 2
Training loss: 2.195983409881592
Validation loss: 2.29662484763771

Epoch: 5| Step: 3
Training loss: 3.042410373687744
Validation loss: 2.2893423290662867

Epoch: 5| Step: 4
Training loss: 2.6371326446533203
Validation loss: 2.3047906647446337

Epoch: 5| Step: 5
Training loss: 2.742333173751831
Validation loss: 2.305658999309745

Epoch: 5| Step: 6
Training loss: 2.3922250270843506
Validation loss: 2.2967029040859592

Epoch: 5| Step: 7
Training loss: 1.930539846420288
Validation loss: 2.307787956730012

Epoch: 5| Step: 8
Training loss: 2.4374325275421143
Validation loss: 2.3055199051416047

Epoch: 5| Step: 9
Training loss: 2.169318914413452
Validation loss: 2.3121158128143637

Epoch: 5| Step: 10
Training loss: 2.54298996925354
Validation loss: 2.309398215304139

Epoch: 271| Step: 0
Training loss: 2.857783555984497
Validation loss: 2.3095078493959162

Epoch: 5| Step: 1
Training loss: 1.5614570379257202
Validation loss: 2.3071513816874516

Epoch: 5| Step: 2
Training loss: 2.1304216384887695
Validation loss: 2.2903892763199343

Epoch: 5| Step: 3
Training loss: 3.1291964054107666
Validation loss: 2.2877721760862615

Epoch: 5| Step: 4
Training loss: 2.861055850982666
Validation loss: 2.2915038806135937

Epoch: 5| Step: 5
Training loss: 2.4045071601867676
Validation loss: 2.28998290851552

Epoch: 5| Step: 6
Training loss: 2.6593737602233887
Validation loss: 2.2891958528949368

Epoch: 5| Step: 7
Training loss: 2.192591428756714
Validation loss: 2.279062009626819

Epoch: 5| Step: 8
Training loss: 2.654634952545166
Validation loss: 2.2962788586975424

Epoch: 5| Step: 9
Training loss: 2.0000176429748535
Validation loss: 2.3163009805064045

Epoch: 5| Step: 10
Training loss: 2.180579423904419
Validation loss: 2.316408985404558

Epoch: 272| Step: 0
Training loss: 2.1962599754333496
Validation loss: 2.3244197137894167

Epoch: 5| Step: 1
Training loss: 2.182748317718506
Validation loss: 2.336725301640008

Epoch: 5| Step: 2
Training loss: 3.4639461040496826
Validation loss: 2.349213743722567

Epoch: 5| Step: 3
Training loss: 1.7650470733642578
Validation loss: 2.339449049324118

Epoch: 5| Step: 4
Training loss: 2.0974209308624268
Validation loss: 2.3381990822412635

Epoch: 5| Step: 5
Training loss: 2.426881790161133
Validation loss: 2.3210906264602498

Epoch: 5| Step: 6
Training loss: 2.1029515266418457
Validation loss: 2.306735525849045

Epoch: 5| Step: 7
Training loss: 2.702333927154541
Validation loss: 2.2829388803051365

Epoch: 5| Step: 8
Training loss: 2.6555449962615967
Validation loss: 2.2714636300199773

Epoch: 5| Step: 9
Training loss: 2.339867115020752
Validation loss: 2.2809880805271927

Epoch: 5| Step: 10
Training loss: 2.838730812072754
Validation loss: 2.276993966871692

Epoch: 273| Step: 0
Training loss: 2.453526020050049
Validation loss: 2.2874027759798112

Epoch: 5| Step: 1
Training loss: 2.0238559246063232
Validation loss: 2.257347401752267

Epoch: 5| Step: 2
Training loss: 2.975839138031006
Validation loss: 2.2741206435747046

Epoch: 5| Step: 3
Training loss: 2.61085844039917
Validation loss: 2.269770209507276

Epoch: 5| Step: 4
Training loss: 2.15512752532959
Validation loss: 2.2959755184829875

Epoch: 5| Step: 5
Training loss: 2.268777370452881
Validation loss: 2.305222140845432

Epoch: 5| Step: 6
Training loss: 2.221402406692505
Validation loss: 2.307483934587048

Epoch: 5| Step: 7
Training loss: 2.627279758453369
Validation loss: 2.310329896147533

Epoch: 5| Step: 8
Training loss: 2.309142589569092
Validation loss: 2.315386326082291

Epoch: 5| Step: 9
Training loss: 2.978487730026245
Validation loss: 2.312828125492219

Epoch: 5| Step: 10
Training loss: 2.0125668048858643
Validation loss: 2.302781025568644

Epoch: 274| Step: 0
Training loss: 2.2842040061950684
Validation loss: 2.3151680602822253

Epoch: 5| Step: 1
Training loss: 2.4654622077941895
Validation loss: 2.301414848655783

Epoch: 5| Step: 2
Training loss: 2.5075016021728516
Validation loss: 2.29764602773933

Epoch: 5| Step: 3
Training loss: 2.255267381668091
Validation loss: 2.2969642287941388

Epoch: 5| Step: 4
Training loss: 2.670278549194336
Validation loss: 2.2884163189959783

Epoch: 5| Step: 5
Training loss: 2.9929471015930176
Validation loss: 2.2972321920497443

Epoch: 5| Step: 6
Training loss: 2.6992363929748535
Validation loss: 2.290626005459857

Epoch: 5| Step: 7
Training loss: 1.9782447814941406
Validation loss: 2.3112991650899253

Epoch: 5| Step: 8
Training loss: 1.851433515548706
Validation loss: 2.297991378332979

Epoch: 5| Step: 9
Training loss: 2.649961233139038
Validation loss: 2.2926567651892222

Epoch: 5| Step: 10
Training loss: 2.408350706100464
Validation loss: 2.2925048489724436

Epoch: 275| Step: 0
Training loss: 2.938453435897827
Validation loss: 2.2865082320346626

Epoch: 5| Step: 1
Training loss: 2.4784157276153564
Validation loss: 2.2864680392767793

Epoch: 5| Step: 2
Training loss: 2.652869701385498
Validation loss: 2.2886735072699924

Epoch: 5| Step: 3
Training loss: 3.0079493522644043
Validation loss: 2.2885575884131977

Epoch: 5| Step: 4
Training loss: 2.1369104385375977
Validation loss: 2.2818244426481185

Epoch: 5| Step: 5
Training loss: 2.19746732711792
Validation loss: 2.28477801815156

Epoch: 5| Step: 6
Training loss: 2.422276020050049
Validation loss: 2.3056544309021323

Epoch: 5| Step: 7
Training loss: 1.5876009464263916
Validation loss: 2.291369153607276

Epoch: 5| Step: 8
Training loss: 2.5132577419281006
Validation loss: 2.3096854174008934

Epoch: 5| Step: 9
Training loss: 1.853191614151001
Validation loss: 2.2996095354839037

Epoch: 5| Step: 10
Training loss: 2.983128547668457
Validation loss: 2.313706414673918

Epoch: 276| Step: 0
Training loss: 2.459416151046753
Validation loss: 2.327921905825215

Epoch: 5| Step: 1
Training loss: 3.0395760536193848
Validation loss: 2.308301028384957

Epoch: 5| Step: 2
Training loss: 2.8252978324890137
Validation loss: 2.2995454380589146

Epoch: 5| Step: 3
Training loss: 2.902998685836792
Validation loss: 2.3220732340248684

Epoch: 5| Step: 4
Training loss: 2.400667905807495
Validation loss: 2.332325173962501

Epoch: 5| Step: 5
Training loss: 2.673184633255005
Validation loss: 2.302202650295791

Epoch: 5| Step: 6
Training loss: 1.617868423461914
Validation loss: 2.3068774541219077

Epoch: 5| Step: 7
Training loss: 2.2348315715789795
Validation loss: 2.298137585322062

Epoch: 5| Step: 8
Training loss: 1.9600505828857422
Validation loss: 2.294797617902038

Epoch: 5| Step: 9
Training loss: 2.3313775062561035
Validation loss: 2.303767196593746

Epoch: 5| Step: 10
Training loss: 2.2366020679473877
Validation loss: 2.305474160819925

Epoch: 277| Step: 0
Training loss: 2.2953667640686035
Validation loss: 2.3137863951344646

Epoch: 5| Step: 1
Training loss: 2.114513874053955
Validation loss: 2.3434329366171234

Epoch: 5| Step: 2
Training loss: 1.9473682641983032
Validation loss: 2.3531913180505075

Epoch: 5| Step: 3
Training loss: 2.849189043045044
Validation loss: 2.324067355484091

Epoch: 5| Step: 4
Training loss: 2.0166847705841064
Validation loss: 2.322111156678969

Epoch: 5| Step: 5
Training loss: 2.9074695110321045
Validation loss: 2.2909977166883406

Epoch: 5| Step: 6
Training loss: 1.9648768901824951
Validation loss: 2.2693278148610103

Epoch: 5| Step: 7
Training loss: 3.517817735671997
Validation loss: 2.2717714117419336

Epoch: 5| Step: 8
Training loss: 2.668290376663208
Validation loss: 2.272142956333776

Epoch: 5| Step: 9
Training loss: 2.563429355621338
Validation loss: 2.2735593242029988

Epoch: 5| Step: 10
Training loss: 1.7904924154281616
Validation loss: 2.274344955721209

Epoch: 278| Step: 0
Training loss: 2.663323163986206
Validation loss: 2.2622673614050752

Epoch: 5| Step: 1
Training loss: 2.7941646575927734
Validation loss: 2.2981393042431084

Epoch: 5| Step: 2
Training loss: 2.2209784984588623
Validation loss: 2.294571013860805

Epoch: 5| Step: 3
Training loss: 2.0022478103637695
Validation loss: 2.280083002582673

Epoch: 5| Step: 4
Training loss: 2.3719513416290283
Validation loss: 2.27851689246393

Epoch: 5| Step: 5
Training loss: 2.761133909225464
Validation loss: 2.2719126234772387

Epoch: 5| Step: 6
Training loss: 2.7252197265625
Validation loss: 2.2736693620681763

Epoch: 5| Step: 7
Training loss: 2.1744933128356934
Validation loss: 2.290748708991594

Epoch: 5| Step: 8
Training loss: 2.4432637691497803
Validation loss: 2.2976480017426195

Epoch: 5| Step: 9
Training loss: 1.8280149698257446
Validation loss: 2.2965361174716743

Epoch: 5| Step: 10
Training loss: 2.613828659057617
Validation loss: 2.3281051817760674

Epoch: 279| Step: 0
Training loss: 2.094918727874756
Validation loss: 2.307708442852061

Epoch: 5| Step: 1
Training loss: 1.5302222967147827
Validation loss: 2.3406380004780267

Epoch: 5| Step: 2
Training loss: 2.32000994682312
Validation loss: 2.3255021238839753

Epoch: 5| Step: 3
Training loss: 2.1362485885620117
Validation loss: 2.3037919972532537

Epoch: 5| Step: 4
Training loss: 2.162776231765747
Validation loss: 2.2892113577935005

Epoch: 5| Step: 5
Training loss: 2.030686855316162
Validation loss: 2.2860233399175827

Epoch: 5| Step: 6
Training loss: 3.0625901222229004
Validation loss: 2.2936869411058325

Epoch: 5| Step: 7
Training loss: 3.322850465774536
Validation loss: 2.2820188358265865

Epoch: 5| Step: 8
Training loss: 2.7299141883850098
Validation loss: 2.2727184654563986

Epoch: 5| Step: 9
Training loss: 2.6027655601501465
Validation loss: 2.269033775534681

Epoch: 5| Step: 10
Training loss: 2.6731996536254883
Validation loss: 2.274185939501691

Epoch: 280| Step: 0
Training loss: 2.2985799312591553
Validation loss: 2.2690957182197162

Epoch: 5| Step: 1
Training loss: 2.247652053833008
Validation loss: 2.274561494909307

Epoch: 5| Step: 2
Training loss: 2.0202248096466064
Validation loss: 2.282280345116892

Epoch: 5| Step: 3
Training loss: 3.2487339973449707
Validation loss: 2.2751888767365487

Epoch: 5| Step: 4
Training loss: 2.6985819339752197
Validation loss: 2.2614905424015497

Epoch: 5| Step: 5
Training loss: 2.4868361949920654
Validation loss: 2.2533338762098745

Epoch: 5| Step: 6
Training loss: 2.0770492553710938
Validation loss: 2.2547161681677705

Epoch: 5| Step: 7
Training loss: 1.618163824081421
Validation loss: 2.2672617717455794

Epoch: 5| Step: 8
Training loss: 2.456672191619873
Validation loss: 2.280125073207322

Epoch: 5| Step: 9
Training loss: 2.6338062286376953
Validation loss: 2.28738937839385

Epoch: 5| Step: 10
Training loss: 2.7454640865325928
Validation loss: 2.2964919164616573

Epoch: 281| Step: 0
Training loss: 2.5712552070617676
Validation loss: 2.295291098215247

Epoch: 5| Step: 1
Training loss: 2.223109722137451
Validation loss: 2.2992133504600933

Epoch: 5| Step: 2
Training loss: 2.410490036010742
Validation loss: 2.2922320570997012

Epoch: 5| Step: 3
Training loss: 2.3465089797973633
Validation loss: 2.2802891961989866

Epoch: 5| Step: 4
Training loss: 2.196040391921997
Validation loss: 2.275844504756312

Epoch: 5| Step: 5
Training loss: 2.3414738178253174
Validation loss: 2.29357635846702

Epoch: 5| Step: 6
Training loss: 2.47318696975708
Validation loss: 2.2882738651767855

Epoch: 5| Step: 7
Training loss: 3.2246384620666504
Validation loss: 2.2950885782959642

Epoch: 5| Step: 8
Training loss: 1.314298391342163
Validation loss: 2.2991735063573366

Epoch: 5| Step: 9
Training loss: 2.413853883743286
Validation loss: 2.2868234880508913

Epoch: 5| Step: 10
Training loss: 3.091979503631592
Validation loss: 2.2797905193862094

Epoch: 282| Step: 0
Training loss: 2.478010892868042
Validation loss: 2.2878834509080455

Epoch: 5| Step: 1
Training loss: 2.3380379676818848
Validation loss: 2.2913116050022904

Epoch: 5| Step: 2
Training loss: 2.2476089000701904
Validation loss: 2.2837069675486577

Epoch: 5| Step: 3
Training loss: 2.0590739250183105
Validation loss: 2.259287985422278

Epoch: 5| Step: 4
Training loss: 2.036348819732666
Validation loss: 2.274523309482041

Epoch: 5| Step: 5
Training loss: 2.656815528869629
Validation loss: 2.2714945641897057

Epoch: 5| Step: 6
Training loss: 2.3952908515930176
Validation loss: 2.28967252854378

Epoch: 5| Step: 7
Training loss: 2.7662320137023926
Validation loss: 2.2787656732784805

Epoch: 5| Step: 8
Training loss: 2.421194076538086
Validation loss: 2.262519851807625

Epoch: 5| Step: 9
Training loss: 2.248960494995117
Validation loss: 2.251587288354033

Epoch: 5| Step: 10
Training loss: 2.962815761566162
Validation loss: 2.2477845273992068

Epoch: 283| Step: 0
Training loss: 2.0723681449890137
Validation loss: 2.250217371089484

Epoch: 5| Step: 1
Training loss: 2.6060359477996826
Validation loss: 2.2529158284587245

Epoch: 5| Step: 2
Training loss: 2.038255453109741
Validation loss: 2.2550458318443707

Epoch: 5| Step: 3
Training loss: 2.038391590118408
Validation loss: 2.269458898933985

Epoch: 5| Step: 4
Training loss: 2.848972797393799
Validation loss: 2.2491445182472147

Epoch: 5| Step: 5
Training loss: 2.3678975105285645
Validation loss: 2.260468044588643

Epoch: 5| Step: 6
Training loss: 2.1676130294799805
Validation loss: 2.2508772932073122

Epoch: 5| Step: 7
Training loss: 2.3591384887695312
Validation loss: 2.2654402332921184

Epoch: 5| Step: 8
Training loss: 2.5166118144989014
Validation loss: 2.2531765891659643

Epoch: 5| Step: 9
Training loss: 2.656810998916626
Validation loss: 2.257362533641118

Epoch: 5| Step: 10
Training loss: 2.7338857650756836
Validation loss: 2.2503915755979476

Epoch: 284| Step: 0
Training loss: 2.3036699295043945
Validation loss: 2.2689815721204205

Epoch: 5| Step: 1
Training loss: 2.4962759017944336
Validation loss: 2.2642107650797856

Epoch: 5| Step: 2
Training loss: 2.4813172817230225
Validation loss: 2.289045895299604

Epoch: 5| Step: 3
Training loss: 2.756619930267334
Validation loss: 2.3029795692813013

Epoch: 5| Step: 4
Training loss: 2.3352949619293213
Validation loss: 2.2916279377475863

Epoch: 5| Step: 5
Training loss: 2.2587504386901855
Validation loss: 2.2874291789147163

Epoch: 5| Step: 6
Training loss: 2.394188404083252
Validation loss: 2.2920721089968117

Epoch: 5| Step: 7
Training loss: 1.9534248113632202
Validation loss: 2.266300416761829

Epoch: 5| Step: 8
Training loss: 2.539503574371338
Validation loss: 2.244075159872732

Epoch: 5| Step: 9
Training loss: 2.134838104248047
Validation loss: 2.2569160551153202

Epoch: 5| Step: 10
Training loss: 2.7962985038757324
Validation loss: 2.2548440630717943

Epoch: 285| Step: 0
Training loss: 2.476266384124756
Validation loss: 2.2553741009004655

Epoch: 5| Step: 1
Training loss: 2.540457248687744
Validation loss: 2.264957679215298

Epoch: 5| Step: 2
Training loss: 2.5846481323242188
Validation loss: 2.255919123208651

Epoch: 5| Step: 3
Training loss: 2.194366931915283
Validation loss: 2.2531222835663827

Epoch: 5| Step: 4
Training loss: 2.3991942405700684
Validation loss: 2.267985056805354

Epoch: 5| Step: 5
Training loss: 1.9547868967056274
Validation loss: 2.2649887325943157

Epoch: 5| Step: 6
Training loss: 2.2131128311157227
Validation loss: 2.267493317204137

Epoch: 5| Step: 7
Training loss: 1.8368021249771118
Validation loss: 2.278047589845555

Epoch: 5| Step: 8
Training loss: 2.204599618911743
Validation loss: 2.276377724063012

Epoch: 5| Step: 9
Training loss: 2.927927017211914
Validation loss: 2.276735480113696

Epoch: 5| Step: 10
Training loss: 3.1704719066619873
Validation loss: 2.28484732233068

Epoch: 286| Step: 0
Training loss: 2.431758403778076
Validation loss: 2.319801776639877

Epoch: 5| Step: 1
Training loss: 2.501931667327881
Validation loss: 2.3113159697542907

Epoch: 5| Step: 2
Training loss: 2.1844959259033203
Validation loss: 2.2815019494743756

Epoch: 5| Step: 3
Training loss: 3.03999400138855
Validation loss: 2.2606811395255466

Epoch: 5| Step: 4
Training loss: 1.6475410461425781
Validation loss: 2.244792035830918

Epoch: 5| Step: 5
Training loss: 2.767916440963745
Validation loss: 2.2437388268850182

Epoch: 5| Step: 6
Training loss: 3.0092949867248535
Validation loss: 2.2533643732788744

Epoch: 5| Step: 7
Training loss: 2.0060157775878906
Validation loss: 2.2604440207122476

Epoch: 5| Step: 8
Training loss: 2.0959904193878174
Validation loss: 2.2508376811140325

Epoch: 5| Step: 9
Training loss: 2.3965158462524414
Validation loss: 2.2728365159803823

Epoch: 5| Step: 10
Training loss: 2.494283437728882
Validation loss: 2.2668267257751955

Epoch: 287| Step: 0
Training loss: 2.0053677558898926
Validation loss: 2.2810999629318074

Epoch: 5| Step: 1
Training loss: 2.507916212081909
Validation loss: 2.288468259637074

Epoch: 5| Step: 2
Training loss: 1.9470577239990234
Validation loss: 2.2925980052640362

Epoch: 5| Step: 3
Training loss: 2.8389458656311035
Validation loss: 2.29196161095814

Epoch: 5| Step: 4
Training loss: 2.308809518814087
Validation loss: 2.3021059677165043

Epoch: 5| Step: 5
Training loss: 2.6684610843658447
Validation loss: 2.309905280349075

Epoch: 5| Step: 6
Training loss: 2.5796313285827637
Validation loss: 2.297303948351132

Epoch: 5| Step: 7
Training loss: 2.1345455646514893
Validation loss: 2.2711516887910905

Epoch: 5| Step: 8
Training loss: 2.321669101715088
Validation loss: 2.279116924091052

Epoch: 5| Step: 9
Training loss: 2.5984644889831543
Validation loss: 2.2564719300116263

Epoch: 5| Step: 10
Training loss: 2.3653202056884766
Validation loss: 2.2709329423084053

Epoch: 288| Step: 0
Training loss: 2.2751262187957764
Validation loss: 2.263467070876911

Epoch: 5| Step: 1
Training loss: 2.6461563110351562
Validation loss: 2.2823523949551325

Epoch: 5| Step: 2
Training loss: 1.8476892709732056
Validation loss: 2.2789808165642524

Epoch: 5| Step: 3
Training loss: 2.671283483505249
Validation loss: 2.2911261845660467

Epoch: 5| Step: 4
Training loss: 1.9743287563323975
Validation loss: 2.2597742388325353

Epoch: 5| Step: 5
Training loss: 2.6418468952178955
Validation loss: 2.256205681831606

Epoch: 5| Step: 6
Training loss: 2.500159740447998
Validation loss: 2.268251188339726

Epoch: 5| Step: 7
Training loss: 1.6250442266464233
Validation loss: 2.234806422264345

Epoch: 5| Step: 8
Training loss: 2.8119521141052246
Validation loss: 2.2588865680079304

Epoch: 5| Step: 9
Training loss: 2.416297435760498
Validation loss: 2.241232766900011

Epoch: 5| Step: 10
Training loss: 2.944265604019165
Validation loss: 2.264182218941309

Epoch: 289| Step: 0
Training loss: 2.7101409435272217
Validation loss: 2.2555248570698563

Epoch: 5| Step: 1
Training loss: 2.1064770221710205
Validation loss: 2.253040188102312

Epoch: 5| Step: 2
Training loss: 2.611851215362549
Validation loss: 2.275216708901108

Epoch: 5| Step: 3
Training loss: 2.5211215019226074
Validation loss: 2.2700479158791165

Epoch: 5| Step: 4
Training loss: 3.1531898975372314
Validation loss: 2.260379757932437

Epoch: 5| Step: 5
Training loss: 2.661400318145752
Validation loss: 2.266220890065675

Epoch: 5| Step: 6
Training loss: 2.0010035037994385
Validation loss: 2.2562471166733773

Epoch: 5| Step: 7
Training loss: 1.8741439580917358
Validation loss: 2.249666196043773

Epoch: 5| Step: 8
Training loss: 2.5226240158081055
Validation loss: 2.2474325754309215

Epoch: 5| Step: 9
Training loss: 1.812300682067871
Validation loss: 2.240276075178577

Epoch: 5| Step: 10
Training loss: 2.279895067214966
Validation loss: 2.246482700429937

Epoch: 290| Step: 0
Training loss: 2.6223440170288086
Validation loss: 2.257822782762589

Epoch: 5| Step: 1
Training loss: 2.1785547733306885
Validation loss: 2.2466603863623833

Epoch: 5| Step: 2
Training loss: 2.966928482055664
Validation loss: 2.2502042298675864

Epoch: 5| Step: 3
Training loss: 2.670863628387451
Validation loss: 2.2580041244465816

Epoch: 5| Step: 4
Training loss: 2.3728132247924805
Validation loss: 2.2661522703786052

Epoch: 5| Step: 5
Training loss: 1.9771912097930908
Validation loss: 2.2714857568023024

Epoch: 5| Step: 6
Training loss: 2.09147310256958
Validation loss: 2.279984804891771

Epoch: 5| Step: 7
Training loss: 2.271756649017334
Validation loss: 2.2742721803726687

Epoch: 5| Step: 8
Training loss: 2.4983136653900146
Validation loss: 2.2872358240107054

Epoch: 5| Step: 9
Training loss: 2.69124436378479
Validation loss: 2.2699479492761756

Epoch: 5| Step: 10
Training loss: 1.7193217277526855
Validation loss: 2.266322869126515

Epoch: 291| Step: 0
Training loss: 2.8206591606140137
Validation loss: 2.2448428779520015

Epoch: 5| Step: 1
Training loss: 1.9667030572891235
Validation loss: 2.24317902903403

Epoch: 5| Step: 2
Training loss: 2.5800774097442627
Validation loss: 2.2365707787134315

Epoch: 5| Step: 3
Training loss: 2.8478167057037354
Validation loss: 2.240965553509292

Epoch: 5| Step: 4
Training loss: 3.1442062854766846
Validation loss: 2.217468891092526

Epoch: 5| Step: 5
Training loss: 2.2498834133148193
Validation loss: 2.2372530019411476

Epoch: 5| Step: 6
Training loss: 2.4202327728271484
Validation loss: 2.226160418602728

Epoch: 5| Step: 7
Training loss: 2.371619462966919
Validation loss: 2.232919011064755

Epoch: 5| Step: 8
Training loss: 2.116299867630005
Validation loss: 2.2400812936085526

Epoch: 5| Step: 9
Training loss: 1.5235397815704346
Validation loss: 2.241766571998596

Epoch: 5| Step: 10
Training loss: 2.0684995651245117
Validation loss: 2.255433092835129

Epoch: 292| Step: 0
Training loss: 2.9889864921569824
Validation loss: 2.2810460726420083

Epoch: 5| Step: 1
Training loss: 2.483145236968994
Validation loss: 2.262367286989766

Epoch: 5| Step: 2
Training loss: 1.5524282455444336
Validation loss: 2.2475438989618772

Epoch: 5| Step: 3
Training loss: 2.7724509239196777
Validation loss: 2.2516436269206386

Epoch: 5| Step: 4
Training loss: 3.182037830352783
Validation loss: 2.267767103769446

Epoch: 5| Step: 5
Training loss: 2.4830965995788574
Validation loss: 2.2586777210235596

Epoch: 5| Step: 6
Training loss: 1.9747774600982666
Validation loss: 2.247440174061765

Epoch: 5| Step: 7
Training loss: 1.913267731666565
Validation loss: 2.2477753290566067

Epoch: 5| Step: 8
Training loss: 1.670488953590393
Validation loss: 2.245469544523506

Epoch: 5| Step: 9
Training loss: 2.350098133087158
Validation loss: 2.2470004135562527

Epoch: 5| Step: 10
Training loss: 2.8118016719818115
Validation loss: 2.248634904943487

Epoch: 293| Step: 0
Training loss: 2.28405499458313
Validation loss: 2.263175505463795

Epoch: 5| Step: 1
Training loss: 2.491330862045288
Validation loss: 2.27262411450827

Epoch: 5| Step: 2
Training loss: 2.1341991424560547
Validation loss: 2.2896490686683246

Epoch: 5| Step: 3
Training loss: 2.195302724838257
Validation loss: 2.297890754156215

Epoch: 5| Step: 4
Training loss: 2.1662447452545166
Validation loss: 2.284142045564549

Epoch: 5| Step: 5
Training loss: 2.0206944942474365
Validation loss: 2.2714169358694427

Epoch: 5| Step: 6
Training loss: 2.2259116172790527
Validation loss: 2.253654697889923

Epoch: 5| Step: 7
Training loss: 3.2337493896484375
Validation loss: 2.2437315141001055

Epoch: 5| Step: 8
Training loss: 2.3999316692352295
Validation loss: 2.2427243212217927

Epoch: 5| Step: 9
Training loss: 2.446474075317383
Validation loss: 2.240202498692338

Epoch: 5| Step: 10
Training loss: 2.7227799892425537
Validation loss: 2.24809375116902

Epoch: 294| Step: 0
Training loss: 2.3087806701660156
Validation loss: 2.2436506876381497

Epoch: 5| Step: 1
Training loss: 2.131270170211792
Validation loss: 2.2437390409490114

Epoch: 5| Step: 2
Training loss: 1.5351991653442383
Validation loss: 2.2523654507052515

Epoch: 5| Step: 3
Training loss: 3.316020965576172
Validation loss: 2.2385608047567387

Epoch: 5| Step: 4
Training loss: 2.509765148162842
Validation loss: 2.25585106367706

Epoch: 5| Step: 5
Training loss: 2.2196645736694336
Validation loss: 2.2695841302153883

Epoch: 5| Step: 6
Training loss: 2.679553508758545
Validation loss: 2.252796462787095

Epoch: 5| Step: 7
Training loss: 1.9928398132324219
Validation loss: 2.2728624395144883

Epoch: 5| Step: 8
Training loss: 2.3620200157165527
Validation loss: 2.2482864523446686

Epoch: 5| Step: 9
Training loss: 2.4998269081115723
Validation loss: 2.2613650983379734

Epoch: 5| Step: 10
Training loss: 2.740828037261963
Validation loss: 2.265121849634314

Epoch: 295| Step: 0
Training loss: 2.7263362407684326
Validation loss: 2.2612468734864266

Epoch: 5| Step: 1
Training loss: 2.182220935821533
Validation loss: 2.2469242221565655

Epoch: 5| Step: 2
Training loss: 2.0732173919677734
Validation loss: 2.2498922207022227

Epoch: 5| Step: 3
Training loss: 2.645547389984131
Validation loss: 2.2613856074630574

Epoch: 5| Step: 4
Training loss: 2.280949831008911
Validation loss: 2.2371091560650895

Epoch: 5| Step: 5
Training loss: 2.6434121131896973
Validation loss: 2.239528767524227

Epoch: 5| Step: 6
Training loss: 2.7047667503356934
Validation loss: 2.2261341182134484

Epoch: 5| Step: 7
Training loss: 1.9587701559066772
Validation loss: 2.2413374916199715

Epoch: 5| Step: 8
Training loss: 1.794812560081482
Validation loss: 2.2423396469444357

Epoch: 5| Step: 9
Training loss: 2.5578670501708984
Validation loss: 2.2224235893577657

Epoch: 5| Step: 10
Training loss: 2.6027421951293945
Validation loss: 2.2533872230078584

Epoch: 296| Step: 0
Training loss: 2.4044811725616455
Validation loss: 2.252364948231687

Epoch: 5| Step: 1
Training loss: 2.317378044128418
Validation loss: 2.255146693157893

Epoch: 5| Step: 2
Training loss: 2.3148090839385986
Validation loss: 2.266960656771096

Epoch: 5| Step: 3
Training loss: 2.147430419921875
Validation loss: 2.2983788597968315

Epoch: 5| Step: 4
Training loss: 3.002835512161255
Validation loss: 2.288054022737729

Epoch: 5| Step: 5
Training loss: 2.4609875679016113
Validation loss: 2.272301653380035

Epoch: 5| Step: 6
Training loss: 1.979736566543579
Validation loss: 2.2653902115360385

Epoch: 5| Step: 7
Training loss: 2.334881544113159
Validation loss: 2.2626891392533497

Epoch: 5| Step: 8
Training loss: 2.104210615158081
Validation loss: 2.2607555248404063

Epoch: 5| Step: 9
Training loss: 2.3823180198669434
Validation loss: 2.250359178871237

Epoch: 5| Step: 10
Training loss: 2.6988401412963867
Validation loss: 2.229263708155642

Epoch: 297| Step: 0
Training loss: 2.3526151180267334
Validation loss: 2.242990339955976

Epoch: 5| Step: 1
Training loss: 1.7977874279022217
Validation loss: 2.2247583661028134

Epoch: 5| Step: 2
Training loss: 2.2980847358703613
Validation loss: 2.2320122718811035

Epoch: 5| Step: 3
Training loss: 2.5950522422790527
Validation loss: 2.222668235019971

Epoch: 5| Step: 4
Training loss: 2.5036208629608154
Validation loss: 2.2359918676396853

Epoch: 5| Step: 5
Training loss: 2.742125988006592
Validation loss: 2.2415684858957925

Epoch: 5| Step: 6
Training loss: 2.1247870922088623
Validation loss: 2.2416992290045625

Epoch: 5| Step: 7
Training loss: 2.6361279487609863
Validation loss: 2.247209384877195

Epoch: 5| Step: 8
Training loss: 2.034384250640869
Validation loss: 2.253713494987898

Epoch: 5| Step: 9
Training loss: 2.054192066192627
Validation loss: 2.257463324454523

Epoch: 5| Step: 10
Training loss: 3.0007262229919434
Validation loss: 2.2786004825304915

Epoch: 298| Step: 0
Training loss: 2.6534037590026855
Validation loss: 2.272405537225867

Epoch: 5| Step: 1
Training loss: 1.8066251277923584
Validation loss: 2.2811660843510784

Epoch: 5| Step: 2
Training loss: 2.4068238735198975
Validation loss: 2.2683931294307915

Epoch: 5| Step: 3
Training loss: 2.624544620513916
Validation loss: 2.264025734316918

Epoch: 5| Step: 4
Training loss: 2.332305669784546
Validation loss: 2.2397193780509372

Epoch: 5| Step: 5
Training loss: 2.5137972831726074
Validation loss: 2.2390996153636644

Epoch: 5| Step: 6
Training loss: 2.0348219871520996
Validation loss: 2.235260037965672

Epoch: 5| Step: 7
Training loss: 2.6313369274139404
Validation loss: 2.2389083805904595

Epoch: 5| Step: 8
Training loss: 1.9906930923461914
Validation loss: 2.2304438903767574

Epoch: 5| Step: 9
Training loss: 2.698174238204956
Validation loss: 2.2313187455618255

Epoch: 5| Step: 10
Training loss: 2.3297247886657715
Validation loss: 2.2354807904971543

Epoch: 299| Step: 0
Training loss: 1.2563724517822266
Validation loss: 2.2576312685525544

Epoch: 5| Step: 1
Training loss: 2.9400837421417236
Validation loss: 2.2750163796127483

Epoch: 5| Step: 2
Training loss: 2.53849720954895
Validation loss: 2.268480790558682

Epoch: 5| Step: 3
Training loss: 2.7133421897888184
Validation loss: 2.259119100468133

Epoch: 5| Step: 4
Training loss: 2.7500927448272705
Validation loss: 2.2650170544142365

Epoch: 5| Step: 5
Training loss: 1.7688484191894531
Validation loss: 2.244868511794716

Epoch: 5| Step: 6
Training loss: 2.4397530555725098
Validation loss: 2.253511631360618

Epoch: 5| Step: 7
Training loss: 2.740039825439453
Validation loss: 2.251368053497807

Epoch: 5| Step: 8
Training loss: 2.371992826461792
Validation loss: 2.2537512522871777

Epoch: 5| Step: 9
Training loss: 2.1843695640563965
Validation loss: 2.250540316745799

Epoch: 5| Step: 10
Training loss: 2.1573636531829834
Validation loss: 2.2339373429616294

Epoch: 300| Step: 0
Training loss: 2.5584867000579834
Validation loss: 2.2421459177488923

Epoch: 5| Step: 1
Training loss: 2.481804370880127
Validation loss: 2.234767590799639

Epoch: 5| Step: 2
Training loss: 2.2548134326934814
Validation loss: 2.2396021530192387

Epoch: 5| Step: 3
Training loss: 1.6644798517227173
Validation loss: 2.2312576463145595

Epoch: 5| Step: 4
Training loss: 2.823092460632324
Validation loss: 2.2228622269886795

Epoch: 5| Step: 5
Training loss: 2.0405478477478027
Validation loss: 2.2323164555334274

Epoch: 5| Step: 6
Training loss: 2.626920461654663
Validation loss: 2.249553060018888

Epoch: 5| Step: 7
Training loss: 2.976191759109497
Validation loss: 2.2713963062532487

Epoch: 5| Step: 8
Training loss: 1.9322878122329712
Validation loss: 2.295807692312425

Epoch: 5| Step: 9
Training loss: 2.0470364093780518
Validation loss: 2.306437538516137

Epoch: 5| Step: 10
Training loss: 2.6072254180908203
Validation loss: 2.2856151288555515

Epoch: 301| Step: 0
Training loss: 2.113839626312256
Validation loss: 2.276363052347655

Epoch: 5| Step: 1
Training loss: 2.4232516288757324
Validation loss: 2.238672838416151

Epoch: 5| Step: 2
Training loss: 2.397834062576294
Validation loss: 2.2317231701266382

Epoch: 5| Step: 3
Training loss: 2.180412769317627
Validation loss: 2.209682995273221

Epoch: 5| Step: 4
Training loss: 2.788466691970825
Validation loss: 2.220320188870994

Epoch: 5| Step: 5
Training loss: 2.014319896697998
Validation loss: 2.217904370318177

Epoch: 5| Step: 6
Training loss: 2.611534595489502
Validation loss: 2.2306756460538475

Epoch: 5| Step: 7
Training loss: 2.6989853382110596
Validation loss: 2.2453153620484056

Epoch: 5| Step: 8
Training loss: 2.2183632850646973
Validation loss: 2.2373147062076035

Epoch: 5| Step: 9
Training loss: 2.8308162689208984
Validation loss: 2.245270072772939

Epoch: 5| Step: 10
Training loss: 1.651825189590454
Validation loss: 2.260993908810359

Epoch: 302| Step: 0
Training loss: 1.6725196838378906
Validation loss: 2.265943983549713

Epoch: 5| Step: 1
Training loss: 2.7210075855255127
Validation loss: 2.263478409859442

Epoch: 5| Step: 2
Training loss: 2.960583448410034
Validation loss: 2.2572217897702287

Epoch: 5| Step: 3
Training loss: 2.3517513275146484
Validation loss: 2.2675895844736407

Epoch: 5| Step: 4
Training loss: 2.5794131755828857
Validation loss: 2.2588989401376374

Epoch: 5| Step: 5
Training loss: 2.2846157550811768
Validation loss: 2.2444322724496164

Epoch: 5| Step: 6
Training loss: 2.9729812145233154
Validation loss: 2.245431330896193

Epoch: 5| Step: 7
Training loss: 1.9898035526275635
Validation loss: 2.233843009958985

Epoch: 5| Step: 8
Training loss: 2.3682684898376465
Validation loss: 2.220927876810874

Epoch: 5| Step: 9
Training loss: 2.0839245319366455
Validation loss: 2.218638088113518

Epoch: 5| Step: 10
Training loss: 1.9221503734588623
Validation loss: 2.214421454296317

Epoch: 303| Step: 0
Training loss: 2.0211353302001953
Validation loss: 2.2278230574823197

Epoch: 5| Step: 1
Training loss: 2.8793184757232666
Validation loss: 2.2221620775038198

Epoch: 5| Step: 2
Training loss: 2.0641262531280518
Validation loss: 2.238029791462806

Epoch: 5| Step: 3
Training loss: 2.8559558391571045
Validation loss: 2.2418352455221195

Epoch: 5| Step: 4
Training loss: 2.3022103309631348
Validation loss: 2.24723970249135

Epoch: 5| Step: 5
Training loss: 2.211230754852295
Validation loss: 2.23255673275199

Epoch: 5| Step: 6
Training loss: 2.8074076175689697
Validation loss: 2.2348627557036695

Epoch: 5| Step: 7
Training loss: 2.789909839630127
Validation loss: 2.22397982048732

Epoch: 5| Step: 8
Training loss: 2.088191509246826
Validation loss: 2.241083521996775

Epoch: 5| Step: 9
Training loss: 2.4226386547088623
Validation loss: 2.262012299670968

Epoch: 5| Step: 10
Training loss: 1.5485326051712036
Validation loss: 2.2578587967862367

Epoch: 304| Step: 0
Training loss: 2.450374126434326
Validation loss: 2.2446700065366683

Epoch: 5| Step: 1
Training loss: 2.2717792987823486
Validation loss: 2.232870888966386

Epoch: 5| Step: 2
Training loss: 2.076801300048828
Validation loss: 2.2341584133845505

Epoch: 5| Step: 3
Training loss: 3.051119804382324
Validation loss: 2.2184018806744645

Epoch: 5| Step: 4
Training loss: 2.2334916591644287
Validation loss: 2.211099173433037

Epoch: 5| Step: 5
Training loss: 2.066387891769409
Validation loss: 2.2141128560548187

Epoch: 5| Step: 6
Training loss: 2.248539686203003
Validation loss: 2.2272008542091615

Epoch: 5| Step: 7
Training loss: 2.304412841796875
Validation loss: 2.240339538102509

Epoch: 5| Step: 8
Training loss: 2.2953314781188965
Validation loss: 2.2383291336797897

Epoch: 5| Step: 9
Training loss: 2.44665789604187
Validation loss: 2.248882427010485

Epoch: 5| Step: 10
Training loss: 2.4469146728515625
Validation loss: 2.265462726675054

Epoch: 305| Step: 0
Training loss: 1.9909284114837646
Validation loss: 2.278820283951298

Epoch: 5| Step: 1
Training loss: 2.0933165550231934
Validation loss: 2.282812867113339

Epoch: 5| Step: 2
Training loss: 2.7516424655914307
Validation loss: 2.29422027321272

Epoch: 5| Step: 3
Training loss: 1.9878003597259521
Validation loss: 2.2680985517399286

Epoch: 5| Step: 4
Training loss: 2.383056640625
Validation loss: 2.2459404058353876

Epoch: 5| Step: 5
Training loss: 2.3052210807800293
Validation loss: 2.2260074692387737

Epoch: 5| Step: 6
Training loss: 2.903663158416748
Validation loss: 2.192788322766622

Epoch: 5| Step: 7
Training loss: 2.497666835784912
Validation loss: 2.2005600954896662

Epoch: 5| Step: 8
Training loss: 2.1433498859405518
Validation loss: 2.2020956213756273

Epoch: 5| Step: 9
Training loss: 2.82532000541687
Validation loss: 2.2006406886603243

Epoch: 5| Step: 10
Training loss: 2.1731059551239014
Validation loss: 2.2071051623231623

Epoch: 306| Step: 0
Training loss: 2.6592440605163574
Validation loss: 2.2002971313332997

Epoch: 5| Step: 1
Training loss: 2.2098560333251953
Validation loss: 2.2052081528530327

Epoch: 5| Step: 2
Training loss: 2.085052013397217
Validation loss: 2.218737468924574

Epoch: 5| Step: 3
Training loss: 2.2282209396362305
Validation loss: 2.209308816540626

Epoch: 5| Step: 4
Training loss: 2.885342836380005
Validation loss: 2.206112620651081

Epoch: 5| Step: 5
Training loss: 2.0248782634735107
Validation loss: 2.230273856911608

Epoch: 5| Step: 6
Training loss: 2.006568670272827
Validation loss: 2.23953091841872

Epoch: 5| Step: 7
Training loss: 2.6985747814178467
Validation loss: 2.248837153116862

Epoch: 5| Step: 8
Training loss: 2.7922213077545166
Validation loss: 2.267933601974159

Epoch: 5| Step: 9
Training loss: 2.178361415863037
Validation loss: 2.2755067989390385

Epoch: 5| Step: 10
Training loss: 2.102449655532837
Validation loss: 2.264514648786155

Epoch: 307| Step: 0
Training loss: 1.9204785823822021
Validation loss: 2.2677410212896203

Epoch: 5| Step: 1
Training loss: 2.1946959495544434
Validation loss: 2.265863576243001

Epoch: 5| Step: 2
Training loss: 2.734009027481079
Validation loss: 2.267407348079066

Epoch: 5| Step: 3
Training loss: 1.7539669275283813
Validation loss: 2.256864504147601

Epoch: 5| Step: 4
Training loss: 2.293602466583252
Validation loss: 2.2490822345979753

Epoch: 5| Step: 5
Training loss: 2.5612332820892334
Validation loss: 2.2672433494239725

Epoch: 5| Step: 6
Training loss: 2.3299484252929688
Validation loss: 2.2551961393766504

Epoch: 5| Step: 7
Training loss: 1.9550788402557373
Validation loss: 2.231816735318912

Epoch: 5| Step: 8
Training loss: 2.292799472808838
Validation loss: 2.242909698076146

Epoch: 5| Step: 9
Training loss: 2.746070384979248
Validation loss: 2.2356617578896145

Epoch: 5| Step: 10
Training loss: 3.063638210296631
Validation loss: 2.233424787880272

Epoch: 308| Step: 0
Training loss: 2.343416690826416
Validation loss: 2.2173078239604993

Epoch: 5| Step: 1
Training loss: 2.2413198947906494
Validation loss: 2.214358796355545

Epoch: 5| Step: 2
Training loss: 2.7689967155456543
Validation loss: 2.2185259301175355

Epoch: 5| Step: 3
Training loss: 2.436439037322998
Validation loss: 2.2090373398155294

Epoch: 5| Step: 4
Training loss: 2.7851197719573975
Validation loss: 2.2076642590184368

Epoch: 5| Step: 5
Training loss: 2.171609401702881
Validation loss: 2.22407595316569

Epoch: 5| Step: 6
Training loss: 2.2429237365722656
Validation loss: 2.223211749907463

Epoch: 5| Step: 7
Training loss: 2.311159610748291
Validation loss: 2.2216052239941013

Epoch: 5| Step: 8
Training loss: 2.0585310459136963
Validation loss: 2.2399457898191226

Epoch: 5| Step: 9
Training loss: 2.220637559890747
Validation loss: 2.2417707417600896

Epoch: 5| Step: 10
Training loss: 2.1768720149993896
Validation loss: 2.265604652384276

Epoch: 309| Step: 0
Training loss: 1.779750108718872
Validation loss: 2.236409551353865

Epoch: 5| Step: 1
Training loss: 2.156291961669922
Validation loss: 2.248995242580291

Epoch: 5| Step: 2
Training loss: 2.1108968257904053
Validation loss: 2.230425009163477

Epoch: 5| Step: 3
Training loss: 2.1700541973114014
Validation loss: 2.2166958752498833

Epoch: 5| Step: 4
Training loss: 2.362051010131836
Validation loss: 2.209991643505712

Epoch: 5| Step: 5
Training loss: 2.8598482608795166
Validation loss: 2.20651053613232

Epoch: 5| Step: 6
Training loss: 2.9017045497894287
Validation loss: 2.204802697704684

Epoch: 5| Step: 7
Training loss: 1.8590179681777954
Validation loss: 2.2002278681724303

Epoch: 5| Step: 8
Training loss: 2.6431450843811035
Validation loss: 2.2234564570970434

Epoch: 5| Step: 9
Training loss: 2.6536402702331543
Validation loss: 2.200272516537738

Epoch: 5| Step: 10
Training loss: 2.2074923515319824
Validation loss: 2.2038151512863817

Epoch: 310| Step: 0
Training loss: 2.3548583984375
Validation loss: 2.2141155888957362

Epoch: 5| Step: 1
Training loss: 3.209195375442505
Validation loss: 2.235958960748488

Epoch: 5| Step: 2
Training loss: 2.394200086593628
Validation loss: 2.225517906168456

Epoch: 5| Step: 3
Training loss: 2.0700111389160156
Validation loss: 2.2537624938513643

Epoch: 5| Step: 4
Training loss: 2.137251377105713
Validation loss: 2.2467868610094954

Epoch: 5| Step: 5
Training loss: 2.4825618267059326
Validation loss: 2.25912174999073

Epoch: 5| Step: 6
Training loss: 1.582393765449524
Validation loss: 2.2602960883930163

Epoch: 5| Step: 7
Training loss: 2.4966399669647217
Validation loss: 2.250662680595152

Epoch: 5| Step: 8
Training loss: 2.3689117431640625
Validation loss: 2.255721515224826

Epoch: 5| Step: 9
Training loss: 2.436652660369873
Validation loss: 2.230499662378783

Epoch: 5| Step: 10
Training loss: 2.1295063495635986
Validation loss: 2.2574587560469106

Epoch: 311| Step: 0
Training loss: 2.2196109294891357
Validation loss: 2.241648684265793

Epoch: 5| Step: 1
Training loss: 1.6652657985687256
Validation loss: 2.2435185165815454

Epoch: 5| Step: 2
Training loss: 2.6635584831237793
Validation loss: 2.2574322326208955

Epoch: 5| Step: 3
Training loss: 2.0131733417510986
Validation loss: 2.2508773752438125

Epoch: 5| Step: 4
Training loss: 2.484553813934326
Validation loss: 2.2290294349834485

Epoch: 5| Step: 5
Training loss: 2.089313268661499
Validation loss: 2.251317698468444

Epoch: 5| Step: 6
Training loss: 1.8487765789031982
Validation loss: 2.26030299996817

Epoch: 5| Step: 7
Training loss: 2.6471519470214844
Validation loss: 2.2530944334563388

Epoch: 5| Step: 8
Training loss: 2.16863751411438
Validation loss: 2.248030972737138

Epoch: 5| Step: 9
Training loss: 3.2200565338134766
Validation loss: 2.2440709913930585

Epoch: 5| Step: 10
Training loss: 2.8023712635040283
Validation loss: 2.2457912839869016

Epoch: 312| Step: 0
Training loss: 2.2443528175354004
Validation loss: 2.236135798115884

Epoch: 5| Step: 1
Training loss: 2.2447781562805176
Validation loss: 2.2407140706175115

Epoch: 5| Step: 2
Training loss: 2.565189838409424
Validation loss: 2.2277639066019366

Epoch: 5| Step: 3
Training loss: 2.1906604766845703
Validation loss: 2.236473165532594

Epoch: 5| Step: 4
Training loss: 2.2118403911590576
Validation loss: 2.241949858204011

Epoch: 5| Step: 5
Training loss: 2.5250048637390137
Validation loss: 2.204613717653418

Epoch: 5| Step: 6
Training loss: 2.0308122634887695
Validation loss: 2.211397695285018

Epoch: 5| Step: 7
Training loss: 2.31613826751709
Validation loss: 2.1993413061224003

Epoch: 5| Step: 8
Training loss: 2.448277711868286
Validation loss: 2.2060333195553032

Epoch: 5| Step: 9
Training loss: 2.6607773303985596
Validation loss: 2.2164239780877226

Epoch: 5| Step: 10
Training loss: 2.4592695236206055
Validation loss: 2.232914293965986

Epoch: 313| Step: 0
Training loss: 2.856903553009033
Validation loss: 2.251286345143472

Epoch: 5| Step: 1
Training loss: 2.345136880874634
Validation loss: 2.244852073730961

Epoch: 5| Step: 2
Training loss: 1.9549659490585327
Validation loss: 2.2363764419350574

Epoch: 5| Step: 3
Training loss: 2.256077527999878
Validation loss: 2.2248812721621607

Epoch: 5| Step: 4
Training loss: 1.8637332916259766
Validation loss: 2.2139382849457445

Epoch: 5| Step: 5
Training loss: 2.8408615589141846
Validation loss: 2.2218557070660334

Epoch: 5| Step: 6
Training loss: 2.0263774394989014
Validation loss: 2.2180988993695987

Epoch: 5| Step: 7
Training loss: 2.583583354949951
Validation loss: 2.1980158282864477

Epoch: 5| Step: 8
Training loss: 2.7805228233337402
Validation loss: 2.198741207840622

Epoch: 5| Step: 9
Training loss: 2.4748334884643555
Validation loss: 2.189321361562257

Epoch: 5| Step: 10
Training loss: 1.8664426803588867
Validation loss: 2.1942448462209394

Epoch: 314| Step: 0
Training loss: 2.3091864585876465
Validation loss: 2.189654357971684

Epoch: 5| Step: 1
Training loss: 2.4385342597961426
Validation loss: 2.1894193849255963

Epoch: 5| Step: 2
Training loss: 2.075817584991455
Validation loss: 2.2230354483409593

Epoch: 5| Step: 3
Training loss: 2.528576612472534
Validation loss: 2.228575009171681

Epoch: 5| Step: 4
Training loss: 1.7949025630950928
Validation loss: 2.2648399440191125

Epoch: 5| Step: 5
Training loss: 2.9006359577178955
Validation loss: 2.267941205732284

Epoch: 5| Step: 6
Training loss: 2.389301061630249
Validation loss: 2.3190622406621135

Epoch: 5| Step: 7
Training loss: 2.396466016769409
Validation loss: 2.2893627612821517

Epoch: 5| Step: 8
Training loss: 2.367644786834717
Validation loss: 2.276296064417849

Epoch: 5| Step: 9
Training loss: 2.447187900543213
Validation loss: 2.258381209065837

Epoch: 5| Step: 10
Training loss: 2.3428337574005127
Validation loss: 2.2435618703083327

Epoch: 315| Step: 0
Training loss: 2.539353609085083
Validation loss: 2.248819056377616

Epoch: 5| Step: 1
Training loss: 1.7707774639129639
Validation loss: 2.2385465380966023

Epoch: 5| Step: 2
Training loss: 2.801424503326416
Validation loss: 2.226609876078944

Epoch: 5| Step: 3
Training loss: 1.8165340423583984
Validation loss: 2.2307385859950895

Epoch: 5| Step: 4
Training loss: 2.6081466674804688
Validation loss: 2.2113492847770773

Epoch: 5| Step: 5
Training loss: 2.82681941986084
Validation loss: 2.2066978126443844

Epoch: 5| Step: 6
Training loss: 2.6389360427856445
Validation loss: 2.196275136804068

Epoch: 5| Step: 7
Training loss: 2.3270251750946045
Validation loss: 2.206546389928428

Epoch: 5| Step: 8
Training loss: 2.2871909141540527
Validation loss: 2.209903273531186

Epoch: 5| Step: 9
Training loss: 2.4158401489257812
Validation loss: 2.2320396336176063

Epoch: 5| Step: 10
Training loss: 1.810706615447998
Validation loss: 2.2565248294543196

Epoch: 316| Step: 0
Training loss: 2.7777211666107178
Validation loss: 2.265021367739606

Epoch: 5| Step: 1
Training loss: 2.1429760456085205
Validation loss: 2.2534092292990735

Epoch: 5| Step: 2
Training loss: 2.179532527923584
Validation loss: 2.244301270413142

Epoch: 5| Step: 3
Training loss: 2.654958724975586
Validation loss: 2.228909803975013

Epoch: 5| Step: 4
Training loss: 2.050780773162842
Validation loss: 2.2197403715502833

Epoch: 5| Step: 5
Training loss: 1.7183595895767212
Validation loss: 2.1996373053519958

Epoch: 5| Step: 6
Training loss: 2.4070916175842285
Validation loss: 2.220545381628057

Epoch: 5| Step: 7
Training loss: 2.697833299636841
Validation loss: 2.2246046117556992

Epoch: 5| Step: 8
Training loss: 1.7618567943572998
Validation loss: 2.200443337040563

Epoch: 5| Step: 9
Training loss: 2.5864429473876953
Validation loss: 2.216292929905717

Epoch: 5| Step: 10
Training loss: 2.956245183944702
Validation loss: 2.2285375364365114

Epoch: 317| Step: 0
Training loss: 1.9242966175079346
Validation loss: 2.2217642658500263

Epoch: 5| Step: 1
Training loss: 2.5373787879943848
Validation loss: 2.2315644243712067

Epoch: 5| Step: 2
Training loss: 1.9316002130508423
Validation loss: 2.2108439450622885

Epoch: 5| Step: 3
Training loss: 2.7913289070129395
Validation loss: 2.2106827894846597

Epoch: 5| Step: 4
Training loss: 2.5284652709960938
Validation loss: 2.21098308409414

Epoch: 5| Step: 5
Training loss: 2.472292423248291
Validation loss: 2.2160138032769643

Epoch: 5| Step: 6
Training loss: 2.6209092140197754
Validation loss: 2.233703064662154

Epoch: 5| Step: 7
Training loss: 2.3168866634368896
Validation loss: 2.245523332267679

Epoch: 5| Step: 8
Training loss: 2.2601895332336426
Validation loss: 2.2296887161911174

Epoch: 5| Step: 9
Training loss: 2.1388297080993652
Validation loss: 2.2490480099954913

Epoch: 5| Step: 10
Training loss: 1.9867208003997803
Validation loss: 2.232035708683793

Epoch: 318| Step: 0
Training loss: 2.998248815536499
Validation loss: 2.225234511078045

Epoch: 5| Step: 1
Training loss: 2.102334499359131
Validation loss: 2.2061610516681465

Epoch: 5| Step: 2
Training loss: 1.9662154912948608
Validation loss: 2.215722922355898

Epoch: 5| Step: 3
Training loss: 2.3908581733703613
Validation loss: 2.214077975160332

Epoch: 5| Step: 4
Training loss: 2.8884453773498535
Validation loss: 2.2400127021215295

Epoch: 5| Step: 5
Training loss: 2.4766244888305664
Validation loss: 2.2262994935435634

Epoch: 5| Step: 6
Training loss: 2.0145440101623535
Validation loss: 2.218020123820151

Epoch: 5| Step: 7
Training loss: 2.126857280731201
Validation loss: 2.2227786971676733

Epoch: 5| Step: 8
Training loss: 2.270900249481201
Validation loss: 2.2277702311033845

Epoch: 5| Step: 9
Training loss: 1.731930136680603
Validation loss: 2.2388374984905286

Epoch: 5| Step: 10
Training loss: 2.6417276859283447
Validation loss: 2.2111492285164456

Epoch: 319| Step: 0
Training loss: 2.166365146636963
Validation loss: 2.208889192150485

Epoch: 5| Step: 1
Training loss: 2.0611021518707275
Validation loss: 2.2209839410679315

Epoch: 5| Step: 2
Training loss: 2.2086596488952637
Validation loss: 2.22575072832005

Epoch: 5| Step: 3
Training loss: 1.9234501123428345
Validation loss: 2.222076630079618

Epoch: 5| Step: 4
Training loss: 2.115022659301758
Validation loss: 2.2372066667003017

Epoch: 5| Step: 5
Training loss: 2.3969311714172363
Validation loss: 2.2196882001815306

Epoch: 5| Step: 6
Training loss: 2.8774847984313965
Validation loss: 2.2329380255873486

Epoch: 5| Step: 7
Training loss: 2.136225700378418
Validation loss: 2.2133631872874435

Epoch: 5| Step: 8
Training loss: 2.28204083442688
Validation loss: 2.2174219854416384

Epoch: 5| Step: 9
Training loss: 3.169970989227295
Validation loss: 2.2435758677862023

Epoch: 5| Step: 10
Training loss: 2.2860748767852783
Validation loss: 2.2168754518672986

Epoch: 320| Step: 0
Training loss: 2.566662549972534
Validation loss: 2.1958924621664067

Epoch: 5| Step: 1
Training loss: 1.8768342733383179
Validation loss: 2.1907176304888982

Epoch: 5| Step: 2
Training loss: 2.5190625190734863
Validation loss: 2.1713571638189335

Epoch: 5| Step: 3
Training loss: 2.371368885040283
Validation loss: 2.1741451473646265

Epoch: 5| Step: 4
Training loss: 2.0912370681762695
Validation loss: 2.1790368454430693

Epoch: 5| Step: 5
Training loss: 2.3504538536071777
Validation loss: 2.191391912839746

Epoch: 5| Step: 6
Training loss: 2.417398452758789
Validation loss: 2.1913936215062297

Epoch: 5| Step: 7
Training loss: 2.50001859664917
Validation loss: 2.1994817744019213

Epoch: 5| Step: 8
Training loss: 2.2398951053619385
Validation loss: 2.2093429488520466

Epoch: 5| Step: 9
Training loss: 2.087860584259033
Validation loss: 2.208244351930516

Epoch: 5| Step: 10
Training loss: 2.574899196624756
Validation loss: 2.2088655297474196

Epoch: 321| Step: 0
Training loss: 3.1762046813964844
Validation loss: 2.222787877564789

Epoch: 5| Step: 1
Training loss: 2.5423529148101807
Validation loss: 2.2333787859127088

Epoch: 5| Step: 2
Training loss: 1.9795334339141846
Validation loss: 2.227028536540206

Epoch: 5| Step: 3
Training loss: 2.256683349609375
Validation loss: 2.2241555439528597

Epoch: 5| Step: 4
Training loss: 2.219325542449951
Validation loss: 2.215260192912112

Epoch: 5| Step: 5
Training loss: 2.5555574893951416
Validation loss: 2.2224118171199674

Epoch: 5| Step: 6
Training loss: 2.024620532989502
Validation loss: 2.2082948889783633

Epoch: 5| Step: 7
Training loss: 1.7416433095932007
Validation loss: 2.204781529723957

Epoch: 5| Step: 8
Training loss: 2.2982916831970215
Validation loss: 2.205289440770303

Epoch: 5| Step: 9
Training loss: 2.437509536743164
Validation loss: 2.209031146059754

Epoch: 5| Step: 10
Training loss: 2.1465206146240234
Validation loss: 2.2114760901338313

Epoch: 322| Step: 0
Training loss: 2.040027618408203
Validation loss: 2.213331796789682

Epoch: 5| Step: 1
Training loss: 2.1527793407440186
Validation loss: 2.233736265090204

Epoch: 5| Step: 2
Training loss: 1.9323335886001587
Validation loss: 2.2430661160458802

Epoch: 5| Step: 3
Training loss: 2.6769700050354004
Validation loss: 2.254014156197989

Epoch: 5| Step: 4
Training loss: 2.4856832027435303
Validation loss: 2.262391928703554

Epoch: 5| Step: 5
Training loss: 2.5295615196228027
Validation loss: 2.2673156876717844

Epoch: 5| Step: 6
Training loss: 2.071795701980591
Validation loss: 2.2542203639143255

Epoch: 5| Step: 7
Training loss: 2.175062894821167
Validation loss: 2.2363814128342496

Epoch: 5| Step: 8
Training loss: 2.6850967407226562
Validation loss: 2.218387570432437

Epoch: 5| Step: 9
Training loss: 2.6632938385009766
Validation loss: 2.2109950383504233

Epoch: 5| Step: 10
Training loss: 2.0908327102661133
Validation loss: 2.1941718542447655

Epoch: 323| Step: 0
Training loss: 2.3912456035614014
Validation loss: 2.1967652446480206

Epoch: 5| Step: 1
Training loss: 2.3739688396453857
Validation loss: 2.1889447448074177

Epoch: 5| Step: 2
Training loss: 2.185981273651123
Validation loss: 2.1622754591767506

Epoch: 5| Step: 3
Training loss: 2.854694366455078
Validation loss: 2.1847562610462146

Epoch: 5| Step: 4
Training loss: 1.9418271780014038
Validation loss: 2.174385655310846

Epoch: 5| Step: 5
Training loss: 2.373828172683716
Validation loss: 2.191831511835898

Epoch: 5| Step: 6
Training loss: 1.8499431610107422
Validation loss: 2.175789325468002

Epoch: 5| Step: 7
Training loss: 3.430880069732666
Validation loss: 2.202096692977413

Epoch: 5| Step: 8
Training loss: 2.179046869277954
Validation loss: 2.199973631930608

Epoch: 5| Step: 9
Training loss: 1.8941535949707031
Validation loss: 2.2514377576048656

Epoch: 5| Step: 10
Training loss: 2.1549179553985596
Validation loss: 2.247290898394841

Epoch: 324| Step: 0
Training loss: 2.4735355377197266
Validation loss: 2.269751556458012

Epoch: 5| Step: 1
Training loss: 2.601292371749878
Validation loss: 2.2774706630296606

Epoch: 5| Step: 2
Training loss: 2.194608688354492
Validation loss: 2.2815798174950386

Epoch: 5| Step: 3
Training loss: 2.416128396987915
Validation loss: 2.248103130248285

Epoch: 5| Step: 4
Training loss: 1.7018578052520752
Validation loss: 2.2412520813685592

Epoch: 5| Step: 5
Training loss: 1.845435380935669
Validation loss: 2.218981332676385

Epoch: 5| Step: 6
Training loss: 2.2530837059020996
Validation loss: 2.209526418357767

Epoch: 5| Step: 7
Training loss: 3.1029906272888184
Validation loss: 2.2060140102140364

Epoch: 5| Step: 8
Training loss: 2.6049904823303223
Validation loss: 2.2064066035773164

Epoch: 5| Step: 9
Training loss: 1.9216750860214233
Validation loss: 2.195489050239645

Epoch: 5| Step: 10
Training loss: 2.5596115589141846
Validation loss: 2.1937953579810356

Epoch: 325| Step: 0
Training loss: 2.053487539291382
Validation loss: 2.186570329050864

Epoch: 5| Step: 1
Training loss: 2.232999801635742
Validation loss: 2.2108231436821724

Epoch: 5| Step: 2
Training loss: 2.1216235160827637
Validation loss: 2.2049662477226666

Epoch: 5| Step: 3
Training loss: 2.073211431503296
Validation loss: 2.2048227017925632

Epoch: 5| Step: 4
Training loss: 2.1049060821533203
Validation loss: 2.204681732321298

Epoch: 5| Step: 5
Training loss: 2.3751964569091797
Validation loss: 2.218674034200689

Epoch: 5| Step: 6
Training loss: 1.9588359594345093
Validation loss: 2.232100035554619

Epoch: 5| Step: 7
Training loss: 2.220327377319336
Validation loss: 2.222705920537313

Epoch: 5| Step: 8
Training loss: 3.032263994216919
Validation loss: 2.2263844884851927

Epoch: 5| Step: 9
Training loss: 2.2928109169006348
Validation loss: 2.2168300728644095

Epoch: 5| Step: 10
Training loss: 3.074337959289551
Validation loss: 2.2218909045701385

Epoch: 326| Step: 0
Training loss: 1.8902404308319092
Validation loss: 2.1976617946419665

Epoch: 5| Step: 1
Training loss: 2.381523609161377
Validation loss: 2.214875166134168

Epoch: 5| Step: 2
Training loss: 2.5580897331237793
Validation loss: 2.2148715488372313

Epoch: 5| Step: 3
Training loss: 2.0923354625701904
Validation loss: 2.2052370245738695

Epoch: 5| Step: 4
Training loss: 2.2095813751220703
Validation loss: 2.2020216859796995

Epoch: 5| Step: 5
Training loss: 2.7139573097229004
Validation loss: 2.1842414820066063

Epoch: 5| Step: 6
Training loss: 2.5129752159118652
Validation loss: 2.196748933484477

Epoch: 5| Step: 7
Training loss: 2.3531556129455566
Validation loss: 2.1881334448373444

Epoch: 5| Step: 8
Training loss: 2.569350481033325
Validation loss: 2.192400775929933

Epoch: 5| Step: 9
Training loss: 1.8466968536376953
Validation loss: 2.193562897302771

Epoch: 5| Step: 10
Training loss: 2.435579299926758
Validation loss: 2.2033341110393567

Epoch: 327| Step: 0
Training loss: 2.113555908203125
Validation loss: 2.223998320999966

Epoch: 5| Step: 1
Training loss: 2.541832447052002
Validation loss: 2.2349308049806984

Epoch: 5| Step: 2
Training loss: 2.666877508163452
Validation loss: 2.2240181840876097

Epoch: 5| Step: 3
Training loss: 2.414848804473877
Validation loss: 2.2373552886388635

Epoch: 5| Step: 4
Training loss: 1.8044192790985107
Validation loss: 2.2381996749549784

Epoch: 5| Step: 5
Training loss: 2.0692479610443115
Validation loss: 2.2291151195444088

Epoch: 5| Step: 6
Training loss: 2.0444436073303223
Validation loss: 2.243789619015109

Epoch: 5| Step: 7
Training loss: 2.713923215866089
Validation loss: 2.2323789135102303

Epoch: 5| Step: 8
Training loss: 2.215036630630493
Validation loss: 2.208474487386724

Epoch: 5| Step: 9
Training loss: 2.6073827743530273
Validation loss: 2.2051177922115532

Epoch: 5| Step: 10
Training loss: 2.336846113204956
Validation loss: 2.1866566032491703

Epoch: 328| Step: 0
Training loss: 2.4764246940612793
Validation loss: 2.1831738769367175

Epoch: 5| Step: 1
Training loss: 2.46618914604187
Validation loss: 2.1641478102694274

Epoch: 5| Step: 2
Training loss: 2.326508045196533
Validation loss: 2.16601134884742

Epoch: 5| Step: 3
Training loss: 1.6972267627716064
Validation loss: 2.1526944432207333

Epoch: 5| Step: 4
Training loss: 2.575960159301758
Validation loss: 2.1601612824265675

Epoch: 5| Step: 5
Training loss: 2.4757583141326904
Validation loss: 2.1761157358846357

Epoch: 5| Step: 6
Training loss: 3.062877893447876
Validation loss: 2.203285458267376

Epoch: 5| Step: 7
Training loss: 2.225076198577881
Validation loss: 2.2231733914344542

Epoch: 5| Step: 8
Training loss: 2.566272735595703
Validation loss: 2.2295830698423487

Epoch: 5| Step: 9
Training loss: 1.6754286289215088
Validation loss: 2.236773666515145

Epoch: 5| Step: 10
Training loss: 1.8838554620742798
Validation loss: 2.252273410879156

Epoch: 329| Step: 0
Training loss: 2.5408999919891357
Validation loss: 2.2509693432879705

Epoch: 5| Step: 1
Training loss: 1.8373134136199951
Validation loss: 2.2223538903779883

Epoch: 5| Step: 2
Training loss: 2.897888660430908
Validation loss: 2.2185147962262555

Epoch: 5| Step: 3
Training loss: 2.117367744445801
Validation loss: 2.2103080006055933

Epoch: 5| Step: 4
Training loss: 2.106417655944824
Validation loss: 2.203353676744687

Epoch: 5| Step: 5
Training loss: 1.9849202632904053
Validation loss: 2.194015722120962

Epoch: 5| Step: 6
Training loss: 2.6380512714385986
Validation loss: 2.212316325915757

Epoch: 5| Step: 7
Training loss: 2.4243409633636475
Validation loss: 2.190722019441666

Epoch: 5| Step: 8
Training loss: 2.4110352993011475
Validation loss: 2.195764054534256

Epoch: 5| Step: 9
Training loss: 2.172578811645508
Validation loss: 2.183675931346032

Epoch: 5| Step: 10
Training loss: 2.226783514022827
Validation loss: 2.195740306249229

Epoch: 330| Step: 0
Training loss: 2.7959983348846436
Validation loss: 2.198196789269806

Epoch: 5| Step: 1
Training loss: 2.3723068237304688
Validation loss: 2.1823239018840175

Epoch: 5| Step: 2
Training loss: 2.262558937072754
Validation loss: 2.1881763268542547

Epoch: 5| Step: 3
Training loss: 2.3440747261047363
Validation loss: 2.2148690172421035

Epoch: 5| Step: 4
Training loss: 2.6834006309509277
Validation loss: 2.2138192858747257

Epoch: 5| Step: 5
Training loss: 2.5420944690704346
Validation loss: 2.1872329147913123

Epoch: 5| Step: 6
Training loss: 2.1177303791046143
Validation loss: 2.201780152577226

Epoch: 5| Step: 7
Training loss: 2.151808500289917
Validation loss: 2.2002317879789617

Epoch: 5| Step: 8
Training loss: 2.1095685958862305
Validation loss: 2.1978522423774964

Epoch: 5| Step: 9
Training loss: 1.674928903579712
Validation loss: 2.205482817465259

Epoch: 5| Step: 10
Training loss: 2.2886245250701904
Validation loss: 2.2113742700187107

Epoch: 331| Step: 0
Training loss: 1.9390451908111572
Validation loss: 2.21480925877889

Epoch: 5| Step: 1
Training loss: 2.377091646194458
Validation loss: 2.2303582186340005

Epoch: 5| Step: 2
Training loss: 2.096557140350342
Validation loss: 2.2094093727809128

Epoch: 5| Step: 3
Training loss: 1.963883638381958
Validation loss: 2.195911874053299

Epoch: 5| Step: 4
Training loss: 2.664451837539673
Validation loss: 2.208873753906578

Epoch: 5| Step: 5
Training loss: 2.28760027885437
Validation loss: 2.1952164711490756

Epoch: 5| Step: 6
Training loss: 2.685685873031616
Validation loss: 2.2021053286008936

Epoch: 5| Step: 7
Training loss: 1.7116105556488037
Validation loss: 2.1923517475845995

Epoch: 5| Step: 8
Training loss: 2.4033236503601074
Validation loss: 2.1870846004896265

Epoch: 5| Step: 9
Training loss: 2.374439239501953
Validation loss: 2.193180404683595

Epoch: 5| Step: 10
Training loss: 2.925959825515747
Validation loss: 2.208151037975024

Epoch: 332| Step: 0
Training loss: 2.3094475269317627
Validation loss: 2.2102997354281846

Epoch: 5| Step: 1
Training loss: 2.385474681854248
Validation loss: 2.2164758636105444

Epoch: 5| Step: 2
Training loss: 2.5497138500213623
Validation loss: 2.203625971271146

Epoch: 5| Step: 3
Training loss: 2.482525587081909
Validation loss: 2.2044185874282674

Epoch: 5| Step: 4
Training loss: 1.9552319049835205
Validation loss: 2.198001787226687

Epoch: 5| Step: 5
Training loss: 1.8521430492401123
Validation loss: 2.2069228080011185

Epoch: 5| Step: 6
Training loss: 2.6332085132598877
Validation loss: 2.2039739649782897

Epoch: 5| Step: 7
Training loss: 2.256776809692383
Validation loss: 2.202158015261414

Epoch: 5| Step: 8
Training loss: 2.4345157146453857
Validation loss: 2.216392465817031

Epoch: 5| Step: 9
Training loss: 1.8962020874023438
Validation loss: 2.2177897601999264

Epoch: 5| Step: 10
Training loss: 2.5999701023101807
Validation loss: 2.2288697483719035

Epoch: 333| Step: 0
Training loss: 2.5671615600585938
Validation loss: 2.2264808839367283

Epoch: 5| Step: 1
Training loss: 2.2370200157165527
Validation loss: 2.253585528301936

Epoch: 5| Step: 2
Training loss: 2.089005708694458
Validation loss: 2.2295687032002274

Epoch: 5| Step: 3
Training loss: 2.4575822353363037
Validation loss: 2.215221558847735

Epoch: 5| Step: 4
Training loss: 2.1580843925476074
Validation loss: 2.2107884678789365

Epoch: 5| Step: 5
Training loss: 3.122680902481079
Validation loss: 2.1901823410423855

Epoch: 5| Step: 6
Training loss: 1.4516346454620361
Validation loss: 2.190930502389067

Epoch: 5| Step: 7
Training loss: 2.349858045578003
Validation loss: 2.176733070804227

Epoch: 5| Step: 8
Training loss: 2.2497141361236572
Validation loss: 2.169915485125716

Epoch: 5| Step: 9
Training loss: 2.306440830230713
Validation loss: 2.1688635887638217

Epoch: 5| Step: 10
Training loss: 2.3185300827026367
Validation loss: 2.166726250802317

Epoch: 334| Step: 0
Training loss: 2.6171483993530273
Validation loss: 2.166748332720931

Epoch: 5| Step: 1
Training loss: 2.4889278411865234
Validation loss: 2.1803405836064327

Epoch: 5| Step: 2
Training loss: 2.0897040367126465
Validation loss: 2.177452173284305

Epoch: 5| Step: 3
Training loss: 2.1649258136749268
Validation loss: 2.1720230502467

Epoch: 5| Step: 4
Training loss: 2.4129974842071533
Validation loss: 2.1961908648090978

Epoch: 5| Step: 5
Training loss: 2.6918463706970215
Validation loss: 2.2121442594835834

Epoch: 5| Step: 6
Training loss: 1.5019855499267578
Validation loss: 2.2245557641470306

Epoch: 5| Step: 7
Training loss: 2.0607142448425293
Validation loss: 2.226724152923912

Epoch: 5| Step: 8
Training loss: 2.1347174644470215
Validation loss: 2.257741376917849

Epoch: 5| Step: 9
Training loss: 2.7947027683258057
Validation loss: 2.2455126393225884

Epoch: 5| Step: 10
Training loss: 2.3727893829345703
Validation loss: 2.2446542580922446

Epoch: 335| Step: 0
Training loss: 1.8824745416641235
Validation loss: 2.2294271543461788

Epoch: 5| Step: 1
Training loss: 1.8205486536026
Validation loss: 2.2114584548498994

Epoch: 5| Step: 2
Training loss: 2.5890235900878906
Validation loss: 2.200643972683978

Epoch: 5| Step: 3
Training loss: 2.1582252979278564
Validation loss: 2.189440534960839

Epoch: 5| Step: 4
Training loss: 2.2968978881835938
Validation loss: 2.1734898103180753

Epoch: 5| Step: 5
Training loss: 2.302309989929199
Validation loss: 2.1677822592437908

Epoch: 5| Step: 6
Training loss: 2.2960705757141113
Validation loss: 2.1689006782347158

Epoch: 5| Step: 7
Training loss: 2.1237118244171143
Validation loss: 2.179174429626875

Epoch: 5| Step: 8
Training loss: 2.752171039581299
Validation loss: 2.184534534331291

Epoch: 5| Step: 9
Training loss: 2.1755030155181885
Validation loss: 2.17538595327767

Epoch: 5| Step: 10
Training loss: 2.874063014984131
Validation loss: 2.1842727789314846

Epoch: 336| Step: 0
Training loss: 2.422942876815796
Validation loss: 2.194958289464315

Epoch: 5| Step: 1
Training loss: 2.749695301055908
Validation loss: 2.1807006917974

Epoch: 5| Step: 2
Training loss: 1.8205296993255615
Validation loss: 2.1710579523476223

Epoch: 5| Step: 3
Training loss: 2.641388416290283
Validation loss: 2.1908211541432205

Epoch: 5| Step: 4
Training loss: 2.4553706645965576
Validation loss: 2.1938593720877044

Epoch: 5| Step: 5
Training loss: 2.2488255500793457
Validation loss: 2.1992510646902104

Epoch: 5| Step: 6
Training loss: 2.290623426437378
Validation loss: 2.2032881270172777

Epoch: 5| Step: 7
Training loss: 1.7562377452850342
Validation loss: 2.200249884718208

Epoch: 5| Step: 8
Training loss: 2.2666592597961426
Validation loss: 2.203131962847966

Epoch: 5| Step: 9
Training loss: 2.019160270690918
Validation loss: 2.224920142081476

Epoch: 5| Step: 10
Training loss: 2.557558298110962
Validation loss: 2.2226354742562897

Epoch: 337| Step: 0
Training loss: 2.1676888465881348
Validation loss: 2.235548637246573

Epoch: 5| Step: 1
Training loss: 2.451874256134033
Validation loss: 2.2255867963196128

Epoch: 5| Step: 2
Training loss: 2.2361161708831787
Validation loss: 2.1941292875556537

Epoch: 5| Step: 3
Training loss: 1.7570558786392212
Validation loss: 2.196239950836346

Epoch: 5| Step: 4
Training loss: 2.0420594215393066
Validation loss: 2.1992751526576217

Epoch: 5| Step: 5
Training loss: 2.3704373836517334
Validation loss: 2.1810203521482405

Epoch: 5| Step: 6
Training loss: 2.4096884727478027
Validation loss: 2.1777248523568593

Epoch: 5| Step: 7
Training loss: 1.727596640586853
Validation loss: 2.1739736077606038

Epoch: 5| Step: 8
Training loss: 2.612421989440918
Validation loss: 2.1812739602981077

Epoch: 5| Step: 9
Training loss: 2.2264397144317627
Validation loss: 2.173528250827584

Epoch: 5| Step: 10
Training loss: 3.2608206272125244
Validation loss: 2.1687877447374406

Epoch: 338| Step: 0
Training loss: 2.1604671478271484
Validation loss: 2.1773019836794947

Epoch: 5| Step: 1
Training loss: 2.160090684890747
Validation loss: 2.1766935035746586

Epoch: 5| Step: 2
Training loss: 2.3806862831115723
Validation loss: 2.172866121415169

Epoch: 5| Step: 3
Training loss: 2.3602371215820312
Validation loss: 2.182834653444188

Epoch: 5| Step: 4
Training loss: 2.651437997817993
Validation loss: 2.1930435139645814

Epoch: 5| Step: 5
Training loss: 2.539990186691284
Validation loss: 2.183126111184397

Epoch: 5| Step: 6
Training loss: 2.218205213546753
Validation loss: 2.1952832565512708

Epoch: 5| Step: 7
Training loss: 2.4241325855255127
Validation loss: 2.204326081019576

Epoch: 5| Step: 8
Training loss: 2.75785756111145
Validation loss: 2.1929724639461887

Epoch: 5| Step: 9
Training loss: 1.9636818170547485
Validation loss: 2.1911352539575226

Epoch: 5| Step: 10
Training loss: 1.3209881782531738
Validation loss: 2.2025644920205556

Epoch: 339| Step: 0
Training loss: 2.3747286796569824
Validation loss: 2.19795992553875

Epoch: 5| Step: 1
Training loss: 2.1895363330841064
Validation loss: 2.1767753260110014

Epoch: 5| Step: 2
Training loss: 2.232586622238159
Validation loss: 2.1652176687794347

Epoch: 5| Step: 3
Training loss: 2.3684630393981934
Validation loss: 2.1791451900236067

Epoch: 5| Step: 4
Training loss: 1.8924267292022705
Validation loss: 2.1703458242518927

Epoch: 5| Step: 5
Training loss: 2.2786669731140137
Validation loss: 2.17471484984121

Epoch: 5| Step: 6
Training loss: 2.1222236156463623
Validation loss: 2.1795910686574955

Epoch: 5| Step: 7
Training loss: 2.435616970062256
Validation loss: 2.1886577221655075

Epoch: 5| Step: 8
Training loss: 2.4058139324188232
Validation loss: 2.19945784794387

Epoch: 5| Step: 9
Training loss: 2.1910464763641357
Validation loss: 2.1845164119556384

Epoch: 5| Step: 10
Training loss: 2.665980577468872
Validation loss: 2.1894191285615325

Epoch: 340| Step: 0
Training loss: 2.0172946453094482
Validation loss: 2.214563541514899

Epoch: 5| Step: 1
Training loss: 2.047156572341919
Validation loss: 2.208094749399411

Epoch: 5| Step: 2
Training loss: 2.32354474067688
Validation loss: 2.2141286352629304

Epoch: 5| Step: 3
Training loss: 1.8673057556152344
Validation loss: 2.213313025812949

Epoch: 5| Step: 4
Training loss: 2.3275747299194336
Validation loss: 2.1966666918928905

Epoch: 5| Step: 5
Training loss: 2.103520631790161
Validation loss: 2.186396232215307

Epoch: 5| Step: 6
Training loss: 2.9092886447906494
Validation loss: 2.2053724514540805

Epoch: 5| Step: 7
Training loss: 2.3993773460388184
Validation loss: 2.182482196438697

Epoch: 5| Step: 8
Training loss: 2.48905873298645
Validation loss: 2.1796194878957604

Epoch: 5| Step: 9
Training loss: 2.4292588233947754
Validation loss: 2.1721446937130344

Epoch: 5| Step: 10
Training loss: 2.156510353088379
Validation loss: 2.1673119324509815

Epoch: 341| Step: 0
Training loss: 2.757455587387085
Validation loss: 2.176870902379354

Epoch: 5| Step: 1
Training loss: 2.743321418762207
Validation loss: 2.182468193833546

Epoch: 5| Step: 2
Training loss: 1.8084081411361694
Validation loss: 2.188482156363867

Epoch: 5| Step: 3
Training loss: 2.264612913131714
Validation loss: 2.2040587112467778

Epoch: 5| Step: 4
Training loss: 2.092501401901245
Validation loss: 2.2193554960271364

Epoch: 5| Step: 5
Training loss: 2.251174211502075
Validation loss: 2.225175637070851

Epoch: 5| Step: 6
Training loss: 2.9066288471221924
Validation loss: 2.237608307151384

Epoch: 5| Step: 7
Training loss: 2.4254367351531982
Validation loss: 2.200718516944557

Epoch: 5| Step: 8
Training loss: 1.7940266132354736
Validation loss: 2.2074510294903993

Epoch: 5| Step: 9
Training loss: 2.292297840118408
Validation loss: 2.208551155623569

Epoch: 5| Step: 10
Training loss: 1.7281606197357178
Validation loss: 2.186173536444223

Epoch: 342| Step: 0
Training loss: 2.411555290222168
Validation loss: 2.1780878882254324

Epoch: 5| Step: 1
Training loss: 2.365543842315674
Validation loss: 2.1704850555748068

Epoch: 5| Step: 2
Training loss: 2.7938168048858643
Validation loss: 2.1536009632131106

Epoch: 5| Step: 3
Training loss: 2.7813198566436768
Validation loss: 2.1710842553005425

Epoch: 5| Step: 4
Training loss: 2.4597115516662598
Validation loss: 2.1524572218618085

Epoch: 5| Step: 5
Training loss: 1.4785966873168945
Validation loss: 2.174139174081946

Epoch: 5| Step: 6
Training loss: 1.804420828819275
Validation loss: 2.163410468768048

Epoch: 5| Step: 7
Training loss: 2.1040663719177246
Validation loss: 2.1723954780127412

Epoch: 5| Step: 8
Training loss: 2.088451385498047
Validation loss: 2.166395887251823

Epoch: 5| Step: 9
Training loss: 2.241694688796997
Validation loss: 2.1973042513734553

Epoch: 5| Step: 10
Training loss: 2.5436782836914062
Validation loss: 2.214587155208793

Epoch: 343| Step: 0
Training loss: 1.8404737710952759
Validation loss: 2.2075659972365185

Epoch: 5| Step: 1
Training loss: 2.0344603061676025
Validation loss: 2.202556851089642

Epoch: 5| Step: 2
Training loss: 2.462088108062744
Validation loss: 2.2135342782543552

Epoch: 5| Step: 3
Training loss: 2.092364549636841
Validation loss: 2.204410881124517

Epoch: 5| Step: 4
Training loss: 2.8765931129455566
Validation loss: 2.1983382368600495

Epoch: 5| Step: 5
Training loss: 2.5870068073272705
Validation loss: 2.1731892311444847

Epoch: 5| Step: 6
Training loss: 1.8802417516708374
Validation loss: 2.1541408441400014

Epoch: 5| Step: 7
Training loss: 2.211559295654297
Validation loss: 2.1680868107785463

Epoch: 5| Step: 8
Training loss: 2.746990919113159
Validation loss: 2.1539875384299987

Epoch: 5| Step: 9
Training loss: 1.5729103088378906
Validation loss: 2.1728990359972884

Epoch: 5| Step: 10
Training loss: 2.848785638809204
Validation loss: 2.1850203698681248

Epoch: 344| Step: 0
Training loss: 2.5482022762298584
Validation loss: 2.182275285003006

Epoch: 5| Step: 1
Training loss: 2.3235273361206055
Validation loss: 2.1809140661711335

Epoch: 5| Step: 2
Training loss: 1.5164523124694824
Validation loss: 2.197863345505089

Epoch: 5| Step: 3
Training loss: 2.266230583190918
Validation loss: 2.2156091454208537

Epoch: 5| Step: 4
Training loss: 2.347957134246826
Validation loss: 2.216366316682549

Epoch: 5| Step: 5
Training loss: 2.7155277729034424
Validation loss: 2.224841367813849

Epoch: 5| Step: 6
Training loss: 2.8627171516418457
Validation loss: 2.2257184392662457

Epoch: 5| Step: 7
Training loss: 1.9412199258804321
Validation loss: 2.2150268605960313

Epoch: 5| Step: 8
Training loss: 2.1786322593688965
Validation loss: 2.208357436682588

Epoch: 5| Step: 9
Training loss: 2.0644404888153076
Validation loss: 2.195360727207635

Epoch: 5| Step: 10
Training loss: 2.269421100616455
Validation loss: 2.182498290974607

Epoch: 345| Step: 0
Training loss: 1.7652826309204102
Validation loss: 2.166531365404847

Epoch: 5| Step: 1
Training loss: 1.7203648090362549
Validation loss: 2.177830562796644

Epoch: 5| Step: 2
Training loss: 2.5012154579162598
Validation loss: 2.1658120283516507

Epoch: 5| Step: 3
Training loss: 2.544703722000122
Validation loss: 2.1596311189795054

Epoch: 5| Step: 4
Training loss: 2.4006996154785156
Validation loss: 2.188407669785202

Epoch: 5| Step: 5
Training loss: 2.718766689300537
Validation loss: 2.1805194629135953

Epoch: 5| Step: 6
Training loss: 2.33632493019104
Validation loss: 2.179952895769509

Epoch: 5| Step: 7
Training loss: 2.521838665008545
Validation loss: 2.1739685048339186

Epoch: 5| Step: 8
Training loss: 2.132547378540039
Validation loss: 2.183659335618378

Epoch: 5| Step: 9
Training loss: 1.9057652950286865
Validation loss: 2.1788526555543304

Epoch: 5| Step: 10
Training loss: 2.3756940364837646
Validation loss: 2.1993353571943057

Epoch: 346| Step: 0
Training loss: 2.082611322402954
Validation loss: 2.2119189026535198

Epoch: 5| Step: 1
Training loss: 1.956110954284668
Validation loss: 2.208948061030398

Epoch: 5| Step: 2
Training loss: 2.168161153793335
Validation loss: 2.215473703158799

Epoch: 5| Step: 3
Training loss: 2.316173553466797
Validation loss: 2.2144921377140987

Epoch: 5| Step: 4
Training loss: 2.3933749198913574
Validation loss: 2.2142861504708566

Epoch: 5| Step: 5
Training loss: 1.741580605506897
Validation loss: 2.220655600229899

Epoch: 5| Step: 6
Training loss: 2.462838649749756
Validation loss: 2.2246159686837146

Epoch: 5| Step: 7
Training loss: 2.4521241188049316
Validation loss: 2.208967883099792

Epoch: 5| Step: 8
Training loss: 2.6827445030212402
Validation loss: 2.187596441597067

Epoch: 5| Step: 9
Training loss: 2.1698057651519775
Validation loss: 2.1892522227379585

Epoch: 5| Step: 10
Training loss: 2.3868091106414795
Validation loss: 2.1665812333424888

Epoch: 347| Step: 0
Training loss: 2.077028751373291
Validation loss: 2.1871661088799916

Epoch: 5| Step: 1
Training loss: 2.5172972679138184
Validation loss: 2.1713344230446765

Epoch: 5| Step: 2
Training loss: 2.4015018939971924
Validation loss: 2.1676425780019453

Epoch: 5| Step: 3
Training loss: 2.028425693511963
Validation loss: 2.16689024689377

Epoch: 5| Step: 4
Training loss: 2.0891222953796387
Validation loss: 2.1736956796338482

Epoch: 5| Step: 5
Training loss: 2.588247299194336
Validation loss: 2.169948850908587

Epoch: 5| Step: 6
Training loss: 2.273390531539917
Validation loss: 2.177764082467684

Epoch: 5| Step: 7
Training loss: 2.7842094898223877
Validation loss: 2.1774671064910067

Epoch: 5| Step: 8
Training loss: 1.928876519203186
Validation loss: 2.180794619744824

Epoch: 5| Step: 9
Training loss: 2.2302448749542236
Validation loss: 2.155205039567845

Epoch: 5| Step: 10
Training loss: 1.991429090499878
Validation loss: 2.1723707978443434

Epoch: 348| Step: 0
Training loss: 2.3883860111236572
Validation loss: 2.1731564896081084

Epoch: 5| Step: 1
Training loss: 1.3257920742034912
Validation loss: 2.18168705765919

Epoch: 5| Step: 2
Training loss: 2.6300010681152344
Validation loss: 2.1762659113894225

Epoch: 5| Step: 3
Training loss: 2.219210147857666
Validation loss: 2.1887607433462657

Epoch: 5| Step: 4
Training loss: 1.9081766605377197
Validation loss: 2.2059627707286547

Epoch: 5| Step: 5
Training loss: 2.3202078342437744
Validation loss: 2.1998149195025043

Epoch: 5| Step: 6
Training loss: 2.9259705543518066
Validation loss: 2.1880977025596042

Epoch: 5| Step: 7
Training loss: 2.610915422439575
Validation loss: 2.1810937876342447

Epoch: 5| Step: 8
Training loss: 1.9424209594726562
Validation loss: 2.17170948238783

Epoch: 5| Step: 9
Training loss: 2.0620017051696777
Validation loss: 2.173773761718504

Epoch: 5| Step: 10
Training loss: 2.6449244022369385
Validation loss: 2.168023851609999

Epoch: 349| Step: 0
Training loss: 2.1419837474823
Validation loss: 2.192828752661264

Epoch: 5| Step: 1
Training loss: 1.9694366455078125
Validation loss: 2.173626402372955

Epoch: 5| Step: 2
Training loss: 2.188692092895508
Validation loss: 2.1955419907005886

Epoch: 5| Step: 3
Training loss: 2.1225943565368652
Validation loss: 2.2079521866254908

Epoch: 5| Step: 4
Training loss: 1.661001443862915
Validation loss: 2.2180121803796418

Epoch: 5| Step: 5
Training loss: 2.911640167236328
Validation loss: 2.2243536595375306

Epoch: 5| Step: 6
Training loss: 2.1864917278289795
Validation loss: 2.207752073964765

Epoch: 5| Step: 7
Training loss: 2.001027822494507
Validation loss: 2.2145303885142007

Epoch: 5| Step: 8
Training loss: 2.4264488220214844
Validation loss: 2.20410317502996

Epoch: 5| Step: 9
Training loss: 1.9374587535858154
Validation loss: 2.1978289863114715

Epoch: 5| Step: 10
Training loss: 3.3930530548095703
Validation loss: 2.1870631505084295

Epoch: 350| Step: 0
Training loss: 2.7119035720825195
Validation loss: 2.1813418737021824

Epoch: 5| Step: 1
Training loss: 2.1097984313964844
Validation loss: 2.1537252472292994

Epoch: 5| Step: 2
Training loss: 2.3264565467834473
Validation loss: 2.1398419334042456

Epoch: 5| Step: 3
Training loss: 1.7045786380767822
Validation loss: 2.180881249007358

Epoch: 5| Step: 4
Training loss: 1.3286670446395874
Validation loss: 2.192214339010177

Epoch: 5| Step: 5
Training loss: 2.478738307952881
Validation loss: 2.1962531766583844

Epoch: 5| Step: 6
Training loss: 2.3017690181732178
Validation loss: 2.1714461054853214

Epoch: 5| Step: 7
Training loss: 2.8833556175231934
Validation loss: 2.176473504753523

Epoch: 5| Step: 8
Training loss: 2.1088764667510986
Validation loss: 2.1777961151574248

Epoch: 5| Step: 9
Training loss: 2.3837366104125977
Validation loss: 2.1989478270212808

Epoch: 5| Step: 10
Training loss: 2.457819700241089
Validation loss: 2.193916291318914

Epoch: 351| Step: 0
Training loss: 2.2266440391540527
Validation loss: 2.1941445155810286

Epoch: 5| Step: 1
Training loss: 2.421186685562134
Validation loss: 2.1717128446025233

Epoch: 5| Step: 2
Training loss: 2.2037742137908936
Validation loss: 2.19658556548498

Epoch: 5| Step: 3
Training loss: 2.0069384574890137
Validation loss: 2.191567192795456

Epoch: 5| Step: 4
Training loss: 2.1445226669311523
Validation loss: 2.183957694679178

Epoch: 5| Step: 5
Training loss: 1.6539580821990967
Validation loss: 2.194194039990825

Epoch: 5| Step: 6
Training loss: 2.1877381801605225
Validation loss: 2.197222343055151

Epoch: 5| Step: 7
Training loss: 2.0980935096740723
Validation loss: 2.1733869429557555

Epoch: 5| Step: 8
Training loss: 2.108917236328125
Validation loss: 2.1871248342657603

Epoch: 5| Step: 9
Training loss: 2.9835891723632812
Validation loss: 2.1791013261323333

Epoch: 5| Step: 10
Training loss: 2.789271593093872
Validation loss: 2.187012541678644

Epoch: 352| Step: 0
Training loss: 2.065728187561035
Validation loss: 2.196840875892229

Epoch: 5| Step: 1
Training loss: 1.898848295211792
Validation loss: 2.200024207433065

Epoch: 5| Step: 2
Training loss: 2.397951364517212
Validation loss: 2.1871286399902834

Epoch: 5| Step: 3
Training loss: 2.618408441543579
Validation loss: 2.170585160614342

Epoch: 5| Step: 4
Training loss: 1.9671249389648438
Validation loss: 2.150839305693103

Epoch: 5| Step: 5
Training loss: 2.268463373184204
Validation loss: 2.162812928999624

Epoch: 5| Step: 6
Training loss: 2.1864891052246094
Validation loss: 2.153786374676612

Epoch: 5| Step: 7
Training loss: 2.346963405609131
Validation loss: 2.150377327396024

Epoch: 5| Step: 8
Training loss: 2.7388739585876465
Validation loss: 2.1476486652128157

Epoch: 5| Step: 9
Training loss: 2.2474377155303955
Validation loss: 2.159670296535697

Epoch: 5| Step: 10
Training loss: 1.9940376281738281
Validation loss: 2.1469496373207337

Epoch: 353| Step: 0
Training loss: 2.3001835346221924
Validation loss: 2.1598744571849866

Epoch: 5| Step: 1
Training loss: 2.1874232292175293
Validation loss: 2.1662991405815206

Epoch: 5| Step: 2
Training loss: 2.3944013118743896
Validation loss: 2.176143250157756

Epoch: 5| Step: 3
Training loss: 2.8014445304870605
Validation loss: 2.193055365675239

Epoch: 5| Step: 4
Training loss: 2.3625919818878174
Validation loss: 2.2020152666235484

Epoch: 5| Step: 5
Training loss: 2.2732443809509277
Validation loss: 2.1962767775340746

Epoch: 5| Step: 6
Training loss: 2.029679775238037
Validation loss: 2.187160879053095

Epoch: 5| Step: 7
Training loss: 2.2265944480895996
Validation loss: 2.173711907479071

Epoch: 5| Step: 8
Training loss: 1.9021450281143188
Validation loss: 2.191557550943026

Epoch: 5| Step: 9
Training loss: 1.9367249011993408
Validation loss: 2.1721656501934095

Epoch: 5| Step: 10
Training loss: 2.3134567737579346
Validation loss: 2.1730997626499464

Epoch: 354| Step: 0
Training loss: 2.198636531829834
Validation loss: 2.171739096282631

Epoch: 5| Step: 1
Training loss: 2.5512893199920654
Validation loss: 2.1649181727440125

Epoch: 5| Step: 2
Training loss: 2.265399932861328
Validation loss: 2.1760742113154423

Epoch: 5| Step: 3
Training loss: 2.820711612701416
Validation loss: 2.1716343997627177

Epoch: 5| Step: 4
Training loss: 2.5675015449523926
Validation loss: 2.173955240557271

Epoch: 5| Step: 5
Training loss: 2.171722888946533
Validation loss: 2.164006592125021

Epoch: 5| Step: 6
Training loss: 1.6952520608901978
Validation loss: 2.1736708225742465

Epoch: 5| Step: 7
Training loss: 2.1584267616271973
Validation loss: 2.168847999265117

Epoch: 5| Step: 8
Training loss: 2.023146390914917
Validation loss: 2.187757617683821

Epoch: 5| Step: 9
Training loss: 2.328733205795288
Validation loss: 2.182847284501599

Epoch: 5| Step: 10
Training loss: 1.9248219728469849
Validation loss: 2.1854613545120403

Epoch: 355| Step: 0
Training loss: 1.9452917575836182
Validation loss: 2.180023741978471

Epoch: 5| Step: 1
Training loss: 2.206343412399292
Validation loss: 2.154911132269008

Epoch: 5| Step: 2
Training loss: 2.473278522491455
Validation loss: 2.1416939330357376

Epoch: 5| Step: 3
Training loss: 2.7489774227142334
Validation loss: 2.154098795306298

Epoch: 5| Step: 4
Training loss: 2.1742682456970215
Validation loss: 2.157477573681903

Epoch: 5| Step: 5
Training loss: 2.101109504699707
Validation loss: 2.1397555797330794

Epoch: 5| Step: 6
Training loss: 2.4637932777404785
Validation loss: 2.140098751232188

Epoch: 5| Step: 7
Training loss: 1.6849796772003174
Validation loss: 2.158507914953334

Epoch: 5| Step: 8
Training loss: 2.6615219116210938
Validation loss: 2.157007896771995

Epoch: 5| Step: 9
Training loss: 1.8557002544403076
Validation loss: 2.175003792649956

Epoch: 5| Step: 10
Training loss: 2.4321811199188232
Validation loss: 2.1839947418500016

Epoch: 356| Step: 0
Training loss: 2.8618876934051514
Validation loss: 2.218986520203211

Epoch: 5| Step: 1
Training loss: 2.328385591506958
Validation loss: 2.174660200713783

Epoch: 5| Step: 2
Training loss: 2.0545706748962402
Validation loss: 2.1818382150383404

Epoch: 5| Step: 3
Training loss: 2.1361618041992188
Validation loss: 2.1737850430191203

Epoch: 5| Step: 4
Training loss: 2.1007721424102783
Validation loss: 2.160876243345199

Epoch: 5| Step: 5
Training loss: 2.4637389183044434
Validation loss: 2.169867141272432

Epoch: 5| Step: 6
Training loss: 2.4563117027282715
Validation loss: 2.1463236372957946

Epoch: 5| Step: 7
Training loss: 2.0211410522460938
Validation loss: 2.1474110669987176

Epoch: 5| Step: 8
Training loss: 2.1497068405151367
Validation loss: 2.1489318224691574

Epoch: 5| Step: 9
Training loss: 2.0752298831939697
Validation loss: 2.1541035059959657

Epoch: 5| Step: 10
Training loss: 1.9464665651321411
Validation loss: 2.1576989235416537

Epoch: 357| Step: 0
Training loss: 2.406337022781372
Validation loss: 2.176151855017549

Epoch: 5| Step: 1
Training loss: 2.4503448009490967
Validation loss: 2.1721294977331675

Epoch: 5| Step: 2
Training loss: 2.086094379425049
Validation loss: 2.212526315002031

Epoch: 5| Step: 3
Training loss: 1.573052167892456
Validation loss: 2.18765619749664

Epoch: 5| Step: 4
Training loss: 2.05461049079895
Validation loss: 2.2103860839720695

Epoch: 5| Step: 5
Training loss: 2.7084481716156006
Validation loss: 2.173386363572972

Epoch: 5| Step: 6
Training loss: 1.7235103845596313
Validation loss: 2.160230703251336

Epoch: 5| Step: 7
Training loss: 2.8088977336883545
Validation loss: 2.1484405020231843

Epoch: 5| Step: 8
Training loss: 2.568176031112671
Validation loss: 2.13048614481444

Epoch: 5| Step: 9
Training loss: 1.8762661218643188
Validation loss: 2.1477578122128724

Epoch: 5| Step: 10
Training loss: 2.5291945934295654
Validation loss: 2.151109104515404

Epoch: 358| Step: 0
Training loss: 1.999169111251831
Validation loss: 2.1539525421716834

Epoch: 5| Step: 1
Training loss: 2.1309573650360107
Validation loss: 2.1374921516705583

Epoch: 5| Step: 2
Training loss: 2.1505210399627686
Validation loss: 2.1595142041483233

Epoch: 5| Step: 3
Training loss: 2.822962760925293
Validation loss: 2.175084683202928

Epoch: 5| Step: 4
Training loss: 2.1368443965911865
Validation loss: 2.170335610707601

Epoch: 5| Step: 5
Training loss: 2.293522596359253
Validation loss: 2.17808045623123

Epoch: 5| Step: 6
Training loss: 2.2679526805877686
Validation loss: 2.1840300277997087

Epoch: 5| Step: 7
Training loss: 1.9625717401504517
Validation loss: 2.1774667027176067

Epoch: 5| Step: 8
Training loss: 2.281217098236084
Validation loss: 2.171155842401648

Epoch: 5| Step: 9
Training loss: 2.5745322704315186
Validation loss: 2.161777327137609

Epoch: 5| Step: 10
Training loss: 2.244182825088501
Validation loss: 2.1356997836020684

Epoch: 359| Step: 0
Training loss: 2.103156328201294
Validation loss: 2.152500496115736

Epoch: 5| Step: 1
Training loss: 2.5505146980285645
Validation loss: 2.139685143706619

Epoch: 5| Step: 2
Training loss: 1.9861646890640259
Validation loss: 2.1489526738402662

Epoch: 5| Step: 3
Training loss: 2.484673023223877
Validation loss: 2.162419001261393

Epoch: 5| Step: 4
Training loss: 2.8076930046081543
Validation loss: 2.1532447517559095

Epoch: 5| Step: 5
Training loss: 1.416711688041687
Validation loss: 2.148292023648498

Epoch: 5| Step: 6
Training loss: 1.98977530002594
Validation loss: 2.17313636759276

Epoch: 5| Step: 7
Training loss: 2.688661813735962
Validation loss: 2.17797444200003

Epoch: 5| Step: 8
Training loss: 2.4431660175323486
Validation loss: 2.174380697229857

Epoch: 5| Step: 9
Training loss: 2.538278579711914
Validation loss: 2.1729898196394726

Epoch: 5| Step: 10
Training loss: 1.631354808807373
Validation loss: 2.156677697294502

Epoch: 360| Step: 0
Training loss: 2.4438223838806152
Validation loss: 2.1654130130685787

Epoch: 5| Step: 1
Training loss: 2.3306634426116943
Validation loss: 2.161087797534081

Epoch: 5| Step: 2
Training loss: 2.7148711681365967
Validation loss: 2.157765805080373

Epoch: 5| Step: 3
Training loss: 1.9874608516693115
Validation loss: 2.1551876991025862

Epoch: 5| Step: 4
Training loss: 1.883880615234375
Validation loss: 2.160436555903445

Epoch: 5| Step: 5
Training loss: 2.8016161918640137
Validation loss: 2.1618695156548613

Epoch: 5| Step: 6
Training loss: 2.0700185298919678
Validation loss: 2.148194154103597

Epoch: 5| Step: 7
Training loss: 2.1809420585632324
Validation loss: 2.1544810597614577

Epoch: 5| Step: 8
Training loss: 2.0076522827148438
Validation loss: 2.150439070117089

Epoch: 5| Step: 9
Training loss: 2.128108024597168
Validation loss: 2.1756005261534

Epoch: 5| Step: 10
Training loss: 1.8875091075897217
Validation loss: 2.16732201012232

Epoch: 361| Step: 0
Training loss: 2.1944806575775146
Validation loss: 2.1724540136193715

Epoch: 5| Step: 1
Training loss: 2.148637056350708
Validation loss: 2.1925156090849187

Epoch: 5| Step: 2
Training loss: 2.3903095722198486
Validation loss: 2.1542149974453833

Epoch: 5| Step: 3
Training loss: 2.574394464492798
Validation loss: 2.173924966525006

Epoch: 5| Step: 4
Training loss: 2.645531177520752
Validation loss: 2.1629667218013475

Epoch: 5| Step: 5
Training loss: 2.3731014728546143
Validation loss: 2.1705885279563164

Epoch: 5| Step: 6
Training loss: 1.7165355682373047
Validation loss: 2.1676488371305567

Epoch: 5| Step: 7
Training loss: 2.122732639312744
Validation loss: 2.1613909377846667

Epoch: 5| Step: 8
Training loss: 2.2743701934814453
Validation loss: 2.169970343189855

Epoch: 5| Step: 9
Training loss: 2.105318307876587
Validation loss: 2.1795353710010485

Epoch: 5| Step: 10
Training loss: 1.9066790342330933
Validation loss: 2.1771481011503484

Epoch: 362| Step: 0
Training loss: 2.355891227722168
Validation loss: 2.1720265547434487

Epoch: 5| Step: 1
Training loss: 1.695625901222229
Validation loss: 2.1676703858119186

Epoch: 5| Step: 2
Training loss: 2.8222384452819824
Validation loss: 2.16160983936761

Epoch: 5| Step: 3
Training loss: 2.0939419269561768
Validation loss: 2.161090950812063

Epoch: 5| Step: 4
Training loss: 2.4255003929138184
Validation loss: 2.174388357388076

Epoch: 5| Step: 5
Training loss: 2.0087342262268066
Validation loss: 2.1481056623561408

Epoch: 5| Step: 6
Training loss: 2.7174389362335205
Validation loss: 2.1584968387439685

Epoch: 5| Step: 7
Training loss: 2.1905744075775146
Validation loss: 2.1816467239010717

Epoch: 5| Step: 8
Training loss: 2.2347347736358643
Validation loss: 2.158749347092003

Epoch: 5| Step: 9
Training loss: 2.0604398250579834
Validation loss: 2.1646833342890583

Epoch: 5| Step: 10
Training loss: 1.689774513244629
Validation loss: 2.149858528567899

Epoch: 363| Step: 0
Training loss: 2.364809513092041
Validation loss: 2.1624711585301224

Epoch: 5| Step: 1
Training loss: 2.026401996612549
Validation loss: 2.1449786386182232

Epoch: 5| Step: 2
Training loss: 1.8996756076812744
Validation loss: 2.1574832418913483

Epoch: 5| Step: 3
Training loss: 2.4805495738983154
Validation loss: 2.154287299802226

Epoch: 5| Step: 4
Training loss: 2.5606603622436523
Validation loss: 2.155866692143102

Epoch: 5| Step: 5
Training loss: 2.3622727394104004
Validation loss: 2.1818873984839326

Epoch: 5| Step: 6
Training loss: 2.454301595687866
Validation loss: 2.2143750959827053

Epoch: 5| Step: 7
Training loss: 2.6067092418670654
Validation loss: 2.209644140735749

Epoch: 5| Step: 8
Training loss: 1.7584974765777588
Validation loss: 2.1959400830730313

Epoch: 5| Step: 9
Training loss: 1.9747158288955688
Validation loss: 2.1708861794523013

Epoch: 5| Step: 10
Training loss: 2.1590325832366943
Validation loss: 2.163907818896796

Epoch: 364| Step: 0
Training loss: 2.0171637535095215
Validation loss: 2.1722544649595856

Epoch: 5| Step: 1
Training loss: 1.9253404140472412
Validation loss: 2.165300783290658

Epoch: 5| Step: 2
Training loss: 2.0613765716552734
Validation loss: 2.158936289048964

Epoch: 5| Step: 3
Training loss: 1.9871673583984375
Validation loss: 2.1577203068681943

Epoch: 5| Step: 4
Training loss: 1.821732521057129
Validation loss: 2.16780432321692

Epoch: 5| Step: 5
Training loss: 2.5187249183654785
Validation loss: 2.1591519745447303

Epoch: 5| Step: 6
Training loss: 2.7592129707336426
Validation loss: 2.1564163879681657

Epoch: 5| Step: 7
Training loss: 2.55230975151062
Validation loss: 2.165813925445721

Epoch: 5| Step: 8
Training loss: 2.512760877609253
Validation loss: 2.1573913840837378

Epoch: 5| Step: 9
Training loss: 1.9839658737182617
Validation loss: 2.1466334917212047

Epoch: 5| Step: 10
Training loss: 2.2470407485961914
Validation loss: 2.1593929016461937

Epoch: 365| Step: 0
Training loss: 2.2568631172180176
Validation loss: 2.1791236426240657

Epoch: 5| Step: 1
Training loss: 1.9963533878326416
Validation loss: 2.1756605127806306

Epoch: 5| Step: 2
Training loss: 2.451829433441162
Validation loss: 2.1780631849842687

Epoch: 5| Step: 3
Training loss: 2.3604674339294434
Validation loss: 2.1929763850345405

Epoch: 5| Step: 4
Training loss: 2.0545432567596436
Validation loss: 2.209794766159468

Epoch: 5| Step: 5
Training loss: 2.0937018394470215
Validation loss: 2.211110381669896

Epoch: 5| Step: 6
Training loss: 2.3720498085021973
Validation loss: 2.205393300261549

Epoch: 5| Step: 7
Training loss: 3.021886110305786
Validation loss: 2.182656431710848

Epoch: 5| Step: 8
Training loss: 1.698751449584961
Validation loss: 2.16531366173939

Epoch: 5| Step: 9
Training loss: 2.2231807708740234
Validation loss: 2.163588241864276

Epoch: 5| Step: 10
Training loss: 2.0397751331329346
Validation loss: 2.142121212456816

Epoch: 366| Step: 0
Training loss: 2.2653160095214844
Validation loss: 2.1383855240319365

Epoch: 5| Step: 1
Training loss: 2.31183123588562
Validation loss: 2.153271493091378

Epoch: 5| Step: 2
Training loss: 2.2636945247650146
Validation loss: 2.134122158891411

Epoch: 5| Step: 3
Training loss: 2.149139404296875
Validation loss: 2.1230257839284916

Epoch: 5| Step: 4
Training loss: 1.9598544836044312
Validation loss: 2.1245270224027735

Epoch: 5| Step: 5
Training loss: 1.6880137920379639
Validation loss: 2.1521887356235134

Epoch: 5| Step: 6
Training loss: 2.677055835723877
Validation loss: 2.178745477430282

Epoch: 5| Step: 7
Training loss: 2.962364673614502
Validation loss: 2.1711942124110397

Epoch: 5| Step: 8
Training loss: 2.5961761474609375
Validation loss: 2.1758309871919694

Epoch: 5| Step: 9
Training loss: 2.2295150756835938
Validation loss: 2.1722609612249557

Epoch: 5| Step: 10
Training loss: 1.3313336372375488
Validation loss: 2.1746805175658195

Epoch: 367| Step: 0
Training loss: 2.4632039070129395
Validation loss: 2.1660285611306467

Epoch: 5| Step: 1
Training loss: 2.5904293060302734
Validation loss: 2.1742042623540407

Epoch: 5| Step: 2
Training loss: 2.299191951751709
Validation loss: 2.1721186535332793

Epoch: 5| Step: 3
Training loss: 2.3902297019958496
Validation loss: 2.159113924990418

Epoch: 5| Step: 4
Training loss: 1.8665342330932617
Validation loss: 2.1522117942892094

Epoch: 5| Step: 5
Training loss: 2.098890781402588
Validation loss: 2.173233180917719

Epoch: 5| Step: 6
Training loss: 2.2670416831970215
Validation loss: 2.1522814842962448

Epoch: 5| Step: 7
Training loss: 2.1542840003967285
Validation loss: 2.1445852761627524

Epoch: 5| Step: 8
Training loss: 2.0524306297302246
Validation loss: 2.1577961470491145

Epoch: 5| Step: 9
Training loss: 1.7207542657852173
Validation loss: 2.149146492763232

Epoch: 5| Step: 10
Training loss: 2.495532512664795
Validation loss: 2.148891945039072

Epoch: 368| Step: 0
Training loss: 1.755297303199768
Validation loss: 2.173966923067647

Epoch: 5| Step: 1
Training loss: 2.013179302215576
Validation loss: 2.1736059599025275

Epoch: 5| Step: 2
Training loss: 2.2386841773986816
Validation loss: 2.175977776127477

Epoch: 5| Step: 3
Training loss: 1.8529924154281616
Validation loss: 2.1586252258669947

Epoch: 5| Step: 4
Training loss: 2.364541530609131
Validation loss: 2.16745896749599

Epoch: 5| Step: 5
Training loss: 2.8353450298309326
Validation loss: 2.165422599802735

Epoch: 5| Step: 6
Training loss: 2.613154649734497
Validation loss: 2.140034201324627

Epoch: 5| Step: 7
Training loss: 2.615762710571289
Validation loss: 2.138546202772407

Epoch: 5| Step: 8
Training loss: 1.8464956283569336
Validation loss: 2.1366591479188655

Epoch: 5| Step: 9
Training loss: 2.184882640838623
Validation loss: 2.13870576120192

Epoch: 5| Step: 10
Training loss: 2.0907208919525146
Validation loss: 2.135278920973501

Epoch: 369| Step: 0
Training loss: 2.4818427562713623
Validation loss: 2.156121592367849

Epoch: 5| Step: 1
Training loss: 2.8596298694610596
Validation loss: 2.171441706277991

Epoch: 5| Step: 2
Training loss: 2.2706782817840576
Validation loss: 2.151295156889064

Epoch: 5| Step: 3
Training loss: 2.5074985027313232
Validation loss: 2.1743474493744555

Epoch: 5| Step: 4
Training loss: 1.6418368816375732
Validation loss: 2.1640904667556926

Epoch: 5| Step: 5
Training loss: 2.0118234157562256
Validation loss: 2.1735722762282177

Epoch: 5| Step: 6
Training loss: 1.786699652671814
Validation loss: 2.1808891629660003

Epoch: 5| Step: 7
Training loss: 2.209512948989868
Validation loss: 2.1722384601510982

Epoch: 5| Step: 8
Training loss: 1.913866400718689
Validation loss: 2.175212344815654

Epoch: 5| Step: 9
Training loss: 2.4138052463531494
Validation loss: 2.163121715668709

Epoch: 5| Step: 10
Training loss: 2.177210807800293
Validation loss: 2.1454082304431545

Epoch: 370| Step: 0
Training loss: 2.377106189727783
Validation loss: 2.1287826466304

Epoch: 5| Step: 1
Training loss: 1.3477263450622559
Validation loss: 2.1386322385521344

Epoch: 5| Step: 2
Training loss: 3.0877022743225098
Validation loss: 2.1354353402250554

Epoch: 5| Step: 3
Training loss: 2.4445064067840576
Validation loss: 2.126940195278455

Epoch: 5| Step: 4
Training loss: 2.6997478008270264
Validation loss: 2.1488516305082586

Epoch: 5| Step: 5
Training loss: 2.2550175189971924
Validation loss: 2.149768867800313

Epoch: 5| Step: 6
Training loss: 2.1537535190582275
Validation loss: 2.157611995614985

Epoch: 5| Step: 7
Training loss: 2.275773763656616
Validation loss: 2.1563048247368104

Epoch: 5| Step: 8
Training loss: 1.8523874282836914
Validation loss: 2.1595917235138598

Epoch: 5| Step: 9
Training loss: 1.7038614749908447
Validation loss: 2.1678659044286257

Epoch: 5| Step: 10
Training loss: 1.922894835472107
Validation loss: 2.1626106692898657

Epoch: 371| Step: 0
Training loss: 2.823263168334961
Validation loss: 2.1730220510113623

Epoch: 5| Step: 1
Training loss: 2.93769907951355
Validation loss: 2.176346427650862

Epoch: 5| Step: 2
Training loss: 2.054506778717041
Validation loss: 2.1644728286291963

Epoch: 5| Step: 3
Training loss: 2.1102187633514404
Validation loss: 2.152980209678732

Epoch: 5| Step: 4
Training loss: 2.4116241931915283
Validation loss: 2.1460130060872724

Epoch: 5| Step: 5
Training loss: 1.447404146194458
Validation loss: 2.1302245022148214

Epoch: 5| Step: 6
Training loss: 2.2345471382141113
Validation loss: 2.1273168261333177

Epoch: 5| Step: 7
Training loss: 2.1043405532836914
Validation loss: 2.1376684199097338

Epoch: 5| Step: 8
Training loss: 1.4002307653427124
Validation loss: 2.1469396468131774

Epoch: 5| Step: 9
Training loss: 2.550955295562744
Validation loss: 2.1408000274371077

Epoch: 5| Step: 10
Training loss: 2.1743788719177246
Validation loss: 2.1455779588350685

Epoch: 372| Step: 0
Training loss: 2.107475996017456
Validation loss: 2.1390098833268687

Epoch: 5| Step: 1
Training loss: 2.480649948120117
Validation loss: 2.144757952741397

Epoch: 5| Step: 2
Training loss: 2.576601505279541
Validation loss: 2.128640187683926

Epoch: 5| Step: 3
Training loss: 2.1838736534118652
Validation loss: 2.121584406463049

Epoch: 5| Step: 4
Training loss: 2.3916447162628174
Validation loss: 2.1281589026092202

Epoch: 5| Step: 5
Training loss: 2.177665948867798
Validation loss: 2.1247193018595376

Epoch: 5| Step: 6
Training loss: 2.228686571121216
Validation loss: 2.1404830717271373

Epoch: 5| Step: 7
Training loss: 2.3736231327056885
Validation loss: 2.1663962025796213

Epoch: 5| Step: 8
Training loss: 1.7405767440795898
Validation loss: 2.168249895495753

Epoch: 5| Step: 9
Training loss: 2.200721025466919
Validation loss: 2.1600052964302803

Epoch: 5| Step: 10
Training loss: 1.7274531126022339
Validation loss: 2.1975414996506064

Epoch: 373| Step: 0
Training loss: 2.5157971382141113
Validation loss: 2.1816934770153416

Epoch: 5| Step: 1
Training loss: 1.7222026586532593
Validation loss: 2.182343470152988

Epoch: 5| Step: 2
Training loss: 2.537105083465576
Validation loss: 2.1722822394422305

Epoch: 5| Step: 3
Training loss: 2.7700817584991455
Validation loss: 2.149112102805927

Epoch: 5| Step: 4
Training loss: 2.3659164905548096
Validation loss: 2.1454810455281246

Epoch: 5| Step: 5
Training loss: 2.6224019527435303
Validation loss: 2.1269670289049865

Epoch: 5| Step: 6
Training loss: 1.8770641088485718
Validation loss: 2.1563744173255017

Epoch: 5| Step: 7
Training loss: 2.184689521789551
Validation loss: 2.1456682374400478

Epoch: 5| Step: 8
Training loss: 1.739642858505249
Validation loss: 2.1558951844451246

Epoch: 5| Step: 9
Training loss: 1.3091747760772705
Validation loss: 2.1460891487777873

Epoch: 5| Step: 10
Training loss: 2.810980796813965
Validation loss: 2.144532001146706

Epoch: 374| Step: 0
Training loss: 2.3546903133392334
Validation loss: 2.1517521463414675

Epoch: 5| Step: 1
Training loss: 2.166747808456421
Validation loss: 2.136304939946821

Epoch: 5| Step: 2
Training loss: 2.1674675941467285
Validation loss: 2.152448559320101

Epoch: 5| Step: 3
Training loss: 2.296252965927124
Validation loss: 2.141113542741345

Epoch: 5| Step: 4
Training loss: 1.9473636150360107
Validation loss: 2.135634632520778

Epoch: 5| Step: 5
Training loss: 1.487410306930542
Validation loss: 2.1464700288670038

Epoch: 5| Step: 6
Training loss: 2.0942330360412598
Validation loss: 2.1441763934268745

Epoch: 5| Step: 7
Training loss: 2.200396776199341
Validation loss: 2.1463461024786836

Epoch: 5| Step: 8
Training loss: 1.7920961380004883
Validation loss: 2.1408611830844673

Epoch: 5| Step: 9
Training loss: 3.1675546169281006
Validation loss: 2.1640335872609127

Epoch: 5| Step: 10
Training loss: 2.4668710231781006
Validation loss: 2.152347071196443

Epoch: 375| Step: 0
Training loss: 1.7662718296051025
Validation loss: 2.1554015003224856

Epoch: 5| Step: 1
Training loss: 2.2861626148223877
Validation loss: 2.146710054848784

Epoch: 5| Step: 2
Training loss: 2.1142830848693848
Validation loss: 2.1598074231096493

Epoch: 5| Step: 3
Training loss: 2.373966693878174
Validation loss: 2.1563565013229207

Epoch: 5| Step: 4
Training loss: 2.100844621658325
Validation loss: 2.1632912774239816

Epoch: 5| Step: 5
Training loss: 2.3026490211486816
Validation loss: 2.143002261397659

Epoch: 5| Step: 6
Training loss: 2.514875650405884
Validation loss: 2.1658038887926327

Epoch: 5| Step: 7
Training loss: 1.7266120910644531
Validation loss: 2.163009535881781

Epoch: 5| Step: 8
Training loss: 2.342634677886963
Validation loss: 2.143629389424478

Epoch: 5| Step: 9
Training loss: 1.9039947986602783
Validation loss: 2.159060062900666

Epoch: 5| Step: 10
Training loss: 2.8153648376464844
Validation loss: 2.134426861680964

Epoch: 376| Step: 0
Training loss: 2.518401622772217
Validation loss: 2.1306309059102047

Epoch: 5| Step: 1
Training loss: 2.2000222206115723
Validation loss: 2.132126851748395

Epoch: 5| Step: 2
Training loss: 2.2978813648223877
Validation loss: 2.1149853429486676

Epoch: 5| Step: 3
Training loss: 2.7962284088134766
Validation loss: 2.105162856399372

Epoch: 5| Step: 4
Training loss: 2.017423391342163
Validation loss: 2.1128045051328597

Epoch: 5| Step: 5
Training loss: 2.022416114807129
Validation loss: 2.106941928145706

Epoch: 5| Step: 6
Training loss: 2.1704883575439453
Validation loss: 2.1161994062444216

Epoch: 5| Step: 7
Training loss: 1.8353869915008545
Validation loss: 2.126266110327936

Epoch: 5| Step: 8
Training loss: 1.7446248531341553
Validation loss: 2.1391003977867866

Epoch: 5| Step: 9
Training loss: 2.371575355529785
Validation loss: 2.1406665822511077

Epoch: 5| Step: 10
Training loss: 2.4710617065429688
Validation loss: 2.170583486557007

Epoch: 377| Step: 0
Training loss: 2.3437247276306152
Validation loss: 2.2021783526225756

Epoch: 5| Step: 1
Training loss: 2.3037455081939697
Validation loss: 2.169839382171631

Epoch: 5| Step: 2
Training loss: 2.2564265727996826
Validation loss: 2.193427421713388

Epoch: 5| Step: 3
Training loss: 1.9646564722061157
Validation loss: 2.1740683996549217

Epoch: 5| Step: 4
Training loss: 1.9958473443984985
Validation loss: 2.169257404983685

Epoch: 5| Step: 5
Training loss: 2.001626491546631
Validation loss: 2.17046526170546

Epoch: 5| Step: 6
Training loss: 2.04473614692688
Validation loss: 2.147144809845955

Epoch: 5| Step: 7
Training loss: 2.298779249191284
Validation loss: 2.140762495738204

Epoch: 5| Step: 8
Training loss: 2.5502769947052
Validation loss: 2.142140660234677

Epoch: 5| Step: 9
Training loss: 2.0863780975341797
Validation loss: 2.139092077491104

Epoch: 5| Step: 10
Training loss: 2.452788829803467
Validation loss: 2.125452526154057

Epoch: 378| Step: 0
Training loss: 2.443345308303833
Validation loss: 2.13330663147793

Epoch: 5| Step: 1
Training loss: 1.6347099542617798
Validation loss: 2.1312722467607066

Epoch: 5| Step: 2
Training loss: 2.063415050506592
Validation loss: 2.125075458198465

Epoch: 5| Step: 3
Training loss: 2.631938934326172
Validation loss: 2.121890357745591

Epoch: 5| Step: 4
Training loss: 1.7306489944458008
Validation loss: 2.1090673938874276

Epoch: 5| Step: 5
Training loss: 2.148590564727783
Validation loss: 2.1098551378455213

Epoch: 5| Step: 6
Training loss: 1.8643925189971924
Validation loss: 2.119633436203003

Epoch: 5| Step: 7
Training loss: 2.3159050941467285
Validation loss: 2.135142293027652

Epoch: 5| Step: 8
Training loss: 2.2708420753479004
Validation loss: 2.1408376488634335

Epoch: 5| Step: 9
Training loss: 2.440911054611206
Validation loss: 2.1360316609823577

Epoch: 5| Step: 10
Training loss: 2.7885990142822266
Validation loss: 2.142610729381602

Epoch: 379| Step: 0
Training loss: 2.5979115962982178
Validation loss: 2.1612871334116948

Epoch: 5| Step: 1
Training loss: 2.0050318241119385
Validation loss: 2.175782803566225

Epoch: 5| Step: 2
Training loss: 2.581153631210327
Validation loss: 2.176920014043008

Epoch: 5| Step: 3
Training loss: 2.098827838897705
Validation loss: 2.1841726328736994

Epoch: 5| Step: 4
Training loss: 1.7648828029632568
Validation loss: 2.1810124651078255

Epoch: 5| Step: 5
Training loss: 2.04217267036438
Validation loss: 2.1449151885124946

Epoch: 5| Step: 6
Training loss: 2.434873342514038
Validation loss: 2.144079416028915

Epoch: 5| Step: 7
Training loss: 2.0990748405456543
Validation loss: 2.136606381785485

Epoch: 5| Step: 8
Training loss: 1.6853172779083252
Validation loss: 2.1356700402434154

Epoch: 5| Step: 9
Training loss: 2.3688645362854004
Validation loss: 2.131110037526777

Epoch: 5| Step: 10
Training loss: 2.534205675125122
Validation loss: 2.11333413662449

Epoch: 380| Step: 0
Training loss: 2.0235233306884766
Validation loss: 2.108713601225166

Epoch: 5| Step: 1
Training loss: 2.2424368858337402
Validation loss: 2.1221208328841836

Epoch: 5| Step: 2
Training loss: 2.1007866859436035
Validation loss: 2.123711957726427

Epoch: 5| Step: 3
Training loss: 2.7605504989624023
Validation loss: 2.1219155198784283

Epoch: 5| Step: 4
Training loss: 2.3645496368408203
Validation loss: 2.128773340614893

Epoch: 5| Step: 5
Training loss: 2.223970890045166
Validation loss: 2.128357410430908

Epoch: 5| Step: 6
Training loss: 2.1857409477233887
Validation loss: 2.151235206152803

Epoch: 5| Step: 7
Training loss: 1.9247798919677734
Validation loss: 2.1635666047373125

Epoch: 5| Step: 8
Training loss: 1.6351921558380127
Validation loss: 2.1617803791517853

Epoch: 5| Step: 9
Training loss: 2.334981918334961
Validation loss: 2.185218193197763

Epoch: 5| Step: 10
Training loss: 2.369859218597412
Validation loss: 2.1841028736483667

Epoch: 381| Step: 0
Training loss: 2.323638439178467
Validation loss: 2.1660507802040345

Epoch: 5| Step: 1
Training loss: 2.1664986610412598
Validation loss: 2.1426549111643145

Epoch: 5| Step: 2
Training loss: 2.4647669792175293
Validation loss: 2.1375844786244054

Epoch: 5| Step: 3
Training loss: 1.869362235069275
Validation loss: 2.146462760945802

Epoch: 5| Step: 4
Training loss: 2.6898388862609863
Validation loss: 2.136259078979492

Epoch: 5| Step: 5
Training loss: 2.174237012863159
Validation loss: 2.127693565942908

Epoch: 5| Step: 6
Training loss: 2.2051918506622314
Validation loss: 2.117185313214538

Epoch: 5| Step: 7
Training loss: 2.4874141216278076
Validation loss: 2.11995288120803

Epoch: 5| Step: 8
Training loss: 1.7182817459106445
Validation loss: 2.1359439024361233

Epoch: 5| Step: 9
Training loss: 2.0698599815368652
Validation loss: 2.1305296010868524

Epoch: 5| Step: 10
Training loss: 1.8290023803710938
Validation loss: 2.15892098411437

Epoch: 382| Step: 0
Training loss: 2.368985891342163
Validation loss: 2.1803066474135204

Epoch: 5| Step: 1
Training loss: 1.9701032638549805
Validation loss: 2.185005205933766

Epoch: 5| Step: 2
Training loss: 2.302098512649536
Validation loss: 2.1978591693344938

Epoch: 5| Step: 3
Training loss: 1.943556785583496
Validation loss: 2.1588965462100123

Epoch: 5| Step: 4
Training loss: 2.527686834335327
Validation loss: 2.141935956093573

Epoch: 5| Step: 5
Training loss: 1.9360342025756836
Validation loss: 2.142209686258788

Epoch: 5| Step: 6
Training loss: 3.0053067207336426
Validation loss: 2.140013402508151

Epoch: 5| Step: 7
Training loss: 1.7628517150878906
Validation loss: 2.147070365567361

Epoch: 5| Step: 8
Training loss: 2.3316714763641357
Validation loss: 2.146615589818647

Epoch: 5| Step: 9
Training loss: 1.8447978496551514
Validation loss: 2.1439303980078748

Epoch: 5| Step: 10
Training loss: 2.085263252258301
Validation loss: 2.1396616453765542

Epoch: 383| Step: 0
Training loss: 1.3371837139129639
Validation loss: 2.132679493196549

Epoch: 5| Step: 1
Training loss: 2.491509199142456
Validation loss: 2.1189321317980365

Epoch: 5| Step: 2
Training loss: 2.6708621978759766
Validation loss: 2.1183205061061408

Epoch: 5| Step: 3
Training loss: 2.6731438636779785
Validation loss: 2.119747701511588

Epoch: 5| Step: 4
Training loss: 1.4308267831802368
Validation loss: 2.137369325084071

Epoch: 5| Step: 5
Training loss: 1.5361335277557373
Validation loss: 2.1464997158255628

Epoch: 5| Step: 6
Training loss: 2.049884796142578
Validation loss: 2.1663303862335863

Epoch: 5| Step: 7
Training loss: 2.575065851211548
Validation loss: 2.1974917868132233

Epoch: 5| Step: 8
Training loss: 2.676032781600952
Validation loss: 2.2321312555702786

Epoch: 5| Step: 9
Training loss: 2.7506935596466064
Validation loss: 2.207866093163849

Epoch: 5| Step: 10
Training loss: 2.0371487140655518
Validation loss: 2.1939437081736903

Epoch: 384| Step: 0
Training loss: 1.604520559310913
Validation loss: 2.152917438937772

Epoch: 5| Step: 1
Training loss: 1.8790935277938843
Validation loss: 2.1374114995361655

Epoch: 5| Step: 2
Training loss: 2.3669979572296143
Validation loss: 2.1117316894633795

Epoch: 5| Step: 3
Training loss: 1.8920924663543701
Validation loss: 2.110018507126839

Epoch: 5| Step: 4
Training loss: 2.169481039047241
Validation loss: 2.109381425765253

Epoch: 5| Step: 5
Training loss: 2.2331435680389404
Validation loss: 2.1313385014892905

Epoch: 5| Step: 6
Training loss: 2.229395627975464
Validation loss: 2.112022904939549

Epoch: 5| Step: 7
Training loss: 2.398890972137451
Validation loss: 2.106888671075144

Epoch: 5| Step: 8
Training loss: 2.7929134368896484
Validation loss: 2.11435357985958

Epoch: 5| Step: 9
Training loss: 2.047071933746338
Validation loss: 2.112151922718171

Epoch: 5| Step: 10
Training loss: 2.664094924926758
Validation loss: 2.133108849166542

Epoch: 385| Step: 0
Training loss: 1.9165709018707275
Validation loss: 2.145642565142724

Epoch: 5| Step: 1
Training loss: 2.5574612617492676
Validation loss: 2.1412862629018803

Epoch: 5| Step: 2
Training loss: 2.213587999343872
Validation loss: 2.139348978637367

Epoch: 5| Step: 3
Training loss: 1.9432979822158813
Validation loss: 2.140620453383333

Epoch: 5| Step: 4
Training loss: 2.013803243637085
Validation loss: 2.1590928364825506

Epoch: 5| Step: 5
Training loss: 2.1043591499328613
Validation loss: 2.15224313992326

Epoch: 5| Step: 6
Training loss: 2.5403780937194824
Validation loss: 2.161390189201601

Epoch: 5| Step: 7
Training loss: 2.648145914077759
Validation loss: 2.172754144155851

Epoch: 5| Step: 8
Training loss: 2.3101582527160645
Validation loss: 2.1724667536315097

Epoch: 5| Step: 9
Training loss: 1.2169207334518433
Validation loss: 2.1506155972839682

Epoch: 5| Step: 10
Training loss: 2.3050971031188965
Validation loss: 2.161425075223369

Epoch: 386| Step: 0
Training loss: 1.9930131435394287
Validation loss: 2.1428003695703324

Epoch: 5| Step: 1
Training loss: 1.9234920740127563
Validation loss: 2.132631996626495

Epoch: 5| Step: 2
Training loss: 2.507896900177002
Validation loss: 2.142867422872974

Epoch: 5| Step: 3
Training loss: 2.674436569213867
Validation loss: 2.139498056903962

Epoch: 5| Step: 4
Training loss: 2.7889041900634766
Validation loss: 2.130588904503853

Epoch: 5| Step: 5
Training loss: 2.3230960369110107
Validation loss: 2.113175594678489

Epoch: 5| Step: 6
Training loss: 1.9439083337783813
Validation loss: 2.1121447214516262

Epoch: 5| Step: 7
Training loss: 1.7681982517242432
Validation loss: 2.1207418928864183

Epoch: 5| Step: 8
Training loss: 2.44620943069458
Validation loss: 2.1091142572382444

Epoch: 5| Step: 9
Training loss: 1.8061786890029907
Validation loss: 2.115597233977369

Epoch: 5| Step: 10
Training loss: 1.7701643705368042
Validation loss: 2.132663405069741

Epoch: 387| Step: 0
Training loss: 2.0894131660461426
Validation loss: 2.1191426451488207

Epoch: 5| Step: 1
Training loss: 2.4382028579711914
Validation loss: 2.1253214869447934

Epoch: 5| Step: 2
Training loss: 2.102973461151123
Validation loss: 2.1386471717588362

Epoch: 5| Step: 3
Training loss: 2.0168073177337646
Validation loss: 2.172427720921014

Epoch: 5| Step: 4
Training loss: 2.5167365074157715
Validation loss: 2.17443000629384

Epoch: 5| Step: 5
Training loss: 3.03564715385437
Validation loss: 2.172790414543562

Epoch: 5| Step: 6
Training loss: 1.9840164184570312
Validation loss: 2.185744772675217

Epoch: 5| Step: 7
Training loss: 2.49491810798645
Validation loss: 2.162933564955188

Epoch: 5| Step: 8
Training loss: 1.3054124116897583
Validation loss: 2.147165670189806

Epoch: 5| Step: 9
Training loss: 1.6118299961090088
Validation loss: 2.1040959909398067

Epoch: 5| Step: 10
Training loss: 2.5127811431884766
Validation loss: 2.1052205165227256

Epoch: 388| Step: 0
Training loss: 1.910291314125061
Validation loss: 2.106201171875

Epoch: 5| Step: 1
Training loss: 1.4936583042144775
Validation loss: 2.1106931240327897

Epoch: 5| Step: 2
Training loss: 2.457937002182007
Validation loss: 2.1212629733547086

Epoch: 5| Step: 3
Training loss: 2.3153953552246094
Validation loss: 2.120780044986356

Epoch: 5| Step: 4
Training loss: 2.0253021717071533
Validation loss: 2.1372950999967513

Epoch: 5| Step: 5
Training loss: 2.376652479171753
Validation loss: 2.1599111505734023

Epoch: 5| Step: 6
Training loss: 1.9889453649520874
Validation loss: 2.1724363424444713

Epoch: 5| Step: 7
Training loss: 2.520155429840088
Validation loss: 2.161691270848756

Epoch: 5| Step: 8
Training loss: 2.3624417781829834
Validation loss: 2.1748762335828555

Epoch: 5| Step: 9
Training loss: 1.718238115310669
Validation loss: 2.161128964475406

Epoch: 5| Step: 10
Training loss: 2.943303108215332
Validation loss: 2.1702980226086033

Epoch: 389| Step: 0
Training loss: 2.225259304046631
Validation loss: 2.128169339190247

Epoch: 5| Step: 1
Training loss: 2.406790018081665
Validation loss: 2.124044164534538

Epoch: 5| Step: 2
Training loss: 2.3999838829040527
Validation loss: 2.120203674480479

Epoch: 5| Step: 3
Training loss: 2.050030469894409
Validation loss: 2.095687412446545

Epoch: 5| Step: 4
Training loss: 1.9348194599151611
Validation loss: 2.119182591797203

Epoch: 5| Step: 5
Training loss: 2.7928075790405273
Validation loss: 2.1079928362241356

Epoch: 5| Step: 6
Training loss: 1.8317954540252686
Validation loss: 2.0963889757792153

Epoch: 5| Step: 7
Training loss: 1.9550888538360596
Validation loss: 2.1110130843295845

Epoch: 5| Step: 8
Training loss: 2.156383514404297
Validation loss: 2.0911633660716396

Epoch: 5| Step: 9
Training loss: 1.6989589929580688
Validation loss: 2.0972105585118777

Epoch: 5| Step: 10
Training loss: 2.7000861167907715
Validation loss: 2.1180521993226904

Epoch: 390| Step: 0
Training loss: 2.5605998039245605
Validation loss: 2.1286871997258996

Epoch: 5| Step: 1
Training loss: 2.530224323272705
Validation loss: 2.11496187410047

Epoch: 5| Step: 2
Training loss: 2.1579887866973877
Validation loss: 2.1375562862683366

Epoch: 5| Step: 3
Training loss: 2.295846939086914
Validation loss: 2.14683836121713

Epoch: 5| Step: 4
Training loss: 1.8598419427871704
Validation loss: 2.144449859537104

Epoch: 5| Step: 5
Training loss: 2.4115042686462402
Validation loss: 2.1439290751693068

Epoch: 5| Step: 6
Training loss: 1.885413408279419
Validation loss: 2.155713999143211

Epoch: 5| Step: 7
Training loss: 2.4896862506866455
Validation loss: 2.138637979825338

Epoch: 5| Step: 8
Training loss: 1.9435036182403564
Validation loss: 2.1410204184952604

Epoch: 5| Step: 9
Training loss: 1.965612769126892
Validation loss: 2.12966263422402

Epoch: 5| Step: 10
Training loss: 1.5363574028015137
Validation loss: 2.137493871873425

Epoch: 391| Step: 0
Training loss: 2.178328037261963
Validation loss: 2.1281184381054294

Epoch: 5| Step: 1
Training loss: 2.4010720252990723
Validation loss: 2.102305858365951

Epoch: 5| Step: 2
Training loss: 2.236570358276367
Validation loss: 2.1294429507306827

Epoch: 5| Step: 3
Training loss: 1.7132517099380493
Validation loss: 2.111945995720484

Epoch: 5| Step: 4
Training loss: 2.283883571624756
Validation loss: 2.127151361075781

Epoch: 5| Step: 5
Training loss: 2.7394049167633057
Validation loss: 2.1315458025983585

Epoch: 5| Step: 6
Training loss: 2.4164986610412598
Validation loss: 2.1390480251722437

Epoch: 5| Step: 7
Training loss: 2.3013851642608643
Validation loss: 2.139087701356539

Epoch: 5| Step: 8
Training loss: 1.8089542388916016
Validation loss: 2.1608277328552736

Epoch: 5| Step: 9
Training loss: 1.5897009372711182
Validation loss: 2.1466199736441336

Epoch: 5| Step: 10
Training loss: 2.0345566272735596
Validation loss: 2.1449580500202794

Epoch: 392| Step: 0
Training loss: 2.1982903480529785
Validation loss: 2.1364382723326325

Epoch: 5| Step: 1
Training loss: 1.955338478088379
Validation loss: 2.1492895182742866

Epoch: 5| Step: 2
Training loss: 1.8872661590576172
Validation loss: 2.150475517396004

Epoch: 5| Step: 3
Training loss: 2.4264042377471924
Validation loss: 2.135008647877683

Epoch: 5| Step: 4
Training loss: 1.740726113319397
Validation loss: 2.132262518329005

Epoch: 5| Step: 5
Training loss: 2.029460906982422
Validation loss: 2.123856506040019

Epoch: 5| Step: 6
Training loss: 2.2117178440093994
Validation loss: 2.1228780490095898

Epoch: 5| Step: 7
Training loss: 2.6978046894073486
Validation loss: 2.107618908728323

Epoch: 5| Step: 8
Training loss: 1.6950172185897827
Validation loss: 2.1254810543470484

Epoch: 5| Step: 9
Training loss: 2.465022087097168
Validation loss: 2.1203067661613546

Epoch: 5| Step: 10
Training loss: 2.451120615005493
Validation loss: 2.1107779343922934

Epoch: 393| Step: 0
Training loss: 2.3520610332489014
Validation loss: 2.127081307031775

Epoch: 5| Step: 1
Training loss: 1.8870691061019897
Validation loss: 2.108550052489004

Epoch: 5| Step: 2
Training loss: 2.0723462104797363
Validation loss: 2.1115360708646875

Epoch: 5| Step: 3
Training loss: 2.70520281791687
Validation loss: 2.115307718194941

Epoch: 5| Step: 4
Training loss: 1.874839425086975
Validation loss: 2.1217354779602378

Epoch: 5| Step: 5
Training loss: 1.7745780944824219
Validation loss: 2.1186924172985937

Epoch: 5| Step: 6
Training loss: 2.7418389320373535
Validation loss: 2.1386071430739535

Epoch: 5| Step: 7
Training loss: 1.8694581985473633
Validation loss: 2.1265113687002533

Epoch: 5| Step: 8
Training loss: 1.8331607580184937
Validation loss: 2.1337257867218344

Epoch: 5| Step: 9
Training loss: 2.015145778656006
Validation loss: 2.1359364704419206

Epoch: 5| Step: 10
Training loss: 2.842883586883545
Validation loss: 2.1337965970398276

Epoch: 394| Step: 0
Training loss: 1.8347375392913818
Validation loss: 2.136907726205805

Epoch: 5| Step: 1
Training loss: 3.060237169265747
Validation loss: 2.1602933893921556

Epoch: 5| Step: 2
Training loss: 2.088820219039917
Validation loss: 2.152006374892368

Epoch: 5| Step: 3
Training loss: 2.5031018257141113
Validation loss: 2.1272570266518542

Epoch: 5| Step: 4
Training loss: 1.8250499963760376
Validation loss: 2.1065728459306943

Epoch: 5| Step: 5
Training loss: 1.6736834049224854
Validation loss: 2.1247245175864107

Epoch: 5| Step: 6
Training loss: 1.8650928735733032
Validation loss: 2.1100505680166264

Epoch: 5| Step: 7
Training loss: 2.2834725379943848
Validation loss: 2.1280202570781914

Epoch: 5| Step: 8
Training loss: 2.1142563819885254
Validation loss: 2.1347288700842086

Epoch: 5| Step: 9
Training loss: 2.3888814449310303
Validation loss: 2.1404989457899526

Epoch: 5| Step: 10
Training loss: 2.1925182342529297
Validation loss: 2.144157394286125

Epoch: 395| Step: 0
Training loss: 2.116507053375244
Validation loss: 2.124724652177544

Epoch: 5| Step: 1
Training loss: 1.9879944324493408
Validation loss: 2.116802453994751

Epoch: 5| Step: 2
Training loss: 2.464834690093994
Validation loss: 2.097020342785825

Epoch: 5| Step: 3
Training loss: 1.9044691324234009
Validation loss: 2.104768016005075

Epoch: 5| Step: 4
Training loss: 2.1351981163024902
Validation loss: 2.093574516234859

Epoch: 5| Step: 5
Training loss: 1.6429640054702759
Validation loss: 2.10189236364057

Epoch: 5| Step: 6
Training loss: 2.017540216445923
Validation loss: 2.09193245826229

Epoch: 5| Step: 7
Training loss: 2.792273759841919
Validation loss: 2.126899383401358

Epoch: 5| Step: 8
Training loss: 1.9828506708145142
Validation loss: 2.1174758608623216

Epoch: 5| Step: 9
Training loss: 2.396933078765869
Validation loss: 2.133939384132303

Epoch: 5| Step: 10
Training loss: 2.40472674369812
Validation loss: 2.1409367771558863

Epoch: 396| Step: 0
Training loss: 1.6281236410140991
Validation loss: 2.1468637592049054

Epoch: 5| Step: 1
Training loss: 1.9051424264907837
Validation loss: 2.139620882208629

Epoch: 5| Step: 2
Training loss: 2.0978569984436035
Validation loss: 2.1483207389872563

Epoch: 5| Step: 3
Training loss: 2.1660969257354736
Validation loss: 2.1522441294885453

Epoch: 5| Step: 4
Training loss: 2.7622456550598145
Validation loss: 2.145087367744856

Epoch: 5| Step: 5
Training loss: 2.00846791267395
Validation loss: 2.1384042334812943

Epoch: 5| Step: 6
Training loss: 2.365777015686035
Validation loss: 2.1222581965948946

Epoch: 5| Step: 7
Training loss: 2.0951082706451416
Validation loss: 2.1209772863695697

Epoch: 5| Step: 8
Training loss: 2.8075664043426514
Validation loss: 2.115661367293327

Epoch: 5| Step: 9
Training loss: 1.7598483562469482
Validation loss: 2.107352861794092

Epoch: 5| Step: 10
Training loss: 1.9804236888885498
Validation loss: 2.106913294843448

Epoch: 397| Step: 0
Training loss: 2.0524330139160156
Validation loss: 2.092409372329712

Epoch: 5| Step: 1
Training loss: 2.349581241607666
Validation loss: 2.095022047719648

Epoch: 5| Step: 2
Training loss: 1.8057790994644165
Validation loss: 2.100834209431884

Epoch: 5| Step: 3
Training loss: 1.9911797046661377
Validation loss: 2.104517323996431

Epoch: 5| Step: 4
Training loss: 1.7542250156402588
Validation loss: 2.116026334865119

Epoch: 5| Step: 5
Training loss: 1.6031970977783203
Validation loss: 2.099222062736429

Epoch: 5| Step: 6
Training loss: 1.9469531774520874
Validation loss: 2.125252516038956

Epoch: 5| Step: 7
Training loss: 2.7227656841278076
Validation loss: 2.119940896188059

Epoch: 5| Step: 8
Training loss: 2.6860110759735107
Validation loss: 2.121905308897777

Epoch: 5| Step: 9
Training loss: 2.0757365226745605
Validation loss: 2.12039715115742

Epoch: 5| Step: 10
Training loss: 2.5487098693847656
Validation loss: 2.132223754800776

Epoch: 398| Step: 0
Training loss: 1.5587892532348633
Validation loss: 2.134489643958307

Epoch: 5| Step: 1
Training loss: 2.1015868186950684
Validation loss: 2.1214308443889824

Epoch: 5| Step: 2
Training loss: 2.833334445953369
Validation loss: 2.1174217193357405

Epoch: 5| Step: 3
Training loss: 2.1977360248565674
Validation loss: 2.1348071546964746

Epoch: 5| Step: 4
Training loss: 1.9270985126495361
Validation loss: 2.110154685153756

Epoch: 5| Step: 5
Training loss: 1.9607486724853516
Validation loss: 2.1050663148203204

Epoch: 5| Step: 6
Training loss: 1.9141333103179932
Validation loss: 2.1192927347716464

Epoch: 5| Step: 7
Training loss: 2.3153223991394043
Validation loss: 2.119959477455385

Epoch: 5| Step: 8
Training loss: 2.3936057090759277
Validation loss: 2.121884929236545

Epoch: 5| Step: 9
Training loss: 2.199065685272217
Validation loss: 2.1130085017091487

Epoch: 5| Step: 10
Training loss: 2.106644868850708
Validation loss: 2.1200617590258197

Epoch: 399| Step: 0
Training loss: 1.6901662349700928
Validation loss: 2.134197481216923

Epoch: 5| Step: 1
Training loss: 2.3351073265075684
Validation loss: 2.154270631010814

Epoch: 5| Step: 2
Training loss: 2.6866261959075928
Validation loss: 2.1472515316419702

Epoch: 5| Step: 3
Training loss: 2.601500988006592
Validation loss: 2.133679252798839

Epoch: 5| Step: 4
Training loss: 2.046395778656006
Validation loss: 2.113960540422829

Epoch: 5| Step: 5
Training loss: 2.36407208442688
Validation loss: 2.1135068555032053

Epoch: 5| Step: 6
Training loss: 2.1043128967285156
Validation loss: 2.109070885565973

Epoch: 5| Step: 7
Training loss: 2.0797743797302246
Validation loss: 2.091463121034766

Epoch: 5| Step: 8
Training loss: 2.2221789360046387
Validation loss: 2.097486478026195

Epoch: 5| Step: 9
Training loss: 1.7361987829208374
Validation loss: 2.096641534118242

Epoch: 5| Step: 10
Training loss: 1.7710436582565308
Validation loss: 2.098469006117954

Epoch: 400| Step: 0
Training loss: 2.2483010292053223
Validation loss: 2.121361470991565

Epoch: 5| Step: 1
Training loss: 1.8225898742675781
Validation loss: 2.1052238710464968

Epoch: 5| Step: 2
Training loss: 2.069262742996216
Validation loss: 2.144916977933658

Epoch: 5| Step: 3
Training loss: 2.113004207611084
Validation loss: 2.1607757537595687

Epoch: 5| Step: 4
Training loss: 1.4876797199249268
Validation loss: 2.1825056306777464

Epoch: 5| Step: 5
Training loss: 1.826501488685608
Validation loss: 2.178985300884452

Epoch: 5| Step: 6
Training loss: 2.7694103717803955
Validation loss: 2.1736383771383636

Epoch: 5| Step: 7
Training loss: 2.2084736824035645
Validation loss: 2.1489484874151086

Epoch: 5| Step: 8
Training loss: 2.1532540321350098
Validation loss: 2.1534416060293875

Epoch: 5| Step: 9
Training loss: 2.653202772140503
Validation loss: 2.1391579233190066

Epoch: 5| Step: 10
Training loss: 2.19338321685791
Validation loss: 2.1362193528042046

Epoch: 401| Step: 0
Training loss: 2.6873722076416016
Validation loss: 2.1271869879896923

Epoch: 5| Step: 1
Training loss: 1.7602707147598267
Validation loss: 2.126245765275853

Epoch: 5| Step: 2
Training loss: 2.2149178981781006
Validation loss: 2.1168729066848755

Epoch: 5| Step: 3
Training loss: 2.6888890266418457
Validation loss: 2.0957282179145404

Epoch: 5| Step: 4
Training loss: 2.0859434604644775
Validation loss: 2.0988701620409564

Epoch: 5| Step: 5
Training loss: 2.3840043544769287
Validation loss: 2.098654444499682

Epoch: 5| Step: 6
Training loss: 2.2382984161376953
Validation loss: 2.0949014591914352

Epoch: 5| Step: 7
Training loss: 1.845126748085022
Validation loss: 2.12670809735534

Epoch: 5| Step: 8
Training loss: 2.027425765991211
Validation loss: 2.128482569930374

Epoch: 5| Step: 9
Training loss: 2.4526679515838623
Validation loss: 2.1473238903989076

Epoch: 5| Step: 10
Training loss: 0.8955053091049194
Validation loss: 2.1511546360549105

Epoch: 402| Step: 0
Training loss: 2.4902288913726807
Validation loss: 2.130921358703285

Epoch: 5| Step: 1
Training loss: 2.0168426036834717
Validation loss: 2.1200228814155824

Epoch: 5| Step: 2
Training loss: 2.5644583702087402
Validation loss: 2.110049941206491

Epoch: 5| Step: 3
Training loss: 1.7442134618759155
Validation loss: 2.1004560147562334

Epoch: 5| Step: 4
Training loss: 2.2805111408233643
Validation loss: 2.1082543506417224

Epoch: 5| Step: 5
Training loss: 2.387415647506714
Validation loss: 2.0954970390565935

Epoch: 5| Step: 6
Training loss: 2.006617307662964
Validation loss: 2.1002460987337175

Epoch: 5| Step: 7
Training loss: 1.6628481149673462
Validation loss: 2.094116981311511

Epoch: 5| Step: 8
Training loss: 2.0771305561065674
Validation loss: 2.092644355630362

Epoch: 5| Step: 9
Training loss: 1.649652123451233
Validation loss: 2.109070395910612

Epoch: 5| Step: 10
Training loss: 2.7585387229919434
Validation loss: 2.1208717976847002

Epoch: 403| Step: 0
Training loss: 1.409119963645935
Validation loss: 2.107746926687097

Epoch: 5| Step: 1
Training loss: 2.6344869136810303
Validation loss: 2.1086923153169694

Epoch: 5| Step: 2
Training loss: 1.7916443347930908
Validation loss: 2.1206932426780782

Epoch: 5| Step: 3
Training loss: 2.267775774002075
Validation loss: 2.094276464113625

Epoch: 5| Step: 4
Training loss: 2.033447265625
Validation loss: 2.1000702752861926

Epoch: 5| Step: 5
Training loss: 1.9491904973983765
Validation loss: 2.09176488461033

Epoch: 5| Step: 6
Training loss: 2.2317123413085938
Validation loss: 2.0903730302728634

Epoch: 5| Step: 7
Training loss: 2.481748580932617
Validation loss: 2.0813577918596167

Epoch: 5| Step: 8
Training loss: 2.0587735176086426
Validation loss: 2.093009982057797

Epoch: 5| Step: 9
Training loss: 2.4476261138916016
Validation loss: 2.0885517135743172

Epoch: 5| Step: 10
Training loss: 2.102513074874878
Validation loss: 2.101044606137019

Epoch: 404| Step: 0
Training loss: 1.734808325767517
Validation loss: 2.0996298495159356

Epoch: 5| Step: 1
Training loss: 1.9603111743927002
Validation loss: 2.1117035829892723

Epoch: 5| Step: 2
Training loss: 2.3492817878723145
Validation loss: 2.1146765075704104

Epoch: 5| Step: 3
Training loss: 2.4962377548217773
Validation loss: 2.0960233262790147

Epoch: 5| Step: 4
Training loss: 1.6692724227905273
Validation loss: 2.1200168671146518

Epoch: 5| Step: 5
Training loss: 2.2158544063568115
Validation loss: 2.098674112750638

Epoch: 5| Step: 6
Training loss: 2.5082268714904785
Validation loss: 2.1083181737571635

Epoch: 5| Step: 7
Training loss: 2.1146044731140137
Validation loss: 2.1042014873155983

Epoch: 5| Step: 8
Training loss: 2.508103847503662
Validation loss: 2.136141020764587

Epoch: 5| Step: 9
Training loss: 1.7351289987564087
Validation loss: 2.1375825507666475

Epoch: 5| Step: 10
Training loss: 2.203474760055542
Validation loss: 2.1155367641038794

Epoch: 405| Step: 0
Training loss: 2.2470948696136475
Validation loss: 2.10984214146932

Epoch: 5| Step: 1
Training loss: 1.9301542043685913
Validation loss: 2.096854937973843

Epoch: 5| Step: 2
Training loss: 2.4297666549682617
Validation loss: 2.109738189687011

Epoch: 5| Step: 3
Training loss: 1.6675666570663452
Validation loss: 2.0992285743836434

Epoch: 5| Step: 4
Training loss: 2.5104377269744873
Validation loss: 2.082338507457446

Epoch: 5| Step: 5
Training loss: 2.489468812942505
Validation loss: 2.1126339115122312

Epoch: 5| Step: 6
Training loss: 1.7696382999420166
Validation loss: 2.0994387813793716

Epoch: 5| Step: 7
Training loss: 2.005021095275879
Validation loss: 2.109198321578323

Epoch: 5| Step: 8
Training loss: 2.014786720275879
Validation loss: 2.1031919474242837

Epoch: 5| Step: 9
Training loss: 2.6353347301483154
Validation loss: 2.111754854520162

Epoch: 5| Step: 10
Training loss: 1.515320897102356
Validation loss: 2.1177004357819915

Epoch: 406| Step: 0
Training loss: 1.8539930582046509
Validation loss: 2.1259479676523516

Epoch: 5| Step: 1
Training loss: 2.2781338691711426
Validation loss: 2.117017540880429

Epoch: 5| Step: 2
Training loss: 2.5131614208221436
Validation loss: 2.1198897220755137

Epoch: 5| Step: 3
Training loss: 1.7650960683822632
Validation loss: 2.111141244570414

Epoch: 5| Step: 4
Training loss: 2.2158541679382324
Validation loss: 2.100097958759595

Epoch: 5| Step: 5
Training loss: 2.195678472518921
Validation loss: 2.098514659430391

Epoch: 5| Step: 6
Training loss: 1.7838882207870483
Validation loss: 2.1120159818280126

Epoch: 5| Step: 7
Training loss: 2.4257709980010986
Validation loss: 2.091878710254546

Epoch: 5| Step: 8
Training loss: 2.178280830383301
Validation loss: 2.0931789029029106

Epoch: 5| Step: 9
Training loss: 2.5054800510406494
Validation loss: 2.0928864761065413

Epoch: 5| Step: 10
Training loss: 1.5700311660766602
Validation loss: 2.0956072704766386

Epoch: 407| Step: 0
Training loss: 1.5977344512939453
Validation loss: 2.0885000498064104

Epoch: 5| Step: 1
Training loss: 2.059217929840088
Validation loss: 2.0783846327053603

Epoch: 5| Step: 2
Training loss: 2.3134846687316895
Validation loss: 2.0927562944350706

Epoch: 5| Step: 3
Training loss: 2.441027879714966
Validation loss: 2.088026228771415

Epoch: 5| Step: 4
Training loss: 1.641300916671753
Validation loss: 2.1019946939201763

Epoch: 5| Step: 5
Training loss: 1.9446007013320923
Validation loss: 2.1351494750668927

Epoch: 5| Step: 6
Training loss: 1.9087320566177368
Validation loss: 2.112274167358234

Epoch: 5| Step: 7
Training loss: 2.1335625648498535
Validation loss: 2.1238050396724413

Epoch: 5| Step: 8
Training loss: 2.511484146118164
Validation loss: 2.119511050562705

Epoch: 5| Step: 9
Training loss: 1.718792200088501
Validation loss: 2.1166789300980104

Epoch: 5| Step: 10
Training loss: 3.2967607975006104
Validation loss: 2.105411562868344

Epoch: 408| Step: 0
Training loss: 2.406691789627075
Validation loss: 2.102929340895786

Epoch: 5| Step: 1
Training loss: 1.503412127494812
Validation loss: 2.10273572193679

Epoch: 5| Step: 2
Training loss: 2.6151223182678223
Validation loss: 2.1078336854134836

Epoch: 5| Step: 3
Training loss: 2.6573503017425537
Validation loss: 2.0994330042151996

Epoch: 5| Step: 4
Training loss: 2.2467875480651855
Validation loss: 2.11298119637274

Epoch: 5| Step: 5
Training loss: 1.971133828163147
Validation loss: 2.0963949631619196

Epoch: 5| Step: 6
Training loss: 2.425093650817871
Validation loss: 2.0937520022033365

Epoch: 5| Step: 7
Training loss: 2.4016621112823486
Validation loss: 2.113456331273561

Epoch: 5| Step: 8
Training loss: 2.364044189453125
Validation loss: 2.1306404849534393

Epoch: 5| Step: 9
Training loss: 1.3306024074554443
Validation loss: 2.1382836090621127

Epoch: 5| Step: 10
Training loss: 1.3440958261489868
Validation loss: 2.131480529744138

Epoch: 409| Step: 0
Training loss: 2.375242233276367
Validation loss: 2.153590558677591

Epoch: 5| Step: 1
Training loss: 1.4355604648590088
Validation loss: 2.133735177337482

Epoch: 5| Step: 2
Training loss: 2.5498764514923096
Validation loss: 2.11135737229419

Epoch: 5| Step: 3
Training loss: 2.8052210807800293
Validation loss: 2.1158763952152704

Epoch: 5| Step: 4
Training loss: 2.6630241870880127
Validation loss: 2.096876096981828

Epoch: 5| Step: 5
Training loss: 1.4308404922485352
Validation loss: 2.0855865709243284

Epoch: 5| Step: 6
Training loss: 1.576061487197876
Validation loss: 2.0693913147013676

Epoch: 5| Step: 7
Training loss: 2.252976655960083
Validation loss: 2.0862274375013126

Epoch: 5| Step: 8
Training loss: 1.852994680404663
Validation loss: 2.0825643116428005

Epoch: 5| Step: 9
Training loss: 2.53786563873291
Validation loss: 2.099539723447574

Epoch: 5| Step: 10
Training loss: 1.8832507133483887
Validation loss: 2.072096570845573

Epoch: 410| Step: 0
Training loss: 2.334289789199829
Validation loss: 2.0990866666199057

Epoch: 5| Step: 1
Training loss: 2.4065122604370117
Validation loss: 2.0895286478022093

Epoch: 5| Step: 2
Training loss: 2.2288172245025635
Validation loss: 2.1016170029999106

Epoch: 5| Step: 3
Training loss: 2.7047698497772217
Validation loss: 2.113048215066233

Epoch: 5| Step: 4
Training loss: 1.5750662088394165
Validation loss: 2.133619854527135

Epoch: 5| Step: 5
Training loss: 2.34989333152771
Validation loss: 2.131065099470077

Epoch: 5| Step: 6
Training loss: 1.5840728282928467
Validation loss: 2.1319415902578704

Epoch: 5| Step: 7
Training loss: 2.2166905403137207
Validation loss: 2.1386302055851107

Epoch: 5| Step: 8
Training loss: 1.806758165359497
Validation loss: 2.1157504320144653

Epoch: 5| Step: 9
Training loss: 2.1551380157470703
Validation loss: 2.0968778774302494

Epoch: 5| Step: 10
Training loss: 2.0734941959381104
Validation loss: 2.0875421954739477

Epoch: 411| Step: 0
Training loss: 2.4424452781677246
Validation loss: 2.087915846096572

Epoch: 5| Step: 1
Training loss: 2.170362949371338
Validation loss: 2.087723416666831

Epoch: 5| Step: 2
Training loss: 2.1520984172821045
Validation loss: 2.1079821650699904

Epoch: 5| Step: 3
Training loss: 2.73091983795166
Validation loss: 2.104163982534921

Epoch: 5| Step: 4
Training loss: 1.2497169971466064
Validation loss: 2.102533648090978

Epoch: 5| Step: 5
Training loss: 1.7142846584320068
Validation loss: 2.1095688189229658

Epoch: 5| Step: 6
Training loss: 2.0411181449890137
Validation loss: 2.1179610426707933

Epoch: 5| Step: 7
Training loss: 2.5290675163269043
Validation loss: 2.118309238905548

Epoch: 5| Step: 8
Training loss: 1.678145408630371
Validation loss: 2.1079320843501756

Epoch: 5| Step: 9
Training loss: 2.0278782844543457
Validation loss: 2.1337061889709963

Epoch: 5| Step: 10
Training loss: 2.555163860321045
Validation loss: 2.114651526174238

Epoch: 412| Step: 0
Training loss: 2.8350162506103516
Validation loss: 2.1293224903845016

Epoch: 5| Step: 1
Training loss: 2.550058364868164
Validation loss: 2.137546508542953

Epoch: 5| Step: 2
Training loss: 2.8649749755859375
Validation loss: 2.1439274152119956

Epoch: 5| Step: 3
Training loss: 2.3833837509155273
Validation loss: 2.1286696669875935

Epoch: 5| Step: 4
Training loss: 1.923499345779419
Validation loss: 2.081766169558289

Epoch: 5| Step: 5
Training loss: 1.9211180210113525
Validation loss: 2.0855023578930925

Epoch: 5| Step: 6
Training loss: 1.1050822734832764
Validation loss: 2.0828694989604335

Epoch: 5| Step: 7
Training loss: 2.291301965713501
Validation loss: 2.0840891253563667

Epoch: 5| Step: 8
Training loss: 1.8469051122665405
Validation loss: 2.0824665869435957

Epoch: 5| Step: 9
Training loss: 1.7575252056121826
Validation loss: 2.0903431318139516

Epoch: 5| Step: 10
Training loss: 1.869372010231018
Validation loss: 2.0819847224861063

Epoch: 413| Step: 0
Training loss: 2.2444119453430176
Validation loss: 2.081165917458073

Epoch: 5| Step: 1
Training loss: 1.9940941333770752
Validation loss: 2.105412108923799

Epoch: 5| Step: 2
Training loss: 1.0137758255004883
Validation loss: 2.1207468086673367

Epoch: 5| Step: 3
Training loss: 1.8402950763702393
Validation loss: 2.102087718184276

Epoch: 5| Step: 4
Training loss: 1.9142751693725586
Validation loss: 2.1093236733508367

Epoch: 5| Step: 5
Training loss: 2.497509717941284
Validation loss: 2.1133431388485815

Epoch: 5| Step: 6
Training loss: 1.980851173400879
Validation loss: 2.1393111367379465

Epoch: 5| Step: 7
Training loss: 2.4183709621429443
Validation loss: 2.1468556260549896

Epoch: 5| Step: 8
Training loss: 3.026506185531616
Validation loss: 2.169746788599158

Epoch: 5| Step: 9
Training loss: 2.24299955368042
Validation loss: 2.121872273824548

Epoch: 5| Step: 10
Training loss: 2.329533576965332
Validation loss: 2.106879316350465

Epoch: 414| Step: 0
Training loss: 2.085127830505371
Validation loss: 2.0974034699060584

Epoch: 5| Step: 1
Training loss: 2.400176525115967
Validation loss: 2.049409789423789

Epoch: 5| Step: 2
Training loss: 2.050171375274658
Validation loss: 2.061385703343217

Epoch: 5| Step: 3
Training loss: 2.0531668663024902
Validation loss: 2.0484343626165904

Epoch: 5| Step: 4
Training loss: 1.714928388595581
Validation loss: 2.077403247997325

Epoch: 5| Step: 5
Training loss: 2.082932233810425
Validation loss: 2.0739294816088933

Epoch: 5| Step: 6
Training loss: 2.262115955352783
Validation loss: 2.0801665936746905

Epoch: 5| Step: 7
Training loss: 2.508395195007324
Validation loss: 2.0880638937796316

Epoch: 5| Step: 8
Training loss: 1.2488285303115845
Validation loss: 2.1040324062429447

Epoch: 5| Step: 9
Training loss: 2.6777985095977783
Validation loss: 2.144665923169864

Epoch: 5| Step: 10
Training loss: 2.254258871078491
Validation loss: 2.16305705296096

Epoch: 415| Step: 0
Training loss: 2.4099180698394775
Validation loss: 2.1711467478864934

Epoch: 5| Step: 1
Training loss: 2.231689929962158
Validation loss: 2.1717813194438977

Epoch: 5| Step: 2
Training loss: 2.764122486114502
Validation loss: 2.128074353741061

Epoch: 5| Step: 3
Training loss: 2.072824716567993
Validation loss: 2.1057881411685737

Epoch: 5| Step: 4
Training loss: 2.035618543624878
Validation loss: 2.106599730830039

Epoch: 5| Step: 5
Training loss: 1.7446529865264893
Validation loss: 2.083072200898201

Epoch: 5| Step: 6
Training loss: 1.896202802658081
Validation loss: 2.0679291102194015

Epoch: 5| Step: 7
Training loss: 2.747920274734497
Validation loss: 2.0798089183786863

Epoch: 5| Step: 8
Training loss: 1.4783263206481934
Validation loss: 2.0715927116332518

Epoch: 5| Step: 9
Training loss: 1.7198808193206787
Validation loss: 2.088152293236025

Epoch: 5| Step: 10
Training loss: 2.2673044204711914
Validation loss: 2.0810153420253465

Epoch: 416| Step: 0
Training loss: 1.4584206342697144
Validation loss: 2.092185906184617

Epoch: 5| Step: 1
Training loss: 2.4335567951202393
Validation loss: 2.0779102989422378

Epoch: 5| Step: 2
Training loss: 2.3752682209014893
Validation loss: 2.1059478047073528

Epoch: 5| Step: 3
Training loss: 2.3518452644348145
Validation loss: 2.103721836561798

Epoch: 5| Step: 4
Training loss: 1.584262728691101
Validation loss: 2.128943527898481

Epoch: 5| Step: 5
Training loss: 2.267289638519287
Validation loss: 2.152997983399258

Epoch: 5| Step: 6
Training loss: 1.6995782852172852
Validation loss: 2.170917349476968

Epoch: 5| Step: 7
Training loss: 2.5774447917938232
Validation loss: 2.173141025727795

Epoch: 5| Step: 8
Training loss: 2.087826728820801
Validation loss: 2.167120216995157

Epoch: 5| Step: 9
Training loss: 2.391188859939575
Validation loss: 2.1705287182202904

Epoch: 5| Step: 10
Training loss: 2.2382452487945557
Validation loss: 2.1221265613391833

Epoch: 417| Step: 0
Training loss: 1.715934157371521
Validation loss: 2.0959836744493052

Epoch: 5| Step: 1
Training loss: 2.430190086364746
Validation loss: 2.115632741681991

Epoch: 5| Step: 2
Training loss: 1.9811649322509766
Validation loss: 2.0866590610114475

Epoch: 5| Step: 3
Training loss: 2.502725839614868
Validation loss: 2.0732569540700605

Epoch: 5| Step: 4
Training loss: 2.018209934234619
Validation loss: 2.0683457697591474

Epoch: 5| Step: 5
Training loss: 2.4107413291931152
Validation loss: 2.064313660385788

Epoch: 5| Step: 6
Training loss: 1.8347965478897095
Validation loss: 2.060478889813987

Epoch: 5| Step: 7
Training loss: 2.268397808074951
Validation loss: 2.075662807751727

Epoch: 5| Step: 8
Training loss: 1.5070003271102905
Validation loss: 2.0710879577103483

Epoch: 5| Step: 9
Training loss: 2.2116494178771973
Validation loss: 2.0748220848780807

Epoch: 5| Step: 10
Training loss: 2.383229970932007
Validation loss: 2.0948292273347096

Epoch: 418| Step: 0
Training loss: 1.9654258489608765
Validation loss: 2.0661418412321355

Epoch: 5| Step: 1
Training loss: 2.2718563079833984
Validation loss: 2.0882138308658393

Epoch: 5| Step: 2
Training loss: 1.4653997421264648
Validation loss: 2.094900163271094

Epoch: 5| Step: 3
Training loss: 1.6770696640014648
Validation loss: 2.0987370591009817

Epoch: 5| Step: 4
Training loss: 2.2843339443206787
Validation loss: 2.10010027885437

Epoch: 5| Step: 5
Training loss: 2.668212413787842
Validation loss: 2.108619290013467

Epoch: 5| Step: 6
Training loss: 2.4553980827331543
Validation loss: 2.12185428988549

Epoch: 5| Step: 7
Training loss: 1.9824146032333374
Validation loss: 2.093674188019127

Epoch: 5| Step: 8
Training loss: 2.2859137058258057
Validation loss: 2.0861147296044136

Epoch: 5| Step: 9
Training loss: 1.9059944152832031
Validation loss: 2.0665781139045634

Epoch: 5| Step: 10
Training loss: 2.116553783416748
Validation loss: 2.087547068954796

Epoch: 419| Step: 0
Training loss: 2.390066623687744
Validation loss: 2.100718129065729

Epoch: 5| Step: 1
Training loss: 1.7920773029327393
Validation loss: 2.0997635472205376

Epoch: 5| Step: 2
Training loss: 1.7352735996246338
Validation loss: 2.076336376128658

Epoch: 5| Step: 3
Training loss: 1.8105027675628662
Validation loss: 2.1032329579835296

Epoch: 5| Step: 4
Training loss: 2.1537184715270996
Validation loss: 2.0980568457675237

Epoch: 5| Step: 5
Training loss: 2.063262701034546
Validation loss: 2.119587371426244

Epoch: 5| Step: 6
Training loss: 2.653383255004883
Validation loss: 2.10789789307502

Epoch: 5| Step: 7
Training loss: 2.243022918701172
Validation loss: 2.1025033061222365

Epoch: 5| Step: 8
Training loss: 2.1997218132019043
Validation loss: 2.1100258545209

Epoch: 5| Step: 9
Training loss: 1.8964214324951172
Validation loss: 2.1116323829979025

Epoch: 5| Step: 10
Training loss: 2.1120412349700928
Validation loss: 2.1112156170670704

Epoch: 420| Step: 0
Training loss: 2.527026891708374
Validation loss: 2.118141379407657

Epoch: 5| Step: 1
Training loss: 1.987066626548767
Validation loss: 2.08442061690874

Epoch: 5| Step: 2
Training loss: 2.749269485473633
Validation loss: 2.0779206265685377

Epoch: 5| Step: 3
Training loss: 2.0988121032714844
Validation loss: 2.087350671009351

Epoch: 5| Step: 4
Training loss: 2.16326904296875
Validation loss: 2.0747341673861266

Epoch: 5| Step: 5
Training loss: 1.8695440292358398
Validation loss: 2.08759327601361

Epoch: 5| Step: 6
Training loss: 2.4083614349365234
Validation loss: 2.0709194688386816

Epoch: 5| Step: 7
Training loss: 1.531456708908081
Validation loss: 2.075651445696431

Epoch: 5| Step: 8
Training loss: 2.0288491249084473
Validation loss: 2.091166747513638

Epoch: 5| Step: 9
Training loss: 1.5985009670257568
Validation loss: 2.0940636652772144

Epoch: 5| Step: 10
Training loss: 2.193779468536377
Validation loss: 2.077120095170954

Epoch: 421| Step: 0
Training loss: 2.420449733734131
Validation loss: 2.0878508039700088

Epoch: 5| Step: 1
Training loss: 2.049588441848755
Validation loss: 2.1130742770369335

Epoch: 5| Step: 2
Training loss: 2.0836594104766846
Validation loss: 2.0942784406805552

Epoch: 5| Step: 3
Training loss: 2.729691743850708
Validation loss: 2.0967649413693334

Epoch: 5| Step: 4
Training loss: 2.552196502685547
Validation loss: 2.0837450642739572

Epoch: 5| Step: 5
Training loss: 2.319185972213745
Validation loss: 2.0601798436974965

Epoch: 5| Step: 6
Training loss: 1.7762022018432617
Validation loss: 2.0687622780440957

Epoch: 5| Step: 7
Training loss: 1.8591912984848022
Validation loss: 2.061816928207233

Epoch: 5| Step: 8
Training loss: 1.6048088073730469
Validation loss: 2.0665330540749336

Epoch: 5| Step: 9
Training loss: 1.5748010873794556
Validation loss: 2.0653239488601685

Epoch: 5| Step: 10
Training loss: 2.1559348106384277
Validation loss: 2.075889313092796

Epoch: 422| Step: 0
Training loss: 2.6599106788635254
Validation loss: 2.0915799064020955

Epoch: 5| Step: 1
Training loss: 2.6290993690490723
Validation loss: 2.109816251262542

Epoch: 5| Step: 2
Training loss: 2.7448620796203613
Validation loss: 2.118148337128342

Epoch: 5| Step: 3
Training loss: 1.8503780364990234
Validation loss: 2.1007141541409236

Epoch: 5| Step: 4
Training loss: 1.8890358209609985
Validation loss: 2.1028569001023487

Epoch: 5| Step: 5
Training loss: 1.7190688848495483
Validation loss: 2.0862557606030534

Epoch: 5| Step: 6
Training loss: 1.7254085540771484
Validation loss: 2.093248623673634

Epoch: 5| Step: 7
Training loss: 1.948883295059204
Validation loss: 2.076754991726209

Epoch: 5| Step: 8
Training loss: 2.340301752090454
Validation loss: 2.0783736513506983

Epoch: 5| Step: 9
Training loss: 1.8087965250015259
Validation loss: 2.0694049173785793

Epoch: 5| Step: 10
Training loss: 1.6788634061813354
Validation loss: 2.0757272012772097

Epoch: 423| Step: 0
Training loss: 2.0993669033050537
Validation loss: 2.0795974731445312

Epoch: 5| Step: 1
Training loss: 1.756042718887329
Validation loss: 2.0504458911957277

Epoch: 5| Step: 2
Training loss: 2.4487946033477783
Validation loss: 2.074185607253864

Epoch: 5| Step: 3
Training loss: 1.9071754217147827
Validation loss: 2.0700252568849953

Epoch: 5| Step: 4
Training loss: 2.1064558029174805
Validation loss: 2.0821334174884263

Epoch: 5| Step: 5
Training loss: 1.9098846912384033
Validation loss: 2.097664189595048

Epoch: 5| Step: 6
Training loss: 2.215010404586792
Validation loss: 2.1230749776286464

Epoch: 5| Step: 7
Training loss: 1.8776538372039795
Validation loss: 2.1105448187038465

Epoch: 5| Step: 8
Training loss: 3.002927303314209
Validation loss: 2.13258578572222

Epoch: 5| Step: 9
Training loss: 1.6830322742462158
Validation loss: 2.104347014939913

Epoch: 5| Step: 10
Training loss: 2.16726016998291
Validation loss: 2.095787602086221

Epoch: 424| Step: 0
Training loss: 2.4530041217803955
Validation loss: 2.091865542114422

Epoch: 5| Step: 1
Training loss: 1.6576913595199585
Validation loss: 2.0739388491517756

Epoch: 5| Step: 2
Training loss: 2.3630146980285645
Validation loss: 2.0811409693892284

Epoch: 5| Step: 3
Training loss: 2.005016803741455
Validation loss: 2.090864336618813

Epoch: 5| Step: 4
Training loss: 1.4021170139312744
Validation loss: 2.094097811688659

Epoch: 5| Step: 5
Training loss: 1.7593780755996704
Validation loss: 2.0950794835244455

Epoch: 5| Step: 6
Training loss: 2.466862201690674
Validation loss: 2.0886819003730692

Epoch: 5| Step: 7
Training loss: 2.265798568725586
Validation loss: 2.0913755521979382

Epoch: 5| Step: 8
Training loss: 2.089590549468994
Validation loss: 2.091475327809652

Epoch: 5| Step: 9
Training loss: 2.0831680297851562
Validation loss: 2.100927775905978

Epoch: 5| Step: 10
Training loss: 2.5425193309783936
Validation loss: 2.0975774154868176

Epoch: 425| Step: 0
Training loss: 1.8114560842514038
Validation loss: 2.1061188226105063

Epoch: 5| Step: 1
Training loss: 1.6632187366485596
Validation loss: 2.1180136895948842

Epoch: 5| Step: 2
Training loss: 2.7059741020202637
Validation loss: 2.1137240855924544

Epoch: 5| Step: 3
Training loss: 1.9517529010772705
Validation loss: 2.0968495466375865

Epoch: 5| Step: 4
Training loss: 2.097053050994873
Validation loss: 2.110469095168575

Epoch: 5| Step: 5
Training loss: 1.8880113363265991
Validation loss: 2.0979388580527356

Epoch: 5| Step: 6
Training loss: 2.291919469833374
Validation loss: 2.0956463480508454

Epoch: 5| Step: 7
Training loss: 2.1722187995910645
Validation loss: 2.0880375139174925

Epoch: 5| Step: 8
Training loss: 2.088423728942871
Validation loss: 2.07529309744476

Epoch: 5| Step: 9
Training loss: 1.6841144561767578
Validation loss: 2.066284869306831

Epoch: 5| Step: 10
Training loss: 2.602193832397461
Validation loss: 2.065676899366481

Epoch: 426| Step: 0
Training loss: 1.5185641050338745
Validation loss: 2.0733028406737954

Epoch: 5| Step: 1
Training loss: 1.732609748840332
Validation loss: 2.1125205075868996

Epoch: 5| Step: 2
Training loss: 2.7195534706115723
Validation loss: 2.1089602208906606

Epoch: 5| Step: 3
Training loss: 2.4203970432281494
Validation loss: 2.1178325914567515

Epoch: 5| Step: 4
Training loss: 1.3703138828277588
Validation loss: 2.1221958232182327

Epoch: 5| Step: 5
Training loss: 2.1262288093566895
Validation loss: 2.112743693013345

Epoch: 5| Step: 6
Training loss: 2.207138776779175
Validation loss: 2.1168132417945453

Epoch: 5| Step: 7
Training loss: 1.9539310932159424
Validation loss: 2.084583987471878

Epoch: 5| Step: 8
Training loss: 1.5487947463989258
Validation loss: 2.098598575079313

Epoch: 5| Step: 9
Training loss: 2.7913403511047363
Validation loss: 2.055625911681883

Epoch: 5| Step: 10
Training loss: 2.7679595947265625
Validation loss: 2.0742742579470397

Epoch: 427| Step: 0
Training loss: 2.334939479827881
Validation loss: 2.0657505642983223

Epoch: 5| Step: 1
Training loss: 1.5605213642120361
Validation loss: 2.047635632176553

Epoch: 5| Step: 2
Training loss: 1.5730818510055542
Validation loss: 2.0706778905724965

Epoch: 5| Step: 3
Training loss: 1.900892972946167
Validation loss: 2.068802146501439

Epoch: 5| Step: 4
Training loss: 2.2195050716400146
Validation loss: 2.064937537716281

Epoch: 5| Step: 5
Training loss: 2.5004870891571045
Validation loss: 2.0585207875056932

Epoch: 5| Step: 6
Training loss: 1.932193398475647
Validation loss: 2.0689009799752185

Epoch: 5| Step: 7
Training loss: 2.4268670082092285
Validation loss: 2.072984569816179

Epoch: 5| Step: 8
Training loss: 1.7993395328521729
Validation loss: 2.0864734700931016

Epoch: 5| Step: 9
Training loss: 2.549818515777588
Validation loss: 2.0982794736021306

Epoch: 5| Step: 10
Training loss: 2.2276432514190674
Validation loss: 2.10147346732437

Epoch: 428| Step: 0
Training loss: 2.2159056663513184
Validation loss: 2.091572474407893

Epoch: 5| Step: 1
Training loss: 2.0434622764587402
Validation loss: 2.0828642832335604

Epoch: 5| Step: 2
Training loss: 2.107839584350586
Validation loss: 2.073817249267332

Epoch: 5| Step: 3
Training loss: 2.0297303199768066
Validation loss: 2.071609475279367

Epoch: 5| Step: 4
Training loss: 2.0017426013946533
Validation loss: 2.0778114436775126

Epoch: 5| Step: 5
Training loss: 2.2411134243011475
Validation loss: 2.0763478868751117

Epoch: 5| Step: 6
Training loss: 1.6995617151260376
Validation loss: 2.0771233471491004

Epoch: 5| Step: 7
Training loss: 2.2979817390441895
Validation loss: 2.0732342696958974

Epoch: 5| Step: 8
Training loss: 2.4618635177612305
Validation loss: 2.0947772200389574

Epoch: 5| Step: 9
Training loss: 2.3778045177459717
Validation loss: 2.088616217336347

Epoch: 5| Step: 10
Training loss: 1.2734471559524536
Validation loss: 2.0731850618957193

Epoch: 429| Step: 0
Training loss: 1.8363845348358154
Validation loss: 2.080278724752447

Epoch: 5| Step: 1
Training loss: 1.9024204015731812
Validation loss: 2.0924599093775593

Epoch: 5| Step: 2
Training loss: 1.9196138381958008
Validation loss: 2.0879189096471316

Epoch: 5| Step: 3
Training loss: 2.5232927799224854
Validation loss: 2.0753218384199243

Epoch: 5| Step: 4
Training loss: 1.9138374328613281
Validation loss: 2.055519316786079

Epoch: 5| Step: 5
Training loss: 1.9993442296981812
Validation loss: 2.071933933483657

Epoch: 5| Step: 6
Training loss: 2.1044225692749023
Validation loss: 2.0576327693077827

Epoch: 5| Step: 7
Training loss: 2.3686165809631348
Validation loss: 2.0842860334662983

Epoch: 5| Step: 8
Training loss: 1.9054934978485107
Validation loss: 2.073760405663521

Epoch: 5| Step: 9
Training loss: 1.9500477313995361
Validation loss: 2.08456527802252

Epoch: 5| Step: 10
Training loss: 2.3600614070892334
Validation loss: 2.0920303995891283

Epoch: 430| Step: 0
Training loss: 2.006740093231201
Validation loss: 2.082884757749496

Epoch: 5| Step: 1
Training loss: 2.0286331176757812
Validation loss: 2.097409907207694

Epoch: 5| Step: 2
Training loss: 2.4754133224487305
Validation loss: 2.085345769441256

Epoch: 5| Step: 3
Training loss: 1.7447608709335327
Validation loss: 2.094760343592654

Epoch: 5| Step: 4
Training loss: 2.230571746826172
Validation loss: 2.069716795798271

Epoch: 5| Step: 5
Training loss: 2.184293508529663
Validation loss: 2.0798800504335793

Epoch: 5| Step: 6
Training loss: 2.2507786750793457
Validation loss: 2.071219666029817

Epoch: 5| Step: 7
Training loss: 2.0308609008789062
Validation loss: 2.0822679253034693

Epoch: 5| Step: 8
Training loss: 1.5099736452102661
Validation loss: 2.086326014611029

Epoch: 5| Step: 9
Training loss: 2.313755512237549
Validation loss: 2.087993916644845

Epoch: 5| Step: 10
Training loss: 1.9835301637649536
Validation loss: 2.0835042435635804

Epoch: 431| Step: 0
Training loss: 1.967502236366272
Validation loss: 2.093382986642981

Epoch: 5| Step: 1
Training loss: 2.5102248191833496
Validation loss: 2.0890624292435183

Epoch: 5| Step: 2
Training loss: 2.3884758949279785
Validation loss: 2.1013403554116525

Epoch: 5| Step: 3
Training loss: 1.7861312627792358
Validation loss: 2.0987475136274933

Epoch: 5| Step: 4
Training loss: 1.8965327739715576
Validation loss: 2.078426609757126

Epoch: 5| Step: 5
Training loss: 2.0916991233825684
Validation loss: 2.0830530966481855

Epoch: 5| Step: 6
Training loss: 1.810196876525879
Validation loss: 2.0738552731852375

Epoch: 5| Step: 7
Training loss: 2.1256792545318604
Validation loss: 2.0498720138303694

Epoch: 5| Step: 8
Training loss: 1.8765827417373657
Validation loss: 2.0539038911942513

Epoch: 5| Step: 9
Training loss: 2.0066773891448975
Validation loss: 2.0618967420311383

Epoch: 5| Step: 10
Training loss: 2.455458641052246
Validation loss: 2.0583560300129715

Epoch: 432| Step: 0
Training loss: 2.3454887866973877
Validation loss: 2.0429627010899205

Epoch: 5| Step: 1
Training loss: 1.8497158288955688
Validation loss: 2.0664482629427345

Epoch: 5| Step: 2
Training loss: 2.2280755043029785
Validation loss: 2.0804049097081667

Epoch: 5| Step: 3
Training loss: 2.8140053749084473
Validation loss: 2.0884109876489125

Epoch: 5| Step: 4
Training loss: 1.8822462558746338
Validation loss: 2.061654472863802

Epoch: 5| Step: 5
Training loss: 1.9815623760223389
Validation loss: 2.079886192916542

Epoch: 5| Step: 6
Training loss: 2.311910390853882
Validation loss: 2.0612967424495245

Epoch: 5| Step: 7
Training loss: 1.6252717971801758
Validation loss: 2.070060240325107

Epoch: 5| Step: 8
Training loss: 1.6767847537994385
Validation loss: 2.0746320691159976

Epoch: 5| Step: 9
Training loss: 1.6216552257537842
Validation loss: 2.0691966882316013

Epoch: 5| Step: 10
Training loss: 2.414557456970215
Validation loss: 2.058253462596606

Epoch: 433| Step: 0
Training loss: 2.5082848072052
Validation loss: 2.0676343607646164

Epoch: 5| Step: 1
Training loss: 1.9462963342666626
Validation loss: 2.0755165212897846

Epoch: 5| Step: 2
Training loss: 2.0742294788360596
Validation loss: 2.065287927145599

Epoch: 5| Step: 3
Training loss: 2.273601770401001
Validation loss: 2.060083971228651

Epoch: 5| Step: 4
Training loss: 1.944250464439392
Validation loss: 2.06618211730834

Epoch: 5| Step: 5
Training loss: 1.9802967309951782
Validation loss: 2.064018386666493

Epoch: 5| Step: 6
Training loss: 1.929492712020874
Validation loss: 2.0747560352407475

Epoch: 5| Step: 7
Training loss: 1.8632514476776123
Validation loss: 2.0812722380443285

Epoch: 5| Step: 8
Training loss: 2.035367488861084
Validation loss: 2.1057499224139797

Epoch: 5| Step: 9
Training loss: 2.4564931392669678
Validation loss: 2.0801450847297587

Epoch: 5| Step: 10
Training loss: 1.7093076705932617
Validation loss: 2.103586240481305

Epoch: 434| Step: 0
Training loss: 2.3699302673339844
Validation loss: 2.0675378589219946

Epoch: 5| Step: 1
Training loss: 1.51059889793396
Validation loss: 2.091813264354583

Epoch: 5| Step: 2
Training loss: 1.9980199337005615
Validation loss: 2.08329999831415

Epoch: 5| Step: 3
Training loss: 2.302377223968506
Validation loss: 2.080532876394128

Epoch: 5| Step: 4
Training loss: 2.6702980995178223
Validation loss: 2.0871645224991666

Epoch: 5| Step: 5
Training loss: 2.6868345737457275
Validation loss: 2.054757297679942

Epoch: 5| Step: 6
Training loss: 1.9790455102920532
Validation loss: 2.067117198821037

Epoch: 5| Step: 7
Training loss: 1.6095157861709595
Validation loss: 2.047559917614024

Epoch: 5| Step: 8
Training loss: 1.948513388633728
Validation loss: 2.050769721308062

Epoch: 5| Step: 9
Training loss: 1.8912051916122437
Validation loss: 2.058331251144409

Epoch: 5| Step: 10
Training loss: 1.8077173233032227
Validation loss: 2.0588322531792427

Epoch: 435| Step: 0
Training loss: 1.3420313596725464
Validation loss: 2.063083492299562

Epoch: 5| Step: 1
Training loss: 1.811789870262146
Validation loss: 2.0594253065765544

Epoch: 5| Step: 2
Training loss: 1.9944117069244385
Validation loss: 2.0810848846230456

Epoch: 5| Step: 3
Training loss: 2.8048133850097656
Validation loss: 2.1038258332078175

Epoch: 5| Step: 4
Training loss: 2.2221145629882812
Validation loss: 2.0852564124650854

Epoch: 5| Step: 5
Training loss: 2.0918495655059814
Validation loss: 2.0639349286274244

Epoch: 5| Step: 6
Training loss: 1.777581810951233
Validation loss: 2.1111836997411584

Epoch: 5| Step: 7
Training loss: 2.6270670890808105
Validation loss: 2.084319455649263

Epoch: 5| Step: 8
Training loss: 2.0762293338775635
Validation loss: 2.0836316347122192

Epoch: 5| Step: 9
Training loss: 1.2355334758758545
Validation loss: 2.0687312515833045

Epoch: 5| Step: 10
Training loss: 2.8739278316497803
Validation loss: 2.087915023167928

Epoch: 436| Step: 0
Training loss: 1.9363826513290405
Validation loss: 2.0611376993117796

Epoch: 5| Step: 1
Training loss: 2.456132650375366
Validation loss: 2.07924896670926

Epoch: 5| Step: 2
Training loss: 1.3217308521270752
Validation loss: 2.068239168454242

Epoch: 5| Step: 3
Training loss: 1.772345781326294
Validation loss: 2.060949299925117

Epoch: 5| Step: 4
Training loss: 2.33447527885437
Validation loss: 2.055475640040572

Epoch: 5| Step: 5
Training loss: 2.551206588745117
Validation loss: 2.0663564884534447

Epoch: 5| Step: 6
Training loss: 2.181408405303955
Validation loss: 2.045022036439629

Epoch: 5| Step: 7
Training loss: 1.9277883768081665
Validation loss: 2.0586169560750327

Epoch: 5| Step: 8
Training loss: 1.868952989578247
Validation loss: 2.0693878589137906

Epoch: 5| Step: 9
Training loss: 2.2117342948913574
Validation loss: 2.065234266301637

Epoch: 5| Step: 10
Training loss: 2.1045899391174316
Validation loss: 2.0623062015861593

Epoch: 437| Step: 0
Training loss: 2.32796049118042
Validation loss: 2.052553758826307

Epoch: 5| Step: 1
Training loss: 1.1851555109024048
Validation loss: 2.0702829437871135

Epoch: 5| Step: 2
Training loss: 2.152103900909424
Validation loss: 2.0680709615830453

Epoch: 5| Step: 3
Training loss: 2.1847009658813477
Validation loss: 2.059357972555263

Epoch: 5| Step: 4
Training loss: 2.3178012371063232
Validation loss: 2.0577138162428334

Epoch: 5| Step: 5
Training loss: 2.262176036834717
Validation loss: 2.0609586674679994

Epoch: 5| Step: 6
Training loss: 1.6726634502410889
Validation loss: 2.041942372116991

Epoch: 5| Step: 7
Training loss: 2.3802103996276855
Validation loss: 2.060893891960062

Epoch: 5| Step: 8
Training loss: 2.1633999347686768
Validation loss: 2.0626633397994505

Epoch: 5| Step: 9
Training loss: 2.001316547393799
Validation loss: 2.0649606553457116

Epoch: 5| Step: 10
Training loss: 2.1502740383148193
Validation loss: 2.077962281883404

Epoch: 438| Step: 0
Training loss: 1.856527328491211
Validation loss: 2.081875346040213

Epoch: 5| Step: 1
Training loss: 1.9329357147216797
Validation loss: 2.089063024008146

Epoch: 5| Step: 2
Training loss: 1.6013253927230835
Validation loss: 2.104045480810186

Epoch: 5| Step: 3
Training loss: 2.1149067878723145
Validation loss: 2.0897523959477744

Epoch: 5| Step: 4
Training loss: 2.4816088676452637
Validation loss: 2.077462680878178

Epoch: 5| Step: 5
Training loss: 1.3710159063339233
Validation loss: 2.0758408807939097

Epoch: 5| Step: 6
Training loss: 2.1050891876220703
Validation loss: 2.0738730789512716

Epoch: 5| Step: 7
Training loss: 1.842537522315979
Validation loss: 2.064343567817442

Epoch: 5| Step: 8
Training loss: 2.8569164276123047
Validation loss: 2.0756452083587646

Epoch: 5| Step: 9
Training loss: 2.5178885459899902
Validation loss: 2.064359229098084

Epoch: 5| Step: 10
Training loss: 2.0764920711517334
Validation loss: 2.0823289450778755

Epoch: 439| Step: 0
Training loss: 2.3109021186828613
Validation loss: 2.0771106186733452

Epoch: 5| Step: 1
Training loss: 2.0391550064086914
Validation loss: 2.07569480839596

Epoch: 5| Step: 2
Training loss: 1.725913643836975
Validation loss: 2.0671247487427085

Epoch: 5| Step: 3
Training loss: 1.7336450815200806
Validation loss: 2.076582775321058

Epoch: 5| Step: 4
Training loss: 2.720513105392456
Validation loss: 2.0833288725986274

Epoch: 5| Step: 5
Training loss: 2.202735185623169
Validation loss: 2.0959636088340514

Epoch: 5| Step: 6
Training loss: 2.0809128284454346
Validation loss: 2.079719735730079

Epoch: 5| Step: 7
Training loss: 2.425271511077881
Validation loss: 2.0762617434224775

Epoch: 5| Step: 8
Training loss: 2.21140456199646
Validation loss: 2.0645928613601194

Epoch: 5| Step: 9
Training loss: 1.347388744354248
Validation loss: 2.0735475542724773

Epoch: 5| Step: 10
Training loss: 1.8325774669647217
Validation loss: 2.0815744758934103

Epoch: 440| Step: 0
Training loss: 2.5218446254730225
Validation loss: 2.0660350476541827

Epoch: 5| Step: 1
Training loss: 1.6589603424072266
Validation loss: 2.0606274732979397

Epoch: 5| Step: 2
Training loss: 1.920262098312378
Validation loss: 2.0545872795966362

Epoch: 5| Step: 3
Training loss: 2.4332544803619385
Validation loss: 2.0635394075865388

Epoch: 5| Step: 4
Training loss: 1.6541740894317627
Validation loss: 2.0654621688268517

Epoch: 5| Step: 5
Training loss: 2.366004467010498
Validation loss: 2.068396940026232

Epoch: 5| Step: 6
Training loss: 2.0378167629241943
Validation loss: 2.067986544742379

Epoch: 5| Step: 7
Training loss: 1.8641185760498047
Validation loss: 2.0694240677741265

Epoch: 5| Step: 8
Training loss: 1.972038984298706
Validation loss: 2.065167006625924

Epoch: 5| Step: 9
Training loss: 1.7771899700164795
Validation loss: 2.063259736184151

Epoch: 5| Step: 10
Training loss: 2.439817428588867
Validation loss: 2.073039471462209

Epoch: 441| Step: 0
Training loss: 1.9296741485595703
Validation loss: 2.079951613180099

Epoch: 5| Step: 1
Training loss: 2.6898996829986572
Validation loss: 2.0899773515680784

Epoch: 5| Step: 2
Training loss: 2.2055156230926514
Validation loss: 2.1057213711482223

Epoch: 5| Step: 3
Training loss: 1.8681163787841797
Validation loss: 2.1090122833046863

Epoch: 5| Step: 4
Training loss: 2.0474562644958496
Validation loss: 2.096932416321129

Epoch: 5| Step: 5
Training loss: 2.0496411323547363
Validation loss: 2.099371789604105

Epoch: 5| Step: 6
Training loss: 2.3771729469299316
Validation loss: 2.082726675976989

Epoch: 5| Step: 7
Training loss: 1.9833943843841553
Validation loss: 2.0829528736811813

Epoch: 5| Step: 8
Training loss: 2.0211715698242188
Validation loss: 2.0672999940892702

Epoch: 5| Step: 9
Training loss: 1.6541255712509155
Validation loss: 2.0530627312198764

Epoch: 5| Step: 10
Training loss: 1.8161842823028564
Validation loss: 2.058176848196214

Epoch: 442| Step: 0
Training loss: 1.9161396026611328
Validation loss: 2.0690583157283005

Epoch: 5| Step: 1
Training loss: 2.997425079345703
Validation loss: 2.0558608014096498

Epoch: 5| Step: 2
Training loss: 1.9990463256835938
Validation loss: 2.0441587227647022

Epoch: 5| Step: 3
Training loss: 2.652061939239502
Validation loss: 2.0483373365094586

Epoch: 5| Step: 4
Training loss: 2.282891273498535
Validation loss: 2.046154542635846

Epoch: 5| Step: 5
Training loss: 1.5793412923812866
Validation loss: 2.064437903383727

Epoch: 5| Step: 6
Training loss: 1.0778964757919312
Validation loss: 2.084374878996162

Epoch: 5| Step: 7
Training loss: 2.3423125743865967
Validation loss: 2.084878181898466

Epoch: 5| Step: 8
Training loss: 1.6126291751861572
Validation loss: 2.0904550526731756

Epoch: 5| Step: 9
Training loss: 1.7285715341567993
Validation loss: 2.0932999426318752

Epoch: 5| Step: 10
Training loss: 2.5590593814849854
Validation loss: 2.092445332516906

Epoch: 443| Step: 0
Training loss: 2.1781556606292725
Validation loss: 2.058559389524562

Epoch: 5| Step: 1
Training loss: 2.4473822116851807
Validation loss: 2.06572445618209

Epoch: 5| Step: 2
Training loss: 2.339172840118408
Validation loss: 2.04632282000716

Epoch: 5| Step: 3
Training loss: 1.9166529178619385
Validation loss: 2.0398329240019604

Epoch: 5| Step: 4
Training loss: 1.6600697040557861
Validation loss: 2.037071317754766

Epoch: 5| Step: 5
Training loss: 2.2484354972839355
Validation loss: 2.055044025503179

Epoch: 5| Step: 6
Training loss: 2.047903060913086
Validation loss: 2.0501530657532396

Epoch: 5| Step: 7
Training loss: 2.354888439178467
Validation loss: 2.0648568843000676

Epoch: 5| Step: 8
Training loss: 2.3336546421051025
Validation loss: 2.0836349033540293

Epoch: 5| Step: 9
Training loss: 1.5885239839553833
Validation loss: 2.1042734346082135

Epoch: 5| Step: 10
Training loss: 1.6394420862197876
Validation loss: 2.1179879044973724

Epoch: 444| Step: 0
Training loss: 2.2037625312805176
Validation loss: 2.0932398470499183

Epoch: 5| Step: 1
Training loss: 2.5762155055999756
Validation loss: 2.092218909212338

Epoch: 5| Step: 2
Training loss: 2.153590679168701
Validation loss: 2.0913906789595083

Epoch: 5| Step: 3
Training loss: 1.5646202564239502
Validation loss: 2.0649269293713313

Epoch: 5| Step: 4
Training loss: 1.9109256267547607
Validation loss: 2.080625298202679

Epoch: 5| Step: 5
Training loss: 2.438711643218994
Validation loss: 2.0649095273786977

Epoch: 5| Step: 6
Training loss: 2.3936500549316406
Validation loss: 2.0729419108360045

Epoch: 5| Step: 7
Training loss: 1.9298944473266602
Validation loss: 2.0568688415711924

Epoch: 5| Step: 8
Training loss: 1.9674293994903564
Validation loss: 2.047534223525755

Epoch: 5| Step: 9
Training loss: 1.5031020641326904
Validation loss: 2.0360515143281672

Epoch: 5| Step: 10
Training loss: 2.0588884353637695
Validation loss: 2.053280184345861

Epoch: 445| Step: 0
Training loss: 1.6146667003631592
Validation loss: 2.076787853753695

Epoch: 5| Step: 1
Training loss: 2.0405240058898926
Validation loss: 2.098270349605109

Epoch: 5| Step: 2
Training loss: 2.5268523693084717
Validation loss: 2.06173873460421

Epoch: 5| Step: 3
Training loss: 1.7331825494766235
Validation loss: 2.063511002448297

Epoch: 5| Step: 4
Training loss: 1.8451309204101562
Validation loss: 2.076600802842007

Epoch: 5| Step: 5
Training loss: 1.993638038635254
Validation loss: 2.0737648574254846

Epoch: 5| Step: 6
Training loss: 3.0350375175476074
Validation loss: 2.061475912729899

Epoch: 5| Step: 7
Training loss: 2.5682270526885986
Validation loss: 2.0743634495683896

Epoch: 5| Step: 8
Training loss: 1.6584926843643188
Validation loss: 2.0584683982274865

Epoch: 5| Step: 9
Training loss: 1.72263503074646
Validation loss: 2.050603715322351

Epoch: 5| Step: 10
Training loss: 1.8175363540649414
Validation loss: 2.0628472297422347

Epoch: 446| Step: 0
Training loss: 2.3847198486328125
Validation loss: 2.0533594905689196

Epoch: 5| Step: 1
Training loss: 2.263632297515869
Validation loss: 2.0661941215556157

Epoch: 5| Step: 2
Training loss: 1.5656214952468872
Validation loss: 2.0689411112057265

Epoch: 5| Step: 3
Training loss: 2.2106680870056152
Validation loss: 2.076734822283509

Epoch: 5| Step: 4
Training loss: 2.0851211547851562
Validation loss: 2.09929032223199

Epoch: 5| Step: 5
Training loss: 1.9098247289657593
Validation loss: 2.0625233842480566

Epoch: 5| Step: 6
Training loss: 2.3487372398376465
Validation loss: 2.0659254648352183

Epoch: 5| Step: 7
Training loss: 1.5937910079956055
Validation loss: 2.0686808427174888

Epoch: 5| Step: 8
Training loss: 1.9702974557876587
Validation loss: 2.062557963914769

Epoch: 5| Step: 9
Training loss: 2.3080029487609863
Validation loss: 2.0664289151468584

Epoch: 5| Step: 10
Training loss: 1.8502525091171265
Validation loss: 2.061420976474721

Epoch: 447| Step: 0
Training loss: 2.387930393218994
Validation loss: 2.0569913502662414

Epoch: 5| Step: 1
Training loss: 2.5233402252197266
Validation loss: 2.0633016427357993

Epoch: 5| Step: 2
Training loss: 2.3748879432678223
Validation loss: 2.04904100202745

Epoch: 5| Step: 3
Training loss: 2.0544934272766113
Validation loss: 2.0529112046764744

Epoch: 5| Step: 4
Training loss: 1.4713594913482666
Validation loss: 2.061523452881844

Epoch: 5| Step: 5
Training loss: 2.494424819946289
Validation loss: 2.052058886456233

Epoch: 5| Step: 6
Training loss: 1.4959138631820679
Validation loss: 2.0627119976987123

Epoch: 5| Step: 7
Training loss: 2.020094394683838
Validation loss: 2.071135938808482

Epoch: 5| Step: 8
Training loss: 2.248760938644409
Validation loss: 2.0899851142719226

Epoch: 5| Step: 9
Training loss: 1.4356238842010498
Validation loss: 2.090325709312193

Epoch: 5| Step: 10
Training loss: 1.9226938486099243
Validation loss: 2.1121678506174395

Epoch: 448| Step: 0
Training loss: 2.5321736335754395
Validation loss: 2.0916645911432084

Epoch: 5| Step: 1
Training loss: 1.9373794794082642
Validation loss: 2.0823755264282227

Epoch: 5| Step: 2
Training loss: 1.6199944019317627
Validation loss: 2.0750833788225727

Epoch: 5| Step: 3
Training loss: 2.1040995121002197
Validation loss: 2.07200724335127

Epoch: 5| Step: 4
Training loss: 1.4664676189422607
Validation loss: 2.0730316715855754

Epoch: 5| Step: 5
Training loss: 2.3999688625335693
Validation loss: 2.043113677732406

Epoch: 5| Step: 6
Training loss: 2.470128297805786
Validation loss: 2.057685507241116

Epoch: 5| Step: 7
Training loss: 1.8931491374969482
Validation loss: 2.0589993769122708

Epoch: 5| Step: 8
Training loss: 2.237278461456299
Validation loss: 2.0491416838861283

Epoch: 5| Step: 9
Training loss: 2.0364232063293457
Validation loss: 2.0469018977175475

Epoch: 5| Step: 10
Training loss: 1.622798204421997
Validation loss: 2.031057729515978

Epoch: 449| Step: 0
Training loss: 2.061082124710083
Validation loss: 2.0426534555291616

Epoch: 5| Step: 1
Training loss: 2.2093605995178223
Validation loss: 2.0551393826802573

Epoch: 5| Step: 2
Training loss: 1.729859709739685
Validation loss: 2.0544786325065036

Epoch: 5| Step: 3
Training loss: 1.818381667137146
Validation loss: 2.0480581637351745

Epoch: 5| Step: 4
Training loss: 2.5558159351348877
Validation loss: 2.052369527919318

Epoch: 5| Step: 5
Training loss: 1.982312798500061
Validation loss: 2.0393911433476273

Epoch: 5| Step: 6
Training loss: 1.543601393699646
Validation loss: 2.0354571509104904

Epoch: 5| Step: 7
Training loss: 2.377664089202881
Validation loss: 2.0565508770686325

Epoch: 5| Step: 8
Training loss: 2.5088133811950684
Validation loss: 2.0645846243827575

Epoch: 5| Step: 9
Training loss: 1.9667564630508423
Validation loss: 2.092956112277123

Epoch: 5| Step: 10
Training loss: 1.6725738048553467
Validation loss: 2.1166889180419264

Epoch: 450| Step: 0
Training loss: 2.358537197113037
Validation loss: 2.1429727538939445

Epoch: 5| Step: 1
Training loss: 1.2047431468963623
Validation loss: 2.1466525395711265

Epoch: 5| Step: 2
Training loss: 2.4051108360290527
Validation loss: 2.1179849204196723

Epoch: 5| Step: 3
Training loss: 1.9346046447753906
Validation loss: 2.104563287509385

Epoch: 5| Step: 4
Training loss: 1.7476822137832642
Validation loss: 2.062909551846084

Epoch: 5| Step: 5
Training loss: 2.2411675453186035
Validation loss: 2.0500108324071413

Epoch: 5| Step: 6
Training loss: 2.215977430343628
Validation loss: 2.0492781208407496

Epoch: 5| Step: 7
Training loss: 2.1922898292541504
Validation loss: 2.0493174368335354

Epoch: 5| Step: 8
Training loss: 1.7354644536972046
Validation loss: 2.048954786792878

Epoch: 5| Step: 9
Training loss: 2.360801935195923
Validation loss: 2.0634079171765234

Epoch: 5| Step: 10
Training loss: 2.168379783630371
Validation loss: 2.041914718125456

Epoch: 451| Step: 0
Training loss: 2.0524864196777344
Validation loss: 2.0504956937605336

Epoch: 5| Step: 1
Training loss: 2.496232271194458
Validation loss: 2.040814430482926

Epoch: 5| Step: 2
Training loss: 1.8895355463027954
Validation loss: 2.062728830563125

Epoch: 5| Step: 3
Training loss: 1.612480878829956
Validation loss: 2.057448133345573

Epoch: 5| Step: 4
Training loss: 2.143120288848877
Validation loss: 2.046876081856348

Epoch: 5| Step: 5
Training loss: 2.0483927726745605
Validation loss: 2.079884365040769

Epoch: 5| Step: 6
Training loss: 2.0478503704071045
Validation loss: 2.0550128413784887

Epoch: 5| Step: 7
Training loss: 1.962811827659607
Validation loss: 2.0716771438557613

Epoch: 5| Step: 8
Training loss: 2.002776622772217
Validation loss: 2.0791939279084564

Epoch: 5| Step: 9
Training loss: 1.7103159427642822
Validation loss: 2.0869583417010564

Epoch: 5| Step: 10
Training loss: 2.473499059677124
Validation loss: 2.087726052089404

Epoch: 452| Step: 0
Training loss: 1.470169186592102
Validation loss: 2.0658605944725776

Epoch: 5| Step: 1
Training loss: 2.6536850929260254
Validation loss: 2.063545778233518

Epoch: 5| Step: 2
Training loss: 1.7211768627166748
Validation loss: 2.0620441680313437

Epoch: 5| Step: 3
Training loss: 1.6985251903533936
Validation loss: 2.0501501252574306

Epoch: 5| Step: 4
Training loss: 1.9684654474258423
Validation loss: 2.046727652190834

Epoch: 5| Step: 5
Training loss: 2.4006333351135254
Validation loss: 2.0474097113455496

Epoch: 5| Step: 6
Training loss: 1.5692369937896729
Validation loss: 2.069913759026476

Epoch: 5| Step: 7
Training loss: 2.7545790672302246
Validation loss: 2.0614213584571757

Epoch: 5| Step: 8
Training loss: 1.922019600868225
Validation loss: 2.0680864305906397

Epoch: 5| Step: 9
Training loss: 2.74208402633667
Validation loss: 2.062560865955968

Epoch: 5| Step: 10
Training loss: 1.3829429149627686
Validation loss: 2.0863541877397926

Epoch: 453| Step: 0
Training loss: 2.1063284873962402
Validation loss: 2.086078164398029

Epoch: 5| Step: 1
Training loss: 1.928393006324768
Validation loss: 2.0722912255153862

Epoch: 5| Step: 2
Training loss: 1.3177787065505981
Validation loss: 2.12348698928792

Epoch: 5| Step: 3
Training loss: 1.8500264883041382
Validation loss: 2.12353713281693

Epoch: 5| Step: 4
Training loss: 3.25590443611145
Validation loss: 2.127222985349676

Epoch: 5| Step: 5
Training loss: 1.9795697927474976
Validation loss: 2.133570727481637

Epoch: 5| Step: 6
Training loss: 2.2665488719940186
Validation loss: 2.0937060720177105

Epoch: 5| Step: 7
Training loss: 1.6970546245574951
Validation loss: 2.062691469346323

Epoch: 5| Step: 8
Training loss: 2.5847702026367188
Validation loss: 2.0578741745282243

Epoch: 5| Step: 9
Training loss: 1.556687593460083
Validation loss: 2.078791250464737

Epoch: 5| Step: 10
Training loss: 2.1511151790618896
Validation loss: 2.077958022394488

Epoch: 454| Step: 0
Training loss: 1.7655683755874634
Validation loss: 2.064233459452147

Epoch: 5| Step: 1
Training loss: 2.2551913261413574
Validation loss: 2.0697521740390408

Epoch: 5| Step: 2
Training loss: 2.542930841445923
Validation loss: 2.0601182240311817

Epoch: 5| Step: 3
Training loss: 2.4577746391296387
Validation loss: 2.0517485039208525

Epoch: 5| Step: 4
Training loss: 2.0127439498901367
Validation loss: 2.0431139494783137

Epoch: 5| Step: 5
Training loss: 2.4681313037872314
Validation loss: 2.0299535438578618

Epoch: 5| Step: 6
Training loss: 1.8661060333251953
Validation loss: 2.042488795454784

Epoch: 5| Step: 7
Training loss: 1.5600239038467407
Validation loss: 2.049314991120369

Epoch: 5| Step: 8
Training loss: 2.2689945697784424
Validation loss: 2.062985481754426

Epoch: 5| Step: 9
Training loss: 1.6292216777801514
Validation loss: 2.0838444053485827

Epoch: 5| Step: 10
Training loss: 2.058736801147461
Validation loss: 2.082516690736176

Epoch: 455| Step: 0
Training loss: 2.0519886016845703
Validation loss: 2.100426766180223

Epoch: 5| Step: 1
Training loss: 2.2759900093078613
Validation loss: 2.07969569647184

Epoch: 5| Step: 2
Training loss: 1.2289884090423584
Validation loss: 2.080608373047203

Epoch: 5| Step: 3
Training loss: 1.9940357208251953
Validation loss: 2.0651218404052076

Epoch: 5| Step: 4
Training loss: 2.800285816192627
Validation loss: 2.0704282855474823

Epoch: 5| Step: 5
Training loss: 2.2057995796203613
Validation loss: 2.0631673464211087

Epoch: 5| Step: 6
Training loss: 2.0557701587677
Validation loss: 2.051145940698603

Epoch: 5| Step: 7
Training loss: 1.655233383178711
Validation loss: 2.0521251232393327

Epoch: 5| Step: 8
Training loss: 2.0603861808776855
Validation loss: 2.035453211876654

Epoch: 5| Step: 9
Training loss: 2.17034649848938
Validation loss: 2.055315657328534

Epoch: 5| Step: 10
Training loss: 1.975226640701294
Validation loss: 2.053466719965781

Epoch: 456| Step: 0
Training loss: 1.3021552562713623
Validation loss: 2.052024410616967

Epoch: 5| Step: 1
Training loss: 1.729797124862671
Validation loss: 2.055808210885653

Epoch: 5| Step: 2
Training loss: 2.7254302501678467
Validation loss: 2.0639055287966164

Epoch: 5| Step: 3
Training loss: 1.7352731227874756
Validation loss: 2.0505647890029417

Epoch: 5| Step: 4
Training loss: 2.0353245735168457
Validation loss: 2.0773580125583115

Epoch: 5| Step: 5
Training loss: 2.6068949699401855
Validation loss: 2.0624280104073147

Epoch: 5| Step: 6
Training loss: 2.5418999195098877
Validation loss: 2.0639438526604765

Epoch: 5| Step: 7
Training loss: 2.2767632007598877
Validation loss: 2.0655463664762435

Epoch: 5| Step: 8
Training loss: 1.9350559711456299
Validation loss: 2.0706560009269306

Epoch: 5| Step: 9
Training loss: 1.6799205541610718
Validation loss: 2.063538835894677

Epoch: 5| Step: 10
Training loss: 1.697285771369934
Validation loss: 2.057508865992228

Epoch: 457| Step: 0
Training loss: 2.622426748275757
Validation loss: 2.061422558240993

Epoch: 5| Step: 1
Training loss: 1.8935205936431885
Validation loss: 2.052734098126811

Epoch: 5| Step: 2
Training loss: 1.9526221752166748
Validation loss: 2.0611425087016118

Epoch: 5| Step: 3
Training loss: 1.8937660455703735
Validation loss: 2.067704418654083

Epoch: 5| Step: 4
Training loss: 1.4790376424789429
Validation loss: 2.092486792995084

Epoch: 5| Step: 5
Training loss: 2.093550682067871
Validation loss: 2.0734181506659395

Epoch: 5| Step: 6
Training loss: 2.5323238372802734
Validation loss: 2.0701515700227473

Epoch: 5| Step: 7
Training loss: 1.8633673191070557
Validation loss: 2.0633042781583724

Epoch: 5| Step: 8
Training loss: 2.1097328662872314
Validation loss: 2.0501326540464997

Epoch: 5| Step: 9
Training loss: 2.2319140434265137
Validation loss: 2.053608214983376

Epoch: 5| Step: 10
Training loss: 1.5971887111663818
Validation loss: 2.0459335247675576

Epoch: 458| Step: 0
Training loss: 1.8314812183380127
Validation loss: 2.0400855054137526

Epoch: 5| Step: 1
Training loss: 1.846587896347046
Validation loss: 2.039202772161012

Epoch: 5| Step: 2
Training loss: 2.1363847255706787
Validation loss: 2.0561267663073797

Epoch: 5| Step: 3
Training loss: 2.525972366333008
Validation loss: 2.0533726958818335

Epoch: 5| Step: 4
Training loss: 2.3464717864990234
Validation loss: 2.075970652282879

Epoch: 5| Step: 5
Training loss: 1.864160180091858
Validation loss: 2.0545976802866948

Epoch: 5| Step: 6
Training loss: 1.8282760381698608
Validation loss: 2.072353788601455

Epoch: 5| Step: 7
Training loss: 2.0096917152404785
Validation loss: 2.055574442750664

Epoch: 5| Step: 8
Training loss: 2.552764415740967
Validation loss: 2.083570679028829

Epoch: 5| Step: 9
Training loss: 1.8280189037322998
Validation loss: 2.0905166915667954

Epoch: 5| Step: 10
Training loss: 1.7039456367492676
Validation loss: 2.108122394930932

Epoch: 459| Step: 0
Training loss: 1.7050859928131104
Validation loss: 2.082041650690058

Epoch: 5| Step: 1
Training loss: 2.2333359718322754
Validation loss: 2.0542415777842202

Epoch: 5| Step: 2
Training loss: 1.8292267322540283
Validation loss: 2.033699935482394

Epoch: 5| Step: 3
Training loss: 1.608717918395996
Validation loss: 2.0430994110722698

Epoch: 5| Step: 4
Training loss: 2.685307741165161
Validation loss: 2.0473602176994405

Epoch: 5| Step: 5
Training loss: 1.878578782081604
Validation loss: 2.0484829461702736

Epoch: 5| Step: 6
Training loss: 1.814218521118164
Validation loss: 2.043736668043239

Epoch: 5| Step: 7
Training loss: 2.4839134216308594
Validation loss: 2.0438695261555333

Epoch: 5| Step: 8
Training loss: 2.127703905105591
Validation loss: 2.036820734700849

Epoch: 5| Step: 9
Training loss: 1.5083107948303223
Validation loss: 2.052387706695064

Epoch: 5| Step: 10
Training loss: 2.595010757446289
Validation loss: 2.0452611613017257

Epoch: 460| Step: 0
Training loss: 2.2017524242401123
Validation loss: 2.070030261111516

Epoch: 5| Step: 1
Training loss: 2.224508762359619
Validation loss: 2.077847583319551

Epoch: 5| Step: 2
Training loss: 2.3285326957702637
Validation loss: 2.0776354087296354

Epoch: 5| Step: 3
Training loss: 2.370021343231201
Validation loss: 2.079980068309333

Epoch: 5| Step: 4
Training loss: 1.8609049320220947
Validation loss: 2.0574039259264545

Epoch: 5| Step: 5
Training loss: 1.8575996160507202
Validation loss: 2.0571291318503757

Epoch: 5| Step: 6
Training loss: 1.9573848247528076
Validation loss: 2.06051420011828

Epoch: 5| Step: 7
Training loss: 1.8662773370742798
Validation loss: 2.069113036637665

Epoch: 5| Step: 8
Training loss: 1.865064263343811
Validation loss: 2.052264987781484

Epoch: 5| Step: 9
Training loss: 1.6871795654296875
Validation loss: 2.0682017111009166

Epoch: 5| Step: 10
Training loss: 2.0698511600494385
Validation loss: 2.0756443687664565

Epoch: 461| Step: 0
Training loss: 1.9346730709075928
Validation loss: 2.0592364918801094

Epoch: 5| Step: 1
Training loss: 2.7972846031188965
Validation loss: 2.0683763129736787

Epoch: 5| Step: 2
Training loss: 1.5036031007766724
Validation loss: 2.065652511453116

Epoch: 5| Step: 3
Training loss: 1.9300895929336548
Validation loss: 2.065046907753073

Epoch: 5| Step: 4
Training loss: 1.9189822673797607
Validation loss: 2.079453094031221

Epoch: 5| Step: 5
Training loss: 2.104715347290039
Validation loss: 2.057751460741925

Epoch: 5| Step: 6
Training loss: 2.6302144527435303
Validation loss: 2.064134179904897

Epoch: 5| Step: 7
Training loss: 1.8334373235702515
Validation loss: 2.063674267902169

Epoch: 5| Step: 8
Training loss: 1.7395009994506836
Validation loss: 2.065409929521622

Epoch: 5| Step: 9
Training loss: 1.8499294519424438
Validation loss: 2.0490410097183718

Epoch: 5| Step: 10
Training loss: 1.9505032300949097
Validation loss: 2.024540837093066

Epoch: 462| Step: 0
Training loss: 1.6838830709457397
Validation loss: 2.036372370617364

Epoch: 5| Step: 1
Training loss: 1.9755489826202393
Validation loss: 2.0395259293176795

Epoch: 5| Step: 2
Training loss: 2.197389841079712
Validation loss: 2.0436378114966938

Epoch: 5| Step: 3
Training loss: 2.402930498123169
Validation loss: 2.040511356886997

Epoch: 5| Step: 4
Training loss: 2.2960898876190186
Validation loss: 2.0554312672666324

Epoch: 5| Step: 5
Training loss: 1.9765653610229492
Validation loss: 2.0363440244428572

Epoch: 5| Step: 6
Training loss: 1.876546859741211
Validation loss: 2.063811012493667

Epoch: 5| Step: 7
Training loss: 2.077502489089966
Validation loss: 2.067822710160286

Epoch: 5| Step: 8
Training loss: 1.936522126197815
Validation loss: 2.0738414359349076

Epoch: 5| Step: 9
Training loss: 2.115612506866455
Validation loss: 2.093127614708357

Epoch: 5| Step: 10
Training loss: 1.5545613765716553
Validation loss: 2.098972442329571

Epoch: 463| Step: 0
Training loss: 1.8808199167251587
Validation loss: 2.0765104114368396

Epoch: 5| Step: 1
Training loss: 2.1264240741729736
Validation loss: 2.0490913121931014

Epoch: 5| Step: 2
Training loss: 2.160183906555176
Validation loss: 2.063641009792205

Epoch: 5| Step: 3
Training loss: 2.1374945640563965
Validation loss: 2.068872929901205

Epoch: 5| Step: 4
Training loss: 2.3433308601379395
Validation loss: 2.058120978775845

Epoch: 5| Step: 5
Training loss: 2.1326851844787598
Validation loss: 2.051056229940025

Epoch: 5| Step: 6
Training loss: 2.439176082611084
Validation loss: 2.058801720219274

Epoch: 5| Step: 7
Training loss: 1.683475136756897
Validation loss: 2.058805050388459

Epoch: 5| Step: 8
Training loss: 1.8350893259048462
Validation loss: 2.044778226524271

Epoch: 5| Step: 9
Training loss: 1.6555664539337158
Validation loss: 2.0410396668218795

Epoch: 5| Step: 10
Training loss: 1.6810166835784912
Validation loss: 2.0553777474229054

Epoch: 464| Step: 0
Training loss: 2.0872063636779785
Validation loss: 2.0450928224030362

Epoch: 5| Step: 1
Training loss: 1.2861219644546509
Validation loss: 2.056977727079904

Epoch: 5| Step: 2
Training loss: 2.185716152191162
Validation loss: 2.0418532227957122

Epoch: 5| Step: 3
Training loss: 2.3292202949523926
Validation loss: 2.0460261888401483

Epoch: 5| Step: 4
Training loss: 2.7188735008239746
Validation loss: 2.0419893008406445

Epoch: 5| Step: 5
Training loss: 1.691451072692871
Validation loss: 2.045272009347075

Epoch: 5| Step: 6
Training loss: 1.940951943397522
Validation loss: 2.0415015810279438

Epoch: 5| Step: 7
Training loss: 2.033010959625244
Validation loss: 2.054629769376529

Epoch: 5| Step: 8
Training loss: 1.7617629766464233
Validation loss: 2.0371395759685065

Epoch: 5| Step: 9
Training loss: 1.90911066532135
Validation loss: 2.064889259235833

Epoch: 5| Step: 10
Training loss: 2.1637868881225586
Validation loss: 2.04918691291604

Epoch: 465| Step: 0
Training loss: 2.0462822914123535
Validation loss: 2.0593476910744943

Epoch: 5| Step: 1
Training loss: 2.543778896331787
Validation loss: 2.0394862057060323

Epoch: 5| Step: 2
Training loss: 1.507551908493042
Validation loss: 2.040272223052158

Epoch: 5| Step: 3
Training loss: 2.597592830657959
Validation loss: 2.0531657536824546

Epoch: 5| Step: 4
Training loss: 2.3456673622131348
Validation loss: 2.036082757416592

Epoch: 5| Step: 5
Training loss: 1.4793370962142944
Validation loss: 2.0458045518526466

Epoch: 5| Step: 6
Training loss: 1.636490821838379
Validation loss: 2.051146707227153

Epoch: 5| Step: 7
Training loss: 1.8649415969848633
Validation loss: 2.057377189718267

Epoch: 5| Step: 8
Training loss: 1.8739875555038452
Validation loss: 2.0723010224680745

Epoch: 5| Step: 9
Training loss: 2.0588583946228027
Validation loss: 2.067457701570244

Epoch: 5| Step: 10
Training loss: 2.18648099899292
Validation loss: 2.0619334315740936

Epoch: 466| Step: 0
Training loss: 1.7478482723236084
Validation loss: 2.0689305900245585

Epoch: 5| Step: 1
Training loss: 2.2962608337402344
Validation loss: 2.069632864767505

Epoch: 5| Step: 2
Training loss: 2.725461006164551
Validation loss: 2.0775658597228346

Epoch: 5| Step: 3
Training loss: 2.504152297973633
Validation loss: 2.055773760682793

Epoch: 5| Step: 4
Training loss: 1.5341358184814453
Validation loss: 2.0748562018076577

Epoch: 5| Step: 5
Training loss: 1.7014414072036743
Validation loss: 2.062755725717032

Epoch: 5| Step: 6
Training loss: 2.0882654190063477
Validation loss: 2.04147703929614

Epoch: 5| Step: 7
Training loss: 2.6228420734405518
Validation loss: 2.0459945509510655

Epoch: 5| Step: 8
Training loss: 1.5380523204803467
Validation loss: 2.0373941313835884

Epoch: 5| Step: 9
Training loss: 1.7239993810653687
Validation loss: 2.046809099053824

Epoch: 5| Step: 10
Training loss: 1.573431372642517
Validation loss: 2.0379122816106325

Epoch: 467| Step: 0
Training loss: 1.7791023254394531
Validation loss: 2.0534972247257026

Epoch: 5| Step: 1
Training loss: 1.9529212713241577
Validation loss: 2.0425463414961293

Epoch: 5| Step: 2
Training loss: 2.1191439628601074
Validation loss: 2.043949919362222

Epoch: 5| Step: 3
Training loss: 2.293311595916748
Validation loss: 2.0450726221966486

Epoch: 5| Step: 4
Training loss: 1.4857487678527832
Validation loss: 2.038446012363639

Epoch: 5| Step: 5
Training loss: 2.565190076828003
Validation loss: 2.0759268255643946

Epoch: 5| Step: 6
Training loss: 2.308718204498291
Validation loss: 2.0485664016457013

Epoch: 5| Step: 7
Training loss: 2.066455364227295
Validation loss: 2.0436873307792087

Epoch: 5| Step: 8
Training loss: 2.4118380546569824
Validation loss: 2.0438868409843853

Epoch: 5| Step: 9
Training loss: 1.8659414052963257
Validation loss: 2.049445236882856

Epoch: 5| Step: 10
Training loss: 1.1304874420166016
Validation loss: 2.0400943102375155

Epoch: 468| Step: 0
Training loss: 1.37466561794281
Validation loss: 2.047935060275498

Epoch: 5| Step: 1
Training loss: 1.7180951833724976
Validation loss: 2.0581336444424045

Epoch: 5| Step: 2
Training loss: 2.4191086292266846
Validation loss: 2.079977289322884

Epoch: 5| Step: 3
Training loss: 2.3973817825317383
Validation loss: 2.0791649715874785

Epoch: 5| Step: 4
Training loss: 1.652199387550354
Validation loss: 2.0695128569038967

Epoch: 5| Step: 5
Training loss: 2.413146495819092
Validation loss: 2.0411108539950464

Epoch: 5| Step: 6
Training loss: 1.8229939937591553
Validation loss: 2.0223276345960555

Epoch: 5| Step: 7
Training loss: 2.8343183994293213
Validation loss: 2.0268940207778767

Epoch: 5| Step: 8
Training loss: 2.202650547027588
Validation loss: 2.0280529414453814

Epoch: 5| Step: 9
Training loss: 1.6406395435333252
Validation loss: 2.0249370221168763

Epoch: 5| Step: 10
Training loss: 1.7125930786132812
Validation loss: 2.020957266130755

Epoch: 469| Step: 0
Training loss: 1.8954511880874634
Validation loss: 2.0370373982255177

Epoch: 5| Step: 1
Training loss: 1.8817565441131592
Validation loss: 2.0310194671794934

Epoch: 5| Step: 2
Training loss: 1.980376958847046
Validation loss: 2.0339085696845927

Epoch: 5| Step: 3
Training loss: 2.310385227203369
Validation loss: 2.0587041121657177

Epoch: 5| Step: 4
Training loss: 1.9234600067138672
Validation loss: 2.083879710525595

Epoch: 5| Step: 5
Training loss: 1.6505966186523438
Validation loss: 2.0704339345296225

Epoch: 5| Step: 6
Training loss: 2.3796591758728027
Validation loss: 2.060665540797736

Epoch: 5| Step: 7
Training loss: 1.4928033351898193
Validation loss: 2.0339593733510664

Epoch: 5| Step: 8
Training loss: 2.173906087875366
Validation loss: 2.0529909480002617

Epoch: 5| Step: 9
Training loss: 2.3782029151916504
Validation loss: 2.053774764460902

Epoch: 5| Step: 10
Training loss: 2.2437660694122314
Validation loss: 2.044598379442769

Epoch: 470| Step: 0
Training loss: 2.326066493988037
Validation loss: 2.0473323227256857

Epoch: 5| Step: 1
Training loss: 1.8913135528564453
Validation loss: 2.0412234080735074

Epoch: 5| Step: 2
Training loss: 2.097301959991455
Validation loss: 2.0644155984283774

Epoch: 5| Step: 3
Training loss: 2.086296796798706
Validation loss: 2.0304708455198552

Epoch: 5| Step: 4
Training loss: 1.9145418405532837
Validation loss: 2.029930494164908

Epoch: 5| Step: 5
Training loss: 2.4896504878997803
Validation loss: 2.0359295593794955

Epoch: 5| Step: 6
Training loss: 1.9542922973632812
Validation loss: 2.045843405108298

Epoch: 5| Step: 7
Training loss: 2.157583713531494
Validation loss: 2.0542626637284473

Epoch: 5| Step: 8
Training loss: 1.6337257623672485
Validation loss: 2.050434591949627

Epoch: 5| Step: 9
Training loss: 1.873081922531128
Validation loss: 2.0687408613902267

Epoch: 5| Step: 10
Training loss: 1.4760924577713013
Validation loss: 2.0678923463308685

Epoch: 471| Step: 0
Training loss: 2.016467332839966
Validation loss: 2.055900199438936

Epoch: 5| Step: 1
Training loss: 1.7846558094024658
Validation loss: 2.0642077653638777

Epoch: 5| Step: 2
Training loss: 2.379202365875244
Validation loss: 2.042681017229634

Epoch: 5| Step: 3
Training loss: 2.005539655685425
Validation loss: 2.037384040894047

Epoch: 5| Step: 4
Training loss: 2.310234546661377
Validation loss: 2.035328882996754

Epoch: 5| Step: 5
Training loss: 1.6218976974487305
Validation loss: 2.0309500668638494

Epoch: 5| Step: 6
Training loss: 2.273284435272217
Validation loss: 2.0206294867300216

Epoch: 5| Step: 7
Training loss: 2.0960021018981934
Validation loss: 2.025899916566828

Epoch: 5| Step: 8
Training loss: 1.8542745113372803
Validation loss: 2.0304106127831245

Epoch: 5| Step: 9
Training loss: 1.4023230075836182
Validation loss: 2.0304269752194806

Epoch: 5| Step: 10
Training loss: 2.3265960216522217
Validation loss: 2.0355434251087967

Epoch: 472| Step: 0
Training loss: 2.0717990398406982
Validation loss: 2.026397171840873

Epoch: 5| Step: 1
Training loss: 1.7083427906036377
Validation loss: 2.0364930155456706

Epoch: 5| Step: 2
Training loss: 1.7617183923721313
Validation loss: 2.049901161142575

Epoch: 5| Step: 3
Training loss: 1.9769792556762695
Validation loss: 2.0188972847436064

Epoch: 5| Step: 4
Training loss: 2.7447409629821777
Validation loss: 2.0473283567736225

Epoch: 5| Step: 5
Training loss: 2.2258429527282715
Validation loss: 2.042559107144674

Epoch: 5| Step: 6
Training loss: 1.6274044513702393
Validation loss: 2.045790021137525

Epoch: 5| Step: 7
Training loss: 2.024893283843994
Validation loss: 2.043497065062164

Epoch: 5| Step: 8
Training loss: 2.113882541656494
Validation loss: 2.024598647189397

Epoch: 5| Step: 9
Training loss: 2.350754499435425
Validation loss: 2.0543359992324666

Epoch: 5| Step: 10
Training loss: 1.2423160076141357
Validation loss: 2.0435681317442205

Epoch: 473| Step: 0
Training loss: 2.100501537322998
Validation loss: 2.041575515142051

Epoch: 5| Step: 1
Training loss: 1.9389785528182983
Validation loss: 2.019883022513441

Epoch: 5| Step: 2
Training loss: 1.7444305419921875
Validation loss: 2.0410010148120183

Epoch: 5| Step: 3
Training loss: 1.5312719345092773
Validation loss: 2.0326232217973277

Epoch: 5| Step: 4
Training loss: 1.7440881729125977
Validation loss: 2.0329133977172194

Epoch: 5| Step: 5
Training loss: 2.052610397338867
Validation loss: 2.055445546744972

Epoch: 5| Step: 6
Training loss: 2.2995355129241943
Validation loss: 2.0347955201261785

Epoch: 5| Step: 7
Training loss: 2.566336154937744
Validation loss: 2.045967816024698

Epoch: 5| Step: 8
Training loss: 1.9560401439666748
Validation loss: 2.0397031691766556

Epoch: 5| Step: 9
Training loss: 2.1482319831848145
Validation loss: 2.0407680221783218

Epoch: 5| Step: 10
Training loss: 1.8273206949234009
Validation loss: 2.0360989634708693

Epoch: 474| Step: 0
Training loss: 2.3291945457458496
Validation loss: 2.0344578719908193

Epoch: 5| Step: 1
Training loss: 1.2996107339859009
Validation loss: 2.0611502662781747

Epoch: 5| Step: 2
Training loss: 2.0581741333007812
Validation loss: 2.07145756547169

Epoch: 5| Step: 3
Training loss: 2.395254373550415
Validation loss: 2.053086401313864

Epoch: 5| Step: 4
Training loss: 1.8552830219268799
Validation loss: 2.0564300014126684

Epoch: 5| Step: 5
Training loss: 1.5020530223846436
Validation loss: 2.056604072611819

Epoch: 5| Step: 6
Training loss: 2.090071439743042
Validation loss: 2.0279484025893675

Epoch: 5| Step: 7
Training loss: 2.1774349212646484
Validation loss: 2.0144710566407893

Epoch: 5| Step: 8
Training loss: 1.8293660879135132
Validation loss: 2.013645318246657

Epoch: 5| Step: 9
Training loss: 1.8805888891220093
Validation loss: 2.035218354194395

Epoch: 5| Step: 10
Training loss: 2.601602792739868
Validation loss: 2.0265810335836103

Epoch: 475| Step: 0
Training loss: 1.8695249557495117
Validation loss: 2.0321003467805925

Epoch: 5| Step: 1
Training loss: 1.981180191040039
Validation loss: 2.0415361171127646

Epoch: 5| Step: 2
Training loss: 2.132218837738037
Validation loss: 2.036266044903827

Epoch: 5| Step: 3
Training loss: 2.2486045360565186
Validation loss: 2.0527063133896037

Epoch: 5| Step: 4
Training loss: 1.9042946100234985
Validation loss: 2.0338874863040064

Epoch: 5| Step: 5
Training loss: 1.7879302501678467
Validation loss: 2.020240778564125

Epoch: 5| Step: 6
Training loss: 1.900922417640686
Validation loss: 2.0206318568157893

Epoch: 5| Step: 7
Training loss: 2.3387162685394287
Validation loss: 2.0306712042900825

Epoch: 5| Step: 8
Training loss: 2.0114924907684326
Validation loss: 2.0312696413327287

Epoch: 5| Step: 9
Training loss: 1.8469899892807007
Validation loss: 2.03429280173394

Epoch: 5| Step: 10
Training loss: 1.895459771156311
Validation loss: 2.0489041856540147

Epoch: 476| Step: 0
Training loss: 2.033064365386963
Validation loss: 2.050348945843276

Epoch: 5| Step: 1
Training loss: 2.0570521354675293
Validation loss: 2.0533004089068343

Epoch: 5| Step: 2
Training loss: 2.382019281387329
Validation loss: 2.070986568286855

Epoch: 5| Step: 3
Training loss: 2.190967082977295
Validation loss: 2.063298776585569

Epoch: 5| Step: 4
Training loss: 1.7385097742080688
Validation loss: 2.0650552318942164

Epoch: 5| Step: 5
Training loss: 1.5034202337265015
Validation loss: 2.048883209946335

Epoch: 5| Step: 6
Training loss: 2.133847713470459
Validation loss: 2.0412023452020462

Epoch: 5| Step: 7
Training loss: 2.214123249053955
Validation loss: 2.032999179696524

Epoch: 5| Step: 8
Training loss: 1.6547975540161133
Validation loss: 2.0271878396311114

Epoch: 5| Step: 9
Training loss: 2.0045933723449707
Validation loss: 2.0269356876291256

Epoch: 5| Step: 10
Training loss: 1.9926643371582031
Validation loss: 2.03884639534899

Epoch: 477| Step: 0
Training loss: 1.8236726522445679
Validation loss: 2.028160814316042

Epoch: 5| Step: 1
Training loss: 2.1806693077087402
Validation loss: 2.0374285572318622

Epoch: 5| Step: 2
Training loss: 2.371875524520874
Validation loss: 2.0388211973251833

Epoch: 5| Step: 3
Training loss: 1.5307542085647583
Validation loss: 2.0274105687295236

Epoch: 5| Step: 4
Training loss: 1.964076042175293
Validation loss: 2.048763685328986

Epoch: 5| Step: 5
Training loss: 2.2155754566192627
Validation loss: 2.0528173651746524

Epoch: 5| Step: 6
Training loss: 2.28539776802063
Validation loss: 2.033933378035022

Epoch: 5| Step: 7
Training loss: 2.073819160461426
Validation loss: 2.0217473686382337

Epoch: 5| Step: 8
Training loss: 2.0304527282714844
Validation loss: 2.030678164574408

Epoch: 5| Step: 9
Training loss: 1.6065107583999634
Validation loss: 2.0214947359536284

Epoch: 5| Step: 10
Training loss: 1.646113634109497
Validation loss: 2.035122561198409

Epoch: 478| Step: 0
Training loss: 2.156055450439453
Validation loss: 2.016497478690199

Epoch: 5| Step: 1
Training loss: 1.9966961145401
Validation loss: 2.027233474998064

Epoch: 5| Step: 2
Training loss: 1.7924261093139648
Validation loss: 2.027507423072733

Epoch: 5| Step: 3
Training loss: 2.2282626628875732
Validation loss: 2.0258702488355738

Epoch: 5| Step: 4
Training loss: 1.6741546392440796
Validation loss: 2.028644161839639

Epoch: 5| Step: 5
Training loss: 2.0961925983428955
Validation loss: 2.039413759785314

Epoch: 5| Step: 6
Training loss: 1.678394079208374
Validation loss: 2.0336527670583417

Epoch: 5| Step: 7
Training loss: 1.8902451992034912
Validation loss: 2.04384526898784

Epoch: 5| Step: 8
Training loss: 2.0030252933502197
Validation loss: 2.0366270055053053

Epoch: 5| Step: 9
Training loss: 2.116217851638794
Validation loss: 2.019988859853437

Epoch: 5| Step: 10
Training loss: 2.1685400009155273
Validation loss: 2.0414838867802776

Epoch: 479| Step: 0
Training loss: 1.800326943397522
Validation loss: 2.0253487415211175

Epoch: 5| Step: 1
Training loss: 2.6359055042266846
Validation loss: 2.0374667106136197

Epoch: 5| Step: 2
Training loss: 2.469287395477295
Validation loss: 2.041856813174422

Epoch: 5| Step: 3
Training loss: 1.8614050149917603
Validation loss: 2.0374308734811764

Epoch: 5| Step: 4
Training loss: 2.1251590251922607
Validation loss: 2.031162310672063

Epoch: 5| Step: 5
Training loss: 2.6128294467926025
Validation loss: 2.024135253762686

Epoch: 5| Step: 6
Training loss: 2.0456137657165527
Validation loss: 2.0429112052404754

Epoch: 5| Step: 7
Training loss: 1.5428060293197632
Validation loss: 2.030258560693392

Epoch: 5| Step: 8
Training loss: 1.5164439678192139
Validation loss: 2.0397390447637087

Epoch: 5| Step: 9
Training loss: 1.2992626428604126
Validation loss: 2.0476333377181843

Epoch: 5| Step: 10
Training loss: 1.7691984176635742
Validation loss: 2.036831627609909

Epoch: 480| Step: 0
Training loss: 1.8036867380142212
Validation loss: 2.0440910477792062

Epoch: 5| Step: 1
Training loss: 1.7542377710342407
Validation loss: 2.0277357050167617

Epoch: 5| Step: 2
Training loss: 1.7314319610595703
Validation loss: 2.0399805691934403

Epoch: 5| Step: 3
Training loss: 1.7050373554229736
Validation loss: 2.046068360728602

Epoch: 5| Step: 4
Training loss: 2.524691343307495
Validation loss: 2.049325789174726

Epoch: 5| Step: 5
Training loss: 2.058004140853882
Validation loss: 2.055655930631904

Epoch: 5| Step: 6
Training loss: 1.7087100744247437
Validation loss: 2.040297705640075

Epoch: 5| Step: 7
Training loss: 1.7693212032318115
Validation loss: 2.0357039256762435

Epoch: 5| Step: 8
Training loss: 1.9907249212265015
Validation loss: 2.038391723427721

Epoch: 5| Step: 9
Training loss: 2.0494556427001953
Validation loss: 2.06690021996857

Epoch: 5| Step: 10
Training loss: 2.7567524909973145
Validation loss: 2.056186294042936

Epoch: 481| Step: 0
Training loss: 1.5974373817443848
Validation loss: 2.0306337251458118

Epoch: 5| Step: 1
Training loss: 1.8038164377212524
Validation loss: 2.0287620457269813

Epoch: 5| Step: 2
Training loss: 2.1220641136169434
Validation loss: 2.02055501168774

Epoch: 5| Step: 3
Training loss: 2.3413286209106445
Validation loss: 2.0312112223717476

Epoch: 5| Step: 4
Training loss: 2.182610034942627
Validation loss: 2.017442105918802

Epoch: 5| Step: 5
Training loss: 1.77985417842865
Validation loss: 2.0405842822085143

Epoch: 5| Step: 6
Training loss: 1.7801506519317627
Validation loss: 2.0407080919511857

Epoch: 5| Step: 7
Training loss: 2.093981981277466
Validation loss: 2.0378172192522275

Epoch: 5| Step: 8
Training loss: 1.9874629974365234
Validation loss: 2.0245260346320366

Epoch: 5| Step: 9
Training loss: 2.016244649887085
Validation loss: 2.059923488606689

Epoch: 5| Step: 10
Training loss: 1.9645493030548096
Validation loss: 2.046042598703856

Epoch: 482| Step: 0
Training loss: 2.1419358253479004
Validation loss: 2.031908389060728

Epoch: 5| Step: 1
Training loss: 2.036139965057373
Validation loss: 2.040150865431755

Epoch: 5| Step: 2
Training loss: 1.7060606479644775
Validation loss: 2.0332348231346375

Epoch: 5| Step: 3
Training loss: 1.5915708541870117
Validation loss: 2.0363181021905716

Epoch: 5| Step: 4
Training loss: 1.9388539791107178
Validation loss: 2.0427421600587907

Epoch: 5| Step: 5
Training loss: 2.1731410026550293
Validation loss: 2.045989759506718

Epoch: 5| Step: 6
Training loss: 2.415592670440674
Validation loss: 2.027149456803517

Epoch: 5| Step: 7
Training loss: 1.9072058200836182
Validation loss: 2.035118838792206

Epoch: 5| Step: 8
Training loss: 2.2056074142456055
Validation loss: 2.038296221404947

Epoch: 5| Step: 9
Training loss: 1.885135293006897
Validation loss: 2.028603434562683

Epoch: 5| Step: 10
Training loss: 1.6440610885620117
Validation loss: 2.0323959025003577

Epoch: 483| Step: 0
Training loss: 2.591010570526123
Validation loss: 2.0381182162992415

Epoch: 5| Step: 1
Training loss: 1.6562000513076782
Validation loss: 2.0439589356863372

Epoch: 5| Step: 2
Training loss: 2.246598482131958
Validation loss: 2.0754091919109388

Epoch: 5| Step: 3
Training loss: 1.5056307315826416
Validation loss: 2.0430747924312467

Epoch: 5| Step: 4
Training loss: 1.538386344909668
Validation loss: 2.0545549033790507

Epoch: 5| Step: 5
Training loss: 1.7463699579238892
Validation loss: 2.033964093013476

Epoch: 5| Step: 6
Training loss: 1.8706789016723633
Validation loss: 2.0238598200582687

Epoch: 5| Step: 7
Training loss: 1.39444100856781
Validation loss: 2.05756974733004

Epoch: 5| Step: 8
Training loss: 2.573643207550049
Validation loss: 2.0442986770342757

Epoch: 5| Step: 9
Training loss: 1.7781654596328735
Validation loss: 2.0358929505912204

Epoch: 5| Step: 10
Training loss: 2.898043632507324
Validation loss: 2.0418780311461417

Epoch: 484| Step: 0
Training loss: 1.5486371517181396
Validation loss: 2.0334807019079886

Epoch: 5| Step: 1
Training loss: 1.8868004083633423
Validation loss: 2.013781432182558

Epoch: 5| Step: 2
Training loss: 2.230494737625122
Validation loss: 2.0277290485238515

Epoch: 5| Step: 3
Training loss: 2.3291709423065186
Validation loss: 2.0226973231120775

Epoch: 5| Step: 4
Training loss: 1.9259850978851318
Validation loss: 2.025284141622564

Epoch: 5| Step: 5
Training loss: 2.1787269115448
Validation loss: 2.0171582519367175

Epoch: 5| Step: 6
Training loss: 2.3445489406585693
Validation loss: 2.0371891529329362

Epoch: 5| Step: 7
Training loss: 2.0218520164489746
Validation loss: 2.0343742062968593

Epoch: 5| Step: 8
Training loss: 1.900498390197754
Validation loss: 2.0274197491266395

Epoch: 5| Step: 9
Training loss: 1.5913984775543213
Validation loss: 2.015953638220346

Epoch: 5| Step: 10
Training loss: 1.644979476928711
Validation loss: 2.0320048537305606

Epoch: 485| Step: 0
Training loss: 1.9760119915008545
Validation loss: 2.029182862210017

Epoch: 5| Step: 1
Training loss: 1.3442652225494385
Validation loss: 2.0376966345694756

Epoch: 5| Step: 2
Training loss: 1.6099284887313843
Validation loss: 2.0391724007104033

Epoch: 5| Step: 3
Training loss: 2.3447329998016357
Validation loss: 2.0470539933891705

Epoch: 5| Step: 4
Training loss: 2.126542806625366
Validation loss: 2.0469727836629397

Epoch: 5| Step: 5
Training loss: 2.0732641220092773
Validation loss: 2.0452915442887174

Epoch: 5| Step: 6
Training loss: 1.9839366674423218
Validation loss: 2.0325773582663587

Epoch: 5| Step: 7
Training loss: 2.330195903778076
Validation loss: 2.0148232803549817

Epoch: 5| Step: 8
Training loss: 1.8899619579315186
Validation loss: 2.023102083513814

Epoch: 5| Step: 9
Training loss: 1.923006296157837
Validation loss: 2.041473695026931

Epoch: 5| Step: 10
Training loss: 2.1483683586120605
Validation loss: 2.0203901055038616

Epoch: 486| Step: 0
Training loss: 2.1835923194885254
Validation loss: 2.0288352248489216

Epoch: 5| Step: 1
Training loss: 2.0402464866638184
Validation loss: 2.0264130523127895

Epoch: 5| Step: 2
Training loss: 1.8092939853668213
Validation loss: 2.043236335118612

Epoch: 5| Step: 3
Training loss: 1.3824704885482788
Validation loss: 2.058242174886888

Epoch: 5| Step: 4
Training loss: 1.4996784925460815
Validation loss: 2.0595516415052515

Epoch: 5| Step: 5
Training loss: 1.8978099822998047
Validation loss: 2.037930137367659

Epoch: 5| Step: 6
Training loss: 1.9848734140396118
Validation loss: 2.0427934277442192

Epoch: 5| Step: 7
Training loss: 1.8983020782470703
Validation loss: 2.0258822530828495

Epoch: 5| Step: 8
Training loss: 2.072089672088623
Validation loss: 2.030722487357355

Epoch: 5| Step: 9
Training loss: 2.780985116958618
Validation loss: 2.0316322926552064

Epoch: 5| Step: 10
Training loss: 2.082913637161255
Validation loss: 2.019619846856722

Epoch: 487| Step: 0
Training loss: 1.9412429332733154
Validation loss: 2.033247240128056

Epoch: 5| Step: 1
Training loss: 2.2159502506256104
Validation loss: 2.0163789282562914

Epoch: 5| Step: 2
Training loss: 1.7855335474014282
Validation loss: 2.0332923422577562

Epoch: 5| Step: 3
Training loss: 2.200896978378296
Validation loss: 2.0105991824980705

Epoch: 5| Step: 4
Training loss: 1.7909988164901733
Validation loss: 2.0135444005330405

Epoch: 5| Step: 5
Training loss: 1.7403643131256104
Validation loss: 2.002405256353399

Epoch: 5| Step: 6
Training loss: 1.7693793773651123
Validation loss: 2.0078458670646913

Epoch: 5| Step: 7
Training loss: 2.050187349319458
Validation loss: 2.034736079554404

Epoch: 5| Step: 8
Training loss: 1.5907552242279053
Validation loss: 2.020400324175435

Epoch: 5| Step: 9
Training loss: 2.3681976795196533
Validation loss: 2.021766707461367

Epoch: 5| Step: 10
Training loss: 2.14394474029541
Validation loss: 2.026986555386615

Epoch: 488| Step: 0
Training loss: 2.491062879562378
Validation loss: 2.0196386908972137

Epoch: 5| Step: 1
Training loss: 1.613051176071167
Validation loss: 2.0370401156845914

Epoch: 5| Step: 2
Training loss: 2.0135769844055176
Validation loss: 2.0268622162521526

Epoch: 5| Step: 3
Training loss: 1.9745244979858398
Validation loss: 2.0452476829610844

Epoch: 5| Step: 4
Training loss: 2.0927164554595947
Validation loss: 2.033317523617898

Epoch: 5| Step: 5
Training loss: 1.9445412158966064
Validation loss: 2.0442201668216335

Epoch: 5| Step: 6
Training loss: 1.286811351776123
Validation loss: 2.05638462497342

Epoch: 5| Step: 7
Training loss: 2.172283887863159
Validation loss: 2.046082244124464

Epoch: 5| Step: 8
Training loss: 1.8941246271133423
Validation loss: 2.032457226066179

Epoch: 5| Step: 9
Training loss: 2.042562961578369
Validation loss: 2.034327877465115

Epoch: 5| Step: 10
Training loss: 2.1931357383728027
Validation loss: 2.0216699338728383

Epoch: 489| Step: 0
Training loss: 2.257699728012085
Validation loss: 2.0377832535774476

Epoch: 5| Step: 1
Training loss: 1.6051740646362305
Validation loss: 2.017773042442978

Epoch: 5| Step: 2
Training loss: 2.2027411460876465
Validation loss: 2.0003428151530604

Epoch: 5| Step: 3
Training loss: 2.0551669597625732
Validation loss: 2.0366967467851538

Epoch: 5| Step: 4
Training loss: 1.8983583450317383
Validation loss: 2.0139123739734774

Epoch: 5| Step: 5
Training loss: 2.6571037769317627
Validation loss: 2.0158528051068707

Epoch: 5| Step: 6
Training loss: 1.6854887008666992
Validation loss: 2.0036322429615963

Epoch: 5| Step: 7
Training loss: 1.8975791931152344
Validation loss: 2.0145616403190036

Epoch: 5| Step: 8
Training loss: 1.8241662979125977
Validation loss: 2.0184042402493056

Epoch: 5| Step: 9
Training loss: 1.7723360061645508
Validation loss: 2.034957503759733

Epoch: 5| Step: 10
Training loss: 1.8117506504058838
Validation loss: 2.033910841070196

Epoch: 490| Step: 0
Training loss: 1.7401901483535767
Validation loss: 2.046953735813018

Epoch: 5| Step: 1
Training loss: 1.7194201946258545
Validation loss: 2.0410894501593804

Epoch: 5| Step: 2
Training loss: 1.9637378454208374
Validation loss: 2.049172568064864

Epoch: 5| Step: 3
Training loss: 1.8193092346191406
Validation loss: 2.03992300392479

Epoch: 5| Step: 4
Training loss: 2.2336716651916504
Validation loss: 2.019206923823203

Epoch: 5| Step: 5
Training loss: 2.268996000289917
Validation loss: 2.014164927185223

Epoch: 5| Step: 6
Training loss: 1.758784532546997
Validation loss: 2.024260938808482

Epoch: 5| Step: 7
Training loss: 1.8291250467300415
Validation loss: 2.007947539770475

Epoch: 5| Step: 8
Training loss: 1.8168137073516846
Validation loss: 2.012860617329997

Epoch: 5| Step: 9
Training loss: 2.3873848915100098
Validation loss: 2.013711183301864

Epoch: 5| Step: 10
Training loss: 2.2686069011688232
Validation loss: 2.003278850227274

Epoch: 491| Step: 0
Training loss: 1.8838382959365845
Validation loss: 2.0172134740378267

Epoch: 5| Step: 1
Training loss: 1.6953233480453491
Validation loss: 2.0203759824076006

Epoch: 5| Step: 2
Training loss: 1.8647794723510742
Validation loss: 2.032651421844318

Epoch: 5| Step: 3
Training loss: 1.8530079126358032
Validation loss: 2.0796887977148897

Epoch: 5| Step: 4
Training loss: 1.7986853122711182
Validation loss: 2.122522384889664

Epoch: 5| Step: 5
Training loss: 2.35404896736145
Validation loss: 2.1378684043884277

Epoch: 5| Step: 6
Training loss: 1.9870579242706299
Validation loss: 2.073884843498148

Epoch: 5| Step: 7
Training loss: 1.6397281885147095
Validation loss: 2.071729875379993

Epoch: 5| Step: 8
Training loss: 2.3753323554992676
Validation loss: 2.0401110674745295

Epoch: 5| Step: 9
Training loss: 2.305934190750122
Validation loss: 2.0364807959525817

Epoch: 5| Step: 10
Training loss: 1.9908727407455444
Validation loss: 2.0615591259412867

Epoch: 492| Step: 0
Training loss: 1.5939710140228271
Validation loss: 2.0470153054883404

Epoch: 5| Step: 1
Training loss: 2.0510520935058594
Validation loss: 2.0384548582056516

Epoch: 5| Step: 2
Training loss: 2.0754637718200684
Validation loss: 2.020623258365098

Epoch: 5| Step: 3
Training loss: 2.3147921562194824
Validation loss: 2.0085358427416895

Epoch: 5| Step: 4
Training loss: 1.5555763244628906
Validation loss: 2.0336824770896667

Epoch: 5| Step: 5
Training loss: 1.612715721130371
Validation loss: 2.0349129630673315

Epoch: 5| Step: 6
Training loss: 1.872347116470337
Validation loss: 2.0198250765441568

Epoch: 5| Step: 7
Training loss: 1.9942009449005127
Validation loss: 2.005016392277133

Epoch: 5| Step: 8
Training loss: 2.148977518081665
Validation loss: 2.0299256591386694

Epoch: 5| Step: 9
Training loss: 1.8015260696411133
Validation loss: 2.0046906804525726

Epoch: 5| Step: 10
Training loss: 2.6140239238739014
Validation loss: 2.009197276125672

Epoch: 493| Step: 0
Training loss: 2.3989322185516357
Validation loss: 2.011856537993236

Epoch: 5| Step: 1
Training loss: 2.1137871742248535
Validation loss: 2.010174641045191

Epoch: 5| Step: 2
Training loss: 1.4527738094329834
Validation loss: 2.0116294455784622

Epoch: 5| Step: 3
Training loss: 1.8976755142211914
Validation loss: 2.013262169335478

Epoch: 5| Step: 4
Training loss: 2.1132898330688477
Validation loss: 2.007242009203921

Epoch: 5| Step: 5
Training loss: 1.4503599405288696
Validation loss: 2.031174800729239

Epoch: 5| Step: 6
Training loss: 1.8281444311141968
Validation loss: 2.0248975369238083

Epoch: 5| Step: 7
Training loss: 2.2124855518341064
Validation loss: 2.0370396619201987

Epoch: 5| Step: 8
Training loss: 1.9254779815673828
Validation loss: 2.022900786451114

Epoch: 5| Step: 9
Training loss: 2.3257575035095215
Validation loss: 2.0633666476895733

Epoch: 5| Step: 10
Training loss: 1.6640052795410156
Validation loss: 2.045201816866475

Epoch: 494| Step: 0
Training loss: 2.248411178588867
Validation loss: 2.0172931507069576

Epoch: 5| Step: 1
Training loss: 2.3067469596862793
Validation loss: 2.0120737885916107

Epoch: 5| Step: 2
Training loss: 1.6974855661392212
Validation loss: 2.021320912145799

Epoch: 5| Step: 3
Training loss: 1.8460134267807007
Validation loss: 2.0126881227698377

Epoch: 5| Step: 4
Training loss: 1.9013341665267944
Validation loss: 2.0178515962375108

Epoch: 5| Step: 5
Training loss: 2.300187587738037
Validation loss: 2.0074649690299906

Epoch: 5| Step: 6
Training loss: 1.1313300132751465
Validation loss: 2.0064599411461943

Epoch: 5| Step: 7
Training loss: 1.4522812366485596
Validation loss: 2.0327270197611984

Epoch: 5| Step: 8
Training loss: 1.7264331579208374
Validation loss: 2.0304558674494424

Epoch: 5| Step: 9
Training loss: 2.7212986946105957
Validation loss: 2.0338518311900478

Epoch: 5| Step: 10
Training loss: 2.2339882850646973
Validation loss: 2.042366620033018

Epoch: 495| Step: 0
Training loss: 1.2637180089950562
Validation loss: 2.0740901680402857

Epoch: 5| Step: 1
Training loss: 2.4519686698913574
Validation loss: 2.0902611106954594

Epoch: 5| Step: 2
Training loss: 2.018955945968628
Validation loss: 2.1053845369687645

Epoch: 5| Step: 3
Training loss: 1.9671690464019775
Validation loss: 2.0753955187336093

Epoch: 5| Step: 4
Training loss: 1.5902512073516846
Validation loss: 2.066843658365229

Epoch: 5| Step: 5
Training loss: 1.8200485706329346
Validation loss: 2.050888083314383

Epoch: 5| Step: 6
Training loss: 2.25551176071167
Validation loss: 2.029753669615715

Epoch: 5| Step: 7
Training loss: 1.8425220251083374
Validation loss: 2.026674732085197

Epoch: 5| Step: 8
Training loss: 2.3963773250579834
Validation loss: 2.020981995008325

Epoch: 5| Step: 9
Training loss: 1.643908143043518
Validation loss: 2.011204428570245

Epoch: 5| Step: 10
Training loss: 2.254484176635742
Validation loss: 2.0413717762116463

Epoch: 496| Step: 0
Training loss: 1.7545292377471924
Validation loss: 2.020479376598071

Epoch: 5| Step: 1
Training loss: 1.5075232982635498
Validation loss: 2.0138198252647155

Epoch: 5| Step: 2
Training loss: 2.195998430252075
Validation loss: 2.0248943169911704

Epoch: 5| Step: 3
Training loss: 1.8432410955429077
Validation loss: 2.04599093878141

Epoch: 5| Step: 4
Training loss: 2.2181763648986816
Validation loss: 2.052538546182776

Epoch: 5| Step: 5
Training loss: 2.120379686355591
Validation loss: 2.0798471563605854

Epoch: 5| Step: 6
Training loss: 2.117497205734253
Validation loss: 2.0663620143808346

Epoch: 5| Step: 7
Training loss: 1.6857101917266846
Validation loss: 2.048503368131576

Epoch: 5| Step: 8
Training loss: 2.0511603355407715
Validation loss: 2.0604975736269386

Epoch: 5| Step: 9
Training loss: 1.9660106897354126
Validation loss: 2.0531355796321744

Epoch: 5| Step: 10
Training loss: 2.310029983520508
Validation loss: 2.047803258383146

Epoch: 497| Step: 0
Training loss: 2.0156781673431396
Validation loss: 2.0245529477314284

Epoch: 5| Step: 1
Training loss: 1.8272325992584229
Validation loss: 2.0224016994558354

Epoch: 5| Step: 2
Training loss: 2.157055616378784
Validation loss: 2.019661094552727

Epoch: 5| Step: 3
Training loss: 2.1448323726654053
Validation loss: 2.0020632205470914

Epoch: 5| Step: 4
Training loss: 2.041287422180176
Validation loss: 2.0196139069013697

Epoch: 5| Step: 5
Training loss: 1.9144290685653687
Validation loss: 2.0050415762009157

Epoch: 5| Step: 6
Training loss: 2.1838748455047607
Validation loss: 2.0273052030994045

Epoch: 5| Step: 7
Training loss: 1.8109363317489624
Validation loss: 2.0239264452329246

Epoch: 5| Step: 8
Training loss: 2.0624046325683594
Validation loss: 2.029278650078722

Epoch: 5| Step: 9
Training loss: 1.529552698135376
Validation loss: 1.9966564255376016

Epoch: 5| Step: 10
Training loss: 1.7880563735961914
Validation loss: 2.023607950056753

Epoch: 498| Step: 0
Training loss: 1.9229710102081299
Validation loss: 2.030492680047148

Epoch: 5| Step: 1
Training loss: 2.209791898727417
Validation loss: 2.0264425969892934

Epoch: 5| Step: 2
Training loss: 1.5352696180343628
Validation loss: 2.0302333216513357

Epoch: 5| Step: 3
Training loss: 1.9119281768798828
Validation loss: 2.05229813437308

Epoch: 5| Step: 4
Training loss: 1.2442258596420288
Validation loss: 2.0245961886580273

Epoch: 5| Step: 5
Training loss: 2.8462345600128174
Validation loss: 2.0604341953031478

Epoch: 5| Step: 6
Training loss: 1.7957382202148438
Validation loss: 2.0213274417384977

Epoch: 5| Step: 7
Training loss: 2.426259994506836
Validation loss: 2.0282819629997335

Epoch: 5| Step: 8
Training loss: 2.264115571975708
Validation loss: 2.0244948017981743

Epoch: 5| Step: 9
Training loss: 1.4200851917266846
Validation loss: 2.0113768500666462

Epoch: 5| Step: 10
Training loss: 1.8575851917266846
Validation loss: 2.0109338324557067

Epoch: 499| Step: 0
Training loss: 1.9653114080429077
Validation loss: 2.030224612964097

Epoch: 5| Step: 1
Training loss: 2.330446481704712
Validation loss: 2.0247885488694712

Epoch: 5| Step: 2
Training loss: 1.5422252416610718
Validation loss: 2.013740103731873

Epoch: 5| Step: 3
Training loss: 1.8551336526870728
Validation loss: 2.0182644192890455

Epoch: 5| Step: 4
Training loss: 2.1565849781036377
Validation loss: 2.0191224569915445

Epoch: 5| Step: 5
Training loss: 1.7589079141616821
Validation loss: 2.038306342658176

Epoch: 5| Step: 6
Training loss: 2.2065234184265137
Validation loss: 2.027177756832492

Epoch: 5| Step: 7
Training loss: 1.89248788356781
Validation loss: 2.035642941792806

Epoch: 5| Step: 8
Training loss: 1.5811021327972412
Validation loss: 2.02620126611443

Epoch: 5| Step: 9
Training loss: 2.2890048027038574
Validation loss: 2.01886817332237

Epoch: 5| Step: 10
Training loss: 1.7897706031799316
Validation loss: 2.019465463135832

Epoch: 500| Step: 0
Training loss: 1.9606605768203735
Validation loss: 2.0216349594054686

Epoch: 5| Step: 1
Training loss: 2.375028133392334
Validation loss: 2.0217702786127725

Epoch: 5| Step: 2
Training loss: 1.7043224573135376
Validation loss: 2.0179829366745485

Epoch: 5| Step: 3
Training loss: 2.3793892860412598
Validation loss: 2.019803806017804

Epoch: 5| Step: 4
Training loss: 1.6286824941635132
Validation loss: 2.020750166267477

Epoch: 5| Step: 5
Training loss: 2.1354920864105225
Validation loss: 2.0389866739191036

Epoch: 5| Step: 6
Training loss: 1.6220178604125977
Validation loss: 2.0328236062039613

Epoch: 5| Step: 7
Training loss: 1.9667975902557373
Validation loss: 2.022133840027676

Epoch: 5| Step: 8
Training loss: 1.5851085186004639
Validation loss: 2.0500657250804286

Epoch: 5| Step: 9
Training loss: 1.972717523574829
Validation loss: 2.029188388137407

Epoch: 5| Step: 10
Training loss: 1.9619605541229248
Validation loss: 2.009142429597916

Epoch: 501| Step: 0
Training loss: 2.1779370307922363
Validation loss: 2.015159704351938

Epoch: 5| Step: 1
Training loss: 1.5415815114974976
Validation loss: 2.0118247180856685

Epoch: 5| Step: 2
Training loss: 2.1790122985839844
Validation loss: 2.014225798268472

Epoch: 5| Step: 3
Training loss: 1.953421950340271
Validation loss: 1.9976572631507792

Epoch: 5| Step: 4
Training loss: 1.8492857217788696
Validation loss: 2.028765647642074

Epoch: 5| Step: 5
Training loss: 2.0078320503234863
Validation loss: 2.0033782784656813

Epoch: 5| Step: 6
Training loss: 1.8980077505111694
Validation loss: 2.0065238962891283

Epoch: 5| Step: 7
Training loss: 1.615521788597107
Validation loss: 2.0096080328828547

Epoch: 5| Step: 8
Training loss: 2.1621482372283936
Validation loss: 2.0232525781918596

Epoch: 5| Step: 9
Training loss: 1.8824412822723389
Validation loss: 2.0089023395251204

Epoch: 5| Step: 10
Training loss: 2.0395543575286865
Validation loss: 2.0291536572158977

Epoch: 502| Step: 0
Training loss: 1.444668173789978
Validation loss: 2.0198434834839194

Epoch: 5| Step: 1
Training loss: 1.7708828449249268
Validation loss: 2.0334125385489514

Epoch: 5| Step: 2
Training loss: 1.4341893196105957
Validation loss: 2.045828988475184

Epoch: 5| Step: 3
Training loss: 1.8102281093597412
Validation loss: 2.054271618525187

Epoch: 5| Step: 4
Training loss: 1.93770432472229
Validation loss: 2.0535354370711953

Epoch: 5| Step: 5
Training loss: 1.6399322748184204
Validation loss: 2.0290498079792147

Epoch: 5| Step: 6
Training loss: 2.553452730178833
Validation loss: 2.021291007277786

Epoch: 5| Step: 7
Training loss: 2.392442464828491
Validation loss: 2.021810828998525

Epoch: 5| Step: 8
Training loss: 2.415825366973877
Validation loss: 2.017428518623434

Epoch: 5| Step: 9
Training loss: 1.8886058330535889
Validation loss: 2.0124471674683275

Epoch: 5| Step: 10
Training loss: 2.0349056720733643
Validation loss: 2.0113115900306293

Epoch: 503| Step: 0
Training loss: 2.0854976177215576
Validation loss: 2.007119829936694

Epoch: 5| Step: 1
Training loss: 1.635956048965454
Validation loss: 2.009099337362474

Epoch: 5| Step: 2
Training loss: 1.838658094406128
Validation loss: 1.9997155461260068

Epoch: 5| Step: 3
Training loss: 1.3259923458099365
Validation loss: 2.01416882904627

Epoch: 5| Step: 4
Training loss: 2.344729423522949
Validation loss: 2.0092150716371435

Epoch: 5| Step: 5
Training loss: 1.8585420846939087
Validation loss: 2.0159257406829507

Epoch: 5| Step: 6
Training loss: 1.8130733966827393
Validation loss: 2.0080453311243365

Epoch: 5| Step: 7
Training loss: 1.710019826889038
Validation loss: 2.0217983902141614

Epoch: 5| Step: 8
Training loss: 2.2799878120422363
Validation loss: 2.049129464293039

Epoch: 5| Step: 9
Training loss: 2.2493467330932617
Validation loss: 2.0450786852067515

Epoch: 5| Step: 10
Training loss: 2.1270813941955566
Validation loss: 2.0531359257236605

Epoch: 504| Step: 0
Training loss: 1.6789289712905884
Validation loss: 2.0300189038758636

Epoch: 5| Step: 1
Training loss: 2.101085901260376
Validation loss: 2.0464979756262993

Epoch: 5| Step: 2
Training loss: 1.7612987756729126
Validation loss: 2.034512027617424

Epoch: 5| Step: 3
Training loss: 2.6083102226257324
Validation loss: 2.0251492377250426

Epoch: 5| Step: 4
Training loss: 1.8506923913955688
Validation loss: 2.0315354524120206

Epoch: 5| Step: 5
Training loss: 1.3024879693984985
Validation loss: 2.02609081422129

Epoch: 5| Step: 6
Training loss: 1.3877052068710327
Validation loss: 2.027137371801561

Epoch: 5| Step: 7
Training loss: 2.8334851264953613
Validation loss: 2.015851313068021

Epoch: 5| Step: 8
Training loss: 1.749172568321228
Validation loss: 2.002015339430942

Epoch: 5| Step: 9
Training loss: 1.8783929347991943
Validation loss: 2.039673101517462

Epoch: 5| Step: 10
Training loss: 2.365549087524414
Validation loss: 2.0477265773280973

Epoch: 505| Step: 0
Training loss: 1.7951126098632812
Validation loss: 2.0481261822485153

Epoch: 5| Step: 1
Training loss: 2.5540642738342285
Validation loss: 2.041347457516578

Epoch: 5| Step: 2
Training loss: 1.6538499593734741
Validation loss: 2.036067161508786

Epoch: 5| Step: 3
Training loss: 1.7929178476333618
Validation loss: 2.0372464015919673

Epoch: 5| Step: 4
Training loss: 2.295565366744995
Validation loss: 2.034032360199959

Epoch: 5| Step: 5
Training loss: 1.4052237272262573
Validation loss: 1.9918268470353977

Epoch: 5| Step: 6
Training loss: 2.3757901191711426
Validation loss: 2.0020133269730436

Epoch: 5| Step: 7
Training loss: 1.3882405757904053
Validation loss: 2.009751050702987

Epoch: 5| Step: 8
Training loss: 2.4349212646484375
Validation loss: 2.0141699621754308

Epoch: 5| Step: 9
Training loss: 1.7189366817474365
Validation loss: 2.002879647798436

Epoch: 5| Step: 10
Training loss: 1.9451360702514648
Validation loss: 2.0138740949733283

Epoch: 506| Step: 0
Training loss: 1.535118818283081
Validation loss: 2.003962105320346

Epoch: 5| Step: 1
Training loss: 2.2744014263153076
Validation loss: 2.0094699475073043

Epoch: 5| Step: 2
Training loss: 1.3505289554595947
Validation loss: 2.0418904468577397

Epoch: 5| Step: 3
Training loss: 2.017538070678711
Validation loss: 2.0343400022035003

Epoch: 5| Step: 4
Training loss: 2.476135730743408
Validation loss: 2.0226022658809537

Epoch: 5| Step: 5
Training loss: 2.0997323989868164
Validation loss: 2.0249519899327266

Epoch: 5| Step: 6
Training loss: 1.6861317157745361
Validation loss: 2.0246219660646174

Epoch: 5| Step: 7
Training loss: 1.8461143970489502
Validation loss: 2.016776495082404

Epoch: 5| Step: 8
Training loss: 2.389841318130493
Validation loss: 2.0000681338771695

Epoch: 5| Step: 9
Training loss: 1.8702236413955688
Validation loss: 2.010311234381891

Epoch: 5| Step: 10
Training loss: 1.666332483291626
Validation loss: 2.0306253176863476

Epoch: 507| Step: 0
Training loss: 2.2194550037384033
Validation loss: 2.014417645751789

Epoch: 5| Step: 1
Training loss: 1.4143807888031006
Validation loss: 2.022897251190678

Epoch: 5| Step: 2
Training loss: 2.724146604537964
Validation loss: 2.05335578098092

Epoch: 5| Step: 3
Training loss: 1.7925751209259033
Validation loss: 2.041121925077131

Epoch: 5| Step: 4
Training loss: 1.8694032430648804
Validation loss: 2.030284877746336

Epoch: 5| Step: 5
Training loss: 1.795800805091858
Validation loss: 2.031673382687312

Epoch: 5| Step: 6
Training loss: 2.2273030281066895
Validation loss: 2.0203397299653743

Epoch: 5| Step: 7
Training loss: 1.8489668369293213
Validation loss: 2.0214544098864318

Epoch: 5| Step: 8
Training loss: 1.3832950592041016
Validation loss: 2.018795668437917

Epoch: 5| Step: 9
Training loss: 2.2261805534362793
Validation loss: 2.029563348780396

Epoch: 5| Step: 10
Training loss: 1.6336486339569092
Validation loss: 2.0183728228333178

Epoch: 508| Step: 0
Training loss: 2.144592523574829
Validation loss: 2.0259199706456994

Epoch: 5| Step: 1
Training loss: 1.8897387981414795
Validation loss: 2.0356903870900473

Epoch: 5| Step: 2
Training loss: 2.2925102710723877
Validation loss: 2.0368100135557112

Epoch: 5| Step: 3
Training loss: 1.76589834690094
Validation loss: 2.036143531081497

Epoch: 5| Step: 4
Training loss: 1.8831440210342407
Validation loss: 2.010524057572888

Epoch: 5| Step: 5
Training loss: 1.9039027690887451
Validation loss: 2.0103870079081547

Epoch: 5| Step: 6
Training loss: 2.3817734718322754
Validation loss: 2.0133793174579577

Epoch: 5| Step: 7
Training loss: 1.437743902206421
Validation loss: 2.0170560280481973

Epoch: 5| Step: 8
Training loss: 2.0330538749694824
Validation loss: 2.023849969269127

Epoch: 5| Step: 9
Training loss: 1.52622652053833
Validation loss: 2.029739978492901

Epoch: 5| Step: 10
Training loss: 1.9110697507858276
Validation loss: 2.012010633304555

Epoch: 509| Step: 0
Training loss: 2.1406025886535645
Validation loss: 2.0061442698201826

Epoch: 5| Step: 1
Training loss: 1.8736900091171265
Validation loss: 2.0329907786461616

Epoch: 5| Step: 2
Training loss: 2.2500064373016357
Validation loss: 2.001056230196389

Epoch: 5| Step: 3
Training loss: 1.849816083908081
Validation loss: 2.0042711201534478

Epoch: 5| Step: 4
Training loss: 1.781592607498169
Validation loss: 2.001892130862

Epoch: 5| Step: 5
Training loss: 1.4964393377304077
Validation loss: 2.0123624532453475

Epoch: 5| Step: 6
Training loss: 2.54777193069458
Validation loss: 2.0016963046084166

Epoch: 5| Step: 7
Training loss: 2.045217990875244
Validation loss: 2.0112554373279696

Epoch: 5| Step: 8
Training loss: 1.8747133016586304
Validation loss: 2.010835078454787

Epoch: 5| Step: 9
Training loss: 1.3170912265777588
Validation loss: 2.00321005493082

Epoch: 5| Step: 10
Training loss: 1.8678433895111084
Validation loss: 2.0038309635654574

Epoch: 510| Step: 0
Training loss: 1.9522813558578491
Validation loss: 2.0190192666105045

Epoch: 5| Step: 1
Training loss: 2.4286160469055176
Validation loss: 2.030030333867637

Epoch: 5| Step: 2
Training loss: 2.2445034980773926
Validation loss: 2.034507288727709

Epoch: 5| Step: 3
Training loss: 1.2641538381576538
Validation loss: 2.0268665564957487

Epoch: 5| Step: 4
Training loss: 2.357337236404419
Validation loss: 2.032216497646865

Epoch: 5| Step: 5
Training loss: 1.9097936153411865
Validation loss: 2.026072957182443

Epoch: 5| Step: 6
Training loss: 1.9554554224014282
Validation loss: 2.0048789901118123

Epoch: 5| Step: 7
Training loss: 1.5448471307754517
Validation loss: 2.003022893782585

Epoch: 5| Step: 8
Training loss: 1.8460562229156494
Validation loss: 2.008039802633306

Epoch: 5| Step: 9
Training loss: 2.2092156410217285
Validation loss: 2.0320177026974258

Epoch: 5| Step: 10
Training loss: 1.352785587310791
Validation loss: 2.035913667371196

Epoch: 511| Step: 0
Training loss: 1.8829452991485596
Validation loss: 2.033129015276509

Epoch: 5| Step: 1
Training loss: 2.289576292037964
Validation loss: 2.0206321003616496

Epoch: 5| Step: 2
Training loss: 2.4891438484191895
Validation loss: 2.017214557175995

Epoch: 5| Step: 3
Training loss: 1.861201286315918
Validation loss: 2.021363910808358

Epoch: 5| Step: 4
Training loss: 1.6800594329833984
Validation loss: 2.021187082413704

Epoch: 5| Step: 5
Training loss: 1.7568740844726562
Validation loss: 2.013516761923349

Epoch: 5| Step: 6
Training loss: 1.9987837076187134
Validation loss: 2.021086679991855

Epoch: 5| Step: 7
Training loss: 1.6454460620880127
Validation loss: 2.0184591367680538

Epoch: 5| Step: 8
Training loss: 1.5851329565048218
Validation loss: 2.022060723714931

Epoch: 5| Step: 9
Training loss: 2.3580288887023926
Validation loss: 2.035543913482338

Epoch: 5| Step: 10
Training loss: 1.571380376815796
Validation loss: 2.034020672562302

Epoch: 512| Step: 0
Training loss: 1.3078296184539795
Validation loss: 2.0282206009793025

Epoch: 5| Step: 1
Training loss: 1.2994427680969238
Validation loss: 2.041354151182277

Epoch: 5| Step: 2
Training loss: 2.098346471786499
Validation loss: 2.0498559346763034

Epoch: 5| Step: 3
Training loss: 2.3077800273895264
Validation loss: 2.046721758381013

Epoch: 5| Step: 4
Training loss: 2.3039798736572266
Validation loss: 2.027968047767557

Epoch: 5| Step: 5
Training loss: 2.436950206756592
Validation loss: 2.034839471181234

Epoch: 5| Step: 6
Training loss: 1.6950263977050781
Validation loss: 2.0369837309724543

Epoch: 5| Step: 7
Training loss: 1.986620545387268
Validation loss: 2.0172362891576623

Epoch: 5| Step: 8
Training loss: 1.970106840133667
Validation loss: 2.0129919064942228

Epoch: 5| Step: 9
Training loss: 2.2311415672302246
Validation loss: 2.0235533304111932

Epoch: 5| Step: 10
Training loss: 1.495064377784729
Validation loss: 2.013562930527554

Epoch: 513| Step: 0
Training loss: 1.307395339012146
Validation loss: 2.0189574610802437

Epoch: 5| Step: 1
Training loss: 2.279179096221924
Validation loss: 2.0115763371990574

Epoch: 5| Step: 2
Training loss: 1.856382966041565
Validation loss: 2.012687794623836

Epoch: 5| Step: 3
Training loss: 2.4305665493011475
Validation loss: 2.0165694247009935

Epoch: 5| Step: 4
Training loss: 1.670879602432251
Validation loss: 2.028380504218481

Epoch: 5| Step: 5
Training loss: 1.2008486986160278
Validation loss: 2.0571158752646497

Epoch: 5| Step: 6
Training loss: 2.595914840698242
Validation loss: 2.036794624020976

Epoch: 5| Step: 7
Training loss: 1.9668678045272827
Validation loss: 2.0762072878499187

Epoch: 5| Step: 8
Training loss: 1.80474853515625
Validation loss: 2.0477288564046225

Epoch: 5| Step: 9
Training loss: 1.9164148569107056
Validation loss: 2.050616818089639

Epoch: 5| Step: 10
Training loss: 2.124494791030884
Validation loss: 2.0363254918847034

Epoch: 514| Step: 0
Training loss: 2.115851640701294
Validation loss: 2.022055859206825

Epoch: 5| Step: 1
Training loss: 1.2563693523406982
Validation loss: 2.0201744110353532

Epoch: 5| Step: 2
Training loss: 1.8200557231903076
Validation loss: 1.9961273542014502

Epoch: 5| Step: 3
Training loss: 1.6502549648284912
Validation loss: 2.0055942586673203

Epoch: 5| Step: 4
Training loss: 1.4685677289962769
Validation loss: 2.009896737273021

Epoch: 5| Step: 5
Training loss: 2.44773530960083
Validation loss: 2.01728533416666

Epoch: 5| Step: 6
Training loss: 2.413008689880371
Validation loss: 2.0242516686839442

Epoch: 5| Step: 7
Training loss: 1.6510289907455444
Validation loss: 2.0124126929108814

Epoch: 5| Step: 8
Training loss: 1.69059157371521
Validation loss: 2.0221409464395173

Epoch: 5| Step: 9
Training loss: 2.136003255844116
Validation loss: 2.044398848728467

Epoch: 5| Step: 10
Training loss: 2.535472869873047
Validation loss: 2.0338685230542253

Epoch: 515| Step: 0
Training loss: 1.755843162536621
Validation loss: 2.0259483296384095

Epoch: 5| Step: 1
Training loss: 1.8950684070587158
Validation loss: 2.034690705678796

Epoch: 5| Step: 2
Training loss: 1.6116622686386108
Validation loss: 2.016487347182407

Epoch: 5| Step: 3
Training loss: 1.94748055934906
Validation loss: 2.0144951497354815

Epoch: 5| Step: 4
Training loss: 2.3204448223114014
Validation loss: 2.0347933000133884

Epoch: 5| Step: 5
Training loss: 2.0141055583953857
Validation loss: 2.02553867396488

Epoch: 5| Step: 6
Training loss: 2.1402909755706787
Validation loss: 2.0257263234866563

Epoch: 5| Step: 7
Training loss: 1.723427176475525
Validation loss: 2.0162860180742

Epoch: 5| Step: 8
Training loss: 1.3922840356826782
Validation loss: 1.999859134356181

Epoch: 5| Step: 9
Training loss: 2.5548200607299805
Validation loss: 2.009532989994172

Epoch: 5| Step: 10
Training loss: 1.694169044494629
Validation loss: 2.016186398844565

Epoch: 516| Step: 0
Training loss: 2.036520004272461
Validation loss: 2.0138691932924333

Epoch: 5| Step: 1
Training loss: 2.124821901321411
Validation loss: 2.0187520519379647

Epoch: 5| Step: 2
Training loss: 2.1956546306610107
Validation loss: 2.004737332303037

Epoch: 5| Step: 3
Training loss: 1.4145708084106445
Validation loss: 2.011438032632233

Epoch: 5| Step: 4
Training loss: 2.5644335746765137
Validation loss: 2.0115975090252456

Epoch: 5| Step: 5
Training loss: 1.4253575801849365
Validation loss: 2.0164200798157723

Epoch: 5| Step: 6
Training loss: 1.4240326881408691
Validation loss: 2.010114218599053

Epoch: 5| Step: 7
Training loss: 2.058461904525757
Validation loss: 2.02915753984964

Epoch: 5| Step: 8
Training loss: 1.9902145862579346
Validation loss: 2.0140597717736357

Epoch: 5| Step: 9
Training loss: 1.4601595401763916
Validation loss: 2.029027667096866

Epoch: 5| Step: 10
Training loss: 2.3132524490356445
Validation loss: 2.0335028940631497

Epoch: 517| Step: 0
Training loss: 2.1038050651550293
Validation loss: 2.0315402361654464

Epoch: 5| Step: 1
Training loss: 1.545194149017334
Validation loss: 2.012574621426162

Epoch: 5| Step: 2
Training loss: 1.9722696542739868
Validation loss: 2.002982061396363

Epoch: 5| Step: 3
Training loss: 1.7879483699798584
Validation loss: 2.018277193910332

Epoch: 5| Step: 4
Training loss: 1.9831078052520752
Validation loss: 1.9932042270578363

Epoch: 5| Step: 5
Training loss: 1.7808711528778076
Validation loss: 2.011417450443391

Epoch: 5| Step: 6
Training loss: 1.7085826396942139
Validation loss: 2.0015366526060205

Epoch: 5| Step: 7
Training loss: 2.0496115684509277
Validation loss: 2.010283661145036

Epoch: 5| Step: 8
Training loss: 2.070011854171753
Validation loss: 2.0124591332609936

Epoch: 5| Step: 9
Training loss: 1.726872205734253
Validation loss: 2.0069111982981362

Epoch: 5| Step: 10
Training loss: 2.3070502281188965
Validation loss: 2.010733187839549

Epoch: 518| Step: 0
Training loss: 2.349613904953003
Validation loss: 2.0231515412689536

Epoch: 5| Step: 1
Training loss: 2.4209835529327393
Validation loss: 2.0315687194947274

Epoch: 5| Step: 2
Training loss: 2.0184531211853027
Validation loss: 2.0269487737327494

Epoch: 5| Step: 3
Training loss: 1.4927490949630737
Validation loss: 2.019538243611654

Epoch: 5| Step: 4
Training loss: 1.8763878345489502
Validation loss: 2.0225389542118197

Epoch: 5| Step: 5
Training loss: 1.2535040378570557
Validation loss: 2.008388630805477

Epoch: 5| Step: 6
Training loss: 2.0354928970336914
Validation loss: 2.0166405606013473

Epoch: 5| Step: 7
Training loss: 1.9370310306549072
Validation loss: 2.0351711985885457

Epoch: 5| Step: 8
Training loss: 1.9688215255737305
Validation loss: 2.0263779163360596

Epoch: 5| Step: 9
Training loss: 2.2854697704315186
Validation loss: 2.0180424772283083

Epoch: 5| Step: 10
Training loss: 1.0717856884002686
Validation loss: 2.0120954949368715

Epoch: 519| Step: 0
Training loss: 1.4649477005004883
Validation loss: 2.006433043428647

Epoch: 5| Step: 1
Training loss: 2.0201985836029053
Validation loss: 2.0066346558191444

Epoch: 5| Step: 2
Training loss: 1.3934520483016968
Validation loss: 2.0095445814953057

Epoch: 5| Step: 3
Training loss: 1.8247947692871094
Validation loss: 2.0208497483243226

Epoch: 5| Step: 4
Training loss: 2.1938161849975586
Validation loss: 1.9978038341768327

Epoch: 5| Step: 5
Training loss: 1.977927565574646
Validation loss: 2.002248267973623

Epoch: 5| Step: 6
Training loss: 1.5356154441833496
Validation loss: 2.0144749149199455

Epoch: 5| Step: 7
Training loss: 1.5332645177841187
Validation loss: 2.004859975589219

Epoch: 5| Step: 8
Training loss: 2.3334035873413086
Validation loss: 2.0005275152062856

Epoch: 5| Step: 9
Training loss: 2.242335081100464
Validation loss: 2.021377104584889

Epoch: 5| Step: 10
Training loss: 2.50793719291687
Validation loss: 2.0106957215134815

Epoch: 520| Step: 0
Training loss: 1.6045137643814087
Validation loss: 2.0007366262456423

Epoch: 5| Step: 1
Training loss: 1.5361337661743164
Validation loss: 2.0034055581656833

Epoch: 5| Step: 2
Training loss: 2.161388397216797
Validation loss: 2.0045793159033662

Epoch: 5| Step: 3
Training loss: 1.7191858291625977
Validation loss: 1.9968349190168484

Epoch: 5| Step: 4
Training loss: 2.503540277481079
Validation loss: 2.0126125261347783

Epoch: 5| Step: 5
Training loss: 1.6480987071990967
Validation loss: 1.9955086041522283

Epoch: 5| Step: 6
Training loss: 2.21242618560791
Validation loss: 2.003493209039011

Epoch: 5| Step: 7
Training loss: 2.083256483078003
Validation loss: 2.00363669344174

Epoch: 5| Step: 8
Training loss: 2.026893377304077
Validation loss: 2.0246805016712477

Epoch: 5| Step: 9
Training loss: 2.1077756881713867
Validation loss: 1.9933569405668525

Epoch: 5| Step: 10
Training loss: 1.2495101690292358
Validation loss: 2.0348147653764292

Epoch: 521| Step: 0
Training loss: 1.897717833518982
Validation loss: 2.0365626658162763

Epoch: 5| Step: 1
Training loss: 1.733764886856079
Validation loss: 2.0364652481130374

Epoch: 5| Step: 2
Training loss: 1.879668951034546
Validation loss: 2.021446389536704

Epoch: 5| Step: 3
Training loss: 1.2154563665390015
Validation loss: 2.0050499785330986

Epoch: 5| Step: 4
Training loss: 1.8794658184051514
Validation loss: 2.0002438765700146

Epoch: 5| Step: 5
Training loss: 2.250849485397339
Validation loss: 2.0014121301712526

Epoch: 5| Step: 6
Training loss: 1.5040185451507568
Validation loss: 1.9941886317345403

Epoch: 5| Step: 7
Training loss: 2.3886470794677734
Validation loss: 2.0153156172844673

Epoch: 5| Step: 8
Training loss: 1.6910957098007202
Validation loss: 2.021759630531393

Epoch: 5| Step: 9
Training loss: 2.047637462615967
Validation loss: 2.0129595482221214

Epoch: 5| Step: 10
Training loss: 2.506695508956909
Validation loss: 2.0187507919085923

Epoch: 522| Step: 0
Training loss: 1.698491096496582
Validation loss: 2.0207855304082236

Epoch: 5| Step: 1
Training loss: 1.8899829387664795
Validation loss: 2.035457247047014

Epoch: 5| Step: 2
Training loss: 2.042834997177124
Validation loss: 2.025203868906985

Epoch: 5| Step: 3
Training loss: 1.9080593585968018
Validation loss: 2.0105763917328208

Epoch: 5| Step: 4
Training loss: 1.9939048290252686
Validation loss: 2.006041016629947

Epoch: 5| Step: 5
Training loss: 1.990410566329956
Validation loss: 2.0342818485793246

Epoch: 5| Step: 6
Training loss: 1.4721729755401611
Validation loss: 2.020667809312062

Epoch: 5| Step: 7
Training loss: 1.491471767425537
Validation loss: 2.038232945626782

Epoch: 5| Step: 8
Training loss: 2.1898064613342285
Validation loss: 2.0257164060428576

Epoch: 5| Step: 9
Training loss: 1.7413721084594727
Validation loss: 2.0252100703536824

Epoch: 5| Step: 10
Training loss: 2.5325756072998047
Validation loss: 2.0046266125094507

Epoch: 523| Step: 0
Training loss: 1.6305220127105713
Validation loss: 1.9987438083976827

Epoch: 5| Step: 1
Training loss: 1.3450219631195068
Validation loss: 2.011662055087346

Epoch: 5| Step: 2
Training loss: 1.944604516029358
Validation loss: 2.047012316283359

Epoch: 5| Step: 3
Training loss: 2.195068836212158
Validation loss: 2.0266090875030844

Epoch: 5| Step: 4
Training loss: 1.909926414489746
Validation loss: 2.0277544939389793

Epoch: 5| Step: 5
Training loss: 1.539941668510437
Validation loss: 2.020546925965176

Epoch: 5| Step: 6
Training loss: 1.5191997289657593
Validation loss: 2.0191714148367605

Epoch: 5| Step: 7
Training loss: 1.7667258977890015
Validation loss: 1.9847770237153577

Epoch: 5| Step: 8
Training loss: 2.5510284900665283
Validation loss: 2.024590866540068

Epoch: 5| Step: 9
Training loss: 2.362898349761963
Validation loss: 2.0167164469277985

Epoch: 5| Step: 10
Training loss: 2.045700788497925
Validation loss: 1.9989082467171453

Epoch: 524| Step: 0
Training loss: 2.2822060585021973
Validation loss: 2.000161390150747

Epoch: 5| Step: 1
Training loss: 1.8588619232177734
Validation loss: 1.9969899731297647

Epoch: 5| Step: 2
Training loss: 1.5059982538223267
Validation loss: 1.9833577397049114

Epoch: 5| Step: 3
Training loss: 1.4888969659805298
Validation loss: 1.9931522543712328

Epoch: 5| Step: 4
Training loss: 2.035346508026123
Validation loss: 1.9983178825788601

Epoch: 5| Step: 5
Training loss: 1.0868715047836304
Validation loss: 2.0044129561352473

Epoch: 5| Step: 6
Training loss: 2.416536331176758
Validation loss: 2.022085428237915

Epoch: 5| Step: 7
Training loss: 1.3887670040130615
Validation loss: 2.0172860712133427

Epoch: 5| Step: 8
Training loss: 2.120120048522949
Validation loss: 2.0358804771977086

Epoch: 5| Step: 9
Training loss: 2.359266996383667
Validation loss: 2.029045994563769

Epoch: 5| Step: 10
Training loss: 2.412317991256714
Validation loss: 2.0301266806100005

Epoch: 525| Step: 0
Training loss: 2.0428519248962402
Validation loss: 2.0064997852489515

Epoch: 5| Step: 1
Training loss: 2.1994380950927734
Validation loss: 2.010956346347768

Epoch: 5| Step: 2
Training loss: 1.6445776224136353
Validation loss: 1.9994306833513322

Epoch: 5| Step: 3
Training loss: 2.218015670776367
Validation loss: 2.0009843918585006

Epoch: 5| Step: 4
Training loss: 2.3017945289611816
Validation loss: 1.9796298421839231

Epoch: 5| Step: 5
Training loss: 1.516316533088684
Validation loss: 1.991089928534723

Epoch: 5| Step: 6
Training loss: 1.4173885583877563
Validation loss: 1.989287107221542

Epoch: 5| Step: 7
Training loss: 1.5387051105499268
Validation loss: 1.9763318697611492

Epoch: 5| Step: 8
Training loss: 1.728074073791504
Validation loss: 1.9856429920401624

Epoch: 5| Step: 9
Training loss: 2.440760374069214
Validation loss: 2.0029812128313127

Epoch: 5| Step: 10
Training loss: 1.7664483785629272
Validation loss: 2.0174964499729935

Epoch: 526| Step: 0
Training loss: 1.7967002391815186
Validation loss: 2.033060992917707

Epoch: 5| Step: 1
Training loss: 2.3402321338653564
Validation loss: 2.043369335512961

Epoch: 5| Step: 2
Training loss: 1.2267049551010132
Validation loss: 2.0608882058051323

Epoch: 5| Step: 3
Training loss: 2.4263410568237305
Validation loss: 2.0470776609195176

Epoch: 5| Step: 4
Training loss: 2.3232498168945312
Validation loss: 2.020591915294688

Epoch: 5| Step: 5
Training loss: 1.4270213842391968
Validation loss: 2.006927021088139

Epoch: 5| Step: 6
Training loss: 1.9394201040267944
Validation loss: 2.025166460262832

Epoch: 5| Step: 7
Training loss: 1.7212114334106445
Validation loss: 2.001611973649712

Epoch: 5| Step: 8
Training loss: 1.7208044528961182
Validation loss: 1.982402684868023

Epoch: 5| Step: 9
Training loss: 2.2901394367218018
Validation loss: 1.9841162953325497

Epoch: 5| Step: 10
Training loss: 1.5710278749465942
Validation loss: 1.9941298141274402

Epoch: 527| Step: 0
Training loss: 2.2878708839416504
Validation loss: 2.007703532454788

Epoch: 5| Step: 1
Training loss: 1.935811996459961
Validation loss: 2.003660204590008

Epoch: 5| Step: 2
Training loss: 1.93252432346344
Validation loss: 2.027168047043585

Epoch: 5| Step: 3
Training loss: 2.544524669647217
Validation loss: 2.014862293838173

Epoch: 5| Step: 4
Training loss: 2.198889970779419
Validation loss: 2.0291151859427012

Epoch: 5| Step: 5
Training loss: 1.453318476676941
Validation loss: 2.0409802967502224

Epoch: 5| Step: 6
Training loss: 1.9949522018432617
Validation loss: 2.0574650533737673

Epoch: 5| Step: 7
Training loss: 1.5136486291885376
Validation loss: 2.024969211188696

Epoch: 5| Step: 8
Training loss: 1.6246801614761353
Validation loss: 2.0188677285307195

Epoch: 5| Step: 9
Training loss: 1.7872426509857178
Validation loss: 2.011841053603798

Epoch: 5| Step: 10
Training loss: 1.486485242843628
Validation loss: 2.006588464142174

Epoch: 528| Step: 0
Training loss: 1.6700252294540405
Validation loss: 1.9964706179916218

Epoch: 5| Step: 1
Training loss: 1.9951378107070923
Validation loss: 2.0017526354841007

Epoch: 5| Step: 2
Training loss: 1.6351776123046875
Validation loss: 2.002275541264524

Epoch: 5| Step: 3
Training loss: 1.7668492794036865
Validation loss: 2.0553222164030998

Epoch: 5| Step: 4
Training loss: 1.4054083824157715
Validation loss: 2.0369073447360786

Epoch: 5| Step: 5
Training loss: 1.9764995574951172
Validation loss: 2.0050842710720596

Epoch: 5| Step: 6
Training loss: 1.830204725265503
Validation loss: 1.9995158667205482

Epoch: 5| Step: 7
Training loss: 2.100802421569824
Validation loss: 1.9887195902486001

Epoch: 5| Step: 8
Training loss: 1.9184048175811768
Validation loss: 2.013692062388184

Epoch: 5| Step: 9
Training loss: 2.070474624633789
Validation loss: 1.9885969636260823

Epoch: 5| Step: 10
Training loss: 2.549098253250122
Validation loss: 1.993384366394371

Epoch: 529| Step: 0
Training loss: 2.0154168605804443
Validation loss: 1.9905262390772502

Epoch: 5| Step: 1
Training loss: 2.138430118560791
Validation loss: 1.983988082537087

Epoch: 5| Step: 2
Training loss: 2.0948991775512695
Validation loss: 2.0032235153259768

Epoch: 5| Step: 3
Training loss: 1.57146418094635
Validation loss: 2.00513118825933

Epoch: 5| Step: 4
Training loss: 1.5851353406906128
Validation loss: 2.01236899693807

Epoch: 5| Step: 5
Training loss: 1.744275689125061
Validation loss: 2.010646591904343

Epoch: 5| Step: 6
Training loss: 2.4080488681793213
Validation loss: 2.0193863735404065

Epoch: 5| Step: 7
Training loss: 2.177217721939087
Validation loss: 2.0181149462217927

Epoch: 5| Step: 8
Training loss: 1.02644944190979
Validation loss: 1.980657471123562

Epoch: 5| Step: 9
Training loss: 1.8703546524047852
Validation loss: 1.99947936560518

Epoch: 5| Step: 10
Training loss: 2.0809667110443115
Validation loss: 2.0080036732458297

Epoch: 530| Step: 0
Training loss: 2.0017149448394775
Validation loss: 2.00295550464302

Epoch: 5| Step: 1
Training loss: 2.0048303604125977
Validation loss: 2.0364372294436217

Epoch: 5| Step: 2
Training loss: 2.0200912952423096
Validation loss: 2.0534697155798636

Epoch: 5| Step: 3
Training loss: 1.6970806121826172
Validation loss: 2.0494328596258677

Epoch: 5| Step: 4
Training loss: 1.6486003398895264
Validation loss: 2.0529444832955637

Epoch: 5| Step: 5
Training loss: 1.8521225452423096
Validation loss: 2.020604569424865

Epoch: 5| Step: 6
Training loss: 1.5705301761627197
Validation loss: 2.0093502600987754

Epoch: 5| Step: 7
Training loss: 1.6358394622802734
Validation loss: 2.0103042292338547

Epoch: 5| Step: 8
Training loss: 2.155341148376465
Validation loss: 2.0172637265215636

Epoch: 5| Step: 9
Training loss: 2.2990520000457764
Validation loss: 2.0070358514785767

Epoch: 5| Step: 10
Training loss: 1.6333529949188232
Validation loss: 2.0035105366860666

Epoch: 531| Step: 0
Training loss: 1.7747440338134766
Validation loss: 2.000053628798454

Epoch: 5| Step: 1
Training loss: 1.6484482288360596
Validation loss: 1.9982880007836126

Epoch: 5| Step: 2
Training loss: 2.125281810760498
Validation loss: 2.014068954734392

Epoch: 5| Step: 3
Training loss: 1.7831119298934937
Validation loss: 1.9935680025367326

Epoch: 5| Step: 4
Training loss: 2.161139965057373
Validation loss: 1.9880339419969948

Epoch: 5| Step: 5
Training loss: 2.047811508178711
Validation loss: 2.002792012306952

Epoch: 5| Step: 6
Training loss: 1.7656971216201782
Validation loss: 2.0409155981515044

Epoch: 5| Step: 7
Training loss: 1.625189185142517
Validation loss: 2.043548422475015

Epoch: 5| Step: 8
Training loss: 2.314844846725464
Validation loss: 2.095806739663565

Epoch: 5| Step: 9
Training loss: 1.5011374950408936
Validation loss: 2.0860703824668803

Epoch: 5| Step: 10
Training loss: 2.071995258331299
Validation loss: 2.0283430186651086

Epoch: 532| Step: 0
Training loss: 2.56027889251709
Validation loss: 2.0279781382570983

Epoch: 5| Step: 1
Training loss: 1.3225643634796143
Validation loss: 2.00473831289558

Epoch: 5| Step: 2
Training loss: 1.4584543704986572
Validation loss: 2.0010250242807532

Epoch: 5| Step: 3
Training loss: 2.1771419048309326
Validation loss: 1.9865920210397372

Epoch: 5| Step: 4
Training loss: 1.2031093835830688
Validation loss: 1.9889549132316344

Epoch: 5| Step: 5
Training loss: 1.8548723459243774
Validation loss: 1.9769019708838513

Epoch: 5| Step: 6
Training loss: 2.0746142864227295
Validation loss: 1.9780220677775722

Epoch: 5| Step: 7
Training loss: 2.085456609725952
Validation loss: 1.992586176882508

Epoch: 5| Step: 8
Training loss: 2.450038433074951
Validation loss: 2.0084104204690583

Epoch: 5| Step: 9
Training loss: 1.8675520420074463
Validation loss: 1.9778210168243737

Epoch: 5| Step: 10
Training loss: 1.6500426530838013
Validation loss: 2.016032406078872

Epoch: 533| Step: 0
Training loss: 2.303586006164551
Validation loss: 2.0123853632198867

Epoch: 5| Step: 1
Training loss: 1.9530071020126343
Validation loss: 1.995689207507718

Epoch: 5| Step: 2
Training loss: 2.3049378395080566
Validation loss: 2.0306979827983405

Epoch: 5| Step: 3
Training loss: 2.650766611099243
Validation loss: 2.0256212090933197

Epoch: 5| Step: 4
Training loss: 1.4882068634033203
Validation loss: 2.017584018809821

Epoch: 5| Step: 5
Training loss: 1.5286558866500854
Validation loss: 2.0384284629616687

Epoch: 5| Step: 6
Training loss: 1.4853293895721436
Validation loss: 2.0057952711659093

Epoch: 5| Step: 7
Training loss: 1.742087960243225
Validation loss: 1.9947890645714217

Epoch: 5| Step: 8
Training loss: 1.2535234689712524
Validation loss: 1.9948596005798669

Epoch: 5| Step: 9
Training loss: 1.566235065460205
Validation loss: 2.0204982091021795

Epoch: 5| Step: 10
Training loss: 2.334627151489258
Validation loss: 2.0038482617306452

Epoch: 534| Step: 0
Training loss: 1.4592927694320679
Validation loss: 2.000824060491336

Epoch: 5| Step: 1
Training loss: 2.537158966064453
Validation loss: 2.002959325749387

Epoch: 5| Step: 2
Training loss: 1.6668615341186523
Validation loss: 1.9956651579949163

Epoch: 5| Step: 3
Training loss: 1.9342120885849
Validation loss: 1.996679889258518

Epoch: 5| Step: 4
Training loss: 1.778337836265564
Validation loss: 1.9962785397806475

Epoch: 5| Step: 5
Training loss: 1.7173864841461182
Validation loss: 2.0115872006262503

Epoch: 5| Step: 6
Training loss: 2.7848682403564453
Validation loss: 2.0024141880773727

Epoch: 5| Step: 7
Training loss: 1.7368491888046265
Validation loss: 1.978417520881981

Epoch: 5| Step: 8
Training loss: 1.1205968856811523
Validation loss: 1.9943220602568759

Epoch: 5| Step: 9
Training loss: 1.644158124923706
Validation loss: 2.0199740817469936

Epoch: 5| Step: 10
Training loss: 2.261168956756592
Validation loss: 2.0012257560606925

Epoch: 535| Step: 0
Training loss: 1.8973662853240967
Validation loss: 2.031024266314763

Epoch: 5| Step: 1
Training loss: 2.2785229682922363
Validation loss: 2.032683187915433

Epoch: 5| Step: 2
Training loss: 1.5361207723617554
Validation loss: 2.038124677955463

Epoch: 5| Step: 3
Training loss: 1.8620951175689697
Validation loss: 2.033722395538002

Epoch: 5| Step: 4
Training loss: 1.653728723526001
Validation loss: 2.0644092380359607

Epoch: 5| Step: 5
Training loss: 2.3444275856018066
Validation loss: 2.0301954284791024

Epoch: 5| Step: 6
Training loss: 2.3743343353271484
Validation loss: 2.013824707718306

Epoch: 5| Step: 7
Training loss: 1.3926292657852173
Validation loss: 1.9928356973073815

Epoch: 5| Step: 8
Training loss: 1.5090240240097046
Validation loss: 1.9895024966168147

Epoch: 5| Step: 9
Training loss: 1.8739032745361328
Validation loss: 1.9858188462513748

Epoch: 5| Step: 10
Training loss: 1.8685240745544434
Validation loss: 1.995946838009742

Epoch: 536| Step: 0
Training loss: 2.0119452476501465
Validation loss: 1.9786991688512987

Epoch: 5| Step: 1
Training loss: 1.9538676738739014
Validation loss: 1.9991815705453195

Epoch: 5| Step: 2
Training loss: 1.5607759952545166
Validation loss: 1.9977534547928841

Epoch: 5| Step: 3
Training loss: 2.2439656257629395
Validation loss: 1.9845708800900368

Epoch: 5| Step: 4
Training loss: 1.8497940301895142
Validation loss: 2.0085482161532164

Epoch: 5| Step: 5
Training loss: 2.254427909851074
Validation loss: 2.005782119689449

Epoch: 5| Step: 6
Training loss: 1.6364459991455078
Validation loss: 2.0256392084142214

Epoch: 5| Step: 7
Training loss: 1.5682495832443237
Validation loss: 2.0267537563077864

Epoch: 5| Step: 8
Training loss: 1.7145557403564453
Validation loss: 2.041661059984597

Epoch: 5| Step: 9
Training loss: 1.599034309387207
Validation loss: 2.0414936901420675

Epoch: 5| Step: 10
Training loss: 2.1379268169403076
Validation loss: 2.024475803939245

Epoch: 537| Step: 0
Training loss: 1.714450478553772
Validation loss: 2.0251733487652195

Epoch: 5| Step: 1
Training loss: 2.3892059326171875
Validation loss: 2.026515004455402

Epoch: 5| Step: 2
Training loss: 1.3555214405059814
Validation loss: 2.0091340003475064

Epoch: 5| Step: 3
Training loss: 1.1531572341918945
Validation loss: 1.9973369977807487

Epoch: 5| Step: 4
Training loss: 2.4861552715301514
Validation loss: 1.9948194821675618

Epoch: 5| Step: 5
Training loss: 1.5797934532165527
Validation loss: 1.9905692685034968

Epoch: 5| Step: 6
Training loss: 2.4195547103881836
Validation loss: 2.0119530052267094

Epoch: 5| Step: 7
Training loss: 1.7844579219818115
Validation loss: 1.9973120740664903

Epoch: 5| Step: 8
Training loss: 2.095989227294922
Validation loss: 2.008851585849639

Epoch: 5| Step: 9
Training loss: 1.5146276950836182
Validation loss: 2.011541474250055

Epoch: 5| Step: 10
Training loss: 1.9837099313735962
Validation loss: 2.0106899533220517

Epoch: 538| Step: 0
Training loss: 2.1193490028381348
Validation loss: 1.9990763818064043

Epoch: 5| Step: 1
Training loss: 1.793524146080017
Validation loss: 2.002136725251393

Epoch: 5| Step: 2
Training loss: 1.3333892822265625
Validation loss: 1.9899712531797347

Epoch: 5| Step: 3
Training loss: 1.6555668115615845
Validation loss: 2.006589040961317

Epoch: 5| Step: 4
Training loss: 1.7841157913208008
Validation loss: 2.0018037749874975

Epoch: 5| Step: 5
Training loss: 2.32511568069458
Validation loss: 2.0035492476596626

Epoch: 5| Step: 6
Training loss: 1.8580608367919922
Validation loss: 1.9927854845600743

Epoch: 5| Step: 7
Training loss: 1.9089807271957397
Validation loss: 2.0028125906503327

Epoch: 5| Step: 8
Training loss: 2.083369255065918
Validation loss: 1.9886323521214146

Epoch: 5| Step: 9
Training loss: 1.9946283102035522
Validation loss: 2.0021017533476635

Epoch: 5| Step: 10
Training loss: 1.4621893167495728
Validation loss: 2.0069935783263175

Epoch: 539| Step: 0
Training loss: 1.8981730937957764
Validation loss: 2.011549283099431

Epoch: 5| Step: 1
Training loss: 1.6566892862319946
Validation loss: 2.0097376031260334

Epoch: 5| Step: 2
Training loss: 2.120548963546753
Validation loss: 1.9866640542143135

Epoch: 5| Step: 3
Training loss: 1.5359665155410767
Validation loss: 2.001288042273573

Epoch: 5| Step: 4
Training loss: 1.8544219732284546
Validation loss: 2.002432620653542

Epoch: 5| Step: 5
Training loss: 1.4906482696533203
Validation loss: 2.0004215009750856

Epoch: 5| Step: 6
Training loss: 2.8084495067596436
Validation loss: 1.9987385785707863

Epoch: 5| Step: 7
Training loss: 1.4665223360061646
Validation loss: 2.0029192034916212

Epoch: 5| Step: 8
Training loss: 2.377875804901123
Validation loss: 2.016173860078217

Epoch: 5| Step: 9
Training loss: 1.3191944360733032
Validation loss: 2.0313423115720033

Epoch: 5| Step: 10
Training loss: 1.9029624462127686
Validation loss: 2.0086712555218766

Epoch: 540| Step: 0
Training loss: 2.5378894805908203
Validation loss: 2.0300358969678163

Epoch: 5| Step: 1
Training loss: 1.9688516855239868
Validation loss: 2.0050662935421033

Epoch: 5| Step: 2
Training loss: 0.8289309740066528
Validation loss: 2.0013217182569605

Epoch: 5| Step: 3
Training loss: 1.576947569847107
Validation loss: 1.9907334735316615

Epoch: 5| Step: 4
Training loss: 1.6402839422225952
Validation loss: 1.9992902522446008

Epoch: 5| Step: 5
Training loss: 2.03495454788208
Validation loss: 1.985128079691241

Epoch: 5| Step: 6
Training loss: 1.623500108718872
Validation loss: 1.9916948759427635

Epoch: 5| Step: 7
Training loss: 2.10771107673645
Validation loss: 1.9871762926860521

Epoch: 5| Step: 8
Training loss: 1.9644060134887695
Validation loss: 1.9998827313864103

Epoch: 5| Step: 9
Training loss: 2.3041982650756836
Validation loss: 1.9949479064633768

Epoch: 5| Step: 10
Training loss: 1.6597669124603271
Validation loss: 1.9983274295765867

Epoch: 541| Step: 0
Training loss: 1.5554195642471313
Validation loss: 1.9998443408678936

Epoch: 5| Step: 1
Training loss: 2.0685508251190186
Validation loss: 2.0136738387487267

Epoch: 5| Step: 2
Training loss: 1.5256747007369995
Validation loss: 2.019122192936559

Epoch: 5| Step: 3
Training loss: 1.5363823175430298
Validation loss: 2.0001584983641103

Epoch: 5| Step: 4
Training loss: 1.9522778987884521
Validation loss: 1.996606380708756

Epoch: 5| Step: 5
Training loss: 2.2246310710906982
Validation loss: 2.027984896013814

Epoch: 5| Step: 6
Training loss: 2.2750391960144043
Validation loss: 2.014028504330625

Epoch: 5| Step: 7
Training loss: 1.397648811340332
Validation loss: 2.0164221050918743

Epoch: 5| Step: 8
Training loss: 2.233794689178467
Validation loss: 2.0142195301671184

Epoch: 5| Step: 9
Training loss: 1.800811767578125
Validation loss: 2.0381816471776655

Epoch: 5| Step: 10
Training loss: 1.715733528137207
Validation loss: 2.0057821376349336

Epoch: 542| Step: 0
Training loss: 2.7135186195373535
Validation loss: 2.0209518376217095

Epoch: 5| Step: 1
Training loss: 1.5526931285858154
Validation loss: 2.0029621149903987

Epoch: 5| Step: 2
Training loss: 2.34175181388855
Validation loss: 2.0181244009284565

Epoch: 5| Step: 3
Training loss: 1.3956485986709595
Validation loss: 1.9955086631159629

Epoch: 5| Step: 4
Training loss: 1.6218162775039673
Validation loss: 2.003148631383014

Epoch: 5| Step: 5
Training loss: 2.4685440063476562
Validation loss: 1.9996349093734578

Epoch: 5| Step: 6
Training loss: 1.3057643175125122
Validation loss: 1.9934279764852216

Epoch: 5| Step: 7
Training loss: 1.3252551555633545
Validation loss: 1.999978021908832

Epoch: 5| Step: 8
Training loss: 1.5247776508331299
Validation loss: 1.9927897709672169

Epoch: 5| Step: 9
Training loss: 2.437976121902466
Validation loss: 2.0002400952000774

Epoch: 5| Step: 10
Training loss: 1.6090805530548096
Validation loss: 2.0334521929423013

Epoch: 543| Step: 0
Training loss: 1.8895400762557983
Validation loss: 1.9934901050342027

Epoch: 5| Step: 1
Training loss: 1.8388515710830688
Validation loss: 2.03480016544301

Epoch: 5| Step: 2
Training loss: 2.0273640155792236
Validation loss: 2.0090698337042205

Epoch: 5| Step: 3
Training loss: 1.6996265649795532
Validation loss: 1.9861071776318293

Epoch: 5| Step: 4
Training loss: 1.7494418621063232
Validation loss: 2.0158432632364254

Epoch: 5| Step: 5
Training loss: 1.8235286474227905
Validation loss: 1.9971593054392005

Epoch: 5| Step: 6
Training loss: 1.770167350769043
Validation loss: 1.9831999591601792

Epoch: 5| Step: 7
Training loss: 1.789191484451294
Validation loss: 1.9950776689796037

Epoch: 5| Step: 8
Training loss: 1.607373595237732
Validation loss: 1.9887196402395926

Epoch: 5| Step: 9
Training loss: 1.8894141912460327
Validation loss: 2.0321783211923417

Epoch: 5| Step: 10
Training loss: 2.325563430786133
Validation loss: 2.056119159985614

Epoch: 544| Step: 0
Training loss: 1.7278053760528564
Validation loss: 2.043816940758818

Epoch: 5| Step: 1
Training loss: 2.3133962154388428
Validation loss: 2.0045167438445555

Epoch: 5| Step: 2
Training loss: 1.7929191589355469
Validation loss: 2.009173092021737

Epoch: 5| Step: 3
Training loss: 1.4824453592300415
Validation loss: 2.0108423220214022

Epoch: 5| Step: 4
Training loss: 1.9762027263641357
Validation loss: 2.011032819747925

Epoch: 5| Step: 5
Training loss: 1.5870968103408813
Validation loss: 2.0006679488766577

Epoch: 5| Step: 6
Training loss: 1.9940040111541748
Validation loss: 1.9811040227131178

Epoch: 5| Step: 7
Training loss: 1.5637121200561523
Validation loss: 1.991440282073072

Epoch: 5| Step: 8
Training loss: 1.972663164138794
Validation loss: 1.9933131664030013

Epoch: 5| Step: 9
Training loss: 1.8401691913604736
Validation loss: 1.9910457570065734

Epoch: 5| Step: 10
Training loss: 2.0252981185913086
Validation loss: 1.9911855369485834

Epoch: 545| Step: 0
Training loss: 1.5795453786849976
Validation loss: 2.009015098694832

Epoch: 5| Step: 1
Training loss: 1.9948875904083252
Validation loss: 2.004089747705767

Epoch: 5| Step: 2
Training loss: 1.6634178161621094
Validation loss: 1.9916702752472253

Epoch: 5| Step: 3
Training loss: 2.3620922565460205
Validation loss: 2.002890170261424

Epoch: 5| Step: 4
Training loss: 1.6355171203613281
Validation loss: 2.0198824636397825

Epoch: 5| Step: 5
Training loss: 1.9665117263793945
Validation loss: 1.9851660190090057

Epoch: 5| Step: 6
Training loss: 1.6857883930206299
Validation loss: 1.9953880104967343

Epoch: 5| Step: 7
Training loss: 1.784422516822815
Validation loss: 1.985157315449048

Epoch: 5| Step: 8
Training loss: 1.543398380279541
Validation loss: 1.9815844976773827

Epoch: 5| Step: 9
Training loss: 2.14076566696167
Validation loss: 1.999863398972378

Epoch: 5| Step: 10
Training loss: 1.866529107093811
Validation loss: 1.994672211267615

Epoch: 546| Step: 0
Training loss: 1.707810401916504
Validation loss: 2.0065560763882053

Epoch: 5| Step: 1
Training loss: 1.6310062408447266
Validation loss: 2.012249037783633

Epoch: 5| Step: 2
Training loss: 2.4464337825775146
Validation loss: 2.044581513251028

Epoch: 5| Step: 3
Training loss: 2.2736964225769043
Validation loss: 2.029391179802597

Epoch: 5| Step: 4
Training loss: 1.8550128936767578
Validation loss: 2.018797230976884

Epoch: 5| Step: 5
Training loss: 1.829419732093811
Validation loss: 1.9953171463422879

Epoch: 5| Step: 6
Training loss: 1.9516931772232056
Validation loss: 1.988996862083353

Epoch: 5| Step: 7
Training loss: 1.087336778640747
Validation loss: 2.0014777747533654

Epoch: 5| Step: 8
Training loss: 1.5713598728179932
Validation loss: 1.9965365484196653

Epoch: 5| Step: 9
Training loss: 1.9322799444198608
Validation loss: 2.008156048354282

Epoch: 5| Step: 10
Training loss: 2.049626588821411
Validation loss: 2.024258070094611

Epoch: 547| Step: 0
Training loss: 1.7555103302001953
Validation loss: 2.030292610968313

Epoch: 5| Step: 1
Training loss: 2.3645946979522705
Validation loss: 2.0367735662767963

Epoch: 5| Step: 2
Training loss: 1.8456261157989502
Validation loss: 2.0369630423925256

Epoch: 5| Step: 3
Training loss: 1.5157334804534912
Validation loss: 2.004152037764108

Epoch: 5| Step: 4
Training loss: 1.730638861656189
Validation loss: 2.001917305813041

Epoch: 5| Step: 5
Training loss: 2.2099969387054443
Validation loss: 2.0080599631032636

Epoch: 5| Step: 6
Training loss: 1.7100719213485718
Validation loss: 1.9992089322818223

Epoch: 5| Step: 7
Training loss: 1.5205785036087036
Validation loss: 1.9810471816729474

Epoch: 5| Step: 8
Training loss: 1.6002076864242554
Validation loss: 1.9956954627908685

Epoch: 5| Step: 9
Training loss: 2.3843166828155518
Validation loss: 2.015840732923118

Epoch: 5| Step: 10
Training loss: 1.4825608730316162
Validation loss: 2.002607774990861

Epoch: 548| Step: 0
Training loss: 1.8480606079101562
Validation loss: 1.9950698832029938

Epoch: 5| Step: 1
Training loss: 1.1954982280731201
Validation loss: 1.9890860690865466

Epoch: 5| Step: 2
Training loss: 2.2079269886016846
Validation loss: 2.0008086350656327

Epoch: 5| Step: 3
Training loss: 1.5806548595428467
Validation loss: 2.0325309384253716

Epoch: 5| Step: 4
Training loss: 2.0093352794647217
Validation loss: 2.0117789365911998

Epoch: 5| Step: 5
Training loss: 1.9937595129013062
Validation loss: 2.029790355313209

Epoch: 5| Step: 6
Training loss: 2.0061967372894287
Validation loss: 2.028037222482825

Epoch: 5| Step: 7
Training loss: 1.9884655475616455
Validation loss: 2.0389276755753385

Epoch: 5| Step: 8
Training loss: 1.8255202770233154
Validation loss: 2.0128322698736705

Epoch: 5| Step: 9
Training loss: 1.4090023040771484
Validation loss: 2.024479509681784

Epoch: 5| Step: 10
Training loss: 2.150099039077759
Validation loss: 2.0166112838252896

Epoch: 549| Step: 0
Training loss: 1.23210871219635
Validation loss: 2.0048998017464914

Epoch: 5| Step: 1
Training loss: 1.8054183721542358
Validation loss: 2.0164160190090055

Epoch: 5| Step: 2
Training loss: 0.8769943118095398
Validation loss: 2.0199193800649335

Epoch: 5| Step: 3
Training loss: 1.9839805364608765
Validation loss: 2.027185561836407

Epoch: 5| Step: 4
Training loss: 1.8711349964141846
Validation loss: 2.0307901443973666

Epoch: 5| Step: 5
Training loss: 1.6131772994995117
Validation loss: 2.023106037929494

Epoch: 5| Step: 6
Training loss: 2.4833781719207764
Validation loss: 2.0411216546130437

Epoch: 5| Step: 7
Training loss: 1.8099571466445923
Validation loss: 2.0171269114299486

Epoch: 5| Step: 8
Training loss: 2.1543023586273193
Validation loss: 2.0086560390328847

Epoch: 5| Step: 9
Training loss: 1.961660385131836
Validation loss: 1.996115707582043

Epoch: 5| Step: 10
Training loss: 2.5046396255493164
Validation loss: 2.0005821489518687

Epoch: 550| Step: 0
Training loss: 1.9217519760131836
Validation loss: 1.9977069221517092

Epoch: 5| Step: 1
Training loss: 1.9433892965316772
Validation loss: 2.0106850029319845

Epoch: 5| Step: 2
Training loss: 1.7641633749008179
Validation loss: 2.001273489767505

Epoch: 5| Step: 3
Training loss: 2.001446485519409
Validation loss: 1.9962784705623504

Epoch: 5| Step: 4
Training loss: 1.9239921569824219
Validation loss: 1.9937497390213834

Epoch: 5| Step: 5
Training loss: 0.8620400428771973
Validation loss: 2.0056200924740044

Epoch: 5| Step: 6
Training loss: 2.3342156410217285
Validation loss: 2.0189628190891717

Epoch: 5| Step: 7
Training loss: 1.9836089611053467
Validation loss: 2.024152099445302

Epoch: 5| Step: 8
Training loss: 1.6047970056533813
Validation loss: 2.032893244938184

Epoch: 5| Step: 9
Training loss: 1.9174015522003174
Validation loss: 2.0170212509811565

Epoch: 5| Step: 10
Training loss: 1.941147804260254
Validation loss: 2.0040130820325626

Testing loss: 2.2943144109514026
