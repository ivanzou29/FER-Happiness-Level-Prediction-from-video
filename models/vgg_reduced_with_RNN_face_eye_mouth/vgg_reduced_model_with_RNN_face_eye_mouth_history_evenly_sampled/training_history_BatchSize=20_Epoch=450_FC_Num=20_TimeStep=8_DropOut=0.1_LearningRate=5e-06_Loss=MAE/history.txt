Epoch: 1| Step: 0
Training loss: 5.54943323135376
Validation loss: 5.231653444228634

Epoch: 5| Step: 1
Training loss: 5.2154340744018555
Validation loss: 5.227424883073376

Epoch: 5| Step: 2
Training loss: 4.199317932128906
Validation loss: 5.222758636679701

Epoch: 5| Step: 3
Training loss: 5.598658561706543
Validation loss: 5.218378959163543

Epoch: 5| Step: 4
Training loss: 5.592077732086182
Validation loss: 5.213795077416204

Epoch: 5| Step: 5
Training loss: 5.405138969421387
Validation loss: 5.209395700885404

Epoch: 5| Step: 6
Training loss: 4.0615129470825195
Validation loss: 5.204537796717818

Epoch: 5| Step: 7
Training loss: 4.9599223136901855
Validation loss: 5.200251804885044

Epoch: 5| Step: 8
Training loss: 4.947653293609619
Validation loss: 5.19522932011594

Epoch: 5| Step: 9
Training loss: 3.6808724403381348
Validation loss: 5.189734843469435

Epoch: 5| Step: 10
Training loss: 5.9784464836120605
Validation loss: 5.184962144462011

Epoch: 2| Step: 0
Training loss: 3.8761420249938965
Validation loss: 5.179545940891389

Epoch: 5| Step: 1
Training loss: 5.4253339767456055
Validation loss: 5.174060662587483

Epoch: 5| Step: 2
Training loss: 6.084362983703613
Validation loss: 5.1683807885775

Epoch: 5| Step: 3
Training loss: 4.381971836090088
Validation loss: 5.162873524491505

Epoch: 5| Step: 4
Training loss: 5.124203681945801
Validation loss: 5.156458567547542

Epoch: 5| Step: 5
Training loss: 5.475978851318359
Validation loss: 5.150078055679157

Epoch: 5| Step: 6
Training loss: 5.379234790802002
Validation loss: 5.143648029655538

Epoch: 5| Step: 7
Training loss: 4.83298921585083
Validation loss: 5.13710702875609

Epoch: 5| Step: 8
Training loss: 4.0228729248046875
Validation loss: 5.129811599690427

Epoch: 5| Step: 9
Training loss: 5.122140407562256
Validation loss: 5.122384784042194

Epoch: 5| Step: 10
Training loss: 4.600589752197266
Validation loss: 5.114750841612457

Epoch: 3| Step: 0
Training loss: 4.879248142242432
Validation loss: 5.106831596743676

Epoch: 5| Step: 1
Training loss: 4.665790557861328
Validation loss: 5.0980126729575534

Epoch: 5| Step: 2
Training loss: 3.6332764625549316
Validation loss: 5.089447672649096

Epoch: 5| Step: 3
Training loss: 5.02188777923584
Validation loss: 5.079597221907749

Epoch: 5| Step: 4
Training loss: 4.457247257232666
Validation loss: 5.070515432665425

Epoch: 5| Step: 5
Training loss: 5.445733547210693
Validation loss: 5.060586334556661

Epoch: 5| Step: 6
Training loss: 5.451515197753906
Validation loss: 5.04978794692665

Epoch: 5| Step: 7
Training loss: 4.6927008628845215
Validation loss: 5.038823189273957

Epoch: 5| Step: 8
Training loss: 4.459847927093506
Validation loss: 5.027119164825768

Epoch: 5| Step: 9
Training loss: 5.567957878112793
Validation loss: 5.015682287113641

Epoch: 5| Step: 10
Training loss: 5.107609748840332
Validation loss: 5.003083813575007

Epoch: 4| Step: 0
Training loss: 4.634030342102051
Validation loss: 4.98961603513328

Epoch: 5| Step: 1
Training loss: 4.422471046447754
Validation loss: 4.975386393967495

Epoch: 5| Step: 2
Training loss: 5.342154502868652
Validation loss: 4.961298906674949

Epoch: 5| Step: 3
Training loss: 4.902762413024902
Validation loss: 4.947102572328301

Epoch: 5| Step: 4
Training loss: 6.2199835777282715
Validation loss: 4.932037650897938

Epoch: 5| Step: 5
Training loss: 4.680246829986572
Validation loss: 4.915706044884138

Epoch: 5| Step: 6
Training loss: 3.6502537727355957
Validation loss: 4.900539575084563

Epoch: 5| Step: 7
Training loss: 4.387375831604004
Validation loss: 4.883347485655097

Epoch: 5| Step: 8
Training loss: 3.974760055541992
Validation loss: 4.865900983092605

Epoch: 5| Step: 9
Training loss: 5.168844223022461
Validation loss: 4.848507327418173

Epoch: 5| Step: 10
Training loss: 4.287376403808594
Validation loss: 4.828896999359131

Epoch: 5| Step: 0
Training loss: 5.801323890686035
Validation loss: 4.810436669216361

Epoch: 5| Step: 1
Training loss: 4.467480182647705
Validation loss: 4.791642537681005

Epoch: 5| Step: 2
Training loss: 4.863242149353027
Validation loss: 4.770445131486462

Epoch: 5| Step: 3
Training loss: 4.605462551116943
Validation loss: 4.749797103225544

Epoch: 5| Step: 4
Training loss: 4.423850059509277
Validation loss: 4.727987540665493

Epoch: 5| Step: 5
Training loss: 3.2586917877197266
Validation loss: 4.706084302676621

Epoch: 5| Step: 6
Training loss: 4.293603420257568
Validation loss: 4.683655154320501

Epoch: 5| Step: 7
Training loss: 4.342799663543701
Validation loss: 4.661579383316861

Epoch: 5| Step: 8
Training loss: 4.362557411193848
Validation loss: 4.637874659671579

Epoch: 5| Step: 9
Training loss: 3.874844789505005
Validation loss: 4.614388332572035

Epoch: 5| Step: 10
Training loss: 5.20263147354126
Validation loss: 4.5912833572715845

Epoch: 6| Step: 0
Training loss: 4.7177252769470215
Validation loss: 4.569218025412611

Epoch: 5| Step: 1
Training loss: 4.5823259353637695
Validation loss: 4.544939128301477

Epoch: 5| Step: 2
Training loss: 3.757518768310547
Validation loss: 4.5226545333862305

Epoch: 5| Step: 3
Training loss: 3.976217746734619
Validation loss: 4.49869441986084

Epoch: 5| Step: 4
Training loss: 3.5508484840393066
Validation loss: 4.476392097370599

Epoch: 5| Step: 5
Training loss: 4.8081560134887695
Validation loss: 4.455223370623845

Epoch: 5| Step: 6
Training loss: 4.448089122772217
Validation loss: 4.4332145772954465

Epoch: 5| Step: 7
Training loss: 4.303175449371338
Validation loss: 4.412218755291354

Epoch: 5| Step: 8
Training loss: 3.916024684906006
Validation loss: 4.39290524554509

Epoch: 5| Step: 9
Training loss: 3.6565699577331543
Validation loss: 4.372268963885563

Epoch: 5| Step: 10
Training loss: 5.108583927154541
Validation loss: 4.351663486931914

Epoch: 7| Step: 0
Training loss: 2.5376827716827393
Validation loss: 4.332921597265428

Epoch: 5| Step: 1
Training loss: 5.599896430969238
Validation loss: 4.313708207940542

Epoch: 5| Step: 2
Training loss: 3.6376311779022217
Validation loss: 4.296466571028515

Epoch: 5| Step: 3
Training loss: 3.798231601715088
Validation loss: 4.277644644501389

Epoch: 5| Step: 4
Training loss: 4.133401870727539
Validation loss: 4.259806940632481

Epoch: 5| Step: 5
Training loss: 3.4629955291748047
Validation loss: 4.2405797486664145

Epoch: 5| Step: 6
Training loss: 3.55753755569458
Validation loss: 4.223377048328358

Epoch: 5| Step: 7
Training loss: 3.477804660797119
Validation loss: 4.206123318723453

Epoch: 5| Step: 8
Training loss: 4.9031267166137695
Validation loss: 4.1876557155322

Epoch: 5| Step: 9
Training loss: 4.728326320648193
Validation loss: 4.173042717800345

Epoch: 5| Step: 10
Training loss: 4.877145290374756
Validation loss: 4.155309123377646

Epoch: 8| Step: 0
Training loss: 4.919926643371582
Validation loss: 4.140045363415954

Epoch: 5| Step: 1
Training loss: 4.579447269439697
Validation loss: 4.123709119776244

Epoch: 5| Step: 2
Training loss: 3.929147243499756
Validation loss: 4.108591956477011

Epoch: 5| Step: 3
Training loss: 3.8716518878936768
Validation loss: 4.093125312559066

Epoch: 5| Step: 4
Training loss: 3.6232192516326904
Validation loss: 4.077289255716467

Epoch: 5| Step: 5
Training loss: 3.9408295154571533
Validation loss: 4.063431286042737

Epoch: 5| Step: 6
Training loss: 2.824889659881592
Validation loss: 4.047993936846333

Epoch: 5| Step: 7
Training loss: 3.4275925159454346
Validation loss: 4.034691943917223

Epoch: 5| Step: 8
Training loss: 3.369602918624878
Validation loss: 4.019740186711793

Epoch: 5| Step: 9
Training loss: 3.5527195930480957
Validation loss: 4.007173228007491

Epoch: 5| Step: 10
Training loss: 5.066986560821533
Validation loss: 3.993460839794528

Epoch: 9| Step: 0
Training loss: 3.2148826122283936
Validation loss: 3.9796489233611734

Epoch: 5| Step: 1
Training loss: 4.490719795227051
Validation loss: 3.9654146420058383

Epoch: 5| Step: 2
Training loss: 3.090123176574707
Validation loss: 3.950986272545271

Epoch: 5| Step: 3
Training loss: 3.2734005451202393
Validation loss: 3.9382807516282603

Epoch: 5| Step: 4
Training loss: 3.1055305004119873
Validation loss: 3.926037334626721

Epoch: 5| Step: 5
Training loss: 3.8646023273468018
Validation loss: 3.911079365720031

Epoch: 5| Step: 6
Training loss: 4.230113983154297
Validation loss: 3.899523309482041

Epoch: 5| Step: 7
Training loss: 4.042937278747559
Validation loss: 3.8848481793557443

Epoch: 5| Step: 8
Training loss: 3.7283947467803955
Validation loss: 3.8748355424532326

Epoch: 5| Step: 9
Training loss: 4.059111595153809
Validation loss: 3.8589107246809107

Epoch: 5| Step: 10
Training loss: 4.538273334503174
Validation loss: 3.84738157128775

Epoch: 10| Step: 0
Training loss: 2.670116901397705
Validation loss: 3.8357366874653804

Epoch: 5| Step: 1
Training loss: 4.189938545227051
Validation loss: 3.823894998078705

Epoch: 5| Step: 2
Training loss: 4.144252300262451
Validation loss: 3.811630182368781

Epoch: 5| Step: 3
Training loss: 2.9752674102783203
Validation loss: 3.7977506037681334

Epoch: 5| Step: 4
Training loss: 3.128821849822998
Validation loss: 3.7872347036997476

Epoch: 5| Step: 5
Training loss: 3.453792095184326
Validation loss: 3.775906975551318

Epoch: 5| Step: 6
Training loss: 3.823923110961914
Validation loss: 3.7629938997248167

Epoch: 5| Step: 7
Training loss: 5.035563945770264
Validation loss: 3.7501200681091635

Epoch: 5| Step: 8
Training loss: 3.9553940296173096
Validation loss: 3.7392409847628687

Epoch: 5| Step: 9
Training loss: 4.03588342666626
Validation loss: 3.7242619094028266

Epoch: 5| Step: 10
Training loss: 2.696559190750122
Validation loss: 3.7101762217860066

Epoch: 11| Step: 0
Training loss: 4.709329128265381
Validation loss: 3.6984022766031246

Epoch: 5| Step: 1
Training loss: 2.9797325134277344
Validation loss: 3.6870478430101947

Epoch: 5| Step: 2
Training loss: 4.081155776977539
Validation loss: 3.673522556981733

Epoch: 5| Step: 3
Training loss: 3.5693740844726562
Validation loss: 3.659545195999966

Epoch: 5| Step: 4
Training loss: 3.4724700450897217
Validation loss: 3.6486968173775622

Epoch: 5| Step: 5
Training loss: 3.108280658721924
Validation loss: 3.635085810897171

Epoch: 5| Step: 6
Training loss: 2.795929431915283
Validation loss: 3.6224954307720227

Epoch: 5| Step: 7
Training loss: 4.782334804534912
Validation loss: 3.6127462925449496

Epoch: 5| Step: 8
Training loss: 3.7516207695007324
Validation loss: 3.60228907164707

Epoch: 5| Step: 9
Training loss: 2.5797557830810547
Validation loss: 3.5938781871590564

Epoch: 5| Step: 10
Training loss: 3.211350202560425
Validation loss: 3.581144114976288

Epoch: 12| Step: 0
Training loss: 3.2151176929473877
Validation loss: 3.571285896403815

Epoch: 5| Step: 1
Training loss: 3.419445514678955
Validation loss: 3.563979402665169

Epoch: 5| Step: 2
Training loss: 3.454092502593994
Validation loss: 3.5539720955715386

Epoch: 5| Step: 3
Training loss: 4.11993408203125
Validation loss: 3.5460603365334133

Epoch: 5| Step: 4
Training loss: 3.7788453102111816
Validation loss: 3.5372356343012985

Epoch: 5| Step: 5
Training loss: 3.3598551750183105
Validation loss: 3.5292732023423716

Epoch: 5| Step: 6
Training loss: 3.2615158557891846
Validation loss: 3.521816046007218

Epoch: 5| Step: 7
Training loss: 3.299391508102417
Validation loss: 3.5127156575520835

Epoch: 5| Step: 8
Training loss: 3.3444371223449707
Validation loss: 3.5071871793398293

Epoch: 5| Step: 9
Training loss: 2.8722198009490967
Validation loss: 3.4974139582726265

Epoch: 5| Step: 10
Training loss: 3.9686193466186523
Validation loss: 3.4874951608719362

Epoch: 13| Step: 0
Training loss: 2.854210376739502
Validation loss: 3.482542771165089

Epoch: 5| Step: 1
Training loss: 2.952967405319214
Validation loss: 3.4749988689217517

Epoch: 5| Step: 2
Training loss: 4.271890163421631
Validation loss: 3.4739273440453315

Epoch: 5| Step: 3
Training loss: 3.03837513923645
Validation loss: 3.4647419478303645

Epoch: 5| Step: 4
Training loss: 3.5806784629821777
Validation loss: 3.4586691651293027

Epoch: 5| Step: 5
Training loss: 3.6608970165252686
Validation loss: 3.4509463694787796

Epoch: 5| Step: 6
Training loss: 3.3769021034240723
Validation loss: 3.4439570903778076

Epoch: 5| Step: 7
Training loss: 3.187037467956543
Validation loss: 3.4367118702139905

Epoch: 5| Step: 8
Training loss: 4.193974494934082
Validation loss: 3.431297814974221

Epoch: 5| Step: 9
Training loss: 3.251988172531128
Validation loss: 3.4266624040501092

Epoch: 5| Step: 10
Training loss: 2.8187196254730225
Validation loss: 3.421218159378216

Epoch: 14| Step: 0
Training loss: 2.6644370555877686
Validation loss: 3.4152539263489428

Epoch: 5| Step: 1
Training loss: 3.6633715629577637
Validation loss: 3.4056396971466723

Epoch: 5| Step: 2
Training loss: 3.0242276191711426
Validation loss: 3.4044035455232025

Epoch: 5| Step: 3
Training loss: 3.227907657623291
Validation loss: 3.39907604904585

Epoch: 5| Step: 4
Training loss: 2.8448517322540283
Validation loss: 3.392473333625383

Epoch: 5| Step: 5
Training loss: 3.2735202312469482
Validation loss: 3.3876029470915436

Epoch: 5| Step: 6
Training loss: 3.4809112548828125
Validation loss: 3.380511663293326

Epoch: 5| Step: 7
Training loss: 4.4503092765808105
Validation loss: 3.3747943011663293

Epoch: 5| Step: 8
Training loss: 2.8963043689727783
Validation loss: 3.3673622198002313

Epoch: 5| Step: 9
Training loss: 3.4230690002441406
Validation loss: 3.3633706185125534

Epoch: 5| Step: 10
Training loss: 3.826104164123535
Validation loss: 3.3615271763135026

Epoch: 15| Step: 0
Training loss: 3.122063636779785
Validation loss: 3.3533676901171283

Epoch: 5| Step: 1
Training loss: 4.525935173034668
Validation loss: 3.3419094598421486

Epoch: 5| Step: 2
Training loss: 2.9859707355499268
Validation loss: 3.334605763035436

Epoch: 5| Step: 3
Training loss: 2.7415847778320312
Validation loss: 3.3284854273642264

Epoch: 5| Step: 4
Training loss: 2.801299571990967
Validation loss: 3.319144630944857

Epoch: 5| Step: 5
Training loss: 3.7809436321258545
Validation loss: 3.3131409973226567

Epoch: 5| Step: 6
Training loss: 3.790226697921753
Validation loss: 3.307168112006239

Epoch: 5| Step: 7
Training loss: 2.800481081008911
Validation loss: 3.3041462821345173

Epoch: 5| Step: 8
Training loss: 3.803783893585205
Validation loss: 3.297687958645564

Epoch: 5| Step: 9
Training loss: 2.855170488357544
Validation loss: 3.29006435537851

Epoch: 5| Step: 10
Training loss: 2.7599284648895264
Validation loss: 3.2878285838711645

Epoch: 16| Step: 0
Training loss: 4.140511512756348
Validation loss: 3.2847950304708173

Epoch: 5| Step: 1
Training loss: 3.0065150260925293
Validation loss: 3.279257841007684

Epoch: 5| Step: 2
Training loss: 3.06363582611084
Validation loss: 3.2736916439507597

Epoch: 5| Step: 3
Training loss: 3.1505908966064453
Validation loss: 3.2679380396360993

Epoch: 5| Step: 4
Training loss: 2.648651599884033
Validation loss: 3.2670405782679075

Epoch: 5| Step: 5
Training loss: 3.02677059173584
Validation loss: 3.2622652925470823

Epoch: 5| Step: 6
Training loss: 3.408679962158203
Validation loss: 3.2559400707162838

Epoch: 5| Step: 7
Training loss: 3.768395185470581
Validation loss: 3.2525960014712427

Epoch: 5| Step: 8
Training loss: 3.4303946495056152
Validation loss: 3.2500963031604724

Epoch: 5| Step: 9
Training loss: 2.9837913513183594
Validation loss: 3.243280951694776

Epoch: 5| Step: 10
Training loss: 2.974058151245117
Validation loss: 3.2412088609510854

Epoch: 17| Step: 0
Training loss: 3.3112781047821045
Validation loss: 3.2412727571302846

Epoch: 5| Step: 1
Training loss: 3.208829164505005
Validation loss: 3.2401858042645197

Epoch: 5| Step: 2
Training loss: 3.1473464965820312
Validation loss: 3.2362919366487892

Epoch: 5| Step: 3
Training loss: 3.3370773792266846
Validation loss: 3.235341300246536

Epoch: 5| Step: 4
Training loss: 3.0075466632843018
Validation loss: 3.2297335388839885

Epoch: 5| Step: 5
Training loss: 2.5896387100219727
Validation loss: 3.2265711061416136

Epoch: 5| Step: 6
Training loss: 3.278820753097534
Validation loss: 3.2172928676810315

Epoch: 5| Step: 7
Training loss: 3.169823169708252
Validation loss: 3.211692717767531

Epoch: 5| Step: 8
Training loss: 3.6662166118621826
Validation loss: 3.2088030179341636

Epoch: 5| Step: 9
Training loss: 3.2342445850372314
Validation loss: 3.2060303431685253

Epoch: 5| Step: 10
Training loss: 3.354667901992798
Validation loss: 3.2000797589619956

Epoch: 18| Step: 0
Training loss: 3.1878819465637207
Validation loss: 3.196395433077248

Epoch: 5| Step: 1
Training loss: 2.9764955043792725
Validation loss: 3.1959579683119252

Epoch: 5| Step: 2
Training loss: 3.332186222076416
Validation loss: 3.193753934675647

Epoch: 5| Step: 3
Training loss: 2.77363657951355
Validation loss: 3.1930291447588193

Epoch: 5| Step: 4
Training loss: 3.0379550457000732
Validation loss: 3.1888904981715704

Epoch: 5| Step: 5
Training loss: 2.1371350288391113
Validation loss: 3.1854887085576213

Epoch: 5| Step: 6
Training loss: 3.8100593090057373
Validation loss: 3.186857754184354

Epoch: 5| Step: 7
Training loss: 2.503713607788086
Validation loss: 3.1804860458579114

Epoch: 5| Step: 8
Training loss: 3.3589539527893066
Validation loss: 3.177747595694757

Epoch: 5| Step: 9
Training loss: 3.5000648498535156
Validation loss: 3.173088647985971

Epoch: 5| Step: 10
Training loss: 4.605515003204346
Validation loss: 3.1713967015666347

Epoch: 19| Step: 0
Training loss: 3.354998826980591
Validation loss: 3.1689773938989125

Epoch: 5| Step: 1
Training loss: 2.8799538612365723
Validation loss: 3.180672891678349

Epoch: 5| Step: 2
Training loss: 3.3799209594726562
Validation loss: 3.169494439196843

Epoch: 5| Step: 3
Training loss: 2.7866594791412354
Validation loss: 3.1601714728980936

Epoch: 5| Step: 4
Training loss: 3.135423183441162
Validation loss: 3.1598970633681103

Epoch: 5| Step: 5
Training loss: 4.002911567687988
Validation loss: 3.158367569728564

Epoch: 5| Step: 6
Training loss: 3.294705629348755
Validation loss: 3.1570267600397908

Epoch: 5| Step: 7
Training loss: 2.305389165878296
Validation loss: 3.1587462989232873

Epoch: 5| Step: 8
Training loss: 3.053234100341797
Validation loss: 3.1581222216288247

Epoch: 5| Step: 9
Training loss: 2.9874467849731445
Validation loss: 3.1518208262740925

Epoch: 5| Step: 10
Training loss: 3.74316143989563
Validation loss: 3.1459576237586235

Epoch: 20| Step: 0
Training loss: 2.8574676513671875
Validation loss: 3.141829611152731

Epoch: 5| Step: 1
Training loss: 3.700112819671631
Validation loss: 3.139697136417512

Epoch: 5| Step: 2
Training loss: 3.7272162437438965
Validation loss: 3.138818707517398

Epoch: 5| Step: 3
Training loss: 2.487126111984253
Validation loss: 3.1368403793663107

Epoch: 5| Step: 4
Training loss: 2.532104015350342
Validation loss: 3.140637710530271

Epoch: 5| Step: 5
Training loss: 3.2203171253204346
Validation loss: 3.134521330556562

Epoch: 5| Step: 6
Training loss: 3.50396728515625
Validation loss: 3.139409731793147

Epoch: 5| Step: 7
Training loss: 3.1335196495056152
Validation loss: 3.122669025134015

Epoch: 5| Step: 8
Training loss: 3.3750100135803223
Validation loss: 3.1207642785964476

Epoch: 5| Step: 9
Training loss: 2.816208600997925
Validation loss: 3.117118740594515

Epoch: 5| Step: 10
Training loss: 3.2714757919311523
Validation loss: 3.1226053417369886

Epoch: 21| Step: 0
Training loss: 3.0931806564331055
Validation loss: 3.1212892942531134

Epoch: 5| Step: 1
Training loss: 2.9367544651031494
Validation loss: 3.117383333944505

Epoch: 5| Step: 2
Training loss: 4.047745704650879
Validation loss: 3.1120968352081957

Epoch: 5| Step: 3
Training loss: 3.3005924224853516
Validation loss: 3.1121794280185493

Epoch: 5| Step: 4
Training loss: 2.380741596221924
Validation loss: 3.1084555297769527

Epoch: 5| Step: 5
Training loss: 3.225426435470581
Validation loss: 3.108757967590004

Epoch: 5| Step: 6
Training loss: 3.6738688945770264
Validation loss: 3.1040520873121036

Epoch: 5| Step: 7
Training loss: 2.8167736530303955
Validation loss: 3.1005921517649004

Epoch: 5| Step: 8
Training loss: 2.8523144721984863
Validation loss: 3.0997545232055006

Epoch: 5| Step: 9
Training loss: 3.076890468597412
Validation loss: 3.0976158829145533

Epoch: 5| Step: 10
Training loss: 2.972410202026367
Validation loss: 3.091782236611971

Epoch: 22| Step: 0
Training loss: 3.117887496948242
Validation loss: 3.089397884184314

Epoch: 5| Step: 1
Training loss: 2.775322914123535
Validation loss: 3.087679962958059

Epoch: 5| Step: 2
Training loss: 3.8683695793151855
Validation loss: 3.0842080808454946

Epoch: 5| Step: 3
Training loss: 2.649524688720703
Validation loss: 3.0806760300872145

Epoch: 5| Step: 4
Training loss: 2.5563602447509766
Validation loss: 3.080768521114062

Epoch: 5| Step: 5
Training loss: 2.9063913822174072
Validation loss: 3.0763046049302623

Epoch: 5| Step: 6
Training loss: 3.301358461380005
Validation loss: 3.075116308786536

Epoch: 5| Step: 7
Training loss: 3.0590972900390625
Validation loss: 3.071423994597568

Epoch: 5| Step: 8
Training loss: 3.2198448181152344
Validation loss: 3.073762483494256

Epoch: 5| Step: 9
Training loss: 3.655393600463867
Validation loss: 3.073719927059707

Epoch: 5| Step: 10
Training loss: 3.033729076385498
Validation loss: 3.068382304201844

Epoch: 23| Step: 0
Training loss: 3.5814011096954346
Validation loss: 3.061180281382735

Epoch: 5| Step: 1
Training loss: 3.6696338653564453
Validation loss: 3.059283182185183

Epoch: 5| Step: 2
Training loss: 2.2726776599884033
Validation loss: 3.0587599200587117

Epoch: 5| Step: 3
Training loss: 3.3567512035369873
Validation loss: 3.0558450401470227

Epoch: 5| Step: 4
Training loss: 2.6856229305267334
Validation loss: 3.0559881605127805

Epoch: 5| Step: 5
Training loss: 2.4917004108428955
Validation loss: 3.0514601892040623

Epoch: 5| Step: 6
Training loss: 3.644186019897461
Validation loss: 3.053004813450639

Epoch: 5| Step: 7
Training loss: 3.3043580055236816
Validation loss: 3.0502496124595724

Epoch: 5| Step: 8
Training loss: 2.4937801361083984
Validation loss: 3.048319096206337

Epoch: 5| Step: 9
Training loss: 3.322327136993408
Validation loss: 3.042249023273427

Epoch: 5| Step: 10
Training loss: 3.195009231567383
Validation loss: 3.0382912210238877

Epoch: 24| Step: 0
Training loss: 2.823836088180542
Validation loss: 3.036981882587556

Epoch: 5| Step: 1
Training loss: 2.5383965969085693
Validation loss: 3.037863664729621

Epoch: 5| Step: 2
Training loss: 3.435703992843628
Validation loss: 3.033985778849612

Epoch: 5| Step: 3
Training loss: 4.0238237380981445
Validation loss: 3.0317313953112532

Epoch: 5| Step: 4
Training loss: 2.9761064052581787
Validation loss: 3.0288919838525916

Epoch: 5| Step: 5
Training loss: 3.0654501914978027
Validation loss: 3.0290391342614287

Epoch: 5| Step: 6
Training loss: 2.506101131439209
Validation loss: 3.034162995635822

Epoch: 5| Step: 7
Training loss: 2.5395913124084473
Validation loss: 3.054045984821935

Epoch: 5| Step: 8
Training loss: 3.2498180866241455
Validation loss: 3.078822471762216

Epoch: 5| Step: 9
Training loss: 3.464139461517334
Validation loss: 3.054531248666907

Epoch: 5| Step: 10
Training loss: 3.3424391746520996
Validation loss: 3.021287264362458

Epoch: 25| Step: 0
Training loss: 2.25437068939209
Validation loss: 3.0142739511305288

Epoch: 5| Step: 1
Training loss: 3.171555757522583
Validation loss: 3.021602781870032

Epoch: 5| Step: 2
Training loss: 3.5299453735351562
Validation loss: 3.02927464823569

Epoch: 5| Step: 3
Training loss: 2.2656707763671875
Validation loss: 3.0223646856123403

Epoch: 5| Step: 4
Training loss: 3.441926956176758
Validation loss: 3.0191121383379866

Epoch: 5| Step: 5
Training loss: 3.021273612976074
Validation loss: 3.017702715371245

Epoch: 5| Step: 6
Training loss: 4.110919952392578
Validation loss: 3.018302133006434

Epoch: 5| Step: 7
Training loss: 2.5852112770080566
Validation loss: 3.0159526794187483

Epoch: 5| Step: 8
Training loss: 3.028517246246338
Validation loss: 3.015545796322566

Epoch: 5| Step: 9
Training loss: 3.3751463890075684
Validation loss: 3.010450170886132

Epoch: 5| Step: 10
Training loss: 3.009368896484375
Validation loss: 3.014164299093267

Epoch: 26| Step: 0
Training loss: 3.015570640563965
Validation loss: 3.011256435865997

Epoch: 5| Step: 1
Training loss: 2.9013354778289795
Validation loss: 3.0118455938113633

Epoch: 5| Step: 2
Training loss: 2.4025497436523438
Validation loss: 3.0067536164355535

Epoch: 5| Step: 3
Training loss: 2.6827893257141113
Validation loss: 3.0100717390737226

Epoch: 5| Step: 4
Training loss: 3.43933367729187
Validation loss: 3.0037376649918093

Epoch: 5| Step: 5
Training loss: 3.029123306274414
Validation loss: 2.9983921179207425

Epoch: 5| Step: 6
Training loss: 4.0129194259643555
Validation loss: 2.9991619407489734

Epoch: 5| Step: 7
Training loss: 2.9265451431274414
Validation loss: 2.9986119475415958

Epoch: 5| Step: 8
Training loss: 2.4603092670440674
Validation loss: 2.9956014489614837

Epoch: 5| Step: 9
Training loss: 3.3144569396972656
Validation loss: 2.9927121464924147

Epoch: 5| Step: 10
Training loss: 3.5360264778137207
Validation loss: 2.990016652691749

Epoch: 27| Step: 0
Training loss: 3.151984453201294
Validation loss: 2.9877566445258354

Epoch: 5| Step: 1
Training loss: 3.8348655700683594
Validation loss: 2.982813596725464

Epoch: 5| Step: 2
Training loss: 3.00002121925354
Validation loss: 2.979519490272768

Epoch: 5| Step: 3
Training loss: 2.784515857696533
Validation loss: 2.9764413474708475

Epoch: 5| Step: 4
Training loss: 2.7869181632995605
Validation loss: 2.972418254421603

Epoch: 5| Step: 5
Training loss: 3.231306791305542
Validation loss: 2.970760630023095

Epoch: 5| Step: 6
Training loss: 3.5083587169647217
Validation loss: 2.9700498529659805

Epoch: 5| Step: 7
Training loss: 2.5372180938720703
Validation loss: 2.969896472910399

Epoch: 5| Step: 8
Training loss: 3.2332682609558105
Validation loss: 2.9646522973173406

Epoch: 5| Step: 9
Training loss: 2.2290263175964355
Validation loss: 2.9635738608657674

Epoch: 5| Step: 10
Training loss: 3.1968064308166504
Validation loss: 2.963970107416953

Epoch: 28| Step: 0
Training loss: 2.9340808391571045
Validation loss: 2.9636584815158638

Epoch: 5| Step: 1
Training loss: 2.9031453132629395
Validation loss: 2.9657674681755806

Epoch: 5| Step: 2
Training loss: 3.0539817810058594
Validation loss: 2.962916915134717

Epoch: 5| Step: 3
Training loss: 3.0439107418060303
Validation loss: 2.959733957885414

Epoch: 5| Step: 4
Training loss: 3.4485831260681152
Validation loss: 2.9587769892907914

Epoch: 5| Step: 5
Training loss: 3.196646213531494
Validation loss: 2.95578279290148

Epoch: 5| Step: 6
Training loss: 3.3700547218322754
Validation loss: 2.95715158472779

Epoch: 5| Step: 7
Training loss: 2.3202428817749023
Validation loss: 2.955830794508739

Epoch: 5| Step: 8
Training loss: 2.5041003227233887
Validation loss: 2.9526795187304096

Epoch: 5| Step: 9
Training loss: 3.5330021381378174
Validation loss: 2.950921468837287

Epoch: 5| Step: 10
Training loss: 2.971191644668579
Validation loss: 2.948041344201693

Epoch: 29| Step: 0
Training loss: 3.4668116569519043
Validation loss: 2.9449630398904123

Epoch: 5| Step: 1
Training loss: 3.0555546283721924
Validation loss: 2.940125573065973

Epoch: 5| Step: 2
Training loss: 3.77197003364563
Validation loss: 2.9372026843409382

Epoch: 5| Step: 3
Training loss: 2.935053586959839
Validation loss: 2.93615302988278

Epoch: 5| Step: 4
Training loss: 3.8057358264923096
Validation loss: 2.936193081640428

Epoch: 5| Step: 5
Training loss: 2.4434497356414795
Validation loss: 2.9348126073037424

Epoch: 5| Step: 6
Training loss: 2.06459379196167
Validation loss: 2.9311494622179257

Epoch: 5| Step: 7
Training loss: 4.3958210945129395
Validation loss: 2.9281514870223178

Epoch: 5| Step: 8
Training loss: 3.0327694416046143
Validation loss: 2.9290468359506256

Epoch: 5| Step: 9
Training loss: 1.9442329406738281
Validation loss: 2.9287346434849564

Epoch: 5| Step: 10
Training loss: 2.1426658630371094
Validation loss: 2.926505219551825

Epoch: 30| Step: 0
Training loss: 3.2611279487609863
Validation loss: 2.9244980414708457

Epoch: 5| Step: 1
Training loss: 3.109246253967285
Validation loss: 2.9239677049780406

Epoch: 5| Step: 2
Training loss: 2.818012237548828
Validation loss: 2.9239386153477493

Epoch: 5| Step: 3
Training loss: 2.9182586669921875
Validation loss: 2.925248904894757

Epoch: 5| Step: 4
Training loss: 3.2240912914276123
Validation loss: 2.925638667998775

Epoch: 5| Step: 5
Training loss: 2.704224109649658
Validation loss: 2.9216218276690413

Epoch: 5| Step: 6
Training loss: 2.7699291706085205
Validation loss: 2.918385141639299

Epoch: 5| Step: 7
Training loss: 3.22453236579895
Validation loss: 2.9146578824648293

Epoch: 5| Step: 8
Training loss: 2.556445598602295
Validation loss: 2.9163676461865826

Epoch: 5| Step: 9
Training loss: 3.150104284286499
Validation loss: 2.917477712836317

Epoch: 5| Step: 10
Training loss: 3.339959144592285
Validation loss: 2.9157717407390638

Epoch: 31| Step: 0
Training loss: 3.417445421218872
Validation loss: 2.9120762219993015

Epoch: 5| Step: 1
Training loss: 2.5210299491882324
Validation loss: 2.90905080046705

Epoch: 5| Step: 2
Training loss: 3.374910354614258
Validation loss: 2.9014376440355854

Epoch: 5| Step: 3
Training loss: 2.8792576789855957
Validation loss: 2.9047225982912126

Epoch: 5| Step: 4
Training loss: 2.8787872791290283
Validation loss: 2.9031483152861237

Epoch: 5| Step: 5
Training loss: 3.118952989578247
Validation loss: 2.9028534786675566

Epoch: 5| Step: 6
Training loss: 2.969006061553955
Validation loss: 2.9027963222995883

Epoch: 5| Step: 7
Training loss: 3.7643978595733643
Validation loss: 2.901479741578461

Epoch: 5| Step: 8
Training loss: 3.2405242919921875
Validation loss: 2.8936741685354583

Epoch: 5| Step: 9
Training loss: 3.134125232696533
Validation loss: 2.8938489575539865

Epoch: 5| Step: 10
Training loss: 1.3349469900131226
Validation loss: 2.891487503564486

Epoch: 32| Step: 0
Training loss: 3.85429048538208
Validation loss: 2.893117566262522

Epoch: 5| Step: 1
Training loss: 2.349694013595581
Validation loss: 2.894889859743016

Epoch: 5| Step: 2
Training loss: 2.862595319747925
Validation loss: 2.890789895929316

Epoch: 5| Step: 3
Training loss: 2.9337985515594482
Validation loss: 2.8935409104952248

Epoch: 5| Step: 4
Training loss: 2.6306657791137695
Validation loss: 2.889706996179396

Epoch: 5| Step: 5
Training loss: 3.1944632530212402
Validation loss: 2.891315516605172

Epoch: 5| Step: 6
Training loss: 2.599379062652588
Validation loss: 2.887094864281275

Epoch: 5| Step: 7
Training loss: 2.9882969856262207
Validation loss: 2.881207973726334

Epoch: 5| Step: 8
Training loss: 3.3070850372314453
Validation loss: 2.877528388013122

Epoch: 5| Step: 9
Training loss: 3.1389148235321045
Validation loss: 2.878535039963261

Epoch: 5| Step: 10
Training loss: 2.878770589828491
Validation loss: 2.876417144652336

Epoch: 33| Step: 0
Training loss: 2.909949541091919
Validation loss: 2.8802653281919417

Epoch: 5| Step: 1
Training loss: 2.8612265586853027
Validation loss: 2.87958110532453

Epoch: 5| Step: 2
Training loss: 2.833829402923584
Validation loss: 2.8789641652055966

Epoch: 5| Step: 3
Training loss: 2.662367105484009
Validation loss: 2.8767854141932663

Epoch: 5| Step: 4
Training loss: 2.768474817276001
Validation loss: 2.8765559222108577

Epoch: 5| Step: 5
Training loss: 3.4027562141418457
Validation loss: 2.875694849157846

Epoch: 5| Step: 6
Training loss: 3.7851009368896484
Validation loss: 2.872258814432288

Epoch: 5| Step: 7
Training loss: 3.3565285205841064
Validation loss: 2.8733067179238923

Epoch: 5| Step: 8
Training loss: 2.764882802963257
Validation loss: 2.881841495472898

Epoch: 5| Step: 9
Training loss: 2.309386730194092
Validation loss: 2.8779095347209642

Epoch: 5| Step: 10
Training loss: 2.9866905212402344
Validation loss: 2.8736298212441067

Epoch: 34| Step: 0
Training loss: 2.683871269226074
Validation loss: 2.8668898228676087

Epoch: 5| Step: 1
Training loss: 3.0016109943389893
Validation loss: 2.867102389694542

Epoch: 5| Step: 2
Training loss: 2.9311819076538086
Validation loss: 2.8669976598473004

Epoch: 5| Step: 3
Training loss: 2.213933229446411
Validation loss: 2.863954667122133

Epoch: 5| Step: 4
Training loss: 3.788013458251953
Validation loss: 2.862490753973684

Epoch: 5| Step: 5
Training loss: 2.8278262615203857
Validation loss: 2.8604932267178773

Epoch: 5| Step: 6
Training loss: 2.8600940704345703
Validation loss: 2.8565462379045385

Epoch: 5| Step: 7
Training loss: 2.7633273601531982
Validation loss: 2.8566741020448747

Epoch: 5| Step: 8
Training loss: 2.8781166076660156
Validation loss: 2.857279085343884

Epoch: 5| Step: 9
Training loss: 3.287003993988037
Validation loss: 2.854833218359178

Epoch: 5| Step: 10
Training loss: 3.3859329223632812
Validation loss: 2.857386586486652

Epoch: 35| Step: 0
Training loss: 2.485313892364502
Validation loss: 2.8464564533643824

Epoch: 5| Step: 1
Training loss: 2.5392651557922363
Validation loss: 2.848684054549022

Epoch: 5| Step: 2
Training loss: 3.186837673187256
Validation loss: 2.8460078752169045

Epoch: 5| Step: 3
Training loss: 3.281684398651123
Validation loss: 2.846845949849775

Epoch: 5| Step: 4
Training loss: 2.1338350772857666
Validation loss: 2.8477867444356284

Epoch: 5| Step: 5
Training loss: 2.8776233196258545
Validation loss: 2.8476938611717633

Epoch: 5| Step: 6
Training loss: 3.6912169456481934
Validation loss: 2.8462712175102642

Epoch: 5| Step: 7
Training loss: 2.6632239818573
Validation loss: 2.845003492088728

Epoch: 5| Step: 8
Training loss: 3.369279146194458
Validation loss: 2.847040481464837

Epoch: 5| Step: 9
Training loss: 3.008026361465454
Validation loss: 2.836385962783649

Epoch: 5| Step: 10
Training loss: 3.2398910522460938
Validation loss: 2.8380380215183383

Epoch: 36| Step: 0
Training loss: 3.2571678161621094
Validation loss: 2.838211997862785

Epoch: 5| Step: 1
Training loss: 3.274238109588623
Validation loss: 2.8448091168557443

Epoch: 5| Step: 2
Training loss: 2.5445008277893066
Validation loss: 2.8452038970044864

Epoch: 5| Step: 3
Training loss: 2.933384418487549
Validation loss: 2.839300735022432

Epoch: 5| Step: 4
Training loss: 2.656507730484009
Validation loss: 2.8366844705356065

Epoch: 5| Step: 5
Training loss: 2.3960797786712646
Validation loss: 2.835559883425313

Epoch: 5| Step: 6
Training loss: 3.3661274909973145
Validation loss: 2.83054361292111

Epoch: 5| Step: 7
Training loss: 2.4760050773620605
Validation loss: 2.828854335251675

Epoch: 5| Step: 8
Training loss: 3.4237122535705566
Validation loss: 2.8320809871919694

Epoch: 5| Step: 9
Training loss: 2.621506452560425
Validation loss: 2.8363292601800736

Epoch: 5| Step: 10
Training loss: 3.5127484798431396
Validation loss: 2.8421743018652803

Epoch: 37| Step: 0
Training loss: 2.6753358840942383
Validation loss: 2.8341071887682845

Epoch: 5| Step: 1
Training loss: 3.0753729343414307
Validation loss: 2.8326644923097346

Epoch: 5| Step: 2
Training loss: 3.574101686477661
Validation loss: 2.831549172760338

Epoch: 5| Step: 3
Training loss: 2.728114128112793
Validation loss: 2.827668059256769

Epoch: 5| Step: 4
Training loss: 2.982696533203125
Validation loss: 2.8226803682183705

Epoch: 5| Step: 5
Training loss: 2.719825267791748
Validation loss: 2.8219593212168705

Epoch: 5| Step: 6
Training loss: 3.1302900314331055
Validation loss: 2.827468051705309

Epoch: 5| Step: 7
Training loss: 2.539583444595337
Validation loss: 2.8300686010750393

Epoch: 5| Step: 8
Training loss: 2.8412437438964844
Validation loss: 2.8348605248235885

Epoch: 5| Step: 9
Training loss: 2.637721061706543
Validation loss: 2.831528507253175

Epoch: 5| Step: 10
Training loss: 3.48603892326355
Validation loss: 2.825967199058943

Epoch: 38| Step: 0
Training loss: 3.1165809631347656
Validation loss: 2.8201568665043

Epoch: 5| Step: 1
Training loss: 3.0518414974212646
Validation loss: 2.8178508307344172

Epoch: 5| Step: 2
Training loss: 2.4357714653015137
Validation loss: 2.8228435336902575

Epoch: 5| Step: 3
Training loss: 3.39973521232605
Validation loss: 2.8226042665461057

Epoch: 5| Step: 4
Training loss: 3.0484447479248047
Validation loss: 2.8213349311582503

Epoch: 5| Step: 5
Training loss: 2.945730686187744
Validation loss: 2.818944828484648

Epoch: 5| Step: 6
Training loss: 3.368344783782959
Validation loss: 2.820324808038691

Epoch: 5| Step: 7
Training loss: 2.3579471111297607
Validation loss: 2.81395459687838

Epoch: 5| Step: 8
Training loss: 3.2319083213806152
Validation loss: 2.813007689291431

Epoch: 5| Step: 9
Training loss: 2.742103338241577
Validation loss: 2.813474965351884

Epoch: 5| Step: 10
Training loss: 2.4416353702545166
Validation loss: 2.808685146352296

Epoch: 39| Step: 0
Training loss: 2.765103340148926
Validation loss: 2.80981376606931

Epoch: 5| Step: 1
Training loss: 3.369359254837036
Validation loss: 2.8153373169642624

Epoch: 5| Step: 2
Training loss: 2.274157762527466
Validation loss: 2.8143260504609797

Epoch: 5| Step: 3
Training loss: 3.0326061248779297
Validation loss: 2.811412936897688

Epoch: 5| Step: 4
Training loss: 2.963371515274048
Validation loss: 2.8113279701561056

Epoch: 5| Step: 5
Training loss: 2.748812437057495
Validation loss: 2.808537365287863

Epoch: 5| Step: 6
Training loss: 2.501920223236084
Validation loss: 2.8090841436898835

Epoch: 5| Step: 7
Training loss: 2.986727476119995
Validation loss: 2.809845603922362

Epoch: 5| Step: 8
Training loss: 3.689345121383667
Validation loss: 2.8077478972814416

Epoch: 5| Step: 9
Training loss: 2.275740146636963
Validation loss: 2.8074623743693032

Epoch: 5| Step: 10
Training loss: 3.672496795654297
Validation loss: 2.8042467742837887

Epoch: 40| Step: 0
Training loss: 2.7130463123321533
Validation loss: 2.8077198049073577

Epoch: 5| Step: 1
Training loss: 2.8470873832702637
Validation loss: 2.807053017359908

Epoch: 5| Step: 2
Training loss: 2.5540456771850586
Validation loss: 2.8107555450931674

Epoch: 5| Step: 3
Training loss: 2.757087469100952
Validation loss: 2.808954561910322

Epoch: 5| Step: 4
Training loss: 1.9182965755462646
Validation loss: 2.810599337341965

Epoch: 5| Step: 5
Training loss: 3.23933482170105
Validation loss: 2.810989725974298

Epoch: 5| Step: 6
Training loss: 3.4100043773651123
Validation loss: 2.806176777808897

Epoch: 5| Step: 7
Training loss: 3.1151540279388428
Validation loss: 2.802113094637471

Epoch: 5| Step: 8
Training loss: 4.118906497955322
Validation loss: 2.805714920002927

Epoch: 5| Step: 9
Training loss: 2.730255603790283
Validation loss: 2.803491582152664

Epoch: 5| Step: 10
Training loss: 2.691419839859009
Validation loss: 2.805719011573381

Epoch: 41| Step: 0
Training loss: 3.2552287578582764
Validation loss: 2.803016698488625

Epoch: 5| Step: 1
Training loss: 3.2725765705108643
Validation loss: 2.8012869640063216

Epoch: 5| Step: 2
Training loss: 2.984102249145508
Validation loss: 2.8015260542592695

Epoch: 5| Step: 3
Training loss: 2.621211290359497
Validation loss: 2.8034622848674817

Epoch: 5| Step: 4
Training loss: 2.03070330619812
Validation loss: 2.8078599617045414

Epoch: 5| Step: 5
Training loss: 3.037238359451294
Validation loss: 2.8069578806559243

Epoch: 5| Step: 6
Training loss: 3.215461254119873
Validation loss: 2.8109930099979525

Epoch: 5| Step: 7
Training loss: 2.6516849994659424
Validation loss: 2.8084007719511628

Epoch: 5| Step: 8
Training loss: 2.268648624420166
Validation loss: 2.8035095789099254

Epoch: 5| Step: 9
Training loss: 3.2458221912384033
Validation loss: 2.8050597483111965

Epoch: 5| Step: 10
Training loss: 3.6551458835601807
Validation loss: 2.8021345625641527

Epoch: 42| Step: 0
Training loss: 2.2736144065856934
Validation loss: 2.79780811648215

Epoch: 5| Step: 1
Training loss: 3.1207833290100098
Validation loss: 2.804206053415934

Epoch: 5| Step: 2
Training loss: 3.136439800262451
Validation loss: 2.8099374130208004

Epoch: 5| Step: 3
Training loss: 3.131923198699951
Validation loss: 2.8195051557274273

Epoch: 5| Step: 4
Training loss: 3.136706829071045
Validation loss: 2.8006006004989787

Epoch: 5| Step: 5
Training loss: 3.550339460372925
Validation loss: 2.7963194257469586

Epoch: 5| Step: 6
Training loss: 2.556807279586792
Validation loss: 2.799089144634944

Epoch: 5| Step: 7
Training loss: 2.865532159805298
Validation loss: 2.795852391950546

Epoch: 5| Step: 8
Training loss: 2.817223310470581
Validation loss: 2.7985811028429257

Epoch: 5| Step: 9
Training loss: 2.503605604171753
Validation loss: 2.7938591793019283

Epoch: 5| Step: 10
Training loss: 2.977452516555786
Validation loss: 2.7924948969194965

Epoch: 43| Step: 0
Training loss: 2.716151475906372
Validation loss: 2.789511788275934

Epoch: 5| Step: 1
Training loss: 2.506613254547119
Validation loss: 2.793574304990871

Epoch: 5| Step: 2
Training loss: 3.5730202198028564
Validation loss: 2.793399856936547

Epoch: 5| Step: 3
Training loss: 3.4778449535369873
Validation loss: 2.791339933231313

Epoch: 5| Step: 4
Training loss: 3.0894200801849365
Validation loss: 2.792065615295082

Epoch: 5| Step: 5
Training loss: 3.0342798233032227
Validation loss: 2.79064687349463

Epoch: 5| Step: 6
Training loss: 2.9334471225738525
Validation loss: 2.7887858985572733

Epoch: 5| Step: 7
Training loss: 2.5682311058044434
Validation loss: 2.7914779314430813

Epoch: 5| Step: 8
Training loss: 2.889169692993164
Validation loss: 2.7877714377577587

Epoch: 5| Step: 9
Training loss: 2.644421100616455
Validation loss: 2.7875267151863343

Epoch: 5| Step: 10
Training loss: 2.571089267730713
Validation loss: 2.7909794571579143

Epoch: 44| Step: 0
Training loss: 3.2099082469940186
Validation loss: 2.7927315363319973

Epoch: 5| Step: 1
Training loss: 2.942412853240967
Validation loss: 2.7898263931274414

Epoch: 5| Step: 2
Training loss: 2.347809076309204
Validation loss: 2.787386727589433

Epoch: 5| Step: 3
Training loss: 3.299847364425659
Validation loss: 2.7891420984780915

Epoch: 5| Step: 4
Training loss: 3.278444290161133
Validation loss: 2.7883776618588354

Epoch: 5| Step: 5
Training loss: 2.3710083961486816
Validation loss: 2.788562654167093

Epoch: 5| Step: 6
Training loss: 2.84120512008667
Validation loss: 2.7833716536080964

Epoch: 5| Step: 7
Training loss: 3.252408504486084
Validation loss: 2.782526364890478

Epoch: 5| Step: 8
Training loss: 2.6165332794189453
Validation loss: 2.7816511507957213

Epoch: 5| Step: 9
Training loss: 2.397454261779785
Validation loss: 2.786678655173189

Epoch: 5| Step: 10
Training loss: 3.491241216659546
Validation loss: 2.783099082208449

Epoch: 45| Step: 0
Training loss: 2.620553970336914
Validation loss: 2.7783357738166727

Epoch: 5| Step: 1
Training loss: 2.7771382331848145
Validation loss: 2.7807672433955695

Epoch: 5| Step: 2
Training loss: 3.0947678089141846
Validation loss: 2.7827873178707656

Epoch: 5| Step: 3
Training loss: 2.9319605827331543
Validation loss: 2.7843437143551406

Epoch: 5| Step: 4
Training loss: 2.9907047748565674
Validation loss: 2.781590259203347

Epoch: 5| Step: 5
Training loss: 3.3874518871307373
Validation loss: 2.7813888083222094

Epoch: 5| Step: 6
Training loss: 3.180758476257324
Validation loss: 2.7777049695291827

Epoch: 5| Step: 7
Training loss: 2.389198064804077
Validation loss: 2.77973598049533

Epoch: 5| Step: 8
Training loss: 3.0606868267059326
Validation loss: 2.7779238890576106

Epoch: 5| Step: 9
Training loss: 2.5962977409362793
Validation loss: 2.7739628130389797

Epoch: 5| Step: 10
Training loss: 2.9162564277648926
Validation loss: 2.778059997866231

Epoch: 46| Step: 0
Training loss: 3.2893664836883545
Validation loss: 2.771333222748131

Epoch: 5| Step: 1
Training loss: 2.706193208694458
Validation loss: 2.776804383083056

Epoch: 5| Step: 2
Training loss: 2.811279058456421
Validation loss: 2.7735735408721434

Epoch: 5| Step: 3
Training loss: 2.6778454780578613
Validation loss: 2.7734984608106714

Epoch: 5| Step: 4
Training loss: 2.805485486984253
Validation loss: 2.7734201954257105

Epoch: 5| Step: 5
Training loss: 3.3332462310791016
Validation loss: 2.771814856477963

Epoch: 5| Step: 6
Training loss: 3.696418046951294
Validation loss: 2.7723053706589567

Epoch: 5| Step: 7
Training loss: 2.4985427856445312
Validation loss: 2.7714602101233696

Epoch: 5| Step: 8
Training loss: 2.580653667449951
Validation loss: 2.7736257301863803

Epoch: 5| Step: 9
Training loss: 2.8970208168029785
Validation loss: 2.7699421400664956

Epoch: 5| Step: 10
Training loss: 2.516510248184204
Validation loss: 2.7685992179378385

Epoch: 47| Step: 0
Training loss: 2.701730251312256
Validation loss: 2.7700162523536274

Epoch: 5| Step: 1
Training loss: 4.050829887390137
Validation loss: 2.770303705687164

Epoch: 5| Step: 2
Training loss: 3.719339370727539
Validation loss: 2.7706647790888304

Epoch: 5| Step: 3
Training loss: 2.6808829307556152
Validation loss: 2.770166422731133

Epoch: 5| Step: 4
Training loss: 3.232506275177002
Validation loss: 2.7756019587157876

Epoch: 5| Step: 5
Training loss: 3.0000252723693848
Validation loss: 2.7777897081067486

Epoch: 5| Step: 6
Training loss: 2.8958916664123535
Validation loss: 2.77426726330993

Epoch: 5| Step: 7
Training loss: 2.7272884845733643
Validation loss: 2.7738099841661352

Epoch: 5| Step: 8
Training loss: 2.2209153175354004
Validation loss: 2.7805223157328944

Epoch: 5| Step: 9
Training loss: 2.4922144412994385
Validation loss: 2.773800250022642

Epoch: 5| Step: 10
Training loss: 2.0248355865478516
Validation loss: 2.7710350354512534

Epoch: 48| Step: 0
Training loss: 2.8299059867858887
Validation loss: 2.7678887818449285

Epoch: 5| Step: 1
Training loss: 3.051579713821411
Validation loss: 2.7676390576106247

Epoch: 5| Step: 2
Training loss: 2.7710695266723633
Validation loss: 2.768634127032372

Epoch: 5| Step: 3
Training loss: 3.172323226928711
Validation loss: 2.7657701071872505

Epoch: 5| Step: 4
Training loss: 2.9552001953125
Validation loss: 2.769413707076862

Epoch: 5| Step: 5
Training loss: 2.6610260009765625
Validation loss: 2.763673213220412

Epoch: 5| Step: 6
Training loss: 2.9254279136657715
Validation loss: 2.7635686730825775

Epoch: 5| Step: 7
Training loss: 2.7362003326416016
Validation loss: 2.765647444673764

Epoch: 5| Step: 8
Training loss: 2.7001266479492188
Validation loss: 2.761519880704982

Epoch: 5| Step: 9
Training loss: 3.161947727203369
Validation loss: 2.761915001817929

Epoch: 5| Step: 10
Training loss: 2.8894200325012207
Validation loss: 2.761694154431743

Epoch: 49| Step: 0
Training loss: 2.3594491481781006
Validation loss: 2.7588662973014255

Epoch: 5| Step: 1
Training loss: 2.8571338653564453
Validation loss: 2.7611441227697555

Epoch: 5| Step: 2
Training loss: 2.257066249847412
Validation loss: 2.7641426670935845

Epoch: 5| Step: 3
Training loss: 2.8847997188568115
Validation loss: 2.764783154251755

Epoch: 5| Step: 4
Training loss: 3.074185371398926
Validation loss: 2.7628300625790834

Epoch: 5| Step: 5
Training loss: 3.4164860248565674
Validation loss: 2.761512597401937

Epoch: 5| Step: 6
Training loss: 3.267171859741211
Validation loss: 2.7658648977997484

Epoch: 5| Step: 7
Training loss: 2.904163360595703
Validation loss: 2.7688800827149422

Epoch: 5| Step: 8
Training loss: 2.3095614910125732
Validation loss: 2.762826147899833

Epoch: 5| Step: 9
Training loss: 3.4878344535827637
Validation loss: 2.763910108996976

Epoch: 5| Step: 10
Training loss: 2.9569106101989746
Validation loss: 2.766979499529767

Epoch: 50| Step: 0
Training loss: 2.8979134559631348
Validation loss: 2.7609417105233796

Epoch: 5| Step: 1
Training loss: 2.2502541542053223
Validation loss: 2.7629210910489483

Epoch: 5| Step: 2
Training loss: 2.968395948410034
Validation loss: 2.761833331918204

Epoch: 5| Step: 3
Training loss: 3.01251482963562
Validation loss: 2.75830671095079

Epoch: 5| Step: 4
Training loss: 3.1886157989501953
Validation loss: 2.7613766859936457

Epoch: 5| Step: 5
Training loss: 3.3949084281921387
Validation loss: 2.7658179703579155

Epoch: 5| Step: 6
Training loss: 2.304049015045166
Validation loss: 2.763537888885826

Epoch: 5| Step: 7
Training loss: 2.6090500354766846
Validation loss: 2.7564726696219495

Epoch: 5| Step: 8
Training loss: 2.810640335083008
Validation loss: 2.757427700104252

Epoch: 5| Step: 9
Training loss: 3.226696014404297
Validation loss: 2.7571746559553247

Epoch: 5| Step: 10
Training loss: 3.118429660797119
Validation loss: 2.7578037067126204

Epoch: 51| Step: 0
Training loss: 3.09283185005188
Validation loss: 2.752761422946889

Epoch: 5| Step: 1
Training loss: 2.938666820526123
Validation loss: 2.7558468362336517

Epoch: 5| Step: 2
Training loss: 2.1901886463165283
Validation loss: 2.7547606550237185

Epoch: 5| Step: 3
Training loss: 3.328916072845459
Validation loss: 2.7528170552304996

Epoch: 5| Step: 4
Training loss: 2.7632925510406494
Validation loss: 2.753384277384768

Epoch: 5| Step: 5
Training loss: 2.2681617736816406
Validation loss: 2.7539905924950876

Epoch: 5| Step: 6
Training loss: 2.0750057697296143
Validation loss: 2.753340349402479

Epoch: 5| Step: 7
Training loss: 3.3172271251678467
Validation loss: 2.7541366648930374

Epoch: 5| Step: 8
Training loss: 3.9281821250915527
Validation loss: 2.753690322240194

Epoch: 5| Step: 9
Training loss: 3.057750701904297
Validation loss: 2.75392920483825

Epoch: 5| Step: 10
Training loss: 2.712061882019043
Validation loss: 2.751200806710028

Epoch: 52| Step: 0
Training loss: 2.5929946899414062
Validation loss: 2.7510648491562053

Epoch: 5| Step: 1
Training loss: 3.1019911766052246
Validation loss: 2.7568787220985658

Epoch: 5| Step: 2
Training loss: 3.0273337364196777
Validation loss: 2.7685969209158294

Epoch: 5| Step: 3
Training loss: 3.4791502952575684
Validation loss: 2.751348075046334

Epoch: 5| Step: 4
Training loss: 2.5587737560272217
Validation loss: 2.7507970820191088

Epoch: 5| Step: 5
Training loss: 2.6756889820098877
Validation loss: 2.7502664186621226

Epoch: 5| Step: 6
Training loss: 2.7118868827819824
Validation loss: 2.75017733727732

Epoch: 5| Step: 7
Training loss: 2.309450149536133
Validation loss: 2.752875961283202

Epoch: 5| Step: 8
Training loss: 3.638106107711792
Validation loss: 2.74838016879174

Epoch: 5| Step: 9
Training loss: 2.2924067974090576
Validation loss: 2.7484941200543473

Epoch: 5| Step: 10
Training loss: 3.3808975219726562
Validation loss: 2.7505666286714616

Epoch: 53| Step: 0
Training loss: 2.808987855911255
Validation loss: 2.7483742390909502

Epoch: 5| Step: 1
Training loss: 3.499180316925049
Validation loss: 2.7514210849679928

Epoch: 5| Step: 2
Training loss: 3.2234573364257812
Validation loss: 2.751645918815367

Epoch: 5| Step: 3
Training loss: 2.420257091522217
Validation loss: 2.751920069417646

Epoch: 5| Step: 4
Training loss: 3.172288656234741
Validation loss: 2.7526693523571057

Epoch: 5| Step: 5
Training loss: 2.1450705528259277
Validation loss: 2.751994122741043

Epoch: 5| Step: 6
Training loss: 2.925776720046997
Validation loss: 2.75250441797318

Epoch: 5| Step: 7
Training loss: 2.7475438117980957
Validation loss: 2.754651801560515

Epoch: 5| Step: 8
Training loss: 3.094593048095703
Validation loss: 2.75229654260861

Epoch: 5| Step: 9
Training loss: 2.519075870513916
Validation loss: 2.7512209876891105

Epoch: 5| Step: 10
Training loss: 3.1618497371673584
Validation loss: 2.7487032054572977

Epoch: 54| Step: 0
Training loss: 2.636254072189331
Validation loss: 2.7452876003839637

Epoch: 5| Step: 1
Training loss: 2.4276862144470215
Validation loss: 2.7489453336243987

Epoch: 5| Step: 2
Training loss: 2.6682000160217285
Validation loss: 2.7494325099452848

Epoch: 5| Step: 3
Training loss: 2.153200626373291
Validation loss: 2.7452313899993896

Epoch: 5| Step: 4
Training loss: 2.8862242698669434
Validation loss: 2.7493317127227783

Epoch: 5| Step: 5
Training loss: 3.017873764038086
Validation loss: 2.7440359412982898

Epoch: 5| Step: 6
Training loss: 2.7978508472442627
Validation loss: 2.7452524836345384

Epoch: 5| Step: 7
Training loss: 3.3775627613067627
Validation loss: 2.7446042440270864

Epoch: 5| Step: 8
Training loss: 3.9586548805236816
Validation loss: 2.743235408618886

Epoch: 5| Step: 9
Training loss: 2.9682023525238037
Validation loss: 2.747376531682989

Epoch: 5| Step: 10
Training loss: 2.726679801940918
Validation loss: 2.7450133446724183

Epoch: 55| Step: 0
Training loss: 2.783764362335205
Validation loss: 2.7418904919778146

Epoch: 5| Step: 1
Training loss: 2.045290946960449
Validation loss: 2.7431450043955157

Epoch: 5| Step: 2
Training loss: 3.1431612968444824
Validation loss: 2.74429226434359

Epoch: 5| Step: 3
Training loss: 3.4408347606658936
Validation loss: 2.7415469795145015

Epoch: 5| Step: 4
Training loss: 3.7449584007263184
Validation loss: 2.74101673915822

Epoch: 5| Step: 5
Training loss: 2.9198520183563232
Validation loss: 2.743168656544019

Epoch: 5| Step: 6
Training loss: 2.268928050994873
Validation loss: 2.7409437933275775

Epoch: 5| Step: 7
Training loss: 3.1660232543945312
Validation loss: 2.7412693321063952

Epoch: 5| Step: 8
Training loss: 2.8215832710266113
Validation loss: 2.738286664409022

Epoch: 5| Step: 9
Training loss: 2.9636757373809814
Validation loss: 2.7434773214401735

Epoch: 5| Step: 10
Training loss: 2.2174432277679443
Validation loss: 2.7394411051145164

Epoch: 56| Step: 0
Training loss: 3.438387632369995
Validation loss: 2.745152276049378

Epoch: 5| Step: 1
Training loss: 2.416834592819214
Validation loss: 2.742348414595409

Epoch: 5| Step: 2
Training loss: 2.7246246337890625
Validation loss: 2.739589798835016

Epoch: 5| Step: 3
Training loss: 2.8427233695983887
Validation loss: 2.738629053997737

Epoch: 5| Step: 4
Training loss: 2.514491558074951
Validation loss: 2.738369869929488

Epoch: 5| Step: 5
Training loss: 2.9704031944274902
Validation loss: 2.738090838155439

Epoch: 5| Step: 6
Training loss: 2.753934860229492
Validation loss: 2.73590834166414

Epoch: 5| Step: 7
Training loss: 3.2043609619140625
Validation loss: 2.7391746044158936

Epoch: 5| Step: 8
Training loss: 3.255500078201294
Validation loss: 2.7430127589933333

Epoch: 5| Step: 9
Training loss: 3.089388370513916
Validation loss: 2.739328263908304

Epoch: 5| Step: 10
Training loss: 2.307630777359009
Validation loss: 2.7403475315340105

Epoch: 57| Step: 0
Training loss: 2.7343266010284424
Validation loss: 2.7366455537016674

Epoch: 5| Step: 1
Training loss: 3.0422418117523193
Validation loss: 2.7357300353306595

Epoch: 5| Step: 2
Training loss: 2.349785566329956
Validation loss: 2.7381220709893013

Epoch: 5| Step: 3
Training loss: 2.755913019180298
Validation loss: 2.7344130931362027

Epoch: 5| Step: 4
Training loss: 2.3169476985931396
Validation loss: 2.7325123202416206

Epoch: 5| Step: 5
Training loss: 2.884622097015381
Validation loss: 2.7319721560324393

Epoch: 5| Step: 6
Training loss: 3.031452178955078
Validation loss: 2.735843789192938

Epoch: 5| Step: 7
Training loss: 3.459315061569214
Validation loss: 2.7342183487389677

Epoch: 5| Step: 8
Training loss: 2.5603394508361816
Validation loss: 2.7357791931398454

Epoch: 5| Step: 9
Training loss: 3.1238925457000732
Validation loss: 2.733941698587069

Epoch: 5| Step: 10
Training loss: 3.3564324378967285
Validation loss: 2.7316304047902427

Epoch: 58| Step: 0
Training loss: 3.568647861480713
Validation loss: 2.730356390758227

Epoch: 5| Step: 1
Training loss: 2.079413414001465
Validation loss: 2.7324077544673795

Epoch: 5| Step: 2
Training loss: 2.7082297801971436
Validation loss: 2.729300001616119

Epoch: 5| Step: 3
Training loss: 2.9519050121307373
Validation loss: 2.731808639341785

Epoch: 5| Step: 4
Training loss: 2.8479275703430176
Validation loss: 2.7280663751786753

Epoch: 5| Step: 5
Training loss: 3.403782367706299
Validation loss: 2.7326040447399182

Epoch: 5| Step: 6
Training loss: 2.6580612659454346
Validation loss: 2.729426981300436

Epoch: 5| Step: 7
Training loss: 2.8306806087493896
Validation loss: 2.731165547524729

Epoch: 5| Step: 8
Training loss: 3.044219970703125
Validation loss: 2.729146311360021

Epoch: 5| Step: 9
Training loss: 3.156343698501587
Validation loss: 2.7309586463436

Epoch: 5| Step: 10
Training loss: 2.191908836364746
Validation loss: 2.7304973371567263

Epoch: 59| Step: 0
Training loss: 3.702410936355591
Validation loss: 2.7312880075106056

Epoch: 5| Step: 1
Training loss: 3.0962295532226562
Validation loss: 2.7300287831214165

Epoch: 5| Step: 2
Training loss: 2.7280304431915283
Validation loss: 2.7278401749108427

Epoch: 5| Step: 3
Training loss: 2.8973581790924072
Validation loss: 2.728179616312827

Epoch: 5| Step: 4
Training loss: 2.6137006282806396
Validation loss: 2.730003405642766

Epoch: 5| Step: 5
Training loss: 3.3193061351776123
Validation loss: 2.727694962614326

Epoch: 5| Step: 6
Training loss: 2.291921377182007
Validation loss: 2.728483292364305

Epoch: 5| Step: 7
Training loss: 2.5831573009490967
Validation loss: 2.725984752819102

Epoch: 5| Step: 8
Training loss: 2.758059024810791
Validation loss: 2.7242744994419876

Epoch: 5| Step: 9
Training loss: 2.6192080974578857
Validation loss: 2.7257185777028403

Epoch: 5| Step: 10
Training loss: 2.898125171661377
Validation loss: 2.7282593763002785

Epoch: 60| Step: 0
Training loss: 3.3237195014953613
Validation loss: 2.7287745603951077

Epoch: 5| Step: 1
Training loss: 2.560251235961914
Validation loss: 2.734224163075929

Epoch: 5| Step: 2
Training loss: 2.945657730102539
Validation loss: 2.7314547466975387

Epoch: 5| Step: 3
Training loss: 2.5964090824127197
Validation loss: 2.7300426037080827

Epoch: 5| Step: 4
Training loss: 2.7112138271331787
Validation loss: 2.7280221293049474

Epoch: 5| Step: 5
Training loss: 3.468620777130127
Validation loss: 2.723820409467143

Epoch: 5| Step: 6
Training loss: 2.8396122455596924
Validation loss: 2.7255479597276255

Epoch: 5| Step: 7
Training loss: 2.7250375747680664
Validation loss: 2.7235059481795116

Epoch: 5| Step: 8
Training loss: 2.5140221118927
Validation loss: 2.718077369915542

Epoch: 5| Step: 9
Training loss: 3.210824966430664
Validation loss: 2.719936106794624

Epoch: 5| Step: 10
Training loss: 2.5286355018615723
Validation loss: 2.72228100222926

Epoch: 61| Step: 0
Training loss: 3.5128817558288574
Validation loss: 2.7223932896890948

Epoch: 5| Step: 1
Training loss: 1.9273420572280884
Validation loss: 2.7251791979676936

Epoch: 5| Step: 2
Training loss: 2.864678144454956
Validation loss: 2.723502710301389

Epoch: 5| Step: 3
Training loss: 2.707127332687378
Validation loss: 2.7211238620101765

Epoch: 5| Step: 4
Training loss: 3.207927703857422
Validation loss: 2.717355482039913

Epoch: 5| Step: 5
Training loss: 2.552102565765381
Validation loss: 2.717967812732984

Epoch: 5| Step: 6
Training loss: 2.711059093475342
Validation loss: 2.7185364461714223

Epoch: 5| Step: 7
Training loss: 2.8150668144226074
Validation loss: 2.717830393903999

Epoch: 5| Step: 8
Training loss: 3.1787216663360596
Validation loss: 2.722252030526438

Epoch: 5| Step: 9
Training loss: 2.7908005714416504
Validation loss: 2.7240793551168134

Epoch: 5| Step: 10
Training loss: 3.278122663497925
Validation loss: 2.7190903540580504

Epoch: 62| Step: 0
Training loss: 3.2149453163146973
Validation loss: 2.719271226595807

Epoch: 5| Step: 1
Training loss: 2.826249837875366
Validation loss: 2.7197656631469727

Epoch: 5| Step: 2
Training loss: 3.322305202484131
Validation loss: 2.7184418375774095

Epoch: 5| Step: 3
Training loss: 2.732146739959717
Validation loss: 2.7202810113148024

Epoch: 5| Step: 4
Training loss: 2.2650396823883057
Validation loss: 2.7202242574384137

Epoch: 5| Step: 5
Training loss: 3.070382595062256
Validation loss: 2.722759267335297

Epoch: 5| Step: 6
Training loss: 2.319704055786133
Validation loss: 2.722817777305521

Epoch: 5| Step: 7
Training loss: 2.926002025604248
Validation loss: 2.7169168456908195

Epoch: 5| Step: 8
Training loss: 3.289966583251953
Validation loss: 2.7167660138940297

Epoch: 5| Step: 9
Training loss: 2.9056968688964844
Validation loss: 2.7148890623482327

Epoch: 5| Step: 10
Training loss: 2.4791126251220703
Validation loss: 2.7156823373609975

Epoch: 63| Step: 0
Training loss: 2.631171703338623
Validation loss: 2.717883199773809

Epoch: 5| Step: 1
Training loss: 3.1149063110351562
Validation loss: 2.7132657343341458

Epoch: 5| Step: 2
Training loss: 2.6259305477142334
Validation loss: 2.7136984050914807

Epoch: 5| Step: 3
Training loss: 3.055142641067505
Validation loss: 2.7138044244499615

Epoch: 5| Step: 4
Training loss: 2.676844358444214
Validation loss: 2.7145113663006852

Epoch: 5| Step: 5
Training loss: 3.2819924354553223
Validation loss: 2.7168688312653573

Epoch: 5| Step: 6
Training loss: 2.7783939838409424
Validation loss: 2.714503252378074

Epoch: 5| Step: 7
Training loss: 2.328209400177002
Validation loss: 2.717155123269686

Epoch: 5| Step: 8
Training loss: 3.179661989212036
Validation loss: 2.719635932676254

Epoch: 5| Step: 9
Training loss: 3.1229491233825684
Validation loss: 2.715060169978808

Epoch: 5| Step: 10
Training loss: 2.5534958839416504
Validation loss: 2.7168779988442697

Epoch: 64| Step: 0
Training loss: 2.549962282180786
Validation loss: 2.719165740474578

Epoch: 5| Step: 1
Training loss: 3.1096768379211426
Validation loss: 2.7141984137155677

Epoch: 5| Step: 2
Training loss: 2.495114326477051
Validation loss: 2.715420102560392

Epoch: 5| Step: 3
Training loss: 2.374793767929077
Validation loss: 2.7126884639904065

Epoch: 5| Step: 4
Training loss: 3.153494358062744
Validation loss: 2.7141909932577484

Epoch: 5| Step: 5
Training loss: 2.8371188640594482
Validation loss: 2.715156534666656

Epoch: 5| Step: 6
Training loss: 3.3575046062469482
Validation loss: 2.7128915427833475

Epoch: 5| Step: 7
Training loss: 2.6439967155456543
Validation loss: 2.7122278418592227

Epoch: 5| Step: 8
Training loss: 2.872479200363159
Validation loss: 2.717660222002255

Epoch: 5| Step: 9
Training loss: 3.175147533416748
Validation loss: 2.71287658650388

Epoch: 5| Step: 10
Training loss: 2.7482750415802
Validation loss: 2.7200197353157947

Epoch: 65| Step: 0
Training loss: 2.494293212890625
Validation loss: 2.7182422325175297

Epoch: 5| Step: 1
Training loss: 3.1415061950683594
Validation loss: 2.7204627349812496

Epoch: 5| Step: 2
Training loss: 2.757079839706421
Validation loss: 2.727390868689424

Epoch: 5| Step: 3
Training loss: 3.6180007457733154
Validation loss: 2.723651820613492

Epoch: 5| Step: 4
Training loss: 3.1170380115509033
Validation loss: 2.722608963648478

Epoch: 5| Step: 5
Training loss: 3.1727688312530518
Validation loss: 2.7247152866855746

Epoch: 5| Step: 6
Training loss: 3.1463332176208496
Validation loss: 2.7204617172159176

Epoch: 5| Step: 7
Training loss: 1.8405898809432983
Validation loss: 2.7182069337496193

Epoch: 5| Step: 8
Training loss: 2.510225296020508
Validation loss: 2.715052289347495

Epoch: 5| Step: 9
Training loss: 3.0290884971618652
Validation loss: 2.7104446631605907

Epoch: 5| Step: 10
Training loss: 2.492300033569336
Validation loss: 2.710786352875412

Epoch: 66| Step: 0
Training loss: 2.680534839630127
Validation loss: 2.70829197155532

Epoch: 5| Step: 1
Training loss: 2.7434773445129395
Validation loss: 2.709534850171817

Epoch: 5| Step: 2
Training loss: 2.698598861694336
Validation loss: 2.7115390505841983

Epoch: 5| Step: 3
Training loss: 2.7151730060577393
Validation loss: 2.711467273773686

Epoch: 5| Step: 4
Training loss: 2.4680824279785156
Validation loss: 2.711238891847672

Epoch: 5| Step: 5
Training loss: 3.292334794998169
Validation loss: 2.716163340435233

Epoch: 5| Step: 6
Training loss: 3.3651955127716064
Validation loss: 2.716073041321129

Epoch: 5| Step: 7
Training loss: 3.1170756816864014
Validation loss: 2.7119951491714804

Epoch: 5| Step: 8
Training loss: 2.7243082523345947
Validation loss: 2.710310887264949

Epoch: 5| Step: 9
Training loss: 3.165313959121704
Validation loss: 2.710510846107237

Epoch: 5| Step: 10
Training loss: 2.2478716373443604
Validation loss: 2.709048419870356

Epoch: 67| Step: 0
Training loss: 2.6367228031158447
Validation loss: 2.712243177557504

Epoch: 5| Step: 1
Training loss: 3.748447895050049
Validation loss: 2.7134312096462456

Epoch: 5| Step: 2
Training loss: 2.2397708892822266
Validation loss: 2.713879277629237

Epoch: 5| Step: 3
Training loss: 3.3077011108398438
Validation loss: 2.7139464142501994

Epoch: 5| Step: 4
Training loss: 2.4843411445617676
Validation loss: 2.715079479320075

Epoch: 5| Step: 5
Training loss: 2.849107027053833
Validation loss: 2.707325586708643

Epoch: 5| Step: 6
Training loss: 2.625694513320923
Validation loss: 2.704905822712888

Epoch: 5| Step: 7
Training loss: 2.8896584510803223
Validation loss: 2.704240175985521

Epoch: 5| Step: 8
Training loss: 2.737452745437622
Validation loss: 2.7019673880710395

Epoch: 5| Step: 9
Training loss: 3.1835007667541504
Validation loss: 2.7021138283514206

Epoch: 5| Step: 10
Training loss: 2.5465245246887207
Validation loss: 2.699447671572367

Epoch: 68| Step: 0
Training loss: 2.507305145263672
Validation loss: 2.699130747907905

Epoch: 5| Step: 1
Training loss: 2.6669657230377197
Validation loss: 2.704143096041936

Epoch: 5| Step: 2
Training loss: 2.416334867477417
Validation loss: 2.702901783809867

Epoch: 5| Step: 3
Training loss: 3.5209145545959473
Validation loss: 2.709198377465689

Epoch: 5| Step: 4
Training loss: 3.4351882934570312
Validation loss: 2.7016957472729426

Epoch: 5| Step: 5
Training loss: 2.9511094093322754
Validation loss: 2.7013163848589827

Epoch: 5| Step: 6
Training loss: 3.0442593097686768
Validation loss: 2.701048545939948

Epoch: 5| Step: 7
Training loss: 1.9526422023773193
Validation loss: 2.700609948045464

Epoch: 5| Step: 8
Training loss: 3.012708902359009
Validation loss: 2.7014892203833467

Epoch: 5| Step: 9
Training loss: 2.40409517288208
Validation loss: 2.704778581537226

Epoch: 5| Step: 10
Training loss: 3.450791835784912
Validation loss: 2.700132798123103

Epoch: 69| Step: 0
Training loss: 2.7577855587005615
Validation loss: 2.7014412418488534

Epoch: 5| Step: 1
Training loss: 2.434168577194214
Validation loss: 2.705575689192741

Epoch: 5| Step: 2
Training loss: 3.6442623138427734
Validation loss: 2.707920782027706

Epoch: 5| Step: 3
Training loss: 3.0527844429016113
Validation loss: 2.702741635743008

Epoch: 5| Step: 4
Training loss: 3.2651379108428955
Validation loss: 2.701991763166202

Epoch: 5| Step: 5
Training loss: 2.2339892387390137
Validation loss: 2.698546573679934

Epoch: 5| Step: 6
Training loss: 2.362053394317627
Validation loss: 2.6994943644410823

Epoch: 5| Step: 7
Training loss: 2.651587724685669
Validation loss: 2.6955429174566783

Epoch: 5| Step: 8
Training loss: 3.0887577533721924
Validation loss: 2.695289429797921

Epoch: 5| Step: 9
Training loss: 3.3016083240509033
Validation loss: 2.693952352769913

Epoch: 5| Step: 10
Training loss: 2.3637349605560303
Validation loss: 2.6940033564003567

Epoch: 70| Step: 0
Training loss: 2.5642902851104736
Validation loss: 2.6949198886912358

Epoch: 5| Step: 1
Training loss: 2.2391974925994873
Validation loss: 2.699827717196557

Epoch: 5| Step: 2
Training loss: 2.6724040508270264
Validation loss: 2.698869707763836

Epoch: 5| Step: 3
Training loss: 2.9135584831237793
Validation loss: 2.696254781497422

Epoch: 5| Step: 4
Training loss: 3.112232208251953
Validation loss: 2.7024767065560944

Epoch: 5| Step: 5
Training loss: 2.4478676319122314
Validation loss: 2.7100820567018244

Epoch: 5| Step: 6
Training loss: 3.9033913612365723
Validation loss: 2.7265158955768873

Epoch: 5| Step: 7
Training loss: 3.443026304244995
Validation loss: 2.734418910036805

Epoch: 5| Step: 8
Training loss: 2.794890880584717
Validation loss: 2.7025678721807336

Epoch: 5| Step: 9
Training loss: 2.776238203048706
Validation loss: 2.6949330196585706

Epoch: 5| Step: 10
Training loss: 2.3261470794677734
Validation loss: 2.69385039934548

Epoch: 71| Step: 0
Training loss: 2.9157698154449463
Validation loss: 2.6941181844280613

Epoch: 5| Step: 1
Training loss: 2.9671595096588135
Validation loss: 2.692818844190208

Epoch: 5| Step: 2
Training loss: 2.73555326461792
Validation loss: 2.6984828697737826

Epoch: 5| Step: 3
Training loss: 2.669156551361084
Validation loss: 2.697927849267119

Epoch: 5| Step: 4
Training loss: 2.975456714630127
Validation loss: 2.6960607574832056

Epoch: 5| Step: 5
Training loss: 2.3391668796539307
Validation loss: 2.693997852263912

Epoch: 5| Step: 6
Training loss: 2.4691953659057617
Validation loss: 2.697001016268166

Epoch: 5| Step: 7
Training loss: 3.187250852584839
Validation loss: 2.699140335923882

Epoch: 5| Step: 8
Training loss: 2.8493270874023438
Validation loss: 2.700069891509189

Epoch: 5| Step: 9
Training loss: 3.599384307861328
Validation loss: 2.699852838311144

Epoch: 5| Step: 10
Training loss: 2.4872331619262695
Validation loss: 2.699331719388244

Epoch: 72| Step: 0
Training loss: 2.418116331100464
Validation loss: 2.7061250261081162

Epoch: 5| Step: 1
Training loss: 3.0994105339050293
Validation loss: 2.7317204680494083

Epoch: 5| Step: 2
Training loss: 2.7370200157165527
Validation loss: 2.699076473072011

Epoch: 5| Step: 3
Training loss: 3.0002825260162354
Validation loss: 2.6960159347903345

Epoch: 5| Step: 4
Training loss: 2.3002424240112305
Validation loss: 2.695235188289355

Epoch: 5| Step: 5
Training loss: 2.76739239692688
Validation loss: 2.6951016097940426

Epoch: 5| Step: 6
Training loss: 3.2459518909454346
Validation loss: 2.6966922821537143

Epoch: 5| Step: 7
Training loss: 2.6242263317108154
Validation loss: 2.6980148259029595

Epoch: 5| Step: 8
Training loss: 3.5723133087158203
Validation loss: 2.7004391531790457

Epoch: 5| Step: 9
Training loss: 3.038831949234009
Validation loss: 2.7025340782698763

Epoch: 5| Step: 10
Training loss: 2.437993049621582
Validation loss: 2.707482076460315

Epoch: 73| Step: 0
Training loss: 2.391512393951416
Validation loss: 2.702485961298789

Epoch: 5| Step: 1
Training loss: 2.27063250541687
Validation loss: 2.7054456075032554

Epoch: 5| Step: 2
Training loss: 3.0583558082580566
Validation loss: 2.694906770542104

Epoch: 5| Step: 3
Training loss: 2.9193103313446045
Validation loss: 2.6955298351985153

Epoch: 5| Step: 4
Training loss: 2.795207977294922
Validation loss: 2.6965546223425094

Epoch: 5| Step: 5
Training loss: 2.191401958465576
Validation loss: 2.691564570191086

Epoch: 5| Step: 6
Training loss: 3.4925804138183594
Validation loss: 2.699646170421313

Epoch: 5| Step: 7
Training loss: 3.417886257171631
Validation loss: 2.6984837798662085

Epoch: 5| Step: 8
Training loss: 3.1198859214782715
Validation loss: 2.6965613621537403

Epoch: 5| Step: 9
Training loss: 2.7539124488830566
Validation loss: 2.6965943869724067

Epoch: 5| Step: 10
Training loss: 2.816143274307251
Validation loss: 2.696315260343654

Epoch: 74| Step: 0
Training loss: 2.898988723754883
Validation loss: 2.692044614463724

Epoch: 5| Step: 1
Training loss: 3.255260944366455
Validation loss: 2.693613993224277

Epoch: 5| Step: 2
Training loss: 2.440300464630127
Validation loss: 2.692919361975885

Epoch: 5| Step: 3
Training loss: 2.97894549369812
Validation loss: 2.695299184450539

Epoch: 5| Step: 4
Training loss: 2.9615492820739746
Validation loss: 2.6957571070681334

Epoch: 5| Step: 5
Training loss: 2.2641515731811523
Validation loss: 2.6917914677691717

Epoch: 5| Step: 6
Training loss: 3.558769941329956
Validation loss: 2.6983612019528627

Epoch: 5| Step: 7
Training loss: 2.6689162254333496
Validation loss: 2.702635439493323

Epoch: 5| Step: 8
Training loss: 2.341564178466797
Validation loss: 2.6961784311520156

Epoch: 5| Step: 9
Training loss: 3.1526761054992676
Validation loss: 2.6974528963847826

Epoch: 5| Step: 10
Training loss: 2.6052565574645996
Validation loss: 2.6882142507901756

Epoch: 75| Step: 0
Training loss: 2.6378071308135986
Validation loss: 2.6859384505979476

Epoch: 5| Step: 1
Training loss: 3.358900785446167
Validation loss: 2.6863388810106503

Epoch: 5| Step: 2
Training loss: 2.612699508666992
Validation loss: 2.6833361297525387

Epoch: 5| Step: 3
Training loss: 2.880431652069092
Validation loss: 2.680190045346496

Epoch: 5| Step: 4
Training loss: 3.152320384979248
Validation loss: 2.6867065378414687

Epoch: 5| Step: 5
Training loss: 2.5542173385620117
Validation loss: 2.683241451940229

Epoch: 5| Step: 6
Training loss: 2.6894888877868652
Validation loss: 2.6774305502573648

Epoch: 5| Step: 7
Training loss: 3.2444496154785156
Validation loss: 2.6818384329477944

Epoch: 5| Step: 8
Training loss: 2.82928204536438
Validation loss: 2.6777272352608303

Epoch: 5| Step: 9
Training loss: 2.89738392829895
Validation loss: 2.6817332108815513

Epoch: 5| Step: 10
Training loss: 2.178595781326294
Validation loss: 2.6810227183885473

Epoch: 76| Step: 0
Training loss: 3.015913724899292
Validation loss: 2.6808696639153267

Epoch: 5| Step: 1
Training loss: 2.5229580402374268
Validation loss: 2.676506160407938

Epoch: 5| Step: 2
Training loss: 2.9578073024749756
Validation loss: 2.6752776945790937

Epoch: 5| Step: 3
Training loss: 2.3505234718322754
Validation loss: 2.67931854596702

Epoch: 5| Step: 4
Training loss: 2.828789234161377
Validation loss: 2.6776823510405836

Epoch: 5| Step: 5
Training loss: 2.5531671047210693
Validation loss: 2.6774591092140443

Epoch: 5| Step: 6
Training loss: 2.766144275665283
Validation loss: 2.684150183072654

Epoch: 5| Step: 7
Training loss: 2.714998245239258
Validation loss: 2.6811416174775813

Epoch: 5| Step: 8
Training loss: 3.0589189529418945
Validation loss: 2.6809163913931897

Epoch: 5| Step: 9
Training loss: 3.204092502593994
Validation loss: 2.6836323507370485

Epoch: 5| Step: 10
Training loss: 3.2002928256988525
Validation loss: 2.685058219458467

Epoch: 77| Step: 0
Training loss: 3.2061100006103516
Validation loss: 2.6863575955872894

Epoch: 5| Step: 1
Training loss: 2.415036678314209
Validation loss: 2.6774380796699115

Epoch: 5| Step: 2
Training loss: 2.65625262260437
Validation loss: 2.681858601108674

Epoch: 5| Step: 3
Training loss: 2.7512826919555664
Validation loss: 2.681495125575732

Epoch: 5| Step: 4
Training loss: 3.016737461090088
Validation loss: 2.678466168783044

Epoch: 5| Step: 5
Training loss: 2.789334774017334
Validation loss: 2.68750286358659

Epoch: 5| Step: 6
Training loss: 3.599519729614258
Validation loss: 2.685831605747182

Epoch: 5| Step: 7
Training loss: 1.6823068857192993
Validation loss: 2.6889406788733696

Epoch: 5| Step: 8
Training loss: 3.072434902191162
Validation loss: 2.6881736722043765

Epoch: 5| Step: 9
Training loss: 3.154326915740967
Validation loss: 2.6853457112466135

Epoch: 5| Step: 10
Training loss: 2.71685528755188
Validation loss: 2.6846625215263775

Epoch: 78| Step: 0
Training loss: 2.908902406692505
Validation loss: 2.6849379770217405

Epoch: 5| Step: 1
Training loss: 2.418566942214966
Validation loss: 2.6893954277038574

Epoch: 5| Step: 2
Training loss: 3.4357686042785645
Validation loss: 2.682953337187408

Epoch: 5| Step: 3
Training loss: 3.1118152141571045
Validation loss: 2.6816483184855473

Epoch: 5| Step: 4
Training loss: 2.275212049484253
Validation loss: 2.6770475936192337

Epoch: 5| Step: 5
Training loss: 2.5726444721221924
Validation loss: 2.6774079261287564

Epoch: 5| Step: 6
Training loss: 3.7947299480438232
Validation loss: 2.6796561236022622

Epoch: 5| Step: 7
Training loss: 2.462587833404541
Validation loss: 2.6813727630082

Epoch: 5| Step: 8
Training loss: 2.2684779167175293
Validation loss: 2.681594228231779

Epoch: 5| Step: 9
Training loss: 2.922269344329834
Validation loss: 2.6763014357577086

Epoch: 5| Step: 10
Training loss: 2.8838062286376953
Validation loss: 2.673860001307662

Epoch: 79| Step: 0
Training loss: 3.3342208862304688
Validation loss: 2.674675203138782

Epoch: 5| Step: 1
Training loss: 2.4359281063079834
Validation loss: 2.67203720923393

Epoch: 5| Step: 2
Training loss: 3.0312423706054688
Validation loss: 2.673810907589492

Epoch: 5| Step: 3
Training loss: 3.409794569015503
Validation loss: 2.6680496943894254

Epoch: 5| Step: 4
Training loss: 2.2462730407714844
Validation loss: 2.6663001814196186

Epoch: 5| Step: 5
Training loss: 2.4673542976379395
Validation loss: 2.671175443997947

Epoch: 5| Step: 6
Training loss: 2.528923273086548
Validation loss: 2.6656509855742097

Epoch: 5| Step: 7
Training loss: 2.6492371559143066
Validation loss: 2.6721843237517984

Epoch: 5| Step: 8
Training loss: 2.897853374481201
Validation loss: 2.6728107672865673

Epoch: 5| Step: 9
Training loss: 3.239748477935791
Validation loss: 2.668269826519874

Epoch: 5| Step: 10
Training loss: 2.7724769115448
Validation loss: 2.676390646606363

Epoch: 80| Step: 0
Training loss: 2.7197728157043457
Validation loss: 2.670465002777756

Epoch: 5| Step: 1
Training loss: 3.313532590866089
Validation loss: 2.673151590490854

Epoch: 5| Step: 2
Training loss: 3.083019733428955
Validation loss: 2.6811118638643654

Epoch: 5| Step: 3
Training loss: 2.5468406677246094
Validation loss: 2.675437737536687

Epoch: 5| Step: 4
Training loss: 3.5729668140411377
Validation loss: 2.680600191957207

Epoch: 5| Step: 5
Training loss: 2.5976555347442627
Validation loss: 2.685037671878774

Epoch: 5| Step: 6
Training loss: 2.4099221229553223
Validation loss: 2.6802013843290267

Epoch: 5| Step: 7
Training loss: 2.2696728706359863
Validation loss: 2.6749950506353892

Epoch: 5| Step: 8
Training loss: 3.0115246772766113
Validation loss: 2.6766251876790035

Epoch: 5| Step: 9
Training loss: 2.1988844871520996
Validation loss: 2.6689644398227816

Epoch: 5| Step: 10
Training loss: 3.4806435108184814
Validation loss: 2.674621133394139

Epoch: 81| Step: 0
Training loss: 2.825551986694336
Validation loss: 2.6727012126676497

Epoch: 5| Step: 1
Training loss: 2.3930344581604004
Validation loss: 2.6707425476402364

Epoch: 5| Step: 2
Training loss: 3.311596632003784
Validation loss: 2.675489235949773

Epoch: 5| Step: 3
Training loss: 2.0199403762817383
Validation loss: 2.6762085012210313

Epoch: 5| Step: 4
Training loss: 2.4205124378204346
Validation loss: 2.674421336061211

Epoch: 5| Step: 5
Training loss: 2.509059190750122
Validation loss: 2.6793609383285686

Epoch: 5| Step: 6
Training loss: 2.8835363388061523
Validation loss: 2.6860510636401433

Epoch: 5| Step: 7
Training loss: 3.524479627609253
Validation loss: 2.6776869655937277

Epoch: 5| Step: 8
Training loss: 3.066802501678467
Validation loss: 2.684222036792386

Epoch: 5| Step: 9
Training loss: 3.1528401374816895
Validation loss: 2.6842902347605717

Epoch: 5| Step: 10
Training loss: 3.00242018699646
Validation loss: 2.67460266236336

Epoch: 82| Step: 0
Training loss: 2.7170462608337402
Validation loss: 2.674796647922967

Epoch: 5| Step: 1
Training loss: 2.497710704803467
Validation loss: 2.6711947687210573

Epoch: 5| Step: 2
Training loss: 3.124493360519409
Validation loss: 2.6717259960789836

Epoch: 5| Step: 3
Training loss: 2.6093826293945312
Validation loss: 2.666238843753774

Epoch: 5| Step: 4
Training loss: 3.1894125938415527
Validation loss: 2.6707317572768017

Epoch: 5| Step: 5
Training loss: 3.1289451122283936
Validation loss: 2.666205411316246

Epoch: 5| Step: 6
Training loss: 2.5255353450775146
Validation loss: 2.664604366466563

Epoch: 5| Step: 7
Training loss: 2.8049893379211426
Validation loss: 2.6629462857400217

Epoch: 5| Step: 8
Training loss: 3.0540852546691895
Validation loss: 2.6649866616854103

Epoch: 5| Step: 9
Training loss: 2.3132848739624023
Validation loss: 2.6639195924164145

Epoch: 5| Step: 10
Training loss: 3.013695001602173
Validation loss: 2.6640664685157036

Epoch: 83| Step: 0
Training loss: 2.492183208465576
Validation loss: 2.661451088484897

Epoch: 5| Step: 1
Training loss: 3.028045415878296
Validation loss: 2.663783388753091

Epoch: 5| Step: 2
Training loss: 2.197338581085205
Validation loss: 2.665194449886199

Epoch: 5| Step: 3
Training loss: 2.88496732711792
Validation loss: 2.6684032947786394

Epoch: 5| Step: 4
Training loss: 3.124119758605957
Validation loss: 2.6699573634773173

Epoch: 5| Step: 5
Training loss: 2.273189067840576
Validation loss: 2.6732177631829375

Epoch: 5| Step: 6
Training loss: 2.727750301361084
Validation loss: 2.6677943891094578

Epoch: 5| Step: 7
Training loss: 3.426628828048706
Validation loss: 2.6711119144193587

Epoch: 5| Step: 8
Training loss: 3.025521755218506
Validation loss: 2.670040358779251

Epoch: 5| Step: 9
Training loss: 2.939868927001953
Validation loss: 2.6683415136029645

Epoch: 5| Step: 10
Training loss: 2.7943999767303467
Validation loss: 2.668540526461858

Epoch: 84| Step: 0
Training loss: 2.522012233734131
Validation loss: 2.6667611240058817

Epoch: 5| Step: 1
Training loss: 2.960707426071167
Validation loss: 2.6685204762284473

Epoch: 5| Step: 2
Training loss: 2.3919403553009033
Validation loss: 2.672517325288506

Epoch: 5| Step: 3
Training loss: 3.3315651416778564
Validation loss: 2.685636261458038

Epoch: 5| Step: 4
Training loss: 2.9696121215820312
Validation loss: 2.6758062070415867

Epoch: 5| Step: 5
Training loss: 2.9936299324035645
Validation loss: 2.672867090471329

Epoch: 5| Step: 6
Training loss: 3.192396402359009
Validation loss: 2.670529096357284

Epoch: 5| Step: 7
Training loss: 2.9339847564697266
Validation loss: 2.6693253670969317

Epoch: 5| Step: 8
Training loss: 2.6524817943573
Validation loss: 2.6664035858646518

Epoch: 5| Step: 9
Training loss: 2.4744086265563965
Validation loss: 2.66419642971408

Epoch: 5| Step: 10
Training loss: 2.4425048828125
Validation loss: 2.6621507572871383

Epoch: 85| Step: 0
Training loss: 3.5240771770477295
Validation loss: 2.6648194636068037

Epoch: 5| Step: 1
Training loss: 2.621152400970459
Validation loss: 2.665233555660453

Epoch: 5| Step: 2
Training loss: 2.467566728591919
Validation loss: 2.6726182686385287

Epoch: 5| Step: 3
Training loss: 2.7881367206573486
Validation loss: 2.672313690185547

Epoch: 5| Step: 4
Training loss: 2.5590133666992188
Validation loss: 2.675270967586066

Epoch: 5| Step: 5
Training loss: 2.8438947200775146
Validation loss: 2.6638074536477365

Epoch: 5| Step: 6
Training loss: 2.7493793964385986
Validation loss: 2.6600269938027985

Epoch: 5| Step: 7
Training loss: 2.8145904541015625
Validation loss: 2.658433170728786

Epoch: 5| Step: 8
Training loss: 2.4573230743408203
Validation loss: 2.6567031760369577

Epoch: 5| Step: 9
Training loss: 3.1902294158935547
Validation loss: 2.6576186098078245

Epoch: 5| Step: 10
Training loss: 2.9424288272857666
Validation loss: 2.6555419378383185

Epoch: 86| Step: 0
Training loss: 3.0817854404449463
Validation loss: 2.6556391459639355

Epoch: 5| Step: 1
Training loss: 2.702723979949951
Validation loss: 2.654533742576517

Epoch: 5| Step: 2
Training loss: 2.909470319747925
Validation loss: 2.6564666301973405

Epoch: 5| Step: 3
Training loss: 2.6756863594055176
Validation loss: 2.6583224906716296

Epoch: 5| Step: 4
Training loss: 2.866318941116333
Validation loss: 2.65925697870152

Epoch: 5| Step: 5
Training loss: 2.5458335876464844
Validation loss: 2.6548216778744935

Epoch: 5| Step: 6
Training loss: 3.246729612350464
Validation loss: 2.654338400851014

Epoch: 5| Step: 7
Training loss: 2.4984874725341797
Validation loss: 2.6554931376570012

Epoch: 5| Step: 8
Training loss: 2.5850377082824707
Validation loss: 2.655400094165597

Epoch: 5| Step: 9
Training loss: 2.798612356185913
Validation loss: 2.653803022958899

Epoch: 5| Step: 10
Training loss: 3.035257339477539
Validation loss: 2.6543784731177875

Epoch: 87| Step: 0
Training loss: 3.485741138458252
Validation loss: 2.6533252039263324

Epoch: 5| Step: 1
Training loss: 2.9953808784484863
Validation loss: 2.6544354628491145

Epoch: 5| Step: 2
Training loss: 3.458735704421997
Validation loss: 2.656650484249156

Epoch: 5| Step: 3
Training loss: 2.8490471839904785
Validation loss: 2.65664674902475

Epoch: 5| Step: 4
Training loss: 3.0318832397460938
Validation loss: 2.6536462486431165

Epoch: 5| Step: 5
Training loss: 2.4173731803894043
Validation loss: 2.6567575136820474

Epoch: 5| Step: 6
Training loss: 2.376919984817505
Validation loss: 2.6546514700817805

Epoch: 5| Step: 7
Training loss: 2.3275671005249023
Validation loss: 2.65348151165952

Epoch: 5| Step: 8
Training loss: 2.994781494140625
Validation loss: 2.654689250453826

Epoch: 5| Step: 9
Training loss: 2.396296262741089
Validation loss: 2.6552954155911683

Epoch: 5| Step: 10
Training loss: 2.4897046089172363
Validation loss: 2.6525366178122898

Epoch: 88| Step: 0
Training loss: 2.516225814819336
Validation loss: 2.6526542914811

Epoch: 5| Step: 1
Training loss: 3.5812957286834717
Validation loss: 2.6509155329837593

Epoch: 5| Step: 2
Training loss: 3.046997308731079
Validation loss: 2.65172440262251

Epoch: 5| Step: 3
Training loss: 2.106743335723877
Validation loss: 2.6529195565049366

Epoch: 5| Step: 4
Training loss: 2.4049973487854004
Validation loss: 2.657486051641485

Epoch: 5| Step: 5
Training loss: 2.589137554168701
Validation loss: 2.664074120983001

Epoch: 5| Step: 6
Training loss: 2.821254253387451
Validation loss: 2.665586458739414

Epoch: 5| Step: 7
Training loss: 3.3399136066436768
Validation loss: 2.6587374389812513

Epoch: 5| Step: 8
Training loss: 2.009063243865967
Validation loss: 2.6593299373503654

Epoch: 5| Step: 9
Training loss: 3.403979778289795
Validation loss: 2.6488497013686807

Epoch: 5| Step: 10
Training loss: 3.153958320617676
Validation loss: 2.6470597405587473

Epoch: 89| Step: 0
Training loss: 2.8826770782470703
Validation loss: 2.6459210303521927

Epoch: 5| Step: 1
Training loss: 3.047873020172119
Validation loss: 2.6515658491401264

Epoch: 5| Step: 2
Training loss: 1.9440162181854248
Validation loss: 2.665184497833252

Epoch: 5| Step: 3
Training loss: 2.144521713256836
Validation loss: 2.6760324201276227

Epoch: 5| Step: 4
Training loss: 3.4300131797790527
Validation loss: 2.6729867381434285

Epoch: 5| Step: 5
Training loss: 3.061548948287964
Validation loss: 2.6760371833719234

Epoch: 5| Step: 6
Training loss: 2.7142367362976074
Validation loss: 2.6689224653346564

Epoch: 5| Step: 7
Training loss: 2.9517571926116943
Validation loss: 2.6648019526594426

Epoch: 5| Step: 8
Training loss: 3.474860668182373
Validation loss: 2.6669950331411054

Epoch: 5| Step: 9
Training loss: 2.966459274291992
Validation loss: 2.6642324283558834

Epoch: 5| Step: 10
Training loss: 2.2559475898742676
Validation loss: 2.6581487527457615

Epoch: 90| Step: 0
Training loss: 1.9408680200576782
Validation loss: 2.6498077428469093

Epoch: 5| Step: 1
Training loss: 2.556558132171631
Validation loss: 2.642493724822998

Epoch: 5| Step: 2
Training loss: 2.6149909496307373
Validation loss: 2.643308008870771

Epoch: 5| Step: 3
Training loss: 2.5469772815704346
Validation loss: 2.6409504131604264

Epoch: 5| Step: 4
Training loss: 2.824981212615967
Validation loss: 2.6393767710654967

Epoch: 5| Step: 5
Training loss: 3.269491195678711
Validation loss: 2.6448720552588023

Epoch: 5| Step: 6
Training loss: 3.0503854751586914
Validation loss: 2.6455765539600002

Epoch: 5| Step: 7
Training loss: 2.8730320930480957
Validation loss: 2.646906424594182

Epoch: 5| Step: 8
Training loss: 3.552136182785034
Validation loss: 2.6527507920419016

Epoch: 5| Step: 9
Training loss: 2.7283339500427246
Validation loss: 2.6517313398340696

Epoch: 5| Step: 10
Training loss: 2.8904976844787598
Validation loss: 2.651344609516923

Epoch: 91| Step: 0
Training loss: 2.8598408699035645
Validation loss: 2.651014353639336

Epoch: 5| Step: 1
Training loss: 2.465017318725586
Validation loss: 2.645118490342171

Epoch: 5| Step: 2
Training loss: 2.6292338371276855
Validation loss: 2.646924857170351

Epoch: 5| Step: 3
Training loss: 3.257789134979248
Validation loss: 2.645535335745863

Epoch: 5| Step: 4
Training loss: 2.7933008670806885
Validation loss: 2.6431009923258135

Epoch: 5| Step: 5
Training loss: 2.2847957611083984
Validation loss: 2.6444410995770524

Epoch: 5| Step: 6
Training loss: 2.5101466178894043
Validation loss: 2.6434535364950857

Epoch: 5| Step: 7
Training loss: 2.5698745250701904
Validation loss: 2.640533757466142

Epoch: 5| Step: 8
Training loss: 2.7176079750061035
Validation loss: 2.6452703373406523

Epoch: 5| Step: 9
Training loss: 3.1395516395568848
Validation loss: 2.6466198326438986

Epoch: 5| Step: 10
Training loss: 3.756476879119873
Validation loss: 2.6477523952402096

Epoch: 92| Step: 0
Training loss: 2.721011161804199
Validation loss: 2.655436879845076

Epoch: 5| Step: 1
Training loss: 3.1156325340270996
Validation loss: 2.6589244822020173

Epoch: 5| Step: 2
Training loss: 2.8479487895965576
Validation loss: 2.6485298910448627

Epoch: 5| Step: 3
Training loss: 2.777010440826416
Validation loss: 2.6567809043392057

Epoch: 5| Step: 4
Training loss: 2.8291172981262207
Validation loss: 2.6554730656326457

Epoch: 5| Step: 5
Training loss: 3.1860976219177246
Validation loss: 2.659332867591612

Epoch: 5| Step: 6
Training loss: 3.977057695388794
Validation loss: 2.6633897263516664

Epoch: 5| Step: 7
Training loss: 2.3126978874206543
Validation loss: 2.658794451785344

Epoch: 5| Step: 8
Training loss: 2.9673731327056885
Validation loss: 2.6537095808213755

Epoch: 5| Step: 9
Training loss: 1.7387853860855103
Validation loss: 2.6430114930675876

Epoch: 5| Step: 10
Training loss: 2.256239175796509
Validation loss: 2.6482024526083343

Epoch: 93| Step: 0
Training loss: 3.0637621879577637
Validation loss: 2.643135063109859

Epoch: 5| Step: 1
Training loss: 2.6809909343719482
Validation loss: 2.646703932874946

Epoch: 5| Step: 2
Training loss: 3.3001201152801514
Validation loss: 2.647070882140949

Epoch: 5| Step: 3
Training loss: 2.876863479614258
Validation loss: 2.6512822733130506

Epoch: 5| Step: 4
Training loss: 2.9647507667541504
Validation loss: 2.642956041520642

Epoch: 5| Step: 5
Training loss: 2.587519407272339
Validation loss: 2.6460903024160736

Epoch: 5| Step: 6
Training loss: 2.424297571182251
Validation loss: 2.643609557100522

Epoch: 5| Step: 7
Training loss: 2.3295319080352783
Validation loss: 2.6437141280020438

Epoch: 5| Step: 8
Training loss: 2.6792843341827393
Validation loss: 2.639490348036571

Epoch: 5| Step: 9
Training loss: 2.8729329109191895
Validation loss: 2.6433045915378037

Epoch: 5| Step: 10
Training loss: 3.0616743564605713
Validation loss: 2.6413599650065103

Epoch: 94| Step: 0
Training loss: 2.7505295276641846
Validation loss: 2.639891352704776

Epoch: 5| Step: 1
Training loss: 3.431506633758545
Validation loss: 2.6403137842814126

Epoch: 5| Step: 2
Training loss: 3.2427639961242676
Validation loss: 2.641312758127848

Epoch: 5| Step: 3
Training loss: 2.498007297515869
Validation loss: 2.64623914482773

Epoch: 5| Step: 4
Training loss: 3.15661883354187
Validation loss: 2.6476457682988976

Epoch: 5| Step: 5
Training loss: 2.9023921489715576
Validation loss: 2.648169791826638

Epoch: 5| Step: 6
Training loss: 2.526388645172119
Validation loss: 2.6480131277474026

Epoch: 5| Step: 7
Training loss: 2.3851099014282227
Validation loss: 2.6494266986846924

Epoch: 5| Step: 8
Training loss: 2.628391981124878
Validation loss: 2.6488035673736245

Epoch: 5| Step: 9
Training loss: 2.243978500366211
Validation loss: 2.6477643853874615

Epoch: 5| Step: 10
Training loss: 3.0455689430236816
Validation loss: 2.6438110182362218

Epoch: 95| Step: 0
Training loss: 2.259204864501953
Validation loss: 2.647117425036687

Epoch: 5| Step: 1
Training loss: 2.813124179840088
Validation loss: 2.6487030085696968

Epoch: 5| Step: 2
Training loss: 3.2763924598693848
Validation loss: 2.653264340534005

Epoch: 5| Step: 3
Training loss: 3.3672263622283936
Validation loss: 2.653809301314815

Epoch: 5| Step: 4
Training loss: 2.6867690086364746
Validation loss: 2.659290595721173

Epoch: 5| Step: 5
Training loss: 2.160675048828125
Validation loss: 2.654898456347886

Epoch: 5| Step: 6
Training loss: 3.0951528549194336
Validation loss: 2.658030625312559

Epoch: 5| Step: 7
Training loss: 3.226144313812256
Validation loss: 2.6480043729146323

Epoch: 5| Step: 8
Training loss: 2.710434913635254
Validation loss: 2.645125389099121

Epoch: 5| Step: 9
Training loss: 2.4102816581726074
Validation loss: 2.6418463876170497

Epoch: 5| Step: 10
Training loss: 2.725069046020508
Validation loss: 2.644285717318135

Epoch: 96| Step: 0
Training loss: 3.38970685005188
Validation loss: 2.648408559060866

Epoch: 5| Step: 1
Training loss: 2.1285862922668457
Validation loss: 2.6464525166378228

Epoch: 5| Step: 2
Training loss: 3.2206473350524902
Validation loss: 2.643501038192421

Epoch: 5| Step: 3
Training loss: 2.8071227073669434
Validation loss: 2.6427593872111332

Epoch: 5| Step: 4
Training loss: 2.6660704612731934
Validation loss: 2.642492284056961

Epoch: 5| Step: 5
Training loss: 2.1256484985351562
Validation loss: 2.64073452385523

Epoch: 5| Step: 6
Training loss: 2.8305258750915527
Validation loss: 2.6390294439049176

Epoch: 5| Step: 7
Training loss: 2.975736141204834
Validation loss: 2.6390460229689077

Epoch: 5| Step: 8
Training loss: 3.126174211502075
Validation loss: 2.6425161361694336

Epoch: 5| Step: 9
Training loss: 2.804413080215454
Validation loss: 2.6459966398054555

Epoch: 5| Step: 10
Training loss: 2.616244077682495
Validation loss: 2.6405576249604583

Epoch: 97| Step: 0
Training loss: 2.9527766704559326
Validation loss: 2.638312457710184

Epoch: 5| Step: 1
Training loss: 3.0633740425109863
Validation loss: 2.632882818098991

Epoch: 5| Step: 2
Training loss: 2.6194231510162354
Validation loss: 2.636535011312013

Epoch: 5| Step: 3
Training loss: 3.105947971343994
Validation loss: 2.6381343308315484

Epoch: 5| Step: 4
Training loss: 2.879542827606201
Validation loss: 2.6357796089623564

Epoch: 5| Step: 5
Training loss: 2.7380752563476562
Validation loss: 2.635312141910676

Epoch: 5| Step: 6
Training loss: 2.245011568069458
Validation loss: 2.6384987728570097

Epoch: 5| Step: 7
Training loss: 2.7064530849456787
Validation loss: 2.6335246614230576

Epoch: 5| Step: 8
Training loss: 3.027034044265747
Validation loss: 2.6332114127374466

Epoch: 5| Step: 9
Training loss: 2.684527635574341
Validation loss: 2.6326731635678198

Epoch: 5| Step: 10
Training loss: 2.6131110191345215
Validation loss: 2.631984403056483

Epoch: 98| Step: 0
Training loss: 2.331789016723633
Validation loss: 2.632094088421073

Epoch: 5| Step: 1
Training loss: 2.132241725921631
Validation loss: 2.6322185275375203

Epoch: 5| Step: 2
Training loss: 3.4350802898406982
Validation loss: 2.6274906127683577

Epoch: 5| Step: 3
Training loss: 3.0834243297576904
Validation loss: 2.626006885241437

Epoch: 5| Step: 4
Training loss: 3.6251513957977295
Validation loss: 2.6263295553063832

Epoch: 5| Step: 5
Training loss: 2.830066680908203
Validation loss: 2.626704651822326

Epoch: 5| Step: 6
Training loss: 2.693713426589966
Validation loss: 2.6270875776967695

Epoch: 5| Step: 7
Training loss: 2.4936492443084717
Validation loss: 2.6305821531562397

Epoch: 5| Step: 8
Training loss: 3.0076000690460205
Validation loss: 2.6309058499592606

Epoch: 5| Step: 9
Training loss: 2.6138172149658203
Validation loss: 2.6355350735366985

Epoch: 5| Step: 10
Training loss: 2.3471360206604004
Validation loss: 2.6357920221103135

Epoch: 99| Step: 0
Training loss: 2.2071526050567627
Validation loss: 2.629575772952008

Epoch: 5| Step: 1
Training loss: 3.765334367752075
Validation loss: 2.632602624995734

Epoch: 5| Step: 2
Training loss: 2.294898509979248
Validation loss: 2.6312081454902567

Epoch: 5| Step: 3
Training loss: 2.4187748432159424
Validation loss: 2.63132748552548

Epoch: 5| Step: 4
Training loss: 2.9789609909057617
Validation loss: 2.6362107979354037

Epoch: 5| Step: 5
Training loss: 2.6746973991394043
Validation loss: 2.631700174782866

Epoch: 5| Step: 6
Training loss: 2.6406359672546387
Validation loss: 2.633263785351989

Epoch: 5| Step: 7
Training loss: 2.4015889167785645
Validation loss: 2.6450170650277087

Epoch: 5| Step: 8
Training loss: 3.0601840019226074
Validation loss: 2.6408028269326813

Epoch: 5| Step: 9
Training loss: 3.3414406776428223
Validation loss: 2.6374337903914915

Epoch: 5| Step: 10
Training loss: 2.8422176837921143
Validation loss: 2.640259906809817

Epoch: 100| Step: 0
Training loss: 2.9685604572296143
Validation loss: 2.632165419158115

Epoch: 5| Step: 1
Training loss: 2.8458962440490723
Validation loss: 2.6336081489439933

Epoch: 5| Step: 2
Training loss: 3.1652657985687256
Validation loss: 2.6296307143344673

Epoch: 5| Step: 3
Training loss: 3.1647350788116455
Validation loss: 2.630667599298621

Epoch: 5| Step: 4
Training loss: 2.889651298522949
Validation loss: 2.631439838358151

Epoch: 5| Step: 5
Training loss: 2.871276617050171
Validation loss: 2.6304742213218444

Epoch: 5| Step: 6
Training loss: 2.1803689002990723
Validation loss: 2.626363738890617

Epoch: 5| Step: 7
Training loss: 2.6400609016418457
Validation loss: 2.619755647515738

Epoch: 5| Step: 8
Training loss: 2.5630624294281006
Validation loss: 2.6244879691831526

Epoch: 5| Step: 9
Training loss: 2.5263333320617676
Validation loss: 2.626025838236655

Epoch: 5| Step: 10
Training loss: 2.7128543853759766
Validation loss: 2.626548961926532

Epoch: 101| Step: 0
Training loss: 3.2932815551757812
Validation loss: 2.623147959350258

Epoch: 5| Step: 1
Training loss: 2.7762885093688965
Validation loss: 2.62665750903468

Epoch: 5| Step: 2
Training loss: 3.136936664581299
Validation loss: 2.625469110345328

Epoch: 5| Step: 3
Training loss: 1.9063119888305664
Validation loss: 2.6277069443015644

Epoch: 5| Step: 4
Training loss: 2.469395637512207
Validation loss: 2.6306677890080277

Epoch: 5| Step: 5
Training loss: 3.3743889331817627
Validation loss: 2.626188201289023

Epoch: 5| Step: 6
Training loss: 2.872321128845215
Validation loss: 2.6298858350323093

Epoch: 5| Step: 7
Training loss: 2.413036823272705
Validation loss: 2.6251893786973852

Epoch: 5| Step: 8
Training loss: 2.755855083465576
Validation loss: 2.6207092244138

Epoch: 5| Step: 9
Training loss: 2.4869937896728516
Validation loss: 2.6260504312412714

Epoch: 5| Step: 10
Training loss: 3.1381168365478516
Validation loss: 2.624613679865355

Epoch: 102| Step: 0
Training loss: 2.9624011516571045
Validation loss: 2.626089349869759

Epoch: 5| Step: 1
Training loss: 2.75520396232605
Validation loss: 2.6294802824656167

Epoch: 5| Step: 2
Training loss: 2.7436575889587402
Validation loss: 2.6281628019066265

Epoch: 5| Step: 3
Training loss: 3.1164231300354004
Validation loss: 2.625067940322302

Epoch: 5| Step: 4
Training loss: 2.469179153442383
Validation loss: 2.6303247405636694

Epoch: 5| Step: 5
Training loss: 2.825134754180908
Validation loss: 2.6267806022397933

Epoch: 5| Step: 6
Training loss: 2.3048224449157715
Validation loss: 2.6256788058947493

Epoch: 5| Step: 7
Training loss: 2.6198654174804688
Validation loss: 2.6283917093789704

Epoch: 5| Step: 8
Training loss: 2.9318366050720215
Validation loss: 2.630174083094443

Epoch: 5| Step: 9
Training loss: 2.8219916820526123
Validation loss: 2.6262537920346825

Epoch: 5| Step: 10
Training loss: 2.967344284057617
Validation loss: 2.6276227658794773

Epoch: 103| Step: 0
Training loss: 2.4775452613830566
Validation loss: 2.6296382898925454

Epoch: 5| Step: 1
Training loss: 3.640558958053589
Validation loss: 2.626479958975187

Epoch: 5| Step: 2
Training loss: 2.8584628105163574
Validation loss: 2.618363167649956

Epoch: 5| Step: 3
Training loss: 3.7140870094299316
Validation loss: 2.625155248949605

Epoch: 5| Step: 4
Training loss: 2.3868045806884766
Validation loss: 2.6230883905964513

Epoch: 5| Step: 5
Training loss: 2.7816970348358154
Validation loss: 2.623489890047299

Epoch: 5| Step: 6
Training loss: 2.6266868114471436
Validation loss: 2.6272237352145615

Epoch: 5| Step: 7
Training loss: 2.5955307483673096
Validation loss: 2.627082483742827

Epoch: 5| Step: 8
Training loss: 2.538653612136841
Validation loss: 2.6289021789386706

Epoch: 5| Step: 9
Training loss: 2.8393421173095703
Validation loss: 2.6390483199909167

Epoch: 5| Step: 10
Training loss: 1.934075951576233
Validation loss: 2.64521018151314

Epoch: 104| Step: 0
Training loss: 2.77417254447937
Validation loss: 2.6556201340049825

Epoch: 5| Step: 1
Training loss: 2.6408355236053467
Validation loss: 2.6637676326177453

Epoch: 5| Step: 2
Training loss: 3.0169506072998047
Validation loss: 2.6587701817994476

Epoch: 5| Step: 3
Training loss: 2.8187365531921387
Validation loss: 2.659024028367894

Epoch: 5| Step: 4
Training loss: 2.7451586723327637
Validation loss: 2.6547193834858556

Epoch: 5| Step: 5
Training loss: 2.936629056930542
Validation loss: 2.6465332226086686

Epoch: 5| Step: 6
Training loss: 3.0487217903137207
Validation loss: 2.63806301547635

Epoch: 5| Step: 7
Training loss: 2.68841552734375
Validation loss: 2.6402831846667874

Epoch: 5| Step: 8
Training loss: 2.601973056793213
Validation loss: 2.6450555529645694

Epoch: 5| Step: 9
Training loss: 2.375807046890259
Validation loss: 2.649135302471858

Epoch: 5| Step: 10
Training loss: 3.099990129470825
Validation loss: 2.652524591774069

Epoch: 105| Step: 0
Training loss: 2.9849355220794678
Validation loss: 2.6618601660574637

Epoch: 5| Step: 1
Training loss: 1.9929291009902954
Validation loss: 2.6602930151006228

Epoch: 5| Step: 2
Training loss: 3.2234768867492676
Validation loss: 2.6584952133958057

Epoch: 5| Step: 3
Training loss: 2.3134310245513916
Validation loss: 2.661957069109845

Epoch: 5| Step: 4
Training loss: 2.757030725479126
Validation loss: 2.646735683564217

Epoch: 5| Step: 5
Training loss: 2.8115932941436768
Validation loss: 2.6316175127542145

Epoch: 5| Step: 6
Training loss: 2.997136116027832
Validation loss: 2.6261495774792087

Epoch: 5| Step: 7
Training loss: 2.0826570987701416
Validation loss: 2.621336078131071

Epoch: 5| Step: 8
Training loss: 3.1465888023376465
Validation loss: 2.6158966095216813

Epoch: 5| Step: 9
Training loss: 3.18562388420105
Validation loss: 2.6151322113570346

Epoch: 5| Step: 10
Training loss: 3.1006879806518555
Validation loss: 2.610304601730839

Epoch: 106| Step: 0
Training loss: 2.7626614570617676
Validation loss: 2.6171399316480084

Epoch: 5| Step: 1
Training loss: 2.2361228466033936
Validation loss: 2.627311988543439

Epoch: 5| Step: 2
Training loss: 2.458388090133667
Validation loss: 2.6355299462554274

Epoch: 5| Step: 3
Training loss: 3.3912322521209717
Validation loss: 2.636455907616564

Epoch: 5| Step: 4
Training loss: 2.7341980934143066
Validation loss: 2.6373388305787118

Epoch: 5| Step: 5
Training loss: 2.355067014694214
Validation loss: 2.6419762155061126

Epoch: 5| Step: 6
Training loss: 2.7796597480773926
Validation loss: 2.643935811135077

Epoch: 5| Step: 7
Training loss: 3.121460437774658
Validation loss: 2.6345977860112346

Epoch: 5| Step: 8
Training loss: 2.2336783409118652
Validation loss: 2.6302606110931723

Epoch: 5| Step: 9
Training loss: 3.348506212234497
Validation loss: 2.6230475800011748

Epoch: 5| Step: 10
Training loss: 3.2396721839904785
Validation loss: 2.617482272527551

Epoch: 107| Step: 0
Training loss: 2.0702884197235107
Validation loss: 2.6163131549794185

Epoch: 5| Step: 1
Training loss: 2.9827349185943604
Validation loss: 2.615293425898398

Epoch: 5| Step: 2
Training loss: 3.0401828289031982
Validation loss: 2.6202333460571947

Epoch: 5| Step: 3
Training loss: 3.403463840484619
Validation loss: 2.6199729647687686

Epoch: 5| Step: 4
Training loss: 2.9930293560028076
Validation loss: 2.6215191579634145

Epoch: 5| Step: 5
Training loss: 2.2703094482421875
Validation loss: 2.629072627713603

Epoch: 5| Step: 6
Training loss: 2.9543254375457764
Validation loss: 2.626830106140465

Epoch: 5| Step: 7
Training loss: 3.4807987213134766
Validation loss: 2.6352266265499975

Epoch: 5| Step: 8
Training loss: 1.8845672607421875
Validation loss: 2.627738360435732

Epoch: 5| Step: 9
Training loss: 3.0858027935028076
Validation loss: 2.6286050786254225

Epoch: 5| Step: 10
Training loss: 2.136288642883301
Validation loss: 2.6336588013556694

Epoch: 108| Step: 0
Training loss: 3.0539615154266357
Validation loss: 2.6286708436986452

Epoch: 5| Step: 1
Training loss: 2.8941152095794678
Validation loss: 2.6297005427780973

Epoch: 5| Step: 2
Training loss: 2.253894329071045
Validation loss: 2.6234760797151955

Epoch: 5| Step: 3
Training loss: 3.063215970993042
Validation loss: 2.6216915166506203

Epoch: 5| Step: 4
Training loss: 2.561466932296753
Validation loss: 2.6199132883420555

Epoch: 5| Step: 5
Training loss: 2.5028743743896484
Validation loss: 2.617616347087327

Epoch: 5| Step: 6
Training loss: 2.865243434906006
Validation loss: 2.6138741995698664

Epoch: 5| Step: 7
Training loss: 3.2196877002716064
Validation loss: 2.613630794709729

Epoch: 5| Step: 8
Training loss: 2.7816505432128906
Validation loss: 2.611507728535642

Epoch: 5| Step: 9
Training loss: 2.7519049644470215
Validation loss: 2.6074507723572435

Epoch: 5| Step: 10
Training loss: 2.3964991569519043
Validation loss: 2.607224597725817

Epoch: 109| Step: 0
Training loss: 2.521423578262329
Validation loss: 2.6079276582246185

Epoch: 5| Step: 1
Training loss: 3.444432020187378
Validation loss: 2.607404144861365

Epoch: 5| Step: 2
Training loss: 3.0122878551483154
Validation loss: 2.606824367277084

Epoch: 5| Step: 3
Training loss: 2.410648822784424
Validation loss: 2.6050963632522093

Epoch: 5| Step: 4
Training loss: 3.4973857402801514
Validation loss: 2.603173445629817

Epoch: 5| Step: 5
Training loss: 2.099172830581665
Validation loss: 2.5992795780140865

Epoch: 5| Step: 6
Training loss: 1.966508150100708
Validation loss: 2.601555391024518

Epoch: 5| Step: 7
Training loss: 3.1051299571990967
Validation loss: 2.600521690102034

Epoch: 5| Step: 8
Training loss: 3.0272598266601562
Validation loss: 2.6016297750575568

Epoch: 5| Step: 9
Training loss: 2.545762777328491
Validation loss: 2.6017927328745523

Epoch: 5| Step: 10
Training loss: 2.7759854793548584
Validation loss: 2.600078393054265

Epoch: 110| Step: 0
Training loss: 3.0152711868286133
Validation loss: 2.6049573318932646

Epoch: 5| Step: 1
Training loss: 3.0700974464416504
Validation loss: 2.6023806346360074

Epoch: 5| Step: 2
Training loss: 3.2551207542419434
Validation loss: 2.6052080764565417

Epoch: 5| Step: 3
Training loss: 2.962050199508667
Validation loss: 2.6005413865530365

Epoch: 5| Step: 4
Training loss: 2.3591318130493164
Validation loss: 2.6022162437438965

Epoch: 5| Step: 5
Training loss: 2.386589527130127
Validation loss: 2.599257746050435

Epoch: 5| Step: 6
Training loss: 3.45080828666687
Validation loss: 2.5990895660974647

Epoch: 5| Step: 7
Training loss: 2.856492519378662
Validation loss: 2.6003328472055416

Epoch: 5| Step: 8
Training loss: 2.5020203590393066
Validation loss: 2.6048200361190306

Epoch: 5| Step: 9
Training loss: 2.4620752334594727
Validation loss: 2.603700319925944

Epoch: 5| Step: 10
Training loss: 1.8871421813964844
Validation loss: 2.601818302626251

Epoch: 111| Step: 0
Training loss: 2.6713831424713135
Validation loss: 2.6053364430704424

Epoch: 5| Step: 1
Training loss: 2.5778207778930664
Validation loss: 2.616261064365346

Epoch: 5| Step: 2
Training loss: 2.6921091079711914
Validation loss: 2.6274459900394564

Epoch: 5| Step: 3
Training loss: 3.2526562213897705
Validation loss: 2.621138552183746

Epoch: 5| Step: 4
Training loss: 2.3581671714782715
Validation loss: 2.628490763325845

Epoch: 5| Step: 5
Training loss: 3.311457395553589
Validation loss: 2.6106010508793656

Epoch: 5| Step: 6
Training loss: 1.6378711462020874
Validation loss: 2.6145276484950895

Epoch: 5| Step: 7
Training loss: 2.781799793243408
Validation loss: 2.6164500841530423

Epoch: 5| Step: 8
Training loss: 2.6215662956237793
Validation loss: 2.6201900077122513

Epoch: 5| Step: 9
Training loss: 3.1942520141601562
Validation loss: 2.6174032841959307

Epoch: 5| Step: 10
Training loss: 3.310338020324707
Validation loss: 2.6162067203111548

Epoch: 112| Step: 0
Training loss: 2.686051845550537
Validation loss: 2.616579653114401

Epoch: 5| Step: 1
Training loss: 2.9213528633117676
Validation loss: 2.601584513982137

Epoch: 5| Step: 2
Training loss: 2.403327703475952
Validation loss: 2.6006442475062546

Epoch: 5| Step: 3
Training loss: 2.2459206581115723
Validation loss: 2.5995039837334746

Epoch: 5| Step: 4
Training loss: 2.48209285736084
Validation loss: 2.596803467760804

Epoch: 5| Step: 5
Training loss: 3.766050338745117
Validation loss: 2.6040178857823855

Epoch: 5| Step: 6
Training loss: 2.3745553493499756
Validation loss: 2.606744876471899

Epoch: 5| Step: 7
Training loss: 2.6228058338165283
Validation loss: 2.615705454221336

Epoch: 5| Step: 8
Training loss: 2.408419609069824
Validation loss: 2.6071456170851186

Epoch: 5| Step: 9
Training loss: 3.373624324798584
Validation loss: 2.613274176915487

Epoch: 5| Step: 10
Training loss: 3.204564094543457
Validation loss: 2.6068141537327922

Epoch: 113| Step: 0
Training loss: 2.4634222984313965
Validation loss: 2.598147689655263

Epoch: 5| Step: 1
Training loss: 2.359018325805664
Validation loss: 2.5966072825975317

Epoch: 5| Step: 2
Training loss: 3.176403522491455
Validation loss: 2.5940819222440004

Epoch: 5| Step: 3
Training loss: 2.5410690307617188
Validation loss: 2.5885525262483986

Epoch: 5| Step: 4
Training loss: 2.8637518882751465
Validation loss: 2.587336127476026

Epoch: 5| Step: 5
Training loss: 3.1455321311950684
Validation loss: 2.592893277445147

Epoch: 5| Step: 6
Training loss: 2.6266720294952393
Validation loss: 2.5891542716692855

Epoch: 5| Step: 7
Training loss: 3.6125450134277344
Validation loss: 2.5880364218065814

Epoch: 5| Step: 8
Training loss: 2.4532458782196045
Validation loss: 2.5929719555762505

Epoch: 5| Step: 9
Training loss: 2.6610169410705566
Validation loss: 2.587301900309901

Epoch: 5| Step: 10
Training loss: 2.421950578689575
Validation loss: 2.586327291304065

Epoch: 114| Step: 0
Training loss: 2.657681465148926
Validation loss: 2.5874662066018708

Epoch: 5| Step: 1
Training loss: 2.914299249649048
Validation loss: 2.5887797750452513

Epoch: 5| Step: 2
Training loss: 3.846224308013916
Validation loss: 2.589141725212015

Epoch: 5| Step: 3
Training loss: 3.161264657974243
Validation loss: 2.5937082870032198

Epoch: 5| Step: 4
Training loss: 2.9951400756835938
Validation loss: 2.5913481404704433

Epoch: 5| Step: 5
Training loss: 2.320247173309326
Validation loss: 2.5899517843800206

Epoch: 5| Step: 6
Training loss: 2.4500892162323
Validation loss: 2.5955953239112772

Epoch: 5| Step: 7
Training loss: 2.2890098094940186
Validation loss: 2.592580492778491

Epoch: 5| Step: 8
Training loss: 2.5660743713378906
Validation loss: 2.59672519212128

Epoch: 5| Step: 9
Training loss: 2.8427982330322266
Validation loss: 2.599214856342603

Epoch: 5| Step: 10
Training loss: 2.145195245742798
Validation loss: 2.6054117987232823

Epoch: 115| Step: 0
Training loss: 2.9483132362365723
Validation loss: 2.603900319786482

Epoch: 5| Step: 1
Training loss: 2.40802264213562
Validation loss: 2.6052860854774393

Epoch: 5| Step: 2
Training loss: 3.061357021331787
Validation loss: 2.609135350873393

Epoch: 5| Step: 3
Training loss: 2.733592987060547
Validation loss: 2.60303771111273

Epoch: 5| Step: 4
Training loss: 2.7503387928009033
Validation loss: 2.6021747332747265

Epoch: 5| Step: 5
Training loss: 3.0304927825927734
Validation loss: 2.595143661704115

Epoch: 5| Step: 6
Training loss: 2.1594090461730957
Validation loss: 2.598848025004069

Epoch: 5| Step: 7
Training loss: 2.818352460861206
Validation loss: 2.5914647527920303

Epoch: 5| Step: 8
Training loss: 2.7479212284088135
Validation loss: 2.5844212732007428

Epoch: 5| Step: 9
Training loss: 2.910527229309082
Validation loss: 2.5832325745654363

Epoch: 5| Step: 10
Training loss: 2.692228317260742
Validation loss: 2.584285469465358

Epoch: 116| Step: 0
Training loss: 2.541687488555908
Validation loss: 2.580806293795186

Epoch: 5| Step: 1
Training loss: 2.5504002571105957
Validation loss: 2.581161152931952

Epoch: 5| Step: 2
Training loss: 2.6788787841796875
Validation loss: 2.5845063706879974

Epoch: 5| Step: 3
Training loss: 3.1202268600463867
Validation loss: 2.579812757430538

Epoch: 5| Step: 4
Training loss: 2.579895257949829
Validation loss: 2.5834772535549697

Epoch: 5| Step: 5
Training loss: 2.6476616859436035
Validation loss: 2.5811859407732562

Epoch: 5| Step: 6
Training loss: 2.8032689094543457
Validation loss: 2.5798571904500327

Epoch: 5| Step: 7
Training loss: 3.2039153575897217
Validation loss: 2.5810388749645603

Epoch: 5| Step: 8
Training loss: 2.9272537231445312
Validation loss: 2.58383531724253

Epoch: 5| Step: 9
Training loss: 2.3236396312713623
Validation loss: 2.583914215846728

Epoch: 5| Step: 10
Training loss: 2.9690725803375244
Validation loss: 2.5810537927894184

Epoch: 117| Step: 0
Training loss: 2.878739595413208
Validation loss: 2.5836387962423344

Epoch: 5| Step: 1
Training loss: 2.1972804069519043
Validation loss: 2.581279521347374

Epoch: 5| Step: 2
Training loss: 3.2375073432922363
Validation loss: 2.5832227045489895

Epoch: 5| Step: 3
Training loss: 2.912367343902588
Validation loss: 2.5850245157877603

Epoch: 5| Step: 4
Training loss: 3.3796608448028564
Validation loss: 2.5865646075176936

Epoch: 5| Step: 5
Training loss: 2.696746349334717
Validation loss: 2.5884464709989485

Epoch: 5| Step: 6
Training loss: 2.4763143062591553
Validation loss: 2.584433622257684

Epoch: 5| Step: 7
Training loss: 2.2652456760406494
Validation loss: 2.587140831896054

Epoch: 5| Step: 8
Training loss: 2.654428005218506
Validation loss: 2.5889451273026003

Epoch: 5| Step: 9
Training loss: 2.505709171295166
Validation loss: 2.580107558158136

Epoch: 5| Step: 10
Training loss: 3.062676429748535
Validation loss: 2.5822712580362954

Epoch: 118| Step: 0
Training loss: 3.516613721847534
Validation loss: 2.5788829018992763

Epoch: 5| Step: 1
Training loss: 2.875028610229492
Validation loss: 2.583895657652168

Epoch: 5| Step: 2
Training loss: 2.739745616912842
Validation loss: 2.579386826484434

Epoch: 5| Step: 3
Training loss: 2.6896350383758545
Validation loss: 2.5801575927324194

Epoch: 5| Step: 4
Training loss: 2.7070584297180176
Validation loss: 2.5862052773916595

Epoch: 5| Step: 5
Training loss: 2.5691609382629395
Validation loss: 2.5803097653132614

Epoch: 5| Step: 6
Training loss: 2.8779520988464355
Validation loss: 2.5815721352895102

Epoch: 5| Step: 7
Training loss: 3.3738434314727783
Validation loss: 2.579881542472429

Epoch: 5| Step: 8
Training loss: 1.9599931240081787
Validation loss: 2.5843622787024385

Epoch: 5| Step: 9
Training loss: 2.071270227432251
Validation loss: 2.5838823818391368

Epoch: 5| Step: 10
Training loss: 2.7784624099731445
Validation loss: 2.588072253811744

Epoch: 119| Step: 0
Training loss: 2.6690664291381836
Validation loss: 2.5836349469359203

Epoch: 5| Step: 1
Training loss: 2.999268054962158
Validation loss: 2.587968546857116

Epoch: 5| Step: 2
Training loss: 2.455631971359253
Validation loss: 2.5851177682158766

Epoch: 5| Step: 3
Training loss: 4.0293869972229
Validation loss: 2.5905599132660897

Epoch: 5| Step: 4
Training loss: 2.553524971008301
Validation loss: 2.5809206501130135

Epoch: 5| Step: 5
Training loss: 2.6065945625305176
Validation loss: 2.578722256486134

Epoch: 5| Step: 6
Training loss: 2.989522933959961
Validation loss: 2.593427699099305

Epoch: 5| Step: 7
Training loss: 2.4562389850616455
Validation loss: 2.588460373622115

Epoch: 5| Step: 8
Training loss: 1.7881500720977783
Validation loss: 2.5781927006219023

Epoch: 5| Step: 9
Training loss: 3.103087902069092
Validation loss: 2.5808602045941096

Epoch: 5| Step: 10
Training loss: 2.4639265537261963
Validation loss: 2.5902175390592186

Epoch: 120| Step: 0
Training loss: 2.8218636512756348
Validation loss: 2.5887479192467144

Epoch: 5| Step: 1
Training loss: 2.9591164588928223
Validation loss: 2.594508501791185

Epoch: 5| Step: 2
Training loss: 2.2187604904174805
Validation loss: 2.5926595093101583

Epoch: 5| Step: 3
Training loss: 1.8858556747436523
Validation loss: 2.5954628580360004

Epoch: 5| Step: 4
Training loss: 3.494691848754883
Validation loss: 2.5952007667992705

Epoch: 5| Step: 5
Training loss: 2.5120463371276855
Validation loss: 2.5937281988000356

Epoch: 5| Step: 6
Training loss: 2.4975929260253906
Validation loss: 2.5901201642969602

Epoch: 5| Step: 7
Training loss: 2.736764430999756
Validation loss: 2.594211483514437

Epoch: 5| Step: 8
Training loss: 2.607775926589966
Validation loss: 2.588545940255606

Epoch: 5| Step: 9
Training loss: 3.218355894088745
Validation loss: 2.5873753460504676

Epoch: 5| Step: 10
Training loss: 3.23435378074646
Validation loss: 2.5890766087398736

Epoch: 121| Step: 0
Training loss: 3.039963722229004
Validation loss: 2.5882477401405253

Epoch: 5| Step: 1
Training loss: 2.8811793327331543
Validation loss: 2.5913712029816

Epoch: 5| Step: 2
Training loss: 2.8766555786132812
Validation loss: 2.5825228691101074

Epoch: 5| Step: 3
Training loss: 2.2529711723327637
Validation loss: 2.582922826531113

Epoch: 5| Step: 4
Training loss: 2.6907262802124023
Validation loss: 2.588526113058931

Epoch: 5| Step: 5
Training loss: 2.414353847503662
Validation loss: 2.582782788943219

Epoch: 5| Step: 6
Training loss: 2.478147506713867
Validation loss: 2.585010936183314

Epoch: 5| Step: 7
Training loss: 2.1316256523132324
Validation loss: 2.586220941235942

Epoch: 5| Step: 8
Training loss: 3.392521619796753
Validation loss: 2.5788227640172487

Epoch: 5| Step: 9
Training loss: 2.941760540008545
Validation loss: 2.5799013747963855

Epoch: 5| Step: 10
Training loss: 3.066312789916992
Validation loss: 2.5769330301592426

Epoch: 122| Step: 0
Training loss: 2.2699968814849854
Validation loss: 2.580319780175404

Epoch: 5| Step: 1
Training loss: 3.0708975791931152
Validation loss: 2.577743004727107

Epoch: 5| Step: 2
Training loss: 3.191312074661255
Validation loss: 2.577673445465744

Epoch: 5| Step: 3
Training loss: 2.6393654346466064
Validation loss: 2.5776416358127388

Epoch: 5| Step: 4
Training loss: 2.3027138710021973
Validation loss: 2.5766429465304137

Epoch: 5| Step: 5
Training loss: 2.7437472343444824
Validation loss: 2.573491665624803

Epoch: 5| Step: 6
Training loss: 2.9279696941375732
Validation loss: 2.5713307972877257

Epoch: 5| Step: 7
Training loss: 3.065687656402588
Validation loss: 2.5718775231351136

Epoch: 5| Step: 8
Training loss: 2.980807065963745
Validation loss: 2.567448280190909

Epoch: 5| Step: 9
Training loss: 1.8222240209579468
Validation loss: 2.572230815887451

Epoch: 5| Step: 10
Training loss: 3.134249687194824
Validation loss: 2.571783406760103

Epoch: 123| Step: 0
Training loss: 2.387770175933838
Validation loss: 2.569451009073565

Epoch: 5| Step: 1
Training loss: 2.5127997398376465
Validation loss: 2.5684045027661067

Epoch: 5| Step: 2
Training loss: 3.1067872047424316
Validation loss: 2.571876351551343

Epoch: 5| Step: 3
Training loss: 1.9223051071166992
Validation loss: 2.5715350848372265

Epoch: 5| Step: 4
Training loss: 2.6368515491485596
Validation loss: 2.5720042003098356

Epoch: 5| Step: 5
Training loss: 2.6009092330932617
Validation loss: 2.57095734278361

Epoch: 5| Step: 6
Training loss: 3.0431580543518066
Validation loss: 2.5759759769644788

Epoch: 5| Step: 7
Training loss: 2.924813747406006
Validation loss: 2.5731433668444232

Epoch: 5| Step: 8
Training loss: 2.3390183448791504
Validation loss: 2.5719181978574364

Epoch: 5| Step: 9
Training loss: 3.490435838699341
Validation loss: 2.567859165130123

Epoch: 5| Step: 10
Training loss: 3.167975425720215
Validation loss: 2.569911774768624

Epoch: 124| Step: 0
Training loss: 2.7675940990448
Validation loss: 2.5708128662519556

Epoch: 5| Step: 1
Training loss: 2.372309446334839
Validation loss: 2.573503243025913

Epoch: 5| Step: 2
Training loss: 2.3788094520568848
Validation loss: 2.5729354966071343

Epoch: 5| Step: 3
Training loss: 3.051804304122925
Validation loss: 2.572962591725011

Epoch: 5| Step: 4
Training loss: 2.1242318153381348
Validation loss: 2.5726296773520847

Epoch: 5| Step: 5
Training loss: 2.93928861618042
Validation loss: 2.575142455357377

Epoch: 5| Step: 6
Training loss: 2.9383554458618164
Validation loss: 2.573223513941611

Epoch: 5| Step: 7
Training loss: 2.8221821784973145
Validation loss: 2.5751429603945826

Epoch: 5| Step: 8
Training loss: 2.738825798034668
Validation loss: 2.5943929097985707

Epoch: 5| Step: 9
Training loss: 3.526468276977539
Validation loss: 2.6006625839459

Epoch: 5| Step: 10
Training loss: 2.3598833084106445
Validation loss: 2.601081766108031

Epoch: 125| Step: 0
Training loss: 2.3202598094940186
Validation loss: 2.581588929699313

Epoch: 5| Step: 1
Training loss: 3.256648540496826
Validation loss: 2.5847595712190032

Epoch: 5| Step: 2
Training loss: 2.0673179626464844
Validation loss: 2.575813331911641

Epoch: 5| Step: 3
Training loss: 2.0153841972351074
Validation loss: 2.574482007693219

Epoch: 5| Step: 4
Training loss: 2.8270466327667236
Validation loss: 2.5734807547702583

Epoch: 5| Step: 5
Training loss: 2.6941347122192383
Validation loss: 2.5752976222704818

Epoch: 5| Step: 6
Training loss: 3.3647239208221436
Validation loss: 2.5783792157326975

Epoch: 5| Step: 7
Training loss: 3.0034308433532715
Validation loss: 2.5741559305498676

Epoch: 5| Step: 8
Training loss: 3.111515522003174
Validation loss: 2.574745601223361

Epoch: 5| Step: 9
Training loss: 2.8923850059509277
Validation loss: 2.578025607652562

Epoch: 5| Step: 10
Training loss: 2.397214412689209
Validation loss: 2.57447293496901

Epoch: 126| Step: 0
Training loss: 2.758427858352661
Validation loss: 2.567946862148982

Epoch: 5| Step: 1
Training loss: 3.035893201828003
Validation loss: 2.569231289689259

Epoch: 5| Step: 2
Training loss: 2.9274630546569824
Validation loss: 2.562037529483918

Epoch: 5| Step: 3
Training loss: 1.7844417095184326
Validation loss: 2.564596394056915

Epoch: 5| Step: 4
Training loss: 3.8418495655059814
Validation loss: 2.5686314490533646

Epoch: 5| Step: 5
Training loss: 2.498197078704834
Validation loss: 2.56664026424449

Epoch: 5| Step: 6
Training loss: 2.7372069358825684
Validation loss: 2.56923085130671

Epoch: 5| Step: 7
Training loss: 2.5287747383117676
Validation loss: 2.5699228496961695

Epoch: 5| Step: 8
Training loss: 2.414124011993408
Validation loss: 2.5723304312716246

Epoch: 5| Step: 9
Training loss: 2.7407422065734863
Validation loss: 2.573677491116267

Epoch: 5| Step: 10
Training loss: 2.7573089599609375
Validation loss: 2.5769473224557857

Epoch: 127| Step: 0
Training loss: 2.3334665298461914
Validation loss: 2.578273298919842

Epoch: 5| Step: 1
Training loss: 3.478156328201294
Validation loss: 2.5768911838531494

Epoch: 5| Step: 2
Training loss: 2.614266872406006
Validation loss: 2.5734609685918337

Epoch: 5| Step: 3
Training loss: 2.155925750732422
Validation loss: 2.5735296997972714

Epoch: 5| Step: 4
Training loss: 2.8038601875305176
Validation loss: 2.5741880837307183

Epoch: 5| Step: 5
Training loss: 2.9097700119018555
Validation loss: 2.573400592291227

Epoch: 5| Step: 6
Training loss: 2.5070979595184326
Validation loss: 2.573022296351771

Epoch: 5| Step: 7
Training loss: 3.294658660888672
Validation loss: 2.5745401972083637

Epoch: 5| Step: 8
Training loss: 2.2244560718536377
Validation loss: 2.5764510118833153

Epoch: 5| Step: 9
Training loss: 2.967939853668213
Validation loss: 2.569621455284857

Epoch: 5| Step: 10
Training loss: 2.7216930389404297
Validation loss: 2.5639170267248668

Epoch: 128| Step: 0
Training loss: 2.5626275539398193
Validation loss: 2.5661418412321355

Epoch: 5| Step: 1
Training loss: 2.8000285625457764
Validation loss: 2.5656627326883297

Epoch: 5| Step: 2
Training loss: 2.9815468788146973
Validation loss: 2.5686849906880367

Epoch: 5| Step: 3
Training loss: 3.499854564666748
Validation loss: 2.573542933310232

Epoch: 5| Step: 4
Training loss: 2.747087001800537
Validation loss: 2.5759272498469197

Epoch: 5| Step: 5
Training loss: 2.617920398712158
Validation loss: 2.5746433452893327

Epoch: 5| Step: 6
Training loss: 2.880061626434326
Validation loss: 2.5736125284625637

Epoch: 5| Step: 7
Training loss: 2.4222159385681152
Validation loss: 2.5706073109821608

Epoch: 5| Step: 8
Training loss: 2.3715615272521973
Validation loss: 2.5686862801992767

Epoch: 5| Step: 9
Training loss: 2.8857011795043945
Validation loss: 2.567395443557411

Epoch: 5| Step: 10
Training loss: 2.1143627166748047
Validation loss: 2.5749495926723687

Epoch: 129| Step: 0
Training loss: 2.839719295501709
Validation loss: 2.5735465095889185

Epoch: 5| Step: 1
Training loss: 3.062615156173706
Validation loss: 2.573078091426562

Epoch: 5| Step: 2
Training loss: 2.9516966342926025
Validation loss: 2.5717331927309752

Epoch: 5| Step: 3
Training loss: 2.297069549560547
Validation loss: 2.5658864154610583

Epoch: 5| Step: 4
Training loss: 2.8479580879211426
Validation loss: 2.5688293621104252

Epoch: 5| Step: 5
Training loss: 2.6920034885406494
Validation loss: 2.563173287658281

Epoch: 5| Step: 6
Training loss: 2.7292182445526123
Validation loss: 2.564356050183696

Epoch: 5| Step: 7
Training loss: 2.6396944522857666
Validation loss: 2.5629032247809955

Epoch: 5| Step: 8
Training loss: 2.68172025680542
Validation loss: 2.560154266254876

Epoch: 5| Step: 9
Training loss: 2.373718738555908
Validation loss: 2.5650653352019606

Epoch: 5| Step: 10
Training loss: 2.8016464710235596
Validation loss: 2.566762572975569

Epoch: 130| Step: 0
Training loss: 2.133296489715576
Validation loss: 2.556716752308671

Epoch: 5| Step: 1
Training loss: 2.622044086456299
Validation loss: 2.5565430477101314

Epoch: 5| Step: 2
Training loss: 2.215059995651245
Validation loss: 2.5590178633248932

Epoch: 5| Step: 3
Training loss: 3.2159457206726074
Validation loss: 2.5638729064695296

Epoch: 5| Step: 4
Training loss: 3.132416009902954
Validation loss: 2.5635750396277315

Epoch: 5| Step: 5
Training loss: 2.2168285846710205
Validation loss: 2.563510646102249

Epoch: 5| Step: 6
Training loss: 2.930940866470337
Validation loss: 2.563305244650892

Epoch: 5| Step: 7
Training loss: 2.62675404548645
Validation loss: 2.5670320962065007

Epoch: 5| Step: 8
Training loss: 2.511143207550049
Validation loss: 2.5737997921564246

Epoch: 5| Step: 9
Training loss: 3.149841070175171
Validation loss: 2.569920434746691

Epoch: 5| Step: 10
Training loss: 3.2960617542266846
Validation loss: 2.5698092137613604

Epoch: 131| Step: 0
Training loss: 2.6842315196990967
Validation loss: 2.565422640051893

Epoch: 5| Step: 1
Training loss: 2.448903799057007
Validation loss: 2.557328124200144

Epoch: 5| Step: 2
Training loss: 3.1733882427215576
Validation loss: 2.5654145056201565

Epoch: 5| Step: 3
Training loss: 3.0626161098480225
Validation loss: 2.566155751546224

Epoch: 5| Step: 4
Training loss: 2.231722354888916
Validation loss: 2.5518450429362636

Epoch: 5| Step: 5
Training loss: 2.307025194168091
Validation loss: 2.5568865422279603

Epoch: 5| Step: 6
Training loss: 2.86885142326355
Validation loss: 2.550351758157053

Epoch: 5| Step: 7
Training loss: 2.867311477661133
Validation loss: 2.5581032563281316

Epoch: 5| Step: 8
Training loss: 3.005385637283325
Validation loss: 2.559987724468272

Epoch: 5| Step: 9
Training loss: 2.790226459503174
Validation loss: 2.5566635311290784

Epoch: 5| Step: 10
Training loss: 2.364971160888672
Validation loss: 2.555587096880841

Epoch: 132| Step: 0
Training loss: 2.8126156330108643
Validation loss: 2.5566643796941286

Epoch: 5| Step: 1
Training loss: 2.4110701084136963
Validation loss: 2.5557717661703787

Epoch: 5| Step: 2
Training loss: 2.1270694732666016
Validation loss: 2.5583483173001196

Epoch: 5| Step: 3
Training loss: 2.4592807292938232
Validation loss: 2.558388735658379

Epoch: 5| Step: 4
Training loss: 2.819309949874878
Validation loss: 2.5525939567114717

Epoch: 5| Step: 5
Training loss: 2.85371732711792
Validation loss: 2.5564219208173853

Epoch: 5| Step: 6
Training loss: 2.973853588104248
Validation loss: 2.552602803835305

Epoch: 5| Step: 7
Training loss: 3.0256593227386475
Validation loss: 2.55503152519144

Epoch: 5| Step: 8
Training loss: 1.9232228994369507
Validation loss: 2.5584580539375223

Epoch: 5| Step: 9
Training loss: 3.3665378093719482
Validation loss: 2.556039020579348

Epoch: 5| Step: 10
Training loss: 3.1766459941864014
Validation loss: 2.550450565994427

Epoch: 133| Step: 0
Training loss: 2.4857726097106934
Validation loss: 2.5566877088239117

Epoch: 5| Step: 1
Training loss: 2.429030418395996
Validation loss: 2.5555277896183792

Epoch: 5| Step: 2
Training loss: 2.5998237133026123
Validation loss: 2.556472829593125

Epoch: 5| Step: 3
Training loss: 2.60728120803833
Validation loss: 2.561278473946356

Epoch: 5| Step: 4
Training loss: 2.604036808013916
Validation loss: 2.5662910476807625

Epoch: 5| Step: 5
Training loss: 2.720606803894043
Validation loss: 2.5606133707108034

Epoch: 5| Step: 6
Training loss: 2.7114546298980713
Validation loss: 2.5712102997687554

Epoch: 5| Step: 7
Training loss: 2.5971920490264893
Validation loss: 2.579087670131396

Epoch: 5| Step: 8
Training loss: 3.0238723754882812
Validation loss: 2.5724976601139193

Epoch: 5| Step: 9
Training loss: 2.9226274490356445
Validation loss: 2.5618622174827

Epoch: 5| Step: 10
Training loss: 3.300405740737915
Validation loss: 2.5605203849013134

Epoch: 134| Step: 0
Training loss: 2.958299160003662
Validation loss: 2.557701938895769

Epoch: 5| Step: 1
Training loss: 2.3705573081970215
Validation loss: 2.552859144826089

Epoch: 5| Step: 2
Training loss: 1.8853271007537842
Validation loss: 2.5560839483814854

Epoch: 5| Step: 3
Training loss: 2.5329031944274902
Validation loss: 2.5501368866171887

Epoch: 5| Step: 4
Training loss: 2.6507534980773926
Validation loss: 2.5470748075874905

Epoch: 5| Step: 5
Training loss: 2.613569736480713
Validation loss: 2.549676287558771

Epoch: 5| Step: 6
Training loss: 2.582310676574707
Validation loss: 2.546783290883546

Epoch: 5| Step: 7
Training loss: 2.5884952545166016
Validation loss: 2.5498797021886355

Epoch: 5| Step: 8
Training loss: 3.641374111175537
Validation loss: 2.5481211652037916

Epoch: 5| Step: 9
Training loss: 2.8305678367614746
Validation loss: 2.550782965075585

Epoch: 5| Step: 10
Training loss: 3.245753049850464
Validation loss: 2.5468360736805904

Epoch: 135| Step: 0
Training loss: 3.4272620677948
Validation loss: 2.547515592267436

Epoch: 5| Step: 1
Training loss: 2.6330723762512207
Validation loss: 2.5466379786050446

Epoch: 5| Step: 2
Training loss: 2.5550589561462402
Validation loss: 2.545135321155671

Epoch: 5| Step: 3
Training loss: 2.5478439331054688
Validation loss: 2.542545759549705

Epoch: 5| Step: 4
Training loss: 2.338364362716675
Validation loss: 2.539659751358853

Epoch: 5| Step: 5
Training loss: 2.776536226272583
Validation loss: 2.5419274171193442

Epoch: 5| Step: 6
Training loss: 2.7252166271209717
Validation loss: 2.541706677406065

Epoch: 5| Step: 7
Training loss: 2.800903797149658
Validation loss: 2.5429590081655853

Epoch: 5| Step: 8
Training loss: 2.795215129852295
Validation loss: 2.544352633978731

Epoch: 5| Step: 9
Training loss: 2.7161083221435547
Validation loss: 2.5472807807307087

Epoch: 5| Step: 10
Training loss: 2.445784330368042
Validation loss: 2.546558395508797

Epoch: 136| Step: 0
Training loss: 3.1636645793914795
Validation loss: 2.544442558801302

Epoch: 5| Step: 1
Training loss: 3.5530846118927
Validation loss: 2.546681031104057

Epoch: 5| Step: 2
Training loss: 2.487987995147705
Validation loss: 2.5458230357016287

Epoch: 5| Step: 3
Training loss: 2.6143276691436768
Validation loss: 2.5377907727354314

Epoch: 5| Step: 4
Training loss: 2.571920394897461
Validation loss: 2.5471496838395313

Epoch: 5| Step: 5
Training loss: 2.8811256885528564
Validation loss: 2.5478413694648334

Epoch: 5| Step: 6
Training loss: 2.169381856918335
Validation loss: 2.543807909052859

Epoch: 5| Step: 7
Training loss: 2.508448600769043
Validation loss: 2.545542937453075

Epoch: 5| Step: 8
Training loss: 2.9965708255767822
Validation loss: 2.540314333413237

Epoch: 5| Step: 9
Training loss: 2.50325345993042
Validation loss: 2.5411621421896

Epoch: 5| Step: 10
Training loss: 2.2033002376556396
Validation loss: 2.5437348235038018

Epoch: 137| Step: 0
Training loss: 3.1418888568878174
Validation loss: 2.5405114312325754

Epoch: 5| Step: 1
Training loss: 2.4337167739868164
Validation loss: 2.541687609047018

Epoch: 5| Step: 2
Training loss: 3.074000597000122
Validation loss: 2.5421281963266353

Epoch: 5| Step: 3
Training loss: 2.6212472915649414
Validation loss: 2.5429428777387066

Epoch: 5| Step: 4
Training loss: 3.271885395050049
Validation loss: 2.5428788815775225

Epoch: 5| Step: 5
Training loss: 2.214456081390381
Validation loss: 2.5398445475486016

Epoch: 5| Step: 6
Training loss: 3.0809218883514404
Validation loss: 2.5379940412377797

Epoch: 5| Step: 7
Training loss: 2.534578800201416
Validation loss: 2.5411476345472437

Epoch: 5| Step: 8
Training loss: 2.4347662925720215
Validation loss: 2.5443730456854707

Epoch: 5| Step: 9
Training loss: 2.24541974067688
Validation loss: 2.543897477529382

Epoch: 5| Step: 10
Training loss: 2.747802495956421
Validation loss: 2.5449461988223496

Epoch: 138| Step: 0
Training loss: 2.5961227416992188
Validation loss: 2.5419713015197427

Epoch: 5| Step: 1
Training loss: 3.5740323066711426
Validation loss: 2.546222981586251

Epoch: 5| Step: 2
Training loss: 2.351085901260376
Validation loss: 2.5517881660051245

Epoch: 5| Step: 3
Training loss: 3.276310443878174
Validation loss: 2.551751449543943

Epoch: 5| Step: 4
Training loss: 2.5234439373016357
Validation loss: 2.5617072582244873

Epoch: 5| Step: 5
Training loss: 2.4336533546447754
Validation loss: 2.5612477999861523

Epoch: 5| Step: 6
Training loss: 2.543102741241455
Validation loss: 2.5547350273337415

Epoch: 5| Step: 7
Training loss: 3.125619411468506
Validation loss: 2.5566888445167133

Epoch: 5| Step: 8
Training loss: 3.14371919631958
Validation loss: 2.5616889025575373

Epoch: 5| Step: 9
Training loss: 2.1419618129730225
Validation loss: 2.562501261311193

Epoch: 5| Step: 10
Training loss: 2.0978848934173584
Validation loss: 2.5608862625655306

Epoch: 139| Step: 0
Training loss: 2.7983274459838867
Validation loss: 2.5540900230407715

Epoch: 5| Step: 1
Training loss: 2.3132174015045166
Validation loss: 2.5379511284571823

Epoch: 5| Step: 2
Training loss: 3.2363059520721436
Validation loss: 2.5368767912669847

Epoch: 5| Step: 3
Training loss: 2.3673806190490723
Validation loss: 2.535937055464714

Epoch: 5| Step: 4
Training loss: 3.2152743339538574
Validation loss: 2.5356115551405054

Epoch: 5| Step: 5
Training loss: 2.7791056632995605
Validation loss: 2.5308539918673936

Epoch: 5| Step: 6
Training loss: 2.2435829639434814
Validation loss: 2.5313787409054336

Epoch: 5| Step: 7
Training loss: 2.861532688140869
Validation loss: 2.530360109062605

Epoch: 5| Step: 8
Training loss: 3.090813398361206
Validation loss: 2.5360126726088987

Epoch: 5| Step: 9
Training loss: 1.7463347911834717
Validation loss: 2.5349892070216518

Epoch: 5| Step: 10
Training loss: 3.2239110469818115
Validation loss: 2.5414224363142446

Epoch: 140| Step: 0
Training loss: 2.0322461128234863
Validation loss: 2.5357279751890447

Epoch: 5| Step: 1
Training loss: 2.9820847511291504
Validation loss: 2.5374228108313774

Epoch: 5| Step: 2
Training loss: 3.2149925231933594
Validation loss: 2.532675304720479

Epoch: 5| Step: 3
Training loss: 3.0511984825134277
Validation loss: 2.5336226212081088

Epoch: 5| Step: 4
Training loss: 2.592237949371338
Validation loss: 2.5311440037142847

Epoch: 5| Step: 5
Training loss: 2.4221954345703125
Validation loss: 2.5297105722529913

Epoch: 5| Step: 6
Training loss: 3.3810627460479736
Validation loss: 2.5320618383346067

Epoch: 5| Step: 7
Training loss: 3.3776469230651855
Validation loss: 2.5362452204509447

Epoch: 5| Step: 8
Training loss: 1.8924230337142944
Validation loss: 2.531299137300061

Epoch: 5| Step: 9
Training loss: 2.7999954223632812
Validation loss: 2.5339103078329437

Epoch: 5| Step: 10
Training loss: 1.8968175649642944
Validation loss: 2.5349932768011607

Epoch: 141| Step: 0
Training loss: 2.0837349891662598
Validation loss: 2.5348647486779

Epoch: 5| Step: 1
Training loss: 2.4709019660949707
Validation loss: 2.536395611301545

Epoch: 5| Step: 2
Training loss: 3.2457454204559326
Validation loss: 2.545895132967221

Epoch: 5| Step: 3
Training loss: 2.6634745597839355
Validation loss: 2.5420163523766304

Epoch: 5| Step: 4
Training loss: 2.3194000720977783
Validation loss: 2.5541463398164317

Epoch: 5| Step: 5
Training loss: 2.631410598754883
Validation loss: 2.5487585913750435

Epoch: 5| Step: 6
Training loss: 2.6233997344970703
Validation loss: 2.560474452152047

Epoch: 5| Step: 7
Training loss: 2.896505355834961
Validation loss: 2.5605962584095616

Epoch: 5| Step: 8
Training loss: 3.4279847145080566
Validation loss: 2.5562625110790296

Epoch: 5| Step: 9
Training loss: 3.0799930095672607
Validation loss: 2.557653646315298

Epoch: 5| Step: 10
Training loss: 2.3102242946624756
Validation loss: 2.552555427756361

Epoch: 142| Step: 0
Training loss: 3.1067185401916504
Validation loss: 2.5527335623259186

Epoch: 5| Step: 1
Training loss: 2.5073180198669434
Validation loss: 2.5539856828669065

Epoch: 5| Step: 2
Training loss: 2.1188838481903076
Validation loss: 2.5528154655169417

Epoch: 5| Step: 3
Training loss: 2.5851542949676514
Validation loss: 2.553904036039947

Epoch: 5| Step: 4
Training loss: 3.2617347240448
Validation loss: 2.5530992682262132

Epoch: 5| Step: 5
Training loss: 3.088094711303711
Validation loss: 2.553506851196289

Epoch: 5| Step: 6
Training loss: 2.398890972137451
Validation loss: 2.550819945591752

Epoch: 5| Step: 7
Training loss: 2.139899492263794
Validation loss: 2.542734153809086

Epoch: 5| Step: 8
Training loss: 3.1089043617248535
Validation loss: 2.5509625532293834

Epoch: 5| Step: 9
Training loss: 3.058659553527832
Validation loss: 2.54519211605031

Epoch: 5| Step: 10
Training loss: 2.2848973274230957
Validation loss: 2.546274838909026

Epoch: 143| Step: 0
Training loss: 2.671541690826416
Validation loss: 2.5417877422866

Epoch: 5| Step: 1
Training loss: 3.318911075592041
Validation loss: 2.5421907209580943

Epoch: 5| Step: 2
Training loss: 2.3583950996398926
Validation loss: 2.538813808912872

Epoch: 5| Step: 3
Training loss: 2.1926088333129883
Validation loss: 2.538397796692387

Epoch: 5| Step: 4
Training loss: 3.7715415954589844
Validation loss: 2.5399464561093237

Epoch: 5| Step: 5
Training loss: 2.5639400482177734
Validation loss: 2.533192342327487

Epoch: 5| Step: 6
Training loss: 2.6335222721099854
Validation loss: 2.537612881711734

Epoch: 5| Step: 7
Training loss: 2.937950849533081
Validation loss: 2.53579968021762

Epoch: 5| Step: 8
Training loss: 2.260324478149414
Validation loss: 2.5339520733843566

Epoch: 5| Step: 9
Training loss: 2.7075347900390625
Validation loss: 2.5309855707230104

Epoch: 5| Step: 10
Training loss: 2.2016141414642334
Validation loss: 2.529784607630904

Epoch: 144| Step: 0
Training loss: 1.9713420867919922
Validation loss: 2.527897319486064

Epoch: 5| Step: 1
Training loss: 2.9853978157043457
Validation loss: 2.5295224881941274

Epoch: 5| Step: 2
Training loss: 2.664720058441162
Validation loss: 2.530043750680903

Epoch: 5| Step: 3
Training loss: 2.8726232051849365
Validation loss: 2.5264148917249454

Epoch: 5| Step: 4
Training loss: 2.4812419414520264
Validation loss: 2.526852789745536

Epoch: 5| Step: 5
Training loss: 2.6630890369415283
Validation loss: 2.5267901318047636

Epoch: 5| Step: 6
Training loss: 2.6112492084503174
Validation loss: 2.5273916131706646

Epoch: 5| Step: 7
Training loss: 2.688403367996216
Validation loss: 2.5291670342927337

Epoch: 5| Step: 8
Training loss: 3.2007312774658203
Validation loss: 2.5263811029413694

Epoch: 5| Step: 9
Training loss: 2.571061611175537
Validation loss: 2.5318313798596783

Epoch: 5| Step: 10
Training loss: 3.012789726257324
Validation loss: 2.5295570563244563

Epoch: 145| Step: 0
Training loss: 3.0604591369628906
Validation loss: 2.5363024306553665

Epoch: 5| Step: 1
Training loss: 3.16538405418396
Validation loss: 2.5425760130728445

Epoch: 5| Step: 2
Training loss: 1.791055679321289
Validation loss: 2.538237558898105

Epoch: 5| Step: 3
Training loss: 3.1778361797332764
Validation loss: 2.546974753820768

Epoch: 5| Step: 4
Training loss: 2.477571964263916
Validation loss: 2.542977635578443

Epoch: 5| Step: 5
Training loss: 2.6366920471191406
Validation loss: 2.5432266855752594

Epoch: 5| Step: 6
Training loss: 2.554527759552002
Validation loss: 2.537885319802069

Epoch: 5| Step: 7
Training loss: 3.4169673919677734
Validation loss: 2.5322832907399824

Epoch: 5| Step: 8
Training loss: 2.5250442028045654
Validation loss: 2.545358004108552

Epoch: 5| Step: 9
Training loss: 2.072929620742798
Validation loss: 2.557739027084843

Epoch: 5| Step: 10
Training loss: 2.9115352630615234
Validation loss: 2.575403498065087

Epoch: 146| Step: 0
Training loss: 2.902724504470825
Validation loss: 2.57081945993567

Epoch: 5| Step: 1
Training loss: 2.6113486289978027
Validation loss: 2.5552430075983845

Epoch: 5| Step: 2
Training loss: 3.4877827167510986
Validation loss: 2.5474174509766283

Epoch: 5| Step: 3
Training loss: 2.42336368560791
Validation loss: 2.5350415373361237

Epoch: 5| Step: 4
Training loss: 2.473158359527588
Validation loss: 2.5269021372641287

Epoch: 5| Step: 5
Training loss: 2.0262484550476074
Validation loss: 2.5315943712829263

Epoch: 5| Step: 6
Training loss: 2.7698802947998047
Validation loss: 2.5284478484943347

Epoch: 5| Step: 7
Training loss: 2.3079349994659424
Validation loss: 2.5253930399494786

Epoch: 5| Step: 8
Training loss: 2.633533477783203
Validation loss: 2.5281597709143036

Epoch: 5| Step: 9
Training loss: 3.0383498668670654
Validation loss: 2.5244043988566243

Epoch: 5| Step: 10
Training loss: 3.1240322589874268
Validation loss: 2.5295203065359466

Epoch: 147| Step: 0
Training loss: 2.7693064212799072
Validation loss: 2.5306784183748308

Epoch: 5| Step: 1
Training loss: 2.616203784942627
Validation loss: 2.5275104712414485

Epoch: 5| Step: 2
Training loss: 3.4412341117858887
Validation loss: 2.5281704382229875

Epoch: 5| Step: 3
Training loss: 2.262235641479492
Validation loss: 2.5283923790019047

Epoch: 5| Step: 4
Training loss: 2.818225383758545
Validation loss: 2.5299627216913367

Epoch: 5| Step: 5
Training loss: 2.3963329792022705
Validation loss: 2.52734342698128

Epoch: 5| Step: 6
Training loss: 2.597673177719116
Validation loss: 2.525493678226266

Epoch: 5| Step: 7
Training loss: 2.4317898750305176
Validation loss: 2.526807036451114

Epoch: 5| Step: 8
Training loss: 2.6865649223327637
Validation loss: 2.5307575938522175

Epoch: 5| Step: 9
Training loss: 2.8668463230133057
Validation loss: 2.530219198555075

Epoch: 5| Step: 10
Training loss: 2.8185486793518066
Validation loss: 2.525743438351539

Epoch: 148| Step: 0
Training loss: 2.3140227794647217
Validation loss: 2.5248385834437546

Epoch: 5| Step: 1
Training loss: 2.533013343811035
Validation loss: 2.52517197978112

Epoch: 5| Step: 2
Training loss: 2.703227996826172
Validation loss: 2.5283149775638374

Epoch: 5| Step: 3
Training loss: 3.0481460094451904
Validation loss: 2.526624725710961

Epoch: 5| Step: 4
Training loss: 2.914442300796509
Validation loss: 2.5251973598234114

Epoch: 5| Step: 5
Training loss: 1.942100167274475
Validation loss: 2.5255916682622765

Epoch: 5| Step: 6
Training loss: 3.195213556289673
Validation loss: 2.527630054822532

Epoch: 5| Step: 7
Training loss: 2.8570988178253174
Validation loss: 2.5240829247300343

Epoch: 5| Step: 8
Training loss: 2.826063394546509
Validation loss: 2.525226395617249

Epoch: 5| Step: 9
Training loss: 2.689485788345337
Validation loss: 2.523818208325294

Epoch: 5| Step: 10
Training loss: 2.623572826385498
Validation loss: 2.5223367316748506

Epoch: 149| Step: 0
Training loss: 3.0065627098083496
Validation loss: 2.5225410743426253

Epoch: 5| Step: 1
Training loss: 2.1995351314544678
Validation loss: 2.526177267874441

Epoch: 5| Step: 2
Training loss: 2.8452401161193848
Validation loss: 2.525599930876045

Epoch: 5| Step: 3
Training loss: 2.6712048053741455
Validation loss: 2.522318791317683

Epoch: 5| Step: 4
Training loss: 2.6538844108581543
Validation loss: 2.5241446597601778

Epoch: 5| Step: 5
Training loss: 2.721069812774658
Validation loss: 2.525889486394903

Epoch: 5| Step: 6
Training loss: 2.5550031661987305
Validation loss: 2.525621029638475

Epoch: 5| Step: 7
Training loss: 2.7097690105438232
Validation loss: 2.5287704621591875

Epoch: 5| Step: 8
Training loss: 2.578526496887207
Validation loss: 2.520303096822513

Epoch: 5| Step: 9
Training loss: 2.8046722412109375
Validation loss: 2.526947964904129

Epoch: 5| Step: 10
Training loss: 2.8760507106781006
Validation loss: 2.52239647219258

Epoch: 150| Step: 0
Training loss: 2.7694854736328125
Validation loss: 2.52316088573907

Epoch: 5| Step: 1
Training loss: 2.320417642593384
Validation loss: 2.524799116196171

Epoch: 5| Step: 2
Training loss: 3.0340850353240967
Validation loss: 2.5269794002656014

Epoch: 5| Step: 3
Training loss: 2.1511104106903076
Validation loss: 2.5198861629732194

Epoch: 5| Step: 4
Training loss: 2.4497694969177246
Validation loss: 2.524296542649628

Epoch: 5| Step: 5
Training loss: 2.1726717948913574
Validation loss: 2.519741976132957

Epoch: 5| Step: 6
Training loss: 2.681258201599121
Validation loss: 2.520550679135066

Epoch: 5| Step: 7
Training loss: 3.4150047302246094
Validation loss: 2.5239425654052408

Epoch: 5| Step: 8
Training loss: 3.2283923625946045
Validation loss: 2.5227905870765768

Epoch: 5| Step: 9
Training loss: 2.826289653778076
Validation loss: 2.5194068083199124

Epoch: 5| Step: 10
Training loss: 2.5011184215545654
Validation loss: 2.523409887026715

Epoch: 151| Step: 0
Training loss: 2.3782174587249756
Validation loss: 2.521634219795145

Epoch: 5| Step: 1
Training loss: 3.0091450214385986
Validation loss: 2.518899876584289

Epoch: 5| Step: 2
Training loss: 3.026097059249878
Validation loss: 2.5219206502360683

Epoch: 5| Step: 3
Training loss: 2.8960165977478027
Validation loss: 2.5243125705308813

Epoch: 5| Step: 4
Training loss: 2.865952968597412
Validation loss: 2.528571072445121

Epoch: 5| Step: 5
Training loss: 2.222564458847046
Validation loss: 2.525747137684976

Epoch: 5| Step: 6
Training loss: 3.0819077491760254
Validation loss: 2.519028899490192

Epoch: 5| Step: 7
Training loss: 2.861717700958252
Validation loss: 2.5226157070488058

Epoch: 5| Step: 8
Training loss: 1.9561984539031982
Validation loss: 2.514078673496041

Epoch: 5| Step: 9
Training loss: 2.7297439575195312
Validation loss: 2.5155295607864216

Epoch: 5| Step: 10
Training loss: 2.4793717861175537
Validation loss: 2.5156308681734147

Epoch: 152| Step: 0
Training loss: 3.205744981765747
Validation loss: 2.5186069139870266

Epoch: 5| Step: 1
Training loss: 2.684813976287842
Validation loss: 2.520654293798631

Epoch: 5| Step: 2
Training loss: 2.3925013542175293
Validation loss: 2.52424382650724

Epoch: 5| Step: 3
Training loss: 2.595114231109619
Validation loss: 2.5205522532104165

Epoch: 5| Step: 4
Training loss: 2.7224245071411133
Validation loss: 2.5202260940305647

Epoch: 5| Step: 5
Training loss: 2.914799928665161
Validation loss: 2.522559465900544

Epoch: 5| Step: 6
Training loss: 2.7492098808288574
Validation loss: 2.5166882930263395

Epoch: 5| Step: 7
Training loss: 2.979008436203003
Validation loss: 2.518102935565415

Epoch: 5| Step: 8
Training loss: 2.283590316772461
Validation loss: 2.5113674030509046

Epoch: 5| Step: 9
Training loss: 2.4827804565429688
Validation loss: 2.5169966195219304

Epoch: 5| Step: 10
Training loss: 2.514225721359253
Validation loss: 2.5197174831103255

Epoch: 153| Step: 0
Training loss: 2.555835723876953
Validation loss: 2.5240789305779243

Epoch: 5| Step: 1
Training loss: 2.509983539581299
Validation loss: 2.5321497712084042

Epoch: 5| Step: 2
Training loss: 2.3959801197052
Validation loss: 2.5424552502170688

Epoch: 5| Step: 3
Training loss: 3.0572636127471924
Validation loss: 2.54401046229947

Epoch: 5| Step: 4
Training loss: 2.5860791206359863
Validation loss: 2.5276849116048505

Epoch: 5| Step: 5
Training loss: 2.112917184829712
Validation loss: 2.5245635817127843

Epoch: 5| Step: 6
Training loss: 3.5646278858184814
Validation loss: 2.5210621895328647

Epoch: 5| Step: 7
Training loss: 2.6927649974823
Validation loss: 2.5248820602252917

Epoch: 5| Step: 8
Training loss: 2.2799715995788574
Validation loss: 2.5180515473888767

Epoch: 5| Step: 9
Training loss: 3.5002200603485107
Validation loss: 2.5202262017034713

Epoch: 5| Step: 10
Training loss: 2.2201762199401855
Validation loss: 2.527810178777223

Epoch: 154| Step: 0
Training loss: 2.028641939163208
Validation loss: 2.523880676556659

Epoch: 5| Step: 1
Training loss: 3.1328048706054688
Validation loss: 2.5242543041065173

Epoch: 5| Step: 2
Training loss: 2.638274908065796
Validation loss: 2.5245300339114283

Epoch: 5| Step: 3
Training loss: 3.8223166465759277
Validation loss: 2.5217694467113865

Epoch: 5| Step: 4
Training loss: 2.0127148628234863
Validation loss: 2.5123852965652302

Epoch: 5| Step: 5
Training loss: 2.1970105171203613
Validation loss: 2.510355818656183

Epoch: 5| Step: 6
Training loss: 3.07018780708313
Validation loss: 2.5100268548534763

Epoch: 5| Step: 7
Training loss: 2.771312713623047
Validation loss: 2.5079117487835627

Epoch: 5| Step: 8
Training loss: 2.7921810150146484
Validation loss: 2.505713491029637

Epoch: 5| Step: 9
Training loss: 2.3071212768554688
Validation loss: 2.506523932180097

Epoch: 5| Step: 10
Training loss: 2.7570087909698486
Validation loss: 2.5033985748085925

Epoch: 155| Step: 0
Training loss: 2.6099371910095215
Validation loss: 2.5049225053479596

Epoch: 5| Step: 1
Training loss: 3.0073463916778564
Validation loss: 2.5112515931488364

Epoch: 5| Step: 2
Training loss: 2.3207364082336426
Validation loss: 2.5130641947510424

Epoch: 5| Step: 3
Training loss: 3.211982011795044
Validation loss: 2.509529775188815

Epoch: 5| Step: 4
Training loss: 2.465313673019409
Validation loss: 2.5127886085100073

Epoch: 5| Step: 5
Training loss: 2.5855941772460938
Validation loss: 2.5088807793073755

Epoch: 5| Step: 6
Training loss: 2.6369192600250244
Validation loss: 2.507353413489557

Epoch: 5| Step: 7
Training loss: 2.5253827571868896
Validation loss: 2.5100005211368686

Epoch: 5| Step: 8
Training loss: 2.957387685775757
Validation loss: 2.5115711535176923

Epoch: 5| Step: 9
Training loss: 2.510145664215088
Validation loss: 2.5133016724740305

Epoch: 5| Step: 10
Training loss: 2.6542952060699463
Validation loss: 2.511645045331729

Epoch: 156| Step: 0
Training loss: 1.7820003032684326
Validation loss: 2.515195861939461

Epoch: 5| Step: 1
Training loss: 2.8885650634765625
Validation loss: 2.514757407608853

Epoch: 5| Step: 2
Training loss: 2.9848930835723877
Validation loss: 2.5118105744802826

Epoch: 5| Step: 3
Training loss: 2.015361785888672
Validation loss: 2.5118378285438783

Epoch: 5| Step: 4
Training loss: 2.6025943756103516
Validation loss: 2.519516598793768

Epoch: 5| Step: 5
Training loss: 3.2457175254821777
Validation loss: 2.5090048005503993

Epoch: 5| Step: 6
Training loss: 2.9749855995178223
Validation loss: 2.5115338756192114

Epoch: 5| Step: 7
Training loss: 2.6668238639831543
Validation loss: 2.5105043252309165

Epoch: 5| Step: 8
Training loss: 3.2143890857696533
Validation loss: 2.5078010251445155

Epoch: 5| Step: 9
Training loss: 2.479567527770996
Validation loss: 2.5047707839678695

Epoch: 5| Step: 10
Training loss: 2.687572717666626
Validation loss: 2.5013085385804534

Epoch: 157| Step: 0
Training loss: 2.278562068939209
Validation loss: 2.5065321999211467

Epoch: 5| Step: 1
Training loss: 2.8666820526123047
Validation loss: 2.5029968318118843

Epoch: 5| Step: 2
Training loss: 2.497743606567383
Validation loss: 2.503243500186551

Epoch: 5| Step: 3
Training loss: 2.9071342945098877
Validation loss: 2.4984980526790825

Epoch: 5| Step: 4
Training loss: 2.0901448726654053
Validation loss: 2.4964045478451635

Epoch: 5| Step: 5
Training loss: 2.5390400886535645
Validation loss: 2.4984647843145553

Epoch: 5| Step: 6
Training loss: 2.7617475986480713
Validation loss: 2.5000590970439296

Epoch: 5| Step: 7
Training loss: 3.4959323406219482
Validation loss: 2.498530844206451

Epoch: 5| Step: 8
Training loss: 3.0272369384765625
Validation loss: 2.50281273934149

Epoch: 5| Step: 9
Training loss: 2.373919725418091
Validation loss: 2.4984403015464864

Epoch: 5| Step: 10
Training loss: 2.61074161529541
Validation loss: 2.4999868459598993

Epoch: 158| Step: 0
Training loss: 2.6701266765594482
Validation loss: 2.5042257270505353

Epoch: 5| Step: 1
Training loss: 2.8479955196380615
Validation loss: 2.5055887006944224

Epoch: 5| Step: 2
Training loss: 3.1970725059509277
Validation loss: 2.503011331763319

Epoch: 5| Step: 3
Training loss: 2.061743974685669
Validation loss: 2.5033292667840117

Epoch: 5| Step: 4
Training loss: 3.448124647140503
Validation loss: 2.5041100850669284

Epoch: 5| Step: 5
Training loss: 2.793091297149658
Validation loss: 2.5079306710150933

Epoch: 5| Step: 6
Training loss: 2.453913927078247
Validation loss: 2.5113837975327686

Epoch: 5| Step: 7
Training loss: 2.7077062129974365
Validation loss: 2.50935116634574

Epoch: 5| Step: 8
Training loss: 2.604506254196167
Validation loss: 2.5108897198912916

Epoch: 5| Step: 9
Training loss: 2.019862651824951
Validation loss: 2.5149615374944543

Epoch: 5| Step: 10
Training loss: 2.6734745502471924
Validation loss: 2.5133390272817304

Epoch: 159| Step: 0
Training loss: 3.0670995712280273
Validation loss: 2.5156668514333744

Epoch: 5| Step: 1
Training loss: 2.587475538253784
Validation loss: 2.5112772116097073

Epoch: 5| Step: 2
Training loss: 2.1916165351867676
Validation loss: 2.5077652828667754

Epoch: 5| Step: 3
Training loss: 3.24560809135437
Validation loss: 2.511139649216847

Epoch: 5| Step: 4
Training loss: 3.811131238937378
Validation loss: 2.5111672698810534

Epoch: 5| Step: 5
Training loss: 2.786581039428711
Validation loss: 2.5184055400151077

Epoch: 5| Step: 6
Training loss: 2.448776960372925
Validation loss: 2.5143764634286203

Epoch: 5| Step: 7
Training loss: 2.558305025100708
Validation loss: 2.512287562893283

Epoch: 5| Step: 8
Training loss: 1.7736793756484985
Validation loss: 2.5070014410121466

Epoch: 5| Step: 9
Training loss: 2.937612533569336
Validation loss: 2.5054623567929832

Epoch: 5| Step: 10
Training loss: 2.011293411254883
Validation loss: 2.500528094589069

Epoch: 160| Step: 0
Training loss: 2.7619407176971436
Validation loss: 2.495030931247178

Epoch: 5| Step: 1
Training loss: 2.2293081283569336
Validation loss: 2.4963503729912544

Epoch: 5| Step: 2
Training loss: 3.410742998123169
Validation loss: 2.4961199247708885

Epoch: 5| Step: 3
Training loss: 2.7645764350891113
Validation loss: 2.4964117644935526

Epoch: 5| Step: 4
Training loss: 2.454453229904175
Validation loss: 2.492243287383869

Epoch: 5| Step: 5
Training loss: 3.148083209991455
Validation loss: 2.4965448456425823

Epoch: 5| Step: 6
Training loss: 2.1834702491760254
Validation loss: 2.496997707633562

Epoch: 5| Step: 7
Training loss: 2.8003854751586914
Validation loss: 2.497289385846866

Epoch: 5| Step: 8
Training loss: 2.246574640274048
Validation loss: 2.50257553849169

Epoch: 5| Step: 9
Training loss: 2.9285337924957275
Validation loss: 2.4996885663719586

Epoch: 5| Step: 10
Training loss: 2.4674110412597656
Validation loss: 2.4998648525566183

Epoch: 161| Step: 0
Training loss: 2.5538411140441895
Validation loss: 2.5022359689076743

Epoch: 5| Step: 1
Training loss: 2.5616140365600586
Validation loss: 2.5018149498970277

Epoch: 5| Step: 2
Training loss: 2.3287689685821533
Validation loss: 2.5043563560772966

Epoch: 5| Step: 3
Training loss: 2.7157883644104004
Validation loss: 2.5053405710445937

Epoch: 5| Step: 4
Training loss: 2.839292526245117
Validation loss: 2.5044040013385076

Epoch: 5| Step: 5
Training loss: 2.6448917388916016
Validation loss: 2.507381841700564

Epoch: 5| Step: 6
Training loss: 3.119110107421875
Validation loss: 2.501202916586271

Epoch: 5| Step: 7
Training loss: 3.125645160675049
Validation loss: 2.508742417058637

Epoch: 5| Step: 8
Training loss: 2.867788553237915
Validation loss: 2.508860085600166

Epoch: 5| Step: 9
Training loss: 1.985111951828003
Validation loss: 2.510171439058037

Epoch: 5| Step: 10
Training loss: 2.6719470024108887
Validation loss: 2.509415293252596

Epoch: 162| Step: 0
Training loss: 2.5439374446868896
Validation loss: 2.509025973658408

Epoch: 5| Step: 1
Training loss: 2.837185859680176
Validation loss: 2.5099745950391217

Epoch: 5| Step: 2
Training loss: 2.9368889331817627
Validation loss: 2.5099261447947514

Epoch: 5| Step: 3
Training loss: 2.402435779571533
Validation loss: 2.5132342999981296

Epoch: 5| Step: 4
Training loss: 2.93676495552063
Validation loss: 2.517629756722399

Epoch: 5| Step: 5
Training loss: 2.4283599853515625
Validation loss: 2.5122448654584986

Epoch: 5| Step: 6
Training loss: 2.1303791999816895
Validation loss: 2.5165729035613356

Epoch: 5| Step: 7
Training loss: 2.9821572303771973
Validation loss: 2.5254624402651222

Epoch: 5| Step: 8
Training loss: 3.0994367599487305
Validation loss: 2.527559623923353

Epoch: 5| Step: 9
Training loss: 2.403975009918213
Validation loss: 2.5162888329516173

Epoch: 5| Step: 10
Training loss: 2.809335708618164
Validation loss: 2.5056444752600884

Epoch: 163| Step: 0
Training loss: 2.5216431617736816
Validation loss: 2.5064179948581162

Epoch: 5| Step: 1
Training loss: 3.260216236114502
Validation loss: 2.4990851674028622

Epoch: 5| Step: 2
Training loss: 2.316640853881836
Validation loss: 2.4976315036896737

Epoch: 5| Step: 3
Training loss: 2.7207229137420654
Validation loss: 2.499719209568475

Epoch: 5| Step: 4
Training loss: 2.19063138961792
Validation loss: 2.4951499226272746

Epoch: 5| Step: 5
Training loss: 2.94169545173645
Validation loss: 2.4988193358144453

Epoch: 5| Step: 6
Training loss: 2.727811098098755
Validation loss: 2.4948103427886963

Epoch: 5| Step: 7
Training loss: 2.440824031829834
Validation loss: 2.4927223651639876

Epoch: 5| Step: 8
Training loss: 2.763683319091797
Validation loss: 2.4945805713694584

Epoch: 5| Step: 9
Training loss: 2.6957569122314453
Validation loss: 2.4959074681805027

Epoch: 5| Step: 10
Training loss: 2.7998270988464355
Validation loss: 2.5022515250790502

Epoch: 164| Step: 0
Training loss: 2.985273838043213
Validation loss: 2.495112593455981

Epoch: 5| Step: 1
Training loss: 2.4609439373016357
Validation loss: 2.490803672421363

Epoch: 5| Step: 2
Training loss: 2.541792392730713
Validation loss: 2.4970894346955004

Epoch: 5| Step: 3
Training loss: 3.1248679161071777
Validation loss: 2.49505978245889

Epoch: 5| Step: 4
Training loss: 2.7658321857452393
Validation loss: 2.495249679011683

Epoch: 5| Step: 5
Training loss: 2.682685375213623
Validation loss: 2.4968440007137995

Epoch: 5| Step: 6
Training loss: 2.1543469429016113
Validation loss: 2.499554080347861

Epoch: 5| Step: 7
Training loss: 3.4175021648406982
Validation loss: 2.5046421276625765

Epoch: 5| Step: 8
Training loss: 2.8648037910461426
Validation loss: 2.5051224718811693

Epoch: 5| Step: 9
Training loss: 2.479475498199463
Validation loss: 2.50914361399989

Epoch: 5| Step: 10
Training loss: 1.845947504043579
Validation loss: 2.510073500294839

Epoch: 165| Step: 0
Training loss: 3.1421189308166504
Validation loss: 2.515111013125348

Epoch: 5| Step: 1
Training loss: 3.542529344558716
Validation loss: 2.512587549865887

Epoch: 5| Step: 2
Training loss: 2.607609510421753
Validation loss: 2.5094452391388598

Epoch: 5| Step: 3
Training loss: 2.782979965209961
Validation loss: 2.5077630371175785

Epoch: 5| Step: 4
Training loss: 2.3517069816589355
Validation loss: 2.5126279374604583

Epoch: 5| Step: 5
Training loss: 2.147080421447754
Validation loss: 2.5086321036020913

Epoch: 5| Step: 6
Training loss: 2.053126811981201
Validation loss: 2.510516487142091

Epoch: 5| Step: 7
Training loss: 3.3722808361053467
Validation loss: 2.5203171904369066

Epoch: 5| Step: 8
Training loss: 2.6916377544403076
Validation loss: 2.5133996753282446

Epoch: 5| Step: 9
Training loss: 1.9723918437957764
Validation loss: 2.517207299509356

Epoch: 5| Step: 10
Training loss: 2.8159852027893066
Validation loss: 2.512519395479592

Epoch: 166| Step: 0
Training loss: 2.924428701400757
Validation loss: 2.508048745893663

Epoch: 5| Step: 1
Training loss: 2.6687045097351074
Validation loss: 2.502109986479564

Epoch: 5| Step: 2
Training loss: 2.355679512023926
Validation loss: 2.50055480259721

Epoch: 5| Step: 3
Training loss: 2.8308253288269043
Validation loss: 2.4962976158306165

Epoch: 5| Step: 4
Training loss: 2.3120126724243164
Validation loss: 2.4899160503059306

Epoch: 5| Step: 5
Training loss: 2.844597578048706
Validation loss: 2.497250331345425

Epoch: 5| Step: 6
Training loss: 2.6115059852600098
Validation loss: 2.495730492376512

Epoch: 5| Step: 7
Training loss: 2.650299072265625
Validation loss: 2.4948126526289087

Epoch: 5| Step: 8
Training loss: 2.4259047508239746
Validation loss: 2.4971357904454714

Epoch: 5| Step: 9
Training loss: 2.640927791595459
Validation loss: 2.496446976097681

Epoch: 5| Step: 10
Training loss: 3.2042627334594727
Validation loss: 2.487879071184384

Epoch: 167| Step: 0
Training loss: 2.4316163063049316
Validation loss: 2.495192012479228

Epoch: 5| Step: 1
Training loss: 2.3891749382019043
Validation loss: 2.4929255823935232

Epoch: 5| Step: 2
Training loss: 3.228935956954956
Validation loss: 2.4977667562423216

Epoch: 5| Step: 3
Training loss: 2.145081043243408
Validation loss: 2.50629743196631

Epoch: 5| Step: 4
Training loss: 2.360852003097534
Validation loss: 2.498044531832459

Epoch: 5| Step: 5
Training loss: 3.215991973876953
Validation loss: 2.5011486084230485

Epoch: 5| Step: 6
Training loss: 2.9940669536590576
Validation loss: 2.501262687867688

Epoch: 5| Step: 7
Training loss: 2.5881097316741943
Validation loss: 2.508666573032256

Epoch: 5| Step: 8
Training loss: 3.212383985519409
Validation loss: 2.4978320598602295

Epoch: 5| Step: 9
Training loss: 2.1559791564941406
Validation loss: 2.492809018781108

Epoch: 5| Step: 10
Training loss: 2.581390380859375
Validation loss: 2.490786793411419

Epoch: 168| Step: 0
Training loss: 2.247844696044922
Validation loss: 2.495284854724843

Epoch: 5| Step: 1
Training loss: 2.0633957386016846
Validation loss: 2.495335696845926

Epoch: 5| Step: 2
Training loss: 3.175572633743286
Validation loss: 2.4999147179306194

Epoch: 5| Step: 3
Training loss: 3.4638469219207764
Validation loss: 2.5017331184879428

Epoch: 5| Step: 4
Training loss: 2.3292646408081055
Validation loss: 2.5054257249319427

Epoch: 5| Step: 5
Training loss: 2.307433843612671
Validation loss: 2.50921287844258

Epoch: 5| Step: 6
Training loss: 2.2038960456848145
Validation loss: 2.5073184685040544

Epoch: 5| Step: 7
Training loss: 2.42641019821167
Validation loss: 2.5177942552874164

Epoch: 5| Step: 8
Training loss: 3.3963875770568848
Validation loss: 2.504052931262601

Epoch: 5| Step: 9
Training loss: 3.151616334915161
Validation loss: 2.5021629179677656

Epoch: 5| Step: 10
Training loss: 2.5944926738739014
Validation loss: 2.4992396293147916

Epoch: 169| Step: 0
Training loss: 2.9057631492614746
Validation loss: 2.48762999298752

Epoch: 5| Step: 1
Training loss: 1.9028888940811157
Validation loss: 2.485678213898854

Epoch: 5| Step: 2
Training loss: 2.2274177074432373
Validation loss: 2.4867765954745713

Epoch: 5| Step: 3
Training loss: 2.8044986724853516
Validation loss: 2.4836791689677904

Epoch: 5| Step: 4
Training loss: 2.478668689727783
Validation loss: 2.4872099917422057

Epoch: 5| Step: 5
Training loss: 3.1442418098449707
Validation loss: 2.4903170626650573

Epoch: 5| Step: 6
Training loss: 2.9172146320343018
Validation loss: 2.4888446523297216

Epoch: 5| Step: 7
Training loss: 3.117250680923462
Validation loss: 2.4968967745381017

Epoch: 5| Step: 8
Training loss: 2.553436279296875
Validation loss: 2.491985749172908

Epoch: 5| Step: 9
Training loss: 2.197874069213867
Validation loss: 2.4887800216674805

Epoch: 5| Step: 10
Training loss: 3.1820099353790283
Validation loss: 2.4869280143450667

Epoch: 170| Step: 0
Training loss: 3.5331733226776123
Validation loss: 2.483601103546799

Epoch: 5| Step: 1
Training loss: 3.130647659301758
Validation loss: 2.480372036657026

Epoch: 5| Step: 2
Training loss: 2.1817028522491455
Validation loss: 2.485553785036969

Epoch: 5| Step: 3
Training loss: 2.1704516410827637
Validation loss: 2.4812823905739734

Epoch: 5| Step: 4
Training loss: 3.0673370361328125
Validation loss: 2.4829275531153523

Epoch: 5| Step: 5
Training loss: 2.8060028553009033
Validation loss: 2.4874139242274786

Epoch: 5| Step: 6
Training loss: 2.2141079902648926
Validation loss: 2.4832159267958773

Epoch: 5| Step: 7
Training loss: 2.5067341327667236
Validation loss: 2.4875680400479223

Epoch: 5| Step: 8
Training loss: 2.4653639793395996
Validation loss: 2.4908418834850354

Epoch: 5| Step: 9
Training loss: 3.0614895820617676
Validation loss: 2.492980275102841

Epoch: 5| Step: 10
Training loss: 2.132614850997925
Validation loss: 2.4936649876256145

Epoch: 171| Step: 0
Training loss: 2.3712077140808105
Validation loss: 2.4904260430284726

Epoch: 5| Step: 1
Training loss: 3.2365498542785645
Validation loss: 2.4881166873439664

Epoch: 5| Step: 2
Training loss: 2.9908604621887207
Validation loss: 2.485090301882836

Epoch: 5| Step: 3
Training loss: 2.442018985748291
Validation loss: 2.487251768830002

Epoch: 5| Step: 4
Training loss: 2.0946218967437744
Validation loss: 2.4836049977169243

Epoch: 5| Step: 5
Training loss: 3.138813018798828
Validation loss: 2.4869422451142342

Epoch: 5| Step: 6
Training loss: 2.202653646469116
Validation loss: 2.483496614681777

Epoch: 5| Step: 7
Training loss: 2.3872923851013184
Validation loss: 2.481749180824526

Epoch: 5| Step: 8
Training loss: 3.4288382530212402
Validation loss: 2.4830536098890406

Epoch: 5| Step: 9
Training loss: 2.7562968730926514
Validation loss: 2.496178157867924

Epoch: 5| Step: 10
Training loss: 2.2405641078948975
Validation loss: 2.50214974341854

Epoch: 172| Step: 0
Training loss: 2.594086170196533
Validation loss: 2.5186584277819564

Epoch: 5| Step: 1
Training loss: 3.127157211303711
Validation loss: 2.5296554667975313

Epoch: 5| Step: 2
Training loss: 2.7522995471954346
Validation loss: 2.524583124345349

Epoch: 5| Step: 3
Training loss: 2.6539573669433594
Validation loss: 2.5241652483581216

Epoch: 5| Step: 4
Training loss: 2.575197696685791
Validation loss: 2.5123841916361163

Epoch: 5| Step: 5
Training loss: 2.6971545219421387
Validation loss: 2.507213197728639

Epoch: 5| Step: 6
Training loss: 3.0833258628845215
Validation loss: 2.4921328124179634

Epoch: 5| Step: 7
Training loss: 2.1400306224823
Validation loss: 2.4850929001326203

Epoch: 5| Step: 8
Training loss: 2.8417985439300537
Validation loss: 2.4855226932033414

Epoch: 5| Step: 9
Training loss: 2.705881118774414
Validation loss: 2.4840161056928736

Epoch: 5| Step: 10
Training loss: 2.079909086227417
Validation loss: 2.4837575881711897

Epoch: 173| Step: 0
Training loss: 2.4543919563293457
Validation loss: 2.4867000195287887

Epoch: 5| Step: 1
Training loss: 2.389601945877075
Validation loss: 2.4823613807719243

Epoch: 5| Step: 2
Training loss: 3.0301642417907715
Validation loss: 2.482453700034849

Epoch: 5| Step: 3
Training loss: 2.8382747173309326
Validation loss: 2.4852003282116306

Epoch: 5| Step: 4
Training loss: 2.4333369731903076
Validation loss: 2.484019999862999

Epoch: 5| Step: 5
Training loss: 3.2068066596984863
Validation loss: 2.4790717171084498

Epoch: 5| Step: 6
Training loss: 2.446347713470459
Validation loss: 2.4828430606472875

Epoch: 5| Step: 7
Training loss: 2.223536968231201
Validation loss: 2.478175365796653

Epoch: 5| Step: 8
Training loss: 3.0829153060913086
Validation loss: 2.4873464492059525

Epoch: 5| Step: 9
Training loss: 2.8257548809051514
Validation loss: 2.483719664235269

Epoch: 5| Step: 10
Training loss: 2.333155870437622
Validation loss: 2.4895348536070956

Epoch: 174| Step: 0
Training loss: 2.226801633834839
Validation loss: 2.490023015647806

Epoch: 5| Step: 1
Training loss: 2.7508931159973145
Validation loss: 2.485966479906472

Epoch: 5| Step: 2
Training loss: 2.022158145904541
Validation loss: 2.4858322861374065

Epoch: 5| Step: 3
Training loss: 3.2632198333740234
Validation loss: 2.486091318950858

Epoch: 5| Step: 4
Training loss: 3.3084137439727783
Validation loss: 2.4815853795697613

Epoch: 5| Step: 5
Training loss: 2.4326109886169434
Validation loss: 2.480071178046606

Epoch: 5| Step: 6
Training loss: 2.6701819896698
Validation loss: 2.477367795923705

Epoch: 5| Step: 7
Training loss: 2.5652201175689697
Validation loss: 2.4822321604656916

Epoch: 5| Step: 8
Training loss: 2.3034379482269287
Validation loss: 2.4801825374685307

Epoch: 5| Step: 9
Training loss: 2.789083480834961
Validation loss: 2.4779264747455554

Epoch: 5| Step: 10
Training loss: 3.065919876098633
Validation loss: 2.476048074742799

Epoch: 175| Step: 0
Training loss: 3.155669927597046
Validation loss: 2.4792743831552486

Epoch: 5| Step: 1
Training loss: 2.1120693683624268
Validation loss: 2.483368915896262

Epoch: 5| Step: 2
Training loss: 2.430476188659668
Validation loss: 2.475094097916798

Epoch: 5| Step: 3
Training loss: 2.227548599243164
Validation loss: 2.4813924861210648

Epoch: 5| Step: 4
Training loss: 2.731796979904175
Validation loss: 2.478940697126491

Epoch: 5| Step: 5
Training loss: 2.715615749359131
Validation loss: 2.4851358116313977

Epoch: 5| Step: 6
Training loss: 2.126739978790283
Validation loss: 2.478349560050554

Epoch: 5| Step: 7
Training loss: 2.651245594024658
Validation loss: 2.4876607310387397

Epoch: 5| Step: 8
Training loss: 3.4071052074432373
Validation loss: 2.4837628154344458

Epoch: 5| Step: 9
Training loss: 2.948007583618164
Validation loss: 2.4880521323091243

Epoch: 5| Step: 10
Training loss: 2.7928402423858643
Validation loss: 2.483715234264251

Epoch: 176| Step: 0
Training loss: 2.477013349533081
Validation loss: 2.477661763468096

Epoch: 5| Step: 1
Training loss: 2.5559239387512207
Validation loss: 2.479112599485664

Epoch: 5| Step: 2
Training loss: 2.435626268386841
Validation loss: 2.4790949001107165

Epoch: 5| Step: 3
Training loss: 3.4765899181365967
Validation loss: 2.4760668995559856

Epoch: 5| Step: 4
Training loss: 2.4398465156555176
Validation loss: 2.47067589657281

Epoch: 5| Step: 5
Training loss: 2.658510684967041
Validation loss: 2.472700539455619

Epoch: 5| Step: 6
Training loss: 2.204296827316284
Validation loss: 2.4779978003553165

Epoch: 5| Step: 7
Training loss: 2.5256247520446777
Validation loss: 2.480447594837476

Epoch: 5| Step: 8
Training loss: 2.8787853717803955
Validation loss: 2.4879890872586157

Epoch: 5| Step: 9
Training loss: 2.794670343399048
Validation loss: 2.4895497598955707

Epoch: 5| Step: 10
Training loss: 2.8046772480010986
Validation loss: 2.4828105613749516

Epoch: 177| Step: 0
Training loss: 2.8506317138671875
Validation loss: 2.481597342798787

Epoch: 5| Step: 1
Training loss: 2.2141246795654297
Validation loss: 2.4724696502890637

Epoch: 5| Step: 2
Training loss: 2.5184848308563232
Validation loss: 2.4727268475358204

Epoch: 5| Step: 3
Training loss: 2.4148547649383545
Validation loss: 2.471480818204982

Epoch: 5| Step: 4
Training loss: 3.3099429607391357
Validation loss: 2.4813834928697154

Epoch: 5| Step: 5
Training loss: 2.5093321800231934
Validation loss: 2.481705919388802

Epoch: 5| Step: 6
Training loss: 2.7337887287139893
Validation loss: 2.487077607903429

Epoch: 5| Step: 7
Training loss: 2.3688158988952637
Validation loss: 2.4981630463753977

Epoch: 5| Step: 8
Training loss: 2.6312975883483887
Validation loss: 2.5208797044651483

Epoch: 5| Step: 9
Training loss: 2.681978940963745
Validation loss: 2.5259211550476732

Epoch: 5| Step: 10
Training loss: 3.175415515899658
Validation loss: 2.527349918119369

Epoch: 178| Step: 0
Training loss: 2.745424747467041
Validation loss: 2.5094958941141763

Epoch: 5| Step: 1
Training loss: 3.218153476715088
Validation loss: 2.4991183691127326

Epoch: 5| Step: 2
Training loss: 3.1557486057281494
Validation loss: 2.4820028376835648

Epoch: 5| Step: 3
Training loss: 2.084873914718628
Validation loss: 2.4857119257732103

Epoch: 5| Step: 4
Training loss: 2.5233378410339355
Validation loss: 2.4837511072876635

Epoch: 5| Step: 5
Training loss: 2.2269225120544434
Validation loss: 2.4793119712542464

Epoch: 5| Step: 6
Training loss: 2.289536714553833
Validation loss: 2.4797624977686072

Epoch: 5| Step: 7
Training loss: 2.473893642425537
Validation loss: 2.4779385033474175

Epoch: 5| Step: 8
Training loss: 3.083275556564331
Validation loss: 2.4748495060910463

Epoch: 5| Step: 9
Training loss: 2.5582146644592285
Validation loss: 2.4786469244187876

Epoch: 5| Step: 10
Training loss: 2.932859182357788
Validation loss: 2.4809710466733543

Epoch: 179| Step: 0
Training loss: 2.769282341003418
Validation loss: 2.4752380873567317

Epoch: 5| Step: 1
Training loss: 3.2606098651885986
Validation loss: 2.4772066070187475

Epoch: 5| Step: 2
Training loss: 2.6650798320770264
Validation loss: 2.4752542485472975

Epoch: 5| Step: 3
Training loss: 2.2455055713653564
Validation loss: 2.4703009897662747

Epoch: 5| Step: 4
Training loss: 2.8087639808654785
Validation loss: 2.4751964717782955

Epoch: 5| Step: 5
Training loss: 1.9395067691802979
Validation loss: 2.4756242229092504

Epoch: 5| Step: 6
Training loss: 2.722255229949951
Validation loss: 2.4630979491818334

Epoch: 5| Step: 7
Training loss: 2.872447967529297
Validation loss: 2.464752076774515

Epoch: 5| Step: 8
Training loss: 2.6868319511413574
Validation loss: 2.4691326310557704

Epoch: 5| Step: 9
Training loss: 2.241560697555542
Validation loss: 2.4661546009843067

Epoch: 5| Step: 10
Training loss: 3.092454195022583
Validation loss: 2.4640739861355034

Epoch: 180| Step: 0
Training loss: 2.0754435062408447
Validation loss: 2.469795193723453

Epoch: 5| Step: 1
Training loss: 2.5687875747680664
Validation loss: 2.4710276460134857

Epoch: 5| Step: 2
Training loss: 3.388869047164917
Validation loss: 2.471122372534967

Epoch: 5| Step: 3
Training loss: 2.5341007709503174
Validation loss: 2.474234275920417

Epoch: 5| Step: 4
Training loss: 2.926237106323242
Validation loss: 2.4746049475926224

Epoch: 5| Step: 5
Training loss: 2.978071689605713
Validation loss: 2.479971367825744

Epoch: 5| Step: 6
Training loss: 3.0479485988616943
Validation loss: 2.4744746890119327

Epoch: 5| Step: 7
Training loss: 2.726191997528076
Validation loss: 2.478768753749068

Epoch: 5| Step: 8
Training loss: 1.864675760269165
Validation loss: 2.481925477263748

Epoch: 5| Step: 9
Training loss: 2.787635087966919
Validation loss: 2.4822780547603482

Epoch: 5| Step: 10
Training loss: 2.318375825881958
Validation loss: 2.4846132391242572

Epoch: 181| Step: 0
Training loss: 2.892698287963867
Validation loss: 2.487614475270753

Epoch: 5| Step: 1
Training loss: 3.1982614994049072
Validation loss: 2.480339865530691

Epoch: 5| Step: 2
Training loss: 2.4946811199188232
Validation loss: 2.4827712530730874

Epoch: 5| Step: 3
Training loss: 2.472954273223877
Validation loss: 2.486708774361559

Epoch: 5| Step: 4
Training loss: 3.3070411682128906
Validation loss: 2.4840054281296267

Epoch: 5| Step: 5
Training loss: 2.4621949195861816
Validation loss: 2.474548262934531

Epoch: 5| Step: 6
Training loss: 2.5735511779785156
Validation loss: 2.473592222377818

Epoch: 5| Step: 7
Training loss: 2.4794869422912598
Validation loss: 2.468358652566069

Epoch: 5| Step: 8
Training loss: 2.0524628162384033
Validation loss: 2.4720906416575112

Epoch: 5| Step: 9
Training loss: 2.8465511798858643
Validation loss: 2.4677981766321326

Epoch: 5| Step: 10
Training loss: 2.4576714038848877
Validation loss: 2.465634589554161

Epoch: 182| Step: 0
Training loss: 2.8771958351135254
Validation loss: 2.469171647102602

Epoch: 5| Step: 1
Training loss: 2.766378402709961
Validation loss: 2.471709023239792

Epoch: 5| Step: 2
Training loss: 3.234809160232544
Validation loss: 2.4707737917541177

Epoch: 5| Step: 3
Training loss: 3.0860962867736816
Validation loss: 2.4761480849276305

Epoch: 5| Step: 4
Training loss: 2.0144569873809814
Validation loss: 2.480880319431264

Epoch: 5| Step: 5
Training loss: 3.210953950881958
Validation loss: 2.4779223242113666

Epoch: 5| Step: 6
Training loss: 2.529747486114502
Validation loss: 2.4799924794063775

Epoch: 5| Step: 7
Training loss: 2.2979447841644287
Validation loss: 2.4790308501130793

Epoch: 5| Step: 8
Training loss: 2.9301676750183105
Validation loss: 2.4856137588459957

Epoch: 5| Step: 9
Training loss: 2.0578842163085938
Validation loss: 2.480848768705963

Epoch: 5| Step: 10
Training loss: 2.1422648429870605
Validation loss: 2.472061090571906

Epoch: 183| Step: 0
Training loss: 2.975538969039917
Validation loss: 2.4732508633726384

Epoch: 5| Step: 1
Training loss: 2.177272319793701
Validation loss: 2.4762260631848405

Epoch: 5| Step: 2
Training loss: 2.675009250640869
Validation loss: 2.4736174537289526

Epoch: 5| Step: 3
Training loss: 3.004380464553833
Validation loss: 2.472405643873317

Epoch: 5| Step: 4
Training loss: 2.5603785514831543
Validation loss: 2.4791776108485397

Epoch: 5| Step: 5
Training loss: 2.309617757797241
Validation loss: 2.474045204859908

Epoch: 5| Step: 6
Training loss: 2.914909839630127
Validation loss: 2.474553205633676

Epoch: 5| Step: 7
Training loss: 2.837549924850464
Validation loss: 2.4754727322568177

Epoch: 5| Step: 8
Training loss: 2.5445640087127686
Validation loss: 2.4758688711350962

Epoch: 5| Step: 9
Training loss: 3.2192840576171875
Validation loss: 2.4739521139411518

Epoch: 5| Step: 10
Training loss: 1.8558576107025146
Validation loss: 2.474866420991959

Epoch: 184| Step: 0
Training loss: 2.2648420333862305
Validation loss: 2.471594241357619

Epoch: 5| Step: 1
Training loss: 2.761849880218506
Validation loss: 2.4801975552753737

Epoch: 5| Step: 2
Training loss: 2.3947055339813232
Validation loss: 2.4856450044980614

Epoch: 5| Step: 3
Training loss: 2.3547253608703613
Validation loss: 2.492713448821857

Epoch: 5| Step: 4
Training loss: 2.64311146736145
Validation loss: 2.4975793720573507

Epoch: 5| Step: 5
Training loss: 2.455667018890381
Validation loss: 2.492472356365573

Epoch: 5| Step: 6
Training loss: 2.8687407970428467
Validation loss: 2.491705062568829

Epoch: 5| Step: 7
Training loss: 2.5447468757629395
Validation loss: 2.481196923922467

Epoch: 5| Step: 8
Training loss: 3.0448031425476074
Validation loss: 2.484374705181327

Epoch: 5| Step: 9
Training loss: 3.320791721343994
Validation loss: 2.482559186156078

Epoch: 5| Step: 10
Training loss: 2.4648189544677734
Validation loss: 2.4767146623262795

Epoch: 185| Step: 0
Training loss: 2.428229808807373
Validation loss: 2.4738911339031753

Epoch: 5| Step: 1
Training loss: 2.5306713581085205
Validation loss: 2.4732213379234396

Epoch: 5| Step: 2
Training loss: 2.277280569076538
Validation loss: 2.4681999926925986

Epoch: 5| Step: 3
Training loss: 3.325779676437378
Validation loss: 2.4687454162105436

Epoch: 5| Step: 4
Training loss: 2.757455348968506
Validation loss: 2.4633255350974297

Epoch: 5| Step: 5
Training loss: 1.5965890884399414
Validation loss: 2.464081388647838

Epoch: 5| Step: 6
Training loss: 2.939706325531006
Validation loss: 2.4692074021985455

Epoch: 5| Step: 7
Training loss: 2.781040906906128
Validation loss: 2.476074154658984

Epoch: 5| Step: 8
Training loss: 3.0087368488311768
Validation loss: 2.474066642022902

Epoch: 5| Step: 9
Training loss: 3.2089290618896484
Validation loss: 2.4767377812375306

Epoch: 5| Step: 10
Training loss: 2.2316482067108154
Validation loss: 2.467417250397385

Epoch: 186| Step: 0
Training loss: 3.0851547718048096
Validation loss: 2.462308604230163

Epoch: 5| Step: 1
Training loss: 2.7081196308135986
Validation loss: 2.4698886935428908

Epoch: 5| Step: 2
Training loss: 2.4023067951202393
Validation loss: 2.4633047196172897

Epoch: 5| Step: 3
Training loss: 2.741377830505371
Validation loss: 2.4631130797888643

Epoch: 5| Step: 4
Training loss: 2.38554048538208
Validation loss: 2.46533953502614

Epoch: 5| Step: 5
Training loss: 2.4248552322387695
Validation loss: 2.4678024066391813

Epoch: 5| Step: 6
Training loss: 3.0231595039367676
Validation loss: 2.4696133931477866

Epoch: 5| Step: 7
Training loss: 2.5079047679901123
Validation loss: 2.47346467356528

Epoch: 5| Step: 8
Training loss: 2.5024497509002686
Validation loss: 2.471358588946763

Epoch: 5| Step: 9
Training loss: 2.175966739654541
Validation loss: 2.481965828967351

Epoch: 5| Step: 10
Training loss: 3.2101099491119385
Validation loss: 2.486316752690141

Epoch: 187| Step: 0
Training loss: 2.725011110305786
Validation loss: 2.4726357152385097

Epoch: 5| Step: 1
Training loss: 2.3934428691864014
Validation loss: 2.479872913770778

Epoch: 5| Step: 2
Training loss: 2.8148245811462402
Validation loss: 2.4949971347726803

Epoch: 5| Step: 3
Training loss: 2.6120030879974365
Validation loss: 2.489282064540412

Epoch: 5| Step: 4
Training loss: 3.521496295928955
Validation loss: 2.489492457400086

Epoch: 5| Step: 5
Training loss: 2.8946032524108887
Validation loss: 2.4853475093841553

Epoch: 5| Step: 6
Training loss: 2.195249557495117
Validation loss: 2.479942073104202

Epoch: 5| Step: 7
Training loss: 2.0765011310577393
Validation loss: 2.477406788897771

Epoch: 5| Step: 8
Training loss: 2.86271071434021
Validation loss: 2.473368513968683

Epoch: 5| Step: 9
Training loss: 2.1167633533477783
Validation loss: 2.4745489602447837

Epoch: 5| Step: 10
Training loss: 2.9185729026794434
Validation loss: 2.4753520616921048

Epoch: 188| Step: 0
Training loss: 3.354351043701172
Validation loss: 2.4701539316485004

Epoch: 5| Step: 1
Training loss: 3.0078928470611572
Validation loss: 2.4781167635353665

Epoch: 5| Step: 2
Training loss: 2.6590142250061035
Validation loss: 2.4769491046987553

Epoch: 5| Step: 3
Training loss: 2.648402690887451
Validation loss: 2.482608849002469

Epoch: 5| Step: 4
Training loss: 2.856534242630005
Validation loss: 2.5006370980252504

Epoch: 5| Step: 5
Training loss: 2.266402244567871
Validation loss: 2.5026604001240065

Epoch: 5| Step: 6
Training loss: 2.8710203170776367
Validation loss: 2.5021003625726186

Epoch: 5| Step: 7
Training loss: 1.6504528522491455
Validation loss: 2.4985049847633607

Epoch: 5| Step: 8
Training loss: 3.0157570838928223
Validation loss: 2.4877478614930184

Epoch: 5| Step: 9
Training loss: 2.6747348308563232
Validation loss: 2.491210109444075

Epoch: 5| Step: 10
Training loss: 2.3109188079833984
Validation loss: 2.484049779112621

Epoch: 189| Step: 0
Training loss: 2.276949405670166
Validation loss: 2.477931796863515

Epoch: 5| Step: 1
Training loss: 3.1141104698181152
Validation loss: 2.4698248576092463

Epoch: 5| Step: 2
Training loss: 3.4242091178894043
Validation loss: 2.462030185166226

Epoch: 5| Step: 3
Training loss: 2.3923614025115967
Validation loss: 2.4553887126266316

Epoch: 5| Step: 4
Training loss: 2.6196818351745605
Validation loss: 2.4520126004372873

Epoch: 5| Step: 5
Training loss: 2.8525562286376953
Validation loss: 2.4522200117829027

Epoch: 5| Step: 6
Training loss: 2.4497196674346924
Validation loss: 2.450886849434145

Epoch: 5| Step: 7
Training loss: 2.448667287826538
Validation loss: 2.451105592071369

Epoch: 5| Step: 8
Training loss: 2.228095531463623
Validation loss: 2.4573095011454757

Epoch: 5| Step: 9
Training loss: 3.0363621711730957
Validation loss: 2.4536955741143998

Epoch: 5| Step: 10
Training loss: 2.1859867572784424
Validation loss: 2.4605950847748788

Epoch: 190| Step: 0
Training loss: 2.4296507835388184
Validation loss: 2.4580271884959233

Epoch: 5| Step: 1
Training loss: 3.00602388381958
Validation loss: 2.466141270053002

Epoch: 5| Step: 2
Training loss: 1.63614821434021
Validation loss: 2.4617816709703013

Epoch: 5| Step: 3
Training loss: 3.1290645599365234
Validation loss: 2.4735840956370034

Epoch: 5| Step: 4
Training loss: 2.8632302284240723
Validation loss: 2.477315354090865

Epoch: 5| Step: 5
Training loss: 2.6178269386291504
Validation loss: 2.4735243243555867

Epoch: 5| Step: 6
Training loss: 3.304669141769409
Validation loss: 2.4607574170635593

Epoch: 5| Step: 7
Training loss: 2.9800832271575928
Validation loss: 2.4695780661798294

Epoch: 5| Step: 8
Training loss: 2.4350314140319824
Validation loss: 2.4660584926605225

Epoch: 5| Step: 9
Training loss: 2.5337603092193604
Validation loss: 2.474518137593423

Epoch: 5| Step: 10
Training loss: 2.0502798557281494
Validation loss: 2.471051639126193

Epoch: 191| Step: 0
Training loss: 3.0670974254608154
Validation loss: 2.4729927560334564

Epoch: 5| Step: 1
Training loss: 2.7731781005859375
Validation loss: 2.4730964142789125

Epoch: 5| Step: 2
Training loss: 2.5615181922912598
Validation loss: 2.4747352677006877

Epoch: 5| Step: 3
Training loss: 2.896467685699463
Validation loss: 2.4720431540601995

Epoch: 5| Step: 4
Training loss: 2.362375020980835
Validation loss: 2.479244973069878

Epoch: 5| Step: 5
Training loss: 2.8776895999908447
Validation loss: 2.4657374940892702

Epoch: 5| Step: 6
Training loss: 2.574155330657959
Validation loss: 2.4735138647017942

Epoch: 5| Step: 7
Training loss: 1.9511514902114868
Validation loss: 2.4687772309908302

Epoch: 5| Step: 8
Training loss: 2.8877205848693848
Validation loss: 2.4782678593871412

Epoch: 5| Step: 9
Training loss: 2.44380521774292
Validation loss: 2.4777729511260986

Epoch: 5| Step: 10
Training loss: 2.65010404586792
Validation loss: 2.479117580639419

Epoch: 192| Step: 0
Training loss: 2.9340014457702637
Validation loss: 2.473856036381055

Epoch: 5| Step: 1
Training loss: 2.5490729808807373
Validation loss: 2.470574589185817

Epoch: 5| Step: 2
Training loss: 2.1634838581085205
Validation loss: 2.4636409321138935

Epoch: 5| Step: 3
Training loss: 2.8212890625
Validation loss: 2.4655536118374077

Epoch: 5| Step: 4
Training loss: 2.483225107192993
Validation loss: 2.4640090619364092

Epoch: 5| Step: 5
Training loss: 2.224367141723633
Validation loss: 2.4636129486945366

Epoch: 5| Step: 6
Training loss: 2.483586072921753
Validation loss: 2.466895757182952

Epoch: 5| Step: 7
Training loss: 2.650780200958252
Validation loss: 2.4589477021207093

Epoch: 5| Step: 8
Training loss: 3.6129374504089355
Validation loss: 2.4547639431491977

Epoch: 5| Step: 9
Training loss: 2.6977202892303467
Validation loss: 2.4584975396433184

Epoch: 5| Step: 10
Training loss: 2.3677258491516113
Validation loss: 2.4565980357508503

Epoch: 193| Step: 0
Training loss: 2.329603672027588
Validation loss: 2.453906592502389

Epoch: 5| Step: 1
Training loss: 3.123487710952759
Validation loss: 2.4584866467342583

Epoch: 5| Step: 2
Training loss: 3.0424370765686035
Validation loss: 2.456955499546502

Epoch: 5| Step: 3
Training loss: 3.152881383895874
Validation loss: 2.459783443840601

Epoch: 5| Step: 4
Training loss: 2.7962486743927
Validation loss: 2.4697298721600602

Epoch: 5| Step: 5
Training loss: 2.5915095806121826
Validation loss: 2.468286370718351

Epoch: 5| Step: 6
Training loss: 2.7906548976898193
Validation loss: 2.467035298706383

Epoch: 5| Step: 7
Training loss: 1.8923628330230713
Validation loss: 2.468124676776189

Epoch: 5| Step: 8
Training loss: 2.378333568572998
Validation loss: 2.4603274919653453

Epoch: 5| Step: 9
Training loss: 2.1259536743164062
Validation loss: 2.468262505787675

Epoch: 5| Step: 10
Training loss: 2.9314093589782715
Validation loss: 2.4656809735041794

Epoch: 194| Step: 0
Training loss: 2.628709554672241
Validation loss: 2.4604022810536046

Epoch: 5| Step: 1
Training loss: 3.148934841156006
Validation loss: 2.4607314909658125

Epoch: 5| Step: 2
Training loss: 2.693665027618408
Validation loss: 2.4579577651075137

Epoch: 5| Step: 3
Training loss: 2.2800776958465576
Validation loss: 2.4575380253535446

Epoch: 5| Step: 4
Training loss: 2.547266960144043
Validation loss: 2.4650130374457246

Epoch: 5| Step: 5
Training loss: 2.6304121017456055
Validation loss: 2.4610399379525134

Epoch: 5| Step: 6
Training loss: 3.07572865486145
Validation loss: 2.4580134960912887

Epoch: 5| Step: 7
Training loss: 2.743460178375244
Validation loss: 2.4589815883226294

Epoch: 5| Step: 8
Training loss: 2.7530617713928223
Validation loss: 2.4569147043330695

Epoch: 5| Step: 9
Training loss: 2.4611945152282715
Validation loss: 2.458121981672061

Epoch: 5| Step: 10
Training loss: 2.0120275020599365
Validation loss: 2.4584566803388697

Epoch: 195| Step: 0
Training loss: 2.2901668548583984
Validation loss: 2.4557951509311633

Epoch: 5| Step: 1
Training loss: 2.550487518310547
Validation loss: 2.4620983164797545

Epoch: 5| Step: 2
Training loss: 2.455169439315796
Validation loss: 2.4590174485278387

Epoch: 5| Step: 3
Training loss: 2.003491163253784
Validation loss: 2.4623005697804112

Epoch: 5| Step: 4
Training loss: 2.191453218460083
Validation loss: 2.458766588600733

Epoch: 5| Step: 5
Training loss: 3.145899772644043
Validation loss: 2.45476540442436

Epoch: 5| Step: 6
Training loss: 3.165095806121826
Validation loss: 2.463314346087876

Epoch: 5| Step: 7
Training loss: 2.2635693550109863
Validation loss: 2.4643573555895077

Epoch: 5| Step: 8
Training loss: 3.4740777015686035
Validation loss: 2.4672862688700357

Epoch: 5| Step: 9
Training loss: 2.6627395153045654
Validation loss: 2.4571380769052813

Epoch: 5| Step: 10
Training loss: 2.8216190338134766
Validation loss: 2.459171220820437

Epoch: 196| Step: 0
Training loss: 3.4152073860168457
Validation loss: 2.4537495464406986

Epoch: 5| Step: 1
Training loss: 2.697453022003174
Validation loss: 2.4547160184511574

Epoch: 5| Step: 2
Training loss: 2.9872663021087646
Validation loss: 2.4571556147708686

Epoch: 5| Step: 3
Training loss: 2.6140332221984863
Validation loss: 2.466532379068354

Epoch: 5| Step: 4
Training loss: 3.140129566192627
Validation loss: 2.459527031067879

Epoch: 5| Step: 5
Training loss: 2.214562177658081
Validation loss: 2.464145509145593

Epoch: 5| Step: 6
Training loss: 2.380885362625122
Validation loss: 2.4593468366130704

Epoch: 5| Step: 7
Training loss: 2.1332576274871826
Validation loss: 2.464413112209689

Epoch: 5| Step: 8
Training loss: 2.7320430278778076
Validation loss: 2.470680329107469

Epoch: 5| Step: 9
Training loss: 2.679055690765381
Validation loss: 2.463084590050482

Epoch: 5| Step: 10
Training loss: 1.8417181968688965
Validation loss: 2.46088937277435

Epoch: 197| Step: 0
Training loss: 2.5867457389831543
Validation loss: 2.474837198052355

Epoch: 5| Step: 1
Training loss: 2.227724552154541
Validation loss: 2.4636885632750807

Epoch: 5| Step: 2
Training loss: 2.0076651573181152
Validation loss: 2.470496836528983

Epoch: 5| Step: 3
Training loss: 2.5931472778320312
Validation loss: 2.470867705601518

Epoch: 5| Step: 4
Training loss: 2.222501277923584
Validation loss: 2.471287550464753

Epoch: 5| Step: 5
Training loss: 2.65425181388855
Validation loss: 2.4667282540311097

Epoch: 5| Step: 6
Training loss: 2.8678042888641357
Validation loss: 2.471129166182651

Epoch: 5| Step: 7
Training loss: 3.1573996543884277
Validation loss: 2.46438261770433

Epoch: 5| Step: 8
Training loss: 3.0314197540283203
Validation loss: 2.458056599863114

Epoch: 5| Step: 9
Training loss: 2.9953231811523438
Validation loss: 2.4556235626179683

Epoch: 5| Step: 10
Training loss: 2.5919926166534424
Validation loss: 2.4582707933200303

Epoch: 198| Step: 0
Training loss: 2.664659023284912
Validation loss: 2.4620263115052254

Epoch: 5| Step: 1
Training loss: 2.853851318359375
Validation loss: 2.4591986620297996

Epoch: 5| Step: 2
Training loss: 2.725295066833496
Validation loss: 2.4687007216997046

Epoch: 5| Step: 3
Training loss: 2.256204128265381
Validation loss: 2.4635888120179534

Epoch: 5| Step: 4
Training loss: 3.1444733142852783
Validation loss: 2.475287937348889

Epoch: 5| Step: 5
Training loss: 3.3023979663848877
Validation loss: 2.4708821850438274

Epoch: 5| Step: 6
Training loss: 2.6811256408691406
Validation loss: 2.468904476011953

Epoch: 5| Step: 7
Training loss: 2.2972068786621094
Validation loss: 2.45596662388053

Epoch: 5| Step: 8
Training loss: 2.3378374576568604
Validation loss: 2.4617496639169674

Epoch: 5| Step: 9
Training loss: 2.4498767852783203
Validation loss: 2.4573082436797438

Epoch: 5| Step: 10
Training loss: 2.193624496459961
Validation loss: 2.4553611252897527

Epoch: 199| Step: 0
Training loss: 2.678251266479492
Validation loss: 2.450478333298878

Epoch: 5| Step: 1
Training loss: 2.1363015174865723
Validation loss: 2.4507831142794703

Epoch: 5| Step: 2
Training loss: 2.604835271835327
Validation loss: 2.451481710198105

Epoch: 5| Step: 3
Training loss: 2.568739891052246
Validation loss: 2.454422266252579

Epoch: 5| Step: 4
Training loss: 2.6582131385803223
Validation loss: 2.4467467108080463

Epoch: 5| Step: 5
Training loss: 2.4153900146484375
Validation loss: 2.451922526923559

Epoch: 5| Step: 6
Training loss: 2.513813018798828
Validation loss: 2.4458023860890377

Epoch: 5| Step: 7
Training loss: 3.3313915729522705
Validation loss: 2.4492829538160756

Epoch: 5| Step: 8
Training loss: 2.5199267864227295
Validation loss: 2.4486719639070573

Epoch: 5| Step: 9
Training loss: 2.472543239593506
Validation loss: 2.4400553934035765

Epoch: 5| Step: 10
Training loss: 3.246981382369995
Validation loss: 2.443155783478932

Epoch: 200| Step: 0
Training loss: 2.4259567260742188
Validation loss: 2.4408958188949095

Epoch: 5| Step: 1
Training loss: 2.5541305541992188
Validation loss: 2.439968001457953

Epoch: 5| Step: 2
Training loss: 3.069287061691284
Validation loss: 2.4420399653014315

Epoch: 5| Step: 3
Training loss: 3.1616499423980713
Validation loss: 2.442655655645555

Epoch: 5| Step: 4
Training loss: 2.6949198246002197
Validation loss: 2.4440970702837874

Epoch: 5| Step: 5
Training loss: 2.8054332733154297
Validation loss: 2.445128874112201

Epoch: 5| Step: 6
Training loss: 1.8475024700164795
Validation loss: 2.445001345808788

Epoch: 5| Step: 7
Training loss: 2.3939669132232666
Validation loss: 2.452279249827067

Epoch: 5| Step: 8
Training loss: 2.426281452178955
Validation loss: 2.44998150743464

Epoch: 5| Step: 9
Training loss: 2.8244166374206543
Validation loss: 2.444063635282619

Epoch: 5| Step: 10
Training loss: 2.9354915618896484
Validation loss: 2.4463502463474067

Epoch: 201| Step: 0
Training loss: 2.781985282897949
Validation loss: 2.442259091202931

Epoch: 5| Step: 1
Training loss: 2.5148987770080566
Validation loss: 2.4475011107742146

Epoch: 5| Step: 2
Training loss: 2.868546962738037
Validation loss: 2.438964186176177

Epoch: 5| Step: 3
Training loss: 1.8691043853759766
Validation loss: 2.4373430641748572

Epoch: 5| Step: 4
Training loss: 2.221174716949463
Validation loss: 2.4333228859850156

Epoch: 5| Step: 5
Training loss: 2.5037176609039307
Validation loss: 2.440597800798314

Epoch: 5| Step: 6
Training loss: 2.951183795928955
Validation loss: 2.441545912014541

Epoch: 5| Step: 7
Training loss: 3.2588858604431152
Validation loss: 2.4448710026279574

Epoch: 5| Step: 8
Training loss: 2.7533421516418457
Validation loss: 2.4442096602532173

Epoch: 5| Step: 9
Training loss: 2.3717901706695557
Validation loss: 2.4446207143927134

Epoch: 5| Step: 10
Training loss: 3.0097031593322754
Validation loss: 2.447535619940809

Epoch: 202| Step: 0
Training loss: 2.39532208442688
Validation loss: 2.4480588615581556

Epoch: 5| Step: 1
Training loss: 3.1229453086853027
Validation loss: 2.452374214767128

Epoch: 5| Step: 2
Training loss: 2.650336742401123
Validation loss: 2.4479348838970227

Epoch: 5| Step: 3
Training loss: 2.4461066722869873
Validation loss: 2.447561196101609

Epoch: 5| Step: 4
Training loss: 2.663130760192871
Validation loss: 2.4436565214587795

Epoch: 5| Step: 5
Training loss: 2.9925143718719482
Validation loss: 2.4463270402723745

Epoch: 5| Step: 6
Training loss: 2.50433087348938
Validation loss: 2.4396334463550198

Epoch: 5| Step: 7
Training loss: 2.882262706756592
Validation loss: 2.4425621391624532

Epoch: 5| Step: 8
Training loss: 2.4432148933410645
Validation loss: 2.4432688938674105

Epoch: 5| Step: 9
Training loss: 2.2283923625946045
Validation loss: 2.4422133199630247

Epoch: 5| Step: 10
Training loss: 2.6078898906707764
Validation loss: 2.438604680440759

Epoch: 203| Step: 0
Training loss: 3.2077858448028564
Validation loss: 2.44218708110112

Epoch: 5| Step: 1
Training loss: 2.9808313846588135
Validation loss: 2.438038000496485

Epoch: 5| Step: 2
Training loss: 2.4036061763763428
Validation loss: 2.441234568113922

Epoch: 5| Step: 3
Training loss: 2.2722487449645996
Validation loss: 2.4395883467889603

Epoch: 5| Step: 4
Training loss: 1.9452918767929077
Validation loss: 2.439931495215303

Epoch: 5| Step: 5
Training loss: 2.8740506172180176
Validation loss: 2.4552762482755925

Epoch: 5| Step: 6
Training loss: 2.6092281341552734
Validation loss: 2.452082944172685

Epoch: 5| Step: 7
Training loss: 3.1924283504486084
Validation loss: 2.4524839872954995

Epoch: 5| Step: 8
Training loss: 2.728023052215576
Validation loss: 2.454493018888658

Epoch: 5| Step: 9
Training loss: 3.0774197578430176
Validation loss: 2.4553613688356135

Epoch: 5| Step: 10
Training loss: 1.515666127204895
Validation loss: 2.456396923270277

Epoch: 204| Step: 0
Training loss: 2.4427123069763184
Validation loss: 2.453805249224427

Epoch: 5| Step: 1
Training loss: 2.5340707302093506
Validation loss: 2.445276609031103

Epoch: 5| Step: 2
Training loss: 2.4928650856018066
Validation loss: 2.4435339025271836

Epoch: 5| Step: 3
Training loss: 2.978236436843872
Validation loss: 2.441627508850508

Epoch: 5| Step: 4
Training loss: 2.780299663543701
Validation loss: 2.447779502919925

Epoch: 5| Step: 5
Training loss: 2.2678301334381104
Validation loss: 2.444704750532745

Epoch: 5| Step: 6
Training loss: 2.1695396900177
Validation loss: 2.448845307032267

Epoch: 5| Step: 7
Training loss: 2.7205023765563965
Validation loss: 2.448416917554794

Epoch: 5| Step: 8
Training loss: 2.5221660137176514
Validation loss: 2.4470199205542125

Epoch: 5| Step: 9
Training loss: 2.8541579246520996
Validation loss: 2.44474785558639

Epoch: 5| Step: 10
Training loss: 3.206974983215332
Validation loss: 2.4559617862906507

Epoch: 205| Step: 0
Training loss: 2.623145580291748
Validation loss: 2.447638548830504

Epoch: 5| Step: 1
Training loss: 2.657592296600342
Validation loss: 2.4528567790985107

Epoch: 5| Step: 2
Training loss: 2.552489757537842
Validation loss: 2.444925897864885

Epoch: 5| Step: 3
Training loss: 2.906165599822998
Validation loss: 2.4518826443661927

Epoch: 5| Step: 4
Training loss: 2.7185356616973877
Validation loss: 2.44024553350223

Epoch: 5| Step: 5
Training loss: 2.890179395675659
Validation loss: 2.449992367016372

Epoch: 5| Step: 6
Training loss: 2.9169013500213623
Validation loss: 2.456119760390251

Epoch: 5| Step: 7
Training loss: 1.953690767288208
Validation loss: 2.4489923318227134

Epoch: 5| Step: 8
Training loss: 2.808450222015381
Validation loss: 2.450008189806374

Epoch: 5| Step: 9
Training loss: 2.7414095401763916
Validation loss: 2.4506019187229935

Epoch: 5| Step: 10
Training loss: 2.060209035873413
Validation loss: 2.4534654463491132

Epoch: 206| Step: 0
Training loss: 1.6807518005371094
Validation loss: 2.4585454130685456

Epoch: 5| Step: 1
Training loss: 2.60667085647583
Validation loss: 2.4578344950111966

Epoch: 5| Step: 2
Training loss: 2.085271120071411
Validation loss: 2.4629890406003563

Epoch: 5| Step: 3
Training loss: 2.6125643253326416
Validation loss: 2.464967650751914

Epoch: 5| Step: 4
Training loss: 2.783247232437134
Validation loss: 2.4456228338262087

Epoch: 5| Step: 5
Training loss: 3.6534523963928223
Validation loss: 2.442416685883717

Epoch: 5| Step: 6
Training loss: 2.870331048965454
Validation loss: 2.437432978742866

Epoch: 5| Step: 7
Training loss: 3.5454678535461426
Validation loss: 2.431646223991148

Epoch: 5| Step: 8
Training loss: 2.079444408416748
Validation loss: 2.4270556972872828

Epoch: 5| Step: 9
Training loss: 2.5860791206359863
Validation loss: 2.427616832076862

Epoch: 5| Step: 10
Training loss: 2.5316011905670166
Validation loss: 2.427714878512967

Epoch: 207| Step: 0
Training loss: 3.2357897758483887
Validation loss: 2.4271624985561577

Epoch: 5| Step: 1
Training loss: 2.7235121726989746
Validation loss: 2.4345241003139044

Epoch: 5| Step: 2
Training loss: 2.7616946697235107
Validation loss: 2.4278395714298373

Epoch: 5| Step: 3
Training loss: 2.5862059593200684
Validation loss: 2.430749547096991

Epoch: 5| Step: 4
Training loss: 2.3949484825134277
Validation loss: 2.4360301802235265

Epoch: 5| Step: 5
Training loss: 2.912876844406128
Validation loss: 2.4327839010505268

Epoch: 5| Step: 6
Training loss: 2.6996116638183594
Validation loss: 2.4369613329569497

Epoch: 5| Step: 7
Training loss: 2.8222031593322754
Validation loss: 2.438149457336754

Epoch: 5| Step: 8
Training loss: 2.042168140411377
Validation loss: 2.436695416768392

Epoch: 5| Step: 9
Training loss: 2.024505615234375
Validation loss: 2.442138159146873

Epoch: 5| Step: 10
Training loss: 2.811716079711914
Validation loss: 2.435340917238625

Epoch: 208| Step: 0
Training loss: 2.925541639328003
Validation loss: 2.4404665013795257

Epoch: 5| Step: 1
Training loss: 2.5672080516815186
Validation loss: 2.431312758435485

Epoch: 5| Step: 2
Training loss: 2.6045868396759033
Validation loss: 2.443192974213631

Epoch: 5| Step: 3
Training loss: 2.700446367263794
Validation loss: 2.443329780332504

Epoch: 5| Step: 4
Training loss: 2.047697067260742
Validation loss: 2.4452428010202225

Epoch: 5| Step: 5
Training loss: 2.4000985622406006
Validation loss: 2.4496333573454168

Epoch: 5| Step: 6
Training loss: 3.3452064990997314
Validation loss: 2.448220952864616

Epoch: 5| Step: 7
Training loss: 2.435922145843506
Validation loss: 2.4448765734190583

Epoch: 5| Step: 8
Training loss: 2.4067275524139404
Validation loss: 2.4458026142530542

Epoch: 5| Step: 9
Training loss: 2.999262571334839
Validation loss: 2.446927175726942

Epoch: 5| Step: 10
Training loss: 2.3340682983398438
Validation loss: 2.456823146471413

Epoch: 209| Step: 0
Training loss: 2.264397621154785
Validation loss: 2.4507063947698122

Epoch: 5| Step: 1
Training loss: 3.5799789428710938
Validation loss: 2.443532174633395

Epoch: 5| Step: 2
Training loss: 2.2511391639709473
Validation loss: 2.432872044142856

Epoch: 5| Step: 3
Training loss: 2.7342593669891357
Validation loss: 2.427220021524737

Epoch: 5| Step: 4
Training loss: 2.050745725631714
Validation loss: 2.424547685089932

Epoch: 5| Step: 5
Training loss: 2.7217276096343994
Validation loss: 2.4252828346785678

Epoch: 5| Step: 6
Training loss: 2.4923977851867676
Validation loss: 2.4269557486298265

Epoch: 5| Step: 7
Training loss: 3.0023090839385986
Validation loss: 2.4239265431639967

Epoch: 5| Step: 8
Training loss: 2.788890838623047
Validation loss: 2.429939341801469

Epoch: 5| Step: 9
Training loss: 2.385336399078369
Validation loss: 2.4285254657909436

Epoch: 5| Step: 10
Training loss: 2.5779542922973633
Validation loss: 2.4308554767280497

Epoch: 210| Step: 0
Training loss: 2.01359224319458
Validation loss: 2.4257076145500265

Epoch: 5| Step: 1
Training loss: 2.5315842628479004
Validation loss: 2.4239467779795327

Epoch: 5| Step: 2
Training loss: 3.1560373306274414
Validation loss: 2.4214297956035984

Epoch: 5| Step: 3
Training loss: 2.6290836334228516
Validation loss: 2.428496147996636

Epoch: 5| Step: 4
Training loss: 2.635601758956909
Validation loss: 2.4220229951284264

Epoch: 5| Step: 5
Training loss: 1.6862179040908813
Validation loss: 2.4223773992189797

Epoch: 5| Step: 6
Training loss: 2.6384825706481934
Validation loss: 2.4255467896820395

Epoch: 5| Step: 7
Training loss: 2.6536552906036377
Validation loss: 2.435573729135657

Epoch: 5| Step: 8
Training loss: 2.705648899078369
Validation loss: 2.431103526905019

Epoch: 5| Step: 9
Training loss: 2.3981411457061768
Validation loss: 2.4414865098973757

Epoch: 5| Step: 10
Training loss: 3.9721012115478516
Validation loss: 2.4483205092850553

Epoch: 211| Step: 0
Training loss: 3.072861909866333
Validation loss: 2.4519292487893054

Epoch: 5| Step: 1
Training loss: 2.4872894287109375
Validation loss: 2.44868867628036

Epoch: 5| Step: 2
Training loss: 2.948808431625366
Validation loss: 2.4494721389585927

Epoch: 5| Step: 3
Training loss: 2.9857394695281982
Validation loss: 2.4379676362519622

Epoch: 5| Step: 4
Training loss: 2.7477757930755615
Validation loss: 2.4403559905226513

Epoch: 5| Step: 5
Training loss: 2.4239907264709473
Validation loss: 2.434594308176348

Epoch: 5| Step: 6
Training loss: 2.4728469848632812
Validation loss: 2.4256116702992427

Epoch: 5| Step: 7
Training loss: 2.0289266109466553
Validation loss: 2.4236516491059334

Epoch: 5| Step: 8
Training loss: 3.133267879486084
Validation loss: 2.4281720884384645

Epoch: 5| Step: 9
Training loss: 2.116325855255127
Validation loss: 2.426374363642867

Epoch: 5| Step: 10
Training loss: 2.4463326930999756
Validation loss: 2.4310536282036894

Epoch: 212| Step: 0
Training loss: 2.1977899074554443
Validation loss: 2.4383797825023694

Epoch: 5| Step: 1
Training loss: 2.878572463989258
Validation loss: 2.437060445867559

Epoch: 5| Step: 2
Training loss: 2.6288559436798096
Validation loss: 2.439751107205627

Epoch: 5| Step: 3
Training loss: 3.225130558013916
Validation loss: 2.4317813714345298

Epoch: 5| Step: 4
Training loss: 2.1611218452453613
Validation loss: 2.426580024021928

Epoch: 5| Step: 5
Training loss: 2.7771687507629395
Validation loss: 2.42884051158864

Epoch: 5| Step: 6
Training loss: 2.557931423187256
Validation loss: 2.41741967585779

Epoch: 5| Step: 7
Training loss: 2.5641255378723145
Validation loss: 2.4131500490250124

Epoch: 5| Step: 8
Training loss: 3.056760311126709
Validation loss: 2.4172188210231003

Epoch: 5| Step: 9
Training loss: 2.847604751586914
Validation loss: 2.415194667795653

Epoch: 5| Step: 10
Training loss: 2.0110647678375244
Validation loss: 2.412652031067879

Epoch: 213| Step: 0
Training loss: 3.0708069801330566
Validation loss: 2.4159816670161423

Epoch: 5| Step: 1
Training loss: 2.8344924449920654
Validation loss: 2.4171299678023144

Epoch: 5| Step: 2
Training loss: 2.565891981124878
Validation loss: 2.4179679783441688

Epoch: 5| Step: 3
Training loss: 2.7141644954681396
Validation loss: 2.415591004074261

Epoch: 5| Step: 4
Training loss: 2.822974681854248
Validation loss: 2.4177891233915925

Epoch: 5| Step: 5
Training loss: 2.1856939792633057
Validation loss: 2.4207047365045034

Epoch: 5| Step: 6
Training loss: 2.7759804725646973
Validation loss: 2.4251315196355185

Epoch: 5| Step: 7
Training loss: 2.400672674179077
Validation loss: 2.4242476570990776

Epoch: 5| Step: 8
Training loss: 2.716641902923584
Validation loss: 2.421569390963483

Epoch: 5| Step: 9
Training loss: 2.298316717147827
Validation loss: 2.4275522078237226

Epoch: 5| Step: 10
Training loss: 2.4181885719299316
Validation loss: 2.4241593396791847

Epoch: 214| Step: 0
Training loss: 2.5193562507629395
Validation loss: 2.4289772151618876

Epoch: 5| Step: 1
Training loss: 3.2273857593536377
Validation loss: 2.4259537522510817

Epoch: 5| Step: 2
Training loss: 2.419847011566162
Validation loss: 2.4305893580118814

Epoch: 5| Step: 3
Training loss: 2.8396239280700684
Validation loss: 2.428028198980516

Epoch: 5| Step: 4
Training loss: 2.773151159286499
Validation loss: 2.427457271083709

Epoch: 5| Step: 5
Training loss: 2.814659357070923
Validation loss: 2.425465768383395

Epoch: 5| Step: 6
Training loss: 2.7379469871520996
Validation loss: 2.4266903015875045

Epoch: 5| Step: 7
Training loss: 2.5948233604431152
Validation loss: 2.422592962941816

Epoch: 5| Step: 8
Training loss: 2.721219778060913
Validation loss: 2.42346550315939

Epoch: 5| Step: 9
Training loss: 1.6599578857421875
Validation loss: 2.42644642501749

Epoch: 5| Step: 10
Training loss: 2.45440411567688
Validation loss: 2.426315211480664

Epoch: 215| Step: 0
Training loss: 2.0175156593322754
Validation loss: 2.4295367207578433

Epoch: 5| Step: 1
Training loss: 2.126354694366455
Validation loss: 2.43116952783318

Epoch: 5| Step: 2
Training loss: 3.427015781402588
Validation loss: 2.445852202753867

Epoch: 5| Step: 3
Training loss: 2.440464496612549
Validation loss: 2.4415317402091077

Epoch: 5| Step: 4
Training loss: 3.269087314605713
Validation loss: 2.4432404041290283

Epoch: 5| Step: 5
Training loss: 3.0194249153137207
Validation loss: 2.449886873204221

Epoch: 5| Step: 6
Training loss: 2.594113826751709
Validation loss: 2.448111839191888

Epoch: 5| Step: 7
Training loss: 2.096224069595337
Validation loss: 2.436624662850493

Epoch: 5| Step: 8
Training loss: 2.240530490875244
Validation loss: 2.439655298827797

Epoch: 5| Step: 9
Training loss: 2.3820621967315674
Validation loss: 2.4306386978395524

Epoch: 5| Step: 10
Training loss: 3.248183488845825
Validation loss: 2.435499986012777

Epoch: 216| Step: 0
Training loss: 2.408651351928711
Validation loss: 2.430429140726725

Epoch: 5| Step: 1
Training loss: 2.8689396381378174
Validation loss: 2.4209755697558

Epoch: 5| Step: 2
Training loss: 2.7244136333465576
Validation loss: 2.4308103720347085

Epoch: 5| Step: 3
Training loss: 2.05007266998291
Validation loss: 2.4354170291654524

Epoch: 5| Step: 4
Training loss: 2.3897364139556885
Validation loss: 2.4331625687178744

Epoch: 5| Step: 5
Training loss: 2.7911481857299805
Validation loss: 2.436194642897575

Epoch: 5| Step: 6
Training loss: 2.6689839363098145
Validation loss: 2.434261998822612

Epoch: 5| Step: 7
Training loss: 2.7656168937683105
Validation loss: 2.435167476695071

Epoch: 5| Step: 8
Training loss: 2.807349681854248
Validation loss: 2.4363406114680792

Epoch: 5| Step: 9
Training loss: 2.9332690238952637
Validation loss: 2.437315517856229

Epoch: 5| Step: 10
Training loss: 2.2593746185302734
Validation loss: 2.4365780122818483

Epoch: 217| Step: 0
Training loss: 2.9008841514587402
Validation loss: 2.4322808557941067

Epoch: 5| Step: 1
Training loss: 2.3772270679473877
Validation loss: 2.4325493163959955

Epoch: 5| Step: 2
Training loss: 2.4887661933898926
Validation loss: 2.427517757620863

Epoch: 5| Step: 3
Training loss: 2.2542903423309326
Validation loss: 2.424005280258835

Epoch: 5| Step: 4
Training loss: 2.104377031326294
Validation loss: 2.4203583578909598

Epoch: 5| Step: 5
Training loss: 2.550380229949951
Validation loss: 2.419321011471492

Epoch: 5| Step: 6
Training loss: 3.177969455718994
Validation loss: 2.41631979198866

Epoch: 5| Step: 7
Training loss: 2.5127952098846436
Validation loss: 2.4191055118396716

Epoch: 5| Step: 8
Training loss: 2.225099802017212
Validation loss: 2.420644810122828

Epoch: 5| Step: 9
Training loss: 3.0695114135742188
Validation loss: 2.419627207581715

Epoch: 5| Step: 10
Training loss: 3.159508228302002
Validation loss: 2.4305295328940115

Epoch: 218| Step: 0
Training loss: 3.2271652221679688
Validation loss: 2.430845627220728

Epoch: 5| Step: 1
Training loss: 2.334226369857788
Validation loss: 2.4256344533735708

Epoch: 5| Step: 2
Training loss: 2.8913028240203857
Validation loss: 2.425796462643531

Epoch: 5| Step: 3
Training loss: 1.93767511844635
Validation loss: 2.4212340821502027

Epoch: 5| Step: 4
Training loss: 2.588156223297119
Validation loss: 2.4210369920217865

Epoch: 5| Step: 5
Training loss: 2.8411285877227783
Validation loss: 2.4169690480796238

Epoch: 5| Step: 6
Training loss: 2.782392978668213
Validation loss: 2.4155143717283845

Epoch: 5| Step: 7
Training loss: 2.7236430644989014
Validation loss: 2.411873035533454

Epoch: 5| Step: 8
Training loss: 2.672515392303467
Validation loss: 2.4155221933959634

Epoch: 5| Step: 9
Training loss: 2.1940629482269287
Validation loss: 2.4176757976573002

Epoch: 5| Step: 10
Training loss: 2.4463515281677246
Validation loss: 2.4117812520714215

Epoch: 219| Step: 0
Training loss: 2.5028836727142334
Validation loss: 2.415179814061811

Epoch: 5| Step: 1
Training loss: 3.225302219390869
Validation loss: 2.417813757414459

Epoch: 5| Step: 2
Training loss: 1.729377031326294
Validation loss: 2.4197410319441106

Epoch: 5| Step: 3
Training loss: 3.056119203567505
Validation loss: 2.427079475054177

Epoch: 5| Step: 4
Training loss: 2.7688636779785156
Validation loss: 2.417460133952479

Epoch: 5| Step: 5
Training loss: 2.4014010429382324
Validation loss: 2.432707719905402

Epoch: 5| Step: 6
Training loss: 2.4403958320617676
Validation loss: 2.428193897329351

Epoch: 5| Step: 7
Training loss: 2.8495965003967285
Validation loss: 2.4319269311043525

Epoch: 5| Step: 8
Training loss: 2.572910785675049
Validation loss: 2.437886361152895

Epoch: 5| Step: 9
Training loss: 2.814563035964966
Validation loss: 2.4436669247124785

Epoch: 5| Step: 10
Training loss: 2.385843515396118
Validation loss: 2.4453466169295774

Epoch: 220| Step: 0
Training loss: 1.7847802639007568
Validation loss: 2.4438726671280397

Epoch: 5| Step: 1
Training loss: 2.2755589485168457
Validation loss: 2.43809405449898

Epoch: 5| Step: 2
Training loss: 2.9294676780700684
Validation loss: 2.4386587142944336

Epoch: 5| Step: 3
Training loss: 2.2915287017822266
Validation loss: 2.4374880688164824

Epoch: 5| Step: 4
Training loss: 2.118152618408203
Validation loss: 2.435292213193832

Epoch: 5| Step: 5
Training loss: 2.7865917682647705
Validation loss: 2.4301134360733854

Epoch: 5| Step: 6
Training loss: 3.0683984756469727
Validation loss: 2.4247328440348306

Epoch: 5| Step: 7
Training loss: 2.655297040939331
Validation loss: 2.420341104589483

Epoch: 5| Step: 8
Training loss: 2.7816810607910156
Validation loss: 2.4160884323940484

Epoch: 5| Step: 9
Training loss: 2.846306562423706
Validation loss: 2.409281956252231

Epoch: 5| Step: 10
Training loss: 3.335698366165161
Validation loss: 2.407779421857608

Epoch: 221| Step: 0
Training loss: 2.080076217651367
Validation loss: 2.4040952215912523

Epoch: 5| Step: 1
Training loss: 2.4822869300842285
Validation loss: 2.4099821147098335

Epoch: 5| Step: 2
Training loss: 3.0716025829315186
Validation loss: 2.412946939468384

Epoch: 5| Step: 3
Training loss: 2.7713475227355957
Validation loss: 2.4215107348657425

Epoch: 5| Step: 4
Training loss: 2.1019771099090576
Validation loss: 2.4235167323902087

Epoch: 5| Step: 5
Training loss: 3.4177699089050293
Validation loss: 2.418548991603236

Epoch: 5| Step: 6
Training loss: 2.7036051750183105
Validation loss: 2.4138987602726107

Epoch: 5| Step: 7
Training loss: 3.1741631031036377
Validation loss: 2.4117778552475797

Epoch: 5| Step: 8
Training loss: 2.630026340484619
Validation loss: 2.4119348090182067

Epoch: 5| Step: 9
Training loss: 2.1210544109344482
Validation loss: 2.407387051531064

Epoch: 5| Step: 10
Training loss: 2.134507179260254
Validation loss: 2.4043104597317275

Epoch: 222| Step: 0
Training loss: 2.767275333404541
Validation loss: 2.4040757225405787

Epoch: 5| Step: 1
Training loss: 2.673813581466675
Validation loss: 2.40302259947664

Epoch: 5| Step: 2
Training loss: 2.997699499130249
Validation loss: 2.403868334267729

Epoch: 5| Step: 3
Training loss: 3.073669672012329
Validation loss: 2.40084828868989

Epoch: 5| Step: 4
Training loss: 2.3359484672546387
Validation loss: 2.4040810523494596

Epoch: 5| Step: 5
Training loss: 1.8687984943389893
Validation loss: 2.4075266622727916

Epoch: 5| Step: 6
Training loss: 2.5293502807617188
Validation loss: 2.4071728849923737

Epoch: 5| Step: 7
Training loss: 2.884829044342041
Validation loss: 2.4083661674171366

Epoch: 5| Step: 8
Training loss: 2.1885294914245605
Validation loss: 2.4139260732999412

Epoch: 5| Step: 9
Training loss: 2.738513231277466
Validation loss: 2.4239545458106586

Epoch: 5| Step: 10
Training loss: 2.6314988136291504
Validation loss: 2.4256582260131836

Epoch: 223| Step: 0
Training loss: 1.9223411083221436
Validation loss: 2.429462968662221

Epoch: 5| Step: 1
Training loss: 2.5586514472961426
Validation loss: 2.4342812056182535

Epoch: 5| Step: 2
Training loss: 2.341212749481201
Validation loss: 2.4260000964646697

Epoch: 5| Step: 3
Training loss: 2.356882095336914
Validation loss: 2.416760670241489

Epoch: 5| Step: 4
Training loss: 3.067476749420166
Validation loss: 2.4185982083761566

Epoch: 5| Step: 5
Training loss: 2.4363503456115723
Validation loss: 2.413387034528999

Epoch: 5| Step: 6
Training loss: 2.5249075889587402
Validation loss: 2.4140431009313112

Epoch: 5| Step: 7
Training loss: 3.166877269744873
Validation loss: 2.405289557672316

Epoch: 5| Step: 8
Training loss: 2.945343255996704
Validation loss: 2.412868609992407

Epoch: 5| Step: 9
Training loss: 3.0200035572052
Validation loss: 2.406106759143132

Epoch: 5| Step: 10
Training loss: 2.2745473384857178
Validation loss: 2.406105374777189

Epoch: 224| Step: 0
Training loss: 2.844449520111084
Validation loss: 2.4136883187037643

Epoch: 5| Step: 1
Training loss: 2.7619118690490723
Validation loss: 2.4033101809922086

Epoch: 5| Step: 2
Training loss: 2.150428533554077
Validation loss: 2.4109304899810464

Epoch: 5| Step: 3
Training loss: 2.713959217071533
Validation loss: 2.410075221010434

Epoch: 5| Step: 4
Training loss: 2.441997766494751
Validation loss: 2.4065045310604956

Epoch: 5| Step: 5
Training loss: 2.8618016242980957
Validation loss: 2.4088638110827376

Epoch: 5| Step: 6
Training loss: 2.7445309162139893
Validation loss: 2.4032059587458128

Epoch: 5| Step: 7
Training loss: 2.706122636795044
Validation loss: 2.3984002195378786

Epoch: 5| Step: 8
Training loss: 2.2611780166625977
Validation loss: 2.4000141133544264

Epoch: 5| Step: 9
Training loss: 2.4189467430114746
Validation loss: 2.4062380970165296

Epoch: 5| Step: 10
Training loss: 2.8345983028411865
Validation loss: 2.4029921716259373

Epoch: 225| Step: 0
Training loss: 2.129545211791992
Validation loss: 2.405151108259796

Epoch: 5| Step: 1
Training loss: 2.478572368621826
Validation loss: 2.4042599739566928

Epoch: 5| Step: 2
Training loss: 2.7170844078063965
Validation loss: 2.4071793146030878

Epoch: 5| Step: 3
Training loss: 3.0645079612731934
Validation loss: 2.405282010314285

Epoch: 5| Step: 4
Training loss: 2.033785581588745
Validation loss: 2.405384176520891

Epoch: 5| Step: 5
Training loss: 2.3066933155059814
Validation loss: 2.414804950837166

Epoch: 5| Step: 6
Training loss: 3.200284242630005
Validation loss: 2.4249327105860554

Epoch: 5| Step: 7
Training loss: 2.6688079833984375
Validation loss: 2.4289231441354238

Epoch: 5| Step: 8
Training loss: 2.993093967437744
Validation loss: 2.4219513503454064

Epoch: 5| Step: 9
Training loss: 2.4867539405822754
Validation loss: 2.415901804483065

Epoch: 5| Step: 10
Training loss: 2.5299642086029053
Validation loss: 2.419158261309388

Epoch: 226| Step: 0
Training loss: 2.893339157104492
Validation loss: 2.418432794591432

Epoch: 5| Step: 1
Training loss: 2.131476879119873
Validation loss: 2.4011457556037494

Epoch: 5| Step: 2
Training loss: 1.809787392616272
Validation loss: 2.400319953118601

Epoch: 5| Step: 3
Training loss: 2.998666763305664
Validation loss: 2.398155022692937

Epoch: 5| Step: 4
Training loss: 2.6539700031280518
Validation loss: 2.3955358343739666

Epoch: 5| Step: 5
Training loss: 1.8286842107772827
Validation loss: 2.3950513896121772

Epoch: 5| Step: 6
Training loss: 3.0114903450012207
Validation loss: 2.3890478687901653

Epoch: 5| Step: 7
Training loss: 2.4568400382995605
Validation loss: 2.3954560269591627

Epoch: 5| Step: 8
Training loss: 2.847158432006836
Validation loss: 2.395439342785907

Epoch: 5| Step: 9
Training loss: 3.0097339153289795
Validation loss: 2.3973933342964417

Epoch: 5| Step: 10
Training loss: 3.065519332885742
Validation loss: 2.392335061104067

Epoch: 227| Step: 0
Training loss: 3.2381603717803955
Validation loss: 2.394096633439423

Epoch: 5| Step: 1
Training loss: 2.2180259227752686
Validation loss: 2.3961644762305805

Epoch: 5| Step: 2
Training loss: 2.4352047443389893
Validation loss: 2.3988699720751856

Epoch: 5| Step: 3
Training loss: 2.3761544227600098
Validation loss: 2.403375259009741

Epoch: 5| Step: 4
Training loss: 2.589229106903076
Validation loss: 2.401714740260955

Epoch: 5| Step: 5
Training loss: 3.2744967937469482
Validation loss: 2.40694486453969

Epoch: 5| Step: 6
Training loss: 2.10246205329895
Validation loss: 2.4021664845046176

Epoch: 5| Step: 7
Training loss: 2.930431365966797
Validation loss: 2.393495766065454

Epoch: 5| Step: 8
Training loss: 2.7076690196990967
Validation loss: 2.401129489303917

Epoch: 5| Step: 9
Training loss: 2.5133814811706543
Validation loss: 2.4058731781539096

Epoch: 5| Step: 10
Training loss: 2.291376829147339
Validation loss: 2.4043834722170265

Epoch: 228| Step: 0
Training loss: 2.616013765335083
Validation loss: 2.41754670809674

Epoch: 5| Step: 1
Training loss: 2.4648101329803467
Validation loss: 2.412922041390532

Epoch: 5| Step: 2
Training loss: 2.9064557552337646
Validation loss: 2.4119161572507632

Epoch: 5| Step: 3
Training loss: 2.748779773712158
Validation loss: 2.4045451328318608

Epoch: 5| Step: 4
Training loss: 2.8623180389404297
Validation loss: 2.400563714324787

Epoch: 5| Step: 5
Training loss: 2.354097366333008
Validation loss: 2.3982092462560183

Epoch: 5| Step: 6
Training loss: 2.711249589920044
Validation loss: 2.3970391186334754

Epoch: 5| Step: 7
Training loss: 2.6408941745758057
Validation loss: 2.397898584283808

Epoch: 5| Step: 8
Training loss: 2.3532814979553223
Validation loss: 2.3947553250097458

Epoch: 5| Step: 9
Training loss: 2.5318245887756348
Validation loss: 2.4024130375154558

Epoch: 5| Step: 10
Training loss: 2.416566848754883
Validation loss: 2.39234745887018

Epoch: 229| Step: 0
Training loss: 2.4545044898986816
Validation loss: 2.4038082502221547

Epoch: 5| Step: 1
Training loss: 1.9537360668182373
Validation loss: 2.4038473636873308

Epoch: 5| Step: 2
Training loss: 2.459636688232422
Validation loss: 2.403227383090604

Epoch: 5| Step: 3
Training loss: 3.132718563079834
Validation loss: 2.4017662309831187

Epoch: 5| Step: 4
Training loss: 2.5311484336853027
Validation loss: 2.404856474168839

Epoch: 5| Step: 5
Training loss: 3.1048247814178467
Validation loss: 2.413869370696365

Epoch: 5| Step: 6
Training loss: 2.774233341217041
Validation loss: 2.4116494501790693

Epoch: 5| Step: 7
Training loss: 2.708895444869995
Validation loss: 2.4088197831184632

Epoch: 5| Step: 8
Training loss: 2.2003378868103027
Validation loss: 2.406475679848784

Epoch: 5| Step: 9
Training loss: 2.1576955318450928
Validation loss: 2.4116321532957015

Epoch: 5| Step: 10
Training loss: 3.1867177486419678
Validation loss: 2.407999279678509

Epoch: 230| Step: 0
Training loss: 2.502629518508911
Validation loss: 2.41369378694924

Epoch: 5| Step: 1
Training loss: 1.9453681707382202
Validation loss: 2.4179918304566415

Epoch: 5| Step: 2
Training loss: 2.440328359603882
Validation loss: 2.431094079889277

Epoch: 5| Step: 3
Training loss: 2.6184728145599365
Validation loss: 2.4295227066163094

Epoch: 5| Step: 4
Training loss: 3.4629197120666504
Validation loss: 2.424201670513358

Epoch: 5| Step: 5
Training loss: 2.7237560749053955
Validation loss: 2.4209770541037283

Epoch: 5| Step: 6
Training loss: 2.9965271949768066
Validation loss: 2.4142064099670737

Epoch: 5| Step: 7
Training loss: 2.2931809425354004
Validation loss: 2.403849381272511

Epoch: 5| Step: 8
Training loss: 3.3099770545959473
Validation loss: 2.4002600203278246

Epoch: 5| Step: 9
Training loss: 1.99961256980896
Validation loss: 2.3956561344926075

Epoch: 5| Step: 10
Training loss: 2.1719605922698975
Validation loss: 2.4011369494981665

Epoch: 231| Step: 0
Training loss: 2.619377613067627
Validation loss: 2.396923577913674

Epoch: 5| Step: 1
Training loss: 2.7101948261260986
Validation loss: 2.396841569613385

Epoch: 5| Step: 2
Training loss: 3.4886295795440674
Validation loss: 2.3965660833543345

Epoch: 5| Step: 3
Training loss: 2.495884418487549
Validation loss: 2.398171119792487

Epoch: 5| Step: 4
Training loss: 2.522387981414795
Validation loss: 2.40037114133117

Epoch: 5| Step: 5
Training loss: 1.8322227001190186
Validation loss: 2.4017792927321566

Epoch: 5| Step: 6
Training loss: 2.6519534587860107
Validation loss: 2.402287816488615

Epoch: 5| Step: 7
Training loss: 2.8151659965515137
Validation loss: 2.4132961534684703

Epoch: 5| Step: 8
Training loss: 2.675295829772949
Validation loss: 2.4088173886781097

Epoch: 5| Step: 9
Training loss: 2.5001449584960938
Validation loss: 2.408432517000424

Epoch: 5| Step: 10
Training loss: 2.2143473625183105
Validation loss: 2.4135192081492436

Epoch: 232| Step: 0
Training loss: 2.7719430923461914
Validation loss: 2.414923534598402

Epoch: 5| Step: 1
Training loss: 3.027838945388794
Validation loss: 2.414804558600149

Epoch: 5| Step: 2
Training loss: 3.086141586303711
Validation loss: 2.415620121904599

Epoch: 5| Step: 3
Training loss: 2.2869107723236084
Validation loss: 2.4143569828361593

Epoch: 5| Step: 4
Training loss: 1.9482536315917969
Validation loss: 2.4115851873992593

Epoch: 5| Step: 5
Training loss: 2.4797120094299316
Validation loss: 2.4059959867949128

Epoch: 5| Step: 6
Training loss: 2.6593689918518066
Validation loss: 2.4020497158009517

Epoch: 5| Step: 7
Training loss: 2.2149205207824707
Validation loss: 2.391686689469122

Epoch: 5| Step: 8
Training loss: 2.132258892059326
Validation loss: 2.396589909830401

Epoch: 5| Step: 9
Training loss: 3.074279308319092
Validation loss: 2.401221613730154

Epoch: 5| Step: 10
Training loss: 2.9218199253082275
Validation loss: 2.398521705340314

Epoch: 233| Step: 0
Training loss: 2.5508835315704346
Validation loss: 2.400601822842834

Epoch: 5| Step: 1
Training loss: 2.300168037414551
Validation loss: 2.4019791413378972

Epoch: 5| Step: 2
Training loss: 2.811224937438965
Validation loss: 2.403573397667177

Epoch: 5| Step: 3
Training loss: 2.8001317977905273
Validation loss: 2.4075637222618185

Epoch: 5| Step: 4
Training loss: 2.775834083557129
Validation loss: 2.4116644782404744

Epoch: 5| Step: 5
Training loss: 2.549595832824707
Validation loss: 2.4086924240153325

Epoch: 5| Step: 6
Training loss: 2.8980445861816406
Validation loss: 2.4132044033337663

Epoch: 5| Step: 7
Training loss: 2.0905654430389404
Validation loss: 2.41818308061169

Epoch: 5| Step: 8
Training loss: 3.2086806297302246
Validation loss: 2.41677346024462

Epoch: 5| Step: 9
Training loss: 2.1106560230255127
Validation loss: 2.4110526756573747

Epoch: 5| Step: 10
Training loss: 2.368921995162964
Validation loss: 2.4090436222732707

Epoch: 234| Step: 0
Training loss: 1.9056974649429321
Validation loss: 2.404001569235197

Epoch: 5| Step: 1
Training loss: 3.1000149250030518
Validation loss: 2.399417725942468

Epoch: 5| Step: 2
Training loss: 2.4584755897521973
Validation loss: 2.3932157742079867

Epoch: 5| Step: 3
Training loss: 2.379023551940918
Validation loss: 2.3934944009268158

Epoch: 5| Step: 4
Training loss: 2.512930154800415
Validation loss: 2.3960234426682994

Epoch: 5| Step: 5
Training loss: 2.6887733936309814
Validation loss: 2.4056809871427474

Epoch: 5| Step: 6
Training loss: 2.519852876663208
Validation loss: 2.402346408495339

Epoch: 5| Step: 7
Training loss: 2.3526551723480225
Validation loss: 2.4050397796015583

Epoch: 5| Step: 8
Training loss: 3.1439034938812256
Validation loss: 2.4018018989152807

Epoch: 5| Step: 9
Training loss: 2.9903178215026855
Validation loss: 2.4053134174757105

Epoch: 5| Step: 10
Training loss: 2.584190845489502
Validation loss: 2.4107289262997207

Epoch: 235| Step: 0
Training loss: 2.2037594318389893
Validation loss: 2.4069281137117775

Epoch: 5| Step: 1
Training loss: 2.5431222915649414
Validation loss: 2.404138667609102

Epoch: 5| Step: 2
Training loss: 3.0177128314971924
Validation loss: 2.4037180433991137

Epoch: 5| Step: 3
Training loss: 2.7379462718963623
Validation loss: 2.400352124244936

Epoch: 5| Step: 4
Training loss: 3.0979819297790527
Validation loss: 2.388575653876028

Epoch: 5| Step: 5
Training loss: 2.8007984161376953
Validation loss: 2.3879508279984996

Epoch: 5| Step: 6
Training loss: 2.6298835277557373
Validation loss: 2.3873218772231892

Epoch: 5| Step: 7
Training loss: 2.1278138160705566
Validation loss: 2.390046058162566

Epoch: 5| Step: 8
Training loss: 1.9027185440063477
Validation loss: 2.4011460542678833

Epoch: 5| Step: 9
Training loss: 2.450364828109741
Validation loss: 2.408097441478442

Epoch: 5| Step: 10
Training loss: 3.1145362854003906
Validation loss: 2.4080867203333045

Epoch: 236| Step: 0
Training loss: 2.362504482269287
Validation loss: 2.4137270066045944

Epoch: 5| Step: 1
Training loss: 2.5727944374084473
Validation loss: 2.4096658563101165

Epoch: 5| Step: 2
Training loss: 3.0960776805877686
Validation loss: 2.4078845541964293

Epoch: 5| Step: 3
Training loss: 2.5948803424835205
Validation loss: 2.4078865743452504

Epoch: 5| Step: 4
Training loss: 2.089970827102661
Validation loss: 2.407709370377243

Epoch: 5| Step: 5
Training loss: 2.8839690685272217
Validation loss: 2.409898886116602

Epoch: 5| Step: 6
Training loss: 1.7990055084228516
Validation loss: 2.400375025246733

Epoch: 5| Step: 7
Training loss: 2.3765273094177246
Validation loss: 2.4000791170263804

Epoch: 5| Step: 8
Training loss: 2.4514713287353516
Validation loss: 2.3930611277139313

Epoch: 5| Step: 9
Training loss: 3.9122557640075684
Validation loss: 2.3847393733198925

Epoch: 5| Step: 10
Training loss: 2.362565040588379
Validation loss: 2.3832677487404115

Epoch: 237| Step: 0
Training loss: 2.332780361175537
Validation loss: 2.3774691371507544

Epoch: 5| Step: 1
Training loss: 3.1692817211151123
Validation loss: 2.3753643856253674

Epoch: 5| Step: 2
Training loss: 2.8206076622009277
Validation loss: 2.3747451741208314

Epoch: 5| Step: 3
Training loss: 1.8811107873916626
Validation loss: 2.3737768947437243

Epoch: 5| Step: 4
Training loss: 2.886608600616455
Validation loss: 2.3808019366315616

Epoch: 5| Step: 5
Training loss: 2.744903087615967
Validation loss: 2.374067157827398

Epoch: 5| Step: 6
Training loss: 2.4147167205810547
Validation loss: 2.3864059448242188

Epoch: 5| Step: 7
Training loss: 2.630282402038574
Validation loss: 2.3873731590086416

Epoch: 5| Step: 8
Training loss: 2.2771897315979004
Validation loss: 2.3877524688679683

Epoch: 5| Step: 9
Training loss: 2.8990116119384766
Validation loss: 2.3886664682818997

Epoch: 5| Step: 10
Training loss: 2.4270694255828857
Validation loss: 2.382828027971329

Epoch: 238| Step: 0
Training loss: 2.378593921661377
Validation loss: 2.3907177089363016

Epoch: 5| Step: 1
Training loss: 2.6982667446136475
Validation loss: 2.3885039462838122

Epoch: 5| Step: 2
Training loss: 2.745283603668213
Validation loss: 2.39062677403932

Epoch: 5| Step: 3
Training loss: 2.3340108394622803
Validation loss: 2.397782794890865

Epoch: 5| Step: 4
Training loss: 2.850520610809326
Validation loss: 2.3931944575361026

Epoch: 5| Step: 5
Training loss: 3.0920233726501465
Validation loss: 2.3964165897779566

Epoch: 5| Step: 6
Training loss: 3.065035820007324
Validation loss: 2.3947818381811983

Epoch: 5| Step: 7
Training loss: 3.195570230484009
Validation loss: 2.400039594660523

Epoch: 5| Step: 8
Training loss: 1.509990930557251
Validation loss: 2.399210801688574

Epoch: 5| Step: 9
Training loss: 1.9160124063491821
Validation loss: 2.3901283817906536

Epoch: 5| Step: 10
Training loss: 2.669611692428589
Validation loss: 2.3944637980512393

Epoch: 239| Step: 0
Training loss: 2.810861110687256
Validation loss: 2.3868014658651044

Epoch: 5| Step: 1
Training loss: 2.7256171703338623
Validation loss: 2.391640972065669

Epoch: 5| Step: 2
Training loss: 3.073996067047119
Validation loss: 2.3853717337372484

Epoch: 5| Step: 3
Training loss: 2.5675482749938965
Validation loss: 2.3919073586822837

Epoch: 5| Step: 4
Training loss: 3.0396673679351807
Validation loss: 2.387771342390327

Epoch: 5| Step: 5
Training loss: 2.608187198638916
Validation loss: 2.3890739153790217

Epoch: 5| Step: 6
Training loss: 2.6305880546569824
Validation loss: 2.3892459433565856

Epoch: 5| Step: 7
Training loss: 2.4513981342315674
Validation loss: 2.397183374692035

Epoch: 5| Step: 8
Training loss: 2.4384560585021973
Validation loss: 2.3918346410156577

Epoch: 5| Step: 9
Training loss: 2.5772488117218018
Validation loss: 2.3937305737567205

Epoch: 5| Step: 10
Training loss: 1.257340908050537
Validation loss: 2.3995746412584857

Epoch: 240| Step: 0
Training loss: 2.954286813735962
Validation loss: 2.3925645453955537

Epoch: 5| Step: 1
Training loss: 2.0634002685546875
Validation loss: 2.393681092928815

Epoch: 5| Step: 2
Training loss: 2.3263051509857178
Validation loss: 2.389192755504321

Epoch: 5| Step: 3
Training loss: 3.065692186355591
Validation loss: 2.3856392650194067

Epoch: 5| Step: 4
Training loss: 2.5333292484283447
Validation loss: 2.3891031049912974

Epoch: 5| Step: 5
Training loss: 2.6594011783599854
Validation loss: 2.3927514911979757

Epoch: 5| Step: 6
Training loss: 2.8191018104553223
Validation loss: 2.3955140498376664

Epoch: 5| Step: 7
Training loss: 2.387380838394165
Validation loss: 2.387285283816758

Epoch: 5| Step: 8
Training loss: 2.211643934249878
Validation loss: 2.381912928755565

Epoch: 5| Step: 9
Training loss: 2.538628101348877
Validation loss: 2.3762194341228855

Epoch: 5| Step: 10
Training loss: 2.9527769088745117
Validation loss: 2.3735917665625132

Epoch: 241| Step: 0
Training loss: 2.697713851928711
Validation loss: 2.3804896723839546

Epoch: 5| Step: 1
Training loss: 2.2227814197540283
Validation loss: 2.3774903897316224

Epoch: 5| Step: 2
Training loss: 2.7888593673706055
Validation loss: 2.379865700198758

Epoch: 5| Step: 3
Training loss: 2.7167108058929443
Validation loss: 2.385212372708064

Epoch: 5| Step: 4
Training loss: 2.2426257133483887
Validation loss: 2.385042623807025

Epoch: 5| Step: 5
Training loss: 2.87943959236145
Validation loss: 2.3910141221938597

Epoch: 5| Step: 6
Training loss: 2.28471040725708
Validation loss: 2.387644188378447

Epoch: 5| Step: 7
Training loss: 2.448737144470215
Validation loss: 2.3790313069538405

Epoch: 5| Step: 8
Training loss: 3.050279140472412
Validation loss: 2.3783767659177064

Epoch: 5| Step: 9
Training loss: 2.4391391277313232
Validation loss: 2.3824373163202757

Epoch: 5| Step: 10
Training loss: 2.770822286605835
Validation loss: 2.392869416103568

Epoch: 242| Step: 0
Training loss: 2.12632417678833
Validation loss: 2.399426632030036

Epoch: 5| Step: 1
Training loss: 2.12764048576355
Validation loss: 2.393958258372481

Epoch: 5| Step: 2
Training loss: 2.6541945934295654
Validation loss: 2.3954074357145574

Epoch: 5| Step: 3
Training loss: 2.542419910430908
Validation loss: 2.4016387052433465

Epoch: 5| Step: 4
Training loss: 2.3047518730163574
Validation loss: 2.413783650244436

Epoch: 5| Step: 5
Training loss: 2.6840953826904297
Validation loss: 2.4124663824676187

Epoch: 5| Step: 6
Training loss: 3.279184341430664
Validation loss: 2.3943969741944344

Epoch: 5| Step: 7
Training loss: 2.605498790740967
Validation loss: 2.410438883689142

Epoch: 5| Step: 8
Training loss: 3.247041702270508
Validation loss: 2.403696980527652

Epoch: 5| Step: 9
Training loss: 2.2489852905273438
Validation loss: 2.3916288960364556

Epoch: 5| Step: 10
Training loss: 2.578145980834961
Validation loss: 2.3837773210258892

Epoch: 243| Step: 0
Training loss: 2.4318151473999023
Validation loss: 2.3695657714720695

Epoch: 5| Step: 1
Training loss: 3.3345839977264404
Validation loss: 2.3818451102061937

Epoch: 5| Step: 2
Training loss: 2.813709259033203
Validation loss: 2.384073144646101

Epoch: 5| Step: 3
Training loss: 2.8396029472351074
Validation loss: 2.3958664376248597

Epoch: 5| Step: 4
Training loss: 1.6231844425201416
Validation loss: 2.3964728642535467

Epoch: 5| Step: 5
Training loss: 2.1715846061706543
Validation loss: 2.40133697243147

Epoch: 5| Step: 6
Training loss: 2.391420841217041
Validation loss: 2.406560336389849

Epoch: 5| Step: 7
Training loss: 3.399019956588745
Validation loss: 2.3958471975018902

Epoch: 5| Step: 8
Training loss: 2.367403268814087
Validation loss: 2.40119005275029

Epoch: 5| Step: 9
Training loss: 2.987668991088867
Validation loss: 2.3944690381326983

Epoch: 5| Step: 10
Training loss: 2.5178380012512207
Validation loss: 2.3859672905296407

Epoch: 244| Step: 0
Training loss: 3.2397022247314453
Validation loss: 2.3813475460134526

Epoch: 5| Step: 1
Training loss: 2.9102847576141357
Validation loss: 2.3695520585583103

Epoch: 5| Step: 2
Training loss: 2.554962635040283
Validation loss: 2.3808008342660885

Epoch: 5| Step: 3
Training loss: 2.554067611694336
Validation loss: 2.3883261270420526

Epoch: 5| Step: 4
Training loss: 2.232758045196533
Validation loss: 2.392577886581421

Epoch: 5| Step: 5
Training loss: 2.3434953689575195
Validation loss: 2.39668531058937

Epoch: 5| Step: 6
Training loss: 3.125058889389038
Validation loss: 2.4193961838240265

Epoch: 5| Step: 7
Training loss: 2.047161817550659
Validation loss: 2.407150124990812

Epoch: 5| Step: 8
Training loss: 2.6595168113708496
Validation loss: 2.4059974685792

Epoch: 5| Step: 9
Training loss: 2.0709762573242188
Validation loss: 2.398415316817581

Epoch: 5| Step: 10
Training loss: 2.8228518962860107
Validation loss: 2.393187827961419

Epoch: 245| Step: 0
Training loss: 2.97375750541687
Validation loss: 2.3810514532109743

Epoch: 5| Step: 1
Training loss: 1.7754828929901123
Validation loss: 2.385639709811057

Epoch: 5| Step: 2
Training loss: 2.6109626293182373
Validation loss: 2.386586517416021

Epoch: 5| Step: 3
Training loss: 2.0032238960266113
Validation loss: 2.4055281454516995

Epoch: 5| Step: 4
Training loss: 2.4030189514160156
Validation loss: 2.391471298792029

Epoch: 5| Step: 5
Training loss: 2.7825253009796143
Validation loss: 2.40484199472653

Epoch: 5| Step: 6
Training loss: 2.9441590309143066
Validation loss: 2.397443781616867

Epoch: 5| Step: 7
Training loss: 2.61735463142395
Validation loss: 2.3969289538680867

Epoch: 5| Step: 8
Training loss: 2.8293166160583496
Validation loss: 2.3898484040332097

Epoch: 5| Step: 9
Training loss: 2.8449625968933105
Validation loss: 2.3849275983789915

Epoch: 5| Step: 10
Training loss: 2.5730090141296387
Validation loss: 2.3775769484940397

Epoch: 246| Step: 0
Training loss: 2.0037569999694824
Validation loss: 2.373370168029621

Epoch: 5| Step: 1
Training loss: 2.36413836479187
Validation loss: 2.3660716395224295

Epoch: 5| Step: 2
Training loss: 3.0816376209259033
Validation loss: 2.3630987649322837

Epoch: 5| Step: 3
Training loss: 2.9072463512420654
Validation loss: 2.3680493498361237

Epoch: 5| Step: 4
Training loss: 2.043694019317627
Validation loss: 2.3688294528633036

Epoch: 5| Step: 5
Training loss: 2.9059996604919434
Validation loss: 2.369802995394635

Epoch: 5| Step: 6
Training loss: 2.78334903717041
Validation loss: 2.3667541011687248

Epoch: 5| Step: 7
Training loss: 2.2532551288604736
Validation loss: 2.3718376710850704

Epoch: 5| Step: 8
Training loss: 2.87711763381958
Validation loss: 2.3624261053659583

Epoch: 5| Step: 9
Training loss: 2.9586703777313232
Validation loss: 2.3634437361071186

Epoch: 5| Step: 10
Training loss: 2.19352388381958
Validation loss: 2.3658536429046304

Epoch: 247| Step: 0
Training loss: 2.673809289932251
Validation loss: 2.363341828828217

Epoch: 5| Step: 1
Training loss: 2.8022799491882324
Validation loss: 2.3662507687845538

Epoch: 5| Step: 2
Training loss: 2.2175097465515137
Validation loss: 2.365596281584873

Epoch: 5| Step: 3
Training loss: 2.5521111488342285
Validation loss: 2.370081898986652

Epoch: 5| Step: 4
Training loss: 2.9060239791870117
Validation loss: 2.3760837893332205

Epoch: 5| Step: 5
Training loss: 2.750444173812866
Validation loss: 2.3763757777470413

Epoch: 5| Step: 6
Training loss: 2.2264957427978516
Validation loss: 2.3731525405760734

Epoch: 5| Step: 7
Training loss: 2.9587249755859375
Validation loss: 2.3842543812208277

Epoch: 5| Step: 8
Training loss: 2.568024158477783
Validation loss: 2.386197031185191

Epoch: 5| Step: 9
Training loss: 2.9038684368133545
Validation loss: 2.380989602817002

Epoch: 5| Step: 10
Training loss: 1.6822460889816284
Validation loss: 2.3911211106085006

Epoch: 248| Step: 0
Training loss: 2.099386692047119
Validation loss: 2.3935949135852117

Epoch: 5| Step: 1
Training loss: 2.538452386856079
Validation loss: 2.385305858427478

Epoch: 5| Step: 2
Training loss: 3.0888562202453613
Validation loss: 2.3884280471391577

Epoch: 5| Step: 3
Training loss: 2.7325305938720703
Validation loss: 2.3919811402597735

Epoch: 5| Step: 4
Training loss: 2.6028473377227783
Validation loss: 2.3796693612170476

Epoch: 5| Step: 5
Training loss: 1.6796385049819946
Validation loss: 2.38136782697452

Epoch: 5| Step: 6
Training loss: 2.7988979816436768
Validation loss: 2.3906271124398835

Epoch: 5| Step: 7
Training loss: 2.6787116527557373
Validation loss: 2.3803088306098856

Epoch: 5| Step: 8
Training loss: 2.982614278793335
Validation loss: 2.3722541178426435

Epoch: 5| Step: 9
Training loss: 2.8656299114227295
Validation loss: 2.3734419679128997

Epoch: 5| Step: 10
Training loss: 2.1884806156158447
Validation loss: 2.37376400732225

Epoch: 249| Step: 0
Training loss: 2.5327305793762207
Validation loss: 2.37509576735958

Epoch: 5| Step: 1
Training loss: 2.2253670692443848
Validation loss: 2.375982351200555

Epoch: 5| Step: 2
Training loss: 2.7842228412628174
Validation loss: 2.37434797645897

Epoch: 5| Step: 3
Training loss: 2.0471959114074707
Validation loss: 2.381060290080245

Epoch: 5| Step: 4
Training loss: 3.1031429767608643
Validation loss: 2.384742013869747

Epoch: 5| Step: 5
Training loss: 2.5679736137390137
Validation loss: 2.3907985200164137

Epoch: 5| Step: 6
Training loss: 2.2506422996520996
Validation loss: 2.387986457476052

Epoch: 5| Step: 7
Training loss: 3.179302930831909
Validation loss: 2.3914016369850404

Epoch: 5| Step: 8
Training loss: 2.106443405151367
Validation loss: 2.39081504268031

Epoch: 5| Step: 9
Training loss: 2.705261707305908
Validation loss: 2.3886232145370974

Epoch: 5| Step: 10
Training loss: 2.834684133529663
Validation loss: 2.3731679711290585

Epoch: 250| Step: 0
Training loss: 2.541806221008301
Validation loss: 2.3697176928161294

Epoch: 5| Step: 1
Training loss: 2.196087598800659
Validation loss: 2.3751600660303587

Epoch: 5| Step: 2
Training loss: 3.034397840499878
Validation loss: 2.376480371721329

Epoch: 5| Step: 3
Training loss: 2.608471393585205
Validation loss: 2.3768611185012327

Epoch: 5| Step: 4
Training loss: 2.8422038555145264
Validation loss: 2.3760533127733456

Epoch: 5| Step: 5
Training loss: 2.597757577896118
Validation loss: 2.3884993573670745

Epoch: 5| Step: 6
Training loss: 2.1372759342193604
Validation loss: 2.394984564473552

Epoch: 5| Step: 7
Training loss: 2.727695941925049
Validation loss: 2.38589116578461

Epoch: 5| Step: 8
Training loss: 2.734086513519287
Validation loss: 2.388059531488726

Epoch: 5| Step: 9
Training loss: 2.3841326236724854
Validation loss: 2.3839662280133975

Epoch: 5| Step: 10
Training loss: 2.5287325382232666
Validation loss: 2.3834794464931695

Epoch: 251| Step: 0
Training loss: 2.569951057434082
Validation loss: 2.3764701171587874

Epoch: 5| Step: 1
Training loss: 2.707395315170288
Validation loss: 2.3729934743655625

Epoch: 5| Step: 2
Training loss: 2.9505209922790527
Validation loss: 2.362514558658805

Epoch: 5| Step: 3
Training loss: 2.2547049522399902
Validation loss: 2.3674279054005942

Epoch: 5| Step: 4
Training loss: 2.7062058448791504
Validation loss: 2.360314371765301

Epoch: 5| Step: 5
Training loss: 2.388258457183838
Validation loss: 2.3686763112263014

Epoch: 5| Step: 6
Training loss: 2.9625840187072754
Validation loss: 2.358317267510199

Epoch: 5| Step: 7
Training loss: 2.650484800338745
Validation loss: 2.3623180056131012

Epoch: 5| Step: 8
Training loss: 2.4599907398223877
Validation loss: 2.3658401581548874

Epoch: 5| Step: 9
Training loss: 2.184150457382202
Validation loss: 2.3701543961801836

Epoch: 5| Step: 10
Training loss: 2.485126256942749
Validation loss: 2.3724899215082966

Epoch: 252| Step: 0
Training loss: 3.13254714012146
Validation loss: 2.3761295118639545

Epoch: 5| Step: 1
Training loss: 2.7406105995178223
Validation loss: 2.3740062277804137

Epoch: 5| Step: 2
Training loss: 2.5077099800109863
Validation loss: 2.385657884741342

Epoch: 5| Step: 3
Training loss: 2.1899688243865967
Validation loss: 2.3737143342212965

Epoch: 5| Step: 4
Training loss: 2.109543561935425
Validation loss: 2.377847440781132

Epoch: 5| Step: 5
Training loss: 2.9438602924346924
Validation loss: 2.379320733008846

Epoch: 5| Step: 6
Training loss: 2.065779209136963
Validation loss: 2.3922947119641047

Epoch: 5| Step: 7
Training loss: 3.0922884941101074
Validation loss: 2.3929498246921006

Epoch: 5| Step: 8
Training loss: 2.209864377975464
Validation loss: 2.3865887682924987

Epoch: 5| Step: 9
Training loss: 2.9035816192626953
Validation loss: 2.3919228840899724

Epoch: 5| Step: 10
Training loss: 2.2845265865325928
Validation loss: 2.389299460636672

Epoch: 253| Step: 0
Training loss: 2.3077447414398193
Validation loss: 2.3987600521374772

Epoch: 5| Step: 1
Training loss: 3.128082752227783
Validation loss: 2.388469216644123

Epoch: 5| Step: 2
Training loss: 2.5002284049987793
Validation loss: 2.3961738642825874

Epoch: 5| Step: 3
Training loss: 2.7947325706481934
Validation loss: 2.3879148985749934

Epoch: 5| Step: 4
Training loss: 2.214238405227661
Validation loss: 2.376904074863721

Epoch: 5| Step: 5
Training loss: 2.758450984954834
Validation loss: 2.372507372210103

Epoch: 5| Step: 6
Training loss: 2.622500419616699
Validation loss: 2.376599834811303

Epoch: 5| Step: 7
Training loss: 2.432952880859375
Validation loss: 2.366274038950602

Epoch: 5| Step: 8
Training loss: 2.560080051422119
Validation loss: 2.367991831994826

Epoch: 5| Step: 9
Training loss: 2.2923643589019775
Validation loss: 2.3636335249870055

Epoch: 5| Step: 10
Training loss: 2.6484341621398926
Validation loss: 2.3687047009826987

Epoch: 254| Step: 0
Training loss: 2.3377225399017334
Validation loss: 2.366722306897563

Epoch: 5| Step: 1
Training loss: 2.5109200477600098
Validation loss: 2.372143437785487

Epoch: 5| Step: 2
Training loss: 2.551583766937256
Validation loss: 2.375606390737718

Epoch: 5| Step: 3
Training loss: 2.816359281539917
Validation loss: 2.3784451894862677

Epoch: 5| Step: 4
Training loss: 2.489523410797119
Validation loss: 2.3820120391025337

Epoch: 5| Step: 5
Training loss: 2.4582717418670654
Validation loss: 2.375059317517024

Epoch: 5| Step: 6
Training loss: 2.201598644256592
Validation loss: 2.3780811922524565

Epoch: 5| Step: 7
Training loss: 2.5668678283691406
Validation loss: 2.378949457599271

Epoch: 5| Step: 8
Training loss: 2.567155361175537
Validation loss: 2.38213360950511

Epoch: 5| Step: 9
Training loss: 2.8806490898132324
Validation loss: 2.378142544018325

Epoch: 5| Step: 10
Training loss: 2.9255034923553467
Validation loss: 2.3838199979515484

Epoch: 255| Step: 0
Training loss: 2.776632785797119
Validation loss: 2.379907152986014

Epoch: 5| Step: 1
Training loss: 2.633582592010498
Validation loss: 2.3683822898454565

Epoch: 5| Step: 2
Training loss: 2.26224422454834
Validation loss: 2.3667089913481023

Epoch: 5| Step: 3
Training loss: 2.497073173522949
Validation loss: 2.3576825780253254

Epoch: 5| Step: 4
Training loss: 2.4984323978424072
Validation loss: 2.362348125826928

Epoch: 5| Step: 5
Training loss: 2.8917927742004395
Validation loss: 2.362762684463173

Epoch: 5| Step: 6
Training loss: 2.1769070625305176
Validation loss: 2.3611431737099924

Epoch: 5| Step: 7
Training loss: 2.161592483520508
Validation loss: 2.354600009097848

Epoch: 5| Step: 8
Training loss: 2.5596039295196533
Validation loss: 2.3475962326090825

Epoch: 5| Step: 9
Training loss: 2.790449857711792
Validation loss: 2.344440298695718

Epoch: 5| Step: 10
Training loss: 2.957592010498047
Validation loss: 2.350273746316151

Epoch: 256| Step: 0
Training loss: 2.2790932655334473
Validation loss: 2.3548578318729194

Epoch: 5| Step: 1
Training loss: 2.8907344341278076
Validation loss: 2.351085565423453

Epoch: 5| Step: 2
Training loss: 2.43131685256958
Validation loss: 2.3528844720573834

Epoch: 5| Step: 3
Training loss: 2.2870211601257324
Validation loss: 2.350440958494781

Epoch: 5| Step: 4
Training loss: 3.1630070209503174
Validation loss: 2.3643214164241666

Epoch: 5| Step: 5
Training loss: 2.8970179557800293
Validation loss: 2.3662573060681744

Epoch: 5| Step: 6
Training loss: 2.2453668117523193
Validation loss: 2.371152185624646

Epoch: 5| Step: 7
Training loss: 2.115070343017578
Validation loss: 2.3642014149696595

Epoch: 5| Step: 8
Training loss: 2.703848361968994
Validation loss: 2.361382484436035

Epoch: 5| Step: 9
Training loss: 2.43861722946167
Validation loss: 2.363188415445307

Epoch: 5| Step: 10
Training loss: 2.8445401191711426
Validation loss: 2.3712582075467674

Epoch: 257| Step: 0
Training loss: 1.7463264465332031
Validation loss: 2.3641831541574128

Epoch: 5| Step: 1
Training loss: 2.4897866249084473
Validation loss: 2.359184747101158

Epoch: 5| Step: 2
Training loss: 2.381591796875
Validation loss: 2.3637575000844975

Epoch: 5| Step: 3
Training loss: 2.442493438720703
Validation loss: 2.373772405808972

Epoch: 5| Step: 4
Training loss: 2.6357333660125732
Validation loss: 2.370046402818413

Epoch: 5| Step: 5
Training loss: 2.226799249649048
Validation loss: 2.378101489877188

Epoch: 5| Step: 6
Training loss: 3.1330952644348145
Validation loss: 2.3762618239207933

Epoch: 5| Step: 7
Training loss: 2.663473606109619
Validation loss: 2.376963669253934

Epoch: 5| Step: 8
Training loss: 2.676530361175537
Validation loss: 2.386496236247401

Epoch: 5| Step: 9
Training loss: 2.655669689178467
Validation loss: 2.388425088697864

Epoch: 5| Step: 10
Training loss: 3.330514907836914
Validation loss: 2.379265849308301

Epoch: 258| Step: 0
Training loss: 2.4672024250030518
Validation loss: 2.3739240887344524

Epoch: 5| Step: 1
Training loss: 2.340388536453247
Validation loss: 2.363942171937676

Epoch: 5| Step: 2
Training loss: 3.213502883911133
Validation loss: 2.358598878306727

Epoch: 5| Step: 3
Training loss: 2.723501682281494
Validation loss: 2.355932940718948

Epoch: 5| Step: 4
Training loss: 2.1525681018829346
Validation loss: 2.3494220972061157

Epoch: 5| Step: 5
Training loss: 2.9409947395324707
Validation loss: 2.3458472362128635

Epoch: 5| Step: 6
Training loss: 2.4552128314971924
Validation loss: 2.351408859734894

Epoch: 5| Step: 7
Training loss: 2.5855488777160645
Validation loss: 2.351037556125272

Epoch: 5| Step: 8
Training loss: 2.774401903152466
Validation loss: 2.3436959712736067

Epoch: 5| Step: 9
Training loss: 2.242993116378784
Validation loss: 2.3495974438164824

Epoch: 5| Step: 10
Training loss: 2.3219919204711914
Validation loss: 2.3511677390785626

Epoch: 259| Step: 0
Training loss: 2.1249642372131348
Validation loss: 2.349843407189974

Epoch: 5| Step: 1
Training loss: 2.318966865539551
Validation loss: 2.3540039575228127

Epoch: 5| Step: 2
Training loss: 2.3834340572357178
Validation loss: 2.3530260542387604

Epoch: 5| Step: 3
Training loss: 3.4444572925567627
Validation loss: 2.3480786174856205

Epoch: 5| Step: 4
Training loss: 2.8413329124450684
Validation loss: 2.3439671762527956

Epoch: 5| Step: 5
Training loss: 2.2751784324645996
Validation loss: 2.3591179937444706

Epoch: 5| Step: 6
Training loss: 3.4880592823028564
Validation loss: 2.3558587899772068

Epoch: 5| Step: 7
Training loss: 1.7665868997573853
Validation loss: 2.357587637439851

Epoch: 5| Step: 8
Training loss: 2.4107472896575928
Validation loss: 2.351059224015923

Epoch: 5| Step: 9
Training loss: 2.644340991973877
Validation loss: 2.35679409709028

Epoch: 5| Step: 10
Training loss: 2.607412338256836
Validation loss: 2.36066315251012

Epoch: 260| Step: 0
Training loss: 2.3799357414245605
Validation loss: 2.352592734880345

Epoch: 5| Step: 1
Training loss: 2.504877805709839
Validation loss: 2.3520058598569644

Epoch: 5| Step: 2
Training loss: 2.0559513568878174
Validation loss: 2.3629056689559773

Epoch: 5| Step: 3
Training loss: 2.7178807258605957
Validation loss: 2.3746957702021443

Epoch: 5| Step: 4
Training loss: 1.9999973773956299
Validation loss: 2.36757977034456

Epoch: 5| Step: 5
Training loss: 2.6498899459838867
Validation loss: 2.369756883190524

Epoch: 5| Step: 6
Training loss: 3.150247097015381
Validation loss: 2.370037333939665

Epoch: 5| Step: 7
Training loss: 2.5676074028015137
Validation loss: 2.374710136844266

Epoch: 5| Step: 8
Training loss: 2.7115461826324463
Validation loss: 2.376559772799092

Epoch: 5| Step: 9
Training loss: 3.071345806121826
Validation loss: 2.37518734060308

Epoch: 5| Step: 10
Training loss: 2.4360289573669434
Validation loss: 2.372275367859871

Epoch: 261| Step: 0
Training loss: 2.3066933155059814
Validation loss: 2.368575152530465

Epoch: 5| Step: 1
Training loss: 3.0699374675750732
Validation loss: 2.3771008291552143

Epoch: 5| Step: 2
Training loss: 1.9651241302490234
Validation loss: 2.3712859692112094

Epoch: 5| Step: 3
Training loss: 2.84538197517395
Validation loss: 2.3611233798406457

Epoch: 5| Step: 4
Training loss: 2.8382115364074707
Validation loss: 2.3651083130990305

Epoch: 5| Step: 5
Training loss: 2.5189671516418457
Validation loss: 2.3538737091966855

Epoch: 5| Step: 6
Training loss: 2.4213571548461914
Validation loss: 2.3545799050279843

Epoch: 5| Step: 7
Training loss: 2.6049606800079346
Validation loss: 2.3518408344637964

Epoch: 5| Step: 8
Training loss: 2.509800434112549
Validation loss: 2.346995319089582

Epoch: 5| Step: 9
Training loss: 2.6850571632385254
Validation loss: 2.3504268405258015

Epoch: 5| Step: 10
Training loss: 2.4118616580963135
Validation loss: 2.3529746686258624

Epoch: 262| Step: 0
Training loss: 1.8666679859161377
Validation loss: 2.3542659462139173

Epoch: 5| Step: 1
Training loss: 2.5985472202301025
Validation loss: 2.357483289575064

Epoch: 5| Step: 2
Training loss: 2.693232536315918
Validation loss: 2.359341957235849

Epoch: 5| Step: 3
Training loss: 2.5671558380126953
Validation loss: 2.3588774691345873

Epoch: 5| Step: 4
Training loss: 2.6005425453186035
Validation loss: 2.3554136906900713

Epoch: 5| Step: 5
Training loss: 2.8265624046325684
Validation loss: 2.3528162638346353

Epoch: 5| Step: 6
Training loss: 3.0199851989746094
Validation loss: 2.356397844129993

Epoch: 5| Step: 7
Training loss: 2.2039477825164795
Validation loss: 2.3520582619533745

Epoch: 5| Step: 8
Training loss: 2.4830658435821533
Validation loss: 2.337686482296195

Epoch: 5| Step: 9
Training loss: 2.539618730545044
Validation loss: 2.3426904832163165

Epoch: 5| Step: 10
Training loss: 2.7848525047302246
Validation loss: 2.3386252849332747

Epoch: 263| Step: 0
Training loss: 2.8925857543945312
Validation loss: 2.349984997062273

Epoch: 5| Step: 1
Training loss: 3.3903579711914062
Validation loss: 2.3542099793752036

Epoch: 5| Step: 2
Training loss: 2.8706393241882324
Validation loss: 2.357853099864016

Epoch: 5| Step: 3
Training loss: 2.028775215148926
Validation loss: 2.3662196333690355

Epoch: 5| Step: 4
Training loss: 2.3051295280456543
Validation loss: 2.3652683278565765

Epoch: 5| Step: 5
Training loss: 2.9963154792785645
Validation loss: 2.372558488640734

Epoch: 5| Step: 6
Training loss: 2.364703416824341
Validation loss: 2.3805515484143327

Epoch: 5| Step: 7
Training loss: 2.7108912467956543
Validation loss: 2.3829412332145115

Epoch: 5| Step: 8
Training loss: 1.4947469234466553
Validation loss: 2.379824258947885

Epoch: 5| Step: 9
Training loss: 2.6098995208740234
Validation loss: 2.3674412465864614

Epoch: 5| Step: 10
Training loss: 2.4393558502197266
Validation loss: 2.3609960027920303

Epoch: 264| Step: 0
Training loss: 2.4299376010894775
Validation loss: 2.3581285656139417

Epoch: 5| Step: 1
Training loss: 2.6858084201812744
Validation loss: 2.350940878673266

Epoch: 5| Step: 2
Training loss: 2.2760696411132812
Validation loss: 2.3533839487260386

Epoch: 5| Step: 3
Training loss: 2.57712721824646
Validation loss: 2.35055043620448

Epoch: 5| Step: 4
Training loss: 2.415130615234375
Validation loss: 2.3490458457700667

Epoch: 5| Step: 5
Training loss: 2.3038697242736816
Validation loss: 2.3460001971132014

Epoch: 5| Step: 6
Training loss: 2.7883453369140625
Validation loss: 2.3402200924452914

Epoch: 5| Step: 7
Training loss: 2.5498123168945312
Validation loss: 2.3479761641512633

Epoch: 5| Step: 8
Training loss: 2.155136823654175
Validation loss: 2.3419239623572237

Epoch: 5| Step: 9
Training loss: 3.775789976119995
Validation loss: 2.3381013703602616

Epoch: 5| Step: 10
Training loss: 2.0171148777008057
Validation loss: 2.345130343591013

Epoch: 265| Step: 0
Training loss: 2.042541980743408
Validation loss: 2.3470961868122058

Epoch: 5| Step: 1
Training loss: 2.7042949199676514
Validation loss: 2.3447230349304857

Epoch: 5| Step: 2
Training loss: 2.6907057762145996
Validation loss: 2.3565288179664203

Epoch: 5| Step: 3
Training loss: 2.778897523880005
Validation loss: 2.358785080653365

Epoch: 5| Step: 4
Training loss: 2.71077299118042
Validation loss: 2.3598876640360844

Epoch: 5| Step: 5
Training loss: 2.7906620502471924
Validation loss: 2.3591097503580074

Epoch: 5| Step: 6
Training loss: 2.883019208908081
Validation loss: 2.3608677746147237

Epoch: 5| Step: 7
Training loss: 2.011345863342285
Validation loss: 2.359855551873484

Epoch: 5| Step: 8
Training loss: 2.7781078815460205
Validation loss: 2.3538215852552846

Epoch: 5| Step: 9
Training loss: 2.2019052505493164
Validation loss: 2.3573857968853367

Epoch: 5| Step: 10
Training loss: 2.4527344703674316
Validation loss: 2.355701882352111

Epoch: 266| Step: 0
Training loss: 2.9003090858459473
Validation loss: 2.3517536553003455

Epoch: 5| Step: 1
Training loss: 2.3452861309051514
Validation loss: 2.351734515159361

Epoch: 5| Step: 2
Training loss: 3.0410208702087402
Validation loss: 2.352865686980627

Epoch: 5| Step: 3
Training loss: 2.559113025665283
Validation loss: 2.353071956224339

Epoch: 5| Step: 4
Training loss: 2.153764486312866
Validation loss: 2.3519373529700824

Epoch: 5| Step: 5
Training loss: 1.811489462852478
Validation loss: 2.3625805019050516

Epoch: 5| Step: 6
Training loss: 2.809420108795166
Validation loss: 2.3569184285338207

Epoch: 5| Step: 7
Training loss: 2.080596446990967
Validation loss: 2.3747283207472933

Epoch: 5| Step: 8
Training loss: 2.4672420024871826
Validation loss: 2.3676293921727005

Epoch: 5| Step: 9
Training loss: 2.9007906913757324
Validation loss: 2.3704027104121383

Epoch: 5| Step: 10
Training loss: 3.0372536182403564
Validation loss: 2.3511356269159625

Epoch: 267| Step: 0
Training loss: 2.498523235321045
Validation loss: 2.354290141854235

Epoch: 5| Step: 1
Training loss: 2.9701344966888428
Validation loss: 2.3445418022012197

Epoch: 5| Step: 2
Training loss: 2.5994534492492676
Validation loss: 2.338887110833199

Epoch: 5| Step: 3
Training loss: 2.3343822956085205
Validation loss: 2.341355662192068

Epoch: 5| Step: 4
Training loss: 2.3765060901641846
Validation loss: 2.3383607146560506

Epoch: 5| Step: 5
Training loss: 2.6846632957458496
Validation loss: 2.336283432540073

Epoch: 5| Step: 6
Training loss: 2.785717487335205
Validation loss: 2.341688097164195

Epoch: 5| Step: 7
Training loss: 2.1481142044067383
Validation loss: 2.344164261253931

Epoch: 5| Step: 8
Training loss: 1.9002647399902344
Validation loss: 2.3501625137944377

Epoch: 5| Step: 9
Training loss: 2.525596857070923
Validation loss: 2.355437086474511

Epoch: 5| Step: 10
Training loss: 3.3372488021850586
Validation loss: 2.360073786909862

Epoch: 268| Step: 0
Training loss: 2.2658298015594482
Validation loss: 2.36140344219823

Epoch: 5| Step: 1
Training loss: 2.8835370540618896
Validation loss: 2.3617360258615143

Epoch: 5| Step: 2
Training loss: 2.667330265045166
Validation loss: 2.3711613314126128

Epoch: 5| Step: 3
Training loss: 2.552708387374878
Validation loss: 2.3723784672316683

Epoch: 5| Step: 4
Training loss: 1.9119691848754883
Validation loss: 2.3702761639830885

Epoch: 5| Step: 5
Training loss: 3.098720073699951
Validation loss: 2.366607237887639

Epoch: 5| Step: 6
Training loss: 2.5114591121673584
Validation loss: 2.368666797555903

Epoch: 5| Step: 7
Training loss: 2.608720302581787
Validation loss: 2.3628589799327235

Epoch: 5| Step: 8
Training loss: 1.927147626876831
Validation loss: 2.359660825421733

Epoch: 5| Step: 9
Training loss: 2.689908504486084
Validation loss: 2.3443857880048853

Epoch: 5| Step: 10
Training loss: 2.9794840812683105
Validation loss: 2.3448619560528825

Epoch: 269| Step: 0
Training loss: 2.5794942378997803
Validation loss: 2.3465289428669918

Epoch: 5| Step: 1
Training loss: 2.652315616607666
Validation loss: 2.3445866133577082

Epoch: 5| Step: 2
Training loss: 2.7593765258789062
Validation loss: 2.3381365678643666

Epoch: 5| Step: 3
Training loss: 2.0595712661743164
Validation loss: 2.34400184436511

Epoch: 5| Step: 4
Training loss: 2.750189781188965
Validation loss: 2.3418034404836674

Epoch: 5| Step: 5
Training loss: 2.482022523880005
Validation loss: 2.3357740704731276

Epoch: 5| Step: 6
Training loss: 2.4536449909210205
Validation loss: 2.341424044742379

Epoch: 5| Step: 7
Training loss: 2.30926775932312
Validation loss: 2.342243271489297

Epoch: 5| Step: 8
Training loss: 3.206043243408203
Validation loss: 2.3415222232059767

Epoch: 5| Step: 9
Training loss: 2.590750217437744
Validation loss: 2.3546306369125203

Epoch: 5| Step: 10
Training loss: 2.151174306869507
Validation loss: 2.3612756524034726

Epoch: 270| Step: 0
Training loss: 2.591172695159912
Validation loss: 2.3671052994266635

Epoch: 5| Step: 1
Training loss: 2.930248260498047
Validation loss: 2.365366953675465

Epoch: 5| Step: 2
Training loss: 2.538264036178589
Validation loss: 2.373986692838771

Epoch: 5| Step: 3
Training loss: 2.5726287364959717
Validation loss: 2.3769014471320697

Epoch: 5| Step: 4
Training loss: 2.533501625061035
Validation loss: 2.3933878329492386

Epoch: 5| Step: 5
Training loss: 2.667269229888916
Validation loss: 2.3866289982231716

Epoch: 5| Step: 6
Training loss: 2.292978286743164
Validation loss: 2.3845419883728027

Epoch: 5| Step: 7
Training loss: 2.7453901767730713
Validation loss: 2.372041533070226

Epoch: 5| Step: 8
Training loss: 2.2440760135650635
Validation loss: 2.3747471404331986

Epoch: 5| Step: 9
Training loss: 2.7390143871307373
Validation loss: 2.364246683736001

Epoch: 5| Step: 10
Training loss: 2.1925158500671387
Validation loss: 2.3558564468096663

Epoch: 271| Step: 0
Training loss: 2.2244021892547607
Validation loss: 2.3556684140236146

Epoch: 5| Step: 1
Training loss: 2.2265028953552246
Validation loss: 2.360542610127439

Epoch: 5| Step: 2
Training loss: 3.5585219860076904
Validation loss: 2.3496126564600135

Epoch: 5| Step: 3
Training loss: 2.6573920249938965
Validation loss: 2.3458126591097925

Epoch: 5| Step: 4
Training loss: 2.6233818531036377
Validation loss: 2.341206435234316

Epoch: 5| Step: 5
Training loss: 2.557468891143799
Validation loss: 2.338121706439603

Epoch: 5| Step: 6
Training loss: 1.9642932415008545
Validation loss: 2.3385403515190206

Epoch: 5| Step: 7
Training loss: 2.6127023696899414
Validation loss: 2.3408466077619985

Epoch: 5| Step: 8
Training loss: 2.741518020629883
Validation loss: 2.352834209319084

Epoch: 5| Step: 9
Training loss: 2.3113930225372314
Validation loss: 2.3601325147895404

Epoch: 5| Step: 10
Training loss: 2.6867198944091797
Validation loss: 2.3710222603172384

Epoch: 272| Step: 0
Training loss: 2.3436026573181152
Validation loss: 2.367561058331561

Epoch: 5| Step: 1
Training loss: 2.8804173469543457
Validation loss: 2.3605545566928003

Epoch: 5| Step: 2
Training loss: 2.9016454219818115
Validation loss: 2.3637308074582006

Epoch: 5| Step: 3
Training loss: 2.3940467834472656
Validation loss: 2.3480334307557795

Epoch: 5| Step: 4
Training loss: 2.3294742107391357
Validation loss: 2.344203859247187

Epoch: 5| Step: 5
Training loss: 2.6644530296325684
Validation loss: 2.334451044759443

Epoch: 5| Step: 6
Training loss: 2.2709550857543945
Validation loss: 2.344916371889012

Epoch: 5| Step: 7
Training loss: 2.4079439640045166
Validation loss: 2.3335382835839384

Epoch: 5| Step: 8
Training loss: 2.845691204071045
Validation loss: 2.3365577202971264

Epoch: 5| Step: 9
Training loss: 2.968411922454834
Validation loss: 2.336015027056458

Epoch: 5| Step: 10
Training loss: 1.8315322399139404
Validation loss: 2.3462664978478545

Epoch: 273| Step: 0
Training loss: 2.166276693344116
Validation loss: 2.3358210312422885

Epoch: 5| Step: 1
Training loss: 2.5413880348205566
Validation loss: 2.334453187963014

Epoch: 5| Step: 2
Training loss: 2.201629877090454
Validation loss: 2.3531389672269105

Epoch: 5| Step: 3
Training loss: 3.1372456550598145
Validation loss: 2.3457953160808933

Epoch: 5| Step: 4
Training loss: 1.9914172887802124
Validation loss: 2.353355766624533

Epoch: 5| Step: 5
Training loss: 2.4618115425109863
Validation loss: 2.3529433242736326

Epoch: 5| Step: 6
Training loss: 2.854715347290039
Validation loss: 2.3580500387376353

Epoch: 5| Step: 7
Training loss: 2.9863743782043457
Validation loss: 2.3616004579810688

Epoch: 5| Step: 8
Training loss: 2.0707764625549316
Validation loss: 2.357311899944018

Epoch: 5| Step: 9
Training loss: 2.778712511062622
Validation loss: 2.3570138690292195

Epoch: 5| Step: 10
Training loss: 2.8719959259033203
Validation loss: 2.352950270457934

Epoch: 274| Step: 0
Training loss: 2.6507766246795654
Validation loss: 2.3445625279539373

Epoch: 5| Step: 1
Training loss: 2.043808937072754
Validation loss: 2.351443031782745

Epoch: 5| Step: 2
Training loss: 2.9411234855651855
Validation loss: 2.3557610152870097

Epoch: 5| Step: 3
Training loss: 2.4109082221984863
Validation loss: 2.3550451083849837

Epoch: 5| Step: 4
Training loss: 2.1974239349365234
Validation loss: 2.350575029209096

Epoch: 5| Step: 5
Training loss: 2.657860279083252
Validation loss: 2.354698558007517

Epoch: 5| Step: 6
Training loss: 3.005603313446045
Validation loss: 2.3319529487240698

Epoch: 5| Step: 7
Training loss: 2.407074451446533
Validation loss: 2.323409764997421

Epoch: 5| Step: 8
Training loss: 3.0154175758361816
Validation loss: 2.33304524678056

Epoch: 5| Step: 9
Training loss: 2.3410606384277344
Validation loss: 2.3230261661673106

Epoch: 5| Step: 10
Training loss: 2.299351930618286
Validation loss: 2.327016128006802

Epoch: 275| Step: 0
Training loss: 2.7899880409240723
Validation loss: 2.3219219638455297

Epoch: 5| Step: 1
Training loss: 2.5521509647369385
Validation loss: 2.334850572770642

Epoch: 5| Step: 2
Training loss: 2.0902035236358643
Validation loss: 2.3254424936027935

Epoch: 5| Step: 3
Training loss: 2.3737258911132812
Validation loss: 2.332225630360265

Epoch: 5| Step: 4
Training loss: 2.6258554458618164
Validation loss: 2.334420386181083

Epoch: 5| Step: 5
Training loss: 2.5307693481445312
Validation loss: 2.3283804770438903

Epoch: 5| Step: 6
Training loss: 2.53828763961792
Validation loss: 2.3386454812942015

Epoch: 5| Step: 7
Training loss: 2.307340383529663
Validation loss: 2.349490511801935

Epoch: 5| Step: 8
Training loss: 2.721168041229248
Validation loss: 2.3555030092116325

Epoch: 5| Step: 9
Training loss: 2.566398859024048
Validation loss: 2.3696064359398297

Epoch: 5| Step: 10
Training loss: 2.9932613372802734
Validation loss: 2.373770062641431

Epoch: 276| Step: 0
Training loss: 3.4710726737976074
Validation loss: 2.3754174094046316

Epoch: 5| Step: 1
Training loss: 2.268115997314453
Validation loss: 2.351016103580434

Epoch: 5| Step: 2
Training loss: 2.383857011795044
Validation loss: 2.3522279031815065

Epoch: 5| Step: 3
Training loss: 2.4112043380737305
Validation loss: 2.3455071244188535

Epoch: 5| Step: 4
Training loss: 2.4322288036346436
Validation loss: 2.3374374502448627

Epoch: 5| Step: 5
Training loss: 2.7656936645507812
Validation loss: 2.329590830751645

Epoch: 5| Step: 6
Training loss: 2.0562891960144043
Validation loss: 2.3281105436304563

Epoch: 5| Step: 7
Training loss: 2.3684773445129395
Validation loss: 2.319327582595169

Epoch: 5| Step: 8
Training loss: 2.2297568321228027
Validation loss: 2.3220581034178376

Epoch: 5| Step: 9
Training loss: 2.6457855701446533
Validation loss: 2.3225224633370676

Epoch: 5| Step: 10
Training loss: 3.024059534072876
Validation loss: 2.333702874440019

Epoch: 277| Step: 0
Training loss: 2.431870698928833
Validation loss: 2.3320926825205484

Epoch: 5| Step: 1
Training loss: 2.767974615097046
Validation loss: 2.3341333955846806

Epoch: 5| Step: 2
Training loss: 2.8977956771850586
Validation loss: 2.3406094761304956

Epoch: 5| Step: 3
Training loss: 2.065446615219116
Validation loss: 2.337988838072746

Epoch: 5| Step: 4
Training loss: 2.436136245727539
Validation loss: 2.344373174892959

Epoch: 5| Step: 5
Training loss: 2.9210503101348877
Validation loss: 2.354892046220841

Epoch: 5| Step: 6
Training loss: 2.4727158546447754
Validation loss: 2.3417239881330922

Epoch: 5| Step: 7
Training loss: 2.1774065494537354
Validation loss: 2.3342906992922545

Epoch: 5| Step: 8
Training loss: 2.8412604331970215
Validation loss: 2.3309064424166115

Epoch: 5| Step: 9
Training loss: 1.893945336341858
Validation loss: 2.3167311299231743

Epoch: 5| Step: 10
Training loss: 3.1005399227142334
Validation loss: 2.3196685903815815

Epoch: 278| Step: 0
Training loss: 2.635223865509033
Validation loss: 2.314289116090344

Epoch: 5| Step: 1
Training loss: 1.9100205898284912
Validation loss: 2.318535089492798

Epoch: 5| Step: 2
Training loss: 2.7514641284942627
Validation loss: 2.3234973389615297

Epoch: 5| Step: 3
Training loss: 2.801055669784546
Validation loss: 2.323041233965146

Epoch: 5| Step: 4
Training loss: 2.836832046508789
Validation loss: 2.3353330730110087

Epoch: 5| Step: 5
Training loss: 2.3947417736053467
Validation loss: 2.3429803720084568

Epoch: 5| Step: 6
Training loss: 3.365518569946289
Validation loss: 2.3441444314936155

Epoch: 5| Step: 7
Training loss: 2.739025354385376
Validation loss: 2.3601125132653022

Epoch: 5| Step: 8
Training loss: 2.583500385284424
Validation loss: 2.3564747994945896

Epoch: 5| Step: 9
Training loss: 1.7106631994247437
Validation loss: 2.355642307189203

Epoch: 5| Step: 10
Training loss: 2.1531431674957275
Validation loss: 2.3515751861756846

Epoch: 279| Step: 0
Training loss: 2.833728551864624
Validation loss: 2.350887370365922

Epoch: 5| Step: 1
Training loss: 2.6181583404541016
Validation loss: 2.3424971513850714

Epoch: 5| Step: 2
Training loss: 3.0349698066711426
Validation loss: 2.3331777895650556

Epoch: 5| Step: 3
Training loss: 2.2615842819213867
Validation loss: 2.337089861592939

Epoch: 5| Step: 4
Training loss: 2.7108445167541504
Validation loss: 2.3278490407492525

Epoch: 5| Step: 5
Training loss: 2.746516466140747
Validation loss: 2.321662841304656

Epoch: 5| Step: 6
Training loss: 1.7897224426269531
Validation loss: 2.3191162386248187

Epoch: 5| Step: 7
Training loss: 1.9306684732437134
Validation loss: 2.319999731997008

Epoch: 5| Step: 8
Training loss: 2.546355962753296
Validation loss: 2.317366284708823

Epoch: 5| Step: 9
Training loss: 2.6971685886383057
Validation loss: 2.332550064209969

Epoch: 5| Step: 10
Training loss: 2.724921941757202
Validation loss: 2.327576850050239

Epoch: 280| Step: 0
Training loss: 2.5142765045166016
Validation loss: 2.3213579423965944

Epoch: 5| Step: 1
Training loss: 2.639265537261963
Validation loss: 2.319910595493932

Epoch: 5| Step: 2
Training loss: 2.389857769012451
Validation loss: 2.333442916152298

Epoch: 5| Step: 3
Training loss: 2.3642172813415527
Validation loss: 2.339973213852093

Epoch: 5| Step: 4
Training loss: 2.404667377471924
Validation loss: 2.327217125123547

Epoch: 5| Step: 5
Training loss: 3.271101474761963
Validation loss: 2.3301586950978925

Epoch: 5| Step: 6
Training loss: 2.5580058097839355
Validation loss: 2.3308352244797574

Epoch: 5| Step: 7
Training loss: 2.0874221324920654
Validation loss: 2.329466712090277

Epoch: 5| Step: 8
Training loss: 2.1155519485473633
Validation loss: 2.329955239449778

Epoch: 5| Step: 9
Training loss: 2.2556991577148438
Validation loss: 2.333668367837065

Epoch: 5| Step: 10
Training loss: 3.370654821395874
Validation loss: 2.333761517719556

Epoch: 281| Step: 0
Training loss: 2.842881679534912
Validation loss: 2.3434944460468907

Epoch: 5| Step: 1
Training loss: 2.4883999824523926
Validation loss: 2.3459168172651723

Epoch: 5| Step: 2
Training loss: 3.0653977394104004
Validation loss: 2.356835078167659

Epoch: 5| Step: 3
Training loss: 2.0852322578430176
Validation loss: 2.3509867934770483

Epoch: 5| Step: 4
Training loss: 2.0850777626037598
Validation loss: 2.3447307578979

Epoch: 5| Step: 5
Training loss: 2.92767333984375
Validation loss: 2.33015154510416

Epoch: 5| Step: 6
Training loss: 2.5325636863708496
Validation loss: 2.3330546912326606

Epoch: 5| Step: 7
Training loss: 2.4229331016540527
Validation loss: 2.337774527970181

Epoch: 5| Step: 8
Training loss: 2.390314817428589
Validation loss: 2.3285692430311635

Epoch: 5| Step: 9
Training loss: 2.5976369380950928
Validation loss: 2.319847645298127

Epoch: 5| Step: 10
Training loss: 2.473851203918457
Validation loss: 2.31376189057545

Epoch: 282| Step: 0
Training loss: 2.811796188354492
Validation loss: 2.3088325428706344

Epoch: 5| Step: 1
Training loss: 2.3040614128112793
Validation loss: 2.313190593514391

Epoch: 5| Step: 2
Training loss: 2.457368850708008
Validation loss: 2.3269031868186048

Epoch: 5| Step: 3
Training loss: 2.0364387035369873
Validation loss: 2.3202609426231793

Epoch: 5| Step: 4
Training loss: 1.8827072381973267
Validation loss: 2.317754573719476

Epoch: 5| Step: 5
Training loss: 2.6836581230163574
Validation loss: 2.3192328663282495

Epoch: 5| Step: 6
Training loss: 2.7728703022003174
Validation loss: 2.3295010751293552

Epoch: 5| Step: 7
Training loss: 2.902698278427124
Validation loss: 2.328851919020376

Epoch: 5| Step: 8
Training loss: 2.5558695793151855
Validation loss: 2.3332929611206055

Epoch: 5| Step: 9
Training loss: 2.8606433868408203
Validation loss: 2.345068399624158

Epoch: 5| Step: 10
Training loss: 2.5802857875823975
Validation loss: 2.335850005508751

Epoch: 283| Step: 0
Training loss: 2.7125327587127686
Validation loss: 2.3488379293872463

Epoch: 5| Step: 1
Training loss: 2.420170545578003
Validation loss: 2.3363687556277037

Epoch: 5| Step: 2
Training loss: 2.5846445560455322
Validation loss: 2.332959803201819

Epoch: 5| Step: 3
Training loss: 2.4188148975372314
Validation loss: 2.334804706676032

Epoch: 5| Step: 4
Training loss: 2.0718698501586914
Validation loss: 2.331226493722649

Epoch: 5| Step: 5
Training loss: 2.973583936691284
Validation loss: 2.3287523818272415

Epoch: 5| Step: 6
Training loss: 2.8180413246154785
Validation loss: 2.3262466487064155

Epoch: 5| Step: 7
Training loss: 2.5956692695617676
Validation loss: 2.305494849399854

Epoch: 5| Step: 8
Training loss: 1.9538160562515259
Validation loss: 2.3104162498186995

Epoch: 5| Step: 9
Training loss: 2.670560359954834
Validation loss: 2.3040833678296817

Epoch: 5| Step: 10
Training loss: 2.593766212463379
Validation loss: 2.3074175234763854

Epoch: 284| Step: 0
Training loss: 2.270014524459839
Validation loss: 2.3137127584026707

Epoch: 5| Step: 1
Training loss: 2.7076618671417236
Validation loss: 2.3218279295070197

Epoch: 5| Step: 2
Training loss: 2.4560937881469727
Validation loss: 2.3201134051046064

Epoch: 5| Step: 3
Training loss: 2.6852798461914062
Validation loss: 2.331725246162825

Epoch: 5| Step: 4
Training loss: 2.391895055770874
Validation loss: 2.3365719138935046

Epoch: 5| Step: 5
Training loss: 2.265423536300659
Validation loss: 2.3290691632096485

Epoch: 5| Step: 6
Training loss: 3.0820841789245605
Validation loss: 2.33211164833397

Epoch: 5| Step: 7
Training loss: 2.331265926361084
Validation loss: 2.328832498160742

Epoch: 5| Step: 8
Training loss: 2.4383347034454346
Validation loss: 2.3193032613364597

Epoch: 5| Step: 9
Training loss: 2.707210063934326
Validation loss: 2.319919673345422

Epoch: 5| Step: 10
Training loss: 2.4782660007476807
Validation loss: 2.3077635688166462

Epoch: 285| Step: 0
Training loss: 2.089327812194824
Validation loss: 2.3160800600564606

Epoch: 5| Step: 1
Training loss: 3.009995222091675
Validation loss: 2.3146889696839037

Epoch: 5| Step: 2
Training loss: 2.607818365097046
Validation loss: 2.315690414879912

Epoch: 5| Step: 3
Training loss: 2.5112786293029785
Validation loss: 2.326589661259805

Epoch: 5| Step: 4
Training loss: 2.7701821327209473
Validation loss: 2.3308974389106996

Epoch: 5| Step: 5
Training loss: 2.9169955253601074
Validation loss: 2.3273350346472954

Epoch: 5| Step: 6
Training loss: 2.7533867359161377
Validation loss: 2.3289737445051952

Epoch: 5| Step: 7
Training loss: 2.0527865886688232
Validation loss: 2.324026289806571

Epoch: 5| Step: 8
Training loss: 2.326408863067627
Validation loss: 2.327443779155772

Epoch: 5| Step: 9
Training loss: 1.7978512048721313
Validation loss: 2.3242821821602444

Epoch: 5| Step: 10
Training loss: 3.011441707611084
Validation loss: 2.3233879919975036

Epoch: 286| Step: 0
Training loss: 2.090825080871582
Validation loss: 2.332002209078881

Epoch: 5| Step: 1
Training loss: 2.619464159011841
Validation loss: 2.3206657876250563

Epoch: 5| Step: 2
Training loss: 2.8024725914001465
Validation loss: 2.3284716170321227

Epoch: 5| Step: 3
Training loss: 2.431102752685547
Validation loss: 2.324117637449695

Epoch: 5| Step: 4
Training loss: 3.0346927642822266
Validation loss: 2.3358309563770088

Epoch: 5| Step: 5
Training loss: 2.72930645942688
Validation loss: 2.3268333019748813

Epoch: 5| Step: 6
Training loss: 2.6685781478881836
Validation loss: 2.3213395021295034

Epoch: 5| Step: 7
Training loss: 2.130469560623169
Validation loss: 2.3173251177674983

Epoch: 5| Step: 8
Training loss: 2.4127120971679688
Validation loss: 2.3159183456051733

Epoch: 5| Step: 9
Training loss: 2.187426805496216
Validation loss: 2.317698429989558

Epoch: 5| Step: 10
Training loss: 2.679385185241699
Validation loss: 2.310665681797971

Epoch: 287| Step: 0
Training loss: 2.870293617248535
Validation loss: 2.3221350600642543

Epoch: 5| Step: 1
Training loss: 2.5279488563537598
Validation loss: 2.3195211195176646

Epoch: 5| Step: 2
Training loss: 3.1391806602478027
Validation loss: 2.3258978038705806

Epoch: 5| Step: 3
Training loss: 3.3194191455841064
Validation loss: 2.328660880365679

Epoch: 5| Step: 4
Training loss: 2.0685970783233643
Validation loss: 2.333102621057982

Epoch: 5| Step: 5
Training loss: 1.9537675380706787
Validation loss: 2.3298084376960673

Epoch: 5| Step: 6
Training loss: 1.9037790298461914
Validation loss: 2.346232562936762

Epoch: 5| Step: 7
Training loss: 2.7004218101501465
Validation loss: 2.3465751063439155

Epoch: 5| Step: 8
Training loss: 2.168513774871826
Validation loss: 2.335306829021823

Epoch: 5| Step: 9
Training loss: 2.7269768714904785
Validation loss: 2.339824197112873

Epoch: 5| Step: 10
Training loss: 2.289228916168213
Validation loss: 2.338037980500088

Epoch: 288| Step: 0
Training loss: 2.317160129547119
Validation loss: 2.334959719770698

Epoch: 5| Step: 1
Training loss: 2.8124353885650635
Validation loss: 2.341856615517729

Epoch: 5| Step: 2
Training loss: 2.1464195251464844
Validation loss: 2.3317162298387095

Epoch: 5| Step: 3
Training loss: 2.3540680408477783
Validation loss: 2.3354913803838913

Epoch: 5| Step: 4
Training loss: 2.9909145832061768
Validation loss: 2.313061278353455

Epoch: 5| Step: 5
Training loss: 2.143022298812866
Validation loss: 2.3185162441704863

Epoch: 5| Step: 6
Training loss: 1.849745750427246
Validation loss: 2.313910210004417

Epoch: 5| Step: 7
Training loss: 2.702880382537842
Validation loss: 2.3109202282403105

Epoch: 5| Step: 8
Training loss: 2.5308985710144043
Validation loss: 2.3066258533026582

Epoch: 5| Step: 9
Training loss: 3.0491955280303955
Validation loss: 2.303180807380266

Epoch: 5| Step: 10
Training loss: 2.8992843627929688
Validation loss: 2.3065664793855403

Epoch: 289| Step: 0
Training loss: 2.6379528045654297
Validation loss: 2.316608146954608

Epoch: 5| Step: 1
Training loss: 2.1527328491210938
Validation loss: 2.310258012945934

Epoch: 5| Step: 2
Training loss: 2.7415788173675537
Validation loss: 2.3144352000246764

Epoch: 5| Step: 3
Training loss: 2.2304110527038574
Validation loss: 2.315637114227459

Epoch: 5| Step: 4
Training loss: 2.494810104370117
Validation loss: 2.3112941929089126

Epoch: 5| Step: 5
Training loss: 2.3132474422454834
Validation loss: 2.3187502353422103

Epoch: 5| Step: 6
Training loss: 2.5355982780456543
Validation loss: 2.325060295802291

Epoch: 5| Step: 7
Training loss: 3.0521295070648193
Validation loss: 2.325337971410444

Epoch: 5| Step: 8
Training loss: 2.817185878753662
Validation loss: 2.3308853077632126

Epoch: 5| Step: 9
Training loss: 2.667018413543701
Validation loss: 2.3273255594315065

Epoch: 5| Step: 10
Training loss: 1.911596655845642
Validation loss: 2.3229268802109586

Epoch: 290| Step: 0
Training loss: 3.0389389991760254
Validation loss: 2.328377539111722

Epoch: 5| Step: 1
Training loss: 2.506338596343994
Validation loss: 2.3171189420966694

Epoch: 5| Step: 2
Training loss: 2.733764171600342
Validation loss: 2.3036540836416264

Epoch: 5| Step: 3
Training loss: 2.87357234954834
Validation loss: 2.30610716214744

Epoch: 5| Step: 4
Training loss: 2.149010181427002
Validation loss: 2.308729430680634

Epoch: 5| Step: 5
Training loss: 2.2190210819244385
Validation loss: 2.3011905416365592

Epoch: 5| Step: 6
Training loss: 2.8860318660736084
Validation loss: 2.300074500422324

Epoch: 5| Step: 7
Training loss: 1.9674766063690186
Validation loss: 2.307446451597316

Epoch: 5| Step: 8
Training loss: 2.493147850036621
Validation loss: 2.299769775841826

Epoch: 5| Step: 9
Training loss: 2.5749645233154297
Validation loss: 2.2978531827208815

Epoch: 5| Step: 10
Training loss: 2.325838804244995
Validation loss: 2.287693477446033

Epoch: 291| Step: 0
Training loss: 2.724457025527954
Validation loss: 2.295249812064632

Epoch: 5| Step: 1
Training loss: 2.1102497577667236
Validation loss: 2.2989816281103317

Epoch: 5| Step: 2
Training loss: 2.4953091144561768
Validation loss: 2.30591816799615

Epoch: 5| Step: 3
Training loss: 3.2090442180633545
Validation loss: 2.308360320265575

Epoch: 5| Step: 4
Training loss: 2.916876792907715
Validation loss: 2.3133863710588023

Epoch: 5| Step: 5
Training loss: 1.9105113744735718
Validation loss: 2.3214006372677383

Epoch: 5| Step: 6
Training loss: 2.582735061645508
Validation loss: 2.329666591459705

Epoch: 5| Step: 7
Training loss: 2.4752626419067383
Validation loss: 2.328800488543767

Epoch: 5| Step: 8
Training loss: 2.4305546283721924
Validation loss: 2.339207369794128

Epoch: 5| Step: 9
Training loss: 2.4792468547821045
Validation loss: 2.3322366142785675

Epoch: 5| Step: 10
Training loss: 2.350738286972046
Validation loss: 2.3326560143501527

Epoch: 292| Step: 0
Training loss: 2.5803823471069336
Validation loss: 2.3408394808410318

Epoch: 5| Step: 1
Training loss: 2.6429319381713867
Validation loss: 2.3271175943395144

Epoch: 5| Step: 2
Training loss: 1.8947662115097046
Validation loss: 2.3347112081384145

Epoch: 5| Step: 3
Training loss: 2.5089755058288574
Validation loss: 2.3291838451098372

Epoch: 5| Step: 4
Training loss: 2.5403456687927246
Validation loss: 2.3337670423651256

Epoch: 5| Step: 5
Training loss: 2.4435980319976807
Validation loss: 2.323008447565058

Epoch: 5| Step: 6
Training loss: 2.386371374130249
Validation loss: 2.307405912747947

Epoch: 5| Step: 7
Training loss: 2.8322298526763916
Validation loss: 2.3106483849146033

Epoch: 5| Step: 8
Training loss: 2.302201271057129
Validation loss: 2.3079044408695673

Epoch: 5| Step: 9
Training loss: 2.755514144897461
Validation loss: 2.306417203718616

Epoch: 5| Step: 10
Training loss: 2.945389747619629
Validation loss: 2.3015890659824496

Epoch: 293| Step: 0
Training loss: 2.73453426361084
Validation loss: 2.3104275298374954

Epoch: 5| Step: 1
Training loss: 2.0542187690734863
Validation loss: 2.3104408351323937

Epoch: 5| Step: 2
Training loss: 2.151658296585083
Validation loss: 2.3162535031636557

Epoch: 5| Step: 3
Training loss: 2.254652500152588
Validation loss: 2.317291816075643

Epoch: 5| Step: 4
Training loss: 2.1025214195251465
Validation loss: 2.331591493339949

Epoch: 5| Step: 5
Training loss: 2.7171988487243652
Validation loss: 2.3270566181469987

Epoch: 5| Step: 6
Training loss: 2.859884738922119
Validation loss: 2.3345357833370084

Epoch: 5| Step: 7
Training loss: 2.7381300926208496
Validation loss: 2.334976775671846

Epoch: 5| Step: 8
Training loss: 2.67026948928833
Validation loss: 2.3338765354566675

Epoch: 5| Step: 9
Training loss: 2.8541171550750732
Validation loss: 2.326298888011645

Epoch: 5| Step: 10
Training loss: 2.615938186645508
Validation loss: 2.316356037252693

Epoch: 294| Step: 0
Training loss: 2.535637617111206
Validation loss: 2.308663614334599

Epoch: 5| Step: 1
Training loss: 1.8894023895263672
Validation loss: 2.3045510835545038

Epoch: 5| Step: 2
Training loss: 2.858900308609009
Validation loss: 2.3078441363508984

Epoch: 5| Step: 3
Training loss: 2.169785737991333
Validation loss: 2.3101933438290834

Epoch: 5| Step: 4
Training loss: 2.3002638816833496
Validation loss: 2.311997987890756

Epoch: 5| Step: 5
Training loss: 3.3544018268585205
Validation loss: 2.315507904175789

Epoch: 5| Step: 6
Training loss: 3.069899559020996
Validation loss: 2.316136908787553

Epoch: 5| Step: 7
Training loss: 2.5238564014434814
Validation loss: 2.317876074903755

Epoch: 5| Step: 8
Training loss: 1.9795606136322021
Validation loss: 2.3339875769871536

Epoch: 5| Step: 9
Training loss: 3.0313971042633057
Validation loss: 2.319739450690567

Epoch: 5| Step: 10
Training loss: 1.7818286418914795
Validation loss: 2.3145054771054174

Epoch: 295| Step: 0
Training loss: 2.653433322906494
Validation loss: 2.309337008383966

Epoch: 5| Step: 1
Training loss: 2.594837188720703
Validation loss: 2.309808600333429

Epoch: 5| Step: 2
Training loss: 2.6669209003448486
Validation loss: 2.306163105913388

Epoch: 5| Step: 3
Training loss: 2.565429210662842
Validation loss: 2.310535195053265

Epoch: 5| Step: 4
Training loss: 2.3351197242736816
Validation loss: 2.306655437715592

Epoch: 5| Step: 5
Training loss: 2.832850694656372
Validation loss: 2.3075854393743698

Epoch: 5| Step: 6
Training loss: 2.669123411178589
Validation loss: 2.296745123401765

Epoch: 5| Step: 7
Training loss: 2.8585338592529297
Validation loss: 2.303561182432277

Epoch: 5| Step: 8
Training loss: 2.0909810066223145
Validation loss: 2.29869141117219

Epoch: 5| Step: 9
Training loss: 2.3402366638183594
Validation loss: 2.3060690023565806

Epoch: 5| Step: 10
Training loss: 1.957025408744812
Validation loss: 2.2933242474832842

Epoch: 296| Step: 0
Training loss: 2.828535556793213
Validation loss: 2.2994544044617684

Epoch: 5| Step: 1
Training loss: 1.5308527946472168
Validation loss: 2.304986592262022

Epoch: 5| Step: 2
Training loss: 2.7359020709991455
Validation loss: 2.3103836351825344

Epoch: 5| Step: 3
Training loss: 2.6293442249298096
Validation loss: 2.3162391339578936

Epoch: 5| Step: 4
Training loss: 2.095900297164917
Validation loss: 2.3259392681942193

Epoch: 5| Step: 5
Training loss: 2.095959186553955
Validation loss: 2.3257034965740737

Epoch: 5| Step: 6
Training loss: 2.9783451557159424
Validation loss: 2.333405827963224

Epoch: 5| Step: 7
Training loss: 2.5671329498291016
Validation loss: 2.3319879578005884

Epoch: 5| Step: 8
Training loss: 2.452796459197998
Validation loss: 2.329118979874478

Epoch: 5| Step: 9
Training loss: 2.6473050117492676
Validation loss: 2.3244786698331117

Epoch: 5| Step: 10
Training loss: 3.2259328365325928
Validation loss: 2.31609671859331

Epoch: 297| Step: 0
Training loss: 2.227290391921997
Validation loss: 2.3188701086146857

Epoch: 5| Step: 1
Training loss: 2.4909558296203613
Validation loss: 2.319380731992824

Epoch: 5| Step: 2
Training loss: 3.214137315750122
Validation loss: 2.3190423416835007

Epoch: 5| Step: 3
Training loss: 2.938887119293213
Validation loss: 2.316084167008759

Epoch: 5| Step: 4
Training loss: 2.458350658416748
Validation loss: 2.3213908236513854

Epoch: 5| Step: 5
Training loss: 2.131315231323242
Validation loss: 2.3121207452589467

Epoch: 5| Step: 6
Training loss: 2.9734573364257812
Validation loss: 2.3181820684863674

Epoch: 5| Step: 7
Training loss: 2.0671260356903076
Validation loss: 2.3226450335594917

Epoch: 5| Step: 8
Training loss: 2.4818294048309326
Validation loss: 2.321546862202306

Epoch: 5| Step: 9
Training loss: 2.142214775085449
Validation loss: 2.325603054415795

Epoch: 5| Step: 10
Training loss: 2.508469581604004
Validation loss: 2.334102363996608

Epoch: 298| Step: 0
Training loss: 2.7669217586517334
Validation loss: 2.3375354248990297

Epoch: 5| Step: 1
Training loss: 2.437155246734619
Validation loss: 2.3310668929930656

Epoch: 5| Step: 2
Training loss: 2.147798538208008
Validation loss: 2.3244049626012004

Epoch: 5| Step: 3
Training loss: 1.6136410236358643
Validation loss: 2.3236604198332755

Epoch: 5| Step: 4
Training loss: 2.1447622776031494
Validation loss: 2.3091509598557667

Epoch: 5| Step: 5
Training loss: 2.87480092048645
Validation loss: 2.3086524189159436

Epoch: 5| Step: 6
Training loss: 2.062183141708374
Validation loss: 2.3019879402652865

Epoch: 5| Step: 7
Training loss: 3.0207269191741943
Validation loss: 2.298742507093696

Epoch: 5| Step: 8
Training loss: 3.0696940422058105
Validation loss: 2.3022194946965864

Epoch: 5| Step: 9
Training loss: 2.5018208026885986
Validation loss: 2.304883498017506

Epoch: 5| Step: 10
Training loss: 3.004199743270874
Validation loss: 2.3015764067249913

Epoch: 299| Step: 0
Training loss: 1.929807424545288
Validation loss: 2.2941445612138316

Epoch: 5| Step: 1
Training loss: 2.889986515045166
Validation loss: 2.3073652803256945

Epoch: 5| Step: 2
Training loss: 2.121920108795166
Validation loss: 2.2992642874358804

Epoch: 5| Step: 3
Training loss: 2.290215015411377
Validation loss: 2.310790104250754

Epoch: 5| Step: 4
Training loss: 2.3194496631622314
Validation loss: 2.2953675587972007

Epoch: 5| Step: 5
Training loss: 2.7724769115448
Validation loss: 2.2934347532128774

Epoch: 5| Step: 6
Training loss: 2.4198362827301025
Validation loss: 2.301940402676982

Epoch: 5| Step: 7
Training loss: 2.835062026977539
Validation loss: 2.3021956284840903

Epoch: 5| Step: 8
Training loss: 3.325709819793701
Validation loss: 2.307035797385759

Epoch: 5| Step: 9
Training loss: 2.3454456329345703
Validation loss: 2.2979277949179373

Epoch: 5| Step: 10
Training loss: 2.336926221847534
Validation loss: 2.313242817437777

Epoch: 300| Step: 0
Training loss: 2.529649496078491
Validation loss: 2.323264411700669

Epoch: 5| Step: 1
Training loss: 2.8766767978668213
Validation loss: 2.324318246174884

Epoch: 5| Step: 2
Training loss: 2.7255940437316895
Validation loss: 2.327563965192405

Epoch: 5| Step: 3
Training loss: 2.3177216053009033
Validation loss: 2.321912452738772

Epoch: 5| Step: 4
Training loss: 2.86018705368042
Validation loss: 2.313249521358039

Epoch: 5| Step: 5
Training loss: 2.012382984161377
Validation loss: 2.3279195190757833

Epoch: 5| Step: 6
Training loss: 2.8842363357543945
Validation loss: 2.3264484713154454

Epoch: 5| Step: 7
Training loss: 2.4757208824157715
Validation loss: 2.3332712791299306

Epoch: 5| Step: 8
Training loss: 2.8110766410827637
Validation loss: 2.318264122932188

Epoch: 5| Step: 9
Training loss: 1.9522521495819092
Validation loss: 2.3226641378095074

Epoch: 5| Step: 10
Training loss: 2.020811080932617
Validation loss: 2.3162739071794736

Epoch: 301| Step: 0
Training loss: 2.8796706199645996
Validation loss: 2.302988090822774

Epoch: 5| Step: 1
Training loss: 2.8422582149505615
Validation loss: 2.2920577269728466

Epoch: 5| Step: 2
Training loss: 2.001187801361084
Validation loss: 2.2913490008282404

Epoch: 5| Step: 3
Training loss: 2.8869144916534424
Validation loss: 2.288885480614119

Epoch: 5| Step: 4
Training loss: 2.557316303253174
Validation loss: 2.296726703643799

Epoch: 5| Step: 5
Training loss: 2.582524061203003
Validation loss: 2.304126197291959

Epoch: 5| Step: 6
Training loss: 2.21652889251709
Validation loss: 2.308902899424235

Epoch: 5| Step: 7
Training loss: 1.6668888330459595
Validation loss: 2.31300324650221

Epoch: 5| Step: 8
Training loss: 2.74255108833313
Validation loss: 2.323161289256106

Epoch: 5| Step: 9
Training loss: 2.559943437576294
Validation loss: 2.327213054062218

Epoch: 5| Step: 10
Training loss: 2.689199686050415
Validation loss: 2.3205967487827426

Epoch: 302| Step: 0
Training loss: 2.4491162300109863
Validation loss: 2.323989032417215

Epoch: 5| Step: 1
Training loss: 2.5653433799743652
Validation loss: 2.3256518840789795

Epoch: 5| Step: 2
Training loss: 2.692572593688965
Validation loss: 2.320413907368978

Epoch: 5| Step: 3
Training loss: 2.0036873817443848
Validation loss: 2.3240342229925175

Epoch: 5| Step: 4
Training loss: 2.2458817958831787
Validation loss: 2.324944851219013

Epoch: 5| Step: 5
Training loss: 2.3832154273986816
Validation loss: 2.3244970331909838

Epoch: 5| Step: 6
Training loss: 2.4127116203308105
Validation loss: 2.32177476216388

Epoch: 5| Step: 7
Training loss: 3.0894813537597656
Validation loss: 2.3145498511611775

Epoch: 5| Step: 8
Training loss: 2.4737191200256348
Validation loss: 2.320900711961972

Epoch: 5| Step: 9
Training loss: 2.5508193969726562
Validation loss: 2.3191251165123394

Epoch: 5| Step: 10
Training loss: 2.785897731781006
Validation loss: 2.31603652943847

Epoch: 303| Step: 0
Training loss: 1.917188048362732
Validation loss: 2.3032907849998883

Epoch: 5| Step: 1
Training loss: 2.6469826698303223
Validation loss: 2.287702452751898

Epoch: 5| Step: 2
Training loss: 2.1855645179748535
Validation loss: 2.286619378674415

Epoch: 5| Step: 3
Training loss: 3.131551742553711
Validation loss: 2.2928181207308205

Epoch: 5| Step: 4
Training loss: 2.608585834503174
Validation loss: 2.287474045189478

Epoch: 5| Step: 5
Training loss: 2.145049810409546
Validation loss: 2.292110614879157

Epoch: 5| Step: 6
Training loss: 2.8953206539154053
Validation loss: 2.288382391775808

Epoch: 5| Step: 7
Training loss: 2.218245029449463
Validation loss: 2.2919785232954126

Epoch: 5| Step: 8
Training loss: 2.402442216873169
Validation loss: 2.28802292577682

Epoch: 5| Step: 9
Training loss: 2.1519689559936523
Validation loss: 2.2997970119599374

Epoch: 5| Step: 10
Training loss: 3.3672659397125244
Validation loss: 2.31057168335043

Epoch: 304| Step: 0
Training loss: 2.8010103702545166
Validation loss: 2.311088167211061

Epoch: 5| Step: 1
Training loss: 2.9126782417297363
Validation loss: 2.32724485089702

Epoch: 5| Step: 2
Training loss: 2.4437832832336426
Validation loss: 2.3492843335674656

Epoch: 5| Step: 3
Training loss: 2.4913134574890137
Validation loss: 2.338937756835773

Epoch: 5| Step: 4
Training loss: 2.477931499481201
Validation loss: 2.3419811443615983

Epoch: 5| Step: 5
Training loss: 2.126499891281128
Validation loss: 2.332095374343216

Epoch: 5| Step: 6
Training loss: 2.903693675994873
Validation loss: 2.3258381889712427

Epoch: 5| Step: 7
Training loss: 2.4204139709472656
Validation loss: 2.307798126692413

Epoch: 5| Step: 8
Training loss: 2.428774356842041
Validation loss: 2.2878120842800347

Epoch: 5| Step: 9
Training loss: 2.232083320617676
Validation loss: 2.290361153182163

Epoch: 5| Step: 10
Training loss: 2.404668092727661
Validation loss: 2.297086678525453

Epoch: 305| Step: 0
Training loss: 2.416858196258545
Validation loss: 2.290482005765361

Epoch: 5| Step: 1
Training loss: 2.6856117248535156
Validation loss: 2.2948474166213826

Epoch: 5| Step: 2
Training loss: 2.797772169113159
Validation loss: 2.299222238602177

Epoch: 5| Step: 3
Training loss: 3.224452257156372
Validation loss: 2.296514179116936

Epoch: 5| Step: 4
Training loss: 3.098327159881592
Validation loss: 2.2976793627585135

Epoch: 5| Step: 5
Training loss: 2.439892530441284
Validation loss: 2.294956632839736

Epoch: 5| Step: 6
Training loss: 2.0115113258361816
Validation loss: 2.291735336344729

Epoch: 5| Step: 7
Training loss: 2.11163330078125
Validation loss: 2.2896972548577095

Epoch: 5| Step: 8
Training loss: 2.1579558849334717
Validation loss: 2.304790965972408

Epoch: 5| Step: 9
Training loss: 2.4381957054138184
Validation loss: 2.3039358021110616

Epoch: 5| Step: 10
Training loss: 2.1492440700531006
Validation loss: 2.3062607114033034

Epoch: 306| Step: 0
Training loss: 2.1223556995391846
Validation loss: 2.315075223163892

Epoch: 5| Step: 1
Training loss: 2.576847791671753
Validation loss: 2.3219223201915784

Epoch: 5| Step: 2
Training loss: 3.095642566680908
Validation loss: 2.3152655965538433

Epoch: 5| Step: 3
Training loss: 2.6482551097869873
Validation loss: 2.3259551909662064

Epoch: 5| Step: 4
Training loss: 2.2267746925354004
Validation loss: 2.321688372601745

Epoch: 5| Step: 5
Training loss: 2.2461130619049072
Validation loss: 2.3224516402008715

Epoch: 5| Step: 6
Training loss: 2.8527181148529053
Validation loss: 2.312457646093061

Epoch: 5| Step: 7
Training loss: 2.571497678756714
Validation loss: 2.3128386774370746

Epoch: 5| Step: 8
Training loss: 2.3781232833862305
Validation loss: 2.297113085305819

Epoch: 5| Step: 9
Training loss: 2.533928871154785
Validation loss: 2.292747838522798

Epoch: 5| Step: 10
Training loss: 2.2826895713806152
Validation loss: 2.297013162284769

Epoch: 307| Step: 0
Training loss: 2.109433650970459
Validation loss: 2.290815491830149

Epoch: 5| Step: 1
Training loss: 2.1792232990264893
Validation loss: 2.2903914067053024

Epoch: 5| Step: 2
Training loss: 2.0805611610412598
Validation loss: 2.3001862341357815

Epoch: 5| Step: 3
Training loss: 3.037659168243408
Validation loss: 2.296087611106134

Epoch: 5| Step: 4
Training loss: 2.0728747844696045
Validation loss: 2.2988950001296176

Epoch: 5| Step: 5
Training loss: 2.9883666038513184
Validation loss: 2.303712930730594

Epoch: 5| Step: 6
Training loss: 2.8691201210021973
Validation loss: 2.3046151707249303

Epoch: 5| Step: 7
Training loss: 1.8782821893692017
Validation loss: 2.301319565824283

Epoch: 5| Step: 8
Training loss: 2.390807867050171
Validation loss: 2.2984340729251986

Epoch: 5| Step: 9
Training loss: 3.243061065673828
Validation loss: 2.304770618356684

Epoch: 5| Step: 10
Training loss: 2.663353681564331
Validation loss: 2.3056873557388142

Epoch: 308| Step: 0
Training loss: 2.1604013442993164
Validation loss: 2.304024483567925

Epoch: 5| Step: 1
Training loss: 2.5651533603668213
Validation loss: 2.3006301849119124

Epoch: 5| Step: 2
Training loss: 2.3642401695251465
Validation loss: 2.316249224447435

Epoch: 5| Step: 3
Training loss: 2.338270664215088
Validation loss: 2.31137861487686

Epoch: 5| Step: 4
Training loss: 2.4813475608825684
Validation loss: 2.321796759482353

Epoch: 5| Step: 5
Training loss: 2.1354520320892334
Validation loss: 2.3215584857489473

Epoch: 5| Step: 6
Training loss: 2.801877021789551
Validation loss: 2.3185509251010035

Epoch: 5| Step: 7
Training loss: 2.446908473968506
Validation loss: 2.31230438909223

Epoch: 5| Step: 8
Training loss: 2.527578830718994
Validation loss: 2.3089467684427896

Epoch: 5| Step: 9
Training loss: 2.8213512897491455
Validation loss: 2.29322454878079

Epoch: 5| Step: 10
Training loss: 2.880687952041626
Validation loss: 2.2940668777752946

Epoch: 309| Step: 0
Training loss: 2.618924856185913
Validation loss: 2.281092923174622

Epoch: 5| Step: 1
Training loss: 2.39874529838562
Validation loss: 2.281965730010822

Epoch: 5| Step: 2
Training loss: 2.534165859222412
Validation loss: 2.279378306481146

Epoch: 5| Step: 3
Training loss: 2.6867122650146484
Validation loss: 2.2797183221386326

Epoch: 5| Step: 4
Training loss: 2.7610421180725098
Validation loss: 2.2817273421954085

Epoch: 5| Step: 5
Training loss: 2.5083351135253906
Validation loss: 2.274651860678068

Epoch: 5| Step: 6
Training loss: 2.4600751399993896
Validation loss: 2.2675224055526075

Epoch: 5| Step: 7
Training loss: 2.5537173748016357
Validation loss: 2.271435031326868

Epoch: 5| Step: 8
Training loss: 2.052401065826416
Validation loss: 2.273002524529734

Epoch: 5| Step: 9
Training loss: 2.454552412033081
Validation loss: 2.278059728683964

Epoch: 5| Step: 10
Training loss: 2.455023765563965
Validation loss: 2.279311413406044

Epoch: 310| Step: 0
Training loss: 2.2367496490478516
Validation loss: 2.2970758535528697

Epoch: 5| Step: 1
Training loss: 2.40089750289917
Validation loss: 2.315842141387283

Epoch: 5| Step: 2
Training loss: 2.8899035453796387
Validation loss: 2.3268081180510984

Epoch: 5| Step: 3
Training loss: 2.180612087249756
Validation loss: 2.319147353531212

Epoch: 5| Step: 4
Training loss: 2.9635117053985596
Validation loss: 2.3207996096662296

Epoch: 5| Step: 5
Training loss: 2.9842536449432373
Validation loss: 2.3153805066180486

Epoch: 5| Step: 6
Training loss: 3.0795321464538574
Validation loss: 2.3150088735806045

Epoch: 5| Step: 7
Training loss: 2.2038142681121826
Validation loss: 2.3076330513082524

Epoch: 5| Step: 8
Training loss: 2.8113415241241455
Validation loss: 2.297116817966584

Epoch: 5| Step: 9
Training loss: 1.915360689163208
Validation loss: 2.289291907382268

Epoch: 5| Step: 10
Training loss: 1.7056611776351929
Validation loss: 2.2872448890439925

Epoch: 311| Step: 0
Training loss: 2.1407034397125244
Validation loss: 2.2860734911375147

Epoch: 5| Step: 1
Training loss: 2.563154935836792
Validation loss: 2.2865061016492945

Epoch: 5| Step: 2
Training loss: 2.230010986328125
Validation loss: 2.282897780018468

Epoch: 5| Step: 3
Training loss: 2.4906115531921387
Validation loss: 2.287193536758423

Epoch: 5| Step: 4
Training loss: 2.4786925315856934
Validation loss: 2.2799991125701577

Epoch: 5| Step: 5
Training loss: 2.6451804637908936
Validation loss: 2.278688088540108

Epoch: 5| Step: 6
Training loss: 2.265155792236328
Validation loss: 2.27838497777139

Epoch: 5| Step: 7
Training loss: 2.7480521202087402
Validation loss: 2.2836866481329805

Epoch: 5| Step: 8
Training loss: 1.860100507736206
Validation loss: 2.2876999621750205

Epoch: 5| Step: 9
Training loss: 3.4799094200134277
Validation loss: 2.2833615169730237

Epoch: 5| Step: 10
Training loss: 2.553581953048706
Validation loss: 2.293113459822952

Epoch: 312| Step: 0
Training loss: 2.398805618286133
Validation loss: 2.3002599157312864

Epoch: 5| Step: 1
Training loss: 2.380592107772827
Validation loss: 2.295574903488159

Epoch: 5| Step: 2
Training loss: 2.421494722366333
Validation loss: 2.304155913732385

Epoch: 5| Step: 3
Training loss: 2.3633370399475098
Validation loss: 2.307461369422174

Epoch: 5| Step: 4
Training loss: 2.516918897628784
Validation loss: 2.3110211023720364

Epoch: 5| Step: 5
Training loss: 1.808908462524414
Validation loss: 2.306452510177448

Epoch: 5| Step: 6
Training loss: 2.312662124633789
Validation loss: 2.293236024918095

Epoch: 5| Step: 7
Training loss: 3.068463087081909
Validation loss: 2.2802329858144126

Epoch: 5| Step: 8
Training loss: 2.2287914752960205
Validation loss: 2.278398222820733

Epoch: 5| Step: 9
Training loss: 3.1453857421875
Validation loss: 2.282037337621053

Epoch: 5| Step: 10
Training loss: 2.679198741912842
Validation loss: 2.2707100376006095

Epoch: 313| Step: 0
Training loss: 2.291818380355835
Validation loss: 2.2684173173801874

Epoch: 5| Step: 1
Training loss: 2.3727684020996094
Validation loss: 2.2751468125210015

Epoch: 5| Step: 2
Training loss: 2.3306639194488525
Validation loss: 2.279500581884897

Epoch: 5| Step: 3
Training loss: 2.093557596206665
Validation loss: 2.2720340682614233

Epoch: 5| Step: 4
Training loss: 2.658966064453125
Validation loss: 2.2733049315790974

Epoch: 5| Step: 5
Training loss: 2.6297221183776855
Validation loss: 2.2706907308229836

Epoch: 5| Step: 6
Training loss: 2.386099338531494
Validation loss: 2.270570711422992

Epoch: 5| Step: 7
Training loss: 2.774698495864868
Validation loss: 2.2698868346470658

Epoch: 5| Step: 8
Training loss: 1.8430461883544922
Validation loss: 2.2705052206593175

Epoch: 5| Step: 9
Training loss: 3.2408814430236816
Validation loss: 2.283705316564088

Epoch: 5| Step: 10
Training loss: 2.8161699771881104
Validation loss: 2.2927550282529605

Epoch: 314| Step: 0
Training loss: 2.788661003112793
Validation loss: 2.2863655987606255

Epoch: 5| Step: 1
Training loss: 2.770740270614624
Validation loss: 2.286129582312799

Epoch: 5| Step: 2
Training loss: 3.1628565788269043
Validation loss: 2.2903207040602163

Epoch: 5| Step: 3
Training loss: 2.528813123703003
Validation loss: 2.2938356476445354

Epoch: 5| Step: 4
Training loss: 2.128772258758545
Validation loss: 2.2803835766289824

Epoch: 5| Step: 5
Training loss: 1.8908088207244873
Validation loss: 2.2928185591133694

Epoch: 5| Step: 6
Training loss: 2.402924060821533
Validation loss: 2.291824161365468

Epoch: 5| Step: 7
Training loss: 2.7203259468078613
Validation loss: 2.2822930018107095

Epoch: 5| Step: 8
Training loss: 1.9687515497207642
Validation loss: 2.2914286787791918

Epoch: 5| Step: 9
Training loss: 2.4212119579315186
Validation loss: 2.277316349808888

Epoch: 5| Step: 10
Training loss: 2.6070642471313477
Validation loss: 2.2850440445766655

Epoch: 315| Step: 0
Training loss: 2.9242987632751465
Validation loss: 2.287188373586183

Epoch: 5| Step: 1
Training loss: 1.9072563648223877
Validation loss: 2.2877331549121487

Epoch: 5| Step: 2
Training loss: 2.656735897064209
Validation loss: 2.2791580859050957

Epoch: 5| Step: 3
Training loss: 2.498805284500122
Validation loss: 2.283933707462844

Epoch: 5| Step: 4
Training loss: 2.4266722202301025
Validation loss: 2.2890771742789977

Epoch: 5| Step: 5
Training loss: 2.656208038330078
Validation loss: 2.2825943449492097

Epoch: 5| Step: 6
Training loss: 2.310354471206665
Validation loss: 2.29232523774588

Epoch: 5| Step: 7
Training loss: 2.005781888961792
Validation loss: 2.286178655521844

Epoch: 5| Step: 8
Training loss: 2.8026041984558105
Validation loss: 2.2825530331621886

Epoch: 5| Step: 9
Training loss: 2.9754202365875244
Validation loss: 2.276640692064839

Epoch: 5| Step: 10
Training loss: 2.08028507232666
Validation loss: 2.2827626300114456

Epoch: 316| Step: 0
Training loss: 2.753880023956299
Validation loss: 2.2730098808965375

Epoch: 5| Step: 1
Training loss: 2.5802693367004395
Validation loss: 2.281472343270497

Epoch: 5| Step: 2
Training loss: 2.0076904296875
Validation loss: 2.2852290958486576

Epoch: 5| Step: 3
Training loss: 2.616180896759033
Validation loss: 2.2710550523573354

Epoch: 5| Step: 4
Training loss: 2.546865940093994
Validation loss: 2.270366158536685

Epoch: 5| Step: 5
Training loss: 2.069267749786377
Validation loss: 2.267863306947934

Epoch: 5| Step: 6
Training loss: 2.632861614227295
Validation loss: 2.281649684393278

Epoch: 5| Step: 7
Training loss: 2.3788695335388184
Validation loss: 2.2794718588552167

Epoch: 5| Step: 8
Training loss: 2.264418125152588
Validation loss: 2.2829630246726413

Epoch: 5| Step: 9
Training loss: 2.8478949069976807
Validation loss: 2.283331532632151

Epoch: 5| Step: 10
Training loss: 2.6871092319488525
Validation loss: 2.295433900689566

Epoch: 317| Step: 0
Training loss: 3.0293052196502686
Validation loss: 2.2963330027877644

Epoch: 5| Step: 1
Training loss: 2.431234121322632
Validation loss: 2.2999927664315827

Epoch: 5| Step: 2
Training loss: 1.9175851345062256
Validation loss: 2.306632593113889

Epoch: 5| Step: 3
Training loss: 2.18485689163208
Validation loss: 2.310508299899358

Epoch: 5| Step: 4
Training loss: 2.294800043106079
Validation loss: 2.3055988088730843

Epoch: 5| Step: 5
Training loss: 2.5273900032043457
Validation loss: 2.2975859154937086

Epoch: 5| Step: 6
Training loss: 2.994154691696167
Validation loss: 2.305552795369138

Epoch: 5| Step: 7
Training loss: 2.9882609844207764
Validation loss: 2.29354202875527

Epoch: 5| Step: 8
Training loss: 2.343034029006958
Validation loss: 2.2957168548337874

Epoch: 5| Step: 9
Training loss: 2.3593051433563232
Validation loss: 2.281915359599616

Epoch: 5| Step: 10
Training loss: 2.132997751235962
Validation loss: 2.2864672009662916

Epoch: 318| Step: 0
Training loss: 2.354506731033325
Validation loss: 2.278777922353437

Epoch: 5| Step: 1
Training loss: 3.1980769634246826
Validation loss: 2.290395895640055

Epoch: 5| Step: 2
Training loss: 3.315232753753662
Validation loss: 2.2926794944270963

Epoch: 5| Step: 3
Training loss: 2.7426133155822754
Validation loss: 2.2990668460886967

Epoch: 5| Step: 4
Training loss: 1.7030060291290283
Validation loss: 2.295533218691426

Epoch: 5| Step: 5
Training loss: 1.840397834777832
Validation loss: 2.290322724209037

Epoch: 5| Step: 6
Training loss: 1.954498052597046
Validation loss: 2.292611470786474

Epoch: 5| Step: 7
Training loss: 2.1515700817108154
Validation loss: 2.29755493902391

Epoch: 5| Step: 8
Training loss: 3.0141825675964355
Validation loss: 2.3007114420654955

Epoch: 5| Step: 9
Training loss: 2.216904878616333
Validation loss: 2.3183796713429112

Epoch: 5| Step: 10
Training loss: 2.9240615367889404
Validation loss: 2.3354828639697005

Epoch: 319| Step: 0
Training loss: 2.400075912475586
Validation loss: 2.356262312140516

Epoch: 5| Step: 1
Training loss: 3.2121033668518066
Validation loss: 2.3670067274442284

Epoch: 5| Step: 2
Training loss: 2.249436616897583
Validation loss: 2.361901770355881

Epoch: 5| Step: 3
Training loss: 2.2502424716949463
Validation loss: 2.3230325739870787

Epoch: 5| Step: 4
Training loss: 2.117434024810791
Validation loss: 2.2964580494870424

Epoch: 5| Step: 5
Training loss: 2.0753185749053955
Validation loss: 2.2817890823528333

Epoch: 5| Step: 6
Training loss: 2.7021889686584473
Validation loss: 2.2775490309602473

Epoch: 5| Step: 7
Training loss: 2.0474581718444824
Validation loss: 2.2736747957045034

Epoch: 5| Step: 8
Training loss: 3.1845433712005615
Validation loss: 2.272738315725839

Epoch: 5| Step: 9
Training loss: 2.8077425956726074
Validation loss: 2.2708351612091064

Epoch: 5| Step: 10
Training loss: 2.4361133575439453
Validation loss: 2.27640018668226

Epoch: 320| Step: 0
Training loss: 2.3319032192230225
Validation loss: 2.2807692558534685

Epoch: 5| Step: 1
Training loss: 2.4572596549987793
Validation loss: 2.281199687270708

Epoch: 5| Step: 2
Training loss: 2.407376527786255
Validation loss: 2.2848279296710925

Epoch: 5| Step: 3
Training loss: 2.181020975112915
Validation loss: 2.2794261440154044

Epoch: 5| Step: 4
Training loss: 2.7886643409729004
Validation loss: 2.2694849609046854

Epoch: 5| Step: 5
Training loss: 2.5458872318267822
Validation loss: 2.2778106325416156

Epoch: 5| Step: 6
Training loss: 2.232326030731201
Validation loss: 2.272299987013622

Epoch: 5| Step: 7
Training loss: 2.4455885887145996
Validation loss: 2.2736615660370036

Epoch: 5| Step: 8
Training loss: 2.5364747047424316
Validation loss: 2.276099479326638

Epoch: 5| Step: 9
Training loss: 3.255659818649292
Validation loss: 2.2843645772626324

Epoch: 5| Step: 10
Training loss: 2.125174045562744
Validation loss: 2.294624146594796

Epoch: 321| Step: 0
Training loss: 2.7640814781188965
Validation loss: 2.300391099786246

Epoch: 5| Step: 1
Training loss: 2.4183199405670166
Validation loss: 2.286295872862621

Epoch: 5| Step: 2
Training loss: 2.1193509101867676
Validation loss: 2.285154425969688

Epoch: 5| Step: 3
Training loss: 3.184065580368042
Validation loss: 2.2772952664283013

Epoch: 5| Step: 4
Training loss: 2.451554536819458
Validation loss: 2.2721135231756393

Epoch: 5| Step: 5
Training loss: 2.1242027282714844
Validation loss: 2.2692593105377687

Epoch: 5| Step: 6
Training loss: 2.1681017875671387
Validation loss: 2.271136631247818

Epoch: 5| Step: 7
Training loss: 2.6853346824645996
Validation loss: 2.260364091524514

Epoch: 5| Step: 8
Training loss: 2.268136501312256
Validation loss: 2.2651048911515104

Epoch: 5| Step: 9
Training loss: 2.333620071411133
Validation loss: 2.2672258230947677

Epoch: 5| Step: 10
Training loss: 2.8244519233703613
Validation loss: 2.271200203126477

Epoch: 322| Step: 0
Training loss: 2.113399028778076
Validation loss: 2.2699768466334187

Epoch: 5| Step: 1
Training loss: 2.4517102241516113
Validation loss: 2.264458994711599

Epoch: 5| Step: 2
Training loss: 2.875861883163452
Validation loss: 2.2706613591922227

Epoch: 5| Step: 3
Training loss: 2.6534054279327393
Validation loss: 2.273160688338741

Epoch: 5| Step: 4
Training loss: 2.526400327682495
Validation loss: 2.2687710997878865

Epoch: 5| Step: 5
Training loss: 2.180344343185425
Validation loss: 2.269232616629652

Epoch: 5| Step: 6
Training loss: 2.4740421772003174
Validation loss: 2.2703656355539956

Epoch: 5| Step: 7
Training loss: 2.615004301071167
Validation loss: 2.266445520103619

Epoch: 5| Step: 8
Training loss: 2.6607003211975098
Validation loss: 2.261669676790955

Epoch: 5| Step: 9
Training loss: 2.4689278602600098
Validation loss: 2.269646365155456

Epoch: 5| Step: 10
Training loss: 2.1497325897216797
Validation loss: 2.2685531211155716

Epoch: 323| Step: 0
Training loss: 2.435850143432617
Validation loss: 2.265752520612491

Epoch: 5| Step: 1
Training loss: 2.5889594554901123
Validation loss: 2.270792757311175

Epoch: 5| Step: 2
Training loss: 2.9246325492858887
Validation loss: 2.2600532065155687

Epoch: 5| Step: 3
Training loss: 2.006920099258423
Validation loss: 2.270963106104123

Epoch: 5| Step: 4
Training loss: 2.6832380294799805
Validation loss: 2.2695275378483597

Epoch: 5| Step: 5
Training loss: 1.7227427959442139
Validation loss: 2.267854893079368

Epoch: 5| Step: 6
Training loss: 2.576831102371216
Validation loss: 2.261258427814771

Epoch: 5| Step: 7
Training loss: 2.370868682861328
Validation loss: 2.274940406122515

Epoch: 5| Step: 8
Training loss: 2.838585376739502
Validation loss: 2.2698451062684417

Epoch: 5| Step: 9
Training loss: 2.590573787689209
Validation loss: 2.2695001735482165

Epoch: 5| Step: 10
Training loss: 2.4178991317749023
Validation loss: 2.2734774594665854

Epoch: 324| Step: 0
Training loss: 2.4467039108276367
Validation loss: 2.281488718525056

Epoch: 5| Step: 1
Training loss: 2.104005813598633
Validation loss: 2.27633257578778

Epoch: 5| Step: 2
Training loss: 2.2819247245788574
Validation loss: 2.280669063650152

Epoch: 5| Step: 3
Training loss: 2.6989471912384033
Validation loss: 2.2849659381374234

Epoch: 5| Step: 4
Training loss: 2.0679867267608643
Validation loss: 2.2853674580973964

Epoch: 5| Step: 5
Training loss: 2.759181022644043
Validation loss: 2.296956508390365

Epoch: 5| Step: 6
Training loss: 2.7106635570526123
Validation loss: 2.303560241576164

Epoch: 5| Step: 7
Training loss: 2.6147830486297607
Validation loss: 2.299863656361898

Epoch: 5| Step: 8
Training loss: 2.0158023834228516
Validation loss: 2.295866051027852

Epoch: 5| Step: 9
Training loss: 2.7804863452911377
Validation loss: 2.2915944771100114

Epoch: 5| Step: 10
Training loss: 2.8030588626861572
Validation loss: 2.293970548978416

Epoch: 325| Step: 0
Training loss: 1.7727100849151611
Validation loss: 2.2850432754844747

Epoch: 5| Step: 1
Training loss: 2.6338279247283936
Validation loss: 2.297763547589702

Epoch: 5| Step: 2
Training loss: 2.5082855224609375
Validation loss: 2.2941701412200928

Epoch: 5| Step: 3
Training loss: 2.8205697536468506
Validation loss: 2.2892900423337053

Epoch: 5| Step: 4
Training loss: 2.178382396697998
Validation loss: 2.282057262236072

Epoch: 5| Step: 5
Training loss: 2.538025379180908
Validation loss: 2.27171823029877

Epoch: 5| Step: 6
Training loss: 2.121600866317749
Validation loss: 2.2783963962267806

Epoch: 5| Step: 7
Training loss: 2.407404899597168
Validation loss: 2.2759126078697944

Epoch: 5| Step: 8
Training loss: 2.8796226978302
Validation loss: 2.277009048769551

Epoch: 5| Step: 9
Training loss: 2.5697436332702637
Validation loss: 2.271848855480071

Epoch: 5| Step: 10
Training loss: 2.724411964416504
Validation loss: 2.2751839340374036

Epoch: 326| Step: 0
Training loss: 2.167992115020752
Validation loss: 2.263390830768052

Epoch: 5| Step: 1
Training loss: 2.5418179035186768
Validation loss: 2.2734778337581183

Epoch: 5| Step: 2
Training loss: 2.4160807132720947
Validation loss: 2.2609118620554605

Epoch: 5| Step: 3
Training loss: 2.678657054901123
Validation loss: 2.2678023563918246

Epoch: 5| Step: 4
Training loss: 2.037393093109131
Validation loss: 2.2719484657369633

Epoch: 5| Step: 5
Training loss: 2.46879506111145
Validation loss: 2.2653100618752102

Epoch: 5| Step: 6
Training loss: 3.4351277351379395
Validation loss: 2.266836081781695

Epoch: 5| Step: 7
Training loss: 2.4398810863494873
Validation loss: 2.2693979406869538

Epoch: 5| Step: 8
Training loss: 3.0628609657287598
Validation loss: 2.2674217839394846

Epoch: 5| Step: 9
Training loss: 1.4362319707870483
Validation loss: 2.2759385134584162

Epoch: 5| Step: 10
Training loss: 2.558197498321533
Validation loss: 2.2924441445258354

Epoch: 327| Step: 0
Training loss: 2.5188801288604736
Validation loss: 2.29344601784983

Epoch: 5| Step: 1
Training loss: 2.676588773727417
Validation loss: 2.3008112292135916

Epoch: 5| Step: 2
Training loss: 2.180337905883789
Validation loss: 2.3029160089390253

Epoch: 5| Step: 3
Training loss: 2.7891147136688232
Validation loss: 2.307019600304224

Epoch: 5| Step: 4
Training loss: 2.646557092666626
Validation loss: 2.318953844808763

Epoch: 5| Step: 5
Training loss: 2.002838134765625
Validation loss: 2.3145923845229612

Epoch: 5| Step: 6
Training loss: 2.2274844646453857
Validation loss: 2.311791104655112

Epoch: 5| Step: 7
Training loss: 2.9648261070251465
Validation loss: 2.3043116215736634

Epoch: 5| Step: 8
Training loss: 2.023765802383423
Validation loss: 2.289952939556491

Epoch: 5| Step: 9
Training loss: 2.1343905925750732
Validation loss: 2.276698568815826

Epoch: 5| Step: 10
Training loss: 3.1350269317626953
Validation loss: 2.270805840851158

Epoch: 328| Step: 0
Training loss: 2.5564706325531006
Validation loss: 2.262991028447305

Epoch: 5| Step: 1
Training loss: 1.748544454574585
Validation loss: 2.2639421263048725

Epoch: 5| Step: 2
Training loss: 2.26992130279541
Validation loss: 2.2581643878772693

Epoch: 5| Step: 3
Training loss: 2.476780414581299
Validation loss: 2.2515431783532582

Epoch: 5| Step: 4
Training loss: 2.0259785652160645
Validation loss: 2.262710737925704

Epoch: 5| Step: 5
Training loss: 2.9299042224884033
Validation loss: 2.2610861614186275

Epoch: 5| Step: 6
Training loss: 2.3436684608459473
Validation loss: 2.27128335993777

Epoch: 5| Step: 7
Training loss: 2.668955087661743
Validation loss: 2.2645133477385326

Epoch: 5| Step: 8
Training loss: 2.6925501823425293
Validation loss: 2.2627128375473844

Epoch: 5| Step: 9
Training loss: 2.643775224685669
Validation loss: 2.275724900666104

Epoch: 5| Step: 10
Training loss: 2.805527925491333
Validation loss: 2.2784354558555027

Epoch: 329| Step: 0
Training loss: 2.501899242401123
Validation loss: 2.2715012514463035

Epoch: 5| Step: 1
Training loss: 2.197309732437134
Validation loss: 2.275203756106797

Epoch: 5| Step: 2
Training loss: 2.492572546005249
Validation loss: 2.2605654296054634

Epoch: 5| Step: 3
Training loss: 2.513702392578125
Validation loss: 2.2635255577743694

Epoch: 5| Step: 4
Training loss: 1.9241602420806885
Validation loss: 2.2488089530698714

Epoch: 5| Step: 5
Training loss: 2.475076675415039
Validation loss: 2.2586761187481623

Epoch: 5| Step: 6
Training loss: 2.8226234912872314
Validation loss: 2.2536607993546354

Epoch: 5| Step: 7
Training loss: 2.7144622802734375
Validation loss: 2.2560093351589736

Epoch: 5| Step: 8
Training loss: 2.7138020992279053
Validation loss: 2.2555752338901645

Epoch: 5| Step: 9
Training loss: 2.3193132877349854
Validation loss: 2.2556620310711604

Epoch: 5| Step: 10
Training loss: 2.375520706176758
Validation loss: 2.2619030449980047

Epoch: 330| Step: 0
Training loss: 2.593078136444092
Validation loss: 2.2680197710631997

Epoch: 5| Step: 1
Training loss: 2.4765634536743164
Validation loss: 2.264985827989476

Epoch: 5| Step: 2
Training loss: 2.369356393814087
Validation loss: 2.2765320090837378

Epoch: 5| Step: 3
Training loss: 2.2311975955963135
Validation loss: 2.278310719356742

Epoch: 5| Step: 4
Training loss: 2.371873378753662
Validation loss: 2.2868067705503075

Epoch: 5| Step: 5
Training loss: 2.5995116233825684
Validation loss: 2.283513281935005

Epoch: 5| Step: 6
Training loss: 2.340648889541626
Validation loss: 2.281015924228135

Epoch: 5| Step: 7
Training loss: 2.4976062774658203
Validation loss: 2.2738991578420005

Epoch: 5| Step: 8
Training loss: 1.7577660083770752
Validation loss: 2.2748792504751556

Epoch: 5| Step: 9
Training loss: 2.66072678565979
Validation loss: 2.272078219280448

Epoch: 5| Step: 10
Training loss: 3.3205370903015137
Validation loss: 2.2720134027542604

Epoch: 331| Step: 0
Training loss: 2.306429624557495
Validation loss: 2.2726911139744583

Epoch: 5| Step: 1
Training loss: 2.174204111099243
Validation loss: 2.274881160387429

Epoch: 5| Step: 2
Training loss: 2.813596487045288
Validation loss: 2.281223822665471

Epoch: 5| Step: 3
Training loss: 2.3738415241241455
Validation loss: 2.277328383538031

Epoch: 5| Step: 4
Training loss: 1.8622214794158936
Validation loss: 2.2799361085378997

Epoch: 5| Step: 5
Training loss: 3.187446355819702
Validation loss: 2.280011684663834

Epoch: 5| Step: 6
Training loss: 2.169208526611328
Validation loss: 2.2701001628752677

Epoch: 5| Step: 7
Training loss: 2.247697114944458
Validation loss: 2.2629691849472704

Epoch: 5| Step: 8
Training loss: 2.558997392654419
Validation loss: 2.2552189275782597

Epoch: 5| Step: 9
Training loss: 2.8854613304138184
Validation loss: 2.259184419467885

Epoch: 5| Step: 10
Training loss: 2.3985729217529297
Validation loss: 2.2632522993190314

Epoch: 332| Step: 0
Training loss: 2.804429292678833
Validation loss: 2.264016782083819

Epoch: 5| Step: 1
Training loss: 2.2982726097106934
Validation loss: 2.2637439453473656

Epoch: 5| Step: 2
Training loss: 2.74069881439209
Validation loss: 2.265776203524682

Epoch: 5| Step: 3
Training loss: 2.2183241844177246
Validation loss: 2.2560901206026793

Epoch: 5| Step: 4
Training loss: 2.485793352127075
Validation loss: 2.251935605079897

Epoch: 5| Step: 5
Training loss: 2.4251809120178223
Validation loss: 2.260438334557318

Epoch: 5| Step: 6
Training loss: 2.4863274097442627
Validation loss: 2.264970964001071

Epoch: 5| Step: 7
Training loss: 2.7324576377868652
Validation loss: 2.259920766276698

Epoch: 5| Step: 8
Training loss: 2.405743360519409
Validation loss: 2.2749886538392756

Epoch: 5| Step: 9
Training loss: 2.2000808715820312
Validation loss: 2.275521937236991

Epoch: 5| Step: 10
Training loss: 2.1183643341064453
Validation loss: 2.2849018368669736

Epoch: 333| Step: 0
Training loss: 2.949859142303467
Validation loss: 2.284907769131404

Epoch: 5| Step: 1
Training loss: 2.6432652473449707
Validation loss: 2.2948331166339178

Epoch: 5| Step: 2
Training loss: 2.474301338195801
Validation loss: 2.31237821168797

Epoch: 5| Step: 3
Training loss: 2.146533250808716
Validation loss: 2.3112198357941

Epoch: 5| Step: 4
Training loss: 3.062307119369507
Validation loss: 2.316572222658383

Epoch: 5| Step: 5
Training loss: 2.5056228637695312
Validation loss: 2.318436257300838

Epoch: 5| Step: 6
Training loss: 2.463904619216919
Validation loss: 2.3189051561458136

Epoch: 5| Step: 7
Training loss: 1.840710997581482
Validation loss: 2.3151868774044897

Epoch: 5| Step: 8
Training loss: 1.6024091243743896
Validation loss: 2.3058261614973827

Epoch: 5| Step: 9
Training loss: 2.8466086387634277
Validation loss: 2.304535504310362

Epoch: 5| Step: 10
Training loss: 2.5845327377319336
Validation loss: 2.2810256455534246

Epoch: 334| Step: 0
Training loss: 2.647620439529419
Validation loss: 2.280046498903664

Epoch: 5| Step: 1
Training loss: 2.505307912826538
Validation loss: 2.2779970656159105

Epoch: 5| Step: 2
Training loss: 2.3511440753936768
Validation loss: 2.2780059640125563

Epoch: 5| Step: 3
Training loss: 2.951408863067627
Validation loss: 2.2712435427532403

Epoch: 5| Step: 4
Training loss: 2.243919849395752
Validation loss: 2.2735756392120035

Epoch: 5| Step: 5
Training loss: 2.3890182971954346
Validation loss: 2.274594268491191

Epoch: 5| Step: 6
Training loss: 2.692202091217041
Validation loss: 2.2829609250509613

Epoch: 5| Step: 7
Training loss: 2.615187883377075
Validation loss: 2.277596148111487

Epoch: 5| Step: 8
Training loss: 2.0620315074920654
Validation loss: 2.2921845784751316

Epoch: 5| Step: 9
Training loss: 2.2913146018981934
Validation loss: 2.2858078300312

Epoch: 5| Step: 10
Training loss: 2.1536126136779785
Validation loss: 2.2817803326473443

Epoch: 335| Step: 0
Training loss: 2.3373165130615234
Validation loss: 2.2909062908541773

Epoch: 5| Step: 1
Training loss: 2.701202154159546
Validation loss: 2.2797610118824947

Epoch: 5| Step: 2
Training loss: 2.0142149925231934
Validation loss: 2.2574559693695395

Epoch: 5| Step: 3
Training loss: 2.921797275543213
Validation loss: 2.2547426915937856

Epoch: 5| Step: 4
Training loss: 1.915632963180542
Validation loss: 2.254886891252251

Epoch: 5| Step: 5
Training loss: 2.5198419094085693
Validation loss: 2.2567249664696316

Epoch: 5| Step: 6
Training loss: 2.905339002609253
Validation loss: 2.249948050386162

Epoch: 5| Step: 7
Training loss: 2.7229011058807373
Validation loss: 2.262260575448313

Epoch: 5| Step: 8
Training loss: 2.0450758934020996
Validation loss: 2.26108540514464

Epoch: 5| Step: 9
Training loss: 2.479881763458252
Validation loss: 2.263882811351489

Epoch: 5| Step: 10
Training loss: 2.3424315452575684
Validation loss: 2.261299443501298

Epoch: 336| Step: 0
Training loss: 2.478529691696167
Validation loss: 2.2662219078310075

Epoch: 5| Step: 1
Training loss: 3.0071327686309814
Validation loss: 2.2667980706819923

Epoch: 5| Step: 2
Training loss: 2.3547840118408203
Validation loss: 2.272928209714992

Epoch: 5| Step: 3
Training loss: 1.9715532064437866
Validation loss: 2.2808266865309847

Epoch: 5| Step: 4
Training loss: 2.397954225540161
Validation loss: 2.2684442099704536

Epoch: 5| Step: 5
Training loss: 2.4956347942352295
Validation loss: 2.2737891853496595

Epoch: 5| Step: 6
Training loss: 2.1032042503356934
Validation loss: 2.280110720665224

Epoch: 5| Step: 7
Training loss: 2.2153210639953613
Validation loss: 2.2829400595798286

Epoch: 5| Step: 8
Training loss: 2.703680992126465
Validation loss: 2.2778518840830815

Epoch: 5| Step: 9
Training loss: 2.849557399749756
Validation loss: 2.2765685127627466

Epoch: 5| Step: 10
Training loss: 2.2588138580322266
Validation loss: 2.2768785133156726

Epoch: 337| Step: 0
Training loss: 2.3990278244018555
Validation loss: 2.2741703423120643

Epoch: 5| Step: 1
Training loss: 2.6427903175354004
Validation loss: 2.2630781050651305

Epoch: 5| Step: 2
Training loss: 2.6565442085266113
Validation loss: 2.26363286664409

Epoch: 5| Step: 3
Training loss: 3.087005615234375
Validation loss: 2.258987275503015

Epoch: 5| Step: 4
Training loss: 2.30098295211792
Validation loss: 2.2569568977561048

Epoch: 5| Step: 5
Training loss: 2.23456072807312
Validation loss: 2.2595013277505034

Epoch: 5| Step: 6
Training loss: 1.9460866451263428
Validation loss: 2.25931010066822

Epoch: 5| Step: 7
Training loss: 2.4430055618286133
Validation loss: 2.263295222354192

Epoch: 5| Step: 8
Training loss: 2.5682380199432373
Validation loss: 2.265000243340769

Epoch: 5| Step: 9
Training loss: 1.7789433002471924
Validation loss: 2.267522245325068

Epoch: 5| Step: 10
Training loss: 2.891031265258789
Validation loss: 2.2708457849359

Epoch: 338| Step: 0
Training loss: 2.496260166168213
Validation loss: 2.2766173526804936

Epoch: 5| Step: 1
Training loss: 2.540930986404419
Validation loss: 2.2889215279650945

Epoch: 5| Step: 2
Training loss: 2.397855520248413
Validation loss: 2.2929564393976682

Epoch: 5| Step: 3
Training loss: 2.1142818927764893
Validation loss: 2.2954759931051605

Epoch: 5| Step: 4
Training loss: 2.2609477043151855
Validation loss: 2.303619069437827

Epoch: 5| Step: 5
Training loss: 2.5813446044921875
Validation loss: 2.278776366223571

Epoch: 5| Step: 6
Training loss: 3.18841814994812
Validation loss: 2.280923866456555

Epoch: 5| Step: 7
Training loss: 2.327378273010254
Validation loss: 2.2819684038880053

Epoch: 5| Step: 8
Training loss: 2.0339574813842773
Validation loss: 2.2581462065378823

Epoch: 5| Step: 9
Training loss: 2.902474880218506
Validation loss: 2.2475169397169545

Epoch: 5| Step: 10
Training loss: 2.011451005935669
Validation loss: 2.245986869258265

Epoch: 339| Step: 0
Training loss: 2.2588722705841064
Validation loss: 2.241487272324101

Epoch: 5| Step: 1
Training loss: 2.2506794929504395
Validation loss: 2.234596421641688

Epoch: 5| Step: 2
Training loss: 2.4815986156463623
Validation loss: 2.236817136887581

Epoch: 5| Step: 3
Training loss: 2.975358724594116
Validation loss: 2.23989357743212

Epoch: 5| Step: 4
Training loss: 1.8752124309539795
Validation loss: 2.2402781235274447

Epoch: 5| Step: 5
Training loss: 2.280003070831299
Validation loss: 2.2463792139484036

Epoch: 5| Step: 6
Training loss: 3.320148468017578
Validation loss: 2.242462806804206

Epoch: 5| Step: 7
Training loss: 2.278796672821045
Validation loss: 2.2573983874372257

Epoch: 5| Step: 8
Training loss: 2.285720109939575
Validation loss: 2.2554774040816934

Epoch: 5| Step: 9
Training loss: 2.548816204071045
Validation loss: 2.265889924059632

Epoch: 5| Step: 10
Training loss: 2.4634151458740234
Validation loss: 2.2666534916047127

Epoch: 340| Step: 0
Training loss: 2.4039275646209717
Validation loss: 2.259464448498141

Epoch: 5| Step: 1
Training loss: 2.330526113510132
Validation loss: 2.2493849018568635

Epoch: 5| Step: 2
Training loss: 2.3775665760040283
Validation loss: 2.264330099987727

Epoch: 5| Step: 3
Training loss: 1.947328805923462
Validation loss: 2.2620489469138523

Epoch: 5| Step: 4
Training loss: 2.831968307495117
Validation loss: 2.260954564617526

Epoch: 5| Step: 5
Training loss: 2.1718926429748535
Validation loss: 2.262274948499536

Epoch: 5| Step: 6
Training loss: 2.138803720474243
Validation loss: 2.251854540199362

Epoch: 5| Step: 7
Training loss: 2.508784532546997
Validation loss: 2.2676316102345786

Epoch: 5| Step: 8
Training loss: 2.279235363006592
Validation loss: 2.2578792341293825

Epoch: 5| Step: 9
Training loss: 2.89485502243042
Validation loss: 2.250853338549214

Epoch: 5| Step: 10
Training loss: 3.042633056640625
Validation loss: 2.24792754778298

Epoch: 341| Step: 0
Training loss: 2.5629465579986572
Validation loss: 2.264032017800116

Epoch: 5| Step: 1
Training loss: 2.699941396713257
Validation loss: 2.255919256517964

Epoch: 5| Step: 2
Training loss: 3.132206916809082
Validation loss: 2.2780441468761814

Epoch: 5| Step: 3
Training loss: 3.0497567653656006
Validation loss: 2.2714464767004854

Epoch: 5| Step: 4
Training loss: 2.8132195472717285
Validation loss: 2.2598932481581167

Epoch: 5| Step: 5
Training loss: 1.5469019412994385
Validation loss: 2.2632647932216687

Epoch: 5| Step: 6
Training loss: 2.8122143745422363
Validation loss: 2.2592068231233986

Epoch: 5| Step: 7
Training loss: 2.090056896209717
Validation loss: 2.249074943604008

Epoch: 5| Step: 8
Training loss: 1.9374099969863892
Validation loss: 2.256015885260797

Epoch: 5| Step: 9
Training loss: 2.3706095218658447
Validation loss: 2.2674822140765447

Epoch: 5| Step: 10
Training loss: 1.647346019744873
Validation loss: 2.2571875715768464

Epoch: 342| Step: 0
Training loss: 2.6025798320770264
Validation loss: 2.2607348195968138

Epoch: 5| Step: 1
Training loss: 2.7137832641601562
Validation loss: 2.257436026809036

Epoch: 5| Step: 2
Training loss: 2.5988171100616455
Validation loss: 2.256662699484056

Epoch: 5| Step: 3
Training loss: 2.450791358947754
Validation loss: 2.2615479500063005

Epoch: 5| Step: 4
Training loss: 2.33034610748291
Validation loss: 2.2644045019662506

Epoch: 5| Step: 5
Training loss: 1.9262250661849976
Validation loss: 2.267762214906754

Epoch: 5| Step: 6
Training loss: 2.8898448944091797
Validation loss: 2.276382254016015

Epoch: 5| Step: 7
Training loss: 2.7308788299560547
Validation loss: 2.274605325473252

Epoch: 5| Step: 8
Training loss: 2.6600823402404785
Validation loss: 2.2826681547267462

Epoch: 5| Step: 9
Training loss: 1.4958915710449219
Validation loss: 2.267161824369943

Epoch: 5| Step: 10
Training loss: 2.3550894260406494
Validation loss: 2.290332709589312

Epoch: 343| Step: 0
Training loss: 2.355452060699463
Validation loss: 2.2865445844588743

Epoch: 5| Step: 1
Training loss: 3.039580821990967
Validation loss: 2.2771861681374173

Epoch: 5| Step: 2
Training loss: 1.772226333618164
Validation loss: 2.2738367972835416

Epoch: 5| Step: 3
Training loss: 2.6869285106658936
Validation loss: 2.262375675221925

Epoch: 5| Step: 4
Training loss: 2.231461763381958
Validation loss: 2.262834192604147

Epoch: 5| Step: 5
Training loss: 1.8596630096435547
Validation loss: 2.2683689517359578

Epoch: 5| Step: 6
Training loss: 2.553382396697998
Validation loss: 2.2582184242945846

Epoch: 5| Step: 7
Training loss: 2.838132858276367
Validation loss: 2.262284104542066

Epoch: 5| Step: 8
Training loss: 2.1881608963012695
Validation loss: 2.2663906107666674

Epoch: 5| Step: 9
Training loss: 2.526254177093506
Validation loss: 2.2638049510217484

Epoch: 5| Step: 10
Training loss: 2.678162097930908
Validation loss: 2.2654697266958093

Epoch: 344| Step: 0
Training loss: 2.70324444770813
Validation loss: 2.2578621372099845

Epoch: 5| Step: 1
Training loss: 3.2381672859191895
Validation loss: 2.2465175813244236

Epoch: 5| Step: 2
Training loss: 1.9695717096328735
Validation loss: 2.2371124272705405

Epoch: 5| Step: 3
Training loss: 2.5184342861175537
Validation loss: 2.2387270055791384

Epoch: 5| Step: 4
Training loss: 1.9470211267471313
Validation loss: 2.2533182213383336

Epoch: 5| Step: 5
Training loss: 1.9215198755264282
Validation loss: 2.250241459056895

Epoch: 5| Step: 6
Training loss: 1.9903590679168701
Validation loss: 2.2538629642096897

Epoch: 5| Step: 7
Training loss: 2.634813070297241
Validation loss: 2.2508483638045607

Epoch: 5| Step: 8
Training loss: 1.975502610206604
Validation loss: 2.252055060478949

Epoch: 5| Step: 9
Training loss: 3.4580092430114746
Validation loss: 2.2548590860059186

Epoch: 5| Step: 10
Training loss: 2.4274251461029053
Validation loss: 2.2476959382334063

Epoch: 345| Step: 0
Training loss: 2.716162919998169
Validation loss: 2.2435123202621297

Epoch: 5| Step: 1
Training loss: 2.680310010910034
Validation loss: 2.2364303629885436

Epoch: 5| Step: 2
Training loss: 1.8197352886199951
Validation loss: 2.2384700621328046

Epoch: 5| Step: 3
Training loss: 2.5838749408721924
Validation loss: 2.2495871410574964

Epoch: 5| Step: 4
Training loss: 2.5588855743408203
Validation loss: 2.2507207521828274

Epoch: 5| Step: 5
Training loss: 2.4764537811279297
Validation loss: 2.2604969598913707

Epoch: 5| Step: 6
Training loss: 2.3325634002685547
Validation loss: 2.269914391220257

Epoch: 5| Step: 7
Training loss: 3.122199535369873
Validation loss: 2.275555836257114

Epoch: 5| Step: 8
Training loss: 1.6541706323623657
Validation loss: 2.2742624257200506

Epoch: 5| Step: 9
Training loss: 2.2980737686157227
Validation loss: 2.2579387541740172

Epoch: 5| Step: 10
Training loss: 2.593947172164917
Validation loss: 2.2654725954096806

Epoch: 346| Step: 0
Training loss: 1.8767588138580322
Validation loss: 2.240272242535827

Epoch: 5| Step: 1
Training loss: 2.350372314453125
Validation loss: 2.2396074213007444

Epoch: 5| Step: 2
Training loss: 1.5822510719299316
Validation loss: 2.2502549284247944

Epoch: 5| Step: 3
Training loss: 2.8117258548736572
Validation loss: 2.2537105314193235

Epoch: 5| Step: 4
Training loss: 2.8560283184051514
Validation loss: 2.2408569435919485

Epoch: 5| Step: 5
Training loss: 2.615074634552002
Validation loss: 2.2580281867775867

Epoch: 5| Step: 6
Training loss: 2.709912061691284
Validation loss: 2.2618585786511822

Epoch: 5| Step: 7
Training loss: 2.889904499053955
Validation loss: 2.2623661718060895

Epoch: 5| Step: 8
Training loss: 2.2949280738830566
Validation loss: 2.25206240787301

Epoch: 5| Step: 9
Training loss: 2.6266727447509766
Validation loss: 2.2676242192586265

Epoch: 5| Step: 10
Training loss: 2.076188087463379
Validation loss: 2.2668678965619815

Epoch: 347| Step: 0
Training loss: 2.4912099838256836
Validation loss: 2.265184115338069

Epoch: 5| Step: 1
Training loss: 2.6589455604553223
Validation loss: 2.26141454327491

Epoch: 5| Step: 2
Training loss: 2.4232592582702637
Validation loss: 2.2689026145524878

Epoch: 5| Step: 3
Training loss: 2.512420177459717
Validation loss: 2.24955742589889

Epoch: 5| Step: 4
Training loss: 2.774773597717285
Validation loss: 2.258704916123421

Epoch: 5| Step: 5
Training loss: 2.6228580474853516
Validation loss: 2.258195225910474

Epoch: 5| Step: 6
Training loss: 2.2047133445739746
Validation loss: 2.2399563353548766

Epoch: 5| Step: 7
Training loss: 1.9405717849731445
Validation loss: 2.2431267256377847

Epoch: 5| Step: 8
Training loss: 2.060180425643921
Validation loss: 2.242108924414522

Epoch: 5| Step: 9
Training loss: 2.8556699752807617
Validation loss: 2.250893838943974

Epoch: 5| Step: 10
Training loss: 2.027829885482788
Validation loss: 2.255615295902375

Epoch: 348| Step: 0
Training loss: 2.012638807296753
Validation loss: 2.269437292570709

Epoch: 5| Step: 1
Training loss: 2.856750011444092
Validation loss: 2.281569183513682

Epoch: 5| Step: 2
Training loss: 1.8846603631973267
Validation loss: 2.2854137625745548

Epoch: 5| Step: 3
Training loss: 2.3757705688476562
Validation loss: 2.2705415115561536

Epoch: 5| Step: 4
Training loss: 2.2752578258514404
Validation loss: 2.262104078005719

Epoch: 5| Step: 5
Training loss: 2.2569377422332764
Validation loss: 2.2543014685312905

Epoch: 5| Step: 6
Training loss: 2.5579276084899902
Validation loss: 2.257290071056735

Epoch: 5| Step: 7
Training loss: 2.243373394012451
Validation loss: 2.250519198756064

Epoch: 5| Step: 8
Training loss: 2.516356945037842
Validation loss: 2.261367763242414

Epoch: 5| Step: 9
Training loss: 2.9607059955596924
Validation loss: 2.247315708027091

Epoch: 5| Step: 10
Training loss: 2.9434316158294678
Validation loss: 2.2426504909351306

Epoch: 349| Step: 0
Training loss: 2.3741800785064697
Validation loss: 2.2470778854944373

Epoch: 5| Step: 1
Training loss: 2.5847315788269043
Validation loss: 2.245506159720882

Epoch: 5| Step: 2
Training loss: 2.1262989044189453
Validation loss: 2.2458596050098376

Epoch: 5| Step: 3
Training loss: 2.208676815032959
Validation loss: 2.2447884505794895

Epoch: 5| Step: 4
Training loss: 2.100015163421631
Validation loss: 2.2567016373398485

Epoch: 5| Step: 5
Training loss: 2.0316784381866455
Validation loss: 2.2473221671196724

Epoch: 5| Step: 6
Training loss: 2.114875316619873
Validation loss: 2.261760534778718

Epoch: 5| Step: 7
Training loss: 2.4161267280578613
Validation loss: 2.2653022248257875

Epoch: 5| Step: 8
Training loss: 2.540907382965088
Validation loss: 2.2565701956390054

Epoch: 5| Step: 9
Training loss: 2.938800573348999
Validation loss: 2.264923846849831

Epoch: 5| Step: 10
Training loss: 3.3249449729919434
Validation loss: 2.2610282487766717

Epoch: 350| Step: 0
Training loss: 2.5168681144714355
Validation loss: 2.258830144841184

Epoch: 5| Step: 1
Training loss: 1.7784137725830078
Validation loss: 2.250629891631424

Epoch: 5| Step: 2
Training loss: 2.2854561805725098
Validation loss: 2.2410897157525502

Epoch: 5| Step: 3
Training loss: 3.08381986618042
Validation loss: 2.2458437694016324

Epoch: 5| Step: 4
Training loss: 2.627061367034912
Validation loss: 2.2444697682575514

Epoch: 5| Step: 5
Training loss: 2.4572534561157227
Validation loss: 2.238415923169864

Epoch: 5| Step: 6
Training loss: 1.7376800775527954
Validation loss: 2.2434252000624135

Epoch: 5| Step: 7
Training loss: 2.42568039894104
Validation loss: 2.2519585727363505

Epoch: 5| Step: 8
Training loss: 1.9656593799591064
Validation loss: 2.2392834899246052

Epoch: 5| Step: 9
Training loss: 3.0521860122680664
Validation loss: 2.2414788687100975

Epoch: 5| Step: 10
Training loss: 2.6361145973205566
Validation loss: 2.24493505108741

Epoch: 351| Step: 0
Training loss: 2.4158482551574707
Validation loss: 2.2477487005213255

Epoch: 5| Step: 1
Training loss: 2.3514533042907715
Validation loss: 2.240899706399569

Epoch: 5| Step: 2
Training loss: 2.7097058296203613
Validation loss: 2.2437189317518667

Epoch: 5| Step: 3
Training loss: 2.5012402534484863
Validation loss: 2.2438894035995647

Epoch: 5| Step: 4
Training loss: 2.710376024246216
Validation loss: 2.2500292767760572

Epoch: 5| Step: 5
Training loss: 2.1626181602478027
Validation loss: 2.253125632962873

Epoch: 5| Step: 6
Training loss: 2.694483518600464
Validation loss: 2.2647753095114105

Epoch: 5| Step: 7
Training loss: 1.7839393615722656
Validation loss: 2.259865032729282

Epoch: 5| Step: 8
Training loss: 2.6063363552093506
Validation loss: 2.2567615124487106

Epoch: 5| Step: 9
Training loss: 2.0745091438293457
Validation loss: 2.2614018532537643

Epoch: 5| Step: 10
Training loss: 2.4869134426116943
Validation loss: 2.246488768567321

Epoch: 352| Step: 0
Training loss: 2.1883463859558105
Validation loss: 2.255063949092742

Epoch: 5| Step: 1
Training loss: 2.338676929473877
Validation loss: 2.2552911158530944

Epoch: 5| Step: 2
Training loss: 2.5619194507598877
Validation loss: 2.2603369169337775

Epoch: 5| Step: 3
Training loss: 3.175689220428467
Validation loss: 2.2574824517773044

Epoch: 5| Step: 4
Training loss: 2.0589168071746826
Validation loss: 2.2515203311879146

Epoch: 5| Step: 5
Training loss: 1.981471300125122
Validation loss: 2.25337661979019

Epoch: 5| Step: 6
Training loss: 2.9637703895568848
Validation loss: 2.251506200400732

Epoch: 5| Step: 7
Training loss: 2.4989709854125977
Validation loss: 2.2494617021212013

Epoch: 5| Step: 8
Training loss: 2.365974187850952
Validation loss: 2.2542285150097263

Epoch: 5| Step: 9
Training loss: 2.3432955741882324
Validation loss: 2.2542935327817033

Epoch: 5| Step: 10
Training loss: 1.9431488513946533
Validation loss: 2.2596313658580987

Epoch: 353| Step: 0
Training loss: 3.085829973220825
Validation loss: 2.2681567233095885

Epoch: 5| Step: 1
Training loss: 2.4274864196777344
Validation loss: 2.2634239991505942

Epoch: 5| Step: 2
Training loss: 1.7744715213775635
Validation loss: 2.2737019446588334

Epoch: 5| Step: 3
Training loss: 2.829052448272705
Validation loss: 2.2701164471205844

Epoch: 5| Step: 4
Training loss: 2.0994136333465576
Validation loss: 2.2857539217959166

Epoch: 5| Step: 5
Training loss: 2.5863728523254395
Validation loss: 2.2836335166808097

Epoch: 5| Step: 6
Training loss: 2.5691962242126465
Validation loss: 2.2712246653854207

Epoch: 5| Step: 7
Training loss: 3.05268931388855
Validation loss: 2.2609234522747736

Epoch: 5| Step: 8
Training loss: 2.04624605178833
Validation loss: 2.2501577177355365

Epoch: 5| Step: 9
Training loss: 1.5309982299804688
Validation loss: 2.246544830260738

Epoch: 5| Step: 10
Training loss: 2.6227598190307617
Validation loss: 2.2466730943290134

Epoch: 354| Step: 0
Training loss: 2.1532070636749268
Validation loss: 2.2456186868811168

Epoch: 5| Step: 1
Training loss: 2.3572754859924316
Validation loss: 2.2444695913663475

Epoch: 5| Step: 2
Training loss: 2.448202133178711
Validation loss: 2.248725970586141

Epoch: 5| Step: 3
Training loss: 2.7252590656280518
Validation loss: 2.2509716838918705

Epoch: 5| Step: 4
Training loss: 2.4312939643859863
Validation loss: 2.2503918845166444

Epoch: 5| Step: 5
Training loss: 2.498058319091797
Validation loss: 2.264312287812592

Epoch: 5| Step: 6
Training loss: 2.5567402839660645
Validation loss: 2.253625105786067

Epoch: 5| Step: 7
Training loss: 2.008488416671753
Validation loss: 2.273650506491302

Epoch: 5| Step: 8
Training loss: 2.243170738220215
Validation loss: 2.276369312758087

Epoch: 5| Step: 9
Training loss: 1.8876314163208008
Validation loss: 2.2794546568265526

Epoch: 5| Step: 10
Training loss: 3.31807804107666
Validation loss: 2.26817504308557

Epoch: 355| Step: 0
Training loss: 2.2043814659118652
Validation loss: 2.26205357684884

Epoch: 5| Step: 1
Training loss: 2.3031978607177734
Validation loss: 2.2415046358621247

Epoch: 5| Step: 2
Training loss: 2.2699484825134277
Validation loss: 2.231321686057634

Epoch: 5| Step: 3
Training loss: 2.4413037300109863
Validation loss: 2.23303545418606

Epoch: 5| Step: 4
Training loss: 2.413980007171631
Validation loss: 2.224411905452769

Epoch: 5| Step: 5
Training loss: 2.0330867767333984
Validation loss: 2.229027058488579

Epoch: 5| Step: 6
Training loss: 2.3955821990966797
Validation loss: 2.2172270282622306

Epoch: 5| Step: 7
Training loss: 2.8453023433685303
Validation loss: 2.216079737550469

Epoch: 5| Step: 8
Training loss: 2.779778003692627
Validation loss: 2.2187769259175947

Epoch: 5| Step: 9
Training loss: 2.1194920539855957
Validation loss: 2.228652569555467

Epoch: 5| Step: 10
Training loss: 2.799654245376587
Validation loss: 2.2307595104299565

Epoch: 356| Step: 0
Training loss: 2.383556842803955
Validation loss: 2.2316933396042034

Epoch: 5| Step: 1
Training loss: 2.5708088874816895
Validation loss: 2.2444965070293796

Epoch: 5| Step: 2
Training loss: 2.4023444652557373
Validation loss: 2.237432518313008

Epoch: 5| Step: 3
Training loss: 2.343782901763916
Validation loss: 2.2368225154056343

Epoch: 5| Step: 4
Training loss: 2.3140017986297607
Validation loss: 2.243328056027812

Epoch: 5| Step: 5
Training loss: 2.783446788787842
Validation loss: 2.2333326672994964

Epoch: 5| Step: 6
Training loss: 2.4640560150146484
Validation loss: 2.2447599428956226

Epoch: 5| Step: 7
Training loss: 2.403003454208374
Validation loss: 2.230649253373505

Epoch: 5| Step: 8
Training loss: 2.720750570297241
Validation loss: 2.2290425095506894

Epoch: 5| Step: 9
Training loss: 1.4918498992919922
Validation loss: 2.238675263620192

Epoch: 5| Step: 10
Training loss: 2.6521403789520264
Validation loss: 2.2307850609543505

Epoch: 357| Step: 0
Training loss: 2.225435733795166
Validation loss: 2.248514821452479

Epoch: 5| Step: 1
Training loss: 2.6453990936279297
Validation loss: 2.256407013503454

Epoch: 5| Step: 2
Training loss: 2.690965175628662
Validation loss: 2.272935918582383

Epoch: 5| Step: 3
Training loss: 2.241248607635498
Validation loss: 2.2656279674140354

Epoch: 5| Step: 4
Training loss: 2.268296480178833
Validation loss: 2.2675923506418862

Epoch: 5| Step: 5
Training loss: 2.6928341388702393
Validation loss: 2.2797557871828795

Epoch: 5| Step: 6
Training loss: 2.5776243209838867
Validation loss: 2.2727195293672624

Epoch: 5| Step: 7
Training loss: 2.8043339252471924
Validation loss: 2.2661549711740143

Epoch: 5| Step: 8
Training loss: 2.233837127685547
Validation loss: 2.2649144088068316

Epoch: 5| Step: 9
Training loss: 1.723204255104065
Validation loss: 2.262508802516486

Epoch: 5| Step: 10
Training loss: 2.468766927719116
Validation loss: 2.2646036891527075

Epoch: 358| Step: 0
Training loss: 2.274998188018799
Validation loss: 2.2773463508134246

Epoch: 5| Step: 1
Training loss: 3.099515914916992
Validation loss: 2.2628266119187876

Epoch: 5| Step: 2
Training loss: 2.834301710128784
Validation loss: 2.2728512133321455

Epoch: 5| Step: 3
Training loss: 2.446303606033325
Validation loss: 2.2669329848340762

Epoch: 5| Step: 4
Training loss: 2.742215394973755
Validation loss: 2.2502939188352196

Epoch: 5| Step: 5
Training loss: 1.534197449684143
Validation loss: 2.2348859951060307

Epoch: 5| Step: 6
Training loss: 1.7389923334121704
Validation loss: 2.232793882328977

Epoch: 5| Step: 7
Training loss: 2.4900553226470947
Validation loss: 2.2437134455609065

Epoch: 5| Step: 8
Training loss: 2.425872325897217
Validation loss: 2.2284131050109863

Epoch: 5| Step: 9
Training loss: 2.0031347274780273
Validation loss: 2.223386997817665

Epoch: 5| Step: 10
Training loss: 3.231846570968628
Validation loss: 2.2377725262795725

Epoch: 359| Step: 0
Training loss: 2.1652731895446777
Validation loss: 2.240395233195315

Epoch: 5| Step: 1
Training loss: 2.2293713092803955
Validation loss: 2.235418899084932

Epoch: 5| Step: 2
Training loss: 2.1392951011657715
Validation loss: 2.239504953866364

Epoch: 5| Step: 3
Training loss: 2.7323687076568604
Validation loss: 2.252490694804858

Epoch: 5| Step: 4
Training loss: 2.5323455333709717
Validation loss: 2.2648162790524062

Epoch: 5| Step: 5
Training loss: 2.7930445671081543
Validation loss: 2.2822274559287616

Epoch: 5| Step: 6
Training loss: 3.3358314037323
Validation loss: 2.2831918629266883

Epoch: 5| Step: 7
Training loss: 2.3903043270111084
Validation loss: 2.257856620255337

Epoch: 5| Step: 8
Training loss: 1.783704400062561
Validation loss: 2.2655164259736256

Epoch: 5| Step: 9
Training loss: 1.8038829565048218
Validation loss: 2.248148892515449

Epoch: 5| Step: 10
Training loss: 2.7076683044433594
Validation loss: 2.229483856949755

Epoch: 360| Step: 0
Training loss: 2.094088077545166
Validation loss: 2.2324512607307843

Epoch: 5| Step: 1
Training loss: 2.849496364593506
Validation loss: 2.2297742187335925

Epoch: 5| Step: 2
Training loss: 3.3078460693359375
Validation loss: 2.23688982635416

Epoch: 5| Step: 3
Training loss: 2.0590810775756836
Validation loss: 2.2332892904999437

Epoch: 5| Step: 4
Training loss: 2.212280750274658
Validation loss: 2.2290122944821595

Epoch: 5| Step: 5
Training loss: 2.4330077171325684
Validation loss: 2.22089994594615

Epoch: 5| Step: 6
Training loss: 2.873875141143799
Validation loss: 2.221289296304026

Epoch: 5| Step: 7
Training loss: 2.057124614715576
Validation loss: 2.216313180103097

Epoch: 5| Step: 8
Training loss: 1.9638044834136963
Validation loss: 2.2127385549647833

Epoch: 5| Step: 9
Training loss: 2.2831056118011475
Validation loss: 2.2138142739572833

Epoch: 5| Step: 10
Training loss: 2.5506348609924316
Validation loss: 2.215549735612767

Epoch: 361| Step: 0
Training loss: 1.6257896423339844
Validation loss: 2.215145734048659

Epoch: 5| Step: 1
Training loss: 2.7997257709503174
Validation loss: 2.2325996045143373

Epoch: 5| Step: 2
Training loss: 2.325601100921631
Validation loss: 2.239169002861105

Epoch: 5| Step: 3
Training loss: 2.227102756500244
Validation loss: 2.236513122435539

Epoch: 5| Step: 4
Training loss: 2.4848713874816895
Validation loss: 2.237915467190486

Epoch: 5| Step: 5
Training loss: 2.620642900466919
Validation loss: 2.2405491772518364

Epoch: 5| Step: 6
Training loss: 2.8087658882141113
Validation loss: 2.240827288678897

Epoch: 5| Step: 7
Training loss: 2.750633716583252
Validation loss: 2.239498958792738

Epoch: 5| Step: 8
Training loss: 2.0470261573791504
Validation loss: 2.2542886605826755

Epoch: 5| Step: 9
Training loss: 2.484424114227295
Validation loss: 2.254223213400892

Epoch: 5| Step: 10
Training loss: 2.3730714321136475
Validation loss: 2.2687042528583157

Epoch: 362| Step: 0
Training loss: 2.6963882446289062
Validation loss: 2.2610341169500865

Epoch: 5| Step: 1
Training loss: 2.523665189743042
Validation loss: 2.247626502026794

Epoch: 5| Step: 2
Training loss: 2.7209651470184326
Validation loss: 2.260111521649104

Epoch: 5| Step: 3
Training loss: 2.3930084705352783
Validation loss: 2.2499096367948797

Epoch: 5| Step: 4
Training loss: 2.3709771633148193
Validation loss: 2.24571822022879

Epoch: 5| Step: 5
Training loss: 2.082874298095703
Validation loss: 2.2552124569492955

Epoch: 5| Step: 6
Training loss: 2.8278393745422363
Validation loss: 2.246396013485488

Epoch: 5| Step: 7
Training loss: 1.509100079536438
Validation loss: 2.262166010436191

Epoch: 5| Step: 8
Training loss: 2.4092750549316406
Validation loss: 2.2576492601825344

Epoch: 5| Step: 9
Training loss: 2.6867949962615967
Validation loss: 2.2511382564421623

Epoch: 5| Step: 10
Training loss: 2.3736627101898193
Validation loss: 2.2408502588989916

Epoch: 363| Step: 0
Training loss: 1.8989183902740479
Validation loss: 2.2426952751733924

Epoch: 5| Step: 1
Training loss: 2.199831485748291
Validation loss: 2.2399830715630644

Epoch: 5| Step: 2
Training loss: 2.1692769527435303
Validation loss: 2.2384880742719098

Epoch: 5| Step: 3
Training loss: 1.8908780813217163
Validation loss: 2.2340699267643753

Epoch: 5| Step: 4
Training loss: 2.665539026260376
Validation loss: 2.233515371558487

Epoch: 5| Step: 5
Training loss: 3.2311980724334717
Validation loss: 2.234035804707517

Epoch: 5| Step: 6
Training loss: 2.6162800788879395
Validation loss: 2.230717617978332

Epoch: 5| Step: 7
Training loss: 2.1380538940429688
Validation loss: 2.228619631900582

Epoch: 5| Step: 8
Training loss: 2.6112418174743652
Validation loss: 2.231027859513478

Epoch: 5| Step: 9
Training loss: 2.4474055767059326
Validation loss: 2.2345291388932096

Epoch: 5| Step: 10
Training loss: 2.4445714950561523
Validation loss: 2.2482536300536125

Epoch: 364| Step: 0
Training loss: 2.897617816925049
Validation loss: 2.227376381556193

Epoch: 5| Step: 1
Training loss: 2.6336421966552734
Validation loss: 2.2405305370207755

Epoch: 5| Step: 2
Training loss: 1.3824398517608643
Validation loss: 2.2278402877110306

Epoch: 5| Step: 3
Training loss: 2.879753351211548
Validation loss: 2.2267314669906453

Epoch: 5| Step: 4
Training loss: 2.278578758239746
Validation loss: 2.2259271631958666

Epoch: 5| Step: 5
Training loss: 2.0959672927856445
Validation loss: 2.234282926846576

Epoch: 5| Step: 6
Training loss: 1.9754912853240967
Validation loss: 2.224312674614691

Epoch: 5| Step: 7
Training loss: 2.7632012367248535
Validation loss: 2.236714191334222

Epoch: 5| Step: 8
Training loss: 2.7624058723449707
Validation loss: 2.2387917323779036

Epoch: 5| Step: 9
Training loss: 2.2904186248779297
Validation loss: 2.2268211944128877

Epoch: 5| Step: 10
Training loss: 2.249054431915283
Validation loss: 2.2236101268440165

Epoch: 365| Step: 0
Training loss: 2.0968775749206543
Validation loss: 2.217839499955536

Epoch: 5| Step: 1
Training loss: 2.4698989391326904
Validation loss: 2.231889996477353

Epoch: 5| Step: 2
Training loss: 2.3948781490325928
Validation loss: 2.2309921685085503

Epoch: 5| Step: 3
Training loss: 2.2242422103881836
Validation loss: 2.239085722995061

Epoch: 5| Step: 4
Training loss: 2.597435474395752
Validation loss: 2.2377010827423423

Epoch: 5| Step: 5
Training loss: 2.2526142597198486
Validation loss: 2.2331183597605717

Epoch: 5| Step: 6
Training loss: 2.3355727195739746
Validation loss: 2.251592856581493

Epoch: 5| Step: 7
Training loss: 2.480459690093994
Validation loss: 2.248549820274435

Epoch: 5| Step: 8
Training loss: 2.199862241744995
Validation loss: 2.2425185557334655

Epoch: 5| Step: 9
Training loss: 3.030890941619873
Validation loss: 2.239596495064356

Epoch: 5| Step: 10
Training loss: 2.1712517738342285
Validation loss: 2.2490371811774468

Epoch: 366| Step: 0
Training loss: 2.0326988697052
Validation loss: 2.26104639678873

Epoch: 5| Step: 1
Training loss: 2.241013288497925
Validation loss: 2.2747400524795696

Epoch: 5| Step: 2
Training loss: 2.394209623336792
Validation loss: 2.2659003426951747

Epoch: 5| Step: 3
Training loss: 2.7262473106384277
Validation loss: 2.274472518633771

Epoch: 5| Step: 4
Training loss: 2.7346153259277344
Validation loss: 2.278345400287259

Epoch: 5| Step: 5
Training loss: 2.070812225341797
Validation loss: 2.2750755561295377

Epoch: 5| Step: 6
Training loss: 2.3014378547668457
Validation loss: 2.2573864511264268

Epoch: 5| Step: 7
Training loss: 2.5844225883483887
Validation loss: 2.2455131315415904

Epoch: 5| Step: 8
Training loss: 1.743520975112915
Validation loss: 2.251404462322112

Epoch: 5| Step: 9
Training loss: 3.1338977813720703
Validation loss: 2.2369964763682377

Epoch: 5| Step: 10
Training loss: 2.2511045932769775
Validation loss: 2.238465509107036

Epoch: 367| Step: 0
Training loss: 2.0772716999053955
Validation loss: 2.2384099857781523

Epoch: 5| Step: 1
Training loss: 2.385906219482422
Validation loss: 2.230194068724109

Epoch: 5| Step: 2
Training loss: 2.3002617359161377
Validation loss: 2.2243724612779516

Epoch: 5| Step: 3
Training loss: 2.604315757751465
Validation loss: 2.227813938612579

Epoch: 5| Step: 4
Training loss: 2.743922710418701
Validation loss: 2.2236795322869414

Epoch: 5| Step: 5
Training loss: 2.4075868129730225
Validation loss: 2.232053302949475

Epoch: 5| Step: 6
Training loss: 2.129610776901245
Validation loss: 2.2520064256524526

Epoch: 5| Step: 7
Training loss: 2.737560510635376
Validation loss: 2.258489388291554

Epoch: 5| Step: 8
Training loss: 2.563504695892334
Validation loss: 2.2673842945406513

Epoch: 5| Step: 9
Training loss: 2.29815411567688
Validation loss: 2.2678412596384683

Epoch: 5| Step: 10
Training loss: 1.9287991523742676
Validation loss: 2.282339706215807

Epoch: 368| Step: 0
Training loss: 2.123310089111328
Validation loss: 2.2688068779565955

Epoch: 5| Step: 1
Training loss: 2.45473051071167
Validation loss: 2.2462811572577364

Epoch: 5| Step: 2
Training loss: 2.406705379486084
Validation loss: 2.2438125071987027

Epoch: 5| Step: 3
Training loss: 2.904340982437134
Validation loss: 2.2414732581825665

Epoch: 5| Step: 4
Training loss: 2.2734735012054443
Validation loss: 2.2349507885594524

Epoch: 5| Step: 5
Training loss: 2.496309280395508
Validation loss: 2.2441563606262207

Epoch: 5| Step: 6
Training loss: 2.0534162521362305
Validation loss: 2.242264409219065

Epoch: 5| Step: 7
Training loss: 2.783269166946411
Validation loss: 2.2306852443243868

Epoch: 5| Step: 8
Training loss: 2.476339817047119
Validation loss: 2.224875544988981

Epoch: 5| Step: 9
Training loss: 1.7430553436279297
Validation loss: 2.2220476058221634

Epoch: 5| Step: 10
Training loss: 2.450958013534546
Validation loss: 2.221546220523055

Epoch: 369| Step: 0
Training loss: 2.4962656497955322
Validation loss: 2.2147291321908273

Epoch: 5| Step: 1
Training loss: 2.64797306060791
Validation loss: 2.2211560177546676

Epoch: 5| Step: 2
Training loss: 1.8993829488754272
Validation loss: 2.2041448752085366

Epoch: 5| Step: 3
Training loss: 1.9336185455322266
Validation loss: 2.214181555214749

Epoch: 5| Step: 4
Training loss: 2.014604091644287
Validation loss: 2.2196195381943897

Epoch: 5| Step: 5
Training loss: 2.917931318283081
Validation loss: 2.2008859918963526

Epoch: 5| Step: 6
Training loss: 1.8781722784042358
Validation loss: 2.213486853466239

Epoch: 5| Step: 7
Training loss: 2.5555496215820312
Validation loss: 2.206477274176895

Epoch: 5| Step: 8
Training loss: 2.248438835144043
Validation loss: 2.206624710431663

Epoch: 5| Step: 9
Training loss: 2.5909409523010254
Validation loss: 2.2171003305783836

Epoch: 5| Step: 10
Training loss: 2.976058006286621
Validation loss: 2.223867275381601

Epoch: 370| Step: 0
Training loss: 2.8642845153808594
Validation loss: 2.2429268078137468

Epoch: 5| Step: 1
Training loss: 2.3335137367248535
Validation loss: 2.24817649010689

Epoch: 5| Step: 2
Training loss: 2.359877109527588
Validation loss: 2.2683511190516974

Epoch: 5| Step: 3
Training loss: 1.7341152429580688
Validation loss: 2.272048188794044

Epoch: 5| Step: 4
Training loss: 2.2964038848876953
Validation loss: 2.271719568519182

Epoch: 5| Step: 5
Training loss: 2.394258975982666
Validation loss: 2.2574169558863484

Epoch: 5| Step: 6
Training loss: 2.004183292388916
Validation loss: 2.252179968741632

Epoch: 5| Step: 7
Training loss: 2.2243616580963135
Validation loss: 2.2483646664568173

Epoch: 5| Step: 8
Training loss: 2.4789490699768066
Validation loss: 2.237785111191452

Epoch: 5| Step: 9
Training loss: 2.9131546020507812
Validation loss: 2.2387755199145247

Epoch: 5| Step: 10
Training loss: 2.4790871143341064
Validation loss: 2.250267815846269

Epoch: 371| Step: 0
Training loss: 2.199528932571411
Validation loss: 2.242331948331607

Epoch: 5| Step: 1
Training loss: 2.5337142944335938
Validation loss: 2.251321828493508

Epoch: 5| Step: 2
Training loss: 1.6088413000106812
Validation loss: 2.2481502743177515

Epoch: 5| Step: 3
Training loss: 2.328653573989868
Validation loss: 2.2571343427063315

Epoch: 5| Step: 4
Training loss: 2.6943488121032715
Validation loss: 2.273858716410975

Epoch: 5| Step: 5
Training loss: 2.7188544273376465
Validation loss: 2.2720029046458583

Epoch: 5| Step: 6
Training loss: 2.6611971855163574
Validation loss: 2.2776813891626175

Epoch: 5| Step: 7
Training loss: 1.9198096990585327
Validation loss: 2.2553000552679903

Epoch: 5| Step: 8
Training loss: 2.205035448074341
Validation loss: 2.2332776772078646

Epoch: 5| Step: 9
Training loss: 2.851933717727661
Validation loss: 2.2273676856871574

Epoch: 5| Step: 10
Training loss: 2.392585039138794
Validation loss: 2.2299683632389193

Epoch: 372| Step: 0
Training loss: 2.4073188304901123
Validation loss: 2.2098683336729645

Epoch: 5| Step: 1
Training loss: 2.0811994075775146
Validation loss: 2.211490756721907

Epoch: 5| Step: 2
Training loss: 2.7310433387756348
Validation loss: 2.2089638684385564

Epoch: 5| Step: 3
Training loss: 2.479813814163208
Validation loss: 2.233123771605953

Epoch: 5| Step: 4
Training loss: 2.2309117317199707
Validation loss: 2.210807290128482

Epoch: 5| Step: 5
Training loss: 2.5823023319244385
Validation loss: 2.2215589618170135

Epoch: 5| Step: 6
Training loss: 2.6278460025787354
Validation loss: 2.236399504446214

Epoch: 5| Step: 7
Training loss: 2.3613393306732178
Validation loss: 2.24038940347651

Epoch: 5| Step: 8
Training loss: 2.0083272457122803
Validation loss: 2.261479188037175

Epoch: 5| Step: 9
Training loss: 2.4212353229522705
Validation loss: 2.2529659553240706

Epoch: 5| Step: 10
Training loss: 2.1196744441986084
Validation loss: 2.2647380264856483

Epoch: 373| Step: 0
Training loss: 2.0713868141174316
Validation loss: 2.2609131028575282

Epoch: 5| Step: 1
Training loss: 2.282348871231079
Validation loss: 2.2495491645669423

Epoch: 5| Step: 2
Training loss: 2.3788275718688965
Validation loss: 2.230378456013177

Epoch: 5| Step: 3
Training loss: 2.606637477874756
Validation loss: 2.232345414418046

Epoch: 5| Step: 4
Training loss: 2.114938259124756
Validation loss: 2.234059654256349

Epoch: 5| Step: 5
Training loss: 2.0494987964630127
Validation loss: 2.222630457211566

Epoch: 5| Step: 6
Training loss: 2.5226643085479736
Validation loss: 2.223723042395807

Epoch: 5| Step: 7
Training loss: 2.978743553161621
Validation loss: 2.2039217359276226

Epoch: 5| Step: 8
Training loss: 2.302675724029541
Validation loss: 2.20959819516828

Epoch: 5| Step: 9
Training loss: 2.3391165733337402
Validation loss: 2.213442246119181

Epoch: 5| Step: 10
Training loss: 2.3814756870269775
Validation loss: 2.218770186106364

Epoch: 374| Step: 0
Training loss: 2.8735122680664062
Validation loss: 2.2281571485662974

Epoch: 5| Step: 1
Training loss: 1.9022371768951416
Validation loss: 2.2354688029135428

Epoch: 5| Step: 2
Training loss: 2.4376702308654785
Validation loss: 2.2429819107055664

Epoch: 5| Step: 3
Training loss: 2.038834810256958
Validation loss: 2.243848446876772

Epoch: 5| Step: 4
Training loss: 2.735581159591675
Validation loss: 2.237949299555953

Epoch: 5| Step: 5
Training loss: 1.933274507522583
Validation loss: 2.2279269579918153

Epoch: 5| Step: 6
Training loss: 2.761925220489502
Validation loss: 2.2362562546166043

Epoch: 5| Step: 7
Training loss: 2.6845285892486572
Validation loss: 2.2344666347708753

Epoch: 5| Step: 8
Training loss: 2.63474440574646
Validation loss: 2.2301064665599535

Epoch: 5| Step: 9
Training loss: 2.341822862625122
Validation loss: 2.2410931510310017

Epoch: 5| Step: 10
Training loss: 1.6331567764282227
Validation loss: 2.241735453246742

Epoch: 375| Step: 0
Training loss: 2.6305220127105713
Validation loss: 2.2405831403629755

Epoch: 5| Step: 1
Training loss: 2.551170825958252
Validation loss: 2.2409393274655907

Epoch: 5| Step: 2
Training loss: 2.286764144897461
Validation loss: 2.2317277757070397

Epoch: 5| Step: 3
Training loss: 2.2095303535461426
Validation loss: 2.2218455806855233

Epoch: 5| Step: 4
Training loss: 2.026780605316162
Validation loss: 2.233580812331169

Epoch: 5| Step: 5
Training loss: 1.8368412256240845
Validation loss: 2.2327105537537606

Epoch: 5| Step: 6
Training loss: 2.3143961429595947
Validation loss: 2.232804339419129

Epoch: 5| Step: 7
Training loss: 1.9341039657592773
Validation loss: 2.229595584254111

Epoch: 5| Step: 8
Training loss: 2.9288833141326904
Validation loss: 2.232745500021083

Epoch: 5| Step: 9
Training loss: 3.0040841102600098
Validation loss: 2.2208223778714418

Epoch: 5| Step: 10
Training loss: 2.3219199180603027
Validation loss: 2.203893784553774

Epoch: 376| Step: 0
Training loss: 1.7930856943130493
Validation loss: 2.2171017072534047

Epoch: 5| Step: 1
Training loss: 2.826200008392334
Validation loss: 2.212000587935089

Epoch: 5| Step: 2
Training loss: 2.4175267219543457
Validation loss: 2.2064097799280638

Epoch: 5| Step: 3
Training loss: 2.2977232933044434
Validation loss: 2.2050834189179125

Epoch: 5| Step: 4
Training loss: 1.6875015497207642
Validation loss: 2.1894177134319017

Epoch: 5| Step: 5
Training loss: 2.1660232543945312
Validation loss: 2.2009050807645245

Epoch: 5| Step: 6
Training loss: 2.575684070587158
Validation loss: 2.2057422335429857

Epoch: 5| Step: 7
Training loss: 2.611180067062378
Validation loss: 2.204462318010228

Epoch: 5| Step: 8
Training loss: 2.4540536403656006
Validation loss: 2.2187202181867374

Epoch: 5| Step: 9
Training loss: 3.1685829162597656
Validation loss: 2.2363931030355473

Epoch: 5| Step: 10
Training loss: 1.9612267017364502
Validation loss: 2.255102542138869

Epoch: 377| Step: 0
Training loss: 2.7563250064849854
Validation loss: 2.280766189739268

Epoch: 5| Step: 1
Training loss: 2.4912028312683105
Validation loss: 2.2815820042805006

Epoch: 5| Step: 2
Training loss: 2.45831561088562
Validation loss: 2.284535070901276

Epoch: 5| Step: 3
Training loss: 2.390923500061035
Validation loss: 2.2608648243770806

Epoch: 5| Step: 4
Training loss: 2.2358970642089844
Validation loss: 2.2677165180124264

Epoch: 5| Step: 5
Training loss: 2.0572667121887207
Validation loss: 2.267265381351594

Epoch: 5| Step: 6
Training loss: 2.051074981689453
Validation loss: 2.2538657957507717

Epoch: 5| Step: 7
Training loss: 2.3968911170959473
Validation loss: 2.248969552337482

Epoch: 5| Step: 8
Training loss: 2.199385404586792
Validation loss: 2.253585425756311

Epoch: 5| Step: 9
Training loss: 2.366612195968628
Validation loss: 2.2369721628004506

Epoch: 5| Step: 10
Training loss: 2.820115804672241
Validation loss: 2.2441453113350818

Epoch: 378| Step: 0
Training loss: 2.453496217727661
Validation loss: 2.245925180373653

Epoch: 5| Step: 1
Training loss: 2.684312105178833
Validation loss: 2.2416179756964407

Epoch: 5| Step: 2
Training loss: 3.1523725986480713
Validation loss: 2.226695737531108

Epoch: 5| Step: 3
Training loss: 2.199021577835083
Validation loss: 2.230496169418417

Epoch: 5| Step: 4
Training loss: 2.512124538421631
Validation loss: 2.218553363635976

Epoch: 5| Step: 5
Training loss: 2.1705687046051025
Validation loss: 2.2292751778838453

Epoch: 5| Step: 6
Training loss: 2.461775064468384
Validation loss: 2.2185644436908025

Epoch: 5| Step: 7
Training loss: 1.829618215560913
Validation loss: 2.2125849070087558

Epoch: 5| Step: 8
Training loss: 1.9545276165008545
Validation loss: 2.212676130315309

Epoch: 5| Step: 9
Training loss: 2.6550397872924805
Validation loss: 2.2136571484227336

Epoch: 5| Step: 10
Training loss: 1.8119136095046997
Validation loss: 2.210547370295371

Epoch: 379| Step: 0
Training loss: 2.1599841117858887
Validation loss: 2.2231206817011677

Epoch: 5| Step: 1
Training loss: 2.5898656845092773
Validation loss: 2.2149231177504345

Epoch: 5| Step: 2
Training loss: 2.6272521018981934
Validation loss: 2.2158309080267466

Epoch: 5| Step: 3
Training loss: 1.877789855003357
Validation loss: 2.2212110463009087

Epoch: 5| Step: 4
Training loss: 2.330080509185791
Validation loss: 2.218854788810976

Epoch: 5| Step: 5
Training loss: 2.0896992683410645
Validation loss: 2.214147267803069

Epoch: 5| Step: 6
Training loss: 2.4013326168060303
Validation loss: 2.2111658806441934

Epoch: 5| Step: 7
Training loss: 2.4139244556427
Validation loss: 2.221038367158623

Epoch: 5| Step: 8
Training loss: 2.8436107635498047
Validation loss: 2.211543990719703

Epoch: 5| Step: 9
Training loss: 2.036313533782959
Validation loss: 2.217894951502482

Epoch: 5| Step: 10
Training loss: 2.68891978263855
Validation loss: 2.216772481959353

Epoch: 380| Step: 0
Training loss: 2.645918846130371
Validation loss: 2.2172098185426448

Epoch: 5| Step: 1
Training loss: 2.2637972831726074
Validation loss: 2.225406768501446

Epoch: 5| Step: 2
Training loss: 1.8376953601837158
Validation loss: 2.2293327136706282

Epoch: 5| Step: 3
Training loss: 2.504852771759033
Validation loss: 2.2330356438954673

Epoch: 5| Step: 4
Training loss: 2.230140209197998
Validation loss: 2.225372314453125

Epoch: 5| Step: 5
Training loss: 2.543062448501587
Validation loss: 2.2428904605168167

Epoch: 5| Step: 6
Training loss: 3.059849500656128
Validation loss: 2.2411157469595633

Epoch: 5| Step: 7
Training loss: 2.609558582305908
Validation loss: 2.2517365768391597

Epoch: 5| Step: 8
Training loss: 2.1246166229248047
Validation loss: 2.240207782355688

Epoch: 5| Step: 9
Training loss: 2.429701328277588
Validation loss: 2.2492881128864903

Epoch: 5| Step: 10
Training loss: 1.4329297542572021
Validation loss: 2.2447057782962756

Epoch: 381| Step: 0
Training loss: 2.5244274139404297
Validation loss: 2.2219505104967343

Epoch: 5| Step: 1
Training loss: 2.557518482208252
Validation loss: 2.218241207061275

Epoch: 5| Step: 2
Training loss: 2.090466022491455
Validation loss: 2.2175639419145483

Epoch: 5| Step: 3
Training loss: 2.263465404510498
Validation loss: 2.2126553366261144

Epoch: 5| Step: 4
Training loss: 2.2342238426208496
Validation loss: 2.215161100510628

Epoch: 5| Step: 5
Training loss: 2.283773183822632
Validation loss: 2.2123829985177643

Epoch: 5| Step: 6
Training loss: 2.3422186374664307
Validation loss: 2.2273962625893216

Epoch: 5| Step: 7
Training loss: 2.4983344078063965
Validation loss: 2.220933605265874

Epoch: 5| Step: 8
Training loss: 1.9955189228057861
Validation loss: 2.234525667723789

Epoch: 5| Step: 9
Training loss: 2.5996012687683105
Validation loss: 2.2156778048443537

Epoch: 5| Step: 10
Training loss: 2.4471323490142822
Validation loss: 2.2245137588952177

Epoch: 382| Step: 0
Training loss: 2.5582454204559326
Validation loss: 2.231303579063826

Epoch: 5| Step: 1
Training loss: 2.3054566383361816
Validation loss: 2.226007946075932

Epoch: 5| Step: 2
Training loss: 1.7167819738388062
Validation loss: 2.2193616923465522

Epoch: 5| Step: 3
Training loss: 2.568013906478882
Validation loss: 2.221365764576902

Epoch: 5| Step: 4
Training loss: 2.114715099334717
Validation loss: 2.21005694840544

Epoch: 5| Step: 5
Training loss: 2.393270492553711
Validation loss: 2.2150426910769556

Epoch: 5| Step: 6
Training loss: 2.2765862941741943
Validation loss: 2.2127708491458686

Epoch: 5| Step: 7
Training loss: 2.1694867610931396
Validation loss: 2.2138493881430676

Epoch: 5| Step: 8
Training loss: 2.9112820625305176
Validation loss: 2.221733605989846

Epoch: 5| Step: 9
Training loss: 2.403589963912964
Validation loss: 2.2265546706414994

Epoch: 5| Step: 10
Training loss: 2.336395263671875
Validation loss: 2.229344032144034

Epoch: 383| Step: 0
Training loss: 1.873706579208374
Validation loss: 2.2286400166890954

Epoch: 5| Step: 1
Training loss: 3.0193963050842285
Validation loss: 2.2362804771751486

Epoch: 5| Step: 2
Training loss: 3.0137526988983154
Validation loss: 2.246740274531867

Epoch: 5| Step: 3
Training loss: 2.073582172393799
Validation loss: 2.237085901280885

Epoch: 5| Step: 4
Training loss: 2.3399221897125244
Validation loss: 2.2542711355352916

Epoch: 5| Step: 5
Training loss: 1.899404764175415
Validation loss: 2.252110924772037

Epoch: 5| Step: 6
Training loss: 1.754463791847229
Validation loss: 2.2364469728162213

Epoch: 5| Step: 7
Training loss: 2.5298614501953125
Validation loss: 2.236194593932039

Epoch: 5| Step: 8
Training loss: 2.2283356189727783
Validation loss: 2.2336560705656647

Epoch: 5| Step: 9
Training loss: 2.5772671699523926
Validation loss: 2.231396726382676

Epoch: 5| Step: 10
Training loss: 2.39670467376709
Validation loss: 2.224398656557965

Epoch: 384| Step: 0
Training loss: 2.318002223968506
Validation loss: 2.2130194787056214

Epoch: 5| Step: 1
Training loss: 2.570651054382324
Validation loss: 2.20869271473218

Epoch: 5| Step: 2
Training loss: 2.352130889892578
Validation loss: 2.220497877367081

Epoch: 5| Step: 3
Training loss: 2.8640778064727783
Validation loss: 2.2061917140919673

Epoch: 5| Step: 4
Training loss: 2.737910747528076
Validation loss: 2.210515775988179

Epoch: 5| Step: 5
Training loss: 2.539599657058716
Validation loss: 2.2112487528913762

Epoch: 5| Step: 6
Training loss: 2.3458569049835205
Validation loss: 2.2043980552304174

Epoch: 5| Step: 7
Training loss: 1.6915760040283203
Validation loss: 2.2022508882707164

Epoch: 5| Step: 8
Training loss: 2.020381450653076
Validation loss: 2.2035302295479724

Epoch: 5| Step: 9
Training loss: 1.7210661172866821
Validation loss: 2.2133379956727386

Epoch: 5| Step: 10
Training loss: 2.718569755554199
Validation loss: 2.231843953491539

Epoch: 385| Step: 0
Training loss: 2.5797908306121826
Validation loss: 2.2427283871558403

Epoch: 5| Step: 1
Training loss: 2.863102436065674
Validation loss: 2.251250451610934

Epoch: 5| Step: 2
Training loss: 1.8912627696990967
Validation loss: 2.2712605230269896

Epoch: 5| Step: 3
Training loss: 2.5071167945861816
Validation loss: 2.2894667835645777

Epoch: 5| Step: 4
Training loss: 2.9996323585510254
Validation loss: 2.2804405509784655

Epoch: 5| Step: 5
Training loss: 2.055154323577881
Validation loss: 2.2637294518050326

Epoch: 5| Step: 6
Training loss: 1.9523754119873047
Validation loss: 2.256767697231744

Epoch: 5| Step: 7
Training loss: 2.122296094894409
Validation loss: 2.242729530539564

Epoch: 5| Step: 8
Training loss: 2.32991361618042
Validation loss: 2.2236236244119625

Epoch: 5| Step: 9
Training loss: 2.494044542312622
Validation loss: 2.2260907644866617

Epoch: 5| Step: 10
Training loss: 2.0277979373931885
Validation loss: 2.215428654865552

Epoch: 386| Step: 0
Training loss: 2.3537356853485107
Validation loss: 2.224372991951563

Epoch: 5| Step: 1
Training loss: 2.304987907409668
Validation loss: 2.221004181010749

Epoch: 5| Step: 2
Training loss: 2.7680540084838867
Validation loss: 2.2121709444189586

Epoch: 5| Step: 3
Training loss: 2.4801878929138184
Validation loss: 2.2150899107738207

Epoch: 5| Step: 4
Training loss: 2.8427648544311523
Validation loss: 2.2136512315401466

Epoch: 5| Step: 5
Training loss: 2.8712055683135986
Validation loss: 2.216439086903808

Epoch: 5| Step: 6
Training loss: 2.157120943069458
Validation loss: 2.213614217696651

Epoch: 5| Step: 7
Training loss: 2.0018134117126465
Validation loss: 2.2230246848957513

Epoch: 5| Step: 8
Training loss: 1.968166708946228
Validation loss: 2.219170367845925

Epoch: 5| Step: 9
Training loss: 1.8855257034301758
Validation loss: 2.227792798831899

Epoch: 5| Step: 10
Training loss: 2.1560981273651123
Validation loss: 2.2265148111568984

Epoch: 387| Step: 0
Training loss: 1.7479900121688843
Validation loss: 2.220388158675163

Epoch: 5| Step: 1
Training loss: 2.1313812732696533
Validation loss: 2.223175505156158

Epoch: 5| Step: 2
Training loss: 2.61682391166687
Validation loss: 2.234828761828843

Epoch: 5| Step: 3
Training loss: 2.1707677841186523
Validation loss: 2.21949988924047

Epoch: 5| Step: 4
Training loss: 1.9041917324066162
Validation loss: 2.228411284826135

Epoch: 5| Step: 5
Training loss: 2.660407304763794
Validation loss: 2.231382780177619

Epoch: 5| Step: 6
Training loss: 2.0875244140625
Validation loss: 2.223261385835627

Epoch: 5| Step: 7
Training loss: 2.0505943298339844
Validation loss: 2.2233718185014624

Epoch: 5| Step: 8
Training loss: 3.0937461853027344
Validation loss: 2.2218468291785127

Epoch: 5| Step: 9
Training loss: 2.8074069023132324
Validation loss: 2.2234178640509166

Epoch: 5| Step: 10
Training loss: 2.386413097381592
Validation loss: 2.2091227090486916

Epoch: 388| Step: 0
Training loss: 2.7592124938964844
Validation loss: 2.2068477240941857

Epoch: 5| Step: 1
Training loss: 2.4262073040008545
Validation loss: 2.2001579423104562

Epoch: 5| Step: 2
Training loss: 2.6115646362304688
Validation loss: 2.1977550624519266

Epoch: 5| Step: 3
Training loss: 2.0732779502868652
Validation loss: 2.191541467943499

Epoch: 5| Step: 4
Training loss: 2.419724702835083
Validation loss: 2.1970142831084547

Epoch: 5| Step: 5
Training loss: 2.468989610671997
Validation loss: 2.2041136269928305

Epoch: 5| Step: 6
Training loss: 1.8500261306762695
Validation loss: 2.2033813294544013

Epoch: 5| Step: 7
Training loss: 2.2653870582580566
Validation loss: 2.212127749637891

Epoch: 5| Step: 8
Training loss: 2.494483470916748
Validation loss: 2.22375165647076

Epoch: 5| Step: 9
Training loss: 2.20167875289917
Validation loss: 2.2252487008289625

Epoch: 5| Step: 10
Training loss: 2.16567325592041
Validation loss: 2.2247852253657516

Epoch: 389| Step: 0
Training loss: 2.5160093307495117
Validation loss: 2.2241612531805552

Epoch: 5| Step: 1
Training loss: 2.3594486713409424
Validation loss: 2.2401490237123225

Epoch: 5| Step: 2
Training loss: 2.9050750732421875
Validation loss: 2.242142083824322

Epoch: 5| Step: 3
Training loss: 2.107682466506958
Validation loss: 2.2276758276006228

Epoch: 5| Step: 4
Training loss: 2.451112985610962
Validation loss: 2.224763342129287

Epoch: 5| Step: 5
Training loss: 1.9868781566619873
Validation loss: 2.220535565448064

Epoch: 5| Step: 6
Training loss: 2.3449461460113525
Validation loss: 2.2139208188620945

Epoch: 5| Step: 7
Training loss: 2.9169514179229736
Validation loss: 2.2013204995022027

Epoch: 5| Step: 8
Training loss: 1.7645492553710938
Validation loss: 2.224705775578817

Epoch: 5| Step: 9
Training loss: 2.051231861114502
Validation loss: 2.2142344405574184

Epoch: 5| Step: 10
Training loss: 2.3079187870025635
Validation loss: 2.213891085758004

Epoch: 390| Step: 0
Training loss: 2.169623851776123
Validation loss: 2.226080030523321

Epoch: 5| Step: 1
Training loss: 2.2161622047424316
Validation loss: 2.2327336893286756

Epoch: 5| Step: 2
Training loss: 2.527465581893921
Validation loss: 2.2326671795178483

Epoch: 5| Step: 3
Training loss: 2.860670566558838
Validation loss: 2.2322952003889185

Epoch: 5| Step: 4
Training loss: 2.6570117473602295
Validation loss: 2.234918171359647

Epoch: 5| Step: 5
Training loss: 2.111948013305664
Validation loss: 2.239182908047912

Epoch: 5| Step: 6
Training loss: 3.1685001850128174
Validation loss: 2.228297077199464

Epoch: 5| Step: 7
Training loss: 1.7938735485076904
Validation loss: 2.237415306029781

Epoch: 5| Step: 8
Training loss: 2.058051347732544
Validation loss: 2.2226885236719602

Epoch: 5| Step: 9
Training loss: 2.5890915393829346
Validation loss: 2.2208393209724018

Epoch: 5| Step: 10
Training loss: 1.247984766960144
Validation loss: 2.2127538675902994

Epoch: 391| Step: 0
Training loss: 2.524055242538452
Validation loss: 2.2122605282773256

Epoch: 5| Step: 1
Training loss: 2.1894583702087402
Validation loss: 2.213317435274842

Epoch: 5| Step: 2
Training loss: 2.7690606117248535
Validation loss: 2.218899573049238

Epoch: 5| Step: 3
Training loss: 2.720870018005371
Validation loss: 2.2209130217952113

Epoch: 5| Step: 4
Training loss: 1.9921722412109375
Validation loss: 2.240528239998766

Epoch: 5| Step: 5
Training loss: 2.063889265060425
Validation loss: 2.2354647036521667

Epoch: 5| Step: 6
Training loss: 2.550750255584717
Validation loss: 2.235695885073754

Epoch: 5| Step: 7
Training loss: 2.2146239280700684
Validation loss: 2.228188448054816

Epoch: 5| Step: 8
Training loss: 1.9818496704101562
Validation loss: 2.2173260399090347

Epoch: 5| Step: 9
Training loss: 1.9514048099517822
Validation loss: 2.2313439948584444

Epoch: 5| Step: 10
Training loss: 2.6782453060150146
Validation loss: 2.2381264266147407

Epoch: 392| Step: 0
Training loss: 2.098069667816162
Validation loss: 2.230507171282204

Epoch: 5| Step: 1
Training loss: 2.4727447032928467
Validation loss: 2.22081285010102

Epoch: 5| Step: 2
Training loss: 2.3287863731384277
Validation loss: 2.2230246220865557

Epoch: 5| Step: 3
Training loss: 2.14701771736145
Validation loss: 2.222776292472757

Epoch: 5| Step: 4
Training loss: 2.4782333374023438
Validation loss: 2.2220687609846874

Epoch: 5| Step: 5
Training loss: 1.8165805339813232
Validation loss: 2.2334699476918867

Epoch: 5| Step: 6
Training loss: 3.0179991722106934
Validation loss: 2.2302773844811226

Epoch: 5| Step: 7
Training loss: 3.1547203063964844
Validation loss: 2.238457948930802

Epoch: 5| Step: 8
Training loss: 1.5310351848602295
Validation loss: 2.2396303351207445

Epoch: 5| Step: 9
Training loss: 1.929650068283081
Validation loss: 2.223994534502747

Epoch: 5| Step: 10
Training loss: 2.603111743927002
Validation loss: 2.225762608230755

Epoch: 393| Step: 0
Training loss: 2.363132953643799
Validation loss: 2.2237829418592554

Epoch: 5| Step: 1
Training loss: 2.803330898284912
Validation loss: 2.222570816675822

Epoch: 5| Step: 2
Training loss: 2.5920023918151855
Validation loss: 2.206106480731759

Epoch: 5| Step: 3
Training loss: 2.2506368160247803
Validation loss: 2.215356078199161

Epoch: 5| Step: 4
Training loss: 2.1354126930236816
Validation loss: 2.219336405877144

Epoch: 5| Step: 5
Training loss: 2.646946668624878
Validation loss: 2.218337094911965

Epoch: 5| Step: 6
Training loss: 2.1128108501434326
Validation loss: 2.239597758939189

Epoch: 5| Step: 7
Training loss: 1.905013084411621
Validation loss: 2.243469866373206

Epoch: 5| Step: 8
Training loss: 2.334348201751709
Validation loss: 2.237301234276064

Epoch: 5| Step: 9
Training loss: 2.035893201828003
Validation loss: 2.212949183679396

Epoch: 5| Step: 10
Training loss: 2.2960376739501953
Validation loss: 2.20480497934485

Epoch: 394| Step: 0
Training loss: 2.5401413440704346
Validation loss: 2.2180073286897395

Epoch: 5| Step: 1
Training loss: 3.036705255508423
Validation loss: 2.2140531181007304

Epoch: 5| Step: 2
Training loss: 2.3485562801361084
Validation loss: 2.205644348616241

Epoch: 5| Step: 3
Training loss: 2.404987096786499
Validation loss: 2.2035409737658758

Epoch: 5| Step: 4
Training loss: 2.701159954071045
Validation loss: 2.1918595375553256

Epoch: 5| Step: 5
Training loss: 1.73542058467865
Validation loss: 2.1917820720262426

Epoch: 5| Step: 6
Training loss: 2.4969284534454346
Validation loss: 2.1910123953255276

Epoch: 5| Step: 7
Training loss: 2.3459033966064453
Validation loss: 2.19833202515879

Epoch: 5| Step: 8
Training loss: 1.9996337890625
Validation loss: 2.2156497483612387

Epoch: 5| Step: 9
Training loss: 1.9373490810394287
Validation loss: 2.2138663799532

Epoch: 5| Step: 10
Training loss: 1.9329768419265747
Validation loss: 2.2129031522299654

Epoch: 395| Step: 0
Training loss: 2.359612226486206
Validation loss: 2.2455309014166556

Epoch: 5| Step: 1
Training loss: 2.177767276763916
Validation loss: 2.253095369185171

Epoch: 5| Step: 2
Training loss: 2.0385518074035645
Validation loss: 2.2647075627439763

Epoch: 5| Step: 3
Training loss: 1.8514350652694702
Validation loss: 2.274029985550911

Epoch: 5| Step: 4
Training loss: 2.6729841232299805
Validation loss: 2.2607513461061703

Epoch: 5| Step: 5
Training loss: 3.3957889080047607
Validation loss: 2.2560269037882485

Epoch: 5| Step: 6
Training loss: 2.5661139488220215
Validation loss: 2.236843462913267

Epoch: 5| Step: 7
Training loss: 1.9711462259292603
Validation loss: 2.216527574805803

Epoch: 5| Step: 8
Training loss: 2.207906484603882
Validation loss: 2.2102352342297955

Epoch: 5| Step: 9
Training loss: 2.874682903289795
Validation loss: 2.20923606041939

Epoch: 5| Step: 10
Training loss: 1.4426100254058838
Validation loss: 2.2083625896002657

Epoch: 396| Step: 0
Training loss: 2.059288501739502
Validation loss: 2.2073360079078266

Epoch: 5| Step: 1
Training loss: 2.5311572551727295
Validation loss: 2.223063866297404

Epoch: 5| Step: 2
Training loss: 2.762751340866089
Validation loss: 2.228401973683347

Epoch: 5| Step: 3
Training loss: 1.9728147983551025
Validation loss: 2.239328504890524

Epoch: 5| Step: 4
Training loss: 2.106070041656494
Validation loss: 2.240386829581312

Epoch: 5| Step: 5
Training loss: 2.5394206047058105
Validation loss: 2.2396141380392094

Epoch: 5| Step: 6
Training loss: 2.1682090759277344
Validation loss: 2.229503285500311

Epoch: 5| Step: 7
Training loss: 2.3278119564056396
Validation loss: 2.2252852903899325

Epoch: 5| Step: 8
Training loss: 2.169027328491211
Validation loss: 2.2261159009830926

Epoch: 5| Step: 9
Training loss: 2.5845110416412354
Validation loss: 2.2264867598010647

Epoch: 5| Step: 10
Training loss: 2.4963016510009766
Validation loss: 2.231772017735307

Epoch: 397| Step: 0
Training loss: 2.6986823081970215
Validation loss: 2.2294895674592707

Epoch: 5| Step: 1
Training loss: 2.2303004264831543
Validation loss: 2.252870516110492

Epoch: 5| Step: 2
Training loss: 2.7237439155578613
Validation loss: 2.2695594654288342

Epoch: 5| Step: 3
Training loss: 2.4292402267456055
Validation loss: 2.2648310725406935

Epoch: 5| Step: 4
Training loss: 2.4369521141052246
Validation loss: 2.2634826475574124

Epoch: 5| Step: 5
Training loss: 1.6536182165145874
Validation loss: 2.2438309525930755

Epoch: 5| Step: 6
Training loss: 1.822763442993164
Validation loss: 2.2337675427877777

Epoch: 5| Step: 7
Training loss: 2.36381196975708
Validation loss: 2.242345561263382

Epoch: 5| Step: 8
Training loss: 2.333545207977295
Validation loss: 2.237517515818278

Epoch: 5| Step: 9
Training loss: 2.2356903553009033
Validation loss: 2.236654637962259

Epoch: 5| Step: 10
Training loss: 2.760988712310791
Validation loss: 2.231751262500722

Epoch: 398| Step: 0
Training loss: 2.9488861560821533
Validation loss: 2.234122799288842

Epoch: 5| Step: 1
Training loss: 2.113568067550659
Validation loss: 2.2249023170881372

Epoch: 5| Step: 2
Training loss: 2.3626391887664795
Validation loss: 2.2071421787302983

Epoch: 5| Step: 3
Training loss: 1.992327094078064
Validation loss: 2.2148814944810766

Epoch: 5| Step: 4
Training loss: 2.024750232696533
Validation loss: 2.223845854882271

Epoch: 5| Step: 5
Training loss: 2.33852219581604
Validation loss: 2.2238997438902497

Epoch: 5| Step: 6
Training loss: 2.4250497817993164
Validation loss: 2.2373540222003894

Epoch: 5| Step: 7
Training loss: 3.066819906234741
Validation loss: 2.241707262172494

Epoch: 5| Step: 8
Training loss: 1.77548348903656
Validation loss: 2.246233319723478

Epoch: 5| Step: 9
Training loss: 2.439476728439331
Validation loss: 2.2487797865303616

Epoch: 5| Step: 10
Training loss: 1.9094700813293457
Validation loss: 2.22808741241373

Epoch: 399| Step: 0
Training loss: 2.276087999343872
Validation loss: 2.2218622789588025

Epoch: 5| Step: 1
Training loss: 2.3081119060516357
Validation loss: 2.237368106842041

Epoch: 5| Step: 2
Training loss: 2.340322971343994
Validation loss: 2.231335952717771

Epoch: 5| Step: 3
Training loss: 2.6410083770751953
Validation loss: 2.2519591649373374

Epoch: 5| Step: 4
Training loss: 2.5683534145355225
Validation loss: 2.2377080071356987

Epoch: 5| Step: 5
Training loss: 2.723167896270752
Validation loss: 2.2482740391967115

Epoch: 5| Step: 6
Training loss: 2.0697245597839355
Validation loss: 2.255045619062198

Epoch: 5| Step: 7
Training loss: 2.4877281188964844
Validation loss: 2.26033188450721

Epoch: 5| Step: 8
Training loss: 1.900193452835083
Validation loss: 2.2628081331970873

Epoch: 5| Step: 9
Training loss: 1.9355103969573975
Validation loss: 2.241673477234379

Epoch: 5| Step: 10
Training loss: 2.2183990478515625
Validation loss: 2.2365040163840018

Epoch: 400| Step: 0
Training loss: 1.5904920101165771
Validation loss: 2.215673851710494

Epoch: 5| Step: 1
Training loss: 1.7888896465301514
Validation loss: 2.2116752773202877

Epoch: 5| Step: 2
Training loss: 2.598085641860962
Validation loss: 2.211816282682521

Epoch: 5| Step: 3
Training loss: 2.156893491744995
Validation loss: 2.200877771582655

Epoch: 5| Step: 4
Training loss: 2.0614919662475586
Validation loss: 2.2093295025569137

Epoch: 5| Step: 5
Training loss: 2.592078924179077
Validation loss: 2.2071272903873074

Epoch: 5| Step: 6
Training loss: 2.660261631011963
Validation loss: 2.217690606271067

Epoch: 5| Step: 7
Training loss: 2.114576816558838
Validation loss: 2.2262671839806343

Epoch: 5| Step: 8
Training loss: 2.393930673599243
Validation loss: 2.2252504441045944

Epoch: 5| Step: 9
Training loss: 2.440635919570923
Validation loss: 2.2215657080373457

Epoch: 5| Step: 10
Training loss: 3.0310750007629395
Validation loss: 2.2173307762351087

Epoch: 401| Step: 0
Training loss: 2.813063144683838
Validation loss: 2.2106716197024108

Epoch: 5| Step: 1
Training loss: 2.200791835784912
Validation loss: 2.217711930633873

Epoch: 5| Step: 2
Training loss: 2.2553844451904297
Validation loss: 2.212627895416752

Epoch: 5| Step: 3
Training loss: 2.6793293952941895
Validation loss: 2.208392855941608

Epoch: 5| Step: 4
Training loss: 2.017940044403076
Validation loss: 2.1967549247126423

Epoch: 5| Step: 5
Training loss: 2.025158405303955
Validation loss: 2.199798860857564

Epoch: 5| Step: 6
Training loss: 2.08209228515625
Validation loss: 2.2210232006606234

Epoch: 5| Step: 7
Training loss: 2.7601490020751953
Validation loss: 2.2080815889502086

Epoch: 5| Step: 8
Training loss: 2.202017068862915
Validation loss: 2.2197153388812976

Epoch: 5| Step: 9
Training loss: 1.776803970336914
Validation loss: 2.2358338679036787

Epoch: 5| Step: 10
Training loss: 2.586975574493408
Validation loss: 2.2278055119258102

Epoch: 402| Step: 0
Training loss: 2.6237292289733887
Validation loss: 2.2285628395695842

Epoch: 5| Step: 1
Training loss: 2.6342837810516357
Validation loss: 2.2437198726079797

Epoch: 5| Step: 2
Training loss: 1.7804553508758545
Validation loss: 2.249309426994734

Epoch: 5| Step: 3
Training loss: 1.8144404888153076
Validation loss: 2.2359127280532674

Epoch: 5| Step: 4
Training loss: 1.403570294380188
Validation loss: 2.247580720532325

Epoch: 5| Step: 5
Training loss: 2.9701344966888428
Validation loss: 2.2340715085306475

Epoch: 5| Step: 6
Training loss: 2.6467080116271973
Validation loss: 2.2147827212528517

Epoch: 5| Step: 7
Training loss: 1.9928451776504517
Validation loss: 2.200803223476615

Epoch: 5| Step: 8
Training loss: 2.6530113220214844
Validation loss: 2.2044783048732306

Epoch: 5| Step: 9
Training loss: 2.792632579803467
Validation loss: 2.2007846883548203

Epoch: 5| Step: 10
Training loss: 2.092883586883545
Validation loss: 2.1859132525741414

Epoch: 403| Step: 0
Training loss: 2.474449872970581
Validation loss: 2.2028670003337245

Epoch: 5| Step: 1
Training loss: 1.8811126947402954
Validation loss: 2.191268813225531

Epoch: 5| Step: 2
Training loss: 2.46042799949646
Validation loss: 2.2051127392758607

Epoch: 5| Step: 3
Training loss: 2.7450242042541504
Validation loss: 2.217118937482116

Epoch: 5| Step: 4
Training loss: 2.4173107147216797
Validation loss: 2.2291631826790432

Epoch: 5| Step: 5
Training loss: 1.8192020654678345
Validation loss: 2.2289263868844635

Epoch: 5| Step: 6
Training loss: 1.9196170568466187
Validation loss: 2.220801830291748

Epoch: 5| Step: 7
Training loss: 2.624053716659546
Validation loss: 2.212308333766076

Epoch: 5| Step: 8
Training loss: 2.435554027557373
Validation loss: 2.232231722083143

Epoch: 5| Step: 9
Training loss: 2.3138840198516846
Validation loss: 2.2367868346552693

Epoch: 5| Step: 10
Training loss: 2.1464781761169434
Validation loss: 2.2472050010517077

Epoch: 404| Step: 0
Training loss: 2.0190577507019043
Validation loss: 2.2555827351026636

Epoch: 5| Step: 1
Training loss: 2.0419809818267822
Validation loss: 2.2491246782323366

Epoch: 5| Step: 2
Training loss: 2.2150988578796387
Validation loss: 2.25754968068933

Epoch: 5| Step: 3
Training loss: 2.118093252182007
Validation loss: 2.2365195699917373

Epoch: 5| Step: 4
Training loss: 2.059922933578491
Validation loss: 2.231687497067195

Epoch: 5| Step: 5
Training loss: 2.9000487327575684
Validation loss: 2.2252329395663355

Epoch: 5| Step: 6
Training loss: 2.237365245819092
Validation loss: 2.2306620074856665

Epoch: 5| Step: 7
Training loss: 2.0280306339263916
Validation loss: 2.2446075408689437

Epoch: 5| Step: 8
Training loss: 2.3331265449523926
Validation loss: 2.2484654700884255

Epoch: 5| Step: 9
Training loss: 2.7827811241149902
Validation loss: 2.250557156019313

Epoch: 5| Step: 10
Training loss: 2.6754419803619385
Validation loss: 2.244328801349927

Epoch: 405| Step: 0
Training loss: 1.860439658164978
Validation loss: 2.22714796117557

Epoch: 5| Step: 1
Training loss: 2.2810981273651123
Validation loss: 2.230616351609589

Epoch: 5| Step: 2
Training loss: 1.8904844522476196
Validation loss: 2.2123184101555937

Epoch: 5| Step: 3
Training loss: 2.363006353378296
Validation loss: 2.235734244828583

Epoch: 5| Step: 4
Training loss: 2.306927442550659
Validation loss: 2.2324809028256323

Epoch: 5| Step: 5
Training loss: 2.195955753326416
Validation loss: 2.2299425102049306

Epoch: 5| Step: 6
Training loss: 2.498020887374878
Validation loss: 2.234544256682037

Epoch: 5| Step: 7
Training loss: 2.494567632675171
Validation loss: 2.2311946333095594

Epoch: 5| Step: 8
Training loss: 2.237349033355713
Validation loss: 2.2324190037224882

Epoch: 5| Step: 9
Training loss: 2.2183821201324463
Validation loss: 2.2353185389631536

Epoch: 5| Step: 10
Training loss: 2.9927785396575928
Validation loss: 2.2304900077081498

Epoch: 406| Step: 0
Training loss: 2.2815635204315186
Validation loss: 2.2255583104266914

Epoch: 5| Step: 1
Training loss: 1.9157634973526
Validation loss: 2.228463629240631

Epoch: 5| Step: 2
Training loss: 2.4116055965423584
Validation loss: 2.2259800152112077

Epoch: 5| Step: 3
Training loss: 2.277515411376953
Validation loss: 2.224332430029428

Epoch: 5| Step: 4
Training loss: 2.255882740020752
Validation loss: 2.2375739543668685

Epoch: 5| Step: 5
Training loss: 1.7031217813491821
Validation loss: 2.236430411697716

Epoch: 5| Step: 6
Training loss: 2.5831234455108643
Validation loss: 2.2253134994096655

Epoch: 5| Step: 7
Training loss: 2.1060116291046143
Validation loss: 2.2356049732495378

Epoch: 5| Step: 8
Training loss: 2.166900396347046
Validation loss: 2.2349992695675103

Epoch: 5| Step: 9
Training loss: 2.7217724323272705
Validation loss: 2.2475898881112375

Epoch: 5| Step: 10
Training loss: 2.9239649772644043
Validation loss: 2.23565217884638

Epoch: 407| Step: 0
Training loss: 2.5368263721466064
Validation loss: 2.2437095411362185

Epoch: 5| Step: 1
Training loss: 2.7092647552490234
Validation loss: 2.225804680137224

Epoch: 5| Step: 2
Training loss: 2.3317251205444336
Validation loss: 2.2099922600612847

Epoch: 5| Step: 3
Training loss: 2.0319228172302246
Validation loss: 2.2097598788558797

Epoch: 5| Step: 4
Training loss: 2.3635916709899902
Validation loss: 2.2218384665827595

Epoch: 5| Step: 5
Training loss: 1.513800024986267
Validation loss: 2.212381262933054

Epoch: 5| Step: 6
Training loss: 2.2430901527404785
Validation loss: 2.2327917339981243

Epoch: 5| Step: 7
Training loss: 2.2559947967529297
Validation loss: 2.2294893495498167

Epoch: 5| Step: 8
Training loss: 2.4460747241973877
Validation loss: 2.238964206428938

Epoch: 5| Step: 9
Training loss: 2.578042507171631
Validation loss: 2.233234877227455

Epoch: 5| Step: 10
Training loss: 1.9730392694473267
Validation loss: 2.2380588157202608

Epoch: 408| Step: 0
Training loss: 2.7066848278045654
Validation loss: 2.232251610807193

Epoch: 5| Step: 1
Training loss: 2.525975465774536
Validation loss: 2.225090181955727

Epoch: 5| Step: 2
Training loss: 2.0876107215881348
Validation loss: 2.224143551241967

Epoch: 5| Step: 3
Training loss: 2.198516368865967
Validation loss: 2.235871463693598

Epoch: 5| Step: 4
Training loss: 2.24650502204895
Validation loss: 2.2405944896000687

Epoch: 5| Step: 5
Training loss: 2.2489442825317383
Validation loss: 2.2433038526965725

Epoch: 5| Step: 6
Training loss: 1.6865441799163818
Validation loss: 2.242665990706413

Epoch: 5| Step: 7
Training loss: 1.9183555841445923
Validation loss: 2.229313936284793

Epoch: 5| Step: 8
Training loss: 2.3939318656921387
Validation loss: 2.2284593197607223

Epoch: 5| Step: 9
Training loss: 2.363316297531128
Validation loss: 2.22995586036354

Epoch: 5| Step: 10
Training loss: 2.6756536960601807
Validation loss: 2.2259748007661555

Epoch: 409| Step: 0
Training loss: 2.02234148979187
Validation loss: 2.212474779416156

Epoch: 5| Step: 1
Training loss: 2.2693021297454834
Validation loss: 2.2124217223095637

Epoch: 5| Step: 2
Training loss: 2.2977824211120605
Validation loss: 2.1896812890165593

Epoch: 5| Step: 3
Training loss: 2.013702392578125
Validation loss: 2.2061246800166305

Epoch: 5| Step: 4
Training loss: 2.5455517768859863
Validation loss: 2.1962286708175496

Epoch: 5| Step: 5
Training loss: 2.2596564292907715
Validation loss: 2.204905585576129

Epoch: 5| Step: 6
Training loss: 2.5303988456726074
Validation loss: 2.2116209153206117

Epoch: 5| Step: 7
Training loss: 1.786159873008728
Validation loss: 2.220359995800962

Epoch: 5| Step: 8
Training loss: 2.53462290763855
Validation loss: 2.236209897584813

Epoch: 5| Step: 9
Training loss: 2.5564494132995605
Validation loss: 2.2392446110325475

Epoch: 5| Step: 10
Training loss: 2.4381489753723145
Validation loss: 2.2587702966505483

Epoch: 410| Step: 0
Training loss: 2.372466564178467
Validation loss: 2.23026365874916

Epoch: 5| Step: 1
Training loss: 1.8784761428833008
Validation loss: 2.2124185151951288

Epoch: 5| Step: 2
Training loss: 2.6563549041748047
Validation loss: 2.215041152892574

Epoch: 5| Step: 3
Training loss: 1.9793485403060913
Validation loss: 2.218879420270202

Epoch: 5| Step: 4
Training loss: 2.5490097999572754
Validation loss: 2.218348213421401

Epoch: 5| Step: 5
Training loss: 2.2315640449523926
Validation loss: 2.2286364468195106

Epoch: 5| Step: 6
Training loss: 2.6123909950256348
Validation loss: 2.2341518530281643

Epoch: 5| Step: 7
Training loss: 2.6063618659973145
Validation loss: 2.240543600051634

Epoch: 5| Step: 8
Training loss: 2.3160147666931152
Validation loss: 2.220751513716995

Epoch: 5| Step: 9
Training loss: 2.6062819957733154
Validation loss: 2.221817780566472

Epoch: 5| Step: 10
Training loss: 1.397261619567871
Validation loss: 2.194407182355081

Epoch: 411| Step: 0
Training loss: 2.198334217071533
Validation loss: 2.19127401485238

Epoch: 5| Step: 1
Training loss: 2.3828043937683105
Validation loss: 2.1964208541377896

Epoch: 5| Step: 2
Training loss: 2.217647075653076
Validation loss: 2.2092193070278374

Epoch: 5| Step: 3
Training loss: 2.234117269515991
Validation loss: 2.220914316433732

Epoch: 5| Step: 4
Training loss: 2.635148525238037
Validation loss: 2.223936201423727

Epoch: 5| Step: 5
Training loss: 2.0918936729431152
Validation loss: 2.218378407980806

Epoch: 5| Step: 6
Training loss: 2.953655242919922
Validation loss: 2.2193199614042878

Epoch: 5| Step: 7
Training loss: 2.0826401710510254
Validation loss: 2.205782316064322

Epoch: 5| Step: 8
Training loss: 2.576402187347412
Validation loss: 2.2076442869760657

Epoch: 5| Step: 9
Training loss: 1.765869140625
Validation loss: 2.2117422370500464

Epoch: 5| Step: 10
Training loss: 2.262380599975586
Validation loss: 2.205799020746703

Epoch: 412| Step: 0
Training loss: 1.8816139698028564
Validation loss: 2.220274317649103

Epoch: 5| Step: 1
Training loss: 2.5193142890930176
Validation loss: 2.2341315105397213

Epoch: 5| Step: 2
Training loss: 2.46250581741333
Validation loss: 2.229531870093397

Epoch: 5| Step: 3
Training loss: 2.3049590587615967
Validation loss: 2.2430067113650742

Epoch: 5| Step: 4
Training loss: 2.1541342735290527
Validation loss: 2.2564513119318153

Epoch: 5| Step: 5
Training loss: 3.0824668407440186
Validation loss: 2.250899609699044

Epoch: 5| Step: 6
Training loss: 2.120023012161255
Validation loss: 2.248589813068349

Epoch: 5| Step: 7
Training loss: 1.78106689453125
Validation loss: 2.22591257351701

Epoch: 5| Step: 8
Training loss: 2.8878824710845947
Validation loss: 2.2258299678884526

Epoch: 5| Step: 9
Training loss: 2.065619945526123
Validation loss: 2.1999092512233283

Epoch: 5| Step: 10
Training loss: 1.7220734357833862
Validation loss: 2.207378331051078

Epoch: 413| Step: 0
Training loss: 2.317981719970703
Validation loss: 2.2165728589539886

Epoch: 5| Step: 1
Training loss: 2.1645734310150146
Validation loss: 2.2176981843927854

Epoch: 5| Step: 2
Training loss: 2.023681640625
Validation loss: 2.2077553708066224

Epoch: 5| Step: 3
Training loss: 2.3955459594726562
Validation loss: 2.2041495974345873

Epoch: 5| Step: 4
Training loss: 1.8553669452667236
Validation loss: 2.2097548900112027

Epoch: 5| Step: 5
Training loss: 2.0898945331573486
Validation loss: 2.2145835225300123

Epoch: 5| Step: 6
Training loss: 2.540009021759033
Validation loss: 2.2184763364894415

Epoch: 5| Step: 7
Training loss: 2.254425048828125
Validation loss: 2.2209969784623835

Epoch: 5| Step: 8
Training loss: 2.7947332859039307
Validation loss: 2.2220838608280307

Epoch: 5| Step: 9
Training loss: 2.152564764022827
Validation loss: 2.222324255974062

Epoch: 5| Step: 10
Training loss: 2.3498592376708984
Validation loss: 2.2153065960894347

Epoch: 414| Step: 0
Training loss: 2.1497559547424316
Validation loss: 2.2152438804667485

Epoch: 5| Step: 1
Training loss: 2.5688462257385254
Validation loss: 2.2488943299939557

Epoch: 5| Step: 2
Training loss: 2.0364389419555664
Validation loss: 2.238399854270361

Epoch: 5| Step: 3
Training loss: 2.0317721366882324
Validation loss: 2.24979829788208

Epoch: 5| Step: 4
Training loss: 2.9972422122955322
Validation loss: 2.2509294632942445

Epoch: 5| Step: 5
Training loss: 2.814161777496338
Validation loss: 2.248344406004875

Epoch: 5| Step: 6
Training loss: 2.007333278656006
Validation loss: 2.2332025753554476

Epoch: 5| Step: 7
Training loss: 2.6897940635681152
Validation loss: 2.239649159933931

Epoch: 5| Step: 8
Training loss: 2.197978973388672
Validation loss: 2.2426032891837497

Epoch: 5| Step: 9
Training loss: 1.3510395288467407
Validation loss: 2.2422282695770264

Epoch: 5| Step: 10
Training loss: 2.122821092605591
Validation loss: 2.2403135684228714

Epoch: 415| Step: 0
Training loss: 1.5116571187973022
Validation loss: 2.2284437200074554

Epoch: 5| Step: 1
Training loss: 2.336082935333252
Validation loss: 2.206932588290143

Epoch: 5| Step: 2
Training loss: 2.471717357635498
Validation loss: 2.2147062824618433

Epoch: 5| Step: 3
Training loss: 1.8681236505508423
Validation loss: 2.197530387550272

Epoch: 5| Step: 4
Training loss: 2.378422975540161
Validation loss: 2.2033939271844845

Epoch: 5| Step: 5
Training loss: 2.678825616836548
Validation loss: 2.2213036193642566

Epoch: 5| Step: 6
Training loss: 2.5142345428466797
Validation loss: 2.2111299935207573

Epoch: 5| Step: 7
Training loss: 2.487827777862549
Validation loss: 2.1988971361549954

Epoch: 5| Step: 8
Training loss: 2.5466322898864746
Validation loss: 2.199546294827615

Epoch: 5| Step: 9
Training loss: 2.3428244590759277
Validation loss: 2.192917593063847

Epoch: 5| Step: 10
Training loss: 1.9321939945220947
Validation loss: 2.2027307043793383

Epoch: 416| Step: 0
Training loss: 2.200678586959839
Validation loss: 2.206963582705426

Epoch: 5| Step: 1
Training loss: 2.774704694747925
Validation loss: 2.2270994365856214

Epoch: 5| Step: 2
Training loss: 1.9300308227539062
Validation loss: 2.2378686653670443

Epoch: 5| Step: 3
Training loss: 1.9113876819610596
Validation loss: 2.247248770088278

Epoch: 5| Step: 4
Training loss: 2.460611343383789
Validation loss: 2.2523086096650813

Epoch: 5| Step: 5
Training loss: 2.3800549507141113
Validation loss: 2.254507044310211

Epoch: 5| Step: 6
Training loss: 1.7996963262557983
Validation loss: 2.2635092760926936

Epoch: 5| Step: 7
Training loss: 2.684723377227783
Validation loss: 2.232885373535977

Epoch: 5| Step: 8
Training loss: 2.2551918029785156
Validation loss: 2.2148301293773036

Epoch: 5| Step: 9
Training loss: 2.1202902793884277
Validation loss: 2.215484147430748

Epoch: 5| Step: 10
Training loss: 2.434659481048584
Validation loss: 2.2124380527004117

Epoch: 417| Step: 0
Training loss: 1.398827314376831
Validation loss: 2.2125858312012046

Epoch: 5| Step: 1
Training loss: 3.0377821922302246
Validation loss: 2.217498948497157

Epoch: 5| Step: 2
Training loss: 2.084321975708008
Validation loss: 2.2246508188145135

Epoch: 5| Step: 3
Training loss: 2.4152421951293945
Validation loss: 2.2318109761002245

Epoch: 5| Step: 4
Training loss: 1.9292110204696655
Validation loss: 2.228851790069252

Epoch: 5| Step: 5
Training loss: 2.878809690475464
Validation loss: 2.2316769258950346

Epoch: 5| Step: 6
Training loss: 1.9418672323226929
Validation loss: 2.2282028223878596

Epoch: 5| Step: 7
Training loss: 2.328005075454712
Validation loss: 2.2312691224518644

Epoch: 5| Step: 8
Training loss: 2.4818756580352783
Validation loss: 2.2234449719869964

Epoch: 5| Step: 9
Training loss: 1.902700662612915
Validation loss: 2.241486067413002

Epoch: 5| Step: 10
Training loss: 2.4910104274749756
Validation loss: 2.247976149282148

Epoch: 418| Step: 0
Training loss: 1.672244668006897
Validation loss: 2.2333282834740094

Epoch: 5| Step: 1
Training loss: 2.5977542400360107
Validation loss: 2.2221456368764243

Epoch: 5| Step: 2
Training loss: 2.305034875869751
Validation loss: 2.205844008794395

Epoch: 5| Step: 3
Training loss: 2.1679534912109375
Validation loss: 2.2026333167988765

Epoch: 5| Step: 4
Training loss: 2.4393908977508545
Validation loss: 2.186669034342612

Epoch: 5| Step: 5
Training loss: 2.5110507011413574
Validation loss: 2.1846624061625493

Epoch: 5| Step: 6
Training loss: 1.730974555015564
Validation loss: 2.190134991881668

Epoch: 5| Step: 7
Training loss: 2.2314319610595703
Validation loss: 2.2053300001287974

Epoch: 5| Step: 8
Training loss: 2.860900640487671
Validation loss: 2.227193163287255

Epoch: 5| Step: 9
Training loss: 2.188326597213745
Validation loss: 2.218927588514102

Epoch: 5| Step: 10
Training loss: 2.117034912109375
Validation loss: 2.2205823723987868

Epoch: 419| Step: 0
Training loss: 1.944397211074829
Validation loss: 2.2255833289956533

Epoch: 5| Step: 1
Training loss: 2.7534561157226562
Validation loss: 2.228193442026774

Epoch: 5| Step: 2
Training loss: 1.805542230606079
Validation loss: 2.2259713449785785

Epoch: 5| Step: 3
Training loss: 2.2612717151641846
Validation loss: 2.201968933946343

Epoch: 5| Step: 4
Training loss: 2.9361979961395264
Validation loss: 2.2132969658861876

Epoch: 5| Step: 5
Training loss: 2.169316291809082
Validation loss: 2.201618020252515

Epoch: 5| Step: 6
Training loss: 2.479501724243164
Validation loss: 2.2164994696135163

Epoch: 5| Step: 7
Training loss: 1.3494573831558228
Validation loss: 2.2067659234487884

Epoch: 5| Step: 8
Training loss: 2.2035930156707764
Validation loss: 2.1979976623289046

Epoch: 5| Step: 9
Training loss: 2.5738980770111084
Validation loss: 2.2043216100303074

Epoch: 5| Step: 10
Training loss: 2.2902634143829346
Validation loss: 2.201577930040257

Epoch: 420| Step: 0
Training loss: 2.2040927410125732
Validation loss: 2.2144283286986814

Epoch: 5| Step: 1
Training loss: 2.2903103828430176
Validation loss: 2.217894023464572

Epoch: 5| Step: 2
Training loss: 2.307107925415039
Validation loss: 2.211759210914694

Epoch: 5| Step: 3
Training loss: 2.507312297821045
Validation loss: 2.2170940650406705

Epoch: 5| Step: 4
Training loss: 2.032289505004883
Validation loss: 2.206438104311625

Epoch: 5| Step: 5
Training loss: 1.9032026529312134
Validation loss: 2.2044385274251304

Epoch: 5| Step: 6
Training loss: 2.502716064453125
Validation loss: 2.2098810006213445

Epoch: 5| Step: 7
Training loss: 2.3513002395629883
Validation loss: 2.2033262893717778

Epoch: 5| Step: 8
Training loss: 1.994990348815918
Validation loss: 2.2158951631156345

Epoch: 5| Step: 9
Training loss: 1.8785569667816162
Validation loss: 2.221667253842918

Epoch: 5| Step: 10
Training loss: 2.7106471061706543
Validation loss: 2.2224190106955906

Epoch: 421| Step: 0
Training loss: 2.5845561027526855
Validation loss: 2.2268070790075485

Epoch: 5| Step: 1
Training loss: 1.769533395767212
Validation loss: 2.223229113445487

Epoch: 5| Step: 2
Training loss: 2.528928279876709
Validation loss: 2.2273973213729037

Epoch: 5| Step: 3
Training loss: 2.4156441688537598
Validation loss: 2.237490761664606

Epoch: 5| Step: 4
Training loss: 2.4646689891815186
Validation loss: 2.2202675060559343

Epoch: 5| Step: 5
Training loss: 2.0320017337799072
Validation loss: 2.226106245030639

Epoch: 5| Step: 6
Training loss: 2.4743638038635254
Validation loss: 2.224465823942615

Epoch: 5| Step: 7
Training loss: 1.5374560356140137
Validation loss: 2.2253370118397537

Epoch: 5| Step: 8
Training loss: 2.4970765113830566
Validation loss: 2.2058384162123486

Epoch: 5| Step: 9
Training loss: 2.350689172744751
Validation loss: 2.2008398181648663

Epoch: 5| Step: 10
Training loss: 1.7601748704910278
Validation loss: 2.2017104625701904

Epoch: 422| Step: 0
Training loss: 1.9128036499023438
Validation loss: 2.1825541014312417

Epoch: 5| Step: 1
Training loss: 2.827465295791626
Validation loss: 2.189711804031044

Epoch: 5| Step: 2
Training loss: 2.281466245651245
Validation loss: 2.17936142926575

Epoch: 5| Step: 3
Training loss: 1.8978376388549805
Validation loss: 2.191106306609287

Epoch: 5| Step: 4
Training loss: 2.1747443675994873
Validation loss: 2.1927376203639533

Epoch: 5| Step: 5
Training loss: 2.8021769523620605
Validation loss: 2.1887389383008404

Epoch: 5| Step: 6
Training loss: 2.175880193710327
Validation loss: 2.2067313040456464

Epoch: 5| Step: 7
Training loss: 2.2611446380615234
Validation loss: 2.2098010624608686

Epoch: 5| Step: 8
Training loss: 2.591979503631592
Validation loss: 2.2210167249043784

Epoch: 5| Step: 9
Training loss: 1.703142762184143
Validation loss: 2.2233879232919342

Epoch: 5| Step: 10
Training loss: 2.0297110080718994
Validation loss: 2.235886363572972

Epoch: 423| Step: 0
Training loss: 1.6604840755462646
Validation loss: 2.247006659866661

Epoch: 5| Step: 1
Training loss: 2.2882351875305176
Validation loss: 2.235699035788095

Epoch: 5| Step: 2
Training loss: 1.760965347290039
Validation loss: 2.2237928285393664

Epoch: 5| Step: 3
Training loss: 2.9655208587646484
Validation loss: 2.2213881246505247

Epoch: 5| Step: 4
Training loss: 1.9493255615234375
Validation loss: 2.2290936362358833

Epoch: 5| Step: 5
Training loss: 2.9573616981506348
Validation loss: 2.2096629527307328

Epoch: 5| Step: 6
Training loss: 2.021718978881836
Validation loss: 2.2198890870617283

Epoch: 5| Step: 7
Training loss: 2.504776954650879
Validation loss: 2.22085549113571

Epoch: 5| Step: 8
Training loss: 1.5962121486663818
Validation loss: 2.2257861706518356

Epoch: 5| Step: 9
Training loss: 2.3062000274658203
Validation loss: 2.2185700375546693

Epoch: 5| Step: 10
Training loss: 2.5940921306610107
Validation loss: 2.215620284439415

Epoch: 424| Step: 0
Training loss: 2.0506339073181152
Validation loss: 2.199401040231028

Epoch: 5| Step: 1
Training loss: 2.8292222023010254
Validation loss: 2.200977007548014

Epoch: 5| Step: 2
Training loss: 2.044891595840454
Validation loss: 2.195604670432306

Epoch: 5| Step: 3
Training loss: 1.8799912929534912
Validation loss: 2.198490955496347

Epoch: 5| Step: 4
Training loss: 1.838804841041565
Validation loss: 2.1936678706958728

Epoch: 5| Step: 5
Training loss: 1.5886995792388916
Validation loss: 2.1897460914427236

Epoch: 5| Step: 6
Training loss: 2.6056747436523438
Validation loss: 2.194454890425487

Epoch: 5| Step: 7
Training loss: 2.689375162124634
Validation loss: 2.183619709425075

Epoch: 5| Step: 8
Training loss: 2.424828052520752
Validation loss: 2.1966388174282607

Epoch: 5| Step: 9
Training loss: 2.5055553913116455
Validation loss: 2.19775455228744

Epoch: 5| Step: 10
Training loss: 2.047004222869873
Validation loss: 2.1946608174231743

Epoch: 425| Step: 0
Training loss: 2.71449613571167
Validation loss: 2.193534835692375

Epoch: 5| Step: 1
Training loss: 2.3617587089538574
Validation loss: 2.210483222879389

Epoch: 5| Step: 2
Training loss: 1.8640226125717163
Validation loss: 2.2099608298270934

Epoch: 5| Step: 3
Training loss: 2.31518292427063
Validation loss: 2.2118357278967418

Epoch: 5| Step: 4
Training loss: 2.516026735305786
Validation loss: 2.2182664602033553

Epoch: 5| Step: 5
Training loss: 2.2037887573242188
Validation loss: 2.2197946912498883

Epoch: 5| Step: 6
Training loss: 2.431431531906128
Validation loss: 2.2341527874751756

Epoch: 5| Step: 7
Training loss: 2.7977399826049805
Validation loss: 2.2353318352853098

Epoch: 5| Step: 8
Training loss: 1.626328706741333
Validation loss: 2.229139630512525

Epoch: 5| Step: 9
Training loss: 2.0697154998779297
Validation loss: 2.218878819096473

Epoch: 5| Step: 10
Training loss: 1.3933219909667969
Validation loss: 2.2257520255222114

Epoch: 426| Step: 0
Training loss: 2.106813430786133
Validation loss: 2.21930851474885

Epoch: 5| Step: 1
Training loss: 2.091350793838501
Validation loss: 2.2195949656988985

Epoch: 5| Step: 2
Training loss: 2.2429840564727783
Validation loss: 2.2164201172449256

Epoch: 5| Step: 3
Training loss: 2.195690155029297
Validation loss: 2.204384857608426

Epoch: 5| Step: 4
Training loss: 2.4771275520324707
Validation loss: 2.2016246011180263

Epoch: 5| Step: 5
Training loss: 2.4573497772216797
Validation loss: 2.2125623303074993

Epoch: 5| Step: 6
Training loss: 2.137953281402588
Validation loss: 2.204567955386254

Epoch: 5| Step: 7
Training loss: 2.4535000324249268
Validation loss: 2.199197881965227

Epoch: 5| Step: 8
Training loss: 1.9365160465240479
Validation loss: 2.190934741368858

Epoch: 5| Step: 9
Training loss: 2.615480422973633
Validation loss: 2.186947545697612

Epoch: 5| Step: 10
Training loss: 1.7879360914230347
Validation loss: 2.1928786513625935

Epoch: 427| Step: 0
Training loss: 2.3487586975097656
Validation loss: 2.1957091798064527

Epoch: 5| Step: 1
Training loss: 2.2712714672088623
Validation loss: 2.2067211340832453

Epoch: 5| Step: 2
Training loss: 2.8480091094970703
Validation loss: 2.211665568813201

Epoch: 5| Step: 3
Training loss: 2.375070810317993
Validation loss: 2.220370190117949

Epoch: 5| Step: 4
Training loss: 1.382036805152893
Validation loss: 2.2327034370873564

Epoch: 5| Step: 5
Training loss: 2.5985801219940186
Validation loss: 2.2503161020176385

Epoch: 5| Step: 6
Training loss: 2.418121337890625
Validation loss: 2.249281467929963

Epoch: 5| Step: 7
Training loss: 1.5814182758331299
Validation loss: 2.2425630361803117

Epoch: 5| Step: 8
Training loss: 2.0785000324249268
Validation loss: 2.2115728778223835

Epoch: 5| Step: 9
Training loss: 2.5076756477355957
Validation loss: 2.2351464404854724

Epoch: 5| Step: 10
Training loss: 2.1505537033081055
Validation loss: 2.2392788317895707

Epoch: 428| Step: 0
Training loss: 2.6983795166015625
Validation loss: 2.2269867953433784

Epoch: 5| Step: 1
Training loss: 2.339019298553467
Validation loss: 2.2325626291254514

Epoch: 5| Step: 2
Training loss: 2.0709571838378906
Validation loss: 2.2309205826892646

Epoch: 5| Step: 3
Training loss: 1.5337028503417969
Validation loss: 2.2239278542098178

Epoch: 5| Step: 4
Training loss: 2.6561007499694824
Validation loss: 2.2234813039020827

Epoch: 5| Step: 5
Training loss: 2.3057408332824707
Validation loss: 2.2206403465681177

Epoch: 5| Step: 6
Training loss: 1.7462444305419922
Validation loss: 2.205278763207056

Epoch: 5| Step: 7
Training loss: 2.4041004180908203
Validation loss: 2.2226707371332313

Epoch: 5| Step: 8
Training loss: 2.8055431842803955
Validation loss: 2.220819630930501

Epoch: 5| Step: 9
Training loss: 1.3351482152938843
Validation loss: 2.231728769117786

Epoch: 5| Step: 10
Training loss: 2.8042469024658203
Validation loss: 2.2621019527476323

Epoch: 429| Step: 0
Training loss: 2.1382923126220703
Validation loss: 2.237896215531134

Epoch: 5| Step: 1
Training loss: 2.9126243591308594
Validation loss: 2.2294435936917543

Epoch: 5| Step: 2
Training loss: 2.040879487991333
Validation loss: 2.2166998745292745

Epoch: 5| Step: 3
Training loss: 2.4056434631347656
Validation loss: 2.196164510583365

Epoch: 5| Step: 4
Training loss: 2.367954730987549
Validation loss: 2.183062953333701

Epoch: 5| Step: 5
Training loss: 2.360952615737915
Validation loss: 2.1789699703134517

Epoch: 5| Step: 6
Training loss: 2.329094648361206
Validation loss: 2.1679091017733336

Epoch: 5| Step: 7
Training loss: 2.468719720840454
Validation loss: 2.1819489297046455

Epoch: 5| Step: 8
Training loss: 1.9625390768051147
Validation loss: 2.2039956585053475

Epoch: 5| Step: 9
Training loss: 2.148604393005371
Validation loss: 2.20778775471513

Epoch: 5| Step: 10
Training loss: 1.4631109237670898
Validation loss: 2.207524104784894

Epoch: 430| Step: 0
Training loss: 1.622693657875061
Validation loss: 2.2267712726387927

Epoch: 5| Step: 1
Training loss: 2.105576992034912
Validation loss: 2.2261676147419918

Epoch: 5| Step: 2
Training loss: 1.9983060359954834
Validation loss: 2.2203167702562068

Epoch: 5| Step: 3
Training loss: 2.2311534881591797
Validation loss: 2.232249931622577

Epoch: 5| Step: 4
Training loss: 2.1780714988708496
Validation loss: 2.225092200822728

Epoch: 5| Step: 5
Training loss: 2.3864948749542236
Validation loss: 2.221968012471353

Epoch: 5| Step: 6
Training loss: 2.7827813625335693
Validation loss: 2.2433502353647703

Epoch: 5| Step: 7
Training loss: 2.1176462173461914
Validation loss: 2.248922207022226

Epoch: 5| Step: 8
Training loss: 2.3693366050720215
Validation loss: 2.2520127270811345

Epoch: 5| Step: 9
Training loss: 2.3091092109680176
Validation loss: 2.2772611674442085

Epoch: 5| Step: 10
Training loss: 2.666856288909912
Validation loss: 2.249110990954984

Epoch: 431| Step: 0
Training loss: 2.5753848552703857
Validation loss: 2.2620524847379295

Epoch: 5| Step: 1
Training loss: 2.0541749000549316
Validation loss: 2.2383137338904926

Epoch: 5| Step: 2
Training loss: 1.9659826755523682
Validation loss: 2.206626263997888

Epoch: 5| Step: 3
Training loss: 2.304002285003662
Validation loss: 2.199886311766922

Epoch: 5| Step: 4
Training loss: 2.5655601024627686
Validation loss: 2.199341889350645

Epoch: 5| Step: 5
Training loss: 2.0646347999572754
Validation loss: 2.1814170037546465

Epoch: 5| Step: 6
Training loss: 2.1493356227874756
Validation loss: 2.195405116645239

Epoch: 5| Step: 7
Training loss: 2.489440441131592
Validation loss: 2.1863941197754233

Epoch: 5| Step: 8
Training loss: 2.1886119842529297
Validation loss: 2.1851250945880847

Epoch: 5| Step: 9
Training loss: 2.1615214347839355
Validation loss: 2.17958253429782

Epoch: 5| Step: 10
Training loss: 2.0434417724609375
Validation loss: 2.182292986941594

Epoch: 432| Step: 0
Training loss: 1.9136464595794678
Validation loss: 2.180076388902562

Epoch: 5| Step: 1
Training loss: 2.2477567195892334
Validation loss: 2.1882266588108514

Epoch: 5| Step: 2
Training loss: 2.422079563140869
Validation loss: 2.1902821602359897

Epoch: 5| Step: 3
Training loss: 2.291776657104492
Validation loss: 2.1970329207758748

Epoch: 5| Step: 4
Training loss: 2.3153560161590576
Validation loss: 2.1923110869623

Epoch: 5| Step: 5
Training loss: 1.8140140771865845
Validation loss: 2.200734107725082

Epoch: 5| Step: 6
Training loss: 1.9950958490371704
Validation loss: 2.1962458087551977

Epoch: 5| Step: 7
Training loss: 2.101637363433838
Validation loss: 2.2159473716571765

Epoch: 5| Step: 8
Training loss: 2.69749116897583
Validation loss: 2.195083292581702

Epoch: 5| Step: 9
Training loss: 2.2431492805480957
Validation loss: 2.2124599359368764

Epoch: 5| Step: 10
Training loss: 2.265265941619873
Validation loss: 2.1998786016177108

Epoch: 433| Step: 0
Training loss: 2.887017011642456
Validation loss: 2.2111662433993433

Epoch: 5| Step: 1
Training loss: 1.470232605934143
Validation loss: 2.213907180293914

Epoch: 5| Step: 2
Training loss: 2.0242393016815186
Validation loss: 2.2007759027583624

Epoch: 5| Step: 3
Training loss: 2.573831558227539
Validation loss: 2.195357758511779

Epoch: 5| Step: 4
Training loss: 2.1124744415283203
Validation loss: 2.1963281580196914

Epoch: 5| Step: 5
Training loss: 1.8137037754058838
Validation loss: 2.1962651155328237

Epoch: 5| Step: 6
Training loss: 1.8728361129760742
Validation loss: 2.1892219974148657

Epoch: 5| Step: 7
Training loss: 1.8544867038726807
Validation loss: 2.1941986929985786

Epoch: 5| Step: 8
Training loss: 2.7959859371185303
Validation loss: 2.2033967266800585

Epoch: 5| Step: 9
Training loss: 2.651259183883667
Validation loss: 2.2213968179559194

Epoch: 5| Step: 10
Training loss: 2.288372278213501
Validation loss: 2.2159135264735066

Epoch: 434| Step: 0
Training loss: 2.0041251182556152
Validation loss: 2.232366882344728

Epoch: 5| Step: 1
Training loss: 1.9554812908172607
Validation loss: 2.2300942021031536

Epoch: 5| Step: 2
Training loss: 2.047288179397583
Validation loss: 2.229668060938517

Epoch: 5| Step: 3
Training loss: 2.3786873817443848
Validation loss: 2.223181373329573

Epoch: 5| Step: 4
Training loss: 2.5227677822113037
Validation loss: 2.235051288399645

Epoch: 5| Step: 5
Training loss: 2.5350182056427
Validation loss: 2.2267341754769765

Epoch: 5| Step: 6
Training loss: 1.613904595375061
Validation loss: 2.2033796105333554

Epoch: 5| Step: 7
Training loss: 2.5151419639587402
Validation loss: 2.2162826932886595

Epoch: 5| Step: 8
Training loss: 1.8872467279434204
Validation loss: 2.210036434153075

Epoch: 5| Step: 9
Training loss: 2.234091281890869
Validation loss: 2.2008439135807816

Epoch: 5| Step: 10
Training loss: 2.6454296112060547
Validation loss: 2.2052306231632026

Epoch: 435| Step: 0
Training loss: 1.706773042678833
Validation loss: 2.190176333150556

Epoch: 5| Step: 1
Training loss: 2.6488735675811768
Validation loss: 2.1915304558251494

Epoch: 5| Step: 2
Training loss: 3.21358060836792
Validation loss: 2.1921749345717894

Epoch: 5| Step: 3
Training loss: 1.91005539894104
Validation loss: 2.200593533054475

Epoch: 5| Step: 4
Training loss: 2.4017839431762695
Validation loss: 2.194184850620967

Epoch: 5| Step: 5
Training loss: 2.339381694793701
Validation loss: 2.183561699364775

Epoch: 5| Step: 6
Training loss: 1.7083841562271118
Validation loss: 2.1750454415557203

Epoch: 5| Step: 7
Training loss: 1.7350711822509766
Validation loss: 2.1830535447725685

Epoch: 5| Step: 8
Training loss: 1.6939976215362549
Validation loss: 2.185500832014186

Epoch: 5| Step: 9
Training loss: 2.49271821975708
Validation loss: 2.193760715505128

Epoch: 5| Step: 10
Training loss: 2.3427584171295166
Validation loss: 2.1928750366292973

Epoch: 436| Step: 0
Training loss: 2.1844820976257324
Validation loss: 2.2000360950346916

Epoch: 5| Step: 1
Training loss: 2.118983745574951
Validation loss: 2.210043291891775

Epoch: 5| Step: 2
Training loss: 1.8693199157714844
Validation loss: 2.225692464459327

Epoch: 5| Step: 3
Training loss: 2.228210926055908
Validation loss: 2.231793825344373

Epoch: 5| Step: 4
Training loss: 2.230823516845703
Validation loss: 2.2300877750560804

Epoch: 5| Step: 5
Training loss: 1.8638187646865845
Validation loss: 2.23165467990342

Epoch: 5| Step: 6
Training loss: 2.340864658355713
Validation loss: 2.2136105721996677

Epoch: 5| Step: 7
Training loss: 2.0177574157714844
Validation loss: 2.21092878618548

Epoch: 5| Step: 8
Training loss: 2.542598009109497
Validation loss: 2.221040064288724

Epoch: 5| Step: 9
Training loss: 2.351518392562866
Validation loss: 2.215767518166573

Epoch: 5| Step: 10
Training loss: 2.4013729095458984
Validation loss: 2.218608174272763

Epoch: 437| Step: 0
Training loss: 2.6590940952301025
Validation loss: 2.2042778999574724

Epoch: 5| Step: 1
Training loss: 2.3663125038146973
Validation loss: 2.2070624956520657

Epoch: 5| Step: 2
Training loss: 2.1466259956359863
Validation loss: 2.219005306561788

Epoch: 5| Step: 3
Training loss: 2.208277463912964
Validation loss: 2.2138157070323987

Epoch: 5| Step: 4
Training loss: 1.9893372058868408
Validation loss: 2.1996004786542667

Epoch: 5| Step: 5
Training loss: 2.4889280796051025
Validation loss: 2.2029089825127715

Epoch: 5| Step: 6
Training loss: 2.0730109214782715
Validation loss: 2.213435644744545

Epoch: 5| Step: 7
Training loss: 2.198739767074585
Validation loss: 2.2095768579872708

Epoch: 5| Step: 8
Training loss: 1.8792394399642944
Validation loss: 2.2117335463082917

Epoch: 5| Step: 9
Training loss: 1.9617998600006104
Validation loss: 2.1996556482007428

Epoch: 5| Step: 10
Training loss: 2.2429087162017822
Validation loss: 2.2022895941170315

Epoch: 438| Step: 0
Training loss: 1.8459047079086304
Validation loss: 2.201509734635712

Epoch: 5| Step: 1
Training loss: 2.618403196334839
Validation loss: 2.2122767817589546

Epoch: 5| Step: 2
Training loss: 2.216621160507202
Validation loss: 2.20255890200215

Epoch: 5| Step: 3
Training loss: 2.0680415630340576
Validation loss: 2.1832802936594975

Epoch: 5| Step: 4
Training loss: 2.679358959197998
Validation loss: 2.1796615662113314

Epoch: 5| Step: 5
Training loss: 2.007631778717041
Validation loss: 2.1703689149630967

Epoch: 5| Step: 6
Training loss: 2.2196602821350098
Validation loss: 2.188215042955132

Epoch: 5| Step: 7
Training loss: 1.91219961643219
Validation loss: 2.2019960085550943

Epoch: 5| Step: 8
Training loss: 2.02327561378479
Validation loss: 2.192898496504753

Epoch: 5| Step: 9
Training loss: 1.986127257347107
Validation loss: 2.1834414082188762

Epoch: 5| Step: 10
Training loss: 2.555002212524414
Validation loss: 2.189857339346281

Epoch: 439| Step: 0
Training loss: 1.6260493993759155
Validation loss: 2.189611086281397

Epoch: 5| Step: 1
Training loss: 1.6487146615982056
Validation loss: 2.202244497114612

Epoch: 5| Step: 2
Training loss: 2.42344331741333
Validation loss: 2.2036239408677623

Epoch: 5| Step: 3
Training loss: 2.366344928741455
Validation loss: 2.2098429074851413

Epoch: 5| Step: 4
Training loss: 2.139864206314087
Validation loss: 2.221087122476229

Epoch: 5| Step: 5
Training loss: 2.0092852115631104
Validation loss: 2.2219671639063026

Epoch: 5| Step: 6
Training loss: 2.675623893737793
Validation loss: 2.2127241908863025

Epoch: 5| Step: 7
Training loss: 2.4635632038116455
Validation loss: 2.2273794733067995

Epoch: 5| Step: 8
Training loss: 2.054999828338623
Validation loss: 2.2004557578794417

Epoch: 5| Step: 9
Training loss: 2.7994136810302734
Validation loss: 2.1949794369359172

Epoch: 5| Step: 10
Training loss: 1.8847465515136719
Validation loss: 2.181563546580653

Epoch: 440| Step: 0
Training loss: 1.604060411453247
Validation loss: 2.1711373995709162

Epoch: 5| Step: 1
Training loss: 1.6952877044677734
Validation loss: 2.172720424590572

Epoch: 5| Step: 2
Training loss: 1.9216365814208984
Validation loss: 2.1759838199102752

Epoch: 5| Step: 3
Training loss: 2.1826796531677246
Validation loss: 2.1744933948721936

Epoch: 5| Step: 4
Training loss: 1.3717763423919678
Validation loss: 2.170732012359045

Epoch: 5| Step: 5
Training loss: 2.8247828483581543
Validation loss: 2.1754823295019006

Epoch: 5| Step: 6
Training loss: 3.0370113849639893
Validation loss: 2.177040389789048

Epoch: 5| Step: 7
Training loss: 1.740129828453064
Validation loss: 2.1765203373406523

Epoch: 5| Step: 8
Training loss: 2.8508269786834717
Validation loss: 2.2115811096724642

Epoch: 5| Step: 9
Training loss: 2.562809705734253
Validation loss: 2.2030126381945867

Epoch: 5| Step: 10
Training loss: 2.3307266235351562
Validation loss: 2.223196696209651

Epoch: 441| Step: 0
Training loss: 2.2457773685455322
Validation loss: 2.2177940542979906

Epoch: 5| Step: 1
Training loss: 2.153843402862549
Validation loss: 2.194775378832253

Epoch: 5| Step: 2
Training loss: 2.8294222354888916
Validation loss: 2.179139124449863

Epoch: 5| Step: 3
Training loss: 2.636409282684326
Validation loss: 2.1778737575777116

Epoch: 5| Step: 4
Training loss: 2.1788430213928223
Validation loss: 2.16129127112768

Epoch: 5| Step: 5
Training loss: 2.259594678878784
Validation loss: 2.1699465679866012

Epoch: 5| Step: 6
Training loss: 1.678320288658142
Validation loss: 2.1476699434300905

Epoch: 5| Step: 7
Training loss: 2.40098237991333
Validation loss: 2.1578642296534714

Epoch: 5| Step: 8
Training loss: 1.520280122756958
Validation loss: 2.1712845551070346

Epoch: 5| Step: 9
Training loss: 2.0009305477142334
Validation loss: 2.1649539906491517

Epoch: 5| Step: 10
Training loss: 2.1943466663360596
Validation loss: 2.1721981135747765

Epoch: 442| Step: 0
Training loss: 1.7134599685668945
Validation loss: 2.196079672023814

Epoch: 5| Step: 1
Training loss: 1.7343788146972656
Validation loss: 2.19465345592909

Epoch: 5| Step: 2
Training loss: 1.878900170326233
Validation loss: 2.216575945577314

Epoch: 5| Step: 3
Training loss: 1.576622724533081
Validation loss: 2.2128457920525664

Epoch: 5| Step: 4
Training loss: 2.3471598625183105
Validation loss: 2.2019395674428632

Epoch: 5| Step: 5
Training loss: 2.158782482147217
Validation loss: 2.2325056342668432

Epoch: 5| Step: 6
Training loss: 2.9166347980499268
Validation loss: 2.248032100739018

Epoch: 5| Step: 7
Training loss: 2.4507832527160645
Validation loss: 2.2219798154728387

Epoch: 5| Step: 8
Training loss: 2.2300286293029785
Validation loss: 2.229917041717037

Epoch: 5| Step: 9
Training loss: 2.4304165840148926
Validation loss: 2.2220009808899253

Epoch: 5| Step: 10
Training loss: 2.6587820053100586
Validation loss: 2.208701479819513

Epoch: 443| Step: 0
Training loss: 2.038759708404541
Validation loss: 2.1973396116687405

Epoch: 5| Step: 1
Training loss: 2.061800956726074
Validation loss: 2.191211663266664

Epoch: 5| Step: 2
Training loss: 2.095364570617676
Validation loss: 2.19201409944924

Epoch: 5| Step: 3
Training loss: 1.6849040985107422
Validation loss: 2.1821515508877334

Epoch: 5| Step: 4
Training loss: 2.5162289142608643
Validation loss: 2.195270328111546

Epoch: 5| Step: 5
Training loss: 2.310976028442383
Validation loss: 2.1948085395238732

Epoch: 5| Step: 6
Training loss: 2.6988658905029297
Validation loss: 2.199169969045988

Epoch: 5| Step: 7
Training loss: 2.484473705291748
Validation loss: 2.2032050496788433

Epoch: 5| Step: 8
Training loss: 1.6269023418426514
Validation loss: 2.203195669317758

Epoch: 5| Step: 9
Training loss: 2.4521772861480713
Validation loss: 2.1858669865515923

Epoch: 5| Step: 10
Training loss: 1.9454030990600586
Validation loss: 2.1903796785621235

Epoch: 444| Step: 0
Training loss: 2.60308575630188
Validation loss: 2.1893342643655758

Epoch: 5| Step: 1
Training loss: 2.1822142601013184
Validation loss: 2.187465290869436

Epoch: 5| Step: 2
Training loss: 1.8810116052627563
Validation loss: 2.18412882666434

Epoch: 5| Step: 3
Training loss: 1.831437349319458
Validation loss: 2.196626273534631

Epoch: 5| Step: 4
Training loss: 2.481288194656372
Validation loss: 2.194112152181646

Epoch: 5| Step: 5
Training loss: 2.2456212043762207
Validation loss: 2.1991655083112818

Epoch: 5| Step: 6
Training loss: 1.5831074714660645
Validation loss: 2.1897141702713503

Epoch: 5| Step: 7
Training loss: 2.607189893722534
Validation loss: 2.188252854090865

Epoch: 5| Step: 8
Training loss: 2.609668254852295
Validation loss: 2.181860003420102

Epoch: 5| Step: 9
Training loss: 1.589085340499878
Validation loss: 2.1697265358381372

Epoch: 5| Step: 10
Training loss: 2.4075746536254883
Validation loss: 2.1649195814645417

Epoch: 445| Step: 0
Training loss: 2.816890001296997
Validation loss: 2.171740042266025

Epoch: 5| Step: 1
Training loss: 2.5527994632720947
Validation loss: 2.1850488967792963

Epoch: 5| Step: 2
Training loss: 1.5361008644104004
Validation loss: 2.16946054145854

Epoch: 5| Step: 3
Training loss: 2.4281251430511475
Validation loss: 2.1715268832381054

Epoch: 5| Step: 4
Training loss: 2.1410880088806152
Validation loss: 2.1749556064605713

Epoch: 5| Step: 5
Training loss: 1.6176750659942627
Validation loss: 2.182814323773948

Epoch: 5| Step: 6
Training loss: 2.4718270301818848
Validation loss: 2.2047571751379196

Epoch: 5| Step: 7
Training loss: 2.496084690093994
Validation loss: 2.208556467486966

Epoch: 5| Step: 8
Training loss: 2.246561050415039
Validation loss: 2.206232983578918

Epoch: 5| Step: 9
Training loss: 2.0065016746520996
Validation loss: 2.1973281765496857

Epoch: 5| Step: 10
Training loss: 1.624985694885254
Validation loss: 2.2075923027530795

Epoch: 446| Step: 0
Training loss: 1.7876884937286377
Validation loss: 2.198633683625088

Epoch: 5| Step: 1
Training loss: 3.0087196826934814
Validation loss: 2.2101397732252717

Epoch: 5| Step: 2
Training loss: 3.0281357765197754
Validation loss: 2.2205384367255756

Epoch: 5| Step: 3
Training loss: 1.7434991598129272
Validation loss: 2.2040977798482424

Epoch: 5| Step: 4
Training loss: 2.112820863723755
Validation loss: 2.2068189805553806

Epoch: 5| Step: 5
Training loss: 2.1398441791534424
Validation loss: 2.1980790938100507

Epoch: 5| Step: 6
Training loss: 2.497683048248291
Validation loss: 2.176643063945155

Epoch: 5| Step: 7
Training loss: 1.9608676433563232
Validation loss: 2.168200631295481

Epoch: 5| Step: 8
Training loss: 1.8967361450195312
Validation loss: 2.172319286613054

Epoch: 5| Step: 9
Training loss: 1.9998365640640259
Validation loss: 2.179805296723561

Epoch: 5| Step: 10
Training loss: 1.7662416696548462
Validation loss: 2.2000367000538814

Epoch: 447| Step: 0
Training loss: 1.623792052268982
Validation loss: 2.20880449715481

Epoch: 5| Step: 1
Training loss: 2.4677038192749023
Validation loss: 2.218296863699472

Epoch: 5| Step: 2
Training loss: 1.681722640991211
Validation loss: 2.2312894816039712

Epoch: 5| Step: 3
Training loss: 2.073551654815674
Validation loss: 2.1996525872138237

Epoch: 5| Step: 4
Training loss: 2.329710006713867
Validation loss: 2.1883272688875914

Epoch: 5| Step: 5
Training loss: 2.434818744659424
Validation loss: 2.182654555125903

Epoch: 5| Step: 6
Training loss: 2.2834553718566895
Validation loss: 2.16001816462445

Epoch: 5| Step: 7
Training loss: 2.295714855194092
Validation loss: 2.149664108471204

Epoch: 5| Step: 8
Training loss: 1.883032202720642
Validation loss: 2.1632040187876713

Epoch: 5| Step: 9
Training loss: 2.8427212238311768
Validation loss: 2.1669455882041686

Epoch: 5| Step: 10
Training loss: 2.1842904090881348
Validation loss: 2.163614042343632

Epoch: 448| Step: 0
Training loss: 2.5566635131835938
Validation loss: 2.155545732026459

Epoch: 5| Step: 1
Training loss: 1.4826706647872925
Validation loss: 2.1590743577608498

Epoch: 5| Step: 2
Training loss: 2.438214063644409
Validation loss: 2.1628005786608626

Epoch: 5| Step: 3
Training loss: 2.035818099975586
Validation loss: 2.1545747531357633

Epoch: 5| Step: 4
Training loss: 2.224822998046875
Validation loss: 2.1619659367428032

Epoch: 5| Step: 5
Training loss: 2.1491692066192627
Validation loss: 2.1685027281443277

Epoch: 5| Step: 6
Training loss: 1.647202491760254
Validation loss: 2.1781792435594785

Epoch: 5| Step: 7
Training loss: 2.3872830867767334
Validation loss: 2.1958505799693446

Epoch: 5| Step: 8
Training loss: 2.322057008743286
Validation loss: 2.1708911823970016

Epoch: 5| Step: 9
Training loss: 1.7817636728286743
Validation loss: 2.186482278249597

Epoch: 5| Step: 10
Training loss: 3.055826187133789
Validation loss: 2.1862850753209924

Epoch: 449| Step: 0
Training loss: 2.2553622722625732
Validation loss: 2.1867543112847114

Epoch: 5| Step: 1
Training loss: 2.7925174236297607
Validation loss: 2.1736963359258508

Epoch: 5| Step: 2
Training loss: 1.723702073097229
Validation loss: 2.1636016958503315

Epoch: 5| Step: 3
Training loss: 2.0325255393981934
Validation loss: 2.156821932843936

Epoch: 5| Step: 4
Training loss: 2.268019914627075
Validation loss: 2.1691881200318694

Epoch: 5| Step: 5
Training loss: 2.127058506011963
Validation loss: 2.178070154241336

Epoch: 5| Step: 6
Training loss: 1.9995243549346924
Validation loss: 2.1649238230079733

Epoch: 5| Step: 7
Training loss: 2.0837066173553467
Validation loss: 2.1808120460920435

Epoch: 5| Step: 8
Training loss: 2.111684799194336
Validation loss: 2.186608576005505

Epoch: 5| Step: 9
Training loss: 1.9329679012298584
Validation loss: 2.2041832349633657

Epoch: 5| Step: 10
Training loss: 2.5338687896728516
Validation loss: 2.1858566909708004

Epoch: 450| Step: 0
Training loss: 2.615910768508911
Validation loss: 2.198339118752428

Epoch: 5| Step: 1
Training loss: 1.8832862377166748
Validation loss: 2.1811750242787022

Epoch: 5| Step: 2
Training loss: 1.749863862991333
Validation loss: 2.18135336137587

Epoch: 5| Step: 3
Training loss: 2.6641974449157715
Validation loss: 2.1751440699382494

Epoch: 5| Step: 4
Training loss: 1.9001262187957764
Validation loss: 2.16538010233192

Epoch: 5| Step: 5
Training loss: 1.9038835763931274
Validation loss: 2.1713822144334034

Epoch: 5| Step: 6
Training loss: 1.682257056236267
Validation loss: 2.1698125100904897

Epoch: 5| Step: 7
Training loss: 2.626278877258301
Validation loss: 2.1671854244765414

Epoch: 5| Step: 8
Training loss: 2.3496010303497314
Validation loss: 2.1712203974364908

Epoch: 5| Step: 9
Training loss: 2.1411848068237305
Validation loss: 2.188319465165497

Epoch: 5| Step: 10
Training loss: 2.320284366607666
Validation loss: 2.1845019043132825

Testing loss: 2.32340235180325
