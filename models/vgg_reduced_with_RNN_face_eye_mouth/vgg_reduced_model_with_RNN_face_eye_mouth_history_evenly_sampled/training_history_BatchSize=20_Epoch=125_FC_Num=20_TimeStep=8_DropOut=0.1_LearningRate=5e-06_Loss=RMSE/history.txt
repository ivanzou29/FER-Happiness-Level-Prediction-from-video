Epoch: 1| Step: 0
Training loss: 5.72254492745818
Validation loss: 5.769294149977771

Epoch: 5| Step: 1
Training loss: 5.815169510998832
Validation loss: 5.764501215415318

Epoch: 5| Step: 2
Training loss: 5.75849287342963
Validation loss: 5.760276375125328

Epoch: 5| Step: 3
Training loss: 5.322699236923691
Validation loss: 5.756538857005152

Epoch: 5| Step: 4
Training loss: 6.189829070114645
Validation loss: 5.752327503670419

Epoch: 5| Step: 5
Training loss: 6.20407135708549
Validation loss: 5.748519580261766

Epoch: 5| Step: 6
Training loss: 4.506268268183108
Validation loss: 5.744785394701321

Epoch: 5| Step: 7
Training loss: 5.526904279404184
Validation loss: 5.741097794724955

Epoch: 5| Step: 8
Training loss: 5.8969249276461815
Validation loss: 5.737620123485236

Epoch: 5| Step: 9
Training loss: 5.318044305015006
Validation loss: 5.7337099641766205

Epoch: 5| Step: 10
Training loss: 7.223856915397125
Validation loss: 5.7299212608947006

Epoch: 2| Step: 0
Training loss: 6.2926389772377345
Validation loss: 5.725756559684641

Epoch: 5| Step: 1
Training loss: 5.160125755433645
Validation loss: 5.7221081083787855

Epoch: 5| Step: 2
Training loss: 6.12250140861847
Validation loss: 5.717350980126108

Epoch: 5| Step: 3
Training loss: 5.441129503517431
Validation loss: 5.713591919149084

Epoch: 5| Step: 4
Training loss: 5.2850411255246
Validation loss: 5.7090883856699275

Epoch: 5| Step: 5
Training loss: 5.628746311051839
Validation loss: 5.7043634162122

Epoch: 5| Step: 6
Training loss: 4.185479886742286
Validation loss: 5.699346266244524

Epoch: 5| Step: 7
Training loss: 6.14305474353202
Validation loss: 5.693920807265243

Epoch: 5| Step: 8
Training loss: 5.595264762497944
Validation loss: 5.688337446273254

Epoch: 5| Step: 9
Training loss: 6.291233005694003
Validation loss: 5.682277823761111

Epoch: 5| Step: 10
Training loss: 6.711039816594883
Validation loss: 5.676060421531627

Epoch: 3| Step: 0
Training loss: 5.945959228950679
Validation loss: 5.66959496659707

Epoch: 5| Step: 1
Training loss: 4.735527477430783
Validation loss: 5.662285438722341

Epoch: 5| Step: 2
Training loss: 5.177661436208247
Validation loss: 5.654990892371482

Epoch: 5| Step: 3
Training loss: 6.718413872406009
Validation loss: 5.6470387803607105

Epoch: 5| Step: 4
Training loss: 5.525315716728887
Validation loss: 5.638789869020632

Epoch: 5| Step: 5
Training loss: 6.370071600447221
Validation loss: 5.6301016766766026

Epoch: 5| Step: 6
Training loss: 5.504616966954273
Validation loss: 5.621392755798609

Epoch: 5| Step: 7
Training loss: 5.2941486014913535
Validation loss: 5.610502908134447

Epoch: 5| Step: 8
Training loss: 6.028697368052771
Validation loss: 5.601051542845642

Epoch: 5| Step: 9
Training loss: 5.430158548025044
Validation loss: 5.589860713586137

Epoch: 5| Step: 10
Training loss: 5.242740516657295
Validation loss: 5.577768732366541

Epoch: 4| Step: 0
Training loss: 5.408147225413077
Validation loss: 5.566327844429888

Epoch: 5| Step: 1
Training loss: 5.441279183223396
Validation loss: 5.554254670099023

Epoch: 5| Step: 2
Training loss: 5.7554845775284615
Validation loss: 5.541209895131192

Epoch: 5| Step: 3
Training loss: 5.248494795327242
Validation loss: 5.5263185444396115

Epoch: 5| Step: 4
Training loss: 5.486622059309727
Validation loss: 5.512507304480505

Epoch: 5| Step: 5
Training loss: 5.909530777998646
Validation loss: 5.496698733036204

Epoch: 5| Step: 6
Training loss: 5.275346334215683
Validation loss: 5.480628431984737

Epoch: 5| Step: 7
Training loss: 5.452413343102124
Validation loss: 5.463759618832945

Epoch: 5| Step: 8
Training loss: 5.5729652283831435
Validation loss: 5.446516878259856

Epoch: 5| Step: 9
Training loss: 4.5195443327111855
Validation loss: 5.428737141893118

Epoch: 5| Step: 10
Training loss: 6.75103893055326
Validation loss: 5.409316771761579

Epoch: 5| Step: 0
Training loss: 4.864703528847774
Validation loss: 5.38976214284397

Epoch: 5| Step: 1
Training loss: 5.347262115109521
Validation loss: 5.369368439676382

Epoch: 5| Step: 2
Training loss: 5.351450407984382
Validation loss: 5.349429227359751

Epoch: 5| Step: 3
Training loss: 5.173219073957549
Validation loss: 5.329601448591391

Epoch: 5| Step: 4
Training loss: 5.897502254082999
Validation loss: 5.3080709275506175

Epoch: 5| Step: 5
Training loss: 5.902279442588957
Validation loss: 5.2863870097530326

Epoch: 5| Step: 6
Training loss: 4.636609533320391
Validation loss: 5.264070281525214

Epoch: 5| Step: 7
Training loss: 5.202894417633797
Validation loss: 5.24126351983573

Epoch: 5| Step: 8
Training loss: 5.997155786950926
Validation loss: 5.219851762603523

Epoch: 5| Step: 9
Training loss: 5.169175841053622
Validation loss: 5.197282198751319

Epoch: 5| Step: 10
Training loss: 4.851962504582453
Validation loss: 5.174538986329545

Epoch: 6| Step: 0
Training loss: 5.847981109463387
Validation loss: 5.152116193262236

Epoch: 5| Step: 1
Training loss: 5.333947186111662
Validation loss: 5.13019307868588

Epoch: 5| Step: 2
Training loss: 5.2888957100155505
Validation loss: 5.107751177907521

Epoch: 5| Step: 3
Training loss: 4.906937277698343
Validation loss: 5.085690080969968

Epoch: 5| Step: 4
Training loss: 4.498878763173378
Validation loss: 5.063884027873654

Epoch: 5| Step: 5
Training loss: 4.411958932528096
Validation loss: 5.0413932261719685

Epoch: 5| Step: 6
Training loss: 4.766793329827925
Validation loss: 5.019366343838524

Epoch: 5| Step: 7
Training loss: 5.092799747505146
Validation loss: 4.995958910191896

Epoch: 5| Step: 8
Training loss: 5.902883710720966
Validation loss: 4.973778429102821

Epoch: 5| Step: 9
Training loss: 4.364341832340427
Validation loss: 4.951680245047938

Epoch: 5| Step: 10
Training loss: 5.482928049865327
Validation loss: 4.927289587162658

Epoch: 7| Step: 0
Training loss: 5.443096569274807
Validation loss: 4.903965651458517

Epoch: 5| Step: 1
Training loss: 5.24750568536793
Validation loss: 4.876181075255697

Epoch: 5| Step: 2
Training loss: 5.173806005756795
Validation loss: 4.852391212940759

Epoch: 5| Step: 3
Training loss: 3.8872071232512395
Validation loss: 4.825618086823684

Epoch: 5| Step: 4
Training loss: 4.730367947677026
Validation loss: 4.800760105496041

Epoch: 5| Step: 5
Training loss: 5.754780647876666
Validation loss: 4.776820248219777

Epoch: 5| Step: 6
Training loss: 4.889573054173504
Validation loss: 4.751451563041274

Epoch: 5| Step: 7
Training loss: 4.845113254794177
Validation loss: 4.727092558956089

Epoch: 5| Step: 8
Training loss: 4.058173590198378
Validation loss: 4.703358289668217

Epoch: 5| Step: 9
Training loss: 5.055422509833346
Validation loss: 4.684116589038909

Epoch: 5| Step: 10
Training loss: 3.833258227289803
Validation loss: 4.6624156264774745

Epoch: 8| Step: 0
Training loss: 5.246174281248518
Validation loss: 4.643149325095023

Epoch: 5| Step: 1
Training loss: 4.212447820957205
Validation loss: 4.623501505793017

Epoch: 5| Step: 2
Training loss: 3.904120757580445
Validation loss: 4.606852994126676

Epoch: 5| Step: 3
Training loss: 4.936564876031566
Validation loss: 4.5890157777602

Epoch: 5| Step: 4
Training loss: 5.5767923253767355
Validation loss: 4.57325701017351

Epoch: 5| Step: 5
Training loss: 5.231700612557878
Validation loss: 4.556799284556767

Epoch: 5| Step: 6
Training loss: 3.4756700377486514
Validation loss: 4.543672269897761

Epoch: 5| Step: 7
Training loss: 4.73336549577845
Validation loss: 4.528556465029894

Epoch: 5| Step: 8
Training loss: 4.502060736240987
Validation loss: 4.517339619977124

Epoch: 5| Step: 9
Training loss: 4.658934977558935
Validation loss: 4.502800750108692

Epoch: 5| Step: 10
Training loss: 4.261944311171069
Validation loss: 4.4907627300586785

Epoch: 9| Step: 0
Training loss: 4.047178043522028
Validation loss: 4.477445875795418

Epoch: 5| Step: 1
Training loss: 4.915548078804546
Validation loss: 4.466728606335642

Epoch: 5| Step: 2
Training loss: 4.208422644142743
Validation loss: 4.454709483679091

Epoch: 5| Step: 3
Training loss: 4.960751026884178
Validation loss: 4.441777288262232

Epoch: 5| Step: 4
Training loss: 4.7679423716986
Validation loss: 4.430334181686732

Epoch: 5| Step: 5
Training loss: 4.092107312209526
Validation loss: 4.415341886526033

Epoch: 5| Step: 6
Training loss: 5.0517261916357645
Validation loss: 4.40420696178681

Epoch: 5| Step: 7
Training loss: 3.906189818872351
Validation loss: 4.393278099634801

Epoch: 5| Step: 8
Training loss: 4.538560744373825
Validation loss: 4.381097850334685

Epoch: 5| Step: 9
Training loss: 4.790084555562509
Validation loss: 4.372581314952497

Epoch: 5| Step: 10
Training loss: 4.310051928072406
Validation loss: 4.358674682533728

Epoch: 10| Step: 0
Training loss: 4.226450807572828
Validation loss: 4.348317548636813

Epoch: 5| Step: 1
Training loss: 4.411122975518974
Validation loss: 4.335711793531958

Epoch: 5| Step: 2
Training loss: 4.29784723553378
Validation loss: 4.323989035768974

Epoch: 5| Step: 3
Training loss: 3.8136688691908542
Validation loss: 4.311772869408672

Epoch: 5| Step: 4
Training loss: 4.596556552253167
Validation loss: 4.302998652068747

Epoch: 5| Step: 5
Training loss: 4.230486558927773
Validation loss: 4.2902566608808455

Epoch: 5| Step: 6
Training loss: 4.626359894299408
Validation loss: 4.280828656567394

Epoch: 5| Step: 7
Training loss: 4.194288984930739
Validation loss: 4.269117589466876

Epoch: 5| Step: 8
Training loss: 5.022043085044858
Validation loss: 4.261077604944529

Epoch: 5| Step: 9
Training loss: 4.424919670798282
Validation loss: 4.251490790533558

Epoch: 5| Step: 10
Training loss: 4.649483494118993
Validation loss: 4.243132426237672

Epoch: 11| Step: 0
Training loss: 4.142819611139777
Validation loss: 4.235367044728419

Epoch: 5| Step: 1
Training loss: 3.397292792799485
Validation loss: 4.226252070974426

Epoch: 5| Step: 2
Training loss: 4.233965751887842
Validation loss: 4.217911008890947

Epoch: 5| Step: 3
Training loss: 4.9810902645293105
Validation loss: 4.209993833874902

Epoch: 5| Step: 4
Training loss: 4.930876913328847
Validation loss: 4.20378185793236

Epoch: 5| Step: 5
Training loss: 4.312790128374699
Validation loss: 4.196529018111195

Epoch: 5| Step: 6
Training loss: 4.739333976921209
Validation loss: 4.190761718027172

Epoch: 5| Step: 7
Training loss: 3.9034165749169567
Validation loss: 4.182613778396468

Epoch: 5| Step: 8
Training loss: 3.8308849117205472
Validation loss: 4.176927284310878

Epoch: 5| Step: 9
Training loss: 4.6387199833031625
Validation loss: 4.169270347160716

Epoch: 5| Step: 10
Training loss: 4.1968963872459755
Validation loss: 4.163661241221143

Epoch: 12| Step: 0
Training loss: 4.456703862729535
Validation loss: 4.156896609509072

Epoch: 5| Step: 1
Training loss: 4.451836864817405
Validation loss: 4.14765120249457

Epoch: 5| Step: 2
Training loss: 4.743758668753402
Validation loss: 4.14358925196486

Epoch: 5| Step: 3
Training loss: 4.430556116266856
Validation loss: 4.137570768491602

Epoch: 5| Step: 4
Training loss: 4.50567904385568
Validation loss: 4.130232467097742

Epoch: 5| Step: 5
Training loss: 3.5968613134632497
Validation loss: 4.125859570927969

Epoch: 5| Step: 6
Training loss: 4.530645080176695
Validation loss: 4.119673528263829

Epoch: 5| Step: 7
Training loss: 3.8382177470719387
Validation loss: 4.111337164048373

Epoch: 5| Step: 8
Training loss: 3.977275192458144
Validation loss: 4.102727914027283

Epoch: 5| Step: 9
Training loss: 3.7893914463366456
Validation loss: 4.097018787600371

Epoch: 5| Step: 10
Training loss: 4.452266784420417
Validation loss: 4.092483810649467

Epoch: 13| Step: 0
Training loss: 4.544866688601887
Validation loss: 4.083279347936601

Epoch: 5| Step: 1
Training loss: 3.957022814727559
Validation loss: 4.076278328135054

Epoch: 5| Step: 2
Training loss: 4.869423244091906
Validation loss: 4.070501541718138

Epoch: 5| Step: 3
Training loss: 3.50285685973743
Validation loss: 4.064926190337795

Epoch: 5| Step: 4
Training loss: 3.73230152744556
Validation loss: 4.05603906555231

Epoch: 5| Step: 5
Training loss: 4.332814014323121
Validation loss: 4.050711267276795

Epoch: 5| Step: 6
Training loss: 4.584245047778429
Validation loss: 4.0418585560574245

Epoch: 5| Step: 7
Training loss: 3.96857025460337
Validation loss: 4.033974282414947

Epoch: 5| Step: 8
Training loss: 2.835946411455093
Validation loss: 4.030609970370178

Epoch: 5| Step: 9
Training loss: 4.70699153899224
Validation loss: 4.022741294908578

Epoch: 5| Step: 10
Training loss: 4.71936273701807
Validation loss: 4.01491657371717

Epoch: 14| Step: 0
Training loss: 3.949886397647569
Validation loss: 4.003793208669722

Epoch: 5| Step: 1
Training loss: 3.9371354676093655
Validation loss: 3.996669477414074

Epoch: 5| Step: 2
Training loss: 4.24172459670843
Validation loss: 3.989927544925039

Epoch: 5| Step: 3
Training loss: 4.286384343945204
Validation loss: 3.9827089980334534

Epoch: 5| Step: 4
Training loss: 3.7531816336927104
Validation loss: 3.975817814775179

Epoch: 5| Step: 5
Training loss: 3.5308834999763548
Validation loss: 3.9702240875204855

Epoch: 5| Step: 6
Training loss: 3.3777981214440507
Validation loss: 3.9646750444500403

Epoch: 5| Step: 7
Training loss: 5.099424419460498
Validation loss: 3.9571648073797916

Epoch: 5| Step: 8
Training loss: 4.708706303680586
Validation loss: 3.9486923908079254

Epoch: 5| Step: 9
Training loss: 4.043484832701262
Validation loss: 3.9411451307964027

Epoch: 5| Step: 10
Training loss: 4.130169028455528
Validation loss: 3.9360529097187205

Epoch: 15| Step: 0
Training loss: 4.055583524099493
Validation loss: 3.9287476844599762

Epoch: 5| Step: 1
Training loss: 3.844337232438625
Validation loss: 3.923963050305135

Epoch: 5| Step: 2
Training loss: 4.52430160781221
Validation loss: 3.918777991591317

Epoch: 5| Step: 3
Training loss: 4.44264760782734
Validation loss: 3.9106052407212104

Epoch: 5| Step: 4
Training loss: 3.4787498879304155
Validation loss: 3.9044445461156974

Epoch: 5| Step: 5
Training loss: 3.7661023609028277
Validation loss: 3.9002800114449934

Epoch: 5| Step: 6
Training loss: 4.558151472091433
Validation loss: 3.8940070447647934

Epoch: 5| Step: 7
Training loss: 3.8060728836818716
Validation loss: 3.8893216823013983

Epoch: 5| Step: 8
Training loss: 4.072858076657921
Validation loss: 3.882480475999147

Epoch: 5| Step: 9
Training loss: 3.661433531386408
Validation loss: 3.8778320506467185

Epoch: 5| Step: 10
Training loss: 4.354956571973412
Validation loss: 3.872755511430317

Epoch: 16| Step: 0
Training loss: 4.359909845172515
Validation loss: 3.866161297037944

Epoch: 5| Step: 1
Training loss: 3.7691823531055
Validation loss: 3.860470599715016

Epoch: 5| Step: 2
Training loss: 3.939261632756031
Validation loss: 3.857515162374085

Epoch: 5| Step: 3
Training loss: 4.5559532539843115
Validation loss: 3.8534071413654134

Epoch: 5| Step: 4
Training loss: 3.463424030495638
Validation loss: 3.848865039273191

Epoch: 5| Step: 5
Training loss: 4.416908521448097
Validation loss: 3.8431092922223815

Epoch: 5| Step: 6
Training loss: 3.4667093959033446
Validation loss: 3.8397897400597816

Epoch: 5| Step: 7
Training loss: 3.341004287127816
Validation loss: 3.835630225411118

Epoch: 5| Step: 8
Training loss: 4.4895578665427776
Validation loss: 3.8306527942177717

Epoch: 5| Step: 9
Training loss: 4.029959538637657
Validation loss: 3.8274193259599945

Epoch: 5| Step: 10
Training loss: 4.088400337384487
Validation loss: 3.8241670762084428

Epoch: 17| Step: 0
Training loss: 3.465130816655857
Validation loss: 3.8174587569350664

Epoch: 5| Step: 1
Training loss: 4.225357645460993
Validation loss: 3.814070952364851

Epoch: 5| Step: 2
Training loss: 4.0486304993526
Validation loss: 3.8085370028685284

Epoch: 5| Step: 3
Training loss: 3.9831863126131535
Validation loss: 3.802953499429107

Epoch: 5| Step: 4
Training loss: 4.296785776772518
Validation loss: 3.801484654393526

Epoch: 5| Step: 5
Training loss: 3.6252280854126475
Validation loss: 3.7954491688222696

Epoch: 5| Step: 6
Training loss: 3.2784910683113897
Validation loss: 3.7924719334799635

Epoch: 5| Step: 7
Training loss: 3.6834117403502686
Validation loss: 3.785561021679183

Epoch: 5| Step: 8
Training loss: 4.404132307069558
Validation loss: 3.780668389705291

Epoch: 5| Step: 9
Training loss: 3.756850026170944
Validation loss: 3.7765112723281877

Epoch: 5| Step: 10
Training loss: 4.78929548334686
Validation loss: 3.7701858026175863

Epoch: 18| Step: 0
Training loss: 3.7415656287832486
Validation loss: 3.7661689668701346

Epoch: 5| Step: 1
Training loss: 4.172435022834435
Validation loss: 3.7628130650793086

Epoch: 5| Step: 2
Training loss: 4.323068908706952
Validation loss: 3.755890068726664

Epoch: 5| Step: 3
Training loss: 4.091002962210662
Validation loss: 3.7496785261940455

Epoch: 5| Step: 4
Training loss: 3.5632106674486868
Validation loss: 3.7480985243801426

Epoch: 5| Step: 5
Training loss: 3.738137109861545
Validation loss: 3.740333466582833

Epoch: 5| Step: 6
Training loss: 3.4940818069480026
Validation loss: 3.7389109999987347

Epoch: 5| Step: 7
Training loss: 4.040662319545005
Validation loss: 3.7325885344181455

Epoch: 5| Step: 8
Training loss: 3.671975122263623
Validation loss: 3.7287657364035476

Epoch: 5| Step: 9
Training loss: 3.8929288240085236
Validation loss: 3.7242229679437715

Epoch: 5| Step: 10
Training loss: 4.404551077059918
Validation loss: 3.722579777767376

Epoch: 19| Step: 0
Training loss: 3.6757783960702257
Validation loss: 3.714786672170382

Epoch: 5| Step: 1
Training loss: 4.5245130245288125
Validation loss: 3.711598917075006

Epoch: 5| Step: 2
Training loss: 3.9298726639247596
Validation loss: 3.7081612748348416

Epoch: 5| Step: 3
Training loss: 3.5585820923330593
Validation loss: 3.7090986447711236

Epoch: 5| Step: 4
Training loss: 3.8763791983095404
Validation loss: 3.7064499800587876

Epoch: 5| Step: 5
Training loss: 3.610660604757332
Validation loss: 3.696300217193107

Epoch: 5| Step: 6
Training loss: 3.660489355214834
Validation loss: 3.6919012096074946

Epoch: 5| Step: 7
Training loss: 3.667650105343618
Validation loss: 3.6891061167807853

Epoch: 5| Step: 8
Training loss: 4.526806145280923
Validation loss: 3.689400391960272

Epoch: 5| Step: 9
Training loss: 3.281631302249881
Validation loss: 3.6826111212754213

Epoch: 5| Step: 10
Training loss: 4.265523273526599
Validation loss: 3.6796488343047455

Epoch: 20| Step: 0
Training loss: 3.945152355003164
Validation loss: 3.6722269232126825

Epoch: 5| Step: 1
Training loss: 3.758685163338969
Validation loss: 3.667300367177177

Epoch: 5| Step: 2
Training loss: 4.197103164390194
Validation loss: 3.6653614116813733

Epoch: 5| Step: 3
Training loss: 3.2344998690324593
Validation loss: 3.6618206511407823

Epoch: 5| Step: 4
Training loss: 4.6868603079138635
Validation loss: 3.6630744318135497

Epoch: 5| Step: 5
Training loss: 3.631446368214699
Validation loss: 3.654447823953765

Epoch: 5| Step: 6
Training loss: 3.465516241240018
Validation loss: 3.649883562951218

Epoch: 5| Step: 7
Training loss: 3.455027750789858
Validation loss: 3.646764981587014

Epoch: 5| Step: 8
Training loss: 4.568375657971195
Validation loss: 3.6438201863765722

Epoch: 5| Step: 9
Training loss: 3.8090384355780578
Validation loss: 3.6401739910150397

Epoch: 5| Step: 10
Training loss: 3.1137751590749088
Validation loss: 3.637818575616027

Epoch: 21| Step: 0
Training loss: 3.8935905705566847
Validation loss: 3.6329175052028604

Epoch: 5| Step: 1
Training loss: 4.044132437449454
Validation loss: 3.6284164267151726

Epoch: 5| Step: 2
Training loss: 3.3829278023255345
Validation loss: 3.6265074665148593

Epoch: 5| Step: 3
Training loss: 3.5757111648982267
Validation loss: 3.621760452980269

Epoch: 5| Step: 4
Training loss: 3.9331051959671695
Validation loss: 3.618405591151851

Epoch: 5| Step: 5
Training loss: 3.928628646136665
Validation loss: 3.6181938950555343

Epoch: 5| Step: 6
Training loss: 3.415337296189166
Validation loss: 3.61417730952481

Epoch: 5| Step: 7
Training loss: 4.095036661172602
Validation loss: 3.6108310026561057

Epoch: 5| Step: 8
Training loss: 4.012133315970095
Validation loss: 3.606396719907573

Epoch: 5| Step: 9
Training loss: 3.718374281423661
Validation loss: 3.6024537609644605

Epoch: 5| Step: 10
Training loss: 3.863450466110489
Validation loss: 3.6027118640072424

Epoch: 22| Step: 0
Training loss: 4.092181888210881
Validation loss: 3.602524814406248

Epoch: 5| Step: 1
Training loss: 3.2548450155321187
Validation loss: 3.5956093378316027

Epoch: 5| Step: 2
Training loss: 4.235992010280145
Validation loss: 3.587884405761522

Epoch: 5| Step: 3
Training loss: 4.372761180791638
Validation loss: 3.589067460444102

Epoch: 5| Step: 4
Training loss: 3.535620626224687
Validation loss: 3.5850438334977683

Epoch: 5| Step: 5
Training loss: 3.756418711194677
Validation loss: 3.580131679172599

Epoch: 5| Step: 6
Training loss: 2.6878487116779652
Validation loss: 3.5787981375186884

Epoch: 5| Step: 7
Training loss: 3.4368075973913372
Validation loss: 3.5732208919358874

Epoch: 5| Step: 8
Training loss: 4.096877206762492
Validation loss: 3.5719249196439473

Epoch: 5| Step: 9
Training loss: 3.502292291117267
Validation loss: 3.5697717835872487

Epoch: 5| Step: 10
Training loss: 4.357096852723013
Validation loss: 3.564902086043042

Epoch: 23| Step: 0
Training loss: 3.7995328666268486
Validation loss: 3.562792959007168

Epoch: 5| Step: 1
Training loss: 3.7689637384489605
Validation loss: 3.5609415283462553

Epoch: 5| Step: 2
Training loss: 4.641635155470958
Validation loss: 3.558625279251971

Epoch: 5| Step: 3
Training loss: 3.9910301725718518
Validation loss: 3.5514771098113695

Epoch: 5| Step: 4
Training loss: 3.4415707153787554
Validation loss: 3.553297074672851

Epoch: 5| Step: 5
Training loss: 3.7933354460761204
Validation loss: 3.5502763082270885

Epoch: 5| Step: 6
Training loss: 3.7305891566792257
Validation loss: 3.5442029558879247

Epoch: 5| Step: 7
Training loss: 3.822170936686439
Validation loss: 3.544593388345161

Epoch: 5| Step: 8
Training loss: 3.3593014731234083
Validation loss: 3.540710597167561

Epoch: 5| Step: 9
Training loss: 3.531236496621029
Validation loss: 3.5385535190929835

Epoch: 5| Step: 10
Training loss: 3.1533088199504107
Validation loss: 3.5353843131792324

Epoch: 24| Step: 0
Training loss: 4.025663541512491
Validation loss: 3.5307754080071274

Epoch: 5| Step: 1
Training loss: 4.054837321488416
Validation loss: 3.528549211297226

Epoch: 5| Step: 2
Training loss: 3.242902929584166
Validation loss: 3.5270890413634763

Epoch: 5| Step: 3
Training loss: 3.918208866995586
Validation loss: 3.523938610975974

Epoch: 5| Step: 4
Training loss: 3.4747383732729165
Validation loss: 3.521471297183663

Epoch: 5| Step: 5
Training loss: 3.4426651036736415
Validation loss: 3.5217270323365164

Epoch: 5| Step: 6
Training loss: 3.685001496686075
Validation loss: 3.518144362127785

Epoch: 5| Step: 7
Training loss: 3.7001315222381423
Validation loss: 3.5141644935924417

Epoch: 5| Step: 8
Training loss: 3.4371293301571533
Validation loss: 3.5099693464416553

Epoch: 5| Step: 9
Training loss: 3.878940424619721
Validation loss: 3.508209450886293

Epoch: 5| Step: 10
Training loss: 4.105400687396682
Validation loss: 3.5061119699500143

Epoch: 25| Step: 0
Training loss: 4.163370099929774
Validation loss: 3.50380260700969

Epoch: 5| Step: 1
Training loss: 3.4335995827062233
Validation loss: 3.499489738255805

Epoch: 5| Step: 2
Training loss: 3.3384367181922907
Validation loss: 3.4990167701676924

Epoch: 5| Step: 3
Training loss: 3.568752490575559
Validation loss: 3.4936846274804236

Epoch: 5| Step: 4
Training loss: 3.713977347662831
Validation loss: 3.491420514343168

Epoch: 5| Step: 5
Training loss: 3.5963358987965317
Validation loss: 3.489524909632226

Epoch: 5| Step: 6
Training loss: 3.844747522445725
Validation loss: 3.4877303812870393

Epoch: 5| Step: 7
Training loss: 3.834923262443853
Validation loss: 3.483274100052661

Epoch: 5| Step: 8
Training loss: 3.856436533566546
Validation loss: 3.4817094260476518

Epoch: 5| Step: 9
Training loss: 3.349220578064363
Validation loss: 3.479611055552714

Epoch: 5| Step: 10
Training loss: 4.003572299335414
Validation loss: 3.4757196569587387

Epoch: 26| Step: 0
Training loss: 3.8452915728951704
Validation loss: 3.4756809246499127

Epoch: 5| Step: 1
Training loss: 3.668686541604741
Validation loss: 3.472089815684768

Epoch: 5| Step: 2
Training loss: 3.8826093716516104
Validation loss: 3.47351469933426

Epoch: 5| Step: 3
Training loss: 2.3682734953774807
Validation loss: 3.4679777051881757

Epoch: 5| Step: 4
Training loss: 4.383860960753406
Validation loss: 3.4742494250147695

Epoch: 5| Step: 5
Training loss: 3.089849922955275
Validation loss: 3.467530880052601

Epoch: 5| Step: 6
Training loss: 3.6333624310742785
Validation loss: 3.462337625404992

Epoch: 5| Step: 7
Training loss: 3.5642224882575415
Validation loss: 3.4560995368581224

Epoch: 5| Step: 8
Training loss: 3.880414809636804
Validation loss: 3.4558155122501497

Epoch: 5| Step: 9
Training loss: 4.052366088311406
Validation loss: 3.454792561995591

Epoch: 5| Step: 10
Training loss: 3.749021020894962
Validation loss: 3.45072815742584

Epoch: 27| Step: 0
Training loss: 4.006040303995496
Validation loss: 3.4470818732154016

Epoch: 5| Step: 1
Training loss: 3.2169962429206116
Validation loss: 3.4474896464355633

Epoch: 5| Step: 2
Training loss: 3.660571812638484
Validation loss: 3.4420320557998085

Epoch: 5| Step: 3
Training loss: 3.774717757429606
Validation loss: 3.439759322833297

Epoch: 5| Step: 4
Training loss: 3.8188026736758256
Validation loss: 3.4363582635393484

Epoch: 5| Step: 5
Training loss: 3.626751443722867
Validation loss: 3.4360601308818195

Epoch: 5| Step: 6
Training loss: 3.7380922084352934
Validation loss: 3.433332716546231

Epoch: 5| Step: 7
Training loss: 3.282729187842843
Validation loss: 3.4344194810818434

Epoch: 5| Step: 8
Training loss: 4.224622693792575
Validation loss: 3.428073347455996

Epoch: 5| Step: 9
Training loss: 2.6584251025233563
Validation loss: 3.4275264957772014

Epoch: 5| Step: 10
Training loss: 4.026709313282591
Validation loss: 3.4251892818384433

Epoch: 28| Step: 0
Training loss: 3.4702356954334315
Validation loss: 3.4274572911536656

Epoch: 5| Step: 1
Training loss: 3.013741651260033
Validation loss: 3.420257296852402

Epoch: 5| Step: 2
Training loss: 3.330382248759377
Validation loss: 3.417565491404356

Epoch: 5| Step: 3
Training loss: 5.033669215904685
Validation loss: 3.4162782802977905

Epoch: 5| Step: 4
Training loss: 4.2224970248512825
Validation loss: 3.412629112671826

Epoch: 5| Step: 5
Training loss: 3.968153660944555
Validation loss: 3.4125969962956946

Epoch: 5| Step: 6
Training loss: 2.955709144199574
Validation loss: 3.407051265387525

Epoch: 5| Step: 7
Training loss: 3.7422050841999446
Validation loss: 3.4054673345529576

Epoch: 5| Step: 8
Training loss: 2.9607730709105686
Validation loss: 3.402650939561967

Epoch: 5| Step: 9
Training loss: 2.982080186457828
Validation loss: 3.4031753082370173

Epoch: 5| Step: 10
Training loss: 3.768509895432174
Validation loss: 3.404774552783464

Epoch: 29| Step: 0
Training loss: 3.6747723774905006
Validation loss: 3.4003420658304053

Epoch: 5| Step: 1
Training loss: 3.1948377634327163
Validation loss: 3.3934347087797176

Epoch: 5| Step: 2
Training loss: 3.81384078666382
Validation loss: 3.402123367392219

Epoch: 5| Step: 3
Training loss: 3.461401225899025
Validation loss: 3.402285328207791

Epoch: 5| Step: 4
Training loss: 3.722501513376434
Validation loss: 3.392949234240575

Epoch: 5| Step: 5
Training loss: 3.40401560441597
Validation loss: 3.38613032212513

Epoch: 5| Step: 6
Training loss: 3.4310650329208037
Validation loss: 3.3856109818318596

Epoch: 5| Step: 7
Training loss: 3.854993425653099
Validation loss: 3.388340122255705

Epoch: 5| Step: 8
Training loss: 3.3159871010615736
Validation loss: 3.3864731698000075

Epoch: 5| Step: 9
Training loss: 3.524096509791857
Validation loss: 3.383169134222953

Epoch: 5| Step: 10
Training loss: 4.387682380037418
Validation loss: 3.3811602550021993

Epoch: 30| Step: 0
Training loss: 3.699095259702897
Validation loss: 3.376392651427382

Epoch: 5| Step: 1
Training loss: 3.548041466970584
Validation loss: 3.372891389114552

Epoch: 5| Step: 2
Training loss: 2.6825191561822836
Validation loss: 3.37050402727851

Epoch: 5| Step: 3
Training loss: 4.000594333363682
Validation loss: 3.364306023803236

Epoch: 5| Step: 4
Training loss: 3.360719065925577
Validation loss: 3.367773323650863

Epoch: 5| Step: 5
Training loss: 3.345306604585972
Validation loss: 3.3751779552655785

Epoch: 5| Step: 6
Training loss: 3.4234182283249925
Validation loss: 3.375002705684232

Epoch: 5| Step: 7
Training loss: 4.242602923374952
Validation loss: 3.370491878786269

Epoch: 5| Step: 8
Training loss: 3.436666214132295
Validation loss: 3.36316632604736

Epoch: 5| Step: 9
Training loss: 4.185863118010981
Validation loss: 3.35368723427877

Epoch: 5| Step: 10
Training loss: 3.364006363063242
Validation loss: 3.352411842287944

Epoch: 31| Step: 0
Training loss: 3.443001246531602
Validation loss: 3.3681601418713267

Epoch: 5| Step: 1
Training loss: 3.472664351394867
Validation loss: 3.3686142810721504

Epoch: 5| Step: 2
Training loss: 3.493818819463497
Validation loss: 3.362514915483547

Epoch: 5| Step: 3
Training loss: 3.540290131182988
Validation loss: 3.3461453408039543

Epoch: 5| Step: 4
Training loss: 3.886682680815677
Validation loss: 3.348747594453769

Epoch: 5| Step: 5
Training loss: 3.5639123626620437
Validation loss: 3.3509210332718715

Epoch: 5| Step: 6
Training loss: 3.34604430588542
Validation loss: 3.3447555718220445

Epoch: 5| Step: 7
Training loss: 3.353415521583985
Validation loss: 3.3428485012772877

Epoch: 5| Step: 8
Training loss: 4.039529031929922
Validation loss: 3.341029080884941

Epoch: 5| Step: 9
Training loss: 3.8907685157626006
Validation loss: 3.3378130518431552

Epoch: 5| Step: 10
Training loss: 3.2532775198208466
Validation loss: 3.335775862276368

Epoch: 32| Step: 0
Training loss: 3.6946224673282146
Validation loss: 3.334696024080121

Epoch: 5| Step: 1
Training loss: 3.0841547584939413
Validation loss: 3.338937968773216

Epoch: 5| Step: 2
Training loss: 3.04572372204503
Validation loss: 3.341307281357551

Epoch: 5| Step: 3
Training loss: 4.3616943752257535
Validation loss: 3.338907404002479

Epoch: 5| Step: 4
Training loss: 3.785727254120446
Validation loss: 3.324392406034933

Epoch: 5| Step: 5
Training loss: 3.2489782341122053
Validation loss: 3.323623070377242

Epoch: 5| Step: 6
Training loss: 3.3773107741945694
Validation loss: 3.330213903465915

Epoch: 5| Step: 7
Training loss: 2.9812887321211377
Validation loss: 3.339323969272275

Epoch: 5| Step: 8
Training loss: 3.489885155829473
Validation loss: 3.337566902584217

Epoch: 5| Step: 9
Training loss: 3.9419890956718167
Validation loss: 3.3324086926978382

Epoch: 5| Step: 10
Training loss: 4.036911884380913
Validation loss: 3.324295587717945

Epoch: 33| Step: 0
Training loss: 2.925139373327971
Validation loss: 3.3152496803715756

Epoch: 5| Step: 1
Training loss: 4.345137998718254
Validation loss: 3.3168907034413513

Epoch: 5| Step: 2
Training loss: 3.0861150376639883
Validation loss: 3.314937526690998

Epoch: 5| Step: 3
Training loss: 3.294972092042861
Validation loss: 3.3193200628803123

Epoch: 5| Step: 4
Training loss: 3.8205317958931024
Validation loss: 3.3135587285436476

Epoch: 5| Step: 5
Training loss: 3.6754634123843983
Validation loss: 3.31237835698472

Epoch: 5| Step: 6
Training loss: 3.277529396373402
Validation loss: 3.3086173485335912

Epoch: 5| Step: 7
Training loss: 3.942605598888409
Validation loss: 3.3013081156748254

Epoch: 5| Step: 8
Training loss: 3.146041071687344
Validation loss: 3.298450606103493

Epoch: 5| Step: 9
Training loss: 4.322983093976953
Validation loss: 3.301391854202758

Epoch: 5| Step: 10
Training loss: 2.671814321085472
Validation loss: 3.297051164595514

Epoch: 34| Step: 0
Training loss: 3.728222491259868
Validation loss: 3.2980176614114716

Epoch: 5| Step: 1
Training loss: 3.026959401004915
Validation loss: 3.296846311205572

Epoch: 5| Step: 2
Training loss: 3.512879108862684
Validation loss: 3.2980032372862715

Epoch: 5| Step: 3
Training loss: 3.6167163253633
Validation loss: 3.2943475978509316

Epoch: 5| Step: 4
Training loss: 3.1899732082760575
Validation loss: 3.297446489046164

Epoch: 5| Step: 5
Training loss: 3.7633634875440722
Validation loss: 3.2942988607736794

Epoch: 5| Step: 6
Training loss: 3.582386261331742
Validation loss: 3.2870307547233395

Epoch: 5| Step: 7
Training loss: 3.8872121526490098
Validation loss: 3.290536597463965

Epoch: 5| Step: 8
Training loss: 2.731062272034094
Validation loss: 3.2847791093886607

Epoch: 5| Step: 9
Training loss: 3.511144605978483
Validation loss: 3.2850264592545058

Epoch: 5| Step: 10
Training loss: 4.220189731906732
Validation loss: 3.2834220467186315

Epoch: 35| Step: 0
Training loss: 4.113721282404368
Validation loss: 3.2793038248865054

Epoch: 5| Step: 1
Training loss: 3.08877564305738
Validation loss: 3.2801962493059187

Epoch: 5| Step: 2
Training loss: 2.6147510631809685
Validation loss: 3.280258360138388

Epoch: 5| Step: 3
Training loss: 4.3174213579412
Validation loss: 3.279141113938053

Epoch: 5| Step: 4
Training loss: 4.270531148997238
Validation loss: 3.275098906846393

Epoch: 5| Step: 5
Training loss: 3.7044550442659974
Validation loss: 3.275112857297173

Epoch: 5| Step: 6
Training loss: 2.8443928086375663
Validation loss: 3.2747447872159254

Epoch: 5| Step: 7
Training loss: 3.242599130260765
Validation loss: 3.274411698047195

Epoch: 5| Step: 8
Training loss: 3.78129464115242
Validation loss: 3.2739684746995534

Epoch: 5| Step: 9
Training loss: 2.9370275888624637
Validation loss: 3.2692699867301322

Epoch: 5| Step: 10
Training loss: 3.3051008682902183
Validation loss: 3.273135118681173

Epoch: 36| Step: 0
Training loss: 4.015529527531158
Validation loss: 3.2700960451629424

Epoch: 5| Step: 1
Training loss: 2.897432631202313
Validation loss: 3.2693787059888826

Epoch: 5| Step: 2
Training loss: 3.9103214865420965
Validation loss: 3.2686820091982134

Epoch: 5| Step: 3
Training loss: 3.4849587537385274
Validation loss: 3.2672570078653824

Epoch: 5| Step: 4
Training loss: 3.761873521324434
Validation loss: 3.2654490257878748

Epoch: 5| Step: 5
Training loss: 3.175049945108055
Validation loss: 3.265833901425268

Epoch: 5| Step: 6
Training loss: 3.1944913298626094
Validation loss: 3.2661721289883077

Epoch: 5| Step: 7
Training loss: 3.3960842359719794
Validation loss: 3.261051886010612

Epoch: 5| Step: 8
Training loss: 3.472970130904003
Validation loss: 3.257724543093542

Epoch: 5| Step: 9
Training loss: 3.919967856372692
Validation loss: 3.260846980258794

Epoch: 5| Step: 10
Training loss: 3.1794623967751723
Validation loss: 3.263654975535366

Epoch: 37| Step: 0
Training loss: 3.393317634481253
Validation loss: 3.261136183410828

Epoch: 5| Step: 1
Training loss: 3.322093243755003
Validation loss: 3.2617158222289735

Epoch: 5| Step: 2
Training loss: 4.197457842998546
Validation loss: 3.2619277239708397

Epoch: 5| Step: 3
Training loss: 3.557285441015706
Validation loss: 3.254056974643127

Epoch: 5| Step: 4
Training loss: 3.1112511883339122
Validation loss: 3.256192903858744

Epoch: 5| Step: 5
Training loss: 3.362513296108122
Validation loss: 3.2571088223186866

Epoch: 5| Step: 6
Training loss: 3.4435176542518326
Validation loss: 3.2532566624985186

Epoch: 5| Step: 7
Training loss: 3.9580421474500764
Validation loss: 3.25050802022939

Epoch: 5| Step: 8
Training loss: 3.3285586652154353
Validation loss: 3.2534116282322203

Epoch: 5| Step: 9
Training loss: 3.398176231426072
Validation loss: 3.2512158445794026

Epoch: 5| Step: 10
Training loss: 3.2872231022364384
Validation loss: 3.252299001266159

Epoch: 38| Step: 0
Training loss: 3.245923640341939
Validation loss: 3.2484852847774963

Epoch: 5| Step: 1
Training loss: 3.9476783834864007
Validation loss: 3.2507990745327855

Epoch: 5| Step: 2
Training loss: 2.2079313620112893
Validation loss: 3.248859833415432

Epoch: 5| Step: 3
Training loss: 3.785463365943126
Validation loss: 3.2589097062860377

Epoch: 5| Step: 4
Training loss: 3.48727884445934
Validation loss: 3.2451551973085944

Epoch: 5| Step: 5
Training loss: 4.217600800146857
Validation loss: 3.2482200067671387

Epoch: 5| Step: 6
Training loss: 3.1072662717365693
Validation loss: 3.245312434718378

Epoch: 5| Step: 7
Training loss: 3.7501857711553797
Validation loss: 3.25174567808012

Epoch: 5| Step: 8
Training loss: 3.5486924140775353
Validation loss: 3.252588091939238

Epoch: 5| Step: 9
Training loss: 3.1814358939846925
Validation loss: 3.247612281958799

Epoch: 5| Step: 10
Training loss: 3.594720858585192
Validation loss: 3.2523266357891627

Epoch: 39| Step: 0
Training loss: 3.462677460126931
Validation loss: 3.2444941009734913

Epoch: 5| Step: 1
Training loss: 3.7629594034462905
Validation loss: 3.244505387472405

Epoch: 5| Step: 2
Training loss: 3.425688130103773
Validation loss: 3.2467723734480987

Epoch: 5| Step: 3
Training loss: 3.73777507675543
Validation loss: 3.2406863771505763

Epoch: 5| Step: 4
Training loss: 3.1477118098320798
Validation loss: 3.2378069544399444

Epoch: 5| Step: 5
Training loss: 3.3433476856667808
Validation loss: 3.2390550295331746

Epoch: 5| Step: 6
Training loss: 2.8907185307397887
Validation loss: 3.2361492616731753

Epoch: 5| Step: 7
Training loss: 3.8045256969974286
Validation loss: 3.2360662376558476

Epoch: 5| Step: 8
Training loss: 3.6600449910551442
Validation loss: 3.232262557478969

Epoch: 5| Step: 9
Training loss: 3.837871615530212
Validation loss: 3.234026946770412

Epoch: 5| Step: 10
Training loss: 3.111339619358476
Validation loss: 3.2350159102668328

Epoch: 40| Step: 0
Training loss: 3.51004344793746
Validation loss: 3.235089618289596

Epoch: 5| Step: 1
Training loss: 3.6893417155790167
Validation loss: 3.2342392857950912

Epoch: 5| Step: 2
Training loss: 3.3965502179231115
Validation loss: 3.234003455561538

Epoch: 5| Step: 3
Training loss: 3.544518448333795
Validation loss: 3.236765766525311

Epoch: 5| Step: 4
Training loss: 3.129261925301804
Validation loss: 3.249678934296983

Epoch: 5| Step: 5
Training loss: 3.463364002384487
Validation loss: 3.2341800373532794

Epoch: 5| Step: 6
Training loss: 3.7231884282760563
Validation loss: 3.2287721920249233

Epoch: 5| Step: 7
Training loss: 3.7086380108317045
Validation loss: 3.234953685225516

Epoch: 5| Step: 8
Training loss: 3.765354130923439
Validation loss: 3.243085108879839

Epoch: 5| Step: 9
Training loss: 2.8810652733624416
Validation loss: 3.2329128710238746

Epoch: 5| Step: 10
Training loss: 3.4145561926280767
Validation loss: 3.241462731873674

Epoch: 41| Step: 0
Training loss: 3.4132065038165083
Validation loss: 3.246925087326621

Epoch: 5| Step: 1
Training loss: 4.061596109630261
Validation loss: 3.253720153987121

Epoch: 5| Step: 2
Training loss: 3.2771513999535897
Validation loss: 3.2420866255592165

Epoch: 5| Step: 3
Training loss: 3.804659175571544
Validation loss: 3.236860562549914

Epoch: 5| Step: 4
Training loss: 2.540344665751675
Validation loss: 3.235586102023751

Epoch: 5| Step: 5
Training loss: 3.0824163121405417
Validation loss: 3.2392439672219395

Epoch: 5| Step: 6
Training loss: 3.1057029012059543
Validation loss: 3.237136672387346

Epoch: 5| Step: 7
Training loss: 3.952371638588538
Validation loss: 3.2349645469573924

Epoch: 5| Step: 8
Training loss: 3.4494650937476377
Validation loss: 3.2311233282098293

Epoch: 5| Step: 9
Training loss: 3.7970341150671647
Validation loss: 3.2295676266602382

Epoch: 5| Step: 10
Training loss: 3.6480321883655407
Validation loss: 3.226950756786798

Epoch: 42| Step: 0
Training loss: 3.7178830971563768
Validation loss: 3.2301291617487724

Epoch: 5| Step: 1
Training loss: 3.396090975545939
Validation loss: 3.2278467715351207

Epoch: 5| Step: 2
Training loss: 3.257531023558456
Validation loss: 3.228299825165794

Epoch: 5| Step: 3
Training loss: 3.281633627127701
Validation loss: 3.2267417247133734

Epoch: 5| Step: 4
Training loss: 3.8183076742823383
Validation loss: 3.2279818999492105

Epoch: 5| Step: 5
Training loss: 2.930064103398493
Validation loss: 3.223724304788225

Epoch: 5| Step: 6
Training loss: 3.114013891993941
Validation loss: 3.22440805203795

Epoch: 5| Step: 7
Training loss: 4.434431277583997
Validation loss: 3.221396830139287

Epoch: 5| Step: 8
Training loss: 3.581914901923833
Validation loss: 3.217992263108672

Epoch: 5| Step: 9
Training loss: 3.453141156327094
Validation loss: 3.2183927582080885

Epoch: 5| Step: 10
Training loss: 2.854212201351581
Validation loss: 3.2174612018379336

Epoch: 43| Step: 0
Training loss: 2.505660515236401
Validation loss: 3.2177292148666483

Epoch: 5| Step: 1
Training loss: 3.9096551320606205
Validation loss: 3.218125056954266

Epoch: 5| Step: 2
Training loss: 3.1997929804118073
Validation loss: 3.220127597427932

Epoch: 5| Step: 3
Training loss: 3.0094129391632713
Validation loss: 3.2156504605210317

Epoch: 5| Step: 4
Training loss: 3.919942189588305
Validation loss: 3.215382631413747

Epoch: 5| Step: 5
Training loss: 3.528851530078574
Validation loss: 3.2159524610453887

Epoch: 5| Step: 6
Training loss: 3.02784616546703
Validation loss: 3.2220276359636344

Epoch: 5| Step: 7
Training loss: 3.5962739788657503
Validation loss: 3.230916259360391

Epoch: 5| Step: 8
Training loss: 4.110382072714336
Validation loss: 3.223849101274243

Epoch: 5| Step: 9
Training loss: 3.4760485322766534
Validation loss: 3.219078137239987

Epoch: 5| Step: 10
Training loss: 3.5722765705990045
Validation loss: 3.218275210993962

Epoch: 44| Step: 0
Training loss: 3.119143376740333
Validation loss: 3.2122115236018303

Epoch: 5| Step: 1
Training loss: 4.261123014187811
Validation loss: 3.2093109657109387

Epoch: 5| Step: 2
Training loss: 3.7175759137014674
Validation loss: 3.212667635969701

Epoch: 5| Step: 3
Training loss: 3.8980952477676767
Validation loss: 3.2129675024047146

Epoch: 5| Step: 4
Training loss: 2.039126106527086
Validation loss: 3.2156574554848025

Epoch: 5| Step: 5
Training loss: 3.463895683074572
Validation loss: 3.2135122461421983

Epoch: 5| Step: 6
Training loss: 3.3367337207998706
Validation loss: 3.212570181331752

Epoch: 5| Step: 7
Training loss: 3.631623235486292
Validation loss: 3.213950185131283

Epoch: 5| Step: 8
Training loss: 3.034963476473454
Validation loss: 3.2074373579228492

Epoch: 5| Step: 9
Training loss: 3.301488748603169
Validation loss: 3.206954339009353

Epoch: 5| Step: 10
Training loss: 3.8849434790310804
Validation loss: 3.204482354857089

Epoch: 45| Step: 0
Training loss: 3.1831199621089166
Validation loss: 3.2037250107894613

Epoch: 5| Step: 1
Training loss: 3.2752076236052834
Validation loss: 3.2035474353098334

Epoch: 5| Step: 2
Training loss: 3.4057441825825414
Validation loss: 3.2038044014642897

Epoch: 5| Step: 3
Training loss: 3.303891349825632
Validation loss: 3.2063289734394003

Epoch: 5| Step: 4
Training loss: 3.1662894241764077
Validation loss: 3.203295835455836

Epoch: 5| Step: 5
Training loss: 3.6716294226804367
Validation loss: 3.2071138218221584

Epoch: 5| Step: 6
Training loss: 3.9696771935352655
Validation loss: 3.2059725969735675

Epoch: 5| Step: 7
Training loss: 4.208156821197032
Validation loss: 3.208083780046977

Epoch: 5| Step: 8
Training loss: 3.408702002796969
Validation loss: 3.2080074544861996

Epoch: 5| Step: 9
Training loss: 3.3981201023657976
Validation loss: 3.201587129945162

Epoch: 5| Step: 10
Training loss: 2.6692770658590854
Validation loss: 3.1996964708703066

Epoch: 46| Step: 0
Training loss: 3.591607690903739
Validation loss: 3.1973628637856386

Epoch: 5| Step: 1
Training loss: 3.352698215937193
Validation loss: 3.197694674070467

Epoch: 5| Step: 2
Training loss: 3.669724634218651
Validation loss: 3.199760094617349

Epoch: 5| Step: 3
Training loss: 3.822802397278747
Validation loss: 3.1986706743895112

Epoch: 5| Step: 4
Training loss: 3.249103569232762
Validation loss: 3.2019641372358048

Epoch: 5| Step: 5
Training loss: 2.841657937969625
Validation loss: 3.1953849849446874

Epoch: 5| Step: 6
Training loss: 3.9227901773965566
Validation loss: 3.197835006438173

Epoch: 5| Step: 7
Training loss: 2.9873195322346917
Validation loss: 3.1929048915554157

Epoch: 5| Step: 8
Training loss: 3.4060443501119004
Validation loss: 3.193107241341591

Epoch: 5| Step: 9
Training loss: 3.699899677256822
Validation loss: 3.1921929724362212

Epoch: 5| Step: 10
Training loss: 3.2015990553519456
Validation loss: 3.1998151444422156

Epoch: 47| Step: 0
Training loss: 3.6328860039606856
Validation loss: 3.1965216007756236

Epoch: 5| Step: 1
Training loss: 3.7515133665045766
Validation loss: 3.195504413915669

Epoch: 5| Step: 2
Training loss: 3.826182592745964
Validation loss: 3.193142006901933

Epoch: 5| Step: 3
Training loss: 3.4035125371646875
Validation loss: 3.1943358692825488

Epoch: 5| Step: 4
Training loss: 3.7157965720742925
Validation loss: 3.194873960943357

Epoch: 5| Step: 5
Training loss: 2.645407144258294
Validation loss: 3.1937755413762736

Epoch: 5| Step: 6
Training loss: 3.8358984671352943
Validation loss: 3.1921632914388924

Epoch: 5| Step: 7
Training loss: 3.474615962261884
Validation loss: 3.191348378497988

Epoch: 5| Step: 8
Training loss: 3.1977051075759144
Validation loss: 3.191900607642743

Epoch: 5| Step: 9
Training loss: 2.7772069111310174
Validation loss: 3.1912194246268477

Epoch: 5| Step: 10
Training loss: 3.396448996185782
Validation loss: 3.1878759446767027

Epoch: 48| Step: 0
Training loss: 3.2733547591720837
Validation loss: 3.190429367690719

Epoch: 5| Step: 1
Training loss: 3.3370199479743468
Validation loss: 3.1895510568922276

Epoch: 5| Step: 2
Training loss: 2.7191466118925165
Validation loss: 3.1892318540822817

Epoch: 5| Step: 3
Training loss: 3.4566098403551333
Validation loss: 3.1885373773742396

Epoch: 5| Step: 4
Training loss: 3.9180926439315678
Validation loss: 3.1864135550671047

Epoch: 5| Step: 5
Training loss: 4.555842310453122
Validation loss: 3.1881458610164177

Epoch: 5| Step: 6
Training loss: 3.4056617158817257
Validation loss: 3.188312225159569

Epoch: 5| Step: 7
Training loss: 2.9868800649302663
Validation loss: 3.1868454649004847

Epoch: 5| Step: 8
Training loss: 3.132393749532746
Validation loss: 3.1894949296826245

Epoch: 5| Step: 9
Training loss: 3.254649284676854
Validation loss: 3.189008308856153

Epoch: 5| Step: 10
Training loss: 3.4640005778076537
Validation loss: 3.1829755595452864

Epoch: 49| Step: 0
Training loss: 3.5588113527734095
Validation loss: 3.1858157252826795

Epoch: 5| Step: 1
Training loss: 2.6077449984125374
Validation loss: 3.1883023880966643

Epoch: 5| Step: 2
Training loss: 3.3415707055168324
Validation loss: 3.191530366301221

Epoch: 5| Step: 3
Training loss: 3.3403905231343685
Validation loss: 3.191791779387718

Epoch: 5| Step: 4
Training loss: 3.97282788891446
Validation loss: 3.1997425467357883

Epoch: 5| Step: 5
Training loss: 3.4035687173962104
Validation loss: 3.193752830530927

Epoch: 5| Step: 6
Training loss: 3.682645285253125
Validation loss: 3.1868385418427096

Epoch: 5| Step: 7
Training loss: 2.998777617326959
Validation loss: 3.1853377512114975

Epoch: 5| Step: 8
Training loss: 3.310404708645451
Validation loss: 3.188751849935088

Epoch: 5| Step: 9
Training loss: 3.879997353503711
Validation loss: 3.185042374653668

Epoch: 5| Step: 10
Training loss: 3.512082090665346
Validation loss: 3.1850273922096646

Epoch: 50| Step: 0
Training loss: 3.209814464638089
Validation loss: 3.185347710105063

Epoch: 5| Step: 1
Training loss: 2.986616481234483
Validation loss: 3.1822953815350243

Epoch: 5| Step: 2
Training loss: 3.2691973990899217
Validation loss: 3.1895740701290625

Epoch: 5| Step: 3
Training loss: 3.5197060189161715
Validation loss: 3.1813358975352943

Epoch: 5| Step: 4
Training loss: 3.7205208801331615
Validation loss: 3.181902380064847

Epoch: 5| Step: 5
Training loss: 3.0203267341353346
Validation loss: 3.1819530207718887

Epoch: 5| Step: 6
Training loss: 3.4982333493010596
Validation loss: 3.1810270532757814

Epoch: 5| Step: 7
Training loss: 3.8517005384984233
Validation loss: 3.1819582995926003

Epoch: 5| Step: 8
Training loss: 3.4349008617504104
Validation loss: 3.1784516716247047

Epoch: 5| Step: 9
Training loss: 3.8990482929738612
Validation loss: 3.1794095731844143

Epoch: 5| Step: 10
Training loss: 3.1685007873890547
Validation loss: 3.182971505045044

Epoch: 51| Step: 0
Training loss: 3.164152469062315
Validation loss: 3.1775145454758316

Epoch: 5| Step: 1
Training loss: 3.3138075353231593
Validation loss: 3.177012187793927

Epoch: 5| Step: 2
Training loss: 3.6781626009903
Validation loss: 3.1813836430650744

Epoch: 5| Step: 3
Training loss: 3.1990081382426148
Validation loss: 3.1807624697167354

Epoch: 5| Step: 4
Training loss: 3.1720513355868225
Validation loss: 3.179320442270575

Epoch: 5| Step: 5
Training loss: 3.4951577068323947
Validation loss: 3.184872549102679

Epoch: 5| Step: 6
Training loss: 3.3587279650324198
Validation loss: 3.1834140545940808

Epoch: 5| Step: 7
Training loss: 3.445103230251576
Validation loss: 3.183420938391188

Epoch: 5| Step: 8
Training loss: 3.9800093126427663
Validation loss: 3.178176240569152

Epoch: 5| Step: 9
Training loss: 3.705802110752491
Validation loss: 3.1778936462605873

Epoch: 5| Step: 10
Training loss: 3.0516749988763694
Validation loss: 3.176482615507432

Epoch: 52| Step: 0
Training loss: 4.022584813695545
Validation loss: 3.173808135696202

Epoch: 5| Step: 1
Training loss: 3.8818079303234936
Validation loss: 3.1742529472973144

Epoch: 5| Step: 2
Training loss: 3.375472565521512
Validation loss: 3.177707929589593

Epoch: 5| Step: 3
Training loss: 3.567826154485099
Validation loss: 3.1743101903984767

Epoch: 5| Step: 4
Training loss: 3.1789797433385965
Validation loss: 3.175702112952977

Epoch: 5| Step: 5
Training loss: 3.1857083839249425
Validation loss: 3.173723137544467

Epoch: 5| Step: 6
Training loss: 3.1155426351207076
Validation loss: 3.1778630153097462

Epoch: 5| Step: 7
Training loss: 2.898615006514948
Validation loss: 3.1750199698176322

Epoch: 5| Step: 8
Training loss: 3.737906091374824
Validation loss: 3.1773921650360903

Epoch: 5| Step: 9
Training loss: 3.7727977771166854
Validation loss: 3.176099823022768

Epoch: 5| Step: 10
Training loss: 2.514629095799402
Validation loss: 3.1730578007604593

Epoch: 53| Step: 0
Training loss: 3.3490658154995776
Validation loss: 3.172636247785719

Epoch: 5| Step: 1
Training loss: 3.2934739346420376
Validation loss: 3.1713696908824045

Epoch: 5| Step: 2
Training loss: 3.039439827605937
Validation loss: 3.1729281641233023

Epoch: 5| Step: 3
Training loss: 4.2310726337081315
Validation loss: 3.171243927008943

Epoch: 5| Step: 4
Training loss: 3.209676007471317
Validation loss: 3.171547294534668

Epoch: 5| Step: 5
Training loss: 2.5864803055685055
Validation loss: 3.1706871379872874

Epoch: 5| Step: 6
Training loss: 3.4613969553854216
Validation loss: 3.167153273037717

Epoch: 5| Step: 7
Training loss: 3.341913877810022
Validation loss: 3.1685615374286185

Epoch: 5| Step: 8
Training loss: 3.6170552767157007
Validation loss: 3.1713630670903674

Epoch: 5| Step: 9
Training loss: 3.5587162201929305
Validation loss: 3.17146655235805

Epoch: 5| Step: 10
Training loss: 3.7766428221185246
Validation loss: 3.170273603737671

Epoch: 54| Step: 0
Training loss: 2.732862740998698
Validation loss: 3.166778237579922

Epoch: 5| Step: 1
Training loss: 3.157075830572936
Validation loss: 3.1696841840562318

Epoch: 5| Step: 2
Training loss: 4.002660820021691
Validation loss: 3.1717025133660695

Epoch: 5| Step: 3
Training loss: 3.954708822457396
Validation loss: 3.1792055484184956

Epoch: 5| Step: 4
Training loss: 2.3050529578159766
Validation loss: 3.1741795161919444

Epoch: 5| Step: 5
Training loss: 3.747865959758878
Validation loss: 3.1787446709315694

Epoch: 5| Step: 6
Training loss: 2.9016344068714335
Validation loss: 3.1726433480907326

Epoch: 5| Step: 7
Training loss: 3.451907534469294
Validation loss: 3.1688093817019047

Epoch: 5| Step: 8
Training loss: 3.2445453940179005
Validation loss: 3.166131640401278

Epoch: 5| Step: 9
Training loss: 3.31221093410016
Validation loss: 3.165941898379011

Epoch: 5| Step: 10
Training loss: 4.461064057968331
Validation loss: 3.1703275272722395

Epoch: 55| Step: 0
Training loss: 4.141973311945662
Validation loss: 3.170156722597489

Epoch: 5| Step: 1
Training loss: 3.5800982369098886
Validation loss: 3.167523446833367

Epoch: 5| Step: 2
Training loss: 4.04663745079827
Validation loss: 3.1652135167516637

Epoch: 5| Step: 3
Training loss: 3.134997131735723
Validation loss: 3.1667900212543265

Epoch: 5| Step: 4
Training loss: 3.686031372375608
Validation loss: 3.165031779088117

Epoch: 5| Step: 5
Training loss: 2.9800913160529428
Validation loss: 3.1645589111187644

Epoch: 5| Step: 6
Training loss: 2.3612184712055355
Validation loss: 3.1620978106192164

Epoch: 5| Step: 7
Training loss: 2.8273776421013674
Validation loss: 3.1641827611984277

Epoch: 5| Step: 8
Training loss: 3.3416099473764547
Validation loss: 3.163928903675891

Epoch: 5| Step: 9
Training loss: 3.3769053979240105
Validation loss: 3.1649257854047215

Epoch: 5| Step: 10
Training loss: 3.7700664239187187
Validation loss: 3.1608834709074047

Epoch: 56| Step: 0
Training loss: 3.430463490213885
Validation loss: 3.163126007732903

Epoch: 5| Step: 1
Training loss: 3.182489084133657
Validation loss: 3.1662275900996097

Epoch: 5| Step: 2
Training loss: 3.5098868101296192
Validation loss: 3.166804018965562

Epoch: 5| Step: 3
Training loss: 3.8361198552871647
Validation loss: 3.162705445992188

Epoch: 5| Step: 4
Training loss: 3.2916245437695344
Validation loss: 3.1613467146900107

Epoch: 5| Step: 5
Training loss: 3.102774664242544
Validation loss: 3.1624117072596225

Epoch: 5| Step: 6
Training loss: 3.9446801009248915
Validation loss: 3.16357823530718

Epoch: 5| Step: 7
Training loss: 3.9685504292449716
Validation loss: 3.1617949083398313

Epoch: 5| Step: 8
Training loss: 3.638842887361163
Validation loss: 3.1623046302330398

Epoch: 5| Step: 9
Training loss: 2.5700134288867447
Validation loss: 3.160871567886887

Epoch: 5| Step: 10
Training loss: 2.7316705026496857
Validation loss: 3.1626374599017644

Epoch: 57| Step: 0
Training loss: 3.345177746713094
Validation loss: 3.15819775776882

Epoch: 5| Step: 1
Training loss: 3.2127300373051173
Validation loss: 3.1564119992491575

Epoch: 5| Step: 2
Training loss: 3.5934801083268053
Validation loss: 3.1575724681030897

Epoch: 5| Step: 3
Training loss: 4.12342827648824
Validation loss: 3.1572613431455956

Epoch: 5| Step: 4
Training loss: 3.2615629056144653
Validation loss: 3.1579932945358116

Epoch: 5| Step: 5
Training loss: 3.162703158521346
Validation loss: 3.161819025222318

Epoch: 5| Step: 6
Training loss: 3.005346461426777
Validation loss: 3.159899696745776

Epoch: 5| Step: 7
Training loss: 3.4024965096483117
Validation loss: 3.1564756922125374

Epoch: 5| Step: 8
Training loss: 3.70274009796708
Validation loss: 3.155621016275133

Epoch: 5| Step: 9
Training loss: 3.2648251662828813
Validation loss: 3.159435310095262

Epoch: 5| Step: 10
Training loss: 3.3211920078255397
Validation loss: 3.162677458810525

Epoch: 58| Step: 0
Training loss: 3.332741700755929
Validation loss: 3.1610871211083937

Epoch: 5| Step: 1
Training loss: 3.139786185984831
Validation loss: 3.1617296546449944

Epoch: 5| Step: 2
Training loss: 3.673811381665395
Validation loss: 3.1581627698867356

Epoch: 5| Step: 3
Training loss: 3.5670276447291123
Validation loss: 3.158832855770872

Epoch: 5| Step: 4
Training loss: 3.6373885671844413
Validation loss: 3.1554613341353885

Epoch: 5| Step: 5
Training loss: 3.4698260588570062
Validation loss: 3.162923276643298

Epoch: 5| Step: 6
Training loss: 3.277824139312058
Validation loss: 3.1601132345933345

Epoch: 5| Step: 7
Training loss: 3.6147091245429017
Validation loss: 3.1587351710564815

Epoch: 5| Step: 8
Training loss: 2.791938474337951
Validation loss: 3.157068661962982

Epoch: 5| Step: 9
Training loss: 3.504963352811727
Validation loss: 3.156269704943422

Epoch: 5| Step: 10
Training loss: 3.4075629827285963
Validation loss: 3.1544654046586476

Epoch: 59| Step: 0
Training loss: 3.081444514017533
Validation loss: 3.1665372357905777

Epoch: 5| Step: 1
Training loss: 3.3679587770870527
Validation loss: 3.164044170764583

Epoch: 5| Step: 2
Training loss: 3.261044296614197
Validation loss: 3.1613360573894798

Epoch: 5| Step: 3
Training loss: 3.168382196693406
Validation loss: 3.1571914453031127

Epoch: 5| Step: 4
Training loss: 3.5736519786285106
Validation loss: 3.154307695062472

Epoch: 5| Step: 5
Training loss: 3.1122850765188548
Validation loss: 3.1533705667094667

Epoch: 5| Step: 6
Training loss: 3.8209327865076075
Validation loss: 3.151609118318029

Epoch: 5| Step: 7
Training loss: 3.229347634115561
Validation loss: 3.153380681843402

Epoch: 5| Step: 8
Training loss: 3.62148522294814
Validation loss: 3.155935657840644

Epoch: 5| Step: 9
Training loss: 3.8915291467148805
Validation loss: 3.1568172549800924

Epoch: 5| Step: 10
Training loss: 3.242134553408039
Validation loss: 3.1563627340074984

Epoch: 60| Step: 0
Training loss: 3.2242831475842655
Validation loss: 3.1582971961780704

Epoch: 5| Step: 1
Training loss: 2.485362114724652
Validation loss: 3.1570311962103657

Epoch: 5| Step: 2
Training loss: 4.116463353211112
Validation loss: 3.155934631063599

Epoch: 5| Step: 3
Training loss: 3.5657067840317356
Validation loss: 3.153597929072723

Epoch: 5| Step: 4
Training loss: 3.2039926237766734
Validation loss: 3.1541585865703756

Epoch: 5| Step: 5
Training loss: 4.105685706535463
Validation loss: 3.1525133599169837

Epoch: 5| Step: 6
Training loss: 3.030298142573721
Validation loss: 3.149318837059073

Epoch: 5| Step: 7
Training loss: 3.58542657673848
Validation loss: 3.1491804277192066

Epoch: 5| Step: 8
Training loss: 3.3360611403554854
Validation loss: 3.1483732307689967

Epoch: 5| Step: 9
Training loss: 3.2516454785971742
Validation loss: 3.149981878703481

Epoch: 5| Step: 10
Training loss: 3.2038893369215713
Validation loss: 3.1486769299949207

Epoch: 61| Step: 0
Training loss: 3.3753252225935753
Validation loss: 3.1470494947331455

Epoch: 5| Step: 1
Training loss: 2.8326570227280685
Validation loss: 3.1457924367855075

Epoch: 5| Step: 2
Training loss: 3.218601556706726
Validation loss: 3.1468206620723853

Epoch: 5| Step: 3
Training loss: 3.7206013663086157
Validation loss: 3.15102592728068

Epoch: 5| Step: 4
Training loss: 3.686866835206674
Validation loss: 3.154364565409329

Epoch: 5| Step: 5
Training loss: 3.3541185995571206
Validation loss: 3.145519007546143

Epoch: 5| Step: 6
Training loss: 3.7271261048923496
Validation loss: 3.1444938712986628

Epoch: 5| Step: 7
Training loss: 3.4680969723318102
Validation loss: 3.145665140972518

Epoch: 5| Step: 8
Training loss: 3.657273630162746
Validation loss: 3.145683948925388

Epoch: 5| Step: 9
Training loss: 3.3503391549674646
Validation loss: 3.1445660732315313

Epoch: 5| Step: 10
Training loss: 2.7729013703858447
Validation loss: 3.1430635412797217

Epoch: 62| Step: 0
Training loss: 3.6191287670980863
Validation loss: 3.1440371366233926

Epoch: 5| Step: 1
Training loss: 3.378014242807359
Validation loss: 3.1452506626663275

Epoch: 5| Step: 2
Training loss: 3.8901922146101944
Validation loss: 3.145420865342593

Epoch: 5| Step: 3
Training loss: 3.3283073840962745
Validation loss: 3.1455072322082285

Epoch: 5| Step: 4
Training loss: 3.859635935004913
Validation loss: 3.145830944223087

Epoch: 5| Step: 5
Training loss: 3.220551662457704
Validation loss: 3.144541589231671

Epoch: 5| Step: 6
Training loss: 3.563643154976483
Validation loss: 3.1428208637201203

Epoch: 5| Step: 7
Training loss: 2.9908200318969045
Validation loss: 3.1442450969279085

Epoch: 5| Step: 8
Training loss: 2.6077649294455383
Validation loss: 3.149005234220109

Epoch: 5| Step: 9
Training loss: 3.36382307944976
Validation loss: 3.1615684176426386

Epoch: 5| Step: 10
Training loss: 3.386521347963122
Validation loss: 3.153386746680692

Epoch: 63| Step: 0
Training loss: 3.111802883289403
Validation loss: 3.144362447981436

Epoch: 5| Step: 1
Training loss: 3.3092880511366047
Validation loss: 3.1387891861262562

Epoch: 5| Step: 2
Training loss: 3.2408232610782557
Validation loss: 3.1394296280415284

Epoch: 5| Step: 3
Training loss: 3.308386209547404
Validation loss: 3.139696135991335

Epoch: 5| Step: 4
Training loss: 3.08283906703818
Validation loss: 3.141529469516171

Epoch: 5| Step: 5
Training loss: 3.694813216757523
Validation loss: 3.14117988505139

Epoch: 5| Step: 6
Training loss: 3.913938478496072
Validation loss: 3.140788874449782

Epoch: 5| Step: 7
Training loss: 2.6601849300950278
Validation loss: 3.1395134331890557

Epoch: 5| Step: 8
Training loss: 4.327058626317746
Validation loss: 3.1402963543797626

Epoch: 5| Step: 9
Training loss: 3.1756817003251103
Validation loss: 3.139487909475659

Epoch: 5| Step: 10
Training loss: 3.1803556672815945
Validation loss: 3.138742523405963

Epoch: 64| Step: 0
Training loss: 3.6388550741421883
Validation loss: 3.1366662314887206

Epoch: 5| Step: 1
Training loss: 3.470907279360678
Validation loss: 3.1377298602725086

Epoch: 5| Step: 2
Training loss: 3.2094913391005933
Validation loss: 3.1375362214878404

Epoch: 5| Step: 3
Training loss: 3.1069281837455844
Validation loss: 3.1374808077798595

Epoch: 5| Step: 4
Training loss: 3.9463871766911125
Validation loss: 3.1363577980533965

Epoch: 5| Step: 5
Training loss: 2.548075667936019
Validation loss: 3.135869996485426

Epoch: 5| Step: 6
Training loss: 3.650004473121724
Validation loss: 3.1367571694091256

Epoch: 5| Step: 7
Training loss: 3.0998496603658245
Validation loss: 3.1388133221381556

Epoch: 5| Step: 8
Training loss: 3.2439604174625
Validation loss: 3.141397035914444

Epoch: 5| Step: 9
Training loss: 2.997659087807329
Validation loss: 3.1431424691343306

Epoch: 5| Step: 10
Training loss: 4.26882266964362
Validation loss: 3.1579342424501076

Epoch: 65| Step: 0
Training loss: 2.829959337730924
Validation loss: 3.1395074150432523

Epoch: 5| Step: 1
Training loss: 3.6149650320891817
Validation loss: 3.134333498285812

Epoch: 5| Step: 2
Training loss: 3.9040143749019314
Validation loss: 3.134778106381439

Epoch: 5| Step: 3
Training loss: 3.3601836894550696
Validation loss: 3.132560327242627

Epoch: 5| Step: 4
Training loss: 3.3477153617064537
Validation loss: 3.1349988719050215

Epoch: 5| Step: 5
Training loss: 2.99848788618141
Validation loss: 3.135180413358403

Epoch: 5| Step: 6
Training loss: 3.576558265666863
Validation loss: 3.1366990595435165

Epoch: 5| Step: 7
Training loss: 3.125069884472492
Validation loss: 3.13341787170104

Epoch: 5| Step: 8
Training loss: 3.1862663424863324
Validation loss: 3.1308651166285753

Epoch: 5| Step: 9
Training loss: 3.1300654746328043
Validation loss: 3.1312780113605574

Epoch: 5| Step: 10
Training loss: 4.129397273753449
Validation loss: 3.1325850415561804

Epoch: 66| Step: 0
Training loss: 3.806462494629687
Validation loss: 3.131918014876754

Epoch: 5| Step: 1
Training loss: 3.763070280636773
Validation loss: 3.130359433003053

Epoch: 5| Step: 2
Training loss: 2.6474149187085385
Validation loss: 3.133745429924192

Epoch: 5| Step: 3
Training loss: 3.3955304219390343
Validation loss: 3.127747059647094

Epoch: 5| Step: 4
Training loss: 2.9307816967081948
Validation loss: 3.1365253414041976

Epoch: 5| Step: 5
Training loss: 3.7812156990954557
Validation loss: 3.1306874217732834

Epoch: 5| Step: 6
Training loss: 3.0537184326938718
Validation loss: 3.129118035881575

Epoch: 5| Step: 7
Training loss: 3.6710992521223265
Validation loss: 3.1305293086400523

Epoch: 5| Step: 8
Training loss: 3.7337906511952603
Validation loss: 3.1319228361497404

Epoch: 5| Step: 9
Training loss: 3.028656311979177
Validation loss: 3.1352789169979376

Epoch: 5| Step: 10
Training loss: 3.1438525871390097
Validation loss: 3.1313305187231775

Epoch: 67| Step: 0
Training loss: 3.5589525730695537
Validation loss: 3.1317694726486023

Epoch: 5| Step: 1
Training loss: 3.1948691062799752
Validation loss: 3.129628844016101

Epoch: 5| Step: 2
Training loss: 3.215791842893263
Validation loss: 3.1287280235459196

Epoch: 5| Step: 3
Training loss: 3.396358160796457
Validation loss: 3.1268924299034486

Epoch: 5| Step: 4
Training loss: 3.6815994381814234
Validation loss: 3.126913594737389

Epoch: 5| Step: 5
Training loss: 3.5303216574766982
Validation loss: 3.129400653632255

Epoch: 5| Step: 6
Training loss: 3.110912153906196
Validation loss: 3.1286175435785992

Epoch: 5| Step: 7
Training loss: 3.5826808128328462
Validation loss: 3.125579975411809

Epoch: 5| Step: 8
Training loss: 3.425291124208787
Validation loss: 3.127947667759224

Epoch: 5| Step: 9
Training loss: 2.7674911151526267
Validation loss: 3.1252368615737955

Epoch: 5| Step: 10
Training loss: 3.685222763098544
Validation loss: 3.1478989069032592

Epoch: 68| Step: 0
Training loss: 2.6950522476821885
Validation loss: 3.129450700493841

Epoch: 5| Step: 1
Training loss: 4.067616219480935
Validation loss: 3.123229040586279

Epoch: 5| Step: 2
Training loss: 3.7174671428693205
Validation loss: 3.126236580277121

Epoch: 5| Step: 3
Training loss: 3.286069981057944
Validation loss: 3.1258109469982367

Epoch: 5| Step: 4
Training loss: 3.745150291167255
Validation loss: 3.1249246091875174

Epoch: 5| Step: 5
Training loss: 3.559875324509245
Validation loss: 3.123047258350027

Epoch: 5| Step: 6
Training loss: 2.6949815629884024
Validation loss: 3.1248928765425217

Epoch: 5| Step: 7
Training loss: 3.421771740335194
Validation loss: 3.123997129906865

Epoch: 5| Step: 8
Training loss: 2.628380642136385
Validation loss: 3.128199031418857

Epoch: 5| Step: 9
Training loss: 3.642591477438664
Validation loss: 3.1277376156890524

Epoch: 5| Step: 10
Training loss: 3.4336752681147344
Validation loss: 3.1293715239783455

Epoch: 69| Step: 0
Training loss: 3.314783712612539
Validation loss: 3.123113348176353

Epoch: 5| Step: 1
Training loss: 3.65392509946596
Validation loss: 3.125772726033072

Epoch: 5| Step: 2
Training loss: 3.5605337505757837
Validation loss: 3.1236841142600116

Epoch: 5| Step: 3
Training loss: 3.6957893950994674
Validation loss: 3.1230557864394197

Epoch: 5| Step: 4
Training loss: 3.1884067218135854
Validation loss: 3.121876833182664

Epoch: 5| Step: 5
Training loss: 3.7871944895992313
Validation loss: 3.123298812834175

Epoch: 5| Step: 6
Training loss: 2.707989059476854
Validation loss: 3.1217045001418784

Epoch: 5| Step: 7
Training loss: 3.454163270096591
Validation loss: 3.120758385661036

Epoch: 5| Step: 8
Training loss: 3.242719124100954
Validation loss: 3.1209392571745207

Epoch: 5| Step: 9
Training loss: 3.0980764635573235
Validation loss: 3.11990678900679

Epoch: 5| Step: 10
Training loss: 3.3425410571889973
Validation loss: 3.12051095100122

Epoch: 70| Step: 0
Training loss: 3.2269895700452245
Validation loss: 3.122787704836369

Epoch: 5| Step: 1
Training loss: 4.016526176770983
Validation loss: 3.1219046687904903

Epoch: 5| Step: 2
Training loss: 3.8114324857438824
Validation loss: 3.1203835760416188

Epoch: 5| Step: 3
Training loss: 3.2542444536499295
Validation loss: 3.1218593295602424

Epoch: 5| Step: 4
Training loss: 2.9344386929718023
Validation loss: 3.119406449330565

Epoch: 5| Step: 5
Training loss: 3.4226051143891794
Validation loss: 3.1173628171457746

Epoch: 5| Step: 6
Training loss: 4.141927032166902
Validation loss: 3.121989324564812

Epoch: 5| Step: 7
Training loss: 2.044582101891365
Validation loss: 3.119015186459812

Epoch: 5| Step: 8
Training loss: 3.475650693499722
Validation loss: 3.1198038326970314

Epoch: 5| Step: 9
Training loss: 2.670088053333622
Validation loss: 3.1185203628653233

Epoch: 5| Step: 10
Training loss: 3.6382441123359586
Validation loss: 3.1148012563585157

Epoch: 71| Step: 0
Training loss: 3.229438885115387
Validation loss: 3.117568955022365

Epoch: 5| Step: 1
Training loss: 3.6274818606090715
Validation loss: 3.1166179460585988

Epoch: 5| Step: 2
Training loss: 3.7599667661293843
Validation loss: 3.1143213526070217

Epoch: 5| Step: 3
Training loss: 2.7685120594436485
Validation loss: 3.115239165310734

Epoch: 5| Step: 4
Training loss: 3.902065385545364
Validation loss: 3.115610281316996

Epoch: 5| Step: 5
Training loss: 3.719341199026106
Validation loss: 3.1158875882162973

Epoch: 5| Step: 6
Training loss: 3.0203733072016044
Validation loss: 3.1156548754931017

Epoch: 5| Step: 7
Training loss: 2.848654071151821
Validation loss: 3.113607654580306

Epoch: 5| Step: 8
Training loss: 2.745519803274662
Validation loss: 3.112402842689206

Epoch: 5| Step: 9
Training loss: 3.8629563737894816
Validation loss: 3.1142713861284093

Epoch: 5| Step: 10
Training loss: 3.3600563955115494
Validation loss: 3.1125723409879944

Epoch: 72| Step: 0
Training loss: 3.3999355478348634
Validation loss: 3.1120478601846404

Epoch: 5| Step: 1
Training loss: 2.594256891564035
Validation loss: 3.1149170937101673

Epoch: 5| Step: 2
Training loss: 3.3895664232641507
Validation loss: 3.1110633359581845

Epoch: 5| Step: 3
Training loss: 3.4998758838989925
Validation loss: 3.1159252969151217

Epoch: 5| Step: 4
Training loss: 3.238933060484624
Validation loss: 3.1090544821265333

Epoch: 5| Step: 5
Training loss: 3.3404698905941093
Validation loss: 3.1146511380949446

Epoch: 5| Step: 6
Training loss: 3.469852718998391
Validation loss: 3.113458871145924

Epoch: 5| Step: 7
Training loss: 3.9590800066305007
Validation loss: 3.1173514058521095

Epoch: 5| Step: 8
Training loss: 3.1938144744516386
Validation loss: 3.1156474585341902

Epoch: 5| Step: 9
Training loss: 3.3206812754765824
Validation loss: 3.1210355045680167

Epoch: 5| Step: 10
Training loss: 3.5412444068657156
Validation loss: 3.1230801154589445

Epoch: 73| Step: 0
Training loss: 3.1206668566588496
Validation loss: 3.120984740376714

Epoch: 5| Step: 1
Training loss: 2.7559387065842853
Validation loss: 3.1166633335701324

Epoch: 5| Step: 2
Training loss: 3.7119578675312503
Validation loss: 3.1162093579563277

Epoch: 5| Step: 3
Training loss: 3.44539360245033
Validation loss: 3.1154217174856496

Epoch: 5| Step: 4
Training loss: 3.052219340100814
Validation loss: 3.1130301773055216

Epoch: 5| Step: 5
Training loss: 3.094276768699509
Validation loss: 3.1131672490861146

Epoch: 5| Step: 6
Training loss: 3.964078060686472
Validation loss: 3.1137163634251994

Epoch: 5| Step: 7
Training loss: 3.2015962255441357
Validation loss: 3.111248469164908

Epoch: 5| Step: 8
Training loss: 3.1378135433295964
Validation loss: 3.108941213494809

Epoch: 5| Step: 9
Training loss: 3.856472143764283
Validation loss: 3.1132096762935917

Epoch: 5| Step: 10
Training loss: 3.571135645161435
Validation loss: 3.1115125874347873

Epoch: 74| Step: 0
Training loss: 3.381194328935688
Validation loss: 3.1097763972384094

Epoch: 5| Step: 1
Training loss: 3.7918720958240226
Validation loss: 3.1112475133352393

Epoch: 5| Step: 2
Training loss: 3.4200608831418444
Validation loss: 3.109295887774672

Epoch: 5| Step: 3
Training loss: 3.2001734090549627
Validation loss: 3.110574557789424

Epoch: 5| Step: 4
Training loss: 3.4045477297044093
Validation loss: 3.1123228535766696

Epoch: 5| Step: 5
Training loss: 3.487414620834446
Validation loss: 3.1114063319414154

Epoch: 5| Step: 6
Training loss: 3.278193621649049
Validation loss: 3.114565889416195

Epoch: 5| Step: 7
Training loss: 3.2669038595643918
Validation loss: 3.108806792138519

Epoch: 5| Step: 8
Training loss: 3.3321288475778292
Validation loss: 3.111978887673903

Epoch: 5| Step: 9
Training loss: 2.851346109619248
Validation loss: 3.115124616355494

Epoch: 5| Step: 10
Training loss: 3.571018942093424
Validation loss: 3.111550244517291

Epoch: 75| Step: 0
Training loss: 3.1966734881389605
Validation loss: 3.111756879491402

Epoch: 5| Step: 1
Training loss: 3.1694656015489198
Validation loss: 3.110335292185378

Epoch: 5| Step: 2
Training loss: 3.6489953997042788
Validation loss: 3.111808094923201

Epoch: 5| Step: 3
Training loss: 3.770655141311938
Validation loss: 3.1112001186472344

Epoch: 5| Step: 4
Training loss: 3.705937472413489
Validation loss: 3.1073063357593504

Epoch: 5| Step: 5
Training loss: 3.407723904122233
Validation loss: 3.1077052416240716

Epoch: 5| Step: 6
Training loss: 2.5997653745278617
Validation loss: 3.1050710924876093

Epoch: 5| Step: 7
Training loss: 3.11539708014564
Validation loss: 3.106202452270876

Epoch: 5| Step: 8
Training loss: 3.2305800431441307
Validation loss: 3.1066388179147526

Epoch: 5| Step: 9
Training loss: 3.505435673604607
Validation loss: 3.1029545466360267

Epoch: 5| Step: 10
Training loss: 3.534112765755595
Validation loss: 3.105858230339372

Epoch: 76| Step: 0
Training loss: 3.305253505708679
Validation loss: 3.1058565142886194

Epoch: 5| Step: 1
Training loss: 3.3477367271266765
Validation loss: 3.103631073248143

Epoch: 5| Step: 2
Training loss: 3.8454533966180793
Validation loss: 3.109878213222556

Epoch: 5| Step: 3
Training loss: 3.412963969789607
Validation loss: 3.114874013227011

Epoch: 5| Step: 4
Training loss: 2.6361123072848494
Validation loss: 3.1124371284031995

Epoch: 5| Step: 5
Training loss: 3.2930488259929485
Validation loss: 3.1077256041402084

Epoch: 5| Step: 6
Training loss: 3.844672239741963
Validation loss: 3.1075285101019556

Epoch: 5| Step: 7
Training loss: 3.137117771407718
Validation loss: 3.10528560693542

Epoch: 5| Step: 8
Training loss: 3.8991963903527034
Validation loss: 3.104016216888411

Epoch: 5| Step: 9
Training loss: 2.9057559341991026
Validation loss: 3.1006632768789264

Epoch: 5| Step: 10
Training loss: 3.0951339246526386
Validation loss: 3.1024915033787837

Epoch: 77| Step: 0
Training loss: 3.3345804424687255
Validation loss: 3.1005434450405103

Epoch: 5| Step: 1
Training loss: 4.0749709988363625
Validation loss: 3.100511112280821

Epoch: 5| Step: 2
Training loss: 3.4310582230691353
Validation loss: 3.098251882419119

Epoch: 5| Step: 3
Training loss: 3.631744424641961
Validation loss: 3.096513905896388

Epoch: 5| Step: 4
Training loss: 3.66936455799372
Validation loss: 3.100002817555555

Epoch: 5| Step: 5
Training loss: 3.340809750421772
Validation loss: 3.09880927121962

Epoch: 5| Step: 6
Training loss: 3.156821624056906
Validation loss: 3.101271079434946

Epoch: 5| Step: 7
Training loss: 3.2205298974601324
Validation loss: 3.096993815844771

Epoch: 5| Step: 8
Training loss: 2.7055072320133995
Validation loss: 3.097136545623352

Epoch: 5| Step: 9
Training loss: 3.268413320674976
Validation loss: 3.0960066259197245

Epoch: 5| Step: 10
Training loss: 2.85669503449013
Validation loss: 3.097706506828322

Epoch: 78| Step: 0
Training loss: 2.9234399531490243
Validation loss: 3.0969364085212683

Epoch: 5| Step: 1
Training loss: 3.5736783979353985
Validation loss: 3.097485490197348

Epoch: 5| Step: 2
Training loss: 3.489750568690726
Validation loss: 3.0950065489788208

Epoch: 5| Step: 3
Training loss: 3.091991965427792
Validation loss: 3.095965214985865

Epoch: 5| Step: 4
Training loss: 3.5639716337896856
Validation loss: 3.097306969580678

Epoch: 5| Step: 5
Training loss: 2.99122990755697
Validation loss: 3.09372983387092

Epoch: 5| Step: 6
Training loss: 3.012863871652094
Validation loss: 3.0970742521864763

Epoch: 5| Step: 7
Training loss: 3.227296168526714
Validation loss: 3.0968727451626394

Epoch: 5| Step: 8
Training loss: 3.4030877229524754
Validation loss: 3.093735104124442

Epoch: 5| Step: 9
Training loss: 3.75863594026739
Validation loss: 3.097725128445454

Epoch: 5| Step: 10
Training loss: 3.817355831399277
Validation loss: 3.0984143789086485

Epoch: 79| Step: 0
Training loss: 2.6778132609983856
Validation loss: 3.1011615929150897

Epoch: 5| Step: 1
Training loss: 3.2098459583529833
Validation loss: 3.1003868499419367

Epoch: 5| Step: 2
Training loss: 3.401440506001706
Validation loss: 3.097169185109336

Epoch: 5| Step: 3
Training loss: 3.1421423136280437
Validation loss: 3.097739757686793

Epoch: 5| Step: 4
Training loss: 3.707996624579843
Validation loss: 3.0928977570565044

Epoch: 5| Step: 5
Training loss: 3.6836085071450158
Validation loss: 3.0916794599339092

Epoch: 5| Step: 6
Training loss: 3.7091950833299037
Validation loss: 3.093842098273534

Epoch: 5| Step: 7
Training loss: 3.5783111657100224
Validation loss: 3.091932700829585

Epoch: 5| Step: 8
Training loss: 3.2884539768408336
Validation loss: 3.089332485270857

Epoch: 5| Step: 9
Training loss: 3.336143469426366
Validation loss: 3.0910088004513736

Epoch: 5| Step: 10
Training loss: 2.9554169656611853
Validation loss: 3.0921268275802594

Epoch: 80| Step: 0
Training loss: 3.5083960236832703
Validation loss: 3.092674863232697

Epoch: 5| Step: 1
Training loss: 3.569792528080936
Validation loss: 3.0912191339778836

Epoch: 5| Step: 2
Training loss: 3.0689751816308823
Validation loss: 3.0926366190392724

Epoch: 5| Step: 3
Training loss: 3.6558464675318407
Validation loss: 3.09322064526851

Epoch: 5| Step: 4
Training loss: 3.6971781821573217
Validation loss: 3.0930410405398616

Epoch: 5| Step: 5
Training loss: 3.6271835853763905
Validation loss: 3.0946770351488566

Epoch: 5| Step: 6
Training loss: 2.6812115219663113
Validation loss: 3.0911495474351693

Epoch: 5| Step: 7
Training loss: 2.9160010713698274
Validation loss: 3.0884077215368353

Epoch: 5| Step: 8
Training loss: 3.4362658973012503
Validation loss: 3.092482486896471

Epoch: 5| Step: 9
Training loss: 3.114026448318189
Validation loss: 3.090102469222742

Epoch: 5| Step: 10
Training loss: 3.462596624795814
Validation loss: 3.0903169392968786

Epoch: 81| Step: 0
Training loss: 3.572622941439757
Validation loss: 3.095123682112792

Epoch: 5| Step: 1
Training loss: 3.1691857574420186
Validation loss: 3.0977296992114827

Epoch: 5| Step: 2
Training loss: 3.4433716997173787
Validation loss: 3.100014400217177

Epoch: 5| Step: 3
Training loss: 3.3283354643418686
Validation loss: 3.0999735770553274

Epoch: 5| Step: 4
Training loss: 3.287941929807925
Validation loss: 3.0882312504049154

Epoch: 5| Step: 5
Training loss: 3.6236172373658024
Validation loss: 3.0879208367003748

Epoch: 5| Step: 6
Training loss: 2.566183838286401
Validation loss: 3.088828678709415

Epoch: 5| Step: 7
Training loss: 3.420269593884177
Validation loss: 3.0925651776588583

Epoch: 5| Step: 8
Training loss: 3.2891573133416983
Validation loss: 3.0897563781287194

Epoch: 5| Step: 9
Training loss: 3.4074613884398595
Validation loss: 3.088970218023868

Epoch: 5| Step: 10
Training loss: 3.7056042061935033
Validation loss: 3.0882615334842147

Epoch: 82| Step: 0
Training loss: 3.2795969841085397
Validation loss: 3.0899285258335296

Epoch: 5| Step: 1
Training loss: 3.132401056454777
Validation loss: 3.0878990417985523

Epoch: 5| Step: 2
Training loss: 3.511806194162959
Validation loss: 3.0910783719165025

Epoch: 5| Step: 3
Training loss: 3.410591228835904
Validation loss: 3.092019697798507

Epoch: 5| Step: 4
Training loss: 3.723556233640825
Validation loss: 3.0936671329096828

Epoch: 5| Step: 5
Training loss: 3.004563675112847
Validation loss: 3.092984178178025

Epoch: 5| Step: 6
Training loss: 2.982758089011899
Validation loss: 3.0958876795755925

Epoch: 5| Step: 7
Training loss: 3.2360418327749163
Validation loss: 3.094875493503449

Epoch: 5| Step: 8
Training loss: 3.712173930532801
Validation loss: 3.091239839789606

Epoch: 5| Step: 9
Training loss: 3.746578181252502
Validation loss: 3.0922762452570995

Epoch: 5| Step: 10
Training loss: 2.9297599274901436
Validation loss: 3.0926518708498

Epoch: 83| Step: 0
Training loss: 3.0029511241612914
Validation loss: 3.0884121060422003

Epoch: 5| Step: 1
Training loss: 4.223356769339176
Validation loss: 3.088990786203507

Epoch: 5| Step: 2
Training loss: 3.2519221857105536
Validation loss: 3.090569945104585

Epoch: 5| Step: 3
Training loss: 3.1550529400574927
Validation loss: 3.091723213533316

Epoch: 5| Step: 4
Training loss: 3.6470688533826006
Validation loss: 3.08926990169287

Epoch: 5| Step: 5
Training loss: 3.103050048168806
Validation loss: 3.088078241602263

Epoch: 5| Step: 6
Training loss: 3.6027786286907877
Validation loss: 3.088093704374639

Epoch: 5| Step: 7
Training loss: 3.1407748513981852
Validation loss: 3.086435397714261

Epoch: 5| Step: 8
Training loss: 3.455673727104908
Validation loss: 3.088350617808016

Epoch: 5| Step: 9
Training loss: 3.094016477880017
Validation loss: 3.0873820726367778

Epoch: 5| Step: 10
Training loss: 2.852746837744925
Validation loss: 3.0867326124638925

Epoch: 84| Step: 0
Training loss: 3.447297577534282
Validation loss: 3.088077723573973

Epoch: 5| Step: 1
Training loss: 2.2821931326445495
Validation loss: 3.086975011306819

Epoch: 5| Step: 2
Training loss: 3.002293187116923
Validation loss: 3.087717684516209

Epoch: 5| Step: 3
Training loss: 3.0062403942438465
Validation loss: 3.088023511100952

Epoch: 5| Step: 4
Training loss: 3.8657296563601045
Validation loss: 3.087175723606443

Epoch: 5| Step: 5
Training loss: 2.6361861079483266
Validation loss: 3.10478811133581

Epoch: 5| Step: 6
Training loss: 3.19496193900444
Validation loss: 3.102479426736263

Epoch: 5| Step: 7
Training loss: 3.294802479822194
Validation loss: 3.0918932684063734

Epoch: 5| Step: 8
Training loss: 3.976692602281392
Validation loss: 3.090395234147061

Epoch: 5| Step: 9
Training loss: 4.2000912066047835
Validation loss: 3.085785106895654

Epoch: 5| Step: 10
Training loss: 3.379091255547543
Validation loss: 3.086879192663932

Epoch: 85| Step: 0
Training loss: 3.526100793039436
Validation loss: 3.0883882011984793

Epoch: 5| Step: 1
Training loss: 3.022754049801813
Validation loss: 3.086256002841133

Epoch: 5| Step: 2
Training loss: 2.94513521748659
Validation loss: 3.0877499835268636

Epoch: 5| Step: 3
Training loss: 3.108646940172689
Validation loss: 3.084942143267464

Epoch: 5| Step: 4
Training loss: 2.8371221416805383
Validation loss: 3.0850041382054956

Epoch: 5| Step: 5
Training loss: 2.657258414540582
Validation loss: 3.0856522872379495

Epoch: 5| Step: 6
Training loss: 3.49195564063563
Validation loss: 3.0821222262003656

Epoch: 5| Step: 7
Training loss: 3.305883889939604
Validation loss: 3.0833199896242394

Epoch: 5| Step: 8
Training loss: 4.046147461523802
Validation loss: 3.0838198187944226

Epoch: 5| Step: 9
Training loss: 2.975882224695525
Validation loss: 3.0850871823129355

Epoch: 5| Step: 10
Training loss: 4.562057264611625
Validation loss: 3.085233421063614

Epoch: 86| Step: 0
Training loss: 2.820264060325664
Validation loss: 3.0830638543800184

Epoch: 5| Step: 1
Training loss: 3.8033986503303807
Validation loss: 3.0871794089911986

Epoch: 5| Step: 2
Training loss: 2.7289284657978214
Validation loss: 3.082685553581729

Epoch: 5| Step: 3
Training loss: 3.4725551869433535
Validation loss: 3.0796262083765216

Epoch: 5| Step: 4
Training loss: 2.647792681400717
Validation loss: 3.0785898944740975

Epoch: 5| Step: 5
Training loss: 3.434470905495605
Validation loss: 3.0800903535643154

Epoch: 5| Step: 6
Training loss: 3.4495564659397218
Validation loss: 3.078188426470588

Epoch: 5| Step: 7
Training loss: 3.235751536361517
Validation loss: 3.079323928597881

Epoch: 5| Step: 8
Training loss: 3.353593544340836
Validation loss: 3.0769734851984984

Epoch: 5| Step: 9
Training loss: 3.904499241449158
Validation loss: 3.0775566686186373

Epoch: 5| Step: 10
Training loss: 3.6892113028296807
Validation loss: 3.0759860975008215

Epoch: 87| Step: 0
Training loss: 3.1659187805688718
Validation loss: 3.075089248547916

Epoch: 5| Step: 1
Training loss: 2.9621135218139902
Validation loss: 3.073781531701137

Epoch: 5| Step: 2
Training loss: 3.545573798310386
Validation loss: 3.0751076928305823

Epoch: 5| Step: 3
Training loss: 3.4480109686887244
Validation loss: 3.0791603064224016

Epoch: 5| Step: 4
Training loss: 3.4812575280263927
Validation loss: 3.0740490317057363

Epoch: 5| Step: 5
Training loss: 2.458858907951293
Validation loss: 3.0766596975434144

Epoch: 5| Step: 6
Training loss: 3.489582908212816
Validation loss: 3.0761848799714966

Epoch: 5| Step: 7
Training loss: 3.7973130212876347
Validation loss: 3.074502605285176

Epoch: 5| Step: 8
Training loss: 3.193072067541794
Validation loss: 3.0768867351945115

Epoch: 5| Step: 9
Training loss: 3.3414917923094305
Validation loss: 3.072326365413499

Epoch: 5| Step: 10
Training loss: 3.641626048498062
Validation loss: 3.071446334834651

Epoch: 88| Step: 0
Training loss: 3.443434984369118
Validation loss: 3.0707035182575564

Epoch: 5| Step: 1
Training loss: 3.4355689433540078
Validation loss: 3.0690411845507475

Epoch: 5| Step: 2
Training loss: 3.0071935239729752
Validation loss: 3.068150106380595

Epoch: 5| Step: 3
Training loss: 3.7090366996621804
Validation loss: 3.0663529360528106

Epoch: 5| Step: 4
Training loss: 3.5031835518809094
Validation loss: 3.0663629569953077

Epoch: 5| Step: 5
Training loss: 3.6329093674081325
Validation loss: 3.065592421016883

Epoch: 5| Step: 6
Training loss: 3.702007785098537
Validation loss: 3.0668651752862957

Epoch: 5| Step: 7
Training loss: 3.1731985553468403
Validation loss: 3.0640824753750957

Epoch: 5| Step: 8
Training loss: 2.830315347631959
Validation loss: 3.063528722311648

Epoch: 5| Step: 9
Training loss: 2.8461220039600867
Validation loss: 3.0608586778130817

Epoch: 5| Step: 10
Training loss: 3.1077660466515518
Validation loss: 3.065740144102229

Epoch: 89| Step: 0
Training loss: 3.2385297985888064
Validation loss: 3.067885213971034

Epoch: 5| Step: 1
Training loss: 3.5894502874519474
Validation loss: 3.0689806004828237

Epoch: 5| Step: 2
Training loss: 2.4534679586161907
Validation loss: 3.0686467155109405

Epoch: 5| Step: 3
Training loss: 3.3137655179967336
Validation loss: 3.068111648397997

Epoch: 5| Step: 4
Training loss: 2.5168329975496846
Validation loss: 3.0679373055135875

Epoch: 5| Step: 5
Training loss: 3.277283660010434
Validation loss: 3.064307099269095

Epoch: 5| Step: 6
Training loss: 4.043077963123338
Validation loss: 3.066749865240195

Epoch: 5| Step: 7
Training loss: 3.476798814607112
Validation loss: 3.0667558673344515

Epoch: 5| Step: 8
Training loss: 3.2210988483485754
Validation loss: 3.0634494403859227

Epoch: 5| Step: 9
Training loss: 3.823186187528894
Validation loss: 3.0567253119146067

Epoch: 5| Step: 10
Training loss: 3.2506127880169964
Validation loss: 3.0630149902197847

Epoch: 90| Step: 0
Training loss: 3.0201205410174263
Validation loss: 3.0584676655771847

Epoch: 5| Step: 1
Training loss: 3.166879563118459
Validation loss: 3.057920995987381

Epoch: 5| Step: 2
Training loss: 3.8145550051598596
Validation loss: 3.05713285049845

Epoch: 5| Step: 3
Training loss: 3.331746597921461
Validation loss: 3.0578285871267608

Epoch: 5| Step: 4
Training loss: 3.3878110116449176
Validation loss: 3.0564479735324617

Epoch: 5| Step: 5
Training loss: 3.262824797265984
Validation loss: 3.054379351165876

Epoch: 5| Step: 6
Training loss: 3.360054124895759
Validation loss: 3.054632270262718

Epoch: 5| Step: 7
Training loss: 3.2284426626094564
Validation loss: 3.054614644004889

Epoch: 5| Step: 8
Training loss: 3.266585797327428
Validation loss: 3.0541316523474955

Epoch: 5| Step: 9
Training loss: 3.4783952661132886
Validation loss: 3.0498071437080814

Epoch: 5| Step: 10
Training loss: 3.0953850327013255
Validation loss: 3.054379312556569

Epoch: 91| Step: 0
Training loss: 3.414259147654693
Validation loss: 3.051893218602207

Epoch: 5| Step: 1
Training loss: 3.4097897397098786
Validation loss: 3.0502456628304073

Epoch: 5| Step: 2
Training loss: 3.5201819153941836
Validation loss: 3.050868684320551

Epoch: 5| Step: 3
Training loss: 2.9711042204879763
Validation loss: 3.0518821177640763

Epoch: 5| Step: 4
Training loss: 3.354422249543856
Validation loss: 3.0486886616516116

Epoch: 5| Step: 5
Training loss: 3.168617266822542
Validation loss: 3.0487204373946395

Epoch: 5| Step: 6
Training loss: 3.0411390256252924
Validation loss: 3.0478503008041233

Epoch: 5| Step: 7
Training loss: 3.4845921743821235
Validation loss: 3.0462480521074777

Epoch: 5| Step: 8
Training loss: 3.475043284194654
Validation loss: 3.0486588095747895

Epoch: 5| Step: 9
Training loss: 3.058930788921373
Validation loss: 3.050024074053958

Epoch: 5| Step: 10
Training loss: 3.51899510236325
Validation loss: 3.046418763808343

Epoch: 92| Step: 0
Training loss: 3.225890452152638
Validation loss: 3.0474726307225692

Epoch: 5| Step: 1
Training loss: 3.1197899684147785
Validation loss: 3.0447297492424723

Epoch: 5| Step: 2
Training loss: 3.5769367493840645
Validation loss: 3.0469982609244526

Epoch: 5| Step: 3
Training loss: 3.3955168001211224
Validation loss: 3.0460490295407845

Epoch: 5| Step: 4
Training loss: 3.4509984713882336
Validation loss: 3.0487691321447885

Epoch: 5| Step: 5
Training loss: 2.8678943895609708
Validation loss: 3.045266399128149

Epoch: 5| Step: 6
Training loss: 3.455325293015724
Validation loss: 3.0461358548723134

Epoch: 5| Step: 7
Training loss: 3.544639790558698
Validation loss: 3.045545853409936

Epoch: 5| Step: 8
Training loss: 3.730115560219325
Validation loss: 3.0463478862969318

Epoch: 5| Step: 9
Training loss: 3.014862912985305
Validation loss: 3.0456460001753967

Epoch: 5| Step: 10
Training loss: 2.843114593278846
Validation loss: 3.041961942717361

Epoch: 93| Step: 0
Training loss: 2.5822794415511683
Validation loss: 3.0429385823228197

Epoch: 5| Step: 1
Training loss: 3.6649854591570374
Validation loss: 3.044191805543272

Epoch: 5| Step: 2
Training loss: 3.5315824369065765
Validation loss: 3.045451175013118

Epoch: 5| Step: 3
Training loss: 3.2341327668670536
Validation loss: 3.043668412478308

Epoch: 5| Step: 4
Training loss: 3.4832468986434453
Validation loss: 3.0436161051985535

Epoch: 5| Step: 5
Training loss: 2.9921178585543684
Validation loss: 3.0408736029605214

Epoch: 5| Step: 6
Training loss: 3.5785756722700564
Validation loss: 3.0437096463317337

Epoch: 5| Step: 7
Training loss: 3.6871055780022033
Validation loss: 3.0420990750473202

Epoch: 5| Step: 8
Training loss: 2.40104349816198
Validation loss: 3.0405255701696174

Epoch: 5| Step: 9
Training loss: 3.473720254513338
Validation loss: 3.0377593240654677

Epoch: 5| Step: 10
Training loss: 3.486006966124866
Validation loss: 3.0397611715907193

Epoch: 94| Step: 0
Training loss: 2.340730476803996
Validation loss: 3.043671900384463

Epoch: 5| Step: 1
Training loss: 3.799336706797792
Validation loss: 3.0448097846615356

Epoch: 5| Step: 2
Training loss: 2.7997374990575725
Validation loss: 3.0482546492767595

Epoch: 5| Step: 3
Training loss: 3.5637980990607674
Validation loss: 3.052556798129917

Epoch: 5| Step: 4
Training loss: 2.5415687750637215
Validation loss: 3.0492756555514244

Epoch: 5| Step: 5
Training loss: 3.3983850233915396
Validation loss: 3.0423389090331763

Epoch: 5| Step: 6
Training loss: 3.4009997300526735
Validation loss: 3.0413913970288133

Epoch: 5| Step: 7
Training loss: 3.6553745362805548
Validation loss: 3.04129217227371

Epoch: 5| Step: 8
Training loss: 3.046134976237434
Validation loss: 3.0406422355753637

Epoch: 5| Step: 9
Training loss: 3.5182862106581694
Validation loss: 3.0457339421684595

Epoch: 5| Step: 10
Training loss: 3.96650860789423
Validation loss: 3.0484582481755274

Epoch: 95| Step: 0
Training loss: 3.2003072114343327
Validation loss: 3.052616801151782

Epoch: 5| Step: 1
Training loss: 3.457337722555842
Validation loss: 3.0407533278747585

Epoch: 5| Step: 2
Training loss: 2.7242674691668567
Validation loss: 3.0383192849632805

Epoch: 5| Step: 3
Training loss: 2.786206404566111
Validation loss: 3.0404912391493197

Epoch: 5| Step: 4
Training loss: 3.955781428594789
Validation loss: 3.042371712554167

Epoch: 5| Step: 5
Training loss: 3.490237790507912
Validation loss: 3.044714044351598

Epoch: 5| Step: 6
Training loss: 3.779319333347354
Validation loss: 3.0406564261744236

Epoch: 5| Step: 7
Training loss: 3.2107906261553905
Validation loss: 3.035898634091533

Epoch: 5| Step: 8
Training loss: 2.7501312571325607
Validation loss: 3.0340088220194246

Epoch: 5| Step: 9
Training loss: 3.305938556042463
Validation loss: 3.036486128241863

Epoch: 5| Step: 10
Training loss: 3.4361891588005737
Validation loss: 3.0351993394451213

Epoch: 96| Step: 0
Training loss: 3.634246871146011
Validation loss: 3.0355131319277797

Epoch: 5| Step: 1
Training loss: 3.2852500149185695
Validation loss: 3.0362679114987667

Epoch: 5| Step: 2
Training loss: 3.503100248278274
Validation loss: 3.034386914075879

Epoch: 5| Step: 3
Training loss: 3.093809955671014
Validation loss: 3.036022205545518

Epoch: 5| Step: 4
Training loss: 3.411087520723507
Validation loss: 3.0340622564858473

Epoch: 5| Step: 5
Training loss: 3.3456891577897307
Validation loss: 3.0338388155917144

Epoch: 5| Step: 6
Training loss: 3.6298780833806967
Validation loss: 3.0375822229573526

Epoch: 5| Step: 7
Training loss: 2.4818915664323606
Validation loss: 3.0331567641448225

Epoch: 5| Step: 8
Training loss: 2.936447604347991
Validation loss: 3.03409315795719

Epoch: 5| Step: 9
Training loss: 3.2260991611269976
Validation loss: 3.0358248069983285

Epoch: 5| Step: 10
Training loss: 3.6332368336266203
Validation loss: 3.0365317223277977

Epoch: 97| Step: 0
Training loss: 3.281231689402035
Validation loss: 3.0349618563340055

Epoch: 5| Step: 1
Training loss: 3.627091823672386
Validation loss: 3.031798426131808

Epoch: 5| Step: 2
Training loss: 2.0086132783062873
Validation loss: 3.0326778565936103

Epoch: 5| Step: 3
Training loss: 3.6781624713502548
Validation loss: 3.0323560697138157

Epoch: 5| Step: 4
Training loss: 3.3509629075590963
Validation loss: 3.031040116302381

Epoch: 5| Step: 5
Training loss: 3.022596769716365
Validation loss: 3.0304431084496173

Epoch: 5| Step: 6
Training loss: 3.508486948403009
Validation loss: 3.0320305842042883

Epoch: 5| Step: 7
Training loss: 2.8448698752198833
Validation loss: 3.0324522424587412

Epoch: 5| Step: 8
Training loss: 3.9327470461006366
Validation loss: 3.031201143064501

Epoch: 5| Step: 9
Training loss: 3.2293077663645415
Validation loss: 3.0280782032417286

Epoch: 5| Step: 10
Training loss: 3.3785486285639412
Validation loss: 3.0295533926459783

Epoch: 98| Step: 0
Training loss: 3.0360764295484346
Validation loss: 3.0286100779050917

Epoch: 5| Step: 1
Training loss: 3.6039483035462356
Validation loss: 3.0267154075661034

Epoch: 5| Step: 2
Training loss: 2.9568546701013387
Validation loss: 3.0289221484416022

Epoch: 5| Step: 3
Training loss: 2.665975024015476
Validation loss: 3.029221451680833

Epoch: 5| Step: 4
Training loss: 3.348971132023601
Validation loss: 3.026513234465555

Epoch: 5| Step: 5
Training loss: 2.9338258532099157
Validation loss: 3.027897394730208

Epoch: 5| Step: 6
Training loss: 3.2517559003162737
Validation loss: 3.028836946532155

Epoch: 5| Step: 7
Training loss: 3.8239247225610336
Validation loss: 3.0297982812154793

Epoch: 5| Step: 8
Training loss: 3.2164158922652715
Validation loss: 3.0304374980224207

Epoch: 5| Step: 9
Training loss: 3.2280770873422044
Validation loss: 3.0267944286375816

Epoch: 5| Step: 10
Training loss: 4.054821563444802
Validation loss: 3.0231514754334246

Epoch: 99| Step: 0
Training loss: 3.3978223221944854
Validation loss: 3.026024590036124

Epoch: 5| Step: 1
Training loss: 3.173569100007046
Validation loss: 3.025108124073442

Epoch: 5| Step: 2
Training loss: 3.5621194468909176
Validation loss: 3.028602127807908

Epoch: 5| Step: 3
Training loss: 3.4488490631266386
Validation loss: 3.026818260078498

Epoch: 5| Step: 4
Training loss: 3.3150831982513087
Validation loss: 3.02697896770216

Epoch: 5| Step: 5
Training loss: 2.8811640794897286
Validation loss: 3.024188081086935

Epoch: 5| Step: 6
Training loss: 3.005405483467439
Validation loss: 3.0253071929935498

Epoch: 5| Step: 7
Training loss: 3.1391242697654187
Validation loss: 3.027971553111625

Epoch: 5| Step: 8
Training loss: 3.615626086710484
Validation loss: 3.0300700144146346

Epoch: 5| Step: 9
Training loss: 3.3029714326700104
Validation loss: 3.030467482217514

Epoch: 5| Step: 10
Training loss: 3.2771937412127237
Validation loss: 3.030537878432805

Epoch: 100| Step: 0
Training loss: 2.9382605684055116
Validation loss: 3.0234757563246037

Epoch: 5| Step: 1
Training loss: 3.390776881318899
Validation loss: 3.027536388014704

Epoch: 5| Step: 2
Training loss: 3.180392550345317
Validation loss: 3.0366179991823055

Epoch: 5| Step: 3
Training loss: 2.4883523448806337
Validation loss: 3.029497303586117

Epoch: 5| Step: 4
Training loss: 3.8404127070058287
Validation loss: 3.0258376789276733

Epoch: 5| Step: 5
Training loss: 2.935465168783495
Validation loss: 3.022695634523668

Epoch: 5| Step: 6
Training loss: 3.7006175891845183
Validation loss: 3.02105153830012

Epoch: 5| Step: 7
Training loss: 3.6065442102436363
Validation loss: 3.021399832207465

Epoch: 5| Step: 8
Training loss: 3.9174558507285346
Validation loss: 3.0226126081835663

Epoch: 5| Step: 9
Training loss: 2.923671557681756
Validation loss: 3.021382753665261

Epoch: 5| Step: 10
Training loss: 2.8442407540895904
Validation loss: 3.0247752376059

Epoch: 101| Step: 0
Training loss: 3.259104081595562
Validation loss: 3.022318304812379

Epoch: 5| Step: 1
Training loss: 3.6411970614125053
Validation loss: 3.0210883610350945

Epoch: 5| Step: 2
Training loss: 3.0610899501222204
Validation loss: 3.021381065151522

Epoch: 5| Step: 3
Training loss: 3.6666443275002347
Validation loss: 3.0202437470790384

Epoch: 5| Step: 4
Training loss: 2.8574937979563293
Validation loss: 3.0198252086613633

Epoch: 5| Step: 5
Training loss: 2.7896284282554036
Validation loss: 3.022541567675383

Epoch: 5| Step: 6
Training loss: 2.6434241813290775
Validation loss: 3.019132024870776

Epoch: 5| Step: 7
Training loss: 4.073481579927279
Validation loss: 3.0209905731273725

Epoch: 5| Step: 8
Training loss: 3.2716307103465714
Validation loss: 3.026127348271678

Epoch: 5| Step: 9
Training loss: 3.190099815313784
Validation loss: 3.0214992707129906

Epoch: 5| Step: 10
Training loss: 3.4960675627510853
Validation loss: 3.017261749332985

Epoch: 102| Step: 0
Training loss: 2.8733990399606317
Validation loss: 3.017794174540018

Epoch: 5| Step: 1
Training loss: 2.9772842613489185
Validation loss: 3.0185272874499343

Epoch: 5| Step: 2
Training loss: 3.1840086122520943
Validation loss: 3.0174380991974887

Epoch: 5| Step: 3
Training loss: 3.1117296360906743
Validation loss: 3.0184528919426463

Epoch: 5| Step: 4
Training loss: 3.297674145499743
Validation loss: 3.01887164269858

Epoch: 5| Step: 5
Training loss: 3.118031475953086
Validation loss: 3.0190331860241173

Epoch: 5| Step: 6
Training loss: 3.7315415362740474
Validation loss: 3.017586015785956

Epoch: 5| Step: 7
Training loss: 3.415682131332224
Validation loss: 3.0175796678167925

Epoch: 5| Step: 8
Training loss: 3.4182908609381304
Validation loss: 3.018839299706948

Epoch: 5| Step: 9
Training loss: 3.653607709726076
Validation loss: 3.0142950557375396

Epoch: 5| Step: 10
Training loss: 3.2826484243359677
Validation loss: 3.015458662795111

Epoch: 103| Step: 0
Training loss: 3.548895306704499
Validation loss: 3.014517757936981

Epoch: 5| Step: 1
Training loss: 2.3415368375615437
Validation loss: 3.0150224008253326

Epoch: 5| Step: 2
Training loss: 2.6586603336252423
Validation loss: 3.014208305775946

Epoch: 5| Step: 3
Training loss: 3.125716470601555
Validation loss: 3.020271631507184

Epoch: 5| Step: 4
Training loss: 3.526642620915703
Validation loss: 3.0177145231834075

Epoch: 5| Step: 5
Training loss: 3.6193157221623946
Validation loss: 3.015865201807849

Epoch: 5| Step: 6
Training loss: 3.963031884726686
Validation loss: 3.0190942756370047

Epoch: 5| Step: 7
Training loss: 3.334163149223452
Validation loss: 3.013171765368894

Epoch: 5| Step: 8
Training loss: 3.038876407682121
Validation loss: 3.0155922532316004

Epoch: 5| Step: 9
Training loss: 3.3577754981202013
Validation loss: 3.0144093557461957

Epoch: 5| Step: 10
Training loss: 3.325865789140549
Validation loss: 3.0146406444741674

Epoch: 104| Step: 0
Training loss: 3.2881184217470225
Validation loss: 3.013398069277482

Epoch: 5| Step: 1
Training loss: 3.233491786207246
Validation loss: 3.0132353134976015

Epoch: 5| Step: 2
Training loss: 3.9232886452886038
Validation loss: 3.0140120523950777

Epoch: 5| Step: 3
Training loss: 2.863047091913211
Validation loss: 3.0124486106383896

Epoch: 5| Step: 4
Training loss: 3.119993853929775
Validation loss: 3.012793116928907

Epoch: 5| Step: 5
Training loss: 3.4961016606928657
Validation loss: 3.014451175224461

Epoch: 5| Step: 6
Training loss: 3.434950837029202
Validation loss: 3.012573583935871

Epoch: 5| Step: 7
Training loss: 3.564858040999393
Validation loss: 3.0117797181438415

Epoch: 5| Step: 8
Training loss: 3.3741346592106143
Validation loss: 3.008296378412651

Epoch: 5| Step: 9
Training loss: 2.918558615182979
Validation loss: 3.010555761591049

Epoch: 5| Step: 10
Training loss: 2.6024786908159543
Validation loss: 3.0126321920778705

Epoch: 105| Step: 0
Training loss: 3.2370158301088057
Validation loss: 3.0114959497764464

Epoch: 5| Step: 1
Training loss: 3.9351518683591844
Validation loss: 3.012157357759418

Epoch: 5| Step: 2
Training loss: 3.4876981890843264
Validation loss: 3.0120981514070655

Epoch: 5| Step: 3
Training loss: 3.2643180312536155
Validation loss: 3.0146175731217952

Epoch: 5| Step: 4
Training loss: 2.983798785280274
Validation loss: 3.0127318076454506

Epoch: 5| Step: 5
Training loss: 3.3023181113806164
Validation loss: 3.0207928720946287

Epoch: 5| Step: 6
Training loss: 3.652468298762073
Validation loss: 3.0299436009866594

Epoch: 5| Step: 7
Training loss: 3.053244950154994
Validation loss: 3.0072969751026917

Epoch: 5| Step: 8
Training loss: 3.060816710943058
Validation loss: 3.009844489737721

Epoch: 5| Step: 9
Training loss: 2.630812703308412
Validation loss: 3.009105828879419

Epoch: 5| Step: 10
Training loss: 3.3076425601514288
Validation loss: 3.008346560065113

Epoch: 106| Step: 0
Training loss: 2.697747145424221
Validation loss: 3.008789038642582

Epoch: 5| Step: 1
Training loss: 2.6490258207636
Validation loss: 3.007921321473414

Epoch: 5| Step: 2
Training loss: 3.6226525433990093
Validation loss: 3.0111870929317077

Epoch: 5| Step: 3
Training loss: 3.5190109562704635
Validation loss: 3.0110764891527735

Epoch: 5| Step: 4
Training loss: 3.5223835047456706
Validation loss: 3.0124911449467153

Epoch: 5| Step: 5
Training loss: 2.780887623013968
Validation loss: 3.0098475764848707

Epoch: 5| Step: 6
Training loss: 2.4999299993251567
Validation loss: 3.009096674545176

Epoch: 5| Step: 7
Training loss: 3.6397579617777756
Validation loss: 3.0103313968909062

Epoch: 5| Step: 8
Training loss: 3.7222799008836587
Validation loss: 3.004538782326468

Epoch: 5| Step: 9
Training loss: 3.878222448460275
Validation loss: 3.0056232362116546

Epoch: 5| Step: 10
Training loss: 3.1578828723584205
Validation loss: 3.009050061555297

Epoch: 107| Step: 0
Training loss: 3.294467716088387
Validation loss: 3.0082358032725174

Epoch: 5| Step: 1
Training loss: 3.5774204943210797
Validation loss: 3.0117816580384136

Epoch: 5| Step: 2
Training loss: 3.102841668385189
Validation loss: 3.0236981138538344

Epoch: 5| Step: 3
Training loss: 3.171097683675036
Validation loss: 3.022377434798866

Epoch: 5| Step: 4
Training loss: 3.6032013381322
Validation loss: 3.0214798170125436

Epoch: 5| Step: 5
Training loss: 3.6187471854243425
Validation loss: 3.020051368831196

Epoch: 5| Step: 6
Training loss: 3.727419836562617
Validation loss: 3.0153086863703935

Epoch: 5| Step: 7
Training loss: 2.657290086754469
Validation loss: 3.0045260483074747

Epoch: 5| Step: 8
Training loss: 2.783279878327639
Validation loss: 3.0020863275445486

Epoch: 5| Step: 9
Training loss: 3.5136926384270475
Validation loss: 3.0047504847379223

Epoch: 5| Step: 10
Training loss: 2.699217425068642
Validation loss: 3.0045646461099325

Epoch: 108| Step: 0
Training loss: 3.128737084319782
Validation loss: 3.004238086703876

Epoch: 5| Step: 1
Training loss: 3.3900143121737942
Validation loss: 3.004609297984877

Epoch: 5| Step: 2
Training loss: 3.1321034378178556
Validation loss: 3.002738386480802

Epoch: 5| Step: 3
Training loss: 3.403625457087814
Validation loss: 3.0042932871430885

Epoch: 5| Step: 4
Training loss: 3.8059007406115697
Validation loss: 3.002583898388691

Epoch: 5| Step: 5
Training loss: 3.1378109599272004
Validation loss: 3.00414666685227

Epoch: 5| Step: 6
Training loss: 2.916140881331097
Validation loss: 3.0019747616353385

Epoch: 5| Step: 7
Training loss: 3.455499997430006
Validation loss: 3.0022866104168573

Epoch: 5| Step: 8
Training loss: 2.5988752903536545
Validation loss: 3.0010880271310136

Epoch: 5| Step: 9
Training loss: 3.5768846252621183
Validation loss: 3.0019046486694405

Epoch: 5| Step: 10
Training loss: 3.3101962733780805
Validation loss: 3.00180420578997

Epoch: 109| Step: 0
Training loss: 4.015554702084096
Validation loss: 2.9992426758936968

Epoch: 5| Step: 1
Training loss: 3.3794386604116466
Validation loss: 3.00069876449496

Epoch: 5| Step: 2
Training loss: 2.864835101536663
Validation loss: 2.9988669098027523

Epoch: 5| Step: 3
Training loss: 2.773992606474272
Validation loss: 3.0000331083815666

Epoch: 5| Step: 4
Training loss: 2.7379123150791838
Validation loss: 3.000137688269762

Epoch: 5| Step: 5
Training loss: 3.3415809797937026
Validation loss: 3.0006850632866886

Epoch: 5| Step: 6
Training loss: 3.126927658634978
Validation loss: 3.00468547392386

Epoch: 5| Step: 7
Training loss: 3.0610218762797152
Validation loss: 3.0003735478934264

Epoch: 5| Step: 8
Training loss: 3.5509671035656565
Validation loss: 3.0036186181793054

Epoch: 5| Step: 9
Training loss: 3.41176697400155
Validation loss: 3.0010729318698304

Epoch: 5| Step: 10
Training loss: 3.4971562140385126
Validation loss: 3.001076472698196

Epoch: 110| Step: 0
Training loss: 2.847796066472854
Validation loss: 3.00897953920694

Epoch: 5| Step: 1
Training loss: 3.6659217135514086
Validation loss: 3.003818235600508

Epoch: 5| Step: 2
Training loss: 2.9439483640537656
Validation loss: 3.0013373514895823

Epoch: 5| Step: 3
Training loss: 2.8843640956486563
Validation loss: 2.9982953150532983

Epoch: 5| Step: 4
Training loss: 2.888408904263726
Validation loss: 2.997806689014079

Epoch: 5| Step: 5
Training loss: 3.4998499974395525
Validation loss: 2.9960199722871197

Epoch: 5| Step: 6
Training loss: 3.773466816979799
Validation loss: 2.994605627215729

Epoch: 5| Step: 7
Training loss: 3.6858472838120897
Validation loss: 3.0002237188674776

Epoch: 5| Step: 8
Training loss: 3.2406231518761306
Validation loss: 2.9967992176407363

Epoch: 5| Step: 9
Training loss: 2.462148604518505
Validation loss: 2.9974320660207807

Epoch: 5| Step: 10
Training loss: 3.814356117558078
Validation loss: 2.997907720763939

Epoch: 111| Step: 0
Training loss: 3.1006102361252608
Validation loss: 2.9971159262647658

Epoch: 5| Step: 1
Training loss: 3.4167481079319617
Validation loss: 2.995176060187162

Epoch: 5| Step: 2
Training loss: 3.6196562743995186
Validation loss: 2.997061144499422

Epoch: 5| Step: 3
Training loss: 3.244270997295701
Validation loss: 2.994466902077963

Epoch: 5| Step: 4
Training loss: 2.70487716424107
Validation loss: 2.996384037762923

Epoch: 5| Step: 5
Training loss: 2.8639443164505645
Validation loss: 2.993451196713562

Epoch: 5| Step: 6
Training loss: 3.3653029547205375
Validation loss: 2.9942043604212993

Epoch: 5| Step: 7
Training loss: 3.400224167782812
Validation loss: 2.9935830476755343

Epoch: 5| Step: 8
Training loss: 3.363154640428687
Validation loss: 2.9920094450809276

Epoch: 5| Step: 9
Training loss: 3.4033226943589225
Validation loss: 2.9938413400327586

Epoch: 5| Step: 10
Training loss: 3.3572819776609255
Validation loss: 2.9918398609519072

Epoch: 112| Step: 0
Training loss: 3.9064587346573947
Validation loss: 2.99084799093105

Epoch: 5| Step: 1
Training loss: 2.7711521242552095
Validation loss: 2.9926709031193357

Epoch: 5| Step: 2
Training loss: 3.7310548970956727
Validation loss: 2.991857778209403

Epoch: 5| Step: 3
Training loss: 3.2565498375085933
Validation loss: 2.9930890185835874

Epoch: 5| Step: 4
Training loss: 3.0190798877357112
Validation loss: 2.9922361526040193

Epoch: 5| Step: 5
Training loss: 3.4513094863269154
Validation loss: 2.989724688028544

Epoch: 5| Step: 6
Training loss: 2.6297397510870284
Validation loss: 2.9903662220568084

Epoch: 5| Step: 7
Training loss: 3.0303198576951256
Validation loss: 2.992147381954642

Epoch: 5| Step: 8
Training loss: 3.3191082374920375
Validation loss: 2.989947333137312

Epoch: 5| Step: 9
Training loss: 2.9076055831303496
Validation loss: 2.991511142922689

Epoch: 5| Step: 10
Training loss: 3.6760807705827334
Validation loss: 2.9941240810872674

Epoch: 113| Step: 0
Training loss: 4.101889402895205
Validation loss: 2.9943565282943405

Epoch: 5| Step: 1
Training loss: 3.697795138802284
Validation loss: 2.9946889343760623

Epoch: 5| Step: 2
Training loss: 3.314589651035032
Validation loss: 2.989292566400705

Epoch: 5| Step: 3
Training loss: 3.034034629769996
Validation loss: 2.991833289550182

Epoch: 5| Step: 4
Training loss: 3.243117895260077
Validation loss: 2.991763007467472

Epoch: 5| Step: 5
Training loss: 2.835702092932768
Validation loss: 2.993162913078745

Epoch: 5| Step: 6
Training loss: 3.1389966700531065
Validation loss: 2.993728361330509

Epoch: 5| Step: 7
Training loss: 3.206734461183373
Validation loss: 2.995083744025213

Epoch: 5| Step: 8
Training loss: 3.024362506371597
Validation loss: 2.9897568769415024

Epoch: 5| Step: 9
Training loss: 3.666909614374905
Validation loss: 2.990395555286002

Epoch: 5| Step: 10
Training loss: 2.031861902650589
Validation loss: 2.990002716811699

Epoch: 114| Step: 0
Training loss: 3.346970477910566
Validation loss: 2.989254026972742

Epoch: 5| Step: 1
Training loss: 3.3594756355293502
Validation loss: 2.9873831711831196

Epoch: 5| Step: 2
Training loss: 2.6589723885183223
Validation loss: 2.990394655129811

Epoch: 5| Step: 3
Training loss: 2.7790969058255226
Validation loss: 2.987346022239334

Epoch: 5| Step: 4
Training loss: 3.37614675748857
Validation loss: 2.9877533198266764

Epoch: 5| Step: 5
Training loss: 3.1646812304953267
Validation loss: 2.986724344562203

Epoch: 5| Step: 6
Training loss: 2.9737833821177637
Validation loss: 2.985456342391782

Epoch: 5| Step: 7
Training loss: 3.812530392384943
Validation loss: 2.98780905563673

Epoch: 5| Step: 8
Training loss: 3.1689624662478715
Validation loss: 2.986345282114829

Epoch: 5| Step: 9
Training loss: 3.7642638726245776
Validation loss: 2.986112173515399

Epoch: 5| Step: 10
Training loss: 3.2838966957784956
Validation loss: 2.9848411439544646

Epoch: 115| Step: 0
Training loss: 3.3246507733734347
Validation loss: 2.9859970727926006

Epoch: 5| Step: 1
Training loss: 3.0046806379012745
Validation loss: 2.9869299729704375

Epoch: 5| Step: 2
Training loss: 2.6052137990774975
Validation loss: 2.9873215420780594

Epoch: 5| Step: 3
Training loss: 3.3126901536020497
Validation loss: 2.990726511494251

Epoch: 5| Step: 4
Training loss: 3.0848742234667164
Validation loss: 2.9878688522597345

Epoch: 5| Step: 5
Training loss: 2.9796677459238023
Validation loss: 2.989727336794983

Epoch: 5| Step: 6
Training loss: 3.6223029264835014
Validation loss: 2.9985447502170106

Epoch: 5| Step: 7
Training loss: 3.251921892445738
Validation loss: 2.989851303985149

Epoch: 5| Step: 8
Training loss: 3.59033319334989
Validation loss: 2.9845598023264808

Epoch: 5| Step: 9
Training loss: 3.9263509915785453
Validation loss: 2.9824038322877464

Epoch: 5| Step: 10
Training loss: 2.905132283860919
Validation loss: 2.983811082796106

Epoch: 116| Step: 0
Training loss: 3.2479761130859255
Validation loss: 2.991353550230679

Epoch: 5| Step: 1
Training loss: 3.355711744966724
Validation loss: 2.989088427332651

Epoch: 5| Step: 2
Training loss: 2.9764493985853124
Validation loss: 2.987419095949539

Epoch: 5| Step: 3
Training loss: 3.035109746667558
Validation loss: 2.984432254914873

Epoch: 5| Step: 4
Training loss: 3.5431573012207416
Validation loss: 2.980690771422129

Epoch: 5| Step: 5
Training loss: 3.059854883231083
Validation loss: 2.982357445082351

Epoch: 5| Step: 6
Training loss: 3.4728482067833597
Validation loss: 2.9814338384386367

Epoch: 5| Step: 7
Training loss: 3.428997552594379
Validation loss: 2.9802189890327315

Epoch: 5| Step: 8
Training loss: 2.5705852885556095
Validation loss: 2.982574947420738

Epoch: 5| Step: 9
Training loss: 3.2404630556171035
Validation loss: 2.9809025489483307

Epoch: 5| Step: 10
Training loss: 3.837034857079852
Validation loss: 2.979620827420221

Epoch: 117| Step: 0
Training loss: 3.3219271694332124
Validation loss: 2.983317761687916

Epoch: 5| Step: 1
Training loss: 3.059364270511941
Validation loss: 2.9928960024279982

Epoch: 5| Step: 2
Training loss: 3.166113068894864
Validation loss: 2.999984563425472

Epoch: 5| Step: 3
Training loss: 3.441582076639548
Validation loss: 2.982287852605947

Epoch: 5| Step: 4
Training loss: 4.025533008232104
Validation loss: 2.979115743364648

Epoch: 5| Step: 5
Training loss: 3.0740050031910413
Validation loss: 2.9838593539006695

Epoch: 5| Step: 6
Training loss: 3.2154805884080084
Validation loss: 2.9767919358369888

Epoch: 5| Step: 7
Training loss: 2.8282347599881064
Validation loss: 2.9787791681589977

Epoch: 5| Step: 8
Training loss: 3.3555859866106243
Validation loss: 2.9803842324981247

Epoch: 5| Step: 9
Training loss: 3.134513108014769
Validation loss: 2.9790406398734226

Epoch: 5| Step: 10
Training loss: 3.032707729033375
Validation loss: 2.979276144946382

Epoch: 118| Step: 0
Training loss: 3.1480227971105816
Validation loss: 2.978393744132331

Epoch: 5| Step: 1
Training loss: 3.1724317841827534
Validation loss: 2.9792298346759236

Epoch: 5| Step: 2
Training loss: 3.773447609329108
Validation loss: 2.9789812400475104

Epoch: 5| Step: 3
Training loss: 2.9633009845811693
Validation loss: 2.976189589094507

Epoch: 5| Step: 4
Training loss: 3.534800542144026
Validation loss: 2.9779685499946695

Epoch: 5| Step: 5
Training loss: 3.7272127172033294
Validation loss: 2.9755906372965835

Epoch: 5| Step: 6
Training loss: 3.018588492612389
Validation loss: 2.9761119205754762

Epoch: 5| Step: 7
Training loss: 3.097394857646471
Validation loss: 2.9744983109105343

Epoch: 5| Step: 8
Training loss: 2.9979374471071902
Validation loss: 2.9768894050386043

Epoch: 5| Step: 9
Training loss: 3.0922869681252587
Validation loss: 2.975491023282345

Epoch: 5| Step: 10
Training loss: 3.105836321112244
Validation loss: 2.9775628774743503

Epoch: 119| Step: 0
Training loss: 3.510346243101948
Validation loss: 2.9789236617735413

Epoch: 5| Step: 1
Training loss: 2.9359214274731364
Validation loss: 2.980130696579629

Epoch: 5| Step: 2
Training loss: 3.224634957168738
Validation loss: 2.986887129593278

Epoch: 5| Step: 3
Training loss: 3.2048719154984924
Validation loss: 2.985756180212031

Epoch: 5| Step: 4
Training loss: 2.9281680630150366
Validation loss: 2.9846622427809186

Epoch: 5| Step: 5
Training loss: 3.7402402394699457
Validation loss: 2.9816629260851295

Epoch: 5| Step: 6
Training loss: 2.9606406835583936
Validation loss: 2.976440310046028

Epoch: 5| Step: 7
Training loss: 3.110956911019772
Validation loss: 2.9767389417176635

Epoch: 5| Step: 8
Training loss: 3.19753495878029
Validation loss: 2.9752324915263157

Epoch: 5| Step: 9
Training loss: 3.481924794953211
Validation loss: 2.9757570190974914

Epoch: 5| Step: 10
Training loss: 3.3985647594258417
Validation loss: 2.976051760234483

Epoch: 120| Step: 0
Training loss: 3.111615011491031
Validation loss: 2.973670058616021

Epoch: 5| Step: 1
Training loss: 2.7029237176120935
Validation loss: 2.9734681887868057

Epoch: 5| Step: 2
Training loss: 3.502186637109722
Validation loss: 2.9752264478326778

Epoch: 5| Step: 3
Training loss: 3.659520439039793
Validation loss: 2.9745913883217243

Epoch: 5| Step: 4
Training loss: 3.0023522691806828
Validation loss: 2.972210876373675

Epoch: 5| Step: 5
Training loss: 3.3326660124057046
Validation loss: 2.979382145239477

Epoch: 5| Step: 6
Training loss: 3.8797574525903262
Validation loss: 2.9939227495334846

Epoch: 5| Step: 7
Training loss: 2.6880208774845795
Validation loss: 2.98273423816314

Epoch: 5| Step: 8
Training loss: 3.2580794629826597
Validation loss: 2.981578490584335

Epoch: 5| Step: 9
Training loss: 3.7211909897917526
Validation loss: 2.9819622495112967

Epoch: 5| Step: 10
Training loss: 2.500685979189733
Validation loss: 2.97293135556758

Epoch: 121| Step: 0
Training loss: 3.0320188196247386
Validation loss: 2.9732606567748405

Epoch: 5| Step: 1
Training loss: 3.159880712164987
Validation loss: 2.971093722940682

Epoch: 5| Step: 2
Training loss: 3.3687250649514904
Validation loss: 2.97240835446599

Epoch: 5| Step: 3
Training loss: 3.1884684867815034
Validation loss: 2.971526699157049

Epoch: 5| Step: 4
Training loss: 3.3923941360856555
Validation loss: 2.971726369056248

Epoch: 5| Step: 5
Training loss: 3.3721134416134864
Validation loss: 2.9721299796910166

Epoch: 5| Step: 6
Training loss: 3.7008099623104442
Validation loss: 2.9773839298850353

Epoch: 5| Step: 7
Training loss: 3.1887064128006726
Validation loss: 2.99300519322249

Epoch: 5| Step: 8
Training loss: 3.2079150600175805
Validation loss: 2.998649706031811

Epoch: 5| Step: 9
Training loss: 2.7884631968930926
Validation loss: 2.97366837145973

Epoch: 5| Step: 10
Training loss: 3.2486810208520227
Validation loss: 2.9696718383356324

Epoch: 122| Step: 0
Training loss: 3.638945228845859
Validation loss: 2.9712432805838684

Epoch: 5| Step: 1
Training loss: 3.423432296268438
Validation loss: 2.96816194989283

Epoch: 5| Step: 2
Training loss: 2.985930990853793
Validation loss: 2.967987948906175

Epoch: 5| Step: 3
Training loss: 3.2235208357274723
Validation loss: 2.970091221787041

Epoch: 5| Step: 4
Training loss: 2.780779509449784
Validation loss: 2.9678577025555914

Epoch: 5| Step: 5
Training loss: 3.1669431030346735
Validation loss: 2.9697186921650878

Epoch: 5| Step: 6
Training loss: 2.990211571445137
Validation loss: 2.971867956894997

Epoch: 5| Step: 7
Training loss: 3.0080445831728406
Validation loss: 2.9668918305945424

Epoch: 5| Step: 8
Training loss: 3.517506278329979
Validation loss: 2.9675890808836654

Epoch: 5| Step: 9
Training loss: 3.5417650695294935
Validation loss: 2.969624471837299

Epoch: 5| Step: 10
Training loss: 3.2728471974835873
Validation loss: 2.968030580527548

Epoch: 123| Step: 0
Training loss: 3.3023080037377333
Validation loss: 2.96596400174373

Epoch: 5| Step: 1
Training loss: 3.707068681276709
Validation loss: 2.964485150769804

Epoch: 5| Step: 2
Training loss: 3.7610317723971645
Validation loss: 2.9653312821281923

Epoch: 5| Step: 3
Training loss: 3.4485642361913014
Validation loss: 2.9655539994203766

Epoch: 5| Step: 4
Training loss: 2.606046735489395
Validation loss: 2.965765557749427

Epoch: 5| Step: 5
Training loss: 2.949772137392416
Validation loss: 2.9648621676235027

Epoch: 5| Step: 6
Training loss: 2.9945752051810057
Validation loss: 2.9654158621016204

Epoch: 5| Step: 7
Training loss: 2.9663435970799976
Validation loss: 2.9676377272913372

Epoch: 5| Step: 8
Training loss: 3.111559230078251
Validation loss: 2.9723203199015886

Epoch: 5| Step: 9
Training loss: 3.0156879319655956
Validation loss: 2.9653142247506508

Epoch: 5| Step: 10
Training loss: 3.6284940257575866
Validation loss: 2.9652967246265702

Epoch: 124| Step: 0
Training loss: 3.143450628325848
Validation loss: 2.9635904118064085

Epoch: 5| Step: 1
Training loss: 3.7445388446860575
Validation loss: 2.96861797356541

Epoch: 5| Step: 2
Training loss: 3.370321068113964
Validation loss: 2.9624123160831646

Epoch: 5| Step: 3
Training loss: 3.6984130239704194
Validation loss: 2.9685781674183174

Epoch: 5| Step: 4
Training loss: 2.762957045777278
Validation loss: 2.968149262782621

Epoch: 5| Step: 5
Training loss: 2.8227455866212154
Validation loss: 2.9665168329165765

Epoch: 5| Step: 6
Training loss: 2.155458056100862
Validation loss: 2.9719308329138157

Epoch: 5| Step: 7
Training loss: 3.7425874564043857
Validation loss: 2.9616596846542325

Epoch: 5| Step: 8
Training loss: 3.1039310510980593
Validation loss: 2.968621001277148

Epoch: 5| Step: 9
Training loss: 3.2841740250006937
Validation loss: 2.962548210278255

Epoch: 5| Step: 10
Training loss: 3.4879642355336467
Validation loss: 2.9643728598424914

Epoch: 125| Step: 0
Training loss: 2.9094948650707475
Validation loss: 2.9623921732077196

Epoch: 5| Step: 1
Training loss: 3.354705830396474
Validation loss: 2.968054497708067

Epoch: 5| Step: 2
Training loss: 3.2966150841246873
Validation loss: 2.9592718801763

Epoch: 5| Step: 3
Training loss: 3.087947142805831
Validation loss: 2.9616455016092966

Epoch: 5| Step: 4
Training loss: 3.3368820532741905
Validation loss: 2.9592548155939014

Epoch: 5| Step: 5
Training loss: 2.794053428608724
Validation loss: 2.9608398234371793

Epoch: 5| Step: 6
Training loss: 3.2630561325384337
Validation loss: 2.960045689978777

Epoch: 5| Step: 7
Training loss: 3.3116632520340965
Validation loss: 2.958660433195128

Epoch: 5| Step: 8
Training loss: 3.347490161884144
Validation loss: 2.958644116334502

Epoch: 5| Step: 9
Training loss: 3.238574558866886
Validation loss: 2.956779165906357

Epoch: 5| Step: 10
Training loss: 3.692000277724829
Validation loss: 2.9568733750477443

Testing loss: 3.1509146000066557
