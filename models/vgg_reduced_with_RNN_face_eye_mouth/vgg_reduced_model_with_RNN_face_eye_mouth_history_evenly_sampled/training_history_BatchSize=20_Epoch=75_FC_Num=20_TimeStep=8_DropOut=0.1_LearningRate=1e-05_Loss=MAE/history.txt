Epoch: 1| Step: 0
Training loss: 5.858905792236328
Validation loss: 5.196167884334441

Epoch: 5| Step: 1
Training loss: 4.476916313171387
Validation loss: 5.185876646349507

Epoch: 5| Step: 2
Training loss: 4.446476936340332
Validation loss: 5.1759889766734135

Epoch: 5| Step: 3
Training loss: 5.209108829498291
Validation loss: 5.166057007287138

Epoch: 5| Step: 4
Training loss: 4.7231035232543945
Validation loss: 5.155812755707772

Epoch: 5| Step: 5
Training loss: 5.155107021331787
Validation loss: 5.145402098214754

Epoch: 5| Step: 6
Training loss: 4.741451263427734
Validation loss: 5.1344412526776715

Epoch: 5| Step: 7
Training loss: 5.670095920562744
Validation loss: 5.122582743244786

Epoch: 5| Step: 8
Training loss: 4.471990585327148
Validation loss: 5.109446915247107

Epoch: 5| Step: 9
Training loss: 5.559762001037598
Validation loss: 5.095787161140032

Epoch: 5| Step: 10
Training loss: 3.8434956073760986
Validation loss: 5.080697910760039

Epoch: 2| Step: 0
Training loss: 4.842975616455078
Validation loss: 5.064665214989775

Epoch: 5| Step: 1
Training loss: 4.000457286834717
Validation loss: 5.046365671260382

Epoch: 5| Step: 2
Training loss: 5.618462562561035
Validation loss: 5.027234133853708

Epoch: 5| Step: 3
Training loss: 5.485718727111816
Validation loss: 5.006904181613717

Epoch: 5| Step: 4
Training loss: 4.9545183181762695
Validation loss: 4.984533397100305

Epoch: 5| Step: 5
Training loss: 5.210826873779297
Validation loss: 4.962140852405179

Epoch: 5| Step: 6
Training loss: 3.5312132835388184
Validation loss: 4.936972648866715

Epoch: 5| Step: 7
Training loss: 5.151231288909912
Validation loss: 4.910582152746057

Epoch: 5| Step: 8
Training loss: 4.6251726150512695
Validation loss: 4.881815935975762

Epoch: 5| Step: 9
Training loss: 4.072823524475098
Validation loss: 4.851385824141964

Epoch: 5| Step: 10
Training loss: 4.754919528961182
Validation loss: 4.819828264174923

Epoch: 3| Step: 0
Training loss: 4.6327338218688965
Validation loss: 4.786767928831039

Epoch: 5| Step: 1
Training loss: 5.545803070068359
Validation loss: 4.752483772975142

Epoch: 5| Step: 2
Training loss: 6.363133907318115
Validation loss: 4.71657290509952

Epoch: 5| Step: 3
Training loss: 4.254232406616211
Validation loss: 4.6793886359019945

Epoch: 5| Step: 4
Training loss: 4.22750186920166
Validation loss: 4.643689386306271

Epoch: 5| Step: 5
Training loss: 3.6787352561950684
Validation loss: 4.606841502651092

Epoch: 5| Step: 6
Training loss: 4.245872497558594
Validation loss: 4.568851435056296

Epoch: 5| Step: 7
Training loss: 3.805448055267334
Validation loss: 4.533421203654299

Epoch: 5| Step: 8
Training loss: 3.575044631958008
Validation loss: 4.497200842826597

Epoch: 5| Step: 9
Training loss: 3.720917224884033
Validation loss: 4.461850796976397

Epoch: 5| Step: 10
Training loss: 4.3339619636535645
Validation loss: 4.425782213928879

Epoch: 4| Step: 0
Training loss: 4.261743068695068
Validation loss: 4.389637034426453

Epoch: 5| Step: 1
Training loss: 2.690826416015625
Validation loss: 4.354339140717701

Epoch: 5| Step: 2
Training loss: 5.0269365310668945
Validation loss: 4.318379735433927

Epoch: 5| Step: 3
Training loss: 4.449344158172607
Validation loss: 4.281379522815827

Epoch: 5| Step: 4
Training loss: 4.42875862121582
Validation loss: 4.244691976936915

Epoch: 5| Step: 5
Training loss: 4.169100761413574
Validation loss: 4.209891155201902

Epoch: 5| Step: 6
Training loss: 3.2040066719055176
Validation loss: 4.178353704432006

Epoch: 5| Step: 7
Training loss: 4.954470634460449
Validation loss: 4.147220442371983

Epoch: 5| Step: 8
Training loss: 3.1505532264709473
Validation loss: 4.117111036854405

Epoch: 5| Step: 9
Training loss: 4.8983354568481445
Validation loss: 4.0884501267504945

Epoch: 5| Step: 10
Training loss: 2.989696502685547
Validation loss: 4.059850351784819

Epoch: 5| Step: 0
Training loss: 3.8735594749450684
Validation loss: 4.031468409363941

Epoch: 5| Step: 1
Training loss: 4.012328147888184
Validation loss: 4.007105688894948

Epoch: 5| Step: 2
Training loss: 4.723661422729492
Validation loss: 3.9784484935063187

Epoch: 5| Step: 3
Training loss: 4.128698825836182
Validation loss: 3.950253117469049

Epoch: 5| Step: 4
Training loss: 4.4300031661987305
Validation loss: 3.925544059404763

Epoch: 5| Step: 5
Training loss: 3.4307830333709717
Validation loss: 3.899990112550797

Epoch: 5| Step: 6
Training loss: 3.380723476409912
Validation loss: 3.8799155912091656

Epoch: 5| Step: 7
Training loss: 4.290245532989502
Validation loss: 3.862025501907513

Epoch: 5| Step: 8
Training loss: 3.3875412940979004
Validation loss: 3.8439688862011

Epoch: 5| Step: 9
Training loss: 3.374415636062622
Validation loss: 3.828127348294822

Epoch: 5| Step: 10
Training loss: 2.360440731048584
Validation loss: 3.8119636402335217

Epoch: 6| Step: 0
Training loss: 2.8628363609313965
Validation loss: 3.7944565178245626

Epoch: 5| Step: 1
Training loss: 2.345768451690674
Validation loss: 3.777892251168528

Epoch: 5| Step: 2
Training loss: 4.340632915496826
Validation loss: 3.76493086097061

Epoch: 5| Step: 3
Training loss: 3.380328416824341
Validation loss: 3.751424853519727

Epoch: 5| Step: 4
Training loss: 4.233481407165527
Validation loss: 3.737708901846281

Epoch: 5| Step: 5
Training loss: 3.469555616378784
Validation loss: 3.724738900379468

Epoch: 5| Step: 6
Training loss: 3.6883761882781982
Validation loss: 3.7145928413637224

Epoch: 5| Step: 7
Training loss: 4.160356044769287
Validation loss: 3.705209296236756

Epoch: 5| Step: 8
Training loss: 4.8649091720581055
Validation loss: 3.692453738181822

Epoch: 5| Step: 9
Training loss: 3.029829740524292
Validation loss: 3.6786319209683325

Epoch: 5| Step: 10
Training loss: 3.5055322647094727
Validation loss: 3.667432733761367

Epoch: 7| Step: 0
Training loss: 2.9094765186309814
Validation loss: 3.655013181829965

Epoch: 5| Step: 1
Training loss: 3.800004243850708
Validation loss: 3.645798606257285

Epoch: 5| Step: 2
Training loss: 3.0280845165252686
Validation loss: 3.6342391711409374

Epoch: 5| Step: 3
Training loss: 3.5420219898223877
Validation loss: 3.623238809647099

Epoch: 5| Step: 4
Training loss: 3.4663283824920654
Validation loss: 3.6142080368534213

Epoch: 5| Step: 5
Training loss: 3.0184483528137207
Validation loss: 3.6019973011427027

Epoch: 5| Step: 6
Training loss: 3.960566759109497
Validation loss: 3.590087954716016

Epoch: 5| Step: 7
Training loss: 3.8348305225372314
Validation loss: 3.5771736329601658

Epoch: 5| Step: 8
Training loss: 3.085462808609009
Validation loss: 3.5671167527475665

Epoch: 5| Step: 9
Training loss: 4.258945465087891
Validation loss: 3.5586680109782884

Epoch: 5| Step: 10
Training loss: 3.781920909881592
Validation loss: 3.548060176193073

Epoch: 8| Step: 0
Training loss: 4.231957912445068
Validation loss: 3.5344031164723058

Epoch: 5| Step: 1
Training loss: 4.173902988433838
Validation loss: 3.523572083442442

Epoch: 5| Step: 2
Training loss: 2.9604594707489014
Validation loss: 3.5141199173465854

Epoch: 5| Step: 3
Training loss: 3.450289487838745
Validation loss: 3.5060754206872757

Epoch: 5| Step: 4
Training loss: 3.279912233352661
Validation loss: 3.498628354841663

Epoch: 5| Step: 5
Training loss: 3.88409423828125
Validation loss: 3.487891548423357

Epoch: 5| Step: 6
Training loss: 2.0114097595214844
Validation loss: 3.4810310230460217

Epoch: 5| Step: 7
Training loss: 3.2562289237976074
Validation loss: 3.4739110956909838

Epoch: 5| Step: 8
Training loss: 4.202644348144531
Validation loss: 3.4636915781164683

Epoch: 5| Step: 9
Training loss: 2.925326108932495
Validation loss: 3.4568388590248684

Epoch: 5| Step: 10
Training loss: 3.279630661010742
Validation loss: 3.449212643408006

Epoch: 9| Step: 0
Training loss: 3.332973003387451
Validation loss: 3.4402622510028142

Epoch: 5| Step: 1
Training loss: 3.2369110584259033
Validation loss: 3.4331784068897204

Epoch: 5| Step: 2
Training loss: 1.6195894479751587
Validation loss: 3.4219851160562165

Epoch: 5| Step: 3
Training loss: 3.6098411083221436
Validation loss: 3.418178217385405

Epoch: 5| Step: 4
Training loss: 4.016292572021484
Validation loss: 3.407602802399666

Epoch: 5| Step: 5
Training loss: 3.699176788330078
Validation loss: 3.4026800611967682

Epoch: 5| Step: 6
Training loss: 3.23705792427063
Validation loss: 3.3931394648808304

Epoch: 5| Step: 7
Training loss: 4.287631034851074
Validation loss: 3.3874710631626908

Epoch: 5| Step: 8
Training loss: 3.227375030517578
Validation loss: 3.3716118028087

Epoch: 5| Step: 9
Training loss: 3.605480194091797
Validation loss: 3.3588833834535334

Epoch: 5| Step: 10
Training loss: 2.908620834350586
Validation loss: 3.350872883232691

Epoch: 10| Step: 0
Training loss: 3.1668455600738525
Validation loss: 3.3430800181563183

Epoch: 5| Step: 1
Training loss: 2.6495211124420166
Validation loss: 3.3388690820304294

Epoch: 5| Step: 2
Training loss: 2.5666210651397705
Validation loss: 3.3347161380193566

Epoch: 5| Step: 3
Training loss: 3.5218117237091064
Validation loss: 3.325339550613075

Epoch: 5| Step: 4
Training loss: 3.1827633380889893
Validation loss: 3.3163093418203373

Epoch: 5| Step: 5
Training loss: 3.473471164703369
Validation loss: 3.305813850895051

Epoch: 5| Step: 6
Training loss: 4.198051452636719
Validation loss: 3.300346164293187

Epoch: 5| Step: 7
Training loss: 2.984201431274414
Validation loss: 3.293477871084726

Epoch: 5| Step: 8
Training loss: 3.6362998485565186
Validation loss: 3.2866852847478722

Epoch: 5| Step: 9
Training loss: 4.184958457946777
Validation loss: 3.283026320959932

Epoch: 5| Step: 10
Training loss: 2.2990779876708984
Validation loss: 3.274574513076454

Epoch: 11| Step: 0
Training loss: 2.6272473335266113
Validation loss: 3.2621529435598724

Epoch: 5| Step: 1
Training loss: 3.4387779235839844
Validation loss: 3.2553725422069593

Epoch: 5| Step: 2
Training loss: 2.7707276344299316
Validation loss: 3.249873971426359

Epoch: 5| Step: 3
Training loss: 2.611055612564087
Validation loss: 3.2457547751806115

Epoch: 5| Step: 4
Training loss: 2.4424338340759277
Validation loss: 3.2393140536482616

Epoch: 5| Step: 5
Training loss: 3.2625892162323
Validation loss: 3.230909647480134

Epoch: 5| Step: 6
Training loss: 3.5367729663848877
Validation loss: 3.224553890125726

Epoch: 5| Step: 7
Training loss: 4.726447105407715
Validation loss: 3.217918021704561

Epoch: 5| Step: 8
Training loss: 3.2755305767059326
Validation loss: 3.2059762195874284

Epoch: 5| Step: 9
Training loss: 3.8978729248046875
Validation loss: 3.2007369302934214

Epoch: 5| Step: 10
Training loss: 2.711629867553711
Validation loss: 3.194712297890776

Epoch: 12| Step: 0
Training loss: 3.0719470977783203
Validation loss: 3.194277737730293

Epoch: 5| Step: 1
Training loss: 3.7589523792266846
Validation loss: 3.1818559682497414

Epoch: 5| Step: 2
Training loss: 3.4071946144104004
Validation loss: 3.1736695843358196

Epoch: 5| Step: 3
Training loss: 2.8966124057769775
Validation loss: 3.167926360202092

Epoch: 5| Step: 4
Training loss: 2.814271926879883
Validation loss: 3.1611388934555875

Epoch: 5| Step: 5
Training loss: 3.3562264442443848
Validation loss: 3.1552836664261354

Epoch: 5| Step: 6
Training loss: 4.1673736572265625
Validation loss: 3.146859286933817

Epoch: 5| Step: 7
Training loss: 3.098433494567871
Validation loss: 3.142692078826248

Epoch: 5| Step: 8
Training loss: 1.9386208057403564
Validation loss: 3.1320199453702537

Epoch: 5| Step: 9
Training loss: 2.6091742515563965
Validation loss: 3.1293996841676774

Epoch: 5| Step: 10
Training loss: 3.7988173961639404
Validation loss: 3.119599696128599

Epoch: 13| Step: 0
Training loss: 2.740696430206299
Validation loss: 3.111874431692144

Epoch: 5| Step: 1
Training loss: 3.15368914604187
Validation loss: 3.1081901058073966

Epoch: 5| Step: 2
Training loss: 3.242854356765747
Validation loss: 3.1042405097715315

Epoch: 5| Step: 3
Training loss: 4.202988624572754
Validation loss: 3.1008714399030133

Epoch: 5| Step: 4
Training loss: 2.8267550468444824
Validation loss: 3.0940514251750004

Epoch: 5| Step: 5
Training loss: 2.518815040588379
Validation loss: 3.086360331504576

Epoch: 5| Step: 6
Training loss: 3.3140316009521484
Validation loss: 3.080471913019816

Epoch: 5| Step: 7
Training loss: 3.722223997116089
Validation loss: 3.0805873537576325

Epoch: 5| Step: 8
Training loss: 3.1201541423797607
Validation loss: 3.076550893886115

Epoch: 5| Step: 9
Training loss: 2.698110342025757
Validation loss: 3.0666464631275465

Epoch: 5| Step: 10
Training loss: 2.729853391647339
Validation loss: 3.0603211515693256

Epoch: 14| Step: 0
Training loss: 3.217703342437744
Validation loss: 3.058148555858161

Epoch: 5| Step: 1
Training loss: 2.992511034011841
Validation loss: 3.0578403959992113

Epoch: 5| Step: 2
Training loss: 3.9286556243896484
Validation loss: 3.0517006920230005

Epoch: 5| Step: 3
Training loss: 3.163311004638672
Validation loss: 3.043251411889189

Epoch: 5| Step: 4
Training loss: 2.7563159465789795
Validation loss: 3.036408714068833

Epoch: 5| Step: 5
Training loss: 3.5661747455596924
Validation loss: 3.035740698537519

Epoch: 5| Step: 6
Training loss: 2.6426620483398438
Validation loss: 3.0320242040900776

Epoch: 5| Step: 7
Training loss: 2.7177624702453613
Validation loss: 3.0277530711184264

Epoch: 5| Step: 8
Training loss: 2.999828577041626
Validation loss: 3.022531763199837

Epoch: 5| Step: 9
Training loss: 3.2938168048858643
Validation loss: 3.014543210306475

Epoch: 5| Step: 10
Training loss: 2.584798574447632
Validation loss: 3.011944773376629

Epoch: 15| Step: 0
Training loss: 3.802621841430664
Validation loss: 3.007441928309779

Epoch: 5| Step: 1
Training loss: 2.425604820251465
Validation loss: 3.00068070555246

Epoch: 5| Step: 2
Training loss: 2.718686580657959
Validation loss: 3.0072364807128906

Epoch: 5| Step: 3
Training loss: 3.079030752182007
Validation loss: 2.9913393194957445

Epoch: 5| Step: 4
Training loss: 2.749661922454834
Validation loss: 2.9861804208447857

Epoch: 5| Step: 5
Training loss: 2.6510117053985596
Validation loss: 2.985436688187302

Epoch: 5| Step: 6
Training loss: 3.0374863147735596
Validation loss: 2.982606900635586

Epoch: 5| Step: 7
Training loss: 3.9389843940734863
Validation loss: 2.9773802244535057

Epoch: 5| Step: 8
Training loss: 2.8579587936401367
Validation loss: 2.970942025543541

Epoch: 5| Step: 9
Training loss: 3.39813232421875
Validation loss: 2.964906782232305

Epoch: 5| Step: 10
Training loss: 2.893810749053955
Validation loss: 2.961427539907476

Epoch: 16| Step: 0
Training loss: 2.9352376461029053
Validation loss: 2.957891079687303

Epoch: 5| Step: 1
Training loss: 3.561601161956787
Validation loss: 2.9506942174767934

Epoch: 5| Step: 2
Training loss: 2.715092420578003
Validation loss: 2.9457383976187757

Epoch: 5| Step: 3
Training loss: 2.582186222076416
Validation loss: 2.941536972599645

Epoch: 5| Step: 4
Training loss: 2.8735227584838867
Validation loss: 2.9381907242600636

Epoch: 5| Step: 5
Training loss: 2.728797435760498
Validation loss: 2.9371643809862036

Epoch: 5| Step: 6
Training loss: 3.9176459312438965
Validation loss: 2.930576862827424

Epoch: 5| Step: 7
Training loss: 2.9457828998565674
Validation loss: 2.9256271546886814

Epoch: 5| Step: 8
Training loss: 2.632049322128296
Validation loss: 2.9233275254567466

Epoch: 5| Step: 9
Training loss: 3.0264382362365723
Validation loss: 2.9169424349261868

Epoch: 5| Step: 10
Training loss: 3.3498096466064453
Validation loss: 2.9143682705458773

Epoch: 17| Step: 0
Training loss: 3.3810362815856934
Validation loss: 2.9084923805729037

Epoch: 5| Step: 1
Training loss: 3.06134295463562
Validation loss: 2.9050988510090816

Epoch: 5| Step: 2
Training loss: 2.3308515548706055
Validation loss: 2.901904818832233

Epoch: 5| Step: 3
Training loss: 2.6071887016296387
Validation loss: 2.8955798584927797

Epoch: 5| Step: 4
Training loss: 3.4894301891326904
Validation loss: 2.894064785331808

Epoch: 5| Step: 5
Training loss: 3.4461898803710938
Validation loss: 2.88830457451523

Epoch: 5| Step: 6
Training loss: 2.976214647293091
Validation loss: 2.881957305374966

Epoch: 5| Step: 7
Training loss: 2.9228553771972656
Validation loss: 2.8787113902389363

Epoch: 5| Step: 8
Training loss: 3.0706241130828857
Validation loss: 2.8744224476557907

Epoch: 5| Step: 9
Training loss: 2.9377493858337402
Validation loss: 2.867633996471282

Epoch: 5| Step: 10
Training loss: 2.532778739929199
Validation loss: 2.862153148138395

Epoch: 18| Step: 0
Training loss: 1.9783645868301392
Validation loss: 2.862898072888774

Epoch: 5| Step: 1
Training loss: 3.342430830001831
Validation loss: 2.8586629770135366

Epoch: 5| Step: 2
Training loss: 3.031226634979248
Validation loss: 2.8535246361968336

Epoch: 5| Step: 3
Training loss: 3.3933005332946777
Validation loss: 2.8457839130073466

Epoch: 5| Step: 4
Training loss: 2.756836414337158
Validation loss: 2.8360847939727125

Epoch: 5| Step: 5
Training loss: 3.285147190093994
Validation loss: 2.8347645498091176

Epoch: 5| Step: 6
Training loss: 2.6114509105682373
Validation loss: 2.835762354635423

Epoch: 5| Step: 7
Training loss: 3.310040235519409
Validation loss: 2.829010286638814

Epoch: 5| Step: 8
Training loss: 3.1748640537261963
Validation loss: 2.819526703126969

Epoch: 5| Step: 9
Training loss: 2.7020204067230225
Validation loss: 2.816672237970496

Epoch: 5| Step: 10
Training loss: 2.92742657661438
Validation loss: 2.81293152224633

Epoch: 19| Step: 0
Training loss: 3.522202253341675
Validation loss: 2.808229451538414

Epoch: 5| Step: 1
Training loss: 2.7611985206604004
Validation loss: 2.8047952395613476

Epoch: 5| Step: 2
Training loss: 2.5415444374084473
Validation loss: 2.800273951663766

Epoch: 5| Step: 3
Training loss: 3.771765947341919
Validation loss: 2.799502565014747

Epoch: 5| Step: 4
Training loss: 2.6590912342071533
Validation loss: 2.791654638064805

Epoch: 5| Step: 5
Training loss: 2.1270554065704346
Validation loss: 2.787043530453918

Epoch: 5| Step: 6
Training loss: 2.785971164703369
Validation loss: 2.78318118023616

Epoch: 5| Step: 7
Training loss: 2.8769524097442627
Validation loss: 2.781177041351154

Epoch: 5| Step: 8
Training loss: 3.4000351428985596
Validation loss: 2.7791236754386657

Epoch: 5| Step: 9
Training loss: 3.2806618213653564
Validation loss: 2.775280467925533

Epoch: 5| Step: 10
Training loss: 2.3878772258758545
Validation loss: 2.770549817751813

Epoch: 20| Step: 0
Training loss: 3.067004442214966
Validation loss: 2.771217951210596

Epoch: 5| Step: 1
Training loss: 2.673953056335449
Validation loss: 2.767792691466629

Epoch: 5| Step: 2
Training loss: 3.1920924186706543
Validation loss: 2.763832205085344

Epoch: 5| Step: 3
Training loss: 2.5763893127441406
Validation loss: 2.7555485002456175

Epoch: 5| Step: 4
Training loss: 2.4339864253997803
Validation loss: 2.7509452681387625

Epoch: 5| Step: 5
Training loss: 2.754288911819458
Validation loss: 2.7694356877316713

Epoch: 5| Step: 6
Training loss: 3.2388534545898438
Validation loss: 2.757030681897235

Epoch: 5| Step: 7
Training loss: 3.124969482421875
Validation loss: 2.7507760678568194

Epoch: 5| Step: 8
Training loss: 2.5687859058380127
Validation loss: 2.765365098112373

Epoch: 5| Step: 9
Training loss: 3.1016266345977783
Validation loss: 2.779872327722529

Epoch: 5| Step: 10
Training loss: 3.2504310607910156
Validation loss: 2.7775839041638117

Epoch: 21| Step: 0
Training loss: 2.5673327445983887
Validation loss: 2.766870544802758

Epoch: 5| Step: 1
Training loss: 3.115311861038208
Validation loss: 2.752871831258138

Epoch: 5| Step: 2
Training loss: 2.3013758659362793
Validation loss: 2.7437324139379684

Epoch: 5| Step: 3
Training loss: 2.8774476051330566
Validation loss: 2.7395200319187616

Epoch: 5| Step: 4
Training loss: 2.7417118549346924
Validation loss: 2.7600552061552643

Epoch: 5| Step: 5
Training loss: 2.5247886180877686
Validation loss: 2.7305288878820275

Epoch: 5| Step: 6
Training loss: 3.8686561584472656
Validation loss: 2.7299325389246785

Epoch: 5| Step: 7
Training loss: 3.3194358348846436
Validation loss: 2.7255037292357414

Epoch: 5| Step: 8
Training loss: 3.0947985649108887
Validation loss: 2.721141738276328

Epoch: 5| Step: 9
Training loss: 1.6813857555389404
Validation loss: 2.71744119223728

Epoch: 5| Step: 10
Training loss: 3.810020923614502
Validation loss: 2.7176631932617514

Epoch: 22| Step: 0
Training loss: 3.1065921783447266
Validation loss: 2.710449885296565

Epoch: 5| Step: 1
Training loss: 2.7752299308776855
Validation loss: 2.7095460737905195

Epoch: 5| Step: 2
Training loss: 2.783104419708252
Validation loss: 2.7008839832839144

Epoch: 5| Step: 3
Training loss: 3.122234344482422
Validation loss: 2.7015093911078667

Epoch: 5| Step: 4
Training loss: 2.491508722305298
Validation loss: 2.699222062223701

Epoch: 5| Step: 5
Training loss: 2.789929151535034
Validation loss: 2.691377470570226

Epoch: 5| Step: 6
Training loss: 2.9255077838897705
Validation loss: 2.6877234187177432

Epoch: 5| Step: 7
Training loss: 2.3733763694763184
Validation loss: 2.6823811607976116

Epoch: 5| Step: 8
Training loss: 3.2928619384765625
Validation loss: 2.6832269160978255

Epoch: 5| Step: 9
Training loss: 2.660222291946411
Validation loss: 2.6808244823127665

Epoch: 5| Step: 10
Training loss: 3.155174493789673
Validation loss: 2.6720249781044583

Epoch: 23| Step: 0
Training loss: 2.4570517539978027
Validation loss: 2.7265827373791764

Epoch: 5| Step: 1
Training loss: 3.3491833209991455
Validation loss: 2.8075503098067416

Epoch: 5| Step: 2
Training loss: 3.4787135124206543
Validation loss: 2.8625155033603793

Epoch: 5| Step: 3
Training loss: 2.514033317565918
Validation loss: 2.843622930588261

Epoch: 5| Step: 4
Training loss: 2.9705376625061035
Validation loss: 2.790131245889971

Epoch: 5| Step: 5
Training loss: 3.0864148139953613
Validation loss: 2.8261481228695122

Epoch: 5| Step: 6
Training loss: 3.4380688667297363
Validation loss: 2.873843131526824

Epoch: 5| Step: 7
Training loss: 2.7597720623016357
Validation loss: 2.8704523424948416

Epoch: 5| Step: 8
Training loss: 2.9302632808685303
Validation loss: 2.8411801143359114

Epoch: 5| Step: 9
Training loss: 2.682816505432129
Validation loss: 2.8087094650473645

Epoch: 5| Step: 10
Training loss: 2.8255274295806885
Validation loss: 2.7975763249140915

Epoch: 24| Step: 0
Training loss: 2.9447808265686035
Validation loss: 2.8072034774288053

Epoch: 5| Step: 1
Training loss: 3.0958969593048096
Validation loss: 2.820478544440321

Epoch: 5| Step: 2
Training loss: 2.7778842449188232
Validation loss: 2.8296785072613786

Epoch: 5| Step: 3
Training loss: 2.6608242988586426
Validation loss: 2.810065192560996

Epoch: 5| Step: 4
Training loss: 3.117128610610962
Validation loss: 2.7913946695225214

Epoch: 5| Step: 5
Training loss: 2.574647903442383
Validation loss: 2.778301533832345

Epoch: 5| Step: 6
Training loss: 2.583221912384033
Validation loss: 2.7736175265363467

Epoch: 5| Step: 7
Training loss: 3.666503429412842
Validation loss: 2.775646763463174

Epoch: 5| Step: 8
Training loss: 3.44744873046875
Validation loss: 2.774031562189902

Epoch: 5| Step: 9
Training loss: 2.5947015285491943
Validation loss: 2.7631245966880553

Epoch: 5| Step: 10
Training loss: 2.691436767578125
Validation loss: 2.7472766189165014

Epoch: 25| Step: 0
Training loss: 2.4353079795837402
Validation loss: 2.7420695622762046

Epoch: 5| Step: 1
Training loss: 2.486506938934326
Validation loss: 2.7280553694694274

Epoch: 5| Step: 2
Training loss: 3.4220218658447266
Validation loss: 2.72042110402097

Epoch: 5| Step: 3
Training loss: 3.5020408630371094
Validation loss: 2.7008908640953804

Epoch: 5| Step: 4
Training loss: 3.364708423614502
Validation loss: 2.6907071887805896

Epoch: 5| Step: 5
Training loss: 3.05548357963562
Validation loss: 2.6858334823321273

Epoch: 5| Step: 6
Training loss: 2.5604867935180664
Validation loss: 2.692072686328683

Epoch: 5| Step: 7
Training loss: 3.0148212909698486
Validation loss: 2.695079086929239

Epoch: 5| Step: 8
Training loss: 2.6752350330352783
Validation loss: 2.7219742190453315

Epoch: 5| Step: 9
Training loss: 1.8955013751983643
Validation loss: 2.7207397209700717

Epoch: 5| Step: 10
Training loss: 3.200455665588379
Validation loss: 2.7504618680605324

Epoch: 26| Step: 0
Training loss: 2.595916509628296
Validation loss: 2.7020820597166657

Epoch: 5| Step: 1
Training loss: 2.4603686332702637
Validation loss: 2.6804425280581237

Epoch: 5| Step: 2
Training loss: 3.38688588142395
Validation loss: 2.703796289300406

Epoch: 5| Step: 3
Training loss: 3.20470929145813
Validation loss: 2.6955443377135904

Epoch: 5| Step: 4
Training loss: 3.5761444568634033
Validation loss: 2.694017215441632

Epoch: 5| Step: 5
Training loss: 1.952347993850708
Validation loss: 2.686135148489347

Epoch: 5| Step: 6
Training loss: 2.7485740184783936
Validation loss: 2.6872692877246487

Epoch: 5| Step: 7
Training loss: 2.8454062938690186
Validation loss: 2.676484966790804

Epoch: 5| Step: 8
Training loss: 2.8744540214538574
Validation loss: 2.6676016443519184

Epoch: 5| Step: 9
Training loss: 3.424412488937378
Validation loss: 2.6666619854588665

Epoch: 5| Step: 10
Training loss: 2.2160487174987793
Validation loss: 2.6646997697891726

Epoch: 27| Step: 0
Training loss: 2.604355573654175
Validation loss: 2.666024931015507

Epoch: 5| Step: 1
Training loss: 3.149418592453003
Validation loss: 2.673706926325316

Epoch: 5| Step: 2
Training loss: 3.0300235748291016
Validation loss: 2.6751750643535326

Epoch: 5| Step: 3
Training loss: 2.590369701385498
Validation loss: 2.65533737726109

Epoch: 5| Step: 4
Training loss: 3.0037479400634766
Validation loss: 2.6543221063511346

Epoch: 5| Step: 5
Training loss: 2.4779040813446045
Validation loss: 2.657618240643573

Epoch: 5| Step: 6
Training loss: 2.195239305496216
Validation loss: 2.6695975501050233

Epoch: 5| Step: 7
Training loss: 3.1076204776763916
Validation loss: 2.6801851898111324

Epoch: 5| Step: 8
Training loss: 2.5705103874206543
Validation loss: 2.6832461946754047

Epoch: 5| Step: 9
Training loss: 3.1077487468719482
Validation loss: 2.665729697032641

Epoch: 5| Step: 10
Training loss: 3.478473663330078
Validation loss: 2.645923565792781

Epoch: 28| Step: 0
Training loss: 3.111445426940918
Validation loss: 2.6396684851697696

Epoch: 5| Step: 1
Training loss: 3.234205722808838
Validation loss: 2.6406291659160326

Epoch: 5| Step: 2
Training loss: 2.2005672454833984
Validation loss: 2.6455398618534045

Epoch: 5| Step: 3
Training loss: 3.0809130668640137
Validation loss: 2.64486599481234

Epoch: 5| Step: 4
Training loss: 3.069504976272583
Validation loss: 2.642188684914702

Epoch: 5| Step: 5
Training loss: 2.582780361175537
Validation loss: 2.640513289359308

Epoch: 5| Step: 6
Training loss: 2.8854668140411377
Validation loss: 2.6412257327828357

Epoch: 5| Step: 7
Training loss: 3.501589298248291
Validation loss: 2.6383897924935944

Epoch: 5| Step: 8
Training loss: 2.513280153274536
Validation loss: 2.6318490479582097

Epoch: 5| Step: 9
Training loss: 3.0446038246154785
Validation loss: 2.6320791013779177

Epoch: 5| Step: 10
Training loss: 1.6283082962036133
Validation loss: 2.6284782245594966

Epoch: 29| Step: 0
Training loss: 3.0885329246520996
Validation loss: 2.6293277509750856

Epoch: 5| Step: 1
Training loss: 2.874056577682495
Validation loss: 2.6343673377908687

Epoch: 5| Step: 2
Training loss: 3.0607950687408447
Validation loss: 2.634159316298782

Epoch: 5| Step: 3
Training loss: 3.6524062156677246
Validation loss: 2.63980342495826

Epoch: 5| Step: 4
Training loss: 2.5311150550842285
Validation loss: 2.634593394494826

Epoch: 5| Step: 5
Training loss: 2.222289562225342
Validation loss: 2.639255949245986

Epoch: 5| Step: 6
Training loss: 2.662315845489502
Validation loss: 2.6253775294109056

Epoch: 5| Step: 7
Training loss: 2.274247646331787
Validation loss: 2.6171754508890133

Epoch: 5| Step: 8
Training loss: 2.91418719291687
Validation loss: 2.6255044475678475

Epoch: 5| Step: 9
Training loss: 2.959628105163574
Validation loss: 2.6274389195185837

Epoch: 5| Step: 10
Training loss: 2.648691415786743
Validation loss: 2.639522075653076

Epoch: 30| Step: 0
Training loss: 2.9278323650360107
Validation loss: 2.634116070244902

Epoch: 5| Step: 1
Training loss: 2.3243777751922607
Validation loss: 2.6233076869800525

Epoch: 5| Step: 2
Training loss: 3.253528118133545
Validation loss: 2.622261639564268

Epoch: 5| Step: 3
Training loss: 3.182539463043213
Validation loss: 2.624112641939553

Epoch: 5| Step: 4
Training loss: 2.613795757293701
Validation loss: 2.627186921335036

Epoch: 5| Step: 5
Training loss: 2.652566909790039
Validation loss: 2.6337699787591093

Epoch: 5| Step: 6
Training loss: 2.927367687225342
Validation loss: 2.6317991415659585

Epoch: 5| Step: 7
Training loss: 3.418510913848877
Validation loss: 2.642366914338963

Epoch: 5| Step: 8
Training loss: 2.756300449371338
Validation loss: 2.648251856527021

Epoch: 5| Step: 9
Training loss: 2.750420093536377
Validation loss: 2.6482037882651053

Epoch: 5| Step: 10
Training loss: 1.9569042921066284
Validation loss: 2.635886382031184

Epoch: 31| Step: 0
Training loss: 1.740545630455017
Validation loss: 2.633399994142594

Epoch: 5| Step: 1
Training loss: 2.075129270553589
Validation loss: 2.6254285227867866

Epoch: 5| Step: 2
Training loss: 3.2966041564941406
Validation loss: 2.624718955768052

Epoch: 5| Step: 3
Training loss: 3.421245574951172
Validation loss: 2.6249145128393687

Epoch: 5| Step: 4
Training loss: 1.9962739944458008
Validation loss: 2.6181234826323805

Epoch: 5| Step: 5
Training loss: 2.9158997535705566
Validation loss: 2.6141406182319886

Epoch: 5| Step: 6
Training loss: 2.8346664905548096
Validation loss: 2.616650714669176

Epoch: 5| Step: 7
Training loss: 2.4937355518341064
Validation loss: 2.6199724469133603

Epoch: 5| Step: 8
Training loss: 3.2904839515686035
Validation loss: 2.62553386534414

Epoch: 5| Step: 9
Training loss: 3.6257622241973877
Validation loss: 2.6305894595320507

Epoch: 5| Step: 10
Training loss: 3.1210498809814453
Validation loss: 2.618587806660642

Epoch: 32| Step: 0
Training loss: 2.5430307388305664
Validation loss: 2.6110727017925632

Epoch: 5| Step: 1
Training loss: 2.8385794162750244
Validation loss: 2.6100701285946752

Epoch: 5| Step: 2
Training loss: 2.69377064704895
Validation loss: 2.6101613557466896

Epoch: 5| Step: 3
Training loss: 2.821934461593628
Validation loss: 2.614743355781801

Epoch: 5| Step: 4
Training loss: 3.403081178665161
Validation loss: 2.6176918950132144

Epoch: 5| Step: 5
Training loss: 2.506779193878174
Validation loss: 2.612768429581837

Epoch: 5| Step: 6
Training loss: 2.5819499492645264
Validation loss: 2.614281628721504

Epoch: 5| Step: 7
Training loss: 3.2349636554718018
Validation loss: 2.6097234705443024

Epoch: 5| Step: 8
Training loss: 2.358739137649536
Validation loss: 2.6137440704530284

Epoch: 5| Step: 9
Training loss: 2.1148781776428223
Validation loss: 2.6183271023534958

Epoch: 5| Step: 10
Training loss: 3.8412749767303467
Validation loss: 2.628960722236223

Epoch: 33| Step: 0
Training loss: 2.6545331478118896
Validation loss: 2.633703754794213

Epoch: 5| Step: 1
Training loss: 2.6945419311523438
Validation loss: 2.6279272366595525

Epoch: 5| Step: 2
Training loss: 2.6621813774108887
Validation loss: 2.6208743792708202

Epoch: 5| Step: 3
Training loss: 2.5422306060791016
Validation loss: 2.6022922710705827

Epoch: 5| Step: 4
Training loss: 2.747509717941284
Validation loss: 2.6030555514879126

Epoch: 5| Step: 5
Training loss: 3.1505942344665527
Validation loss: 2.594652627104072

Epoch: 5| Step: 6
Training loss: 2.4460349082946777
Validation loss: 2.593910642849502

Epoch: 5| Step: 7
Training loss: 3.4084019660949707
Validation loss: 2.5947419340892504

Epoch: 5| Step: 8
Training loss: 2.6522953510284424
Validation loss: 2.588956763667445

Epoch: 5| Step: 9
Training loss: 2.8792202472686768
Validation loss: 2.5906946069450787

Epoch: 5| Step: 10
Training loss: 2.861995220184326
Validation loss: 2.5897741804840746

Epoch: 34| Step: 0
Training loss: 3.1843161582946777
Validation loss: 2.5855505953552904

Epoch: 5| Step: 1
Training loss: 2.9311909675598145
Validation loss: 2.592684643242949

Epoch: 5| Step: 2
Training loss: 2.3804101943969727
Validation loss: 2.593304229039018

Epoch: 5| Step: 3
Training loss: 2.1740410327911377
Validation loss: 2.594809188637682

Epoch: 5| Step: 4
Training loss: 2.828787326812744
Validation loss: 2.5847520366791756

Epoch: 5| Step: 5
Training loss: 3.6302685737609863
Validation loss: 2.585883614837482

Epoch: 5| Step: 6
Training loss: 2.958800792694092
Validation loss: 2.5833116269880727

Epoch: 5| Step: 7
Training loss: 3.1572091579437256
Validation loss: 2.5812858676397674

Epoch: 5| Step: 8
Training loss: 2.6445491313934326
Validation loss: 2.5841357656704482

Epoch: 5| Step: 9
Training loss: 1.5690721273422241
Validation loss: 2.583175592525031

Epoch: 5| Step: 10
Training loss: 3.167006731033325
Validation loss: 2.5857085694548902

Epoch: 35| Step: 0
Training loss: 1.9394276142120361
Validation loss: 2.581980833443262

Epoch: 5| Step: 1
Training loss: 3.0598363876342773
Validation loss: 2.57990199776106

Epoch: 5| Step: 2
Training loss: 2.348381519317627
Validation loss: 2.574337372215845

Epoch: 5| Step: 3
Training loss: 2.780580759048462
Validation loss: 2.5764317512512207

Epoch: 5| Step: 4
Training loss: 3.2142059803009033
Validation loss: 2.5837218017988306

Epoch: 5| Step: 5
Training loss: 3.225435733795166
Validation loss: 2.5835799529988277

Epoch: 5| Step: 6
Training loss: 2.832188129425049
Validation loss: 2.5840071939652964

Epoch: 5| Step: 7
Training loss: 2.1934914588928223
Validation loss: 2.5921749325208765

Epoch: 5| Step: 8
Training loss: 3.1228995323181152
Validation loss: 2.5883210141171693

Epoch: 5| Step: 9
Training loss: 2.7244393825531006
Validation loss: 2.5837509221928094

Epoch: 5| Step: 10
Training loss: 3.1128439903259277
Validation loss: 2.583192963753977

Epoch: 36| Step: 0
Training loss: 2.85385799407959
Validation loss: 2.5885592634959886

Epoch: 5| Step: 1
Training loss: 2.6759772300720215
Validation loss: 2.5912027077008317

Epoch: 5| Step: 2
Training loss: 2.798807144165039
Validation loss: 2.591466998541227

Epoch: 5| Step: 3
Training loss: 2.572390079498291
Validation loss: 2.583821024945987

Epoch: 5| Step: 4
Training loss: 2.7759575843811035
Validation loss: 2.5871041602985834

Epoch: 5| Step: 5
Training loss: 2.51265287399292
Validation loss: 2.589131873141053

Epoch: 5| Step: 6
Training loss: 3.007416248321533
Validation loss: 2.5811405412612425

Epoch: 5| Step: 7
Training loss: 2.998703956604004
Validation loss: 2.583091764039891

Epoch: 5| Step: 8
Training loss: 3.1864571571350098
Validation loss: 2.5750952254059496

Epoch: 5| Step: 9
Training loss: 1.896471381187439
Validation loss: 2.573033650716146

Epoch: 5| Step: 10
Training loss: 3.2371928691864014
Validation loss: 2.571937668708063

Epoch: 37| Step: 0
Training loss: 3.5268821716308594
Validation loss: 2.57288146275346

Epoch: 5| Step: 1
Training loss: 2.768536329269409
Validation loss: 2.5722928611181115

Epoch: 5| Step: 2
Training loss: 3.0477123260498047
Validation loss: 2.569875460799022

Epoch: 5| Step: 3
Training loss: 2.62654185295105
Validation loss: 2.5666627319910194

Epoch: 5| Step: 4
Training loss: 2.166760206222534
Validation loss: 2.5702892990522486

Epoch: 5| Step: 5
Training loss: 3.0560898780822754
Validation loss: 2.5703781548366753

Epoch: 5| Step: 6
Training loss: 2.911937713623047
Validation loss: 2.5696718744052354

Epoch: 5| Step: 7
Training loss: 2.8969948291778564
Validation loss: 2.567181659001176

Epoch: 5| Step: 8
Training loss: 2.4292564392089844
Validation loss: 2.5675462650996383

Epoch: 5| Step: 9
Training loss: 2.1202571392059326
Validation loss: 2.5635879834493003

Epoch: 5| Step: 10
Training loss: 2.806922435760498
Validation loss: 2.586292036118046

Epoch: 38| Step: 0
Training loss: 2.671466112136841
Validation loss: 2.5753178237586893

Epoch: 5| Step: 1
Training loss: 3.0251059532165527
Validation loss: 2.565384872498051

Epoch: 5| Step: 2
Training loss: 3.1455366611480713
Validation loss: 2.565903909744755

Epoch: 5| Step: 3
Training loss: 2.427199363708496
Validation loss: 2.569196275485459

Epoch: 5| Step: 4
Training loss: 2.382599353790283
Validation loss: 2.5625891377848964

Epoch: 5| Step: 5
Training loss: 2.406486988067627
Validation loss: 2.5598486956729682

Epoch: 5| Step: 6
Training loss: 2.827993869781494
Validation loss: 2.563325633284866

Epoch: 5| Step: 7
Training loss: 3.047617197036743
Validation loss: 2.563915214230937

Epoch: 5| Step: 8
Training loss: 2.8958301544189453
Validation loss: 2.5623928705851235

Epoch: 5| Step: 9
Training loss: 3.273275375366211
Validation loss: 2.5657038355386383

Epoch: 5| Step: 10
Training loss: 2.0325493812561035
Validation loss: 2.5748053904502624

Epoch: 39| Step: 0
Training loss: 2.34065318107605
Validation loss: 2.5666311940839215

Epoch: 5| Step: 1
Training loss: 2.783778190612793
Validation loss: 2.567454855929139

Epoch: 5| Step: 2
Training loss: 3.0229368209838867
Validation loss: 2.571006223719607

Epoch: 5| Step: 3
Training loss: 3.6216537952423096
Validation loss: 2.5732716488581833

Epoch: 5| Step: 4
Training loss: 2.139254093170166
Validation loss: 2.5684638959105297

Epoch: 5| Step: 5
Training loss: 1.7281010150909424
Validation loss: 2.56819135655639

Epoch: 5| Step: 6
Training loss: 2.637533664703369
Validation loss: 2.5623541621751684

Epoch: 5| Step: 7
Training loss: 3.8052191734313965
Validation loss: 2.5656259495724916

Epoch: 5| Step: 8
Training loss: 3.0107383728027344
Validation loss: 2.5651231863165416

Epoch: 5| Step: 9
Training loss: 2.8036468029022217
Validation loss: 2.567915601115073

Epoch: 5| Step: 10
Training loss: 2.210822820663452
Validation loss: 2.560158693662254

Epoch: 40| Step: 0
Training loss: 3.1884570121765137
Validation loss: 2.5533429858505086

Epoch: 5| Step: 1
Training loss: 2.5300862789154053
Validation loss: 2.5553129693513275

Epoch: 5| Step: 2
Training loss: 2.035104274749756
Validation loss: 2.554187872076547

Epoch: 5| Step: 3
Training loss: 3.13594126701355
Validation loss: 2.551499564160583

Epoch: 5| Step: 4
Training loss: 2.4613332748413086
Validation loss: 2.548160404287359

Epoch: 5| Step: 5
Training loss: 2.8612899780273438
Validation loss: 2.5576990368545696

Epoch: 5| Step: 6
Training loss: 2.781862258911133
Validation loss: 2.5562473163809827

Epoch: 5| Step: 7
Training loss: 2.7930092811584473
Validation loss: 2.5632520132167365

Epoch: 5| Step: 8
Training loss: 2.657575845718384
Validation loss: 2.5657648014765915

Epoch: 5| Step: 9
Training loss: 2.407351016998291
Validation loss: 2.5599145658554567

Epoch: 5| Step: 10
Training loss: 3.3216896057128906
Validation loss: 2.571204129085746

Epoch: 41| Step: 0
Training loss: 3.0975441932678223
Validation loss: 2.5637923850808093

Epoch: 5| Step: 1
Training loss: 2.6032116413116455
Validation loss: 2.5622982286637828

Epoch: 5| Step: 2
Training loss: 3.0273680686950684
Validation loss: 2.5550260954005743

Epoch: 5| Step: 3
Training loss: 3.359870433807373
Validation loss: 2.5563466497646865

Epoch: 5| Step: 4
Training loss: 3.1072158813476562
Validation loss: 2.5542037025574715

Epoch: 5| Step: 5
Training loss: 2.567971706390381
Validation loss: 2.553761224592886

Epoch: 5| Step: 6
Training loss: 2.461596965789795
Validation loss: 2.5658447845007784

Epoch: 5| Step: 7
Training loss: 1.7397844791412354
Validation loss: 2.622183499797698

Epoch: 5| Step: 8
Training loss: 2.688645124435425
Validation loss: 2.646755682524814

Epoch: 5| Step: 9
Training loss: 3.2928385734558105
Validation loss: 2.655644319390738

Epoch: 5| Step: 10
Training loss: 2.4337692260742188
Validation loss: 2.641564561474708

Epoch: 42| Step: 0
Training loss: 3.3084609508514404
Validation loss: 2.5983204739068144

Epoch: 5| Step: 1
Training loss: 2.369032382965088
Validation loss: 2.5752496796269573

Epoch: 5| Step: 2
Training loss: 2.076914072036743
Validation loss: 2.580216323175738

Epoch: 5| Step: 3
Training loss: 3.1704745292663574
Validation loss: 2.6088361381202616

Epoch: 5| Step: 4
Training loss: 2.9767050743103027
Validation loss: 2.6845835613948044

Epoch: 5| Step: 5
Training loss: 2.699409246444702
Validation loss: 2.663052205116518

Epoch: 5| Step: 6
Training loss: 2.433481216430664
Validation loss: 2.599101153753137

Epoch: 5| Step: 7
Training loss: 2.936762571334839
Validation loss: 2.5802372091559955

Epoch: 5| Step: 8
Training loss: 2.888120174407959
Validation loss: 2.573800738139819

Epoch: 5| Step: 9
Training loss: 3.1852636337280273
Validation loss: 2.5823719834768646

Epoch: 5| Step: 10
Training loss: 2.653186082839966
Validation loss: 2.5900450880809496

Epoch: 43| Step: 0
Training loss: 2.801035165786743
Validation loss: 2.594515082656696

Epoch: 5| Step: 1
Training loss: 2.6256983280181885
Validation loss: 2.6050686067150486

Epoch: 5| Step: 2
Training loss: 2.672541379928589
Validation loss: 2.607129781476913

Epoch: 5| Step: 3
Training loss: 3.7079739570617676
Validation loss: 2.6036861891387613

Epoch: 5| Step: 4
Training loss: 2.5492305755615234
Validation loss: 2.5993614888960317

Epoch: 5| Step: 5
Training loss: 2.381295919418335
Validation loss: 2.5892277558644614

Epoch: 5| Step: 6
Training loss: 2.787484645843506
Validation loss: 2.5836194330646145

Epoch: 5| Step: 7
Training loss: 2.3551716804504395
Validation loss: 2.575697422027588

Epoch: 5| Step: 8
Training loss: 3.126325845718384
Validation loss: 2.5738459479424263

Epoch: 5| Step: 9
Training loss: 2.511620044708252
Validation loss: 2.575077364521642

Epoch: 5| Step: 10
Training loss: 2.946901321411133
Validation loss: 2.568325306779595

Epoch: 44| Step: 0
Training loss: 2.9712445735931396
Validation loss: 2.5695142053788707

Epoch: 5| Step: 1
Training loss: 2.8825414180755615
Validation loss: 2.5657747830114057

Epoch: 5| Step: 2
Training loss: 2.821241855621338
Validation loss: 2.561995747268841

Epoch: 5| Step: 3
Training loss: 2.345815658569336
Validation loss: 2.5606257120768228

Epoch: 5| Step: 4
Training loss: 2.659966230392456
Validation loss: 2.5587184006167996

Epoch: 5| Step: 5
Training loss: 2.738121747970581
Validation loss: 2.551968602723973

Epoch: 5| Step: 6
Training loss: 2.9936275482177734
Validation loss: 2.5439242727013043

Epoch: 5| Step: 7
Training loss: 2.5416812896728516
Validation loss: 2.529847514244818

Epoch: 5| Step: 8
Training loss: 2.650132656097412
Validation loss: 2.524764237865325

Epoch: 5| Step: 9
Training loss: 2.6286582946777344
Validation loss: 2.5226483729577835

Epoch: 5| Step: 10
Training loss: 2.939535617828369
Validation loss: 2.524156332015991

Epoch: 45| Step: 0
Training loss: 3.073826313018799
Validation loss: 2.5317436854044595

Epoch: 5| Step: 1
Training loss: 2.486388683319092
Validation loss: 2.5306854888957035

Epoch: 5| Step: 2
Training loss: 2.8636655807495117
Validation loss: 2.527921886854274

Epoch: 5| Step: 3
Training loss: 2.440746307373047
Validation loss: 2.526955989099318

Epoch: 5| Step: 4
Training loss: 2.5992114543914795
Validation loss: 2.527040009857506

Epoch: 5| Step: 5
Training loss: 2.730524778366089
Validation loss: 2.5395802041535736

Epoch: 5| Step: 6
Training loss: 2.2120614051818848
Validation loss: 2.5474813804831555

Epoch: 5| Step: 7
Training loss: 2.69299578666687
Validation loss: 2.523811307004703

Epoch: 5| Step: 8
Training loss: 2.7197067737579346
Validation loss: 2.5212194406858055

Epoch: 5| Step: 9
Training loss: 2.8390417098999023
Validation loss: 2.5227310144773094

Epoch: 5| Step: 10
Training loss: 3.424886703491211
Validation loss: 2.5200349105301725

Epoch: 46| Step: 0
Training loss: 2.272326946258545
Validation loss: 2.522921403249105

Epoch: 5| Step: 1
Training loss: 2.9061970710754395
Validation loss: 2.521184952028336

Epoch: 5| Step: 2
Training loss: 2.4239001274108887
Validation loss: 2.5226358111186693

Epoch: 5| Step: 3
Training loss: 2.6375503540039062
Validation loss: 2.5288893253572526

Epoch: 5| Step: 4
Training loss: 2.9862704277038574
Validation loss: 2.525319440390474

Epoch: 5| Step: 5
Training loss: 2.82200026512146
Validation loss: 2.5202387789244294

Epoch: 5| Step: 6
Training loss: 3.1503710746765137
Validation loss: 2.518292369381074

Epoch: 5| Step: 7
Training loss: 1.8824536800384521
Validation loss: 2.5165918591201946

Epoch: 5| Step: 8
Training loss: 3.0861644744873047
Validation loss: 2.520315641997963

Epoch: 5| Step: 9
Training loss: 3.2257907390594482
Validation loss: 2.52625967866631

Epoch: 5| Step: 10
Training loss: 2.399134397506714
Validation loss: 2.5336749886953704

Epoch: 47| Step: 0
Training loss: 3.097717523574829
Validation loss: 2.5246698369262037

Epoch: 5| Step: 1
Training loss: 2.726945161819458
Validation loss: 2.5214686214282946

Epoch: 5| Step: 2
Training loss: 3.1415164470672607
Validation loss: 2.521551832076042

Epoch: 5| Step: 3
Training loss: 2.999612808227539
Validation loss: 2.525851539386216

Epoch: 5| Step: 4
Training loss: 2.935202121734619
Validation loss: 2.5439256416854037

Epoch: 5| Step: 5
Training loss: 2.5256659984588623
Validation loss: 2.563539581914102

Epoch: 5| Step: 6
Training loss: 3.1397550106048584
Validation loss: 2.5543017566844983

Epoch: 5| Step: 7
Training loss: 2.364774227142334
Validation loss: 2.537712481714064

Epoch: 5| Step: 8
Training loss: 2.4274940490722656
Validation loss: 2.5215793707037486

Epoch: 5| Step: 9
Training loss: 2.307513475418091
Validation loss: 2.5021997959383073

Epoch: 5| Step: 10
Training loss: 2.134178638458252
Validation loss: 2.5017694119484193

Epoch: 48| Step: 0
Training loss: 2.756847858428955
Validation loss: 2.509834389532766

Epoch: 5| Step: 1
Training loss: 2.34006929397583
Validation loss: 2.526798084218015

Epoch: 5| Step: 2
Training loss: 2.5190770626068115
Validation loss: 2.5345321829601

Epoch: 5| Step: 3
Training loss: 2.545494556427002
Validation loss: 2.5426037875554894

Epoch: 5| Step: 4
Training loss: 2.846277952194214
Validation loss: 2.5404558745763635

Epoch: 5| Step: 5
Training loss: 2.7597696781158447
Validation loss: 2.5235584192378546

Epoch: 5| Step: 6
Training loss: 2.6196677684783936
Validation loss: 2.5110756005010297

Epoch: 5| Step: 7
Training loss: 2.734902858734131
Validation loss: 2.500454710375878

Epoch: 5| Step: 8
Training loss: 2.635911226272583
Validation loss: 2.498126555514592

Epoch: 5| Step: 9
Training loss: 2.8825035095214844
Validation loss: 2.493133916649767

Epoch: 5| Step: 10
Training loss: 3.485548734664917
Validation loss: 2.4928389518491683

Epoch: 49| Step: 0
Training loss: 2.2831082344055176
Validation loss: 2.494422617778983

Epoch: 5| Step: 1
Training loss: 2.3843581676483154
Validation loss: 2.5110872484022573

Epoch: 5| Step: 2
Training loss: 3.0922281742095947
Validation loss: 2.5233962125675653

Epoch: 5| Step: 3
Training loss: 2.189404010772705
Validation loss: 2.5414163220313286

Epoch: 5| Step: 4
Training loss: 3.0662808418273926
Validation loss: 2.5705276689221783

Epoch: 5| Step: 5
Training loss: 2.9672324657440186
Validation loss: 2.579769770304362

Epoch: 5| Step: 6
Training loss: 3.262620449066162
Validation loss: 2.5830502125524704

Epoch: 5| Step: 7
Training loss: 2.525264024734497
Validation loss: 2.5438821443947415

Epoch: 5| Step: 8
Training loss: 3.205911159515381
Validation loss: 2.5284605256972776

Epoch: 5| Step: 9
Training loss: 2.4532406330108643
Validation loss: 2.5098909921543573

Epoch: 5| Step: 10
Training loss: 2.294790267944336
Validation loss: 2.495538152674193

Epoch: 50| Step: 0
Training loss: 2.6177031993865967
Validation loss: 2.4828854260906095

Epoch: 5| Step: 1
Training loss: 2.5959506034851074
Validation loss: 2.484785205574446

Epoch: 5| Step: 2
Training loss: 3.0778162479400635
Validation loss: 2.485493234408799

Epoch: 5| Step: 3
Training loss: 3.1288256645202637
Validation loss: 2.49533611471935

Epoch: 5| Step: 4
Training loss: 2.2992680072784424
Validation loss: 2.5023344409081245

Epoch: 5| Step: 5
Training loss: 2.7054007053375244
Validation loss: 2.511637541555589

Epoch: 5| Step: 6
Training loss: 2.4922924041748047
Validation loss: 2.508333045949218

Epoch: 5| Step: 7
Training loss: 2.83465838432312
Validation loss: 2.5084921108779086

Epoch: 5| Step: 8
Training loss: 2.859745502471924
Validation loss: 2.513189541396274

Epoch: 5| Step: 9
Training loss: 2.2921249866485596
Validation loss: 2.499755231283044

Epoch: 5| Step: 10
Training loss: 2.8949458599090576
Validation loss: 2.4850377446861676

Epoch: 51| Step: 0
Training loss: 2.895749092102051
Validation loss: 2.4838909205570014

Epoch: 5| Step: 1
Training loss: 2.452627420425415
Validation loss: 2.4838011956984

Epoch: 5| Step: 2
Training loss: 2.4104740619659424
Validation loss: 2.4814674879914973

Epoch: 5| Step: 3
Training loss: 3.1428520679473877
Validation loss: 2.479915019004576

Epoch: 5| Step: 4
Training loss: 3.034733295440674
Validation loss: 2.482554740803216

Epoch: 5| Step: 5
Training loss: 2.4325613975524902
Validation loss: 2.485140715875933

Epoch: 5| Step: 6
Training loss: 3.0789880752563477
Validation loss: 2.4813421259644213

Epoch: 5| Step: 7
Training loss: 2.375176191329956
Validation loss: 2.482831039736348

Epoch: 5| Step: 8
Training loss: 2.8966667652130127
Validation loss: 2.4824613678839897

Epoch: 5| Step: 9
Training loss: 2.398141384124756
Validation loss: 2.4777486529401553

Epoch: 5| Step: 10
Training loss: 2.433612585067749
Validation loss: 2.474143771715062

Epoch: 52| Step: 0
Training loss: 2.6775903701782227
Validation loss: 2.4768392757702897

Epoch: 5| Step: 1
Training loss: 2.6200480461120605
Validation loss: 2.478017576279179

Epoch: 5| Step: 2
Training loss: 2.761505126953125
Validation loss: 2.4758971711640716

Epoch: 5| Step: 3
Training loss: 3.2423102855682373
Validation loss: 2.480565068542316

Epoch: 5| Step: 4
Training loss: 3.230787754058838
Validation loss: 2.4791011579575075

Epoch: 5| Step: 5
Training loss: 2.173448085784912
Validation loss: 2.4833395814382904

Epoch: 5| Step: 6
Training loss: 2.656668186187744
Validation loss: 2.5183195580718336

Epoch: 5| Step: 7
Training loss: 2.6738412380218506
Validation loss: 2.4734262522830757

Epoch: 5| Step: 8
Training loss: 2.80118989944458
Validation loss: 2.4747263693040416

Epoch: 5| Step: 9
Training loss: 2.219709873199463
Validation loss: 2.4723274887249036

Epoch: 5| Step: 10
Training loss: 2.450575113296509
Validation loss: 2.485397761867892

Epoch: 53| Step: 0
Training loss: 2.1873066425323486
Validation loss: 2.5005622909915064

Epoch: 5| Step: 1
Training loss: 2.4547886848449707
Validation loss: 2.4920310256301716

Epoch: 5| Step: 2
Training loss: 2.379085063934326
Validation loss: 2.499473738413985

Epoch: 5| Step: 3
Training loss: 2.836554527282715
Validation loss: 2.494080251263034

Epoch: 5| Step: 4
Training loss: 3.1263976097106934
Validation loss: 2.4884505887185373

Epoch: 5| Step: 5
Training loss: 2.4256720542907715
Validation loss: 2.478051459917458

Epoch: 5| Step: 6
Training loss: 2.581174373626709
Validation loss: 2.4770617677319433

Epoch: 5| Step: 7
Training loss: 3.4637961387634277
Validation loss: 2.471019985855267

Epoch: 5| Step: 8
Training loss: 2.7172768115997314
Validation loss: 2.473343679981847

Epoch: 5| Step: 9
Training loss: 2.685192584991455
Validation loss: 2.464903921209356

Epoch: 5| Step: 10
Training loss: 2.7632498741149902
Validation loss: 2.4655774972772084

Epoch: 54| Step: 0
Training loss: 3.1935653686523438
Validation loss: 2.4664538368102042

Epoch: 5| Step: 1
Training loss: 2.4180188179016113
Validation loss: 2.4661152875551613

Epoch: 5| Step: 2
Training loss: 2.489478588104248
Validation loss: 2.4634992281595864

Epoch: 5| Step: 3
Training loss: 3.2365832328796387
Validation loss: 2.4683847068458475

Epoch: 5| Step: 4
Training loss: 2.2700953483581543
Validation loss: 2.4704109084221626

Epoch: 5| Step: 5
Training loss: 2.92280650138855
Validation loss: 2.4747194961834977

Epoch: 5| Step: 6
Training loss: 2.191458225250244
Validation loss: 2.4796654101341002

Epoch: 5| Step: 7
Training loss: 2.1566638946533203
Validation loss: 2.4826527872393207

Epoch: 5| Step: 8
Training loss: 2.798489809036255
Validation loss: 2.4772745088864396

Epoch: 5| Step: 9
Training loss: 2.7897725105285645
Validation loss: 2.5005687257295013

Epoch: 5| Step: 10
Training loss: 3.0126640796661377
Validation loss: 2.504137785203995

Epoch: 55| Step: 0
Training loss: 3.0069515705108643
Validation loss: 2.49524067037849

Epoch: 5| Step: 1
Training loss: 2.2358813285827637
Validation loss: 2.487139353188135

Epoch: 5| Step: 2
Training loss: 2.1623730659484863
Validation loss: 2.4757421606330463

Epoch: 5| Step: 3
Training loss: 2.6837849617004395
Validation loss: 2.4666401827207176

Epoch: 5| Step: 4
Training loss: 2.879199266433716
Validation loss: 2.465946610255908

Epoch: 5| Step: 5
Training loss: 2.3840813636779785
Validation loss: 2.4632051298695226

Epoch: 5| Step: 6
Training loss: 2.7337164878845215
Validation loss: 2.4594571385332333

Epoch: 5| Step: 7
Training loss: 3.148329973220825
Validation loss: 2.4572599959629837

Epoch: 5| Step: 8
Training loss: 2.714970588684082
Validation loss: 2.459024267811929

Epoch: 5| Step: 9
Training loss: 2.7105231285095215
Validation loss: 2.460846033147586

Epoch: 5| Step: 10
Training loss: 2.7661361694335938
Validation loss: 2.4568540896138837

Epoch: 56| Step: 0
Training loss: 2.331120491027832
Validation loss: 2.4629586127496537

Epoch: 5| Step: 1
Training loss: 2.7418973445892334
Validation loss: 2.4601833538342546

Epoch: 5| Step: 2
Training loss: 2.214172840118408
Validation loss: 2.4647977916143273

Epoch: 5| Step: 3
Training loss: 3.662259578704834
Validation loss: 2.4684383151351765

Epoch: 5| Step: 4
Training loss: 2.324367046356201
Validation loss: 2.474898866427842

Epoch: 5| Step: 5
Training loss: 2.420222520828247
Validation loss: 2.484368638325763

Epoch: 5| Step: 6
Training loss: 3.204258680343628
Validation loss: 2.4823721403716714

Epoch: 5| Step: 7
Training loss: 2.8199055194854736
Validation loss: 2.477033302348147

Epoch: 5| Step: 8
Training loss: 2.3756930828094482
Validation loss: 2.476874359192387

Epoch: 5| Step: 9
Training loss: 2.474341869354248
Validation loss: 2.4759114147514425

Epoch: 5| Step: 10
Training loss: 2.8289647102355957
Validation loss: 2.475467194793045

Epoch: 57| Step: 0
Training loss: 2.7432303428649902
Validation loss: 2.4861875862203617

Epoch: 5| Step: 1
Training loss: 2.688019275665283
Validation loss: 2.4979776541392007

Epoch: 5| Step: 2
Training loss: 2.677454710006714
Validation loss: 2.511502024947956

Epoch: 5| Step: 3
Training loss: 3.284334659576416
Validation loss: 2.5356572366529897

Epoch: 5| Step: 4
Training loss: 2.8202743530273438
Validation loss: 2.5222327863016436

Epoch: 5| Step: 5
Training loss: 2.57904314994812
Validation loss: 2.5093142371023855

Epoch: 5| Step: 6
Training loss: 2.414146900177002
Validation loss: 2.4824912983884095

Epoch: 5| Step: 7
Training loss: 2.5305356979370117
Validation loss: 2.4609702787091656

Epoch: 5| Step: 8
Training loss: 2.010542154312134
Validation loss: 2.455011575452743

Epoch: 5| Step: 9
Training loss: 2.872844696044922
Validation loss: 2.4544695782405075

Epoch: 5| Step: 10
Training loss: 2.9773786067962646
Validation loss: 2.453514765667659

Epoch: 58| Step: 0
Training loss: 2.332785129547119
Validation loss: 2.452971730180966

Epoch: 5| Step: 1
Training loss: 3.0346157550811768
Validation loss: 2.461584616732854

Epoch: 5| Step: 2
Training loss: 2.547086238861084
Validation loss: 2.4590108471532024

Epoch: 5| Step: 3
Training loss: 2.717097043991089
Validation loss: 2.474351043342262

Epoch: 5| Step: 4
Training loss: 2.5669732093811035
Validation loss: 2.485175412188294

Epoch: 5| Step: 5
Training loss: 3.14723539352417
Validation loss: 2.4771084785461426

Epoch: 5| Step: 6
Training loss: 2.0889275074005127
Validation loss: 2.4637859303464174

Epoch: 5| Step: 7
Training loss: 2.4718472957611084
Validation loss: 2.4569954538858063

Epoch: 5| Step: 8
Training loss: 2.857813596725464
Validation loss: 2.4672359317861576

Epoch: 5| Step: 9
Training loss: 2.3498218059539795
Validation loss: 2.485101342201233

Epoch: 5| Step: 10
Training loss: 3.477405071258545
Validation loss: 2.4961814085642495

Epoch: 59| Step: 0
Training loss: 1.790362000465393
Validation loss: 2.500095710959486

Epoch: 5| Step: 1
Training loss: 2.5667786598205566
Validation loss: 2.4851293384387927

Epoch: 5| Step: 2
Training loss: 3.160484790802002
Validation loss: 2.472717223628875

Epoch: 5| Step: 3
Training loss: 2.9459915161132812
Validation loss: 2.4627323124998357

Epoch: 5| Step: 4
Training loss: 2.2385072708129883
Validation loss: 2.4530757780997985

Epoch: 5| Step: 5
Training loss: 2.210484027862549
Validation loss: 2.450998628011314

Epoch: 5| Step: 6
Training loss: 3.091407299041748
Validation loss: 2.4477397164990826

Epoch: 5| Step: 7
Training loss: 3.4644126892089844
Validation loss: 2.4429414656854447

Epoch: 5| Step: 8
Training loss: 2.676065683364868
Validation loss: 2.4418505455857966

Epoch: 5| Step: 9
Training loss: 3.1224586963653564
Validation loss: 2.4407932091784734

Epoch: 5| Step: 10
Training loss: 1.9186508655548096
Validation loss: 2.444482531598819

Epoch: 60| Step: 0
Training loss: 2.6919894218444824
Validation loss: 2.446447172472554

Epoch: 5| Step: 1
Training loss: 2.7917494773864746
Validation loss: 2.4457843124225573

Epoch: 5| Step: 2
Training loss: 2.0875566005706787
Validation loss: 2.4557229447108444

Epoch: 5| Step: 3
Training loss: 3.081554889678955
Validation loss: 2.4700348351591375

Epoch: 5| Step: 4
Training loss: 2.894279956817627
Validation loss: 2.4969409178662043

Epoch: 5| Step: 5
Training loss: 3.037637710571289
Validation loss: 2.5010658130850842

Epoch: 5| Step: 6
Training loss: 2.50962495803833
Validation loss: 2.487154588904432

Epoch: 5| Step: 7
Training loss: 2.7042994499206543
Validation loss: 2.4851905094679965

Epoch: 5| Step: 8
Training loss: 2.400162696838379
Validation loss: 2.4730464822502545

Epoch: 5| Step: 9
Training loss: 2.7799227237701416
Validation loss: 2.4747727353085756

Epoch: 5| Step: 10
Training loss: 2.392782211303711
Validation loss: 2.4632624374922885

Epoch: 61| Step: 0
Training loss: 2.2037413120269775
Validation loss: 2.45613177873755

Epoch: 5| Step: 1
Training loss: 2.690716505050659
Validation loss: 2.458765337544103

Epoch: 5| Step: 2
Training loss: 2.5250344276428223
Validation loss: 2.4592526625561457

Epoch: 5| Step: 3
Training loss: 2.0112385749816895
Validation loss: 2.4651303791230723

Epoch: 5| Step: 4
Training loss: 2.456166982650757
Validation loss: 2.4683370410755114

Epoch: 5| Step: 5
Training loss: 2.5896553993225098
Validation loss: 2.4496999530382055

Epoch: 5| Step: 6
Training loss: 3.0707430839538574
Validation loss: 2.445930088720014

Epoch: 5| Step: 7
Training loss: 2.9906070232391357
Validation loss: 2.4467967223095637

Epoch: 5| Step: 8
Training loss: 2.789416551589966
Validation loss: 2.442859331766764

Epoch: 5| Step: 9
Training loss: 2.746699333190918
Validation loss: 2.436874356321109

Epoch: 5| Step: 10
Training loss: 3.2902941703796387
Validation loss: 2.438890708390103

Epoch: 62| Step: 0
Training loss: 2.112928867340088
Validation loss: 2.4366983547005603

Epoch: 5| Step: 1
Training loss: 2.5003156661987305
Validation loss: 2.4369593666445826

Epoch: 5| Step: 2
Training loss: 3.266911268234253
Validation loss: 2.4348315833717264

Epoch: 5| Step: 3
Training loss: 2.921907663345337
Validation loss: 2.4352794565180296

Epoch: 5| Step: 4
Training loss: 2.027456760406494
Validation loss: 2.4341957107667

Epoch: 5| Step: 5
Training loss: 2.950403928756714
Validation loss: 2.4324406731513237

Epoch: 5| Step: 6
Training loss: 2.6440582275390625
Validation loss: 2.4337891660710818

Epoch: 5| Step: 7
Training loss: 3.1712448596954346
Validation loss: 2.4329065507458103

Epoch: 5| Step: 8
Training loss: 2.095729351043701
Validation loss: 2.438835938771566

Epoch: 5| Step: 9
Training loss: 2.4024453163146973
Validation loss: 2.4353146604312363

Epoch: 5| Step: 10
Training loss: 3.3516833782196045
Validation loss: 2.432108045906149

Epoch: 63| Step: 0
Training loss: 2.9800639152526855
Validation loss: 2.43128449942476

Epoch: 5| Step: 1
Training loss: 2.5644726753234863
Validation loss: 2.431822355075549

Epoch: 5| Step: 2
Training loss: 2.1650052070617676
Validation loss: 2.430674094025807

Epoch: 5| Step: 3
Training loss: 3.308920383453369
Validation loss: 2.4257347353043093

Epoch: 5| Step: 4
Training loss: 2.6563313007354736
Validation loss: 2.4312095898453907

Epoch: 5| Step: 5
Training loss: 2.700763463973999
Validation loss: 2.431743965354017

Epoch: 5| Step: 6
Training loss: 3.2351088523864746
Validation loss: 2.4318086536981727

Epoch: 5| Step: 7
Training loss: 2.7696757316589355
Validation loss: 2.4328506967072845

Epoch: 5| Step: 8
Training loss: 2.352578639984131
Validation loss: 2.4376384314670356

Epoch: 5| Step: 9
Training loss: 2.1517772674560547
Validation loss: 2.4353412223118607

Epoch: 5| Step: 10
Training loss: 2.2821969985961914
Validation loss: 2.4383976510775986

Epoch: 64| Step: 0
Training loss: 2.4571592807769775
Validation loss: 2.4385556072317143

Epoch: 5| Step: 1
Training loss: 2.057028293609619
Validation loss: 2.4442519910873903

Epoch: 5| Step: 2
Training loss: 3.3152599334716797
Validation loss: 2.4463640336067445

Epoch: 5| Step: 3
Training loss: 3.0322139263153076
Validation loss: 2.451152474649491

Epoch: 5| Step: 4
Training loss: 2.722604751586914
Validation loss: 2.452856553498135

Epoch: 5| Step: 5
Training loss: 3.007272243499756
Validation loss: 2.450665786702146

Epoch: 5| Step: 6
Training loss: 2.7092137336730957
Validation loss: 2.4466658817824496

Epoch: 5| Step: 7
Training loss: 2.944460153579712
Validation loss: 2.438949969507033

Epoch: 5| Step: 8
Training loss: 2.282224655151367
Validation loss: 2.4366902792325584

Epoch: 5| Step: 9
Training loss: 2.0042924880981445
Validation loss: 2.4322312237114034

Epoch: 5| Step: 10
Training loss: 2.67525315284729
Validation loss: 2.4317703708525626

Epoch: 65| Step: 0
Training loss: 2.866054058074951
Validation loss: 2.4262199863310783

Epoch: 5| Step: 1
Training loss: 2.876321792602539
Validation loss: 2.42723604940599

Epoch: 5| Step: 2
Training loss: 2.346144914627075
Validation loss: 2.4216225967612317

Epoch: 5| Step: 3
Training loss: 2.1947638988494873
Validation loss: 2.428956454800021

Epoch: 5| Step: 4
Training loss: 2.5629217624664307
Validation loss: 2.4283025982559368

Epoch: 5| Step: 5
Training loss: 3.0663797855377197
Validation loss: 2.4285171006315496

Epoch: 5| Step: 6
Training loss: 2.631819248199463
Validation loss: 2.42842161527244

Epoch: 5| Step: 7
Training loss: 3.142890691757202
Validation loss: 2.4301520547559186

Epoch: 5| Step: 8
Training loss: 2.3133983612060547
Validation loss: 2.4287253887422624

Epoch: 5| Step: 9
Training loss: 2.5144405364990234
Validation loss: 2.4342374852908555

Epoch: 5| Step: 10
Training loss: 2.5716707706451416
Validation loss: 2.44479981289115

Epoch: 66| Step: 0
Training loss: 2.7193591594696045
Validation loss: 2.4448615043394026

Epoch: 5| Step: 1
Training loss: 2.786311149597168
Validation loss: 2.43704568442478

Epoch: 5| Step: 2
Training loss: 2.78932785987854
Validation loss: 2.4384999864844867

Epoch: 5| Step: 3
Training loss: 2.3028507232666016
Validation loss: 2.435147608480146

Epoch: 5| Step: 4
Training loss: 2.8944168090820312
Validation loss: 2.431335554328016

Epoch: 5| Step: 5
Training loss: 3.1366355419158936
Validation loss: 2.425629255592182

Epoch: 5| Step: 6
Training loss: 2.442250967025757
Validation loss: 2.4183777122087378

Epoch: 5| Step: 7
Training loss: 2.5312843322753906
Validation loss: 2.411034753245692

Epoch: 5| Step: 8
Training loss: 2.6869444847106934
Validation loss: 2.4106566880338933

Epoch: 5| Step: 9
Training loss: 2.197201728820801
Validation loss: 2.408698876698812

Epoch: 5| Step: 10
Training loss: 2.584995746612549
Validation loss: 2.4081632629517586

Epoch: 67| Step: 0
Training loss: 2.8113720417022705
Validation loss: 2.409307925931869

Epoch: 5| Step: 1
Training loss: 3.069190502166748
Validation loss: 2.4055334880787838

Epoch: 5| Step: 2
Training loss: 2.11959171295166
Validation loss: 2.405490848325914

Epoch: 5| Step: 3
Training loss: 2.4896492958068848
Validation loss: 2.4092325574608258

Epoch: 5| Step: 4
Training loss: 2.533552885055542
Validation loss: 2.408705706237465

Epoch: 5| Step: 5
Training loss: 2.890589475631714
Validation loss: 2.419310820999966

Epoch: 5| Step: 6
Training loss: 2.454537868499756
Validation loss: 2.4200276251762145

Epoch: 5| Step: 7
Training loss: 2.714838743209839
Validation loss: 2.4272970179075837

Epoch: 5| Step: 8
Training loss: 2.874992847442627
Validation loss: 2.416124533581477

Epoch: 5| Step: 9
Training loss: 2.7292072772979736
Validation loss: 2.4199246193773005

Epoch: 5| Step: 10
Training loss: 2.2653253078460693
Validation loss: 2.4121808236645115

Epoch: 68| Step: 0
Training loss: 2.179157257080078
Validation loss: 2.409173401453162

Epoch: 5| Step: 1
Training loss: 2.869715452194214
Validation loss: 2.414156557411276

Epoch: 5| Step: 2
Training loss: 2.652017116546631
Validation loss: 2.406993891603203

Epoch: 5| Step: 3
Training loss: 3.1550850868225098
Validation loss: 2.4094639516645864

Epoch: 5| Step: 4
Training loss: 2.605661630630493
Validation loss: 2.4128268495682748

Epoch: 5| Step: 5
Training loss: 1.8555781841278076
Validation loss: 2.415069777478454

Epoch: 5| Step: 6
Training loss: 2.703920602798462
Validation loss: 2.4145680383969377

Epoch: 5| Step: 7
Training loss: 3.2527878284454346
Validation loss: 2.422987053471227

Epoch: 5| Step: 8
Training loss: 2.5036258697509766
Validation loss: 2.414078535572175

Epoch: 5| Step: 9
Training loss: 2.2963926792144775
Validation loss: 2.403634948115195

Epoch: 5| Step: 10
Training loss: 2.9513444900512695
Validation loss: 2.3976335448603474

Epoch: 69| Step: 0
Training loss: 3.021120071411133
Validation loss: 2.3953563039020827

Epoch: 5| Step: 1
Training loss: 3.540555477142334
Validation loss: 2.398535479781448

Epoch: 5| Step: 2
Training loss: 1.6625686883926392
Validation loss: 2.39860451093284

Epoch: 5| Step: 3
Training loss: 1.9507287740707397
Validation loss: 2.4018566762247393

Epoch: 5| Step: 4
Training loss: 2.654980182647705
Validation loss: 2.4059038405777304

Epoch: 5| Step: 5
Training loss: 3.1438026428222656
Validation loss: 2.4047397157197357

Epoch: 5| Step: 6
Training loss: 2.2719273567199707
Validation loss: 2.40732031355622

Epoch: 5| Step: 7
Training loss: 2.612079620361328
Validation loss: 2.3984004887201453

Epoch: 5| Step: 8
Training loss: 2.5629830360412598
Validation loss: 2.396693680876045

Epoch: 5| Step: 9
Training loss: 2.848998546600342
Validation loss: 2.3943975099953274

Epoch: 5| Step: 10
Training loss: 2.8804447650909424
Validation loss: 2.393041427417468

Epoch: 70| Step: 0
Training loss: 2.6099276542663574
Validation loss: 2.4012064779958417

Epoch: 5| Step: 1
Training loss: 3.13010835647583
Validation loss: 2.4004735792836835

Epoch: 5| Step: 2
Training loss: 3.0120086669921875
Validation loss: 2.402090487941619

Epoch: 5| Step: 3
Training loss: 2.445659637451172
Validation loss: 2.4085805313561552

Epoch: 5| Step: 4
Training loss: 2.3815345764160156
Validation loss: 2.4204775107804166

Epoch: 5| Step: 5
Training loss: 2.7562508583068848
Validation loss: 2.4217815245351484

Epoch: 5| Step: 6
Training loss: 1.982569932937622
Validation loss: 2.437204663471509

Epoch: 5| Step: 7
Training loss: 3.0389323234558105
Validation loss: 2.4375671981483378

Epoch: 5| Step: 8
Training loss: 2.3977277278900146
Validation loss: 2.425603897340836

Epoch: 5| Step: 9
Training loss: 2.4983184337615967
Validation loss: 2.4080468890487507

Epoch: 5| Step: 10
Training loss: 2.682386636734009
Validation loss: 2.3997711212404313

Epoch: 71| Step: 0
Training loss: 2.187896728515625
Validation loss: 2.4000594218571982

Epoch: 5| Step: 1
Training loss: 2.5833816528320312
Validation loss: 2.4009004190403926

Epoch: 5| Step: 2
Training loss: 2.586566209793091
Validation loss: 2.4018157041201027

Epoch: 5| Step: 3
Training loss: 2.7799243927001953
Validation loss: 2.413950143321868

Epoch: 5| Step: 4
Training loss: 2.411158800125122
Validation loss: 2.4175471823702575

Epoch: 5| Step: 5
Training loss: 2.522275924682617
Validation loss: 2.4159528132407897

Epoch: 5| Step: 6
Training loss: 2.541923999786377
Validation loss: 2.424919782146331

Epoch: 5| Step: 7
Training loss: 3.227261781692505
Validation loss: 2.4215118026220672

Epoch: 5| Step: 8
Training loss: 1.990936279296875
Validation loss: 2.416203065585065

Epoch: 5| Step: 9
Training loss: 3.072044849395752
Validation loss: 2.4114583666606615

Epoch: 5| Step: 10
Training loss: 3.0626718997955322
Validation loss: 2.4027541478474936

Epoch: 72| Step: 0
Training loss: 2.771949529647827
Validation loss: 2.4027594648381716

Epoch: 5| Step: 1
Training loss: 2.461683988571167
Validation loss: 2.3994991010235203

Epoch: 5| Step: 2
Training loss: 3.34352445602417
Validation loss: 2.39884013770729

Epoch: 5| Step: 3
Training loss: 1.814849853515625
Validation loss: 2.4012917933925504

Epoch: 5| Step: 4
Training loss: 2.8649823665618896
Validation loss: 2.390505898383356

Epoch: 5| Step: 5
Training loss: 3.1518847942352295
Validation loss: 2.400844371446999

Epoch: 5| Step: 6
Training loss: 2.0850086212158203
Validation loss: 2.395347870806212

Epoch: 5| Step: 7
Training loss: 2.732954263687134
Validation loss: 2.4001822035799742

Epoch: 5| Step: 8
Training loss: 2.16239070892334
Validation loss: 2.393725243947839

Epoch: 5| Step: 9
Training loss: 2.8133091926574707
Validation loss: 2.3908698533170964

Epoch: 5| Step: 10
Training loss: 2.680295467376709
Validation loss: 2.3949579090200444

Epoch: 73| Step: 0
Training loss: 3.1820545196533203
Validation loss: 2.3934785294276413

Epoch: 5| Step: 1
Training loss: 2.7032527923583984
Validation loss: 2.3880892389564106

Epoch: 5| Step: 2
Training loss: 2.789109468460083
Validation loss: 2.394477287928263

Epoch: 5| Step: 3
Training loss: 3.3004767894744873
Validation loss: 2.3870799900383077

Epoch: 5| Step: 4
Training loss: 2.3430113792419434
Validation loss: 2.386057751153105

Epoch: 5| Step: 5
Training loss: 2.109832286834717
Validation loss: 2.3917835040759017

Epoch: 5| Step: 6
Training loss: 3.1787238121032715
Validation loss: 2.393154216069047

Epoch: 5| Step: 7
Training loss: 2.0365514755249023
Validation loss: 2.3893545391739055

Epoch: 5| Step: 8
Training loss: 2.6928982734680176
Validation loss: 2.390250539266935

Epoch: 5| Step: 9
Training loss: 2.3913941383361816
Validation loss: 2.3935256593970844

Epoch: 5| Step: 10
Training loss: 2.013129711151123
Validation loss: 2.393295657250189

Epoch: 74| Step: 0
Training loss: 2.177685260772705
Validation loss: 2.3914338337477816

Epoch: 5| Step: 1
Training loss: 2.409480571746826
Validation loss: 2.3811529374891713

Epoch: 5| Step: 2
Training loss: 2.7101612091064453
Validation loss: 2.3789461761392574

Epoch: 5| Step: 3
Training loss: 2.209718704223633
Validation loss: 2.3830554434048232

Epoch: 5| Step: 4
Training loss: 3.1715035438537598
Validation loss: 2.3937137280741045

Epoch: 5| Step: 5
Training loss: 2.974925994873047
Validation loss: 2.3987279169021116

Epoch: 5| Step: 6
Training loss: 3.00669527053833
Validation loss: 2.415608331721316

Epoch: 5| Step: 7
Training loss: 3.0196332931518555
Validation loss: 2.431585460580805

Epoch: 5| Step: 8
Training loss: 2.2884879112243652
Validation loss: 2.4258479790021013

Epoch: 5| Step: 9
Training loss: 2.429168939590454
Validation loss: 2.43768383097905

Epoch: 5| Step: 10
Training loss: 2.5159809589385986
Validation loss: 2.440196562838811

Epoch: 75| Step: 0
Training loss: 2.513819456100464
Validation loss: 2.4210616337355746

Epoch: 5| Step: 1
Training loss: 2.169471263885498
Validation loss: 2.4044574306857203

Epoch: 5| Step: 2
Training loss: 1.8683788776397705
Validation loss: 2.3853109651996243

Epoch: 5| Step: 3
Training loss: 3.111853837966919
Validation loss: 2.379854671416744

Epoch: 5| Step: 4
Training loss: 2.929286003112793
Validation loss: 2.377254088719686

Epoch: 5| Step: 5
Training loss: 2.7120790481567383
Validation loss: 2.390476111442812

Epoch: 5| Step: 6
Training loss: 2.800863265991211
Validation loss: 2.3871206570697088

Epoch: 5| Step: 7
Training loss: 2.5906155109405518
Validation loss: 2.400892029526413

Epoch: 5| Step: 8
Training loss: 3.468876600265503
Validation loss: 2.4103475757824477

Epoch: 5| Step: 9
Training loss: 2.1719136238098145
Validation loss: 2.3831722813267864

Epoch: 5| Step: 10
Training loss: 2.4542593955993652
Validation loss: 2.3834905752571682

Testing loss: 2.555006636513604
