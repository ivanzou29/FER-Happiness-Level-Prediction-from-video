Epoch: 1| Step: 0
Training loss: 4.888568878173828
Validation loss: 5.166824274165656

Epoch: 6| Step: 1
Training loss: 5.618160724639893
Validation loss: 5.162208526365219

Epoch: 6| Step: 2
Training loss: 5.050726413726807
Validation loss: 5.1572909765346076

Epoch: 6| Step: 3
Training loss: 4.9208984375
Validation loss: 5.152606979493172

Epoch: 6| Step: 4
Training loss: 5.365334510803223
Validation loss: 5.1474920344609085

Epoch: 6| Step: 5
Training loss: 4.365200996398926
Validation loss: 5.142433371595157

Epoch: 6| Step: 6
Training loss: 5.630644798278809
Validation loss: 5.136954615193028

Epoch: 6| Step: 7
Training loss: 5.124083518981934
Validation loss: 5.131762079013291

Epoch: 6| Step: 8
Training loss: 4.659216403961182
Validation loss: 5.125953402570499

Epoch: 6| Step: 9
Training loss: 5.012298107147217
Validation loss: 5.120411073007891

Epoch: 6| Step: 10
Training loss: 3.9860496520996094
Validation loss: 5.114265941804455

Epoch: 6| Step: 11
Training loss: 5.145297050476074
Validation loss: 5.108000586109776

Epoch: 6| Step: 12
Training loss: 4.351184368133545
Validation loss: 5.1015091762747815

Epoch: 6| Step: 13
Training loss: 4.882326602935791
Validation loss: 5.094625032076272

Epoch: 2| Step: 0
Training loss: 5.148569107055664
Validation loss: 5.087554593240061

Epoch: 6| Step: 1
Training loss: 3.9450807571411133
Validation loss: 5.080772312738562

Epoch: 6| Step: 2
Training loss: 6.173250198364258
Validation loss: 5.072966514095183

Epoch: 6| Step: 3
Training loss: 3.9751906394958496
Validation loss: 5.065502658967049

Epoch: 6| Step: 4
Training loss: 4.640386581420898
Validation loss: 5.057357018993747

Epoch: 6| Step: 5
Training loss: 5.702652931213379
Validation loss: 5.048480141547419

Epoch: 6| Step: 6
Training loss: 5.035506725311279
Validation loss: 5.04047461991669

Epoch: 6| Step: 7
Training loss: 3.108489513397217
Validation loss: 5.03116008286835

Epoch: 6| Step: 8
Training loss: 5.252936840057373
Validation loss: 5.022074966020481

Epoch: 6| Step: 9
Training loss: 4.4916605949401855
Validation loss: 5.012560126602009

Epoch: 6| Step: 10
Training loss: 5.511436939239502
Validation loss: 5.001699791159681

Epoch: 6| Step: 11
Training loss: 5.817707061767578
Validation loss: 4.9906036366698565

Epoch: 6| Step: 12
Training loss: 4.666232585906982
Validation loss: 4.980242380531886

Epoch: 6| Step: 13
Training loss: 3.5963430404663086
Validation loss: 4.968732951789774

Epoch: 3| Step: 0
Training loss: 4.943356990814209
Validation loss: 4.956818344772503

Epoch: 6| Step: 1
Training loss: 4.147618770599365
Validation loss: 4.943065925311017

Epoch: 6| Step: 2
Training loss: 5.8183088302612305
Validation loss: 4.929891276103194

Epoch: 6| Step: 3
Training loss: 4.519640922546387
Validation loss: 4.915931399150561

Epoch: 6| Step: 4
Training loss: 4.721734046936035
Validation loss: 4.901090283547679

Epoch: 6| Step: 5
Training loss: 4.261656284332275
Validation loss: 4.885893150042462

Epoch: 6| Step: 6
Training loss: 5.0973920822143555
Validation loss: 4.870155508800219

Epoch: 6| Step: 7
Training loss: 4.738591194152832
Validation loss: 4.854302339656378

Epoch: 6| Step: 8
Training loss: 5.766037940979004
Validation loss: 4.835882125362273

Epoch: 6| Step: 9
Training loss: 4.831826210021973
Validation loss: 4.818035807660831

Epoch: 6| Step: 10
Training loss: 3.8514769077301025
Validation loss: 4.800662922602828

Epoch: 6| Step: 11
Training loss: 4.280529022216797
Validation loss: 4.780019678095336

Epoch: 6| Step: 12
Training loss: 3.5981321334838867
Validation loss: 4.760315372097876

Epoch: 6| Step: 13
Training loss: 4.562864303588867
Validation loss: 4.738902917472265

Epoch: 4| Step: 0
Training loss: 4.195830345153809
Validation loss: 4.717865456816971

Epoch: 6| Step: 1
Training loss: 4.819414138793945
Validation loss: 4.695625176993749

Epoch: 6| Step: 2
Training loss: 5.02713680267334
Validation loss: 4.672027372544812

Epoch: 6| Step: 3
Training loss: 3.8565855026245117
Validation loss: 4.6475831052308445

Epoch: 6| Step: 4
Training loss: 4.814766883850098
Validation loss: 4.623303726155271

Epoch: 6| Step: 5
Training loss: 5.398555278778076
Validation loss: 4.597217936669627

Epoch: 6| Step: 6
Training loss: 3.327690839767456
Validation loss: 4.570464377762169

Epoch: 6| Step: 7
Training loss: 4.260376930236816
Validation loss: 4.541297984379594

Epoch: 6| Step: 8
Training loss: 4.396811485290527
Validation loss: 4.512489713648314

Epoch: 6| Step: 9
Training loss: 3.0991506576538086
Validation loss: 4.4815415361876125

Epoch: 6| Step: 10
Training loss: 4.617664813995361
Validation loss: 4.451473236083984

Epoch: 6| Step: 11
Training loss: 4.404940605163574
Validation loss: 4.42077967428392

Epoch: 6| Step: 12
Training loss: 4.673323631286621
Validation loss: 4.390761206226964

Epoch: 6| Step: 13
Training loss: 3.3785643577575684
Validation loss: 4.358691071951261

Epoch: 5| Step: 0
Training loss: 4.321249008178711
Validation loss: 4.327629438010595

Epoch: 6| Step: 1
Training loss: 4.41728401184082
Validation loss: 4.295526043061288

Epoch: 6| Step: 2
Training loss: 3.9530982971191406
Validation loss: 4.26325842642015

Epoch: 6| Step: 3
Training loss: 4.29142951965332
Validation loss: 4.232526604847242

Epoch: 6| Step: 4
Training loss: 4.120323181152344
Validation loss: 4.201138209271175

Epoch: 6| Step: 5
Training loss: 3.95985746383667
Validation loss: 4.172165875793786

Epoch: 6| Step: 6
Training loss: 3.510146141052246
Validation loss: 4.14042209040734

Epoch: 6| Step: 7
Training loss: 3.8381261825561523
Validation loss: 4.113387964105093

Epoch: 6| Step: 8
Training loss: 4.585600852966309
Validation loss: 4.086091918330038

Epoch: 6| Step: 9
Training loss: 3.1933236122131348
Validation loss: 4.059200604756673

Epoch: 6| Step: 10
Training loss: 4.32366943359375
Validation loss: 4.034248987833659

Epoch: 6| Step: 11
Training loss: 3.8369383811950684
Validation loss: 4.0083458808160595

Epoch: 6| Step: 12
Training loss: 3.0036568641662598
Validation loss: 3.984275746089156

Epoch: 6| Step: 13
Training loss: 4.257591724395752
Validation loss: 3.9614528071495796

Epoch: 6| Step: 0
Training loss: 4.084327697753906
Validation loss: 3.941530050769929

Epoch: 6| Step: 1
Training loss: 2.64927077293396
Validation loss: 3.919936751806608

Epoch: 6| Step: 2
Training loss: 4.1999359130859375
Validation loss: 3.9028804686761673

Epoch: 6| Step: 3
Training loss: 4.032111167907715
Validation loss: 3.8843294497459167

Epoch: 6| Step: 4
Training loss: 3.465390682220459
Validation loss: 3.866920053317983

Epoch: 6| Step: 5
Training loss: 3.787233352661133
Validation loss: 3.8515688065559632

Epoch: 6| Step: 6
Training loss: 3.850456476211548
Validation loss: 3.8367182798283075

Epoch: 6| Step: 7
Training loss: 3.137669801712036
Validation loss: 3.821352651042323

Epoch: 6| Step: 8
Training loss: 3.964790105819702
Validation loss: 3.8029125275150424

Epoch: 6| Step: 9
Training loss: 4.501453399658203
Validation loss: 3.7879128661206973

Epoch: 6| Step: 10
Training loss: 2.9376978874206543
Validation loss: 3.771471602942354

Epoch: 6| Step: 11
Training loss: 4.097182273864746
Validation loss: 3.7565927428583943

Epoch: 6| Step: 12
Training loss: 3.5235700607299805
Validation loss: 3.7378162466069704

Epoch: 6| Step: 13
Training loss: 3.4621832370758057
Validation loss: 3.724002927862188

Epoch: 7| Step: 0
Training loss: 3.6665773391723633
Validation loss: 3.7087764791263047

Epoch: 6| Step: 1
Training loss: 3.9967455863952637
Validation loss: 3.6946845054626465

Epoch: 6| Step: 2
Training loss: 4.433371543884277
Validation loss: 3.6813806923486854

Epoch: 6| Step: 3
Training loss: 3.9949073791503906
Validation loss: 3.6671710834708264

Epoch: 6| Step: 4
Training loss: 3.646987199783325
Validation loss: 3.6536780736779653

Epoch: 6| Step: 5
Training loss: 3.8791542053222656
Validation loss: 3.63960172284034

Epoch: 6| Step: 6
Training loss: 3.884824752807617
Validation loss: 3.6259442247370237

Epoch: 6| Step: 7
Training loss: 2.9106802940368652
Validation loss: 3.6120550350476335

Epoch: 6| Step: 8
Training loss: 2.9303030967712402
Validation loss: 3.6005592910192346

Epoch: 6| Step: 9
Training loss: 2.6743791103363037
Validation loss: 3.589528509365615

Epoch: 6| Step: 10
Training loss: 3.2777843475341797
Validation loss: 3.575391261808334

Epoch: 6| Step: 11
Training loss: 4.2800211906433105
Validation loss: 3.5621314228221936

Epoch: 6| Step: 12
Training loss: 3.3949966430664062
Validation loss: 3.5500118552997546

Epoch: 6| Step: 13
Training loss: 1.8213367462158203
Validation loss: 3.5401634503436346

Epoch: 8| Step: 0
Training loss: 4.376696586608887
Validation loss: 3.52746517427506

Epoch: 6| Step: 1
Training loss: 2.685427665710449
Validation loss: 3.515331035019249

Epoch: 6| Step: 2
Training loss: 2.809628486633301
Validation loss: 3.5069653885338896

Epoch: 6| Step: 3
Training loss: 2.983522891998291
Validation loss: 3.4953706649041947

Epoch: 6| Step: 4
Training loss: 3.439723014831543
Validation loss: 3.483914500923567

Epoch: 6| Step: 5
Training loss: 4.012013912200928
Validation loss: 3.476178951160882

Epoch: 6| Step: 6
Training loss: 3.2659406661987305
Validation loss: 3.463492742148779

Epoch: 6| Step: 7
Training loss: 2.762357234954834
Validation loss: 3.454956264906032

Epoch: 6| Step: 8
Training loss: 3.9981131553649902
Validation loss: 3.4460813922266804

Epoch: 6| Step: 9
Training loss: 3.4500954151153564
Validation loss: 3.4364224633862896

Epoch: 6| Step: 10
Training loss: 3.451301097869873
Validation loss: 3.4259230859817995

Epoch: 6| Step: 11
Training loss: 3.940363883972168
Validation loss: 3.416020498480848

Epoch: 6| Step: 12
Training loss: 3.386131763458252
Validation loss: 3.4071332972536803

Epoch: 6| Step: 13
Training loss: 2.6427876949310303
Validation loss: 3.3973154150029665

Epoch: 9| Step: 0
Training loss: 3.6706299781799316
Validation loss: 3.386185943439443

Epoch: 6| Step: 1
Training loss: 2.532935380935669
Validation loss: 3.3813319103692168

Epoch: 6| Step: 2
Training loss: 3.26851224899292
Validation loss: 3.3709063811968734

Epoch: 6| Step: 3
Training loss: 2.87634539604187
Validation loss: 3.3653976737812

Epoch: 6| Step: 4
Training loss: 3.0817713737487793
Validation loss: 3.3549273219159854

Epoch: 6| Step: 5
Training loss: 3.036942481994629
Validation loss: 3.3492260338157736

Epoch: 6| Step: 6
Training loss: 2.7016820907592773
Validation loss: 3.3400789332646195

Epoch: 6| Step: 7
Training loss: 3.3515963554382324
Validation loss: 3.331206306334465

Epoch: 6| Step: 8
Training loss: 3.8249356746673584
Validation loss: 3.324199189421951

Epoch: 6| Step: 9
Training loss: 3.3834400177001953
Validation loss: 3.3200815108514603

Epoch: 6| Step: 10
Training loss: 3.659727096557617
Validation loss: 3.3120470380270355

Epoch: 6| Step: 11
Training loss: 3.00589919090271
Validation loss: 3.3050574461619058

Epoch: 6| Step: 12
Training loss: 5.25758171081543
Validation loss: 3.2946682489046486

Epoch: 6| Step: 13
Training loss: 1.982776403427124
Validation loss: 3.2898324228102163

Epoch: 10| Step: 0
Training loss: 3.620108127593994
Validation loss: 3.28558018899733

Epoch: 6| Step: 1
Training loss: 3.8573555946350098
Validation loss: 3.279069521093881

Epoch: 6| Step: 2
Training loss: 3.1148815155029297
Validation loss: 3.2718882868366856

Epoch: 6| Step: 3
Training loss: 3.3917453289031982
Validation loss: 3.2656644672475834

Epoch: 6| Step: 4
Training loss: 4.038900375366211
Validation loss: 3.260048063852454

Epoch: 6| Step: 5
Training loss: 3.056605815887451
Validation loss: 3.2541254182015695

Epoch: 6| Step: 6
Training loss: 2.394279956817627
Validation loss: 3.2515320342074157

Epoch: 6| Step: 7
Training loss: 2.8553383350372314
Validation loss: 3.2497964956427134

Epoch: 6| Step: 8
Training loss: 2.5672576427459717
Validation loss: 3.2419918019284486

Epoch: 6| Step: 9
Training loss: 3.50120210647583
Validation loss: 3.235475263287944

Epoch: 6| Step: 10
Training loss: 3.4230854511260986
Validation loss: 3.230632315399826

Epoch: 6| Step: 11
Training loss: 2.929218053817749
Validation loss: 3.2246013456775295

Epoch: 6| Step: 12
Training loss: 3.4140195846557617
Validation loss: 3.2192267628126245

Epoch: 6| Step: 13
Training loss: 2.9213356971740723
Validation loss: 3.2163776941196893

Epoch: 11| Step: 0
Training loss: 3.2487006187438965
Validation loss: 3.209463434834634

Epoch: 6| Step: 1
Training loss: 2.77542781829834
Validation loss: 3.204197919496926

Epoch: 6| Step: 2
Training loss: 4.6184892654418945
Validation loss: 3.198385428356868

Epoch: 6| Step: 3
Training loss: 2.9164795875549316
Validation loss: 3.1915530235536638

Epoch: 6| Step: 4
Training loss: 2.7880449295043945
Validation loss: 3.183728292424192

Epoch: 6| Step: 5
Training loss: 2.697312116622925
Validation loss: 3.1772040192798903

Epoch: 6| Step: 6
Training loss: 2.9053492546081543
Validation loss: 3.1694789983892955

Epoch: 6| Step: 7
Training loss: 3.9118564128875732
Validation loss: 3.1632946768114643

Epoch: 6| Step: 8
Training loss: 3.4397659301757812
Validation loss: 3.1557722886403403

Epoch: 6| Step: 9
Training loss: 2.7433581352233887
Validation loss: 3.149682573092881

Epoch: 6| Step: 10
Training loss: 2.8729374408721924
Validation loss: 3.1474428305061917

Epoch: 6| Step: 11
Training loss: 2.8511791229248047
Validation loss: 3.1434813878869496

Epoch: 6| Step: 12
Training loss: 3.6851086616516113
Validation loss: 3.131253957748413

Epoch: 6| Step: 13
Training loss: 2.8748841285705566
Validation loss: 3.1236656763220347

Epoch: 12| Step: 0
Training loss: 3.7918241024017334
Validation loss: 3.1217634293340866

Epoch: 6| Step: 1
Training loss: 3.6496710777282715
Validation loss: 3.1202695241538425

Epoch: 6| Step: 2
Training loss: 2.4507527351379395
Validation loss: 3.1102497090575514

Epoch: 6| Step: 3
Training loss: 2.513117790222168
Validation loss: 3.1059404162950415

Epoch: 6| Step: 4
Training loss: 3.911634922027588
Validation loss: 3.1021417879289195

Epoch: 6| Step: 5
Training loss: 2.893017292022705
Validation loss: 3.0981303825173327

Epoch: 6| Step: 6
Training loss: 2.5799400806427
Validation loss: 3.09076185892987

Epoch: 6| Step: 7
Training loss: 3.3285727500915527
Validation loss: 3.083502238796603

Epoch: 6| Step: 8
Training loss: 3.463090419769287
Validation loss: 3.0785339980997066

Epoch: 6| Step: 9
Training loss: 3.5435962677001953
Validation loss: 3.0727470254385345

Epoch: 6| Step: 10
Training loss: 2.6007113456726074
Validation loss: 3.0639470802840365

Epoch: 6| Step: 11
Training loss: 2.6757161617279053
Validation loss: 3.0591970951326433

Epoch: 6| Step: 12
Training loss: 3.7037734985351562
Validation loss: 3.0541050254657702

Epoch: 6| Step: 13
Training loss: 2.0940492153167725
Validation loss: 3.0516490808097263

Epoch: 13| Step: 0
Training loss: 3.839905261993408
Validation loss: 3.053454404236168

Epoch: 6| Step: 1
Training loss: 2.847700595855713
Validation loss: 3.043923242117769

Epoch: 6| Step: 2
Training loss: 2.6325674057006836
Validation loss: 3.043395742293327

Epoch: 6| Step: 3
Training loss: 2.9259860515594482
Validation loss: 3.0385011575555287

Epoch: 6| Step: 4
Training loss: 3.3754920959472656
Validation loss: 3.030987431926112

Epoch: 6| Step: 5
Training loss: 3.1433095932006836
Validation loss: 3.024462945999638

Epoch: 6| Step: 6
Training loss: 2.5138747692108154
Validation loss: 3.0217066375158166

Epoch: 6| Step: 7
Training loss: 3.4046213626861572
Validation loss: 3.0193877681609123

Epoch: 6| Step: 8
Training loss: 3.6068263053894043
Validation loss: 3.0156741603728263

Epoch: 6| Step: 9
Training loss: 2.4946861267089844
Validation loss: 3.013948978916291

Epoch: 6| Step: 10
Training loss: 2.9895200729370117
Validation loss: 3.0110486348470054

Epoch: 6| Step: 11
Training loss: 2.792853593826294
Validation loss: 3.008822617992278

Epoch: 6| Step: 12
Training loss: 2.9629077911376953
Validation loss: 3.0031852875986407

Epoch: 6| Step: 13
Training loss: 3.907654285430908
Validation loss: 3.0006266742624264

Epoch: 14| Step: 0
Training loss: 2.5566554069519043
Validation loss: 2.9946509381776214

Epoch: 6| Step: 1
Training loss: 3.1840739250183105
Validation loss: 2.990209592285977

Epoch: 6| Step: 2
Training loss: 3.9000983238220215
Validation loss: 2.985772643038022

Epoch: 6| Step: 3
Training loss: 2.6165719032287598
Validation loss: 2.981358174354799

Epoch: 6| Step: 4
Training loss: 1.9362287521362305
Validation loss: 2.9832661869705364

Epoch: 6| Step: 5
Training loss: 3.444230318069458
Validation loss: 2.9763122630375687

Epoch: 6| Step: 6
Training loss: 3.5170164108276367
Validation loss: 2.9723270452150734

Epoch: 6| Step: 7
Training loss: 3.1918911933898926
Validation loss: 2.9685390739030737

Epoch: 6| Step: 8
Training loss: 3.1747028827667236
Validation loss: 2.9625102166206605

Epoch: 6| Step: 9
Training loss: 3.062222957611084
Validation loss: 2.967125097910563

Epoch: 6| Step: 10
Training loss: 2.6556124687194824
Validation loss: 2.960123492825416

Epoch: 6| Step: 11
Training loss: 2.399606227874756
Validation loss: 2.954769834395378

Epoch: 6| Step: 12
Training loss: 3.7305824756622314
Validation loss: 2.9518130722866265

Epoch: 6| Step: 13
Training loss: 3.395796060562134
Validation loss: 2.9498668768072642

Epoch: 15| Step: 0
Training loss: 3.3851749897003174
Validation loss: 2.947658815691548

Epoch: 6| Step: 1
Training loss: 2.513211727142334
Validation loss: 2.945907108245357

Epoch: 6| Step: 2
Training loss: 2.784456968307495
Validation loss: 2.93955490409687

Epoch: 6| Step: 3
Training loss: 3.4618430137634277
Validation loss: 2.9383044986314673

Epoch: 6| Step: 4
Training loss: 3.5391898155212402
Validation loss: 2.9359895977922665

Epoch: 6| Step: 5
Training loss: 2.9535346031188965
Validation loss: 2.930457727883452

Epoch: 6| Step: 6
Training loss: 2.3760149478912354
Validation loss: 2.928912937000234

Epoch: 6| Step: 7
Training loss: 3.214735269546509
Validation loss: 2.925928767009448

Epoch: 6| Step: 8
Training loss: 3.1489510536193848
Validation loss: 2.925553596147927

Epoch: 6| Step: 9
Training loss: 3.127215623855591
Validation loss: 2.921901367043936

Epoch: 6| Step: 10
Training loss: 3.220020055770874
Validation loss: 2.9207242047914894

Epoch: 6| Step: 11
Training loss: 3.160170078277588
Validation loss: 2.9188440025493665

Epoch: 6| Step: 12
Training loss: 2.0383479595184326
Validation loss: 2.9136083843887493

Epoch: 6| Step: 13
Training loss: 3.4926564693450928
Validation loss: 2.914817620349187

Epoch: 16| Step: 0
Training loss: 3.0897555351257324
Validation loss: 2.9129759265530493

Epoch: 6| Step: 1
Training loss: 2.4378061294555664
Validation loss: 2.9082142076184674

Epoch: 6| Step: 2
Training loss: 2.948728084564209
Validation loss: 2.910251468740484

Epoch: 6| Step: 3
Training loss: 3.0173654556274414
Validation loss: 2.907753141977454

Epoch: 6| Step: 4
Training loss: 2.9174208641052246
Validation loss: 2.9068812375427573

Epoch: 6| Step: 5
Training loss: 2.914487600326538
Validation loss: 2.9038342199017926

Epoch: 6| Step: 6
Training loss: 2.9305105209350586
Validation loss: 2.8987147936256985

Epoch: 6| Step: 7
Training loss: 4.250827789306641
Validation loss: 2.8954971118639876

Epoch: 6| Step: 8
Training loss: 2.783073663711548
Validation loss: 2.8928657500974593

Epoch: 6| Step: 9
Training loss: 2.2343215942382812
Validation loss: 2.8901099671599684

Epoch: 6| Step: 10
Training loss: 2.967041254043579
Validation loss: 2.8875839428235124

Epoch: 6| Step: 11
Training loss: 2.8029494285583496
Validation loss: 2.888675266696561

Epoch: 6| Step: 12
Training loss: 3.3001112937927246
Validation loss: 2.8868367877057803

Epoch: 6| Step: 13
Training loss: 3.542616128921509
Validation loss: 2.883231944935296

Epoch: 17| Step: 0
Training loss: 2.7633442878723145
Validation loss: 2.8816612561543784

Epoch: 6| Step: 1
Training loss: 2.892958402633667
Validation loss: 2.8794196369827434

Epoch: 6| Step: 2
Training loss: 2.5393190383911133
Validation loss: 2.8772075535148702

Epoch: 6| Step: 3
Training loss: 2.8521289825439453
Validation loss: 2.8767758825773835

Epoch: 6| Step: 4
Training loss: 2.96219539642334
Validation loss: 2.8775000238931305

Epoch: 6| Step: 5
Training loss: 2.59141206741333
Validation loss: 2.8727797513367026

Epoch: 6| Step: 6
Training loss: 3.1301259994506836
Validation loss: 2.871018983984506

Epoch: 6| Step: 7
Training loss: 2.594682216644287
Validation loss: 2.8662619513850056

Epoch: 6| Step: 8
Training loss: 3.64253568649292
Validation loss: 2.865851797083373

Epoch: 6| Step: 9
Training loss: 3.1689414978027344
Validation loss: 2.8624602210137153

Epoch: 6| Step: 10
Training loss: 3.859332323074341
Validation loss: 2.865339166374617

Epoch: 6| Step: 11
Training loss: 2.9595189094543457
Validation loss: 2.862202910966771

Epoch: 6| Step: 12
Training loss: 2.4211437702178955
Validation loss: 2.85953527368525

Epoch: 6| Step: 13
Training loss: 3.5038559436798096
Validation loss: 2.8557360531181417

Epoch: 18| Step: 0
Training loss: 3.6946027278900146
Validation loss: 2.861658162968133

Epoch: 6| Step: 1
Training loss: 2.6173596382141113
Validation loss: 2.852309347480856

Epoch: 6| Step: 2
Training loss: 3.0791807174682617
Validation loss: 2.8476757849416425

Epoch: 6| Step: 3
Training loss: 3.182175636291504
Validation loss: 2.8470089871396302

Epoch: 6| Step: 4
Training loss: 3.090116500854492
Validation loss: 2.845939684939641

Epoch: 6| Step: 5
Training loss: 2.983114242553711
Validation loss: 2.844676576634889

Epoch: 6| Step: 6
Training loss: 3.101942777633667
Validation loss: 2.8463673283976894

Epoch: 6| Step: 7
Training loss: 2.4741687774658203
Validation loss: 2.842750753125837

Epoch: 6| Step: 8
Training loss: 3.4924795627593994
Validation loss: 2.8374200482522287

Epoch: 6| Step: 9
Training loss: 2.3161988258361816
Validation loss: 2.837334909746724

Epoch: 6| Step: 10
Training loss: 2.60498046875
Validation loss: 2.8350151328630346

Epoch: 6| Step: 11
Training loss: 3.0970940589904785
Validation loss: 2.833509493899602

Epoch: 6| Step: 12
Training loss: 3.355132579803467
Validation loss: 2.831253715740737

Epoch: 6| Step: 13
Training loss: 1.870368480682373
Validation loss: 2.829965268411944

Epoch: 19| Step: 0
Training loss: 3.2849960327148438
Validation loss: 2.8288131298557406

Epoch: 6| Step: 1
Training loss: 3.1864500045776367
Validation loss: 2.83195859642439

Epoch: 6| Step: 2
Training loss: 2.9295554161071777
Validation loss: 2.8304693288700555

Epoch: 6| Step: 3
Training loss: 3.1669154167175293
Validation loss: 2.825412478498233

Epoch: 6| Step: 4
Training loss: 2.4206252098083496
Validation loss: 2.823424998150077

Epoch: 6| Step: 5
Training loss: 2.7077839374542236
Validation loss: 2.817952066339472

Epoch: 6| Step: 6
Training loss: 3.0262303352355957
Validation loss: 2.815889097029163

Epoch: 6| Step: 7
Training loss: 2.975937604904175
Validation loss: 2.8119395958480013

Epoch: 6| Step: 8
Training loss: 3.6972239017486572
Validation loss: 2.8099319832299345

Epoch: 6| Step: 9
Training loss: 2.6382641792297363
Validation loss: 2.8105997013789352

Epoch: 6| Step: 10
Training loss: 2.123229503631592
Validation loss: 2.8113938326476724

Epoch: 6| Step: 11
Training loss: 3.0470621585845947
Validation loss: 2.827863585564398

Epoch: 6| Step: 12
Training loss: 2.901038646697998
Validation loss: 2.818533892272621

Epoch: 6| Step: 13
Training loss: 3.214015245437622
Validation loss: 2.8091674748287407

Epoch: 20| Step: 0
Training loss: 2.3348217010498047
Validation loss: 2.8044841571520736

Epoch: 6| Step: 1
Training loss: 2.499002695083618
Validation loss: 2.801738259612873

Epoch: 6| Step: 2
Training loss: 4.0027852058410645
Validation loss: 2.8076660094722623

Epoch: 6| Step: 3
Training loss: 3.666249990463257
Validation loss: 2.801993780238654

Epoch: 6| Step: 4
Training loss: 2.1251676082611084
Validation loss: 2.7958568783216577

Epoch: 6| Step: 5
Training loss: 2.7392821311950684
Validation loss: 2.7936997772544943

Epoch: 6| Step: 6
Training loss: 2.9249660968780518
Validation loss: 2.795088998733028

Epoch: 6| Step: 7
Training loss: 3.227076530456543
Validation loss: 2.8029898699893745

Epoch: 6| Step: 8
Training loss: 2.280698776245117
Validation loss: 2.81024460382359

Epoch: 6| Step: 9
Training loss: 3.2431366443634033
Validation loss: 2.8161341836375575

Epoch: 6| Step: 10
Training loss: 2.5072286128997803
Validation loss: 2.807701805586456

Epoch: 6| Step: 11
Training loss: 3.190488338470459
Validation loss: 2.793937288304811

Epoch: 6| Step: 12
Training loss: 2.7347571849823
Validation loss: 2.788657331979403

Epoch: 6| Step: 13
Training loss: 4.031091213226318
Validation loss: 2.7870067217016734

Epoch: 21| Step: 0
Training loss: 2.4762401580810547
Validation loss: 2.7876655875995593

Epoch: 6| Step: 1
Training loss: 3.9425439834594727
Validation loss: 2.7850445983230427

Epoch: 6| Step: 2
Training loss: 3.255091667175293
Validation loss: 2.783087420207198

Epoch: 6| Step: 3
Training loss: 2.9714341163635254
Validation loss: 2.781429139516687

Epoch: 6| Step: 4
Training loss: 2.5179283618927
Validation loss: 2.781195486745527

Epoch: 6| Step: 5
Training loss: 2.5235438346862793
Validation loss: 2.7788117419007006

Epoch: 6| Step: 6
Training loss: 2.7789478302001953
Validation loss: 2.7788966676240325

Epoch: 6| Step: 7
Training loss: 3.1662893295288086
Validation loss: 2.775747068466679

Epoch: 6| Step: 8
Training loss: 3.091686248779297
Validation loss: 2.7739303855485815

Epoch: 6| Step: 9
Training loss: 3.7801547050476074
Validation loss: 2.7723858843567553

Epoch: 6| Step: 10
Training loss: 1.8333101272583008
Validation loss: 2.7703187055485223

Epoch: 6| Step: 11
Training loss: 3.314366340637207
Validation loss: 2.7669797905029787

Epoch: 6| Step: 12
Training loss: 2.5419540405273438
Validation loss: 2.767598554652224

Epoch: 6| Step: 13
Training loss: 2.4330551624298096
Validation loss: 2.7643126544132026

Epoch: 22| Step: 0
Training loss: 2.279000759124756
Validation loss: 2.766867673525246

Epoch: 6| Step: 1
Training loss: 2.8245561122894287
Validation loss: 2.765871609410932

Epoch: 6| Step: 2
Training loss: 3.2233574390411377
Validation loss: 2.7659318831659134

Epoch: 6| Step: 3
Training loss: 3.0992627143859863
Validation loss: 2.762631890594318

Epoch: 6| Step: 4
Training loss: 3.1169028282165527
Validation loss: 2.7644821161864908

Epoch: 6| Step: 5
Training loss: 3.74600887298584
Validation loss: 2.75980875056277

Epoch: 6| Step: 6
Training loss: 2.5918684005737305
Validation loss: 2.758284584168465

Epoch: 6| Step: 7
Training loss: 3.207137107849121
Validation loss: 2.7559902667999268

Epoch: 6| Step: 8
Training loss: 2.2175328731536865
Validation loss: 2.7521076381847425

Epoch: 6| Step: 9
Training loss: 3.657757043838501
Validation loss: 2.757644194428639

Epoch: 6| Step: 10
Training loss: 2.9716081619262695
Validation loss: 2.7547677665628414

Epoch: 6| Step: 11
Training loss: 3.0178146362304688
Validation loss: 2.7531504041405133

Epoch: 6| Step: 12
Training loss: 2.255147933959961
Validation loss: 2.7543501110487085

Epoch: 6| Step: 13
Training loss: 2.047863245010376
Validation loss: 2.753133989149524

Epoch: 23| Step: 0
Training loss: 2.9908857345581055
Validation loss: 2.7529084554282566

Epoch: 6| Step: 1
Training loss: 2.9828929901123047
Validation loss: 2.7522680195428992

Epoch: 6| Step: 2
Training loss: 2.381439685821533
Validation loss: 2.7527115857729347

Epoch: 6| Step: 3
Training loss: 2.5093841552734375
Validation loss: 2.7507916522282425

Epoch: 6| Step: 4
Training loss: 3.233558416366577
Validation loss: 2.7506991535104732

Epoch: 6| Step: 5
Training loss: 3.2829384803771973
Validation loss: 2.7475333341988186

Epoch: 6| Step: 6
Training loss: 2.9869837760925293
Validation loss: 2.7438509823173605

Epoch: 6| Step: 7
Training loss: 2.696406841278076
Validation loss: 2.74219193766194

Epoch: 6| Step: 8
Training loss: 3.497863292694092
Validation loss: 2.7417168463430097

Epoch: 6| Step: 9
Training loss: 1.898899793624878
Validation loss: 2.7390606300805205

Epoch: 6| Step: 10
Training loss: 2.6564316749572754
Validation loss: 2.7420661731432845

Epoch: 6| Step: 11
Training loss: 3.4252467155456543
Validation loss: 2.737177889834168

Epoch: 6| Step: 12
Training loss: 3.1298952102661133
Validation loss: 2.7341320745406614

Epoch: 6| Step: 13
Training loss: 2.84932279586792
Validation loss: 2.7347825188790598

Epoch: 24| Step: 0
Training loss: 2.5450165271759033
Validation loss: 2.7319086828539447

Epoch: 6| Step: 1
Training loss: 1.9479451179504395
Validation loss: 2.7361306887800976

Epoch: 6| Step: 2
Training loss: 2.0702695846557617
Validation loss: 2.7357543078801965

Epoch: 6| Step: 3
Training loss: 2.6886205673217773
Validation loss: 2.7377225686145086

Epoch: 6| Step: 4
Training loss: 2.376311779022217
Validation loss: 2.7343269214835217

Epoch: 6| Step: 5
Training loss: 4.1665449142456055
Validation loss: 2.732816719239758

Epoch: 6| Step: 6
Training loss: 4.176412582397461
Validation loss: 2.7312284874659714

Epoch: 6| Step: 7
Training loss: 2.4767158031463623
Validation loss: 2.727516166625484

Epoch: 6| Step: 8
Training loss: 3.3327207565307617
Validation loss: 2.7261254941263506

Epoch: 6| Step: 9
Training loss: 3.491672992706299
Validation loss: 2.7236196610235397

Epoch: 6| Step: 10
Training loss: 3.0222039222717285
Validation loss: 2.726514644520257

Epoch: 6| Step: 11
Training loss: 3.105315923690796
Validation loss: 2.7270709776109263

Epoch: 6| Step: 12
Training loss: 2.142340660095215
Validation loss: 2.7273642093904558

Epoch: 6| Step: 13
Training loss: 2.8139429092407227
Validation loss: 2.7257487261167137

Epoch: 25| Step: 0
Training loss: 2.322584629058838
Validation loss: 2.729420974690427

Epoch: 6| Step: 1
Training loss: 2.7479488849639893
Validation loss: 2.7282820106834493

Epoch: 6| Step: 2
Training loss: 2.3470957279205322
Validation loss: 2.729057550430298

Epoch: 6| Step: 3
Training loss: 3.8109633922576904
Validation loss: 2.7297330543559086

Epoch: 6| Step: 4
Training loss: 1.7499184608459473
Validation loss: 2.734882629045876

Epoch: 6| Step: 5
Training loss: 3.3482046127319336
Validation loss: 2.7693224773612073

Epoch: 6| Step: 6
Training loss: 4.100202560424805
Validation loss: 2.722689628601074

Epoch: 6| Step: 7
Training loss: 3.1217455863952637
Validation loss: 2.715070757814633

Epoch: 6| Step: 8
Training loss: 2.7587838172912598
Validation loss: 2.721564431344309

Epoch: 6| Step: 9
Training loss: 2.2000656127929688
Validation loss: 2.7323456374547814

Epoch: 6| Step: 10
Training loss: 2.5202574729919434
Validation loss: 2.7717522293008785

Epoch: 6| Step: 11
Training loss: 3.2404544353485107
Validation loss: 2.7916096846262612

Epoch: 6| Step: 12
Training loss: 3.2938272953033447
Validation loss: 2.7943396747753186

Epoch: 6| Step: 13
Training loss: 2.9954850673675537
Validation loss: 2.8150456387509584

Epoch: 26| Step: 0
Training loss: 2.3136513233184814
Validation loss: 2.799927608941191

Epoch: 6| Step: 1
Training loss: 3.35982608795166
Validation loss: 2.7978252223742905

Epoch: 6| Step: 2
Training loss: 2.483151912689209
Validation loss: 2.7982879069543656

Epoch: 6| Step: 3
Training loss: 3.0914206504821777
Validation loss: 2.8008604075319026

Epoch: 6| Step: 4
Training loss: 3.1659765243530273
Validation loss: 2.8013986105559976

Epoch: 6| Step: 5
Training loss: 2.83661150932312
Validation loss: 2.7911915035657984

Epoch: 6| Step: 6
Training loss: 2.727766275405884
Validation loss: 2.7874887553594445

Epoch: 6| Step: 7
Training loss: 2.783825159072876
Validation loss: 2.783762490877541

Epoch: 6| Step: 8
Training loss: 3.1978673934936523
Validation loss: 2.7766802234034382

Epoch: 6| Step: 9
Training loss: 3.134124994277954
Validation loss: 2.774595276001961

Epoch: 6| Step: 10
Training loss: 2.2781662940979004
Validation loss: 2.7738951124170774

Epoch: 6| Step: 11
Training loss: 1.991044044494629
Validation loss: 2.7724448711641374

Epoch: 6| Step: 12
Training loss: 4.269627571105957
Validation loss: 2.771292737735215

Epoch: 6| Step: 13
Training loss: 3.530745506286621
Validation loss: 2.771422216969152

Epoch: 27| Step: 0
Training loss: 2.301785945892334
Validation loss: 2.7671491587033836

Epoch: 6| Step: 1
Training loss: 2.5058884620666504
Validation loss: 2.767354016662926

Epoch: 6| Step: 2
Training loss: 3.774723529815674
Validation loss: 2.7663500642263763

Epoch: 6| Step: 3
Training loss: 2.777472972869873
Validation loss: 2.7661370308168474

Epoch: 6| Step: 4
Training loss: 3.419870376586914
Validation loss: 2.7666345334822133

Epoch: 6| Step: 5
Training loss: 2.4437432289123535
Validation loss: 2.7583105179571334

Epoch: 6| Step: 6
Training loss: 2.9469871520996094
Validation loss: 2.7564075787862143

Epoch: 6| Step: 7
Training loss: 3.0730488300323486
Validation loss: 2.7567771506565872

Epoch: 6| Step: 8
Training loss: 2.945103168487549
Validation loss: 2.7529306386106756

Epoch: 6| Step: 9
Training loss: 3.1920809745788574
Validation loss: 2.7510885141229116

Epoch: 6| Step: 10
Training loss: 2.9325990676879883
Validation loss: 2.7501871944755636

Epoch: 6| Step: 11
Training loss: 2.3769941329956055
Validation loss: 2.7478501258357877

Epoch: 6| Step: 12
Training loss: 3.2860591411590576
Validation loss: 2.7484745440944547

Epoch: 6| Step: 13
Training loss: 2.4492218494415283
Validation loss: 2.7459462355541926

Epoch: 28| Step: 0
Training loss: 2.8917393684387207
Validation loss: 2.7429282229433776

Epoch: 6| Step: 1
Training loss: 2.480672836303711
Validation loss: 2.7427628322314193

Epoch: 6| Step: 2
Training loss: 2.79557466506958
Validation loss: 2.7466777114457983

Epoch: 6| Step: 3
Training loss: 2.5094313621520996
Validation loss: 2.754791175165484

Epoch: 6| Step: 4
Training loss: 2.620082378387451
Validation loss: 2.744715754703809

Epoch: 6| Step: 5
Training loss: 1.6952295303344727
Validation loss: 2.736537697494671

Epoch: 6| Step: 6
Training loss: 2.881998300552368
Validation loss: 2.7377337101967103

Epoch: 6| Step: 7
Training loss: 2.826756000518799
Validation loss: 2.738706329817413

Epoch: 6| Step: 8
Training loss: 3.4861509799957275
Validation loss: 2.7350857360388643

Epoch: 6| Step: 9
Training loss: 2.9538075923919678
Validation loss: 2.7343918841372252

Epoch: 6| Step: 10
Training loss: 3.282086133956909
Validation loss: 2.7347843570093953

Epoch: 6| Step: 11
Training loss: 3.7292420864105225
Validation loss: 2.735225644162906

Epoch: 6| Step: 12
Training loss: 3.134308338165283
Validation loss: 2.7378663862905195

Epoch: 6| Step: 13
Training loss: 3.3919928073883057
Validation loss: 2.7318753068165114

Epoch: 29| Step: 0
Training loss: 2.991532802581787
Validation loss: 2.7323327961788384

Epoch: 6| Step: 1
Training loss: 2.7775421142578125
Validation loss: 2.7307895588618454

Epoch: 6| Step: 2
Training loss: 2.4635891914367676
Validation loss: 2.7313621967069563

Epoch: 6| Step: 3
Training loss: 2.571643114089966
Validation loss: 2.7225296112798874

Epoch: 6| Step: 4
Training loss: 2.6768341064453125
Validation loss: 2.7221184571584067

Epoch: 6| Step: 5
Training loss: 3.562736988067627
Validation loss: 2.723458828464631

Epoch: 6| Step: 6
Training loss: 3.9722580909729004
Validation loss: 2.7241792422468945

Epoch: 6| Step: 7
Training loss: 2.9641947746276855
Validation loss: 2.7214104180694907

Epoch: 6| Step: 8
Training loss: 2.1737899780273438
Validation loss: 2.7198037024467223

Epoch: 6| Step: 9
Training loss: 2.5007832050323486
Validation loss: 2.717754010231264

Epoch: 6| Step: 10
Training loss: 2.9827871322631836
Validation loss: 2.7209889811854207

Epoch: 6| Step: 11
Training loss: 3.0333666801452637
Validation loss: 2.7178827819003852

Epoch: 6| Step: 12
Training loss: 3.0298848152160645
Validation loss: 2.7158198074627946

Epoch: 6| Step: 13
Training loss: 2.398421287536621
Validation loss: 2.718288334467078

Epoch: 30| Step: 0
Training loss: 2.328083038330078
Validation loss: 2.7213299787172707

Epoch: 6| Step: 1
Training loss: 2.702676296234131
Validation loss: 2.7223331928253174

Epoch: 6| Step: 2
Training loss: 3.1715567111968994
Validation loss: 2.7285742708431777

Epoch: 6| Step: 3
Training loss: 2.462623119354248
Validation loss: 2.719198421765399

Epoch: 6| Step: 4
Training loss: 3.5409607887268066
Validation loss: 2.7175159736346175

Epoch: 6| Step: 5
Training loss: 2.993986129760742
Validation loss: 2.7118823092470885

Epoch: 6| Step: 6
Training loss: 2.424846649169922
Validation loss: 2.7155070074142946

Epoch: 6| Step: 7
Training loss: 2.853893995285034
Validation loss: 2.710810028096681

Epoch: 6| Step: 8
Training loss: 3.874300003051758
Validation loss: 2.7124315000349477

Epoch: 6| Step: 9
Training loss: 3.062596321105957
Validation loss: 2.712384062428628

Epoch: 6| Step: 10
Training loss: 2.571406126022339
Validation loss: 2.7090480199424167

Epoch: 6| Step: 11
Training loss: 3.3841300010681152
Validation loss: 2.709723985323342

Epoch: 6| Step: 12
Training loss: 1.9446758031845093
Validation loss: 2.708997716185867

Epoch: 6| Step: 13
Training loss: 2.957423210144043
Validation loss: 2.7105988148720033

Epoch: 31| Step: 0
Training loss: 3.489596366882324
Validation loss: 2.709520593766243

Epoch: 6| Step: 1
Training loss: 4.062561511993408
Validation loss: 2.707821971626692

Epoch: 6| Step: 2
Training loss: 2.536238670349121
Validation loss: 2.7114624105474

Epoch: 6| Step: 3
Training loss: 2.6603949069976807
Validation loss: 2.706456494587724

Epoch: 6| Step: 4
Training loss: 2.2835755348205566
Validation loss: 2.708033666815809

Epoch: 6| Step: 5
Training loss: 2.399348735809326
Validation loss: 2.7054413287870345

Epoch: 6| Step: 6
Training loss: 2.7983527183532715
Validation loss: 2.7047268344509985

Epoch: 6| Step: 7
Training loss: 2.4301581382751465
Validation loss: 2.702214769137803

Epoch: 6| Step: 8
Training loss: 2.8613181114196777
Validation loss: 2.702665187979257

Epoch: 6| Step: 9
Training loss: 3.18009614944458
Validation loss: 2.7016445385512484

Epoch: 6| Step: 10
Training loss: 2.750697135925293
Validation loss: 2.703086647936093

Epoch: 6| Step: 11
Training loss: 2.731508255004883
Validation loss: 2.70425170980474

Epoch: 6| Step: 12
Training loss: 2.477592706680298
Validation loss: 2.7072921260710685

Epoch: 6| Step: 13
Training loss: 4.013649940490723
Validation loss: 2.7117197129034225

Epoch: 32| Step: 0
Training loss: 3.071627140045166
Validation loss: 2.709898264177384

Epoch: 6| Step: 1
Training loss: 2.776589870452881
Validation loss: 2.708431610497095

Epoch: 6| Step: 2
Training loss: 2.8614184856414795
Validation loss: 2.700927742065922

Epoch: 6| Step: 3
Training loss: 2.5978970527648926
Validation loss: 2.7012015337585122

Epoch: 6| Step: 4
Training loss: 2.2970547676086426
Validation loss: 2.698623111171107

Epoch: 6| Step: 5
Training loss: 4.019388198852539
Validation loss: 2.697886815635107

Epoch: 6| Step: 6
Training loss: 3.273362159729004
Validation loss: 2.698220032517628

Epoch: 6| Step: 7
Training loss: 2.7854371070861816
Validation loss: 2.6942119803479923

Epoch: 6| Step: 8
Training loss: 3.181743621826172
Validation loss: 2.6983280899704143

Epoch: 6| Step: 9
Training loss: 2.898313045501709
Validation loss: 2.694830261250978

Epoch: 6| Step: 10
Training loss: 3.061915874481201
Validation loss: 2.696736002481112

Epoch: 6| Step: 11
Training loss: 2.6337010860443115
Validation loss: 2.6916550692691597

Epoch: 6| Step: 12
Training loss: 1.936399221420288
Validation loss: 2.6942108062005814

Epoch: 6| Step: 13
Training loss: 2.591763496398926
Validation loss: 2.6938791326297227

Epoch: 33| Step: 0
Training loss: 1.7976709604263306
Validation loss: 2.6959545561062392

Epoch: 6| Step: 1
Training loss: 3.651945114135742
Validation loss: 2.694506137601791

Epoch: 6| Step: 2
Training loss: 2.762671947479248
Validation loss: 2.6965887315811647

Epoch: 6| Step: 3
Training loss: 2.830287456512451
Validation loss: 2.6994072955141784

Epoch: 6| Step: 4
Training loss: 2.7665600776672363
Validation loss: 2.6984455457297702

Epoch: 6| Step: 5
Training loss: 3.5033490657806396
Validation loss: 2.6971540451049805

Epoch: 6| Step: 6
Training loss: 3.2983884811401367
Validation loss: 2.688577864759712

Epoch: 6| Step: 7
Training loss: 2.392896890640259
Validation loss: 2.6916737735912366

Epoch: 6| Step: 8
Training loss: 2.4774203300476074
Validation loss: 2.6952153046925864

Epoch: 6| Step: 9
Training loss: 2.527966022491455
Validation loss: 2.6921044780362036

Epoch: 6| Step: 10
Training loss: 3.2378406524658203
Validation loss: 2.696345454903059

Epoch: 6| Step: 11
Training loss: 2.857456684112549
Validation loss: 2.6899234300018637

Epoch: 6| Step: 12
Training loss: 2.988802433013916
Validation loss: 2.6910272003501974

Epoch: 6| Step: 13
Training loss: 3.018151044845581
Validation loss: 2.690025742335986

Epoch: 34| Step: 0
Training loss: 3.1217522621154785
Validation loss: 2.6910434589591077

Epoch: 6| Step: 1
Training loss: 1.9485654830932617
Validation loss: 2.6942432747092298

Epoch: 6| Step: 2
Training loss: 2.7567670345306396
Validation loss: 2.69439451156124

Epoch: 6| Step: 3
Training loss: 2.2766778469085693
Validation loss: 2.694500248919251

Epoch: 6| Step: 4
Training loss: 2.8445448875427246
Validation loss: 2.694548483817808

Epoch: 6| Step: 5
Training loss: 3.581376552581787
Validation loss: 2.6915984512657247

Epoch: 6| Step: 6
Training loss: 2.260390520095825
Validation loss: 2.6895716190338135

Epoch: 6| Step: 7
Training loss: 3.577359199523926
Validation loss: 2.6893273220267346

Epoch: 6| Step: 8
Training loss: 2.6608643531799316
Validation loss: 2.6845733478505123

Epoch: 6| Step: 9
Training loss: 3.2426562309265137
Validation loss: 2.6818951791332615

Epoch: 6| Step: 10
Training loss: 2.785691738128662
Validation loss: 2.680853792416152

Epoch: 6| Step: 11
Training loss: 2.853048324584961
Validation loss: 2.6815899238791516

Epoch: 6| Step: 12
Training loss: 3.458864212036133
Validation loss: 2.681284878843574

Epoch: 6| Step: 13
Training loss: 2.4797842502593994
Validation loss: 2.6799007974645144

Epoch: 35| Step: 0
Training loss: 2.0812344551086426
Validation loss: 2.6838191427210325

Epoch: 6| Step: 1
Training loss: 3.0052833557128906
Validation loss: 2.678951847937799

Epoch: 6| Step: 2
Training loss: 3.1242852210998535
Validation loss: 2.690046730861869

Epoch: 6| Step: 3
Training loss: 2.052917957305908
Validation loss: 2.7054718617470033

Epoch: 6| Step: 4
Training loss: 3.377030849456787
Validation loss: 2.6929372433693177

Epoch: 6| Step: 5
Training loss: 2.7566514015197754
Validation loss: 2.6849943745520806

Epoch: 6| Step: 6
Training loss: 3.9686856269836426
Validation loss: 2.6805163891084733

Epoch: 6| Step: 7
Training loss: 2.434020519256592
Validation loss: 2.675406645703059

Epoch: 6| Step: 8
Training loss: 2.6728296279907227
Validation loss: 2.6744497155630462

Epoch: 6| Step: 9
Training loss: 3.369842529296875
Validation loss: 2.6723056454812326

Epoch: 6| Step: 10
Training loss: 2.2607295513153076
Validation loss: 2.6727640423723447

Epoch: 6| Step: 11
Training loss: 2.9197940826416016
Validation loss: 2.6725294820723997

Epoch: 6| Step: 12
Training loss: 3.341765880584717
Validation loss: 2.6735136047486336

Epoch: 6| Step: 13
Training loss: 2.396010160446167
Validation loss: 2.6754934223749305

Epoch: 36| Step: 0
Training loss: 2.727822780609131
Validation loss: 2.674786501033332

Epoch: 6| Step: 1
Training loss: 3.151258945465088
Validation loss: 2.6748628641969416

Epoch: 6| Step: 2
Training loss: 2.052032947540283
Validation loss: 2.6726770029273084

Epoch: 6| Step: 3
Training loss: 2.6278300285339355
Validation loss: 2.6757682343964935

Epoch: 6| Step: 4
Training loss: 2.513294219970703
Validation loss: 2.6723012283284175

Epoch: 6| Step: 5
Training loss: 3.5252597332000732
Validation loss: 2.671099647398918

Epoch: 6| Step: 6
Training loss: 2.343144416809082
Validation loss: 2.6678173977841615

Epoch: 6| Step: 7
Training loss: 3.8001668453216553
Validation loss: 2.6720666244465816

Epoch: 6| Step: 8
Training loss: 2.6926398277282715
Validation loss: 2.6712456877513597

Epoch: 6| Step: 9
Training loss: 2.9765634536743164
Validation loss: 2.669401773842432

Epoch: 6| Step: 10
Training loss: 3.7335801124572754
Validation loss: 2.666814863040883

Epoch: 6| Step: 11
Training loss: 2.3093221187591553
Validation loss: 2.6673679685079925

Epoch: 6| Step: 12
Training loss: 2.6179351806640625
Validation loss: 2.670280874416392

Epoch: 6| Step: 13
Training loss: 2.7459492683410645
Validation loss: 2.67032640980136

Epoch: 37| Step: 0
Training loss: 3.219276189804077
Validation loss: 2.6719647197313208

Epoch: 6| Step: 1
Training loss: 3.135413408279419
Validation loss: 2.6700184473427395

Epoch: 6| Step: 2
Training loss: 3.080348014831543
Validation loss: 2.663999398549398

Epoch: 6| Step: 3
Training loss: 1.9330626726150513
Validation loss: 2.6634734625457437

Epoch: 6| Step: 4
Training loss: 2.7320942878723145
Validation loss: 2.661700825537405

Epoch: 6| Step: 5
Training loss: 2.560574769973755
Validation loss: 2.6629064467645462

Epoch: 6| Step: 6
Training loss: 3.1647212505340576
Validation loss: 2.6637483950584167

Epoch: 6| Step: 7
Training loss: 3.381427526473999
Validation loss: 2.6618703462744273

Epoch: 6| Step: 8
Training loss: 2.7097389698028564
Validation loss: 2.6614279465008805

Epoch: 6| Step: 9
Training loss: 2.7502267360687256
Validation loss: 2.663295094684888

Epoch: 6| Step: 10
Training loss: 1.9354172945022583
Validation loss: 2.663145849781652

Epoch: 6| Step: 11
Training loss: 2.9823238849639893
Validation loss: 2.6609293465973227

Epoch: 6| Step: 12
Training loss: 3.413173198699951
Validation loss: 2.6627050163925334

Epoch: 6| Step: 13
Training loss: 2.780729055404663
Validation loss: 2.6648045611637894

Epoch: 38| Step: 0
Training loss: 2.30621337890625
Validation loss: 2.664446892276887

Epoch: 6| Step: 1
Training loss: 3.581962823867798
Validation loss: 2.669635631704843

Epoch: 6| Step: 2
Training loss: 2.1637473106384277
Validation loss: 2.663553432751727

Epoch: 6| Step: 3
Training loss: 3.548961877822876
Validation loss: 2.6664178448338665

Epoch: 6| Step: 4
Training loss: 3.311231851577759
Validation loss: 2.6648973931548414

Epoch: 6| Step: 5
Training loss: 2.169487476348877
Validation loss: 2.6748500536846858

Epoch: 6| Step: 6
Training loss: 2.2842471599578857
Validation loss: 2.679587359069496

Epoch: 6| Step: 7
Training loss: 2.330160140991211
Validation loss: 2.6968652971329226

Epoch: 6| Step: 8
Training loss: 3.245086669921875
Validation loss: 2.6950639037675757

Epoch: 6| Step: 9
Training loss: 2.676065683364868
Validation loss: 2.6781425194073747

Epoch: 6| Step: 10
Training loss: 2.866421699523926
Validation loss: 2.6773353366441626

Epoch: 6| Step: 11
Training loss: 2.622981071472168
Validation loss: 2.6567601593591834

Epoch: 6| Step: 12
Training loss: 3.4889578819274902
Validation loss: 2.658266916069933

Epoch: 6| Step: 13
Training loss: 3.3725414276123047
Validation loss: 2.653653916492257

Epoch: 39| Step: 0
Training loss: 2.7588350772857666
Validation loss: 2.65947953859965

Epoch: 6| Step: 1
Training loss: 2.912200450897217
Validation loss: 2.6581997256125174

Epoch: 6| Step: 2
Training loss: 2.4907021522521973
Validation loss: 2.664145108192198

Epoch: 6| Step: 3
Training loss: 2.6542325019836426
Validation loss: 2.6650452370284707

Epoch: 6| Step: 4
Training loss: 2.0220625400543213
Validation loss: 2.662273536446274

Epoch: 6| Step: 5
Training loss: 2.620934247970581
Validation loss: 2.6613236678543912

Epoch: 6| Step: 6
Training loss: 3.4370880126953125
Validation loss: 2.656831390114241

Epoch: 6| Step: 7
Training loss: 2.190321445465088
Validation loss: 2.6573879308598016

Epoch: 6| Step: 8
Training loss: 3.0516867637634277
Validation loss: 2.654477919301679

Epoch: 6| Step: 9
Training loss: 3.2630717754364014
Validation loss: 2.6520212106807257

Epoch: 6| Step: 10
Training loss: 3.4790151119232178
Validation loss: 2.652536407593758

Epoch: 6| Step: 11
Training loss: 3.5121355056762695
Validation loss: 2.6478095464808966

Epoch: 6| Step: 12
Training loss: 2.8315253257751465
Validation loss: 2.6484825508568877

Epoch: 6| Step: 13
Training loss: 2.250336170196533
Validation loss: 2.647265249683011

Epoch: 40| Step: 0
Training loss: 2.6588211059570312
Validation loss: 2.648930690621817

Epoch: 6| Step: 1
Training loss: 3.2044949531555176
Validation loss: 2.6490026520144556

Epoch: 6| Step: 2
Training loss: 2.298429012298584
Validation loss: 2.648608958849343

Epoch: 6| Step: 3
Training loss: 3.4444570541381836
Validation loss: 2.6509600454761135

Epoch: 6| Step: 4
Training loss: 2.348480701446533
Validation loss: 2.6512004816403953

Epoch: 6| Step: 5
Training loss: 3.2372169494628906
Validation loss: 2.6540166280602895

Epoch: 6| Step: 6
Training loss: 2.5972957611083984
Validation loss: 2.6584697692624983

Epoch: 6| Step: 7
Training loss: 2.7261180877685547
Validation loss: 2.6667409891723306

Epoch: 6| Step: 8
Training loss: 3.132106304168701
Validation loss: 2.6633090306353826

Epoch: 6| Step: 9
Training loss: 2.6198525428771973
Validation loss: 2.6521539098473004

Epoch: 6| Step: 10
Training loss: 2.5218193531036377
Validation loss: 2.65270665384108

Epoch: 6| Step: 11
Training loss: 2.690648078918457
Validation loss: 2.648451151386384

Epoch: 6| Step: 12
Training loss: 3.2948474884033203
Validation loss: 2.652582960744058

Epoch: 6| Step: 13
Training loss: 2.897597312927246
Validation loss: 2.647542402308474

Epoch: 41| Step: 0
Training loss: 3.0618960857391357
Validation loss: 2.64390294782577

Epoch: 6| Step: 1
Training loss: 2.352215528488159
Validation loss: 2.6464456101899505

Epoch: 6| Step: 2
Training loss: 2.385474920272827
Validation loss: 2.640145501782817

Epoch: 6| Step: 3
Training loss: 3.097355365753174
Validation loss: 2.6418094404282106

Epoch: 6| Step: 4
Training loss: 3.108689785003662
Validation loss: 2.6418988499590146

Epoch: 6| Step: 5
Training loss: 2.6061458587646484
Validation loss: 2.6439904602625037

Epoch: 6| Step: 6
Training loss: 3.0377888679504395
Validation loss: 2.6401719739360194

Epoch: 6| Step: 7
Training loss: 2.7881929874420166
Validation loss: 2.6402556255299556

Epoch: 6| Step: 8
Training loss: 2.635420799255371
Validation loss: 2.6465473482685704

Epoch: 6| Step: 9
Training loss: 2.5141122341156006
Validation loss: 2.6423258576341855

Epoch: 6| Step: 10
Training loss: 3.041384220123291
Validation loss: 2.6506290076881327

Epoch: 6| Step: 11
Training loss: 2.8612446784973145
Validation loss: 2.6502617354034097

Epoch: 6| Step: 12
Training loss: 2.9535140991210938
Validation loss: 2.644407787630635

Epoch: 6| Step: 13
Training loss: 3.347752094268799
Validation loss: 2.641596012218024

Epoch: 42| Step: 0
Training loss: 2.2443933486938477
Validation loss: 2.6408030140784478

Epoch: 6| Step: 1
Training loss: 3.3023533821105957
Validation loss: 2.6417662020652526

Epoch: 6| Step: 2
Training loss: 2.935694694519043
Validation loss: 2.6400266565302366

Epoch: 6| Step: 3
Training loss: 3.2910313606262207
Validation loss: 2.6418647612294843

Epoch: 6| Step: 4
Training loss: 3.1251845359802246
Validation loss: 2.641111917393182

Epoch: 6| Step: 5
Training loss: 3.4734749794006348
Validation loss: 2.6403833691791823

Epoch: 6| Step: 6
Training loss: 3.1265463829040527
Validation loss: 2.6418460876710954

Epoch: 6| Step: 7
Training loss: 2.973353385925293
Validation loss: 2.635274430756928

Epoch: 6| Step: 8
Training loss: 2.6370697021484375
Validation loss: 2.6384642483085714

Epoch: 6| Step: 9
Training loss: 1.9942400455474854
Validation loss: 2.639047343243835

Epoch: 6| Step: 10
Training loss: 2.275826930999756
Validation loss: 2.635393791301276

Epoch: 6| Step: 11
Training loss: 3.0063986778259277
Validation loss: 2.6333336881411973

Epoch: 6| Step: 12
Training loss: 2.819088935852051
Validation loss: 2.637510945720057

Epoch: 6| Step: 13
Training loss: 1.9014477729797363
Validation loss: 2.6367842253818305

Epoch: 43| Step: 0
Training loss: 2.6590206623077393
Validation loss: 2.6399058962381012

Epoch: 6| Step: 1
Training loss: 1.9813930988311768
Validation loss: 2.641511324913271

Epoch: 6| Step: 2
Training loss: 3.131206512451172
Validation loss: 2.642038106918335

Epoch: 6| Step: 3
Training loss: 4.574347496032715
Validation loss: 2.641641475821054

Epoch: 6| Step: 4
Training loss: 1.9491634368896484
Validation loss: 2.6338394482930503

Epoch: 6| Step: 5
Training loss: 2.833977460861206
Validation loss: 2.631687915453347

Epoch: 6| Step: 6
Training loss: 3.049973487854004
Validation loss: 2.631144913293982

Epoch: 6| Step: 7
Training loss: 2.843506336212158
Validation loss: 2.6331101950778755

Epoch: 6| Step: 8
Training loss: 2.3243942260742188
Validation loss: 2.6276988342244136

Epoch: 6| Step: 9
Training loss: 2.6671700477600098
Validation loss: 2.6312136188630135

Epoch: 6| Step: 10
Training loss: 2.438775062561035
Validation loss: 2.6310168068896056

Epoch: 6| Step: 11
Training loss: 3.1606247425079346
Validation loss: 2.6310642944869174

Epoch: 6| Step: 12
Training loss: 3.1494998931884766
Validation loss: 2.6377029111308437

Epoch: 6| Step: 13
Training loss: 2.5008225440979004
Validation loss: 2.6363285151861047

Epoch: 44| Step: 0
Training loss: 3.514378070831299
Validation loss: 2.635132920357489

Epoch: 6| Step: 1
Training loss: 2.5138015747070312
Validation loss: 2.6347560267294607

Epoch: 6| Step: 2
Training loss: 3.4144396781921387
Validation loss: 2.637551828097272

Epoch: 6| Step: 3
Training loss: 2.2232437133789062
Validation loss: 2.6376718167335755

Epoch: 6| Step: 4
Training loss: 2.599278211593628
Validation loss: 2.6400227623601116

Epoch: 6| Step: 5
Training loss: 3.066267967224121
Validation loss: 2.634142034797258

Epoch: 6| Step: 6
Training loss: 3.112356424331665
Validation loss: 2.6343947815638717

Epoch: 6| Step: 7
Training loss: 2.5323877334594727
Validation loss: 2.6399704692184285

Epoch: 6| Step: 8
Training loss: 2.7869505882263184
Validation loss: 2.64914716956436

Epoch: 6| Step: 9
Training loss: 2.667893171310425
Validation loss: 2.6400044912933023

Epoch: 6| Step: 10
Training loss: 2.472601890563965
Validation loss: 2.6424080351347565

Epoch: 6| Step: 11
Training loss: 2.704087972640991
Validation loss: 2.630215332072268

Epoch: 6| Step: 12
Training loss: 2.7080576419830322
Validation loss: 2.6309738184816096

Epoch: 6| Step: 13
Training loss: 3.2769381999969482
Validation loss: 2.634943595496557

Epoch: 45| Step: 0
Training loss: 2.4757044315338135
Validation loss: 2.6286118953458724

Epoch: 6| Step: 1
Training loss: 2.6302990913391113
Validation loss: 2.6315793696270195

Epoch: 6| Step: 2
Training loss: 3.01377010345459
Validation loss: 2.6287946701049805

Epoch: 6| Step: 3
Training loss: 3.4854354858398438
Validation loss: 2.626121013395248

Epoch: 6| Step: 4
Training loss: 3.0285496711730957
Validation loss: 2.6273798096564507

Epoch: 6| Step: 5
Training loss: 2.6270995140075684
Validation loss: 2.625543625124039

Epoch: 6| Step: 6
Training loss: 2.0671579837799072
Validation loss: 2.6245458202977336

Epoch: 6| Step: 7
Training loss: 2.382523775100708
Validation loss: 2.6258880938253095

Epoch: 6| Step: 8
Training loss: 3.0078866481781006
Validation loss: 2.6242387012768815

Epoch: 6| Step: 9
Training loss: 2.4249320030212402
Validation loss: 2.626127045641663

Epoch: 6| Step: 10
Training loss: 2.6706604957580566
Validation loss: 2.6213888070916616

Epoch: 6| Step: 11
Training loss: 2.9852471351623535
Validation loss: 2.623996747437344

Epoch: 6| Step: 12
Training loss: 3.3705780506134033
Validation loss: 2.6291927663228845

Epoch: 6| Step: 13
Training loss: 3.460458517074585
Validation loss: 2.6316991416356896

Epoch: 46| Step: 0
Training loss: 2.980142116546631
Validation loss: 2.640222931420931

Epoch: 6| Step: 1
Training loss: 3.0684492588043213
Validation loss: 2.6453951686941166

Epoch: 6| Step: 2
Training loss: 3.0196399688720703
Validation loss: 2.6361488167957594

Epoch: 6| Step: 3
Training loss: 3.2909181118011475
Validation loss: 2.6369453450684905

Epoch: 6| Step: 4
Training loss: 1.9194352626800537
Validation loss: 2.6416265836326023

Epoch: 6| Step: 5
Training loss: 2.4753546714782715
Validation loss: 2.652120359482304

Epoch: 6| Step: 6
Training loss: 2.1147267818450928
Validation loss: 2.6924325702010945

Epoch: 6| Step: 7
Training loss: 3.418499708175659
Validation loss: 2.69316017499534

Epoch: 6| Step: 8
Training loss: 3.797290325164795
Validation loss: 2.6582044427112868

Epoch: 6| Step: 9
Training loss: 2.3514859676361084
Validation loss: 2.6288782473533385

Epoch: 6| Step: 10
Training loss: 2.6671512126922607
Validation loss: 2.621536103628015

Epoch: 6| Step: 11
Training loss: 3.0492124557495117
Validation loss: 2.6224104409576743

Epoch: 6| Step: 12
Training loss: 2.658900260925293
Validation loss: 2.633022444222563

Epoch: 6| Step: 13
Training loss: 2.4091484546661377
Validation loss: 2.644349431478849

Epoch: 47| Step: 0
Training loss: 2.6233291625976562
Validation loss: 2.648047924041748

Epoch: 6| Step: 1
Training loss: 3.034183979034424
Validation loss: 2.6567367148655716

Epoch: 6| Step: 2
Training loss: 2.4572715759277344
Validation loss: 2.6432014280749905

Epoch: 6| Step: 3
Training loss: 2.679079294204712
Validation loss: 2.6500411853995374

Epoch: 6| Step: 4
Training loss: 3.043728828430176
Validation loss: 2.6515521669900544

Epoch: 6| Step: 5
Training loss: 2.2639904022216797
Validation loss: 2.639318161113288

Epoch: 6| Step: 6
Training loss: 2.4857609272003174
Validation loss: 2.641145549794679

Epoch: 6| Step: 7
Training loss: 2.6814143657684326
Validation loss: 2.6420333718740814

Epoch: 6| Step: 8
Training loss: 2.9639878273010254
Validation loss: 2.63812860878565

Epoch: 6| Step: 9
Training loss: 2.895051956176758
Validation loss: 2.6294661978239655

Epoch: 6| Step: 10
Training loss: 3.0104808807373047
Validation loss: 2.6318037484281804

Epoch: 6| Step: 11
Training loss: 3.688399314880371
Validation loss: 2.632454446567002

Epoch: 6| Step: 12
Training loss: 2.3710711002349854
Validation loss: 2.627559788765446

Epoch: 6| Step: 13
Training loss: 3.7360904216766357
Validation loss: 2.6236287086240706

Epoch: 48| Step: 0
Training loss: 2.815216064453125
Validation loss: 2.6181320375011814

Epoch: 6| Step: 1
Training loss: 2.8503799438476562
Validation loss: 2.6229646718630226

Epoch: 6| Step: 2
Training loss: 2.3868212699890137
Validation loss: 2.6188268507680585

Epoch: 6| Step: 3
Training loss: 2.039707660675049
Validation loss: 2.621988183708601

Epoch: 6| Step: 4
Training loss: 2.807647943496704
Validation loss: 2.6287583381898942

Epoch: 6| Step: 5
Training loss: 2.842122793197632
Validation loss: 2.632049206764467

Epoch: 6| Step: 6
Training loss: 2.8149237632751465
Validation loss: 2.632922949329499

Epoch: 6| Step: 7
Training loss: 3.0420570373535156
Validation loss: 2.6326905194149224

Epoch: 6| Step: 8
Training loss: 3.1092944145202637
Validation loss: 2.630255837594309

Epoch: 6| Step: 9
Training loss: 3.5319814682006836
Validation loss: 2.621002366465907

Epoch: 6| Step: 10
Training loss: 2.546502113342285
Validation loss: 2.621496726107854

Epoch: 6| Step: 11
Training loss: 2.6025590896606445
Validation loss: 2.618419203706967

Epoch: 6| Step: 12
Training loss: 3.215611457824707
Validation loss: 2.6160069896328833

Epoch: 6| Step: 13
Training loss: 2.509333372116089
Validation loss: 2.6154437885489514

Epoch: 49| Step: 0
Training loss: 2.0084753036499023
Validation loss: 2.61375016807228

Epoch: 6| Step: 1
Training loss: 2.588336706161499
Validation loss: 2.6100541776226414

Epoch: 6| Step: 2
Training loss: 2.8965001106262207
Validation loss: 2.615612463284564

Epoch: 6| Step: 3
Training loss: 3.205724000930786
Validation loss: 2.6143801622493292

Epoch: 6| Step: 4
Training loss: 2.976792335510254
Validation loss: 2.6171291720482612

Epoch: 6| Step: 5
Training loss: 3.06717586517334
Validation loss: 2.6127191435906196

Epoch: 6| Step: 6
Training loss: 2.7176337242126465
Validation loss: 2.6134940475545902

Epoch: 6| Step: 7
Training loss: 2.9724690914154053
Validation loss: 2.6127915202930407

Epoch: 6| Step: 8
Training loss: 2.883147716522217
Validation loss: 2.621546535081761

Epoch: 6| Step: 9
Training loss: 3.3679819107055664
Validation loss: 2.6182126101627143

Epoch: 6| Step: 10
Training loss: 2.6275925636291504
Validation loss: 2.6220934416658137

Epoch: 6| Step: 11
Training loss: 3.083019971847534
Validation loss: 2.618323520947528

Epoch: 6| Step: 12
Training loss: 2.7106146812438965
Validation loss: 2.620077476706556

Epoch: 6| Step: 13
Training loss: 1.5007011890411377
Validation loss: 2.6125842294385357

Epoch: 50| Step: 0
Training loss: 2.7959775924682617
Validation loss: 2.6119398224738335

Epoch: 6| Step: 1
Training loss: 3.4154555797576904
Validation loss: 2.6089858060242026

Epoch: 6| Step: 2
Training loss: 2.197861433029175
Validation loss: 2.6097525729927966

Epoch: 6| Step: 3
Training loss: 3.3702850341796875
Validation loss: 2.612737171111568

Epoch: 6| Step: 4
Training loss: 2.4888339042663574
Validation loss: 2.612213473166189

Epoch: 6| Step: 5
Training loss: 3.4500813484191895
Validation loss: 2.6116949230112056

Epoch: 6| Step: 6
Training loss: 2.292109251022339
Validation loss: 2.613621663021785

Epoch: 6| Step: 7
Training loss: 2.899061679840088
Validation loss: 2.615408933290871

Epoch: 6| Step: 8
Training loss: 2.3149287700653076
Validation loss: 2.6119460880115466

Epoch: 6| Step: 9
Training loss: 3.280491352081299
Validation loss: 2.6108506725680445

Epoch: 6| Step: 10
Training loss: 2.289628505706787
Validation loss: 2.610777296045775

Epoch: 6| Step: 11
Training loss: 2.999051332473755
Validation loss: 2.6124235968435965

Epoch: 6| Step: 12
Training loss: 2.6449546813964844
Validation loss: 2.61234950506559

Epoch: 6| Step: 13
Training loss: 2.54239559173584
Validation loss: 2.624317184571297

Epoch: 51| Step: 0
Training loss: 2.3776116371154785
Validation loss: 2.616968967581308

Epoch: 6| Step: 1
Training loss: 2.9256203174591064
Validation loss: 2.6161975988777737

Epoch: 6| Step: 2
Training loss: 3.014113426208496
Validation loss: 2.6027515703631985

Epoch: 6| Step: 3
Training loss: 3.1493496894836426
Validation loss: 2.6029559719947075

Epoch: 6| Step: 4
Training loss: 3.0369527339935303
Validation loss: 2.606761893918437

Epoch: 6| Step: 5
Training loss: 2.6220827102661133
Validation loss: 2.6022312589870986

Epoch: 6| Step: 6
Training loss: 2.3109521865844727
Validation loss: 2.6043159013153403

Epoch: 6| Step: 7
Training loss: 2.732978582382202
Validation loss: 2.6033703191306

Epoch: 6| Step: 8
Training loss: 2.849818706512451
Validation loss: 2.611441607116371

Epoch: 6| Step: 9
Training loss: 2.872589111328125
Validation loss: 2.6059074760765157

Epoch: 6| Step: 10
Training loss: 2.3443048000335693
Validation loss: 2.613202700050928

Epoch: 6| Step: 11
Training loss: 3.573467254638672
Validation loss: 2.611918341728949

Epoch: 6| Step: 12
Training loss: 2.1364054679870605
Validation loss: 2.609881301080027

Epoch: 6| Step: 13
Training loss: 3.3908491134643555
Validation loss: 2.607564901792875

Epoch: 52| Step: 0
Training loss: 2.7629570960998535
Validation loss: 2.6087835937417965

Epoch: 6| Step: 1
Training loss: 1.5933992862701416
Validation loss: 2.6105836360685286

Epoch: 6| Step: 2
Training loss: 2.2827749252319336
Validation loss: 2.613045759098504

Epoch: 6| Step: 3
Training loss: 2.5774102210998535
Validation loss: 2.6113352903755764

Epoch: 6| Step: 4
Training loss: 3.0284950733184814
Validation loss: 2.604270386439498

Epoch: 6| Step: 5
Training loss: 3.7799813747406006
Validation loss: 2.6076184857276177

Epoch: 6| Step: 6
Training loss: 2.0638267993927
Validation loss: 2.6014878442210536

Epoch: 6| Step: 7
Training loss: 3.213944911956787
Validation loss: 2.5982719493168656

Epoch: 6| Step: 8
Training loss: 3.0238826274871826
Validation loss: 2.598332174362675

Epoch: 6| Step: 9
Training loss: 2.183312177658081
Validation loss: 2.600308951511178

Epoch: 6| Step: 10
Training loss: 3.4528133869171143
Validation loss: 2.5983434236177834

Epoch: 6| Step: 11
Training loss: 3.0265140533447266
Validation loss: 2.5977293086308304

Epoch: 6| Step: 12
Training loss: 2.7368059158325195
Validation loss: 2.601055242682016

Epoch: 6| Step: 13
Training loss: 3.7247695922851562
Validation loss: 2.6000311400300715

Epoch: 53| Step: 0
Training loss: 3.566237449645996
Validation loss: 2.6023717080393145

Epoch: 6| Step: 1
Training loss: 3.1145577430725098
Validation loss: 2.5990483632651706

Epoch: 6| Step: 2
Training loss: 1.8583182096481323
Validation loss: 2.6007105791440575

Epoch: 6| Step: 3
Training loss: 2.9242498874664307
Validation loss: 2.5965163938460813

Epoch: 6| Step: 4
Training loss: 2.403491497039795
Validation loss: 2.595536849832022

Epoch: 6| Step: 5
Training loss: 2.8682284355163574
Validation loss: 2.5951623096260974

Epoch: 6| Step: 6
Training loss: 1.832871437072754
Validation loss: 2.5984002056942193

Epoch: 6| Step: 7
Training loss: 3.056800365447998
Validation loss: 2.6022150644692044

Epoch: 6| Step: 8
Training loss: 2.1480393409729004
Validation loss: 2.6009267068678334

Epoch: 6| Step: 9
Training loss: 3.796581506729126
Validation loss: 2.607764087697511

Epoch: 6| Step: 10
Training loss: 3.2306315898895264
Validation loss: 2.6058394152631044

Epoch: 6| Step: 11
Training loss: 2.795117139816284
Validation loss: 2.6037278944446194

Epoch: 6| Step: 12
Training loss: 2.5963616371154785
Validation loss: 2.598015503216815

Epoch: 6| Step: 13
Training loss: 2.7366092205047607
Validation loss: 2.6057729028886363

Epoch: 54| Step: 0
Training loss: 3.5452098846435547
Validation loss: 2.6008461649699877

Epoch: 6| Step: 1
Training loss: 2.0064945220947266
Validation loss: 2.6000081800645396

Epoch: 6| Step: 2
Training loss: 2.7458019256591797
Validation loss: 2.6021328074957735

Epoch: 6| Step: 3
Training loss: 3.212388038635254
Validation loss: 2.6062581359699206

Epoch: 6| Step: 4
Training loss: 3.147942304611206
Validation loss: 2.601921401998048

Epoch: 6| Step: 5
Training loss: 3.1560733318328857
Validation loss: 2.600207254450808

Epoch: 6| Step: 6
Training loss: 2.7780580520629883
Validation loss: 2.597285657800654

Epoch: 6| Step: 7
Training loss: 2.2894062995910645
Validation loss: 2.5966866964934976

Epoch: 6| Step: 8
Training loss: 2.997128486633301
Validation loss: 2.5972731703071186

Epoch: 6| Step: 9
Training loss: 2.0318143367767334
Validation loss: 2.596934723597701

Epoch: 6| Step: 10
Training loss: 3.2425742149353027
Validation loss: 2.594718122995028

Epoch: 6| Step: 11
Training loss: 2.5324974060058594
Validation loss: 2.5950564851043043

Epoch: 6| Step: 12
Training loss: 2.0797719955444336
Validation loss: 2.6017231787404707

Epoch: 6| Step: 13
Training loss: 3.2603678703308105
Validation loss: 2.6088235557720227

Epoch: 55| Step: 0
Training loss: 2.5556535720825195
Validation loss: 2.6106852818560857

Epoch: 6| Step: 1
Training loss: 3.144049644470215
Validation loss: 2.616212506448069

Epoch: 6| Step: 2
Training loss: 2.6809473037719727
Validation loss: 2.611241009927565

Epoch: 6| Step: 3
Training loss: 2.8524622917175293
Validation loss: 2.608402670070689

Epoch: 6| Step: 4
Training loss: 2.9288673400878906
Validation loss: 2.602556526020009

Epoch: 6| Step: 5
Training loss: 2.2860512733459473
Validation loss: 2.604515965266894

Epoch: 6| Step: 6
Training loss: 2.1387288570404053
Validation loss: 2.606122321979974

Epoch: 6| Step: 7
Training loss: 2.5311520099639893
Validation loss: 2.603462552511564

Epoch: 6| Step: 8
Training loss: 2.4755682945251465
Validation loss: 2.6099502937768095

Epoch: 6| Step: 9
Training loss: 3.5026628971099854
Validation loss: 2.6082058939882504

Epoch: 6| Step: 10
Training loss: 3.204840660095215
Validation loss: 2.6078356978713826

Epoch: 6| Step: 11
Training loss: 3.0713157653808594
Validation loss: 2.6052074945101173

Epoch: 6| Step: 12
Training loss: 2.8325343132019043
Validation loss: 2.604712070957307

Epoch: 6| Step: 13
Training loss: 2.740161895751953
Validation loss: 2.6046573936298327

Epoch: 56| Step: 0
Training loss: 2.601792335510254
Validation loss: 2.5928352391848

Epoch: 6| Step: 1
Training loss: 2.744309663772583
Validation loss: 2.5953407287597656

Epoch: 6| Step: 2
Training loss: 2.488755464553833
Validation loss: 2.5941289317223335

Epoch: 6| Step: 3
Training loss: 3.0827231407165527
Validation loss: 2.6036967897927887

Epoch: 6| Step: 4
Training loss: 2.223924160003662
Validation loss: 2.5993021354880383

Epoch: 6| Step: 5
Training loss: 2.6293773651123047
Validation loss: 2.6021241270085818

Epoch: 6| Step: 6
Training loss: 3.5138630867004395
Validation loss: 2.5992459686853553

Epoch: 6| Step: 7
Training loss: 2.5326032638549805
Validation loss: 2.5922699333519064

Epoch: 6| Step: 8
Training loss: 3.4819188117980957
Validation loss: 2.5924083904553483

Epoch: 6| Step: 9
Training loss: 3.0273499488830566
Validation loss: 2.59517732743294

Epoch: 6| Step: 10
Training loss: 2.576481342315674
Validation loss: 2.5976943046815935

Epoch: 6| Step: 11
Training loss: 1.9946494102478027
Validation loss: 2.595368336605769

Epoch: 6| Step: 12
Training loss: 3.0644235610961914
Validation loss: 2.5968596678908153

Epoch: 6| Step: 13
Training loss: 3.0599701404571533
Validation loss: 2.5896697223827405

Epoch: 57| Step: 0
Training loss: 2.86430025100708
Validation loss: 2.5864292960013113

Epoch: 6| Step: 1
Training loss: 3.00632381439209
Validation loss: 2.5848638191018054

Epoch: 6| Step: 2
Training loss: 2.977078914642334
Validation loss: 2.5853260358174643

Epoch: 6| Step: 3
Training loss: 3.0955650806427
Validation loss: 2.5884646318292104

Epoch: 6| Step: 4
Training loss: 2.7229490280151367
Validation loss: 2.5923367828451176

Epoch: 6| Step: 5
Training loss: 3.232253074645996
Validation loss: 2.5953193146695375

Epoch: 6| Step: 6
Training loss: 2.6156883239746094
Validation loss: 2.5938124400313183

Epoch: 6| Step: 7
Training loss: 3.409046173095703
Validation loss: 2.5961076085285475

Epoch: 6| Step: 8
Training loss: 2.7506089210510254
Validation loss: 2.59525828976785

Epoch: 6| Step: 9
Training loss: 2.4176511764526367
Validation loss: 2.5921509137717624

Epoch: 6| Step: 10
Training loss: 2.3479528427124023
Validation loss: 2.593884329642019

Epoch: 6| Step: 11
Training loss: 2.482436418533325
Validation loss: 2.596653797293222

Epoch: 6| Step: 12
Training loss: 2.589364767074585
Validation loss: 2.5944231889581166

Epoch: 6| Step: 13
Training loss: 1.9241623878479004
Validation loss: 2.5880532431346115

Epoch: 58| Step: 0
Training loss: 2.0495595932006836
Validation loss: 2.5846873893532702

Epoch: 6| Step: 1
Training loss: 2.7223644256591797
Validation loss: 2.5903643664493354

Epoch: 6| Step: 2
Training loss: 2.3492612838745117
Validation loss: 2.5880764786915114

Epoch: 6| Step: 3
Training loss: 3.1769604682922363
Validation loss: 2.5874351968047438

Epoch: 6| Step: 4
Training loss: 2.8928322792053223
Validation loss: 2.587821001647621

Epoch: 6| Step: 5
Training loss: 1.8325031995773315
Validation loss: 2.5849827104999172

Epoch: 6| Step: 6
Training loss: 3.736767053604126
Validation loss: 2.5850836999954714

Epoch: 6| Step: 7
Training loss: 2.261461019515991
Validation loss: 2.583415477506576

Epoch: 6| Step: 8
Training loss: 3.013154983520508
Validation loss: 2.585505570134809

Epoch: 6| Step: 9
Training loss: 2.307767868041992
Validation loss: 2.5917518318340345

Epoch: 6| Step: 10
Training loss: 3.474247694015503
Validation loss: 2.601970185515701

Epoch: 6| Step: 11
Training loss: 3.1753368377685547
Validation loss: 2.6150855736065934

Epoch: 6| Step: 12
Training loss: 3.107041835784912
Validation loss: 2.6312501020328973

Epoch: 6| Step: 13
Training loss: 2.522455930709839
Validation loss: 2.6260963844996628

Epoch: 59| Step: 0
Training loss: 2.885695695877075
Validation loss: 2.6038341829853673

Epoch: 6| Step: 1
Training loss: 2.6688082218170166
Validation loss: 2.5903010291437947

Epoch: 6| Step: 2
Training loss: 2.8502540588378906
Validation loss: 2.574015543025027

Epoch: 6| Step: 3
Training loss: 3.137570381164551
Validation loss: 2.576606737670078

Epoch: 6| Step: 4
Training loss: 2.885673999786377
Validation loss: 2.581976898254887

Epoch: 6| Step: 5
Training loss: 3.084043502807617
Validation loss: 2.5805039457095567

Epoch: 6| Step: 6
Training loss: 2.8112313747406006
Validation loss: 2.583408263421828

Epoch: 6| Step: 7
Training loss: 2.3276171684265137
Validation loss: 2.585568820276568

Epoch: 6| Step: 8
Training loss: 1.9150681495666504
Validation loss: 2.59234962155742

Epoch: 6| Step: 9
Training loss: 2.3481717109680176
Validation loss: 2.5918027739371023

Epoch: 6| Step: 10
Training loss: 2.8337390422821045
Validation loss: 2.5923126333503315

Epoch: 6| Step: 11
Training loss: 2.299957275390625
Validation loss: 2.598415587538032

Epoch: 6| Step: 12
Training loss: 3.8646607398986816
Validation loss: 2.5976500280441774

Epoch: 6| Step: 13
Training loss: 3.0015814304351807
Validation loss: 2.602630853652954

Epoch: 60| Step: 0
Training loss: 2.053696632385254
Validation loss: 2.601538292823299

Epoch: 6| Step: 1
Training loss: 2.8620166778564453
Validation loss: 2.598945520257437

Epoch: 6| Step: 2
Training loss: 2.402305841445923
Validation loss: 2.5978226328408844

Epoch: 6| Step: 3
Training loss: 2.907332420349121
Validation loss: 2.587238545058876

Epoch: 6| Step: 4
Training loss: 2.836047649383545
Validation loss: 2.5836406959000455

Epoch: 6| Step: 5
Training loss: 2.832862138748169
Validation loss: 2.58448959935096

Epoch: 6| Step: 6
Training loss: 3.0119357109069824
Validation loss: 2.58211410814716

Epoch: 6| Step: 7
Training loss: 2.8595800399780273
Validation loss: 2.583477140754782

Epoch: 6| Step: 8
Training loss: 2.754828929901123
Validation loss: 2.5879959803755566

Epoch: 6| Step: 9
Training loss: 2.8124642372131348
Validation loss: 2.5880176918480986

Epoch: 6| Step: 10
Training loss: 2.840435743331909
Validation loss: 2.5808933806675736

Epoch: 6| Step: 11
Training loss: 2.7960731983184814
Validation loss: 2.5781497340048514

Epoch: 6| Step: 12
Training loss: 2.819164276123047
Validation loss: 2.577665131579163

Epoch: 6| Step: 13
Training loss: 3.247161865234375
Validation loss: 2.5786452498487247

Epoch: 61| Step: 0
Training loss: 2.7060699462890625
Validation loss: 2.57810438576565

Epoch: 6| Step: 1
Training loss: 2.2212929725646973
Validation loss: 2.5721309749029015

Epoch: 6| Step: 2
Training loss: 1.7351737022399902
Validation loss: 2.578818908301733

Epoch: 6| Step: 3
Training loss: 3.015357255935669
Validation loss: 2.577017666191183

Epoch: 6| Step: 4
Training loss: 2.8748698234558105
Validation loss: 2.5768783835954565

Epoch: 6| Step: 5
Training loss: 4.032222747802734
Validation loss: 2.5730434720234205

Epoch: 6| Step: 6
Training loss: 3.2366273403167725
Validation loss: 2.5740768986363567

Epoch: 6| Step: 7
Training loss: 3.004021644592285
Validation loss: 2.5751688018921883

Epoch: 6| Step: 8
Training loss: 1.879867434501648
Validation loss: 2.5782922288422943

Epoch: 6| Step: 9
Training loss: 3.236706495285034
Validation loss: 2.575248782352735

Epoch: 6| Step: 10
Training loss: 2.998936176300049
Validation loss: 2.5812975924502135

Epoch: 6| Step: 11
Training loss: 2.2787423133850098
Validation loss: 2.582238099908316

Epoch: 6| Step: 12
Training loss: 2.408139944076538
Validation loss: 2.5814725686145086

Epoch: 6| Step: 13
Training loss: 3.3362889289855957
Validation loss: 2.5801657681824057

Epoch: 62| Step: 0
Training loss: 3.3006436824798584
Validation loss: 2.574421408355877

Epoch: 6| Step: 1
Training loss: 2.4563169479370117
Validation loss: 2.572519189567976

Epoch: 6| Step: 2
Training loss: 2.5182182788848877
Validation loss: 2.570106332020093

Epoch: 6| Step: 3
Training loss: 2.441962957382202
Validation loss: 2.567471981048584

Epoch: 6| Step: 4
Training loss: 2.1532692909240723
Validation loss: 2.568585236867269

Epoch: 6| Step: 5
Training loss: 2.3957207202911377
Validation loss: 2.567324653748543

Epoch: 6| Step: 6
Training loss: 2.735830783843994
Validation loss: 2.568468152835805

Epoch: 6| Step: 7
Training loss: 2.491725206375122
Validation loss: 2.567675182896276

Epoch: 6| Step: 8
Training loss: 2.6795380115509033
Validation loss: 2.5633560970265377

Epoch: 6| Step: 9
Training loss: 2.405216693878174
Validation loss: 2.5669641571660198

Epoch: 6| Step: 10
Training loss: 3.164515495300293
Validation loss: 2.566404732324744

Epoch: 6| Step: 11
Training loss: 3.106121063232422
Validation loss: 2.5748036317927863

Epoch: 6| Step: 12
Training loss: 3.76934814453125
Validation loss: 2.579751158273348

Epoch: 6| Step: 13
Training loss: 3.219419240951538
Validation loss: 2.583369198665824

Epoch: 63| Step: 0
Training loss: 2.607267141342163
Validation loss: 2.5825889828384563

Epoch: 6| Step: 1
Training loss: 2.778013229370117
Validation loss: 2.5778746963829122

Epoch: 6| Step: 2
Training loss: 2.741821765899658
Validation loss: 2.575384352796821

Epoch: 6| Step: 3
Training loss: 2.728428363800049
Validation loss: 2.5714500155500186

Epoch: 6| Step: 4
Training loss: 2.033353328704834
Validation loss: 2.5699697207379084

Epoch: 6| Step: 5
Training loss: 2.529357671737671
Validation loss: 2.567923145909463

Epoch: 6| Step: 6
Training loss: 2.2077932357788086
Validation loss: 2.570818608806979

Epoch: 6| Step: 7
Training loss: 2.961784839630127
Validation loss: 2.5727849083562053

Epoch: 6| Step: 8
Training loss: 2.4163880348205566
Validation loss: 2.5765290798679477

Epoch: 6| Step: 9
Training loss: 3.8937647342681885
Validation loss: 2.57304972217929

Epoch: 6| Step: 10
Training loss: 2.782485008239746
Validation loss: 2.5764630584306616

Epoch: 6| Step: 11
Training loss: 3.729827404022217
Validation loss: 2.5680996371853735

Epoch: 6| Step: 12
Training loss: 2.536630630493164
Validation loss: 2.5629383697304675

Epoch: 6| Step: 13
Training loss: 2.3904974460601807
Validation loss: 2.5627682875561457

Epoch: 64| Step: 0
Training loss: 3.028981924057007
Validation loss: 2.5645816633778233

Epoch: 6| Step: 1
Training loss: 3.0478341579437256
Validation loss: 2.5722559421293196

Epoch: 6| Step: 2
Training loss: 2.2602837085723877
Validation loss: 2.5736810468858287

Epoch: 6| Step: 3
Training loss: 2.881441116333008
Validation loss: 2.5790010395870415

Epoch: 6| Step: 4
Training loss: 1.7190396785736084
Validation loss: 2.5708099206288657

Epoch: 6| Step: 5
Training loss: 2.206098794937134
Validation loss: 2.564706348603772

Epoch: 6| Step: 6
Training loss: 4.176841735839844
Validation loss: 2.572807240229781

Epoch: 6| Step: 7
Training loss: 2.440145254135132
Validation loss: 2.573660522378901

Epoch: 6| Step: 8
Training loss: 2.377943754196167
Validation loss: 2.5790902824812036

Epoch: 6| Step: 9
Training loss: 3.309269428253174
Validation loss: 2.5897946024453766

Epoch: 6| Step: 10
Training loss: 2.7483410835266113
Validation loss: 2.5923352318425334

Epoch: 6| Step: 11
Training loss: 2.473600387573242
Validation loss: 2.5932242562693935

Epoch: 6| Step: 12
Training loss: 3.175480365753174
Validation loss: 2.595062425059657

Epoch: 6| Step: 13
Training loss: 2.895167112350464
Validation loss: 2.5871627587144093

Epoch: 65| Step: 0
Training loss: 2.442037582397461
Validation loss: 2.576319540700605

Epoch: 6| Step: 1
Training loss: 2.7430179119110107
Validation loss: 2.571318354657901

Epoch: 6| Step: 2
Training loss: 2.940943956375122
Validation loss: 2.563713432640158

Epoch: 6| Step: 3
Training loss: 3.0580697059631348
Validation loss: 2.566449466572013

Epoch: 6| Step: 4
Training loss: 2.391254425048828
Validation loss: 2.568935066141108

Epoch: 6| Step: 5
Training loss: 2.4587044715881348
Validation loss: 2.5833532784574773

Epoch: 6| Step: 6
Training loss: 2.8619794845581055
Validation loss: 2.5927083056460143

Epoch: 6| Step: 7
Training loss: 2.7234182357788086
Validation loss: 2.5899028444802887

Epoch: 6| Step: 8
Training loss: 3.3593766689300537
Validation loss: 2.5962977229907946

Epoch: 6| Step: 9
Training loss: 2.6724562644958496
Validation loss: 2.5961876761528755

Epoch: 6| Step: 10
Training loss: 2.421320676803589
Validation loss: 2.585938089637346

Epoch: 6| Step: 11
Training loss: 2.985072135925293
Validation loss: 2.566740882012152

Epoch: 6| Step: 12
Training loss: 2.590449571609497
Validation loss: 2.561726895711755

Epoch: 6| Step: 13
Training loss: 3.2299869060516357
Validation loss: 2.557650807083294

Epoch: 66| Step: 0
Training loss: 3.7439966201782227
Validation loss: 2.5575979140497025

Epoch: 6| Step: 1
Training loss: 2.1738553047180176
Validation loss: 2.5596074724710114

Epoch: 6| Step: 2
Training loss: 2.982966899871826
Validation loss: 2.5652165259084394

Epoch: 6| Step: 3
Training loss: 2.9503960609436035
Validation loss: 2.5646765001358522

Epoch: 6| Step: 4
Training loss: 2.8088176250457764
Validation loss: 2.567205967441682

Epoch: 6| Step: 5
Training loss: 2.8776636123657227
Validation loss: 2.5655752151243147

Epoch: 6| Step: 6
Training loss: 3.0116875171661377
Validation loss: 2.567385922196091

Epoch: 6| Step: 7
Training loss: 1.915968418121338
Validation loss: 2.565626254645727

Epoch: 6| Step: 8
Training loss: 2.0993809700012207
Validation loss: 2.5671156298729683

Epoch: 6| Step: 9
Training loss: 2.1218409538269043
Validation loss: 2.5664533620239585

Epoch: 6| Step: 10
Training loss: 3.6450695991516113
Validation loss: 2.5617643940833306

Epoch: 6| Step: 11
Training loss: 2.7151403427124023
Validation loss: 2.5668324808920584

Epoch: 6| Step: 12
Training loss: 2.5723114013671875
Validation loss: 2.581080241869855

Epoch: 6| Step: 13
Training loss: 2.925074338912964
Validation loss: 2.5841095062994186

Epoch: 67| Step: 0
Training loss: 3.486285448074341
Validation loss: 2.5838807936637633

Epoch: 6| Step: 1
Training loss: 2.1186039447784424
Validation loss: 2.5898241355854976

Epoch: 6| Step: 2
Training loss: 2.4249985218048096
Validation loss: 2.591924572503695

Epoch: 6| Step: 3
Training loss: 3.2567152976989746
Validation loss: 2.5894928824517036

Epoch: 6| Step: 4
Training loss: 2.371978998184204
Validation loss: 2.582012664887213

Epoch: 6| Step: 5
Training loss: 3.1410231590270996
Validation loss: 2.573206055548883

Epoch: 6| Step: 6
Training loss: 2.5209498405456543
Validation loss: 2.574477805886217

Epoch: 6| Step: 7
Training loss: 2.466251850128174
Validation loss: 2.5802379961936706

Epoch: 6| Step: 8
Training loss: 2.758538246154785
Validation loss: 2.5781126406884964

Epoch: 6| Step: 9
Training loss: 2.1704556941986084
Validation loss: 2.5736988795700895

Epoch: 6| Step: 10
Training loss: 2.938708782196045
Validation loss: 2.567281664058726

Epoch: 6| Step: 11
Training loss: 3.3087291717529297
Validation loss: 2.566518375950475

Epoch: 6| Step: 12
Training loss: 2.9330432415008545
Validation loss: 2.558731563629643

Epoch: 6| Step: 13
Training loss: 2.4470105171203613
Validation loss: 2.5569223691058416

Epoch: 68| Step: 0
Training loss: 2.968839168548584
Validation loss: 2.551163404218612

Epoch: 6| Step: 1
Training loss: 2.999612808227539
Validation loss: 2.5549224576642438

Epoch: 6| Step: 2
Training loss: 2.2121291160583496
Validation loss: 2.554716112793133

Epoch: 6| Step: 3
Training loss: 2.8625359535217285
Validation loss: 2.554026492180363

Epoch: 6| Step: 4
Training loss: 2.0902187824249268
Validation loss: 2.5593346652164253

Epoch: 6| Step: 5
Training loss: 2.3566174507141113
Validation loss: 2.556890013397381

Epoch: 6| Step: 6
Training loss: 3.2354488372802734
Validation loss: 2.560021464542676

Epoch: 6| Step: 7
Training loss: 3.1278085708618164
Validation loss: 2.561227806152836

Epoch: 6| Step: 8
Training loss: 2.186048746109009
Validation loss: 2.5598586323440715

Epoch: 6| Step: 9
Training loss: 2.928800582885742
Validation loss: 2.5500052205977903

Epoch: 6| Step: 10
Training loss: 2.6219520568847656
Validation loss: 2.5476839568025325

Epoch: 6| Step: 11
Training loss: 2.5531673431396484
Validation loss: 2.54672852382865

Epoch: 6| Step: 12
Training loss: 3.477634906768799
Validation loss: 2.547626692761657

Epoch: 6| Step: 13
Training loss: 2.8150033950805664
Validation loss: 2.548896305022701

Epoch: 69| Step: 0
Training loss: 2.6209869384765625
Validation loss: 2.5482315119876655

Epoch: 6| Step: 1
Training loss: 2.896033763885498
Validation loss: 2.5470368528878815

Epoch: 6| Step: 2
Training loss: 2.8880064487457275
Validation loss: 2.5487469498829176

Epoch: 6| Step: 3
Training loss: 2.980623245239258
Validation loss: 2.5471090424445366

Epoch: 6| Step: 4
Training loss: 3.221417188644409
Validation loss: 2.5457298140372

Epoch: 6| Step: 5
Training loss: 3.118788480758667
Validation loss: 2.5460336003252255

Epoch: 6| Step: 6
Training loss: 2.0588834285736084
Validation loss: 2.5462224022034676

Epoch: 6| Step: 7
Training loss: 3.0796608924865723
Validation loss: 2.5482274204172115

Epoch: 6| Step: 8
Training loss: 2.72062611579895
Validation loss: 2.5552485168621106

Epoch: 6| Step: 9
Training loss: 2.23834228515625
Validation loss: 2.5773171327447377

Epoch: 6| Step: 10
Training loss: 2.3594586849212646
Validation loss: 2.6101199298776607

Epoch: 6| Step: 11
Training loss: 2.915210723876953
Validation loss: 2.652193364276681

Epoch: 6| Step: 12
Training loss: 2.844367504119873
Validation loss: 2.6050540067816295

Epoch: 6| Step: 13
Training loss: 2.3414018154144287
Validation loss: 2.586269296625609

Epoch: 70| Step: 0
Training loss: 2.733567714691162
Validation loss: 2.5875913609740553

Epoch: 6| Step: 1
Training loss: 1.8797938823699951
Validation loss: 2.5774605094745593

Epoch: 6| Step: 2
Training loss: 2.9957327842712402
Validation loss: 2.5785387792894916

Epoch: 6| Step: 3
Training loss: 2.3040969371795654
Validation loss: 2.57755954803959

Epoch: 6| Step: 4
Training loss: 2.265387535095215
Validation loss: 2.58242695049573

Epoch: 6| Step: 5
Training loss: 2.9306352138519287
Validation loss: 2.5764630994489117

Epoch: 6| Step: 6
Training loss: 3.912703275680542
Validation loss: 2.5728682369314213

Epoch: 6| Step: 7
Training loss: 2.907125473022461
Validation loss: 2.558987973838724

Epoch: 6| Step: 8
Training loss: 2.055980682373047
Validation loss: 2.5566118481338664

Epoch: 6| Step: 9
Training loss: 3.255490303039551
Validation loss: 2.555020163136144

Epoch: 6| Step: 10
Training loss: 3.851808547973633
Validation loss: 2.55410401539136

Epoch: 6| Step: 11
Training loss: 2.5342440605163574
Validation loss: 2.56080029344046

Epoch: 6| Step: 12
Training loss: 2.053057909011841
Validation loss: 2.561296001557381

Epoch: 6| Step: 13
Training loss: 2.7169761657714844
Validation loss: 2.5693004438954015

Epoch: 71| Step: 0
Training loss: 2.2237420082092285
Validation loss: 2.5629841691704205

Epoch: 6| Step: 1
Training loss: 2.191131591796875
Validation loss: 2.5565646463824856

Epoch: 6| Step: 2
Training loss: 1.990462064743042
Validation loss: 2.557838673232704

Epoch: 6| Step: 3
Training loss: 2.004163980484009
Validation loss: 2.551133240422895

Epoch: 6| Step: 4
Training loss: 3.104947328567505
Validation loss: 2.5502719699695544

Epoch: 6| Step: 5
Training loss: 3.9557180404663086
Validation loss: 2.5484220058687272

Epoch: 6| Step: 6
Training loss: 2.7825825214385986
Validation loss: 2.5458893596485095

Epoch: 6| Step: 7
Training loss: 2.913456439971924
Validation loss: 2.5412848559758996

Epoch: 6| Step: 8
Training loss: 2.2950594425201416
Validation loss: 2.542526129753359

Epoch: 6| Step: 9
Training loss: 3.624863624572754
Validation loss: 2.548178808663481

Epoch: 6| Step: 10
Training loss: 2.748400926589966
Validation loss: 2.5440330069552184

Epoch: 6| Step: 11
Training loss: 3.0427114963531494
Validation loss: 2.5465349587061072

Epoch: 6| Step: 12
Training loss: 2.825562000274658
Validation loss: 2.546251371342649

Epoch: 6| Step: 13
Training loss: 2.4251620769500732
Validation loss: 2.551577568054199

Epoch: 72| Step: 0
Training loss: 3.274580240249634
Validation loss: 2.555237013806579

Epoch: 6| Step: 1
Training loss: 2.60428524017334
Validation loss: 2.5431010338567916

Epoch: 6| Step: 2
Training loss: 2.5910558700561523
Validation loss: 2.5441393647142636

Epoch: 6| Step: 3
Training loss: 3.026209831237793
Validation loss: 2.5471701365645214

Epoch: 6| Step: 4
Training loss: 2.109278678894043
Validation loss: 2.548186973858905

Epoch: 6| Step: 5
Training loss: 2.5987679958343506
Validation loss: 2.5517371751928843

Epoch: 6| Step: 6
Training loss: 1.7365269660949707
Validation loss: 2.554846122700681

Epoch: 6| Step: 7
Training loss: 2.6005141735076904
Validation loss: 2.5485105899072464

Epoch: 6| Step: 8
Training loss: 3.6028037071228027
Validation loss: 2.5498414270339476

Epoch: 6| Step: 9
Training loss: 3.3562979698181152
Validation loss: 2.5536559807356967

Epoch: 6| Step: 10
Training loss: 2.984011650085449
Validation loss: 2.5458074026210333

Epoch: 6| Step: 11
Training loss: 2.5090765953063965
Validation loss: 2.548477913743706

Epoch: 6| Step: 12
Training loss: 2.0367798805236816
Validation loss: 2.5489471291983

Epoch: 6| Step: 13
Training loss: 3.4811651706695557
Validation loss: 2.5497081228481826

Epoch: 73| Step: 0
Training loss: 3.0233302116394043
Validation loss: 2.5488757343702417

Epoch: 6| Step: 1
Training loss: 3.023536443710327
Validation loss: 2.551253334168465

Epoch: 6| Step: 2
Training loss: 2.18966007232666
Validation loss: 2.548125405465403

Epoch: 6| Step: 3
Training loss: 2.07378888130188
Validation loss: 2.5517026455171647

Epoch: 6| Step: 4
Training loss: 2.7976951599121094
Validation loss: 2.5438253059182117

Epoch: 6| Step: 5
Training loss: 2.677440643310547
Validation loss: 2.5519674644675305

Epoch: 6| Step: 6
Training loss: 2.612032890319824
Validation loss: 2.5465435161385486

Epoch: 6| Step: 7
Training loss: 2.7983124256134033
Validation loss: 2.5462902053709953

Epoch: 6| Step: 8
Training loss: 3.537605047225952
Validation loss: 2.546781160498178

Epoch: 6| Step: 9
Training loss: 2.713618278503418
Validation loss: 2.5447806004554994

Epoch: 6| Step: 10
Training loss: 2.947749376296997
Validation loss: 2.547220568503103

Epoch: 6| Step: 11
Training loss: 2.6204843521118164
Validation loss: 2.5484240234539075

Epoch: 6| Step: 12
Training loss: 2.482541799545288
Validation loss: 2.54040349939818

Epoch: 6| Step: 13
Training loss: 2.814587116241455
Validation loss: 2.5354802429035144

Epoch: 74| Step: 0
Training loss: 3.5563156604766846
Validation loss: 2.5372232801170758

Epoch: 6| Step: 1
Training loss: 2.539978504180908
Validation loss: 2.5339073263188845

Epoch: 6| Step: 2
Training loss: 3.4774727821350098
Validation loss: 2.533666049280474

Epoch: 6| Step: 3
Training loss: 2.4746546745300293
Validation loss: 2.5402488195767967

Epoch: 6| Step: 4
Training loss: 2.7595603466033936
Validation loss: 2.5403289384739374

Epoch: 6| Step: 5
Training loss: 3.1177866458892822
Validation loss: 2.5462290933055263

Epoch: 6| Step: 6
Training loss: 3.190727710723877
Validation loss: 2.545490291810805

Epoch: 6| Step: 7
Training loss: 2.89522647857666
Validation loss: 2.5429852970184816

Epoch: 6| Step: 8
Training loss: 3.0752177238464355
Validation loss: 2.542596094069942

Epoch: 6| Step: 9
Training loss: 2.2224457263946533
Validation loss: 2.544741443408433

Epoch: 6| Step: 10
Training loss: 1.78663170337677
Validation loss: 2.5472340840165333

Epoch: 6| Step: 11
Training loss: 2.019530773162842
Validation loss: 2.5450963333088863

Epoch: 6| Step: 12
Training loss: 2.62671160697937
Validation loss: 2.5461808635342504

Epoch: 6| Step: 13
Training loss: 2.440882444381714
Validation loss: 2.541575280568933

Epoch: 75| Step: 0
Training loss: 3.5736405849456787
Validation loss: 2.5431778046392624

Epoch: 6| Step: 1
Training loss: 2.0216996669769287
Validation loss: 2.5418888779096704

Epoch: 6| Step: 2
Training loss: 2.550543785095215
Validation loss: 2.539400146853539

Epoch: 6| Step: 3
Training loss: 3.0200600624084473
Validation loss: 2.5367550132095174

Epoch: 6| Step: 4
Training loss: 2.932701826095581
Validation loss: 2.5375971973583265

Epoch: 6| Step: 5
Training loss: 2.0641255378723145
Validation loss: 2.538937630191926

Epoch: 6| Step: 6
Training loss: 2.183440923690796
Validation loss: 2.5359372041558705

Epoch: 6| Step: 7
Training loss: 2.5964956283569336
Validation loss: 2.535160372334142

Epoch: 6| Step: 8
Training loss: 2.1533076763153076
Validation loss: 2.5328086576154156

Epoch: 6| Step: 9
Training loss: 2.357673168182373
Validation loss: 2.5293511036903626

Epoch: 6| Step: 10
Training loss: 3.5213685035705566
Validation loss: 2.5308832071160756

Epoch: 6| Step: 11
Training loss: 3.6490070819854736
Validation loss: 2.5310001296381794

Epoch: 6| Step: 12
Training loss: 2.656548500061035
Validation loss: 2.529622672706522

Epoch: 6| Step: 13
Training loss: 3.0301320552825928
Validation loss: 2.5314956557366157

Epoch: 76| Step: 0
Training loss: 3.0353918075561523
Validation loss: 2.534919907969813

Epoch: 6| Step: 1
Training loss: 3.3701112270355225
Validation loss: 2.5333064832995014

Epoch: 6| Step: 2
Training loss: 2.738523006439209
Validation loss: 2.534550723209176

Epoch: 6| Step: 3
Training loss: 3.104196071624756
Validation loss: 2.5332665751057286

Epoch: 6| Step: 4
Training loss: 2.6643190383911133
Validation loss: 2.529021196467902

Epoch: 6| Step: 5
Training loss: 1.9922962188720703
Validation loss: 2.52876042806974

Epoch: 6| Step: 6
Training loss: 1.8199050426483154
Validation loss: 2.5358214301447712

Epoch: 6| Step: 7
Training loss: 3.4606218338012695
Validation loss: 2.5365541545293664

Epoch: 6| Step: 8
Training loss: 2.4476447105407715
Validation loss: 2.5375271035778906

Epoch: 6| Step: 9
Training loss: 2.450562000274658
Validation loss: 2.541012374303674

Epoch: 6| Step: 10
Training loss: 2.6333985328674316
Validation loss: 2.534529855174403

Epoch: 6| Step: 11
Training loss: 2.751932382583618
Validation loss: 2.5349710115822415

Epoch: 6| Step: 12
Training loss: 3.04787015914917
Validation loss: 2.5502204971928752

Epoch: 6| Step: 13
Training loss: 2.468033790588379
Validation loss: 2.5580863670636247

Epoch: 77| Step: 0
Training loss: 3.1483609676361084
Validation loss: 2.5614455540974936

Epoch: 6| Step: 1
Training loss: 3.463343620300293
Validation loss: 2.5556058114574802

Epoch: 6| Step: 2
Training loss: 2.4968981742858887
Validation loss: 2.554500413197343

Epoch: 6| Step: 3
Training loss: 3.3904871940612793
Validation loss: 2.558522960191132

Epoch: 6| Step: 4
Training loss: 2.6830382347106934
Validation loss: 2.543158613225465

Epoch: 6| Step: 5
Training loss: 2.869802951812744
Validation loss: 2.535030339353828

Epoch: 6| Step: 6
Training loss: 2.28257417678833
Validation loss: 2.526293464886245

Epoch: 6| Step: 7
Training loss: 1.6470179557800293
Validation loss: 2.5236285963366107

Epoch: 6| Step: 8
Training loss: 2.5335795879364014
Validation loss: 2.5239602468347035

Epoch: 6| Step: 9
Training loss: 3.1919636726379395
Validation loss: 2.5233645336602324

Epoch: 6| Step: 10
Training loss: 2.803861141204834
Validation loss: 2.5250559263331915

Epoch: 6| Step: 11
Training loss: 2.2348461151123047
Validation loss: 2.521909744508805

Epoch: 6| Step: 12
Training loss: 2.822969913482666
Validation loss: 2.523378097882835

Epoch: 6| Step: 13
Training loss: 2.4373655319213867
Validation loss: 2.524121578021716

Epoch: 78| Step: 0
Training loss: 3.2483577728271484
Validation loss: 2.523340230347008

Epoch: 6| Step: 1
Training loss: 2.6591897010803223
Validation loss: 2.5273915747160554

Epoch: 6| Step: 2
Training loss: 3.0189404487609863
Validation loss: 2.52769559942266

Epoch: 6| Step: 3
Training loss: 2.8196849822998047
Validation loss: 2.5320203355563584

Epoch: 6| Step: 4
Training loss: 2.836611747741699
Validation loss: 2.5325134441416752

Epoch: 6| Step: 5
Training loss: 2.4940643310546875
Validation loss: 2.528871295272663

Epoch: 6| Step: 6
Training loss: 2.753089427947998
Validation loss: 2.531590525821973

Epoch: 6| Step: 7
Training loss: 2.479065418243408
Validation loss: 2.5322643967084986

Epoch: 6| Step: 8
Training loss: 3.095515727996826
Validation loss: 2.5311590087029243

Epoch: 6| Step: 9
Training loss: 2.578291893005371
Validation loss: 2.540153493163406

Epoch: 6| Step: 10
Training loss: 2.739600658416748
Validation loss: 2.535648221610695

Epoch: 6| Step: 11
Training loss: 1.8577089309692383
Validation loss: 2.5302790057274605

Epoch: 6| Step: 12
Training loss: 2.898836612701416
Validation loss: 2.53026912032917

Epoch: 6| Step: 13
Training loss: 2.3769216537475586
Validation loss: 2.5238555016056186

Epoch: 79| Step: 0
Training loss: 2.6656718254089355
Validation loss: 2.5271779285964144

Epoch: 6| Step: 1
Training loss: 3.90718936920166
Validation loss: 2.5312347053199686

Epoch: 6| Step: 2
Training loss: 2.3753747940063477
Validation loss: 2.531819361512379

Epoch: 6| Step: 3
Training loss: 2.700927257537842
Validation loss: 2.528968208579607

Epoch: 6| Step: 4
Training loss: 3.177776575088501
Validation loss: 2.530674014040219

Epoch: 6| Step: 5
Training loss: 2.017648935317993
Validation loss: 2.5370890132842527

Epoch: 6| Step: 6
Training loss: 2.5723161697387695
Validation loss: 2.5329520804907686

Epoch: 6| Step: 7
Training loss: 2.6881895065307617
Validation loss: 2.530772324531309

Epoch: 6| Step: 8
Training loss: 2.507742166519165
Validation loss: 2.536780785488826

Epoch: 6| Step: 9
Training loss: 3.203256607055664
Validation loss: 2.5474617147958405

Epoch: 6| Step: 10
Training loss: 2.3926267623901367
Validation loss: 2.5562791362885506

Epoch: 6| Step: 11
Training loss: 3.166940689086914
Validation loss: 2.571724889098957

Epoch: 6| Step: 12
Training loss: 2.300236463546753
Validation loss: 2.5821763366781254

Epoch: 6| Step: 13
Training loss: 2.091207265853882
Validation loss: 2.58490280694859

Epoch: 80| Step: 0
Training loss: 2.982923746109009
Validation loss: 2.5733703541499313

Epoch: 6| Step: 1
Training loss: 2.8282251358032227
Validation loss: 2.547458302590155

Epoch: 6| Step: 2
Training loss: 2.43145751953125
Validation loss: 2.5419294962318997

Epoch: 6| Step: 3
Training loss: 2.62324595451355
Validation loss: 2.528898880045901

Epoch: 6| Step: 4
Training loss: 3.281238555908203
Validation loss: 2.53097899242114

Epoch: 6| Step: 5
Training loss: 2.6223251819610596
Validation loss: 2.5271762981209704

Epoch: 6| Step: 6
Training loss: 2.6649036407470703
Validation loss: 2.5233645618602796

Epoch: 6| Step: 7
Training loss: 2.4877848625183105
Validation loss: 2.5221447585731425

Epoch: 6| Step: 8
Training loss: 2.942081928253174
Validation loss: 2.5221115337905062

Epoch: 6| Step: 9
Training loss: 2.1665971279144287
Validation loss: 2.521127659787414

Epoch: 6| Step: 10
Training loss: 2.891432046890259
Validation loss: 2.5205091814840994

Epoch: 6| Step: 11
Training loss: 2.9089417457580566
Validation loss: 2.5239742071397844

Epoch: 6| Step: 12
Training loss: 2.590217113494873
Validation loss: 2.521254406180433

Epoch: 6| Step: 13
Training loss: 2.4152002334594727
Validation loss: 2.523541840173865

Epoch: 81| Step: 0
Training loss: 2.7423994541168213
Validation loss: 2.52884699708672

Epoch: 6| Step: 1
Training loss: 2.505342483520508
Validation loss: 2.5301124844499814

Epoch: 6| Step: 2
Training loss: 2.5292763710021973
Validation loss: 2.528946130506454

Epoch: 6| Step: 3
Training loss: 2.959728717803955
Validation loss: 2.5305085156553533

Epoch: 6| Step: 4
Training loss: 1.8840019702911377
Validation loss: 2.5382396687743483

Epoch: 6| Step: 5
Training loss: 2.084852695465088
Validation loss: 2.544614468851397

Epoch: 6| Step: 6
Training loss: 3.018777847290039
Validation loss: 2.5420162139400357

Epoch: 6| Step: 7
Training loss: 2.323420524597168
Validation loss: 2.5377370747186805

Epoch: 6| Step: 8
Training loss: 3.106921911239624
Validation loss: 2.5350335285227787

Epoch: 6| Step: 9
Training loss: 3.2591450214385986
Validation loss: 2.5224980410709175

Epoch: 6| Step: 10
Training loss: 2.7769343852996826
Validation loss: 2.5205008855430027

Epoch: 6| Step: 11
Training loss: 3.310418128967285
Validation loss: 2.513395295348219

Epoch: 6| Step: 12
Training loss: 3.163473606109619
Validation loss: 2.511822933791786

Epoch: 6| Step: 13
Training loss: 2.026123046875
Validation loss: 2.5107884073770173

Epoch: 82| Step: 0
Training loss: 2.4220192432403564
Validation loss: 2.508679413026379

Epoch: 6| Step: 1
Training loss: 2.6859264373779297
Validation loss: 2.5117935621610252

Epoch: 6| Step: 2
Training loss: 2.36439847946167
Validation loss: 2.5119539973556355

Epoch: 6| Step: 3
Training loss: 3.0136051177978516
Validation loss: 2.5135994495884066

Epoch: 6| Step: 4
Training loss: 2.209200382232666
Validation loss: 2.5125512615326913

Epoch: 6| Step: 5
Training loss: 3.6339688301086426
Validation loss: 2.517297524277882

Epoch: 6| Step: 6
Training loss: 2.238358736038208
Validation loss: 2.5162289347699893

Epoch: 6| Step: 7
Training loss: 2.693521738052368
Validation loss: 2.516857147216797

Epoch: 6| Step: 8
Training loss: 3.3441925048828125
Validation loss: 2.512660011168449

Epoch: 6| Step: 9
Training loss: 2.762953042984009
Validation loss: 2.521559835762106

Epoch: 6| Step: 10
Training loss: 2.4413259029388428
Validation loss: 2.5221848257126345

Epoch: 6| Step: 11
Training loss: 2.9030258655548096
Validation loss: 2.523240312453239

Epoch: 6| Step: 12
Training loss: 2.753843069076538
Validation loss: 2.5160781939824424

Epoch: 6| Step: 13
Training loss: 2.235846757888794
Validation loss: 2.5222953493877123

Epoch: 83| Step: 0
Training loss: 2.5206117630004883
Validation loss: 2.5210179513500584

Epoch: 6| Step: 1
Training loss: 1.9244236946105957
Validation loss: 2.5160747548585296

Epoch: 6| Step: 2
Training loss: 2.172280788421631
Validation loss: 2.5191248334864134

Epoch: 6| Step: 3
Training loss: 2.5398073196411133
Validation loss: 2.5126573578003915

Epoch: 6| Step: 4
Training loss: 2.804107666015625
Validation loss: 2.5105647963862263

Epoch: 6| Step: 5
Training loss: 3.3886327743530273
Validation loss: 2.509502746725595

Epoch: 6| Step: 6
Training loss: 2.4781713485717773
Validation loss: 2.5075898273016817

Epoch: 6| Step: 7
Training loss: 2.811363697052002
Validation loss: 2.510287328432965

Epoch: 6| Step: 8
Training loss: 2.6554317474365234
Validation loss: 2.5097749694701164

Epoch: 6| Step: 9
Training loss: 3.000258445739746
Validation loss: 2.5073793088236163

Epoch: 6| Step: 10
Training loss: 2.7349541187286377
Validation loss: 2.5006043526434127

Epoch: 6| Step: 11
Training loss: 2.9952831268310547
Validation loss: 2.5037009946761595

Epoch: 6| Step: 12
Training loss: 2.5032660961151123
Validation loss: 2.5046419584622948

Epoch: 6| Step: 13
Training loss: 3.741767406463623
Validation loss: 2.4998227191227738

Epoch: 84| Step: 0
Training loss: 2.849616527557373
Validation loss: 2.4994519038866927

Epoch: 6| Step: 1
Training loss: 1.4622557163238525
Validation loss: 2.4999524701026177

Epoch: 6| Step: 2
Training loss: 2.3703548908233643
Validation loss: 2.498821379036032

Epoch: 6| Step: 3
Training loss: 2.6690993309020996
Validation loss: 2.4996420773126746

Epoch: 6| Step: 4
Training loss: 2.9018771648406982
Validation loss: 2.499232187066027

Epoch: 6| Step: 5
Training loss: 2.722261905670166
Validation loss: 2.5077320709023425

Epoch: 6| Step: 6
Training loss: 2.5038225650787354
Validation loss: 2.5174706328299736

Epoch: 6| Step: 7
Training loss: 3.6526906490325928
Validation loss: 2.52384417287765

Epoch: 6| Step: 8
Training loss: 2.7126047611236572
Validation loss: 2.5475905736287436

Epoch: 6| Step: 9
Training loss: 3.118522882461548
Validation loss: 2.547032276789347

Epoch: 6| Step: 10
Training loss: 2.8163347244262695
Validation loss: 2.57275051711708

Epoch: 6| Step: 11
Training loss: 2.3312182426452637
Validation loss: 2.5804579591238372

Epoch: 6| Step: 12
Training loss: 2.9228734970092773
Validation loss: 2.554618407321233

Epoch: 6| Step: 13
Training loss: 3.1628758907318115
Validation loss: 2.53529784499958

Epoch: 85| Step: 0
Training loss: 2.522503137588501
Validation loss: 2.51559777157281

Epoch: 6| Step: 1
Training loss: 2.3415496349334717
Validation loss: 2.504266354345506

Epoch: 6| Step: 2
Training loss: 2.8418502807617188
Validation loss: 2.5003439739186275

Epoch: 6| Step: 3
Training loss: 2.0680274963378906
Validation loss: 2.495891219826155

Epoch: 6| Step: 4
Training loss: 2.416109561920166
Validation loss: 2.4980127452522196

Epoch: 6| Step: 5
Training loss: 3.466036796569824
Validation loss: 2.501283707157258

Epoch: 6| Step: 6
Training loss: 3.6331570148468018
Validation loss: 2.509382972153284

Epoch: 6| Step: 7
Training loss: 2.967806339263916
Validation loss: 2.506674628103933

Epoch: 6| Step: 8
Training loss: 2.3387532234191895
Validation loss: 2.501952355907809

Epoch: 6| Step: 9
Training loss: 2.2298176288604736
Validation loss: 2.503307101547077

Epoch: 6| Step: 10
Training loss: 3.175232410430908
Validation loss: 2.4994594999538955

Epoch: 6| Step: 11
Training loss: 2.641695022583008
Validation loss: 2.5056105249671528

Epoch: 6| Step: 12
Training loss: 2.186272621154785
Validation loss: 2.5097101170529603

Epoch: 6| Step: 13
Training loss: 3.0522565841674805
Validation loss: 2.518776926943051

Epoch: 86| Step: 0
Training loss: 2.9228620529174805
Validation loss: 2.5313968658447266

Epoch: 6| Step: 1
Training loss: 3.202515125274658
Validation loss: 2.5276506741841636

Epoch: 6| Step: 2
Training loss: 2.748079538345337
Validation loss: 2.528316422175336

Epoch: 6| Step: 3
Training loss: 2.7196125984191895
Validation loss: 2.527849776770479

Epoch: 6| Step: 4
Training loss: 2.617034912109375
Validation loss: 2.520979583904307

Epoch: 6| Step: 5
Training loss: 2.3175759315490723
Validation loss: 2.514671197501562

Epoch: 6| Step: 6
Training loss: 2.4609599113464355
Validation loss: 2.5149727918768443

Epoch: 6| Step: 7
Training loss: 2.91892147064209
Validation loss: 2.5111575921376548

Epoch: 6| Step: 8
Training loss: 2.4513936042785645
Validation loss: 2.5170474744612172

Epoch: 6| Step: 9
Training loss: 2.8287909030914307
Validation loss: 2.5141575669729583

Epoch: 6| Step: 10
Training loss: 2.1897225379943848
Validation loss: 2.5107019460329445

Epoch: 6| Step: 11
Training loss: 3.2066588401794434
Validation loss: 2.508979399998983

Epoch: 6| Step: 12
Training loss: 2.286761999130249
Validation loss: 2.5068011091601465

Epoch: 6| Step: 13
Training loss: 3.120058059692383
Validation loss: 2.5100868696807535

Epoch: 87| Step: 0
Training loss: 2.643587589263916
Validation loss: 2.5084864965049167

Epoch: 6| Step: 1
Training loss: 2.0544562339782715
Validation loss: 2.5053565373984714

Epoch: 6| Step: 2
Training loss: 2.420670986175537
Validation loss: 2.509985626384776

Epoch: 6| Step: 3
Training loss: 2.6272897720336914
Validation loss: 2.5135926046679096

Epoch: 6| Step: 4
Training loss: 2.5203616619110107
Validation loss: 2.5146258697714856

Epoch: 6| Step: 5
Training loss: 2.9053850173950195
Validation loss: 2.5063994110271497

Epoch: 6| Step: 6
Training loss: 2.896888256072998
Validation loss: 2.5069871717883694

Epoch: 6| Step: 7
Training loss: 2.8964507579803467
Validation loss: 2.5046001685562955

Epoch: 6| Step: 8
Training loss: 3.356536388397217
Validation loss: 2.5008199984027493

Epoch: 6| Step: 9
Training loss: 2.2193665504455566
Validation loss: 2.500616988828105

Epoch: 6| Step: 10
Training loss: 2.916991710662842
Validation loss: 2.4987528965037358

Epoch: 6| Step: 11
Training loss: 2.9984374046325684
Validation loss: 2.497392169890865

Epoch: 6| Step: 12
Training loss: 2.869518518447876
Validation loss: 2.496626120741649

Epoch: 6| Step: 13
Training loss: 1.9822605848312378
Validation loss: 2.4926586458759923

Epoch: 88| Step: 0
Training loss: 2.288935661315918
Validation loss: 2.4921762174175632

Epoch: 6| Step: 1
Training loss: 2.85714054107666
Validation loss: 2.489866356695852

Epoch: 6| Step: 2
Training loss: 3.2786707878112793
Validation loss: 2.494759172521612

Epoch: 6| Step: 3
Training loss: 2.8035531044006348
Validation loss: 2.4960144668497066

Epoch: 6| Step: 4
Training loss: 2.4014363288879395
Validation loss: 2.5025724749411307

Epoch: 6| Step: 5
Training loss: 2.8958888053894043
Validation loss: 2.4990828883263374

Epoch: 6| Step: 6
Training loss: 3.0009169578552246
Validation loss: 2.502231346663608

Epoch: 6| Step: 7
Training loss: 2.20745849609375
Validation loss: 2.4977101433661675

Epoch: 6| Step: 8
Training loss: 2.4216413497924805
Validation loss: 2.4999826954257105

Epoch: 6| Step: 9
Training loss: 3.0430283546447754
Validation loss: 2.496155908030848

Epoch: 6| Step: 10
Training loss: 1.9603677988052368
Validation loss: 2.494798952533353

Epoch: 6| Step: 11
Training loss: 2.868147373199463
Validation loss: 2.4954948579111407

Epoch: 6| Step: 12
Training loss: 2.8498308658599854
Validation loss: 2.4978362309035433

Epoch: 6| Step: 13
Training loss: 2.850813627243042
Validation loss: 2.4965774551514657

Epoch: 89| Step: 0
Training loss: 2.202993869781494
Validation loss: 2.4962186633899646

Epoch: 6| Step: 1
Training loss: 2.9499917030334473
Validation loss: 2.4945456699658464

Epoch: 6| Step: 2
Training loss: 2.5410757064819336
Validation loss: 2.5033965238960842

Epoch: 6| Step: 3
Training loss: 2.5612053871154785
Validation loss: 2.516605143905968

Epoch: 6| Step: 4
Training loss: 2.4523911476135254
Validation loss: 2.5194755369617092

Epoch: 6| Step: 5
Training loss: 2.2525949478149414
Validation loss: 2.518512233611076

Epoch: 6| Step: 6
Training loss: 2.750938653945923
Validation loss: 2.5186951083521687

Epoch: 6| Step: 7
Training loss: 2.4010043144226074
Validation loss: 2.521435122336111

Epoch: 6| Step: 8
Training loss: 2.81402587890625
Validation loss: 2.5298887196407525

Epoch: 6| Step: 9
Training loss: 3.163198947906494
Validation loss: 2.5226920676487747

Epoch: 6| Step: 10
Training loss: 2.4375205039978027
Validation loss: 2.523119241960587

Epoch: 6| Step: 11
Training loss: 2.6500015258789062
Validation loss: 2.528942451682142

Epoch: 6| Step: 12
Training loss: 3.5101308822631836
Validation loss: 2.5232908700102117

Epoch: 6| Step: 13
Training loss: 3.4977025985717773
Validation loss: 2.5218641552873837

Epoch: 90| Step: 0
Training loss: 2.9179909229278564
Validation loss: 2.515297015508016

Epoch: 6| Step: 1
Training loss: 2.4456872940063477
Validation loss: 2.5059230378879014

Epoch: 6| Step: 2
Training loss: 1.7113666534423828
Validation loss: 2.4991644326076714

Epoch: 6| Step: 3
Training loss: 3.2540600299835205
Validation loss: 2.502364509849138

Epoch: 6| Step: 4
Training loss: 3.132826805114746
Validation loss: 2.499361684245448

Epoch: 6| Step: 5
Training loss: 2.8070294857025146
Validation loss: 2.494339653240737

Epoch: 6| Step: 6
Training loss: 2.854617118835449
Validation loss: 2.4909490616090837

Epoch: 6| Step: 7
Training loss: 2.174943447113037
Validation loss: 2.493732254992249

Epoch: 6| Step: 8
Training loss: 3.345134973526001
Validation loss: 2.487077279757428

Epoch: 6| Step: 9
Training loss: 2.4993808269500732
Validation loss: 2.4931207344096196

Epoch: 6| Step: 10
Training loss: 2.3506689071655273
Validation loss: 2.487608309715025

Epoch: 6| Step: 11
Training loss: 2.5870511531829834
Validation loss: 2.490271258097823

Epoch: 6| Step: 12
Training loss: 2.714865207672119
Validation loss: 2.485199564246721

Epoch: 6| Step: 13
Training loss: 2.8915462493896484
Validation loss: 2.496523282861197

Epoch: 91| Step: 0
Training loss: 2.5817506313323975
Validation loss: 2.5081319450050272

Epoch: 6| Step: 1
Training loss: 2.0508804321289062
Validation loss: 2.513255544888076

Epoch: 6| Step: 2
Training loss: 2.630826234817505
Validation loss: 2.530511051095942

Epoch: 6| Step: 3
Training loss: 2.92673921585083
Validation loss: 2.546609873412758

Epoch: 6| Step: 4
Training loss: 2.6702983379364014
Validation loss: 2.5460395454078593

Epoch: 6| Step: 5
Training loss: 2.1999523639678955
Validation loss: 2.535713429092079

Epoch: 6| Step: 6
Training loss: 3.496335983276367
Validation loss: 2.5301999840685117

Epoch: 6| Step: 7
Training loss: 2.612159252166748
Validation loss: 2.527816682733515

Epoch: 6| Step: 8
Training loss: 2.671553373336792
Validation loss: 2.5123945282351587

Epoch: 6| Step: 9
Training loss: 2.8771212100982666
Validation loss: 2.504637254181729

Epoch: 6| Step: 10
Training loss: 3.063678741455078
Validation loss: 2.485078106644333

Epoch: 6| Step: 11
Training loss: 3.0274927616119385
Validation loss: 2.478292126809397

Epoch: 6| Step: 12
Training loss: 2.870377779006958
Validation loss: 2.4791269712550665

Epoch: 6| Step: 13
Training loss: 1.607482671737671
Validation loss: 2.4826248666291595

Epoch: 92| Step: 0
Training loss: 3.401974678039551
Validation loss: 2.4879334075476534

Epoch: 6| Step: 1
Training loss: 3.136610984802246
Validation loss: 2.4928096776367514

Epoch: 6| Step: 2
Training loss: 2.388658046722412
Validation loss: 2.4952578288252636

Epoch: 6| Step: 3
Training loss: 3.112241744995117
Validation loss: 2.4981891339825046

Epoch: 6| Step: 4
Training loss: 2.4183099269866943
Validation loss: 2.4999334991619153

Epoch: 6| Step: 5
Training loss: 2.968667507171631
Validation loss: 2.501386527092226

Epoch: 6| Step: 6
Training loss: 3.07902193069458
Validation loss: 2.4949304467888287

Epoch: 6| Step: 7
Training loss: 2.73980712890625
Validation loss: 2.4949409807882

Epoch: 6| Step: 8
Training loss: 2.060561180114746
Validation loss: 2.487929983805585

Epoch: 6| Step: 9
Training loss: 2.71242356300354
Validation loss: 2.491547776806739

Epoch: 6| Step: 10
Training loss: 2.988649368286133
Validation loss: 2.4910750517281155

Epoch: 6| Step: 11
Training loss: 2.1339797973632812
Validation loss: 2.4895297199167232

Epoch: 6| Step: 12
Training loss: 2.376976251602173
Validation loss: 2.4962175533335698

Epoch: 6| Step: 13
Training loss: 1.9183472394943237
Validation loss: 2.50266356109291

Epoch: 93| Step: 0
Training loss: 2.9207725524902344
Validation loss: 2.4995326239575624

Epoch: 6| Step: 1
Training loss: 1.838108777999878
Validation loss: 2.5082671180848153

Epoch: 6| Step: 2
Training loss: 3.392703056335449
Validation loss: 2.5124429118248726

Epoch: 6| Step: 3
Training loss: 3.243259906768799
Validation loss: 2.513105002782678

Epoch: 6| Step: 4
Training loss: 3.1015872955322266
Validation loss: 2.506997887806226

Epoch: 6| Step: 5
Training loss: 3.462418556213379
Validation loss: 2.5011051572779173

Epoch: 6| Step: 6
Training loss: 3.123197317123413
Validation loss: 2.493070166598084

Epoch: 6| Step: 7
Training loss: 2.4768974781036377
Validation loss: 2.489111203019337

Epoch: 6| Step: 8
Training loss: 2.233304500579834
Validation loss: 2.4865478084933375

Epoch: 6| Step: 9
Training loss: 3.093906879425049
Validation loss: 2.4825980842754407

Epoch: 6| Step: 10
Training loss: 2.238137722015381
Validation loss: 2.4814840773100495

Epoch: 6| Step: 11
Training loss: 2.0329151153564453
Validation loss: 2.483846369610038

Epoch: 6| Step: 12
Training loss: 1.9116153717041016
Validation loss: 2.488313933854462

Epoch: 6| Step: 13
Training loss: 2.5518991947174072
Validation loss: 2.488250829840219

Epoch: 94| Step: 0
Training loss: 3.4975087642669678
Validation loss: 2.4915408165224138

Epoch: 6| Step: 1
Training loss: 2.9136815071105957
Validation loss: 2.4906618646396104

Epoch: 6| Step: 2
Training loss: 2.685014247894287
Validation loss: 2.490592837333679

Epoch: 6| Step: 3
Training loss: 2.650111675262451
Validation loss: 2.4849397777229227

Epoch: 6| Step: 4
Training loss: 2.680952548980713
Validation loss: 2.486514852892968

Epoch: 6| Step: 5
Training loss: 2.9499971866607666
Validation loss: 2.4822591504743023

Epoch: 6| Step: 6
Training loss: 2.216966152191162
Validation loss: 2.479374498449346

Epoch: 6| Step: 7
Training loss: 2.4358811378479004
Validation loss: 2.483696920897371

Epoch: 6| Step: 8
Training loss: 3.2271993160247803
Validation loss: 2.487559610797513

Epoch: 6| Step: 9
Training loss: 2.3102993965148926
Validation loss: 2.494016998557634

Epoch: 6| Step: 10
Training loss: 2.3930253982543945
Validation loss: 2.494696086452853

Epoch: 6| Step: 11
Training loss: 2.8850035667419434
Validation loss: 2.495399869898314

Epoch: 6| Step: 12
Training loss: 2.2593493461608887
Validation loss: 2.508727668434061

Epoch: 6| Step: 13
Training loss: 2.460524320602417
Validation loss: 2.4956219529592865

Epoch: 95| Step: 0
Training loss: 2.330284833908081
Validation loss: 2.49193670416391

Epoch: 6| Step: 1
Training loss: 3.0930380821228027
Validation loss: 2.4937778570318736

Epoch: 6| Step: 2
Training loss: 2.4204015731811523
Validation loss: 2.4831750495459444

Epoch: 6| Step: 3
Training loss: 2.2595279216766357
Validation loss: 2.484353265454692

Epoch: 6| Step: 4
Training loss: 2.425384759902954
Validation loss: 2.47777864497195

Epoch: 6| Step: 5
Training loss: 2.911200761795044
Validation loss: 2.481014044054093

Epoch: 6| Step: 6
Training loss: 2.7351815700531006
Validation loss: 2.4749801107632217

Epoch: 6| Step: 7
Training loss: 2.2509117126464844
Validation loss: 2.4800623950137886

Epoch: 6| Step: 8
Training loss: 2.066934108734131
Validation loss: 2.480056278167232

Epoch: 6| Step: 9
Training loss: 2.9042515754699707
Validation loss: 2.48395961330783

Epoch: 6| Step: 10
Training loss: 2.5219480991363525
Validation loss: 2.488357792618454

Epoch: 6| Step: 11
Training loss: 3.2371294498443604
Validation loss: 2.4890394877361994

Epoch: 6| Step: 12
Training loss: 3.1270768642425537
Validation loss: 2.4860621780477543

Epoch: 6| Step: 13
Training loss: 3.6299357414245605
Validation loss: 2.4959439128957768

Epoch: 96| Step: 0
Training loss: 2.1922130584716797
Validation loss: 2.4953037128653577

Epoch: 6| Step: 1
Training loss: 2.741508960723877
Validation loss: 2.5003325734087216

Epoch: 6| Step: 2
Training loss: 2.7081518173217773
Validation loss: 2.499807983316401

Epoch: 6| Step: 3
Training loss: 2.4688873291015625
Validation loss: 2.5044248578368977

Epoch: 6| Step: 4
Training loss: 3.5870909690856934
Validation loss: 2.4986388785864717

Epoch: 6| Step: 5
Training loss: 2.617733955383301
Validation loss: 2.497275234550558

Epoch: 6| Step: 6
Training loss: 1.9683606624603271
Validation loss: 2.492720465506277

Epoch: 6| Step: 7
Training loss: 2.928802013397217
Validation loss: 2.4893235775732223

Epoch: 6| Step: 8
Training loss: 2.990746021270752
Validation loss: 2.4994155527443014

Epoch: 6| Step: 9
Training loss: 2.457212448120117
Validation loss: 2.4966028723665463

Epoch: 6| Step: 10
Training loss: 3.6043906211853027
Validation loss: 2.494239863529

Epoch: 6| Step: 11
Training loss: 2.291017532348633
Validation loss: 2.4924264953982447

Epoch: 6| Step: 12
Training loss: 2.1218032836914062
Validation loss: 2.4935606679608746

Epoch: 6| Step: 13
Training loss: 2.895630359649658
Validation loss: 2.482686411949896

Epoch: 97| Step: 0
Training loss: 2.8135721683502197
Validation loss: 2.4805244425291657

Epoch: 6| Step: 1
Training loss: 2.341362953186035
Validation loss: 2.4795990195325626

Epoch: 6| Step: 2
Training loss: 2.6745712757110596
Validation loss: 2.478763311139999

Epoch: 6| Step: 3
Training loss: 3.0876035690307617
Validation loss: 2.4780424641024683

Epoch: 6| Step: 4
Training loss: 2.101468086242676
Validation loss: 2.4798090073370163

Epoch: 6| Step: 5
Training loss: 2.782200813293457
Validation loss: 2.4719983993038053

Epoch: 6| Step: 6
Training loss: 2.944553852081299
Validation loss: 2.4705295614016953

Epoch: 6| Step: 7
Training loss: 2.731192111968994
Validation loss: 2.4743135667616323

Epoch: 6| Step: 8
Training loss: 2.6341605186462402
Validation loss: 2.4717118329899286

Epoch: 6| Step: 9
Training loss: 2.473191499710083
Validation loss: 2.4744571844736734

Epoch: 6| Step: 10
Training loss: 2.29196834564209
Validation loss: 2.4652538658470236

Epoch: 6| Step: 11
Training loss: 3.082815647125244
Validation loss: 2.4776943473405737

Epoch: 6| Step: 12
Training loss: 3.1156539916992188
Validation loss: 2.479205416094872

Epoch: 6| Step: 13
Training loss: 2.1499624252319336
Validation loss: 2.480790279244864

Epoch: 98| Step: 0
Training loss: 2.3614535331726074
Validation loss: 2.4743786870792346

Epoch: 6| Step: 1
Training loss: 3.4289422035217285
Validation loss: 2.4689544631588842

Epoch: 6| Step: 2
Training loss: 3.097673177719116
Validation loss: 2.4710126461521273

Epoch: 6| Step: 3
Training loss: 3.275907039642334
Validation loss: 2.473284770083684

Epoch: 6| Step: 4
Training loss: 2.1083807945251465
Validation loss: 2.482432455144903

Epoch: 6| Step: 5
Training loss: 2.3272523880004883
Validation loss: 2.4936512157481205

Epoch: 6| Step: 6
Training loss: 2.448744773864746
Validation loss: 2.491817033419045

Epoch: 6| Step: 7
Training loss: 3.061138153076172
Validation loss: 2.4943853091168147

Epoch: 6| Step: 8
Training loss: 2.1272926330566406
Validation loss: 2.495015016166113

Epoch: 6| Step: 9
Training loss: 2.9236230850219727
Validation loss: 2.5072903351117204

Epoch: 6| Step: 10
Training loss: 3.1348166465759277
Validation loss: 2.507058843489616

Epoch: 6| Step: 11
Training loss: 2.7318882942199707
Validation loss: 2.5140507862132084

Epoch: 6| Step: 12
Training loss: 1.9873363971710205
Validation loss: 2.50595280431932

Epoch: 6| Step: 13
Training loss: 2.3096017837524414
Validation loss: 2.4904040726282264

Epoch: 99| Step: 0
Training loss: 2.4040260314941406
Validation loss: 2.4867080616694626

Epoch: 6| Step: 1
Training loss: 2.992384910583496
Validation loss: 2.489258994338333

Epoch: 6| Step: 2
Training loss: 1.8821816444396973
Validation loss: 2.485945624689902

Epoch: 6| Step: 3
Training loss: 2.2699270248413086
Validation loss: 2.4830808742071993

Epoch: 6| Step: 4
Training loss: 1.634150743484497
Validation loss: 2.4854796727498374

Epoch: 6| Step: 5
Training loss: 2.607621669769287
Validation loss: 2.4883903867454937

Epoch: 6| Step: 6
Training loss: 3.0136256217956543
Validation loss: 2.496453054489628

Epoch: 6| Step: 7
Training loss: 3.1539437770843506
Validation loss: 2.4969813157153387

Epoch: 6| Step: 8
Training loss: 2.5022640228271484
Validation loss: 2.494484680955128

Epoch: 6| Step: 9
Training loss: 2.8839807510375977
Validation loss: 2.489125162042597

Epoch: 6| Step: 10
Training loss: 3.852519989013672
Validation loss: 2.499525503445697

Epoch: 6| Step: 11
Training loss: 3.171795129776001
Validation loss: 2.49141421369327

Epoch: 6| Step: 12
Training loss: 2.2851057052612305
Validation loss: 2.487962217741115

Epoch: 6| Step: 13
Training loss: 2.7987897396087646
Validation loss: 2.475544439849033

Epoch: 100| Step: 0
Training loss: 2.7445359230041504
Validation loss: 2.4765233044983237

Epoch: 6| Step: 1
Training loss: 2.7774081230163574
Validation loss: 2.4749487933292182

Epoch: 6| Step: 2
Training loss: 2.679487705230713
Validation loss: 2.468577851531326

Epoch: 6| Step: 3
Training loss: 2.505843162536621
Validation loss: 2.4720541072148148

Epoch: 6| Step: 4
Training loss: 2.5517678260803223
Validation loss: 2.4676822616207983

Epoch: 6| Step: 5
Training loss: 3.0997209548950195
Validation loss: 2.4683980762317614

Epoch: 6| Step: 6
Training loss: 1.8843908309936523
Validation loss: 2.4662813166136384

Epoch: 6| Step: 7
Training loss: 2.08307147026062
Validation loss: 2.4749806773278022

Epoch: 6| Step: 8
Training loss: 2.94671630859375
Validation loss: 2.4740166612850722

Epoch: 6| Step: 9
Training loss: 3.648963212966919
Validation loss: 2.4830649052896807

Epoch: 6| Step: 10
Training loss: 2.611288547515869
Validation loss: 2.4657049973805747

Epoch: 6| Step: 11
Training loss: 2.8371219635009766
Validation loss: 2.4667071757778043

Epoch: 6| Step: 12
Training loss: 2.684610366821289
Validation loss: 2.4591704876192155

Epoch: 6| Step: 13
Training loss: 2.2641706466674805
Validation loss: 2.4620393053177865

Epoch: 101| Step: 0
Training loss: 3.212067127227783
Validation loss: 2.4593338351095877

Epoch: 6| Step: 1
Training loss: 2.726811408996582
Validation loss: 2.466560982888745

Epoch: 6| Step: 2
Training loss: 1.9512333869934082
Validation loss: 2.4671858100480932

Epoch: 6| Step: 3
Training loss: 2.631540298461914
Validation loss: 2.472593007549163

Epoch: 6| Step: 4
Training loss: 3.393054485321045
Validation loss: 2.47762438302399

Epoch: 6| Step: 5
Training loss: 2.431898355484009
Validation loss: 2.4825418610726633

Epoch: 6| Step: 6
Training loss: 2.833909511566162
Validation loss: 2.4952007314210296

Epoch: 6| Step: 7
Training loss: 2.2640414237976074
Validation loss: 2.490834113090269

Epoch: 6| Step: 8
Training loss: 2.946312427520752
Validation loss: 2.491734040680752

Epoch: 6| Step: 9
Training loss: 2.4759202003479004
Validation loss: 2.4882819883285032

Epoch: 6| Step: 10
Training loss: 2.703230857849121
Validation loss: 2.473795513952932

Epoch: 6| Step: 11
Training loss: 2.2512125968933105
Validation loss: 2.469121748401273

Epoch: 6| Step: 12
Training loss: 2.600677967071533
Validation loss: 2.471758727104433

Epoch: 6| Step: 13
Training loss: 3.2197721004486084
Validation loss: 2.466749160520492

Epoch: 102| Step: 0
Training loss: 2.880500316619873
Validation loss: 2.4691359714795182

Epoch: 6| Step: 1
Training loss: 2.954564094543457
Validation loss: 2.4722620902522916

Epoch: 6| Step: 2
Training loss: 2.2503976821899414
Validation loss: 2.468547405735139

Epoch: 6| Step: 3
Training loss: 1.8975099325180054
Validation loss: 2.4743719562407462

Epoch: 6| Step: 4
Training loss: 3.1722614765167236
Validation loss: 2.4728172543228313

Epoch: 6| Step: 5
Training loss: 2.261979103088379
Validation loss: 2.472830703181605

Epoch: 6| Step: 6
Training loss: 1.9391613006591797
Validation loss: 2.4880147031558457

Epoch: 6| Step: 7
Training loss: 3.3885412216186523
Validation loss: 2.493328022700484

Epoch: 6| Step: 8
Training loss: 2.50357985496521
Validation loss: 2.496473858433385

Epoch: 6| Step: 9
Training loss: 3.249314546585083
Validation loss: 2.497401560506513

Epoch: 6| Step: 10
Training loss: 3.511728525161743
Validation loss: 2.4938737141188754

Epoch: 6| Step: 11
Training loss: 2.037313938140869
Validation loss: 2.488943233284899

Epoch: 6| Step: 12
Training loss: 3.1116485595703125
Validation loss: 2.482948459604735

Epoch: 6| Step: 13
Training loss: 1.9617396593093872
Validation loss: 2.479686793460641

Epoch: 103| Step: 0
Training loss: 2.7180538177490234
Validation loss: 2.4788942772855043

Epoch: 6| Step: 1
Training loss: 2.725471019744873
Validation loss: 2.4797842348775556

Epoch: 6| Step: 2
Training loss: 3.457705020904541
Validation loss: 2.4838041643942557

Epoch: 6| Step: 3
Training loss: 2.3644635677337646
Validation loss: 2.477005225355907

Epoch: 6| Step: 4
Training loss: 2.415668249130249
Validation loss: 2.4735679318827968

Epoch: 6| Step: 5
Training loss: 2.846705198287964
Validation loss: 2.4722694812282437

Epoch: 6| Step: 6
Training loss: 2.167222738265991
Validation loss: 2.4605582555135093

Epoch: 6| Step: 7
Training loss: 2.1712677478790283
Validation loss: 2.464933249258226

Epoch: 6| Step: 8
Training loss: 2.9748380184173584
Validation loss: 2.465705333217498

Epoch: 6| Step: 9
Training loss: 2.658160924911499
Validation loss: 2.470966454475157

Epoch: 6| Step: 10
Training loss: 2.9913196563720703
Validation loss: 2.4740570181159565

Epoch: 6| Step: 11
Training loss: 3.0268595218658447
Validation loss: 2.4763809993702877

Epoch: 6| Step: 12
Training loss: 2.4496302604675293
Validation loss: 2.4814256980854976

Epoch: 6| Step: 13
Training loss: 2.090841293334961
Validation loss: 2.4895509622430287

Epoch: 104| Step: 0
Training loss: 3.2104077339172363
Validation loss: 2.4851559157012613

Epoch: 6| Step: 1
Training loss: 2.367281436920166
Validation loss: 2.487986550536207

Epoch: 6| Step: 2
Training loss: 2.645864486694336
Validation loss: 2.4841179873353694

Epoch: 6| Step: 3
Training loss: 3.083796977996826
Validation loss: 2.485321360249673

Epoch: 6| Step: 4
Training loss: 2.017179250717163
Validation loss: 2.487493484250961

Epoch: 6| Step: 5
Training loss: 2.4074273109436035
Validation loss: 2.4852331120480775

Epoch: 6| Step: 6
Training loss: 2.058988094329834
Validation loss: 2.490433354531565

Epoch: 6| Step: 7
Training loss: 3.757136106491089
Validation loss: 2.496007378383349

Epoch: 6| Step: 8
Training loss: 2.856865406036377
Validation loss: 2.4870310675713325

Epoch: 6| Step: 9
Training loss: 2.2989683151245117
Validation loss: 2.4874433573856147

Epoch: 6| Step: 10
Training loss: 2.7974069118499756
Validation loss: 2.4834029392529557

Epoch: 6| Step: 11
Training loss: 2.139333963394165
Validation loss: 2.474901658232494

Epoch: 6| Step: 12
Training loss: 3.515354871749878
Validation loss: 2.4696493687168246

Epoch: 6| Step: 13
Training loss: 1.7120870351791382
Validation loss: 2.4676810259460122

Epoch: 105| Step: 0
Training loss: 3.158684253692627
Validation loss: 2.4597596583827848

Epoch: 6| Step: 1
Training loss: 2.6806845664978027
Validation loss: 2.454530692869617

Epoch: 6| Step: 2
Training loss: 2.14158034324646
Validation loss: 2.459942312650783

Epoch: 6| Step: 3
Training loss: 2.7378652095794678
Validation loss: 2.47174378877045

Epoch: 6| Step: 4
Training loss: 2.518887758255005
Validation loss: 2.4757953741217174

Epoch: 6| Step: 5
Training loss: 2.9615261554718018
Validation loss: 2.4884130031831804

Epoch: 6| Step: 6
Training loss: 2.2157604694366455
Validation loss: 2.4885324829368183

Epoch: 6| Step: 7
Training loss: 1.8334567546844482
Validation loss: 2.4946429396188385

Epoch: 6| Step: 8
Training loss: 2.287848949432373
Validation loss: 2.4917565802092194

Epoch: 6| Step: 9
Training loss: 3.7164382934570312
Validation loss: 2.4944526867199968

Epoch: 6| Step: 10
Training loss: 3.024031162261963
Validation loss: 2.49593081525577

Epoch: 6| Step: 11
Training loss: 2.4939441680908203
Validation loss: 2.4881418674222884

Epoch: 6| Step: 12
Training loss: 2.9484097957611084
Validation loss: 2.47767355749684

Epoch: 6| Step: 13
Training loss: 2.5658531188964844
Validation loss: 2.4665123724168345

Epoch: 106| Step: 0
Training loss: 1.9076287746429443
Validation loss: 2.4643550252401702

Epoch: 6| Step: 1
Training loss: 3.3463711738586426
Validation loss: 2.458187880054597

Epoch: 6| Step: 2
Training loss: 2.4832422733306885
Validation loss: 2.457353038172568

Epoch: 6| Step: 3
Training loss: 2.6423869132995605
Validation loss: 2.456042489697856

Epoch: 6| Step: 4
Training loss: 2.54172420501709
Validation loss: 2.4480224860611783

Epoch: 6| Step: 5
Training loss: 2.5079081058502197
Validation loss: 2.450898460162583

Epoch: 6| Step: 6
Training loss: 2.7869338989257812
Validation loss: 2.449945129374022

Epoch: 6| Step: 7
Training loss: 2.5215420722961426
Validation loss: 2.448985189519903

Epoch: 6| Step: 8
Training loss: 2.5531983375549316
Validation loss: 2.45197957305498

Epoch: 6| Step: 9
Training loss: 3.1434669494628906
Validation loss: 2.4557583511516614

Epoch: 6| Step: 10
Training loss: 2.60599684715271
Validation loss: 2.458935535082253

Epoch: 6| Step: 11
Training loss: 2.19987416267395
Validation loss: 2.4583532348755868

Epoch: 6| Step: 12
Training loss: 2.8842825889587402
Validation loss: 2.4633098699713267

Epoch: 6| Step: 13
Training loss: 3.5451407432556152
Validation loss: 2.4640873273213706

Epoch: 107| Step: 0
Training loss: 2.8313424587249756
Validation loss: 2.4750525695021435

Epoch: 6| Step: 1
Training loss: 2.986142635345459
Validation loss: 2.4776881356393137

Epoch: 6| Step: 2
Training loss: 3.418055534362793
Validation loss: 2.480014911261938

Epoch: 6| Step: 3
Training loss: 3.019730567932129
Validation loss: 2.4782412026518132

Epoch: 6| Step: 4
Training loss: 3.0030531883239746
Validation loss: 2.4756659717969995

Epoch: 6| Step: 5
Training loss: 2.285945415496826
Validation loss: 2.4725436702851327

Epoch: 6| Step: 6
Training loss: 2.8670384883880615
Validation loss: 2.4720194903753137

Epoch: 6| Step: 7
Training loss: 1.880519986152649
Validation loss: 2.4732362711301414

Epoch: 6| Step: 8
Training loss: 2.5833616256713867
Validation loss: 2.47010132574266

Epoch: 6| Step: 9
Training loss: 2.686251640319824
Validation loss: 2.4707762682309715

Epoch: 6| Step: 10
Training loss: 2.8369698524475098
Validation loss: 2.4633756324809086

Epoch: 6| Step: 11
Training loss: 1.561366081237793
Validation loss: 2.4687098380058043

Epoch: 6| Step: 12
Training loss: 2.4899158477783203
Validation loss: 2.4642753190891717

Epoch: 6| Step: 13
Training loss: 2.8592002391815186
Validation loss: 2.4594723281039985

Epoch: 108| Step: 0
Training loss: 2.6186723709106445
Validation loss: 2.4594757313369424

Epoch: 6| Step: 1
Training loss: 2.0543158054351807
Validation loss: 2.455989988901282

Epoch: 6| Step: 2
Training loss: 2.305082321166992
Validation loss: 2.4544765846703642

Epoch: 6| Step: 3
Training loss: 3.039555072784424
Validation loss: 2.461599506357665

Epoch: 6| Step: 4
Training loss: 3.534715175628662
Validation loss: 2.463653620853219

Epoch: 6| Step: 5
Training loss: 2.91137433052063
Validation loss: 2.4665814317682737

Epoch: 6| Step: 6
Training loss: 1.775597333908081
Validation loss: 2.4649825506312872

Epoch: 6| Step: 7
Training loss: 2.4636590480804443
Validation loss: 2.470166165341613

Epoch: 6| Step: 8
Training loss: 2.5216424465179443
Validation loss: 2.476568482255423

Epoch: 6| Step: 9
Training loss: 3.0840539932250977
Validation loss: 2.4759696145211496

Epoch: 6| Step: 10
Training loss: 2.8645191192626953
Validation loss: 2.4753680434278262

Epoch: 6| Step: 11
Training loss: 3.047307014465332
Validation loss: 2.4732212738324235

Epoch: 6| Step: 12
Training loss: 2.32741117477417
Validation loss: 2.4798481848932084

Epoch: 6| Step: 13
Training loss: 2.525667667388916
Validation loss: 2.4711926803793958

Epoch: 109| Step: 0
Training loss: 2.5243539810180664
Validation loss: 2.4600595838280133

Epoch: 6| Step: 1
Training loss: 2.366837978363037
Validation loss: 2.4621092965525966

Epoch: 6| Step: 2
Training loss: 2.3445825576782227
Validation loss: 2.459024724139962

Epoch: 6| Step: 3
Training loss: 2.416433572769165
Validation loss: 2.455957302483179

Epoch: 6| Step: 4
Training loss: 2.6256327629089355
Validation loss: 2.4537733472803587

Epoch: 6| Step: 5
Training loss: 3.3424880504608154
Validation loss: 2.4501365692384782

Epoch: 6| Step: 6
Training loss: 3.176055908203125
Validation loss: 2.4538129452736146

Epoch: 6| Step: 7
Training loss: 3.0788955688476562
Validation loss: 2.4538875625979517

Epoch: 6| Step: 8
Training loss: 2.5830459594726562
Validation loss: 2.454436634176521

Epoch: 6| Step: 9
Training loss: 2.248502731323242
Validation loss: 2.456952884633054

Epoch: 6| Step: 10
Training loss: 2.4007773399353027
Validation loss: 2.4570877423850437

Epoch: 6| Step: 11
Training loss: 2.4191904067993164
Validation loss: 2.457454809578516

Epoch: 6| Step: 12
Training loss: 2.651501178741455
Validation loss: 2.462549214722008

Epoch: 6| Step: 13
Training loss: 3.1752941608428955
Validation loss: 2.4738571605374737

Epoch: 110| Step: 0
Training loss: 2.2220001220703125
Validation loss: 2.477296240868107

Epoch: 6| Step: 1
Training loss: 2.209581136703491
Validation loss: 2.4827830740200576

Epoch: 6| Step: 2
Training loss: 2.140000820159912
Validation loss: 2.4996885484264744

Epoch: 6| Step: 3
Training loss: 3.286895275115967
Validation loss: 2.5068298975626626

Epoch: 6| Step: 4
Training loss: 3.680716037750244
Validation loss: 2.5010690509632068

Epoch: 6| Step: 5
Training loss: 2.393671989440918
Validation loss: 2.489023503436837

Epoch: 6| Step: 6
Training loss: 2.819976568222046
Validation loss: 2.474278055211549

Epoch: 6| Step: 7
Training loss: 2.6951446533203125
Validation loss: 2.4706435383007093

Epoch: 6| Step: 8
Training loss: 2.6038551330566406
Validation loss: 2.4610846760452434

Epoch: 6| Step: 9
Training loss: 2.551262378692627
Validation loss: 2.460322582593528

Epoch: 6| Step: 10
Training loss: 2.7248101234436035
Validation loss: 2.452187301010214

Epoch: 6| Step: 11
Training loss: 2.7078685760498047
Validation loss: 2.451998079976728

Epoch: 6| Step: 12
Training loss: 2.644412040710449
Validation loss: 2.4516096192021526

Epoch: 6| Step: 13
Training loss: 2.342369318008423
Validation loss: 2.4567674488149662

Epoch: 111| Step: 0
Training loss: 3.303898811340332
Validation loss: 2.4640785007066626

Epoch: 6| Step: 1
Training loss: 3.0551095008850098
Validation loss: 2.466640644176032

Epoch: 6| Step: 2
Training loss: 2.662149429321289
Validation loss: 2.467026449018909

Epoch: 6| Step: 3
Training loss: 2.7357234954833984
Validation loss: 2.464007992898264

Epoch: 6| Step: 4
Training loss: 2.9647128582000732
Validation loss: 2.4607660026960474

Epoch: 6| Step: 5
Training loss: 2.3389639854431152
Validation loss: 2.460525587040891

Epoch: 6| Step: 6
Training loss: 2.845327854156494
Validation loss: 2.453619590369604

Epoch: 6| Step: 7
Training loss: 3.2562379837036133
Validation loss: 2.4552476380461004

Epoch: 6| Step: 8
Training loss: 2.0411510467529297
Validation loss: 2.4565538719136226

Epoch: 6| Step: 9
Training loss: 2.2836897373199463
Validation loss: 2.466871348760461

Epoch: 6| Step: 10
Training loss: 2.265183448791504
Validation loss: 2.469806986470376

Epoch: 6| Step: 11
Training loss: 2.4755077362060547
Validation loss: 2.4784399027465494

Epoch: 6| Step: 12
Training loss: 2.597817897796631
Validation loss: 2.489833201131513

Epoch: 6| Step: 13
Training loss: 2.411003589630127
Validation loss: 2.487875359032744

Epoch: 112| Step: 0
Training loss: 2.2869935035705566
Validation loss: 2.4807404651436755

Epoch: 6| Step: 1
Training loss: 3.804670810699463
Validation loss: 2.470640331186274

Epoch: 6| Step: 2
Training loss: 2.485334873199463
Validation loss: 2.47102245976848

Epoch: 6| Step: 3
Training loss: 1.8069908618927002
Validation loss: 2.446973753231828

Epoch: 6| Step: 4
Training loss: 3.3056607246398926
Validation loss: 2.4491130767330045

Epoch: 6| Step: 5
Training loss: 2.6432056427001953
Validation loss: 2.4539367870617936

Epoch: 6| Step: 6
Training loss: 3.1974215507507324
Validation loss: 2.4471990780163835

Epoch: 6| Step: 7
Training loss: 2.546359062194824
Validation loss: 2.4519698901843

Epoch: 6| Step: 8
Training loss: 2.5895566940307617
Validation loss: 2.4539668149845575

Epoch: 6| Step: 9
Training loss: 2.4163765907287598
Validation loss: 2.4481728564026537

Epoch: 6| Step: 10
Training loss: 2.603975534439087
Validation loss: 2.4563129768576673

Epoch: 6| Step: 11
Training loss: 2.121182918548584
Validation loss: 2.454911467849567

Epoch: 6| Step: 12
Training loss: 2.767143726348877
Validation loss: 2.4610417171191146

Epoch: 6| Step: 13
Training loss: 2.4650888442993164
Validation loss: 2.460108990310341

Epoch: 113| Step: 0
Training loss: 2.373518466949463
Validation loss: 2.463187107475855

Epoch: 6| Step: 1
Training loss: 2.9016029834747314
Validation loss: 2.463274807058355

Epoch: 6| Step: 2
Training loss: 2.4134979248046875
Validation loss: 2.464499742754044

Epoch: 6| Step: 3
Training loss: 2.0320253372192383
Validation loss: 2.4723821301614084

Epoch: 6| Step: 4
Training loss: 2.471409320831299
Validation loss: 2.4779273848379813

Epoch: 6| Step: 5
Training loss: 2.8069534301757812
Validation loss: 2.4809149593435307

Epoch: 6| Step: 6
Training loss: 1.799536943435669
Validation loss: 2.4924776759198917

Epoch: 6| Step: 7
Training loss: 3.0183205604553223
Validation loss: 2.486860675196494

Epoch: 6| Step: 8
Training loss: 2.2494707107543945
Validation loss: 2.4749837613874868

Epoch: 6| Step: 9
Training loss: 3.213576555252075
Validation loss: 2.463200215370424

Epoch: 6| Step: 10
Training loss: 2.5024795532226562
Validation loss: 2.4692017237345376

Epoch: 6| Step: 11
Training loss: 3.1917366981506348
Validation loss: 2.462434809695008

Epoch: 6| Step: 12
Training loss: 3.2675669193267822
Validation loss: 2.4591352067967898

Epoch: 6| Step: 13
Training loss: 3.267479419708252
Validation loss: 2.4580057923511793

Epoch: 114| Step: 0
Training loss: 2.4691195487976074
Validation loss: 2.4513562315253803

Epoch: 6| Step: 1
Training loss: 2.9548027515411377
Validation loss: 2.4493628163491525

Epoch: 6| Step: 2
Training loss: 2.598194122314453
Validation loss: 2.443913205977409

Epoch: 6| Step: 3
Training loss: 2.6001358032226562
Validation loss: 2.4485281821220153

Epoch: 6| Step: 4
Training loss: 2.246425151824951
Validation loss: 2.4453939160993023

Epoch: 6| Step: 5
Training loss: 2.0192646980285645
Validation loss: 2.4532318192143596

Epoch: 6| Step: 6
Training loss: 2.6751503944396973
Validation loss: 2.4724176699115383

Epoch: 6| Step: 7
Training loss: 2.5373058319091797
Validation loss: 2.4710567407710577

Epoch: 6| Step: 8
Training loss: 2.404737710952759
Validation loss: 2.48196247828904

Epoch: 6| Step: 9
Training loss: 3.074863910675049
Validation loss: 2.4946890877139185

Epoch: 6| Step: 10
Training loss: 2.8124656677246094
Validation loss: 2.504822054216939

Epoch: 6| Step: 11
Training loss: 3.357393980026245
Validation loss: 2.502633520351943

Epoch: 6| Step: 12
Training loss: 2.6347665786743164
Validation loss: 2.5131650458100023

Epoch: 6| Step: 13
Training loss: 2.8662190437316895
Validation loss: 2.492404435270576

Epoch: 115| Step: 0
Training loss: 2.4735124111175537
Validation loss: 2.477385628607965

Epoch: 6| Step: 1
Training loss: 3.2617416381835938
Validation loss: 2.465675284785609

Epoch: 6| Step: 2
Training loss: 2.3435935974121094
Validation loss: 2.456673273476221

Epoch: 6| Step: 3
Training loss: 2.1878161430358887
Validation loss: 2.452474319806663

Epoch: 6| Step: 4
Training loss: 2.2663609981536865
Validation loss: 2.448721049934305

Epoch: 6| Step: 5
Training loss: 2.2097859382629395
Validation loss: 2.449134462623186

Epoch: 6| Step: 6
Training loss: 2.8401196002960205
Validation loss: 2.4487684875406246

Epoch: 6| Step: 7
Training loss: 2.9782662391662598
Validation loss: 2.4517520294394544

Epoch: 6| Step: 8
Training loss: 2.9646856784820557
Validation loss: 2.4546115526589016

Epoch: 6| Step: 9
Training loss: 2.283207893371582
Validation loss: 2.4553272595969577

Epoch: 6| Step: 10
Training loss: 2.4135525226593018
Validation loss: 2.4679448860947804

Epoch: 6| Step: 11
Training loss: 3.0473413467407227
Validation loss: 2.4850194428556707

Epoch: 6| Step: 12
Training loss: 3.187772274017334
Validation loss: 2.4856182298352643

Epoch: 6| Step: 13
Training loss: 2.65769362449646
Validation loss: 2.495472244037095

Epoch: 116| Step: 0
Training loss: 2.6737914085388184
Validation loss: 2.5091066770656134

Epoch: 6| Step: 1
Training loss: 1.9698270559310913
Validation loss: 2.5185765630455426

Epoch: 6| Step: 2
Training loss: 2.579164981842041
Validation loss: 2.519930601119995

Epoch: 6| Step: 3
Training loss: 2.634754180908203
Validation loss: 2.5222002972838697

Epoch: 6| Step: 4
Training loss: 2.9244775772094727
Validation loss: 2.5383337800220778

Epoch: 6| Step: 5
Training loss: 2.819256067276001
Validation loss: 2.530176090937789

Epoch: 6| Step: 6
Training loss: 3.3686835765838623
Validation loss: 2.526463572696973

Epoch: 6| Step: 7
Training loss: 2.9325103759765625
Validation loss: 2.5221126156468547

Epoch: 6| Step: 8
Training loss: 2.6851248741149902
Validation loss: 2.526569410036969

Epoch: 6| Step: 9
Training loss: 2.674055814743042
Validation loss: 2.5191846586042836

Epoch: 6| Step: 10
Training loss: 2.063347816467285
Validation loss: 2.5261598428090415

Epoch: 6| Step: 11
Training loss: 3.1018455028533936
Validation loss: 2.5235185828260196

Epoch: 6| Step: 12
Training loss: 2.9311938285827637
Validation loss: 2.5188908051419

Epoch: 6| Step: 13
Training loss: 2.043818235397339
Validation loss: 2.518774760666714

Epoch: 117| Step: 0
Training loss: 2.445380687713623
Validation loss: 2.519576641821092

Epoch: 6| Step: 1
Training loss: 2.7240757942199707
Validation loss: 2.5108895737637758

Epoch: 6| Step: 2
Training loss: 3.404500722885132
Validation loss: 2.5097047487894693

Epoch: 6| Step: 3
Training loss: 3.0942344665527344
Validation loss: 2.4972327729707122

Epoch: 6| Step: 4
Training loss: 2.01789927482605
Validation loss: 2.4921508271207093

Epoch: 6| Step: 5
Training loss: 2.8805956840515137
Validation loss: 2.473667960013113

Epoch: 6| Step: 6
Training loss: 3.5278329849243164
Validation loss: 2.475870483665056

Epoch: 6| Step: 7
Training loss: 2.359586715698242
Validation loss: 2.4730615487662693

Epoch: 6| Step: 8
Training loss: 2.5354723930358887
Validation loss: 2.463044830547866

Epoch: 6| Step: 9
Training loss: 1.5802574157714844
Validation loss: 2.4442894125497467

Epoch: 6| Step: 10
Training loss: 3.0509960651397705
Validation loss: 2.443135920391288

Epoch: 6| Step: 11
Training loss: 2.591175079345703
Validation loss: 2.438130135177284

Epoch: 6| Step: 12
Training loss: 2.8083362579345703
Validation loss: 2.425358554368378

Epoch: 6| Step: 13
Training loss: 1.890505313873291
Validation loss: 2.4319599008047454

Epoch: 118| Step: 0
Training loss: 2.9263288974761963
Validation loss: 2.431942714157925

Epoch: 6| Step: 1
Training loss: 3.103153705596924
Validation loss: 2.4312673640507523

Epoch: 6| Step: 2
Training loss: 1.9992903470993042
Validation loss: 2.4500827250942105

Epoch: 6| Step: 3
Training loss: 2.8532638549804688
Validation loss: 2.4633816108908704

Epoch: 6| Step: 4
Training loss: 3.2220447063446045
Validation loss: 2.4680722195615052

Epoch: 6| Step: 5
Training loss: 1.7334704399108887
Validation loss: 2.477374630589639

Epoch: 6| Step: 6
Training loss: 2.967864990234375
Validation loss: 2.479443306564003

Epoch: 6| Step: 7
Training loss: 3.265535831451416
Validation loss: 2.484648117455103

Epoch: 6| Step: 8
Training loss: 3.0266735553741455
Validation loss: 2.4798137423812703

Epoch: 6| Step: 9
Training loss: 2.0759098529815674
Validation loss: 2.464011341012934

Epoch: 6| Step: 10
Training loss: 2.4002199172973633
Validation loss: 2.451658694974838

Epoch: 6| Step: 11
Training loss: 2.709023952484131
Validation loss: 2.4374269208600445

Epoch: 6| Step: 12
Training loss: 2.4678847789764404
Validation loss: 2.4288952324980047

Epoch: 6| Step: 13
Training loss: 2.3300411701202393
Validation loss: 2.4282482003652923

Epoch: 119| Step: 0
Training loss: 2.311785936355591
Validation loss: 2.4284869419631137

Epoch: 6| Step: 1
Training loss: 2.4603757858276367
Validation loss: 2.4296509604300223

Epoch: 6| Step: 2
Training loss: 3.192284107208252
Validation loss: 2.4359587828318277

Epoch: 6| Step: 3
Training loss: 3.1976757049560547
Validation loss: 2.441009600957235

Epoch: 6| Step: 4
Training loss: 3.25821590423584
Validation loss: 2.446765658675983

Epoch: 6| Step: 5
Training loss: 2.7708358764648438
Validation loss: 2.4482663344311457

Epoch: 6| Step: 6
Training loss: 3.3746867179870605
Validation loss: 2.448746801704489

Epoch: 6| Step: 7
Training loss: 2.5176634788513184
Validation loss: 2.45206803916603

Epoch: 6| Step: 8
Training loss: 1.913499116897583
Validation loss: 2.451470531443114

Epoch: 6| Step: 9
Training loss: 1.936682939529419
Validation loss: 2.442533198223319

Epoch: 6| Step: 10
Training loss: 2.5862069129943848
Validation loss: 2.4436332000199186

Epoch: 6| Step: 11
Training loss: 2.6239006519317627
Validation loss: 2.4376207295284478

Epoch: 6| Step: 12
Training loss: 2.576018810272217
Validation loss: 2.4420003352626676

Epoch: 6| Step: 13
Training loss: 2.1386215686798096
Validation loss: 2.4372749905432425

Epoch: 120| Step: 0
Training loss: 2.6504147052764893
Validation loss: 2.4359630794935327

Epoch: 6| Step: 1
Training loss: 2.5108482837677
Validation loss: 2.435616890589396

Epoch: 6| Step: 2
Training loss: 3.323699951171875
Validation loss: 2.43508844478156

Epoch: 6| Step: 3
Training loss: 2.432323694229126
Validation loss: 2.4387373898618963

Epoch: 6| Step: 4
Training loss: 3.2888832092285156
Validation loss: 2.4386131135366296

Epoch: 6| Step: 5
Training loss: 2.7853715419769287
Validation loss: 2.444743110287574

Epoch: 6| Step: 6
Training loss: 2.2720556259155273
Validation loss: 2.44196028606866

Epoch: 6| Step: 7
Training loss: 2.05704665184021
Validation loss: 2.4436038053163918

Epoch: 6| Step: 8
Training loss: 2.6197776794433594
Validation loss: 2.451541805780062

Epoch: 6| Step: 9
Training loss: 2.528926372528076
Validation loss: 2.4501136246547905

Epoch: 6| Step: 10
Training loss: 2.3002259731292725
Validation loss: 2.440523483419931

Epoch: 6| Step: 11
Training loss: 2.4850950241088867
Validation loss: 2.4389914184488277

Epoch: 6| Step: 12
Training loss: 2.943645477294922
Validation loss: 2.4445898943049933

Epoch: 6| Step: 13
Training loss: 2.948289155960083
Validation loss: 2.442098186862084

Epoch: 121| Step: 0
Training loss: 2.8210105895996094
Validation loss: 2.440965457629132

Epoch: 6| Step: 1
Training loss: 2.240790367126465
Validation loss: 2.44050415613318

Epoch: 6| Step: 2
Training loss: 3.1259653568267822
Validation loss: 2.447452142674436

Epoch: 6| Step: 3
Training loss: 2.6169240474700928
Validation loss: 2.4445267543997815

Epoch: 6| Step: 4
Training loss: 3.0102744102478027
Validation loss: 2.4422181934438725

Epoch: 6| Step: 5
Training loss: 2.511789321899414
Validation loss: 2.449641981432515

Epoch: 6| Step: 6
Training loss: 3.038912773132324
Validation loss: 2.4427892649045555

Epoch: 6| Step: 7
Training loss: 2.46437931060791
Validation loss: 2.4436084429423013

Epoch: 6| Step: 8
Training loss: 2.8065614700317383
Validation loss: 2.4516765968773955

Epoch: 6| Step: 9
Training loss: 2.998450517654419
Validation loss: 2.4431753568751837

Epoch: 6| Step: 10
Training loss: 2.31368350982666
Validation loss: 2.4495237181263585

Epoch: 6| Step: 11
Training loss: 2.13626766204834
Validation loss: 2.4458279045679236

Epoch: 6| Step: 12
Training loss: 2.4744863510131836
Validation loss: 2.4499580962683565

Epoch: 6| Step: 13
Training loss: 2.020718574523926
Validation loss: 2.4496679767485587

Epoch: 122| Step: 0
Training loss: 2.8224270343780518
Validation loss: 2.447706360970774

Epoch: 6| Step: 1
Training loss: 3.4859886169433594
Validation loss: 2.4522330248227684

Epoch: 6| Step: 2
Training loss: 3.1432480812072754
Validation loss: 2.457397955720143

Epoch: 6| Step: 3
Training loss: 1.9016220569610596
Validation loss: 2.4537663536687053

Epoch: 6| Step: 4
Training loss: 2.1105635166168213
Validation loss: 2.45809188196736

Epoch: 6| Step: 5
Training loss: 3.1799402236938477
Validation loss: 2.459626664397537

Epoch: 6| Step: 6
Training loss: 2.7120141983032227
Validation loss: 2.454152258493567

Epoch: 6| Step: 7
Training loss: 3.046294689178467
Validation loss: 2.4506754721364667

Epoch: 6| Step: 8
Training loss: 2.072551965713501
Validation loss: 2.4490438122903146

Epoch: 6| Step: 9
Training loss: 2.2860453128814697
Validation loss: 2.452636945632196

Epoch: 6| Step: 10
Training loss: 2.3376083374023438
Validation loss: 2.445621536624047

Epoch: 6| Step: 11
Training loss: 2.7917585372924805
Validation loss: 2.4538362949125228

Epoch: 6| Step: 12
Training loss: 1.7605981826782227
Validation loss: 2.4458589348741757

Epoch: 6| Step: 13
Training loss: 3.604116201400757
Validation loss: 2.4452766192856656

Epoch: 123| Step: 0
Training loss: 2.376340389251709
Validation loss: 2.4402291300476238

Epoch: 6| Step: 1
Training loss: 2.697787046432495
Validation loss: 2.4425102536396315

Epoch: 6| Step: 2
Training loss: 3.4506888389587402
Validation loss: 2.442179718325215

Epoch: 6| Step: 3
Training loss: 2.4210286140441895
Validation loss: 2.435717003319853

Epoch: 6| Step: 4
Training loss: 2.8704042434692383
Validation loss: 2.4319096175573205

Epoch: 6| Step: 5
Training loss: 2.386241912841797
Validation loss: 2.4316561580986105

Epoch: 6| Step: 6
Training loss: 2.6543006896972656
Validation loss: 2.4353544583884617

Epoch: 6| Step: 7
Training loss: 2.669649600982666
Validation loss: 2.4360615207302954

Epoch: 6| Step: 8
Training loss: 2.6384942531585693
Validation loss: 2.4402631072587866

Epoch: 6| Step: 9
Training loss: 3.0877299308776855
Validation loss: 2.435240378943823

Epoch: 6| Step: 10
Training loss: 2.584876298904419
Validation loss: 2.4374103084687264

Epoch: 6| Step: 11
Training loss: 1.7696613073349
Validation loss: 2.4454886400571434

Epoch: 6| Step: 12
Training loss: 2.550943374633789
Validation loss: 2.4489823259333128

Epoch: 6| Step: 13
Training loss: 2.7617578506469727
Validation loss: 2.447159961987567

Epoch: 124| Step: 0
Training loss: 2.89884877204895
Validation loss: 2.4577083613282893

Epoch: 6| Step: 1
Training loss: 2.393261432647705
Validation loss: 2.4663163615811254

Epoch: 6| Step: 2
Training loss: 2.170562744140625
Validation loss: 2.464807798785548

Epoch: 6| Step: 3
Training loss: 1.9840253591537476
Validation loss: 2.461122570499297

Epoch: 6| Step: 4
Training loss: 2.6681923866271973
Validation loss: 2.460480067037767

Epoch: 6| Step: 5
Training loss: 2.87998628616333
Validation loss: 2.4510459874265935

Epoch: 6| Step: 6
Training loss: 3.3047382831573486
Validation loss: 2.441951013380481

Epoch: 6| Step: 7
Training loss: 2.575474977493286
Validation loss: 2.4404724541530816

Epoch: 6| Step: 8
Training loss: 2.3989367485046387
Validation loss: 2.4332520320851314

Epoch: 6| Step: 9
Training loss: 2.338132381439209
Validation loss: 2.4346181705433834

Epoch: 6| Step: 10
Training loss: 3.084649085998535
Validation loss: 2.4307940903530327

Epoch: 6| Step: 11
Training loss: 2.7506680488586426
Validation loss: 2.433483677525674

Epoch: 6| Step: 12
Training loss: 2.4688010215759277
Validation loss: 2.4254649992912047

Epoch: 6| Step: 13
Training loss: 3.122796058654785
Validation loss: 2.430193296042822

Epoch: 125| Step: 0
Training loss: 2.184187173843384
Validation loss: 2.4344976614880305

Epoch: 6| Step: 1
Training loss: 3.115567207336426
Validation loss: 2.4322312160204818

Epoch: 6| Step: 2
Training loss: 2.55633544921875
Validation loss: 2.436968377841416

Epoch: 6| Step: 3
Training loss: 3.348620891571045
Validation loss: 2.4472851599416425

Epoch: 6| Step: 4
Training loss: 2.3840417861938477
Validation loss: 2.448421210371038

Epoch: 6| Step: 5
Training loss: 2.5980610847473145
Validation loss: 2.445761319129698

Epoch: 6| Step: 6
Training loss: 2.7398204803466797
Validation loss: 2.4408884330462386

Epoch: 6| Step: 7
Training loss: 1.7025222778320312
Validation loss: 2.4490570304214314

Epoch: 6| Step: 8
Training loss: 2.4493303298950195
Validation loss: 2.44799812634786

Epoch: 6| Step: 9
Training loss: 2.4331111907958984
Validation loss: 2.43446171668268

Epoch: 6| Step: 10
Training loss: 2.573582172393799
Validation loss: 2.4366444413379957

Epoch: 6| Step: 11
Training loss: 2.8071775436401367
Validation loss: 2.424389377717049

Epoch: 6| Step: 12
Training loss: 2.9802682399749756
Validation loss: 2.4220055123811126

Epoch: 6| Step: 13
Training loss: 3.1620185375213623
Validation loss: 2.426324625169077

Epoch: 126| Step: 0
Training loss: 3.1252026557922363
Validation loss: 2.426887837789392

Epoch: 6| Step: 1
Training loss: 2.823942184448242
Validation loss: 2.433340698160151

Epoch: 6| Step: 2
Training loss: 2.7796578407287598
Validation loss: 2.438110546399188

Epoch: 6| Step: 3
Training loss: 2.2975783348083496
Validation loss: 2.4429410375574583

Epoch: 6| Step: 4
Training loss: 2.9672975540161133
Validation loss: 2.443813787993564

Epoch: 6| Step: 5
Training loss: 2.1389763355255127
Validation loss: 2.45592079624053

Epoch: 6| Step: 6
Training loss: 2.2268831729888916
Validation loss: 2.4615604877471924

Epoch: 6| Step: 7
Training loss: 2.177248477935791
Validation loss: 2.4779827722939114

Epoch: 6| Step: 8
Training loss: 3.3297295570373535
Validation loss: 2.4830285887564383

Epoch: 6| Step: 9
Training loss: 2.5736546516418457
Validation loss: 2.482908835975073

Epoch: 6| Step: 10
Training loss: 2.5421204566955566
Validation loss: 2.480194645543252

Epoch: 6| Step: 11
Training loss: 2.9829368591308594
Validation loss: 2.4729996419722036

Epoch: 6| Step: 12
Training loss: 2.780285596847534
Validation loss: 2.463960906510712

Epoch: 6| Step: 13
Training loss: 1.7446826696395874
Validation loss: 2.4649173803226923

Epoch: 127| Step: 0
Training loss: 3.0569286346435547
Validation loss: 2.465188839102304

Epoch: 6| Step: 1
Training loss: 2.9000234603881836
Validation loss: 2.462904771169027

Epoch: 6| Step: 2
Training loss: 2.814772129058838
Validation loss: 2.4574657229967016

Epoch: 6| Step: 3
Training loss: 2.2296481132507324
Validation loss: 2.4574528894116803

Epoch: 6| Step: 4
Training loss: 1.9418150186538696
Validation loss: 2.454150635709045

Epoch: 6| Step: 5
Training loss: 3.1778368949890137
Validation loss: 2.4619906794640327

Epoch: 6| Step: 6
Training loss: 2.9886183738708496
Validation loss: 2.461245959804904

Epoch: 6| Step: 7
Training loss: 2.0963540077209473
Validation loss: 2.465430918560233

Epoch: 6| Step: 8
Training loss: 2.933136224746704
Validation loss: 2.4605954359936457

Epoch: 6| Step: 9
Training loss: 2.756387710571289
Validation loss: 2.445894205442039

Epoch: 6| Step: 10
Training loss: 2.5711278915405273
Validation loss: 2.4323714420359623

Epoch: 6| Step: 11
Training loss: 2.8397998809814453
Validation loss: 2.4285149779371036

Epoch: 6| Step: 12
Training loss: 2.4285929203033447
Validation loss: 2.422969174641435

Epoch: 6| Step: 13
Training loss: 1.7704954147338867
Validation loss: 2.412957563195177

Epoch: 128| Step: 0
Training loss: 3.076096534729004
Validation loss: 2.40247332408864

Epoch: 6| Step: 1
Training loss: 2.668379306793213
Validation loss: 2.40838183382506

Epoch: 6| Step: 2
Training loss: 3.0290493965148926
Validation loss: 2.4029565549665883

Epoch: 6| Step: 3
Training loss: 2.872100830078125
Validation loss: 2.4075479404900664

Epoch: 6| Step: 4
Training loss: 2.5372512340545654
Validation loss: 2.408542961202642

Epoch: 6| Step: 5
Training loss: 2.815700054168701
Validation loss: 2.4148794502340336

Epoch: 6| Step: 6
Training loss: 1.8487507104873657
Validation loss: 2.4139687989347722

Epoch: 6| Step: 7
Training loss: 2.9756007194519043
Validation loss: 2.4106300030985186

Epoch: 6| Step: 8
Training loss: 1.7550767660140991
Validation loss: 2.4171558016089985

Epoch: 6| Step: 9
Training loss: 2.3982388973236084
Validation loss: 2.415525754292806

Epoch: 6| Step: 10
Training loss: 2.420128583908081
Validation loss: 2.4181411650873

Epoch: 6| Step: 11
Training loss: 2.9268958568573
Validation loss: 2.4197430149201424

Epoch: 6| Step: 12
Training loss: 2.7824435234069824
Validation loss: 2.419669084651496

Epoch: 6| Step: 13
Training loss: 2.8441519737243652
Validation loss: 2.4139165621931835

Epoch: 129| Step: 0
Training loss: 2.5288639068603516
Validation loss: 2.428403974861227

Epoch: 6| Step: 1
Training loss: 1.8611022233963013
Validation loss: 2.431480251332765

Epoch: 6| Step: 2
Training loss: 2.3917150497436523
Validation loss: 2.439752677435516

Epoch: 6| Step: 3
Training loss: 2.216341972351074
Validation loss: 2.442606814445988

Epoch: 6| Step: 4
Training loss: 2.7185239791870117
Validation loss: 2.4552483840655257

Epoch: 6| Step: 5
Training loss: 2.2352912425994873
Validation loss: 2.457178497827181

Epoch: 6| Step: 6
Training loss: 2.926849603652954
Validation loss: 2.4688920333821285

Epoch: 6| Step: 7
Training loss: 3.387301206588745
Validation loss: 2.4704987105502876

Epoch: 6| Step: 8
Training loss: 2.8561792373657227
Validation loss: 2.46588158863847

Epoch: 6| Step: 9
Training loss: 2.770965576171875
Validation loss: 2.4631017766973025

Epoch: 6| Step: 10
Training loss: 2.266509771347046
Validation loss: 2.4572051186715402

Epoch: 6| Step: 11
Training loss: 3.069827079772949
Validation loss: 2.4511134086116666

Epoch: 6| Step: 12
Training loss: 2.8079090118408203
Validation loss: 2.444747309530935

Epoch: 6| Step: 13
Training loss: 2.6178207397460938
Validation loss: 2.4374110596154326

Epoch: 130| Step: 0
Training loss: 2.290346622467041
Validation loss: 2.421808527361962

Epoch: 6| Step: 1
Training loss: 2.922518253326416
Validation loss: 2.4196501393471994

Epoch: 6| Step: 2
Training loss: 2.5414435863494873
Validation loss: 2.4170935282143216

Epoch: 6| Step: 3
Training loss: 2.961452007293701
Validation loss: 2.4235520978127756

Epoch: 6| Step: 4
Training loss: 2.4996063709259033
Validation loss: 2.4276430786296888

Epoch: 6| Step: 5
Training loss: 2.7649552822113037
Validation loss: 2.4246032007278933

Epoch: 6| Step: 6
Training loss: 2.127685070037842
Validation loss: 2.4201076082004014

Epoch: 6| Step: 7
Training loss: 2.8604636192321777
Validation loss: 2.4224603996481946

Epoch: 6| Step: 8
Training loss: 2.7611076831817627
Validation loss: 2.4323720111641833

Epoch: 6| Step: 9
Training loss: 2.9978089332580566
Validation loss: 2.4230354037336124

Epoch: 6| Step: 10
Training loss: 2.41420841217041
Validation loss: 2.4285022699704735

Epoch: 6| Step: 11
Training loss: 2.9662792682647705
Validation loss: 2.424029291317027

Epoch: 6| Step: 12
Training loss: 2.318199634552002
Validation loss: 2.418290594572662

Epoch: 6| Step: 13
Training loss: 2.2975993156433105
Validation loss: 2.4196671029572845

Epoch: 131| Step: 0
Training loss: 3.0162434577941895
Validation loss: 2.4228535736760786

Epoch: 6| Step: 1
Training loss: 2.011000633239746
Validation loss: 2.418943533333399

Epoch: 6| Step: 2
Training loss: 2.491194486618042
Validation loss: 2.4207922361230336

Epoch: 6| Step: 3
Training loss: 2.1568241119384766
Validation loss: 2.414024970864737

Epoch: 6| Step: 4
Training loss: 2.0484066009521484
Validation loss: 2.4200656952396518

Epoch: 6| Step: 5
Training loss: 2.6259677410125732
Validation loss: 2.4116319353862474

Epoch: 6| Step: 6
Training loss: 3.211550235748291
Validation loss: 2.4157183375409854

Epoch: 6| Step: 7
Training loss: 2.649941921234131
Validation loss: 2.4106211149564354

Epoch: 6| Step: 8
Training loss: 2.523737907409668
Validation loss: 2.4112732307885283

Epoch: 6| Step: 9
Training loss: 3.325381278991699
Validation loss: 2.413632164719284

Epoch: 6| Step: 10
Training loss: 2.6642227172851562
Validation loss: 2.4109104320567143

Epoch: 6| Step: 11
Training loss: 2.3620846271514893
Validation loss: 2.413066961432016

Epoch: 6| Step: 12
Training loss: 2.845404863357544
Validation loss: 2.4161561868524037

Epoch: 6| Step: 13
Training loss: 3.2150633335113525
Validation loss: 2.4162789980570474

Epoch: 132| Step: 0
Training loss: 2.7814207077026367
Validation loss: 2.418480337307017

Epoch: 6| Step: 1
Training loss: 3.0178520679473877
Validation loss: 2.4250275011985534

Epoch: 6| Step: 2
Training loss: 2.9864072799682617
Validation loss: 2.4151380959377495

Epoch: 6| Step: 3
Training loss: 2.8815126419067383
Validation loss: 2.4271978178331928

Epoch: 6| Step: 4
Training loss: 2.3739895820617676
Validation loss: 2.422518366126604

Epoch: 6| Step: 5
Training loss: 3.485475540161133
Validation loss: 2.423821850489545

Epoch: 6| Step: 6
Training loss: 2.7309303283691406
Validation loss: 2.4238723324191187

Epoch: 6| Step: 7
Training loss: 2.8320019245147705
Validation loss: 2.4235870453619186

Epoch: 6| Step: 8
Training loss: 1.8376846313476562
Validation loss: 2.423420270284017

Epoch: 6| Step: 9
Training loss: 2.475844383239746
Validation loss: 2.417623334033515

Epoch: 6| Step: 10
Training loss: 2.818058729171753
Validation loss: 2.421913439227689

Epoch: 6| Step: 11
Training loss: 2.0045387744903564
Validation loss: 2.4222810845221243

Epoch: 6| Step: 12
Training loss: 1.9125661849975586
Validation loss: 2.4208759543716267

Epoch: 6| Step: 13
Training loss: 2.3401551246643066
Validation loss: 2.430180411184988

Epoch: 133| Step: 0
Training loss: 2.7399797439575195
Validation loss: 2.4331262239845852

Epoch: 6| Step: 1
Training loss: 2.872391700744629
Validation loss: 2.436270389505612

Epoch: 6| Step: 2
Training loss: 2.074253797531128
Validation loss: 2.43477967990342

Epoch: 6| Step: 3
Training loss: 2.3958330154418945
Validation loss: 2.443072949686358

Epoch: 6| Step: 4
Training loss: 2.7669477462768555
Validation loss: 2.437386638374739

Epoch: 6| Step: 5
Training loss: 2.3561391830444336
Validation loss: 2.4409264902914725

Epoch: 6| Step: 6
Training loss: 2.767848014831543
Validation loss: 2.438151172412339

Epoch: 6| Step: 7
Training loss: 2.543930768966675
Validation loss: 2.439440747743012

Epoch: 6| Step: 8
Training loss: 2.248955726623535
Validation loss: 2.4380097363584783

Epoch: 6| Step: 9
Training loss: 3.1983933448791504
Validation loss: 2.4354880009928057

Epoch: 6| Step: 10
Training loss: 2.9213876724243164
Validation loss: 2.442497102163171

Epoch: 6| Step: 11
Training loss: 2.634221315383911
Validation loss: 2.4314533741243425

Epoch: 6| Step: 12
Training loss: 2.6667027473449707
Validation loss: 2.4349775032330583

Epoch: 6| Step: 13
Training loss: 2.117694854736328
Validation loss: 2.43074978551557

Epoch: 134| Step: 0
Training loss: 3.1682517528533936
Validation loss: 2.4282150704373597

Epoch: 6| Step: 1
Training loss: 2.784466505050659
Validation loss: 2.4282993988324235

Epoch: 6| Step: 2
Training loss: 2.2613465785980225
Validation loss: 2.437160955962314

Epoch: 6| Step: 3
Training loss: 2.7224693298339844
Validation loss: 2.4329155798881286

Epoch: 6| Step: 4
Training loss: 2.776975631713867
Validation loss: 2.432808094127204

Epoch: 6| Step: 5
Training loss: 2.848144054412842
Validation loss: 2.428952245302098

Epoch: 6| Step: 6
Training loss: 2.0921213626861572
Validation loss: 2.443470334493986

Epoch: 6| Step: 7
Training loss: 2.2183425426483154
Validation loss: 2.442116388710596

Epoch: 6| Step: 8
Training loss: 3.405939817428589
Validation loss: 2.437333535122615

Epoch: 6| Step: 9
Training loss: 2.514397382736206
Validation loss: 2.4484067911742837

Epoch: 6| Step: 10
Training loss: 2.4722249507904053
Validation loss: 2.4365756511688232

Epoch: 6| Step: 11
Training loss: 2.59326434135437
Validation loss: 2.436178550925306

Epoch: 6| Step: 12
Training loss: 1.9488916397094727
Validation loss: 2.42947490625484

Epoch: 6| Step: 13
Training loss: 2.899594306945801
Validation loss: 2.4337705771128335

Epoch: 135| Step: 0
Training loss: 2.4113972187042236
Validation loss: 2.4372978069448985

Epoch: 6| Step: 1
Training loss: 2.3462705612182617
Validation loss: 2.4323768564449844

Epoch: 6| Step: 2
Training loss: 2.812487840652466
Validation loss: 2.4362080943199897

Epoch: 6| Step: 3
Training loss: 2.594803810119629
Validation loss: 2.433911819611826

Epoch: 6| Step: 4
Training loss: 2.0064198970794678
Validation loss: 2.424482583999634

Epoch: 6| Step: 5
Training loss: 3.4844210147857666
Validation loss: 2.4246589445298716

Epoch: 6| Step: 6
Training loss: 2.597752094268799
Validation loss: 2.4317125171743412

Epoch: 6| Step: 7
Training loss: 2.5818939208984375
Validation loss: 2.4389885651168

Epoch: 6| Step: 8
Training loss: 3.388646125793457
Validation loss: 2.428784147385628

Epoch: 6| Step: 9
Training loss: 2.3066062927246094
Validation loss: 2.430014676945184

Epoch: 6| Step: 10
Training loss: 2.5410971641540527
Validation loss: 2.4236299940334853

Epoch: 6| Step: 11
Training loss: 3.2188873291015625
Validation loss: 2.4241752650148127

Epoch: 6| Step: 12
Training loss: 1.819361925125122
Validation loss: 2.4212096711640716

Epoch: 6| Step: 13
Training loss: 2.42201566696167
Validation loss: 2.415866128859981

Epoch: 136| Step: 0
Training loss: 2.2454493045806885
Validation loss: 2.4193965183791293

Epoch: 6| Step: 1
Training loss: 2.132378578186035
Validation loss: 2.4237215518951416

Epoch: 6| Step: 2
Training loss: 3.0508999824523926
Validation loss: 2.4237467473553074

Epoch: 6| Step: 3
Training loss: 2.8943066596984863
Validation loss: 2.4228904965103313

Epoch: 6| Step: 4
Training loss: 2.7576444149017334
Validation loss: 2.426091150570941

Epoch: 6| Step: 5
Training loss: 3.2237796783447266
Validation loss: 2.4307484883134083

Epoch: 6| Step: 6
Training loss: 2.8744335174560547
Validation loss: 2.416041176806214

Epoch: 6| Step: 7
Training loss: 3.014488697052002
Validation loss: 2.4185930452039166

Epoch: 6| Step: 8
Training loss: 2.3152401447296143
Validation loss: 2.4188930706311296

Epoch: 6| Step: 9
Training loss: 2.2020211219787598
Validation loss: 2.4127004864395305

Epoch: 6| Step: 10
Training loss: 2.2534945011138916
Validation loss: 2.416114466164702

Epoch: 6| Step: 11
Training loss: 2.703537940979004
Validation loss: 2.411006030216012

Epoch: 6| Step: 12
Training loss: 2.2932803630828857
Validation loss: 2.4083981821613927

Epoch: 6| Step: 13
Training loss: 2.5477731227874756
Validation loss: 2.4112703569473757

Epoch: 137| Step: 0
Training loss: 2.0900022983551025
Validation loss: 2.4122052500324864

Epoch: 6| Step: 1
Training loss: 2.4022698402404785
Validation loss: 2.4037704006318124

Epoch: 6| Step: 2
Training loss: 2.8545234203338623
Validation loss: 2.4081774706481607

Epoch: 6| Step: 3
Training loss: 3.3534786701202393
Validation loss: 2.405344383690947

Epoch: 6| Step: 4
Training loss: 2.8772764205932617
Validation loss: 2.410014767800608

Epoch: 6| Step: 5
Training loss: 2.5142712593078613
Validation loss: 2.4090320192357546

Epoch: 6| Step: 6
Training loss: 2.80683970451355
Validation loss: 2.4157549950384323

Epoch: 6| Step: 7
Training loss: 1.6560412645339966
Validation loss: 2.4189386470343477

Epoch: 6| Step: 8
Training loss: 2.9752426147460938
Validation loss: 2.425102759433049

Epoch: 6| Step: 9
Training loss: 3.647164821624756
Validation loss: 2.4306468117621636

Epoch: 6| Step: 10
Training loss: 1.993892788887024
Validation loss: 2.4219605691971315

Epoch: 6| Step: 11
Training loss: 2.374516248703003
Validation loss: 2.431595607470441

Epoch: 6| Step: 12
Training loss: 2.415628433227539
Validation loss: 2.438950774490192

Epoch: 6| Step: 13
Training loss: 2.7113661766052246
Validation loss: 2.445076786061769

Epoch: 138| Step: 0
Training loss: 2.6110939979553223
Validation loss: 2.437777578189809

Epoch: 6| Step: 1
Training loss: 2.6845107078552246
Validation loss: 2.4372029471141037

Epoch: 6| Step: 2
Training loss: 2.0351791381835938
Validation loss: 2.4272970537985525

Epoch: 6| Step: 3
Training loss: 2.2563388347625732
Validation loss: 2.417939498860349

Epoch: 6| Step: 4
Training loss: 2.6786515712738037
Validation loss: 2.420226420125654

Epoch: 6| Step: 5
Training loss: 2.919095277786255
Validation loss: 2.4256443567173456

Epoch: 6| Step: 6
Training loss: 3.155886650085449
Validation loss: 2.42050180896636

Epoch: 6| Step: 7
Training loss: 2.6349589824676514
Validation loss: 2.409587014106012

Epoch: 6| Step: 8
Training loss: 2.0074827671051025
Validation loss: 2.411461014901438

Epoch: 6| Step: 9
Training loss: 2.7117056846618652
Validation loss: 2.412414721263352

Epoch: 6| Step: 10
Training loss: 2.7654035091400146
Validation loss: 2.4122293943999917

Epoch: 6| Step: 11
Training loss: 2.64569354057312
Validation loss: 2.413657101251746

Epoch: 6| Step: 12
Training loss: 3.0524914264678955
Validation loss: 2.4035525629597325

Epoch: 6| Step: 13
Training loss: 2.3045599460601807
Validation loss: 2.4046692079113376

Epoch: 139| Step: 0
Training loss: 2.1271204948425293
Validation loss: 2.3983544867525817

Epoch: 6| Step: 1
Training loss: 2.15537166595459
Validation loss: 2.3939237671513713

Epoch: 6| Step: 2
Training loss: 2.48404860496521
Validation loss: 2.393715750786566

Epoch: 6| Step: 3
Training loss: 2.452014923095703
Validation loss: 2.395396596641951

Epoch: 6| Step: 4
Training loss: 2.4270832538604736
Validation loss: 2.398648364569551

Epoch: 6| Step: 5
Training loss: 2.6709675788879395
Validation loss: 2.395078730839555

Epoch: 6| Step: 6
Training loss: 2.8371059894561768
Validation loss: 2.396422586133403

Epoch: 6| Step: 7
Training loss: 3.2438740730285645
Validation loss: 2.404620352611747

Epoch: 6| Step: 8
Training loss: 2.1302077770233154
Validation loss: 2.40394805195511

Epoch: 6| Step: 9
Training loss: 3.2365589141845703
Validation loss: 2.4076070836795274

Epoch: 6| Step: 10
Training loss: 3.2565603256225586
Validation loss: 2.416472206833542

Epoch: 6| Step: 11
Training loss: 1.7158061265945435
Validation loss: 2.4205194339957288

Epoch: 6| Step: 12
Training loss: 2.982451915740967
Validation loss: 2.421323699335898

Epoch: 6| Step: 13
Training loss: 2.9584405422210693
Validation loss: 2.417608517472462

Epoch: 140| Step: 0
Training loss: 2.0714917182922363
Validation loss: 2.4157800418074413

Epoch: 6| Step: 1
Training loss: 2.977808952331543
Validation loss: 2.409685755288729

Epoch: 6| Step: 2
Training loss: 1.9857996702194214
Validation loss: 2.4188856668369745

Epoch: 6| Step: 3
Training loss: 2.4909534454345703
Validation loss: 2.417523358457832

Epoch: 6| Step: 4
Training loss: 2.335239887237549
Validation loss: 2.4167546174859487

Epoch: 6| Step: 5
Training loss: 3.1274428367614746
Validation loss: 2.4078835056674097

Epoch: 6| Step: 6
Training loss: 2.225512981414795
Validation loss: 2.4155667366520053

Epoch: 6| Step: 7
Training loss: 2.6480491161346436
Validation loss: 2.4107092836851716

Epoch: 6| Step: 8
Training loss: 3.4182024002075195
Validation loss: 2.41340531328673

Epoch: 6| Step: 9
Training loss: 2.8654258251190186
Validation loss: 2.4108515093403478

Epoch: 6| Step: 10
Training loss: 3.1432461738586426
Validation loss: 2.4184672806852605

Epoch: 6| Step: 11
Training loss: 2.4192142486572266
Validation loss: 2.4109820140305387

Epoch: 6| Step: 12
Training loss: 2.264965057373047
Validation loss: 2.4135080178578696

Epoch: 6| Step: 13
Training loss: 2.279838800430298
Validation loss: 2.4155215217221166

Epoch: 141| Step: 0
Training loss: 3.1312918663024902
Validation loss: 2.4134337594432216

Epoch: 6| Step: 1
Training loss: 1.9125823974609375
Validation loss: 2.4138679837667816

Epoch: 6| Step: 2
Training loss: 2.9967310428619385
Validation loss: 2.4139680324062223

Epoch: 6| Step: 3
Training loss: 2.47281813621521
Validation loss: 2.411988571125974

Epoch: 6| Step: 4
Training loss: 2.899116277694702
Validation loss: 2.416510976770873

Epoch: 6| Step: 5
Training loss: 2.545621395111084
Validation loss: 2.418730156396025

Epoch: 6| Step: 6
Training loss: 1.8874608278274536
Validation loss: 2.4165555969361336

Epoch: 6| Step: 7
Training loss: 2.267413377761841
Validation loss: 2.4261261596474597

Epoch: 6| Step: 8
Training loss: 2.8684744834899902
Validation loss: 2.4159060549992386

Epoch: 6| Step: 9
Training loss: 2.432647466659546
Validation loss: 2.419829199391027

Epoch: 6| Step: 10
Training loss: 2.8246266841888428
Validation loss: 2.411283416132773

Epoch: 6| Step: 11
Training loss: 3.0133912563323975
Validation loss: 2.414074179946735

Epoch: 6| Step: 12
Training loss: 2.3989145755767822
Validation loss: 2.407464755478726

Epoch: 6| Step: 13
Training loss: 2.813054084777832
Validation loss: 2.388286969994986

Epoch: 142| Step: 0
Training loss: 3.3565285205841064
Validation loss: 2.386726951086393

Epoch: 6| Step: 1
Training loss: 2.4270918369293213
Validation loss: 2.3870277430421565

Epoch: 6| Step: 2
Training loss: 2.76574969291687
Validation loss: 2.391240559598451

Epoch: 6| Step: 3
Training loss: 2.5731539726257324
Validation loss: 2.387135141639299

Epoch: 6| Step: 4
Training loss: 2.6388604640960693
Validation loss: 2.3884732646326863

Epoch: 6| Step: 5
Training loss: 3.6135716438293457
Validation loss: 2.3884108092195246

Epoch: 6| Step: 6
Training loss: 2.4124417304992676
Validation loss: 2.393648342419696

Epoch: 6| Step: 7
Training loss: 2.7957587242126465
Validation loss: 2.393480970013526

Epoch: 6| Step: 8
Training loss: 1.9516944885253906
Validation loss: 2.3867976460405576

Epoch: 6| Step: 9
Training loss: 2.2544682025909424
Validation loss: 2.3981760932553198

Epoch: 6| Step: 10
Training loss: 2.2302470207214355
Validation loss: 2.399050680539941

Epoch: 6| Step: 11
Training loss: 2.7448296546936035
Validation loss: 2.4066531965809483

Epoch: 6| Step: 12
Training loss: 2.2898635864257812
Validation loss: 2.409654691655149

Epoch: 6| Step: 13
Training loss: 2.2745091915130615
Validation loss: 2.4204112688700357

Epoch: 143| Step: 0
Training loss: 2.2552409172058105
Validation loss: 2.4235122408918155

Epoch: 6| Step: 1
Training loss: 2.3238391876220703
Validation loss: 2.4169989426930747

Epoch: 6| Step: 2
Training loss: 2.4835596084594727
Validation loss: 2.410217087755921

Epoch: 6| Step: 3
Training loss: 3.4931342601776123
Validation loss: 2.409180461719472

Epoch: 6| Step: 4
Training loss: 3.22192645072937
Validation loss: 2.4048255592264156

Epoch: 6| Step: 5
Training loss: 2.713956356048584
Validation loss: 2.4072375733365297

Epoch: 6| Step: 6
Training loss: 2.5019383430480957
Validation loss: 2.407315577230146

Epoch: 6| Step: 7
Training loss: 2.087905168533325
Validation loss: 2.412707196768894

Epoch: 6| Step: 8
Training loss: 2.54449462890625
Validation loss: 2.405951182047526

Epoch: 6| Step: 9
Training loss: 2.7687087059020996
Validation loss: 2.4137701552401305

Epoch: 6| Step: 10
Training loss: 2.586472988128662
Validation loss: 2.413870011606524

Epoch: 6| Step: 11
Training loss: 2.14955997467041
Validation loss: 2.4099778231754097

Epoch: 6| Step: 12
Training loss: 2.4589109420776367
Validation loss: 2.419301571384553

Epoch: 6| Step: 13
Training loss: 2.9784841537475586
Validation loss: 2.406565661071449

Epoch: 144| Step: 0
Training loss: 1.766406774520874
Validation loss: 2.4126519695405038

Epoch: 6| Step: 1
Training loss: 2.7243244647979736
Validation loss: 2.4177470591760453

Epoch: 6| Step: 2
Training loss: 2.089721918106079
Validation loss: 2.418270928885347

Epoch: 6| Step: 3
Training loss: 2.1082780361175537
Validation loss: 2.417687608349708

Epoch: 6| Step: 4
Training loss: 2.591081380844116
Validation loss: 2.409869360667403

Epoch: 6| Step: 5
Training loss: 2.384608030319214
Validation loss: 2.416427207249467

Epoch: 6| Step: 6
Training loss: 2.353109359741211
Validation loss: 2.416979420569635

Epoch: 6| Step: 7
Training loss: 3.2983715534210205
Validation loss: 2.4170658434590986

Epoch: 6| Step: 8
Training loss: 2.6273458003997803
Validation loss: 2.4132640720695577

Epoch: 6| Step: 9
Training loss: 2.8935060501098633
Validation loss: 2.415115246208765

Epoch: 6| Step: 10
Training loss: 3.1040430068969727
Validation loss: 2.4093351338499334

Epoch: 6| Step: 11
Training loss: 2.7284507751464844
Validation loss: 2.4051117768851658

Epoch: 6| Step: 12
Training loss: 3.1961474418640137
Validation loss: 2.4068362174495572

Epoch: 6| Step: 13
Training loss: 2.2275381088256836
Validation loss: 2.397866263184496

Epoch: 145| Step: 0
Training loss: 1.512955904006958
Validation loss: 2.3994373044660016

Epoch: 6| Step: 1
Training loss: 2.97335147857666
Validation loss: 2.4033667195227837

Epoch: 6| Step: 2
Training loss: 2.650261163711548
Validation loss: 2.3979276995505057

Epoch: 6| Step: 3
Training loss: 2.4323625564575195
Validation loss: 2.4023507718117005

Epoch: 6| Step: 4
Training loss: 2.335568428039551
Validation loss: 2.3975958824157715

Epoch: 6| Step: 5
Training loss: 2.7243709564208984
Validation loss: 2.3964277390510804

Epoch: 6| Step: 6
Training loss: 2.4296889305114746
Validation loss: 2.3953645742067726

Epoch: 6| Step: 7
Training loss: 2.8897221088409424
Validation loss: 2.392591304676507

Epoch: 6| Step: 8
Training loss: 2.2371180057525635
Validation loss: 2.397083274779781

Epoch: 6| Step: 9
Training loss: 2.027780294418335
Validation loss: 2.3912031983816497

Epoch: 6| Step: 10
Training loss: 2.8654356002807617
Validation loss: 2.3980280558268228

Epoch: 6| Step: 11
Training loss: 3.738107681274414
Validation loss: 2.393459778960033

Epoch: 6| Step: 12
Training loss: 2.8446240425109863
Validation loss: 2.392530946321385

Epoch: 6| Step: 13
Training loss: 2.66180157661438
Validation loss: 2.400491363258772

Epoch: 146| Step: 0
Training loss: 3.056628704071045
Validation loss: 2.398446754742694

Epoch: 6| Step: 1
Training loss: 2.580071449279785
Validation loss: 2.3943928108420423

Epoch: 6| Step: 2
Training loss: 3.0035367012023926
Validation loss: 2.401458571034093

Epoch: 6| Step: 3
Training loss: 2.141000747680664
Validation loss: 2.4042837940236574

Epoch: 6| Step: 4
Training loss: 2.6043508052825928
Validation loss: 2.402856380708756

Epoch: 6| Step: 5
Training loss: 2.60426926612854
Validation loss: 2.395375026169644

Epoch: 6| Step: 6
Training loss: 2.053593158721924
Validation loss: 2.39999101238866

Epoch: 6| Step: 7
Training loss: 2.951356887817383
Validation loss: 2.4039653091020483

Epoch: 6| Step: 8
Training loss: 2.913451671600342
Validation loss: 2.4112823188945813

Epoch: 6| Step: 9
Training loss: 1.8524422645568848
Validation loss: 2.4059775414005404

Epoch: 6| Step: 10
Training loss: 2.15392804145813
Validation loss: 2.4059327187076693

Epoch: 6| Step: 11
Training loss: 2.304323196411133
Validation loss: 2.4029134396583802

Epoch: 6| Step: 12
Training loss: 3.1740541458129883
Validation loss: 2.4004950523376465

Epoch: 6| Step: 13
Training loss: 3.043849468231201
Validation loss: 2.397108418967134

Epoch: 147| Step: 0
Training loss: 3.479694366455078
Validation loss: 2.3944876168363836

Epoch: 6| Step: 1
Training loss: 1.9598300457000732
Validation loss: 2.3903616551429994

Epoch: 6| Step: 2
Training loss: 2.517897844314575
Validation loss: 2.38959167849633

Epoch: 6| Step: 3
Training loss: 3.028590202331543
Validation loss: 2.375887252951181

Epoch: 6| Step: 4
Training loss: 2.72226619720459
Validation loss: 2.3732038851707213

Epoch: 6| Step: 5
Training loss: 2.4172096252441406
Validation loss: 2.3747206554617932

Epoch: 6| Step: 6
Training loss: 3.213998556137085
Validation loss: 2.37421606304825

Epoch: 6| Step: 7
Training loss: 2.6168031692504883
Validation loss: 2.376258316860404

Epoch: 6| Step: 8
Training loss: 2.747786521911621
Validation loss: 2.37713655220565

Epoch: 6| Step: 9
Training loss: 2.941728353500366
Validation loss: 2.385227532796962

Epoch: 6| Step: 10
Training loss: 2.212864637374878
Validation loss: 2.3799118149665093

Epoch: 6| Step: 11
Training loss: 2.283775806427002
Validation loss: 2.3824707846487723

Epoch: 6| Step: 12
Training loss: 2.1529598236083984
Validation loss: 2.3885657684777373

Epoch: 6| Step: 13
Training loss: 1.4746394157409668
Validation loss: 2.380100593771986

Epoch: 148| Step: 0
Training loss: 2.2229552268981934
Validation loss: 2.39292081709831

Epoch: 6| Step: 1
Training loss: 2.916961669921875
Validation loss: 2.398184823733504

Epoch: 6| Step: 2
Training loss: 3.1818337440490723
Validation loss: 2.3958144982655845

Epoch: 6| Step: 3
Training loss: 2.2249155044555664
Validation loss: 2.402012445593393

Epoch: 6| Step: 4
Training loss: 2.4869675636291504
Validation loss: 2.4027658175396662

Epoch: 6| Step: 5
Training loss: 1.7198619842529297
Validation loss: 2.4045958595891155

Epoch: 6| Step: 6
Training loss: 2.2139363288879395
Validation loss: 2.4176318030203543

Epoch: 6| Step: 7
Training loss: 2.713517904281616
Validation loss: 2.4070054382406254

Epoch: 6| Step: 8
Training loss: 2.3916635513305664
Validation loss: 2.405545691008209

Epoch: 6| Step: 9
Training loss: 2.6519508361816406
Validation loss: 2.4108590310619724

Epoch: 6| Step: 10
Training loss: 3.1943936347961426
Validation loss: 2.40513857974801

Epoch: 6| Step: 11
Training loss: 3.039053440093994
Validation loss: 2.4033575211801836

Epoch: 6| Step: 12
Training loss: 2.913802146911621
Validation loss: 2.3941615063657045

Epoch: 6| Step: 13
Training loss: 2.403242588043213
Validation loss: 2.3868960680500155

Epoch: 149| Step: 0
Training loss: 2.6916422843933105
Validation loss: 2.380733246444374

Epoch: 6| Step: 1
Training loss: 2.245002269744873
Validation loss: 2.3772798212625648

Epoch: 6| Step: 2
Training loss: 2.892951488494873
Validation loss: 2.375784889344246

Epoch: 6| Step: 3
Training loss: 3.4571094512939453
Validation loss: 2.3762151413066412

Epoch: 6| Step: 4
Training loss: 2.7685604095458984
Validation loss: 2.3752080907103834

Epoch: 6| Step: 5
Training loss: 1.9300665855407715
Validation loss: 2.378382739200387

Epoch: 6| Step: 6
Training loss: 2.9423134326934814
Validation loss: 2.3752203218398558

Epoch: 6| Step: 7
Training loss: 2.879002809524536
Validation loss: 2.3783500732914096

Epoch: 6| Step: 8
Training loss: 1.9634352922439575
Validation loss: 2.377016636633104

Epoch: 6| Step: 9
Training loss: 2.6086974143981934
Validation loss: 2.380742931878695

Epoch: 6| Step: 10
Training loss: 2.3595612049102783
Validation loss: 2.3853831163016697

Epoch: 6| Step: 11
Training loss: 2.160649538040161
Validation loss: 2.387131114159861

Epoch: 6| Step: 12
Training loss: 2.6152920722961426
Validation loss: 2.3864121257617907

Epoch: 6| Step: 13
Training loss: 2.593946933746338
Validation loss: 2.3855395675987325

Epoch: 150| Step: 0
Training loss: 3.3033645153045654
Validation loss: 2.4017700302985405

Epoch: 6| Step: 1
Training loss: 2.8511486053466797
Validation loss: 2.4216960425017984

Epoch: 6| Step: 2
Training loss: 3.3182339668273926
Validation loss: 2.4303117670038694

Epoch: 6| Step: 3
Training loss: 2.29469895362854
Validation loss: 2.445112702667072

Epoch: 6| Step: 4
Training loss: 2.0332653522491455
Validation loss: 2.446320733716411

Epoch: 6| Step: 5
Training loss: 2.8205924034118652
Validation loss: 2.466669544096916

Epoch: 6| Step: 6
Training loss: 3.3955307006835938
Validation loss: 2.473322165909634

Epoch: 6| Step: 7
Training loss: 2.9059431552886963
Validation loss: 2.4663340148105415

Epoch: 6| Step: 8
Training loss: 2.1703290939331055
Validation loss: 2.4661620637421966

Epoch: 6| Step: 9
Training loss: 2.8377914428710938
Validation loss: 2.4448538031629337

Epoch: 6| Step: 10
Training loss: 1.8134859800338745
Validation loss: 2.433103456292101

Epoch: 6| Step: 11
Training loss: 2.7182259559631348
Validation loss: 2.4102654021273375

Epoch: 6| Step: 12
Training loss: 1.7106854915618896
Validation loss: 2.4041887406379945

Epoch: 6| Step: 13
Training loss: 1.6350362300872803
Validation loss: 2.406947274361887

Epoch: 151| Step: 0
Training loss: 2.5205235481262207
Validation loss: 2.398840417144119

Epoch: 6| Step: 1
Training loss: 2.622917890548706
Validation loss: 2.4047582585324525

Epoch: 6| Step: 2
Training loss: 2.425616502761841
Validation loss: 2.4110431863415624

Epoch: 6| Step: 3
Training loss: 2.510314702987671
Validation loss: 2.4154471479436403

Epoch: 6| Step: 4
Training loss: 2.0057947635650635
Validation loss: 2.4183592283597557

Epoch: 6| Step: 5
Training loss: 2.9835333824157715
Validation loss: 2.412116935176234

Epoch: 6| Step: 6
Training loss: 2.189816474914551
Validation loss: 2.4035986059455463

Epoch: 6| Step: 7
Training loss: 2.6543643474578857
Validation loss: 2.4029807608614684

Epoch: 6| Step: 8
Training loss: 3.058183193206787
Validation loss: 2.393927248575354

Epoch: 6| Step: 9
Training loss: 2.905726671218872
Validation loss: 2.380806589639315

Epoch: 6| Step: 10
Training loss: 2.2084343433380127
Validation loss: 2.3806191080360004

Epoch: 6| Step: 11
Training loss: 2.7802910804748535
Validation loss: 2.3912355233264226

Epoch: 6| Step: 12
Training loss: 2.6868410110473633
Validation loss: 2.3978977075187107

Epoch: 6| Step: 13
Training loss: 2.7433207035064697
Validation loss: 2.4078603739379556

Epoch: 152| Step: 0
Training loss: 2.610032558441162
Validation loss: 2.415786258635982

Epoch: 6| Step: 1
Training loss: 2.4281842708587646
Validation loss: 2.4160940262579147

Epoch: 6| Step: 2
Training loss: 3.1583077907562256
Validation loss: 2.4118824082036174

Epoch: 6| Step: 3
Training loss: 2.7803802490234375
Validation loss: 2.4090381258277485

Epoch: 6| Step: 4
Training loss: 2.0856149196624756
Validation loss: 2.3921262089924147

Epoch: 6| Step: 5
Training loss: 2.277838706970215
Validation loss: 2.3879515047996276

Epoch: 6| Step: 6
Training loss: 3.149991035461426
Validation loss: 2.3786994744372625

Epoch: 6| Step: 7
Training loss: 1.8012111186981201
Validation loss: 2.3742069723785564

Epoch: 6| Step: 8
Training loss: 2.534489154815674
Validation loss: 2.3586881442736556

Epoch: 6| Step: 9
Training loss: 2.539830446243286
Validation loss: 2.363967607098241

Epoch: 6| Step: 10
Training loss: 3.1641592979431152
Validation loss: 2.3677238982210875

Epoch: 6| Step: 11
Training loss: 2.326934814453125
Validation loss: 2.373628315105233

Epoch: 6| Step: 12
Training loss: 2.7630867958068848
Validation loss: 2.3747084807324153

Epoch: 6| Step: 13
Training loss: 2.8625292778015137
Validation loss: 2.3756654903452885

Epoch: 153| Step: 0
Training loss: 2.151866912841797
Validation loss: 2.372425212655016

Epoch: 6| Step: 1
Training loss: 2.7741880416870117
Validation loss: 2.375623321020475

Epoch: 6| Step: 2
Training loss: 2.7275023460388184
Validation loss: 2.374279322162751

Epoch: 6| Step: 3
Training loss: 2.4005424976348877
Validation loss: 2.373576630828201

Epoch: 6| Step: 4
Training loss: 2.679460048675537
Validation loss: 2.3703134085542414

Epoch: 6| Step: 5
Training loss: 2.838404417037964
Validation loss: 2.369969397462824

Epoch: 6| Step: 6
Training loss: 2.198545455932617
Validation loss: 2.3830852149635233

Epoch: 6| Step: 7
Training loss: 2.6840453147888184
Validation loss: 2.3730768131953415

Epoch: 6| Step: 8
Training loss: 2.1224520206451416
Validation loss: 2.3768287653564126

Epoch: 6| Step: 9
Training loss: 2.2236392498016357
Validation loss: 2.3716656341347644

Epoch: 6| Step: 10
Training loss: 3.1572396755218506
Validation loss: 2.3775994059860066

Epoch: 6| Step: 11
Training loss: 3.2816481590270996
Validation loss: 2.3699254810169177

Epoch: 6| Step: 12
Training loss: 2.224137306213379
Validation loss: 2.3639334606867966

Epoch: 6| Step: 13
Training loss: 2.5880959033966064
Validation loss: 2.3556627201777633

Epoch: 154| Step: 0
Training loss: 2.412731647491455
Validation loss: 2.3482750846493627

Epoch: 6| Step: 1
Training loss: 2.3520913124084473
Validation loss: 2.3468499478473457

Epoch: 6| Step: 2
Training loss: 2.991567611694336
Validation loss: 2.3521614766890004

Epoch: 6| Step: 3
Training loss: 2.4147491455078125
Validation loss: 2.3576284352169243

Epoch: 6| Step: 4
Training loss: 2.7237277030944824
Validation loss: 2.3558937708536782

Epoch: 6| Step: 5
Training loss: 3.1999239921569824
Validation loss: 2.3513869880348124

Epoch: 6| Step: 6
Training loss: 1.9380183219909668
Validation loss: 2.3514497613394134

Epoch: 6| Step: 7
Training loss: 2.782335042953491
Validation loss: 2.359426003630443

Epoch: 6| Step: 8
Training loss: 2.4873411655426025
Validation loss: 2.3575533795100387

Epoch: 6| Step: 9
Training loss: 2.2927913665771484
Validation loss: 2.349949170184392

Epoch: 6| Step: 10
Training loss: 3.313626289367676
Validation loss: 2.344128216466596

Epoch: 6| Step: 11
Training loss: 2.5802950859069824
Validation loss: 2.3514716599577214

Epoch: 6| Step: 12
Training loss: 2.3697595596313477
Validation loss: 2.354173747442102

Epoch: 6| Step: 13
Training loss: 2.2060546875
Validation loss: 2.359640654697213

Epoch: 155| Step: 0
Training loss: 3.3973381519317627
Validation loss: 2.3648241950619604

Epoch: 6| Step: 1
Training loss: 2.5625624656677246
Validation loss: 2.363277878812564

Epoch: 6| Step: 2
Training loss: 2.4673116207122803
Validation loss: 2.386574473432315

Epoch: 6| Step: 3
Training loss: 2.056804656982422
Validation loss: 2.3929851619146203

Epoch: 6| Step: 4
Training loss: 2.5926129817962646
Validation loss: 2.3847705087354107

Epoch: 6| Step: 5
Training loss: 1.8757057189941406
Validation loss: 2.3845637767545638

Epoch: 6| Step: 6
Training loss: 2.3630683422088623
Validation loss: 2.3936267898928736

Epoch: 6| Step: 7
Training loss: 2.1164989471435547
Validation loss: 2.393969310227261

Epoch: 6| Step: 8
Training loss: 2.67875075340271
Validation loss: 2.394738366526942

Epoch: 6| Step: 9
Training loss: 2.7028591632843018
Validation loss: 2.3992904078575874

Epoch: 6| Step: 10
Training loss: 2.634219169616699
Validation loss: 2.4059245355667604

Epoch: 6| Step: 11
Training loss: 3.0231480598449707
Validation loss: 2.4006840464889363

Epoch: 6| Step: 12
Training loss: 3.179661273956299
Validation loss: 2.3850728798938055

Epoch: 6| Step: 13
Training loss: 2.1610288619995117
Validation loss: 2.3962494506630847

Epoch: 156| Step: 0
Training loss: 1.742445468902588
Validation loss: 2.3779114600150817

Epoch: 6| Step: 1
Training loss: 2.291996479034424
Validation loss: 2.3717196064610637

Epoch: 6| Step: 2
Training loss: 2.5105903148651123
Validation loss: 2.3831624241285425

Epoch: 6| Step: 3
Training loss: 2.877309799194336
Validation loss: 2.383762010964014

Epoch: 6| Step: 4
Training loss: 2.437488555908203
Validation loss: 2.387321610604563

Epoch: 6| Step: 5
Training loss: 2.407550811767578
Validation loss: 2.3775259730636433

Epoch: 6| Step: 6
Training loss: 2.5408973693847656
Validation loss: 2.3809625282082507

Epoch: 6| Step: 7
Training loss: 3.0938682556152344
Validation loss: 2.3846338179803666

Epoch: 6| Step: 8
Training loss: 2.040677785873413
Validation loss: 2.383349403258293

Epoch: 6| Step: 9
Training loss: 2.6817712783813477
Validation loss: 2.3774736081400225

Epoch: 6| Step: 10
Training loss: 3.035378932952881
Validation loss: 2.382088453538956

Epoch: 6| Step: 11
Training loss: 2.9113128185272217
Validation loss: 2.378453281617934

Epoch: 6| Step: 12
Training loss: 2.261355400085449
Validation loss: 2.377483316647109

Epoch: 6| Step: 13
Training loss: 3.371384859085083
Validation loss: 2.373865399309384

Epoch: 157| Step: 0
Training loss: 3.135756015777588
Validation loss: 2.3680984820089033

Epoch: 6| Step: 1
Training loss: 3.046395778656006
Validation loss: 2.366162048873081

Epoch: 6| Step: 2
Training loss: 2.0326156616210938
Validation loss: 2.3658966992491033

Epoch: 6| Step: 3
Training loss: 2.4256491661071777
Validation loss: 2.3661548194064888

Epoch: 6| Step: 4
Training loss: 2.1076388359069824
Validation loss: 2.368843727214362

Epoch: 6| Step: 5
Training loss: 1.9026317596435547
Validation loss: 2.373113642456711

Epoch: 6| Step: 6
Training loss: 2.807802438735962
Validation loss: 2.37141316680498

Epoch: 6| Step: 7
Training loss: 3.326824903488159
Validation loss: 2.3739903332084737

Epoch: 6| Step: 8
Training loss: 2.12909197807312
Validation loss: 2.36820730855388

Epoch: 6| Step: 9
Training loss: 2.672022581100464
Validation loss: 2.369410285385706

Epoch: 6| Step: 10
Training loss: 3.1232566833496094
Validation loss: 2.37237669831963

Epoch: 6| Step: 11
Training loss: 2.16851806640625
Validation loss: 2.372561167645198

Epoch: 6| Step: 12
Training loss: 1.9550515413284302
Validation loss: 2.376570660580871

Epoch: 6| Step: 13
Training loss: 3.4511210918426514
Validation loss: 2.377846112815283

Epoch: 158| Step: 0
Training loss: 2.38423490524292
Validation loss: 2.3672820573211997

Epoch: 6| Step: 1
Training loss: 3.0919790267944336
Validation loss: 2.3663880594315065

Epoch: 6| Step: 2
Training loss: 2.8215537071228027
Validation loss: 2.368397666561988

Epoch: 6| Step: 3
Training loss: 2.509498357772827
Validation loss: 2.367194373120544

Epoch: 6| Step: 4
Training loss: 2.51875638961792
Validation loss: 2.3694095534663044

Epoch: 6| Step: 5
Training loss: 2.7335166931152344
Validation loss: 2.3712413618641515

Epoch: 6| Step: 6
Training loss: 3.301551580429077
Validation loss: 2.3703180513074322

Epoch: 6| Step: 7
Training loss: 2.2448573112487793
Validation loss: 2.3774626126853367

Epoch: 6| Step: 8
Training loss: 2.179248571395874
Validation loss: 2.3728775644815094

Epoch: 6| Step: 9
Training loss: 2.9665346145629883
Validation loss: 2.366554085926343

Epoch: 6| Step: 10
Training loss: 2.9569764137268066
Validation loss: 2.3608593581825175

Epoch: 6| Step: 11
Training loss: 1.712660551071167
Validation loss: 2.365800972907774

Epoch: 6| Step: 12
Training loss: 1.732933759689331
Validation loss: 2.3560485352752027

Epoch: 6| Step: 13
Training loss: 2.952511787414551
Validation loss: 2.370361112779187

Epoch: 159| Step: 0
Training loss: 2.332488536834717
Validation loss: 2.3663119526319605

Epoch: 6| Step: 1
Training loss: 2.6893396377563477
Validation loss: 2.3648811976114907

Epoch: 6| Step: 2
Training loss: 2.7250125408172607
Validation loss: 2.370516377110635

Epoch: 6| Step: 3
Training loss: 2.7021381855010986
Validation loss: 2.3704482996335594

Epoch: 6| Step: 4
Training loss: 2.3388984203338623
Validation loss: 2.364681905315768

Epoch: 6| Step: 5
Training loss: 2.5899343490600586
Validation loss: 2.3634471842037734

Epoch: 6| Step: 6
Training loss: 2.352424383163452
Validation loss: 2.3615791900183565

Epoch: 6| Step: 7
Training loss: 3.530367851257324
Validation loss: 2.367158107860114

Epoch: 6| Step: 8
Training loss: 1.7828242778778076
Validation loss: 2.3625550782808693

Epoch: 6| Step: 9
Training loss: 2.6526739597320557
Validation loss: 2.3777317026610016

Epoch: 6| Step: 10
Training loss: 2.3082151412963867
Validation loss: 2.3791811645671888

Epoch: 6| Step: 11
Training loss: 2.419632911682129
Validation loss: 2.3767349412364345

Epoch: 6| Step: 12
Training loss: 2.6536664962768555
Validation loss: 2.3728406249835925

Epoch: 6| Step: 13
Training loss: 2.811356544494629
Validation loss: 2.368447026898784

Epoch: 160| Step: 0
Training loss: 3.0468480587005615
Validation loss: 2.3853148337333434

Epoch: 6| Step: 1
Training loss: 2.684154987335205
Validation loss: 2.3789376161431752

Epoch: 6| Step: 2
Training loss: 2.38446044921875
Validation loss: 2.373654865449475

Epoch: 6| Step: 3
Training loss: 2.8668923377990723
Validation loss: 2.3747099061166086

Epoch: 6| Step: 4
Training loss: 2.9246959686279297
Validation loss: 2.3741297004043416

Epoch: 6| Step: 5
Training loss: 1.74580717086792
Validation loss: 2.3668386526005243

Epoch: 6| Step: 6
Training loss: 1.8886115550994873
Validation loss: 2.3664538245047293

Epoch: 6| Step: 7
Training loss: 2.5679686069488525
Validation loss: 2.3572872249029015

Epoch: 6| Step: 8
Training loss: 1.8985990285873413
Validation loss: 2.364715442862562

Epoch: 6| Step: 9
Training loss: 3.1237144470214844
Validation loss: 2.3868447888282036

Epoch: 6| Step: 10
Training loss: 2.78305721282959
Validation loss: 2.395694896739016

Epoch: 6| Step: 11
Training loss: 2.7192649841308594
Validation loss: 2.4016041037856892

Epoch: 6| Step: 12
Training loss: 2.736114740371704
Validation loss: 2.3930606483131327

Epoch: 6| Step: 13
Training loss: 2.541003942489624
Validation loss: 2.397354548977267

Epoch: 161| Step: 0
Training loss: 1.9505739212036133
Validation loss: 2.401924540919642

Epoch: 6| Step: 1
Training loss: 2.5234079360961914
Validation loss: 2.3905623984593216

Epoch: 6| Step: 2
Training loss: 2.68729829788208
Validation loss: 2.3845928330575266

Epoch: 6| Step: 3
Training loss: 2.3229212760925293
Validation loss: 2.384719402559342

Epoch: 6| Step: 4
Training loss: 3.266101837158203
Validation loss: 2.377095386546145

Epoch: 6| Step: 5
Training loss: 2.565225124359131
Validation loss: 2.387344265496859

Epoch: 6| Step: 6
Training loss: 2.3998827934265137
Validation loss: 2.3978765062106553

Epoch: 6| Step: 7
Training loss: 3.0152134895324707
Validation loss: 2.400158292503767

Epoch: 6| Step: 8
Training loss: 2.3842883110046387
Validation loss: 2.4017014311205958

Epoch: 6| Step: 9
Training loss: 2.561221122741699
Validation loss: 2.394784349267201

Epoch: 6| Step: 10
Training loss: 2.5186195373535156
Validation loss: 2.385395760177284

Epoch: 6| Step: 11
Training loss: 2.1574106216430664
Validation loss: 2.3838674817033993

Epoch: 6| Step: 12
Training loss: 3.1763768196105957
Validation loss: 2.3790352062512468

Epoch: 6| Step: 13
Training loss: 2.3265814781188965
Validation loss: 2.3824780038608018

Epoch: 162| Step: 0
Training loss: 2.6498210430145264
Validation loss: 2.371554495185934

Epoch: 6| Step: 1
Training loss: 2.4269824028015137
Validation loss: 2.3733593674116236

Epoch: 6| Step: 2
Training loss: 2.704586982727051
Validation loss: 2.3668621970761206

Epoch: 6| Step: 3
Training loss: 2.090348482131958
Validation loss: 2.374897467192783

Epoch: 6| Step: 4
Training loss: 2.4515697956085205
Validation loss: 2.375932434553741

Epoch: 6| Step: 5
Training loss: 1.763542890548706
Validation loss: 2.373767570782733

Epoch: 6| Step: 6
Training loss: 2.405646800994873
Validation loss: 2.375709086336115

Epoch: 6| Step: 7
Training loss: 3.292673110961914
Validation loss: 2.3708961163797686

Epoch: 6| Step: 8
Training loss: 2.4923653602600098
Validation loss: 2.3724109665040047

Epoch: 6| Step: 9
Training loss: 2.124423027038574
Validation loss: 2.3700138650914675

Epoch: 6| Step: 10
Training loss: 2.6639022827148438
Validation loss: 2.36775702814902

Epoch: 6| Step: 11
Training loss: 3.391008138656616
Validation loss: 2.3626259885808474

Epoch: 6| Step: 12
Training loss: 3.006455659866333
Validation loss: 2.356294298684725

Epoch: 6| Step: 13
Training loss: 1.9686224460601807
Validation loss: 2.353328381815264

Epoch: 163| Step: 0
Training loss: 2.4464969635009766
Validation loss: 2.3461609553265315

Epoch: 6| Step: 1
Training loss: 3.2454233169555664
Validation loss: 2.3381541185481574

Epoch: 6| Step: 2
Training loss: 2.4372475147247314
Validation loss: 2.3340959574586604

Epoch: 6| Step: 3
Training loss: 2.569603443145752
Validation loss: 2.338853474586241

Epoch: 6| Step: 4
Training loss: 1.9506293535232544
Validation loss: 2.3424478243756037

Epoch: 6| Step: 5
Training loss: 2.337130069732666
Validation loss: 2.3391995865811586

Epoch: 6| Step: 6
Training loss: 2.885697364807129
Validation loss: 2.3492278129823747

Epoch: 6| Step: 7
Training loss: 2.9867796897888184
Validation loss: 2.34430887622218

Epoch: 6| Step: 8
Training loss: 2.223572254180908
Validation loss: 2.345697808009322

Epoch: 6| Step: 9
Training loss: 2.3725197315216064
Validation loss: 2.3397732473188833

Epoch: 6| Step: 10
Training loss: 2.837416172027588
Validation loss: 2.3388565996641755

Epoch: 6| Step: 11
Training loss: 2.6921873092651367
Validation loss: 2.3441091096529396

Epoch: 6| Step: 12
Training loss: 2.5493922233581543
Validation loss: 2.354191518598987

Epoch: 6| Step: 13
Training loss: 2.115713596343994
Validation loss: 2.3671040329881894

Epoch: 164| Step: 0
Training loss: 2.430703639984131
Validation loss: 2.3730859705196914

Epoch: 6| Step: 1
Training loss: 2.896824598312378
Validation loss: 2.37598777586414

Epoch: 6| Step: 2
Training loss: 2.916757106781006
Validation loss: 2.3801527125861055

Epoch: 6| Step: 3
Training loss: 2.6664071083068848
Validation loss: 2.3954382070931057

Epoch: 6| Step: 4
Training loss: 1.7870028018951416
Validation loss: 2.3878350283509944

Epoch: 6| Step: 5
Training loss: 2.0959620475769043
Validation loss: 2.375498080766329

Epoch: 6| Step: 6
Training loss: 2.410557270050049
Validation loss: 2.3806015778613347

Epoch: 6| Step: 7
Training loss: 2.5449328422546387
Validation loss: 2.374375189504316

Epoch: 6| Step: 8
Training loss: 2.054068088531494
Validation loss: 2.3666624381978023

Epoch: 6| Step: 9
Training loss: 2.4581894874572754
Validation loss: 2.3562798935879945

Epoch: 6| Step: 10
Training loss: 3.6074061393737793
Validation loss: 2.367461840311686

Epoch: 6| Step: 11
Training loss: 3.0938827991485596
Validation loss: 2.352595959940264

Epoch: 6| Step: 12
Training loss: 2.506812810897827
Validation loss: 2.3492597995265836

Epoch: 6| Step: 13
Training loss: 2.158888816833496
Validation loss: 2.346872388675649

Epoch: 165| Step: 0
Training loss: 2.475790023803711
Validation loss: 2.3365382481646795

Epoch: 6| Step: 1
Training loss: 2.835076093673706
Validation loss: 2.338025152042348

Epoch: 6| Step: 2
Training loss: 2.695889472961426
Validation loss: 2.33791688693467

Epoch: 6| Step: 3
Training loss: 2.408486843109131
Validation loss: 2.3370475307587655

Epoch: 6| Step: 4
Training loss: 1.8242226839065552
Validation loss: 2.354751458732031

Epoch: 6| Step: 5
Training loss: 2.9558115005493164
Validation loss: 2.35659033765075

Epoch: 6| Step: 6
Training loss: 1.886583685874939
Validation loss: 2.3708286246945782

Epoch: 6| Step: 7
Training loss: 2.8221585750579834
Validation loss: 2.380877456357402

Epoch: 6| Step: 8
Training loss: 3.0383551120758057
Validation loss: 2.3848146661635368

Epoch: 6| Step: 9
Training loss: 2.7661774158477783
Validation loss: 2.3916941868361605

Epoch: 6| Step: 10
Training loss: 3.2306246757507324
Validation loss: 2.3760727144056752

Epoch: 6| Step: 11
Training loss: 2.6523079872131348
Validation loss: 2.3758196676931074

Epoch: 6| Step: 12
Training loss: 2.3000588417053223
Validation loss: 2.3610325141619612

Epoch: 6| Step: 13
Training loss: 1.3908737897872925
Validation loss: 2.351080604778823

Epoch: 166| Step: 0
Training loss: 1.9817893505096436
Validation loss: 2.3484646479288735

Epoch: 6| Step: 1
Training loss: 3.011488199234009
Validation loss: 2.3472450343511437

Epoch: 6| Step: 2
Training loss: 2.492825508117676
Validation loss: 2.3477899541137037

Epoch: 6| Step: 3
Training loss: 2.7500405311584473
Validation loss: 2.3578731988065984

Epoch: 6| Step: 4
Training loss: 2.948557138442993
Validation loss: 2.3610155531155166

Epoch: 6| Step: 5
Training loss: 1.9661794900894165
Validation loss: 2.356050516969414

Epoch: 6| Step: 6
Training loss: 2.714832305908203
Validation loss: 2.3521161233225176

Epoch: 6| Step: 7
Training loss: 2.6316609382629395
Validation loss: 2.3452362911675566

Epoch: 6| Step: 8
Training loss: 3.022456169128418
Validation loss: 2.3448245397178074

Epoch: 6| Step: 9
Training loss: 2.0683116912841797
Validation loss: 2.3538634584796045

Epoch: 6| Step: 10
Training loss: 2.140483856201172
Validation loss: 2.346362506189654

Epoch: 6| Step: 11
Training loss: 2.332444906234741
Validation loss: 2.3392989943104405

Epoch: 6| Step: 12
Training loss: 2.706441879272461
Validation loss: 2.356225949461742

Epoch: 6| Step: 13
Training loss: 3.3216781616210938
Validation loss: 2.3680338064829507

Epoch: 167| Step: 0
Training loss: 2.9295616149902344
Validation loss: 2.374776937628305

Epoch: 6| Step: 1
Training loss: 2.370340585708618
Validation loss: 2.366331720864901

Epoch: 6| Step: 2
Training loss: 2.903818130493164
Validation loss: 2.3665113269641833

Epoch: 6| Step: 3
Training loss: 2.6202664375305176
Validation loss: 2.3689216900897283

Epoch: 6| Step: 4
Training loss: 2.951335906982422
Validation loss: 2.3647952413046234

Epoch: 6| Step: 5
Training loss: 2.3008928298950195
Validation loss: 2.3653421273795505

Epoch: 6| Step: 6
Training loss: 1.9390668869018555
Validation loss: 2.3392282609016664

Epoch: 6| Step: 7
Training loss: 2.3778014183044434
Validation loss: 2.334463401507306

Epoch: 6| Step: 8
Training loss: 2.3327016830444336
Validation loss: 2.3307467173504572

Epoch: 6| Step: 9
Training loss: 2.9587149620056152
Validation loss: 2.337249522568077

Epoch: 6| Step: 10
Training loss: 2.6562047004699707
Validation loss: 2.3311463479072816

Epoch: 6| Step: 11
Training loss: 2.138262987136841
Validation loss: 2.3421199731929327

Epoch: 6| Step: 12
Training loss: 2.7825512886047363
Validation loss: 2.3378250470725437

Epoch: 6| Step: 13
Training loss: 2.2620928287506104
Validation loss: 2.34927801675694

Epoch: 168| Step: 0
Training loss: 2.368429660797119
Validation loss: 2.3510286013285318

Epoch: 6| Step: 1
Training loss: 2.5745325088500977
Validation loss: 2.35187727661543

Epoch: 6| Step: 2
Training loss: 2.534296989440918
Validation loss: 2.355305597346316

Epoch: 6| Step: 3
Training loss: 2.8216304779052734
Validation loss: 2.368775918919553

Epoch: 6| Step: 4
Training loss: 2.942718505859375
Validation loss: 2.3898720382362284

Epoch: 6| Step: 5
Training loss: 2.6164023876190186
Validation loss: 2.4061616441254974

Epoch: 6| Step: 6
Training loss: 2.348045587539673
Validation loss: 2.423151085453649

Epoch: 6| Step: 7
Training loss: 2.633573532104492
Validation loss: 2.42761823438829

Epoch: 6| Step: 8
Training loss: 2.3555169105529785
Validation loss: 2.422262296881727

Epoch: 6| Step: 9
Training loss: 1.6590648889541626
Validation loss: 2.4050438532265286

Epoch: 6| Step: 10
Training loss: 2.473686456680298
Validation loss: 2.3942084876439904

Epoch: 6| Step: 11
Training loss: 3.078282356262207
Validation loss: 2.3848166645214124

Epoch: 6| Step: 12
Training loss: 2.7180445194244385
Validation loss: 2.378075433033769

Epoch: 6| Step: 13
Training loss: 2.662047863006592
Validation loss: 2.3571572355044785

Epoch: 169| Step: 0
Training loss: 2.332808494567871
Validation loss: 2.36158654766698

Epoch: 6| Step: 1
Training loss: 2.0178184509277344
Validation loss: 2.36085839938092

Epoch: 6| Step: 2
Training loss: 2.3270299434661865
Validation loss: 2.3584887622505106

Epoch: 6| Step: 3
Training loss: 2.6488840579986572
Validation loss: 2.3640571589111

Epoch: 6| Step: 4
Training loss: 3.2987587451934814
Validation loss: 2.351388967165383

Epoch: 6| Step: 5
Training loss: 2.077670097351074
Validation loss: 2.3474707116362867

Epoch: 6| Step: 6
Training loss: 2.301170825958252
Validation loss: 2.3313724430658485

Epoch: 6| Step: 7
Training loss: 3.1384100914001465
Validation loss: 2.3207495417646182

Epoch: 6| Step: 8
Training loss: 3.2851853370666504
Validation loss: 2.3113797018604894

Epoch: 6| Step: 9
Training loss: 3.3764755725860596
Validation loss: 2.3076967449598413

Epoch: 6| Step: 10
Training loss: 2.3697123527526855
Validation loss: 2.307654324398246

Epoch: 6| Step: 11
Training loss: 2.4385504722595215
Validation loss: 2.30343129557948

Epoch: 6| Step: 12
Training loss: 1.712414264678955
Validation loss: 2.308871699917701

Epoch: 6| Step: 13
Training loss: 2.3334407806396484
Validation loss: 2.33392846199774

Epoch: 170| Step: 0
Training loss: 2.050081729888916
Validation loss: 2.341761037867556

Epoch: 6| Step: 1
Training loss: 3.219494342803955
Validation loss: 2.340839521859282

Epoch: 6| Step: 2
Training loss: 1.7462869882583618
Validation loss: 2.3445653761586835

Epoch: 6| Step: 3
Training loss: 3.2975692749023438
Validation loss: 2.3494641242488736

Epoch: 6| Step: 4
Training loss: 2.6896495819091797
Validation loss: 2.3580751316521757

Epoch: 6| Step: 5
Training loss: 1.8975118398666382
Validation loss: 2.3596993364313597

Epoch: 6| Step: 6
Training loss: 2.694181442260742
Validation loss: 2.3500171066612325

Epoch: 6| Step: 7
Training loss: 2.38806414604187
Validation loss: 2.3596006311396116

Epoch: 6| Step: 8
Training loss: 2.4592981338500977
Validation loss: 2.3592304132317983

Epoch: 6| Step: 9
Training loss: 2.6447200775146484
Validation loss: 2.373951783744238

Epoch: 6| Step: 10
Training loss: 3.0595040321350098
Validation loss: 2.376261918775497

Epoch: 6| Step: 11
Training loss: 2.2360973358154297
Validation loss: 2.386374488953621

Epoch: 6| Step: 12
Training loss: 3.144044876098633
Validation loss: 2.394151528676351

Epoch: 6| Step: 13
Training loss: 1.9655346870422363
Validation loss: 2.381063275439765

Epoch: 171| Step: 0
Training loss: 3.109088897705078
Validation loss: 2.3699382274381575

Epoch: 6| Step: 1
Training loss: 3.4339733123779297
Validation loss: 2.3579497286068496

Epoch: 6| Step: 2
Training loss: 2.0622518062591553
Validation loss: 2.3482327409969863

Epoch: 6| Step: 3
Training loss: 3.3432817459106445
Validation loss: 2.3471978018360753

Epoch: 6| Step: 4
Training loss: 2.5192248821258545
Validation loss: 2.346553241052935

Epoch: 6| Step: 5
Training loss: 1.8531486988067627
Validation loss: 2.340847549899932

Epoch: 6| Step: 6
Training loss: 2.4422764778137207
Validation loss: 2.3453389701022895

Epoch: 6| Step: 7
Training loss: 2.497359037399292
Validation loss: 2.329857828796551

Epoch: 6| Step: 8
Training loss: 2.4649782180786133
Validation loss: 2.330002792419926

Epoch: 6| Step: 9
Training loss: 2.5821990966796875
Validation loss: 2.3263900459453626

Epoch: 6| Step: 10
Training loss: 2.460108757019043
Validation loss: 2.31290530132991

Epoch: 6| Step: 11
Training loss: 2.7883801460266113
Validation loss: 2.3208521642992572

Epoch: 6| Step: 12
Training loss: 1.406903624534607
Validation loss: 2.3227463127464376

Epoch: 6| Step: 13
Training loss: 3.1255033016204834
Validation loss: 2.321243506605907

Epoch: 172| Step: 0
Training loss: 2.439305067062378
Validation loss: 2.3227696931490334

Epoch: 6| Step: 1
Training loss: 1.787369728088379
Validation loss: 2.3330213087861256

Epoch: 6| Step: 2
Training loss: 2.000247001647949
Validation loss: 2.3417141796440206

Epoch: 6| Step: 3
Training loss: 3.459771156311035
Validation loss: 2.3553429085721254

Epoch: 6| Step: 4
Training loss: 3.418842077255249
Validation loss: 2.3476371431863434

Epoch: 6| Step: 5
Training loss: 1.9835553169250488
Validation loss: 2.3538477446443293

Epoch: 6| Step: 6
Training loss: 2.7965903282165527
Validation loss: 2.3487569209068053

Epoch: 6| Step: 7
Training loss: 2.1345865726470947
Validation loss: 2.3430143120468303

Epoch: 6| Step: 8
Training loss: 2.0926380157470703
Validation loss: 2.346259952873312

Epoch: 6| Step: 9
Training loss: 2.168105125427246
Validation loss: 2.336980806883945

Epoch: 6| Step: 10
Training loss: 3.1961188316345215
Validation loss: 2.33489481864437

Epoch: 6| Step: 11
Training loss: 2.2596921920776367
Validation loss: 2.3338934657394246

Epoch: 6| Step: 12
Training loss: 2.879877805709839
Validation loss: 2.3435836017772718

Epoch: 6| Step: 13
Training loss: 3.108771562576294
Validation loss: 2.3525613687371694

Epoch: 173| Step: 0
Training loss: 2.944148063659668
Validation loss: 2.358964417570381

Epoch: 6| Step: 1
Training loss: 2.712653636932373
Validation loss: 2.3589035823781

Epoch: 6| Step: 2
Training loss: 1.8903155326843262
Validation loss: 2.368212451216995

Epoch: 6| Step: 3
Training loss: 1.8486758470535278
Validation loss: 2.3715577125549316

Epoch: 6| Step: 4
Training loss: 2.1663126945495605
Validation loss: 2.3557534269107285

Epoch: 6| Step: 5
Training loss: 2.9674086570739746
Validation loss: 2.3734344564458376

Epoch: 6| Step: 6
Training loss: 1.9001343250274658
Validation loss: 2.3721347265346076

Epoch: 6| Step: 7
Training loss: 3.013957977294922
Validation loss: 2.3658858345400904

Epoch: 6| Step: 8
Training loss: 3.484501361846924
Validation loss: 2.3730190338626986

Epoch: 6| Step: 9
Training loss: 2.5591182708740234
Validation loss: 2.3707071401739634

Epoch: 6| Step: 10
Training loss: 2.390077590942383
Validation loss: 2.366250571384225

Epoch: 6| Step: 11
Training loss: 2.2578282356262207
Validation loss: 2.3641349987317155

Epoch: 6| Step: 12
Training loss: 3.063633441925049
Validation loss: 2.351741806153328

Epoch: 6| Step: 13
Training loss: 2.0432374477386475
Validation loss: 2.3434199440863823

Epoch: 174| Step: 0
Training loss: 2.1388189792633057
Validation loss: 2.333712726510981

Epoch: 6| Step: 1
Training loss: 2.636547088623047
Validation loss: 2.327904306432252

Epoch: 6| Step: 2
Training loss: 3.0895028114318848
Validation loss: 2.322302269679244

Epoch: 6| Step: 3
Training loss: 2.274580478668213
Validation loss: 2.3135225721584853

Epoch: 6| Step: 4
Training loss: 2.1137192249298096
Validation loss: 2.3184172978965183

Epoch: 6| Step: 5
Training loss: 1.9458585977554321
Validation loss: 2.315698551875289

Epoch: 6| Step: 6
Training loss: 2.5617222785949707
Validation loss: 2.328781012565859

Epoch: 6| Step: 7
Training loss: 2.1465325355529785
Validation loss: 2.340158575324602

Epoch: 6| Step: 8
Training loss: 2.908933639526367
Validation loss: 2.345342528435492

Epoch: 6| Step: 9
Training loss: 2.5307226181030273
Validation loss: 2.3505967381179973

Epoch: 6| Step: 10
Training loss: 2.725546360015869
Validation loss: 2.3542332315957673

Epoch: 6| Step: 11
Training loss: 3.4432730674743652
Validation loss: 2.3617751188175653

Epoch: 6| Step: 12
Training loss: 2.95233154296875
Validation loss: 2.357491766252825

Epoch: 6| Step: 13
Training loss: 1.8147618770599365
Validation loss: 2.3702131676417526

Epoch: 175| Step: 0
Training loss: 3.0161004066467285
Validation loss: 2.369599125718558

Epoch: 6| Step: 1
Training loss: 2.875544786453247
Validation loss: 2.3739400397064867

Epoch: 6| Step: 2
Training loss: 1.6607693433761597
Validation loss: 2.3773174824253207

Epoch: 6| Step: 3
Training loss: 2.9997634887695312
Validation loss: 2.375230630238851

Epoch: 6| Step: 4
Training loss: 2.446431875228882
Validation loss: 2.360222888249223

Epoch: 6| Step: 5
Training loss: 1.8863333463668823
Validation loss: 2.3546851527306343

Epoch: 6| Step: 6
Training loss: 2.3169476985931396
Validation loss: 2.3433636824289956

Epoch: 6| Step: 7
Training loss: 2.2988967895507812
Validation loss: 2.3627328718862226

Epoch: 6| Step: 8
Training loss: 1.9333394765853882
Validation loss: 2.351038109871649

Epoch: 6| Step: 9
Training loss: 2.74625825881958
Validation loss: 2.360434934657107

Epoch: 6| Step: 10
Training loss: 2.614227771759033
Validation loss: 2.3513390710276942

Epoch: 6| Step: 11
Training loss: 3.2758355140686035
Validation loss: 2.354268694436678

Epoch: 6| Step: 12
Training loss: 2.7982335090637207
Validation loss: 2.3512252223107124

Epoch: 6| Step: 13
Training loss: 2.3789477348327637
Validation loss: 2.348857828365859

Testing loss: 2.529142072465685
