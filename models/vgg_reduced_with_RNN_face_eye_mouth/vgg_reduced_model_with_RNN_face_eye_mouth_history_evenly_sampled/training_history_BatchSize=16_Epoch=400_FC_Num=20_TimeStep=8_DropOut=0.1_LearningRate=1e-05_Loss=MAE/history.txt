Epoch: 1| Step: 0
Training loss: 5.144887924194336
Validation loss: 5.099997002591369

Epoch: 6| Step: 1
Training loss: 5.607201099395752
Validation loss: 5.086708755903347

Epoch: 6| Step: 2
Training loss: 5.74876594543457
Validation loss: 5.074252195255731

Epoch: 6| Step: 3
Training loss: 3.834632635116577
Validation loss: 5.061451255634267

Epoch: 6| Step: 4
Training loss: 4.896692276000977
Validation loss: 5.048337218581989

Epoch: 6| Step: 5
Training loss: 5.293705940246582
Validation loss: 5.035009389282555

Epoch: 6| Step: 6
Training loss: 3.5630011558532715
Validation loss: 5.020437486710087

Epoch: 6| Step: 7
Training loss: 5.360753536224365
Validation loss: 5.005342637338946

Epoch: 6| Step: 8
Training loss: 4.228797435760498
Validation loss: 4.989972775982272

Epoch: 6| Step: 9
Training loss: 5.742156028747559
Validation loss: 4.9734283672866

Epoch: 6| Step: 10
Training loss: 5.156442642211914
Validation loss: 4.955837680447486

Epoch: 6| Step: 11
Training loss: 4.388672828674316
Validation loss: 4.936935209458874

Epoch: 6| Step: 12
Training loss: 4.94184684753418
Validation loss: 4.916425958756478

Epoch: 6| Step: 13
Training loss: 2.340769052505493
Validation loss: 4.89583634817472

Epoch: 2| Step: 0
Training loss: 5.6754302978515625
Validation loss: 4.873276187527564

Epoch: 6| Step: 1
Training loss: 4.028144836425781
Validation loss: 4.849281413580782

Epoch: 6| Step: 2
Training loss: 4.456225395202637
Validation loss: 4.823294762642153

Epoch: 6| Step: 3
Training loss: 4.146405220031738
Validation loss: 4.796709352923978

Epoch: 6| Step: 4
Training loss: 5.4636735916137695
Validation loss: 4.768334655351536

Epoch: 6| Step: 5
Training loss: 4.110353469848633
Validation loss: 4.7387674854647726

Epoch: 6| Step: 6
Training loss: 4.62775993347168
Validation loss: 4.707609843182308

Epoch: 6| Step: 7
Training loss: 3.974214553833008
Validation loss: 4.676022868002614

Epoch: 6| Step: 8
Training loss: 3.664964437484741
Validation loss: 4.642975658498784

Epoch: 6| Step: 9
Training loss: 4.797999858856201
Validation loss: 4.60996502189226

Epoch: 6| Step: 10
Training loss: 4.268242835998535
Validation loss: 4.575579089503134

Epoch: 6| Step: 11
Training loss: 3.8798093795776367
Validation loss: 4.538609791827458

Epoch: 6| Step: 12
Training loss: 5.079657077789307
Validation loss: 4.502682547415456

Epoch: 6| Step: 13
Training loss: 4.491857051849365
Validation loss: 4.4677580043833744

Epoch: 3| Step: 0
Training loss: 2.7653589248657227
Validation loss: 4.430148211858606

Epoch: 6| Step: 1
Training loss: 4.736484527587891
Validation loss: 4.396915661391391

Epoch: 6| Step: 2
Training loss: 4.533867835998535
Validation loss: 4.361290265155095

Epoch: 6| Step: 3
Training loss: 3.9156246185302734
Validation loss: 4.325463638510755

Epoch: 6| Step: 4
Training loss: 4.7609148025512695
Validation loss: 4.291236549295405

Epoch: 6| Step: 5
Training loss: 4.1103105545043945
Validation loss: 4.25691101115237

Epoch: 6| Step: 6
Training loss: 2.9042539596557617
Validation loss: 4.2245824772824525

Epoch: 6| Step: 7
Training loss: 3.767993927001953
Validation loss: 4.1944446102265385

Epoch: 6| Step: 8
Training loss: 3.9829413890838623
Validation loss: 4.16448208337189

Epoch: 6| Step: 9
Training loss: 3.773360252380371
Validation loss: 4.133632295875139

Epoch: 6| Step: 10
Training loss: 4.928230285644531
Validation loss: 4.103287307165003

Epoch: 6| Step: 11
Training loss: 4.044846057891846
Validation loss: 4.07044102555962

Epoch: 6| Step: 12
Training loss: 4.591787338256836
Validation loss: 4.0380459139423985

Epoch: 6| Step: 13
Training loss: 3.124267578125
Validation loss: 4.006128577775852

Epoch: 4| Step: 0
Training loss: 3.644097328186035
Validation loss: 3.9754029807224067

Epoch: 6| Step: 1
Training loss: 4.420813083648682
Validation loss: 3.947556557193879

Epoch: 6| Step: 2
Training loss: 3.861624240875244
Validation loss: 3.9173156471662622

Epoch: 6| Step: 3
Training loss: 3.6178996562957764
Validation loss: 3.888719251078944

Epoch: 6| Step: 4
Training loss: 3.3661551475524902
Validation loss: 3.8634123956003497

Epoch: 6| Step: 5
Training loss: 4.284285545349121
Validation loss: 3.8369131524075746

Epoch: 6| Step: 6
Training loss: 3.8960859775543213
Validation loss: 3.8120101344200874

Epoch: 6| Step: 7
Training loss: 3.435131311416626
Validation loss: 3.7875436390599897

Epoch: 6| Step: 8
Training loss: 2.9231386184692383
Validation loss: 3.762271596539405

Epoch: 6| Step: 9
Training loss: 4.179174900054932
Validation loss: 3.7438660539606565

Epoch: 6| Step: 10
Training loss: 3.695620059967041
Validation loss: 3.7210467502635014

Epoch: 6| Step: 11
Training loss: 3.6778221130371094
Validation loss: 3.700838781172229

Epoch: 6| Step: 12
Training loss: 3.441924810409546
Validation loss: 3.6835548082987466

Epoch: 6| Step: 13
Training loss: 3.00909161567688
Validation loss: 3.663971362575408

Epoch: 5| Step: 0
Training loss: 4.855990409851074
Validation loss: 3.647015622867051

Epoch: 6| Step: 1
Training loss: 2.9905343055725098
Validation loss: 3.6306312750744563

Epoch: 6| Step: 2
Training loss: 2.8176634311676025
Validation loss: 3.613806773257512

Epoch: 6| Step: 3
Training loss: 2.247201919555664
Validation loss: 3.5966296119074666

Epoch: 6| Step: 4
Training loss: 4.888004302978516
Validation loss: 3.5801396908298617

Epoch: 6| Step: 5
Training loss: 3.802051544189453
Validation loss: 3.5689534012989332

Epoch: 6| Step: 6
Training loss: 3.091458320617676
Validation loss: 3.5531007577014226

Epoch: 6| Step: 7
Training loss: 2.860403299331665
Validation loss: 3.546157749750281

Epoch: 6| Step: 8
Training loss: 3.052700996398926
Validation loss: 3.535483052653651

Epoch: 6| Step: 9
Training loss: 4.202717304229736
Validation loss: 3.5257088702212096

Epoch: 6| Step: 10
Training loss: 3.4896719455718994
Validation loss: 3.5136101015152468

Epoch: 6| Step: 11
Training loss: 3.052154541015625
Validation loss: 3.508394472060665

Epoch: 6| Step: 12
Training loss: 4.391990661621094
Validation loss: 3.5031643221455235

Epoch: 6| Step: 13
Training loss: 2.6906051635742188
Validation loss: 3.4974794028907694

Epoch: 6| Step: 0
Training loss: 3.2578728199005127
Validation loss: 3.483661743902391

Epoch: 6| Step: 1
Training loss: 4.232143878936768
Validation loss: 3.472980014739498

Epoch: 6| Step: 2
Training loss: 3.366401433944702
Validation loss: 3.4609690737980667

Epoch: 6| Step: 3
Training loss: 3.1038496494293213
Validation loss: 3.456739943514588

Epoch: 6| Step: 4
Training loss: 3.3606927394866943
Validation loss: 3.449796207489506

Epoch: 6| Step: 5
Training loss: 3.7290258407592773
Validation loss: 3.4383675770093034

Epoch: 6| Step: 6
Training loss: 2.0212979316711426
Validation loss: 3.4321352897151822

Epoch: 6| Step: 7
Training loss: 4.288764953613281
Validation loss: 3.4264430179390857

Epoch: 6| Step: 8
Training loss: 2.789856433868408
Validation loss: 3.4213170261793238

Epoch: 6| Step: 9
Training loss: 4.012801170349121
Validation loss: 3.414667724281229

Epoch: 6| Step: 10
Training loss: 2.5079994201660156
Validation loss: 3.4072337894029516

Epoch: 6| Step: 11
Training loss: 3.4167966842651367
Validation loss: 3.4041398186837473

Epoch: 6| Step: 12
Training loss: 3.796200752258301
Validation loss: 3.400714874267578

Epoch: 6| Step: 13
Training loss: 3.4909615516662598
Validation loss: 3.395885862329955

Epoch: 7| Step: 0
Training loss: 3.429337501525879
Validation loss: 3.391209392137425

Epoch: 6| Step: 1
Training loss: 3.400665760040283
Validation loss: 3.384540327133671

Epoch: 6| Step: 2
Training loss: 3.0177693367004395
Validation loss: 3.3792736914850052

Epoch: 6| Step: 3
Training loss: 2.645390272140503
Validation loss: 3.373748069168419

Epoch: 6| Step: 4
Training loss: 2.7654991149902344
Validation loss: 3.3677535544159594

Epoch: 6| Step: 5
Training loss: 3.485714912414551
Validation loss: 3.3624708242313837

Epoch: 6| Step: 6
Training loss: 2.7067322731018066
Validation loss: 3.358126119900775

Epoch: 6| Step: 7
Training loss: 3.4093616008758545
Validation loss: 3.3532227880211285

Epoch: 6| Step: 8
Training loss: 3.4762747287750244
Validation loss: 3.3482340817810385

Epoch: 6| Step: 9
Training loss: 4.325543403625488
Validation loss: 3.3420191657158638

Epoch: 6| Step: 10
Training loss: 3.6398813724517822
Validation loss: 3.337635488920314

Epoch: 6| Step: 11
Training loss: 3.3501975536346436
Validation loss: 3.3336936889156217

Epoch: 6| Step: 12
Training loss: 3.164128065109253
Validation loss: 3.328662431368264

Epoch: 6| Step: 13
Training loss: 3.9115660190582275
Validation loss: 3.3254254966653805

Epoch: 8| Step: 0
Training loss: 2.8678529262542725
Validation loss: 3.3185481307327107

Epoch: 6| Step: 1
Training loss: 3.373384475708008
Validation loss: 3.3143813815168155

Epoch: 6| Step: 2
Training loss: 2.9383058547973633
Validation loss: 3.3090460300445557

Epoch: 6| Step: 3
Training loss: 4.221757411956787
Validation loss: 3.305176514451222

Epoch: 6| Step: 4
Training loss: 3.1169350147247314
Validation loss: 3.299863253870318

Epoch: 6| Step: 5
Training loss: 2.9292774200439453
Validation loss: 3.2974594946830504

Epoch: 6| Step: 6
Training loss: 3.597576141357422
Validation loss: 3.2927498279079312

Epoch: 6| Step: 7
Training loss: 2.623978614807129
Validation loss: 3.2864853951238815

Epoch: 6| Step: 8
Training loss: 3.7645533084869385
Validation loss: 3.2817950351263887

Epoch: 6| Step: 9
Training loss: 3.2697243690490723
Validation loss: 3.276412615212061

Epoch: 6| Step: 10
Training loss: 4.004085540771484
Validation loss: 3.2750040843922603

Epoch: 6| Step: 11
Training loss: 1.9334304332733154
Validation loss: 3.270478884379069

Epoch: 6| Step: 12
Training loss: 3.6399855613708496
Validation loss: 3.2664880521835817

Epoch: 6| Step: 13
Training loss: 3.539689302444458
Validation loss: 3.2616370775366343

Epoch: 9| Step: 0
Training loss: 4.662800312042236
Validation loss: 3.258550282447569

Epoch: 6| Step: 1
Training loss: 3.030527353286743
Validation loss: 3.253702222660024

Epoch: 6| Step: 2
Training loss: 2.7522666454315186
Validation loss: 3.2505317682861

Epoch: 6| Step: 3
Training loss: 3.1766529083251953
Validation loss: 3.2457235500376713

Epoch: 6| Step: 4
Training loss: 3.171928882598877
Validation loss: 3.243601199119322

Epoch: 6| Step: 5
Training loss: 2.162071704864502
Validation loss: 3.2410243941891577

Epoch: 6| Step: 6
Training loss: 3.3301877975463867
Validation loss: 3.2375378865067677

Epoch: 6| Step: 7
Training loss: 3.2710587978363037
Validation loss: 3.234661004876578

Epoch: 6| Step: 8
Training loss: 3.7798221111297607
Validation loss: 3.231899151238062

Epoch: 6| Step: 9
Training loss: 4.410154342651367
Validation loss: 3.2238499297890613

Epoch: 6| Step: 10
Training loss: 2.8298377990722656
Validation loss: 3.222238027921287

Epoch: 6| Step: 11
Training loss: 3.343316078186035
Validation loss: 3.216010562835201

Epoch: 6| Step: 12
Training loss: 2.5374937057495117
Validation loss: 3.2142151376252532

Epoch: 6| Step: 13
Training loss: 2.1396262645721436
Validation loss: 3.208902533336352

Epoch: 10| Step: 0
Training loss: 2.783067464828491
Validation loss: 3.2075741419228176

Epoch: 6| Step: 1
Training loss: 2.8848743438720703
Validation loss: 3.2052027820259013

Epoch: 6| Step: 2
Training loss: 1.6468199491500854
Validation loss: 3.201295865479336

Epoch: 6| Step: 3
Training loss: 3.6600496768951416
Validation loss: 3.1985283231222503

Epoch: 6| Step: 4
Training loss: 3.9230964183807373
Validation loss: 3.195417234974523

Epoch: 6| Step: 5
Training loss: 2.4140877723693848
Validation loss: 3.1922005812327066

Epoch: 6| Step: 6
Training loss: 3.705876111984253
Validation loss: 3.1872600688729236

Epoch: 6| Step: 7
Training loss: 3.5198047161102295
Validation loss: 3.1839782140588246

Epoch: 6| Step: 8
Training loss: 3.155846118927002
Validation loss: 3.1812131738149994

Epoch: 6| Step: 9
Training loss: 3.7583327293395996
Validation loss: 3.177487575879661

Epoch: 6| Step: 10
Training loss: 4.0531086921691895
Validation loss: 3.1752457003439627

Epoch: 6| Step: 11
Training loss: 2.973710536956787
Validation loss: 3.17222003270221

Epoch: 6| Step: 12
Training loss: 2.9999442100524902
Validation loss: 3.16915956107519

Epoch: 6| Step: 13
Training loss: 3.162369728088379
Validation loss: 3.167012458206505

Epoch: 11| Step: 0
Training loss: 3.6247501373291016
Validation loss: 3.164411634527227

Epoch: 6| Step: 1
Training loss: 3.3690977096557617
Validation loss: 3.1632713963908534

Epoch: 6| Step: 2
Training loss: 2.832676410675049
Validation loss: 3.163149731133574

Epoch: 6| Step: 3
Training loss: 2.2499117851257324
Validation loss: 3.1559819098441833

Epoch: 6| Step: 4
Training loss: 2.958367347717285
Validation loss: 3.1517427557258197

Epoch: 6| Step: 5
Training loss: 4.292716979980469
Validation loss: 3.1465447513006066

Epoch: 6| Step: 6
Training loss: 2.813741683959961
Validation loss: 3.1462693188780095

Epoch: 6| Step: 7
Training loss: 3.3782687187194824
Validation loss: 3.142318738404141

Epoch: 6| Step: 8
Training loss: 4.098596096038818
Validation loss: 3.1385034181738414

Epoch: 6| Step: 9
Training loss: 2.538036823272705
Validation loss: 3.13473710449793

Epoch: 6| Step: 10
Training loss: 2.9491024017333984
Validation loss: 3.134006010588779

Epoch: 6| Step: 11
Training loss: 2.1589887142181396
Validation loss: 3.1274188795397357

Epoch: 6| Step: 12
Training loss: 3.435250997543335
Validation loss: 3.124595944599439

Epoch: 6| Step: 13
Training loss: 3.824904203414917
Validation loss: 3.1218502854788177

Epoch: 12| Step: 0
Training loss: 3.2294230461120605
Validation loss: 3.121084154293101

Epoch: 6| Step: 1
Training loss: 4.617714881896973
Validation loss: 3.1171540342351443

Epoch: 6| Step: 2
Training loss: 2.498260498046875
Validation loss: 3.116122781589467

Epoch: 6| Step: 3
Training loss: 3.8022358417510986
Validation loss: 3.111594569298529

Epoch: 6| Step: 4
Training loss: 3.5597548484802246
Validation loss: 3.108503326292961

Epoch: 6| Step: 5
Training loss: 2.0547423362731934
Validation loss: 3.1065318212714246

Epoch: 6| Step: 6
Training loss: 2.1054224967956543
Validation loss: 3.1068646061804985

Epoch: 6| Step: 7
Training loss: 3.681196928024292
Validation loss: 3.1184519695979294

Epoch: 6| Step: 8
Training loss: 3.6746392250061035
Validation loss: 3.103339933579968

Epoch: 6| Step: 9
Training loss: 3.4905848503112793
Validation loss: 3.097862289797875

Epoch: 6| Step: 10
Training loss: 3.4076528549194336
Validation loss: 3.096127881798693

Epoch: 6| Step: 11
Training loss: 2.5026731491088867
Validation loss: 3.0953039635894117

Epoch: 6| Step: 12
Training loss: 2.5811281204223633
Validation loss: 3.0926439941570325

Epoch: 6| Step: 13
Training loss: 2.281940221786499
Validation loss: 3.0911288543414046

Epoch: 13| Step: 0
Training loss: 2.4389588832855225
Validation loss: 3.0904310082876556

Epoch: 6| Step: 1
Training loss: 3.1000418663024902
Validation loss: 3.087673005237374

Epoch: 6| Step: 2
Training loss: 3.1754255294799805
Validation loss: 3.0834649326980754

Epoch: 6| Step: 3
Training loss: 3.402761220932007
Validation loss: 3.0788748187403523

Epoch: 6| Step: 4
Training loss: 3.1426992416381836
Validation loss: 3.0776935315901235

Epoch: 6| Step: 5
Training loss: 2.8180530071258545
Validation loss: 3.077392908834642

Epoch: 6| Step: 6
Training loss: 2.066124200820923
Validation loss: 3.077844924824212

Epoch: 6| Step: 7
Training loss: 3.155068874359131
Validation loss: 3.0823875601573656

Epoch: 6| Step: 8
Training loss: 3.244297504425049
Validation loss: 3.0773385263258413

Epoch: 6| Step: 9
Training loss: 2.4492998123168945
Validation loss: 3.0705086620905067

Epoch: 6| Step: 10
Training loss: 3.3644230365753174
Validation loss: 3.0669196395463842

Epoch: 6| Step: 11
Training loss: 3.9334375858306885
Validation loss: 3.0654331868694675

Epoch: 6| Step: 12
Training loss: 3.779360055923462
Validation loss: 3.0653777660862094

Epoch: 6| Step: 13
Training loss: 3.8526010513305664
Validation loss: 3.0640050852170555

Epoch: 14| Step: 0
Training loss: 2.573066234588623
Validation loss: 3.0628785138489096

Epoch: 6| Step: 1
Training loss: 2.883945941925049
Validation loss: 3.06573555033694

Epoch: 6| Step: 2
Training loss: 3.310664653778076
Validation loss: 3.0650618896689465

Epoch: 6| Step: 3
Training loss: 1.8935030698776245
Validation loss: 3.061790194562686

Epoch: 6| Step: 4
Training loss: 3.8452911376953125
Validation loss: 3.058965080527849

Epoch: 6| Step: 5
Training loss: 2.3059730529785156
Validation loss: 3.0524728272550847

Epoch: 6| Step: 6
Training loss: 3.4474406242370605
Validation loss: 3.0480874840931227

Epoch: 6| Step: 7
Training loss: 2.9444751739501953
Validation loss: 3.046953829385901

Epoch: 6| Step: 8
Training loss: 2.6388838291168213
Validation loss: 3.045644860113821

Epoch: 6| Step: 9
Training loss: 3.854825973510742
Validation loss: 3.0451187062007126

Epoch: 6| Step: 10
Training loss: 3.607042074203491
Validation loss: 3.046884275251819

Epoch: 6| Step: 11
Training loss: 3.1789557933807373
Validation loss: 3.049983432216029

Epoch: 6| Step: 12
Training loss: 3.7360572814941406
Validation loss: 3.0471199199717534

Epoch: 6| Step: 13
Training loss: 3.1772189140319824
Validation loss: 3.0348310265489804

Epoch: 15| Step: 0
Training loss: 3.2147669792175293
Validation loss: 3.030764182408651

Epoch: 6| Step: 1
Training loss: 2.3226141929626465
Validation loss: 3.0288124494655158

Epoch: 6| Step: 2
Training loss: 2.890552043914795
Validation loss: 3.028903789417718

Epoch: 6| Step: 3
Training loss: 2.1571366786956787
Validation loss: 3.027952435196087

Epoch: 6| Step: 4
Training loss: 3.0619728565216064
Validation loss: 3.024262628247661

Epoch: 6| Step: 5
Training loss: 2.9036946296691895
Validation loss: 3.025291617198657

Epoch: 6| Step: 6
Training loss: 3.613123655319214
Validation loss: 3.0205062794429

Epoch: 6| Step: 7
Training loss: 2.594862461090088
Validation loss: 3.014678406459029

Epoch: 6| Step: 8
Training loss: 3.0952372550964355
Validation loss: 3.012314622120191

Epoch: 6| Step: 9
Training loss: 3.3231682777404785
Validation loss: 3.007294824046473

Epoch: 6| Step: 10
Training loss: 3.145447254180908
Validation loss: 3.0056114888960317

Epoch: 6| Step: 11
Training loss: 4.04853630065918
Validation loss: 3.0020475797755743

Epoch: 6| Step: 12
Training loss: 3.3216726779937744
Validation loss: 3.001021387756512

Epoch: 6| Step: 13
Training loss: 3.606997489929199
Validation loss: 2.999028087944113

Epoch: 16| Step: 0
Training loss: 2.932036876678467
Validation loss: 2.994484591227706

Epoch: 6| Step: 1
Training loss: 3.701206684112549
Validation loss: 2.99064439599232

Epoch: 6| Step: 2
Training loss: 2.9670095443725586
Validation loss: 2.989237093156384

Epoch: 6| Step: 3
Training loss: 2.7918901443481445
Validation loss: 2.9884995491273942

Epoch: 6| Step: 4
Training loss: 3.163382053375244
Validation loss: 2.9865417531741563

Epoch: 6| Step: 5
Training loss: 2.7169313430786133
Validation loss: 2.9846721310769357

Epoch: 6| Step: 6
Training loss: 3.011840343475342
Validation loss: 2.9841890360719416

Epoch: 6| Step: 7
Training loss: 2.5272133350372314
Validation loss: 2.978999242987684

Epoch: 6| Step: 8
Training loss: 3.2179367542266846
Validation loss: 2.9789905676277737

Epoch: 6| Step: 9
Training loss: 3.3296568393707275
Validation loss: 2.977039921668268

Epoch: 6| Step: 10
Training loss: 3.3681793212890625
Validation loss: 2.9762497255879063

Epoch: 6| Step: 11
Training loss: 2.4753503799438477
Validation loss: 2.9761068949135403

Epoch: 6| Step: 12
Training loss: 2.8664731979370117
Validation loss: 2.9756447679253033

Epoch: 6| Step: 13
Training loss: 4.217526912689209
Validation loss: 2.9763340129647204

Epoch: 17| Step: 0
Training loss: 3.129535675048828
Validation loss: 2.975321969678325

Epoch: 6| Step: 1
Training loss: 3.218320608139038
Validation loss: 2.9732955604471187

Epoch: 6| Step: 2
Training loss: 3.5409231185913086
Validation loss: 2.9699444924631426

Epoch: 6| Step: 3
Training loss: 2.4991793632507324
Validation loss: 2.967599335537162

Epoch: 6| Step: 4
Training loss: 2.723623275756836
Validation loss: 2.965942129012077

Epoch: 6| Step: 5
Training loss: 3.7095744609832764
Validation loss: 2.9661032179350495

Epoch: 6| Step: 6
Training loss: 4.141032695770264
Validation loss: 2.9620455336827103

Epoch: 6| Step: 7
Training loss: 2.9692792892456055
Validation loss: 2.959970546025102

Epoch: 6| Step: 8
Training loss: 2.4580321311950684
Validation loss: 2.959530238182314

Epoch: 6| Step: 9
Training loss: 3.5198488235473633
Validation loss: 2.9570573811889975

Epoch: 6| Step: 10
Training loss: 2.7181501388549805
Validation loss: 2.9553091013303368

Epoch: 6| Step: 11
Training loss: 2.4672341346740723
Validation loss: 2.953272347809166

Epoch: 6| Step: 12
Training loss: 2.206878185272217
Validation loss: 2.9516721438336115

Epoch: 6| Step: 13
Training loss: 3.49300217628479
Validation loss: 2.9493387693999917

Epoch: 18| Step: 0
Training loss: 3.219233751296997
Validation loss: 2.9475099655889694

Epoch: 6| Step: 1
Training loss: 2.973346710205078
Validation loss: 2.944989676116615

Epoch: 6| Step: 2
Training loss: 3.184746026992798
Validation loss: 2.941905718977733

Epoch: 6| Step: 3
Training loss: 2.9774022102355957
Validation loss: 2.9349552431414203

Epoch: 6| Step: 4
Training loss: 3.2384514808654785
Validation loss: 2.9339307943979898

Epoch: 6| Step: 5
Training loss: 3.9742989540100098
Validation loss: 2.930667318323607

Epoch: 6| Step: 6
Training loss: 2.4813318252563477
Validation loss: 2.9238435376075005

Epoch: 6| Step: 7
Training loss: 3.678157329559326
Validation loss: 2.922372935920633

Epoch: 6| Step: 8
Training loss: 2.380932331085205
Validation loss: 2.9213711420694985

Epoch: 6| Step: 9
Training loss: 2.815458297729492
Validation loss: 2.9203596474021993

Epoch: 6| Step: 10
Training loss: 2.40828013420105
Validation loss: 2.9193060321192585

Epoch: 6| Step: 11
Training loss: 2.9671738147735596
Validation loss: 2.9209960147898686

Epoch: 6| Step: 12
Training loss: 3.0646870136260986
Validation loss: 2.9194547027669926

Epoch: 6| Step: 13
Training loss: 2.792581796646118
Validation loss: 2.915595377645185

Epoch: 19| Step: 0
Training loss: 2.822883367538452
Validation loss: 2.9150210606154574

Epoch: 6| Step: 1
Training loss: 3.1855812072753906
Validation loss: 2.909443983467676

Epoch: 6| Step: 2
Training loss: 2.479106903076172
Validation loss: 2.9042649115285566

Epoch: 6| Step: 3
Training loss: 2.7112579345703125
Validation loss: 2.9045903554526706

Epoch: 6| Step: 4
Training loss: 3.455615520477295
Validation loss: 2.9009229085778676

Epoch: 6| Step: 5
Training loss: 3.693112373352051
Validation loss: 2.8998430211056947

Epoch: 6| Step: 6
Training loss: 2.9653873443603516
Validation loss: 2.903211339827507

Epoch: 6| Step: 7
Training loss: 1.7593843936920166
Validation loss: 2.9152944857074368

Epoch: 6| Step: 8
Training loss: 3.08773136138916
Validation loss: 2.9321944534137683

Epoch: 6| Step: 9
Training loss: 3.2367541790008545
Validation loss: 2.9008664879747617

Epoch: 6| Step: 10
Training loss: 3.716710090637207
Validation loss: 2.895495737752607

Epoch: 6| Step: 11
Training loss: 3.2112221717834473
Validation loss: 2.8977141277764433

Epoch: 6| Step: 12
Training loss: 2.9764208793640137
Validation loss: 2.913771306314776

Epoch: 6| Step: 13
Training loss: 2.465796947479248
Validation loss: 2.925201444215672

Epoch: 20| Step: 0
Training loss: 2.7847695350646973
Validation loss: 2.929287936097832

Epoch: 6| Step: 1
Training loss: 2.979607105255127
Validation loss: 2.9007145409942954

Epoch: 6| Step: 2
Training loss: 2.6229963302612305
Validation loss: 2.8901899219841085

Epoch: 6| Step: 3
Training loss: 3.1325430870056152
Validation loss: 2.8937760783780004

Epoch: 6| Step: 4
Training loss: 3.1801905632019043
Validation loss: 2.8956807095517396

Epoch: 6| Step: 5
Training loss: 2.5563035011291504
Validation loss: 2.8982910545923377

Epoch: 6| Step: 6
Training loss: 3.5730772018432617
Validation loss: 2.897951187626008

Epoch: 6| Step: 7
Training loss: 2.993842601776123
Validation loss: 2.9000277109043573

Epoch: 6| Step: 8
Training loss: 3.4983062744140625
Validation loss: 2.9029850370140484

Epoch: 6| Step: 9
Training loss: 2.7354657649993896
Validation loss: 2.8979263562028126

Epoch: 6| Step: 10
Training loss: 2.871656894683838
Validation loss: 2.8896484067363124

Epoch: 6| Step: 11
Training loss: 3.5848708152770996
Validation loss: 2.8888239322170133

Epoch: 6| Step: 12
Training loss: 1.9081593751907349
Validation loss: 2.8850103296259397

Epoch: 6| Step: 13
Training loss: 4.010807514190674
Validation loss: 2.88171878937752

Epoch: 21| Step: 0
Training loss: 3.2813289165496826
Validation loss: 2.8821405749167166

Epoch: 6| Step: 1
Training loss: 2.763429880142212
Validation loss: 2.8787709102835706

Epoch: 6| Step: 2
Training loss: 3.032238006591797
Validation loss: 2.878222844933951

Epoch: 6| Step: 3
Training loss: 2.8908729553222656
Validation loss: 2.8765971352977138

Epoch: 6| Step: 4
Training loss: 3.031979560852051
Validation loss: 2.8769586983547417

Epoch: 6| Step: 5
Training loss: 3.4623889923095703
Validation loss: 2.8815168462773806

Epoch: 6| Step: 6
Training loss: 2.884725570678711
Validation loss: 2.878937869943598

Epoch: 6| Step: 7
Training loss: 2.668881893157959
Validation loss: 2.8754654366482972

Epoch: 6| Step: 8
Training loss: 2.5654795169830322
Validation loss: 2.8732975093267297

Epoch: 6| Step: 9
Training loss: 3.0464437007904053
Validation loss: 2.8700279651149625

Epoch: 6| Step: 10
Training loss: 2.827421188354492
Validation loss: 2.8680243851036153

Epoch: 6| Step: 11
Training loss: 2.9778733253479004
Validation loss: 2.8601042121969242

Epoch: 6| Step: 12
Training loss: 3.338484764099121
Validation loss: 2.8569972156196513

Epoch: 6| Step: 13
Training loss: 2.8204028606414795
Validation loss: 2.8536324859947286

Epoch: 22| Step: 0
Training loss: 2.8173346519470215
Validation loss: 2.8539121022788425

Epoch: 6| Step: 1
Training loss: 3.1290972232818604
Validation loss: 2.850573206460604

Epoch: 6| Step: 2
Training loss: 2.5310349464416504
Validation loss: 2.859676394411313

Epoch: 6| Step: 3
Training loss: 3.195232391357422
Validation loss: 2.916611304847143

Epoch: 6| Step: 4
Training loss: 2.711571216583252
Validation loss: 2.9263094932802263

Epoch: 6| Step: 5
Training loss: 2.2738709449768066
Validation loss: 2.925189692486999

Epoch: 6| Step: 6
Training loss: 3.0926036834716797
Validation loss: 2.9270741093543267

Epoch: 6| Step: 7
Training loss: 2.8727035522460938
Validation loss: 2.9274114024254585

Epoch: 6| Step: 8
Training loss: 3.724083662033081
Validation loss: 2.920962869480092

Epoch: 6| Step: 9
Training loss: 2.627826690673828
Validation loss: 2.922320847870201

Epoch: 6| Step: 10
Training loss: 2.4419164657592773
Validation loss: 2.933180416783979

Epoch: 6| Step: 11
Training loss: 3.651578426361084
Validation loss: 2.938554422829741

Epoch: 6| Step: 12
Training loss: 3.8118224143981934
Validation loss: 2.920362505861508

Epoch: 6| Step: 13
Training loss: 3.411229372024536
Validation loss: 2.9354282963660454

Epoch: 23| Step: 0
Training loss: 3.9543728828430176
Validation loss: 2.950705566713887

Epoch: 6| Step: 1
Training loss: 3.8165199756622314
Validation loss: 2.953389972768804

Epoch: 6| Step: 2
Training loss: 2.4988033771514893
Validation loss: 2.958597198609383

Epoch: 6| Step: 3
Training loss: 3.336153268814087
Validation loss: 2.9585823397482596

Epoch: 6| Step: 4
Training loss: 2.3857431411743164
Validation loss: 2.9729363482485534

Epoch: 6| Step: 5
Training loss: 3.059457778930664
Validation loss: 3.0121619496294247

Epoch: 6| Step: 6
Training loss: 2.3640949726104736
Validation loss: 2.9650680788101687

Epoch: 6| Step: 7
Training loss: 3.4735159873962402
Validation loss: 2.937945450505903

Epoch: 6| Step: 8
Training loss: 3.7849578857421875
Validation loss: 2.9276504414055937

Epoch: 6| Step: 9
Training loss: 1.8303635120391846
Validation loss: 2.9169682200236986

Epoch: 6| Step: 10
Training loss: 3.1939878463745117
Validation loss: 2.919123672669934

Epoch: 6| Step: 11
Training loss: 2.60384202003479
Validation loss: 2.9086434866792414

Epoch: 6| Step: 12
Training loss: 3.4535465240478516
Validation loss: 2.8873401277808735

Epoch: 6| Step: 13
Training loss: 2.2042295932769775
Validation loss: 2.8465983508735575

Epoch: 24| Step: 0
Training loss: 2.948162078857422
Validation loss: 2.841227385305589

Epoch: 6| Step: 1
Training loss: 2.934420585632324
Validation loss: 2.8447256242075274

Epoch: 6| Step: 2
Training loss: 2.6856436729431152
Validation loss: 2.8472113634950373

Epoch: 6| Step: 3
Training loss: 2.527627944946289
Validation loss: 2.8461161531427854

Epoch: 6| Step: 4
Training loss: 2.967916488647461
Validation loss: 2.8417627452522196

Epoch: 6| Step: 5
Training loss: 3.2593743801116943
Validation loss: 2.8359889932858047

Epoch: 6| Step: 6
Training loss: 2.7771639823913574
Validation loss: 2.8254086432918424

Epoch: 6| Step: 7
Training loss: 3.5045742988586426
Validation loss: 2.820490465369276

Epoch: 6| Step: 8
Training loss: 1.7724100351333618
Validation loss: 2.8177456599409862

Epoch: 6| Step: 9
Training loss: 2.9617204666137695
Validation loss: 2.8110032927605415

Epoch: 6| Step: 10
Training loss: 3.960296630859375
Validation loss: 2.8096132098987536

Epoch: 6| Step: 11
Training loss: 2.8670709133148193
Validation loss: 2.806081412940897

Epoch: 6| Step: 12
Training loss: 2.7763428688049316
Validation loss: 2.807529411008281

Epoch: 6| Step: 13
Training loss: 3.639943838119507
Validation loss: 2.807836865866056

Epoch: 25| Step: 0
Training loss: 2.842122793197632
Validation loss: 2.7976097137697282

Epoch: 6| Step: 1
Training loss: 2.1271724700927734
Validation loss: 2.791684530114615

Epoch: 6| Step: 2
Training loss: 3.380610466003418
Validation loss: 2.7936546264156217

Epoch: 6| Step: 3
Training loss: 3.0680222511291504
Validation loss: 2.795831711061539

Epoch: 6| Step: 4
Training loss: 2.951530694961548
Validation loss: 2.7981397900530087

Epoch: 6| Step: 5
Training loss: 2.990978240966797
Validation loss: 2.7922231638303368

Epoch: 6| Step: 6
Training loss: 2.6193959712982178
Validation loss: 2.791419823964437

Epoch: 6| Step: 7
Training loss: 3.599649429321289
Validation loss: 2.790323475355743

Epoch: 6| Step: 8
Training loss: 3.4687113761901855
Validation loss: 2.7892891309594594

Epoch: 6| Step: 9
Training loss: 2.9134578704833984
Validation loss: 2.788564912734493

Epoch: 6| Step: 10
Training loss: 3.024806022644043
Validation loss: 2.785130254683956

Epoch: 6| Step: 11
Training loss: 2.3117122650146484
Validation loss: 2.7834688284063853

Epoch: 6| Step: 12
Training loss: 2.5660512447357178
Validation loss: 2.7826360092368176

Epoch: 6| Step: 13
Training loss: 3.1883277893066406
Validation loss: 2.780238530969107

Epoch: 26| Step: 0
Training loss: 4.181955337524414
Validation loss: 2.783915847860357

Epoch: 6| Step: 1
Training loss: 2.588050603866577
Validation loss: 2.7802049498404227

Epoch: 6| Step: 2
Training loss: 3.001614809036255
Validation loss: 2.7848557528629097

Epoch: 6| Step: 3
Training loss: 2.875810384750366
Validation loss: 2.78195010974843

Epoch: 6| Step: 4
Training loss: 3.4506020545959473
Validation loss: 2.7831612710029847

Epoch: 6| Step: 5
Training loss: 2.495727777481079
Validation loss: 2.7823330074228267

Epoch: 6| Step: 6
Training loss: 2.6776490211486816
Validation loss: 2.782111539635607

Epoch: 6| Step: 7
Training loss: 2.011460781097412
Validation loss: 2.7801908549442085

Epoch: 6| Step: 8
Training loss: 3.049880266189575
Validation loss: 2.7754640015222694

Epoch: 6| Step: 9
Training loss: 3.137019157409668
Validation loss: 2.7809055287350892

Epoch: 6| Step: 10
Training loss: 2.6292760372161865
Validation loss: 2.779225282771613

Epoch: 6| Step: 11
Training loss: 2.6144638061523438
Validation loss: 2.777569140157392

Epoch: 6| Step: 12
Training loss: 3.219989061355591
Validation loss: 2.780561290761476

Epoch: 6| Step: 13
Training loss: 2.8849122524261475
Validation loss: 2.781469473274805

Epoch: 27| Step: 0
Training loss: 3.532695770263672
Validation loss: 2.7747950810258106

Epoch: 6| Step: 1
Training loss: 3.293616771697998
Validation loss: 2.770611862982473

Epoch: 6| Step: 2
Training loss: 2.6299901008605957
Validation loss: 2.774527439507105

Epoch: 6| Step: 3
Training loss: 2.8256378173828125
Validation loss: 2.7699167010604695

Epoch: 6| Step: 4
Training loss: 2.7041826248168945
Validation loss: 2.7764497880012757

Epoch: 6| Step: 5
Training loss: 3.1855716705322266
Validation loss: 2.7801874324839604

Epoch: 6| Step: 6
Training loss: 3.2942323684692383
Validation loss: 2.811129154697541

Epoch: 6| Step: 7
Training loss: 3.492133378982544
Validation loss: 2.789192025379468

Epoch: 6| Step: 8
Training loss: 2.648460865020752
Validation loss: 2.7727933083811114

Epoch: 6| Step: 9
Training loss: 2.6905384063720703
Validation loss: 2.772064483293923

Epoch: 6| Step: 10
Training loss: 2.6367735862731934
Validation loss: 2.771760840569773

Epoch: 6| Step: 11
Training loss: 2.8785791397094727
Validation loss: 2.7728805336900937

Epoch: 6| Step: 12
Training loss: 2.2561721801757812
Validation loss: 2.7741227662691506

Epoch: 6| Step: 13
Training loss: 2.561739444732666
Validation loss: 2.7780521864532144

Epoch: 28| Step: 0
Training loss: 2.5391831398010254
Validation loss: 2.7846168548830095

Epoch: 6| Step: 1
Training loss: 3.0062177181243896
Validation loss: 2.7874544653841244

Epoch: 6| Step: 2
Training loss: 3.4758129119873047
Validation loss: 2.786638839270479

Epoch: 6| Step: 3
Training loss: 3.172980308532715
Validation loss: 2.782038814278059

Epoch: 6| Step: 4
Training loss: 3.146669864654541
Validation loss: 2.7807306012799664

Epoch: 6| Step: 5
Training loss: 2.701197624206543
Validation loss: 2.7750348749981133

Epoch: 6| Step: 6
Training loss: 3.0869340896606445
Validation loss: 2.7709481075245845

Epoch: 6| Step: 7
Training loss: 2.4779131412506104
Validation loss: 2.769376926524665

Epoch: 6| Step: 8
Training loss: 3.563446044921875
Validation loss: 2.767319740787629

Epoch: 6| Step: 9
Training loss: 2.183931827545166
Validation loss: 2.7634392246123283

Epoch: 6| Step: 10
Training loss: 3.246265172958374
Validation loss: 2.762963423164942

Epoch: 6| Step: 11
Training loss: 2.7372488975524902
Validation loss: 2.7627848630310385

Epoch: 6| Step: 12
Training loss: 3.1078286170959473
Validation loss: 2.7628651767648678

Epoch: 6| Step: 13
Training loss: 2.010206937789917
Validation loss: 2.7625828096943517

Epoch: 29| Step: 0
Training loss: 2.4337449073791504
Validation loss: 2.7620719248248684

Epoch: 6| Step: 1
Training loss: 2.2928483486175537
Validation loss: 2.7627278322814615

Epoch: 6| Step: 2
Training loss: 2.676220417022705
Validation loss: 2.7651185040832846

Epoch: 6| Step: 3
Training loss: 2.8190903663635254
Validation loss: 2.7593592905229136

Epoch: 6| Step: 4
Training loss: 2.4107348918914795
Validation loss: 2.767609924398443

Epoch: 6| Step: 5
Training loss: 2.921069622039795
Validation loss: 2.7631649714644237

Epoch: 6| Step: 6
Training loss: 2.5886125564575195
Validation loss: 2.7674223171767367

Epoch: 6| Step: 7
Training loss: 3.396268367767334
Validation loss: 2.7658939079571794

Epoch: 6| Step: 8
Training loss: 3.1749472618103027
Validation loss: 2.7692715173126548

Epoch: 6| Step: 9
Training loss: 3.509274959564209
Validation loss: 2.7683712128669984

Epoch: 6| Step: 10
Training loss: 2.4700496196746826
Validation loss: 2.777814834348617

Epoch: 6| Step: 11
Training loss: 3.15159010887146
Validation loss: 2.7691742707324285

Epoch: 6| Step: 12
Training loss: 3.970992088317871
Validation loss: 2.768025762291365

Epoch: 6| Step: 13
Training loss: 2.7235450744628906
Validation loss: 2.764138183286113

Epoch: 30| Step: 0
Training loss: 3.5465402603149414
Validation loss: 2.764693670375373

Epoch: 6| Step: 1
Training loss: 2.9031598567962646
Validation loss: 2.7684624387371923

Epoch: 6| Step: 2
Training loss: 2.451303482055664
Validation loss: 2.7701580191171296

Epoch: 6| Step: 3
Training loss: 2.9947938919067383
Validation loss: 2.763202823618407

Epoch: 6| Step: 4
Training loss: 3.062786817550659
Validation loss: 2.770755672967562

Epoch: 6| Step: 5
Training loss: 2.746809482574463
Validation loss: 2.774211173416466

Epoch: 6| Step: 6
Training loss: 2.772350788116455
Validation loss: 2.7637222300293627

Epoch: 6| Step: 7
Training loss: 3.0448005199432373
Validation loss: 2.758193444180232

Epoch: 6| Step: 8
Training loss: 3.474578380584717
Validation loss: 2.7634785098414265

Epoch: 6| Step: 9
Training loss: 3.0718023777008057
Validation loss: 2.759703328532557

Epoch: 6| Step: 10
Training loss: 2.214036226272583
Validation loss: 2.758353089773527

Epoch: 6| Step: 11
Training loss: 2.7888264656066895
Validation loss: 2.7588105509358067

Epoch: 6| Step: 12
Training loss: 2.4655261039733887
Validation loss: 2.75583307204708

Epoch: 6| Step: 13
Training loss: 3.0694820880889893
Validation loss: 2.757331807126281

Epoch: 31| Step: 0
Training loss: 2.754667043685913
Validation loss: 2.7504451787599953

Epoch: 6| Step: 1
Training loss: 2.050952911376953
Validation loss: 2.7607042968914075

Epoch: 6| Step: 2
Training loss: 3.5315566062927246
Validation loss: 2.7564401882950977

Epoch: 6| Step: 3
Training loss: 2.6243534088134766
Validation loss: 2.759537717347504

Epoch: 6| Step: 4
Training loss: 2.7153916358947754
Validation loss: 2.7560061844446326

Epoch: 6| Step: 5
Training loss: 2.9830832481384277
Validation loss: 2.7559431240122807

Epoch: 6| Step: 6
Training loss: 2.755627393722534
Validation loss: 2.7528704571467575

Epoch: 6| Step: 7
Training loss: 3.455805778503418
Validation loss: 2.745166165854341

Epoch: 6| Step: 8
Training loss: 2.5687313079833984
Validation loss: 2.750449647185623

Epoch: 6| Step: 9
Training loss: 4.236344337463379
Validation loss: 2.7480376587119153

Epoch: 6| Step: 10
Training loss: 2.7232465744018555
Validation loss: 2.746330576558267

Epoch: 6| Step: 11
Training loss: 2.9489543437957764
Validation loss: 2.749678075954478

Epoch: 6| Step: 12
Training loss: 2.2947402000427246
Validation loss: 2.7465740608912643

Epoch: 6| Step: 13
Training loss: 2.7258033752441406
Validation loss: 2.7502605248523015

Epoch: 32| Step: 0
Training loss: 2.594839572906494
Validation loss: 2.758017765578403

Epoch: 6| Step: 1
Training loss: 3.565433979034424
Validation loss: 2.7787677062455045

Epoch: 6| Step: 2
Training loss: 3.334406614303589
Validation loss: 2.7837472064520723

Epoch: 6| Step: 3
Training loss: 2.212427854537964
Validation loss: 2.7790526061929683

Epoch: 6| Step: 4
Training loss: 3.372922420501709
Validation loss: 2.772778364919847

Epoch: 6| Step: 5
Training loss: 2.004610300064087
Validation loss: 2.7558072946404897

Epoch: 6| Step: 6
Training loss: 2.6507935523986816
Validation loss: 2.7526488099046933

Epoch: 6| Step: 7
Training loss: 3.180196762084961
Validation loss: 2.752687959260838

Epoch: 6| Step: 8
Training loss: 2.7299208641052246
Validation loss: 2.7522292547328497

Epoch: 6| Step: 9
Training loss: 2.7024593353271484
Validation loss: 2.75116725121775

Epoch: 6| Step: 10
Training loss: 3.5201597213745117
Validation loss: 2.7486556678689937

Epoch: 6| Step: 11
Training loss: 2.2275824546813965
Validation loss: 2.7504062114223355

Epoch: 6| Step: 12
Training loss: 3.2793214321136475
Validation loss: 2.7467786855595087

Epoch: 6| Step: 13
Training loss: 3.4256699085235596
Validation loss: 2.743841778847479

Epoch: 33| Step: 0
Training loss: 3.9338674545288086
Validation loss: 2.742848014318815

Epoch: 6| Step: 1
Training loss: 3.737412452697754
Validation loss: 2.74199309913061

Epoch: 6| Step: 2
Training loss: 2.7594685554504395
Validation loss: 2.7439007630912204

Epoch: 6| Step: 3
Training loss: 3.047564744949341
Validation loss: 2.7487755231959845

Epoch: 6| Step: 4
Training loss: 2.1607799530029297
Validation loss: 2.7709515786940053

Epoch: 6| Step: 5
Training loss: 3.223526954650879
Validation loss: 2.822397842202135

Epoch: 6| Step: 6
Training loss: 2.4309256076812744
Validation loss: 2.85709241385101

Epoch: 6| Step: 7
Training loss: 2.096935749053955
Validation loss: 2.846440645956224

Epoch: 6| Step: 8
Training loss: 2.8582606315612793
Validation loss: 2.8294866546507804

Epoch: 6| Step: 9
Training loss: 3.118107318878174
Validation loss: 2.823260966167655

Epoch: 6| Step: 10
Training loss: 3.3566651344299316
Validation loss: 2.8015587176046064

Epoch: 6| Step: 11
Training loss: 2.2889273166656494
Validation loss: 2.791330014505694

Epoch: 6| Step: 12
Training loss: 2.4873242378234863
Validation loss: 2.7462326403587096

Epoch: 6| Step: 13
Training loss: 3.3122646808624268
Validation loss: 2.7407214641571045

Epoch: 34| Step: 0
Training loss: 1.9586297273635864
Validation loss: 2.7624941128556446

Epoch: 6| Step: 1
Training loss: 3.0456199645996094
Validation loss: 2.842960924230596

Epoch: 6| Step: 2
Training loss: 3.26292085647583
Validation loss: 2.775471515552972

Epoch: 6| Step: 3
Training loss: 3.0175023078918457
Validation loss: 2.7418027821407525

Epoch: 6| Step: 4
Training loss: 3.0549705028533936
Validation loss: 2.7386736305811072

Epoch: 6| Step: 5
Training loss: 3.085622787475586
Validation loss: 2.735167375174902

Epoch: 6| Step: 6
Training loss: 2.856477737426758
Validation loss: 2.7393902322297454

Epoch: 6| Step: 7
Training loss: 3.8381187915802
Validation loss: 2.7548440963991228

Epoch: 6| Step: 8
Training loss: 3.299670934677124
Validation loss: 2.7547171474784933

Epoch: 6| Step: 9
Training loss: 1.9773417711257935
Validation loss: 2.768430899548274

Epoch: 6| Step: 10
Training loss: 2.8070335388183594
Validation loss: 2.756141713870469

Epoch: 6| Step: 11
Training loss: 3.0600767135620117
Validation loss: 2.7462528623560423

Epoch: 6| Step: 12
Training loss: 2.532573699951172
Validation loss: 2.7397152428985923

Epoch: 6| Step: 13
Training loss: 2.5456552505493164
Validation loss: 2.7401724271876837

Epoch: 35| Step: 0
Training loss: 3.108236312866211
Validation loss: 2.7364753651362594

Epoch: 6| Step: 1
Training loss: 3.1376383304595947
Validation loss: 2.7387852002215642

Epoch: 6| Step: 2
Training loss: 2.631943464279175
Validation loss: 2.741596475724251

Epoch: 6| Step: 3
Training loss: 3.406264305114746
Validation loss: 2.7392865637297272

Epoch: 6| Step: 4
Training loss: 2.560319423675537
Validation loss: 2.7352190427882697

Epoch: 6| Step: 5
Training loss: 2.205695629119873
Validation loss: 2.7415866595442577

Epoch: 6| Step: 6
Training loss: 3.638401508331299
Validation loss: 2.7379698112446773

Epoch: 6| Step: 7
Training loss: 2.9040141105651855
Validation loss: 2.735637185394123

Epoch: 6| Step: 8
Training loss: 3.70743727684021
Validation loss: 2.734569887961111

Epoch: 6| Step: 9
Training loss: 3.168994903564453
Validation loss: 2.7443619261505785

Epoch: 6| Step: 10
Training loss: 2.983767509460449
Validation loss: 2.7398386975770355

Epoch: 6| Step: 11
Training loss: 1.8957083225250244
Validation loss: 2.7480424501562632

Epoch: 6| Step: 12
Training loss: 2.599543809890747
Validation loss: 2.7460914401597876

Epoch: 6| Step: 13
Training loss: 2.00748872756958
Validation loss: 2.7330605445369596

Epoch: 36| Step: 0
Training loss: 3.086038589477539
Validation loss: 2.7306519451961724

Epoch: 6| Step: 1
Training loss: 2.501894235610962
Validation loss: 2.7340037156176824

Epoch: 6| Step: 2
Training loss: 3.611513137817383
Validation loss: 2.7310218887944377

Epoch: 6| Step: 3
Training loss: 2.7416231632232666
Validation loss: 2.731656543670162

Epoch: 6| Step: 4
Training loss: 3.081270694732666
Validation loss: 2.728694003115418

Epoch: 6| Step: 5
Training loss: 2.358163356781006
Validation loss: 2.732136618706488

Epoch: 6| Step: 6
Training loss: 2.640773296356201
Validation loss: 2.733768291370843

Epoch: 6| Step: 7
Training loss: 2.8892998695373535
Validation loss: 2.7337894516606487

Epoch: 6| Step: 8
Training loss: 3.2295033931732178
Validation loss: 2.7310956062809115

Epoch: 6| Step: 9
Training loss: 3.041632890701294
Validation loss: 2.7331145886451966

Epoch: 6| Step: 10
Training loss: 2.7859416007995605
Validation loss: 2.7295432603487404

Epoch: 6| Step: 11
Training loss: 2.7869434356689453
Validation loss: 2.728163306431104

Epoch: 6| Step: 12
Training loss: 2.882781505584717
Validation loss: 2.7294672868585073

Epoch: 6| Step: 13
Training loss: 2.5217044353485107
Validation loss: 2.7241817059055453

Epoch: 37| Step: 0
Training loss: 3.202122211456299
Validation loss: 2.7281101621607298

Epoch: 6| Step: 1
Training loss: 3.3821794986724854
Validation loss: 2.726346100530317

Epoch: 6| Step: 2
Training loss: 2.874931812286377
Validation loss: 2.730157744499945

Epoch: 6| Step: 3
Training loss: 2.299095630645752
Validation loss: 2.733689285093738

Epoch: 6| Step: 4
Training loss: 3.4052929878234863
Validation loss: 2.7366796103856896

Epoch: 6| Step: 5
Training loss: 2.5515875816345215
Validation loss: 2.7350757916768393

Epoch: 6| Step: 6
Training loss: 2.5311033725738525
Validation loss: 2.729875756848243

Epoch: 6| Step: 7
Training loss: 3.0311436653137207
Validation loss: 2.7285716636206514

Epoch: 6| Step: 8
Training loss: 2.5960986614227295
Validation loss: 2.7314066040900444

Epoch: 6| Step: 9
Training loss: 3.071305990219116
Validation loss: 2.724958430054367

Epoch: 6| Step: 10
Training loss: 2.507129669189453
Validation loss: 2.7253749626939014

Epoch: 6| Step: 11
Training loss: 3.368886709213257
Validation loss: 2.7208148664043796

Epoch: 6| Step: 12
Training loss: 2.818645477294922
Validation loss: 2.7222539737660396

Epoch: 6| Step: 13
Training loss: 2.179321050643921
Validation loss: 2.7217344853185836

Epoch: 38| Step: 0
Training loss: 2.922168731689453
Validation loss: 2.720723867416382

Epoch: 6| Step: 1
Training loss: 2.479199171066284
Validation loss: 2.7212460015409734

Epoch: 6| Step: 2
Training loss: 3.8173208236694336
Validation loss: 2.7250291634631414

Epoch: 6| Step: 3
Training loss: 2.7362465858459473
Validation loss: 2.726815777440225

Epoch: 6| Step: 4
Training loss: 3.1241767406463623
Validation loss: 2.720414307809645

Epoch: 6| Step: 5
Training loss: 2.1478512287139893
Validation loss: 2.722038358770391

Epoch: 6| Step: 6
Training loss: 3.5974340438842773
Validation loss: 2.7237033331266014

Epoch: 6| Step: 7
Training loss: 2.859924554824829
Validation loss: 2.7171687515833045

Epoch: 6| Step: 8
Training loss: 2.9226341247558594
Validation loss: 2.7238576437837336

Epoch: 6| Step: 9
Training loss: 2.6165311336517334
Validation loss: 2.7181031780858196

Epoch: 6| Step: 10
Training loss: 2.886418104171753
Validation loss: 2.71495133830655

Epoch: 6| Step: 11
Training loss: 3.1787109375
Validation loss: 2.7196145749861196

Epoch: 6| Step: 12
Training loss: 2.074580669403076
Validation loss: 2.71954010891658

Epoch: 6| Step: 13
Training loss: 2.6758651733398438
Validation loss: 2.725532906029814

Epoch: 39| Step: 0
Training loss: 3.3226027488708496
Validation loss: 2.7259833171803463

Epoch: 6| Step: 1
Training loss: 2.4867398738861084
Validation loss: 2.730827749416392

Epoch: 6| Step: 2
Training loss: 2.8230016231536865
Validation loss: 2.7244021046546196

Epoch: 6| Step: 3
Training loss: 2.481003999710083
Validation loss: 2.720275212359685

Epoch: 6| Step: 4
Training loss: 2.99124813079834
Validation loss: 2.721960790695683

Epoch: 6| Step: 5
Training loss: 3.1142091751098633
Validation loss: 2.719013137202109

Epoch: 6| Step: 6
Training loss: 3.035215377807617
Validation loss: 2.717374240198443

Epoch: 6| Step: 7
Training loss: 2.837892770767212
Validation loss: 2.71869654809275

Epoch: 6| Step: 8
Training loss: 3.6298112869262695
Validation loss: 2.717928865904449

Epoch: 6| Step: 9
Training loss: 3.274974822998047
Validation loss: 2.716723129313479

Epoch: 6| Step: 10
Training loss: 2.377526044845581
Validation loss: 2.7125518885991906

Epoch: 6| Step: 11
Training loss: 2.693692207336426
Validation loss: 2.712717486966041

Epoch: 6| Step: 12
Training loss: 2.1692774295806885
Validation loss: 2.71438076162851

Epoch: 6| Step: 13
Training loss: 2.81229305267334
Validation loss: 2.7242062373827864

Epoch: 40| Step: 0
Training loss: 4.04127311706543
Validation loss: 2.7096470248314644

Epoch: 6| Step: 1
Training loss: 2.6070783138275146
Validation loss: 2.7101993073699293

Epoch: 6| Step: 2
Training loss: 3.16357684135437
Validation loss: 2.7091566234506588

Epoch: 6| Step: 3
Training loss: 2.9196629524230957
Validation loss: 2.705963300120446

Epoch: 6| Step: 4
Training loss: 2.2149317264556885
Validation loss: 2.7084864262611634

Epoch: 6| Step: 5
Training loss: 2.7591562271118164
Validation loss: 2.7078616978019796

Epoch: 6| Step: 6
Training loss: 3.281959056854248
Validation loss: 2.708746402494369

Epoch: 6| Step: 7
Training loss: 2.1690595149993896
Validation loss: 2.712980998459683

Epoch: 6| Step: 8
Training loss: 3.093749761581421
Validation loss: 2.7072966893514

Epoch: 6| Step: 9
Training loss: 2.5598652362823486
Validation loss: 2.707949733221403

Epoch: 6| Step: 10
Training loss: 2.8132166862487793
Validation loss: 2.7077632514379357

Epoch: 6| Step: 11
Training loss: 2.6253576278686523
Validation loss: 2.7064501034316195

Epoch: 6| Step: 12
Training loss: 2.908442974090576
Validation loss: 2.703122747841702

Epoch: 6| Step: 13
Training loss: 2.7878310680389404
Validation loss: 2.703674013896655

Epoch: 41| Step: 0
Training loss: 2.153944492340088
Validation loss: 2.702228602542672

Epoch: 6| Step: 1
Training loss: 3.06779146194458
Validation loss: 2.705934698863696

Epoch: 6| Step: 2
Training loss: 2.825259208679199
Validation loss: 2.7089972572941936

Epoch: 6| Step: 3
Training loss: 2.257575273513794
Validation loss: 2.706658319760394

Epoch: 6| Step: 4
Training loss: 2.5799670219421387
Validation loss: 2.714428678635628

Epoch: 6| Step: 5
Training loss: 2.3226263523101807
Validation loss: 2.7072290656387166

Epoch: 6| Step: 6
Training loss: 3.6545510292053223
Validation loss: 2.708480929815641

Epoch: 6| Step: 7
Training loss: 2.9836134910583496
Validation loss: 2.713524813293129

Epoch: 6| Step: 8
Training loss: 2.914858102798462
Validation loss: 2.7220453934002946

Epoch: 6| Step: 9
Training loss: 2.423764228820801
Validation loss: 2.7201441411049134

Epoch: 6| Step: 10
Training loss: 3.4490878582000732
Validation loss: 2.7192020980260705

Epoch: 6| Step: 11
Training loss: 2.4793763160705566
Validation loss: 2.7182601908201813

Epoch: 6| Step: 12
Training loss: 3.5351428985595703
Validation loss: 2.7079210999191448

Epoch: 6| Step: 13
Training loss: 3.653433084487915
Validation loss: 2.7038093869404127

Epoch: 42| Step: 0
Training loss: 3.4039385318756104
Validation loss: 2.6976459205791516

Epoch: 6| Step: 1
Training loss: 2.3698644638061523
Validation loss: 2.6976055970755954

Epoch: 6| Step: 2
Training loss: 2.9098961353302
Validation loss: 2.698694331671602

Epoch: 6| Step: 3
Training loss: 2.4928574562072754
Validation loss: 2.6987495473636094

Epoch: 6| Step: 4
Training loss: 3.232757329940796
Validation loss: 2.6986035557203394

Epoch: 6| Step: 5
Training loss: 2.589137077331543
Validation loss: 2.697104513004262

Epoch: 6| Step: 6
Training loss: 3.0267271995544434
Validation loss: 2.700145923963157

Epoch: 6| Step: 7
Training loss: 3.083094596862793
Validation loss: 2.6959147171307634

Epoch: 6| Step: 8
Training loss: 2.9155831336975098
Validation loss: 2.694600805159538

Epoch: 6| Step: 9
Training loss: 3.0491247177124023
Validation loss: 2.6972042770795923

Epoch: 6| Step: 10
Training loss: 2.566148281097412
Validation loss: 2.6941837751737205

Epoch: 6| Step: 11
Training loss: 3.1392085552215576
Validation loss: 2.6971527863574285

Epoch: 6| Step: 12
Training loss: 2.6835310459136963
Validation loss: 2.6968856806396158

Epoch: 6| Step: 13
Training loss: 2.089916706085205
Validation loss: 2.6936121909849104

Epoch: 43| Step: 0
Training loss: 2.977756977081299
Validation loss: 2.695380336494856

Epoch: 6| Step: 1
Training loss: 2.8953857421875
Validation loss: 2.6964224948677966

Epoch: 6| Step: 2
Training loss: 3.512451171875
Validation loss: 2.693065022909513

Epoch: 6| Step: 3
Training loss: 3.520958662033081
Validation loss: 2.6941946424463743

Epoch: 6| Step: 4
Training loss: 2.0860776901245117
Validation loss: 2.6982073245509977

Epoch: 6| Step: 5
Training loss: 2.7944037914276123
Validation loss: 2.6942335277475338

Epoch: 6| Step: 6
Training loss: 3.3787248134613037
Validation loss: 2.6949621400525494

Epoch: 6| Step: 7
Training loss: 2.5295767784118652
Validation loss: 2.6971061486069874

Epoch: 6| Step: 8
Training loss: 2.759779930114746
Validation loss: 2.699119747325938

Epoch: 6| Step: 9
Training loss: 2.1796491146087646
Validation loss: 2.6958490904941352

Epoch: 6| Step: 10
Training loss: 2.847148895263672
Validation loss: 2.7019311330651723

Epoch: 6| Step: 11
Training loss: 3.244420051574707
Validation loss: 2.7032359748758297

Epoch: 6| Step: 12
Training loss: 2.3997621536254883
Validation loss: 2.6969840424035185

Epoch: 6| Step: 13
Training loss: 2.520253896713257
Validation loss: 2.696210533060053

Epoch: 44| Step: 0
Training loss: 2.1251111030578613
Validation loss: 2.6923997658555225

Epoch: 6| Step: 1
Training loss: 3.1501336097717285
Validation loss: 2.6921720274033083

Epoch: 6| Step: 2
Training loss: 3.2285118103027344
Validation loss: 2.6936365276254635

Epoch: 6| Step: 3
Training loss: 2.4868903160095215
Validation loss: 2.6889353849554576

Epoch: 6| Step: 4
Training loss: 2.4334845542907715
Validation loss: 2.688487296463341

Epoch: 6| Step: 5
Training loss: 2.6867117881774902
Validation loss: 2.689883585899107

Epoch: 6| Step: 6
Training loss: 2.6629080772399902
Validation loss: 2.688617093588716

Epoch: 6| Step: 7
Training loss: 3.4626176357269287
Validation loss: 2.686280756868342

Epoch: 6| Step: 8
Training loss: 2.8840086460113525
Validation loss: 2.6889726038902038

Epoch: 6| Step: 9
Training loss: 3.3295109272003174
Validation loss: 2.692687270461872

Epoch: 6| Step: 10
Training loss: 2.7564687728881836
Validation loss: 2.698774322386711

Epoch: 6| Step: 11
Training loss: 1.8189584016799927
Validation loss: 2.7035355029567594

Epoch: 6| Step: 12
Training loss: 3.150804042816162
Validation loss: 2.707836884324269

Epoch: 6| Step: 13
Training loss: 4.052263259887695
Validation loss: 2.70993980028296

Epoch: 45| Step: 0
Training loss: 2.5230376720428467
Validation loss: 2.7050926813515286

Epoch: 6| Step: 1
Training loss: 3.2384209632873535
Validation loss: 2.70588170841176

Epoch: 6| Step: 2
Training loss: 3.7002410888671875
Validation loss: 2.7040641794922533

Epoch: 6| Step: 3
Training loss: 2.3782827854156494
Validation loss: 2.6927242714871644

Epoch: 6| Step: 4
Training loss: 2.811649799346924
Validation loss: 2.6895078894912556

Epoch: 6| Step: 5
Training loss: 2.7737534046173096
Validation loss: 2.6840896939718597

Epoch: 6| Step: 6
Training loss: 2.5677602291107178
Validation loss: 2.682132967056767

Epoch: 6| Step: 7
Training loss: 3.5124170780181885
Validation loss: 2.6863364737520934

Epoch: 6| Step: 8
Training loss: 2.6936521530151367
Validation loss: 2.682271254959927

Epoch: 6| Step: 9
Training loss: 2.465322732925415
Validation loss: 2.6849714453502367

Epoch: 6| Step: 10
Training loss: 2.8147926330566406
Validation loss: 2.684592798192014

Epoch: 6| Step: 11
Training loss: 2.819728136062622
Validation loss: 2.683140250944322

Epoch: 6| Step: 12
Training loss: 2.3478336334228516
Validation loss: 2.686486926130069

Epoch: 6| Step: 13
Training loss: 3.292189836502075
Validation loss: 2.6858718831052064

Epoch: 46| Step: 0
Training loss: 2.0569024085998535
Validation loss: 2.689883578208185

Epoch: 6| Step: 1
Training loss: 2.6164469718933105
Validation loss: 2.6914314813511346

Epoch: 6| Step: 2
Training loss: 2.5363752841949463
Validation loss: 2.687137672978063

Epoch: 6| Step: 3
Training loss: 3.3078980445861816
Validation loss: 2.6872987106282222

Epoch: 6| Step: 4
Training loss: 2.970217227935791
Validation loss: 2.6889894854637886

Epoch: 6| Step: 5
Training loss: 2.698859214782715
Validation loss: 2.688296917946108

Epoch: 6| Step: 6
Training loss: 2.815035820007324
Validation loss: 2.6851662205111597

Epoch: 6| Step: 7
Training loss: 2.5875964164733887
Validation loss: 2.6841883069725445

Epoch: 6| Step: 8
Training loss: 3.661094903945923
Validation loss: 2.684535049623059

Epoch: 6| Step: 9
Training loss: 2.920377254486084
Validation loss: 2.6830881205938195

Epoch: 6| Step: 10
Training loss: 3.3052096366882324
Validation loss: 2.6788655327212427

Epoch: 6| Step: 11
Training loss: 2.624859571456909
Validation loss: 2.6759991440721738

Epoch: 6| Step: 12
Training loss: 2.8131158351898193
Validation loss: 2.6796251035505727

Epoch: 6| Step: 13
Training loss: 2.6862573623657227
Validation loss: 2.6800518369161956

Epoch: 47| Step: 0
Training loss: 3.196146011352539
Validation loss: 2.6804459966639036

Epoch: 6| Step: 1
Training loss: 3.369081497192383
Validation loss: 2.6850566146194295

Epoch: 6| Step: 2
Training loss: 2.6291615962982178
Validation loss: 2.68731285936089

Epoch: 6| Step: 3
Training loss: 2.860887050628662
Validation loss: 2.6892395070804063

Epoch: 6| Step: 4
Training loss: 2.751823902130127
Validation loss: 2.6863730338311966

Epoch: 6| Step: 5
Training loss: 2.4279112815856934
Validation loss: 2.685260142049482

Epoch: 6| Step: 6
Training loss: 2.128535270690918
Validation loss: 2.6897423933911067

Epoch: 6| Step: 7
Training loss: 2.3157143592834473
Validation loss: 2.690174805220737

Epoch: 6| Step: 8
Training loss: 3.569148302078247
Validation loss: 2.6943624711805776

Epoch: 6| Step: 9
Training loss: 2.629554271697998
Validation loss: 2.684702475865682

Epoch: 6| Step: 10
Training loss: 2.5735971927642822
Validation loss: 2.6769612553299114

Epoch: 6| Step: 11
Training loss: 2.8439977169036865
Validation loss: 2.67753686699816

Epoch: 6| Step: 12
Training loss: 3.3969407081604004
Validation loss: 2.6766275334101852

Epoch: 6| Step: 13
Training loss: 3.050143241882324
Validation loss: 2.6784653984090334

Epoch: 48| Step: 0
Training loss: 2.4192731380462646
Validation loss: 2.6741462112754903

Epoch: 6| Step: 1
Training loss: 2.7020978927612305
Validation loss: 2.6708481965526456

Epoch: 6| Step: 2
Training loss: 3.0097484588623047
Validation loss: 2.675548594485047

Epoch: 6| Step: 3
Training loss: 2.4935855865478516
Validation loss: 2.677639771533269

Epoch: 6| Step: 4
Training loss: 2.8059024810791016
Validation loss: 2.67995124478494

Epoch: 6| Step: 5
Training loss: 3.2980854511260986
Validation loss: 2.6772742322696153

Epoch: 6| Step: 6
Training loss: 3.8702993392944336
Validation loss: 2.6758626660993023

Epoch: 6| Step: 7
Training loss: 2.157411575317383
Validation loss: 2.678761297656644

Epoch: 6| Step: 8
Training loss: 2.636228084564209
Validation loss: 2.674501262685304

Epoch: 6| Step: 9
Training loss: 3.227548599243164
Validation loss: 2.674036625892885

Epoch: 6| Step: 10
Training loss: 2.561138391494751
Validation loss: 2.6691170482225317

Epoch: 6| Step: 11
Training loss: 2.9295740127563477
Validation loss: 2.6697309606818744

Epoch: 6| Step: 12
Training loss: 2.6546506881713867
Validation loss: 2.6710016778720322

Epoch: 6| Step: 13
Training loss: 2.943039655685425
Validation loss: 2.682821484022243

Epoch: 49| Step: 0
Training loss: 3.2278528213500977
Validation loss: 2.682425924526748

Epoch: 6| Step: 1
Training loss: 2.9807920455932617
Validation loss: 2.6845552100930163

Epoch: 6| Step: 2
Training loss: 2.9106922149658203
Validation loss: 2.6833570464964835

Epoch: 6| Step: 3
Training loss: 1.9696950912475586
Validation loss: 2.6856013215998167

Epoch: 6| Step: 4
Training loss: 3.686901330947876
Validation loss: 2.686774428172778

Epoch: 6| Step: 5
Training loss: 2.6887669563293457
Validation loss: 2.6872031457962526

Epoch: 6| Step: 6
Training loss: 3.4888787269592285
Validation loss: 2.6802706564626386

Epoch: 6| Step: 7
Training loss: 2.8198087215423584
Validation loss: 2.675256283052506

Epoch: 6| Step: 8
Training loss: 2.9554455280303955
Validation loss: 2.669093742165514

Epoch: 6| Step: 9
Training loss: 3.1470537185668945
Validation loss: 2.6688714309405257

Epoch: 6| Step: 10
Training loss: 2.564218521118164
Validation loss: 2.66151584604735

Epoch: 6| Step: 11
Training loss: 2.603653907775879
Validation loss: 2.663225043204523

Epoch: 6| Step: 12
Training loss: 2.0064144134521484
Validation loss: 2.661308526992798

Epoch: 6| Step: 13
Training loss: 2.1371982097625732
Validation loss: 2.6661231440882527

Epoch: 50| Step: 0
Training loss: 3.7518668174743652
Validation loss: 2.662307152184107

Epoch: 6| Step: 1
Training loss: 2.470829486846924
Validation loss: 2.6644001571081017

Epoch: 6| Step: 2
Training loss: 2.868460178375244
Validation loss: 2.6655521751731954

Epoch: 6| Step: 3
Training loss: 1.886153221130371
Validation loss: 2.666305160009733

Epoch: 6| Step: 4
Training loss: 3.976208209991455
Validation loss: 2.6605369839617

Epoch: 6| Step: 5
Training loss: 2.822464942932129
Validation loss: 2.661598277348344

Epoch: 6| Step: 6
Training loss: 2.6418685913085938
Validation loss: 2.6622806672127015

Epoch: 6| Step: 7
Training loss: 2.9168667793273926
Validation loss: 2.6621719970498035

Epoch: 6| Step: 8
Training loss: 2.5511224269866943
Validation loss: 2.667727224288448

Epoch: 6| Step: 9
Training loss: 3.1058082580566406
Validation loss: 2.668341264929823

Epoch: 6| Step: 10
Training loss: 2.7721104621887207
Validation loss: 2.663824430076025

Epoch: 6| Step: 11
Training loss: 2.33268141746521
Validation loss: 2.6649570772724767

Epoch: 6| Step: 12
Training loss: 2.153726577758789
Validation loss: 2.661404891680646

Epoch: 6| Step: 13
Training loss: 3.5308353900909424
Validation loss: 2.66100465097735

Epoch: 51| Step: 0
Training loss: 2.920128345489502
Validation loss: 2.6614173894287436

Epoch: 6| Step: 1
Training loss: 2.5476887226104736
Validation loss: 2.6608233733843734

Epoch: 6| Step: 2
Training loss: 2.409040927886963
Validation loss: 2.6590420840888895

Epoch: 6| Step: 3
Training loss: 3.034134864807129
Validation loss: 2.6561315085298274

Epoch: 6| Step: 4
Training loss: 3.086378574371338
Validation loss: 2.658115981727518

Epoch: 6| Step: 5
Training loss: 2.6552534103393555
Validation loss: 2.6584830822483188

Epoch: 6| Step: 6
Training loss: 2.812337875366211
Validation loss: 2.6575372219085693

Epoch: 6| Step: 7
Training loss: 2.9521584510803223
Validation loss: 2.66589859736863

Epoch: 6| Step: 8
Training loss: 2.9655022621154785
Validation loss: 2.674012876326038

Epoch: 6| Step: 9
Training loss: 2.0406675338745117
Validation loss: 2.6855459982349026

Epoch: 6| Step: 10
Training loss: 2.9750304222106934
Validation loss: 2.7039451650393906

Epoch: 6| Step: 11
Training loss: 2.6641013622283936
Validation loss: 2.6599202156066895

Epoch: 6| Step: 12
Training loss: 2.700526714324951
Validation loss: 2.653460625679262

Epoch: 6| Step: 13
Training loss: 4.2404398918151855
Validation loss: 2.6574463075207126

Epoch: 52| Step: 0
Training loss: 3.085871696472168
Validation loss: 2.655990654422391

Epoch: 6| Step: 1
Training loss: 2.937000274658203
Validation loss: 2.6615932526126986

Epoch: 6| Step: 2
Training loss: 2.636756181716919
Validation loss: 2.6654969517902662

Epoch: 6| Step: 3
Training loss: 2.203418254852295
Validation loss: 2.6708130016121814

Epoch: 6| Step: 4
Training loss: 2.726447105407715
Validation loss: 2.6793026180677515

Epoch: 6| Step: 5
Training loss: 3.2895545959472656
Validation loss: 2.6766235187489498

Epoch: 6| Step: 6
Training loss: 2.804288387298584
Validation loss: 2.6699497238282235

Epoch: 6| Step: 7
Training loss: 3.179086208343506
Validation loss: 2.6664401613255984

Epoch: 6| Step: 8
Training loss: 2.1435651779174805
Validation loss: 2.6641704497798795

Epoch: 6| Step: 9
Training loss: 3.292259693145752
Validation loss: 2.663000332411899

Epoch: 6| Step: 10
Training loss: 2.6543102264404297
Validation loss: 2.66342007729315

Epoch: 6| Step: 11
Training loss: 3.5371594429016113
Validation loss: 2.6625245181463097

Epoch: 6| Step: 12
Training loss: 2.7531094551086426
Validation loss: 2.661961301680534

Epoch: 6| Step: 13
Training loss: 1.7849093675613403
Validation loss: 2.665290122391075

Epoch: 53| Step: 0
Training loss: 2.1981735229492188
Validation loss: 2.665183831286687

Epoch: 6| Step: 1
Training loss: 3.1449460983276367
Validation loss: 2.6604071970908874

Epoch: 6| Step: 2
Training loss: 2.7264292240142822
Validation loss: 2.655313550785024

Epoch: 6| Step: 3
Training loss: 2.56064510345459
Validation loss: 2.649132413248862

Epoch: 6| Step: 4
Training loss: 2.683922290802002
Validation loss: 2.64911836706182

Epoch: 6| Step: 5
Training loss: 3.565610408782959
Validation loss: 2.6481148376259753

Epoch: 6| Step: 6
Training loss: 1.7752232551574707
Validation loss: 2.655841845338063

Epoch: 6| Step: 7
Training loss: 2.8295342922210693
Validation loss: 2.6622565766816497

Epoch: 6| Step: 8
Training loss: 2.8812246322631836
Validation loss: 2.6590679050773702

Epoch: 6| Step: 9
Training loss: 3.08626651763916
Validation loss: 2.660609217100246

Epoch: 6| Step: 10
Training loss: 2.1858081817626953
Validation loss: 2.6589583786585

Epoch: 6| Step: 11
Training loss: 3.5295748710632324
Validation loss: 2.66063327686761

Epoch: 6| Step: 12
Training loss: 3.355860710144043
Validation loss: 2.658332073560325

Epoch: 6| Step: 13
Training loss: 2.9982566833496094
Validation loss: 2.6534407549006964

Epoch: 54| Step: 0
Training loss: 2.552900791168213
Validation loss: 2.6519238923185613

Epoch: 6| Step: 1
Training loss: 2.5280585289001465
Validation loss: 2.64956505580615

Epoch: 6| Step: 2
Training loss: 3.0644032955169678
Validation loss: 2.6448538534102903

Epoch: 6| Step: 3
Training loss: 2.7791333198547363
Validation loss: 2.6471979720618135

Epoch: 6| Step: 4
Training loss: 3.416236400604248
Validation loss: 2.6527626463162

Epoch: 6| Step: 5
Training loss: 2.736147403717041
Validation loss: 2.6554153657728627

Epoch: 6| Step: 6
Training loss: 2.9328980445861816
Validation loss: 2.6579008179326213

Epoch: 6| Step: 7
Training loss: 2.6823930740356445
Validation loss: 2.6574020539560625

Epoch: 6| Step: 8
Training loss: 3.0700581073760986
Validation loss: 2.6597662536046838

Epoch: 6| Step: 9
Training loss: 1.843207597732544
Validation loss: 2.656881445197649

Epoch: 6| Step: 10
Training loss: 2.8602101802825928
Validation loss: 2.64828465061803

Epoch: 6| Step: 11
Training loss: 3.220388889312744
Validation loss: 2.6406383181131012

Epoch: 6| Step: 12
Training loss: 2.8205409049987793
Validation loss: 2.6460511479326474

Epoch: 6| Step: 13
Training loss: 2.820779800415039
Validation loss: 2.641423184384582

Epoch: 55| Step: 0
Training loss: 3.0756423473358154
Validation loss: 2.64573392047677

Epoch: 6| Step: 1
Training loss: 3.8386311531066895
Validation loss: 2.6425874694701164

Epoch: 6| Step: 2
Training loss: 2.5566372871398926
Validation loss: 2.64537614135332

Epoch: 6| Step: 3
Training loss: 2.579585313796997
Validation loss: 2.6445349954789683

Epoch: 6| Step: 4
Training loss: 3.0918116569519043
Validation loss: 2.6469403005415395

Epoch: 6| Step: 5
Training loss: 1.986954927444458
Validation loss: 2.6496537628994195

Epoch: 6| Step: 6
Training loss: 2.666037082672119
Validation loss: 2.6415776180964645

Epoch: 6| Step: 7
Training loss: 3.4293212890625
Validation loss: 2.6409631083088536

Epoch: 6| Step: 8
Training loss: 2.820411443710327
Validation loss: 2.638914615877213

Epoch: 6| Step: 9
Training loss: 2.482780933380127
Validation loss: 2.638311255362726

Epoch: 6| Step: 10
Training loss: 2.407764434814453
Validation loss: 2.639827512925671

Epoch: 6| Step: 11
Training loss: 3.0351016521453857
Validation loss: 2.6384549781840336

Epoch: 6| Step: 12
Training loss: 2.6724071502685547
Validation loss: 2.6403283611420663

Epoch: 6| Step: 13
Training loss: 2.3827807903289795
Validation loss: 2.636022913840509

Epoch: 56| Step: 0
Training loss: 2.59922456741333
Validation loss: 2.6350937248558126

Epoch: 6| Step: 1
Training loss: 3.011049747467041
Validation loss: 2.640866151420019

Epoch: 6| Step: 2
Training loss: 2.420119047164917
Validation loss: 2.6361386365787958

Epoch: 6| Step: 3
Training loss: 2.2937374114990234
Validation loss: 2.637422038662818

Epoch: 6| Step: 4
Training loss: 3.9962716102600098
Validation loss: 2.6390848518699728

Epoch: 6| Step: 5
Training loss: 2.308471918106079
Validation loss: 2.6341474004971084

Epoch: 6| Step: 6
Training loss: 2.488309144973755
Validation loss: 2.6377480183878252

Epoch: 6| Step: 7
Training loss: 2.2125144004821777
Validation loss: 2.6350883489014

Epoch: 6| Step: 8
Training loss: 3.340200901031494
Validation loss: 2.634487813518893

Epoch: 6| Step: 9
Training loss: 3.2159934043884277
Validation loss: 2.6333419828004736

Epoch: 6| Step: 10
Training loss: 2.32028865814209
Validation loss: 2.6374957740947766

Epoch: 6| Step: 11
Training loss: 3.289461851119995
Validation loss: 2.632346373732372

Epoch: 6| Step: 12
Training loss: 2.7841391563415527
Validation loss: 2.63340421389508

Epoch: 6| Step: 13
Training loss: 2.91646146774292
Validation loss: 2.6318898867535334

Epoch: 57| Step: 0
Training loss: 2.8625593185424805
Validation loss: 2.62946835384574

Epoch: 6| Step: 1
Training loss: 3.179859161376953
Validation loss: 2.6346750951582387

Epoch: 6| Step: 2
Training loss: 2.368262767791748
Validation loss: 2.6274446108007945

Epoch: 6| Step: 3
Training loss: 2.4519286155700684
Validation loss: 2.6299047034273864

Epoch: 6| Step: 4
Training loss: 2.6857657432556152
Validation loss: 2.6287797804801696

Epoch: 6| Step: 5
Training loss: 3.0195765495300293
Validation loss: 2.6334328728337444

Epoch: 6| Step: 6
Training loss: 2.534559488296509
Validation loss: 2.6332280302560456

Epoch: 6| Step: 7
Training loss: 2.7928128242492676
Validation loss: 2.6386428853516937

Epoch: 6| Step: 8
Training loss: 2.777508497238159
Validation loss: 2.6413044724413144

Epoch: 6| Step: 9
Training loss: 2.498016357421875
Validation loss: 2.643556812758087

Epoch: 6| Step: 10
Training loss: 2.6126108169555664
Validation loss: 2.642794314251151

Epoch: 6| Step: 11
Training loss: 3.1140623092651367
Validation loss: 2.649441680600566

Epoch: 6| Step: 12
Training loss: 3.4280896186828613
Validation loss: 2.6466962124711726

Epoch: 6| Step: 13
Training loss: 2.7652666568756104
Validation loss: 2.643653310755248

Epoch: 58| Step: 0
Training loss: 3.1973154544830322
Validation loss: 2.6325861997501825

Epoch: 6| Step: 1
Training loss: 2.496610164642334
Validation loss: 2.62958961661144

Epoch: 6| Step: 2
Training loss: 2.437631607055664
Validation loss: 2.6286624529028453

Epoch: 6| Step: 3
Training loss: 2.8441245555877686
Validation loss: 2.626434072371452

Epoch: 6| Step: 4
Training loss: 2.738077163696289
Validation loss: 2.6265553864099647

Epoch: 6| Step: 5
Training loss: 3.3379454612731934
Validation loss: 2.6243280428712086

Epoch: 6| Step: 6
Training loss: 2.960686206817627
Validation loss: 2.626035900526149

Epoch: 6| Step: 7
Training loss: 2.892012119293213
Validation loss: 2.6241942246754966

Epoch: 6| Step: 8
Training loss: 2.8867979049682617
Validation loss: 2.6235879723743727

Epoch: 6| Step: 9
Training loss: 2.495662212371826
Validation loss: 2.6252637934941117

Epoch: 6| Step: 10
Training loss: 3.132877826690674
Validation loss: 2.6256918009891304

Epoch: 6| Step: 11
Training loss: 3.037266731262207
Validation loss: 2.6261327292329524

Epoch: 6| Step: 12
Training loss: 2.3096578121185303
Validation loss: 2.618759012991382

Epoch: 6| Step: 13
Training loss: 1.8681784868240356
Validation loss: 2.625660393827705

Epoch: 59| Step: 0
Training loss: 2.632554531097412
Validation loss: 2.627318266899355

Epoch: 6| Step: 1
Training loss: 2.272388458251953
Validation loss: 2.621515966230823

Epoch: 6| Step: 2
Training loss: 3.2229979038238525
Validation loss: 2.6220508621584986

Epoch: 6| Step: 3
Training loss: 2.5969319343566895
Validation loss: 2.619997816701089

Epoch: 6| Step: 4
Training loss: 3.0527548789978027
Validation loss: 2.6216807980691232

Epoch: 6| Step: 5
Training loss: 3.351881742477417
Validation loss: 2.622416421931277

Epoch: 6| Step: 6
Training loss: 3.054335355758667
Validation loss: 2.6196533633816625

Epoch: 6| Step: 7
Training loss: 2.771397829055786
Validation loss: 2.6228950792743313

Epoch: 6| Step: 8
Training loss: 3.5472640991210938
Validation loss: 2.622830824185443

Epoch: 6| Step: 9
Training loss: 1.9231449365615845
Validation loss: 2.6265013781926965

Epoch: 6| Step: 10
Training loss: 2.680960178375244
Validation loss: 2.6288086214373187

Epoch: 6| Step: 11
Training loss: 2.2415690422058105
Validation loss: 2.6375889957592054

Epoch: 6| Step: 12
Training loss: 2.705343246459961
Validation loss: 2.6601963222667737

Epoch: 6| Step: 13
Training loss: 3.1515421867370605
Validation loss: 2.669207711373606

Epoch: 60| Step: 0
Training loss: 2.9727134704589844
Validation loss: 2.666270443188247

Epoch: 6| Step: 1
Training loss: 2.041118621826172
Validation loss: 2.674438379144156

Epoch: 6| Step: 2
Training loss: 3.413872241973877
Validation loss: 2.6712081765615814

Epoch: 6| Step: 3
Training loss: 2.5622847080230713
Validation loss: 2.6556228335185716

Epoch: 6| Step: 4
Training loss: 3.2312421798706055
Validation loss: 2.6496970397169872

Epoch: 6| Step: 5
Training loss: 3.008040428161621
Validation loss: 2.6353469125686155

Epoch: 6| Step: 6
Training loss: 2.308692455291748
Validation loss: 2.6241610614202355

Epoch: 6| Step: 7
Training loss: 2.3257861137390137
Validation loss: 2.6204057726808774

Epoch: 6| Step: 8
Training loss: 2.8219454288482666
Validation loss: 2.6176697618217877

Epoch: 6| Step: 9
Training loss: 3.0162343978881836
Validation loss: 2.6186560584652807

Epoch: 6| Step: 10
Training loss: 2.6034646034240723
Validation loss: 2.6160455570426038

Epoch: 6| Step: 11
Training loss: 3.442858934402466
Validation loss: 2.617103453605406

Epoch: 6| Step: 12
Training loss: 2.364272117614746
Validation loss: 2.6203966961112073

Epoch: 6| Step: 13
Training loss: 3.449946165084839
Validation loss: 2.6179264104494484

Epoch: 61| Step: 0
Training loss: 3.1066532135009766
Validation loss: 2.623209065006625

Epoch: 6| Step: 1
Training loss: 2.8363852500915527
Validation loss: 2.6288651779133785

Epoch: 6| Step: 2
Training loss: 2.7315187454223633
Validation loss: 2.6298284569094257

Epoch: 6| Step: 3
Training loss: 2.3300509452819824
Validation loss: 2.623167460964572

Epoch: 6| Step: 4
Training loss: 3.2011213302612305
Validation loss: 2.6217506521491596

Epoch: 6| Step: 5
Training loss: 2.627102851867676
Validation loss: 2.6202569828238538

Epoch: 6| Step: 6
Training loss: 2.4929516315460205
Validation loss: 2.6166953527799217

Epoch: 6| Step: 7
Training loss: 2.5020742416381836
Validation loss: 2.6125173953271683

Epoch: 6| Step: 8
Training loss: 2.753328800201416
Validation loss: 2.6158270348784742

Epoch: 6| Step: 9
Training loss: 2.7980051040649414
Validation loss: 2.617541495189872

Epoch: 6| Step: 10
Training loss: 2.7541818618774414
Validation loss: 2.6263643541643695

Epoch: 6| Step: 11
Training loss: 3.2277188301086426
Validation loss: 2.621072664055773

Epoch: 6| Step: 12
Training loss: 2.3776960372924805
Validation loss: 2.6230213898484425

Epoch: 6| Step: 13
Training loss: 3.552760124206543
Validation loss: 2.6313157901969007

Epoch: 62| Step: 0
Training loss: 2.5020298957824707
Validation loss: 2.630050192597092

Epoch: 6| Step: 1
Training loss: 2.4321794509887695
Validation loss: 2.625189532515823

Epoch: 6| Step: 2
Training loss: 2.0880751609802246
Validation loss: 2.6239238785159205

Epoch: 6| Step: 3
Training loss: 2.5448479652404785
Validation loss: 2.6222813155061457

Epoch: 6| Step: 4
Training loss: 3.146155834197998
Validation loss: 2.621193657639206

Epoch: 6| Step: 5
Training loss: 2.7152557373046875
Validation loss: 2.613910352030108

Epoch: 6| Step: 6
Training loss: 3.428185224533081
Validation loss: 2.6161950096007316

Epoch: 6| Step: 7
Training loss: 2.9133801460266113
Validation loss: 2.6078433195749917

Epoch: 6| Step: 8
Training loss: 2.7559759616851807
Validation loss: 2.6105280178849415

Epoch: 6| Step: 9
Training loss: 2.901437759399414
Validation loss: 2.6094529705662883

Epoch: 6| Step: 10
Training loss: 2.6569135189056396
Validation loss: 2.6090764717389177

Epoch: 6| Step: 11
Training loss: 3.2203516960144043
Validation loss: 2.608494556078347

Epoch: 6| Step: 12
Training loss: 2.343278408050537
Validation loss: 2.6135744535794823

Epoch: 6| Step: 13
Training loss: 3.394166946411133
Validation loss: 2.613789230264643

Epoch: 63| Step: 0
Training loss: 2.124706268310547
Validation loss: 2.6187275173843547

Epoch: 6| Step: 1
Training loss: 3.3480215072631836
Validation loss: 2.6235657199736564

Epoch: 6| Step: 2
Training loss: 3.112636089324951
Validation loss: 2.6214411591970794

Epoch: 6| Step: 3
Training loss: 3.3948826789855957
Validation loss: 2.6212804958384526

Epoch: 6| Step: 4
Training loss: 3.572216510772705
Validation loss: 2.6162778510842273

Epoch: 6| Step: 5
Training loss: 3.436014175415039
Validation loss: 2.6152480161318215

Epoch: 6| Step: 6
Training loss: 2.335251808166504
Validation loss: 2.6122969914508123

Epoch: 6| Step: 7
Training loss: 2.262324810028076
Validation loss: 2.609832602162515

Epoch: 6| Step: 8
Training loss: 2.792647361755371
Validation loss: 2.6035023786688365

Epoch: 6| Step: 9
Training loss: 2.67567777633667
Validation loss: 2.6008809561370523

Epoch: 6| Step: 10
Training loss: 2.4439735412597656
Validation loss: 2.605801490045363

Epoch: 6| Step: 11
Training loss: 2.7586722373962402
Validation loss: 2.6217910756347

Epoch: 6| Step: 12
Training loss: 2.178616762161255
Validation loss: 2.6278217531019643

Epoch: 6| Step: 13
Training loss: 2.5410678386688232
Validation loss: 2.621769843562957

Epoch: 64| Step: 0
Training loss: 2.888568639755249
Validation loss: 2.6114965202987834

Epoch: 6| Step: 1
Training loss: 3.3703176975250244
Validation loss: 2.6161420524761243

Epoch: 6| Step: 2
Training loss: 1.8236579895019531
Validation loss: 2.6108918933458227

Epoch: 6| Step: 3
Training loss: 2.4000329971313477
Validation loss: 2.6044863962358042

Epoch: 6| Step: 4
Training loss: 2.5816261768341064
Validation loss: 2.602607862923735

Epoch: 6| Step: 5
Training loss: 3.6765787601470947
Validation loss: 2.6049370765686035

Epoch: 6| Step: 6
Training loss: 2.675520896911621
Validation loss: 2.605872590054748

Epoch: 6| Step: 7
Training loss: 2.337031364440918
Validation loss: 2.597704372098369

Epoch: 6| Step: 8
Training loss: 3.0341997146606445
Validation loss: 2.6069042093010357

Epoch: 6| Step: 9
Training loss: 3.191473960876465
Validation loss: 2.6125859316959175

Epoch: 6| Step: 10
Training loss: 2.2087345123291016
Validation loss: 2.615105305948565

Epoch: 6| Step: 11
Training loss: 2.5175352096557617
Validation loss: 2.615299388926516

Epoch: 6| Step: 12
Training loss: 3.3076231479644775
Validation loss: 2.6091719519707466

Epoch: 6| Step: 13
Training loss: 2.7484893798828125
Validation loss: 2.6080850426868727

Epoch: 65| Step: 0
Training loss: 2.534618854522705
Validation loss: 2.601024176484795

Epoch: 6| Step: 1
Training loss: 3.0036096572875977
Validation loss: 2.599388086667625

Epoch: 6| Step: 2
Training loss: 2.2600865364074707
Validation loss: 2.5926579762530584

Epoch: 6| Step: 3
Training loss: 2.2884206771850586
Validation loss: 2.5979317336954098

Epoch: 6| Step: 4
Training loss: 2.7749340534210205
Validation loss: 2.597964240658668

Epoch: 6| Step: 5
Training loss: 2.936722993850708
Validation loss: 2.592533605073088

Epoch: 6| Step: 6
Training loss: 2.8572731018066406
Validation loss: 2.5983424391797794

Epoch: 6| Step: 7
Training loss: 2.5691189765930176
Validation loss: 2.601456331950362

Epoch: 6| Step: 8
Training loss: 3.1165101528167725
Validation loss: 2.597330472802603

Epoch: 6| Step: 9
Training loss: 2.8109545707702637
Validation loss: 2.5999346010146605

Epoch: 6| Step: 10
Training loss: 3.542553186416626
Validation loss: 2.5979875774793726

Epoch: 6| Step: 11
Training loss: 3.0870442390441895
Validation loss: 2.6040500415268766

Epoch: 6| Step: 12
Training loss: 2.6611595153808594
Validation loss: 2.6001975741437686

Epoch: 6| Step: 13
Training loss: 2.055250644683838
Validation loss: 2.5990245521709485

Epoch: 66| Step: 0
Training loss: 3.7198009490966797
Validation loss: 2.5944391553119948

Epoch: 6| Step: 1
Training loss: 2.503328800201416
Validation loss: 2.5948807859933503

Epoch: 6| Step: 2
Training loss: 2.215219497680664
Validation loss: 2.59624049996817

Epoch: 6| Step: 3
Training loss: 3.161560535430908
Validation loss: 2.5989807139160814

Epoch: 6| Step: 4
Training loss: 3.4541096687316895
Validation loss: 2.6114908443984164

Epoch: 6| Step: 5
Training loss: 2.8535139560699463
Validation loss: 2.621264398738902

Epoch: 6| Step: 6
Training loss: 2.5272650718688965
Validation loss: 2.631138540083362

Epoch: 6| Step: 7
Training loss: 2.6875314712524414
Validation loss: 2.6358327634872927

Epoch: 6| Step: 8
Training loss: 2.45263409614563
Validation loss: 2.6281799782988844

Epoch: 6| Step: 9
Training loss: 2.1894474029541016
Validation loss: 2.6189256765509166

Epoch: 6| Step: 10
Training loss: 2.584362268447876
Validation loss: 2.612605961420203

Epoch: 6| Step: 11
Training loss: 2.531588315963745
Validation loss: 2.6104148946782595

Epoch: 6| Step: 12
Training loss: 3.481273651123047
Validation loss: 2.606606747514458

Epoch: 6| Step: 13
Training loss: 2.273991584777832
Validation loss: 2.602863586077126

Epoch: 67| Step: 0
Training loss: 2.9112000465393066
Validation loss: 2.596500499274141

Epoch: 6| Step: 1
Training loss: 2.310271739959717
Validation loss: 2.593399035033359

Epoch: 6| Step: 2
Training loss: 2.3895201683044434
Validation loss: 2.5912435336779525

Epoch: 6| Step: 3
Training loss: 3.1466503143310547
Validation loss: 2.5929344751501597

Epoch: 6| Step: 4
Training loss: 2.8909788131713867
Validation loss: 2.59185988672318

Epoch: 6| Step: 5
Training loss: 1.963451862335205
Validation loss: 2.5895428554986113

Epoch: 6| Step: 6
Training loss: 3.649529457092285
Validation loss: 2.5861614109367452

Epoch: 6| Step: 7
Training loss: 2.7243552207946777
Validation loss: 2.5939091559379333

Epoch: 6| Step: 8
Training loss: 2.366940975189209
Validation loss: 2.5904332924914617

Epoch: 6| Step: 9
Training loss: 3.3676249980926514
Validation loss: 2.587434632803804

Epoch: 6| Step: 10
Training loss: 3.268446922302246
Validation loss: 2.588690370641729

Epoch: 6| Step: 11
Training loss: 3.182271957397461
Validation loss: 2.5840588359422583

Epoch: 6| Step: 12
Training loss: 2.37907075881958
Validation loss: 2.5916043225155083

Epoch: 6| Step: 13
Training loss: 1.5411344766616821
Validation loss: 2.583802056568925

Epoch: 68| Step: 0
Training loss: 2.107495069503784
Validation loss: 2.582594233174478

Epoch: 6| Step: 1
Training loss: 2.3126838207244873
Validation loss: 2.5858599601253385

Epoch: 6| Step: 2
Training loss: 2.7027788162231445
Validation loss: 2.578540566147015

Epoch: 6| Step: 3
Training loss: 3.125271797180176
Validation loss: 2.582614980718141

Epoch: 6| Step: 4
Training loss: 3.16900897026062
Validation loss: 2.582384709388979

Epoch: 6| Step: 5
Training loss: 3.219799041748047
Validation loss: 2.5843722820281982

Epoch: 6| Step: 6
Training loss: 3.7182400226593018
Validation loss: 2.5904955863952637

Epoch: 6| Step: 7
Training loss: 2.5072574615478516
Validation loss: 2.5879686160754134

Epoch: 6| Step: 8
Training loss: 2.1651194095611572
Validation loss: 2.5918255057386173

Epoch: 6| Step: 9
Training loss: 2.6086273193359375
Validation loss: 2.5887679387164373

Epoch: 6| Step: 10
Training loss: 2.82204532623291
Validation loss: 2.5844676366416355

Epoch: 6| Step: 11
Training loss: 2.619649887084961
Validation loss: 2.5818366542939217

Epoch: 6| Step: 12
Training loss: 3.018198251724243
Validation loss: 2.5802185279066845

Epoch: 6| Step: 13
Training loss: 2.438059091567993
Validation loss: 2.578628765639438

Epoch: 69| Step: 0
Training loss: 2.6855032444000244
Validation loss: 2.582489167490313

Epoch: 6| Step: 1
Training loss: 3.0097978115081787
Validation loss: 2.5772733662718084

Epoch: 6| Step: 2
Training loss: 3.0766470432281494
Validation loss: 2.582210712535407

Epoch: 6| Step: 3
Training loss: 1.5299010276794434
Validation loss: 2.5855475138592463

Epoch: 6| Step: 4
Training loss: 2.2323012351989746
Validation loss: 2.5896683713441253

Epoch: 6| Step: 5
Training loss: 2.9949464797973633
Validation loss: 2.581463675345144

Epoch: 6| Step: 6
Training loss: 2.64689564704895
Validation loss: 2.582229786021735

Epoch: 6| Step: 7
Training loss: 3.1913657188415527
Validation loss: 2.578699332411571

Epoch: 6| Step: 8
Training loss: 2.8313546180725098
Validation loss: 2.5817436402843845

Epoch: 6| Step: 9
Training loss: 2.8723320960998535
Validation loss: 2.5783429658541115

Epoch: 6| Step: 10
Training loss: 2.7568471431732178
Validation loss: 2.5778933340503323

Epoch: 6| Step: 11
Training loss: 3.3043336868286133
Validation loss: 2.577171746120658

Epoch: 6| Step: 12
Training loss: 2.905634641647339
Validation loss: 2.578361157448061

Epoch: 6| Step: 13
Training loss: 2.2610793113708496
Validation loss: 2.5757176081339517

Epoch: 70| Step: 0
Training loss: 3.2620849609375
Validation loss: 2.578741324845181

Epoch: 6| Step: 1
Training loss: 1.9579622745513916
Validation loss: 2.587157021286667

Epoch: 6| Step: 2
Training loss: 2.8480911254882812
Validation loss: 2.585810071678572

Epoch: 6| Step: 3
Training loss: 3.0879220962524414
Validation loss: 2.5891677256553405

Epoch: 6| Step: 4
Training loss: 3.210495948791504
Validation loss: 2.6131941374912055

Epoch: 6| Step: 5
Training loss: 2.4019742012023926
Validation loss: 2.6049145960038707

Epoch: 6| Step: 6
Training loss: 3.252643585205078
Validation loss: 2.6268661483641593

Epoch: 6| Step: 7
Training loss: 2.6117193698883057
Validation loss: 2.6000057343513734

Epoch: 6| Step: 8
Training loss: 2.692356586456299
Validation loss: 2.584007381111063

Epoch: 6| Step: 9
Training loss: 2.5906848907470703
Validation loss: 2.5826069924139206

Epoch: 6| Step: 10
Training loss: 2.816223621368408
Validation loss: 2.571742452600951

Epoch: 6| Step: 11
Training loss: 2.275444746017456
Validation loss: 2.5715865832503124

Epoch: 6| Step: 12
Training loss: 2.2602553367614746
Validation loss: 2.5690569339259977

Epoch: 6| Step: 13
Training loss: 3.5537939071655273
Validation loss: 2.5748880960608043

Epoch: 71| Step: 0
Training loss: 2.2419118881225586
Validation loss: 2.5781354622174333

Epoch: 6| Step: 1
Training loss: 2.224639654159546
Validation loss: 2.577843053366548

Epoch: 6| Step: 2
Training loss: 2.0518698692321777
Validation loss: 2.5830120219979236

Epoch: 6| Step: 3
Training loss: 2.5752885341644287
Validation loss: 2.578820249085785

Epoch: 6| Step: 4
Training loss: 3.7473974227905273
Validation loss: 2.5741447607676187

Epoch: 6| Step: 5
Training loss: 3.2145957946777344
Validation loss: 2.5795578161875405

Epoch: 6| Step: 6
Training loss: 3.2067480087280273
Validation loss: 2.577206793651786

Epoch: 6| Step: 7
Training loss: 2.374268054962158
Validation loss: 2.5749397688014533

Epoch: 6| Step: 8
Training loss: 3.2272496223449707
Validation loss: 2.572436294248027

Epoch: 6| Step: 9
Training loss: 2.188046455383301
Validation loss: 2.570264785520492

Epoch: 6| Step: 10
Training loss: 2.752189874649048
Validation loss: 2.5699871637487925

Epoch: 6| Step: 11
Training loss: 2.7088658809661865
Validation loss: 2.5700569409196095

Epoch: 6| Step: 12
Training loss: 3.2661662101745605
Validation loss: 2.5716434806905766

Epoch: 6| Step: 13
Training loss: 2.7988595962524414
Validation loss: 2.570316037824077

Epoch: 72| Step: 0
Training loss: 2.7384591102600098
Validation loss: 2.5781635238278295

Epoch: 6| Step: 1
Training loss: 3.4882712364196777
Validation loss: 2.578420990256853

Epoch: 6| Step: 2
Training loss: 2.0703063011169434
Validation loss: 2.5820636672358357

Epoch: 6| Step: 3
Training loss: 1.5942357778549194
Validation loss: 2.583105400044431

Epoch: 6| Step: 4
Training loss: 2.958003044128418
Validation loss: 2.563511344694322

Epoch: 6| Step: 5
Training loss: 2.7868216037750244
Validation loss: 2.5659505295497116

Epoch: 6| Step: 6
Training loss: 3.5269088745117188
Validation loss: 2.5618941655722995

Epoch: 6| Step: 7
Training loss: 2.4153225421905518
Validation loss: 2.567636428340789

Epoch: 6| Step: 8
Training loss: 2.786308765411377
Validation loss: 2.5656780863320954

Epoch: 6| Step: 9
Training loss: 2.86307692527771
Validation loss: 2.569793206389232

Epoch: 6| Step: 10
Training loss: 3.0673203468322754
Validation loss: 2.5688091888222644

Epoch: 6| Step: 11
Training loss: 2.5812063217163086
Validation loss: 2.570141605151597

Epoch: 6| Step: 12
Training loss: 2.540680170059204
Validation loss: 2.5689498737294185

Epoch: 6| Step: 13
Training loss: 3.219125747680664
Validation loss: 2.570302055728051

Epoch: 73| Step: 0
Training loss: 2.8267714977264404
Validation loss: 2.5677640694443897

Epoch: 6| Step: 1
Training loss: 2.4895079135894775
Validation loss: 2.566210575001214

Epoch: 6| Step: 2
Training loss: 2.289818525314331
Validation loss: 2.5618947398278022

Epoch: 6| Step: 3
Training loss: 3.0073399543762207
Validation loss: 2.570627515034009

Epoch: 6| Step: 4
Training loss: 3.0906686782836914
Validation loss: 2.572534732921149

Epoch: 6| Step: 5
Training loss: 2.4317915439605713
Validation loss: 2.5718526455663864

Epoch: 6| Step: 6
Training loss: 2.4455456733703613
Validation loss: 2.584830391791559

Epoch: 6| Step: 7
Training loss: 3.753767490386963
Validation loss: 2.5831414499590473

Epoch: 6| Step: 8
Training loss: 2.203019618988037
Validation loss: 2.5895944410754788

Epoch: 6| Step: 9
Training loss: 2.8581666946411133
Validation loss: 2.5874437798735914

Epoch: 6| Step: 10
Training loss: 2.499398708343506
Validation loss: 2.5967231437724125

Epoch: 6| Step: 11
Training loss: 3.547821044921875
Validation loss: 2.598247928004111

Epoch: 6| Step: 12
Training loss: 2.4201910495758057
Validation loss: 2.5861549941442346

Epoch: 6| Step: 13
Training loss: 2.6762068271636963
Validation loss: 2.5944228172302246

Epoch: 74| Step: 0
Training loss: 1.9135559797286987
Validation loss: 2.589519941678611

Epoch: 6| Step: 1
Training loss: 2.6459789276123047
Validation loss: 2.5976028878201722

Epoch: 6| Step: 2
Training loss: 2.5041027069091797
Validation loss: 2.5786760237909134

Epoch: 6| Step: 3
Training loss: 2.342562198638916
Validation loss: 2.57179848353068

Epoch: 6| Step: 4
Training loss: 3.0162734985351562
Validation loss: 2.5635417097358295

Epoch: 6| Step: 5
Training loss: 2.9444761276245117
Validation loss: 2.560842360219648

Epoch: 6| Step: 6
Training loss: 2.449300765991211
Validation loss: 2.5565831456133115

Epoch: 6| Step: 7
Training loss: 3.2730579376220703
Validation loss: 2.556960541714904

Epoch: 6| Step: 8
Training loss: 3.0767300128936768
Validation loss: 2.557935268648209

Epoch: 6| Step: 9
Training loss: 2.58884334564209
Validation loss: 2.5583490633195445

Epoch: 6| Step: 10
Training loss: 3.5407986640930176
Validation loss: 2.5582822189536145

Epoch: 6| Step: 11
Training loss: 1.8379321098327637
Validation loss: 2.5606400300097722

Epoch: 6| Step: 12
Training loss: 3.561206102371216
Validation loss: 2.5632937082680325

Epoch: 6| Step: 13
Training loss: 2.459993362426758
Validation loss: 2.561101290487474

Epoch: 75| Step: 0
Training loss: 2.6674790382385254
Validation loss: 2.5640814483806653

Epoch: 6| Step: 1
Training loss: 2.468531370162964
Validation loss: 2.5629654699756252

Epoch: 6| Step: 2
Training loss: 3.7370083332061768
Validation loss: 2.5609855754401094

Epoch: 6| Step: 3
Training loss: 2.1428582668304443
Validation loss: 2.56282477994119

Epoch: 6| Step: 4
Training loss: 3.2018613815307617
Validation loss: 2.5626104749659055

Epoch: 6| Step: 5
Training loss: 3.2144923210144043
Validation loss: 2.562024942008398

Epoch: 6| Step: 6
Training loss: 3.3442862033843994
Validation loss: 2.5549642578248055

Epoch: 6| Step: 7
Training loss: 2.6881520748138428
Validation loss: 2.5574432649920062

Epoch: 6| Step: 8
Training loss: 2.994922161102295
Validation loss: 2.561232909079521

Epoch: 6| Step: 9
Training loss: 2.2872722148895264
Validation loss: 2.567571093959193

Epoch: 6| Step: 10
Training loss: 2.20625376701355
Validation loss: 2.5668203753809773

Epoch: 6| Step: 11
Training loss: 2.2343215942382812
Validation loss: 2.5691082785206456

Epoch: 6| Step: 12
Training loss: 2.3858208656311035
Validation loss: 2.5596720018694477

Epoch: 6| Step: 13
Training loss: 2.742372512817383
Validation loss: 2.555545776121078

Epoch: 76| Step: 0
Training loss: 3.642209768295288
Validation loss: 2.5560725196715324

Epoch: 6| Step: 1
Training loss: 2.6481995582580566
Validation loss: 2.5580883667033207

Epoch: 6| Step: 2
Training loss: 2.365880250930786
Validation loss: 2.555734444690007

Epoch: 6| Step: 3
Training loss: 3.081202507019043
Validation loss: 2.551895664584252

Epoch: 6| Step: 4
Training loss: 2.898613214492798
Validation loss: 2.550185780371389

Epoch: 6| Step: 5
Training loss: 2.3737518787384033
Validation loss: 2.5506474869225615

Epoch: 6| Step: 6
Training loss: 2.114370107650757
Validation loss: 2.548803767850322

Epoch: 6| Step: 7
Training loss: 3.3097381591796875
Validation loss: 2.5479812070887577

Epoch: 6| Step: 8
Training loss: 2.4733290672302246
Validation loss: 2.5498392325575634

Epoch: 6| Step: 9
Training loss: 2.6461660861968994
Validation loss: 2.5482309633685696

Epoch: 6| Step: 10
Training loss: 2.4138381481170654
Validation loss: 2.547974217322565

Epoch: 6| Step: 11
Training loss: 2.697831153869629
Validation loss: 2.5522878041831394

Epoch: 6| Step: 12
Training loss: 2.798570156097412
Validation loss: 2.5503703189152542

Epoch: 6| Step: 13
Training loss: 2.824413776397705
Validation loss: 2.547557569319202

Epoch: 77| Step: 0
Training loss: 3.002899169921875
Validation loss: 2.560989256828062

Epoch: 6| Step: 1
Training loss: 1.7792086601257324
Validation loss: 2.553732664354386

Epoch: 6| Step: 2
Training loss: 2.854308843612671
Validation loss: 2.553802195415702

Epoch: 6| Step: 3
Training loss: 3.099576473236084
Validation loss: 2.5546995491109867

Epoch: 6| Step: 4
Training loss: 2.890498638153076
Validation loss: 2.5476553414457586

Epoch: 6| Step: 5
Training loss: 2.6917080879211426
Validation loss: 2.5490667332885084

Epoch: 6| Step: 6
Training loss: 2.4553980827331543
Validation loss: 2.550776030427666

Epoch: 6| Step: 7
Training loss: 2.3637499809265137
Validation loss: 2.5489968381902224

Epoch: 6| Step: 8
Training loss: 2.702660083770752
Validation loss: 2.548868038321054

Epoch: 6| Step: 9
Training loss: 3.3376340866088867
Validation loss: 2.548321585501394

Epoch: 6| Step: 10
Training loss: 3.019868850708008
Validation loss: 2.5475107546775573

Epoch: 6| Step: 11
Training loss: 2.248164176940918
Validation loss: 2.5436175510447514

Epoch: 6| Step: 12
Training loss: 3.2076473236083984
Validation loss: 2.5426733621986966

Epoch: 6| Step: 13
Training loss: 2.2863430976867676
Validation loss: 2.5402672188256377

Epoch: 78| Step: 0
Training loss: 2.7927558422088623
Validation loss: 2.5433022386284283

Epoch: 6| Step: 1
Training loss: 3.146874189376831
Validation loss: 2.5410499957300003

Epoch: 6| Step: 2
Training loss: 2.8158555030822754
Validation loss: 2.5412430788881037

Epoch: 6| Step: 3
Training loss: 2.793391704559326
Validation loss: 2.5405279051872993

Epoch: 6| Step: 4
Training loss: 1.8553916215896606
Validation loss: 2.545576262217696

Epoch: 6| Step: 5
Training loss: 2.2930426597595215
Validation loss: 2.5407411923972507

Epoch: 6| Step: 6
Training loss: 3.0826573371887207
Validation loss: 2.543463881297778

Epoch: 6| Step: 7
Training loss: 2.5113368034362793
Validation loss: 2.5455020140576106

Epoch: 6| Step: 8
Training loss: 2.245936393737793
Validation loss: 2.549685667919856

Epoch: 6| Step: 9
Training loss: 3.291637897491455
Validation loss: 2.5482425279514764

Epoch: 6| Step: 10
Training loss: 2.7473435401916504
Validation loss: 2.5479602070264917

Epoch: 6| Step: 11
Training loss: 2.656221866607666
Validation loss: 2.5588176250457764

Epoch: 6| Step: 12
Training loss: 2.9631240367889404
Validation loss: 2.5621848901112876

Epoch: 6| Step: 13
Training loss: 3.058035373687744
Validation loss: 2.5668879939663793

Epoch: 79| Step: 0
Training loss: 2.6654052734375
Validation loss: 2.5682281063449

Epoch: 6| Step: 1
Training loss: 2.7367210388183594
Validation loss: 2.5608448290055796

Epoch: 6| Step: 2
Training loss: 2.733081340789795
Validation loss: 2.5541301773440455

Epoch: 6| Step: 3
Training loss: 2.8895602226257324
Validation loss: 2.5450043960284163

Epoch: 6| Step: 4
Training loss: 3.1633188724517822
Validation loss: 2.5451278045613277

Epoch: 6| Step: 5
Training loss: 2.647052049636841
Validation loss: 2.5411365006559636

Epoch: 6| Step: 6
Training loss: 2.7862634658813477
Validation loss: 2.54840503456772

Epoch: 6| Step: 7
Training loss: 1.7958331108093262
Validation loss: 2.5577880028755433

Epoch: 6| Step: 8
Training loss: 3.1983461380004883
Validation loss: 2.5583609432302494

Epoch: 6| Step: 9
Training loss: 2.9706997871398926
Validation loss: 2.552224010549566

Epoch: 6| Step: 10
Training loss: 2.3900299072265625
Validation loss: 2.5478619119172454

Epoch: 6| Step: 11
Training loss: 2.1143457889556885
Validation loss: 2.5413862787267214

Epoch: 6| Step: 12
Training loss: 3.313241481781006
Validation loss: 2.537540284536218

Epoch: 6| Step: 13
Training loss: 2.6170153617858887
Validation loss: 2.533806857242379

Epoch: 80| Step: 0
Training loss: 3.077672004699707
Validation loss: 2.5394005390905563

Epoch: 6| Step: 1
Training loss: 2.1770870685577393
Validation loss: 2.5375656081784155

Epoch: 6| Step: 2
Training loss: 3.976790428161621
Validation loss: 2.541190719091764

Epoch: 6| Step: 3
Training loss: 2.3876867294311523
Validation loss: 2.54024266171199

Epoch: 6| Step: 4
Training loss: 2.1640377044677734
Validation loss: 2.536855507922429

Epoch: 6| Step: 5
Training loss: 2.4791035652160645
Validation loss: 2.538774715956821

Epoch: 6| Step: 6
Training loss: 2.418341636657715
Validation loss: 2.533385110157792

Epoch: 6| Step: 7
Training loss: 2.538003921508789
Validation loss: 2.5357482407682683

Epoch: 6| Step: 8
Training loss: 2.3857288360595703
Validation loss: 2.5407593557911534

Epoch: 6| Step: 9
Training loss: 2.6013171672821045
Validation loss: 2.5378307552747827

Epoch: 6| Step: 10
Training loss: 2.760922431945801
Validation loss: 2.5329550927685154

Epoch: 6| Step: 11
Training loss: 2.870352268218994
Validation loss: 2.530889006071193

Epoch: 6| Step: 12
Training loss: 2.8604369163513184
Validation loss: 2.5311999910621235

Epoch: 6| Step: 13
Training loss: 3.8775546550750732
Validation loss: 2.5348553965168614

Epoch: 81| Step: 0
Training loss: 3.1329894065856934
Validation loss: 2.5395114178298623

Epoch: 6| Step: 1
Training loss: 3.2491817474365234
Validation loss: 2.560768629914971

Epoch: 6| Step: 2
Training loss: 2.7990424633026123
Validation loss: 2.5708189984803558

Epoch: 6| Step: 3
Training loss: 2.8956027030944824
Validation loss: 2.5927073878626667

Epoch: 6| Step: 4
Training loss: 1.6563100814819336
Validation loss: 2.5950224579021497

Epoch: 6| Step: 5
Training loss: 2.664327621459961
Validation loss: 2.600534969760526

Epoch: 6| Step: 6
Training loss: 2.16926908493042
Validation loss: 2.5978198974363265

Epoch: 6| Step: 7
Training loss: 3.661944627761841
Validation loss: 2.5947576274154005

Epoch: 6| Step: 8
Training loss: 2.1157748699188232
Validation loss: 2.585177542060934

Epoch: 6| Step: 9
Training loss: 2.7176713943481445
Validation loss: 2.5551498961705033

Epoch: 6| Step: 10
Training loss: 2.7510881423950195
Validation loss: 2.5414779006793933

Epoch: 6| Step: 11
Training loss: 2.9047091007232666
Validation loss: 2.5260591301866757

Epoch: 6| Step: 12
Training loss: 2.9046411514282227
Validation loss: 2.5430635406124975

Epoch: 6| Step: 13
Training loss: 2.256549119949341
Validation loss: 2.5582488377889

Epoch: 82| Step: 0
Training loss: 3.081395149230957
Validation loss: 2.577075909542781

Epoch: 6| Step: 1
Training loss: 3.048816204071045
Validation loss: 2.588892275287259

Epoch: 6| Step: 2
Training loss: 2.664004325866699
Validation loss: 2.608726106664186

Epoch: 6| Step: 3
Training loss: 2.3978335857391357
Validation loss: 2.626831823779691

Epoch: 6| Step: 4
Training loss: 2.368208885192871
Validation loss: 2.60786295706226

Epoch: 6| Step: 5
Training loss: 3.2461652755737305
Validation loss: 2.590821102101316

Epoch: 6| Step: 6
Training loss: 3.0081276893615723
Validation loss: 2.5713881702833277

Epoch: 6| Step: 7
Training loss: 2.5026040077209473
Validation loss: 2.5530257737764748

Epoch: 6| Step: 8
Training loss: 2.8927998542785645
Validation loss: 2.5432911406281176

Epoch: 6| Step: 9
Training loss: 2.752225637435913
Validation loss: 2.5402697029934136

Epoch: 6| Step: 10
Training loss: 2.4895944595336914
Validation loss: 2.533048072168904

Epoch: 6| Step: 11
Training loss: 2.5103282928466797
Validation loss: 2.5245263320143505

Epoch: 6| Step: 12
Training loss: 2.9192123413085938
Validation loss: 2.532971159104378

Epoch: 6| Step: 13
Training loss: 2.387972354888916
Validation loss: 2.5508352992355183

Epoch: 83| Step: 0
Training loss: 2.6942410469055176
Validation loss: 2.5773760939157135

Epoch: 6| Step: 1
Training loss: 1.7858471870422363
Validation loss: 2.588119109471639

Epoch: 6| Step: 2
Training loss: 3.110726833343506
Validation loss: 2.566363383364934

Epoch: 6| Step: 3
Training loss: 2.9313995838165283
Validation loss: 2.56832056660806

Epoch: 6| Step: 4
Training loss: 2.535766363143921
Validation loss: 2.5509177202819497

Epoch: 6| Step: 5
Training loss: 2.5577445030212402
Validation loss: 2.5614781687336583

Epoch: 6| Step: 6
Training loss: 2.9244537353515625
Validation loss: 2.5489235437044533

Epoch: 6| Step: 7
Training loss: 2.670740842819214
Validation loss: 2.541011864139188

Epoch: 6| Step: 8
Training loss: 2.9903149604797363
Validation loss: 2.542941636936639

Epoch: 6| Step: 9
Training loss: 2.510316848754883
Validation loss: 2.5382842658668436

Epoch: 6| Step: 10
Training loss: 2.9855194091796875
Validation loss: 2.5240458134681947

Epoch: 6| Step: 11
Training loss: 2.1354658603668213
Validation loss: 2.52530086681407

Epoch: 6| Step: 12
Training loss: 3.343653678894043
Validation loss: 2.524088824948957

Epoch: 6| Step: 13
Training loss: 2.9105427265167236
Validation loss: 2.51845657953652

Epoch: 84| Step: 0
Training loss: 3.2031657695770264
Validation loss: 2.5201784718421196

Epoch: 6| Step: 1
Training loss: 2.2046267986297607
Validation loss: 2.518320814255745

Epoch: 6| Step: 2
Training loss: 3.05838680267334
Validation loss: 2.519034816372779

Epoch: 6| Step: 3
Training loss: 1.8974647521972656
Validation loss: 2.5198008168128228

Epoch: 6| Step: 4
Training loss: 1.9884533882141113
Validation loss: 2.519515370809904

Epoch: 6| Step: 5
Training loss: 3.382082939147949
Validation loss: 2.5220197734012397

Epoch: 6| Step: 6
Training loss: 2.884605646133423
Validation loss: 2.519584996725923

Epoch: 6| Step: 7
Training loss: 3.1018638610839844
Validation loss: 2.520458229126469

Epoch: 6| Step: 8
Training loss: 2.4853482246398926
Validation loss: 2.5168963657912387

Epoch: 6| Step: 9
Training loss: 2.6969785690307617
Validation loss: 2.518668577235232

Epoch: 6| Step: 10
Training loss: 2.7633280754089355
Validation loss: 2.5203539197162916

Epoch: 6| Step: 11
Training loss: 2.188455104827881
Validation loss: 2.526203429827126

Epoch: 6| Step: 12
Training loss: 2.967075824737549
Validation loss: 2.5293021971179592

Epoch: 6| Step: 13
Training loss: 3.2567102909088135
Validation loss: 2.5249072710673013

Epoch: 85| Step: 0
Training loss: 2.1904821395874023
Validation loss: 2.5221736995122765

Epoch: 6| Step: 1
Training loss: 2.75382661819458
Validation loss: 2.5219352527331282

Epoch: 6| Step: 2
Training loss: 2.9568874835968018
Validation loss: 2.5266484393868396

Epoch: 6| Step: 3
Training loss: 2.076918125152588
Validation loss: 2.529462165729974

Epoch: 6| Step: 4
Training loss: 2.726266622543335
Validation loss: 2.5212746230504846

Epoch: 6| Step: 5
Training loss: 2.9403390884399414
Validation loss: 2.522804488417923

Epoch: 6| Step: 6
Training loss: 2.7103164196014404
Validation loss: 2.5118820308357157

Epoch: 6| Step: 7
Training loss: 3.1480400562286377
Validation loss: 2.5109891019841677

Epoch: 6| Step: 8
Training loss: 3.17844820022583
Validation loss: 2.5119321269373738

Epoch: 6| Step: 9
Training loss: 2.2525105476379395
Validation loss: 2.516714567779213

Epoch: 6| Step: 10
Training loss: 2.7035298347473145
Validation loss: 2.5095480513829056

Epoch: 6| Step: 11
Training loss: 1.7127817869186401
Validation loss: 2.5104901867528118

Epoch: 6| Step: 12
Training loss: 3.345176935195923
Validation loss: 2.5131186644236245

Epoch: 6| Step: 13
Training loss: 3.4312477111816406
Validation loss: 2.5175272059696976

Epoch: 86| Step: 0
Training loss: 2.263382911682129
Validation loss: 2.5175146364396617

Epoch: 6| Step: 1
Training loss: 2.5647201538085938
Validation loss: 2.518521960063647

Epoch: 6| Step: 2
Training loss: 2.8983681201934814
Validation loss: 2.520210091785718

Epoch: 6| Step: 3
Training loss: 3.2014026641845703
Validation loss: 2.518407893437211

Epoch: 6| Step: 4
Training loss: 3.0340137481689453
Validation loss: 2.5160477263953096

Epoch: 6| Step: 5
Training loss: 3.2482995986938477
Validation loss: 2.5171944479788504

Epoch: 6| Step: 6
Training loss: 2.816180467605591
Validation loss: 2.5159302911450787

Epoch: 6| Step: 7
Training loss: 2.272392511367798
Validation loss: 2.515541809861378

Epoch: 6| Step: 8
Training loss: 3.110241413116455
Validation loss: 2.5123959510557112

Epoch: 6| Step: 9
Training loss: 2.337759494781494
Validation loss: 2.509985905821605

Epoch: 6| Step: 10
Training loss: 2.8307018280029297
Validation loss: 2.5098524221809964

Epoch: 6| Step: 11
Training loss: 2.9983205795288086
Validation loss: 2.50583319253819

Epoch: 6| Step: 12
Training loss: 2.2516489028930664
Validation loss: 2.51151039010735

Epoch: 6| Step: 13
Training loss: 1.5881739854812622
Validation loss: 2.511468246418943

Epoch: 87| Step: 0
Training loss: 3.1592211723327637
Validation loss: 2.508299622484433

Epoch: 6| Step: 1
Training loss: 2.3767356872558594
Validation loss: 2.508349254567136

Epoch: 6| Step: 2
Training loss: 2.7218775749206543
Validation loss: 2.5125955279155443

Epoch: 6| Step: 3
Training loss: 3.47861909866333
Validation loss: 2.513129606041857

Epoch: 6| Step: 4
Training loss: 1.7013394832611084
Validation loss: 2.5123341365527083

Epoch: 6| Step: 5
Training loss: 2.8194713592529297
Validation loss: 2.514684628414851

Epoch: 6| Step: 6
Training loss: 3.3277790546417236
Validation loss: 2.5090801203122703

Epoch: 6| Step: 7
Training loss: 2.0291335582733154
Validation loss: 2.5058383608377106

Epoch: 6| Step: 8
Training loss: 2.369011163711548
Validation loss: 2.5112314301152385

Epoch: 6| Step: 9
Training loss: 2.3387503623962402
Validation loss: 2.5205441700514926

Epoch: 6| Step: 10
Training loss: 2.88478422164917
Validation loss: 2.5214250959375852

Epoch: 6| Step: 11
Training loss: 2.6494626998901367
Validation loss: 2.5282988291914745

Epoch: 6| Step: 12
Training loss: 3.4885425567626953
Validation loss: 2.527779177952838

Epoch: 6| Step: 13
Training loss: 2.4303369522094727
Validation loss: 2.5218318175244074

Epoch: 88| Step: 0
Training loss: 2.4435839653015137
Validation loss: 2.5205090122838176

Epoch: 6| Step: 1
Training loss: 3.703335762023926
Validation loss: 2.519434062383508

Epoch: 6| Step: 2
Training loss: 2.411151170730591
Validation loss: 2.509329475382323

Epoch: 6| Step: 3
Training loss: 3.46032977104187
Validation loss: 2.509473813477383

Epoch: 6| Step: 4
Training loss: 2.4836978912353516
Validation loss: 2.5065524655003704

Epoch: 6| Step: 5
Training loss: 2.981271982192993
Validation loss: 2.508321649284773

Epoch: 6| Step: 6
Training loss: 2.7789340019226074
Validation loss: 2.50581512143535

Epoch: 6| Step: 7
Training loss: 2.529036521911621
Validation loss: 2.5061981472917783

Epoch: 6| Step: 8
Training loss: 2.9614124298095703
Validation loss: 2.503640010792722

Epoch: 6| Step: 9
Training loss: 2.326279878616333
Validation loss: 2.505573093250234

Epoch: 6| Step: 10
Training loss: 2.003495454788208
Validation loss: 2.5060195051213747

Epoch: 6| Step: 11
Training loss: 2.3801193237304688
Validation loss: 2.5015325289900585

Epoch: 6| Step: 12
Training loss: 2.6557767391204834
Validation loss: 2.508463321193572

Epoch: 6| Step: 13
Training loss: 2.5972213745117188
Validation loss: 2.5130094020597395

Epoch: 89| Step: 0
Training loss: 3.296682596206665
Validation loss: 2.512702639384936

Epoch: 6| Step: 1
Training loss: 1.8500313758850098
Validation loss: 2.5122664923309

Epoch: 6| Step: 2
Training loss: 2.592541217803955
Validation loss: 2.5123539560584613

Epoch: 6| Step: 3
Training loss: 2.18147611618042
Validation loss: 2.505772690619192

Epoch: 6| Step: 4
Training loss: 2.398348808288574
Validation loss: 2.503694772720337

Epoch: 6| Step: 5
Training loss: 3.5986108779907227
Validation loss: 2.5063659939714658

Epoch: 6| Step: 6
Training loss: 2.6857759952545166
Validation loss: 2.520353424933649

Epoch: 6| Step: 7
Training loss: 2.6339218616485596
Validation loss: 2.5281228737164567

Epoch: 6| Step: 8
Training loss: 1.9108487367630005
Validation loss: 2.528960189511699

Epoch: 6| Step: 9
Training loss: 3.3182694911956787
Validation loss: 2.5243098761445735

Epoch: 6| Step: 10
Training loss: 3.0410284996032715
Validation loss: 2.5222844052058395

Epoch: 6| Step: 11
Training loss: 2.732849597930908
Validation loss: 2.520462933407035

Epoch: 6| Step: 12
Training loss: 2.7941055297851562
Validation loss: 2.5178184919459845

Epoch: 6| Step: 13
Training loss: 2.9100520610809326
Validation loss: 2.514331269007857

Epoch: 90| Step: 0
Training loss: 2.8674659729003906
Validation loss: 2.510414633699643

Epoch: 6| Step: 1
Training loss: 2.133230686187744
Validation loss: 2.504875547142439

Epoch: 6| Step: 2
Training loss: 1.9892971515655518
Validation loss: 2.5015175368196223

Epoch: 6| Step: 3
Training loss: 2.912238359451294
Validation loss: 2.50246609410932

Epoch: 6| Step: 4
Training loss: 2.89007306098938
Validation loss: 2.505144670445432

Epoch: 6| Step: 5
Training loss: 3.1950173377990723
Validation loss: 2.5073996410574964

Epoch: 6| Step: 6
Training loss: 2.264822483062744
Validation loss: 2.506963404276038

Epoch: 6| Step: 7
Training loss: 2.8608450889587402
Validation loss: 2.5105041073214625

Epoch: 6| Step: 8
Training loss: 2.8149163722991943
Validation loss: 2.509149202736475

Epoch: 6| Step: 9
Training loss: 2.6598260402679443
Validation loss: 2.5226358675187632

Epoch: 6| Step: 10
Training loss: 2.823164939880371
Validation loss: 2.519089324499971

Epoch: 6| Step: 11
Training loss: 2.7664902210235596
Validation loss: 2.5168731340798

Epoch: 6| Step: 12
Training loss: 2.2829833030700684
Validation loss: 2.5104683855528473

Epoch: 6| Step: 13
Training loss: 3.4250993728637695
Validation loss: 2.5181621659186577

Epoch: 91| Step: 0
Training loss: 2.9173264503479004
Validation loss: 2.5218799678228234

Epoch: 6| Step: 1
Training loss: 2.632371187210083
Validation loss: 2.515282097683158

Epoch: 6| Step: 2
Training loss: 3.418813705444336
Validation loss: 2.5007835716329594

Epoch: 6| Step: 3
Training loss: 2.3285937309265137
Validation loss: 2.507896961704377

Epoch: 6| Step: 4
Training loss: 2.8520045280456543
Validation loss: 2.4959577283551617

Epoch: 6| Step: 5
Training loss: 1.8989737033843994
Validation loss: 2.493698463645033

Epoch: 6| Step: 6
Training loss: 3.1118197441101074
Validation loss: 2.491449443242883

Epoch: 6| Step: 7
Training loss: 2.6582865715026855
Validation loss: 2.492885930563814

Epoch: 6| Step: 8
Training loss: 2.7933335304260254
Validation loss: 2.491003820973058

Epoch: 6| Step: 9
Training loss: 2.6387600898742676
Validation loss: 2.4936995557559434

Epoch: 6| Step: 10
Training loss: 2.143420934677124
Validation loss: 2.4985992139385593

Epoch: 6| Step: 11
Training loss: 2.7632460594177246
Validation loss: 2.49478397574476

Epoch: 6| Step: 12
Training loss: 2.58034348487854
Validation loss: 2.489641281866258

Epoch: 6| Step: 13
Training loss: 3.261263132095337
Validation loss: 2.4894686488695044

Epoch: 92| Step: 0
Training loss: 1.8885643482208252
Validation loss: 2.4895540398936116

Epoch: 6| Step: 1
Training loss: 2.674297332763672
Validation loss: 2.4882431594274377

Epoch: 6| Step: 2
Training loss: 3.0158438682556152
Validation loss: 2.491207189457391

Epoch: 6| Step: 3
Training loss: 2.5595545768737793
Validation loss: 2.4921016411114763

Epoch: 6| Step: 4
Training loss: 2.1864027976989746
Validation loss: 2.4989431776026243

Epoch: 6| Step: 5
Training loss: 3.4800992012023926
Validation loss: 2.509785036886892

Epoch: 6| Step: 6
Training loss: 2.371654510498047
Validation loss: 2.541353487199353

Epoch: 6| Step: 7
Training loss: 2.9749393463134766
Validation loss: 2.5268099538741575

Epoch: 6| Step: 8
Training loss: 2.4278643131256104
Validation loss: 2.539031333820794

Epoch: 6| Step: 9
Training loss: 2.935624122619629
Validation loss: 2.523905390052385

Epoch: 6| Step: 10
Training loss: 3.3896899223327637
Validation loss: 2.5159811896662556

Epoch: 6| Step: 11
Training loss: 2.022545337677002
Validation loss: 2.505330249827395

Epoch: 6| Step: 12
Training loss: 2.701117992401123
Validation loss: 2.5015326110265588

Epoch: 6| Step: 13
Training loss: 3.418282985687256
Validation loss: 2.500026243989186

Epoch: 93| Step: 0
Training loss: 2.120633363723755
Validation loss: 2.4937820255115466

Epoch: 6| Step: 1
Training loss: 2.706763744354248
Validation loss: 2.4958740216429516

Epoch: 6| Step: 2
Training loss: 2.5624046325683594
Validation loss: 2.4911941200174312

Epoch: 6| Step: 3
Training loss: 1.9024654626846313
Validation loss: 2.493621510844077

Epoch: 6| Step: 4
Training loss: 3.4459118843078613
Validation loss: 2.49178070663124

Epoch: 6| Step: 5
Training loss: 2.6084227561950684
Validation loss: 2.491994462987428

Epoch: 6| Step: 6
Training loss: 3.0214710235595703
Validation loss: 2.489037339405347

Epoch: 6| Step: 7
Training loss: 2.691333055496216
Validation loss: 2.4902683304202173

Epoch: 6| Step: 8
Training loss: 2.4803659915924072
Validation loss: 2.4979264889993975

Epoch: 6| Step: 9
Training loss: 2.1981723308563232
Validation loss: 2.4914645277043825

Epoch: 6| Step: 10
Training loss: 3.0848894119262695
Validation loss: 2.4927624015397924

Epoch: 6| Step: 11
Training loss: 2.642634868621826
Validation loss: 2.4857948390386437

Epoch: 6| Step: 12
Training loss: 3.1845602989196777
Validation loss: 2.4887054530523156

Epoch: 6| Step: 13
Training loss: 3.0501084327697754
Validation loss: 2.486838153613511

Epoch: 94| Step: 0
Training loss: 2.248932361602783
Validation loss: 2.485450283173592

Epoch: 6| Step: 1
Training loss: 2.8515968322753906
Validation loss: 2.4833546018087738

Epoch: 6| Step: 2
Training loss: 2.6817493438720703
Validation loss: 2.4826298400919926

Epoch: 6| Step: 3
Training loss: 3.0997955799102783
Validation loss: 2.4829678176551737

Epoch: 6| Step: 4
Training loss: 3.7576661109924316
Validation loss: 2.4851503064555507

Epoch: 6| Step: 5
Training loss: 2.491831064224243
Validation loss: 2.4855373687641595

Epoch: 6| Step: 6
Training loss: 2.301215171813965
Validation loss: 2.486068061603013

Epoch: 6| Step: 7
Training loss: 1.7244824171066284
Validation loss: 2.488947586346698

Epoch: 6| Step: 8
Training loss: 2.3780832290649414
Validation loss: 2.4865637671562935

Epoch: 6| Step: 9
Training loss: 1.9657410383224487
Validation loss: 2.497598740362352

Epoch: 6| Step: 10
Training loss: 2.863656520843506
Validation loss: 2.4942512794207503

Epoch: 6| Step: 11
Training loss: 2.6001839637756348
Validation loss: 2.5039574843581005

Epoch: 6| Step: 12
Training loss: 3.0742008686065674
Validation loss: 2.5182152230252504

Epoch: 6| Step: 13
Training loss: 4.102529048919678
Validation loss: 2.524837629769438

Epoch: 95| Step: 0
Training loss: 3.4859557151794434
Validation loss: 2.538778333253758

Epoch: 6| Step: 1
Training loss: 2.9424123764038086
Validation loss: 2.5329172277963288

Epoch: 6| Step: 2
Training loss: 2.1933722496032715
Validation loss: 2.5397652579892065

Epoch: 6| Step: 3
Training loss: 2.68446946144104
Validation loss: 2.5266455911820933

Epoch: 6| Step: 4
Training loss: 1.7067128419876099
Validation loss: 2.5109683672587075

Epoch: 6| Step: 5
Training loss: 2.755134105682373
Validation loss: 2.5075946149005683

Epoch: 6| Step: 6
Training loss: 2.47607421875
Validation loss: 2.5028275187297533

Epoch: 6| Step: 7
Training loss: 3.9744224548339844
Validation loss: 2.4991202572340607

Epoch: 6| Step: 8
Training loss: 2.779632329940796
Validation loss: 2.4903041457617157

Epoch: 6| Step: 9
Training loss: 2.4340600967407227
Validation loss: 2.490027477664332

Epoch: 6| Step: 10
Training loss: 2.685065507888794
Validation loss: 2.4863673179380354

Epoch: 6| Step: 11
Training loss: 1.903217077255249
Validation loss: 2.4800726008671585

Epoch: 6| Step: 12
Training loss: 3.3552017211914062
Validation loss: 2.480243913588985

Epoch: 6| Step: 13
Training loss: 1.6672868728637695
Validation loss: 2.4774094422658286

Epoch: 96| Step: 0
Training loss: 3.1668334007263184
Validation loss: 2.4706623938775834

Epoch: 6| Step: 1
Training loss: 2.266660451889038
Validation loss: 2.477077455930812

Epoch: 6| Step: 2
Training loss: 2.1357803344726562
Validation loss: 2.479949612771311

Epoch: 6| Step: 3
Training loss: 3.6664364337921143
Validation loss: 2.482998619797409

Epoch: 6| Step: 4
Training loss: 2.741018772125244
Validation loss: 2.483464430737239

Epoch: 6| Step: 5
Training loss: 2.5203025341033936
Validation loss: 2.4786811080030215

Epoch: 6| Step: 6
Training loss: 2.5684499740600586
Validation loss: 2.4781560205644175

Epoch: 6| Step: 7
Training loss: 2.5734708309173584
Validation loss: 2.481896164596722

Epoch: 6| Step: 8
Training loss: 2.7243642807006836
Validation loss: 2.481209208888392

Epoch: 6| Step: 9
Training loss: 3.0614614486694336
Validation loss: 2.481377519587035

Epoch: 6| Step: 10
Training loss: 1.9968092441558838
Validation loss: 2.4808962627123763

Epoch: 6| Step: 11
Training loss: 2.1137261390686035
Validation loss: 2.4739401725030716

Epoch: 6| Step: 12
Training loss: 3.0890555381774902
Validation loss: 2.4698241397898686

Epoch: 6| Step: 13
Training loss: 3.237248659133911
Validation loss: 2.4709604581197104

Epoch: 97| Step: 0
Training loss: 2.26663875579834
Validation loss: 2.472998865189091

Epoch: 6| Step: 1
Training loss: 2.3654611110687256
Validation loss: 2.47649751170989

Epoch: 6| Step: 2
Training loss: 2.8652048110961914
Validation loss: 2.474149683470367

Epoch: 6| Step: 3
Training loss: 2.062011241912842
Validation loss: 2.478039582570394

Epoch: 6| Step: 4
Training loss: 3.126631021499634
Validation loss: 2.4746293572969336

Epoch: 6| Step: 5
Training loss: 3.27886962890625
Validation loss: 2.4767654019017376

Epoch: 6| Step: 6
Training loss: 3.0441343784332275
Validation loss: 2.4703377190456597

Epoch: 6| Step: 7
Training loss: 1.9220921993255615
Validation loss: 2.469005653935094

Epoch: 6| Step: 8
Training loss: 2.3060073852539062
Validation loss: 2.4715976535633044

Epoch: 6| Step: 9
Training loss: 2.2620983123779297
Validation loss: 2.4687204207143476

Epoch: 6| Step: 10
Training loss: 2.8682541847229004
Validation loss: 2.469477204866307

Epoch: 6| Step: 11
Training loss: 3.6375513076782227
Validation loss: 2.469852924346924

Epoch: 6| Step: 12
Training loss: 2.5016074180603027
Validation loss: 2.4674298327456237

Epoch: 6| Step: 13
Training loss: 3.251309394836426
Validation loss: 2.4723499949260423

Epoch: 98| Step: 0
Training loss: 2.5381999015808105
Validation loss: 2.4693263756331576

Epoch: 6| Step: 1
Training loss: 2.360757827758789
Validation loss: 2.4692113476414836

Epoch: 6| Step: 2
Training loss: 2.5478291511535645
Validation loss: 2.4688056438199935

Epoch: 6| Step: 3
Training loss: 3.0205092430114746
Validation loss: 2.4653254375662854

Epoch: 6| Step: 4
Training loss: 3.0762779712677
Validation loss: 2.471159237687306

Epoch: 6| Step: 5
Training loss: 2.3034539222717285
Validation loss: 2.466645425365817

Epoch: 6| Step: 6
Training loss: 1.85630464553833
Validation loss: 2.4676057472023913

Epoch: 6| Step: 7
Training loss: 3.2624716758728027
Validation loss: 2.468655217078424

Epoch: 6| Step: 8
Training loss: 2.2013111114501953
Validation loss: 2.4720430169054257

Epoch: 6| Step: 9
Training loss: 2.883711576461792
Validation loss: 2.46777013040358

Epoch: 6| Step: 10
Training loss: 2.3264691829681396
Validation loss: 2.470926848790979

Epoch: 6| Step: 11
Training loss: 2.909848213195801
Validation loss: 2.4699088424764652

Epoch: 6| Step: 12
Training loss: 3.090667724609375
Validation loss: 2.467919695761896

Epoch: 6| Step: 13
Training loss: 3.368253469467163
Validation loss: 2.47246382569754

Epoch: 99| Step: 0
Training loss: 2.8322603702545166
Validation loss: 2.4810907020363757

Epoch: 6| Step: 1
Training loss: 2.778855800628662
Validation loss: 2.4988877234920377

Epoch: 6| Step: 2
Training loss: 2.4641876220703125
Validation loss: 2.505346086717421

Epoch: 6| Step: 3
Training loss: 1.6915290355682373
Validation loss: 2.5116751117091023

Epoch: 6| Step: 4
Training loss: 2.588228702545166
Validation loss: 2.508321867194227

Epoch: 6| Step: 5
Training loss: 2.5230348110198975
Validation loss: 2.508947846710041

Epoch: 6| Step: 6
Training loss: 2.4770092964172363
Validation loss: 2.497352912861814

Epoch: 6| Step: 7
Training loss: 2.749884605407715
Validation loss: 2.4876609566391155

Epoch: 6| Step: 8
Training loss: 2.7703723907470703
Validation loss: 2.472764333089193

Epoch: 6| Step: 9
Training loss: 2.8901352882385254
Validation loss: 2.47288017888223

Epoch: 6| Step: 10
Training loss: 3.2356395721435547
Validation loss: 2.4866129108654556

Epoch: 6| Step: 11
Training loss: 3.1094648838043213
Validation loss: 2.488215510563184

Epoch: 6| Step: 12
Training loss: 2.52388072013855
Validation loss: 2.4827273225271576

Epoch: 6| Step: 13
Training loss: 3.400926351547241
Validation loss: 2.4776050865009265

Epoch: 100| Step: 0
Training loss: 3.3944759368896484
Validation loss: 2.470776475885863

Epoch: 6| Step: 1
Training loss: 3.0052132606506348
Validation loss: 2.464919883717773

Epoch: 6| Step: 2
Training loss: 2.1974549293518066
Validation loss: 2.4625094706012356

Epoch: 6| Step: 3
Training loss: 2.497236490249634
Validation loss: 2.460118252743957

Epoch: 6| Step: 4
Training loss: 3.026132583618164
Validation loss: 2.4621559740394674

Epoch: 6| Step: 5
Training loss: 2.8310117721557617
Validation loss: 2.4655269012656262

Epoch: 6| Step: 6
Training loss: 2.7914891242980957
Validation loss: 2.469468257760489

Epoch: 6| Step: 7
Training loss: 2.100989818572998
Validation loss: 2.4809271135637836

Epoch: 6| Step: 8
Training loss: 2.6649861335754395
Validation loss: 2.484522343963705

Epoch: 6| Step: 9
Training loss: 2.9579520225524902
Validation loss: 2.4881778686277327

Epoch: 6| Step: 10
Training loss: 2.727933168411255
Validation loss: 2.4944696477664414

Epoch: 6| Step: 11
Training loss: 2.3437838554382324
Validation loss: 2.4958421568716727

Epoch: 6| Step: 12
Training loss: 2.2904152870178223
Validation loss: 2.4914817425512497

Epoch: 6| Step: 13
Training loss: 2.4978742599487305
Validation loss: 2.5015674355209514

Epoch: 101| Step: 0
Training loss: 2.1987085342407227
Validation loss: 2.511101063861642

Epoch: 6| Step: 1
Training loss: 3.3171873092651367
Validation loss: 2.527138707458332

Epoch: 6| Step: 2
Training loss: 2.4087090492248535
Validation loss: 2.5338695228740735

Epoch: 6| Step: 3
Training loss: 2.4877352714538574
Validation loss: 2.524140663044427

Epoch: 6| Step: 4
Training loss: 2.854675531387329
Validation loss: 2.528394786260461

Epoch: 6| Step: 5
Training loss: 3.434014320373535
Validation loss: 2.5025340216134184

Epoch: 6| Step: 6
Training loss: 2.0102312564849854
Validation loss: 2.4914924560054654

Epoch: 6| Step: 7
Training loss: 2.6259045600891113
Validation loss: 2.4793557454180974

Epoch: 6| Step: 8
Training loss: 2.7797839641571045
Validation loss: 2.46941953064293

Epoch: 6| Step: 9
Training loss: 2.101879596710205
Validation loss: 2.4637414357995473

Epoch: 6| Step: 10
Training loss: 2.364380359649658
Validation loss: 2.4641283814625075

Epoch: 6| Step: 11
Training loss: 3.1666066646575928
Validation loss: 2.4652675556880173

Epoch: 6| Step: 12
Training loss: 3.1623337268829346
Validation loss: 2.461634397506714

Epoch: 6| Step: 13
Training loss: 2.5276670455932617
Validation loss: 2.459639560791754

Epoch: 102| Step: 0
Training loss: 2.8212358951568604
Validation loss: 2.4612629849423646

Epoch: 6| Step: 1
Training loss: 2.4225850105285645
Validation loss: 2.462625800922353

Epoch: 6| Step: 2
Training loss: 2.94319748878479
Validation loss: 2.4616559013243644

Epoch: 6| Step: 3
Training loss: 3.6368861198425293
Validation loss: 2.4624250729878745

Epoch: 6| Step: 4
Training loss: 3.009993553161621
Validation loss: 2.4601976179307505

Epoch: 6| Step: 5
Training loss: 2.4967567920684814
Validation loss: 2.4592534470301803

Epoch: 6| Step: 6
Training loss: 2.5120701789855957
Validation loss: 2.462829528316375

Epoch: 6| Step: 7
Training loss: 2.6135239601135254
Validation loss: 2.463251297191907

Epoch: 6| Step: 8
Training loss: 2.5092358589172363
Validation loss: 2.4647027215650006

Epoch: 6| Step: 9
Training loss: 2.142606258392334
Validation loss: 2.4655903667531986

Epoch: 6| Step: 10
Training loss: 1.9894416332244873
Validation loss: 2.4741619453635266

Epoch: 6| Step: 11
Training loss: 2.8452134132385254
Validation loss: 2.4973130456862913

Epoch: 6| Step: 12
Training loss: 2.393496036529541
Validation loss: 2.5088560222297587

Epoch: 6| Step: 13
Training loss: 3.1319284439086914
Validation loss: 2.545000309585243

Epoch: 103| Step: 0
Training loss: 2.937655448913574
Validation loss: 2.5526134916531142

Epoch: 6| Step: 1
Training loss: 3.2027149200439453
Validation loss: 2.5357263267681165

Epoch: 6| Step: 2
Training loss: 2.4140830039978027
Validation loss: 2.5185130193669307

Epoch: 6| Step: 3
Training loss: 2.847947597503662
Validation loss: 2.49241469752404

Epoch: 6| Step: 4
Training loss: 2.5838513374328613
Validation loss: 2.466690958187144

Epoch: 6| Step: 5
Training loss: 2.401501417160034
Validation loss: 2.4556946959546817

Epoch: 6| Step: 6
Training loss: 3.0046586990356445
Validation loss: 2.451820453008016

Epoch: 6| Step: 7
Training loss: 2.8553643226623535
Validation loss: 2.4556799960392777

Epoch: 6| Step: 8
Training loss: 2.38310170173645
Validation loss: 2.4676057561751334

Epoch: 6| Step: 9
Training loss: 2.35823130607605
Validation loss: 2.4740709002299974

Epoch: 6| Step: 10
Training loss: 2.7937569618225098
Validation loss: 2.480337227544477

Epoch: 6| Step: 11
Training loss: 3.3173668384552
Validation loss: 2.47701693606633

Epoch: 6| Step: 12
Training loss: 2.5466575622558594
Validation loss: 2.476245759635843

Epoch: 6| Step: 13
Training loss: 1.3922803401947021
Validation loss: 2.4713839048980386

Epoch: 104| Step: 0
Training loss: 2.4615728855133057
Validation loss: 2.4665079860277075

Epoch: 6| Step: 1
Training loss: 2.7408218383789062
Validation loss: 2.461479098566117

Epoch: 6| Step: 2
Training loss: 2.869018316268921
Validation loss: 2.4605740706125894

Epoch: 6| Step: 3
Training loss: 3.358414888381958
Validation loss: 2.4563425023068666

Epoch: 6| Step: 4
Training loss: 2.6434543132781982
Validation loss: 2.4570856401997228

Epoch: 6| Step: 5
Training loss: 2.450288772583008
Validation loss: 2.45608695860832

Epoch: 6| Step: 6
Training loss: 2.178454637527466
Validation loss: 2.4538135759292112

Epoch: 6| Step: 7
Training loss: 2.4906249046325684
Validation loss: 2.4594613787948445

Epoch: 6| Step: 8
Training loss: 2.565640449523926
Validation loss: 2.4737558005958475

Epoch: 6| Step: 9
Training loss: 2.928250789642334
Validation loss: 2.4988410267778622

Epoch: 6| Step: 10
Training loss: 2.3481011390686035
Validation loss: 2.5039551501633017

Epoch: 6| Step: 11
Training loss: 2.4648537635803223
Validation loss: 2.5068256803738174

Epoch: 6| Step: 12
Training loss: 3.1950886249542236
Validation loss: 2.5057385172895206

Epoch: 6| Step: 13
Training loss: 2.8622899055480957
Validation loss: 2.4988922278086343

Epoch: 105| Step: 0
Training loss: 2.5475656986236572
Validation loss: 2.4934140046437583

Epoch: 6| Step: 1
Training loss: 3.1138410568237305
Validation loss: 2.467990841916812

Epoch: 6| Step: 2
Training loss: 1.9883995056152344
Validation loss: 2.4497302245068293

Epoch: 6| Step: 3
Training loss: 3.2300548553466797
Validation loss: 2.4499945435472714

Epoch: 6| Step: 4
Training loss: 3.1558210849761963
Validation loss: 2.4533688919518584

Epoch: 6| Step: 5
Training loss: 2.609705924987793
Validation loss: 2.4529309708585023

Epoch: 6| Step: 6
Training loss: 2.8964171409606934
Validation loss: 2.4540598161758913

Epoch: 6| Step: 7
Training loss: 1.8419946432113647
Validation loss: 2.4537220462676017

Epoch: 6| Step: 8
Training loss: 2.5352258682250977
Validation loss: 2.453220352049797

Epoch: 6| Step: 9
Training loss: 2.83504056930542
Validation loss: 2.45153183321799

Epoch: 6| Step: 10
Training loss: 2.425886392593384
Validation loss: 2.4561119925591255

Epoch: 6| Step: 11
Training loss: 2.462590217590332
Validation loss: 2.454482196479715

Epoch: 6| Step: 12
Training loss: 3.137016773223877
Validation loss: 2.4621219071008826

Epoch: 6| Step: 13
Training loss: 2.5723063945770264
Validation loss: 2.45577145648259

Epoch: 106| Step: 0
Training loss: 2.8451461791992188
Validation loss: 2.467492308667911

Epoch: 6| Step: 1
Training loss: 2.3119959831237793
Validation loss: 2.475566820431781

Epoch: 6| Step: 2
Training loss: 2.932429790496826
Validation loss: 2.4828496261309554

Epoch: 6| Step: 3
Training loss: 2.554248332977295
Validation loss: 2.4845611305646997

Epoch: 6| Step: 4
Training loss: 2.904003858566284
Validation loss: 2.4804613897877354

Epoch: 6| Step: 5
Training loss: 3.4261226654052734
Validation loss: 2.4858078982240412

Epoch: 6| Step: 6
Training loss: 2.426624298095703
Validation loss: 2.5032135491730063

Epoch: 6| Step: 7
Training loss: 2.8088974952697754
Validation loss: 2.493512753517397

Epoch: 6| Step: 8
Training loss: 1.4906818866729736
Validation loss: 2.5000845104135494

Epoch: 6| Step: 9
Training loss: 2.941816806793213
Validation loss: 2.4972519284935406

Epoch: 6| Step: 10
Training loss: 3.2306032180786133
Validation loss: 2.4892550386408323

Epoch: 6| Step: 11
Training loss: 1.7486295700073242
Validation loss: 2.49739940961202

Epoch: 6| Step: 12
Training loss: 2.601072311401367
Validation loss: 2.487938229755689

Epoch: 6| Step: 13
Training loss: 3.536036968231201
Validation loss: 2.4831642207279

Epoch: 107| Step: 0
Training loss: 3.3092758655548096
Validation loss: 2.4733416341966197

Epoch: 6| Step: 1
Training loss: 2.8867347240448
Validation loss: 2.473852321665774

Epoch: 6| Step: 2
Training loss: 2.856614828109741
Validation loss: 2.471056112679102

Epoch: 6| Step: 3
Training loss: 2.8600566387176514
Validation loss: 2.46465818343624

Epoch: 6| Step: 4
Training loss: 2.294041156768799
Validation loss: 2.464599496574812

Epoch: 6| Step: 5
Training loss: 2.2271814346313477
Validation loss: 2.46005755342463

Epoch: 6| Step: 6
Training loss: 2.038443088531494
Validation loss: 2.4617547065980974

Epoch: 6| Step: 7
Training loss: 2.4963622093200684
Validation loss: 2.4582118590672812

Epoch: 6| Step: 8
Training loss: 2.8163046836853027
Validation loss: 2.4583265960857434

Epoch: 6| Step: 9
Training loss: 3.443605899810791
Validation loss: 2.4544270474423646

Epoch: 6| Step: 10
Training loss: 2.7025644779205322
Validation loss: 2.4492359443377425

Epoch: 6| Step: 11
Training loss: 2.605363130569458
Validation loss: 2.4543116682319233

Epoch: 6| Step: 12
Training loss: 2.7591803073883057
Validation loss: 2.4484371395521265

Epoch: 6| Step: 13
Training loss: 1.5080386400222778
Validation loss: 2.4418974538003244

Epoch: 108| Step: 0
Training loss: 2.224316120147705
Validation loss: 2.4444707080882084

Epoch: 6| Step: 1
Training loss: 2.437394618988037
Validation loss: 2.4423218234892814

Epoch: 6| Step: 2
Training loss: 2.715529441833496
Validation loss: 2.440804822470552

Epoch: 6| Step: 3
Training loss: 2.2964608669281006
Validation loss: 2.4392430218317176

Epoch: 6| Step: 4
Training loss: 2.403196334838867
Validation loss: 2.444467604801219

Epoch: 6| Step: 5
Training loss: 2.9256162643432617
Validation loss: 2.443390146378548

Epoch: 6| Step: 6
Training loss: 2.9493842124938965
Validation loss: 2.4459321447598037

Epoch: 6| Step: 7
Training loss: 3.5289320945739746
Validation loss: 2.444387338494742

Epoch: 6| Step: 8
Training loss: 2.792809247970581
Validation loss: 2.4438701291238107

Epoch: 6| Step: 9
Training loss: 2.282186508178711
Validation loss: 2.440799190152076

Epoch: 6| Step: 10
Training loss: 2.78177547454834
Validation loss: 2.44440266137482

Epoch: 6| Step: 11
Training loss: 2.397808790206909
Validation loss: 2.440214039177023

Epoch: 6| Step: 12
Training loss: 3.3655872344970703
Validation loss: 2.4380587634219917

Epoch: 6| Step: 13
Training loss: 1.713970422744751
Validation loss: 2.4385801438362367

Epoch: 109| Step: 0
Training loss: 2.5536038875579834
Validation loss: 2.4371269236328783

Epoch: 6| Step: 1
Training loss: 2.6023850440979004
Validation loss: 2.439566958335138

Epoch: 6| Step: 2
Training loss: 2.310062885284424
Validation loss: 2.4375274924821753

Epoch: 6| Step: 3
Training loss: 2.799394130706787
Validation loss: 2.437243641063731

Epoch: 6| Step: 4
Training loss: 2.345269203186035
Validation loss: 2.438539356313726

Epoch: 6| Step: 5
Training loss: 2.2947287559509277
Validation loss: 2.441946557773057

Epoch: 6| Step: 6
Training loss: 2.829725742340088
Validation loss: 2.4483539981226765

Epoch: 6| Step: 7
Training loss: 2.890486717224121
Validation loss: 2.4511039436504407

Epoch: 6| Step: 8
Training loss: 2.1065776348114014
Validation loss: 2.4536734627139185

Epoch: 6| Step: 9
Training loss: 2.7296853065490723
Validation loss: 2.458398237023302

Epoch: 6| Step: 10
Training loss: 3.6134753227233887
Validation loss: 2.4627214195907756

Epoch: 6| Step: 11
Training loss: 2.72951078414917
Validation loss: 2.450042042680966

Epoch: 6| Step: 12
Training loss: 2.8363912105560303
Validation loss: 2.447949488957723

Epoch: 6| Step: 13
Training loss: 2.387709617614746
Validation loss: 2.447338750285487

Epoch: 110| Step: 0
Training loss: 2.5636115074157715
Validation loss: 2.45130060308723

Epoch: 6| Step: 1
Training loss: 2.5221643447875977
Validation loss: 2.4447822545164373

Epoch: 6| Step: 2
Training loss: 2.8557395935058594
Validation loss: 2.443544146835163

Epoch: 6| Step: 3
Training loss: 3.2204067707061768
Validation loss: 2.433352821616716

Epoch: 6| Step: 4
Training loss: 2.7609221935272217
Validation loss: 2.434675826821276

Epoch: 6| Step: 5
Training loss: 2.2450265884399414
Validation loss: 2.433194004079347

Epoch: 6| Step: 6
Training loss: 2.3705711364746094
Validation loss: 2.4316392560159006

Epoch: 6| Step: 7
Training loss: 2.3580245971679688
Validation loss: 2.431536300207979

Epoch: 6| Step: 8
Training loss: 2.7812299728393555
Validation loss: 2.4310042986305813

Epoch: 6| Step: 9
Training loss: 2.5901668071746826
Validation loss: 2.427638748640655

Epoch: 6| Step: 10
Training loss: 2.7194876670837402
Validation loss: 2.431957785801221

Epoch: 6| Step: 11
Training loss: 3.4633731842041016
Validation loss: 2.4269588378167923

Epoch: 6| Step: 12
Training loss: 2.246993064880371
Validation loss: 2.425371498189947

Epoch: 6| Step: 13
Training loss: 2.382274627685547
Validation loss: 2.427227343282392

Epoch: 111| Step: 0
Training loss: 2.6327083110809326
Validation loss: 2.4310049703044276

Epoch: 6| Step: 1
Training loss: 3.4926133155822754
Validation loss: 2.4288616667511644

Epoch: 6| Step: 2
Training loss: 1.483353614807129
Validation loss: 2.4330122881038214

Epoch: 6| Step: 3
Training loss: 3.21128511428833
Validation loss: 2.436320509961856

Epoch: 6| Step: 4
Training loss: 1.8993794918060303
Validation loss: 2.4294184664244294

Epoch: 6| Step: 5
Training loss: 2.8747639656066895
Validation loss: 2.433346563769925

Epoch: 6| Step: 6
Training loss: 3.039409637451172
Validation loss: 2.434553800090667

Epoch: 6| Step: 7
Training loss: 3.397919178009033
Validation loss: 2.432890740774011

Epoch: 6| Step: 8
Training loss: 2.6106691360473633
Validation loss: 2.4344651955430225

Epoch: 6| Step: 9
Training loss: 2.5052552223205566
Validation loss: 2.4404983071870703

Epoch: 6| Step: 10
Training loss: 2.3580551147460938
Validation loss: 2.443574610576835

Epoch: 6| Step: 11
Training loss: 3.25248384475708
Validation loss: 2.435648718187886

Epoch: 6| Step: 12
Training loss: 2.006190299987793
Validation loss: 2.441727661317395

Epoch: 6| Step: 13
Training loss: 1.956540584564209
Validation loss: 2.437328025858889

Epoch: 112| Step: 0
Training loss: 3.295698881149292
Validation loss: 2.435605405479349

Epoch: 6| Step: 1
Training loss: 2.426701068878174
Validation loss: 2.4371476686129006

Epoch: 6| Step: 2
Training loss: 2.6825761795043945
Validation loss: 2.4344534335597867

Epoch: 6| Step: 3
Training loss: 3.317728042602539
Validation loss: 2.429412559796405

Epoch: 6| Step: 4
Training loss: 2.75831937789917
Validation loss: 2.433396359925629

Epoch: 6| Step: 5
Training loss: 2.6518869400024414
Validation loss: 2.435852484036517

Epoch: 6| Step: 6
Training loss: 2.6245250701904297
Validation loss: 2.4353233691184752

Epoch: 6| Step: 7
Training loss: 3.352932929992676
Validation loss: 2.4412442561118834

Epoch: 6| Step: 8
Training loss: 2.548790216445923
Validation loss: 2.444847640170846

Epoch: 6| Step: 9
Training loss: 2.0894148349761963
Validation loss: 2.441448644925189

Epoch: 6| Step: 10
Training loss: 2.670121431350708
Validation loss: 2.450033974903886

Epoch: 6| Step: 11
Training loss: 2.077852249145508
Validation loss: 2.4421954360059512

Epoch: 6| Step: 12
Training loss: 1.9915392398834229
Validation loss: 2.4461014373328096

Epoch: 6| Step: 13
Training loss: 2.5035619735717773
Validation loss: 2.449094949230071

Epoch: 113| Step: 0
Training loss: 2.6656556129455566
Validation loss: 2.447245987512732

Epoch: 6| Step: 1
Training loss: 2.8595361709594727
Validation loss: 2.451455421345208

Epoch: 6| Step: 2
Training loss: 2.8704357147216797
Validation loss: 2.454637953030166

Epoch: 6| Step: 3
Training loss: 2.4755940437316895
Validation loss: 2.450808258466823

Epoch: 6| Step: 4
Training loss: 2.076796531677246
Validation loss: 2.447744630998181

Epoch: 6| Step: 5
Training loss: 3.4908995628356934
Validation loss: 2.4705545415160475

Epoch: 6| Step: 6
Training loss: 2.853238344192505
Validation loss: 2.4681210569156113

Epoch: 6| Step: 7
Training loss: 2.1859865188598633
Validation loss: 2.4597389903119815

Epoch: 6| Step: 8
Training loss: 1.831022024154663
Validation loss: 2.4464372460560133

Epoch: 6| Step: 9
Training loss: 2.444988489151001
Validation loss: 2.4420984944989605

Epoch: 6| Step: 10
Training loss: 2.9182281494140625
Validation loss: 2.4335114007355063

Epoch: 6| Step: 11
Training loss: 3.0294198989868164
Validation loss: 2.42768721683051

Epoch: 6| Step: 12
Training loss: 2.7533185482025146
Validation loss: 2.4285560884783344

Epoch: 6| Step: 13
Training loss: 2.7143373489379883
Validation loss: 2.4281753468257126

Epoch: 114| Step: 0
Training loss: 3.1599695682525635
Validation loss: 2.4256349558471353

Epoch: 6| Step: 1
Training loss: 3.039503335952759
Validation loss: 2.426552027784368

Epoch: 6| Step: 2
Training loss: 2.1055917739868164
Validation loss: 2.430537382761637

Epoch: 6| Step: 3
Training loss: 2.748537540435791
Validation loss: 2.4287432637265933

Epoch: 6| Step: 4
Training loss: 3.5455589294433594
Validation loss: 2.429052201650476

Epoch: 6| Step: 5
Training loss: 2.521547555923462
Validation loss: 2.435373665184103

Epoch: 6| Step: 6
Training loss: 1.8653446435928345
Validation loss: 2.434204859118308

Epoch: 6| Step: 7
Training loss: 3.4786758422851562
Validation loss: 2.4324034183256087

Epoch: 6| Step: 8
Training loss: 2.272390842437744
Validation loss: 2.4283428448502735

Epoch: 6| Step: 9
Training loss: 1.9147264957427979
Validation loss: 2.426873737765897

Epoch: 6| Step: 10
Training loss: 2.9976606369018555
Validation loss: 2.4330727874591784

Epoch: 6| Step: 11
Training loss: 2.450204372406006
Validation loss: 2.4349691996010403

Epoch: 6| Step: 12
Training loss: 2.7738916873931885
Validation loss: 2.449023513383763

Epoch: 6| Step: 13
Training loss: 1.7789194583892822
Validation loss: 2.4585325025743052

Epoch: 115| Step: 0
Training loss: 2.0434412956237793
Validation loss: 2.475267143659694

Epoch: 6| Step: 1
Training loss: 2.9309654235839844
Validation loss: 2.4994537240715435

Epoch: 6| Step: 2
Training loss: 3.504744052886963
Validation loss: 2.5064334715566328

Epoch: 6| Step: 3
Training loss: 2.4416985511779785
Validation loss: 2.4776420490716093

Epoch: 6| Step: 4
Training loss: 2.861104965209961
Validation loss: 2.4584024913849367

Epoch: 6| Step: 5
Training loss: 2.972163200378418
Validation loss: 2.44161715046052

Epoch: 6| Step: 6
Training loss: 2.4019250869750977
Validation loss: 2.4331380500588367

Epoch: 6| Step: 7
Training loss: 2.5023245811462402
Validation loss: 2.4296382909180014

Epoch: 6| Step: 8
Training loss: 2.8394222259521484
Validation loss: 2.4237129201171217

Epoch: 6| Step: 9
Training loss: 2.6605541706085205
Validation loss: 2.4314577682043916

Epoch: 6| Step: 10
Training loss: 2.103860855102539
Validation loss: 2.4402283750554568

Epoch: 6| Step: 11
Training loss: 3.334641695022583
Validation loss: 2.446134187841928

Epoch: 6| Step: 12
Training loss: 2.2189414501190186
Validation loss: 2.446673477849653

Epoch: 6| Step: 13
Training loss: 2.414030075073242
Validation loss: 2.4453616270454983

Epoch: 116| Step: 0
Training loss: 2.547337055206299
Validation loss: 2.4431229534969536

Epoch: 6| Step: 1
Training loss: 2.9175846576690674
Validation loss: 2.435109676853303

Epoch: 6| Step: 2
Training loss: 3.272477865219116
Validation loss: 2.4294361965630644

Epoch: 6| Step: 3
Training loss: 2.7086076736450195
Validation loss: 2.4221922223285963

Epoch: 6| Step: 4
Training loss: 2.256047487258911
Validation loss: 2.4305804391061105

Epoch: 6| Step: 5
Training loss: 2.442025661468506
Validation loss: 2.4243236408438733

Epoch: 6| Step: 6
Training loss: 2.4720873832702637
Validation loss: 2.4342865405544156

Epoch: 6| Step: 7
Training loss: 3.0110831260681152
Validation loss: 2.4364959552723873

Epoch: 6| Step: 8
Training loss: 2.6932907104492188
Validation loss: 2.446403818745767

Epoch: 6| Step: 9
Training loss: 2.3558692932128906
Validation loss: 2.4533447322025093

Epoch: 6| Step: 10
Training loss: 1.8154805898666382
Validation loss: 2.4500353041515557

Epoch: 6| Step: 11
Training loss: 3.137873649597168
Validation loss: 2.43322604702365

Epoch: 6| Step: 12
Training loss: 2.397829532623291
Validation loss: 2.440959592019358

Epoch: 6| Step: 13
Training loss: 3.284698486328125
Validation loss: 2.425025716904671

Epoch: 117| Step: 0
Training loss: 3.1442253589630127
Validation loss: 2.4185594948389197

Epoch: 6| Step: 1
Training loss: 2.60945200920105
Validation loss: 2.42012160055099

Epoch: 6| Step: 2
Training loss: 2.32663631439209
Validation loss: 2.4096835941396733

Epoch: 6| Step: 3
Training loss: 2.912816047668457
Validation loss: 2.4106760460843324

Epoch: 6| Step: 4
Training loss: 2.0487070083618164
Validation loss: 2.412206995871759

Epoch: 6| Step: 5
Training loss: 2.5622668266296387
Validation loss: 2.4154152844541814

Epoch: 6| Step: 6
Training loss: 2.4723949432373047
Validation loss: 2.412989995812857

Epoch: 6| Step: 7
Training loss: 2.2788610458374023
Validation loss: 2.4115835594874557

Epoch: 6| Step: 8
Training loss: 2.383601427078247
Validation loss: 2.408839753879014

Epoch: 6| Step: 9
Training loss: 3.323958158493042
Validation loss: 2.412936543905607

Epoch: 6| Step: 10
Training loss: 2.1156930923461914
Validation loss: 2.413791552666695

Epoch: 6| Step: 11
Training loss: 2.3870046138763428
Validation loss: 2.4141274677809847

Epoch: 6| Step: 12
Training loss: 3.0881638526916504
Validation loss: 2.421318336199689

Epoch: 6| Step: 13
Training loss: 3.582366943359375
Validation loss: 2.4213403732545915

Epoch: 118| Step: 0
Training loss: 2.645144462585449
Validation loss: 2.4335703388337167

Epoch: 6| Step: 1
Training loss: 2.100827693939209
Validation loss: 2.4371922118689424

Epoch: 6| Step: 2
Training loss: 3.2815566062927246
Validation loss: 2.452678608637984

Epoch: 6| Step: 3
Training loss: 2.877467155456543
Validation loss: 2.454468034928845

Epoch: 6| Step: 4
Training loss: 2.4929561614990234
Validation loss: 2.4561396337324575

Epoch: 6| Step: 5
Training loss: 2.890519618988037
Validation loss: 2.4378877506461194

Epoch: 6| Step: 6
Training loss: 2.935549736022949
Validation loss: 2.44291284648321

Epoch: 6| Step: 7
Training loss: 2.152428388595581
Validation loss: 2.4237924865497056

Epoch: 6| Step: 8
Training loss: 2.6474015712738037
Validation loss: 2.417422784272061

Epoch: 6| Step: 9
Training loss: 2.9487783908843994
Validation loss: 2.4046283050249984

Epoch: 6| Step: 10
Training loss: 2.060513496398926
Validation loss: 2.4019176165262857

Epoch: 6| Step: 11
Training loss: 2.2028350830078125
Validation loss: 2.408994851573821

Epoch: 6| Step: 12
Training loss: 2.859049081802368
Validation loss: 2.4111669063568115

Epoch: 6| Step: 13
Training loss: 3.151409149169922
Validation loss: 2.416299645618726

Epoch: 119| Step: 0
Training loss: 2.0900986194610596
Validation loss: 2.4234130151810183

Epoch: 6| Step: 1
Training loss: 3.2789177894592285
Validation loss: 2.4264111288132204

Epoch: 6| Step: 2
Training loss: 2.404052257537842
Validation loss: 2.4274740270389024

Epoch: 6| Step: 3
Training loss: 3.1549291610717773
Validation loss: 2.4301148691485004

Epoch: 6| Step: 4
Training loss: 2.3821206092834473
Validation loss: 2.428199550156952

Epoch: 6| Step: 5
Training loss: 2.1783506870269775
Validation loss: 2.422858709930092

Epoch: 6| Step: 6
Training loss: 2.403221607208252
Validation loss: 2.4174202462678314

Epoch: 6| Step: 7
Training loss: 3.5829663276672363
Validation loss: 2.412201378935127

Epoch: 6| Step: 8
Training loss: 2.0121593475341797
Validation loss: 2.402554806842599

Epoch: 6| Step: 9
Training loss: 2.5507965087890625
Validation loss: 2.4050895116662465

Epoch: 6| Step: 10
Training loss: 3.568161964416504
Validation loss: 2.4086642239683416

Epoch: 6| Step: 11
Training loss: 1.864162802696228
Validation loss: 2.4043391212340324

Epoch: 6| Step: 12
Training loss: 2.6991777420043945
Validation loss: 2.409122408077281

Epoch: 6| Step: 13
Training loss: 2.9869396686553955
Validation loss: 2.418371682525963

Epoch: 120| Step: 0
Training loss: 2.5416135787963867
Validation loss: 2.4200683844986783

Epoch: 6| Step: 1
Training loss: 2.3197567462921143
Validation loss: 2.4281655691003285

Epoch: 6| Step: 2
Training loss: 2.5653278827667236
Validation loss: 2.4289624139826786

Epoch: 6| Step: 3
Training loss: 2.785900115966797
Validation loss: 2.422560730288106

Epoch: 6| Step: 4
Training loss: 3.316790819168091
Validation loss: 2.4252215149582073

Epoch: 6| Step: 5
Training loss: 1.6498191356658936
Validation loss: 2.423658622208462

Epoch: 6| Step: 6
Training loss: 2.9295284748077393
Validation loss: 2.4278129736582437

Epoch: 6| Step: 7
Training loss: 2.5796844959259033
Validation loss: 2.4298246227284914

Epoch: 6| Step: 8
Training loss: 4.287176609039307
Validation loss: 2.4267136871173816

Epoch: 6| Step: 9
Training loss: 1.5631321668624878
Validation loss: 2.4263437922282884

Epoch: 6| Step: 10
Training loss: 2.568136692047119
Validation loss: 2.4235276663175194

Epoch: 6| Step: 11
Training loss: 2.526008129119873
Validation loss: 2.424684589908969

Epoch: 6| Step: 12
Training loss: 2.9409916400909424
Validation loss: 2.4222771595883112

Epoch: 6| Step: 13
Training loss: 2.0495426654815674
Validation loss: 2.415758027825304

Epoch: 121| Step: 0
Training loss: 2.258479118347168
Validation loss: 2.4181196510150866

Epoch: 6| Step: 1
Training loss: 3.293637275695801
Validation loss: 2.4271453144729778

Epoch: 6| Step: 2
Training loss: 2.207885265350342
Validation loss: 2.4352989683869066

Epoch: 6| Step: 3
Training loss: 2.440988302230835
Validation loss: 2.443426555202853

Epoch: 6| Step: 4
Training loss: 3.1475706100463867
Validation loss: 2.4421287505857405

Epoch: 6| Step: 5
Training loss: 2.8001580238342285
Validation loss: 2.4500559350495696

Epoch: 6| Step: 6
Training loss: 2.8069279193878174
Validation loss: 2.453920974526354

Epoch: 6| Step: 7
Training loss: 2.537564754486084
Validation loss: 2.448653967149796

Epoch: 6| Step: 8
Training loss: 3.5733394622802734
Validation loss: 2.452800710995992

Epoch: 6| Step: 9
Training loss: 1.9282405376434326
Validation loss: 2.4388187290519796

Epoch: 6| Step: 10
Training loss: 2.564100980758667
Validation loss: 2.4292197881206388

Epoch: 6| Step: 11
Training loss: 2.2613654136657715
Validation loss: 2.42583732194798

Epoch: 6| Step: 12
Training loss: 2.619415760040283
Validation loss: 2.416479361954556

Epoch: 6| Step: 13
Training loss: 2.2437915802001953
Validation loss: 2.4126188934490247

Epoch: 122| Step: 0
Training loss: 2.7834532260894775
Validation loss: 2.4079651153215798

Epoch: 6| Step: 1
Training loss: 3.258898973464966
Validation loss: 2.4053682998944352

Epoch: 6| Step: 2
Training loss: 3.7409942150115967
Validation loss: 2.4088474499282015

Epoch: 6| Step: 3
Training loss: 2.489379405975342
Validation loss: 2.402499193786293

Epoch: 6| Step: 4
Training loss: 2.1955716609954834
Validation loss: 2.3999059687378588

Epoch: 6| Step: 5
Training loss: 2.3948731422424316
Validation loss: 2.3999875360919583

Epoch: 6| Step: 6
Training loss: 2.570209503173828
Validation loss: 2.4000814012301865

Epoch: 6| Step: 7
Training loss: 3.1006455421447754
Validation loss: 2.3954960223167174

Epoch: 6| Step: 8
Training loss: 2.0911507606506348
Validation loss: 2.394027256196545

Epoch: 6| Step: 9
Training loss: 2.453953266143799
Validation loss: 2.40174755742473

Epoch: 6| Step: 10
Training loss: 2.4093987941741943
Validation loss: 2.404961345016315

Epoch: 6| Step: 11
Training loss: 2.2483818531036377
Validation loss: 2.412859316795103

Epoch: 6| Step: 12
Training loss: 2.169661521911621
Validation loss: 2.411298664667273

Epoch: 6| Step: 13
Training loss: 3.0782625675201416
Validation loss: 2.420755286370554

Epoch: 123| Step: 0
Training loss: 3.2181363105773926
Validation loss: 2.422717950677359

Epoch: 6| Step: 1
Training loss: 3.195564031600952
Validation loss: 2.426948070526123

Epoch: 6| Step: 2
Training loss: 2.441267967224121
Validation loss: 2.4454048166992846

Epoch: 6| Step: 3
Training loss: 2.638927936553955
Validation loss: 2.4320645973246586

Epoch: 6| Step: 4
Training loss: 3.1033706665039062
Validation loss: 2.4482199376629246

Epoch: 6| Step: 5
Training loss: 2.6455025672912598
Validation loss: 2.4488396875319944

Epoch: 6| Step: 6
Training loss: 3.1249518394470215
Validation loss: 2.448927484532838

Epoch: 6| Step: 7
Training loss: 2.812744140625
Validation loss: 2.4473388015582995

Epoch: 6| Step: 8
Training loss: 2.1291441917419434
Validation loss: 2.4354148910891626

Epoch: 6| Step: 9
Training loss: 2.7784996032714844
Validation loss: 2.4307951952821467

Epoch: 6| Step: 10
Training loss: 2.8887112140655518
Validation loss: 2.414149563799622

Epoch: 6| Step: 11
Training loss: 1.45015549659729
Validation loss: 2.3993831039756857

Epoch: 6| Step: 12
Training loss: 1.9112317562103271
Validation loss: 2.391044734626688

Epoch: 6| Step: 13
Training loss: 2.4280381202697754
Validation loss: 2.3879644178575083

Epoch: 124| Step: 0
Training loss: 3.516935348510742
Validation loss: 2.385013795668079

Epoch: 6| Step: 1
Training loss: 2.7511041164398193
Validation loss: 2.384017070134481

Epoch: 6| Step: 2
Training loss: 2.032841205596924
Validation loss: 2.3865612911921676

Epoch: 6| Step: 3
Training loss: 1.9281357526779175
Validation loss: 2.3880488616164013

Epoch: 6| Step: 4
Training loss: 3.009413719177246
Validation loss: 2.387167433256744

Epoch: 6| Step: 5
Training loss: 1.9251320362091064
Validation loss: 2.389548486278903

Epoch: 6| Step: 6
Training loss: 2.5150623321533203
Validation loss: 2.3922606078527306

Epoch: 6| Step: 7
Training loss: 2.831848382949829
Validation loss: 2.389730707291634

Epoch: 6| Step: 8
Training loss: 2.7240309715270996
Validation loss: 2.3869115742303992

Epoch: 6| Step: 9
Training loss: 3.2804927825927734
Validation loss: 2.3962489302440355

Epoch: 6| Step: 10
Training loss: 2.718841075897217
Validation loss: 2.39454319143808

Epoch: 6| Step: 11
Training loss: 2.546644449234009
Validation loss: 2.396048871419763

Epoch: 6| Step: 12
Training loss: 2.7739124298095703
Validation loss: 2.39623244859839

Epoch: 6| Step: 13
Training loss: 1.8874659538269043
Validation loss: 2.4001380781973563

Epoch: 125| Step: 0
Training loss: 3.19439697265625
Validation loss: 2.4146922865221576

Epoch: 6| Step: 1
Training loss: 2.2485461235046387
Validation loss: 2.4237847200004

Epoch: 6| Step: 2
Training loss: 1.9826586246490479
Validation loss: 2.432312411646689

Epoch: 6| Step: 3
Training loss: 2.4640161991119385
Validation loss: 2.4516988005689395

Epoch: 6| Step: 4
Training loss: 3.2290120124816895
Validation loss: 2.4643046817471905

Epoch: 6| Step: 5
Training loss: 1.9390184879302979
Validation loss: 2.4560151997432915

Epoch: 6| Step: 6
Training loss: 2.3161027431488037
Validation loss: 2.4682467752887356

Epoch: 6| Step: 7
Training loss: 3.2331438064575195
Validation loss: 2.4624529269433792

Epoch: 6| Step: 8
Training loss: 3.286403179168701
Validation loss: 2.477203908786979

Epoch: 6| Step: 9
Training loss: 2.517585515975952
Validation loss: 2.453849348970639

Epoch: 6| Step: 10
Training loss: 3.579359531402588
Validation loss: 2.4345376337728193

Epoch: 6| Step: 11
Training loss: 2.5158958435058594
Validation loss: 2.416481351339689

Epoch: 6| Step: 12
Training loss: 2.201106071472168
Validation loss: 2.412930114294893

Epoch: 6| Step: 13
Training loss: 1.8865724802017212
Validation loss: 2.4115901711166545

Epoch: 126| Step: 0
Training loss: 2.1560769081115723
Validation loss: 2.4253481126600698

Epoch: 6| Step: 1
Training loss: 2.499886989593506
Validation loss: 2.4463630363505375

Epoch: 6| Step: 2
Training loss: 2.5901362895965576
Validation loss: 2.467730901574576

Epoch: 6| Step: 3
Training loss: 3.5587384700775146
Validation loss: 2.4673786522239767

Epoch: 6| Step: 4
Training loss: 2.240926742553711
Validation loss: 2.4433617079129784

Epoch: 6| Step: 5
Training loss: 2.6405210494995117
Validation loss: 2.4343285124789

Epoch: 6| Step: 6
Training loss: 2.4394314289093018
Validation loss: 2.4258077913714993

Epoch: 6| Step: 7
Training loss: 2.899806499481201
Validation loss: 2.403642987692228

Epoch: 6| Step: 8
Training loss: 2.810739040374756
Validation loss: 2.3967358732736237

Epoch: 6| Step: 9
Training loss: 2.6367597579956055
Validation loss: 2.3896822134653726

Epoch: 6| Step: 10
Training loss: 1.9804952144622803
Validation loss: 2.3845948660245506

Epoch: 6| Step: 11
Training loss: 2.9672904014587402
Validation loss: 2.3865895963484243

Epoch: 6| Step: 12
Training loss: 3.414376735687256
Validation loss: 2.3933885764050227

Epoch: 6| Step: 13
Training loss: 2.126838207244873
Validation loss: 2.3937579534387075

Epoch: 127| Step: 0
Training loss: 2.7952938079833984
Validation loss: 2.390305455012988

Epoch: 6| Step: 1
Training loss: 2.4390664100646973
Validation loss: 2.383130068420082

Epoch: 6| Step: 2
Training loss: 1.90561842918396
Validation loss: 2.3834027449289956

Epoch: 6| Step: 3
Training loss: 2.6172866821289062
Validation loss: 2.3941075776212957

Epoch: 6| Step: 4
Training loss: 2.400485038757324
Validation loss: 2.3966623660056823

Epoch: 6| Step: 5
Training loss: 2.1515190601348877
Validation loss: 2.403370016364641

Epoch: 6| Step: 6
Training loss: 2.752960205078125
Validation loss: 2.4063544632286153

Epoch: 6| Step: 7
Training loss: 3.2015950679779053
Validation loss: 2.412042179415303

Epoch: 6| Step: 8
Training loss: 2.4747848510742188
Validation loss: 2.4172516689505628

Epoch: 6| Step: 9
Training loss: 3.1657180786132812
Validation loss: 2.423345560668617

Epoch: 6| Step: 10
Training loss: 3.625237226486206
Validation loss: 2.422693396127352

Epoch: 6| Step: 11
Training loss: 2.0612175464630127
Validation loss: 2.4179991855416247

Epoch: 6| Step: 12
Training loss: 2.4319305419921875
Validation loss: 2.4103154059379333

Epoch: 6| Step: 13
Training loss: 2.769796371459961
Validation loss: 2.402618997840471

Epoch: 128| Step: 0
Training loss: 2.347378730773926
Validation loss: 2.421409977379666

Epoch: 6| Step: 1
Training loss: 2.7433207035064697
Validation loss: 2.427935766917403

Epoch: 6| Step: 2
Training loss: 2.3238704204559326
Validation loss: 2.4263980773187455

Epoch: 6| Step: 3
Training loss: 2.9117066860198975
Validation loss: 2.4241200929046958

Epoch: 6| Step: 4
Training loss: 3.183220148086548
Validation loss: 2.4292083094196935

Epoch: 6| Step: 5
Training loss: 2.8315892219543457
Validation loss: 2.4213071971811275

Epoch: 6| Step: 6
Training loss: 2.9240946769714355
Validation loss: 2.421015352331182

Epoch: 6| Step: 7
Training loss: 2.261364221572876
Validation loss: 2.4032402961484847

Epoch: 6| Step: 8
Training loss: 2.006195545196533
Validation loss: 2.3834499261712514

Epoch: 6| Step: 9
Training loss: 2.8800101280212402
Validation loss: 2.377314075346916

Epoch: 6| Step: 10
Training loss: 2.505591630935669
Validation loss: 2.37479829788208

Epoch: 6| Step: 11
Training loss: 2.6346096992492676
Validation loss: 2.3740122420813448

Epoch: 6| Step: 12
Training loss: 2.7680482864379883
Validation loss: 2.376743531996204

Epoch: 6| Step: 13
Training loss: 2.3801145553588867
Validation loss: 2.3785536032851025

Epoch: 129| Step: 0
Training loss: 2.4120092391967773
Validation loss: 2.373342913966025

Epoch: 6| Step: 1
Training loss: 2.034658432006836
Validation loss: 2.374384505774385

Epoch: 6| Step: 2
Training loss: 2.609035015106201
Validation loss: 2.3710944729466594

Epoch: 6| Step: 3
Training loss: 3.0563712120056152
Validation loss: 2.3676565565088743

Epoch: 6| Step: 4
Training loss: 3.628048896789551
Validation loss: 2.372901455048592

Epoch: 6| Step: 5
Training loss: 3.4910569190979004
Validation loss: 2.379682371693273

Epoch: 6| Step: 6
Training loss: 1.728407382965088
Validation loss: 2.379945639641054

Epoch: 6| Step: 7
Training loss: 1.8441171646118164
Validation loss: 2.3837218258970525

Epoch: 6| Step: 8
Training loss: 2.522796869277954
Validation loss: 2.40150196577913

Epoch: 6| Step: 9
Training loss: 2.807893753051758
Validation loss: 2.403577076491489

Epoch: 6| Step: 10
Training loss: 2.474398374557495
Validation loss: 2.4051685410161174

Epoch: 6| Step: 11
Training loss: 3.263695240020752
Validation loss: 2.3973381391135593

Epoch: 6| Step: 12
Training loss: 2.9344029426574707
Validation loss: 2.401646042382845

Epoch: 6| Step: 13
Training loss: 1.5719547271728516
Validation loss: 2.3969772323485343

Epoch: 130| Step: 0
Training loss: 2.6650402545928955
Validation loss: 2.395305049034857

Epoch: 6| Step: 1
Training loss: 2.135589599609375
Validation loss: 2.3876563861805904

Epoch: 6| Step: 2
Training loss: 2.7031381130218506
Validation loss: 2.3892235038101033

Epoch: 6| Step: 3
Training loss: 3.2962136268615723
Validation loss: 2.3916715268165833

Epoch: 6| Step: 4
Training loss: 3.2467916011810303
Validation loss: 2.3907576248209965

Epoch: 6| Step: 5
Training loss: 2.3914103507995605
Validation loss: 2.3859591689161075

Epoch: 6| Step: 6
Training loss: 3.171111583709717
Validation loss: 2.3812962565370785

Epoch: 6| Step: 7
Training loss: 3.0665252208709717
Validation loss: 2.3823212115995345

Epoch: 6| Step: 8
Training loss: 2.288181781768799
Validation loss: 2.383292236635762

Epoch: 6| Step: 9
Training loss: 2.1339175701141357
Validation loss: 2.3837920696504655

Epoch: 6| Step: 10
Training loss: 2.03068470954895
Validation loss: 2.3844256939426547

Epoch: 6| Step: 11
Training loss: 2.2333552837371826
Validation loss: 2.388699769973755

Epoch: 6| Step: 12
Training loss: 2.739894390106201
Validation loss: 2.3929573848683345

Epoch: 6| Step: 13
Training loss: 2.4483485221862793
Validation loss: 2.406598226998442

Epoch: 131| Step: 0
Training loss: 2.741978406906128
Validation loss: 2.4293798374873337

Epoch: 6| Step: 1
Training loss: 2.626241683959961
Validation loss: 2.46056640789073

Epoch: 6| Step: 2
Training loss: 2.6582610607147217
Validation loss: 2.468318321371591

Epoch: 6| Step: 3
Training loss: 2.922881603240967
Validation loss: 2.4811946397186606

Epoch: 6| Step: 4
Training loss: 2.3464455604553223
Validation loss: 2.456476391002696

Epoch: 6| Step: 5
Training loss: 2.3516201972961426
Validation loss: 2.4175729546495663

Epoch: 6| Step: 6
Training loss: 2.3692073822021484
Validation loss: 2.3955903796739477

Epoch: 6| Step: 7
Training loss: 2.6885135173797607
Validation loss: 2.3900161225308656

Epoch: 6| Step: 8
Training loss: 2.9817733764648438
Validation loss: 2.3779008593610538

Epoch: 6| Step: 9
Training loss: 1.914003610610962
Validation loss: 2.3766734625703547

Epoch: 6| Step: 10
Training loss: 2.8134870529174805
Validation loss: 2.3781744459623932

Epoch: 6| Step: 11
Training loss: 2.474210262298584
Validation loss: 2.3731447958177134

Epoch: 6| Step: 12
Training loss: 2.6777987480163574
Validation loss: 2.3688513771180184

Epoch: 6| Step: 13
Training loss: 3.1003432273864746
Validation loss: 2.3732000653461744

Epoch: 132| Step: 0
Training loss: 2.8243825435638428
Validation loss: 2.3735417858246834

Epoch: 6| Step: 1
Training loss: 2.577688217163086
Validation loss: 2.3759801464696086

Epoch: 6| Step: 2
Training loss: 2.5780818462371826
Validation loss: 2.3818669857517367

Epoch: 6| Step: 3
Training loss: 2.348111867904663
Validation loss: 2.37374436214406

Epoch: 6| Step: 4
Training loss: 2.6980130672454834
Validation loss: 2.37725434764739

Epoch: 6| Step: 5
Training loss: 3.110886573791504
Validation loss: 2.3668046382165726

Epoch: 6| Step: 6
Training loss: 2.3761229515075684
Validation loss: 2.3650660335376696

Epoch: 6| Step: 7
Training loss: 2.5696449279785156
Validation loss: 2.36185614267985

Epoch: 6| Step: 8
Training loss: 2.766155242919922
Validation loss: 2.359204658897974

Epoch: 6| Step: 9
Training loss: 1.5140541791915894
Validation loss: 2.360096016237813

Epoch: 6| Step: 10
Training loss: 2.887371063232422
Validation loss: 2.360767787502658

Epoch: 6| Step: 11
Training loss: 2.5309276580810547
Validation loss: 2.361617188299856

Epoch: 6| Step: 12
Training loss: 3.0357015132904053
Validation loss: 2.3632952859324794

Epoch: 6| Step: 13
Training loss: 2.8206279277801514
Validation loss: 2.365199896597093

Epoch: 133| Step: 0
Training loss: 1.9818116426467896
Validation loss: 2.361892338721983

Epoch: 6| Step: 1
Training loss: 2.1827311515808105
Validation loss: 2.364209049491472

Epoch: 6| Step: 2
Training loss: 2.970536231994629
Validation loss: 2.3642339373147614

Epoch: 6| Step: 3
Training loss: 2.96907114982605
Validation loss: 2.3653200082881476

Epoch: 6| Step: 4
Training loss: 2.379112720489502
Validation loss: 2.366818151166362

Epoch: 6| Step: 5
Training loss: 3.0722694396972656
Validation loss: 2.3782984902781825

Epoch: 6| Step: 6
Training loss: 2.352755308151245
Validation loss: 2.386503642605197

Epoch: 6| Step: 7
Training loss: 1.8849260807037354
Validation loss: 2.4014517543136433

Epoch: 6| Step: 8
Training loss: 1.9300692081451416
Validation loss: 2.412395161967124

Epoch: 6| Step: 9
Training loss: 3.2713801860809326
Validation loss: 2.4417459272569224

Epoch: 6| Step: 10
Training loss: 3.0659492015838623
Validation loss: 2.4438634149489866

Epoch: 6| Step: 11
Training loss: 2.626962661743164
Validation loss: 2.4451161866546958

Epoch: 6| Step: 12
Training loss: 3.113853931427002
Validation loss: 2.439520956367575

Epoch: 6| Step: 13
Training loss: 2.8814620971679688
Validation loss: 2.429558357884807

Epoch: 134| Step: 0
Training loss: 3.208322048187256
Validation loss: 2.406145208625383

Epoch: 6| Step: 1
Training loss: 2.5769243240356445
Validation loss: 2.3957583468447448

Epoch: 6| Step: 2
Training loss: 2.425731658935547
Validation loss: 2.4000748049828315

Epoch: 6| Step: 3
Training loss: 2.6546084880828857
Validation loss: 2.389738041867492

Epoch: 6| Step: 4
Training loss: 2.766400098800659
Validation loss: 2.382804306604529

Epoch: 6| Step: 5
Training loss: 1.8485770225524902
Validation loss: 2.379739584461335

Epoch: 6| Step: 6
Training loss: 2.4469995498657227
Validation loss: 2.364162936005541

Epoch: 6| Step: 7
Training loss: 2.4340131282806396
Validation loss: 2.365500586007231

Epoch: 6| Step: 8
Training loss: 2.888446092605591
Validation loss: 2.3692347465022916

Epoch: 6| Step: 9
Training loss: 2.3901169300079346
Validation loss: 2.363221010854167

Epoch: 6| Step: 10
Training loss: 3.1539785861968994
Validation loss: 2.36937125267521

Epoch: 6| Step: 11
Training loss: 2.770022392272949
Validation loss: 2.3717274845287366

Epoch: 6| Step: 12
Training loss: 2.5831496715545654
Validation loss: 2.3716002305348716

Epoch: 6| Step: 13
Training loss: 2.0212533473968506
Validation loss: 2.3744854081061577

Epoch: 135| Step: 0
Training loss: 2.4233226776123047
Validation loss: 2.3744670037300355

Epoch: 6| Step: 1
Training loss: 2.6834917068481445
Validation loss: 2.3733642178197063

Epoch: 6| Step: 2
Training loss: 2.6154685020446777
Validation loss: 2.3687526295262

Epoch: 6| Step: 3
Training loss: 2.9327402114868164
Validation loss: 2.3655488234694286

Epoch: 6| Step: 4
Training loss: 2.5958292484283447
Validation loss: 2.3658050132054154

Epoch: 6| Step: 5
Training loss: 2.9378721714019775
Validation loss: 2.3625911179409234

Epoch: 6| Step: 6
Training loss: 2.0906620025634766
Validation loss: 2.3614022116507254

Epoch: 6| Step: 7
Training loss: 2.5764708518981934
Validation loss: 2.35744208674277

Epoch: 6| Step: 8
Training loss: 3.6075901985168457
Validation loss: 2.356768951621107

Epoch: 6| Step: 9
Training loss: 2.620713710784912
Validation loss: 2.3658716383800713

Epoch: 6| Step: 10
Training loss: 2.3597934246063232
Validation loss: 2.3674228473376204

Epoch: 6| Step: 11
Training loss: 2.091796398162842
Validation loss: 2.376235515840592

Epoch: 6| Step: 12
Training loss: 2.5769472122192383
Validation loss: 2.3789441072812645

Epoch: 6| Step: 13
Training loss: 2.260197639465332
Validation loss: 2.398634974674512

Epoch: 136| Step: 0
Training loss: 2.597851514816284
Validation loss: 2.415012959511049

Epoch: 6| Step: 1
Training loss: 2.717600107192993
Validation loss: 2.468516221610449

Epoch: 6| Step: 2
Training loss: 2.913876533508301
Validation loss: 2.5119067904769734

Epoch: 6| Step: 3
Training loss: 2.7065911293029785
Validation loss: 2.517189746261925

Epoch: 6| Step: 4
Training loss: 2.854689598083496
Validation loss: 2.514769043973697

Epoch: 6| Step: 5
Training loss: 2.3035998344421387
Validation loss: 2.481934498715144

Epoch: 6| Step: 6
Training loss: 2.3388893604278564
Validation loss: 2.4556584614579395

Epoch: 6| Step: 7
Training loss: 2.4290854930877686
Validation loss: 2.4537513486800657

Epoch: 6| Step: 8
Training loss: 3.0418338775634766
Validation loss: 2.448610782623291

Epoch: 6| Step: 9
Training loss: 3.233853578567505
Validation loss: 2.4386474599120436

Epoch: 6| Step: 10
Training loss: 1.6581687927246094
Validation loss: 2.4353898520110757

Epoch: 6| Step: 11
Training loss: 1.8309001922607422
Validation loss: 2.41974667579897

Epoch: 6| Step: 12
Training loss: 3.1234848499298096
Validation loss: 2.405421797947217

Epoch: 6| Step: 13
Training loss: 3.4480714797973633
Validation loss: 2.3914668201118388

Epoch: 137| Step: 0
Training loss: 2.848299980163574
Validation loss: 2.3856265980710267

Epoch: 6| Step: 1
Training loss: 2.373105049133301
Validation loss: 2.377455472946167

Epoch: 6| Step: 2
Training loss: 2.9721450805664062
Validation loss: 2.373888570775268

Epoch: 6| Step: 3
Training loss: 2.317732810974121
Validation loss: 2.3677433844535583

Epoch: 6| Step: 4
Training loss: 2.475005865097046
Validation loss: 2.370064407266596

Epoch: 6| Step: 5
Training loss: 2.0078320503234863
Validation loss: 2.3777465281947965

Epoch: 6| Step: 6
Training loss: 2.579719066619873
Validation loss: 2.374802012597361

Epoch: 6| Step: 7
Training loss: 2.394029378890991
Validation loss: 2.3807399606191986

Epoch: 6| Step: 8
Training loss: 3.35490345954895
Validation loss: 2.3852542497778453

Epoch: 6| Step: 9
Training loss: 2.3126251697540283
Validation loss: 2.3943295619821034

Epoch: 6| Step: 10
Training loss: 1.9898903369903564
Validation loss: 2.4035043998431136

Epoch: 6| Step: 11
Training loss: 2.8105294704437256
Validation loss: 2.40192400768239

Epoch: 6| Step: 12
Training loss: 2.646857261657715
Validation loss: 2.398334123755014

Epoch: 6| Step: 13
Training loss: 4.065577507019043
Validation loss: 2.4082932087682907

Epoch: 138| Step: 0
Training loss: 3.1780576705932617
Validation loss: 2.406342234662784

Epoch: 6| Step: 1
Training loss: 2.2542648315429688
Validation loss: 2.409938335418701

Epoch: 6| Step: 2
Training loss: 2.346374750137329
Validation loss: 2.4115749610367643

Epoch: 6| Step: 3
Training loss: 3.5335984230041504
Validation loss: 2.4100417526819373

Epoch: 6| Step: 4
Training loss: 2.3949790000915527
Validation loss: 2.42446558449858

Epoch: 6| Step: 5
Training loss: 2.8832030296325684
Validation loss: 2.4242211964822586

Epoch: 6| Step: 6
Training loss: 2.738206386566162
Validation loss: 2.4309139931073753

Epoch: 6| Step: 7
Training loss: 2.737856388092041
Validation loss: 2.418223427188012

Epoch: 6| Step: 8
Training loss: 2.3419992923736572
Validation loss: 2.424222861566851

Epoch: 6| Step: 9
Training loss: 2.844147205352783
Validation loss: 2.4263270465276574

Epoch: 6| Step: 10
Training loss: 1.5321893692016602
Validation loss: 2.4307481909310944

Epoch: 6| Step: 11
Training loss: 2.7081618309020996
Validation loss: 2.4304061269247406

Epoch: 6| Step: 12
Training loss: 2.112077236175537
Validation loss: 2.430710438759096

Epoch: 6| Step: 13
Training loss: 3.0022268295288086
Validation loss: 2.4371959188933014

Epoch: 139| Step: 0
Training loss: 2.557605504989624
Validation loss: 2.427221990400745

Epoch: 6| Step: 1
Training loss: 2.803180456161499
Validation loss: 2.4210958942290275

Epoch: 6| Step: 2
Training loss: 2.4698266983032227
Validation loss: 2.409279948921614

Epoch: 6| Step: 3
Training loss: 2.4922118186950684
Validation loss: 2.4175559679667153

Epoch: 6| Step: 4
Training loss: 2.4114673137664795
Validation loss: 2.4175431292544127

Epoch: 6| Step: 5
Training loss: 2.9161574840545654
Validation loss: 2.408900401925528

Epoch: 6| Step: 6
Training loss: 2.326211929321289
Validation loss: 2.407671309286548

Epoch: 6| Step: 7
Training loss: 3.158869981765747
Validation loss: 2.391110066444643

Epoch: 6| Step: 8
Training loss: 2.1112122535705566
Validation loss: 2.381353937169557

Epoch: 6| Step: 9
Training loss: 2.3925580978393555
Validation loss: 2.378725117252719

Epoch: 6| Step: 10
Training loss: 2.6903786659240723
Validation loss: 2.366143457351192

Epoch: 6| Step: 11
Training loss: 3.14980411529541
Validation loss: 2.3690795847164687

Epoch: 6| Step: 12
Training loss: 2.6384406089782715
Validation loss: 2.362049182256063

Epoch: 6| Step: 13
Training loss: 2.085190534591675
Validation loss: 2.3613949078385548

Epoch: 140| Step: 0
Training loss: 2.887868881225586
Validation loss: 2.3658003268703336

Epoch: 6| Step: 1
Training loss: 2.538733959197998
Validation loss: 2.3556363069882957

Epoch: 6| Step: 2
Training loss: 2.3758223056793213
Validation loss: 2.3635680496051745

Epoch: 6| Step: 3
Training loss: 2.8419408798217773
Validation loss: 2.3710761993162093

Epoch: 6| Step: 4
Training loss: 2.7043612003326416
Validation loss: 2.374789373849028

Epoch: 6| Step: 5
Training loss: 2.2499582767486572
Validation loss: 2.370460228253436

Epoch: 6| Step: 6
Training loss: 2.895969867706299
Validation loss: 2.3780583668780584

Epoch: 6| Step: 7
Training loss: 2.3738231658935547
Validation loss: 2.370302128535445

Epoch: 6| Step: 8
Training loss: 2.279670000076294
Validation loss: 2.371664725324159

Epoch: 6| Step: 9
Training loss: 3.0378363132476807
Validation loss: 2.3649757139144407

Epoch: 6| Step: 10
Training loss: 1.997664213180542
Validation loss: 2.355070242317774

Epoch: 6| Step: 11
Training loss: 2.5390896797180176
Validation loss: 2.354986006213773

Epoch: 6| Step: 12
Training loss: 2.9867095947265625
Validation loss: 2.351903279622396

Epoch: 6| Step: 13
Training loss: 2.54006028175354
Validation loss: 2.34478751818339

Epoch: 141| Step: 0
Training loss: 2.617039442062378
Validation loss: 2.347450146111109

Epoch: 6| Step: 1
Training loss: 2.293795585632324
Validation loss: 2.3566813879115607

Epoch: 6| Step: 2
Training loss: 2.5951685905456543
Validation loss: 2.3572818438212075

Epoch: 6| Step: 3
Training loss: 2.5126116275787354
Validation loss: 2.356018381734048

Epoch: 6| Step: 4
Training loss: 2.329167127609253
Validation loss: 2.366001905933503

Epoch: 6| Step: 5
Training loss: 3.3224902153015137
Validation loss: 2.3633181382251043

Epoch: 6| Step: 6
Training loss: 2.55844783782959
Validation loss: 2.371448691173266

Epoch: 6| Step: 7
Training loss: 1.8129183053970337
Validation loss: 2.3714953340509886

Epoch: 6| Step: 8
Training loss: 2.0686442852020264
Validation loss: 2.367960209487587

Epoch: 6| Step: 9
Training loss: 2.9408786296844482
Validation loss: 2.3671413852322485

Epoch: 6| Step: 10
Training loss: 3.0277607440948486
Validation loss: 2.3662115245737056

Epoch: 6| Step: 11
Training loss: 2.4144368171691895
Validation loss: 2.371974686140655

Epoch: 6| Step: 12
Training loss: 2.755446672439575
Validation loss: 2.37517644769402

Epoch: 6| Step: 13
Training loss: 3.211165428161621
Validation loss: 2.367851967452675

Epoch: 142| Step: 0
Training loss: 2.45566463470459
Validation loss: 2.3739751974741616

Epoch: 6| Step: 1
Training loss: 1.8204326629638672
Validation loss: 2.3766347849240868

Epoch: 6| Step: 2
Training loss: 2.9152441024780273
Validation loss: 2.391117029292609

Epoch: 6| Step: 3
Training loss: 2.193246364593506
Validation loss: 2.4086289085367674

Epoch: 6| Step: 4
Training loss: 2.5940499305725098
Validation loss: 2.4231071933623283

Epoch: 6| Step: 5
Training loss: 2.0314111709594727
Validation loss: 2.445034629555159

Epoch: 6| Step: 6
Training loss: 2.118154525756836
Validation loss: 2.45983854416878

Epoch: 6| Step: 7
Training loss: 2.4154958724975586
Validation loss: 2.4573834762778333

Epoch: 6| Step: 8
Training loss: 2.9855499267578125
Validation loss: 2.4578928767993884

Epoch: 6| Step: 9
Training loss: 3.0711817741394043
Validation loss: 2.4544399528093237

Epoch: 6| Step: 10
Training loss: 3.097057342529297
Validation loss: 2.448761104255594

Epoch: 6| Step: 11
Training loss: 3.072575092315674
Validation loss: 2.4354704990181872

Epoch: 6| Step: 12
Training loss: 2.96398663520813
Validation loss: 2.4085506598154702

Epoch: 6| Step: 13
Training loss: 2.7449378967285156
Validation loss: 2.3803289641616163

Epoch: 143| Step: 0
Training loss: 1.8312677145004272
Validation loss: 2.369409579102711

Epoch: 6| Step: 1
Training loss: 2.377718925476074
Validation loss: 2.360773237802649

Epoch: 6| Step: 2
Training loss: 1.9358922243118286
Validation loss: 2.361753591927149

Epoch: 6| Step: 3
Training loss: 2.793604850769043
Validation loss: 2.357719688005345

Epoch: 6| Step: 4
Training loss: 2.5628156661987305
Validation loss: 2.365152182117585

Epoch: 6| Step: 5
Training loss: 2.912947177886963
Validation loss: 2.3607892015928864

Epoch: 6| Step: 6
Training loss: 2.4158859252929688
Validation loss: 2.3645783034704064

Epoch: 6| Step: 7
Training loss: 2.9598236083984375
Validation loss: 2.3644881069019275

Epoch: 6| Step: 8
Training loss: 2.8232998847961426
Validation loss: 2.3636792064994894

Epoch: 6| Step: 9
Training loss: 2.034595012664795
Validation loss: 2.3662663275195706

Epoch: 6| Step: 10
Training loss: 2.507983684539795
Validation loss: 2.35889349701584

Epoch: 6| Step: 11
Training loss: 3.394117832183838
Validation loss: 2.361023287619314

Epoch: 6| Step: 12
Training loss: 3.1349921226501465
Validation loss: 2.365986006234282

Epoch: 6| Step: 13
Training loss: 2.5171399116516113
Validation loss: 2.3788324017678537

Epoch: 144| Step: 0
Training loss: 1.8675739765167236
Validation loss: 2.3954366945451304

Epoch: 6| Step: 1
Training loss: 2.844572067260742
Validation loss: 2.418437683454124

Epoch: 6| Step: 2
Training loss: 3.019306182861328
Validation loss: 2.4188800883549515

Epoch: 6| Step: 3
Training loss: 2.892240047454834
Validation loss: 2.4268686771392822

Epoch: 6| Step: 4
Training loss: 1.7665067911148071
Validation loss: 2.4325226840152534

Epoch: 6| Step: 5
Training loss: 3.3244454860687256
Validation loss: 2.435536612746536

Epoch: 6| Step: 6
Training loss: 2.722473382949829
Validation loss: 2.4238792875761628

Epoch: 6| Step: 7
Training loss: 2.255692481994629
Validation loss: 2.416534146954936

Epoch: 6| Step: 8
Training loss: 2.5932867527008057
Validation loss: 2.398068751058271

Epoch: 6| Step: 9
Training loss: 2.347503185272217
Validation loss: 2.3891081989452405

Epoch: 6| Step: 10
Training loss: 2.100487232208252
Validation loss: 2.381224142607822

Epoch: 6| Step: 11
Training loss: 3.217489719390869
Validation loss: 2.3754706921116

Epoch: 6| Step: 12
Training loss: 2.1646883487701416
Validation loss: 2.3700796686192995

Epoch: 6| Step: 13
Training loss: 3.739105701446533
Validation loss: 2.356424252192179

Epoch: 145| Step: 0
Training loss: 3.193713665008545
Validation loss: 2.3510660202272478

Epoch: 6| Step: 1
Training loss: 3.2081499099731445
Validation loss: 2.3473782770095335

Epoch: 6| Step: 2
Training loss: 2.3071603775024414
Validation loss: 2.341797491555573

Epoch: 6| Step: 3
Training loss: 2.4517149925231934
Validation loss: 2.344527795750608

Epoch: 6| Step: 4
Training loss: 2.529568672180176
Validation loss: 2.343197140642392

Epoch: 6| Step: 5
Training loss: 3.166410207748413
Validation loss: 2.3477202128338557

Epoch: 6| Step: 6
Training loss: 2.9167709350585938
Validation loss: 2.36241009671201

Epoch: 6| Step: 7
Training loss: 2.8463692665100098
Validation loss: 2.3752498703618206

Epoch: 6| Step: 8
Training loss: 2.4099960327148438
Validation loss: 2.3595223734455724

Epoch: 6| Step: 9
Training loss: 1.806621789932251
Validation loss: 2.335075878327893

Epoch: 6| Step: 10
Training loss: 2.646365165710449
Validation loss: 2.3318572582737094

Epoch: 6| Step: 11
Training loss: 2.1347882747650146
Validation loss: 2.323822690594581

Epoch: 6| Step: 12
Training loss: 2.4176480770111084
Validation loss: 2.3327513394817228

Epoch: 6| Step: 13
Training loss: 2.215576648712158
Validation loss: 2.3324234588171846

Epoch: 146| Step: 0
Training loss: 2.633521318435669
Validation loss: 2.3311891837786605

Epoch: 6| Step: 1
Training loss: 2.4465246200561523
Validation loss: 2.333904750885502

Epoch: 6| Step: 2
Training loss: 2.833801031112671
Validation loss: 2.333165196962254

Epoch: 6| Step: 3
Training loss: 2.4778802394866943
Validation loss: 2.337302174619449

Epoch: 6| Step: 4
Training loss: 2.6327576637268066
Validation loss: 2.3368902475603166

Epoch: 6| Step: 5
Training loss: 1.8127140998840332
Validation loss: 2.343882273602229

Epoch: 6| Step: 6
Training loss: 2.966285228729248
Validation loss: 2.3544073976496214

Epoch: 6| Step: 7
Training loss: 2.7033820152282715
Validation loss: 2.367252060162124

Epoch: 6| Step: 8
Training loss: 2.3422040939331055
Validation loss: 2.373731190158475

Epoch: 6| Step: 9
Training loss: 2.739712715148926
Validation loss: 2.391762933423442

Epoch: 6| Step: 10
Training loss: 3.1327738761901855
Validation loss: 2.4018252024086575

Epoch: 6| Step: 11
Training loss: 2.228485107421875
Validation loss: 2.3948681277613484

Epoch: 6| Step: 12
Training loss: 2.369940757751465
Validation loss: 2.386698449811628

Epoch: 6| Step: 13
Training loss: 3.028231620788574
Validation loss: 2.3808364445163357

Epoch: 147| Step: 0
Training loss: 2.9387924671173096
Validation loss: 2.3647897756227882

Epoch: 6| Step: 1
Training loss: 2.3779726028442383
Validation loss: 2.356781821097097

Epoch: 6| Step: 2
Training loss: 1.9800150394439697
Validation loss: 2.361097438361055

Epoch: 6| Step: 3
Training loss: 3.024923324584961
Validation loss: 2.3498014301382084

Epoch: 6| Step: 4
Training loss: 1.6257805824279785
Validation loss: 2.3412577259925103

Epoch: 6| Step: 5
Training loss: 2.36885142326355
Validation loss: 2.3462209855356524

Epoch: 6| Step: 6
Training loss: 2.5032901763916016
Validation loss: 2.3484216761845413

Epoch: 6| Step: 7
Training loss: 2.8910374641418457
Validation loss: 2.3389435865545787

Epoch: 6| Step: 8
Training loss: 2.6009929180145264
Validation loss: 2.339480547494786

Epoch: 6| Step: 9
Training loss: 3.077127695083618
Validation loss: 2.342536682723671

Epoch: 6| Step: 10
Training loss: 2.4295601844787598
Validation loss: 2.354088342317971

Epoch: 6| Step: 11
Training loss: 2.5314316749572754
Validation loss: 2.3524889869074666

Epoch: 6| Step: 12
Training loss: 3.461484432220459
Validation loss: 2.3608588787817184

Epoch: 6| Step: 13
Training loss: 1.9208199977874756
Validation loss: 2.359099736777685

Epoch: 148| Step: 0
Training loss: 1.8670144081115723
Validation loss: 2.3738783867128435

Epoch: 6| Step: 1
Training loss: 2.783628463745117
Validation loss: 2.3911629902419222

Epoch: 6| Step: 2
Training loss: 2.943166732788086
Validation loss: 2.408481326154483

Epoch: 6| Step: 3
Training loss: 2.442120313644409
Validation loss: 2.4260595460091867

Epoch: 6| Step: 4
Training loss: 2.136960506439209
Validation loss: 2.4249323875673356

Epoch: 6| Step: 5
Training loss: 3.301906108856201
Validation loss: 2.431071327578637

Epoch: 6| Step: 6
Training loss: 2.370548725128174
Validation loss: 2.4270786828892206

Epoch: 6| Step: 7
Training loss: 2.483283042907715
Validation loss: 2.404812015512938

Epoch: 6| Step: 8
Training loss: 3.2778971195220947
Validation loss: 2.3888212609034714

Epoch: 6| Step: 9
Training loss: 2.9457225799560547
Validation loss: 2.3739141571906304

Epoch: 6| Step: 10
Training loss: 2.508202075958252
Validation loss: 2.3659487385903635

Epoch: 6| Step: 11
Training loss: 2.60148286819458
Validation loss: 2.3452669241095103

Epoch: 6| Step: 12
Training loss: 2.4965529441833496
Validation loss: 2.333647983048552

Epoch: 6| Step: 13
Training loss: 1.7683805227279663
Validation loss: 2.328950076974848

Epoch: 149| Step: 0
Training loss: 2.862860679626465
Validation loss: 2.3213281746833556

Epoch: 6| Step: 1
Training loss: 1.9846041202545166
Validation loss: 2.314002375448904

Epoch: 6| Step: 2
Training loss: 2.8532657623291016
Validation loss: 2.315836056586235

Epoch: 6| Step: 3
Training loss: 3.0388669967651367
Validation loss: 2.3116412778054514

Epoch: 6| Step: 4
Training loss: 3.268911361694336
Validation loss: 2.3108008202686103

Epoch: 6| Step: 5
Training loss: 1.8828743696212769
Validation loss: 2.3151163285778416

Epoch: 6| Step: 6
Training loss: 2.4552152156829834
Validation loss: 2.3163843359998477

Epoch: 6| Step: 7
Training loss: 1.9278790950775146
Validation loss: 2.3241246169613254

Epoch: 6| Step: 8
Training loss: 2.319624662399292
Validation loss: 2.3385378852967293

Epoch: 6| Step: 9
Training loss: 2.1528661251068115
Validation loss: 2.348604994435464

Epoch: 6| Step: 10
Training loss: 2.6514639854431152
Validation loss: 2.354579328208841

Epoch: 6| Step: 11
Training loss: 3.415966510772705
Validation loss: 2.372218102537176

Epoch: 6| Step: 12
Training loss: 2.9940431118011475
Validation loss: 2.3792914036781556

Epoch: 6| Step: 13
Training loss: 2.0334506034851074
Validation loss: 2.3809330950501146

Epoch: 150| Step: 0
Training loss: 2.0482029914855957
Validation loss: 2.3718025838175127

Epoch: 6| Step: 1
Training loss: 2.78401255607605
Validation loss: 2.3457381879129717

Epoch: 6| Step: 2
Training loss: 3.08178448677063
Validation loss: 2.3326807663004887

Epoch: 6| Step: 3
Training loss: 2.735617160797119
Validation loss: 2.3197347810191493

Epoch: 6| Step: 4
Training loss: 1.8949053287506104
Validation loss: 2.3181719318512948

Epoch: 6| Step: 5
Training loss: 3.2438554763793945
Validation loss: 2.3206684179203485

Epoch: 6| Step: 6
Training loss: 2.745082378387451
Validation loss: 2.3163770501331618

Epoch: 6| Step: 7
Training loss: 2.4569692611694336
Validation loss: 2.3227966857212845

Epoch: 6| Step: 8
Training loss: 2.4478087425231934
Validation loss: 2.3191277980804443

Epoch: 6| Step: 9
Training loss: 2.6952383518218994
Validation loss: 2.324946811122279

Epoch: 6| Step: 10
Training loss: 2.213148832321167
Validation loss: 2.3274235366493143

Epoch: 6| Step: 11
Training loss: 2.7953128814697266
Validation loss: 2.323276978667064

Epoch: 6| Step: 12
Training loss: 2.72198486328125
Validation loss: 2.324944842246271

Epoch: 6| Step: 13
Training loss: 2.0179014205932617
Validation loss: 2.3206155402686006

Epoch: 151| Step: 0
Training loss: 2.1441798210144043
Validation loss: 2.3268640272078978

Epoch: 6| Step: 1
Training loss: 2.631594181060791
Validation loss: 2.324635849204115

Epoch: 6| Step: 2
Training loss: 2.369157314300537
Validation loss: 2.3335254346170733

Epoch: 6| Step: 3
Training loss: 2.5312342643737793
Validation loss: 2.3504931208907918

Epoch: 6| Step: 4
Training loss: 2.7352356910705566
Validation loss: 2.363258474616594

Epoch: 6| Step: 5
Training loss: 2.6766486167907715
Validation loss: 2.3613320396792505

Epoch: 6| Step: 6
Training loss: 3.071377992630005
Validation loss: 2.3550434138185237

Epoch: 6| Step: 7
Training loss: 2.9441986083984375
Validation loss: 2.3415276286422566

Epoch: 6| Step: 8
Training loss: 1.7667927742004395
Validation loss: 2.356710664687618

Epoch: 6| Step: 9
Training loss: 2.721831798553467
Validation loss: 2.360517035248459

Epoch: 6| Step: 10
Training loss: 2.298806667327881
Validation loss: 2.3493314199550177

Epoch: 6| Step: 11
Training loss: 2.7826170921325684
Validation loss: 2.347608332992882

Epoch: 6| Step: 12
Training loss: 2.2954187393188477
Validation loss: 2.3477615284663376

Epoch: 6| Step: 13
Training loss: 3.2644548416137695
Validation loss: 2.3399582011725313

Epoch: 152| Step: 0
Training loss: 2.9523186683654785
Validation loss: 2.3431794694674912

Epoch: 6| Step: 1
Training loss: 2.252607822418213
Validation loss: 2.3312788804372153

Epoch: 6| Step: 2
Training loss: 2.0623998641967773
Validation loss: 2.327535495963148

Epoch: 6| Step: 3
Training loss: 2.798142910003662
Validation loss: 2.313819544289702

Epoch: 6| Step: 4
Training loss: 2.9665133953094482
Validation loss: 2.3116285185660086

Epoch: 6| Step: 5
Training loss: 2.820678234100342
Validation loss: 2.304388943538871

Epoch: 6| Step: 6
Training loss: 2.1757631301879883
Validation loss: 2.3019303070601596

Epoch: 6| Step: 7
Training loss: 2.8828604221343994
Validation loss: 2.2997465992486603

Epoch: 6| Step: 8
Training loss: 2.3699722290039062
Validation loss: 2.3064937668461956

Epoch: 6| Step: 9
Training loss: 3.0093483924865723
Validation loss: 2.301065619273852

Epoch: 6| Step: 10
Training loss: 2.0614120960235596
Validation loss: 2.3014217935582644

Epoch: 6| Step: 11
Training loss: 2.864753007888794
Validation loss: 2.3008422672107653

Epoch: 6| Step: 12
Training loss: 2.974027156829834
Validation loss: 2.305111062142157

Epoch: 6| Step: 13
Training loss: 1.2644888162612915
Validation loss: 2.300767416595131

Epoch: 153| Step: 0
Training loss: 2.2781903743743896
Validation loss: 2.312978216396865

Epoch: 6| Step: 1
Training loss: 1.587316870689392
Validation loss: 2.3109991755536807

Epoch: 6| Step: 2
Training loss: 2.8168911933898926
Validation loss: 2.307844913134011

Epoch: 6| Step: 3
Training loss: 2.682438373565674
Validation loss: 2.3096450810791342

Epoch: 6| Step: 4
Training loss: 3.2153825759887695
Validation loss: 2.3239856971207487

Epoch: 6| Step: 5
Training loss: 2.7192025184631348
Validation loss: 2.3286764929371495

Epoch: 6| Step: 6
Training loss: 2.2366747856140137
Validation loss: 2.3301414007781656

Epoch: 6| Step: 7
Training loss: 2.7022671699523926
Validation loss: 2.3312065626985286

Epoch: 6| Step: 8
Training loss: 2.340554714202881
Validation loss: 2.3461162377429265

Epoch: 6| Step: 9
Training loss: 2.1299567222595215
Validation loss: 2.3386433919270835

Epoch: 6| Step: 10
Training loss: 2.61981463432312
Validation loss: 2.354684493874991

Epoch: 6| Step: 11
Training loss: 2.64479923248291
Validation loss: 2.3587239147514425

Epoch: 6| Step: 12
Training loss: 3.6274161338806152
Validation loss: 2.3579561274538756

Epoch: 6| Step: 13
Training loss: 1.9624905586242676
Validation loss: 2.355880591177171

Epoch: 154| Step: 0
Training loss: 3.285778045654297
Validation loss: 2.360525072261851

Epoch: 6| Step: 1
Training loss: 2.020625114440918
Validation loss: 2.3640651087607107

Epoch: 6| Step: 2
Training loss: 2.13874888420105
Validation loss: 2.3536446043240127

Epoch: 6| Step: 3
Training loss: 2.164703369140625
Validation loss: 2.353718037246376

Epoch: 6| Step: 4
Training loss: 2.490570545196533
Validation loss: 2.3586758285440426

Epoch: 6| Step: 5
Training loss: 2.1152498722076416
Validation loss: 2.3513599159897014

Epoch: 6| Step: 6
Training loss: 2.921109199523926
Validation loss: 2.345447281355499

Epoch: 6| Step: 7
Training loss: 2.4922993183135986
Validation loss: 2.348194870897519

Epoch: 6| Step: 8
Training loss: 2.6301326751708984
Validation loss: 2.352395019223613

Epoch: 6| Step: 9
Training loss: 3.1536593437194824
Validation loss: 2.3509285270526843

Epoch: 6| Step: 10
Training loss: 2.6117630004882812
Validation loss: 2.347290741500034

Epoch: 6| Step: 11
Training loss: 2.6432764530181885
Validation loss: 2.3407515838582027

Epoch: 6| Step: 12
Training loss: 2.600980758666992
Validation loss: 2.3320392793224705

Epoch: 6| Step: 13
Training loss: 2.31190824508667
Validation loss: 2.3350272076104277

Epoch: 155| Step: 0
Training loss: 2.8033790588378906
Validation loss: 2.331085010241437

Epoch: 6| Step: 1
Training loss: 2.3584775924682617
Validation loss: 2.336903779737411

Epoch: 6| Step: 2
Training loss: 3.1730289459228516
Validation loss: 2.349188740535449

Epoch: 6| Step: 3
Training loss: 2.6449482440948486
Validation loss: 2.353979810591667

Epoch: 6| Step: 4
Training loss: 1.998840093612671
Validation loss: 2.3610502289187525

Epoch: 6| Step: 5
Training loss: 3.388366222381592
Validation loss: 2.3648722940875637

Epoch: 6| Step: 6
Training loss: 2.7724967002868652
Validation loss: 2.3585123810716855

Epoch: 6| Step: 7
Training loss: 2.2662951946258545
Validation loss: 2.3493534365007953

Epoch: 6| Step: 8
Training loss: 2.316767454147339
Validation loss: 2.352249950490972

Epoch: 6| Step: 9
Training loss: 3.094705581665039
Validation loss: 2.3354060073052683

Epoch: 6| Step: 10
Training loss: 2.858375310897827
Validation loss: 2.3288072898823726

Epoch: 6| Step: 11
Training loss: 1.8097310066223145
Validation loss: 2.3328887672834497

Epoch: 6| Step: 12
Training loss: 2.021040439605713
Validation loss: 2.3313079277674356

Epoch: 6| Step: 13
Training loss: 1.741258144378662
Validation loss: 2.3216373125712075

Epoch: 156| Step: 0
Training loss: 2.2754507064819336
Validation loss: 2.3280605359744

Epoch: 6| Step: 1
Training loss: 2.355586051940918
Validation loss: 2.3271202989803847

Epoch: 6| Step: 2
Training loss: 3.230616569519043
Validation loss: 2.3186103913091842

Epoch: 6| Step: 3
Training loss: 2.8174142837524414
Validation loss: 2.3135888473961943

Epoch: 6| Step: 4
Training loss: 2.682274341583252
Validation loss: 2.3177066387668734

Epoch: 6| Step: 5
Training loss: 2.7838001251220703
Validation loss: 2.31737990789516

Epoch: 6| Step: 6
Training loss: 2.5994679927825928
Validation loss: 2.319680936874882

Epoch: 6| Step: 7
Training loss: 2.259589672088623
Validation loss: 2.323561715823348

Epoch: 6| Step: 8
Training loss: 2.1596860885620117
Validation loss: 2.3274948391863095

Epoch: 6| Step: 9
Training loss: 2.382241725921631
Validation loss: 2.324160122102307

Epoch: 6| Step: 10
Training loss: 3.1979856491088867
Validation loss: 2.3445334460145686

Epoch: 6| Step: 11
Training loss: 2.068289279937744
Validation loss: 2.3527287680615663

Epoch: 6| Step: 12
Training loss: 2.1934213638305664
Validation loss: 2.345360748229488

Epoch: 6| Step: 13
Training loss: 2.6524407863616943
Validation loss: 2.3545773721510366

Epoch: 157| Step: 0
Training loss: 2.2181806564331055
Validation loss: 2.3543131530925794

Epoch: 6| Step: 1
Training loss: 2.9963340759277344
Validation loss: 2.3619739419670513

Epoch: 6| Step: 2
Training loss: 2.761232852935791
Validation loss: 2.359022207157586

Epoch: 6| Step: 3
Training loss: 2.325939416885376
Validation loss: 2.351240699009229

Epoch: 6| Step: 4
Training loss: 2.06523060798645
Validation loss: 2.3563770581317205

Epoch: 6| Step: 5
Training loss: 2.781906843185425
Validation loss: 2.3612548253869496

Epoch: 6| Step: 6
Training loss: 2.721752643585205
Validation loss: 2.3601427539702384

Epoch: 6| Step: 7
Training loss: 2.220324754714966
Validation loss: 2.3489641553612164

Epoch: 6| Step: 8
Training loss: 2.3964765071868896
Validation loss: 2.3489599022814023

Epoch: 6| Step: 9
Training loss: 2.6607375144958496
Validation loss: 2.3259050666645007

Epoch: 6| Step: 10
Training loss: 2.6180224418640137
Validation loss: 2.323188797120125

Epoch: 6| Step: 11
Training loss: 2.807039737701416
Validation loss: 2.3130208343587895

Epoch: 6| Step: 12
Training loss: 2.161876916885376
Validation loss: 2.3093246900907127

Epoch: 6| Step: 13
Training loss: 2.876863956451416
Validation loss: 2.304292707033055

Epoch: 158| Step: 0
Training loss: 2.824223041534424
Validation loss: 2.3028734986500075

Epoch: 6| Step: 1
Training loss: 2.1043596267700195
Validation loss: 2.2940166842552925

Epoch: 6| Step: 2
Training loss: 1.9559991359710693
Validation loss: 2.306004516540035

Epoch: 6| Step: 3
Training loss: 2.0531930923461914
Validation loss: 2.305168322337571

Epoch: 6| Step: 4
Training loss: 3.2215161323547363
Validation loss: 2.3111059973316808

Epoch: 6| Step: 5
Training loss: 1.9044981002807617
Validation loss: 2.3093177503155125

Epoch: 6| Step: 6
Training loss: 3.4588770866394043
Validation loss: 2.3185834910279963

Epoch: 6| Step: 7
Training loss: 3.3394720554351807
Validation loss: 2.315178696827222

Epoch: 6| Step: 8
Training loss: 1.2216962575912476
Validation loss: 2.3214589267648678

Epoch: 6| Step: 9
Training loss: 2.4602279663085938
Validation loss: 2.3379575411478677

Epoch: 6| Step: 10
Training loss: 2.5495119094848633
Validation loss: 2.347358339576311

Epoch: 6| Step: 11
Training loss: 2.4605772495269775
Validation loss: 2.362255496363486

Epoch: 6| Step: 12
Training loss: 3.1190104484558105
Validation loss: 2.3728185648559244

Epoch: 6| Step: 13
Training loss: 3.117655038833618
Validation loss: 2.3537148532047065

Epoch: 159| Step: 0
Training loss: 2.406820058822632
Validation loss: 2.3295935725653045

Epoch: 6| Step: 1
Training loss: 1.458398699760437
Validation loss: 2.3173557789094987

Epoch: 6| Step: 2
Training loss: 2.6646385192871094
Validation loss: 2.3117522757540465

Epoch: 6| Step: 3
Training loss: 2.2826592922210693
Validation loss: 2.3113559292208765

Epoch: 6| Step: 4
Training loss: 2.896595001220703
Validation loss: 2.320880628401233

Epoch: 6| Step: 5
Training loss: 2.892713785171509
Validation loss: 2.3181200924740044

Epoch: 6| Step: 6
Training loss: 3.061695098876953
Validation loss: 2.3314204395458265

Epoch: 6| Step: 7
Training loss: 2.2960336208343506
Validation loss: 2.3457969401472356

Epoch: 6| Step: 8
Training loss: 2.582303047180176
Validation loss: 2.356141521084693

Epoch: 6| Step: 9
Training loss: 2.5997474193573
Validation loss: 2.3782160384680635

Epoch: 6| Step: 10
Training loss: 2.362549066543579
Validation loss: 2.3920951222860687

Epoch: 6| Step: 11
Training loss: 2.7146787643432617
Validation loss: 2.401077857581518

Epoch: 6| Step: 12
Training loss: 2.8942813873291016
Validation loss: 2.3983845146753455

Epoch: 6| Step: 13
Training loss: 2.6404294967651367
Validation loss: 2.393739713135586

Epoch: 160| Step: 0
Training loss: 3.210052967071533
Validation loss: 2.3973195540007723

Epoch: 6| Step: 1
Training loss: 3.0942959785461426
Validation loss: 2.390654420339933

Epoch: 6| Step: 2
Training loss: 2.124251127243042
Validation loss: 2.37770236948485

Epoch: 6| Step: 3
Training loss: 2.516582727432251
Validation loss: 2.3615710350774948

Epoch: 6| Step: 4
Training loss: 3.103404998779297
Validation loss: 2.3595915507244807

Epoch: 6| Step: 5
Training loss: 2.2570767402648926
Validation loss: 2.358805610287574

Epoch: 6| Step: 6
Training loss: 1.7180726528167725
Validation loss: 2.3620129708320863

Epoch: 6| Step: 7
Training loss: 2.3782620429992676
Validation loss: 2.350932721168764

Epoch: 6| Step: 8
Training loss: 2.338303565979004
Validation loss: 2.342747139674361

Epoch: 6| Step: 9
Training loss: 2.881462574005127
Validation loss: 2.335873870439427

Epoch: 6| Step: 10
Training loss: 2.61103892326355
Validation loss: 2.334536329392464

Epoch: 6| Step: 11
Training loss: 2.620692729949951
Validation loss: 2.3324724397351666

Epoch: 6| Step: 12
Training loss: 2.4395456314086914
Validation loss: 2.316805644701886

Epoch: 6| Step: 13
Training loss: 2.7491722106933594
Validation loss: 2.315760112577869

Epoch: 161| Step: 0
Training loss: 2.0233569145202637
Validation loss: 2.3208887500147664

Epoch: 6| Step: 1
Training loss: 2.603060722351074
Validation loss: 2.3185804172228743

Epoch: 6| Step: 2
Training loss: 2.580738067626953
Validation loss: 2.302077134450277

Epoch: 6| Step: 3
Training loss: 3.0644049644470215
Validation loss: 2.3039016287813903

Epoch: 6| Step: 4
Training loss: 2.8666934967041016
Validation loss: 2.3001155571271013

Epoch: 6| Step: 5
Training loss: 2.601294994354248
Validation loss: 2.311768930445435

Epoch: 6| Step: 6
Training loss: 2.747030019760132
Validation loss: 2.3089430755184543

Epoch: 6| Step: 7
Training loss: 2.857447624206543
Validation loss: 2.3093118154874412

Epoch: 6| Step: 8
Training loss: 2.1553351879119873
Validation loss: 2.308572930674399

Epoch: 6| Step: 9
Training loss: 2.4048519134521484
Validation loss: 2.31134428516511

Epoch: 6| Step: 10
Training loss: 2.4638853073120117
Validation loss: 2.301544602199267

Epoch: 6| Step: 11
Training loss: 2.161081314086914
Validation loss: 2.2979318095791723

Epoch: 6| Step: 12
Training loss: 2.475229024887085
Validation loss: 2.3060120049343316

Epoch: 6| Step: 13
Training loss: 2.488962411880493
Validation loss: 2.3054067934713056

Epoch: 162| Step: 0
Training loss: 2.4413461685180664
Validation loss: 2.3196268389301915

Epoch: 6| Step: 1
Training loss: 2.6741483211517334
Validation loss: 2.3183979988098145

Epoch: 6| Step: 2
Training loss: 3.0061988830566406
Validation loss: 2.3381943933425413

Epoch: 6| Step: 3
Training loss: 2.3660645484924316
Validation loss: 2.3320267021015124

Epoch: 6| Step: 4
Training loss: 1.935593843460083
Validation loss: 2.3363742879641953

Epoch: 6| Step: 5
Training loss: 2.328272819519043
Validation loss: 2.315441431537751

Epoch: 6| Step: 6
Training loss: 2.5854175090789795
Validation loss: 2.3153973728097896

Epoch: 6| Step: 7
Training loss: 2.658015012741089
Validation loss: 2.304063104814099

Epoch: 6| Step: 8
Training loss: 2.4717893600463867
Validation loss: 2.307613136947796

Epoch: 6| Step: 9
Training loss: 2.688582420349121
Validation loss: 2.3096799183917303

Epoch: 6| Step: 10
Training loss: 2.529569625854492
Validation loss: 2.3144389480672856

Epoch: 6| Step: 11
Training loss: 2.707097291946411
Validation loss: 2.3018924036333637

Epoch: 6| Step: 12
Training loss: 2.6317644119262695
Validation loss: 2.311824455056139

Epoch: 6| Step: 13
Training loss: 2.2637012004852295
Validation loss: 2.3207585221977642

Epoch: 163| Step: 0
Training loss: 2.1246514320373535
Validation loss: 2.3304400213303103

Epoch: 6| Step: 1
Training loss: 4.17808723449707
Validation loss: 2.3475315699013333

Epoch: 6| Step: 2
Training loss: 2.941347599029541
Validation loss: 2.3439778743251676

Epoch: 6| Step: 3
Training loss: 2.565845012664795
Validation loss: 2.344864494057112

Epoch: 6| Step: 4
Training loss: 2.252361297607422
Validation loss: 2.3590865109556463

Epoch: 6| Step: 5
Training loss: 2.9590976238250732
Validation loss: 2.3652105254511677

Epoch: 6| Step: 6
Training loss: 2.6617062091827393
Validation loss: 2.3731559143271497

Epoch: 6| Step: 7
Training loss: 1.9307849407196045
Validation loss: 2.3534190988027923

Epoch: 6| Step: 8
Training loss: 2.3755130767822266
Validation loss: 2.33866617243777

Epoch: 6| Step: 9
Training loss: 2.2505040168762207
Validation loss: 2.338024208622594

Epoch: 6| Step: 10
Training loss: 2.4604029655456543
Validation loss: 2.3328669891562512

Epoch: 6| Step: 11
Training loss: 2.8087100982666016
Validation loss: 2.3120985082400742

Epoch: 6| Step: 12
Training loss: 1.7152783870697021
Validation loss: 2.304637655135124

Epoch: 6| Step: 13
Training loss: 2.2684683799743652
Validation loss: 2.3028362233151674

Epoch: 164| Step: 0
Training loss: 3.178316593170166
Validation loss: 2.2919980146551646

Epoch: 6| Step: 1
Training loss: 3.113544464111328
Validation loss: 2.2975183251083537

Epoch: 6| Step: 2
Training loss: 3.2653422355651855
Validation loss: 2.294952723287767

Epoch: 6| Step: 3
Training loss: 2.1477434635162354
Validation loss: 2.2893173874065442

Epoch: 6| Step: 4
Training loss: 2.2140204906463623
Validation loss: 2.297178260741695

Epoch: 6| Step: 5
Training loss: 2.454954147338867
Validation loss: 2.2903715102903304

Epoch: 6| Step: 6
Training loss: 2.561995029449463
Validation loss: 2.292218315985895

Epoch: 6| Step: 7
Training loss: 2.136479139328003
Validation loss: 2.2835659365500174

Epoch: 6| Step: 8
Training loss: 2.003739833831787
Validation loss: 2.279436480614447

Epoch: 6| Step: 9
Training loss: 2.7583045959472656
Validation loss: 2.2780972475646646

Epoch: 6| Step: 10
Training loss: 2.1569361686706543
Validation loss: 2.272727406153115

Epoch: 6| Step: 11
Training loss: 2.6275076866149902
Validation loss: 2.2628336298850273

Epoch: 6| Step: 12
Training loss: 2.1339259147644043
Validation loss: 2.2659388024319886

Epoch: 6| Step: 13
Training loss: 2.932249069213867
Validation loss: 2.27060886608657

Epoch: 165| Step: 0
Training loss: 2.855644702911377
Validation loss: 2.2660353927202124

Epoch: 6| Step: 1
Training loss: 2.5626015663146973
Validation loss: 2.2642409827119563

Epoch: 6| Step: 2
Training loss: 1.8281389474868774
Validation loss: 2.260644474337178

Epoch: 6| Step: 3
Training loss: 2.803426742553711
Validation loss: 2.2610989898763676

Epoch: 6| Step: 4
Training loss: 3.183657646179199
Validation loss: 2.2733894573744906

Epoch: 6| Step: 5
Training loss: 2.1856606006622314
Validation loss: 2.277313529804189

Epoch: 6| Step: 6
Training loss: 2.731184482574463
Validation loss: 2.2977211270281064

Epoch: 6| Step: 7
Training loss: 1.5653088092803955
Validation loss: 2.278214185468612

Epoch: 6| Step: 8
Training loss: 2.104692220687866
Validation loss: 2.3011543878944973

Epoch: 6| Step: 9
Training loss: 3.353546619415283
Validation loss: 2.3241256129357124

Epoch: 6| Step: 10
Training loss: 3.0944173336029053
Validation loss: 2.325181486786053

Epoch: 6| Step: 11
Training loss: 2.2282652854919434
Validation loss: 2.3317362851994012

Epoch: 6| Step: 12
Training loss: 2.8141465187072754
Validation loss: 2.3230897918824227

Epoch: 6| Step: 13
Training loss: 2.111617088317871
Validation loss: 2.3154338354705484

Epoch: 166| Step: 0
Training loss: 2.798574447631836
Validation loss: 2.2924129398920203

Epoch: 6| Step: 1
Training loss: 3.2469873428344727
Validation loss: 2.2900121981097805

Epoch: 6| Step: 2
Training loss: 2.7117786407470703
Validation loss: 2.2896280878333637

Epoch: 6| Step: 3
Training loss: 2.618408203125
Validation loss: 2.279779290640226

Epoch: 6| Step: 4
Training loss: 2.069188117980957
Validation loss: 2.290470484764345

Epoch: 6| Step: 5
Training loss: 2.159834384918213
Validation loss: 2.2791592844070925

Epoch: 6| Step: 6
Training loss: 2.3668155670166016
Validation loss: 2.274979269632729

Epoch: 6| Step: 7
Training loss: 2.3871893882751465
Validation loss: 2.273199337784962

Epoch: 6| Step: 8
Training loss: 1.9814033508300781
Validation loss: 2.2705602902238087

Epoch: 6| Step: 9
Training loss: 2.83855938911438
Validation loss: 2.2662753879383044

Epoch: 6| Step: 10
Training loss: 3.0891058444976807
Validation loss: 2.265565385100662

Epoch: 6| Step: 11
Training loss: 2.557920455932617
Validation loss: 2.257494162487727

Epoch: 6| Step: 12
Training loss: 2.0352821350097656
Validation loss: 2.258215444062346

Epoch: 6| Step: 13
Training loss: 2.4362125396728516
Validation loss: 2.256706199338359

Epoch: 167| Step: 0
Training loss: 3.0192904472351074
Validation loss: 2.2574540966300556

Epoch: 6| Step: 1
Training loss: 2.7450225353240967
Validation loss: 2.268839382356213

Epoch: 6| Step: 2
Training loss: 2.3400166034698486
Validation loss: 2.264852452021773

Epoch: 6| Step: 3
Training loss: 2.3625330924987793
Validation loss: 2.2707303877799743

Epoch: 6| Step: 4
Training loss: 2.4507665634155273
Validation loss: 2.274550261036042

Epoch: 6| Step: 5
Training loss: 2.7368321418762207
Validation loss: 2.276153773389837

Epoch: 6| Step: 6
Training loss: 3.0859503746032715
Validation loss: 2.284527926034825

Epoch: 6| Step: 7
Training loss: 3.392508029937744
Validation loss: 2.2948757448504047

Epoch: 6| Step: 8
Training loss: 1.437822699546814
Validation loss: 2.303426989945032

Epoch: 6| Step: 9
Training loss: 1.7944705486297607
Validation loss: 2.3004264408542263

Epoch: 6| Step: 10
Training loss: 2.995769500732422
Validation loss: 2.305275212052048

Epoch: 6| Step: 11
Training loss: 2.3904025554656982
Validation loss: 2.3042118805710987

Epoch: 6| Step: 12
Training loss: 2.7783379554748535
Validation loss: 2.3051920039679414

Epoch: 6| Step: 13
Training loss: 1.2135047912597656
Validation loss: 2.296675843577231

Epoch: 168| Step: 0
Training loss: 2.864802598953247
Validation loss: 2.300096599004602

Epoch: 6| Step: 1
Training loss: 2.570702075958252
Validation loss: 2.3066972250579507

Epoch: 6| Step: 2
Training loss: 2.4329030513763428
Validation loss: 2.307274100601032

Epoch: 6| Step: 3
Training loss: 2.562037944793701
Validation loss: 2.306617409952225

Epoch: 6| Step: 4
Training loss: 2.55216646194458
Validation loss: 2.3127191271833194

Epoch: 6| Step: 5
Training loss: 1.9225754737854004
Validation loss: 2.3150414894985896

Epoch: 6| Step: 6
Training loss: 2.3790194988250732
Validation loss: 2.32486585135101

Epoch: 6| Step: 7
Training loss: 1.1188814640045166
Validation loss: 2.336277969421879

Epoch: 6| Step: 8
Training loss: 3.598975419998169
Validation loss: 2.3387294225795294

Epoch: 6| Step: 9
Training loss: 2.3480124473571777
Validation loss: 2.3487797629448677

Epoch: 6| Step: 10
Training loss: 3.0467453002929688
Validation loss: 2.3687063929855183

Epoch: 6| Step: 11
Training loss: 3.127929449081421
Validation loss: 2.3722711660528697

Epoch: 6| Step: 12
Training loss: 2.2379465103149414
Validation loss: 2.373410419751239

Epoch: 6| Step: 13
Training loss: 2.7731094360351562
Validation loss: 2.3866913574998097

Epoch: 169| Step: 0
Training loss: 1.6964259147644043
Validation loss: 2.3680609349281556

Epoch: 6| Step: 1
Training loss: 2.5025718212127686
Validation loss: 2.3869005146846978

Epoch: 6| Step: 2
Training loss: 2.5510458946228027
Validation loss: 2.3914193671236754

Epoch: 6| Step: 3
Training loss: 2.863461971282959
Validation loss: 2.395900505845265

Epoch: 6| Step: 4
Training loss: 2.7716126441955566
Validation loss: 2.3843966273851294

Epoch: 6| Step: 5
Training loss: 3.4621458053588867
Validation loss: 2.345490276172597

Epoch: 6| Step: 6
Training loss: 1.9772319793701172
Validation loss: 2.32461118185392

Epoch: 6| Step: 7
Training loss: 2.5335476398468018
Validation loss: 2.309158040631202

Epoch: 6| Step: 8
Training loss: 2.6004695892333984
Validation loss: 2.30196826945069

Epoch: 6| Step: 9
Training loss: 1.9235481023788452
Validation loss: 2.3135349417245514

Epoch: 6| Step: 10
Training loss: 2.653907299041748
Validation loss: 2.2947378953297934

Epoch: 6| Step: 11
Training loss: 2.349992275238037
Validation loss: 2.296893299266856

Epoch: 6| Step: 12
Training loss: 3.091156005859375
Validation loss: 2.289911118886804

Epoch: 6| Step: 13
Training loss: 2.357896089553833
Validation loss: 2.28185450133457

Epoch: 170| Step: 0
Training loss: 2.4879584312438965
Validation loss: 2.28121522677842

Epoch: 6| Step: 1
Training loss: 2.664410352706909
Validation loss: 2.2737481363358034

Epoch: 6| Step: 2
Training loss: 2.3670501708984375
Validation loss: 2.276198774255732

Epoch: 6| Step: 3
Training loss: 2.002720832824707
Validation loss: 2.2774425783464984

Epoch: 6| Step: 4
Training loss: 2.395653247833252
Validation loss: 2.2822642633991856

Epoch: 6| Step: 5
Training loss: 2.9683918952941895
Validation loss: 2.2940435307000273

Epoch: 6| Step: 6
Training loss: 2.5959839820861816
Validation loss: 2.283637644142233

Epoch: 6| Step: 7
Training loss: 3.0652012825012207
Validation loss: 2.28494950520095

Epoch: 6| Step: 8
Training loss: 2.28926944732666
Validation loss: 2.2759299598714358

Epoch: 6| Step: 9
Training loss: 2.836611270904541
Validation loss: 2.270274862166374

Epoch: 6| Step: 10
Training loss: 2.1800079345703125
Validation loss: 2.278502671949325

Epoch: 6| Step: 11
Training loss: 2.4739041328430176
Validation loss: 2.2692687767808155

Epoch: 6| Step: 12
Training loss: 2.3310301303863525
Validation loss: 2.2795406131334204

Epoch: 6| Step: 13
Training loss: 2.4170703887939453
Validation loss: 2.2676450924206804

Epoch: 171| Step: 0
Training loss: 2.9135901927948
Validation loss: 2.2650908218917025

Epoch: 6| Step: 1
Training loss: 2.281414270401001
Validation loss: 2.2718679751119306

Epoch: 6| Step: 2
Training loss: 2.563732147216797
Validation loss: 2.263781362964261

Epoch: 6| Step: 3
Training loss: 2.9561710357666016
Validation loss: 2.2608656831966933

Epoch: 6| Step: 4
Training loss: 2.362131118774414
Validation loss: 2.257240007000585

Epoch: 6| Step: 5
Training loss: 1.9350391626358032
Validation loss: 2.2614703460406234

Epoch: 6| Step: 6
Training loss: 2.107649803161621
Validation loss: 2.25401303075975

Epoch: 6| Step: 7
Training loss: 2.7037153244018555
Validation loss: 2.251423596053995

Epoch: 6| Step: 8
Training loss: 2.303020715713501
Validation loss: 2.2659743960185716

Epoch: 6| Step: 9
Training loss: 2.3143703937530518
Validation loss: 2.264423583143501

Epoch: 6| Step: 10
Training loss: 2.5644102096557617
Validation loss: 2.257406883342292

Epoch: 6| Step: 11
Training loss: 2.950450897216797
Validation loss: 2.271509498678228

Epoch: 6| Step: 12
Training loss: 2.3462538719177246
Validation loss: 2.2781636561116865

Epoch: 6| Step: 13
Training loss: 2.6554346084594727
Validation loss: 2.2826321432667394

Epoch: 172| Step: 0
Training loss: 2.3333568572998047
Validation loss: 2.3048669086989535

Epoch: 6| Step: 1
Training loss: 2.172234058380127
Validation loss: 2.3101251945700696

Epoch: 6| Step: 2
Training loss: 3.039121389389038
Validation loss: 2.3351887169704644

Epoch: 6| Step: 3
Training loss: 2.640192985534668
Validation loss: 2.3565568513767694

Epoch: 6| Step: 4
Training loss: 2.518824815750122
Validation loss: 2.3720217161281134

Epoch: 6| Step: 5
Training loss: 2.7030816078186035
Validation loss: 2.3848541552020657

Epoch: 6| Step: 6
Training loss: 2.2734694480895996
Validation loss: 2.40249301028508

Epoch: 6| Step: 7
Training loss: 3.0483055114746094
Validation loss: 2.4212696219003327

Epoch: 6| Step: 8
Training loss: 1.7999836206436157
Validation loss: 2.4107697650950444

Epoch: 6| Step: 9
Training loss: 2.979458808898926
Validation loss: 2.412200350915232

Epoch: 6| Step: 10
Training loss: 2.5326390266418457
Validation loss: 2.3976663697150444

Epoch: 6| Step: 11
Training loss: 3.1338515281677246
Validation loss: 2.388422889094199

Epoch: 6| Step: 12
Training loss: 2.454493999481201
Validation loss: 2.3561308204486804

Epoch: 6| Step: 13
Training loss: 1.873374104499817
Validation loss: 2.3348392107153453

Epoch: 173| Step: 0
Training loss: 1.986500859260559
Validation loss: 2.323137511489212

Epoch: 6| Step: 1
Training loss: 3.2838644981384277
Validation loss: 2.3169731093991186

Epoch: 6| Step: 2
Training loss: 2.4084653854370117
Validation loss: 2.2996580575102117

Epoch: 6| Step: 3
Training loss: 2.280409812927246
Validation loss: 2.3203465912931707

Epoch: 6| Step: 4
Training loss: 1.9708507061004639
Validation loss: 2.314346323731125

Epoch: 6| Step: 5
Training loss: 2.3695590496063232
Validation loss: 2.3036858266399753

Epoch: 6| Step: 6
Training loss: 3.093869686126709
Validation loss: 2.3425968231693393

Epoch: 6| Step: 7
Training loss: 2.4409573078155518
Validation loss: 2.336939629688058

Epoch: 6| Step: 8
Training loss: 2.6157617568969727
Validation loss: 2.3377463330504713

Epoch: 6| Step: 9
Training loss: 2.8245608806610107
Validation loss: 2.3248464420277584

Epoch: 6| Step: 10
Training loss: 2.085153818130493
Validation loss: 2.277958080332766

Epoch: 6| Step: 11
Training loss: 1.9594608545303345
Validation loss: 2.2594179120115054

Epoch: 6| Step: 12
Training loss: 3.0408968925476074
Validation loss: 2.2537207552181777

Epoch: 6| Step: 13
Training loss: 2.9052274227142334
Validation loss: 2.2528452129774195

Epoch: 174| Step: 0
Training loss: 2.592930793762207
Validation loss: 2.2511933990704116

Epoch: 6| Step: 1
Training loss: 2.3950068950653076
Validation loss: 2.2537160611921743

Epoch: 6| Step: 2
Training loss: 3.2098159790039062
Validation loss: 2.264583280009608

Epoch: 6| Step: 3
Training loss: 2.801199197769165
Validation loss: 2.2764212546810025

Epoch: 6| Step: 4
Training loss: 1.671393871307373
Validation loss: 2.27769285632718

Epoch: 6| Step: 5
Training loss: 3.1533865928649902
Validation loss: 2.2865140232988583

Epoch: 6| Step: 6
Training loss: 2.3039610385894775
Validation loss: 2.270858797975766

Epoch: 6| Step: 7
Training loss: 1.9402316808700562
Validation loss: 2.275425793022238

Epoch: 6| Step: 8
Training loss: 3.322770357131958
Validation loss: 2.2688072881390973

Epoch: 6| Step: 9
Training loss: 1.7156260013580322
Validation loss: 2.2602632763565227

Epoch: 6| Step: 10
Training loss: 2.7559051513671875
Validation loss: 2.2544857968566236

Epoch: 6| Step: 11
Training loss: 2.6236701011657715
Validation loss: 2.2629035083196496

Epoch: 6| Step: 12
Training loss: 1.8707327842712402
Validation loss: 2.255908005981035

Epoch: 6| Step: 13
Training loss: 2.993408441543579
Validation loss: 2.258004960193429

Epoch: 175| Step: 0
Training loss: 1.7457889318466187
Validation loss: 2.2469240593653854

Epoch: 6| Step: 1
Training loss: 2.747511386871338
Validation loss: 2.2388964365887385

Epoch: 6| Step: 2
Training loss: 2.7824385166168213
Validation loss: 2.23540561942644

Epoch: 6| Step: 3
Training loss: 2.1917176246643066
Validation loss: 2.2372666533275316

Epoch: 6| Step: 4
Training loss: 3.0798180103302
Validation loss: 2.237106807770268

Epoch: 6| Step: 5
Training loss: 2.4365642070770264
Validation loss: 2.244048010918402

Epoch: 6| Step: 6
Training loss: 2.9222469329833984
Validation loss: 2.242732914545203

Epoch: 6| Step: 7
Training loss: 2.744579792022705
Validation loss: 2.238339859952209

Epoch: 6| Step: 8
Training loss: 2.5109939575195312
Validation loss: 2.2420511579000824

Epoch: 6| Step: 9
Training loss: 2.3851022720336914
Validation loss: 2.2452255359259983

Epoch: 6| Step: 10
Training loss: 2.569181442260742
Validation loss: 2.2445709346443095

Epoch: 6| Step: 11
Training loss: 2.224191665649414
Validation loss: 2.2437029243797384

Epoch: 6| Step: 12
Training loss: 2.0355231761932373
Validation loss: 2.245634760907901

Epoch: 6| Step: 13
Training loss: 2.940993547439575
Validation loss: 2.2490106756969164

Epoch: 176| Step: 0
Training loss: 2.562100410461426
Validation loss: 2.2397924341181272

Epoch: 6| Step: 1
Training loss: 2.830538272857666
Validation loss: 2.243313640676519

Epoch: 6| Step: 2
Training loss: 3.0103001594543457
Validation loss: 2.264151543699285

Epoch: 6| Step: 3
Training loss: 3.0725326538085938
Validation loss: 2.272683740943991

Epoch: 6| Step: 4
Training loss: 3.257591962814331
Validation loss: 2.279646517128073

Epoch: 6| Step: 5
Training loss: 3.1108899116516113
Validation loss: 2.278246307885775

Epoch: 6| Step: 6
Training loss: 2.6423888206481934
Validation loss: 2.287406970095891

Epoch: 6| Step: 7
Training loss: 1.3429534435272217
Validation loss: 2.286384028773154

Epoch: 6| Step: 8
Training loss: 1.8414570093154907
Validation loss: 2.268786753377607

Epoch: 6| Step: 9
Training loss: 2.7870564460754395
Validation loss: 2.252956158371382

Epoch: 6| Step: 10
Training loss: 2.511690139770508
Validation loss: 2.245447458759431

Epoch: 6| Step: 11
Training loss: 2.0637083053588867
Validation loss: 2.24501355232731

Epoch: 6| Step: 12
Training loss: 1.904695749282837
Validation loss: 2.2350962418381886

Epoch: 6| Step: 13
Training loss: 1.8203330039978027
Validation loss: 2.235765157207366

Epoch: 177| Step: 0
Training loss: 2.1978559494018555
Validation loss: 2.228653297629408

Epoch: 6| Step: 1
Training loss: 2.1162705421447754
Validation loss: 2.2286031220548894

Epoch: 6| Step: 2
Training loss: 3.1631932258605957
Validation loss: 2.230177399932697

Epoch: 6| Step: 3
Training loss: 1.9991769790649414
Validation loss: 2.2393208985687583

Epoch: 6| Step: 4
Training loss: 3.2268052101135254
Validation loss: 2.2475631698485343

Epoch: 6| Step: 5
Training loss: 2.102285623550415
Validation loss: 2.2401328676490375

Epoch: 6| Step: 6
Training loss: 2.9392433166503906
Validation loss: 2.2485011418660483

Epoch: 6| Step: 7
Training loss: 2.2435755729675293
Validation loss: 2.262828576949335

Epoch: 6| Step: 8
Training loss: 3.0788378715515137
Validation loss: 2.261988232212682

Epoch: 6| Step: 9
Training loss: 2.134110450744629
Validation loss: 2.2638918892029793

Epoch: 6| Step: 10
Training loss: 2.142253875732422
Validation loss: 2.264444653705884

Epoch: 6| Step: 11
Training loss: 2.044621467590332
Validation loss: 2.2611572460461686

Epoch: 6| Step: 12
Training loss: 2.838836193084717
Validation loss: 2.264480480583765

Epoch: 6| Step: 13
Training loss: 2.790203094482422
Validation loss: 2.2700634566686486

Epoch: 178| Step: 0
Training loss: 2.2337276935577393
Validation loss: 2.28355166732624

Epoch: 6| Step: 1
Training loss: 2.227602958679199
Validation loss: 2.30303987379997

Epoch: 6| Step: 2
Training loss: 3.6836142539978027
Validation loss: 2.3167694819870817

Epoch: 6| Step: 3
Training loss: 3.4759507179260254
Validation loss: 2.3119992235655427

Epoch: 6| Step: 4
Training loss: 2.0510096549987793
Validation loss: 2.302088204250541

Epoch: 6| Step: 5
Training loss: 1.8288624286651611
Validation loss: 2.2753567413617204

Epoch: 6| Step: 6
Training loss: 2.5651936531066895
Validation loss: 2.253164788728119

Epoch: 6| Step: 7
Training loss: 1.5297667980194092
Validation loss: 2.2515414325139855

Epoch: 6| Step: 8
Training loss: 2.64900279045105
Validation loss: 2.2366759751432683

Epoch: 6| Step: 9
Training loss: 2.4887890815734863
Validation loss: 2.2296577269031155

Epoch: 6| Step: 10
Training loss: 2.2216291427612305
Validation loss: 2.230634358621413

Epoch: 6| Step: 11
Training loss: 2.6325736045837402
Validation loss: 2.233258637048865

Epoch: 6| Step: 12
Training loss: 2.870589256286621
Validation loss: 2.2382461832415674

Epoch: 6| Step: 13
Training loss: 2.3992559909820557
Validation loss: 2.239496018296929

Epoch: 179| Step: 0
Training loss: 3.1729846000671387
Validation loss: 2.2212155506175053

Epoch: 6| Step: 1
Training loss: 2.2963647842407227
Validation loss: 2.232019498784055

Epoch: 6| Step: 2
Training loss: 2.766908645629883
Validation loss: 2.2194088658978863

Epoch: 6| Step: 3
Training loss: 2.713726043701172
Validation loss: 2.2243233790961643

Epoch: 6| Step: 4
Training loss: 2.1518020629882812
Validation loss: 2.2271065583793064

Epoch: 6| Step: 5
Training loss: 2.008915901184082
Validation loss: 2.2276381497742026

Epoch: 6| Step: 6
Training loss: 2.189053773880005
Validation loss: 2.237908612015427

Epoch: 6| Step: 7
Training loss: 2.135559320449829
Validation loss: 2.24892678312076

Epoch: 6| Step: 8
Training loss: 2.4157001972198486
Validation loss: 2.2628462212060088

Epoch: 6| Step: 9
Training loss: 2.7982096672058105
Validation loss: 2.269543396529331

Epoch: 6| Step: 10
Training loss: 2.1945438385009766
Validation loss: 2.252768744704544

Epoch: 6| Step: 11
Training loss: 2.421988010406494
Validation loss: 2.248716249260851

Epoch: 6| Step: 12
Training loss: 2.9872732162475586
Validation loss: 2.239441051278063

Epoch: 6| Step: 13
Training loss: 2.453239679336548
Validation loss: 2.246156248995053

Epoch: 180| Step: 0
Training loss: 1.8954198360443115
Validation loss: 2.2522524761897262

Epoch: 6| Step: 1
Training loss: 2.537961959838867
Validation loss: 2.27579907191697

Epoch: 6| Step: 2
Training loss: 2.3089990615844727
Validation loss: 2.292906963697044

Epoch: 6| Step: 3
Training loss: 1.455559253692627
Validation loss: 2.2947911857276835

Epoch: 6| Step: 4
Training loss: 2.2482807636260986
Validation loss: 2.2986579915528655

Epoch: 6| Step: 5
Training loss: 3.8169350624084473
Validation loss: 2.291793600205452

Epoch: 6| Step: 6
Training loss: 2.7722268104553223
Validation loss: 2.269208105661536

Epoch: 6| Step: 7
Training loss: 3.321638822555542
Validation loss: 2.2585169961375575

Epoch: 6| Step: 8
Training loss: 2.328770399093628
Validation loss: 2.249528400359615

Epoch: 6| Step: 9
Training loss: 2.500059127807617
Validation loss: 2.2366665101820424

Epoch: 6| Step: 10
Training loss: 1.981894850730896
Validation loss: 2.2255778235773884

Epoch: 6| Step: 11
Training loss: 2.451817035675049
Validation loss: 2.2169860819334626

Epoch: 6| Step: 12
Training loss: 2.15092396736145
Validation loss: 2.2300700141537573

Epoch: 6| Step: 13
Training loss: 3.2257206439971924
Validation loss: 2.230731964111328

Epoch: 181| Step: 0
Training loss: 1.8105149269104004
Validation loss: 2.2425016651871386

Epoch: 6| Step: 1
Training loss: 2.366152286529541
Validation loss: 2.27096160252889

Epoch: 6| Step: 2
Training loss: 2.0391345024108887
Validation loss: 2.2693745013206237

Epoch: 6| Step: 3
Training loss: 2.078723669052124
Validation loss: 2.2707934302668416

Epoch: 6| Step: 4
Training loss: 3.291212558746338
Validation loss: 2.2678299411650626

Epoch: 6| Step: 5
Training loss: 3.114899158477783
Validation loss: 2.2633325848528134

Epoch: 6| Step: 6
Training loss: 2.7625198364257812
Validation loss: 2.236652244803726

Epoch: 6| Step: 7
Training loss: 2.658416509628296
Validation loss: 2.2200133236505653

Epoch: 6| Step: 8
Training loss: 2.487374782562256
Validation loss: 2.221439528208907

Epoch: 6| Step: 9
Training loss: 2.6297831535339355
Validation loss: 2.206694854203091

Epoch: 6| Step: 10
Training loss: 2.739931583404541
Validation loss: 2.213558230348813

Epoch: 6| Step: 11
Training loss: 2.1788926124572754
Validation loss: 2.2118025646414807

Epoch: 6| Step: 12
Training loss: 2.121872901916504
Validation loss: 2.2228644099286807

Epoch: 6| Step: 13
Training loss: 2.285613536834717
Validation loss: 2.2250214110138598

Epoch: 182| Step: 0
Training loss: 2.8546485900878906
Validation loss: 2.2309157617630495

Epoch: 6| Step: 1
Training loss: 1.9349734783172607
Validation loss: 2.2242804137609338

Epoch: 6| Step: 2
Training loss: 2.0137076377868652
Validation loss: 2.2471447913877425

Epoch: 6| Step: 3
Training loss: 2.515929698944092
Validation loss: 2.246220196447065

Epoch: 6| Step: 4
Training loss: 2.997652530670166
Validation loss: 2.2672120037899224

Epoch: 6| Step: 5
Training loss: 2.699505090713501
Validation loss: 2.2671422189281834

Epoch: 6| Step: 6
Training loss: 2.848507881164551
Validation loss: 2.292057711591003

Epoch: 6| Step: 7
Training loss: 2.9816455841064453
Validation loss: 2.304208129964849

Epoch: 6| Step: 8
Training loss: 1.9353021383285522
Validation loss: 2.2965468642532185

Epoch: 6| Step: 9
Training loss: 2.5752530097961426
Validation loss: 2.3145645280038156

Epoch: 6| Step: 10
Training loss: 2.3834891319274902
Validation loss: 2.3169443094602196

Epoch: 6| Step: 11
Training loss: 2.307569980621338
Validation loss: 2.3067767312449794

Epoch: 6| Step: 12
Training loss: 2.31300950050354
Validation loss: 2.2792314483273413

Epoch: 6| Step: 13
Training loss: 2.126650810241699
Validation loss: 2.262837617628036

Epoch: 183| Step: 0
Training loss: 2.6114931106567383
Validation loss: 2.243585225074522

Epoch: 6| Step: 1
Training loss: 2.785606861114502
Validation loss: 2.2380982752769225

Epoch: 6| Step: 2
Training loss: 2.7082443237304688
Validation loss: 2.2468971052477436

Epoch: 6| Step: 3
Training loss: 2.0231330394744873
Validation loss: 2.246453636436052

Epoch: 6| Step: 4
Training loss: 2.6556591987609863
Validation loss: 2.2423990670070855

Epoch: 6| Step: 5
Training loss: 2.9078116416931152
Validation loss: 2.253819388727988

Epoch: 6| Step: 6
Training loss: 2.792057514190674
Validation loss: 2.2522769512668734

Epoch: 6| Step: 7
Training loss: 1.7614550590515137
Validation loss: 2.2472679948294036

Epoch: 6| Step: 8
Training loss: 2.7145628929138184
Validation loss: 2.2538541311858804

Epoch: 6| Step: 9
Training loss: 1.8950843811035156
Validation loss: 2.254482933270034

Epoch: 6| Step: 10
Training loss: 1.6423336267471313
Validation loss: 2.2392390645960325

Epoch: 6| Step: 11
Training loss: 2.4033548831939697
Validation loss: 2.2359265947854645

Epoch: 6| Step: 12
Training loss: 2.8069887161254883
Validation loss: 2.255094079561131

Epoch: 6| Step: 13
Training loss: 2.946659803390503
Validation loss: 2.26874973440683

Epoch: 184| Step: 0
Training loss: 2.4147305488586426
Validation loss: 2.280715614236811

Epoch: 6| Step: 1
Training loss: 2.674959421157837
Validation loss: 2.2981758425312657

Epoch: 6| Step: 2
Training loss: 2.9417176246643066
Validation loss: 2.2813345437408774

Epoch: 6| Step: 3
Training loss: 2.7721376419067383
Validation loss: 2.238993337077479

Epoch: 6| Step: 4
Training loss: 2.9022057056427
Validation loss: 2.2256440142149567

Epoch: 6| Step: 5
Training loss: 2.5170984268188477
Validation loss: 2.228720616268855

Epoch: 6| Step: 6
Training loss: 1.733635663986206
Validation loss: 2.227440221335298

Epoch: 6| Step: 7
Training loss: 1.8511595726013184
Validation loss: 2.2324072173846665

Epoch: 6| Step: 8
Training loss: 2.216503381729126
Validation loss: 2.2421723886202742

Epoch: 6| Step: 9
Training loss: 2.1633682250976562
Validation loss: 2.24701351247808

Epoch: 6| Step: 10
Training loss: 3.0586652755737305
Validation loss: 2.267754547057613

Epoch: 6| Step: 11
Training loss: 2.4381184577941895
Validation loss: 2.2549906904979418

Epoch: 6| Step: 12
Training loss: 2.630847454071045
Validation loss: 2.2622555866036365

Epoch: 6| Step: 13
Training loss: 1.8403058052062988
Validation loss: 2.272365636723016

Epoch: 185| Step: 0
Training loss: 2.1137278079986572
Validation loss: 2.2760505983906407

Epoch: 6| Step: 1
Training loss: 2.285554885864258
Validation loss: 2.2686723739870134

Epoch: 6| Step: 2
Training loss: 2.1418867111206055
Validation loss: 2.255472378064227

Epoch: 6| Step: 3
Training loss: 3.079652786254883
Validation loss: 2.2605931707607803

Epoch: 6| Step: 4
Training loss: 2.1686153411865234
Validation loss: 2.25254758199056

Epoch: 6| Step: 5
Training loss: 2.4111785888671875
Validation loss: 2.244999039557672

Epoch: 6| Step: 6
Training loss: 2.279306411743164
Validation loss: 2.2543999764227096

Epoch: 6| Step: 7
Training loss: 3.128145456314087
Validation loss: 2.250038481527759

Epoch: 6| Step: 8
Training loss: 2.7766990661621094
Validation loss: 2.2570445255566667

Epoch: 6| Step: 9
Training loss: 1.9203262329101562
Validation loss: 2.2509208930436

Epoch: 6| Step: 10
Training loss: 2.810649871826172
Validation loss: 2.2452600027925227

Epoch: 6| Step: 11
Training loss: 2.6600265502929688
Validation loss: 2.2433050396621868

Epoch: 6| Step: 12
Training loss: 2.53727388381958
Validation loss: 2.2356534516939552

Epoch: 6| Step: 13
Training loss: 1.654052972793579
Validation loss: 2.2391253107337543

Epoch: 186| Step: 0
Training loss: 3.108366012573242
Validation loss: 2.2331832480686966

Epoch: 6| Step: 1
Training loss: 2.231820583343506
Validation loss: 2.233628590901693

Epoch: 6| Step: 2
Training loss: 2.771780014038086
Validation loss: 2.2285567175957466

Epoch: 6| Step: 3
Training loss: 1.6826951503753662
Validation loss: 2.2119608643234416

Epoch: 6| Step: 4
Training loss: 2.574634075164795
Validation loss: 2.220920960108439

Epoch: 6| Step: 5
Training loss: 2.3962974548339844
Validation loss: 2.207877597501201

Epoch: 6| Step: 6
Training loss: 1.5484087467193604
Validation loss: 2.2081512866481656

Epoch: 6| Step: 7
Training loss: 2.9307286739349365
Validation loss: 2.1983459098364717

Epoch: 6| Step: 8
Training loss: 2.3117566108703613
Validation loss: 2.1937706367943877

Epoch: 6| Step: 9
Training loss: 2.531229019165039
Validation loss: 2.1936005315473004

Epoch: 6| Step: 10
Training loss: 2.3885583877563477
Validation loss: 2.1973305197172266

Epoch: 6| Step: 11
Training loss: 2.7507777214050293
Validation loss: 2.196054838036978

Epoch: 6| Step: 12
Training loss: 2.4783639907836914
Validation loss: 2.2120506020002466

Epoch: 6| Step: 13
Training loss: 2.914762020111084
Validation loss: 2.212486484999298

Epoch: 187| Step: 0
Training loss: 2.8519325256347656
Validation loss: 2.229053851096861

Epoch: 6| Step: 1
Training loss: 2.913105010986328
Validation loss: 2.2514008296433317

Epoch: 6| Step: 2
Training loss: 2.8895201683044434
Validation loss: 2.262850089739728

Epoch: 6| Step: 3
Training loss: 2.8969686031341553
Validation loss: 2.2709707983078493

Epoch: 6| Step: 4
Training loss: 1.5886561870574951
Validation loss: 2.2804526359804216

Epoch: 6| Step: 5
Training loss: 2.9236443042755127
Validation loss: 2.282816897156418

Epoch: 6| Step: 6
Training loss: 2.992495536804199
Validation loss: 2.2882835121564966

Epoch: 6| Step: 7
Training loss: 2.090620279312134
Validation loss: 2.2943720715020293

Epoch: 6| Step: 8
Training loss: 1.5488691329956055
Validation loss: 2.3064649925437024

Epoch: 6| Step: 9
Training loss: 3.3820762634277344
Validation loss: 2.314615165033648

Epoch: 6| Step: 10
Training loss: 1.3507139682769775
Validation loss: 2.3088516881389003

Epoch: 6| Step: 11
Training loss: 2.143064260482788
Validation loss: 2.29039071195869

Epoch: 6| Step: 12
Training loss: 2.124885082244873
Validation loss: 2.277726777138249

Epoch: 6| Step: 13
Training loss: 2.6886329650878906
Validation loss: 2.2710872619382796

Epoch: 188| Step: 0
Training loss: 1.6074873208999634
Validation loss: 2.2624523601224347

Epoch: 6| Step: 1
Training loss: 1.3357425928115845
Validation loss: 2.2458761353646555

Epoch: 6| Step: 2
Training loss: 2.6974990367889404
Validation loss: 2.2425315008368543

Epoch: 6| Step: 3
Training loss: 2.7574563026428223
Validation loss: 2.2344124060805126

Epoch: 6| Step: 4
Training loss: 2.183342933654785
Validation loss: 2.2287153864419587

Epoch: 6| Step: 5
Training loss: 2.2100889682769775
Validation loss: 2.243214681584348

Epoch: 6| Step: 6
Training loss: 2.5495643615722656
Validation loss: 2.2537285563766316

Epoch: 6| Step: 7
Training loss: 2.1983017921447754
Validation loss: 2.262900073041198

Epoch: 6| Step: 8
Training loss: 3.0620369911193848
Validation loss: 2.2904845886333014

Epoch: 6| Step: 9
Training loss: 2.743439197540283
Validation loss: 2.282249007173764

Epoch: 6| Step: 10
Training loss: 2.121041774749756
Validation loss: 2.2567663269658245

Epoch: 6| Step: 11
Training loss: 3.055736541748047
Validation loss: 2.2405848067293883

Epoch: 6| Step: 12
Training loss: 2.5579421520233154
Validation loss: 2.219685974941459

Epoch: 6| Step: 13
Training loss: 3.8245577812194824
Validation loss: 2.2280966876655497

Epoch: 189| Step: 0
Training loss: 2.8488669395446777
Validation loss: 2.2341688204837102

Epoch: 6| Step: 1
Training loss: 2.5169622898101807
Validation loss: 2.2507912394821004

Epoch: 6| Step: 2
Training loss: 2.161599636077881
Validation loss: 2.2558324183187177

Epoch: 6| Step: 3
Training loss: 2.060171604156494
Validation loss: 2.2652881965842298

Epoch: 6| Step: 4
Training loss: 2.3397057056427
Validation loss: 2.271166119524228

Epoch: 6| Step: 5
Training loss: 3.129110813140869
Validation loss: 2.2490039051219983

Epoch: 6| Step: 6
Training loss: 2.1847310066223145
Validation loss: 2.2375732314202095

Epoch: 6| Step: 7
Training loss: 2.7924509048461914
Validation loss: 2.225452141095233

Epoch: 6| Step: 8
Training loss: 2.4768128395080566
Validation loss: 2.2113951816353747

Epoch: 6| Step: 9
Training loss: 2.2949249744415283
Validation loss: 2.200188272742815

Epoch: 6| Step: 10
Training loss: 2.243532180786133
Validation loss: 2.198905393641482

Epoch: 6| Step: 11
Training loss: 2.4642350673675537
Validation loss: 2.1966689068783998

Epoch: 6| Step: 12
Training loss: 2.32273006439209
Validation loss: 2.202485848498601

Epoch: 6| Step: 13
Training loss: 2.5735867023468018
Validation loss: 2.206518916673558

Epoch: 190| Step: 0
Training loss: 2.2767081260681152
Validation loss: 2.2345743756140433

Epoch: 6| Step: 1
Training loss: 3.0341336727142334
Validation loss: 2.2500282385016

Epoch: 6| Step: 2
Training loss: 2.1319894790649414
Validation loss: 2.2640399676497265

Epoch: 6| Step: 3
Training loss: 2.2861340045928955
Validation loss: 2.2660562530640633

Epoch: 6| Step: 4
Training loss: 2.7850756645202637
Validation loss: 2.253655531073129

Epoch: 6| Step: 5
Training loss: 2.67445969581604
Validation loss: 2.239676267870011

Epoch: 6| Step: 6
Training loss: 2.5753417015075684
Validation loss: 2.243341335686304

Epoch: 6| Step: 7
Training loss: 2.653322696685791
Validation loss: 2.245114608477521

Epoch: 6| Step: 8
Training loss: 2.5699877738952637
Validation loss: 2.260174988418497

Epoch: 6| Step: 9
Training loss: 2.6015844345092773
Validation loss: 2.260540308490876

Epoch: 6| Step: 10
Training loss: 2.6458675861358643
Validation loss: 2.259065242223842

Epoch: 6| Step: 11
Training loss: 2.2068729400634766
Validation loss: 2.2734821329834642

Epoch: 6| Step: 12
Training loss: 2.350189447402954
Validation loss: 2.285368811699652

Epoch: 6| Step: 13
Training loss: 0.6928133368492126
Validation loss: 2.274848714951546

Epoch: 191| Step: 0
Training loss: 2.31855845451355
Validation loss: 2.27662060594046

Epoch: 6| Step: 1
Training loss: 2.859700918197632
Validation loss: 2.272943699231712

Epoch: 6| Step: 2
Training loss: 2.3263988494873047
Validation loss: 2.2636042307781916

Epoch: 6| Step: 3
Training loss: 3.214655876159668
Validation loss: 2.2502686336476314

Epoch: 6| Step: 4
Training loss: 2.4355998039245605
Validation loss: 2.2368722525976037

Epoch: 6| Step: 5
Training loss: 1.7549042701721191
Validation loss: 2.230410437430105

Epoch: 6| Step: 6
Training loss: 1.6941449642181396
Validation loss: 2.2241023407187512

Epoch: 6| Step: 7
Training loss: 3.9557852745056152
Validation loss: 2.217781574495377

Epoch: 6| Step: 8
Training loss: 2.0764000415802
Validation loss: 2.2208963286492134

Epoch: 6| Step: 9
Training loss: 2.244210720062256
Validation loss: 2.2133186504405034

Epoch: 6| Step: 10
Training loss: 2.533264636993408
Validation loss: 2.2239295308307936

Epoch: 6| Step: 11
Training loss: 2.28517484664917
Validation loss: 2.227519732649608

Epoch: 6| Step: 12
Training loss: 1.7658652067184448
Validation loss: 2.2338583777027745

Epoch: 6| Step: 13
Training loss: 2.3830080032348633
Validation loss: 2.241141778166576

Epoch: 192| Step: 0
Training loss: 2.093348503112793
Validation loss: 2.248345195606191

Epoch: 6| Step: 1
Training loss: 3.1879169940948486
Validation loss: 2.268252582960231

Epoch: 6| Step: 2
Training loss: 2.4901797771453857
Validation loss: 2.276114653515559

Epoch: 6| Step: 3
Training loss: 2.932027816772461
Validation loss: 2.278649171193441

Epoch: 6| Step: 4
Training loss: 1.9720165729522705
Validation loss: 2.2692692920725834

Epoch: 6| Step: 5
Training loss: 2.0489559173583984
Validation loss: 2.260346274222097

Epoch: 6| Step: 6
Training loss: 2.7913155555725098
Validation loss: 2.240337238516859

Epoch: 6| Step: 7
Training loss: 1.5728026628494263
Validation loss: 2.2365854735015542

Epoch: 6| Step: 8
Training loss: 2.461998224258423
Validation loss: 2.232703347359934

Epoch: 6| Step: 9
Training loss: 1.4811546802520752
Validation loss: 2.2212884631208194

Epoch: 6| Step: 10
Training loss: 2.278285503387451
Validation loss: 2.211053595747999

Epoch: 6| Step: 11
Training loss: 3.1362557411193848
Validation loss: 2.1995245333640807

Epoch: 6| Step: 12
Training loss: 3.042469024658203
Validation loss: 2.2131784167341007

Epoch: 6| Step: 13
Training loss: 2.3258779048919678
Validation loss: 2.1960097077072307

Epoch: 193| Step: 0
Training loss: 2.2540855407714844
Validation loss: 2.187577478347286

Epoch: 6| Step: 1
Training loss: 2.2840681076049805
Validation loss: 2.187943579048239

Epoch: 6| Step: 2
Training loss: 2.138331890106201
Validation loss: 2.1731685874282674

Epoch: 6| Step: 3
Training loss: 2.7460553646087646
Validation loss: 2.1789399449543287

Epoch: 6| Step: 4
Training loss: 2.9017372131347656
Validation loss: 2.1812458704876643

Epoch: 6| Step: 5
Training loss: 2.46272611618042
Validation loss: 2.1899441467818392

Epoch: 6| Step: 6
Training loss: 2.1698808670043945
Validation loss: 2.2008966822778024

Epoch: 6| Step: 7
Training loss: 2.015104293823242
Validation loss: 2.204856921267766

Epoch: 6| Step: 8
Training loss: 2.5271108150482178
Validation loss: 2.23264233527645

Epoch: 6| Step: 9
Training loss: 2.25518798828125
Validation loss: 2.240801365144791

Epoch: 6| Step: 10
Training loss: 2.453549385070801
Validation loss: 2.2407598085300897

Epoch: 6| Step: 11
Training loss: 2.647536277770996
Validation loss: 2.2404816227574504

Epoch: 6| Step: 12
Training loss: 2.59768009185791
Validation loss: 2.263903158967213

Epoch: 6| Step: 13
Training loss: 2.6911377906799316
Validation loss: 2.2666372253048803

Epoch: 194| Step: 0
Training loss: 2.108243227005005
Validation loss: 2.2821034898040113

Epoch: 6| Step: 1
Training loss: 2.1778018474578857
Validation loss: 2.288060580530474

Epoch: 6| Step: 2
Training loss: 2.5658395290374756
Validation loss: 2.3001205357172156

Epoch: 6| Step: 3
Training loss: 3.130901336669922
Validation loss: 2.2942848884931175

Epoch: 6| Step: 4
Training loss: 2.1351571083068848
Validation loss: 2.29443682137356

Epoch: 6| Step: 5
Training loss: 2.303389072418213
Validation loss: 2.250055261837539

Epoch: 6| Step: 6
Training loss: 2.02822208404541
Validation loss: 2.2333278912369923

Epoch: 6| Step: 7
Training loss: 2.2591092586517334
Validation loss: 2.2214128176371255

Epoch: 6| Step: 8
Training loss: 3.348205804824829
Validation loss: 2.212611183043449

Epoch: 6| Step: 9
Training loss: 2.235074520111084
Validation loss: 2.218599634785806

Epoch: 6| Step: 10
Training loss: 3.1701786518096924
Validation loss: 2.207740468363608

Epoch: 6| Step: 11
Training loss: 1.769730567932129
Validation loss: 2.1987486526530278

Epoch: 6| Step: 12
Training loss: 2.430083751678467
Validation loss: 2.2023599250342256

Epoch: 6| Step: 13
Training loss: 2.6113743782043457
Validation loss: 2.1890702709074943

Epoch: 195| Step: 0
Training loss: 2.4430251121520996
Validation loss: 2.184880546344224

Epoch: 6| Step: 1
Training loss: 2.0890536308288574
Validation loss: 2.1909329250294673

Epoch: 6| Step: 2
Training loss: 3.131096363067627
Validation loss: 2.1811039934876146

Epoch: 6| Step: 3
Training loss: 2.0486721992492676
Validation loss: 2.182685141922325

Epoch: 6| Step: 4
Training loss: 2.1999289989471436
Validation loss: 2.1910972825942503

Epoch: 6| Step: 5
Training loss: 1.9158496856689453
Validation loss: 2.184715299196141

Epoch: 6| Step: 6
Training loss: 1.8804833889007568
Validation loss: 2.2090586436692106

Epoch: 6| Step: 7
Training loss: 2.428831100463867
Validation loss: 2.2010786789719776

Epoch: 6| Step: 8
Training loss: 2.98579478263855
Validation loss: 2.198291893928282

Epoch: 6| Step: 9
Training loss: 1.7005690336227417
Validation loss: 2.212455024001419

Epoch: 6| Step: 10
Training loss: 2.4191977977752686
Validation loss: 2.227539159918344

Epoch: 6| Step: 11
Training loss: 2.3837087154388428
Validation loss: 2.2216226849504697

Epoch: 6| Step: 12
Training loss: 3.171617031097412
Validation loss: 2.240674739242882

Epoch: 6| Step: 13
Training loss: 3.283695697784424
Validation loss: 2.224335124415736

Epoch: 196| Step: 0
Training loss: 1.8179268836975098
Validation loss: 2.218396573938349

Epoch: 6| Step: 1
Training loss: 2.835439920425415
Validation loss: 2.2096924089616343

Epoch: 6| Step: 2
Training loss: 1.7320626974105835
Validation loss: 2.201461879155969

Epoch: 6| Step: 3
Training loss: 1.7254626750946045
Validation loss: 2.1915207011725313

Epoch: 6| Step: 4
Training loss: 2.2110824584960938
Validation loss: 2.1765968235590125

Epoch: 6| Step: 5
Training loss: 2.0063745975494385
Validation loss: 2.1886679972371748

Epoch: 6| Step: 6
Training loss: 3.167680263519287
Validation loss: 2.1771417843398226

Epoch: 6| Step: 7
Training loss: 2.6512365341186523
Validation loss: 2.1795265674591064

Epoch: 6| Step: 8
Training loss: 2.7019362449645996
Validation loss: 2.1803309814904326

Epoch: 6| Step: 9
Training loss: 2.0435070991516113
Validation loss: 2.188862080215126

Epoch: 6| Step: 10
Training loss: 3.088742733001709
Validation loss: 2.190649429957072

Epoch: 6| Step: 11
Training loss: 2.203723430633545
Validation loss: 2.192778989832888

Epoch: 6| Step: 12
Training loss: 2.6019017696380615
Validation loss: 2.195907541500625

Epoch: 6| Step: 13
Training loss: 3.029694080352783
Validation loss: 2.2074336941524217

Epoch: 197| Step: 0
Training loss: 2.3804383277893066
Validation loss: 2.2065468924019926

Epoch: 6| Step: 1
Training loss: 2.063091516494751
Validation loss: 2.207899667883432

Epoch: 6| Step: 2
Training loss: 2.057617664337158
Validation loss: 2.2047263063410276

Epoch: 6| Step: 3
Training loss: 2.086233615875244
Validation loss: 2.1829337996821248

Epoch: 6| Step: 4
Training loss: 2.78464412689209
Validation loss: 2.1942671268217024

Epoch: 6| Step: 5
Training loss: 2.017474412918091
Validation loss: 2.183033909848941

Epoch: 6| Step: 6
Training loss: 2.636399745941162
Validation loss: 2.186611011464109

Epoch: 6| Step: 7
Training loss: 2.6337730884552
Validation loss: 2.1812731783877135

Epoch: 6| Step: 8
Training loss: 1.923325538635254
Validation loss: 2.1893394762469875

Epoch: 6| Step: 9
Training loss: 2.450038433074951
Validation loss: 2.187744435443673

Epoch: 6| Step: 10
Training loss: 2.8845274448394775
Validation loss: 2.1857314173893263

Epoch: 6| Step: 11
Training loss: 2.71453595161438
Validation loss: 2.191971307159752

Epoch: 6| Step: 12
Training loss: 2.5805015563964844
Validation loss: 2.198245156195856

Epoch: 6| Step: 13
Training loss: 2.3559110164642334
Validation loss: 2.187678765225154

Epoch: 198| Step: 0
Training loss: 2.768674612045288
Validation loss: 2.2035431195330877

Epoch: 6| Step: 1
Training loss: 3.1587741374969482
Validation loss: 2.2051841469221216

Epoch: 6| Step: 2
Training loss: 2.1101417541503906
Validation loss: 2.2080967810846146

Epoch: 6| Step: 3
Training loss: 2.2933883666992188
Validation loss: 2.213692213899346

Epoch: 6| Step: 4
Training loss: 1.8432111740112305
Validation loss: 2.205001756709109

Epoch: 6| Step: 5
Training loss: 2.499293804168701
Validation loss: 2.1960738192322435

Epoch: 6| Step: 6
Training loss: 1.718013048171997
Validation loss: 2.192673211456627

Epoch: 6| Step: 7
Training loss: 2.233273506164551
Validation loss: 2.1985411233799432

Epoch: 6| Step: 8
Training loss: 2.903207302093506
Validation loss: 2.19949443622302

Epoch: 6| Step: 9
Training loss: 2.6278390884399414
Validation loss: 2.1899037873873146

Epoch: 6| Step: 10
Training loss: 2.4324452877044678
Validation loss: 2.205793919101838

Epoch: 6| Step: 11
Training loss: 2.087334156036377
Validation loss: 2.2070007862583285

Epoch: 6| Step: 12
Training loss: 2.58408784866333
Validation loss: 2.2046155545019333

Epoch: 6| Step: 13
Training loss: 1.9793553352355957
Validation loss: 2.2170138641070296

Epoch: 199| Step: 0
Training loss: 2.955474615097046
Validation loss: 2.222672664990989

Epoch: 6| Step: 1
Training loss: 2.263828754425049
Validation loss: 2.210250731437437

Epoch: 6| Step: 2
Training loss: 2.629086494445801
Validation loss: 2.2049146160002677

Epoch: 6| Step: 3
Training loss: 1.8289424180984497
Validation loss: 2.220452844455678

Epoch: 6| Step: 4
Training loss: 2.0123813152313232
Validation loss: 2.218000155623241

Epoch: 6| Step: 5
Training loss: 2.2618203163146973
Validation loss: 2.2087435978715138

Epoch: 6| Step: 6
Training loss: 3.1178557872772217
Validation loss: 2.202639796400583

Epoch: 6| Step: 7
Training loss: 1.921309232711792
Validation loss: 2.205012441963278

Epoch: 6| Step: 8
Training loss: 2.259547710418701
Validation loss: 2.201796967496154

Epoch: 6| Step: 9
Training loss: 3.0475082397460938
Validation loss: 2.182639906483312

Epoch: 6| Step: 10
Training loss: 2.4032185077667236
Validation loss: 2.1749143959373556

Epoch: 6| Step: 11
Training loss: 2.434901237487793
Validation loss: 2.176602026467682

Epoch: 6| Step: 12
Training loss: 2.283207416534424
Validation loss: 2.175275307829662

Epoch: 6| Step: 13
Training loss: 1.916919469833374
Validation loss: 2.1695753323134555

Epoch: 200| Step: 0
Training loss: 3.2877297401428223
Validation loss: 2.1688976082750546

Epoch: 6| Step: 1
Training loss: 2.119180917739868
Validation loss: 2.172639318691787

Epoch: 6| Step: 2
Training loss: 2.4690120220184326
Validation loss: 2.1703583707091627

Epoch: 6| Step: 3
Training loss: 1.8804945945739746
Validation loss: 2.1834504424884753

Epoch: 6| Step: 4
Training loss: 2.497490644454956
Validation loss: 2.180863226613691

Epoch: 6| Step: 5
Training loss: 1.8722246885299683
Validation loss: 2.1871810856685845

Epoch: 6| Step: 6
Training loss: 2.4827866554260254
Validation loss: 2.189202183036394

Epoch: 6| Step: 7
Training loss: 2.0260019302368164
Validation loss: 2.2042573600687008

Epoch: 6| Step: 8
Training loss: 2.4555249214172363
Validation loss: 2.2084039206145913

Epoch: 6| Step: 9
Training loss: 2.3222527503967285
Validation loss: 2.198953784922118

Epoch: 6| Step: 10
Training loss: 2.8414664268493652
Validation loss: 2.2270004774934504

Epoch: 6| Step: 11
Training loss: 2.7565736770629883
Validation loss: 2.209095242202923

Epoch: 6| Step: 12
Training loss: 2.4476146697998047
Validation loss: 2.204522563565162

Epoch: 6| Step: 13
Training loss: 2.0763204097747803
Validation loss: 2.2004489962772658

Epoch: 201| Step: 0
Training loss: 2.6348981857299805
Validation loss: 2.209274399665094

Epoch: 6| Step: 1
Training loss: 2.7429275512695312
Validation loss: 2.213931343888724

Epoch: 6| Step: 2
Training loss: 2.0684001445770264
Validation loss: 2.2108071824555755

Epoch: 6| Step: 3
Training loss: 2.3312036991119385
Validation loss: 2.2120801710313365

Epoch: 6| Step: 4
Training loss: 2.8848185539245605
Validation loss: 2.1973986215488885

Epoch: 6| Step: 5
Training loss: 2.6565980911254883
Validation loss: 2.2077446573524067

Epoch: 6| Step: 6
Training loss: 1.9418284893035889
Validation loss: 2.1952005099224787

Epoch: 6| Step: 7
Training loss: 2.659881591796875
Validation loss: 2.189246141782371

Epoch: 6| Step: 8
Training loss: 2.629375457763672
Validation loss: 2.176595923721149

Epoch: 6| Step: 9
Training loss: 2.420771598815918
Validation loss: 2.1774839637100056

Epoch: 6| Step: 10
Training loss: 1.6267340183258057
Validation loss: 2.1942085360967987

Epoch: 6| Step: 11
Training loss: 2.361569404602051
Validation loss: 2.2176930904388428

Epoch: 6| Step: 12
Training loss: 1.8999099731445312
Validation loss: 2.218939140278806

Epoch: 6| Step: 13
Training loss: 2.7175965309143066
Validation loss: 2.2257593472798667

Epoch: 202| Step: 0
Training loss: 2.17438006401062
Validation loss: 2.2298492923859627

Epoch: 6| Step: 1
Training loss: 2.077550172805786
Validation loss: 2.2343549164392615

Epoch: 6| Step: 2
Training loss: 2.736339569091797
Validation loss: 2.22527337843372

Epoch: 6| Step: 3
Training loss: 3.051412582397461
Validation loss: 2.2196395345913467

Epoch: 6| Step: 4
Training loss: 2.4066667556762695
Validation loss: 2.208896506217218

Epoch: 6| Step: 5
Training loss: 1.930160641670227
Validation loss: 2.200080397308514

Epoch: 6| Step: 6
Training loss: 2.8533527851104736
Validation loss: 2.201563791562152

Epoch: 6| Step: 7
Training loss: 2.1958541870117188
Validation loss: 2.1997656924750215

Epoch: 6| Step: 8
Training loss: 2.896184206008911
Validation loss: 2.1975872183358796

Epoch: 6| Step: 9
Training loss: 2.3827619552612305
Validation loss: 2.218858285616803

Epoch: 6| Step: 10
Training loss: 2.0199499130249023
Validation loss: 2.2239392034469114

Epoch: 6| Step: 11
Training loss: 2.048154354095459
Validation loss: 2.2135639408583283

Epoch: 6| Step: 12
Training loss: 1.9607353210449219
Validation loss: 2.223747626427681

Epoch: 6| Step: 13
Training loss: 2.942351818084717
Validation loss: 2.2327410072408695

Epoch: 203| Step: 0
Training loss: 2.599583864212036
Validation loss: 2.220242843833021

Epoch: 6| Step: 1
Training loss: 1.882542610168457
Validation loss: 2.2235922172505367

Epoch: 6| Step: 2
Training loss: 2.6622650623321533
Validation loss: 2.2263524968137025

Epoch: 6| Step: 3
Training loss: 1.8878968954086304
Validation loss: 2.2252008222764537

Epoch: 6| Step: 4
Training loss: 2.659963607788086
Validation loss: 2.231412200517552

Epoch: 6| Step: 5
Training loss: 2.1755316257476807
Validation loss: 2.2197798375160462

Epoch: 6| Step: 6
Training loss: 2.1897459030151367
Validation loss: 2.1925281734876734

Epoch: 6| Step: 7
Training loss: 2.568267345428467
Validation loss: 2.1838128848742415

Epoch: 6| Step: 8
Training loss: 1.8927106857299805
Validation loss: 2.1725982696779313

Epoch: 6| Step: 9
Training loss: 2.8307437896728516
Validation loss: 2.1578268338275213

Epoch: 6| Step: 10
Training loss: 2.4052834510803223
Validation loss: 2.1589323577060493

Epoch: 6| Step: 11
Training loss: 3.1191446781158447
Validation loss: 2.1574464562118694

Epoch: 6| Step: 12
Training loss: 2.4424021244049072
Validation loss: 2.1614031407140915

Epoch: 6| Step: 13
Training loss: 1.6596988439559937
Validation loss: 2.137905228522516

Epoch: 204| Step: 0
Training loss: 1.815319299697876
Validation loss: 2.148755576020928

Epoch: 6| Step: 1
Training loss: 2.5086917877197266
Validation loss: 2.1466926938744

Epoch: 6| Step: 2
Training loss: 2.4065334796905518
Validation loss: 2.154533842558502

Epoch: 6| Step: 3
Training loss: 2.6842498779296875
Validation loss: 2.155335154584659

Epoch: 6| Step: 4
Training loss: 2.437568426132202
Validation loss: 2.1743695889749834

Epoch: 6| Step: 5
Training loss: 2.2336506843566895
Validation loss: 2.1640766538599485

Epoch: 6| Step: 6
Training loss: 2.381908893585205
Validation loss: 2.1737971664756857

Epoch: 6| Step: 7
Training loss: 2.176790714263916
Validation loss: 2.2009910716805408

Epoch: 6| Step: 8
Training loss: 2.126293182373047
Validation loss: 2.205452513951127

Epoch: 6| Step: 9
Training loss: 2.2527904510498047
Validation loss: 2.2191872609558927

Epoch: 6| Step: 10
Training loss: 2.6135647296905518
Validation loss: 2.209471730775731

Epoch: 6| Step: 11
Training loss: 3.02006196975708
Validation loss: 2.214697463538057

Epoch: 6| Step: 12
Training loss: 2.3156890869140625
Validation loss: 2.2371857935382473

Epoch: 6| Step: 13
Training loss: 2.118197441101074
Validation loss: 2.236629614266016

Epoch: 205| Step: 0
Training loss: 2.407284736633301
Validation loss: 2.2460974147242885

Epoch: 6| Step: 1
Training loss: 1.6935478448867798
Validation loss: 2.2518053311173634

Epoch: 6| Step: 2
Training loss: 2.8059422969818115
Validation loss: 2.2592336080407582

Epoch: 6| Step: 3
Training loss: 2.691603422164917
Validation loss: 2.229470811864381

Epoch: 6| Step: 4
Training loss: 2.1928858757019043
Validation loss: 2.196502415082788

Epoch: 6| Step: 5
Training loss: 2.5906214714050293
Validation loss: 2.154294139595442

Epoch: 6| Step: 6
Training loss: 1.8721911907196045
Validation loss: 2.133155507426108

Epoch: 6| Step: 7
Training loss: 2.8246726989746094
Validation loss: 2.1414438627099477

Epoch: 6| Step: 8
Training loss: 2.426710605621338
Validation loss: 2.1509651240482124

Epoch: 6| Step: 9
Training loss: 2.4048118591308594
Validation loss: 2.1719776738074517

Epoch: 6| Step: 10
Training loss: 2.6247286796569824
Validation loss: 2.169389368385397

Epoch: 6| Step: 11
Training loss: 2.1732559204101562
Validation loss: 2.174748028478315

Epoch: 6| Step: 12
Training loss: 2.061666488647461
Validation loss: 2.1832679599844

Epoch: 6| Step: 13
Training loss: 2.5027379989624023
Validation loss: 2.1898909050931215

Epoch: 206| Step: 0
Training loss: 3.1368565559387207
Validation loss: 2.1970766231577885

Epoch: 6| Step: 1
Training loss: 2.0943524837493896
Validation loss: 2.1816867038767827

Epoch: 6| Step: 2
Training loss: 2.4589571952819824
Validation loss: 2.1846635546735538

Epoch: 6| Step: 3
Training loss: 1.992588758468628
Validation loss: 2.180729450718049

Epoch: 6| Step: 4
Training loss: 1.9779011011123657
Validation loss: 2.1808456656753377

Epoch: 6| Step: 5
Training loss: 2.689002513885498
Validation loss: 2.178250494823661

Epoch: 6| Step: 6
Training loss: 1.844693660736084
Validation loss: 2.1964062170315812

Epoch: 6| Step: 7
Training loss: 2.670225143432617
Validation loss: 2.208779199149019

Epoch: 6| Step: 8
Training loss: 2.115711212158203
Validation loss: 2.1933170313476236

Epoch: 6| Step: 9
Training loss: 2.528751850128174
Validation loss: 2.1557420351172007

Epoch: 6| Step: 10
Training loss: 2.4681079387664795
Validation loss: 2.1672785410317044

Epoch: 6| Step: 11
Training loss: 1.7886219024658203
Validation loss: 2.1623699921433643

Epoch: 6| Step: 12
Training loss: 3.084017276763916
Validation loss: 2.197630111889173

Epoch: 6| Step: 13
Training loss: 1.8858896493911743
Validation loss: 2.221382385940962

Epoch: 207| Step: 0
Training loss: 2.09464430809021
Validation loss: 2.2362733515360023

Epoch: 6| Step: 1
Training loss: 2.7964975833892822
Validation loss: 2.268231471379598

Epoch: 6| Step: 2
Training loss: 1.9962449073791504
Validation loss: 2.275801743230512

Epoch: 6| Step: 3
Training loss: 1.8876969814300537
Validation loss: 2.3060733464456376

Epoch: 6| Step: 4
Training loss: 2.3403351306915283
Validation loss: 2.298538177244125

Epoch: 6| Step: 5
Training loss: 3.3865180015563965
Validation loss: 2.3093735325721

Epoch: 6| Step: 6
Training loss: 2.181612730026245
Validation loss: 2.3040189358495895

Epoch: 6| Step: 7
Training loss: 2.106675863265991
Validation loss: 2.279023370435161

Epoch: 6| Step: 8
Training loss: 2.231096029281616
Validation loss: 2.2314838235096266

Epoch: 6| Step: 9
Training loss: 3.1123969554901123
Validation loss: 2.2123567622195006

Epoch: 6| Step: 10
Training loss: 2.484663486480713
Validation loss: 2.193706940579158

Epoch: 6| Step: 11
Training loss: 2.41389799118042
Validation loss: 2.163862238648117

Epoch: 6| Step: 12
Training loss: 2.6866750717163086
Validation loss: 2.1573700751027753

Epoch: 6| Step: 13
Training loss: 2.6004581451416016
Validation loss: 2.1461689882380988

Epoch: 208| Step: 0
Training loss: 2.432490348815918
Validation loss: 2.154851846797492

Epoch: 6| Step: 1
Training loss: 2.8211593627929688
Validation loss: 2.17158834011324

Epoch: 6| Step: 2
Training loss: 2.4779529571533203
Validation loss: 2.1759063556630123

Epoch: 6| Step: 3
Training loss: 2.4730260372161865
Validation loss: 2.1704128160271594

Epoch: 6| Step: 4
Training loss: 1.8212921619415283
Validation loss: 2.1531251745839275

Epoch: 6| Step: 5
Training loss: 3.018258810043335
Validation loss: 2.152338227918071

Epoch: 6| Step: 6
Training loss: 1.6363252401351929
Validation loss: 2.1656346923561505

Epoch: 6| Step: 7
Training loss: 3.080141305923462
Validation loss: 2.1673818096037833

Epoch: 6| Step: 8
Training loss: 1.688173770904541
Validation loss: 2.167572944395004

Epoch: 6| Step: 9
Training loss: 2.3185529708862305
Validation loss: 2.17044476796222

Epoch: 6| Step: 10
Training loss: 2.2164173126220703
Validation loss: 2.1622877300426526

Epoch: 6| Step: 11
Training loss: 2.4732589721679688
Validation loss: 2.1699352495131956

Epoch: 6| Step: 12
Training loss: 2.39607834815979
Validation loss: 2.183672728077058

Epoch: 6| Step: 13
Training loss: 2.327686071395874
Validation loss: 2.1921666386306926

Epoch: 209| Step: 0
Training loss: 2.2797250747680664
Validation loss: 2.208708281158119

Epoch: 6| Step: 1
Training loss: 2.2259018421173096
Validation loss: 2.22315425385711

Epoch: 6| Step: 2
Training loss: 2.3949427604675293
Validation loss: 2.250750152013635

Epoch: 6| Step: 3
Training loss: 1.7431834936141968
Validation loss: 2.254171694478681

Epoch: 6| Step: 4
Training loss: 2.070323944091797
Validation loss: 2.2524102323798725

Epoch: 6| Step: 5
Training loss: 2.9777169227600098
Validation loss: 2.235772834029249

Epoch: 6| Step: 6
Training loss: 2.516483783721924
Validation loss: 2.2156127909178376

Epoch: 6| Step: 7
Training loss: 2.459700107574463
Validation loss: 2.1977935580797094

Epoch: 6| Step: 8
Training loss: 2.295654058456421
Validation loss: 2.1894447829133723

Epoch: 6| Step: 9
Training loss: 2.7911248207092285
Validation loss: 2.176683595103602

Epoch: 6| Step: 10
Training loss: 2.627092123031616
Validation loss: 2.1872657716915174

Epoch: 6| Step: 11
Training loss: 1.9254722595214844
Validation loss: 2.18537550844172

Epoch: 6| Step: 12
Training loss: 2.354731798171997
Validation loss: 2.1733255129988476

Epoch: 6| Step: 13
Training loss: 2.459132194519043
Validation loss: 2.1727218653566096

Epoch: 210| Step: 0
Training loss: 2.6676836013793945
Validation loss: 2.1669754469266502

Epoch: 6| Step: 1
Training loss: 1.7640918493270874
Validation loss: 2.168620729959139

Epoch: 6| Step: 2
Training loss: 2.2651875019073486
Validation loss: 2.1717767151453162

Epoch: 6| Step: 3
Training loss: 2.3422462940216064
Validation loss: 2.1593438630462973

Epoch: 6| Step: 4
Training loss: 1.9870185852050781
Validation loss: 2.163845113528672

Epoch: 6| Step: 5
Training loss: 2.259704113006592
Validation loss: 2.1570361762918453

Epoch: 6| Step: 6
Training loss: 1.8325188159942627
Validation loss: 2.1566110990380727

Epoch: 6| Step: 7
Training loss: 2.0676045417785645
Validation loss: 2.1449326443415817

Epoch: 6| Step: 8
Training loss: 2.478024482727051
Validation loss: 2.1556721066915863

Epoch: 6| Step: 9
Training loss: 2.468294143676758
Validation loss: 2.1454356690888763

Epoch: 6| Step: 10
Training loss: 2.316838264465332
Validation loss: 2.1410869295879076

Epoch: 6| Step: 11
Training loss: 2.853010892868042
Validation loss: 2.14887055530343

Epoch: 6| Step: 12
Training loss: 2.544649124145508
Validation loss: 2.1489095982684883

Epoch: 6| Step: 13
Training loss: 3.2563648223876953
Validation loss: 2.1511025274953535

Epoch: 211| Step: 0
Training loss: 1.9805324077606201
Validation loss: 2.1556191559760802

Epoch: 6| Step: 1
Training loss: 2.2826216220855713
Validation loss: 2.1435264515620407

Epoch: 6| Step: 2
Training loss: 3.19334077835083
Validation loss: 2.143191546522161

Epoch: 6| Step: 3
Training loss: 2.496156930923462
Validation loss: 2.1505671278122933

Epoch: 6| Step: 4
Training loss: 2.537114381790161
Validation loss: 2.149762648408131

Epoch: 6| Step: 5
Training loss: 2.083441734313965
Validation loss: 2.1503334455592658

Epoch: 6| Step: 6
Training loss: 2.1478190422058105
Validation loss: 2.1627724016866376

Epoch: 6| Step: 7
Training loss: 2.0926780700683594
Validation loss: 2.187211592992147

Epoch: 6| Step: 8
Training loss: 2.412504196166992
Validation loss: 2.1745326647194485

Epoch: 6| Step: 9
Training loss: 1.9597060680389404
Validation loss: 2.1857989321472826

Epoch: 6| Step: 10
Training loss: 2.1022303104400635
Validation loss: 2.193005274700862

Epoch: 6| Step: 11
Training loss: 2.4779019355773926
Validation loss: 2.192262280371881

Epoch: 6| Step: 12
Training loss: 2.6952033042907715
Validation loss: 2.2043818043124292

Epoch: 6| Step: 13
Training loss: 2.07916522026062
Validation loss: 2.194030140035896

Epoch: 212| Step: 0
Training loss: 2.5283474922180176
Validation loss: 2.18181687273005

Epoch: 6| Step: 1
Training loss: 2.474116086959839
Validation loss: 2.177015394292852

Epoch: 6| Step: 2
Training loss: 2.0306105613708496
Validation loss: 2.1678805376893733

Epoch: 6| Step: 3
Training loss: 2.315870761871338
Validation loss: 2.1656380930254535

Epoch: 6| Step: 4
Training loss: 2.4750540256500244
Validation loss: 2.137067005198489

Epoch: 6| Step: 5
Training loss: 2.037452220916748
Validation loss: 2.1365629626858618

Epoch: 6| Step: 6
Training loss: 2.886320114135742
Validation loss: 2.1318214170394407

Epoch: 6| Step: 7
Training loss: 2.2166380882263184
Validation loss: 2.142747449618514

Epoch: 6| Step: 8
Training loss: 2.3987488746643066
Validation loss: 2.153677317403978

Epoch: 6| Step: 9
Training loss: 2.315162181854248
Validation loss: 2.1595393893539265

Epoch: 6| Step: 10
Training loss: 2.4622836112976074
Validation loss: 2.1475321592823153

Epoch: 6| Step: 11
Training loss: 2.5269012451171875
Validation loss: 2.149170152602657

Epoch: 6| Step: 12
Training loss: 1.6450767517089844
Validation loss: 2.161354375141923

Epoch: 6| Step: 13
Training loss: 2.53914737701416
Validation loss: 2.1564991935606925

Epoch: 213| Step: 0
Training loss: 1.0704389810562134
Validation loss: 2.167013141416734

Epoch: 6| Step: 1
Training loss: 1.5132384300231934
Validation loss: 2.17001647333945

Epoch: 6| Step: 2
Training loss: 1.9942686557769775
Validation loss: 2.2172038606418076

Epoch: 6| Step: 3
Training loss: 2.5601065158843994
Validation loss: 2.2306745770157024

Epoch: 6| Step: 4
Training loss: 1.796844720840454
Validation loss: 2.246309024031444

Epoch: 6| Step: 5
Training loss: 2.4218509197235107
Validation loss: 2.2307946861431165

Epoch: 6| Step: 6
Training loss: 2.571376323699951
Validation loss: 2.2243108057206675

Epoch: 6| Step: 7
Training loss: 2.5709853172302246
Validation loss: 2.1947755275234098

Epoch: 6| Step: 8
Training loss: 2.0952558517456055
Validation loss: 2.1730097596363356

Epoch: 6| Step: 9
Training loss: 2.9986932277679443
Validation loss: 2.1825121115612727

Epoch: 6| Step: 10
Training loss: 3.1835641860961914
Validation loss: 2.180338148147829

Epoch: 6| Step: 11
Training loss: 2.6142029762268066
Validation loss: 2.205395088400892

Epoch: 6| Step: 12
Training loss: 2.7033586502075195
Validation loss: 2.2209276460832164

Epoch: 6| Step: 13
Training loss: 2.767744541168213
Validation loss: 2.1982023972336964

Epoch: 214| Step: 0
Training loss: 2.656771183013916
Validation loss: 2.1691404606706355

Epoch: 6| Step: 1
Training loss: 2.3110852241516113
Validation loss: 2.153019077034407

Epoch: 6| Step: 2
Training loss: 2.253795623779297
Validation loss: 2.1249857102670977

Epoch: 6| Step: 3
Training loss: 2.366121768951416
Validation loss: 2.110462398939235

Epoch: 6| Step: 4
Training loss: 1.7820086479187012
Validation loss: 2.126304870010704

Epoch: 6| Step: 5
Training loss: 2.499965190887451
Validation loss: 2.1482436682588313

Epoch: 6| Step: 6
Training loss: 2.2198333740234375
Validation loss: 2.1831272186771518

Epoch: 6| Step: 7
Training loss: 2.922072410583496
Validation loss: 2.246664547151135

Epoch: 6| Step: 8
Training loss: 2.532496452331543
Validation loss: 2.2892080788971274

Epoch: 6| Step: 9
Training loss: 2.0794143676757812
Validation loss: 2.3126676108247493

Epoch: 6| Step: 10
Training loss: 1.9395891427993774
Validation loss: 2.2928516198230047

Epoch: 6| Step: 11
Training loss: 2.7532103061676025
Validation loss: 2.276738920519429

Epoch: 6| Step: 12
Training loss: 3.316732406616211
Validation loss: 2.219462017859182

Epoch: 6| Step: 13
Training loss: 1.706371784210205
Validation loss: 2.1666286299305577

Epoch: 215| Step: 0
Training loss: 2.186370611190796
Validation loss: 2.120328269979005

Epoch: 6| Step: 1
Training loss: 2.4238386154174805
Validation loss: 2.1111631777978714

Epoch: 6| Step: 2
Training loss: 3.400425672531128
Validation loss: 2.106588590529657

Epoch: 6| Step: 3
Training loss: 1.7616060972213745
Validation loss: 2.1265479595430437

Epoch: 6| Step: 4
Training loss: 2.380937099456787
Validation loss: 2.148984532202444

Epoch: 6| Step: 5
Training loss: 1.8137214183807373
Validation loss: 2.1605022402219873

Epoch: 6| Step: 6
Training loss: 2.2535459995269775
Validation loss: 2.1752038873651975

Epoch: 6| Step: 7
Training loss: 2.351045608520508
Validation loss: 2.181892092509936

Epoch: 6| Step: 8
Training loss: 2.4065675735473633
Validation loss: 2.1747831221549743

Epoch: 6| Step: 9
Training loss: 2.0226173400878906
Validation loss: 2.209989615665969

Epoch: 6| Step: 10
Training loss: 2.8783719539642334
Validation loss: 2.220272623082643

Epoch: 6| Step: 11
Training loss: 2.8684985637664795
Validation loss: 2.213071289882865

Epoch: 6| Step: 12
Training loss: 2.3603525161743164
Validation loss: 2.19449794420632

Epoch: 6| Step: 13
Training loss: 2.877035140991211
Validation loss: 2.1977309411571873

Epoch: 216| Step: 0
Training loss: 1.8247252702713013
Validation loss: 2.1834558722793416

Epoch: 6| Step: 1
Training loss: 2.6613121032714844
Validation loss: 2.1966057695368284

Epoch: 6| Step: 2
Training loss: 1.7020388841629028
Validation loss: 2.2012686370521464

Epoch: 6| Step: 3
Training loss: 2.975257158279419
Validation loss: 2.2155123743959653

Epoch: 6| Step: 4
Training loss: 1.8780897855758667
Validation loss: 2.214979435807915

Epoch: 6| Step: 5
Training loss: 2.311471462249756
Validation loss: 2.1781064054017425

Epoch: 6| Step: 6
Training loss: 1.8406944274902344
Validation loss: 2.163242955361643

Epoch: 6| Step: 7
Training loss: 3.032743453979492
Validation loss: 2.1537322023863434

Epoch: 6| Step: 8
Training loss: 2.7429141998291016
Validation loss: 2.1558544866500364

Epoch: 6| Step: 9
Training loss: 2.209984302520752
Validation loss: 2.1348272754300024

Epoch: 6| Step: 10
Training loss: 2.041262626647949
Validation loss: 2.127037089358094

Epoch: 6| Step: 11
Training loss: 2.314650297164917
Validation loss: 2.1358505525896625

Epoch: 6| Step: 12
Training loss: 2.724656105041504
Validation loss: 2.143729261172715

Epoch: 6| Step: 13
Training loss: 2.462526798248291
Validation loss: 2.137664218102732

Epoch: 217| Step: 0
Training loss: 2.5890157222747803
Validation loss: 2.1436685182714976

Epoch: 6| Step: 1
Training loss: 3.2533493041992188
Validation loss: 2.155408864380211

Epoch: 6| Step: 2
Training loss: 2.427751064300537
Validation loss: 2.1344565960668747

Epoch: 6| Step: 3
Training loss: 1.8612687587738037
Validation loss: 2.1355337583890526

Epoch: 6| Step: 4
Training loss: 1.9801888465881348
Validation loss: 2.1343931715975524

Epoch: 6| Step: 5
Training loss: 2.4830751419067383
Validation loss: 2.12500395185204

Epoch: 6| Step: 6
Training loss: 2.8892502784729004
Validation loss: 2.1238234760940715

Epoch: 6| Step: 7
Training loss: 2.27705979347229
Validation loss: 2.127174449223344

Epoch: 6| Step: 8
Training loss: 2.056624412536621
Validation loss: 2.1355161538688083

Epoch: 6| Step: 9
Training loss: 2.800727128982544
Validation loss: 2.1394042712385937

Epoch: 6| Step: 10
Training loss: 2.1008987426757812
Validation loss: 2.144285689118088

Epoch: 6| Step: 11
Training loss: 1.3369228839874268
Validation loss: 2.1605430982446157

Epoch: 6| Step: 12
Training loss: 1.929521918296814
Validation loss: 2.140584771351148

Epoch: 6| Step: 13
Training loss: 2.348489999771118
Validation loss: 2.1672612274846723

Epoch: 218| Step: 0
Training loss: 2.251020908355713
Validation loss: 2.1531075149454098

Epoch: 6| Step: 1
Training loss: 1.86002516746521
Validation loss: 2.152114647690968

Epoch: 6| Step: 2
Training loss: 2.557314872741699
Validation loss: 2.1569784713047806

Epoch: 6| Step: 3
Training loss: 3.4924609661102295
Validation loss: 2.1646566672991683

Epoch: 6| Step: 4
Training loss: 2.406515121459961
Validation loss: 2.163754532414098

Epoch: 6| Step: 5
Training loss: 2.044783115386963
Validation loss: 2.1577794962031867

Epoch: 6| Step: 6
Training loss: 1.9800245761871338
Validation loss: 2.1530295802700903

Epoch: 6| Step: 7
Training loss: 2.1018059253692627
Validation loss: 2.142832843206262

Epoch: 6| Step: 8
Training loss: 2.3585333824157715
Validation loss: 2.1435051912902505

Epoch: 6| Step: 9
Training loss: 2.070460557937622
Validation loss: 2.153801223283173

Epoch: 6| Step: 10
Training loss: 2.125582695007324
Validation loss: 2.1713040644122708

Epoch: 6| Step: 11
Training loss: 2.430166006088257
Validation loss: 2.1801701758497503

Epoch: 6| Step: 12
Training loss: 2.2870593070983887
Validation loss: 2.168574492136637

Epoch: 6| Step: 13
Training loss: 2.2369191646575928
Validation loss: 2.164094373744021

Epoch: 219| Step: 0
Training loss: 2.1236627101898193
Validation loss: 2.1877479527586248

Epoch: 6| Step: 1
Training loss: 2.0379137992858887
Validation loss: 2.1920678513024443

Epoch: 6| Step: 2
Training loss: 2.028291940689087
Validation loss: 2.185718479976859

Epoch: 6| Step: 3
Training loss: 2.9493584632873535
Validation loss: 2.1786919768138597

Epoch: 6| Step: 4
Training loss: 2.275052070617676
Validation loss: 2.1739807667270785

Epoch: 6| Step: 5
Training loss: 1.6697900295257568
Validation loss: 2.160610642484439

Epoch: 6| Step: 6
Training loss: 2.591601848602295
Validation loss: 2.153495675774031

Epoch: 6| Step: 7
Training loss: 2.257262706756592
Validation loss: 2.15094526608785

Epoch: 6| Step: 8
Training loss: 2.3539299964904785
Validation loss: 2.1652175995611374

Epoch: 6| Step: 9
Training loss: 2.325141191482544
Validation loss: 2.16714132729397

Epoch: 6| Step: 10
Training loss: 2.554659605026245
Validation loss: 2.178794704457765

Epoch: 6| Step: 11
Training loss: 2.8095216751098633
Validation loss: 2.1661280765328357

Epoch: 6| Step: 12
Training loss: 1.828627109527588
Validation loss: 2.160034356578704

Epoch: 6| Step: 13
Training loss: 2.8405025005340576
Validation loss: 2.1500350788075435

Epoch: 220| Step: 0
Training loss: 2.038759708404541
Validation loss: 2.1538574490495908

Epoch: 6| Step: 1
Training loss: 1.7985057830810547
Validation loss: 2.135868449364939

Epoch: 6| Step: 2
Training loss: 2.7798924446105957
Validation loss: 2.141296216236648

Epoch: 6| Step: 3
Training loss: 2.255734920501709
Validation loss: 2.1411532804530156

Epoch: 6| Step: 4
Training loss: 2.380403518676758
Validation loss: 2.15741475166813

Epoch: 6| Step: 5
Training loss: 2.583573579788208
Validation loss: 2.176446860836398

Epoch: 6| Step: 6
Training loss: 2.4088759422302246
Validation loss: 2.1802903939318914

Epoch: 6| Step: 7
Training loss: 2.3289432525634766
Validation loss: 2.197275774453276

Epoch: 6| Step: 8
Training loss: 2.737607479095459
Validation loss: 2.1823812505250335

Epoch: 6| Step: 9
Training loss: 2.05107045173645
Validation loss: 2.1572059867202595

Epoch: 6| Step: 10
Training loss: 2.665832281112671
Validation loss: 2.1366392374038696

Epoch: 6| Step: 11
Training loss: 2.2110774517059326
Validation loss: 2.138097068314911

Epoch: 6| Step: 12
Training loss: 2.1484880447387695
Validation loss: 2.1457574828978507

Epoch: 6| Step: 13
Training loss: 2.1224162578582764
Validation loss: 2.1410786721014206

Epoch: 221| Step: 0
Training loss: 2.3133769035339355
Validation loss: 2.1655036223832

Epoch: 6| Step: 1
Training loss: 2.1034417152404785
Validation loss: 2.1877637819577287

Epoch: 6| Step: 2
Training loss: 2.3875808715820312
Validation loss: 2.2131231010601087

Epoch: 6| Step: 3
Training loss: 2.4147579669952393
Validation loss: 2.2158052664931103

Epoch: 6| Step: 4
Training loss: 2.315230369567871
Validation loss: 2.20702717509321

Epoch: 6| Step: 5
Training loss: 2.0508718490600586
Validation loss: 2.195664340449918

Epoch: 6| Step: 6
Training loss: 1.8396179676055908
Validation loss: 2.167513801205543

Epoch: 6| Step: 7
Training loss: 2.8751659393310547
Validation loss: 2.1359459943668817

Epoch: 6| Step: 8
Training loss: 2.1189064979553223
Validation loss: 2.12927076637104

Epoch: 6| Step: 9
Training loss: 1.832917332649231
Validation loss: 2.135576237914383

Epoch: 6| Step: 10
Training loss: 2.457037925720215
Validation loss: 2.149537512051162

Epoch: 6| Step: 11
Training loss: 2.610222339630127
Validation loss: 2.167600218967725

Epoch: 6| Step: 12
Training loss: 2.8309853076934814
Validation loss: 2.158506493414602

Epoch: 6| Step: 13
Training loss: 2.121788263320923
Validation loss: 2.157386061965778

Epoch: 222| Step: 0
Training loss: 2.121875286102295
Validation loss: 2.143884133267146

Epoch: 6| Step: 1
Training loss: 1.9676728248596191
Validation loss: 2.130309058773902

Epoch: 6| Step: 2
Training loss: 2.6338555812835693
Validation loss: 2.1201677937661447

Epoch: 6| Step: 3
Training loss: 2.499629497528076
Validation loss: 2.123279376696515

Epoch: 6| Step: 4
Training loss: 2.6618223190307617
Validation loss: 2.1355250702109387

Epoch: 6| Step: 5
Training loss: 2.1090056896209717
Validation loss: 2.1286423231965754

Epoch: 6| Step: 6
Training loss: 2.46880841255188
Validation loss: 2.1292314913965042

Epoch: 6| Step: 7
Training loss: 2.040933132171631
Validation loss: 2.124557323353265

Epoch: 6| Step: 8
Training loss: 2.3581223487854004
Validation loss: 2.1264774286618797

Epoch: 6| Step: 9
Training loss: 2.5574378967285156
Validation loss: 2.130300639778055

Epoch: 6| Step: 10
Training loss: 2.4310302734375
Validation loss: 2.1348736337436143

Epoch: 6| Step: 11
Training loss: 2.021455764770508
Validation loss: 2.1471918641879992

Epoch: 6| Step: 12
Training loss: 1.8636243343353271
Validation loss: 2.1549119359703472

Epoch: 6| Step: 13
Training loss: 2.0567169189453125
Validation loss: 2.1661118179239254

Epoch: 223| Step: 0
Training loss: 1.9226199388504028
Validation loss: 2.1738361312497045

Epoch: 6| Step: 1
Training loss: 2.0181972980499268
Validation loss: 2.1809262793551207

Epoch: 6| Step: 2
Training loss: 1.970559000968933
Validation loss: 2.177864892508394

Epoch: 6| Step: 3
Training loss: 2.2212281227111816
Validation loss: 2.182617151609031

Epoch: 6| Step: 4
Training loss: 2.1653313636779785
Validation loss: 2.1578184609772055

Epoch: 6| Step: 5
Training loss: 2.7199301719665527
Validation loss: 2.1336570298799904

Epoch: 6| Step: 6
Training loss: 3.0380938053131104
Validation loss: 2.1171004144094323

Epoch: 6| Step: 7
Training loss: 2.2187798023223877
Validation loss: 2.1123997114037953

Epoch: 6| Step: 8
Training loss: 2.0651164054870605
Validation loss: 2.1032463299330844

Epoch: 6| Step: 9
Training loss: 2.1277406215667725
Validation loss: 2.106759414877943

Epoch: 6| Step: 10
Training loss: 2.294182777404785
Validation loss: 2.11539117751583

Epoch: 6| Step: 11
Training loss: 1.9782264232635498
Validation loss: 2.115307366976174

Epoch: 6| Step: 12
Training loss: 2.631228446960449
Validation loss: 2.1148612396691435

Epoch: 6| Step: 13
Training loss: 3.159271001815796
Validation loss: 2.1190925618653655

Epoch: 224| Step: 0
Training loss: 2.2133402824401855
Validation loss: 2.1248169611859065

Epoch: 6| Step: 1
Training loss: 2.203328847885132
Validation loss: 2.110106952728764

Epoch: 6| Step: 2
Training loss: 2.469797134399414
Validation loss: 2.1215933369052027

Epoch: 6| Step: 3
Training loss: 2.2816319465637207
Validation loss: 2.1226783106403966

Epoch: 6| Step: 4
Training loss: 3.1619150638580322
Validation loss: 2.125243330514559

Epoch: 6| Step: 5
Training loss: 2.5737409591674805
Validation loss: 2.120062433263307

Epoch: 6| Step: 6
Training loss: 1.977392315864563
Validation loss: 2.1235306314242783

Epoch: 6| Step: 7
Training loss: 2.146453619003296
Validation loss: 2.1221159299214682

Epoch: 6| Step: 8
Training loss: 2.3026745319366455
Validation loss: 2.1378518099425943

Epoch: 6| Step: 9
Training loss: 2.316650867462158
Validation loss: 2.153622793894942

Epoch: 6| Step: 10
Training loss: 2.1144559383392334
Validation loss: 2.1637575523827666

Epoch: 6| Step: 11
Training loss: 1.4844200611114502
Validation loss: 2.16091929071693

Epoch: 6| Step: 12
Training loss: 2.5797665119171143
Validation loss: 2.1704695199125554

Epoch: 6| Step: 13
Training loss: 1.803885579109192
Validation loss: 2.17705895311089

Epoch: 225| Step: 0
Training loss: 2.131091594696045
Validation loss: 2.1696869301539596

Epoch: 6| Step: 1
Training loss: 2.1323792934417725
Validation loss: 2.163464243694018

Epoch: 6| Step: 2
Training loss: 2.6176233291625977
Validation loss: 2.1495034335761942

Epoch: 6| Step: 3
Training loss: 1.9052776098251343
Validation loss: 2.125239687581216

Epoch: 6| Step: 4
Training loss: 2.521153450012207
Validation loss: 2.1242383128853253

Epoch: 6| Step: 5
Training loss: 2.6039466857910156
Validation loss: 2.1402415011518743

Epoch: 6| Step: 6
Training loss: 2.197934865951538
Validation loss: 2.1268133912035214

Epoch: 6| Step: 7
Training loss: 2.1852807998657227
Validation loss: 2.1474473809683197

Epoch: 6| Step: 8
Training loss: 1.5717371702194214
Validation loss: 2.1370520719917874

Epoch: 6| Step: 9
Training loss: 3.0883636474609375
Validation loss: 2.134300865152831

Epoch: 6| Step: 10
Training loss: 1.8620389699935913
Validation loss: 2.136833001208562

Epoch: 6| Step: 11
Training loss: 2.9023635387420654
Validation loss: 2.1306024841082993

Epoch: 6| Step: 12
Training loss: 1.4758323431015015
Validation loss: 2.1235999612398047

Epoch: 6| Step: 13
Training loss: 2.708162307739258
Validation loss: 2.110656435771655

Epoch: 226| Step: 0
Training loss: 2.5349550247192383
Validation loss: 2.123031520074414

Epoch: 6| Step: 1
Training loss: 2.825774669647217
Validation loss: 2.1043553095991894

Epoch: 6| Step: 2
Training loss: 2.2908949851989746
Validation loss: 2.103780161949896

Epoch: 6| Step: 3
Training loss: 2.5551505088806152
Validation loss: 2.115191944183842

Epoch: 6| Step: 4
Training loss: 2.0598936080932617
Validation loss: 2.1024829751701763

Epoch: 6| Step: 5
Training loss: 1.8765392303466797
Validation loss: 2.115817346880513

Epoch: 6| Step: 6
Training loss: 2.4576797485351562
Validation loss: 2.1118762570042766

Epoch: 6| Step: 7
Training loss: 1.424293041229248
Validation loss: 2.1044295885229625

Epoch: 6| Step: 8
Training loss: 2.311300277709961
Validation loss: 2.1204241527024137

Epoch: 6| Step: 9
Training loss: 2.5847108364105225
Validation loss: 2.1202189153240574

Epoch: 6| Step: 10
Training loss: 2.6668148040771484
Validation loss: 2.128871971561063

Epoch: 6| Step: 11
Training loss: 1.8496143817901611
Validation loss: 2.1366741323983796

Epoch: 6| Step: 12
Training loss: 2.077674627304077
Validation loss: 2.1233027724809546

Epoch: 6| Step: 13
Training loss: 1.7679486274719238
Validation loss: 2.1192522638587543

Epoch: 227| Step: 0
Training loss: 2.580378532409668
Validation loss: 2.1139179250245452

Epoch: 6| Step: 1
Training loss: 2.06587553024292
Validation loss: 2.123415582923479

Epoch: 6| Step: 2
Training loss: 2.5927462577819824
Validation loss: 2.114448619145219

Epoch: 6| Step: 3
Training loss: 2.2828140258789062
Validation loss: 2.1172352401159142

Epoch: 6| Step: 4
Training loss: 2.046156167984009
Validation loss: 2.1262098973797214

Epoch: 6| Step: 5
Training loss: 2.558225393295288
Validation loss: 2.144512138059062

Epoch: 6| Step: 6
Training loss: 2.48280930519104
Validation loss: 2.1268835554840746

Epoch: 6| Step: 7
Training loss: 2.666231870651245
Validation loss: 2.133615670665618

Epoch: 6| Step: 8
Training loss: 1.6069586277008057
Validation loss: 2.1262702429166405

Epoch: 6| Step: 9
Training loss: 2.613494396209717
Validation loss: 2.1098111547449583

Epoch: 6| Step: 10
Training loss: 1.9279378652572632
Validation loss: 2.0957042107018093

Epoch: 6| Step: 11
Training loss: 2.0481224060058594
Validation loss: 2.0982612153535247

Epoch: 6| Step: 12
Training loss: 2.2839746475219727
Validation loss: 2.0915630632831204

Epoch: 6| Step: 13
Training loss: 1.6018643379211426
Validation loss: 2.1002837483600905

Epoch: 228| Step: 0
Training loss: 2.268932819366455
Validation loss: 2.105037109826201

Epoch: 6| Step: 1
Training loss: 2.222804307937622
Validation loss: 2.119319867062312

Epoch: 6| Step: 2
Training loss: 2.304841995239258
Validation loss: 2.1501413135118383

Epoch: 6| Step: 3
Training loss: 1.262444019317627
Validation loss: 2.15171617333607

Epoch: 6| Step: 4
Training loss: 2.2262463569641113
Validation loss: 2.150885389697167

Epoch: 6| Step: 5
Training loss: 2.3327250480651855
Validation loss: 2.1260716504948114

Epoch: 6| Step: 6
Training loss: 2.139720916748047
Validation loss: 2.1156088382967058

Epoch: 6| Step: 7
Training loss: 2.747769355773926
Validation loss: 2.105269980686967

Epoch: 6| Step: 8
Training loss: 2.909672498703003
Validation loss: 2.1134445641630437

Epoch: 6| Step: 9
Training loss: 2.4615135192871094
Validation loss: 2.1284457022143948

Epoch: 6| Step: 10
Training loss: 1.6691434383392334
Validation loss: 2.13340453819562

Epoch: 6| Step: 11
Training loss: 2.778367042541504
Validation loss: 2.147678106061874

Epoch: 6| Step: 12
Training loss: 2.410634994506836
Validation loss: 2.135135886489704

Epoch: 6| Step: 13
Training loss: 1.9108115434646606
Validation loss: 2.1304122747913485

Epoch: 229| Step: 0
Training loss: 1.9864956140518188
Validation loss: 2.1332304426418838

Epoch: 6| Step: 1
Training loss: 2.2097668647766113
Validation loss: 2.137017939680366

Epoch: 6| Step: 2
Training loss: 2.081125259399414
Validation loss: 2.1588665593054985

Epoch: 6| Step: 3
Training loss: 2.2457001209259033
Validation loss: 2.1520495132733415

Epoch: 6| Step: 4
Training loss: 2.6016221046447754
Validation loss: 2.1631629005555184

Epoch: 6| Step: 5
Training loss: 2.7296202182769775
Validation loss: 2.170704674977128

Epoch: 6| Step: 6
Training loss: 2.091536045074463
Validation loss: 2.165605519407539

Epoch: 6| Step: 7
Training loss: 1.7878774404525757
Validation loss: 2.189642554970198

Epoch: 6| Step: 8
Training loss: 2.440964698791504
Validation loss: 2.160698988104379

Epoch: 6| Step: 9
Training loss: 2.406920909881592
Validation loss: 2.1469484580460416

Epoch: 6| Step: 10
Training loss: 2.2423558235168457
Validation loss: 2.124889055887858

Epoch: 6| Step: 11
Training loss: 2.295013904571533
Validation loss: 2.1057141391179894

Epoch: 6| Step: 12
Training loss: 2.102062940597534
Validation loss: 2.1063588037285754

Epoch: 6| Step: 13
Training loss: 2.042725086212158
Validation loss: 2.110472644529035

Epoch: 230| Step: 0
Training loss: 2.5133652687072754
Validation loss: 2.127002182827201

Epoch: 6| Step: 1
Training loss: 2.201878309249878
Validation loss: 2.1203288878163984

Epoch: 6| Step: 2
Training loss: 2.6048989295959473
Validation loss: 2.1282309242474136

Epoch: 6| Step: 3
Training loss: 2.6162350177764893
Validation loss: 2.1274233479653635

Epoch: 6| Step: 4
Training loss: 2.576735019683838
Validation loss: 2.112484521763299

Epoch: 6| Step: 5
Training loss: 2.135498046875
Validation loss: 2.096934756925029

Epoch: 6| Step: 6
Training loss: 1.9156270027160645
Validation loss: 2.095932678509784

Epoch: 6| Step: 7
Training loss: 2.913461685180664
Validation loss: 2.098211234615695

Epoch: 6| Step: 8
Training loss: 1.9538097381591797
Validation loss: 2.0915700620220554

Epoch: 6| Step: 9
Training loss: 2.0383942127227783
Validation loss: 2.1224605409047936

Epoch: 6| Step: 10
Training loss: 2.068424940109253
Validation loss: 2.10769969929931

Epoch: 6| Step: 11
Training loss: 1.7528822422027588
Validation loss: 2.107619006146667

Epoch: 6| Step: 12
Training loss: 2.2191741466522217
Validation loss: 2.073986922540972

Epoch: 6| Step: 13
Training loss: 2.174237012863159
Validation loss: 2.063209286300085

Epoch: 231| Step: 0
Training loss: 1.922173261642456
Validation loss: 2.0790908157184558

Epoch: 6| Step: 1
Training loss: 2.010263442993164
Validation loss: 2.08871042343878

Epoch: 6| Step: 2
Training loss: 1.90276038646698
Validation loss: 2.101762512678741

Epoch: 6| Step: 3
Training loss: 2.5472359657287598
Validation loss: 2.1176554772161666

Epoch: 6| Step: 4
Training loss: 2.196826934814453
Validation loss: 2.1232713422467633

Epoch: 6| Step: 5
Training loss: 2.1324338912963867
Validation loss: 2.1288712511780443

Epoch: 6| Step: 6
Training loss: 2.148287296295166
Validation loss: 2.1346466233653407

Epoch: 6| Step: 7
Training loss: 2.6004858016967773
Validation loss: 2.1717813630257883

Epoch: 6| Step: 8
Training loss: 2.1034998893737793
Validation loss: 2.210483166479295

Epoch: 6| Step: 9
Training loss: 2.5427801609039307
Validation loss: 2.2116392812421246

Epoch: 6| Step: 10
Training loss: 2.821666717529297
Validation loss: 2.2096179480193765

Epoch: 6| Step: 11
Training loss: 2.052894115447998
Validation loss: 2.1962763852970575

Epoch: 6| Step: 12
Training loss: 2.0096094608306885
Validation loss: 2.181958786902889

Epoch: 6| Step: 13
Training loss: 3.2143282890319824
Validation loss: 2.1690364153154436

Epoch: 232| Step: 0
Training loss: 1.6959893703460693
Validation loss: 2.1424920405111005

Epoch: 6| Step: 1
Training loss: 2.40177583694458
Validation loss: 2.118797068954796

Epoch: 6| Step: 2
Training loss: 2.068692445755005
Validation loss: 2.1095944014928674

Epoch: 6| Step: 3
Training loss: 2.4145703315734863
Validation loss: 2.1106275614871772

Epoch: 6| Step: 4
Training loss: 2.855358123779297
Validation loss: 2.099398712958059

Epoch: 6| Step: 5
Training loss: 2.622241735458374
Validation loss: 2.09010709101154

Epoch: 6| Step: 6
Training loss: 3.1886894702911377
Validation loss: 2.0863983477315595

Epoch: 6| Step: 7
Training loss: 2.53044056892395
Validation loss: 2.078783669779378

Epoch: 6| Step: 8
Training loss: 1.5935600996017456
Validation loss: 2.0774645843813495

Epoch: 6| Step: 9
Training loss: 2.2183656692504883
Validation loss: 2.0728946962664203

Epoch: 6| Step: 10
Training loss: 1.8578550815582275
Validation loss: 2.0682596878338884

Epoch: 6| Step: 11
Training loss: 2.449517250061035
Validation loss: 2.0700200834581928

Epoch: 6| Step: 12
Training loss: 1.3290045261383057
Validation loss: 2.079579640460271

Epoch: 6| Step: 13
Training loss: 1.987001895904541
Validation loss: 2.079020684765231

Epoch: 233| Step: 0
Training loss: 2.0760154724121094
Validation loss: 2.0895583783426592

Epoch: 6| Step: 1
Training loss: 2.2006826400756836
Validation loss: 2.133739773945142

Epoch: 6| Step: 2
Training loss: 2.493974208831787
Validation loss: 2.1452455610357304

Epoch: 6| Step: 3
Training loss: 2.133704662322998
Validation loss: 2.1643506044982583

Epoch: 6| Step: 4
Training loss: 2.6293396949768066
Validation loss: 2.1840231674973682

Epoch: 6| Step: 5
Training loss: 2.2667980194091797
Validation loss: 2.1911182172836794

Epoch: 6| Step: 6
Training loss: 2.805997848510742
Validation loss: 2.203190859927926

Epoch: 6| Step: 7
Training loss: 2.0797832012176514
Validation loss: 2.187592873009302

Epoch: 6| Step: 8
Training loss: 1.7572076320648193
Validation loss: 2.1677881389535885

Epoch: 6| Step: 9
Training loss: 1.730236291885376
Validation loss: 2.1453923691985426

Epoch: 6| Step: 10
Training loss: 2.764659881591797
Validation loss: 2.1367130202631794

Epoch: 6| Step: 11
Training loss: 1.5472208261489868
Validation loss: 2.158297486202691

Epoch: 6| Step: 12
Training loss: 2.681743621826172
Validation loss: 2.1672225459929435

Epoch: 6| Step: 13
Training loss: 2.210498094558716
Validation loss: 2.164053537512338

Epoch: 234| Step: 0
Training loss: 2.6252918243408203
Validation loss: 2.151273254425295

Epoch: 6| Step: 1
Training loss: 2.3970494270324707
Validation loss: 2.131878552898284

Epoch: 6| Step: 2
Training loss: 2.3013641834259033
Validation loss: 2.124687994680097

Epoch: 6| Step: 3
Training loss: 2.2135939598083496
Validation loss: 2.1005822048392346

Epoch: 6| Step: 4
Training loss: 2.560943603515625
Validation loss: 2.0986685445231776

Epoch: 6| Step: 5
Training loss: 2.038379669189453
Validation loss: 2.0925537770794285

Epoch: 6| Step: 6
Training loss: 2.648401975631714
Validation loss: 2.1097094012844946

Epoch: 6| Step: 7
Training loss: 2.141887664794922
Validation loss: 2.1268752697975404

Epoch: 6| Step: 8
Training loss: 2.620911121368408
Validation loss: 2.12868235957238

Epoch: 6| Step: 9
Training loss: 1.7403755187988281
Validation loss: 2.1427954089257026

Epoch: 6| Step: 10
Training loss: 2.1354360580444336
Validation loss: 2.1123164007740636

Epoch: 6| Step: 11
Training loss: 1.6088488101959229
Validation loss: 2.0997226943251905

Epoch: 6| Step: 12
Training loss: 1.8194550275802612
Validation loss: 2.110314239737808

Epoch: 6| Step: 13
Training loss: 2.615058422088623
Validation loss: 2.111506405697074

Epoch: 235| Step: 0
Training loss: 1.532167911529541
Validation loss: 2.1226387152107815

Epoch: 6| Step: 1
Training loss: 2.6126956939697266
Validation loss: 2.1092869581714755

Epoch: 6| Step: 2
Training loss: 2.2191662788391113
Validation loss: 2.1180287304744927

Epoch: 6| Step: 3
Training loss: 2.5243077278137207
Validation loss: 2.1146738426659697

Epoch: 6| Step: 4
Training loss: 1.967340350151062
Validation loss: 2.1144935700201217

Epoch: 6| Step: 5
Training loss: 2.0348281860351562
Validation loss: 2.1127783611256588

Epoch: 6| Step: 6
Training loss: 2.464240074157715
Validation loss: 2.096473002946505

Epoch: 6| Step: 7
Training loss: 2.658754348754883
Validation loss: 2.11465105190072

Epoch: 6| Step: 8
Training loss: 2.5227091312408447
Validation loss: 2.149045963441172

Epoch: 6| Step: 9
Training loss: 2.41237735748291
Validation loss: 2.1467055466867264

Epoch: 6| Step: 10
Training loss: 2.5764126777648926
Validation loss: 2.1465420466597362

Epoch: 6| Step: 11
Training loss: 2.184800386428833
Validation loss: 2.1535458372485254

Epoch: 6| Step: 12
Training loss: 1.722528338432312
Validation loss: 2.135567279272182

Epoch: 6| Step: 13
Training loss: 1.7051732540130615
Validation loss: 2.1240479177044285

Epoch: 236| Step: 0
Training loss: 2.112088203430176
Validation loss: 2.127821610819909

Epoch: 6| Step: 1
Training loss: 2.5168910026550293
Validation loss: 2.122323477140037

Epoch: 6| Step: 2
Training loss: 2.1201446056365967
Validation loss: 2.1371743499591784

Epoch: 6| Step: 3
Training loss: 2.141601800918579
Validation loss: 2.127099299943575

Epoch: 6| Step: 4
Training loss: 2.054551601409912
Validation loss: 2.1221466884818128

Epoch: 6| Step: 5
Training loss: 1.8228825330734253
Validation loss: 2.110508736743722

Epoch: 6| Step: 6
Training loss: 2.467341423034668
Validation loss: 2.1055103155874435

Epoch: 6| Step: 7
Training loss: 2.2208166122436523
Validation loss: 2.114283715524981

Epoch: 6| Step: 8
Training loss: 2.116410255432129
Validation loss: 2.1095192355494343

Epoch: 6| Step: 9
Training loss: 2.5203025341033936
Validation loss: 2.0954162818129345

Epoch: 6| Step: 10
Training loss: 1.9662754535675049
Validation loss: 2.1029850693159204

Epoch: 6| Step: 11
Training loss: 1.8058052062988281
Validation loss: 2.0965497929562806

Epoch: 6| Step: 12
Training loss: 2.4954655170440674
Validation loss: 2.1094017464627504

Epoch: 6| Step: 13
Training loss: 2.9507017135620117
Validation loss: 2.112476841095955

Epoch: 237| Step: 0
Training loss: 2.6344528198242188
Validation loss: 2.129919780197964

Epoch: 6| Step: 1
Training loss: 1.6209120750427246
Validation loss: 2.140280444134948

Epoch: 6| Step: 2
Training loss: 2.030395269393921
Validation loss: 2.169491660210394

Epoch: 6| Step: 3
Training loss: 1.8544728755950928
Validation loss: 2.1817273068171676

Epoch: 6| Step: 4
Training loss: 2.4749131202697754
Validation loss: 2.199064989243784

Epoch: 6| Step: 5
Training loss: 2.9822006225585938
Validation loss: 2.194584201740962

Epoch: 6| Step: 6
Training loss: 2.8710126876831055
Validation loss: 2.1840977168852285

Epoch: 6| Step: 7
Training loss: 2.877224922180176
Validation loss: 2.17079706217653

Epoch: 6| Step: 8
Training loss: 1.732080340385437
Validation loss: 2.1425160720784175

Epoch: 6| Step: 9
Training loss: 2.168801784515381
Validation loss: 2.1449857475937053

Epoch: 6| Step: 10
Training loss: 2.244663953781128
Validation loss: 2.1402406974505355

Epoch: 6| Step: 11
Training loss: 1.4147506952285767
Validation loss: 2.126059536010988

Epoch: 6| Step: 12
Training loss: 2.356661796569824
Validation loss: 2.1261624777188866

Epoch: 6| Step: 13
Training loss: 1.256611704826355
Validation loss: 2.120378815999595

Epoch: 238| Step: 0
Training loss: 1.9870350360870361
Validation loss: 2.1227080591263308

Epoch: 6| Step: 1
Training loss: 2.747145175933838
Validation loss: 2.109999005512525

Epoch: 6| Step: 2
Training loss: 1.7159616947174072
Validation loss: 2.1031734917753484

Epoch: 6| Step: 3
Training loss: 2.6488265991210938
Validation loss: 2.102609303689772

Epoch: 6| Step: 4
Training loss: 2.6179986000061035
Validation loss: 2.077415979036721

Epoch: 6| Step: 5
Training loss: 2.7528069019317627
Validation loss: 2.0847011432852796

Epoch: 6| Step: 6
Training loss: 1.866131067276001
Validation loss: 2.0855819538075435

Epoch: 6| Step: 7
Training loss: 1.4012081623077393
Validation loss: 2.0830515020637104

Epoch: 6| Step: 8
Training loss: 1.5179659128189087
Validation loss: 2.100394052843894

Epoch: 6| Step: 9
Training loss: 2.891995429992676
Validation loss: 2.09502855167594

Epoch: 6| Step: 10
Training loss: 1.535980463027954
Validation loss: 2.0984440900946177

Epoch: 6| Step: 11
Training loss: 2.893535614013672
Validation loss: 2.1079990761254424

Epoch: 6| Step: 12
Training loss: 1.9101120233535767
Validation loss: 2.109202338803199

Epoch: 6| Step: 13
Training loss: 2.677203416824341
Validation loss: 2.13611206957089

Epoch: 239| Step: 0
Training loss: 1.9747505187988281
Validation loss: 2.1685009976868987

Epoch: 6| Step: 1
Training loss: 2.9962010383605957
Validation loss: 2.1664755062390397

Epoch: 6| Step: 2
Training loss: 2.6487088203430176
Validation loss: 2.15419949254682

Epoch: 6| Step: 3
Training loss: 2.27217960357666
Validation loss: 2.1391573336816605

Epoch: 6| Step: 4
Training loss: 2.4061999320983887
Validation loss: 2.1309818221676733

Epoch: 6| Step: 5
Training loss: 2.5934619903564453
Validation loss: 2.102527669681016

Epoch: 6| Step: 6
Training loss: 1.4996941089630127
Validation loss: 2.0813471373691352

Epoch: 6| Step: 7
Training loss: 2.0929856300354004
Validation loss: 2.073459376570999

Epoch: 6| Step: 8
Training loss: 1.8679001331329346
Validation loss: 2.065110122003863

Epoch: 6| Step: 9
Training loss: 1.9322179555892944
Validation loss: 2.0636810743680565

Epoch: 6| Step: 10
Training loss: 2.2556066513061523
Validation loss: 2.0654820062780894

Epoch: 6| Step: 11
Training loss: 2.1089510917663574
Validation loss: 2.0686469283155215

Epoch: 6| Step: 12
Training loss: 2.482698917388916
Validation loss: 2.0673436528892926

Epoch: 6| Step: 13
Training loss: 1.5593552589416504
Validation loss: 2.0802771942589873

Epoch: 240| Step: 0
Training loss: 1.706371784210205
Validation loss: 2.073905006531746

Epoch: 6| Step: 1
Training loss: 3.0949251651763916
Validation loss: 2.097899977878858

Epoch: 6| Step: 2
Training loss: 2.110912322998047
Validation loss: 2.108316539436258

Epoch: 6| Step: 3
Training loss: 2.3588151931762695
Validation loss: 2.1072534438102477

Epoch: 6| Step: 4
Training loss: 2.3207573890686035
Validation loss: 2.1206739769187024

Epoch: 6| Step: 5
Training loss: 1.9898362159729004
Validation loss: 2.1293719789033294

Epoch: 6| Step: 6
Training loss: 2.1423635482788086
Validation loss: 2.137890633716378

Epoch: 6| Step: 7
Training loss: 1.9667394161224365
Validation loss: 2.139928256311724

Epoch: 6| Step: 8
Training loss: 2.4896903038024902
Validation loss: 2.157072756880073

Epoch: 6| Step: 9
Training loss: 2.0927531719207764
Validation loss: 2.164221553392308

Epoch: 6| Step: 10
Training loss: 1.9439067840576172
Validation loss: 2.153689569042575

Epoch: 6| Step: 11
Training loss: 2.0673162937164307
Validation loss: 2.1405443863202165

Epoch: 6| Step: 12
Training loss: 2.364544630050659
Validation loss: 2.130245663786447

Epoch: 6| Step: 13
Training loss: 1.7804194688796997
Validation loss: 2.147859569518797

Epoch: 241| Step: 0
Training loss: 2.3353936672210693
Validation loss: 2.1316394062452417

Epoch: 6| Step: 1
Training loss: 2.2741103172302246
Validation loss: 2.1199523979617703

Epoch: 6| Step: 2
Training loss: 1.9147751331329346
Validation loss: 2.1057336996960383

Epoch: 6| Step: 3
Training loss: 1.8716355562210083
Validation loss: 2.07554873599801

Epoch: 6| Step: 4
Training loss: 1.805228590965271
Validation loss: 2.064824402973216

Epoch: 6| Step: 5
Training loss: 1.8024656772613525
Validation loss: 2.065241099685751

Epoch: 6| Step: 6
Training loss: 1.6871508359909058
Validation loss: 2.064568543946871

Epoch: 6| Step: 7
Training loss: 2.531376838684082
Validation loss: 2.087375181977467

Epoch: 6| Step: 8
Training loss: 2.7055277824401855
Validation loss: 2.082707602490661

Epoch: 6| Step: 9
Training loss: 1.930932641029358
Validation loss: 2.094080391750541

Epoch: 6| Step: 10
Training loss: 1.7807644605636597
Validation loss: 2.090632777060232

Epoch: 6| Step: 11
Training loss: 2.6917920112609863
Validation loss: 2.094851257980511

Epoch: 6| Step: 12
Training loss: 2.467620372772217
Validation loss: 2.096454930561845

Epoch: 6| Step: 13
Training loss: 3.5508220195770264
Validation loss: 2.1143596133878155

Epoch: 242| Step: 0
Training loss: 1.638309359550476
Validation loss: 2.1175032995080434

Epoch: 6| Step: 1
Training loss: 1.9767147302627563
Validation loss: 2.111517011478383

Epoch: 6| Step: 2
Training loss: 2.195145606994629
Validation loss: 2.1145232672332437

Epoch: 6| Step: 3
Training loss: 2.6048593521118164
Validation loss: 2.141189262431155

Epoch: 6| Step: 4
Training loss: 2.0740458965301514
Validation loss: 2.141072847509897

Epoch: 6| Step: 5
Training loss: 1.8680176734924316
Validation loss: 2.150186892478697

Epoch: 6| Step: 6
Training loss: 2.477797031402588
Validation loss: 2.134128330856241

Epoch: 6| Step: 7
Training loss: 2.479203701019287
Validation loss: 2.129589106446953

Epoch: 6| Step: 8
Training loss: 1.481366753578186
Validation loss: 2.116400380288401

Epoch: 6| Step: 9
Training loss: 2.3862171173095703
Validation loss: 2.087448605927088

Epoch: 6| Step: 10
Training loss: 1.9011374711990356
Validation loss: 2.076640513635451

Epoch: 6| Step: 11
Training loss: 2.96419620513916
Validation loss: 2.063287801640008

Epoch: 6| Step: 12
Training loss: 2.028578758239746
Validation loss: 2.070552279872279

Epoch: 6| Step: 13
Training loss: 2.733517646789551
Validation loss: 2.074653272987694

Epoch: 243| Step: 0
Training loss: 2.5917608737945557
Validation loss: 2.078007722413668

Epoch: 6| Step: 1
Training loss: 2.1225719451904297
Validation loss: 2.0794334027074997

Epoch: 6| Step: 2
Training loss: 2.3664374351501465
Validation loss: 2.0571402003688197

Epoch: 6| Step: 3
Training loss: 1.7035194635391235
Validation loss: 2.048236818723781

Epoch: 6| Step: 4
Training loss: 2.3632314205169678
Validation loss: 2.062446253274077

Epoch: 6| Step: 5
Training loss: 2.2754013538360596
Validation loss: 2.0870405192016275

Epoch: 6| Step: 6
Training loss: 1.5131739377975464
Validation loss: 2.0943702754154

Epoch: 6| Step: 7
Training loss: 1.4618370532989502
Validation loss: 2.0729374783013457

Epoch: 6| Step: 8
Training loss: 2.1920018196105957
Validation loss: 2.090850414768342

Epoch: 6| Step: 9
Training loss: 2.3198812007904053
Validation loss: 2.104103970271285

Epoch: 6| Step: 10
Training loss: 2.9719653129577637
Validation loss: 2.116994728324234

Epoch: 6| Step: 11
Training loss: 2.206963539123535
Validation loss: 2.106957438171551

Epoch: 6| Step: 12
Training loss: 2.747180223464966
Validation loss: 2.1207110625441357

Epoch: 6| Step: 13
Training loss: 1.3438624143600464
Validation loss: 2.1122919718424478

Epoch: 244| Step: 0
Training loss: 1.8515346050262451
Validation loss: 2.114485204860728

Epoch: 6| Step: 1
Training loss: 2.2244601249694824
Validation loss: 2.1372271019925355

Epoch: 6| Step: 2
Training loss: 2.24595046043396
Validation loss: 2.1263093127999255

Epoch: 6| Step: 3
Training loss: 1.870086669921875
Validation loss: 2.1377158549524125

Epoch: 6| Step: 4
Training loss: 1.7917835712432861
Validation loss: 2.1448345825236332

Epoch: 6| Step: 5
Training loss: 2.8917441368103027
Validation loss: 2.1386172925272295

Epoch: 6| Step: 6
Training loss: 1.8675765991210938
Validation loss: 2.1299386460294008

Epoch: 6| Step: 7
Training loss: 1.2418630123138428
Validation loss: 2.123645950389165

Epoch: 6| Step: 8
Training loss: 1.6630914211273193
Validation loss: 2.13260821629596

Epoch: 6| Step: 9
Training loss: 2.7296462059020996
Validation loss: 2.1187632981167046

Epoch: 6| Step: 10
Training loss: 2.550264596939087
Validation loss: 2.105282874517543

Epoch: 6| Step: 11
Training loss: 1.9107210636138916
Validation loss: 2.085053595163489

Epoch: 6| Step: 12
Training loss: 2.8035740852355957
Validation loss: 2.0953572232236146

Epoch: 6| Step: 13
Training loss: 3.0714447498321533
Validation loss: 2.0791064257262857

Epoch: 245| Step: 0
Training loss: 1.6949708461761475
Validation loss: 2.0802072017423567

Epoch: 6| Step: 1
Training loss: 1.819795846939087
Validation loss: 2.0668198306073426

Epoch: 6| Step: 2
Training loss: 1.8158671855926514
Validation loss: 2.0620208683834282

Epoch: 6| Step: 3
Training loss: 3.0216407775878906
Validation loss: 2.058690386433755

Epoch: 6| Step: 4
Training loss: 2.1110987663269043
Validation loss: 2.062442292449295

Epoch: 6| Step: 5
Training loss: 2.026878833770752
Validation loss: 2.0752393302097114

Epoch: 6| Step: 6
Training loss: 2.152886390686035
Validation loss: 2.068813139392484

Epoch: 6| Step: 7
Training loss: 2.091174602508545
Validation loss: 2.0785857708223405

Epoch: 6| Step: 8
Training loss: 1.624210238456726
Validation loss: 2.086727426898095

Epoch: 6| Step: 9
Training loss: 1.7144160270690918
Validation loss: 2.0984056752215148

Epoch: 6| Step: 10
Training loss: 2.194575071334839
Validation loss: 2.1128167208804878

Epoch: 6| Step: 11
Training loss: 2.906486988067627
Validation loss: 2.112496982338608

Epoch: 6| Step: 12
Training loss: 2.7648661136627197
Validation loss: 2.1355272544327604

Epoch: 6| Step: 13
Training loss: 2.665679931640625
Validation loss: 2.1462060251543598

Epoch: 246| Step: 0
Training loss: 2.0117900371551514
Validation loss: 2.1479846444181216

Epoch: 6| Step: 1
Training loss: 2.1487507820129395
Validation loss: 2.1215287075247815

Epoch: 6| Step: 2
Training loss: 2.1964712142944336
Validation loss: 2.1221818949586604

Epoch: 6| Step: 3
Training loss: 2.62453556060791
Validation loss: 2.0934202953051497

Epoch: 6| Step: 4
Training loss: 2.8967251777648926
Validation loss: 2.0941245235422605

Epoch: 6| Step: 5
Training loss: 2.1251769065856934
Validation loss: 2.101496201689525

Epoch: 6| Step: 6
Training loss: 2.600130558013916
Validation loss: 2.128516932969452

Epoch: 6| Step: 7
Training loss: 1.2589802742004395
Validation loss: 2.1341502448563934

Epoch: 6| Step: 8
Training loss: 1.7343651056289673
Validation loss: 2.1257747129727433

Epoch: 6| Step: 9
Training loss: 2.8905701637268066
Validation loss: 2.1130576723365375

Epoch: 6| Step: 10
Training loss: 1.9132556915283203
Validation loss: 2.0960598248307423

Epoch: 6| Step: 11
Training loss: 2.3836121559143066
Validation loss: 2.078844601108182

Epoch: 6| Step: 12
Training loss: 2.1061224937438965
Validation loss: 2.078163795573737

Epoch: 6| Step: 13
Training loss: 1.1267218589782715
Validation loss: 2.0771539211273193

Epoch: 247| Step: 0
Training loss: 1.9236698150634766
Validation loss: 2.0850226725301435

Epoch: 6| Step: 1
Training loss: 2.438098192214966
Validation loss: 2.1022478098510415

Epoch: 6| Step: 2
Training loss: 1.7893915176391602
Validation loss: 2.1074306990510676

Epoch: 6| Step: 3
Training loss: 1.8085777759552002
Validation loss: 2.103404632178686

Epoch: 6| Step: 4
Training loss: 2.134023666381836
Validation loss: 2.113352874273895

Epoch: 6| Step: 5
Training loss: 2.5877926349639893
Validation loss: 2.1386877849537838

Epoch: 6| Step: 6
Training loss: 2.9912328720092773
Validation loss: 2.1467337069972867

Epoch: 6| Step: 7
Training loss: 2.4041738510131836
Validation loss: 2.161308506483673

Epoch: 6| Step: 8
Training loss: 2.39546537399292
Validation loss: 2.165642494796425

Epoch: 6| Step: 9
Training loss: 1.7494149208068848
Validation loss: 2.1527290754420783

Epoch: 6| Step: 10
Training loss: 1.8766412734985352
Validation loss: 2.166780326956062

Epoch: 6| Step: 11
Training loss: 1.8807328939437866
Validation loss: 2.1432099239800566

Epoch: 6| Step: 12
Training loss: 2.1810526847839355
Validation loss: 2.1205452385769097

Epoch: 6| Step: 13
Training loss: 2.126220226287842
Validation loss: 2.102269728978475

Epoch: 248| Step: 0
Training loss: 1.3872458934783936
Validation loss: 2.1016700626701437

Epoch: 6| Step: 1
Training loss: 2.3256893157958984
Validation loss: 2.106600643486105

Epoch: 6| Step: 2
Training loss: 2.169917345046997
Validation loss: 2.100480310378536

Epoch: 6| Step: 3
Training loss: 2.786630868911743
Validation loss: 2.0909377016046995

Epoch: 6| Step: 4
Training loss: 2.235250473022461
Validation loss: 2.09609398406039

Epoch: 6| Step: 5
Training loss: 2.7701821327209473
Validation loss: 2.0955987386806036

Epoch: 6| Step: 6
Training loss: 1.543816328048706
Validation loss: 2.094524332272109

Epoch: 6| Step: 7
Training loss: 2.05570650100708
Validation loss: 2.096273445313977

Epoch: 6| Step: 8
Training loss: 1.451763391494751
Validation loss: 2.112629016240438

Epoch: 6| Step: 9
Training loss: 2.4340453147888184
Validation loss: 2.1140323556879514

Epoch: 6| Step: 10
Training loss: 1.6838412284851074
Validation loss: 2.1294574532457577

Epoch: 6| Step: 11
Training loss: 2.413778066635132
Validation loss: 2.1493417627067974

Epoch: 6| Step: 12
Training loss: 2.823056697845459
Validation loss: 2.135599605498775

Epoch: 6| Step: 13
Training loss: 1.8657937049865723
Validation loss: 2.1179939085437405

Epoch: 249| Step: 0
Training loss: 2.5528407096862793
Validation loss: 2.1029277232385453

Epoch: 6| Step: 1
Training loss: 1.626781702041626
Validation loss: 2.0907550268275763

Epoch: 6| Step: 2
Training loss: 1.6805487871170044
Validation loss: 2.0838617406865603

Epoch: 6| Step: 3
Training loss: 2.4546689987182617
Validation loss: 2.0808826902861237

Epoch: 6| Step: 4
Training loss: 2.256669044494629
Validation loss: 2.081021906227194

Epoch: 6| Step: 5
Training loss: 2.2431015968322754
Validation loss: 2.07352884610494

Epoch: 6| Step: 6
Training loss: 2.1178336143493652
Validation loss: 2.093142822224607

Epoch: 6| Step: 7
Training loss: 2.5022568702697754
Validation loss: 2.0977173043835546

Epoch: 6| Step: 8
Training loss: 1.8627710342407227
Validation loss: 2.109402210481705

Epoch: 6| Step: 9
Training loss: 1.8253021240234375
Validation loss: 2.093901753425598

Epoch: 6| Step: 10
Training loss: 2.0143930912017822
Validation loss: 2.086490700321813

Epoch: 6| Step: 11
Training loss: 1.6942460536956787
Validation loss: 2.0754328530321837

Epoch: 6| Step: 12
Training loss: 2.922006845474243
Validation loss: 2.0792164136004705

Epoch: 6| Step: 13
Training loss: 1.9667481184005737
Validation loss: 2.081650128928564

Epoch: 250| Step: 0
Training loss: 1.474175214767456
Validation loss: 2.085050134248631

Epoch: 6| Step: 1
Training loss: 2.605966091156006
Validation loss: 2.086420491177549

Epoch: 6| Step: 2
Training loss: 2.214885711669922
Validation loss: 2.099155533698297

Epoch: 6| Step: 3
Training loss: 1.70847749710083
Validation loss: 2.0894371796679754

Epoch: 6| Step: 4
Training loss: 1.7789247035980225
Validation loss: 2.085232503952519

Epoch: 6| Step: 5
Training loss: 2.8944029808044434
Validation loss: 2.104858511237688

Epoch: 6| Step: 6
Training loss: 1.5808626413345337
Validation loss: 2.11747750671961

Epoch: 6| Step: 7
Training loss: 2.448103427886963
Validation loss: 2.136446752855855

Epoch: 6| Step: 8
Training loss: 2.5481691360473633
Validation loss: 2.15601207107626

Epoch: 6| Step: 9
Training loss: 1.8532160520553589
Validation loss: 2.1409289477973856

Epoch: 6| Step: 10
Training loss: 2.1107730865478516
Validation loss: 2.137841914289741

Epoch: 6| Step: 11
Training loss: 2.283918857574463
Validation loss: 2.1163758475293397

Epoch: 6| Step: 12
Training loss: 2.3111515045166016
Validation loss: 2.1134564620192333

Epoch: 6| Step: 13
Training loss: 1.9185736179351807
Validation loss: 2.10858477059231

Epoch: 251| Step: 0
Training loss: 1.167083740234375
Validation loss: 2.0948800399739254

Epoch: 6| Step: 1
Training loss: 2.2960381507873535
Validation loss: 2.099491424458001

Epoch: 6| Step: 2
Training loss: 2.192563056945801
Validation loss: 2.0939885185610865

Epoch: 6| Step: 3
Training loss: 2.345366954803467
Validation loss: 2.096838761401433

Epoch: 6| Step: 4
Training loss: 2.3072705268859863
Validation loss: 2.0876472919218

Epoch: 6| Step: 5
Training loss: 2.6889944076538086
Validation loss: 2.0978013418054067

Epoch: 6| Step: 6
Training loss: 2.7602663040161133
Validation loss: 2.0831725879382064

Epoch: 6| Step: 7
Training loss: 1.3478870391845703
Validation loss: 2.0879505244634484

Epoch: 6| Step: 8
Training loss: 2.196161985397339
Validation loss: 2.1033078829447427

Epoch: 6| Step: 9
Training loss: 1.4267374277114868
Validation loss: 2.116345062050768

Epoch: 6| Step: 10
Training loss: 2.168997049331665
Validation loss: 2.1044133119685675

Epoch: 6| Step: 11
Training loss: 2.8184356689453125
Validation loss: 2.114664411032072

Epoch: 6| Step: 12
Training loss: 2.003818988800049
Validation loss: 2.0812879505977837

Epoch: 6| Step: 13
Training loss: 1.8953334093093872
Validation loss: 2.0832073791052705

Epoch: 252| Step: 0
Training loss: 2.246100902557373
Validation loss: 2.0921095289209837

Epoch: 6| Step: 1
Training loss: 2.227909803390503
Validation loss: 2.097566539241422

Epoch: 6| Step: 2
Training loss: 1.93833589553833
Validation loss: 2.106323487015181

Epoch: 6| Step: 3
Training loss: 2.1132969856262207
Validation loss: 2.124783887658068

Epoch: 6| Step: 4
Training loss: 2.121016025543213
Validation loss: 2.1060467753359067

Epoch: 6| Step: 5
Training loss: 2.022012948989868
Validation loss: 2.1157683736534527

Epoch: 6| Step: 6
Training loss: 2.1492340564727783
Validation loss: 2.0995417512873167

Epoch: 6| Step: 7
Training loss: 1.9795526266098022
Validation loss: 2.0982444683710733

Epoch: 6| Step: 8
Training loss: 2.447999954223633
Validation loss: 2.0952263147600236

Epoch: 6| Step: 9
Training loss: 1.9617987871170044
Validation loss: 2.0963867197754564

Epoch: 6| Step: 10
Training loss: 2.136693000793457
Validation loss: 2.09745426588161

Epoch: 6| Step: 11
Training loss: 2.5077695846557617
Validation loss: 2.1058637826673445

Epoch: 6| Step: 12
Training loss: 2.1957826614379883
Validation loss: 2.1016996714376632

Epoch: 6| Step: 13
Training loss: 1.672177791595459
Validation loss: 2.0976822747979114

Epoch: 253| Step: 0
Training loss: 2.2858943939208984
Validation loss: 2.098010878409109

Epoch: 6| Step: 1
Training loss: 1.4630640745162964
Validation loss: 2.081229243227231

Epoch: 6| Step: 2
Training loss: 1.9034563302993774
Validation loss: 2.0797668323721936

Epoch: 6| Step: 3
Training loss: 2.024235486984253
Validation loss: 2.0741444928671724

Epoch: 6| Step: 4
Training loss: 2.109506130218506
Validation loss: 2.0851248592458744

Epoch: 6| Step: 5
Training loss: 1.6840009689331055
Validation loss: 2.077263416782502

Epoch: 6| Step: 6
Training loss: 2.8455917835235596
Validation loss: 2.0981062419952883

Epoch: 6| Step: 7
Training loss: 2.3465991020202637
Validation loss: 2.0979850869024954

Epoch: 6| Step: 8
Training loss: 2.0199429988861084
Validation loss: 2.1039782467708794

Epoch: 6| Step: 9
Training loss: 2.3131637573242188
Validation loss: 2.1062851336694535

Epoch: 6| Step: 10
Training loss: 3.0239429473876953
Validation loss: 2.1194737918915285

Epoch: 6| Step: 11
Training loss: 2.215848684310913
Validation loss: 2.092762677900253

Epoch: 6| Step: 12
Training loss: 1.9598032236099243
Validation loss: 2.0842565451898882

Epoch: 6| Step: 13
Training loss: 1.1250693798065186
Validation loss: 2.0919766579904864

Epoch: 254| Step: 0
Training loss: 2.239224910736084
Validation loss: 2.0667705305161013

Epoch: 6| Step: 1
Training loss: 2.3078689575195312
Validation loss: 2.0876830034358527

Epoch: 6| Step: 2
Training loss: 2.081292152404785
Validation loss: 2.066114435913742

Epoch: 6| Step: 3
Training loss: 2.001901865005493
Validation loss: 2.058035978706934

Epoch: 6| Step: 4
Training loss: 1.5239496231079102
Validation loss: 2.065712292989095

Epoch: 6| Step: 5
Training loss: 2.391664505004883
Validation loss: 2.0672368926386677

Epoch: 6| Step: 6
Training loss: 1.8217060565948486
Validation loss: 2.074425225616783

Epoch: 6| Step: 7
Training loss: 2.380861520767212
Validation loss: 2.0682083919484127

Epoch: 6| Step: 8
Training loss: 2.1835501194000244
Validation loss: 2.067814720574246

Epoch: 6| Step: 9
Training loss: 1.6299233436584473
Validation loss: 2.081092708854265

Epoch: 6| Step: 10
Training loss: 2.302307605743408
Validation loss: 2.0829017905778784

Epoch: 6| Step: 11
Training loss: 2.1428287029266357
Validation loss: 2.1015238351719354

Epoch: 6| Step: 12
Training loss: 2.5460691452026367
Validation loss: 2.11396300408148

Epoch: 6| Step: 13
Training loss: 1.7150506973266602
Validation loss: 2.117019919938939

Epoch: 255| Step: 0
Training loss: 2.224069118499756
Validation loss: 2.111081761698569

Epoch: 6| Step: 1
Training loss: 2.2985987663269043
Validation loss: 2.102787648477862

Epoch: 6| Step: 2
Training loss: 1.6788716316223145
Validation loss: 2.0967974278234665

Epoch: 6| Step: 3
Training loss: 2.1207172870635986
Validation loss: 2.0962231979575208

Epoch: 6| Step: 4
Training loss: 2.2260642051696777
Validation loss: 2.0788800985582414

Epoch: 6| Step: 5
Training loss: 2.1201424598693848
Validation loss: 2.0873279622806016

Epoch: 6| Step: 6
Training loss: 2.346621513366699
Validation loss: 2.087067186191518

Epoch: 6| Step: 7
Training loss: 2.6454014778137207
Validation loss: 2.065187515751008

Epoch: 6| Step: 8
Training loss: 1.8575429916381836
Validation loss: 2.048459240185317

Epoch: 6| Step: 9
Training loss: 2.017871141433716
Validation loss: 2.043956882210188

Epoch: 6| Step: 10
Training loss: 1.9764628410339355
Validation loss: 2.060935579320436

Epoch: 6| Step: 11
Training loss: 1.237112283706665
Validation loss: 2.0637273942270586

Epoch: 6| Step: 12
Training loss: 2.494457244873047
Validation loss: 2.0567768119996592

Epoch: 6| Step: 13
Training loss: 2.695044994354248
Validation loss: 2.075763230682701

Epoch: 256| Step: 0
Training loss: 2.6185221672058105
Validation loss: 2.100357888847269

Epoch: 6| Step: 1
Training loss: 2.269712448120117
Validation loss: 2.0990008615678355

Epoch: 6| Step: 2
Training loss: 1.4924733638763428
Validation loss: 2.091700630803262

Epoch: 6| Step: 3
Training loss: 2.102476119995117
Validation loss: 2.103231895354486

Epoch: 6| Step: 4
Training loss: 1.4205687046051025
Validation loss: 2.0937903952854935

Epoch: 6| Step: 5
Training loss: 1.522138237953186
Validation loss: 2.0962441223923878

Epoch: 6| Step: 6
Training loss: 2.8759775161743164
Validation loss: 2.1015798763562272

Epoch: 6| Step: 7
Training loss: 3.138192653656006
Validation loss: 2.101800900633617

Epoch: 6| Step: 8
Training loss: 1.8164863586425781
Validation loss: 2.105838885871313

Epoch: 6| Step: 9
Training loss: 1.8650360107421875
Validation loss: 2.1072295609340874

Epoch: 6| Step: 10
Training loss: 1.8567168712615967
Validation loss: 2.0948220299136255

Epoch: 6| Step: 11
Training loss: 1.9179599285125732
Validation loss: 2.0980653121907222

Epoch: 6| Step: 12
Training loss: 2.6506364345550537
Validation loss: 2.086582806802565

Epoch: 6| Step: 13
Training loss: 1.715825080871582
Validation loss: 2.0911346199691936

Epoch: 257| Step: 0
Training loss: 2.93552827835083
Validation loss: 2.1031428819061606

Epoch: 6| Step: 1
Training loss: 2.217075824737549
Validation loss: 2.0954501603239324

Epoch: 6| Step: 2
Training loss: 1.9377037286758423
Validation loss: 2.105289351555609

Epoch: 6| Step: 3
Training loss: 1.8653727769851685
Validation loss: 2.0856227592755388

Epoch: 6| Step: 4
Training loss: 1.6029284000396729
Validation loss: 2.0859817971465406

Epoch: 6| Step: 5
Training loss: 1.8562054634094238
Validation loss: 2.0826631463984007

Epoch: 6| Step: 6
Training loss: 2.4648079872131348
Validation loss: 2.0890893051701207

Epoch: 6| Step: 7
Training loss: 2.4372010231018066
Validation loss: 2.0844527982896373

Epoch: 6| Step: 8
Training loss: 2.267472743988037
Validation loss: 2.0908984138119604

Epoch: 6| Step: 9
Training loss: 2.154491901397705
Validation loss: 2.0999987433033604

Epoch: 6| Step: 10
Training loss: 2.4711761474609375
Validation loss: 2.091506258133919

Epoch: 6| Step: 11
Training loss: 1.855080246925354
Validation loss: 2.075883146255247

Epoch: 6| Step: 12
Training loss: 1.3460623025894165
Validation loss: 2.0648120680162982

Epoch: 6| Step: 13
Training loss: 1.7180429697036743
Validation loss: 2.054567019144694

Epoch: 258| Step: 0
Training loss: 1.4436874389648438
Validation loss: 2.0622202683520574

Epoch: 6| Step: 1
Training loss: 2.140166997909546
Validation loss: 2.064026373688893

Epoch: 6| Step: 2
Training loss: 2.169631004333496
Validation loss: 2.049233757039552

Epoch: 6| Step: 3
Training loss: 2.629497528076172
Validation loss: 2.0658366231508154

Epoch: 6| Step: 4
Training loss: 2.00063419342041
Validation loss: 2.0706654261517268

Epoch: 6| Step: 5
Training loss: 2.735990047454834
Validation loss: 2.072492607178227

Epoch: 6| Step: 6
Training loss: 1.679574728012085
Validation loss: 2.0833117679883073

Epoch: 6| Step: 7
Training loss: 1.6870583295822144
Validation loss: 2.0820428171465473

Epoch: 6| Step: 8
Training loss: 1.9762566089630127
Validation loss: 2.0917343824140486

Epoch: 6| Step: 9
Training loss: 2.342007637023926
Validation loss: 2.089968066061697

Epoch: 6| Step: 10
Training loss: 1.575993537902832
Validation loss: 2.088791257591658

Epoch: 6| Step: 11
Training loss: 2.74249005317688
Validation loss: 2.101148086209451

Epoch: 6| Step: 12
Training loss: 1.7542104721069336
Validation loss: 2.0931513860661495

Epoch: 6| Step: 13
Training loss: 2.2463765144348145
Validation loss: 2.087710072917323

Epoch: 259| Step: 0
Training loss: 1.8420774936676025
Validation loss: 2.0848114939146143

Epoch: 6| Step: 1
Training loss: 1.9878920316696167
Validation loss: 2.0848332951145787

Epoch: 6| Step: 2
Training loss: 2.247382164001465
Validation loss: 2.078239679336548

Epoch: 6| Step: 3
Training loss: 1.5640780925750732
Validation loss: 2.0751905825830277

Epoch: 6| Step: 4
Training loss: 2.104661703109741
Validation loss: 2.073100454063826

Epoch: 6| Step: 5
Training loss: 2.064518928527832
Validation loss: 2.07149274246667

Epoch: 6| Step: 6
Training loss: 2.139620780944824
Validation loss: 2.0560547895328973

Epoch: 6| Step: 7
Training loss: 3.0117948055267334
Validation loss: 2.0676636336952128

Epoch: 6| Step: 8
Training loss: 1.9691327810287476
Validation loss: 2.0726912303637435

Epoch: 6| Step: 9
Training loss: 1.7101051807403564
Validation loss: 2.0585350964659

Epoch: 6| Step: 10
Training loss: 2.201328754425049
Validation loss: 2.066091873312509

Epoch: 6| Step: 11
Training loss: 2.41290283203125
Validation loss: 2.0692751740896576

Epoch: 6| Step: 12
Training loss: 1.3533021211624146
Validation loss: 2.0706932313980593

Epoch: 6| Step: 13
Training loss: 2.5504093170166016
Validation loss: 2.077283969489477

Epoch: 260| Step: 0
Training loss: 1.9590445756912231
Validation loss: 2.0743538807797175

Epoch: 6| Step: 1
Training loss: 2.1310946941375732
Validation loss: 2.080544794759443

Epoch: 6| Step: 2
Training loss: 2.14101505279541
Validation loss: 2.0893550393401936

Epoch: 6| Step: 3
Training loss: 1.231764554977417
Validation loss: 2.095853913214899

Epoch: 6| Step: 4
Training loss: 2.5398263931274414
Validation loss: 2.115860349388533

Epoch: 6| Step: 5
Training loss: 2.0670390129089355
Validation loss: 2.1321801767554334

Epoch: 6| Step: 6
Training loss: 2.7412655353546143
Validation loss: 2.1508824940650695

Epoch: 6| Step: 7
Training loss: 2.001943588256836
Validation loss: 2.132140597989482

Epoch: 6| Step: 8
Training loss: 1.2739323377609253
Validation loss: 2.1007293142298216

Epoch: 6| Step: 9
Training loss: 2.3617963790893555
Validation loss: 2.096027890841166

Epoch: 6| Step: 10
Training loss: 2.3938822746276855
Validation loss: 2.0841510603504796

Epoch: 6| Step: 11
Training loss: 1.7954041957855225
Validation loss: 2.088507165190994

Epoch: 6| Step: 12
Training loss: 2.7335968017578125
Validation loss: 2.1075727670423445

Epoch: 6| Step: 13
Training loss: 1.885986328125
Validation loss: 2.116748591904999

Epoch: 261| Step: 0
Training loss: 1.9577422142028809
Validation loss: 2.083336055919688

Epoch: 6| Step: 1
Training loss: 2.1988120079040527
Validation loss: 2.0593302352454073

Epoch: 6| Step: 2
Training loss: 2.1786372661590576
Validation loss: 2.050871359404697

Epoch: 6| Step: 3
Training loss: 2.260005235671997
Validation loss: 2.051177078677762

Epoch: 6| Step: 4
Training loss: 2.284115791320801
Validation loss: 2.0573319030064408

Epoch: 6| Step: 5
Training loss: 1.690967321395874
Validation loss: 2.0524908214487056

Epoch: 6| Step: 6
Training loss: 1.3077454566955566
Validation loss: 2.077101194730369

Epoch: 6| Step: 7
Training loss: 2.5323567390441895
Validation loss: 2.0803503887627715

Epoch: 6| Step: 8
Training loss: 1.9855996370315552
Validation loss: 2.0934166639081893

Epoch: 6| Step: 9
Training loss: 1.752621054649353
Validation loss: 2.0775151944929555

Epoch: 6| Step: 10
Training loss: 2.586595058441162
Validation loss: 2.0685858495773806

Epoch: 6| Step: 11
Training loss: 2.242832660675049
Validation loss: 2.097287557458365

Epoch: 6| Step: 12
Training loss: 2.2113845348358154
Validation loss: 2.1029757351003666

Epoch: 6| Step: 13
Training loss: 1.7715952396392822
Validation loss: 2.0900071513268257

Epoch: 262| Step: 0
Training loss: 1.7123610973358154
Validation loss: 2.0870388092533236

Epoch: 6| Step: 1
Training loss: 2.1993682384490967
Validation loss: 2.077576237340127

Epoch: 6| Step: 2
Training loss: 1.5165425539016724
Validation loss: 2.0785510757918

Epoch: 6| Step: 3
Training loss: 2.4806058406829834
Validation loss: 2.073076343023649

Epoch: 6| Step: 4
Training loss: 1.6913930177688599
Validation loss: 2.0661250186222855

Epoch: 6| Step: 5
Training loss: 1.9213321208953857
Validation loss: 2.0692550854016374

Epoch: 6| Step: 6
Training loss: 2.2656311988830566
Validation loss: 2.0840025665939494

Epoch: 6| Step: 7
Training loss: 2.2936789989471436
Validation loss: 2.0776922061879146

Epoch: 6| Step: 8
Training loss: 2.2163660526275635
Validation loss: 2.064871644461027

Epoch: 6| Step: 9
Training loss: 2.174830913543701
Validation loss: 2.0708979714301323

Epoch: 6| Step: 10
Training loss: 1.8086000680923462
Validation loss: 2.069537215335395

Epoch: 6| Step: 11
Training loss: 2.053710699081421
Validation loss: 2.0554253196203582

Epoch: 6| Step: 12
Training loss: 2.3784847259521484
Validation loss: 2.075521319143234

Epoch: 6| Step: 13
Training loss: 2.113359212875366
Validation loss: 2.08302124597693

Epoch: 263| Step: 0
Training loss: 2.1075944900512695
Validation loss: 2.0945292211348012

Epoch: 6| Step: 1
Training loss: 2.449357509613037
Validation loss: 2.098979360313826

Epoch: 6| Step: 2
Training loss: 2.1952011585235596
Validation loss: 2.0930369438663607

Epoch: 6| Step: 3
Training loss: 1.8687717914581299
Validation loss: 2.0995571036492624

Epoch: 6| Step: 4
Training loss: 2.2676286697387695
Validation loss: 2.080487971664757

Epoch: 6| Step: 5
Training loss: 1.3734402656555176
Validation loss: 2.079214398578931

Epoch: 6| Step: 6
Training loss: 2.5527005195617676
Validation loss: 2.0844383931929067

Epoch: 6| Step: 7
Training loss: 2.3591508865356445
Validation loss: 2.061743038956837

Epoch: 6| Step: 8
Training loss: 2.2814035415649414
Validation loss: 2.061205073069501

Epoch: 6| Step: 9
Training loss: 1.538521647453308
Validation loss: 2.060420226025325

Epoch: 6| Step: 10
Training loss: 1.8431086540222168
Validation loss: 2.0599386794592744

Epoch: 6| Step: 11
Training loss: 2.1535332202911377
Validation loss: 2.0698614389665666

Epoch: 6| Step: 12
Training loss: 1.6519083976745605
Validation loss: 2.0692756663086596

Epoch: 6| Step: 13
Training loss: 2.0756425857543945
Validation loss: 2.0635180037508727

Epoch: 264| Step: 0
Training loss: 1.4891743659973145
Validation loss: 2.0556701357646654

Epoch: 6| Step: 1
Training loss: 2.861250162124634
Validation loss: 2.068536514876991

Epoch: 6| Step: 2
Training loss: 2.004873037338257
Validation loss: 2.0817749884820755

Epoch: 6| Step: 3
Training loss: 2.326007843017578
Validation loss: 2.085622009410653

Epoch: 6| Step: 4
Training loss: 1.2568070888519287
Validation loss: 2.1020390320849676

Epoch: 6| Step: 5
Training loss: 2.1557154655456543
Validation loss: 2.0950123802308114

Epoch: 6| Step: 6
Training loss: 1.8872177600860596
Validation loss: 2.1039704635579097

Epoch: 6| Step: 7
Training loss: 2.0366814136505127
Validation loss: 2.0904060615006315

Epoch: 6| Step: 8
Training loss: 1.9462790489196777
Validation loss: 2.0908567405516103

Epoch: 6| Step: 9
Training loss: 2.3241822719573975
Validation loss: 2.076204402472383

Epoch: 6| Step: 10
Training loss: 1.943495273590088
Validation loss: 2.0546731038760115

Epoch: 6| Step: 11
Training loss: 2.100938320159912
Validation loss: 2.061020048715735

Epoch: 6| Step: 12
Training loss: 2.121563673019409
Validation loss: 2.0639730191999868

Epoch: 6| Step: 13
Training loss: 2.533529281616211
Validation loss: 2.059700994081395

Epoch: 265| Step: 0
Training loss: 2.3731350898742676
Validation loss: 2.0599675281073457

Epoch: 6| Step: 1
Training loss: 2.204921007156372
Validation loss: 2.081496807836717

Epoch: 6| Step: 2
Training loss: 1.9362115859985352
Validation loss: 2.0949675421560965

Epoch: 6| Step: 3
Training loss: 2.5015461444854736
Validation loss: 2.0968384281281502

Epoch: 6| Step: 4
Training loss: 1.9544768333435059
Validation loss: 2.077366334135814

Epoch: 6| Step: 5
Training loss: 2.3631367683410645
Validation loss: 2.0823652641747588

Epoch: 6| Step: 6
Training loss: 1.6359186172485352
Validation loss: 2.0538658147217124

Epoch: 6| Step: 7
Training loss: 1.7827370166778564
Validation loss: 2.0454848479199153

Epoch: 6| Step: 8
Training loss: 1.6427898406982422
Validation loss: 2.054121178965415

Epoch: 6| Step: 9
Training loss: 1.8511779308319092
Validation loss: 2.0548697838219265

Epoch: 6| Step: 10
Training loss: 2.2654366493225098
Validation loss: 2.056355059787791

Epoch: 6| Step: 11
Training loss: 1.921712875366211
Validation loss: 2.0591120617364043

Epoch: 6| Step: 12
Training loss: 2.079916000366211
Validation loss: 2.0546691789421985

Epoch: 6| Step: 13
Training loss: 2.1495397090911865
Validation loss: 2.0587698874935025

Epoch: 266| Step: 0
Training loss: 2.7339365482330322
Validation loss: 2.071507444945715

Epoch: 6| Step: 1
Training loss: 2.2852540016174316
Validation loss: 2.0763336919969126

Epoch: 6| Step: 2
Training loss: 1.5619969367980957
Validation loss: 2.084632936344352

Epoch: 6| Step: 3
Training loss: 1.699310064315796
Validation loss: 2.0980050589448664

Epoch: 6| Step: 4
Training loss: 1.7645981311798096
Validation loss: 2.094541352282288

Epoch: 6| Step: 5
Training loss: 2.2401580810546875
Validation loss: 2.0859237819589596

Epoch: 6| Step: 6
Training loss: 3.260708808898926
Validation loss: 2.0919151267697735

Epoch: 6| Step: 7
Training loss: 1.9952902793884277
Validation loss: 2.0864934062445037

Epoch: 6| Step: 8
Training loss: 1.1559545993804932
Validation loss: 2.0637994940562914

Epoch: 6| Step: 9
Training loss: 1.9975841045379639
Validation loss: 2.0645641152576735

Epoch: 6| Step: 10
Training loss: 1.707749366760254
Validation loss: 2.078244754063186

Epoch: 6| Step: 11
Training loss: 2.3699052333831787
Validation loss: 2.0506613587820404

Epoch: 6| Step: 12
Training loss: 2.13430118560791
Validation loss: 2.0440586228524484

Epoch: 6| Step: 13
Training loss: 1.1038577556610107
Validation loss: 2.0508099089386644

Epoch: 267| Step: 0
Training loss: 1.8374481201171875
Validation loss: 2.0475064990341023

Epoch: 6| Step: 1
Training loss: 2.5687005519866943
Validation loss: 2.0391399257926532

Epoch: 6| Step: 2
Training loss: 2.4914186000823975
Validation loss: 2.0509697955141784

Epoch: 6| Step: 3
Training loss: 2.156168222427368
Validation loss: 2.044907805740192

Epoch: 6| Step: 4
Training loss: 1.9309895038604736
Validation loss: 2.047700628157585

Epoch: 6| Step: 5
Training loss: 1.8840484619140625
Validation loss: 2.064514988212175

Epoch: 6| Step: 6
Training loss: 1.0824902057647705
Validation loss: 2.0772369061746905

Epoch: 6| Step: 7
Training loss: 1.5273122787475586
Validation loss: 2.086392366757957

Epoch: 6| Step: 8
Training loss: 1.2582767009735107
Validation loss: 2.082164269621654

Epoch: 6| Step: 9
Training loss: 2.4248852729797363
Validation loss: 2.094368143748212

Epoch: 6| Step: 10
Training loss: 2.2231812477111816
Validation loss: 2.0911512682514806

Epoch: 6| Step: 11
Training loss: 2.3315610885620117
Validation loss: 2.092793559515348

Epoch: 6| Step: 12
Training loss: 2.1822798252105713
Validation loss: 2.0960286676242785

Epoch: 6| Step: 13
Training loss: 2.834416151046753
Validation loss: 2.090559938902496

Epoch: 268| Step: 0
Training loss: 1.9769837856292725
Validation loss: 2.090205687348561

Epoch: 6| Step: 1
Training loss: 1.3347513675689697
Validation loss: 2.077445412194857

Epoch: 6| Step: 2
Training loss: 2.108880043029785
Validation loss: 2.0668490497014855

Epoch: 6| Step: 3
Training loss: 1.6999330520629883
Validation loss: 2.0649313836969356

Epoch: 6| Step: 4
Training loss: 1.2407538890838623
Validation loss: 2.0640849054500623

Epoch: 6| Step: 5
Training loss: 2.011296033859253
Validation loss: 2.0613399987579673

Epoch: 6| Step: 6
Training loss: 2.280543804168701
Validation loss: 2.0428067945664927

Epoch: 6| Step: 7
Training loss: 2.458216905593872
Validation loss: 2.0488624803481565

Epoch: 6| Step: 8
Training loss: 2.4336183071136475
Validation loss: 2.040430884207449

Epoch: 6| Step: 9
Training loss: 2.3866260051727295
Validation loss: 2.0415100974421345

Epoch: 6| Step: 10
Training loss: 2.3757386207580566
Validation loss: 2.0403888969011206

Epoch: 6| Step: 11
Training loss: 1.5827711820602417
Validation loss: 2.0603008231809063

Epoch: 6| Step: 12
Training loss: 2.2849111557006836
Validation loss: 2.072853381915759

Epoch: 6| Step: 13
Training loss: 2.1291184425354004
Validation loss: 2.0772079062718216

Epoch: 269| Step: 0
Training loss: 2.115309000015259
Validation loss: 2.0874411008691274

Epoch: 6| Step: 1
Training loss: 2.373332977294922
Validation loss: 2.090397878359723

Epoch: 6| Step: 2
Training loss: 1.7468340396881104
Validation loss: 2.0839881435517342

Epoch: 6| Step: 3
Training loss: 2.6403517723083496
Validation loss: 2.0973732625284502

Epoch: 6| Step: 4
Training loss: 2.737102508544922
Validation loss: 2.091442369645642

Epoch: 6| Step: 5
Training loss: 1.5389883518218994
Validation loss: 2.076973371608283

Epoch: 6| Step: 6
Training loss: 2.2949318885803223
Validation loss: 2.053588765923695

Epoch: 6| Step: 7
Training loss: 1.9103375673294067
Validation loss: 2.0690927992584887

Epoch: 6| Step: 8
Training loss: 2.1160659790039062
Validation loss: 2.0607593059539795

Epoch: 6| Step: 9
Training loss: 1.3604984283447266
Validation loss: 2.0636896920460526

Epoch: 6| Step: 10
Training loss: 1.4293919801712036
Validation loss: 2.059455152480833

Epoch: 6| Step: 11
Training loss: 2.224365234375
Validation loss: 2.0694225500988703

Epoch: 6| Step: 12
Training loss: 2.1908507347106934
Validation loss: 2.051365262718611

Epoch: 6| Step: 13
Training loss: 1.2129487991333008
Validation loss: 2.073486343506844

Epoch: 270| Step: 0
Training loss: 1.9226891994476318
Validation loss: 2.0744843764971663

Epoch: 6| Step: 1
Training loss: 1.6164815425872803
Validation loss: 2.085246273266372

Epoch: 6| Step: 2
Training loss: 2.123480796813965
Validation loss: 2.1046958892576155

Epoch: 6| Step: 3
Training loss: 1.9441578388214111
Validation loss: 2.1129954143237044

Epoch: 6| Step: 4
Training loss: 1.9149664640426636
Validation loss: 2.1481470138795915

Epoch: 6| Step: 5
Training loss: 2.279510974884033
Validation loss: 2.144653348512547

Epoch: 6| Step: 6
Training loss: 2.1031992435455322
Validation loss: 2.124535496516894

Epoch: 6| Step: 7
Training loss: 1.9835952520370483
Validation loss: 2.094644054289787

Epoch: 6| Step: 8
Training loss: 2.0586819648742676
Validation loss: 2.085502742439188

Epoch: 6| Step: 9
Training loss: 2.2904434204101562
Validation loss: 2.0763068993886313

Epoch: 6| Step: 10
Training loss: 2.164552927017212
Validation loss: 2.0671560789949153

Epoch: 6| Step: 11
Training loss: 2.1165080070495605
Validation loss: 2.056189916467154

Epoch: 6| Step: 12
Training loss: 1.7753567695617676
Validation loss: 2.036821799893533

Epoch: 6| Step: 13
Training loss: 2.730452060699463
Validation loss: 2.031727861332637

Epoch: 271| Step: 0
Training loss: 1.7418606281280518
Validation loss: 2.0473560261470016

Epoch: 6| Step: 1
Training loss: 2.219207286834717
Validation loss: 2.0551780167446343

Epoch: 6| Step: 2
Training loss: 2.0403428077697754
Validation loss: 2.0476941716286445

Epoch: 6| Step: 3
Training loss: 2.920835494995117
Validation loss: 2.064795476134105

Epoch: 6| Step: 4
Training loss: 2.0580410957336426
Validation loss: 2.064898467832996

Epoch: 6| Step: 5
Training loss: 2.073721408843994
Validation loss: 2.062512605421005

Epoch: 6| Step: 6
Training loss: 1.7575716972351074
Validation loss: 2.0634482740074076

Epoch: 6| Step: 7
Training loss: 1.5131375789642334
Validation loss: 2.072628376304462

Epoch: 6| Step: 8
Training loss: 2.1178500652313232
Validation loss: 2.0668317630726802

Epoch: 6| Step: 9
Training loss: 2.3440845012664795
Validation loss: 2.0602899776991976

Epoch: 6| Step: 10
Training loss: 1.8323739767074585
Validation loss: 2.0558617640567083

Epoch: 6| Step: 11
Training loss: 2.1474013328552246
Validation loss: 2.0531687787784043

Epoch: 6| Step: 12
Training loss: 1.5712591409683228
Validation loss: 2.042593156137774

Epoch: 6| Step: 13
Training loss: 1.539146900177002
Validation loss: 2.0390387863241215

Epoch: 272| Step: 0
Training loss: 1.7530593872070312
Validation loss: 2.0718409207559403

Epoch: 6| Step: 1
Training loss: 1.3588223457336426
Validation loss: 2.055686478973717

Epoch: 6| Step: 2
Training loss: 1.9522690773010254
Validation loss: 2.0624679250101887

Epoch: 6| Step: 3
Training loss: 2.2164390087127686
Validation loss: 2.063667590900134

Epoch: 6| Step: 4
Training loss: 2.3503172397613525
Validation loss: 2.0404063655484106

Epoch: 6| Step: 5
Training loss: 1.8515313863754272
Validation loss: 2.035853975562639

Epoch: 6| Step: 6
Training loss: 1.7651207447052002
Validation loss: 2.03275954082448

Epoch: 6| Step: 7
Training loss: 1.5302084684371948
Validation loss: 2.0454471342025267

Epoch: 6| Step: 8
Training loss: 2.1083030700683594
Validation loss: 2.0439539596598637

Epoch: 6| Step: 9
Training loss: 1.805434226989746
Validation loss: 2.0638661525582753

Epoch: 6| Step: 10
Training loss: 2.2504053115844727
Validation loss: 2.078879505075434

Epoch: 6| Step: 11
Training loss: 2.5648393630981445
Validation loss: 2.0757759668493785

Epoch: 6| Step: 12
Training loss: 2.1723384857177734
Validation loss: 2.0885900015472085

Epoch: 6| Step: 13
Training loss: 2.637230157852173
Validation loss: 2.073964580412834

Epoch: 273| Step: 0
Training loss: 2.057593822479248
Validation loss: 2.0635024578340593

Epoch: 6| Step: 1
Training loss: 2.2445290088653564
Validation loss: 2.050505389449417

Epoch: 6| Step: 2
Training loss: 2.1181297302246094
Validation loss: 2.0473361502411547

Epoch: 6| Step: 3
Training loss: 2.241744041442871
Validation loss: 2.039183666629176

Epoch: 6| Step: 4
Training loss: 1.7091498374938965
Validation loss: 2.025973235407183

Epoch: 6| Step: 5
Training loss: 1.6538913249969482
Validation loss: 2.0297858945785032

Epoch: 6| Step: 6
Training loss: 2.2075283527374268
Validation loss: 2.0233743767584524

Epoch: 6| Step: 7
Training loss: 2.129244804382324
Validation loss: 2.0332824132775746

Epoch: 6| Step: 8
Training loss: 2.298983335494995
Validation loss: 2.0335215855670232

Epoch: 6| Step: 9
Training loss: 2.512417793273926
Validation loss: 2.0325591359087216

Epoch: 6| Step: 10
Training loss: 1.4146325588226318
Validation loss: 2.032814347615806

Epoch: 6| Step: 11
Training loss: 1.9076131582260132
Validation loss: 2.0341539870026293

Epoch: 6| Step: 12
Training loss: 1.5409083366394043
Validation loss: 2.0496358089549567

Epoch: 6| Step: 13
Training loss: 1.7178586721420288
Validation loss: 2.043973312583021

Epoch: 274| Step: 0
Training loss: 2.4323890209198
Validation loss: 2.058168448427672

Epoch: 6| Step: 1
Training loss: 2.5752339363098145
Validation loss: 2.0671566776050034

Epoch: 6| Step: 2
Training loss: 2.1127662658691406
Validation loss: 2.0686909831980222

Epoch: 6| Step: 3
Training loss: 1.9268097877502441
Validation loss: 2.0708686972177155

Epoch: 6| Step: 4
Training loss: 1.404237985610962
Validation loss: 2.08361400840103

Epoch: 6| Step: 5
Training loss: 2.6367926597595215
Validation loss: 2.069539826403382

Epoch: 6| Step: 6
Training loss: 2.201974391937256
Validation loss: 2.0695961085698937

Epoch: 6| Step: 7
Training loss: 1.257394552230835
Validation loss: 2.0728657489181845

Epoch: 6| Step: 8
Training loss: 1.342996597290039
Validation loss: 2.057814917256755

Epoch: 6| Step: 9
Training loss: 1.744009256362915
Validation loss: 2.0497766284532446

Epoch: 6| Step: 10
Training loss: 1.7784456014633179
Validation loss: 2.055435472919095

Epoch: 6| Step: 11
Training loss: 1.7370526790618896
Validation loss: 2.0379521295588505

Epoch: 6| Step: 12
Training loss: 2.7644004821777344
Validation loss: 2.046830270880012

Epoch: 6| Step: 13
Training loss: 1.8375489711761475
Validation loss: 2.0608789484987975

Epoch: 275| Step: 0
Training loss: 1.926327109336853
Validation loss: 2.037438766930693

Epoch: 6| Step: 1
Training loss: 1.5209245681762695
Validation loss: 2.0453217760209115

Epoch: 6| Step: 2
Training loss: 2.1688969135284424
Validation loss: 2.0429872210307787

Epoch: 6| Step: 3
Training loss: 1.8014583587646484
Validation loss: 2.0543028359772055

Epoch: 6| Step: 4
Training loss: 2.171015501022339
Validation loss: 2.0499479181023053

Epoch: 6| Step: 5
Training loss: 2.084902048110962
Validation loss: 2.05260960261027

Epoch: 6| Step: 6
Training loss: 2.4460926055908203
Validation loss: 2.06681030027328

Epoch: 6| Step: 7
Training loss: 2.202867031097412
Validation loss: 2.052467810210361

Epoch: 6| Step: 8
Training loss: 1.867324948310852
Validation loss: 2.0606522585756037

Epoch: 6| Step: 9
Training loss: 2.2825424671173096
Validation loss: 2.0713404455492572

Epoch: 6| Step: 10
Training loss: 1.7801125049591064
Validation loss: 2.0589027468876173

Epoch: 6| Step: 11
Training loss: 1.8331249952316284
Validation loss: 2.0412823948808896

Epoch: 6| Step: 12
Training loss: 1.675250768661499
Validation loss: 2.053746865641686

Epoch: 6| Step: 13
Training loss: 1.9884155988693237
Validation loss: 2.0454095166216613

Epoch: 276| Step: 0
Training loss: 1.4466376304626465
Validation loss: 2.056379182364351

Epoch: 6| Step: 1
Training loss: 2.016557216644287
Validation loss: 2.064767365814537

Epoch: 6| Step: 2
Training loss: 2.1279196739196777
Validation loss: 2.049209309521542

Epoch: 6| Step: 3
Training loss: 1.039642095565796
Validation loss: 2.065390702216856

Epoch: 6| Step: 4
Training loss: 2.6931252479553223
Validation loss: 2.0684038516013854

Epoch: 6| Step: 5
Training loss: 1.8369083404541016
Validation loss: 2.0601478840715144

Epoch: 6| Step: 6
Training loss: 1.979980230331421
Validation loss: 2.067869676056729

Epoch: 6| Step: 7
Training loss: 2.841097593307495
Validation loss: 2.0758435392892487

Epoch: 6| Step: 8
Training loss: 2.310887336730957
Validation loss: 2.058017171839232

Epoch: 6| Step: 9
Training loss: 2.8567705154418945
Validation loss: 2.054217066816104

Epoch: 6| Step: 10
Training loss: 1.836043357849121
Validation loss: 2.0467667361741424

Epoch: 6| Step: 11
Training loss: 0.9601434469223022
Validation loss: 2.0332509138250865

Epoch: 6| Step: 12
Training loss: 1.7527964115142822
Validation loss: 2.038774621102118

Epoch: 6| Step: 13
Training loss: 1.887316346168518
Validation loss: 2.024174613337363

Epoch: 277| Step: 0
Training loss: 1.9100927114486694
Validation loss: 2.030218651217799

Epoch: 6| Step: 1
Training loss: 1.2522454261779785
Validation loss: 2.03325681788947

Epoch: 6| Step: 2
Training loss: 2.1060338020324707
Validation loss: 2.0387683658189673

Epoch: 6| Step: 3
Training loss: 2.299415349960327
Validation loss: 2.0553970875278598

Epoch: 6| Step: 4
Training loss: 2.215733766555786
Validation loss: 2.0674498029934463

Epoch: 6| Step: 5
Training loss: 1.9360113143920898
Validation loss: 2.053191213197606

Epoch: 6| Step: 6
Training loss: 1.2714123725891113
Validation loss: 2.052815383480441

Epoch: 6| Step: 7
Training loss: 2.9856152534484863
Validation loss: 2.052245195193957

Epoch: 6| Step: 8
Training loss: 2.009324550628662
Validation loss: 2.0350336528593496

Epoch: 6| Step: 9
Training loss: 2.399383068084717
Validation loss: 2.0409453453556186

Epoch: 6| Step: 10
Training loss: 1.5823345184326172
Validation loss: 2.061694734839983

Epoch: 6| Step: 11
Training loss: 1.4288625717163086
Validation loss: 2.0918042711032334

Epoch: 6| Step: 12
Training loss: 2.1601181030273438
Validation loss: 2.0968899291048766

Epoch: 6| Step: 13
Training loss: 2.301656484603882
Validation loss: 2.0969379371212375

Epoch: 278| Step: 0
Training loss: 2.080991268157959
Validation loss: 2.0755825055542814

Epoch: 6| Step: 1
Training loss: 1.2891077995300293
Validation loss: 2.0567792923219743

Epoch: 6| Step: 2
Training loss: 1.3828277587890625
Validation loss: 2.053006002979894

Epoch: 6| Step: 3
Training loss: 1.853440284729004
Validation loss: 2.074568061418431

Epoch: 6| Step: 4
Training loss: 1.625627875328064
Validation loss: 2.1030554015149354

Epoch: 6| Step: 5
Training loss: 2.0681114196777344
Validation loss: 2.1163366840731714

Epoch: 6| Step: 6
Training loss: 2.872619867324829
Validation loss: 2.1000578954655635

Epoch: 6| Step: 7
Training loss: 1.5911931991577148
Validation loss: 2.082076221384028

Epoch: 6| Step: 8
Training loss: 1.8770418167114258
Validation loss: 2.0685657173074703

Epoch: 6| Step: 9
Training loss: 2.8033175468444824
Validation loss: 2.036000451733989

Epoch: 6| Step: 10
Training loss: 2.2806100845336914
Validation loss: 2.0431934941199517

Epoch: 6| Step: 11
Training loss: 2.0601139068603516
Validation loss: 2.0617201917914936

Epoch: 6| Step: 12
Training loss: 1.802058219909668
Validation loss: 2.0818630854288735

Epoch: 6| Step: 13
Training loss: 2.552309989929199
Validation loss: 2.1085436062146257

Epoch: 279| Step: 0
Training loss: 1.8438279628753662
Validation loss: 2.1292692589503464

Epoch: 6| Step: 1
Training loss: 1.9295365810394287
Validation loss: 2.109484980183263

Epoch: 6| Step: 2
Training loss: 1.748705267906189
Validation loss: 2.0897641489582677

Epoch: 6| Step: 3
Training loss: 1.4552819728851318
Validation loss: 2.053755501265167

Epoch: 6| Step: 4
Training loss: 2.435945987701416
Validation loss: 2.0572119323156213

Epoch: 6| Step: 5
Training loss: 1.9818916320800781
Validation loss: 2.0728116984008462

Epoch: 6| Step: 6
Training loss: 2.417111396789551
Validation loss: 2.0759314285811556

Epoch: 6| Step: 7
Training loss: 2.472975730895996
Validation loss: 2.0905581725540983

Epoch: 6| Step: 8
Training loss: 1.885053277015686
Validation loss: 2.090520483191295

Epoch: 6| Step: 9
Training loss: 2.513683319091797
Validation loss: 2.068656518895139

Epoch: 6| Step: 10
Training loss: 1.3627064228057861
Validation loss: 2.033614709813108

Epoch: 6| Step: 11
Training loss: 2.5002598762512207
Validation loss: 2.0365615660144436

Epoch: 6| Step: 12
Training loss: 1.7336249351501465
Validation loss: 2.0305708467319445

Epoch: 6| Step: 13
Training loss: 1.5950474739074707
Validation loss: 2.035397187356026

Epoch: 280| Step: 0
Training loss: 2.118588924407959
Validation loss: 2.0663131693358063

Epoch: 6| Step: 1
Training loss: 2.19587779045105
Validation loss: 2.0560099642763854

Epoch: 6| Step: 2
Training loss: 2.059813976287842
Validation loss: 2.059891846872145

Epoch: 6| Step: 3
Training loss: 2.3284361362457275
Validation loss: 2.062974319663099

Epoch: 6| Step: 4
Training loss: 1.5012743473052979
Validation loss: 2.058617639285262

Epoch: 6| Step: 5
Training loss: 2.0556676387786865
Validation loss: 2.0535295983796478

Epoch: 6| Step: 6
Training loss: 1.8988826274871826
Validation loss: 2.0498286075489496

Epoch: 6| Step: 7
Training loss: 1.9050911664962769
Validation loss: 2.0525347045672837

Epoch: 6| Step: 8
Training loss: 2.666031837463379
Validation loss: 2.0715529508488153

Epoch: 6| Step: 9
Training loss: 1.2027337551116943
Validation loss: 2.081394341684157

Epoch: 6| Step: 10
Training loss: 1.9240998029708862
Validation loss: 2.0745205956120647

Epoch: 6| Step: 11
Training loss: 2.5217556953430176
Validation loss: 2.048864814542955

Epoch: 6| Step: 12
Training loss: 1.4520654678344727
Validation loss: 2.0345827892262447

Epoch: 6| Step: 13
Training loss: 2.1460437774658203
Validation loss: 2.0311682352455716

Epoch: 281| Step: 0
Training loss: 2.2093448638916016
Validation loss: 2.02405192518747

Epoch: 6| Step: 1
Training loss: 2.0720701217651367
Validation loss: 2.0335412333088536

Epoch: 6| Step: 2
Training loss: 1.7128586769104004
Validation loss: 2.0302500622246855

Epoch: 6| Step: 3
Training loss: 1.9045495986938477
Validation loss: 2.0405662444330033

Epoch: 6| Step: 4
Training loss: 1.6194931268692017
Validation loss: 2.0207655583658526

Epoch: 6| Step: 5
Training loss: 1.6553716659545898
Validation loss: 2.0155097617897937

Epoch: 6| Step: 6
Training loss: 2.608766555786133
Validation loss: 2.0180580051996375

Epoch: 6| Step: 7
Training loss: 2.105125904083252
Validation loss: 2.0222794394339285

Epoch: 6| Step: 8
Training loss: 2.2169065475463867
Validation loss: 2.025741256693358

Epoch: 6| Step: 9
Training loss: 1.9254069328308105
Validation loss: 2.02668006702136

Epoch: 6| Step: 10
Training loss: 2.0045552253723145
Validation loss: 2.0310434692649433

Epoch: 6| Step: 11
Training loss: 1.4200079441070557
Validation loss: 2.030964920597692

Epoch: 6| Step: 12
Training loss: 1.8171913623809814
Validation loss: 2.051059023026497

Epoch: 6| Step: 13
Training loss: 2.4260833263397217
Validation loss: 2.040426318363477

Epoch: 282| Step: 0
Training loss: 1.9821938276290894
Validation loss: 2.0749671638652845

Epoch: 6| Step: 1
Training loss: 2.4535319805145264
Validation loss: 2.079018928671396

Epoch: 6| Step: 2
Training loss: 1.69929838180542
Validation loss: 2.0727396677899104

Epoch: 6| Step: 3
Training loss: 2.736861228942871
Validation loss: 2.082068420225574

Epoch: 6| Step: 4
Training loss: 1.1238653659820557
Validation loss: 2.0836072608988774

Epoch: 6| Step: 5
Training loss: 1.23270583152771
Validation loss: 2.080228720941851

Epoch: 6| Step: 6
Training loss: 2.080296754837036
Validation loss: 2.06440233671537

Epoch: 6| Step: 7
Training loss: 1.4014387130737305
Validation loss: 2.0577249667977773

Epoch: 6| Step: 8
Training loss: 2.0676333904266357
Validation loss: 2.0439456944824546

Epoch: 6| Step: 9
Training loss: 1.942794919013977
Validation loss: 2.0522162324638775

Epoch: 6| Step: 10
Training loss: 1.9266619682312012
Validation loss: 2.0608395684149956

Epoch: 6| Step: 11
Training loss: 1.9841420650482178
Validation loss: 2.065824800922025

Epoch: 6| Step: 12
Training loss: 2.319026470184326
Validation loss: 2.0692311397162815

Epoch: 6| Step: 13
Training loss: 2.9516899585723877
Validation loss: 2.059572281376008

Epoch: 283| Step: 0
Training loss: 2.4018173217773438
Validation loss: 2.03245460602545

Epoch: 6| Step: 1
Training loss: 1.4390699863433838
Validation loss: 2.01888431015835

Epoch: 6| Step: 2
Training loss: 1.9182411432266235
Validation loss: 2.018990639717348

Epoch: 6| Step: 3
Training loss: 2.500147581100464
Validation loss: 2.0178164410334762

Epoch: 6| Step: 4
Training loss: 1.8386023044586182
Validation loss: 2.036395647192514

Epoch: 6| Step: 5
Training loss: 1.8294721841812134
Validation loss: 2.0338761075850456

Epoch: 6| Step: 6
Training loss: 2.451383113861084
Validation loss: 2.0392106040831535

Epoch: 6| Step: 7
Training loss: 1.8238558769226074
Validation loss: 2.038935084496775

Epoch: 6| Step: 8
Training loss: 1.850823163986206
Validation loss: 2.022929696626561

Epoch: 6| Step: 9
Training loss: 1.0567636489868164
Validation loss: 2.025936213872766

Epoch: 6| Step: 10
Training loss: 1.9876867532730103
Validation loss: 2.027253136839918

Epoch: 6| Step: 11
Training loss: 1.703010082244873
Validation loss: 2.027814370329662

Epoch: 6| Step: 12
Training loss: 1.955419898033142
Validation loss: 2.0346247355143228

Epoch: 6| Step: 13
Training loss: 3.0165348052978516
Validation loss: 2.034449697822653

Epoch: 284| Step: 0
Training loss: 2.1529958248138428
Validation loss: 2.053548880802688

Epoch: 6| Step: 1
Training loss: 2.422107696533203
Validation loss: 2.052718662446545

Epoch: 6| Step: 2
Training loss: 2.3928983211517334
Validation loss: 2.0505640352925947

Epoch: 6| Step: 3
Training loss: 1.982761263847351
Validation loss: 2.0460258940214753

Epoch: 6| Step: 4
Training loss: 1.5437564849853516
Validation loss: 2.054218440927485

Epoch: 6| Step: 5
Training loss: 1.8411357402801514
Validation loss: 2.038390480062013

Epoch: 6| Step: 6
Training loss: 1.2359600067138672
Validation loss: 2.052668051053119

Epoch: 6| Step: 7
Training loss: 1.975816249847412
Validation loss: 2.059320435729078

Epoch: 6| Step: 8
Training loss: 1.8832929134368896
Validation loss: 2.0678681840178785

Epoch: 6| Step: 9
Training loss: 1.8284926414489746
Validation loss: 2.0739295431362685

Epoch: 6| Step: 10
Training loss: 2.743295192718506
Validation loss: 2.0580335304301274

Epoch: 6| Step: 11
Training loss: 1.7847216129302979
Validation loss: 2.0491821124989498

Epoch: 6| Step: 12
Training loss: 1.7742100954055786
Validation loss: 2.0431044127351496

Epoch: 6| Step: 13
Training loss: 1.4406099319458008
Validation loss: 2.0382626825763333

Epoch: 285| Step: 0
Training loss: 2.064985752105713
Validation loss: 2.032556841450353

Epoch: 6| Step: 1
Training loss: 1.6972649097442627
Validation loss: 2.0209737952037523

Epoch: 6| Step: 2
Training loss: 1.8603870868682861
Validation loss: 2.0173668476843063

Epoch: 6| Step: 3
Training loss: 2.4478354454040527
Validation loss: 2.0260750773132488

Epoch: 6| Step: 4
Training loss: 1.2311545610427856
Validation loss: 2.018207101411717

Epoch: 6| Step: 5
Training loss: 2.52866792678833
Validation loss: 2.017963795251744

Epoch: 6| Step: 6
Training loss: 1.5486016273498535
Validation loss: 2.0292261441548667

Epoch: 6| Step: 7
Training loss: 2.0285191535949707
Validation loss: 2.031711409168859

Epoch: 6| Step: 8
Training loss: 1.3259685039520264
Validation loss: 2.0248753819414365

Epoch: 6| Step: 9
Training loss: 2.2255361080169678
Validation loss: 2.0288707197353406

Epoch: 6| Step: 10
Training loss: 2.155961036682129
Validation loss: 2.038994691705191

Epoch: 6| Step: 11
Training loss: 1.3018543720245361
Validation loss: 2.0369160944415676

Epoch: 6| Step: 12
Training loss: 2.8983840942382812
Validation loss: 2.0318749937959897

Epoch: 6| Step: 13
Training loss: 1.7815660238265991
Validation loss: 2.0309299935576735

Epoch: 286| Step: 0
Training loss: 1.9320969581604004
Validation loss: 2.02672549216978

Epoch: 6| Step: 1
Training loss: 1.3418124914169312
Validation loss: 2.0263293891824703

Epoch: 6| Step: 2
Training loss: 2.040587902069092
Validation loss: 2.0174177692782496

Epoch: 6| Step: 3
Training loss: 2.5296478271484375
Validation loss: 2.0156615549518215

Epoch: 6| Step: 4
Training loss: 1.6144956350326538
Validation loss: 2.013769280525946

Epoch: 6| Step: 5
Training loss: 1.4008760452270508
Validation loss: 2.0159314883652555

Epoch: 6| Step: 6
Training loss: 2.2248291969299316
Validation loss: 2.021439690743723

Epoch: 6| Step: 7
Training loss: 2.1242356300354004
Validation loss: 2.014670960364803

Epoch: 6| Step: 8
Training loss: 1.740548014640808
Validation loss: 2.0183676391519527

Epoch: 6| Step: 9
Training loss: 1.421872854232788
Validation loss: 2.0134360738979873

Epoch: 6| Step: 10
Training loss: 2.254303216934204
Validation loss: 2.0179508809120423

Epoch: 6| Step: 11
Training loss: 2.2520415782928467
Validation loss: 2.0274469801174697

Epoch: 6| Step: 12
Training loss: 1.8781702518463135
Validation loss: 2.030326145951466

Epoch: 6| Step: 13
Training loss: 2.3797998428344727
Validation loss: 2.0356684987263014

Epoch: 287| Step: 0
Training loss: 2.2246620655059814
Validation loss: 2.0304702661370717

Epoch: 6| Step: 1
Training loss: 1.9876816272735596
Validation loss: 2.030084515130648

Epoch: 6| Step: 2
Training loss: 2.773519992828369
Validation loss: 2.039504384481779

Epoch: 6| Step: 3
Training loss: 1.8101361989974976
Validation loss: 2.0439447651627245

Epoch: 6| Step: 4
Training loss: 2.1816399097442627
Validation loss: 2.043802797153432

Epoch: 6| Step: 5
Training loss: 2.4209342002868652
Validation loss: 2.035415498159265

Epoch: 6| Step: 6
Training loss: 1.5263489484786987
Validation loss: 2.030682402272378

Epoch: 6| Step: 7
Training loss: 1.8739793300628662
Validation loss: 2.0263661517891833

Epoch: 6| Step: 8
Training loss: 1.3687679767608643
Validation loss: 2.0256291409974456

Epoch: 6| Step: 9
Training loss: 1.7840937376022339
Validation loss: 2.0308438065231487

Epoch: 6| Step: 10
Training loss: 1.6953608989715576
Validation loss: 2.0350930331855692

Epoch: 6| Step: 11
Training loss: 1.3722233772277832
Validation loss: 2.0275130143729587

Epoch: 6| Step: 12
Training loss: 1.7637149095535278
Validation loss: 2.0289746279357583

Epoch: 6| Step: 13
Training loss: 2.3517961502075195
Validation loss: 2.032900292386291

Epoch: 288| Step: 0
Training loss: 1.8106971979141235
Validation loss: 2.036293015685133

Epoch: 6| Step: 1
Training loss: 1.8731505870819092
Validation loss: 2.0291239856391825

Epoch: 6| Step: 2
Training loss: 2.3082633018493652
Validation loss: 2.0235330802138134

Epoch: 6| Step: 3
Training loss: 1.9874032735824585
Validation loss: 2.025331966338619

Epoch: 6| Step: 4
Training loss: 2.0651450157165527
Validation loss: 2.0312291909289617

Epoch: 6| Step: 5
Training loss: 1.7646949291229248
Validation loss: 2.027341987497063

Epoch: 6| Step: 6
Training loss: 1.5301952362060547
Validation loss: 2.0272330378973358

Epoch: 6| Step: 7
Training loss: 2.337707281112671
Validation loss: 2.0276613081655195

Epoch: 6| Step: 8
Training loss: 2.2498064041137695
Validation loss: 2.017341524042109

Epoch: 6| Step: 9
Training loss: 1.711024284362793
Validation loss: 2.032296210206965

Epoch: 6| Step: 10
Training loss: 2.241136312484741
Validation loss: 2.024930595069803

Epoch: 6| Step: 11
Training loss: 1.7175016403198242
Validation loss: 2.031183676053119

Epoch: 6| Step: 12
Training loss: 1.7833778858184814
Validation loss: 2.041158540274507

Epoch: 6| Step: 13
Training loss: 1.0307282209396362
Validation loss: 2.0345066978085424

Epoch: 289| Step: 0
Training loss: 1.8330936431884766
Validation loss: 2.039567147531817

Epoch: 6| Step: 1
Training loss: 2.179417610168457
Validation loss: 2.040899831761596

Epoch: 6| Step: 2
Training loss: 1.4347305297851562
Validation loss: 2.047392168352681

Epoch: 6| Step: 3
Training loss: 1.8754700422286987
Validation loss: 2.053203502008992

Epoch: 6| Step: 4
Training loss: 1.5817477703094482
Validation loss: 2.047286695049655

Epoch: 6| Step: 5
Training loss: 2.8331451416015625
Validation loss: 2.04864405047509

Epoch: 6| Step: 6
Training loss: 2.1685056686401367
Validation loss: 2.029502764824898

Epoch: 6| Step: 7
Training loss: 1.6209981441497803
Validation loss: 2.028975946928865

Epoch: 6| Step: 8
Training loss: 1.970215082168579
Validation loss: 2.0418273300252934

Epoch: 6| Step: 9
Training loss: 1.3708215951919556
Validation loss: 2.01615842311613

Epoch: 6| Step: 10
Training loss: 2.2195334434509277
Validation loss: 2.0204697219274377

Epoch: 6| Step: 11
Training loss: 1.7392756938934326
Validation loss: 2.0224849101035827

Epoch: 6| Step: 12
Training loss: 1.7900358438491821
Validation loss: 2.0080010775596864

Epoch: 6| Step: 13
Training loss: 2.3239877223968506
Validation loss: 2.0178163102878037

Epoch: 290| Step: 0
Training loss: 1.9969788789749146
Validation loss: 2.01069535106741

Epoch: 6| Step: 1
Training loss: 1.0720670223236084
Validation loss: 2.0281304351745115

Epoch: 6| Step: 2
Training loss: 2.1240439414978027
Validation loss: 2.026521372538741

Epoch: 6| Step: 3
Training loss: 2.429539203643799
Validation loss: 2.0162501386416856

Epoch: 6| Step: 4
Training loss: 1.4542800188064575
Validation loss: 2.0461718446464947

Epoch: 6| Step: 5
Training loss: 2.413573980331421
Validation loss: 2.037826115085233

Epoch: 6| Step: 6
Training loss: 1.6784173250198364
Validation loss: 2.021852954741447

Epoch: 6| Step: 7
Training loss: 2.647109031677246
Validation loss: 2.0205702781677246

Epoch: 6| Step: 8
Training loss: 1.9788315296173096
Validation loss: 2.028597390779885

Epoch: 6| Step: 9
Training loss: 1.6462929248809814
Validation loss: 2.031894022418607

Epoch: 6| Step: 10
Training loss: 1.699851393699646
Validation loss: 2.0092359319809945

Epoch: 6| Step: 11
Training loss: 1.2905082702636719
Validation loss: 2.0301964129171064

Epoch: 6| Step: 12
Training loss: 2.1166601181030273
Validation loss: 2.029184059430194

Epoch: 6| Step: 13
Training loss: 2.311035633087158
Validation loss: 2.0658318022246003

Epoch: 291| Step: 0
Training loss: 1.1485823392868042
Validation loss: 2.1144341525211128

Epoch: 6| Step: 1
Training loss: 1.8776769638061523
Validation loss: 2.112101875325685

Epoch: 6| Step: 2
Training loss: 2.114107131958008
Validation loss: 2.0933591704214773

Epoch: 6| Step: 3
Training loss: 2.123303174972534
Validation loss: 2.061484541944278

Epoch: 6| Step: 4
Training loss: 2.029691696166992
Validation loss: 2.0305563711350962

Epoch: 6| Step: 5
Training loss: 1.6007561683654785
Validation loss: 2.0234836673223846

Epoch: 6| Step: 6
Training loss: 1.5658655166625977
Validation loss: 2.024222763635779

Epoch: 6| Step: 7
Training loss: 2.0680058002471924
Validation loss: 2.043888211250305

Epoch: 6| Step: 8
Training loss: 2.939627170562744
Validation loss: 2.083661793380655

Epoch: 6| Step: 9
Training loss: 1.9837709665298462
Validation loss: 2.0740540860801615

Epoch: 6| Step: 10
Training loss: 2.033297061920166
Validation loss: 2.0580345533227407

Epoch: 6| Step: 11
Training loss: 1.8148454427719116
Validation loss: 2.0160649258603334

Epoch: 6| Step: 12
Training loss: 2.4108643531799316
Validation loss: 2.021818268683649

Epoch: 6| Step: 13
Training loss: 1.457825779914856
Validation loss: 2.0003242825949066

Epoch: 292| Step: 0
Training loss: 1.7617321014404297
Validation loss: 2.0061537386268697

Epoch: 6| Step: 1
Training loss: 1.6962040662765503
Validation loss: 1.9889819916858469

Epoch: 6| Step: 2
Training loss: 1.8856929540634155
Validation loss: 2.0148916962326213

Epoch: 6| Step: 3
Training loss: 1.7817840576171875
Validation loss: 2.008442891541348

Epoch: 6| Step: 4
Training loss: 2.711894989013672
Validation loss: 2.010031919325552

Epoch: 6| Step: 5
Training loss: 1.7501188516616821
Validation loss: 2.016388593181487

Epoch: 6| Step: 6
Training loss: 1.7794272899627686
Validation loss: 2.0105029293285903

Epoch: 6| Step: 7
Training loss: 1.5725728273391724
Validation loss: 2.020646467003771

Epoch: 6| Step: 8
Training loss: 2.3386294841766357
Validation loss: 2.0168356972356

Epoch: 6| Step: 9
Training loss: 2.205549716949463
Validation loss: 2.0353526582000074

Epoch: 6| Step: 10
Training loss: 1.3371667861938477
Validation loss: 2.02413543193571

Epoch: 6| Step: 11
Training loss: 1.5350589752197266
Validation loss: 2.0345773171353083

Epoch: 6| Step: 12
Training loss: 1.6723511219024658
Validation loss: 2.034179319617569

Epoch: 6| Step: 13
Training loss: 2.9758591651916504
Validation loss: 2.0511255469373477

Epoch: 293| Step: 0
Training loss: 2.0044941902160645
Validation loss: 2.0358242142585015

Epoch: 6| Step: 1
Training loss: 2.115396022796631
Validation loss: 2.053766753083916

Epoch: 6| Step: 2
Training loss: 1.9190977811813354
Validation loss: 2.04741996078081

Epoch: 6| Step: 3
Training loss: 1.6042078733444214
Validation loss: 2.0534106416086995

Epoch: 6| Step: 4
Training loss: 2.212763786315918
Validation loss: 2.0547659281761415

Epoch: 6| Step: 5
Training loss: 1.8093233108520508
Validation loss: 2.0431159862907986

Epoch: 6| Step: 6
Training loss: 1.8746178150177002
Validation loss: 2.0414276725502423

Epoch: 6| Step: 7
Training loss: 2.035329818725586
Validation loss: 2.013367215792338

Epoch: 6| Step: 8
Training loss: 1.783442735671997
Validation loss: 2.0119276738935903

Epoch: 6| Step: 9
Training loss: 1.899628758430481
Validation loss: 2.014047343243835

Epoch: 6| Step: 10
Training loss: 2.1493306159973145
Validation loss: 1.9871346706985145

Epoch: 6| Step: 11
Training loss: 1.2940064668655396
Validation loss: 2.0028111575752177

Epoch: 6| Step: 12
Training loss: 2.0405945777893066
Validation loss: 1.9960606495539348

Epoch: 6| Step: 13
Training loss: 1.9766629934310913
Validation loss: 2.018908695508075

Epoch: 294| Step: 0
Training loss: 2.3511695861816406
Validation loss: 2.0242000895161785

Epoch: 6| Step: 1
Training loss: 2.4234249591827393
Validation loss: 2.0060266576787478

Epoch: 6| Step: 2
Training loss: 1.774674892425537
Validation loss: 2.004976918620448

Epoch: 6| Step: 3
Training loss: 1.399413824081421
Validation loss: 2.0258121041841406

Epoch: 6| Step: 4
Training loss: 2.1664528846740723
Validation loss: 2.042368047980852

Epoch: 6| Step: 5
Training loss: 1.7048335075378418
Validation loss: 2.0434231553026425

Epoch: 6| Step: 6
Training loss: 1.3557803630828857
Validation loss: 2.050648579033472

Epoch: 6| Step: 7
Training loss: 2.0607757568359375
Validation loss: 2.020102534242856

Epoch: 6| Step: 8
Training loss: 2.078341484069824
Validation loss: 2.012364384948566

Epoch: 6| Step: 9
Training loss: 1.8474671840667725
Validation loss: 2.0143570412871656

Epoch: 6| Step: 10
Training loss: 1.453136920928955
Validation loss: 2.0195340930774646

Epoch: 6| Step: 11
Training loss: 1.802759051322937
Validation loss: 2.0215672651926675

Epoch: 6| Step: 12
Training loss: 2.6125316619873047
Validation loss: 2.035118643955518

Epoch: 6| Step: 13
Training loss: 1.5571039915084839
Validation loss: 2.025519765833373

Epoch: 295| Step: 0
Training loss: 1.904107689857483
Validation loss: 2.0361128622485745

Epoch: 6| Step: 1
Training loss: 1.9761830568313599
Validation loss: 2.0337961668609292

Epoch: 6| Step: 2
Training loss: 2.429705858230591
Validation loss: 2.0241952044989473

Epoch: 6| Step: 3
Training loss: 2.0773673057556152
Validation loss: 2.0362397714327742

Epoch: 6| Step: 4
Training loss: 2.038963794708252
Validation loss: 2.0285308194416825

Epoch: 6| Step: 5
Training loss: 1.8203431367874146
Validation loss: 2.0165797048999416

Epoch: 6| Step: 6
Training loss: 2.060908317565918
Validation loss: 2.0138573774727444

Epoch: 6| Step: 7
Training loss: 1.1871049404144287
Validation loss: 2.017287908061858

Epoch: 6| Step: 8
Training loss: 1.4241241216659546
Validation loss: 2.022892354637064

Epoch: 6| Step: 9
Training loss: 1.9086735248565674
Validation loss: 2.0131100993002615

Epoch: 6| Step: 10
Training loss: 1.0912699699401855
Validation loss: 1.993382046299596

Epoch: 6| Step: 11
Training loss: 1.8550167083740234
Validation loss: 1.9854670955288796

Epoch: 6| Step: 12
Training loss: 2.562713384628296
Validation loss: 1.9958838352593042

Epoch: 6| Step: 13
Training loss: 2.048945665359497
Validation loss: 1.9862798311377083

Epoch: 296| Step: 0
Training loss: 1.4626412391662598
Validation loss: 1.9954372259878344

Epoch: 6| Step: 1
Training loss: 1.456294298171997
Validation loss: 2.006305968889626

Epoch: 6| Step: 2
Training loss: 1.8467744588851929
Validation loss: 2.0241291112797235

Epoch: 6| Step: 3
Training loss: 2.0888314247131348
Validation loss: 2.02830518445661

Epoch: 6| Step: 4
Training loss: 1.856299638748169
Validation loss: 2.0314298598997054

Epoch: 6| Step: 5
Training loss: 1.974196195602417
Validation loss: 2.037860712697429

Epoch: 6| Step: 6
Training loss: 2.012755870819092
Validation loss: 2.0351439855431996

Epoch: 6| Step: 7
Training loss: 1.501934289932251
Validation loss: 2.0424466774027836

Epoch: 6| Step: 8
Training loss: 2.1269476413726807
Validation loss: 2.0195271225385767

Epoch: 6| Step: 9
Training loss: 1.7333498001098633
Validation loss: 2.034435211971242

Epoch: 6| Step: 10
Training loss: 2.0588271617889404
Validation loss: 2.02282138024607

Epoch: 6| Step: 11
Training loss: 1.9174712896347046
Validation loss: 2.0199586447849067

Epoch: 6| Step: 12
Training loss: 1.9675520658493042
Validation loss: 2.042457727975743

Epoch: 6| Step: 13
Training loss: 2.5547280311584473
Validation loss: 2.0104763751388877

Epoch: 297| Step: 0
Training loss: 1.8591454029083252
Validation loss: 2.0315929151350454

Epoch: 6| Step: 1
Training loss: 1.8945406675338745
Validation loss: 2.0274328877848964

Epoch: 6| Step: 2
Training loss: 1.9267200231552124
Validation loss: 2.0282949324577086

Epoch: 6| Step: 3
Training loss: 1.305814266204834
Validation loss: 2.0306131762842976

Epoch: 6| Step: 4
Training loss: 1.3466286659240723
Validation loss: 2.041392618610013

Epoch: 6| Step: 5
Training loss: 1.8318548202514648
Validation loss: 2.0555057756362425

Epoch: 6| Step: 6
Training loss: 2.436081647872925
Validation loss: 2.0675944448799215

Epoch: 6| Step: 7
Training loss: 2.242515802383423
Validation loss: 2.0695483402539323

Epoch: 6| Step: 8
Training loss: 1.6480683088302612
Validation loss: 2.0447552832224036

Epoch: 6| Step: 9
Training loss: 1.03377366065979
Validation loss: 2.0275658330609723

Epoch: 6| Step: 10
Training loss: 2.2458508014678955
Validation loss: 2.022799530336934

Epoch: 6| Step: 11
Training loss: 1.7480223178863525
Validation loss: 2.027647036378102

Epoch: 6| Step: 12
Training loss: 2.1921591758728027
Validation loss: 2.022006304033341

Epoch: 6| Step: 13
Training loss: 3.0907211303710938
Validation loss: 2.013863230264315

Epoch: 298| Step: 0
Training loss: 2.1317851543426514
Validation loss: 2.000823377281107

Epoch: 6| Step: 1
Training loss: 2.358725070953369
Validation loss: 1.9993404265372985

Epoch: 6| Step: 2
Training loss: 2.473275661468506
Validation loss: 1.9794663536933161

Epoch: 6| Step: 3
Training loss: 1.174185872077942
Validation loss: 1.993540144735767

Epoch: 6| Step: 4
Training loss: 1.4106342792510986
Validation loss: 1.9903489453818208

Epoch: 6| Step: 5
Training loss: 1.3913898468017578
Validation loss: 1.9857834539105814

Epoch: 6| Step: 6
Training loss: 1.8484952449798584
Validation loss: 1.9869028458031275

Epoch: 6| Step: 7
Training loss: 1.9569013118743896
Validation loss: 1.974539287628666

Epoch: 6| Step: 8
Training loss: 1.2353367805480957
Validation loss: 1.9781598185980191

Epoch: 6| Step: 9
Training loss: 1.6055231094360352
Validation loss: 1.9822113719037784

Epoch: 6| Step: 10
Training loss: 1.816135287284851
Validation loss: 1.989435016468007

Epoch: 6| Step: 11
Training loss: 2.401197910308838
Validation loss: 1.999697018695134

Epoch: 6| Step: 12
Training loss: 2.176551580429077
Validation loss: 2.01841075317834

Epoch: 6| Step: 13
Training loss: 2.487668037414551
Validation loss: 2.0284548792787778

Epoch: 299| Step: 0
Training loss: 2.803140640258789
Validation loss: 2.0468951771336217

Epoch: 6| Step: 1
Training loss: 1.4771161079406738
Validation loss: 2.0512457893740748

Epoch: 6| Step: 2
Training loss: 2.1025664806365967
Validation loss: 2.0487951860632947

Epoch: 6| Step: 3
Training loss: 1.198511004447937
Validation loss: 2.054874527838922

Epoch: 6| Step: 4
Training loss: 1.834831953048706
Validation loss: 2.0509757136785858

Epoch: 6| Step: 5
Training loss: 1.83571457862854
Validation loss: 2.064341401541105

Epoch: 6| Step: 6
Training loss: 1.4628247022628784
Validation loss: 2.0583440565293833

Epoch: 6| Step: 7
Training loss: 2.2649776935577393
Validation loss: 2.066049373278054

Epoch: 6| Step: 8
Training loss: 1.45391845703125
Validation loss: 2.0553416539263982

Epoch: 6| Step: 9
Training loss: 2.314401149749756
Validation loss: 2.0469856134024997

Epoch: 6| Step: 10
Training loss: 2.053917407989502
Validation loss: 2.0228844816966722

Epoch: 6| Step: 11
Training loss: 1.7211978435516357
Validation loss: 2.018527207836028

Epoch: 6| Step: 12
Training loss: 1.98104727268219
Validation loss: 2.0230195983763664

Epoch: 6| Step: 13
Training loss: 1.2854444980621338
Validation loss: 1.9983662841140584

Epoch: 300| Step: 0
Training loss: 1.8768196105957031
Validation loss: 1.9996276504249983

Epoch: 6| Step: 1
Training loss: 1.4479994773864746
Validation loss: 1.984363445671656

Epoch: 6| Step: 2
Training loss: 1.7953386306762695
Validation loss: 1.9949129089232414

Epoch: 6| Step: 3
Training loss: 1.7408115863800049
Validation loss: 1.9904316753469489

Epoch: 6| Step: 4
Training loss: 1.8394367694854736
Validation loss: 2.000466654377599

Epoch: 6| Step: 5
Training loss: 2.4342219829559326
Validation loss: 2.000169123372724

Epoch: 6| Step: 6
Training loss: 2.1247267723083496
Validation loss: 1.9958648476549374

Epoch: 6| Step: 7
Training loss: 1.880579948425293
Validation loss: 1.9961711052925355

Epoch: 6| Step: 8
Training loss: 1.4207484722137451
Validation loss: 2.002783497174581

Epoch: 6| Step: 9
Training loss: 2.2072277069091797
Validation loss: 1.9945961993227723

Epoch: 6| Step: 10
Training loss: 2.039121150970459
Validation loss: 2.0084188471558275

Epoch: 6| Step: 11
Training loss: 1.734320044517517
Validation loss: 2.0088346363395773

Epoch: 6| Step: 12
Training loss: 1.4788306951522827
Validation loss: 2.0052207439176497

Epoch: 6| Step: 13
Training loss: 2.0271177291870117
Validation loss: 2.012822257575168

Epoch: 301| Step: 0
Training loss: 1.9327502250671387
Validation loss: 2.0161745394429853

Epoch: 6| Step: 1
Training loss: 1.7786296606063843
Validation loss: 2.02710202945176

Epoch: 6| Step: 2
Training loss: 1.6755330562591553
Validation loss: 2.022579155942445

Epoch: 6| Step: 3
Training loss: 1.2924864292144775
Validation loss: 2.0497943867919264

Epoch: 6| Step: 4
Training loss: 2.6738927364349365
Validation loss: 2.0419665536572857

Epoch: 6| Step: 5
Training loss: 1.5201070308685303
Validation loss: 2.063242591837401

Epoch: 6| Step: 6
Training loss: 2.2734713554382324
Validation loss: 2.0551060989338863

Epoch: 6| Step: 7
Training loss: 2.253061294555664
Validation loss: 2.0560397409623667

Epoch: 6| Step: 8
Training loss: 1.6517987251281738
Validation loss: 2.054623455129644

Epoch: 6| Step: 9
Training loss: 1.9953721761703491
Validation loss: 2.0840194853403236

Epoch: 6| Step: 10
Training loss: 1.0842229127883911
Validation loss: 2.0630685975474696

Epoch: 6| Step: 11
Training loss: 1.8217192888259888
Validation loss: 2.0631152019705823

Epoch: 6| Step: 12
Training loss: 1.8338744640350342
Validation loss: 2.0402982286227647

Epoch: 6| Step: 13
Training loss: 2.5790865421295166
Validation loss: 2.0380880140489146

Epoch: 302| Step: 0
Training loss: 1.926267385482788
Validation loss: 2.025201182211599

Epoch: 6| Step: 1
Training loss: 1.790108323097229
Validation loss: 1.992966616025535

Epoch: 6| Step: 2
Training loss: 1.3418712615966797
Validation loss: 1.9866032215856737

Epoch: 6| Step: 3
Training loss: 1.8386558294296265
Validation loss: 1.9956495556780087

Epoch: 6| Step: 4
Training loss: 2.014984130859375
Validation loss: 1.9893265975418912

Epoch: 6| Step: 5
Training loss: 2.0680832862854004
Validation loss: 1.9840270165474183

Epoch: 6| Step: 6
Training loss: 1.1797840595245361
Validation loss: 1.9757652359624063

Epoch: 6| Step: 7
Training loss: 1.9716066122055054
Validation loss: 1.9927791805677517

Epoch: 6| Step: 8
Training loss: 1.9841763973236084
Validation loss: 1.9869293012926657

Epoch: 6| Step: 9
Training loss: 2.0825228691101074
Validation loss: 1.991927077693324

Epoch: 6| Step: 10
Training loss: 2.357025623321533
Validation loss: 1.994268145612491

Epoch: 6| Step: 11
Training loss: 1.9764312505722046
Validation loss: 2.0012367643335813

Epoch: 6| Step: 12
Training loss: 1.6744686365127563
Validation loss: 1.9989131971072125

Epoch: 6| Step: 13
Training loss: 1.4044445753097534
Validation loss: 2.009976545969645

Epoch: 303| Step: 0
Training loss: 1.5848584175109863
Validation loss: 2.0092582830818753

Epoch: 6| Step: 1
Training loss: 1.9254424571990967
Validation loss: 2.019509715418662

Epoch: 6| Step: 2
Training loss: 1.6286684274673462
Validation loss: 2.0218748866870837

Epoch: 6| Step: 3
Training loss: 1.5844998359680176
Validation loss: 2.021311536911995

Epoch: 6| Step: 4
Training loss: 2.078679323196411
Validation loss: 2.031663094797442

Epoch: 6| Step: 5
Training loss: 1.8371917009353638
Validation loss: 2.0245686731030865

Epoch: 6| Step: 6
Training loss: 1.7065359354019165
Validation loss: 2.0357212597324

Epoch: 6| Step: 7
Training loss: 2.3394370079040527
Validation loss: 2.0394774957369735

Epoch: 6| Step: 8
Training loss: 1.7244482040405273
Validation loss: 2.0386582138717815

Epoch: 6| Step: 9
Training loss: 2.9126834869384766
Validation loss: 2.0134046372546943

Epoch: 6| Step: 10
Training loss: 1.883791446685791
Validation loss: 2.005212494122085

Epoch: 6| Step: 11
Training loss: 1.6493701934814453
Validation loss: 2.0024707932626047

Epoch: 6| Step: 12
Training loss: 1.5227731466293335
Validation loss: 2.0183810854470856

Epoch: 6| Step: 13
Training loss: 1.0449720621109009
Validation loss: 2.027796604300058

Epoch: 304| Step: 0
Training loss: 1.648064374923706
Validation loss: 2.0034425668818976

Epoch: 6| Step: 1
Training loss: 1.4151396751403809
Validation loss: 2.021851057647377

Epoch: 6| Step: 2
Training loss: 2.400775909423828
Validation loss: 2.017474136044902

Epoch: 6| Step: 3
Training loss: 1.3229050636291504
Validation loss: 2.0259110235398814

Epoch: 6| Step: 4
Training loss: 2.0527124404907227
Validation loss: 2.0300503405191566

Epoch: 6| Step: 5
Training loss: 2.181488037109375
Validation loss: 2.013523559416494

Epoch: 6| Step: 6
Training loss: 2.3438825607299805
Validation loss: 2.0370417461600354

Epoch: 6| Step: 7
Training loss: 1.7096550464630127
Validation loss: 2.0235453959434264

Epoch: 6| Step: 8
Training loss: 1.287532091140747
Validation loss: 2.0591333091899915

Epoch: 6| Step: 9
Training loss: 1.9214872121810913
Validation loss: 2.085179118699925

Epoch: 6| Step: 10
Training loss: 2.0386900901794434
Validation loss: 2.0867842410200383

Epoch: 6| Step: 11
Training loss: 2.104816436767578
Validation loss: 2.0813194039047405

Epoch: 6| Step: 12
Training loss: 1.8671891689300537
Validation loss: 2.073949335723795

Epoch: 6| Step: 13
Training loss: 1.4907044172286987
Validation loss: 2.053100283427905

Epoch: 305| Step: 0
Training loss: 1.5381841659545898
Validation loss: 2.0254732203739945

Epoch: 6| Step: 1
Training loss: 1.8474862575531006
Validation loss: 2.0249566365313787

Epoch: 6| Step: 2
Training loss: 1.4901771545410156
Validation loss: 2.029190573641049

Epoch: 6| Step: 3
Training loss: 1.827757716178894
Validation loss: 2.055356731978796

Epoch: 6| Step: 4
Training loss: 2.489029884338379
Validation loss: 2.04872811994245

Epoch: 6| Step: 5
Training loss: 2.030050039291382
Validation loss: 2.0344472521094867

Epoch: 6| Step: 6
Training loss: 1.6929680109024048
Validation loss: 2.0329028688451296

Epoch: 6| Step: 7
Training loss: 1.4285988807678223
Validation loss: 2.041091698472218

Epoch: 6| Step: 8
Training loss: 2.005836009979248
Validation loss: 2.022368263172847

Epoch: 6| Step: 9
Training loss: 2.7586560249328613
Validation loss: 2.032486618206065

Epoch: 6| Step: 10
Training loss: 1.6115748882293701
Validation loss: 2.0410610475847797

Epoch: 6| Step: 11
Training loss: 1.4880120754241943
Validation loss: 2.0499223329687632

Epoch: 6| Step: 12
Training loss: 1.3214930295944214
Validation loss: 2.0644425346005346

Epoch: 6| Step: 13
Training loss: 2.3749122619628906
Validation loss: 2.0458021945850824

Epoch: 306| Step: 0
Training loss: 1.7904901504516602
Validation loss: 2.050747885498949

Epoch: 6| Step: 1
Training loss: 2.7772796154022217
Validation loss: 2.0233986121352

Epoch: 6| Step: 2
Training loss: 1.0771199464797974
Validation loss: 2.017170462557065

Epoch: 6| Step: 3
Training loss: 0.6706018447875977
Validation loss: 2.0344354209079536

Epoch: 6| Step: 4
Training loss: 1.6966791152954102
Validation loss: 2.013881634640437

Epoch: 6| Step: 5
Training loss: 2.733975887298584
Validation loss: 2.029401609974523

Epoch: 6| Step: 6
Training loss: 1.5160534381866455
Validation loss: 2.02617698202851

Epoch: 6| Step: 7
Training loss: 1.3703478574752808
Validation loss: 2.015111683517374

Epoch: 6| Step: 8
Training loss: 1.767683744430542
Validation loss: 2.019181625817412

Epoch: 6| Step: 9
Training loss: 1.7425159215927124
Validation loss: 2.0304636621987946

Epoch: 6| Step: 10
Training loss: 2.062265634536743
Validation loss: 2.020465076610606

Epoch: 6| Step: 11
Training loss: 2.5161633491516113
Validation loss: 2.0181810984047512

Epoch: 6| Step: 12
Training loss: 1.5749903917312622
Validation loss: 2.048032734983711

Epoch: 6| Step: 13
Training loss: 2.400153636932373
Validation loss: 2.044989375657933

Epoch: 307| Step: 0
Training loss: 1.6461312770843506
Validation loss: 2.024124676181424

Epoch: 6| Step: 1
Training loss: 1.9230010509490967
Validation loss: 2.020658059786725

Epoch: 6| Step: 2
Training loss: 0.9472588300704956
Validation loss: 2.018853210633801

Epoch: 6| Step: 3
Training loss: 1.9741785526275635
Validation loss: 2.033132481318648

Epoch: 6| Step: 4
Training loss: 2.134371042251587
Validation loss: 2.048987570629325

Epoch: 6| Step: 5
Training loss: 1.7729439735412598
Validation loss: 2.0408138434092202

Epoch: 6| Step: 6
Training loss: 1.4234132766723633
Validation loss: 2.040366526572935

Epoch: 6| Step: 7
Training loss: 1.4487860202789307
Validation loss: 2.03420574690706

Epoch: 6| Step: 8
Training loss: 1.9680144786834717
Validation loss: 2.0362115624130412

Epoch: 6| Step: 9
Training loss: 2.1878881454467773
Validation loss: 2.056981998105203

Epoch: 6| Step: 10
Training loss: 1.5675935745239258
Validation loss: 2.078850894845942

Epoch: 6| Step: 11
Training loss: 2.5061874389648438
Validation loss: 2.102545110128259

Epoch: 6| Step: 12
Training loss: 2.285421371459961
Validation loss: 2.0891394397263885

Epoch: 6| Step: 13
Training loss: 1.8677951097488403
Validation loss: 2.0642996782897622

Epoch: 308| Step: 0
Training loss: 1.0843868255615234
Validation loss: 2.03949135862371

Epoch: 6| Step: 1
Training loss: 2.3259341716766357
Validation loss: 2.031628188266549

Epoch: 6| Step: 2
Training loss: 1.743906021118164
Validation loss: 2.0362153899285103

Epoch: 6| Step: 3
Training loss: 1.421228289604187
Validation loss: 2.0509761200156262

Epoch: 6| Step: 4
Training loss: 1.332384705543518
Validation loss: 2.0494232664826098

Epoch: 6| Step: 5
Training loss: 2.3418755531311035
Validation loss: 2.041585668440788

Epoch: 6| Step: 6
Training loss: 2.441075325012207
Validation loss: 2.0421852847581268

Epoch: 6| Step: 7
Training loss: 2.175501823425293
Validation loss: 2.0265482497471634

Epoch: 6| Step: 8
Training loss: 1.5641695261001587
Validation loss: 2.0214485532494

Epoch: 6| Step: 9
Training loss: 2.238919258117676
Validation loss: 2.024183770661713

Epoch: 6| Step: 10
Training loss: 1.773465871810913
Validation loss: 2.0261514648314445

Epoch: 6| Step: 11
Training loss: 1.586378812789917
Validation loss: 2.013329654611567

Epoch: 6| Step: 12
Training loss: 1.1748433113098145
Validation loss: 2.015221118927002

Epoch: 6| Step: 13
Training loss: 2.0661237239837646
Validation loss: 2.0128671366681337

Epoch: 309| Step: 0
Training loss: 1.2897948026657104
Validation loss: 2.0260357113294702

Epoch: 6| Step: 1
Training loss: 1.5304760932922363
Validation loss: 2.0207373429370183

Epoch: 6| Step: 2
Training loss: 1.5573846101760864
Validation loss: 2.0020269732321463

Epoch: 6| Step: 3
Training loss: 1.4701179265975952
Validation loss: 2.0086836302152244

Epoch: 6| Step: 4
Training loss: 1.3127299547195435
Validation loss: 2.009031980268417

Epoch: 6| Step: 5
Training loss: 2.4069247245788574
Validation loss: 2.003999666501117

Epoch: 6| Step: 6
Training loss: 1.9483990669250488
Validation loss: 2.006958635904456

Epoch: 6| Step: 7
Training loss: 2.0405445098876953
Validation loss: 2.016882150403915

Epoch: 6| Step: 8
Training loss: 2.235468864440918
Validation loss: 2.0203315134971374

Epoch: 6| Step: 9
Training loss: 2.335477352142334
Validation loss: 2.034960525010222

Epoch: 6| Step: 10
Training loss: 1.8599867820739746
Validation loss: 2.0310633464526107

Epoch: 6| Step: 11
Training loss: 2.284621477127075
Validation loss: 2.0313479643996044

Epoch: 6| Step: 12
Training loss: 1.3317646980285645
Validation loss: 2.024710906449185

Epoch: 6| Step: 13
Training loss: 1.4909882545471191
Validation loss: 2.0211842675362863

Epoch: 310| Step: 0
Training loss: 2.4937937259674072
Validation loss: 2.0360243653738372

Epoch: 6| Step: 1
Training loss: 2.0211377143859863
Validation loss: 2.033467802950131

Epoch: 6| Step: 2
Training loss: 1.940622091293335
Validation loss: 2.0482746478049987

Epoch: 6| Step: 3
Training loss: 1.207594394683838
Validation loss: 2.0528358131326656

Epoch: 6| Step: 4
Training loss: 1.1692794561386108
Validation loss: 2.045776249260031

Epoch: 6| Step: 5
Training loss: 1.8235136270523071
Validation loss: 2.0835312130630657

Epoch: 6| Step: 6
Training loss: 1.9558463096618652
Validation loss: 2.0537442084281676

Epoch: 6| Step: 7
Training loss: 1.5009713172912598
Validation loss: 2.037907318402362

Epoch: 6| Step: 8
Training loss: 1.8979737758636475
Validation loss: 2.0318578968765917

Epoch: 6| Step: 9
Training loss: 2.0219500064849854
Validation loss: 2.0264639956976778

Epoch: 6| Step: 10
Training loss: 1.6121981143951416
Validation loss: 2.0480081829973447

Epoch: 6| Step: 11
Training loss: 1.537482738494873
Validation loss: 2.0514719614418606

Epoch: 6| Step: 12
Training loss: 1.8826881647109985
Validation loss: 2.0660004872147755

Epoch: 6| Step: 13
Training loss: 2.4057414531707764
Validation loss: 2.0453001850394794

Epoch: 311| Step: 0
Training loss: 2.9462013244628906
Validation loss: 2.0366479619856803

Epoch: 6| Step: 1
Training loss: 1.6256746053695679
Validation loss: 2.0329924450125745

Epoch: 6| Step: 2
Training loss: 1.546341896057129
Validation loss: 2.0188987665278937

Epoch: 6| Step: 3
Training loss: 1.872564673423767
Validation loss: 2.023198595610998

Epoch: 6| Step: 4
Training loss: 1.6865442991256714
Validation loss: 2.047481788102017

Epoch: 6| Step: 5
Training loss: 1.1766725778579712
Validation loss: 2.048981487110097

Epoch: 6| Step: 6
Training loss: 1.1175990104675293
Validation loss: 2.0502229070150726

Epoch: 6| Step: 7
Training loss: 2.3515686988830566
Validation loss: 2.053858587818761

Epoch: 6| Step: 8
Training loss: 2.0603535175323486
Validation loss: 2.0511998361156834

Epoch: 6| Step: 9
Training loss: 1.4358421564102173
Validation loss: 2.0501769793930875

Epoch: 6| Step: 10
Training loss: 1.126237392425537
Validation loss: 2.0396737334548787

Epoch: 6| Step: 11
Training loss: 1.9580788612365723
Validation loss: 2.0392233479407524

Epoch: 6| Step: 12
Training loss: 2.1149351596832275
Validation loss: 2.061093318846918

Epoch: 6| Step: 13
Training loss: 2.6260054111480713
Validation loss: 2.0609438932070168

Epoch: 312| Step: 0
Training loss: 1.7550036907196045
Validation loss: 2.053877471595682

Epoch: 6| Step: 1
Training loss: 2.44594144821167
Validation loss: 2.051013735032851

Epoch: 6| Step: 2
Training loss: 1.9160737991333008
Validation loss: 2.051273916357307

Epoch: 6| Step: 3
Training loss: 1.793246865272522
Validation loss: 2.0453830572866623

Epoch: 6| Step: 4
Training loss: 1.8500107526779175
Validation loss: 2.0271427246832077

Epoch: 6| Step: 5
Training loss: 1.7581846714019775
Validation loss: 2.0364655627999255

Epoch: 6| Step: 6
Training loss: 1.4692790508270264
Validation loss: 2.0291267364255843

Epoch: 6| Step: 7
Training loss: 1.783123254776001
Validation loss: 2.0232789234448503

Epoch: 6| Step: 8
Training loss: 1.5906487703323364
Validation loss: 2.025042862020513

Epoch: 6| Step: 9
Training loss: 1.8324601650238037
Validation loss: 2.027477634850369

Epoch: 6| Step: 10
Training loss: 1.6568926572799683
Validation loss: 2.0383701606463362

Epoch: 6| Step: 11
Training loss: 1.635767936706543
Validation loss: 2.020257306355302

Epoch: 6| Step: 12
Training loss: 1.959312081336975
Validation loss: 2.0313596289644957

Epoch: 6| Step: 13
Training loss: 1.189870834350586
Validation loss: 2.029820162762878

Epoch: 313| Step: 0
Training loss: 2.2289180755615234
Validation loss: 2.0356831345506894

Epoch: 6| Step: 1
Training loss: 1.9775625467300415
Validation loss: 2.042168414720925

Epoch: 6| Step: 2
Training loss: 2.085982084274292
Validation loss: 2.0502434930493756

Epoch: 6| Step: 3
Training loss: 1.7142611742019653
Validation loss: 2.0453663154314925

Epoch: 6| Step: 4
Training loss: 1.453084111213684
Validation loss: 2.033123803395097

Epoch: 6| Step: 5
Training loss: 1.8615232706069946
Validation loss: 2.030024233684745

Epoch: 6| Step: 6
Training loss: 1.5739036798477173
Validation loss: 2.0319962847617363

Epoch: 6| Step: 7
Training loss: 1.474346399307251
Validation loss: 2.046187549509028

Epoch: 6| Step: 8
Training loss: 0.9495642185211182
Validation loss: 2.0483007251575427

Epoch: 6| Step: 9
Training loss: 2.0858869552612305
Validation loss: 2.0251379794971918

Epoch: 6| Step: 10
Training loss: 1.4326081275939941
Validation loss: 2.0282268543397226

Epoch: 6| Step: 11
Training loss: 2.2950191497802734
Validation loss: 2.0161095434619534

Epoch: 6| Step: 12
Training loss: 2.0332629680633545
Validation loss: 2.004878047973879

Epoch: 6| Step: 13
Training loss: 1.574657917022705
Validation loss: 2.0165386661406486

Epoch: 314| Step: 0
Training loss: 2.6693475246429443
Validation loss: 2.0122388767939743

Epoch: 6| Step: 1
Training loss: 1.5296955108642578
Validation loss: 2.0155377977637836

Epoch: 6| Step: 2
Training loss: 2.3871116638183594
Validation loss: 1.9988635099062355

Epoch: 6| Step: 3
Training loss: 1.7731354236602783
Validation loss: 2.0031229244765414

Epoch: 6| Step: 4
Training loss: 2.1076488494873047
Validation loss: 2.003011147181193

Epoch: 6| Step: 5
Training loss: 1.906251072883606
Validation loss: 2.005821639491666

Epoch: 6| Step: 6
Training loss: 0.6806442737579346
Validation loss: 2.007063488806448

Epoch: 6| Step: 7
Training loss: 1.923170566558838
Validation loss: 2.007555172007571

Epoch: 6| Step: 8
Training loss: 1.4120726585388184
Validation loss: 2.0133076047384613

Epoch: 6| Step: 9
Training loss: 1.8311383724212646
Validation loss: 2.008703518939275

Epoch: 6| Step: 10
Training loss: 1.8658570051193237
Validation loss: 2.018143441087456

Epoch: 6| Step: 11
Training loss: 1.232144832611084
Validation loss: 2.05229583350561

Epoch: 6| Step: 12
Training loss: 1.861918568611145
Validation loss: 2.0525328779733307

Epoch: 6| Step: 13
Training loss: 1.4617387056350708
Validation loss: 2.0648698755489883

Epoch: 315| Step: 0
Training loss: 1.7376751899719238
Validation loss: 2.0704056191188034

Epoch: 6| Step: 1
Training loss: 1.6377975940704346
Validation loss: 2.0475738253644717

Epoch: 6| Step: 2
Training loss: 1.7024505138397217
Validation loss: 2.0654695777482885

Epoch: 6| Step: 3
Training loss: 1.9830690622329712
Validation loss: 2.0593535695024716

Epoch: 6| Step: 4
Training loss: 1.6824181079864502
Validation loss: 2.0680961057703984

Epoch: 6| Step: 5
Training loss: 2.084766149520874
Validation loss: 2.0635992352680494

Epoch: 6| Step: 6
Training loss: 2.131169319152832
Validation loss: 2.060252869000999

Epoch: 6| Step: 7
Training loss: 1.6017487049102783
Validation loss: 2.058197182993735

Epoch: 6| Step: 8
Training loss: 1.9802193641662598
Validation loss: 2.0515536518507105

Epoch: 6| Step: 9
Training loss: 1.46394944190979
Validation loss: 2.0392823450026976

Epoch: 6| Step: 10
Training loss: 2.0558066368103027
Validation loss: 2.0288327586266304

Epoch: 6| Step: 11
Training loss: 1.4978094100952148
Validation loss: 2.020425690117703

Epoch: 6| Step: 12
Training loss: 1.6266567707061768
Validation loss: 2.026021324178224

Epoch: 6| Step: 13
Training loss: 1.5197217464447021
Validation loss: 2.0129327863775273

Epoch: 316| Step: 0
Training loss: 1.442640781402588
Validation loss: 2.010656117111124

Epoch: 6| Step: 1
Training loss: 1.270084023475647
Validation loss: 2.0154183628738567

Epoch: 6| Step: 2
Training loss: 1.7984696626663208
Validation loss: 2.0141885742064445

Epoch: 6| Step: 3
Training loss: 1.8921639919281006
Validation loss: 2.0246226736294326

Epoch: 6| Step: 4
Training loss: 1.5013787746429443
Validation loss: 2.0532542095389417

Epoch: 6| Step: 5
Training loss: 1.9499235153198242
Validation loss: 2.0560555201704784

Epoch: 6| Step: 6
Training loss: 2.2562875747680664
Validation loss: 2.0530951612739154

Epoch: 6| Step: 7
Training loss: 1.6182794570922852
Validation loss: 2.059293968703157

Epoch: 6| Step: 8
Training loss: 1.5189893245697021
Validation loss: 2.039368267982237

Epoch: 6| Step: 9
Training loss: 2.3410840034484863
Validation loss: 2.0325580258523264

Epoch: 6| Step: 10
Training loss: 1.054718255996704
Validation loss: 2.031705423067975

Epoch: 6| Step: 11
Training loss: 2.738013982772827
Validation loss: 2.029367111062491

Epoch: 6| Step: 12
Training loss: 1.5755361318588257
Validation loss: 2.0201511242056407

Epoch: 6| Step: 13
Training loss: 1.3485467433929443
Validation loss: 2.001699334831648

Epoch: 317| Step: 0
Training loss: 1.5026534795761108
Validation loss: 2.0263967462765273

Epoch: 6| Step: 1
Training loss: 1.4752870798110962
Validation loss: 2.024438965705133

Epoch: 6| Step: 2
Training loss: 1.7598496675491333
Validation loss: 2.02421373192982

Epoch: 6| Step: 3
Training loss: 2.0225014686584473
Validation loss: 2.026177619093208

Epoch: 6| Step: 4
Training loss: 1.2309097051620483
Validation loss: 2.024416217239954

Epoch: 6| Step: 5
Training loss: 1.7876999378204346
Validation loss: 2.0197582424327893

Epoch: 6| Step: 6
Training loss: 1.5813477039337158
Validation loss: 2.022715368578511

Epoch: 6| Step: 7
Training loss: 1.6943382024765015
Validation loss: 2.0228017222496772

Epoch: 6| Step: 8
Training loss: 1.5415912866592407
Validation loss: 2.0302288519438876

Epoch: 6| Step: 9
Training loss: 1.5874136686325073
Validation loss: 2.022013871900497

Epoch: 6| Step: 10
Training loss: 2.7044270038604736
Validation loss: 2.045975451828331

Epoch: 6| Step: 11
Training loss: 2.03973388671875
Validation loss: 2.021222481163599

Epoch: 6| Step: 12
Training loss: 1.7163307666778564
Validation loss: 2.0589911988986436

Epoch: 6| Step: 13
Training loss: 1.6762809753417969
Validation loss: 2.0658499169093307

Epoch: 318| Step: 0
Training loss: 2.5155887603759766
Validation loss: 2.063898353166478

Epoch: 6| Step: 1
Training loss: 1.7876619100570679
Validation loss: 2.0493950843811035

Epoch: 6| Step: 2
Training loss: 1.5548069477081299
Validation loss: 2.0706120870446645

Epoch: 6| Step: 3
Training loss: 1.6775139570236206
Validation loss: 2.0742710316053

Epoch: 6| Step: 4
Training loss: 1.3055062294006348
Validation loss: 2.03896854769799

Epoch: 6| Step: 5
Training loss: 1.3751875162124634
Validation loss: 2.0430291698824976

Epoch: 6| Step: 6
Training loss: 1.7141950130462646
Validation loss: 2.048856432719897

Epoch: 6| Step: 7
Training loss: 1.9691219329833984
Validation loss: 2.0365166894851194

Epoch: 6| Step: 8
Training loss: 1.0785549879074097
Validation loss: 2.043861130232452

Epoch: 6| Step: 9
Training loss: 1.4996039867401123
Validation loss: 2.0477408901337655

Epoch: 6| Step: 10
Training loss: 2.313915491104126
Validation loss: 2.0209463642489527

Epoch: 6| Step: 11
Training loss: 1.9882500171661377
Validation loss: 2.0250643402017574

Epoch: 6| Step: 12
Training loss: 2.0179946422576904
Validation loss: 2.008593149082635

Epoch: 6| Step: 13
Training loss: 1.68032705783844
Validation loss: 2.00150724123883

Epoch: 319| Step: 0
Training loss: 2.0799272060394287
Validation loss: 1.9998315726557085

Epoch: 6| Step: 1
Training loss: 0.9639265537261963
Validation loss: 2.0046542408645793

Epoch: 6| Step: 2
Training loss: 2.3439407348632812
Validation loss: 2.022894310694869

Epoch: 6| Step: 3
Training loss: 1.6597858667373657
Validation loss: 2.0608097430198424

Epoch: 6| Step: 4
Training loss: 1.3478796482086182
Validation loss: 2.0570575101401216

Epoch: 6| Step: 5
Training loss: 1.58314847946167
Validation loss: 2.054205407378494

Epoch: 6| Step: 6
Training loss: 1.6907175779342651
Validation loss: 2.06083821481274

Epoch: 6| Step: 7
Training loss: 1.65693998336792
Validation loss: 2.0469765099146033

Epoch: 6| Step: 8
Training loss: 1.5265438556671143
Validation loss: 2.051960106818907

Epoch: 6| Step: 9
Training loss: 1.7552998065948486
Validation loss: 2.0375377208955827

Epoch: 6| Step: 10
Training loss: 1.7087966203689575
Validation loss: 2.0382276786270963

Epoch: 6| Step: 11
Training loss: 2.0690841674804688
Validation loss: 2.0444674081699823

Epoch: 6| Step: 12
Training loss: 1.913977026939392
Validation loss: 2.029183610793083

Epoch: 6| Step: 13
Training loss: 1.9463266134262085
Validation loss: 2.032676053303544

Epoch: 320| Step: 0
Training loss: 1.264045238494873
Validation loss: 2.0136087850857805

Epoch: 6| Step: 1
Training loss: 1.6496822834014893
Validation loss: 2.0194793055134435

Epoch: 6| Step: 2
Training loss: 1.6722261905670166
Validation loss: 2.0050620725077968

Epoch: 6| Step: 3
Training loss: 2.3319108486175537
Validation loss: 1.9919599448480914

Epoch: 6| Step: 4
Training loss: 1.4024696350097656
Validation loss: 1.99728347152792

Epoch: 6| Step: 5
Training loss: 1.8697941303253174
Validation loss: 2.024903461497317

Epoch: 6| Step: 6
Training loss: 1.7458226680755615
Validation loss: 1.9924635887145996

Epoch: 6| Step: 7
Training loss: 1.8389157056808472
Validation loss: 2.008441217484013

Epoch: 6| Step: 8
Training loss: 1.9881517887115479
Validation loss: 2.0001989449224165

Epoch: 6| Step: 9
Training loss: 1.78211510181427
Validation loss: 1.9951051409526537

Epoch: 6| Step: 10
Training loss: 1.526780366897583
Validation loss: 1.9871507178070724

Epoch: 6| Step: 11
Training loss: 1.847935676574707
Validation loss: 2.0052054774376655

Epoch: 6| Step: 12
Training loss: 1.641860842704773
Validation loss: 2.0261973001623668

Epoch: 6| Step: 13
Training loss: 1.5768046379089355
Validation loss: 2.010638820227756

Epoch: 321| Step: 0
Training loss: 1.811875581741333
Validation loss: 2.0124192648036505

Epoch: 6| Step: 1
Training loss: 1.4855537414550781
Validation loss: 2.0318433776978524

Epoch: 6| Step: 2
Training loss: 1.9777352809906006
Validation loss: 2.046864366018644

Epoch: 6| Step: 3
Training loss: 1.7601778507232666
Validation loss: 2.0574452979590303

Epoch: 6| Step: 4
Training loss: 1.5131336450576782
Validation loss: 2.0629751682281494

Epoch: 6| Step: 5
Training loss: 0.9052643775939941
Validation loss: 2.0525624213680143

Epoch: 6| Step: 6
Training loss: 1.8126754760742188
Validation loss: 2.0465869390836327

Epoch: 6| Step: 7
Training loss: 1.931148886680603
Validation loss: 2.0366770118795414

Epoch: 6| Step: 8
Training loss: 1.9020187854766846
Validation loss: 2.032699456778906

Epoch: 6| Step: 9
Training loss: 1.9162472486495972
Validation loss: 2.0213185894873833

Epoch: 6| Step: 10
Training loss: 2.277400493621826
Validation loss: 2.0277768886217507

Epoch: 6| Step: 11
Training loss: 1.3683745861053467
Validation loss: 2.0106984364089144

Epoch: 6| Step: 12
Training loss: 1.7870029211044312
Validation loss: 2.0103691188238

Epoch: 6| Step: 13
Training loss: 1.74688720703125
Validation loss: 1.9987086916482577

Epoch: 322| Step: 0
Training loss: 1.632454752922058
Validation loss: 2.0017211129588466

Epoch: 6| Step: 1
Training loss: 1.649756669998169
Validation loss: 1.9961382958196825

Epoch: 6| Step: 2
Training loss: 1.816943883895874
Validation loss: 2.0060092620952155

Epoch: 6| Step: 3
Training loss: 2.6544337272644043
Validation loss: 2.011969156162713

Epoch: 6| Step: 4
Training loss: 1.4749410152435303
Validation loss: 2.014949970347907

Epoch: 6| Step: 5
Training loss: 1.5926191806793213
Validation loss: 2.020528369052436

Epoch: 6| Step: 6
Training loss: 1.909837007522583
Validation loss: 2.014491322220013

Epoch: 6| Step: 7
Training loss: 1.407397747039795
Validation loss: 2.0468806989731325

Epoch: 6| Step: 8
Training loss: 1.544034719467163
Validation loss: 2.0549830441833823

Epoch: 6| Step: 9
Training loss: 1.5525449514389038
Validation loss: 2.045868307031611

Epoch: 6| Step: 10
Training loss: 1.5993249416351318
Validation loss: 2.0367411285318355

Epoch: 6| Step: 11
Training loss: 1.8849126100540161
Validation loss: 2.0350484540385585

Epoch: 6| Step: 12
Training loss: 1.61899733543396
Validation loss: 2.022336158701169

Epoch: 6| Step: 13
Training loss: 1.9554636478424072
Validation loss: 2.0178394689354846

Epoch: 323| Step: 0
Training loss: 1.9992828369140625
Validation loss: 2.022587676202097

Epoch: 6| Step: 1
Training loss: 1.509732723236084
Validation loss: 2.0120140685830066

Epoch: 6| Step: 2
Training loss: 2.7862002849578857
Validation loss: 2.0089591523652435

Epoch: 6| Step: 3
Training loss: 1.650458574295044
Validation loss: 2.0069584256859234

Epoch: 6| Step: 4
Training loss: 1.6976909637451172
Validation loss: 1.998936842846614

Epoch: 6| Step: 5
Training loss: 2.4214024543762207
Validation loss: 2.01493432957639

Epoch: 6| Step: 6
Training loss: 1.5696160793304443
Validation loss: 1.999519807036205

Epoch: 6| Step: 7
Training loss: 1.5234379768371582
Validation loss: 2.0112992512282504

Epoch: 6| Step: 8
Training loss: 1.5493463277816772
Validation loss: 2.011160845397621

Epoch: 6| Step: 9
Training loss: 0.5956997275352478
Validation loss: 2.001664762855858

Epoch: 6| Step: 10
Training loss: 1.9079731702804565
Validation loss: 1.9864608267302155

Epoch: 6| Step: 11
Training loss: 1.799621343612671
Validation loss: 1.992134149356555

Epoch: 6| Step: 12
Training loss: 1.5475335121154785
Validation loss: 2.0012158796351445

Epoch: 6| Step: 13
Training loss: 1.1620186567306519
Validation loss: 2.0206249093496673

Epoch: 324| Step: 0
Training loss: 1.5865501165390015
Validation loss: 2.02951983738971

Epoch: 6| Step: 1
Training loss: 1.578270435333252
Validation loss: 2.0542582799029607

Epoch: 6| Step: 2
Training loss: 1.102229356765747
Validation loss: 2.058026591936747

Epoch: 6| Step: 3
Training loss: 2.184429883956909
Validation loss: 2.0577636213712793

Epoch: 6| Step: 4
Training loss: 2.092512607574463
Validation loss: 2.0682475489954792

Epoch: 6| Step: 5
Training loss: 1.6639037132263184
Validation loss: 2.0577472512440016

Epoch: 6| Step: 6
Training loss: 2.0178985595703125
Validation loss: 2.03412204147667

Epoch: 6| Step: 7
Training loss: 1.9309542179107666
Validation loss: 2.01290863303728

Epoch: 6| Step: 8
Training loss: 1.0148684978485107
Validation loss: 2.021068008997107

Epoch: 6| Step: 9
Training loss: 1.808061122894287
Validation loss: 2.014235335011636

Epoch: 6| Step: 10
Training loss: 1.2360398769378662
Validation loss: 1.9976201057434082

Epoch: 6| Step: 11
Training loss: 2.4974944591522217
Validation loss: 2.031772880144017

Epoch: 6| Step: 12
Training loss: 1.9988598823547363
Validation loss: 2.0118625292214016

Epoch: 6| Step: 13
Training loss: 0.8633082509040833
Validation loss: 2.0032152155394196

Epoch: 325| Step: 0
Training loss: 1.0893304347991943
Validation loss: 2.018284951486895

Epoch: 6| Step: 1
Training loss: 2.327345371246338
Validation loss: 2.0154373825237317

Epoch: 6| Step: 2
Training loss: 1.3243159055709839
Validation loss: 2.005224984179261

Epoch: 6| Step: 3
Training loss: 1.5610523223876953
Validation loss: 2.0177283620321624

Epoch: 6| Step: 4
Training loss: 1.5338491201400757
Validation loss: 2.013902853893977

Epoch: 6| Step: 5
Training loss: 1.2819143533706665
Validation loss: 2.010150927369313

Epoch: 6| Step: 6
Training loss: 1.7573442459106445
Validation loss: 1.9920799065661687

Epoch: 6| Step: 7
Training loss: 1.6594520807266235
Validation loss: 2.0112384134723293

Epoch: 6| Step: 8
Training loss: 2.0381522178649902
Validation loss: 2.0033018947929464

Epoch: 6| Step: 9
Training loss: 1.8427653312683105
Validation loss: 1.999209612928411

Epoch: 6| Step: 10
Training loss: 1.6448560953140259
Validation loss: 1.98900471707826

Epoch: 6| Step: 11
Training loss: 1.4551950693130493
Validation loss: 2.0017369549761534

Epoch: 6| Step: 12
Training loss: 2.4813218116760254
Validation loss: 2.006029593047275

Epoch: 6| Step: 13
Training loss: 1.6300199031829834
Validation loss: 2.0091107147996143

Epoch: 326| Step: 0
Training loss: 1.7150967121124268
Validation loss: 2.015755534172058

Epoch: 6| Step: 1
Training loss: 1.783782720565796
Validation loss: 2.0194866823893722

Epoch: 6| Step: 2
Training loss: 1.7341945171356201
Validation loss: 1.9965687003186954

Epoch: 6| Step: 3
Training loss: 1.2538890838623047
Validation loss: 2.0119331729027534

Epoch: 6| Step: 4
Training loss: 2.1459531784057617
Validation loss: 2.0249938541843044

Epoch: 6| Step: 5
Training loss: 0.8107007741928101
Validation loss: 2.0262140689357633

Epoch: 6| Step: 6
Training loss: 2.089580774307251
Validation loss: 2.032369509820015

Epoch: 6| Step: 7
Training loss: 1.7279876470565796
Validation loss: 2.032796480322397

Epoch: 6| Step: 8
Training loss: 1.9401285648345947
Validation loss: 2.0369361267294934

Epoch: 6| Step: 9
Training loss: 1.4536712169647217
Validation loss: 2.025364141310415

Epoch: 6| Step: 10
Training loss: 1.9867230653762817
Validation loss: 2.024037779018443

Epoch: 6| Step: 11
Training loss: 1.9914108514785767
Validation loss: 2.050793255529096

Epoch: 6| Step: 12
Training loss: 1.4319977760314941
Validation loss: 2.0373580404507217

Epoch: 6| Step: 13
Training loss: 1.1617577075958252
Validation loss: 2.0291859757515693

Epoch: 327| Step: 0
Training loss: 1.1597263813018799
Validation loss: 2.0367592483438473

Epoch: 6| Step: 1
Training loss: 2.2939352989196777
Validation loss: 2.0249708929369525

Epoch: 6| Step: 2
Training loss: 1.9335440397262573
Validation loss: 2.024501186545177

Epoch: 6| Step: 3
Training loss: 1.3058240413665771
Validation loss: 2.012026568894745

Epoch: 6| Step: 4
Training loss: 1.419425368309021
Validation loss: 2.0259192733354467

Epoch: 6| Step: 5
Training loss: 1.8255784511566162
Validation loss: 2.014841930840605

Epoch: 6| Step: 6
Training loss: 1.3928769826889038
Validation loss: 2.002437812025829

Epoch: 6| Step: 7
Training loss: 1.4926378726959229
Validation loss: 2.0262740119811027

Epoch: 6| Step: 8
Training loss: 1.7566746473312378
Validation loss: 2.0195046958102973

Epoch: 6| Step: 9
Training loss: 1.6262390613555908
Validation loss: 2.0241513739350023

Epoch: 6| Step: 10
Training loss: 1.2446331977844238
Validation loss: 2.031952658007222

Epoch: 6| Step: 11
Training loss: 2.0481252670288086
Validation loss: 2.000323518629997

Epoch: 6| Step: 12
Training loss: 2.151613712310791
Validation loss: 2.000867386018076

Epoch: 6| Step: 13
Training loss: 1.8990974426269531
Validation loss: 2.0078463157018027

Epoch: 328| Step: 0
Training loss: 1.5437790155410767
Validation loss: 2.0071019946887927

Epoch: 6| Step: 1
Training loss: 2.396820306777954
Validation loss: 2.007281605915357

Epoch: 6| Step: 2
Training loss: 1.38062584400177
Validation loss: 2.011002885398044

Epoch: 6| Step: 3
Training loss: 1.808363676071167
Validation loss: 1.9932263948584115

Epoch: 6| Step: 4
Training loss: 1.62912118434906
Validation loss: 2.015185538158622

Epoch: 6| Step: 5
Training loss: 1.9129761457443237
Validation loss: 2.0098645007738503

Epoch: 6| Step: 6
Training loss: 1.876252293586731
Validation loss: 2.0172681962290118

Epoch: 6| Step: 7
Training loss: 1.3362393379211426
Validation loss: 2.020791656227522

Epoch: 6| Step: 8
Training loss: 1.805321216583252
Validation loss: 2.0106170779915264

Epoch: 6| Step: 9
Training loss: 1.2140421867370605
Validation loss: 2.020953316842356

Epoch: 6| Step: 10
Training loss: 1.3536765575408936
Validation loss: 2.02995268888371

Epoch: 6| Step: 11
Training loss: 1.278062343597412
Validation loss: 2.0151452133732457

Epoch: 6| Step: 12
Training loss: 2.0578980445861816
Validation loss: 2.0384872177595734

Epoch: 6| Step: 13
Training loss: 1.7938847541809082
Validation loss: 2.0404052683102187

Epoch: 329| Step: 0
Training loss: 1.4727296829223633
Validation loss: 2.058600523138559

Epoch: 6| Step: 1
Training loss: 1.2610259056091309
Validation loss: 2.02890948582721

Epoch: 6| Step: 2
Training loss: 1.3337552547454834
Validation loss: 2.0474481018640662

Epoch: 6| Step: 3
Training loss: 1.6023266315460205
Validation loss: 2.058996210816086

Epoch: 6| Step: 4
Training loss: 1.3019224405288696
Validation loss: 2.046499747101979

Epoch: 6| Step: 5
Training loss: 2.0765717029571533
Validation loss: 2.04407250496649

Epoch: 6| Step: 6
Training loss: 1.1934995651245117
Validation loss: 2.03530179813344

Epoch: 6| Step: 7
Training loss: 1.6026427745819092
Validation loss: 2.033308479093736

Epoch: 6| Step: 8
Training loss: 2.1392908096313477
Validation loss: 2.0271897879979943

Epoch: 6| Step: 9
Training loss: 1.670116901397705
Validation loss: 2.0341815666485856

Epoch: 6| Step: 10
Training loss: 1.8348875045776367
Validation loss: 2.008625752182417

Epoch: 6| Step: 11
Training loss: 2.7141916751861572
Validation loss: 2.008647862301078

Epoch: 6| Step: 12
Training loss: 1.2994873523712158
Validation loss: 2.0061484895726687

Epoch: 6| Step: 13
Training loss: 1.8336105346679688
Validation loss: 1.9886341658971642

Epoch: 330| Step: 0
Training loss: 1.7322888374328613
Validation loss: 1.9812662986017042

Epoch: 6| Step: 1
Training loss: 1.517791509628296
Validation loss: 1.9665229679435812

Epoch: 6| Step: 2
Training loss: 1.9684135913848877
Validation loss: 1.9558865613834833

Epoch: 6| Step: 3
Training loss: 1.1798986196517944
Validation loss: 1.9510432879130046

Epoch: 6| Step: 4
Training loss: 2.322533130645752
Validation loss: 1.9579318569552513

Epoch: 6| Step: 5
Training loss: 1.9244232177734375
Validation loss: 1.9511955040757374

Epoch: 6| Step: 6
Training loss: 1.7305610179901123
Validation loss: 1.9691182208317581

Epoch: 6| Step: 7
Training loss: 1.0296533107757568
Validation loss: 1.9648589677708124

Epoch: 6| Step: 8
Training loss: 1.367250919342041
Validation loss: 1.9604847277364423

Epoch: 6| Step: 9
Training loss: 1.9865500926971436
Validation loss: 1.9718740108192607

Epoch: 6| Step: 10
Training loss: 1.4068739414215088
Validation loss: 1.9917564750999532

Epoch: 6| Step: 11
Training loss: 1.8145782947540283
Validation loss: 1.99218967781272

Epoch: 6| Step: 12
Training loss: 1.6299951076507568
Validation loss: 2.0143211733910347

Epoch: 6| Step: 13
Training loss: 1.9320530891418457
Validation loss: 2.0428540809180147

Epoch: 331| Step: 0
Training loss: 1.8141330480575562
Validation loss: 2.0482267372069822

Epoch: 6| Step: 1
Training loss: 1.3366143703460693
Validation loss: 2.0500139023668025

Epoch: 6| Step: 2
Training loss: 1.552042007446289
Validation loss: 2.017932450899514

Epoch: 6| Step: 3
Training loss: 1.5042481422424316
Validation loss: 2.0263807491589616

Epoch: 6| Step: 4
Training loss: 2.215773105621338
Validation loss: 2.007513503874502

Epoch: 6| Step: 5
Training loss: 1.521775484085083
Validation loss: 2.0199673970540366

Epoch: 6| Step: 6
Training loss: 2.128805160522461
Validation loss: 2.0030638453780965

Epoch: 6| Step: 7
Training loss: 1.4811148643493652
Validation loss: 1.9952103066188034

Epoch: 6| Step: 8
Training loss: 1.799459457397461
Validation loss: 1.9925913874820997

Epoch: 6| Step: 9
Training loss: 1.4543931484222412
Validation loss: 1.9970754295267084

Epoch: 6| Step: 10
Training loss: 1.9689767360687256
Validation loss: 2.0035966878296225

Epoch: 6| Step: 11
Training loss: 1.5883113145828247
Validation loss: 2.001744874062077

Epoch: 6| Step: 12
Training loss: 1.4168422222137451
Validation loss: 2.01425753870318

Epoch: 6| Step: 13
Training loss: 1.212024211883545
Validation loss: 2.010618434157423

Epoch: 332| Step: 0
Training loss: 2.1465678215026855
Validation loss: 2.037212546153735

Epoch: 6| Step: 1
Training loss: 2.203784942626953
Validation loss: 2.04961875818109

Epoch: 6| Step: 2
Training loss: 1.7603590488433838
Validation loss: 2.095721662685435

Epoch: 6| Step: 3
Training loss: 2.1378536224365234
Validation loss: 2.097572524060485

Epoch: 6| Step: 4
Training loss: 1.4505877494812012
Validation loss: 2.082202672958374

Epoch: 6| Step: 5
Training loss: 1.552108883857727
Validation loss: 2.060729765122937

Epoch: 6| Step: 6
Training loss: 1.5370640754699707
Validation loss: 2.0685958400849374

Epoch: 6| Step: 7
Training loss: 1.4291131496429443
Validation loss: 2.0614274496673257

Epoch: 6| Step: 8
Training loss: 1.5532071590423584
Validation loss: 2.030102550342519

Epoch: 6| Step: 9
Training loss: 1.3106439113616943
Validation loss: 2.053439388992966

Epoch: 6| Step: 10
Training loss: 1.369690179824829
Validation loss: 2.031398096392232

Epoch: 6| Step: 11
Training loss: 1.4529201984405518
Validation loss: 2.009863051035071

Epoch: 6| Step: 12
Training loss: 1.5680288076400757
Validation loss: 1.994209010113952

Epoch: 6| Step: 13
Training loss: 2.2001399993896484
Validation loss: 1.96885992762863

Epoch: 333| Step: 0
Training loss: 1.7693586349487305
Validation loss: 1.9943623658149474

Epoch: 6| Step: 1
Training loss: 1.3247987031936646
Validation loss: 1.9947257118840371

Epoch: 6| Step: 2
Training loss: 2.2757630348205566
Validation loss: 2.0133108708166305

Epoch: 6| Step: 3
Training loss: 1.653164267539978
Validation loss: 2.001859875135524

Epoch: 6| Step: 4
Training loss: 1.3080620765686035
Validation loss: 2.0087823508888163

Epoch: 6| Step: 5
Training loss: 1.093721866607666
Validation loss: 2.0087814869419223

Epoch: 6| Step: 6
Training loss: 1.7589737176895142
Validation loss: 1.9950228942337858

Epoch: 6| Step: 7
Training loss: 2.0655903816223145
Validation loss: 1.990299351753727

Epoch: 6| Step: 8
Training loss: 1.6963058710098267
Validation loss: 1.9904997887149933

Epoch: 6| Step: 9
Training loss: 1.811631202697754
Validation loss: 1.997078025212852

Epoch: 6| Step: 10
Training loss: 1.1947441101074219
Validation loss: 2.0007348752790883

Epoch: 6| Step: 11
Training loss: 2.220412254333496
Validation loss: 1.9984398554730158

Epoch: 6| Step: 12
Training loss: 1.6586099863052368
Validation loss: 2.013513770154727

Epoch: 6| Step: 13
Training loss: 1.2783879041671753
Validation loss: 2.0194879142186974

Epoch: 334| Step: 0
Training loss: 2.1882266998291016
Validation loss: 2.0142222745444185

Epoch: 6| Step: 1
Training loss: 1.244206428527832
Validation loss: 1.9980450650697112

Epoch: 6| Step: 2
Training loss: 1.4511041641235352
Validation loss: 2.0119772213761524

Epoch: 6| Step: 3
Training loss: 1.3357656002044678
Validation loss: 2.0268008375680573

Epoch: 6| Step: 4
Training loss: 1.5537365674972534
Validation loss: 2.0334427459265596

Epoch: 6| Step: 5
Training loss: 1.4523587226867676
Validation loss: 2.031075258408823

Epoch: 6| Step: 6
Training loss: 1.712573528289795
Validation loss: 2.047416106347115

Epoch: 6| Step: 7
Training loss: 1.248795509338379
Validation loss: 2.0398396484313475

Epoch: 6| Step: 8
Training loss: 1.4860000610351562
Validation loss: 2.0486755576185

Epoch: 6| Step: 9
Training loss: 1.766963005065918
Validation loss: 2.0516250287332842

Epoch: 6| Step: 10
Training loss: 1.842613935470581
Validation loss: 2.026507500679262

Epoch: 6| Step: 11
Training loss: 1.5100878477096558
Validation loss: 2.0216807755090858

Epoch: 6| Step: 12
Training loss: 1.9416418075561523
Validation loss: 2.030280508020873

Epoch: 6| Step: 13
Training loss: 2.76358699798584
Validation loss: 2.026354169332853

Epoch: 335| Step: 0
Training loss: 1.5770130157470703
Validation loss: 2.0348340772813365

Epoch: 6| Step: 1
Training loss: 1.832425832748413
Validation loss: 2.020449189729588

Epoch: 6| Step: 2
Training loss: 1.1820663213729858
Validation loss: 2.0222668083765174

Epoch: 6| Step: 3
Training loss: 1.2794764041900635
Validation loss: 1.9987546936158211

Epoch: 6| Step: 4
Training loss: 1.8964805603027344
Validation loss: 2.004866146272229

Epoch: 6| Step: 5
Training loss: 2.0783281326293945
Validation loss: 1.9898155658475813

Epoch: 6| Step: 6
Training loss: 1.0719923973083496
Validation loss: 2.00570071640835

Epoch: 6| Step: 7
Training loss: 1.4080936908721924
Validation loss: 2.0117127280081473

Epoch: 6| Step: 8
Training loss: 2.060824155807495
Validation loss: 2.010562740346437

Epoch: 6| Step: 9
Training loss: 1.2837064266204834
Validation loss: 2.0259616182696436

Epoch: 6| Step: 10
Training loss: 2.1051409244537354
Validation loss: 2.0114952466821157

Epoch: 6| Step: 11
Training loss: 1.605194091796875
Validation loss: 2.009162833613734

Epoch: 6| Step: 12
Training loss: 1.7023601531982422
Validation loss: 2.004510136060817

Epoch: 6| Step: 13
Training loss: 2.15366530418396
Validation loss: 2.0026405421636437

Epoch: 336| Step: 0
Training loss: 1.24397611618042
Validation loss: 2.003952072512719

Epoch: 6| Step: 1
Training loss: 1.1028928756713867
Validation loss: 2.011594082719536

Epoch: 6| Step: 2
Training loss: 1.6706528663635254
Validation loss: 2.016909614686043

Epoch: 6| Step: 3
Training loss: 1.1188451051712036
Validation loss: 2.04181404523952

Epoch: 6| Step: 4
Training loss: 1.3909213542938232
Validation loss: 2.044118244160888

Epoch: 6| Step: 5
Training loss: 2.068495273590088
Validation loss: 2.069276281582412

Epoch: 6| Step: 6
Training loss: 1.7373700141906738
Validation loss: 2.0811408924800094

Epoch: 6| Step: 7
Training loss: 1.459282636642456
Validation loss: 2.0807391392287387

Epoch: 6| Step: 8
Training loss: 1.8609464168548584
Validation loss: 2.0959171364384312

Epoch: 6| Step: 9
Training loss: 1.562872290611267
Validation loss: 2.0740646367431967

Epoch: 6| Step: 10
Training loss: 2.614344596862793
Validation loss: 2.0754843373452463

Epoch: 6| Step: 11
Training loss: 1.6797419786453247
Validation loss: 2.050813897963493

Epoch: 6| Step: 12
Training loss: 1.9506912231445312
Validation loss: 2.056689344426637

Epoch: 6| Step: 13
Training loss: 1.1406468152999878
Validation loss: 2.010821609086888

Epoch: 337| Step: 0
Training loss: 1.5686700344085693
Validation loss: 2.016234210742417

Epoch: 6| Step: 1
Training loss: 1.7096343040466309
Validation loss: 2.0127397814104633

Epoch: 6| Step: 2
Training loss: 1.6988743543624878
Validation loss: 1.9887120672451553

Epoch: 6| Step: 3
Training loss: 1.1771676540374756
Validation loss: 1.991855429064843

Epoch: 6| Step: 4
Training loss: 0.783974289894104
Validation loss: 1.9775764839623564

Epoch: 6| Step: 5
Training loss: 1.6807799339294434
Validation loss: 1.9811375128325595

Epoch: 6| Step: 6
Training loss: 2.2008347511291504
Validation loss: 1.9848100126430552

Epoch: 6| Step: 7
Training loss: 2.4279329776763916
Validation loss: 1.9863477650509085

Epoch: 6| Step: 8
Training loss: 1.8067708015441895
Validation loss: 2.002072065107284

Epoch: 6| Step: 9
Training loss: 1.2017505168914795
Validation loss: 1.9846989493216238

Epoch: 6| Step: 10
Training loss: 1.4158381223678589
Validation loss: 1.98997849546453

Epoch: 6| Step: 11
Training loss: 2.2662973403930664
Validation loss: 2.006773817923761

Epoch: 6| Step: 12
Training loss: 1.096994161605835
Validation loss: 2.002601253089084

Epoch: 6| Step: 13
Training loss: 1.7413910627365112
Validation loss: 2.019045829772949

Epoch: 338| Step: 0
Training loss: 1.9547786712646484
Validation loss: 2.0143214477005826

Epoch: 6| Step: 1
Training loss: 1.5774378776550293
Validation loss: 2.0336373429144583

Epoch: 6| Step: 2
Training loss: 1.890631079673767
Validation loss: 2.029374755838866

Epoch: 6| Step: 3
Training loss: 2.054684638977051
Validation loss: 2.03537844586116

Epoch: 6| Step: 4
Training loss: 1.2148619890213013
Validation loss: 2.0505474100830736

Epoch: 6| Step: 5
Training loss: 2.2073440551757812
Validation loss: 2.035324440207533

Epoch: 6| Step: 6
Training loss: 1.550368309020996
Validation loss: 2.0197179599474837

Epoch: 6| Step: 7
Training loss: 1.0936040878295898
Validation loss: 2.024567473319269

Epoch: 6| Step: 8
Training loss: 1.6045061349868774
Validation loss: 1.995135207330027

Epoch: 6| Step: 9
Training loss: 1.7817513942718506
Validation loss: 2.007539972182243

Epoch: 6| Step: 10
Training loss: 1.4713122844696045
Validation loss: 1.9953344124619679

Epoch: 6| Step: 11
Training loss: 1.318158507347107
Validation loss: 1.9913671016693115

Epoch: 6| Step: 12
Training loss: 0.9958456754684448
Validation loss: 1.99248856113803

Epoch: 6| Step: 13
Training loss: 1.9718748331069946
Validation loss: 1.9737897380705802

Epoch: 339| Step: 0
Training loss: 0.8898944854736328
Validation loss: 1.9844250755925332

Epoch: 6| Step: 1
Training loss: 1.6648606061935425
Validation loss: 1.989885058454288

Epoch: 6| Step: 2
Training loss: 1.7717528343200684
Validation loss: 1.982951255254848

Epoch: 6| Step: 3
Training loss: 1.3950947523117065
Validation loss: 1.997055890739605

Epoch: 6| Step: 4
Training loss: 2.2658352851867676
Validation loss: 1.9990814603785032

Epoch: 6| Step: 5
Training loss: 0.6979042291641235
Validation loss: 2.001495079327655

Epoch: 6| Step: 6
Training loss: 2.2543210983276367
Validation loss: 2.0189026145524878

Epoch: 6| Step: 7
Training loss: 1.4675625562667847
Validation loss: 2.032523544885779

Epoch: 6| Step: 8
Training loss: 1.6757776737213135
Validation loss: 2.0280795302442325

Epoch: 6| Step: 9
Training loss: 1.1923017501831055
Validation loss: 2.022671507250878

Epoch: 6| Step: 10
Training loss: 2.3382794857025146
Validation loss: 2.0294336952188963

Epoch: 6| Step: 11
Training loss: 1.3462587594985962
Validation loss: 2.027274094602113

Epoch: 6| Step: 12
Training loss: 1.942529559135437
Validation loss: 2.040254733895743

Epoch: 6| Step: 13
Training loss: 1.6464518308639526
Validation loss: 2.0200823096818823

Epoch: 340| Step: 0
Training loss: 1.155644416809082
Validation loss: 2.0123701326308714

Epoch: 6| Step: 1
Training loss: 2.0458645820617676
Validation loss: 2.0137755447818386

Epoch: 6| Step: 2
Training loss: 1.386211633682251
Validation loss: 1.9910625334708922

Epoch: 6| Step: 3
Training loss: 1.7079060077667236
Validation loss: 1.9879613025214082

Epoch: 6| Step: 4
Training loss: 1.7821794748306274
Validation loss: 2.001810271252868

Epoch: 6| Step: 5
Training loss: 1.5668143033981323
Validation loss: 1.9978155051508257

Epoch: 6| Step: 6
Training loss: 1.3774683475494385
Validation loss: 1.9897906677697295

Epoch: 6| Step: 7
Training loss: 1.2904407978057861
Validation loss: 2.0078319426505797

Epoch: 6| Step: 8
Training loss: 1.6086136102676392
Validation loss: 2.020899852116903

Epoch: 6| Step: 9
Training loss: 2.089837074279785
Validation loss: 2.015959305147971

Epoch: 6| Step: 10
Training loss: 1.0599831342697144
Validation loss: 2.002537751710543

Epoch: 6| Step: 11
Training loss: 1.8406808376312256
Validation loss: 1.9985155725991854

Epoch: 6| Step: 12
Training loss: 1.9414622783660889
Validation loss: 1.9943981926928285

Epoch: 6| Step: 13
Training loss: 1.3382803201675415
Validation loss: 1.9816545491577477

Epoch: 341| Step: 0
Training loss: 1.7538790702819824
Validation loss: 1.9863440734083935

Epoch: 6| Step: 1
Training loss: 1.5656943321228027
Validation loss: 1.9970562714402393

Epoch: 6| Step: 2
Training loss: 1.6903893947601318
Validation loss: 1.9994795117326962

Epoch: 6| Step: 3
Training loss: 1.295846939086914
Validation loss: 1.9994515372860817

Epoch: 6| Step: 4
Training loss: 1.2035268545150757
Validation loss: 2.0073162060911938

Epoch: 6| Step: 5
Training loss: 2.0701422691345215
Validation loss: 1.9876920920546337

Epoch: 6| Step: 6
Training loss: 1.666568636894226
Validation loss: 2.0168264450565463

Epoch: 6| Step: 7
Training loss: 0.9293333888053894
Validation loss: 2.002850878623224

Epoch: 6| Step: 8
Training loss: 2.080293655395508
Validation loss: 2.034197950875887

Epoch: 6| Step: 9
Training loss: 2.0597496032714844
Validation loss: 2.0391921535615

Epoch: 6| Step: 10
Training loss: 1.7858033180236816
Validation loss: 2.0503537167784986

Epoch: 6| Step: 11
Training loss: 1.3358138799667358
Validation loss: 2.042887233918713

Epoch: 6| Step: 12
Training loss: 1.4008692502975464
Validation loss: 2.0281442493520756

Epoch: 6| Step: 13
Training loss: 1.499306559562683
Validation loss: 2.0048965023409937

Epoch: 342| Step: 0
Training loss: 1.3000340461730957
Validation loss: 2.000676570400115

Epoch: 6| Step: 1
Training loss: 2.056295394897461
Validation loss: 2.005869560344245

Epoch: 6| Step: 2
Training loss: 1.998556137084961
Validation loss: 2.019522246494088

Epoch: 6| Step: 3
Training loss: 2.217618942260742
Validation loss: 1.9877142496006464

Epoch: 6| Step: 4
Training loss: 1.7487163543701172
Validation loss: 1.9768972717305666

Epoch: 6| Step: 5
Training loss: 1.1922416687011719
Validation loss: 1.9721860513892224

Epoch: 6| Step: 6
Training loss: 1.970790147781372
Validation loss: 1.9856264052852508

Epoch: 6| Step: 7
Training loss: 1.1002452373504639
Validation loss: 1.9907174828231975

Epoch: 6| Step: 8
Training loss: 1.3106236457824707
Validation loss: 2.008136413430655

Epoch: 6| Step: 9
Training loss: 1.6488908529281616
Validation loss: 2.001569148032896

Epoch: 6| Step: 10
Training loss: 0.9494706988334656
Validation loss: 2.030129213486948

Epoch: 6| Step: 11
Training loss: 1.652540683746338
Validation loss: 2.02987317885122

Epoch: 6| Step: 12
Training loss: 1.3282757997512817
Validation loss: 2.0506550304351316

Epoch: 6| Step: 13
Training loss: 1.8222416639328003
Validation loss: 2.0542691189755677

Epoch: 343| Step: 0
Training loss: 2.0123469829559326
Validation loss: 2.039222709594234

Epoch: 6| Step: 1
Training loss: 1.2540069818496704
Validation loss: 2.0499556154333134

Epoch: 6| Step: 2
Training loss: 1.0457872152328491
Validation loss: 2.0489302886429654

Epoch: 6| Step: 3
Training loss: 1.7088723182678223
Validation loss: 2.0523363826095418

Epoch: 6| Step: 4
Training loss: 1.5576575994491577
Validation loss: 2.043787722946495

Epoch: 6| Step: 5
Training loss: 1.2892436981201172
Validation loss: 2.0373944082567768

Epoch: 6| Step: 6
Training loss: 1.3224687576293945
Validation loss: 2.0456242689522366

Epoch: 6| Step: 7
Training loss: 1.3345181941986084
Validation loss: 2.0275962096388622

Epoch: 6| Step: 8
Training loss: 1.8725340366363525
Validation loss: 2.020968250049058

Epoch: 6| Step: 9
Training loss: 2.0370306968688965
Validation loss: 2.0016882547768216

Epoch: 6| Step: 10
Training loss: 1.2568204402923584
Validation loss: 2.004077396085185

Epoch: 6| Step: 11
Training loss: 1.6147956848144531
Validation loss: 1.997833567280923

Epoch: 6| Step: 12
Training loss: 2.116663932800293
Validation loss: 1.9851629541766258

Epoch: 6| Step: 13
Training loss: 1.777323603630066
Validation loss: 1.964000331458225

Epoch: 344| Step: 0
Training loss: 1.7167799472808838
Validation loss: 1.979350987301078

Epoch: 6| Step: 1
Training loss: 1.199453353881836
Validation loss: 1.9800208076353996

Epoch: 6| Step: 2
Training loss: 1.5793426036834717
Validation loss: 1.9735776416717037

Epoch: 6| Step: 3
Training loss: 1.3080918788909912
Validation loss: 1.9950553960697626

Epoch: 6| Step: 4
Training loss: 1.5018179416656494
Validation loss: 1.9949510584595382

Epoch: 6| Step: 5
Training loss: 1.3544564247131348
Validation loss: 1.9878276342986732

Epoch: 6| Step: 6
Training loss: 1.8858449459075928
Validation loss: 2.007222460162255

Epoch: 6| Step: 7
Training loss: 1.9567956924438477
Validation loss: 2.03029905339723

Epoch: 6| Step: 8
Training loss: 2.1151585578918457
Validation loss: 2.0396259318115892

Epoch: 6| Step: 9
Training loss: 1.266850471496582
Validation loss: 2.0434005004103466

Epoch: 6| Step: 10
Training loss: 1.5313904285430908
Validation loss: 2.051370992455431

Epoch: 6| Step: 11
Training loss: 1.8643310070037842
Validation loss: 2.0857537869484193

Epoch: 6| Step: 12
Training loss: 1.4640007019042969
Validation loss: 2.063710635708224

Epoch: 6| Step: 13
Training loss: 0.9543530941009521
Validation loss: 2.0502294378895916

Epoch: 345| Step: 0
Training loss: 1.7855534553527832
Validation loss: 2.0437057607917377

Epoch: 6| Step: 1
Training loss: 2.0431246757507324
Validation loss: 2.0524321909873717

Epoch: 6| Step: 2
Training loss: 1.779179334640503
Validation loss: 2.039425371795572

Epoch: 6| Step: 3
Training loss: 2.05645489692688
Validation loss: 2.037230932584373

Epoch: 6| Step: 4
Training loss: 1.1310622692108154
Validation loss: 2.0090411529746106

Epoch: 6| Step: 5
Training loss: 1.4575982093811035
Validation loss: 1.9937378155287875

Epoch: 6| Step: 6
Training loss: 1.9190300703048706
Validation loss: 1.9911641792584491

Epoch: 6| Step: 7
Training loss: 0.9652045965194702
Validation loss: 1.9995205748465754

Epoch: 6| Step: 8
Training loss: 1.4530022144317627
Validation loss: 1.991470351014086

Epoch: 6| Step: 9
Training loss: 1.1206737756729126
Validation loss: 1.9967558025031962

Epoch: 6| Step: 10
Training loss: 1.334538221359253
Validation loss: 1.9882783915406914

Epoch: 6| Step: 11
Training loss: 1.8631625175476074
Validation loss: 1.9953309182197816

Epoch: 6| Step: 12
Training loss: 1.6598470211029053
Validation loss: 1.9864591680547243

Epoch: 6| Step: 13
Training loss: 0.8757143020629883
Validation loss: 2.0075366445766982

Epoch: 346| Step: 0
Training loss: 1.5419658422470093
Validation loss: 1.9853671699441888

Epoch: 6| Step: 1
Training loss: 0.9834654927253723
Validation loss: 2.0042999867470033

Epoch: 6| Step: 2
Training loss: 1.4544322490692139
Validation loss: 2.0090900774924987

Epoch: 6| Step: 3
Training loss: 1.765212059020996
Validation loss: 2.0336388772533787

Epoch: 6| Step: 4
Training loss: 1.59182870388031
Validation loss: 2.037681028407107

Epoch: 6| Step: 5
Training loss: 1.6170486211776733
Validation loss: 2.0215062300364175

Epoch: 6| Step: 6
Training loss: 2.0603256225585938
Validation loss: 2.040878129261796

Epoch: 6| Step: 7
Training loss: 1.7533581256866455
Validation loss: 2.0171509737609536

Epoch: 6| Step: 8
Training loss: 0.964839518070221
Validation loss: 2.0239415155944003

Epoch: 6| Step: 9
Training loss: 1.6870217323303223
Validation loss: 2.0151898950658818

Epoch: 6| Step: 10
Training loss: 1.0144507884979248
Validation loss: 2.0360248806656047

Epoch: 6| Step: 11
Training loss: 1.6336333751678467
Validation loss: 2.0329676751167542

Epoch: 6| Step: 12
Training loss: 2.22086501121521
Validation loss: 2.0388398785744943

Epoch: 6| Step: 13
Training loss: 1.2731009721755981
Validation loss: 2.0511469943549043

Epoch: 347| Step: 0
Training loss: 0.9963740110397339
Validation loss: 2.0222596532555035

Epoch: 6| Step: 1
Training loss: 1.6200065612792969
Validation loss: 1.9978694364588747

Epoch: 6| Step: 2
Training loss: 1.647079348564148
Validation loss: 2.030366207963677

Epoch: 6| Step: 3
Training loss: 1.9404833316802979
Validation loss: 2.016514516645862

Epoch: 6| Step: 4
Training loss: 1.517359972000122
Validation loss: 2.0202679095729703

Epoch: 6| Step: 5
Training loss: 1.5242290496826172
Validation loss: 2.005758936687182

Epoch: 6| Step: 6
Training loss: 1.7362337112426758
Validation loss: 1.9885282208842616

Epoch: 6| Step: 7
Training loss: 1.3859837055206299
Validation loss: 1.9845846827312181

Epoch: 6| Step: 8
Training loss: 1.6958035230636597
Validation loss: 1.9882740230970486

Epoch: 6| Step: 9
Training loss: 1.4222407341003418
Validation loss: 1.9846459921970163

Epoch: 6| Step: 10
Training loss: 1.5488808155059814
Validation loss: 1.9843854904174805

Epoch: 6| Step: 11
Training loss: 0.9685045480728149
Validation loss: 1.9678115895999375

Epoch: 6| Step: 12
Training loss: 2.1928675174713135
Validation loss: 1.9909861382617746

Epoch: 6| Step: 13
Training loss: 1.1952054500579834
Validation loss: 2.0100018773027646

Epoch: 348| Step: 0
Training loss: 1.4483948945999146
Validation loss: 2.005180876742127

Epoch: 6| Step: 1
Training loss: 1.6769129037857056
Validation loss: 2.023102407814354

Epoch: 6| Step: 2
Training loss: 2.126757860183716
Validation loss: 2.0431090721520047

Epoch: 6| Step: 3
Training loss: 1.7427878379821777
Validation loss: 2.070421134271929

Epoch: 6| Step: 4
Training loss: 1.6276514530181885
Validation loss: 2.068320389716856

Epoch: 6| Step: 5
Training loss: 1.5344021320343018
Validation loss: 2.0800113754887737

Epoch: 6| Step: 6
Training loss: 1.8198033571243286
Validation loss: 2.080512576205756

Epoch: 6| Step: 7
Training loss: 1.4803849458694458
Validation loss: 2.080654159668953

Epoch: 6| Step: 8
Training loss: 1.1289238929748535
Validation loss: 2.0649204536150862

Epoch: 6| Step: 9
Training loss: 1.6092302799224854
Validation loss: 2.0701634319879676

Epoch: 6| Step: 10
Training loss: 1.1155577898025513
Validation loss: 2.034944212564858

Epoch: 6| Step: 11
Training loss: 1.8890361785888672
Validation loss: 2.008501457911666

Epoch: 6| Step: 12
Training loss: 1.0594429969787598
Validation loss: 2.0074903862450713

Epoch: 6| Step: 13
Training loss: 1.2722944021224976
Validation loss: 2.0168259861648723

Epoch: 349| Step: 0
Training loss: 2.0790815353393555
Validation loss: 2.0094460569402224

Epoch: 6| Step: 1
Training loss: 1.3260550498962402
Validation loss: 2.0033200569050287

Epoch: 6| Step: 2
Training loss: 0.8415719270706177
Validation loss: 2.0084771366529566

Epoch: 6| Step: 3
Training loss: 1.9516522884368896
Validation loss: 2.006948591560446

Epoch: 6| Step: 4
Training loss: 2.0056514739990234
Validation loss: 1.974848331943635

Epoch: 6| Step: 5
Training loss: 1.9662786722183228
Validation loss: 1.9787333165445635

Epoch: 6| Step: 6
Training loss: 1.3145320415496826
Validation loss: 1.983603128822901

Epoch: 6| Step: 7
Training loss: 1.390586256980896
Validation loss: 1.98615800949835

Epoch: 6| Step: 8
Training loss: 1.2013747692108154
Validation loss: 2.017638350045809

Epoch: 6| Step: 9
Training loss: 1.3559238910675049
Validation loss: 2.01402848510332

Epoch: 6| Step: 10
Training loss: 1.3596384525299072
Validation loss: 2.0209895051935667

Epoch: 6| Step: 11
Training loss: 1.9319865703582764
Validation loss: 2.050213506144862

Epoch: 6| Step: 12
Training loss: 1.4172848463058472
Validation loss: 2.0597427250236593

Epoch: 6| Step: 13
Training loss: 1.772911787033081
Validation loss: 2.094893863124232

Epoch: 350| Step: 0
Training loss: 1.832892656326294
Validation loss: 2.079827421454973

Epoch: 6| Step: 1
Training loss: 1.753998041152954
Validation loss: 2.120923847280523

Epoch: 6| Step: 2
Training loss: 1.6243224143981934
Validation loss: 2.0807257262609338

Epoch: 6| Step: 3
Training loss: 1.5990102291107178
Validation loss: 2.0802461101162817

Epoch: 6| Step: 4
Training loss: 1.6340959072113037
Validation loss: 2.0291141463864233

Epoch: 6| Step: 5
Training loss: 2.2851905822753906
Validation loss: 2.024526301250663

Epoch: 6| Step: 6
Training loss: 1.1949381828308105
Validation loss: 2.0132328092411

Epoch: 6| Step: 7
Training loss: 2.135246515274048
Validation loss: 2.005145526701404

Epoch: 6| Step: 8
Training loss: 1.3665032386779785
Validation loss: 2.0139511939018004

Epoch: 6| Step: 9
Training loss: 1.2211048603057861
Validation loss: 1.9914153070860012

Epoch: 6| Step: 10
Training loss: 1.4461058378219604
Validation loss: 1.960496433319584

Epoch: 6| Step: 11
Training loss: 0.7944779396057129
Validation loss: 1.9858828462580198

Epoch: 6| Step: 12
Training loss: 1.1725437641143799
Validation loss: 1.9673161557925645

Epoch: 6| Step: 13
Training loss: 1.3835837841033936
Validation loss: 1.9893081547111593

Epoch: 351| Step: 0
Training loss: 2.0123088359832764
Validation loss: 1.9882945565767185

Epoch: 6| Step: 1
Training loss: 1.6131587028503418
Validation loss: 2.006230454291067

Epoch: 6| Step: 2
Training loss: 1.138777256011963
Validation loss: 2.0142487364430584

Epoch: 6| Step: 3
Training loss: 1.425805926322937
Validation loss: 2.0225081251513575

Epoch: 6| Step: 4
Training loss: 1.3437641859054565
Validation loss: 2.030094136473953

Epoch: 6| Step: 5
Training loss: 1.3381497859954834
Validation loss: 2.048643796674667

Epoch: 6| Step: 6
Training loss: 1.977797269821167
Validation loss: 2.0436308935124385

Epoch: 6| Step: 7
Training loss: 1.6885690689086914
Validation loss: 2.0503488099703224

Epoch: 6| Step: 8
Training loss: 1.2961434125900269
Validation loss: 2.070132722136795

Epoch: 6| Step: 9
Training loss: 1.2125366926193237
Validation loss: 2.0470090732779553

Epoch: 6| Step: 10
Training loss: 1.6423661708831787
Validation loss: 2.0688627766024683

Epoch: 6| Step: 11
Training loss: 1.5004873275756836
Validation loss: 2.0704988587287163

Epoch: 6| Step: 12
Training loss: 1.3641588687896729
Validation loss: 2.0582954499029342

Epoch: 6| Step: 13
Training loss: 1.7941619157791138
Validation loss: 2.0304994044765348

Epoch: 352| Step: 0
Training loss: 0.9272905588150024
Validation loss: 2.0159672549975816

Epoch: 6| Step: 1
Training loss: 1.461197018623352
Validation loss: 1.9752790530522664

Epoch: 6| Step: 2
Training loss: 1.3325486183166504
Validation loss: 1.978620667611399

Epoch: 6| Step: 3
Training loss: 1.8341461420059204
Validation loss: 1.9632770963894424

Epoch: 6| Step: 4
Training loss: 1.461451768875122
Validation loss: 1.9685919925730715

Epoch: 6| Step: 5
Training loss: 1.1138464212417603
Validation loss: 1.9697862568721975

Epoch: 6| Step: 6
Training loss: 1.9440398216247559
Validation loss: 1.9583663914793281

Epoch: 6| Step: 7
Training loss: 1.8378469944000244
Validation loss: 1.956241310283702

Epoch: 6| Step: 8
Training loss: 1.2291887998580933
Validation loss: 1.9633366189977175

Epoch: 6| Step: 9
Training loss: 1.194901943206787
Validation loss: 1.970829112555391

Epoch: 6| Step: 10
Training loss: 1.889774203300476
Validation loss: 1.988030638746036

Epoch: 6| Step: 11
Training loss: 1.3809306621551514
Validation loss: 2.0111307392838182

Epoch: 6| Step: 12
Training loss: 1.9683012962341309
Validation loss: 2.027661851657334

Epoch: 6| Step: 13
Training loss: 1.7782282829284668
Validation loss: 2.040992180506388

Epoch: 353| Step: 0
Training loss: 1.7999283075332642
Validation loss: 2.062283990203693

Epoch: 6| Step: 1
Training loss: 1.4874515533447266
Validation loss: 2.038711635015344

Epoch: 6| Step: 2
Training loss: 1.6963720321655273
Validation loss: 2.043275979257399

Epoch: 6| Step: 3
Training loss: 1.4289790391921997
Validation loss: 2.0176264214259323

Epoch: 6| Step: 4
Training loss: 1.9256155490875244
Validation loss: 2.0322289979586037

Epoch: 6| Step: 5
Training loss: 1.291144609451294
Validation loss: 2.0265553125771145

Epoch: 6| Step: 6
Training loss: 1.5934793949127197
Validation loss: 2.0150341474881737

Epoch: 6| Step: 7
Training loss: 1.8819756507873535
Validation loss: 2.013722135174659

Epoch: 6| Step: 8
Training loss: 1.2025518417358398
Validation loss: 2.027388426565355

Epoch: 6| Step: 9
Training loss: 1.351266622543335
Validation loss: 2.031797147566272

Epoch: 6| Step: 10
Training loss: 1.2242722511291504
Validation loss: 2.03094381670798

Epoch: 6| Step: 11
Training loss: 1.5179643630981445
Validation loss: 2.035765891434044

Epoch: 6| Step: 12
Training loss: 1.513880729675293
Validation loss: 2.000400358630765

Epoch: 6| Step: 13
Training loss: 1.2002581357955933
Validation loss: 1.997753018973976

Epoch: 354| Step: 0
Training loss: 1.5466423034667969
Validation loss: 1.975970639977404

Epoch: 6| Step: 1
Training loss: 1.3071260452270508
Validation loss: 1.9671205295029508

Epoch: 6| Step: 2
Training loss: 1.9356197118759155
Validation loss: 1.963603837515718

Epoch: 6| Step: 3
Training loss: 1.6677721738815308
Validation loss: 1.947205158971971

Epoch: 6| Step: 4
Training loss: 1.4636847972869873
Validation loss: 1.9419098105481876

Epoch: 6| Step: 5
Training loss: 1.169867753982544
Validation loss: 1.9234043103392406

Epoch: 6| Step: 6
Training loss: 1.4431861639022827
Validation loss: 1.9436921278635662

Epoch: 6| Step: 7
Training loss: 1.2838037014007568
Validation loss: 1.9511178565281693

Epoch: 6| Step: 8
Training loss: 1.9689351320266724
Validation loss: 1.9526996612548828

Epoch: 6| Step: 9
Training loss: 1.9011681079864502
Validation loss: 1.97905267823127

Epoch: 6| Step: 10
Training loss: 1.296443223953247
Validation loss: 1.9732629560655164

Epoch: 6| Step: 11
Training loss: 1.4927184581756592
Validation loss: 1.9830951652219218

Epoch: 6| Step: 12
Training loss: 1.212539553642273
Validation loss: 1.9994630505961757

Epoch: 6| Step: 13
Training loss: 1.029679775238037
Validation loss: 2.00095094532095

Epoch: 355| Step: 0
Training loss: 1.5340874195098877
Validation loss: 2.029574364744207

Epoch: 6| Step: 1
Training loss: 1.3851462602615356
Validation loss: 2.055861824302263

Epoch: 6| Step: 2
Training loss: 0.7637174129486084
Validation loss: 2.049721407633956

Epoch: 6| Step: 3
Training loss: 1.5514954328536987
Validation loss: 2.0665049886190765

Epoch: 6| Step: 4
Training loss: 1.8653968572616577
Validation loss: 2.064542188439318

Epoch: 6| Step: 5
Training loss: 2.0210816860198975
Validation loss: 2.035856887858401

Epoch: 6| Step: 6
Training loss: 1.051155924797058
Validation loss: 2.054005415208878

Epoch: 6| Step: 7
Training loss: 1.6048915386199951
Validation loss: 2.04345287558853

Epoch: 6| Step: 8
Training loss: 1.5166125297546387
Validation loss: 2.0076808301351403

Epoch: 6| Step: 9
Training loss: 1.3341310024261475
Validation loss: 2.006837478248022

Epoch: 6| Step: 10
Training loss: 1.7288000583648682
Validation loss: 2.007390409387568

Epoch: 6| Step: 11
Training loss: 1.3045165538787842
Validation loss: 1.9921068042837164

Epoch: 6| Step: 12
Training loss: 1.6567914485931396
Validation loss: 2.001725491657052

Epoch: 6| Step: 13
Training loss: 1.3988356590270996
Validation loss: 1.98064818433536

Epoch: 356| Step: 0
Training loss: 1.5952483415603638
Validation loss: 2.008683760960897

Epoch: 6| Step: 1
Training loss: 1.804206371307373
Validation loss: 2.0026036334294144

Epoch: 6| Step: 2
Training loss: 1.528069257736206
Validation loss: 2.010713400379304

Epoch: 6| Step: 3
Training loss: 1.9063081741333008
Validation loss: 2.0306185650569137

Epoch: 6| Step: 4
Training loss: 1.3210922479629517
Validation loss: 2.041911482810974

Epoch: 6| Step: 5
Training loss: 1.4059865474700928
Validation loss: 2.0557574559283514

Epoch: 6| Step: 6
Training loss: 1.3333735466003418
Validation loss: 2.0515320288237704

Epoch: 6| Step: 7
Training loss: 1.6726261377334595
Validation loss: 2.016460664810673

Epoch: 6| Step: 8
Training loss: 1.8894400596618652
Validation loss: 2.007810188877967

Epoch: 6| Step: 9
Training loss: 0.8244351744651794
Validation loss: 1.9990923097056728

Epoch: 6| Step: 10
Training loss: 1.066474437713623
Validation loss: 1.9847088424108361

Epoch: 6| Step: 11
Training loss: 1.2244211435317993
Validation loss: 1.991429860873889

Epoch: 6| Step: 12
Training loss: 1.9141613245010376
Validation loss: 1.9899575056568268

Epoch: 6| Step: 13
Training loss: 1.6620080471038818
Validation loss: 1.9682554993578183

Epoch: 357| Step: 0
Training loss: 1.5821330547332764
Validation loss: 1.9588510182596022

Epoch: 6| Step: 1
Training loss: 1.1887245178222656
Validation loss: 1.9933716404822566

Epoch: 6| Step: 2
Training loss: 1.0626753568649292
Validation loss: 2.0026339215617024

Epoch: 6| Step: 3
Training loss: 1.6637547016143799
Validation loss: 2.0431160670454784

Epoch: 6| Step: 4
Training loss: 0.9856612682342529
Validation loss: 2.0546042060339325

Epoch: 6| Step: 5
Training loss: 2.359795570373535
Validation loss: 2.0322827062299176

Epoch: 6| Step: 6
Training loss: 1.1943036317825317
Validation loss: 2.010467311387421

Epoch: 6| Step: 7
Training loss: 1.1385248899459839
Validation loss: 2.0008194779837005

Epoch: 6| Step: 8
Training loss: 1.4120591878890991
Validation loss: 2.0211834061530327

Epoch: 6| Step: 9
Training loss: 1.53775155544281
Validation loss: 2.0032035843018563

Epoch: 6| Step: 10
Training loss: 1.531151294708252
Validation loss: 2.0192242245520315

Epoch: 6| Step: 11
Training loss: 1.6642969846725464
Validation loss: 2.0247137341448056

Epoch: 6| Step: 12
Training loss: 1.862168550491333
Validation loss: 2.0180805319099018

Epoch: 6| Step: 13
Training loss: 1.3764994144439697
Validation loss: 2.013689148810602

Epoch: 358| Step: 0
Training loss: 1.0506778955459595
Validation loss: 2.020096209741408

Epoch: 6| Step: 1
Training loss: 1.7476763725280762
Validation loss: 2.014344375620606

Epoch: 6| Step: 2
Training loss: 1.4017122983932495
Validation loss: 1.9980996783061693

Epoch: 6| Step: 3
Training loss: 1.2365994453430176
Validation loss: 2.0132805019296627

Epoch: 6| Step: 4
Training loss: 1.235363483428955
Validation loss: 1.9985386633103894

Epoch: 6| Step: 5
Training loss: 1.4138033390045166
Validation loss: 2.014090140660604

Epoch: 6| Step: 6
Training loss: 1.1910438537597656
Validation loss: 2.0000487886449343

Epoch: 6| Step: 7
Training loss: 1.4356441497802734
Validation loss: 2.0176556366746143

Epoch: 6| Step: 8
Training loss: 2.030515670776367
Validation loss: 2.0189953824525237

Epoch: 6| Step: 9
Training loss: 1.9997879266738892
Validation loss: 1.990120449373799

Epoch: 6| Step: 10
Training loss: 1.589411735534668
Validation loss: 1.9881738642210602

Epoch: 6| Step: 11
Training loss: 1.5322668552398682
Validation loss: 2.0120746089566137

Epoch: 6| Step: 12
Training loss: 0.9358092546463013
Validation loss: 2.0015032022230086

Epoch: 6| Step: 13
Training loss: 1.7285888195037842
Validation loss: 2.0085365977338565

Epoch: 359| Step: 0
Training loss: 1.3904438018798828
Validation loss: 1.991436468657627

Epoch: 6| Step: 1
Training loss: 0.9385709166526794
Validation loss: 2.0210426725367063

Epoch: 6| Step: 2
Training loss: 2.425339460372925
Validation loss: 2.028808214331186

Epoch: 6| Step: 3
Training loss: 1.800689935684204
Validation loss: 2.0460147088573826

Epoch: 6| Step: 4
Training loss: 0.8307300209999084
Validation loss: 2.0721827553164576

Epoch: 6| Step: 5
Training loss: 1.0852913856506348
Validation loss: 2.0572761258771344

Epoch: 6| Step: 6
Training loss: 1.5840237140655518
Validation loss: 2.0649922483710834

Epoch: 6| Step: 7
Training loss: 1.3570008277893066
Validation loss: 2.047932735053442

Epoch: 6| Step: 8
Training loss: 1.3489148616790771
Validation loss: 2.0388048592434136

Epoch: 6| Step: 9
Training loss: 1.2421529293060303
Validation loss: 2.0484109540139475

Epoch: 6| Step: 10
Training loss: 1.6843143701553345
Validation loss: 2.0248811424419446

Epoch: 6| Step: 11
Training loss: 1.218092918395996
Validation loss: 2.021031468145309

Epoch: 6| Step: 12
Training loss: 1.5591261386871338
Validation loss: 2.0170789944228305

Epoch: 6| Step: 13
Training loss: 2.3415863513946533
Validation loss: 2.018013572180143

Epoch: 360| Step: 0
Training loss: 1.3410775661468506
Validation loss: 2.0106944704568512

Epoch: 6| Step: 1
Training loss: 1.6036992073059082
Validation loss: 1.9890960929214314

Epoch: 6| Step: 2
Training loss: 1.3489668369293213
Validation loss: 1.9868060645236765

Epoch: 6| Step: 3
Training loss: 1.3977693319320679
Validation loss: 1.9365406690105316

Epoch: 6| Step: 4
Training loss: 1.387805700302124
Validation loss: 1.9443969867562736

Epoch: 6| Step: 5
Training loss: 1.5565123558044434
Validation loss: 1.9766423471512333

Epoch: 6| Step: 6
Training loss: 1.4124418497085571
Validation loss: 1.9707697540201166

Epoch: 6| Step: 7
Training loss: 1.6428788900375366
Validation loss: 1.984179748001919

Epoch: 6| Step: 8
Training loss: 1.4148476123809814
Validation loss: 1.9723904043115594

Epoch: 6| Step: 9
Training loss: 1.3248741626739502
Validation loss: 1.9732149313854914

Epoch: 6| Step: 10
Training loss: 1.7384982109069824
Validation loss: 1.983821617659702

Epoch: 6| Step: 11
Training loss: 2.344898223876953
Validation loss: 2.0113838539328626

Epoch: 6| Step: 12
Training loss: 0.9646032452583313
Validation loss: 2.0179743433511383

Epoch: 6| Step: 13
Training loss: 1.143139362335205
Validation loss: 2.014749675668696

Epoch: 361| Step: 0
Training loss: 0.9834532141685486
Validation loss: 2.020892805950616

Epoch: 6| Step: 1
Training loss: 1.9969711303710938
Validation loss: 2.031623622422577

Epoch: 6| Step: 2
Training loss: 1.8049358129501343
Validation loss: 2.0214536651488273

Epoch: 6| Step: 3
Training loss: 1.3344999551773071
Validation loss: 2.0320180308434272

Epoch: 6| Step: 4
Training loss: 1.5298017263412476
Validation loss: 2.0196750061486357

Epoch: 6| Step: 5
Training loss: 1.036830186843872
Validation loss: 2.0348454931730866

Epoch: 6| Step: 6
Training loss: 1.3402273654937744
Validation loss: 2.005198058261666

Epoch: 6| Step: 7
Training loss: 1.0854963064193726
Validation loss: 1.987150630643291

Epoch: 6| Step: 8
Training loss: 2.2314352989196777
Validation loss: 1.9843899755067722

Epoch: 6| Step: 9
Training loss: 0.8378071784973145
Validation loss: 1.974337003564322

Epoch: 6| Step: 10
Training loss: 2.103915214538574
Validation loss: 1.9814837722368137

Epoch: 6| Step: 11
Training loss: 1.0263097286224365
Validation loss: 1.9818953288498746

Epoch: 6| Step: 12
Training loss: 1.6477253437042236
Validation loss: 1.9988999059123378

Epoch: 6| Step: 13
Training loss: 1.3606390953063965
Validation loss: 2.0011196149292814

Epoch: 362| Step: 0
Training loss: 1.7208821773529053
Validation loss: 1.998901979897612

Epoch: 6| Step: 1
Training loss: 1.1310659646987915
Validation loss: 1.9922411928894699

Epoch: 6| Step: 2
Training loss: 1.5132734775543213
Validation loss: 2.0039700897791053

Epoch: 6| Step: 3
Training loss: 1.1714069843292236
Validation loss: 1.9854209217973935

Epoch: 6| Step: 4
Training loss: 1.611769676208496
Validation loss: 1.9863714043812086

Epoch: 6| Step: 5
Training loss: 1.379773497581482
Validation loss: 1.9887426822416243

Epoch: 6| Step: 6
Training loss: 1.812214970588684
Validation loss: 1.9724233791392336

Epoch: 6| Step: 7
Training loss: 1.3353543281555176
Validation loss: 2.018702474973535

Epoch: 6| Step: 8
Training loss: 1.3638954162597656
Validation loss: 2.0152162633916384

Epoch: 6| Step: 9
Training loss: 0.36680203676223755
Validation loss: 2.0004298866436048

Epoch: 6| Step: 10
Training loss: 2.286993980407715
Validation loss: 2.0114144894384567

Epoch: 6| Step: 11
Training loss: 1.3763169050216675
Validation loss: 1.9883705005850842

Epoch: 6| Step: 12
Training loss: 1.8646609783172607
Validation loss: 2.0190738695924

Epoch: 6| Step: 13
Training loss: 0.8985692262649536
Validation loss: 1.990461721215197

Epoch: 363| Step: 0
Training loss: 1.2768279314041138
Validation loss: 1.9787071315191125

Epoch: 6| Step: 1
Training loss: 1.7315895557403564
Validation loss: 1.978169951387631

Epoch: 6| Step: 2
Training loss: 1.4739432334899902
Validation loss: 1.9850752686941495

Epoch: 6| Step: 3
Training loss: 1.7341653108596802
Validation loss: 1.961073584454034

Epoch: 6| Step: 4
Training loss: 1.259383201599121
Validation loss: 1.9861737182063441

Epoch: 6| Step: 5
Training loss: 1.0379140377044678
Validation loss: 1.9821202306337253

Epoch: 6| Step: 6
Training loss: 1.0697752237319946
Validation loss: 1.989326056613717

Epoch: 6| Step: 7
Training loss: 2.040841579437256
Validation loss: 2.0029778044710875

Epoch: 6| Step: 8
Training loss: 1.802175760269165
Validation loss: 2.0407915961357856

Epoch: 6| Step: 9
Training loss: 1.5590496063232422
Validation loss: 2.0199843324640745

Epoch: 6| Step: 10
Training loss: 1.0295753479003906
Validation loss: 2.0233139222668064

Epoch: 6| Step: 11
Training loss: 1.8706486225128174
Validation loss: 2.001015629819644

Epoch: 6| Step: 12
Training loss: 1.03767728805542
Validation loss: 2.0142070413917623

Epoch: 6| Step: 13
Training loss: 1.0101521015167236
Validation loss: 1.9904346863428752

Epoch: 364| Step: 0
Training loss: 1.6444075107574463
Validation loss: 1.9957697288964384

Epoch: 6| Step: 1
Training loss: 1.3715027570724487
Validation loss: 2.007954162936057

Epoch: 6| Step: 2
Training loss: 1.3537685871124268
Validation loss: 1.9872739686760852

Epoch: 6| Step: 3
Training loss: 1.908405065536499
Validation loss: 1.9881112370439755

Epoch: 6| Step: 4
Training loss: 1.7540638446807861
Validation loss: 2.0074274604038527

Epoch: 6| Step: 5
Training loss: 0.8409262299537659
Validation loss: 2.0087341416266655

Epoch: 6| Step: 6
Training loss: 1.3984901905059814
Validation loss: 1.9866704966432305

Epoch: 6| Step: 7
Training loss: 1.0011488199234009
Validation loss: 1.979573235716871

Epoch: 6| Step: 8
Training loss: 1.256386399269104
Validation loss: 1.999433671274493

Epoch: 6| Step: 9
Training loss: 2.1623635292053223
Validation loss: 2.0160202954405095

Epoch: 6| Step: 10
Training loss: 1.1304552555084229
Validation loss: 2.0059639036014514

Epoch: 6| Step: 11
Training loss: 1.8791478872299194
Validation loss: 2.006816512794905

Epoch: 6| Step: 12
Training loss: 0.6425424814224243
Validation loss: 1.9997227563652942

Epoch: 6| Step: 13
Training loss: 1.8378005027770996
Validation loss: 2.012729713993688

Epoch: 365| Step: 0
Training loss: 1.6473875045776367
Validation loss: 2.018130451120356

Epoch: 6| Step: 1
Training loss: 1.1480435132980347
Validation loss: 2.051883074545091

Epoch: 6| Step: 2
Training loss: 1.2189100980758667
Validation loss: 2.0534230098929456

Epoch: 6| Step: 3
Training loss: 1.3707127571105957
Validation loss: 2.035763176538611

Epoch: 6| Step: 4
Training loss: 1.3858084678649902
Validation loss: 2.038911978403727

Epoch: 6| Step: 5
Training loss: 1.7753146886825562
Validation loss: 2.023215578448388

Epoch: 6| Step: 6
Training loss: 1.3951892852783203
Validation loss: 2.019516157847579

Epoch: 6| Step: 7
Training loss: 0.7200096249580383
Validation loss: 2.0358486918992895

Epoch: 6| Step: 8
Training loss: 1.4827302694320679
Validation loss: 2.0399438335049536

Epoch: 6| Step: 9
Training loss: 1.1953885555267334
Validation loss: 2.030323355428634

Epoch: 6| Step: 10
Training loss: 1.7768819332122803
Validation loss: 2.017543347932959

Epoch: 6| Step: 11
Training loss: 1.3912049531936646
Validation loss: 2.0026038385206655

Epoch: 6| Step: 12
Training loss: 2.037539482116699
Validation loss: 2.0115681566217893

Epoch: 6| Step: 13
Training loss: 1.2862995862960815
Validation loss: 1.9931418562448153

Epoch: 366| Step: 0
Training loss: 1.7060513496398926
Validation loss: 1.9922901315073813

Epoch: 6| Step: 1
Training loss: 0.9593588709831238
Validation loss: 1.9934911458723006

Epoch: 6| Step: 2
Training loss: 1.6875591278076172
Validation loss: 1.973920827270836

Epoch: 6| Step: 3
Training loss: 1.6855802536010742
Validation loss: 1.9804879773047663

Epoch: 6| Step: 4
Training loss: 0.9355999231338501
Validation loss: 1.993751746352001

Epoch: 6| Step: 5
Training loss: 1.0397800207138062
Validation loss: 1.9891624168683124

Epoch: 6| Step: 6
Training loss: 1.5768661499023438
Validation loss: 1.9847527229657738

Epoch: 6| Step: 7
Training loss: 1.067146897315979
Validation loss: 2.0085279069921023

Epoch: 6| Step: 8
Training loss: 2.3897762298583984
Validation loss: 2.0029955038460354

Epoch: 6| Step: 9
Training loss: 1.3765710592269897
Validation loss: 1.9844885923529183

Epoch: 6| Step: 10
Training loss: 1.4914360046386719
Validation loss: 1.98797026500907

Epoch: 6| Step: 11
Training loss: 1.199924349784851
Validation loss: 1.9886031868637248

Epoch: 6| Step: 12
Training loss: 1.5555918216705322
Validation loss: 1.9867266301185853

Epoch: 6| Step: 13
Training loss: 1.0795338153839111
Validation loss: 1.9963194747124948

Epoch: 367| Step: 0
Training loss: 1.4451549053192139
Validation loss: 2.0023458491089525

Epoch: 6| Step: 1
Training loss: 1.570749282836914
Validation loss: 2.0208821091600644

Epoch: 6| Step: 2
Training loss: 1.4317724704742432
Validation loss: 2.0145131362381803

Epoch: 6| Step: 3
Training loss: 1.4788591861724854
Validation loss: 2.0087559248811457

Epoch: 6| Step: 4
Training loss: 1.8595640659332275
Validation loss: 2.0318962002313263

Epoch: 6| Step: 5
Training loss: 1.0495507717132568
Validation loss: 2.010614328486945

Epoch: 6| Step: 6
Training loss: 1.438918948173523
Validation loss: 2.0089374690927486

Epoch: 6| Step: 7
Training loss: 1.1417218446731567
Validation loss: 2.01690068680753

Epoch: 6| Step: 8
Training loss: 1.8122385740280151
Validation loss: 2.0247335126323085

Epoch: 6| Step: 9
Training loss: 0.9008159637451172
Validation loss: 2.0310687813707577

Epoch: 6| Step: 10
Training loss: 1.3382142782211304
Validation loss: 2.042666901824295

Epoch: 6| Step: 11
Training loss: 1.179605484008789
Validation loss: 2.0339142161030925

Epoch: 6| Step: 12
Training loss: 1.0344226360321045
Validation loss: 2.001058952782744

Epoch: 6| Step: 13
Training loss: 2.292550802230835
Validation loss: 1.992207173378237

Epoch: 368| Step: 0
Training loss: 1.8142067193984985
Validation loss: 2.0091466698595273

Epoch: 6| Step: 1
Training loss: 1.0588970184326172
Validation loss: 2.00680709397921

Epoch: 6| Step: 2
Training loss: 1.5210565328598022
Validation loss: 2.005326509475708

Epoch: 6| Step: 3
Training loss: 1.7206333875656128
Validation loss: 1.992938954343078

Epoch: 6| Step: 4
Training loss: 1.6254782676696777
Validation loss: 1.9591658935751965

Epoch: 6| Step: 5
Training loss: 1.4522433280944824
Validation loss: 1.9672862509245514

Epoch: 6| Step: 6
Training loss: 1.3887944221496582
Validation loss: 1.990679205104869

Epoch: 6| Step: 7
Training loss: 1.3261425495147705
Validation loss: 1.9834430653561828

Epoch: 6| Step: 8
Training loss: 1.8317121267318726
Validation loss: 1.996784492205548

Epoch: 6| Step: 9
Training loss: 0.8790672421455383
Validation loss: 1.9897554023291475

Epoch: 6| Step: 10
Training loss: 0.9870526790618896
Validation loss: 1.9904185315614105

Epoch: 6| Step: 11
Training loss: 1.1649802923202515
Validation loss: 2.0009655683271346

Epoch: 6| Step: 12
Training loss: 1.5416091680526733
Validation loss: 2.029839964323146

Epoch: 6| Step: 13
Training loss: 1.6407859325408936
Validation loss: 2.0366935191615934

Epoch: 369| Step: 0
Training loss: 1.0897490978240967
Validation loss: 2.0498088482887513

Epoch: 6| Step: 1
Training loss: 1.341052770614624
Validation loss: 2.0385667252284225

Epoch: 6| Step: 2
Training loss: 1.6808032989501953
Validation loss: 2.0415632724761963

Epoch: 6| Step: 3
Training loss: 1.5253030061721802
Validation loss: 2.034863805258146

Epoch: 6| Step: 4
Training loss: 1.459235429763794
Validation loss: 2.035275705399052

Epoch: 6| Step: 5
Training loss: 1.2994900941848755
Validation loss: 2.0442554707168252

Epoch: 6| Step: 6
Training loss: 0.8641258478164673
Validation loss: 2.0002991871167253

Epoch: 6| Step: 7
Training loss: 1.9068007469177246
Validation loss: 2.0121957743039696

Epoch: 6| Step: 8
Training loss: 1.469012975692749
Validation loss: 1.9816916014558525

Epoch: 6| Step: 9
Training loss: 1.1247565746307373
Validation loss: 1.9912573637500885

Epoch: 6| Step: 10
Training loss: 1.2689794301986694
Validation loss: 1.9627760661545621

Epoch: 6| Step: 11
Training loss: 1.6139729022979736
Validation loss: 1.9479755996375956

Epoch: 6| Step: 12
Training loss: 1.6189544200897217
Validation loss: 1.9770987072298605

Epoch: 6| Step: 13
Training loss: 1.5787601470947266
Validation loss: 1.9613107391583022

Epoch: 370| Step: 0
Training loss: 1.4104804992675781
Validation loss: 1.992614185938271

Epoch: 6| Step: 1
Training loss: 1.895200252532959
Validation loss: 1.9975413814667733

Epoch: 6| Step: 2
Training loss: 1.2225300073623657
Validation loss: 1.9932973000311083

Epoch: 6| Step: 3
Training loss: 0.6734766364097595
Validation loss: 2.0280944044871996

Epoch: 6| Step: 4
Training loss: 0.6925795078277588
Validation loss: 2.041108677464147

Epoch: 6| Step: 5
Training loss: 1.1198885440826416
Validation loss: 2.039217056766633

Epoch: 6| Step: 6
Training loss: 1.461553692817688
Validation loss: 2.0458876163728776

Epoch: 6| Step: 7
Training loss: 1.5124629735946655
Validation loss: 2.032757577075753

Epoch: 6| Step: 8
Training loss: 1.3622238636016846
Validation loss: 2.0268732475978073

Epoch: 6| Step: 9
Training loss: 1.0964784622192383
Validation loss: 2.00930078183451

Epoch: 6| Step: 10
Training loss: 1.6234073638916016
Validation loss: 2.0072212757602816

Epoch: 6| Step: 11
Training loss: 1.9427218437194824
Validation loss: 2.0283138572528796

Epoch: 6| Step: 12
Training loss: 2.180396318435669
Validation loss: 1.9821444788286764

Epoch: 6| Step: 13
Training loss: 0.7821314930915833
Validation loss: 1.990524386846891

Epoch: 371| Step: 0
Training loss: 1.5088553428649902
Validation loss: 1.9830925746630597

Epoch: 6| Step: 1
Training loss: 0.9490381479263306
Validation loss: 1.9905788103739421

Epoch: 6| Step: 2
Training loss: 1.3088362216949463
Validation loss: 1.9866622365931028

Epoch: 6| Step: 3
Training loss: 1.0222506523132324
Validation loss: 1.9819565998610629

Epoch: 6| Step: 4
Training loss: 2.0391249656677246
Validation loss: 1.984666116776005

Epoch: 6| Step: 5
Training loss: 1.1900913715362549
Validation loss: 1.9705139308847406

Epoch: 6| Step: 6
Training loss: 1.211801528930664
Validation loss: 1.963233664471616

Epoch: 6| Step: 7
Training loss: 1.441034197807312
Validation loss: 1.9965402592894852

Epoch: 6| Step: 8
Training loss: 1.3537002801895142
Validation loss: 1.993968217603622

Epoch: 6| Step: 9
Training loss: 1.3658069372177124
Validation loss: 2.0157303143573064

Epoch: 6| Step: 10
Training loss: 1.9677351713180542
Validation loss: 2.0279468349231187

Epoch: 6| Step: 11
Training loss: 1.0921262502670288
Validation loss: 2.020527329496158

Epoch: 6| Step: 12
Training loss: 1.7374383211135864
Validation loss: 2.0345542841060187

Epoch: 6| Step: 13
Training loss: 0.7930624485015869
Validation loss: 2.036223957615514

Epoch: 372| Step: 0
Training loss: 1.403757095336914
Validation loss: 2.017742985038347

Epoch: 6| Step: 1
Training loss: 1.2386829853057861
Validation loss: 2.0387837245900142

Epoch: 6| Step: 2
Training loss: 1.4764153957366943
Validation loss: 2.0384949279087845

Epoch: 6| Step: 3
Training loss: 1.3154131174087524
Validation loss: 2.03824738020538

Epoch: 6| Step: 4
Training loss: 0.822005033493042
Validation loss: 2.0287631480924544

Epoch: 6| Step: 5
Training loss: 1.2816771268844604
Validation loss: 1.9907929358943817

Epoch: 6| Step: 6
Training loss: 1.452155351638794
Validation loss: 1.999304348422635

Epoch: 6| Step: 7
Training loss: 2.194700241088867
Validation loss: 1.9910264912471975

Epoch: 6| Step: 8
Training loss: 0.8620399236679077
Validation loss: 1.9920105780324628

Epoch: 6| Step: 9
Training loss: 1.5538649559020996
Validation loss: 1.9857332373178134

Epoch: 6| Step: 10
Training loss: 1.7706565856933594
Validation loss: 2.0088240920856433

Epoch: 6| Step: 11
Training loss: 1.0608477592468262
Validation loss: 2.002919343210036

Epoch: 6| Step: 12
Training loss: 1.228653907775879
Validation loss: 1.9776465367245417

Epoch: 6| Step: 13
Training loss: 1.8085428476333618
Validation loss: 1.999078699337539

Epoch: 373| Step: 0
Training loss: 1.6764960289001465
Validation loss: 2.000330250750306

Epoch: 6| Step: 1
Training loss: 1.5404614210128784
Validation loss: 2.0062509711070726

Epoch: 6| Step: 2
Training loss: 0.9320675730705261
Validation loss: 2.009144119037095

Epoch: 6| Step: 3
Training loss: 1.2133851051330566
Validation loss: 2.011108462528516

Epoch: 6| Step: 4
Training loss: 1.9162241220474243
Validation loss: 2.0123401316263343

Epoch: 6| Step: 5
Training loss: 2.032956600189209
Validation loss: 2.0025578339894614

Epoch: 6| Step: 6
Training loss: 1.0983282327651978
Validation loss: 2.002870334092007

Epoch: 6| Step: 7
Training loss: 1.2568695545196533
Validation loss: 2.028062464088522

Epoch: 6| Step: 8
Training loss: 1.1089056730270386
Validation loss: 2.0235448832152994

Epoch: 6| Step: 9
Training loss: 1.3306676149368286
Validation loss: 2.0734078832851943

Epoch: 6| Step: 10
Training loss: 1.3605611324310303
Validation loss: 2.0726440209214405

Epoch: 6| Step: 11
Training loss: 1.2819747924804688
Validation loss: 2.0324209813148744

Epoch: 6| Step: 12
Training loss: 0.9908363819122314
Validation loss: 2.0555881633553454

Epoch: 6| Step: 13
Training loss: 1.6446315050125122
Validation loss: 2.0544797938357116

Epoch: 374| Step: 0
Training loss: 1.3434247970581055
Validation loss: 2.0297867969800065

Epoch: 6| Step: 1
Training loss: 1.9042972326278687
Validation loss: 2.0689570788414247

Epoch: 6| Step: 2
Training loss: 1.406275749206543
Validation loss: 2.0631718481740644

Epoch: 6| Step: 3
Training loss: 1.2424966096878052
Validation loss: 2.057499470249299

Epoch: 6| Step: 4
Training loss: 0.7980936765670776
Validation loss: 2.0620352632255963

Epoch: 6| Step: 5
Training loss: 1.4144492149353027
Validation loss: 2.0429166645132084

Epoch: 6| Step: 6
Training loss: 1.5440027713775635
Validation loss: 2.0529094011552873

Epoch: 6| Step: 7
Training loss: 1.8083590269088745
Validation loss: 2.0378994236710253

Epoch: 6| Step: 8
Training loss: 1.0681272745132446
Validation loss: 2.012281597301524

Epoch: 6| Step: 9
Training loss: 1.4108562469482422
Validation loss: 2.0117121588799263

Epoch: 6| Step: 10
Training loss: 1.119012713432312
Validation loss: 1.9973191497146443

Epoch: 6| Step: 11
Training loss: 1.420846700668335
Validation loss: 2.0129473350381337

Epoch: 6| Step: 12
Training loss: 1.3392645120620728
Validation loss: 2.0187921857321136

Epoch: 6| Step: 13
Training loss: 1.5738247632980347
Validation loss: 2.017866988335886

Epoch: 375| Step: 0
Training loss: 0.4758216142654419
Validation loss: 2.0264983331003497

Epoch: 6| Step: 1
Training loss: 0.9086011052131653
Validation loss: 2.0231832881127634

Epoch: 6| Step: 2
Training loss: 1.2012940645217896
Validation loss: 2.0199847003465057

Epoch: 6| Step: 3
Training loss: 1.871954083442688
Validation loss: 2.039414305840769

Epoch: 6| Step: 4
Training loss: 1.6399554014205933
Validation loss: 2.0250302771086335

Epoch: 6| Step: 5
Training loss: 1.1228067874908447
Validation loss: 2.032067024579612

Epoch: 6| Step: 6
Training loss: 0.9519057273864746
Validation loss: 2.037205071859462

Epoch: 6| Step: 7
Training loss: 1.970341682434082
Validation loss: 2.030402119441699

Epoch: 6| Step: 8
Training loss: 1.1418542861938477
Validation loss: 2.0198375384012857

Epoch: 6| Step: 9
Training loss: 1.6015386581420898
Validation loss: 2.0163162241699877

Epoch: 6| Step: 10
Training loss: 1.468907356262207
Validation loss: 2.021844317836146

Epoch: 6| Step: 11
Training loss: 1.7920191287994385
Validation loss: 2.0121627469216623

Epoch: 6| Step: 12
Training loss: 1.2716355323791504
Validation loss: 1.990287244960826

Epoch: 6| Step: 13
Training loss: 2.069817543029785
Validation loss: 2.001080133581674

Epoch: 376| Step: 0
Training loss: 1.9738836288452148
Validation loss: 1.9916644147647324

Epoch: 6| Step: 1
Training loss: 1.1697288751602173
Validation loss: 2.004600674875321

Epoch: 6| Step: 2
Training loss: 1.2447590827941895
Validation loss: 1.994076999284888

Epoch: 6| Step: 3
Training loss: 0.7641441226005554
Validation loss: 1.9965973451573362

Epoch: 6| Step: 4
Training loss: 0.8800750374794006
Validation loss: 2.017998436445831

Epoch: 6| Step: 5
Training loss: 1.4199607372283936
Validation loss: 2.0258198579152427

Epoch: 6| Step: 6
Training loss: 1.8948400020599365
Validation loss: 2.051948134617139

Epoch: 6| Step: 7
Training loss: 1.3676518201828003
Validation loss: 2.0228199574255172

Epoch: 6| Step: 8
Training loss: 0.9781705141067505
Validation loss: 2.036356064581102

Epoch: 6| Step: 9
Training loss: 1.7902495861053467
Validation loss: 2.006036220058318

Epoch: 6| Step: 10
Training loss: 1.5812313556671143
Validation loss: 2.0105763866055395

Epoch: 6| Step: 11
Training loss: 1.689447045326233
Validation loss: 1.9798932575410413

Epoch: 6| Step: 12
Training loss: 1.2023260593414307
Validation loss: 1.9707180556430612

Epoch: 6| Step: 13
Training loss: 0.8783769011497498
Validation loss: 1.9765327169049172

Epoch: 377| Step: 0
Training loss: 1.5049545764923096
Validation loss: 1.9822423945191086

Epoch: 6| Step: 1
Training loss: 1.599528193473816
Validation loss: 1.9987828936628116

Epoch: 6| Step: 2
Training loss: 0.9853629469871521
Validation loss: 1.9884392305087017

Epoch: 6| Step: 3
Training loss: 1.6644071340560913
Validation loss: 1.997674310079185

Epoch: 6| Step: 4
Training loss: 1.5108541250228882
Validation loss: 1.9932930854059034

Epoch: 6| Step: 5
Training loss: 1.1156914234161377
Validation loss: 2.0083249666357554

Epoch: 6| Step: 6
Training loss: 1.1393297910690308
Validation loss: 2.0290056915693384

Epoch: 6| Step: 7
Training loss: 1.5540962219238281
Validation loss: 2.028232323226108

Epoch: 6| Step: 8
Training loss: 1.2570815086364746
Validation loss: 2.030960282971782

Epoch: 6| Step: 9
Training loss: 1.1251699924468994
Validation loss: 2.0584442666781846

Epoch: 6| Step: 10
Training loss: 1.1699589490890503
Validation loss: 2.0566176009434525

Epoch: 6| Step: 11
Training loss: 1.4094350337982178
Validation loss: 2.075831047950252

Epoch: 6| Step: 12
Training loss: 1.1241023540496826
Validation loss: 2.0599423275198987

Epoch: 6| Step: 13
Training loss: 1.7874916791915894
Validation loss: 2.0327932321897118

Epoch: 378| Step: 0
Training loss: 1.9265315532684326
Validation loss: 2.0237126568312287

Epoch: 6| Step: 1
Training loss: 1.2049009799957275
Validation loss: 2.025650164132477

Epoch: 6| Step: 2
Training loss: 1.1930618286132812
Validation loss: 1.9964440202200284

Epoch: 6| Step: 3
Training loss: 1.1806893348693848
Validation loss: 2.0077087007543093

Epoch: 6| Step: 4
Training loss: 1.5817097425460815
Validation loss: 1.998480922432356

Epoch: 6| Step: 5
Training loss: 1.1430177688598633
Validation loss: 2.012494787093132

Epoch: 6| Step: 6
Training loss: 1.2178349494934082
Validation loss: 1.9866686008309806

Epoch: 6| Step: 7
Training loss: 1.046604871749878
Validation loss: 2.016426019771125

Epoch: 6| Step: 8
Training loss: 1.1794755458831787
Validation loss: 2.0199079103367303

Epoch: 6| Step: 9
Training loss: 1.5185726881027222
Validation loss: 2.031646251678467

Epoch: 6| Step: 10
Training loss: 1.0886344909667969
Validation loss: 2.059865641337569

Epoch: 6| Step: 11
Training loss: 1.227017879486084
Validation loss: 2.041630338597041

Epoch: 6| Step: 12
Training loss: 1.950535774230957
Validation loss: 2.017509760395173

Epoch: 6| Step: 13
Training loss: 1.4118653535842896
Validation loss: 2.0180075758246967

Epoch: 379| Step: 0
Training loss: 1.3633230924606323
Validation loss: 2.0300920445431947

Epoch: 6| Step: 1
Training loss: 0.8539217114448547
Validation loss: 2.015835487714378

Epoch: 6| Step: 2
Training loss: 0.9001718759536743
Validation loss: 2.026109819771141

Epoch: 6| Step: 3
Training loss: 1.8763842582702637
Validation loss: 2.0205897861911404

Epoch: 6| Step: 4
Training loss: 1.4262285232543945
Validation loss: 2.001706264352286

Epoch: 6| Step: 5
Training loss: 1.6004823446273804
Validation loss: 2.0214878923149517

Epoch: 6| Step: 6
Training loss: 0.8944457173347473
Validation loss: 2.001927352720691

Epoch: 6| Step: 7
Training loss: 1.024574637413025
Validation loss: 2.0255450946028515

Epoch: 6| Step: 8
Training loss: 1.8592344522476196
Validation loss: 2.0306200981140137

Epoch: 6| Step: 9
Training loss: 1.0765671730041504
Validation loss: 2.018486407495314

Epoch: 6| Step: 10
Training loss: 1.5554320812225342
Validation loss: 2.0099551421339794

Epoch: 6| Step: 11
Training loss: 1.5056614875793457
Validation loss: 2.0050659192505704

Epoch: 6| Step: 12
Training loss: 1.6091995239257812
Validation loss: 2.029213595133956

Epoch: 6| Step: 13
Training loss: 0.9018309116363525
Validation loss: 2.0446509956031718

Epoch: 380| Step: 0
Training loss: 1.3957595825195312
Validation loss: 2.0455095973066104

Epoch: 6| Step: 1
Training loss: 1.4613858461380005
Validation loss: 2.053400384482517

Epoch: 6| Step: 2
Training loss: 1.165278673171997
Validation loss: 2.0477393698948685

Epoch: 6| Step: 3
Training loss: 1.4960720539093018
Validation loss: 2.05939253171285

Epoch: 6| Step: 4
Training loss: 0.7567132711410522
Validation loss: 2.0677175291122927

Epoch: 6| Step: 5
Training loss: 1.1788520812988281
Validation loss: 2.0261651392905944

Epoch: 6| Step: 6
Training loss: 1.2617287635803223
Validation loss: 2.048075409345729

Epoch: 6| Step: 7
Training loss: 1.3438361883163452
Validation loss: 2.0490793348640524

Epoch: 6| Step: 8
Training loss: 1.3088624477386475
Validation loss: 2.040255517087957

Epoch: 6| Step: 9
Training loss: 1.275005578994751
Validation loss: 2.0220721947249545

Epoch: 6| Step: 10
Training loss: 1.9231665134429932
Validation loss: 2.001979286952685

Epoch: 6| Step: 11
Training loss: 1.7013441324234009
Validation loss: 2.0117414971833587

Epoch: 6| Step: 12
Training loss: 0.9565489292144775
Validation loss: 1.996998724117074

Epoch: 6| Step: 13
Training loss: 1.3101229667663574
Validation loss: 1.9629833339363016

Epoch: 381| Step: 0
Training loss: 1.6966867446899414
Validation loss: 2.0016948484605357

Epoch: 6| Step: 1
Training loss: 1.4837394952774048
Validation loss: 1.9868599842953425

Epoch: 6| Step: 2
Training loss: 1.425567865371704
Validation loss: 1.9845439028996292

Epoch: 6| Step: 3
Training loss: 1.2146629095077515
Validation loss: 1.9767538283460884

Epoch: 6| Step: 4
Training loss: 0.9444008469581604
Validation loss: 1.9844074890177736

Epoch: 6| Step: 5
Training loss: 1.302743911743164
Validation loss: 2.0009432351717384

Epoch: 6| Step: 6
Training loss: 1.7156240940093994
Validation loss: 2.003686571633944

Epoch: 6| Step: 7
Training loss: 0.9025194644927979
Validation loss: 2.0095803045457408

Epoch: 6| Step: 8
Training loss: 1.7981438636779785
Validation loss: 2.0333648394512873

Epoch: 6| Step: 9
Training loss: 1.1690467596054077
Validation loss: 2.0457061823978218

Epoch: 6| Step: 10
Training loss: 0.7355712056159973
Validation loss: 2.0558691114507694

Epoch: 6| Step: 11
Training loss: 1.3611578941345215
Validation loss: 2.048265378962281

Epoch: 6| Step: 12
Training loss: 1.4774361848831177
Validation loss: 2.048779647837403

Epoch: 6| Step: 13
Training loss: 1.4454389810562134
Validation loss: 2.01950785293374

Epoch: 382| Step: 0
Training loss: 1.166927695274353
Validation loss: 2.04199246950047

Epoch: 6| Step: 1
Training loss: 1.551612377166748
Validation loss: 2.0356177642781246

Epoch: 6| Step: 2
Training loss: 1.9072436094284058
Validation loss: 2.035324535062236

Epoch: 6| Step: 3
Training loss: 1.8596071004867554
Validation loss: 2.027142658028551

Epoch: 6| Step: 4
Training loss: 0.7458691596984863
Validation loss: 2.015075957903298

Epoch: 6| Step: 5
Training loss: 1.5648808479309082
Validation loss: 2.02056884765625

Epoch: 6| Step: 6
Training loss: 1.4110233783721924
Validation loss: 2.0175187536465224

Epoch: 6| Step: 7
Training loss: 1.1820201873779297
Validation loss: 1.9932794135103944

Epoch: 6| Step: 8
Training loss: 0.8809025287628174
Validation loss: 2.0019321774923675

Epoch: 6| Step: 9
Training loss: 1.9938364028930664
Validation loss: 1.9925643115915277

Epoch: 6| Step: 10
Training loss: 0.6168815493583679
Validation loss: 1.991541507423565

Epoch: 6| Step: 11
Training loss: 1.1427345275878906
Validation loss: 1.9681528409322102

Epoch: 6| Step: 12
Training loss: 1.2913553714752197
Validation loss: 2.0072113442164596

Epoch: 6| Step: 13
Training loss: 0.9229632616043091
Validation loss: 2.0209613371920843

Epoch: 383| Step: 0
Training loss: 1.161390781402588
Validation loss: 2.008596771506853

Epoch: 6| Step: 1
Training loss: 1.30712890625
Validation loss: 2.0443697924255044

Epoch: 6| Step: 2
Training loss: 0.9328333139419556
Validation loss: 2.061610839700186

Epoch: 6| Step: 3
Training loss: 0.8688086867332458
Validation loss: 2.0534298202042938

Epoch: 6| Step: 4
Training loss: 1.4811954498291016
Validation loss: 2.0573947506566204

Epoch: 6| Step: 5
Training loss: 1.3423590660095215
Validation loss: 2.0474225346760084

Epoch: 6| Step: 6
Training loss: 1.4665849208831787
Validation loss: 2.020770184455379

Epoch: 6| Step: 7
Training loss: 1.519377589225769
Validation loss: 2.001446762392598

Epoch: 6| Step: 8
Training loss: 1.0367885828018188
Validation loss: 2.0011815306960896

Epoch: 6| Step: 9
Training loss: 1.6613889932632446
Validation loss: 1.9983395581604333

Epoch: 6| Step: 10
Training loss: 1.1775480508804321
Validation loss: 1.9703911824892926

Epoch: 6| Step: 11
Training loss: 1.4394848346710205
Validation loss: 1.9952069392768286

Epoch: 6| Step: 12
Training loss: 1.3659738302230835
Validation loss: 2.0158058930468816

Epoch: 6| Step: 13
Training loss: 2.0139169692993164
Validation loss: 2.005029656553781

Epoch: 384| Step: 0
Training loss: 0.9187017679214478
Validation loss: 1.9889799497460807

Epoch: 6| Step: 1
Training loss: 1.0521080493927002
Validation loss: 1.989923987337338

Epoch: 6| Step: 2
Training loss: 1.450642704963684
Validation loss: 1.9848642913244103

Epoch: 6| Step: 3
Training loss: 1.5627365112304688
Validation loss: 2.0102312539213445

Epoch: 6| Step: 4
Training loss: 1.714709758758545
Validation loss: 2.032584733860467

Epoch: 6| Step: 5
Training loss: 1.2864054441452026
Validation loss: 2.0440771631015244

Epoch: 6| Step: 6
Training loss: 0.6700365543365479
Validation loss: 2.048610289891561

Epoch: 6| Step: 7
Training loss: 1.4249862432479858
Validation loss: 2.049406978391832

Epoch: 6| Step: 8
Training loss: 1.9937924146652222
Validation loss: 2.051406898806172

Epoch: 6| Step: 9
Training loss: 0.941536545753479
Validation loss: 2.0280136613435644

Epoch: 6| Step: 10
Training loss: 1.075566291809082
Validation loss: 2.0240733520959013

Epoch: 6| Step: 11
Training loss: 1.4913688898086548
Validation loss: 2.0304299939063286

Epoch: 6| Step: 12
Training loss: 1.5825926065444946
Validation loss: 2.0236913170865787

Epoch: 6| Step: 13
Training loss: 0.9495453238487244
Validation loss: 2.0247123984880346

Epoch: 385| Step: 0
Training loss: 1.226654052734375
Validation loss: 1.998568501523746

Epoch: 6| Step: 1
Training loss: 1.5731232166290283
Validation loss: 1.9948083675035866

Epoch: 6| Step: 2
Training loss: 1.688711404800415
Validation loss: 1.9878111167620587

Epoch: 6| Step: 3
Training loss: 1.1902432441711426
Validation loss: 1.9839869750443326

Epoch: 6| Step: 4
Training loss: 1.1234281063079834
Validation loss: 1.965691694649317

Epoch: 6| Step: 5
Training loss: 1.560025691986084
Validation loss: 1.9889309842099425

Epoch: 6| Step: 6
Training loss: 1.1958324909210205
Validation loss: 1.9723958623024724

Epoch: 6| Step: 7
Training loss: 1.4015129804611206
Validation loss: 1.9901887434785084

Epoch: 6| Step: 8
Training loss: 1.0694966316223145
Validation loss: 1.9980701092750794

Epoch: 6| Step: 9
Training loss: 1.3818998336791992
Validation loss: 2.0082600885821926

Epoch: 6| Step: 10
Training loss: 1.243348240852356
Validation loss: 2.001201396347374

Epoch: 6| Step: 11
Training loss: 0.9897054433822632
Validation loss: 1.9838676798728205

Epoch: 6| Step: 12
Training loss: 1.3875715732574463
Validation loss: 2.0195722297955583

Epoch: 6| Step: 13
Training loss: 1.0721681118011475
Validation loss: 1.9931535567006757

Epoch: 386| Step: 0
Training loss: 1.1253124475479126
Validation loss: 2.0257191555474394

Epoch: 6| Step: 1
Training loss: 1.4662351608276367
Validation loss: 2.026058127803187

Epoch: 6| Step: 2
Training loss: 1.1174275875091553
Validation loss: 2.0353463080621537

Epoch: 6| Step: 3
Training loss: 1.0097790956497192
Validation loss: 2.043057859584849

Epoch: 6| Step: 4
Training loss: 0.9608507752418518
Validation loss: 2.0499310596014864

Epoch: 6| Step: 5
Training loss: 1.4253804683685303
Validation loss: 2.0259089393000447

Epoch: 6| Step: 6
Training loss: 1.3954098224639893
Validation loss: 2.028258373660426

Epoch: 6| Step: 7
Training loss: 1.2912282943725586
Validation loss: 2.032604093192726

Epoch: 6| Step: 8
Training loss: 1.1225422620773315
Validation loss: 1.985423905875093

Epoch: 6| Step: 9
Training loss: 1.7554290294647217
Validation loss: 1.9784777100368212

Epoch: 6| Step: 10
Training loss: 1.4864214658737183
Validation loss: 1.9658683640982515

Epoch: 6| Step: 11
Training loss: 1.3338474035263062
Validation loss: 1.9649390418042418

Epoch: 6| Step: 12
Training loss: 1.1341094970703125
Validation loss: 1.9508735723392938

Epoch: 6| Step: 13
Training loss: 1.5268102884292603
Validation loss: 1.9630054632822673

Epoch: 387| Step: 0
Training loss: 1.2489469051361084
Validation loss: 1.9696728132104362

Epoch: 6| Step: 1
Training loss: 1.370742917060852
Validation loss: 1.9641482618547255

Epoch: 6| Step: 2
Training loss: 1.440251350402832
Validation loss: 1.9710433842033468

Epoch: 6| Step: 3
Training loss: 1.5713138580322266
Validation loss: 1.976317697955716

Epoch: 6| Step: 4
Training loss: 1.3202686309814453
Validation loss: 1.983432303192795

Epoch: 6| Step: 5
Training loss: 1.9117329120635986
Validation loss: 2.0247771099049556

Epoch: 6| Step: 6
Training loss: 1.0341300964355469
Validation loss: 2.01516483676049

Epoch: 6| Step: 7
Training loss: 1.0312209129333496
Validation loss: 1.9866440783264816

Epoch: 6| Step: 8
Training loss: 0.8443712592124939
Validation loss: 2.0042832897555445

Epoch: 6| Step: 9
Training loss: 1.5278905630111694
Validation loss: 2.0114328104962587

Epoch: 6| Step: 10
Training loss: 1.1853079795837402
Validation loss: 1.9980709809128956

Epoch: 6| Step: 11
Training loss: 1.3083288669586182
Validation loss: 2.011386145827591

Epoch: 6| Step: 12
Training loss: 0.9772468209266663
Validation loss: 2.026911553516183

Epoch: 6| Step: 13
Training loss: 1.1456503868103027
Validation loss: 2.0239596623246388

Epoch: 388| Step: 0
Training loss: 1.251877784729004
Validation loss: 2.0367671853752545

Epoch: 6| Step: 1
Training loss: 0.9460933804512024
Validation loss: 2.0388854319049465

Epoch: 6| Step: 2
Training loss: 0.7353983521461487
Validation loss: 2.030189541078383

Epoch: 6| Step: 3
Training loss: 1.00374174118042
Validation loss: 2.0046449143399476

Epoch: 6| Step: 4
Training loss: 1.192057728767395
Validation loss: 1.9975967663590626

Epoch: 6| Step: 5
Training loss: 0.9357547163963318
Validation loss: 1.998593129137511

Epoch: 6| Step: 6
Training loss: 1.205640435218811
Validation loss: 1.9904794077719412

Epoch: 6| Step: 7
Training loss: 1.5707744359970093
Validation loss: 1.97691975614076

Epoch: 6| Step: 8
Training loss: 1.7100496292114258
Validation loss: 1.970070332609197

Epoch: 6| Step: 9
Training loss: 1.544692873954773
Validation loss: 1.9909763643818517

Epoch: 6| Step: 10
Training loss: 1.5126070976257324
Validation loss: 1.9813436359487555

Epoch: 6| Step: 11
Training loss: 1.3701759576797485
Validation loss: 1.981350923097262

Epoch: 6| Step: 12
Training loss: 1.1119552850723267
Validation loss: 1.9822437532486454

Epoch: 6| Step: 13
Training loss: 2.3154213428497314
Validation loss: 1.991299497183933

Epoch: 389| Step: 0
Training loss: 1.0669209957122803
Validation loss: 2.001485228538513

Epoch: 6| Step: 1
Training loss: 1.7641255855560303
Validation loss: 1.9775621173202351

Epoch: 6| Step: 2
Training loss: 0.9094616770744324
Validation loss: 1.9998267927477438

Epoch: 6| Step: 3
Training loss: 1.3043996095657349
Validation loss: 1.9983758452118083

Epoch: 6| Step: 4
Training loss: 0.6520822644233704
Validation loss: 2.0320615153158865

Epoch: 6| Step: 5
Training loss: 1.3235549926757812
Validation loss: 2.0156313155287053

Epoch: 6| Step: 6
Training loss: 1.5417848825454712
Validation loss: 1.9929068421804776

Epoch: 6| Step: 7
Training loss: 1.4556355476379395
Validation loss: 1.9958351465963549

Epoch: 6| Step: 8
Training loss: 0.8881547451019287
Validation loss: 1.9982683145871727

Epoch: 6| Step: 9
Training loss: 1.0724198818206787
Validation loss: 1.9870248225427443

Epoch: 6| Step: 10
Training loss: 1.9279305934906006
Validation loss: 2.0017336350615307

Epoch: 6| Step: 11
Training loss: 0.8969879150390625
Validation loss: 1.9851672739110968

Epoch: 6| Step: 12
Training loss: 1.714921236038208
Validation loss: 2.00214086937648

Epoch: 6| Step: 13
Training loss: 1.3824793100357056
Validation loss: 1.9961880586480583

Epoch: 390| Step: 0
Training loss: 1.9757959842681885
Validation loss: 1.961051893490617

Epoch: 6| Step: 1
Training loss: 0.9676219820976257
Validation loss: 1.9565704740503782

Epoch: 6| Step: 2
Training loss: 1.6199164390563965
Validation loss: 1.9501221385053409

Epoch: 6| Step: 3
Training loss: 0.8656938076019287
Validation loss: 1.9564220456666843

Epoch: 6| Step: 4
Training loss: 1.0147664546966553
Validation loss: 1.942060665417743

Epoch: 6| Step: 5
Training loss: 1.204145908355713
Validation loss: 1.9653511854910082

Epoch: 6| Step: 6
Training loss: 1.0926402807235718
Validation loss: 1.950295002229752

Epoch: 6| Step: 7
Training loss: 1.5433464050292969
Validation loss: 1.9552721413232947

Epoch: 6| Step: 8
Training loss: 1.5006513595581055
Validation loss: 1.9462987594707037

Epoch: 6| Step: 9
Training loss: 0.800610363483429
Validation loss: 1.976423018722124

Epoch: 6| Step: 10
Training loss: 1.2682254314422607
Validation loss: 1.9679604345752346

Epoch: 6| Step: 11
Training loss: 1.444250464439392
Validation loss: 1.976259441785915

Epoch: 6| Step: 12
Training loss: 1.3617957830429077
Validation loss: 1.958353909113074

Epoch: 6| Step: 13
Training loss: 0.9725924730300903
Validation loss: 1.9853051157407864

Epoch: 391| Step: 0
Training loss: 1.092678427696228
Validation loss: 2.000913809704524

Epoch: 6| Step: 1
Training loss: 1.2400660514831543
Validation loss: 1.9983026878808134

Epoch: 6| Step: 2
Training loss: 1.400192141532898
Validation loss: 2.00647065460041

Epoch: 6| Step: 3
Training loss: 1.9970498085021973
Validation loss: 2.018229733231247

Epoch: 6| Step: 4
Training loss: 0.8179687261581421
Validation loss: 2.0157340188180246

Epoch: 6| Step: 5
Training loss: 1.1118659973144531
Validation loss: 2.032492417161183

Epoch: 6| Step: 6
Training loss: 1.188129186630249
Validation loss: 2.013842059719947

Epoch: 6| Step: 7
Training loss: 1.0971941947937012
Validation loss: 2.0083638865460633

Epoch: 6| Step: 8
Training loss: 1.0128628015518188
Validation loss: 1.9799276205801195

Epoch: 6| Step: 9
Training loss: 1.3437591791152954
Validation loss: 1.9962219909955097

Epoch: 6| Step: 10
Training loss: 1.233941912651062
Validation loss: 1.986891733702793

Epoch: 6| Step: 11
Training loss: 1.602112054824829
Validation loss: 1.9817015368451354

Epoch: 6| Step: 12
Training loss: 0.9958488941192627
Validation loss: 1.9643271277027745

Epoch: 6| Step: 13
Training loss: 1.4885226488113403
Validation loss: 2.001542414388349

Epoch: 392| Step: 0
Training loss: 1.250982403755188
Validation loss: 1.987630492897444

Epoch: 6| Step: 1
Training loss: 1.2397470474243164
Validation loss: 1.9995315305648311

Epoch: 6| Step: 2
Training loss: 1.568274974822998
Validation loss: 1.9939091641415831

Epoch: 6| Step: 3
Training loss: 1.5797230005264282
Validation loss: 1.9829453076085737

Epoch: 6| Step: 4
Training loss: 1.0340540409088135
Validation loss: 1.9894877031285276

Epoch: 6| Step: 5
Training loss: 1.6330349445343018
Validation loss: 2.0259958877358386

Epoch: 6| Step: 6
Training loss: 1.3797597885131836
Validation loss: 2.0113562640323432

Epoch: 6| Step: 7
Training loss: 1.0895562171936035
Validation loss: 1.9866468419310868

Epoch: 6| Step: 8
Training loss: 1.0064804553985596
Validation loss: 1.988674718846557

Epoch: 6| Step: 9
Training loss: 1.0627615451812744
Validation loss: 1.984000869976577

Epoch: 6| Step: 10
Training loss: 0.8830468654632568
Validation loss: 1.9686728382623324

Epoch: 6| Step: 11
Training loss: 1.718956708908081
Validation loss: 1.9835107505962413

Epoch: 6| Step: 12
Training loss: 0.8925061821937561
Validation loss: 1.9674645675125944

Epoch: 6| Step: 13
Training loss: 1.1246613264083862
Validation loss: 1.963327967992393

Epoch: 393| Step: 0
Training loss: 1.3236981630325317
Validation loss: 1.9834690222176172

Epoch: 6| Step: 1
Training loss: 1.2108564376831055
Validation loss: 1.9548539987174414

Epoch: 6| Step: 2
Training loss: 1.0705478191375732
Validation loss: 1.9697096706718527

Epoch: 6| Step: 3
Training loss: 1.2929844856262207
Validation loss: 1.9611653820160897

Epoch: 6| Step: 4
Training loss: 1.6041276454925537
Validation loss: 1.9776874639654671

Epoch: 6| Step: 5
Training loss: 0.9626160860061646
Validation loss: 1.987160195586502

Epoch: 6| Step: 6
Training loss: 0.986117422580719
Validation loss: 1.998716467170305

Epoch: 6| Step: 7
Training loss: 1.2639524936676025
Validation loss: 1.994512673347227

Epoch: 6| Step: 8
Training loss: 1.1736793518066406
Validation loss: 2.010302943568076

Epoch: 6| Step: 9
Training loss: 1.542391300201416
Validation loss: 2.031549540899133

Epoch: 6| Step: 10
Training loss: 1.0822356939315796
Validation loss: 2.013899210960634

Epoch: 6| Step: 11
Training loss: 0.7740887403488159
Validation loss: 2.0057851742672663

Epoch: 6| Step: 12
Training loss: 1.4478665590286255
Validation loss: 2.0422657510285736

Epoch: 6| Step: 13
Training loss: 2.188993215560913
Validation loss: 2.0300250591770297

Epoch: 394| Step: 0
Training loss: 1.116510033607483
Validation loss: 2.0314464133272887

Epoch: 6| Step: 1
Training loss: 1.041194200515747
Validation loss: 2.0194797797869612

Epoch: 6| Step: 2
Training loss: 0.9061253666877747
Validation loss: 2.009506675504869

Epoch: 6| Step: 3
Training loss: 1.0524494647979736
Validation loss: 2.0030721067100443

Epoch: 6| Step: 4
Training loss: 1.6343436241149902
Validation loss: 1.9997654473909767

Epoch: 6| Step: 5
Training loss: 1.0508520603179932
Validation loss: 1.9885581103704308

Epoch: 6| Step: 6
Training loss: 1.8763885498046875
Validation loss: 1.9687033109767462

Epoch: 6| Step: 7
Training loss: 1.4861328601837158
Validation loss: 1.9984358638845465

Epoch: 6| Step: 8
Training loss: 0.929016649723053
Validation loss: 1.9896954797929334

Epoch: 6| Step: 9
Training loss: 1.784050464630127
Validation loss: 1.9904986222585042

Epoch: 6| Step: 10
Training loss: 0.8218726515769958
Validation loss: 1.964198814925327

Epoch: 6| Step: 11
Training loss: 1.1238062381744385
Validation loss: 1.961701262381769

Epoch: 6| Step: 12
Training loss: 1.6069988012313843
Validation loss: 1.9724905170420164

Epoch: 6| Step: 13
Training loss: 0.6695612668991089
Validation loss: 1.9692943698616439

Epoch: 395| Step: 0
Training loss: 1.5287878513336182
Validation loss: 1.9716391858234201

Epoch: 6| Step: 1
Training loss: 1.4921633005142212
Validation loss: 1.9561698270100418

Epoch: 6| Step: 2
Training loss: 1.356825828552246
Validation loss: 1.9647245150740429

Epoch: 6| Step: 3
Training loss: 1.5479469299316406
Validation loss: 1.9850599919596026

Epoch: 6| Step: 4
Training loss: 1.6059041023254395
Validation loss: 2.0037992564580773

Epoch: 6| Step: 5
Training loss: 0.53602534532547
Validation loss: 1.987410629949262

Epoch: 6| Step: 6
Training loss: 0.7666019201278687
Validation loss: 1.994891487142091

Epoch: 6| Step: 7
Training loss: 1.5907033681869507
Validation loss: 2.0093949328186693

Epoch: 6| Step: 8
Training loss: 0.67740797996521
Validation loss: 2.0624338952443932

Epoch: 6| Step: 9
Training loss: 1.3351757526397705
Validation loss: 2.0796566663249845

Epoch: 6| Step: 10
Training loss: 1.4214664697647095
Validation loss: 2.0466783738905385

Epoch: 6| Step: 11
Training loss: 1.1890867948532104
Validation loss: 2.029364553830957

Epoch: 6| Step: 12
Training loss: 1.203479528427124
Validation loss: 2.004527602144467

Epoch: 6| Step: 13
Training loss: 1.5462925434112549
Validation loss: 1.958473063284351

Epoch: 396| Step: 0
Training loss: 1.6161749362945557
Validation loss: 1.9571565248632943

Epoch: 6| Step: 1
Training loss: 0.8361623287200928
Validation loss: 1.9646866872746458

Epoch: 6| Step: 2
Training loss: 1.163711428642273
Validation loss: 1.9340808840208157

Epoch: 6| Step: 3
Training loss: 1.8536311388015747
Validation loss: 1.9237467653007918

Epoch: 6| Step: 4
Training loss: 1.447744607925415
Validation loss: 1.963858950522638

Epoch: 6| Step: 5
Training loss: 1.0965170860290527
Validation loss: 1.9526093121497863

Epoch: 6| Step: 6
Training loss: 1.5098505020141602
Validation loss: 1.947181893933204

Epoch: 6| Step: 7
Training loss: 2.067333698272705
Validation loss: 1.9596234201103129

Epoch: 6| Step: 8
Training loss: 1.1750352382659912
Validation loss: 1.9616132090168614

Epoch: 6| Step: 9
Training loss: 0.5213343501091003
Validation loss: 1.9713253705732283

Epoch: 6| Step: 10
Training loss: 0.8536760210990906
Validation loss: 1.9689234674617808

Epoch: 6| Step: 11
Training loss: 1.0644824504852295
Validation loss: 1.9806957731964767

Epoch: 6| Step: 12
Training loss: 0.8519765138626099
Validation loss: 1.9976490056642922

Epoch: 6| Step: 13
Training loss: 1.219475269317627
Validation loss: 2.0148477592775897

Epoch: 397| Step: 0
Training loss: 1.3669681549072266
Validation loss: 1.9969744900221467

Epoch: 6| Step: 1
Training loss: 1.4745891094207764
Validation loss: 2.0070271081821893

Epoch: 6| Step: 2
Training loss: 1.3973522186279297
Validation loss: 2.0075081612474177

Epoch: 6| Step: 3
Training loss: 1.1459565162658691
Validation loss: 2.020731981082629

Epoch: 6| Step: 4
Training loss: 1.1697041988372803
Validation loss: 2.003137042445521

Epoch: 6| Step: 5
Training loss: 1.3962042331695557
Validation loss: 2.0157128559645785

Epoch: 6| Step: 6
Training loss: 0.8725383877754211
Validation loss: 1.9919036460179154

Epoch: 6| Step: 7
Training loss: 1.0986459255218506
Validation loss: 1.9909738981595604

Epoch: 6| Step: 8
Training loss: 1.6111061573028564
Validation loss: 1.9793302512937976

Epoch: 6| Step: 9
Training loss: 1.414111614227295
Validation loss: 1.9875622872383363

Epoch: 6| Step: 10
Training loss: 0.6755132675170898
Validation loss: 1.9700301949695875

Epoch: 6| Step: 11
Training loss: 0.871674120426178
Validation loss: 1.9673985665844334

Epoch: 6| Step: 12
Training loss: 1.4099842309951782
Validation loss: 1.9415012149400608

Epoch: 6| Step: 13
Training loss: 1.3276324272155762
Validation loss: 1.9580228931160384

Epoch: 398| Step: 0
Training loss: 1.482597827911377
Validation loss: 1.987045273985914

Epoch: 6| Step: 1
Training loss: 1.5303723812103271
Validation loss: 1.9659536846222416

Epoch: 6| Step: 2
Training loss: 1.203305959701538
Validation loss: 1.9605350263657109

Epoch: 6| Step: 3
Training loss: 1.2587593793869019
Validation loss: 1.9957843647208264

Epoch: 6| Step: 4
Training loss: 1.0896015167236328
Validation loss: 1.959550012824356

Epoch: 6| Step: 5
Training loss: 0.5975564122200012
Validation loss: 1.9995537855291878

Epoch: 6| Step: 6
Training loss: 0.9733306169509888
Validation loss: 1.9862949925084268

Epoch: 6| Step: 7
Training loss: 1.638207197189331
Validation loss: 1.9735986263521257

Epoch: 6| Step: 8
Training loss: 2.011261463165283
Validation loss: 2.017752899918505

Epoch: 6| Step: 9
Training loss: 0.9790594577789307
Validation loss: 1.9835489321780462

Epoch: 6| Step: 10
Training loss: 1.1019800901412964
Validation loss: 2.004419840792174

Epoch: 6| Step: 11
Training loss: 0.8791496157646179
Validation loss: 1.9954130662384855

Epoch: 6| Step: 12
Training loss: 0.9755558371543884
Validation loss: 2.01218980614857

Epoch: 6| Step: 13
Training loss: 1.508048176765442
Validation loss: 2.0002376264141453

Epoch: 399| Step: 0
Training loss: 0.7998005151748657
Validation loss: 2.002515169882005

Epoch: 6| Step: 1
Training loss: 0.9371767044067383
Validation loss: 2.011679764716856

Epoch: 6| Step: 2
Training loss: 0.8169695138931274
Validation loss: 2.0005607348616405

Epoch: 6| Step: 3
Training loss: 1.2734733819961548
Validation loss: 2.0167618054215626

Epoch: 6| Step: 4
Training loss: 1.425976276397705
Validation loss: 2.011426660322374

Epoch: 6| Step: 5
Training loss: 1.9399032592773438
Validation loss: 2.006184821487755

Epoch: 6| Step: 6
Training loss: 1.014955759048462
Validation loss: 1.9778190710211312

Epoch: 6| Step: 7
Training loss: 1.5216624736785889
Validation loss: 1.9705824903262559

Epoch: 6| Step: 8
Training loss: 0.9273432493209839
Validation loss: 1.9671408925005185

Epoch: 6| Step: 9
Training loss: 1.398958444595337
Validation loss: 1.9756292566176383

Epoch: 6| Step: 10
Training loss: 1.3059628009796143
Validation loss: 1.9817258491311023

Epoch: 6| Step: 11
Training loss: 1.2737884521484375
Validation loss: 1.9460825292013024

Epoch: 6| Step: 12
Training loss: 0.9640236496925354
Validation loss: 1.93959980241714

Epoch: 6| Step: 13
Training loss: 1.5200631618499756
Validation loss: 1.968539858377108

Epoch: 400| Step: 0
Training loss: 1.1007094383239746
Validation loss: 1.9347054701979443

Epoch: 6| Step: 1
Training loss: 1.7862056493759155
Validation loss: 1.9718642920576117

Epoch: 6| Step: 2
Training loss: 1.6035947799682617
Validation loss: 1.9650774360984884

Epoch: 6| Step: 3
Training loss: 1.244325876235962
Validation loss: 1.9794026267143987

Epoch: 6| Step: 4
Training loss: 1.474177360534668
Validation loss: 1.9775770735997025

Epoch: 6| Step: 5
Training loss: 1.261183500289917
Validation loss: 1.9824078467584425

Epoch: 6| Step: 6
Training loss: 0.9923044443130493
Validation loss: 2.0248719684539305

Epoch: 6| Step: 7
Training loss: 0.9856452941894531
Validation loss: 2.0293627246733634

Epoch: 6| Step: 8
Training loss: 1.3900048732757568
Validation loss: 2.033402589059645

Epoch: 6| Step: 9
Training loss: 1.2393709421157837
Validation loss: 2.0060499970630934

Epoch: 6| Step: 10
Training loss: 0.7321716547012329
Validation loss: 2.0166039633494552

Epoch: 6| Step: 11
Training loss: 1.0817036628723145
Validation loss: 2.024139873443111

Epoch: 6| Step: 12
Training loss: 0.6549432277679443
Validation loss: 1.981349040103215

Epoch: 6| Step: 13
Training loss: 1.6695685386657715
Validation loss: 1.9700307897342149

Testing loss: 2.1938483715057373
