Epoch: 1| Step: 0
Training loss: 6.516696320423193
Validation loss: 5.790554662566523

Epoch: 5| Step: 1
Training loss: 5.918162770128114
Validation loss: 5.784508201349098

Epoch: 5| Step: 2
Training loss: 5.357856201634435
Validation loss: 5.778547635954161

Epoch: 5| Step: 3
Training loss: 5.555577117030371
Validation loss: 5.772677405212858

Epoch: 5| Step: 4
Training loss: 5.166874707043054
Validation loss: 5.76668150486917

Epoch: 5| Step: 5
Training loss: 6.589375423303659
Validation loss: 5.759732801849543

Epoch: 5| Step: 6
Training loss: 6.846254212839761
Validation loss: 5.752044645918752

Epoch: 5| Step: 7
Training loss: 5.471147981511349
Validation loss: 5.743644608392549

Epoch: 5| Step: 8
Training loss: 5.481908868666128
Validation loss: 5.734259414547374

Epoch: 5| Step: 9
Training loss: 5.626560079610612
Validation loss: 5.723994742792971

Epoch: 5| Step: 10
Training loss: 4.6694494987327815
Validation loss: 5.712234516104572

Epoch: 2| Step: 0
Training loss: 5.073470861514985
Validation loss: 5.700331115316461

Epoch: 5| Step: 1
Training loss: 5.5729316877596435
Validation loss: 5.686907384325433

Epoch: 5| Step: 2
Training loss: 5.742595050906965
Validation loss: 5.673355477474953

Epoch: 5| Step: 3
Training loss: 6.342647362704863
Validation loss: 5.658252626916044

Epoch: 5| Step: 4
Training loss: 5.827512979971669
Validation loss: 5.641815457152911

Epoch: 5| Step: 5
Training loss: 5.028226903780142
Validation loss: 5.623852928908249

Epoch: 5| Step: 6
Training loss: 6.023879216841237
Validation loss: 5.605623791925006

Epoch: 5| Step: 7
Training loss: 5.432122915200348
Validation loss: 5.584939707520762

Epoch: 5| Step: 8
Training loss: 6.320130825378723
Validation loss: 5.563127523552408

Epoch: 5| Step: 9
Training loss: 5.802234403423014
Validation loss: 5.539534815716438

Epoch: 5| Step: 10
Training loss: 4.663278689569891
Validation loss: 5.514315757732774

Epoch: 3| Step: 0
Training loss: 5.6861003788458175
Validation loss: 5.487307728937803

Epoch: 5| Step: 1
Training loss: 5.304697028307441
Validation loss: 5.459031558316731

Epoch: 5| Step: 2
Training loss: 5.453191106444758
Validation loss: 5.428372773782354

Epoch: 5| Step: 3
Training loss: 5.643076187076462
Validation loss: 5.394943455962957

Epoch: 5| Step: 4
Training loss: 5.53530424858378
Validation loss: 5.359005890963178

Epoch: 5| Step: 5
Training loss: 5.503288499698438
Validation loss: 5.322041894327708

Epoch: 5| Step: 6
Training loss: 4.654578196819516
Validation loss: 5.27998241404541

Epoch: 5| Step: 7
Training loss: 4.635796806378521
Validation loss: 5.239260273747343

Epoch: 5| Step: 8
Training loss: 4.933781636119515
Validation loss: 5.1985304193071595

Epoch: 5| Step: 9
Training loss: 5.824363169424251
Validation loss: 5.154626437943933

Epoch: 5| Step: 10
Training loss: 5.70386907870798
Validation loss: 5.110180086437837

Epoch: 4| Step: 0
Training loss: 5.038439808304183
Validation loss: 5.066205095796961

Epoch: 5| Step: 1
Training loss: 4.936029529106064
Validation loss: 5.022215521426795

Epoch: 5| Step: 2
Training loss: 5.338243826644673
Validation loss: 4.97694686209229

Epoch: 5| Step: 3
Training loss: 5.21242134894808
Validation loss: 4.928837650291566

Epoch: 5| Step: 4
Training loss: 5.407321360719714
Validation loss: 4.885070955770856

Epoch: 5| Step: 5
Training loss: 4.4098597681149085
Validation loss: 4.838123887333551

Epoch: 5| Step: 6
Training loss: 5.460431731764955
Validation loss: 4.791486454054198

Epoch: 5| Step: 7
Training loss: 5.712494310505577
Validation loss: 4.744522770954787

Epoch: 5| Step: 8
Training loss: 3.7459395996454474
Validation loss: 4.69897206501952

Epoch: 5| Step: 9
Training loss: 3.486508798058308
Validation loss: 4.656531307325414

Epoch: 5| Step: 10
Training loss: 4.91594636888791
Validation loss: 4.617387485942965

Epoch: 5| Step: 0
Training loss: 5.091539710793476
Validation loss: 4.581762825981992

Epoch: 5| Step: 1
Training loss: 3.8931101020629595
Validation loss: 4.548842056741917

Epoch: 5| Step: 2
Training loss: 4.713607107589864
Validation loss: 4.516841971542413

Epoch: 5| Step: 3
Training loss: 5.121928899829363
Validation loss: 4.483210360366174

Epoch: 5| Step: 4
Training loss: 4.752699837614402
Validation loss: 4.450386180069664

Epoch: 5| Step: 5
Training loss: 3.9231713572740046
Validation loss: 4.421233071998071

Epoch: 5| Step: 6
Training loss: 3.665117774725978
Validation loss: 4.394245300396533

Epoch: 5| Step: 7
Training loss: 4.711913151716233
Validation loss: 4.369929965306483

Epoch: 5| Step: 8
Training loss: 4.682152508063428
Validation loss: 4.34576450984343

Epoch: 5| Step: 9
Training loss: 4.326666300400854
Validation loss: 4.320853362312562

Epoch: 5| Step: 10
Training loss: 4.836470714747415
Validation loss: 4.297674470660312

Epoch: 6| Step: 0
Training loss: 4.865144989895478
Validation loss: 4.27288398563185

Epoch: 5| Step: 1
Training loss: 4.746063006266167
Validation loss: 4.247457338433813

Epoch: 5| Step: 2
Training loss: 3.7224611629512236
Validation loss: 4.223137359305544

Epoch: 5| Step: 3
Training loss: 4.443179082880728
Validation loss: 4.198342614394063

Epoch: 5| Step: 4
Training loss: 4.04053463108293
Validation loss: 4.173556730066603

Epoch: 5| Step: 5
Training loss: 4.588263940218285
Validation loss: 4.153433380212434

Epoch: 5| Step: 6
Training loss: 4.259176333321982
Validation loss: 4.129224054467081

Epoch: 5| Step: 7
Training loss: 3.192993665746851
Validation loss: 4.10721200349639

Epoch: 5| Step: 8
Training loss: 4.089844216362199
Validation loss: 4.088143721992369

Epoch: 5| Step: 9
Training loss: 5.051198707552368
Validation loss: 4.06605576487924

Epoch: 5| Step: 10
Training loss: 3.798686282297273
Validation loss: 4.049179079429607

Epoch: 7| Step: 0
Training loss: 3.106549076288851
Validation loss: 4.028984054300981

Epoch: 5| Step: 1
Training loss: 4.746370836497472
Validation loss: 4.012564174622052

Epoch: 5| Step: 2
Training loss: 4.786846002674445
Validation loss: 3.996001850099866

Epoch: 5| Step: 3
Training loss: 4.485029113062649
Validation loss: 3.9829801675170526

Epoch: 5| Step: 4
Training loss: 3.2254293821283206
Validation loss: 3.96480067761287

Epoch: 5| Step: 5
Training loss: 4.01286844718818
Validation loss: 3.9518009023875433

Epoch: 5| Step: 6
Training loss: 4.039741031164863
Validation loss: 3.9386951229902265

Epoch: 5| Step: 7
Training loss: 3.9433221309843476
Validation loss: 3.923601077332503

Epoch: 5| Step: 8
Training loss: 4.515210406532434
Validation loss: 3.910525378142584

Epoch: 5| Step: 9
Training loss: 3.849980832337064
Validation loss: 3.898507363564738

Epoch: 5| Step: 10
Training loss: 4.100323706152876
Validation loss: 3.886966745271991

Epoch: 8| Step: 0
Training loss: 3.974234208530052
Validation loss: 3.877720095456011

Epoch: 5| Step: 1
Training loss: 2.521815106178194
Validation loss: 3.8656842805928795

Epoch: 5| Step: 2
Training loss: 4.27466338321451
Validation loss: 3.857096592999566

Epoch: 5| Step: 3
Training loss: 4.446480059694932
Validation loss: 3.850573789670662

Epoch: 5| Step: 4
Training loss: 3.716689620923605
Validation loss: 3.8419501379796808

Epoch: 5| Step: 5
Training loss: 4.496571824468884
Validation loss: 3.8329794953601803

Epoch: 5| Step: 6
Training loss: 4.356021151558742
Validation loss: 3.823236978733972

Epoch: 5| Step: 7
Training loss: 3.7327388227623857
Validation loss: 3.8114755425119906

Epoch: 5| Step: 8
Training loss: 3.6125054593688475
Validation loss: 3.801617162122058

Epoch: 5| Step: 9
Training loss: 3.966788700908614
Validation loss: 3.7908659428364935

Epoch: 5| Step: 10
Training loss: 4.544644047696549
Validation loss: 3.7835004010612616

Epoch: 9| Step: 0
Training loss: 4.202215046568586
Validation loss: 3.7727852524319765

Epoch: 5| Step: 1
Training loss: 3.7201927656046045
Validation loss: 3.7595062139944857

Epoch: 5| Step: 2
Training loss: 4.204159067006547
Validation loss: 3.750165772961239

Epoch: 5| Step: 3
Training loss: 3.0531282860260913
Validation loss: 3.7439895823572775

Epoch: 5| Step: 4
Training loss: 3.660809274431298
Validation loss: 3.7400956456635592

Epoch: 5| Step: 5
Training loss: 4.242741164016357
Validation loss: 3.728722964878086

Epoch: 5| Step: 6
Training loss: 4.334557115927226
Validation loss: 3.7191005895523728

Epoch: 5| Step: 7
Training loss: 3.215967549724933
Validation loss: 3.7109339767465235

Epoch: 5| Step: 8
Training loss: 3.9116230137169956
Validation loss: 3.7054070002259745

Epoch: 5| Step: 9
Training loss: 4.444799732206596
Validation loss: 3.696240489983729

Epoch: 5| Step: 10
Training loss: 3.7489649297824554
Validation loss: 3.6889939977673727

Epoch: 10| Step: 0
Training loss: 3.8910811436451263
Validation loss: 3.677472863836185

Epoch: 5| Step: 1
Training loss: 3.907107327793599
Validation loss: 3.6670621708051785

Epoch: 5| Step: 2
Training loss: 3.4402429907387573
Validation loss: 3.6567334392858206

Epoch: 5| Step: 3
Training loss: 3.94027793620432
Validation loss: 3.65021682743654

Epoch: 5| Step: 4
Training loss: 3.784392887139357
Validation loss: 3.6446590973788884

Epoch: 5| Step: 5
Training loss: 3.902337151599151
Validation loss: 3.635087382158075

Epoch: 5| Step: 6
Training loss: 3.792326789375751
Validation loss: 3.6243946021113853

Epoch: 5| Step: 7
Training loss: 3.887001771063336
Validation loss: 3.617227208991896

Epoch: 5| Step: 8
Training loss: 3.920287278216993
Validation loss: 3.605890006550828

Epoch: 5| Step: 9
Training loss: 4.101311376240874
Validation loss: 3.600974793099021

Epoch: 5| Step: 10
Training loss: 3.407150009664161
Validation loss: 3.5921758898645497

Epoch: 11| Step: 0
Training loss: 2.5018156134451592
Validation loss: 3.587261236854354

Epoch: 5| Step: 1
Training loss: 4.5014798592075875
Validation loss: 3.586504259869459

Epoch: 5| Step: 2
Training loss: 3.7887064658356864
Validation loss: 3.5761381734762296

Epoch: 5| Step: 3
Training loss: 3.689584304634252
Validation loss: 3.570432541974949

Epoch: 5| Step: 4
Training loss: 3.3097323965824343
Validation loss: 3.5583765863637673

Epoch: 5| Step: 5
Training loss: 4.025732478433588
Validation loss: 3.557711849381124

Epoch: 5| Step: 6
Training loss: 4.0021080184458535
Validation loss: 3.5567852520941856

Epoch: 5| Step: 7
Training loss: 4.1865137561484165
Validation loss: 3.5491715271720805

Epoch: 5| Step: 8
Training loss: 3.5987712776532916
Validation loss: 3.5424794740445726

Epoch: 5| Step: 9
Training loss: 3.466183924686608
Validation loss: 3.5338802330186296

Epoch: 5| Step: 10
Training loss: 3.953084108646278
Validation loss: 3.528026056896432

Epoch: 12| Step: 0
Training loss: 3.7408019110864825
Validation loss: 3.5225043183707836

Epoch: 5| Step: 1
Training loss: 4.49881834834127
Validation loss: 3.5204929047182234

Epoch: 5| Step: 2
Training loss: 4.153817519064776
Validation loss: 3.5169884491374717

Epoch: 5| Step: 3
Training loss: 3.224525381250111
Validation loss: 3.5076904041758183

Epoch: 5| Step: 4
Training loss: 3.3606860064516533
Validation loss: 3.5008482732780477

Epoch: 5| Step: 5
Training loss: 3.452857650142623
Validation loss: 3.495592453627544

Epoch: 5| Step: 6
Training loss: 3.438381151491517
Validation loss: 3.49497936602933

Epoch: 5| Step: 7
Training loss: 3.689701134588742
Validation loss: 3.4884853104230666

Epoch: 5| Step: 8
Training loss: 3.5637725431170137
Validation loss: 3.486170405456252

Epoch: 5| Step: 9
Training loss: 3.6107364085189326
Validation loss: 3.4813491468125517

Epoch: 5| Step: 10
Training loss: 3.9556534110929644
Validation loss: 3.4749712323951334

Epoch: 13| Step: 0
Training loss: 4.773199746661898
Validation loss: 3.4702228115893345

Epoch: 5| Step: 1
Training loss: 4.19813167251754
Validation loss: 3.463711917951012

Epoch: 5| Step: 2
Training loss: 3.8382372517609777
Validation loss: 3.456990961593575

Epoch: 5| Step: 3
Training loss: 3.812373299916665
Validation loss: 3.4540364069522034

Epoch: 5| Step: 4
Training loss: 3.196522527898451
Validation loss: 3.45601151697666

Epoch: 5| Step: 5
Training loss: 4.042514882434823
Validation loss: 3.4500739492867365

Epoch: 5| Step: 6
Training loss: 3.472183452813615
Validation loss: 3.4444834766719077

Epoch: 5| Step: 7
Training loss: 2.757596966585373
Validation loss: 3.440770434274107

Epoch: 5| Step: 8
Training loss: 3.3301406988714133
Validation loss: 3.4369891535685966

Epoch: 5| Step: 9
Training loss: 2.9996595189478183
Validation loss: 3.436806899194592

Epoch: 5| Step: 10
Training loss: 3.4780953103552292
Validation loss: 3.430684832126765

Epoch: 14| Step: 0
Training loss: 3.8222677457917595
Validation loss: 3.42774696680839

Epoch: 5| Step: 1
Training loss: 3.8713877669231644
Validation loss: 3.4230904931333273

Epoch: 5| Step: 2
Training loss: 3.782837967784919
Validation loss: 3.4218481143980233

Epoch: 5| Step: 3
Training loss: 4.291998964549541
Validation loss: 3.418055007432129

Epoch: 5| Step: 4
Training loss: 3.198801686509224
Validation loss: 3.4199465224052417

Epoch: 5| Step: 5
Training loss: 3.318213232278873
Validation loss: 3.419481998386653

Epoch: 5| Step: 6
Training loss: 3.8963810880734053
Validation loss: 3.4133397776760934

Epoch: 5| Step: 7
Training loss: 3.3189226181052645
Validation loss: 3.4071693350120795

Epoch: 5| Step: 8
Training loss: 3.473459020111233
Validation loss: 3.406162532915065

Epoch: 5| Step: 9
Training loss: 2.9477998061095354
Validation loss: 3.404815955998851

Epoch: 5| Step: 10
Training loss: 3.951715632767715
Validation loss: 3.406192921685877

Epoch: 15| Step: 0
Training loss: 3.0274732205177552
Validation loss: 3.395467694833541

Epoch: 5| Step: 1
Training loss: 3.0951887696216986
Validation loss: 3.3960469914319553

Epoch: 5| Step: 2
Training loss: 3.833199014936526
Validation loss: 3.397529563935451

Epoch: 5| Step: 3
Training loss: 4.562733683415183
Validation loss: 3.3900251399003523

Epoch: 5| Step: 4
Training loss: 3.517589376326745
Validation loss: 3.387096768236136

Epoch: 5| Step: 5
Training loss: 3.063795166180745
Validation loss: 3.386256794899956

Epoch: 5| Step: 6
Training loss: 3.498154289773193
Validation loss: 3.382460362066373

Epoch: 5| Step: 7
Training loss: 3.8168076740409225
Validation loss: 3.381743211625625

Epoch: 5| Step: 8
Training loss: 4.1380584247754975
Validation loss: 3.37889514840421

Epoch: 5| Step: 9
Training loss: 3.708421870399842
Validation loss: 3.3792322376534676

Epoch: 5| Step: 10
Training loss: 3.1195350163544755
Validation loss: 3.3808338716468165

Epoch: 16| Step: 0
Training loss: 4.008499889654039
Validation loss: 3.37724055120454

Epoch: 5| Step: 1
Training loss: 3.7139765773233866
Validation loss: 3.3718808374051497

Epoch: 5| Step: 2
Training loss: 3.6081047960697297
Validation loss: 3.3699006509655804

Epoch: 5| Step: 3
Training loss: 3.9669435249541656
Validation loss: 3.364721721237723

Epoch: 5| Step: 4
Training loss: 3.1039646944909016
Validation loss: 3.3644750429022388

Epoch: 5| Step: 5
Training loss: 3.44844559745028
Validation loss: 3.3608255515619954

Epoch: 5| Step: 6
Training loss: 2.6033542637425255
Validation loss: 3.357456429607859

Epoch: 5| Step: 7
Training loss: 3.958140934066227
Validation loss: 3.3592108497283606

Epoch: 5| Step: 8
Training loss: 3.2322604873797482
Validation loss: 3.3552365307263723

Epoch: 5| Step: 9
Training loss: 4.265066480576854
Validation loss: 3.3491430147305734

Epoch: 5| Step: 10
Training loss: 3.2625096989629987
Validation loss: 3.366222635356276

Epoch: 17| Step: 0
Training loss: 4.013200436120592
Validation loss: 3.391825224277368

Epoch: 5| Step: 1
Training loss: 3.896753838191972
Validation loss: 3.334158209801203

Epoch: 5| Step: 2
Training loss: 3.3379129104361382
Validation loss: 3.336595457760666

Epoch: 5| Step: 3
Training loss: 3.040357299186046
Validation loss: 3.3376201725834993

Epoch: 5| Step: 4
Training loss: 4.375191384625318
Validation loss: 3.3281102172208974

Epoch: 5| Step: 5
Training loss: 3.4470844167139494
Validation loss: 3.3279672566329266

Epoch: 5| Step: 6
Training loss: 3.4995785868214697
Validation loss: 3.3324035229602633

Epoch: 5| Step: 7
Training loss: 3.4214846593057735
Validation loss: 3.3286691171078924

Epoch: 5| Step: 8
Training loss: 3.653139927216014
Validation loss: 3.3251385667541533

Epoch: 5| Step: 9
Training loss: 3.3316724613120856
Validation loss: 3.3218826602091966

Epoch: 5| Step: 10
Training loss: 2.995138520872834
Validation loss: 3.3231951601713408

Epoch: 18| Step: 0
Training loss: 3.1934368719094177
Validation loss: 3.3230976558595295

Epoch: 5| Step: 1
Training loss: 3.4026046985715532
Validation loss: 3.320349003532638

Epoch: 5| Step: 2
Training loss: 3.7458025010607705
Validation loss: 3.322237725720766

Epoch: 5| Step: 3
Training loss: 3.8546593153610864
Validation loss: 3.3165180086927584

Epoch: 5| Step: 4
Training loss: 3.809803744089903
Validation loss: 3.3117507354957687

Epoch: 5| Step: 5
Training loss: 2.93476870559618
Validation loss: 3.3071385042038046

Epoch: 5| Step: 6
Training loss: 3.9759891598820425
Validation loss: 3.3038011867965165

Epoch: 5| Step: 7
Training loss: 3.722460522464757
Validation loss: 3.2979398391033192

Epoch: 5| Step: 8
Training loss: 3.5140907839412403
Validation loss: 3.2943902176892847

Epoch: 5| Step: 9
Training loss: 2.9587473154317703
Validation loss: 3.29628798474524

Epoch: 5| Step: 10
Training loss: 3.7913914395445327
Validation loss: 3.293737752690498

Epoch: 19| Step: 0
Training loss: 3.6280896404426
Validation loss: 3.2879147848779313

Epoch: 5| Step: 1
Training loss: 3.796801907813055
Validation loss: 3.2837475773385245

Epoch: 5| Step: 2
Training loss: 3.88791988349912
Validation loss: 3.2785564142833983

Epoch: 5| Step: 3
Training loss: 4.37830075681078
Validation loss: 3.2789489099849103

Epoch: 5| Step: 4
Training loss: 2.8284579760710433
Validation loss: 3.276614548017853

Epoch: 5| Step: 5
Training loss: 3.4996765532221477
Validation loss: 3.281241949474891

Epoch: 5| Step: 6
Training loss: 3.5237501052255604
Validation loss: 3.2695214518671993

Epoch: 5| Step: 7
Training loss: 3.3935865837080166
Validation loss: 3.26023537039592

Epoch: 5| Step: 8
Training loss: 2.9644595011523043
Validation loss: 3.253339945993036

Epoch: 5| Step: 9
Training loss: 3.3480322681180024
Validation loss: 3.250507633771649

Epoch: 5| Step: 10
Training loss: 3.1221880659389813
Validation loss: 3.2455141963740357

Epoch: 20| Step: 0
Training loss: 3.659992617406852
Validation loss: 3.239996972945407

Epoch: 5| Step: 1
Training loss: 3.0315900788813894
Validation loss: 3.2392941103688777

Epoch: 5| Step: 2
Training loss: 3.815206223859808
Validation loss: 3.234836907813088

Epoch: 5| Step: 3
Training loss: 3.5958360008209223
Validation loss: 3.2360085072903146

Epoch: 5| Step: 4
Training loss: 3.554406861346395
Validation loss: 3.2312670881102323

Epoch: 5| Step: 5
Training loss: 2.891753765044058
Validation loss: 3.2324191007276006

Epoch: 5| Step: 6
Training loss: 3.793589233813058
Validation loss: 3.2308138110172617

Epoch: 5| Step: 7
Training loss: 3.4659525270199047
Validation loss: 3.2292548308839293

Epoch: 5| Step: 8
Training loss: 3.658946420540513
Validation loss: 3.227814057190121

Epoch: 5| Step: 9
Training loss: 3.3515053057292112
Validation loss: 3.227976909236528

Epoch: 5| Step: 10
Training loss: 3.4168949206022563
Validation loss: 3.227438511835949

Epoch: 21| Step: 0
Training loss: 3.315989114253418
Validation loss: 3.2230373557213947

Epoch: 5| Step: 1
Training loss: 4.018227531678351
Validation loss: 3.2220917417052872

Epoch: 5| Step: 2
Training loss: 3.349012280509715
Validation loss: 3.2157391664408332

Epoch: 5| Step: 3
Training loss: 3.941639132467373
Validation loss: 3.2155062942297983

Epoch: 5| Step: 4
Training loss: 4.003111582725368
Validation loss: 3.2120294720391214

Epoch: 5| Step: 5
Training loss: 2.9293904471798924
Validation loss: 3.2143545240403033

Epoch: 5| Step: 6
Training loss: 3.591461514472419
Validation loss: 3.215332198288021

Epoch: 5| Step: 7
Training loss: 3.7504930807827153
Validation loss: 3.21326799028923

Epoch: 5| Step: 8
Training loss: 2.8415453402962747
Validation loss: 3.210904099194113

Epoch: 5| Step: 9
Training loss: 2.9986217829781525
Validation loss: 3.2094941763251095

Epoch: 5| Step: 10
Training loss: 3.148004468951028
Validation loss: 3.2096289080538614

Epoch: 22| Step: 0
Training loss: 3.865795771312241
Validation loss: 3.210131943433284

Epoch: 5| Step: 1
Training loss: 3.2237938924747076
Validation loss: 3.207243550638044

Epoch: 5| Step: 2
Training loss: 3.2946825014004277
Validation loss: 3.2020594127241737

Epoch: 5| Step: 3
Training loss: 3.5942708840411863
Validation loss: 3.201829214288003

Epoch: 5| Step: 4
Training loss: 2.565834481054357
Validation loss: 3.200601735919782

Epoch: 5| Step: 5
Training loss: 3.6952533999469286
Validation loss: 3.2014653966503896

Epoch: 5| Step: 6
Training loss: 3.350249488991644
Validation loss: 3.198905979919144

Epoch: 5| Step: 7
Training loss: 3.2828779269438777
Validation loss: 3.196621869636567

Epoch: 5| Step: 8
Training loss: 3.8704436802415025
Validation loss: 3.1972975566337234

Epoch: 5| Step: 9
Training loss: 3.6718809736487312
Validation loss: 3.2034403359868766

Epoch: 5| Step: 10
Training loss: 3.4902529553226755
Validation loss: 3.236583290143544

Epoch: 23| Step: 0
Training loss: 3.3518091924617215
Validation loss: 3.1875679407795166

Epoch: 5| Step: 1
Training loss: 3.555991803334662
Validation loss: 3.1911962071548805

Epoch: 5| Step: 2
Training loss: 3.550122492651428
Validation loss: 3.198275218756416

Epoch: 5| Step: 3
Training loss: 2.6329336619584485
Validation loss: 3.202423459074056

Epoch: 5| Step: 4
Training loss: 3.0199380183648845
Validation loss: 3.209403796072339

Epoch: 5| Step: 5
Training loss: 4.128010893637307
Validation loss: 3.2088472066403533

Epoch: 5| Step: 6
Training loss: 3.3608293091169523
Validation loss: 3.197086347619155

Epoch: 5| Step: 7
Training loss: 3.319626824881033
Validation loss: 3.1945231680482844

Epoch: 5| Step: 8
Training loss: 3.0261105098980168
Validation loss: 3.193499201071303

Epoch: 5| Step: 9
Training loss: 3.8697284404095655
Validation loss: 3.2042463043219

Epoch: 5| Step: 10
Training loss: 4.05938108001794
Validation loss: 3.2026618412571777

Epoch: 24| Step: 0
Training loss: 3.551698337546788
Validation loss: 3.195314083765394

Epoch: 5| Step: 1
Training loss: 3.116378794004305
Validation loss: 3.1858346333710466

Epoch: 5| Step: 2
Training loss: 3.502045442435576
Validation loss: 3.17802314004196

Epoch: 5| Step: 3
Training loss: 3.9415969121996377
Validation loss: 3.176889145657669

Epoch: 5| Step: 4
Training loss: 3.226822886455307
Validation loss: 3.1699746156908453

Epoch: 5| Step: 5
Training loss: 3.3625758336247884
Validation loss: 3.1792302508986987

Epoch: 5| Step: 6
Training loss: 3.22670481370282
Validation loss: 3.180281669324911

Epoch: 5| Step: 7
Training loss: 3.3547298519337687
Validation loss: 3.1613450895796964

Epoch: 5| Step: 8
Training loss: 3.7372282611975876
Validation loss: 3.1619788857291384

Epoch: 5| Step: 9
Training loss: 3.2396269833158002
Validation loss: 3.1612350212816045

Epoch: 5| Step: 10
Training loss: 3.4978500302306235
Validation loss: 3.161986425890014

Epoch: 25| Step: 0
Training loss: 3.9768234197307213
Validation loss: 3.1603083616832692

Epoch: 5| Step: 1
Training loss: 3.2530368408218404
Validation loss: 3.1547881804128446

Epoch: 5| Step: 2
Training loss: 3.293222872339778
Validation loss: 3.154896919142663

Epoch: 5| Step: 3
Training loss: 3.231137927120591
Validation loss: 3.152492408425499

Epoch: 5| Step: 4
Training loss: 3.753928860249936
Validation loss: 3.1500089027707388

Epoch: 5| Step: 5
Training loss: 3.1083745065643362
Validation loss: 3.1484434277931537

Epoch: 5| Step: 6
Training loss: 3.3495112902457707
Validation loss: 3.149925886344539

Epoch: 5| Step: 7
Training loss: 3.277733507952975
Validation loss: 3.150610996322323

Epoch: 5| Step: 8
Training loss: 3.3830891907898843
Validation loss: 3.1444591622231797

Epoch: 5| Step: 9
Training loss: 3.6869281390030983
Validation loss: 3.144278946557452

Epoch: 5| Step: 10
Training loss: 3.1895350523387664
Validation loss: 3.1458007320764865

Epoch: 26| Step: 0
Training loss: 3.2760957471854457
Validation loss: 3.1450583330398487

Epoch: 5| Step: 1
Training loss: 3.323052924699883
Validation loss: 3.144356472544322

Epoch: 5| Step: 2
Training loss: 3.5208037486140693
Validation loss: 3.142819208637491

Epoch: 5| Step: 3
Training loss: 3.525868053284865
Validation loss: 3.1422663671638427

Epoch: 5| Step: 4
Training loss: 3.840956874876447
Validation loss: 3.1390622934101162

Epoch: 5| Step: 5
Training loss: 2.471234290883945
Validation loss: 3.1396096901076795

Epoch: 5| Step: 6
Training loss: 3.043082513017068
Validation loss: 3.1378374866789334

Epoch: 5| Step: 7
Training loss: 3.6763107453547956
Validation loss: 3.135358598459133

Epoch: 5| Step: 8
Training loss: 3.560570713116169
Validation loss: 3.136265602807867

Epoch: 5| Step: 9
Training loss: 3.544383917729879
Validation loss: 3.137582159427194

Epoch: 5| Step: 10
Training loss: 3.5619356478019126
Validation loss: 3.137471084255572

Epoch: 27| Step: 0
Training loss: 3.367458819369063
Validation loss: 3.1355831314773233

Epoch: 5| Step: 1
Training loss: 3.5114739219178435
Validation loss: 3.1303934720909994

Epoch: 5| Step: 2
Training loss: 2.484266170781142
Validation loss: 3.129460638172414

Epoch: 5| Step: 3
Training loss: 3.0185594265572635
Validation loss: 3.128264087999332

Epoch: 5| Step: 4
Training loss: 2.714558494456183
Validation loss: 3.1251546702511668

Epoch: 5| Step: 5
Training loss: 4.117509456547229
Validation loss: 3.1249288538555646

Epoch: 5| Step: 6
Training loss: 3.5810894409191047
Validation loss: 3.1225268021672705

Epoch: 5| Step: 7
Training loss: 3.5605776770300968
Validation loss: 3.120404128586321

Epoch: 5| Step: 8
Training loss: 3.4172395985647572
Validation loss: 3.1194153563768223

Epoch: 5| Step: 9
Training loss: 3.695045768031059
Validation loss: 3.118477144725401

Epoch: 5| Step: 10
Training loss: 3.6175502652865794
Validation loss: 3.114029425210088

Epoch: 28| Step: 0
Training loss: 3.190233292853297
Validation loss: 3.1155863144401232

Epoch: 5| Step: 1
Training loss: 3.060167631157831
Validation loss: 3.111764462255922

Epoch: 5| Step: 2
Training loss: 3.8670566729369953
Validation loss: 3.111752313676213

Epoch: 5| Step: 3
Training loss: 3.5921117614487277
Validation loss: 3.1097513029789394

Epoch: 5| Step: 4
Training loss: 4.039240525120458
Validation loss: 3.1076851817259517

Epoch: 5| Step: 5
Training loss: 3.106177751710247
Validation loss: 3.1054159853257737

Epoch: 5| Step: 6
Training loss: 3.275928359910011
Validation loss: 3.1034316267473683

Epoch: 5| Step: 7
Training loss: 3.0888543745288315
Validation loss: 3.1029342635212216

Epoch: 5| Step: 8
Training loss: 3.9120839004334713
Validation loss: 3.0976137595601436

Epoch: 5| Step: 9
Training loss: 2.892231427832343
Validation loss: 3.0985048492573255

Epoch: 5| Step: 10
Training loss: 2.816196216894263
Validation loss: 3.1023110111361896

Epoch: 29| Step: 0
Training loss: 2.8691682132565726
Validation loss: 3.1073277123772978

Epoch: 5| Step: 1
Training loss: 3.01266159953787
Validation loss: 3.1328366395052365

Epoch: 5| Step: 2
Training loss: 3.0993352238756064
Validation loss: 3.1199579133822906

Epoch: 5| Step: 3
Training loss: 2.9197889418945953
Validation loss: 3.1083857693684225

Epoch: 5| Step: 4
Training loss: 4.095227157012086
Validation loss: 3.107288460470669

Epoch: 5| Step: 5
Training loss: 3.3331374269772764
Validation loss: 3.0967760514395617

Epoch: 5| Step: 6
Training loss: 3.7658607757327074
Validation loss: 3.1018345500335824

Epoch: 5| Step: 7
Training loss: 3.4755449155962794
Validation loss: 3.099683514018975

Epoch: 5| Step: 8
Training loss: 3.603312499568065
Validation loss: 3.093628822257961

Epoch: 5| Step: 9
Training loss: 3.383983101173574
Validation loss: 3.0920646322012315

Epoch: 5| Step: 10
Training loss: 3.2922153900804574
Validation loss: 3.0861278919134554

Epoch: 30| Step: 0
Training loss: 3.618178691139456
Validation loss: 3.0865791074374065

Epoch: 5| Step: 1
Training loss: 2.991895855666976
Validation loss: 3.0838307464745163

Epoch: 5| Step: 2
Training loss: 3.150041422495892
Validation loss: 3.0790728645257963

Epoch: 5| Step: 3
Training loss: 3.8205918286014757
Validation loss: 3.079402421362879

Epoch: 5| Step: 4
Training loss: 3.7859103905198794
Validation loss: 3.0753517331884335

Epoch: 5| Step: 5
Training loss: 3.3027864944974663
Validation loss: 3.075533706298977

Epoch: 5| Step: 6
Training loss: 3.8162215782629048
Validation loss: 3.077131841661285

Epoch: 5| Step: 7
Training loss: 3.6711452327088767
Validation loss: 3.077102871210863

Epoch: 5| Step: 8
Training loss: 2.7560757363519706
Validation loss: 3.0716680482705225

Epoch: 5| Step: 9
Training loss: 2.577351494552295
Validation loss: 3.0698515212945203

Epoch: 5| Step: 10
Training loss: 3.060116521574032
Validation loss: 3.0677197749663763

Epoch: 31| Step: 0
Training loss: 2.9374691576048733
Validation loss: 3.102876842171737

Epoch: 5| Step: 1
Training loss: 3.5843161780162833
Validation loss: 3.111086873747741

Epoch: 5| Step: 2
Training loss: 3.2608581504069134
Validation loss: 3.089480743608999

Epoch: 5| Step: 3
Training loss: 4.146039309089417
Validation loss: 3.06753314460762

Epoch: 5| Step: 4
Training loss: 2.8163922821418113
Validation loss: 3.068411039074632

Epoch: 5| Step: 5
Training loss: 3.212730630989751
Validation loss: 3.0692376044645897

Epoch: 5| Step: 6
Training loss: 3.1994116122995164
Validation loss: 3.065194659466764

Epoch: 5| Step: 7
Training loss: 3.2715917951114153
Validation loss: 3.063968258767455

Epoch: 5| Step: 8
Training loss: 3.5212074547507264
Validation loss: 3.0614100097184846

Epoch: 5| Step: 9
Training loss: 3.176216949567169
Validation loss: 3.058546927440006

Epoch: 5| Step: 10
Training loss: 3.517599678714851
Validation loss: 3.0615783587041863

Epoch: 32| Step: 0
Training loss: 3.5369984247594015
Validation loss: 3.0679832084781737

Epoch: 5| Step: 1
Training loss: 2.899429686142227
Validation loss: 3.085042973948329

Epoch: 5| Step: 2
Training loss: 3.4013448972407003
Validation loss: 3.0802563948840995

Epoch: 5| Step: 3
Training loss: 3.445919891586419
Validation loss: 3.0786462732521267

Epoch: 5| Step: 4
Training loss: 2.876121799707114
Validation loss: 3.0870704408189567

Epoch: 5| Step: 5
Training loss: 3.5183846048522227
Validation loss: 3.1094206218533462

Epoch: 5| Step: 6
Training loss: 3.540039870689563
Validation loss: 3.082374489072362

Epoch: 5| Step: 7
Training loss: 3.1433303340548315
Validation loss: 3.058857851286437

Epoch: 5| Step: 8
Training loss: 3.6423123751081827
Validation loss: 3.0594049970230146

Epoch: 5| Step: 9
Training loss: 3.2589241162174476
Validation loss: 3.068245005109744

Epoch: 5| Step: 10
Training loss: 3.5093095129599874
Validation loss: 3.077065119154599

Epoch: 33| Step: 0
Training loss: 3.5625522007380326
Validation loss: 3.084966922445133

Epoch: 5| Step: 1
Training loss: 3.7428479975564732
Validation loss: 3.0672628430681925

Epoch: 5| Step: 2
Training loss: 2.3885307363888613
Validation loss: 3.0636005596383526

Epoch: 5| Step: 3
Training loss: 3.131352034255964
Validation loss: 3.076278069963575

Epoch: 5| Step: 4
Training loss: 2.907611814990922
Validation loss: 3.0799327401971737

Epoch: 5| Step: 5
Training loss: 3.8385731641011125
Validation loss: 3.0725858454312673

Epoch: 5| Step: 6
Training loss: 3.102869330223936
Validation loss: 3.0696966893891386

Epoch: 5| Step: 7
Training loss: 3.2178562738294323
Validation loss: 3.0634717222119

Epoch: 5| Step: 8
Training loss: 3.945122379972077
Validation loss: 3.0700402586755935

Epoch: 5| Step: 9
Training loss: 3.5122338788096115
Validation loss: 3.0628114801002284

Epoch: 5| Step: 10
Training loss: 3.1278624585442234
Validation loss: 3.0622792159140926

Epoch: 34| Step: 0
Training loss: 3.601527811739811
Validation loss: 3.060754587930305

Epoch: 5| Step: 1
Training loss: 3.2132037627608536
Validation loss: 3.059977891075247

Epoch: 5| Step: 2
Training loss: 2.993913356967078
Validation loss: 3.0576131654817216

Epoch: 5| Step: 3
Training loss: 3.0064559453581543
Validation loss: 3.0533169992080476

Epoch: 5| Step: 4
Training loss: 3.6288204449876615
Validation loss: 3.053409186938729

Epoch: 5| Step: 5
Training loss: 3.460542333358573
Validation loss: 3.0489414415254847

Epoch: 5| Step: 6
Training loss: 3.4001921936017347
Validation loss: 3.054523721381109

Epoch: 5| Step: 7
Training loss: 3.5502251083568384
Validation loss: 3.057890068706586

Epoch: 5| Step: 8
Training loss: 3.0720567092628284
Validation loss: 3.0466030860900064

Epoch: 5| Step: 9
Training loss: 3.358200648662865
Validation loss: 3.0444817714120966

Epoch: 5| Step: 10
Training loss: 3.32064164269339
Validation loss: 3.0404994498945044

Epoch: 35| Step: 0
Training loss: 3.4301446075651962
Validation loss: 3.0416003236996016

Epoch: 5| Step: 1
Training loss: 3.6508101726866307
Validation loss: 3.0507061662457757

Epoch: 5| Step: 2
Training loss: 3.617763531094721
Validation loss: 3.0443834170498443

Epoch: 5| Step: 3
Training loss: 2.6004993912795693
Validation loss: 3.0447219767966853

Epoch: 5| Step: 4
Training loss: 3.0068026345995937
Validation loss: 3.041950105302197

Epoch: 5| Step: 5
Training loss: 3.366472420581032
Validation loss: 3.0557085205588304

Epoch: 5| Step: 6
Training loss: 3.713491488523887
Validation loss: 3.035131800701642

Epoch: 5| Step: 7
Training loss: 3.18708918298926
Validation loss: 3.0350628557616277

Epoch: 5| Step: 8
Training loss: 3.13932841851749
Validation loss: 3.03289845835977

Epoch: 5| Step: 9
Training loss: 3.171030467685504
Validation loss: 3.0410580556469275

Epoch: 5| Step: 10
Training loss: 3.6054442829529383
Validation loss: 3.042630180534238

Epoch: 36| Step: 0
Training loss: 3.9271815900711853
Validation loss: 3.052981592664642

Epoch: 5| Step: 1
Training loss: 3.6171624530889033
Validation loss: 3.044134680856554

Epoch: 5| Step: 2
Training loss: 3.543011010032556
Validation loss: 3.038001554601761

Epoch: 5| Step: 3
Training loss: 2.796066934649375
Validation loss: 3.029497437289887

Epoch: 5| Step: 4
Training loss: 3.3773524245204354
Validation loss: 3.0272023907174064

Epoch: 5| Step: 5
Training loss: 2.7224063183908735
Validation loss: 3.030140188047062

Epoch: 5| Step: 6
Training loss: 3.202368074628585
Validation loss: 3.0235681586398853

Epoch: 5| Step: 7
Training loss: 3.6330894446688022
Validation loss: 3.0310897945503172

Epoch: 5| Step: 8
Training loss: 2.9240458374918505
Validation loss: 3.029411134509948

Epoch: 5| Step: 9
Training loss: 3.2000202297524925
Validation loss: 3.024443441861098

Epoch: 5| Step: 10
Training loss: 3.3083400876787423
Validation loss: 3.024262863622712

Epoch: 37| Step: 0
Training loss: 3.013431205707335
Validation loss: 3.0253757128565177

Epoch: 5| Step: 1
Training loss: 3.226570480373757
Validation loss: 3.024952437642941

Epoch: 5| Step: 2
Training loss: 2.7866987368306457
Validation loss: 3.0226744905540777

Epoch: 5| Step: 3
Training loss: 3.1497412317951627
Validation loss: 3.0240443421613072

Epoch: 5| Step: 4
Training loss: 3.360623008098867
Validation loss: 3.0308634041345526

Epoch: 5| Step: 5
Training loss: 3.1735543752134645
Validation loss: 3.0275324564381108

Epoch: 5| Step: 6
Training loss: 3.7257373464072936
Validation loss: 3.022690457530106

Epoch: 5| Step: 7
Training loss: 3.4527394351345997
Validation loss: 3.020713359641301

Epoch: 5| Step: 8
Training loss: 3.5792048128439307
Validation loss: 3.020869803429504

Epoch: 5| Step: 9
Training loss: 3.4793995457601077
Validation loss: 3.016930709507338

Epoch: 5| Step: 10
Training loss: 3.3069141723181468
Validation loss: 3.023490548108991

Epoch: 38| Step: 0
Training loss: 3.666354700746644
Validation loss: 3.053806252194267

Epoch: 5| Step: 1
Training loss: 3.5618816976890906
Validation loss: 3.0318501923503276

Epoch: 5| Step: 2
Training loss: 3.337170982573586
Validation loss: 3.0173398607820623

Epoch: 5| Step: 3
Training loss: 3.8863392706943274
Validation loss: 3.0143648039646447

Epoch: 5| Step: 4
Training loss: 3.290776981564539
Validation loss: 3.015692661926265

Epoch: 5| Step: 5
Training loss: 2.693955851254716
Validation loss: 3.0165944221025476

Epoch: 5| Step: 6
Training loss: 3.424971899209682
Validation loss: 3.011814230035068

Epoch: 5| Step: 7
Training loss: 3.080795291675743
Validation loss: 3.0116930634216246

Epoch: 5| Step: 8
Training loss: 3.19188164633557
Validation loss: 3.0093384222663793

Epoch: 5| Step: 9
Training loss: 3.1982548604233654
Validation loss: 3.009722419296579

Epoch: 5| Step: 10
Training loss: 2.6806629952183667
Validation loss: 3.0079981055842833

Epoch: 39| Step: 0
Training loss: 3.9563540814103932
Validation loss: 3.0126346564677364

Epoch: 5| Step: 1
Training loss: 2.716254656700359
Validation loss: 3.0171193925712054

Epoch: 5| Step: 2
Training loss: 3.3737598542574454
Validation loss: 3.0331471152640286

Epoch: 5| Step: 3
Training loss: 3.933254556890738
Validation loss: 3.0341695518166865

Epoch: 5| Step: 4
Training loss: 3.501723546312559
Validation loss: 3.014939840026043

Epoch: 5| Step: 5
Training loss: 2.5754146316175492
Validation loss: 3.0090578213493595

Epoch: 5| Step: 6
Training loss: 2.62454028872531
Validation loss: 3.010711220065289

Epoch: 5| Step: 7
Training loss: 3.498932539419026
Validation loss: 3.01964347978992

Epoch: 5| Step: 8
Training loss: 3.4801455432228923
Validation loss: 3.017340023912174

Epoch: 5| Step: 9
Training loss: 2.807239699487238
Validation loss: 3.00544257040311

Epoch: 5| Step: 10
Training loss: 3.5296186882022322
Validation loss: 3.0208778443131816

Epoch: 40| Step: 0
Training loss: 3.0125663148537662
Validation loss: 3.0408244639350595

Epoch: 5| Step: 1
Training loss: 3.1765458616467384
Validation loss: 3.035988740638117

Epoch: 5| Step: 2
Training loss: 2.5882262275021914
Validation loss: 3.051127176103902

Epoch: 5| Step: 3
Training loss: 3.8858080846620817
Validation loss: 3.081964354070661

Epoch: 5| Step: 4
Training loss: 2.836192053938042
Validation loss: 3.0323616410833645

Epoch: 5| Step: 5
Training loss: 3.259742366463235
Validation loss: 3.0022050793162993

Epoch: 5| Step: 6
Training loss: 2.90324213389109
Validation loss: 2.9951387434156436

Epoch: 5| Step: 7
Training loss: 3.62954072364025
Validation loss: 2.9968217229871725

Epoch: 5| Step: 8
Training loss: 3.49690150301165
Validation loss: 3.0024777438371077

Epoch: 5| Step: 9
Training loss: 3.6119468080610897
Validation loss: 3.0021769425459763

Epoch: 5| Step: 10
Training loss: 3.68713868520835
Validation loss: 3.001693328020047

Epoch: 41| Step: 0
Training loss: 3.967506634442864
Validation loss: 2.9867913204906196

Epoch: 5| Step: 1
Training loss: 3.451180164994288
Validation loss: 2.9843931708147515

Epoch: 5| Step: 2
Training loss: 2.9388061216926915
Validation loss: 2.9830780037131297

Epoch: 5| Step: 3
Training loss: 3.4806147928990723
Validation loss: 2.9827859293722114

Epoch: 5| Step: 4
Training loss: 3.1836635464933334
Validation loss: 2.9901497477136396

Epoch: 5| Step: 5
Training loss: 3.319419543298369
Validation loss: 3.015063153205138

Epoch: 5| Step: 6
Training loss: 2.9822507957849487
Validation loss: 3.0038136320302846

Epoch: 5| Step: 7
Training loss: 3.0695430189350295
Validation loss: 2.9981774242426074

Epoch: 5| Step: 8
Training loss: 3.30842728629535
Validation loss: 2.992043578385427

Epoch: 5| Step: 9
Training loss: 2.6228163583091484
Validation loss: 2.988936127634495

Epoch: 5| Step: 10
Training loss: 3.5586809802957955
Validation loss: 2.9841064571111406

Epoch: 42| Step: 0
Training loss: 2.952911369226038
Validation loss: 2.9808423777885023

Epoch: 5| Step: 1
Training loss: 4.056580206504212
Validation loss: 2.9788727710366563

Epoch: 5| Step: 2
Training loss: 2.9047063193858143
Validation loss: 2.980710393284789

Epoch: 5| Step: 3
Training loss: 2.410065734251725
Validation loss: 2.9779945093844753

Epoch: 5| Step: 4
Training loss: 3.1706733118516452
Validation loss: 2.978475691192945

Epoch: 5| Step: 5
Training loss: 2.842109961812558
Validation loss: 2.9796068804402633

Epoch: 5| Step: 6
Training loss: 3.365928467623416
Validation loss: 2.976644002254923

Epoch: 5| Step: 7
Training loss: 3.590191480795198
Validation loss: 2.9743486980115352

Epoch: 5| Step: 8
Training loss: 3.4323419886572504
Validation loss: 2.9721990181969735

Epoch: 5| Step: 9
Training loss: 3.9298372334948803
Validation loss: 2.97150784660799

Epoch: 5| Step: 10
Training loss: 2.8359847472067194
Validation loss: 2.9687617458765274

Epoch: 43| Step: 0
Training loss: 3.02995760393855
Validation loss: 2.967857612720209

Epoch: 5| Step: 1
Training loss: 2.97189806619351
Validation loss: 2.964232638524614

Epoch: 5| Step: 2
Training loss: 3.1077537719026105
Validation loss: 2.9672301827268535

Epoch: 5| Step: 3
Training loss: 3.343397032744824
Validation loss: 2.9658805835668405

Epoch: 5| Step: 4
Training loss: 3.2804201075705715
Validation loss: 2.9651493570702065

Epoch: 5| Step: 5
Training loss: 3.476684979627979
Validation loss: 2.964518598713738

Epoch: 5| Step: 6
Training loss: 3.0122213970849074
Validation loss: 2.962199405297173

Epoch: 5| Step: 7
Training loss: 3.298896495230288
Validation loss: 2.966408257281461

Epoch: 5| Step: 8
Training loss: 3.1186912943908816
Validation loss: 2.960370894356315

Epoch: 5| Step: 9
Training loss: 3.6062371952880747
Validation loss: 2.959587644690961

Epoch: 5| Step: 10
Training loss: 3.581843813253038
Validation loss: 2.9605419303694793

Epoch: 44| Step: 0
Training loss: 3.955938250415579
Validation loss: 2.959116760214351

Epoch: 5| Step: 1
Training loss: 2.303760613734219
Validation loss: 2.956278565006099

Epoch: 5| Step: 2
Training loss: 3.1429503074065077
Validation loss: 2.955877745706986

Epoch: 5| Step: 3
Training loss: 3.1199544228379263
Validation loss: 2.9554263088198525

Epoch: 5| Step: 4
Training loss: 2.788097823830836
Validation loss: 2.9530273827642035

Epoch: 5| Step: 5
Training loss: 4.075600028766614
Validation loss: 2.9481624687913155

Epoch: 5| Step: 6
Training loss: 3.3150278199008087
Validation loss: 2.944352082892026

Epoch: 5| Step: 7
Training loss: 3.4793339001938413
Validation loss: 2.937090561328771

Epoch: 5| Step: 8
Training loss: 3.2086418465909876
Validation loss: 2.933597317220141

Epoch: 5| Step: 9
Training loss: 3.1940805163377823
Validation loss: 2.934790826190225

Epoch: 5| Step: 10
Training loss: 2.5095867404938894
Validation loss: 2.930721357259624

Epoch: 45| Step: 0
Training loss: 3.164370976233971
Validation loss: 2.9350678396898466

Epoch: 5| Step: 1
Training loss: 3.507419895554347
Validation loss: 2.9322204114904125

Epoch: 5| Step: 2
Training loss: 3.1394731677361185
Validation loss: 2.9309393011966614

Epoch: 5| Step: 3
Training loss: 2.5048140904924834
Validation loss: 2.9279896478878453

Epoch: 5| Step: 4
Training loss: 3.0170825341415943
Validation loss: 2.9370742538197034

Epoch: 5| Step: 5
Training loss: 2.8375942130559735
Validation loss: 2.944687401704548

Epoch: 5| Step: 6
Training loss: 3.5777766295510838
Validation loss: 2.9262025416097477

Epoch: 5| Step: 7
Training loss: 3.0523997762286803
Validation loss: 2.9234074137501134

Epoch: 5| Step: 8
Training loss: 3.369068301986427
Validation loss: 2.917261365977628

Epoch: 5| Step: 9
Training loss: 3.8288660694528893
Validation loss: 2.9196298714778526

Epoch: 5| Step: 10
Training loss: 3.2637919706920817
Validation loss: 2.9224312826179837

Epoch: 46| Step: 0
Training loss: 2.8280750923600566
Validation loss: 2.920382417823205

Epoch: 5| Step: 1
Training loss: 4.016464442521805
Validation loss: 2.92444972746832

Epoch: 5| Step: 2
Training loss: 2.8443237396630403
Validation loss: 2.92555953231619

Epoch: 5| Step: 3
Training loss: 3.4324850781387974
Validation loss: 2.92476105241193

Epoch: 5| Step: 4
Training loss: 2.883399634802552
Validation loss: 2.9300950324891075

Epoch: 5| Step: 5
Training loss: 3.048780891790596
Validation loss: 2.935875982406176

Epoch: 5| Step: 6
Training loss: 2.8848967009088127
Validation loss: 2.931643159221721

Epoch: 5| Step: 7
Training loss: 4.2090944917440005
Validation loss: 2.9392157147538076

Epoch: 5| Step: 8
Training loss: 2.4722321494637765
Validation loss: 2.921156184098866

Epoch: 5| Step: 9
Training loss: 3.0762186876398383
Validation loss: 2.9214034617717393

Epoch: 5| Step: 10
Training loss: 3.307220714538915
Validation loss: 2.9169335341357803

Epoch: 47| Step: 0
Training loss: 3.1773872772079255
Validation loss: 2.921976734018075

Epoch: 5| Step: 1
Training loss: 3.0671690556986504
Validation loss: 2.9364655610107597

Epoch: 5| Step: 2
Training loss: 3.0835345606394156
Validation loss: 2.943719484388646

Epoch: 5| Step: 3
Training loss: 3.0105701834178635
Validation loss: 2.958761057479239

Epoch: 5| Step: 4
Training loss: 3.0281012787101385
Validation loss: 2.948361575880383

Epoch: 5| Step: 5
Training loss: 3.412472142814983
Validation loss: 2.929219269993827

Epoch: 5| Step: 6
Training loss: 3.5055741473022484
Validation loss: 2.91433319468213

Epoch: 5| Step: 7
Training loss: 3.3762502826915117
Validation loss: 2.9208678797174668

Epoch: 5| Step: 8
Training loss: 3.18692983876021
Validation loss: 2.9358605317614495

Epoch: 5| Step: 9
Training loss: 3.0160852585031575
Validation loss: 2.9403182094712195

Epoch: 5| Step: 10
Training loss: 3.656110711990281
Validation loss: 2.962865245383031

Epoch: 48| Step: 0
Training loss: 3.4131599822082688
Validation loss: 2.9635619603223877

Epoch: 5| Step: 1
Training loss: 2.867706667595567
Validation loss: 2.976295019707358

Epoch: 5| Step: 2
Training loss: 3.540768109196165
Validation loss: 2.946372890918483

Epoch: 5| Step: 3
Training loss: 2.9764601321902613
Validation loss: 2.91868341016037

Epoch: 5| Step: 4
Training loss: 3.2336245048481578
Validation loss: 2.9084664726111535

Epoch: 5| Step: 5
Training loss: 3.41313092334445
Validation loss: 2.9113870314412487

Epoch: 5| Step: 6
Training loss: 3.060172461592637
Validation loss: 2.9247065860872477

Epoch: 5| Step: 7
Training loss: 3.56413873827587
Validation loss: 2.9250257682524174

Epoch: 5| Step: 8
Training loss: 3.5469778440916504
Validation loss: 2.9088556502269927

Epoch: 5| Step: 9
Training loss: 3.082199884981739
Validation loss: 2.9072960294179766

Epoch: 5| Step: 10
Training loss: 2.5635482690863833
Validation loss: 2.9044640052993844

Epoch: 49| Step: 0
Training loss: 2.924577248825988
Validation loss: 2.9068122634786686

Epoch: 5| Step: 1
Training loss: 2.445784160719755
Validation loss: 2.906860469162043

Epoch: 5| Step: 2
Training loss: 3.4105214625814213
Validation loss: 2.906488906932749

Epoch: 5| Step: 3
Training loss: 2.7858072726481558
Validation loss: 2.910850746063693

Epoch: 5| Step: 4
Training loss: 4.031855811205137
Validation loss: 2.9173186480273325

Epoch: 5| Step: 5
Training loss: 3.2461727789153936
Validation loss: 2.9144234558412005

Epoch: 5| Step: 6
Training loss: 3.377397886323722
Validation loss: 2.914579893685684

Epoch: 5| Step: 7
Training loss: 3.741975463721502
Validation loss: 2.9142527392937465

Epoch: 5| Step: 8
Training loss: 3.6080786288420517
Validation loss: 2.9076477740115223

Epoch: 5| Step: 9
Training loss: 2.6506764897996624
Validation loss: 2.9035600237990042

Epoch: 5| Step: 10
Training loss: 2.65281041665051
Validation loss: 2.904665126358135

Epoch: 50| Step: 0
Training loss: 3.653542583997884
Validation loss: 2.902159213901563

Epoch: 5| Step: 1
Training loss: 3.451795088882352
Validation loss: 2.9004691739130553

Epoch: 5| Step: 2
Training loss: 3.276917567408632
Validation loss: 2.8993651821492805

Epoch: 5| Step: 3
Training loss: 3.3990298401705914
Validation loss: 2.897878716981869

Epoch: 5| Step: 4
Training loss: 3.0229827775480382
Validation loss: 2.9015269613760357

Epoch: 5| Step: 5
Training loss: 3.2157971809637247
Validation loss: 2.8998088683161853

Epoch: 5| Step: 6
Training loss: 3.0066264402598355
Validation loss: 2.897168665556065

Epoch: 5| Step: 7
Training loss: 2.83177766914284
Validation loss: 2.8959000648310473

Epoch: 5| Step: 8
Training loss: 3.110264329869755
Validation loss: 2.8960288999758825

Epoch: 5| Step: 9
Training loss: 3.1921188698148946
Validation loss: 2.895473013099148

Epoch: 5| Step: 10
Training loss: 2.9586520672518613
Validation loss: 2.8939607015387403

Epoch: 51| Step: 0
Training loss: 2.882112578322286
Validation loss: 2.895005870514677

Epoch: 5| Step: 1
Training loss: 3.597195640344649
Validation loss: 2.896620899990939

Epoch: 5| Step: 2
Training loss: 3.632810006089534
Validation loss: 2.896207233924213

Epoch: 5| Step: 3
Training loss: 2.447196064391998
Validation loss: 2.896430680700098

Epoch: 5| Step: 4
Training loss: 3.413005743871908
Validation loss: 2.897851780694855

Epoch: 5| Step: 5
Training loss: 3.0318212855670086
Validation loss: 2.9031529053100007

Epoch: 5| Step: 6
Training loss: 3.4439108975411425
Validation loss: 2.9080547295812247

Epoch: 5| Step: 7
Training loss: 3.1122619415306603
Validation loss: 2.898591675873131

Epoch: 5| Step: 8
Training loss: 3.499082990134785
Validation loss: 2.895076711883269

Epoch: 5| Step: 9
Training loss: 2.877021244897456
Validation loss: 2.893889988765589

Epoch: 5| Step: 10
Training loss: 2.9928459060619277
Validation loss: 2.894205018177425

Epoch: 52| Step: 0
Training loss: 2.7347386581558144
Validation loss: 2.888709244797021

Epoch: 5| Step: 1
Training loss: 3.2893601235312975
Validation loss: 2.8909954176267876

Epoch: 5| Step: 2
Training loss: 3.5445905546356418
Validation loss: 2.892023140311498

Epoch: 5| Step: 3
Training loss: 3.1684274964551373
Validation loss: 2.8886365539383303

Epoch: 5| Step: 4
Training loss: 3.581986521667307
Validation loss: 2.8898810921881877

Epoch: 5| Step: 5
Training loss: 2.9547047098627894
Validation loss: 2.8904405813856813

Epoch: 5| Step: 6
Training loss: 3.0108527337392537
Validation loss: 2.893289683126934

Epoch: 5| Step: 7
Training loss: 3.164925163312345
Validation loss: 2.8894306938335683

Epoch: 5| Step: 8
Training loss: 3.3654840324724686
Validation loss: 2.8901325474840838

Epoch: 5| Step: 9
Training loss: 3.1466624365255513
Validation loss: 2.885182635767881

Epoch: 5| Step: 10
Training loss: 3.0200171233948567
Validation loss: 2.8839140224126534

Epoch: 53| Step: 0
Training loss: 3.4281986976289462
Validation loss: 2.882990015296295

Epoch: 5| Step: 1
Training loss: 2.8322664570969627
Validation loss: 2.8839360894961947

Epoch: 5| Step: 2
Training loss: 3.4450452359223482
Validation loss: 2.8851647979907455

Epoch: 5| Step: 3
Training loss: 3.414075349482398
Validation loss: 2.8870822702528063

Epoch: 5| Step: 4
Training loss: 3.127779220692144
Validation loss: 2.8858598690281645

Epoch: 5| Step: 5
Training loss: 3.1662921349409725
Validation loss: 2.887773924425356

Epoch: 5| Step: 6
Training loss: 2.9376280736396234
Validation loss: 2.8862455833006644

Epoch: 5| Step: 7
Training loss: 3.57160976222769
Validation loss: 2.892536429551255

Epoch: 5| Step: 8
Training loss: 3.182129468181725
Validation loss: 2.887847909120587

Epoch: 5| Step: 9
Training loss: 2.8916511982294266
Validation loss: 2.8891772918868774

Epoch: 5| Step: 10
Training loss: 2.9389849217025796
Validation loss: 2.886184651188257

Epoch: 54| Step: 0
Training loss: 2.854838456963274
Validation loss: 2.881047784711128

Epoch: 5| Step: 1
Training loss: 3.4868448168413515
Validation loss: 2.8788013384315434

Epoch: 5| Step: 2
Training loss: 3.077047246481613
Validation loss: 2.878152795862964

Epoch: 5| Step: 3
Training loss: 3.4821963491278596
Validation loss: 2.8772667272667007

Epoch: 5| Step: 4
Training loss: 3.498914005187644
Validation loss: 2.8787385896712343

Epoch: 5| Step: 5
Training loss: 2.371521862414237
Validation loss: 2.8779202370578036

Epoch: 5| Step: 6
Training loss: 3.799888262862699
Validation loss: 2.8768904294948188

Epoch: 5| Step: 7
Training loss: 3.0390847801039014
Validation loss: 2.8775357267724644

Epoch: 5| Step: 8
Training loss: 2.8266408830342464
Validation loss: 2.880337657931567

Epoch: 5| Step: 9
Training loss: 2.855846458325495
Validation loss: 2.885347127307845

Epoch: 5| Step: 10
Training loss: 3.472460849615416
Validation loss: 2.8946614036831706

Epoch: 55| Step: 0
Training loss: 3.025563677769368
Validation loss: 2.912998429998608

Epoch: 5| Step: 1
Training loss: 3.353098270704348
Validation loss: 2.9213355606530853

Epoch: 5| Step: 2
Training loss: 3.385389513738265
Validation loss: 2.9353705747404515

Epoch: 5| Step: 3
Training loss: 2.8141675456095294
Validation loss: 2.9120091503117416

Epoch: 5| Step: 4
Training loss: 3.4605149125206545
Validation loss: 2.9114677491711696

Epoch: 5| Step: 5
Training loss: 3.7401006370916985
Validation loss: 2.905342091670975

Epoch: 5| Step: 6
Training loss: 2.805828829214954
Validation loss: 2.878482758236112

Epoch: 5| Step: 7
Training loss: 3.5318229008013002
Validation loss: 2.8774556038612777

Epoch: 5| Step: 8
Training loss: 3.034309809227064
Validation loss: 2.8723986343243544

Epoch: 5| Step: 9
Training loss: 2.9071794889852876
Validation loss: 2.874934609031975

Epoch: 5| Step: 10
Training loss: 2.7285460331832767
Validation loss: 2.8833004945042844

Epoch: 56| Step: 0
Training loss: 2.918580998300396
Validation loss: 2.900286944036635

Epoch: 5| Step: 1
Training loss: 3.3654942337460527
Validation loss: 2.894587603766601

Epoch: 5| Step: 2
Training loss: 2.9869067253412305
Validation loss: 2.8734777414454

Epoch: 5| Step: 3
Training loss: 2.1824853366564594
Validation loss: 2.872907116650317

Epoch: 5| Step: 4
Training loss: 3.049591887638794
Validation loss: 2.8765832537248595

Epoch: 5| Step: 5
Training loss: 3.137102875520521
Validation loss: 2.8847252696468555

Epoch: 5| Step: 6
Training loss: 3.5087593007278706
Validation loss: 2.89947355921372

Epoch: 5| Step: 7
Training loss: 3.813259111718031
Validation loss: 2.8989532819321613

Epoch: 5| Step: 8
Training loss: 3.2020068194038545
Validation loss: 2.8907782472154566

Epoch: 5| Step: 9
Training loss: 3.0723918057070585
Validation loss: 2.8903526011514233

Epoch: 5| Step: 10
Training loss: 3.646532627434162
Validation loss: 2.8896829991960478

Epoch: 57| Step: 0
Training loss: 3.2173568525386096
Validation loss: 2.8823336667599917

Epoch: 5| Step: 1
Training loss: 2.952200285632609
Validation loss: 2.874544500833549

Epoch: 5| Step: 2
Training loss: 3.056552327498632
Validation loss: 2.8724756416161865

Epoch: 5| Step: 3
Training loss: 3.176916766360249
Validation loss: 2.8697091757700277

Epoch: 5| Step: 4
Training loss: 3.169194634596936
Validation loss: 2.867581419814615

Epoch: 5| Step: 5
Training loss: 3.4674218186721264
Validation loss: 2.8674563087164304

Epoch: 5| Step: 6
Training loss: 3.344423885711758
Validation loss: 2.8644592980224055

Epoch: 5| Step: 7
Training loss: 3.722707870141515
Validation loss: 2.8688013274377404

Epoch: 5| Step: 8
Training loss: 2.846686722761461
Validation loss: 2.8661875380789894

Epoch: 5| Step: 9
Training loss: 2.699394518460832
Validation loss: 2.8648162305615936

Epoch: 5| Step: 10
Training loss: 3.2154309094634135
Validation loss: 2.866072017576646

Epoch: 58| Step: 0
Training loss: 2.879432412749479
Validation loss: 2.8631639342819737

Epoch: 5| Step: 1
Training loss: 3.7768030420670464
Validation loss: 2.866155829014005

Epoch: 5| Step: 2
Training loss: 3.538415441244692
Validation loss: 2.864485057289801

Epoch: 5| Step: 3
Training loss: 3.187835825264584
Validation loss: 2.863994831628273

Epoch: 5| Step: 4
Training loss: 3.107516706303613
Validation loss: 2.8640892669214817

Epoch: 5| Step: 5
Training loss: 3.226550972758616
Validation loss: 2.8629311008358647

Epoch: 5| Step: 6
Training loss: 2.590631839756973
Validation loss: 2.8617511919620227

Epoch: 5| Step: 7
Training loss: 3.181628785131822
Validation loss: 2.8626302560962262

Epoch: 5| Step: 8
Training loss: 3.062797220559993
Validation loss: 2.8610355776280993

Epoch: 5| Step: 9
Training loss: 2.8479660137806095
Validation loss: 2.8619078001425864

Epoch: 5| Step: 10
Training loss: 3.322472298465747
Validation loss: 2.867736663671865

Epoch: 59| Step: 0
Training loss: 3.5072861172426646
Validation loss: 2.8625693461183537

Epoch: 5| Step: 1
Training loss: 3.280086638073983
Validation loss: 2.865774745389938

Epoch: 5| Step: 2
Training loss: 3.0166510383102776
Validation loss: 2.86545015854822

Epoch: 5| Step: 3
Training loss: 3.174116873884317
Validation loss: 2.8702294628197715

Epoch: 5| Step: 4
Training loss: 2.6949952754331377
Validation loss: 2.8714399200372207

Epoch: 5| Step: 5
Training loss: 3.1314169041661883
Validation loss: 2.8786234143254705

Epoch: 5| Step: 6
Training loss: 3.4398604178387626
Validation loss: 2.8608387966397824

Epoch: 5| Step: 7
Training loss: 2.788876738359276
Validation loss: 2.8591038686155383

Epoch: 5| Step: 8
Training loss: 3.3415756999609236
Validation loss: 2.8560750473709646

Epoch: 5| Step: 9
Training loss: 3.466872248300355
Validation loss: 2.8582600329956667

Epoch: 5| Step: 10
Training loss: 2.853717313788989
Validation loss: 2.8569453116396484

Epoch: 60| Step: 0
Training loss: 3.775660142588194
Validation loss: 2.8581381689875007

Epoch: 5| Step: 1
Training loss: 2.4648693826977905
Validation loss: 2.8574183687925903

Epoch: 5| Step: 2
Training loss: 3.5011334627498587
Validation loss: 2.855411579301623

Epoch: 5| Step: 3
Training loss: 3.243048643167895
Validation loss: 2.8576135291642837

Epoch: 5| Step: 4
Training loss: 2.974145423540384
Validation loss: 2.855122293891321

Epoch: 5| Step: 5
Training loss: 3.187310007454274
Validation loss: 2.8560581668732654

Epoch: 5| Step: 6
Training loss: 3.214952617669863
Validation loss: 2.856797079508528

Epoch: 5| Step: 7
Training loss: 2.6075135861387557
Validation loss: 2.8543021739759293

Epoch: 5| Step: 8
Training loss: 3.162341895693568
Validation loss: 2.8549928950569803

Epoch: 5| Step: 9
Training loss: 2.9984695981500753
Validation loss: 2.854566231006547

Epoch: 5| Step: 10
Training loss: 3.5568688040307186
Validation loss: 2.85193689135852

Epoch: 61| Step: 0
Training loss: 3.1034028481121974
Validation loss: 2.8508570642613047

Epoch: 5| Step: 1
Training loss: 3.5157850441001592
Validation loss: 2.849607423666427

Epoch: 5| Step: 2
Training loss: 3.1063444618276552
Validation loss: 2.850316550516812

Epoch: 5| Step: 3
Training loss: 3.01912695385215
Validation loss: 2.8513657764291382

Epoch: 5| Step: 4
Training loss: 3.351794254853313
Validation loss: 2.8544825004968497

Epoch: 5| Step: 5
Training loss: 2.9123893618546175
Validation loss: 2.8567761578487216

Epoch: 5| Step: 6
Training loss: 3.169228939300875
Validation loss: 2.8623032320584776

Epoch: 5| Step: 7
Training loss: 2.6492811451580764
Validation loss: 2.8669207308203166

Epoch: 5| Step: 8
Training loss: 2.9692729288622526
Validation loss: 2.8789216964186415

Epoch: 5| Step: 9
Training loss: 3.759668728459185
Validation loss: 2.8810230064188356

Epoch: 5| Step: 10
Training loss: 3.122256027964811
Validation loss: 2.8731486720723427

Epoch: 62| Step: 0
Training loss: 3.234299073733295
Validation loss: 2.851720777055892

Epoch: 5| Step: 1
Training loss: 2.8591930560816983
Validation loss: 2.8477100465305405

Epoch: 5| Step: 2
Training loss: 2.832924495446254
Validation loss: 2.848495665093906

Epoch: 5| Step: 3
Training loss: 3.0819914879306927
Validation loss: 2.8474318811228527

Epoch: 5| Step: 4
Training loss: 3.6975946133923054
Validation loss: 2.849308538976714

Epoch: 5| Step: 5
Training loss: 3.401116518810246
Validation loss: 2.8525391667517916

Epoch: 5| Step: 6
Training loss: 3.007941860042916
Validation loss: 2.8495420896560963

Epoch: 5| Step: 7
Training loss: 2.971299371818702
Validation loss: 2.8482460054850547

Epoch: 5| Step: 8
Training loss: 3.7253956117423632
Validation loss: 2.8467561603637197

Epoch: 5| Step: 9
Training loss: 2.798648463763244
Validation loss: 2.8468032415256443

Epoch: 5| Step: 10
Training loss: 2.994083769794097
Validation loss: 2.8466307481839417

Epoch: 63| Step: 0
Training loss: 3.386713399739863
Validation loss: 2.8452474191638886

Epoch: 5| Step: 1
Training loss: 3.098799620766184
Validation loss: 2.8444253200108998

Epoch: 5| Step: 2
Training loss: 3.3881853881250654
Validation loss: 2.8434609950643037

Epoch: 5| Step: 3
Training loss: 3.330065524169708
Validation loss: 2.84358290747432

Epoch: 5| Step: 4
Training loss: 3.13502785604899
Validation loss: 2.8404510133584813

Epoch: 5| Step: 5
Training loss: 3.1589875388338924
Validation loss: 2.842162307367561

Epoch: 5| Step: 6
Training loss: 3.190802116596677
Validation loss: 2.8410773480464324

Epoch: 5| Step: 7
Training loss: 2.8721277567784695
Validation loss: 2.844198529393773

Epoch: 5| Step: 8
Training loss: 2.685248829341925
Validation loss: 2.8442082324943407

Epoch: 5| Step: 9
Training loss: 3.4181891670000484
Validation loss: 2.847564895208601

Epoch: 5| Step: 10
Training loss: 2.8982821934469327
Validation loss: 2.8491364834465926

Epoch: 64| Step: 0
Training loss: 3.4694789086258906
Validation loss: 2.845530253246449

Epoch: 5| Step: 1
Training loss: 3.0692090097144735
Validation loss: 2.8461539028950478

Epoch: 5| Step: 2
Training loss: 1.8934708291932727
Validation loss: 2.8477756179207994

Epoch: 5| Step: 3
Training loss: 2.80754177887862
Validation loss: 2.85372143721844

Epoch: 5| Step: 4
Training loss: 3.148664821246488
Validation loss: 2.8528050674219205

Epoch: 5| Step: 5
Training loss: 3.462370083020715
Validation loss: 2.8481667472045893

Epoch: 5| Step: 6
Training loss: 3.714441961628114
Validation loss: 2.8376807898939145

Epoch: 5| Step: 7
Training loss: 3.6706138230563967
Validation loss: 2.838436396079498

Epoch: 5| Step: 8
Training loss: 2.9498502143721543
Validation loss: 2.8366223005118316

Epoch: 5| Step: 9
Training loss: 2.85971717663168
Validation loss: 2.83682007721736

Epoch: 5| Step: 10
Training loss: 3.170950017144778
Validation loss: 2.8361635103663034

Epoch: 65| Step: 0
Training loss: 3.128555563944328
Validation loss: 2.8343393402546333

Epoch: 5| Step: 1
Training loss: 2.674383491704109
Validation loss: 2.835815193822399

Epoch: 5| Step: 2
Training loss: 3.3398376107856587
Validation loss: 2.837005720499973

Epoch: 5| Step: 3
Training loss: 3.712071424208167
Validation loss: 2.8350581204040726

Epoch: 5| Step: 4
Training loss: 2.9448884613210025
Validation loss: 2.83357385746082

Epoch: 5| Step: 5
Training loss: 3.0349392807242626
Validation loss: 2.8333174441457265

Epoch: 5| Step: 6
Training loss: 3.243004238712859
Validation loss: 2.833157543565727

Epoch: 5| Step: 7
Training loss: 3.127685003747343
Validation loss: 2.8324233279111906

Epoch: 5| Step: 8
Training loss: 3.204921014202283
Validation loss: 2.832722454310626

Epoch: 5| Step: 9
Training loss: 2.9809304375989236
Validation loss: 2.8311256793390163

Epoch: 5| Step: 10
Training loss: 3.097109271291194
Validation loss: 2.834160187957747

Epoch: 66| Step: 0
Training loss: 2.91792838644481
Validation loss: 2.836494207875944

Epoch: 5| Step: 1
Training loss: 2.919097886193138
Validation loss: 2.8387077575723247

Epoch: 5| Step: 2
Training loss: 2.858477342127116
Validation loss: 2.833082177710503

Epoch: 5| Step: 3
Training loss: 3.226781509762191
Validation loss: 2.829968083209392

Epoch: 5| Step: 4
Training loss: 2.818483642038
Validation loss: 2.831796854437258

Epoch: 5| Step: 5
Training loss: 3.3002621575463844
Validation loss: 2.8298351723929374

Epoch: 5| Step: 6
Training loss: 3.244658555698335
Validation loss: 2.830361358121563

Epoch: 5| Step: 7
Training loss: 3.189336210445182
Validation loss: 2.828121740293644

Epoch: 5| Step: 8
Training loss: 3.1599253792945747
Validation loss: 2.8273647122406693

Epoch: 5| Step: 9
Training loss: 3.2549346727416695
Validation loss: 2.8274903397452986

Epoch: 5| Step: 10
Training loss: 3.643724816367799
Validation loss: 2.8226568142330515

Epoch: 67| Step: 0
Training loss: 3.093662915786274
Validation loss: 2.8238811097915346

Epoch: 5| Step: 1
Training loss: 2.877164772054134
Validation loss: 2.819243484968551

Epoch: 5| Step: 2
Training loss: 3.4316197819692857
Validation loss: 2.8239680008296415

Epoch: 5| Step: 3
Training loss: 3.563569159440261
Validation loss: 2.8206965846486174

Epoch: 5| Step: 4
Training loss: 2.825104422875832
Validation loss: 2.816107716893343

Epoch: 5| Step: 5
Training loss: 3.0087283635044964
Validation loss: 2.8168763233825884

Epoch: 5| Step: 6
Training loss: 2.7523560401626948
Validation loss: 2.818823025581971

Epoch: 5| Step: 7
Training loss: 2.8235043034886362
Validation loss: 2.8168000677573044

Epoch: 5| Step: 8
Training loss: 3.39511177182376
Validation loss: 2.8165566269690516

Epoch: 5| Step: 9
Training loss: 3.061124064361742
Validation loss: 2.8134487871559193

Epoch: 5| Step: 10
Training loss: 3.552784571783234
Validation loss: 2.8117706592823453

Epoch: 68| Step: 0
Training loss: 3.4714133545431585
Validation loss: 2.81174358281995

Epoch: 5| Step: 1
Training loss: 3.0661166886571545
Validation loss: 2.820042601997921

Epoch: 5| Step: 2
Training loss: 2.3987938432925846
Validation loss: 2.8216464152844813

Epoch: 5| Step: 3
Training loss: 3.1196472100559642
Validation loss: 2.8119718951387993

Epoch: 5| Step: 4
Training loss: 3.264206719761844
Validation loss: 2.8072950924114215

Epoch: 5| Step: 5
Training loss: 3.322450627059865
Validation loss: 2.80650250981366

Epoch: 5| Step: 6
Training loss: 2.2679032019624823
Validation loss: 2.803435254788386

Epoch: 5| Step: 7
Training loss: 3.177198180744179
Validation loss: 2.8039994543133338

Epoch: 5| Step: 8
Training loss: 2.8869916195881595
Validation loss: 2.808446711184459

Epoch: 5| Step: 9
Training loss: 3.6246866551163177
Validation loss: 2.809252616816196

Epoch: 5| Step: 10
Training loss: 3.583918782395348
Validation loss: 2.8045748677933413

Epoch: 69| Step: 0
Training loss: 2.630870249838326
Validation loss: 2.805823808517416

Epoch: 5| Step: 1
Training loss: 3.409935173917508
Validation loss: 2.803136588651458

Epoch: 5| Step: 2
Training loss: 3.183668788657448
Validation loss: 2.802898493503662

Epoch: 5| Step: 3
Training loss: 3.2834898070666143
Validation loss: 2.8042825367703137

Epoch: 5| Step: 4
Training loss: 2.736184006788715
Validation loss: 2.806722030516935

Epoch: 5| Step: 5
Training loss: 3.703275395812005
Validation loss: 2.80691127371436

Epoch: 5| Step: 6
Training loss: 2.918661216676148
Validation loss: 2.8055818706025453

Epoch: 5| Step: 7
Training loss: 3.6442080698918713
Validation loss: 2.801582183346895

Epoch: 5| Step: 8
Training loss: 3.2398125832123097
Validation loss: 2.7976738416859637

Epoch: 5| Step: 9
Training loss: 2.7493463086094314
Validation loss: 2.7976701222301426

Epoch: 5| Step: 10
Training loss: 2.462333452818166
Validation loss: 2.7964042083557663

Epoch: 70| Step: 0
Training loss: 3.294985840091178
Validation loss: 2.7977806115098294

Epoch: 5| Step: 1
Training loss: 3.0602399310624233
Validation loss: 2.7948285579836005

Epoch: 5| Step: 2
Training loss: 3.55492291352169
Validation loss: 2.796009816493049

Epoch: 5| Step: 3
Training loss: 2.8538875768234915
Validation loss: 2.7956013440226752

Epoch: 5| Step: 4
Training loss: 3.236215261403303
Validation loss: 2.797694029658637

Epoch: 5| Step: 5
Training loss: 3.118263154646114
Validation loss: 2.79601269186668

Epoch: 5| Step: 6
Training loss: 3.500305979841569
Validation loss: 2.7954063131848086

Epoch: 5| Step: 7
Training loss: 2.3086793628702997
Validation loss: 2.793118307141117

Epoch: 5| Step: 8
Training loss: 2.840490800060703
Validation loss: 2.7980074464065186

Epoch: 5| Step: 9
Training loss: 3.3769233309577085
Validation loss: 2.801184992426082

Epoch: 5| Step: 10
Training loss: 2.9084033167014676
Validation loss: 2.793276318309822

Epoch: 71| Step: 0
Training loss: 2.929959460033358
Validation loss: 2.798693027259495

Epoch: 5| Step: 1
Training loss: 2.7496360191141416
Validation loss: 2.7995543468059862

Epoch: 5| Step: 2
Training loss: 3.397918591400356
Validation loss: 2.7958724204326915

Epoch: 5| Step: 3
Training loss: 3.1127831265163026
Validation loss: 2.797336517605125

Epoch: 5| Step: 4
Training loss: 3.279057960372599
Validation loss: 2.797023368470778

Epoch: 5| Step: 5
Training loss: 2.8924340438246774
Validation loss: 2.7976185661595028

Epoch: 5| Step: 6
Training loss: 4.01205535041151
Validation loss: 2.8001510710474697

Epoch: 5| Step: 7
Training loss: 3.0458711975777777
Validation loss: 2.7985143586164956

Epoch: 5| Step: 8
Training loss: 2.674199927640176
Validation loss: 2.791773537059664

Epoch: 5| Step: 9
Training loss: 2.8894860575574417
Validation loss: 2.7933921850388956

Epoch: 5| Step: 10
Training loss: 3.0140602914694314
Validation loss: 2.7909114081094897

Epoch: 72| Step: 0
Training loss: 3.1412447038052558
Validation loss: 2.791457517488147

Epoch: 5| Step: 1
Training loss: 3.8774331360197816
Validation loss: 2.788760567275515

Epoch: 5| Step: 2
Training loss: 2.7645201981748917
Validation loss: 2.7844534336710103

Epoch: 5| Step: 3
Training loss: 3.848892121870383
Validation loss: 2.7843991027534964

Epoch: 5| Step: 4
Training loss: 2.9444708393121455
Validation loss: 2.782073592731028

Epoch: 5| Step: 5
Training loss: 2.617454036975846
Validation loss: 2.7837075076329776

Epoch: 5| Step: 6
Training loss: 2.7671750999444256
Validation loss: 2.7924789222919695

Epoch: 5| Step: 7
Training loss: 3.171000092207162
Validation loss: 2.792440343647711

Epoch: 5| Step: 8
Training loss: 2.8256015373459085
Validation loss: 2.804120953093754

Epoch: 5| Step: 9
Training loss: 2.7862047787158803
Validation loss: 2.79025332293015

Epoch: 5| Step: 10
Training loss: 3.191051972427723
Validation loss: 2.78846975569968

Epoch: 73| Step: 0
Training loss: 3.129874433247364
Validation loss: 2.782601273780724

Epoch: 5| Step: 1
Training loss: 2.9081870566001697
Validation loss: 2.7798776166065053

Epoch: 5| Step: 2
Training loss: 3.0712974463319593
Validation loss: 2.7837896067991474

Epoch: 5| Step: 3
Training loss: 2.61497791448716
Validation loss: 2.783476201844325

Epoch: 5| Step: 4
Training loss: 2.7550598758345695
Validation loss: 2.7832117769876485

Epoch: 5| Step: 5
Training loss: 3.488135391381183
Validation loss: 2.7819955233792255

Epoch: 5| Step: 6
Training loss: 3.051503583160602
Validation loss: 2.780962995704235

Epoch: 5| Step: 7
Training loss: 3.6843703615322796
Validation loss: 2.7821100704191637

Epoch: 5| Step: 8
Training loss: 3.2431299517364547
Validation loss: 2.7832787969722514

Epoch: 5| Step: 9
Training loss: 3.181458076312339
Validation loss: 2.78277063687816

Epoch: 5| Step: 10
Training loss: 2.8298617767978085
Validation loss: 2.7880562338645674

Epoch: 74| Step: 0
Training loss: 3.271439044695276
Validation loss: 2.7818157159469745

Epoch: 5| Step: 1
Training loss: 3.7021497255009628
Validation loss: 2.784493489268965

Epoch: 5| Step: 2
Training loss: 3.780781488318857
Validation loss: 2.7870456941720954

Epoch: 5| Step: 3
Training loss: 2.592706125538674
Validation loss: 2.7861789260055314

Epoch: 5| Step: 4
Training loss: 2.658619979025038
Validation loss: 2.788083738058894

Epoch: 5| Step: 5
Training loss: 2.7297196349778297
Validation loss: 2.787062202520817

Epoch: 5| Step: 6
Training loss: 3.3058848996119665
Validation loss: 2.7848299184483856

Epoch: 5| Step: 7
Training loss: 3.0938791575588644
Validation loss: 2.7802054118979878

Epoch: 5| Step: 8
Training loss: 2.440403993493442
Validation loss: 2.779745065546002

Epoch: 5| Step: 9
Training loss: 2.8361281654010373
Validation loss: 2.7792586354660114

Epoch: 5| Step: 10
Training loss: 3.4618080026066758
Validation loss: 2.7772612276698845

Epoch: 75| Step: 0
Training loss: 3.0491191717763093
Validation loss: 2.7766526697700233

Epoch: 5| Step: 1
Training loss: 2.991572782553998
Validation loss: 2.7735886223682074

Epoch: 5| Step: 2
Training loss: 2.7532759141207306
Validation loss: 2.772191412389795

Epoch: 5| Step: 3
Training loss: 2.891347598924276
Validation loss: 2.773594565640217

Epoch: 5| Step: 4
Training loss: 3.6263128073880178
Validation loss: 2.7749293403974997

Epoch: 5| Step: 5
Training loss: 2.4263693178092756
Validation loss: 2.775660525702581

Epoch: 5| Step: 6
Training loss: 3.34918996782084
Validation loss: 2.774762858041824

Epoch: 5| Step: 7
Training loss: 3.1712629357218094
Validation loss: 2.777340398385795

Epoch: 5| Step: 8
Training loss: 3.2134781413340194
Validation loss: 2.7775840652424004

Epoch: 5| Step: 9
Training loss: 3.428166427987912
Validation loss: 2.774188538372956

Epoch: 5| Step: 10
Training loss: 2.9836923507535613
Validation loss: 2.777445933985014

Epoch: 76| Step: 0
Training loss: 2.964180571879439
Validation loss: 2.7788565498186912

Epoch: 5| Step: 1
Training loss: 3.212535302825389
Validation loss: 2.778740706195914

Epoch: 5| Step: 2
Training loss: 2.875046439417735
Validation loss: 2.7807408551547286

Epoch: 5| Step: 3
Training loss: 2.9373276030902606
Validation loss: 2.7791491883109822

Epoch: 5| Step: 4
Training loss: 2.8395492212080224
Validation loss: 2.7811624315705212

Epoch: 5| Step: 5
Training loss: 3.266296317717031
Validation loss: 2.7893041943349797

Epoch: 5| Step: 6
Training loss: 2.959681423158059
Validation loss: 2.796565520116439

Epoch: 5| Step: 7
Training loss: 3.1641905958831233
Validation loss: 2.7998946028677194

Epoch: 5| Step: 8
Training loss: 3.0824741678632823
Validation loss: 2.79190995948937

Epoch: 5| Step: 9
Training loss: 3.4562752969378256
Validation loss: 2.7775753477299037

Epoch: 5| Step: 10
Training loss: 3.2857099467894533
Validation loss: 2.768050345398658

Epoch: 77| Step: 0
Training loss: 3.3163782125305556
Validation loss: 2.7696469030830784

Epoch: 5| Step: 1
Training loss: 3.6038292228890403
Validation loss: 2.7731567129753385

Epoch: 5| Step: 2
Training loss: 3.072680310141307
Validation loss: 2.7903505625979372

Epoch: 5| Step: 3
Training loss: 3.065170836175995
Validation loss: 2.785362822443373

Epoch: 5| Step: 4
Training loss: 3.232325397446177
Validation loss: 2.785515242521419

Epoch: 5| Step: 5
Training loss: 2.905251280115087
Validation loss: 2.7712615736408956

Epoch: 5| Step: 6
Training loss: 3.2308102926502396
Validation loss: 2.765860443076794

Epoch: 5| Step: 7
Training loss: 3.1474229110233916
Validation loss: 2.7661080156167257

Epoch: 5| Step: 8
Training loss: 2.4653062582982646
Validation loss: 2.766173187723082

Epoch: 5| Step: 9
Training loss: 2.4031020541639614
Validation loss: 2.773887618780101

Epoch: 5| Step: 10
Training loss: 3.54341285891451
Validation loss: 2.7760095090957666

Epoch: 78| Step: 0
Training loss: 3.566459596867923
Validation loss: 2.783015945147705

Epoch: 5| Step: 1
Training loss: 3.060216246799048
Validation loss: 2.7884756120923004

Epoch: 5| Step: 2
Training loss: 2.9233750353469943
Validation loss: 2.8094909632355147

Epoch: 5| Step: 3
Training loss: 3.353603497410909
Validation loss: 2.829456955485538

Epoch: 5| Step: 4
Training loss: 2.9839167218080243
Validation loss: 2.8156400955496803

Epoch: 5| Step: 5
Training loss: 2.755068010435761
Validation loss: 2.7874173084091183

Epoch: 5| Step: 6
Training loss: 3.3606157717259704
Validation loss: 2.7990059483786047

Epoch: 5| Step: 7
Training loss: 2.9038290789933425
Validation loss: 2.795314916283419

Epoch: 5| Step: 8
Training loss: 2.8414157887199836
Validation loss: 2.7690716612109054

Epoch: 5| Step: 9
Training loss: 2.6030926028064005
Validation loss: 2.764155650194824

Epoch: 5| Step: 10
Training loss: 3.5535193232038713
Validation loss: 2.767534571322952

Epoch: 79| Step: 0
Training loss: 3.376037861932629
Validation loss: 2.7654208430113423

Epoch: 5| Step: 1
Training loss: 2.4002494801553618
Validation loss: 2.7630919581410085

Epoch: 5| Step: 2
Training loss: 3.2207006080853566
Validation loss: 2.7618548302329957

Epoch: 5| Step: 3
Training loss: 3.0850298741901994
Validation loss: 2.761892459553191

Epoch: 5| Step: 4
Training loss: 2.5472275191593687
Validation loss: 2.7640350964639295

Epoch: 5| Step: 5
Training loss: 3.5463302126698415
Validation loss: 2.7598306384800564

Epoch: 5| Step: 6
Training loss: 3.2556042402473016
Validation loss: 2.762915841937807

Epoch: 5| Step: 7
Training loss: 3.1690024912984773
Validation loss: 2.7620110843026118

Epoch: 5| Step: 8
Training loss: 3.281514765638651
Validation loss: 2.7618510913140066

Epoch: 5| Step: 9
Training loss: 2.9225978671118407
Validation loss: 2.7620999801421924

Epoch: 5| Step: 10
Training loss: 2.99294277449737
Validation loss: 2.760364114203451

Epoch: 80| Step: 0
Training loss: 3.320066914171339
Validation loss: 2.7591492677914933

Epoch: 5| Step: 1
Training loss: 3.1305593250443393
Validation loss: 2.763785333731149

Epoch: 5| Step: 2
Training loss: 3.31392984300113
Validation loss: 2.763875348642022

Epoch: 5| Step: 3
Training loss: 2.7839539488897036
Validation loss: 2.7636687029974683

Epoch: 5| Step: 4
Training loss: 3.1352777460864583
Validation loss: 2.7599922514841326

Epoch: 5| Step: 5
Training loss: 3.075948032530479
Validation loss: 2.764749151798745

Epoch: 5| Step: 6
Training loss: 2.7837837764641895
Validation loss: 2.7580516838934277

Epoch: 5| Step: 7
Training loss: 3.226206614377378
Validation loss: 2.759681414902297

Epoch: 5| Step: 8
Training loss: 3.3404136483802653
Validation loss: 2.7593603058951017

Epoch: 5| Step: 9
Training loss: 2.232718647398539
Validation loss: 2.7587009409396415

Epoch: 5| Step: 10
Training loss: 3.4540420626324995
Validation loss: 2.7591199569318037

Epoch: 81| Step: 0
Training loss: 2.8553034242709336
Validation loss: 2.7603654209301625

Epoch: 5| Step: 1
Training loss: 3.3148943326976026
Validation loss: 2.766791611464565

Epoch: 5| Step: 2
Training loss: 3.1548035583762357
Validation loss: 2.766137740849379

Epoch: 5| Step: 3
Training loss: 3.5042914919821966
Validation loss: 2.77298258208181

Epoch: 5| Step: 4
Training loss: 2.5681756595712657
Validation loss: 2.7642907906309517

Epoch: 5| Step: 5
Training loss: 2.826463242744446
Validation loss: 2.760918653138434

Epoch: 5| Step: 6
Training loss: 2.9015476372276012
Validation loss: 2.763024959743023

Epoch: 5| Step: 7
Training loss: 3.0473244360031178
Validation loss: 2.757409581644387

Epoch: 5| Step: 8
Training loss: 3.2479910877274634
Validation loss: 2.7538310016029244

Epoch: 5| Step: 9
Training loss: 3.1053601899755305
Validation loss: 2.752063569880746

Epoch: 5| Step: 10
Training loss: 3.278822373214251
Validation loss: 2.751899232139225

Epoch: 82| Step: 0
Training loss: 3.335668334107643
Validation loss: 2.751659562831718

Epoch: 5| Step: 1
Training loss: 3.3899266802755545
Validation loss: 2.7534356344586253

Epoch: 5| Step: 2
Training loss: 2.885294520320957
Validation loss: 2.7512861844350374

Epoch: 5| Step: 3
Training loss: 3.4304848962697907
Validation loss: 2.750483361327494

Epoch: 5| Step: 4
Training loss: 3.4432618835461297
Validation loss: 2.751656632725756

Epoch: 5| Step: 5
Training loss: 2.777484359079129
Validation loss: 2.7514019941340813

Epoch: 5| Step: 6
Training loss: 3.00174630519258
Validation loss: 2.7506690437362256

Epoch: 5| Step: 7
Training loss: 2.776847440903531
Validation loss: 2.750620964843596

Epoch: 5| Step: 8
Training loss: 2.431034315883102
Validation loss: 2.7491081876212555

Epoch: 5| Step: 9
Training loss: 3.268749293952705
Validation loss: 2.7565472840961385

Epoch: 5| Step: 10
Training loss: 2.982056201233789
Validation loss: 2.7501711330694403

Epoch: 83| Step: 0
Training loss: 2.327837625471133
Validation loss: 2.749200066931342

Epoch: 5| Step: 1
Training loss: 3.4505692772493597
Validation loss: 2.7503888777210235

Epoch: 5| Step: 2
Training loss: 3.2309341187721845
Validation loss: 2.745821348235077

Epoch: 5| Step: 3
Training loss: 3.2029475465327004
Validation loss: 2.749438738483703

Epoch: 5| Step: 4
Training loss: 2.779752692604768
Validation loss: 2.750421570042456

Epoch: 5| Step: 5
Training loss: 3.5178753919453136
Validation loss: 2.7452638138328838

Epoch: 5| Step: 6
Training loss: 2.878385789220568
Validation loss: 2.7503015048998343

Epoch: 5| Step: 7
Training loss: 2.8417030764696185
Validation loss: 2.7515445652439

Epoch: 5| Step: 8
Training loss: 3.088581893341577
Validation loss: 2.7541572176590448

Epoch: 5| Step: 9
Training loss: 3.1742857242234495
Validation loss: 2.7553220952954187

Epoch: 5| Step: 10
Training loss: 3.1312967567227017
Validation loss: 2.7529910108907196

Epoch: 84| Step: 0
Training loss: 3.41879063779121
Validation loss: 2.748593136454397

Epoch: 5| Step: 1
Training loss: 2.715144693723564
Validation loss: 2.744796425713562

Epoch: 5| Step: 2
Training loss: 2.9113642495955814
Validation loss: 2.7479355269986168

Epoch: 5| Step: 3
Training loss: 2.8126754706004533
Validation loss: 2.746254315592988

Epoch: 5| Step: 4
Training loss: 2.7347357811652744
Validation loss: 2.742616529020995

Epoch: 5| Step: 5
Training loss: 3.281375846266015
Validation loss: 2.745820931826409

Epoch: 5| Step: 6
Training loss: 2.8269355759676214
Validation loss: 2.7425855654960096

Epoch: 5| Step: 7
Training loss: 3.7699805431723963
Validation loss: 2.7432159822058844

Epoch: 5| Step: 8
Training loss: 3.514592676125805
Validation loss: 2.744842127834878

Epoch: 5| Step: 9
Training loss: 2.343112095807212
Validation loss: 2.744324653383329

Epoch: 5| Step: 10
Training loss: 3.1776435900042683
Validation loss: 2.74456928239047

Epoch: 85| Step: 0
Training loss: 2.5553911739039603
Validation loss: 2.747106282572292

Epoch: 5| Step: 1
Training loss: 2.5630058161520335
Validation loss: 2.7575239469618356

Epoch: 5| Step: 2
Training loss: 3.2583055740565867
Validation loss: 2.7608124634768068

Epoch: 5| Step: 3
Training loss: 2.811006785414088
Validation loss: 2.7643818296068186

Epoch: 5| Step: 4
Training loss: 3.941997200224108
Validation loss: 2.754947742999601

Epoch: 5| Step: 5
Training loss: 2.8327894997859717
Validation loss: 2.7418149934615235

Epoch: 5| Step: 6
Training loss: 3.2091766504135557
Validation loss: 2.7415382549924945

Epoch: 5| Step: 7
Training loss: 3.3581481112635005
Validation loss: 2.7399513249826466

Epoch: 5| Step: 8
Training loss: 3.3314367302811276
Validation loss: 2.741424016733891

Epoch: 5| Step: 9
Training loss: 2.8164457828958724
Validation loss: 2.7414637359757448

Epoch: 5| Step: 10
Training loss: 2.7350080356793676
Validation loss: 2.742528297243257

Epoch: 86| Step: 0
Training loss: 2.9701467340358962
Validation loss: 2.7401677083935634

Epoch: 5| Step: 1
Training loss: 2.325745666047173
Validation loss: 2.74228150146699

Epoch: 5| Step: 2
Training loss: 2.712860656528813
Validation loss: 2.741947430591266

Epoch: 5| Step: 3
Training loss: 2.8146778575536806
Validation loss: 2.7396017450070875

Epoch: 5| Step: 4
Training loss: 3.099284606341592
Validation loss: 2.750834037439528

Epoch: 5| Step: 5
Training loss: 3.480767679274927
Validation loss: 2.7502297382840504

Epoch: 5| Step: 6
Training loss: 3.2210155032524113
Validation loss: 2.744115349467038

Epoch: 5| Step: 7
Training loss: 3.0443558671538424
Validation loss: 2.7413715908300444

Epoch: 5| Step: 8
Training loss: 3.413788459306971
Validation loss: 2.7422747143978885

Epoch: 5| Step: 9
Training loss: 2.9538124535698365
Validation loss: 2.741876462120803

Epoch: 5| Step: 10
Training loss: 3.598193133757529
Validation loss: 2.737793468313762

Epoch: 87| Step: 0
Training loss: 2.638059826054653
Validation loss: 2.7375323867698835

Epoch: 5| Step: 1
Training loss: 3.3739948895319034
Validation loss: 2.7394890814428403

Epoch: 5| Step: 2
Training loss: 2.645715806007831
Validation loss: 2.7408755304905887

Epoch: 5| Step: 3
Training loss: 2.8833773093278614
Validation loss: 2.7428510720952275

Epoch: 5| Step: 4
Training loss: 3.0188110598120828
Validation loss: 2.7417012697932335

Epoch: 5| Step: 5
Training loss: 2.8860833858675434
Validation loss: 2.743844798396641

Epoch: 5| Step: 6
Training loss: 3.09506398050121
Validation loss: 2.738818588082065

Epoch: 5| Step: 7
Training loss: 3.2865611371114323
Validation loss: 2.739258791439483

Epoch: 5| Step: 8
Training loss: 3.2476215462554494
Validation loss: 2.7338724441565474

Epoch: 5| Step: 9
Training loss: 3.6746478061201238
Validation loss: 2.7349821452058376

Epoch: 5| Step: 10
Training loss: 2.7265449239169803
Validation loss: 2.739234403949968

Epoch: 88| Step: 0
Training loss: 3.3908089442831866
Validation loss: 2.7403951679042224

Epoch: 5| Step: 1
Training loss: 3.0398723239188086
Validation loss: 2.7422552617794964

Epoch: 5| Step: 2
Training loss: 2.5976486320670724
Validation loss: 2.7361752847990197

Epoch: 5| Step: 3
Training loss: 3.2687405412876265
Validation loss: 2.733020028837336

Epoch: 5| Step: 4
Training loss: 2.845808855866539
Validation loss: 2.7346422702940254

Epoch: 5| Step: 5
Training loss: 3.7095519360296163
Validation loss: 2.732665998152024

Epoch: 5| Step: 6
Training loss: 2.7640772222339254
Validation loss: 2.730198547128147

Epoch: 5| Step: 7
Training loss: 2.9293139410278473
Validation loss: 2.732483909136314

Epoch: 5| Step: 8
Training loss: 3.2559913283567683
Validation loss: 2.7302182865931295

Epoch: 5| Step: 9
Training loss: 2.828278258159655
Validation loss: 2.732445864501863

Epoch: 5| Step: 10
Training loss: 2.9041331795978826
Validation loss: 2.7338147008017333

Epoch: 89| Step: 0
Training loss: 3.1309209045341944
Validation loss: 2.7325973990916377

Epoch: 5| Step: 1
Training loss: 3.20757048484085
Validation loss: 2.72864174759625

Epoch: 5| Step: 2
Training loss: 3.1440107779669995
Validation loss: 2.732494255684123

Epoch: 5| Step: 3
Training loss: 2.5028698661403666
Validation loss: 2.736444273571378

Epoch: 5| Step: 4
Training loss: 2.8044285561718922
Validation loss: 2.7340574431127904

Epoch: 5| Step: 5
Training loss: 3.6255671616524143
Validation loss: 2.739396802962997

Epoch: 5| Step: 6
Training loss: 2.298232112294139
Validation loss: 2.7431545038438254

Epoch: 5| Step: 7
Training loss: 2.976888964113893
Validation loss: 2.747717794124292

Epoch: 5| Step: 8
Training loss: 3.494362514352778
Validation loss: 2.7391175416426568

Epoch: 5| Step: 9
Training loss: 2.589649774298009
Validation loss: 2.7312197949697348

Epoch: 5| Step: 10
Training loss: 3.635526566178703
Validation loss: 2.726439366309129

Epoch: 90| Step: 0
Training loss: 3.0305731892813315
Validation loss: 2.7255851267170685

Epoch: 5| Step: 1
Training loss: 3.358132917862359
Validation loss: 2.7253735887840587

Epoch: 5| Step: 2
Training loss: 2.9083905284544262
Validation loss: 2.7258649839364324

Epoch: 5| Step: 3
Training loss: 2.8174533035213187
Validation loss: 2.7256208479664608

Epoch: 5| Step: 4
Training loss: 2.954942577856249
Validation loss: 2.7220837431104563

Epoch: 5| Step: 5
Training loss: 2.614139980301148
Validation loss: 2.7224090455001635

Epoch: 5| Step: 6
Training loss: 3.352743727595309
Validation loss: 2.725260774444558

Epoch: 5| Step: 7
Training loss: 2.7729358488050413
Validation loss: 2.7262381784371863

Epoch: 5| Step: 8
Training loss: 3.3781407189157875
Validation loss: 2.7267812781028993

Epoch: 5| Step: 9
Training loss: 3.2407894199489613
Validation loss: 2.7228508350378084

Epoch: 5| Step: 10
Training loss: 3.085495079292524
Validation loss: 2.7239636915820813

Epoch: 91| Step: 0
Training loss: 3.1787200880724664
Validation loss: 2.7231980051667004

Epoch: 5| Step: 1
Training loss: 3.236570046498848
Validation loss: 2.720768178637003

Epoch: 5| Step: 2
Training loss: 3.0349466651616757
Validation loss: 2.7223169965181193

Epoch: 5| Step: 3
Training loss: 3.056205196871326
Validation loss: 2.722754582799617

Epoch: 5| Step: 4
Training loss: 2.5757360313826876
Validation loss: 2.7225059794659527

Epoch: 5| Step: 5
Training loss: 2.752561589936996
Validation loss: 2.72225941017415

Epoch: 5| Step: 6
Training loss: 3.5330662740391565
Validation loss: 2.7244435882439317

Epoch: 5| Step: 7
Training loss: 3.468339225572173
Validation loss: 2.7279401517262865

Epoch: 5| Step: 8
Training loss: 2.8714795327019265
Validation loss: 2.732397072772937

Epoch: 5| Step: 9
Training loss: 3.0640955291477394
Validation loss: 2.728259462723426

Epoch: 5| Step: 10
Training loss: 2.5984917007087676
Validation loss: 2.729742678084651

Epoch: 92| Step: 0
Training loss: 3.3688555699157168
Validation loss: 2.7351704630245925

Epoch: 5| Step: 1
Training loss: 2.9220721336406497
Validation loss: 2.748127300612219

Epoch: 5| Step: 2
Training loss: 2.87594307068784
Validation loss: 2.76251992269643

Epoch: 5| Step: 3
Training loss: 3.456117463976693
Validation loss: 2.7614234288006374

Epoch: 5| Step: 4
Training loss: 2.807715011882734
Validation loss: 2.74371795955139

Epoch: 5| Step: 5
Training loss: 3.2801241441819116
Validation loss: 2.739567065103896

Epoch: 5| Step: 6
Training loss: 3.0833415641331143
Validation loss: 2.7295341241194047

Epoch: 5| Step: 7
Training loss: 2.7040623269036423
Validation loss: 2.7248875025302026

Epoch: 5| Step: 8
Training loss: 3.036264263950355
Validation loss: 2.7255324732798596

Epoch: 5| Step: 9
Training loss: 2.5111889317456044
Validation loss: 2.7200707874340186

Epoch: 5| Step: 10
Training loss: 3.425766356554356
Validation loss: 2.720388700088712

Epoch: 93| Step: 0
Training loss: 3.275467200114866
Validation loss: 2.7202024379061984

Epoch: 5| Step: 1
Training loss: 3.0474308387224927
Validation loss: 2.721839245376208

Epoch: 5| Step: 2
Training loss: 3.4297151673054738
Validation loss: 2.7177964762465803

Epoch: 5| Step: 3
Training loss: 2.9493367758875113
Validation loss: 2.7183587369471627

Epoch: 5| Step: 4
Training loss: 3.0828027182731756
Validation loss: 2.7177508098347496

Epoch: 5| Step: 5
Training loss: 2.983630661737337
Validation loss: 2.720840364304596

Epoch: 5| Step: 6
Training loss: 3.350734368296712
Validation loss: 2.7161692854461155

Epoch: 5| Step: 7
Training loss: 3.171044452337616
Validation loss: 2.719456390542939

Epoch: 5| Step: 8
Training loss: 3.026667641234836
Validation loss: 2.716158494453903

Epoch: 5| Step: 9
Training loss: 2.581245891577012
Validation loss: 2.718875918397331

Epoch: 5| Step: 10
Training loss: 2.443571500771427
Validation loss: 2.7199026325220474

Epoch: 94| Step: 0
Training loss: 3.1036981489357225
Validation loss: 2.721740279508627

Epoch: 5| Step: 1
Training loss: 3.0386083896143266
Validation loss: 2.7207598500868393

Epoch: 5| Step: 2
Training loss: 3.3138915683777785
Validation loss: 2.722906226456913

Epoch: 5| Step: 3
Training loss: 2.7765232167124254
Validation loss: 2.7211331342446363

Epoch: 5| Step: 4
Training loss: 2.903196309736255
Validation loss: 2.7355156526036923

Epoch: 5| Step: 5
Training loss: 3.2562057228519348
Validation loss: 2.730219972075035

Epoch: 5| Step: 6
Training loss: 3.0049174061625865
Validation loss: 2.738143178035693

Epoch: 5| Step: 7
Training loss: 2.660056046490598
Validation loss: 2.730604273282547

Epoch: 5| Step: 8
Training loss: 3.1868053502134273
Validation loss: 2.7349221071594196

Epoch: 5| Step: 9
Training loss: 2.5587584930264065
Validation loss: 2.7200585765008403

Epoch: 5| Step: 10
Training loss: 3.6279003773630953
Validation loss: 2.7177067953356064

Epoch: 95| Step: 0
Training loss: 3.101675190067486
Validation loss: 2.715914338330228

Epoch: 5| Step: 1
Training loss: 2.7163385680672483
Validation loss: 2.7161820603473665

Epoch: 5| Step: 2
Training loss: 2.7469291881298306
Validation loss: 2.714555768904089

Epoch: 5| Step: 3
Training loss: 2.4234797913669133
Validation loss: 2.71373153311057

Epoch: 5| Step: 4
Training loss: 3.901937805384007
Validation loss: 2.7134344527626406

Epoch: 5| Step: 5
Training loss: 2.6491835002078354
Validation loss: 2.711976887138097

Epoch: 5| Step: 6
Training loss: 3.746473179795402
Validation loss: 2.7139358415293047

Epoch: 5| Step: 7
Training loss: 2.9844913160415367
Validation loss: 2.7136657364002446

Epoch: 5| Step: 8
Training loss: 3.2704881295596873
Validation loss: 2.7088820009766703

Epoch: 5| Step: 9
Training loss: 2.937685209888054
Validation loss: 2.710481637560323

Epoch: 5| Step: 10
Training loss: 2.4933547392689555
Validation loss: 2.7133201981280703

Epoch: 96| Step: 0
Training loss: 2.606052590630714
Validation loss: 2.727116904129692

Epoch: 5| Step: 1
Training loss: 2.924382240725067
Validation loss: 2.7356432695609576

Epoch: 5| Step: 2
Training loss: 3.1889556851925023
Validation loss: 2.766797984441811

Epoch: 5| Step: 3
Training loss: 3.2301968479700647
Validation loss: 2.7803920073653763

Epoch: 5| Step: 4
Training loss: 2.875682915558487
Validation loss: 2.763896593232332

Epoch: 5| Step: 5
Training loss: 3.414243645303397
Validation loss: 2.747990217804844

Epoch: 5| Step: 6
Training loss: 2.6003363758518097
Validation loss: 2.7266745901134324

Epoch: 5| Step: 7
Training loss: 3.150660787635298
Validation loss: 2.7169678424157717

Epoch: 5| Step: 8
Training loss: 3.2048808425914936
Validation loss: 2.7130386915859726

Epoch: 5| Step: 9
Training loss: 3.545521347599213
Validation loss: 2.725484040324416

Epoch: 5| Step: 10
Training loss: 2.7234393489128834
Validation loss: 2.7264621423615463

Epoch: 97| Step: 0
Training loss: 3.0400980383975855
Validation loss: 2.737130602325192

Epoch: 5| Step: 1
Training loss: 2.8716261597129007
Validation loss: 2.727250966817755

Epoch: 5| Step: 2
Training loss: 3.1152435589598166
Validation loss: 2.715350769909346

Epoch: 5| Step: 3
Training loss: 2.750737004789633
Validation loss: 2.71692687904176

Epoch: 5| Step: 4
Training loss: 3.456905177344523
Validation loss: 2.7113615373849154

Epoch: 5| Step: 5
Training loss: 3.5075702541110156
Validation loss: 2.7102536633985372

Epoch: 5| Step: 6
Training loss: 3.0870830486014467
Validation loss: 2.7072807724626458

Epoch: 5| Step: 7
Training loss: 3.056471203871022
Validation loss: 2.7061728279027015

Epoch: 5| Step: 8
Training loss: 2.975166694394792
Validation loss: 2.710123471677026

Epoch: 5| Step: 9
Training loss: 2.7494002468496124
Validation loss: 2.7071577835501768

Epoch: 5| Step: 10
Training loss: 2.798111541013576
Validation loss: 2.708985031765097

Epoch: 98| Step: 0
Training loss: 3.3686262628198413
Validation loss: 2.726748299525891

Epoch: 5| Step: 1
Training loss: 3.2464210170842005
Validation loss: 2.7505739345860496

Epoch: 5| Step: 2
Training loss: 2.991390749676233
Validation loss: 2.7608406810810613

Epoch: 5| Step: 3
Training loss: 2.2403967747778646
Validation loss: 2.804078809037769

Epoch: 5| Step: 4
Training loss: 3.078766886594727
Validation loss: 2.7928079437332993

Epoch: 5| Step: 5
Training loss: 3.0043378304137787
Validation loss: 2.8183294755785764

Epoch: 5| Step: 6
Training loss: 3.237037336952602
Validation loss: 2.8729032483074906

Epoch: 5| Step: 7
Training loss: 2.778714427917652
Validation loss: 2.810262275229734

Epoch: 5| Step: 8
Training loss: 3.0755221598097706
Validation loss: 2.772520999472923

Epoch: 5| Step: 9
Training loss: 3.3888156827374636
Validation loss: 2.731547687441078

Epoch: 5| Step: 10
Training loss: 3.1163488038975533
Validation loss: 2.7118334468068475

Epoch: 99| Step: 0
Training loss: 3.1986138560281994
Validation loss: 2.7001860375233844

Epoch: 5| Step: 1
Training loss: 2.750747059005861
Validation loss: 2.706007532591648

Epoch: 5| Step: 2
Training loss: 3.6373904024897454
Validation loss: 2.711581469145979

Epoch: 5| Step: 3
Training loss: 3.0940844422488865
Validation loss: 2.723716673514112

Epoch: 5| Step: 4
Training loss: 2.827311530539685
Validation loss: 2.722533442473414

Epoch: 5| Step: 5
Training loss: 2.7769745099742327
Validation loss: 2.7284132706545545

Epoch: 5| Step: 6
Training loss: 3.284093877809616
Validation loss: 2.7152152311846547

Epoch: 5| Step: 7
Training loss: 3.2448375488433605
Validation loss: 2.711895625760443

Epoch: 5| Step: 8
Training loss: 2.909108222834043
Validation loss: 2.708964026559277

Epoch: 5| Step: 9
Training loss: 2.967210711910179
Validation loss: 2.7063642217265325

Epoch: 5| Step: 10
Training loss: 2.7748019448475745
Validation loss: 2.7051771706810093

Epoch: 100| Step: 0
Training loss: 3.4138356707399384
Validation loss: 2.7016259178260773

Epoch: 5| Step: 1
Training loss: 2.861430112303576
Validation loss: 2.7017708821727737

Epoch: 5| Step: 2
Training loss: 3.1509207878361942
Validation loss: 2.6991538598916227

Epoch: 5| Step: 3
Training loss: 3.254378816834247
Validation loss: 2.697483651503788

Epoch: 5| Step: 4
Training loss: 3.2393933860968005
Validation loss: 2.7014197512376827

Epoch: 5| Step: 5
Training loss: 2.6981899658186204
Validation loss: 2.7276489799140538

Epoch: 5| Step: 6
Training loss: 2.8797207098219
Validation loss: 2.767940830163777

Epoch: 5| Step: 7
Training loss: 2.733075165380407
Validation loss: 2.7869967958822865

Epoch: 5| Step: 8
Training loss: 2.8584553224502804
Validation loss: 2.761644183268168

Epoch: 5| Step: 9
Training loss: 3.289039448636933
Validation loss: 2.7248443221116454

Epoch: 5| Step: 10
Training loss: 3.1714032202828006
Validation loss: 2.72168679531914

Epoch: 101| Step: 0
Training loss: 2.4993685878662824
Validation loss: 2.7160105498088756

Epoch: 5| Step: 1
Training loss: 3.0337361630696726
Validation loss: 2.712041599937673

Epoch: 5| Step: 2
Training loss: 2.8578260218079845
Validation loss: 2.7090483132690593

Epoch: 5| Step: 3
Training loss: 3.1475968291619236
Validation loss: 2.710989211344817

Epoch: 5| Step: 4
Training loss: 3.2124854299014496
Validation loss: 2.70590864994403

Epoch: 5| Step: 5
Training loss: 2.913824567720266
Validation loss: 2.703390191555029

Epoch: 5| Step: 6
Training loss: 2.922602598609988
Validation loss: 2.703761386071847

Epoch: 5| Step: 7
Training loss: 3.3427727242640928
Validation loss: 2.7022760070281118

Epoch: 5| Step: 8
Training loss: 2.9593794857905547
Validation loss: 2.7018969599391185

Epoch: 5| Step: 9
Training loss: 3.217562558292895
Validation loss: 2.7029467520435784

Epoch: 5| Step: 10
Training loss: 3.214111541388737
Validation loss: 2.70251911103564

Epoch: 102| Step: 0
Training loss: 3.111359389555723
Validation loss: 2.6977238109660004

Epoch: 5| Step: 1
Training loss: 2.594687878281213
Validation loss: 2.7015304817945123

Epoch: 5| Step: 2
Training loss: 2.5856581246013355
Validation loss: 2.7020379770525866

Epoch: 5| Step: 3
Training loss: 3.0707290017474436
Validation loss: 2.7095473147347033

Epoch: 5| Step: 4
Training loss: 2.9595109628383125
Validation loss: 2.7183456827470676

Epoch: 5| Step: 5
Training loss: 2.8093601926555514
Validation loss: 2.7383872189791982

Epoch: 5| Step: 6
Training loss: 3.409292839312072
Validation loss: 2.7387238228041983

Epoch: 5| Step: 7
Training loss: 3.110182920761759
Validation loss: 2.7179980248799285

Epoch: 5| Step: 8
Training loss: 3.4466785309204298
Validation loss: 2.6979196278976345

Epoch: 5| Step: 9
Training loss: 3.1964151210151805
Validation loss: 2.6972654748274594

Epoch: 5| Step: 10
Training loss: 2.896531951575294
Validation loss: 2.7029216006273997

Epoch: 103| Step: 0
Training loss: 2.96297849500965
Validation loss: 2.696595437665351

Epoch: 5| Step: 1
Training loss: 3.1312891426609406
Validation loss: 2.695603042881774

Epoch: 5| Step: 2
Training loss: 3.0132451129197353
Validation loss: 2.6942784258205648

Epoch: 5| Step: 3
Training loss: 3.3084249802458197
Validation loss: 2.693992439154169

Epoch: 5| Step: 4
Training loss: 2.9380601389464305
Validation loss: 2.6943553830835567

Epoch: 5| Step: 5
Training loss: 3.0900366490236926
Validation loss: 2.688287764047848

Epoch: 5| Step: 6
Training loss: 2.5184244253101054
Validation loss: 2.6922212031829957

Epoch: 5| Step: 7
Training loss: 3.431225963848816
Validation loss: 2.6916919552261387

Epoch: 5| Step: 8
Training loss: 2.6635170655102174
Validation loss: 2.688361620975968

Epoch: 5| Step: 9
Training loss: 3.180784743786305
Validation loss: 2.68936145798517

Epoch: 5| Step: 10
Training loss: 3.0057215172557874
Validation loss: 2.6892052687408516

Epoch: 104| Step: 0
Training loss: 3.95193475589101
Validation loss: 2.692856765482998

Epoch: 5| Step: 1
Training loss: 3.2693632349303225
Validation loss: 2.7001807311476784

Epoch: 5| Step: 2
Training loss: 3.234250273580157
Validation loss: 2.694491503947707

Epoch: 5| Step: 3
Training loss: 2.887192456269761
Validation loss: 2.6892774808449635

Epoch: 5| Step: 4
Training loss: 3.0033487067921105
Validation loss: 2.6910864501025094

Epoch: 5| Step: 5
Training loss: 2.7640953359599654
Validation loss: 2.6907472054653105

Epoch: 5| Step: 6
Training loss: 2.8183038802575227
Validation loss: 2.6973773106603303

Epoch: 5| Step: 7
Training loss: 3.0002077348629617
Validation loss: 2.6973000409041377

Epoch: 5| Step: 8
Training loss: 2.3669822276535646
Validation loss: 2.701187865130056

Epoch: 5| Step: 9
Training loss: 3.0788677113465215
Validation loss: 2.7071854941139253

Epoch: 5| Step: 10
Training loss: 2.471917739672286
Validation loss: 2.719119763338459

Epoch: 105| Step: 0
Training loss: 2.5571540334507534
Validation loss: 2.722737753279019

Epoch: 5| Step: 1
Training loss: 3.4772284737829233
Validation loss: 2.7299863393349306

Epoch: 5| Step: 2
Training loss: 3.2666945462756374
Validation loss: 2.742614960522384

Epoch: 5| Step: 3
Training loss: 2.268303701677629
Validation loss: 2.733533519174203

Epoch: 5| Step: 4
Training loss: 3.563485795539902
Validation loss: 2.7181987946259976

Epoch: 5| Step: 5
Training loss: 2.941713274045303
Validation loss: 2.715417375485099

Epoch: 5| Step: 6
Training loss: 2.7477489274669904
Validation loss: 2.721815633333004

Epoch: 5| Step: 7
Training loss: 3.3017761536850085
Validation loss: 2.711145490248453

Epoch: 5| Step: 8
Training loss: 3.3792155747141415
Validation loss: 2.71499961629275

Epoch: 5| Step: 9
Training loss: 2.6507420598513525
Validation loss: 2.6850752044862056

Epoch: 5| Step: 10
Training loss: 2.8496448496335414
Validation loss: 2.6836883460900673

Epoch: 106| Step: 0
Training loss: 3.0538129017894566
Validation loss: 2.6817379552094858

Epoch: 5| Step: 1
Training loss: 3.0644820669641906
Validation loss: 2.68593921636148

Epoch: 5| Step: 2
Training loss: 2.905072701836238
Validation loss: 2.6841428640655844

Epoch: 5| Step: 3
Training loss: 3.3619809001718193
Validation loss: 2.684121528825617

Epoch: 5| Step: 4
Training loss: 3.005398819746701
Validation loss: 2.6804381680337115

Epoch: 5| Step: 5
Training loss: 3.277742673035766
Validation loss: 2.685020568884058

Epoch: 5| Step: 6
Training loss: 3.1422846569972913
Validation loss: 2.681719289022819

Epoch: 5| Step: 7
Training loss: 2.941054770251838
Validation loss: 2.6875222165371584

Epoch: 5| Step: 8
Training loss: 3.5107064660474068
Validation loss: 2.6861066227662844

Epoch: 5| Step: 9
Training loss: 2.389557743572937
Validation loss: 2.682045730672119

Epoch: 5| Step: 10
Training loss: 2.243177773446615
Validation loss: 2.6807066902991044

Epoch: 107| Step: 0
Training loss: 2.620072872371466
Validation loss: 2.687225198015222

Epoch: 5| Step: 1
Training loss: 3.375721183300726
Validation loss: 2.6940383246337523

Epoch: 5| Step: 2
Training loss: 3.068112271737673
Validation loss: 2.7020808862536287

Epoch: 5| Step: 3
Training loss: 2.7552590801178347
Validation loss: 2.7028610761683107

Epoch: 5| Step: 4
Training loss: 3.1350670975557695
Validation loss: 2.705973565655683

Epoch: 5| Step: 5
Training loss: 3.272467931673367
Validation loss: 2.715635702447528

Epoch: 5| Step: 6
Training loss: 2.7624615178944847
Validation loss: 2.706690516409472

Epoch: 5| Step: 7
Training loss: 2.8575403550069356
Validation loss: 2.7086053429276244

Epoch: 5| Step: 8
Training loss: 3.0523607216942423
Validation loss: 2.71612514715716

Epoch: 5| Step: 9
Training loss: 2.9625444304277195
Validation loss: 2.6980728431722993

Epoch: 5| Step: 10
Training loss: 3.3071624650523996
Validation loss: 2.695983152697105

Epoch: 108| Step: 0
Training loss: 3.1034732189126126
Validation loss: 2.6909341555701545

Epoch: 5| Step: 1
Training loss: 3.189717736746044
Validation loss: 2.6931107149937166

Epoch: 5| Step: 2
Training loss: 3.672481275787298
Validation loss: 2.6861525980968173

Epoch: 5| Step: 3
Training loss: 2.79820611914115
Validation loss: 2.684498487553568

Epoch: 5| Step: 4
Training loss: 2.9342760290775876
Validation loss: 2.6809650438287473

Epoch: 5| Step: 5
Training loss: 3.199673761188717
Validation loss: 2.6864549856821878

Epoch: 5| Step: 6
Training loss: 3.125408451090036
Validation loss: 2.6900989817642507

Epoch: 5| Step: 7
Training loss: 2.9103638440533426
Validation loss: 2.694348798794422

Epoch: 5| Step: 8
Training loss: 2.5478578321058833
Validation loss: 2.6896089262103837

Epoch: 5| Step: 9
Training loss: 2.810552049622799
Validation loss: 2.698784411210019

Epoch: 5| Step: 10
Training loss: 2.684037928351624
Validation loss: 2.7171991319300135

Epoch: 109| Step: 0
Training loss: 3.266962680898916
Validation loss: 2.726452132581451

Epoch: 5| Step: 1
Training loss: 3.239661719711875
Validation loss: 2.7446396661018495

Epoch: 5| Step: 2
Training loss: 3.3102550456735544
Validation loss: 2.7464864646045655

Epoch: 5| Step: 3
Training loss: 3.1320408658008256
Validation loss: 2.728258609510565

Epoch: 5| Step: 4
Training loss: 3.1480556663525805
Validation loss: 2.7117367193705406

Epoch: 5| Step: 5
Training loss: 3.120033437354081
Validation loss: 2.702202334024123

Epoch: 5| Step: 6
Training loss: 2.9673624108674694
Validation loss: 2.6814079596307523

Epoch: 5| Step: 7
Training loss: 2.505507791641413
Validation loss: 2.6730309340100638

Epoch: 5| Step: 8
Training loss: 2.4562402856066843
Validation loss: 2.674496793832143

Epoch: 5| Step: 9
Training loss: 3.040503466726647
Validation loss: 2.676220310693271

Epoch: 5| Step: 10
Training loss: 3.089690965426934
Validation loss: 2.677439076143081

Epoch: 110| Step: 0
Training loss: 2.8145306356161806
Validation loss: 2.679557432396793

Epoch: 5| Step: 1
Training loss: 2.5018236184829794
Validation loss: 2.687516231731095

Epoch: 5| Step: 2
Training loss: 2.3126122730940617
Validation loss: 2.6947689640810406

Epoch: 5| Step: 3
Training loss: 3.12670516222889
Validation loss: 2.6939091297792954

Epoch: 5| Step: 4
Training loss: 3.2237370938430643
Validation loss: 2.698512075098053

Epoch: 5| Step: 5
Training loss: 2.897552437361281
Validation loss: 2.7038721401979093

Epoch: 5| Step: 6
Training loss: 3.2383520765117177
Validation loss: 2.6999445208793853

Epoch: 5| Step: 7
Training loss: 3.1574209326285243
Validation loss: 2.685693192151368

Epoch: 5| Step: 8
Training loss: 3.441742931441558
Validation loss: 2.679598930686834

Epoch: 5| Step: 9
Training loss: 3.143483241994491
Validation loss: 2.6746067958008997

Epoch: 5| Step: 10
Training loss: 3.128368850639166
Validation loss: 2.6795420192659076

Epoch: 111| Step: 0
Training loss: 2.6912116214267674
Validation loss: 2.6776885098009573

Epoch: 5| Step: 1
Training loss: 3.241424985635176
Validation loss: 2.674827220336793

Epoch: 5| Step: 2
Training loss: 3.437547440634996
Validation loss: 2.678479954866227

Epoch: 5| Step: 3
Training loss: 3.0037736999872116
Validation loss: 2.6795992856319724

Epoch: 5| Step: 4
Training loss: 2.7405254837463175
Validation loss: 2.6752002976121685

Epoch: 5| Step: 5
Training loss: 3.382166565152946
Validation loss: 2.6739846985521103

Epoch: 5| Step: 6
Training loss: 2.895569402801955
Validation loss: 2.673126720039971

Epoch: 5| Step: 7
Training loss: 3.1764646501007756
Validation loss: 2.67281346899774

Epoch: 5| Step: 8
Training loss: 2.394593976989884
Validation loss: 2.673614048264805

Epoch: 5| Step: 9
Training loss: 2.776417852872654
Validation loss: 2.672477613433016

Epoch: 5| Step: 10
Training loss: 3.316151172187685
Validation loss: 2.670319649541037

Epoch: 112| Step: 0
Training loss: 2.953311006046857
Validation loss: 2.668150805724118

Epoch: 5| Step: 1
Training loss: 2.9770443343608437
Validation loss: 2.671643706546438

Epoch: 5| Step: 2
Training loss: 2.6227383634538013
Validation loss: 2.6678206035818324

Epoch: 5| Step: 3
Training loss: 2.948063301959583
Validation loss: 2.671231578859532

Epoch: 5| Step: 4
Training loss: 3.0025606353506866
Validation loss: 2.672651292180294

Epoch: 5| Step: 5
Training loss: 3.2795716852727543
Validation loss: 2.6725183583228413

Epoch: 5| Step: 6
Training loss: 3.4167178235449853
Validation loss: 2.6708645279847496

Epoch: 5| Step: 7
Training loss: 3.429537341886589
Validation loss: 2.6752993522272184

Epoch: 5| Step: 8
Training loss: 2.6165798108047524
Validation loss: 2.677568053665267

Epoch: 5| Step: 9
Training loss: 2.4137657995511925
Validation loss: 2.676620440187044

Epoch: 5| Step: 10
Training loss: 3.2115862485685525
Validation loss: 2.681011664806784

Epoch: 113| Step: 0
Training loss: 3.191144019644643
Validation loss: 2.6796235232030443

Epoch: 5| Step: 1
Training loss: 2.8628975271526156
Validation loss: 2.6930558387880743

Epoch: 5| Step: 2
Training loss: 2.664070912456934
Validation loss: 2.6843749858274544

Epoch: 5| Step: 3
Training loss: 2.5892446524084267
Validation loss: 2.689738929985498

Epoch: 5| Step: 4
Training loss: 2.7559377549648545
Validation loss: 2.6868380689845948

Epoch: 5| Step: 5
Training loss: 2.9580813197576763
Validation loss: 2.6845386498649124

Epoch: 5| Step: 6
Training loss: 2.753911531051009
Validation loss: 2.6899532244835833

Epoch: 5| Step: 7
Training loss: 3.680413759647101
Validation loss: 2.6769775820459776

Epoch: 5| Step: 8
Training loss: 3.4432948426135317
Validation loss: 2.67782748833934

Epoch: 5| Step: 9
Training loss: 2.9087044800596944
Validation loss: 2.662232479628977

Epoch: 5| Step: 10
Training loss: 3.020015386580119
Validation loss: 2.6633561457064183

Epoch: 114| Step: 0
Training loss: 3.49764908446259
Validation loss: 2.663943362053769

Epoch: 5| Step: 1
Training loss: 3.25543228396303
Validation loss: 2.665653531084213

Epoch: 5| Step: 2
Training loss: 2.906452951215518
Validation loss: 2.6624649344032076

Epoch: 5| Step: 3
Training loss: 2.8863802699795547
Validation loss: 2.6603687876014144

Epoch: 5| Step: 4
Training loss: 2.919911096865559
Validation loss: 2.661376494966797

Epoch: 5| Step: 5
Training loss: 3.052482101550416
Validation loss: 2.656721959419191

Epoch: 5| Step: 6
Training loss: 2.4599976697771155
Validation loss: 2.658462072384785

Epoch: 5| Step: 7
Training loss: 2.7637012924947157
Validation loss: 2.6590040750254227

Epoch: 5| Step: 8
Training loss: 3.1091418921728327
Validation loss: 2.657880209721

Epoch: 5| Step: 9
Training loss: 2.954153537765907
Validation loss: 2.659494506816013

Epoch: 5| Step: 10
Training loss: 3.1059394911492824
Validation loss: 2.670162607608927

Epoch: 115| Step: 0
Training loss: 3.020891088174774
Validation loss: 2.6589311072737356

Epoch: 5| Step: 1
Training loss: 3.2280880182738425
Validation loss: 2.672505348803631

Epoch: 5| Step: 2
Training loss: 2.9172316594349463
Validation loss: 2.6849882479690974

Epoch: 5| Step: 3
Training loss: 2.8545154070749934
Validation loss: 2.6810634618615823

Epoch: 5| Step: 4
Training loss: 3.2865775318968127
Validation loss: 2.6823221987260855

Epoch: 5| Step: 5
Training loss: 2.8326216720212036
Validation loss: 2.6643178592074412

Epoch: 5| Step: 6
Training loss: 3.10019175028736
Validation loss: 2.663859901113816

Epoch: 5| Step: 7
Training loss: 2.58915966084145
Validation loss: 2.6565008509474195

Epoch: 5| Step: 8
Training loss: 3.1876928233745874
Validation loss: 2.6557003661418306

Epoch: 5| Step: 9
Training loss: 3.025303779670655
Validation loss: 2.654936049631883

Epoch: 5| Step: 10
Training loss: 2.8773825351525777
Validation loss: 2.654620083237968

Epoch: 116| Step: 0
Training loss: 3.3686657557100923
Validation loss: 2.6552682170890445

Epoch: 5| Step: 1
Training loss: 3.2895982899405345
Validation loss: 2.651554788035659

Epoch: 5| Step: 2
Training loss: 2.86354935914347
Validation loss: 2.654484582363278

Epoch: 5| Step: 3
Training loss: 2.7490776422553425
Validation loss: 2.654806441897931

Epoch: 5| Step: 4
Training loss: 2.7386793862053342
Validation loss: 2.6627484323305257

Epoch: 5| Step: 5
Training loss: 2.91694723323872
Validation loss: 2.672739604460624

Epoch: 5| Step: 6
Training loss: 2.69678384178162
Validation loss: 2.6813897232980124

Epoch: 5| Step: 7
Training loss: 3.032859453626907
Validation loss: 2.7094955730324517

Epoch: 5| Step: 8
Training loss: 3.3751432600345774
Validation loss: 2.725276541396769

Epoch: 5| Step: 9
Training loss: 2.6176706352105032
Validation loss: 2.717876800935289

Epoch: 5| Step: 10
Training loss: 3.3397006890961087
Validation loss: 2.7116316716050055

Epoch: 117| Step: 0
Training loss: 3.3380703328050068
Validation loss: 2.695694269408554

Epoch: 5| Step: 1
Training loss: 2.823800252506956
Validation loss: 2.6693973064498766

Epoch: 5| Step: 2
Training loss: 2.735498339287671
Validation loss: 2.660076005768691

Epoch: 5| Step: 3
Training loss: 3.341907457030338
Validation loss: 2.659365790263829

Epoch: 5| Step: 4
Training loss: 2.906371247418303
Validation loss: 2.6566416423344337

Epoch: 5| Step: 5
Training loss: 3.2124593056799045
Validation loss: 2.652112036905262

Epoch: 5| Step: 6
Training loss: 2.840621065277631
Validation loss: 2.649843645658896

Epoch: 5| Step: 7
Training loss: 2.8611471385806775
Validation loss: 2.6536389773594435

Epoch: 5| Step: 8
Training loss: 2.7976027239909778
Validation loss: 2.6525853588407267

Epoch: 5| Step: 9
Training loss: 2.917834420540082
Validation loss: 2.6502869665599924

Epoch: 5| Step: 10
Training loss: 3.0820006162332145
Validation loss: 2.6501228694869066

Epoch: 118| Step: 0
Training loss: 3.6918436104166727
Validation loss: 2.652113225873613

Epoch: 5| Step: 1
Training loss: 3.252002832531135
Validation loss: 2.650063734667659

Epoch: 5| Step: 2
Training loss: 3.4634256826307745
Validation loss: 2.652375979637511

Epoch: 5| Step: 3
Training loss: 2.968541830694986
Validation loss: 2.650697022625944

Epoch: 5| Step: 4
Training loss: 2.8546293305983363
Validation loss: 2.650835126170939

Epoch: 5| Step: 5
Training loss: 2.714513788823091
Validation loss: 2.655009261396448

Epoch: 5| Step: 6
Training loss: 2.5841524814813823
Validation loss: 2.662020586793338

Epoch: 5| Step: 7
Training loss: 2.4697381468441244
Validation loss: 2.657129299258144

Epoch: 5| Step: 8
Training loss: 3.114731818054466
Validation loss: 2.660871146972193

Epoch: 5| Step: 9
Training loss: 3.116880320469316
Validation loss: 2.6645237024827257

Epoch: 5| Step: 10
Training loss: 2.294642602688328
Validation loss: 2.670380161292979

Epoch: 119| Step: 0
Training loss: 3.136471103189082
Validation loss: 2.6681982885834015

Epoch: 5| Step: 1
Training loss: 2.964669565504627
Validation loss: 2.6904855386799174

Epoch: 5| Step: 2
Training loss: 3.2569470616817915
Validation loss: 2.6936039433182044

Epoch: 5| Step: 3
Training loss: 2.939564405597081
Validation loss: 2.7011535167941476

Epoch: 5| Step: 4
Training loss: 2.9184841124752605
Validation loss: 2.701080603788104

Epoch: 5| Step: 5
Training loss: 3.0683172600646507
Validation loss: 2.694193691314282

Epoch: 5| Step: 6
Training loss: 2.8520478972041787
Validation loss: 2.6666998982922507

Epoch: 5| Step: 7
Training loss: 3.3165577920139664
Validation loss: 2.661958792413736

Epoch: 5| Step: 8
Training loss: 2.915930100941492
Validation loss: 2.653672089713957

Epoch: 5| Step: 9
Training loss: 2.779267794147972
Validation loss: 2.6461100024683275

Epoch: 5| Step: 10
Training loss: 2.652289186346209
Validation loss: 2.6488586414248214

Epoch: 120| Step: 0
Training loss: 3.167739652917675
Validation loss: 2.645265900298868

Epoch: 5| Step: 1
Training loss: 3.151882965180701
Validation loss: 2.651449117582715

Epoch: 5| Step: 2
Training loss: 2.6599289493106504
Validation loss: 2.6501457882398447

Epoch: 5| Step: 3
Training loss: 2.8757785903847894
Validation loss: 2.6496155618825457

Epoch: 5| Step: 4
Training loss: 2.836953057498777
Validation loss: 2.655798411481938

Epoch: 5| Step: 5
Training loss: 3.46853472067392
Validation loss: 2.652281233342108

Epoch: 5| Step: 6
Training loss: 3.018721339877537
Validation loss: 2.6473357282596477

Epoch: 5| Step: 7
Training loss: 2.4650938750492193
Validation loss: 2.6479710753739494

Epoch: 5| Step: 8
Training loss: 2.938732619078011
Validation loss: 2.6440504641636813

Epoch: 5| Step: 9
Training loss: 3.035149180282548
Validation loss: 2.643470467432637

Epoch: 5| Step: 10
Training loss: 3.2264017060418873
Validation loss: 2.6493874526648233

Epoch: 121| Step: 0
Training loss: 2.279032844738632
Validation loss: 2.6415869236297618

Epoch: 5| Step: 1
Training loss: 2.9144178894800734
Validation loss: 2.646329769399523

Epoch: 5| Step: 2
Training loss: 3.5190318236975764
Validation loss: 2.6508824743291517

Epoch: 5| Step: 3
Training loss: 3.0061985193868797
Validation loss: 2.647919097643935

Epoch: 5| Step: 4
Training loss: 2.5981243887674155
Validation loss: 2.64587126234672

Epoch: 5| Step: 5
Training loss: 2.909575825611931
Validation loss: 2.6482518267416

Epoch: 5| Step: 6
Training loss: 3.3206336012013935
Validation loss: 2.6535489289870964

Epoch: 5| Step: 7
Training loss: 2.924039803731083
Validation loss: 2.6573738900610997

Epoch: 5| Step: 8
Training loss: 2.9864435666352005
Validation loss: 2.657420472466093

Epoch: 5| Step: 9
Training loss: 3.3812608926706913
Validation loss: 2.663857653959825

Epoch: 5| Step: 10
Training loss: 2.8527924693801423
Validation loss: 2.6637081345639353

Epoch: 122| Step: 0
Training loss: 2.6672032432337347
Validation loss: 2.661002708883077

Epoch: 5| Step: 1
Training loss: 3.078780825697189
Validation loss: 2.65844858037844

Epoch: 5| Step: 2
Training loss: 3.3829891167538078
Validation loss: 2.658794900459963

Epoch: 5| Step: 3
Training loss: 2.1742195263723123
Validation loss: 2.654986022528662

Epoch: 5| Step: 4
Training loss: 2.9877043522490228
Validation loss: 2.6494460829699054

Epoch: 5| Step: 5
Training loss: 3.474242938887994
Validation loss: 2.6579141566068083

Epoch: 5| Step: 6
Training loss: 3.1539143900261872
Validation loss: 2.6584790966513094

Epoch: 5| Step: 7
Training loss: 3.223107508652031
Validation loss: 2.6548395590042615

Epoch: 5| Step: 8
Training loss: 2.911627931153405
Validation loss: 2.6612068084547404

Epoch: 5| Step: 9
Training loss: 2.8765879682235034
Validation loss: 2.6660130152163117

Epoch: 5| Step: 10
Training loss: 2.6143579474542102
Validation loss: 2.650831277083142

Epoch: 123| Step: 0
Training loss: 2.706918777397197
Validation loss: 2.6629440138817935

Epoch: 5| Step: 1
Training loss: 2.632610822701474
Validation loss: 2.6555525537873965

Epoch: 5| Step: 2
Training loss: 3.0377368536388345
Validation loss: 2.676109454436411

Epoch: 5| Step: 3
Training loss: 3.230716423679041
Validation loss: 2.681314954375602

Epoch: 5| Step: 4
Training loss: 3.1557882745502845
Validation loss: 2.6686262140021473

Epoch: 5| Step: 5
Training loss: 3.0826782011698484
Validation loss: 2.6770628202991613

Epoch: 5| Step: 6
Training loss: 2.9500062004929375
Validation loss: 2.681246376278964

Epoch: 5| Step: 7
Training loss: 2.7093986079013552
Validation loss: 2.6776868917808003

Epoch: 5| Step: 8
Training loss: 3.0635487843136477
Validation loss: 2.675321292529059

Epoch: 5| Step: 9
Training loss: 3.355202998516615
Validation loss: 2.675555082217569

Epoch: 5| Step: 10
Training loss: 2.811059540521411
Validation loss: 2.650382074328427

Epoch: 124| Step: 0
Training loss: 2.778448000690584
Validation loss: 2.640766401898639

Epoch: 5| Step: 1
Training loss: 3.1895595703302906
Validation loss: 2.6355303914457546

Epoch: 5| Step: 2
Training loss: 2.904254843761092
Validation loss: 2.636959081929044

Epoch: 5| Step: 3
Training loss: 3.006212477737346
Validation loss: 2.6431306631607474

Epoch: 5| Step: 4
Training loss: 2.7127055358364487
Validation loss: 2.641438383615764

Epoch: 5| Step: 5
Training loss: 3.0761097153938017
Validation loss: 2.647473396124919

Epoch: 5| Step: 6
Training loss: 2.951183993139829
Validation loss: 2.6464312763273394

Epoch: 5| Step: 7
Training loss: 3.015840987144583
Validation loss: 2.642086408372663

Epoch: 5| Step: 8
Training loss: 3.348911330554237
Validation loss: 2.640432155727676

Epoch: 5| Step: 9
Training loss: 2.8742980100005235
Validation loss: 2.640399314253757

Epoch: 5| Step: 10
Training loss: 2.9525651350596855
Validation loss: 2.6376583470373665

Epoch: 125| Step: 0
Training loss: 2.5059395804767033
Validation loss: 2.636420840771941

Epoch: 5| Step: 1
Training loss: 3.245842548662521
Validation loss: 2.6377881306263276

Epoch: 5| Step: 2
Training loss: 2.8073985139026907
Validation loss: 2.635116280521594

Epoch: 5| Step: 3
Training loss: 2.8395038805392847
Validation loss: 2.642058849508258

Epoch: 5| Step: 4
Training loss: 2.676817043335235
Validation loss: 2.6422673027380483

Epoch: 5| Step: 5
Training loss: 3.11251902133997
Validation loss: 2.6528706576126253

Epoch: 5| Step: 6
Training loss: 2.970744537125062
Validation loss: 2.6501985160001253

Epoch: 5| Step: 7
Training loss: 3.1041863630723867
Validation loss: 2.643835135992879

Epoch: 5| Step: 8
Training loss: 3.1078340171962826
Validation loss: 2.6472474701016453

Epoch: 5| Step: 9
Training loss: 3.2014128784545988
Validation loss: 2.659085303177799

Epoch: 5| Step: 10
Training loss: 3.114548562832845
Validation loss: 2.6449407881222204

Epoch: 126| Step: 0
Training loss: 3.0651358335680094
Validation loss: 2.6344822142108324

Epoch: 5| Step: 1
Training loss: 3.018738715425175
Validation loss: 2.634317104405201

Epoch: 5| Step: 2
Training loss: 2.907361874107969
Validation loss: 2.6298700360989193

Epoch: 5| Step: 3
Training loss: 3.1123992168241683
Validation loss: 2.6343908668039946

Epoch: 5| Step: 4
Training loss: 3.3042723482860716
Validation loss: 2.633541760452407

Epoch: 5| Step: 5
Training loss: 2.8358458617145974
Validation loss: 2.6316742767344694

Epoch: 5| Step: 6
Training loss: 2.975510619123891
Validation loss: 2.6330466534056822

Epoch: 5| Step: 7
Training loss: 3.239853499126277
Validation loss: 2.6316888450797715

Epoch: 5| Step: 8
Training loss: 3.086559686832318
Validation loss: 2.6328798031504785

Epoch: 5| Step: 9
Training loss: 2.441481444154528
Validation loss: 2.629089872724308

Epoch: 5| Step: 10
Training loss: 2.5866528584744235
Validation loss: 2.632134415327755

Epoch: 127| Step: 0
Training loss: 2.2141521255346857
Validation loss: 2.635351085288655

Epoch: 5| Step: 1
Training loss: 3.0406544886822404
Validation loss: 2.6278827140348877

Epoch: 5| Step: 2
Training loss: 3.152407582900026
Validation loss: 2.6338383912518553

Epoch: 5| Step: 3
Training loss: 3.200748511033597
Validation loss: 2.631845924808551

Epoch: 5| Step: 4
Training loss: 3.2351882575560595
Validation loss: 2.6298823270437097

Epoch: 5| Step: 5
Training loss: 3.1157477168151577
Validation loss: 2.638414107247401

Epoch: 5| Step: 6
Training loss: 2.539841846288169
Validation loss: 2.6364894413259115

Epoch: 5| Step: 7
Training loss: 2.902415052644501
Validation loss: 2.6449609167098758

Epoch: 5| Step: 8
Training loss: 3.344559188330445
Validation loss: 2.643701125537097

Epoch: 5| Step: 9
Training loss: 2.8723384313072935
Validation loss: 2.6330403481028073

Epoch: 5| Step: 10
Training loss: 2.9108251839723986
Validation loss: 2.63912333855824

Epoch: 128| Step: 0
Training loss: 3.429711413463044
Validation loss: 2.635556885364873

Epoch: 5| Step: 1
Training loss: 3.440577568538014
Validation loss: 2.6369837833651157

Epoch: 5| Step: 2
Training loss: 2.575325758244553
Validation loss: 2.6313777332257193

Epoch: 5| Step: 3
Training loss: 3.5602905382048053
Validation loss: 2.6310647615312877

Epoch: 5| Step: 4
Training loss: 2.718598986410753
Validation loss: 2.637547764406144

Epoch: 5| Step: 5
Training loss: 2.535922788341107
Validation loss: 2.6383565221790737

Epoch: 5| Step: 6
Training loss: 3.305794316349963
Validation loss: 2.629408859217091

Epoch: 5| Step: 7
Training loss: 2.9759644235412335
Validation loss: 2.6285953393645243

Epoch: 5| Step: 8
Training loss: 2.241312314734695
Validation loss: 2.6307796053224504

Epoch: 5| Step: 9
Training loss: 2.6962773019878887
Validation loss: 2.6290040288638026

Epoch: 5| Step: 10
Training loss: 2.8403376972206895
Validation loss: 2.6346481096231233

Epoch: 129| Step: 0
Training loss: 2.698386388315612
Validation loss: 2.638552210483157

Epoch: 5| Step: 1
Training loss: 2.7880192362861944
Validation loss: 2.640982889833429

Epoch: 5| Step: 2
Training loss: 2.854160243860151
Validation loss: 2.637152632211142

Epoch: 5| Step: 3
Training loss: 3.188049867362038
Validation loss: 2.6733930298440534

Epoch: 5| Step: 4
Training loss: 3.6305148826707017
Validation loss: 2.6647044263596595

Epoch: 5| Step: 5
Training loss: 3.2377944046544282
Validation loss: 2.664886929238649

Epoch: 5| Step: 6
Training loss: 2.177826117392115
Validation loss: 2.66139212022416

Epoch: 5| Step: 7
Training loss: 2.62133551447646
Validation loss: 2.6465935477704594

Epoch: 5| Step: 8
Training loss: 3.7100695428217034
Validation loss: 2.6479607035325907

Epoch: 5| Step: 9
Training loss: 3.038815054344255
Validation loss: 2.6277922152400603

Epoch: 5| Step: 10
Training loss: 2.2238015708497176
Validation loss: 2.628067679330827

Epoch: 130| Step: 0
Training loss: 3.152871013351332
Validation loss: 2.6243133760269655

Epoch: 5| Step: 1
Training loss: 2.4597290947467076
Validation loss: 2.622896867183579

Epoch: 5| Step: 2
Training loss: 3.189577211207605
Validation loss: 2.623122024488902

Epoch: 5| Step: 3
Training loss: 2.805262259668429
Validation loss: 2.624429943126163

Epoch: 5| Step: 4
Training loss: 2.0467385981880404
Validation loss: 2.6270289063592513

Epoch: 5| Step: 5
Training loss: 3.201380557042274
Validation loss: 2.6358823418731037

Epoch: 5| Step: 6
Training loss: 2.4445325686243047
Validation loss: 2.6321055571796514

Epoch: 5| Step: 7
Training loss: 3.214051307729206
Validation loss: 2.6327713889247937

Epoch: 5| Step: 8
Training loss: 3.148180323999404
Validation loss: 2.624732492687397

Epoch: 5| Step: 9
Training loss: 3.1406292512020357
Validation loss: 2.6241719062371027

Epoch: 5| Step: 10
Training loss: 3.579953988061945
Validation loss: 2.6258021768249584

Epoch: 131| Step: 0
Training loss: 2.450641906104016
Validation loss: 2.622604211451551

Epoch: 5| Step: 1
Training loss: 3.055633632548625
Validation loss: 2.6242942652436185

Epoch: 5| Step: 2
Training loss: 3.133337419250205
Validation loss: 2.6215549418600306

Epoch: 5| Step: 3
Training loss: 2.6503730835190056
Validation loss: 2.6285553785365416

Epoch: 5| Step: 4
Training loss: 3.1532593712657997
Validation loss: 2.623090179163847

Epoch: 5| Step: 5
Training loss: 2.508386373962417
Validation loss: 2.629370737906488

Epoch: 5| Step: 6
Training loss: 3.303039717137207
Validation loss: 2.6230703587135524

Epoch: 5| Step: 7
Training loss: 3.0008024096270542
Validation loss: 2.6323735286922085

Epoch: 5| Step: 8
Training loss: 2.915766731570715
Validation loss: 2.639438903287846

Epoch: 5| Step: 9
Training loss: 3.2005613907473145
Validation loss: 2.6312865070026707

Epoch: 5| Step: 10
Training loss: 3.1063585841889623
Validation loss: 2.63353999752052

Epoch: 132| Step: 0
Training loss: 3.4109584917793416
Validation loss: 2.637527691994592

Epoch: 5| Step: 1
Training loss: 3.260121942591474
Validation loss: 2.630568516811337

Epoch: 5| Step: 2
Training loss: 2.8497663301745777
Validation loss: 2.6294878632131535

Epoch: 5| Step: 3
Training loss: 2.805268463914384
Validation loss: 2.6400186971615747

Epoch: 5| Step: 4
Training loss: 3.206155227539461
Validation loss: 2.6359677886161244

Epoch: 5| Step: 5
Training loss: 2.9080421090625657
Validation loss: 2.6337598691461506

Epoch: 5| Step: 6
Training loss: 2.5816072009014257
Validation loss: 2.626356061250299

Epoch: 5| Step: 7
Training loss: 2.9068679972867537
Validation loss: 2.626084167289101

Epoch: 5| Step: 8
Training loss: 2.9250128721296296
Validation loss: 2.6247482052080358

Epoch: 5| Step: 9
Training loss: 2.831929887733467
Validation loss: 2.6207945919031377

Epoch: 5| Step: 10
Training loss: 2.785211977193846
Validation loss: 2.62089689804265

Epoch: 133| Step: 0
Training loss: 2.3917079292840597
Validation loss: 2.6202173411757985

Epoch: 5| Step: 1
Training loss: 2.8814998625941115
Validation loss: 2.614402888968134

Epoch: 5| Step: 2
Training loss: 2.929781736765633
Validation loss: 2.6178169082603917

Epoch: 5| Step: 3
Training loss: 3.3045582126010054
Validation loss: 2.6157643327266094

Epoch: 5| Step: 4
Training loss: 2.9259191259027038
Validation loss: 2.619253949152496

Epoch: 5| Step: 5
Training loss: 3.217567893425671
Validation loss: 2.62068189489975

Epoch: 5| Step: 6
Training loss: 2.4666604965579557
Validation loss: 2.616935638274022

Epoch: 5| Step: 7
Training loss: 3.1372106411093044
Validation loss: 2.617183066596836

Epoch: 5| Step: 8
Training loss: 2.72885900806562
Validation loss: 2.6194678265666815

Epoch: 5| Step: 9
Training loss: 3.132972618063731
Validation loss: 2.618099559535515

Epoch: 5| Step: 10
Training loss: 3.316444495601762
Validation loss: 2.6159205928974782

Epoch: 134| Step: 0
Training loss: 3.0904092958350504
Validation loss: 2.6135996244420445

Epoch: 5| Step: 1
Training loss: 2.721166479522586
Validation loss: 2.6157445978973195

Epoch: 5| Step: 2
Training loss: 3.0903255120828104
Validation loss: 2.6203548928722507

Epoch: 5| Step: 3
Training loss: 3.5248104558535944
Validation loss: 2.6139337974599886

Epoch: 5| Step: 4
Training loss: 2.9504644125347097
Validation loss: 2.614723925080372

Epoch: 5| Step: 5
Training loss: 2.828780630420377
Validation loss: 2.614368347682123

Epoch: 5| Step: 6
Training loss: 2.9025799949064375
Validation loss: 2.6150155946592872

Epoch: 5| Step: 7
Training loss: 2.8341681054760417
Validation loss: 2.614378609605092

Epoch: 5| Step: 8
Training loss: 2.99256117755815
Validation loss: 2.6144193568374963

Epoch: 5| Step: 9
Training loss: 2.623690323862049
Validation loss: 2.6154615352931394

Epoch: 5| Step: 10
Training loss: 2.8820053666095946
Validation loss: 2.611989887825585

Epoch: 135| Step: 0
Training loss: 2.8067213244639526
Validation loss: 2.6172416699772105

Epoch: 5| Step: 1
Training loss: 2.3816713696222696
Validation loss: 2.618872961643142

Epoch: 5| Step: 2
Training loss: 2.8809874839100376
Validation loss: 2.6163710600093415

Epoch: 5| Step: 3
Training loss: 3.2291819582341232
Validation loss: 2.622822023534252

Epoch: 5| Step: 4
Training loss: 2.947715042462147
Validation loss: 2.6221422020093463

Epoch: 5| Step: 5
Training loss: 3.0459987847669536
Validation loss: 2.6330400170642525

Epoch: 5| Step: 6
Training loss: 2.7078113835459594
Validation loss: 2.6341676172273956

Epoch: 5| Step: 7
Training loss: 3.17710753051215
Validation loss: 2.640669614858286

Epoch: 5| Step: 8
Training loss: 3.5594965002206433
Validation loss: 2.6373249968864587

Epoch: 5| Step: 9
Training loss: 2.6902054764220322
Validation loss: 2.628253752362859

Epoch: 5| Step: 10
Training loss: 2.8867108212002073
Validation loss: 2.6262494466904935

Epoch: 136| Step: 0
Training loss: 3.0073508168397773
Validation loss: 2.617686467488493

Epoch: 5| Step: 1
Training loss: 3.2227515374170297
Validation loss: 2.616583665208425

Epoch: 5| Step: 2
Training loss: 2.8010091223386033
Validation loss: 2.6104685934609773

Epoch: 5| Step: 3
Training loss: 2.95714896407461
Validation loss: 2.60790139011067

Epoch: 5| Step: 4
Training loss: 2.9493466381108613
Validation loss: 2.614594441901661

Epoch: 5| Step: 5
Training loss: 3.2926317723581366
Validation loss: 2.610266818186823

Epoch: 5| Step: 6
Training loss: 2.8637478436545583
Validation loss: 2.6147618030415405

Epoch: 5| Step: 7
Training loss: 1.9055016096033741
Validation loss: 2.6087106909481146

Epoch: 5| Step: 8
Training loss: 2.8919638342699905
Validation loss: 2.6060207551085552

Epoch: 5| Step: 9
Training loss: 3.335464336778156
Validation loss: 2.6068758045027844

Epoch: 5| Step: 10
Training loss: 3.0110073016181724
Validation loss: 2.611925127364406

Epoch: 137| Step: 0
Training loss: 3.147219287331868
Validation loss: 2.6116313211756537

Epoch: 5| Step: 1
Training loss: 3.087779748266335
Validation loss: 2.61012480904319

Epoch: 5| Step: 2
Training loss: 2.568258653413581
Validation loss: 2.607995003189976

Epoch: 5| Step: 3
Training loss: 2.707851533338788
Validation loss: 2.611453817846731

Epoch: 5| Step: 4
Training loss: 3.0312773713124725
Validation loss: 2.616706631814235

Epoch: 5| Step: 5
Training loss: 2.4740243896231986
Validation loss: 2.6225406173237897

Epoch: 5| Step: 6
Training loss: 3.17330344220784
Validation loss: 2.62261723781295

Epoch: 5| Step: 7
Training loss: 3.207332471484926
Validation loss: 2.640866365595011

Epoch: 5| Step: 8
Training loss: 3.267843998354727
Validation loss: 2.6301701927445285

Epoch: 5| Step: 9
Training loss: 2.988487565641302
Validation loss: 2.619264300577105

Epoch: 5| Step: 10
Training loss: 2.622834538594782
Validation loss: 2.6175111592846054

Epoch: 138| Step: 0
Training loss: 3.033370072977214
Validation loss: 2.6097534241288836

Epoch: 5| Step: 1
Training loss: 2.95978195469875
Validation loss: 2.6082312735138564

Epoch: 5| Step: 2
Training loss: 2.591957484014348
Validation loss: 2.603893113730106

Epoch: 5| Step: 3
Training loss: 2.5125371332413673
Validation loss: 2.6073225788331134

Epoch: 5| Step: 4
Training loss: 2.8484200498514096
Validation loss: 2.5997909805803157

Epoch: 5| Step: 5
Training loss: 2.9954904995893217
Validation loss: 2.6026529322123046

Epoch: 5| Step: 6
Training loss: 3.3131180672464193
Validation loss: 2.6082369556749905

Epoch: 5| Step: 7
Training loss: 2.7672376510754
Validation loss: 2.606288635718256

Epoch: 5| Step: 8
Training loss: 3.072589369763012
Validation loss: 2.6070772158382347

Epoch: 5| Step: 9
Training loss: 2.770346022659645
Validation loss: 2.61133672304921

Epoch: 5| Step: 10
Training loss: 3.510113681354248
Validation loss: 2.610317257329345

Epoch: 139| Step: 0
Training loss: 3.1729478947652936
Validation loss: 2.62240474051066

Epoch: 5| Step: 1
Training loss: 2.9007854976360967
Validation loss: 2.6140066943422138

Epoch: 5| Step: 2
Training loss: 2.941512917741355
Validation loss: 2.619017312611383

Epoch: 5| Step: 3
Training loss: 2.746028980777341
Validation loss: 2.615758262145891

Epoch: 5| Step: 4
Training loss: 3.2437065518506825
Validation loss: 2.636366125520898

Epoch: 5| Step: 5
Training loss: 2.947435499266925
Validation loss: 2.64055164864146

Epoch: 5| Step: 6
Training loss: 3.182819745107503
Validation loss: 2.641036997396026

Epoch: 5| Step: 7
Training loss: 2.1060310136733977
Validation loss: 2.6310761538853855

Epoch: 5| Step: 8
Training loss: 2.9267687283434243
Validation loss: 2.6149532963507434

Epoch: 5| Step: 9
Training loss: 3.2863715029861806
Validation loss: 2.604017566637471

Epoch: 5| Step: 10
Training loss: 2.685105343675462
Validation loss: 2.5995553089941152

Epoch: 140| Step: 0
Training loss: 3.053175139625557
Validation loss: 2.598080932927395

Epoch: 5| Step: 1
Training loss: 3.0640158502353025
Validation loss: 2.5996787625306093

Epoch: 5| Step: 2
Training loss: 2.7287739963848137
Validation loss: 2.602683319610843

Epoch: 5| Step: 3
Training loss: 3.006638334892187
Validation loss: 2.604351349875597

Epoch: 5| Step: 4
Training loss: 3.311858348959354
Validation loss: 2.6044923361315555

Epoch: 5| Step: 5
Training loss: 3.574003953159838
Validation loss: 2.6026944692838736

Epoch: 5| Step: 6
Training loss: 2.6608421572921137
Validation loss: 2.599028400437824

Epoch: 5| Step: 7
Training loss: 2.3985784532711416
Validation loss: 2.5990958031440026

Epoch: 5| Step: 8
Training loss: 2.7740306810911464
Validation loss: 2.600268919528571

Epoch: 5| Step: 9
Training loss: 2.704802593424698
Validation loss: 2.599837768390271

Epoch: 5| Step: 10
Training loss: 3.0566510770088873
Validation loss: 2.599576527648939

Epoch: 141| Step: 0
Training loss: 2.817264420849787
Validation loss: 2.5966984649360487

Epoch: 5| Step: 1
Training loss: 2.7927092318241127
Validation loss: 2.609425361082963

Epoch: 5| Step: 2
Training loss: 2.8618685163235784
Validation loss: 2.611713668335699

Epoch: 5| Step: 3
Training loss: 3.332512341166694
Validation loss: 2.6102659264059223

Epoch: 5| Step: 4
Training loss: 2.610223506550807
Validation loss: 2.609674310935231

Epoch: 5| Step: 5
Training loss: 2.5852999636008263
Validation loss: 2.6145530561331456

Epoch: 5| Step: 6
Training loss: 3.3175847595931836
Validation loss: 2.629296355933524

Epoch: 5| Step: 7
Training loss: 2.827929663893613
Validation loss: 2.6598383514921853

Epoch: 5| Step: 8
Training loss: 3.0505158410279245
Validation loss: 2.65041978896655

Epoch: 5| Step: 9
Training loss: 2.5922205448631197
Validation loss: 2.646120608269964

Epoch: 5| Step: 10
Training loss: 3.5397835306481182
Validation loss: 2.631469223223598

Epoch: 142| Step: 0
Training loss: 2.9972801594933007
Validation loss: 2.6079700488122057

Epoch: 5| Step: 1
Training loss: 2.7752234497834634
Validation loss: 2.605453006815941

Epoch: 5| Step: 2
Training loss: 3.0829256836443566
Validation loss: 2.6019512027662235

Epoch: 5| Step: 3
Training loss: 2.84519251193881
Validation loss: 2.5977802655031663

Epoch: 5| Step: 4
Training loss: 3.453334474035637
Validation loss: 2.6006310894063405

Epoch: 5| Step: 5
Training loss: 2.6752448887898725
Validation loss: 2.5939290409535576

Epoch: 5| Step: 6
Training loss: 2.637148673717282
Validation loss: 2.594128895955247

Epoch: 5| Step: 7
Training loss: 2.385242761216926
Validation loss: 2.5988425175729915

Epoch: 5| Step: 8
Training loss: 3.0029933618757347
Validation loss: 2.5944072208502593

Epoch: 5| Step: 9
Training loss: 3.059648392865407
Validation loss: 2.5957579961598154

Epoch: 5| Step: 10
Training loss: 3.3716747715906497
Validation loss: 2.596612751270294

Epoch: 143| Step: 0
Training loss: 3.439338608524452
Validation loss: 2.5973190025781894

Epoch: 5| Step: 1
Training loss: 2.1843234294866893
Validation loss: 2.5921536082106447

Epoch: 5| Step: 2
Training loss: 3.026670792138513
Validation loss: 2.592647628090977

Epoch: 5| Step: 3
Training loss: 3.155008808492464
Validation loss: 2.5917377803502406

Epoch: 5| Step: 4
Training loss: 2.7850505279121385
Validation loss: 2.599319342842527

Epoch: 5| Step: 5
Training loss: 1.9998601626147334
Validation loss: 2.591146222491376

Epoch: 5| Step: 6
Training loss: 3.1325290770524545
Validation loss: 2.6016158246568515

Epoch: 5| Step: 7
Training loss: 3.5384122070012243
Validation loss: 2.5993242091130337

Epoch: 5| Step: 8
Training loss: 2.535371885841961
Validation loss: 2.599901453403454

Epoch: 5| Step: 9
Training loss: 2.627466949922874
Validation loss: 2.60241646081842

Epoch: 5| Step: 10
Training loss: 3.500341534980727
Validation loss: 2.6056269115721524

Epoch: 144| Step: 0
Training loss: 2.500240791168815
Validation loss: 2.609007917332898

Epoch: 5| Step: 1
Training loss: 3.2340123069967808
Validation loss: 2.6207026275132024

Epoch: 5| Step: 2
Training loss: 3.4690427914330986
Validation loss: 2.61100289316096

Epoch: 5| Step: 3
Training loss: 3.000092981804914
Validation loss: 2.616750115359227

Epoch: 5| Step: 4
Training loss: 3.1200710335005764
Validation loss: 2.600285470008433

Epoch: 5| Step: 5
Training loss: 2.781234055376961
Validation loss: 2.5935437164530897

Epoch: 5| Step: 6
Training loss: 2.853370072701673
Validation loss: 2.592557715850191

Epoch: 5| Step: 7
Training loss: 2.6298700297626123
Validation loss: 2.5910551252651617

Epoch: 5| Step: 8
Training loss: 2.891092128640847
Validation loss: 2.5974467215614316

Epoch: 5| Step: 9
Training loss: 2.7097210092268647
Validation loss: 2.590326094553164

Epoch: 5| Step: 10
Training loss: 3.0641363015398095
Validation loss: 2.5996170394536824

Epoch: 145| Step: 0
Training loss: 2.6910768703225227
Validation loss: 2.6003046556952727

Epoch: 5| Step: 1
Training loss: 3.0095678978691884
Validation loss: 2.601017300719748

Epoch: 5| Step: 2
Training loss: 2.794809271185547
Validation loss: 2.593889931715505

Epoch: 5| Step: 3
Training loss: 3.1894324933311573
Validation loss: 2.601981494907155

Epoch: 5| Step: 4
Training loss: 3.0112141187659134
Validation loss: 2.5993002573876365

Epoch: 5| Step: 5
Training loss: 3.119218590036094
Validation loss: 2.601871271990751

Epoch: 5| Step: 6
Training loss: 3.115979106220912
Validation loss: 2.5931887078010454

Epoch: 5| Step: 7
Training loss: 2.868157412424194
Validation loss: 2.5928398222547613

Epoch: 5| Step: 8
Training loss: 2.8199633437675873
Validation loss: 2.595297744885947

Epoch: 5| Step: 9
Training loss: 2.8628455607297165
Validation loss: 2.591432766118962

Epoch: 5| Step: 10
Training loss: 2.717607806330023
Validation loss: 2.5858255789726043

Epoch: 146| Step: 0
Training loss: 2.77335222140018
Validation loss: 2.5850628608370325

Epoch: 5| Step: 1
Training loss: 2.95962809494507
Validation loss: 2.5909580846399827

Epoch: 5| Step: 2
Training loss: 2.9785964704704337
Validation loss: 2.5860791610115172

Epoch: 5| Step: 3
Training loss: 2.7770102256391573
Validation loss: 2.58379121454552

Epoch: 5| Step: 4
Training loss: 2.9784999359217945
Validation loss: 2.587552672485095

Epoch: 5| Step: 5
Training loss: 2.803723948098731
Validation loss: 2.588690773367769

Epoch: 5| Step: 6
Training loss: 3.366992918264829
Validation loss: 2.5939597894873283

Epoch: 5| Step: 7
Training loss: 2.6299099189503075
Validation loss: 2.593998002275154

Epoch: 5| Step: 8
Training loss: 2.605165935803335
Validation loss: 2.5985235061368903

Epoch: 5| Step: 9
Training loss: 3.5523294193942716
Validation loss: 2.6201414880480325

Epoch: 5| Step: 10
Training loss: 2.637595069220449
Validation loss: 2.6298034528538285

Epoch: 147| Step: 0
Training loss: 2.9673490732404466
Validation loss: 2.6236261512132155

Epoch: 5| Step: 1
Training loss: 3.455034651410004
Validation loss: 2.625520764878991

Epoch: 5| Step: 2
Training loss: 3.137139659113647
Validation loss: 2.6235110801290924

Epoch: 5| Step: 3
Training loss: 2.391161889518308
Validation loss: 2.614016605603421

Epoch: 5| Step: 4
Training loss: 3.124196368836281
Validation loss: 2.6182440207045437

Epoch: 5| Step: 5
Training loss: 2.7743957583378505
Validation loss: 2.620093372039778

Epoch: 5| Step: 6
Training loss: 2.987603802653293
Validation loss: 2.619546044067887

Epoch: 5| Step: 7
Training loss: 2.9343507808380513
Validation loss: 2.61440768793994

Epoch: 5| Step: 8
Training loss: 2.8746687656824284
Validation loss: 2.6030076723970126

Epoch: 5| Step: 9
Training loss: 2.814770947313448
Validation loss: 2.6024722612136073

Epoch: 5| Step: 10
Training loss: 2.6232136597373397
Validation loss: 2.583623493371326

Epoch: 148| Step: 0
Training loss: 2.859168039972177
Validation loss: 2.582044236804549

Epoch: 5| Step: 1
Training loss: 2.959286997210705
Validation loss: 2.5834972105997287

Epoch: 5| Step: 2
Training loss: 3.4087338971553955
Validation loss: 2.582399239765871

Epoch: 5| Step: 3
Training loss: 3.1029025241049193
Validation loss: 2.5821885676342915

Epoch: 5| Step: 4
Training loss: 2.7529428514894554
Validation loss: 2.5856009946180905

Epoch: 5| Step: 5
Training loss: 2.153816729910528
Validation loss: 2.5864552080414396

Epoch: 5| Step: 6
Training loss: 2.3573549224776875
Validation loss: 2.582807000680075

Epoch: 5| Step: 7
Training loss: 3.2451038159425836
Validation loss: 2.5867310652673194

Epoch: 5| Step: 8
Training loss: 3.338209178315295
Validation loss: 2.5889747745719136

Epoch: 5| Step: 9
Training loss: 3.158637173278918
Validation loss: 2.584613208774015

Epoch: 5| Step: 10
Training loss: 2.6425503364900713
Validation loss: 2.5959749904656335

Epoch: 149| Step: 0
Training loss: 2.8307279126475393
Validation loss: 2.6034558293667973

Epoch: 5| Step: 1
Training loss: 3.160295971397466
Validation loss: 2.6196295516546932

Epoch: 5| Step: 2
Training loss: 3.0636675419132944
Validation loss: 2.624249988414636

Epoch: 5| Step: 3
Training loss: 2.2752616354600064
Validation loss: 2.6341397828143256

Epoch: 5| Step: 4
Training loss: 3.3234680260465588
Validation loss: 2.641333003380562

Epoch: 5| Step: 5
Training loss: 2.695873169012611
Validation loss: 2.615307261117375

Epoch: 5| Step: 6
Training loss: 3.014899606377573
Validation loss: 2.6054596622586086

Epoch: 5| Step: 7
Training loss: 2.9595873328533715
Validation loss: 2.597418759142341

Epoch: 5| Step: 8
Training loss: 2.553023329990175
Validation loss: 2.5927878931871287

Epoch: 5| Step: 9
Training loss: 3.2574737885036136
Validation loss: 2.5903724179449985

Epoch: 5| Step: 10
Training loss: 2.956479543923843
Validation loss: 2.595563398696583

Epoch: 150| Step: 0
Training loss: 2.271702684586652
Validation loss: 2.582175982655683

Epoch: 5| Step: 1
Training loss: 3.0540739648202324
Validation loss: 2.5772890229019176

Epoch: 5| Step: 2
Training loss: 3.3227227292921078
Validation loss: 2.5855396037622174

Epoch: 5| Step: 3
Training loss: 2.987662856000571
Validation loss: 2.594207580981011

Epoch: 5| Step: 4
Training loss: 2.43897906691611
Validation loss: 2.5806054178889712

Epoch: 5| Step: 5
Training loss: 2.7585755068063134
Validation loss: 2.579843476276415

Epoch: 5| Step: 6
Training loss: 2.760622921321709
Validation loss: 2.5815338816903592

Epoch: 5| Step: 7
Training loss: 3.2050214410264037
Validation loss: 2.581037982914879

Epoch: 5| Step: 8
Training loss: 2.891029453334716
Validation loss: 2.5796450571556084

Epoch: 5| Step: 9
Training loss: 3.284583296917161
Validation loss: 2.577156542780529

Epoch: 5| Step: 10
Training loss: 3.1035749310924126
Validation loss: 2.5846913255280928

Epoch: 151| Step: 0
Training loss: 2.7838846650458757
Validation loss: 2.590128549231687

Epoch: 5| Step: 1
Training loss: 3.041202997549201
Validation loss: 2.5891643125332977

Epoch: 5| Step: 2
Training loss: 2.902857779861097
Validation loss: 2.5962733302448417

Epoch: 5| Step: 3
Training loss: 3.012607309796541
Validation loss: 2.598941072401779

Epoch: 5| Step: 4
Training loss: 3.147705901836766
Validation loss: 2.595601859489635

Epoch: 5| Step: 5
Training loss: 2.898781974454927
Validation loss: 2.5914708994364815

Epoch: 5| Step: 6
Training loss: 2.9332668564228466
Validation loss: 2.57786607582538

Epoch: 5| Step: 7
Training loss: 3.220553439185706
Validation loss: 2.576407912368121

Epoch: 5| Step: 8
Training loss: 3.015122129582619
Validation loss: 2.5780586072539893

Epoch: 5| Step: 9
Training loss: 2.6292244660502453
Validation loss: 2.5726469975615682

Epoch: 5| Step: 10
Training loss: 2.4630707713470814
Validation loss: 2.58110369017103

Epoch: 152| Step: 0
Training loss: 2.3092526497647583
Validation loss: 2.5753987833546557

Epoch: 5| Step: 1
Training loss: 2.725503185605567
Validation loss: 2.580573475070207

Epoch: 5| Step: 2
Training loss: 2.6227150009070117
Validation loss: 2.579130514730017

Epoch: 5| Step: 3
Training loss: 3.129040052050927
Validation loss: 2.5862542931675265

Epoch: 5| Step: 4
Training loss: 3.2370604640155967
Validation loss: 2.587187190421043

Epoch: 5| Step: 5
Training loss: 3.2259770709722915
Validation loss: 2.5836009291537554

Epoch: 5| Step: 6
Training loss: 2.952496497065754
Validation loss: 2.585347569948956

Epoch: 5| Step: 7
Training loss: 3.3175677993849084
Validation loss: 2.5911937412172583

Epoch: 5| Step: 8
Training loss: 2.5112202625783024
Validation loss: 2.579596259328656

Epoch: 5| Step: 9
Training loss: 3.2272796203402905
Validation loss: 2.5784344081970563

Epoch: 5| Step: 10
Training loss: 2.6218753564627475
Validation loss: 2.5781071189640636

Epoch: 153| Step: 0
Training loss: 3.2292058798757357
Validation loss: 2.5860325545159633

Epoch: 5| Step: 1
Training loss: 2.8474214768404873
Validation loss: 2.586820031415293

Epoch: 5| Step: 2
Training loss: 3.114892406289307
Validation loss: 2.5900675359043546

Epoch: 5| Step: 3
Training loss: 2.2167373985344496
Validation loss: 2.601526628369086

Epoch: 5| Step: 4
Training loss: 3.1638010176000773
Validation loss: 2.617699404717428

Epoch: 5| Step: 5
Training loss: 2.8332245936751232
Validation loss: 2.597363393533004

Epoch: 5| Step: 6
Training loss: 3.2007276542185674
Validation loss: 2.6020363272682894

Epoch: 5| Step: 7
Training loss: 2.8168213600551404
Validation loss: 2.58494439303725

Epoch: 5| Step: 8
Training loss: 2.6997486703952243
Validation loss: 2.5847368463412486

Epoch: 5| Step: 9
Training loss: 3.102221671137477
Validation loss: 2.581726262724847

Epoch: 5| Step: 10
Training loss: 2.777052379835339
Validation loss: 2.573137838193676

Epoch: 154| Step: 0
Training loss: 2.5023639946105836
Validation loss: 2.578165581397159

Epoch: 5| Step: 1
Training loss: 3.33976965035672
Validation loss: 2.5700575967122448

Epoch: 5| Step: 2
Training loss: 2.9503926549253245
Validation loss: 2.5766992250403584

Epoch: 5| Step: 3
Training loss: 3.3399015722790706
Validation loss: 2.580920775626274

Epoch: 5| Step: 4
Training loss: 3.3469995413153897
Validation loss: 2.583328604983297

Epoch: 5| Step: 5
Training loss: 2.6039873798961093
Validation loss: 2.5816659405678024

Epoch: 5| Step: 6
Training loss: 2.7849977937754686
Validation loss: 2.577159321131132

Epoch: 5| Step: 7
Training loss: 2.99217825706389
Validation loss: 2.577410728075352

Epoch: 5| Step: 8
Training loss: 2.7733603023477102
Validation loss: 2.570368103688619

Epoch: 5| Step: 9
Training loss: 2.665978690649609
Validation loss: 2.5728087900606607

Epoch: 5| Step: 10
Training loss: 2.6125301085566908
Validation loss: 2.573770518312345

Epoch: 155| Step: 0
Training loss: 2.340521661695261
Validation loss: 2.5872479357668383

Epoch: 5| Step: 1
Training loss: 3.0959775977494735
Validation loss: 2.5746695442948124

Epoch: 5| Step: 2
Training loss: 2.632751101901391
Validation loss: 2.5782781193154163

Epoch: 5| Step: 3
Training loss: 3.091635087118442
Validation loss: 2.58860853462925

Epoch: 5| Step: 4
Training loss: 2.447107405849142
Validation loss: 2.6035977739353324

Epoch: 5| Step: 5
Training loss: 3.4371142084204993
Validation loss: 2.6331338103058264

Epoch: 5| Step: 6
Training loss: 2.75204227213774
Validation loss: 2.615921976677869

Epoch: 5| Step: 7
Training loss: 2.892317158056088
Validation loss: 2.6180108719742443

Epoch: 5| Step: 8
Training loss: 2.9800530739992768
Validation loss: 2.5962882917554553

Epoch: 5| Step: 9
Training loss: 3.2958900462856144
Validation loss: 2.58578710562026

Epoch: 5| Step: 10
Training loss: 2.9644873282962276
Validation loss: 2.5698032068452785

Epoch: 156| Step: 0
Training loss: 3.211481869628131
Validation loss: 2.5652826548912038

Epoch: 5| Step: 1
Training loss: 2.6062851388881474
Validation loss: 2.5641656999805713

Epoch: 5| Step: 2
Training loss: 2.580003273836173
Validation loss: 2.569731883303215

Epoch: 5| Step: 3
Training loss: 3.0404186214025826
Validation loss: 2.5667288317088603

Epoch: 5| Step: 4
Training loss: 2.9968235365473395
Validation loss: 2.564364049682973

Epoch: 5| Step: 5
Training loss: 2.7102197581921863
Validation loss: 2.573839423616245

Epoch: 5| Step: 6
Training loss: 3.0414997908570047
Validation loss: 2.567685952081034

Epoch: 5| Step: 7
Training loss: 3.072795766402558
Validation loss: 2.5703892052274258

Epoch: 5| Step: 8
Training loss: 2.9273304320236813
Validation loss: 2.5697666843791374

Epoch: 5| Step: 9
Training loss: 2.9679244650408454
Validation loss: 2.5737034305229565

Epoch: 5| Step: 10
Training loss: 2.8933580829364605
Validation loss: 2.5761774646712357

Epoch: 157| Step: 0
Training loss: 2.5717131442083017
Validation loss: 2.5806020422250606

Epoch: 5| Step: 1
Training loss: 3.4449805967008738
Validation loss: 2.583316265715374

Epoch: 5| Step: 2
Training loss: 2.815144037793045
Validation loss: 2.581402573807185

Epoch: 5| Step: 3
Training loss: 2.534499825485684
Validation loss: 2.574661403304828

Epoch: 5| Step: 4
Training loss: 2.6420290673307987
Validation loss: 2.57159836306687

Epoch: 5| Step: 5
Training loss: 2.7506102838449777
Validation loss: 2.5808312415643697

Epoch: 5| Step: 6
Training loss: 3.3214009015737034
Validation loss: 2.5772170232050238

Epoch: 5| Step: 7
Training loss: 2.6854592492806737
Validation loss: 2.57529863771698

Epoch: 5| Step: 8
Training loss: 3.1246626099607018
Validation loss: 2.586778817721469

Epoch: 5| Step: 9
Training loss: 2.6988661186535383
Validation loss: 2.575041237307874

Epoch: 5| Step: 10
Training loss: 3.34758887562562
Validation loss: 2.577827515503577

Epoch: 158| Step: 0
Training loss: 2.5575883826592434
Validation loss: 2.583863223533347

Epoch: 5| Step: 1
Training loss: 3.1437406505650456
Validation loss: 2.5948228076538866

Epoch: 5| Step: 2
Training loss: 3.0115699187042195
Validation loss: 2.590592673815097

Epoch: 5| Step: 3
Training loss: 3.27437663661321
Validation loss: 2.5894912962218246

Epoch: 5| Step: 4
Training loss: 3.1214277067304836
Validation loss: 2.5835764754317814

Epoch: 5| Step: 5
Training loss: 3.076879413918493
Validation loss: 2.606436351111142

Epoch: 5| Step: 6
Training loss: 2.341942153509459
Validation loss: 2.5832618418343585

Epoch: 5| Step: 7
Training loss: 2.9825681639281987
Validation loss: 2.572252158271445

Epoch: 5| Step: 8
Training loss: 2.652678568273655
Validation loss: 2.5693602393965

Epoch: 5| Step: 9
Training loss: 2.693789021149635
Validation loss: 2.5704405016805985

Epoch: 5| Step: 10
Training loss: 2.9504521298244684
Validation loss: 2.564886928812592

Epoch: 159| Step: 0
Training loss: 2.983495932326781
Validation loss: 2.570806483816617

Epoch: 5| Step: 1
Training loss: 2.978640814479747
Validation loss: 2.5637661646770553

Epoch: 5| Step: 2
Training loss: 3.32297859413216
Validation loss: 2.5686652816847464

Epoch: 5| Step: 3
Training loss: 2.8978514374431295
Validation loss: 2.582338764560173

Epoch: 5| Step: 4
Training loss: 2.749824084810882
Validation loss: 2.5760020216273594

Epoch: 5| Step: 5
Training loss: 2.816232620368493
Validation loss: 2.585562464381758

Epoch: 5| Step: 6
Training loss: 3.226453876283325
Validation loss: 2.5824689914318992

Epoch: 5| Step: 7
Training loss: 2.919118631678992
Validation loss: 2.5841097430777262

Epoch: 5| Step: 8
Training loss: 2.3932126071981052
Validation loss: 2.5837679195417174

Epoch: 5| Step: 9
Training loss: 3.34059264949768
Validation loss: 2.5835790920823807

Epoch: 5| Step: 10
Training loss: 1.9345441235883531
Validation loss: 2.5713257996343293

Epoch: 160| Step: 0
Training loss: 2.4134924749553828
Validation loss: 2.5674462211574522

Epoch: 5| Step: 1
Training loss: 2.7483454842315225
Validation loss: 2.5766881753013475

Epoch: 5| Step: 2
Training loss: 2.252852962330021
Validation loss: 2.566085859611668

Epoch: 5| Step: 3
Training loss: 2.795768902676262
Validation loss: 2.5631791687172933

Epoch: 5| Step: 4
Training loss: 3.4918909138947933
Validation loss: 2.5642980954457

Epoch: 5| Step: 5
Training loss: 2.7807296094639815
Validation loss: 2.5629114260410977

Epoch: 5| Step: 6
Training loss: 2.9394703202362504
Validation loss: 2.559375293448251

Epoch: 5| Step: 7
Training loss: 3.2865297981790533
Validation loss: 2.567793775672499

Epoch: 5| Step: 8
Training loss: 3.0197036911061454
Validation loss: 2.564473760377022

Epoch: 5| Step: 9
Training loss: 2.898941201915466
Validation loss: 2.564329481204525

Epoch: 5| Step: 10
Training loss: 3.1670152238119167
Validation loss: 2.5726698750881294

Epoch: 161| Step: 0
Training loss: 2.8021699024616553
Validation loss: 2.5642608507267695

Epoch: 5| Step: 1
Training loss: 2.7210788617971255
Validation loss: 2.555335121923222

Epoch: 5| Step: 2
Training loss: 2.6177245542724727
Validation loss: 2.560854449725502

Epoch: 5| Step: 3
Training loss: 2.8035477471501244
Validation loss: 2.560077584714747

Epoch: 5| Step: 4
Training loss: 3.3576704091947778
Validation loss: 2.554663288329995

Epoch: 5| Step: 5
Training loss: 3.2613131882031587
Validation loss: 2.5585367541621373

Epoch: 5| Step: 6
Training loss: 2.3925645726656994
Validation loss: 2.5527954641581365

Epoch: 5| Step: 7
Training loss: 2.765378089702004
Validation loss: 2.556336325050251

Epoch: 5| Step: 8
Training loss: 3.089323634222833
Validation loss: 2.5562050907793266

Epoch: 5| Step: 9
Training loss: 3.2667022826400576
Validation loss: 2.555031873543806

Epoch: 5| Step: 10
Training loss: 2.7077707048592563
Validation loss: 2.568382111050297

Epoch: 162| Step: 0
Training loss: 3.4321051138317626
Validation loss: 2.5723173803543458

Epoch: 5| Step: 1
Training loss: 2.4992362763200817
Validation loss: 2.576261217730222

Epoch: 5| Step: 2
Training loss: 3.6666622739823356
Validation loss: 2.578962521266038

Epoch: 5| Step: 3
Training loss: 3.0159541923828614
Validation loss: 2.580394661894672

Epoch: 5| Step: 4
Training loss: 2.9546453205650445
Validation loss: 2.575373292641184

Epoch: 5| Step: 5
Training loss: 2.8647262445116204
Validation loss: 2.57595477102531

Epoch: 5| Step: 6
Training loss: 2.7531235035644346
Validation loss: 2.5732586871510907

Epoch: 5| Step: 7
Training loss: 3.0237324100154646
Validation loss: 2.5699925536940853

Epoch: 5| Step: 8
Training loss: 2.1771755168569142
Validation loss: 2.5700220683957737

Epoch: 5| Step: 9
Training loss: 2.616287577760648
Validation loss: 2.568152340715756

Epoch: 5| Step: 10
Training loss: 2.6038418885204644
Validation loss: 2.55531199890652

Epoch: 163| Step: 0
Training loss: 2.7768634965732604
Validation loss: 2.558008620314801

Epoch: 5| Step: 1
Training loss: 3.1365956131457677
Validation loss: 2.5558712387418336

Epoch: 5| Step: 2
Training loss: 3.0468300840539486
Validation loss: 2.554471386145192

Epoch: 5| Step: 3
Training loss: 3.0224992740399896
Validation loss: 2.551028813842794

Epoch: 5| Step: 4
Training loss: 3.060527243974214
Validation loss: 2.5505748825415564

Epoch: 5| Step: 5
Training loss: 2.5670943593306093
Validation loss: 2.5520079788491272

Epoch: 5| Step: 6
Training loss: 3.1547845138740445
Validation loss: 2.551439340557919

Epoch: 5| Step: 7
Training loss: 2.307838897450798
Validation loss: 2.5525327463005896

Epoch: 5| Step: 8
Training loss: 2.9329358619104795
Validation loss: 2.549396592533285

Epoch: 5| Step: 9
Training loss: 2.939079184842244
Validation loss: 2.553729722189541

Epoch: 5| Step: 10
Training loss: 2.841165395098837
Validation loss: 2.561010715293661

Epoch: 164| Step: 0
Training loss: 2.8910202168589394
Validation loss: 2.57338889185354

Epoch: 5| Step: 1
Training loss: 3.0255870028865695
Validation loss: 2.566601999355408

Epoch: 5| Step: 2
Training loss: 3.2036998698122394
Validation loss: 2.5779753506391185

Epoch: 5| Step: 3
Training loss: 2.358618810873712
Validation loss: 2.56963204956577

Epoch: 5| Step: 4
Training loss: 2.788929997563767
Validation loss: 2.5756877318077205

Epoch: 5| Step: 5
Training loss: 3.069770435112696
Validation loss: 2.577554574397441

Epoch: 5| Step: 6
Training loss: 2.8442892045468167
Validation loss: 2.572694060791081

Epoch: 5| Step: 7
Training loss: 2.8209055438206723
Validation loss: 2.5842014769970625

Epoch: 5| Step: 8
Training loss: 2.596657926849165
Validation loss: 2.5876310948111914

Epoch: 5| Step: 9
Training loss: 3.351615567443001
Validation loss: 2.5805972568811026

Epoch: 5| Step: 10
Training loss: 2.7392471068473956
Validation loss: 2.5737770216071976

Epoch: 165| Step: 0
Training loss: 3.5764272068444134
Validation loss: 2.564113089216053

Epoch: 5| Step: 1
Training loss: 2.5216926707330263
Validation loss: 2.5548816105536694

Epoch: 5| Step: 2
Training loss: 2.910224903500181
Validation loss: 2.5465738508642164

Epoch: 5| Step: 3
Training loss: 2.688721844797525
Validation loss: 2.5482951812982946

Epoch: 5| Step: 4
Training loss: 2.8175800644500204
Validation loss: 2.556371811913611

Epoch: 5| Step: 5
Training loss: 2.5498815471588117
Validation loss: 2.5486327889219718

Epoch: 5| Step: 6
Training loss: 2.75558719061395
Validation loss: 2.5505458604644726

Epoch: 5| Step: 7
Training loss: 3.238896549609114
Validation loss: 2.5469285390744996

Epoch: 5| Step: 8
Training loss: 2.908710217763263
Validation loss: 2.549968671274492

Epoch: 5| Step: 9
Training loss: 2.93376214043178
Validation loss: 2.55509879138202

Epoch: 5| Step: 10
Training loss: 2.9734350881000466
Validation loss: 2.569010619574982

Epoch: 166| Step: 0
Training loss: 3.028266303482831
Validation loss: 2.5718803392847596

Epoch: 5| Step: 1
Training loss: 2.800201653984676
Validation loss: 2.583228627827561

Epoch: 5| Step: 2
Training loss: 3.303198368408953
Validation loss: 2.57196949767366

Epoch: 5| Step: 3
Training loss: 2.7907876201206885
Validation loss: 2.5868263532480578

Epoch: 5| Step: 4
Training loss: 2.612719647970831
Validation loss: 2.5751413153040423

Epoch: 5| Step: 5
Training loss: 2.619601010816644
Validation loss: 2.570404118924984

Epoch: 5| Step: 6
Training loss: 2.615628726277494
Validation loss: 2.5670798708085325

Epoch: 5| Step: 7
Training loss: 2.8231679562891268
Validation loss: 2.545811864894873

Epoch: 5| Step: 8
Training loss: 2.844363806578259
Validation loss: 2.547055714462704

Epoch: 5| Step: 9
Training loss: 2.9763774664129548
Validation loss: 2.5474967164994364

Epoch: 5| Step: 10
Training loss: 3.4755078719896058
Validation loss: 2.5466616740202235

Epoch: 167| Step: 0
Training loss: 3.228766254497851
Validation loss: 2.547112610910653

Epoch: 5| Step: 1
Training loss: 2.185681486373412
Validation loss: 2.5521290624128263

Epoch: 5| Step: 2
Training loss: 3.477522196805142
Validation loss: 2.5498859266599028

Epoch: 5| Step: 3
Training loss: 2.2335816155204444
Validation loss: 2.5583489062988445

Epoch: 5| Step: 4
Training loss: 2.209023229930164
Validation loss: 2.566169387581174

Epoch: 5| Step: 5
Training loss: 2.4753589292799276
Validation loss: 2.564639086319022

Epoch: 5| Step: 6
Training loss: 3.2079263569377097
Validation loss: 2.5722540738361577

Epoch: 5| Step: 7
Training loss: 2.985517512816821
Validation loss: 2.581125228366278

Epoch: 5| Step: 8
Training loss: 2.887290722417692
Validation loss: 2.590626770127385

Epoch: 5| Step: 9
Training loss: 3.4240042972448603
Validation loss: 2.5768313376851575

Epoch: 5| Step: 10
Training loss: 3.086048288408837
Validation loss: 2.5701263776264156

Epoch: 168| Step: 0
Training loss: 3.026060716018641
Validation loss: 2.573546141089835

Epoch: 5| Step: 1
Training loss: 1.9282653139273613
Validation loss: 2.5818411188801957

Epoch: 5| Step: 2
Training loss: 3.3976342666065666
Validation loss: 2.590119763987079

Epoch: 5| Step: 3
Training loss: 2.979239153924924
Validation loss: 2.5705943091039516

Epoch: 5| Step: 4
Training loss: 3.4086614349800586
Validation loss: 2.5790258678852283

Epoch: 5| Step: 5
Training loss: 2.671809591641597
Validation loss: 2.5815953757474697

Epoch: 5| Step: 6
Training loss: 2.4682896824732716
Validation loss: 2.578534736279556

Epoch: 5| Step: 7
Training loss: 2.7857542104969113
Validation loss: 2.5795351787551724

Epoch: 5| Step: 8
Training loss: 3.1571656966662447
Validation loss: 2.572268059807295

Epoch: 5| Step: 9
Training loss: 2.766276482180821
Validation loss: 2.5614236151176573

Epoch: 5| Step: 10
Training loss: 2.8783513314620057
Validation loss: 2.563482942900406

Epoch: 169| Step: 0
Training loss: 2.7268295375925873
Validation loss: 2.5599722671769127

Epoch: 5| Step: 1
Training loss: 3.047708407153509
Validation loss: 2.5569652769042452

Epoch: 5| Step: 2
Training loss: 3.070709125244583
Validation loss: 2.5580417719306294

Epoch: 5| Step: 3
Training loss: 2.876729527917846
Validation loss: 2.550666529990294

Epoch: 5| Step: 4
Training loss: 2.4640628405893077
Validation loss: 2.538643714817233

Epoch: 5| Step: 5
Training loss: 3.006682106734031
Validation loss: 2.547732349513549

Epoch: 5| Step: 6
Training loss: 2.491546261365013
Validation loss: 2.5450660285029545

Epoch: 5| Step: 7
Training loss: 3.372121925964323
Validation loss: 2.5407798110149016

Epoch: 5| Step: 8
Training loss: 2.5988478602066123
Validation loss: 2.550849821039671

Epoch: 5| Step: 9
Training loss: 2.936311846747981
Validation loss: 2.5464976202449123

Epoch: 5| Step: 10
Training loss: 3.0576936023268337
Validation loss: 2.5556559592746235

Epoch: 170| Step: 0
Training loss: 2.520013239689516
Validation loss: 2.555864590585239

Epoch: 5| Step: 1
Training loss: 3.311510622072298
Validation loss: 2.5663393363121574

Epoch: 5| Step: 2
Training loss: 2.633408838308282
Validation loss: 2.582040998052525

Epoch: 5| Step: 3
Training loss: 3.622805621810987
Validation loss: 2.5890917133052573

Epoch: 5| Step: 4
Training loss: 3.352332962505948
Validation loss: 2.590582504704707

Epoch: 5| Step: 5
Training loss: 2.888197916080824
Validation loss: 2.5730565440650537

Epoch: 5| Step: 6
Training loss: 1.5954833235339845
Validation loss: 2.556592131129024

Epoch: 5| Step: 7
Training loss: 2.8753167682786422
Validation loss: 2.561252717630393

Epoch: 5| Step: 8
Training loss: 2.336130395790281
Validation loss: 2.5607562280958263

Epoch: 5| Step: 9
Training loss: 3.2467169685566333
Validation loss: 2.562163578242542

Epoch: 5| Step: 10
Training loss: 2.7344569602671953
Validation loss: 2.555779768900547

Epoch: 171| Step: 0
Training loss: 3.0219729323825413
Validation loss: 2.5604981307127694

Epoch: 5| Step: 1
Training loss: 3.0263430805852547
Validation loss: 2.5462767950806726

Epoch: 5| Step: 2
Training loss: 2.9432903603181257
Validation loss: 2.5536991136757514

Epoch: 5| Step: 3
Training loss: 2.689969369933725
Validation loss: 2.5443877251879905

Epoch: 5| Step: 4
Training loss: 3.240605494588568
Validation loss: 2.5459179484553007

Epoch: 5| Step: 5
Training loss: 2.4385203646696683
Validation loss: 2.5378125426876688

Epoch: 5| Step: 6
Training loss: 3.0824548311783717
Validation loss: 2.544041138901127

Epoch: 5| Step: 7
Training loss: 2.9345158779789133
Validation loss: 2.543048801242408

Epoch: 5| Step: 8
Training loss: 2.735648419996991
Validation loss: 2.5447134093849746

Epoch: 5| Step: 9
Training loss: 2.289516781460737
Validation loss: 2.5467091852462533

Epoch: 5| Step: 10
Training loss: 3.208935189871464
Validation loss: 2.546941139685555

Epoch: 172| Step: 0
Training loss: 3.306260620561643
Validation loss: 2.5569660469091136

Epoch: 5| Step: 1
Training loss: 3.1006580638756587
Validation loss: 2.56511980002756

Epoch: 5| Step: 2
Training loss: 3.1256295142306123
Validation loss: 2.5689704693620703

Epoch: 5| Step: 3
Training loss: 2.6145977815226313
Validation loss: 2.584553510457567

Epoch: 5| Step: 4
Training loss: 2.652440289859882
Validation loss: 2.578632884186377

Epoch: 5| Step: 5
Training loss: 2.839843246271018
Validation loss: 2.5810015568502194

Epoch: 5| Step: 6
Training loss: 3.0071584807923033
Validation loss: 2.5922085723072867

Epoch: 5| Step: 7
Training loss: 2.173961158924859
Validation loss: 2.571786355631458

Epoch: 5| Step: 8
Training loss: 2.7166398727718293
Validation loss: 2.559049528748795

Epoch: 5| Step: 9
Training loss: 2.6257831676763304
Validation loss: 2.5605770612505663

Epoch: 5| Step: 10
Training loss: 3.4851587893680502
Validation loss: 2.553645035395643

Epoch: 173| Step: 0
Training loss: 3.1350707479035225
Validation loss: 2.5471185008770365

Epoch: 5| Step: 1
Training loss: 2.257090416776788
Validation loss: 2.5432798164081993

Epoch: 5| Step: 2
Training loss: 3.3715877944488217
Validation loss: 2.5447900087699065

Epoch: 5| Step: 3
Training loss: 3.2304235821925493
Validation loss: 2.545430252579609

Epoch: 5| Step: 4
Training loss: 2.209777527740504
Validation loss: 2.5415608649487775

Epoch: 5| Step: 5
Training loss: 2.8314019707657465
Validation loss: 2.538787555306636

Epoch: 5| Step: 6
Training loss: 3.1132829347842836
Validation loss: 2.5417498657821818

Epoch: 5| Step: 7
Training loss: 2.512834980207882
Validation loss: 2.5486469356998005

Epoch: 5| Step: 8
Training loss: 3.356060433317624
Validation loss: 2.556743290271412

Epoch: 5| Step: 9
Training loss: 2.420429610589181
Validation loss: 2.5722443744064014

Epoch: 5| Step: 10
Training loss: 3.0500628105324914
Validation loss: 2.585854572904241

Epoch: 174| Step: 0
Training loss: 3.1872960941692785
Validation loss: 2.5777209271350228

Epoch: 5| Step: 1
Training loss: 2.886466999974772
Validation loss: 2.56197700195616

Epoch: 5| Step: 2
Training loss: 2.7356754371363343
Validation loss: 2.5670395805430726

Epoch: 5| Step: 3
Training loss: 2.74104628766629
Validation loss: 2.555069448445793

Epoch: 5| Step: 4
Training loss: 2.711398126786422
Validation loss: 2.5584879475297697

Epoch: 5| Step: 5
Training loss: 2.820816121877643
Validation loss: 2.5453851598747144

Epoch: 5| Step: 6
Training loss: 3.015184439462948
Validation loss: 2.5506883704276277

Epoch: 5| Step: 7
Training loss: 3.0182570597972784
Validation loss: 2.555946116573892

Epoch: 5| Step: 8
Training loss: 2.6413287065931783
Validation loss: 2.5465997904189646

Epoch: 5| Step: 9
Training loss: 2.9517504202621985
Validation loss: 2.549676637215673

Epoch: 5| Step: 10
Training loss: 2.9007294428046895
Validation loss: 2.548628665781317

Epoch: 175| Step: 0
Training loss: 2.4943180364662836
Validation loss: 2.5606504198652096

Epoch: 5| Step: 1
Training loss: 2.7303027537781994
Validation loss: 2.5516939054857533

Epoch: 5| Step: 2
Training loss: 2.9679175565019293
Validation loss: 2.557041146334885

Epoch: 5| Step: 3
Training loss: 3.1118916050976844
Validation loss: 2.5466212982943244

Epoch: 5| Step: 4
Training loss: 2.919166166055215
Validation loss: 2.54784600325543

Epoch: 5| Step: 5
Training loss: 2.9322134293214015
Validation loss: 2.553483096884966

Epoch: 5| Step: 6
Training loss: 3.2769329918490624
Validation loss: 2.54878914648896

Epoch: 5| Step: 7
Training loss: 2.5340761020195144
Validation loss: 2.5413832187874665

Epoch: 5| Step: 8
Training loss: 3.03949175551373
Validation loss: 2.530230136548529

Epoch: 5| Step: 9
Training loss: 2.93240759142152
Validation loss: 2.543403960372387

Epoch: 5| Step: 10
Training loss: 2.571083857500767
Validation loss: 2.5358162300278475

Epoch: 176| Step: 0
Training loss: 2.40512881229452
Validation loss: 2.533886698778205

Epoch: 5| Step: 1
Training loss: 3.206055431150919
Validation loss: 2.5301498337492294

Epoch: 5| Step: 2
Training loss: 3.158490886801296
Validation loss: 2.536133008604187

Epoch: 5| Step: 3
Training loss: 2.6936166929463603
Validation loss: 2.530568377338798

Epoch: 5| Step: 4
Training loss: 2.2887634498621847
Validation loss: 2.5447725201149662

Epoch: 5| Step: 5
Training loss: 3.3453667555662783
Validation loss: 2.5392014039367554

Epoch: 5| Step: 6
Training loss: 3.039609099904889
Validation loss: 2.5381406139386793

Epoch: 5| Step: 7
Training loss: 2.276592045515692
Validation loss: 2.55441250788204

Epoch: 5| Step: 8
Training loss: 3.326690077944566
Validation loss: 2.554702495325098

Epoch: 5| Step: 9
Training loss: 2.9425858643740317
Validation loss: 2.556564222244086

Epoch: 5| Step: 10
Training loss: 2.6074575357463092
Validation loss: 2.5576186359027115

Epoch: 177| Step: 0
Training loss: 3.175061659326846
Validation loss: 2.555312001916298

Epoch: 5| Step: 1
Training loss: 2.787808261812955
Validation loss: 2.553315265417237

Epoch: 5| Step: 2
Training loss: 3.1909137471878157
Validation loss: 2.555054403099556

Epoch: 5| Step: 3
Training loss: 3.4130842609974423
Validation loss: 2.5619682562658666

Epoch: 5| Step: 4
Training loss: 2.3380003531319486
Validation loss: 2.5789445853990167

Epoch: 5| Step: 5
Training loss: 2.7524883109943707
Validation loss: 2.5707921069622635

Epoch: 5| Step: 6
Training loss: 2.246400497056629
Validation loss: 2.5813916286165246

Epoch: 5| Step: 7
Training loss: 2.8342416279798597
Validation loss: 2.5635929128061523

Epoch: 5| Step: 8
Training loss: 2.8106557097314924
Validation loss: 2.5588857622360988

Epoch: 5| Step: 9
Training loss: 2.8638031238039354
Validation loss: 2.5710622740747904

Epoch: 5| Step: 10
Training loss: 3.0368390027362397
Validation loss: 2.5366149858685856

Epoch: 178| Step: 0
Training loss: 2.4134483173369476
Validation loss: 2.537242433577655

Epoch: 5| Step: 1
Training loss: 3.2590781847508428
Validation loss: 2.5316162350828684

Epoch: 5| Step: 2
Training loss: 2.700509454205976
Validation loss: 2.5327729869860023

Epoch: 5| Step: 3
Training loss: 3.3837474914022896
Validation loss: 2.537108471651032

Epoch: 5| Step: 4
Training loss: 2.7724116617616024
Validation loss: 2.5342351300372536

Epoch: 5| Step: 5
Training loss: 1.7759910717988914
Validation loss: 2.5334197275210855

Epoch: 5| Step: 6
Training loss: 3.094997270179247
Validation loss: 2.5395932686407208

Epoch: 5| Step: 7
Training loss: 2.974621878564496
Validation loss: 2.5329219411490445

Epoch: 5| Step: 8
Training loss: 3.25035768154574
Validation loss: 2.534809729421204

Epoch: 5| Step: 9
Training loss: 2.9190108188848156
Validation loss: 2.542124525602265

Epoch: 5| Step: 10
Training loss: 2.701487315219976
Validation loss: 2.54676136835618

Epoch: 179| Step: 0
Training loss: 2.396084603664378
Validation loss: 2.551596023480714

Epoch: 5| Step: 1
Training loss: 2.6765526766354597
Validation loss: 2.553377618794656

Epoch: 5| Step: 2
Training loss: 2.7770528091008484
Validation loss: 2.565886172298241

Epoch: 5| Step: 3
Training loss: 2.6395089764999713
Validation loss: 2.574027246032529

Epoch: 5| Step: 4
Training loss: 2.866327889702967
Validation loss: 2.555695033677384

Epoch: 5| Step: 5
Training loss: 2.676844030784933
Validation loss: 2.557505375351433

Epoch: 5| Step: 6
Training loss: 3.172482887985457
Validation loss: 2.5633268715495525

Epoch: 5| Step: 7
Training loss: 2.9949498585370953
Validation loss: 2.5771929794220227

Epoch: 5| Step: 8
Training loss: 2.91978012302243
Validation loss: 2.5692762254589563

Epoch: 5| Step: 9
Training loss: 3.4619626836765507
Validation loss: 2.547444184151202

Epoch: 5| Step: 10
Training loss: 2.8262687197254674
Validation loss: 2.548684523258718

Epoch: 180| Step: 0
Training loss: 2.621287036028341
Validation loss: 2.5315946128923286

Epoch: 5| Step: 1
Training loss: 2.746728251316167
Validation loss: 2.5388947532906627

Epoch: 5| Step: 2
Training loss: 2.5955749893422597
Validation loss: 2.539436121760964

Epoch: 5| Step: 3
Training loss: 2.6560140168325703
Validation loss: 2.530102692473197

Epoch: 5| Step: 4
Training loss: 3.0554633752809255
Validation loss: 2.5282194600306362

Epoch: 5| Step: 5
Training loss: 2.6950469397595516
Validation loss: 2.5316244694312013

Epoch: 5| Step: 6
Training loss: 2.5669947955290904
Validation loss: 2.5256402492892382

Epoch: 5| Step: 7
Training loss: 2.872040261711625
Validation loss: 2.5313786066711153

Epoch: 5| Step: 8
Training loss: 3.2586692214160817
Validation loss: 2.531384730731787

Epoch: 5| Step: 9
Training loss: 3.2777182327580405
Validation loss: 2.539790287135765

Epoch: 5| Step: 10
Training loss: 3.145550713043755
Validation loss: 2.541955149467897

Epoch: 181| Step: 0
Training loss: 2.645205075222738
Validation loss: 2.5434012560235737

Epoch: 5| Step: 1
Training loss: 3.2139783137028397
Validation loss: 2.5520459548861534

Epoch: 5| Step: 2
Training loss: 3.14126625916007
Validation loss: 2.552860906167365

Epoch: 5| Step: 3
Training loss: 2.8142750542752077
Validation loss: 2.5371367542026997

Epoch: 5| Step: 4
Training loss: 3.13322145451681
Validation loss: 2.54988078808474

Epoch: 5| Step: 5
Training loss: 3.1550208993935924
Validation loss: 2.538049775780308

Epoch: 5| Step: 6
Training loss: 2.3824952961894272
Validation loss: 2.5372386001008893

Epoch: 5| Step: 7
Training loss: 2.5463474405977133
Validation loss: 2.530010828042602

Epoch: 5| Step: 8
Training loss: 3.1202583961590857
Validation loss: 2.534216389005112

Epoch: 5| Step: 9
Training loss: 2.8724762163762922
Validation loss: 2.527893684168733

Epoch: 5| Step: 10
Training loss: 2.244748132081449
Validation loss: 2.5282576443290794

Epoch: 182| Step: 0
Training loss: 2.987010012231527
Validation loss: 2.529118608660549

Epoch: 5| Step: 1
Training loss: 2.7655365493337243
Validation loss: 2.5336408030890682

Epoch: 5| Step: 2
Training loss: 2.4033508670853334
Validation loss: 2.5238584995672704

Epoch: 5| Step: 3
Training loss: 2.983781525885209
Validation loss: 2.5336364288983697

Epoch: 5| Step: 4
Training loss: 3.289717873996298
Validation loss: 2.538057754412462

Epoch: 5| Step: 5
Training loss: 2.388709603711137
Validation loss: 2.5346175539982236

Epoch: 5| Step: 6
Training loss: 3.125535537608009
Validation loss: 2.544674668067104

Epoch: 5| Step: 7
Training loss: 2.836303351057279
Validation loss: 2.5376071602799457

Epoch: 5| Step: 8
Training loss: 2.9153280910418933
Validation loss: 2.560701899393764

Epoch: 5| Step: 9
Training loss: 2.788810569006261
Validation loss: 2.54944810925171

Epoch: 5| Step: 10
Training loss: 2.9634451601821867
Validation loss: 2.561989711672421

Epoch: 183| Step: 0
Training loss: 2.781959271805418
Validation loss: 2.547544537192904

Epoch: 5| Step: 1
Training loss: 2.895345267096524
Validation loss: 2.5413923621534678

Epoch: 5| Step: 2
Training loss: 2.9207319175828528
Validation loss: 2.5271391064195523

Epoch: 5| Step: 3
Training loss: 3.3570980428469928
Validation loss: 2.5360083692050965

Epoch: 5| Step: 4
Training loss: 3.224956565387015
Validation loss: 2.527555650399632

Epoch: 5| Step: 5
Training loss: 2.478008341598941
Validation loss: 2.523768854909503

Epoch: 5| Step: 6
Training loss: 2.6940047035261183
Validation loss: 2.524635606803279

Epoch: 5| Step: 7
Training loss: 2.482259173279962
Validation loss: 2.5229086520333417

Epoch: 5| Step: 8
Training loss: 2.922420675149124
Validation loss: 2.5215006607495742

Epoch: 5| Step: 9
Training loss: 2.4770688282440596
Validation loss: 2.5232460159873393

Epoch: 5| Step: 10
Training loss: 3.173139648884562
Validation loss: 2.526076812212095

Epoch: 184| Step: 0
Training loss: 3.0981926664035497
Validation loss: 2.524118662530632

Epoch: 5| Step: 1
Training loss: 2.2195371923800136
Validation loss: 2.518234944337204

Epoch: 5| Step: 2
Training loss: 2.761866369982822
Validation loss: 2.524912289517783

Epoch: 5| Step: 3
Training loss: 2.792595002036269
Validation loss: 2.5302987751583985

Epoch: 5| Step: 4
Training loss: 2.7486599344761236
Validation loss: 2.5339649841730836

Epoch: 5| Step: 5
Training loss: 3.162089017315954
Validation loss: 2.5305650352216214

Epoch: 5| Step: 6
Training loss: 2.4706681923790366
Validation loss: 2.5303393789158615

Epoch: 5| Step: 7
Training loss: 2.7744711225872942
Validation loss: 2.5369768925080916

Epoch: 5| Step: 8
Training loss: 3.06432910714435
Validation loss: 2.5313627632411744

Epoch: 5| Step: 9
Training loss: 3.263704748347682
Validation loss: 2.5458669101144364

Epoch: 5| Step: 10
Training loss: 2.9779578114961236
Validation loss: 2.5498009352463713

Epoch: 185| Step: 0
Training loss: 2.7216558602518184
Validation loss: 2.550387660516545

Epoch: 5| Step: 1
Training loss: 3.42926036634086
Validation loss: 2.5499524326218928

Epoch: 5| Step: 2
Training loss: 2.4949822615182113
Validation loss: 2.5758744535623097

Epoch: 5| Step: 3
Training loss: 2.7526757487526563
Validation loss: 2.57439937633498

Epoch: 5| Step: 4
Training loss: 2.783258377329853
Validation loss: 2.5707105970446205

Epoch: 5| Step: 5
Training loss: 3.102887771312766
Validation loss: 2.5631864365152275

Epoch: 5| Step: 6
Training loss: 2.6002884227993603
Validation loss: 2.548341408589083

Epoch: 5| Step: 7
Training loss: 2.877898538069465
Validation loss: 2.524341198564711

Epoch: 5| Step: 8
Training loss: 2.7268045312526814
Validation loss: 2.522415160780963

Epoch: 5| Step: 9
Training loss: 2.961946743194665
Validation loss: 2.520657734529225

Epoch: 5| Step: 10
Training loss: 2.9638499729215892
Validation loss: 2.5169012599948912

Epoch: 186| Step: 0
Training loss: 2.5780307636955753
Validation loss: 2.521376751998662

Epoch: 5| Step: 1
Training loss: 2.511605694778968
Validation loss: 2.5196624012013658

Epoch: 5| Step: 2
Training loss: 3.1102388801704013
Validation loss: 2.51562850158036

Epoch: 5| Step: 3
Training loss: 2.5361670314403084
Validation loss: 2.5137996656239565

Epoch: 5| Step: 4
Training loss: 3.263433277624552
Validation loss: 2.5190976275235855

Epoch: 5| Step: 5
Training loss: 2.7060827049366085
Validation loss: 2.5115753435518413

Epoch: 5| Step: 6
Training loss: 2.77548391573284
Validation loss: 2.5210407679884743

Epoch: 5| Step: 7
Training loss: 2.428205915401396
Validation loss: 2.5386188340956357

Epoch: 5| Step: 8
Training loss: 3.6187620752426315
Validation loss: 2.5358249071905172

Epoch: 5| Step: 9
Training loss: 3.0213155076639358
Validation loss: 2.5551173300844527

Epoch: 5| Step: 10
Training loss: 2.6266478861058307
Validation loss: 2.5409796754810716

Epoch: 187| Step: 0
Training loss: 2.79687960320632
Validation loss: 2.5708005573752635

Epoch: 5| Step: 1
Training loss: 3.2179011734889107
Validation loss: 2.605935732230969

Epoch: 5| Step: 2
Training loss: 2.691916009162344
Validation loss: 2.5867577190609685

Epoch: 5| Step: 3
Training loss: 2.995288487011287
Validation loss: 2.5826850723447716

Epoch: 5| Step: 4
Training loss: 2.720392366887868
Validation loss: 2.5476132808860283

Epoch: 5| Step: 5
Training loss: 2.9557910974319066
Validation loss: 2.529103213300147

Epoch: 5| Step: 6
Training loss: 2.5252556171012985
Validation loss: 2.5171368137038983

Epoch: 5| Step: 7
Training loss: 2.759587740446551
Validation loss: 2.5188911496760107

Epoch: 5| Step: 8
Training loss: 2.411885387816428
Validation loss: 2.5183281280588004

Epoch: 5| Step: 9
Training loss: 3.2517163073023867
Validation loss: 2.525639975226846

Epoch: 5| Step: 10
Training loss: 3.188546551203525
Validation loss: 2.5242023665747118

Epoch: 188| Step: 0
Training loss: 2.81154548554224
Validation loss: 2.5231074244909766

Epoch: 5| Step: 1
Training loss: 2.546112789002103
Validation loss: 2.5153174839429018

Epoch: 5| Step: 2
Training loss: 2.8681549186417916
Validation loss: 2.5200112711893157

Epoch: 5| Step: 3
Training loss: 2.7269602488189877
Validation loss: 2.517089212792954

Epoch: 5| Step: 4
Training loss: 2.864141441709909
Validation loss: 2.515561004601221

Epoch: 5| Step: 5
Training loss: 2.7720188864742994
Validation loss: 2.5256114827262297

Epoch: 5| Step: 6
Training loss: 2.862213227012405
Validation loss: 2.5350934191216963

Epoch: 5| Step: 7
Training loss: 3.2292718849677953
Validation loss: 2.557578117404438

Epoch: 5| Step: 8
Training loss: 2.6618836741721488
Validation loss: 2.561829760177576

Epoch: 5| Step: 9
Training loss: 3.0728800281129254
Validation loss: 2.5791768453750596

Epoch: 5| Step: 10
Training loss: 3.076361291291331
Validation loss: 2.5699392641753747

Epoch: 189| Step: 0
Training loss: 3.3798133999481745
Validation loss: 2.5681608417408595

Epoch: 5| Step: 1
Training loss: 3.004155301210559
Validation loss: 2.545901571185394

Epoch: 5| Step: 2
Training loss: 2.9929206288650616
Validation loss: 2.544642216785182

Epoch: 5| Step: 3
Training loss: 2.788674036322527
Validation loss: 2.5243801818644496

Epoch: 5| Step: 4
Training loss: 3.1856004627428622
Validation loss: 2.5213630724425835

Epoch: 5| Step: 5
Training loss: 3.4953677995422954
Validation loss: 2.524411791754038

Epoch: 5| Step: 6
Training loss: 2.642826223744871
Validation loss: 2.516126055540854

Epoch: 5| Step: 7
Training loss: 2.340798210386634
Validation loss: 2.5122004333700927

Epoch: 5| Step: 8
Training loss: 2.372331324571612
Validation loss: 2.5138922121958966

Epoch: 5| Step: 9
Training loss: 2.3317676695551626
Validation loss: 2.5167594995499316

Epoch: 5| Step: 10
Training loss: 2.572981170792963
Validation loss: 2.51367673369787

Epoch: 190| Step: 0
Training loss: 2.732161230671968
Validation loss: 2.514939228133305

Epoch: 5| Step: 1
Training loss: 3.3461735578946326
Validation loss: 2.5305822279816663

Epoch: 5| Step: 2
Training loss: 2.3486377866696286
Validation loss: 2.5192116145022116

Epoch: 5| Step: 3
Training loss: 2.5846675278264777
Validation loss: 2.525638334912053

Epoch: 5| Step: 4
Training loss: 2.809230684471145
Validation loss: 2.516349690645273

Epoch: 5| Step: 5
Training loss: 3.1731086924992127
Validation loss: 2.544725493573432

Epoch: 5| Step: 6
Training loss: 3.0306277865449944
Validation loss: 2.533154645961245

Epoch: 5| Step: 7
Training loss: 3.017759842323836
Validation loss: 2.5261983978664175

Epoch: 5| Step: 8
Training loss: 2.6441513081595565
Validation loss: 2.5344973240507436

Epoch: 5| Step: 9
Training loss: 2.635227985689295
Validation loss: 2.518122036086488

Epoch: 5| Step: 10
Training loss: 2.848865142544103
Validation loss: 2.528725036602014

Epoch: 191| Step: 0
Training loss: 3.0975064677986066
Validation loss: 2.543348437488739

Epoch: 5| Step: 1
Training loss: 2.7409660901348794
Validation loss: 2.5320690343582197

Epoch: 5| Step: 2
Training loss: 2.8670075487423987
Validation loss: 2.5299148897298176

Epoch: 5| Step: 3
Training loss: 2.9341169314912405
Validation loss: 2.521233212606398

Epoch: 5| Step: 4
Training loss: 2.796438001878828
Validation loss: 2.533597367435224

Epoch: 5| Step: 5
Training loss: 3.147706053323964
Validation loss: 2.5357432559672173

Epoch: 5| Step: 6
Training loss: 2.4721232678996152
Validation loss: 2.527394571037594

Epoch: 5| Step: 7
Training loss: 2.6300569597755517
Validation loss: 2.5373538979199566

Epoch: 5| Step: 8
Training loss: 2.808950685360871
Validation loss: 2.546286572284181

Epoch: 5| Step: 9
Training loss: 3.3370199479743468
Validation loss: 2.5325538784347303

Epoch: 5| Step: 10
Training loss: 2.1906248389229055
Validation loss: 2.5224341998747364

Epoch: 192| Step: 0
Training loss: 2.9283883838403892
Validation loss: 2.5281172355831667

Epoch: 5| Step: 1
Training loss: 3.2330195586028543
Validation loss: 2.5253149904015526

Epoch: 5| Step: 2
Training loss: 2.9410071032508696
Validation loss: 2.5264930260108853

Epoch: 5| Step: 3
Training loss: 2.8809874839100376
Validation loss: 2.515818152365482

Epoch: 5| Step: 4
Training loss: 2.639587017760281
Validation loss: 2.5192668756058736

Epoch: 5| Step: 5
Training loss: 2.965567077135376
Validation loss: 2.5160658652662042

Epoch: 5| Step: 6
Training loss: 3.0299903375956254
Validation loss: 2.502348534021945

Epoch: 5| Step: 7
Training loss: 2.3034716486311186
Validation loss: 2.5074115144191182

Epoch: 5| Step: 8
Training loss: 2.6363327082849755
Validation loss: 2.509849905778549

Epoch: 5| Step: 9
Training loss: 2.7359654623941387
Validation loss: 2.506891004063819

Epoch: 5| Step: 10
Training loss: 2.997172612755945
Validation loss: 2.512061169211242

Epoch: 193| Step: 0
Training loss: 3.1091751724518066
Validation loss: 2.512085637384742

Epoch: 5| Step: 1
Training loss: 2.335002393047405
Validation loss: 2.5213639448291545

Epoch: 5| Step: 2
Training loss: 2.6738892932078437
Validation loss: 2.5293029351778893

Epoch: 5| Step: 3
Training loss: 3.133154339107938
Validation loss: 2.530162066526182

Epoch: 5| Step: 4
Training loss: 2.460054463194574
Validation loss: 2.55157715375668

Epoch: 5| Step: 5
Training loss: 3.2214116322915154
Validation loss: 2.5653284981185953

Epoch: 5| Step: 6
Training loss: 3.4576156208513367
Validation loss: 2.547212527132548

Epoch: 5| Step: 7
Training loss: 2.7803440976049036
Validation loss: 2.545465526902049

Epoch: 5| Step: 8
Training loss: 2.8235725307210857
Validation loss: 2.530713524704119

Epoch: 5| Step: 9
Training loss: 2.4120895076041626
Validation loss: 2.5184456536368143

Epoch: 5| Step: 10
Training loss: 2.7925227736156617
Validation loss: 2.5242830241170178

Epoch: 194| Step: 0
Training loss: 2.509576955153089
Validation loss: 2.5127853205836113

Epoch: 5| Step: 1
Training loss: 2.7144266590294452
Validation loss: 2.5033877425253923

Epoch: 5| Step: 2
Training loss: 3.173357537228043
Validation loss: 2.511843568942405

Epoch: 5| Step: 3
Training loss: 2.8962219489809113
Validation loss: 2.5130980522121025

Epoch: 5| Step: 4
Training loss: 3.31182897716824
Validation loss: 2.5210938291536547

Epoch: 5| Step: 5
Training loss: 2.6668861616717736
Validation loss: 2.5095145687499465

Epoch: 5| Step: 6
Training loss: 2.2534913419968112
Validation loss: 2.5166617817278856

Epoch: 5| Step: 7
Training loss: 2.9163598217092788
Validation loss: 2.5147188715554116

Epoch: 5| Step: 8
Training loss: 2.9729529895626357
Validation loss: 2.5146999891544164

Epoch: 5| Step: 9
Training loss: 2.9494163194378324
Validation loss: 2.516989796634279

Epoch: 5| Step: 10
Training loss: 2.827609189030746
Validation loss: 2.5081300986395645

Epoch: 195| Step: 0
Training loss: 2.528816277639055
Validation loss: 2.5087821097293124

Epoch: 5| Step: 1
Training loss: 2.3021491085914647
Validation loss: 2.5189944650092184

Epoch: 5| Step: 2
Training loss: 2.8715298483637506
Validation loss: 2.5148033257983693

Epoch: 5| Step: 3
Training loss: 3.1859093979610598
Validation loss: 2.522861782932896

Epoch: 5| Step: 4
Training loss: 3.1209313418418425
Validation loss: 2.519445738279717

Epoch: 5| Step: 5
Training loss: 2.5182709609899185
Validation loss: 2.5118188667275985

Epoch: 5| Step: 6
Training loss: 2.901536955179187
Validation loss: 2.514993047982497

Epoch: 5| Step: 7
Training loss: 2.9280897335831493
Validation loss: 2.518439047161299

Epoch: 5| Step: 8
Training loss: 2.9320491783108285
Validation loss: 2.5417536647182484

Epoch: 5| Step: 9
Training loss: 2.9799143424300327
Validation loss: 2.5406190140932456

Epoch: 5| Step: 10
Training loss: 2.962814662012382
Validation loss: 2.5290142127377484

Epoch: 196| Step: 0
Training loss: 2.3839894874264167
Validation loss: 2.5178108662404783

Epoch: 5| Step: 1
Training loss: 3.139656183165018
Validation loss: 2.509540765711755

Epoch: 5| Step: 2
Training loss: 2.9014631658014274
Validation loss: 2.501004275756193

Epoch: 5| Step: 3
Training loss: 3.20024552595447
Validation loss: 2.5000655729656684

Epoch: 5| Step: 4
Training loss: 3.0240846872732883
Validation loss: 2.506632978332518

Epoch: 5| Step: 5
Training loss: 2.361100936069879
Validation loss: 2.49946706895623

Epoch: 5| Step: 6
Training loss: 2.8475901068814453
Validation loss: 2.502066987278419

Epoch: 5| Step: 7
Training loss: 2.6303615311427024
Validation loss: 2.5050365576801723

Epoch: 5| Step: 8
Training loss: 2.9274434765213724
Validation loss: 2.502192378873434

Epoch: 5| Step: 9
Training loss: 2.421420245391382
Validation loss: 2.5077030849448296

Epoch: 5| Step: 10
Training loss: 3.328093622623875
Validation loss: 2.5081677220229945

Epoch: 197| Step: 0
Training loss: 3.2691457651056646
Validation loss: 2.515274034579188

Epoch: 5| Step: 1
Training loss: 3.1362375766816735
Validation loss: 2.5092116953010057

Epoch: 5| Step: 2
Training loss: 2.5216314035064973
Validation loss: 2.514401675911398

Epoch: 5| Step: 3
Training loss: 3.29944080469983
Validation loss: 2.5193113917440737

Epoch: 5| Step: 4
Training loss: 2.098372978076312
Validation loss: 2.5374695814915946

Epoch: 5| Step: 5
Training loss: 3.0247525452845028
Validation loss: 2.5414185018708664

Epoch: 5| Step: 6
Training loss: 2.466379016995331
Validation loss: 2.544377598113783

Epoch: 5| Step: 7
Training loss: 3.0697921816788005
Validation loss: 2.5593024111519225

Epoch: 5| Step: 8
Training loss: 2.4933185940407134
Validation loss: 2.54749198469767

Epoch: 5| Step: 9
Training loss: 3.035882929116628
Validation loss: 2.543086000768875

Epoch: 5| Step: 10
Training loss: 2.522609232266187
Validation loss: 2.5260100866453197

Epoch: 198| Step: 0
Training loss: 2.905559498784453
Validation loss: 2.5046864463297234

Epoch: 5| Step: 1
Training loss: 2.836106308465873
Validation loss: 2.5094763137886904

Epoch: 5| Step: 2
Training loss: 2.8704768549629396
Validation loss: 2.506099565338625

Epoch: 5| Step: 3
Training loss: 2.4096223063524373
Validation loss: 2.5074312624834456

Epoch: 5| Step: 4
Training loss: 2.3137137861833734
Validation loss: 2.5028204502672295

Epoch: 5| Step: 5
Training loss: 2.770663741426267
Validation loss: 2.507907075823361

Epoch: 5| Step: 6
Training loss: 3.248313906595052
Validation loss: 2.5070238503529914

Epoch: 5| Step: 7
Training loss: 3.0186655794901065
Validation loss: 2.5024350459080265

Epoch: 5| Step: 8
Training loss: 3.0943000381564896
Validation loss: 2.5048479625125655

Epoch: 5| Step: 9
Training loss: 3.0377823749418464
Validation loss: 2.50702596403171

Epoch: 5| Step: 10
Training loss: 2.617612252000848
Validation loss: 2.513650292232346

Epoch: 199| Step: 0
Training loss: 2.629871298973358
Validation loss: 2.536006607212812

Epoch: 5| Step: 1
Training loss: 2.6426937870221234
Validation loss: 2.5300549565399093

Epoch: 5| Step: 2
Training loss: 3.071393703503572
Validation loss: 2.5282626859072423

Epoch: 5| Step: 3
Training loss: 3.6238148823798673
Validation loss: 2.547665672894748

Epoch: 5| Step: 4
Training loss: 2.8972170334652985
Validation loss: 2.5410961766303495

Epoch: 5| Step: 5
Training loss: 2.9202585900128684
Validation loss: 2.5192327100098533

Epoch: 5| Step: 6
Training loss: 2.8842488667361135
Validation loss: 2.5467861695296286

Epoch: 5| Step: 7
Training loss: 2.698801629481227
Validation loss: 2.578475292941092

Epoch: 5| Step: 8
Training loss: 2.032442652419983
Validation loss: 2.577892420505459

Epoch: 5| Step: 9
Training loss: 2.846911171977512
Validation loss: 2.5724569721000408

Epoch: 5| Step: 10
Training loss: 2.7162225309511157
Validation loss: 2.5765490943751335

Epoch: 200| Step: 0
Training loss: 2.194969503412438
Validation loss: 2.5560674027335146

Epoch: 5| Step: 1
Training loss: 3.025437750550901
Validation loss: 2.537039046198625

Epoch: 5| Step: 2
Training loss: 2.401410872289719
Validation loss: 2.5249235536578833

Epoch: 5| Step: 3
Training loss: 2.7281304253418277
Validation loss: 2.5148547713184475

Epoch: 5| Step: 4
Training loss: 3.261186860168929
Validation loss: 2.5129934804300103

Epoch: 5| Step: 5
Training loss: 3.0211968214210487
Validation loss: 2.507563699831637

Epoch: 5| Step: 6
Training loss: 2.8334883105210396
Validation loss: 2.5129789105467286

Epoch: 5| Step: 7
Training loss: 2.6903933541670972
Validation loss: 2.5167878518702604

Epoch: 5| Step: 8
Training loss: 2.8952680260113826
Validation loss: 2.5153661671307503

Epoch: 5| Step: 9
Training loss: 3.0129195811481297
Validation loss: 2.5137330761613903

Epoch: 5| Step: 10
Training loss: 3.2170426368057927
Validation loss: 2.520384848705872

Epoch: 201| Step: 0
Training loss: 2.5561101376201556
Validation loss: 2.509692030349124

Epoch: 5| Step: 1
Training loss: 3.3347351623337755
Validation loss: 2.512012576075453

Epoch: 5| Step: 2
Training loss: 2.579470658965255
Validation loss: 2.5143946112124325

Epoch: 5| Step: 3
Training loss: 2.8392783419366836
Validation loss: 2.5191375875131046

Epoch: 5| Step: 4
Training loss: 3.0275267711813427
Validation loss: 2.5328712482224174

Epoch: 5| Step: 5
Training loss: 2.874334341194194
Validation loss: 2.544659976334687

Epoch: 5| Step: 6
Training loss: 2.8884153426279124
Validation loss: 2.566324586796292

Epoch: 5| Step: 7
Training loss: 2.783451880330822
Validation loss: 2.5638769888551063

Epoch: 5| Step: 8
Training loss: 2.8883975132765483
Validation loss: 2.587229334489331

Epoch: 5| Step: 9
Training loss: 2.6130584484969392
Validation loss: 2.582831577817949

Epoch: 5| Step: 10
Training loss: 2.8046031716082958
Validation loss: 2.599241003904508

Epoch: 202| Step: 0
Training loss: 2.65615566310537
Validation loss: 2.5723399558472817

Epoch: 5| Step: 1
Training loss: 2.703006014106995
Validation loss: 2.5617557698453925

Epoch: 5| Step: 2
Training loss: 3.0050959221736737
Validation loss: 2.5192548270301542

Epoch: 5| Step: 3
Training loss: 3.5563801183511883
Validation loss: 2.5094937756617846

Epoch: 5| Step: 4
Training loss: 2.4471731693616423
Validation loss: 2.506934532249178

Epoch: 5| Step: 5
Training loss: 2.0030652636876414
Validation loss: 2.508216369205438

Epoch: 5| Step: 6
Training loss: 3.148666941420703
Validation loss: 2.509042636418744

Epoch: 5| Step: 7
Training loss: 3.1386916249573082
Validation loss: 2.504787903458312

Epoch: 5| Step: 8
Training loss: 2.494478613551697
Validation loss: 2.508045265339648

Epoch: 5| Step: 9
Training loss: 2.8625865473427754
Validation loss: 2.5013144872555926

Epoch: 5| Step: 10
Training loss: 3.0223990931677682
Validation loss: 2.518409971337425

Epoch: 203| Step: 0
Training loss: 2.810001619956205
Validation loss: 2.524982933751079

Epoch: 5| Step: 1
Training loss: 1.7890623667354617
Validation loss: 2.535355252374096

Epoch: 5| Step: 2
Training loss: 3.1007494112909373
Validation loss: 2.5337531260363533

Epoch: 5| Step: 3
Training loss: 3.1805124923108097
Validation loss: 2.5556146031338405

Epoch: 5| Step: 4
Training loss: 2.920775670794319
Validation loss: 2.5630653762086744

Epoch: 5| Step: 5
Training loss: 3.146475585319039
Validation loss: 2.564091746060542

Epoch: 5| Step: 6
Training loss: 2.7312489105850943
Validation loss: 2.550907967491304

Epoch: 5| Step: 7
Training loss: 2.567787669557235
Validation loss: 2.529061016476348

Epoch: 5| Step: 8
Training loss: 3.024521113549812
Validation loss: 2.544436846618741

Epoch: 5| Step: 9
Training loss: 2.640581480491512
Validation loss: 2.539099052677241

Epoch: 5| Step: 10
Training loss: 3.0410897914145516
Validation loss: 2.5292018005744077

Epoch: 204| Step: 0
Training loss: 3.05581651979649
Validation loss: 2.5129287360252603

Epoch: 5| Step: 1
Training loss: 2.5288279684193355
Validation loss: 2.4985927240796655

Epoch: 5| Step: 2
Training loss: 2.8967829914974823
Validation loss: 2.5152444961255265

Epoch: 5| Step: 3
Training loss: 2.866640958744666
Validation loss: 2.5113925476096686

Epoch: 5| Step: 4
Training loss: 2.5804363640217653
Validation loss: 2.508535936119585

Epoch: 5| Step: 5
Training loss: 2.671057503547211
Validation loss: 2.5091342927912046

Epoch: 5| Step: 6
Training loss: 3.1060440394318523
Validation loss: 2.5050064389989743

Epoch: 5| Step: 7
Training loss: 3.1897150458896184
Validation loss: 2.505088341930025

Epoch: 5| Step: 8
Training loss: 3.0169777479707216
Validation loss: 2.5064444633961878

Epoch: 5| Step: 9
Training loss: 2.2553247387968764
Validation loss: 2.5028419912173816

Epoch: 5| Step: 10
Training loss: 2.841113870349443
Validation loss: 2.5079777482685355

Epoch: 205| Step: 0
Training loss: 2.457152152915176
Validation loss: 2.5181967353168293

Epoch: 5| Step: 1
Training loss: 2.6235763685722886
Validation loss: 2.5184511108371854

Epoch: 5| Step: 2
Training loss: 2.550861818872581
Validation loss: 2.5251412562420357

Epoch: 5| Step: 3
Training loss: 3.181107187719128
Validation loss: 2.544497043838963

Epoch: 5| Step: 4
Training loss: 3.0567665147298593
Validation loss: 2.5500439948706894

Epoch: 5| Step: 5
Training loss: 2.87642203282785
Validation loss: 2.5595620263305583

Epoch: 5| Step: 6
Training loss: 3.078508692030402
Validation loss: 2.547239388120171

Epoch: 5| Step: 7
Training loss: 2.784528022097671
Validation loss: 2.5341143012579224

Epoch: 5| Step: 8
Training loss: 2.7118988531206107
Validation loss: 2.5299936790246296

Epoch: 5| Step: 9
Training loss: 2.8325637632433547
Validation loss: 2.5153153843662293

Epoch: 5| Step: 10
Training loss: 2.9538106778273345
Validation loss: 2.516543453628246

Epoch: 206| Step: 0
Training loss: 3.334130684536799
Validation loss: 2.5129825545557063

Epoch: 5| Step: 1
Training loss: 2.9664583697398172
Validation loss: 2.520421810081191

Epoch: 5| Step: 2
Training loss: 2.4577365948401995
Validation loss: 2.5303054661707556

Epoch: 5| Step: 3
Training loss: 2.9834900187969025
Validation loss: 2.5272407435304056

Epoch: 5| Step: 4
Training loss: 2.793930635010381
Validation loss: 2.534169241434201

Epoch: 5| Step: 5
Training loss: 2.5902185873632875
Validation loss: 2.5550386643384506

Epoch: 5| Step: 6
Training loss: 2.9303438392404253
Validation loss: 2.5659387377163836

Epoch: 5| Step: 7
Training loss: 2.64335779838577
Validation loss: 2.5487982944680185

Epoch: 5| Step: 8
Training loss: 2.6554425078058013
Validation loss: 2.5460530810782362

Epoch: 5| Step: 9
Training loss: 3.0804793750213033
Validation loss: 2.559760185932937

Epoch: 5| Step: 10
Training loss: 2.535579416844595
Validation loss: 2.551937117331858

Epoch: 207| Step: 0
Training loss: 2.9932527961459825
Validation loss: 2.5170136607816116

Epoch: 5| Step: 1
Training loss: 3.224743346418216
Validation loss: 2.5069969603592335

Epoch: 5| Step: 2
Training loss: 3.194388183614312
Validation loss: 2.5072529772729557

Epoch: 5| Step: 3
Training loss: 3.027349892886913
Validation loss: 2.508120536574234

Epoch: 5| Step: 4
Training loss: 2.4698377699606744
Validation loss: 2.509776579179109

Epoch: 5| Step: 5
Training loss: 2.467565614548734
Validation loss: 2.5100465727334145

Epoch: 5| Step: 6
Training loss: 2.4444368884904235
Validation loss: 2.5019063961631702

Epoch: 5| Step: 7
Training loss: 3.0549989039142846
Validation loss: 2.5033209641732443

Epoch: 5| Step: 8
Training loss: 2.7812365413725892
Validation loss: 2.502701063129426

Epoch: 5| Step: 9
Training loss: 2.9352587001974735
Validation loss: 2.50373406111161

Epoch: 5| Step: 10
Training loss: 2.628586272085229
Validation loss: 2.5098788376689805

Epoch: 208| Step: 0
Training loss: 2.6933654829347438
Validation loss: 2.5189185177518447

Epoch: 5| Step: 1
Training loss: 2.32360995998786
Validation loss: 2.5278186031528906

Epoch: 5| Step: 2
Training loss: 3.1937474379557207
Validation loss: 2.5441574706388903

Epoch: 5| Step: 3
Training loss: 3.1269906379503443
Validation loss: 2.5448261583252147

Epoch: 5| Step: 4
Training loss: 3.399974116058557
Validation loss: 2.526023342183238

Epoch: 5| Step: 5
Training loss: 2.9554797275953444
Validation loss: 2.529283345719566

Epoch: 5| Step: 6
Training loss: 2.372415240334373
Validation loss: 2.523436174208532

Epoch: 5| Step: 7
Training loss: 2.7195301909583005
Validation loss: 2.508473856995492

Epoch: 5| Step: 8
Training loss: 2.8284067255979495
Validation loss: 2.50049517967554

Epoch: 5| Step: 9
Training loss: 2.6941491311475385
Validation loss: 2.4994483810896937

Epoch: 5| Step: 10
Training loss: 2.7042788650285474
Validation loss: 2.4993858618781895

Epoch: 209| Step: 0
Training loss: 2.8447027601561707
Validation loss: 2.5054045361514397

Epoch: 5| Step: 1
Training loss: 2.9216409681299433
Validation loss: 2.5041235919874723

Epoch: 5| Step: 2
Training loss: 2.7690505026155003
Validation loss: 2.518766716621947

Epoch: 5| Step: 3
Training loss: 2.2828107746386683
Validation loss: 2.535336975656676

Epoch: 5| Step: 4
Training loss: 3.342191386387774
Validation loss: 2.5325740104772283

Epoch: 5| Step: 5
Training loss: 2.6806012700409796
Validation loss: 2.5347970305775487

Epoch: 5| Step: 6
Training loss: 2.662574061406895
Validation loss: 2.5359616289883897

Epoch: 5| Step: 7
Training loss: 2.973564340088096
Validation loss: 2.5279830375391517

Epoch: 5| Step: 8
Training loss: 2.8834504039422333
Validation loss: 2.5270702982949653

Epoch: 5| Step: 9
Training loss: 2.6089656303133335
Validation loss: 2.5163553918070782

Epoch: 5| Step: 10
Training loss: 2.958675597544264
Validation loss: 2.5145088909108955

Epoch: 210| Step: 0
Training loss: 2.470960954926541
Validation loss: 2.51494956651031

Epoch: 5| Step: 1
Training loss: 3.028781160768176
Validation loss: 2.51308143249792

Epoch: 5| Step: 2
Training loss: 3.192082719768357
Validation loss: 2.5013850179990156

Epoch: 5| Step: 3
Training loss: 2.8780057370868946
Validation loss: 2.504492886875942

Epoch: 5| Step: 4
Training loss: 2.7066930254073998
Validation loss: 2.502243572427665

Epoch: 5| Step: 5
Training loss: 2.4910904433876846
Validation loss: 2.5102985796657062

Epoch: 5| Step: 6
Training loss: 2.5943214981859337
Validation loss: 2.5086849855605107

Epoch: 5| Step: 7
Training loss: 2.7576110593369827
Validation loss: 2.5098080451093354

Epoch: 5| Step: 8
Training loss: 3.0975087769317047
Validation loss: 2.5112958235065963

Epoch: 5| Step: 9
Training loss: 2.8475500853624087
Validation loss: 2.511799937009909

Epoch: 5| Step: 10
Training loss: 2.8498464777237102
Validation loss: 2.514056691707095

Epoch: 211| Step: 0
Training loss: 2.0782803355508146
Validation loss: 2.512210310539367

Epoch: 5| Step: 1
Training loss: 3.035436983025258
Validation loss: 2.5114432228926695

Epoch: 5| Step: 2
Training loss: 2.986510306789688
Validation loss: 2.502180799294761

Epoch: 5| Step: 3
Training loss: 2.888837601948176
Validation loss: 2.502223924808215

Epoch: 5| Step: 4
Training loss: 2.80255964312692
Validation loss: 2.4949976865794823

Epoch: 5| Step: 5
Training loss: 2.3912217137228593
Validation loss: 2.495399988888756

Epoch: 5| Step: 6
Training loss: 2.76095980692964
Validation loss: 2.49211350043507

Epoch: 5| Step: 7
Training loss: 2.8709087286259356
Validation loss: 2.495503689152164

Epoch: 5| Step: 8
Training loss: 2.8164096361370072
Validation loss: 2.500957704476582

Epoch: 5| Step: 9
Training loss: 2.876360695643095
Validation loss: 2.518539857649147

Epoch: 5| Step: 10
Training loss: 3.453371479334331
Validation loss: 2.518319059760018

Epoch: 212| Step: 0
Training loss: 2.415150912448562
Validation loss: 2.524732968280366

Epoch: 5| Step: 1
Training loss: 2.952986941062299
Validation loss: 2.5450717388705035

Epoch: 5| Step: 2
Training loss: 2.8407914418221862
Validation loss: 2.5222136676860036

Epoch: 5| Step: 3
Training loss: 2.597416595647297
Validation loss: 2.5263386362265092

Epoch: 5| Step: 4
Training loss: 2.8975219925843128
Validation loss: 2.5320279561450425

Epoch: 5| Step: 5
Training loss: 3.3996669606176475
Validation loss: 2.5480289891037384

Epoch: 5| Step: 6
Training loss: 2.7640426333130197
Validation loss: 2.533003113507652

Epoch: 5| Step: 7
Training loss: 3.2127530425044473
Validation loss: 2.5260488960171967

Epoch: 5| Step: 8
Training loss: 2.624206604720797
Validation loss: 2.5160329104961296

Epoch: 5| Step: 9
Training loss: 2.4044742720209737
Validation loss: 2.5148177770538043

Epoch: 5| Step: 10
Training loss: 2.7368918906154747
Validation loss: 2.530113792663572

Epoch: 213| Step: 0
Training loss: 2.6800251294851005
Validation loss: 2.5368307463147866

Epoch: 5| Step: 1
Training loss: 1.9417454751301981
Validation loss: 2.521882016947223

Epoch: 5| Step: 2
Training loss: 2.982297963464298
Validation loss: 2.5404783672191704

Epoch: 5| Step: 3
Training loss: 3.5796570808653385
Validation loss: 2.53320069818585

Epoch: 5| Step: 4
Training loss: 3.223173638628322
Validation loss: 2.5264399787984977

Epoch: 5| Step: 5
Training loss: 2.5399262352993084
Validation loss: 2.5194821812655372

Epoch: 5| Step: 6
Training loss: 2.6601937133122826
Validation loss: 2.5085515180001594

Epoch: 5| Step: 7
Training loss: 2.6352006625185647
Validation loss: 2.51301123716977

Epoch: 5| Step: 8
Training loss: 2.749831974791806
Validation loss: 2.49938805176429

Epoch: 5| Step: 9
Training loss: 2.9317969293879234
Validation loss: 2.504918808258562

Epoch: 5| Step: 10
Training loss: 2.798692081017375
Validation loss: 2.5000086271485813

Epoch: 214| Step: 0
Training loss: 2.580561093818444
Validation loss: 2.498638691510981

Epoch: 5| Step: 1
Training loss: 2.007282825470956
Validation loss: 2.5296884021885244

Epoch: 5| Step: 2
Training loss: 2.524674717563511
Validation loss: 2.541200818709126

Epoch: 5| Step: 3
Training loss: 3.1514941350418417
Validation loss: 2.5653347519935097

Epoch: 5| Step: 4
Training loss: 2.9060921574870293
Validation loss: 2.5565360272624775

Epoch: 5| Step: 5
Training loss: 3.3810076050242674
Validation loss: 2.545407702298363

Epoch: 5| Step: 6
Training loss: 3.1062244191641906
Validation loss: 2.5358831676597724

Epoch: 5| Step: 7
Training loss: 2.6249542232336673
Validation loss: 2.524838130135962

Epoch: 5| Step: 8
Training loss: 2.656284287175308
Validation loss: 2.5133507971601468

Epoch: 5| Step: 9
Training loss: 3.145733374887539
Validation loss: 2.512375920565953

Epoch: 5| Step: 10
Training loss: 2.70707149943585
Validation loss: 2.506356336729152

Epoch: 215| Step: 0
Training loss: 3.388334704947831
Validation loss: 2.5109946677734745

Epoch: 5| Step: 1
Training loss: 3.127563798163752
Validation loss: 2.5089173858915568

Epoch: 5| Step: 2
Training loss: 2.9157747448964697
Validation loss: 2.512017413489496

Epoch: 5| Step: 3
Training loss: 2.370771156751648
Validation loss: 2.519199979842027

Epoch: 5| Step: 4
Training loss: 2.9141122440459353
Validation loss: 2.5406961667671712

Epoch: 5| Step: 5
Training loss: 2.520356650772808
Validation loss: 2.5455923257152917

Epoch: 5| Step: 6
Training loss: 3.0105731927818464
Validation loss: 2.5484517315980186

Epoch: 5| Step: 7
Training loss: 2.8864724514874207
Validation loss: 2.566718835730663

Epoch: 5| Step: 8
Training loss: 2.468353046421801
Validation loss: 2.5694823939536247

Epoch: 5| Step: 9
Training loss: 2.400109419712572
Validation loss: 2.5481765670524745

Epoch: 5| Step: 10
Training loss: 2.815865516339447
Validation loss: 2.547640182930936

Epoch: 216| Step: 0
Training loss: 2.7962678218268504
Validation loss: 2.5135039861254875

Epoch: 5| Step: 1
Training loss: 2.795104334731516
Validation loss: 2.5082184829013157

Epoch: 5| Step: 2
Training loss: 3.25368437634538
Validation loss: 2.496238752427858

Epoch: 5| Step: 3
Training loss: 2.9862053336327525
Validation loss: 2.492562603342398

Epoch: 5| Step: 4
Training loss: 2.682512312520435
Validation loss: 2.495780246634387

Epoch: 5| Step: 5
Training loss: 2.470574392953129
Validation loss: 2.4900442180701288

Epoch: 5| Step: 6
Training loss: 2.648049115085625
Validation loss: 2.4866680445237423

Epoch: 5| Step: 7
Training loss: 2.8712827451613214
Validation loss: 2.4925027141905356

Epoch: 5| Step: 8
Training loss: 3.1636637118481854
Validation loss: 2.4901811319056426

Epoch: 5| Step: 9
Training loss: 2.5218697511223644
Validation loss: 2.5111919841964756

Epoch: 5| Step: 10
Training loss: 2.699673957918797
Validation loss: 2.515161966817493

Epoch: 217| Step: 0
Training loss: 3.3645724521772014
Validation loss: 2.5274449559095995

Epoch: 5| Step: 1
Training loss: 2.942427216102058
Validation loss: 2.522863592719847

Epoch: 5| Step: 2
Training loss: 2.7089512829179223
Validation loss: 2.5131002495316657

Epoch: 5| Step: 3
Training loss: 3.308114369510627
Validation loss: 2.51690610431013

Epoch: 5| Step: 4
Training loss: 2.5820154602214354
Validation loss: 2.524935599551274

Epoch: 5| Step: 5
Training loss: 2.8833407613258015
Validation loss: 2.5326749091992133

Epoch: 5| Step: 6
Training loss: 2.3332105558881544
Validation loss: 2.5225325843606345

Epoch: 5| Step: 7
Training loss: 2.8109956744855227
Validation loss: 2.529873478615129

Epoch: 5| Step: 8
Training loss: 2.8162575099149048
Validation loss: 2.502941507385803

Epoch: 5| Step: 9
Training loss: 2.150603710846319
Validation loss: 2.504154391846732

Epoch: 5| Step: 10
Training loss: 2.7926065276752303
Validation loss: 2.519723936577724

Epoch: 218| Step: 0
Training loss: 2.6597089797559863
Validation loss: 2.5155956470670224

Epoch: 5| Step: 1
Training loss: 2.8662936197081907
Validation loss: 2.5167558202644273

Epoch: 5| Step: 2
Training loss: 2.640345722305069
Validation loss: 2.5071763640079867

Epoch: 5| Step: 3
Training loss: 2.4262840253673783
Validation loss: 2.500270532511434

Epoch: 5| Step: 4
Training loss: 3.2234175828918428
Validation loss: 2.514762259150518

Epoch: 5| Step: 5
Training loss: 2.602908224579948
Validation loss: 2.52477939547267

Epoch: 5| Step: 6
Training loss: 3.1307530661731433
Validation loss: 2.5385065537514007

Epoch: 5| Step: 7
Training loss: 2.6273409986070377
Validation loss: 2.548757965664947

Epoch: 5| Step: 8
Training loss: 2.9973964519925422
Validation loss: 2.55382610699676

Epoch: 5| Step: 9
Training loss: 2.8327019679897716
Validation loss: 2.535763912668952

Epoch: 5| Step: 10
Training loss: 2.7771538563554805
Validation loss: 2.518718277283018

Epoch: 219| Step: 0
Training loss: 2.877722570592645
Validation loss: 2.5193479821873366

Epoch: 5| Step: 1
Training loss: 3.104189435290781
Validation loss: 2.5157248359303046

Epoch: 5| Step: 2
Training loss: 2.7180149356243613
Validation loss: 2.5083077082702943

Epoch: 5| Step: 3
Training loss: 2.7185853930222703
Validation loss: 2.5105673254125627

Epoch: 5| Step: 4
Training loss: 2.68503075651316
Validation loss: 2.5117569616222397

Epoch: 5| Step: 5
Training loss: 3.0248348348625984
Validation loss: 2.5026278456520528

Epoch: 5| Step: 6
Training loss: 2.4868057163861885
Validation loss: 2.506709857746718

Epoch: 5| Step: 7
Training loss: 2.6929165570873264
Validation loss: 2.5038461560705807

Epoch: 5| Step: 8
Training loss: 2.5296227204744732
Validation loss: 2.502751754600807

Epoch: 5| Step: 9
Training loss: 3.0324346056347484
Validation loss: 2.520235267488608

Epoch: 5| Step: 10
Training loss: 2.925267825132407
Validation loss: 2.5183483443024524

Epoch: 220| Step: 0
Training loss: 2.7195585079081845
Validation loss: 2.5264287711411373

Epoch: 5| Step: 1
Training loss: 2.859121509426289
Validation loss: 2.533645686227108

Epoch: 5| Step: 2
Training loss: 2.9120974217456723
Validation loss: 2.564374906596354

Epoch: 5| Step: 3
Training loss: 2.757354784796603
Validation loss: 2.5517648812548948

Epoch: 5| Step: 4
Training loss: 2.4624204012790947
Validation loss: 2.5613577573183286

Epoch: 5| Step: 5
Training loss: 2.8000703598446535
Validation loss: 2.548524992603632

Epoch: 5| Step: 6
Training loss: 2.5222095064392565
Validation loss: 2.5488432382787676

Epoch: 5| Step: 7
Training loss: 3.1357935851050898
Validation loss: 2.54783021694712

Epoch: 5| Step: 8
Training loss: 2.40698330096929
Validation loss: 2.5254024158953072

Epoch: 5| Step: 9
Training loss: 3.2364629373230165
Validation loss: 2.520095842065355

Epoch: 5| Step: 10
Training loss: 2.902105678482365
Validation loss: 2.5212128435836507

Epoch: 221| Step: 0
Training loss: 2.7681436223437035
Validation loss: 2.510786102266075

Epoch: 5| Step: 1
Training loss: 2.9664168977784935
Validation loss: 2.5226636171261156

Epoch: 5| Step: 2
Training loss: 2.7605238599777304
Validation loss: 2.518543419305006

Epoch: 5| Step: 3
Training loss: 2.9047293017223104
Validation loss: 2.5108853291037065

Epoch: 5| Step: 4
Training loss: 2.563010560322415
Validation loss: 2.520934187735123

Epoch: 5| Step: 5
Training loss: 2.9186818018916276
Validation loss: 2.5170451207765723

Epoch: 5| Step: 6
Training loss: 2.8657826820179855
Validation loss: 2.5267381481557702

Epoch: 5| Step: 7
Training loss: 3.2014550298522866
Validation loss: 2.5246109261760847

Epoch: 5| Step: 8
Training loss: 2.743301382732394
Validation loss: 2.5240828857334807

Epoch: 5| Step: 9
Training loss: 2.3056050171455365
Validation loss: 2.5372625516576814

Epoch: 5| Step: 10
Training loss: 2.630498032935139
Validation loss: 2.529837257267444

Epoch: 222| Step: 0
Training loss: 2.6150204925025915
Validation loss: 2.526317294608579

Epoch: 5| Step: 1
Training loss: 2.638302204657724
Validation loss: 2.5135039718462306

Epoch: 5| Step: 2
Training loss: 3.0978283443486347
Validation loss: 2.5163954269249222

Epoch: 5| Step: 3
Training loss: 2.555730857457271
Validation loss: 2.503986389035689

Epoch: 5| Step: 4
Training loss: 2.679108048228371
Validation loss: 2.508861949961657

Epoch: 5| Step: 5
Training loss: 2.8231341757972546
Validation loss: 2.5016667470454927

Epoch: 5| Step: 6
Training loss: 3.291542260116719
Validation loss: 2.5098059031301045

Epoch: 5| Step: 7
Training loss: 2.4042107003431057
Validation loss: 2.5157912422392807

Epoch: 5| Step: 8
Training loss: 3.103987123216878
Validation loss: 2.5450466913243934

Epoch: 5| Step: 9
Training loss: 3.0608326012326375
Validation loss: 2.557800008531683

Epoch: 5| Step: 10
Training loss: 2.1637425375489636
Validation loss: 2.5762788090692195

Epoch: 223| Step: 0
Training loss: 2.5558716249121365
Validation loss: 2.5828403233356942

Epoch: 5| Step: 1
Training loss: 2.5162915596559556
Validation loss: 2.5624651042364004

Epoch: 5| Step: 2
Training loss: 2.918157487150413
Validation loss: 2.5318022023980977

Epoch: 5| Step: 3
Training loss: 3.0974328825223894
Validation loss: 2.5114135709888883

Epoch: 5| Step: 4
Training loss: 2.6920856122238166
Validation loss: 2.506988874693589

Epoch: 5| Step: 5
Training loss: 3.075411767449633
Validation loss: 2.5225420470781166

Epoch: 5| Step: 6
Training loss: 3.21548370258494
Validation loss: 2.519148568105156

Epoch: 5| Step: 7
Training loss: 2.952833534672059
Validation loss: 2.516506421027059

Epoch: 5| Step: 8
Training loss: 2.7223802204948164
Validation loss: 2.535357374790446

Epoch: 5| Step: 9
Training loss: 2.9258791979703678
Validation loss: 2.5556729641814506

Epoch: 5| Step: 10
Training loss: 2.2987319809506634
Validation loss: 2.5593751131482647

Epoch: 224| Step: 0
Training loss: 2.857423543766601
Validation loss: 2.5500601575408095

Epoch: 5| Step: 1
Training loss: 3.0415626577770976
Validation loss: 2.5830640272062992

Epoch: 5| Step: 2
Training loss: 2.57441750021108
Validation loss: 2.5851038152874235

Epoch: 5| Step: 3
Training loss: 2.6066953868535827
Validation loss: 2.56812877707669

Epoch: 5| Step: 4
Training loss: 2.8144939559950237
Validation loss: 2.5294470382612784

Epoch: 5| Step: 5
Training loss: 2.939260726157686
Validation loss: 2.5320181826072914

Epoch: 5| Step: 6
Training loss: 3.2486689849768005
Validation loss: 2.5062899489409443

Epoch: 5| Step: 7
Training loss: 2.121400926803425
Validation loss: 2.505697556710682

Epoch: 5| Step: 8
Training loss: 3.3484579437244113
Validation loss: 2.4883076313562573

Epoch: 5| Step: 9
Training loss: 2.675147478548131
Validation loss: 2.4955474272590883

Epoch: 5| Step: 10
Training loss: 2.606995005437107
Validation loss: 2.495939294755433

Epoch: 225| Step: 0
Training loss: 2.595363436847281
Validation loss: 2.492804913030766

Epoch: 5| Step: 1
Training loss: 2.8013333211454268
Validation loss: 2.500813991560145

Epoch: 5| Step: 2
Training loss: 2.797459546598656
Validation loss: 2.514100422134034

Epoch: 5| Step: 3
Training loss: 3.18358835793255
Validation loss: 2.5299708888091015

Epoch: 5| Step: 4
Training loss: 2.3170069515501015
Validation loss: 2.5447213812282867

Epoch: 5| Step: 5
Training loss: 3.0880275939637496
Validation loss: 2.564160507038889

Epoch: 5| Step: 6
Training loss: 2.6077892487565353
Validation loss: 2.61761844853935

Epoch: 5| Step: 7
Training loss: 2.6815486928319627
Validation loss: 2.6021358212150036

Epoch: 5| Step: 8
Training loss: 3.4305550905159565
Validation loss: 2.5697937415807477

Epoch: 5| Step: 9
Training loss: 2.5833648146485166
Validation loss: 2.52493257589935

Epoch: 5| Step: 10
Training loss: 2.6392479189414395
Validation loss: 2.4932974252829028

Epoch: 226| Step: 0
Training loss: 2.3367680632739023
Validation loss: 2.4875079194572183

Epoch: 5| Step: 1
Training loss: 3.171963093854406
Validation loss: 2.484725526008886

Epoch: 5| Step: 2
Training loss: 3.0325135419249176
Validation loss: 2.4925657012308067

Epoch: 5| Step: 3
Training loss: 3.2187353337518565
Validation loss: 2.486278735056296

Epoch: 5| Step: 4
Training loss: 2.861269630641432
Validation loss: 2.4934327868681283

Epoch: 5| Step: 5
Training loss: 2.493643404181034
Validation loss: 2.4866374507723914

Epoch: 5| Step: 6
Training loss: 3.0299626399088098
Validation loss: 2.4953130985119336

Epoch: 5| Step: 7
Training loss: 2.3321888932662618
Validation loss: 2.503642756909776

Epoch: 5| Step: 8
Training loss: 2.856963094097072
Validation loss: 2.5162457450757083

Epoch: 5| Step: 9
Training loss: 2.452150090383005
Validation loss: 2.5426083899136236

Epoch: 5| Step: 10
Training loss: 3.1270007023238713
Validation loss: 2.553328072969196

Epoch: 227| Step: 0
Training loss: 2.65085187930883
Validation loss: 2.5625421303988123

Epoch: 5| Step: 1
Training loss: 2.4795525728665013
Validation loss: 2.5874900775671814

Epoch: 5| Step: 2
Training loss: 2.6096220527694776
Validation loss: 2.56394224400844

Epoch: 5| Step: 3
Training loss: 2.219486920116475
Validation loss: 2.5511502463536715

Epoch: 5| Step: 4
Training loss: 2.899001567891471
Validation loss: 2.5472383162625887

Epoch: 5| Step: 5
Training loss: 2.7241687486729487
Validation loss: 2.5316852766037514

Epoch: 5| Step: 6
Training loss: 3.3931265186271986
Validation loss: 2.5380288104133903

Epoch: 5| Step: 7
Training loss: 3.216566067112429
Validation loss: 2.5339837381933252

Epoch: 5| Step: 8
Training loss: 2.9350327214719156
Validation loss: 2.507065948729986

Epoch: 5| Step: 9
Training loss: 2.3057157647210347
Validation loss: 2.507903011460879

Epoch: 5| Step: 10
Training loss: 2.9018534558112865
Validation loss: 2.506658874044478

Epoch: 228| Step: 0
Training loss: 3.079307677499129
Validation loss: 2.507864732939174

Epoch: 5| Step: 1
Training loss: 2.732315944884203
Validation loss: 2.520750125931126

Epoch: 5| Step: 2
Training loss: 2.716568959903266
Validation loss: 2.5331932750347246

Epoch: 5| Step: 3
Training loss: 2.8335828858223286
Validation loss: 2.5328848919410687

Epoch: 5| Step: 4
Training loss: 2.7539259023844442
Validation loss: 2.5650040501995917

Epoch: 5| Step: 5
Training loss: 3.00824320297976
Validation loss: 2.5445339179253357

Epoch: 5| Step: 6
Training loss: 2.4800714610171437
Validation loss: 2.5255263991814556

Epoch: 5| Step: 7
Training loss: 2.92831738795667
Validation loss: 2.5146564959882687

Epoch: 5| Step: 8
Training loss: 2.5896517076823384
Validation loss: 2.5009677972321374

Epoch: 5| Step: 9
Training loss: 3.086142231391076
Validation loss: 2.4918895235597787

Epoch: 5| Step: 10
Training loss: 2.3759299013798265
Validation loss: 2.4953280458529776

Epoch: 229| Step: 0
Training loss: 3.084305034489353
Validation loss: 2.500810356473197

Epoch: 5| Step: 1
Training loss: 2.598274145995808
Validation loss: 2.492918299494418

Epoch: 5| Step: 2
Training loss: 2.7286652160138636
Validation loss: 2.4882974460387857

Epoch: 5| Step: 3
Training loss: 2.5506907705526403
Validation loss: 2.5009729296994583

Epoch: 5| Step: 4
Training loss: 2.6049457351099337
Validation loss: 2.5051616154132663

Epoch: 5| Step: 5
Training loss: 2.4476317111336763
Validation loss: 2.509354142659246

Epoch: 5| Step: 6
Training loss: 2.48287419505976
Validation loss: 2.5190464029905173

Epoch: 5| Step: 7
Training loss: 2.943863813463809
Validation loss: 2.53092660867505

Epoch: 5| Step: 8
Training loss: 3.015874822674993
Validation loss: 2.541639978102939

Epoch: 5| Step: 9
Training loss: 3.0830260630596964
Validation loss: 2.5412583859549547

Epoch: 5| Step: 10
Training loss: 2.916563213875157
Validation loss: 2.5889050813397074

Epoch: 230| Step: 0
Training loss: 2.8422065990072625
Validation loss: 2.623723926546056

Epoch: 5| Step: 1
Training loss: 2.214196273649793
Validation loss: 2.6090768141790357

Epoch: 5| Step: 2
Training loss: 3.0585522801107876
Validation loss: 2.5989553290530254

Epoch: 5| Step: 3
Training loss: 2.7274057565380914
Validation loss: 2.559382904099427

Epoch: 5| Step: 4
Training loss: 3.0891132479846886
Validation loss: 2.5320392098921705

Epoch: 5| Step: 5
Training loss: 2.312104577976154
Validation loss: 2.491366267275521

Epoch: 5| Step: 6
Training loss: 3.07722157809379
Validation loss: 2.486272575164441

Epoch: 5| Step: 7
Training loss: 2.3019857831858976
Validation loss: 2.4938064939708076

Epoch: 5| Step: 8
Training loss: 3.165322436741641
Validation loss: 2.490538979836897

Epoch: 5| Step: 9
Training loss: 3.041029893943322
Validation loss: 2.486731293784833

Epoch: 5| Step: 10
Training loss: 2.782768777785477
Validation loss: 2.5015940542261967

Epoch: 231| Step: 0
Training loss: 2.895370300012476
Validation loss: 2.5016727511835244

Epoch: 5| Step: 1
Training loss: 2.635732418238657
Validation loss: 2.506995882033382

Epoch: 5| Step: 2
Training loss: 2.6731436768067307
Validation loss: 2.4961062498150537

Epoch: 5| Step: 3
Training loss: 3.184494696137295
Validation loss: 2.4983953453400263

Epoch: 5| Step: 4
Training loss: 3.200588803957266
Validation loss: 2.510791766029529

Epoch: 5| Step: 5
Training loss: 2.3463395118608545
Validation loss: 2.506919574346224

Epoch: 5| Step: 6
Training loss: 2.6360372383138566
Validation loss: 2.508187029737062

Epoch: 5| Step: 7
Training loss: 2.361285819028846
Validation loss: 2.519367894133629

Epoch: 5| Step: 8
Training loss: 2.80685349667895
Validation loss: 2.5240608059405196

Epoch: 5| Step: 9
Training loss: 2.9172246308458942
Validation loss: 2.5108447058247747

Epoch: 5| Step: 10
Training loss: 2.94279295312977
Validation loss: 2.5314949086302034

Epoch: 232| Step: 0
Training loss: 2.6274150456451526
Validation loss: 2.5427059958196407

Epoch: 5| Step: 1
Training loss: 2.8914242850820604
Validation loss: 2.521783816499403

Epoch: 5| Step: 2
Training loss: 2.955713500038785
Validation loss: 2.513626936698971

Epoch: 5| Step: 3
Training loss: 3.110421622788266
Validation loss: 2.511925079526861

Epoch: 5| Step: 4
Training loss: 2.641281046434412
Validation loss: 2.5087528974588484

Epoch: 5| Step: 5
Training loss: 2.562137019803166
Validation loss: 2.5099700079691876

Epoch: 5| Step: 6
Training loss: 3.0255625745499115
Validation loss: 2.495076492440384

Epoch: 5| Step: 7
Training loss: 2.96249244141721
Validation loss: 2.493564128422762

Epoch: 5| Step: 8
Training loss: 2.816643946930335
Validation loss: 2.498436007889519

Epoch: 5| Step: 9
Training loss: 2.2504351513004637
Validation loss: 2.506290491580159

Epoch: 5| Step: 10
Training loss: 2.709661529772033
Validation loss: 2.5124488937607694

Epoch: 233| Step: 0
Training loss: 2.8434592297473427
Validation loss: 2.5250258094242604

Epoch: 5| Step: 1
Training loss: 2.959718156232288
Validation loss: 2.5409218184083127

Epoch: 5| Step: 2
Training loss: 2.896073109604928
Validation loss: 2.5642273506124895

Epoch: 5| Step: 3
Training loss: 2.8189234813414936
Validation loss: 2.570308901362913

Epoch: 5| Step: 4
Training loss: 2.4011242259982173
Validation loss: 2.5568362336460466

Epoch: 5| Step: 5
Training loss: 2.591114865729809
Validation loss: 2.537544097105024

Epoch: 5| Step: 6
Training loss: 2.7490695766554327
Validation loss: 2.521586274602122

Epoch: 5| Step: 7
Training loss: 3.050070627364091
Validation loss: 2.5000737620311098

Epoch: 5| Step: 8
Training loss: 2.915521415023385
Validation loss: 2.4940830505156715

Epoch: 5| Step: 9
Training loss: 2.5277342693604137
Validation loss: 2.496312778616471

Epoch: 5| Step: 10
Training loss: 2.867823558801431
Validation loss: 2.4976948785928346

Epoch: 234| Step: 0
Training loss: 2.5358503946045237
Validation loss: 2.5129217712440384

Epoch: 5| Step: 1
Training loss: 2.955842881668997
Validation loss: 2.522805724621845

Epoch: 5| Step: 2
Training loss: 2.9595372253231975
Validation loss: 2.545185309970163

Epoch: 5| Step: 3
Training loss: 2.6677745564106026
Validation loss: 2.559237310160635

Epoch: 5| Step: 4
Training loss: 2.893201185217601
Validation loss: 2.5656339827912085

Epoch: 5| Step: 5
Training loss: 2.7310535421357462
Validation loss: 2.558884825498528

Epoch: 5| Step: 6
Training loss: 2.787489332512257
Validation loss: 2.564405529642485

Epoch: 5| Step: 7
Training loss: 2.6236609722152067
Validation loss: 2.5700976366768984

Epoch: 5| Step: 8
Training loss: 2.513771464191232
Validation loss: 2.54194900548946

Epoch: 5| Step: 9
Training loss: 2.7530406267831404
Validation loss: 2.52821969223899

Epoch: 5| Step: 10
Training loss: 3.0834986839978233
Validation loss: 2.5061472164273617

Epoch: 235| Step: 0
Training loss: 2.8152250863265142
Validation loss: 2.511303613553139

Epoch: 5| Step: 1
Training loss: 3.131054620491157
Validation loss: 2.4997246847015573

Epoch: 5| Step: 2
Training loss: 3.0034138011701903
Validation loss: 2.5013211625334377

Epoch: 5| Step: 3
Training loss: 2.2669776824673806
Validation loss: 2.5083741555901757

Epoch: 5| Step: 4
Training loss: 2.480292751045709
Validation loss: 2.506894038227311

Epoch: 5| Step: 5
Training loss: 2.777881425407328
Validation loss: 2.5017873670977204

Epoch: 5| Step: 6
Training loss: 2.5237484200082023
Validation loss: 2.5130209469092524

Epoch: 5| Step: 7
Training loss: 2.8340069213222714
Validation loss: 2.5179702632993517

Epoch: 5| Step: 8
Training loss: 2.750516149459941
Validation loss: 2.524157643173383

Epoch: 5| Step: 9
Training loss: 2.7538016657889424
Validation loss: 2.5401675279693148

Epoch: 5| Step: 10
Training loss: 2.975849857275544
Validation loss: 2.5260102733864027

Epoch: 236| Step: 0
Training loss: 2.428627788867436
Validation loss: 2.52876993571396

Epoch: 5| Step: 1
Training loss: 2.5287742280954397
Validation loss: 2.5197929249617967

Epoch: 5| Step: 2
Training loss: 2.9012427725449212
Validation loss: 2.5238626809498386

Epoch: 5| Step: 3
Training loss: 2.831599509116587
Validation loss: 2.524988428603277

Epoch: 5| Step: 4
Training loss: 2.600400006261713
Validation loss: 2.5307282345940827

Epoch: 5| Step: 5
Training loss: 3.0329803561848894
Validation loss: 2.532011489033462

Epoch: 5| Step: 6
Training loss: 3.053931725708767
Validation loss: 2.519366707643283

Epoch: 5| Step: 7
Training loss: 2.656382389135335
Validation loss: 2.522001847034474

Epoch: 5| Step: 8
Training loss: 2.6052927761331044
Validation loss: 2.5269638419852374

Epoch: 5| Step: 9
Training loss: 3.367078739542818
Validation loss: 2.51573785013973

Epoch: 5| Step: 10
Training loss: 1.876936548261054
Validation loss: 2.5292276365130015

Epoch: 237| Step: 0
Training loss: 2.870202083052445
Validation loss: 2.529631454352722

Epoch: 5| Step: 1
Training loss: 2.4473164789833013
Validation loss: 2.5288885899051756

Epoch: 5| Step: 2
Training loss: 2.7609492717809316
Validation loss: 2.5445526827098965

Epoch: 5| Step: 3
Training loss: 2.6477294695633353
Validation loss: 2.557494883220377

Epoch: 5| Step: 4
Training loss: 2.490486545136582
Validation loss: 2.5301999307147915

Epoch: 5| Step: 5
Training loss: 3.0128059453450766
Validation loss: 2.5409219011414876

Epoch: 5| Step: 6
Training loss: 2.6657192414809656
Validation loss: 2.522266527322571

Epoch: 5| Step: 7
Training loss: 3.1858471343586117
Validation loss: 2.5290542593237153

Epoch: 5| Step: 8
Training loss: 2.554102652796663
Validation loss: 2.5250294974728233

Epoch: 5| Step: 9
Training loss: 2.5217699144820713
Validation loss: 2.5218890372905487

Epoch: 5| Step: 10
Training loss: 3.079837071208942
Validation loss: 2.5178660888509623

Epoch: 238| Step: 0
Training loss: 3.019742694276489
Validation loss: 2.5129591581306396

Epoch: 5| Step: 1
Training loss: 2.464454196912164
Validation loss: 2.5062905795480512

Epoch: 5| Step: 2
Training loss: 2.8183744328361606
Validation loss: 2.5123185394833802

Epoch: 5| Step: 3
Training loss: 2.8592357497364222
Validation loss: 2.520647689084076

Epoch: 5| Step: 4
Training loss: 2.2644866188076787
Validation loss: 2.5204619504688077

Epoch: 5| Step: 5
Training loss: 2.518109628758746
Validation loss: 2.522499602788015

Epoch: 5| Step: 6
Training loss: 2.674986070971009
Validation loss: 2.52955639552574

Epoch: 5| Step: 7
Training loss: 2.8391585959933843
Validation loss: 2.5416157349382615

Epoch: 5| Step: 8
Training loss: 2.4865992923367073
Validation loss: 2.54373259546355

Epoch: 5| Step: 9
Training loss: 2.8604932589092282
Validation loss: 2.5410436602675874

Epoch: 5| Step: 10
Training loss: 3.3153209550469085
Validation loss: 2.556379510730908

Epoch: 239| Step: 0
Training loss: 2.80815314177984
Validation loss: 2.565947686678723

Epoch: 5| Step: 1
Training loss: 3.1028250711635694
Validation loss: 2.546156508543836

Epoch: 5| Step: 2
Training loss: 2.3426053112870324
Validation loss: 2.5253476626332505

Epoch: 5| Step: 3
Training loss: 2.182478345171455
Validation loss: 2.502701942021161

Epoch: 5| Step: 4
Training loss: 3.225106490395263
Validation loss: 2.498847860526437

Epoch: 5| Step: 5
Training loss: 2.7538679837212854
Validation loss: 2.5007071258966995

Epoch: 5| Step: 6
Training loss: 2.8390252404295206
Validation loss: 2.492202136914551

Epoch: 5| Step: 7
Training loss: 2.4805026795477176
Validation loss: 2.4951615899466946

Epoch: 5| Step: 8
Training loss: 2.6468718185315607
Validation loss: 2.5123497194933715

Epoch: 5| Step: 9
Training loss: 3.332372542832087
Validation loss: 2.5205253769588998

Epoch: 5| Step: 10
Training loss: 2.707085943288799
Validation loss: 2.546588607057346

Epoch: 240| Step: 0
Training loss: 2.3933773776635436
Validation loss: 2.5830591615661445

Epoch: 5| Step: 1
Training loss: 2.8951021730514497
Validation loss: 2.575824095379414

Epoch: 5| Step: 2
Training loss: 2.7296391920106933
Validation loss: 2.573116413473664

Epoch: 5| Step: 3
Training loss: 2.5979409427523192
Validation loss: 2.534511905773414

Epoch: 5| Step: 4
Training loss: 2.404678921749289
Validation loss: 2.5356823995086684

Epoch: 5| Step: 5
Training loss: 2.811346198878959
Validation loss: 2.519778108502885

Epoch: 5| Step: 6
Training loss: 2.7459495365482023
Validation loss: 2.5076334495850943

Epoch: 5| Step: 7
Training loss: 2.9872470636911252
Validation loss: 2.505903997343591

Epoch: 5| Step: 8
Training loss: 3.3855355735828736
Validation loss: 2.512500428814138

Epoch: 5| Step: 9
Training loss: 2.5824742478215774
Validation loss: 2.5200245755757327

Epoch: 5| Step: 10
Training loss: 2.601827705314495
Validation loss: 2.5347720332094688

Epoch: 241| Step: 0
Training loss: 2.556521722580053
Validation loss: 2.544778075999651

Epoch: 5| Step: 1
Training loss: 2.9082154221847967
Validation loss: 2.5685237910968386

Epoch: 5| Step: 2
Training loss: 2.8835443327624333
Validation loss: 2.577513037498886

Epoch: 5| Step: 3
Training loss: 2.257058621640341
Validation loss: 2.5713861849029724

Epoch: 5| Step: 4
Training loss: 2.932232943681443
Validation loss: 2.557109710921388

Epoch: 5| Step: 5
Training loss: 2.8306943908258497
Validation loss: 2.557249454111216

Epoch: 5| Step: 6
Training loss: 2.8269757206524946
Validation loss: 2.547765067330258

Epoch: 5| Step: 7
Training loss: 2.688372625578977
Validation loss: 2.564693435575732

Epoch: 5| Step: 8
Training loss: 2.348076552662171
Validation loss: 2.5589515433987557

Epoch: 5| Step: 9
Training loss: 2.434341536207437
Validation loss: 2.5620682975753937

Epoch: 5| Step: 10
Training loss: 3.3090304071914742
Validation loss: 2.5477646608128315

Epoch: 242| Step: 0
Training loss: 2.9605698168497723
Validation loss: 2.539513653602449

Epoch: 5| Step: 1
Training loss: 2.6829743538113124
Validation loss: 2.527528160310547

Epoch: 5| Step: 2
Training loss: 3.1851028703638136
Validation loss: 2.5093677998207338

Epoch: 5| Step: 3
Training loss: 2.7004852635914367
Validation loss: 2.5046251254442993

Epoch: 5| Step: 4
Training loss: 2.10815122921118
Validation loss: 2.5056310742198606

Epoch: 5| Step: 5
Training loss: 2.7952478033503594
Validation loss: 2.517878748867976

Epoch: 5| Step: 6
Training loss: 2.6930161576266185
Validation loss: 2.5288057982663967

Epoch: 5| Step: 7
Training loss: 2.4483471647442747
Validation loss: 2.5309287672188203

Epoch: 5| Step: 8
Training loss: 2.649471205008315
Validation loss: 2.5426045816677414

Epoch: 5| Step: 9
Training loss: 2.9077718708329954
Validation loss: 2.546214777276625

Epoch: 5| Step: 10
Training loss: 2.8034778419681676
Validation loss: 2.5416786113547776

Epoch: 243| Step: 0
Training loss: 2.689888801828959
Validation loss: 2.5797796493835636

Epoch: 5| Step: 1
Training loss: 3.1569693472687894
Validation loss: 2.5721034803839187

Epoch: 5| Step: 2
Training loss: 2.8566084021283618
Validation loss: 2.576892489312304

Epoch: 5| Step: 3
Training loss: 2.7910015300717834
Validation loss: 2.564166013916254

Epoch: 5| Step: 4
Training loss: 3.1423429279023773
Validation loss: 2.551987559112155

Epoch: 5| Step: 5
Training loss: 2.738705154671611
Validation loss: 2.563834610411892

Epoch: 5| Step: 6
Training loss: 2.261019636559028
Validation loss: 2.570078889327005

Epoch: 5| Step: 7
Training loss: 2.363187324612096
Validation loss: 2.568779335605966

Epoch: 5| Step: 8
Training loss: 2.9164960175501253
Validation loss: 2.57020609570858

Epoch: 5| Step: 9
Training loss: 2.970710669112298
Validation loss: 2.571974750353155

Epoch: 5| Step: 10
Training loss: 2.1252445753383027
Validation loss: 2.5451079468757105

Epoch: 244| Step: 0
Training loss: 3.184646525987366
Validation loss: 2.5325930096418743

Epoch: 5| Step: 1
Training loss: 2.9690424724867404
Validation loss: 2.5356140102654945

Epoch: 5| Step: 2
Training loss: 3.2315475710531465
Validation loss: 2.524850120591912

Epoch: 5| Step: 3
Training loss: 2.719167216943219
Validation loss: 2.5296254598224515

Epoch: 5| Step: 4
Training loss: 2.7603321182450378
Validation loss: 2.5211984167820836

Epoch: 5| Step: 5
Training loss: 2.45843533665305
Validation loss: 2.5202691153481345

Epoch: 5| Step: 6
Training loss: 2.9118450820083495
Validation loss: 2.523293887844796

Epoch: 5| Step: 7
Training loss: 1.8192274928470575
Validation loss: 2.5242899321616292

Epoch: 5| Step: 8
Training loss: 2.8894769811734866
Validation loss: 2.5524828717159838

Epoch: 5| Step: 9
Training loss: 2.5355597646594554
Validation loss: 2.590647902589657

Epoch: 5| Step: 10
Training loss: 2.665115461585855
Validation loss: 2.6244956009015272

Epoch: 245| Step: 0
Training loss: 2.456521374026158
Validation loss: 2.602327499836155

Epoch: 5| Step: 1
Training loss: 2.3524681197792323
Validation loss: 2.576366223644637

Epoch: 5| Step: 2
Training loss: 2.7023841857090583
Validation loss: 2.5771575574309353

Epoch: 5| Step: 3
Training loss: 2.373925518117632
Validation loss: 2.552264765170346

Epoch: 5| Step: 4
Training loss: 2.7328666668557093
Validation loss: 2.539025058770031

Epoch: 5| Step: 5
Training loss: 2.80335495089596
Validation loss: 2.5319462239893644

Epoch: 5| Step: 6
Training loss: 2.6665697576874914
Validation loss: 2.5335044265779283

Epoch: 5| Step: 7
Training loss: 2.906541871212057
Validation loss: 2.5265085093200366

Epoch: 5| Step: 8
Training loss: 3.3680025251655445
Validation loss: 2.5296796168222153

Epoch: 5| Step: 9
Training loss: 2.9892992866079084
Validation loss: 2.5216974905942164

Epoch: 5| Step: 10
Training loss: 2.724797680544804
Validation loss: 2.5204915254208933

Epoch: 246| Step: 0
Training loss: 2.309508992645271
Validation loss: 2.5140463098890207

Epoch: 5| Step: 1
Training loss: 2.692510414351332
Validation loss: 2.5047296863239343

Epoch: 5| Step: 2
Training loss: 3.0721552708347404
Validation loss: 2.507924379956907

Epoch: 5| Step: 3
Training loss: 2.751181088754006
Validation loss: 2.5338025598707037

Epoch: 5| Step: 4
Training loss: 2.7971805000750307
Validation loss: 2.5372003448379314

Epoch: 5| Step: 5
Training loss: 2.3946490359935244
Validation loss: 2.532758133093909

Epoch: 5| Step: 6
Training loss: 3.0636487091017406
Validation loss: 2.5410027311751353

Epoch: 5| Step: 7
Training loss: 2.7718135753822954
Validation loss: 2.5436289051559235

Epoch: 5| Step: 8
Training loss: 2.8448371904982355
Validation loss: 2.5289422314954217

Epoch: 5| Step: 9
Training loss: 3.1569134609769804
Validation loss: 2.5341820324466795

Epoch: 5| Step: 10
Training loss: 2.1789599882866595
Validation loss: 2.5427630884008217

Epoch: 247| Step: 0
Training loss: 3.1051834455224507
Validation loss: 2.5374154927534045

Epoch: 5| Step: 1
Training loss: 2.0546109145363354
Validation loss: 2.5235375165127585

Epoch: 5| Step: 2
Training loss: 3.0954135314073823
Validation loss: 2.530048410776986

Epoch: 5| Step: 3
Training loss: 2.7310409710331016
Validation loss: 2.550992002987633

Epoch: 5| Step: 4
Training loss: 3.0223874183304056
Validation loss: 2.5512374617950546

Epoch: 5| Step: 5
Training loss: 2.123992681170999
Validation loss: 2.5528673633105647

Epoch: 5| Step: 6
Training loss: 2.6873002976141103
Validation loss: 2.5499932512422836

Epoch: 5| Step: 7
Training loss: 2.814006910352213
Validation loss: 2.5330641380728944

Epoch: 5| Step: 8
Training loss: 2.8514216976153905
Validation loss: 2.5226817183913264

Epoch: 5| Step: 9
Training loss: 2.8405879959365263
Validation loss: 2.524811993404908

Epoch: 5| Step: 10
Training loss: 2.3965146187985655
Validation loss: 2.5078152381264323

Epoch: 248| Step: 0
Training loss: 2.5944038394289075
Validation loss: 2.498639678024154

Epoch: 5| Step: 1
Training loss: 2.3741315960617477
Validation loss: 2.5075108891088136

Epoch: 5| Step: 2
Training loss: 2.675061651214617
Validation loss: 2.522370686207028

Epoch: 5| Step: 3
Training loss: 3.0582838035404833
Validation loss: 2.5298228421536524

Epoch: 5| Step: 4
Training loss: 2.8890257664393357
Validation loss: 2.5213088618709247

Epoch: 5| Step: 5
Training loss: 3.1929387086743577
Validation loss: 2.5378587083807913

Epoch: 5| Step: 6
Training loss: 2.8029660012901383
Validation loss: 2.5672192100921367

Epoch: 5| Step: 7
Training loss: 2.403223487611731
Validation loss: 2.5741306410417937

Epoch: 5| Step: 8
Training loss: 2.7830737702944344
Validation loss: 2.5544016312070896

Epoch: 5| Step: 9
Training loss: 2.665202593233031
Validation loss: 2.56043719229033

Epoch: 5| Step: 10
Training loss: 2.4115388882874975
Validation loss: 2.548490002054866

Epoch: 249| Step: 0
Training loss: 2.6993925753544827
Validation loss: 2.5438063642563127

Epoch: 5| Step: 1
Training loss: 2.2348135137736245
Validation loss: 2.5136352386470473

Epoch: 5| Step: 2
Training loss: 2.8614787716315573
Validation loss: 2.525321520516461

Epoch: 5| Step: 3
Training loss: 2.438006030644006
Validation loss: 2.5252026159752696

Epoch: 5| Step: 4
Training loss: 3.132551910140766
Validation loss: 2.5309744699752947

Epoch: 5| Step: 5
Training loss: 2.40901916488682
Validation loss: 2.526011242612998

Epoch: 5| Step: 6
Training loss: 2.5824630768639225
Validation loss: 2.5031150197533543

Epoch: 5| Step: 7
Training loss: 2.7026527300931544
Validation loss: 2.52378338281794

Epoch: 5| Step: 8
Training loss: 3.175741460534487
Validation loss: 2.5267521679259035

Epoch: 5| Step: 9
Training loss: 2.6671098301131564
Validation loss: 2.5136279565957893

Epoch: 5| Step: 10
Training loss: 2.696853948800507
Validation loss: 2.5243171355772014

Epoch: 250| Step: 0
Training loss: 2.9719994680370814
Validation loss: 2.5521837493917103

Epoch: 5| Step: 1
Training loss: 2.5000325200826783
Validation loss: 2.5554506786920324

Epoch: 5| Step: 2
Training loss: 2.5125161621181236
Validation loss: 2.564579965662809

Epoch: 5| Step: 3
Training loss: 2.8176026574212734
Validation loss: 2.586769521111326

Epoch: 5| Step: 4
Training loss: 2.9276780217850398
Validation loss: 2.573943132439531

Epoch: 5| Step: 5
Training loss: 2.1916303605044716
Validation loss: 2.5647324422602624

Epoch: 5| Step: 6
Training loss: 2.366557223068433
Validation loss: 2.558086468155328

Epoch: 5| Step: 7
Training loss: 2.5503465828325997
Validation loss: 2.5554906340243217

Epoch: 5| Step: 8
Training loss: 2.6383870590179446
Validation loss: 2.5462999367172587

Epoch: 5| Step: 9
Training loss: 3.1887008798390646
Validation loss: 2.5371616686566325

Epoch: 5| Step: 10
Training loss: 2.9078912510116264
Validation loss: 2.5466100214052156

Epoch: 251| Step: 0
Training loss: 2.8167965601327225
Validation loss: 2.5185004220766025

Epoch: 5| Step: 1
Training loss: 1.971915772707214
Validation loss: 2.520318818745441

Epoch: 5| Step: 2
Training loss: 2.5998867010226228
Validation loss: 2.522223375541013

Epoch: 5| Step: 3
Training loss: 2.7329195345141257
Validation loss: 2.5371671750241043

Epoch: 5| Step: 4
Training loss: 3.1380006064030854
Validation loss: 2.5268764623976936

Epoch: 5| Step: 5
Training loss: 2.9901147740002116
Validation loss: 2.5321154971328963

Epoch: 5| Step: 6
Training loss: 2.9680358027640534
Validation loss: 2.553283656915346

Epoch: 5| Step: 7
Training loss: 2.295895010597985
Validation loss: 2.5562086220188482

Epoch: 5| Step: 8
Training loss: 2.030012957151055
Validation loss: 2.5720738689632903

Epoch: 5| Step: 9
Training loss: 3.033637925110534
Validation loss: 2.5680231038998054

Epoch: 5| Step: 10
Training loss: 2.7406507571324736
Validation loss: 2.539445630519909

Epoch: 252| Step: 0
Training loss: 3.2360623146347507
Validation loss: 2.5528890774687327

Epoch: 5| Step: 1
Training loss: 2.832104491240427
Validation loss: 2.5361714204722094

Epoch: 5| Step: 2
Training loss: 2.5939711510929793
Validation loss: 2.5221020739664564

Epoch: 5| Step: 3
Training loss: 2.3890731861182384
Validation loss: 2.5298312723451097

Epoch: 5| Step: 4
Training loss: 2.7031122990127914
Validation loss: 2.52157317772546

Epoch: 5| Step: 5
Training loss: 2.3540520654201735
Validation loss: 2.508800437861636

Epoch: 5| Step: 6
Training loss: 2.979520994514133
Validation loss: 2.5150418964648202

Epoch: 5| Step: 7
Training loss: 2.800703358863949
Validation loss: 2.532516719576378

Epoch: 5| Step: 8
Training loss: 2.544773943591201
Validation loss: 2.5394253510470604

Epoch: 5| Step: 9
Training loss: 2.6017115094924512
Validation loss: 2.5465767602309337

Epoch: 5| Step: 10
Training loss: 2.526466464999504
Validation loss: 2.5643487009681625

Epoch: 253| Step: 0
Training loss: 2.492519153303288
Validation loss: 2.564838873723795

Epoch: 5| Step: 1
Training loss: 3.0699750020752123
Validation loss: 2.5619455373446147

Epoch: 5| Step: 2
Training loss: 2.9940667289478666
Validation loss: 2.5395306237561037

Epoch: 5| Step: 3
Training loss: 2.4932179966257926
Validation loss: 2.5239932652965673

Epoch: 5| Step: 4
Training loss: 2.3179501410940446
Validation loss: 2.514007578323774

Epoch: 5| Step: 5
Training loss: 2.388399971109753
Validation loss: 2.5296023896160236

Epoch: 5| Step: 6
Training loss: 2.9582884520945383
Validation loss: 2.521672661246635

Epoch: 5| Step: 7
Training loss: 2.763053258669058
Validation loss: 2.522373582835845

Epoch: 5| Step: 8
Training loss: 2.353270053318925
Validation loss: 2.5230456297214348

Epoch: 5| Step: 9
Training loss: 2.942892927383437
Validation loss: 2.5287381359759573

Epoch: 5| Step: 10
Training loss: 2.670347613733805
Validation loss: 2.5469521111298126

Epoch: 254| Step: 0
Training loss: 2.7711701057008797
Validation loss: 2.5625763228220473

Epoch: 5| Step: 1
Training loss: 2.777269064627413
Validation loss: 2.585864281758666

Epoch: 5| Step: 2
Training loss: 2.58717984785065
Validation loss: 2.607213880640215

Epoch: 5| Step: 3
Training loss: 2.6513053198352723
Validation loss: 2.6141567126478726

Epoch: 5| Step: 4
Training loss: 2.982282933844064
Validation loss: 2.6221311364973716

Epoch: 5| Step: 5
Training loss: 2.898171631168682
Validation loss: 2.611976690684498

Epoch: 5| Step: 6
Training loss: 2.5497224955933757
Validation loss: 2.5727071196408575

Epoch: 5| Step: 7
Training loss: 2.607140686646396
Validation loss: 2.5525016403341616

Epoch: 5| Step: 8
Training loss: 2.561906140992747
Validation loss: 2.5247049945785847

Epoch: 5| Step: 9
Training loss: 2.887342744318545
Validation loss: 2.5205106309178578

Epoch: 5| Step: 10
Training loss: 2.1892510081776004
Validation loss: 2.5209246396605933

Epoch: 255| Step: 0
Training loss: 2.9180596068100604
Validation loss: 2.5166838367932858

Epoch: 5| Step: 1
Training loss: 2.7689003380459996
Validation loss: 2.514832083470225

Epoch: 5| Step: 2
Training loss: 2.3354436550117974
Validation loss: 2.5239779351662732

Epoch: 5| Step: 3
Training loss: 2.688123320220018
Validation loss: 2.511504585542269

Epoch: 5| Step: 4
Training loss: 2.062026229543573
Validation loss: 2.5172387874550073

Epoch: 5| Step: 5
Training loss: 2.7121732242479712
Validation loss: 2.5179910734403617

Epoch: 5| Step: 6
Training loss: 2.8391649780925285
Validation loss: 2.528483414433512

Epoch: 5| Step: 7
Training loss: 2.7163160983319172
Validation loss: 2.562877014021884

Epoch: 5| Step: 8
Training loss: 3.020385305570136
Validation loss: 2.5842952268925066

Epoch: 5| Step: 9
Training loss: 2.9044797694808
Validation loss: 2.5931359493429085

Epoch: 5| Step: 10
Training loss: 2.60747948057855
Validation loss: 2.5725488305539597

Epoch: 256| Step: 0
Training loss: 2.6310415226129327
Validation loss: 2.581838291948348

Epoch: 5| Step: 1
Training loss: 2.8470987577470415
Validation loss: 2.570737040981627

Epoch: 5| Step: 2
Training loss: 2.131756084237957
Validation loss: 2.5614459463322916

Epoch: 5| Step: 3
Training loss: 2.7207279245269156
Validation loss: 2.5553842837229963

Epoch: 5| Step: 4
Training loss: 2.7537901508938387
Validation loss: 2.536662059683971

Epoch: 5| Step: 5
Training loss: 2.6988849350668347
Validation loss: 2.5197779274043794

Epoch: 5| Step: 6
Training loss: 3.1570122431027388
Validation loss: 2.5154874592447056

Epoch: 5| Step: 7
Training loss: 2.863992267086735
Validation loss: 2.5201760323862388

Epoch: 5| Step: 8
Training loss: 2.794931258446425
Validation loss: 2.539020258675971

Epoch: 5| Step: 9
Training loss: 2.4538330222653024
Validation loss: 2.547058420970444

Epoch: 5| Step: 10
Training loss: 2.2501338283157315
Validation loss: 2.576742757924352

Epoch: 257| Step: 0
Training loss: 2.232693553022668
Validation loss: 2.5663207568031643

Epoch: 5| Step: 1
Training loss: 2.8070248186232596
Validation loss: 2.592733287444406

Epoch: 5| Step: 2
Training loss: 2.7928337011165354
Validation loss: 2.6142242636770328

Epoch: 5| Step: 3
Training loss: 2.9673762305141573
Validation loss: 2.6186131382390085

Epoch: 5| Step: 4
Training loss: 2.2592653662119018
Validation loss: 2.617022341355174

Epoch: 5| Step: 5
Training loss: 2.8187899297013326
Validation loss: 2.6013368085370194

Epoch: 5| Step: 6
Training loss: 2.5981229205165652
Validation loss: 2.563019800576773

Epoch: 5| Step: 7
Training loss: 2.8312783549322575
Validation loss: 2.551127523544501

Epoch: 5| Step: 8
Training loss: 2.64984129664399
Validation loss: 2.5251832444546305

Epoch: 5| Step: 9
Training loss: 2.6340102009905197
Validation loss: 2.52397742578547

Epoch: 5| Step: 10
Training loss: 2.783572138365971
Validation loss: 2.510046243858107

Epoch: 258| Step: 0
Training loss: 2.7487167485452026
Validation loss: 2.503098349118066

Epoch: 5| Step: 1
Training loss: 2.797360340822006
Validation loss: 2.4933190988889216

Epoch: 5| Step: 2
Training loss: 2.959901814765442
Validation loss: 2.4989343976830765

Epoch: 5| Step: 3
Training loss: 2.8285758149194216
Validation loss: 2.5204624783598755

Epoch: 5| Step: 4
Training loss: 2.8033760426186363
Validation loss: 2.5323286909163083

Epoch: 5| Step: 5
Training loss: 2.7681579197889667
Validation loss: 2.559678231572925

Epoch: 5| Step: 6
Training loss: 2.8387452405438656
Validation loss: 2.633954058436966

Epoch: 5| Step: 7
Training loss: 2.832240024632253
Validation loss: 2.670692357220267

Epoch: 5| Step: 8
Training loss: 2.283392644608435
Validation loss: 2.642892625860101

Epoch: 5| Step: 9
Training loss: 2.381542930707831
Validation loss: 2.601283142095061

Epoch: 5| Step: 10
Training loss: 2.246953597305655
Validation loss: 2.562286155935971

Epoch: 259| Step: 0
Training loss: 2.7052927310798993
Validation loss: 2.5577966689210236

Epoch: 5| Step: 1
Training loss: 2.8470131732728357
Validation loss: 2.5577659126257823

Epoch: 5| Step: 2
Training loss: 2.0807241376896424
Validation loss: 2.545109069994548

Epoch: 5| Step: 3
Training loss: 2.8032497450545133
Validation loss: 2.544301612032955

Epoch: 5| Step: 4
Training loss: 2.035454726343272
Validation loss: 2.543001586566969

Epoch: 5| Step: 5
Training loss: 2.6753095002141407
Validation loss: 2.540858844564742

Epoch: 5| Step: 6
Training loss: 3.153192682362125
Validation loss: 2.545591039661007

Epoch: 5| Step: 7
Training loss: 2.512150325450273
Validation loss: 2.5561242971736555

Epoch: 5| Step: 8
Training loss: 2.794759621698906
Validation loss: 2.53258974105473

Epoch: 5| Step: 9
Training loss: 2.6543524752443286
Validation loss: 2.5410658891052673

Epoch: 5| Step: 10
Training loss: 2.814600605115173
Validation loss: 2.5423127605086573

Epoch: 260| Step: 0
Training loss: 2.8974905600735497
Validation loss: 2.5759720698740334

Epoch: 5| Step: 1
Training loss: 3.0117467737935018
Validation loss: 2.578640168576691

Epoch: 5| Step: 2
Training loss: 3.1493076229591037
Validation loss: 2.614357527757175

Epoch: 5| Step: 3
Training loss: 2.3670937296106302
Validation loss: 2.631682518014938

Epoch: 5| Step: 4
Training loss: 1.6137740373187845
Validation loss: 2.6454061732287895

Epoch: 5| Step: 5
Training loss: 2.391193197705372
Validation loss: 2.658396757361083

Epoch: 5| Step: 6
Training loss: 3.267275452490391
Validation loss: 2.6180548978853153

Epoch: 5| Step: 7
Training loss: 2.3644889330960903
Validation loss: 2.5783224438547516

Epoch: 5| Step: 8
Training loss: 2.7162798479373937
Validation loss: 2.5463278805797955

Epoch: 5| Step: 9
Training loss: 2.4521904398284478
Validation loss: 2.500179511977863

Epoch: 5| Step: 10
Training loss: 2.7813453229363523
Validation loss: 2.5072878582479077

Epoch: 261| Step: 0
Training loss: 2.7337140837700966
Validation loss: 2.4981877844617735

Epoch: 5| Step: 1
Training loss: 2.704367996816822
Validation loss: 2.5018913108541128

Epoch: 5| Step: 2
Training loss: 2.88638539125167
Validation loss: 2.4938284124411187

Epoch: 5| Step: 3
Training loss: 2.647350707198942
Validation loss: 2.508707353964683

Epoch: 5| Step: 4
Training loss: 2.0005208767671854
Validation loss: 2.522006159575367

Epoch: 5| Step: 5
Training loss: 2.102010799652435
Validation loss: 2.549870380201303

Epoch: 5| Step: 6
Training loss: 2.7234043314101837
Validation loss: 2.583233303100967

Epoch: 5| Step: 7
Training loss: 3.269897586257003
Validation loss: 2.5708766238029233

Epoch: 5| Step: 8
Training loss: 2.8616445737447673
Validation loss: 2.5809687339163285

Epoch: 5| Step: 9
Training loss: 2.5301651690400155
Validation loss: 2.558755293431169

Epoch: 5| Step: 10
Training loss: 2.7640904193889204
Validation loss: 2.5900823758857072

Epoch: 262| Step: 0
Training loss: 2.9847097159217797
Validation loss: 2.585758898140459

Epoch: 5| Step: 1
Training loss: 2.4828513409485473
Validation loss: 2.591554141430049

Epoch: 5| Step: 2
Training loss: 1.9891209356290072
Validation loss: 2.6131500530524585

Epoch: 5| Step: 3
Training loss: 2.8192682842809482
Validation loss: 2.6097547689391227

Epoch: 5| Step: 4
Training loss: 2.8629448291020947
Validation loss: 2.609669014042712

Epoch: 5| Step: 5
Training loss: 2.5044248522943935
Validation loss: 2.6005514621022487

Epoch: 5| Step: 6
Training loss: 2.3453176723273246
Validation loss: 2.574484451889745

Epoch: 5| Step: 7
Training loss: 2.6026292967764753
Validation loss: 2.534767870328791

Epoch: 5| Step: 8
Training loss: 2.623222566743827
Validation loss: 2.523375328266009

Epoch: 5| Step: 9
Training loss: 2.413391810212766
Validation loss: 2.502922464436588

Epoch: 5| Step: 10
Training loss: 3.4127768882791565
Validation loss: 2.494991611919786

Epoch: 263| Step: 0
Training loss: 2.9321683831777343
Validation loss: 2.5009373538067083

Epoch: 5| Step: 1
Training loss: 2.4286225858477364
Validation loss: 2.4876988622967673

Epoch: 5| Step: 2
Training loss: 2.5044084780240192
Validation loss: 2.4795107145617723

Epoch: 5| Step: 3
Training loss: 2.392167335589716
Validation loss: 2.490133554153714

Epoch: 5| Step: 4
Training loss: 2.669443373647372
Validation loss: 2.4965075268124868

Epoch: 5| Step: 5
Training loss: 2.6098091540955215
Validation loss: 2.5225756160132677

Epoch: 5| Step: 6
Training loss: 2.1274159105763704
Validation loss: 2.535067583298761

Epoch: 5| Step: 7
Training loss: 2.980857493795272
Validation loss: 2.5508169116329973

Epoch: 5| Step: 8
Training loss: 2.9211251831812053
Validation loss: 2.6090491611331927

Epoch: 5| Step: 9
Training loss: 2.651008011180237
Validation loss: 2.5785009950852813

Epoch: 5| Step: 10
Training loss: 2.983554587515464
Validation loss: 2.5786604478450803

Epoch: 264| Step: 0
Training loss: 3.0076515848291168
Validation loss: 2.563777502096847

Epoch: 5| Step: 1
Training loss: 2.1535390868172573
Validation loss: 2.5396216668633884

Epoch: 5| Step: 2
Training loss: 2.8766943872854056
Validation loss: 2.503118041082878

Epoch: 5| Step: 3
Training loss: 2.4918976139815405
Validation loss: 2.496303853196233

Epoch: 5| Step: 4
Training loss: 2.3739342557035634
Validation loss: 2.4803756643432404

Epoch: 5| Step: 5
Training loss: 2.5845207643743033
Validation loss: 2.4898203026788632

Epoch: 5| Step: 6
Training loss: 2.3542946187134017
Validation loss: 2.4965455379133235

Epoch: 5| Step: 7
Training loss: 1.8180324699011814
Validation loss: 2.5172580490165553

Epoch: 5| Step: 8
Training loss: 3.1861231204930593
Validation loss: 2.5343864735119728

Epoch: 5| Step: 9
Training loss: 2.9687567459832893
Validation loss: 2.560981762929285

Epoch: 5| Step: 10
Training loss: 2.831962553046115
Validation loss: 2.582026133697367

Epoch: 265| Step: 0
Training loss: 2.6909694012589522
Validation loss: 2.57872793655509

Epoch: 5| Step: 1
Training loss: 2.581979817442314
Validation loss: 2.612937232246538

Epoch: 5| Step: 2
Training loss: 3.0494353662869496
Validation loss: 2.619908839894846

Epoch: 5| Step: 3
Training loss: 2.5923180361595572
Validation loss: 2.6068429995405173

Epoch: 5| Step: 4
Training loss: 2.98057913919508
Validation loss: 2.60509367032549

Epoch: 5| Step: 5
Training loss: 2.480407233489153
Validation loss: 2.567289687743936

Epoch: 5| Step: 6
Training loss: 2.3063474722425776
Validation loss: 2.534954333572715

Epoch: 5| Step: 7
Training loss: 2.760583366302918
Validation loss: 2.522052422993015

Epoch: 5| Step: 8
Training loss: 2.2393712024619257
Validation loss: 2.515005653146825

Epoch: 5| Step: 9
Training loss: 2.9204107685404184
Validation loss: 2.525283568460559

Epoch: 5| Step: 10
Training loss: 2.165388231421687
Validation loss: 2.5270130545741085

Epoch: 266| Step: 0
Training loss: 2.4802618946720343
Validation loss: 2.5276425288000945

Epoch: 5| Step: 1
Training loss: 2.861522597646795
Validation loss: 2.5561476214520074

Epoch: 5| Step: 2
Training loss: 2.301706228540037
Validation loss: 2.595740363007789

Epoch: 5| Step: 3
Training loss: 2.302282598050335
Validation loss: 2.6181228438064936

Epoch: 5| Step: 4
Training loss: 3.037087080404505
Validation loss: 2.6499059286232205

Epoch: 5| Step: 5
Training loss: 2.399554759687465
Validation loss: 2.6343530063798313

Epoch: 5| Step: 6
Training loss: 2.857512487616165
Validation loss: 2.6138599922974817

Epoch: 5| Step: 7
Training loss: 2.1482779148826983
Validation loss: 2.5701143360620318

Epoch: 5| Step: 8
Training loss: 2.729610804947177
Validation loss: 2.556621109639106

Epoch: 5| Step: 9
Training loss: 2.8278570733218165
Validation loss: 2.5491741258160987

Epoch: 5| Step: 10
Training loss: 2.8901955775309385
Validation loss: 2.5331275627533936

Epoch: 267| Step: 0
Training loss: 2.972945290748255
Validation loss: 2.5353121636011835

Epoch: 5| Step: 1
Training loss: 2.247117951777984
Validation loss: 2.5377160153798854

Epoch: 5| Step: 2
Training loss: 2.8448413808681505
Validation loss: 2.5388681099740564

Epoch: 5| Step: 3
Training loss: 3.0867761172614547
Validation loss: 2.5371218783675604

Epoch: 5| Step: 4
Training loss: 2.725845548702879
Validation loss: 2.5160591231403133

Epoch: 5| Step: 5
Training loss: 2.723113931419321
Validation loss: 2.5182648396510654

Epoch: 5| Step: 6
Training loss: 2.3709920895950116
Validation loss: 2.5230446735808614

Epoch: 5| Step: 7
Training loss: 2.7140241744300786
Validation loss: 2.5505309180970697

Epoch: 5| Step: 8
Training loss: 2.352412276218492
Validation loss: 2.5264532746991084

Epoch: 5| Step: 9
Training loss: 2.497615535381566
Validation loss: 2.5521270312916324

Epoch: 5| Step: 10
Training loss: 2.11637767210599
Validation loss: 2.570314863847008

Epoch: 268| Step: 0
Training loss: 2.8338302475748813
Validation loss: 2.5591917084292337

Epoch: 5| Step: 1
Training loss: 2.79643348320368
Validation loss: 2.5394987997667253

Epoch: 5| Step: 2
Training loss: 2.8845771826146267
Validation loss: 2.5276492552425713

Epoch: 5| Step: 3
Training loss: 2.7217354003985608
Validation loss: 2.50682315115043

Epoch: 5| Step: 4
Training loss: 2.904642296203869
Validation loss: 2.500955296601094

Epoch: 5| Step: 5
Training loss: 2.370246748493219
Validation loss: 2.507740323197239

Epoch: 5| Step: 6
Training loss: 2.0062533607335924
Validation loss: 2.516107663088707

Epoch: 5| Step: 7
Training loss: 2.7724464902538335
Validation loss: 2.504084998210429

Epoch: 5| Step: 8
Training loss: 2.4640150415159594
Validation loss: 2.5175523436408023

Epoch: 5| Step: 9
Training loss: 2.245778361858543
Validation loss: 2.541454466365808

Epoch: 5| Step: 10
Training loss: 2.2785190278146734
Validation loss: 2.5357617006143798

Epoch: 269| Step: 0
Training loss: 2.517346474323618
Validation loss: 2.557105486155233

Epoch: 5| Step: 1
Training loss: 2.950899607673543
Validation loss: 2.580436051072041

Epoch: 5| Step: 2
Training loss: 2.660559445828794
Validation loss: 2.582518931168984

Epoch: 5| Step: 3
Training loss: 2.092099692316098
Validation loss: 2.568429572829985

Epoch: 5| Step: 4
Training loss: 2.8791207346217367
Validation loss: 2.555118962511243

Epoch: 5| Step: 5
Training loss: 2.314330845431456
Validation loss: 2.550404804587063

Epoch: 5| Step: 6
Training loss: 2.745777269253173
Validation loss: 2.5414980501768225

Epoch: 5| Step: 7
Training loss: 2.768996516635036
Validation loss: 2.5130803491319345

Epoch: 5| Step: 8
Training loss: 2.4824699919424558
Validation loss: 2.4967908052697

Epoch: 5| Step: 9
Training loss: 2.3294637018648015
Validation loss: 2.49661937787485

Epoch: 5| Step: 10
Training loss: 2.6606440383986283
Validation loss: 2.493498527394935

Epoch: 270| Step: 0
Training loss: 2.0859117827812503
Validation loss: 2.504017849916842

Epoch: 5| Step: 1
Training loss: 2.8131599499697435
Validation loss: 2.5215313012207887

Epoch: 5| Step: 2
Training loss: 2.293974101997131
Validation loss: 2.5326408981607593

Epoch: 5| Step: 3
Training loss: 2.7316195310009768
Validation loss: 2.540125811668722

Epoch: 5| Step: 4
Training loss: 2.6867703179116256
Validation loss: 2.56449038492052

Epoch: 5| Step: 5
Training loss: 2.6056815865444003
Validation loss: 2.566886175342102

Epoch: 5| Step: 6
Training loss: 2.31836935039582
Validation loss: 2.566711107997816

Epoch: 5| Step: 7
Training loss: 2.7252377677568074
Validation loss: 2.5828992999679015

Epoch: 5| Step: 8
Training loss: 2.668033984435365
Validation loss: 2.5634206913154247

Epoch: 5| Step: 9
Training loss: 3.0507407680272696
Validation loss: 2.5520362600204627

Epoch: 5| Step: 10
Training loss: 2.118507564931818
Validation loss: 2.557553484032894

Epoch: 271| Step: 0
Training loss: 2.334571668722939
Validation loss: 2.523820131897237

Epoch: 5| Step: 1
Training loss: 2.522627284124989
Validation loss: 2.5053342229402595

Epoch: 5| Step: 2
Training loss: 2.6660412015142203
Validation loss: 2.4909545315236565

Epoch: 5| Step: 3
Training loss: 3.0802097135215423
Validation loss: 2.4939611635384953

Epoch: 5| Step: 4
Training loss: 2.3132784796082704
Validation loss: 2.481596973563727

Epoch: 5| Step: 5
Training loss: 2.7957360703159595
Validation loss: 2.482722265066054

Epoch: 5| Step: 6
Training loss: 2.6383658230922378
Validation loss: 2.4934389300992628

Epoch: 5| Step: 7
Training loss: 2.989750519617927
Validation loss: 2.5210760103667886

Epoch: 5| Step: 8
Training loss: 1.9107177158829136
Validation loss: 2.5799544569490154

Epoch: 5| Step: 9
Training loss: 2.5790766953494004
Validation loss: 2.605339920729023

Epoch: 5| Step: 10
Training loss: 2.2295023466355817
Validation loss: 2.619539132773431

Epoch: 272| Step: 0
Training loss: 2.0509474914019115
Validation loss: 2.6503461341225885

Epoch: 5| Step: 1
Training loss: 2.3776049131717465
Validation loss: 2.6310905404132865

Epoch: 5| Step: 2
Training loss: 2.4851211291136672
Validation loss: 2.6167446084370756

Epoch: 5| Step: 3
Training loss: 2.3812616022583266
Validation loss: 2.5797623661294304

Epoch: 5| Step: 4
Training loss: 2.2755824716266737
Validation loss: 2.567070137847247

Epoch: 5| Step: 5
Training loss: 2.462857130459693
Validation loss: 2.5561750564923997

Epoch: 5| Step: 6
Training loss: 2.870181150135776
Validation loss: 2.53480298051357

Epoch: 5| Step: 7
Training loss: 2.539207947306464
Validation loss: 2.539471543953506

Epoch: 5| Step: 8
Training loss: 3.2545578614420303
Validation loss: 2.5100586532536715

Epoch: 5| Step: 9
Training loss: 3.144490306895719
Validation loss: 2.5258456851976874

Epoch: 5| Step: 10
Training loss: 2.1056452802778063
Validation loss: 2.525903846999131

Epoch: 273| Step: 0
Training loss: 2.7385503661166375
Validation loss: 2.5402126910923455

Epoch: 5| Step: 1
Training loss: 2.9913252342573005
Validation loss: 2.535404836975721

Epoch: 5| Step: 2
Training loss: 2.8793544135776785
Validation loss: 2.548215379377467

Epoch: 5| Step: 3
Training loss: 2.4897808065798146
Validation loss: 2.566855311229927

Epoch: 5| Step: 4
Training loss: 2.415776209274845
Validation loss: 2.5756676978731896

Epoch: 5| Step: 5
Training loss: 2.3832056940574784
Validation loss: 2.5858154743945456

Epoch: 5| Step: 6
Training loss: 2.016710092796848
Validation loss: 2.57149042284881

Epoch: 5| Step: 7
Training loss: 2.3074385436234
Validation loss: 2.5681794009501187

Epoch: 5| Step: 8
Training loss: 2.851788070326945
Validation loss: 2.5541553111704602

Epoch: 5| Step: 9
Training loss: 2.3812532920514276
Validation loss: 2.5619642526510003

Epoch: 5| Step: 10
Training loss: 2.403840481091188
Validation loss: 2.5648621867213666

Epoch: 274| Step: 0
Training loss: 2.413154801760451
Validation loss: 2.5604279907758993

Epoch: 5| Step: 1
Training loss: 2.7364652655118844
Validation loss: 2.5815362729988114

Epoch: 5| Step: 2
Training loss: 2.2076328774159335
Validation loss: 2.6169327326762555

Epoch: 5| Step: 3
Training loss: 2.391403071623531
Validation loss: 2.5794446524191263

Epoch: 5| Step: 4
Training loss: 2.8396802012955407
Validation loss: 2.593356125705057

Epoch: 5| Step: 5
Training loss: 2.5736202765700327
Validation loss: 2.5565737515300486

Epoch: 5| Step: 6
Training loss: 2.7085403265469403
Validation loss: 2.5264921716306206

Epoch: 5| Step: 7
Training loss: 2.4699509029682614
Validation loss: 2.502895279433223

Epoch: 5| Step: 8
Training loss: 2.36510917653523
Validation loss: 2.4796953686267416

Epoch: 5| Step: 9
Training loss: 2.8658758588207176
Validation loss: 2.47219967951845

Epoch: 5| Step: 10
Training loss: 2.5283155032363007
Validation loss: 2.462638167078128

Epoch: 275| Step: 0
Training loss: 2.643830109232508
Validation loss: 2.4804056046038174

Epoch: 5| Step: 1
Training loss: 2.2046579208931116
Validation loss: 2.487443321779058

Epoch: 5| Step: 2
Training loss: 2.441674008754415
Validation loss: 2.4840498644619022

Epoch: 5| Step: 3
Training loss: 2.848787980272131
Validation loss: 2.4985223181860814

Epoch: 5| Step: 4
Training loss: 2.5613961051796332
Validation loss: 2.493191645120358

Epoch: 5| Step: 5
Training loss: 2.239711018552339
Validation loss: 2.5032916415768

Epoch: 5| Step: 6
Training loss: 2.306861188584176
Validation loss: 2.5366061870977012

Epoch: 5| Step: 7
Training loss: 2.719131442968174
Validation loss: 2.564060293402161

Epoch: 5| Step: 8
Training loss: 2.7933893914010963
Validation loss: 2.5636780974766236

Epoch: 5| Step: 9
Training loss: 2.5423815821374838
Validation loss: 2.5724666747144784

Epoch: 5| Step: 10
Training loss: 2.4502562252666573
Validation loss: 2.5921591021013595

Epoch: 276| Step: 0
Training loss: 2.536884864699607
Validation loss: 2.618613076561566

Epoch: 5| Step: 1
Training loss: 2.3548165046169225
Validation loss: 2.607442538038318

Epoch: 5| Step: 2
Training loss: 2.169698818770099
Validation loss: 2.596012943495632

Epoch: 5| Step: 3
Training loss: 2.019286740404127
Validation loss: 2.590134112742633

Epoch: 5| Step: 4
Training loss: 2.874194488464469
Validation loss: 2.581158792233609

Epoch: 5| Step: 5
Training loss: 2.3933355385957014
Validation loss: 2.55959343911409

Epoch: 5| Step: 6
Training loss: 2.634197561277362
Validation loss: 2.5509428746246523

Epoch: 5| Step: 7
Training loss: 2.6616889470489005
Validation loss: 2.5490863057471875

Epoch: 5| Step: 8
Training loss: 2.8669855945812026
Validation loss: 2.5427932518658984

Epoch: 5| Step: 9
Training loss: 2.8082290433843573
Validation loss: 2.5432421126822873

Epoch: 5| Step: 10
Training loss: 2.270873941414228
Validation loss: 2.5223777997116392

Epoch: 277| Step: 0
Training loss: 2.528406689090387
Validation loss: 2.526085537038029

Epoch: 5| Step: 1
Training loss: 2.2839349074900563
Validation loss: 2.505208817706802

Epoch: 5| Step: 2
Training loss: 2.321730876983101
Validation loss: 2.50649178779156

Epoch: 5| Step: 3
Training loss: 2.6512614360816276
Validation loss: 2.501347653361411

Epoch: 5| Step: 4
Training loss: 2.3850729304585125
Validation loss: 2.5150051597872225

Epoch: 5| Step: 5
Training loss: 2.4602502256768752
Validation loss: 2.5180149718773754

Epoch: 5| Step: 6
Training loss: 2.5501482939141735
Validation loss: 2.563505537190642

Epoch: 5| Step: 7
Training loss: 2.055127579007521
Validation loss: 2.56571250553365

Epoch: 5| Step: 8
Training loss: 3.1156485446663966
Validation loss: 2.61416070399597

Epoch: 5| Step: 9
Training loss: 2.69757798669913
Validation loss: 2.5911470743515315

Epoch: 5| Step: 10
Training loss: 2.7626171242581083
Validation loss: 2.60961638050092

Epoch: 278| Step: 0
Training loss: 2.793945568502042
Validation loss: 2.567368591219529

Epoch: 5| Step: 1
Training loss: 2.2129527905613293
Validation loss: 2.5429627420479104

Epoch: 5| Step: 2
Training loss: 2.4786619319073684
Validation loss: 2.51742578834745

Epoch: 5| Step: 3
Training loss: 2.4485443500898016
Validation loss: 2.507454494759904

Epoch: 5| Step: 4
Training loss: 2.9451501128663873
Validation loss: 2.476523847825995

Epoch: 5| Step: 5
Training loss: 2.833282657244901
Validation loss: 2.487503512066671

Epoch: 5| Step: 6
Training loss: 2.865959715353106
Validation loss: 2.4657021552755056

Epoch: 5| Step: 7
Training loss: 2.0785249024148102
Validation loss: 2.4950032176716825

Epoch: 5| Step: 8
Training loss: 2.5019360674977182
Validation loss: 2.513153916986341

Epoch: 5| Step: 9
Training loss: 2.105037269896618
Validation loss: 2.537267008006547

Epoch: 5| Step: 10
Training loss: 2.5723077050824354
Validation loss: 2.571779466511713

Epoch: 279| Step: 0
Training loss: 2.344504985007569
Validation loss: 2.60644103590207

Epoch: 5| Step: 1
Training loss: 2.6540345770416804
Validation loss: 2.5966399039044674

Epoch: 5| Step: 2
Training loss: 2.832986268123009
Validation loss: 2.637170596038254

Epoch: 5| Step: 3
Training loss: 2.040394782593665
Validation loss: 2.59351521968959

Epoch: 5| Step: 4
Training loss: 2.7380954390973953
Validation loss: 2.5818255970300767

Epoch: 5| Step: 5
Training loss: 2.417279220645891
Validation loss: 2.5491095103797736

Epoch: 5| Step: 6
Training loss: 2.5461902282920463
Validation loss: 2.5235920728590657

Epoch: 5| Step: 7
Training loss: 2.443656580083273
Validation loss: 2.5008714228749453

Epoch: 5| Step: 8
Training loss: 2.64019473932628
Validation loss: 2.495376446103553

Epoch: 5| Step: 9
Training loss: 2.5169126638810853
Validation loss: 2.4924828283041576

Epoch: 5| Step: 10
Training loss: 2.4175233199563886
Validation loss: 2.4972685176517793

Epoch: 280| Step: 0
Training loss: 2.5241028466588826
Validation loss: 2.5139658123789888

Epoch: 5| Step: 1
Training loss: 2.8340378801591126
Validation loss: 2.561238551396032

Epoch: 5| Step: 2
Training loss: 2.812882037176821
Validation loss: 2.573473434983842

Epoch: 5| Step: 3
Training loss: 2.4494661878474084
Validation loss: 2.601282830667798

Epoch: 5| Step: 4
Training loss: 2.3324393421720764
Validation loss: 2.6020795722230856

Epoch: 5| Step: 5
Training loss: 2.002514450649741
Validation loss: 2.5618732300147613

Epoch: 5| Step: 6
Training loss: 2.4683421317112644
Validation loss: 2.551713020491646

Epoch: 5| Step: 7
Training loss: 2.5582517439002084
Validation loss: 2.5225299165813286

Epoch: 5| Step: 8
Training loss: 2.6174489360444633
Validation loss: 2.516781230856877

Epoch: 5| Step: 9
Training loss: 2.3563716543347
Validation loss: 2.5326093089874546

Epoch: 5| Step: 10
Training loss: 2.472647379155691
Validation loss: 2.538978397311167

Epoch: 281| Step: 0
Training loss: 2.5191169338972634
Validation loss: 2.5392596126809144

Epoch: 5| Step: 1
Training loss: 2.394830134346795
Validation loss: 2.5386582000150377

Epoch: 5| Step: 2
Training loss: 2.340340232078658
Validation loss: 2.5761706629244165

Epoch: 5| Step: 3
Training loss: 2.1072998011518944
Validation loss: 2.578223830709391

Epoch: 5| Step: 4
Training loss: 2.564644079369536
Validation loss: 2.5918312927617166

Epoch: 5| Step: 5
Training loss: 2.8952507329488104
Validation loss: 2.6088887223867276

Epoch: 5| Step: 6
Training loss: 2.2221390536427656
Validation loss: 2.574088531999398

Epoch: 5| Step: 7
Training loss: 2.9106841357422355
Validation loss: 2.566324536848583

Epoch: 5| Step: 8
Training loss: 2.2889706329555026
Validation loss: 2.5406083967267765

Epoch: 5| Step: 9
Training loss: 2.3682136955172557
Validation loss: 2.5395422566322443

Epoch: 5| Step: 10
Training loss: 2.639423435569804
Validation loss: 2.524166835732811

Epoch: 282| Step: 0
Training loss: 2.9250218382452164
Validation loss: 2.506779653756882

Epoch: 5| Step: 1
Training loss: 2.7111941169407046
Validation loss: 2.52284125227739

Epoch: 5| Step: 2
Training loss: 2.458517962058277
Validation loss: 2.5171700035447495

Epoch: 5| Step: 3
Training loss: 2.4350715668988436
Validation loss: 2.5068837269651296

Epoch: 5| Step: 4
Training loss: 2.3774514847387267
Validation loss: 2.5171797379805563

Epoch: 5| Step: 5
Training loss: 2.3586853231954072
Validation loss: 2.5374373603580507

Epoch: 5| Step: 6
Training loss: 2.3569698579889615
Validation loss: 2.542291785927554

Epoch: 5| Step: 7
Training loss: 2.335624240041134
Validation loss: 2.55146246651844

Epoch: 5| Step: 8
Training loss: 3.0620347272920627
Validation loss: 2.5447767975931708

Epoch: 5| Step: 9
Training loss: 1.7060437870823781
Validation loss: 2.5661836384846017

Epoch: 5| Step: 10
Training loss: 2.1428834459416186
Validation loss: 2.5517346560621794

Epoch: 283| Step: 0
Training loss: 2.9420512228110582
Validation loss: 2.5500171684525244

Epoch: 5| Step: 1
Training loss: 2.5481286269258723
Validation loss: 2.5549886119052445

Epoch: 5| Step: 2
Training loss: 2.407076507905573
Validation loss: 2.5501222296062314

Epoch: 5| Step: 3
Training loss: 2.285431465464979
Validation loss: 2.550671096094426

Epoch: 5| Step: 4
Training loss: 2.8255537789997947
Validation loss: 2.5596226320344764

Epoch: 5| Step: 5
Training loss: 2.2762658003751493
Validation loss: 2.5571151648094737

Epoch: 5| Step: 6
Training loss: 2.29570153810616
Validation loss: 2.5896920114377378

Epoch: 5| Step: 7
Training loss: 2.4195903215350656
Validation loss: 2.609372117422456

Epoch: 5| Step: 8
Training loss: 2.5500061820460163
Validation loss: 2.583449207456716

Epoch: 5| Step: 9
Training loss: 2.0499059934694
Validation loss: 2.5507636265390166

Epoch: 5| Step: 10
Training loss: 2.299410711344496
Validation loss: 2.5401012926524182

Epoch: 284| Step: 0
Training loss: 2.1123401287913244
Validation loss: 2.528352421680195

Epoch: 5| Step: 1
Training loss: 2.50542519331999
Validation loss: 2.5128917144261247

Epoch: 5| Step: 2
Training loss: 2.4853307457072713
Validation loss: 2.5081079704010905

Epoch: 5| Step: 3
Training loss: 2.4025896644333775
Validation loss: 2.499900161636464

Epoch: 5| Step: 4
Training loss: 2.4402482605318183
Validation loss: 2.487007605251505

Epoch: 5| Step: 5
Training loss: 2.8554295068802182
Validation loss: 2.528192980026345

Epoch: 5| Step: 6
Training loss: 2.653569383552583
Validation loss: 2.5530532657943845

Epoch: 5| Step: 7
Training loss: 2.2344846898610946
Validation loss: 2.5898383096008515

Epoch: 5| Step: 8
Training loss: 2.392225938683766
Validation loss: 2.565229181583333

Epoch: 5| Step: 9
Training loss: 2.3218265821047366
Validation loss: 2.5664247060235033

Epoch: 5| Step: 10
Training loss: 2.481431092540917
Validation loss: 2.5796490840133806

Epoch: 285| Step: 0
Training loss: 2.3232695877364353
Validation loss: 2.578701537778811

Epoch: 5| Step: 1
Training loss: 2.3277879509391215
Validation loss: 2.597765063895695

Epoch: 5| Step: 2
Training loss: 2.4095996479834594
Validation loss: 2.6048204456977886

Epoch: 5| Step: 3
Training loss: 2.7109328388097085
Validation loss: 2.6072270959897783

Epoch: 5| Step: 4
Training loss: 2.3903510242120123
Validation loss: 2.6057844024129255

Epoch: 5| Step: 5
Training loss: 2.4293807348169425
Validation loss: 2.6277937995933103

Epoch: 5| Step: 6
Training loss: 1.7663194084163312
Validation loss: 2.6159996926080864

Epoch: 5| Step: 7
Training loss: 2.815899130022492
Validation loss: 2.6121692645753045

Epoch: 5| Step: 8
Training loss: 2.607988914524694
Validation loss: 2.56031452006807

Epoch: 5| Step: 9
Training loss: 2.590315509711096
Validation loss: 2.5021447170167535

Epoch: 5| Step: 10
Training loss: 2.445107350869362
Validation loss: 2.4906047185182523

Epoch: 286| Step: 0
Training loss: 2.381674272682141
Validation loss: 2.482375993000699

Epoch: 5| Step: 1
Training loss: 2.540906782113548
Validation loss: 2.500096567401318

Epoch: 5| Step: 2
Training loss: 2.7799210534446854
Validation loss: 2.4929753106078936

Epoch: 5| Step: 3
Training loss: 2.64384453787088
Validation loss: 2.4809148086204895

Epoch: 5| Step: 4
Training loss: 2.299441402437694
Validation loss: 2.480441931800086

Epoch: 5| Step: 5
Training loss: 2.393345400727575
Validation loss: 2.4905401090355013

Epoch: 5| Step: 6
Training loss: 1.9195915240651318
Validation loss: 2.5069634037048742

Epoch: 5| Step: 7
Training loss: 2.4546405945587657
Validation loss: 2.5356133409481942

Epoch: 5| Step: 8
Training loss: 2.7410715989813523
Validation loss: 2.583334460011798

Epoch: 5| Step: 9
Training loss: 2.608902208816662
Validation loss: 2.566878195432157

Epoch: 5| Step: 10
Training loss: 2.6047633186934918
Validation loss: 2.5441260677910886

Epoch: 287| Step: 0
Training loss: 2.4452250407120695
Validation loss: 2.514861692009266

Epoch: 5| Step: 1
Training loss: 2.072954672715802
Validation loss: 2.495203135356076

Epoch: 5| Step: 2
Training loss: 2.3501012577399423
Validation loss: 2.5032693282153913

Epoch: 5| Step: 3
Training loss: 2.5399777684778213
Validation loss: 2.507643415283734

Epoch: 5| Step: 4
Training loss: 2.172535747765128
Validation loss: 2.5149759086903796

Epoch: 5| Step: 5
Training loss: 1.7418923577031347
Validation loss: 2.4956404863246058

Epoch: 5| Step: 6
Training loss: 2.489877042377239
Validation loss: 2.5219307685892147

Epoch: 5| Step: 7
Training loss: 2.5339437209505706
Validation loss: 2.4965396097559016

Epoch: 5| Step: 8
Training loss: 2.8435001473129122
Validation loss: 2.5156012256079516

Epoch: 5| Step: 9
Training loss: 3.0428684595154722
Validation loss: 2.5174222057615343

Epoch: 5| Step: 10
Training loss: 2.4808188844601085
Validation loss: 2.528930595984519

Epoch: 288| Step: 0
Training loss: 2.8750257076275063
Validation loss: 2.533133561646658

Epoch: 5| Step: 1
Training loss: 2.689167481256706
Validation loss: 2.5484903440761246

Epoch: 5| Step: 2
Training loss: 2.391238264821795
Validation loss: 2.5166028745743176

Epoch: 5| Step: 3
Training loss: 2.2907659552323567
Validation loss: 2.502984836930021

Epoch: 5| Step: 4
Training loss: 2.020028914442946
Validation loss: 2.527213540138283

Epoch: 5| Step: 5
Training loss: 1.78134121577628
Validation loss: 2.54454667194887

Epoch: 5| Step: 6
Training loss: 2.957562216251839
Validation loss: 2.5991656186445087

Epoch: 5| Step: 7
Training loss: 2.7176109646458917
Validation loss: 2.602041752016006

Epoch: 5| Step: 8
Training loss: 2.768820000101604
Validation loss: 2.59663524684605

Epoch: 5| Step: 9
Training loss: 1.49377141641882
Validation loss: 2.582576438051254

Epoch: 5| Step: 10
Training loss: 2.4033678306646857
Validation loss: 2.5698189210228137

Epoch: 289| Step: 0
Training loss: 3.03082115049923
Validation loss: 2.546054128262104

Epoch: 5| Step: 1
Training loss: 1.9704290828957625
Validation loss: 2.534062103547478

Epoch: 5| Step: 2
Training loss: 2.154177014776741
Validation loss: 2.509498281833029

Epoch: 5| Step: 3
Training loss: 2.529937026857246
Validation loss: 2.51174456061725

Epoch: 5| Step: 4
Training loss: 2.4402234439473736
Validation loss: 2.5161602857356202

Epoch: 5| Step: 5
Training loss: 1.9089283497244505
Validation loss: 2.525907232836418

Epoch: 5| Step: 6
Training loss: 2.6926825477255814
Validation loss: 2.523166003502791

Epoch: 5| Step: 7
Training loss: 2.014397417370426
Validation loss: 2.531609876646885

Epoch: 5| Step: 8
Training loss: 2.210597251349083
Validation loss: 2.5418741187596052

Epoch: 5| Step: 9
Training loss: 2.4400786429379533
Validation loss: 2.5402781908278604

Epoch: 5| Step: 10
Training loss: 2.9917689894778587
Validation loss: 2.5143452077245505

Epoch: 290| Step: 0
Training loss: 1.9706791100300582
Validation loss: 2.5262241934843157

Epoch: 5| Step: 1
Training loss: 1.974638352903098
Validation loss: 2.520082322390878

Epoch: 5| Step: 2
Training loss: 2.7289070607732118
Validation loss: 2.501614092627836

Epoch: 5| Step: 3
Training loss: 1.9310273372348816
Validation loss: 2.5207909221398537

Epoch: 5| Step: 4
Training loss: 2.9349310172453404
Validation loss: 2.5218207217901667

Epoch: 5| Step: 5
Training loss: 1.9301035814704552
Validation loss: 2.535619624637647

Epoch: 5| Step: 6
Training loss: 2.824576833983572
Validation loss: 2.561176699695994

Epoch: 5| Step: 7
Training loss: 2.8418225474033694
Validation loss: 2.533982334959953

Epoch: 5| Step: 8
Training loss: 2.1507552528126532
Validation loss: 2.5596964496663697

Epoch: 5| Step: 9
Training loss: 2.0770212555092935
Validation loss: 2.52891411377303

Epoch: 5| Step: 10
Training loss: 2.7076476084872687
Validation loss: 2.5634133146719424

Epoch: 291| Step: 0
Training loss: 2.68001160733001
Validation loss: 2.5440472959656057

Epoch: 5| Step: 1
Training loss: 2.320599779012009
Validation loss: 2.5176726898610053

Epoch: 5| Step: 2
Training loss: 2.1201377667342425
Validation loss: 2.497028655448567

Epoch: 5| Step: 3
Training loss: 2.0064356495177007
Validation loss: 2.492837447789289

Epoch: 5| Step: 4
Training loss: 2.195337804465206
Validation loss: 2.5049846423860194

Epoch: 5| Step: 5
Training loss: 2.446156608970311
Validation loss: 2.4783230617563095

Epoch: 5| Step: 6
Training loss: 2.4310359831217863
Validation loss: 2.483194473286812

Epoch: 5| Step: 7
Training loss: 2.1549969778017593
Validation loss: 2.4894688067148723

Epoch: 5| Step: 8
Training loss: 2.904745389249665
Validation loss: 2.5098665826409783

Epoch: 5| Step: 9
Training loss: 2.020399014183503
Validation loss: 2.509600746775521

Epoch: 5| Step: 10
Training loss: 2.848371167438527
Validation loss: 2.526106942520303

Epoch: 292| Step: 0
Training loss: 2.5149866087843296
Validation loss: 2.584060482916815

Epoch: 5| Step: 1
Training loss: 2.2609324299004787
Validation loss: 2.618237476090944

Epoch: 5| Step: 2
Training loss: 2.3778744418954667
Validation loss: 2.6118406814569335

Epoch: 5| Step: 3
Training loss: 2.7892936375688437
Validation loss: 2.5981297822140226

Epoch: 5| Step: 4
Training loss: 2.3997883425205866
Validation loss: 2.563781679870402

Epoch: 5| Step: 5
Training loss: 2.353325775213595
Validation loss: 2.533120695002558

Epoch: 5| Step: 6
Training loss: 2.442917501011454
Validation loss: 2.496787519589773

Epoch: 5| Step: 7
Training loss: 2.2447566290036454
Validation loss: 2.4814765167802277

Epoch: 5| Step: 8
Training loss: 2.7059782107562143
Validation loss: 2.4818906812041557

Epoch: 5| Step: 9
Training loss: 2.061145453268354
Validation loss: 2.4615851843515193

Epoch: 5| Step: 10
Training loss: 2.3390149923939254
Validation loss: 2.512669841201295

Epoch: 293| Step: 0
Training loss: 2.425959434660725
Validation loss: 2.5152822490431705

Epoch: 5| Step: 1
Training loss: 2.639508524865592
Validation loss: 2.548973514928679

Epoch: 5| Step: 2
Training loss: 2.5257253756893046
Validation loss: 2.535300461262523

Epoch: 5| Step: 3
Training loss: 2.6523315249626216
Validation loss: 2.555693436727391

Epoch: 5| Step: 4
Training loss: 2.433015659794582
Validation loss: 2.5736760896953035

Epoch: 5| Step: 5
Training loss: 1.9632575304243258
Validation loss: 2.5469553965145675

Epoch: 5| Step: 6
Training loss: 2.0304444109407207
Validation loss: 2.544075838954474

Epoch: 5| Step: 7
Training loss: 2.143478162785518
Validation loss: 2.526569699882353

Epoch: 5| Step: 8
Training loss: 2.283219623750804
Validation loss: 2.525511646812134

Epoch: 5| Step: 9
Training loss: 2.5402478077671327
Validation loss: 2.5089459177718143

Epoch: 5| Step: 10
Training loss: 2.4265220113055017
Validation loss: 2.518470622700304

Epoch: 294| Step: 0
Training loss: 2.4170639983019084
Validation loss: 2.522222724015111

Epoch: 5| Step: 1
Training loss: 2.22771929756372
Validation loss: 2.537697310156503

Epoch: 5| Step: 2
Training loss: 1.815160443068885
Validation loss: 2.5184512004162016

Epoch: 5| Step: 3
Training loss: 2.1098565576256845
Validation loss: 2.5261811255441726

Epoch: 5| Step: 4
Training loss: 2.6779084375125537
Validation loss: 2.5247251841306535

Epoch: 5| Step: 5
Training loss: 2.2520456551485664
Validation loss: 2.5372627638408907

Epoch: 5| Step: 6
Training loss: 1.954830432182087
Validation loss: 2.55939556409407

Epoch: 5| Step: 7
Training loss: 2.775693679574897
Validation loss: 2.5833924290397485

Epoch: 5| Step: 8
Training loss: 2.1988822178126095
Validation loss: 2.5993301652026997

Epoch: 5| Step: 9
Training loss: 2.7050359949900655
Validation loss: 2.607583126120771

Epoch: 5| Step: 10
Training loss: 2.803376552900283
Validation loss: 2.549234508843709

Epoch: 295| Step: 0
Training loss: 2.3763114922045463
Validation loss: 2.5334381263455166

Epoch: 5| Step: 1
Training loss: 2.059585129895727
Validation loss: 2.520832092954703

Epoch: 5| Step: 2
Training loss: 2.8264224159528735
Validation loss: 2.5034144864445467

Epoch: 5| Step: 3
Training loss: 2.1637903586358567
Validation loss: 2.5016297862832495

Epoch: 5| Step: 4
Training loss: 2.296158867088189
Validation loss: 2.4745809310271736

Epoch: 5| Step: 5
Training loss: 2.2346766341623656
Validation loss: 2.464308758833869

Epoch: 5| Step: 6
Training loss: 2.017144391982862
Validation loss: 2.475982787600686

Epoch: 5| Step: 7
Training loss: 2.33545457830179
Validation loss: 2.4880436722863712

Epoch: 5| Step: 8
Training loss: 2.4174711488818783
Validation loss: 2.5079888870954203

Epoch: 5| Step: 9
Training loss: 2.3921830828206687
Validation loss: 2.5016828615496336

Epoch: 5| Step: 10
Training loss: 2.9367692728407957
Validation loss: 2.527501808979649

Epoch: 296| Step: 0
Training loss: 2.153656989871691
Validation loss: 2.5352898428576833

Epoch: 5| Step: 1
Training loss: 2.726451095447468
Validation loss: 2.5628106834061404

Epoch: 5| Step: 2
Training loss: 2.273484377033624
Validation loss: 2.574232731272238

Epoch: 5| Step: 3
Training loss: 2.1717325067774005
Validation loss: 2.5439463786908534

Epoch: 5| Step: 4
Training loss: 2.573705966567228
Validation loss: 2.533371946823687

Epoch: 5| Step: 5
Training loss: 2.5573352776335376
Validation loss: 2.5142006153258607

Epoch: 5| Step: 6
Training loss: 2.4899943396875472
Validation loss: 2.4902218997585734

Epoch: 5| Step: 7
Training loss: 2.6771414091190935
Validation loss: 2.4566978613025725

Epoch: 5| Step: 8
Training loss: 2.2733564329605156
Validation loss: 2.4914545012568037

Epoch: 5| Step: 9
Training loss: 2.077320832423416
Validation loss: 2.4714178839149357

Epoch: 5| Step: 10
Training loss: 1.7946745294244697
Validation loss: 2.485293767903275

Epoch: 297| Step: 0
Training loss: 2.5097068215691474
Validation loss: 2.4954607690540516

Epoch: 5| Step: 1
Training loss: 2.5772379880945864
Validation loss: 2.489559854307573

Epoch: 5| Step: 2
Training loss: 1.7593776940008377
Validation loss: 2.5186011522398064

Epoch: 5| Step: 3
Training loss: 2.5551210554674824
Validation loss: 2.530655819900704

Epoch: 5| Step: 4
Training loss: 2.2873218154298507
Validation loss: 2.5415189334641486

Epoch: 5| Step: 5
Training loss: 2.1516072143252187
Validation loss: 2.5793553275221077

Epoch: 5| Step: 6
Training loss: 2.485763449722945
Validation loss: 2.5455203822157295

Epoch: 5| Step: 7
Training loss: 2.3748556394371647
Validation loss: 2.5126146921235817

Epoch: 5| Step: 8
Training loss: 2.21156426162725
Validation loss: 2.4989624198077887

Epoch: 5| Step: 9
Training loss: 2.549116493954279
Validation loss: 2.4738604008840155

Epoch: 5| Step: 10
Training loss: 2.3528802670981896
Validation loss: 2.4739089993715995

Epoch: 298| Step: 0
Training loss: 2.208154443176898
Validation loss: 2.4606319687726685

Epoch: 5| Step: 1
Training loss: 2.4517690227552804
Validation loss: 2.4712655094666784

Epoch: 5| Step: 2
Training loss: 2.1886794044355584
Validation loss: 2.4679152143157492

Epoch: 5| Step: 3
Training loss: 2.1690195097549285
Validation loss: 2.484150548315056

Epoch: 5| Step: 4
Training loss: 2.412778642602392
Validation loss: 2.512888463571294

Epoch: 5| Step: 5
Training loss: 2.6680822390187826
Validation loss: 2.524410876752516

Epoch: 5| Step: 6
Training loss: 2.627222754953277
Validation loss: 2.5316630413485255

Epoch: 5| Step: 7
Training loss: 2.478202685837764
Validation loss: 2.522922587913407

Epoch: 5| Step: 8
Training loss: 2.2085824022247826
Validation loss: 2.5474159727633636

Epoch: 5| Step: 9
Training loss: 2.0410333806045866
Validation loss: 2.5715188975021777

Epoch: 5| Step: 10
Training loss: 2.1828153311206586
Validation loss: 2.5605575818985553

Epoch: 299| Step: 0
Training loss: 2.296082340405526
Validation loss: 2.5875245853108346

Epoch: 5| Step: 1
Training loss: 2.281784413069528
Validation loss: 2.595420940643387

Epoch: 5| Step: 2
Training loss: 2.171868193910761
Validation loss: 2.5726323818665096

Epoch: 5| Step: 3
Training loss: 2.181359309651937
Validation loss: 2.5808550517932525

Epoch: 5| Step: 4
Training loss: 2.25179409977592
Validation loss: 2.58903513933097

Epoch: 5| Step: 5
Training loss: 2.8385130901239783
Validation loss: 2.5822641615976805

Epoch: 5| Step: 6
Training loss: 2.4397966373620874
Validation loss: 2.5425539537383686

Epoch: 5| Step: 7
Training loss: 2.1008537827550287
Validation loss: 2.5333507393410097

Epoch: 5| Step: 8
Training loss: 2.6275979764403568
Validation loss: 2.494770089432373

Epoch: 5| Step: 9
Training loss: 1.9819960865093746
Validation loss: 2.5030541847634664

Epoch: 5| Step: 10
Training loss: 2.423980978573236
Validation loss: 2.4764011990831465

Epoch: 300| Step: 0
Training loss: 1.9237097689243385
Validation loss: 2.478374975926427

Epoch: 5| Step: 1
Training loss: 2.304976519549878
Validation loss: 2.4643650128582926

Epoch: 5| Step: 2
Training loss: 2.31952959717807
Validation loss: 2.4686923442819992

Epoch: 5| Step: 3
Training loss: 2.4169565772313586
Validation loss: 2.471029856917001

Epoch: 5| Step: 4
Training loss: 2.1029218510407066
Validation loss: 2.49109426452168

Epoch: 5| Step: 5
Training loss: 2.5383758085841954
Validation loss: 2.5101781071452063

Epoch: 5| Step: 6
Training loss: 2.767859036141728
Validation loss: 2.5026805555679923

Epoch: 5| Step: 7
Training loss: 2.5030276085507888
Validation loss: 2.5068489001922822

Epoch: 5| Step: 8
Training loss: 2.146137129626762
Validation loss: 2.5364728798623606

Epoch: 5| Step: 9
Training loss: 2.3419518248492115
Validation loss: 2.540102190899968

Epoch: 5| Step: 10
Training loss: 2.195711690101823
Validation loss: 2.535986724819158

Epoch: 301| Step: 0
Training loss: 2.7668700783037146
Validation loss: 2.5459490180540665

Epoch: 5| Step: 1
Training loss: 2.540525419904254
Validation loss: 2.54923419608618

Epoch: 5| Step: 2
Training loss: 2.3806984450392195
Validation loss: 2.523483426815137

Epoch: 5| Step: 3
Training loss: 2.3360846737839744
Validation loss: 2.5573203909760953

Epoch: 5| Step: 4
Training loss: 2.019753301871578
Validation loss: 2.5940866460666054

Epoch: 5| Step: 5
Training loss: 2.787721284713139
Validation loss: 2.5973387263919583

Epoch: 5| Step: 6
Training loss: 2.3349546067851232
Validation loss: 2.565534700065574

Epoch: 5| Step: 7
Training loss: 2.017972894620756
Validation loss: 2.5572494150137453

Epoch: 5| Step: 8
Training loss: 2.3053616846936227
Validation loss: 2.53720303356692

Epoch: 5| Step: 9
Training loss: 1.9180295977292694
Validation loss: 2.516311347042064

Epoch: 5| Step: 10
Training loss: 1.9658528158018331
Validation loss: 2.5184929622135597

Epoch: 302| Step: 0
Training loss: 2.217809665909787
Validation loss: 2.502929478551777

Epoch: 5| Step: 1
Training loss: 2.4508427980359766
Validation loss: 2.503904612852956

Epoch: 5| Step: 2
Training loss: 2.3752707276888825
Validation loss: 2.531221103743815

Epoch: 5| Step: 3
Training loss: 2.238200613969356
Validation loss: 2.5721236646740153

Epoch: 5| Step: 4
Training loss: 3.0262416088518913
Validation loss: 2.5505332349437073

Epoch: 5| Step: 5
Training loss: 2.213202081699106
Validation loss: 2.5709359521595356

Epoch: 5| Step: 6
Training loss: 2.356894800006381
Validation loss: 2.576984972583845

Epoch: 5| Step: 7
Training loss: 1.874490287163399
Validation loss: 2.5858714892681927

Epoch: 5| Step: 8
Training loss: 2.5287640455895843
Validation loss: 2.57510177438258

Epoch: 5| Step: 9
Training loss: 1.9177903599336767
Validation loss: 2.5548672935978765

Epoch: 5| Step: 10
Training loss: 2.216334357724369
Validation loss: 2.5044746541496865

Epoch: 303| Step: 0
Training loss: 2.6693495923340107
Validation loss: 2.459675647315361

Epoch: 5| Step: 1
Training loss: 2.50540130781394
Validation loss: 2.4406170158291873

Epoch: 5| Step: 2
Training loss: 2.6622436220907804
Validation loss: 2.41181319854065

Epoch: 5| Step: 3
Training loss: 2.4450720525628937
Validation loss: 2.3951488503319887

Epoch: 5| Step: 4
Training loss: 2.320796415171177
Validation loss: 2.396738249745331

Epoch: 5| Step: 5
Training loss: 2.268021151745103
Validation loss: 2.41269073395443

Epoch: 5| Step: 6
Training loss: 2.11301069237621
Validation loss: 2.443874292250117

Epoch: 5| Step: 7
Training loss: 2.3889500353870794
Validation loss: 2.456787149419051

Epoch: 5| Step: 8
Training loss: 2.2602304361393517
Validation loss: 2.495851622995919

Epoch: 5| Step: 9
Training loss: 2.358101709626435
Validation loss: 2.5551014010759814

Epoch: 5| Step: 10
Training loss: 1.5805558471515537
Validation loss: 2.59123613622017

Epoch: 304| Step: 0
Training loss: 2.369762266766177
Validation loss: 2.60441345883059

Epoch: 5| Step: 1
Training loss: 2.500036811557595
Validation loss: 2.580014938359895

Epoch: 5| Step: 2
Training loss: 2.2733466795513713
Validation loss: 2.5937187745455534

Epoch: 5| Step: 3
Training loss: 1.8022176512419692
Validation loss: 2.5758335404750903

Epoch: 5| Step: 4
Training loss: 2.4582522319627227
Validation loss: 2.562744663182683

Epoch: 5| Step: 5
Training loss: 2.235365214708201
Validation loss: 2.5558154380242972

Epoch: 5| Step: 6
Training loss: 2.52435928373835
Validation loss: 2.532769927141965

Epoch: 5| Step: 7
Training loss: 2.069288814020725
Validation loss: 2.555013222846509

Epoch: 5| Step: 8
Training loss: 2.053073263459996
Validation loss: 2.522799789070637

Epoch: 5| Step: 9
Training loss: 2.599543340633886
Validation loss: 2.5152164250489992

Epoch: 5| Step: 10
Training loss: 2.3228961162484913
Validation loss: 2.4896824674931395

Epoch: 305| Step: 0
Training loss: 2.1842703820144624
Validation loss: 2.468753882711817

Epoch: 5| Step: 1
Training loss: 2.7286298286933155
Validation loss: 2.4811102405417356

Epoch: 5| Step: 2
Training loss: 2.3717671526890465
Validation loss: 2.4857729276209835

Epoch: 5| Step: 3
Training loss: 2.130053961522525
Validation loss: 2.4988296722769117

Epoch: 5| Step: 4
Training loss: 2.180151886504695
Validation loss: 2.548889261512903

Epoch: 5| Step: 5
Training loss: 2.6688062210772068
Validation loss: 2.549527019893074

Epoch: 5| Step: 6
Training loss: 2.3960457970217894
Validation loss: 2.5293890714500646

Epoch: 5| Step: 7
Training loss: 2.1467971365633596
Validation loss: 2.5076367466122638

Epoch: 5| Step: 8
Training loss: 1.6512018681571061
Validation loss: 2.4662125510619943

Epoch: 5| Step: 9
Training loss: 2.2904306951237445
Validation loss: 2.4558564620931413

Epoch: 5| Step: 10
Training loss: 2.323302939648087
Validation loss: 2.4504389032180196

Epoch: 306| Step: 0
Training loss: 2.0403922119087716
Validation loss: 2.462585066467116

Epoch: 5| Step: 1
Training loss: 2.3984726893922
Validation loss: 2.440529061584718

Epoch: 5| Step: 2
Training loss: 2.156586772769389
Validation loss: 2.4466703360833684

Epoch: 5| Step: 3
Training loss: 2.5962056863939833
Validation loss: 2.4559154076888423

Epoch: 5| Step: 4
Training loss: 2.334416637534452
Validation loss: 2.4615868663076172

Epoch: 5| Step: 5
Training loss: 2.0663753283662345
Validation loss: 2.4865056917875625

Epoch: 5| Step: 6
Training loss: 2.3288071420306466
Validation loss: 2.5006065401962516

Epoch: 5| Step: 7
Training loss: 2.2179747825613076
Validation loss: 2.527461716495148

Epoch: 5| Step: 8
Training loss: 2.7056981006316048
Validation loss: 2.509261215184914

Epoch: 5| Step: 9
Training loss: 1.2321387205982473
Validation loss: 2.5046104608198263

Epoch: 5| Step: 10
Training loss: 2.8668393955385802
Validation loss: 2.5031173354235294

Epoch: 307| Step: 0
Training loss: 2.4459609856726288
Validation loss: 2.4891426144960596

Epoch: 5| Step: 1
Training loss: 1.9150764737907777
Validation loss: 2.474960769295997

Epoch: 5| Step: 2
Training loss: 2.0811482860007775
Validation loss: 2.47830865940787

Epoch: 5| Step: 3
Training loss: 2.187857680369823
Validation loss: 2.464998565565582

Epoch: 5| Step: 4
Training loss: 2.4880875013487116
Validation loss: 2.459244090799386

Epoch: 5| Step: 5
Training loss: 1.948572453013943
Validation loss: 2.4564464941488486

Epoch: 5| Step: 6
Training loss: 2.455729662887399
Validation loss: 2.431938145871192

Epoch: 5| Step: 7
Training loss: 1.997185455211392
Validation loss: 2.476547210626496

Epoch: 5| Step: 8
Training loss: 2.2637559218516166
Validation loss: 2.451807486959614

Epoch: 5| Step: 9
Training loss: 2.730477569085588
Validation loss: 2.483263292898877

Epoch: 5| Step: 10
Training loss: 2.3188121324630764
Validation loss: 2.4937204918102593

Epoch: 308| Step: 0
Training loss: 2.2700517225044585
Validation loss: 2.519662480562778

Epoch: 5| Step: 1
Training loss: 2.451070325959223
Validation loss: 2.537364853228723

Epoch: 5| Step: 2
Training loss: 2.1634954818279923
Validation loss: 2.5839013812524927

Epoch: 5| Step: 3
Training loss: 2.4974581193896865
Validation loss: 2.6068127638920915

Epoch: 5| Step: 4
Training loss: 2.0067375660196607
Validation loss: 2.577139357327277

Epoch: 5| Step: 5
Training loss: 1.9944038180065677
Validation loss: 2.5490971201198573

Epoch: 5| Step: 6
Training loss: 2.1455081458736087
Validation loss: 2.5403964023635974

Epoch: 5| Step: 7
Training loss: 2.465257516219524
Validation loss: 2.521136720123882

Epoch: 5| Step: 8
Training loss: 2.4079122375387696
Validation loss: 2.507925507460993

Epoch: 5| Step: 9
Training loss: 2.0807991891345328
Validation loss: 2.5078009075256826

Epoch: 5| Step: 10
Training loss: 2.2678568403417603
Validation loss: 2.478710956489081

Epoch: 309| Step: 0
Training loss: 2.317698332232782
Validation loss: 2.4571531294795106

Epoch: 5| Step: 1
Training loss: 2.395491390428576
Validation loss: 2.4617197611601904

Epoch: 5| Step: 2
Training loss: 2.343469730149965
Validation loss: 2.4472402761793632

Epoch: 5| Step: 3
Training loss: 2.3532925448606634
Validation loss: 2.4524336008341985

Epoch: 5| Step: 4
Training loss: 1.8723618067026935
Validation loss: 2.449335236443597

Epoch: 5| Step: 5
Training loss: 1.9447324569779856
Validation loss: 2.4459748814997484

Epoch: 5| Step: 6
Training loss: 2.415720842244109
Validation loss: 2.4637887277514117

Epoch: 5| Step: 7
Training loss: 2.2968562118903666
Validation loss: 2.480994784609055

Epoch: 5| Step: 8
Training loss: 1.9548873884544056
Validation loss: 2.4961689153573245

Epoch: 5| Step: 9
Training loss: 2.320428094007489
Validation loss: 2.519281768339219

Epoch: 5| Step: 10
Training loss: 2.369442209041724
Validation loss: 2.524877438798879

Epoch: 310| Step: 0
Training loss: 2.2862797510245914
Validation loss: 2.540443319324948

Epoch: 5| Step: 1
Training loss: 2.2049037164958776
Validation loss: 2.5407217859295157

Epoch: 5| Step: 2
Training loss: 1.8465704600662434
Validation loss: 2.5316720942540383

Epoch: 5| Step: 3
Training loss: 2.1284246337394213
Validation loss: 2.51119380851902

Epoch: 5| Step: 4
Training loss: 2.4522034681822866
Validation loss: 2.5084124099857865

Epoch: 5| Step: 5
Training loss: 2.8525987388378575
Validation loss: 2.5227641856321488

Epoch: 5| Step: 6
Training loss: 2.061774270660578
Validation loss: 2.482868653468216

Epoch: 5| Step: 7
Training loss: 1.8287565004620427
Validation loss: 2.507937971305115

Epoch: 5| Step: 8
Training loss: 2.4892425835952854
Validation loss: 2.5069952393325474

Epoch: 5| Step: 9
Training loss: 2.183518846895656
Validation loss: 2.4988865803280547

Epoch: 5| Step: 10
Training loss: 2.0208456163590207
Validation loss: 2.5031568489682194

Epoch: 311| Step: 0
Training loss: 2.0785298347525107
Validation loss: 2.4791317119772804

Epoch: 5| Step: 1
Training loss: 2.3751766741441442
Validation loss: 2.4583379169447106

Epoch: 5| Step: 2
Training loss: 2.1352724972571355
Validation loss: 2.4573850733825013

Epoch: 5| Step: 3
Training loss: 2.406238209088654
Validation loss: 2.4649213950895206

Epoch: 5| Step: 4
Training loss: 2.356375499185998
Validation loss: 2.4497062877051903

Epoch: 5| Step: 5
Training loss: 2.488790367178452
Validation loss: 2.46089310196639

Epoch: 5| Step: 6
Training loss: 2.114551437463096
Validation loss: 2.4672939959796034

Epoch: 5| Step: 7
Training loss: 2.2012808365749628
Validation loss: 2.4809639054503534

Epoch: 5| Step: 8
Training loss: 2.086434408715049
Validation loss: 2.5187495236182724

Epoch: 5| Step: 9
Training loss: 1.90299371977515
Validation loss: 2.5129157292016275

Epoch: 5| Step: 10
Training loss: 2.4878878918808094
Validation loss: 2.492802870081403

Epoch: 312| Step: 0
Training loss: 2.2820075880454413
Validation loss: 2.4786129404880475

Epoch: 5| Step: 1
Training loss: 2.125551713119218
Validation loss: 2.469817124464853

Epoch: 5| Step: 2
Training loss: 2.5797081912416426
Validation loss: 2.4650586175009157

Epoch: 5| Step: 3
Training loss: 2.2290010717568234
Validation loss: 2.4512397743962238

Epoch: 5| Step: 4
Training loss: 2.0588494563674087
Validation loss: 2.4367096394968835

Epoch: 5| Step: 5
Training loss: 2.2041430995476885
Validation loss: 2.455445526006851

Epoch: 5| Step: 6
Training loss: 1.987655571181088
Validation loss: 2.4708615669674194

Epoch: 5| Step: 7
Training loss: 2.3329281000928077
Validation loss: 2.4684734799701555

Epoch: 5| Step: 8
Training loss: 1.8961816265174039
Validation loss: 2.4817756535971442

Epoch: 5| Step: 9
Training loss: 2.6344683502780866
Validation loss: 2.504492511208601

Epoch: 5| Step: 10
Training loss: 1.9004553600549325
Validation loss: 2.5044261459247505

Epoch: 313| Step: 0
Training loss: 1.4903507612183897
Validation loss: 2.511386154303392

Epoch: 5| Step: 1
Training loss: 2.0865635307507144
Validation loss: 2.5186998482877714

Epoch: 5| Step: 2
Training loss: 2.5391491684427034
Validation loss: 2.5164265767951193

Epoch: 5| Step: 3
Training loss: 2.212536560446185
Validation loss: 2.5255573288331385

Epoch: 5| Step: 4
Training loss: 2.3619130611456987
Validation loss: 2.5053482407166086

Epoch: 5| Step: 5
Training loss: 2.2903734430716813
Validation loss: 2.5059887946916004

Epoch: 5| Step: 6
Training loss: 1.6613563418598858
Validation loss: 2.4891512143899357

Epoch: 5| Step: 7
Training loss: 2.7837074652695217
Validation loss: 2.504522543945743

Epoch: 5| Step: 8
Training loss: 1.8324317087768736
Validation loss: 2.523810256485473

Epoch: 5| Step: 9
Training loss: 2.048377730299949
Validation loss: 2.5166251787143725

Epoch: 5| Step: 10
Training loss: 2.8123468145403274
Validation loss: 2.51022038343236

Epoch: 314| Step: 0
Training loss: 2.4488081154345807
Validation loss: 2.4984751994020398

Epoch: 5| Step: 1
Training loss: 2.2132628381180766
Validation loss: 2.4793157707607714

Epoch: 5| Step: 2
Training loss: 1.9546338776110377
Validation loss: 2.4631855780652305

Epoch: 5| Step: 3
Training loss: 2.0747482284940997
Validation loss: 2.4650584750220412

Epoch: 5| Step: 4
Training loss: 2.417445999852102
Validation loss: 2.462256991148197

Epoch: 5| Step: 5
Training loss: 2.5600320980920763
Validation loss: 2.463414828381269

Epoch: 5| Step: 6
Training loss: 2.1983251568707507
Validation loss: 2.469997209862318

Epoch: 5| Step: 7
Training loss: 2.290305363314369
Validation loss: 2.4720326898248373

Epoch: 5| Step: 8
Training loss: 1.8766467174781938
Validation loss: 2.4809137473750624

Epoch: 5| Step: 9
Training loss: 2.1209014187159614
Validation loss: 2.477884352024931

Epoch: 5| Step: 10
Training loss: 1.981474731888702
Validation loss: 2.4876300324518796

Epoch: 315| Step: 0
Training loss: 2.2036694875151035
Validation loss: 2.4982623090824085

Epoch: 5| Step: 1
Training loss: 1.9593941135478106
Validation loss: 2.4880171799397792

Epoch: 5| Step: 2
Training loss: 2.3798894244240323
Validation loss: 2.4766874769963416

Epoch: 5| Step: 3
Training loss: 2.55342271392728
Validation loss: 2.510002574554092

Epoch: 5| Step: 4
Training loss: 1.8754641276350823
Validation loss: 2.489138583349948

Epoch: 5| Step: 5
Training loss: 2.2729527326939807
Validation loss: 2.491431778331584

Epoch: 5| Step: 6
Training loss: 2.3290888692002123
Validation loss: 2.5142936855024534

Epoch: 5| Step: 7
Training loss: 1.772281353893105
Validation loss: 2.4862301071719797

Epoch: 5| Step: 8
Training loss: 1.9079760882000882
Validation loss: 2.505826044556737

Epoch: 5| Step: 9
Training loss: 2.2855250395189963
Validation loss: 2.4947930758443997

Epoch: 5| Step: 10
Training loss: 2.63425584842655
Validation loss: 2.4825229821853885

Epoch: 316| Step: 0
Training loss: 2.5077524148273223
Validation loss: 2.469321966471222

Epoch: 5| Step: 1
Training loss: 2.4146646779412193
Validation loss: 2.4848395885959658

Epoch: 5| Step: 2
Training loss: 2.051711563540504
Validation loss: 2.472445955976008

Epoch: 5| Step: 3
Training loss: 2.1104524474454447
Validation loss: 2.4869181486295138

Epoch: 5| Step: 4
Training loss: 2.3372780515999207
Validation loss: 2.4899635973613257

Epoch: 5| Step: 5
Training loss: 2.3096046880700234
Validation loss: 2.4931681570595123

Epoch: 5| Step: 6
Training loss: 1.6195327044791918
Validation loss: 2.4724801438919957

Epoch: 5| Step: 7
Training loss: 2.3799795851913803
Validation loss: 2.4702760811709195

Epoch: 5| Step: 8
Training loss: 2.2286020675062135
Validation loss: 2.4609198706835826

Epoch: 5| Step: 9
Training loss: 1.502174787695725
Validation loss: 2.453814897362989

Epoch: 5| Step: 10
Training loss: 2.522714328185917
Validation loss: 2.4442032690467363

Epoch: 317| Step: 0
Training loss: 2.1322540558176986
Validation loss: 2.4731117908085913

Epoch: 5| Step: 1
Training loss: 1.8538853364030894
Validation loss: 2.496116681086443

Epoch: 5| Step: 2
Training loss: 2.5513648961692135
Validation loss: 2.469446281624579

Epoch: 5| Step: 3
Training loss: 1.8691317598935864
Validation loss: 2.515305032204556

Epoch: 5| Step: 4
Training loss: 2.101983010576372
Validation loss: 2.540690989929479

Epoch: 5| Step: 5
Training loss: 2.611245404390534
Validation loss: 2.5614532505749237

Epoch: 5| Step: 6
Training loss: 1.9116631241388375
Validation loss: 2.5399335701381474

Epoch: 5| Step: 7
Training loss: 2.234290701603088
Validation loss: 2.532034809647562

Epoch: 5| Step: 8
Training loss: 1.94210857989042
Validation loss: 2.484211678017814

Epoch: 5| Step: 9
Training loss: 2.4268551720598337
Validation loss: 2.4961063273577726

Epoch: 5| Step: 10
Training loss: 2.4118739210108084
Validation loss: 2.463203713114498

Epoch: 318| Step: 0
Training loss: 2.4976950510284737
Validation loss: 2.4538584858108843

Epoch: 5| Step: 1
Training loss: 2.3808990299968706
Validation loss: 2.4692307011111567

Epoch: 5| Step: 2
Training loss: 2.09842694720855
Validation loss: 2.4640662198452814

Epoch: 5| Step: 3
Training loss: 2.0996768248613553
Validation loss: 2.4732393044779855

Epoch: 5| Step: 4
Training loss: 2.2054960870078935
Validation loss: 2.455870033651709

Epoch: 5| Step: 5
Training loss: 2.1589265879473523
Validation loss: 2.4585053780158392

Epoch: 5| Step: 6
Training loss: 2.076955824917137
Validation loss: 2.4681307025111336

Epoch: 5| Step: 7
Training loss: 1.3798451455625091
Validation loss: 2.5112498116157673

Epoch: 5| Step: 8
Training loss: 2.25844282703608
Validation loss: 2.4905616872327916

Epoch: 5| Step: 9
Training loss: 2.450719346300399
Validation loss: 2.523699088903733

Epoch: 5| Step: 10
Training loss: 2.0251309293640483
Validation loss: 2.515405794015975

Epoch: 319| Step: 0
Training loss: 1.9820610432082828
Validation loss: 2.505611492043395

Epoch: 5| Step: 1
Training loss: 2.7589006303491375
Validation loss: 2.519280720203025

Epoch: 5| Step: 2
Training loss: 2.115360386582984
Validation loss: 2.5238437486221956

Epoch: 5| Step: 3
Training loss: 2.3781689032012254
Validation loss: 2.526324651708015

Epoch: 5| Step: 4
Training loss: 2.4733207014777516
Validation loss: 2.5212587916033593

Epoch: 5| Step: 5
Training loss: 2.114224771501349
Validation loss: 2.524279371031389

Epoch: 5| Step: 6
Training loss: 2.286855942572968
Validation loss: 2.5153063052057636

Epoch: 5| Step: 7
Training loss: 1.8544480899591855
Validation loss: 2.498280544048237

Epoch: 5| Step: 8
Training loss: 1.2352344562978526
Validation loss: 2.466955897272964

Epoch: 5| Step: 9
Training loss: 2.260674902818924
Validation loss: 2.4570213544739468

Epoch: 5| Step: 10
Training loss: 1.9980866697642339
Validation loss: 2.453928037251586

Epoch: 320| Step: 0
Training loss: 1.7919512751843694
Validation loss: 2.4612480752804586

Epoch: 5| Step: 1
Training loss: 2.1670355360552738
Validation loss: 2.477844945536537

Epoch: 5| Step: 2
Training loss: 2.583108789673232
Validation loss: 2.4972863400068603

Epoch: 5| Step: 3
Training loss: 2.2666356430548555
Validation loss: 2.500872499741146

Epoch: 5| Step: 4
Training loss: 2.3847422305747474
Validation loss: 2.5115480848057055

Epoch: 5| Step: 5
Training loss: 2.4240404845970653
Validation loss: 2.504049199832536

Epoch: 5| Step: 6
Training loss: 2.118462097952528
Validation loss: 2.553990898581152

Epoch: 5| Step: 7
Training loss: 1.7938855056885685
Validation loss: 2.5568076295656663

Epoch: 5| Step: 8
Training loss: 1.6299822064464107
Validation loss: 2.5771267327701675

Epoch: 5| Step: 9
Training loss: 2.3268882999864893
Validation loss: 2.563923764115966

Epoch: 5| Step: 10
Training loss: 2.0319205717798057
Validation loss: 2.548091354125649

Epoch: 321| Step: 0
Training loss: 2.3192380735932208
Validation loss: 2.5279421875322146

Epoch: 5| Step: 1
Training loss: 2.2142146863840195
Validation loss: 2.492104634041971

Epoch: 5| Step: 2
Training loss: 2.2499325000386623
Validation loss: 2.4963624640021846

Epoch: 5| Step: 3
Training loss: 2.378285795332383
Validation loss: 2.4752323419858024

Epoch: 5| Step: 4
Training loss: 1.9317663940587122
Validation loss: 2.461650952665395

Epoch: 5| Step: 5
Training loss: 2.0635530500051473
Validation loss: 2.455645956060887

Epoch: 5| Step: 6
Training loss: 1.4235169707808455
Validation loss: 2.4431552559887835

Epoch: 5| Step: 7
Training loss: 2.250172608430454
Validation loss: 2.45605532213298

Epoch: 5| Step: 8
Training loss: 2.297104389387785
Validation loss: 2.4934277458087473

Epoch: 5| Step: 9
Training loss: 1.9571415609309704
Validation loss: 2.5234354061635003

Epoch: 5| Step: 10
Training loss: 2.399479245273552
Validation loss: 2.535095757155621

Epoch: 322| Step: 0
Training loss: 1.7439009105503906
Validation loss: 2.555521482909583

Epoch: 5| Step: 1
Training loss: 2.116807065898033
Validation loss: 2.5619567547370963

Epoch: 5| Step: 2
Training loss: 2.2315445692161724
Validation loss: 2.541480075866742

Epoch: 5| Step: 3
Training loss: 1.5701319652421406
Validation loss: 2.5349177165790033

Epoch: 5| Step: 4
Training loss: 2.3367830615183602
Validation loss: 2.5333873415415997

Epoch: 5| Step: 5
Training loss: 2.3265049565399973
Validation loss: 2.5195998738062766

Epoch: 5| Step: 6
Training loss: 2.083365122234685
Validation loss: 2.505356455492082

Epoch: 5| Step: 7
Training loss: 2.182072145138225
Validation loss: 2.487000278219436

Epoch: 5| Step: 8
Training loss: 2.344954626136488
Validation loss: 2.4952671617694646

Epoch: 5| Step: 9
Training loss: 1.9447106958691958
Validation loss: 2.4821189749211596

Epoch: 5| Step: 10
Training loss: 2.442468226059213
Validation loss: 2.455098865201587

Epoch: 323| Step: 0
Training loss: 2.41460474337767
Validation loss: 2.4429025131832285

Epoch: 5| Step: 1
Training loss: 2.1119928010687814
Validation loss: 2.446806133464486

Epoch: 5| Step: 2
Training loss: 2.687011674384994
Validation loss: 2.4539985467812007

Epoch: 5| Step: 3
Training loss: 1.8280031212502508
Validation loss: 2.483779156780229

Epoch: 5| Step: 4
Training loss: 2.2580027780574876
Validation loss: 2.467652898102157

Epoch: 5| Step: 5
Training loss: 1.8455858304330137
Validation loss: 2.454541888924435

Epoch: 5| Step: 6
Training loss: 2.234213976626516
Validation loss: 2.505754456112268

Epoch: 5| Step: 7
Training loss: 1.7547895420530644
Validation loss: 2.498567145951663

Epoch: 5| Step: 8
Training loss: 2.247368333161309
Validation loss: 2.535196897306407

Epoch: 5| Step: 9
Training loss: 2.1213412482935
Validation loss: 2.525105286820226

Epoch: 5| Step: 10
Training loss: 1.6432907246114037
Validation loss: 2.5098760594048337

Epoch: 324| Step: 0
Training loss: 1.737311686458288
Validation loss: 2.510414211016862

Epoch: 5| Step: 1
Training loss: 2.125561135198264
Validation loss: 2.4833034692248543

Epoch: 5| Step: 2
Training loss: 2.2117198193546512
Validation loss: 2.49314658291228

Epoch: 5| Step: 3
Training loss: 1.71493265881688
Validation loss: 2.4935436474997927

Epoch: 5| Step: 4
Training loss: 2.3740277559028495
Validation loss: 2.5182729471387426

Epoch: 5| Step: 5
Training loss: 2.1728906246488826
Validation loss: 2.527228761373561

Epoch: 5| Step: 6
Training loss: 2.2882535891751163
Validation loss: 2.531955987679742

Epoch: 5| Step: 7
Training loss: 2.025380030634659
Validation loss: 2.5558135141511893

Epoch: 5| Step: 8
Training loss: 1.9754003191501306
Validation loss: 2.567526075374513

Epoch: 5| Step: 9
Training loss: 2.091637869810181
Validation loss: 2.556493306514669

Epoch: 5| Step: 10
Training loss: 2.545677137395885
Validation loss: 2.5392038593430106

Epoch: 325| Step: 0
Training loss: 2.316956427403592
Validation loss: 2.5172550701192193

Epoch: 5| Step: 1
Training loss: 1.9716204350464057
Validation loss: 2.4774473485868005

Epoch: 5| Step: 2
Training loss: 2.3130134837231298
Validation loss: 2.483957981208402

Epoch: 5| Step: 3
Training loss: 2.333473666830265
Validation loss: 2.4739743768574436

Epoch: 5| Step: 4
Training loss: 1.5909128554411105
Validation loss: 2.4671190813789767

Epoch: 5| Step: 5
Training loss: 2.2533817309010677
Validation loss: 2.464523861256916

Epoch: 5| Step: 6
Training loss: 2.167586339267133
Validation loss: 2.4629115867004088

Epoch: 5| Step: 7
Training loss: 1.9045056976850052
Validation loss: 2.5016297278703226

Epoch: 5| Step: 8
Training loss: 1.687586322978372
Validation loss: 2.495725254382036

Epoch: 5| Step: 9
Training loss: 2.365059276749283
Validation loss: 2.4967926519225987

Epoch: 5| Step: 10
Training loss: 2.1504675689430157
Validation loss: 2.5028169092573482

Epoch: 326| Step: 0
Training loss: 2.052484760297543
Validation loss: 2.530501677003103

Epoch: 5| Step: 1
Training loss: 1.8771421275808264
Validation loss: 2.5336865449542563

Epoch: 5| Step: 2
Training loss: 2.337179816853503
Validation loss: 2.518544460622701

Epoch: 5| Step: 3
Training loss: 2.0389475589086974
Validation loss: 2.4990831950063037

Epoch: 5| Step: 4
Training loss: 2.0768473433410373
Validation loss: 2.4909307861690486

Epoch: 5| Step: 5
Training loss: 1.997687075261109
Validation loss: 2.4663131616732388

Epoch: 5| Step: 6
Training loss: 2.3038983561890563
Validation loss: 2.4340167613782207

Epoch: 5| Step: 7
Training loss: 2.0288504879662157
Validation loss: 2.4815952287233674

Epoch: 5| Step: 8
Training loss: 2.123362190533565
Validation loss: 2.4832289385636837

Epoch: 5| Step: 9
Training loss: 2.2781285917779686
Validation loss: 2.47095960824138

Epoch: 5| Step: 10
Training loss: 1.9947857835913643
Validation loss: 2.513232837991968

Epoch: 327| Step: 0
Training loss: 2.621504136091888
Validation loss: 2.5564671735237248

Epoch: 5| Step: 1
Training loss: 1.976317017279694
Validation loss: 2.5700072123325493

Epoch: 5| Step: 2
Training loss: 2.3479139849814734
Validation loss: 2.5720734792452586

Epoch: 5| Step: 3
Training loss: 2.06853722806371
Validation loss: 2.5647200045270897

Epoch: 5| Step: 4
Training loss: 2.052872120512203
Validation loss: 2.541689456237047

Epoch: 5| Step: 5
Training loss: 1.7535033581007844
Validation loss: 2.5398870959505015

Epoch: 5| Step: 6
Training loss: 2.1649191362463394
Validation loss: 2.533059318586433

Epoch: 5| Step: 7
Training loss: 1.9754793116655212
Validation loss: 2.5244594175823543

Epoch: 5| Step: 8
Training loss: 1.898453951791819
Validation loss: 2.5309829581180066

Epoch: 5| Step: 9
Training loss: 1.9467656479889142
Validation loss: 2.5074081659744616

Epoch: 5| Step: 10
Training loss: 2.207473467519428
Validation loss: 2.4900348871841778

Epoch: 328| Step: 0
Training loss: 1.84455537178395
Validation loss: 2.475226290800842

Epoch: 5| Step: 1
Training loss: 2.119184164839294
Validation loss: 2.4902595311888236

Epoch: 5| Step: 2
Training loss: 1.847556500635575
Validation loss: 2.486819232440462

Epoch: 5| Step: 3
Training loss: 1.9739624533362827
Validation loss: 2.488184225071968

Epoch: 5| Step: 4
Training loss: 2.6576966777953706
Validation loss: 2.4997587026003245

Epoch: 5| Step: 5
Training loss: 1.3586116269708457
Validation loss: 2.506035505716145

Epoch: 5| Step: 6
Training loss: 2.36372025881111
Validation loss: 2.4836198357256456

Epoch: 5| Step: 7
Training loss: 1.897262020944114
Validation loss: 2.462174655728107

Epoch: 5| Step: 8
Training loss: 2.102017831931803
Validation loss: 2.4592865958366636

Epoch: 5| Step: 9
Training loss: 2.3542685922709037
Validation loss: 2.473360505509411

Epoch: 5| Step: 10
Training loss: 2.204942210817702
Validation loss: 2.4885829622140125

Epoch: 329| Step: 0
Training loss: 2.174274354224357
Validation loss: 2.5352954023327863

Epoch: 5| Step: 1
Training loss: 2.0624351491269364
Validation loss: 2.5396329959818367

Epoch: 5| Step: 2
Training loss: 1.7173843506990865
Validation loss: 2.5464806607812105

Epoch: 5| Step: 3
Training loss: 1.9073356913623458
Validation loss: 2.535009843105303

Epoch: 5| Step: 4
Training loss: 2.3410684122276266
Validation loss: 2.523186804320692

Epoch: 5| Step: 5
Training loss: 1.7400314606639564
Validation loss: 2.5241932645355476

Epoch: 5| Step: 6
Training loss: 1.7540676662872583
Validation loss: 2.5122772618039617

Epoch: 5| Step: 7
Training loss: 2.496362710470288
Validation loss: 2.52067362388654

Epoch: 5| Step: 8
Training loss: 2.3011450487994045
Validation loss: 2.4863386029658736

Epoch: 5| Step: 9
Training loss: 2.1946115698397213
Validation loss: 2.488659178524449

Epoch: 5| Step: 10
Training loss: 2.2189152615747445
Validation loss: 2.480710999320035

Epoch: 330| Step: 0
Training loss: 1.8546401572994227
Validation loss: 2.4999700503452433

Epoch: 5| Step: 1
Training loss: 1.8205817682415464
Validation loss: 2.529200035867494

Epoch: 5| Step: 2
Training loss: 2.081599951296783
Validation loss: 2.5583059803339956

Epoch: 5| Step: 3
Training loss: 2.5065218732828
Validation loss: 2.605574049776399

Epoch: 5| Step: 4
Training loss: 1.5678496524148975
Validation loss: 2.6317411005010585

Epoch: 5| Step: 5
Training loss: 2.336353277757619
Validation loss: 2.6225049622557375

Epoch: 5| Step: 6
Training loss: 2.49414339715121
Validation loss: 2.6005000971310883

Epoch: 5| Step: 7
Training loss: 2.097770247389771
Validation loss: 2.5050346470019123

Epoch: 5| Step: 8
Training loss: 2.1082219115758396
Validation loss: 2.4490562081873986

Epoch: 5| Step: 9
Training loss: 1.9738766964527121
Validation loss: 2.459773419989864

Epoch: 5| Step: 10
Training loss: 2.2438871208944353
Validation loss: 2.4324212446982174

Epoch: 331| Step: 0
Training loss: 2.3750461774653506
Validation loss: 2.4475877693181927

Epoch: 5| Step: 1
Training loss: 1.5769541712302233
Validation loss: 2.450811288449416

Epoch: 5| Step: 2
Training loss: 2.177387295422001
Validation loss: 2.467035110483695

Epoch: 5| Step: 3
Training loss: 2.5537072030326424
Validation loss: 2.493253951033254

Epoch: 5| Step: 4
Training loss: 1.939077596428914
Validation loss: 2.506449138700423

Epoch: 5| Step: 5
Training loss: 2.018566853154861
Validation loss: 2.559926645489929

Epoch: 5| Step: 6
Training loss: 2.0234591803254545
Validation loss: 2.5719053986199887

Epoch: 5| Step: 7
Training loss: 1.9768409985136743
Validation loss: 2.6212714064301417

Epoch: 5| Step: 8
Training loss: 2.593532599105099
Validation loss: 2.682562892703968

Epoch: 5| Step: 9
Training loss: 2.105241129785036
Validation loss: 2.6784856803829937

Epoch: 5| Step: 10
Training loss: 1.7783930437359519
Validation loss: 2.635546895582687

Epoch: 332| Step: 0
Training loss: 1.575870754591763
Validation loss: 2.589854618885473

Epoch: 5| Step: 1
Training loss: 1.6651646362563142
Validation loss: 2.5410416253300094

Epoch: 5| Step: 2
Training loss: 1.986394260322
Validation loss: 2.4936400094907083

Epoch: 5| Step: 3
Training loss: 1.7391676110979608
Validation loss: 2.447452148335407

Epoch: 5| Step: 4
Training loss: 2.158150319277632
Validation loss: 2.4383126054157716

Epoch: 5| Step: 5
Training loss: 2.183116772033056
Validation loss: 2.436846369634355

Epoch: 5| Step: 6
Training loss: 2.3579508544291325
Validation loss: 2.4264500176491848

Epoch: 5| Step: 7
Training loss: 2.4487691706967767
Validation loss: 2.416903568688748

Epoch: 5| Step: 8
Training loss: 2.0568783759405576
Validation loss: 2.4336679825513725

Epoch: 5| Step: 9
Training loss: 2.645010111740773
Validation loss: 2.4406715355332143

Epoch: 5| Step: 10
Training loss: 1.8937994418598738
Validation loss: 2.4572035326096118

Epoch: 333| Step: 0
Training loss: 2.5470721396694236
Validation loss: 2.494160392827373

Epoch: 5| Step: 1
Training loss: 1.852838583518299
Validation loss: 2.523654197095871

Epoch: 5| Step: 2
Training loss: 1.8039306110308297
Validation loss: 2.5534474263044773

Epoch: 5| Step: 3
Training loss: 2.0176692325372585
Validation loss: 2.566234401627524

Epoch: 5| Step: 4
Training loss: 2.071341780549648
Validation loss: 2.543311865748543

Epoch: 5| Step: 5
Training loss: 1.829669332699123
Validation loss: 2.5332551400347603

Epoch: 5| Step: 6
Training loss: 2.224946945072226
Validation loss: 2.528277487119564

Epoch: 5| Step: 7
Training loss: 2.2172886508829266
Validation loss: 2.5041556101149127

Epoch: 5| Step: 8
Training loss: 2.1513318350264314
Validation loss: 2.513198102772506

Epoch: 5| Step: 9
Training loss: 2.1854653841836726
Validation loss: 2.5350819271277545

Epoch: 5| Step: 10
Training loss: 1.7653367473971688
Validation loss: 2.5385516292782118

Epoch: 334| Step: 0
Training loss: 2.032284517208828
Validation loss: 2.5696336787577128

Epoch: 5| Step: 1
Training loss: 2.0773991055553593
Validation loss: 2.5706498767787807

Epoch: 5| Step: 2
Training loss: 2.556388918359333
Validation loss: 2.5925798362435035

Epoch: 5| Step: 3
Training loss: 2.2492177451139104
Validation loss: 2.5564434229559554

Epoch: 5| Step: 4
Training loss: 1.958280609990302
Validation loss: 2.5318488563799417

Epoch: 5| Step: 5
Training loss: 1.2897078314829211
Validation loss: 2.534259183826508

Epoch: 5| Step: 6
Training loss: 1.897115678931102
Validation loss: 2.51292259606204

Epoch: 5| Step: 7
Training loss: 2.684576706863065
Validation loss: 2.5317564416769356

Epoch: 5| Step: 8
Training loss: 2.1009657909616855
Validation loss: 2.5089669279329585

Epoch: 5| Step: 9
Training loss: 1.6457464299818778
Validation loss: 2.5139048728494395

Epoch: 5| Step: 10
Training loss: 1.8032793769003668
Validation loss: 2.4914473323881787

Epoch: 335| Step: 0
Training loss: 1.8263631302339038
Validation loss: 2.480217711290059

Epoch: 5| Step: 1
Training loss: 2.0184183799073114
Validation loss: 2.473763157518657

Epoch: 5| Step: 2
Training loss: 2.405782579873908
Validation loss: 2.4950575805759545

Epoch: 5| Step: 3
Training loss: 2.237505127458718
Validation loss: 2.5029245938699565

Epoch: 5| Step: 4
Training loss: 1.8562933765827718
Validation loss: 2.528825774628057

Epoch: 5| Step: 5
Training loss: 2.356964092164004
Validation loss: 2.532686091240571

Epoch: 5| Step: 6
Training loss: 2.001005873458455
Validation loss: 2.521367668228584

Epoch: 5| Step: 7
Training loss: 1.389367381429784
Validation loss: 2.4958754396568334

Epoch: 5| Step: 8
Training loss: 2.0611764533603636
Validation loss: 2.5003554850275664

Epoch: 5| Step: 9
Training loss: 1.9322091125237075
Validation loss: 2.50126673282528

Epoch: 5| Step: 10
Training loss: 2.212839232047468
Validation loss: 2.4855949794696524

Epoch: 336| Step: 0
Training loss: 1.9857664261193417
Validation loss: 2.4949140312963833

Epoch: 5| Step: 1
Training loss: 2.110226494623755
Validation loss: 2.4936972857895703

Epoch: 5| Step: 2
Training loss: 1.935494523249815
Validation loss: 2.4604810138668234

Epoch: 5| Step: 3
Training loss: 2.1070862963384496
Validation loss: 2.4407137469220954

Epoch: 5| Step: 4
Training loss: 1.8506828826231418
Validation loss: 2.4278558646512427

Epoch: 5| Step: 5
Training loss: 2.0411056863727355
Validation loss: 2.4318603258231555

Epoch: 5| Step: 6
Training loss: 1.7489611403181655
Validation loss: 2.4303216369464153

Epoch: 5| Step: 7
Training loss: 2.187444195716773
Validation loss: 2.451840583509721

Epoch: 5| Step: 8
Training loss: 2.1385874831737084
Validation loss: 2.4812572530492343

Epoch: 5| Step: 9
Training loss: 1.9491802204123478
Validation loss: 2.527569719391656

Epoch: 5| Step: 10
Training loss: 2.4479132036766287
Validation loss: 2.5648192233330205

Epoch: 337| Step: 0
Training loss: 1.8578963611306183
Validation loss: 2.6408722483784604

Epoch: 5| Step: 1
Training loss: 2.103899369085132
Validation loss: 2.659366192253682

Epoch: 5| Step: 2
Training loss: 1.2842018734716139
Validation loss: 2.6498278197595777

Epoch: 5| Step: 3
Training loss: 2.053323735528453
Validation loss: 2.618952151319016

Epoch: 5| Step: 4
Training loss: 2.1990442020402536
Validation loss: 2.591452808760662

Epoch: 5| Step: 5
Training loss: 2.4640682590492307
Validation loss: 2.5306481664165217

Epoch: 5| Step: 6
Training loss: 1.911670794273295
Validation loss: 2.495101955314265

Epoch: 5| Step: 7
Training loss: 2.138228808628608
Validation loss: 2.458446729146735

Epoch: 5| Step: 8
Training loss: 2.2084514538345847
Validation loss: 2.4420503340167183

Epoch: 5| Step: 9
Training loss: 1.8336137716064096
Validation loss: 2.4269831058982625

Epoch: 5| Step: 10
Training loss: 2.363948305426487
Validation loss: 2.4255061857027975

Epoch: 338| Step: 0
Training loss: 2.2356516785345555
Validation loss: 2.4214957933740453

Epoch: 5| Step: 1
Training loss: 2.054950769767542
Validation loss: 2.4220676987195024

Epoch: 5| Step: 2
Training loss: 1.9375899509345744
Validation loss: 2.411530053075901

Epoch: 5| Step: 3
Training loss: 1.9091818104607763
Validation loss: 2.417291256775143

Epoch: 5| Step: 4
Training loss: 1.511043427313489
Validation loss: 2.419148583319592

Epoch: 5| Step: 5
Training loss: 2.1617884617447007
Validation loss: 2.431075447097419

Epoch: 5| Step: 6
Training loss: 2.0832325974587538
Validation loss: 2.5049100506448645

Epoch: 5| Step: 7
Training loss: 2.018728897409598
Validation loss: 2.5530257068327553

Epoch: 5| Step: 8
Training loss: 2.280030120349494
Validation loss: 2.6165278581015796

Epoch: 5| Step: 9
Training loss: 2.2172668227777894
Validation loss: 2.6162255762738686

Epoch: 5| Step: 10
Training loss: 2.062380700562516
Validation loss: 2.546565813343872

Epoch: 339| Step: 0
Training loss: 2.088521778142004
Validation loss: 2.4988064336805818

Epoch: 5| Step: 1
Training loss: 1.6456542903555043
Validation loss: 2.519251861687733

Epoch: 5| Step: 2
Training loss: 2.0749354157105993
Validation loss: 2.48847870878666

Epoch: 5| Step: 3
Training loss: 1.8231458102121698
Validation loss: 2.5060364888060342

Epoch: 5| Step: 4
Training loss: 1.5821501510584843
Validation loss: 2.505170602398992

Epoch: 5| Step: 5
Training loss: 2.3540831581990798
Validation loss: 2.5247137718698647

Epoch: 5| Step: 6
Training loss: 1.879751035356953
Validation loss: 2.5381335173404107

Epoch: 5| Step: 7
Training loss: 1.829262599587304
Validation loss: 2.5267109494986992

Epoch: 5| Step: 8
Training loss: 2.5392612790278526
Validation loss: 2.5285319516024227

Epoch: 5| Step: 9
Training loss: 2.2020485053891683
Validation loss: 2.5227273083704858

Epoch: 5| Step: 10
Training loss: 1.956586654019259
Validation loss: 2.512848624572532

Epoch: 340| Step: 0
Training loss: 1.7353034069139728
Validation loss: 2.545449760073537

Epoch: 5| Step: 1
Training loss: 2.284948721045266
Validation loss: 2.5788759352946027

Epoch: 5| Step: 2
Training loss: 2.0968972081288917
Validation loss: 2.576060682106592

Epoch: 5| Step: 3
Training loss: 1.7923175900911088
Validation loss: 2.5694133752971178

Epoch: 5| Step: 4
Training loss: 1.9544477942426404
Validation loss: 2.582687703795248

Epoch: 5| Step: 5
Training loss: 2.1130179137135388
Validation loss: 2.5474726729783157

Epoch: 5| Step: 6
Training loss: 2.1590515954485854
Validation loss: 2.514133999773978

Epoch: 5| Step: 7
Training loss: 1.8587525552040705
Validation loss: 2.4781553353603907

Epoch: 5| Step: 8
Training loss: 1.7016804019374892
Validation loss: 2.4668540564410897

Epoch: 5| Step: 9
Training loss: 1.801528874767511
Validation loss: 2.452018101919585

Epoch: 5| Step: 10
Training loss: 2.4703815718373616
Validation loss: 2.4497929821486304

Epoch: 341| Step: 0
Training loss: 2.1864465629281415
Validation loss: 2.482181347560976

Epoch: 5| Step: 1
Training loss: 2.284805140460934
Validation loss: 2.5060811468687847

Epoch: 5| Step: 2
Training loss: 1.5097346728311676
Validation loss: 2.52097918187588

Epoch: 5| Step: 3
Training loss: 2.2118407652038776
Validation loss: 2.5403291971407302

Epoch: 5| Step: 4
Training loss: 2.1233627519510865
Validation loss: 2.5732712524787558

Epoch: 5| Step: 5
Training loss: 2.0491948849520565
Validation loss: 2.565627138104127

Epoch: 5| Step: 6
Training loss: 1.6434603940011425
Validation loss: 2.545649234729312

Epoch: 5| Step: 7
Training loss: 2.1808018177492285
Validation loss: 2.536289759737153

Epoch: 5| Step: 8
Training loss: 2.112914104616837
Validation loss: 2.5067243740696608

Epoch: 5| Step: 9
Training loss: 1.7766284886755817
Validation loss: 2.5125721520659363

Epoch: 5| Step: 10
Training loss: 1.5956922178234174
Validation loss: 2.5016159741500306

Epoch: 342| Step: 0
Training loss: 1.8118453323340769
Validation loss: 2.534651327122699

Epoch: 5| Step: 1
Training loss: 1.934533093328871
Validation loss: 2.533022066946086

Epoch: 5| Step: 2
Training loss: 1.867231232837255
Validation loss: 2.5361063756972184

Epoch: 5| Step: 3
Training loss: 2.2833820987515265
Validation loss: 2.53254055888703

Epoch: 5| Step: 4
Training loss: 1.645012864291551
Validation loss: 2.5281813430951954

Epoch: 5| Step: 5
Training loss: 1.8443407954861295
Validation loss: 2.5449269268820056

Epoch: 5| Step: 6
Training loss: 2.0163114103459345
Validation loss: 2.577600738430482

Epoch: 5| Step: 7
Training loss: 2.231065446503264
Validation loss: 2.55633768693015

Epoch: 5| Step: 8
Training loss: 1.9050327229129853
Validation loss: 2.544857641183599

Epoch: 5| Step: 9
Training loss: 2.091419574180684
Validation loss: 2.5399824214211075

Epoch: 5| Step: 10
Training loss: 1.790178775277719
Validation loss: 2.498523740821654

Epoch: 343| Step: 0
Training loss: 1.9107900242889058
Validation loss: 2.4689234855260187

Epoch: 5| Step: 1
Training loss: 2.0487720347273295
Validation loss: 2.4634911875125467

Epoch: 5| Step: 2
Training loss: 1.9891823036571126
Validation loss: 2.4600739468759527

Epoch: 5| Step: 3
Training loss: 2.1323471959096643
Validation loss: 2.4539831105564245

Epoch: 5| Step: 4
Training loss: 2.465051995864524
Validation loss: 2.480077627524617

Epoch: 5| Step: 5
Training loss: 2.269502360542517
Validation loss: 2.480974821465711

Epoch: 5| Step: 6
Training loss: 1.9840270210394928
Validation loss: 2.480702368616169

Epoch: 5| Step: 7
Training loss: 1.4087195011821425
Validation loss: 2.5045484102987854

Epoch: 5| Step: 8
Training loss: 1.7572582812285766
Validation loss: 2.5478902635618392

Epoch: 5| Step: 9
Training loss: 1.7262197991559964
Validation loss: 2.6021921606132485

Epoch: 5| Step: 10
Training loss: 1.965215325533327
Validation loss: 2.6187489073284094

Epoch: 344| Step: 0
Training loss: 2.0193435316074924
Validation loss: 2.5945677601703423

Epoch: 5| Step: 1
Training loss: 1.6792878851036555
Validation loss: 2.5534260421906034

Epoch: 5| Step: 2
Training loss: 2.219889066347332
Validation loss: 2.5687640072850573

Epoch: 5| Step: 3
Training loss: 1.8469209720163393
Validation loss: 2.5435537564450796

Epoch: 5| Step: 4
Training loss: 2.0734796446460417
Validation loss: 2.561307568134433

Epoch: 5| Step: 5
Training loss: 1.9395554007524225
Validation loss: 2.5282798993936098

Epoch: 5| Step: 6
Training loss: 2.1761504977998896
Validation loss: 2.5604821240418585

Epoch: 5| Step: 7
Training loss: 1.625635609663646
Validation loss: 2.5832396540558187

Epoch: 5| Step: 8
Training loss: 2.257220550341619
Validation loss: 2.5610599468252944

Epoch: 5| Step: 9
Training loss: 1.7939890366626468
Validation loss: 2.5456209641732

Epoch: 5| Step: 10
Training loss: 1.9003979015309047
Validation loss: 2.5252559135398123

Epoch: 345| Step: 0
Training loss: 2.1711419055233763
Validation loss: 2.5387262502550136

Epoch: 5| Step: 1
Training loss: 2.4435192028436217
Validation loss: 2.517539020079559

Epoch: 5| Step: 2
Training loss: 1.971269599850977
Validation loss: 2.5141395407705454

Epoch: 5| Step: 3
Training loss: 1.9257510416938532
Validation loss: 2.479176709913174

Epoch: 5| Step: 4
Training loss: 1.8234164252285023
Validation loss: 2.462361030453036

Epoch: 5| Step: 5
Training loss: 1.6397622882878677
Validation loss: 2.461501723517513

Epoch: 5| Step: 6
Training loss: 1.6359417876120912
Validation loss: 2.4683694438427346

Epoch: 5| Step: 7
Training loss: 2.2363798310411727
Validation loss: 2.4742026156084336

Epoch: 5| Step: 8
Training loss: 1.7249667012414605
Validation loss: 2.475649398440458

Epoch: 5| Step: 9
Training loss: 1.559672735072119
Validation loss: 2.4951093232856674

Epoch: 5| Step: 10
Training loss: 2.388176954872826
Validation loss: 2.510459253801526

Epoch: 346| Step: 0
Training loss: 1.4618926164561301
Validation loss: 2.5113528114621064

Epoch: 5| Step: 1
Training loss: 2.1306904167232985
Validation loss: 2.5174454069374503

Epoch: 5| Step: 2
Training loss: 1.9711873543702163
Validation loss: 2.5566709917364028

Epoch: 5| Step: 3
Training loss: 1.6666129183049854
Validation loss: 2.5567678071155076

Epoch: 5| Step: 4
Training loss: 1.4677820465586677
Validation loss: 2.5879385918234834

Epoch: 5| Step: 5
Training loss: 2.135094396572524
Validation loss: 2.5958981060307926

Epoch: 5| Step: 6
Training loss: 1.8506213665391578
Validation loss: 2.570993830303159

Epoch: 5| Step: 7
Training loss: 2.441156627863664
Validation loss: 2.5732859347809205

Epoch: 5| Step: 8
Training loss: 2.255913064160886
Validation loss: 2.5708594422410607

Epoch: 5| Step: 9
Training loss: 2.0347695010626716
Validation loss: 2.534225340733155

Epoch: 5| Step: 10
Training loss: 1.8604589556436781
Validation loss: 2.5185311570696762

Epoch: 347| Step: 0
Training loss: 1.9471652235588315
Validation loss: 2.529549818575109

Epoch: 5| Step: 1
Training loss: 2.3471102214428625
Validation loss: 2.502594979244691

Epoch: 5| Step: 2
Training loss: 1.7936812171641239
Validation loss: 2.453510064786708

Epoch: 5| Step: 3
Training loss: 1.7715785833205038
Validation loss: 2.46743178464481

Epoch: 5| Step: 4
Training loss: 1.623620401310001
Validation loss: 2.4603789769203286

Epoch: 5| Step: 5
Training loss: 1.6375410613524646
Validation loss: 2.430667387991794

Epoch: 5| Step: 6
Training loss: 1.9861118795338577
Validation loss: 2.4509736469279733

Epoch: 5| Step: 7
Training loss: 2.2044798019843994
Validation loss: 2.4506826517439237

Epoch: 5| Step: 8
Training loss: 1.9694401575833063
Validation loss: 2.485141562880192

Epoch: 5| Step: 9
Training loss: 2.179979202276292
Validation loss: 2.5030137006846567

Epoch: 5| Step: 10
Training loss: 1.748603058886435
Validation loss: 2.5228951159314734

Epoch: 348| Step: 0
Training loss: 1.984470154891299
Validation loss: 2.584541052056587

Epoch: 5| Step: 1
Training loss: 1.7860408402629426
Validation loss: 2.606827910771415

Epoch: 5| Step: 2
Training loss: 2.1205252487956914
Validation loss: 2.641762739016843

Epoch: 5| Step: 3
Training loss: 2.1199425371047727
Validation loss: 2.6499774683472164

Epoch: 5| Step: 4
Training loss: 1.9102003096353293
Validation loss: 2.630484693773541

Epoch: 5| Step: 5
Training loss: 1.8681224573091908
Validation loss: 2.6057975197431733

Epoch: 5| Step: 6
Training loss: 1.835647625054749
Validation loss: 2.573981557731924

Epoch: 5| Step: 7
Training loss: 2.233033424376703
Validation loss: 2.5407363591723295

Epoch: 5| Step: 8
Training loss: 1.6838032532379263
Validation loss: 2.5118798048138298

Epoch: 5| Step: 9
Training loss: 1.7596156387681685
Validation loss: 2.5160050030937726

Epoch: 5| Step: 10
Training loss: 1.9548456166182027
Validation loss: 2.5055088179128298

Epoch: 349| Step: 0
Training loss: 2.066608959848482
Validation loss: 2.507428373131016

Epoch: 5| Step: 1
Training loss: 1.9761671191020862
Validation loss: 2.522434141943585

Epoch: 5| Step: 2
Training loss: 1.610012039471268
Validation loss: 2.526979851982704

Epoch: 5| Step: 3
Training loss: 1.8201502125970912
Validation loss: 2.5648970638654838

Epoch: 5| Step: 4
Training loss: 2.152350617828766
Validation loss: 2.589067669888551

Epoch: 5| Step: 5
Training loss: 1.970791379012927
Validation loss: 2.5464676335490823

Epoch: 5| Step: 6
Training loss: 1.8095419851145575
Validation loss: 2.5247638365741114

Epoch: 5| Step: 7
Training loss: 1.5919891054125714
Validation loss: 2.4914602593858044

Epoch: 5| Step: 8
Training loss: 1.8297004106360923
Validation loss: 2.4685987221353187

Epoch: 5| Step: 9
Training loss: 1.582052499133916
Validation loss: 2.4591593698958283

Epoch: 5| Step: 10
Training loss: 2.481220473875312
Validation loss: 2.439918269253296

Epoch: 350| Step: 0
Training loss: 2.000570811831122
Validation loss: 2.4522274348616957

Epoch: 5| Step: 1
Training loss: 2.006346765008776
Validation loss: 2.4686016455120714

Epoch: 5| Step: 2
Training loss: 1.4784141112618114
Validation loss: 2.507099214118191

Epoch: 5| Step: 3
Training loss: 1.9017652693429217
Validation loss: 2.537116723034692

Epoch: 5| Step: 4
Training loss: 1.891139945529971
Validation loss: 2.557685170328892

Epoch: 5| Step: 5
Training loss: 2.151378491303145
Validation loss: 2.601987224215343

Epoch: 5| Step: 6
Training loss: 1.964718824172989
Validation loss: 2.5813861545141026

Epoch: 5| Step: 7
Training loss: 1.8557031101992378
Validation loss: 2.553496470839748

Epoch: 5| Step: 8
Training loss: 1.4083051287443298
Validation loss: 2.5336978884690584

Epoch: 5| Step: 9
Training loss: 1.9943565976529083
Validation loss: 2.5103254373570385

Epoch: 5| Step: 10
Training loss: 2.385741088217358
Validation loss: 2.4790969446570235

Testing loss: 2.5000504276699855
