Epoch: 1| Step: 0
Training loss: 5.081743240356445
Validation loss: 5.1509335425592235

Epoch: 6| Step: 1
Training loss: 4.509648323059082
Validation loss: 5.139258979469218

Epoch: 6| Step: 2
Training loss: 4.072648048400879
Validation loss: 5.127263776717648

Epoch: 6| Step: 3
Training loss: 3.720263957977295
Validation loss: 5.114958429849276

Epoch: 6| Step: 4
Training loss: 5.818309783935547
Validation loss: 5.102636639789869

Epoch: 6| Step: 5
Training loss: 5.966671466827393
Validation loss: 5.090091638667609

Epoch: 6| Step: 6
Training loss: 4.117955684661865
Validation loss: 5.0763623842629055

Epoch: 6| Step: 7
Training loss: 5.018594741821289
Validation loss: 5.062982774549915

Epoch: 6| Step: 8
Training loss: 4.943029403686523
Validation loss: 5.048890200994348

Epoch: 6| Step: 9
Training loss: 5.12934684753418
Validation loss: 5.033127610401441

Epoch: 6| Step: 10
Training loss: 3.9766294956207275
Validation loss: 5.017021999564222

Epoch: 6| Step: 11
Training loss: 4.937986850738525
Validation loss: 4.9984724034545245

Epoch: 6| Step: 12
Training loss: 6.122710704803467
Validation loss: 4.9789616061795146

Epoch: 6| Step: 13
Training loss: 4.525350570678711
Validation loss: 4.957794133053031

Epoch: 2| Step: 0
Training loss: 4.817676544189453
Validation loss: 4.936274159339167

Epoch: 6| Step: 1
Training loss: 4.920766830444336
Validation loss: 4.912116132756715

Epoch: 6| Step: 2
Training loss: 3.1010775566101074
Validation loss: 4.887069061238279

Epoch: 6| Step: 3
Training loss: 5.479822158813477
Validation loss: 4.859667839542512

Epoch: 6| Step: 4
Training loss: 5.2709197998046875
Validation loss: 4.830153639598559

Epoch: 6| Step: 5
Training loss: 4.224806785583496
Validation loss: 4.7979706487348

Epoch: 6| Step: 6
Training loss: 5.266448020935059
Validation loss: 4.7640681112966226

Epoch: 6| Step: 7
Training loss: 3.7586679458618164
Validation loss: 4.727238055198423

Epoch: 6| Step: 8
Training loss: 4.888951301574707
Validation loss: 4.690560315244941

Epoch: 6| Step: 9
Training loss: 4.539353370666504
Validation loss: 4.6510534696681525

Epoch: 6| Step: 10
Training loss: 4.324512481689453
Validation loss: 4.610798410190049

Epoch: 6| Step: 11
Training loss: 4.472060203552246
Validation loss: 4.568149902487314

Epoch: 6| Step: 12
Training loss: 4.168870449066162
Validation loss: 4.524654408936859

Epoch: 6| Step: 13
Training loss: 3.742208242416382
Validation loss: 4.481112644236575

Epoch: 3| Step: 0
Training loss: 4.688495635986328
Validation loss: 4.435901534172796

Epoch: 6| Step: 1
Training loss: 4.457409858703613
Validation loss: 4.392190094917051

Epoch: 6| Step: 2
Training loss: 3.277777671813965
Validation loss: 4.3508648513465795

Epoch: 6| Step: 3
Training loss: 4.4553937911987305
Validation loss: 4.308915174135598

Epoch: 6| Step: 4
Training loss: 4.52323579788208
Validation loss: 4.2673315899346465

Epoch: 6| Step: 5
Training loss: 4.834655284881592
Validation loss: 4.225003893657397

Epoch: 6| Step: 6
Training loss: 2.5138063430786133
Validation loss: 4.183890219657652

Epoch: 6| Step: 7
Training loss: 3.9694008827209473
Validation loss: 4.140898127709666

Epoch: 6| Step: 8
Training loss: 4.759272575378418
Validation loss: 4.096930739700153

Epoch: 6| Step: 9
Training loss: 3.5965094566345215
Validation loss: 4.05559205496183

Epoch: 6| Step: 10
Training loss: 2.6654841899871826
Validation loss: 4.012674503428961

Epoch: 6| Step: 11
Training loss: 3.317589521408081
Validation loss: 3.9718681407231156

Epoch: 6| Step: 12
Training loss: 4.270374298095703
Validation loss: 3.9300049453653316

Epoch: 6| Step: 13
Training loss: 4.548089504241943
Validation loss: 3.8926436567819245

Epoch: 4| Step: 0
Training loss: 2.407386302947998
Validation loss: 3.850607418244885

Epoch: 6| Step: 1
Training loss: 4.329016208648682
Validation loss: 3.814612957739061

Epoch: 6| Step: 2
Training loss: 4.499011039733887
Validation loss: 3.7817729160349858

Epoch: 6| Step: 3
Training loss: 3.547297954559326
Validation loss: 3.749974091847738

Epoch: 6| Step: 4
Training loss: 4.375089645385742
Validation loss: 3.7205798651582453

Epoch: 6| Step: 5
Training loss: 3.883146047592163
Validation loss: 3.6898301801373883

Epoch: 6| Step: 6
Training loss: 2.65771222114563
Validation loss: 3.6638183696295625

Epoch: 6| Step: 7
Training loss: 2.7798542976379395
Validation loss: 3.6392927938891995

Epoch: 6| Step: 8
Training loss: 4.435107231140137
Validation loss: 3.6193302626250894

Epoch: 6| Step: 9
Training loss: 3.389965772628784
Validation loss: 3.595245768946986

Epoch: 6| Step: 10
Training loss: 3.5274343490600586
Validation loss: 3.5744709584020797

Epoch: 6| Step: 11
Training loss: 4.507370948791504
Validation loss: 3.55601228180752

Epoch: 6| Step: 12
Training loss: 1.8085660934448242
Validation loss: 3.536979111292029

Epoch: 6| Step: 13
Training loss: 4.168439865112305
Validation loss: 3.520635989404494

Epoch: 5| Step: 0
Training loss: 3.0400094985961914
Validation loss: 3.5018979810899302

Epoch: 6| Step: 1
Training loss: 3.7539334297180176
Validation loss: 3.484991301772415

Epoch: 6| Step: 2
Training loss: 3.944734573364258
Validation loss: 3.4699085322759484

Epoch: 6| Step: 3
Training loss: 3.779473304748535
Validation loss: 3.451470249442644

Epoch: 6| Step: 4
Training loss: 3.6591720581054688
Validation loss: 3.4337889148342993

Epoch: 6| Step: 5
Training loss: 2.9131760597229004
Validation loss: 3.4157322709278395

Epoch: 6| Step: 6
Training loss: 3.1906394958496094
Validation loss: 3.39806297773956

Epoch: 6| Step: 7
Training loss: 2.8987278938293457
Validation loss: 3.3800500874878256

Epoch: 6| Step: 8
Training loss: 3.1739020347595215
Validation loss: 3.3636445537690194

Epoch: 6| Step: 9
Training loss: 3.399752616882324
Validation loss: 3.3488762942693566

Epoch: 6| Step: 10
Training loss: 2.7255518436431885
Validation loss: 3.3313792726045013

Epoch: 6| Step: 11
Training loss: 3.7796835899353027
Validation loss: 3.3206139072295158

Epoch: 6| Step: 12
Training loss: 3.201852560043335
Validation loss: 3.3070289704107467

Epoch: 6| Step: 13
Training loss: 3.5510525703430176
Validation loss: 3.2964842114397275

Epoch: 6| Step: 0
Training loss: 4.174471378326416
Validation loss: 3.282481772925264

Epoch: 6| Step: 1
Training loss: 3.408557415008545
Validation loss: 3.271726721076555

Epoch: 6| Step: 2
Training loss: 2.972289562225342
Validation loss: 3.2625462521788893

Epoch: 6| Step: 3
Training loss: 3.466290235519409
Validation loss: 3.2513612060136694

Epoch: 6| Step: 4
Training loss: 4.715736389160156
Validation loss: 3.2437074774055072

Epoch: 6| Step: 5
Training loss: 2.6046438217163086
Validation loss: 3.2350030150464786

Epoch: 6| Step: 6
Training loss: 3.1479485034942627
Validation loss: 3.249282767695765

Epoch: 6| Step: 7
Training loss: 2.6546120643615723
Validation loss: 3.2191452980041504

Epoch: 6| Step: 8
Training loss: 2.942007303237915
Validation loss: 3.208186741798155

Epoch: 6| Step: 9
Training loss: 2.997913360595703
Validation loss: 3.2018132030322985

Epoch: 6| Step: 10
Training loss: 2.4855847358703613
Validation loss: 3.204403454257596

Epoch: 6| Step: 11
Training loss: 3.853776216506958
Validation loss: 3.2071221618242163

Epoch: 6| Step: 12
Training loss: 2.637512445449829
Validation loss: 3.186380522225493

Epoch: 6| Step: 13
Training loss: 2.950051784515381
Validation loss: 3.1747777872188117

Epoch: 7| Step: 0
Training loss: 3.6018481254577637
Validation loss: 3.175245226070445

Epoch: 6| Step: 1
Training loss: 2.38857364654541
Validation loss: 3.1757624277504544

Epoch: 6| Step: 2
Training loss: 4.312959671020508
Validation loss: 3.177902857462565

Epoch: 6| Step: 3
Training loss: 3.2388672828674316
Validation loss: 3.1713885722621793

Epoch: 6| Step: 4
Training loss: 3.568493366241455
Validation loss: 3.162482625694685

Epoch: 6| Step: 5
Training loss: 3.2713451385498047
Validation loss: 3.1599207770439888

Epoch: 6| Step: 6
Training loss: 2.7832045555114746
Validation loss: 3.156916602965324

Epoch: 6| Step: 7
Training loss: 2.7674484252929688
Validation loss: 3.1573203558562906

Epoch: 6| Step: 8
Training loss: 3.068920850753784
Validation loss: 3.155072496783349

Epoch: 6| Step: 9
Training loss: 2.3068923950195312
Validation loss: 3.1520950666037937

Epoch: 6| Step: 10
Training loss: 3.1638591289520264
Validation loss: 3.146676819811585

Epoch: 6| Step: 11
Training loss: 2.331104040145874
Validation loss: 3.1408036370431223

Epoch: 6| Step: 12
Training loss: 3.858837604522705
Validation loss: 3.1324026200079147

Epoch: 6| Step: 13
Training loss: 4.1308369636535645
Validation loss: 3.1238780739486858

Epoch: 8| Step: 0
Training loss: 3.3932487964630127
Validation loss: 3.114016330370339

Epoch: 6| Step: 1
Training loss: 4.004426002502441
Validation loss: 3.1058497198166384

Epoch: 6| Step: 2
Training loss: 3.0723297595977783
Validation loss: 3.098679150304487

Epoch: 6| Step: 3
Training loss: 3.479414701461792
Validation loss: 3.1177417514144734

Epoch: 6| Step: 4
Training loss: 3.2161927223205566
Validation loss: 3.0877527216429352

Epoch: 6| Step: 5
Training loss: 2.645205497741699
Validation loss: 3.0841579257801013

Epoch: 6| Step: 6
Training loss: 3.9450695514678955
Validation loss: 3.083778622329876

Epoch: 6| Step: 7
Training loss: 3.4586610794067383
Validation loss: 3.0814861277098298

Epoch: 6| Step: 8
Training loss: 2.8778939247131348
Validation loss: 3.0805405262977845

Epoch: 6| Step: 9
Training loss: 3.015841007232666
Validation loss: 3.1125121244820217

Epoch: 6| Step: 10
Training loss: 2.70027756690979
Validation loss: 3.0721197487205587

Epoch: 6| Step: 11
Training loss: 2.3040974140167236
Validation loss: 3.0582654809439056

Epoch: 6| Step: 12
Training loss: 2.4380745887756348
Validation loss: 3.067322192653533

Epoch: 6| Step: 13
Training loss: 3.2093257904052734
Validation loss: 3.050437655500186

Epoch: 9| Step: 0
Training loss: 2.7515931129455566
Validation loss: 3.043955769590152

Epoch: 6| Step: 1
Training loss: 2.5863864421844482
Validation loss: 3.0427897976290796

Epoch: 6| Step: 2
Training loss: 2.669330596923828
Validation loss: 3.0384839016904115

Epoch: 6| Step: 3
Training loss: 3.7162203788757324
Validation loss: 3.0405608069512153

Epoch: 6| Step: 4
Training loss: 2.928020715713501
Validation loss: 3.0344986069586968

Epoch: 6| Step: 5
Training loss: 3.242391586303711
Validation loss: 3.033833788287255

Epoch: 6| Step: 6
Training loss: 2.517524480819702
Validation loss: 3.028242531643119

Epoch: 6| Step: 7
Training loss: 3.8158416748046875
Validation loss: 3.019391490567115

Epoch: 6| Step: 8
Training loss: 3.855682373046875
Validation loss: 3.0116056908843336

Epoch: 6| Step: 9
Training loss: 3.674592971801758
Validation loss: 3.009920222784883

Epoch: 6| Step: 10
Training loss: 3.578218936920166
Validation loss: 3.004726848294658

Epoch: 6| Step: 11
Training loss: 2.936229705810547
Validation loss: 2.998817518193235

Epoch: 6| Step: 12
Training loss: 2.5867996215820312
Validation loss: 2.9939898803669918

Epoch: 6| Step: 13
Training loss: 1.620680332183838
Validation loss: 2.9933477114605647

Epoch: 10| Step: 0
Training loss: 2.8042593002319336
Validation loss: 3.0133291367561585

Epoch: 6| Step: 1
Training loss: 2.645249843597412
Validation loss: 2.994177267115603

Epoch: 6| Step: 2
Training loss: 3.1380157470703125
Validation loss: 2.9751667002195954

Epoch: 6| Step: 3
Training loss: 1.995063304901123
Validation loss: 2.977017071939284

Epoch: 6| Step: 4
Training loss: 3.0939056873321533
Validation loss: 2.9720259071678243

Epoch: 6| Step: 5
Training loss: 3.2214155197143555
Validation loss: 2.9695034770555395

Epoch: 6| Step: 6
Training loss: 3.7605786323547363
Validation loss: 2.9649208309829875

Epoch: 6| Step: 7
Training loss: 2.705592393875122
Validation loss: 2.962501443842406

Epoch: 6| Step: 8
Training loss: 3.0433459281921387
Validation loss: 2.953840632592478

Epoch: 6| Step: 9
Training loss: 3.4933135509490967
Validation loss: 2.9496208262699906

Epoch: 6| Step: 10
Training loss: 3.1835787296295166
Validation loss: 2.9466188517949914

Epoch: 6| Step: 11
Training loss: 3.226792097091675
Validation loss: 2.9440348173982356

Epoch: 6| Step: 12
Training loss: 3.0847978591918945
Validation loss: 2.947553914080384

Epoch: 6| Step: 13
Training loss: 3.2530524730682373
Validation loss: 2.936569336921938

Epoch: 11| Step: 0
Training loss: 2.9303536415100098
Validation loss: 2.9396279832368255

Epoch: 6| Step: 1
Training loss: 4.003382682800293
Validation loss: 2.9450655214248167

Epoch: 6| Step: 2
Training loss: 3.2807745933532715
Validation loss: 2.9521806342627412

Epoch: 6| Step: 3
Training loss: 2.3373703956604004
Validation loss: 2.9381260743705173

Epoch: 6| Step: 4
Training loss: 2.8569560050964355
Validation loss: 2.9335721462003645

Epoch: 6| Step: 5
Training loss: 3.313128709793091
Validation loss: 2.938154738436463

Epoch: 6| Step: 6
Training loss: 3.3273496627807617
Validation loss: 2.927741291702435

Epoch: 6| Step: 7
Training loss: 3.035895824432373
Validation loss: 2.911300551506781

Epoch: 6| Step: 8
Training loss: 3.2636353969573975
Validation loss: 2.9133686096437517

Epoch: 6| Step: 9
Training loss: 2.3671326637268066
Validation loss: 2.9238943284557712

Epoch: 6| Step: 10
Training loss: 3.171311378479004
Validation loss: 2.912648964953679

Epoch: 6| Step: 11
Training loss: 3.244128942489624
Validation loss: 2.9058100356850574

Epoch: 6| Step: 12
Training loss: 2.596365451812744
Validation loss: 2.903514959478891

Epoch: 6| Step: 13
Training loss: 1.9830374717712402
Validation loss: 2.9009846512989332

Epoch: 12| Step: 0
Training loss: 3.765575408935547
Validation loss: 2.9006754403473227

Epoch: 6| Step: 1
Training loss: 3.332977771759033
Validation loss: 2.899057108868835

Epoch: 6| Step: 2
Training loss: 2.902104377746582
Validation loss: 2.8975024454055296

Epoch: 6| Step: 3
Training loss: 3.016730308532715
Validation loss: 2.8934814622325282

Epoch: 6| Step: 4
Training loss: 2.4032702445983887
Validation loss: 2.891190239178237

Epoch: 6| Step: 5
Training loss: 3.4351229667663574
Validation loss: 2.897716999053955

Epoch: 6| Step: 6
Training loss: 3.0664772987365723
Validation loss: 2.8939497599037747

Epoch: 6| Step: 7
Training loss: 2.8163232803344727
Validation loss: 2.877652475910802

Epoch: 6| Step: 8
Training loss: 2.9327852725982666
Validation loss: 2.8706681292544127

Epoch: 6| Step: 9
Training loss: 3.410557746887207
Validation loss: 2.868086184224775

Epoch: 6| Step: 10
Training loss: 2.716972589492798
Validation loss: 2.8646831614996797

Epoch: 6| Step: 11
Training loss: 3.230203151702881
Validation loss: 2.8611676872417493

Epoch: 6| Step: 12
Training loss: 2.05033802986145
Validation loss: 2.858012912093952

Epoch: 6| Step: 13
Training loss: 2.5404951572418213
Validation loss: 2.8611457245324248

Epoch: 13| Step: 0
Training loss: 2.6332526206970215
Validation loss: 2.8694525713561685

Epoch: 6| Step: 1
Training loss: 3.3860485553741455
Validation loss: 2.8487165051121868

Epoch: 6| Step: 2
Training loss: 2.076446056365967
Validation loss: 2.851673146729828

Epoch: 6| Step: 3
Training loss: 2.653244972229004
Validation loss: 2.8650876014463362

Epoch: 6| Step: 4
Training loss: 3.3332149982452393
Validation loss: 2.883819405750562

Epoch: 6| Step: 5
Training loss: 3.4487907886505127
Validation loss: 2.870199099663765

Epoch: 6| Step: 6
Training loss: 3.717902660369873
Validation loss: 2.843326166111936

Epoch: 6| Step: 7
Training loss: 3.2016355991363525
Validation loss: 2.8397800230210826

Epoch: 6| Step: 8
Training loss: 3.0803885459899902
Validation loss: 2.8397430143048688

Epoch: 6| Step: 9
Training loss: 2.4706971645355225
Validation loss: 2.831717409113402

Epoch: 6| Step: 10
Training loss: 2.9621500968933105
Validation loss: 2.8286352721593713

Epoch: 6| Step: 11
Training loss: 2.398469924926758
Validation loss: 2.8289630515601045

Epoch: 6| Step: 12
Training loss: 2.7804136276245117
Validation loss: 2.836810847764374

Epoch: 6| Step: 13
Training loss: 3.4918441772460938
Validation loss: 2.8302383679215626

Epoch: 14| Step: 0
Training loss: 2.452939987182617
Validation loss: 2.8244053702200613

Epoch: 6| Step: 1
Training loss: 2.9471869468688965
Validation loss: 2.817329365720031

Epoch: 6| Step: 2
Training loss: 2.4193239212036133
Validation loss: 2.8154226297973306

Epoch: 6| Step: 3
Training loss: 2.399383068084717
Validation loss: 2.8124215884875228

Epoch: 6| Step: 4
Training loss: 3.475578784942627
Validation loss: 2.8095600041010047

Epoch: 6| Step: 5
Training loss: 3.0985522270202637
Validation loss: 2.807416569802069

Epoch: 6| Step: 6
Training loss: 3.0881619453430176
Validation loss: 2.8131195396505375

Epoch: 6| Step: 7
Training loss: 3.624647855758667
Validation loss: 2.825498222022928

Epoch: 6| Step: 8
Training loss: 2.5010483264923096
Validation loss: 2.803835376616447

Epoch: 6| Step: 9
Training loss: 2.813600540161133
Validation loss: 2.795061731851229

Epoch: 6| Step: 10
Training loss: 3.5435993671417236
Validation loss: 2.791888085744714

Epoch: 6| Step: 11
Training loss: 3.2272591590881348
Validation loss: 2.789154629553518

Epoch: 6| Step: 12
Training loss: 2.339545965194702
Validation loss: 2.789965380904495

Epoch: 6| Step: 13
Training loss: 3.2250869274139404
Validation loss: 2.787801750244633

Epoch: 15| Step: 0
Training loss: 3.293628454208374
Validation loss: 2.7909533618598856

Epoch: 6| Step: 1
Training loss: 3.3080086708068848
Validation loss: 2.8032284423869145

Epoch: 6| Step: 2
Training loss: 2.0213091373443604
Validation loss: 2.7860825702708256

Epoch: 6| Step: 3
Training loss: 1.6884020566940308
Validation loss: 2.7819037001620055

Epoch: 6| Step: 4
Training loss: 4.526669979095459
Validation loss: 2.777631446879397

Epoch: 6| Step: 5
Training loss: 3.7112584114074707
Validation loss: 2.7748753050322175

Epoch: 6| Step: 6
Training loss: 3.2663731575012207
Validation loss: 2.7727725941647767

Epoch: 6| Step: 7
Training loss: 2.332977533340454
Validation loss: 2.77580948029795

Epoch: 6| Step: 8
Training loss: 1.7852673530578613
Validation loss: 2.778981475419896

Epoch: 6| Step: 9
Training loss: 2.7420454025268555
Validation loss: 2.7776844168222077

Epoch: 6| Step: 10
Training loss: 2.5302910804748535
Validation loss: 2.7794458891755793

Epoch: 6| Step: 11
Training loss: 3.2156753540039062
Validation loss: 2.7761034837333103

Epoch: 6| Step: 12
Training loss: 2.7564821243286133
Validation loss: 2.7733116636994066

Epoch: 6| Step: 13
Training loss: 4.469723224639893
Validation loss: 2.773673842030187

Epoch: 16| Step: 0
Training loss: 2.9910292625427246
Validation loss: 2.7693908112023466

Epoch: 6| Step: 1
Training loss: 2.6590778827667236
Validation loss: 2.7652631267424552

Epoch: 6| Step: 2
Training loss: 2.1038999557495117
Validation loss: 2.7590696657857587

Epoch: 6| Step: 3
Training loss: 3.417768955230713
Validation loss: 2.7551168985264276

Epoch: 6| Step: 4
Training loss: 2.304368495941162
Validation loss: 2.750657086731285

Epoch: 6| Step: 5
Training loss: 2.688289165496826
Validation loss: 2.7448018007380988

Epoch: 6| Step: 6
Training loss: 2.794865846633911
Validation loss: 2.7438594910406295

Epoch: 6| Step: 7
Training loss: 3.3787412643432617
Validation loss: 2.7361393256853987

Epoch: 6| Step: 8
Training loss: 2.0996642112731934
Validation loss: 2.7371959122278358

Epoch: 6| Step: 9
Training loss: 3.5077195167541504
Validation loss: 2.7312072682124313

Epoch: 6| Step: 10
Training loss: 2.747145652770996
Validation loss: 2.7304974063750236

Epoch: 6| Step: 11
Training loss: 2.938373565673828
Validation loss: 2.723884126191498

Epoch: 6| Step: 12
Training loss: 3.4536705017089844
Validation loss: 2.7278247520487797

Epoch: 6| Step: 13
Training loss: 3.89926815032959
Validation loss: 2.722105856864683

Epoch: 17| Step: 0
Training loss: 2.405895948410034
Validation loss: 2.716316971727597

Epoch: 6| Step: 1
Training loss: 1.475683331489563
Validation loss: 2.7151137628862934

Epoch: 6| Step: 2
Training loss: 3.7530388832092285
Validation loss: 2.710964543845064

Epoch: 6| Step: 3
Training loss: 2.673795223236084
Validation loss: 2.705847232572494

Epoch: 6| Step: 4
Training loss: 2.7946033477783203
Validation loss: 2.7038998783275647

Epoch: 6| Step: 5
Training loss: 3.126624584197998
Validation loss: 2.7028908550098376

Epoch: 6| Step: 6
Training loss: 3.339877128601074
Validation loss: 2.699956742666101

Epoch: 6| Step: 7
Training loss: 2.591559410095215
Validation loss: 2.695725889616115

Epoch: 6| Step: 8
Training loss: 3.273131847381592
Validation loss: 2.6906195045799337

Epoch: 6| Step: 9
Training loss: 2.494494915008545
Validation loss: 2.692958015267567

Epoch: 6| Step: 10
Training loss: 3.14699125289917
Validation loss: 2.687152160111294

Epoch: 6| Step: 11
Training loss: 3.328554153442383
Validation loss: 2.6898618231537523

Epoch: 6| Step: 12
Training loss: 2.974984645843506
Validation loss: 2.6934348793439966

Epoch: 6| Step: 13
Training loss: 2.646862030029297
Validation loss: 2.6914112901174896

Epoch: 18| Step: 0
Training loss: 2.477989435195923
Validation loss: 2.68335251397984

Epoch: 6| Step: 1
Training loss: 2.841883659362793
Validation loss: 2.6738078722389798

Epoch: 6| Step: 2
Training loss: 3.332939624786377
Validation loss: 2.678063936130975

Epoch: 6| Step: 3
Training loss: 2.8553452491760254
Validation loss: 2.671747884442729

Epoch: 6| Step: 4
Training loss: 3.266936779022217
Validation loss: 2.67458692930078

Epoch: 6| Step: 5
Training loss: 3.0230250358581543
Validation loss: 2.6718435056747927

Epoch: 6| Step: 6
Training loss: 2.6835880279541016
Validation loss: 2.6718562162050636

Epoch: 6| Step: 7
Training loss: 3.1485753059387207
Validation loss: 2.6705503463745117

Epoch: 6| Step: 8
Training loss: 2.291926145553589
Validation loss: 2.670135085300733

Epoch: 6| Step: 9
Training loss: 3.13618803024292
Validation loss: 2.6733849099887315

Epoch: 6| Step: 10
Training loss: 2.9014360904693604
Validation loss: 2.665768946370771

Epoch: 6| Step: 11
Training loss: 2.283867359161377
Validation loss: 2.6642654352290656

Epoch: 6| Step: 12
Training loss: 3.155104160308838
Validation loss: 2.6704457549638647

Epoch: 6| Step: 13
Training loss: 2.0460615158081055
Validation loss: 2.6808021312118857

Epoch: 19| Step: 0
Training loss: 2.6796607971191406
Validation loss: 2.717194372607816

Epoch: 6| Step: 1
Training loss: 2.451634407043457
Validation loss: 2.7333226626919163

Epoch: 6| Step: 2
Training loss: 3.4120309352874756
Validation loss: 2.732452710469564

Epoch: 6| Step: 3
Training loss: 2.088571310043335
Validation loss: 2.7332069848173406

Epoch: 6| Step: 4
Training loss: 2.837301731109619
Validation loss: 2.727838034270912

Epoch: 6| Step: 5
Training loss: 3.961829662322998
Validation loss: 2.732217506695819

Epoch: 6| Step: 6
Training loss: 3.0550003051757812
Validation loss: 2.7242836567663375

Epoch: 6| Step: 7
Training loss: 2.9355030059814453
Validation loss: 2.7220305422300934

Epoch: 6| Step: 8
Training loss: 2.8244690895080566
Validation loss: 2.7163255676146476

Epoch: 6| Step: 9
Training loss: 2.0800209045410156
Validation loss: 2.7240812650290867

Epoch: 6| Step: 10
Training loss: 2.651604652404785
Validation loss: 2.722651002227619

Epoch: 6| Step: 11
Training loss: 3.4483425617218018
Validation loss: 2.719958205376902

Epoch: 6| Step: 12
Training loss: 2.366940975189209
Validation loss: 2.7069863452706286

Epoch: 6| Step: 13
Training loss: 3.953404664993286
Validation loss: 2.704869601034349

Epoch: 20| Step: 0
Training loss: 2.5506911277770996
Validation loss: 2.7043871418122323

Epoch: 6| Step: 1
Training loss: 2.482703924179077
Validation loss: 2.7017714464536278

Epoch: 6| Step: 2
Training loss: 3.021538496017456
Validation loss: 2.698644071496943

Epoch: 6| Step: 3
Training loss: 2.7230920791625977
Validation loss: 2.6972196102142334

Epoch: 6| Step: 4
Training loss: 2.691256046295166
Validation loss: 2.692113261069021

Epoch: 6| Step: 5
Training loss: 2.8513715267181396
Validation loss: 2.6765022354741252

Epoch: 6| Step: 6
Training loss: 3.688234329223633
Validation loss: 2.6480698380419003

Epoch: 6| Step: 7
Training loss: 2.7038400173187256
Validation loss: 2.6623353368492535

Epoch: 6| Step: 8
Training loss: 2.8048038482666016
Validation loss: 2.7033132353136615

Epoch: 6| Step: 9
Training loss: 3.1120100021362305
Validation loss: 2.721571640301776

Epoch: 6| Step: 10
Training loss: 3.272554636001587
Validation loss: 2.730192651030838

Epoch: 6| Step: 11
Training loss: 3.5688211917877197
Validation loss: 2.7342755948343584

Epoch: 6| Step: 12
Training loss: 2.301318645477295
Validation loss: 2.738143559425108

Epoch: 6| Step: 13
Training loss: 1.8733760118484497
Validation loss: 2.7330417325419765

Epoch: 21| Step: 0
Training loss: 3.0932798385620117
Validation loss: 2.7352665188491985

Epoch: 6| Step: 1
Training loss: 3.271683931350708
Validation loss: 2.727972612586073

Epoch: 6| Step: 2
Training loss: 2.4560399055480957
Validation loss: 2.7160717492462485

Epoch: 6| Step: 3
Training loss: 2.9214768409729004
Validation loss: 2.706911107545258

Epoch: 6| Step: 4
Training loss: 3.2075247764587402
Validation loss: 2.7030397743307133

Epoch: 6| Step: 5
Training loss: 2.816439151763916
Validation loss: 2.6968553143162883

Epoch: 6| Step: 6
Training loss: 3.246185779571533
Validation loss: 2.6929335542904433

Epoch: 6| Step: 7
Training loss: 2.4908359050750732
Validation loss: 2.6875545106908327

Epoch: 6| Step: 8
Training loss: 2.8359150886535645
Validation loss: 2.6774925698516188

Epoch: 6| Step: 9
Training loss: 2.1178317070007324
Validation loss: 2.6756039588682112

Epoch: 6| Step: 10
Training loss: 2.9952163696289062
Validation loss: 2.675430941325362

Epoch: 6| Step: 11
Training loss: 2.2638931274414062
Validation loss: 2.691023721489855

Epoch: 6| Step: 12
Training loss: 3.2297964096069336
Validation loss: 2.713532204269081

Epoch: 6| Step: 13
Training loss: 3.5603208541870117
Validation loss: 2.7275802396958873

Epoch: 22| Step: 0
Training loss: 2.6930389404296875
Validation loss: 2.6988774525221957

Epoch: 6| Step: 1
Training loss: 3.013857841491699
Validation loss: 2.689445562260125

Epoch: 6| Step: 2
Training loss: 3.1683602333068848
Validation loss: 2.6769025120683896

Epoch: 6| Step: 3
Training loss: 3.1814613342285156
Validation loss: 2.6754201330164427

Epoch: 6| Step: 4
Training loss: 3.4704740047454834
Validation loss: 2.6762505705638597

Epoch: 6| Step: 5
Training loss: 3.030529737472534
Validation loss: 2.669757632799046

Epoch: 6| Step: 6
Training loss: 2.3181426525115967
Validation loss: 2.713502868529289

Epoch: 6| Step: 7
Training loss: 2.6652133464813232
Validation loss: 2.7150062514889624

Epoch: 6| Step: 8
Training loss: 2.934246301651001
Validation loss: 2.6787783048486196

Epoch: 6| Step: 9
Training loss: 2.330430269241333
Validation loss: 2.6166834626146542

Epoch: 6| Step: 10
Training loss: 3.167351007461548
Validation loss: 2.6031922524975193

Epoch: 6| Step: 11
Training loss: 2.623404026031494
Validation loss: 2.5976813557327434

Epoch: 6| Step: 12
Training loss: 2.4194116592407227
Validation loss: 2.595792137166505

Epoch: 6| Step: 13
Training loss: 2.453571081161499
Validation loss: 2.6055089273760395

Epoch: 23| Step: 0
Training loss: 2.7004806995391846
Validation loss: 2.601343067743445

Epoch: 6| Step: 1
Training loss: 3.7477197647094727
Validation loss: 2.614206567887337

Epoch: 6| Step: 2
Training loss: 2.957071542739868
Validation loss: 2.6187633698986423

Epoch: 6| Step: 3
Training loss: 2.3870248794555664
Validation loss: 2.621253316120435

Epoch: 6| Step: 4
Training loss: 2.0992724895477295
Validation loss: 2.6099777375498125

Epoch: 6| Step: 5
Training loss: 3.329500675201416
Validation loss: 2.5975612337871263

Epoch: 6| Step: 6
Training loss: 2.859161615371704
Validation loss: 2.5930378411405828

Epoch: 6| Step: 7
Training loss: 2.3877739906311035
Validation loss: 2.5902344744692565

Epoch: 6| Step: 8
Training loss: 2.774484395980835
Validation loss: 2.5904323157443794

Epoch: 6| Step: 9
Training loss: 3.0465755462646484
Validation loss: 2.5898630824140323

Epoch: 6| Step: 10
Training loss: 2.5077857971191406
Validation loss: 2.5912655579146517

Epoch: 6| Step: 11
Training loss: 2.031193256378174
Validation loss: 2.5937072564196844

Epoch: 6| Step: 12
Training loss: 3.1623432636260986
Validation loss: 2.595961324630245

Epoch: 6| Step: 13
Training loss: 3.396836519241333
Validation loss: 2.589282076845887

Epoch: 24| Step: 0
Training loss: 3.126974105834961
Validation loss: 2.589878894949472

Epoch: 6| Step: 1
Training loss: 2.673259973526001
Validation loss: 2.588784989490304

Epoch: 6| Step: 2
Training loss: 3.0068252086639404
Validation loss: 2.586041324882097

Epoch: 6| Step: 3
Training loss: 2.4271950721740723
Validation loss: 2.5810470440054454

Epoch: 6| Step: 4
Training loss: 2.5214505195617676
Validation loss: 2.5839467202463458

Epoch: 6| Step: 5
Training loss: 3.8968918323516846
Validation loss: 2.5756134448512906

Epoch: 6| Step: 6
Training loss: 2.4941954612731934
Validation loss: 2.568825880686442

Epoch: 6| Step: 7
Training loss: 2.947352409362793
Validation loss: 2.570451336522256

Epoch: 6| Step: 8
Training loss: 2.5054068565368652
Validation loss: 2.5661580767682803

Epoch: 6| Step: 9
Training loss: 2.881295680999756
Validation loss: 2.5758579238768546

Epoch: 6| Step: 10
Training loss: 2.801443576812744
Validation loss: 2.578596553494853

Epoch: 6| Step: 11
Training loss: 3.0074124336242676
Validation loss: 2.58011531829834

Epoch: 6| Step: 12
Training loss: 2.1915202140808105
Validation loss: 2.570727571364372

Epoch: 6| Step: 13
Training loss: 2.321610450744629
Validation loss: 2.566837562027798

Epoch: 25| Step: 0
Training loss: 3.215916156768799
Validation loss: 2.56838555746181

Epoch: 6| Step: 1
Training loss: 2.652130126953125
Validation loss: 2.5575790943637973

Epoch: 6| Step: 2
Training loss: 2.670156955718994
Validation loss: 2.552993151449388

Epoch: 6| Step: 3
Training loss: 2.0775046348571777
Validation loss: 2.5481690078653316

Epoch: 6| Step: 4
Training loss: 3.0692882537841797
Validation loss: 2.5484472038925334

Epoch: 6| Step: 5
Training loss: 3.3266475200653076
Validation loss: 2.5455410147225983

Epoch: 6| Step: 6
Training loss: 2.7098982334136963
Validation loss: 2.5475094459390126

Epoch: 6| Step: 7
Training loss: 2.4890904426574707
Validation loss: 2.5440729356581167

Epoch: 6| Step: 8
Training loss: 2.806155204772949
Validation loss: 2.54760173315643

Epoch: 6| Step: 9
Training loss: 2.4769582748413086
Validation loss: 2.5477161407470703

Epoch: 6| Step: 10
Training loss: 2.9840550422668457
Validation loss: 2.544552887639692

Epoch: 6| Step: 11
Training loss: 2.7191202640533447
Validation loss: 2.543768844296855

Epoch: 6| Step: 12
Training loss: 2.5350699424743652
Validation loss: 2.5434868771542787

Epoch: 6| Step: 13
Training loss: 3.108424663543701
Validation loss: 2.5441712538401284

Epoch: 26| Step: 0
Training loss: 1.5930252075195312
Validation loss: 2.545620943910332

Epoch: 6| Step: 1
Training loss: 2.769413471221924
Validation loss: 2.5507261958173526

Epoch: 6| Step: 2
Training loss: 3.3855669498443604
Validation loss: 2.53928376782325

Epoch: 6| Step: 3
Training loss: 2.4517080783843994
Validation loss: 2.5407020994412

Epoch: 6| Step: 4
Training loss: 2.8378963470458984
Validation loss: 2.5354188232011694

Epoch: 6| Step: 5
Training loss: 2.35699462890625
Validation loss: 2.528980719145908

Epoch: 6| Step: 6
Training loss: 2.884575366973877
Validation loss: 2.531286131951117

Epoch: 6| Step: 7
Training loss: 2.7026548385620117
Validation loss: 2.5300174015824513

Epoch: 6| Step: 8
Training loss: 3.1530840396881104
Validation loss: 2.5307804102538736

Epoch: 6| Step: 9
Training loss: 2.4893617630004883
Validation loss: 2.5384462571913198

Epoch: 6| Step: 10
Training loss: 2.956287384033203
Validation loss: 2.544226905351044

Epoch: 6| Step: 11
Training loss: 3.236142158508301
Validation loss: 2.544952407959969

Epoch: 6| Step: 12
Training loss: 2.9653100967407227
Validation loss: 2.5420585063196

Epoch: 6| Step: 13
Training loss: 2.8789029121398926
Validation loss: 2.5251156207053893

Epoch: 27| Step: 0
Training loss: 2.5545814037323
Validation loss: 2.520394645711427

Epoch: 6| Step: 1
Training loss: 2.0943565368652344
Validation loss: 2.5168208358108357

Epoch: 6| Step: 2
Training loss: 1.8597731590270996
Validation loss: 2.5157429249055925

Epoch: 6| Step: 3
Training loss: 3.151658535003662
Validation loss: 2.5134492945927445

Epoch: 6| Step: 4
Training loss: 3.7995195388793945
Validation loss: 2.512007931227325

Epoch: 6| Step: 5
Training loss: 3.031296730041504
Validation loss: 2.512913860300536

Epoch: 6| Step: 6
Training loss: 3.026982069015503
Validation loss: 2.508980812564973

Epoch: 6| Step: 7
Training loss: 2.581630229949951
Validation loss: 2.50917895378605

Epoch: 6| Step: 8
Training loss: 3.030625820159912
Validation loss: 2.508715348858987

Epoch: 6| Step: 9
Training loss: 2.4633772373199463
Validation loss: 2.5146609737027075

Epoch: 6| Step: 10
Training loss: 2.787332534790039
Validation loss: 2.530914993696315

Epoch: 6| Step: 11
Training loss: 2.4184298515319824
Validation loss: 2.5589855614528862

Epoch: 6| Step: 12
Training loss: 3.1376166343688965
Validation loss: 2.5601142990973687

Epoch: 6| Step: 13
Training loss: 2.276609182357788
Validation loss: 2.532011421777869

Epoch: 28| Step: 0
Training loss: 2.3865675926208496
Validation loss: 2.5397285799826346

Epoch: 6| Step: 1
Training loss: 2.4492712020874023
Validation loss: 2.507812669200282

Epoch: 6| Step: 2
Training loss: 2.549466848373413
Validation loss: 2.5032743356561147

Epoch: 6| Step: 3
Training loss: 3.152416229248047
Validation loss: 2.498753373340894

Epoch: 6| Step: 4
Training loss: 3.1996102333068848
Validation loss: 2.502134176992601

Epoch: 6| Step: 5
Training loss: 2.8841981887817383
Validation loss: 2.504680392562702

Epoch: 6| Step: 6
Training loss: 2.599735736846924
Validation loss: 2.502063948621032

Epoch: 6| Step: 7
Training loss: 1.9682765007019043
Validation loss: 2.501831252087829

Epoch: 6| Step: 8
Training loss: 2.6642417907714844
Validation loss: 2.5007372158829884

Epoch: 6| Step: 9
Training loss: 2.298933267593384
Validation loss: 2.4999101597775697

Epoch: 6| Step: 10
Training loss: 2.786175489425659
Validation loss: 2.5007602348122546

Epoch: 6| Step: 11
Training loss: 2.7816579341888428
Validation loss: 2.5170086968329644

Epoch: 6| Step: 12
Training loss: 2.964165449142456
Validation loss: 2.5289267006740777

Epoch: 6| Step: 13
Training loss: 4.340880393981934
Validation loss: 2.557278556208457

Epoch: 29| Step: 0
Training loss: 2.9454779624938965
Validation loss: 2.5545117265434674

Epoch: 6| Step: 1
Training loss: 2.912680149078369
Validation loss: 2.5273236433664956

Epoch: 6| Step: 2
Training loss: 3.948916435241699
Validation loss: 2.5205625000820366

Epoch: 6| Step: 3
Training loss: 2.117574691772461
Validation loss: 2.5000862101072907

Epoch: 6| Step: 4
Training loss: 1.725890874862671
Validation loss: 2.490287588488671

Epoch: 6| Step: 5
Training loss: 2.82814359664917
Validation loss: 2.4937611728586178

Epoch: 6| Step: 6
Training loss: 3.2414937019348145
Validation loss: 2.493829673336398

Epoch: 6| Step: 7
Training loss: 2.697726011276245
Validation loss: 2.4982404055133944

Epoch: 6| Step: 8
Training loss: 3.323945999145508
Validation loss: 2.49972173219086

Epoch: 6| Step: 9
Training loss: 2.412245035171509
Validation loss: 2.493078488175587

Epoch: 6| Step: 10
Training loss: 3.3728556632995605
Validation loss: 2.494519998950343

Epoch: 6| Step: 11
Training loss: 2.2738022804260254
Validation loss: 2.493211833379602

Epoch: 6| Step: 12
Training loss: 2.303018093109131
Validation loss: 2.488291355871385

Epoch: 6| Step: 13
Training loss: 1.812104344367981
Validation loss: 2.4873204436353458

Epoch: 30| Step: 0
Training loss: 2.6717529296875
Validation loss: 2.4956854902287966

Epoch: 6| Step: 1
Training loss: 3.255330801010132
Validation loss: 2.5020486411227973

Epoch: 6| Step: 2
Training loss: 2.40390944480896
Validation loss: 2.499061602418141

Epoch: 6| Step: 3
Training loss: 2.717599868774414
Validation loss: 2.510509026947842

Epoch: 6| Step: 4
Training loss: 2.723062038421631
Validation loss: 2.5065481944750716

Epoch: 6| Step: 5
Training loss: 2.5657105445861816
Validation loss: 2.503148099427582

Epoch: 6| Step: 6
Training loss: 3.006667137145996
Validation loss: 2.5082897011951735

Epoch: 6| Step: 7
Training loss: 3.663480281829834
Validation loss: 2.499029233891477

Epoch: 6| Step: 8
Training loss: 2.0836079120635986
Validation loss: 2.4920880820161555

Epoch: 6| Step: 9
Training loss: 2.3566179275512695
Validation loss: 2.485417401918801

Epoch: 6| Step: 10
Training loss: 2.5000505447387695
Validation loss: 2.481595080385926

Epoch: 6| Step: 11
Training loss: 2.572612762451172
Validation loss: 2.4831578077808505

Epoch: 6| Step: 12
Training loss: 2.3945655822753906
Validation loss: 2.48247875449478

Epoch: 6| Step: 13
Training loss: 3.5732107162475586
Validation loss: 2.4771236296622985

Epoch: 31| Step: 0
Training loss: 2.502403497695923
Validation loss: 2.476249679442375

Epoch: 6| Step: 1
Training loss: 2.65799617767334
Validation loss: 2.4806314155619633

Epoch: 6| Step: 2
Training loss: 2.9645721912384033
Validation loss: 2.477546952104056

Epoch: 6| Step: 3
Training loss: 2.4367287158966064
Validation loss: 2.4788979227824877

Epoch: 6| Step: 4
Training loss: 2.8645591735839844
Validation loss: 2.480536307058027

Epoch: 6| Step: 5
Training loss: 3.2607526779174805
Validation loss: 2.491491881749963

Epoch: 6| Step: 6
Training loss: 2.913983106613159
Validation loss: 2.5034480453819357

Epoch: 6| Step: 7
Training loss: 2.5982327461242676
Validation loss: 2.506538429567891

Epoch: 6| Step: 8
Training loss: 2.843022346496582
Validation loss: 2.510089046211653

Epoch: 6| Step: 9
Training loss: 1.7158715724945068
Validation loss: 2.5214548726235666

Epoch: 6| Step: 10
Training loss: 2.6297402381896973
Validation loss: 2.4956514989176104

Epoch: 6| Step: 11
Training loss: 2.608020782470703
Validation loss: 2.481561255711381

Epoch: 6| Step: 12
Training loss: 3.0424153804779053
Validation loss: 2.4732903562566286

Epoch: 6| Step: 13
Training loss: 3.1010196208953857
Validation loss: 2.47617926648868

Epoch: 32| Step: 0
Training loss: 2.465728282928467
Validation loss: 2.4831928155755483

Epoch: 6| Step: 1
Training loss: 2.5372154712677
Validation loss: 2.4760943612744732

Epoch: 6| Step: 2
Training loss: 2.752871513366699
Validation loss: 2.480837639941964

Epoch: 6| Step: 3
Training loss: 2.3836019039154053
Validation loss: 2.4824022246945288

Epoch: 6| Step: 4
Training loss: 3.1761746406555176
Validation loss: 2.4783285869065153

Epoch: 6| Step: 5
Training loss: 3.552154064178467
Validation loss: 2.4822170965133177

Epoch: 6| Step: 6
Training loss: 2.6949760913848877
Validation loss: 2.4795609302418207

Epoch: 6| Step: 7
Training loss: 2.5063560009002686
Validation loss: 2.475452500004922

Epoch: 6| Step: 8
Training loss: 3.3422000408172607
Validation loss: 2.4767449337949037

Epoch: 6| Step: 9
Training loss: 3.074326515197754
Validation loss: 2.476505430795813

Epoch: 6| Step: 10
Training loss: 2.6490283012390137
Validation loss: 2.478328130578482

Epoch: 6| Step: 11
Training loss: 2.008517265319824
Validation loss: 2.476605922945084

Epoch: 6| Step: 12
Training loss: 2.4353761672973633
Validation loss: 2.478572032784903

Epoch: 6| Step: 13
Training loss: 2.1794049739837646
Validation loss: 2.4733293697398198

Epoch: 33| Step: 0
Training loss: 2.8842363357543945
Validation loss: 2.476457216406381

Epoch: 6| Step: 1
Training loss: 2.742764949798584
Validation loss: 2.478896220525106

Epoch: 6| Step: 2
Training loss: 2.5591585636138916
Validation loss: 2.4746288176505797

Epoch: 6| Step: 3
Training loss: 2.876046657562256
Validation loss: 2.476847643493324

Epoch: 6| Step: 4
Training loss: 2.5824601650238037
Validation loss: 2.468318577735655

Epoch: 6| Step: 5
Training loss: 2.264333963394165
Validation loss: 2.466090621486787

Epoch: 6| Step: 6
Training loss: 2.6522982120513916
Validation loss: 2.4667184314420147

Epoch: 6| Step: 7
Training loss: 2.4419431686401367
Validation loss: 2.462758210397536

Epoch: 6| Step: 8
Training loss: 2.5299108028411865
Validation loss: 2.4638762166423183

Epoch: 6| Step: 9
Training loss: 2.991051197052002
Validation loss: 2.4666688006411315

Epoch: 6| Step: 10
Training loss: 2.785487651824951
Validation loss: 2.4644450192810385

Epoch: 6| Step: 11
Training loss: 2.951913595199585
Validation loss: 2.462495598741757

Epoch: 6| Step: 12
Training loss: 3.1417765617370605
Validation loss: 2.4610012859426518

Epoch: 6| Step: 13
Training loss: 2.198378562927246
Validation loss: 2.460354894720098

Epoch: 34| Step: 0
Training loss: 2.312624931335449
Validation loss: 2.461359659830729

Epoch: 6| Step: 1
Training loss: 2.580709457397461
Validation loss: 2.4632028456657165

Epoch: 6| Step: 2
Training loss: 2.3891406059265137
Validation loss: 2.456179949545091

Epoch: 6| Step: 3
Training loss: 3.575711250305176
Validation loss: 2.458796088413526

Epoch: 6| Step: 4
Training loss: 3.4802443981170654
Validation loss: 2.465059152213476

Epoch: 6| Step: 5
Training loss: 2.6090826988220215
Validation loss: 2.461822966093658

Epoch: 6| Step: 6
Training loss: 3.0653815269470215
Validation loss: 2.458060727324537

Epoch: 6| Step: 7
Training loss: 2.403607130050659
Validation loss: 2.463793437968018

Epoch: 6| Step: 8
Training loss: 1.8830788135528564
Validation loss: 2.45851485190853

Epoch: 6| Step: 9
Training loss: 2.618706226348877
Validation loss: 2.4595077294175343

Epoch: 6| Step: 10
Training loss: 2.570164203643799
Validation loss: 2.457685475708336

Epoch: 6| Step: 11
Training loss: 2.997107744216919
Validation loss: 2.466954674772037

Epoch: 6| Step: 12
Training loss: 2.052964448928833
Validation loss: 2.4735753895134054

Epoch: 6| Step: 13
Training loss: 3.66817569732666
Validation loss: 2.489721357181508

Epoch: 35| Step: 0
Training loss: 2.910737991333008
Validation loss: 2.497509282122376

Epoch: 6| Step: 1
Training loss: 2.7668657302856445
Validation loss: 2.5013200877815165

Epoch: 6| Step: 2
Training loss: 2.6856117248535156
Validation loss: 2.5027423648424048

Epoch: 6| Step: 3
Training loss: 2.564570903778076
Validation loss: 2.507523613591348

Epoch: 6| Step: 4
Training loss: 2.73231840133667
Validation loss: 2.497607054248933

Epoch: 6| Step: 5
Training loss: 2.1246728897094727
Validation loss: 2.4806864799991732

Epoch: 6| Step: 6
Training loss: 3.057816505432129
Validation loss: 2.4658823897761684

Epoch: 6| Step: 7
Training loss: 2.640805721282959
Validation loss: 2.4601011506972776

Epoch: 6| Step: 8
Training loss: 2.5800118446350098
Validation loss: 2.455310385714295

Epoch: 6| Step: 9
Training loss: 2.5489091873168945
Validation loss: 2.4542502946751092

Epoch: 6| Step: 10
Training loss: 3.0973682403564453
Validation loss: 2.4552962446725495

Epoch: 6| Step: 11
Training loss: 2.6485915184020996
Validation loss: 2.458967880536151

Epoch: 6| Step: 12
Training loss: 2.962167978286743
Validation loss: 2.459814653601698

Epoch: 6| Step: 13
Training loss: 2.1805779933929443
Validation loss: 2.4592212169401106

Epoch: 36| Step: 0
Training loss: 2.479234218597412
Validation loss: 2.4539154344989407

Epoch: 6| Step: 1
Training loss: 2.3138179779052734
Validation loss: 2.455415120688818

Epoch: 6| Step: 2
Training loss: 2.9984889030456543
Validation loss: 2.454693123858462

Epoch: 6| Step: 3
Training loss: 3.1348838806152344
Validation loss: 2.449406626403973

Epoch: 6| Step: 4
Training loss: 3.0135507583618164
Validation loss: 2.4547966834037536

Epoch: 6| Step: 5
Training loss: 1.9015023708343506
Validation loss: 2.4650651895871727

Epoch: 6| Step: 6
Training loss: 2.956425428390503
Validation loss: 2.4653913462033836

Epoch: 6| Step: 7
Training loss: 2.4150948524475098
Validation loss: 2.4645508438028316

Epoch: 6| Step: 8
Training loss: 2.3558759689331055
Validation loss: 2.4597021149050806

Epoch: 6| Step: 9
Training loss: 2.9261937141418457
Validation loss: 2.454067373788485

Epoch: 6| Step: 10
Training loss: 2.804109573364258
Validation loss: 2.4527878607473066

Epoch: 6| Step: 11
Training loss: 3.182927370071411
Validation loss: 2.449828101742652

Epoch: 6| Step: 12
Training loss: 2.8753232955932617
Validation loss: 2.4490963541051394

Epoch: 6| Step: 13
Training loss: 2.2615694999694824
Validation loss: 2.4481234140293573

Epoch: 37| Step: 0
Training loss: 2.5687646865844727
Validation loss: 2.451706691454816

Epoch: 6| Step: 1
Training loss: 2.6481051445007324
Validation loss: 2.454802287522183

Epoch: 6| Step: 2
Training loss: 2.637056350708008
Validation loss: 2.467730863119966

Epoch: 6| Step: 3
Training loss: 3.802187442779541
Validation loss: 2.4829170832069973

Epoch: 6| Step: 4
Training loss: 2.967151403427124
Validation loss: 2.481671658895349

Epoch: 6| Step: 5
Training loss: 2.5187315940856934
Validation loss: 2.4910660072039534

Epoch: 6| Step: 6
Training loss: 2.1489462852478027
Validation loss: 2.4763018956748386

Epoch: 6| Step: 7
Training loss: 2.6748046875
Validation loss: 2.471660480704359

Epoch: 6| Step: 8
Training loss: 3.24820613861084
Validation loss: 2.455314854139923

Epoch: 6| Step: 9
Training loss: 2.590205192565918
Validation loss: 2.4439548471922516

Epoch: 6| Step: 10
Training loss: 2.079644203186035
Validation loss: 2.4379814542749876

Epoch: 6| Step: 11
Training loss: 3.405208110809326
Validation loss: 2.438169471679195

Epoch: 6| Step: 12
Training loss: 2.3227767944335938
Validation loss: 2.4389707157688756

Epoch: 6| Step: 13
Training loss: 1.350327968597412
Validation loss: 2.4404286287164174

Epoch: 38| Step: 0
Training loss: 3.056309223175049
Validation loss: 2.4367271059302875

Epoch: 6| Step: 1
Training loss: 2.353891134262085
Validation loss: 2.4383178987810687

Epoch: 6| Step: 2
Training loss: 2.7566871643066406
Validation loss: 2.4378142485054592

Epoch: 6| Step: 3
Training loss: 2.1910362243652344
Validation loss: 2.4405740358496226

Epoch: 6| Step: 4
Training loss: 2.6216392517089844
Validation loss: 2.4399206253790084

Epoch: 6| Step: 5
Training loss: 2.285104751586914
Validation loss: 2.43748499244772

Epoch: 6| Step: 6
Training loss: 2.4298884868621826
Validation loss: 2.4371492837065007

Epoch: 6| Step: 7
Training loss: 2.986900806427002
Validation loss: 2.43725602088436

Epoch: 6| Step: 8
Training loss: 2.701662540435791
Validation loss: 2.4385908085812806

Epoch: 6| Step: 9
Training loss: 2.927306652069092
Validation loss: 2.4399353560581

Epoch: 6| Step: 10
Training loss: 2.88655161857605
Validation loss: 2.4482929450209423

Epoch: 6| Step: 11
Training loss: 2.3751585483551025
Validation loss: 2.4431393838697866

Epoch: 6| Step: 12
Training loss: 2.967315673828125
Validation loss: 2.446714393554195

Epoch: 6| Step: 13
Training loss: 3.212531089782715
Validation loss: 2.4507801660927395

Epoch: 39| Step: 0
Training loss: 2.5723137855529785
Validation loss: 2.457461351989418

Epoch: 6| Step: 1
Training loss: 2.3595077991485596
Validation loss: 2.4617946891374487

Epoch: 6| Step: 2
Training loss: 2.513941764831543
Validation loss: 2.4756195545196533

Epoch: 6| Step: 3
Training loss: 2.014446258544922
Validation loss: 2.481014379891016

Epoch: 6| Step: 4
Training loss: 3.1193132400512695
Validation loss: 2.484614331235168

Epoch: 6| Step: 5
Training loss: 2.703138828277588
Validation loss: 2.5008677949187574

Epoch: 6| Step: 6
Training loss: 2.105114459991455
Validation loss: 2.5018784846028974

Epoch: 6| Step: 7
Training loss: 2.7594521045684814
Validation loss: 2.476424063405683

Epoch: 6| Step: 8
Training loss: 3.5441396236419678
Validation loss: 2.4690767026716665

Epoch: 6| Step: 9
Training loss: 3.105621814727783
Validation loss: 2.460998055755451

Epoch: 6| Step: 10
Training loss: 2.414673328399658
Validation loss: 2.4536160551091677

Epoch: 6| Step: 11
Training loss: 2.785634994506836
Validation loss: 2.4462588243587042

Epoch: 6| Step: 12
Training loss: 2.798306703567505
Validation loss: 2.4381589915162776

Epoch: 6| Step: 13
Training loss: 2.647869825363159
Validation loss: 2.4360937585112867

Epoch: 40| Step: 0
Training loss: 2.8638505935668945
Validation loss: 2.4362788943834204

Epoch: 6| Step: 1
Training loss: 2.0585503578186035
Validation loss: 2.439410986438874

Epoch: 6| Step: 2
Training loss: 2.6121885776519775
Validation loss: 2.436491604774229

Epoch: 6| Step: 3
Training loss: 2.038491725921631
Validation loss: 2.43636743996733

Epoch: 6| Step: 4
Training loss: 3.4242537021636963
Validation loss: 2.434549347046883

Epoch: 6| Step: 5
Training loss: 2.551138162612915
Validation loss: 2.4302194028772335

Epoch: 6| Step: 6
Training loss: 3.2363390922546387
Validation loss: 2.42689000919301

Epoch: 6| Step: 7
Training loss: 2.5832643508911133
Validation loss: 2.423001033003612

Epoch: 6| Step: 8
Training loss: 2.5444979667663574
Validation loss: 2.427005490949077

Epoch: 6| Step: 9
Training loss: 1.9945591688156128
Validation loss: 2.427480695068195

Epoch: 6| Step: 10
Training loss: 2.478447437286377
Validation loss: 2.4256157464878534

Epoch: 6| Step: 11
Training loss: 2.899355888366699
Validation loss: 2.429101926024242

Epoch: 6| Step: 12
Training loss: 2.988954544067383
Validation loss: 2.433557579594274

Epoch: 6| Step: 13
Training loss: 3.357158899307251
Validation loss: 2.436693306892149

Epoch: 41| Step: 0
Training loss: 2.8783586025238037
Validation loss: 2.45296634140835

Epoch: 6| Step: 1
Training loss: 2.6193552017211914
Validation loss: 2.4732035872756795

Epoch: 6| Step: 2
Training loss: 2.670604705810547
Validation loss: 2.4966978821703183

Epoch: 6| Step: 3
Training loss: 2.2887496948242188
Validation loss: 2.5211626816821355

Epoch: 6| Step: 4
Training loss: 3.516556739807129
Validation loss: 2.541122151959327

Epoch: 6| Step: 5
Training loss: 3.798146963119507
Validation loss: 2.51795897945281

Epoch: 6| Step: 6
Training loss: 2.4398934841156006
Validation loss: 2.492685669211931

Epoch: 6| Step: 7
Training loss: 2.5478947162628174
Validation loss: 2.4604251564189954

Epoch: 6| Step: 8
Training loss: 2.658930778503418
Validation loss: 2.4290942222841325

Epoch: 6| Step: 9
Training loss: 2.8893725872039795
Validation loss: 2.414793460599838

Epoch: 6| Step: 10
Training loss: 2.517971992492676
Validation loss: 2.4269372058171097

Epoch: 6| Step: 11
Training loss: 1.6706105470657349
Validation loss: 2.4678009889459096

Epoch: 6| Step: 12
Training loss: 2.0520009994506836
Validation loss: 2.4951792558034263

Epoch: 6| Step: 13
Training loss: 3.3241870403289795
Validation loss: 2.5253257238736717

Epoch: 42| Step: 0
Training loss: 2.8674116134643555
Validation loss: 2.538555832319362

Epoch: 6| Step: 1
Training loss: 3.145585060119629
Validation loss: 2.550996013866958

Epoch: 6| Step: 2
Training loss: 3.383450508117676
Validation loss: 2.542769762777513

Epoch: 6| Step: 3
Training loss: 2.2745158672332764
Validation loss: 2.5251656834797194

Epoch: 6| Step: 4
Training loss: 2.7257328033447266
Validation loss: 2.5118222723725023

Epoch: 6| Step: 5
Training loss: 2.855546474456787
Validation loss: 2.509785759833551

Epoch: 6| Step: 6
Training loss: 2.619004964828491
Validation loss: 2.500502268473307

Epoch: 6| Step: 7
Training loss: 2.7189340591430664
Validation loss: 2.493099163937312

Epoch: 6| Step: 8
Training loss: 2.7557477951049805
Validation loss: 2.4853858691389843

Epoch: 6| Step: 9
Training loss: 2.4743173122406006
Validation loss: 2.4778621196746826

Epoch: 6| Step: 10
Training loss: 2.0373823642730713
Validation loss: 2.474628404904437

Epoch: 6| Step: 11
Training loss: 2.7064926624298096
Validation loss: 2.4739115776554232

Epoch: 6| Step: 12
Training loss: 2.629037857055664
Validation loss: 2.4836310032875306

Epoch: 6| Step: 13
Training loss: 2.937270164489746
Validation loss: 2.4918552983191704

Epoch: 43| Step: 0
Training loss: 2.9465370178222656
Validation loss: 2.499582362431352

Epoch: 6| Step: 1
Training loss: 2.6332521438598633
Validation loss: 2.509982967889437

Epoch: 6| Step: 2
Training loss: 3.115974187850952
Validation loss: 2.526484568913778

Epoch: 6| Step: 3
Training loss: 2.608229637145996
Validation loss: 2.5357497481889624

Epoch: 6| Step: 4
Training loss: 2.347243309020996
Validation loss: 2.514619864443297

Epoch: 6| Step: 5
Training loss: 2.8965086936950684
Validation loss: 2.4952622741781254

Epoch: 6| Step: 6
Training loss: 2.188876152038574
Validation loss: 2.4824102322260537

Epoch: 6| Step: 7
Training loss: 1.9001986980438232
Validation loss: 2.4786069854613273

Epoch: 6| Step: 8
Training loss: 3.0098164081573486
Validation loss: 2.4877476025653142

Epoch: 6| Step: 9
Training loss: 2.1738409996032715
Validation loss: 2.5024814426258044

Epoch: 6| Step: 10
Training loss: 2.893488883972168
Validation loss: 2.49740182968878

Epoch: 6| Step: 11
Training loss: 3.0344395637512207
Validation loss: 2.4583247169371574

Epoch: 6| Step: 12
Training loss: 2.9990439414978027
Validation loss: 2.439507248581097

Epoch: 6| Step: 13
Training loss: 3.3466134071350098
Validation loss: 2.421774866760418

Epoch: 44| Step: 0
Training loss: 3.5300300121307373
Validation loss: 2.4172486874365036

Epoch: 6| Step: 1
Training loss: 1.8751628398895264
Validation loss: 2.408652890113092

Epoch: 6| Step: 2
Training loss: 2.615490674972534
Validation loss: 2.408690106484198

Epoch: 6| Step: 3
Training loss: 2.8680028915405273
Validation loss: 2.4096413171419533

Epoch: 6| Step: 4
Training loss: 2.698788642883301
Validation loss: 2.4130399906507103

Epoch: 6| Step: 5
Training loss: 2.995492458343506
Validation loss: 2.4110024949555755

Epoch: 6| Step: 6
Training loss: 2.3466644287109375
Validation loss: 2.4144917124061176

Epoch: 6| Step: 7
Training loss: 3.104702949523926
Validation loss: 2.4136986424846034

Epoch: 6| Step: 8
Training loss: 2.2714428901672363
Validation loss: 2.416106785497358

Epoch: 6| Step: 9
Training loss: 3.4087371826171875
Validation loss: 2.4166982943011868

Epoch: 6| Step: 10
Training loss: 2.7367682456970215
Validation loss: 2.4245439114109164

Epoch: 6| Step: 11
Training loss: 2.7291388511657715
Validation loss: 2.429497711120113

Epoch: 6| Step: 12
Training loss: 1.2587735652923584
Validation loss: 2.4498921158493205

Epoch: 6| Step: 13
Training loss: 2.811133861541748
Validation loss: 2.4597348525959957

Epoch: 45| Step: 0
Training loss: 2.488574504852295
Validation loss: 2.475223413077734

Epoch: 6| Step: 1
Training loss: 3.6085805892944336
Validation loss: 2.493518178180982

Epoch: 6| Step: 2
Training loss: 2.896892786026001
Validation loss: 2.453334423803514

Epoch: 6| Step: 3
Training loss: 2.502718448638916
Validation loss: 2.4228884686705885

Epoch: 6| Step: 4
Training loss: 2.213705062866211
Validation loss: 2.40838945809231

Epoch: 6| Step: 5
Training loss: 3.0179057121276855
Validation loss: 2.3991272987857943

Epoch: 6| Step: 6
Training loss: 2.8881115913391113
Validation loss: 2.399248848679245

Epoch: 6| Step: 7
Training loss: 2.494622230529785
Validation loss: 2.400631612347018

Epoch: 6| Step: 8
Training loss: 2.295962333679199
Validation loss: 2.401727230318131

Epoch: 6| Step: 9
Training loss: 2.563840866088867
Validation loss: 2.4057911775445424

Epoch: 6| Step: 10
Training loss: 2.4216554164886475
Validation loss: 2.404223954805764

Epoch: 6| Step: 11
Training loss: 2.7691502571105957
Validation loss: 2.4038804090151222

Epoch: 6| Step: 12
Training loss: 2.84246563911438
Validation loss: 2.403370823911441

Epoch: 6| Step: 13
Training loss: 2.5549230575561523
Validation loss: 2.3982442502052552

Epoch: 46| Step: 0
Training loss: 2.7185773849487305
Validation loss: 2.398225922738352

Epoch: 6| Step: 1
Training loss: 2.825212240219116
Validation loss: 2.3963748255083637

Epoch: 6| Step: 2
Training loss: 2.5045788288116455
Validation loss: 2.3998508735369612

Epoch: 6| Step: 3
Training loss: 2.43204402923584
Validation loss: 2.40344823304043

Epoch: 6| Step: 4
Training loss: 2.22273850440979
Validation loss: 2.4060390687757924

Epoch: 6| Step: 5
Training loss: 3.633622407913208
Validation loss: 2.4163164143921225

Epoch: 6| Step: 6
Training loss: 2.7890067100524902
Validation loss: 2.4272888322030344

Epoch: 6| Step: 7
Training loss: 2.7829079627990723
Validation loss: 2.436715684911256

Epoch: 6| Step: 8
Training loss: 2.610846519470215
Validation loss: 2.4497830944676555

Epoch: 6| Step: 9
Training loss: 2.434739112854004
Validation loss: 2.4534587526834137

Epoch: 6| Step: 10
Training loss: 2.624584197998047
Validation loss: 2.451775391896566

Epoch: 6| Step: 11
Training loss: 2.620852470397949
Validation loss: 2.4327241169509066

Epoch: 6| Step: 12
Training loss: 2.3874683380126953
Validation loss: 2.4281534661528883

Epoch: 6| Step: 13
Training loss: 2.6914541721343994
Validation loss: 2.4159989459540254

Epoch: 47| Step: 0
Training loss: 3.4236397743225098
Validation loss: 2.4079113032228205

Epoch: 6| Step: 1
Training loss: 3.3083956241607666
Validation loss: 2.395559469858805

Epoch: 6| Step: 2
Training loss: 2.2467164993286133
Validation loss: 2.385417748523015

Epoch: 6| Step: 3
Training loss: 2.2832930088043213
Validation loss: 2.3896803420077086

Epoch: 6| Step: 4
Training loss: 2.189124822616577
Validation loss: 2.388815620894073

Epoch: 6| Step: 5
Training loss: 2.421684980392456
Validation loss: 2.3898239674106723

Epoch: 6| Step: 6
Training loss: 2.625009536743164
Validation loss: 2.3890948372502483

Epoch: 6| Step: 7
Training loss: 2.2176144123077393
Validation loss: 2.38885263986485

Epoch: 6| Step: 8
Training loss: 2.9035801887512207
Validation loss: 2.385978767948766

Epoch: 6| Step: 9
Training loss: 2.1772615909576416
Validation loss: 2.3850351174672446

Epoch: 6| Step: 10
Training loss: 3.4650888442993164
Validation loss: 2.387361285507038

Epoch: 6| Step: 11
Training loss: 3.0630111694335938
Validation loss: 2.384740939704321

Epoch: 6| Step: 12
Training loss: 2.337578296661377
Validation loss: 2.3817900483326246

Epoch: 6| Step: 13
Training loss: 2.400256633758545
Validation loss: 2.388349848408853

Epoch: 48| Step: 0
Training loss: 2.7822790145874023
Validation loss: 2.3922583928672214

Epoch: 6| Step: 1
Training loss: 2.27131986618042
Validation loss: 2.394365713160525

Epoch: 6| Step: 2
Training loss: 2.7477266788482666
Validation loss: 2.394989029053719

Epoch: 6| Step: 3
Training loss: 2.2589755058288574
Validation loss: 2.3934317199132775

Epoch: 6| Step: 4
Training loss: 3.234429359436035
Validation loss: 2.3973360651282856

Epoch: 6| Step: 5
Training loss: 2.075636386871338
Validation loss: 2.4056235590288715

Epoch: 6| Step: 6
Training loss: 2.08614182472229
Validation loss: 2.4033107219203824

Epoch: 6| Step: 7
Training loss: 3.013753890991211
Validation loss: 2.402073557658862

Epoch: 6| Step: 8
Training loss: 2.646425247192383
Validation loss: 2.397341988419974

Epoch: 6| Step: 9
Training loss: 2.1920289993286133
Validation loss: 2.3979318731574604

Epoch: 6| Step: 10
Training loss: 3.188149929046631
Validation loss: 2.395204549194664

Epoch: 6| Step: 11
Training loss: 2.6176695823669434
Validation loss: 2.3916378059694843

Epoch: 6| Step: 12
Training loss: 2.93656849861145
Validation loss: 2.38915019137885

Epoch: 6| Step: 13
Training loss: 3.0456109046936035
Validation loss: 2.389101879571074

Epoch: 49| Step: 0
Training loss: 2.3939075469970703
Validation loss: 2.393722682870844

Epoch: 6| Step: 1
Training loss: 2.717348098754883
Validation loss: 2.3951280732308664

Epoch: 6| Step: 2
Training loss: 2.3406457901000977
Validation loss: 2.395312778411373

Epoch: 6| Step: 3
Training loss: 3.4455742835998535
Validation loss: 2.395645103146953

Epoch: 6| Step: 4
Training loss: 2.465855121612549
Validation loss: 2.3953027315037225

Epoch: 6| Step: 5
Training loss: 2.2692227363586426
Validation loss: 2.40290932245152

Epoch: 6| Step: 6
Training loss: 2.411855459213257
Validation loss: 2.402868652856478

Epoch: 6| Step: 7
Training loss: 3.0543408393859863
Validation loss: 2.3973253055285384

Epoch: 6| Step: 8
Training loss: 2.0984058380126953
Validation loss: 2.4014859276433147

Epoch: 6| Step: 9
Training loss: 3.122305154800415
Validation loss: 2.3961779353439168

Epoch: 6| Step: 10
Training loss: 2.98237681388855
Validation loss: 2.394130495286757

Epoch: 6| Step: 11
Training loss: 1.8700357675552368
Validation loss: 2.3959399782201296

Epoch: 6| Step: 12
Training loss: 3.308555841445923
Validation loss: 2.395196017398629

Epoch: 6| Step: 13
Training loss: 2.3703272342681885
Validation loss: 2.404880041717201

Epoch: 50| Step: 0
Training loss: 2.4989829063415527
Validation loss: 2.4039276440938315

Epoch: 6| Step: 1
Training loss: 2.487696886062622
Validation loss: 2.412245378699354

Epoch: 6| Step: 2
Training loss: 2.278883457183838
Validation loss: 2.414814482453049

Epoch: 6| Step: 3
Training loss: 3.310546398162842
Validation loss: 2.4179896436711794

Epoch: 6| Step: 4
Training loss: 2.3862788677215576
Validation loss: 2.416100068758893

Epoch: 6| Step: 5
Training loss: 3.0161619186401367
Validation loss: 2.409680874116959

Epoch: 6| Step: 6
Training loss: 2.7454347610473633
Validation loss: 2.407129523574665

Epoch: 6| Step: 7
Training loss: 3.0345618724823
Validation loss: 2.4012662133862896

Epoch: 6| Step: 8
Training loss: 2.348681926727295
Validation loss: 2.3960795171799196

Epoch: 6| Step: 9
Training loss: 2.0904576778411865
Validation loss: 2.3967431206857004

Epoch: 6| Step: 10
Training loss: 2.1286191940307617
Validation loss: 2.3987745418343493

Epoch: 6| Step: 11
Training loss: 3.114875555038452
Validation loss: 2.396018930660781

Epoch: 6| Step: 12
Training loss: 2.529770612716675
Validation loss: 2.396583669929094

Epoch: 6| Step: 13
Training loss: 2.9849257469177246
Validation loss: 2.3893173330573627

Epoch: 51| Step: 0
Training loss: 2.4095029830932617
Validation loss: 2.3871563326927925

Epoch: 6| Step: 1
Training loss: 2.5634946823120117
Validation loss: 2.3861987154970885

Epoch: 6| Step: 2
Training loss: 2.781271457672119
Validation loss: 2.3861537646221858

Epoch: 6| Step: 3
Training loss: 2.7814528942108154
Validation loss: 2.3877519894671697

Epoch: 6| Step: 4
Training loss: 3.0363121032714844
Validation loss: 2.38798362465315

Epoch: 6| Step: 5
Training loss: 2.3054420948028564
Validation loss: 2.3755586724127493

Epoch: 6| Step: 6
Training loss: 2.9364218711853027
Validation loss: 2.376914862663515

Epoch: 6| Step: 7
Training loss: 2.743621349334717
Validation loss: 2.3751887300963044

Epoch: 6| Step: 8
Training loss: 2.8552725315093994
Validation loss: 2.378473269042148

Epoch: 6| Step: 9
Training loss: 2.19364595413208
Validation loss: 2.3781387331665202

Epoch: 6| Step: 10
Training loss: 2.462522506713867
Validation loss: 2.3759838304212018

Epoch: 6| Step: 11
Training loss: 2.7863454818725586
Validation loss: 2.3808479847446566

Epoch: 6| Step: 12
Training loss: 2.3224246501922607
Validation loss: 2.387139256282519

Epoch: 6| Step: 13
Training loss: 2.5763421058654785
Validation loss: 2.397866133720644

Epoch: 52| Step: 0
Training loss: 1.6892422437667847
Validation loss: 2.3997670283881565

Epoch: 6| Step: 1
Training loss: 2.580679416656494
Validation loss: 2.411769854125156

Epoch: 6| Step: 2
Training loss: 2.1204068660736084
Validation loss: 2.4210713345517396

Epoch: 6| Step: 3
Training loss: 2.5512447357177734
Validation loss: 2.4241308781408493

Epoch: 6| Step: 4
Training loss: 3.6408236026763916
Validation loss: 2.422545979099889

Epoch: 6| Step: 5
Training loss: 2.8654870986938477
Validation loss: 2.415449950002855

Epoch: 6| Step: 6
Training loss: 3.0812878608703613
Validation loss: 2.3923577108690814

Epoch: 6| Step: 7
Training loss: 2.333340644836426
Validation loss: 2.38231752252066

Epoch: 6| Step: 8
Training loss: 2.2209107875823975
Validation loss: 2.3750018906849686

Epoch: 6| Step: 9
Training loss: 2.733076572418213
Validation loss: 2.3637474352313625

Epoch: 6| Step: 10
Training loss: 2.667510986328125
Validation loss: 2.3629649223819857

Epoch: 6| Step: 11
Training loss: 2.4668946266174316
Validation loss: 2.363787594661918

Epoch: 6| Step: 12
Training loss: 2.979639768600464
Validation loss: 2.361337382306335

Epoch: 6| Step: 13
Training loss: 2.8358545303344727
Validation loss: 2.361793141211233

Epoch: 53| Step: 0
Training loss: 2.736879587173462
Validation loss: 2.3589776895379506

Epoch: 6| Step: 1
Training loss: 2.625028133392334
Validation loss: 2.357942404285554

Epoch: 6| Step: 2
Training loss: 2.6691555976867676
Validation loss: 2.358004907126068

Epoch: 6| Step: 3
Training loss: 2.1750400066375732
Validation loss: 2.3598989876367713

Epoch: 6| Step: 4
Training loss: 2.868246078491211
Validation loss: 2.3567400824639106

Epoch: 6| Step: 5
Training loss: 2.7182390689849854
Validation loss: 2.3585260375853507

Epoch: 6| Step: 6
Training loss: 2.74456787109375
Validation loss: 2.357459516935451

Epoch: 6| Step: 7
Training loss: 2.6353678703308105
Validation loss: 2.3564093292400403

Epoch: 6| Step: 8
Training loss: 3.163698196411133
Validation loss: 2.353023562380063

Epoch: 6| Step: 9
Training loss: 2.2900919914245605
Validation loss: 2.354752532897457

Epoch: 6| Step: 10
Training loss: 2.291780710220337
Validation loss: 2.3576470908298286

Epoch: 6| Step: 11
Training loss: 2.9456872940063477
Validation loss: 2.3607087955679944

Epoch: 6| Step: 12
Training loss: 2.6543498039245605
Validation loss: 2.362713744563441

Epoch: 6| Step: 13
Training loss: 1.9300808906555176
Validation loss: 2.3685343906443608

Epoch: 54| Step: 0
Training loss: 2.626829147338867
Validation loss: 2.3796933517661145

Epoch: 6| Step: 1
Training loss: 2.611205816268921
Validation loss: 2.3948236037326116

Epoch: 6| Step: 2
Training loss: 2.7225332260131836
Validation loss: 2.407827159409882

Epoch: 6| Step: 3
Training loss: 3.011251926422119
Validation loss: 2.4073486276852187

Epoch: 6| Step: 4
Training loss: 2.566739082336426
Validation loss: 2.4060459265144925

Epoch: 6| Step: 5
Training loss: 2.192188262939453
Validation loss: 2.398914211539812

Epoch: 6| Step: 6
Training loss: 1.7111921310424805
Validation loss: 2.3739607103409304

Epoch: 6| Step: 7
Training loss: 2.8660879135131836
Validation loss: 2.3561985825979583

Epoch: 6| Step: 8
Training loss: 3.2809433937072754
Validation loss: 2.3541197571703183

Epoch: 6| Step: 9
Training loss: 3.150514602661133
Validation loss: 2.348616889728013

Epoch: 6| Step: 10
Training loss: 1.81760573387146
Validation loss: 2.3519473460412796

Epoch: 6| Step: 11
Training loss: 3.0323798656463623
Validation loss: 2.3496453762054443

Epoch: 6| Step: 12
Training loss: 2.7597672939300537
Validation loss: 2.3513929382447274

Epoch: 6| Step: 13
Training loss: 2.340036153793335
Validation loss: 2.3465324473637406

Epoch: 55| Step: 0
Training loss: 2.870878219604492
Validation loss: 2.350107449357228

Epoch: 6| Step: 1
Training loss: 2.8882179260253906
Validation loss: 2.3486234603389615

Epoch: 6| Step: 2
Training loss: 2.638122320175171
Validation loss: 2.3454051684307795

Epoch: 6| Step: 3
Training loss: 2.914303779602051
Validation loss: 2.3520394320129068

Epoch: 6| Step: 4
Training loss: 2.6970772743225098
Validation loss: 2.3613369182873796

Epoch: 6| Step: 5
Training loss: 2.151322364807129
Validation loss: 2.369182591797203

Epoch: 6| Step: 6
Training loss: 2.7336459159851074
Validation loss: 2.3733274859766804

Epoch: 6| Step: 7
Training loss: 2.126347064971924
Validation loss: 2.3816527987039215

Epoch: 6| Step: 8
Training loss: 2.415093421936035
Validation loss: 2.382873378774171

Epoch: 6| Step: 9
Training loss: 2.8720107078552246
Validation loss: 2.3989884032998035

Epoch: 6| Step: 10
Training loss: 2.3239049911499023
Validation loss: 2.416688803703554

Epoch: 6| Step: 11
Training loss: 2.2602248191833496
Validation loss: 2.42225036826185

Epoch: 6| Step: 12
Training loss: 2.9255571365356445
Validation loss: 2.4221731514059086

Epoch: 6| Step: 13
Training loss: 2.989997625350952
Validation loss: 2.425011219516877

Epoch: 56| Step: 0
Training loss: 2.5777316093444824
Validation loss: 2.4187551826559086

Epoch: 6| Step: 1
Training loss: 3.268003225326538
Validation loss: 2.4039587718184277

Epoch: 6| Step: 2
Training loss: 2.2710516452789307
Validation loss: 2.393001156468545

Epoch: 6| Step: 3
Training loss: 2.540074348449707
Validation loss: 2.3749201349032822

Epoch: 6| Step: 4
Training loss: 2.2092347145080566
Validation loss: 2.3740338843355895

Epoch: 6| Step: 5
Training loss: 2.4915544986724854
Validation loss: 2.365759593184276

Epoch: 6| Step: 6
Training loss: 2.4239492416381836
Validation loss: 2.3647125126213155

Epoch: 6| Step: 7
Training loss: 2.8670504093170166
Validation loss: 2.3568600711002143

Epoch: 6| Step: 8
Training loss: 2.678762912750244
Validation loss: 2.3618287399250972

Epoch: 6| Step: 9
Training loss: 3.0976624488830566
Validation loss: 2.360069359502485

Epoch: 6| Step: 10
Training loss: 2.560227155685425
Validation loss: 2.3490987964855727

Epoch: 6| Step: 11
Training loss: 2.5478878021240234
Validation loss: 2.345956030712333

Epoch: 6| Step: 12
Training loss: 2.7916483879089355
Validation loss: 2.3426589504365

Epoch: 6| Step: 13
Training loss: 2.021620750427246
Validation loss: 2.3413798014322915

Epoch: 57| Step: 0
Training loss: 2.648345947265625
Validation loss: 2.3414019999965543

Epoch: 6| Step: 1
Training loss: 2.5385406017303467
Validation loss: 2.340637735141221

Epoch: 6| Step: 2
Training loss: 2.747690439224243
Validation loss: 2.340489823331115

Epoch: 6| Step: 3
Training loss: 3.052586078643799
Validation loss: 2.340846946162562

Epoch: 6| Step: 4
Training loss: 2.5976319313049316
Validation loss: 2.337037440269224

Epoch: 6| Step: 5
Training loss: 3.0898232460021973
Validation loss: 2.3387562574878817

Epoch: 6| Step: 6
Training loss: 2.6424710750579834
Validation loss: 2.3352810131606234

Epoch: 6| Step: 7
Training loss: 2.3593478202819824
Validation loss: 2.336433426026375

Epoch: 6| Step: 8
Training loss: 2.4561233520507812
Validation loss: 2.3348448225246963

Epoch: 6| Step: 9
Training loss: 2.608259439468384
Validation loss: 2.335424360408578

Epoch: 6| Step: 10
Training loss: 1.991297721862793
Validation loss: 2.333331608003186

Epoch: 6| Step: 11
Training loss: 2.4002959728240967
Validation loss: 2.3433132709995395

Epoch: 6| Step: 12
Training loss: 2.7656943798065186
Validation loss: 2.3484404369067122

Epoch: 6| Step: 13
Training loss: 2.7091264724731445
Validation loss: 2.3495959492139917

Epoch: 58| Step: 0
Training loss: 2.222794532775879
Validation loss: 2.352872130691364

Epoch: 6| Step: 1
Training loss: 2.8120741844177246
Validation loss: 2.3410440132182133

Epoch: 6| Step: 2
Training loss: 2.186288833618164
Validation loss: 2.3408102348286617

Epoch: 6| Step: 3
Training loss: 2.6773056983947754
Validation loss: 2.336957812309265

Epoch: 6| Step: 4
Training loss: 3.2389988899230957
Validation loss: 2.3374833817123086

Epoch: 6| Step: 5
Training loss: 1.9469184875488281
Validation loss: 2.3370636663129254

Epoch: 6| Step: 6
Training loss: 2.8516385555267334
Validation loss: 2.337853358637902

Epoch: 6| Step: 7
Training loss: 2.700359344482422
Validation loss: 2.3372946477705434

Epoch: 6| Step: 8
Training loss: 2.590951442718506
Validation loss: 2.3363306932551886

Epoch: 6| Step: 9
Training loss: 2.6186554431915283
Validation loss: 2.3350510366501345

Epoch: 6| Step: 10
Training loss: 2.1196858882904053
Validation loss: 2.336710742724839

Epoch: 6| Step: 11
Training loss: 3.350710868835449
Validation loss: 2.33873595986315

Epoch: 6| Step: 12
Training loss: 2.55464506149292
Validation loss: 2.3437917822150776

Epoch: 6| Step: 13
Training loss: 2.526120662689209
Validation loss: 2.3430014528254026

Epoch: 59| Step: 0
Training loss: 1.7794156074523926
Validation loss: 2.3507277965545654

Epoch: 6| Step: 1
Training loss: 2.904139757156372
Validation loss: 2.3512860562211726

Epoch: 6| Step: 2
Training loss: 2.7098124027252197
Validation loss: 2.3696704833738265

Epoch: 6| Step: 3
Training loss: 2.6272807121276855
Validation loss: 2.3846543117236068

Epoch: 6| Step: 4
Training loss: 2.1817312240600586
Validation loss: 2.391891333364671

Epoch: 6| Step: 5
Training loss: 2.371917724609375
Validation loss: 2.4072607204478276

Epoch: 6| Step: 6
Training loss: 2.3837690353393555
Validation loss: 2.404495264894219

Epoch: 6| Step: 7
Training loss: 2.953899383544922
Validation loss: 2.396589171501898

Epoch: 6| Step: 8
Training loss: 3.200347661972046
Validation loss: 2.381081868243474

Epoch: 6| Step: 9
Training loss: 2.996098518371582
Validation loss: 2.3654765211125857

Epoch: 6| Step: 10
Training loss: 2.83445143699646
Validation loss: 2.3566822672402985

Epoch: 6| Step: 11
Training loss: 2.902820348739624
Validation loss: 2.3459504381302865

Epoch: 6| Step: 12
Training loss: 2.620821475982666
Validation loss: 2.3444198434070875

Epoch: 6| Step: 13
Training loss: 1.7313988208770752
Validation loss: 2.3319119971285582

Epoch: 60| Step: 0
Training loss: 1.708617925643921
Validation loss: 2.3305275209488405

Epoch: 6| Step: 1
Training loss: 2.7426247596740723
Validation loss: 2.329791961177703

Epoch: 6| Step: 2
Training loss: 2.607269525527954
Validation loss: 2.3285442552258893

Epoch: 6| Step: 3
Training loss: 3.024782657623291
Validation loss: 2.329636699409895

Epoch: 6| Step: 4
Training loss: 2.926013231277466
Validation loss: 2.3276023095653904

Epoch: 6| Step: 5
Training loss: 2.813107967376709
Validation loss: 2.3291930255069526

Epoch: 6| Step: 6
Training loss: 2.451338291168213
Validation loss: 2.3266677933354534

Epoch: 6| Step: 7
Training loss: 1.940700888633728
Validation loss: 2.3306407313193045

Epoch: 6| Step: 8
Training loss: 2.86985445022583
Validation loss: 2.3354341342885006

Epoch: 6| Step: 9
Training loss: 3.0706887245178223
Validation loss: 2.342621816101895

Epoch: 6| Step: 10
Training loss: 2.8351173400878906
Validation loss: 2.3398258122064735

Epoch: 6| Step: 11
Training loss: 2.441409111022949
Validation loss: 2.3455453995735414

Epoch: 6| Step: 12
Training loss: 2.307465076446533
Validation loss: 2.348731799792218

Epoch: 6| Step: 13
Training loss: 2.831909418106079
Validation loss: 2.3424656262961765

Epoch: 61| Step: 0
Training loss: 2.6445119380950928
Validation loss: 2.340483800057442

Epoch: 6| Step: 1
Training loss: 2.7202863693237305
Validation loss: 2.3341466303794616

Epoch: 6| Step: 2
Training loss: 2.9670069217681885
Validation loss: 2.328815867823939

Epoch: 6| Step: 3
Training loss: 2.967960834503174
Validation loss: 2.32386920016299

Epoch: 6| Step: 4
Training loss: 2.1196680068969727
Validation loss: 2.323394170371435

Epoch: 6| Step: 5
Training loss: 2.6842336654663086
Validation loss: 2.321468908299682

Epoch: 6| Step: 6
Training loss: 2.5481042861938477
Validation loss: 2.3258121167459795

Epoch: 6| Step: 7
Training loss: 2.175886631011963
Validation loss: 2.3256352768149426

Epoch: 6| Step: 8
Training loss: 2.8248119354248047
Validation loss: 2.3248015360165666

Epoch: 6| Step: 9
Training loss: 2.463839292526245
Validation loss: 2.3325671201111167

Epoch: 6| Step: 10
Training loss: 2.9349851608276367
Validation loss: 2.328937130589639

Epoch: 6| Step: 11
Training loss: 2.4159862995147705
Validation loss: 2.33841912592611

Epoch: 6| Step: 12
Training loss: 2.1362874507904053
Validation loss: 2.353561919222596

Epoch: 6| Step: 13
Training loss: 2.9915096759796143
Validation loss: 2.3819023075924126

Epoch: 62| Step: 0
Training loss: 1.5833930969238281
Validation loss: 2.414171544454431

Epoch: 6| Step: 1
Training loss: 2.5266366004943848
Validation loss: 2.436912072602139

Epoch: 6| Step: 2
Training loss: 2.359954357147217
Validation loss: 2.4792616931341027

Epoch: 6| Step: 3
Training loss: 2.9126386642456055
Validation loss: 2.4850602611418693

Epoch: 6| Step: 4
Training loss: 2.7319154739379883
Validation loss: 2.503855497606339

Epoch: 6| Step: 5
Training loss: 3.2830142974853516
Validation loss: 2.5060452748370428

Epoch: 6| Step: 6
Training loss: 3.1310408115386963
Validation loss: 2.5040152636907433

Epoch: 6| Step: 7
Training loss: 2.63061261177063
Validation loss: 2.4793767647076677

Epoch: 6| Step: 8
Training loss: 2.6883156299591064
Validation loss: 2.456832283286638

Epoch: 6| Step: 9
Training loss: 2.51338529586792
Validation loss: 2.4313558122163177

Epoch: 6| Step: 10
Training loss: 2.935525417327881
Validation loss: 2.4001502170357654

Epoch: 6| Step: 11
Training loss: 3.7029223442077637
Validation loss: 2.3860926397385134

Epoch: 6| Step: 12
Training loss: 1.9092426300048828
Validation loss: 2.379994059121737

Epoch: 6| Step: 13
Training loss: 2.358337163925171
Validation loss: 2.3784130901418705

Epoch: 63| Step: 0
Training loss: 2.0134215354919434
Validation loss: 2.3779599410231396

Epoch: 6| Step: 1
Training loss: 2.5011916160583496
Validation loss: 2.3849464206285376

Epoch: 6| Step: 2
Training loss: 3.532366991043091
Validation loss: 2.386603331053129

Epoch: 6| Step: 3
Training loss: 2.475411891937256
Validation loss: 2.3917290036396315

Epoch: 6| Step: 4
Training loss: 2.6604292392730713
Validation loss: 2.390829219613024

Epoch: 6| Step: 5
Training loss: 2.2899506092071533
Validation loss: 2.3883249157218525

Epoch: 6| Step: 6
Training loss: 3.249234676361084
Validation loss: 2.3803168830051216

Epoch: 6| Step: 7
Training loss: 2.916701316833496
Validation loss: 2.379060540148007

Epoch: 6| Step: 8
Training loss: 2.4025795459747314
Validation loss: 2.373906215031942

Epoch: 6| Step: 9
Training loss: 2.755694627761841
Validation loss: 2.3753135973407375

Epoch: 6| Step: 10
Training loss: 2.7948131561279297
Validation loss: 2.372027640701622

Epoch: 6| Step: 11
Training loss: 2.5984277725219727
Validation loss: 2.3755920548592844

Epoch: 6| Step: 12
Training loss: 2.5120456218719482
Validation loss: 2.380703100594141

Epoch: 6| Step: 13
Training loss: 2.1514406204223633
Validation loss: 2.3827939161690335

Epoch: 64| Step: 0
Training loss: 2.4922757148742676
Validation loss: 2.3861362447020826

Epoch: 6| Step: 1
Training loss: 2.9466729164123535
Validation loss: 2.391077503081291

Epoch: 6| Step: 2
Training loss: 2.272336483001709
Validation loss: 2.3932228396015782

Epoch: 6| Step: 3
Training loss: 2.566997766494751
Validation loss: 2.3885913689931235

Epoch: 6| Step: 4
Training loss: 2.7162537574768066
Validation loss: 2.394505290574925

Epoch: 6| Step: 5
Training loss: 3.275209426879883
Validation loss: 2.403393635185816

Epoch: 6| Step: 6
Training loss: 2.6878316402435303
Validation loss: 2.3993764103099866

Epoch: 6| Step: 7
Training loss: 2.7168211936950684
Validation loss: 2.40541414547992

Epoch: 6| Step: 8
Training loss: 2.1162545680999756
Validation loss: 2.3999178153212353

Epoch: 6| Step: 9
Training loss: 2.0549423694610596
Validation loss: 2.3992989242717786

Epoch: 6| Step: 10
Training loss: 2.9587960243225098
Validation loss: 2.396788289470057

Epoch: 6| Step: 11
Training loss: 2.5414814949035645
Validation loss: 2.3911832660757084

Epoch: 6| Step: 12
Training loss: 2.811708927154541
Validation loss: 2.3912425220653577

Epoch: 6| Step: 13
Training loss: 2.329392910003662
Validation loss: 2.381772502776115

Epoch: 65| Step: 0
Training loss: 2.70249080657959
Validation loss: 2.366805571381764

Epoch: 6| Step: 1
Training loss: 2.008465528488159
Validation loss: 2.362068436479056

Epoch: 6| Step: 2
Training loss: 2.2581310272216797
Validation loss: 2.359698259702293

Epoch: 6| Step: 3
Training loss: 2.532615900039673
Validation loss: 2.358190995390697

Epoch: 6| Step: 4
Training loss: 2.772512912750244
Validation loss: 2.3621537954576555

Epoch: 6| Step: 5
Training loss: 3.9246420860290527
Validation loss: 2.354782324965282

Epoch: 6| Step: 6
Training loss: 2.8379340171813965
Validation loss: 2.3551409167628132

Epoch: 6| Step: 7
Training loss: 2.854280471801758
Validation loss: 2.358993381582281

Epoch: 6| Step: 8
Training loss: 2.1881470680236816
Validation loss: 2.3567446098532727

Epoch: 6| Step: 9
Training loss: 2.892355442047119
Validation loss: 2.356092632457774

Epoch: 6| Step: 10
Training loss: 2.2291269302368164
Validation loss: 2.358815485431302

Epoch: 6| Step: 11
Training loss: 2.7648983001708984
Validation loss: 2.361725740535285

Epoch: 6| Step: 12
Training loss: 2.761693000793457
Validation loss: 2.3607767679358043

Epoch: 6| Step: 13
Training loss: 1.5206825733184814
Validation loss: 2.3611059419570433

Epoch: 66| Step: 0
Training loss: 1.968249797821045
Validation loss: 2.3657088100269275

Epoch: 6| Step: 1
Training loss: 2.951733112335205
Validation loss: 2.3703119062608287

Epoch: 6| Step: 2
Training loss: 1.927091121673584
Validation loss: 2.3896156190544047

Epoch: 6| Step: 3
Training loss: 2.754243850708008
Validation loss: 2.391548123410953

Epoch: 6| Step: 4
Training loss: 3.3780007362365723
Validation loss: 2.403397411428472

Epoch: 6| Step: 5
Training loss: 2.1800947189331055
Validation loss: 2.3896981029100317

Epoch: 6| Step: 6
Training loss: 2.497619867324829
Validation loss: 2.3846660185885686

Epoch: 6| Step: 7
Training loss: 2.83669114112854
Validation loss: 2.383092854612617

Epoch: 6| Step: 8
Training loss: 2.6963512897491455
Validation loss: 2.36754350508413

Epoch: 6| Step: 9
Training loss: 2.483457565307617
Validation loss: 2.3667456437182683

Epoch: 6| Step: 10
Training loss: 2.852900981903076
Validation loss: 2.3631896780383204

Epoch: 6| Step: 11
Training loss: 3.1349778175354004
Validation loss: 2.364739333429644

Epoch: 6| Step: 12
Training loss: 2.7419867515563965
Validation loss: 2.360494908466134

Epoch: 6| Step: 13
Training loss: 1.84156334400177
Validation loss: 2.3666653607481267

Epoch: 67| Step: 0
Training loss: 2.6428334712982178
Validation loss: 2.3566259261100524

Epoch: 6| Step: 1
Training loss: 2.8888461589813232
Validation loss: 2.366601462005287

Epoch: 6| Step: 2
Training loss: 2.4818179607391357
Validation loss: 2.3605806391726256

Epoch: 6| Step: 3
Training loss: 2.1496739387512207
Validation loss: 2.3663399116967314

Epoch: 6| Step: 4
Training loss: 2.386383056640625
Validation loss: 2.377261318186278

Epoch: 6| Step: 5
Training loss: 2.4212474822998047
Validation loss: 2.388393396972328

Epoch: 6| Step: 6
Training loss: 2.7258853912353516
Validation loss: 2.397553354181269

Epoch: 6| Step: 7
Training loss: 3.196263313293457
Validation loss: 2.4003082270263345

Epoch: 6| Step: 8
Training loss: 2.8059868812561035
Validation loss: 2.389210277988065

Epoch: 6| Step: 9
Training loss: 2.723405599594116
Validation loss: 2.3764452729173886

Epoch: 6| Step: 10
Training loss: 2.862598419189453
Validation loss: 2.370099982907695

Epoch: 6| Step: 11
Training loss: 2.6908421516418457
Validation loss: 2.359707304226455

Epoch: 6| Step: 12
Training loss: 2.3990190029144287
Validation loss: 2.365779589581233

Epoch: 6| Step: 13
Training loss: 1.6602166891098022
Validation loss: 2.363083529215987

Epoch: 68| Step: 0
Training loss: 2.7183444499969482
Validation loss: 2.3678732738699964

Epoch: 6| Step: 1
Training loss: 2.184920310974121
Validation loss: 2.376358647500315

Epoch: 6| Step: 2
Training loss: 3.0072474479675293
Validation loss: 2.3929725590572564

Epoch: 6| Step: 3
Training loss: 3.0877737998962402
Validation loss: 2.3952399658900436

Epoch: 6| Step: 4
Training loss: 2.3886702060699463
Validation loss: 2.3908960742335164

Epoch: 6| Step: 5
Training loss: 2.567260265350342
Validation loss: 2.390847747043897

Epoch: 6| Step: 6
Training loss: 2.74180269241333
Validation loss: 2.3968296999572427

Epoch: 6| Step: 7
Training loss: 2.761683702468872
Validation loss: 2.4041884945284937

Epoch: 6| Step: 8
Training loss: 1.6553882360458374
Validation loss: 2.4125702611861692

Epoch: 6| Step: 9
Training loss: 2.512956142425537
Validation loss: 2.4291872491118727

Epoch: 6| Step: 10
Training loss: 3.0843920707702637
Validation loss: 2.4327537064911215

Epoch: 6| Step: 11
Training loss: 2.554961919784546
Validation loss: 2.4152544493316324

Epoch: 6| Step: 12
Training loss: 2.021575450897217
Validation loss: 2.4069956682061635

Epoch: 6| Step: 13
Training loss: 3.78425931930542
Validation loss: 2.3883785893840175

Epoch: 69| Step: 0
Training loss: 2.4156675338745117
Validation loss: 2.369282591727472

Epoch: 6| Step: 1
Training loss: 1.8625147342681885
Validation loss: 2.3660396606691423

Epoch: 6| Step: 2
Training loss: 2.6686418056488037
Validation loss: 2.364465311009397

Epoch: 6| Step: 3
Training loss: 2.8148438930511475
Validation loss: 2.3659351692404798

Epoch: 6| Step: 4
Training loss: 2.8768463134765625
Validation loss: 2.3669086886990454

Epoch: 6| Step: 5
Training loss: 2.956937789916992
Validation loss: 2.3595821344724266

Epoch: 6| Step: 6
Training loss: 3.3689146041870117
Validation loss: 2.3505267520104685

Epoch: 6| Step: 7
Training loss: 2.537862777709961
Validation loss: 2.347110540636124

Epoch: 6| Step: 8
Training loss: 2.2543911933898926
Validation loss: 2.3407578724686817

Epoch: 6| Step: 9
Training loss: 2.8052148818969727
Validation loss: 2.3367808403507357

Epoch: 6| Step: 10
Training loss: 2.8775746822357178
Validation loss: 2.3352529528320476

Epoch: 6| Step: 11
Training loss: 2.5019989013671875
Validation loss: 2.3352686487218386

Epoch: 6| Step: 12
Training loss: 2.414360284805298
Validation loss: 2.3379336864717546

Epoch: 6| Step: 13
Training loss: 1.84664785861969
Validation loss: 2.336704341314172

Epoch: 70| Step: 0
Training loss: 3.0875186920166016
Validation loss: 2.3360796410550355

Epoch: 6| Step: 1
Training loss: 2.657196283340454
Validation loss: 2.3346700411970898

Epoch: 6| Step: 2
Training loss: 3.0785131454467773
Validation loss: 2.3380178328483336

Epoch: 6| Step: 3
Training loss: 2.49221134185791
Validation loss: 2.3381699208290345

Epoch: 6| Step: 4
Training loss: 3.4468884468078613
Validation loss: 2.348714102980911

Epoch: 6| Step: 5
Training loss: 2.1641387939453125
Validation loss: 2.354785911498531

Epoch: 6| Step: 6
Training loss: 2.37343692779541
Validation loss: 2.358048430053137

Epoch: 6| Step: 7
Training loss: 2.9393560886383057
Validation loss: 2.3566495705676336

Epoch: 6| Step: 8
Training loss: 1.6450097560882568
Validation loss: 2.352748432467061

Epoch: 6| Step: 9
Training loss: 2.838045120239258
Validation loss: 2.3470543789607223

Epoch: 6| Step: 10
Training loss: 2.8040902614593506
Validation loss: 2.353052264900618

Epoch: 6| Step: 11
Training loss: 2.279183864593506
Validation loss: 2.349637036682457

Epoch: 6| Step: 12
Training loss: 2.14567232131958
Validation loss: 2.3463073789432483

Epoch: 6| Step: 13
Training loss: 2.5101592540740967
Validation loss: 2.3451989799417476

Epoch: 71| Step: 0
Training loss: 2.710758686065674
Validation loss: 2.3555613410088325

Epoch: 6| Step: 1
Training loss: 2.378182888031006
Validation loss: 2.367623855990748

Epoch: 6| Step: 2
Training loss: 2.1625118255615234
Validation loss: 2.369047259771696

Epoch: 6| Step: 3
Training loss: 3.086846351623535
Validation loss: 2.3650389691834808

Epoch: 6| Step: 4
Training loss: 3.2022643089294434
Validation loss: 2.373461356727026

Epoch: 6| Step: 5
Training loss: 2.4009809494018555
Validation loss: 2.379448257466798

Epoch: 6| Step: 6
Training loss: 2.446916103363037
Validation loss: 2.3632977726638957

Epoch: 6| Step: 7
Training loss: 1.895182728767395
Validation loss: 2.346800281155494

Epoch: 6| Step: 8
Training loss: 2.94351863861084
Validation loss: 2.3440704307248517

Epoch: 6| Step: 9
Training loss: 3.321117401123047
Validation loss: 2.3410690407599173

Epoch: 6| Step: 10
Training loss: 2.591616153717041
Validation loss: 2.3386659237646286

Epoch: 6| Step: 11
Training loss: 2.130934238433838
Validation loss: 2.339155435562134

Epoch: 6| Step: 12
Training loss: 2.4224419593811035
Validation loss: 2.336018516171363

Epoch: 6| Step: 13
Training loss: 2.799605131149292
Validation loss: 2.3337674294748614

Epoch: 72| Step: 0
Training loss: 2.713942766189575
Validation loss: 2.334307204010666

Epoch: 6| Step: 1
Training loss: 2.766878366470337
Validation loss: 2.3352223109173518

Epoch: 6| Step: 2
Training loss: 3.006925582885742
Validation loss: 2.3339414314557145

Epoch: 6| Step: 3
Training loss: 3.0625994205474854
Validation loss: 2.3346281692545903

Epoch: 6| Step: 4
Training loss: 1.9652469158172607
Validation loss: 2.3349264603789135

Epoch: 6| Step: 5
Training loss: 2.3041470050811768
Validation loss: 2.3425934955637944

Epoch: 6| Step: 6
Training loss: 2.1963064670562744
Validation loss: 2.3524762789408364

Epoch: 6| Step: 7
Training loss: 2.776655435562134
Validation loss: 2.3572934109677552

Epoch: 6| Step: 8
Training loss: 2.143928050994873
Validation loss: 2.371832443821815

Epoch: 6| Step: 9
Training loss: 2.166396141052246
Validation loss: 2.379816378316572

Epoch: 6| Step: 10
Training loss: 2.2168328762054443
Validation loss: 2.4044151306152344

Epoch: 6| Step: 11
Training loss: 3.48211407661438
Validation loss: 2.394536018371582

Epoch: 6| Step: 12
Training loss: 2.3541815280914307
Validation loss: 2.382304681244717

Epoch: 6| Step: 13
Training loss: 3.5435779094696045
Validation loss: 2.3639179865519204

Epoch: 73| Step: 0
Training loss: 3.319457530975342
Validation loss: 2.3696241968421528

Epoch: 6| Step: 1
Training loss: 2.908952236175537
Validation loss: 2.36418060077134

Epoch: 6| Step: 2
Training loss: 2.3523149490356445
Validation loss: 2.366508496704922

Epoch: 6| Step: 3
Training loss: 3.125194549560547
Validation loss: 2.3624387479597524

Epoch: 6| Step: 4
Training loss: 2.346536636352539
Validation loss: 2.3470803588949223

Epoch: 6| Step: 5
Training loss: 1.8294163942337036
Validation loss: 2.3175508335072506

Epoch: 6| Step: 6
Training loss: 1.839691162109375
Validation loss: 2.3043976137715

Epoch: 6| Step: 7
Training loss: 2.625903367996216
Validation loss: 2.3055918421796573

Epoch: 6| Step: 8
Training loss: 2.108025550842285
Validation loss: 2.3041015107144593

Epoch: 6| Step: 9
Training loss: 2.5321245193481445
Validation loss: 2.2969962858384654

Epoch: 6| Step: 10
Training loss: 2.802854299545288
Validation loss: 2.2953820895123225

Epoch: 6| Step: 11
Training loss: 3.1932573318481445
Validation loss: 2.296926236921741

Epoch: 6| Step: 12
Training loss: 2.9504222869873047
Validation loss: 2.294029225585281

Epoch: 6| Step: 13
Training loss: 1.9780319929122925
Validation loss: 2.2972117970066686

Epoch: 74| Step: 0
Training loss: 2.9085516929626465
Validation loss: 2.2946503213656846

Epoch: 6| Step: 1
Training loss: 2.276637077331543
Validation loss: 2.3010636042523127

Epoch: 6| Step: 2
Training loss: 2.2561259269714355
Validation loss: 2.3035620053609214

Epoch: 6| Step: 3
Training loss: 2.033886194229126
Validation loss: 2.303179141013853

Epoch: 6| Step: 4
Training loss: 2.503679037094116
Validation loss: 2.3016932933561263

Epoch: 6| Step: 5
Training loss: 3.0772204399108887
Validation loss: 2.308674935371645

Epoch: 6| Step: 6
Training loss: 2.6224446296691895
Validation loss: 2.312958002090454

Epoch: 6| Step: 7
Training loss: 3.108523368835449
Validation loss: 2.3184259014744915

Epoch: 6| Step: 8
Training loss: 2.975977897644043
Validation loss: 2.3218962864209245

Epoch: 6| Step: 9
Training loss: 2.365243673324585
Validation loss: 2.3206126613001667

Epoch: 6| Step: 10
Training loss: 2.1760544776916504
Validation loss: 2.3175794988550167

Epoch: 6| Step: 11
Training loss: 3.181619882583618
Validation loss: 2.3135671692509807

Epoch: 6| Step: 12
Training loss: 2.4476847648620605
Validation loss: 2.3133217160419752

Epoch: 6| Step: 13
Training loss: 1.6747205257415771
Validation loss: 2.297517353488553

Epoch: 75| Step: 0
Training loss: 2.7507805824279785
Validation loss: 2.2897859875873854

Epoch: 6| Step: 1
Training loss: 3.1214635372161865
Validation loss: 2.284253945914648

Epoch: 6| Step: 2
Training loss: 2.5093817710876465
Validation loss: 2.2851692425307406

Epoch: 6| Step: 3
Training loss: 2.3858642578125
Validation loss: 2.285690229426148

Epoch: 6| Step: 4
Training loss: 2.6779873371124268
Validation loss: 2.2861019449849285

Epoch: 6| Step: 5
Training loss: 2.8226306438446045
Validation loss: 2.2894801016776793

Epoch: 6| Step: 6
Training loss: 2.4909698963165283
Validation loss: 2.292839591221143

Epoch: 6| Step: 7
Training loss: 2.7575995922088623
Validation loss: 2.2924550438439972

Epoch: 6| Step: 8
Training loss: 1.8984817266464233
Validation loss: 2.2904583561804985

Epoch: 6| Step: 9
Training loss: 2.3587496280670166
Validation loss: 2.286634786154634

Epoch: 6| Step: 10
Training loss: 3.14644718170166
Validation loss: 2.2807900726154284

Epoch: 6| Step: 11
Training loss: 2.298341989517212
Validation loss: 2.279270354137626

Epoch: 6| Step: 12
Training loss: 2.1626076698303223
Validation loss: 2.276034488472887

Epoch: 6| Step: 13
Training loss: 2.2988712787628174
Validation loss: 2.2731070133947555

Epoch: 76| Step: 0
Training loss: 2.614656448364258
Validation loss: 2.2715013514282885

Epoch: 6| Step: 1
Training loss: 1.894599199295044
Validation loss: 2.271048197182276

Epoch: 6| Step: 2
Training loss: 2.566323757171631
Validation loss: 2.2760769321072485

Epoch: 6| Step: 3
Training loss: 2.096165895462036
Validation loss: 2.276316576106574

Epoch: 6| Step: 4
Training loss: 1.557636022567749
Validation loss: 2.2859796606084353

Epoch: 6| Step: 5
Training loss: 3.121009349822998
Validation loss: 2.295327317330145

Epoch: 6| Step: 6
Training loss: 3.226426839828491
Validation loss: 2.3030812330143426

Epoch: 6| Step: 7
Training loss: 2.8137049674987793
Validation loss: 2.3077938325943483

Epoch: 6| Step: 8
Training loss: 2.7005128860473633
Validation loss: 2.3058507391201553

Epoch: 6| Step: 9
Training loss: 2.414281129837036
Validation loss: 2.3048343504628828

Epoch: 6| Step: 10
Training loss: 2.825500965118408
Validation loss: 2.3022521541964625

Epoch: 6| Step: 11
Training loss: 2.9721109867095947
Validation loss: 2.296460897691788

Epoch: 6| Step: 12
Training loss: 2.791987419128418
Validation loss: 2.285214424133301

Epoch: 6| Step: 13
Training loss: 1.8716710805892944
Validation loss: 2.270756167750205

Epoch: 77| Step: 0
Training loss: 2.1367311477661133
Validation loss: 2.2665364716642644

Epoch: 6| Step: 1
Training loss: 2.524451494216919
Validation loss: 2.2635981754590104

Epoch: 6| Step: 2
Training loss: 2.8498497009277344
Validation loss: 2.267564909432524

Epoch: 6| Step: 3
Training loss: 2.100613594055176
Validation loss: 2.264502335620183

Epoch: 6| Step: 4
Training loss: 2.158759117126465
Validation loss: 2.262388470352337

Epoch: 6| Step: 5
Training loss: 2.764453411102295
Validation loss: 2.2596344409450406

Epoch: 6| Step: 6
Training loss: 1.9116390943527222
Validation loss: 2.2598943171962613

Epoch: 6| Step: 7
Training loss: 2.5571184158325195
Validation loss: 2.2623704197586223

Epoch: 6| Step: 8
Training loss: 2.79632306098938
Validation loss: 2.2604730590697257

Epoch: 6| Step: 9
Training loss: 2.3813247680664062
Validation loss: 2.262694651080716

Epoch: 6| Step: 10
Training loss: 2.666548728942871
Validation loss: 2.2677467382082375

Epoch: 6| Step: 11
Training loss: 3.237821578979492
Validation loss: 2.2704764463568248

Epoch: 6| Step: 12
Training loss: 2.7651920318603516
Validation loss: 2.2705364893841486

Epoch: 6| Step: 13
Training loss: 3.463263988494873
Validation loss: 2.276833031767158

Epoch: 78| Step: 0
Training loss: 2.760094165802002
Validation loss: 2.2896321665856147

Epoch: 6| Step: 1
Training loss: 2.7952136993408203
Validation loss: 2.2888749517420286

Epoch: 6| Step: 2
Training loss: 2.309936046600342
Validation loss: 2.296030180428618

Epoch: 6| Step: 3
Training loss: 2.5604171752929688
Validation loss: 2.296252134025738

Epoch: 6| Step: 4
Training loss: 2.8610987663269043
Validation loss: 2.311245915710285

Epoch: 6| Step: 5
Training loss: 1.5834753513336182
Validation loss: 2.314114457817488

Epoch: 6| Step: 6
Training loss: 2.9370484352111816
Validation loss: 2.324348326652281

Epoch: 6| Step: 7
Training loss: 2.494856119155884
Validation loss: 2.3306998360541558

Epoch: 6| Step: 8
Training loss: 2.6599433422088623
Validation loss: 2.3325377279712307

Epoch: 6| Step: 9
Training loss: 2.069312810897827
Validation loss: 2.331738966767506

Epoch: 6| Step: 10
Training loss: 2.427121162414551
Validation loss: 2.3314466348258396

Epoch: 6| Step: 11
Training loss: 2.6598896980285645
Validation loss: 2.3196887021423667

Epoch: 6| Step: 12
Training loss: 3.114004373550415
Validation loss: 2.307930851495394

Epoch: 6| Step: 13
Training loss: 2.6079049110412598
Validation loss: 2.2973390471550728

Epoch: 79| Step: 0
Training loss: 2.9331247806549072
Validation loss: 2.2980458249327955

Epoch: 6| Step: 1
Training loss: 2.721799612045288
Validation loss: 2.305781154222386

Epoch: 6| Step: 2
Training loss: 2.4882290363311768
Validation loss: 2.303504164500903

Epoch: 6| Step: 3
Training loss: 2.850524425506592
Validation loss: 2.3033248352748092

Epoch: 6| Step: 4
Training loss: 2.324108123779297
Validation loss: 2.311052781279369

Epoch: 6| Step: 5
Training loss: 2.272257089614868
Validation loss: 2.3245457961995113

Epoch: 6| Step: 6
Training loss: 2.9492380619049072
Validation loss: 2.323498854073145

Epoch: 6| Step: 7
Training loss: 2.3741374015808105
Validation loss: 2.3085115942903744

Epoch: 6| Step: 8
Training loss: 2.7319042682647705
Validation loss: 2.2894940965919086

Epoch: 6| Step: 9
Training loss: 1.593500018119812
Validation loss: 2.2891561164650867

Epoch: 6| Step: 10
Training loss: 2.3967177867889404
Validation loss: 2.28983627083481

Epoch: 6| Step: 11
Training loss: 2.8987040519714355
Validation loss: 2.2881274402782483

Epoch: 6| Step: 12
Training loss: 3.031083106994629
Validation loss: 2.287019439922866

Epoch: 6| Step: 13
Training loss: 2.246244430541992
Validation loss: 2.2923920000753095

Epoch: 80| Step: 0
Training loss: 2.676548957824707
Validation loss: 2.2984414036555956

Epoch: 6| Step: 1
Training loss: 2.684779167175293
Validation loss: 2.306345139780352

Epoch: 6| Step: 2
Training loss: 2.0090906620025635
Validation loss: 2.3277744580340642

Epoch: 6| Step: 3
Training loss: 2.4385159015655518
Validation loss: 2.3398326827633764

Epoch: 6| Step: 4
Training loss: 2.1977012157440186
Validation loss: 2.355715831120809

Epoch: 6| Step: 5
Training loss: 2.551680326461792
Validation loss: 2.3728103073694373

Epoch: 6| Step: 6
Training loss: 3.0161423683166504
Validation loss: 2.3769565243874826

Epoch: 6| Step: 7
Training loss: 2.8041882514953613
Validation loss: 2.376689080269106

Epoch: 6| Step: 8
Training loss: 3.2433652877807617
Validation loss: 2.3854697827369935

Epoch: 6| Step: 9
Training loss: 2.502157211303711
Validation loss: 2.3683254616234892

Epoch: 6| Step: 10
Training loss: 2.1573381423950195
Validation loss: 2.3504353492490706

Epoch: 6| Step: 11
Training loss: 2.3725876808166504
Validation loss: 2.3499855277358845

Epoch: 6| Step: 12
Training loss: 2.9007606506347656
Validation loss: 2.3423210292734127

Epoch: 6| Step: 13
Training loss: 2.285276174545288
Validation loss: 2.342222875164401

Epoch: 81| Step: 0
Training loss: 2.2224173545837402
Validation loss: 2.317550825816329

Epoch: 6| Step: 1
Training loss: 2.616028308868408
Validation loss: 2.3019003791193806

Epoch: 6| Step: 2
Training loss: 2.2569971084594727
Validation loss: 2.294983140883907

Epoch: 6| Step: 3
Training loss: 2.876451253890991
Validation loss: 2.2962926715932865

Epoch: 6| Step: 4
Training loss: 3.0717883110046387
Validation loss: 2.3006898049385316

Epoch: 6| Step: 5
Training loss: 3.0536489486694336
Validation loss: 2.299291241553522

Epoch: 6| Step: 6
Training loss: 1.8949110507965088
Validation loss: 2.314040850567561

Epoch: 6| Step: 7
Training loss: 3.004268169403076
Validation loss: 2.3202983615218953

Epoch: 6| Step: 8
Training loss: 2.6749820709228516
Validation loss: 2.3267986261716453

Epoch: 6| Step: 9
Training loss: 2.2932968139648438
Validation loss: 2.3357204006564234

Epoch: 6| Step: 10
Training loss: 2.5913612842559814
Validation loss: 2.3394979225691928

Epoch: 6| Step: 11
Training loss: 2.301896572113037
Validation loss: 2.3410141173229424

Epoch: 6| Step: 12
Training loss: 2.4871230125427246
Validation loss: 2.3324945588265695

Epoch: 6| Step: 13
Training loss: 2.5692138671875
Validation loss: 2.3312459068913616

Epoch: 82| Step: 0
Training loss: 2.295225143432617
Validation loss: 2.333415521088467

Epoch: 6| Step: 1
Training loss: 2.0846505165100098
Validation loss: 2.330825895391485

Epoch: 6| Step: 2
Training loss: 2.8588244915008545
Validation loss: 2.319813379677393

Epoch: 6| Step: 3
Training loss: 2.29754900932312
Validation loss: 2.312378539833971

Epoch: 6| Step: 4
Training loss: 3.0092992782592773
Validation loss: 2.2986559457676385

Epoch: 6| Step: 5
Training loss: 2.7008719444274902
Validation loss: 2.295916662421278

Epoch: 6| Step: 6
Training loss: 3.061183452606201
Validation loss: 2.291425153773318

Epoch: 6| Step: 7
Training loss: 2.0464391708374023
Validation loss: 2.287515542840445

Epoch: 6| Step: 8
Training loss: 2.7559096813201904
Validation loss: 2.292856949631886

Epoch: 6| Step: 9
Training loss: 2.2757441997528076
Validation loss: 2.282979296099755

Epoch: 6| Step: 10
Training loss: 2.4572277069091797
Validation loss: 2.283809082482451

Epoch: 6| Step: 11
Training loss: 1.9969778060913086
Validation loss: 2.2789124801594722

Epoch: 6| Step: 12
Training loss: 2.7162532806396484
Validation loss: 2.2820837318256335

Epoch: 6| Step: 13
Training loss: 3.5120270252227783
Validation loss: 2.285222481655818

Epoch: 83| Step: 0
Training loss: 1.8515609502792358
Validation loss: 2.276266800459995

Epoch: 6| Step: 1
Training loss: 1.8442391157150269
Validation loss: 2.276477413792764

Epoch: 6| Step: 2
Training loss: 2.1752769947052
Validation loss: 2.2734766185924573

Epoch: 6| Step: 3
Training loss: 2.3122177124023438
Validation loss: 2.2684847590743855

Epoch: 6| Step: 4
Training loss: 3.2217049598693848
Validation loss: 2.2792478505001275

Epoch: 6| Step: 5
Training loss: 2.283099412918091
Validation loss: 2.2739693093043503

Epoch: 6| Step: 6
Training loss: 2.854825735092163
Validation loss: 2.295854458244898

Epoch: 6| Step: 7
Training loss: 2.57423996925354
Validation loss: 2.2994825301631803

Epoch: 6| Step: 8
Training loss: 2.5438661575317383
Validation loss: 2.3270071232190697

Epoch: 6| Step: 9
Training loss: 2.4355008602142334
Validation loss: 2.3509218308233444

Epoch: 6| Step: 10
Training loss: 3.2401082515716553
Validation loss: 2.381124193950366

Epoch: 6| Step: 11
Training loss: 3.3647377490997314
Validation loss: 2.3776635995475193

Epoch: 6| Step: 12
Training loss: 2.3056507110595703
Validation loss: 2.3699511763870076

Epoch: 6| Step: 13
Training loss: 2.9491090774536133
Validation loss: 2.3463327987219698

Epoch: 84| Step: 0
Training loss: 1.8855199813842773
Validation loss: 2.324835267118228

Epoch: 6| Step: 1
Training loss: 2.1806795597076416
Validation loss: 2.293183188284597

Epoch: 6| Step: 2
Training loss: 2.489358901977539
Validation loss: 2.277667699321624

Epoch: 6| Step: 3
Training loss: 2.4322669506073
Validation loss: 2.2732659052777033

Epoch: 6| Step: 4
Training loss: 2.6233248710632324
Validation loss: 2.2662007065229517

Epoch: 6| Step: 5
Training loss: 3.0797922611236572
Validation loss: 2.257164414210986

Epoch: 6| Step: 6
Training loss: 2.912761926651001
Validation loss: 2.25612207381956

Epoch: 6| Step: 7
Training loss: 2.182813882827759
Validation loss: 2.25192367774184

Epoch: 6| Step: 8
Training loss: 2.4737353324890137
Validation loss: 2.2547209211575088

Epoch: 6| Step: 9
Training loss: 2.9213104248046875
Validation loss: 2.249085977513303

Epoch: 6| Step: 10
Training loss: 2.4874939918518066
Validation loss: 2.2539562179196264

Epoch: 6| Step: 11
Training loss: 3.0123887062072754
Validation loss: 2.2504147009183

Epoch: 6| Step: 12
Training loss: 2.315495014190674
Validation loss: 2.248151160055591

Epoch: 6| Step: 13
Training loss: 2.9420204162597656
Validation loss: 2.239909803995522

Epoch: 85| Step: 0
Training loss: 1.9895964860916138
Validation loss: 2.237808694121658

Epoch: 6| Step: 1
Training loss: 2.9288718700408936
Validation loss: 2.242712423365603

Epoch: 6| Step: 2
Training loss: 2.7241933345794678
Validation loss: 2.2446282832853255

Epoch: 6| Step: 3
Training loss: 2.681342601776123
Validation loss: 2.2481598674610095

Epoch: 6| Step: 4
Training loss: 2.071200132369995
Validation loss: 2.2586813280659337

Epoch: 6| Step: 5
Training loss: 2.4824719429016113
Validation loss: 2.2614642599577546

Epoch: 6| Step: 6
Training loss: 2.4416046142578125
Validation loss: 2.2671430751841557

Epoch: 6| Step: 7
Training loss: 2.9335927963256836
Validation loss: 2.2639435311799407

Epoch: 6| Step: 8
Training loss: 2.600980281829834
Validation loss: 2.256396706386279

Epoch: 6| Step: 9
Training loss: 2.1372814178466797
Validation loss: 2.259167969867747

Epoch: 6| Step: 10
Training loss: 2.306863307952881
Validation loss: 2.25771084139424

Epoch: 6| Step: 11
Training loss: 2.6169545650482178
Validation loss: 2.274331864490304

Epoch: 6| Step: 12
Training loss: 2.8982419967651367
Validation loss: 2.285926318937732

Epoch: 6| Step: 13
Training loss: 2.627063274383545
Validation loss: 2.302537064398489

Epoch: 86| Step: 0
Training loss: 2.738121271133423
Validation loss: 2.3118568158918813

Epoch: 6| Step: 1
Training loss: 2.9550304412841797
Validation loss: 2.32830548286438

Epoch: 6| Step: 2
Training loss: 1.9743516445159912
Validation loss: 2.3372289057700866

Epoch: 6| Step: 3
Training loss: 2.3674476146698
Validation loss: 2.3372393244056293

Epoch: 6| Step: 4
Training loss: 2.144132137298584
Validation loss: 2.337378345510011

Epoch: 6| Step: 5
Training loss: 3.091196060180664
Validation loss: 2.329269109233733

Epoch: 6| Step: 6
Training loss: 1.9870939254760742
Validation loss: 2.2671067689054754

Epoch: 6| Step: 7
Training loss: 3.04575777053833
Validation loss: 2.2457925337617115

Epoch: 6| Step: 8
Training loss: 2.031970262527466
Validation loss: 2.231409198494368

Epoch: 6| Step: 9
Training loss: 2.884493112564087
Validation loss: 2.2238243241463937

Epoch: 6| Step: 10
Training loss: 1.8564181327819824
Validation loss: 2.2300736493961786

Epoch: 6| Step: 11
Training loss: 2.727684497833252
Validation loss: 2.23125708487726

Epoch: 6| Step: 12
Training loss: 3.12131404876709
Validation loss: 2.2342707059716664

Epoch: 6| Step: 13
Training loss: 2.8999109268188477
Validation loss: 2.231625497982066

Epoch: 87| Step: 0
Training loss: 3.40315580368042
Validation loss: 2.230799994161052

Epoch: 6| Step: 1
Training loss: 2.424802541732788
Validation loss: 2.222998836989044

Epoch: 6| Step: 2
Training loss: 2.1779351234436035
Validation loss: 2.2275055544350737

Epoch: 6| Step: 3
Training loss: 1.5203070640563965
Validation loss: 2.221941324972337

Epoch: 6| Step: 4
Training loss: 2.9849486351013184
Validation loss: 2.2186706912133003

Epoch: 6| Step: 5
Training loss: 2.588839530944824
Validation loss: 2.2253283710889917

Epoch: 6| Step: 6
Training loss: 3.247439384460449
Validation loss: 2.226167437850788

Epoch: 6| Step: 7
Training loss: 2.423652410507202
Validation loss: 2.229343601452407

Epoch: 6| Step: 8
Training loss: 2.5021438598632812
Validation loss: 2.2335580907842165

Epoch: 6| Step: 9
Training loss: 3.031914472579956
Validation loss: 2.239894328578826

Epoch: 6| Step: 10
Training loss: 2.0824317932128906
Validation loss: 2.240616916328348

Epoch: 6| Step: 11
Training loss: 2.8277227878570557
Validation loss: 2.2451668195827033

Epoch: 6| Step: 12
Training loss: 1.531503677368164
Validation loss: 2.25788362051851

Epoch: 6| Step: 13
Training loss: 2.611128568649292
Validation loss: 2.2678271211603636

Epoch: 88| Step: 0
Training loss: 2.337052345275879
Validation loss: 2.275348860730407

Epoch: 6| Step: 1
Training loss: 2.5852296352386475
Validation loss: 2.2820298517903974

Epoch: 6| Step: 2
Training loss: 2.7194089889526367
Validation loss: 2.286760858310166

Epoch: 6| Step: 3
Training loss: 2.4726436138153076
Validation loss: 2.3123487580207085

Epoch: 6| Step: 4
Training loss: 2.1641111373901367
Validation loss: 2.302075719320646

Epoch: 6| Step: 5
Training loss: 2.638608455657959
Validation loss: 2.2888833899651804

Epoch: 6| Step: 6
Training loss: 2.647274971008301
Validation loss: 2.2852860394344536

Epoch: 6| Step: 7
Training loss: 2.8012380599975586
Validation loss: 2.268252347105293

Epoch: 6| Step: 8
Training loss: 2.8337912559509277
Validation loss: 2.257583866837204

Epoch: 6| Step: 9
Training loss: 2.1048271656036377
Validation loss: 2.240046190959151

Epoch: 6| Step: 10
Training loss: 2.332418441772461
Validation loss: 2.2315172662017164

Epoch: 6| Step: 11
Training loss: 2.5495834350585938
Validation loss: 2.222807912416356

Epoch: 6| Step: 12
Training loss: 3.141688823699951
Validation loss: 2.2164093166269283

Epoch: 6| Step: 13
Training loss: 1.7394044399261475
Validation loss: 2.216164081327377

Epoch: 89| Step: 0
Training loss: 2.821143627166748
Validation loss: 2.2162041228304625

Epoch: 6| Step: 1
Training loss: 3.0640885829925537
Validation loss: 2.2147980505420315

Epoch: 6| Step: 2
Training loss: 2.6887571811676025
Validation loss: 2.2174129127174296

Epoch: 6| Step: 3
Training loss: 2.358325481414795
Validation loss: 2.2189392479517127

Epoch: 6| Step: 4
Training loss: 2.0564992427825928
Validation loss: 2.214189680673743

Epoch: 6| Step: 5
Training loss: 2.7117953300476074
Validation loss: 2.2218806256530104

Epoch: 6| Step: 6
Training loss: 2.5398974418640137
Validation loss: 2.236646193330006

Epoch: 6| Step: 7
Training loss: 2.628234624862671
Validation loss: 2.248689050315529

Epoch: 6| Step: 8
Training loss: 2.875396251678467
Validation loss: 2.2668017456608434

Epoch: 6| Step: 9
Training loss: 1.9559473991394043
Validation loss: 2.26699262280618

Epoch: 6| Step: 10
Training loss: 2.717057228088379
Validation loss: 2.2760797392937446

Epoch: 6| Step: 11
Training loss: 2.192408561706543
Validation loss: 2.2733951089202717

Epoch: 6| Step: 12
Training loss: 2.473757028579712
Validation loss: 2.291309674580892

Epoch: 6| Step: 13
Training loss: 2.410527229309082
Validation loss: 2.2867677327125304

Epoch: 90| Step: 0
Training loss: 3.664482593536377
Validation loss: 2.2740164367101525

Epoch: 6| Step: 1
Training loss: 2.218608856201172
Validation loss: 2.2530386012087584

Epoch: 6| Step: 2
Training loss: 2.0807082653045654
Validation loss: 2.2511930927153556

Epoch: 6| Step: 3
Training loss: 2.727971315383911
Validation loss: 2.2427358652955744

Epoch: 6| Step: 4
Training loss: 2.586595296859741
Validation loss: 2.2372853473950456

Epoch: 6| Step: 5
Training loss: 2.2164440155029297
Validation loss: 2.2450156519489903

Epoch: 6| Step: 6
Training loss: 2.3025145530700684
Validation loss: 2.2369309984227663

Epoch: 6| Step: 7
Training loss: 2.3015151023864746
Validation loss: 2.23204775779478

Epoch: 6| Step: 8
Training loss: 2.7617664337158203
Validation loss: 2.2381853019037554

Epoch: 6| Step: 9
Training loss: 2.2689599990844727
Validation loss: 2.240136645173514

Epoch: 6| Step: 10
Training loss: 2.745266914367676
Validation loss: 2.2420390370071575

Epoch: 6| Step: 11
Training loss: 3.168839931488037
Validation loss: 2.261922195393552

Epoch: 6| Step: 12
Training loss: 1.6361823081970215
Validation loss: 2.272344168796334

Epoch: 6| Step: 13
Training loss: 2.498135566711426
Validation loss: 2.2728961129342355

Epoch: 91| Step: 0
Training loss: 2.196446418762207
Validation loss: 2.284375839335944

Epoch: 6| Step: 1
Training loss: 2.3994624614715576
Validation loss: 2.2711216044682327

Epoch: 6| Step: 2
Training loss: 2.2841382026672363
Validation loss: 2.2798265385371383

Epoch: 6| Step: 3
Training loss: 2.989076614379883
Validation loss: 2.2652746169797835

Epoch: 6| Step: 4
Training loss: 1.784275770187378
Validation loss: 2.265356973935199

Epoch: 6| Step: 5
Training loss: 2.1848862171173096
Validation loss: 2.25580999928136

Epoch: 6| Step: 6
Training loss: 2.8076958656311035
Validation loss: 2.248764944332902

Epoch: 6| Step: 7
Training loss: 2.6197452545166016
Validation loss: 2.23990301675694

Epoch: 6| Step: 8
Training loss: 3.443044424057007
Validation loss: 2.233385242441649

Epoch: 6| Step: 9
Training loss: 2.071993350982666
Validation loss: 2.242709417496958

Epoch: 6| Step: 10
Training loss: 2.1183855533599854
Validation loss: 2.234360956376599

Epoch: 6| Step: 11
Training loss: 3.061617374420166
Validation loss: 2.2459607124328613

Epoch: 6| Step: 12
Training loss: 2.4073753356933594
Validation loss: 2.2414445723256757

Epoch: 6| Step: 13
Training loss: 2.802675485610962
Validation loss: 2.2283768833324475

Epoch: 92| Step: 0
Training loss: 2.0654215812683105
Validation loss: 2.228587564601693

Epoch: 6| Step: 1
Training loss: 2.182509660720825
Validation loss: 2.213891908686648

Epoch: 6| Step: 2
Training loss: 2.6768507957458496
Validation loss: 2.217799605861787

Epoch: 6| Step: 3
Training loss: 2.2790486812591553
Validation loss: 2.2221696812619447

Epoch: 6| Step: 4
Training loss: 2.402892589569092
Validation loss: 2.219377707409602

Epoch: 6| Step: 5
Training loss: 2.1022496223449707
Validation loss: 2.219391030649985

Epoch: 6| Step: 6
Training loss: 3.316145181655884
Validation loss: 2.2188187824782504

Epoch: 6| Step: 7
Training loss: 2.921414852142334
Validation loss: 2.2235197149297243

Epoch: 6| Step: 8
Training loss: 1.73814058303833
Validation loss: 2.2264824041756253

Epoch: 6| Step: 9
Training loss: 2.871196746826172
Validation loss: 2.223956992549281

Epoch: 6| Step: 10
Training loss: 2.4981470108032227
Validation loss: 2.2304244323443343

Epoch: 6| Step: 11
Training loss: 2.5877652168273926
Validation loss: 2.2350387932151876

Epoch: 6| Step: 12
Training loss: 2.5760912895202637
Validation loss: 2.2370416220798286

Epoch: 6| Step: 13
Training loss: 3.2685530185699463
Validation loss: 2.2436685075042067

Epoch: 93| Step: 0
Training loss: 3.06069278717041
Validation loss: 2.234260359118062

Epoch: 6| Step: 1
Training loss: 2.8694896697998047
Validation loss: 2.223000708446708

Epoch: 6| Step: 2
Training loss: 2.2900471687316895
Validation loss: 2.2270202944355626

Epoch: 6| Step: 3
Training loss: 2.699338912963867
Validation loss: 2.219441467715848

Epoch: 6| Step: 4
Training loss: 2.104168176651001
Validation loss: 2.2273934964210755

Epoch: 6| Step: 5
Training loss: 2.83794903755188
Validation loss: 2.2269058688994376

Epoch: 6| Step: 6
Training loss: 2.26558518409729
Validation loss: 2.222158747334634

Epoch: 6| Step: 7
Training loss: 1.8887299299240112
Validation loss: 2.2157388143641974

Epoch: 6| Step: 8
Training loss: 1.9448552131652832
Validation loss: 2.222692243514522

Epoch: 6| Step: 9
Training loss: 2.040175676345825
Validation loss: 2.2275379678254486

Epoch: 6| Step: 10
Training loss: 2.647829294204712
Validation loss: 2.235659145539807

Epoch: 6| Step: 11
Training loss: 2.7777605056762695
Validation loss: 2.23517757333735

Epoch: 6| Step: 12
Training loss: 3.0241761207580566
Validation loss: 2.2384315126685688

Epoch: 6| Step: 13
Training loss: 2.7216575145721436
Validation loss: 2.2370194465883317

Epoch: 94| Step: 0
Training loss: 2.275310516357422
Validation loss: 2.2455805809267106

Epoch: 6| Step: 1
Training loss: 2.8035621643066406
Validation loss: 2.2273526396802676

Epoch: 6| Step: 2
Training loss: 2.9604716300964355
Validation loss: 2.2177761472681516

Epoch: 6| Step: 3
Training loss: 2.3511271476745605
Validation loss: 2.217948600810061

Epoch: 6| Step: 4
Training loss: 2.7718610763549805
Validation loss: 2.219970546742921

Epoch: 6| Step: 5
Training loss: 2.162350654602051
Validation loss: 2.2277635707650134

Epoch: 6| Step: 6
Training loss: 2.4434571266174316
Validation loss: 2.2330145194966304

Epoch: 6| Step: 7
Training loss: 2.903524398803711
Validation loss: 2.2475874193253054

Epoch: 6| Step: 8
Training loss: 2.8957958221435547
Validation loss: 2.2518560194200083

Epoch: 6| Step: 9
Training loss: 1.5947864055633545
Validation loss: 2.2559120065422467

Epoch: 6| Step: 10
Training loss: 2.218841552734375
Validation loss: 2.260092217435119

Epoch: 6| Step: 11
Training loss: 2.425278663635254
Validation loss: 2.250239203053136

Epoch: 6| Step: 12
Training loss: 2.530910015106201
Validation loss: 2.2543040296082855

Epoch: 6| Step: 13
Training loss: 2.799713134765625
Validation loss: 2.236287591277912

Epoch: 95| Step: 0
Training loss: 2.458979845046997
Validation loss: 2.23044987135036

Epoch: 6| Step: 1
Training loss: 3.1179466247558594
Validation loss: 2.2265213330586753

Epoch: 6| Step: 2
Training loss: 2.9054903984069824
Validation loss: 2.223415961829565

Epoch: 6| Step: 3
Training loss: 2.6185970306396484
Validation loss: 2.214327196921072

Epoch: 6| Step: 4
Training loss: 2.2530627250671387
Validation loss: 2.213812085890001

Epoch: 6| Step: 5
Training loss: 2.5183215141296387
Validation loss: 2.2158610513133388

Epoch: 6| Step: 6
Training loss: 2.279758930206299
Validation loss: 2.2221358847874466

Epoch: 6| Step: 7
Training loss: 2.5565333366394043
Validation loss: 2.221189204082694

Epoch: 6| Step: 8
Training loss: 2.598069667816162
Validation loss: 2.2197997826401905

Epoch: 6| Step: 9
Training loss: 2.9342803955078125
Validation loss: 2.2233669257933095

Epoch: 6| Step: 10
Training loss: 1.6417107582092285
Validation loss: 2.2337894208969606

Epoch: 6| Step: 11
Training loss: 2.820361614227295
Validation loss: 2.246582108159219

Epoch: 6| Step: 12
Training loss: 1.9813083410263062
Validation loss: 2.2560819887345835

Epoch: 6| Step: 13
Training loss: 2.1382296085357666
Validation loss: 2.2708255270475983

Epoch: 96| Step: 0
Training loss: 2.9468564987182617
Validation loss: 2.25704950158314

Epoch: 6| Step: 1
Training loss: 2.146817922592163
Validation loss: 2.260032037253021

Epoch: 6| Step: 2
Training loss: 1.9969134330749512
Validation loss: 2.257139951952042

Epoch: 6| Step: 3
Training loss: 3.5691428184509277
Validation loss: 2.24714619241735

Epoch: 6| Step: 4
Training loss: 2.7154059410095215
Validation loss: 2.243677508446478

Epoch: 6| Step: 5
Training loss: 2.5051584243774414
Validation loss: 2.223959799735777

Epoch: 6| Step: 6
Training loss: 2.2918267250061035
Validation loss: 2.215007992200954

Epoch: 6| Step: 7
Training loss: 2.680405855178833
Validation loss: 2.209408147360689

Epoch: 6| Step: 8
Training loss: 2.642728567123413
Validation loss: 2.203513947866296

Epoch: 6| Step: 9
Training loss: 2.567317485809326
Validation loss: 2.2053643952133837

Epoch: 6| Step: 10
Training loss: 2.278359889984131
Validation loss: 2.209157755297999

Epoch: 6| Step: 11
Training loss: 2.1040234565734863
Validation loss: 2.2065993662803405

Epoch: 6| Step: 12
Training loss: 2.063793659210205
Validation loss: 2.21372401842507

Epoch: 6| Step: 13
Training loss: 2.5301315784454346
Validation loss: 2.2174841255270024

Epoch: 97| Step: 0
Training loss: 2.4217212200164795
Validation loss: 2.224567428711922

Epoch: 6| Step: 1
Training loss: 2.5936057567596436
Validation loss: 2.2304444184867283

Epoch: 6| Step: 2
Training loss: 2.0072247982025146
Validation loss: 2.231106068498345

Epoch: 6| Step: 3
Training loss: 2.9615068435668945
Validation loss: 2.241399759887367

Epoch: 6| Step: 4
Training loss: 2.4390029907226562
Validation loss: 2.2409158188809633

Epoch: 6| Step: 5
Training loss: 2.692110538482666
Validation loss: 2.236516365440943

Epoch: 6| Step: 6
Training loss: 1.8387383222579956
Validation loss: 2.2189657841959307

Epoch: 6| Step: 7
Training loss: 2.403871774673462
Validation loss: 2.207233618664485

Epoch: 6| Step: 8
Training loss: 2.9973864555358887
Validation loss: 2.1932376982063375

Epoch: 6| Step: 9
Training loss: 2.079840898513794
Validation loss: 2.196914326760077

Epoch: 6| Step: 10
Training loss: 2.65389347076416
Validation loss: 2.1993901678310928

Epoch: 6| Step: 11
Training loss: 2.516831398010254
Validation loss: 2.1945743714609454

Epoch: 6| Step: 12
Training loss: 2.895275354385376
Validation loss: 2.1959686638206564

Epoch: 6| Step: 13
Training loss: 2.4510228633880615
Validation loss: 2.201702335829376

Epoch: 98| Step: 0
Training loss: 2.322261333465576
Validation loss: 2.1945089601701304

Epoch: 6| Step: 1
Training loss: 2.000081777572632
Validation loss: 2.207329214260142

Epoch: 6| Step: 2
Training loss: 2.810394048690796
Validation loss: 2.2065184770091886

Epoch: 6| Step: 3
Training loss: 2.1211867332458496
Validation loss: 2.2075721371558403

Epoch: 6| Step: 4
Training loss: 2.8991270065307617
Validation loss: 2.213769899901523

Epoch: 6| Step: 5
Training loss: 2.447850227355957
Validation loss: 2.212342903178225

Epoch: 6| Step: 6
Training loss: 2.2343966960906982
Validation loss: 2.232585803154976

Epoch: 6| Step: 7
Training loss: 2.4867401123046875
Validation loss: 2.2306318436899493

Epoch: 6| Step: 8
Training loss: 2.476850748062134
Validation loss: 2.2240539622563187

Epoch: 6| Step: 9
Training loss: 2.966721534729004
Validation loss: 2.224297895226427

Epoch: 6| Step: 10
Training loss: 2.4019784927368164
Validation loss: 2.2328795079262025

Epoch: 6| Step: 11
Training loss: 2.937901020050049
Validation loss: 2.226605233325753

Epoch: 6| Step: 12
Training loss: 2.371257781982422
Validation loss: 2.227138368032312

Epoch: 6| Step: 13
Training loss: 2.360572338104248
Validation loss: 2.2128175663691696

Epoch: 99| Step: 0
Training loss: 2.6185262203216553
Validation loss: 2.196293374543549

Epoch: 6| Step: 1
Training loss: 1.7769508361816406
Validation loss: 2.2074886701440297

Epoch: 6| Step: 2
Training loss: 1.7747119665145874
Validation loss: 2.19602741349128

Epoch: 6| Step: 3
Training loss: 2.812129497528076
Validation loss: 2.204328662605696

Epoch: 6| Step: 4
Training loss: 2.68276309967041
Validation loss: 2.210591644369146

Epoch: 6| Step: 5
Training loss: 2.135831832885742
Validation loss: 2.2051006850375923

Epoch: 6| Step: 6
Training loss: 3.098301887512207
Validation loss: 2.2100579507889284

Epoch: 6| Step: 7
Training loss: 2.489804983139038
Validation loss: 2.2124619894130255

Epoch: 6| Step: 8
Training loss: 2.6921539306640625
Validation loss: 2.2254710017993884

Epoch: 6| Step: 9
Training loss: 3.0748074054718018
Validation loss: 2.235959832386304

Epoch: 6| Step: 10
Training loss: 1.8948893547058105
Validation loss: 2.2319940469598256

Epoch: 6| Step: 11
Training loss: 2.573575973510742
Validation loss: 2.2155541373837377

Epoch: 6| Step: 12
Training loss: 2.503737211227417
Validation loss: 2.2156723212170344

Epoch: 6| Step: 13
Training loss: 2.8459701538085938
Validation loss: 2.195816022093578

Epoch: 100| Step: 0
Training loss: 1.4013359546661377
Validation loss: 2.1869392036109843

Epoch: 6| Step: 1
Training loss: 3.1184496879577637
Validation loss: 2.1852305602001887

Epoch: 6| Step: 2
Training loss: 2.4617133140563965
Validation loss: 2.1747422154231737

Epoch: 6| Step: 3
Training loss: 2.436302661895752
Validation loss: 2.1834999002436155

Epoch: 6| Step: 4
Training loss: 2.254136085510254
Validation loss: 2.1796762558721725

Epoch: 6| Step: 5
Training loss: 3.003106117248535
Validation loss: 2.1793504248383226

Epoch: 6| Step: 6
Training loss: 3.126505136489868
Validation loss: 2.1770998970154793

Epoch: 6| Step: 7
Training loss: 2.427464723587036
Validation loss: 2.176117063850485

Epoch: 6| Step: 8
Training loss: 2.82011079788208
Validation loss: 2.1865499660532963

Epoch: 6| Step: 9
Training loss: 2.2726891040802
Validation loss: 2.1916155661306074

Epoch: 6| Step: 10
Training loss: 2.5833263397216797
Validation loss: 2.201045790026265

Epoch: 6| Step: 11
Training loss: 2.44385027885437
Validation loss: 2.207496109829154

Epoch: 6| Step: 12
Training loss: 2.288984775543213
Validation loss: 2.2176535142365323

Epoch: 6| Step: 13
Training loss: 2.1511526107788086
Validation loss: 2.243119047534081

Epoch: 101| Step: 0
Training loss: 1.9007368087768555
Validation loss: 2.2400543510272937

Epoch: 6| Step: 1
Training loss: 3.0927224159240723
Validation loss: 2.2441962842018373

Epoch: 6| Step: 2
Training loss: 2.9670863151550293
Validation loss: 2.2720253313741376

Epoch: 6| Step: 3
Training loss: 2.396230936050415
Validation loss: 2.2740360177973264

Epoch: 6| Step: 4
Training loss: 1.697554588317871
Validation loss: 2.284764920511553

Epoch: 6| Step: 5
Training loss: 2.6832010746002197
Validation loss: 2.265408969694568

Epoch: 6| Step: 6
Training loss: 2.02559232711792
Validation loss: 2.2293711029073244

Epoch: 6| Step: 7
Training loss: 2.1104557514190674
Validation loss: 2.214158288894161

Epoch: 6| Step: 8
Training loss: 2.7347350120544434
Validation loss: 2.204255014337519

Epoch: 6| Step: 9
Training loss: 2.518674373626709
Validation loss: 2.1908034739955777

Epoch: 6| Step: 10
Training loss: 2.1026668548583984
Validation loss: 2.1860683989781204

Epoch: 6| Step: 11
Training loss: 3.0588274002075195
Validation loss: 2.18464357237662

Epoch: 6| Step: 12
Training loss: 2.432926654815674
Validation loss: 2.180089135323801

Epoch: 6| Step: 13
Training loss: 3.5932416915893555
Validation loss: 2.179573832019683

Epoch: 102| Step: 0
Training loss: 3.2135684490203857
Validation loss: 2.180823036419448

Epoch: 6| Step: 1
Training loss: 1.8067312240600586
Validation loss: 2.1818578448346866

Epoch: 6| Step: 2
Training loss: 2.406083583831787
Validation loss: 2.179903535432713

Epoch: 6| Step: 3
Training loss: 2.565873622894287
Validation loss: 2.173864758142861

Epoch: 6| Step: 4
Training loss: 2.475135326385498
Validation loss: 2.1756002236438055

Epoch: 6| Step: 5
Training loss: 3.2034389972686768
Validation loss: 2.179783351959721

Epoch: 6| Step: 6
Training loss: 2.0275635719299316
Validation loss: 2.1844761884340675

Epoch: 6| Step: 7
Training loss: 2.358780860900879
Validation loss: 2.179601195038006

Epoch: 6| Step: 8
Training loss: 2.1344563961029053
Validation loss: 2.203576675025366

Epoch: 6| Step: 9
Training loss: 2.537274122238159
Validation loss: 2.2234010670774724

Epoch: 6| Step: 10
Training loss: 2.2172629833221436
Validation loss: 2.237381232682095

Epoch: 6| Step: 11
Training loss: 2.808469295501709
Validation loss: 2.2757727561458463

Epoch: 6| Step: 12
Training loss: 2.9232912063598633
Validation loss: 2.2841285531238844

Epoch: 6| Step: 13
Training loss: 2.3411598205566406
Validation loss: 2.2471519259996313

Epoch: 103| Step: 0
Training loss: 2.644371271133423
Validation loss: 2.234960409902757

Epoch: 6| Step: 1
Training loss: 2.6863691806793213
Validation loss: 2.1954225212015133

Epoch: 6| Step: 2
Training loss: 2.554295778274536
Validation loss: 2.196507497500348

Epoch: 6| Step: 3
Training loss: 3.4961514472961426
Validation loss: 2.195578613588887

Epoch: 6| Step: 4
Training loss: 2.263397693634033
Validation loss: 2.1849169500412478

Epoch: 6| Step: 5
Training loss: 1.900277853012085
Validation loss: 2.1850380025884157

Epoch: 6| Step: 6
Training loss: 2.229602813720703
Validation loss: 2.1723327252172653

Epoch: 6| Step: 7
Training loss: 2.3429222106933594
Validation loss: 2.1768459863560174

Epoch: 6| Step: 8
Training loss: 2.433955192565918
Validation loss: 2.184526830591181

Epoch: 6| Step: 9
Training loss: 2.0276002883911133
Validation loss: 2.1882439672306018

Epoch: 6| Step: 10
Training loss: 2.0088565349578857
Validation loss: 2.1903358095435688

Epoch: 6| Step: 11
Training loss: 2.1415929794311523
Validation loss: 2.1845275894288094

Epoch: 6| Step: 12
Training loss: 2.8778529167175293
Validation loss: 2.191142702615389

Epoch: 6| Step: 13
Training loss: 3.651028633117676
Validation loss: 2.1826569418753348

Epoch: 104| Step: 0
Training loss: 2.1810829639434814
Validation loss: 2.184082205577563

Epoch: 6| Step: 1
Training loss: 2.9919042587280273
Validation loss: 2.177387209348781

Epoch: 6| Step: 2
Training loss: 2.5450921058654785
Validation loss: 2.1731433073679605

Epoch: 6| Step: 3
Training loss: 2.4664146900177
Validation loss: 2.1769782804673716

Epoch: 6| Step: 4
Training loss: 2.255326271057129
Validation loss: 2.179048643317274

Epoch: 6| Step: 5
Training loss: 2.6299707889556885
Validation loss: 2.1804158456863894

Epoch: 6| Step: 6
Training loss: 2.5764963626861572
Validation loss: 2.1777405610648533

Epoch: 6| Step: 7
Training loss: 2.9431920051574707
Validation loss: 2.185844236804593

Epoch: 6| Step: 8
Training loss: 2.006596326828003
Validation loss: 2.184027051412931

Epoch: 6| Step: 9
Training loss: 2.6524367332458496
Validation loss: 2.1965087177932903

Epoch: 6| Step: 10
Training loss: 2.064241647720337
Validation loss: 2.2037788296258576

Epoch: 6| Step: 11
Training loss: 2.7174878120422363
Validation loss: 2.2195888385977796

Epoch: 6| Step: 12
Training loss: 2.5855894088745117
Validation loss: 2.206848834150581

Epoch: 6| Step: 13
Training loss: 1.9539426565170288
Validation loss: 2.212129256417674

Epoch: 105| Step: 0
Training loss: 3.7662510871887207
Validation loss: 2.207999480667935

Epoch: 6| Step: 1
Training loss: 2.568481206893921
Validation loss: 2.1887294605214107

Epoch: 6| Step: 2
Training loss: 2.862786293029785
Validation loss: 2.1749842871901808

Epoch: 6| Step: 3
Training loss: 2.152754068374634
Validation loss: 2.171475577098067

Epoch: 6| Step: 4
Training loss: 2.466596841812134
Validation loss: 2.175431428417083

Epoch: 6| Step: 5
Training loss: 1.691992998123169
Validation loss: 2.172308275776525

Epoch: 6| Step: 6
Training loss: 2.3793811798095703
Validation loss: 2.171350602180727

Epoch: 6| Step: 7
Training loss: 2.4019246101379395
Validation loss: 2.168211697250284

Epoch: 6| Step: 8
Training loss: 3.0379438400268555
Validation loss: 2.1709484541287987

Epoch: 6| Step: 9
Training loss: 2.879776954650879
Validation loss: 2.175973517920381

Epoch: 6| Step: 10
Training loss: 1.7236907482147217
Validation loss: 2.1725188609092467

Epoch: 6| Step: 11
Training loss: 2.0189085006713867
Validation loss: 2.1752786021078787

Epoch: 6| Step: 12
Training loss: 2.1756608486175537
Validation loss: 2.1747594802610335

Epoch: 6| Step: 13
Training loss: 2.722423553466797
Validation loss: 2.1810066212889967

Epoch: 106| Step: 0
Training loss: 1.9427666664123535
Validation loss: 2.1804504881622973

Epoch: 6| Step: 1
Training loss: 2.634532928466797
Validation loss: 2.18524440129598

Epoch: 6| Step: 2
Training loss: 2.0130953788757324
Validation loss: 2.180306432067707

Epoch: 6| Step: 3
Training loss: 3.054654598236084
Validation loss: 2.1768557704905027

Epoch: 6| Step: 4
Training loss: 2.4691355228424072
Validation loss: 2.1729651343437935

Epoch: 6| Step: 5
Training loss: 2.160270929336548
Validation loss: 2.168953880187004

Epoch: 6| Step: 6
Training loss: 2.285281181335449
Validation loss: 2.1699124613115863

Epoch: 6| Step: 7
Training loss: 1.5144166946411133
Validation loss: 2.167967789916582

Epoch: 6| Step: 8
Training loss: 2.716810703277588
Validation loss: 2.1701333061341317

Epoch: 6| Step: 9
Training loss: 2.7726874351501465
Validation loss: 2.1672289409945087

Epoch: 6| Step: 10
Training loss: 2.7861757278442383
Validation loss: 2.178869790928338

Epoch: 6| Step: 11
Training loss: 2.471019983291626
Validation loss: 2.1809419047447944

Epoch: 6| Step: 12
Training loss: 2.620025873184204
Validation loss: 2.1929018625649075

Epoch: 6| Step: 13
Training loss: 3.6134707927703857
Validation loss: 2.192155522684897

Epoch: 107| Step: 0
Training loss: 2.802651882171631
Validation loss: 2.200959251772973

Epoch: 6| Step: 1
Training loss: 1.8747347593307495
Validation loss: 2.1942424030714136

Epoch: 6| Step: 2
Training loss: 2.344512939453125
Validation loss: 2.193106230869088

Epoch: 6| Step: 3
Training loss: 2.9134151935577393
Validation loss: 2.1778373910534765

Epoch: 6| Step: 4
Training loss: 2.075296401977539
Validation loss: 2.1883090426844936

Epoch: 6| Step: 5
Training loss: 2.5751562118530273
Validation loss: 2.1777896676012265

Epoch: 6| Step: 6
Training loss: 2.6241965293884277
Validation loss: 2.1732047168157433

Epoch: 6| Step: 7
Training loss: 2.471301555633545
Validation loss: 2.17507690511724

Epoch: 6| Step: 8
Training loss: 2.383481979370117
Validation loss: 2.1742499848847747

Epoch: 6| Step: 9
Training loss: 2.6766552925109863
Validation loss: 2.180796871903122

Epoch: 6| Step: 10
Training loss: 2.3473587036132812
Validation loss: 2.1687300910231886

Epoch: 6| Step: 11
Training loss: 2.118741750717163
Validation loss: 2.1732808928335867

Epoch: 6| Step: 12
Training loss: 2.2810206413269043
Validation loss: 2.169708785190377

Epoch: 6| Step: 13
Training loss: 3.3223304748535156
Validation loss: 2.168186059562109

Epoch: 108| Step: 0
Training loss: 2.1325032711029053
Validation loss: 2.165940212947066

Epoch: 6| Step: 1
Training loss: 2.268373727798462
Validation loss: 2.1720510810934086

Epoch: 6| Step: 2
Training loss: 2.4141080379486084
Validation loss: 2.1724037585719937

Epoch: 6| Step: 3
Training loss: 2.247429609298706
Validation loss: 2.157385978647458

Epoch: 6| Step: 4
Training loss: 2.4565916061401367
Validation loss: 2.1712785638788694

Epoch: 6| Step: 5
Training loss: 2.72141170501709
Validation loss: 2.1602394145022155

Epoch: 6| Step: 6
Training loss: 1.7267429828643799
Validation loss: 2.161790173540833

Epoch: 6| Step: 7
Training loss: 2.946533679962158
Validation loss: 2.169261517063264

Epoch: 6| Step: 8
Training loss: 3.2030506134033203
Validation loss: 2.1754298774144982

Epoch: 6| Step: 9
Training loss: 1.9499783515930176
Validation loss: 2.187221419426703

Epoch: 6| Step: 10
Training loss: 2.507737874984741
Validation loss: 2.1780682251017582

Epoch: 6| Step: 11
Training loss: 2.9590210914611816
Validation loss: 2.174506215639012

Epoch: 6| Step: 12
Training loss: 2.462157964706421
Validation loss: 2.1821574126520464

Epoch: 6| Step: 13
Training loss: 2.5791656970977783
Validation loss: 2.169319642487393

Epoch: 109| Step: 0
Training loss: 2.457587480545044
Validation loss: 2.1692573857563797

Epoch: 6| Step: 1
Training loss: 1.934531807899475
Validation loss: 2.166811171398368

Epoch: 6| Step: 2
Training loss: 1.9888261556625366
Validation loss: 2.1683545958611274

Epoch: 6| Step: 3
Training loss: 2.057554006576538
Validation loss: 2.170329714334139

Epoch: 6| Step: 4
Training loss: 2.438936471939087
Validation loss: 2.167182792899429

Epoch: 6| Step: 5
Training loss: 2.700655937194824
Validation loss: 2.1765446355265956

Epoch: 6| Step: 6
Training loss: 1.7614307403564453
Validation loss: 2.1808564842388196

Epoch: 6| Step: 7
Training loss: 3.0260486602783203
Validation loss: 2.1808945773750223

Epoch: 6| Step: 8
Training loss: 2.2848293781280518
Validation loss: 2.197070224310762

Epoch: 6| Step: 9
Training loss: 2.724674701690674
Validation loss: 2.2069289761204876

Epoch: 6| Step: 10
Training loss: 3.0345706939697266
Validation loss: 2.220426667121149

Epoch: 6| Step: 11
Training loss: 3.2458086013793945
Validation loss: 2.229293728387484

Epoch: 6| Step: 12
Training loss: 2.5077929496765137
Validation loss: 2.1993207957154963

Epoch: 6| Step: 13
Training loss: 2.306360960006714
Validation loss: 2.18323290476235

Epoch: 110| Step: 0
Training loss: 2.7204525470733643
Validation loss: 2.1777839763190157

Epoch: 6| Step: 1
Training loss: 2.214439868927002
Validation loss: 2.1862790046199674

Epoch: 6| Step: 2
Training loss: 1.9724540710449219
Validation loss: 2.18761303347926

Epoch: 6| Step: 3
Training loss: 2.3342294692993164
Validation loss: 2.1909634426075923

Epoch: 6| Step: 4
Training loss: 2.478273868560791
Validation loss: 2.192758483271445

Epoch: 6| Step: 5
Training loss: 2.411477565765381
Validation loss: 2.186554592142823

Epoch: 6| Step: 6
Training loss: 2.3667192459106445
Validation loss: 2.1783266503323793

Epoch: 6| Step: 7
Training loss: 2.296588182449341
Validation loss: 2.1767745966552408

Epoch: 6| Step: 8
Training loss: 2.3227033615112305
Validation loss: 2.168360669125793

Epoch: 6| Step: 9
Training loss: 3.4453842639923096
Validation loss: 2.1481187958871164

Epoch: 6| Step: 10
Training loss: 1.5388453006744385
Validation loss: 2.151026846260153

Epoch: 6| Step: 11
Training loss: 3.056446075439453
Validation loss: 2.148657670585058

Epoch: 6| Step: 12
Training loss: 2.653702735900879
Validation loss: 2.1547798495138846

Epoch: 6| Step: 13
Training loss: 2.670387029647827
Validation loss: 2.151874165381155

Epoch: 111| Step: 0
Training loss: 2.857800006866455
Validation loss: 2.156401370161323

Epoch: 6| Step: 1
Training loss: 2.1091599464416504
Validation loss: 2.1781038391974663

Epoch: 6| Step: 2
Training loss: 2.2349181175231934
Validation loss: 2.1844654544707267

Epoch: 6| Step: 3
Training loss: 1.4477940797805786
Validation loss: 2.1804033966474634

Epoch: 6| Step: 4
Training loss: 2.8946542739868164
Validation loss: 2.190268301194714

Epoch: 6| Step: 5
Training loss: 2.2146575450897217
Validation loss: 2.1954144431698706

Epoch: 6| Step: 6
Training loss: 3.468109607696533
Validation loss: 2.177592897927889

Epoch: 6| Step: 7
Training loss: 2.638289451599121
Validation loss: 2.186698454682545

Epoch: 6| Step: 8
Training loss: 3.1756913661956787
Validation loss: 2.167779217484177

Epoch: 6| Step: 9
Training loss: 2.741771697998047
Validation loss: 2.163243878272272

Epoch: 6| Step: 10
Training loss: 2.634669065475464
Validation loss: 2.1543910759751514

Epoch: 6| Step: 11
Training loss: 1.4486383199691772
Validation loss: 2.158354587452386

Epoch: 6| Step: 12
Training loss: 2.645132541656494
Validation loss: 2.161034007226267

Epoch: 6| Step: 13
Training loss: 1.482637643814087
Validation loss: 2.172064230006228

Epoch: 112| Step: 0
Training loss: 2.2358336448669434
Validation loss: 2.180291993643648

Epoch: 6| Step: 1
Training loss: 3.193885326385498
Validation loss: 2.1911831158463673

Epoch: 6| Step: 2
Training loss: 2.351990222930908
Validation loss: 2.169149045021303

Epoch: 6| Step: 3
Training loss: 3.1715354919433594
Validation loss: 2.170667791879305

Epoch: 6| Step: 4
Training loss: 2.6145834922790527
Validation loss: 2.1658491280771073

Epoch: 6| Step: 5
Training loss: 2.272202491760254
Validation loss: 2.1684061147833384

Epoch: 6| Step: 6
Training loss: 1.9637885093688965
Validation loss: 2.169606480547177

Epoch: 6| Step: 7
Training loss: 2.261895179748535
Validation loss: 2.160710289914121

Epoch: 6| Step: 8
Training loss: 2.0380101203918457
Validation loss: 2.1502527588157245

Epoch: 6| Step: 9
Training loss: 2.2010419368743896
Validation loss: 2.145349571781774

Epoch: 6| Step: 10
Training loss: 1.8267298936843872
Validation loss: 2.1443585580395115

Epoch: 6| Step: 11
Training loss: 2.1433160305023193
Validation loss: 2.1499612510845227

Epoch: 6| Step: 12
Training loss: 3.1168437004089355
Validation loss: 2.152115983347739

Epoch: 6| Step: 13
Training loss: 3.381021738052368
Validation loss: 2.1551020081325243

Epoch: 113| Step: 0
Training loss: 1.9894626140594482
Validation loss: 2.15615758075509

Epoch: 6| Step: 1
Training loss: 2.9963719844818115
Validation loss: 2.173183536016813

Epoch: 6| Step: 2
Training loss: 2.7816953659057617
Validation loss: 2.1736372914365543

Epoch: 6| Step: 3
Training loss: 1.9761936664581299
Validation loss: 2.165013667075865

Epoch: 6| Step: 4
Training loss: 1.642165184020996
Validation loss: 2.1789577135475735

Epoch: 6| Step: 5
Training loss: 2.556288719177246
Validation loss: 2.1666697276535856

Epoch: 6| Step: 6
Training loss: 2.703657627105713
Validation loss: 2.160334684515512

Epoch: 6| Step: 7
Training loss: 2.858311176300049
Validation loss: 2.1618754620193155

Epoch: 6| Step: 8
Training loss: 1.7422945499420166
Validation loss: 2.163862625757853

Epoch: 6| Step: 9
Training loss: 2.502763271331787
Validation loss: 2.157643207939722

Epoch: 6| Step: 10
Training loss: 2.2461512088775635
Validation loss: 2.1498978881425757

Epoch: 6| Step: 11
Training loss: 2.8319830894470215
Validation loss: 2.150046243462511

Epoch: 6| Step: 12
Training loss: 2.939460039138794
Validation loss: 2.1506343631334204

Epoch: 6| Step: 13
Training loss: 2.561638832092285
Validation loss: 2.1441213802624772

Epoch: 114| Step: 0
Training loss: 2.7566843032836914
Validation loss: 2.142479101816813

Epoch: 6| Step: 1
Training loss: 1.7896733283996582
Validation loss: 2.1628707608869

Epoch: 6| Step: 2
Training loss: 2.3239991664886475
Validation loss: 2.172886279321486

Epoch: 6| Step: 3
Training loss: 2.319925308227539
Validation loss: 2.18268193352607

Epoch: 6| Step: 4
Training loss: 2.401224136352539
Validation loss: 2.1902077351847002

Epoch: 6| Step: 5
Training loss: 2.690181255340576
Validation loss: 2.1876607171950804

Epoch: 6| Step: 6
Training loss: 2.8469038009643555
Validation loss: 2.196361075165451

Epoch: 6| Step: 7
Training loss: 2.0376133918762207
Validation loss: 2.1889610059799685

Epoch: 6| Step: 8
Training loss: 2.5166773796081543
Validation loss: 2.1632133786396315

Epoch: 6| Step: 9
Training loss: 2.416907787322998
Validation loss: 2.146089384632726

Epoch: 6| Step: 10
Training loss: 2.643768310546875
Validation loss: 2.14211848474318

Epoch: 6| Step: 11
Training loss: 2.5669233798980713
Validation loss: 2.1358579063928254

Epoch: 6| Step: 12
Training loss: 2.2592720985412598
Validation loss: 2.144303065474315

Epoch: 6| Step: 13
Training loss: 3.0602426528930664
Validation loss: 2.140469984341693

Epoch: 115| Step: 0
Training loss: 2.9087729454040527
Validation loss: 2.1443520310104534

Epoch: 6| Step: 1
Training loss: 2.074547290802002
Validation loss: 2.15109097701247

Epoch: 6| Step: 2
Training loss: 1.7019028663635254
Validation loss: 2.1424411509626653

Epoch: 6| Step: 3
Training loss: 1.9968914985656738
Validation loss: 2.152855037361063

Epoch: 6| Step: 4
Training loss: 1.8400832414627075
Validation loss: 2.1831026320816367

Epoch: 6| Step: 5
Training loss: 3.392582893371582
Validation loss: 2.2241491886877243

Epoch: 6| Step: 6
Training loss: 2.4971916675567627
Validation loss: 2.2628518548063052

Epoch: 6| Step: 7
Training loss: 2.5818710327148438
Validation loss: 2.323561030049478

Epoch: 6| Step: 8
Training loss: 2.295912981033325
Validation loss: 2.333381511831796

Epoch: 6| Step: 9
Training loss: 3.1861066818237305
Validation loss: 2.3147984243208364

Epoch: 6| Step: 10
Training loss: 2.045654773712158
Validation loss: 2.266994612191313

Epoch: 6| Step: 11
Training loss: 3.069585084915161
Validation loss: 2.2234892563153337

Epoch: 6| Step: 12
Training loss: 2.6332550048828125
Validation loss: 2.1800532007730133

Epoch: 6| Step: 13
Training loss: 2.512498378753662
Validation loss: 2.159545660018921

Epoch: 116| Step: 0
Training loss: 2.861948251724243
Validation loss: 2.128881408322242

Epoch: 6| Step: 1
Training loss: 2.330174684524536
Validation loss: 2.127322184142246

Epoch: 6| Step: 2
Training loss: 2.8442511558532715
Validation loss: 2.1227768774955504

Epoch: 6| Step: 3
Training loss: 2.7220890522003174
Validation loss: 2.1226400124129428

Epoch: 6| Step: 4
Training loss: 1.8758726119995117
Validation loss: 2.128442733518539

Epoch: 6| Step: 5
Training loss: 2.056206226348877
Validation loss: 2.127279145743257

Epoch: 6| Step: 6
Training loss: 1.908381700515747
Validation loss: 2.1179788240822415

Epoch: 6| Step: 7
Training loss: 3.0952601432800293
Validation loss: 2.12756226652412

Epoch: 6| Step: 8
Training loss: 2.1247634887695312
Validation loss: 2.122835067010695

Epoch: 6| Step: 9
Training loss: 2.529967784881592
Validation loss: 2.12794832516742

Epoch: 6| Step: 10
Training loss: 3.053506851196289
Validation loss: 2.1306064128875732

Epoch: 6| Step: 11
Training loss: 2.7439024448394775
Validation loss: 2.13105329134131

Epoch: 6| Step: 12
Training loss: 1.9445137977600098
Validation loss: 2.148536830820063

Epoch: 6| Step: 13
Training loss: 2.356543779373169
Validation loss: 2.1556685816857124

Epoch: 117| Step: 0
Training loss: 2.726531505584717
Validation loss: 2.1612863156103317

Epoch: 6| Step: 1
Training loss: 2.4186794757843018
Validation loss: 2.165859189084781

Epoch: 6| Step: 2
Training loss: 2.9686684608459473
Validation loss: 2.172694593347529

Epoch: 6| Step: 3
Training loss: 1.5735352039337158
Validation loss: 2.180381175010435

Epoch: 6| Step: 4
Training loss: 2.649167776107788
Validation loss: 2.179223540008709

Epoch: 6| Step: 5
Training loss: 2.2214269638061523
Validation loss: 2.1812062160943144

Epoch: 6| Step: 6
Training loss: 2.175534963607788
Validation loss: 2.1714569035396782

Epoch: 6| Step: 7
Training loss: 2.8269762992858887
Validation loss: 2.1829292607563797

Epoch: 6| Step: 8
Training loss: 2.3215885162353516
Validation loss: 2.1782904568538872

Epoch: 6| Step: 9
Training loss: 2.3423030376434326
Validation loss: 2.1753018850921304

Epoch: 6| Step: 10
Training loss: 2.4599111080169678
Validation loss: 2.161730791932793

Epoch: 6| Step: 11
Training loss: 2.499626398086548
Validation loss: 2.166056584286433

Epoch: 6| Step: 12
Training loss: 3.135754346847534
Validation loss: 2.1562936062453897

Epoch: 6| Step: 13
Training loss: 1.784363031387329
Validation loss: 2.1324505703423613

Epoch: 118| Step: 0
Training loss: 2.1225814819335938
Validation loss: 2.124136438933752

Epoch: 6| Step: 1
Training loss: 2.547825813293457
Validation loss: 2.129081451764671

Epoch: 6| Step: 2
Training loss: 2.568272113800049
Validation loss: 2.1245599280121508

Epoch: 6| Step: 3
Training loss: 1.9852795600891113
Validation loss: 2.1387639302079395

Epoch: 6| Step: 4
Training loss: 2.309577703475952
Validation loss: 2.142742226200719

Epoch: 6| Step: 5
Training loss: 2.3757266998291016
Validation loss: 2.1469161818104405

Epoch: 6| Step: 6
Training loss: 3.1469359397888184
Validation loss: 2.1481508516496226

Epoch: 6| Step: 7
Training loss: 1.5296261310577393
Validation loss: 2.156128111705985

Epoch: 6| Step: 8
Training loss: 2.265042304992676
Validation loss: 2.1672929281829507

Epoch: 6| Step: 9
Training loss: 1.9702619314193726
Validation loss: 2.177376180566767

Epoch: 6| Step: 10
Training loss: 1.6654658317565918
Validation loss: 2.2043322235025387

Epoch: 6| Step: 11
Training loss: 3.204519271850586
Validation loss: 2.2043815761484127

Epoch: 6| Step: 12
Training loss: 4.11699914932251
Validation loss: 2.1905422902876333

Epoch: 6| Step: 13
Training loss: 3.1247801780700684
Validation loss: 2.176469364473897

Epoch: 119| Step: 0
Training loss: 2.476069450378418
Validation loss: 2.150226177707795

Epoch: 6| Step: 1
Training loss: 2.3521156311035156
Validation loss: 2.1358326686325895

Epoch: 6| Step: 2
Training loss: 2.3428988456726074
Validation loss: 2.1180546975904897

Epoch: 6| Step: 3
Training loss: 2.538877487182617
Validation loss: 2.127842762136972

Epoch: 6| Step: 4
Training loss: 2.716252326965332
Validation loss: 2.118870671077441

Epoch: 6| Step: 5
Training loss: 2.5406646728515625
Validation loss: 2.1172889714599936

Epoch: 6| Step: 6
Training loss: 2.706569194793701
Validation loss: 2.1154182610973233

Epoch: 6| Step: 7
Training loss: 2.4807589054107666
Validation loss: 2.1191885522616807

Epoch: 6| Step: 8
Training loss: 1.8941726684570312
Validation loss: 2.1177422487607567

Epoch: 6| Step: 9
Training loss: 3.0392818450927734
Validation loss: 2.120558606681003

Epoch: 6| Step: 10
Training loss: 2.021944284439087
Validation loss: 2.1195824402634815

Epoch: 6| Step: 11
Training loss: 2.0791163444519043
Validation loss: 2.119489123744349

Epoch: 6| Step: 12
Training loss: 2.4710469245910645
Validation loss: 2.128216223050189

Epoch: 6| Step: 13
Training loss: 2.5243492126464844
Validation loss: 2.14805188486653

Epoch: 120| Step: 0
Training loss: 2.823678731918335
Validation loss: 2.190885220804522

Epoch: 6| Step: 1
Training loss: 2.144068717956543
Validation loss: 2.1910072449714906

Epoch: 6| Step: 2
Training loss: 2.2555675506591797
Validation loss: 2.1981075438120032

Epoch: 6| Step: 3
Training loss: 2.353048801422119
Validation loss: 2.2110719655149724

Epoch: 6| Step: 4
Training loss: 3.0462093353271484
Validation loss: 2.215363251265659

Epoch: 6| Step: 5
Training loss: 2.2854397296905518
Validation loss: 2.217798007431851

Epoch: 6| Step: 6
Training loss: 2.166468620300293
Validation loss: 2.211287042146088

Epoch: 6| Step: 7
Training loss: 2.641483783721924
Validation loss: 2.184513762433042

Epoch: 6| Step: 8
Training loss: 1.8398058414459229
Validation loss: 2.1581145742888093

Epoch: 6| Step: 9
Training loss: 1.9887080192565918
Validation loss: 2.141917828590639

Epoch: 6| Step: 10
Training loss: 3.0702803134918213
Validation loss: 2.1286313251782487

Epoch: 6| Step: 11
Training loss: 2.5138561725616455
Validation loss: 2.118907984866891

Epoch: 6| Step: 12
Training loss: 2.472806692123413
Validation loss: 2.1220550126926874

Epoch: 6| Step: 13
Training loss: 2.425032615661621
Validation loss: 2.1193469929438766

Epoch: 121| Step: 0
Training loss: 2.9846010208129883
Validation loss: 2.119259903507848

Epoch: 6| Step: 1
Training loss: 2.6428935527801514
Validation loss: 2.116778019935854

Epoch: 6| Step: 2
Training loss: 2.260708808898926
Validation loss: 2.122665843655986

Epoch: 6| Step: 3
Training loss: 2.5056262016296387
Validation loss: 2.124016979689239

Epoch: 6| Step: 4
Training loss: 2.6436634063720703
Validation loss: 2.1216130461744083

Epoch: 6| Step: 5
Training loss: 2.3779869079589844
Validation loss: 2.1177366497696086

Epoch: 6| Step: 6
Training loss: 1.887773036956787
Validation loss: 2.1157849065719114

Epoch: 6| Step: 7
Training loss: 1.928026556968689
Validation loss: 2.120190073085088

Epoch: 6| Step: 8
Training loss: 2.08890962600708
Validation loss: 2.120982504660083

Epoch: 6| Step: 9
Training loss: 2.3100454807281494
Validation loss: 2.124087632343333

Epoch: 6| Step: 10
Training loss: 2.642803192138672
Validation loss: 2.144958849876158

Epoch: 6| Step: 11
Training loss: 2.3944520950317383
Validation loss: 2.1679322488846315

Epoch: 6| Step: 12
Training loss: 3.1734657287597656
Validation loss: 2.182353129950903

Epoch: 6| Step: 13
Training loss: 2.6505587100982666
Validation loss: 2.1812864990644556

Epoch: 122| Step: 0
Training loss: 2.9621434211730957
Validation loss: 2.1749048412487073

Epoch: 6| Step: 1
Training loss: 2.2579808235168457
Validation loss: 2.1609615254145798

Epoch: 6| Step: 2
Training loss: 2.9550886154174805
Validation loss: 2.1463922351919194

Epoch: 6| Step: 3
Training loss: 2.2233176231384277
Validation loss: 2.1277627816764255

Epoch: 6| Step: 4
Training loss: 1.8652565479278564
Validation loss: 2.118833990507228

Epoch: 6| Step: 5
Training loss: 2.811307907104492
Validation loss: 2.115688213738062

Epoch: 6| Step: 6
Training loss: 2.4439711570739746
Validation loss: 2.1119082922576577

Epoch: 6| Step: 7
Training loss: 1.8869578838348389
Validation loss: 2.118258027620213

Epoch: 6| Step: 8
Training loss: 2.2674546241760254
Validation loss: 2.116939693368891

Epoch: 6| Step: 9
Training loss: 2.4370954036712646
Validation loss: 2.1228630850392003

Epoch: 6| Step: 10
Training loss: 2.0083813667297363
Validation loss: 2.120001898016981

Epoch: 6| Step: 11
Training loss: 2.6839118003845215
Validation loss: 2.1309561729431152

Epoch: 6| Step: 12
Training loss: 3.076660633087158
Validation loss: 2.1439438122575

Epoch: 6| Step: 13
Training loss: 2.254760265350342
Validation loss: 2.1521718860954366

Epoch: 123| Step: 0
Training loss: 3.264467239379883
Validation loss: 2.1501855927128948

Epoch: 6| Step: 1
Training loss: 2.8186492919921875
Validation loss: 2.1583037966041156

Epoch: 6| Step: 2
Training loss: 1.7318055629730225
Validation loss: 2.151669625313051

Epoch: 6| Step: 3
Training loss: 2.42086124420166
Validation loss: 2.1538684163042294

Epoch: 6| Step: 4
Training loss: 2.1980934143066406
Validation loss: 2.154611920797697

Epoch: 6| Step: 5
Training loss: 2.402613878250122
Validation loss: 2.1548823925756637

Epoch: 6| Step: 6
Training loss: 2.898179531097412
Validation loss: 2.157009704138643

Epoch: 6| Step: 7
Training loss: 1.9592974185943604
Validation loss: 2.1733999893229496

Epoch: 6| Step: 8
Training loss: 2.398423671722412
Validation loss: 2.176678611386207

Epoch: 6| Step: 9
Training loss: 2.0056796073913574
Validation loss: 2.1645968908904702

Epoch: 6| Step: 10
Training loss: 2.058749198913574
Validation loss: 2.161499656656737

Epoch: 6| Step: 11
Training loss: 2.8163249492645264
Validation loss: 2.1513435738061064

Epoch: 6| Step: 12
Training loss: 2.2194437980651855
Validation loss: 2.1474096108508367

Epoch: 6| Step: 13
Training loss: 3.070917844772339
Validation loss: 2.1394926091676116

Epoch: 124| Step: 0
Training loss: 2.4362199306488037
Validation loss: 2.1408825715382895

Epoch: 6| Step: 1
Training loss: 3.0788862705230713
Validation loss: 2.1452052080503075

Epoch: 6| Step: 2
Training loss: 1.9880554676055908
Validation loss: 2.139360192001507

Epoch: 6| Step: 3
Training loss: 2.4304909706115723
Validation loss: 2.1478465718607747

Epoch: 6| Step: 4
Training loss: 1.6975703239440918
Validation loss: 2.1465023717572613

Epoch: 6| Step: 5
Training loss: 2.5637781620025635
Validation loss: 2.1485484287302983

Epoch: 6| Step: 6
Training loss: 3.194155693054199
Validation loss: 2.166389501223

Epoch: 6| Step: 7
Training loss: 2.265953779220581
Validation loss: 2.1760507424672446

Epoch: 6| Step: 8
Training loss: 2.372685194015503
Validation loss: 2.160838992364945

Epoch: 6| Step: 9
Training loss: 2.4847562313079834
Validation loss: 2.1714763308084137

Epoch: 6| Step: 10
Training loss: 2.6044414043426514
Validation loss: 2.1582815877852903

Epoch: 6| Step: 11
Training loss: 2.271818161010742
Validation loss: 2.1626534000519784

Epoch: 6| Step: 12
Training loss: 2.0413284301757812
Validation loss: 2.1327206063014206

Epoch: 6| Step: 13
Training loss: 2.4897043704986572
Validation loss: 2.1437186374459216

Epoch: 125| Step: 0
Training loss: 2.853062152862549
Validation loss: 2.1352962934842674

Epoch: 6| Step: 1
Training loss: 2.416268825531006
Validation loss: 2.1181858124271518

Epoch: 6| Step: 2
Training loss: 2.5361106395721436
Validation loss: 2.118897730304349

Epoch: 6| Step: 3
Training loss: 2.601083755493164
Validation loss: 2.119972998096097

Epoch: 6| Step: 4
Training loss: 2.208220958709717
Validation loss: 2.117015060558114

Epoch: 6| Step: 5
Training loss: 2.207942008972168
Validation loss: 2.1251537440925516

Epoch: 6| Step: 6
Training loss: 2.681105613708496
Validation loss: 2.122364164680563

Epoch: 6| Step: 7
Training loss: 2.690446376800537
Validation loss: 2.137435861813125

Epoch: 6| Step: 8
Training loss: 2.298337936401367
Validation loss: 2.1393216809918805

Epoch: 6| Step: 9
Training loss: 2.026185989379883
Validation loss: 2.1379662931606336

Epoch: 6| Step: 10
Training loss: 2.4860939979553223
Validation loss: 2.156251718921046

Epoch: 6| Step: 11
Training loss: 2.156177520751953
Validation loss: 2.147602932427519

Epoch: 6| Step: 12
Training loss: 2.604985237121582
Validation loss: 2.1501874282795894

Epoch: 6| Step: 13
Training loss: 1.9309136867523193
Validation loss: 2.1493145394068893

Epoch: 126| Step: 0
Training loss: 2.651125192642212
Validation loss: 2.1668068824275846

Epoch: 6| Step: 1
Training loss: 1.4952023029327393
Validation loss: 2.2055818188575005

Epoch: 6| Step: 2
Training loss: 2.803738594055176
Validation loss: 2.2354921986979823

Epoch: 6| Step: 3
Training loss: 2.8796544075012207
Validation loss: 2.2995721627307195

Epoch: 6| Step: 4
Training loss: 2.541351795196533
Validation loss: 2.3660649996931835

Epoch: 6| Step: 5
Training loss: 1.9998822212219238
Validation loss: 2.4122853971296743

Epoch: 6| Step: 6
Training loss: 2.8689980506896973
Validation loss: 2.337465629782728

Epoch: 6| Step: 7
Training loss: 2.430360794067383
Validation loss: 2.285071175585511

Epoch: 6| Step: 8
Training loss: 2.858553647994995
Validation loss: 2.1912188837605138

Epoch: 6| Step: 9
Training loss: 2.781954288482666
Validation loss: 2.1507142384847007

Epoch: 6| Step: 10
Training loss: 2.933455467224121
Validation loss: 2.1424866684021486

Epoch: 6| Step: 11
Training loss: 2.6574339866638184
Validation loss: 2.1558478032388995

Epoch: 6| Step: 12
Training loss: 2.1656768321990967
Validation loss: 2.159944530456297

Epoch: 6| Step: 13
Training loss: 1.3542240858078003
Validation loss: 2.146473705127675

Epoch: 127| Step: 0
Training loss: 2.721177339553833
Validation loss: 2.140327533086141

Epoch: 6| Step: 1
Training loss: 2.0014243125915527
Validation loss: 2.148870339957617

Epoch: 6| Step: 2
Training loss: 2.0177135467529297
Validation loss: 2.161702356030864

Epoch: 6| Step: 3
Training loss: 2.6877598762512207
Validation loss: 2.1629939604831

Epoch: 6| Step: 4
Training loss: 2.9534287452697754
Validation loss: 2.1726224948001165

Epoch: 6| Step: 5
Training loss: 2.4913783073425293
Validation loss: 2.1717076942484868

Epoch: 6| Step: 6
Training loss: 2.55715274810791
Validation loss: 2.1957385488735732

Epoch: 6| Step: 7
Training loss: 2.386197328567505
Validation loss: 2.171424372221834

Epoch: 6| Step: 8
Training loss: 2.444227695465088
Validation loss: 2.1498151568956274

Epoch: 6| Step: 9
Training loss: 2.1876304149627686
Validation loss: 2.142489897307529

Epoch: 6| Step: 10
Training loss: 2.351241111755371
Validation loss: 2.1419180567546556

Epoch: 6| Step: 11
Training loss: 2.481400966644287
Validation loss: 2.1460244271063034

Epoch: 6| Step: 12
Training loss: 2.7427597045898438
Validation loss: 2.16420877492556

Epoch: 6| Step: 13
Training loss: 2.627354621887207
Validation loss: 2.1877230495534916

Epoch: 128| Step: 0
Training loss: 2.0468034744262695
Validation loss: 2.1850761431519703

Epoch: 6| Step: 1
Training loss: 2.8688857555389404
Validation loss: 2.209178416959701

Epoch: 6| Step: 2
Training loss: 2.9535975456237793
Validation loss: 2.2154195513776553

Epoch: 6| Step: 3
Training loss: 2.526641845703125
Validation loss: 2.1991803671724055

Epoch: 6| Step: 4
Training loss: 1.7333242893218994
Validation loss: 2.198309806085402

Epoch: 6| Step: 5
Training loss: 1.8359520435333252
Validation loss: 2.1895015880625737

Epoch: 6| Step: 6
Training loss: 1.882638931274414
Validation loss: 2.179390335595736

Epoch: 6| Step: 7
Training loss: 2.355926036834717
Validation loss: 2.1950101493507304

Epoch: 6| Step: 8
Training loss: 3.0920662879943848
Validation loss: 2.1989658289058234

Epoch: 6| Step: 9
Training loss: 2.429720401763916
Validation loss: 2.1869220605460544

Epoch: 6| Step: 10
Training loss: 2.566789150238037
Validation loss: 2.1529372302434777

Epoch: 6| Step: 11
Training loss: 2.2003207206726074
Validation loss: 2.1432920079077444

Epoch: 6| Step: 12
Training loss: 2.854185104370117
Validation loss: 2.135723567778064

Epoch: 6| Step: 13
Training loss: 3.1081674098968506
Validation loss: 2.1324746711279756

Epoch: 129| Step: 0
Training loss: 1.9333865642547607
Validation loss: 2.1359793242587837

Epoch: 6| Step: 1
Training loss: 1.9869694709777832
Validation loss: 2.1311626254871325

Epoch: 6| Step: 2
Training loss: 2.8282973766326904
Validation loss: 2.1314184793861966

Epoch: 6| Step: 3
Training loss: 2.9911813735961914
Validation loss: 2.1310909973677767

Epoch: 6| Step: 4
Training loss: 2.4299278259277344
Validation loss: 2.1397464506087767

Epoch: 6| Step: 5
Training loss: 1.6914725303649902
Validation loss: 2.139601651058402

Epoch: 6| Step: 6
Training loss: 3.864391326904297
Validation loss: 2.1301619340014715

Epoch: 6| Step: 7
Training loss: 1.889182686805725
Validation loss: 2.1491975245937223

Epoch: 6| Step: 8
Training loss: 2.3826069831848145
Validation loss: 2.152586579322815

Epoch: 6| Step: 9
Training loss: 2.1026341915130615
Validation loss: 2.1517265919716126

Epoch: 6| Step: 10
Training loss: 2.3361637592315674
Validation loss: 2.161148573762627

Epoch: 6| Step: 11
Training loss: 2.736464262008667
Validation loss: 2.1507973132594937

Epoch: 6| Step: 12
Training loss: 2.472601890563965
Validation loss: 2.135092230253322

Epoch: 6| Step: 13
Training loss: 2.1718177795410156
Validation loss: 2.119748584685787

Epoch: 130| Step: 0
Training loss: 3.5235583782196045
Validation loss: 2.108104754519719

Epoch: 6| Step: 1
Training loss: 2.397172451019287
Validation loss: 2.1087639639454503

Epoch: 6| Step: 2
Training loss: 2.820577621459961
Validation loss: 2.107036872576642

Epoch: 6| Step: 3
Training loss: 2.8328335285186768
Validation loss: 2.1092365044419483

Epoch: 6| Step: 4
Training loss: 2.1453394889831543
Validation loss: 2.100704527670337

Epoch: 6| Step: 5
Training loss: 2.0765180587768555
Validation loss: 2.104427355591969

Epoch: 6| Step: 6
Training loss: 2.4273977279663086
Validation loss: 2.0991895134731005

Epoch: 6| Step: 7
Training loss: 2.8958892822265625
Validation loss: 2.100066937426085

Epoch: 6| Step: 8
Training loss: 2.3397152423858643
Validation loss: 2.102816367662081

Epoch: 6| Step: 9
Training loss: 1.6116342544555664
Validation loss: 2.1115027358455043

Epoch: 6| Step: 10
Training loss: 2.405646324157715
Validation loss: 2.1118517998726136

Epoch: 6| Step: 11
Training loss: 1.9844427108764648
Validation loss: 2.120225002688746

Epoch: 6| Step: 12
Training loss: 2.14255428314209
Validation loss: 2.135529923182662

Epoch: 6| Step: 13
Training loss: 2.7302112579345703
Validation loss: 2.1372896471331195

Epoch: 131| Step: 0
Training loss: 2.245232105255127
Validation loss: 2.1432601764637935

Epoch: 6| Step: 1
Training loss: 2.1245710849761963
Validation loss: 2.1449516896278626

Epoch: 6| Step: 2
Training loss: 2.922168731689453
Validation loss: 2.149048482218096

Epoch: 6| Step: 3
Training loss: 2.542264461517334
Validation loss: 2.154010490704608

Epoch: 6| Step: 4
Training loss: 1.7873820066452026
Validation loss: 2.1491107453582106

Epoch: 6| Step: 5
Training loss: 2.3194050788879395
Validation loss: 2.150446935366559

Epoch: 6| Step: 6
Training loss: 2.4270882606506348
Validation loss: 2.1472085137521066

Epoch: 6| Step: 7
Training loss: 2.241652488708496
Validation loss: 2.1386424315873014

Epoch: 6| Step: 8
Training loss: 2.9897537231445312
Validation loss: 2.128934539774413

Epoch: 6| Step: 9
Training loss: 2.393126964569092
Validation loss: 2.1230459572166525

Epoch: 6| Step: 10
Training loss: 2.4833180904388428
Validation loss: 2.100562121278496

Epoch: 6| Step: 11
Training loss: 1.9950332641601562
Validation loss: 2.1034138382122083

Epoch: 6| Step: 12
Training loss: 2.462897300720215
Validation loss: 2.1035123922491588

Epoch: 6| Step: 13
Training loss: 3.0069987773895264
Validation loss: 2.0982322295506797

Epoch: 132| Step: 0
Training loss: 2.5878021717071533
Validation loss: 2.0997401770725044

Epoch: 6| Step: 1
Training loss: 1.554542899131775
Validation loss: 2.10739403898998

Epoch: 6| Step: 2
Training loss: 2.7739076614379883
Validation loss: 2.1112668693706556

Epoch: 6| Step: 3
Training loss: 2.7477777004241943
Validation loss: 2.105168224662863

Epoch: 6| Step: 4
Training loss: 2.286573886871338
Validation loss: 2.1225887857457644

Epoch: 6| Step: 5
Training loss: 2.666919231414795
Validation loss: 2.134261518396357

Epoch: 6| Step: 6
Training loss: 2.457606554031372
Validation loss: 2.1349998802267094

Epoch: 6| Step: 7
Training loss: 2.3248605728149414
Validation loss: 2.135859677868505

Epoch: 6| Step: 8
Training loss: 2.7235827445983887
Validation loss: 2.1357752046277447

Epoch: 6| Step: 9
Training loss: 3.0034360885620117
Validation loss: 2.133535450504672

Epoch: 6| Step: 10
Training loss: 2.162707567214966
Validation loss: 2.1338603188914638

Epoch: 6| Step: 11
Training loss: 2.2005467414855957
Validation loss: 2.122145055442728

Epoch: 6| Step: 12
Training loss: 2.4612231254577637
Validation loss: 2.1058043536319526

Epoch: 6| Step: 13
Training loss: 1.106191873550415
Validation loss: 2.1029153305997133

Epoch: 133| Step: 0
Training loss: 2.6789302825927734
Validation loss: 2.093955329669419

Epoch: 6| Step: 1
Training loss: 2.303800582885742
Validation loss: 2.0927684486553235

Epoch: 6| Step: 2
Training loss: 1.5593533515930176
Validation loss: 2.0911182280509704

Epoch: 6| Step: 3
Training loss: 2.118452548980713
Validation loss: 2.096058068736907

Epoch: 6| Step: 4
Training loss: 2.17303204536438
Validation loss: 2.103751664520592

Epoch: 6| Step: 5
Training loss: 2.6080482006073
Validation loss: 2.117431835461688

Epoch: 6| Step: 6
Training loss: 2.202522039413452
Validation loss: 2.1181533362275813

Epoch: 6| Step: 7
Training loss: 2.816053867340088
Validation loss: 2.121945450382848

Epoch: 6| Step: 8
Training loss: 2.589477300643921
Validation loss: 2.126003988327519

Epoch: 6| Step: 9
Training loss: 2.8605899810791016
Validation loss: 2.1260518271435975

Epoch: 6| Step: 10
Training loss: 2.4144692420959473
Validation loss: 2.1112418431107716

Epoch: 6| Step: 11
Training loss: 2.6020610332489014
Validation loss: 2.1198849806221585

Epoch: 6| Step: 12
Training loss: 2.5827624797821045
Validation loss: 2.1170375218955417

Epoch: 6| Step: 13
Training loss: 1.9935351610183716
Validation loss: 2.1189943308471353

Epoch: 134| Step: 0
Training loss: 1.9423460960388184
Validation loss: 2.115192251820718

Epoch: 6| Step: 1
Training loss: 2.822031259536743
Validation loss: 2.1108604631116314

Epoch: 6| Step: 2
Training loss: 3.032055616378784
Validation loss: 2.1108255206897693

Epoch: 6| Step: 3
Training loss: 3.2810745239257812
Validation loss: 2.1151936566957863

Epoch: 6| Step: 4
Training loss: 2.0936594009399414
Validation loss: 2.1165793044592744

Epoch: 6| Step: 5
Training loss: 1.7985926866531372
Validation loss: 2.1078630032077914

Epoch: 6| Step: 6
Training loss: 2.5143015384674072
Validation loss: 2.1089802326694613

Epoch: 6| Step: 7
Training loss: 2.4965696334838867
Validation loss: 2.097460633964949

Epoch: 6| Step: 8
Training loss: 2.547697067260742
Validation loss: 2.0913446564828195

Epoch: 6| Step: 9
Training loss: 2.350133180618286
Validation loss: 2.093945857017271

Epoch: 6| Step: 10
Training loss: 2.3451945781707764
Validation loss: 2.0946477869505524

Epoch: 6| Step: 11
Training loss: 1.6000938415527344
Validation loss: 2.0821956793467202

Epoch: 6| Step: 12
Training loss: 2.6224398612976074
Validation loss: 2.098175944820527

Epoch: 6| Step: 13
Training loss: 2.071016550064087
Validation loss: 2.0985098205586916

Epoch: 135| Step: 0
Training loss: 2.591952085494995
Validation loss: 2.122187118376455

Epoch: 6| Step: 1
Training loss: 2.3470630645751953
Validation loss: 2.134007533391317

Epoch: 6| Step: 2
Training loss: 2.074946880340576
Validation loss: 2.153985213207942

Epoch: 6| Step: 3
Training loss: 2.2491941452026367
Validation loss: 2.176188829124615

Epoch: 6| Step: 4
Training loss: 2.780656099319458
Validation loss: 2.257490360608665

Epoch: 6| Step: 5
Training loss: 1.3089616298675537
Validation loss: 2.302884719705069

Epoch: 6| Step: 6
Training loss: 3.2177863121032715
Validation loss: 2.3040935813739734

Epoch: 6| Step: 7
Training loss: 2.359004259109497
Validation loss: 2.340437742971605

Epoch: 6| Step: 8
Training loss: 2.5545663833618164
Validation loss: 2.3188813373606694

Epoch: 6| Step: 9
Training loss: 2.830340623855591
Validation loss: 2.3037383120547057

Epoch: 6| Step: 10
Training loss: 2.780749559402466
Validation loss: 2.2498658857037945

Epoch: 6| Step: 11
Training loss: 2.6665306091308594
Validation loss: 2.1726191146399385

Epoch: 6| Step: 12
Training loss: 2.3899192810058594
Validation loss: 2.1224714068956274

Epoch: 6| Step: 13
Training loss: 2.019213914871216
Validation loss: 2.1046372382871565

Epoch: 136| Step: 0
Training loss: 2.1897432804107666
Validation loss: 2.10079748271614

Epoch: 6| Step: 1
Training loss: 2.115009069442749
Validation loss: 2.097330795821323

Epoch: 6| Step: 2
Training loss: 1.5431740283966064
Validation loss: 2.0982133137282504

Epoch: 6| Step: 3
Training loss: 2.6147589683532715
Validation loss: 2.1012526250654653

Epoch: 6| Step: 4
Training loss: 3.4155526161193848
Validation loss: 2.10567210566613

Epoch: 6| Step: 5
Training loss: 2.3649251461029053
Validation loss: 2.107176834537137

Epoch: 6| Step: 6
Training loss: 2.6145782470703125
Validation loss: 2.104426504463278

Epoch: 6| Step: 7
Training loss: 2.679823875427246
Validation loss: 2.100403401159471

Epoch: 6| Step: 8
Training loss: 2.3209152221679688
Validation loss: 2.08675709847481

Epoch: 6| Step: 9
Training loss: 2.570220470428467
Validation loss: 2.0977431035810903

Epoch: 6| Step: 10
Training loss: 2.4914767742156982
Validation loss: 2.097994860782418

Epoch: 6| Step: 11
Training loss: 2.0904786586761475
Validation loss: 2.0994582688936623

Epoch: 6| Step: 12
Training loss: 2.860067367553711
Validation loss: 2.1050938431934645

Epoch: 6| Step: 13
Training loss: 2.5087709426879883
Validation loss: 2.1220271228462138

Epoch: 137| Step: 0
Training loss: 1.9802727699279785
Validation loss: 2.1590473562158565

Epoch: 6| Step: 1
Training loss: 2.8341145515441895
Validation loss: 2.161624050909473

Epoch: 6| Step: 2
Training loss: 2.115919589996338
Validation loss: 2.1986993435890443

Epoch: 6| Step: 3
Training loss: 2.337524890899658
Validation loss: 2.2119860367108415

Epoch: 6| Step: 4
Training loss: 2.4519901275634766
Validation loss: 2.2402947589915287

Epoch: 6| Step: 5
Training loss: 2.3183956146240234
Validation loss: 2.2385984543831117

Epoch: 6| Step: 6
Training loss: 1.9641014337539673
Validation loss: 2.243851000262845

Epoch: 6| Step: 7
Training loss: 3.3253297805786133
Validation loss: 2.252096232547555

Epoch: 6| Step: 8
Training loss: 2.6917905807495117
Validation loss: 2.219300736663162

Epoch: 6| Step: 9
Training loss: 3.331446647644043
Validation loss: 2.233706940886795

Epoch: 6| Step: 10
Training loss: 2.7245287895202637
Validation loss: 2.226742813664098

Epoch: 6| Step: 11
Training loss: 1.9752919673919678
Validation loss: 2.198870110255416

Epoch: 6| Step: 12
Training loss: 2.0765347480773926
Validation loss: 2.1765837771918184

Epoch: 6| Step: 13
Training loss: 1.5232423543930054
Validation loss: 2.132267121345766

Epoch: 138| Step: 0
Training loss: 2.564556121826172
Validation loss: 2.114918032000142

Epoch: 6| Step: 1
Training loss: 2.8321938514709473
Validation loss: 2.11145128485977

Epoch: 6| Step: 2
Training loss: 2.3969225883483887
Validation loss: 2.1023397740497383

Epoch: 6| Step: 3
Training loss: 2.6551198959350586
Validation loss: 2.0909430237226587

Epoch: 6| Step: 4
Training loss: 3.3562774658203125
Validation loss: 2.0953607225930817

Epoch: 6| Step: 5
Training loss: 2.3649744987487793
Validation loss: 2.08967282695155

Epoch: 6| Step: 6
Training loss: 2.0598912239074707
Validation loss: 2.094344481345146

Epoch: 6| Step: 7
Training loss: 1.5594091415405273
Validation loss: 2.101450229203829

Epoch: 6| Step: 8
Training loss: 2.3749282360076904
Validation loss: 2.099857727686564

Epoch: 6| Step: 9
Training loss: 2.0246658325195312
Validation loss: 2.1002395435046126

Epoch: 6| Step: 10
Training loss: 2.530555009841919
Validation loss: 2.0963763767673123

Epoch: 6| Step: 11
Training loss: 2.167041063308716
Validation loss: 2.096541973852342

Epoch: 6| Step: 12
Training loss: 2.4709527492523193
Validation loss: 2.0910712031907934

Epoch: 6| Step: 13
Training loss: 2.437380313873291
Validation loss: 2.092123546907979

Epoch: 139| Step: 0
Training loss: 3.227924346923828
Validation loss: 2.092827143207673

Epoch: 6| Step: 1
Training loss: 3.5225353240966797
Validation loss: 2.108407833242929

Epoch: 6| Step: 2
Training loss: 2.036855936050415
Validation loss: 2.108276988870354

Epoch: 6| Step: 3
Training loss: 2.315830707550049
Validation loss: 2.1126129037590435

Epoch: 6| Step: 4
Training loss: 2.286419153213501
Validation loss: 2.1228132273561213

Epoch: 6| Step: 5
Training loss: 1.762732744216919
Validation loss: 2.1381956531155493

Epoch: 6| Step: 6
Training loss: 2.205840826034546
Validation loss: 2.1621270948840725

Epoch: 6| Step: 7
Training loss: 2.250122308731079
Validation loss: 2.1856614928091727

Epoch: 6| Step: 8
Training loss: 2.190075159072876
Validation loss: 2.2145604561733943

Epoch: 6| Step: 9
Training loss: 2.516145706176758
Validation loss: 2.2414008545619186

Epoch: 6| Step: 10
Training loss: 2.3268074989318848
Validation loss: 2.2487522581572175

Epoch: 6| Step: 11
Training loss: 2.551703929901123
Validation loss: 2.2612703948892574

Epoch: 6| Step: 12
Training loss: 2.472754716873169
Validation loss: 2.2203915965172554

Epoch: 6| Step: 13
Training loss: 2.118675708770752
Validation loss: 2.186736096617996

Epoch: 140| Step: 0
Training loss: 1.6485669612884521
Validation loss: 2.1494623204713226

Epoch: 6| Step: 1
Training loss: 2.459171772003174
Validation loss: 2.1124841436263053

Epoch: 6| Step: 2
Training loss: 2.6970479488372803
Validation loss: 2.0912013130803264

Epoch: 6| Step: 3
Training loss: 2.5476484298706055
Validation loss: 2.0961398360549763

Epoch: 6| Step: 4
Training loss: 2.419865608215332
Validation loss: 2.0904242992401123

Epoch: 6| Step: 5
Training loss: 2.513676404953003
Validation loss: 2.0970165485976846

Epoch: 6| Step: 6
Training loss: 2.529125690460205
Validation loss: 2.0917993745496197

Epoch: 6| Step: 7
Training loss: 1.7617197036743164
Validation loss: 2.1017796583073114

Epoch: 6| Step: 8
Training loss: 2.5558371543884277
Validation loss: 2.101864831421965

Epoch: 6| Step: 9
Training loss: 2.8857243061065674
Validation loss: 2.101460054356565

Epoch: 6| Step: 10
Training loss: 2.4753310680389404
Validation loss: 2.09982660765289

Epoch: 6| Step: 11
Training loss: 1.8361468315124512
Validation loss: 2.100736382187054

Epoch: 6| Step: 12
Training loss: 3.1541523933410645
Validation loss: 2.1028588805147397

Epoch: 6| Step: 13
Training loss: 2.3749091625213623
Validation loss: 2.109563012276926

Epoch: 141| Step: 0
Training loss: 1.320094108581543
Validation loss: 2.106301034650495

Epoch: 6| Step: 1
Training loss: 1.8776226043701172
Validation loss: 2.10291705336622

Epoch: 6| Step: 2
Training loss: 2.730482339859009
Validation loss: 2.102600855212058

Epoch: 6| Step: 3
Training loss: 2.111410140991211
Validation loss: 2.0999765831937074

Epoch: 6| Step: 4
Training loss: 2.0865583419799805
Validation loss: 2.106457289829049

Epoch: 6| Step: 5
Training loss: 2.3797850608825684
Validation loss: 2.10017002654332

Epoch: 6| Step: 6
Training loss: 3.1774861812591553
Validation loss: 2.102568171357596

Epoch: 6| Step: 7
Training loss: 2.4360361099243164
Validation loss: 2.1010629900040163

Epoch: 6| Step: 8
Training loss: 2.785172462463379
Validation loss: 2.1108876889751804

Epoch: 6| Step: 9
Training loss: 2.8844199180603027
Validation loss: 2.108662320721534

Epoch: 6| Step: 10
Training loss: 2.2344741821289062
Validation loss: 2.1163907615087365

Epoch: 6| Step: 11
Training loss: 2.2503662109375
Validation loss: 2.1278265099371634

Epoch: 6| Step: 12
Training loss: 2.536668300628662
Validation loss: 2.132563429494058

Epoch: 6| Step: 13
Training loss: 2.844627618789673
Validation loss: 2.132652008405296

Epoch: 142| Step: 0
Training loss: 2.759673595428467
Validation loss: 2.1268631437773347

Epoch: 6| Step: 1
Training loss: 2.2133853435516357
Validation loss: 2.1339423220644713

Epoch: 6| Step: 2
Training loss: 2.573481559753418
Validation loss: 2.154199666874383

Epoch: 6| Step: 3
Training loss: 2.709745168685913
Validation loss: 2.1699968179066977

Epoch: 6| Step: 4
Training loss: 2.4755544662475586
Validation loss: 2.174677974434309

Epoch: 6| Step: 5
Training loss: 2.0328102111816406
Validation loss: 2.1691129899794057

Epoch: 6| Step: 6
Training loss: 2.1448636054992676
Validation loss: 2.1620626141948085

Epoch: 6| Step: 7
Training loss: 2.711679697036743
Validation loss: 2.1838597174613708

Epoch: 6| Step: 8
Training loss: 2.064272880554199
Validation loss: 2.182201571361993

Epoch: 6| Step: 9
Training loss: 2.0285255908966064
Validation loss: 2.1689793448294363

Epoch: 6| Step: 10
Training loss: 3.3482205867767334
Validation loss: 2.1477699523331015

Epoch: 6| Step: 11
Training loss: 2.18463397026062
Validation loss: 2.110254649193056

Epoch: 6| Step: 12
Training loss: 2.314962148666382
Validation loss: 2.1054002367040163

Epoch: 6| Step: 13
Training loss: 1.5437978506088257
Validation loss: 2.0908431545380624

Epoch: 143| Step: 0
Training loss: 2.1701667308807373
Validation loss: 2.0750609328669887

Epoch: 6| Step: 1
Training loss: 2.8064563274383545
Validation loss: 2.07699744291203

Epoch: 6| Step: 2
Training loss: 3.0883255004882812
Validation loss: 2.072173103209465

Epoch: 6| Step: 3
Training loss: 2.5600032806396484
Validation loss: 2.0821198391658005

Epoch: 6| Step: 4
Training loss: 2.1006386280059814
Validation loss: 2.08961998006349

Epoch: 6| Step: 5
Training loss: 2.586212158203125
Validation loss: 2.0880973518535657

Epoch: 6| Step: 6
Training loss: 2.2433652877807617
Validation loss: 2.0835244629972722

Epoch: 6| Step: 7
Training loss: 2.2704577445983887
Validation loss: 2.082020531418503

Epoch: 6| Step: 8
Training loss: 2.234316349029541
Validation loss: 2.083774620486844

Epoch: 6| Step: 9
Training loss: 2.2465407848358154
Validation loss: 2.0768137542150353

Epoch: 6| Step: 10
Training loss: 2.869016408920288
Validation loss: 2.073248447910432

Epoch: 6| Step: 11
Training loss: 2.123042345046997
Validation loss: 2.0730775351165445

Epoch: 6| Step: 12
Training loss: 2.42927885055542
Validation loss: 2.080291368628061

Epoch: 6| Step: 13
Training loss: 2.1823108196258545
Validation loss: 2.0936111327140563

Epoch: 144| Step: 0
Training loss: 2.739447593688965
Validation loss: 2.104754901701404

Epoch: 6| Step: 1
Training loss: 2.239445447921753
Validation loss: 2.1159108172180834

Epoch: 6| Step: 2
Training loss: 1.9199483394622803
Validation loss: 2.1253609195832284

Epoch: 6| Step: 3
Training loss: 2.434150457382202
Validation loss: 2.1320074296766713

Epoch: 6| Step: 4
Training loss: 2.3629677295684814
Validation loss: 2.140577677757509

Epoch: 6| Step: 5
Training loss: 2.6161084175109863
Validation loss: 2.134931045193826

Epoch: 6| Step: 6
Training loss: 2.6802544593811035
Validation loss: 2.1628638454662856

Epoch: 6| Step: 7
Training loss: 2.5286223888397217
Validation loss: 2.1867097680286696

Epoch: 6| Step: 8
Training loss: 2.0004823207855225
Validation loss: 2.190159954050536

Epoch: 6| Step: 9
Training loss: 1.8019542694091797
Validation loss: 2.183161304843041

Epoch: 6| Step: 10
Training loss: 2.643994092941284
Validation loss: 2.1705650052716656

Epoch: 6| Step: 11
Training loss: 2.2767574787139893
Validation loss: 2.158133893884638

Epoch: 6| Step: 12
Training loss: 2.749629020690918
Validation loss: 2.121139718640235

Epoch: 6| Step: 13
Training loss: 2.6173577308654785
Validation loss: 2.111228842889109

Epoch: 145| Step: 0
Training loss: 2.6364359855651855
Validation loss: 2.0896728115697063

Epoch: 6| Step: 1
Training loss: 1.6824365854263306
Validation loss: 2.086696219700639

Epoch: 6| Step: 2
Training loss: 2.3468077182769775
Validation loss: 2.0893579811178227

Epoch: 6| Step: 3
Training loss: 2.6414027214050293
Validation loss: 2.081484252406705

Epoch: 6| Step: 4
Training loss: 2.1996209621429443
Validation loss: 2.0747736474519134

Epoch: 6| Step: 5
Training loss: 2.4981741905212402
Validation loss: 2.086551261204545

Epoch: 6| Step: 6
Training loss: 2.5895369052886963
Validation loss: 2.084519342709613

Epoch: 6| Step: 7
Training loss: 2.6594667434692383
Validation loss: 2.0767118879543838

Epoch: 6| Step: 8
Training loss: 2.070725679397583
Validation loss: 2.0789946945764686

Epoch: 6| Step: 9
Training loss: 1.8067371845245361
Validation loss: 2.0740350446393414

Epoch: 6| Step: 10
Training loss: 2.950563907623291
Validation loss: 2.0569845502094557

Epoch: 6| Step: 11
Training loss: 2.3631768226623535
Validation loss: 2.0625811917807466

Epoch: 6| Step: 12
Training loss: 2.1715760231018066
Validation loss: 2.054434904488184

Epoch: 6| Step: 13
Training loss: 3.2216856479644775
Validation loss: 2.068090731097806

Epoch: 146| Step: 0
Training loss: 2.0548312664031982
Validation loss: 2.075833423163301

Epoch: 6| Step: 1
Training loss: 2.8562328815460205
Validation loss: 2.078565630861508

Epoch: 6| Step: 2
Training loss: 2.2714037895202637
Validation loss: 2.088029484595022

Epoch: 6| Step: 3
Training loss: 2.5824167728424072
Validation loss: 2.1024360502919843

Epoch: 6| Step: 4
Training loss: 2.8904690742492676
Validation loss: 2.1120611659942137

Epoch: 6| Step: 5
Training loss: 2.2098453044891357
Validation loss: 2.1017048307644424

Epoch: 6| Step: 6
Training loss: 2.749396800994873
Validation loss: 2.0945308862193937

Epoch: 6| Step: 7
Training loss: 2.294822931289673
Validation loss: 2.0656903866798646

Epoch: 6| Step: 8
Training loss: 2.5310957431793213
Validation loss: 2.065989348196214

Epoch: 6| Step: 9
Training loss: 2.0518131256103516
Validation loss: 2.0697868447149954

Epoch: 6| Step: 10
Training loss: 2.069953203201294
Validation loss: 2.067058300459257

Epoch: 6| Step: 11
Training loss: 2.7433176040649414
Validation loss: 2.0732455702238184

Epoch: 6| Step: 12
Training loss: 1.7135273218154907
Validation loss: 2.0682954685662382

Epoch: 6| Step: 13
Training loss: 2.0164363384246826
Validation loss: 2.083665047922442

Epoch: 147| Step: 0
Training loss: 2.4549617767333984
Validation loss: 2.093822620248282

Epoch: 6| Step: 1
Training loss: 1.6933419704437256
Validation loss: 2.0975652497301818

Epoch: 6| Step: 2
Training loss: 3.017397880554199
Validation loss: 2.093060367850847

Epoch: 6| Step: 3
Training loss: 1.7459616661071777
Validation loss: 2.0960489229489396

Epoch: 6| Step: 4
Training loss: 2.5856852531433105
Validation loss: 2.087987958744008

Epoch: 6| Step: 5
Training loss: 1.9018378257751465
Validation loss: 2.096153800205518

Epoch: 6| Step: 6
Training loss: 2.531759262084961
Validation loss: 2.0987955806075886

Epoch: 6| Step: 7
Training loss: 1.7264766693115234
Validation loss: 2.103663142009448

Epoch: 6| Step: 8
Training loss: 2.847321033477783
Validation loss: 2.109200544254754

Epoch: 6| Step: 9
Training loss: 2.7994232177734375
Validation loss: 2.1379447034610215

Epoch: 6| Step: 10
Training loss: 2.5464038848876953
Validation loss: 2.149707526289007

Epoch: 6| Step: 11
Training loss: 2.1524674892425537
Validation loss: 2.138772902950164

Epoch: 6| Step: 12
Training loss: 2.2978177070617676
Validation loss: 2.1423310054245817

Epoch: 6| Step: 13
Training loss: 3.2357699871063232
Validation loss: 2.1187223131938646

Epoch: 148| Step: 0
Training loss: 2.325258731842041
Validation loss: 2.0840350556117233

Epoch: 6| Step: 1
Training loss: 2.563037872314453
Validation loss: 2.081969109914636

Epoch: 6| Step: 2
Training loss: 2.640443801879883
Validation loss: 2.0724140239018265

Epoch: 6| Step: 3
Training loss: 2.7275798320770264
Validation loss: 2.052888577984225

Epoch: 6| Step: 4
Training loss: 2.241872549057007
Validation loss: 2.061771990150534

Epoch: 6| Step: 5
Training loss: 1.8295505046844482
Validation loss: 2.0664826208545315

Epoch: 6| Step: 6
Training loss: 2.624474287033081
Validation loss: 2.0715862051133187

Epoch: 6| Step: 7
Training loss: 2.169576644897461
Validation loss: 2.0753790255515807

Epoch: 6| Step: 8
Training loss: 2.6896371841430664
Validation loss: 2.0815893193726898

Epoch: 6| Step: 9
Training loss: 1.6568074226379395
Validation loss: 2.087440954741611

Epoch: 6| Step: 10
Training loss: 2.484187602996826
Validation loss: 2.0916600099173923

Epoch: 6| Step: 11
Training loss: 2.347377061843872
Validation loss: 2.0832759526468094

Epoch: 6| Step: 12
Training loss: 2.4277501106262207
Validation loss: 2.0797025465196177

Epoch: 6| Step: 13
Training loss: 2.4610915184020996
Validation loss: 2.087445612876646

Epoch: 149| Step: 0
Training loss: 2.281651496887207
Validation loss: 2.074267841154529

Epoch: 6| Step: 1
Training loss: 1.6963038444519043
Validation loss: 2.0839755868399017

Epoch: 6| Step: 2
Training loss: 3.0908398628234863
Validation loss: 2.1096943860412924

Epoch: 6| Step: 3
Training loss: 2.648008346557617
Validation loss: 2.108025940515662

Epoch: 6| Step: 4
Training loss: 2.1431753635406494
Validation loss: 2.1185945131445445

Epoch: 6| Step: 5
Training loss: 2.129617691040039
Validation loss: 2.1190027318974978

Epoch: 6| Step: 6
Training loss: 2.9050402641296387
Validation loss: 2.137012771380845

Epoch: 6| Step: 7
Training loss: 2.441208839416504
Validation loss: 2.1465226886092976

Epoch: 6| Step: 8
Training loss: 2.3996994495391846
Validation loss: 2.1338137888139292

Epoch: 6| Step: 9
Training loss: 2.0091552734375
Validation loss: 2.124056645618972

Epoch: 6| Step: 10
Training loss: 1.9736864566802979
Validation loss: 2.143009611355361

Epoch: 6| Step: 11
Training loss: 2.3327441215515137
Validation loss: 2.151452731060725

Epoch: 6| Step: 12
Training loss: 2.4998738765716553
Validation loss: 2.160168932330224

Epoch: 6| Step: 13
Training loss: 2.3925466537475586
Validation loss: 2.151600217306486

Epoch: 150| Step: 0
Training loss: 1.6953802108764648
Validation loss: 2.110405309225923

Epoch: 6| Step: 1
Training loss: 2.258577346801758
Validation loss: 2.104152056478685

Epoch: 6| Step: 2
Training loss: 1.7947494983673096
Validation loss: 2.094517715515629

Epoch: 6| Step: 3
Training loss: 2.4795124530792236
Validation loss: 2.0832274677932903

Epoch: 6| Step: 4
Training loss: 1.9521087408065796
Validation loss: 2.0627005023341023

Epoch: 6| Step: 5
Training loss: 3.184708833694458
Validation loss: 2.066810764292235

Epoch: 6| Step: 6
Training loss: 2.089707374572754
Validation loss: 2.0799538345747095

Epoch: 6| Step: 7
Training loss: 2.0537352561950684
Validation loss: 2.062849795946511

Epoch: 6| Step: 8
Training loss: 2.7101409435272217
Validation loss: 2.063025184856948

Epoch: 6| Step: 9
Training loss: 3.238055467605591
Validation loss: 2.0554564358085714

Epoch: 6| Step: 10
Training loss: 2.475142002105713
Validation loss: 2.0629249529172013

Epoch: 6| Step: 11
Training loss: 2.129564046859741
Validation loss: 2.0520679591804423

Epoch: 6| Step: 12
Training loss: 2.7688417434692383
Validation loss: 2.046231363409309

Epoch: 6| Step: 13
Training loss: 1.9857444763183594
Validation loss: 2.0531578551056566

Epoch: 151| Step: 0
Training loss: 1.3659207820892334
Validation loss: 2.0595660824929514

Epoch: 6| Step: 1
Training loss: 2.1445343494415283
Validation loss: 2.094190051478724

Epoch: 6| Step: 2
Training loss: 2.7020723819732666
Validation loss: 2.1314595335273334

Epoch: 6| Step: 3
Training loss: 2.5393786430358887
Validation loss: 2.153002862007387

Epoch: 6| Step: 4
Training loss: 2.7203612327575684
Validation loss: 2.159491494137754

Epoch: 6| Step: 5
Training loss: 2.3182904720306396
Validation loss: 2.1542507563867876

Epoch: 6| Step: 6
Training loss: 2.3053994178771973
Validation loss: 2.1576359707822084

Epoch: 6| Step: 7
Training loss: 2.3962559700012207
Validation loss: 2.1456722174921343

Epoch: 6| Step: 8
Training loss: 2.651951313018799
Validation loss: 2.1306286537519066

Epoch: 6| Step: 9
Training loss: 2.7534565925598145
Validation loss: 2.1273283881525837

Epoch: 6| Step: 10
Training loss: 2.1196060180664062
Validation loss: 2.102577572227806

Epoch: 6| Step: 11
Training loss: 2.4734113216400146
Validation loss: 2.0803010361168974

Epoch: 6| Step: 12
Training loss: 1.9694947004318237
Validation loss: 2.062388058631651

Epoch: 6| Step: 13
Training loss: 2.51139235496521
Validation loss: 2.0699878533681235

Epoch: 152| Step: 0
Training loss: 2.624297618865967
Validation loss: 2.0564496824818272

Epoch: 6| Step: 1
Training loss: 2.2262516021728516
Validation loss: 2.0588770771539338

Epoch: 6| Step: 2
Training loss: 1.9204888343811035
Validation loss: 2.0510864321903517

Epoch: 6| Step: 3
Training loss: 1.9276108741760254
Validation loss: 2.055506803656137

Epoch: 6| Step: 4
Training loss: 2.173614263534546
Validation loss: 2.0593552999599005

Epoch: 6| Step: 5
Training loss: 3.337144374847412
Validation loss: 2.0562124162591915

Epoch: 6| Step: 6
Training loss: 2.128537178039551
Validation loss: 2.0535801354274956

Epoch: 6| Step: 7
Training loss: 2.7430365085601807
Validation loss: 2.070362837083878

Epoch: 6| Step: 8
Training loss: 2.214296817779541
Validation loss: 2.0606985604891213

Epoch: 6| Step: 9
Training loss: 2.1674747467041016
Validation loss: 2.089037174819618

Epoch: 6| Step: 10
Training loss: 2.0424652099609375
Validation loss: 2.1120494591292513

Epoch: 6| Step: 11
Training loss: 2.729673385620117
Validation loss: 2.1329360956786783

Epoch: 6| Step: 12
Training loss: 2.582914352416992
Validation loss: 2.1208859259082424

Epoch: 6| Step: 13
Training loss: 1.9640295505523682
Validation loss: 2.124093358234693

Epoch: 153| Step: 0
Training loss: 2.786546468734741
Validation loss: 2.112901943986134

Epoch: 6| Step: 1
Training loss: 2.015617609024048
Validation loss: 2.104685100176001

Epoch: 6| Step: 2
Training loss: 2.5620718002319336
Validation loss: 2.082731085438882

Epoch: 6| Step: 3
Training loss: 1.9719576835632324
Validation loss: 2.0731921080620057

Epoch: 6| Step: 4
Training loss: 2.1087806224823
Validation loss: 2.066024321381764

Epoch: 6| Step: 5
Training loss: 2.2334485054016113
Validation loss: 2.049917769688432

Epoch: 6| Step: 6
Training loss: 2.1990559101104736
Validation loss: 2.036191330161146

Epoch: 6| Step: 7
Training loss: 2.6888670921325684
Validation loss: 2.0468619485055246

Epoch: 6| Step: 8
Training loss: 2.4552831649780273
Validation loss: 2.02988842738572

Epoch: 6| Step: 9
Training loss: 2.087649345397949
Validation loss: 2.024467429807109

Epoch: 6| Step: 10
Training loss: 2.3331358432769775
Validation loss: 2.023769268425562

Epoch: 6| Step: 11
Training loss: 2.13331937789917
Validation loss: 2.0302996276527323

Epoch: 6| Step: 12
Training loss: 2.8949697017669678
Validation loss: 2.024017906958057

Epoch: 6| Step: 13
Training loss: 2.366641044616699
Validation loss: 2.034729047488141

Epoch: 154| Step: 0
Training loss: 2.821859836578369
Validation loss: 2.05351504459176

Epoch: 6| Step: 1
Training loss: 2.332033634185791
Validation loss: 2.056578961751794

Epoch: 6| Step: 2
Training loss: 2.8134374618530273
Validation loss: 2.0803887203175533

Epoch: 6| Step: 3
Training loss: 2.19738507270813
Validation loss: 2.1120441062476045

Epoch: 6| Step: 4
Training loss: 1.9163157939910889
Validation loss: 2.13961039563661

Epoch: 6| Step: 5
Training loss: 2.81870698928833
Validation loss: 2.175019535967099

Epoch: 6| Step: 6
Training loss: 2.3335695266723633
Validation loss: 2.16649382088774

Epoch: 6| Step: 7
Training loss: 2.3776402473449707
Validation loss: 2.1223663745387906

Epoch: 6| Step: 8
Training loss: 1.9554327726364136
Validation loss: 2.081229809791811

Epoch: 6| Step: 9
Training loss: 2.680119276046753
Validation loss: 2.0552275514089935

Epoch: 6| Step: 10
Training loss: 2.422891139984131
Validation loss: 2.046448958817349

Epoch: 6| Step: 11
Training loss: 1.821088433265686
Validation loss: 2.0451128893001105

Epoch: 6| Step: 12
Training loss: 2.3161933422088623
Validation loss: 2.0403757915701917

Epoch: 6| Step: 13
Training loss: 2.2141897678375244
Validation loss: 2.0413686818973993

Epoch: 155| Step: 0
Training loss: 2.2762880325317383
Validation loss: 2.0389170108302945

Epoch: 6| Step: 1
Training loss: 2.748721122741699
Validation loss: 2.0565564888779835

Epoch: 6| Step: 2
Training loss: 2.4236061573028564
Validation loss: 2.06309942019883

Epoch: 6| Step: 3
Training loss: 2.850269079208374
Validation loss: 2.091766790677142

Epoch: 6| Step: 4
Training loss: 2.795816421508789
Validation loss: 2.13401638051515

Epoch: 6| Step: 5
Training loss: 1.69700026512146
Validation loss: 2.1404671463915097

Epoch: 6| Step: 6
Training loss: 2.083709716796875
Validation loss: 2.1359350988941808

Epoch: 6| Step: 7
Training loss: 2.3605170249938965
Validation loss: 2.1290767218476985

Epoch: 6| Step: 8
Training loss: 2.2011165618896484
Validation loss: 2.1197255273019113

Epoch: 6| Step: 9
Training loss: 2.372072696685791
Validation loss: 2.106212192966092

Epoch: 6| Step: 10
Training loss: 2.5209081172943115
Validation loss: 2.0943721930185952

Epoch: 6| Step: 11
Training loss: 1.3446462154388428
Validation loss: 2.0519829873115785

Epoch: 6| Step: 12
Training loss: 2.4075841903686523
Validation loss: 2.054069854879892

Epoch: 6| Step: 13
Training loss: 2.8846096992492676
Validation loss: 2.0528162448636946

Epoch: 156| Step: 0
Training loss: 3.112457275390625
Validation loss: 2.069547640380039

Epoch: 6| Step: 1
Training loss: 2.7424659729003906
Validation loss: 2.069454575097689

Epoch: 6| Step: 2
Training loss: 2.7105658054351807
Validation loss: 2.081591445912597

Epoch: 6| Step: 3
Training loss: 1.986974835395813
Validation loss: 2.095068980288762

Epoch: 6| Step: 4
Training loss: 1.9747939109802246
Validation loss: 2.104149426183393

Epoch: 6| Step: 5
Training loss: 2.781517267227173
Validation loss: 2.092346401624782

Epoch: 6| Step: 6
Training loss: 2.6108055114746094
Validation loss: 2.0690810449661745

Epoch: 6| Step: 7
Training loss: 1.9026916027069092
Validation loss: 2.068483127060757

Epoch: 6| Step: 8
Training loss: 2.0847954750061035
Validation loss: 2.0666083507640387

Epoch: 6| Step: 9
Training loss: 1.5231707096099854
Validation loss: 2.0509820574073383

Epoch: 6| Step: 10
Training loss: 2.3072783946990967
Validation loss: 2.0514783679798083

Epoch: 6| Step: 11
Training loss: 2.1688389778137207
Validation loss: 2.0416486263275146

Epoch: 6| Step: 12
Training loss: 2.292050838470459
Validation loss: 2.0452170641191545

Epoch: 6| Step: 13
Training loss: 2.175827980041504
Validation loss: 2.0630739735018824

Epoch: 157| Step: 0
Training loss: 2.5221049785614014
Validation loss: 2.056080504130292

Epoch: 6| Step: 1
Training loss: 2.429703950881958
Validation loss: 2.0637120226378083

Epoch: 6| Step: 2
Training loss: 2.487764835357666
Validation loss: 2.0499427472391436

Epoch: 6| Step: 3
Training loss: 2.07879900932312
Validation loss: 2.0386318724642516

Epoch: 6| Step: 4
Training loss: 2.599038600921631
Validation loss: 2.0349763695911696

Epoch: 6| Step: 5
Training loss: 2.1393728256225586
Validation loss: 2.0346368333344818

Epoch: 6| Step: 6
Training loss: 2.651731252670288
Validation loss: 2.047931191741779

Epoch: 6| Step: 7
Training loss: 2.084202289581299
Validation loss: 2.04175316902899

Epoch: 6| Step: 8
Training loss: 2.3561112880706787
Validation loss: 2.0456252495447793

Epoch: 6| Step: 9
Training loss: 1.6798925399780273
Validation loss: 2.0639908929024973

Epoch: 6| Step: 10
Training loss: 2.3562488555908203
Validation loss: 2.0867691732222036

Epoch: 6| Step: 11
Training loss: 2.581773281097412
Validation loss: 2.0902515611340924

Epoch: 6| Step: 12
Training loss: 1.8278446197509766
Validation loss: 2.1311286059758996

Epoch: 6| Step: 13
Training loss: 2.5144662857055664
Validation loss: 2.1660552204296155

Epoch: 158| Step: 0
Training loss: 2.5713090896606445
Validation loss: 2.1838848924124115

Epoch: 6| Step: 1
Training loss: 2.504518508911133
Validation loss: 2.1825478666572162

Epoch: 6| Step: 2
Training loss: 2.2683520317077637
Validation loss: 2.176959422326857

Epoch: 6| Step: 3
Training loss: 2.612135171890259
Validation loss: 2.1531755847315632

Epoch: 6| Step: 4
Training loss: 2.3297972679138184
Validation loss: 2.1645279007573284

Epoch: 6| Step: 5
Training loss: 2.700631856918335
Validation loss: 2.136567284983973

Epoch: 6| Step: 6
Training loss: 2.255066156387329
Validation loss: 2.115054153626965

Epoch: 6| Step: 7
Training loss: 2.519601583480835
Validation loss: 2.0968082899688394

Epoch: 6| Step: 8
Training loss: 2.2866058349609375
Validation loss: 2.0950308974071215

Epoch: 6| Step: 9
Training loss: 2.049848794937134
Validation loss: 2.1039008171327653

Epoch: 6| Step: 10
Training loss: 2.068110942840576
Validation loss: 2.0977443520740797

Epoch: 6| Step: 11
Training loss: 1.779637098312378
Validation loss: 2.094876273985832

Epoch: 6| Step: 12
Training loss: 2.3523969650268555
Validation loss: 2.0881056875310917

Epoch: 6| Step: 13
Training loss: 2.554105043411255
Validation loss: 2.0902728752423356

Epoch: 159| Step: 0
Training loss: 2.2373008728027344
Validation loss: 2.096572232502763

Epoch: 6| Step: 1
Training loss: 3.0227150917053223
Validation loss: 2.092363912572143

Epoch: 6| Step: 2
Training loss: 2.6681485176086426
Validation loss: 2.077157126959934

Epoch: 6| Step: 3
Training loss: 2.7825560569763184
Validation loss: 2.0655375654979418

Epoch: 6| Step: 4
Training loss: 2.902876853942871
Validation loss: 2.0698268810908

Epoch: 6| Step: 5
Training loss: 2.024233341217041
Validation loss: 2.0607255722886775

Epoch: 6| Step: 6
Training loss: 1.8989934921264648
Validation loss: 2.048482087350661

Epoch: 6| Step: 7
Training loss: 1.833264946937561
Validation loss: 2.0464617744568856

Epoch: 6| Step: 8
Training loss: 2.17155122756958
Validation loss: 2.0421441037167787

Epoch: 6| Step: 9
Training loss: 2.38566517829895
Validation loss: 2.049278538714173

Epoch: 6| Step: 10
Training loss: 1.8552331924438477
Validation loss: 2.029637836640881

Epoch: 6| Step: 11
Training loss: 2.0324535369873047
Validation loss: 2.043850468051049

Epoch: 6| Step: 12
Training loss: 2.609829902648926
Validation loss: 2.0584542546221005

Epoch: 6| Step: 13
Training loss: 1.6541600227355957
Validation loss: 2.095355074892762

Epoch: 160| Step: 0
Training loss: 2.4660418033599854
Validation loss: 2.151406059982956

Epoch: 6| Step: 1
Training loss: 1.827973484992981
Validation loss: 2.1959715658618557

Epoch: 6| Step: 2
Training loss: 2.6015443801879883
Validation loss: 2.237431626166067

Epoch: 6| Step: 3
Training loss: 2.1807146072387695
Validation loss: 2.2219063415322253

Epoch: 6| Step: 4
Training loss: 2.1638541221618652
Validation loss: 2.245470235424657

Epoch: 6| Step: 5
Training loss: 1.7713102102279663
Validation loss: 2.2111765441074165

Epoch: 6| Step: 6
Training loss: 2.554877996444702
Validation loss: 2.1380233123738277

Epoch: 6| Step: 7
Training loss: 2.672595500946045
Validation loss: 2.0991113416610228

Epoch: 6| Step: 8
Training loss: 2.662543296813965
Validation loss: 2.0554815389776744

Epoch: 6| Step: 9
Training loss: 2.2705748081207275
Validation loss: 2.0484259769480717

Epoch: 6| Step: 10
Training loss: 2.338423728942871
Validation loss: 2.0245775894452165

Epoch: 6| Step: 11
Training loss: 1.8991742134094238
Validation loss: 2.028857483658739

Epoch: 6| Step: 12
Training loss: 2.1988141536712646
Validation loss: 2.0221358319764495

Epoch: 6| Step: 13
Training loss: 2.737407684326172
Validation loss: 2.0326310614103913

Epoch: 161| Step: 0
Training loss: 2.527538776397705
Validation loss: 2.030042594478976

Epoch: 6| Step: 1
Training loss: 2.6084482669830322
Validation loss: 2.0386590726913942

Epoch: 6| Step: 2
Training loss: 2.033754825592041
Validation loss: 2.040051753802966

Epoch: 6| Step: 3
Training loss: 2.0923044681549072
Validation loss: 2.041439180733055

Epoch: 6| Step: 4
Training loss: 2.961252212524414
Validation loss: 2.037336350769125

Epoch: 6| Step: 5
Training loss: 2.0716264247894287
Validation loss: 2.0316358253520024

Epoch: 6| Step: 6
Training loss: 1.8306180238723755
Validation loss: 2.041542250622985

Epoch: 6| Step: 7
Training loss: 1.6350754499435425
Validation loss: 2.0452293606214624

Epoch: 6| Step: 8
Training loss: 2.2121682167053223
Validation loss: 2.052402111791795

Epoch: 6| Step: 9
Training loss: 2.5181078910827637
Validation loss: 2.061304907644949

Epoch: 6| Step: 10
Training loss: 2.685779571533203
Validation loss: 2.0821769724610033

Epoch: 6| Step: 11
Training loss: 2.2021241188049316
Validation loss: 2.114810847466992

Epoch: 6| Step: 12
Training loss: 2.642691135406494
Validation loss: 2.148290646973477

Epoch: 6| Step: 13
Training loss: 2.2304317951202393
Validation loss: 2.1761509192887174

Epoch: 162| Step: 0
Training loss: 2.4346866607666016
Validation loss: 2.190181965469032

Epoch: 6| Step: 1
Training loss: 2.3988404273986816
Validation loss: 2.189308274176813

Epoch: 6| Step: 2
Training loss: 2.091381549835205
Validation loss: 2.168148165108055

Epoch: 6| Step: 3
Training loss: 2.3511781692504883
Validation loss: 2.1506000539307952

Epoch: 6| Step: 4
Training loss: 3.398326873779297
Validation loss: 2.1132718645116335

Epoch: 6| Step: 5
Training loss: 2.2220184803009033
Validation loss: 2.1145762512760777

Epoch: 6| Step: 6
Training loss: 2.078542947769165
Validation loss: 2.084219899228824

Epoch: 6| Step: 7
Training loss: 2.2358644008636475
Validation loss: 2.0595739503060617

Epoch: 6| Step: 8
Training loss: 2.561194896697998
Validation loss: 2.0648462887733214

Epoch: 6| Step: 9
Training loss: 2.092562437057495
Validation loss: 2.0574446339761057

Epoch: 6| Step: 10
Training loss: 2.15205979347229
Validation loss: 2.0454737037740727

Epoch: 6| Step: 11
Training loss: 2.36684513092041
Validation loss: 2.0411297390537877

Epoch: 6| Step: 12
Training loss: 1.7572256326675415
Validation loss: 2.0340255396340483

Epoch: 6| Step: 13
Training loss: 1.9382057189941406
Validation loss: 2.039587579747682

Epoch: 163| Step: 0
Training loss: 1.9270429611206055
Validation loss: 2.057558057128742

Epoch: 6| Step: 1
Training loss: 1.926398754119873
Validation loss: 2.0591175530546453

Epoch: 6| Step: 2
Training loss: 2.4150149822235107
Validation loss: 2.0558358879499536

Epoch: 6| Step: 3
Training loss: 2.6839873790740967
Validation loss: 2.096029181634226

Epoch: 6| Step: 4
Training loss: 2.6831815242767334
Validation loss: 2.1373493825235674

Epoch: 6| Step: 5
Training loss: 2.4457955360412598
Validation loss: 2.1509874713036323

Epoch: 6| Step: 6
Training loss: 1.976144552230835
Validation loss: 2.158942250795262

Epoch: 6| Step: 7
Training loss: 2.4066059589385986
Validation loss: 2.1449273760600756

Epoch: 6| Step: 8
Training loss: 1.5610735416412354
Validation loss: 2.1378748468173447

Epoch: 6| Step: 9
Training loss: 2.5268993377685547
Validation loss: 2.1161105120053856

Epoch: 6| Step: 10
Training loss: 3.0177693367004395
Validation loss: 2.096181044014551

Epoch: 6| Step: 11
Training loss: 2.161972999572754
Validation loss: 2.071996365824053

Epoch: 6| Step: 12
Training loss: 1.6846401691436768
Validation loss: 2.056385906793738

Epoch: 6| Step: 13
Training loss: 3.064427375793457
Validation loss: 2.050610798661427

Epoch: 164| Step: 0
Training loss: 1.90510892868042
Validation loss: 2.0440976799175306

Epoch: 6| Step: 1
Training loss: 1.6573872566223145
Validation loss: 2.0615653453334684

Epoch: 6| Step: 2
Training loss: 2.6954150199890137
Validation loss: 2.072575323043331

Epoch: 6| Step: 3
Training loss: 2.8820316791534424
Validation loss: 2.071367133048273

Epoch: 6| Step: 4
Training loss: 1.6389573812484741
Validation loss: 2.0664407066119614

Epoch: 6| Step: 5
Training loss: 1.9708280563354492
Validation loss: 2.078040066585746

Epoch: 6| Step: 6
Training loss: 2.3687472343444824
Validation loss: 2.0644138705345894

Epoch: 6| Step: 7
Training loss: 1.889992117881775
Validation loss: 2.0590095135473434

Epoch: 6| Step: 8
Training loss: 2.5238656997680664
Validation loss: 2.040456538559288

Epoch: 6| Step: 9
Training loss: 3.2076773643493652
Validation loss: 2.0424696476228776

Epoch: 6| Step: 10
Training loss: 2.697803258895874
Validation loss: 2.046624627164615

Epoch: 6| Step: 11
Training loss: 1.9449501037597656
Validation loss: 2.041829638583686

Epoch: 6| Step: 12
Training loss: 2.322908401489258
Validation loss: 2.049089991918174

Epoch: 6| Step: 13
Training loss: 2.190800905227661
Validation loss: 2.0598959486971617

Epoch: 165| Step: 0
Training loss: 1.8897260427474976
Validation loss: 2.0758360739677184

Epoch: 6| Step: 1
Training loss: 2.2709999084472656
Validation loss: 2.12891822989269

Epoch: 6| Step: 2
Training loss: 2.2843210697174072
Validation loss: 2.165723426367647

Epoch: 6| Step: 3
Training loss: 2.241002082824707
Validation loss: 2.187721892069745

Epoch: 6| Step: 4
Training loss: 2.3978731632232666
Validation loss: 2.2044475565674486

Epoch: 6| Step: 5
Training loss: 2.92059063911438
Validation loss: 2.1886453731085664

Epoch: 6| Step: 6
Training loss: 1.9815833568572998
Validation loss: 2.1613992824349353

Epoch: 6| Step: 7
Training loss: 2.8845183849334717
Validation loss: 2.121105117182578

Epoch: 6| Step: 8
Training loss: 2.308532238006592
Validation loss: 2.111904619842447

Epoch: 6| Step: 9
Training loss: 2.0548250675201416
Validation loss: 2.0788434590062788

Epoch: 6| Step: 10
Training loss: 2.8292274475097656
Validation loss: 2.0599645312114427

Epoch: 6| Step: 11
Training loss: 1.4999165534973145
Validation loss: 2.029244020421018

Epoch: 6| Step: 12
Training loss: 2.388522148132324
Validation loss: 2.028599476301542

Epoch: 6| Step: 13
Training loss: 2.022101402282715
Validation loss: 2.0262650597480034

Epoch: 166| Step: 0
Training loss: 2.178147315979004
Validation loss: 2.0201475171632666

Epoch: 6| Step: 1
Training loss: 1.7511169910430908
Validation loss: 2.0221547080624487

Epoch: 6| Step: 2
Training loss: 1.5599799156188965
Validation loss: 2.0307018397956766

Epoch: 6| Step: 3
Training loss: 2.876723289489746
Validation loss: 2.0348798510848836

Epoch: 6| Step: 4
Training loss: 1.8191139698028564
Validation loss: 2.0437461996591217

Epoch: 6| Step: 5
Training loss: 2.7642858028411865
Validation loss: 2.0583498119026102

Epoch: 6| Step: 6
Training loss: 1.9507415294647217
Validation loss: 2.105884591738383

Epoch: 6| Step: 7
Training loss: 2.637655735015869
Validation loss: 2.181446316421673

Epoch: 6| Step: 8
Training loss: 2.6213207244873047
Validation loss: 2.1900677347695954

Epoch: 6| Step: 9
Training loss: 2.0021772384643555
Validation loss: 2.1967074563426356

Epoch: 6| Step: 10
Training loss: 3.0820250511169434
Validation loss: 2.1883789313736783

Epoch: 6| Step: 11
Training loss: 2.074718952178955
Validation loss: 2.148692597625076

Epoch: 6| Step: 12
Training loss: 2.7811527252197266
Validation loss: 2.0960607144140426

Epoch: 6| Step: 13
Training loss: 1.676138997077942
Validation loss: 2.0653995313952045

Epoch: 167| Step: 0
Training loss: 3.1793441772460938
Validation loss: 2.027508140892111

Epoch: 6| Step: 1
Training loss: 1.3041706085205078
Validation loss: 2.0276773591195383

Epoch: 6| Step: 2
Training loss: 2.375847339630127
Validation loss: 2.037729868324854

Epoch: 6| Step: 3
Training loss: 2.015312671661377
Validation loss: 2.0367059579459568

Epoch: 6| Step: 4
Training loss: 2.8067526817321777
Validation loss: 2.0404859165991507

Epoch: 6| Step: 5
Training loss: 2.159306049346924
Validation loss: 2.047215119484932

Epoch: 6| Step: 6
Training loss: 1.611867904663086
Validation loss: 2.0496995218338503

Epoch: 6| Step: 7
Training loss: 2.3696951866149902
Validation loss: 2.068071439702024

Epoch: 6| Step: 8
Training loss: 2.552555561065674
Validation loss: 2.0720175004774526

Epoch: 6| Step: 9
Training loss: 2.0742058753967285
Validation loss: 2.0971594228539416

Epoch: 6| Step: 10
Training loss: 2.2676730155944824
Validation loss: 2.138749481529318

Epoch: 6| Step: 11
Training loss: 2.431734800338745
Validation loss: 2.1780267402689946

Epoch: 6| Step: 12
Training loss: 2.6887025833129883
Validation loss: 2.2355031941526677

Epoch: 6| Step: 13
Training loss: 2.1395139694213867
Validation loss: 2.2638802720654394

Epoch: 168| Step: 0
Training loss: 1.680537462234497
Validation loss: 2.2086145954747356

Epoch: 6| Step: 1
Training loss: 2.123006582260132
Validation loss: 2.1487120710393435

Epoch: 6| Step: 2
Training loss: 2.513838291168213
Validation loss: 2.1240856288581766

Epoch: 6| Step: 3
Training loss: 2.6491403579711914
Validation loss: 2.0778462143354517

Epoch: 6| Step: 4
Training loss: 2.283454179763794
Validation loss: 2.0449588657707296

Epoch: 6| Step: 5
Training loss: 1.9250013828277588
Validation loss: 2.0445466451747443

Epoch: 6| Step: 6
Training loss: 1.9238510131835938
Validation loss: 2.0335733198350474

Epoch: 6| Step: 7
Training loss: 2.3339319229125977
Validation loss: 2.0255198222334667

Epoch: 6| Step: 8
Training loss: 2.6811437606811523
Validation loss: 2.012972293361541

Epoch: 6| Step: 9
Training loss: 2.2494759559631348
Validation loss: 2.017532992106612

Epoch: 6| Step: 10
Training loss: 2.1931214332580566
Validation loss: 2.020286065275951

Epoch: 6| Step: 11
Training loss: 2.8778724670410156
Validation loss: 2.0091255685334564

Epoch: 6| Step: 12
Training loss: 2.096804141998291
Validation loss: 2.0120393973524853

Epoch: 6| Step: 13
Training loss: 2.4886064529418945
Validation loss: 2.0219740495886853

Epoch: 169| Step: 0
Training loss: 2.4315333366394043
Validation loss: 2.0343429760266374

Epoch: 6| Step: 1
Training loss: 1.7187168598175049
Validation loss: 2.048322349466303

Epoch: 6| Step: 2
Training loss: 2.749885082244873
Validation loss: 2.070385673994659

Epoch: 6| Step: 3
Training loss: 2.3506433963775635
Validation loss: 2.093970003948417

Epoch: 6| Step: 4
Training loss: 2.357465982437134
Validation loss: 2.114728726366515

Epoch: 6| Step: 5
Training loss: 1.738646388053894
Validation loss: 2.0912965766845213

Epoch: 6| Step: 6
Training loss: 2.5219693183898926
Validation loss: 2.0828054130718274

Epoch: 6| Step: 7
Training loss: 2.257157802581787
Validation loss: 2.0823404853061964

Epoch: 6| Step: 8
Training loss: 2.4759607315063477
Validation loss: 2.082215221979285

Epoch: 6| Step: 9
Training loss: 2.9652602672576904
Validation loss: 2.0904922536624375

Epoch: 6| Step: 10
Training loss: 1.6288572549819946
Validation loss: 2.0810549387367825

Epoch: 6| Step: 11
Training loss: 1.2366896867752075
Validation loss: 2.083065909724082

Epoch: 6| Step: 12
Training loss: 2.892892599105835
Validation loss: 2.1027903979824436

Epoch: 6| Step: 13
Training loss: 2.3927907943725586
Validation loss: 2.101987046580161

Epoch: 170| Step: 0
Training loss: 2.9862253665924072
Validation loss: 2.0875007208957466

Epoch: 6| Step: 1
Training loss: 2.4805474281311035
Validation loss: 2.0568554042488016

Epoch: 6| Step: 2
Training loss: 2.024078130722046
Validation loss: 2.0448106053054973

Epoch: 6| Step: 3
Training loss: 2.040750503540039
Validation loss: 2.0416894420500724

Epoch: 6| Step: 4
Training loss: 2.2205004692077637
Validation loss: 2.049336438537926

Epoch: 6| Step: 5
Training loss: 2.0968525409698486
Validation loss: 2.048870035397109

Epoch: 6| Step: 6
Training loss: 1.639312982559204
Validation loss: 2.0557905243289087

Epoch: 6| Step: 7
Training loss: 3.2246127128601074
Validation loss: 2.0627401208364837

Epoch: 6| Step: 8
Training loss: 2.1061530113220215
Validation loss: 2.080213249370616

Epoch: 6| Step: 9
Training loss: 2.1752240657806396
Validation loss: 2.0823679611247075

Epoch: 6| Step: 10
Training loss: 2.4496662616729736
Validation loss: 2.0732636323539158

Epoch: 6| Step: 11
Training loss: 2.1234817504882812
Validation loss: 2.082821351225658

Epoch: 6| Step: 12
Training loss: 1.7583463191986084
Validation loss: 2.0872576159815632

Epoch: 6| Step: 13
Training loss: 2.2314746379852295
Validation loss: 2.073894585332563

Epoch: 171| Step: 0
Training loss: 2.20977783203125
Validation loss: 2.090375227312888

Epoch: 6| Step: 1
Training loss: 2.163710594177246
Validation loss: 2.0998922650532057

Epoch: 6| Step: 2
Training loss: 2.1757616996765137
Validation loss: 2.112567836238492

Epoch: 6| Step: 3
Training loss: 2.667083263397217
Validation loss: 2.113906401459889

Epoch: 6| Step: 4
Training loss: 2.197845935821533
Validation loss: 2.105599921236756

Epoch: 6| Step: 5
Training loss: 1.1925678253173828
Validation loss: 2.106460702034735

Epoch: 6| Step: 6
Training loss: 2.013089179992676
Validation loss: 2.1100518908551944

Epoch: 6| Step: 7
Training loss: 2.68977952003479
Validation loss: 2.1302874703561105

Epoch: 6| Step: 8
Training loss: 2.2872021198272705
Validation loss: 2.1353513399759927

Epoch: 6| Step: 9
Training loss: 2.0430564880371094
Validation loss: 2.147421843262129

Epoch: 6| Step: 10
Training loss: 2.2520291805267334
Validation loss: 2.1178627424342658

Epoch: 6| Step: 11
Training loss: 2.1977248191833496
Validation loss: 2.087797241826211

Epoch: 6| Step: 12
Training loss: 2.7849223613739014
Validation loss: 2.062425469839445

Epoch: 6| Step: 13
Training loss: 2.8813252449035645
Validation loss: 2.0430304363209713

Epoch: 172| Step: 0
Training loss: 2.279306650161743
Validation loss: 2.04577568013181

Epoch: 6| Step: 1
Training loss: 2.2336173057556152
Validation loss: 2.041087976066015

Epoch: 6| Step: 2
Training loss: 1.4129154682159424
Validation loss: 2.059735213556597

Epoch: 6| Step: 3
Training loss: 2.3368711471557617
Validation loss: 2.0557168940062165

Epoch: 6| Step: 4
Training loss: 2.689159631729126
Validation loss: 2.0519894438405193

Epoch: 6| Step: 5
Training loss: 1.6533591747283936
Validation loss: 2.0561317859157437

Epoch: 6| Step: 6
Training loss: 1.666284441947937
Validation loss: 2.0601078566684516

Epoch: 6| Step: 7
Training loss: 2.4068727493286133
Validation loss: 2.075331562308855

Epoch: 6| Step: 8
Training loss: 2.574571132659912
Validation loss: 2.083812818732313

Epoch: 6| Step: 9
Training loss: 1.8970248699188232
Validation loss: 2.1340367947855303

Epoch: 6| Step: 10
Training loss: 2.421773910522461
Validation loss: 2.19422326549407

Epoch: 6| Step: 11
Training loss: 1.9305062294006348
Validation loss: 2.1973384452122513

Epoch: 6| Step: 12
Training loss: 3.564727783203125
Validation loss: 2.183854262034098

Epoch: 6| Step: 13
Training loss: 3.099741220474243
Validation loss: 2.1223907752703597

Epoch: 173| Step: 0
Training loss: 2.7072010040283203
Validation loss: 2.085497616439737

Epoch: 6| Step: 1
Training loss: 1.1993024349212646
Validation loss: 2.028640385596983

Epoch: 6| Step: 2
Training loss: 2.670471668243408
Validation loss: 2.0257090471124135

Epoch: 6| Step: 3
Training loss: 2.3344521522521973
Validation loss: 2.0233322138427408

Epoch: 6| Step: 4
Training loss: 2.3191750049591064
Validation loss: 2.0257174968719482

Epoch: 6| Step: 5
Training loss: 2.306577444076538
Validation loss: 2.019646724065145

Epoch: 6| Step: 6
Training loss: 2.1263647079467773
Validation loss: 2.0071128081249934

Epoch: 6| Step: 7
Training loss: 2.4631290435791016
Validation loss: 2.020371913909912

Epoch: 6| Step: 8
Training loss: 2.6286211013793945
Validation loss: 2.0313957968065814

Epoch: 6| Step: 9
Training loss: 2.596973419189453
Validation loss: 2.032287704047336

Epoch: 6| Step: 10
Training loss: 2.0922060012817383
Validation loss: 2.0372574662649505

Epoch: 6| Step: 11
Training loss: 2.194744825363159
Validation loss: 2.0444635498908257

Epoch: 6| Step: 12
Training loss: 1.7600681781768799
Validation loss: 2.0438643322196057

Epoch: 6| Step: 13
Training loss: 2.0451605319976807
Validation loss: 2.0579816128617976

Epoch: 174| Step: 0
Training loss: 2.452709674835205
Validation loss: 2.090439881047895

Epoch: 6| Step: 1
Training loss: 2.26949405670166
Validation loss: 2.096276993392616

Epoch: 6| Step: 2
Training loss: 2.6078338623046875
Validation loss: 2.1074359929689797

Epoch: 6| Step: 3
Training loss: 1.7158057689666748
Validation loss: 2.1138553465566328

Epoch: 6| Step: 4
Training loss: 2.785590648651123
Validation loss: 2.1336421735825075

Epoch: 6| Step: 5
Training loss: 1.8995472192764282
Validation loss: 2.148312707101145

Epoch: 6| Step: 6
Training loss: 1.3614305257797241
Validation loss: 2.182402269814604

Epoch: 6| Step: 7
Training loss: 2.613718032836914
Validation loss: 2.1872712950552664

Epoch: 6| Step: 8
Training loss: 2.755619764328003
Validation loss: 2.212429267103954

Epoch: 6| Step: 9
Training loss: 2.0726897716522217
Validation loss: 2.178068084101523

Epoch: 6| Step: 10
Training loss: 2.72441029548645
Validation loss: 2.1742904340067217

Epoch: 6| Step: 11
Training loss: 2.1317873001098633
Validation loss: 2.1603095787827686

Epoch: 6| Step: 12
Training loss: 1.531922459602356
Validation loss: 2.1307890466464463

Epoch: 6| Step: 13
Training loss: 2.503040313720703
Validation loss: 2.1021569646814817

Epoch: 175| Step: 0
Training loss: 2.4476943016052246
Validation loss: 2.0980303108051257

Epoch: 6| Step: 1
Training loss: 2.4079205989837646
Validation loss: 2.085466629715376

Epoch: 6| Step: 2
Training loss: 1.6358654499053955
Validation loss: 2.084842462693491

Epoch: 6| Step: 3
Training loss: 2.1596872806549072
Validation loss: 2.0826703297194613

Epoch: 6| Step: 4
Training loss: 1.7026970386505127
Validation loss: 2.067261865062098

Epoch: 6| Step: 5
Training loss: 2.000589370727539
Validation loss: 2.0692347531677573

Epoch: 6| Step: 6
Training loss: 2.248438835144043
Validation loss: 2.056726933807455

Epoch: 6| Step: 7
Training loss: 2.45241117477417
Validation loss: 2.0618721592810845

Epoch: 6| Step: 8
Training loss: 1.9374397993087769
Validation loss: 2.072468880684145

Epoch: 6| Step: 9
Training loss: 1.6411023139953613
Validation loss: 2.076583972541235

Epoch: 6| Step: 10
Training loss: 2.9761440753936768
Validation loss: 2.079027969350097

Epoch: 6| Step: 11
Training loss: 2.697256565093994
Validation loss: 2.0865474541982016

Epoch: 6| Step: 12
Training loss: 2.3029325008392334
Validation loss: 2.1035642162446053

Epoch: 6| Step: 13
Training loss: 2.814812660217285
Validation loss: 2.0943017313557286

Testing loss: 2.283188978830973
