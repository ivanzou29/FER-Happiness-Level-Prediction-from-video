Epoch: 1| Step: 0
Training loss: 7.437534364252282
Validation loss: 5.756352849800419

Epoch: 6| Step: 1
Training loss: 6.142078179177701
Validation loss: 5.748464860050982

Epoch: 6| Step: 2
Training loss: 6.449781831112221
Validation loss: 5.74048641417881

Epoch: 6| Step: 3
Training loss: 6.722667031332145
Validation loss: 5.733144878491524

Epoch: 6| Step: 4
Training loss: 3.7063401827205267
Validation loss: 5.726327757535921

Epoch: 6| Step: 5
Training loss: 3.976720300927215
Validation loss: 5.719888490538973

Epoch: 6| Step: 6
Training loss: 5.251007891592192
Validation loss: 5.713998096233033

Epoch: 6| Step: 7
Training loss: 5.148470842314265
Validation loss: 5.707480709219816

Epoch: 6| Step: 8
Training loss: 6.407512856662933
Validation loss: 5.700848165237007

Epoch: 6| Step: 9
Training loss: 5.238164367054483
Validation loss: 5.693287973584668

Epoch: 6| Step: 10
Training loss: 6.66616069145185
Validation loss: 5.685577547268478

Epoch: 6| Step: 11
Training loss: 5.765876743847733
Validation loss: 5.676601569273508

Epoch: 6| Step: 12
Training loss: 5.890268168278782
Validation loss: 5.666936409530275

Epoch: 6| Step: 13
Training loss: 2.689518636156325
Validation loss: 5.656305844372276

Epoch: 2| Step: 0
Training loss: 4.939121028525605
Validation loss: 5.64501447460329

Epoch: 6| Step: 1
Training loss: 4.298501112760849
Validation loss: 5.633623154353336

Epoch: 6| Step: 2
Training loss: 5.672439925378782
Validation loss: 5.621696999117023

Epoch: 6| Step: 3
Training loss: 5.769273384132474
Validation loss: 5.608288106221112

Epoch: 6| Step: 4
Training loss: 5.682051175975649
Validation loss: 5.593522694696146

Epoch: 6| Step: 5
Training loss: 5.4258164033238465
Validation loss: 5.578153023781956

Epoch: 6| Step: 6
Training loss: 7.186886437806144
Validation loss: 5.56180384447063

Epoch: 6| Step: 7
Training loss: 6.759432101350207
Validation loss: 5.543788644587724

Epoch: 6| Step: 8
Training loss: 5.2208899947265826
Validation loss: 5.525415143216786

Epoch: 6| Step: 9
Training loss: 5.324960255362607
Validation loss: 5.505908769656626

Epoch: 6| Step: 10
Training loss: 5.110100650878549
Validation loss: 5.485189784895174

Epoch: 6| Step: 11
Training loss: 5.713450493399531
Validation loss: 5.46333011882497

Epoch: 6| Step: 12
Training loss: 5.313352449128255
Validation loss: 5.441135717167258

Epoch: 6| Step: 13
Training loss: 4.937417524590542
Validation loss: 5.418018315670801

Epoch: 3| Step: 0
Training loss: 4.395826198096006
Validation loss: 5.394839159543515

Epoch: 6| Step: 1
Training loss: 4.546697554124492
Validation loss: 5.371640528437251

Epoch: 6| Step: 2
Training loss: 5.109856165823103
Validation loss: 5.347471307646677

Epoch: 6| Step: 3
Training loss: 5.5645922894145725
Validation loss: 5.322893643739303

Epoch: 6| Step: 4
Training loss: 6.252813087626166
Validation loss: 5.297945695107618

Epoch: 6| Step: 5
Training loss: 4.64525991872623
Validation loss: 5.274718665543593

Epoch: 6| Step: 6
Training loss: 5.60576732518191
Validation loss: 5.247982571179127

Epoch: 6| Step: 7
Training loss: 4.692470712463648
Validation loss: 5.222353567407526

Epoch: 6| Step: 8
Training loss: 5.873282972993842
Validation loss: 5.195068016100869

Epoch: 6| Step: 9
Training loss: 5.267069542038433
Validation loss: 5.166809240167594

Epoch: 6| Step: 10
Training loss: 5.578832415861546
Validation loss: 5.137215467661247

Epoch: 6| Step: 11
Training loss: 5.160462479380955
Validation loss: 5.108323367481373

Epoch: 6| Step: 12
Training loss: 5.556658131013725
Validation loss: 5.076002231162048

Epoch: 6| Step: 13
Training loss: 5.438405104099358
Validation loss: 5.045214066133539

Epoch: 4| Step: 0
Training loss: 5.572224549664592
Validation loss: 5.0125816459881225

Epoch: 6| Step: 1
Training loss: 4.965269777281154
Validation loss: 4.981748351936587

Epoch: 6| Step: 2
Training loss: 5.351513671652242
Validation loss: 4.951596899936323

Epoch: 6| Step: 3
Training loss: 4.460425673215427
Validation loss: 4.922084450615201

Epoch: 6| Step: 4
Training loss: 4.6652769108366074
Validation loss: 4.893591026898944

Epoch: 6| Step: 5
Training loss: 4.388062947992756
Validation loss: 4.8671239667271

Epoch: 6| Step: 6
Training loss: 4.156860306753558
Validation loss: 4.8404994022150944

Epoch: 6| Step: 7
Training loss: 4.426192154289547
Validation loss: 4.817034096890789

Epoch: 6| Step: 8
Training loss: 5.895422320198621
Validation loss: 4.792896830126522

Epoch: 6| Step: 9
Training loss: 4.752424324151528
Validation loss: 4.769377714975437

Epoch: 6| Step: 10
Training loss: 4.7567181510963765
Validation loss: 4.744152690598355

Epoch: 6| Step: 11
Training loss: 5.14637263428267
Validation loss: 4.71754273115962

Epoch: 6| Step: 12
Training loss: 4.540158689305063
Validation loss: 4.689927682381787

Epoch: 6| Step: 13
Training loss: 5.702580841441341
Validation loss: 4.667060571005209

Epoch: 5| Step: 0
Training loss: 3.4509770544013882
Validation loss: 4.647902763330718

Epoch: 6| Step: 1
Training loss: 4.901500176424784
Validation loss: 4.632162211754646

Epoch: 6| Step: 2
Training loss: 4.242300351716026
Validation loss: 4.6132871316173825

Epoch: 6| Step: 3
Training loss: 4.387646516706469
Validation loss: 4.596658015730501

Epoch: 6| Step: 4
Training loss: 4.189105281305464
Validation loss: 4.578217941651668

Epoch: 6| Step: 5
Training loss: 5.846802266258254
Validation loss: 4.557776527406681

Epoch: 6| Step: 6
Training loss: 4.400384556697991
Validation loss: 4.537322818853187

Epoch: 6| Step: 7
Training loss: 3.942260286715337
Validation loss: 4.516686408268388

Epoch: 6| Step: 8
Training loss: 4.7854767112081555
Validation loss: 4.493329414802197

Epoch: 6| Step: 9
Training loss: 4.193866501851431
Validation loss: 4.471094064121089

Epoch: 6| Step: 10
Training loss: 5.615423740013502
Validation loss: 4.4371391610699185

Epoch: 6| Step: 11
Training loss: 4.9154332224788115
Validation loss: 4.391110781019775

Epoch: 6| Step: 12
Training loss: 4.134547426487571
Validation loss: 4.365136167945681

Epoch: 6| Step: 13
Training loss: 5.314691966506858
Validation loss: 4.3498264180516015

Epoch: 6| Step: 0
Training loss: 4.140220535964936
Validation loss: 4.337173498894719

Epoch: 6| Step: 1
Training loss: 3.971402100654197
Validation loss: 4.330602191442921

Epoch: 6| Step: 2
Training loss: 5.028005750532967
Validation loss: 4.323979561410483

Epoch: 6| Step: 3
Training loss: 3.675697447321143
Validation loss: 4.318418512708267

Epoch: 6| Step: 4
Training loss: 4.943117061178865
Validation loss: 4.306364281781909

Epoch: 6| Step: 5
Training loss: 4.675658464213849
Validation loss: 4.2948885367888145

Epoch: 6| Step: 6
Training loss: 4.485125648329022
Validation loss: 4.279810893002316

Epoch: 6| Step: 7
Training loss: 3.311382609066849
Validation loss: 4.261446128049262

Epoch: 6| Step: 8
Training loss: 4.461504417512154
Validation loss: 4.253755801588419

Epoch: 6| Step: 9
Training loss: 4.251843669640789
Validation loss: 4.246618391346542

Epoch: 6| Step: 10
Training loss: 4.281816653877402
Validation loss: 4.232406429244018

Epoch: 6| Step: 11
Training loss: 3.8290343158307008
Validation loss: 4.218412688886391

Epoch: 6| Step: 12
Training loss: 5.733415653317919
Validation loss: 4.207037602073047

Epoch: 6| Step: 13
Training loss: 4.088584611347246
Validation loss: 4.194122252548944

Epoch: 7| Step: 0
Training loss: 4.346573824290779
Validation loss: 4.181245720267629

Epoch: 6| Step: 1
Training loss: 3.398893759781733
Validation loss: 4.173993761584348

Epoch: 6| Step: 2
Training loss: 4.187610453956637
Validation loss: 4.1668446353108495

Epoch: 6| Step: 3
Training loss: 5.549396983886234
Validation loss: 4.159504306843392

Epoch: 6| Step: 4
Training loss: 4.024503518517116
Validation loss: 4.152390249540651

Epoch: 6| Step: 5
Training loss: 4.342192226433421
Validation loss: 4.14605840198926

Epoch: 6| Step: 6
Training loss: 4.787491856660217
Validation loss: 4.139505337050245

Epoch: 6| Step: 7
Training loss: 4.985309190411265
Validation loss: 4.1317420620138865

Epoch: 6| Step: 8
Training loss: 4.238242097313396
Validation loss: 4.125150725642894

Epoch: 6| Step: 9
Training loss: 4.008619796022988
Validation loss: 4.1212184970911245

Epoch: 6| Step: 10
Training loss: 2.999758392777502
Validation loss: 4.114162541414065

Epoch: 6| Step: 11
Training loss: 4.065369986087281
Validation loss: 4.108060671134116

Epoch: 6| Step: 12
Training loss: 4.706492691570927
Validation loss: 4.10303015511247

Epoch: 6| Step: 13
Training loss: 2.9540000305382397
Validation loss: 4.093606535060275

Epoch: 8| Step: 0
Training loss: 4.278979513848091
Validation loss: 4.087820960248893

Epoch: 6| Step: 1
Training loss: 4.35985100447825
Validation loss: 4.078179657945068

Epoch: 6| Step: 2
Training loss: 5.454300281043035
Validation loss: 4.070831585057046

Epoch: 6| Step: 3
Training loss: 4.271665216079289
Validation loss: 4.062689316900089

Epoch: 6| Step: 4
Training loss: 4.5071115461163975
Validation loss: 4.056805189488597

Epoch: 6| Step: 5
Training loss: 4.155866332738089
Validation loss: 4.0504234025293275

Epoch: 6| Step: 6
Training loss: 3.682727635036605
Validation loss: 4.039976327033402

Epoch: 6| Step: 7
Training loss: 3.244705876685326
Validation loss: 4.031369720637401

Epoch: 6| Step: 8
Training loss: 4.293356380716702
Validation loss: 4.027466056528282

Epoch: 6| Step: 9
Training loss: 4.185933289734025
Validation loss: 4.023806953770885

Epoch: 6| Step: 10
Training loss: 4.313697980259232
Validation loss: 4.015627957143421

Epoch: 6| Step: 11
Training loss: 4.336960570462463
Validation loss: 4.008641923769116

Epoch: 6| Step: 12
Training loss: 3.948333610855636
Validation loss: 4.002392414877074

Epoch: 6| Step: 13
Training loss: 2.0599900202833488
Validation loss: 3.996323960082281

Epoch: 9| Step: 0
Training loss: 4.070859319525208
Validation loss: 3.992090462644597

Epoch: 6| Step: 1
Training loss: 4.28753534864084
Validation loss: 3.9813520339143813

Epoch: 6| Step: 2
Training loss: 3.6975640500435967
Validation loss: 3.9790130870791605

Epoch: 6| Step: 3
Training loss: 4.344859468669871
Validation loss: 3.973277652493071

Epoch: 6| Step: 4
Training loss: 3.9885681826265595
Validation loss: 3.9692409458156277

Epoch: 6| Step: 5
Training loss: 4.464084564036959
Validation loss: 3.961626232169914

Epoch: 6| Step: 6
Training loss: 4.308013129863371
Validation loss: 3.95720377912198

Epoch: 6| Step: 7
Training loss: 5.283642108610761
Validation loss: 3.951916810069546

Epoch: 6| Step: 8
Training loss: 4.331807356914316
Validation loss: 3.9435250808607925

Epoch: 6| Step: 9
Training loss: 3.4653547011310226
Validation loss: 3.9391913257486544

Epoch: 6| Step: 10
Training loss: 4.701721387506634
Validation loss: 3.933395426200806

Epoch: 6| Step: 11
Training loss: 2.7996697128860077
Validation loss: 3.9251077021012626

Epoch: 6| Step: 12
Training loss: 3.256962287888296
Validation loss: 3.9228867763208126

Epoch: 6| Step: 13
Training loss: 3.819007073223299
Validation loss: 3.9183210092025536

Epoch: 10| Step: 0
Training loss: 4.684973277338409
Validation loss: 3.910912878195886

Epoch: 6| Step: 1
Training loss: 3.8461069463658055
Validation loss: 3.9093192707588575

Epoch: 6| Step: 2
Training loss: 3.9090047659465537
Validation loss: 3.906846088171452

Epoch: 6| Step: 3
Training loss: 4.002902170213726
Validation loss: 3.9036274273421134

Epoch: 6| Step: 4
Training loss: 3.866913386947124
Validation loss: 3.901349411227956

Epoch: 6| Step: 5
Training loss: 4.068042436946649
Validation loss: 3.8944558908872824

Epoch: 6| Step: 6
Training loss: 3.7921989123247752
Validation loss: 3.885376577223559

Epoch: 6| Step: 7
Training loss: 4.3848025993708335
Validation loss: 3.8749165851825493

Epoch: 6| Step: 8
Training loss: 3.4508759091577423
Validation loss: 3.8706510991136427

Epoch: 6| Step: 9
Training loss: 3.9041484825554895
Validation loss: 3.872643900675228

Epoch: 6| Step: 10
Training loss: 4.523799479863005
Validation loss: 3.8567248864154795

Epoch: 6| Step: 11
Training loss: 4.494644368905029
Validation loss: 3.8552673834500544

Epoch: 6| Step: 12
Training loss: 4.0979194665668786
Validation loss: 3.8519241065747467

Epoch: 6| Step: 13
Training loss: 2.785987933136165
Validation loss: 3.8486613821620335

Epoch: 11| Step: 0
Training loss: 4.533571266961311
Validation loss: 3.849970872031312

Epoch: 6| Step: 1
Training loss: 4.614391015769159
Validation loss: 3.8413302554127595

Epoch: 6| Step: 2
Training loss: 3.541574155309838
Validation loss: 3.8348887811336914

Epoch: 6| Step: 3
Training loss: 3.927947187989332
Validation loss: 3.828141581382443

Epoch: 6| Step: 4
Training loss: 3.6231355805347008
Validation loss: 3.8221856403778336

Epoch: 6| Step: 5
Training loss: 3.302815369211265
Validation loss: 3.815538468826402

Epoch: 6| Step: 6
Training loss: 3.7121761142207035
Validation loss: 3.8197242157545177

Epoch: 6| Step: 7
Training loss: 3.3804444091992583
Validation loss: 3.8095326232185602

Epoch: 6| Step: 8
Training loss: 3.7423049812750397
Validation loss: 3.8059955979540234

Epoch: 6| Step: 9
Training loss: 3.9185769853621557
Validation loss: 3.7997932436123487

Epoch: 6| Step: 10
Training loss: 4.203583079054659
Validation loss: 3.7940241174008045

Epoch: 6| Step: 11
Training loss: 4.83151215191189
Validation loss: 3.787006671186041

Epoch: 6| Step: 12
Training loss: 4.3250606995661505
Validation loss: 3.7812971659476147

Epoch: 6| Step: 13
Training loss: 3.5914194262405807
Validation loss: 3.7766012431321054

Epoch: 12| Step: 0
Training loss: 4.432451627051045
Validation loss: 3.7796339776652585

Epoch: 6| Step: 1
Training loss: 3.6851113551795476
Validation loss: 3.77236613125076

Epoch: 6| Step: 2
Training loss: 2.9700995339306524
Validation loss: 3.768530286079579

Epoch: 6| Step: 3
Training loss: 4.126111429933341
Validation loss: 3.7635013741727525

Epoch: 6| Step: 4
Training loss: 4.077728836869982
Validation loss: 3.754850904795687

Epoch: 6| Step: 5
Training loss: 3.6125350264068863
Validation loss: 3.7497295924764287

Epoch: 6| Step: 6
Training loss: 3.295050816932788
Validation loss: 3.748938264566768

Epoch: 6| Step: 7
Training loss: 4.592422397312969
Validation loss: 3.7462111498346786

Epoch: 6| Step: 8
Training loss: 3.8769885467525422
Validation loss: 3.739117465875009

Epoch: 6| Step: 9
Training loss: 4.165549064796917
Validation loss: 3.729063245162214

Epoch: 6| Step: 10
Training loss: 3.9223155955822393
Validation loss: 3.726077153529122

Epoch: 6| Step: 11
Training loss: 4.5144153281465895
Validation loss: 3.7239791175382178

Epoch: 6| Step: 12
Training loss: 2.905482693356903
Validation loss: 3.7197373167826004

Epoch: 6| Step: 13
Training loss: 4.555035062585876
Validation loss: 3.7148011784195147

Epoch: 13| Step: 0
Training loss: 3.7231865071916537
Validation loss: 3.7109605654834605

Epoch: 6| Step: 1
Training loss: 4.514006961680238
Validation loss: 3.7036706569067808

Epoch: 6| Step: 2
Training loss: 3.7951284402414744
Validation loss: 3.7021963452943907

Epoch: 6| Step: 3
Training loss: 3.1202159119748925
Validation loss: 3.7146415899998733

Epoch: 6| Step: 4
Training loss: 4.020249134903141
Validation loss: 3.7079709631716176

Epoch: 6| Step: 5
Training loss: 4.963045504396563
Validation loss: 3.688014237059877

Epoch: 6| Step: 6
Training loss: 3.8641858714793753
Validation loss: 3.6836462585536625

Epoch: 6| Step: 7
Training loss: 4.153639812724215
Validation loss: 3.691352089191962

Epoch: 6| Step: 8
Training loss: 3.2174316965721173
Validation loss: 3.6839057295158955

Epoch: 6| Step: 9
Training loss: 3.842850618665832
Validation loss: 3.676590845234372

Epoch: 6| Step: 10
Training loss: 3.9853648433449993
Validation loss: 3.671875019549123

Epoch: 6| Step: 11
Training loss: 3.6940368644225643
Validation loss: 3.669683028631742

Epoch: 6| Step: 12
Training loss: 3.255006162341682
Validation loss: 3.6675132061371127

Epoch: 6| Step: 13
Training loss: 3.5689044070536564
Validation loss: 3.6678518820325614

Epoch: 14| Step: 0
Training loss: 4.619830154665752
Validation loss: 3.6605684902294957

Epoch: 6| Step: 1
Training loss: 2.6999055068823705
Validation loss: 3.653268458572797

Epoch: 6| Step: 2
Training loss: 4.079952838849529
Validation loss: 3.647097028185757

Epoch: 6| Step: 3
Training loss: 4.522384072879781
Validation loss: 3.642921368196016

Epoch: 6| Step: 4
Training loss: 3.4559974288401047
Validation loss: 3.638023299242821

Epoch: 6| Step: 5
Training loss: 4.244191857145913
Validation loss: 3.6349045658150234

Epoch: 6| Step: 6
Training loss: 3.657534772977497
Validation loss: 3.6313814804133404

Epoch: 6| Step: 7
Training loss: 3.6983493318995326
Validation loss: 3.6259490493905093

Epoch: 6| Step: 8
Training loss: 2.636610150396634
Validation loss: 3.6211323683659833

Epoch: 6| Step: 9
Training loss: 4.336724177298554
Validation loss: 3.6290186331435086

Epoch: 6| Step: 10
Training loss: 3.6122281246110353
Validation loss: 3.619533299364337

Epoch: 6| Step: 11
Training loss: 3.056885535815358
Validation loss: 3.6135966906092363

Epoch: 6| Step: 12
Training loss: 3.8802929077489443
Validation loss: 3.614016311672619

Epoch: 6| Step: 13
Training loss: 4.783453340165862
Validation loss: 3.6151921338002064

Epoch: 15| Step: 0
Training loss: 4.169127513257631
Validation loss: 3.6102755773946043

Epoch: 6| Step: 1
Training loss: 3.3804382026619866
Validation loss: 3.607158717536732

Epoch: 6| Step: 2
Training loss: 4.443040853968068
Validation loss: 3.6027373401321676

Epoch: 6| Step: 3
Training loss: 4.531824956787811
Validation loss: 3.602825905302492

Epoch: 6| Step: 4
Training loss: 4.185123053670613
Validation loss: 3.5974265390403444

Epoch: 6| Step: 5
Training loss: 2.6252795479287436
Validation loss: 3.590721318669925

Epoch: 6| Step: 6
Training loss: 2.7876416602297343
Validation loss: 3.5886975426334495

Epoch: 6| Step: 7
Training loss: 4.313929887423809
Validation loss: 3.5867682651529558

Epoch: 6| Step: 8
Training loss: 3.3602051175042367
Validation loss: 3.580244091063181

Epoch: 6| Step: 9
Training loss: 4.534081777796803
Validation loss: 3.579868416198063

Epoch: 6| Step: 10
Training loss: 3.719442094785179
Validation loss: 3.57698365657419

Epoch: 6| Step: 11
Training loss: 3.68516104275115
Validation loss: 3.5749791695237256

Epoch: 6| Step: 12
Training loss: 3.5527155845778515
Validation loss: 3.569942584898696

Epoch: 6| Step: 13
Training loss: 2.3286600202212027
Validation loss: 3.5644998900834697

Epoch: 16| Step: 0
Training loss: 4.023481587288794
Validation loss: 3.561704928656506

Epoch: 6| Step: 1
Training loss: 4.2255530994145225
Validation loss: 3.558198324706011

Epoch: 6| Step: 2
Training loss: 3.557766362805401
Validation loss: 3.5562405303512388

Epoch: 6| Step: 3
Training loss: 3.955085841041856
Validation loss: 3.554335818269807

Epoch: 6| Step: 4
Training loss: 3.5391487296338298
Validation loss: 3.547483485168817

Epoch: 6| Step: 5
Training loss: 4.284360104012557
Validation loss: 3.5435775905012186

Epoch: 6| Step: 6
Training loss: 3.3128995834317623
Validation loss: 3.5394789297193445

Epoch: 6| Step: 7
Training loss: 3.3139744482074063
Validation loss: 3.5374156192641473

Epoch: 6| Step: 8
Training loss: 4.768419790771928
Validation loss: 3.5346726812842673

Epoch: 6| Step: 9
Training loss: 1.7310835389904276
Validation loss: 3.530017513919714

Epoch: 6| Step: 10
Training loss: 4.157395742718302
Validation loss: 3.529696546184894

Epoch: 6| Step: 11
Training loss: 3.8554363461942494
Validation loss: 3.524520957371197

Epoch: 6| Step: 12
Training loss: 3.6263864430922905
Validation loss: 3.5224667948148283

Epoch: 6| Step: 13
Training loss: 2.8236730108957264
Validation loss: 3.5208927495876954

Epoch: 17| Step: 0
Training loss: 3.440344309985912
Validation loss: 3.5170012607990375

Epoch: 6| Step: 1
Training loss: 4.516623838627499
Validation loss: 3.515913252048417

Epoch: 6| Step: 2
Training loss: 4.07386340807187
Validation loss: 3.511847614475982

Epoch: 6| Step: 3
Training loss: 4.101023960180269
Validation loss: 3.5086761938035043

Epoch: 6| Step: 4
Training loss: 4.0841697822273
Validation loss: 3.509833005856776

Epoch: 6| Step: 5
Training loss: 3.1563057469647573
Validation loss: 3.5068546155462417

Epoch: 6| Step: 6
Training loss: 3.5700386994131614
Validation loss: 3.5035501602042847

Epoch: 6| Step: 7
Training loss: 3.4366112687252106
Validation loss: 3.5041664831624235

Epoch: 6| Step: 8
Training loss: 3.8532607104927825
Validation loss: 3.497116068270634

Epoch: 6| Step: 9
Training loss: 2.9536697450406595
Validation loss: 3.4971121639227714

Epoch: 6| Step: 10
Training loss: 3.550841680333544
Validation loss: 3.496037098708649

Epoch: 6| Step: 11
Training loss: 3.3634771806133656
Validation loss: 3.4971025137284664

Epoch: 6| Step: 12
Training loss: 3.480194046705179
Validation loss: 3.4937425555392148

Epoch: 6| Step: 13
Training loss: 4.378785158060306
Validation loss: 3.504099634966822

Epoch: 18| Step: 0
Training loss: 3.752250250549532
Validation loss: 3.490064673667959

Epoch: 6| Step: 1
Training loss: 2.896987099726446
Validation loss: 3.4872808234575623

Epoch: 6| Step: 2
Training loss: 3.782935405311822
Validation loss: 3.4890934112457885

Epoch: 6| Step: 3
Training loss: 3.964002999297854
Validation loss: 3.48541499845673

Epoch: 6| Step: 4
Training loss: 4.138924418616216
Validation loss: 3.4796790166419425

Epoch: 6| Step: 5
Training loss: 4.329895318508091
Validation loss: 3.4788801961858224

Epoch: 6| Step: 6
Training loss: 3.257195357088408
Validation loss: 3.4783484106023383

Epoch: 6| Step: 7
Training loss: 3.1150595684693263
Validation loss: 3.4796271390013644

Epoch: 6| Step: 8
Training loss: 3.230471259304119
Validation loss: 3.473918078392056

Epoch: 6| Step: 9
Training loss: 3.861232171726037
Validation loss: 3.4743753626830687

Epoch: 6| Step: 10
Training loss: 3.946293170778609
Validation loss: 3.473618165551959

Epoch: 6| Step: 11
Training loss: 3.8380189675184955
Validation loss: 3.473902620878376

Epoch: 6| Step: 12
Training loss: 3.2045651059559623
Validation loss: 3.47561659702578

Epoch: 6| Step: 13
Training loss: 4.328968392838115
Validation loss: 3.469290284311617

Epoch: 19| Step: 0
Training loss: 3.6306145694771303
Validation loss: 3.475804062275217

Epoch: 6| Step: 1
Training loss: 3.432596628227905
Validation loss: 3.468508381527301

Epoch: 6| Step: 2
Training loss: 3.052069202863425
Validation loss: 3.4634602203649676

Epoch: 6| Step: 3
Training loss: 3.120602068886526
Validation loss: 3.461461048086212

Epoch: 6| Step: 4
Training loss: 4.200351182696918
Validation loss: 3.458073498161398

Epoch: 6| Step: 5
Training loss: 3.407887196585785
Validation loss: 3.4587360238564404

Epoch: 6| Step: 6
Training loss: 2.980514346032701
Validation loss: 3.4585645776010883

Epoch: 6| Step: 7
Training loss: 3.2117391731802454
Validation loss: 3.4584026460685893

Epoch: 6| Step: 8
Training loss: 3.8708484929954436
Validation loss: 3.4573965042938153

Epoch: 6| Step: 9
Training loss: 3.4028972959397215
Validation loss: 3.454188998711118

Epoch: 6| Step: 10
Training loss: 4.107014373286017
Validation loss: 3.4524729316316054

Epoch: 6| Step: 11
Training loss: 4.83605917437046
Validation loss: 3.4512673142112993

Epoch: 6| Step: 12
Training loss: 3.6075077924426138
Validation loss: 3.4479251082370017

Epoch: 6| Step: 13
Training loss: 4.414596336289189
Validation loss: 3.4468611960035695

Epoch: 20| Step: 0
Training loss: 2.8098722261857807
Validation loss: 3.4431811418790454

Epoch: 6| Step: 1
Training loss: 3.6150724023345777
Validation loss: 3.4417487399093036

Epoch: 6| Step: 2
Training loss: 3.916828449776741
Validation loss: 3.440473873197725

Epoch: 6| Step: 3
Training loss: 4.182012121882628
Validation loss: 3.4395879912940974

Epoch: 6| Step: 4
Training loss: 3.0180556231227245
Validation loss: 3.4376761502265176

Epoch: 6| Step: 5
Training loss: 3.6376828596682826
Validation loss: 3.438760605726821

Epoch: 6| Step: 6
Training loss: 4.000093935817174
Validation loss: 3.4347903941008324

Epoch: 6| Step: 7
Training loss: 3.4382344241638574
Validation loss: 3.4337874693910164

Epoch: 6| Step: 8
Training loss: 4.140961716114528
Validation loss: 3.4319483609773935

Epoch: 6| Step: 9
Training loss: 2.688846694292956
Validation loss: 3.429066682770728

Epoch: 6| Step: 10
Training loss: 3.1120868148167946
Validation loss: 3.4302212436270234

Epoch: 6| Step: 11
Training loss: 4.541014784946159
Validation loss: 3.428279931246758

Epoch: 6| Step: 12
Training loss: 3.6665218209065107
Validation loss: 3.4265754403899353

Epoch: 6| Step: 13
Training loss: 4.055983496141433
Validation loss: 3.424693566310191

Epoch: 21| Step: 0
Training loss: 3.767766319941699
Validation loss: 3.428661159885706

Epoch: 6| Step: 1
Training loss: 3.3851935836455325
Validation loss: 3.4293421893048124

Epoch: 6| Step: 2
Training loss: 3.6444700180748484
Validation loss: 3.42618357153867

Epoch: 6| Step: 3
Training loss: 4.272859021632939
Validation loss: 3.422699414716464

Epoch: 6| Step: 4
Training loss: 3.3072124962329315
Validation loss: 3.4219035965309006

Epoch: 6| Step: 5
Training loss: 2.8489791246361045
Validation loss: 3.4259677500895434

Epoch: 6| Step: 6
Training loss: 4.049429893398311
Validation loss: 3.4325163556683274

Epoch: 6| Step: 7
Training loss: 3.710467563789118
Validation loss: 3.426168694806963

Epoch: 6| Step: 8
Training loss: 3.2051022265432927
Validation loss: 3.4231880572968914

Epoch: 6| Step: 9
Training loss: 3.6043086970280003
Validation loss: 3.4264043639152075

Epoch: 6| Step: 10
Training loss: 4.524350089088784
Validation loss: 3.4249374793525806

Epoch: 6| Step: 11
Training loss: 3.5828619506457757
Validation loss: 3.416840542606591

Epoch: 6| Step: 12
Training loss: 3.217432734001932
Validation loss: 3.4151772875226305

Epoch: 6| Step: 13
Training loss: 3.576055202945581
Validation loss: 3.4146779015090587

Epoch: 22| Step: 0
Training loss: 3.9229680092251336
Validation loss: 3.4159779928817

Epoch: 6| Step: 1
Training loss: 3.7038964864219555
Validation loss: 3.4118725727213786

Epoch: 6| Step: 2
Training loss: 3.3239245346169657
Validation loss: 3.4124879672375363

Epoch: 6| Step: 3
Training loss: 3.5408231890191857
Validation loss: 3.4099706669220233

Epoch: 6| Step: 4
Training loss: 3.95137847797711
Validation loss: 3.4102678794582335

Epoch: 6| Step: 5
Training loss: 2.932319293165864
Validation loss: 3.4088826997069304

Epoch: 6| Step: 6
Training loss: 3.9119648137762733
Validation loss: 3.4058093707674617

Epoch: 6| Step: 7
Training loss: 3.5661892443648493
Validation loss: 3.406351294756057

Epoch: 6| Step: 8
Training loss: 3.7687134799484707
Validation loss: 3.405743041428172

Epoch: 6| Step: 9
Training loss: 4.0239925853441
Validation loss: 3.4048950866328944

Epoch: 6| Step: 10
Training loss: 2.55606107503309
Validation loss: 3.403579871079735

Epoch: 6| Step: 11
Training loss: 2.988842720689899
Validation loss: 3.402694389276362

Epoch: 6| Step: 12
Training loss: 4.273970380681341
Validation loss: 3.3999477238288702

Epoch: 6| Step: 13
Training loss: 4.262560963124805
Validation loss: 3.400764530298214

Epoch: 23| Step: 0
Training loss: 3.20013168779253
Validation loss: 3.3988492854597627

Epoch: 6| Step: 1
Training loss: 4.718436325460149
Validation loss: 3.398814260126205

Epoch: 6| Step: 2
Training loss: 3.4774355360099047
Validation loss: 3.397168440898361

Epoch: 6| Step: 3
Training loss: 3.544007608513167
Validation loss: 3.3967623023485354

Epoch: 6| Step: 4
Training loss: 4.1555517083307185
Validation loss: 3.3957182014577123

Epoch: 6| Step: 5
Training loss: 2.830184608072676
Validation loss: 3.395979336040189

Epoch: 6| Step: 6
Training loss: 3.349797137366863
Validation loss: 3.393217448081785

Epoch: 6| Step: 7
Training loss: 3.3611698057936477
Validation loss: 3.394261896773529

Epoch: 6| Step: 8
Training loss: 4.318360258367164
Validation loss: 3.3917178434310555

Epoch: 6| Step: 9
Training loss: 3.0780351499814755
Validation loss: 3.390065483048616

Epoch: 6| Step: 10
Training loss: 3.8970823818599754
Validation loss: 3.3879502143671782

Epoch: 6| Step: 11
Training loss: 3.1662452986268548
Validation loss: 3.387692999869219

Epoch: 6| Step: 12
Training loss: 3.0441328180037512
Validation loss: 3.3862801883478864

Epoch: 6| Step: 13
Training loss: 4.30975387047477
Validation loss: 3.3856093167122774

Epoch: 24| Step: 0
Training loss: 3.0113694598238143
Validation loss: 3.3869307400645674

Epoch: 6| Step: 1
Training loss: 3.9787191302425957
Validation loss: 3.383601364978906

Epoch: 6| Step: 2
Training loss: 2.359914048617876
Validation loss: 3.3864470841749874

Epoch: 6| Step: 3
Training loss: 3.5004156410831206
Validation loss: 3.389202702917873

Epoch: 6| Step: 4
Training loss: 3.946667610331586
Validation loss: 3.38404912672677

Epoch: 6| Step: 5
Training loss: 3.567029649915524
Validation loss: 3.3807651770178864

Epoch: 6| Step: 6
Training loss: 4.547580520059626
Validation loss: 3.3850974069504396

Epoch: 6| Step: 7
Training loss: 3.3801052898733617
Validation loss: 3.382070417595254

Epoch: 6| Step: 8
Training loss: 2.9117155467579474
Validation loss: 3.379464980679019

Epoch: 6| Step: 9
Training loss: 4.34534957304787
Validation loss: 3.378926070719066

Epoch: 6| Step: 10
Training loss: 3.4475873499835505
Validation loss: 3.3775433217272868

Epoch: 6| Step: 11
Training loss: 3.3734230313293385
Validation loss: 3.3741917464619444

Epoch: 6| Step: 12
Training loss: 4.282438238603804
Validation loss: 3.378454800198986

Epoch: 6| Step: 13
Training loss: 2.931955664961745
Validation loss: 3.3794829911611894

Epoch: 25| Step: 0
Training loss: 3.320266543799609
Validation loss: 3.3833851837625577

Epoch: 6| Step: 1
Training loss: 2.836819430166488
Validation loss: 3.3822896358596917

Epoch: 6| Step: 2
Training loss: 3.3584218646954773
Validation loss: 3.3891041513205433

Epoch: 6| Step: 3
Training loss: 3.1468992806248917
Validation loss: 3.3727808986641654

Epoch: 6| Step: 4
Training loss: 3.765514451299686
Validation loss: 3.3709259403995167

Epoch: 6| Step: 5
Training loss: 4.583490033794399
Validation loss: 3.3678623670246766

Epoch: 6| Step: 6
Training loss: 3.6266834690836083
Validation loss: 3.3629526168762136

Epoch: 6| Step: 7
Training loss: 3.327943608888292
Validation loss: 3.3628677743427255

Epoch: 6| Step: 8
Training loss: 3.478170027531357
Validation loss: 3.3636867332169156

Epoch: 6| Step: 9
Training loss: 4.043732472400914
Validation loss: 3.368655522945301

Epoch: 6| Step: 10
Training loss: 3.314865563199721
Validation loss: 3.3667699353504776

Epoch: 6| Step: 11
Training loss: 3.419858294668835
Validation loss: 3.36522104497074

Epoch: 6| Step: 12
Training loss: 4.154136866262076
Validation loss: 3.3650514904359428

Epoch: 6| Step: 13
Training loss: 3.7060220066082117
Validation loss: 3.3576049796753917

Epoch: 26| Step: 0
Training loss: 3.62245825744125
Validation loss: 3.3600133618930474

Epoch: 6| Step: 1
Training loss: 3.4547076848828007
Validation loss: 3.3613922739757287

Epoch: 6| Step: 2
Training loss: 3.78865574492004
Validation loss: 3.3696556390351273

Epoch: 6| Step: 3
Training loss: 2.6059785770171002
Validation loss: 3.375584596162369

Epoch: 6| Step: 4
Training loss: 3.4807158959319504
Validation loss: 3.3747403490460766

Epoch: 6| Step: 5
Training loss: 4.633917794082503
Validation loss: 3.3719488272977975

Epoch: 6| Step: 6
Training loss: 3.1107663822676215
Validation loss: 3.3672865879754146

Epoch: 6| Step: 7
Training loss: 4.22189168863224
Validation loss: 3.364193248749887

Epoch: 6| Step: 8
Training loss: 3.3811098531564054
Validation loss: 3.3611554513210757

Epoch: 6| Step: 9
Training loss: 3.0474442952723657
Validation loss: 3.358001222043826

Epoch: 6| Step: 10
Training loss: 2.947802070753707
Validation loss: 3.363729974395935

Epoch: 6| Step: 11
Training loss: 3.6766431651282234
Validation loss: 3.358482886085539

Epoch: 6| Step: 12
Training loss: 4.436490011120775
Validation loss: 3.354723440399477

Epoch: 6| Step: 13
Training loss: 3.210892948481984
Validation loss: 3.3520338986812646

Epoch: 27| Step: 0
Training loss: 3.136294743631903
Validation loss: 3.353979051331646

Epoch: 6| Step: 1
Training loss: 3.4101807199061214
Validation loss: 3.3575279337776265

Epoch: 6| Step: 2
Training loss: 3.807538415485836
Validation loss: 3.345632523633314

Epoch: 6| Step: 3
Training loss: 3.925997083813463
Validation loss: 3.3450632630151658

Epoch: 6| Step: 4
Training loss: 4.544506386788399
Validation loss: 3.3439475779237013

Epoch: 6| Step: 5
Training loss: 4.315627139102701
Validation loss: 3.3425190526449473

Epoch: 6| Step: 6
Training loss: 2.6366616928143696
Validation loss: 3.343695285040097

Epoch: 6| Step: 7
Training loss: 2.9879501259048853
Validation loss: 3.3425415004996895

Epoch: 6| Step: 8
Training loss: 4.078338734371557
Validation loss: 3.3440715844844733

Epoch: 6| Step: 9
Training loss: 3.8342780041104447
Validation loss: 3.337541519305598

Epoch: 6| Step: 10
Training loss: 3.1919748647173436
Validation loss: 3.338210878597877

Epoch: 6| Step: 11
Training loss: 2.7444464353621965
Validation loss: 3.335904531538594

Epoch: 6| Step: 12
Training loss: 3.7799833083414973
Validation loss: 3.3350168012223573

Epoch: 6| Step: 13
Training loss: 2.7378525772531526
Validation loss: 3.3351007503256946

Epoch: 28| Step: 0
Training loss: 3.0002926047998226
Validation loss: 3.330836201092529

Epoch: 6| Step: 1
Training loss: 4.2008147857161715
Validation loss: 3.3327294638429716

Epoch: 6| Step: 2
Training loss: 3.9391450624389313
Validation loss: 3.32887434641625

Epoch: 6| Step: 3
Training loss: 3.095984066510661
Validation loss: 3.3255466485844165

Epoch: 6| Step: 4
Training loss: 4.090935824528437
Validation loss: 3.326624862137296

Epoch: 6| Step: 5
Training loss: 3.1078984574234845
Validation loss: 3.3185945532896954

Epoch: 6| Step: 6
Training loss: 4.304882896682602
Validation loss: 3.31586932102629

Epoch: 6| Step: 7
Training loss: 4.173078156328746
Validation loss: 3.313602483064738

Epoch: 6| Step: 8
Training loss: 3.776002126903258
Validation loss: 3.3117437491966815

Epoch: 6| Step: 9
Training loss: 3.2750067033771897
Validation loss: 3.3100526281577816

Epoch: 6| Step: 10
Training loss: 3.1631219666923807
Validation loss: 3.309664580173868

Epoch: 6| Step: 11
Training loss: 3.232515399421187
Validation loss: 3.3157552170959206

Epoch: 6| Step: 12
Training loss: 2.3738652580285904
Validation loss: 3.3156158565593765

Epoch: 6| Step: 13
Training loss: 3.4619750799012725
Validation loss: 3.3165945919535154

Epoch: 29| Step: 0
Training loss: 2.60893236620474
Validation loss: 3.307733968598992

Epoch: 6| Step: 1
Training loss: 3.680546557017588
Validation loss: 3.302168539949717

Epoch: 6| Step: 2
Training loss: 4.036509786298407
Validation loss: 3.302185753151083

Epoch: 6| Step: 3
Training loss: 3.8989187795902223
Validation loss: 3.304015093793485

Epoch: 6| Step: 4
Training loss: 4.053684705972404
Validation loss: 3.3064552516201915

Epoch: 6| Step: 5
Training loss: 3.8814483641030497
Validation loss: 3.3078937230898857

Epoch: 6| Step: 6
Training loss: 3.2241053796778383
Validation loss: 3.3044422083545144

Epoch: 6| Step: 7
Training loss: 3.5441484768853146
Validation loss: 3.298411317109534

Epoch: 6| Step: 8
Training loss: 3.3192860890545743
Validation loss: 3.2947322256621283

Epoch: 6| Step: 9
Training loss: 3.252080104972089
Validation loss: 3.2929782743947205

Epoch: 6| Step: 10
Training loss: 3.2503656034970105
Validation loss: 3.2921666634884033

Epoch: 6| Step: 11
Training loss: 3.2206995717081672
Validation loss: 3.2918776297474226

Epoch: 6| Step: 12
Training loss: 3.4427907282693244
Validation loss: 3.2926886734570173

Epoch: 6| Step: 13
Training loss: 4.141489075525289
Validation loss: 3.292597870414968

Epoch: 30| Step: 0
Training loss: 3.611500036048176
Validation loss: 3.291095263999838

Epoch: 6| Step: 1
Training loss: 2.7121949371506675
Validation loss: 3.289958399737077

Epoch: 6| Step: 2
Training loss: 3.7369266236052803
Validation loss: 3.2902613161010565

Epoch: 6| Step: 3
Training loss: 3.8385791267765232
Validation loss: 3.288031194455529

Epoch: 6| Step: 4
Training loss: 4.016206810508566
Validation loss: 3.2877696078608682

Epoch: 6| Step: 5
Training loss: 3.3160723730456136
Validation loss: 3.2844022907685804

Epoch: 6| Step: 6
Training loss: 3.7536333919760225
Validation loss: 3.2876987948186898

Epoch: 6| Step: 7
Training loss: 3.906766933569237
Validation loss: 3.283485711160139

Epoch: 6| Step: 8
Training loss: 2.4375689570136334
Validation loss: 3.2812491015048733

Epoch: 6| Step: 9
Training loss: 3.5295485727124127
Validation loss: 3.2809589575290694

Epoch: 6| Step: 10
Training loss: 3.9072648828100864
Validation loss: 3.2786384733673395

Epoch: 6| Step: 11
Training loss: 3.3612679759290036
Validation loss: 3.277913821830223

Epoch: 6| Step: 12
Training loss: 3.6710206681482576
Validation loss: 3.2794363342806068

Epoch: 6| Step: 13
Training loss: 2.9815020888489325
Validation loss: 3.280299374901457

Epoch: 31| Step: 0
Training loss: 3.583843076659484
Validation loss: 3.280550589295232

Epoch: 6| Step: 1
Training loss: 4.022794149868571
Validation loss: 3.283724545657241

Epoch: 6| Step: 2
Training loss: 3.1940037815021447
Validation loss: 3.2838645429339035

Epoch: 6| Step: 3
Training loss: 2.442277188402298
Validation loss: 3.2779319413615204

Epoch: 6| Step: 4
Training loss: 3.6294511236107314
Validation loss: 3.277565124912958

Epoch: 6| Step: 5
Training loss: 2.8592545947796526
Validation loss: 3.273580772144028

Epoch: 6| Step: 6
Training loss: 3.0095945157396073
Validation loss: 3.2748542954253326

Epoch: 6| Step: 7
Training loss: 3.195868184986757
Validation loss: 3.2718303820569385

Epoch: 6| Step: 8
Training loss: 4.29327041635161
Validation loss: 3.274647694900947

Epoch: 6| Step: 9
Training loss: 3.5746013499117653
Validation loss: 3.2719869267747863

Epoch: 6| Step: 10
Training loss: 3.3321643368973897
Validation loss: 3.272157453692249

Epoch: 6| Step: 11
Training loss: 3.9485712775214012
Validation loss: 3.2698535526815373

Epoch: 6| Step: 12
Training loss: 4.200031943426819
Validation loss: 3.271031460634207

Epoch: 6| Step: 13
Training loss: 3.4482868529835193
Validation loss: 3.268803567795842

Epoch: 32| Step: 0
Training loss: 3.897999098596131
Validation loss: 3.270645628957164

Epoch: 6| Step: 1
Training loss: 3.19619850615494
Validation loss: 3.268915248204269

Epoch: 6| Step: 2
Training loss: 3.4897108064209523
Validation loss: 3.268150341124494

Epoch: 6| Step: 3
Training loss: 3.4011604011844194
Validation loss: 3.268946581903455

Epoch: 6| Step: 4
Training loss: 3.6358131403817304
Validation loss: 3.2670393374183657

Epoch: 6| Step: 5
Training loss: 3.6682032631035266
Validation loss: 3.268551150148899

Epoch: 6| Step: 6
Training loss: 3.8065551936122772
Validation loss: 3.266209970694574

Epoch: 6| Step: 7
Training loss: 3.7733606682136647
Validation loss: 3.267773817334221

Epoch: 6| Step: 8
Training loss: 3.9642912080351125
Validation loss: 3.2632524652860417

Epoch: 6| Step: 9
Training loss: 3.498169829200787
Validation loss: 3.2628263718324755

Epoch: 6| Step: 10
Training loss: 3.4226747736530814
Validation loss: 3.2672671235079016

Epoch: 6| Step: 11
Training loss: 3.047203946085343
Validation loss: 3.263757775462396

Epoch: 6| Step: 12
Training loss: 2.625392702791731
Validation loss: 3.2611672962743703

Epoch: 6| Step: 13
Training loss: 3.508277233578333
Validation loss: 3.261149556051216

Epoch: 33| Step: 0
Training loss: 3.3510457242910103
Validation loss: 3.2639930958644685

Epoch: 6| Step: 1
Training loss: 3.1482599932514184
Validation loss: 3.2629917442260554

Epoch: 6| Step: 2
Training loss: 3.0815429300650647
Validation loss: 3.2701443150957012

Epoch: 6| Step: 3
Training loss: 3.7444197779999175
Validation loss: 3.2636355426924415

Epoch: 6| Step: 4
Training loss: 3.592849751372509
Validation loss: 3.2602920615876023

Epoch: 6| Step: 5
Training loss: 3.6398499281831422
Validation loss: 3.26170917205259

Epoch: 6| Step: 6
Training loss: 3.5449333085645502
Validation loss: 3.257656427819904

Epoch: 6| Step: 7
Training loss: 2.822006604409279
Validation loss: 3.2572034843627264

Epoch: 6| Step: 8
Training loss: 2.348746099138903
Validation loss: 3.2615354688244964

Epoch: 6| Step: 9
Training loss: 4.79184501426612
Validation loss: 3.2586106217116124

Epoch: 6| Step: 10
Training loss: 4.023482061343038
Validation loss: 3.257126404307216

Epoch: 6| Step: 11
Training loss: 3.5740465133107993
Validation loss: 3.257941831811849

Epoch: 6| Step: 12
Training loss: 3.624037253030457
Validation loss: 3.2567386355913786

Epoch: 6| Step: 13
Training loss: 2.9330999006965004
Validation loss: 3.256117483193437

Epoch: 34| Step: 0
Training loss: 3.955687766478995
Validation loss: 3.2616609171932085

Epoch: 6| Step: 1
Training loss: 3.8284417469006398
Validation loss: 3.2524499470008283

Epoch: 6| Step: 2
Training loss: 3.6656512819666696
Validation loss: 3.251673188053959

Epoch: 6| Step: 3
Training loss: 4.050920151156392
Validation loss: 3.2541114872302463

Epoch: 6| Step: 4
Training loss: 3.535715436178353
Validation loss: 3.249476588644624

Epoch: 6| Step: 5
Training loss: 3.583273036952199
Validation loss: 3.255232338831177

Epoch: 6| Step: 6
Training loss: 3.5290431325670353
Validation loss: 3.2604397154345253

Epoch: 6| Step: 7
Training loss: 3.614893010456987
Validation loss: 3.262089102453483

Epoch: 6| Step: 8
Training loss: 3.0855964568766834
Validation loss: 3.2680948993769685

Epoch: 6| Step: 9
Training loss: 2.578887086997589
Validation loss: 3.267747055608244

Epoch: 6| Step: 10
Training loss: 2.7586277089152977
Validation loss: 3.257385103111203

Epoch: 6| Step: 11
Training loss: 3.3069477693477918
Validation loss: 3.2587814222058413

Epoch: 6| Step: 12
Training loss: 3.7788626961113594
Validation loss: 3.259907147425025

Epoch: 6| Step: 13
Training loss: 3.287508708521691
Validation loss: 3.249562787037846

Epoch: 35| Step: 0
Training loss: 3.6888440802226055
Validation loss: 3.25058633770284

Epoch: 6| Step: 1
Training loss: 3.3597499904262143
Validation loss: 3.2500313093950663

Epoch: 6| Step: 2
Training loss: 2.5298412782841826
Validation loss: 3.254656271441338

Epoch: 6| Step: 3
Training loss: 3.261697698285358
Validation loss: 3.249988090487005

Epoch: 6| Step: 4
Training loss: 3.374214646128698
Validation loss: 3.255375909770127

Epoch: 6| Step: 5
Training loss: 3.0989701129251346
Validation loss: 3.2524061800958743

Epoch: 6| Step: 6
Training loss: 3.533129301718052
Validation loss: 3.2609769975330236

Epoch: 6| Step: 7
Training loss: 4.135951906762073
Validation loss: 3.254717327405388

Epoch: 6| Step: 8
Training loss: 3.8129103392857444
Validation loss: 3.243277648629704

Epoch: 6| Step: 9
Training loss: 3.2850364998890083
Validation loss: 3.2445336146099004

Epoch: 6| Step: 10
Training loss: 4.297483310988833
Validation loss: 3.24591772471114

Epoch: 6| Step: 11
Training loss: 2.813472240673746
Validation loss: 3.246062743806158

Epoch: 6| Step: 12
Training loss: 3.961961121123347
Validation loss: 3.24234428199656

Epoch: 6| Step: 13
Training loss: 3.2041475478165347
Validation loss: 3.243692208674944

Epoch: 36| Step: 0
Training loss: 4.0019297713142405
Validation loss: 3.2446232154180423

Epoch: 6| Step: 1
Training loss: 3.111930372209425
Validation loss: 3.2439310789339486

Epoch: 6| Step: 2
Training loss: 3.398342648640416
Validation loss: 3.242137619842673

Epoch: 6| Step: 3
Training loss: 4.011212132157191
Validation loss: 3.2395904327801204

Epoch: 6| Step: 4
Training loss: 4.077503610091304
Validation loss: 3.238309420558559

Epoch: 6| Step: 5
Training loss: 2.876013038287366
Validation loss: 3.2411688712627287

Epoch: 6| Step: 6
Training loss: 3.0435522496962095
Validation loss: 3.2376783235627453

Epoch: 6| Step: 7
Training loss: 3.556122542579459
Validation loss: 3.2407616791355567

Epoch: 6| Step: 8
Training loss: 3.4541356605699627
Validation loss: 3.2345489602598936

Epoch: 6| Step: 9
Training loss: 2.41750941435471
Validation loss: 3.2357428386341405

Epoch: 6| Step: 10
Training loss: 3.570287658471429
Validation loss: 3.239525585980765

Epoch: 6| Step: 11
Training loss: 3.979494943442297
Validation loss: 3.2412868537172983

Epoch: 6| Step: 12
Training loss: 3.7633685557426526
Validation loss: 3.239941175249133

Epoch: 6| Step: 13
Training loss: 2.811802756455534
Validation loss: 3.239579445697747

Epoch: 37| Step: 0
Training loss: 3.2981579349934345
Validation loss: 3.237329231737975

Epoch: 6| Step: 1
Training loss: 3.9830238594491756
Validation loss: 3.233211660638313

Epoch: 6| Step: 2
Training loss: 2.7803465843962716
Validation loss: 3.2316226750584574

Epoch: 6| Step: 3
Training loss: 2.9516927485405913
Validation loss: 3.230773210701483

Epoch: 6| Step: 4
Training loss: 3.18469413977481
Validation loss: 3.231853048593932

Epoch: 6| Step: 5
Training loss: 3.3145762720198655
Validation loss: 3.228090604080214

Epoch: 6| Step: 6
Training loss: 3.850969435276092
Validation loss: 3.2299662023292544

Epoch: 6| Step: 7
Training loss: 3.1102315211823774
Validation loss: 3.2297927635847126

Epoch: 6| Step: 8
Training loss: 3.745571828051332
Validation loss: 3.227934109825743

Epoch: 6| Step: 9
Training loss: 4.295392144700855
Validation loss: 3.2316981945835255

Epoch: 6| Step: 10
Training loss: 2.961150229670596
Validation loss: 3.227484488727463

Epoch: 6| Step: 11
Training loss: 3.2514392893598028
Validation loss: 3.2267315551198195

Epoch: 6| Step: 12
Training loss: 4.074721980996017
Validation loss: 3.2253279390540466

Epoch: 6| Step: 13
Training loss: 3.5346429778890167
Validation loss: 3.225649730915657

Epoch: 38| Step: 0
Training loss: 3.6059037067083786
Validation loss: 3.222115103344089

Epoch: 6| Step: 1
Training loss: 3.8767309937151735
Validation loss: 3.2245022199353786

Epoch: 6| Step: 2
Training loss: 3.1585043230967718
Validation loss: 3.226632236230743

Epoch: 6| Step: 3
Training loss: 3.1725335400599275
Validation loss: 3.228045928742394

Epoch: 6| Step: 4
Training loss: 3.6465935632002284
Validation loss: 3.226040376672241

Epoch: 6| Step: 5
Training loss: 3.633827248228884
Validation loss: 3.227413879670476

Epoch: 6| Step: 6
Training loss: 3.3643459712687234
Validation loss: 3.229196213432573

Epoch: 6| Step: 7
Training loss: 3.4348626857003612
Validation loss: 3.2254995243634506

Epoch: 6| Step: 8
Training loss: 3.747468602594183
Validation loss: 3.228820239699364

Epoch: 6| Step: 9
Training loss: 3.0371318264342984
Validation loss: 3.2300941577555675

Epoch: 6| Step: 10
Training loss: 2.9872425942079746
Validation loss: 3.2287392329743616

Epoch: 6| Step: 11
Training loss: 2.9290801779367084
Validation loss: 3.232750502364361

Epoch: 6| Step: 12
Training loss: 4.226187021214424
Validation loss: 3.2287930550650197

Epoch: 6| Step: 13
Training loss: 3.6563699816718622
Validation loss: 3.2228734538545796

Epoch: 39| Step: 0
Training loss: 3.371764716323797
Validation loss: 3.220273864708259

Epoch: 6| Step: 1
Training loss: 3.4216787900367707
Validation loss: 3.218277321952476

Epoch: 6| Step: 2
Training loss: 3.735905928021655
Validation loss: 3.2175111761132573

Epoch: 6| Step: 3
Training loss: 3.2496992118735184
Validation loss: 3.2195081239130974

Epoch: 6| Step: 4
Training loss: 3.739405607429475
Validation loss: 3.225629262416002

Epoch: 6| Step: 5
Training loss: 2.6078454748666515
Validation loss: 3.2184384612691406

Epoch: 6| Step: 6
Training loss: 3.3106824098822893
Validation loss: 3.21971380528884

Epoch: 6| Step: 7
Training loss: 2.93988978795669
Validation loss: 3.216323101686172

Epoch: 6| Step: 8
Training loss: 2.9106965862675502
Validation loss: 3.2160117758566593

Epoch: 6| Step: 9
Training loss: 3.7226775129737715
Validation loss: 3.2138824742213954

Epoch: 6| Step: 10
Training loss: 4.037529600997455
Validation loss: 3.2142333867478206

Epoch: 6| Step: 11
Training loss: 3.5243692794241954
Validation loss: 3.2115455376889503

Epoch: 6| Step: 12
Training loss: 4.068020165962641
Validation loss: 3.2123047713291615

Epoch: 6| Step: 13
Training loss: 3.6821164418156127
Validation loss: 3.2119573116323017

Epoch: 40| Step: 0
Training loss: 4.006279308194035
Validation loss: 3.2125992285095553

Epoch: 6| Step: 1
Training loss: 3.4993688831797094
Validation loss: 3.2112412338607563

Epoch: 6| Step: 2
Training loss: 3.4313496448382867
Validation loss: 3.2151963612198284

Epoch: 6| Step: 3
Training loss: 3.021560125504872
Validation loss: 3.2119545691696447

Epoch: 6| Step: 4
Training loss: 3.51018459258533
Validation loss: 3.217770245867749

Epoch: 6| Step: 5
Training loss: 3.345994997849633
Validation loss: 3.21222289719219

Epoch: 6| Step: 6
Training loss: 3.423890378204368
Validation loss: 3.2075559608940436

Epoch: 6| Step: 7
Training loss: 3.528893688923571
Validation loss: 3.2062008891525924

Epoch: 6| Step: 8
Training loss: 2.894606204484563
Validation loss: 3.2060468983459773

Epoch: 6| Step: 9
Training loss: 3.8850054621320544
Validation loss: 3.207436358822653

Epoch: 6| Step: 10
Training loss: 2.9775994364471967
Validation loss: 3.2068109697350753

Epoch: 6| Step: 11
Training loss: 3.950860019205619
Validation loss: 3.2003369018138734

Epoch: 6| Step: 12
Training loss: 3.2482526923853796
Validation loss: 3.200165196225793

Epoch: 6| Step: 13
Training loss: 3.46504150652005
Validation loss: 3.201706294736688

Epoch: 41| Step: 0
Training loss: 3.6370284361463154
Validation loss: 3.1999304727979196

Epoch: 6| Step: 1
Training loss: 2.6000502948298
Validation loss: 3.2038196913890897

Epoch: 6| Step: 2
Training loss: 3.142193606544756
Validation loss: 3.197903602260497

Epoch: 6| Step: 3
Training loss: 3.4725227802317606
Validation loss: 3.198221319149783

Epoch: 6| Step: 4
Training loss: 3.9250310228421683
Validation loss: 3.197537865943726

Epoch: 6| Step: 5
Training loss: 2.9492557750676727
Validation loss: 3.19897871601827

Epoch: 6| Step: 6
Training loss: 2.9145494315025564
Validation loss: 3.1991660458723254

Epoch: 6| Step: 7
Training loss: 3.946046666491467
Validation loss: 3.1991209650038535

Epoch: 6| Step: 8
Training loss: 2.4740518545577266
Validation loss: 3.1943050292274364

Epoch: 6| Step: 9
Training loss: 3.8221658217041705
Validation loss: 3.195110630879811

Epoch: 6| Step: 10
Training loss: 4.360989179479256
Validation loss: 3.194771366294351

Epoch: 6| Step: 11
Training loss: 3.029090347972744
Validation loss: 3.189679971316863

Epoch: 6| Step: 12
Training loss: 3.5885441765778747
Validation loss: 3.192450962547502

Epoch: 6| Step: 13
Training loss: 4.057922836525158
Validation loss: 3.1904879549303162

Epoch: 42| Step: 0
Training loss: 2.2543325037661637
Validation loss: 3.1906717827671427

Epoch: 6| Step: 1
Training loss: 3.230084360633115
Validation loss: 3.1920394455072616

Epoch: 6| Step: 2
Training loss: 3.8252193712145504
Validation loss: 3.191846884717445

Epoch: 6| Step: 3
Training loss: 3.45330589131335
Validation loss: 3.193893059975921

Epoch: 6| Step: 4
Training loss: 3.1659858038578585
Validation loss: 3.1923792549898233

Epoch: 6| Step: 5
Training loss: 3.3942765644082273
Validation loss: 3.193703391561406

Epoch: 6| Step: 6
Training loss: 3.5481841910288137
Validation loss: 3.18963406998147

Epoch: 6| Step: 7
Training loss: 3.704903348622179
Validation loss: 3.189630898416721

Epoch: 6| Step: 8
Training loss: 2.847457816035054
Validation loss: 3.188606660438737

Epoch: 6| Step: 9
Training loss: 3.929992785265175
Validation loss: 3.194280133532854

Epoch: 6| Step: 10
Training loss: 3.9219729954608336
Validation loss: 3.192452456989911

Epoch: 6| Step: 11
Training loss: 2.7456471065028123
Validation loss: 3.18551844869767

Epoch: 6| Step: 12
Training loss: 3.546413038645362
Validation loss: 3.1834532150513493

Epoch: 6| Step: 13
Training loss: 4.538056411466515
Validation loss: 3.1862930966278125

Epoch: 43| Step: 0
Training loss: 4.031615484658438
Validation loss: 3.191923571813118

Epoch: 6| Step: 1
Training loss: 2.7186948397949133
Validation loss: 3.1902240499438923

Epoch: 6| Step: 2
Training loss: 3.686516840846747
Validation loss: 3.1975567167418943

Epoch: 6| Step: 3
Training loss: 3.499042925087025
Validation loss: 3.1951776315541083

Epoch: 6| Step: 4
Training loss: 2.5494710411017625
Validation loss: 3.1882900760457904

Epoch: 6| Step: 5
Training loss: 4.3355591754994895
Validation loss: 3.186176487735419

Epoch: 6| Step: 6
Training loss: 3.8506654387240506
Validation loss: 3.1803853665808024

Epoch: 6| Step: 7
Training loss: 3.2282388318091018
Validation loss: 3.1787746151311453

Epoch: 6| Step: 8
Training loss: 3.558177936266714
Validation loss: 3.1751264565531723

Epoch: 6| Step: 9
Training loss: 4.418664636286482
Validation loss: 3.1766112758411533

Epoch: 6| Step: 10
Training loss: 2.5342055596885
Validation loss: 3.1735896861685573

Epoch: 6| Step: 11
Training loss: 3.6547200188855604
Validation loss: 3.179006647510334

Epoch: 6| Step: 12
Training loss: 2.43615568210373
Validation loss: 3.1799315619203457

Epoch: 6| Step: 13
Training loss: 1.8942909324264248
Validation loss: 3.183419749753443

Epoch: 44| Step: 0
Training loss: 3.306499011752715
Validation loss: 3.1872611972791804

Epoch: 6| Step: 1
Training loss: 3.049311363148852
Validation loss: 3.1819696387148073

Epoch: 6| Step: 2
Training loss: 3.4654991794376615
Validation loss: 3.176363504417654

Epoch: 6| Step: 3
Training loss: 2.954758772451881
Validation loss: 3.175690795044534

Epoch: 6| Step: 4
Training loss: 3.2486143826413887
Validation loss: 3.1727287921106355

Epoch: 6| Step: 5
Training loss: 3.1377381678912757
Validation loss: 3.1752750559545655

Epoch: 6| Step: 6
Training loss: 3.513079726411505
Validation loss: 3.1752911267316843

Epoch: 6| Step: 7
Training loss: 4.157293432520975
Validation loss: 3.171134362363166

Epoch: 6| Step: 8
Training loss: 3.2189778367672295
Validation loss: 3.1704112426238233

Epoch: 6| Step: 9
Training loss: 4.140714363717271
Validation loss: 3.1734162893858957

Epoch: 6| Step: 10
Training loss: 3.1864167410979403
Validation loss: 3.1717217795968513

Epoch: 6| Step: 11
Training loss: 3.4417903135932235
Validation loss: 3.171128747002357

Epoch: 6| Step: 12
Training loss: 3.9449714135510985
Validation loss: 3.167888615004635

Epoch: 6| Step: 13
Training loss: 2.385619164635365
Validation loss: 3.1698091767822496

Epoch: 45| Step: 0
Training loss: 3.0982428400601343
Validation loss: 3.1713663757546313

Epoch: 6| Step: 1
Training loss: 3.2132007947736754
Validation loss: 3.1692536176202695

Epoch: 6| Step: 2
Training loss: 2.9533349018078408
Validation loss: 3.1708088458069716

Epoch: 6| Step: 3
Training loss: 3.390542587474103
Validation loss: 3.169090977257665

Epoch: 6| Step: 4
Training loss: 3.3178030786005945
Validation loss: 3.177935580416702

Epoch: 6| Step: 5
Training loss: 3.6389203316945427
Validation loss: 3.168768223183044

Epoch: 6| Step: 6
Training loss: 3.7174898464779957
Validation loss: 3.166483424205987

Epoch: 6| Step: 7
Training loss: 3.35429644284235
Validation loss: 3.165719097496163

Epoch: 6| Step: 8
Training loss: 3.3836994373953186
Validation loss: 3.176745607422452

Epoch: 6| Step: 9
Training loss: 4.153589530092866
Validation loss: 3.1877161540236796

Epoch: 6| Step: 10
Training loss: 2.8707655530955227
Validation loss: 3.167672669974806

Epoch: 6| Step: 11
Training loss: 4.595056049723187
Validation loss: 3.1594610613323217

Epoch: 6| Step: 12
Training loss: 2.561050563362259
Validation loss: 3.1635889571762936

Epoch: 6| Step: 13
Training loss: 3.031658184451386
Validation loss: 3.1596890288477852

Epoch: 46| Step: 0
Training loss: 3.8293088989629394
Validation loss: 3.1640642549729425

Epoch: 6| Step: 1
Training loss: 3.2534498831191137
Validation loss: 3.170426695210067

Epoch: 6| Step: 2
Training loss: 2.7846327365905275
Validation loss: 3.177036208528324

Epoch: 6| Step: 3
Training loss: 3.531449033816343
Validation loss: 3.185387336116634

Epoch: 6| Step: 4
Training loss: 3.7137010423328007
Validation loss: 3.196958653232999

Epoch: 6| Step: 5
Training loss: 4.11810118871704
Validation loss: 3.1725414914943006

Epoch: 6| Step: 6
Training loss: 3.661710134487544
Validation loss: 3.163188857972963

Epoch: 6| Step: 7
Training loss: 3.3239163576107895
Validation loss: 3.16152072154383

Epoch: 6| Step: 8
Training loss: 3.7122999400683856
Validation loss: 3.1593297185783302

Epoch: 6| Step: 9
Training loss: 3.8939268509822806
Validation loss: 3.162933521711647

Epoch: 6| Step: 10
Training loss: 2.762356049252264
Validation loss: 3.1641621122146746

Epoch: 6| Step: 11
Training loss: 3.020520757529648
Validation loss: 3.166182220807344

Epoch: 6| Step: 12
Training loss: 2.754917949140072
Validation loss: 3.162010152145597

Epoch: 6| Step: 13
Training loss: 3.017982470634016
Validation loss: 3.1672953406357744

Epoch: 47| Step: 0
Training loss: 3.0441530246743964
Validation loss: 3.1635136140245863

Epoch: 6| Step: 1
Training loss: 3.24618981835505
Validation loss: 3.160925078408554

Epoch: 6| Step: 2
Training loss: 3.508826162437804
Validation loss: 3.158049906932192

Epoch: 6| Step: 3
Training loss: 2.588547970759636
Validation loss: 3.1578406167101774

Epoch: 6| Step: 4
Training loss: 3.877106370947992
Validation loss: 3.154900288142878

Epoch: 6| Step: 5
Training loss: 2.8018883468306637
Validation loss: 3.1546735568034214

Epoch: 6| Step: 6
Training loss: 3.6501097675696847
Validation loss: 3.153526050993768

Epoch: 6| Step: 7
Training loss: 3.126064882040761
Validation loss: 3.15202901665571

Epoch: 6| Step: 8
Training loss: 3.6979573565469686
Validation loss: 3.1531983150297886

Epoch: 6| Step: 9
Training loss: 4.076095134339906
Validation loss: 3.1549840545030334

Epoch: 6| Step: 10
Training loss: 3.2245280430574437
Validation loss: 3.15405629640431

Epoch: 6| Step: 11
Training loss: 3.6571054354524186
Validation loss: 3.152325975578129

Epoch: 6| Step: 12
Training loss: 2.969849553520251
Validation loss: 3.15583374696537

Epoch: 6| Step: 13
Training loss: 4.265354916472551
Validation loss: 3.1532357612819686

Epoch: 48| Step: 0
Training loss: 3.2266609232302326
Validation loss: 3.153724320219474

Epoch: 6| Step: 1
Training loss: 3.149377573674281
Validation loss: 3.150027567594224

Epoch: 6| Step: 2
Training loss: 3.107588825260634
Validation loss: 3.151520272484003

Epoch: 6| Step: 3
Training loss: 3.560872425591157
Validation loss: 3.1523859622238066

Epoch: 6| Step: 4
Training loss: 3.41141419515618
Validation loss: 3.153552619523392

Epoch: 6| Step: 5
Training loss: 3.2074522980304203
Validation loss: 3.150437448014517

Epoch: 6| Step: 6
Training loss: 3.006596941368543
Validation loss: 3.1514714310592837

Epoch: 6| Step: 7
Training loss: 3.483232798486858
Validation loss: 3.1512175949289354

Epoch: 6| Step: 8
Training loss: 3.7337700900548474
Validation loss: 3.1492941889422625

Epoch: 6| Step: 9
Training loss: 3.4777892959236074
Validation loss: 3.1482188755178577

Epoch: 6| Step: 10
Training loss: 2.9793319834121896
Validation loss: 3.146833877725747

Epoch: 6| Step: 11
Training loss: 3.028106160297189
Validation loss: 3.1476461061754786

Epoch: 6| Step: 12
Training loss: 4.302041682425811
Validation loss: 3.1452131930733955

Epoch: 6| Step: 13
Training loss: 3.9656540216536804
Validation loss: 3.1453603546360824

Epoch: 49| Step: 0
Training loss: 3.3563849338564773
Validation loss: 3.1442076267665757

Epoch: 6| Step: 1
Training loss: 3.7111081375242136
Validation loss: 3.143770353271395

Epoch: 6| Step: 2
Training loss: 3.398145641203173
Validation loss: 3.1411435992845274

Epoch: 6| Step: 3
Training loss: 4.170932163181665
Validation loss: 3.143486637906929

Epoch: 6| Step: 4
Training loss: 3.4684514097626864
Validation loss: 3.1394840331716374

Epoch: 6| Step: 5
Training loss: 3.8364842912781647
Validation loss: 3.136420946023066

Epoch: 6| Step: 6
Training loss: 2.8315563987680514
Validation loss: 3.1338152633505976

Epoch: 6| Step: 7
Training loss: 3.6569013748952064
Validation loss: 3.1329300755337375

Epoch: 6| Step: 8
Training loss: 3.103603815514596
Validation loss: 3.1297630296480405

Epoch: 6| Step: 9
Training loss: 3.211552544786525
Validation loss: 3.125590708697797

Epoch: 6| Step: 10
Training loss: 3.90660838199748
Validation loss: 3.122688641331503

Epoch: 6| Step: 11
Training loss: 2.7607633456973533
Validation loss: 3.1183997867711524

Epoch: 6| Step: 12
Training loss: 2.2598234414870415
Validation loss: 3.12296226923666

Epoch: 6| Step: 13
Training loss: 3.309064703236411
Validation loss: 3.1274553288313687

Epoch: 50| Step: 0
Training loss: 2.9505806109081796
Validation loss: 3.125868923837713

Epoch: 6| Step: 1
Training loss: 3.7773712693704122
Validation loss: 3.1165807203697775

Epoch: 6| Step: 2
Training loss: 3.313664213758752
Validation loss: 3.1134404902000994

Epoch: 6| Step: 3
Training loss: 2.8856805526941587
Validation loss: 3.112369931343218

Epoch: 6| Step: 4
Training loss: 3.136570985194822
Validation loss: 3.110012842159809

Epoch: 6| Step: 5
Training loss: 2.6079768472474614
Validation loss: 3.110601036593981

Epoch: 6| Step: 6
Training loss: 3.4384457760976215
Validation loss: 3.110778844565098

Epoch: 6| Step: 7
Training loss: 2.8152879248583997
Validation loss: 3.110337135169566

Epoch: 6| Step: 8
Training loss: 3.6936760599704104
Validation loss: 3.1063670565845856

Epoch: 6| Step: 9
Training loss: 3.0168916088000324
Validation loss: 3.106631671556666

Epoch: 6| Step: 10
Training loss: 3.32515157483166
Validation loss: 3.1044492546819407

Epoch: 6| Step: 11
Training loss: 4.388956968098715
Validation loss: 3.105299054668471

Epoch: 6| Step: 12
Training loss: 3.647261043928525
Validation loss: 3.101604792523871

Epoch: 6| Step: 13
Training loss: 4.079136982317193
Validation loss: 3.103942591019464

Epoch: 51| Step: 0
Training loss: 3.85805127381009
Validation loss: 3.1043327707194757

Epoch: 6| Step: 1
Training loss: 2.8137792433071076
Validation loss: 3.101492266041728

Epoch: 6| Step: 2
Training loss: 3.579027486869865
Validation loss: 3.1043427764186635

Epoch: 6| Step: 3
Training loss: 3.5817897636191045
Validation loss: 3.1017337940950727

Epoch: 6| Step: 4
Training loss: 3.581586337980858
Validation loss: 3.1053032147111215

Epoch: 6| Step: 5
Training loss: 2.276325083064601
Validation loss: 3.1039855192825825

Epoch: 6| Step: 6
Training loss: 3.358891509993039
Validation loss: 3.1033458170862156

Epoch: 6| Step: 7
Training loss: 3.393483165838041
Validation loss: 3.09937220341795

Epoch: 6| Step: 8
Training loss: 3.24625591878311
Validation loss: 3.0975870712503273

Epoch: 6| Step: 9
Training loss: 2.9564084161811275
Validation loss: 3.0982412861088884

Epoch: 6| Step: 10
Training loss: 3.808317297658959
Validation loss: 3.0966619296900713

Epoch: 6| Step: 11
Training loss: 2.64825681897163
Validation loss: 3.094472851025772

Epoch: 6| Step: 12
Training loss: 3.554064752713362
Validation loss: 3.097041694477081

Epoch: 6| Step: 13
Training loss: 4.288046905958492
Validation loss: 3.0941214422900467

Epoch: 52| Step: 0
Training loss: 4.136211533469894
Validation loss: 3.092721707083146

Epoch: 6| Step: 1
Training loss: 3.4506987596618224
Validation loss: 3.091940612459628

Epoch: 6| Step: 2
Training loss: 3.2199266375601683
Validation loss: 3.088101859947221

Epoch: 6| Step: 3
Training loss: 2.749021182559022
Validation loss: 3.0884876626592557

Epoch: 6| Step: 4
Training loss: 3.6634474118085705
Validation loss: 3.0901857446658294

Epoch: 6| Step: 5
Training loss: 3.344623772371257
Validation loss: 3.0882468020650227

Epoch: 6| Step: 6
Training loss: 3.6934527179092402
Validation loss: 3.088115252174204

Epoch: 6| Step: 7
Training loss: 2.914010627837165
Validation loss: 3.091304609346956

Epoch: 6| Step: 8
Training loss: 3.7791611127101095
Validation loss: 3.088366391332781

Epoch: 6| Step: 9
Training loss: 3.5463813068443666
Validation loss: 3.0860530949483915

Epoch: 6| Step: 10
Training loss: 3.2540689086557886
Validation loss: 3.0877422272120634

Epoch: 6| Step: 11
Training loss: 1.7840675022244215
Validation loss: 3.085444467354264

Epoch: 6| Step: 12
Training loss: 3.3770261263527184
Validation loss: 3.0840380915546217

Epoch: 6| Step: 13
Training loss: 3.486463391327226
Validation loss: 3.0858146488299876

Epoch: 53| Step: 0
Training loss: 3.2310666473135963
Validation loss: 3.082959850631676

Epoch: 6| Step: 1
Training loss: 3.364808837766192
Validation loss: 3.0862900116843726

Epoch: 6| Step: 2
Training loss: 3.5529036185378895
Validation loss: 3.085022556450297

Epoch: 6| Step: 3
Training loss: 2.877535489788982
Validation loss: 3.0830772094530925

Epoch: 6| Step: 4
Training loss: 3.3779271465731986
Validation loss: 3.083135507606868

Epoch: 6| Step: 5
Training loss: 3.4778710120896372
Validation loss: 3.082758962806065

Epoch: 6| Step: 6
Training loss: 3.8757729528515554
Validation loss: 3.082656340926164

Epoch: 6| Step: 7
Training loss: 4.086355738632681
Validation loss: 3.082853263813037

Epoch: 6| Step: 8
Training loss: 3.3899909626438003
Validation loss: 3.080573091703901

Epoch: 6| Step: 9
Training loss: 3.148448404525161
Validation loss: 3.081480689118946

Epoch: 6| Step: 10
Training loss: 2.6242834657285203
Validation loss: 3.079333009860998

Epoch: 6| Step: 11
Training loss: 3.1923262018439615
Validation loss: 3.0790629865259485

Epoch: 6| Step: 12
Training loss: 2.997945717959555
Validation loss: 3.0791104529229467

Epoch: 6| Step: 13
Training loss: 3.377332234765602
Validation loss: 3.078707670518895

Epoch: 54| Step: 0
Training loss: 3.513340050644458
Validation loss: 3.08050035524953

Epoch: 6| Step: 1
Training loss: 3.6661849716979775
Validation loss: 3.0847377161830734

Epoch: 6| Step: 2
Training loss: 3.3767746392247333
Validation loss: 3.0865964531521057

Epoch: 6| Step: 3
Training loss: 2.731802465924209
Validation loss: 3.0866218569232147

Epoch: 6| Step: 4
Training loss: 3.070521689706889
Validation loss: 3.082547930588415

Epoch: 6| Step: 5
Training loss: 2.4994076980852
Validation loss: 3.079955170796186

Epoch: 6| Step: 6
Training loss: 3.718493925622326
Validation loss: 3.0809211247101453

Epoch: 6| Step: 7
Training loss: 3.8048862663845906
Validation loss: 3.078334922996874

Epoch: 6| Step: 8
Training loss: 2.863428796398803
Validation loss: 3.0782105266523407

Epoch: 6| Step: 9
Training loss: 2.689013565034936
Validation loss: 3.0748250689947625

Epoch: 6| Step: 10
Training loss: 3.749418595065826
Validation loss: 3.077217254289375

Epoch: 6| Step: 11
Training loss: 3.018000640424151
Validation loss: 3.077705229333148

Epoch: 6| Step: 12
Training loss: 4.13209270706388
Validation loss: 3.0753634987222176

Epoch: 6| Step: 13
Training loss: 3.5371061395622974
Validation loss: 3.076653424796905

Epoch: 55| Step: 0
Training loss: 2.4603782381636163
Validation loss: 3.0761845791201656

Epoch: 6| Step: 1
Training loss: 4.335492305410475
Validation loss: 3.07456583715912

Epoch: 6| Step: 2
Training loss: 2.854249957649075
Validation loss: 3.0724030952808707

Epoch: 6| Step: 3
Training loss: 3.343206343617734
Validation loss: 3.0731863135401105

Epoch: 6| Step: 4
Training loss: 3.4604491843009204
Validation loss: 3.0729663564683967

Epoch: 6| Step: 5
Training loss: 3.2772625627794163
Validation loss: 3.0707729035840097

Epoch: 6| Step: 6
Training loss: 3.4640385703919474
Validation loss: 3.071349900687782

Epoch: 6| Step: 7
Training loss: 3.775343893189178
Validation loss: 3.0720887757089437

Epoch: 6| Step: 8
Training loss: 3.3451634922187066
Validation loss: 3.0726416543849546

Epoch: 6| Step: 9
Training loss: 3.388981011880881
Validation loss: 3.073132330555364

Epoch: 6| Step: 10
Training loss: 2.994029461712516
Validation loss: 3.07263257420399

Epoch: 6| Step: 11
Training loss: 2.3701696967684596
Validation loss: 3.0718745118201927

Epoch: 6| Step: 12
Training loss: 3.722944314544828
Validation loss: 3.072318488386209

Epoch: 6| Step: 13
Training loss: 3.438649072195566
Validation loss: 3.0783247411540824

Epoch: 56| Step: 0
Training loss: 3.965301577438546
Validation loss: 3.1065803154954206

Epoch: 6| Step: 1
Training loss: 3.454763722711112
Validation loss: 3.08076034010169

Epoch: 6| Step: 2
Training loss: 3.742431250420445
Validation loss: 3.074461097325993

Epoch: 6| Step: 3
Training loss: 3.3827671109649815
Validation loss: 3.086020183377152

Epoch: 6| Step: 4
Training loss: 3.2164416878512903
Validation loss: 3.0888695661685492

Epoch: 6| Step: 5
Training loss: 3.1278780082270767
Validation loss: 3.067461182082863

Epoch: 6| Step: 6
Training loss: 3.493815270975997
Validation loss: 3.068367510336421

Epoch: 6| Step: 7
Training loss: 2.8809136647426925
Validation loss: 3.0659697805746817

Epoch: 6| Step: 8
Training loss: 4.107273971644625
Validation loss: 3.064434800636702

Epoch: 6| Step: 9
Training loss: 2.4938388244565735
Validation loss: 3.0633002770193913

Epoch: 6| Step: 10
Training loss: 3.2412544838329627
Validation loss: 3.065348440860424

Epoch: 6| Step: 11
Training loss: 2.544319602683709
Validation loss: 3.065517692506285

Epoch: 6| Step: 12
Training loss: 3.016897140747281
Validation loss: 3.0625554059466036

Epoch: 6| Step: 13
Training loss: 3.7713449176783267
Validation loss: 3.064056717396002

Epoch: 57| Step: 0
Training loss: 3.349033780036663
Validation loss: 3.064246199058655

Epoch: 6| Step: 1
Training loss: 2.7754737793225557
Validation loss: 3.0610607633607936

Epoch: 6| Step: 2
Training loss: 3.5788770659896656
Validation loss: 3.062629234897085

Epoch: 6| Step: 3
Training loss: 3.999306380214843
Validation loss: 3.0607244230130743

Epoch: 6| Step: 4
Training loss: 2.9919487681159036
Validation loss: 3.0615398248685723

Epoch: 6| Step: 5
Training loss: 2.5716915431357408
Validation loss: 3.0595468090702087

Epoch: 6| Step: 6
Training loss: 3.573124885979451
Validation loss: 3.060921286160952

Epoch: 6| Step: 7
Training loss: 3.61447351528886
Validation loss: 3.0607981520658756

Epoch: 6| Step: 8
Training loss: 3.582863414617244
Validation loss: 3.0611594277321625

Epoch: 6| Step: 9
Training loss: 3.0723953753195823
Validation loss: 3.0607039086223007

Epoch: 6| Step: 10
Training loss: 3.9127728741828864
Validation loss: 3.0589726274595437

Epoch: 6| Step: 11
Training loss: 3.574276649548113
Validation loss: 3.060884891529387

Epoch: 6| Step: 12
Training loss: 2.3324436353474343
Validation loss: 3.0582225260332407

Epoch: 6| Step: 13
Training loss: 3.1080414485843275
Validation loss: 3.0598256159859414

Epoch: 58| Step: 0
Training loss: 3.3268301150647823
Validation loss: 3.0599582890734665

Epoch: 6| Step: 1
Training loss: 3.4624213144333806
Validation loss: 3.058973743771822

Epoch: 6| Step: 2
Training loss: 3.8181590620411394
Validation loss: 3.0631634975195485

Epoch: 6| Step: 3
Training loss: 3.710550838202892
Validation loss: 3.061985852509953

Epoch: 6| Step: 4
Training loss: 2.5317937949705667
Validation loss: 3.0614749899969134

Epoch: 6| Step: 5
Training loss: 3.7578495523446174
Validation loss: 3.0609096393229023

Epoch: 6| Step: 6
Training loss: 3.6409141851347755
Validation loss: 3.0645951769272513

Epoch: 6| Step: 7
Training loss: 3.5188156907774553
Validation loss: 3.057866636199631

Epoch: 6| Step: 8
Training loss: 2.960202088030062
Validation loss: 3.055834796006424

Epoch: 6| Step: 9
Training loss: 2.901006747480223
Validation loss: 3.0574566120440565

Epoch: 6| Step: 10
Training loss: 3.2149271067754994
Validation loss: 3.0545441161349736

Epoch: 6| Step: 11
Training loss: 2.738460692703954
Validation loss: 3.053701119339066

Epoch: 6| Step: 12
Training loss: 3.2089118601058106
Validation loss: 3.0538541556518317

Epoch: 6| Step: 13
Training loss: 3.4563100633696613
Validation loss: 3.053021766142473

Epoch: 59| Step: 0
Training loss: 3.649357355058481
Validation loss: 3.052672516647585

Epoch: 6| Step: 1
Training loss: 2.699444685449629
Validation loss: 3.0536242259704736

Epoch: 6| Step: 2
Training loss: 3.376588659436713
Validation loss: 3.0513705382630794

Epoch: 6| Step: 3
Training loss: 2.6941805466698403
Validation loss: 3.0508458566838152

Epoch: 6| Step: 4
Training loss: 3.5896588465710253
Validation loss: 3.050372728354558

Epoch: 6| Step: 5
Training loss: 3.6021378527182093
Validation loss: 3.0523942296753517

Epoch: 6| Step: 6
Training loss: 3.836085423493952
Validation loss: 3.0496525130616186

Epoch: 6| Step: 7
Training loss: 3.974341351144242
Validation loss: 3.052322892911782

Epoch: 6| Step: 8
Training loss: 3.60106306274755
Validation loss: 3.0534597421607317

Epoch: 6| Step: 9
Training loss: 2.7650531242192504
Validation loss: 3.0530300649453985

Epoch: 6| Step: 10
Training loss: 3.0262556323220027
Validation loss: 3.0499339526398583

Epoch: 6| Step: 11
Training loss: 3.6244972143405896
Validation loss: 3.0538868212101082

Epoch: 6| Step: 12
Training loss: 2.5712514165374607
Validation loss: 3.0487513080173962

Epoch: 6| Step: 13
Training loss: 2.6805342067819296
Validation loss: 3.04312250378985

Epoch: 60| Step: 0
Training loss: 3.736374834310099
Validation loss: 3.0450399816956057

Epoch: 6| Step: 1
Training loss: 3.1031420934845952
Validation loss: 3.0455367219055542

Epoch: 6| Step: 2
Training loss: 3.4130844007060204
Validation loss: 3.046457719481455

Epoch: 6| Step: 3
Training loss: 3.418128762995549
Validation loss: 3.052546307746831

Epoch: 6| Step: 4
Training loss: 2.868081600470176
Validation loss: 3.049577819321926

Epoch: 6| Step: 5
Training loss: 3.6427158360362637
Validation loss: 3.053148728726205

Epoch: 6| Step: 6
Training loss: 2.757765729037487
Validation loss: 3.0452021421465716

Epoch: 6| Step: 7
Training loss: 3.230012614695006
Validation loss: 3.046484970989489

Epoch: 6| Step: 8
Training loss: 3.3991828890263194
Validation loss: 3.0463469555473646

Epoch: 6| Step: 9
Training loss: 3.5909454016830513
Validation loss: 3.043001608231697

Epoch: 6| Step: 10
Training loss: 3.000399404005595
Validation loss: 3.046978948148862

Epoch: 6| Step: 11
Training loss: 2.5537128980931767
Validation loss: 3.0433981183381005

Epoch: 6| Step: 12
Training loss: 3.09083527716559
Validation loss: 3.045144635679069

Epoch: 6| Step: 13
Training loss: 4.844424686819338
Validation loss: 3.043673007147377

Epoch: 61| Step: 0
Training loss: 3.4830377176472997
Validation loss: 3.0431008244249775

Epoch: 6| Step: 1
Training loss: 3.2434883908892744
Validation loss: 3.0438047882321917

Epoch: 6| Step: 2
Training loss: 3.4737818881421263
Validation loss: 3.040840957793868

Epoch: 6| Step: 3
Training loss: 3.362157760277271
Validation loss: 3.0414704270608266

Epoch: 6| Step: 4
Training loss: 3.3218347268879573
Validation loss: 3.042330253273625

Epoch: 6| Step: 5
Training loss: 3.4345092247375213
Validation loss: 3.040048380862371

Epoch: 6| Step: 6
Training loss: 3.358053115879042
Validation loss: 3.0398657846669095

Epoch: 6| Step: 7
Training loss: 3.347838282226373
Validation loss: 3.0397192254958827

Epoch: 6| Step: 8
Training loss: 3.4664832604627356
Validation loss: 3.0389807407756737

Epoch: 6| Step: 9
Training loss: 3.4329973729271064
Validation loss: 3.0402437259534763

Epoch: 6| Step: 10
Training loss: 3.513904472654932
Validation loss: 3.0388469282690527

Epoch: 6| Step: 11
Training loss: 1.9968335596599258
Validation loss: 3.0374537133709683

Epoch: 6| Step: 12
Training loss: 3.7859103905198794
Validation loss: 3.0367565285463676

Epoch: 6| Step: 13
Training loss: 2.180986680365761
Validation loss: 3.0390135493328514

Epoch: 62| Step: 0
Training loss: 3.6338133386971276
Validation loss: 3.036399078480478

Epoch: 6| Step: 1
Training loss: 3.3561273534660607
Validation loss: 3.0349780610683594

Epoch: 6| Step: 2
Training loss: 3.684442578085056
Validation loss: 3.034376468174195

Epoch: 6| Step: 3
Training loss: 3.7872408233698605
Validation loss: 3.0346806654129383

Epoch: 6| Step: 4
Training loss: 3.616309963748441
Validation loss: 3.0332451603594093

Epoch: 6| Step: 5
Training loss: 3.237290989083009
Validation loss: 3.0341973040414

Epoch: 6| Step: 6
Training loss: 3.1614273966365416
Validation loss: 3.0336513532652924

Epoch: 6| Step: 7
Training loss: 2.9540016447461714
Validation loss: 3.033377288825325

Epoch: 6| Step: 8
Training loss: 2.5088821934348906
Validation loss: 3.035171842174068

Epoch: 6| Step: 9
Training loss: 2.8371715540416282
Validation loss: 3.0302666711070927

Epoch: 6| Step: 10
Training loss: 3.7963697309205933
Validation loss: 3.030015323338492

Epoch: 6| Step: 11
Training loss: 3.1333409194313364
Validation loss: 3.0304282753102694

Epoch: 6| Step: 12
Training loss: 3.3007439786172346
Validation loss: 3.029600536372234

Epoch: 6| Step: 13
Training loss: 2.660908820848368
Validation loss: 3.028227183211662

Epoch: 63| Step: 0
Training loss: 3.512570966227678
Validation loss: 3.0273249003881713

Epoch: 6| Step: 1
Training loss: 3.279257905329797
Validation loss: 3.0273284731772887

Epoch: 6| Step: 2
Training loss: 2.3036775089311066
Validation loss: 3.025098100368361

Epoch: 6| Step: 3
Training loss: 3.258699218682104
Validation loss: 3.02634300349839

Epoch: 6| Step: 4
Training loss: 2.9525478545856227
Validation loss: 3.0230871740963137

Epoch: 6| Step: 5
Training loss: 3.3531698005292903
Validation loss: 3.020137866072695

Epoch: 6| Step: 6
Training loss: 2.951522796186106
Validation loss: 3.0207189049580996

Epoch: 6| Step: 7
Training loss: 2.7674597564776158
Validation loss: 3.0208604861613746

Epoch: 6| Step: 8
Training loss: 4.131005048775987
Validation loss: 3.0199114101677664

Epoch: 6| Step: 9
Training loss: 3.4176113094349874
Validation loss: 3.0182292714242323

Epoch: 6| Step: 10
Training loss: 3.9999352688320085
Validation loss: 3.018742662700844

Epoch: 6| Step: 11
Training loss: 2.805210755398273
Validation loss: 3.0191575734365363

Epoch: 6| Step: 12
Training loss: 3.571163952424707
Validation loss: 3.015367390985375

Epoch: 6| Step: 13
Training loss: 3.3895444774373984
Validation loss: 3.018999024145155

Epoch: 64| Step: 0
Training loss: 2.668409453558584
Validation loss: 3.018067185603289

Epoch: 6| Step: 1
Training loss: 2.6800384736502125
Validation loss: 3.0174122013243156

Epoch: 6| Step: 2
Training loss: 3.1327978880581933
Validation loss: 3.016457565750808

Epoch: 6| Step: 3
Training loss: 2.6248800159462555
Validation loss: 3.0236024622107065

Epoch: 6| Step: 4
Training loss: 2.9059492386272043
Validation loss: 3.0236148293080034

Epoch: 6| Step: 5
Training loss: 3.9265760234048854
Validation loss: 3.036564250035857

Epoch: 6| Step: 6
Training loss: 4.09497331584951
Validation loss: 3.0398265050058506

Epoch: 6| Step: 7
Training loss: 2.9391359684069895
Validation loss: 3.038102566050063

Epoch: 6| Step: 8
Training loss: 3.468410440956848
Validation loss: 3.027505398449431

Epoch: 6| Step: 9
Training loss: 3.2659590700835395
Validation loss: 3.0216368404701215

Epoch: 6| Step: 10
Training loss: 3.618713057202609
Validation loss: 3.0172973990734677

Epoch: 6| Step: 11
Training loss: 3.4942803650788226
Validation loss: 3.01594952743446

Epoch: 6| Step: 12
Training loss: 3.5272418204922515
Validation loss: 3.0128991071431312

Epoch: 6| Step: 13
Training loss: 3.3698092916618307
Validation loss: 3.0146355948139796

Epoch: 65| Step: 0
Training loss: 2.801038573293986
Validation loss: 3.015076925119831

Epoch: 6| Step: 1
Training loss: 3.64674197545185
Validation loss: 3.017383413659846

Epoch: 6| Step: 2
Training loss: 3.5918228953312523
Validation loss: 3.0182512602398752

Epoch: 6| Step: 3
Training loss: 4.19815870522807
Validation loss: 3.0160440762333827

Epoch: 6| Step: 4
Training loss: 3.565506987829533
Validation loss: 3.009294814292498

Epoch: 6| Step: 5
Training loss: 3.3586146714064014
Validation loss: 3.014344169679802

Epoch: 6| Step: 6
Training loss: 2.7464439635436317
Validation loss: 3.009128541220447

Epoch: 6| Step: 7
Training loss: 3.0126661895877636
Validation loss: 3.0079922291445955

Epoch: 6| Step: 8
Training loss: 3.2526895691548208
Validation loss: 3.007950249980087

Epoch: 6| Step: 9
Training loss: 3.582408756177593
Validation loss: 3.0070037406506

Epoch: 6| Step: 10
Training loss: 3.0390998426168156
Validation loss: 3.0162404183853644

Epoch: 6| Step: 11
Training loss: 2.890698406215322
Validation loss: 3.0181153700567407

Epoch: 6| Step: 12
Training loss: 2.6147835238188124
Validation loss: 3.0235399018642615

Epoch: 6| Step: 13
Training loss: 3.329187214723911
Validation loss: 3.0234982242068136

Epoch: 66| Step: 0
Training loss: 3.3279759906489614
Validation loss: 3.019613460279199

Epoch: 6| Step: 1
Training loss: 3.1263013037643934
Validation loss: 3.0102236376764586

Epoch: 6| Step: 2
Training loss: 3.472613271097579
Validation loss: 3.0068383162644863

Epoch: 6| Step: 3
Training loss: 2.860397406224038
Validation loss: 3.00648900822594

Epoch: 6| Step: 4
Training loss: 3.4457676731728317
Validation loss: 3.0065120072292806

Epoch: 6| Step: 5
Training loss: 3.2854625001240967
Validation loss: 3.015375233144358

Epoch: 6| Step: 6
Training loss: 3.3323180241847625
Validation loss: 3.008521309010671

Epoch: 6| Step: 7
Training loss: 3.4370186208576277
Validation loss: 3.0086922611741125

Epoch: 6| Step: 8
Training loss: 3.5620124884873228
Validation loss: 3.003413619358589

Epoch: 6| Step: 9
Training loss: 3.455374834896178
Validation loss: 3.0039851294597146

Epoch: 6| Step: 10
Training loss: 3.1724687593693974
Validation loss: 3.0072473888744353

Epoch: 6| Step: 11
Training loss: 3.088279434230588
Validation loss: 3.0087092438938003

Epoch: 6| Step: 12
Training loss: 2.966003432412711
Validation loss: 3.009454204508746

Epoch: 6| Step: 13
Training loss: 3.3511259777280107
Validation loss: 3.0156409464933125

Epoch: 67| Step: 0
Training loss: 3.079102027087263
Validation loss: 3.009819386802288

Epoch: 6| Step: 1
Training loss: 3.7430198556066108
Validation loss: 3.0074856138744104

Epoch: 6| Step: 2
Training loss: 3.549568397182172
Validation loss: 3.0069224602239824

Epoch: 6| Step: 3
Training loss: 3.810652613578103
Validation loss: 3.0013210488310245

Epoch: 6| Step: 4
Training loss: 2.430703101145421
Validation loss: 3.003298494555005

Epoch: 6| Step: 5
Training loss: 3.5845960713518306
Validation loss: 3.0015988259695847

Epoch: 6| Step: 6
Training loss: 2.889566588588201
Validation loss: 2.9987447925906383

Epoch: 6| Step: 7
Training loss: 3.5214880310141172
Validation loss: 2.9990543956875517

Epoch: 6| Step: 8
Training loss: 2.9892479224354522
Validation loss: 2.9968012810085614

Epoch: 6| Step: 9
Training loss: 2.5978966164344177
Validation loss: 2.997921157600154

Epoch: 6| Step: 10
Training loss: 3.645534626667726
Validation loss: 3.0010103691429215

Epoch: 6| Step: 11
Training loss: 3.0799141733175683
Validation loss: 2.998747673617664

Epoch: 6| Step: 12
Training loss: 3.003266463584932
Validation loss: 2.9999645395131553

Epoch: 6| Step: 13
Training loss: 3.7671048750611487
Validation loss: 2.998848388137335

Epoch: 68| Step: 0
Training loss: 3.7015439291891155
Validation loss: 2.9964989722127093

Epoch: 6| Step: 1
Training loss: 3.5564413920893188
Validation loss: 2.9944756636574827

Epoch: 6| Step: 2
Training loss: 2.540987945570083
Validation loss: 2.9958732585775847

Epoch: 6| Step: 3
Training loss: 2.9020920409441406
Validation loss: 2.9921587755205032

Epoch: 6| Step: 4
Training loss: 2.889294127220153
Validation loss: 2.9931927190908154

Epoch: 6| Step: 5
Training loss: 3.457256624450891
Validation loss: 2.991423689387959

Epoch: 6| Step: 6
Training loss: 3.765977012041445
Validation loss: 2.9917374006260298

Epoch: 6| Step: 7
Training loss: 2.6116748656643445
Validation loss: 2.9931922942715787

Epoch: 6| Step: 8
Training loss: 3.8738182480872623
Validation loss: 2.99237272540214

Epoch: 6| Step: 9
Training loss: 2.440244938641444
Validation loss: 2.9929083507912995

Epoch: 6| Step: 10
Training loss: 3.074698152691346
Validation loss: 2.9900461491591406

Epoch: 6| Step: 11
Training loss: 3.5292649893067103
Validation loss: 2.991069886459743

Epoch: 6| Step: 12
Training loss: 3.624413804637392
Validation loss: 2.989502219286367

Epoch: 6| Step: 13
Training loss: 3.3874543303053968
Validation loss: 2.9916571467841098

Epoch: 69| Step: 0
Training loss: 2.9754918693594212
Validation loss: 2.988858594784216

Epoch: 6| Step: 1
Training loss: 3.1779402447526843
Validation loss: 2.990076246884541

Epoch: 6| Step: 2
Training loss: 3.432726788568536
Validation loss: 2.9888469424678497

Epoch: 6| Step: 3
Training loss: 3.478136439274624
Validation loss: 2.9891309904387957

Epoch: 6| Step: 4
Training loss: 3.1107648494065288
Validation loss: 2.986811161488446

Epoch: 6| Step: 5
Training loss: 3.2720706972258475
Validation loss: 2.987060009074901

Epoch: 6| Step: 6
Training loss: 2.718009497108737
Validation loss: 2.987131728632207

Epoch: 6| Step: 7
Training loss: 3.7507203999600875
Validation loss: 2.9875812278685814

Epoch: 6| Step: 8
Training loss: 2.8562444841260675
Validation loss: 2.987044996549358

Epoch: 6| Step: 9
Training loss: 3.859988762241272
Validation loss: 2.9844691970322987

Epoch: 6| Step: 10
Training loss: 3.165206438657107
Validation loss: 2.9854667241752813

Epoch: 6| Step: 11
Training loss: 3.061434813559776
Validation loss: 2.9824611559881276

Epoch: 6| Step: 12
Training loss: 3.758641776026053
Validation loss: 2.9829687898691115

Epoch: 6| Step: 13
Training loss: 2.359361762205465
Validation loss: 2.9820570506063078

Epoch: 70| Step: 0
Training loss: 3.4406686223978085
Validation loss: 2.98343293484391

Epoch: 6| Step: 1
Training loss: 3.6459865138253846
Validation loss: 2.984876076393667

Epoch: 6| Step: 2
Training loss: 2.8156565436862455
Validation loss: 2.9843094250566407

Epoch: 6| Step: 3
Training loss: 2.5756486501628464
Validation loss: 2.9835369976103316

Epoch: 6| Step: 4
Training loss: 3.197000444771954
Validation loss: 2.9840608927693877

Epoch: 6| Step: 5
Training loss: 3.89681881494712
Validation loss: 2.9864805370948857

Epoch: 6| Step: 6
Training loss: 3.5424941648275037
Validation loss: 2.9822922126062026

Epoch: 6| Step: 7
Training loss: 3.2850286615477104
Validation loss: 2.9817102320322926

Epoch: 6| Step: 8
Training loss: 2.872479868420738
Validation loss: 2.9798362668425775

Epoch: 6| Step: 9
Training loss: 3.0530183334224947
Validation loss: 2.97880113835991

Epoch: 6| Step: 10
Training loss: 3.7028929561232036
Validation loss: 2.98200222947581

Epoch: 6| Step: 11
Training loss: 3.336362003234358
Validation loss: 2.9803543379588513

Epoch: 6| Step: 12
Training loss: 3.219846816358348
Validation loss: 2.981785380053078

Epoch: 6| Step: 13
Training loss: 2.310275373848112
Validation loss: 2.9809426738469216

Epoch: 71| Step: 0
Training loss: 3.3815557598980686
Validation loss: 2.980250302555828

Epoch: 6| Step: 1
Training loss: 3.7527619681004536
Validation loss: 2.9826313412666354

Epoch: 6| Step: 2
Training loss: 3.6625003697522076
Validation loss: 2.9822024668367013

Epoch: 6| Step: 3
Training loss: 2.5768255484658953
Validation loss: 2.978864225190632

Epoch: 6| Step: 4
Training loss: 2.856240143539818
Validation loss: 2.9804026349436326

Epoch: 6| Step: 5
Training loss: 2.954364496304809
Validation loss: 2.980589777077624

Epoch: 6| Step: 6
Training loss: 3.7599827453542027
Validation loss: 2.981821796121256

Epoch: 6| Step: 7
Training loss: 3.288175993485711
Validation loss: 2.980604619131034

Epoch: 6| Step: 8
Training loss: 2.7450021063513397
Validation loss: 2.978930169570152

Epoch: 6| Step: 9
Training loss: 2.5124052305045947
Validation loss: 2.9789164964682078

Epoch: 6| Step: 10
Training loss: 4.2617581345567865
Validation loss: 2.9778408631757407

Epoch: 6| Step: 11
Training loss: 3.0822215438520546
Validation loss: 2.9783622337744338

Epoch: 6| Step: 12
Training loss: 2.819579644764259
Validation loss: 2.9784812101396243

Epoch: 6| Step: 13
Training loss: 3.602905023217132
Validation loss: 2.977662996435831

Epoch: 72| Step: 0
Training loss: 3.162846385697776
Validation loss: 2.9773275752771564

Epoch: 6| Step: 1
Training loss: 2.769312410088542
Validation loss: 2.9739149068295956

Epoch: 6| Step: 2
Training loss: 3.695655468112424
Validation loss: 2.977327190385871

Epoch: 6| Step: 3
Training loss: 3.743750259832459
Validation loss: 2.9735689361741744

Epoch: 6| Step: 4
Training loss: 3.6988949336888104
Validation loss: 2.975156116396441

Epoch: 6| Step: 5
Training loss: 3.246972361069586
Validation loss: 2.9746304383220705

Epoch: 6| Step: 6
Training loss: 3.3445102861188927
Validation loss: 2.974541419776204

Epoch: 6| Step: 7
Training loss: 2.61855669787627
Validation loss: 2.9752077048940375

Epoch: 6| Step: 8
Training loss: 3.2116665720151905
Validation loss: 2.9782753065646634

Epoch: 6| Step: 9
Training loss: 3.2299715741208788
Validation loss: 2.975867440068125

Epoch: 6| Step: 10
Training loss: 2.8926902198064126
Validation loss: 2.9764361809184625

Epoch: 6| Step: 11
Training loss: 3.0211434742239076
Validation loss: 2.9735535675793825

Epoch: 6| Step: 12
Training loss: 3.5290752904983282
Validation loss: 2.9747544727535478

Epoch: 6| Step: 13
Training loss: 2.9905537659583055
Validation loss: 2.9777287384080284

Epoch: 73| Step: 0
Training loss: 2.4006402155188633
Validation loss: 2.9765358339268855

Epoch: 6| Step: 1
Training loss: 2.754427986232632
Validation loss: 2.984050469152955

Epoch: 6| Step: 2
Training loss: 4.15050850016435
Validation loss: 3.001316245825084

Epoch: 6| Step: 3
Training loss: 3.12278088933375
Validation loss: 3.0015601046186444

Epoch: 6| Step: 4
Training loss: 2.5628695337828615
Validation loss: 2.9779461070567783

Epoch: 6| Step: 5
Training loss: 3.2098862163781954
Validation loss: 2.9737903011677282

Epoch: 6| Step: 6
Training loss: 3.121071749766016
Validation loss: 2.96795447441397

Epoch: 6| Step: 7
Training loss: 4.204309686522336
Validation loss: 2.9654412198892324

Epoch: 6| Step: 8
Training loss: 3.357870785370199
Validation loss: 2.9642580215690164

Epoch: 6| Step: 9
Training loss: 3.6611548235117883
Validation loss: 2.9617371106769985

Epoch: 6| Step: 10
Training loss: 3.0477764654517916
Validation loss: 2.9644141736018654

Epoch: 6| Step: 11
Training loss: 3.4667807823130015
Validation loss: 2.967302545723198

Epoch: 6| Step: 12
Training loss: 2.8213165271302945
Validation loss: 2.9710978715730443

Epoch: 6| Step: 13
Training loss: 2.8115744021355535
Validation loss: 2.9717775262376027

Epoch: 74| Step: 0
Training loss: 3.604791546639911
Validation loss: 2.9700191666974978

Epoch: 6| Step: 1
Training loss: 3.483146690466764
Validation loss: 2.9668132584917886

Epoch: 6| Step: 2
Training loss: 2.646927574743499
Validation loss: 2.9603442504359427

Epoch: 6| Step: 3
Training loss: 3.2878814533980876
Validation loss: 2.9565568784225293

Epoch: 6| Step: 4
Training loss: 2.1751151306549277
Validation loss: 2.957547813323546

Epoch: 6| Step: 5
Training loss: 2.7255914483720263
Validation loss: 2.958302208405827

Epoch: 6| Step: 6
Training loss: 3.7093026826617375
Validation loss: 2.953323611935563

Epoch: 6| Step: 7
Training loss: 3.23308327353523
Validation loss: 2.953375361313961

Epoch: 6| Step: 8
Training loss: 2.257040980956167
Validation loss: 2.953332082381993

Epoch: 6| Step: 9
Training loss: 3.0399418125105138
Validation loss: 2.9554067611043147

Epoch: 6| Step: 10
Training loss: 4.363984108564637
Validation loss: 2.9534138550551314

Epoch: 6| Step: 11
Training loss: 2.9795598835414223
Validation loss: 2.9583684577457015

Epoch: 6| Step: 12
Training loss: 3.3847722462337866
Validation loss: 2.9578178149550336

Epoch: 6| Step: 13
Training loss: 4.183176570148697
Validation loss: 2.9563010822478826

Epoch: 75| Step: 0
Training loss: 2.9977141254674944
Validation loss: 2.9558417073271093

Epoch: 6| Step: 1
Training loss: 3.2333239630599433
Validation loss: 2.9521718320570587

Epoch: 6| Step: 2
Training loss: 3.186918467412075
Validation loss: 2.9495184663706007

Epoch: 6| Step: 3
Training loss: 3.0939275517232945
Validation loss: 2.951340058172297

Epoch: 6| Step: 4
Training loss: 2.6012275182292335
Validation loss: 2.947595980139317

Epoch: 6| Step: 5
Training loss: 3.340107582780947
Validation loss: 2.947434737333547

Epoch: 6| Step: 6
Training loss: 4.108561968422073
Validation loss: 2.945699646798283

Epoch: 6| Step: 7
Training loss: 4.115432973450055
Validation loss: 2.944758739428307

Epoch: 6| Step: 8
Training loss: 2.9941270881441384
Validation loss: 2.942356478801689

Epoch: 6| Step: 9
Training loss: 2.9476957923629032
Validation loss: 2.9423827096889044

Epoch: 6| Step: 10
Training loss: 2.9894981948124855
Validation loss: 2.939071978222903

Epoch: 6| Step: 11
Training loss: 3.35753066423151
Validation loss: 2.9398530966436525

Epoch: 6| Step: 12
Training loss: 3.116093570288599
Validation loss: 2.9375224063518823

Epoch: 6| Step: 13
Training loss: 2.2659920230735175
Validation loss: 2.938957645137094

Epoch: 76| Step: 0
Training loss: 3.317221677211476
Validation loss: 2.93788785169595

Epoch: 6| Step: 1
Training loss: 3.278820046343085
Validation loss: 2.939368476503282

Epoch: 6| Step: 2
Training loss: 2.8839554007225794
Validation loss: 2.9358488935144194

Epoch: 6| Step: 3
Training loss: 4.142802806554295
Validation loss: 2.9380402776152725

Epoch: 6| Step: 4
Training loss: 2.907351705454465
Validation loss: 2.936502194252824

Epoch: 6| Step: 5
Training loss: 2.844475622138711
Validation loss: 2.933380343343899

Epoch: 6| Step: 6
Training loss: 3.046488106445657
Validation loss: 2.9303299061868096

Epoch: 6| Step: 7
Training loss: 3.503019937374126
Validation loss: 2.93340055434355

Epoch: 6| Step: 8
Training loss: 2.7565156735078937
Validation loss: 2.9300612607055787

Epoch: 6| Step: 9
Training loss: 3.313128285833664
Validation loss: 2.929614172889472

Epoch: 6| Step: 10
Training loss: 2.5574571254264997
Validation loss: 2.927544235910122

Epoch: 6| Step: 11
Training loss: 2.977095428577481
Validation loss: 2.9274177685732776

Epoch: 6| Step: 12
Training loss: 3.5070155540449885
Validation loss: 2.927343166430768

Epoch: 6| Step: 13
Training loss: 3.9696759923362586
Validation loss: 2.9296724717496496

Epoch: 77| Step: 0
Training loss: 2.723213215454749
Validation loss: 2.930401890876119

Epoch: 6| Step: 1
Training loss: 3.669025760405285
Validation loss: 2.9253448822903736

Epoch: 6| Step: 2
Training loss: 2.9331538737916336
Validation loss: 2.924455029280953

Epoch: 6| Step: 3
Training loss: 2.813557065893121
Validation loss: 2.9232460434618175

Epoch: 6| Step: 4
Training loss: 3.185890689073787
Validation loss: 2.9231717277518174

Epoch: 6| Step: 5
Training loss: 2.774286962093282
Validation loss: 2.9235537022749076

Epoch: 6| Step: 6
Training loss: 3.489750022133388
Validation loss: 2.924547641140143

Epoch: 6| Step: 7
Training loss: 3.914882185760045
Validation loss: 2.924677849253304

Epoch: 6| Step: 8
Training loss: 3.0700141431749843
Validation loss: 2.921060091065934

Epoch: 6| Step: 9
Training loss: 3.28222699833566
Validation loss: 2.9223326857106837

Epoch: 6| Step: 10
Training loss: 3.637188906655825
Validation loss: 2.921313719914382

Epoch: 6| Step: 11
Training loss: 2.737100343837677
Validation loss: 2.921128237300487

Epoch: 6| Step: 12
Training loss: 3.0697782017611326
Validation loss: 2.9210398403188673

Epoch: 6| Step: 13
Training loss: 3.4519181710243716
Validation loss: 2.920494576061449

Epoch: 78| Step: 0
Training loss: 3.223435038474581
Validation loss: 2.917971461266639

Epoch: 6| Step: 1
Training loss: 2.757867915215422
Validation loss: 2.9187037176610358

Epoch: 6| Step: 2
Training loss: 3.3577279244870883
Validation loss: 2.9204856996287667

Epoch: 6| Step: 3
Training loss: 3.3933755292186283
Validation loss: 2.919964174139914

Epoch: 6| Step: 4
Training loss: 3.051882028722003
Validation loss: 2.9141971942225138

Epoch: 6| Step: 5
Training loss: 3.2143907378462497
Validation loss: 2.9146767280997974

Epoch: 6| Step: 6
Training loss: 3.3577292025935055
Validation loss: 2.916243261963468

Epoch: 6| Step: 7
Training loss: 3.0777133724514223
Validation loss: 2.916206162366291

Epoch: 6| Step: 8
Training loss: 3.5442567816163097
Validation loss: 2.9163477979704258

Epoch: 6| Step: 9
Training loss: 3.205373579560719
Validation loss: 2.9155757706851473

Epoch: 6| Step: 10
Training loss: 2.6399708676898266
Validation loss: 2.9127794085863306

Epoch: 6| Step: 11
Training loss: 3.26275230981343
Validation loss: 2.916879477992068

Epoch: 6| Step: 12
Training loss: 3.7517089764313343
Validation loss: 2.9144951341057848

Epoch: 6| Step: 13
Training loss: 2.5228246174869438
Validation loss: 2.912875104150044

Epoch: 79| Step: 0
Training loss: 3.1463052425149645
Validation loss: 2.911182615412362

Epoch: 6| Step: 1
Training loss: 3.699927128254627
Validation loss: 2.913080389704191

Epoch: 6| Step: 2
Training loss: 2.8831624798144424
Validation loss: 2.9178034027805517

Epoch: 6| Step: 3
Training loss: 2.883226649197827
Validation loss: 2.9228648400486414

Epoch: 6| Step: 4
Training loss: 3.4288301200003026
Validation loss: 2.9175325582087037

Epoch: 6| Step: 5
Training loss: 3.5967825658141512
Validation loss: 2.9162771840956774

Epoch: 6| Step: 6
Training loss: 3.081560725084023
Validation loss: 2.91095081336187

Epoch: 6| Step: 7
Training loss: 3.283140673205111
Validation loss: 2.9113818150201523

Epoch: 6| Step: 8
Training loss: 2.562715846949683
Validation loss: 2.911376149504275

Epoch: 6| Step: 9
Training loss: 3.9657848425140587
Validation loss: 2.908662196977786

Epoch: 6| Step: 10
Training loss: 3.0688650199016534
Validation loss: 2.9121355156401894

Epoch: 6| Step: 11
Training loss: 2.361936277920518
Validation loss: 2.912258412415023

Epoch: 6| Step: 12
Training loss: 3.462181263930166
Validation loss: 2.9122148710381666

Epoch: 6| Step: 13
Training loss: 2.8863412819326433
Validation loss: 2.911708131538783

Epoch: 80| Step: 0
Training loss: 3.5291556840445732
Validation loss: 2.9110022521558805

Epoch: 6| Step: 1
Training loss: 3.2938808929088377
Validation loss: 2.911106613540004

Epoch: 6| Step: 2
Training loss: 3.7475076658286284
Validation loss: 2.910758207480727

Epoch: 6| Step: 3
Training loss: 3.0314587393395067
Validation loss: 2.909179026581493

Epoch: 6| Step: 4
Training loss: 3.5311203654302483
Validation loss: 2.909609604322793

Epoch: 6| Step: 5
Training loss: 2.861929164423063
Validation loss: 2.9084589926960116

Epoch: 6| Step: 6
Training loss: 3.0393243593503363
Validation loss: 2.9077169399161447

Epoch: 6| Step: 7
Training loss: 3.42181925967729
Validation loss: 2.9076615212716455

Epoch: 6| Step: 8
Training loss: 3.3927529684723767
Validation loss: 2.904894417932805

Epoch: 6| Step: 9
Training loss: 2.70463255369723
Validation loss: 2.906578958334311

Epoch: 6| Step: 10
Training loss: 3.3851206175643114
Validation loss: 2.9063515338325296

Epoch: 6| Step: 11
Training loss: 2.724642101897983
Validation loss: 2.906266485761358

Epoch: 6| Step: 12
Training loss: 3.1641728134705063
Validation loss: 2.9051515636145675

Epoch: 6| Step: 13
Training loss: 2.3277228091215534
Validation loss: 2.9068552181600458

Epoch: 81| Step: 0
Training loss: 3.1645522503878127
Validation loss: 2.9077653889259554

Epoch: 6| Step: 1
Training loss: 3.6414026567678315
Validation loss: 2.9069980025261777

Epoch: 6| Step: 2
Training loss: 3.830272959451936
Validation loss: 2.9089329870321166

Epoch: 6| Step: 3
Training loss: 3.178860043545899
Validation loss: 2.904702321287971

Epoch: 6| Step: 4
Training loss: 3.3462956800680934
Validation loss: 2.906511654665624

Epoch: 6| Step: 5
Training loss: 3.0935352905983224
Validation loss: 2.9117949998838157

Epoch: 6| Step: 6
Training loss: 2.732750371856008
Validation loss: 2.9064462467357717

Epoch: 6| Step: 7
Training loss: 3.0669414466266116
Validation loss: 2.90574758092203

Epoch: 6| Step: 8
Training loss: 2.9482012679857417
Validation loss: 2.911689432283161

Epoch: 6| Step: 9
Training loss: 3.4871090139989454
Validation loss: 2.9045397237825576

Epoch: 6| Step: 10
Training loss: 2.8594853947908985
Validation loss: 2.9042838841849297

Epoch: 6| Step: 11
Training loss: 2.8093883679573675
Validation loss: 2.901353198351517

Epoch: 6| Step: 12
Training loss: 3.253307566801292
Validation loss: 2.898138333044517

Epoch: 6| Step: 13
Training loss: 3.0312317523210424
Validation loss: 2.897503819350798

Epoch: 82| Step: 0
Training loss: 3.0737262413716957
Validation loss: 2.8977262955934235

Epoch: 6| Step: 1
Training loss: 2.7831263695556507
Validation loss: 2.899161013201685

Epoch: 6| Step: 2
Training loss: 2.8246617477598646
Validation loss: 2.8961921302003795

Epoch: 6| Step: 3
Training loss: 3.895461909630215
Validation loss: 2.8960140051216703

Epoch: 6| Step: 4
Training loss: 3.0576840895647064
Validation loss: 2.897283714216384

Epoch: 6| Step: 5
Training loss: 3.6264822987600827
Validation loss: 2.898232489063357

Epoch: 6| Step: 6
Training loss: 2.6106067422854426
Validation loss: 2.8964030078101866

Epoch: 6| Step: 7
Training loss: 3.061756277280222
Validation loss: 2.8943122261782235

Epoch: 6| Step: 8
Training loss: 3.082842160530306
Validation loss: 2.8944735913833832

Epoch: 6| Step: 9
Training loss: 3.2238063170419844
Validation loss: 2.895693167334258

Epoch: 6| Step: 10
Training loss: 3.543569764090109
Validation loss: 2.8930457659313453

Epoch: 6| Step: 11
Training loss: 2.967742267029464
Validation loss: 2.9016846131214264

Epoch: 6| Step: 12
Training loss: 3.1127638249248437
Validation loss: 2.901468170327491

Epoch: 6| Step: 13
Training loss: 3.8028267886899387
Validation loss: 2.899269498701118

Epoch: 83| Step: 0
Training loss: 3.2249967826413215
Validation loss: 2.8946088685524667

Epoch: 6| Step: 1
Training loss: 3.3808644524441944
Validation loss: 2.894272447702556

Epoch: 6| Step: 2
Training loss: 3.652785004260929
Validation loss: 2.898147190349279

Epoch: 6| Step: 3
Training loss: 2.7443069136115574
Validation loss: 2.897291465428948

Epoch: 6| Step: 4
Training loss: 2.2738191998622295
Validation loss: 2.905590466375916

Epoch: 6| Step: 5
Training loss: 2.5321903130540284
Validation loss: 2.9072871867589805

Epoch: 6| Step: 6
Training loss: 2.169235052124307
Validation loss: 2.9122437370137826

Epoch: 6| Step: 7
Training loss: 3.48342294045384
Validation loss: 2.9080351658145

Epoch: 6| Step: 8
Training loss: 3.312181277506332
Validation loss: 2.909145680844868

Epoch: 6| Step: 9
Training loss: 3.96161869970632
Validation loss: 2.89760531548911

Epoch: 6| Step: 10
Training loss: 3.1466034879107085
Validation loss: 2.8969266422157767

Epoch: 6| Step: 11
Training loss: 3.4042758645543554
Validation loss: 2.893134568100588

Epoch: 6| Step: 12
Training loss: 3.582683740923218
Validation loss: 2.8903306451446378

Epoch: 6| Step: 13
Training loss: 3.541693982785666
Validation loss: 2.8935225004398926

Epoch: 84| Step: 0
Training loss: 3.728132065337042
Validation loss: 2.892230622991486

Epoch: 6| Step: 1
Training loss: 2.364918745229803
Validation loss: 2.89557645031206

Epoch: 6| Step: 2
Training loss: 3.350843374646319
Validation loss: 2.904956290187479

Epoch: 6| Step: 3
Training loss: 3.295890624990741
Validation loss: 2.9221902874268255

Epoch: 6| Step: 4
Training loss: 3.9339030957681875
Validation loss: 2.9315635444366612

Epoch: 6| Step: 5
Training loss: 3.156385060055073
Validation loss: 2.9132278612035605

Epoch: 6| Step: 6
Training loss: 2.3703537717984218
Validation loss: 2.9031615874834378

Epoch: 6| Step: 7
Training loss: 3.374371505427437
Validation loss: 2.8879478804368612

Epoch: 6| Step: 8
Training loss: 3.364456379072936
Validation loss: 2.8869364051667983

Epoch: 6| Step: 9
Training loss: 3.2856592979331753
Validation loss: 2.885153826925547

Epoch: 6| Step: 10
Training loss: 1.99491187414886
Validation loss: 2.8863248990862984

Epoch: 6| Step: 11
Training loss: 2.798911179283877
Validation loss: 2.883106841718856

Epoch: 6| Step: 12
Training loss: 3.8636252285801977
Validation loss: 2.8852154765376317

Epoch: 6| Step: 13
Training loss: 3.0674653575032305
Validation loss: 2.88337575071698

Epoch: 85| Step: 0
Training loss: 2.998839948799066
Validation loss: 2.883128481057181

Epoch: 6| Step: 1
Training loss: 3.847157278480594
Validation loss: 2.88396345265863

Epoch: 6| Step: 2
Training loss: 1.7765635360406087
Validation loss: 2.8835399301396007

Epoch: 6| Step: 3
Training loss: 3.147656516621669
Validation loss: 2.8853947071593127

Epoch: 6| Step: 4
Training loss: 3.5081599345966232
Validation loss: 2.8907204392455004

Epoch: 6| Step: 5
Training loss: 3.527797395212758
Validation loss: 2.892276932886442

Epoch: 6| Step: 6
Training loss: 3.6529937328970945
Validation loss: 2.896302020982937

Epoch: 6| Step: 7
Training loss: 2.679267071809703
Validation loss: 2.8814420384137933

Epoch: 6| Step: 8
Training loss: 2.4369857441231217
Validation loss: 2.8793950792543264

Epoch: 6| Step: 9
Training loss: 3.749474297868433
Validation loss: 2.8820380550052858

Epoch: 6| Step: 10
Training loss: 3.2805212755715423
Validation loss: 2.880218753878551

Epoch: 6| Step: 11
Training loss: 3.646137174025284
Validation loss: 2.880607295338927

Epoch: 6| Step: 12
Training loss: 3.0078608521377372
Validation loss: 2.8809429262120427

Epoch: 6| Step: 13
Training loss: 1.7894431296491815
Validation loss: 2.8817616205351064

Epoch: 86| Step: 0
Training loss: 3.098941031442422
Validation loss: 2.884001763494416

Epoch: 6| Step: 1
Training loss: 3.098576335710892
Validation loss: 2.883121403119225

Epoch: 6| Step: 2
Training loss: 3.3221708953646276
Validation loss: 2.8837592760680217

Epoch: 6| Step: 3
Training loss: 3.059283377314832
Validation loss: 2.8843307812230017

Epoch: 6| Step: 4
Training loss: 3.1388146795842276
Validation loss: 2.885683120171052

Epoch: 6| Step: 5
Training loss: 2.6945696263111887
Validation loss: 2.883498085327818

Epoch: 6| Step: 6
Training loss: 2.982846173055905
Validation loss: 2.8823701866184863

Epoch: 6| Step: 7
Training loss: 3.9113117839045564
Validation loss: 2.8793097406807013

Epoch: 6| Step: 8
Training loss: 2.8937280443977595
Validation loss: 2.8791821804037965

Epoch: 6| Step: 9
Training loss: 3.359195580237784
Validation loss: 2.8820407378069737

Epoch: 6| Step: 10
Training loss: 3.2248288131346503
Validation loss: 2.879216118912869

Epoch: 6| Step: 11
Training loss: 3.202654994814163
Validation loss: 2.8784638003896177

Epoch: 6| Step: 12
Training loss: 3.417575730752319
Validation loss: 2.88318918611019

Epoch: 6| Step: 13
Training loss: 2.795460860279786
Validation loss: 2.8814783889644437

Epoch: 87| Step: 0
Training loss: 2.8336278163985607
Validation loss: 2.8799774416201847

Epoch: 6| Step: 1
Training loss: 3.046327512410018
Validation loss: 2.8800063414087975

Epoch: 6| Step: 2
Training loss: 3.507161715148535
Validation loss: 2.8806186592838694

Epoch: 6| Step: 3
Training loss: 3.5924968358970304
Validation loss: 2.8817096322146907

Epoch: 6| Step: 4
Training loss: 3.8781737589633494
Validation loss: 2.8844305064819395

Epoch: 6| Step: 5
Training loss: 3.03853635965136
Validation loss: 2.8793228878008827

Epoch: 6| Step: 6
Training loss: 2.6781817506988976
Validation loss: 2.882178277860822

Epoch: 6| Step: 7
Training loss: 3.729693171381384
Validation loss: 2.8803205386850155

Epoch: 6| Step: 8
Training loss: 3.03370677060581
Validation loss: 2.8794412910912284

Epoch: 6| Step: 9
Training loss: 2.784411487276055
Validation loss: 2.876435061240757

Epoch: 6| Step: 10
Training loss: 2.8437852123721377
Validation loss: 2.8745001161707027

Epoch: 6| Step: 11
Training loss: 2.868940851515951
Validation loss: 2.8737319960697914

Epoch: 6| Step: 12
Training loss: 3.226183705112482
Validation loss: 2.8731609256678894

Epoch: 6| Step: 13
Training loss: 2.94978199816019
Validation loss: 2.8693317662477744

Epoch: 88| Step: 0
Training loss: 3.0161622512643693
Validation loss: 2.869530926446059

Epoch: 6| Step: 1
Training loss: 3.0735309223973357
Validation loss: 2.8727301919708172

Epoch: 6| Step: 2
Training loss: 2.895253038696455
Validation loss: 2.871406076216358

Epoch: 6| Step: 3
Training loss: 3.6292732307797912
Validation loss: 2.869593861360787

Epoch: 6| Step: 4
Training loss: 3.4373451891631266
Validation loss: 2.8693604435737114

Epoch: 6| Step: 5
Training loss: 2.9801692387188767
Validation loss: 2.869094186492171

Epoch: 6| Step: 6
Training loss: 3.6430553788387754
Validation loss: 2.8691161370280707

Epoch: 6| Step: 7
Training loss: 2.764767874964425
Validation loss: 2.8664466687879506

Epoch: 6| Step: 8
Training loss: 3.0748001964133813
Validation loss: 2.8702992749532896

Epoch: 6| Step: 9
Training loss: 2.8260169840286795
Validation loss: 2.8719963998141576

Epoch: 6| Step: 10
Training loss: 3.5375453231657894
Validation loss: 2.876632667346954

Epoch: 6| Step: 11
Training loss: 2.918840433880309
Validation loss: 2.8734128136790478

Epoch: 6| Step: 12
Training loss: 3.067348767868616
Validation loss: 2.8730960246490604

Epoch: 6| Step: 13
Training loss: 3.4280758766403374
Validation loss: 2.8662147218538405

Epoch: 89| Step: 0
Training loss: 3.303724071849815
Validation loss: 2.8703918960866206

Epoch: 6| Step: 1
Training loss: 3.1559570478700256
Validation loss: 2.8716091117323597

Epoch: 6| Step: 2
Training loss: 2.8659169554834523
Validation loss: 2.8701030478225675

Epoch: 6| Step: 3
Training loss: 3.0027820085638233
Validation loss: 2.864163363967392

Epoch: 6| Step: 4
Training loss: 3.6377782865956467
Validation loss: 2.86745240798683

Epoch: 6| Step: 5
Training loss: 3.1184526137335427
Validation loss: 2.8661189809063616

Epoch: 6| Step: 6
Training loss: 3.6399466083090193
Validation loss: 2.865491923364697

Epoch: 6| Step: 7
Training loss: 3.035620458739703
Validation loss: 2.8655167912225745

Epoch: 6| Step: 8
Training loss: 2.745825981010662
Validation loss: 2.863238511014647

Epoch: 6| Step: 9
Training loss: 2.935893491990722
Validation loss: 2.8625524707811856

Epoch: 6| Step: 10
Training loss: 3.1454488422464375
Validation loss: 2.8594138357258703

Epoch: 6| Step: 11
Training loss: 2.9888888271226213
Validation loss: 2.864187974840135

Epoch: 6| Step: 12
Training loss: 2.9458609558565785
Validation loss: 2.858687200364195

Epoch: 6| Step: 13
Training loss: 3.8681604876040665
Validation loss: 2.858123404958838

Epoch: 90| Step: 0
Training loss: 2.844908090725909
Validation loss: 2.8595030798676917

Epoch: 6| Step: 1
Training loss: 3.4923417912818597
Validation loss: 2.8602802460404293

Epoch: 6| Step: 2
Training loss: 3.399705251371597
Validation loss: 2.856790324002629

Epoch: 6| Step: 3
Training loss: 3.4063369319916794
Validation loss: 2.863529898663185

Epoch: 6| Step: 4
Training loss: 2.6666946608345574
Validation loss: 2.8594861819521733

Epoch: 6| Step: 5
Training loss: 2.4855904155240696
Validation loss: 2.8601825760976585

Epoch: 6| Step: 6
Training loss: 3.419752185387188
Validation loss: 2.8578919459670717

Epoch: 6| Step: 7
Training loss: 3.6755354147419084
Validation loss: 2.8592002076002334

Epoch: 6| Step: 8
Training loss: 3.3070455304366253
Validation loss: 2.8612838224829513

Epoch: 6| Step: 9
Training loss: 3.3481826635411487
Validation loss: 2.8577979347298603

Epoch: 6| Step: 10
Training loss: 3.1135480472060717
Validation loss: 2.8571403760137493

Epoch: 6| Step: 11
Training loss: 2.5759172639117893
Validation loss: 2.8587902835606704

Epoch: 6| Step: 12
Training loss: 2.861163971133838
Validation loss: 2.8595591180487836

Epoch: 6| Step: 13
Training loss: 3.488090279233257
Validation loss: 2.8599391205728537

Epoch: 91| Step: 0
Training loss: 3.0870825852152795
Validation loss: 2.8556539673726262

Epoch: 6| Step: 1
Training loss: 2.9409104698170414
Validation loss: 2.8579947474827447

Epoch: 6| Step: 2
Training loss: 2.7851846701521583
Validation loss: 2.861466350644457

Epoch: 6| Step: 3
Training loss: 2.2807231974140696
Validation loss: 2.8720039613038715

Epoch: 6| Step: 4
Training loss: 2.787973057587972
Validation loss: 2.8647095205903965

Epoch: 6| Step: 5
Training loss: 2.839247104351411
Validation loss: 2.8669160683847634

Epoch: 6| Step: 6
Training loss: 2.719417709264194
Validation loss: 2.8570819412789854

Epoch: 6| Step: 7
Training loss: 3.7679600737090393
Validation loss: 2.867199737047931

Epoch: 6| Step: 8
Training loss: 2.91978110289843
Validation loss: 2.860709575726736

Epoch: 6| Step: 9
Training loss: 3.493761770266119
Validation loss: 2.8747203391274985

Epoch: 6| Step: 10
Training loss: 3.303647285680418
Validation loss: 2.8639836076021106

Epoch: 6| Step: 11
Training loss: 3.933650845034685
Validation loss: 2.8567990501605336

Epoch: 6| Step: 12
Training loss: 3.266527699090173
Validation loss: 2.8530281852593204

Epoch: 6| Step: 13
Training loss: 3.898490584323575
Validation loss: 2.849292082660388

Epoch: 92| Step: 0
Training loss: 3.507814674971486
Validation loss: 2.8564235194836565

Epoch: 6| Step: 1
Training loss: 2.7404546669514915
Validation loss: 2.8515781107166327

Epoch: 6| Step: 2
Training loss: 3.337045811527013
Validation loss: 2.8484652395962504

Epoch: 6| Step: 3
Training loss: 2.9284629602315686
Validation loss: 2.8481579918988076

Epoch: 6| Step: 4
Training loss: 3.801975419416037
Validation loss: 2.8481357763259814

Epoch: 6| Step: 5
Training loss: 2.883066223061416
Validation loss: 2.8486372258746835

Epoch: 6| Step: 6
Training loss: 2.683596059917583
Validation loss: 2.8469309108469476

Epoch: 6| Step: 7
Training loss: 2.577728148463129
Validation loss: 2.8486541305483906

Epoch: 6| Step: 8
Training loss: 2.9468012520389895
Validation loss: 2.846072176809245

Epoch: 6| Step: 9
Training loss: 2.63408161670058
Validation loss: 2.8476585438701636

Epoch: 6| Step: 10
Training loss: 3.8081843229450456
Validation loss: 2.8513791818618395

Epoch: 6| Step: 11
Training loss: 3.742309313485823
Validation loss: 2.841517080562463

Epoch: 6| Step: 12
Training loss: 2.69563552468764
Validation loss: 2.8518689305452676

Epoch: 6| Step: 13
Training loss: 3.5632992567307027
Validation loss: 2.863392975042414

Epoch: 93| Step: 0
Training loss: 2.8149231538735004
Validation loss: 2.845981766546269

Epoch: 6| Step: 1
Training loss: 3.6998200295470585
Validation loss: 2.841874270394299

Epoch: 6| Step: 2
Training loss: 3.912652467919531
Validation loss: 2.847318445292668

Epoch: 6| Step: 3
Training loss: 2.9052747505249132
Validation loss: 2.8475510630847203

Epoch: 6| Step: 4
Training loss: 3.0760945240771016
Validation loss: 2.850117733295127

Epoch: 6| Step: 5
Training loss: 2.932902370207946
Validation loss: 2.851936044133722

Epoch: 6| Step: 6
Training loss: 3.3783247783636003
Validation loss: 2.852373502252271

Epoch: 6| Step: 7
Training loss: 3.32852657563882
Validation loss: 2.8529290256276187

Epoch: 6| Step: 8
Training loss: 2.1334949561328327
Validation loss: 2.853567416345696

Epoch: 6| Step: 9
Training loss: 2.4483021750478917
Validation loss: 2.8514776626578002

Epoch: 6| Step: 10
Training loss: 3.3712210515143957
Validation loss: 2.8505611930032067

Epoch: 6| Step: 11
Training loss: 3.275350735352658
Validation loss: 2.850318064245539

Epoch: 6| Step: 12
Training loss: 3.188361855469221
Validation loss: 2.849107923789282

Epoch: 6| Step: 13
Training loss: 3.351772488504741
Validation loss: 2.8487451012410654

Epoch: 94| Step: 0
Training loss: 3.5951892127061535
Validation loss: 2.8486394937562416

Epoch: 6| Step: 1
Training loss: 3.222126643272366
Validation loss: 2.847712407875793

Epoch: 6| Step: 2
Training loss: 3.487654575217442
Validation loss: 2.845283535643018

Epoch: 6| Step: 3
Training loss: 2.7746352497297675
Validation loss: 2.845447917316359

Epoch: 6| Step: 4
Training loss: 3.6927897126449545
Validation loss: 2.8435230013526342

Epoch: 6| Step: 5
Training loss: 3.105061822297277
Validation loss: 2.842010713501583

Epoch: 6| Step: 6
Training loss: 3.1422166729089254
Validation loss: 2.842882855571313

Epoch: 6| Step: 7
Training loss: 2.3186686951400075
Validation loss: 2.843478307374095

Epoch: 6| Step: 8
Training loss: 3.5636637610548316
Validation loss: 2.8434711388536478

Epoch: 6| Step: 9
Training loss: 3.065906109690494
Validation loss: 2.8409845102540676

Epoch: 6| Step: 10
Training loss: 3.0193564301450566
Validation loss: 2.842810907445723

Epoch: 6| Step: 11
Training loss: 3.0692705322831673
Validation loss: 2.8414527356827346

Epoch: 6| Step: 12
Training loss: 2.692280974622351
Validation loss: 2.840045043060078

Epoch: 6| Step: 13
Training loss: 3.0642265591038758
Validation loss: 2.8402570927036845

Epoch: 95| Step: 0
Training loss: 2.836414643809366
Validation loss: 2.836213376914098

Epoch: 6| Step: 1
Training loss: 2.6708789775913573
Validation loss: 2.838628047830331

Epoch: 6| Step: 2
Training loss: 3.382165860224317
Validation loss: 2.839509467357727

Epoch: 6| Step: 3
Training loss: 2.4599910793297766
Validation loss: 2.8397719487611837

Epoch: 6| Step: 4
Training loss: 3.185799388127577
Validation loss: 2.8401153633616674

Epoch: 6| Step: 5
Training loss: 3.548492466153568
Validation loss: 2.840859715917351

Epoch: 6| Step: 6
Training loss: 3.1330471949768244
Validation loss: 2.84475148932082

Epoch: 6| Step: 7
Training loss: 3.2793541653907146
Validation loss: 2.849169297005674

Epoch: 6| Step: 8
Training loss: 3.3877928547412313
Validation loss: 2.8562222515664817

Epoch: 6| Step: 9
Training loss: 2.4786900187673657
Validation loss: 2.851376166319293

Epoch: 6| Step: 10
Training loss: 3.217684078567654
Validation loss: 2.8543086668193447

Epoch: 6| Step: 11
Training loss: 3.581164139655401
Validation loss: 2.8406106883941296

Epoch: 6| Step: 12
Training loss: 3.3133579798446315
Validation loss: 2.8425345507009787

Epoch: 6| Step: 13
Training loss: 3.3925365210459946
Validation loss: 2.835342325336636

Epoch: 96| Step: 0
Training loss: 2.733936383626956
Validation loss: 2.8311683996344357

Epoch: 6| Step: 1
Training loss: 2.541607611131664
Validation loss: 2.835087326168202

Epoch: 6| Step: 2
Training loss: 3.3956349008697746
Validation loss: 2.834660094284121

Epoch: 6| Step: 3
Training loss: 3.065763175253549
Validation loss: 2.8341965678354297

Epoch: 6| Step: 4
Training loss: 2.6049962566151144
Validation loss: 2.835451115181225

Epoch: 6| Step: 5
Training loss: 2.8995482586197703
Validation loss: 2.838679821802688

Epoch: 6| Step: 6
Training loss: 3.460860344089178
Validation loss: 2.8354423793811807

Epoch: 6| Step: 7
Training loss: 3.608555027683156
Validation loss: 2.834970488646339

Epoch: 6| Step: 8
Training loss: 2.969017900124512
Validation loss: 2.832739216393856

Epoch: 6| Step: 9
Training loss: 3.53604367746158
Validation loss: 2.834038810076867

Epoch: 6| Step: 10
Training loss: 2.9228814171650197
Validation loss: 2.8335127137335765

Epoch: 6| Step: 11
Training loss: 3.2734744996230867
Validation loss: 2.830899539350947

Epoch: 6| Step: 12
Training loss: 3.336878623696071
Validation loss: 2.830073381938847

Epoch: 6| Step: 13
Training loss: 3.4855161431879536
Validation loss: 2.8319201344158125

Epoch: 97| Step: 0
Training loss: 3.726824289399437
Validation loss: 2.8271728954362048

Epoch: 6| Step: 1
Training loss: 2.3104406930575982
Validation loss: 2.828651773935843

Epoch: 6| Step: 2
Training loss: 3.4352276313796923
Validation loss: 2.827145501300196

Epoch: 6| Step: 3
Training loss: 3.295084969057415
Validation loss: 2.831838708201523

Epoch: 6| Step: 4
Training loss: 3.004702855555455
Validation loss: 2.829319110516982

Epoch: 6| Step: 5
Training loss: 2.355664196098216
Validation loss: 2.827588943552498

Epoch: 6| Step: 6
Training loss: 3.1481073173252025
Validation loss: 2.8311591489676355

Epoch: 6| Step: 7
Training loss: 3.3697633029661858
Validation loss: 2.828328439577755

Epoch: 6| Step: 8
Training loss: 2.8210901260880905
Validation loss: 2.8270958765231824

Epoch: 6| Step: 9
Training loss: 2.8649201536120104
Validation loss: 2.8238245487918907

Epoch: 6| Step: 10
Training loss: 3.141398016846025
Validation loss: 2.8271363172682746

Epoch: 6| Step: 11
Training loss: 3.5835057742004586
Validation loss: 2.8233580321258898

Epoch: 6| Step: 12
Training loss: 3.2605585101943624
Validation loss: 2.824181020673571

Epoch: 6| Step: 13
Training loss: 3.312059337167358
Validation loss: 2.8297728344670894

Epoch: 98| Step: 0
Training loss: 2.5341048918694793
Validation loss: 2.827790437628752

Epoch: 6| Step: 1
Training loss: 2.850121539017312
Validation loss: 2.828695651777661

Epoch: 6| Step: 2
Training loss: 3.2116840914649654
Validation loss: 2.837752157108072

Epoch: 6| Step: 3
Training loss: 2.961244431341884
Validation loss: 2.870526722006778

Epoch: 6| Step: 4
Training loss: 3.6177247803930475
Validation loss: 2.8625478048130564

Epoch: 6| Step: 5
Training loss: 2.1755332599991544
Validation loss: 2.827132525944659

Epoch: 6| Step: 6
Training loss: 3.0893381430904445
Validation loss: 2.8244517403896365

Epoch: 6| Step: 7
Training loss: 3.7607165751529816
Validation loss: 2.8232196923266275

Epoch: 6| Step: 8
Training loss: 2.629703757858565
Validation loss: 2.821668124380763

Epoch: 6| Step: 9
Training loss: 3.123969251395889
Validation loss: 2.8303920189871303

Epoch: 6| Step: 10
Training loss: 3.5983957530890915
Validation loss: 2.8253686662716553

Epoch: 6| Step: 11
Training loss: 3.671350839416465
Validation loss: 2.8304241096912444

Epoch: 6| Step: 12
Training loss: 3.1730855501497808
Validation loss: 2.8280162020976567

Epoch: 6| Step: 13
Training loss: 3.1377159804213486
Validation loss: 2.8306432315621293

Epoch: 99| Step: 0
Training loss: 2.7096888060154725
Validation loss: 2.8317411214853565

Epoch: 6| Step: 1
Training loss: 3.9101078361997192
Validation loss: 2.8341398291695357

Epoch: 6| Step: 2
Training loss: 2.8210291070961135
Validation loss: 2.840652676724154

Epoch: 6| Step: 3
Training loss: 3.433282102431003
Validation loss: 2.8340450815862046

Epoch: 6| Step: 4
Training loss: 3.211246967485005
Validation loss: 2.8263736537761157

Epoch: 6| Step: 5
Training loss: 3.0961966040037785
Validation loss: 2.8258647535679398

Epoch: 6| Step: 6
Training loss: 2.116498208538823
Validation loss: 2.82775670011814

Epoch: 6| Step: 7
Training loss: 3.1358869501971056
Validation loss: 2.822501892948376

Epoch: 6| Step: 8
Training loss: 2.9452069412864614
Validation loss: 2.8245875366108604

Epoch: 6| Step: 9
Training loss: 3.596968296143561
Validation loss: 2.824617890754825

Epoch: 6| Step: 10
Training loss: 2.652161716961977
Validation loss: 2.828301037599116

Epoch: 6| Step: 11
Training loss: 3.0970259767255257
Validation loss: 2.8310344648503274

Epoch: 6| Step: 12
Training loss: 3.3035668892258494
Validation loss: 2.8388276895993405

Epoch: 6| Step: 13
Training loss: 3.780781866682803
Validation loss: 2.843765261452611

Epoch: 100| Step: 0
Training loss: 3.648702542400507
Validation loss: 2.842446568607098

Epoch: 6| Step: 1
Training loss: 3.4418266117593777
Validation loss: 2.8359003713476763

Epoch: 6| Step: 2
Training loss: 2.913098214072774
Validation loss: 2.826840113520465

Epoch: 6| Step: 3
Training loss: 3.5189255882346
Validation loss: 2.8264764651579566

Epoch: 6| Step: 4
Training loss: 3.065535306250311
Validation loss: 2.8234330891477133

Epoch: 6| Step: 5
Training loss: 2.4701769604014694
Validation loss: 2.8241574010090416

Epoch: 6| Step: 6
Training loss: 2.877600778891294
Validation loss: 2.8237447493918157

Epoch: 6| Step: 7
Training loss: 2.8964876675217295
Validation loss: 2.823492282925898

Epoch: 6| Step: 8
Training loss: 3.4288334576069572
Validation loss: 2.821844667445122

Epoch: 6| Step: 9
Training loss: 3.4309439823177303
Validation loss: 2.824547281742417

Epoch: 6| Step: 10
Training loss: 2.3474998485496075
Validation loss: 2.8271631329619042

Epoch: 6| Step: 11
Training loss: 2.515625
Validation loss: 2.8211347435617466

Epoch: 6| Step: 12
Training loss: 3.5878560703629994
Validation loss: 2.82735068517906

Epoch: 6| Step: 13
Training loss: 3.375870627676957
Validation loss: 2.8297059118480314

Epoch: 101| Step: 0
Training loss: 3.1973070853871075
Validation loss: 2.8251957852661316

Epoch: 6| Step: 1
Training loss: 3.3370762473847333
Validation loss: 2.8276826064595504

Epoch: 6| Step: 2
Training loss: 2.9743884700270544
Validation loss: 2.820766665674405

Epoch: 6| Step: 3
Training loss: 3.023990708634569
Validation loss: 2.824025680538957

Epoch: 6| Step: 4
Training loss: 2.4427182021819456
Validation loss: 2.8241055813872804

Epoch: 6| Step: 5
Training loss: 3.2840169230500176
Validation loss: 2.8196511891859246

Epoch: 6| Step: 6
Training loss: 2.6067603254281115
Validation loss: 2.818095137542619

Epoch: 6| Step: 7
Training loss: 2.7305071695705494
Validation loss: 2.818922781072917

Epoch: 6| Step: 8
Training loss: 3.416022046073868
Validation loss: 2.817971149040097

Epoch: 6| Step: 9
Training loss: 3.184653862749436
Validation loss: 2.8164851040642076

Epoch: 6| Step: 10
Training loss: 3.0092782548701567
Validation loss: 2.817844941569363

Epoch: 6| Step: 11
Training loss: 4.023168699303652
Validation loss: 2.8164957828264967

Epoch: 6| Step: 12
Training loss: 2.916869746813019
Validation loss: 2.8150859889587156

Epoch: 6| Step: 13
Training loss: 3.4260534963445117
Validation loss: 2.817268300071213

Epoch: 102| Step: 0
Training loss: 3.559098744912481
Validation loss: 2.819992520408163

Epoch: 6| Step: 1
Training loss: 3.2161085530744593
Validation loss: 2.817268599452612

Epoch: 6| Step: 2
Training loss: 3.2577442921329482
Validation loss: 2.81797308861991

Epoch: 6| Step: 3
Training loss: 3.219687019917555
Validation loss: 2.8156156321262715

Epoch: 6| Step: 4
Training loss: 3.431974652034457
Validation loss: 2.815758239566163

Epoch: 6| Step: 5
Training loss: 2.489017587221816
Validation loss: 2.814971511506655

Epoch: 6| Step: 6
Training loss: 2.571298612989052
Validation loss: 2.8170490497069727

Epoch: 6| Step: 7
Training loss: 2.7764631933035835
Validation loss: 2.8178763882053413

Epoch: 6| Step: 8
Training loss: 2.4762646228217955
Validation loss: 2.814478737122923

Epoch: 6| Step: 9
Training loss: 3.253404741233147
Validation loss: 2.823086000665891

Epoch: 6| Step: 10
Training loss: 3.2569242222385673
Validation loss: 2.8237289702748307

Epoch: 6| Step: 11
Training loss: 3.2293907497960297
Validation loss: 2.831375015940614

Epoch: 6| Step: 12
Training loss: 3.0639769437634583
Validation loss: 2.834242258433279

Epoch: 6| Step: 13
Training loss: 4.028380799735271
Validation loss: 2.8412703203561973

Epoch: 103| Step: 0
Training loss: 3.3170008760945056
Validation loss: 2.8092115075026998

Epoch: 6| Step: 1
Training loss: 3.088882007255786
Validation loss: 2.8105793564776507

Epoch: 6| Step: 2
Training loss: 2.9445309196425424
Validation loss: 2.8083621633919447

Epoch: 6| Step: 3
Training loss: 3.227299271302222
Validation loss: 2.8116235139804395

Epoch: 6| Step: 4
Training loss: 2.828434205407877
Validation loss: 2.820268424466363

Epoch: 6| Step: 5
Training loss: 2.488167992234561
Validation loss: 2.822495037192826

Epoch: 6| Step: 6
Training loss: 3.202056259871434
Validation loss: 2.833303392265349

Epoch: 6| Step: 7
Training loss: 2.666228367627857
Validation loss: 2.8404086799769654

Epoch: 6| Step: 8
Training loss: 3.1615896852325025
Validation loss: 2.8394280601506847

Epoch: 6| Step: 9
Training loss: 2.842300213156412
Validation loss: 2.8273780156700963

Epoch: 6| Step: 10
Training loss: 2.95472956263853
Validation loss: 2.815887112500899

Epoch: 6| Step: 11
Training loss: 3.402262181947757
Validation loss: 2.812790454373291

Epoch: 6| Step: 12
Training loss: 3.9206869445995953
Validation loss: 2.8677419416043106

Epoch: 6| Step: 13
Training loss: 3.7129197779217793
Validation loss: 2.8356667060534058

Epoch: 104| Step: 0
Training loss: 3.023859827476397
Validation loss: 2.823275376475033

Epoch: 6| Step: 1
Training loss: 3.0707805558271173
Validation loss: 2.8325128278092557

Epoch: 6| Step: 2
Training loss: 3.5115913817801716
Validation loss: 2.874048335902066

Epoch: 6| Step: 3
Training loss: 3.3474924410221147
Validation loss: 2.9289723396971334

Epoch: 6| Step: 4
Training loss: 2.7311065321893317
Validation loss: 2.923065878165661

Epoch: 6| Step: 5
Training loss: 3.897633073943924
Validation loss: 2.863762602857026

Epoch: 6| Step: 6
Training loss: 3.0201137518775325
Validation loss: 2.8351106684992553

Epoch: 6| Step: 7
Training loss: 3.1754642717828885
Validation loss: 2.8347456130967252

Epoch: 6| Step: 8
Training loss: 3.1915800124341303
Validation loss: 2.881182044361438

Epoch: 6| Step: 9
Training loss: 3.2184688111969426
Validation loss: 2.898297502989609

Epoch: 6| Step: 10
Training loss: 2.7886348791910565
Validation loss: 2.8569231984964882

Epoch: 6| Step: 11
Training loss: 3.1129905344779036
Validation loss: 2.8053918377368534

Epoch: 6| Step: 12
Training loss: 2.6964639609043646
Validation loss: 2.8082809460031033

Epoch: 6| Step: 13
Training loss: 2.9671183067317317
Validation loss: 2.806448396563735

Epoch: 105| Step: 0
Training loss: 3.3910723272477523
Validation loss: 2.8152961768304934

Epoch: 6| Step: 1
Training loss: 2.5937349250079613
Validation loss: 2.8177363408496134

Epoch: 6| Step: 2
Training loss: 3.495724928171194
Validation loss: 2.839484422290727

Epoch: 6| Step: 3
Training loss: 2.5802293916494117
Validation loss: 2.8429461288105626

Epoch: 6| Step: 4
Training loss: 3.323271458418697
Validation loss: 2.8687759983393954

Epoch: 6| Step: 5
Training loss: 3.51041198790528
Validation loss: 2.8862899427818802

Epoch: 6| Step: 6
Training loss: 3.3490954302327163
Validation loss: 2.8194377670830013

Epoch: 6| Step: 7
Training loss: 3.1884931625237867
Validation loss: 2.8090116354359282

Epoch: 6| Step: 8
Training loss: 2.7348820679395134
Validation loss: 2.8028513699849897

Epoch: 6| Step: 9
Training loss: 3.4829829561493906
Validation loss: 2.802348322487125

Epoch: 6| Step: 10
Training loss: 3.3277162112776826
Validation loss: 2.7998413782632015

Epoch: 6| Step: 11
Training loss: 3.080204759702565
Validation loss: 2.8003303566604703

Epoch: 6| Step: 12
Training loss: 2.8204421755917872
Validation loss: 2.8000173995214257

Epoch: 6| Step: 13
Training loss: 2.10446023938917
Validation loss: 2.803922407793063

Epoch: 106| Step: 0
Training loss: 3.5862095548862754
Validation loss: 2.8101193624252563

Epoch: 6| Step: 1
Training loss: 3.438702182361044
Validation loss: 2.8147225862345504

Epoch: 6| Step: 2
Training loss: 2.7377823009116447
Validation loss: 2.8025135119191122

Epoch: 6| Step: 3
Training loss: 3.1253872440731305
Validation loss: 2.8048563429455267

Epoch: 6| Step: 4
Training loss: 2.914739208038844
Validation loss: 2.801100172364329

Epoch: 6| Step: 5
Training loss: 3.4414505885338977
Validation loss: 2.7964583564534107

Epoch: 6| Step: 6
Training loss: 3.6370452177075574
Validation loss: 2.7983077584337397

Epoch: 6| Step: 7
Training loss: 3.070856798376514
Validation loss: 2.798300608870931

Epoch: 6| Step: 8
Training loss: 2.908569066969871
Validation loss: 2.8034581327555546

Epoch: 6| Step: 9
Training loss: 2.751006895743754
Validation loss: 2.807843144651928

Epoch: 6| Step: 10
Training loss: 2.782784799291217
Validation loss: 2.806016843530265

Epoch: 6| Step: 11
Training loss: 2.7553494182344536
Validation loss: 2.8242314273907856

Epoch: 6| Step: 12
Training loss: 3.1489408862082477
Validation loss: 2.8209925137881093

Epoch: 6| Step: 13
Training loss: 3.0504329936870618
Validation loss: 2.820088442827383

Epoch: 107| Step: 0
Training loss: 3.402892391497679
Validation loss: 2.812402208968462

Epoch: 6| Step: 1
Training loss: 3.2642365200608436
Validation loss: 2.8052138443286

Epoch: 6| Step: 2
Training loss: 3.7596821723692875
Validation loss: 2.801810137859371

Epoch: 6| Step: 3
Training loss: 3.225683947052087
Validation loss: 2.801293855931958

Epoch: 6| Step: 4
Training loss: 3.6500482373120207
Validation loss: 2.7968347037473924

Epoch: 6| Step: 5
Training loss: 3.7113665202252295
Validation loss: 2.7913017095614627

Epoch: 6| Step: 6
Training loss: 3.086336134260586
Validation loss: 2.7903845948082973

Epoch: 6| Step: 7
Training loss: 1.9035601790153776
Validation loss: 2.7876471201565836

Epoch: 6| Step: 8
Training loss: 2.861793537500869
Validation loss: 2.7879527863507314

Epoch: 6| Step: 9
Training loss: 3.015008418639214
Validation loss: 2.784974010250011

Epoch: 6| Step: 10
Training loss: 2.464330846558812
Validation loss: 2.786790493586134

Epoch: 6| Step: 11
Training loss: 2.857758946070794
Validation loss: 2.785279186518863

Epoch: 6| Step: 12
Training loss: 2.9463303322536345
Validation loss: 2.792097322627048

Epoch: 6| Step: 13
Training loss: 2.2967160747327457
Validation loss: 2.783308179938307

Epoch: 108| Step: 0
Training loss: 3.706722138101835
Validation loss: 2.7912978851784223

Epoch: 6| Step: 1
Training loss: 2.96565551098965
Validation loss: 2.7860450009485107

Epoch: 6| Step: 2
Training loss: 3.9259935615786024
Validation loss: 2.783407465182282

Epoch: 6| Step: 3
Training loss: 3.093942655479495
Validation loss: 2.788475506364756

Epoch: 6| Step: 4
Training loss: 2.437036323461371
Validation loss: 2.7817424187550093

Epoch: 6| Step: 5
Training loss: 3.0973742285710983
Validation loss: 2.783334113195776

Epoch: 6| Step: 6
Training loss: 2.3470881785604547
Validation loss: 2.7844855106036666

Epoch: 6| Step: 7
Training loss: 3.2031885652515224
Validation loss: 2.7836246471645003

Epoch: 6| Step: 8
Training loss: 3.6957463015888967
Validation loss: 2.786333953102429

Epoch: 6| Step: 9
Training loss: 2.058801977060813
Validation loss: 2.785969239396103

Epoch: 6| Step: 10
Training loss: 3.223954520688039
Validation loss: 2.7855420732686937

Epoch: 6| Step: 11
Training loss: 2.871814787755453
Validation loss: 2.787904644215283

Epoch: 6| Step: 12
Training loss: 3.6357470401441563
Validation loss: 2.7863190285001305

Epoch: 6| Step: 13
Training loss: 1.9781619148365521
Validation loss: 2.7881882491323213

Epoch: 109| Step: 0
Training loss: 3.350300584659287
Validation loss: 2.784511772166305

Epoch: 6| Step: 1
Training loss: 3.053805094536965
Validation loss: 2.788279732528905

Epoch: 6| Step: 2
Training loss: 2.839390525699852
Validation loss: 2.7947531326918487

Epoch: 6| Step: 3
Training loss: 3.2134134441166435
Validation loss: 2.7892100643642137

Epoch: 6| Step: 4
Training loss: 2.969396741591155
Validation loss: 2.7869074100304205

Epoch: 6| Step: 5
Training loss: 2.4168688810087073
Validation loss: 2.7851184572652627

Epoch: 6| Step: 6
Training loss: 3.1642397230460184
Validation loss: 2.7860357486035614

Epoch: 6| Step: 7
Training loss: 3.0433849201934575
Validation loss: 2.792842797840523

Epoch: 6| Step: 8
Training loss: 3.5440972159767212
Validation loss: 2.799738184895656

Epoch: 6| Step: 9
Training loss: 3.3361341789211094
Validation loss: 2.7968816674054993

Epoch: 6| Step: 10
Training loss: 3.444083827293382
Validation loss: 2.8018296857319185

Epoch: 6| Step: 11
Training loss: 2.7121952887751917
Validation loss: 2.782635742568599

Epoch: 6| Step: 12
Training loss: 3.092939328417229
Validation loss: 2.7852538452620843

Epoch: 6| Step: 13
Training loss: 2.970299085720219
Validation loss: 2.779336604595361

Epoch: 110| Step: 0
Training loss: 3.0144834581415734
Validation loss: 2.7842481537285906

Epoch: 6| Step: 1
Training loss: 2.6290985082465914
Validation loss: 2.7824431152295936

Epoch: 6| Step: 2
Training loss: 2.750886080780364
Validation loss: 2.783396535132142

Epoch: 6| Step: 3
Training loss: 2.7639599976798532
Validation loss: 2.7873780857970543

Epoch: 6| Step: 4
Training loss: 3.310986731011553
Validation loss: 2.787114573821219

Epoch: 6| Step: 5
Training loss: 3.4245245443415007
Validation loss: 2.786729047380967

Epoch: 6| Step: 6
Training loss: 2.9764119107658518
Validation loss: 2.7872737062247848

Epoch: 6| Step: 7
Training loss: 2.782724825266688
Validation loss: 2.7863560845367736

Epoch: 6| Step: 8
Training loss: 3.266580104329745
Validation loss: 2.787970173922662

Epoch: 6| Step: 9
Training loss: 3.0077773054962043
Validation loss: 2.786009782982483

Epoch: 6| Step: 10
Training loss: 3.282441131923907
Validation loss: 2.7873091151658116

Epoch: 6| Step: 11
Training loss: 3.2068439015390022
Validation loss: 2.7853412740166323

Epoch: 6| Step: 12
Training loss: 3.5849734404576306
Validation loss: 2.785026936302769

Epoch: 6| Step: 13
Training loss: 3.4170435410723803
Validation loss: 2.7841369460113774

Epoch: 111| Step: 0
Training loss: 2.9827552114493443
Validation loss: 2.784534735639366

Epoch: 6| Step: 1
Training loss: 2.5793413471811597
Validation loss: 2.78519445366445

Epoch: 6| Step: 2
Training loss: 2.7900918722579098
Validation loss: 2.7846581111184983

Epoch: 6| Step: 3
Training loss: 3.594470805982577
Validation loss: 2.7834575943905078

Epoch: 6| Step: 4
Training loss: 3.60037827623635
Validation loss: 2.783808304124872

Epoch: 6| Step: 5
Training loss: 3.233690862125951
Validation loss: 2.780681560774571

Epoch: 6| Step: 6
Training loss: 2.2740957873593297
Validation loss: 2.781820478621722

Epoch: 6| Step: 7
Training loss: 3.0429869272964787
Validation loss: 2.7780552732304375

Epoch: 6| Step: 8
Training loss: 3.768201018120433
Validation loss: 2.7806208665064487

Epoch: 6| Step: 9
Training loss: 2.929497389665109
Validation loss: 2.779987529370488

Epoch: 6| Step: 10
Training loss: 2.6104178714571824
Validation loss: 2.7784825422239323

Epoch: 6| Step: 11
Training loss: 3.184238934815373
Validation loss: 2.7760484666069027

Epoch: 6| Step: 12
Training loss: 3.1088107569961445
Validation loss: 2.7769131946113212

Epoch: 6| Step: 13
Training loss: 3.4943768425167154
Validation loss: 2.7759838772763867

Epoch: 112| Step: 0
Training loss: 3.25702202078028
Validation loss: 2.7756390201765093

Epoch: 6| Step: 1
Training loss: 2.4029528334199806
Validation loss: 2.774884671504286

Epoch: 6| Step: 2
Training loss: 2.730978376556467
Validation loss: 2.773706934526823

Epoch: 6| Step: 3
Training loss: 2.9641936020319504
Validation loss: 2.774796579752747

Epoch: 6| Step: 4
Training loss: 3.312535555666709
Validation loss: 2.7748545142825423

Epoch: 6| Step: 5
Training loss: 3.910823982228132
Validation loss: 2.77691227879878

Epoch: 6| Step: 6
Training loss: 3.7545118528151815
Validation loss: 2.7785111570438623

Epoch: 6| Step: 7
Training loss: 2.9829139528361215
Validation loss: 2.7736523912559448

Epoch: 6| Step: 8
Training loss: 3.268697507010091
Validation loss: 2.771708097255221

Epoch: 6| Step: 9
Training loss: 3.1649043717483805
Validation loss: 2.7723138409679513

Epoch: 6| Step: 10
Training loss: 2.6169526407564967
Validation loss: 2.776825923335474

Epoch: 6| Step: 11
Training loss: 2.4394883091437882
Validation loss: 2.7734285919772015

Epoch: 6| Step: 12
Training loss: 2.692958965233937
Validation loss: 2.7728784927062065

Epoch: 6| Step: 13
Training loss: 3.428476176187613
Validation loss: 2.7846397196262376

Epoch: 113| Step: 0
Training loss: 2.507744238569129
Validation loss: 2.793731556371987

Epoch: 6| Step: 1
Training loss: 3.3205083811705443
Validation loss: 2.798441707667719

Epoch: 6| Step: 2
Training loss: 3.3818256445212262
Validation loss: 2.7964697341587597

Epoch: 6| Step: 3
Training loss: 3.067512303011347
Validation loss: 2.789373145964918

Epoch: 6| Step: 4
Training loss: 2.6401071435687427
Validation loss: 2.784124227856337

Epoch: 6| Step: 5
Training loss: 3.634657524588104
Validation loss: 2.780021970624754

Epoch: 6| Step: 6
Training loss: 2.8135075777642253
Validation loss: 2.7736944356611377

Epoch: 6| Step: 7
Training loss: 3.075096538237852
Validation loss: 2.773971947502064

Epoch: 6| Step: 8
Training loss: 2.693818405238711
Validation loss: 2.7668524914217234

Epoch: 6| Step: 9
Training loss: 3.4397001681402553
Validation loss: 2.7681060909670014

Epoch: 6| Step: 10
Training loss: 3.1466377358265034
Validation loss: 2.765964575039455

Epoch: 6| Step: 11
Training loss: 3.0001187301029195
Validation loss: 2.767886951282809

Epoch: 6| Step: 12
Training loss: 3.0993306083292507
Validation loss: 2.7636926925966825

Epoch: 6| Step: 13
Training loss: 3.2027301824127945
Validation loss: 2.7621034291421283

Epoch: 114| Step: 0
Training loss: 2.8790387520389835
Validation loss: 2.7650247558258116

Epoch: 6| Step: 1
Training loss: 3.181693529189146
Validation loss: 2.7655095013193787

Epoch: 6| Step: 2
Training loss: 2.9173369227892305
Validation loss: 2.7677895902296403

Epoch: 6| Step: 3
Training loss: 2.9337241071445046
Validation loss: 2.7687024781993683

Epoch: 6| Step: 4
Training loss: 2.9631173758095892
Validation loss: 2.769052765317155

Epoch: 6| Step: 5
Training loss: 2.511286245932309
Validation loss: 2.774957846813137

Epoch: 6| Step: 6
Training loss: 3.7756807281922917
Validation loss: 2.7731308638874084

Epoch: 6| Step: 7
Training loss: 2.9264935389111275
Validation loss: 2.7669905140776496

Epoch: 6| Step: 8
Training loss: 2.6675919675837942
Validation loss: 2.7657415829968164

Epoch: 6| Step: 9
Training loss: 3.356629283081909
Validation loss: 2.761560154850895

Epoch: 6| Step: 10
Training loss: 3.2237879759972694
Validation loss: 2.765050636653692

Epoch: 6| Step: 11
Training loss: 3.1323445795933145
Validation loss: 2.76169105192507

Epoch: 6| Step: 12
Training loss: 3.4589379176633845
Validation loss: 2.7607284218163732

Epoch: 6| Step: 13
Training loss: 2.955020679588702
Validation loss: 2.7684766082538483

Epoch: 115| Step: 0
Training loss: 3.114733195872437
Validation loss: 2.763657238953869

Epoch: 6| Step: 1
Training loss: 3.3615915482285446
Validation loss: 2.7612619868339716

Epoch: 6| Step: 2
Training loss: 2.75161730285519
Validation loss: 2.7594984598855845

Epoch: 6| Step: 3
Training loss: 3.1001763693567765
Validation loss: 2.761920253070293

Epoch: 6| Step: 4
Training loss: 3.0216144121985287
Validation loss: 2.762218268356961

Epoch: 6| Step: 5
Training loss: 2.9923490874082668
Validation loss: 2.7679604745955997

Epoch: 6| Step: 6
Training loss: 3.240348864482003
Validation loss: 2.7676972702337372

Epoch: 6| Step: 7
Training loss: 1.9202609844452312
Validation loss: 2.772815485426556

Epoch: 6| Step: 8
Training loss: 3.8154818021380064
Validation loss: 2.7746045040025784

Epoch: 6| Step: 9
Training loss: 3.2143248722173796
Validation loss: 2.766766616057654

Epoch: 6| Step: 10
Training loss: 3.0358188450862253
Validation loss: 2.7721060039013556

Epoch: 6| Step: 11
Training loss: 3.0454974850819734
Validation loss: 2.7669705570094374

Epoch: 6| Step: 12
Training loss: 3.1098798025767183
Validation loss: 2.7611355706612803

Epoch: 6| Step: 13
Training loss: 3.1342873466915666
Validation loss: 2.7640186759674297

Epoch: 116| Step: 0
Training loss: 2.5813056514920043
Validation loss: 2.757928689589438

Epoch: 6| Step: 1
Training loss: 3.1296204550727964
Validation loss: 2.7576629552575906

Epoch: 6| Step: 2
Training loss: 2.9362803422928057
Validation loss: 2.7606365398774693

Epoch: 6| Step: 3
Training loss: 2.972410815980853
Validation loss: 2.7631518572858726

Epoch: 6| Step: 4
Training loss: 3.5496878204627658
Validation loss: 2.7647906899421835

Epoch: 6| Step: 5
Training loss: 3.179231728170926
Validation loss: 2.762504671770581

Epoch: 6| Step: 6
Training loss: 2.930768192606079
Validation loss: 2.7629132902802804

Epoch: 6| Step: 7
Training loss: 3.867542104165155
Validation loss: 2.7634981038222564

Epoch: 6| Step: 8
Training loss: 3.4641306593834997
Validation loss: 2.7606153834941822

Epoch: 6| Step: 9
Training loss: 2.470389196181268
Validation loss: 2.7607218212470177

Epoch: 6| Step: 10
Training loss: 2.548485743886356
Validation loss: 2.762176065045632

Epoch: 6| Step: 11
Training loss: 3.539727222256455
Validation loss: 2.761788982562304

Epoch: 6| Step: 12
Training loss: 2.370310621065968
Validation loss: 2.7604266571464704

Epoch: 6| Step: 13
Training loss: 3.241080883482226
Validation loss: 2.7557491622522705

Epoch: 117| Step: 0
Training loss: 2.8258624220483073
Validation loss: 2.7553948076191306

Epoch: 6| Step: 1
Training loss: 3.1173606575887916
Validation loss: 2.7582933946149493

Epoch: 6| Step: 2
Training loss: 3.478260097296256
Validation loss: 2.7584607603626448

Epoch: 6| Step: 3
Training loss: 3.6289727376343244
Validation loss: 2.764601599506553

Epoch: 6| Step: 4
Training loss: 2.656471871478235
Validation loss: 2.76361398712005

Epoch: 6| Step: 5
Training loss: 3.3345293919178407
Validation loss: 2.7718423339644382

Epoch: 6| Step: 6
Training loss: 3.88913866936351
Validation loss: 2.7621129083008764

Epoch: 6| Step: 7
Training loss: 2.464460485196154
Validation loss: 2.7636583576707405

Epoch: 6| Step: 8
Training loss: 2.8481540323351084
Validation loss: 2.759102106014125

Epoch: 6| Step: 9
Training loss: 2.645846289255055
Validation loss: 2.753291126778777

Epoch: 6| Step: 10
Training loss: 2.914144151786273
Validation loss: 2.7533778237307813

Epoch: 6| Step: 11
Training loss: 2.6516558242406747
Validation loss: 2.7551335162698343

Epoch: 6| Step: 12
Training loss: 3.1938632952457846
Validation loss: 2.7568536636040535

Epoch: 6| Step: 13
Training loss: 3.003502232004133
Validation loss: 2.7576559001917667

Epoch: 118| Step: 0
Training loss: 2.9019208268789196
Validation loss: 2.7598967353724224

Epoch: 6| Step: 1
Training loss: 2.738962042577208
Validation loss: 2.757324956511834

Epoch: 6| Step: 2
Training loss: 3.268745792889486
Validation loss: 2.7614484651447664

Epoch: 6| Step: 3
Training loss: 3.3234470785170647
Validation loss: 2.7622034686854224

Epoch: 6| Step: 4
Training loss: 2.971432568081065
Validation loss: 2.760730484258908

Epoch: 6| Step: 5
Training loss: 3.3230988423665186
Validation loss: 2.759153998976963

Epoch: 6| Step: 6
Training loss: 2.7344818966270297
Validation loss: 2.7618142495104054

Epoch: 6| Step: 7
Training loss: 3.6694026334044016
Validation loss: 2.761583705567996

Epoch: 6| Step: 8
Training loss: 3.1668505029688876
Validation loss: 2.761463970705063

Epoch: 6| Step: 9
Training loss: 3.1363125320714014
Validation loss: 2.758805008607212

Epoch: 6| Step: 10
Training loss: 3.332432498004988
Validation loss: 2.7600576906058607

Epoch: 6| Step: 11
Training loss: 3.2983580232312657
Validation loss: 2.7609127215786784

Epoch: 6| Step: 12
Training loss: 2.113164478961073
Validation loss: 2.7588319253527454

Epoch: 6| Step: 13
Training loss: 2.7939400217858856
Validation loss: 2.7582635365145274

Epoch: 119| Step: 0
Training loss: 3.653816782875779
Validation loss: 2.7579324816979223

Epoch: 6| Step: 1
Training loss: 3.6084799709580855
Validation loss: 2.756383651742075

Epoch: 6| Step: 2
Training loss: 2.873533455354743
Validation loss: 2.753785486830945

Epoch: 6| Step: 3
Training loss: 3.184416831867655
Validation loss: 2.7511622684636117

Epoch: 6| Step: 4
Training loss: 1.7715302012445366
Validation loss: 2.75225402006374

Epoch: 6| Step: 5
Training loss: 3.3579708979733196
Validation loss: 2.7530219253628805

Epoch: 6| Step: 6
Training loss: 2.645488886802459
Validation loss: 2.748368810516257

Epoch: 6| Step: 7
Training loss: 2.6471226672034236
Validation loss: 2.746377253044144

Epoch: 6| Step: 8
Training loss: 3.097358525749987
Validation loss: 2.7494783270255216

Epoch: 6| Step: 9
Training loss: 3.388180180916371
Validation loss: 2.748693871964991

Epoch: 6| Step: 10
Training loss: 3.534442639905233
Validation loss: 2.756019113053327

Epoch: 6| Step: 11
Training loss: 2.822672018075206
Validation loss: 2.756541294768938

Epoch: 6| Step: 12
Training loss: 2.735699142277547
Validation loss: 2.757413021635492

Epoch: 6| Step: 13
Training loss: 3.1253268261712632
Validation loss: 2.762003915038853

Epoch: 120| Step: 0
Training loss: 2.9079830785833587
Validation loss: 2.7646692254884173

Epoch: 6| Step: 1
Training loss: 3.0319326359655823
Validation loss: 2.7627007465645996

Epoch: 6| Step: 2
Training loss: 3.1582035779510345
Validation loss: 2.764841079730328

Epoch: 6| Step: 3
Training loss: 3.029108136296787
Validation loss: 2.762215805153615

Epoch: 6| Step: 4
Training loss: 2.9173985425866347
Validation loss: 2.758059600531134

Epoch: 6| Step: 5
Training loss: 2.921486405424067
Validation loss: 2.7536468637376528

Epoch: 6| Step: 6
Training loss: 3.011054652280253
Validation loss: 2.755044277469538

Epoch: 6| Step: 7
Training loss: 2.6621863955063225
Validation loss: 2.7432135215652114

Epoch: 6| Step: 8
Training loss: 3.387296528353562
Validation loss: 2.7489426184398265

Epoch: 6| Step: 9
Training loss: 3.3625121616299585
Validation loss: 2.748708423536459

Epoch: 6| Step: 10
Training loss: 2.698537384464099
Validation loss: 2.7517007563440905

Epoch: 6| Step: 11
Training loss: 3.1562506043084197
Validation loss: 2.748877031292026

Epoch: 6| Step: 12
Training loss: 3.3951822760616412
Validation loss: 2.754482295440404

Epoch: 6| Step: 13
Training loss: 3.2359848070577817
Validation loss: 2.756350775291964

Epoch: 121| Step: 0
Training loss: 2.308911503387441
Validation loss: 2.7530890079589185

Epoch: 6| Step: 1
Training loss: 3.5170761165327176
Validation loss: 2.755713324530998

Epoch: 6| Step: 2
Training loss: 3.0468709309868665
Validation loss: 2.761340828050718

Epoch: 6| Step: 3
Training loss: 3.2714816056424847
Validation loss: 2.765137002915267

Epoch: 6| Step: 4
Training loss: 3.019426706732439
Validation loss: 2.7635683932067088

Epoch: 6| Step: 5
Training loss: 2.567657305124665
Validation loss: 2.75465310211796

Epoch: 6| Step: 6
Training loss: 3.018588650579315
Validation loss: 2.761331492001524

Epoch: 6| Step: 7
Training loss: 2.7470572939502222
Validation loss: 2.75695727561893

Epoch: 6| Step: 8
Training loss: 3.810238902494119
Validation loss: 2.7543858096843943

Epoch: 6| Step: 9
Training loss: 3.4063548500652407
Validation loss: 2.7517378695728545

Epoch: 6| Step: 10
Training loss: 2.220570314540854
Validation loss: 2.7488433665257874

Epoch: 6| Step: 11
Training loss: 3.637259962413972
Validation loss: 2.752429509840251

Epoch: 6| Step: 12
Training loss: 2.9064081620689506
Validation loss: 2.7501507752253826

Epoch: 6| Step: 13
Training loss: 3.3036438216006276
Validation loss: 2.748805424738629

Epoch: 122| Step: 0
Training loss: 3.4756340930300493
Validation loss: 2.749590928126043

Epoch: 6| Step: 1
Training loss: 3.088423951314288
Validation loss: 2.7498714793611683

Epoch: 6| Step: 2
Training loss: 3.275462541603887
Validation loss: 2.7490698769360247

Epoch: 6| Step: 3
Training loss: 2.9704816084817165
Validation loss: 2.7490974764990685

Epoch: 6| Step: 4
Training loss: 2.6208269463862073
Validation loss: 2.748406946284707

Epoch: 6| Step: 5
Training loss: 3.0949707705299208
Validation loss: 2.7423157057959595

Epoch: 6| Step: 6
Training loss: 3.1966906422606636
Validation loss: 2.745214329138204

Epoch: 6| Step: 7
Training loss: 3.538102110179018
Validation loss: 2.7456594417298255

Epoch: 6| Step: 8
Training loss: 2.271134406146781
Validation loss: 2.7468629406639766

Epoch: 6| Step: 9
Training loss: 3.607561721115146
Validation loss: 2.7439701795057228

Epoch: 6| Step: 10
Training loss: 3.4151009174141613
Validation loss: 2.7405763262363902

Epoch: 6| Step: 11
Training loss: 2.2110062982753313
Validation loss: 2.7394697409941418

Epoch: 6| Step: 12
Training loss: 2.963282962137819
Validation loss: 2.7393768474785842

Epoch: 6| Step: 13
Training loss: 2.6981072573313702
Validation loss: 2.7409611255288353

Epoch: 123| Step: 0
Training loss: 3.0941648879398405
Validation loss: 2.7379612922325434

Epoch: 6| Step: 1
Training loss: 2.7901419466067234
Validation loss: 2.7440614119810993

Epoch: 6| Step: 2
Training loss: 3.4332783524885517
Validation loss: 2.7463105978668008

Epoch: 6| Step: 3
Training loss: 2.7526979216912806
Validation loss: 2.7526549148937947

Epoch: 6| Step: 4
Training loss: 3.165450029725005
Validation loss: 2.7520817999396803

Epoch: 6| Step: 5
Training loss: 3.492240615201841
Validation loss: 2.757846407591962

Epoch: 6| Step: 6
Training loss: 3.222344326760422
Validation loss: 2.7525888056965835

Epoch: 6| Step: 7
Training loss: 2.299474166801319
Validation loss: 2.7424257713244966

Epoch: 6| Step: 8
Training loss: 3.426947748503277
Validation loss: 2.736776034568285

Epoch: 6| Step: 9
Training loss: 2.8486877164103896
Validation loss: 2.737280074683201

Epoch: 6| Step: 10
Training loss: 2.7785265157167855
Validation loss: 2.7362690327856454

Epoch: 6| Step: 11
Training loss: 3.1349119538471926
Validation loss: 2.7338347723752423

Epoch: 6| Step: 12
Training loss: 2.802563131065414
Validation loss: 2.737799717769125

Epoch: 6| Step: 13
Training loss: 3.3970242773698334
Validation loss: 2.7375942816901015

Epoch: 124| Step: 0
Training loss: 3.5927604308000496
Validation loss: 2.7424549268858223

Epoch: 6| Step: 1
Training loss: 3.2721402094490037
Validation loss: 2.751232839462633

Epoch: 6| Step: 2
Training loss: 2.9972325912200377
Validation loss: 2.747518454558608

Epoch: 6| Step: 3
Training loss: 3.0847748316569112
Validation loss: 2.7399433906431323

Epoch: 6| Step: 4
Training loss: 2.7979325154627985
Validation loss: 2.7339546951747202

Epoch: 6| Step: 5
Training loss: 2.7124121445170593
Validation loss: 2.735344030947277

Epoch: 6| Step: 6
Training loss: 2.4748523475453803
Validation loss: 2.7371399366254945

Epoch: 6| Step: 7
Training loss: 3.227573781252372
Validation loss: 2.734590924669291

Epoch: 6| Step: 8
Training loss: 2.592449827527208
Validation loss: 2.734069032675832

Epoch: 6| Step: 9
Training loss: 3.1781255461355693
Validation loss: 2.737720224832158

Epoch: 6| Step: 10
Training loss: 3.2734146299450937
Validation loss: 2.742634023608589

Epoch: 6| Step: 11
Training loss: 2.8062207804562616
Validation loss: 2.743883742622169

Epoch: 6| Step: 12
Training loss: 3.1104553492790084
Validation loss: 2.737887369699841

Epoch: 6| Step: 13
Training loss: 3.6694048425457955
Validation loss: 2.738107281218081

Epoch: 125| Step: 0
Training loss: 2.798312366612286
Validation loss: 2.735514511131538

Epoch: 6| Step: 1
Training loss: 3.316285615306317
Validation loss: 2.7439780718375295

Epoch: 6| Step: 2
Training loss: 2.4447791154623517
Validation loss: 2.746989158800377

Epoch: 6| Step: 3
Training loss: 2.6324538713925767
Validation loss: 2.748157818293866

Epoch: 6| Step: 4
Training loss: 2.6899451731657007
Validation loss: 2.761535188216438

Epoch: 6| Step: 5
Training loss: 3.004601446497509
Validation loss: 2.795191786474914

Epoch: 6| Step: 6
Training loss: 3.266220111556885
Validation loss: 2.776068560656187

Epoch: 6| Step: 7
Training loss: 3.698644446452237
Validation loss: 2.7697916829320457

Epoch: 6| Step: 8
Training loss: 2.7556603871506957
Validation loss: 2.7391381003510777

Epoch: 6| Step: 9
Training loss: 3.6969197106902443
Validation loss: 2.729196343678984

Epoch: 6| Step: 10
Training loss: 3.0595160758638347
Validation loss: 2.7300960535164824

Epoch: 6| Step: 11
Training loss: 2.9503580684272195
Validation loss: 2.731650111101151

Epoch: 6| Step: 12
Training loss: 3.5202133415333887
Validation loss: 2.7328772127022254

Epoch: 6| Step: 13
Training loss: 2.265677615903044
Validation loss: 2.7351561552959938

Epoch: 126| Step: 0
Training loss: 3.5445834247868166
Validation loss: 2.7355252248317337

Epoch: 6| Step: 1
Training loss: 2.7824392455015485
Validation loss: 2.733453435107533

Epoch: 6| Step: 2
Training loss: 2.5529163065190406
Validation loss: 2.7320821291783703

Epoch: 6| Step: 3
Training loss: 3.4339198108479447
Validation loss: 2.7352299454439777

Epoch: 6| Step: 4
Training loss: 3.2314585930144144
Validation loss: 2.7344350931856742

Epoch: 6| Step: 5
Training loss: 3.5434442135916893
Validation loss: 2.740477036994334

Epoch: 6| Step: 6
Training loss: 2.231969218448599
Validation loss: 2.737540727036041

Epoch: 6| Step: 7
Training loss: 2.969379237900016
Validation loss: 2.7376683563473208

Epoch: 6| Step: 8
Training loss: 2.7234167626751904
Validation loss: 2.735505105682748

Epoch: 6| Step: 9
Training loss: 2.4650133077637517
Validation loss: 2.735926843048986

Epoch: 6| Step: 10
Training loss: 3.3202941175961733
Validation loss: 2.7352462013536973

Epoch: 6| Step: 11
Training loss: 3.149895342344664
Validation loss: 2.733749324628332

Epoch: 6| Step: 12
Training loss: 3.551399739434147
Validation loss: 2.734466358070834

Epoch: 6| Step: 13
Training loss: 3.1273922728014973
Validation loss: 2.7343758438038734

Epoch: 127| Step: 0
Training loss: 2.7942586414442103
Validation loss: 2.7302030946733318

Epoch: 6| Step: 1
Training loss: 2.934319580334789
Validation loss: 2.732384443112815

Epoch: 6| Step: 2
Training loss: 2.8587282210147182
Validation loss: 2.731481814949793

Epoch: 6| Step: 3
Training loss: 3.120326705846794
Validation loss: 2.729245533602474

Epoch: 6| Step: 4
Training loss: 3.4864588779752586
Validation loss: 2.7318651119003143

Epoch: 6| Step: 5
Training loss: 2.9689592789619526
Validation loss: 2.726801518968875

Epoch: 6| Step: 6
Training loss: 2.379587260769441
Validation loss: 2.7272205883755616

Epoch: 6| Step: 7
Training loss: 2.8987513780940155
Validation loss: 2.7266015631980287

Epoch: 6| Step: 8
Training loss: 3.7307604291238805
Validation loss: 2.7260097407953774

Epoch: 6| Step: 9
Training loss: 3.50372089418808
Validation loss: 2.721069452616211

Epoch: 6| Step: 10
Training loss: 2.610326353694213
Validation loss: 2.7232756344542257

Epoch: 6| Step: 11
Training loss: 3.1705994695639066
Validation loss: 2.7218171667233366

Epoch: 6| Step: 12
Training loss: 2.511716946472185
Validation loss: 2.723213905502938

Epoch: 6| Step: 13
Training loss: 3.8843265398459814
Validation loss: 2.721429460844662

Epoch: 128| Step: 0
Training loss: 2.8322974349582
Validation loss: 2.722560407082387

Epoch: 6| Step: 1
Training loss: 3.018892879540387
Validation loss: 2.7208917216143327

Epoch: 6| Step: 2
Training loss: 3.441582492294719
Validation loss: 2.7205978081184563

Epoch: 6| Step: 3
Training loss: 2.7147296689441394
Validation loss: 2.7238088521402046

Epoch: 6| Step: 4
Training loss: 2.9677501400142647
Validation loss: 2.7244590663419954

Epoch: 6| Step: 5
Training loss: 2.8744166238437323
Validation loss: 2.7229793232906534

Epoch: 6| Step: 6
Training loss: 2.5755905177939953
Validation loss: 2.7248961524559596

Epoch: 6| Step: 7
Training loss: 2.868088583233938
Validation loss: 2.7287071691007556

Epoch: 6| Step: 8
Training loss: 3.2291276170563976
Validation loss: 2.7208313952611523

Epoch: 6| Step: 9
Training loss: 3.2351528835578507
Validation loss: 2.723272767005412

Epoch: 6| Step: 10
Training loss: 3.115725984916828
Validation loss: 2.7276581408301017

Epoch: 6| Step: 11
Training loss: 3.388733648347258
Validation loss: 2.729107813297244

Epoch: 6| Step: 12
Training loss: 3.2747318012405464
Validation loss: 2.736083548096263

Epoch: 6| Step: 13
Training loss: 2.875985681490212
Validation loss: 2.735558104158422

Epoch: 129| Step: 0
Training loss: 2.9338664856366576
Validation loss: 2.7288006015142003

Epoch: 6| Step: 1
Training loss: 2.6708436280368053
Validation loss: 2.7187334757241297

Epoch: 6| Step: 2
Training loss: 2.683365680270573
Validation loss: 2.718153395284189

Epoch: 6| Step: 3
Training loss: 2.978252421772367
Validation loss: 2.7236637778231576

Epoch: 6| Step: 4
Training loss: 3.1195752170138378
Validation loss: 2.718736243292743

Epoch: 6| Step: 5
Training loss: 2.8028245439546042
Validation loss: 2.7256675347022528

Epoch: 6| Step: 6
Training loss: 3.465836409646684
Validation loss: 2.7233709410489397

Epoch: 6| Step: 7
Training loss: 3.2971610718044775
Validation loss: 2.726977015616447

Epoch: 6| Step: 8
Training loss: 3.6438126259291734
Validation loss: 2.72080998683866

Epoch: 6| Step: 9
Training loss: 2.5181188128545196
Validation loss: 2.7177380649466913

Epoch: 6| Step: 10
Training loss: 2.9015261087513284
Validation loss: 2.7151349684422934

Epoch: 6| Step: 11
Training loss: 2.8884041167528487
Validation loss: 2.716390237937961

Epoch: 6| Step: 12
Training loss: 2.613305517976351
Validation loss: 2.7164408979574723

Epoch: 6| Step: 13
Training loss: 4.173378205672595
Validation loss: 2.718865768953173

Epoch: 130| Step: 0
Training loss: 2.584286626667873
Validation loss: 2.715635830835558

Epoch: 6| Step: 1
Training loss: 2.5648963702053496
Validation loss: 2.7217286449830813

Epoch: 6| Step: 2
Training loss: 3.033541255853356
Validation loss: 2.7187144892788235

Epoch: 6| Step: 3
Training loss: 2.4551319246914534
Validation loss: 2.7201762868222565

Epoch: 6| Step: 4
Training loss: 3.1973674853486496
Validation loss: 2.7129218962595867

Epoch: 6| Step: 5
Training loss: 3.2753567042724017
Validation loss: 2.7136034969197818

Epoch: 6| Step: 6
Training loss: 3.460948108803224
Validation loss: 2.7155077796401783

Epoch: 6| Step: 7
Training loss: 3.525626912744548
Validation loss: 2.717700244038129

Epoch: 6| Step: 8
Training loss: 3.0844007311272352
Validation loss: 2.7116037115026685

Epoch: 6| Step: 9
Training loss: 3.386653419929289
Validation loss: 2.7164658175574306

Epoch: 6| Step: 10
Training loss: 2.6679246041484026
Validation loss: 2.7156446895949733

Epoch: 6| Step: 11
Training loss: 2.7669310853218607
Validation loss: 2.709764109917747

Epoch: 6| Step: 12
Training loss: 3.092569761853982
Validation loss: 2.7135427808512294

Epoch: 6| Step: 13
Training loss: 3.182147150249316
Validation loss: 2.7132505959448205

Epoch: 131| Step: 0
Training loss: 3.371836415831069
Validation loss: 2.7120619857850565

Epoch: 6| Step: 1
Training loss: 3.2277983360781186
Validation loss: 2.7059714538992052

Epoch: 6| Step: 2
Training loss: 3.4614849820040603
Validation loss: 2.7110389841074602

Epoch: 6| Step: 3
Training loss: 3.163968459250631
Validation loss: 2.709356322713032

Epoch: 6| Step: 4
Training loss: 2.632090393108469
Validation loss: 2.709550714252761

Epoch: 6| Step: 5
Training loss: 2.7036770824629466
Validation loss: 2.708222846214156

Epoch: 6| Step: 6
Training loss: 2.8234734824779397
Validation loss: 2.7107039596848157

Epoch: 6| Step: 7
Training loss: 3.110255744452285
Validation loss: 2.7091672618402756

Epoch: 6| Step: 8
Training loss: 3.5170233764045102
Validation loss: 2.7096203991754675

Epoch: 6| Step: 9
Training loss: 2.9727829694368917
Validation loss: 2.7078511555881346

Epoch: 6| Step: 10
Training loss: 2.891979663043978
Validation loss: 2.708684718305153

Epoch: 6| Step: 11
Training loss: 2.889500744736538
Validation loss: 2.7198771402309903

Epoch: 6| Step: 12
Training loss: 2.6452743861003887
Validation loss: 2.7289379258539483

Epoch: 6| Step: 13
Training loss: 2.7695886689382387
Validation loss: 2.7300355647939023

Epoch: 132| Step: 0
Training loss: 3.087943127913866
Validation loss: 2.7223162073627174

Epoch: 6| Step: 1
Training loss: 3.1334669233481303
Validation loss: 2.725741644737741

Epoch: 6| Step: 2
Training loss: 3.2119602328792394
Validation loss: 2.711800041597705

Epoch: 6| Step: 3
Training loss: 3.389757739837766
Validation loss: 2.7157284819851846

Epoch: 6| Step: 4
Training loss: 3.032435706354116
Validation loss: 2.7083148422430336

Epoch: 6| Step: 5
Training loss: 3.155242759203614
Validation loss: 2.706538546737779

Epoch: 6| Step: 6
Training loss: 3.038394962536019
Validation loss: 2.707122915299545

Epoch: 6| Step: 7
Training loss: 2.707372690661357
Validation loss: 2.7066785093683188

Epoch: 6| Step: 8
Training loss: 2.786918008031451
Validation loss: 2.7093505574030647

Epoch: 6| Step: 9
Training loss: 3.1879206361165475
Validation loss: 2.704857985753835

Epoch: 6| Step: 10
Training loss: 2.713144948201023
Validation loss: 2.709298390867375

Epoch: 6| Step: 11
Training loss: 2.967998208675204
Validation loss: 2.706089873617358

Epoch: 6| Step: 12
Training loss: 2.947788482862579
Validation loss: 2.7096039838503647

Epoch: 6| Step: 13
Training loss: 3.141537510032455
Validation loss: 2.7124923366080935

Epoch: 133| Step: 0
Training loss: 2.580850905630685
Validation loss: 2.7150465942535082

Epoch: 6| Step: 1
Training loss: 2.8688507660764753
Validation loss: 2.7253151188243274

Epoch: 6| Step: 2
Training loss: 2.976313863467223
Validation loss: 2.724705166543626

Epoch: 6| Step: 3
Training loss: 3.337168982159987
Validation loss: 2.7047205127269964

Epoch: 6| Step: 4
Training loss: 2.372056240952499
Validation loss: 2.7039683667841197

Epoch: 6| Step: 5
Training loss: 2.822524283940717
Validation loss: 2.701761237798375

Epoch: 6| Step: 6
Training loss: 3.0792444972077133
Validation loss: 2.704852106598542

Epoch: 6| Step: 7
Training loss: 3.2997068563941805
Validation loss: 2.705655001495627

Epoch: 6| Step: 8
Training loss: 3.134373150080461
Validation loss: 2.708917384123689

Epoch: 6| Step: 9
Training loss: 3.5418766782240683
Validation loss: 2.699393063505476

Epoch: 6| Step: 10
Training loss: 2.982119361908888
Validation loss: 2.6997024195157504

Epoch: 6| Step: 11
Training loss: 2.6520406243620407
Validation loss: 2.701895518666108

Epoch: 6| Step: 12
Training loss: 3.3692309204385587
Validation loss: 2.7024506631079794

Epoch: 6| Step: 13
Training loss: 3.3588861154077994
Validation loss: 2.7132286845642497

Epoch: 134| Step: 0
Training loss: 3.1264846326900866
Validation loss: 2.705501993875802

Epoch: 6| Step: 1
Training loss: 3.0968797054312764
Validation loss: 2.7228628978693976

Epoch: 6| Step: 2
Training loss: 2.6228272664956505
Validation loss: 2.7218387169825715

Epoch: 6| Step: 3
Training loss: 3.149996766588277
Validation loss: 2.7226007875820937

Epoch: 6| Step: 4
Training loss: 3.0934525163754065
Validation loss: 2.735888770390834

Epoch: 6| Step: 5
Training loss: 3.073885869346576
Validation loss: 2.7388805484736953

Epoch: 6| Step: 6
Training loss: 2.3003650541434113
Validation loss: 2.7284565336509807

Epoch: 6| Step: 7
Training loss: 3.145108339417707
Validation loss: 2.737104378821539

Epoch: 6| Step: 8
Training loss: 4.080562871365661
Validation loss: 2.7141950992564676

Epoch: 6| Step: 9
Training loss: 3.212337587755988
Validation loss: 2.7075188698685464

Epoch: 6| Step: 10
Training loss: 2.4157146244769105
Validation loss: 2.709029799299954

Epoch: 6| Step: 11
Training loss: 2.6602482940837566
Validation loss: 2.7112802443266055

Epoch: 6| Step: 12
Training loss: 3.0056488578104927
Validation loss: 2.7089577389718515

Epoch: 6| Step: 13
Training loss: 3.0142844585604625
Validation loss: 2.70263477560326

Epoch: 135| Step: 0
Training loss: 3.0377814331286945
Validation loss: 2.7028263308059954

Epoch: 6| Step: 1
Training loss: 2.7516543007504817
Validation loss: 2.7053239925590407

Epoch: 6| Step: 2
Training loss: 2.8449918948629604
Validation loss: 2.7017314936439276

Epoch: 6| Step: 3
Training loss: 2.8785053942008445
Validation loss: 2.703708046874244

Epoch: 6| Step: 4
Training loss: 3.249532372504329
Validation loss: 2.7021111165939002

Epoch: 6| Step: 5
Training loss: 3.292684631037077
Validation loss: 2.6994676014168637

Epoch: 6| Step: 6
Training loss: 3.3234892603937563
Validation loss: 2.701625774538384

Epoch: 6| Step: 7
Training loss: 3.0481115717354506
Validation loss: 2.6988558274666556

Epoch: 6| Step: 8
Training loss: 2.337009349877748
Validation loss: 2.699302682838537

Epoch: 6| Step: 9
Training loss: 3.1602642856610283
Validation loss: 2.6992534287785226

Epoch: 6| Step: 10
Training loss: 3.154232626812787
Validation loss: 2.697066216063742

Epoch: 6| Step: 11
Training loss: 2.8540890722563383
Validation loss: 2.6981957264717904

Epoch: 6| Step: 12
Training loss: 3.1710477605258696
Validation loss: 2.6984924618623936

Epoch: 6| Step: 13
Training loss: 3.1166805151429426
Validation loss: 2.6988364931517683

Epoch: 136| Step: 0
Training loss: 3.554702121578788
Validation loss: 2.6978660582233616

Epoch: 6| Step: 1
Training loss: 3.4180239950892473
Validation loss: 2.6992523375050412

Epoch: 6| Step: 2
Training loss: 2.9920823200753386
Validation loss: 2.703326489309761

Epoch: 6| Step: 3
Training loss: 3.1515540512947613
Validation loss: 2.7066009401552593

Epoch: 6| Step: 4
Training loss: 2.6915557775498744
Validation loss: 2.711240919721993

Epoch: 6| Step: 5
Training loss: 2.453402752550658
Validation loss: 2.7196395092159045

Epoch: 6| Step: 6
Training loss: 3.7365244022707316
Validation loss: 2.726959441264997

Epoch: 6| Step: 7
Training loss: 3.0122443506183276
Validation loss: 2.714103499011179

Epoch: 6| Step: 8
Training loss: 2.772841010624777
Validation loss: 2.7044954635454093

Epoch: 6| Step: 9
Training loss: 3.330292761365554
Validation loss: 2.6892533197964115

Epoch: 6| Step: 10
Training loss: 2.1592188865661024
Validation loss: 2.68976129863668

Epoch: 6| Step: 11
Training loss: 2.1435724835536902
Validation loss: 2.6915479920047867

Epoch: 6| Step: 12
Training loss: 3.17268759555357
Validation loss: 2.6960150137402588

Epoch: 6| Step: 13
Training loss: 3.419763200827134
Validation loss: 2.6988801884682103

Epoch: 137| Step: 0
Training loss: 3.169443184839998
Validation loss: 2.6981972618837875

Epoch: 6| Step: 1
Training loss: 3.1337341322799555
Validation loss: 2.6925730833245063

Epoch: 6| Step: 2
Training loss: 2.542566692486588
Validation loss: 2.6895670438216492

Epoch: 6| Step: 3
Training loss: 3.5671349874567113
Validation loss: 2.697549445665936

Epoch: 6| Step: 4
Training loss: 3.3253557746250295
Validation loss: 2.712330478410161

Epoch: 6| Step: 5
Training loss: 3.0575424862621046
Validation loss: 2.727660035604835

Epoch: 6| Step: 6
Training loss: 3.4074063919207154
Validation loss: 2.7398071868246876

Epoch: 6| Step: 7
Training loss: 2.77312370996658
Validation loss: 2.7350359393007744

Epoch: 6| Step: 8
Training loss: 2.8678922280847967
Validation loss: 2.7446882682179643

Epoch: 6| Step: 9
Training loss: 2.8878234483956953
Validation loss: 2.7231860191325077

Epoch: 6| Step: 10
Training loss: 3.6420170165182366
Validation loss: 2.7086524914157204

Epoch: 6| Step: 11
Training loss: 2.940927332255661
Validation loss: 2.6957652387799365

Epoch: 6| Step: 12
Training loss: 1.957186694643725
Validation loss: 2.6879130697303473

Epoch: 6| Step: 13
Training loss: 2.3922596248465378
Validation loss: 2.6864722371704315

Epoch: 138| Step: 0
Training loss: 2.8862837901229437
Validation loss: 2.68741308187627

Epoch: 6| Step: 1
Training loss: 3.123868966464681
Validation loss: 2.6881932201371708

Epoch: 6| Step: 2
Training loss: 3.262609814662853
Validation loss: 2.6913821909325177

Epoch: 6| Step: 3
Training loss: 3.00838316420886
Validation loss: 2.6868152485347236

Epoch: 6| Step: 4
Training loss: 2.8725492563830266
Validation loss: 2.6858566670506674

Epoch: 6| Step: 5
Training loss: 2.58890844518709
Validation loss: 2.693377785379306

Epoch: 6| Step: 6
Training loss: 3.667050962827903
Validation loss: 2.688539117628337

Epoch: 6| Step: 7
Training loss: 3.0109124396904043
Validation loss: 2.6906010126109368

Epoch: 6| Step: 8
Training loss: 3.612644580732959
Validation loss: 2.6854919101016193

Epoch: 6| Step: 9
Training loss: 2.0578625880744528
Validation loss: 2.6867360400230162

Epoch: 6| Step: 10
Training loss: 2.770706078229164
Validation loss: 2.6912594651954924

Epoch: 6| Step: 11
Training loss: 2.3360036374939073
Validation loss: 2.6870388113204546

Epoch: 6| Step: 12
Training loss: 3.479295526429092
Validation loss: 2.696388996734277

Epoch: 6| Step: 13
Training loss: 3.2988655625743473
Validation loss: 2.6973765118324224

Epoch: 139| Step: 0
Training loss: 2.7360828406803903
Validation loss: 2.7077841120599095

Epoch: 6| Step: 1
Training loss: 3.2003282199857574
Validation loss: 2.707093518420576

Epoch: 6| Step: 2
Training loss: 2.567089715582438
Validation loss: 2.709907562342171

Epoch: 6| Step: 3
Training loss: 3.1920510507961293
Validation loss: 2.718261986123844

Epoch: 6| Step: 4
Training loss: 3.293288318336685
Validation loss: 2.712008974322671

Epoch: 6| Step: 5
Training loss: 2.728520256153237
Validation loss: 2.717403359829135

Epoch: 6| Step: 6
Training loss: 2.5289282806351374
Validation loss: 2.7140734031910174

Epoch: 6| Step: 7
Training loss: 3.547197369281239
Validation loss: 2.722084580364703

Epoch: 6| Step: 8
Training loss: 3.278291949302014
Validation loss: 2.721179004858343

Epoch: 6| Step: 9
Training loss: 2.6294905989443134
Validation loss: 2.7128834109757958

Epoch: 6| Step: 10
Training loss: 2.995879840799329
Validation loss: 2.7016181442205007

Epoch: 6| Step: 11
Training loss: 3.7033471149516624
Validation loss: 2.6987193254183817

Epoch: 6| Step: 12
Training loss: 2.9846363851911075
Validation loss: 2.698101486987665

Epoch: 6| Step: 13
Training loss: 2.0607898442355768
Validation loss: 2.690767315329433

Epoch: 140| Step: 0
Training loss: 3.2981001037618
Validation loss: 2.6964599953579644

Epoch: 6| Step: 1
Training loss: 3.3164391757512335
Validation loss: 2.685009855122943

Epoch: 6| Step: 2
Training loss: 2.7346070109437988
Validation loss: 2.6901495851206025

Epoch: 6| Step: 3
Training loss: 3.176162302727397
Validation loss: 2.6897051359944246

Epoch: 6| Step: 4
Training loss: 2.783792084066188
Validation loss: 2.6880297852888533

Epoch: 6| Step: 5
Training loss: 2.6140277976533257
Validation loss: 2.691479155529083

Epoch: 6| Step: 6
Training loss: 2.9092893397323465
Validation loss: 2.683844368284323

Epoch: 6| Step: 7
Training loss: 2.6229945196748203
Validation loss: 2.684709680570457

Epoch: 6| Step: 8
Training loss: 2.7585104256412705
Validation loss: 2.6856246838526534

Epoch: 6| Step: 9
Training loss: 3.036289391417198
Validation loss: 2.687355789318031

Epoch: 6| Step: 10
Training loss: 3.464601114716417
Validation loss: 2.685796890091215

Epoch: 6| Step: 11
Training loss: 3.0863117232548927
Validation loss: 2.686963750210078

Epoch: 6| Step: 12
Training loss: 2.8356995706083774
Validation loss: 2.6852269730196068

Epoch: 6| Step: 13
Training loss: 3.67764763468973
Validation loss: 2.6902136031969235

Epoch: 141| Step: 0
Training loss: 3.193618586574432
Validation loss: 2.686146232299389

Epoch: 6| Step: 1
Training loss: 3.395731793779244
Validation loss: 2.692409850547346

Epoch: 6| Step: 2
Training loss: 2.967777775632318
Validation loss: 2.688783288208827

Epoch: 6| Step: 3
Training loss: 2.615360909350223
Validation loss: 2.684135235624071

Epoch: 6| Step: 4
Training loss: 3.3073575391241814
Validation loss: 2.68556501055399

Epoch: 6| Step: 5
Training loss: 3.2339043758600887
Validation loss: 2.6877081586042935

Epoch: 6| Step: 6
Training loss: 3.1736063624447817
Validation loss: 2.6795855259722794

Epoch: 6| Step: 7
Training loss: 3.2233937662239387
Validation loss: 2.687963321294178

Epoch: 6| Step: 8
Training loss: 3.1417487871549112
Validation loss: 2.6791662616130103

Epoch: 6| Step: 9
Training loss: 2.3643623842593042
Validation loss: 2.677301479290666

Epoch: 6| Step: 10
Training loss: 2.9930571644349184
Validation loss: 2.677643625176212

Epoch: 6| Step: 11
Training loss: 2.413866251156617
Validation loss: 2.67959583950495

Epoch: 6| Step: 12
Training loss: 2.8837488819478962
Validation loss: 2.67656060445332

Epoch: 6| Step: 13
Training loss: 3.0784485932482246
Validation loss: 2.6802517206556096

Epoch: 142| Step: 0
Training loss: 3.1803052897229604
Validation loss: 2.678791006320274

Epoch: 6| Step: 1
Training loss: 3.4365672840162467
Validation loss: 2.6881708250863383

Epoch: 6| Step: 2
Training loss: 3.2243579787300294
Validation loss: 2.6868298480345634

Epoch: 6| Step: 3
Training loss: 3.7312582249127444
Validation loss: 2.6927858936810956

Epoch: 6| Step: 4
Training loss: 3.033181430520453
Validation loss: 2.6873171887961176

Epoch: 6| Step: 5
Training loss: 2.8374557424446345
Validation loss: 2.68134563969723

Epoch: 6| Step: 6
Training loss: 2.23260075477424
Validation loss: 2.6920901165419577

Epoch: 6| Step: 7
Training loss: 2.543048628857764
Validation loss: 2.689732240036597

Epoch: 6| Step: 8
Training loss: 2.540242270231993
Validation loss: 2.691780251398911

Epoch: 6| Step: 9
Training loss: 3.011299153548695
Validation loss: 2.6976342429739892

Epoch: 6| Step: 10
Training loss: 3.2450776604292226
Validation loss: 2.7021697935890523

Epoch: 6| Step: 11
Training loss: 3.431900457490291
Validation loss: 2.6935397259995004

Epoch: 6| Step: 12
Training loss: 2.5727458902329334
Validation loss: 2.6818735751210108

Epoch: 6| Step: 13
Training loss: 2.349406930473577
Validation loss: 2.6812397779648545

Epoch: 143| Step: 0
Training loss: 3.0828352001686574
Validation loss: 2.6796059578264413

Epoch: 6| Step: 1
Training loss: 3.0126997442228345
Validation loss: 2.6755569765219605

Epoch: 6| Step: 2
Training loss: 3.432549119168635
Validation loss: 2.6747484571328135

Epoch: 6| Step: 3
Training loss: 2.739763280569533
Validation loss: 2.6704201092134787

Epoch: 6| Step: 4
Training loss: 2.9244389835539866
Validation loss: 2.674229755129538

Epoch: 6| Step: 5
Training loss: 2.9589044440524273
Validation loss: 2.6743879165576954

Epoch: 6| Step: 6
Training loss: 3.2977444193895975
Validation loss: 2.6734305608250146

Epoch: 6| Step: 7
Training loss: 3.5588334606849914
Validation loss: 2.67629359829511

Epoch: 6| Step: 8
Training loss: 2.8043532318433417
Validation loss: 2.677122493505521

Epoch: 6| Step: 9
Training loss: 2.927280261020885
Validation loss: 2.6790650725118397

Epoch: 6| Step: 10
Training loss: 2.4071976418141015
Validation loss: 2.683712950805905

Epoch: 6| Step: 11
Training loss: 3.0543559252988515
Validation loss: 2.697232316905939

Epoch: 6| Step: 12
Training loss: 2.7305409608823665
Validation loss: 2.701268282242585

Epoch: 6| Step: 13
Training loss: 2.846364590462005
Validation loss: 2.7152040558963546

Epoch: 144| Step: 0
Training loss: 2.5167874322003905
Validation loss: 2.7146909250367437

Epoch: 6| Step: 1
Training loss: 3.142198462635495
Validation loss: 2.7219631353113414

Epoch: 6| Step: 2
Training loss: 3.239688066136791
Validation loss: 2.7072444976732877

Epoch: 6| Step: 3
Training loss: 2.856882144749632
Validation loss: 2.707332495890286

Epoch: 6| Step: 4
Training loss: 2.9136085463480743
Validation loss: 2.69816127258494

Epoch: 6| Step: 5
Training loss: 3.453453635203178
Validation loss: 2.6956305983277873

Epoch: 6| Step: 6
Training loss: 2.9473958628137056
Validation loss: 2.6730896806245927

Epoch: 6| Step: 7
Training loss: 3.343394037711716
Validation loss: 2.6731675653241393

Epoch: 6| Step: 8
Training loss: 2.6243537834020287
Validation loss: 2.668728739358941

Epoch: 6| Step: 9
Training loss: 2.796310708858165
Validation loss: 2.674248160117776

Epoch: 6| Step: 10
Training loss: 3.2111810373731897
Validation loss: 2.6748207643294553

Epoch: 6| Step: 11
Training loss: 2.526759556226209
Validation loss: 2.6718323781000297

Epoch: 6| Step: 12
Training loss: 3.1527708915228194
Validation loss: 2.6764558024940324

Epoch: 6| Step: 13
Training loss: 3.0911293104330593
Validation loss: 2.678374864287252

Epoch: 145| Step: 0
Training loss: 3.248077704397435
Validation loss: 2.6794870354760545

Epoch: 6| Step: 1
Training loss: 2.555755951759642
Validation loss: 2.682020086933467

Epoch: 6| Step: 2
Training loss: 3.122135069804637
Validation loss: 2.677651215624007

Epoch: 6| Step: 3
Training loss: 3.1281551454903593
Validation loss: 2.680310996709069

Epoch: 6| Step: 4
Training loss: 3.4650909094836644
Validation loss: 2.679119543453024

Epoch: 6| Step: 5
Training loss: 3.4678461770303404
Validation loss: 2.6739200493633755

Epoch: 6| Step: 6
Training loss: 2.5011451006029257
Validation loss: 2.676260833840154

Epoch: 6| Step: 7
Training loss: 2.884845626641187
Validation loss: 2.6750717962698882

Epoch: 6| Step: 8
Training loss: 2.467225581932782
Validation loss: 2.673294234483063

Epoch: 6| Step: 9
Training loss: 3.057021242276936
Validation loss: 2.669658410931883

Epoch: 6| Step: 10
Training loss: 2.535999128588217
Validation loss: 2.673360008320653

Epoch: 6| Step: 11
Training loss: 3.088379948431148
Validation loss: 2.666898891953401

Epoch: 6| Step: 12
Training loss: 3.119555346030232
Validation loss: 2.6702466789764356

Epoch: 6| Step: 13
Training loss: 3.604145439541145
Validation loss: 2.6682400884423965

Epoch: 146| Step: 0
Training loss: 2.792914287329568
Validation loss: 2.6809768762915738

Epoch: 6| Step: 1
Training loss: 3.3662404013977434
Validation loss: 2.6851252208236587

Epoch: 6| Step: 2
Training loss: 2.313696474417598
Validation loss: 2.68217443123767

Epoch: 6| Step: 3
Training loss: 3.3073641711520243
Validation loss: 2.696241423028792

Epoch: 6| Step: 4
Training loss: 2.427367743553718
Validation loss: 2.6945191754179185

Epoch: 6| Step: 5
Training loss: 3.46149903299422
Validation loss: 2.6857078464327193

Epoch: 6| Step: 6
Training loss: 2.358403188886259
Validation loss: 2.6702620190319957

Epoch: 6| Step: 7
Training loss: 3.3797638791466156
Validation loss: 2.6663151917660217

Epoch: 6| Step: 8
Training loss: 2.9495013575275126
Validation loss: 2.6626199953587824

Epoch: 6| Step: 9
Training loss: 2.960796101195833
Validation loss: 2.6597839762837436

Epoch: 6| Step: 10
Training loss: 2.9966292518200794
Validation loss: 2.663598488089104

Epoch: 6| Step: 11
Training loss: 3.309044096831868
Validation loss: 2.6652753056066225

Epoch: 6| Step: 12
Training loss: 2.967026059387575
Validation loss: 2.6588640788429285

Epoch: 6| Step: 13
Training loss: 3.09230100048493
Validation loss: 2.664605402176589

Epoch: 147| Step: 0
Training loss: 3.2795465316390975
Validation loss: 2.6675943067341015

Epoch: 6| Step: 1
Training loss: 3.1094943076396144
Validation loss: 2.6702987309275628

Epoch: 6| Step: 2
Training loss: 3.311454607991566
Validation loss: 2.680696692805057

Epoch: 6| Step: 3
Training loss: 2.685804852665957
Validation loss: 2.67708493096976

Epoch: 6| Step: 4
Training loss: 2.259553970276498
Validation loss: 2.6737619523055556

Epoch: 6| Step: 5
Training loss: 2.6803024075827246
Validation loss: 2.690179411112532

Epoch: 6| Step: 6
Training loss: 2.8126342741384978
Validation loss: 2.68505647461463

Epoch: 6| Step: 7
Training loss: 2.537583046291765
Validation loss: 2.688497054561587

Epoch: 6| Step: 8
Training loss: 2.6996642433787095
Validation loss: 2.682936726052267

Epoch: 6| Step: 9
Training loss: 3.1114781613522178
Validation loss: 2.689977217229846

Epoch: 6| Step: 10
Training loss: 3.3608737175146235
Validation loss: 2.6986708567814706

Epoch: 6| Step: 11
Training loss: 3.2025276929743445
Validation loss: 2.6846882161473267

Epoch: 6| Step: 12
Training loss: 3.189639551492429
Validation loss: 2.6771826389095925

Epoch: 6| Step: 13
Training loss: 3.7276625059383677
Validation loss: 2.6918254317316714

Epoch: 148| Step: 0
Training loss: 3.0368189044175056
Validation loss: 2.6659272765357587

Epoch: 6| Step: 1
Training loss: 2.5605137267829567
Validation loss: 2.6569205454162237

Epoch: 6| Step: 2
Training loss: 2.6996829659156423
Validation loss: 2.657744900138057

Epoch: 6| Step: 3
Training loss: 3.414304816334537
Validation loss: 2.6607905446863986

Epoch: 6| Step: 4
Training loss: 3.2000401971199666
Validation loss: 2.6695001671229894

Epoch: 6| Step: 5
Training loss: 2.8829206741010376
Validation loss: 2.668289848684995

Epoch: 6| Step: 6
Training loss: 2.7987857024763847
Validation loss: 2.680338017844531

Epoch: 6| Step: 7
Training loss: 3.0246144450993926
Validation loss: 2.6874802691953277

Epoch: 6| Step: 8
Training loss: 2.954806701740965
Validation loss: 2.6812367642098405

Epoch: 6| Step: 9
Training loss: 3.4057621037746197
Validation loss: 2.6791428437862153

Epoch: 6| Step: 10
Training loss: 2.8730306099769036
Validation loss: 2.6829802331308534

Epoch: 6| Step: 11
Training loss: 3.2073244432437007
Validation loss: 2.6680874314751137

Epoch: 6| Step: 12
Training loss: 2.451481748652649
Validation loss: 2.6675370748062606

Epoch: 6| Step: 13
Training loss: 3.7815589463308905
Validation loss: 2.6612307000838293

Epoch: 149| Step: 0
Training loss: 3.4289825340575986
Validation loss: 2.6648711676647054

Epoch: 6| Step: 1
Training loss: 2.7986698465255015
Validation loss: 2.6587791104854515

Epoch: 6| Step: 2
Training loss: 3.469571677824725
Validation loss: 2.6709121939208553

Epoch: 6| Step: 3
Training loss: 2.512514833624783
Validation loss: 2.6713549012939093

Epoch: 6| Step: 4
Training loss: 2.6008056822821204
Validation loss: 2.6905272333540173

Epoch: 6| Step: 5
Training loss: 3.5854670064267506
Validation loss: 2.690112576149257

Epoch: 6| Step: 6
Training loss: 2.8228643396086155
Validation loss: 2.6777706560696504

Epoch: 6| Step: 7
Training loss: 2.9316733178660934
Validation loss: 2.6609013194511135

Epoch: 6| Step: 8
Training loss: 2.5814196256087043
Validation loss: 2.656467560575442

Epoch: 6| Step: 9
Training loss: 3.1086725562940623
Validation loss: 2.657807362552041

Epoch: 6| Step: 10
Training loss: 3.5971699239954136
Validation loss: 2.6571436209469863

Epoch: 6| Step: 11
Training loss: 2.568822457806819
Validation loss: 2.656743775232215

Epoch: 6| Step: 12
Training loss: 2.6381720712633574
Validation loss: 2.6576032671855656

Epoch: 6| Step: 13
Training loss: 2.9176082362844005
Validation loss: 2.6591557822636496

Epoch: 150| Step: 0
Training loss: 2.3907119635428593
Validation loss: 2.658319951089103

Epoch: 6| Step: 1
Training loss: 2.825529899524025
Validation loss: 2.6603804071601087

Epoch: 6| Step: 2
Training loss: 3.07615854411794
Validation loss: 2.65684492770583

Epoch: 6| Step: 3
Training loss: 3.4848423118436114
Validation loss: 2.657451124026505

Epoch: 6| Step: 4
Training loss: 2.8807577444997206
Validation loss: 2.658097457476281

Epoch: 6| Step: 5
Training loss: 3.4069493127114123
Validation loss: 2.656559147660497

Epoch: 6| Step: 6
Training loss: 3.0672470980901076
Validation loss: 2.6577351963204054

Epoch: 6| Step: 7
Training loss: 2.9572339410490143
Validation loss: 2.654903482204112

Epoch: 6| Step: 8
Training loss: 2.6036299088757944
Validation loss: 2.658017410539815

Epoch: 6| Step: 9
Training loss: 2.9468161389974203
Validation loss: 2.6594338779952795

Epoch: 6| Step: 10
Training loss: 2.8926557676003455
Validation loss: 2.6597135225191564

Epoch: 6| Step: 11
Training loss: 3.485303678047359
Validation loss: 2.660688783920642

Epoch: 6| Step: 12
Training loss: 2.5747335610921014
Validation loss: 2.6834391653761704

Epoch: 6| Step: 13
Training loss: 3.2331136556765925
Validation loss: 2.728096564703996

Testing loss: 2.8881363373508453
