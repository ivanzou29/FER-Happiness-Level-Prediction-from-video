Epoch: 1| Step: 0
Training loss: 5.423001289367676
Validation loss: 5.260098493227395

Epoch: 5| Step: 1
Training loss: 5.603772163391113
Validation loss: 5.248472798255182

Epoch: 5| Step: 2
Training loss: 5.929618835449219
Validation loss: 5.237403013372934

Epoch: 5| Step: 3
Training loss: 3.443169116973877
Validation loss: 5.227759356139808

Epoch: 5| Step: 4
Training loss: 4.356961250305176
Validation loss: 5.218019885401572

Epoch: 5| Step: 5
Training loss: 5.012654781341553
Validation loss: 5.208414344377415

Epoch: 5| Step: 6
Training loss: 4.6056413650512695
Validation loss: 5.197663166189707

Epoch: 5| Step: 7
Training loss: 5.0800461769104
Validation loss: 5.186827546806746

Epoch: 5| Step: 8
Training loss: 5.3552565574646
Validation loss: 5.174840516941522

Epoch: 5| Step: 9
Training loss: 5.091668605804443
Validation loss: 5.162285333038659

Epoch: 5| Step: 10
Training loss: 5.139657020568848
Validation loss: 5.1488606442687335

Epoch: 2| Step: 0
Training loss: 4.5878190994262695
Validation loss: 5.134464535661923

Epoch: 5| Step: 1
Training loss: 4.566364288330078
Validation loss: 5.119091351826985

Epoch: 5| Step: 2
Training loss: 5.217641353607178
Validation loss: 5.102630092251685

Epoch: 5| Step: 3
Training loss: 5.174866199493408
Validation loss: 5.085440594662902

Epoch: 5| Step: 4
Training loss: 4.820305824279785
Validation loss: 5.0670408536029115

Epoch: 5| Step: 5
Training loss: 4.844943046569824
Validation loss: 5.047057064630652

Epoch: 5| Step: 6
Training loss: 4.9643144607543945
Validation loss: 5.025930214953679

Epoch: 5| Step: 7
Training loss: 5.013155937194824
Validation loss: 5.004545063100835

Epoch: 5| Step: 8
Training loss: 4.812290191650391
Validation loss: 4.982002001936718

Epoch: 5| Step: 9
Training loss: 4.633940696716309
Validation loss: 4.957497940268568

Epoch: 5| Step: 10
Training loss: 4.520651340484619
Validation loss: 4.933581952125795

Epoch: 3| Step: 0
Training loss: 5.376074314117432
Validation loss: 4.908990019111223

Epoch: 5| Step: 1
Training loss: 4.533812522888184
Validation loss: 4.88325555862919

Epoch: 5| Step: 2
Training loss: 5.005490303039551
Validation loss: 4.857158127651419

Epoch: 5| Step: 3
Training loss: 4.080655574798584
Validation loss: 4.832263505587014

Epoch: 5| Step: 4
Training loss: 4.4386186599731445
Validation loss: 4.805665154610911

Epoch: 5| Step: 5
Training loss: 4.429804801940918
Validation loss: 4.7784982445419475

Epoch: 5| Step: 6
Training loss: 3.5913074016571045
Validation loss: 4.752228870186754

Epoch: 5| Step: 7
Training loss: 4.981591701507568
Validation loss: 4.726813977764499

Epoch: 5| Step: 8
Training loss: 4.8405256271362305
Validation loss: 4.701143695462134

Epoch: 5| Step: 9
Training loss: 4.057169437408447
Validation loss: 4.675190782034269

Epoch: 5| Step: 10
Training loss: 4.997515678405762
Validation loss: 4.650503661042901

Epoch: 4| Step: 0
Training loss: 4.910994529724121
Validation loss: 4.624162043294599

Epoch: 5| Step: 1
Training loss: 2.8869357109069824
Validation loss: 4.596739722836402

Epoch: 5| Step: 2
Training loss: 4.209860324859619
Validation loss: 4.569494903728526

Epoch: 5| Step: 3
Training loss: 5.316277503967285
Validation loss: 4.543737319207961

Epoch: 5| Step: 4
Training loss: 3.357707977294922
Validation loss: 4.514746850536715

Epoch: 5| Step: 5
Training loss: 4.462831020355225
Validation loss: 4.487487736568656

Epoch: 5| Step: 6
Training loss: 4.730949878692627
Validation loss: 4.45680042492446

Epoch: 5| Step: 7
Training loss: 5.021419048309326
Validation loss: 4.428670242268552

Epoch: 5| Step: 8
Training loss: 4.66051721572876
Validation loss: 4.400400515525572

Epoch: 5| Step: 9
Training loss: 3.4417526721954346
Validation loss: 4.369834594829108

Epoch: 5| Step: 10
Training loss: 4.03891658782959
Validation loss: 4.3396764263030025

Epoch: 5| Step: 0
Training loss: 3.733400344848633
Validation loss: 4.311977217274327

Epoch: 5| Step: 1
Training loss: 3.8801941871643066
Validation loss: 4.282812013421007

Epoch: 5| Step: 2
Training loss: 5.422421932220459
Validation loss: 4.252064715149582

Epoch: 5| Step: 3
Training loss: 3.913245677947998
Validation loss: 4.2248299865312475

Epoch: 5| Step: 4
Training loss: 3.4743568897247314
Validation loss: 4.196003396023986

Epoch: 5| Step: 5
Training loss: 4.874213218688965
Validation loss: 4.1709944407145185

Epoch: 5| Step: 6
Training loss: 3.599916934967041
Validation loss: 4.146485318419754

Epoch: 5| Step: 7
Training loss: 4.025388717651367
Validation loss: 4.121204355711578

Epoch: 5| Step: 8
Training loss: 3.0375285148620605
Validation loss: 4.0971875806008615

Epoch: 5| Step: 9
Training loss: 4.077602386474609
Validation loss: 4.073994892899708

Epoch: 5| Step: 10
Training loss: 3.8950719833374023
Validation loss: 4.050272869807418

Epoch: 6| Step: 0
Training loss: 4.1753339767456055
Validation loss: 4.023731793126752

Epoch: 5| Step: 1
Training loss: 4.263381481170654
Validation loss: 4.00055359512247

Epoch: 5| Step: 2
Training loss: 5.089443206787109
Validation loss: 3.9812732101768575

Epoch: 5| Step: 3
Training loss: 3.947516918182373
Validation loss: 3.961586844536566

Epoch: 5| Step: 4
Training loss: 3.501272201538086
Validation loss: 3.9430790101328204

Epoch: 5| Step: 5
Training loss: 3.778773069381714
Validation loss: 3.929342228879211

Epoch: 5| Step: 6
Training loss: 4.184107780456543
Validation loss: 3.916284579102711

Epoch: 5| Step: 7
Training loss: 4.400971412658691
Validation loss: 3.8996383502919185

Epoch: 5| Step: 8
Training loss: 3.6079132556915283
Validation loss: 3.8823405183771604

Epoch: 5| Step: 9
Training loss: 1.7674576044082642
Validation loss: 3.8691101740765315

Epoch: 5| Step: 10
Training loss: 2.9342963695526123
Validation loss: 3.858031452343028

Epoch: 7| Step: 0
Training loss: 3.65617299079895
Validation loss: 3.8485810064500376

Epoch: 5| Step: 1
Training loss: 5.164529323577881
Validation loss: 3.8354338779244372

Epoch: 5| Step: 2
Training loss: 3.1364223957061768
Validation loss: 3.8214380023300007

Epoch: 5| Step: 3
Training loss: 4.138699054718018
Validation loss: 3.810164761799638

Epoch: 5| Step: 4
Training loss: 3.427208662033081
Validation loss: 3.7993212976763324

Epoch: 5| Step: 5
Training loss: 3.741055965423584
Validation loss: 3.7887984091235745

Epoch: 5| Step: 6
Training loss: 3.283465623855591
Validation loss: 3.7759015637059368

Epoch: 5| Step: 7
Training loss: 2.904482364654541
Validation loss: 3.7663049492784726

Epoch: 5| Step: 8
Training loss: 3.4903335571289062
Validation loss: 3.7566056994981665

Epoch: 5| Step: 9
Training loss: 3.769881010055542
Validation loss: 3.747591805714433

Epoch: 5| Step: 10
Training loss: 3.754667043685913
Validation loss: 3.739496067006101

Epoch: 8| Step: 0
Training loss: 4.518336296081543
Validation loss: 3.726227909006098

Epoch: 5| Step: 1
Training loss: 3.6837990283966064
Validation loss: 3.715754544863137

Epoch: 5| Step: 2
Training loss: 3.165325164794922
Validation loss: 3.709646071157148

Epoch: 5| Step: 3
Training loss: 3.541093111038208
Validation loss: 3.6999978352618474

Epoch: 5| Step: 4
Training loss: 3.873070478439331
Validation loss: 3.6934288188975346

Epoch: 5| Step: 5
Training loss: 3.847184658050537
Validation loss: 3.682920514896352

Epoch: 5| Step: 6
Training loss: 3.518826961517334
Validation loss: 3.6779683482262397

Epoch: 5| Step: 7
Training loss: 3.519078016281128
Validation loss: 3.6715722417318695

Epoch: 5| Step: 8
Training loss: 3.3710925579071045
Validation loss: 3.6626153274249007

Epoch: 5| Step: 9
Training loss: 3.397937774658203
Validation loss: 3.657114421167681

Epoch: 5| Step: 10
Training loss: 3.0103182792663574
Validation loss: 3.6545025661427486

Epoch: 9| Step: 0
Training loss: 3.532667875289917
Validation loss: 3.649485859819638

Epoch: 5| Step: 1
Training loss: 3.45747709274292
Validation loss: 3.6384917894999185

Epoch: 5| Step: 2
Training loss: 3.3432719707489014
Validation loss: 3.631548971258184

Epoch: 5| Step: 3
Training loss: 3.794111967086792
Validation loss: 3.62873016377931

Epoch: 5| Step: 4
Training loss: 4.817439079284668
Validation loss: 3.625326020743257

Epoch: 5| Step: 5
Training loss: 3.4179580211639404
Validation loss: 3.6165086146323913

Epoch: 5| Step: 6
Training loss: 3.3006973266601562
Validation loss: 3.610888458067371

Epoch: 5| Step: 7
Training loss: 3.329867124557495
Validation loss: 3.6077970381705993

Epoch: 5| Step: 8
Training loss: 3.1644046306610107
Validation loss: 3.602657848788846

Epoch: 5| Step: 9
Training loss: 3.099303722381592
Validation loss: 3.6036118794513006

Epoch: 5| Step: 10
Training loss: 3.6564478874206543
Validation loss: 3.595332025199808

Epoch: 10| Step: 0
Training loss: 3.219033718109131
Validation loss: 3.5845423821480042

Epoch: 5| Step: 1
Training loss: 2.6351189613342285
Validation loss: 3.5817027143252793

Epoch: 5| Step: 2
Training loss: 2.9630424976348877
Validation loss: 3.5781525386277067

Epoch: 5| Step: 3
Training loss: 3.9554665088653564
Validation loss: 3.5718694630489556

Epoch: 5| Step: 4
Training loss: 3.7182679176330566
Validation loss: 3.5684081046811995

Epoch: 5| Step: 5
Training loss: 3.079622268676758
Validation loss: 3.5651266959405716

Epoch: 5| Step: 6
Training loss: 2.7308897972106934
Validation loss: 3.566394959726641

Epoch: 5| Step: 7
Training loss: 3.45186185836792
Validation loss: 3.561158590419318

Epoch: 5| Step: 8
Training loss: 4.136192321777344
Validation loss: 3.5552480579704366

Epoch: 5| Step: 9
Training loss: 4.407068729400635
Validation loss: 3.5460521380106607

Epoch: 5| Step: 10
Training loss: 4.178760051727295
Validation loss: 3.5384402531449513

Epoch: 11| Step: 0
Training loss: 3.861049175262451
Validation loss: 3.540047517386816

Epoch: 5| Step: 1
Training loss: 2.781378746032715
Validation loss: 3.5315857959050003

Epoch: 5| Step: 2
Training loss: 4.263922214508057
Validation loss: 3.5249412700694096

Epoch: 5| Step: 3
Training loss: 3.88227915763855
Validation loss: 3.522089901790824

Epoch: 5| Step: 4
Training loss: 3.506636381149292
Validation loss: 3.522110059697141

Epoch: 5| Step: 5
Training loss: 3.4792187213897705
Validation loss: 3.515941814709735

Epoch: 5| Step: 6
Training loss: 3.5369300842285156
Validation loss: 3.510016559272684

Epoch: 5| Step: 7
Training loss: 3.7647228240966797
Validation loss: 3.504940653360018

Epoch: 5| Step: 8
Training loss: 2.7759411334991455
Validation loss: 3.5045481215241137

Epoch: 5| Step: 9
Training loss: 3.0098347663879395
Validation loss: 3.4969206702324653

Epoch: 5| Step: 10
Training loss: 3.022477626800537
Validation loss: 3.4932138484011412

Epoch: 12| Step: 0
Training loss: 2.8623993396759033
Validation loss: 3.492369782540106

Epoch: 5| Step: 1
Training loss: 3.729736328125
Validation loss: 3.488673786963186

Epoch: 5| Step: 2
Training loss: 2.9033875465393066
Validation loss: 3.4867373948456137

Epoch: 5| Step: 3
Training loss: 4.117038726806641
Validation loss: 3.4789516592538483

Epoch: 5| Step: 4
Training loss: 4.594232559204102
Validation loss: 3.4746660955490603

Epoch: 5| Step: 5
Training loss: 2.8012046813964844
Validation loss: 3.471436349294519

Epoch: 5| Step: 6
Training loss: 3.004361152648926
Validation loss: 3.465031305948893

Epoch: 5| Step: 7
Training loss: 3.6809051036834717
Validation loss: 3.460343171191472

Epoch: 5| Step: 8
Training loss: 2.941333293914795
Validation loss: 3.4554396419114966

Epoch: 5| Step: 9
Training loss: 2.9556045532226562
Validation loss: 3.452933539626419

Epoch: 5| Step: 10
Training loss: 4.028562068939209
Validation loss: 3.4477135930010068

Epoch: 13| Step: 0
Training loss: 3.901872158050537
Validation loss: 3.4436597003731677

Epoch: 5| Step: 1
Training loss: 3.8588027954101562
Validation loss: 3.4411481118971303

Epoch: 5| Step: 2
Training loss: 3.514134168624878
Validation loss: 3.4346802260286067

Epoch: 5| Step: 3
Training loss: 4.649999141693115
Validation loss: 3.432286103566488

Epoch: 5| Step: 4
Training loss: 2.9103426933288574
Validation loss: 3.4259410776117796

Epoch: 5| Step: 5
Training loss: 3.4317386150360107
Validation loss: 3.4230422383995465

Epoch: 5| Step: 6
Training loss: 3.2624764442443848
Validation loss: 3.419123459887761

Epoch: 5| Step: 7
Training loss: 2.479309320449829
Validation loss: 3.41151745857731

Epoch: 5| Step: 8
Training loss: 3.1083877086639404
Validation loss: 3.408497877018426

Epoch: 5| Step: 9
Training loss: 2.3896126747131348
Validation loss: 3.4078725461036927

Epoch: 5| Step: 10
Training loss: 3.5936689376831055
Validation loss: 3.399380773626348

Epoch: 14| Step: 0
Training loss: 3.4988327026367188
Validation loss: 3.397284807697419

Epoch: 5| Step: 1
Training loss: 3.839210033416748
Validation loss: 3.393657204925373

Epoch: 5| Step: 2
Training loss: 3.2537753582000732
Validation loss: 3.3885740105823805

Epoch: 5| Step: 3
Training loss: 2.8812918663024902
Validation loss: 3.3834464729473157

Epoch: 5| Step: 4
Training loss: 3.8454997539520264
Validation loss: 3.378420809263824

Epoch: 5| Step: 5
Training loss: 2.1952226161956787
Validation loss: 3.375210626150972

Epoch: 5| Step: 6
Training loss: 2.7172412872314453
Validation loss: 3.3700582724745556

Epoch: 5| Step: 7
Training loss: 3.979924440383911
Validation loss: 3.367783138828893

Epoch: 5| Step: 8
Training loss: 3.2463631629943848
Validation loss: 3.364057428093367

Epoch: 5| Step: 9
Training loss: 3.820117950439453
Validation loss: 3.358958867288405

Epoch: 5| Step: 10
Training loss: 3.3373653888702393
Validation loss: 3.356330274253763

Epoch: 15| Step: 0
Training loss: 4.527738571166992
Validation loss: 3.3513744031229327

Epoch: 5| Step: 1
Training loss: 2.6131210327148438
Validation loss: 3.3471941845391386

Epoch: 5| Step: 2
Training loss: 3.0935235023498535
Validation loss: 3.342174430047312

Epoch: 5| Step: 3
Training loss: 3.1863698959350586
Validation loss: 3.336726834697108

Epoch: 5| Step: 4
Training loss: 3.795198440551758
Validation loss: 3.3359487364369054

Epoch: 5| Step: 5
Training loss: 2.49535870552063
Validation loss: 3.3314409640527542

Epoch: 5| Step: 6
Training loss: 3.135375738143921
Validation loss: 3.329373103316112

Epoch: 5| Step: 7
Training loss: 3.6202125549316406
Validation loss: 3.323556500096475

Epoch: 5| Step: 8
Training loss: 3.4773471355438232
Validation loss: 3.320028171744398

Epoch: 5| Step: 9
Training loss: 2.9061474800109863
Validation loss: 3.315101287698233

Epoch: 5| Step: 10
Training loss: 3.4173433780670166
Validation loss: 3.3129437431212394

Epoch: 16| Step: 0
Training loss: 4.015206336975098
Validation loss: 3.3070570268938617

Epoch: 5| Step: 1
Training loss: 4.090817451477051
Validation loss: 3.304130059416576

Epoch: 5| Step: 2
Training loss: 2.9931187629699707
Validation loss: 3.2977211629190752

Epoch: 5| Step: 3
Training loss: 2.857703685760498
Validation loss: 3.292872413512199

Epoch: 5| Step: 4
Training loss: 2.9326345920562744
Validation loss: 3.2928696396530315

Epoch: 5| Step: 5
Training loss: 2.8977131843566895
Validation loss: 3.2913469524793726

Epoch: 5| Step: 6
Training loss: 3.0894789695739746
Validation loss: 3.2838006096501506

Epoch: 5| Step: 7
Training loss: 2.427661657333374
Validation loss: 3.2824937630725164

Epoch: 5| Step: 8
Training loss: 3.347090244293213
Validation loss: 3.2794078370576263

Epoch: 5| Step: 9
Training loss: 3.440930128097534
Validation loss: 3.276706305883264

Epoch: 5| Step: 10
Training loss: 3.8556671142578125
Validation loss: 3.273157304333102

Epoch: 17| Step: 0
Training loss: 2.9170432090759277
Validation loss: 3.2658362978248188

Epoch: 5| Step: 1
Training loss: 2.332991361618042
Validation loss: 3.262135016020908

Epoch: 5| Step: 2
Training loss: 3.7293903827667236
Validation loss: 3.2701310957631757

Epoch: 5| Step: 3
Training loss: 2.8877453804016113
Validation loss: 3.2572704438240296

Epoch: 5| Step: 4
Training loss: 4.084442615509033
Validation loss: 3.2785729105754564

Epoch: 5| Step: 5
Training loss: 2.800060749053955
Validation loss: 3.296658703075942

Epoch: 5| Step: 6
Training loss: 3.7259058952331543
Validation loss: 3.333773733467184

Epoch: 5| Step: 7
Training loss: 2.985114574432373
Validation loss: 3.287411028339017

Epoch: 5| Step: 8
Training loss: 3.1325175762176514
Validation loss: 3.2585296220676874

Epoch: 5| Step: 9
Training loss: 4.003859519958496
Validation loss: 3.2501630013988865

Epoch: 5| Step: 10
Training loss: 3.1914196014404297
Validation loss: 3.2503358189777662

Epoch: 18| Step: 0
Training loss: 2.950624942779541
Validation loss: 3.2522611182223082

Epoch: 5| Step: 1
Training loss: 3.509899139404297
Validation loss: 3.268648632111088

Epoch: 5| Step: 2
Training loss: 3.8632640838623047
Validation loss: 3.2521237352842927

Epoch: 5| Step: 3
Training loss: 2.3530170917510986
Validation loss: 3.23967993643976

Epoch: 5| Step: 4
Training loss: 3.533851146697998
Validation loss: 3.2390765272161013

Epoch: 5| Step: 5
Training loss: 2.3057751655578613
Validation loss: 3.239752915597731

Epoch: 5| Step: 6
Training loss: 3.270498275756836
Validation loss: 3.240861395353912

Epoch: 5| Step: 7
Training loss: 2.1361258029937744
Validation loss: 3.240902408476799

Epoch: 5| Step: 8
Training loss: 3.9357521533966064
Validation loss: 3.2442162523987474

Epoch: 5| Step: 9
Training loss: 4.18189811706543
Validation loss: 3.2378086377215642

Epoch: 5| Step: 10
Training loss: 3.558407783508301
Validation loss: 3.2312142438786005

Epoch: 19| Step: 0
Training loss: 2.5452332496643066
Validation loss: 3.220145953598843

Epoch: 5| Step: 1
Training loss: 4.110317230224609
Validation loss: 3.2080852293199107

Epoch: 5| Step: 2
Training loss: 2.8867812156677246
Validation loss: 3.203113455926218

Epoch: 5| Step: 3
Training loss: 3.8274478912353516
Validation loss: 3.198855100139495

Epoch: 5| Step: 4
Training loss: 2.7543742656707764
Validation loss: 3.198081031922371

Epoch: 5| Step: 5
Training loss: 4.21784782409668
Validation loss: 3.200106208042432

Epoch: 5| Step: 6
Training loss: 3.042947292327881
Validation loss: 3.1949298715078704

Epoch: 5| Step: 7
Training loss: 1.9649951457977295
Validation loss: 3.193813390629266

Epoch: 5| Step: 8
Training loss: 3.3088607788085938
Validation loss: 3.1948150024619153

Epoch: 5| Step: 9
Training loss: 3.3753902912139893
Validation loss: 3.1835740612399195

Epoch: 5| Step: 10
Training loss: 3.1218245029449463
Validation loss: 3.1756182511647544

Epoch: 20| Step: 0
Training loss: 3.214956283569336
Validation loss: 3.173217027418075

Epoch: 5| Step: 1
Training loss: 3.0134518146514893
Validation loss: 3.170020713601061

Epoch: 5| Step: 2
Training loss: 3.1934468746185303
Validation loss: 3.169008057604554

Epoch: 5| Step: 3
Training loss: 3.195293426513672
Validation loss: 3.1656600659893406

Epoch: 5| Step: 4
Training loss: 2.9415860176086426
Validation loss: 3.1719042870306198

Epoch: 5| Step: 5
Training loss: 2.421889305114746
Validation loss: 3.1708836581117366

Epoch: 5| Step: 6
Training loss: 3.429063320159912
Validation loss: 3.1670618236705823

Epoch: 5| Step: 7
Training loss: 3.076517105102539
Validation loss: 3.1611573747409287

Epoch: 5| Step: 8
Training loss: 3.244053363800049
Validation loss: 3.1568529195682977

Epoch: 5| Step: 9
Training loss: 3.6659152507781982
Validation loss: 3.1526945201299523

Epoch: 5| Step: 10
Training loss: 3.535332679748535
Validation loss: 3.150618814652966

Epoch: 21| Step: 0
Training loss: 3.986835479736328
Validation loss: 3.1468646628882295

Epoch: 5| Step: 1
Training loss: 3.1093249320983887
Validation loss: 3.145389772230579

Epoch: 5| Step: 2
Training loss: 3.434474468231201
Validation loss: 3.142448022801389

Epoch: 5| Step: 3
Training loss: 3.3878512382507324
Validation loss: 3.1404585735772246

Epoch: 5| Step: 4
Training loss: 2.8965725898742676
Validation loss: 3.1368648441888953

Epoch: 5| Step: 5
Training loss: 3.3441319465637207
Validation loss: 3.13348993691065

Epoch: 5| Step: 6
Training loss: 3.093642473220825
Validation loss: 3.131489133322111

Epoch: 5| Step: 7
Training loss: 2.3718414306640625
Validation loss: 3.1268102943256335

Epoch: 5| Step: 8
Training loss: 3.534219264984131
Validation loss: 3.1270081561098815

Epoch: 5| Step: 9
Training loss: 2.7406749725341797
Validation loss: 3.126209787143174

Epoch: 5| Step: 10
Training loss: 2.7125680446624756
Validation loss: 3.1235747644978185

Epoch: 22| Step: 0
Training loss: 2.8942039012908936
Validation loss: 3.122655232747396

Epoch: 5| Step: 1
Training loss: 2.011143207550049
Validation loss: 3.117205363447948

Epoch: 5| Step: 2
Training loss: 3.9198880195617676
Validation loss: 3.113686289838565

Epoch: 5| Step: 3
Training loss: 3.014334201812744
Validation loss: 3.110352039337158

Epoch: 5| Step: 4
Training loss: 4.040489196777344
Validation loss: 3.1090425317005446

Epoch: 5| Step: 5
Training loss: 2.973186492919922
Validation loss: 3.107981297277635

Epoch: 5| Step: 6
Training loss: 3.376063823699951
Validation loss: 3.103697804994481

Epoch: 5| Step: 7
Training loss: 3.169875383377075
Validation loss: 3.1017529220991236

Epoch: 5| Step: 8
Training loss: 2.65429949760437
Validation loss: 3.102229533656951

Epoch: 5| Step: 9
Training loss: 3.358943223953247
Validation loss: 3.098940344266994

Epoch: 5| Step: 10
Training loss: 3.0427446365356445
Validation loss: 3.097415324180357

Epoch: 23| Step: 0
Training loss: 3.619215488433838
Validation loss: 3.0955898069566294

Epoch: 5| Step: 1
Training loss: 3.7799065113067627
Validation loss: 3.0925331038813435

Epoch: 5| Step: 2
Training loss: 2.957571506500244
Validation loss: 3.088966026101061

Epoch: 5| Step: 3
Training loss: 2.9487788677215576
Validation loss: 3.0894271301966842

Epoch: 5| Step: 4
Training loss: 2.833134412765503
Validation loss: 3.0878346248339583

Epoch: 5| Step: 5
Training loss: 2.749575138092041
Validation loss: 3.084431735418176

Epoch: 5| Step: 6
Training loss: 3.9649219512939453
Validation loss: 3.0828902823950655

Epoch: 5| Step: 7
Training loss: 3.520742416381836
Validation loss: 3.082173314145816

Epoch: 5| Step: 8
Training loss: 3.0295469760894775
Validation loss: 3.0792064666748047

Epoch: 5| Step: 9
Training loss: 2.2544338703155518
Validation loss: 3.0769567745988087

Epoch: 5| Step: 10
Training loss: 2.5690479278564453
Validation loss: 3.078496435637115

Epoch: 24| Step: 0
Training loss: 1.971655249595642
Validation loss: 3.08995678347926

Epoch: 5| Step: 1
Training loss: 2.3085410594940186
Validation loss: 3.13601488964532

Epoch: 5| Step: 2
Training loss: 2.8257946968078613
Validation loss: 3.0977616002482753

Epoch: 5| Step: 3
Training loss: 3.0658462047576904
Validation loss: 3.0778114949503252

Epoch: 5| Step: 4
Training loss: 3.4948830604553223
Validation loss: 3.070962252155427

Epoch: 5| Step: 5
Training loss: 4.350760459899902
Validation loss: 3.0702490550215527

Epoch: 5| Step: 6
Training loss: 2.800699234008789
Validation loss: 3.0680881725844515

Epoch: 5| Step: 7
Training loss: 3.544961452484131
Validation loss: 3.066126387606385

Epoch: 5| Step: 8
Training loss: 3.7843995094299316
Validation loss: 3.065253396188059

Epoch: 5| Step: 9
Training loss: 3.0851571559906006
Validation loss: 3.0621809779956775

Epoch: 5| Step: 10
Training loss: 2.99637770652771
Validation loss: 3.060472378166773

Epoch: 25| Step: 0
Training loss: 3.567668914794922
Validation loss: 3.060240601980558

Epoch: 5| Step: 1
Training loss: 3.0727176666259766
Validation loss: 3.0577513299962527

Epoch: 5| Step: 2
Training loss: 2.97301983833313
Validation loss: 3.05597537050965

Epoch: 5| Step: 3
Training loss: 3.336409091949463
Validation loss: 3.0556462631430676

Epoch: 5| Step: 4
Training loss: 3.2030367851257324
Validation loss: 3.0551272207690823

Epoch: 5| Step: 5
Training loss: 3.3747363090515137
Validation loss: 3.0546288105749313

Epoch: 5| Step: 6
Training loss: 3.2665607929229736
Validation loss: 3.0530660639527025

Epoch: 5| Step: 7
Training loss: 2.167203426361084
Validation loss: 3.0502023671263006

Epoch: 5| Step: 8
Training loss: 2.8263261318206787
Validation loss: 3.048560860336468

Epoch: 5| Step: 9
Training loss: 2.8172478675842285
Validation loss: 3.046265181674752

Epoch: 5| Step: 10
Training loss: 3.5392961502075195
Validation loss: 3.047595675273608

Epoch: 26| Step: 0
Training loss: 2.8348395824432373
Validation loss: 3.044787965795045

Epoch: 5| Step: 1
Training loss: 2.699918031692505
Validation loss: 3.0448285789899927

Epoch: 5| Step: 2
Training loss: 3.08085298538208
Validation loss: 3.042232741591751

Epoch: 5| Step: 3
Training loss: 3.3986153602600098
Validation loss: 3.040538690423453

Epoch: 5| Step: 4
Training loss: 2.828057050704956
Validation loss: 3.0394655478897916

Epoch: 5| Step: 5
Training loss: 4.339968681335449
Validation loss: 3.0371883710225425

Epoch: 5| Step: 6
Training loss: 2.8516428470611572
Validation loss: 3.035543618663665

Epoch: 5| Step: 7
Training loss: 2.857192277908325
Validation loss: 3.034466746032879

Epoch: 5| Step: 8
Training loss: 2.824608325958252
Validation loss: 3.034899303990026

Epoch: 5| Step: 9
Training loss: 2.8675687313079834
Validation loss: 3.0320522490368096

Epoch: 5| Step: 10
Training loss: 3.4479479789733887
Validation loss: 3.032146792257986

Epoch: 27| Step: 0
Training loss: 3.375113010406494
Validation loss: 3.0334843512504333

Epoch: 5| Step: 1
Training loss: 2.916062355041504
Validation loss: 3.030802875436762

Epoch: 5| Step: 2
Training loss: 3.6897614002227783
Validation loss: 3.028997044409475

Epoch: 5| Step: 3
Training loss: 2.5329203605651855
Validation loss: 3.0272419427030828

Epoch: 5| Step: 4
Training loss: 2.88403058052063
Validation loss: 3.0243755771267797

Epoch: 5| Step: 5
Training loss: 3.5137276649475098
Validation loss: 3.0244863417840775

Epoch: 5| Step: 6
Training loss: 3.146061420440674
Validation loss: 3.0241539298847155

Epoch: 5| Step: 7
Training loss: 3.134904623031616
Validation loss: 3.021920286199098

Epoch: 5| Step: 8
Training loss: 3.298577070236206
Validation loss: 3.022172894529117

Epoch: 5| Step: 9
Training loss: 2.457183837890625
Validation loss: 3.0213452513499925

Epoch: 5| Step: 10
Training loss: 2.936164140701294
Validation loss: 3.023784322123374

Epoch: 28| Step: 0
Training loss: 2.751593589782715
Validation loss: 3.0184507293085896

Epoch: 5| Step: 1
Training loss: 2.4473533630371094
Validation loss: 3.0165311392917427

Epoch: 5| Step: 2
Training loss: 2.8907368183135986
Validation loss: 3.0149062807841966

Epoch: 5| Step: 3
Training loss: 3.052276372909546
Validation loss: 3.016777259047313

Epoch: 5| Step: 4
Training loss: 2.471320867538452
Validation loss: 3.0152989664385395

Epoch: 5| Step: 5
Training loss: 3.318749189376831
Validation loss: 3.015415788978659

Epoch: 5| Step: 6
Training loss: 3.3438477516174316
Validation loss: 3.011623744041689

Epoch: 5| Step: 7
Training loss: 3.8972079753875732
Validation loss: 3.0098958630715646

Epoch: 5| Step: 8
Training loss: 2.61903977394104
Validation loss: 3.0074645216746996

Epoch: 5| Step: 9
Training loss: 3.814160108566284
Validation loss: 3.007016953601632

Epoch: 5| Step: 10
Training loss: 3.227064847946167
Validation loss: 3.0057444969813027

Epoch: 29| Step: 0
Training loss: 2.4531614780426025
Validation loss: 3.005469301695465

Epoch: 5| Step: 1
Training loss: 3.1060357093811035
Validation loss: 3.0036797549134944

Epoch: 5| Step: 2
Training loss: 3.574284076690674
Validation loss: 3.00294356448676

Epoch: 5| Step: 3
Training loss: 2.6387717723846436
Validation loss: 3.000720142036356

Epoch: 5| Step: 4
Training loss: 3.181746006011963
Validation loss: 3.000200758698166

Epoch: 5| Step: 5
Training loss: 2.9039299488067627
Validation loss: 2.99881435209705

Epoch: 5| Step: 6
Training loss: 3.9449989795684814
Validation loss: 2.9957357145124868

Epoch: 5| Step: 7
Training loss: 2.6111667156219482
Validation loss: 2.9953838958535144

Epoch: 5| Step: 8
Training loss: 2.8378849029541016
Validation loss: 3.0013625673068467

Epoch: 5| Step: 9
Training loss: 2.743210554122925
Validation loss: 2.9937293273146435

Epoch: 5| Step: 10
Training loss: 3.812720775604248
Validation loss: 2.9979767491740565

Epoch: 30| Step: 0
Training loss: 3.0878853797912598
Validation loss: 2.99675775343372

Epoch: 5| Step: 1
Training loss: 3.713313341140747
Validation loss: 3.0056470030097553

Epoch: 5| Step: 2
Training loss: 2.8717939853668213
Validation loss: 2.9985228584658716

Epoch: 5| Step: 3
Training loss: 2.8546035289764404
Validation loss: 2.9948991370457474

Epoch: 5| Step: 4
Training loss: 2.19142484664917
Validation loss: 2.9856445481700282

Epoch: 5| Step: 5
Training loss: 2.4456746578216553
Validation loss: 2.9868956355638403

Epoch: 5| Step: 6
Training loss: 3.399165630340576
Validation loss: 2.988670549085063

Epoch: 5| Step: 7
Training loss: 3.0167250633239746
Validation loss: 3.002916725732947

Epoch: 5| Step: 8
Training loss: 3.3000564575195312
Validation loss: 2.994096012525661

Epoch: 5| Step: 9
Training loss: 3.8535919189453125
Validation loss: 2.985711020808066

Epoch: 5| Step: 10
Training loss: 2.8751978874206543
Validation loss: 2.982129543058334

Epoch: 31| Step: 0
Training loss: 3.6312155723571777
Validation loss: 2.98112908230033

Epoch: 5| Step: 1
Training loss: 2.935394763946533
Validation loss: 2.979827670640843

Epoch: 5| Step: 2
Training loss: 2.6588876247406006
Validation loss: 2.9786824077688236

Epoch: 5| Step: 3
Training loss: 2.807133436203003
Validation loss: 2.976111488957559

Epoch: 5| Step: 4
Training loss: 3.392045497894287
Validation loss: 2.9770809578639206

Epoch: 5| Step: 5
Training loss: 3.8264365196228027
Validation loss: 2.9746924215747463

Epoch: 5| Step: 6
Training loss: 2.644810438156128
Validation loss: 2.974734357608262

Epoch: 5| Step: 7
Training loss: 3.0971760749816895
Validation loss: 2.975893482085197

Epoch: 5| Step: 8
Training loss: 3.2744216918945312
Validation loss: 2.9745516007946384

Epoch: 5| Step: 9
Training loss: 2.0214076042175293
Validation loss: 2.9712768062468498

Epoch: 5| Step: 10
Training loss: 3.2843821048736572
Validation loss: 2.971365523594682

Epoch: 32| Step: 0
Training loss: 2.8981499671936035
Validation loss: 2.9718737166414977

Epoch: 5| Step: 1
Training loss: 2.694483995437622
Validation loss: 2.969552581028272

Epoch: 5| Step: 2
Training loss: 3.1156601905822754
Validation loss: 2.969739449921475

Epoch: 5| Step: 3
Training loss: 3.3831419944763184
Validation loss: 2.9676471217986076

Epoch: 5| Step: 4
Training loss: 2.9308784008026123
Validation loss: 2.967579815977363

Epoch: 5| Step: 5
Training loss: 3.197890520095825
Validation loss: 2.966861201870826

Epoch: 5| Step: 6
Training loss: 3.100579023361206
Validation loss: 2.967849249480873

Epoch: 5| Step: 7
Training loss: 3.065685749053955
Validation loss: 2.963128618014756

Epoch: 5| Step: 8
Training loss: 2.4215431213378906
Validation loss: 2.961595509641914

Epoch: 5| Step: 9
Training loss: 3.159482479095459
Validation loss: 2.9613997474793465

Epoch: 5| Step: 10
Training loss: 3.558110237121582
Validation loss: 2.960816849944412

Epoch: 33| Step: 0
Training loss: 1.9783138036727905
Validation loss: 2.9621688473609185

Epoch: 5| Step: 1
Training loss: 2.8136839866638184
Validation loss: 2.9651583907424763

Epoch: 5| Step: 2
Training loss: 3.483888626098633
Validation loss: 2.9678679486756683

Epoch: 5| Step: 3
Training loss: 2.958707809448242
Validation loss: 2.9643583964276057

Epoch: 5| Step: 4
Training loss: 2.6778883934020996
Validation loss: 2.9605668847278883

Epoch: 5| Step: 5
Training loss: 2.9790713787078857
Validation loss: 2.9570035370447303

Epoch: 5| Step: 6
Training loss: 4.4885101318359375
Validation loss: 2.9540135578442643

Epoch: 5| Step: 7
Training loss: 3.036069393157959
Validation loss: 2.955073615556122

Epoch: 5| Step: 8
Training loss: 2.4909114837646484
Validation loss: 2.954771384116142

Epoch: 5| Step: 9
Training loss: 2.982820510864258
Validation loss: 2.9505847807853454

Epoch: 5| Step: 10
Training loss: 3.6078970432281494
Validation loss: 2.9517245779755297

Epoch: 34| Step: 0
Training loss: 2.5137887001037598
Validation loss: 2.951092594413347

Epoch: 5| Step: 1
Training loss: 3.084947109222412
Validation loss: 2.9498097486393426

Epoch: 5| Step: 2
Training loss: 3.096457004547119
Validation loss: 2.9498698301212762

Epoch: 5| Step: 3
Training loss: 3.716874599456787
Validation loss: 2.9466397685389363

Epoch: 5| Step: 4
Training loss: 3.1609294414520264
Validation loss: 2.94810410212445

Epoch: 5| Step: 5
Training loss: 2.3596997261047363
Validation loss: 2.947503125795754

Epoch: 5| Step: 6
Training loss: 2.5256190299987793
Validation loss: 2.947433110206358

Epoch: 5| Step: 7
Training loss: 2.564160108566284
Validation loss: 2.946496355918146

Epoch: 5| Step: 8
Training loss: 3.7536025047302246
Validation loss: 2.9441456256374234

Epoch: 5| Step: 9
Training loss: 3.967103958129883
Validation loss: 2.9426287220370386

Epoch: 5| Step: 10
Training loss: 2.5083210468292236
Validation loss: 2.940374953772432

Epoch: 35| Step: 0
Training loss: 3.5662472248077393
Validation loss: 2.9389740344016784

Epoch: 5| Step: 1
Training loss: 2.3627548217773438
Validation loss: 2.9370106112572456

Epoch: 5| Step: 2
Training loss: 2.7102890014648438
Validation loss: 2.935814836973785

Epoch: 5| Step: 3
Training loss: 2.786196231842041
Validation loss: 2.9325435341045423

Epoch: 5| Step: 4
Training loss: 3.3959853649139404
Validation loss: 2.928473377740511

Epoch: 5| Step: 5
Training loss: 2.671316146850586
Validation loss: 2.9281870780452603

Epoch: 5| Step: 6
Training loss: 2.901167631149292
Validation loss: 2.9226130285570697

Epoch: 5| Step: 7
Training loss: 3.310802459716797
Validation loss: 2.9211605389912925

Epoch: 5| Step: 8
Training loss: 3.745068073272705
Validation loss: 2.9178770255017024

Epoch: 5| Step: 9
Training loss: 2.6014583110809326
Validation loss: 2.9156649497247513

Epoch: 5| Step: 10
Training loss: 3.161435604095459
Validation loss: 2.915484530951387

Epoch: 36| Step: 0
Training loss: 2.9123177528381348
Validation loss: 2.9124143226172334

Epoch: 5| Step: 1
Training loss: 2.770669937133789
Validation loss: 2.911754164644467

Epoch: 5| Step: 2
Training loss: 3.1586785316467285
Validation loss: 2.9103006906406854

Epoch: 5| Step: 3
Training loss: 3.993535280227661
Validation loss: 2.9098501436171995

Epoch: 5| Step: 4
Training loss: 2.357764720916748
Validation loss: 2.908986358232396

Epoch: 5| Step: 5
Training loss: 3.340235471725464
Validation loss: 2.907639911097865

Epoch: 5| Step: 6
Training loss: 3.1346518993377686
Validation loss: 2.906744873651894

Epoch: 5| Step: 7
Training loss: 2.6439692974090576
Validation loss: 2.904835062642251

Epoch: 5| Step: 8
Training loss: 2.796151876449585
Validation loss: 2.90461492025724

Epoch: 5| Step: 9
Training loss: 3.5796380043029785
Validation loss: 2.903996165080737

Epoch: 5| Step: 10
Training loss: 2.228370189666748
Validation loss: 2.9031048564500708

Epoch: 37| Step: 0
Training loss: 2.992926597595215
Validation loss: 2.904296544290358

Epoch: 5| Step: 1
Training loss: 3.250298023223877
Validation loss: 2.901280459537301

Epoch: 5| Step: 2
Training loss: 2.362682342529297
Validation loss: 2.8999262343170824

Epoch: 5| Step: 3
Training loss: 2.7221803665161133
Validation loss: 2.9011202422521447

Epoch: 5| Step: 4
Training loss: 3.2847251892089844
Validation loss: 2.899157219035651

Epoch: 5| Step: 5
Training loss: 2.987342357635498
Validation loss: 2.901236818682763

Epoch: 5| Step: 6
Training loss: 2.6233773231506348
Validation loss: 2.900566183110719

Epoch: 5| Step: 7
Training loss: 1.4580671787261963
Validation loss: 2.899773795117614

Epoch: 5| Step: 8
Training loss: 3.8966736793518066
Validation loss: 2.89829183137545

Epoch: 5| Step: 9
Training loss: 3.505344867706299
Validation loss: 2.896591688997002

Epoch: 5| Step: 10
Training loss: 4.030521392822266
Validation loss: 2.896885043831282

Epoch: 38| Step: 0
Training loss: 3.7631187438964844
Validation loss: 2.894800857831073

Epoch: 5| Step: 1
Training loss: 3.073834180831909
Validation loss: 2.894715234797488

Epoch: 5| Step: 2
Training loss: 3.481480121612549
Validation loss: 2.893475919641474

Epoch: 5| Step: 3
Training loss: 2.50453519821167
Validation loss: 2.8917011983932985

Epoch: 5| Step: 4
Training loss: 3.5632576942443848
Validation loss: 2.8921909178456953

Epoch: 5| Step: 5
Training loss: 3.3494873046875
Validation loss: 2.8901764090343187

Epoch: 5| Step: 6
Training loss: 2.448385715484619
Validation loss: 2.8900991229600805

Epoch: 5| Step: 7
Training loss: 2.552203416824341
Validation loss: 2.8899200885526595

Epoch: 5| Step: 8
Training loss: 2.806380033493042
Validation loss: 2.886854789590323

Epoch: 5| Step: 9
Training loss: 2.774061679840088
Validation loss: 2.8873927439412763

Epoch: 5| Step: 10
Training loss: 2.52508807182312
Validation loss: 2.887214001788888

Epoch: 39| Step: 0
Training loss: 2.9853169918060303
Validation loss: 2.8863370418548584

Epoch: 5| Step: 1
Training loss: 2.6209685802459717
Validation loss: 2.8852157438955

Epoch: 5| Step: 2
Training loss: 2.796604633331299
Validation loss: 2.886131153311781

Epoch: 5| Step: 3
Training loss: 2.90224552154541
Validation loss: 2.886188942898986

Epoch: 5| Step: 4
Training loss: 2.309082508087158
Validation loss: 2.887127081553141

Epoch: 5| Step: 5
Training loss: 2.8039097785949707
Validation loss: 2.886407652208882

Epoch: 5| Step: 6
Training loss: 3.3325729370117188
Validation loss: 2.886626312809606

Epoch: 5| Step: 7
Training loss: 2.9537177085876465
Validation loss: 2.886379329107141

Epoch: 5| Step: 8
Training loss: 4.019837379455566
Validation loss: 2.8827188271348194

Epoch: 5| Step: 9
Training loss: 3.7090694904327393
Validation loss: 2.880636079337007

Epoch: 5| Step: 10
Training loss: 2.320152759552002
Validation loss: 2.881617625554403

Epoch: 40| Step: 0
Training loss: 3.523634672164917
Validation loss: 2.8782988902061217

Epoch: 5| Step: 1
Training loss: 2.597525119781494
Validation loss: 2.8783331814632622

Epoch: 5| Step: 2
Training loss: 2.449711561203003
Validation loss: 2.8779812730768675

Epoch: 5| Step: 3
Training loss: 2.3877692222595215
Validation loss: 2.8753929907275784

Epoch: 5| Step: 4
Training loss: 3.606459140777588
Validation loss: 2.879146768200782

Epoch: 5| Step: 5
Training loss: 2.964303493499756
Validation loss: 2.892526508659445

Epoch: 5| Step: 6
Training loss: 3.961111545562744
Validation loss: 2.8848073918332338

Epoch: 5| Step: 7
Training loss: 2.5349225997924805
Validation loss: 2.873342296128632

Epoch: 5| Step: 8
Training loss: 3.1137969493865967
Validation loss: 2.8707625353208153

Epoch: 5| Step: 9
Training loss: 2.4406542778015137
Validation loss: 2.8718177426245903

Epoch: 5| Step: 10
Training loss: 3.2469677925109863
Validation loss: 2.8728784745739353

Epoch: 41| Step: 0
Training loss: 2.4183831214904785
Validation loss: 2.8726375615724953

Epoch: 5| Step: 1
Training loss: 2.309696674346924
Validation loss: 2.872926809454477

Epoch: 5| Step: 2
Training loss: 3.6069881916046143
Validation loss: 2.8720488497005996

Epoch: 5| Step: 3
Training loss: 3.277501344680786
Validation loss: 2.8720050883549515

Epoch: 5| Step: 4
Training loss: 1.985619306564331
Validation loss: 2.870060610514815

Epoch: 5| Step: 5
Training loss: 3.244755506515503
Validation loss: 2.8694892467991

Epoch: 5| Step: 6
Training loss: 3.678358554840088
Validation loss: 2.868314499496132

Epoch: 5| Step: 7
Training loss: 3.3370890617370605
Validation loss: 2.8677122516016804

Epoch: 5| Step: 8
Training loss: 2.994844913482666
Validation loss: 2.8662077893492994

Epoch: 5| Step: 9
Training loss: 2.8798513412475586
Validation loss: 2.863337396293558

Epoch: 5| Step: 10
Training loss: 2.964174270629883
Validation loss: 2.8631363453403598

Epoch: 42| Step: 0
Training loss: 2.9679152965545654
Validation loss: 2.8608097312270955

Epoch: 5| Step: 1
Training loss: 2.866755962371826
Validation loss: 2.86048291062796

Epoch: 5| Step: 2
Training loss: 3.825340986251831
Validation loss: 2.861485199261737

Epoch: 5| Step: 3
Training loss: 3.380281448364258
Validation loss: 2.8596383576752036

Epoch: 5| Step: 4
Training loss: 2.216783046722412
Validation loss: 2.858555145161126

Epoch: 5| Step: 5
Training loss: 3.5017762184143066
Validation loss: 2.8615705172220864

Epoch: 5| Step: 6
Training loss: 2.791987657546997
Validation loss: 2.863555016056184

Epoch: 5| Step: 7
Training loss: 2.519016742706299
Validation loss: 2.8654399482152795

Epoch: 5| Step: 8
Training loss: 2.848139524459839
Validation loss: 2.857733413737307

Epoch: 5| Step: 9
Training loss: 2.9485530853271484
Validation loss: 2.8560578207815848

Epoch: 5| Step: 10
Training loss: 2.733919143676758
Validation loss: 2.857099074189381

Epoch: 43| Step: 0
Training loss: 3.190760850906372
Validation loss: 2.858883132216751

Epoch: 5| Step: 1
Training loss: 2.8503494262695312
Validation loss: 2.8585626181735786

Epoch: 5| Step: 2
Training loss: 3.0555527210235596
Validation loss: 2.859460605088101

Epoch: 5| Step: 3
Training loss: 3.247575044631958
Validation loss: 2.8605270257560154

Epoch: 5| Step: 4
Training loss: 3.0078952312469482
Validation loss: 2.858143985912364

Epoch: 5| Step: 5
Training loss: 2.9403483867645264
Validation loss: 2.85668606399208

Epoch: 5| Step: 6
Training loss: 3.1197733879089355
Validation loss: 2.8561221912343013

Epoch: 5| Step: 7
Training loss: 2.375152826309204
Validation loss: 2.8524584488202165

Epoch: 5| Step: 8
Training loss: 3.1937594413757324
Validation loss: 2.852234968575098

Epoch: 5| Step: 9
Training loss: 2.647956132888794
Validation loss: 2.8494187683187504

Epoch: 5| Step: 10
Training loss: 2.9860589504241943
Validation loss: 2.8448935221600276

Epoch: 44| Step: 0
Training loss: 3.0740456581115723
Validation loss: 2.8431834200377106

Epoch: 5| Step: 1
Training loss: 2.613295793533325
Validation loss: 2.842021629374514

Epoch: 5| Step: 2
Training loss: 3.1689274311065674
Validation loss: 2.8439845577363045

Epoch: 5| Step: 3
Training loss: 3.275103807449341
Validation loss: 2.8488990055617465

Epoch: 5| Step: 4
Training loss: 3.528942108154297
Validation loss: 2.8890804706081266

Epoch: 5| Step: 5
Training loss: 2.9332451820373535
Validation loss: 2.8430422172751477

Epoch: 5| Step: 6
Training loss: 2.324845790863037
Validation loss: 2.839729088608937

Epoch: 5| Step: 7
Training loss: 2.840104579925537
Validation loss: 2.844062566757202

Epoch: 5| Step: 8
Training loss: 2.792383909225464
Validation loss: 2.851369765497023

Epoch: 5| Step: 9
Training loss: 3.206061840057373
Validation loss: 2.852041054797429

Epoch: 5| Step: 10
Training loss: 2.7942028045654297
Validation loss: 2.8602427385186635

Epoch: 45| Step: 0
Training loss: 3.024160861968994
Validation loss: 2.866053404346589

Epoch: 5| Step: 1
Training loss: 2.9944164752960205
Validation loss: 2.8590826014036774

Epoch: 5| Step: 2
Training loss: 3.6129326820373535
Validation loss: 2.8485938297804965

Epoch: 5| Step: 3
Training loss: 2.8404719829559326
Validation loss: 2.8415240139089604

Epoch: 5| Step: 4
Training loss: 2.798328399658203
Validation loss: 2.8447111345106557

Epoch: 5| Step: 5
Training loss: 2.581552028656006
Validation loss: 2.8516134959395214

Epoch: 5| Step: 6
Training loss: 3.659165859222412
Validation loss: 2.864299492169452

Epoch: 5| Step: 7
Training loss: 2.6788394451141357
Validation loss: 2.8554021286708053

Epoch: 5| Step: 8
Training loss: 2.7085120677948
Validation loss: 2.8445966243743896

Epoch: 5| Step: 9
Training loss: 2.7670586109161377
Validation loss: 2.8343691979685137

Epoch: 5| Step: 10
Training loss: 2.935492753982544
Validation loss: 2.8329408091883503

Epoch: 46| Step: 0
Training loss: 2.6014857292175293
Validation loss: 2.8309785114821566

Epoch: 5| Step: 1
Training loss: 2.723224639892578
Validation loss: 2.829523212166243

Epoch: 5| Step: 2
Training loss: 3.461508274078369
Validation loss: 2.828777579851048

Epoch: 5| Step: 3
Training loss: 2.576364517211914
Validation loss: 2.829444049507059

Epoch: 5| Step: 4
Training loss: 3.029402732849121
Validation loss: 2.8289049363905385

Epoch: 5| Step: 5
Training loss: 2.895296573638916
Validation loss: 2.832488480434623

Epoch: 5| Step: 6
Training loss: 3.469130039215088
Validation loss: 2.834985702268539

Epoch: 5| Step: 7
Training loss: 3.0639357566833496
Validation loss: 2.8323812151467926

Epoch: 5| Step: 8
Training loss: 3.241645336151123
Validation loss: 2.8272991641875236

Epoch: 5| Step: 9
Training loss: 2.448859214782715
Validation loss: 2.8269621274804555

Epoch: 5| Step: 10
Training loss: 2.8954176902770996
Validation loss: 2.835109859384516

Epoch: 47| Step: 0
Training loss: 2.9853312969207764
Validation loss: 2.846654076730051

Epoch: 5| Step: 1
Training loss: 2.940366506576538
Validation loss: 2.833100365054223

Epoch: 5| Step: 2
Training loss: 3.203533887863159
Validation loss: 2.8455016074642057

Epoch: 5| Step: 3
Training loss: 3.194636821746826
Validation loss: 2.8539996429156234

Epoch: 5| Step: 4
Training loss: 3.1676831245422363
Validation loss: 2.8320184599968696

Epoch: 5| Step: 5
Training loss: 2.642037868499756
Validation loss: 2.835877808191443

Epoch: 5| Step: 6
Training loss: 3.0376925468444824
Validation loss: 2.8358236384648148

Epoch: 5| Step: 7
Training loss: 2.699650287628174
Validation loss: 2.8360759878671296

Epoch: 5| Step: 8
Training loss: 2.385232925415039
Validation loss: 2.8328280474549983

Epoch: 5| Step: 9
Training loss: 2.9312384128570557
Validation loss: 2.82593810173773

Epoch: 5| Step: 10
Training loss: 3.2437734603881836
Validation loss: 2.8236041274122012

Epoch: 48| Step: 0
Training loss: 3.279987335205078
Validation loss: 2.819007419770764

Epoch: 5| Step: 1
Training loss: 2.50288462638855
Validation loss: 2.817747582671463

Epoch: 5| Step: 2
Training loss: 2.47267484664917
Validation loss: 2.8199982104762906

Epoch: 5| Step: 3
Training loss: 2.2987587451934814
Validation loss: 2.8195796551242953

Epoch: 5| Step: 4
Training loss: 3.2418856620788574
Validation loss: 2.8197237240370883

Epoch: 5| Step: 5
Training loss: 3.225365400314331
Validation loss: 2.821640496612877

Epoch: 5| Step: 6
Training loss: 3.086930751800537
Validation loss: 2.8198315969077488

Epoch: 5| Step: 7
Training loss: 3.8264946937561035
Validation loss: 2.8210695353887414

Epoch: 5| Step: 8
Training loss: 2.8627586364746094
Validation loss: 2.824688644819362

Epoch: 5| Step: 9
Training loss: 2.752772808074951
Validation loss: 2.82671844831077

Epoch: 5| Step: 10
Training loss: 2.7250289916992188
Validation loss: 2.822569775324996

Epoch: 49| Step: 0
Training loss: 2.8897602558135986
Validation loss: 2.817149490438482

Epoch: 5| Step: 1
Training loss: 3.6671791076660156
Validation loss: 2.815665065601308

Epoch: 5| Step: 2
Training loss: 2.034597158432007
Validation loss: 2.812536860025057

Epoch: 5| Step: 3
Training loss: 2.453998565673828
Validation loss: 2.8153190535883748

Epoch: 5| Step: 4
Training loss: 3.2216992378234863
Validation loss: 2.8150486177013767

Epoch: 5| Step: 5
Training loss: 2.351322889328003
Validation loss: 2.8161737252307195

Epoch: 5| Step: 6
Training loss: 3.540151596069336
Validation loss: 2.8168169221570416

Epoch: 5| Step: 7
Training loss: 2.9049181938171387
Validation loss: 2.8169846304001345

Epoch: 5| Step: 8
Training loss: 2.773421287536621
Validation loss: 2.8135569582703295

Epoch: 5| Step: 9
Training loss: 3.323871612548828
Validation loss: 2.812666416168213

Epoch: 5| Step: 10
Training loss: 3.090385913848877
Validation loss: 2.812610903093892

Epoch: 50| Step: 0
Training loss: 2.7944438457489014
Validation loss: 2.8112903589843423

Epoch: 5| Step: 1
Training loss: 2.7210028171539307
Validation loss: 2.8144208513280398

Epoch: 5| Step: 2
Training loss: 3.5092899799346924
Validation loss: 2.8166003227233887

Epoch: 5| Step: 3
Training loss: 2.872525453567505
Validation loss: 2.81409873500947

Epoch: 5| Step: 4
Training loss: 3.1595335006713867
Validation loss: 2.8124095906493483

Epoch: 5| Step: 5
Training loss: 3.285533905029297
Validation loss: 2.8091262950692126

Epoch: 5| Step: 6
Training loss: 3.118131399154663
Validation loss: 2.8086113775930097

Epoch: 5| Step: 7
Training loss: 2.3756394386291504
Validation loss: 2.80693394137967

Epoch: 5| Step: 8
Training loss: 2.7044904232025146
Validation loss: 2.80979230583355

Epoch: 5| Step: 9
Training loss: 3.530646562576294
Validation loss: 2.8085481351421726

Epoch: 5| Step: 10
Training loss: 1.9569600820541382
Validation loss: 2.8067887162649505

Epoch: 51| Step: 0
Training loss: 3.0882577896118164
Validation loss: 2.8058018838205645

Epoch: 5| Step: 1
Training loss: 2.745215892791748
Validation loss: 2.807439370821881

Epoch: 5| Step: 2
Training loss: 2.280944585800171
Validation loss: 2.8124358525840183

Epoch: 5| Step: 3
Training loss: 2.8880562782287598
Validation loss: 2.8089066577214066

Epoch: 5| Step: 4
Training loss: 3.160325050354004
Validation loss: 2.80825618005568

Epoch: 5| Step: 5
Training loss: 2.1992344856262207
Validation loss: 2.8088177455368863

Epoch: 5| Step: 6
Training loss: 2.7705390453338623
Validation loss: 2.8126761759481123

Epoch: 5| Step: 7
Training loss: 3.7855286598205566
Validation loss: 2.810255314714165

Epoch: 5| Step: 8
Training loss: 3.526691436767578
Validation loss: 2.8112925457698044

Epoch: 5| Step: 9
Training loss: 3.060110569000244
Validation loss: 2.810252902328327

Epoch: 5| Step: 10
Training loss: 2.6762940883636475
Validation loss: 2.805763254883469

Epoch: 52| Step: 0
Training loss: 3.21008038520813
Validation loss: 2.803778058739119

Epoch: 5| Step: 1
Training loss: 3.064650535583496
Validation loss: 2.8038232121416318

Epoch: 5| Step: 2
Training loss: 3.1299870014190674
Validation loss: 2.8025903471054567

Epoch: 5| Step: 3
Training loss: 2.9520792961120605
Validation loss: 2.803102795795728

Epoch: 5| Step: 4
Training loss: 3.450430393218994
Validation loss: 2.803788359447192

Epoch: 5| Step: 5
Training loss: 2.697288990020752
Validation loss: 2.799606312987625

Epoch: 5| Step: 6
Training loss: 2.3470561504364014
Validation loss: 2.798844119553925

Epoch: 5| Step: 7
Training loss: 2.852445125579834
Validation loss: 2.7982663621184645

Epoch: 5| Step: 8
Training loss: 2.751585006713867
Validation loss: 2.800275146320302

Epoch: 5| Step: 9
Training loss: 2.5186562538146973
Validation loss: 2.7971234013957362

Epoch: 5| Step: 10
Training loss: 3.214449167251587
Validation loss: 2.796624804055819

Epoch: 53| Step: 0
Training loss: 3.088775634765625
Validation loss: 2.7983156378551195

Epoch: 5| Step: 1
Training loss: 3.056257724761963
Validation loss: 2.7998265656091834

Epoch: 5| Step: 2
Training loss: 2.4328229427337646
Validation loss: 2.812939718205442

Epoch: 5| Step: 3
Training loss: 2.880079746246338
Validation loss: 2.815413575018606

Epoch: 5| Step: 4
Training loss: 3.1437437534332275
Validation loss: 2.8042580337934595

Epoch: 5| Step: 5
Training loss: 2.575064182281494
Validation loss: 2.7986651851284887

Epoch: 5| Step: 6
Training loss: 2.7944676876068115
Validation loss: 2.7998226970754643

Epoch: 5| Step: 7
Training loss: 3.47627592086792
Validation loss: 2.7977539108645533

Epoch: 5| Step: 8
Training loss: 3.350717544555664
Validation loss: 2.8007726489856677

Epoch: 5| Step: 9
Training loss: 2.692936897277832
Validation loss: 2.7972228655251126

Epoch: 5| Step: 10
Training loss: 2.6333236694335938
Validation loss: 2.795087701530867

Epoch: 54| Step: 0
Training loss: 2.6240317821502686
Validation loss: 2.7925717728112334

Epoch: 5| Step: 1
Training loss: 2.6777186393737793
Validation loss: 2.7951089284753285

Epoch: 5| Step: 2
Training loss: 2.704995632171631
Validation loss: 2.7921317392779934

Epoch: 5| Step: 3
Training loss: 3.0297205448150635
Validation loss: 2.7923612081876366

Epoch: 5| Step: 4
Training loss: 3.2442402839660645
Validation loss: 2.79455219545672

Epoch: 5| Step: 5
Training loss: 2.4121646881103516
Validation loss: 2.790828215178623

Epoch: 5| Step: 6
Training loss: 2.666713237762451
Validation loss: 2.7961972605797554

Epoch: 5| Step: 7
Training loss: 3.5945351123809814
Validation loss: 2.8037337795380624

Epoch: 5| Step: 8
Training loss: 3.5681145191192627
Validation loss: 2.807551383972168

Epoch: 5| Step: 9
Training loss: 3.1834335327148438
Validation loss: 2.8080171180027786

Epoch: 5| Step: 10
Training loss: 2.375042200088501
Validation loss: 2.804886923041395

Epoch: 55| Step: 0
Training loss: 2.932032823562622
Validation loss: 2.799162108411071

Epoch: 5| Step: 1
Training loss: 2.3550896644592285
Validation loss: 2.790808036763181

Epoch: 5| Step: 2
Training loss: 2.694246768951416
Validation loss: 2.7881561325442408

Epoch: 5| Step: 3
Training loss: 3.7186264991760254
Validation loss: 2.788560293054068

Epoch: 5| Step: 4
Training loss: 2.7938475608825684
Validation loss: 2.786445476675546

Epoch: 5| Step: 5
Training loss: 2.3424689769744873
Validation loss: 2.785961797160487

Epoch: 5| Step: 6
Training loss: 2.824021816253662
Validation loss: 2.7857044589134956

Epoch: 5| Step: 7
Training loss: 2.7449841499328613
Validation loss: 2.7842539151509604

Epoch: 5| Step: 8
Training loss: 3.3832879066467285
Validation loss: 2.7847184288886284

Epoch: 5| Step: 9
Training loss: 3.715622663497925
Validation loss: 2.782047471692485

Epoch: 5| Step: 10
Training loss: 2.4803688526153564
Validation loss: 2.7832789356990526

Epoch: 56| Step: 0
Training loss: 2.3972365856170654
Validation loss: 2.7823745281465593

Epoch: 5| Step: 1
Training loss: 3.418149471282959
Validation loss: 2.7846431962905394

Epoch: 5| Step: 2
Training loss: 2.933694362640381
Validation loss: 2.7831106544822775

Epoch: 5| Step: 3
Training loss: 3.215480089187622
Validation loss: 2.784278590192077

Epoch: 5| Step: 4
Training loss: 3.0821118354797363
Validation loss: 2.7824455948286158

Epoch: 5| Step: 5
Training loss: 3.6996192932128906
Validation loss: 2.784403985546481

Epoch: 5| Step: 6
Training loss: 2.547794818878174
Validation loss: 2.7834968182348434

Epoch: 5| Step: 7
Training loss: 2.8505187034606934
Validation loss: 2.7812241636296755

Epoch: 5| Step: 8
Training loss: 2.740480899810791
Validation loss: 2.7791203427058395

Epoch: 5| Step: 9
Training loss: 2.292320728302002
Validation loss: 2.7776479362159647

Epoch: 5| Step: 10
Training loss: 2.824954032897949
Validation loss: 2.778022873786188

Epoch: 57| Step: 0
Training loss: 2.7621941566467285
Validation loss: 2.7785345533842682

Epoch: 5| Step: 1
Training loss: 2.471470355987549
Validation loss: 2.7769695456309984

Epoch: 5| Step: 2
Training loss: 2.242037296295166
Validation loss: 2.7760105466329925

Epoch: 5| Step: 3
Training loss: 3.704322338104248
Validation loss: 2.7767791466046403

Epoch: 5| Step: 4
Training loss: 2.238767147064209
Validation loss: 2.7769164654516403

Epoch: 5| Step: 5
Training loss: 2.831397771835327
Validation loss: 2.774974905034547

Epoch: 5| Step: 6
Training loss: 3.430919647216797
Validation loss: 2.7759158842025267

Epoch: 5| Step: 7
Training loss: 3.2549221515655518
Validation loss: 2.774465673713274

Epoch: 5| Step: 8
Training loss: 3.031409978866577
Validation loss: 2.773991389941144

Epoch: 5| Step: 9
Training loss: 3.043710708618164
Validation loss: 2.773076065125004

Epoch: 5| Step: 10
Training loss: 2.9385454654693604
Validation loss: 2.77032369952048

Epoch: 58| Step: 0
Training loss: 2.906592607498169
Validation loss: 2.772066277842368

Epoch: 5| Step: 1
Training loss: 3.406482696533203
Validation loss: 2.7714012822797223

Epoch: 5| Step: 2
Training loss: 2.3933749198913574
Validation loss: 2.769664320894467

Epoch: 5| Step: 3
Training loss: 3.1047749519348145
Validation loss: 2.771858028186265

Epoch: 5| Step: 4
Training loss: 2.127622365951538
Validation loss: 2.768947555172828

Epoch: 5| Step: 5
Training loss: 2.7781100273132324
Validation loss: 2.772265439392418

Epoch: 5| Step: 6
Training loss: 2.851663589477539
Validation loss: 2.7734111150105796

Epoch: 5| Step: 7
Training loss: 2.750150203704834
Validation loss: 2.771751744772798

Epoch: 5| Step: 8
Training loss: 3.301210880279541
Validation loss: 2.7725462503330682

Epoch: 5| Step: 9
Training loss: 3.3949038982391357
Validation loss: 2.7748002211252847

Epoch: 5| Step: 10
Training loss: 2.884384870529175
Validation loss: 2.774250312518048

Epoch: 59| Step: 0
Training loss: 2.8904175758361816
Validation loss: 2.7735237588164625

Epoch: 5| Step: 1
Training loss: 3.0868983268737793
Validation loss: 2.7713757484189925

Epoch: 5| Step: 2
Training loss: 2.8153586387634277
Validation loss: 2.7677966625459733

Epoch: 5| Step: 3
Training loss: 2.6645452976226807
Validation loss: 2.77020110366165

Epoch: 5| Step: 4
Training loss: 2.8486762046813965
Validation loss: 2.769548623792587

Epoch: 5| Step: 5
Training loss: 2.9500913619995117
Validation loss: 2.7739050721609466

Epoch: 5| Step: 6
Training loss: 2.8107218742370605
Validation loss: 2.7745980037155973

Epoch: 5| Step: 7
Training loss: 3.8391151428222656
Validation loss: 2.787806213542979

Epoch: 5| Step: 8
Training loss: 2.6377625465393066
Validation loss: 2.7922256761981594

Epoch: 5| Step: 9
Training loss: 2.4154553413391113
Validation loss: 2.830304827741397

Epoch: 5| Step: 10
Training loss: 2.9726366996765137
Validation loss: 2.8692599265806136

Epoch: 60| Step: 0
Training loss: 2.318446397781372
Validation loss: 2.8622742852857037

Epoch: 5| Step: 1
Training loss: 2.322343349456787
Validation loss: 2.8525601586987896

Epoch: 5| Step: 2
Training loss: 3.190012216567993
Validation loss: 2.850691577439667

Epoch: 5| Step: 3
Training loss: 3.3567779064178467
Validation loss: 2.8105671790338334

Epoch: 5| Step: 4
Training loss: 3.0394680500030518
Validation loss: 2.7748896947471042

Epoch: 5| Step: 5
Training loss: 2.9226346015930176
Validation loss: 2.7680811369290916

Epoch: 5| Step: 6
Training loss: 3.6912436485290527
Validation loss: 2.7678305692570184

Epoch: 5| Step: 7
Training loss: 2.96130108833313
Validation loss: 2.776733898347424

Epoch: 5| Step: 8
Training loss: 2.552497386932373
Validation loss: 2.780950515500961

Epoch: 5| Step: 9
Training loss: 2.7510173320770264
Validation loss: 2.7878651003683768

Epoch: 5| Step: 10
Training loss: 2.8586528301239014
Validation loss: 2.778685256999026

Epoch: 61| Step: 0
Training loss: 3.682213544845581
Validation loss: 2.7732646311483076

Epoch: 5| Step: 1
Training loss: 2.828280210494995
Validation loss: 2.771281652553107

Epoch: 5| Step: 2
Training loss: 2.474888324737549
Validation loss: 2.7720263337576263

Epoch: 5| Step: 3
Training loss: 2.7971744537353516
Validation loss: 2.763822809342415

Epoch: 5| Step: 4
Training loss: 2.255985736846924
Validation loss: 2.7645323199610554

Epoch: 5| Step: 5
Training loss: 2.4643096923828125
Validation loss: 2.7640968394535843

Epoch: 5| Step: 6
Training loss: 3.8462517261505127
Validation loss: 2.7647236906072146

Epoch: 5| Step: 7
Training loss: 3.606048583984375
Validation loss: 2.7649847333149244

Epoch: 5| Step: 8
Training loss: 2.780531644821167
Validation loss: 2.7700628516494588

Epoch: 5| Step: 9
Training loss: 2.3460800647735596
Validation loss: 2.7723997228889057

Epoch: 5| Step: 10
Training loss: 2.655383586883545
Validation loss: 2.7770347441396406

Epoch: 62| Step: 0
Training loss: 2.2325825691223145
Validation loss: 2.791635154395975

Epoch: 5| Step: 1
Training loss: 3.166844367980957
Validation loss: 2.8245543972138436

Epoch: 5| Step: 2
Training loss: 3.1720056533813477
Validation loss: 2.824368287158269

Epoch: 5| Step: 3
Training loss: 3.11771821975708
Validation loss: 2.8165200371896066

Epoch: 5| Step: 4
Training loss: 3.07973051071167
Validation loss: 2.779696838830107

Epoch: 5| Step: 5
Training loss: 3.033006191253662
Validation loss: 2.764535052801973

Epoch: 5| Step: 6
Training loss: 3.113865375518799
Validation loss: 2.758688183240993

Epoch: 5| Step: 7
Training loss: 3.0677695274353027
Validation loss: 2.756543182557629

Epoch: 5| Step: 8
Training loss: 2.716207265853882
Validation loss: 2.7666018701368764

Epoch: 5| Step: 9
Training loss: 2.72111177444458
Validation loss: 2.768400207642586

Epoch: 5| Step: 10
Training loss: 2.460374116897583
Validation loss: 2.7628200156714326

Epoch: 63| Step: 0
Training loss: 2.882211208343506
Validation loss: 2.7558771948660574

Epoch: 5| Step: 1
Training loss: 1.808958649635315
Validation loss: 2.7534752943182506

Epoch: 5| Step: 2
Training loss: 2.842686176300049
Validation loss: 2.75863209719299

Epoch: 5| Step: 3
Training loss: 3.1871230602264404
Validation loss: 2.7604572311524422

Epoch: 5| Step: 4
Training loss: 3.000917434692383
Validation loss: 2.770463498689795

Epoch: 5| Step: 5
Training loss: 3.4208781719207764
Validation loss: 2.764341628679665

Epoch: 5| Step: 6
Training loss: 2.6327016353607178
Validation loss: 2.756470154690486

Epoch: 5| Step: 7
Training loss: 3.0816845893859863
Validation loss: 2.7508203739761026

Epoch: 5| Step: 8
Training loss: 3.0797600746154785
Validation loss: 2.750424467107301

Epoch: 5| Step: 9
Training loss: 3.314265489578247
Validation loss: 2.75344753778109

Epoch: 5| Step: 10
Training loss: 2.5097293853759766
Validation loss: 2.752383844826811

Epoch: 64| Step: 0
Training loss: 3.095179796218872
Validation loss: 2.7559075150438535

Epoch: 5| Step: 1
Training loss: 2.2773776054382324
Validation loss: 2.758452969212686

Epoch: 5| Step: 2
Training loss: 3.1946146488189697
Validation loss: 2.7610905298622708

Epoch: 5| Step: 3
Training loss: 3.090000867843628
Validation loss: 2.763081899253271

Epoch: 5| Step: 4
Training loss: 3.0838463306427
Validation loss: 2.753290560937697

Epoch: 5| Step: 5
Training loss: 2.73979115486145
Validation loss: 2.7479460905956965

Epoch: 5| Step: 6
Training loss: 2.2596540451049805
Validation loss: 2.746138172764932

Epoch: 5| Step: 7
Training loss: 2.458299160003662
Validation loss: 2.7453776482612855

Epoch: 5| Step: 8
Training loss: 2.7425436973571777
Validation loss: 2.745514669725972

Epoch: 5| Step: 9
Training loss: 3.317183256149292
Validation loss: 2.7453723594706547

Epoch: 5| Step: 10
Training loss: 3.6113643646240234
Validation loss: 2.7455358710340274

Epoch: 65| Step: 0
Training loss: 3.3469014167785645
Validation loss: 2.7444112941782963

Epoch: 5| Step: 1
Training loss: 2.663318634033203
Validation loss: 2.7474710531132196

Epoch: 5| Step: 2
Training loss: 2.1695845127105713
Validation loss: 2.745984172308317

Epoch: 5| Step: 3
Training loss: 3.590439558029175
Validation loss: 2.746281854567989

Epoch: 5| Step: 4
Training loss: 2.6520698070526123
Validation loss: 2.7481128041462233

Epoch: 5| Step: 5
Training loss: 2.722137928009033
Validation loss: 2.748267060966902

Epoch: 5| Step: 6
Training loss: 3.672502040863037
Validation loss: 2.749206950587611

Epoch: 5| Step: 7
Training loss: 2.521239757537842
Validation loss: 2.7428251850989556

Epoch: 5| Step: 8
Training loss: 2.361530065536499
Validation loss: 2.741106794726464

Epoch: 5| Step: 9
Training loss: 3.2603752613067627
Validation loss: 2.7413698934739634

Epoch: 5| Step: 10
Training loss: 2.7251574993133545
Validation loss: 2.7408952789921917

Epoch: 66| Step: 0
Training loss: 2.5508971214294434
Validation loss: 2.7459087346189763

Epoch: 5| Step: 1
Training loss: 2.82969331741333
Validation loss: 2.7420981648147746

Epoch: 5| Step: 2
Training loss: 2.595331907272339
Validation loss: 2.74721178700847

Epoch: 5| Step: 3
Training loss: 3.1433491706848145
Validation loss: 2.7460006949722127

Epoch: 5| Step: 4
Training loss: 3.0119094848632812
Validation loss: 2.7467464708512828

Epoch: 5| Step: 5
Training loss: 2.394468307495117
Validation loss: 2.739699122726276

Epoch: 5| Step: 6
Training loss: 3.572312116622925
Validation loss: 2.7357428714793217

Epoch: 5| Step: 7
Training loss: 3.148892402648926
Validation loss: 2.730956167303106

Epoch: 5| Step: 8
Training loss: 3.419867992401123
Validation loss: 2.7264074740871305

Epoch: 5| Step: 9
Training loss: 2.4836270809173584
Validation loss: 2.7260560271560506

Epoch: 5| Step: 10
Training loss: 2.409759998321533
Validation loss: 2.727582282917474

Epoch: 67| Step: 0
Training loss: 3.0756163597106934
Validation loss: 2.7307772892777638

Epoch: 5| Step: 1
Training loss: 3.017967939376831
Validation loss: 2.743697343334075

Epoch: 5| Step: 2
Training loss: 2.3521928787231445
Validation loss: 2.728783622864754

Epoch: 5| Step: 3
Training loss: 2.721503734588623
Validation loss: 2.7384852465762886

Epoch: 5| Step: 4
Training loss: 3.373081922531128
Validation loss: 2.7403023191677627

Epoch: 5| Step: 5
Training loss: 1.823240041732788
Validation loss: 2.7304280034957396

Epoch: 5| Step: 6
Training loss: 3.0076727867126465
Validation loss: 2.726162600260909

Epoch: 5| Step: 7
Training loss: 3.349130153656006
Validation loss: 2.7190059384992047

Epoch: 5| Step: 8
Training loss: 3.168948173522949
Validation loss: 2.7149448907503517

Epoch: 5| Step: 9
Training loss: 3.1813132762908936
Validation loss: 2.716109545000138

Epoch: 5| Step: 10
Training loss: 2.3959195613861084
Validation loss: 2.7183484364581365

Epoch: 68| Step: 0
Training loss: 3.582273483276367
Validation loss: 2.7194388912570093

Epoch: 5| Step: 1
Training loss: 3.3582701683044434
Validation loss: 2.716292204395417

Epoch: 5| Step: 2
Training loss: 2.5147793292999268
Validation loss: 2.7162359222289054

Epoch: 5| Step: 3
Training loss: 2.523332118988037
Validation loss: 2.712026298687022

Epoch: 5| Step: 4
Training loss: 3.2809557914733887
Validation loss: 2.712046323284026

Epoch: 5| Step: 5
Training loss: 3.0045852661132812
Validation loss: 2.7111866961243334

Epoch: 5| Step: 6
Training loss: 2.6343469619750977
Validation loss: 2.7103067905672136

Epoch: 5| Step: 7
Training loss: 2.0327935218811035
Validation loss: 2.714965117874966

Epoch: 5| Step: 8
Training loss: 3.0738558769226074
Validation loss: 2.7206146691435125

Epoch: 5| Step: 9
Training loss: 2.487844705581665
Validation loss: 2.7211408051111365

Epoch: 5| Step: 10
Training loss: 3.001676559448242
Validation loss: 2.72341219071419

Epoch: 69| Step: 0
Training loss: 3.1396031379699707
Validation loss: 2.720216712644023

Epoch: 5| Step: 1
Training loss: 2.177682638168335
Validation loss: 2.7180347929718676

Epoch: 5| Step: 2
Training loss: 2.970410108566284
Validation loss: 2.71337483262503

Epoch: 5| Step: 3
Training loss: 2.4867730140686035
Validation loss: 2.711317308487431

Epoch: 5| Step: 4
Training loss: 3.4361777305603027
Validation loss: 2.709264806521836

Epoch: 5| Step: 5
Training loss: 3.1570873260498047
Validation loss: 2.7060178172203804

Epoch: 5| Step: 6
Training loss: 2.369969129562378
Validation loss: 2.7043065819689023

Epoch: 5| Step: 7
Training loss: 2.72939133644104
Validation loss: 2.7091319689186673

Epoch: 5| Step: 8
Training loss: 3.1350390911102295
Validation loss: 2.7080936406248357

Epoch: 5| Step: 9
Training loss: 3.2543606758117676
Validation loss: 2.7156910409209547

Epoch: 5| Step: 10
Training loss: 2.5190460681915283
Validation loss: 2.7185857244717178

Epoch: 70| Step: 0
Training loss: 2.629581928253174
Validation loss: 2.7186436012227047

Epoch: 5| Step: 1
Training loss: 3.752904176712036
Validation loss: 2.706090724596413

Epoch: 5| Step: 2
Training loss: 2.412264585494995
Validation loss: 2.7047888822452997

Epoch: 5| Step: 3
Training loss: 3.1044769287109375
Validation loss: 2.699797281654932

Epoch: 5| Step: 4
Training loss: 2.225543260574341
Validation loss: 2.6985939651407223

Epoch: 5| Step: 5
Training loss: 2.8659286499023438
Validation loss: 2.702243851077172

Epoch: 5| Step: 6
Training loss: 3.204364776611328
Validation loss: 2.7065772318070933

Epoch: 5| Step: 7
Training loss: 2.517049789428711
Validation loss: 2.709921636889058

Epoch: 5| Step: 8
Training loss: 2.4648852348327637
Validation loss: 2.7143406201434392

Epoch: 5| Step: 9
Training loss: 3.3285183906555176
Validation loss: 2.720694200966948

Epoch: 5| Step: 10
Training loss: 2.8312535285949707
Validation loss: 2.7218052751274517

Epoch: 71| Step: 0
Training loss: 3.2443535327911377
Validation loss: 2.749092766033706

Epoch: 5| Step: 1
Training loss: 3.5302741527557373
Validation loss: 2.7537745327077885

Epoch: 5| Step: 2
Training loss: 2.9494926929473877
Validation loss: 2.7395756808660363

Epoch: 5| Step: 3
Training loss: 2.563936948776245
Validation loss: 2.7034727963068153

Epoch: 5| Step: 4
Training loss: 3.346775770187378
Validation loss: 2.7017021486836095

Epoch: 5| Step: 5
Training loss: 2.489834785461426
Validation loss: 2.7014625944117063

Epoch: 5| Step: 6
Training loss: 2.345221996307373
Validation loss: 2.7019198530463764

Epoch: 5| Step: 7
Training loss: 2.858642578125
Validation loss: 2.703329914359636

Epoch: 5| Step: 8
Training loss: 3.1859021186828613
Validation loss: 2.7008910538047872

Epoch: 5| Step: 9
Training loss: 1.9409987926483154
Validation loss: 2.696013201949417

Epoch: 5| Step: 10
Training loss: 2.957972288131714
Validation loss: 2.695089304318992

Epoch: 72| Step: 0
Training loss: 3.243999481201172
Validation loss: 2.6952844819714947

Epoch: 5| Step: 1
Training loss: 2.3442225456237793
Validation loss: 2.6950491923157887

Epoch: 5| Step: 2
Training loss: 2.602703094482422
Validation loss: 2.6944882408265145

Epoch: 5| Step: 3
Training loss: 2.965831756591797
Validation loss: 2.6934609233692126

Epoch: 5| Step: 4
Training loss: 2.389112949371338
Validation loss: 2.6971210587409233

Epoch: 5| Step: 5
Training loss: 2.8082823753356934
Validation loss: 2.696610084144018

Epoch: 5| Step: 6
Training loss: 2.6170706748962402
Validation loss: 2.694820350216281

Epoch: 5| Step: 7
Training loss: 3.5569446086883545
Validation loss: 2.6951732584225234

Epoch: 5| Step: 8
Training loss: 2.686119556427002
Validation loss: 2.6909736356427594

Epoch: 5| Step: 9
Training loss: 2.965825319290161
Validation loss: 2.6897058563847698

Epoch: 5| Step: 10
Training loss: 3.1709494590759277
Validation loss: 2.691252818671606

Epoch: 73| Step: 0
Training loss: 2.9463531970977783
Validation loss: 2.685798501455656

Epoch: 5| Step: 1
Training loss: 3.015026807785034
Validation loss: 2.6896137806677047

Epoch: 5| Step: 2
Training loss: 3.0060036182403564
Validation loss: 2.6929558579639723

Epoch: 5| Step: 3
Training loss: 2.858950138092041
Validation loss: 2.6954622166131132

Epoch: 5| Step: 4
Training loss: 3.0014584064483643
Validation loss: 2.694995149489372

Epoch: 5| Step: 5
Training loss: 2.71034574508667
Validation loss: 2.695065103551393

Epoch: 5| Step: 6
Training loss: 3.0845882892608643
Validation loss: 2.6968527583665747

Epoch: 5| Step: 7
Training loss: 2.397622585296631
Validation loss: 2.694642759138538

Epoch: 5| Step: 8
Training loss: 2.9928698539733887
Validation loss: 2.6878044964164816

Epoch: 5| Step: 9
Training loss: 2.5434491634368896
Validation loss: 2.6866144723789667

Epoch: 5| Step: 10
Training loss: 2.5813369750976562
Validation loss: 2.6894954122522825

Epoch: 74| Step: 0
Training loss: 2.9766318798065186
Validation loss: 2.688632990724297

Epoch: 5| Step: 1
Training loss: 3.270430326461792
Validation loss: 2.684565087800385

Epoch: 5| Step: 2
Training loss: 2.5813310146331787
Validation loss: 2.6868250344389226

Epoch: 5| Step: 3
Training loss: 2.4636104106903076
Validation loss: 2.6854250918152514

Epoch: 5| Step: 4
Training loss: 2.9429736137390137
Validation loss: 2.689311588964155

Epoch: 5| Step: 5
Training loss: 2.681396722793579
Validation loss: 2.690823111482846

Epoch: 5| Step: 6
Training loss: 2.6786258220672607
Validation loss: 2.6941364349857455

Epoch: 5| Step: 7
Training loss: 2.6424736976623535
Validation loss: 2.691326300303141

Epoch: 5| Step: 8
Training loss: 3.224696636199951
Validation loss: 2.689205179932297

Epoch: 5| Step: 9
Training loss: 3.2690987586975098
Validation loss: 2.685714634515906

Epoch: 5| Step: 10
Training loss: 2.3258564472198486
Validation loss: 2.6791098476738058

Epoch: 75| Step: 0
Training loss: 1.8565969467163086
Validation loss: 2.677681274311517

Epoch: 5| Step: 1
Training loss: 3.2021396160125732
Validation loss: 2.6790945247937272

Epoch: 5| Step: 2
Training loss: 3.4641520977020264
Validation loss: 2.679216049050772

Epoch: 5| Step: 3
Training loss: 2.659752607345581
Validation loss: 2.682398831972512

Epoch: 5| Step: 4
Training loss: 3.0833311080932617
Validation loss: 2.6892299036825857

Epoch: 5| Step: 5
Training loss: 3.395764112472534
Validation loss: 2.691690747455884

Epoch: 5| Step: 6
Training loss: 2.7924726009368896
Validation loss: 2.6898477744030695

Epoch: 5| Step: 7
Training loss: 2.6539642810821533
Validation loss: 2.6837988027962307

Epoch: 5| Step: 8
Training loss: 2.080256700515747
Validation loss: 2.678652994094356

Epoch: 5| Step: 9
Training loss: 2.730947971343994
Validation loss: 2.674542183517128

Epoch: 5| Step: 10
Training loss: 3.274582624435425
Validation loss: 2.677872283484346

Epoch: 76| Step: 0
Training loss: 1.7624431848526
Validation loss: 2.6752560600157707

Epoch: 5| Step: 1
Training loss: 2.8005824089050293
Validation loss: 2.6829125035193657

Epoch: 5| Step: 2
Training loss: 3.2785773277282715
Validation loss: 2.6981046430526243

Epoch: 5| Step: 3
Training loss: 3.302042007446289
Validation loss: 2.717912435531616

Epoch: 5| Step: 4
Training loss: 2.8859400749206543
Validation loss: 2.7175032913043933

Epoch: 5| Step: 5
Training loss: 3.043884754180908
Validation loss: 2.698862039914695

Epoch: 5| Step: 6
Training loss: 2.4925472736358643
Validation loss: 2.6763267978545158

Epoch: 5| Step: 7
Training loss: 2.839534282684326
Validation loss: 2.677992033702071

Epoch: 5| Step: 8
Training loss: 2.500797748565674
Validation loss: 2.678277982178555

Epoch: 5| Step: 9
Training loss: 2.8667759895324707
Validation loss: 2.675017897800733

Epoch: 5| Step: 10
Training loss: 3.430677890777588
Validation loss: 2.672458512808687

Epoch: 77| Step: 0
Training loss: 3.1664741039276123
Validation loss: 2.673652664307625

Epoch: 5| Step: 1
Training loss: 2.6505088806152344
Validation loss: 2.677783355917982

Epoch: 5| Step: 2
Training loss: 3.2784721851348877
Validation loss: 2.67331789898616

Epoch: 5| Step: 3
Training loss: 3.0822927951812744
Validation loss: 2.6735705124434603

Epoch: 5| Step: 4
Training loss: 3.8657584190368652
Validation loss: 2.6710883955801688

Epoch: 5| Step: 5
Training loss: 2.8079893589019775
Validation loss: 2.6695059140523276

Epoch: 5| Step: 6
Training loss: 2.043144702911377
Validation loss: 2.671326965414068

Epoch: 5| Step: 7
Training loss: 2.2060530185699463
Validation loss: 2.6712318902374594

Epoch: 5| Step: 8
Training loss: 2.069138288497925
Validation loss: 2.674835284550985

Epoch: 5| Step: 9
Training loss: 3.0130667686462402
Validation loss: 2.6779115225679133

Epoch: 5| Step: 10
Training loss: 2.8474981784820557
Validation loss: 2.6765913860772246

Epoch: 78| Step: 0
Training loss: 2.40606951713562
Validation loss: 2.6807606758609897

Epoch: 5| Step: 1
Training loss: 3.3588294982910156
Validation loss: 2.682284237236105

Epoch: 5| Step: 2
Training loss: 2.674041748046875
Validation loss: 2.686534802118937

Epoch: 5| Step: 3
Training loss: 2.401582717895508
Validation loss: 2.6814672434201805

Epoch: 5| Step: 4
Training loss: 3.022047519683838
Validation loss: 2.6820443753273255

Epoch: 5| Step: 5
Training loss: 2.176210880279541
Validation loss: 2.6784897594041723

Epoch: 5| Step: 6
Training loss: 2.5355594158172607
Validation loss: 2.6774192651112876

Epoch: 5| Step: 7
Training loss: 2.7176520824432373
Validation loss: 2.6925064081786783

Epoch: 5| Step: 8
Training loss: 3.9358673095703125
Validation loss: 2.707255850556076

Epoch: 5| Step: 9
Training loss: 2.9251883029937744
Validation loss: 2.7019921579668598

Epoch: 5| Step: 10
Training loss: 2.8947322368621826
Validation loss: 2.687197346841135

Epoch: 79| Step: 0
Training loss: 3.012697696685791
Validation loss: 2.6666881063933014

Epoch: 5| Step: 1
Training loss: 2.5735678672790527
Validation loss: 2.6643995264525056

Epoch: 5| Step: 2
Training loss: 2.9531285762786865
Validation loss: 2.6631438962874876

Epoch: 5| Step: 3
Training loss: 2.4038805961608887
Validation loss: 2.6689186685828754

Epoch: 5| Step: 4
Training loss: 2.792297124862671
Validation loss: 2.672127567311769

Epoch: 5| Step: 5
Training loss: 3.058115005493164
Validation loss: 2.6992368441756054

Epoch: 5| Step: 6
Training loss: 3.430736541748047
Validation loss: 2.7004682069183676

Epoch: 5| Step: 7
Training loss: 3.334834337234497
Validation loss: 2.6775866272628948

Epoch: 5| Step: 8
Training loss: 2.5549871921539307
Validation loss: 2.670818277584609

Epoch: 5| Step: 9
Training loss: 3.002227544784546
Validation loss: 2.664939195879044

Epoch: 5| Step: 10
Training loss: 1.7157748937606812
Validation loss: 2.663963479380454

Epoch: 80| Step: 0
Training loss: 2.8153493404388428
Validation loss: 2.659035628841769

Epoch: 5| Step: 1
Training loss: 3.328794002532959
Validation loss: 2.659052141251103

Epoch: 5| Step: 2
Training loss: 3.2480785846710205
Validation loss: 2.6633933551849855

Epoch: 5| Step: 3
Training loss: 3.0631232261657715
Validation loss: 2.6685784503977787

Epoch: 5| Step: 4
Training loss: 2.8516757488250732
Validation loss: 2.677643491375831

Epoch: 5| Step: 5
Training loss: 2.50445818901062
Validation loss: 2.6772993123659523

Epoch: 5| Step: 6
Training loss: 3.7014946937561035
Validation loss: 2.6658393388153403

Epoch: 5| Step: 7
Training loss: 2.2039051055908203
Validation loss: 2.670482499625093

Epoch: 5| Step: 8
Training loss: 3.027552604675293
Validation loss: 2.6737108948410198

Epoch: 5| Step: 9
Training loss: 2.2719345092773438
Validation loss: 2.673377431848998

Epoch: 5| Step: 10
Training loss: 1.8190656900405884
Validation loss: 2.6759017359825874

Epoch: 81| Step: 0
Training loss: 2.8509631156921387
Validation loss: 2.6822542426406697

Epoch: 5| Step: 1
Training loss: 2.806121826171875
Validation loss: 2.687948267946961

Epoch: 5| Step: 2
Training loss: 3.098170280456543
Validation loss: 2.6815971712912283

Epoch: 5| Step: 3
Training loss: 2.160982131958008
Validation loss: 2.6762410568934616

Epoch: 5| Step: 4
Training loss: 3.266655445098877
Validation loss: 2.673965654065532

Epoch: 5| Step: 5
Training loss: 2.3211452960968018
Validation loss: 2.6750598107614825

Epoch: 5| Step: 6
Training loss: 2.8578691482543945
Validation loss: 2.6740938694246355

Epoch: 5| Step: 7
Training loss: 2.93717098236084
Validation loss: 2.6716994675256873

Epoch: 5| Step: 8
Training loss: 3.375314712524414
Validation loss: 2.667184414402131

Epoch: 5| Step: 9
Training loss: 2.5859172344207764
Validation loss: 2.667619237335779

Epoch: 5| Step: 10
Training loss: 2.6315970420837402
Validation loss: 2.663518759512132

Epoch: 82| Step: 0
Training loss: 3.169379711151123
Validation loss: 2.66089044591432

Epoch: 5| Step: 1
Training loss: 3.3369510173797607
Validation loss: 2.6627043421550463

Epoch: 5| Step: 2
Training loss: 2.7630796432495117
Validation loss: 2.6555113279691307

Epoch: 5| Step: 3
Training loss: 2.5022430419921875
Validation loss: 2.6545264438916276

Epoch: 5| Step: 4
Training loss: 2.8335161209106445
Validation loss: 2.6520663640832387

Epoch: 5| Step: 5
Training loss: 3.1104929447174072
Validation loss: 2.650767787810295

Epoch: 5| Step: 6
Training loss: 2.7723569869995117
Validation loss: 2.654216745848297

Epoch: 5| Step: 7
Training loss: 2.1093978881835938
Validation loss: 2.653156716336486

Epoch: 5| Step: 8
Training loss: 2.9033703804016113
Validation loss: 2.6505674751855994

Epoch: 5| Step: 9
Training loss: 2.166308879852295
Validation loss: 2.6511793316051526

Epoch: 5| Step: 10
Training loss: 3.2101352214813232
Validation loss: 2.6516867350506526

Epoch: 83| Step: 0
Training loss: 2.686061143875122
Validation loss: 2.6541558978378132

Epoch: 5| Step: 1
Training loss: 2.6740753650665283
Validation loss: 2.6526792587772494

Epoch: 5| Step: 2
Training loss: 2.2310566902160645
Validation loss: 2.6555824049057497

Epoch: 5| Step: 3
Training loss: 2.543907403945923
Validation loss: 2.6584591968085176

Epoch: 5| Step: 4
Training loss: 3.701328992843628
Validation loss: 2.6563938535669798

Epoch: 5| Step: 5
Training loss: 2.9172844886779785
Validation loss: 2.6551536642095095

Epoch: 5| Step: 6
Training loss: 3.1909730434417725
Validation loss: 2.6510504240630777

Epoch: 5| Step: 7
Training loss: 2.524437427520752
Validation loss: 2.650908811118013

Epoch: 5| Step: 8
Training loss: 2.940065622329712
Validation loss: 2.650894631621658

Epoch: 5| Step: 9
Training loss: 2.695240020751953
Validation loss: 2.6468827288637877

Epoch: 5| Step: 10
Training loss: 2.6711437702178955
Validation loss: 2.6477971948603147

Epoch: 84| Step: 0
Training loss: 2.589290142059326
Validation loss: 2.646723690853324

Epoch: 5| Step: 1
Training loss: 2.727283000946045
Validation loss: 2.646835352784844

Epoch: 5| Step: 2
Training loss: 2.787205696105957
Validation loss: 2.644590787990119

Epoch: 5| Step: 3
Training loss: 2.9161295890808105
Validation loss: 2.6454919486917476

Epoch: 5| Step: 4
Training loss: 2.83311128616333
Validation loss: 2.644658878285398

Epoch: 5| Step: 5
Training loss: 3.1878530979156494
Validation loss: 2.645414959999823

Epoch: 5| Step: 6
Training loss: 2.4745750427246094
Validation loss: 2.647596836090088

Epoch: 5| Step: 7
Training loss: 2.6454639434814453
Validation loss: 2.642746356225783

Epoch: 5| Step: 8
Training loss: 3.0588784217834473
Validation loss: 2.6421986626040552

Epoch: 5| Step: 9
Training loss: 2.4880359172821045
Validation loss: 2.645076564563218

Epoch: 5| Step: 10
Training loss: 3.0641019344329834
Validation loss: 2.643082872513802

Epoch: 85| Step: 0
Training loss: 2.661996364593506
Validation loss: 2.6412207054835495

Epoch: 5| Step: 1
Training loss: 2.850980281829834
Validation loss: 2.6433330376942954

Epoch: 5| Step: 2
Training loss: 2.968348741531372
Validation loss: 2.6430414286992883

Epoch: 5| Step: 3
Training loss: 3.048485040664673
Validation loss: 2.645693612355058

Epoch: 5| Step: 4
Training loss: 1.9720138311386108
Validation loss: 2.6450899518946165

Epoch: 5| Step: 5
Training loss: 2.524168014526367
Validation loss: 2.641732415845317

Epoch: 5| Step: 6
Training loss: 3.2861666679382324
Validation loss: 2.6408258086891583

Epoch: 5| Step: 7
Training loss: 2.233538866043091
Validation loss: 2.6365170940276115

Epoch: 5| Step: 8
Training loss: 2.94581937789917
Validation loss: 2.6367467603375836

Epoch: 5| Step: 9
Training loss: 2.77392578125
Validation loss: 2.6375682046336513

Epoch: 5| Step: 10
Training loss: 3.498558521270752
Validation loss: 2.6374916261242283

Epoch: 86| Step: 0
Training loss: 2.397580862045288
Validation loss: 2.6374555633914087

Epoch: 5| Step: 1
Training loss: 2.935847759246826
Validation loss: 2.6430075296791653

Epoch: 5| Step: 2
Training loss: 2.428123950958252
Validation loss: 2.6437204678853354

Epoch: 5| Step: 3
Training loss: 2.682345151901245
Validation loss: 2.644876656993743

Epoch: 5| Step: 4
Training loss: 1.7516841888427734
Validation loss: 2.6414851424514607

Epoch: 5| Step: 5
Training loss: 3.6305594444274902
Validation loss: 2.6372036498080016

Epoch: 5| Step: 6
Training loss: 2.481739044189453
Validation loss: 2.6378995013493363

Epoch: 5| Step: 7
Training loss: 2.421912670135498
Validation loss: 2.639580916332942

Epoch: 5| Step: 8
Training loss: 3.01286244392395
Validation loss: 2.6371137378036336

Epoch: 5| Step: 9
Training loss: 3.370238780975342
Validation loss: 2.6399776833031767

Epoch: 5| Step: 10
Training loss: 3.709527015686035
Validation loss: 2.6389445386907107

Epoch: 87| Step: 0
Training loss: 3.3498871326446533
Validation loss: 2.6395166074076006

Epoch: 5| Step: 1
Training loss: 2.9135613441467285
Validation loss: 2.6378172482213667

Epoch: 5| Step: 2
Training loss: 2.462289810180664
Validation loss: 2.6366447787131033

Epoch: 5| Step: 3
Training loss: 2.6686208248138428
Validation loss: 2.6346868879051617

Epoch: 5| Step: 4
Training loss: 2.8091282844543457
Validation loss: 2.6344806250705513

Epoch: 5| Step: 5
Training loss: 3.0751919746398926
Validation loss: 2.6311864211995113

Epoch: 5| Step: 6
Training loss: 2.7569549083709717
Validation loss: 2.631068827003561

Epoch: 5| Step: 7
Training loss: 2.3411102294921875
Validation loss: 2.630604523484425

Epoch: 5| Step: 8
Training loss: 2.6084609031677246
Validation loss: 2.626117367898264

Epoch: 5| Step: 9
Training loss: 2.9569358825683594
Validation loss: 2.629659696291852

Epoch: 5| Step: 10
Training loss: 2.661301612854004
Validation loss: 2.632543340806038

Epoch: 88| Step: 0
Training loss: 3.0508365631103516
Validation loss: 2.6310607746083248

Epoch: 5| Step: 1
Training loss: 2.2723875045776367
Validation loss: 2.635868710856284

Epoch: 5| Step: 2
Training loss: 2.96781849861145
Validation loss: 2.6371605524452786

Epoch: 5| Step: 3
Training loss: 2.366751194000244
Validation loss: 2.6341871805088495

Epoch: 5| Step: 4
Training loss: 3.0220863819122314
Validation loss: 2.6327637754460818

Epoch: 5| Step: 5
Training loss: 3.562847137451172
Validation loss: 2.6364415768654115

Epoch: 5| Step: 6
Training loss: 2.880514621734619
Validation loss: 2.6359778450381373

Epoch: 5| Step: 7
Training loss: 2.8444302082061768
Validation loss: 2.627542100926881

Epoch: 5| Step: 8
Training loss: 2.7395451068878174
Validation loss: 2.6271929715269353

Epoch: 5| Step: 9
Training loss: 2.289013624191284
Validation loss: 2.6298028679304224

Epoch: 5| Step: 10
Training loss: 2.530263900756836
Validation loss: 2.6342210513289257

Epoch: 89| Step: 0
Training loss: 2.995512008666992
Validation loss: 2.6367593657585884

Epoch: 5| Step: 1
Training loss: 2.153857469558716
Validation loss: 2.64066404937416

Epoch: 5| Step: 2
Training loss: 3.573773145675659
Validation loss: 2.645272034470753

Epoch: 5| Step: 3
Training loss: 2.3544576168060303
Validation loss: 2.638165061191846

Epoch: 5| Step: 4
Training loss: 3.1977860927581787
Validation loss: 2.635684774767968

Epoch: 5| Step: 5
Training loss: 3.038595676422119
Validation loss: 2.6327677695981917

Epoch: 5| Step: 6
Training loss: 2.8888864517211914
Validation loss: 2.6291309377198577

Epoch: 5| Step: 7
Training loss: 3.0278713703155518
Validation loss: 2.626703655847939

Epoch: 5| Step: 8
Training loss: 2.6367709636688232
Validation loss: 2.622054487146357

Epoch: 5| Step: 9
Training loss: 1.8178774118423462
Validation loss: 2.6241282365655385

Epoch: 5| Step: 10
Training loss: 3.0869083404541016
Validation loss: 2.6230411452631794

Epoch: 90| Step: 0
Training loss: 3.593799114227295
Validation loss: 2.625449247257684

Epoch: 5| Step: 1
Training loss: 2.8295700550079346
Validation loss: 2.6235402322584584

Epoch: 5| Step: 2
Training loss: 2.5682454109191895
Validation loss: 2.6317117265475694

Epoch: 5| Step: 3
Training loss: 2.5802435874938965
Validation loss: 2.640092111402942

Epoch: 5| Step: 4
Training loss: 3.120683193206787
Validation loss: 2.65316024134236

Epoch: 5| Step: 5
Training loss: 2.217021942138672
Validation loss: 2.6508766297371156

Epoch: 5| Step: 6
Training loss: 3.2410290241241455
Validation loss: 2.6411471084881852

Epoch: 5| Step: 7
Training loss: 2.3857522010803223
Validation loss: 2.636503763096307

Epoch: 5| Step: 8
Training loss: 3.138112783432007
Validation loss: 2.6330329910401375

Epoch: 5| Step: 9
Training loss: 2.744438648223877
Validation loss: 2.6303736240633073

Epoch: 5| Step: 10
Training loss: 2.0099565982818604
Validation loss: 2.625331186479138

Epoch: 91| Step: 0
Training loss: 3.115748643875122
Validation loss: 2.621419668197632

Epoch: 5| Step: 1
Training loss: 2.902956247329712
Validation loss: 2.6214051400461504

Epoch: 5| Step: 2
Training loss: 3.293041944503784
Validation loss: 2.6200791405093287

Epoch: 5| Step: 3
Training loss: 2.827659845352173
Validation loss: 2.6187718786219114

Epoch: 5| Step: 4
Training loss: 2.5553030967712402
Validation loss: 2.619524630167151

Epoch: 5| Step: 5
Training loss: 2.2385482788085938
Validation loss: 2.6206500017514793

Epoch: 5| Step: 6
Training loss: 2.7652556896209717
Validation loss: 2.6188484981495845

Epoch: 5| Step: 7
Training loss: 2.8227972984313965
Validation loss: 2.6208870667283253

Epoch: 5| Step: 8
Training loss: 2.6277809143066406
Validation loss: 2.6230293140616467

Epoch: 5| Step: 9
Training loss: 2.8459553718566895
Validation loss: 2.6227368975198395

Epoch: 5| Step: 10
Training loss: 2.4531028270721436
Validation loss: 2.6211840721868698

Epoch: 92| Step: 0
Training loss: 2.599199056625366
Validation loss: 2.6220116922932286

Epoch: 5| Step: 1
Training loss: 2.6013312339782715
Validation loss: 2.621105294073782

Epoch: 5| Step: 2
Training loss: 3.4128479957580566
Validation loss: 2.624148517526606

Epoch: 5| Step: 3
Training loss: 2.8048527240753174
Validation loss: 2.6236200794096916

Epoch: 5| Step: 4
Training loss: 2.68056058883667
Validation loss: 2.629459096539405

Epoch: 5| Step: 5
Training loss: 2.6942429542541504
Validation loss: 2.6233803918284755

Epoch: 5| Step: 6
Training loss: 2.388479471206665
Validation loss: 2.622910745682255

Epoch: 5| Step: 7
Training loss: 3.165004253387451
Validation loss: 2.620366393878896

Epoch: 5| Step: 8
Training loss: 3.0708117485046387
Validation loss: 2.619811106753606

Epoch: 5| Step: 9
Training loss: 2.888493776321411
Validation loss: 2.621588158351119

Epoch: 5| Step: 10
Training loss: 2.0704848766326904
Validation loss: 2.6189405661757275

Epoch: 93| Step: 0
Training loss: 3.1027369499206543
Validation loss: 2.6118814458129225

Epoch: 5| Step: 1
Training loss: 3.121744155883789
Validation loss: 2.6149903035932973

Epoch: 5| Step: 2
Training loss: 3.223984956741333
Validation loss: 2.6175920604377665

Epoch: 5| Step: 3
Training loss: 1.325109839439392
Validation loss: 2.6093640173635175

Epoch: 5| Step: 4
Training loss: 3.1559295654296875
Validation loss: 2.6108254335259877

Epoch: 5| Step: 5
Training loss: 2.693199634552002
Validation loss: 2.607996820121683

Epoch: 5| Step: 6
Training loss: 2.7851622104644775
Validation loss: 2.613270426309237

Epoch: 5| Step: 7
Training loss: 3.3041739463806152
Validation loss: 2.6124674761167137

Epoch: 5| Step: 8
Training loss: 2.8448383808135986
Validation loss: 2.6089591928707656

Epoch: 5| Step: 9
Training loss: 2.3699162006378174
Validation loss: 2.609060290039227

Epoch: 5| Step: 10
Training loss: 2.438251256942749
Validation loss: 2.605534848346505

Epoch: 94| Step: 0
Training loss: 2.2031712532043457
Validation loss: 2.6030121003427813

Epoch: 5| Step: 1
Training loss: 3.076101303100586
Validation loss: 2.6025730384293424

Epoch: 5| Step: 2
Training loss: 2.606510639190674
Validation loss: 2.608898211550969

Epoch: 5| Step: 3
Training loss: 2.622313976287842
Validation loss: 2.6146002559251684

Epoch: 5| Step: 4
Training loss: 3.2867889404296875
Validation loss: 2.621630983967935

Epoch: 5| Step: 5
Training loss: 2.147124767303467
Validation loss: 2.622654248309392

Epoch: 5| Step: 6
Training loss: 3.2476322650909424
Validation loss: 2.6222350905018468

Epoch: 5| Step: 7
Training loss: 3.28448486328125
Validation loss: 2.6241938990931355

Epoch: 5| Step: 8
Training loss: 2.480741262435913
Validation loss: 2.6198044387243127

Epoch: 5| Step: 9
Training loss: 2.78839373588562
Validation loss: 2.621838446586363

Epoch: 5| Step: 10
Training loss: 2.6712169647216797
Validation loss: 2.630136546268258

Epoch: 95| Step: 0
Training loss: 2.1199655532836914
Validation loss: 2.665281903359198

Epoch: 5| Step: 1
Training loss: 2.82993745803833
Validation loss: 2.705352916512438

Epoch: 5| Step: 2
Training loss: 2.697972059249878
Validation loss: 2.7222203772555114

Epoch: 5| Step: 3
Training loss: 2.279973268508911
Validation loss: 2.722117293265558

Epoch: 5| Step: 4
Training loss: 2.4460971355438232
Validation loss: 2.7302761770063833

Epoch: 5| Step: 5
Training loss: 3.742279529571533
Validation loss: 2.7302115809532905

Epoch: 5| Step: 6
Training loss: 2.98935866355896
Validation loss: 2.7148009628377934

Epoch: 5| Step: 7
Training loss: 3.089158773422241
Validation loss: 2.7128139798359205

Epoch: 5| Step: 8
Training loss: 3.1089727878570557
Validation loss: 2.697067186396609

Epoch: 5| Step: 9
Training loss: 2.5671234130859375
Validation loss: 2.6872050582721667

Epoch: 5| Step: 10
Training loss: 3.206681728363037
Validation loss: 2.6857239020768033

Epoch: 96| Step: 0
Training loss: 2.815195322036743
Validation loss: 2.6754760075640935

Epoch: 5| Step: 1
Training loss: 2.2518932819366455
Validation loss: 2.6532375812530518

Epoch: 5| Step: 2
Training loss: 2.9198520183563232
Validation loss: 2.627453860416207

Epoch: 5| Step: 3
Training loss: 2.566124439239502
Validation loss: 2.649964096725628

Epoch: 5| Step: 4
Training loss: 3.195734739303589
Validation loss: 2.7236739589321997

Epoch: 5| Step: 5
Training loss: 3.2157325744628906
Validation loss: 2.7108525050583707

Epoch: 5| Step: 6
Training loss: 2.510925769805908
Validation loss: 2.654015000148486

Epoch: 5| Step: 7
Training loss: 2.0973682403564453
Validation loss: 2.6331643724954255

Epoch: 5| Step: 8
Training loss: 3.651559352874756
Validation loss: 2.6104074062839633

Epoch: 5| Step: 9
Training loss: 2.8035459518432617
Validation loss: 2.6019254448593303

Epoch: 5| Step: 10
Training loss: 2.6797945499420166
Validation loss: 2.594616436189221

Epoch: 97| Step: 0
Training loss: 2.740729570388794
Validation loss: 2.597542337192002

Epoch: 5| Step: 1
Training loss: 3.109964370727539
Validation loss: 2.6086293933212117

Epoch: 5| Step: 2
Training loss: 2.8214194774627686
Validation loss: 2.6197242916271253

Epoch: 5| Step: 3
Training loss: 3.1133909225463867
Validation loss: 2.6284534187727076

Epoch: 5| Step: 4
Training loss: 2.8331708908081055
Validation loss: 2.6427540394567672

Epoch: 5| Step: 5
Training loss: 2.5505127906799316
Validation loss: 2.6483697737416914

Epoch: 5| Step: 6
Training loss: 2.1988091468811035
Validation loss: 2.6584960337608092

Epoch: 5| Step: 7
Training loss: 3.1504573822021484
Validation loss: 2.6368881938278035

Epoch: 5| Step: 8
Training loss: 2.724480152130127
Validation loss: 2.6170871334691204

Epoch: 5| Step: 9
Training loss: 2.6249210834503174
Validation loss: 2.604966507163099

Epoch: 5| Step: 10
Training loss: 2.7286903858184814
Validation loss: 2.592028115385322

Epoch: 98| Step: 0
Training loss: 2.916250228881836
Validation loss: 2.587721901555215

Epoch: 5| Step: 1
Training loss: 3.449885129928589
Validation loss: 2.5894782517545964

Epoch: 5| Step: 2
Training loss: 3.0077853202819824
Validation loss: 2.585888542154784

Epoch: 5| Step: 3
Training loss: 1.881870985031128
Validation loss: 2.5872815860215055

Epoch: 5| Step: 4
Training loss: 3.270371198654175
Validation loss: 2.5881353885896745

Epoch: 5| Step: 5
Training loss: 2.140397548675537
Validation loss: 2.586929626362298

Epoch: 5| Step: 6
Training loss: 2.0870606899261475
Validation loss: 2.5883832157299085

Epoch: 5| Step: 7
Training loss: 3.282029628753662
Validation loss: 2.5870660120441067

Epoch: 5| Step: 8
Training loss: 2.7571370601654053
Validation loss: 2.5890968999555035

Epoch: 5| Step: 9
Training loss: 2.64851713180542
Validation loss: 2.5926397961954915

Epoch: 5| Step: 10
Training loss: 2.9497103691101074
Validation loss: 2.6010238150114655

Epoch: 99| Step: 0
Training loss: 1.920835256576538
Validation loss: 2.5965868093634166

Epoch: 5| Step: 1
Training loss: 3.230149745941162
Validation loss: 2.6003673794449016

Epoch: 5| Step: 2
Training loss: 2.964200973510742
Validation loss: 2.5986300181317072

Epoch: 5| Step: 3
Training loss: 2.4816737174987793
Validation loss: 2.5945574134908695

Epoch: 5| Step: 4
Training loss: 3.1297221183776855
Validation loss: 2.5994877866519395

Epoch: 5| Step: 5
Training loss: 2.402103900909424
Validation loss: 2.585131291420229

Epoch: 5| Step: 6
Training loss: 2.8552443981170654
Validation loss: 2.5854353981633342

Epoch: 5| Step: 7
Training loss: 2.8755545616149902
Validation loss: 2.580701010201567

Epoch: 5| Step: 8
Training loss: 3.106379985809326
Validation loss: 2.582180984558598

Epoch: 5| Step: 9
Training loss: 2.9684996604919434
Validation loss: 2.5803873538970947

Epoch: 5| Step: 10
Training loss: 2.278608798980713
Validation loss: 2.582375334155175

Epoch: 100| Step: 0
Training loss: 2.230438709259033
Validation loss: 2.5809166162244734

Epoch: 5| Step: 1
Training loss: 2.5646328926086426
Validation loss: 2.5821957049831266

Epoch: 5| Step: 2
Training loss: 2.576310634613037
Validation loss: 2.5848501677154214

Epoch: 5| Step: 3
Training loss: 2.6725144386291504
Validation loss: 2.5860540225941646

Epoch: 5| Step: 4
Training loss: 3.0089504718780518
Validation loss: 2.585181846413561

Epoch: 5| Step: 5
Training loss: 2.494584798812866
Validation loss: 2.5793848063356135

Epoch: 5| Step: 6
Training loss: 3.0155460834503174
Validation loss: 2.577660042752502

Epoch: 5| Step: 7
Training loss: 3.369546890258789
Validation loss: 2.5772268259397118

Epoch: 5| Step: 8
Training loss: 2.5457406044006348
Validation loss: 2.5760731184354393

Epoch: 5| Step: 9
Training loss: 2.6366138458251953
Validation loss: 2.5763684524002897

Epoch: 5| Step: 10
Training loss: 3.2604386806488037
Validation loss: 2.5768352708508893

Epoch: 101| Step: 0
Training loss: 2.6482462882995605
Validation loss: 2.580281485793411

Epoch: 5| Step: 1
Training loss: 2.652376890182495
Validation loss: 2.577961629436862

Epoch: 5| Step: 2
Training loss: 2.6524364948272705
Validation loss: 2.575321284673547

Epoch: 5| Step: 3
Training loss: 2.9738872051239014
Validation loss: 2.5791910797037105

Epoch: 5| Step: 4
Training loss: 2.9706661701202393
Validation loss: 2.575942195871825

Epoch: 5| Step: 5
Training loss: 2.530890464782715
Validation loss: 2.575468050536289

Epoch: 5| Step: 6
Training loss: 3.01997709274292
Validation loss: 2.574834623644429

Epoch: 5| Step: 7
Training loss: 2.6556546688079834
Validation loss: 2.5794474309490574

Epoch: 5| Step: 8
Training loss: 2.0368738174438477
Validation loss: 2.5730665781164683

Epoch: 5| Step: 9
Training loss: 2.8399605751037598
Validation loss: 2.575576146443685

Epoch: 5| Step: 10
Training loss: 3.261415481567383
Validation loss: 2.570812589378767

Epoch: 102| Step: 0
Training loss: 3.481703519821167
Validation loss: 2.576612026460709

Epoch: 5| Step: 1
Training loss: 2.896522045135498
Validation loss: 2.5738933445304952

Epoch: 5| Step: 2
Training loss: 2.183096408843994
Validation loss: 2.5712357028838126

Epoch: 5| Step: 3
Training loss: 2.938100814819336
Validation loss: 2.5715633566661547

Epoch: 5| Step: 4
Training loss: 2.754859209060669
Validation loss: 2.5684696602564987

Epoch: 5| Step: 5
Training loss: 1.9228404760360718
Validation loss: 2.5694024127016784

Epoch: 5| Step: 6
Training loss: 3.176872491836548
Validation loss: 2.571061231756723

Epoch: 5| Step: 7
Training loss: 2.1277174949645996
Validation loss: 2.5675532561476513

Epoch: 5| Step: 8
Training loss: 2.907315492630005
Validation loss: 2.56825590133667

Epoch: 5| Step: 9
Training loss: 2.5941290855407715
Validation loss: 2.5704560126027753

Epoch: 5| Step: 10
Training loss: 3.165470600128174
Validation loss: 2.568778504607498

Epoch: 103| Step: 0
Training loss: 2.5756406784057617
Validation loss: 2.568199578151908

Epoch: 5| Step: 1
Training loss: 2.754760265350342
Validation loss: 2.5684188668445875

Epoch: 5| Step: 2
Training loss: 2.0066866874694824
Validation loss: 2.567290444527903

Epoch: 5| Step: 3
Training loss: 2.7143394947052
Validation loss: 2.5672039524201424

Epoch: 5| Step: 4
Training loss: 3.139200210571289
Validation loss: 2.5683360112610685

Epoch: 5| Step: 5
Training loss: 3.0370001792907715
Validation loss: 2.56715033131261

Epoch: 5| Step: 6
Training loss: 3.272146701812744
Validation loss: 2.5655422364511797

Epoch: 5| Step: 7
Training loss: 3.1699821949005127
Validation loss: 2.5625743532693512

Epoch: 5| Step: 8
Training loss: 2.9682564735412598
Validation loss: 2.564705692311769

Epoch: 5| Step: 9
Training loss: 1.9686458110809326
Validation loss: 2.560374290712418

Epoch: 5| Step: 10
Training loss: 2.4228475093841553
Validation loss: 2.56014577034981

Epoch: 104| Step: 0
Training loss: 3.835604190826416
Validation loss: 2.558780336892733

Epoch: 5| Step: 1
Training loss: 2.6404590606689453
Validation loss: 2.5589590021359023

Epoch: 5| Step: 2
Training loss: 2.6056504249572754
Validation loss: 2.5584616379071305

Epoch: 5| Step: 3
Training loss: 2.719376564025879
Validation loss: 2.5590729559621503

Epoch: 5| Step: 4
Training loss: 2.8068745136260986
Validation loss: 2.5584939551609818

Epoch: 5| Step: 5
Training loss: 2.4573044776916504
Validation loss: 2.561132046484178

Epoch: 5| Step: 6
Training loss: 2.7207882404327393
Validation loss: 2.5593256053104194

Epoch: 5| Step: 7
Training loss: 2.401021957397461
Validation loss: 2.556624074136057

Epoch: 5| Step: 8
Training loss: 2.303642749786377
Validation loss: 2.5568876163933867

Epoch: 5| Step: 9
Training loss: 2.653876781463623
Validation loss: 2.5605652511760755

Epoch: 5| Step: 10
Training loss: 2.9111785888671875
Validation loss: 2.5577119934943413

Epoch: 105| Step: 0
Training loss: 2.714324712753296
Validation loss: 2.56804851050018

Epoch: 5| Step: 1
Training loss: 2.3474972248077393
Validation loss: 2.566319819419615

Epoch: 5| Step: 2
Training loss: 2.835568904876709
Validation loss: 2.56825836243168

Epoch: 5| Step: 3
Training loss: 2.9796602725982666
Validation loss: 2.5732554902312574

Epoch: 5| Step: 4
Training loss: 2.0954387187957764
Validation loss: 2.5728199738328175

Epoch: 5| Step: 5
Training loss: 2.8431034088134766
Validation loss: 2.5682291138556694

Epoch: 5| Step: 6
Training loss: 3.144479274749756
Validation loss: 2.5659270414742092

Epoch: 5| Step: 7
Training loss: 2.944392681121826
Validation loss: 2.562297821044922

Epoch: 5| Step: 8
Training loss: 3.45295786857605
Validation loss: 2.562895069840134

Epoch: 5| Step: 9
Training loss: 2.5786027908325195
Validation loss: 2.559131460805093

Epoch: 5| Step: 10
Training loss: 1.9899471998214722
Validation loss: 2.5644755927465295

Epoch: 106| Step: 0
Training loss: 2.3919949531555176
Validation loss: 2.5643305368320917

Epoch: 5| Step: 1
Training loss: 3.0281026363372803
Validation loss: 2.5600200904312955

Epoch: 5| Step: 2
Training loss: 3.158093214035034
Validation loss: 2.5569642333574194

Epoch: 5| Step: 3
Training loss: 2.470822811126709
Validation loss: 2.555718283499441

Epoch: 5| Step: 4
Training loss: 2.8656411170959473
Validation loss: 2.551385223224599

Epoch: 5| Step: 5
Training loss: 2.973808765411377
Validation loss: 2.550659757788463

Epoch: 5| Step: 6
Training loss: 2.4931111335754395
Validation loss: 2.552341407345187

Epoch: 5| Step: 7
Training loss: 2.8475310802459717
Validation loss: 2.55043811439186

Epoch: 5| Step: 8
Training loss: 2.4827966690063477
Validation loss: 2.5473910044598322

Epoch: 5| Step: 9
Training loss: 2.6758084297180176
Validation loss: 2.5459149396547707

Epoch: 5| Step: 10
Training loss: 2.5671887397766113
Validation loss: 2.5495558451580744

Epoch: 107| Step: 0
Training loss: 2.3165178298950195
Validation loss: 2.5477110262840026

Epoch: 5| Step: 1
Training loss: 2.597698926925659
Validation loss: 2.5504188050505934

Epoch: 5| Step: 2
Training loss: 2.789926052093506
Validation loss: 2.5471734769882692

Epoch: 5| Step: 3
Training loss: 2.7527079582214355
Validation loss: 2.549603718583302

Epoch: 5| Step: 4
Training loss: 3.069908857345581
Validation loss: 2.548722328678254

Epoch: 5| Step: 5
Training loss: 3.159156322479248
Validation loss: 2.5467799120051886

Epoch: 5| Step: 6
Training loss: 2.8557615280151367
Validation loss: 2.5468449438771894

Epoch: 5| Step: 7
Training loss: 2.9305615425109863
Validation loss: 2.548026374591294

Epoch: 5| Step: 8
Training loss: 2.7252683639526367
Validation loss: 2.5468619997783373

Epoch: 5| Step: 9
Training loss: 2.566197633743286
Validation loss: 2.5467268933532057

Epoch: 5| Step: 10
Training loss: 2.042224645614624
Validation loss: 2.5484749424842095

Epoch: 108| Step: 0
Training loss: 2.863755941390991
Validation loss: 2.544940133248606

Epoch: 5| Step: 1
Training loss: 2.500415563583374
Validation loss: 2.5425255913888254

Epoch: 5| Step: 2
Training loss: 3.5859317779541016
Validation loss: 2.5434794425964355

Epoch: 5| Step: 3
Training loss: 2.4600601196289062
Validation loss: 2.544120055372997

Epoch: 5| Step: 4
Training loss: 2.805802583694458
Validation loss: 2.544654651354718

Epoch: 5| Step: 5
Training loss: 3.0069735050201416
Validation loss: 2.547844720143144

Epoch: 5| Step: 6
Training loss: 2.4229087829589844
Validation loss: 2.5484708111773253

Epoch: 5| Step: 7
Training loss: 2.8753514289855957
Validation loss: 2.5469470793201077

Epoch: 5| Step: 8
Training loss: 2.9922189712524414
Validation loss: 2.5447845817894064

Epoch: 5| Step: 9
Training loss: 1.6104285717010498
Validation loss: 2.54941419119476

Epoch: 5| Step: 10
Training loss: 2.8326189517974854
Validation loss: 2.5683071356947704

Epoch: 109| Step: 0
Training loss: 2.0309901237487793
Validation loss: 2.590061059562109

Epoch: 5| Step: 1
Training loss: 2.709967851638794
Validation loss: 2.616589343676003

Epoch: 5| Step: 2
Training loss: 3.094710350036621
Validation loss: 2.645459134091613

Epoch: 5| Step: 3
Training loss: 2.8298020362854004
Validation loss: 2.678997652505034

Epoch: 5| Step: 4
Training loss: 2.135457992553711
Validation loss: 2.689067881594422

Epoch: 5| Step: 5
Training loss: 3.0143685340881348
Validation loss: 2.641832656757806

Epoch: 5| Step: 6
Training loss: 3.116919994354248
Validation loss: 2.6163845728802424

Epoch: 5| Step: 7
Training loss: 3.164858341217041
Validation loss: 2.6099196967258247

Epoch: 5| Step: 8
Training loss: 3.1876301765441895
Validation loss: 2.602462068680794

Epoch: 5| Step: 9
Training loss: 2.5373282432556152
Validation loss: 2.5974699630532214

Epoch: 5| Step: 10
Training loss: 2.7726080417633057
Validation loss: 2.5873969319046184

Epoch: 110| Step: 0
Training loss: 2.4151618480682373
Validation loss: 2.5629948544245895

Epoch: 5| Step: 1
Training loss: 2.4254114627838135
Validation loss: 2.548847726596299

Epoch: 5| Step: 2
Training loss: 2.5997135639190674
Validation loss: 2.5531147782520582

Epoch: 5| Step: 3
Training loss: 3.2838962078094482
Validation loss: 2.5628019584122526

Epoch: 5| Step: 4
Training loss: 2.9070000648498535
Validation loss: 2.5647280728945168

Epoch: 5| Step: 5
Training loss: 2.891235828399658
Validation loss: 2.562904598892376

Epoch: 5| Step: 6
Training loss: 2.47442889213562
Validation loss: 2.558436365537746

Epoch: 5| Step: 7
Training loss: 2.901427745819092
Validation loss: 2.555007016786965

Epoch: 5| Step: 8
Training loss: 2.8240742683410645
Validation loss: 2.5475555414794595

Epoch: 5| Step: 9
Training loss: 2.3321354389190674
Validation loss: 2.5449220185638755

Epoch: 5| Step: 10
Training loss: 3.084749221801758
Validation loss: 2.539050163761262

Epoch: 111| Step: 0
Training loss: 2.638338088989258
Validation loss: 2.5393402217536845

Epoch: 5| Step: 1
Training loss: 2.5669312477111816
Validation loss: 2.5347261967197543

Epoch: 5| Step: 2
Training loss: 2.428919553756714
Validation loss: 2.537387091626403

Epoch: 5| Step: 3
Training loss: 2.939438819885254
Validation loss: 2.537300463645689

Epoch: 5| Step: 4
Training loss: 2.486146926879883
Validation loss: 2.539362689500214

Epoch: 5| Step: 5
Training loss: 3.080568552017212
Validation loss: 2.538740127317367

Epoch: 5| Step: 6
Training loss: 2.596417188644409
Validation loss: 2.5399761097405547

Epoch: 5| Step: 7
Training loss: 3.044799327850342
Validation loss: 2.5400248804400043

Epoch: 5| Step: 8
Training loss: 2.6051619052886963
Validation loss: 2.5443196142873457

Epoch: 5| Step: 9
Training loss: 3.199709415435791
Validation loss: 2.5419506257580173

Epoch: 5| Step: 10
Training loss: 2.236459732055664
Validation loss: 2.54007347296643

Epoch: 112| Step: 0
Training loss: 3.120530366897583
Validation loss: 2.537525346202235

Epoch: 5| Step: 1
Training loss: 2.819061040878296
Validation loss: 2.540210254730717

Epoch: 5| Step: 2
Training loss: 3.011267900466919
Validation loss: 2.535827480336671

Epoch: 5| Step: 3
Training loss: 2.867286205291748
Validation loss: 2.530310191133971

Epoch: 5| Step: 4
Training loss: 2.405604839324951
Validation loss: 2.5327027587480444

Epoch: 5| Step: 5
Training loss: 2.5267961025238037
Validation loss: 2.528634273877708

Epoch: 5| Step: 6
Training loss: 2.5886058807373047
Validation loss: 2.5316715317387737

Epoch: 5| Step: 7
Training loss: 2.4733211994171143
Validation loss: 2.53146614310562

Epoch: 5| Step: 8
Training loss: 2.4097626209259033
Validation loss: 2.53151221300966

Epoch: 5| Step: 9
Training loss: 3.2155563831329346
Validation loss: 2.528046149079518

Epoch: 5| Step: 10
Training loss: 2.375217914581299
Validation loss: 2.5280952056248984

Epoch: 113| Step: 0
Training loss: 1.89621901512146
Validation loss: 2.5260619296822497

Epoch: 5| Step: 1
Training loss: 2.949759006500244
Validation loss: 2.5302204085934545

Epoch: 5| Step: 2
Training loss: 3.441455125808716
Validation loss: 2.5279544015084543

Epoch: 5| Step: 3
Training loss: 2.420173168182373
Validation loss: 2.5262039348643315

Epoch: 5| Step: 4
Training loss: 3.3919448852539062
Validation loss: 2.5285253960599183

Epoch: 5| Step: 5
Training loss: 2.1959495544433594
Validation loss: 2.526196713088661

Epoch: 5| Step: 6
Training loss: 2.5734355449676514
Validation loss: 2.5296388236425256

Epoch: 5| Step: 7
Training loss: 2.7791693210601807
Validation loss: 2.528213788104314

Epoch: 5| Step: 8
Training loss: 2.7544503211975098
Validation loss: 2.5273506333751063

Epoch: 5| Step: 9
Training loss: 2.7090275287628174
Validation loss: 2.531050617976855

Epoch: 5| Step: 10
Training loss: 2.6830203533172607
Validation loss: 2.5271644976831253

Epoch: 114| Step: 0
Training loss: 2.9202256202697754
Validation loss: 2.5288321433528775

Epoch: 5| Step: 1
Training loss: 3.086904287338257
Validation loss: 2.532376532913536

Epoch: 5| Step: 2
Training loss: 2.7855827808380127
Validation loss: 2.534174216690884

Epoch: 5| Step: 3
Training loss: 1.8109071254730225
Validation loss: 2.5343930670010146

Epoch: 5| Step: 4
Training loss: 3.0448384284973145
Validation loss: 2.536857747262524

Epoch: 5| Step: 5
Training loss: 3.0961410999298096
Validation loss: 2.53521942323254

Epoch: 5| Step: 6
Training loss: 2.592958450317383
Validation loss: 2.5323010465150237

Epoch: 5| Step: 7
Training loss: 3.131472110748291
Validation loss: 2.530787967866467

Epoch: 5| Step: 8
Training loss: 1.9496101140975952
Validation loss: 2.5383002014570337

Epoch: 5| Step: 9
Training loss: 2.6139678955078125
Validation loss: 2.537336064923194

Epoch: 5| Step: 10
Training loss: 2.7723464965820312
Validation loss: 2.5318232197915354

Epoch: 115| Step: 0
Training loss: 3.0858588218688965
Validation loss: 2.5255050761725313

Epoch: 5| Step: 1
Training loss: 3.0305819511413574
Validation loss: 2.528486536395165

Epoch: 5| Step: 2
Training loss: 2.934790849685669
Validation loss: 2.520634297401674

Epoch: 5| Step: 3
Training loss: 2.38212251663208
Validation loss: 2.5183537083287395

Epoch: 5| Step: 4
Training loss: 3.167703866958618
Validation loss: 2.5187243415463354

Epoch: 5| Step: 5
Training loss: 2.011082172393799
Validation loss: 2.518779093219388

Epoch: 5| Step: 6
Training loss: 2.6208949089050293
Validation loss: 2.5165616158516175

Epoch: 5| Step: 7
Training loss: 3.132059097290039
Validation loss: 2.5179498810921945

Epoch: 5| Step: 8
Training loss: 2.068570137023926
Validation loss: 2.5192167605123212

Epoch: 5| Step: 9
Training loss: 2.797132968902588
Validation loss: 2.5145063759178243

Epoch: 5| Step: 10
Training loss: 2.4832165241241455
Validation loss: 2.5159329163130892

Epoch: 116| Step: 0
Training loss: 2.1556448936462402
Validation loss: 2.5138047254213722

Epoch: 5| Step: 1
Training loss: 2.763798236846924
Validation loss: 2.517656657003587

Epoch: 5| Step: 2
Training loss: 2.6697423458099365
Validation loss: 2.5187368572399182

Epoch: 5| Step: 3
Training loss: 2.4591360092163086
Validation loss: 2.516637004831786

Epoch: 5| Step: 4
Training loss: 2.9220077991485596
Validation loss: 2.5192574608710503

Epoch: 5| Step: 5
Training loss: 2.810990810394287
Validation loss: 2.522163462895219

Epoch: 5| Step: 6
Training loss: 2.286038398742676
Validation loss: 2.5189536284374934

Epoch: 5| Step: 7
Training loss: 2.8200008869171143
Validation loss: 2.522945216906968

Epoch: 5| Step: 8
Training loss: 3.4819564819335938
Validation loss: 2.52001791872004

Epoch: 5| Step: 9
Training loss: 2.7434375286102295
Validation loss: 2.520465768793578

Epoch: 5| Step: 10
Training loss: 2.5838820934295654
Validation loss: 2.5191941543291976

Epoch: 117| Step: 0
Training loss: 3.21112060546875
Validation loss: 2.517573633501607

Epoch: 5| Step: 1
Training loss: 2.621091365814209
Validation loss: 2.517316851564633

Epoch: 5| Step: 2
Training loss: 3.063295602798462
Validation loss: 2.518023262741745

Epoch: 5| Step: 3
Training loss: 2.893437147140503
Validation loss: 2.517361307656893

Epoch: 5| Step: 4
Training loss: 2.0972518920898438
Validation loss: 2.5167326183729273

Epoch: 5| Step: 5
Training loss: 3.003788471221924
Validation loss: 2.5144281079692226

Epoch: 5| Step: 6
Training loss: 2.1109681129455566
Validation loss: 2.511916455402169

Epoch: 5| Step: 7
Training loss: 2.999311923980713
Validation loss: 2.514005644347078

Epoch: 5| Step: 8
Training loss: 2.8647961616516113
Validation loss: 2.514013995406448

Epoch: 5| Step: 9
Training loss: 2.577261447906494
Validation loss: 2.5131133102601573

Epoch: 5| Step: 10
Training loss: 2.1679821014404297
Validation loss: 2.511675214254728

Epoch: 118| Step: 0
Training loss: 2.4004733562469482
Validation loss: 2.5192901780528407

Epoch: 5| Step: 1
Training loss: 3.479386568069458
Validation loss: 2.528590048513105

Epoch: 5| Step: 2
Training loss: 2.733161449432373
Validation loss: 2.5314688374919276

Epoch: 5| Step: 3
Training loss: 2.899928092956543
Validation loss: 2.5429717571504655

Epoch: 5| Step: 4
Training loss: 2.4930882453918457
Validation loss: 2.5407109593832367

Epoch: 5| Step: 5
Training loss: 2.3955726623535156
Validation loss: 2.5393964808474303

Epoch: 5| Step: 6
Training loss: 3.27809476852417
Validation loss: 2.533212359233569

Epoch: 5| Step: 7
Training loss: 2.2878243923187256
Validation loss: 2.524571677689911

Epoch: 5| Step: 8
Training loss: 2.6999592781066895
Validation loss: 2.515000069013206

Epoch: 5| Step: 9
Training loss: 2.11185884475708
Validation loss: 2.5098463694254556

Epoch: 5| Step: 10
Training loss: 3.1229569911956787
Validation loss: 2.5088658640461583

Epoch: 119| Step: 0
Training loss: 2.2549922466278076
Validation loss: 2.5079545180002847

Epoch: 5| Step: 1
Training loss: 2.6821072101593018
Validation loss: 2.511427781915152

Epoch: 5| Step: 2
Training loss: 1.9487098455429077
Validation loss: 2.5072662061260593

Epoch: 5| Step: 3
Training loss: 2.569347620010376
Validation loss: 2.505229103949762

Epoch: 5| Step: 4
Training loss: 2.8726072311401367
Validation loss: 2.5071010974145707

Epoch: 5| Step: 5
Training loss: 2.8759989738464355
Validation loss: 2.5087517000013784

Epoch: 5| Step: 6
Training loss: 2.7635092735290527
Validation loss: 2.5094629154410413

Epoch: 5| Step: 7
Training loss: 2.8547587394714355
Validation loss: 2.503633206890475

Epoch: 5| Step: 8
Training loss: 2.5326952934265137
Validation loss: 2.503696426268547

Epoch: 5| Step: 9
Training loss: 3.4695167541503906
Validation loss: 2.5036450201465237

Epoch: 5| Step: 10
Training loss: 3.0209834575653076
Validation loss: 2.503358297450568

Epoch: 120| Step: 0
Training loss: 2.7538113594055176
Validation loss: 2.4985129346129713

Epoch: 5| Step: 1
Training loss: 2.5293545722961426
Validation loss: 2.5009406817856656

Epoch: 5| Step: 2
Training loss: 2.1797935962677
Validation loss: 2.4964919167180217

Epoch: 5| Step: 3
Training loss: 1.9044901132583618
Validation loss: 2.500876219041886

Epoch: 5| Step: 4
Training loss: 3.3454978466033936
Validation loss: 2.506073154428954

Epoch: 5| Step: 5
Training loss: 2.311506986618042
Validation loss: 2.510118874170447

Epoch: 5| Step: 6
Training loss: 2.9857475757598877
Validation loss: 2.5152450428214124

Epoch: 5| Step: 7
Training loss: 2.7176437377929688
Validation loss: 2.5269902649746148

Epoch: 5| Step: 8
Training loss: 3.266704559326172
Validation loss: 2.5374716994582966

Epoch: 5| Step: 9
Training loss: 3.0088648796081543
Validation loss: 2.547875537667223

Epoch: 5| Step: 10
Training loss: 2.759220600128174
Validation loss: 2.553309327812605

Epoch: 121| Step: 0
Training loss: 2.248553514480591
Validation loss: 2.552512522666685

Epoch: 5| Step: 1
Training loss: 3.0369009971618652
Validation loss: 2.555527235872002

Epoch: 5| Step: 2
Training loss: 3.169313669204712
Validation loss: 2.558692765492265

Epoch: 5| Step: 3
Training loss: 3.0676987171173096
Validation loss: 2.5434128135763188

Epoch: 5| Step: 4
Training loss: 2.971137523651123
Validation loss: 2.548230871077507

Epoch: 5| Step: 5
Training loss: 2.4229202270507812
Validation loss: 2.5382491414264967

Epoch: 5| Step: 6
Training loss: 2.9694526195526123
Validation loss: 2.5333344808188816

Epoch: 5| Step: 7
Training loss: 2.201887607574463
Validation loss: 2.5254189429744596

Epoch: 5| Step: 8
Training loss: 2.965801239013672
Validation loss: 2.5153402820710213

Epoch: 5| Step: 9
Training loss: 2.6269426345825195
Validation loss: 2.5085953807318084

Epoch: 5| Step: 10
Training loss: 2.0554065704345703
Validation loss: 2.4996746586215113

Epoch: 122| Step: 0
Training loss: 2.5182063579559326
Validation loss: 2.4969192345937095

Epoch: 5| Step: 1
Training loss: 2.960228204727173
Validation loss: 2.4962351732356574

Epoch: 5| Step: 2
Training loss: 3.117009162902832
Validation loss: 2.4947318953852498

Epoch: 5| Step: 3
Training loss: 2.5165858268737793
Validation loss: 2.4984204640952488

Epoch: 5| Step: 4
Training loss: 3.115022659301758
Validation loss: 2.4942336646459435

Epoch: 5| Step: 5
Training loss: 2.600983142852783
Validation loss: 2.495028793170888

Epoch: 5| Step: 6
Training loss: 2.9631431102752686
Validation loss: 2.4948132961027083

Epoch: 5| Step: 7
Training loss: 1.6533324718475342
Validation loss: 2.4951719494276148

Epoch: 5| Step: 8
Training loss: 3.1412203311920166
Validation loss: 2.493760488366568

Epoch: 5| Step: 9
Training loss: 2.3186118602752686
Validation loss: 2.4927761272717546

Epoch: 5| Step: 10
Training loss: 2.731163263320923
Validation loss: 2.494421605140932

Epoch: 123| Step: 0
Training loss: 3.1971898078918457
Validation loss: 2.4943455201323315

Epoch: 5| Step: 1
Training loss: 2.4147000312805176
Validation loss: 2.493389091184062

Epoch: 5| Step: 2
Training loss: 3.072141647338867
Validation loss: 2.498761720554803

Epoch: 5| Step: 3
Training loss: 2.4547321796417236
Validation loss: 2.4957403547020367

Epoch: 5| Step: 4
Training loss: 2.863774061203003
Validation loss: 2.4949279677483345

Epoch: 5| Step: 5
Training loss: 2.2696101665496826
Validation loss: 2.493790490652925

Epoch: 5| Step: 6
Training loss: 2.519641876220703
Validation loss: 2.491149938234719

Epoch: 5| Step: 7
Training loss: 2.1277101039886475
Validation loss: 2.49031735492009

Epoch: 5| Step: 8
Training loss: 3.0542004108428955
Validation loss: 2.492491711852371

Epoch: 5| Step: 9
Training loss: 3.0706677436828613
Validation loss: 2.49393831658107

Epoch: 5| Step: 10
Training loss: 2.535759210586548
Validation loss: 2.4908931639886673

Epoch: 124| Step: 0
Training loss: 3.28765606880188
Validation loss: 2.490664433407527

Epoch: 5| Step: 1
Training loss: 2.5853524208068848
Validation loss: 2.492006348025414

Epoch: 5| Step: 2
Training loss: 2.9768459796905518
Validation loss: 2.4936922468164915

Epoch: 5| Step: 3
Training loss: 2.5815799236297607
Validation loss: 2.4935369004485426

Epoch: 5| Step: 4
Training loss: 2.9236655235290527
Validation loss: 2.490234762109736

Epoch: 5| Step: 5
Training loss: 2.21283221244812
Validation loss: 2.4962701054029566

Epoch: 5| Step: 6
Training loss: 2.917235851287842
Validation loss: 2.4924831736472344

Epoch: 5| Step: 7
Training loss: 2.5061144828796387
Validation loss: 2.498185820476983

Epoch: 5| Step: 8
Training loss: 2.8623154163360596
Validation loss: 2.492244815313688

Epoch: 5| Step: 9
Training loss: 2.415165662765503
Validation loss: 2.4938489685776415

Epoch: 5| Step: 10
Training loss: 2.2285232543945312
Validation loss: 2.499345851200883

Epoch: 125| Step: 0
Training loss: 2.5366978645324707
Validation loss: 2.5035156511491343

Epoch: 5| Step: 1
Training loss: 2.809739589691162
Validation loss: 2.506884087798416

Epoch: 5| Step: 2
Training loss: 2.314512252807617
Validation loss: 2.51824124141406

Epoch: 5| Step: 3
Training loss: 2.6967520713806152
Validation loss: 2.523919887440179

Epoch: 5| Step: 4
Training loss: 2.3572134971618652
Validation loss: 2.533706365093108

Epoch: 5| Step: 5
Training loss: 1.8494889736175537
Validation loss: 2.538682224929974

Epoch: 5| Step: 6
Training loss: 3.466233730316162
Validation loss: 2.5475691082657024

Epoch: 5| Step: 7
Training loss: 3.0235040187835693
Validation loss: 2.5340815462091917

Epoch: 5| Step: 8
Training loss: 2.9103195667266846
Validation loss: 2.51091335153067

Epoch: 5| Step: 9
Training loss: 3.2252254486083984
Validation loss: 2.4908613210083335

Epoch: 5| Step: 10
Training loss: 2.460866689682007
Validation loss: 2.4858430072825444

Epoch: 126| Step: 0
Training loss: 3.3252532482147217
Validation loss: 2.485410367288897

Epoch: 5| Step: 1
Training loss: 2.350961208343506
Validation loss: 2.4871765798138035

Epoch: 5| Step: 2
Training loss: 2.435347080230713
Validation loss: 2.487727469013583

Epoch: 5| Step: 3
Training loss: 3.1637966632843018
Validation loss: 2.4877310978469027

Epoch: 5| Step: 4
Training loss: 2.8952934741973877
Validation loss: 2.4863238873020297

Epoch: 5| Step: 5
Training loss: 2.6673407554626465
Validation loss: 2.48782822649966

Epoch: 5| Step: 6
Training loss: 2.7501113414764404
Validation loss: 2.483953091406053

Epoch: 5| Step: 7
Training loss: 2.6589548587799072
Validation loss: 2.481866946784399

Epoch: 5| Step: 8
Training loss: 2.42667555809021
Validation loss: 2.481198339052098

Epoch: 5| Step: 9
Training loss: 2.6340885162353516
Validation loss: 2.485066447206723

Epoch: 5| Step: 10
Training loss: 2.202779531478882
Validation loss: 2.4834281193312777

Epoch: 127| Step: 0
Training loss: 2.2806241512298584
Validation loss: 2.4837103992380123

Epoch: 5| Step: 1
Training loss: 2.985456943511963
Validation loss: 2.484415441431025

Epoch: 5| Step: 2
Training loss: 3.3829643726348877
Validation loss: 2.484931074162965

Epoch: 5| Step: 3
Training loss: 2.1193785667419434
Validation loss: 2.4835114325246503

Epoch: 5| Step: 4
Training loss: 2.4277660846710205
Validation loss: 2.4868510410349858

Epoch: 5| Step: 5
Training loss: 2.455568790435791
Validation loss: 2.4840333538670696

Epoch: 5| Step: 6
Training loss: 3.136399507522583
Validation loss: 2.4834557758864535

Epoch: 5| Step: 7
Training loss: 2.6635782718658447
Validation loss: 2.485900343105357

Epoch: 5| Step: 8
Training loss: 2.7095940113067627
Validation loss: 2.4915090196876117

Epoch: 5| Step: 9
Training loss: 2.8630871772766113
Validation loss: 2.495684184053893

Epoch: 5| Step: 10
Training loss: 2.478630304336548
Validation loss: 2.5097128652757212

Epoch: 128| Step: 0
Training loss: 2.8644659519195557
Validation loss: 2.505862328314012

Epoch: 5| Step: 1
Training loss: 3.460252285003662
Validation loss: 2.5141707081948557

Epoch: 5| Step: 2
Training loss: 2.0898146629333496
Validation loss: 2.5014848068196285

Epoch: 5| Step: 3
Training loss: 2.4423656463623047
Validation loss: 2.4951738798490135

Epoch: 5| Step: 4
Training loss: 2.2588353157043457
Validation loss: 2.488507678431849

Epoch: 5| Step: 5
Training loss: 2.968264102935791
Validation loss: 2.4813694748827206

Epoch: 5| Step: 6
Training loss: 3.3344178199768066
Validation loss: 2.4838859547850904

Epoch: 5| Step: 7
Training loss: 1.9901306629180908
Validation loss: 2.479383017427178

Epoch: 5| Step: 8
Training loss: 2.614537000656128
Validation loss: 2.480038732610723

Epoch: 5| Step: 9
Training loss: 3.1079487800598145
Validation loss: 2.4780737494909637

Epoch: 5| Step: 10
Training loss: 2.3385956287384033
Validation loss: 2.482164893099057

Epoch: 129| Step: 0
Training loss: 2.7150142192840576
Validation loss: 2.4792777466517624

Epoch: 5| Step: 1
Training loss: 2.312244176864624
Validation loss: 2.4824195831052718

Epoch: 5| Step: 2
Training loss: 2.8527307510375977
Validation loss: 2.4863471395225933

Epoch: 5| Step: 3
Training loss: 2.4599356651306152
Validation loss: 2.488804042980235

Epoch: 5| Step: 4
Training loss: 2.3460257053375244
Validation loss: 2.495873784506193

Epoch: 5| Step: 5
Training loss: 2.936105251312256
Validation loss: 2.4945181287744993

Epoch: 5| Step: 6
Training loss: 3.412686586380005
Validation loss: 2.4858222366661153

Epoch: 5| Step: 7
Training loss: 3.082345724105835
Validation loss: 2.4845657476814846

Epoch: 5| Step: 8
Training loss: 1.8115909099578857
Validation loss: 2.4871336747241277

Epoch: 5| Step: 9
Training loss: 3.0696616172790527
Validation loss: 2.480165494385586

Epoch: 5| Step: 10
Training loss: 2.404340982437134
Validation loss: 2.4786340267427507

Epoch: 130| Step: 0
Training loss: 2.6931891441345215
Validation loss: 2.474872963402861

Epoch: 5| Step: 1
Training loss: 2.122627019882202
Validation loss: 2.4687493975444506

Epoch: 5| Step: 2
Training loss: 2.705676317214966
Validation loss: 2.472128621993526

Epoch: 5| Step: 3
Training loss: 2.307649612426758
Validation loss: 2.472013842674994

Epoch: 5| Step: 4
Training loss: 2.5146889686584473
Validation loss: 2.4755376769650366

Epoch: 5| Step: 5
Training loss: 3.025635242462158
Validation loss: 2.473126601147395

Epoch: 5| Step: 6
Training loss: 3.1852049827575684
Validation loss: 2.470477714333483

Epoch: 5| Step: 7
Training loss: 2.689739227294922
Validation loss: 2.4713904780726277

Epoch: 5| Step: 8
Training loss: 2.77284574508667
Validation loss: 2.4684816124618694

Epoch: 5| Step: 9
Training loss: 2.924926280975342
Validation loss: 2.4684912543142996

Epoch: 5| Step: 10
Training loss: 2.493109703063965
Validation loss: 2.4698986238048923

Epoch: 131| Step: 0
Training loss: 2.469014883041382
Validation loss: 2.4691572778968403

Epoch: 5| Step: 1
Training loss: 2.3495261669158936
Validation loss: 2.466542842567608

Epoch: 5| Step: 2
Training loss: 3.0072169303894043
Validation loss: 2.4708217036339546

Epoch: 5| Step: 3
Training loss: 2.649758815765381
Validation loss: 2.47238245830741

Epoch: 5| Step: 4
Training loss: 2.790236711502075
Validation loss: 2.4684750521054832

Epoch: 5| Step: 5
Training loss: 1.8656160831451416
Validation loss: 2.469525396182973

Epoch: 5| Step: 6
Training loss: 3.369642734527588
Validation loss: 2.467969807245398

Epoch: 5| Step: 7
Training loss: 2.521782636642456
Validation loss: 2.470642610262799

Epoch: 5| Step: 8
Training loss: 2.495755672454834
Validation loss: 2.4700281773844073

Epoch: 5| Step: 9
Training loss: 3.1353023052215576
Validation loss: 2.475406805674235

Epoch: 5| Step: 10
Training loss: 2.7455825805664062
Validation loss: 2.4749636598812637

Epoch: 132| Step: 0
Training loss: 2.2687668800354004
Validation loss: 2.4817727586274505

Epoch: 5| Step: 1
Training loss: 2.9717602729797363
Validation loss: 2.486619951904461

Epoch: 5| Step: 2
Training loss: 2.9757070541381836
Validation loss: 2.487170104057558

Epoch: 5| Step: 3
Training loss: 2.8470208644866943
Validation loss: 2.479224984363843

Epoch: 5| Step: 4
Training loss: 2.7898716926574707
Validation loss: 2.4796515818565124

Epoch: 5| Step: 5
Training loss: 2.305187940597534
Validation loss: 2.4720225949441232

Epoch: 5| Step: 6
Training loss: 2.3668270111083984
Validation loss: 2.474950836550805

Epoch: 5| Step: 7
Training loss: 2.6327550411224365
Validation loss: 2.4762901926553376

Epoch: 5| Step: 8
Training loss: 3.1442372798919678
Validation loss: 2.4763132782392603

Epoch: 5| Step: 9
Training loss: 3.285367250442505
Validation loss: 2.480763701982396

Epoch: 5| Step: 10
Training loss: 1.6606433391571045
Validation loss: 2.485033122442102

Epoch: 133| Step: 0
Training loss: 2.5295090675354004
Validation loss: 2.485808046915198

Epoch: 5| Step: 1
Training loss: 2.4943737983703613
Validation loss: 2.4891853640156407

Epoch: 5| Step: 2
Training loss: 2.6656157970428467
Validation loss: 2.4910251927632157

Epoch: 5| Step: 3
Training loss: 3.2139229774475098
Validation loss: 2.490218242009481

Epoch: 5| Step: 4
Training loss: 2.661865234375
Validation loss: 2.4845305335137153

Epoch: 5| Step: 5
Training loss: 2.361367702484131
Validation loss: 2.477307158131753

Epoch: 5| Step: 6
Training loss: 2.9924683570861816
Validation loss: 2.470547109521845

Epoch: 5| Step: 7
Training loss: 2.569758892059326
Validation loss: 2.468407131010486

Epoch: 5| Step: 8
Training loss: 2.7203407287597656
Validation loss: 2.467516278707853

Epoch: 5| Step: 9
Training loss: 2.5143957138061523
Validation loss: 2.469186939218993

Epoch: 5| Step: 10
Training loss: 2.723877429962158
Validation loss: 2.4670675441782963

Epoch: 134| Step: 0
Training loss: 2.5375492572784424
Validation loss: 2.466524418964181

Epoch: 5| Step: 1
Training loss: 2.405609369277954
Validation loss: 2.4640119665412494

Epoch: 5| Step: 2
Training loss: 3.1887991428375244
Validation loss: 2.4639856328246412

Epoch: 5| Step: 3
Training loss: 2.866779327392578
Validation loss: 2.4597757965005855

Epoch: 5| Step: 4
Training loss: 2.4987850189208984
Validation loss: 2.465200234484929

Epoch: 5| Step: 5
Training loss: 1.8531684875488281
Validation loss: 2.465773913168138

Epoch: 5| Step: 6
Training loss: 2.2070059776306152
Validation loss: 2.467770481622347

Epoch: 5| Step: 7
Training loss: 2.889359712600708
Validation loss: 2.470469941375076

Epoch: 5| Step: 8
Training loss: 3.3258934020996094
Validation loss: 2.4763321184342906

Epoch: 5| Step: 9
Training loss: 3.122523069381714
Validation loss: 2.4805295928832023

Epoch: 5| Step: 10
Training loss: 2.4757845401763916
Validation loss: 2.486859526685489

Epoch: 135| Step: 0
Training loss: 2.671032428741455
Validation loss: 2.4948331643176336

Epoch: 5| Step: 1
Training loss: 2.48268461227417
Validation loss: 2.5034232934316

Epoch: 5| Step: 2
Training loss: 2.3851993083953857
Validation loss: 2.493567153971682

Epoch: 5| Step: 3
Training loss: 2.7922451496124268
Validation loss: 2.492692942260414

Epoch: 5| Step: 4
Training loss: 3.119915723800659
Validation loss: 2.483833650107025

Epoch: 5| Step: 5
Training loss: 2.293923854827881
Validation loss: 2.4719789515259447

Epoch: 5| Step: 6
Training loss: 2.674718141555786
Validation loss: 2.4663393394921416

Epoch: 5| Step: 7
Training loss: 3.0297024250030518
Validation loss: 2.4666340094740673

Epoch: 5| Step: 8
Training loss: 2.090505599975586
Validation loss: 2.460545926965693

Epoch: 5| Step: 9
Training loss: 3.4700851440429688
Validation loss: 2.4593493912809636

Epoch: 5| Step: 10
Training loss: 2.419041395187378
Validation loss: 2.4575262402975433

Epoch: 136| Step: 0
Training loss: 1.8019163608551025
Validation loss: 2.4585656632659254

Epoch: 5| Step: 1
Training loss: 2.5031723976135254
Validation loss: 2.45697118133627

Epoch: 5| Step: 2
Training loss: 3.3686721324920654
Validation loss: 2.458812290622342

Epoch: 5| Step: 3
Training loss: 2.6360130310058594
Validation loss: 2.4572775107558056

Epoch: 5| Step: 4
Training loss: 2.997493028640747
Validation loss: 2.456141233444214

Epoch: 5| Step: 5
Training loss: 2.9744067192077637
Validation loss: 2.4539298959957656

Epoch: 5| Step: 6
Training loss: 2.8641271591186523
Validation loss: 2.4573964585540113

Epoch: 5| Step: 7
Training loss: 2.682171583175659
Validation loss: 2.4583497790880102

Epoch: 5| Step: 8
Training loss: 2.6198556423187256
Validation loss: 2.4580972169035222

Epoch: 5| Step: 9
Training loss: 2.737004041671753
Validation loss: 2.4574759826865247

Epoch: 5| Step: 10
Training loss: 2.0934031009674072
Validation loss: 2.4591113162297074

Epoch: 137| Step: 0
Training loss: 2.075698137283325
Validation loss: 2.4626046688325944

Epoch: 5| Step: 1
Training loss: 2.4755771160125732
Validation loss: 2.4587597616257204

Epoch: 5| Step: 2
Training loss: 3.520648956298828
Validation loss: 2.4634277615495908

Epoch: 5| Step: 3
Training loss: 2.4517736434936523
Validation loss: 2.4679320576370403

Epoch: 5| Step: 4
Training loss: 2.0762791633605957
Validation loss: 2.4639808157438874

Epoch: 5| Step: 5
Training loss: 2.607545852661133
Validation loss: 2.463575409304711

Epoch: 5| Step: 6
Training loss: 2.925696611404419
Validation loss: 2.4591306896619898

Epoch: 5| Step: 7
Training loss: 3.228729724884033
Validation loss: 2.4664023717244468

Epoch: 5| Step: 8
Training loss: 3.085880994796753
Validation loss: 2.4730168311826644

Epoch: 5| Step: 9
Training loss: 2.5292935371398926
Validation loss: 2.4857065575097197

Epoch: 5| Step: 10
Training loss: 2.2129786014556885
Validation loss: 2.486652171739968

Epoch: 138| Step: 0
Training loss: 2.1693074703216553
Validation loss: 2.4931288393594886

Epoch: 5| Step: 1
Training loss: 2.4125514030456543
Validation loss: 2.4929174684709117

Epoch: 5| Step: 2
Training loss: 2.1006388664245605
Validation loss: 2.488100923517699

Epoch: 5| Step: 3
Training loss: 2.4895081520080566
Validation loss: 2.4776345863137195

Epoch: 5| Step: 4
Training loss: 2.980747938156128
Validation loss: 2.4626541137695312

Epoch: 5| Step: 5
Training loss: 2.8957269191741943
Validation loss: 2.457915803437592

Epoch: 5| Step: 6
Training loss: 3.0412516593933105
Validation loss: 2.4547133625194593

Epoch: 5| Step: 7
Training loss: 2.6113414764404297
Validation loss: 2.4640381566939817

Epoch: 5| Step: 8
Training loss: 2.5448732376098633
Validation loss: 2.4636284510294595

Epoch: 5| Step: 9
Training loss: 2.811066150665283
Validation loss: 2.458195222321377

Epoch: 5| Step: 10
Training loss: 3.3958821296691895
Validation loss: 2.4566213648806334

Epoch: 139| Step: 0
Training loss: 1.988779067993164
Validation loss: 2.4528556895512406

Epoch: 5| Step: 1
Training loss: 3.1955132484436035
Validation loss: 2.4535224130076747

Epoch: 5| Step: 2
Training loss: 3.398346424102783
Validation loss: 2.4524395004395516

Epoch: 5| Step: 3
Training loss: 2.7204511165618896
Validation loss: 2.450353871109665

Epoch: 5| Step: 4
Training loss: 2.160461902618408
Validation loss: 2.446455119758524

Epoch: 5| Step: 5
Training loss: 2.472219467163086
Validation loss: 2.448901440507622

Epoch: 5| Step: 6
Training loss: 2.5844578742980957
Validation loss: 2.45122258381177

Epoch: 5| Step: 7
Training loss: 3.1487183570861816
Validation loss: 2.457140589273104

Epoch: 5| Step: 8
Training loss: 2.5074398517608643
Validation loss: 2.457557321876608

Epoch: 5| Step: 9
Training loss: 2.811619520187378
Validation loss: 2.4656969911308697

Epoch: 5| Step: 10
Training loss: 2.2020492553710938
Validation loss: 2.4673282382308797

Epoch: 140| Step: 0
Training loss: 3.165006160736084
Validation loss: 2.46008409735977

Epoch: 5| Step: 1
Training loss: 2.450139284133911
Validation loss: 2.4560984667911323

Epoch: 5| Step: 2
Training loss: 2.4573333263397217
Validation loss: 2.4514805629689205

Epoch: 5| Step: 3
Training loss: 3.2092418670654297
Validation loss: 2.447310778402513

Epoch: 5| Step: 4
Training loss: 2.845226764678955
Validation loss: 2.4469025545222785

Epoch: 5| Step: 5
Training loss: 2.8183810710906982
Validation loss: 2.4423380692799888

Epoch: 5| Step: 6
Training loss: 2.8700029850006104
Validation loss: 2.445105706491778

Epoch: 5| Step: 7
Training loss: 2.3965680599212646
Validation loss: 2.4455181783245457

Epoch: 5| Step: 8
Training loss: 2.0091681480407715
Validation loss: 2.4438361173034995

Epoch: 5| Step: 9
Training loss: 2.3766252994537354
Validation loss: 2.451895001114056

Epoch: 5| Step: 10
Training loss: 2.703371524810791
Validation loss: 2.452394357291601

Epoch: 141| Step: 0
Training loss: 2.741642475128174
Validation loss: 2.4557869536902315

Epoch: 5| Step: 1
Training loss: 3.0340139865875244
Validation loss: 2.4601584506291214

Epoch: 5| Step: 2
Training loss: 3.0997302532196045
Validation loss: 2.47068118023616

Epoch: 5| Step: 3
Training loss: 2.543797016143799
Validation loss: 2.4652143088720178

Epoch: 5| Step: 4
Training loss: 2.1823019981384277
Validation loss: 2.455262727634881

Epoch: 5| Step: 5
Training loss: 3.269559383392334
Validation loss: 2.4478991698193293

Epoch: 5| Step: 6
Training loss: 2.748483419418335
Validation loss: 2.4495223004330873

Epoch: 5| Step: 7
Training loss: 2.7078120708465576
Validation loss: 2.446617264901438

Epoch: 5| Step: 8
Training loss: 3.0344443321228027
Validation loss: 2.444550096347768

Epoch: 5| Step: 9
Training loss: 1.4122307300567627
Validation loss: 2.4459952257012807

Epoch: 5| Step: 10
Training loss: 2.423675298690796
Validation loss: 2.4521187556687223

Epoch: 142| Step: 0
Training loss: 3.318283796310425
Validation loss: 2.46153760469088

Epoch: 5| Step: 1
Training loss: 2.682887077331543
Validation loss: 2.476794212095199

Epoch: 5| Step: 2
Training loss: 2.933232069015503
Validation loss: 2.480625826825378

Epoch: 5| Step: 3
Training loss: 2.6590235233306885
Validation loss: 2.4669665700645855

Epoch: 5| Step: 4
Training loss: 2.421739339828491
Validation loss: 2.4652100711740474

Epoch: 5| Step: 5
Training loss: 2.579169750213623
Validation loss: 2.4603976306094917

Epoch: 5| Step: 6
Training loss: 2.2002429962158203
Validation loss: 2.455300138842675

Epoch: 5| Step: 7
Training loss: 2.8717870712280273
Validation loss: 2.4432050207609772

Epoch: 5| Step: 8
Training loss: 1.9422658681869507
Validation loss: 2.437354036556777

Epoch: 5| Step: 9
Training loss: 2.7215328216552734
Validation loss: 2.4390913978699715

Epoch: 5| Step: 10
Training loss: 2.966890573501587
Validation loss: 2.439748446146647

Epoch: 143| Step: 0
Training loss: 2.719205379486084
Validation loss: 2.4369691161699194

Epoch: 5| Step: 1
Training loss: 2.8904643058776855
Validation loss: 2.4417002688172045

Epoch: 5| Step: 2
Training loss: 2.1740541458129883
Validation loss: 2.44063764233743

Epoch: 5| Step: 3
Training loss: 2.858701229095459
Validation loss: 2.4422999376891763

Epoch: 5| Step: 4
Training loss: 3.088801145553589
Validation loss: 2.4410691825292443

Epoch: 5| Step: 5
Training loss: 2.8565356731414795
Validation loss: 2.4391323879200923

Epoch: 5| Step: 6
Training loss: 2.65596866607666
Validation loss: 2.442666240917739

Epoch: 5| Step: 7
Training loss: 2.2932910919189453
Validation loss: 2.4395170903974965

Epoch: 5| Step: 8
Training loss: 2.1044561862945557
Validation loss: 2.4433512969683577

Epoch: 5| Step: 9
Training loss: 2.5540122985839844
Validation loss: 2.44178428188447

Epoch: 5| Step: 10
Training loss: 3.0410611629486084
Validation loss: 2.4408145412322013

Epoch: 144| Step: 0
Training loss: 3.221439838409424
Validation loss: 2.4374676596733833

Epoch: 5| Step: 1
Training loss: 2.5683999061584473
Validation loss: 2.438214079026253

Epoch: 5| Step: 2
Training loss: 2.663116931915283
Validation loss: 2.4358966940192768

Epoch: 5| Step: 3
Training loss: 2.640897274017334
Validation loss: 2.4367889563242593

Epoch: 5| Step: 4
Training loss: 2.65868878364563
Validation loss: 2.438009682522025

Epoch: 5| Step: 5
Training loss: 2.331510543823242
Validation loss: 2.4393632437593196

Epoch: 5| Step: 6
Training loss: 2.6336467266082764
Validation loss: 2.4348666565392607

Epoch: 5| Step: 7
Training loss: 2.695100784301758
Validation loss: 2.432120051435245

Epoch: 5| Step: 8
Training loss: 2.2412939071655273
Validation loss: 2.4334312767110844

Epoch: 5| Step: 9
Training loss: 3.274975538253784
Validation loss: 2.429917215019144

Epoch: 5| Step: 10
Training loss: 2.126993179321289
Validation loss: 2.4333342326584684

Epoch: 145| Step: 0
Training loss: 3.0847442150115967
Validation loss: 2.4353400763644966

Epoch: 5| Step: 1
Training loss: 2.7091946601867676
Validation loss: 2.4316470187197448

Epoch: 5| Step: 2
Training loss: 2.6504650115966797
Validation loss: 2.429829010399439

Epoch: 5| Step: 3
Training loss: 2.593956708908081
Validation loss: 2.4367410111170944

Epoch: 5| Step: 4
Training loss: 3.3615715503692627
Validation loss: 2.432503805365614

Epoch: 5| Step: 5
Training loss: 1.7433557510375977
Validation loss: 2.433222342562932

Epoch: 5| Step: 6
Training loss: 3.000206708908081
Validation loss: 2.432794319686069

Epoch: 5| Step: 7
Training loss: 2.3760640621185303
Validation loss: 2.446151917980563

Epoch: 5| Step: 8
Training loss: 2.303755760192871
Validation loss: 2.4518628735696115

Epoch: 5| Step: 9
Training loss: 2.7464516162872314
Validation loss: 2.4588125341682026

Epoch: 5| Step: 10
Training loss: 2.566391706466675
Validation loss: 2.4625235847247544

Epoch: 146| Step: 0
Training loss: 2.8233799934387207
Validation loss: 2.4547506506725023

Epoch: 5| Step: 1
Training loss: 2.3344826698303223
Validation loss: 2.454112745100452

Epoch: 5| Step: 2
Training loss: 3.197993040084839
Validation loss: 2.446946620941162

Epoch: 5| Step: 3
Training loss: 2.1323940753936768
Validation loss: 2.449532647286692

Epoch: 5| Step: 4
Training loss: 2.288611650466919
Validation loss: 2.445240351461595

Epoch: 5| Step: 5
Training loss: 2.6814496517181396
Validation loss: 2.4478711774272304

Epoch: 5| Step: 6
Training loss: 2.6171905994415283
Validation loss: 2.444920894920185

Epoch: 5| Step: 7
Training loss: 2.486898422241211
Validation loss: 2.460487965614565

Epoch: 5| Step: 8
Training loss: 2.9751060009002686
Validation loss: 2.4558584536275556

Epoch: 5| Step: 9
Training loss: 2.695314407348633
Validation loss: 2.460662849487797

Epoch: 5| Step: 10
Training loss: 3.002300262451172
Validation loss: 2.4763168083724154

Epoch: 147| Step: 0
Training loss: 2.3570077419281006
Validation loss: 2.4870133207690333

Epoch: 5| Step: 1
Training loss: 3.029951572418213
Validation loss: 2.4723750788678407

Epoch: 5| Step: 2
Training loss: 2.586887836456299
Validation loss: 2.465056252735917

Epoch: 5| Step: 3
Training loss: 2.5436012744903564
Validation loss: 2.443758567174276

Epoch: 5| Step: 4
Training loss: 2.9942455291748047
Validation loss: 2.4380778394719607

Epoch: 5| Step: 5
Training loss: 2.468256950378418
Validation loss: 2.4329524988769204

Epoch: 5| Step: 6
Training loss: 2.375546932220459
Validation loss: 2.4281778515026136

Epoch: 5| Step: 7
Training loss: 2.635967254638672
Validation loss: 2.4321969273269817

Epoch: 5| Step: 8
Training loss: 2.824019193649292
Validation loss: 2.4313547585600164

Epoch: 5| Step: 9
Training loss: 3.0247995853424072
Validation loss: 2.4409915606180825

Epoch: 5| Step: 10
Training loss: 2.3220317363739014
Validation loss: 2.4644636364393335

Epoch: 148| Step: 0
Training loss: 3.0964467525482178
Validation loss: 2.4834424629006335

Epoch: 5| Step: 1
Training loss: 2.2170445919036865
Validation loss: 2.488424657493509

Epoch: 5| Step: 2
Training loss: 2.4570724964141846
Validation loss: 2.4758356591706634

Epoch: 5| Step: 3
Training loss: 2.5237717628479004
Validation loss: 2.4643626905256704

Epoch: 5| Step: 4
Training loss: 3.16174578666687
Validation loss: 2.439363855187611

Epoch: 5| Step: 5
Training loss: 2.541271209716797
Validation loss: 2.4371967213128203

Epoch: 5| Step: 6
Training loss: 2.055119037628174
Validation loss: 2.427909538310061

Epoch: 5| Step: 7
Training loss: 3.0100767612457275
Validation loss: 2.431475479115722

Epoch: 5| Step: 8
Training loss: 2.2629029750823975
Validation loss: 2.4292346123726136

Epoch: 5| Step: 9
Training loss: 3.0307974815368652
Validation loss: 2.433264809270059

Epoch: 5| Step: 10
Training loss: 2.811415433883667
Validation loss: 2.437233614665206

Epoch: 149| Step: 0
Training loss: 2.4119863510131836
Validation loss: 2.432732300091815

Epoch: 5| Step: 1
Training loss: 2.4868998527526855
Validation loss: 2.4357048516632407

Epoch: 5| Step: 2
Training loss: 2.654395580291748
Validation loss: 2.4323485128341185

Epoch: 5| Step: 3
Training loss: 3.196078062057495
Validation loss: 2.4220714953637894

Epoch: 5| Step: 4
Training loss: 2.950810432434082
Validation loss: 2.424763415449409

Epoch: 5| Step: 5
Training loss: 2.02181077003479
Validation loss: 2.426573286774338

Epoch: 5| Step: 6
Training loss: 2.4413352012634277
Validation loss: 2.4261266723755868

Epoch: 5| Step: 7
Training loss: 2.947584867477417
Validation loss: 2.4256102372241277

Epoch: 5| Step: 8
Training loss: 2.393933057785034
Validation loss: 2.429868200773834

Epoch: 5| Step: 9
Training loss: 2.3823294639587402
Validation loss: 2.4387257522152317

Epoch: 5| Step: 10
Training loss: 3.2576828002929688
Validation loss: 2.4479044945009294

Epoch: 150| Step: 0
Training loss: 2.47938871383667
Validation loss: 2.4713231645604616

Epoch: 5| Step: 1
Training loss: 2.656106472015381
Validation loss: 2.5015949818395797

Epoch: 5| Step: 2
Training loss: 2.552915573120117
Validation loss: 2.5106460099579184

Epoch: 5| Step: 3
Training loss: 2.506357192993164
Validation loss: 2.5031448692403813

Epoch: 5| Step: 4
Training loss: 2.7899832725524902
Validation loss: 2.5074154843566236

Epoch: 5| Step: 5
Training loss: 2.7806804180145264
Validation loss: 2.505767819701984

Epoch: 5| Step: 6
Training loss: 2.9169812202453613
Validation loss: 2.496735724069739

Epoch: 5| Step: 7
Training loss: 3.0567069053649902
Validation loss: 2.468852153388403

Epoch: 5| Step: 8
Training loss: 2.243147134780884
Validation loss: 2.461079212927049

Epoch: 5| Step: 9
Training loss: 2.65853214263916
Validation loss: 2.4545340435479277

Epoch: 5| Step: 10
Training loss: 2.688422679901123
Validation loss: 2.457337469182989

Testing loss: 2.614286422729492
