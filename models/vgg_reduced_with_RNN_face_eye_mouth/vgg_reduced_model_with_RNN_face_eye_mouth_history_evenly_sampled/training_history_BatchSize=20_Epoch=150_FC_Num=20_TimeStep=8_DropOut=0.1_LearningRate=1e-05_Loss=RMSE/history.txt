Epoch: 1| Step: 0
Training loss: 6.391526883754907
Validation loss: 5.709598694129923

Epoch: 5| Step: 1
Training loss: 5.594537264018029
Validation loss: 5.698973911388183

Epoch: 5| Step: 2
Training loss: 5.710619206567017
Validation loss: 5.6880720847663895

Epoch: 5| Step: 3
Training loss: 6.004885909420449
Validation loss: 5.6775230283351386

Epoch: 5| Step: 4
Training loss: 4.918188646171085
Validation loss: 5.666262119385282

Epoch: 5| Step: 5
Training loss: 6.302168143045904
Validation loss: 5.655147425311655

Epoch: 5| Step: 6
Training loss: 5.9087525570974675
Validation loss: 5.64321959999876

Epoch: 5| Step: 7
Training loss: 6.078317045889558
Validation loss: 5.630562816993961

Epoch: 5| Step: 8
Training loss: 4.962272596553898
Validation loss: 5.616689977594153

Epoch: 5| Step: 9
Training loss: 5.304035938906423
Validation loss: 5.60299951827263

Epoch: 5| Step: 10
Training loss: 5.154287068660149
Validation loss: 5.587238923217638

Epoch: 2| Step: 0
Training loss: 6.031034317508469
Validation loss: 5.571004499904647

Epoch: 5| Step: 1
Training loss: 6.359326411631028
Validation loss: 5.554128931422287

Epoch: 5| Step: 2
Training loss: 5.494836290609185
Validation loss: 5.535278725608437

Epoch: 5| Step: 3
Training loss: 5.775254888813282
Validation loss: 5.5164646068676255

Epoch: 5| Step: 4
Training loss: 5.431858336836029
Validation loss: 5.494198313067475

Epoch: 5| Step: 5
Training loss: 5.657693415296921
Validation loss: 5.471883215525337

Epoch: 5| Step: 6
Training loss: 4.173511427064258
Validation loss: 5.448176718362064

Epoch: 5| Step: 7
Training loss: 5.696414542618665
Validation loss: 5.4237446313472555

Epoch: 5| Step: 8
Training loss: 5.037810603332447
Validation loss: 5.398778730664264

Epoch: 5| Step: 9
Training loss: 5.2349488812039375
Validation loss: 5.371518903475117

Epoch: 5| Step: 10
Training loss: 5.482651659828706
Validation loss: 5.344679877186936

Epoch: 3| Step: 0
Training loss: 5.417292788582371
Validation loss: 5.315393776160659

Epoch: 5| Step: 1
Training loss: 4.766859551286303
Validation loss: 5.287144612453627

Epoch: 5| Step: 2
Training loss: 5.668639381952865
Validation loss: 5.257633915329885

Epoch: 5| Step: 3
Training loss: 5.796113244360835
Validation loss: 5.22801700562367

Epoch: 5| Step: 4
Training loss: 5.612409955430243
Validation loss: 5.199048099444759

Epoch: 5| Step: 5
Training loss: 5.086968336513356
Validation loss: 5.169989623130775

Epoch: 5| Step: 6
Training loss: 6.030690854100746
Validation loss: 5.140892103905812

Epoch: 5| Step: 7
Training loss: 5.1389621259722995
Validation loss: 5.114261939982276

Epoch: 5| Step: 8
Training loss: 4.67718204430941
Validation loss: 5.086935465965323

Epoch: 5| Step: 9
Training loss: 4.38995399642163
Validation loss: 5.0612368915155015

Epoch: 5| Step: 10
Training loss: 4.614587971819175
Validation loss: 5.037220994807764

Epoch: 4| Step: 0
Training loss: 4.578827162916964
Validation loss: 5.014322696482484

Epoch: 5| Step: 1
Training loss: 5.7612867290363114
Validation loss: 4.99301676442477

Epoch: 5| Step: 2
Training loss: 4.587445558645905
Validation loss: 4.971529896487882

Epoch: 5| Step: 3
Training loss: 4.564575977165717
Validation loss: 4.949483120356511

Epoch: 5| Step: 4
Training loss: 5.182087844086409
Validation loss: 4.929622843892866

Epoch: 5| Step: 5
Training loss: 4.719112559152119
Validation loss: 4.90836637785871

Epoch: 5| Step: 6
Training loss: 4.2689625185877915
Validation loss: 4.887832323893962

Epoch: 5| Step: 7
Training loss: 5.169764707660143
Validation loss: 4.868145257097647

Epoch: 5| Step: 8
Training loss: 4.821480632682559
Validation loss: 4.850452413074077

Epoch: 5| Step: 9
Training loss: 4.993915288717728
Validation loss: 4.832768615529987

Epoch: 5| Step: 10
Training loss: 6.079884252450317
Validation loss: 4.8176352988319255

Epoch: 5| Step: 0
Training loss: 4.1929135985111925
Validation loss: 4.80223120674213

Epoch: 5| Step: 1
Training loss: 4.06569276206381
Validation loss: 4.787388186285753

Epoch: 5| Step: 2
Training loss: 5.434009352366037
Validation loss: 4.775258402744201

Epoch: 5| Step: 3
Training loss: 5.340545585849916
Validation loss: 4.760852258041386

Epoch: 5| Step: 4
Training loss: 4.805600062600916
Validation loss: 4.7497550154215284

Epoch: 5| Step: 5
Training loss: 5.9114737847976295
Validation loss: 4.735839073711481

Epoch: 5| Step: 6
Training loss: 4.917909411253416
Validation loss: 4.723173573014741

Epoch: 5| Step: 7
Training loss: 3.521401504328568
Validation loss: 4.7099070763429065

Epoch: 5| Step: 8
Training loss: 5.026401813892533
Validation loss: 4.699754297401001

Epoch: 5| Step: 9
Training loss: 4.472294821982496
Validation loss: 4.688719223229871

Epoch: 5| Step: 10
Training loss: 4.9430690214388076
Validation loss: 4.680447658868048

Epoch: 6| Step: 0
Training loss: 5.532529866051335
Validation loss: 4.670221470511862

Epoch: 5| Step: 1
Training loss: 4.237570819994372
Validation loss: 4.659587525348345

Epoch: 5| Step: 2
Training loss: 5.641210298472465
Validation loss: 4.649384506796793

Epoch: 5| Step: 3
Training loss: 5.195571319328464
Validation loss: 4.638372487862595

Epoch: 5| Step: 4
Training loss: 3.817645118817995
Validation loss: 4.626691819767107

Epoch: 5| Step: 5
Training loss: 4.92058379175526
Validation loss: 4.615694468585568

Epoch: 5| Step: 6
Training loss: 3.870146264951957
Validation loss: 4.603450085548981

Epoch: 5| Step: 7
Training loss: 4.457540471293856
Validation loss: 4.593654323237535

Epoch: 5| Step: 8
Training loss: 4.682978165667876
Validation loss: 4.581659562160567

Epoch: 5| Step: 9
Training loss: 4.638791733648855
Validation loss: 4.570608802307751

Epoch: 5| Step: 10
Training loss: 4.4802814367994435
Validation loss: 4.559706721363736

Epoch: 7| Step: 0
Training loss: 4.971960601932889
Validation loss: 4.550349047953926

Epoch: 5| Step: 1
Training loss: 4.320530146105707
Validation loss: 4.540591967479296

Epoch: 5| Step: 2
Training loss: 4.022174881527143
Validation loss: 4.529744675508654

Epoch: 5| Step: 3
Training loss: 5.334661596518118
Validation loss: 4.520886463941668

Epoch: 5| Step: 4
Training loss: 5.367200648751179
Validation loss: 4.511778130682348

Epoch: 5| Step: 5
Training loss: 4.064095286611428
Validation loss: 4.50084150870836

Epoch: 5| Step: 6
Training loss: 4.452673959476968
Validation loss: 4.489256479643127

Epoch: 5| Step: 7
Training loss: 4.783988417761315
Validation loss: 4.47837113424613

Epoch: 5| Step: 8
Training loss: 3.432100667930941
Validation loss: 4.46688702743329

Epoch: 5| Step: 9
Training loss: 5.060240064512557
Validation loss: 4.4573430025314975

Epoch: 5| Step: 10
Training loss: 4.489005539157957
Validation loss: 4.446309013270858

Epoch: 8| Step: 0
Training loss: 5.102249823590482
Validation loss: 4.435770869809627

Epoch: 5| Step: 1
Training loss: 4.356653163648683
Validation loss: 4.4272226310496805

Epoch: 5| Step: 2
Training loss: 4.770885928112566
Validation loss: 4.413479846160276

Epoch: 5| Step: 3
Training loss: 4.717324957498548
Validation loss: 4.401896363232207

Epoch: 5| Step: 4
Training loss: 3.938214555117727
Validation loss: 4.389714995370829

Epoch: 5| Step: 5
Training loss: 4.238708080825808
Validation loss: 4.379413145053641

Epoch: 5| Step: 6
Training loss: 5.134725507403191
Validation loss: 4.3694919538790735

Epoch: 5| Step: 7
Training loss: 4.1336645967781696
Validation loss: 4.358878511526634

Epoch: 5| Step: 8
Training loss: 4.68131570400684
Validation loss: 4.347770798275007

Epoch: 5| Step: 9
Training loss: 3.569651870209097
Validation loss: 4.336735567500208

Epoch: 5| Step: 10
Training loss: 4.626420704975793
Validation loss: 4.3274821272702795

Epoch: 9| Step: 0
Training loss: 4.758115160606329
Validation loss: 4.317837389762328

Epoch: 5| Step: 1
Training loss: 4.578846949395265
Validation loss: 4.308861213712302

Epoch: 5| Step: 2
Training loss: 4.327220174908907
Validation loss: 4.300863968224703

Epoch: 5| Step: 3
Training loss: 3.8987226057053346
Validation loss: 4.2924099075598665

Epoch: 5| Step: 4
Training loss: 4.593453118728336
Validation loss: 4.282167650570722

Epoch: 5| Step: 5
Training loss: 4.718425209033949
Validation loss: 4.271365152057167

Epoch: 5| Step: 6
Training loss: 4.1389172757147445
Validation loss: 4.260785245332673

Epoch: 5| Step: 7
Training loss: 4.1580058813012215
Validation loss: 4.253362387212269

Epoch: 5| Step: 8
Training loss: 4.146632489700368
Validation loss: 4.244162394630111

Epoch: 5| Step: 9
Training loss: 5.0117745043298765
Validation loss: 4.235390038559904

Epoch: 5| Step: 10
Training loss: 3.791210957623899
Validation loss: 4.224449138405248

Epoch: 10| Step: 0
Training loss: 5.158038574737161
Validation loss: 4.214647188698913

Epoch: 5| Step: 1
Training loss: 3.522313380607764
Validation loss: 4.2044264719593825

Epoch: 5| Step: 2
Training loss: 3.885942575215951
Validation loss: 4.193739076685155

Epoch: 5| Step: 3
Training loss: 4.807706154436565
Validation loss: 4.184615597475274

Epoch: 5| Step: 4
Training loss: 4.1114079193563
Validation loss: 4.176593607683133

Epoch: 5| Step: 5
Training loss: 4.803404300191038
Validation loss: 4.164655285264147

Epoch: 5| Step: 6
Training loss: 4.617966329657524
Validation loss: 4.155491859310963

Epoch: 5| Step: 7
Training loss: 3.534801891122735
Validation loss: 4.146591612282984

Epoch: 5| Step: 8
Training loss: 4.824689612015981
Validation loss: 4.13983917797435

Epoch: 5| Step: 9
Training loss: 4.17172846733238
Validation loss: 4.132185774257906

Epoch: 5| Step: 10
Training loss: 3.301393711669834
Validation loss: 4.121279956051954

Epoch: 11| Step: 0
Training loss: 4.408581056226741
Validation loss: 4.113101488128697

Epoch: 5| Step: 1
Training loss: 3.452231313096435
Validation loss: 4.106582883982471

Epoch: 5| Step: 2
Training loss: 3.7524169762237443
Validation loss: 4.099267531105058

Epoch: 5| Step: 3
Training loss: 4.420626083151686
Validation loss: 4.090595346524116

Epoch: 5| Step: 4
Training loss: 4.833340590022109
Validation loss: 4.083501844128922

Epoch: 5| Step: 5
Training loss: 4.194515443808689
Validation loss: 4.078165770365289

Epoch: 5| Step: 6
Training loss: 4.430340646429821
Validation loss: 4.069216478317289

Epoch: 5| Step: 7
Training loss: 4.325643661319873
Validation loss: 4.0644086848634

Epoch: 5| Step: 8
Training loss: 3.357556653826527
Validation loss: 4.05808105060253

Epoch: 5| Step: 9
Training loss: 4.057788640518755
Validation loss: 4.0547817988331625

Epoch: 5| Step: 10
Training loss: 5.01982629999817
Validation loss: 4.043559061534999

Epoch: 12| Step: 0
Training loss: 4.7723201561558675
Validation loss: 4.040032001128196

Epoch: 5| Step: 1
Training loss: 4.660120232467687
Validation loss: 4.0358695871554

Epoch: 5| Step: 2
Training loss: 3.682900097484557
Validation loss: 4.0299838075155

Epoch: 5| Step: 3
Training loss: 4.159295593925308
Validation loss: 4.019149064514649

Epoch: 5| Step: 4
Training loss: 4.289366219750731
Validation loss: 4.016083578920073

Epoch: 5| Step: 5
Training loss: 4.2811698070728506
Validation loss: 4.009447318736547

Epoch: 5| Step: 6
Training loss: 3.794025874908807
Validation loss: 4.005075690170652

Epoch: 5| Step: 7
Training loss: 4.194685734649926
Validation loss: 3.9985226420426487

Epoch: 5| Step: 8
Training loss: 4.789357809448853
Validation loss: 3.9951321331547964

Epoch: 5| Step: 9
Training loss: 3.561538031014453
Validation loss: 3.9893724815323677

Epoch: 5| Step: 10
Training loss: 3.1784028028455156
Validation loss: 3.990960473068772

Epoch: 13| Step: 0
Training loss: 4.359634227633654
Validation loss: 3.978171528820251

Epoch: 5| Step: 1
Training loss: 3.978688449317614
Validation loss: 3.975406609524825

Epoch: 5| Step: 2
Training loss: 4.489088180155185
Validation loss: 3.9715858503515453

Epoch: 5| Step: 3
Training loss: 4.576547188047853
Validation loss: 3.9682563136846327

Epoch: 5| Step: 4
Training loss: 4.347162456866732
Validation loss: 3.9627567883367485

Epoch: 5| Step: 5
Training loss: 3.4925700752584508
Validation loss: 3.9570481166037355

Epoch: 5| Step: 6
Training loss: 3.6473098090344083
Validation loss: 3.9519124273948667

Epoch: 5| Step: 7
Training loss: 4.745212350642018
Validation loss: 3.94641174643299

Epoch: 5| Step: 8
Training loss: 3.6358923541628085
Validation loss: 3.944140118114006

Epoch: 5| Step: 9
Training loss: 3.3667181621679707
Validation loss: 3.9406363111061715

Epoch: 5| Step: 10
Training loss: 4.397502250909365
Validation loss: 3.9352677178915294

Epoch: 14| Step: 0
Training loss: 3.547274394802162
Validation loss: 3.93049560332635

Epoch: 5| Step: 1
Training loss: 3.860115505328505
Validation loss: 3.9270673820977

Epoch: 5| Step: 2
Training loss: 4.137510114121536
Validation loss: 3.9228116861455504

Epoch: 5| Step: 3
Training loss: 3.8393366838791536
Validation loss: 3.916914625485439

Epoch: 5| Step: 4
Training loss: 3.9864807548254575
Validation loss: 3.91213184941425

Epoch: 5| Step: 5
Training loss: 3.7995720220788494
Validation loss: 3.908629555752899

Epoch: 5| Step: 6
Training loss: 4.280811148099547
Validation loss: 3.9028960525722076

Epoch: 5| Step: 7
Training loss: 4.4861835727147525
Validation loss: 3.8986741643385794

Epoch: 5| Step: 8
Training loss: 4.754136944253583
Validation loss: 3.8951495438414785

Epoch: 5| Step: 9
Training loss: 3.856213962380359
Validation loss: 3.889257019293929

Epoch: 5| Step: 10
Training loss: 4.091262177922125
Validation loss: 3.8846493450788695

Epoch: 15| Step: 0
Training loss: 3.3928753816501596
Validation loss: 3.883235871093088

Epoch: 5| Step: 1
Training loss: 4.476092089158242
Validation loss: 3.8757099926226632

Epoch: 5| Step: 2
Training loss: 4.322056230453753
Validation loss: 3.8719861459842693

Epoch: 5| Step: 3
Training loss: 4.426030555161105
Validation loss: 3.8664186232261204

Epoch: 5| Step: 4
Training loss: 4.491015047403633
Validation loss: 3.8636451942194214

Epoch: 5| Step: 5
Training loss: 4.466041010598717
Validation loss: 3.8575379761264093

Epoch: 5| Step: 6
Training loss: 3.12971126187427
Validation loss: 3.851451431959677

Epoch: 5| Step: 7
Training loss: 4.048875704465975
Validation loss: 3.848378587123075

Epoch: 5| Step: 8
Training loss: 3.934105514980874
Validation loss: 3.844405466439262

Epoch: 5| Step: 9
Training loss: 3.7096860040188155
Validation loss: 3.8397493870027954

Epoch: 5| Step: 10
Training loss: 3.5108539674920527
Validation loss: 3.841710032606537

Epoch: 16| Step: 0
Training loss: 4.0662706922349985
Validation loss: 3.8314889846515827

Epoch: 5| Step: 1
Training loss: 4.330154549040842
Validation loss: 3.827720205817638

Epoch: 5| Step: 2
Training loss: 4.561162046973337
Validation loss: 3.823110393077225

Epoch: 5| Step: 3
Training loss: 4.791301857149905
Validation loss: 3.8193163215176535

Epoch: 5| Step: 4
Training loss: 3.5931770199646103
Validation loss: 3.8152486977951714

Epoch: 5| Step: 5
Training loss: 4.099210169939324
Validation loss: 3.8101018621808525

Epoch: 5| Step: 6
Training loss: 3.9583095884447483
Validation loss: 3.8076648792123184

Epoch: 5| Step: 7
Training loss: 3.1349326401186124
Validation loss: 3.8047719060314913

Epoch: 5| Step: 8
Training loss: 3.0967937870713245
Validation loss: 3.799684356960758

Epoch: 5| Step: 9
Training loss: 3.693899646703271
Validation loss: 3.795795281245838

Epoch: 5| Step: 10
Training loss: 4.195512081350245
Validation loss: 3.791888887117674

Epoch: 17| Step: 0
Training loss: 3.697364543834882
Validation loss: 3.7885598620074736

Epoch: 5| Step: 1
Training loss: 4.283651750259921
Validation loss: 3.7850519719595686

Epoch: 5| Step: 2
Training loss: 3.8799422955892076
Validation loss: 3.779603682958177

Epoch: 5| Step: 3
Training loss: 4.580162662466087
Validation loss: 3.7771300710257454

Epoch: 5| Step: 4
Training loss: 3.010893910383991
Validation loss: 3.7744907723220757

Epoch: 5| Step: 5
Training loss: 4.700119325462278
Validation loss: 3.7744443445235674

Epoch: 5| Step: 6
Training loss: 4.477527028507547
Validation loss: 3.7633484586602504

Epoch: 5| Step: 7
Training loss: 4.210834678852514
Validation loss: 3.7598185180131227

Epoch: 5| Step: 8
Training loss: 3.6601208142628296
Validation loss: 3.7547339608165173

Epoch: 5| Step: 9
Training loss: 2.995533638413969
Validation loss: 3.749238053714919

Epoch: 5| Step: 10
Training loss: 3.3862208580095228
Validation loss: 3.742840286450913

Epoch: 18| Step: 0
Training loss: 3.9105701208447785
Validation loss: 3.7368705910674604

Epoch: 5| Step: 1
Training loss: 3.4564863734617495
Validation loss: 3.7315198085419565

Epoch: 5| Step: 2
Training loss: 3.930690872385277
Validation loss: 3.7302033072071725

Epoch: 5| Step: 3
Training loss: 4.424666423401207
Validation loss: 3.7305036631967345

Epoch: 5| Step: 4
Training loss: 3.891560637331861
Validation loss: 3.722057815097878

Epoch: 5| Step: 5
Training loss: 4.082615743889677
Validation loss: 3.719689594933326

Epoch: 5| Step: 6
Training loss: 3.7615897056493894
Validation loss: 3.7151155022282603

Epoch: 5| Step: 7
Training loss: 3.9796605361246686
Validation loss: 3.7118423707553587

Epoch: 5| Step: 8
Training loss: 3.6795960109214256
Validation loss: 3.707402456173943

Epoch: 5| Step: 9
Training loss: 4.294325859622561
Validation loss: 3.704829428689367

Epoch: 5| Step: 10
Training loss: 3.3072250399549143
Validation loss: 3.7009388788103337

Epoch: 19| Step: 0
Training loss: 3.2989606723389655
Validation loss: 3.6976727657253856

Epoch: 5| Step: 1
Training loss: 3.6146922392841705
Validation loss: 3.696221673094604

Epoch: 5| Step: 2
Training loss: 3.6437683942536627
Validation loss: 3.693246006538704

Epoch: 5| Step: 3
Training loss: 3.7424864201627424
Validation loss: 3.6902449430159376

Epoch: 5| Step: 4
Training loss: 4.226527074640703
Validation loss: 3.6869241060729037

Epoch: 5| Step: 5
Training loss: 3.9414859759884435
Validation loss: 3.6849685567267727

Epoch: 5| Step: 6
Training loss: 4.4079062953896315
Validation loss: 3.6823765413247598

Epoch: 5| Step: 7
Training loss: 4.23179069005758
Validation loss: 3.6771046627615585

Epoch: 5| Step: 8
Training loss: 3.827335696689833
Validation loss: 3.6754547661476846

Epoch: 5| Step: 9
Training loss: 3.570787126975894
Validation loss: 3.6738185565920682

Epoch: 5| Step: 10
Training loss: 3.9595563237341067
Validation loss: 3.671261477700161

Epoch: 20| Step: 0
Training loss: 3.9954327496218087
Validation loss: 3.6678898529279924

Epoch: 5| Step: 1
Training loss: 3.8496388550843563
Validation loss: 3.6668503110283335

Epoch: 5| Step: 2
Training loss: 3.01785780712388
Validation loss: 3.6637625174957686

Epoch: 5| Step: 3
Training loss: 4.192837857285367
Validation loss: 3.664208753643004

Epoch: 5| Step: 4
Training loss: 4.104385421783846
Validation loss: 3.6590544675756873

Epoch: 5| Step: 5
Training loss: 3.703061388974357
Validation loss: 3.656647326758099

Epoch: 5| Step: 6
Training loss: 3.779818807830838
Validation loss: 3.6550661731013996

Epoch: 5| Step: 7
Training loss: 4.190503992983417
Validation loss: 3.6528884092894796

Epoch: 5| Step: 8
Training loss: 3.0560146873081235
Validation loss: 3.6503063967276086

Epoch: 5| Step: 9
Training loss: 4.056473942997751
Validation loss: 3.649010442902235

Epoch: 5| Step: 10
Training loss: 4.2231512776441225
Validation loss: 3.6478483017635397

Epoch: 21| Step: 0
Training loss: 3.3213035630288426
Validation loss: 3.643861202198697

Epoch: 5| Step: 1
Training loss: 3.612632569517197
Validation loss: 3.6419155131473993

Epoch: 5| Step: 2
Training loss: 3.860228532933905
Validation loss: 3.6409019728563496

Epoch: 5| Step: 3
Training loss: 4.078267646720972
Validation loss: 3.639846023398168

Epoch: 5| Step: 4
Training loss: 4.072418546664116
Validation loss: 3.637629825773124

Epoch: 5| Step: 5
Training loss: 3.513650704320601
Validation loss: 3.6362197858127865

Epoch: 5| Step: 6
Training loss: 3.9137635259598644
Validation loss: 3.6338208338784934

Epoch: 5| Step: 7
Training loss: 3.1360663736773593
Validation loss: 3.6330116248273607

Epoch: 5| Step: 8
Training loss: 4.388972612915673
Validation loss: 3.6323384794646434

Epoch: 5| Step: 9
Training loss: 4.0713465689525234
Validation loss: 3.6293018326395408

Epoch: 5| Step: 10
Training loss: 4.027551891672198
Validation loss: 3.627229454049447

Epoch: 22| Step: 0
Training loss: 4.0754137636528025
Validation loss: 3.6281724526539962

Epoch: 5| Step: 1
Training loss: 4.101756180322933
Validation loss: 3.624828071463315

Epoch: 5| Step: 2
Training loss: 3.6565335155668772
Validation loss: 3.6231445497459682

Epoch: 5| Step: 3
Training loss: 3.151547696594664
Validation loss: 3.621527545065729

Epoch: 5| Step: 4
Training loss: 4.34354449547598
Validation loss: 3.6173364241897277

Epoch: 5| Step: 5
Training loss: 4.415196635964079
Validation loss: 3.6152499628765007

Epoch: 5| Step: 6
Training loss: 3.7030319009015082
Validation loss: 3.615146531499684

Epoch: 5| Step: 7
Training loss: 3.618615414450698
Validation loss: 3.612774789797199

Epoch: 5| Step: 8
Training loss: 3.5236694530254353
Validation loss: 3.6134203457520333

Epoch: 5| Step: 9
Training loss: 3.149650245504467
Validation loss: 3.609800888495734

Epoch: 5| Step: 10
Training loss: 4.028575867840796
Validation loss: 3.6080555820845435

Epoch: 23| Step: 0
Training loss: 3.9518597051761
Validation loss: 3.608475786411623

Epoch: 5| Step: 1
Training loss: 3.3089750716468496
Validation loss: 3.6077618090025445

Epoch: 5| Step: 2
Training loss: 4.0768545225273325
Validation loss: 3.6058242237408424

Epoch: 5| Step: 3
Training loss: 3.714527457618053
Validation loss: 3.603608117943979

Epoch: 5| Step: 4
Training loss: 3.898840262299826
Validation loss: 3.6030247747914737

Epoch: 5| Step: 5
Training loss: 4.1571039455504755
Validation loss: 3.602261070036558

Epoch: 5| Step: 6
Training loss: 3.3916738267927644
Validation loss: 3.6010969496076144

Epoch: 5| Step: 7
Training loss: 3.5852612624475952
Validation loss: 3.602313427616208

Epoch: 5| Step: 8
Training loss: 3.824006897900158
Validation loss: 3.5997052528924804

Epoch: 5| Step: 9
Training loss: 3.5919125047235427
Validation loss: 3.5973619056038326

Epoch: 5| Step: 10
Training loss: 4.280673245751146
Validation loss: 3.596362016024508

Epoch: 24| Step: 0
Training loss: 3.6102567314094176
Validation loss: 3.5963257449761463

Epoch: 5| Step: 1
Training loss: 3.5417343731560553
Validation loss: 3.597338020527201

Epoch: 5| Step: 2
Training loss: 4.395010824526497
Validation loss: 3.5967494950508043

Epoch: 5| Step: 3
Training loss: 3.6482584417215804
Validation loss: 3.5916936226174836

Epoch: 5| Step: 4
Training loss: 4.087208420739093
Validation loss: 3.5892632581374193

Epoch: 5| Step: 5
Training loss: 3.1764655507947417
Validation loss: 3.5888483862474754

Epoch: 5| Step: 6
Training loss: 4.127544658564855
Validation loss: 3.5892535228611977

Epoch: 5| Step: 7
Training loss: 3.2209771608231614
Validation loss: 3.587329103780557

Epoch: 5| Step: 8
Training loss: 4.598452904973878
Validation loss: 3.583862061542694

Epoch: 5| Step: 9
Training loss: 3.484696446118978
Validation loss: 3.5794594957511654

Epoch: 5| Step: 10
Training loss: 3.4790773361220033
Validation loss: 3.5822276784646014

Epoch: 25| Step: 0
Training loss: 3.3571909347384516
Validation loss: 3.587067303855913

Epoch: 5| Step: 1
Training loss: 3.6880996992325863
Validation loss: 3.5785888293866495

Epoch: 5| Step: 2
Training loss: 3.6952457865525896
Validation loss: 3.5725653968488773

Epoch: 5| Step: 3
Training loss: 3.043776751328236
Validation loss: 3.5709012157574587

Epoch: 5| Step: 4
Training loss: 4.8313202886168884
Validation loss: 3.5713909078038903

Epoch: 5| Step: 5
Training loss: 3.767873638739405
Validation loss: 3.569581842989413

Epoch: 5| Step: 6
Training loss: 3.8444156225467916
Validation loss: 3.5673908856190977

Epoch: 5| Step: 7
Training loss: 4.082305752956302
Validation loss: 3.567435795513909

Epoch: 5| Step: 8
Training loss: 3.56870559157017
Validation loss: 3.5657104033311313

Epoch: 5| Step: 9
Training loss: 3.7564415601990175
Validation loss: 3.564691605984097

Epoch: 5| Step: 10
Training loss: 3.582677086168912
Validation loss: 3.5638240619739876

Epoch: 26| Step: 0
Training loss: 3.7519655798368237
Validation loss: 3.5649481843619197

Epoch: 5| Step: 1
Training loss: 3.6965328725733166
Validation loss: 3.5609461589546814

Epoch: 5| Step: 2
Training loss: 3.3733693174722195
Validation loss: 3.5609940787749226

Epoch: 5| Step: 3
Training loss: 4.464994119296414
Validation loss: 3.559842158612956

Epoch: 5| Step: 4
Training loss: 3.745952456358443
Validation loss: 3.5576505499646385

Epoch: 5| Step: 5
Training loss: 3.8568124024054673
Validation loss: 3.558583984131069

Epoch: 5| Step: 6
Training loss: 4.122051225413343
Validation loss: 3.557334375837499

Epoch: 5| Step: 7
Training loss: 3.527559090057897
Validation loss: 3.553953040585035

Epoch: 5| Step: 8
Training loss: 3.3269003464060947
Validation loss: 3.552762704765031

Epoch: 5| Step: 9
Training loss: 3.36584360870231
Validation loss: 3.554229791240772

Epoch: 5| Step: 10
Training loss: 4.0437876586103885
Validation loss: 3.5510646528683205

Epoch: 27| Step: 0
Training loss: 3.6627296349725635
Validation loss: 3.54904805294083

Epoch: 5| Step: 1
Training loss: 3.786376252611826
Validation loss: 3.547706173048637

Epoch: 5| Step: 2
Training loss: 3.7528943654010414
Validation loss: 3.5472297124273164

Epoch: 5| Step: 3
Training loss: 3.607671294292701
Validation loss: 3.5459672233199826

Epoch: 5| Step: 4
Training loss: 3.1679332274904235
Validation loss: 3.5439374406041555

Epoch: 5| Step: 5
Training loss: 3.284816148278427
Validation loss: 3.5447328144704575

Epoch: 5| Step: 6
Training loss: 3.768701966139339
Validation loss: 3.5510378415160497

Epoch: 5| Step: 7
Training loss: 3.9846944045152934
Validation loss: 3.537894871120479

Epoch: 5| Step: 8
Training loss: 4.719352835238289
Validation loss: 3.535747542125224

Epoch: 5| Step: 9
Training loss: 3.4789330105166725
Validation loss: 3.538922088393997

Epoch: 5| Step: 10
Training loss: 3.8472840724583746
Validation loss: 3.5423242415748795

Epoch: 28| Step: 0
Training loss: 3.760777943059057
Validation loss: 3.5579227589219635

Epoch: 5| Step: 1
Training loss: 4.2229376460066925
Validation loss: 3.5698110821136457

Epoch: 5| Step: 2
Training loss: 4.180724170504884
Validation loss: 3.5338595649907187

Epoch: 5| Step: 3
Training loss: 3.784095135144106
Validation loss: 3.5259736215195465

Epoch: 5| Step: 4
Training loss: 4.064701833452615
Validation loss: 3.5324825350489313

Epoch: 5| Step: 5
Training loss: 3.6489658667446427
Validation loss: 3.531632282466954

Epoch: 5| Step: 6
Training loss: 3.683142851885468
Validation loss: 3.578691785055066

Epoch: 5| Step: 7
Training loss: 3.311062770920182
Validation loss: 3.5313696522015308

Epoch: 5| Step: 8
Training loss: 3.388465580446135
Validation loss: 3.522729877770117

Epoch: 5| Step: 9
Training loss: 3.8648225585159115
Validation loss: 3.5243803504970868

Epoch: 5| Step: 10
Training loss: 3.086479042920145
Validation loss: 3.524781408305403

Epoch: 29| Step: 0
Training loss: 3.6880486290346703
Validation loss: 3.520975999198319

Epoch: 5| Step: 1
Training loss: 4.248788324302759
Validation loss: 3.5196915476743746

Epoch: 5| Step: 2
Training loss: 3.386792667202655
Validation loss: 3.5084092101569904

Epoch: 5| Step: 3
Training loss: 4.267818348144493
Validation loss: 3.508381580323751

Epoch: 5| Step: 4
Training loss: 4.339734313848593
Validation loss: 3.5040272075767205

Epoch: 5| Step: 5
Training loss: 3.7196149060673576
Validation loss: 3.4997700404727308

Epoch: 5| Step: 6
Training loss: 2.936743780964587
Validation loss: 3.498039450940768

Epoch: 5| Step: 7
Training loss: 4.174029876017156
Validation loss: 3.4970830387869993

Epoch: 5| Step: 8
Training loss: 3.373491161886115
Validation loss: 3.494411381000349

Epoch: 5| Step: 9
Training loss: 3.0397247142127526
Validation loss: 3.4935447168079548

Epoch: 5| Step: 10
Training loss: 3.300399704048274
Validation loss: 3.492729452366409

Epoch: 30| Step: 0
Training loss: 3.319302753171502
Validation loss: 3.4912439006428473

Epoch: 5| Step: 1
Training loss: 3.8642681778196843
Validation loss: 3.4901049534334656

Epoch: 5| Step: 2
Training loss: 3.3396487173500526
Validation loss: 3.4889457569547857

Epoch: 5| Step: 3
Training loss: 3.4090532439492005
Validation loss: 3.487625100596501

Epoch: 5| Step: 4
Training loss: 3.8219114362675075
Validation loss: 3.488344490106293

Epoch: 5| Step: 5
Training loss: 3.8787429944244662
Validation loss: 3.4872834699616018

Epoch: 5| Step: 6
Training loss: 3.3133232964939965
Validation loss: 3.485340733757077

Epoch: 5| Step: 7
Training loss: 3.9017705028545437
Validation loss: 3.484651841221843

Epoch: 5| Step: 8
Training loss: 3.4993518501683787
Validation loss: 3.4824303070353313

Epoch: 5| Step: 9
Training loss: 4.575196667389074
Validation loss: 3.4823443911925454

Epoch: 5| Step: 10
Training loss: 3.5960518804081394
Validation loss: 3.4796627264064046

Epoch: 31| Step: 0
Training loss: 4.111968291906272
Validation loss: 3.480452156305857

Epoch: 5| Step: 1
Training loss: 3.6234144492195464
Validation loss: 3.4789402483830103

Epoch: 5| Step: 2
Training loss: 3.2109544294147683
Validation loss: 3.4779723732630443

Epoch: 5| Step: 3
Training loss: 4.442632152027942
Validation loss: 3.477787266558362

Epoch: 5| Step: 4
Training loss: 2.8990292009433714
Validation loss: 3.4766585326288135

Epoch: 5| Step: 5
Training loss: 3.8371310426367637
Validation loss: 3.476743151109997

Epoch: 5| Step: 6
Training loss: 4.23397904124814
Validation loss: 3.474762468061243

Epoch: 5| Step: 7
Training loss: 3.585191703150592
Validation loss: 3.4745396442895182

Epoch: 5| Step: 8
Training loss: 3.885141944206896
Validation loss: 3.4743382711883672

Epoch: 5| Step: 9
Training loss: 3.5790878399719883
Validation loss: 3.4734239869125223

Epoch: 5| Step: 10
Training loss: 2.709322929541945
Validation loss: 3.471396383759276

Epoch: 32| Step: 0
Training loss: 3.1719261127732117
Validation loss: 3.4715367941906643

Epoch: 5| Step: 1
Training loss: 4.223900709531356
Validation loss: 3.470928297132453

Epoch: 5| Step: 2
Training loss: 3.74061350681257
Validation loss: 3.471118305130865

Epoch: 5| Step: 3
Training loss: 3.902984352723564
Validation loss: 3.4701381257189645

Epoch: 5| Step: 4
Training loss: 3.653769409671039
Validation loss: 3.4694195246918866

Epoch: 5| Step: 5
Training loss: 3.298907480589706
Validation loss: 3.4679746728565464

Epoch: 5| Step: 6
Training loss: 3.277163622228886
Validation loss: 3.467673830497297

Epoch: 5| Step: 7
Training loss: 3.0620773958058725
Validation loss: 3.4680133064260663

Epoch: 5| Step: 8
Training loss: 3.397034383928255
Validation loss: 3.465664289387463

Epoch: 5| Step: 9
Training loss: 4.179739065832611
Validation loss: 3.4660766907280145

Epoch: 5| Step: 10
Training loss: 4.483468100260633
Validation loss: 3.465548095039206

Epoch: 33| Step: 0
Training loss: 3.2633831597311396
Validation loss: 3.4641581803688855

Epoch: 5| Step: 1
Training loss: 3.149839633310904
Validation loss: 3.46149158831689

Epoch: 5| Step: 2
Training loss: 3.9125625264104458
Validation loss: 3.4620223332511717

Epoch: 5| Step: 3
Training loss: 3.6629046011584165
Validation loss: 3.4621985434900786

Epoch: 5| Step: 4
Training loss: 3.7131490120836115
Validation loss: 3.4600145207430613

Epoch: 5| Step: 5
Training loss: 3.5678820194188297
Validation loss: 3.461515061362754

Epoch: 5| Step: 6
Training loss: 4.130160023173025
Validation loss: 3.46013183075392

Epoch: 5| Step: 7
Training loss: 3.2666532366989074
Validation loss: 3.4593709023521937

Epoch: 5| Step: 8
Training loss: 3.3019404977096483
Validation loss: 3.456459415899698

Epoch: 5| Step: 9
Training loss: 4.038012842257117
Validation loss: 3.456301847984784

Epoch: 5| Step: 10
Training loss: 4.369590466686509
Validation loss: 3.456857475824749

Epoch: 34| Step: 0
Training loss: 2.98351399249412
Validation loss: 3.456142181113387

Epoch: 5| Step: 1
Training loss: 3.728345528384986
Validation loss: 3.454958476703963

Epoch: 5| Step: 2
Training loss: 3.9604417238574903
Validation loss: 3.4552459461789335

Epoch: 5| Step: 3
Training loss: 3.6961754079702946
Validation loss: 3.4551247203050095

Epoch: 5| Step: 4
Training loss: 4.412758855818488
Validation loss: 3.4543844723289268

Epoch: 5| Step: 5
Training loss: 3.7974904507384486
Validation loss: 3.4526738722325576

Epoch: 5| Step: 6
Training loss: 3.783573288107031
Validation loss: 3.451621759658429

Epoch: 5| Step: 7
Training loss: 3.2425048672794703
Validation loss: 3.449993789117973

Epoch: 5| Step: 8
Training loss: 3.7623456549432706
Validation loss: 3.4517143700557305

Epoch: 5| Step: 9
Training loss: 3.5275855842227433
Validation loss: 3.4501709956160287

Epoch: 5| Step: 10
Training loss: 3.252832792059208
Validation loss: 3.4502603236197262

Epoch: 35| Step: 0
Training loss: 3.539771406907398
Validation loss: 3.4507908837053294

Epoch: 5| Step: 1
Training loss: 3.173539349843465
Validation loss: 3.448427686948624

Epoch: 5| Step: 2
Training loss: 3.793182964149201
Validation loss: 3.44982415485755

Epoch: 5| Step: 3
Training loss: 3.5491826956796704
Validation loss: 3.4472522061264077

Epoch: 5| Step: 4
Training loss: 3.66131462730395
Validation loss: 3.4463915712198747

Epoch: 5| Step: 5
Training loss: 3.6086795021203306
Validation loss: 3.4451076504429574

Epoch: 5| Step: 6
Training loss: 4.268572002402825
Validation loss: 3.44522563471469

Epoch: 5| Step: 7
Training loss: 3.7839910487256625
Validation loss: 3.4431578163546077

Epoch: 5| Step: 8
Training loss: 3.6511625450392993
Validation loss: 3.44362645277962

Epoch: 5| Step: 9
Training loss: 3.4600490006521674
Validation loss: 3.443010064011282

Epoch: 5| Step: 10
Training loss: 3.7836220607293085
Validation loss: 3.4413740177918806

Epoch: 36| Step: 0
Training loss: 3.49760136837108
Validation loss: 3.440547008080678

Epoch: 5| Step: 1
Training loss: 3.2442727610337943
Validation loss: 3.4396580519426694

Epoch: 5| Step: 2
Training loss: 3.0775623097685303
Validation loss: 3.439128373702343

Epoch: 5| Step: 3
Training loss: 4.376850281868524
Validation loss: 3.4358444687074954

Epoch: 5| Step: 4
Training loss: 3.530859731527944
Validation loss: 3.4342126947942395

Epoch: 5| Step: 5
Training loss: 3.840423633334177
Validation loss: 3.4318441807955438

Epoch: 5| Step: 6
Training loss: 3.226443235396047
Validation loss: 3.4281610915626834

Epoch: 5| Step: 7
Training loss: 3.580546396850626
Validation loss: 3.4294505778786153

Epoch: 5| Step: 8
Training loss: 4.079864014248007
Validation loss: 3.428235787299538

Epoch: 5| Step: 9
Training loss: 3.6293435218251333
Validation loss: 3.4240120585285507

Epoch: 5| Step: 10
Training loss: 3.96793615452101
Validation loss: 3.4235076133739595

Epoch: 37| Step: 0
Training loss: 4.085487939088727
Validation loss: 3.4218730670846518

Epoch: 5| Step: 1
Training loss: 2.929175248185489
Validation loss: 3.42228696924834

Epoch: 5| Step: 2
Training loss: 4.137124247934389
Validation loss: 3.4211948175954183

Epoch: 5| Step: 3
Training loss: 3.0063495199183157
Validation loss: 3.421786242098244

Epoch: 5| Step: 4
Training loss: 4.437222109407841
Validation loss: 3.4211943814790833

Epoch: 5| Step: 5
Training loss: 3.72436945141979
Validation loss: 3.4197568842330672

Epoch: 5| Step: 6
Training loss: 3.5708068906026806
Validation loss: 3.4199619839137396

Epoch: 5| Step: 7
Training loss: 3.583738230222569
Validation loss: 3.4203233252331313

Epoch: 5| Step: 8
Training loss: 3.9307797925509456
Validation loss: 3.4173188181155525

Epoch: 5| Step: 9
Training loss: 3.352800189637507
Validation loss: 3.4176160022228306

Epoch: 5| Step: 10
Training loss: 2.874217051168294
Validation loss: 3.4176901768198302

Epoch: 38| Step: 0
Training loss: 3.4844393189656366
Validation loss: 3.4172307881101296

Epoch: 5| Step: 1
Training loss: 3.653217068467301
Validation loss: 3.416115373924241

Epoch: 5| Step: 2
Training loss: 3.1484464356553565
Validation loss: 3.414861460799303

Epoch: 5| Step: 3
Training loss: 3.986798794597123
Validation loss: 3.4175552475248825

Epoch: 5| Step: 4
Training loss: 4.024194738738185
Validation loss: 3.418416614822814

Epoch: 5| Step: 5
Training loss: 3.8548084996177936
Validation loss: 3.414182151799704

Epoch: 5| Step: 6
Training loss: 3.5202938020076697
Validation loss: 3.414055770372168

Epoch: 5| Step: 7
Training loss: 3.2958631363850257
Validation loss: 3.4126745041827258

Epoch: 5| Step: 8
Training loss: 3.2273554162484315
Validation loss: 3.4140435275517005

Epoch: 5| Step: 9
Training loss: 3.9519545439449613
Validation loss: 3.414209593344994

Epoch: 5| Step: 10
Training loss: 3.8055301179677667
Validation loss: 3.414006191333809

Epoch: 39| Step: 0
Training loss: 3.512508384178717
Validation loss: 3.414138355699758

Epoch: 5| Step: 1
Training loss: 2.948674152946355
Validation loss: 3.411751775920503

Epoch: 5| Step: 2
Training loss: 2.695277382442194
Validation loss: 3.410616045897111

Epoch: 5| Step: 3
Training loss: 3.78329866256176
Validation loss: 3.4101492164669995

Epoch: 5| Step: 4
Training loss: 3.669103477385012
Validation loss: 3.4081655736076195

Epoch: 5| Step: 5
Training loss: 3.5954477031937717
Validation loss: 3.4087658468688

Epoch: 5| Step: 6
Training loss: 4.454242338579146
Validation loss: 3.410212696659195

Epoch: 5| Step: 7
Training loss: 3.8618867553986402
Validation loss: 3.4116347125098345

Epoch: 5| Step: 8
Training loss: 3.383140918039548
Validation loss: 3.409385465585564

Epoch: 5| Step: 9
Training loss: 3.694341745757726
Validation loss: 3.405990108989115

Epoch: 5| Step: 10
Training loss: 4.160766671398823
Validation loss: 3.407325667358496

Epoch: 40| Step: 0
Training loss: 3.590628952143713
Validation loss: 3.405981609649643

Epoch: 5| Step: 1
Training loss: 3.437039986087854
Validation loss: 3.4052156562111477

Epoch: 5| Step: 2
Training loss: 3.535119561273706
Validation loss: 3.4042499740849244

Epoch: 5| Step: 3
Training loss: 3.4432265699095312
Validation loss: 3.402909681319497

Epoch: 5| Step: 4
Training loss: 4.649685732158348
Validation loss: 3.402205540084075

Epoch: 5| Step: 5
Training loss: 4.040131949356715
Validation loss: 3.4029968236977743

Epoch: 5| Step: 6
Training loss: 3.8561747637910457
Validation loss: 3.400872617525125

Epoch: 5| Step: 7
Training loss: 2.568009106789244
Validation loss: 3.4017769874918433

Epoch: 5| Step: 8
Training loss: 2.8222099536302014
Validation loss: 3.400434498647809

Epoch: 5| Step: 9
Training loss: 3.770394371715208
Validation loss: 3.400521886898454

Epoch: 5| Step: 10
Training loss: 3.82641152161545
Validation loss: 3.399052461630635

Epoch: 41| Step: 0
Training loss: 3.6609907145586917
Validation loss: 3.398857105693406

Epoch: 5| Step: 1
Training loss: 2.723938474467275
Validation loss: 3.3987622826383217

Epoch: 5| Step: 2
Training loss: 3.8894799933712796
Validation loss: 3.3994404905465863

Epoch: 5| Step: 3
Training loss: 3.6276936224509893
Validation loss: 3.39819408540296

Epoch: 5| Step: 4
Training loss: 4.462216168948759
Validation loss: 3.397534761342231

Epoch: 5| Step: 5
Training loss: 2.9366841908111363
Validation loss: 3.39677020889767

Epoch: 5| Step: 6
Training loss: 3.452552437242508
Validation loss: 3.395877679056772

Epoch: 5| Step: 7
Training loss: 3.496174901947459
Validation loss: 3.3956296945151774

Epoch: 5| Step: 8
Training loss: 3.6449459776256727
Validation loss: 3.394614715118355

Epoch: 5| Step: 9
Training loss: 3.6984274641254573
Validation loss: 3.394403242702519

Epoch: 5| Step: 10
Training loss: 4.040143279754725
Validation loss: 3.3936245638426517

Epoch: 42| Step: 0
Training loss: 3.2131444024963995
Validation loss: 3.3951620292355864

Epoch: 5| Step: 1
Training loss: 3.497636542010173
Validation loss: 3.393620671872907

Epoch: 5| Step: 2
Training loss: 3.4050104528146248
Validation loss: 3.3931911136054036

Epoch: 5| Step: 3
Training loss: 3.8933363203359495
Validation loss: 3.3909243134053715

Epoch: 5| Step: 4
Training loss: 2.905416061362645
Validation loss: 3.3937517884556683

Epoch: 5| Step: 5
Training loss: 3.427708500169434
Validation loss: 3.392616665028323

Epoch: 5| Step: 6
Training loss: 3.807169830975131
Validation loss: 3.3919254215663046

Epoch: 5| Step: 7
Training loss: 3.6911409151498353
Validation loss: 3.3915835619480545

Epoch: 5| Step: 8
Training loss: 4.527615477312577
Validation loss: 3.3899292696832357

Epoch: 5| Step: 9
Training loss: 3.64318875264713
Validation loss: 3.391159445715373

Epoch: 5| Step: 10
Training loss: 3.5738782710098134
Validation loss: 3.3888881093179024

Epoch: 43| Step: 0
Training loss: 3.6531266133326876
Validation loss: 3.389304201577434

Epoch: 5| Step: 1
Training loss: 3.355033588724519
Validation loss: 3.3878451836514305

Epoch: 5| Step: 2
Training loss: 3.108050193538418
Validation loss: 3.389196513932241

Epoch: 5| Step: 3
Training loss: 4.073069277714835
Validation loss: 3.388250179447603

Epoch: 5| Step: 4
Training loss: 4.063281409599713
Validation loss: 3.387357459459609

Epoch: 5| Step: 5
Training loss: 3.9290610813316404
Validation loss: 3.3867669443505446

Epoch: 5| Step: 6
Training loss: 3.0989253365605873
Validation loss: 3.385831922079901

Epoch: 5| Step: 7
Training loss: 3.633966734268359
Validation loss: 3.3844437607659352

Epoch: 5| Step: 8
Training loss: 3.8161875916921786
Validation loss: 3.385385124621238

Epoch: 5| Step: 9
Training loss: 3.3602847264767854
Validation loss: 3.383596962934996

Epoch: 5| Step: 10
Training loss: 3.5043872856032277
Validation loss: 3.385395842962218

Epoch: 44| Step: 0
Training loss: 4.109603121267436
Validation loss: 3.383716582842682

Epoch: 5| Step: 1
Training loss: 3.225677294914247
Validation loss: 3.383943434767823

Epoch: 5| Step: 2
Training loss: 3.808949051936639
Validation loss: 3.3831224238692243

Epoch: 5| Step: 3
Training loss: 2.7129843072940054
Validation loss: 3.3816674207118074

Epoch: 5| Step: 4
Training loss: 3.2227663333470935
Validation loss: 3.381247498446877

Epoch: 5| Step: 5
Training loss: 4.537125139541597
Validation loss: 3.380660880083261

Epoch: 5| Step: 6
Training loss: 3.7813829130662624
Validation loss: 3.3837002101924294

Epoch: 5| Step: 7
Training loss: 3.7657133859732146
Validation loss: 3.382144160478478

Epoch: 5| Step: 8
Training loss: 3.915249764378802
Validation loss: 3.3808957298175653

Epoch: 5| Step: 9
Training loss: 3.1380153460738245
Validation loss: 3.379926176417239

Epoch: 5| Step: 10
Training loss: 3.004420044293286
Validation loss: 3.3810857688247182

Epoch: 45| Step: 0
Training loss: 3.34356817303709
Validation loss: 3.378640772870018

Epoch: 5| Step: 1
Training loss: 3.5872938462415127
Validation loss: 3.379818565434348

Epoch: 5| Step: 2
Training loss: 3.7374349531044047
Validation loss: 3.378361923850623

Epoch: 5| Step: 3
Training loss: 3.3965732415865
Validation loss: 3.3791802669760416

Epoch: 5| Step: 4
Training loss: 2.8350949888109667
Validation loss: 3.37881376694845

Epoch: 5| Step: 5
Training loss: 3.8643339475931047
Validation loss: 3.379410460114441

Epoch: 5| Step: 6
Training loss: 3.3945226811870417
Validation loss: 3.3774887230823154

Epoch: 5| Step: 7
Training loss: 3.4343878790047273
Validation loss: 3.3793812233174747

Epoch: 5| Step: 8
Training loss: 3.740351790136464
Validation loss: 3.3781818080609596

Epoch: 5| Step: 9
Training loss: 3.934970224696813
Validation loss: 3.376888808530418

Epoch: 5| Step: 10
Training loss: 4.313357945115999
Validation loss: 3.3747905619121976

Epoch: 46| Step: 0
Training loss: 4.362592268790534
Validation loss: 3.377221002977604

Epoch: 5| Step: 1
Training loss: 3.0311552996442668
Validation loss: 3.374837013845464

Epoch: 5| Step: 2
Training loss: 3.83568726012788
Validation loss: 3.3747793389076786

Epoch: 5| Step: 3
Training loss: 3.2578758764162967
Validation loss: 3.374538815495506

Epoch: 5| Step: 4
Training loss: 3.4828687756571113
Validation loss: 3.373831901932906

Epoch: 5| Step: 5
Training loss: 3.002192490812688
Validation loss: 3.3731590804452773

Epoch: 5| Step: 6
Training loss: 3.1403028028719757
Validation loss: 3.3779863341890413

Epoch: 5| Step: 7
Training loss: 4.0260136625131056
Validation loss: 3.3742950900433097

Epoch: 5| Step: 8
Training loss: 4.223620055074663
Validation loss: 3.3727347543799606

Epoch: 5| Step: 9
Training loss: 3.5325205719842168
Validation loss: 3.374541293639377

Epoch: 5| Step: 10
Training loss: 3.3567270177916844
Validation loss: 3.379432482371292

Epoch: 47| Step: 0
Training loss: 3.934020791080769
Validation loss: 3.3768517561610953

Epoch: 5| Step: 1
Training loss: 3.9300997993668556
Validation loss: 3.3710386088531625

Epoch: 5| Step: 2
Training loss: 3.236578886162446
Validation loss: 3.3706146303951683

Epoch: 5| Step: 3
Training loss: 3.0231581763433906
Validation loss: 3.369963332863705

Epoch: 5| Step: 4
Training loss: 3.603427892097657
Validation loss: 3.368260013345563

Epoch: 5| Step: 5
Training loss: 4.0562012186041345
Validation loss: 3.3715150266398983

Epoch: 5| Step: 6
Training loss: 3.8465057666873683
Validation loss: 3.3699724601198953

Epoch: 5| Step: 7
Training loss: 3.7453979227814482
Validation loss: 3.3671381818073103

Epoch: 5| Step: 8
Training loss: 3.071138304875067
Validation loss: 3.3682359223777456

Epoch: 5| Step: 9
Training loss: 3.937279831316638
Validation loss: 3.3643939298513668

Epoch: 5| Step: 10
Training loss: 2.8223642087831724
Validation loss: 3.365784663038416

Epoch: 48| Step: 0
Training loss: 3.2291722123293276
Validation loss: 3.367257947869788

Epoch: 5| Step: 1
Training loss: 3.5142169760694943
Validation loss: 3.369536425344637

Epoch: 5| Step: 2
Training loss: 3.3684098222350833
Validation loss: 3.3690194131056304

Epoch: 5| Step: 3
Training loss: 3.3971419046188207
Validation loss: 3.370608912308481

Epoch: 5| Step: 4
Training loss: 3.5004906991574334
Validation loss: 3.3663300176451396

Epoch: 5| Step: 5
Training loss: 3.961641809569808
Validation loss: 3.3658813778661085

Epoch: 5| Step: 6
Training loss: 3.5591010225197284
Validation loss: 3.3637038450105234

Epoch: 5| Step: 7
Training loss: 3.6879233424397415
Validation loss: 3.3629912387535126

Epoch: 5| Step: 8
Training loss: 3.492968580723338
Validation loss: 3.359946827394509

Epoch: 5| Step: 9
Training loss: 3.9112026708414716
Validation loss: 3.3627272664842

Epoch: 5| Step: 10
Training loss: 3.871389244957696
Validation loss: 3.359997502444209

Epoch: 49| Step: 0
Training loss: 3.6042441357939774
Validation loss: 3.3608037186047404

Epoch: 5| Step: 1
Training loss: 3.642826184373625
Validation loss: 3.359978290330001

Epoch: 5| Step: 2
Training loss: 3.3750669684653634
Validation loss: 3.360564242441743

Epoch: 5| Step: 3
Training loss: 3.9253906055639862
Validation loss: 3.359782334224564

Epoch: 5| Step: 4
Training loss: 3.839653251012739
Validation loss: 3.357190475035147

Epoch: 5| Step: 5
Training loss: 3.5262269610464023
Validation loss: 3.358326634303389

Epoch: 5| Step: 6
Training loss: 3.4214185993880917
Validation loss: 3.3591996662528096

Epoch: 5| Step: 7
Training loss: 3.2476625106123502
Validation loss: 3.3564256996803525

Epoch: 5| Step: 8
Training loss: 4.01765645812672
Validation loss: 3.358325782384078

Epoch: 5| Step: 9
Training loss: 3.7502810055033553
Validation loss: 3.3564125210354727

Epoch: 5| Step: 10
Training loss: 2.8763112933919617
Validation loss: 3.356199655915084

Epoch: 50| Step: 0
Training loss: 4.305829403826677
Validation loss: 3.3547218753413315

Epoch: 5| Step: 1
Training loss: 3.634901533091844
Validation loss: 3.354743481943786

Epoch: 5| Step: 2
Training loss: 3.4896196657633234
Validation loss: 3.3550238110598536

Epoch: 5| Step: 3
Training loss: 3.803954756907939
Validation loss: 3.3532750366162976

Epoch: 5| Step: 4
Training loss: 3.3874812164348924
Validation loss: 3.35301552301851

Epoch: 5| Step: 5
Training loss: 3.444022077553904
Validation loss: 3.3522573402362985

Epoch: 5| Step: 6
Training loss: 3.430006703183934
Validation loss: 3.3535594284783397

Epoch: 5| Step: 7
Training loss: 3.8985415886263817
Validation loss: 3.3521201457692134

Epoch: 5| Step: 8
Training loss: 3.429859061501317
Validation loss: 3.3505859237276234

Epoch: 5| Step: 9
Training loss: 2.921991192960424
Validation loss: 3.3524110102775917

Epoch: 5| Step: 10
Training loss: 3.4973430085139863
Validation loss: 3.3505688520581054

Epoch: 51| Step: 0
Training loss: 3.64967237073361
Validation loss: 3.350445460904428

Epoch: 5| Step: 1
Training loss: 3.261685710442693
Validation loss: 3.3516577940798364

Epoch: 5| Step: 2
Training loss: 3.6133277024041064
Validation loss: 3.3507680982435772

Epoch: 5| Step: 3
Training loss: 3.479142301249512
Validation loss: 3.3486478790471645

Epoch: 5| Step: 4
Training loss: 4.204835224710687
Validation loss: 3.3502810705433936

Epoch: 5| Step: 5
Training loss: 3.0942755358757155
Validation loss: 3.3500181644849025

Epoch: 5| Step: 6
Training loss: 2.896775584073586
Validation loss: 3.3495577544618165

Epoch: 5| Step: 7
Training loss: 4.298798175795834
Validation loss: 3.3512045477937833

Epoch: 5| Step: 8
Training loss: 3.7492881099185693
Validation loss: 3.3503036684025944

Epoch: 5| Step: 9
Training loss: 3.244144446584895
Validation loss: 3.3500253992613147

Epoch: 5| Step: 10
Training loss: 3.5929166408077116
Validation loss: 3.351082280144329

Epoch: 52| Step: 0
Training loss: 3.0975555749915338
Validation loss: 3.3523176035672484

Epoch: 5| Step: 1
Training loss: 3.561010886051686
Validation loss: 3.3529322181934265

Epoch: 5| Step: 2
Training loss: 3.2082025245323162
Validation loss: 3.3502652430748787

Epoch: 5| Step: 3
Training loss: 3.3712987030777226
Validation loss: 3.352802595152327

Epoch: 5| Step: 4
Training loss: 3.9107575311527896
Validation loss: 3.351592152334768

Epoch: 5| Step: 5
Training loss: 3.142932556535638
Validation loss: 3.3501997730022897

Epoch: 5| Step: 6
Training loss: 4.329638935919448
Validation loss: 3.3449673472730046

Epoch: 5| Step: 7
Training loss: 3.735176543081116
Validation loss: 3.343323275631813

Epoch: 5| Step: 8
Training loss: 3.807429083741701
Validation loss: 3.34222001424745

Epoch: 5| Step: 9
Training loss: 3.7834970402414254
Validation loss: 3.3446129233697324

Epoch: 5| Step: 10
Training loss: 3.0814844378874255
Validation loss: 3.3413621305594057

Epoch: 53| Step: 0
Training loss: 3.171718198912537
Validation loss: 3.3430588607603267

Epoch: 5| Step: 1
Training loss: 2.4901843974764315
Validation loss: 3.3411377409311074

Epoch: 5| Step: 2
Training loss: 4.147670294155329
Validation loss: 3.3413113769716842

Epoch: 5| Step: 3
Training loss: 4.10405871770544
Validation loss: 3.338351542879368

Epoch: 5| Step: 4
Training loss: 3.1732352210620123
Validation loss: 3.338711123411438

Epoch: 5| Step: 5
Training loss: 3.819329819934055
Validation loss: 3.3384948121057825

Epoch: 5| Step: 6
Training loss: 3.2554743218151114
Validation loss: 3.339824394319188

Epoch: 5| Step: 7
Training loss: 3.990024764670097
Validation loss: 3.34151601778365

Epoch: 5| Step: 8
Training loss: 4.03553437845926
Validation loss: 3.3395783933096426

Epoch: 5| Step: 9
Training loss: 3.5394933577236896
Validation loss: 3.3402431108944173

Epoch: 5| Step: 10
Training loss: 3.105966971875796
Validation loss: 3.341653767292014

Epoch: 54| Step: 0
Training loss: 4.128083896937688
Validation loss: 3.337728880624457

Epoch: 5| Step: 1
Training loss: 3.068469088685394
Validation loss: 3.336414719258512

Epoch: 5| Step: 2
Training loss: 4.15209064447908
Validation loss: 3.334737104243416

Epoch: 5| Step: 3
Training loss: 3.801605793823618
Validation loss: 3.3342257617636073

Epoch: 5| Step: 4
Training loss: 3.1056195300463436
Validation loss: 3.333042589449079

Epoch: 5| Step: 5
Training loss: 3.8553054914142546
Validation loss: 3.332523769595482

Epoch: 5| Step: 6
Training loss: 3.871082294343229
Validation loss: 3.3343385585569574

Epoch: 5| Step: 7
Training loss: 2.9264304812054096
Validation loss: 3.333092412138168

Epoch: 5| Step: 8
Training loss: 3.6108930293686985
Validation loss: 3.3313054766521533

Epoch: 5| Step: 9
Training loss: 2.4492449355969117
Validation loss: 3.330096437998514

Epoch: 5| Step: 10
Training loss: 3.8843482681790853
Validation loss: 3.3301413932575734

Epoch: 55| Step: 0
Training loss: 4.333973592750783
Validation loss: 3.3305318647713977

Epoch: 5| Step: 1
Training loss: 3.8091388331895564
Validation loss: 3.3334482655143494

Epoch: 5| Step: 2
Training loss: 3.241400271520758
Validation loss: 3.332037077375477

Epoch: 5| Step: 3
Training loss: 3.9290331680633837
Validation loss: 3.3316738786858227

Epoch: 5| Step: 4
Training loss: 2.8636625902480435
Validation loss: 3.332055314979053

Epoch: 5| Step: 5
Training loss: 3.9563112950209507
Validation loss: 3.332737899225422

Epoch: 5| Step: 6
Training loss: 3.9916248858235637
Validation loss: 3.3349739979735484

Epoch: 5| Step: 7
Training loss: 3.0704620557862214
Validation loss: 3.3306649807929722

Epoch: 5| Step: 8
Training loss: 3.1809355514794726
Validation loss: 3.330155069248168

Epoch: 5| Step: 9
Training loss: 3.517281510779912
Validation loss: 3.3287454847350686

Epoch: 5| Step: 10
Training loss: 2.7888145015956693
Validation loss: 3.3275522234765167

Epoch: 56| Step: 0
Training loss: 4.240263388388188
Validation loss: 3.326260946081708

Epoch: 5| Step: 1
Training loss: 3.6164642335928674
Validation loss: 3.3266249253300333

Epoch: 5| Step: 2
Training loss: 3.929714680572004
Validation loss: 3.3289564088754857

Epoch: 5| Step: 3
Training loss: 3.380615930811318
Validation loss: 3.328796541583154

Epoch: 5| Step: 4
Training loss: 3.352141785966497
Validation loss: 3.3269771984772114

Epoch: 5| Step: 5
Training loss: 3.5765240015146893
Validation loss: 3.3275971992399485

Epoch: 5| Step: 6
Training loss: 3.225396118676819
Validation loss: 3.3259341492943437

Epoch: 5| Step: 7
Training loss: 3.0465280188545005
Validation loss: 3.328318561997272

Epoch: 5| Step: 8
Training loss: 3.586436650394098
Validation loss: 3.3260398894776007

Epoch: 5| Step: 9
Training loss: 3.3447661950206666
Validation loss: 3.326720893675676

Epoch: 5| Step: 10
Training loss: 3.672805862933585
Validation loss: 3.326177054423164

Epoch: 57| Step: 0
Training loss: 3.7170231760783934
Validation loss: 3.325584730480616

Epoch: 5| Step: 1
Training loss: 3.650923280342959
Validation loss: 3.3241838159561135

Epoch: 5| Step: 2
Training loss: 3.518818129969112
Validation loss: 3.3219286218342963

Epoch: 5| Step: 3
Training loss: 3.7527300751543233
Validation loss: 3.321079733296184

Epoch: 5| Step: 4
Training loss: 3.734079772260559
Validation loss: 3.321687738375936

Epoch: 5| Step: 5
Training loss: 2.733204792845979
Validation loss: 3.3220236469980056

Epoch: 5| Step: 6
Training loss: 3.6562537820910594
Validation loss: 3.321507628140022

Epoch: 5| Step: 7
Training loss: 3.775633368505743
Validation loss: 3.322513889329484

Epoch: 5| Step: 8
Training loss: 3.8441810676331976
Validation loss: 3.319894642700693

Epoch: 5| Step: 9
Training loss: 3.235347730528971
Validation loss: 3.3194139084764647

Epoch: 5| Step: 10
Training loss: 3.2386771812482915
Validation loss: 3.3165920318633906

Epoch: 58| Step: 0
Training loss: 3.130714532139666
Validation loss: 3.3163804465697595

Epoch: 5| Step: 1
Training loss: 3.7353654768940188
Validation loss: 3.317709061487685

Epoch: 5| Step: 2
Training loss: 2.906988234741212
Validation loss: 3.315780807359606

Epoch: 5| Step: 3
Training loss: 3.544101252295628
Validation loss: 3.315445460121417

Epoch: 5| Step: 4
Training loss: 3.754557319889385
Validation loss: 3.3162626634973686

Epoch: 5| Step: 5
Training loss: 4.22946163457996
Validation loss: 3.3150019454201747

Epoch: 5| Step: 6
Training loss: 2.815010137455034
Validation loss: 3.314117583079954

Epoch: 5| Step: 7
Training loss: 3.2288014031016816
Validation loss: 3.3145395440330283

Epoch: 5| Step: 8
Training loss: 3.620947710402923
Validation loss: 3.313939427833352

Epoch: 5| Step: 9
Training loss: 3.5885530793664144
Validation loss: 3.3154651158667954

Epoch: 5| Step: 10
Training loss: 4.250276444364016
Validation loss: 3.3151658101114254

Epoch: 59| Step: 0
Training loss: 3.6337839447945015
Validation loss: 3.3171478002480477

Epoch: 5| Step: 1
Training loss: 3.504414635290059
Validation loss: 3.3171934171023976

Epoch: 5| Step: 2
Training loss: 3.2322039850562008
Validation loss: 3.3223202376142664

Epoch: 5| Step: 3
Training loss: 3.261302807264512
Validation loss: 3.3143840090354244

Epoch: 5| Step: 4
Training loss: 3.302054291766925
Validation loss: 3.3138130883907007

Epoch: 5| Step: 5
Training loss: 2.986573213608148
Validation loss: 3.31166817081939

Epoch: 5| Step: 6
Training loss: 3.734574955012216
Validation loss: 3.311491904367439

Epoch: 5| Step: 7
Training loss: 3.849690135029336
Validation loss: 3.310854270225885

Epoch: 5| Step: 8
Training loss: 3.873446614638265
Validation loss: 3.3092279958166704

Epoch: 5| Step: 9
Training loss: 3.419377639314877
Validation loss: 3.3111552896718437

Epoch: 5| Step: 10
Training loss: 4.135396398435389
Validation loss: 3.3093740527145568

Epoch: 60| Step: 0
Training loss: 3.4901693430916834
Validation loss: 3.307412701750493

Epoch: 5| Step: 1
Training loss: 3.5512278730219395
Validation loss: 3.306203788655984

Epoch: 5| Step: 2
Training loss: 3.7804239174631644
Validation loss: 3.306720748250542

Epoch: 5| Step: 3
Training loss: 2.7166889314577727
Validation loss: 3.3065635033940906

Epoch: 5| Step: 4
Training loss: 3.4423425030884616
Validation loss: 3.3068308581502897

Epoch: 5| Step: 5
Training loss: 4.449770657919468
Validation loss: 3.3076822882357497

Epoch: 5| Step: 6
Training loss: 3.5752010475660776
Validation loss: 3.3083453647597985

Epoch: 5| Step: 7
Training loss: 3.4055245003071675
Validation loss: 3.3063049213835067

Epoch: 5| Step: 8
Training loss: 3.3303338542753664
Validation loss: 3.3065671628964988

Epoch: 5| Step: 9
Training loss: 3.525005118724813
Validation loss: 3.3091059598197523

Epoch: 5| Step: 10
Training loss: 3.4180618011887387
Validation loss: 3.3085647149565136

Epoch: 61| Step: 0
Training loss: 3.6359967458477502
Validation loss: 3.305110636185391

Epoch: 5| Step: 1
Training loss: 3.7604326721583434
Validation loss: 3.3076546325543386

Epoch: 5| Step: 2
Training loss: 4.175852047897259
Validation loss: 3.3064952064119497

Epoch: 5| Step: 3
Training loss: 3.352613591055518
Validation loss: 3.3024855599346923

Epoch: 5| Step: 4
Training loss: 3.7585648955222974
Validation loss: 3.3016642663680718

Epoch: 5| Step: 5
Training loss: 3.0454005659746586
Validation loss: 3.3021243140634122

Epoch: 5| Step: 6
Training loss: 2.9422473287551636
Validation loss: 3.300780175078959

Epoch: 5| Step: 7
Training loss: 3.258415477396927
Validation loss: 3.3008146127654365

Epoch: 5| Step: 8
Training loss: 3.3970436482470614
Validation loss: 3.301402613830312

Epoch: 5| Step: 9
Training loss: 3.5299585732252616
Validation loss: 3.300365345924108

Epoch: 5| Step: 10
Training loss: 3.8880853292026196
Validation loss: 3.3013372929707834

Epoch: 62| Step: 0
Training loss: 3.8034638428647503
Validation loss: 3.2996544318615735

Epoch: 5| Step: 1
Training loss: 3.4815385846113633
Validation loss: 3.2981896127089287

Epoch: 5| Step: 2
Training loss: 3.3871530784521204
Validation loss: 3.298144979020166

Epoch: 5| Step: 3
Training loss: 3.989404593000418
Validation loss: 3.296584694647008

Epoch: 5| Step: 4
Training loss: 2.987887726846058
Validation loss: 3.2966842125717353

Epoch: 5| Step: 5
Training loss: 3.811741112395012
Validation loss: 3.297780194782443

Epoch: 5| Step: 6
Training loss: 3.476070617853961
Validation loss: 3.298319729577532

Epoch: 5| Step: 7
Training loss: 3.2751160462763984
Validation loss: 3.3001636268791734

Epoch: 5| Step: 8
Training loss: 3.4891611935178037
Validation loss: 3.300605638675452

Epoch: 5| Step: 9
Training loss: 3.460106054455709
Validation loss: 3.2958403146010045

Epoch: 5| Step: 10
Training loss: 3.5778018189116785
Validation loss: 3.294057228523435

Epoch: 63| Step: 0
Training loss: 3.516302424967945
Validation loss: 3.296580601012555

Epoch: 5| Step: 1
Training loss: 3.9128898645739003
Validation loss: 3.294920577198843

Epoch: 5| Step: 2
Training loss: 3.8387416061165505
Validation loss: 3.295318607835455

Epoch: 5| Step: 3
Training loss: 3.7490235646896957
Validation loss: 3.2954395495210576

Epoch: 5| Step: 4
Training loss: 2.5682187350098733
Validation loss: 3.2957821222257397

Epoch: 5| Step: 5
Training loss: 3.475414575230783
Validation loss: 3.2944009799517167

Epoch: 5| Step: 6
Training loss: 3.3769836247899705
Validation loss: 3.294428985014734

Epoch: 5| Step: 7
Training loss: 3.729171255666513
Validation loss: 3.2936220686449724

Epoch: 5| Step: 8
Training loss: 3.9018620374135207
Validation loss: 3.2937784509449073

Epoch: 5| Step: 9
Training loss: 3.428333336646699
Validation loss: 3.2936156743690583

Epoch: 5| Step: 10
Training loss: 2.934927442911291
Validation loss: 3.2920422358581245

Epoch: 64| Step: 0
Training loss: 2.9631035362999882
Validation loss: 3.291038478682993

Epoch: 5| Step: 1
Training loss: 4.06316499402581
Validation loss: 3.291093687378843

Epoch: 5| Step: 2
Training loss: 3.497318603087088
Validation loss: 3.2912610449097635

Epoch: 5| Step: 3
Training loss: 3.2764121585494137
Validation loss: 3.28984540215353

Epoch: 5| Step: 4
Training loss: 3.553609764292157
Validation loss: 3.290027498961341

Epoch: 5| Step: 5
Training loss: 3.731336818177045
Validation loss: 3.289243439872487

Epoch: 5| Step: 6
Training loss: 3.4332746025420047
Validation loss: 3.2896738953123417

Epoch: 5| Step: 7
Training loss: 3.747731603549167
Validation loss: 3.2905045414437333

Epoch: 5| Step: 8
Training loss: 3.296823510224404
Validation loss: 3.29097828664187

Epoch: 5| Step: 9
Training loss: 3.3754082891961996
Validation loss: 3.291414255599941

Epoch: 5| Step: 10
Training loss: 3.6806511072835146
Validation loss: 3.2893612910328316

Epoch: 65| Step: 0
Training loss: 4.1094515833227465
Validation loss: 3.288403301643993

Epoch: 5| Step: 1
Training loss: 3.2735595680365126
Validation loss: 3.288511325983189

Epoch: 5| Step: 2
Training loss: 3.7213553910712793
Validation loss: 3.2882785304645257

Epoch: 5| Step: 3
Training loss: 1.989782100421909
Validation loss: 3.2858354661992597

Epoch: 5| Step: 4
Training loss: 3.7972547553143987
Validation loss: 3.286172617295301

Epoch: 5| Step: 5
Training loss: 3.1155541139303957
Validation loss: 3.284609115991072

Epoch: 5| Step: 6
Training loss: 3.707584062524878
Validation loss: 3.284592478790037

Epoch: 5| Step: 7
Training loss: 3.190315499085257
Validation loss: 3.2838448666679336

Epoch: 5| Step: 8
Training loss: 3.7545324273694782
Validation loss: 3.2835451192613014

Epoch: 5| Step: 9
Training loss: 3.860748293789753
Validation loss: 3.2828493391720803

Epoch: 5| Step: 10
Training loss: 3.678300794680204
Validation loss: 3.2839457058945287

Epoch: 66| Step: 0
Training loss: 3.591802716315261
Validation loss: 3.2820444390525445

Epoch: 5| Step: 1
Training loss: 3.2701590424104285
Validation loss: 3.2826593086573093

Epoch: 5| Step: 2
Training loss: 3.7743983970405828
Validation loss: 3.2802370772756984

Epoch: 5| Step: 3
Training loss: 3.5470388769530987
Validation loss: 3.2806435629636015

Epoch: 5| Step: 4
Training loss: 2.869182505863495
Validation loss: 3.284114729756546

Epoch: 5| Step: 5
Training loss: 3.815726119067623
Validation loss: 3.280474464971402

Epoch: 5| Step: 6
Training loss: 3.59919088065948
Validation loss: 3.2804746947278987

Epoch: 5| Step: 7
Training loss: 2.844451147144421
Validation loss: 3.2811345968349346

Epoch: 5| Step: 8
Training loss: 3.9253931565399465
Validation loss: 3.2794594844131533

Epoch: 5| Step: 9
Training loss: 3.4576256882115324
Validation loss: 3.2780056103650446

Epoch: 5| Step: 10
Training loss: 3.7841653225533802
Validation loss: 3.277821169614024

Epoch: 67| Step: 0
Training loss: 3.775617455517727
Validation loss: 3.2769792162310134

Epoch: 5| Step: 1
Training loss: 4.020529516465889
Validation loss: 3.276767410802446

Epoch: 5| Step: 2
Training loss: 3.0152467480556475
Validation loss: 3.276605487751786

Epoch: 5| Step: 3
Training loss: 3.449539048734291
Validation loss: 3.2758564378807513

Epoch: 5| Step: 4
Training loss: 3.2119352920494055
Validation loss: 3.279216023831873

Epoch: 5| Step: 5
Training loss: 2.7048962032689876
Validation loss: 3.2762343348733993

Epoch: 5| Step: 6
Training loss: 3.5068027597810945
Validation loss: 3.274615702547544

Epoch: 5| Step: 7
Training loss: 3.67483634843855
Validation loss: 3.271133636886854

Epoch: 5| Step: 8
Training loss: 3.719423633758112
Validation loss: 3.2715579290298926

Epoch: 5| Step: 9
Training loss: 4.035870410392586
Validation loss: 3.2721569021285837

Epoch: 5| Step: 10
Training loss: 3.165323491250184
Validation loss: 3.2698406178432706

Epoch: 68| Step: 0
Training loss: 3.7907739922913266
Validation loss: 3.2714408408047686

Epoch: 5| Step: 1
Training loss: 3.5266750711534396
Validation loss: 3.270152811571219

Epoch: 5| Step: 2
Training loss: 2.483108389563877
Validation loss: 3.2681301882282803

Epoch: 5| Step: 3
Training loss: 3.611980604168258
Validation loss: 3.268200054888008

Epoch: 5| Step: 4
Training loss: 4.089207116012404
Validation loss: 3.2683865657540374

Epoch: 5| Step: 5
Training loss: 4.078065133660202
Validation loss: 3.268347724843165

Epoch: 5| Step: 6
Training loss: 3.3421327476778337
Validation loss: 3.2675721089190564

Epoch: 5| Step: 7
Training loss: 3.7660041080073614
Validation loss: 3.2669926710695028

Epoch: 5| Step: 8
Training loss: 3.582568345732327
Validation loss: 3.266681564398374

Epoch: 5| Step: 9
Training loss: 3.066749582690065
Validation loss: 3.2658091459478196

Epoch: 5| Step: 10
Training loss: 2.695321699486112
Validation loss: 3.2672621433704045

Epoch: 69| Step: 0
Training loss: 2.7797447160104007
Validation loss: 3.267380501773856

Epoch: 5| Step: 1
Training loss: 3.5874907011649277
Validation loss: 3.274705177794589

Epoch: 5| Step: 2
Training loss: 3.428666712367872
Validation loss: 3.275666332741579

Epoch: 5| Step: 3
Training loss: 3.7875087423192215
Validation loss: 3.2789224849695415

Epoch: 5| Step: 4
Training loss: 3.476889194183204
Validation loss: 3.2718128775171813

Epoch: 5| Step: 5
Training loss: 3.2265888056017564
Validation loss: 3.264100134186617

Epoch: 5| Step: 6
Training loss: 3.8223517032495793
Validation loss: 3.262778051780702

Epoch: 5| Step: 7
Training loss: 3.814959373807762
Validation loss: 3.2626801256202036

Epoch: 5| Step: 8
Training loss: 2.889166221592945
Validation loss: 3.2690272729915875

Epoch: 5| Step: 9
Training loss: 3.556075879277562
Validation loss: 3.2797128431539937

Epoch: 5| Step: 10
Training loss: 4.025616161500786
Validation loss: 3.2638514262114673

Epoch: 70| Step: 0
Training loss: 3.3107178410407974
Validation loss: 3.2630669887192454

Epoch: 5| Step: 1
Training loss: 4.234151348668658
Validation loss: 3.2667166064021407

Epoch: 5| Step: 2
Training loss: 3.2721466214035844
Validation loss: 3.2715157608880028

Epoch: 5| Step: 3
Training loss: 3.2407661723597294
Validation loss: 3.269910349955862

Epoch: 5| Step: 4
Training loss: 3.3069845382379732
Validation loss: 3.267773417227948

Epoch: 5| Step: 5
Training loss: 3.131423604268141
Validation loss: 3.265993570374467

Epoch: 5| Step: 6
Training loss: 3.069631564121845
Validation loss: 3.263676617894354

Epoch: 5| Step: 7
Training loss: 3.341561572799761
Validation loss: 3.2640239285894475

Epoch: 5| Step: 8
Training loss: 4.0139189780991025
Validation loss: 3.263554737932686

Epoch: 5| Step: 9
Training loss: 3.7703342985684207
Validation loss: 3.2607457333224894

Epoch: 5| Step: 10
Training loss: 3.59592537760297
Validation loss: 3.260045346749257

Epoch: 71| Step: 0
Training loss: 3.8670720863459596
Validation loss: 3.2606538661859568

Epoch: 5| Step: 1
Training loss: 3.929272002139439
Validation loss: 3.258467248370319

Epoch: 5| Step: 2
Training loss: 3.629358499554175
Validation loss: 3.257262191235868

Epoch: 5| Step: 3
Training loss: 3.541903873054642
Validation loss: 3.2576611904896717

Epoch: 5| Step: 4
Training loss: 3.3105180677212718
Validation loss: 3.25735699835873

Epoch: 5| Step: 5
Training loss: 2.772449500102993
Validation loss: 3.2590566864848656

Epoch: 5| Step: 6
Training loss: 3.2123102748077965
Validation loss: 3.2563449413315237

Epoch: 5| Step: 7
Training loss: 3.3222046251656696
Validation loss: 3.2550197342248457

Epoch: 5| Step: 8
Training loss: 3.079943898916211
Validation loss: 3.255583400981252

Epoch: 5| Step: 9
Training loss: 3.626566844248933
Validation loss: 3.2533271267399857

Epoch: 5| Step: 10
Training loss: 3.9966302028728684
Validation loss: 3.2533848634124087

Epoch: 72| Step: 0
Training loss: 4.020006928319322
Validation loss: 3.253699951896331

Epoch: 5| Step: 1
Training loss: 4.193317983464791
Validation loss: 3.25252643953649

Epoch: 5| Step: 2
Training loss: 3.162926288567152
Validation loss: 3.2496431168959634

Epoch: 5| Step: 3
Training loss: 2.087986314969872
Validation loss: 3.249964273696552

Epoch: 5| Step: 4
Training loss: 3.5264360140662854
Validation loss: 3.251333467974824

Epoch: 5| Step: 5
Training loss: 3.425728496288876
Validation loss: 3.24846705939621

Epoch: 5| Step: 6
Training loss: 4.122274249611938
Validation loss: 3.249076020917759

Epoch: 5| Step: 7
Training loss: 3.1720259306378114
Validation loss: 3.2486923038526982

Epoch: 5| Step: 8
Training loss: 3.3590326179085888
Validation loss: 3.2477043064487336

Epoch: 5| Step: 9
Training loss: 3.2171778126182162
Validation loss: 3.247105111382776

Epoch: 5| Step: 10
Training loss: 3.5953003566094224
Validation loss: 3.24718335618822

Epoch: 73| Step: 0
Training loss: 4.044283828992857
Validation loss: 3.2467205928651466

Epoch: 5| Step: 1
Training loss: 3.2602053117751275
Validation loss: 3.246379624842251

Epoch: 5| Step: 2
Training loss: 4.028584390018409
Validation loss: 3.2470047023749795

Epoch: 5| Step: 3
Training loss: 3.672150556897744
Validation loss: 3.248291800413012

Epoch: 5| Step: 4
Training loss: 3.322430821280531
Validation loss: 3.251235009441097

Epoch: 5| Step: 5
Training loss: 2.6298708456838766
Validation loss: 3.2538894187847363

Epoch: 5| Step: 6
Training loss: 3.2566539433314388
Validation loss: 3.257353606253751

Epoch: 5| Step: 7
Training loss: 3.481825507378359
Validation loss: 3.268635869832163

Epoch: 5| Step: 8
Training loss: 3.2727261227788733
Validation loss: 3.2504202505532462

Epoch: 5| Step: 9
Training loss: 3.4958757897315866
Validation loss: 3.244161111044743

Epoch: 5| Step: 10
Training loss: 3.6732035080063925
Validation loss: 3.242671604142902

Epoch: 74| Step: 0
Training loss: 3.7449761116681817
Validation loss: 3.243582359722627

Epoch: 5| Step: 1
Training loss: 2.8801313301448315
Validation loss: 3.2437538163863318

Epoch: 5| Step: 2
Training loss: 4.358021515777821
Validation loss: 3.2444911979569917

Epoch: 5| Step: 3
Training loss: 3.104647622622693
Validation loss: 3.2461600356052536

Epoch: 5| Step: 4
Training loss: 2.8369157433299668
Validation loss: 3.244457543635993

Epoch: 5| Step: 5
Training loss: 4.081630092055627
Validation loss: 3.247037834469516

Epoch: 5| Step: 6
Training loss: 2.6636821217975477
Validation loss: 3.2428641075717173

Epoch: 5| Step: 7
Training loss: 3.5458575566529396
Validation loss: 3.2433261216685696

Epoch: 5| Step: 8
Training loss: 3.751715458457049
Validation loss: 3.2422854236137164

Epoch: 5| Step: 9
Training loss: 2.8368528796113277
Validation loss: 3.241616145095975

Epoch: 5| Step: 10
Training loss: 4.072034475229311
Validation loss: 3.2409257110048713

Epoch: 75| Step: 0
Training loss: 3.0687717910894143
Validation loss: 3.2407772455993276

Epoch: 5| Step: 1
Training loss: 2.7131542629728043
Validation loss: 3.241857134240058

Epoch: 5| Step: 2
Training loss: 4.137986980257344
Validation loss: 3.240798187983746

Epoch: 5| Step: 3
Training loss: 3.5699683092350933
Validation loss: 3.2397961939126874

Epoch: 5| Step: 4
Training loss: 3.5068842078009688
Validation loss: 3.2403833178182166

Epoch: 5| Step: 5
Training loss: 4.06737941270116
Validation loss: 3.2426144617894797

Epoch: 5| Step: 6
Training loss: 2.6375459856842536
Validation loss: 3.239069614856003

Epoch: 5| Step: 7
Training loss: 2.9388948740554692
Validation loss: 3.2379433361963885

Epoch: 5| Step: 8
Training loss: 4.124631460661583
Validation loss: 3.239759469616124

Epoch: 5| Step: 9
Training loss: 3.7845232958918933
Validation loss: 3.2450361712600815

Epoch: 5| Step: 10
Training loss: 3.200622027261132
Validation loss: 3.2464730819883254

Epoch: 76| Step: 0
Training loss: 2.271641811907512
Validation loss: 3.238152728217128

Epoch: 5| Step: 1
Training loss: 3.7317422820030792
Validation loss: 3.235039598578555

Epoch: 5| Step: 2
Training loss: 3.598413642409989
Validation loss: 3.234617199141381

Epoch: 5| Step: 3
Training loss: 4.049013022264534
Validation loss: 3.234216972439011

Epoch: 5| Step: 4
Training loss: 3.755247132642761
Validation loss: 3.235487508957322

Epoch: 5| Step: 5
Training loss: 4.102383195421909
Validation loss: 3.2346504470236885

Epoch: 5| Step: 6
Training loss: 2.9315518156726537
Validation loss: 3.2355299422258548

Epoch: 5| Step: 7
Training loss: 3.2498851168941734
Validation loss: 3.233310522115924

Epoch: 5| Step: 8
Training loss: 3.318228608463025
Validation loss: 3.235027432704277

Epoch: 5| Step: 9
Training loss: 3.360777805991148
Validation loss: 3.2344733915759543

Epoch: 5| Step: 10
Training loss: 3.4289969963534492
Validation loss: 3.2347710067643014

Epoch: 77| Step: 0
Training loss: 3.8382701734634983
Validation loss: 3.2320640566920202

Epoch: 5| Step: 1
Training loss: 3.4831636658251943
Validation loss: 3.2317918192728854

Epoch: 5| Step: 2
Training loss: 3.013947173305558
Validation loss: 3.2315016971897133

Epoch: 5| Step: 3
Training loss: 3.8035666442063225
Validation loss: 3.229776742541038

Epoch: 5| Step: 4
Training loss: 3.223907190922777
Validation loss: 3.2303778431523593

Epoch: 5| Step: 5
Training loss: 3.088739209775707
Validation loss: 3.230715403211149

Epoch: 5| Step: 6
Training loss: 3.4967705950521526
Validation loss: 3.2316884308819955

Epoch: 5| Step: 7
Training loss: 3.6070631145204253
Validation loss: 3.2304415839996383

Epoch: 5| Step: 8
Training loss: 3.574405786175258
Validation loss: 3.2336819067477305

Epoch: 5| Step: 9
Training loss: 3.217053901673768
Validation loss: 3.233933449415378

Epoch: 5| Step: 10
Training loss: 3.71858535530351
Validation loss: 3.2325268958764166

Epoch: 78| Step: 0
Training loss: 3.51745422246734
Validation loss: 3.22636688568274

Epoch: 5| Step: 1
Training loss: 2.6455413376890156
Validation loss: 3.2289503492820546

Epoch: 5| Step: 2
Training loss: 3.704509234956096
Validation loss: 3.2264086014168867

Epoch: 5| Step: 3
Training loss: 3.1168541598574677
Validation loss: 3.2255533226228827

Epoch: 5| Step: 4
Training loss: 3.4927744532165943
Validation loss: 3.224978524680535

Epoch: 5| Step: 5
Training loss: 3.4020614769711055
Validation loss: 3.224329393685413

Epoch: 5| Step: 6
Training loss: 4.25716760633668
Validation loss: 3.224440165682251

Epoch: 5| Step: 7
Training loss: 3.6099086878844013
Validation loss: 3.224034090699493

Epoch: 5| Step: 8
Training loss: 3.7299566586510142
Validation loss: 3.223069316783552

Epoch: 5| Step: 9
Training loss: 3.3296039859031126
Validation loss: 3.2245999094348243

Epoch: 5| Step: 10
Training loss: 2.930458720105386
Validation loss: 3.2245682879172843

Epoch: 79| Step: 0
Training loss: 3.3674960603528103
Validation loss: 3.2246426131764228

Epoch: 5| Step: 1
Training loss: 2.572662299757539
Validation loss: 3.2236890284598525

Epoch: 5| Step: 2
Training loss: 2.7344062149445967
Validation loss: 3.2268380911444443

Epoch: 5| Step: 3
Training loss: 3.150535622728778
Validation loss: 3.22693398756061

Epoch: 5| Step: 4
Training loss: 3.8631196793422524
Validation loss: 3.228590377103914

Epoch: 5| Step: 5
Training loss: 3.869081715304311
Validation loss: 3.223301440574909

Epoch: 5| Step: 6
Training loss: 3.691689003101111
Validation loss: 3.2258211481108234

Epoch: 5| Step: 7
Training loss: 3.303363363422683
Validation loss: 3.2264963250650562

Epoch: 5| Step: 8
Training loss: 4.356808142569754
Validation loss: 3.2286436252101325

Epoch: 5| Step: 9
Training loss: 2.685601561943193
Validation loss: 3.22393191190567

Epoch: 5| Step: 10
Training loss: 4.017122813133895
Validation loss: 3.222545004596697

Epoch: 80| Step: 0
Training loss: 3.604648418239456
Validation loss: 3.2185321498781967

Epoch: 5| Step: 1
Training loss: 3.522013780487846
Validation loss: 3.217795385263802

Epoch: 5| Step: 2
Training loss: 3.857864393130123
Validation loss: 3.2166816875148068

Epoch: 5| Step: 3
Training loss: 3.0362977148447396
Validation loss: 3.2164967375096905

Epoch: 5| Step: 4
Training loss: 3.9640011949200566
Validation loss: 3.2168787658107427

Epoch: 5| Step: 5
Training loss: 3.293003358127377
Validation loss: 3.2168102191778996

Epoch: 5| Step: 6
Training loss: 3.21612174865518
Validation loss: 3.215759340740757

Epoch: 5| Step: 7
Training loss: 2.868694190186804
Validation loss: 3.2155376731998824

Epoch: 5| Step: 8
Training loss: 3.150637329053224
Validation loss: 3.2139738468408594

Epoch: 5| Step: 9
Training loss: 3.126543045555338
Validation loss: 3.216366658180079

Epoch: 5| Step: 10
Training loss: 4.234334910297998
Validation loss: 3.213175700811215

Epoch: 81| Step: 0
Training loss: 3.0726464793934727
Validation loss: 3.212847143465526

Epoch: 5| Step: 1
Training loss: 4.194068198490442
Validation loss: 3.212138048806748

Epoch: 5| Step: 2
Training loss: 3.3071251214012927
Validation loss: 3.2116989311975135

Epoch: 5| Step: 3
Training loss: 3.20426481482727
Validation loss: 3.2122241302398797

Epoch: 5| Step: 4
Training loss: 3.362436717973001
Validation loss: 3.2113874644251643

Epoch: 5| Step: 5
Training loss: 3.4643963134594498
Validation loss: 3.2168977965426255

Epoch: 5| Step: 6
Training loss: 2.7792850368137727
Validation loss: 3.211811704059729

Epoch: 5| Step: 7
Training loss: 3.389350757149911
Validation loss: 3.21190806906583

Epoch: 5| Step: 8
Training loss: 3.846542088647138
Validation loss: 3.210988743062296

Epoch: 5| Step: 9
Training loss: 4.185201213197077
Validation loss: 3.2107026298916272

Epoch: 5| Step: 10
Training loss: 2.6617955381772935
Validation loss: 3.209612484437573

Epoch: 82| Step: 0
Training loss: 3.9520502250275285
Validation loss: 3.211860690291723

Epoch: 5| Step: 1
Training loss: 2.735285144286906
Validation loss: 3.2131265822352466

Epoch: 5| Step: 2
Training loss: 4.082116055862483
Validation loss: 3.2115942342264323

Epoch: 5| Step: 3
Training loss: 3.589777865962339
Validation loss: 3.215165801793001

Epoch: 5| Step: 4
Training loss: 3.4343095712442895
Validation loss: 3.216994449883691

Epoch: 5| Step: 5
Training loss: 3.131904755928494
Validation loss: 3.2143706642217618

Epoch: 5| Step: 6
Training loss: 3.4568295867204646
Validation loss: 3.214446454278147

Epoch: 5| Step: 7
Training loss: 3.127513942428236
Validation loss: 3.2106486530573677

Epoch: 5| Step: 8
Training loss: 3.3863549130544435
Validation loss: 3.2078911426377483

Epoch: 5| Step: 9
Training loss: 3.639305825326966
Validation loss: 3.2063928725452304

Epoch: 5| Step: 10
Training loss: 3.1048148756386915
Validation loss: 3.2050261659289823

Epoch: 83| Step: 0
Training loss: 4.254744405992815
Validation loss: 3.203437334945534

Epoch: 5| Step: 1
Training loss: 3.8168053003533813
Validation loss: 3.2035040614357464

Epoch: 5| Step: 2
Training loss: 3.661563370754929
Validation loss: 3.204340687900101

Epoch: 5| Step: 3
Training loss: 3.7361924604960697
Validation loss: 3.2041668741902023

Epoch: 5| Step: 4
Training loss: 2.95114876960884
Validation loss: 3.203070983511296

Epoch: 5| Step: 5
Training loss: 3.222582119175793
Validation loss: 3.2032790424353905

Epoch: 5| Step: 6
Training loss: 3.730040904171099
Validation loss: 3.201984478390269

Epoch: 5| Step: 7
Training loss: 3.385306692048884
Validation loss: 3.201466693899141

Epoch: 5| Step: 8
Training loss: 2.6408318432937836
Validation loss: 3.200647150763968

Epoch: 5| Step: 9
Training loss: 3.2582224489614737
Validation loss: 3.2002983060290964

Epoch: 5| Step: 10
Training loss: 2.765579050835408
Validation loss: 3.2001804586769236

Epoch: 84| Step: 0
Training loss: 4.002206908818085
Validation loss: 3.199646981120003

Epoch: 5| Step: 1
Training loss: 3.3843724131904502
Validation loss: 3.1977603258596337

Epoch: 5| Step: 2
Training loss: 3.7874513327112536
Validation loss: 3.1985801053219323

Epoch: 5| Step: 3
Training loss: 3.2135137539253633
Validation loss: 3.1977798872506726

Epoch: 5| Step: 4
Training loss: 3.2947635488227935
Validation loss: 3.196084337754572

Epoch: 5| Step: 5
Training loss: 3.1351554651969957
Validation loss: 3.1960215424334204

Epoch: 5| Step: 6
Training loss: 3.2979587021295687
Validation loss: 3.1995314887047734

Epoch: 5| Step: 7
Training loss: 3.1334238573619837
Validation loss: 3.1957036790416447

Epoch: 5| Step: 8
Training loss: 3.5331693851173713
Validation loss: 3.1943476419879633

Epoch: 5| Step: 9
Training loss: 3.268043024403226
Validation loss: 3.1995747786176048

Epoch: 5| Step: 10
Training loss: 3.695852357169601
Validation loss: 3.1992626916130753

Epoch: 85| Step: 0
Training loss: 3.6756380318804855
Validation loss: 3.195218745145723

Epoch: 5| Step: 1
Training loss: 3.5007977257757803
Validation loss: 3.1978084578903188

Epoch: 5| Step: 2
Training loss: 3.846360227476324
Validation loss: 3.1943046423905974

Epoch: 5| Step: 3
Training loss: 3.4614375939304183
Validation loss: 3.1954977615292153

Epoch: 5| Step: 4
Training loss: 3.21821574990165
Validation loss: 3.199506220226993

Epoch: 5| Step: 5
Training loss: 3.4679924764936563
Validation loss: 3.1930003763414083

Epoch: 5| Step: 6
Training loss: 3.5258646722920175
Validation loss: 3.191580196378661

Epoch: 5| Step: 7
Training loss: 2.882590846195878
Validation loss: 3.192358886360871

Epoch: 5| Step: 8
Training loss: 3.5236212773406748
Validation loss: 3.1909467643229807

Epoch: 5| Step: 9
Training loss: 3.6231343960537368
Validation loss: 3.19022223382396

Epoch: 5| Step: 10
Training loss: 2.8181664922303096
Validation loss: 3.190460732953868

Epoch: 86| Step: 0
Training loss: 3.646143189841512
Validation loss: 3.1899835416662614

Epoch: 5| Step: 1
Training loss: 3.2898732542999145
Validation loss: 3.1911303528381265

Epoch: 5| Step: 2
Training loss: 3.0715827934859203
Validation loss: 3.189365797180665

Epoch: 5| Step: 3
Training loss: 3.9173615157159047
Validation loss: 3.1890286482402472

Epoch: 5| Step: 4
Training loss: 3.5899978289159304
Validation loss: 3.1885080643605113

Epoch: 5| Step: 5
Training loss: 3.7457915533251334
Validation loss: 3.188516577367305

Epoch: 5| Step: 6
Training loss: 3.042846833946526
Validation loss: 3.18819808634597

Epoch: 5| Step: 7
Training loss: 2.753038981346341
Validation loss: 3.18849416595169

Epoch: 5| Step: 8
Training loss: 3.620970755816393
Validation loss: 3.187785186331297

Epoch: 5| Step: 9
Training loss: 3.2727765346923268
Validation loss: 3.187183167332153

Epoch: 5| Step: 10
Training loss: 3.6493418060899394
Validation loss: 3.1859266502741477

Epoch: 87| Step: 0
Training loss: 3.737434825520334
Validation loss: 3.1858401077393887

Epoch: 5| Step: 1
Training loss: 2.799155898244287
Validation loss: 3.185965528791695

Epoch: 5| Step: 2
Training loss: 3.6411171772831006
Validation loss: 3.1857130787264256

Epoch: 5| Step: 3
Training loss: 3.228903006998054
Validation loss: 3.1856759933079366

Epoch: 5| Step: 4
Training loss: 3.365061785965342
Validation loss: 3.184047028683275

Epoch: 5| Step: 5
Training loss: 4.222641118222772
Validation loss: 3.1848154459394395

Epoch: 5| Step: 6
Training loss: 3.7520209906505357
Validation loss: 3.1840147878335703

Epoch: 5| Step: 7
Training loss: 3.084136360003748
Validation loss: 3.183031576198236

Epoch: 5| Step: 8
Training loss: 3.2846680776279342
Validation loss: 3.18154303582357

Epoch: 5| Step: 9
Training loss: 3.3346884039447837
Validation loss: 3.181924773453638

Epoch: 5| Step: 10
Training loss: 2.9400411125474486
Validation loss: 3.1814565396383503

Epoch: 88| Step: 0
Training loss: 3.906279540903924
Validation loss: 3.1809082670969726

Epoch: 5| Step: 1
Training loss: 3.448536581837927
Validation loss: 3.1835851271972

Epoch: 5| Step: 2
Training loss: 3.7131535067296335
Validation loss: 3.1831460871166657

Epoch: 5| Step: 3
Training loss: 3.1602289783233384
Validation loss: 3.181255132225109

Epoch: 5| Step: 4
Training loss: 3.7434527143791305
Validation loss: 3.1826191352306865

Epoch: 5| Step: 5
Training loss: 3.2061851212330534
Validation loss: 3.1811528720070954

Epoch: 5| Step: 6
Training loss: 3.032775809504846
Validation loss: 3.182907740624137

Epoch: 5| Step: 7
Training loss: 3.2328222113307192
Validation loss: 3.18454451635635

Epoch: 5| Step: 8
Training loss: 3.3404874482486444
Validation loss: 3.183325580208869

Epoch: 5| Step: 9
Training loss: 3.2029639226839017
Validation loss: 3.1795536765032684

Epoch: 5| Step: 10
Training loss: 3.5863241681167586
Validation loss: 3.1807589894800232

Epoch: 89| Step: 0
Training loss: 2.6105301179052653
Validation loss: 3.177579894548502

Epoch: 5| Step: 1
Training loss: 3.8023208056279434
Validation loss: 3.1794348304400315

Epoch: 5| Step: 2
Training loss: 4.1043659039206775
Validation loss: 3.1790417414594048

Epoch: 5| Step: 3
Training loss: 3.9877497723359143
Validation loss: 3.1758513231304724

Epoch: 5| Step: 4
Training loss: 3.3766252348587
Validation loss: 3.176143570325949

Epoch: 5| Step: 5
Training loss: 3.3435792968528895
Validation loss: 3.1801909675265216

Epoch: 5| Step: 6
Training loss: 3.6522608456917673
Validation loss: 3.177122931163878

Epoch: 5| Step: 7
Training loss: 3.44233904005858
Validation loss: 3.1781116426550415

Epoch: 5| Step: 8
Training loss: 2.8621998991928312
Validation loss: 3.1783682777470434

Epoch: 5| Step: 9
Training loss: 3.5323553465256605
Validation loss: 3.175309963468181

Epoch: 5| Step: 10
Training loss: 2.3017795644257526
Validation loss: 3.174742021997412

Epoch: 90| Step: 0
Training loss: 2.4857224942684093
Validation loss: 3.1751902424030587

Epoch: 5| Step: 1
Training loss: 4.119644387462392
Validation loss: 3.1749882792233164

Epoch: 5| Step: 2
Training loss: 2.856398069855054
Validation loss: 3.175598532404354

Epoch: 5| Step: 3
Training loss: 3.6693142666580085
Validation loss: 3.1800162772331353

Epoch: 5| Step: 4
Training loss: 3.6347791373254346
Validation loss: 3.1777266414747474

Epoch: 5| Step: 5
Training loss: 3.4910493570563164
Validation loss: 3.173796359500362

Epoch: 5| Step: 6
Training loss: 2.926553825369635
Validation loss: 3.1742512334934725

Epoch: 5| Step: 7
Training loss: 3.678441964674118
Validation loss: 3.1711396171548025

Epoch: 5| Step: 8
Training loss: 3.3473858896624877
Validation loss: 3.170033888276786

Epoch: 5| Step: 9
Training loss: 3.788270344465768
Validation loss: 3.169099985727837

Epoch: 5| Step: 10
Training loss: 3.2327720613748294
Validation loss: 3.168967151881022

Epoch: 91| Step: 0
Training loss: 3.5792399838938835
Validation loss: 3.169446790742608

Epoch: 5| Step: 1
Training loss: 3.559109597028058
Validation loss: 3.168170794096225

Epoch: 5| Step: 2
Training loss: 3.411929094675727
Validation loss: 3.1668772770435947

Epoch: 5| Step: 3
Training loss: 2.9901166876538667
Validation loss: 3.167351600608886

Epoch: 5| Step: 4
Training loss: 2.8844373305706017
Validation loss: 3.166677823611058

Epoch: 5| Step: 5
Training loss: 3.6966728303500753
Validation loss: 3.1663995110900367

Epoch: 5| Step: 6
Training loss: 3.461321325094184
Validation loss: 3.165000236342872

Epoch: 5| Step: 7
Training loss: 2.9795525218715007
Validation loss: 3.164830266872493

Epoch: 5| Step: 8
Training loss: 2.9201429812815554
Validation loss: 3.1663373625880205

Epoch: 5| Step: 9
Training loss: 4.144185618982345
Validation loss: 3.166499312101447

Epoch: 5| Step: 10
Training loss: 3.6823336083138205
Validation loss: 3.1647720454873434

Epoch: 92| Step: 0
Training loss: 3.8380464245571164
Validation loss: 3.1690246684342362

Epoch: 5| Step: 1
Training loss: 3.5323125540317233
Validation loss: 3.1643954121268774

Epoch: 5| Step: 2
Training loss: 3.578285979934977
Validation loss: 3.16344044904541

Epoch: 5| Step: 3
Training loss: 2.9299234930992717
Validation loss: 3.1616183745207462

Epoch: 5| Step: 4
Training loss: 3.5509620007797107
Validation loss: 3.1625537608827345

Epoch: 5| Step: 5
Training loss: 3.277853233920048
Validation loss: 3.161400268257163

Epoch: 5| Step: 6
Training loss: 3.067095053509223
Validation loss: 3.161804237599473

Epoch: 5| Step: 7
Training loss: 3.591673806899571
Validation loss: 3.16095053932406

Epoch: 5| Step: 8
Training loss: 3.049735423635107
Validation loss: 3.161257471866538

Epoch: 5| Step: 9
Training loss: 3.684420706196102
Validation loss: 3.1608752062774466

Epoch: 5| Step: 10
Training loss: 3.3009418877331673
Validation loss: 3.1595716531090976

Epoch: 93| Step: 0
Training loss: 3.7402069648555027
Validation loss: 3.1645539419004796

Epoch: 5| Step: 1
Training loss: 2.892442616360855
Validation loss: 3.168673454781301

Epoch: 5| Step: 2
Training loss: 2.467604455872308
Validation loss: 3.1759470526395845

Epoch: 5| Step: 3
Training loss: 2.811042407942379
Validation loss: 3.174794448440002

Epoch: 5| Step: 4
Training loss: 3.927051061738809
Validation loss: 3.1644907801392455

Epoch: 5| Step: 5
Training loss: 3.6238931741948566
Validation loss: 3.1584856629126206

Epoch: 5| Step: 6
Training loss: 3.211333090366858
Validation loss: 3.156752034014374

Epoch: 5| Step: 7
Training loss: 3.664184568279147
Validation loss: 3.157347490054786

Epoch: 5| Step: 8
Training loss: 3.7897399925886446
Validation loss: 3.1560329190814476

Epoch: 5| Step: 9
Training loss: 3.6807899848286034
Validation loss: 3.1567157899972633

Epoch: 5| Step: 10
Training loss: 3.327193295439826
Validation loss: 3.1551155399714146

Epoch: 94| Step: 0
Training loss: 2.8397838056237847
Validation loss: 3.155702301170399

Epoch: 5| Step: 1
Training loss: 3.247545048707375
Validation loss: 3.156336648848787

Epoch: 5| Step: 2
Training loss: 3.703309774818877
Validation loss: 3.1556027127492245

Epoch: 5| Step: 3
Training loss: 3.0274445547733095
Validation loss: 3.1564709287468435

Epoch: 5| Step: 4
Training loss: 3.731468442212729
Validation loss: 3.157022642152657

Epoch: 5| Step: 5
Training loss: 3.2869479161828425
Validation loss: 3.156675243697601

Epoch: 5| Step: 6
Training loss: 3.410698322153217
Validation loss: 3.156216571167449

Epoch: 5| Step: 7
Training loss: 3.161572642304902
Validation loss: 3.1553908065707033

Epoch: 5| Step: 8
Training loss: 3.542089250074476
Validation loss: 3.1525297784896384

Epoch: 5| Step: 9
Training loss: 3.674972331663025
Validation loss: 3.1535013731638184

Epoch: 5| Step: 10
Training loss: 3.7111826604873484
Validation loss: 3.1512978504124884

Epoch: 95| Step: 0
Training loss: 3.1935869328325155
Validation loss: 3.1517972578061237

Epoch: 5| Step: 1
Training loss: 3.7141800697729024
Validation loss: 3.1512895915569086

Epoch: 5| Step: 2
Training loss: 3.5241246536672
Validation loss: 3.151666217939559

Epoch: 5| Step: 3
Training loss: 3.1642641356469596
Validation loss: 3.150978552439534

Epoch: 5| Step: 4
Training loss: 3.4026636965219494
Validation loss: 3.151554527978097

Epoch: 5| Step: 5
Training loss: 2.6828544742275553
Validation loss: 3.151205316150232

Epoch: 5| Step: 6
Training loss: 3.6815316991098004
Validation loss: 3.151768769503081

Epoch: 5| Step: 7
Training loss: 3.5255061334089466
Validation loss: 3.1508182526096182

Epoch: 5| Step: 8
Training loss: 3.9055592651011932
Validation loss: 3.1498131026441207

Epoch: 5| Step: 9
Training loss: 3.042183418447522
Validation loss: 3.149683704959093

Epoch: 5| Step: 10
Training loss: 3.3846744760610177
Validation loss: 3.1490914588201755

Epoch: 96| Step: 0
Training loss: 2.8107959247282164
Validation loss: 3.148264380718193

Epoch: 5| Step: 1
Training loss: 3.738011843740642
Validation loss: 3.146816083587495

Epoch: 5| Step: 2
Training loss: 3.4737459238858244
Validation loss: 3.145679929486723

Epoch: 5| Step: 3
Training loss: 4.126060118421698
Validation loss: 3.146756869002281

Epoch: 5| Step: 4
Training loss: 3.4545078184277025
Validation loss: 3.1446257040830883

Epoch: 5| Step: 5
Training loss: 3.8581863611515046
Validation loss: 3.1439472410038976

Epoch: 5| Step: 6
Training loss: 3.259097936600182
Validation loss: 3.146249538358383

Epoch: 5| Step: 7
Training loss: 2.5378816176717467
Validation loss: 3.1436706478154277

Epoch: 5| Step: 8
Training loss: 3.839091261188116
Validation loss: 3.1434329406313033

Epoch: 5| Step: 9
Training loss: 3.0930885609707817
Validation loss: 3.1483939637628793

Epoch: 5| Step: 10
Training loss: 2.689130066948747
Validation loss: 3.1444778281924646

Epoch: 97| Step: 0
Training loss: 2.9586170938002523
Validation loss: 3.146917027042923

Epoch: 5| Step: 1
Training loss: 3.1735994508966385
Validation loss: 3.1524608654501107

Epoch: 5| Step: 2
Training loss: 3.269897732083328
Validation loss: 3.1683680222806228

Epoch: 5| Step: 3
Training loss: 3.338965013693749
Validation loss: 3.1647038769724767

Epoch: 5| Step: 4
Training loss: 3.733688099785124
Validation loss: 3.146698953576914

Epoch: 5| Step: 5
Training loss: 3.6432111338382045
Validation loss: 3.148560531990182

Epoch: 5| Step: 6
Training loss: 3.3779275700611318
Validation loss: 3.1389853439396345

Epoch: 5| Step: 7
Training loss: 3.006221518907039
Validation loss: 3.137635708446051

Epoch: 5| Step: 8
Training loss: 3.220659152737649
Validation loss: 3.1378232216739956

Epoch: 5| Step: 9
Training loss: 3.6230602994191994
Validation loss: 3.1392676058166553

Epoch: 5| Step: 10
Training loss: 3.9589478802045712
Validation loss: 3.136082633933874

Epoch: 98| Step: 0
Training loss: 3.466887927941604
Validation loss: 3.1373214378674086

Epoch: 5| Step: 1
Training loss: 3.327301353297338
Validation loss: 3.135223266329806

Epoch: 5| Step: 2
Training loss: 3.3607421931753794
Validation loss: 3.1355791138073634

Epoch: 5| Step: 3
Training loss: 3.13293548114287
Validation loss: 3.135076985539891

Epoch: 5| Step: 4
Training loss: 3.555441573090899
Validation loss: 3.135470831002579

Epoch: 5| Step: 5
Training loss: 3.3257440637969813
Validation loss: 3.1400051167403755

Epoch: 5| Step: 6
Training loss: 3.3899607205436193
Validation loss: 3.139006535041774

Epoch: 5| Step: 7
Training loss: 2.6557482077157926
Validation loss: 3.140251768069594

Epoch: 5| Step: 8
Training loss: 3.2236011576376735
Validation loss: 3.144481837753764

Epoch: 5| Step: 9
Training loss: 4.098778817278233
Validation loss: 3.1451724300181985

Epoch: 5| Step: 10
Training loss: 3.6121122211499954
Validation loss: 3.142456056395598

Epoch: 99| Step: 0
Training loss: 3.8354141282310286
Validation loss: 3.1357017313642683

Epoch: 5| Step: 1
Training loss: 3.381581141814692
Validation loss: 3.1339723575120915

Epoch: 5| Step: 2
Training loss: 3.2017593077548665
Validation loss: 3.133309823482323

Epoch: 5| Step: 3
Training loss: 2.9283611906662896
Validation loss: 3.1335054726225904

Epoch: 5| Step: 4
Training loss: 3.7778211447775965
Validation loss: 3.1353490498732253

Epoch: 5| Step: 5
Training loss: 3.4274395851247585
Validation loss: 3.13105488823176

Epoch: 5| Step: 6
Training loss: 3.3320086390095947
Validation loss: 3.1316994077788562

Epoch: 5| Step: 7
Training loss: 3.271084105643921
Validation loss: 3.130401468323875

Epoch: 5| Step: 8
Training loss: 3.0577194893657222
Validation loss: 3.1294565757784003

Epoch: 5| Step: 9
Training loss: 3.301077961423732
Validation loss: 3.128151618198712

Epoch: 5| Step: 10
Training loss: 3.6361167401246814
Validation loss: 3.1284946090320163

Epoch: 100| Step: 0
Training loss: 3.632198421301361
Validation loss: 3.1332161631327726

Epoch: 5| Step: 1
Training loss: 2.9821337527616616
Validation loss: 3.137842619123609

Epoch: 5| Step: 2
Training loss: 3.1326602889301363
Validation loss: 3.1320135565533653

Epoch: 5| Step: 3
Training loss: 3.2082178334505462
Validation loss: 3.130378101970279

Epoch: 5| Step: 4
Training loss: 3.4071238385561102
Validation loss: 3.139017757357691

Epoch: 5| Step: 5
Training loss: 3.637076420717156
Validation loss: 3.1356835568370443

Epoch: 5| Step: 6
Training loss: 3.3995797178019562
Validation loss: 3.148286523163232

Epoch: 5| Step: 7
Training loss: 3.00426894678257
Validation loss: 3.1320010084947576

Epoch: 5| Step: 8
Training loss: 4.039585455975394
Validation loss: 3.126988209575146

Epoch: 5| Step: 9
Training loss: 3.8818768423552372
Validation loss: 3.1263424506343767

Epoch: 5| Step: 10
Training loss: 2.4174922541402535
Validation loss: 3.1247244600624104

Epoch: 101| Step: 0
Training loss: 3.158135181609138
Validation loss: 3.125906235746006

Epoch: 5| Step: 1
Training loss: 3.8378573273046634
Validation loss: 3.126602369107784

Epoch: 5| Step: 2
Training loss: 2.958034894333769
Validation loss: 3.126972883385127

Epoch: 5| Step: 3
Training loss: 3.546378079865648
Validation loss: 3.1263852640263328

Epoch: 5| Step: 4
Training loss: 3.2880805717676
Validation loss: 3.1274270753819597

Epoch: 5| Step: 5
Training loss: 3.5048462150238198
Validation loss: 3.1259746860906867

Epoch: 5| Step: 6
Training loss: 2.730667652749589
Validation loss: 3.12460102446691

Epoch: 5| Step: 7
Training loss: 3.661051800417382
Validation loss: 3.1242969911714447

Epoch: 5| Step: 8
Training loss: 3.770198087066866
Validation loss: 3.123958778425767

Epoch: 5| Step: 9
Training loss: 3.590291490329813
Validation loss: 3.1232797527043545

Epoch: 5| Step: 10
Training loss: 2.8656119609440434
Validation loss: 3.120737919240911

Epoch: 102| Step: 0
Training loss: 2.6737945978084277
Validation loss: 3.121726619100367

Epoch: 5| Step: 1
Training loss: 3.6550798418375923
Validation loss: 3.121392714061929

Epoch: 5| Step: 2
Training loss: 3.2755907938145983
Validation loss: 3.1208661126904427

Epoch: 5| Step: 3
Training loss: 3.261566706785636
Validation loss: 3.121672002217978

Epoch: 5| Step: 4
Training loss: 3.5180126982910274
Validation loss: 3.1285169061499047

Epoch: 5| Step: 5
Training loss: 3.252510568306926
Validation loss: 3.1289048276240004

Epoch: 5| Step: 6
Training loss: 3.1221165896730567
Validation loss: 3.124845107967259

Epoch: 5| Step: 7
Training loss: 3.334962224331743
Validation loss: 3.124096158485041

Epoch: 5| Step: 8
Training loss: 3.7858052204243404
Validation loss: 3.123374468607304

Epoch: 5| Step: 9
Training loss: 3.7872954662730685
Validation loss: 3.1220714021457123

Epoch: 5| Step: 10
Training loss: 3.287765718462103
Validation loss: 3.1180988099900153

Epoch: 103| Step: 0
Training loss: 3.065707492787831
Validation loss: 3.11742934984692

Epoch: 5| Step: 1
Training loss: 3.731716853956177
Validation loss: 3.1156870774299135

Epoch: 5| Step: 2
Training loss: 2.562185872990854
Validation loss: 3.116064447871949

Epoch: 5| Step: 3
Training loss: 3.177151655285916
Validation loss: 3.1162180799890473

Epoch: 5| Step: 4
Training loss: 3.144789330927127
Validation loss: 3.116284326165097

Epoch: 5| Step: 5
Training loss: 2.9125075704451637
Validation loss: 3.11516274905966

Epoch: 5| Step: 6
Training loss: 3.8146370073365694
Validation loss: 3.1126750258497378

Epoch: 5| Step: 7
Training loss: 3.108772257750883
Validation loss: 3.115133231971241

Epoch: 5| Step: 8
Training loss: 4.125370586972569
Validation loss: 3.11299524835921

Epoch: 5| Step: 9
Training loss: 4.1631011712057076
Validation loss: 3.1120425814023522

Epoch: 5| Step: 10
Training loss: 2.7719665064969434
Validation loss: 3.1120423836949764

Epoch: 104| Step: 0
Training loss: 3.9419307907895846
Validation loss: 3.1116955691462564

Epoch: 5| Step: 1
Training loss: 3.5314322905624493
Validation loss: 3.111122290517446

Epoch: 5| Step: 2
Training loss: 3.2697886521754
Validation loss: 3.109996802532113

Epoch: 5| Step: 3
Training loss: 3.315814105797263
Validation loss: 3.1101733130177247

Epoch: 5| Step: 4
Training loss: 3.88162452745857
Validation loss: 3.1094223895279804

Epoch: 5| Step: 5
Training loss: 3.474055588641493
Validation loss: 3.1101173375921203

Epoch: 5| Step: 6
Training loss: 2.861146138623908
Validation loss: 3.111044942506941

Epoch: 5| Step: 7
Training loss: 3.4777138850064704
Validation loss: 3.108985596581899

Epoch: 5| Step: 8
Training loss: 2.831546631488513
Validation loss: 3.1064715054758643

Epoch: 5| Step: 9
Training loss: 3.018571906039131
Validation loss: 3.110260267954766

Epoch: 5| Step: 10
Training loss: 3.209295368042396
Validation loss: 3.1100780293955856

Epoch: 105| Step: 0
Training loss: 3.6337192511266334
Validation loss: 3.1148740296876487

Epoch: 5| Step: 1
Training loss: 3.859773931850501
Validation loss: 3.1102967689501684

Epoch: 5| Step: 2
Training loss: 2.9743309166181042
Validation loss: 3.1076844797055414

Epoch: 5| Step: 3
Training loss: 3.563083801620187
Validation loss: 3.1062329265892563

Epoch: 5| Step: 4
Training loss: 3.06727694644793
Validation loss: 3.1076436863552823

Epoch: 5| Step: 5
Training loss: 2.864284615402636
Validation loss: 3.1086645330328544

Epoch: 5| Step: 6
Training loss: 3.849292016266012
Validation loss: 3.1074232791593164

Epoch: 5| Step: 7
Training loss: 3.1629068406961283
Validation loss: 3.1068989044550546

Epoch: 5| Step: 8
Training loss: 3.4975678303857687
Validation loss: 3.1051070748968623

Epoch: 5| Step: 9
Training loss: 2.892876320561751
Validation loss: 3.1062169730848304

Epoch: 5| Step: 10
Training loss: 3.440489006992868
Validation loss: 3.1049509444485013

Epoch: 106| Step: 0
Training loss: 3.5725024162054733
Validation loss: 3.1037970817932905

Epoch: 5| Step: 1
Training loss: 3.318604656133131
Validation loss: 3.1036157589232363

Epoch: 5| Step: 2
Training loss: 3.545242807872609
Validation loss: 3.103041472533172

Epoch: 5| Step: 3
Training loss: 3.3869544346517606
Validation loss: 3.1035427339954405

Epoch: 5| Step: 4
Training loss: 3.4816259650271975
Validation loss: 3.1027434098547033

Epoch: 5| Step: 5
Training loss: 3.3201652943011637
Validation loss: 3.1014700358401255

Epoch: 5| Step: 6
Training loss: 3.0361733321918223
Validation loss: 3.1021935729713106

Epoch: 5| Step: 7
Training loss: 3.4663154375218572
Validation loss: 3.101838751914744

Epoch: 5| Step: 8
Training loss: 3.1498596160124244
Validation loss: 3.1043894384248367

Epoch: 5| Step: 9
Training loss: 2.9260649804535146
Validation loss: 3.10298409447689

Epoch: 5| Step: 10
Training loss: 3.713901596852824
Validation loss: 3.1048880778919656

Epoch: 107| Step: 0
Training loss: 3.1765386562700337
Validation loss: 3.1081781828015558

Epoch: 5| Step: 1
Training loss: 3.6241580379965495
Validation loss: 3.1031095763065037

Epoch: 5| Step: 2
Training loss: 3.1457589921735614
Validation loss: 3.0972482197130584

Epoch: 5| Step: 3
Training loss: 2.8179489756906437
Validation loss: 3.099506177877971

Epoch: 5| Step: 4
Training loss: 3.0728696313049295
Validation loss: 3.0982653019328845

Epoch: 5| Step: 5
Training loss: 3.359962873253744
Validation loss: 3.098151405500293

Epoch: 5| Step: 6
Training loss: 3.0955701925816035
Validation loss: 3.097712774184784

Epoch: 5| Step: 7
Training loss: 3.661176443666729
Validation loss: 3.0971473973469865

Epoch: 5| Step: 8
Training loss: 3.8473029114807153
Validation loss: 3.0980276691437774

Epoch: 5| Step: 9
Training loss: 2.6313146297826497
Validation loss: 3.097480302469105

Epoch: 5| Step: 10
Training loss: 4.326674015017374
Validation loss: 3.0969767833229427

Epoch: 108| Step: 0
Training loss: 3.753469642232847
Validation loss: 3.095495879681312

Epoch: 5| Step: 1
Training loss: 3.631591329109739
Validation loss: 3.096714831933934

Epoch: 5| Step: 2
Training loss: 2.884410880248969
Validation loss: 3.094451885169399

Epoch: 5| Step: 3
Training loss: 3.548543260443676
Validation loss: 3.095633170521217

Epoch: 5| Step: 4
Training loss: 3.154666767930808
Validation loss: 3.0973147615376337

Epoch: 5| Step: 5
Training loss: 3.1872944485078967
Validation loss: 3.0948915684250657

Epoch: 5| Step: 6
Training loss: 3.598604058780988
Validation loss: 3.098128348670872

Epoch: 5| Step: 7
Training loss: 3.309766541283583
Validation loss: 3.095841965946043

Epoch: 5| Step: 8
Training loss: 3.2380238466380207
Validation loss: 3.0938122054154698

Epoch: 5| Step: 9
Training loss: 3.33724056764316
Validation loss: 3.0938110461550874

Epoch: 5| Step: 10
Training loss: 3.115738687382849
Validation loss: 3.0923344023184987

Epoch: 109| Step: 0
Training loss: 3.152242098732811
Validation loss: 3.093090981978528

Epoch: 5| Step: 1
Training loss: 4.315332560537163
Validation loss: 3.093039719366301

Epoch: 5| Step: 2
Training loss: 3.2520625098908083
Validation loss: 3.0926552919070325

Epoch: 5| Step: 3
Training loss: 2.320886508827851
Validation loss: 3.090814109964113

Epoch: 5| Step: 4
Training loss: 2.965311729679496
Validation loss: 3.0905057026574867

Epoch: 5| Step: 5
Training loss: 3.4499654685241112
Validation loss: 3.0905011801034723

Epoch: 5| Step: 6
Training loss: 3.183631344438687
Validation loss: 3.08989697971814

Epoch: 5| Step: 7
Training loss: 3.7507868894865566
Validation loss: 3.090945724143324

Epoch: 5| Step: 8
Training loss: 3.137205473309438
Validation loss: 3.087630667629763

Epoch: 5| Step: 9
Training loss: 3.644619170965217
Validation loss: 3.0891757351508984

Epoch: 5| Step: 10
Training loss: 3.273255409147099
Validation loss: 3.08963949289791

Epoch: 110| Step: 0
Training loss: 3.103007328380078
Validation loss: 3.0942821846675757

Epoch: 5| Step: 1
Training loss: 3.927063325515628
Validation loss: 3.098846890741443

Epoch: 5| Step: 2
Training loss: 3.2580955620245673
Validation loss: 3.101846008493906

Epoch: 5| Step: 3
Training loss: 2.8178296771101836
Validation loss: 3.087427889937664

Epoch: 5| Step: 4
Training loss: 3.7759340608545306
Validation loss: 3.0864621218170165

Epoch: 5| Step: 5
Training loss: 3.4595255501094875
Validation loss: 3.0868608992756656

Epoch: 5| Step: 6
Training loss: 3.2415831220855864
Validation loss: 3.086547508816351

Epoch: 5| Step: 7
Training loss: 2.533979851224862
Validation loss: 3.0853774360421093

Epoch: 5| Step: 8
Training loss: 3.7755592336169608
Validation loss: 3.0853780891295735

Epoch: 5| Step: 9
Training loss: 3.6118180895228096
Validation loss: 3.0867823910308974

Epoch: 5| Step: 10
Training loss: 3.008009549906972
Validation loss: 3.0912461957252986

Epoch: 111| Step: 0
Training loss: 3.196543859669307
Validation loss: 3.088825626901673

Epoch: 5| Step: 1
Training loss: 3.4874645272368507
Validation loss: 3.088400909852579

Epoch: 5| Step: 2
Training loss: 3.417440109788568
Validation loss: 3.0838764053862633

Epoch: 5| Step: 3
Training loss: 3.736675495564911
Validation loss: 3.084118377854753

Epoch: 5| Step: 4
Training loss: 3.4303489516452568
Validation loss: 3.088135353688313

Epoch: 5| Step: 5
Training loss: 2.746655424366631
Validation loss: 3.0825794936957776

Epoch: 5| Step: 6
Training loss: 2.716451703871533
Validation loss: 3.081983910104799

Epoch: 5| Step: 7
Training loss: 3.583874875924345
Validation loss: 3.0818309238725594

Epoch: 5| Step: 8
Training loss: 3.0714433834441155
Validation loss: 3.081810945945612

Epoch: 5| Step: 9
Training loss: 3.653030151493377
Validation loss: 3.080122199873885

Epoch: 5| Step: 10
Training loss: 3.574773426478828
Validation loss: 3.0806844009024705

Epoch: 112| Step: 0
Training loss: 3.38770094272017
Validation loss: 3.086353300261868

Epoch: 5| Step: 1
Training loss: 3.5516193940841365
Validation loss: 3.0853810521175293

Epoch: 5| Step: 2
Training loss: 2.8918213714052623
Validation loss: 3.079616798326062

Epoch: 5| Step: 3
Training loss: 3.4957062405265336
Validation loss: 3.0760261872263106

Epoch: 5| Step: 4
Training loss: 3.711185487190975
Validation loss: 3.0771861518771573

Epoch: 5| Step: 5
Training loss: 3.156313753900509
Validation loss: 3.0764928121326895

Epoch: 5| Step: 6
Training loss: 2.771078734656995
Validation loss: 3.07725119474105

Epoch: 5| Step: 7
Training loss: 4.091380591145434
Validation loss: 3.077089800968694

Epoch: 5| Step: 8
Training loss: 3.035687531425484
Validation loss: 3.0771163704599425

Epoch: 5| Step: 9
Training loss: 2.852671953479741
Validation loss: 3.0766627489199965

Epoch: 5| Step: 10
Training loss: 3.601921146434135
Validation loss: 3.0766936608106663

Epoch: 113| Step: 0
Training loss: 3.221022757174169
Validation loss: 3.075184089865435

Epoch: 5| Step: 1
Training loss: 3.2982670886799093
Validation loss: 3.0740844732262045

Epoch: 5| Step: 2
Training loss: 3.4557744559583314
Validation loss: 3.074917680739149

Epoch: 5| Step: 3
Training loss: 3.072341365086739
Validation loss: 3.0732680052974755

Epoch: 5| Step: 4
Training loss: 3.2850160330696125
Validation loss: 3.081869846185569

Epoch: 5| Step: 5
Training loss: 3.658013203951123
Validation loss: 3.075854479980251

Epoch: 5| Step: 6
Training loss: 2.6199999828193024
Validation loss: 3.0740080221758945

Epoch: 5| Step: 7
Training loss: 3.1107994918828714
Validation loss: 3.0722140741449446

Epoch: 5| Step: 8
Training loss: 3.687084109889336
Validation loss: 3.0764100276903137

Epoch: 5| Step: 9
Training loss: 3.304283460081824
Validation loss: 3.0743947896604884

Epoch: 5| Step: 10
Training loss: 3.8848586649083487
Validation loss: 3.080136603932627

Epoch: 114| Step: 0
Training loss: 3.4110550892054263
Validation loss: 3.072651323584269

Epoch: 5| Step: 1
Training loss: 4.112351880406302
Validation loss: 3.070157517658353

Epoch: 5| Step: 2
Training loss: 4.006501873983757
Validation loss: 3.0697181141141225

Epoch: 5| Step: 3
Training loss: 3.340005649858824
Validation loss: 3.069114392219118

Epoch: 5| Step: 4
Training loss: 3.690503723580922
Validation loss: 3.0692072547963507

Epoch: 5| Step: 5
Training loss: 2.998287347847713
Validation loss: 3.0677798181875886

Epoch: 5| Step: 6
Training loss: 3.0061501405115085
Validation loss: 3.0661707282708544

Epoch: 5| Step: 7
Training loss: 3.8255986811033726
Validation loss: 3.065757208009397

Epoch: 5| Step: 8
Training loss: 2.502958549842123
Validation loss: 3.067046817724365

Epoch: 5| Step: 9
Training loss: 2.7743576887312082
Validation loss: 3.0672618300695933

Epoch: 5| Step: 10
Training loss: 2.321746588502269
Validation loss: 3.0640798708052923

Epoch: 115| Step: 0
Training loss: 3.369860798255854
Validation loss: 3.064905058937672

Epoch: 5| Step: 1
Training loss: 3.193540048883565
Validation loss: 3.0672709370152806

Epoch: 5| Step: 2
Training loss: 3.0747279287169986
Validation loss: 3.0709685716113455

Epoch: 5| Step: 3
Training loss: 3.5253394971188645
Validation loss: 3.084935342213469

Epoch: 5| Step: 4
Training loss: 3.657827835670076
Validation loss: 3.0836343665421384

Epoch: 5| Step: 5
Training loss: 3.2960656786272793
Validation loss: 3.070774938952301

Epoch: 5| Step: 6
Training loss: 3.262602945508617
Validation loss: 3.065600769416181

Epoch: 5| Step: 7
Training loss: 3.170729406778242
Validation loss: 3.0646334481572044

Epoch: 5| Step: 8
Training loss: 2.950006362132308
Validation loss: 3.0637618648929745

Epoch: 5| Step: 9
Training loss: 3.4738135967768
Validation loss: 3.0643727810897223

Epoch: 5| Step: 10
Training loss: 3.6343068320653895
Validation loss: 3.0657892308014008

Epoch: 116| Step: 0
Training loss: 2.243759508033095
Validation loss: 3.0648841827409687

Epoch: 5| Step: 1
Training loss: 3.574750483415137
Validation loss: 3.0659317342321972

Epoch: 5| Step: 2
Training loss: 2.731224992231676
Validation loss: 3.0664079354577245

Epoch: 5| Step: 3
Training loss: 3.1965917437553886
Validation loss: 3.0658035265976284

Epoch: 5| Step: 4
Training loss: 3.7964955834973835
Validation loss: 3.0627271640380833

Epoch: 5| Step: 5
Training loss: 3.406943434379778
Validation loss: 3.062231584898751

Epoch: 5| Step: 6
Training loss: 3.3723147977816237
Validation loss: 3.061789719278384

Epoch: 5| Step: 7
Training loss: 3.5096394086845586
Validation loss: 3.061442023551569

Epoch: 5| Step: 8
Training loss: 3.826871207305609
Validation loss: 3.0605161702644206

Epoch: 5| Step: 9
Training loss: 3.733299834805018
Validation loss: 3.061122168298703

Epoch: 5| Step: 10
Training loss: 2.7807350110520552
Validation loss: 3.0613538787713224

Epoch: 117| Step: 0
Training loss: 2.9915695946829555
Validation loss: 3.0584667167224096

Epoch: 5| Step: 1
Training loss: 3.115005838746895
Validation loss: 3.056677503775162

Epoch: 5| Step: 2
Training loss: 3.909703917354166
Validation loss: 3.0600229910369454

Epoch: 5| Step: 3
Training loss: 3.458252840752291
Validation loss: 3.059414248021118

Epoch: 5| Step: 4
Training loss: 2.592418926593596
Validation loss: 3.058904633887305

Epoch: 5| Step: 5
Training loss: 3.1140396170916653
Validation loss: 3.0588391598365834

Epoch: 5| Step: 6
Training loss: 3.9081225980272083
Validation loss: 3.0609275794217488

Epoch: 5| Step: 7
Training loss: 3.282794988295898
Validation loss: 3.0641164241042844

Epoch: 5| Step: 8
Training loss: 3.7202491623486798
Validation loss: 3.0632615020580976

Epoch: 5| Step: 9
Training loss: 3.292159916744543
Validation loss: 3.0577426379410784

Epoch: 5| Step: 10
Training loss: 2.823330519253328
Validation loss: 3.0579379593297333

Epoch: 118| Step: 0
Training loss: 3.561529462352664
Validation loss: 3.057163535546152

Epoch: 5| Step: 1
Training loss: 3.692010093427192
Validation loss: 3.0563393767388685

Epoch: 5| Step: 2
Training loss: 3.5473653983669697
Validation loss: 3.0563481740028418

Epoch: 5| Step: 3
Training loss: 3.2751853482744693
Validation loss: 3.0544147456230752

Epoch: 5| Step: 4
Training loss: 2.710760457087049
Validation loss: 3.054844309479902

Epoch: 5| Step: 5
Training loss: 2.9680836783075284
Validation loss: 3.054087125166625

Epoch: 5| Step: 6
Training loss: 3.429419852481928
Validation loss: 3.05374446004828

Epoch: 5| Step: 7
Training loss: 3.4185390149275805
Validation loss: 3.05237027792306

Epoch: 5| Step: 8
Training loss: 2.6966173634621464
Validation loss: 3.054368537183518

Epoch: 5| Step: 9
Training loss: 3.641371752729615
Validation loss: 3.054336682547912

Epoch: 5| Step: 10
Training loss: 3.4153488843321678
Validation loss: 3.0535387923136583

Epoch: 119| Step: 0
Training loss: 3.363651835619235
Validation loss: 3.05195018294897

Epoch: 5| Step: 1
Training loss: 3.531653592162139
Validation loss: 3.0510225912077362

Epoch: 5| Step: 2
Training loss: 3.507348792473168
Validation loss: 3.0526212353843127

Epoch: 5| Step: 3
Training loss: 3.6131647204604684
Validation loss: 3.0506487921044765

Epoch: 5| Step: 4
Training loss: 3.07782910469062
Validation loss: 3.050300036566491

Epoch: 5| Step: 5
Training loss: 3.68244859647904
Validation loss: 3.049125311151001

Epoch: 5| Step: 6
Training loss: 2.98636804308262
Validation loss: 3.049105142476815

Epoch: 5| Step: 7
Training loss: 3.0029668442823154
Validation loss: 3.049182658468105

Epoch: 5| Step: 8
Training loss: 3.2976122569656425
Validation loss: 3.0479244018408984

Epoch: 5| Step: 9
Training loss: 2.950533097800847
Validation loss: 3.0484467471436565

Epoch: 5| Step: 10
Training loss: 3.396309162027548
Validation loss: 3.0484257178706646

Epoch: 120| Step: 0
Training loss: 3.7702335000011935
Validation loss: 3.047174537139935

Epoch: 5| Step: 1
Training loss: 3.3851406200056022
Validation loss: 3.051163306508143

Epoch: 5| Step: 2
Training loss: 3.3038835562167668
Validation loss: 3.0498721812265095

Epoch: 5| Step: 3
Training loss: 3.50878756762249
Validation loss: 3.0516436268960545

Epoch: 5| Step: 4
Training loss: 4.034481675372441
Validation loss: 3.0551561958479376

Epoch: 5| Step: 5
Training loss: 2.840383360334832
Validation loss: 3.049912773914442

Epoch: 5| Step: 6
Training loss: 2.9728317309202366
Validation loss: 3.0483113620367934

Epoch: 5| Step: 7
Training loss: 2.7054970977998876
Validation loss: 3.045412218249957

Epoch: 5| Step: 8
Training loss: 3.5230465014396493
Validation loss: 3.0428141880443027

Epoch: 5| Step: 9
Training loss: 2.8173720652145535
Validation loss: 3.0424497245110107

Epoch: 5| Step: 10
Training loss: 3.3357939856790586
Validation loss: 3.0415510362691465

Epoch: 121| Step: 0
Training loss: 4.067559480894562
Validation loss: 3.0444094745286376

Epoch: 5| Step: 1
Training loss: 2.9255729570590434
Validation loss: 3.042856805924249

Epoch: 5| Step: 2
Training loss: 2.971479105126703
Validation loss: 3.0425547507027493

Epoch: 5| Step: 3
Training loss: 3.4397482715588206
Validation loss: 3.0434979251374905

Epoch: 5| Step: 4
Training loss: 2.2378251974243417
Validation loss: 3.0428780169097807

Epoch: 5| Step: 5
Training loss: 3.8207238722790637
Validation loss: 3.0419167224645753

Epoch: 5| Step: 6
Training loss: 3.345691580677325
Validation loss: 3.0422695173273313

Epoch: 5| Step: 7
Training loss: 2.685927263543294
Validation loss: 3.041492216664988

Epoch: 5| Step: 8
Training loss: 3.319121167248339
Validation loss: 3.041096395474382

Epoch: 5| Step: 9
Training loss: 3.6743401226913166
Validation loss: 3.0398963842641415

Epoch: 5| Step: 10
Training loss: 3.561239856238227
Validation loss: 3.04133397697798

Epoch: 122| Step: 0
Training loss: 3.593722401388592
Validation loss: 3.041166180643987

Epoch: 5| Step: 1
Training loss: 3.0511493143349604
Validation loss: 3.03956850793523

Epoch: 5| Step: 2
Training loss: 3.6795520798047696
Validation loss: 3.04049675851282

Epoch: 5| Step: 3
Training loss: 3.816456227282795
Validation loss: 3.0414066167008165

Epoch: 5| Step: 4
Training loss: 2.8038014151850086
Validation loss: 3.0384872537002363

Epoch: 5| Step: 5
Training loss: 2.9420022753221127
Validation loss: 3.039466420041702

Epoch: 5| Step: 6
Training loss: 3.6513161259050064
Validation loss: 3.0381318189472624

Epoch: 5| Step: 7
Training loss: 2.793429847482334
Validation loss: 3.039464405880326

Epoch: 5| Step: 8
Training loss: 3.252995944142855
Validation loss: 3.03697009946869

Epoch: 5| Step: 9
Training loss: 3.072625373784131
Validation loss: 3.0418867356650083

Epoch: 5| Step: 10
Training loss: 3.549066614294896
Validation loss: 3.039838370930857

Epoch: 123| Step: 0
Training loss: 3.255448396095929
Validation loss: 3.039201494068861

Epoch: 5| Step: 1
Training loss: 3.0208377355784646
Validation loss: 3.0383823290662066

Epoch: 5| Step: 2
Training loss: 3.1004026151513933
Validation loss: 3.0376688151507723

Epoch: 5| Step: 3
Training loss: 3.161631915099724
Validation loss: 3.037497642074258

Epoch: 5| Step: 4
Training loss: 2.934560725597901
Validation loss: 3.037857122412333

Epoch: 5| Step: 5
Training loss: 3.5497408812611493
Validation loss: 3.037098985732109

Epoch: 5| Step: 6
Training loss: 3.5656413901217294
Validation loss: 3.0358851212988838

Epoch: 5| Step: 7
Training loss: 3.238497111415944
Validation loss: 3.0361942082177378

Epoch: 5| Step: 8
Training loss: 3.553410361446927
Validation loss: 3.035154219463961

Epoch: 5| Step: 9
Training loss: 3.521799455321586
Validation loss: 3.0346810641495545

Epoch: 5| Step: 10
Training loss: 3.379849093979092
Validation loss: 3.034161731196283

Epoch: 124| Step: 0
Training loss: 3.3527201184997777
Validation loss: 3.033737025859505

Epoch: 5| Step: 1
Training loss: 2.950611801069458
Validation loss: 3.03388467423294

Epoch: 5| Step: 2
Training loss: 3.3216522745017483
Validation loss: 3.034822755943987

Epoch: 5| Step: 3
Training loss: 3.724665448827381
Validation loss: 3.0425676491157208

Epoch: 5| Step: 4
Training loss: 3.4141031433060607
Validation loss: 3.0437312826158185

Epoch: 5| Step: 5
Training loss: 3.73073435531881
Validation loss: 3.0629056779462327

Epoch: 5| Step: 6
Training loss: 3.5502674163247185
Validation loss: 3.048958070569879

Epoch: 5| Step: 7
Training loss: 2.7766296069483465
Validation loss: 3.0313783209766556

Epoch: 5| Step: 8
Training loss: 2.9675629501286194
Validation loss: 3.029745044855726

Epoch: 5| Step: 9
Training loss: 3.2498903989651167
Validation loss: 3.0323414031824867

Epoch: 5| Step: 10
Training loss: 3.1524745909281733
Validation loss: 3.032859798504517

Epoch: 125| Step: 0
Training loss: 3.541937395107974
Validation loss: 3.0429532837109066

Epoch: 5| Step: 1
Training loss: 3.8514337421429423
Validation loss: 3.039661137936107

Epoch: 5| Step: 2
Training loss: 2.9876389155950602
Validation loss: 3.033494944111611

Epoch: 5| Step: 3
Training loss: 2.6785233084579714
Validation loss: 3.03189555851607

Epoch: 5| Step: 4
Training loss: 3.211077387748901
Validation loss: 3.031848458931962

Epoch: 5| Step: 5
Training loss: 2.4258309818397517
Validation loss: 3.028627852120563

Epoch: 5| Step: 6
Training loss: 3.0905341186121316
Validation loss: 3.03002124167448

Epoch: 5| Step: 7
Training loss: 4.066188604886376
Validation loss: 3.0296502568415136

Epoch: 5| Step: 8
Training loss: 3.0256350709731397
Validation loss: 3.0298895566003887

Epoch: 5| Step: 9
Training loss: 3.610551518502572
Validation loss: 3.02751017684312

Epoch: 5| Step: 10
Training loss: 3.545575546654062
Validation loss: 3.0291709548706116

Epoch: 126| Step: 0
Training loss: 2.916869256386048
Validation loss: 3.027066299368756

Epoch: 5| Step: 1
Training loss: 3.5264276305485263
Validation loss: 3.027635339619877

Epoch: 5| Step: 2
Training loss: 2.789294150426767
Validation loss: 3.0305689198898356

Epoch: 5| Step: 3
Training loss: 3.6961516703742228
Validation loss: 3.0295181266078917

Epoch: 5| Step: 4
Training loss: 3.893510108771011
Validation loss: 3.0262822321773877

Epoch: 5| Step: 5
Training loss: 3.2610790973184454
Validation loss: 3.026068926948183

Epoch: 5| Step: 6
Training loss: 3.2474905743069375
Validation loss: 3.022714033812715

Epoch: 5| Step: 7
Training loss: 2.448090653966193
Validation loss: 3.023989303883719

Epoch: 5| Step: 8
Training loss: 3.2404202344130093
Validation loss: 3.0238389256428873

Epoch: 5| Step: 9
Training loss: 3.5788590790130423
Validation loss: 3.0214875491268165

Epoch: 5| Step: 10
Training loss: 3.4196225072873454
Validation loss: 3.023671049531973

Epoch: 127| Step: 0
Training loss: 3.502264107950161
Validation loss: 3.0215170324565874

Epoch: 5| Step: 1
Training loss: 3.439402937861414
Validation loss: 3.02387910647924

Epoch: 5| Step: 2
Training loss: 2.934185349385887
Validation loss: 3.022167275926797

Epoch: 5| Step: 3
Training loss: 3.019874543369381
Validation loss: 3.0201335029863166

Epoch: 5| Step: 4
Training loss: 3.752807202252446
Validation loss: 3.023870934536975

Epoch: 5| Step: 5
Training loss: 3.3467882560081685
Validation loss: 3.0362731041816544

Epoch: 5| Step: 6
Training loss: 3.333384624722363
Validation loss: 3.031339369415188

Epoch: 5| Step: 7
Training loss: 2.7544708322534226
Validation loss: 3.0250298199852943

Epoch: 5| Step: 8
Training loss: 3.0972034946059828
Validation loss: 3.022530475237777

Epoch: 5| Step: 9
Training loss: 3.6641861298939
Validation loss: 3.020292255853296

Epoch: 5| Step: 10
Training loss: 3.222065967483583
Validation loss: 3.022281106020933

Epoch: 128| Step: 0
Training loss: 2.496592201765784
Validation loss: 3.0218035968940664

Epoch: 5| Step: 1
Training loss: 2.9194211396524166
Validation loss: 3.0214877213661606

Epoch: 5| Step: 2
Training loss: 3.363611858569211
Validation loss: 3.02157696378317

Epoch: 5| Step: 3
Training loss: 3.838079720611918
Validation loss: 3.0217068442837416

Epoch: 5| Step: 4
Training loss: 3.1855622927949243
Validation loss: 3.0217594078003027

Epoch: 5| Step: 5
Training loss: 3.768373997595567
Validation loss: 3.0213436206319955

Epoch: 5| Step: 6
Training loss: 3.3274180059841973
Validation loss: 3.0210110542429214

Epoch: 5| Step: 7
Training loss: 2.5523938256130916
Validation loss: 3.0218739760621385

Epoch: 5| Step: 8
Training loss: 3.3575363450344864
Validation loss: 3.0200690575988993

Epoch: 5| Step: 9
Training loss: 3.206129200464829
Validation loss: 3.020094981922973

Epoch: 5| Step: 10
Training loss: 3.928279070689143
Validation loss: 3.0175916280184496

Epoch: 129| Step: 0
Training loss: 2.8217487429469608
Validation loss: 3.018802834237002

Epoch: 5| Step: 1
Training loss: 3.318580660477858
Validation loss: 3.0159396772974048

Epoch: 5| Step: 2
Training loss: 3.176448137332804
Validation loss: 3.0206574892003366

Epoch: 5| Step: 3
Training loss: 2.958734100131467
Validation loss: 3.0169160674080526

Epoch: 5| Step: 4
Training loss: 3.499385643581931
Validation loss: 3.015332655349048

Epoch: 5| Step: 5
Training loss: 3.8274789693243405
Validation loss: 3.0157257204377834

Epoch: 5| Step: 6
Training loss: 3.3899304781736435
Validation loss: 3.0157456737026056

Epoch: 5| Step: 7
Training loss: 3.5678976560976645
Validation loss: 3.0137734067239825

Epoch: 5| Step: 8
Training loss: 3.8767477216526314
Validation loss: 3.0142321338146445

Epoch: 5| Step: 9
Training loss: 1.9632891046478496
Validation loss: 3.0119935237775293

Epoch: 5| Step: 10
Training loss: 3.3021059887867987
Validation loss: 3.010651424971282

Epoch: 130| Step: 0
Training loss: 3.4424444531271976
Validation loss: 3.009824936858565

Epoch: 5| Step: 1
Training loss: 3.582136412629553
Validation loss: 3.0118819282020897

Epoch: 5| Step: 2
Training loss: 3.00425513812268
Validation loss: 3.011360554146613

Epoch: 5| Step: 3
Training loss: 3.384965383332938
Validation loss: 3.0115314191987737

Epoch: 5| Step: 4
Training loss: 3.1637686133769733
Validation loss: 3.0125197300200814

Epoch: 5| Step: 5
Training loss: 3.3700110684900735
Validation loss: 3.00870526556121

Epoch: 5| Step: 6
Training loss: 3.5726572430056844
Validation loss: 3.008436974576408

Epoch: 5| Step: 7
Training loss: 2.6677059194923056
Validation loss: 3.0092107707463387

Epoch: 5| Step: 8
Training loss: 3.3758634239882803
Validation loss: 3.0105170958351444

Epoch: 5| Step: 9
Training loss: 3.504541311901421
Validation loss: 3.0114780148555167

Epoch: 5| Step: 10
Training loss: 2.8128989042741126
Validation loss: 3.0060697137051324

Epoch: 131| Step: 0
Training loss: 3.4427299248753633
Validation loss: 3.005435197067464

Epoch: 5| Step: 1
Training loss: 3.533882982459354
Validation loss: 3.004177980150071

Epoch: 5| Step: 2
Training loss: 2.732700641800886
Validation loss: 3.0035532807147045

Epoch: 5| Step: 3
Training loss: 2.9081052375546643
Validation loss: 3.004564864541571

Epoch: 5| Step: 4
Training loss: 2.8051490510176627
Validation loss: 3.0027502000393365

Epoch: 5| Step: 5
Training loss: 3.1091182736942216
Validation loss: 3.002391682193265

Epoch: 5| Step: 6
Training loss: 2.84298829996799
Validation loss: 3.0048960483683205

Epoch: 5| Step: 7
Training loss: 3.835598621821596
Validation loss: 3.0023436637922956

Epoch: 5| Step: 8
Training loss: 3.2421420542278034
Validation loss: 3.0027624762897367

Epoch: 5| Step: 9
Training loss: 3.630584624320919
Validation loss: 3.002817214658988

Epoch: 5| Step: 10
Training loss: 3.8413919798869327
Validation loss: 3.002311989807568

Epoch: 132| Step: 0
Training loss: 3.3302953386361254
Validation loss: 3.002365913256048

Epoch: 5| Step: 1
Training loss: 3.396425410104902
Validation loss: 3.0017302011875846

Epoch: 5| Step: 2
Training loss: 3.23649402439527
Validation loss: 3.00198114772643

Epoch: 5| Step: 3
Training loss: 3.709929576318488
Validation loss: 3.0011996430875962

Epoch: 5| Step: 4
Training loss: 2.71602265812295
Validation loss: 3.000647198176738

Epoch: 5| Step: 5
Training loss: 3.656573811073371
Validation loss: 3.000919698413104

Epoch: 5| Step: 6
Training loss: 2.853171701874245
Validation loss: 3.001569578311012

Epoch: 5| Step: 7
Training loss: 3.1374212977048512
Validation loss: 3.000838104545062

Epoch: 5| Step: 8
Training loss: 3.087653887539185
Validation loss: 3.003797680784113

Epoch: 5| Step: 9
Training loss: 2.8671740289938143
Validation loss: 3.008229704018394

Epoch: 5| Step: 10
Training loss: 3.9304642563735244
Validation loss: 3.015397766485078

Epoch: 133| Step: 0
Training loss: 3.7161792235911584
Validation loss: 3.0152446258912566

Epoch: 5| Step: 1
Training loss: 2.96900858505822
Validation loss: 2.9995955327877226

Epoch: 5| Step: 2
Training loss: 3.3337163387239768
Validation loss: 2.997857672230683

Epoch: 5| Step: 3
Training loss: 2.7717677288092273
Validation loss: 2.9984391229799296

Epoch: 5| Step: 4
Training loss: 3.226400228119078
Validation loss: 2.998021623684748

Epoch: 5| Step: 5
Training loss: 2.7135619725927693
Validation loss: 2.997868948316989

Epoch: 5| Step: 6
Training loss: 3.3287325738786646
Validation loss: 2.9968846494615207

Epoch: 5| Step: 7
Training loss: 3.4005569338458588
Validation loss: 2.9974094198584402

Epoch: 5| Step: 8
Training loss: 3.2781355836768347
Validation loss: 2.998416386953802

Epoch: 5| Step: 9
Training loss: 3.1556084613513984
Validation loss: 2.998262230234216

Epoch: 5| Step: 10
Training loss: 4.06469901797039
Validation loss: 3.0006967713006882

Epoch: 134| Step: 0
Training loss: 3.515699055209612
Validation loss: 2.998895261424323

Epoch: 5| Step: 1
Training loss: 2.9824931817564364
Validation loss: 2.9996875921584647

Epoch: 5| Step: 2
Training loss: 3.300115068914812
Validation loss: 2.9984475814011264

Epoch: 5| Step: 3
Training loss: 3.1059764902830347
Validation loss: 2.998530450095089

Epoch: 5| Step: 4
Training loss: 2.9832613000396
Validation loss: 2.997723298312614

Epoch: 5| Step: 5
Training loss: 3.061345408250785
Validation loss: 2.9979284288420387

Epoch: 5| Step: 6
Training loss: 3.6216885141017126
Validation loss: 2.9954293685018274

Epoch: 5| Step: 7
Training loss: 3.576540666999356
Validation loss: 2.994746085413481

Epoch: 5| Step: 8
Training loss: 2.629963315120459
Validation loss: 2.993730750510039

Epoch: 5| Step: 9
Training loss: 3.294703197628191
Validation loss: 2.9949182535876133

Epoch: 5| Step: 10
Training loss: 3.843091582684809
Validation loss: 2.993800792870775

Epoch: 135| Step: 0
Training loss: 2.8737886613565724
Validation loss: 2.9943074666461666

Epoch: 5| Step: 1
Training loss: 3.2820469932841436
Validation loss: 2.991255053367361

Epoch: 5| Step: 2
Training loss: 2.799673289584316
Validation loss: 2.992583241897314

Epoch: 5| Step: 3
Training loss: 3.1357140553179828
Validation loss: 2.9913261786987477

Epoch: 5| Step: 4
Training loss: 2.9439587302425103
Validation loss: 2.991480470888393

Epoch: 5| Step: 5
Training loss: 3.6223075338535256
Validation loss: 2.9959369186321583

Epoch: 5| Step: 6
Training loss: 3.046802695956996
Validation loss: 2.995386000515909

Epoch: 5| Step: 7
Training loss: 3.0274004530979988
Validation loss: 2.9993608863847117

Epoch: 5| Step: 8
Training loss: 3.604990885137074
Validation loss: 2.993083451198346

Epoch: 5| Step: 9
Training loss: 3.7122384130109665
Validation loss: 2.989501314573448

Epoch: 5| Step: 10
Training loss: 3.796899112577756
Validation loss: 2.987509552568831

Epoch: 136| Step: 0
Training loss: 2.9207503658452154
Validation loss: 2.9891702604496206

Epoch: 5| Step: 1
Training loss: 2.7308565882124425
Validation loss: 2.9895541785051503

Epoch: 5| Step: 2
Training loss: 3.407216206275462
Validation loss: 2.9914242850007002

Epoch: 5| Step: 3
Training loss: 3.394440363291694
Validation loss: 2.99267545872567

Epoch: 5| Step: 4
Training loss: 3.2204301023225628
Validation loss: 2.993502708002741

Epoch: 5| Step: 5
Training loss: 3.0140957290138726
Validation loss: 2.9974344043525956

Epoch: 5| Step: 6
Training loss: 3.046921010770385
Validation loss: 2.991432984361196

Epoch: 5| Step: 7
Training loss: 3.4829882954333176
Validation loss: 2.9901192812013333

Epoch: 5| Step: 8
Training loss: 4.0426915760212285
Validation loss: 2.9887668623351455

Epoch: 5| Step: 9
Training loss: 3.1426281969480465
Validation loss: 2.987151122809725

Epoch: 5| Step: 10
Training loss: 3.395238032360429
Validation loss: 2.98586678090031

Epoch: 137| Step: 0
Training loss: 3.5522767999639346
Validation loss: 2.9851951560967174

Epoch: 5| Step: 1
Training loss: 3.459822843349185
Validation loss: 2.9856859044801465

Epoch: 5| Step: 2
Training loss: 2.638292083401701
Validation loss: 2.9858331024483142

Epoch: 5| Step: 3
Training loss: 3.703751008120196
Validation loss: 2.988006294754197

Epoch: 5| Step: 4
Training loss: 3.4366816153387734
Validation loss: 2.988672844503794

Epoch: 5| Step: 5
Training loss: 2.9776085644971366
Validation loss: 2.991075641011566

Epoch: 5| Step: 6
Training loss: 2.9397034193167313
Validation loss: 3.0016798269332012

Epoch: 5| Step: 7
Training loss: 2.6366247089711177
Validation loss: 2.999015852626924

Epoch: 5| Step: 8
Training loss: 3.744317135657439
Validation loss: 3.0012307496665227

Epoch: 5| Step: 9
Training loss: 3.480458200697747
Validation loss: 2.9835485022500654

Epoch: 5| Step: 10
Training loss: 3.084434278357197
Validation loss: 2.9808711493936553

Epoch: 138| Step: 0
Training loss: 3.5054994701232207
Validation loss: 2.9804363326113883

Epoch: 5| Step: 1
Training loss: 3.8123311490048777
Validation loss: 2.9798964290675594

Epoch: 5| Step: 2
Training loss: 3.3708432348708692
Validation loss: 2.989285861615368

Epoch: 5| Step: 3
Training loss: 2.5760304583531775
Validation loss: 2.9826041252019757

Epoch: 5| Step: 4
Training loss: 3.4417178546587257
Validation loss: 2.9833127930644965

Epoch: 5| Step: 5
Training loss: 3.2250891917115454
Validation loss: 2.980151815503933

Epoch: 5| Step: 6
Training loss: 2.8830665538461386
Validation loss: 2.9820146453018666

Epoch: 5| Step: 7
Training loss: 3.1782842815623447
Validation loss: 2.980808404335147

Epoch: 5| Step: 8
Training loss: 3.521925506635822
Validation loss: 2.9778794599178227

Epoch: 5| Step: 9
Training loss: 2.5719895848349603
Validation loss: 2.975635895397744

Epoch: 5| Step: 10
Training loss: 3.6060486365416655
Validation loss: 2.9765592960530656

Epoch: 139| Step: 0
Training loss: 3.479808603482398
Validation loss: 2.978508343377535

Epoch: 5| Step: 1
Training loss: 3.6879176533705293
Validation loss: 2.978204464366326

Epoch: 5| Step: 2
Training loss: 3.270649963551898
Validation loss: 2.978034939467463

Epoch: 5| Step: 3
Training loss: 2.9502633575299986
Validation loss: 2.9800945463114643

Epoch: 5| Step: 4
Training loss: 3.085573430857998
Validation loss: 2.9855890564772767

Epoch: 5| Step: 5
Training loss: 3.5082276232477496
Validation loss: 2.9909580604805264

Epoch: 5| Step: 6
Training loss: 3.4387612543230444
Validation loss: 2.989400237121501

Epoch: 5| Step: 7
Training loss: 3.003700517174607
Validation loss: 2.9905375176710614

Epoch: 5| Step: 8
Training loss: 3.2973613651450266
Validation loss: 2.9850339870119234

Epoch: 5| Step: 9
Training loss: 3.5151555404869237
Validation loss: 2.97437062853767

Epoch: 5| Step: 10
Training loss: 2.1732889965231146
Validation loss: 2.974690946280455

Epoch: 140| Step: 0
Training loss: 3.2635628792204963
Validation loss: 2.9748083812440536

Epoch: 5| Step: 1
Training loss: 3.005694071863884
Validation loss: 2.9765123492222236

Epoch: 5| Step: 2
Training loss: 3.6237104029365517
Validation loss: 2.979438664051011

Epoch: 5| Step: 3
Training loss: 3.326762605582028
Validation loss: 2.977651051490564

Epoch: 5| Step: 4
Training loss: 3.177629034152118
Validation loss: 2.973437897085949

Epoch: 5| Step: 5
Training loss: 3.4337484522351867
Validation loss: 2.9738470271151205

Epoch: 5| Step: 6
Training loss: 2.894079340408044
Validation loss: 2.9721053931771624

Epoch: 5| Step: 7
Training loss: 3.526362860441128
Validation loss: 2.9732207317138744

Epoch: 5| Step: 8
Training loss: 3.7152988865016012
Validation loss: 2.974218590572929

Epoch: 5| Step: 9
Training loss: 3.1236688449021455
Validation loss: 2.9722652657083546

Epoch: 5| Step: 10
Training loss: 2.3959255919453493
Validation loss: 2.9724251434403586

Epoch: 141| Step: 0
Training loss: 2.7293072632738915
Validation loss: 2.972444976835827

Epoch: 5| Step: 1
Training loss: 3.202870428622417
Validation loss: 2.9725117380601156

Epoch: 5| Step: 2
Training loss: 2.8896459622644857
Validation loss: 2.974923389193269

Epoch: 5| Step: 3
Training loss: 3.622323198867774
Validation loss: 2.973278144513879

Epoch: 5| Step: 4
Training loss: 3.4464784755524427
Validation loss: 2.974192231030313

Epoch: 5| Step: 5
Training loss: 2.625201535435718
Validation loss: 2.973123022384731

Epoch: 5| Step: 6
Training loss: 3.6927108154862442
Validation loss: 2.9729104457754234

Epoch: 5| Step: 7
Training loss: 2.9360058819662522
Validation loss: 2.9725613026075366

Epoch: 5| Step: 8
Training loss: 3.4188451722338264
Validation loss: 2.970584736366038

Epoch: 5| Step: 9
Training loss: 3.1336827008964168
Validation loss: 2.9684648205192596

Epoch: 5| Step: 10
Training loss: 3.9113805418579637
Validation loss: 2.96408582176524

Epoch: 142| Step: 0
Training loss: 3.250482083292217
Validation loss: 2.9659002757511415

Epoch: 5| Step: 1
Training loss: 3.534446417426799
Validation loss: 2.9632632577511675

Epoch: 5| Step: 2
Training loss: 2.960350924644897
Validation loss: 2.9635185083497677

Epoch: 5| Step: 3
Training loss: 3.442682971178012
Validation loss: 2.9637219010001186

Epoch: 5| Step: 4
Training loss: 3.1231114593755867
Validation loss: 2.963240911074027

Epoch: 5| Step: 5
Training loss: 2.8844560109641146
Validation loss: 2.9640404175773507

Epoch: 5| Step: 6
Training loss: 3.500511132111303
Validation loss: 2.9615720663687988

Epoch: 5| Step: 7
Training loss: 3.4122317924877352
Validation loss: 2.9627534226173586

Epoch: 5| Step: 8
Training loss: 3.3200568605632412
Validation loss: 2.962721624773196

Epoch: 5| Step: 9
Training loss: 3.4197506515889384
Validation loss: 2.9645199667869733

Epoch: 5| Step: 10
Training loss: 2.6761926042441315
Validation loss: 2.962726162398697

Epoch: 143| Step: 0
Training loss: 3.7618903797327716
Validation loss: 2.964725013244745

Epoch: 5| Step: 1
Training loss: 3.449445740779104
Validation loss: 2.9635475865530276

Epoch: 5| Step: 2
Training loss: 3.0473069104929817
Validation loss: 2.9627173657674994

Epoch: 5| Step: 3
Training loss: 2.596828793551862
Validation loss: 2.96302197220566

Epoch: 5| Step: 4
Training loss: 2.966897969033446
Validation loss: 2.9627263579560092

Epoch: 5| Step: 5
Training loss: 3.1167062182305276
Validation loss: 2.960652194042902

Epoch: 5| Step: 6
Training loss: 3.5221405010456985
Validation loss: 2.960430558479124

Epoch: 5| Step: 7
Training loss: 4.145764195362515
Validation loss: 2.959096054297511

Epoch: 5| Step: 8
Training loss: 3.5305820609824456
Validation loss: 2.9605964925110495

Epoch: 5| Step: 9
Training loss: 2.443416067269205
Validation loss: 2.9608102008579786

Epoch: 5| Step: 10
Training loss: 2.541123149687445
Validation loss: 2.965097763034348

Epoch: 144| Step: 0
Training loss: 3.1426215207344024
Validation loss: 2.967683098902207

Epoch: 5| Step: 1
Training loss: 3.6703485440838715
Validation loss: 2.9625767268798113

Epoch: 5| Step: 2
Training loss: 2.7401952217333805
Validation loss: 2.960290956679719

Epoch: 5| Step: 3
Training loss: 3.42934685407893
Validation loss: 2.9602807975026857

Epoch: 5| Step: 4
Training loss: 3.495499169280955
Validation loss: 2.9579858819956786

Epoch: 5| Step: 5
Training loss: 3.086324083281906
Validation loss: 2.9574424694077464

Epoch: 5| Step: 6
Training loss: 3.0597543670201737
Validation loss: 2.9581641397675518

Epoch: 5| Step: 7
Training loss: 3.517100791591058
Validation loss: 2.9594812559258163

Epoch: 5| Step: 8
Training loss: 3.094211736573946
Validation loss: 2.957283407963493

Epoch: 5| Step: 9
Training loss: 2.8976078954031945
Validation loss: 2.9586584498058497

Epoch: 5| Step: 10
Training loss: 3.4250866175927137
Validation loss: 2.9605451308682023

Epoch: 145| Step: 0
Training loss: 3.1039628510267643
Validation loss: 2.96232295374591

Epoch: 5| Step: 1
Training loss: 2.793802459702169
Validation loss: 2.9601520220838764

Epoch: 5| Step: 2
Training loss: 3.339365142973357
Validation loss: 2.9598015765909484

Epoch: 5| Step: 3
Training loss: 2.4319376936385
Validation loss: 2.9602090336280873

Epoch: 5| Step: 4
Training loss: 3.8606415805395757
Validation loss: 2.9580708314611694

Epoch: 5| Step: 5
Training loss: 2.9191027867149075
Validation loss: 2.9561041533342256

Epoch: 5| Step: 6
Training loss: 3.540922842267272
Validation loss: 2.9550332712437

Epoch: 5| Step: 7
Training loss: 3.766016389759478
Validation loss: 2.9563425591029184

Epoch: 5| Step: 8
Training loss: 3.0444238437719777
Validation loss: 2.954630629234462

Epoch: 5| Step: 9
Training loss: 3.5555216386952253
Validation loss: 2.95517907686158

Epoch: 5| Step: 10
Training loss: 2.9368585738465307
Validation loss: 2.9566540531079406

Epoch: 146| Step: 0
Training loss: 3.7283636894462497
Validation loss: 2.9566171831174572

Epoch: 5| Step: 1
Training loss: 3.345902792723072
Validation loss: 2.953860271501204

Epoch: 5| Step: 2
Training loss: 3.082057551476019
Validation loss: 2.95455133539497

Epoch: 5| Step: 3
Training loss: 3.278469833405115
Validation loss: 2.955111683756626

Epoch: 5| Step: 4
Training loss: 3.281255958188415
Validation loss: 2.9547336613655726

Epoch: 5| Step: 5
Training loss: 3.307940385929407
Validation loss: 2.9608979715632056

Epoch: 5| Step: 6
Training loss: 2.952284435959399
Validation loss: 2.9570524983525797

Epoch: 5| Step: 7
Training loss: 2.786819881382636
Validation loss: 2.954289808384982

Epoch: 5| Step: 8
Training loss: 2.9608682508599053
Validation loss: 2.9511194684672626

Epoch: 5| Step: 9
Training loss: 3.658344418820999
Validation loss: 2.9512331757717396

Epoch: 5| Step: 10
Training loss: 3.0275047210228143
Validation loss: 2.9482691677386006

Epoch: 147| Step: 0
Training loss: 3.2275272432650457
Validation loss: 2.953062307822294

Epoch: 5| Step: 1
Training loss: 3.3210300522903027
Validation loss: 2.950252327018102

Epoch: 5| Step: 2
Training loss: 2.811020525585623
Validation loss: 2.951643134081724

Epoch: 5| Step: 3
Training loss: 2.964088554850974
Validation loss: 2.951926575980213

Epoch: 5| Step: 4
Training loss: 3.5705050827607723
Validation loss: 2.950231899520376

Epoch: 5| Step: 5
Training loss: 2.6673998917418813
Validation loss: 2.9553886644973146

Epoch: 5| Step: 6
Training loss: 3.7025179466003215
Validation loss: 2.9583529018625527

Epoch: 5| Step: 7
Training loss: 3.182342845215938
Validation loss: 2.9692519026504685

Epoch: 5| Step: 8
Training loss: 3.405831407497139
Validation loss: 2.95808524224275

Epoch: 5| Step: 9
Training loss: 2.8157799139390627
Validation loss: 2.9563345638188308

Epoch: 5| Step: 10
Training loss: 3.7711374290185873
Validation loss: 2.9547126227927047

Epoch: 148| Step: 0
Training loss: 3.2961654984395166
Validation loss: 2.949020739620956

Epoch: 5| Step: 1
Training loss: 3.213427837876289
Validation loss: 2.9470353901644404

Epoch: 5| Step: 2
Training loss: 2.6882825200134133
Validation loss: 2.947425639346713

Epoch: 5| Step: 3
Training loss: 3.7414483791870086
Validation loss: 2.9460844036630642

Epoch: 5| Step: 4
Training loss: 3.3966006170807197
Validation loss: 2.947696455081882

Epoch: 5| Step: 5
Training loss: 3.1404947282333597
Validation loss: 2.9458858275464377

Epoch: 5| Step: 6
Training loss: 3.533783130686104
Validation loss: 2.9453083307149632

Epoch: 5| Step: 7
Training loss: 2.8073805946509385
Validation loss: 2.9438527354602217

Epoch: 5| Step: 8
Training loss: 3.3829327357114485
Validation loss: 2.945645981907839

Epoch: 5| Step: 9
Training loss: 2.675238026519352
Validation loss: 2.942885264919004

Epoch: 5| Step: 10
Training loss: 3.496411527544532
Validation loss: 2.9438401839386037

Epoch: 149| Step: 0
Training loss: 3.2976592518698578
Validation loss: 2.944106819768244

Epoch: 5| Step: 1
Training loss: 3.183239501715314
Validation loss: 2.9443820495428437

Epoch: 5| Step: 2
Training loss: 2.718928188754802
Validation loss: 2.9449326948230117

Epoch: 5| Step: 3
Training loss: 3.6311998951486864
Validation loss: 2.947009258974185

Epoch: 5| Step: 4
Training loss: 2.9379807748392763
Validation loss: 2.9461277403345245

Epoch: 5| Step: 5
Training loss: 1.8878156739062848
Validation loss: 2.9547452096112314

Epoch: 5| Step: 6
Training loss: 3.460275832190097
Validation loss: 2.9717959121037594

Epoch: 5| Step: 7
Training loss: 4.267718908576008
Validation loss: 3.0128563956506786

Epoch: 5| Step: 8
Training loss: 3.6532426513313943
Validation loss: 2.9802337383091198

Epoch: 5| Step: 9
Training loss: 2.818270295256082
Validation loss: 2.947057940623846

Epoch: 5| Step: 10
Training loss: 3.1617694598995847
Validation loss: 2.9418047055614425

Epoch: 150| Step: 0
Training loss: 3.1718907849149254
Validation loss: 2.9415203798412652

Epoch: 5| Step: 1
Training loss: 3.2588559316165275
Validation loss: 2.9388591124323273

Epoch: 5| Step: 2
Training loss: 2.9353602306246356
Validation loss: 2.9469061551232567

Epoch: 5| Step: 3
Training loss: 2.6615205422812096
Validation loss: 2.950648157027173

Epoch: 5| Step: 4
Training loss: 3.2588869513972565
Validation loss: 2.960811407863519

Epoch: 5| Step: 5
Training loss: 3.586622251734317
Validation loss: 2.9463824820210953

Epoch: 5| Step: 6
Training loss: 3.34701136605983
Validation loss: 2.9388558281264054

Epoch: 5| Step: 7
Training loss: 3.364924615296155
Validation loss: 2.937222129230866

Epoch: 5| Step: 8
Training loss: 3.588060602388646
Validation loss: 2.9373679296109816

Epoch: 5| Step: 9
Training loss: 3.301348503171407
Validation loss: 2.9366969483841117

Epoch: 5| Step: 10
Training loss: 2.946334054595149
Validation loss: 2.9380609609000414

Testing loss: 3.1544734793854046
