Epoch: 1| Step: 0
Training loss: 5.277568188348305
Validation loss: 5.69442579398247

Epoch: 6| Step: 1
Training loss: 5.709404986323142
Validation loss: 5.6873717908304116

Epoch: 6| Step: 2
Training loss: 4.964074580220193
Validation loss: 5.6811941989496795

Epoch: 6| Step: 3
Training loss: 5.768390602166271
Validation loss: 5.675771587639042

Epoch: 6| Step: 4
Training loss: 6.015889109969304
Validation loss: 5.6703191105873145

Epoch: 6| Step: 5
Training loss: 5.0679920688196765
Validation loss: 5.6646083420826265

Epoch: 6| Step: 6
Training loss: 4.8021513409325935
Validation loss: 5.658610153669993

Epoch: 6| Step: 7
Training loss: 5.981620293996664
Validation loss: 5.652576550620275

Epoch: 6| Step: 8
Training loss: 6.31042567248587
Validation loss: 5.645808982667954

Epoch: 6| Step: 9
Training loss: 6.420153607583755
Validation loss: 5.638647649202845

Epoch: 6| Step: 10
Training loss: 5.623846486814072
Validation loss: 5.630685497503734

Epoch: 6| Step: 11
Training loss: 5.834046819740297
Validation loss: 5.622313169723314

Epoch: 6| Step: 12
Training loss: 6.12283131099816
Validation loss: 5.6133572167695736

Epoch: 6| Step: 13
Training loss: 5.379648726670105
Validation loss: 5.602945243678449

Epoch: 2| Step: 0
Training loss: 5.699910802310583
Validation loss: 5.592499528637393

Epoch: 6| Step: 1
Training loss: 6.2575083074084015
Validation loss: 5.580855877665815

Epoch: 6| Step: 2
Training loss: 6.0346284407145125
Validation loss: 5.568518112991497

Epoch: 6| Step: 3
Training loss: 6.287644201486928
Validation loss: 5.554816896014812

Epoch: 6| Step: 4
Training loss: 5.887106899736557
Validation loss: 5.540633492108476

Epoch: 6| Step: 5
Training loss: 5.355375081807595
Validation loss: 5.525115102618467

Epoch: 6| Step: 6
Training loss: 3.388122478878939
Validation loss: 5.508176909672151

Epoch: 6| Step: 7
Training loss: 5.414267355826291
Validation loss: 5.492039065841604

Epoch: 6| Step: 8
Training loss: 5.271088705799702
Validation loss: 5.473405640124886

Epoch: 6| Step: 9
Training loss: 6.557885573086592
Validation loss: 5.454233373953829

Epoch: 6| Step: 10
Training loss: 4.6418870436415975
Validation loss: 5.4342047890790806

Epoch: 6| Step: 11
Training loss: 4.891663072488343
Validation loss: 5.413170206489532

Epoch: 6| Step: 12
Training loss: 6.299559974441233
Validation loss: 5.391352287976876

Epoch: 6| Step: 13
Training loss: 4.0307614525760815
Validation loss: 5.367777486502288

Epoch: 3| Step: 0
Training loss: 4.945327156129546
Validation loss: 5.344055773431415

Epoch: 6| Step: 1
Training loss: 4.973693883233689
Validation loss: 5.319883364095018

Epoch: 6| Step: 2
Training loss: 5.7860875690477975
Validation loss: 5.2937850852387

Epoch: 6| Step: 3
Training loss: 4.977026038986437
Validation loss: 5.26714597755936

Epoch: 6| Step: 4
Training loss: 4.458962559489998
Validation loss: 5.238536305975841

Epoch: 6| Step: 5
Training loss: 5.317842557173973
Validation loss: 5.209911101879121

Epoch: 6| Step: 6
Training loss: 6.233046464217771
Validation loss: 5.180034242203964

Epoch: 6| Step: 7
Training loss: 5.915098958674991
Validation loss: 5.14910240335827

Epoch: 6| Step: 8
Training loss: 4.6460824851154
Validation loss: 5.115862195669949

Epoch: 6| Step: 9
Training loss: 5.529947418459576
Validation loss: 5.083222266802269

Epoch: 6| Step: 10
Training loss: 3.8321651392575733
Validation loss: 5.048949175783613

Epoch: 6| Step: 11
Training loss: 4.354344463216674
Validation loss: 5.013722717302718

Epoch: 6| Step: 12
Training loss: 5.630403085375735
Validation loss: 4.980187132544463

Epoch: 6| Step: 13
Training loss: 6.312173664986819
Validation loss: 4.940130249447925

Epoch: 4| Step: 0
Training loss: 3.5793950521294775
Validation loss: 4.905054679770625

Epoch: 6| Step: 1
Training loss: 4.903133106893593
Validation loss: 4.867163728055378

Epoch: 6| Step: 2
Training loss: 5.428505836176592
Validation loss: 4.831362409795861

Epoch: 6| Step: 3
Training loss: 4.874074212224259
Validation loss: 4.7951816088249695

Epoch: 6| Step: 4
Training loss: 5.31021104756006
Validation loss: 4.760835657641497

Epoch: 6| Step: 5
Training loss: 5.962748281239926
Validation loss: 4.725724932107382

Epoch: 6| Step: 6
Training loss: 4.191083598805652
Validation loss: 4.6866233963113135

Epoch: 6| Step: 7
Training loss: 5.112131664186432
Validation loss: 4.651465902249632

Epoch: 6| Step: 8
Training loss: 4.637812420379985
Validation loss: 4.613012463642796

Epoch: 6| Step: 9
Training loss: 4.588420864886436
Validation loss: 4.5799372974041885

Epoch: 6| Step: 10
Training loss: 3.7955792260703705
Validation loss: 4.547381144365565

Epoch: 6| Step: 11
Training loss: 4.509931836342655
Validation loss: 4.518280453231435

Epoch: 6| Step: 12
Training loss: 4.390732298928006
Validation loss: 4.490673684910921

Epoch: 6| Step: 13
Training loss: 5.1372877610818275
Validation loss: 4.464484719149281

Epoch: 5| Step: 0
Training loss: 4.288172784185167
Validation loss: 4.4445825337847795

Epoch: 6| Step: 1
Training loss: 5.367564181195956
Validation loss: 4.421568655240082

Epoch: 6| Step: 2
Training loss: 5.229238785731461
Validation loss: 4.398879806913567

Epoch: 6| Step: 3
Training loss: 4.903942756219164
Validation loss: 4.378942125197682

Epoch: 6| Step: 4
Training loss: 4.335540258407871
Validation loss: 4.361613731106466

Epoch: 6| Step: 5
Training loss: 4.060021216426342
Validation loss: 4.344323842236649

Epoch: 6| Step: 6
Training loss: 4.626905924925462
Validation loss: 4.326471835379206

Epoch: 6| Step: 7
Training loss: 4.895485507161683
Validation loss: 4.309539408813814

Epoch: 6| Step: 8
Training loss: 4.98751588594206
Validation loss: 4.294378336518092

Epoch: 6| Step: 9
Training loss: 4.103803563716859
Validation loss: 4.278957679306142

Epoch: 6| Step: 10
Training loss: 2.8259194557282896
Validation loss: 4.263108365831566

Epoch: 6| Step: 11
Training loss: 3.9245302247200504
Validation loss: 4.252012494140799

Epoch: 6| Step: 12
Training loss: 3.402887487048568
Validation loss: 4.23868054223094

Epoch: 6| Step: 13
Training loss: 4.760625098720378
Validation loss: 4.226834778411271

Epoch: 6| Step: 0
Training loss: 5.077717832234188
Validation loss: 4.215617441786185

Epoch: 6| Step: 1
Training loss: 3.5609649563409196
Validation loss: 4.211199920956235

Epoch: 6| Step: 2
Training loss: 4.636855524322748
Validation loss: 4.206371150051543

Epoch: 6| Step: 3
Training loss: 3.7561465434776506
Validation loss: 4.198575353838169

Epoch: 6| Step: 4
Training loss: 4.220322605475452
Validation loss: 4.188831248138456

Epoch: 6| Step: 5
Training loss: 5.054036730893602
Validation loss: 4.17899292955745

Epoch: 6| Step: 6
Training loss: 3.654363814066558
Validation loss: 4.1688857221746245

Epoch: 6| Step: 7
Training loss: 4.404421163019041
Validation loss: 4.160635287234783

Epoch: 6| Step: 8
Training loss: 4.162374472801679
Validation loss: 4.151691241993345

Epoch: 6| Step: 9
Training loss: 3.480057988615416
Validation loss: 4.1416042724697695

Epoch: 6| Step: 10
Training loss: 3.4794280511735627
Validation loss: 4.133659483962174

Epoch: 6| Step: 11
Training loss: 4.993789248735975
Validation loss: 4.123666166683272

Epoch: 6| Step: 12
Training loss: 4.721342675569764
Validation loss: 4.112918569418372

Epoch: 6| Step: 13
Training loss: 4.631805156015946
Validation loss: 4.1018125846316975

Epoch: 7| Step: 0
Training loss: 4.197126113752849
Validation loss: 4.088838835336395

Epoch: 6| Step: 1
Training loss: 3.6864751911164135
Validation loss: 4.0680089409371645

Epoch: 6| Step: 2
Training loss: 3.9294950464646763
Validation loss: 4.024346996256106

Epoch: 6| Step: 3
Training loss: 4.305783113324932
Validation loss: 4.011001406634117

Epoch: 6| Step: 4
Training loss: 3.5297119031706776
Validation loss: 4.009259256554181

Epoch: 6| Step: 5
Training loss: 4.280205146650346
Validation loss: 4.002548218770157

Epoch: 6| Step: 6
Training loss: 3.542869961842845
Validation loss: 4.0041283125666345

Epoch: 6| Step: 7
Training loss: 4.658246937031912
Validation loss: 3.988229715639196

Epoch: 6| Step: 8
Training loss: 3.5311194201606995
Validation loss: 3.9754922441432035

Epoch: 6| Step: 9
Training loss: 3.616320512323481
Validation loss: 3.9738770443293063

Epoch: 6| Step: 10
Training loss: 4.399581082949187
Validation loss: 3.9713661382754624

Epoch: 6| Step: 11
Training loss: 4.882687107764943
Validation loss: 3.959168285310894

Epoch: 6| Step: 12
Training loss: 5.140206456175605
Validation loss: 3.942653574618618

Epoch: 6| Step: 13
Training loss: 3.730164009149765
Validation loss: 3.9338002230390674

Epoch: 8| Step: 0
Training loss: 3.521364943118232
Validation loss: 3.9358544857678375

Epoch: 6| Step: 1
Training loss: 4.193796462869014
Validation loss: 3.9316207190556605

Epoch: 6| Step: 2
Training loss: 4.199797834344557
Validation loss: 3.9248947521337825

Epoch: 6| Step: 3
Training loss: 3.0537226487323403
Validation loss: 3.921332696663121

Epoch: 6| Step: 4
Training loss: 4.337814776956777
Validation loss: 3.916596660542555

Epoch: 6| Step: 5
Training loss: 3.3842888621237583
Validation loss: 3.9145332544404283

Epoch: 6| Step: 6
Training loss: 4.233622466498728
Validation loss: 3.9105726723106233

Epoch: 6| Step: 7
Training loss: 3.9872442946764233
Validation loss: 3.9066846248884946

Epoch: 6| Step: 8
Training loss: 3.644478130055674
Validation loss: 3.899414200562928

Epoch: 6| Step: 9
Training loss: 3.7690894940308426
Validation loss: 3.8921923273658736

Epoch: 6| Step: 10
Training loss: 3.965222330293991
Validation loss: 3.8840046978606924

Epoch: 6| Step: 11
Training loss: 4.911267867158976
Validation loss: 3.878113697429485

Epoch: 6| Step: 12
Training loss: 5.022894893785224
Validation loss: 3.872054614426934

Epoch: 6| Step: 13
Training loss: 4.263710794170745
Validation loss: 3.865350989597689

Epoch: 9| Step: 0
Training loss: 3.3747476554063858
Validation loss: 3.853897351824968

Epoch: 6| Step: 1
Training loss: 3.4675255066167985
Validation loss: 3.8494296153869465

Epoch: 6| Step: 2
Training loss: 3.7684730744353394
Validation loss: 3.8420209900131996

Epoch: 6| Step: 3
Training loss: 3.9502767924615796
Validation loss: 3.8408972352264197

Epoch: 6| Step: 4
Training loss: 4.432968404755833
Validation loss: 3.8381824444147634

Epoch: 6| Step: 5
Training loss: 4.230247822890097
Validation loss: 3.8300005780102886

Epoch: 6| Step: 6
Training loss: 3.599298588981137
Validation loss: 3.8232403797210397

Epoch: 6| Step: 7
Training loss: 4.445456236005505
Validation loss: 3.817861347478168

Epoch: 6| Step: 8
Training loss: 2.364131755532997
Validation loss: 3.815623219357368

Epoch: 6| Step: 9
Training loss: 3.8162568140203352
Validation loss: 3.808038361270585

Epoch: 6| Step: 10
Training loss: 5.305072573813456
Validation loss: 3.8044777354772394

Epoch: 6| Step: 11
Training loss: 4.039914541190453
Validation loss: 3.8033770378688843

Epoch: 6| Step: 12
Training loss: 3.6474832924766747
Validation loss: 3.794411471805809

Epoch: 6| Step: 13
Training loss: 5.047614737232078
Validation loss: 3.7876537542907953

Epoch: 10| Step: 0
Training loss: 3.6830197288529583
Validation loss: 3.783463603986964

Epoch: 6| Step: 1
Training loss: 3.962250802179559
Validation loss: 3.77757311267994

Epoch: 6| Step: 2
Training loss: 4.103997370654002
Validation loss: 3.7715043226894647

Epoch: 6| Step: 3
Training loss: 4.186410107334444
Validation loss: 3.771553475695206

Epoch: 6| Step: 4
Training loss: 3.4219299033302337
Validation loss: 3.76407192280484

Epoch: 6| Step: 5
Training loss: 2.990515019896826
Validation loss: 3.7564705976160586

Epoch: 6| Step: 6
Training loss: 3.633483562221802
Validation loss: 3.7619266872730965

Epoch: 6| Step: 7
Training loss: 4.9116270886498485
Validation loss: 3.7540636789259905

Epoch: 6| Step: 8
Training loss: 3.182936449591583
Validation loss: 3.7487639068280023

Epoch: 6| Step: 9
Training loss: 4.834631427654001
Validation loss: 3.746364209189089

Epoch: 6| Step: 10
Training loss: 3.8822523361573396
Validation loss: 3.7407507640489044

Epoch: 6| Step: 11
Training loss: 4.301807360845464
Validation loss: 3.732660228798297

Epoch: 6| Step: 12
Training loss: 3.83954632403703
Validation loss: 3.7280082042146456

Epoch: 6| Step: 13
Training loss: 3.286485836117505
Validation loss: 3.725665151360641

Epoch: 11| Step: 0
Training loss: 3.799098992190888
Validation loss: 3.728027749129557

Epoch: 6| Step: 1
Training loss: 3.3487337708516023
Validation loss: 3.723350670261212

Epoch: 6| Step: 2
Training loss: 4.3985736615802695
Validation loss: 3.719208179408449

Epoch: 6| Step: 3
Training loss: 3.9551774678881646
Validation loss: 3.713113865283035

Epoch: 6| Step: 4
Training loss: 4.246816677116883
Validation loss: 3.7081886218102116

Epoch: 6| Step: 5
Training loss: 3.8404369187142673
Validation loss: 3.7015333132027157

Epoch: 6| Step: 6
Training loss: 3.987338052647875
Validation loss: 3.6975891749345955

Epoch: 6| Step: 7
Training loss: 4.586618298194224
Validation loss: 3.6983969492499513

Epoch: 6| Step: 8
Training loss: 3.420166146330593
Validation loss: 3.695578291477361

Epoch: 6| Step: 9
Training loss: 3.0646981894422503
Validation loss: 3.6952364345577586

Epoch: 6| Step: 10
Training loss: 3.921373920422164
Validation loss: 3.6881692611681216

Epoch: 6| Step: 11
Training loss: 4.722189956754271
Validation loss: 3.684199649077069

Epoch: 6| Step: 12
Training loss: 3.0921517299223558
Validation loss: 3.6895741711928443

Epoch: 6| Step: 13
Training loss: 3.3741555747008993
Validation loss: 3.6910582140976405

Epoch: 12| Step: 0
Training loss: 3.7204311641912353
Validation loss: 3.6890980737459356

Epoch: 6| Step: 1
Training loss: 3.8498486773985268
Validation loss: 3.67959641223095

Epoch: 6| Step: 2
Training loss: 2.997190272322299
Validation loss: 3.6762074356869414

Epoch: 6| Step: 3
Training loss: 5.047485314660062
Validation loss: 3.67182997250707

Epoch: 6| Step: 4
Training loss: 4.170027991916738
Validation loss: 3.6717296856970054

Epoch: 6| Step: 5
Training loss: 3.816854772693737
Validation loss: 3.6680938193706885

Epoch: 6| Step: 6
Training loss: 3.6448617276310777
Validation loss: 3.667461143254426

Epoch: 6| Step: 7
Training loss: 3.592143885748851
Validation loss: 3.6639279506723157

Epoch: 6| Step: 8
Training loss: 4.073909524683583
Validation loss: 3.662408349131021

Epoch: 6| Step: 9
Training loss: 3.9519620247688163
Validation loss: 3.6563793307094876

Epoch: 6| Step: 10
Training loss: 3.911519638915305
Validation loss: 3.6513541662502704

Epoch: 6| Step: 11
Training loss: 3.3896513916635787
Validation loss: 3.6472369205009665

Epoch: 6| Step: 12
Training loss: 3.6428967374899126
Validation loss: 3.6422560498006975

Epoch: 6| Step: 13
Training loss: 3.808220509555855
Validation loss: 3.644035428111534

Epoch: 13| Step: 0
Training loss: 3.1161411603947515
Validation loss: 3.641016381091118

Epoch: 6| Step: 1
Training loss: 4.514880689901226
Validation loss: 3.636921939659053

Epoch: 6| Step: 2
Training loss: 3.46409280546058
Validation loss: 3.629409997210907

Epoch: 6| Step: 3
Training loss: 3.9398354764174854
Validation loss: 3.6256445812680957

Epoch: 6| Step: 4
Training loss: 3.327114757818602
Validation loss: 3.6216458767411526

Epoch: 6| Step: 5
Training loss: 3.4584580058104075
Validation loss: 3.6272505809518596

Epoch: 6| Step: 6
Training loss: 3.6775991422046843
Validation loss: 3.6291985615643507

Epoch: 6| Step: 7
Training loss: 4.237136672206253
Validation loss: 3.617217315095232

Epoch: 6| Step: 8
Training loss: 4.02927770346566
Validation loss: 3.6133877593009536

Epoch: 6| Step: 9
Training loss: 3.435316744975005
Validation loss: 3.6090957880929375

Epoch: 6| Step: 10
Training loss: 3.8859817189460517
Validation loss: 3.606164346734385

Epoch: 6| Step: 11
Training loss: 4.210761524833549
Validation loss: 3.6029603727044726

Epoch: 6| Step: 12
Training loss: 4.0570994940883125
Validation loss: 3.5991497090716216

Epoch: 6| Step: 13
Training loss: 3.724475076031518
Validation loss: 3.593083065543415

Epoch: 14| Step: 0
Training loss: 3.6296446411387526
Validation loss: 3.5923041817987977

Epoch: 6| Step: 1
Training loss: 4.103857942126564
Validation loss: 3.586366496281653

Epoch: 6| Step: 2
Training loss: 3.369019189387605
Validation loss: 3.5853414143529085

Epoch: 6| Step: 3
Training loss: 3.7709601505655455
Validation loss: 3.5769297470814574

Epoch: 6| Step: 4
Training loss: 4.3475057707842035
Validation loss: 3.5729468263139883

Epoch: 6| Step: 5
Training loss: 3.6069922570890274
Validation loss: 3.5857896954194457

Epoch: 6| Step: 6
Training loss: 3.1575382738368556
Validation loss: 3.5792904994143977

Epoch: 6| Step: 7
Training loss: 3.114320129364363
Validation loss: 3.5679274778320647

Epoch: 6| Step: 8
Training loss: 4.237115740162431
Validation loss: 3.5691259609773147

Epoch: 6| Step: 9
Training loss: 4.684225948066975
Validation loss: 3.564892496384468

Epoch: 6| Step: 10
Training loss: 3.693724857767581
Validation loss: 3.558504308739095

Epoch: 6| Step: 11
Training loss: 3.954878467182721
Validation loss: 3.5612349769352782

Epoch: 6| Step: 12
Training loss: 3.5137850545452975
Validation loss: 3.5598555289986455

Epoch: 6| Step: 13
Training loss: 2.8118354860044716
Validation loss: 3.5547443603958664

Epoch: 15| Step: 0
Training loss: 3.8864504314183117
Validation loss: 3.554032113987793

Epoch: 6| Step: 1
Training loss: 3.456452574492993
Validation loss: 3.5497817491627908

Epoch: 6| Step: 2
Training loss: 4.2337745156266795
Validation loss: 3.5483119652737707

Epoch: 6| Step: 3
Training loss: 4.218678339596822
Validation loss: 3.5468532627905622

Epoch: 6| Step: 4
Training loss: 2.5947181089907456
Validation loss: 3.5436668832891978

Epoch: 6| Step: 5
Training loss: 3.820319739336827
Validation loss: 3.5426275094819766

Epoch: 6| Step: 6
Training loss: 3.8683985191505683
Validation loss: 3.5402239404704052

Epoch: 6| Step: 7
Training loss: 4.0077858490829295
Validation loss: 3.5372345792373534

Epoch: 6| Step: 8
Training loss: 3.8039138916089295
Validation loss: 3.5338653787472576

Epoch: 6| Step: 9
Training loss: 3.93369157474406
Validation loss: 3.5307172510790514

Epoch: 6| Step: 10
Training loss: 3.721287991269265
Validation loss: 3.527304881019174

Epoch: 6| Step: 11
Training loss: 3.3645935688315833
Validation loss: 3.525991405683167

Epoch: 6| Step: 12
Training loss: 3.7270705798410497
Validation loss: 3.5216773261146486

Epoch: 6| Step: 13
Training loss: 3.320524321138598
Validation loss: 3.5195063618041798

Epoch: 16| Step: 0
Training loss: 3.7950997931787707
Validation loss: 3.51694163544245

Epoch: 6| Step: 1
Training loss: 3.8495307190483588
Validation loss: 3.5126753883159734

Epoch: 6| Step: 2
Training loss: 3.4648514567980806
Validation loss: 3.5109780021833044

Epoch: 6| Step: 3
Training loss: 3.935582496349338
Validation loss: 3.507526445878861

Epoch: 6| Step: 4
Training loss: 3.2599841593726113
Validation loss: 3.5076226817695977

Epoch: 6| Step: 5
Training loss: 3.6697277527324563
Validation loss: 3.5047664766401887

Epoch: 6| Step: 6
Training loss: 2.885742352738997
Validation loss: 3.5014267194841864

Epoch: 6| Step: 7
Training loss: 4.439653975260228
Validation loss: 3.498941986739703

Epoch: 6| Step: 8
Training loss: 3.9541739176665947
Validation loss: 3.4973657424843343

Epoch: 6| Step: 9
Training loss: 3.3469422690704174
Validation loss: 3.4959385507287943

Epoch: 6| Step: 10
Training loss: 3.7934142616189317
Validation loss: 3.4943429199615887

Epoch: 6| Step: 11
Training loss: 3.658837079679111
Validation loss: 3.49201091334482

Epoch: 6| Step: 12
Training loss: 3.855191701038719
Validation loss: 3.490594257137797

Epoch: 6| Step: 13
Training loss: 3.981378842459308
Validation loss: 3.48767744584625

Epoch: 17| Step: 0
Training loss: 3.8881791481376853
Validation loss: 3.4848079109886005

Epoch: 6| Step: 1
Training loss: 4.005919606217715
Validation loss: 3.4856635764892347

Epoch: 6| Step: 2
Training loss: 2.9410693620364636
Validation loss: 3.483629911192578

Epoch: 6| Step: 3
Training loss: 3.0094550861861165
Validation loss: 3.479624298064123

Epoch: 6| Step: 4
Training loss: 4.553342015233474
Validation loss: 3.478589892435925

Epoch: 6| Step: 5
Training loss: 4.174145255850994
Validation loss: 3.4743981834807385

Epoch: 6| Step: 6
Training loss: 3.5559401767706222
Validation loss: 3.474574782816277

Epoch: 6| Step: 7
Training loss: 4.3557441932242345
Validation loss: 3.4743042695658084

Epoch: 6| Step: 8
Training loss: 3.889680311114071
Validation loss: 3.4721066826633136

Epoch: 6| Step: 9
Training loss: 3.0623822870792594
Validation loss: 3.4820717456757557

Epoch: 6| Step: 10
Training loss: 3.4155990669403784
Validation loss: 3.486306982406299

Epoch: 6| Step: 11
Training loss: 3.2444526572827534
Validation loss: 3.473441144854334

Epoch: 6| Step: 12
Training loss: 3.2945548476671487
Validation loss: 3.474697109692928

Epoch: 6| Step: 13
Training loss: 3.9546182699485346
Validation loss: 3.4735494821584036

Epoch: 18| Step: 0
Training loss: 4.175828753237756
Validation loss: 3.4651566650717442

Epoch: 6| Step: 1
Training loss: 2.8882271383683826
Validation loss: 3.4584316299490316

Epoch: 6| Step: 2
Training loss: 4.006653735308691
Validation loss: 3.4548291569082283

Epoch: 6| Step: 3
Training loss: 2.8318743221607967
Validation loss: 3.454503276683458

Epoch: 6| Step: 4
Training loss: 3.6518900380370916
Validation loss: 3.453384584911351

Epoch: 6| Step: 5
Training loss: 3.268342999708739
Validation loss: 3.450402687853281

Epoch: 6| Step: 6
Training loss: 3.7746097489295325
Validation loss: 3.448064936893749

Epoch: 6| Step: 7
Training loss: 3.869404721670434
Validation loss: 3.4453192161971002

Epoch: 6| Step: 8
Training loss: 3.9535677816423647
Validation loss: 3.4414352593251434

Epoch: 6| Step: 9
Training loss: 4.075029974517107
Validation loss: 3.441255223541612

Epoch: 6| Step: 10
Training loss: 4.303058627634121
Validation loss: 3.4353405386572247

Epoch: 6| Step: 11
Training loss: 3.613402394506322
Validation loss: 3.432249263368484

Epoch: 6| Step: 12
Training loss: 3.368291050039815
Validation loss: 3.4313974170519606

Epoch: 6| Step: 13
Training loss: 2.8099258510811667
Validation loss: 3.4289692155928595

Epoch: 19| Step: 0
Training loss: 3.7219861479208842
Validation loss: 3.430003199297651

Epoch: 6| Step: 1
Training loss: 2.635970488445307
Validation loss: 3.4277252803887865

Epoch: 6| Step: 2
Training loss: 3.652480048426054
Validation loss: 3.4280035017450863

Epoch: 6| Step: 3
Training loss: 3.038822429363412
Validation loss: 3.4264974089813696

Epoch: 6| Step: 4
Training loss: 3.98805623255717
Validation loss: 3.4261904135265775

Epoch: 6| Step: 5
Training loss: 3.475053712717893
Validation loss: 3.423886044432036

Epoch: 6| Step: 6
Training loss: 4.282167211140863
Validation loss: 3.4220543772840375

Epoch: 6| Step: 7
Training loss: 3.498222172027981
Validation loss: 3.419427956925223

Epoch: 6| Step: 8
Training loss: 3.5630773779137854
Validation loss: 3.4163994543319296

Epoch: 6| Step: 9
Training loss: 4.255402217013622
Validation loss: 3.414498086404885

Epoch: 6| Step: 10
Training loss: 3.9628594605492813
Validation loss: 3.412947781012197

Epoch: 6| Step: 11
Training loss: 3.861520765300843
Validation loss: 3.4116374883300655

Epoch: 6| Step: 12
Training loss: 3.3100919787947065
Validation loss: 3.40972531332051

Epoch: 6| Step: 13
Training loss: 3.2590442405523494
Validation loss: 3.410567322625205

Epoch: 20| Step: 0
Training loss: 3.9381323412602924
Validation loss: 3.4129146791100755

Epoch: 6| Step: 1
Training loss: 3.6822863429928954
Validation loss: 3.4100036605749398

Epoch: 6| Step: 2
Training loss: 3.480892887666921
Validation loss: 3.409743893267267

Epoch: 6| Step: 3
Training loss: 3.457456883667097
Validation loss: 3.4049185402573756

Epoch: 6| Step: 4
Training loss: 4.288488130727155
Validation loss: 3.4030678169600965

Epoch: 6| Step: 5
Training loss: 3.006163623227162
Validation loss: 3.401134805086026

Epoch: 6| Step: 6
Training loss: 4.395604035723325
Validation loss: 3.399895544999164

Epoch: 6| Step: 7
Training loss: 3.4825459285426774
Validation loss: 3.4001734016181846

Epoch: 6| Step: 8
Training loss: 3.658061565016662
Validation loss: 3.400231232401677

Epoch: 6| Step: 9
Training loss: 3.6840149526385813
Validation loss: 3.399230003149289

Epoch: 6| Step: 10
Training loss: 3.853585042971109
Validation loss: 3.400522876010166

Epoch: 6| Step: 11
Training loss: 3.331622940572936
Validation loss: 3.3968003496172035

Epoch: 6| Step: 12
Training loss: 2.0687988505977617
Validation loss: 3.396831234218699

Epoch: 6| Step: 13
Training loss: 4.13710004365863
Validation loss: 3.3959668514039274

Epoch: 21| Step: 0
Training loss: 3.581518171831763
Validation loss: 3.391747590657405

Epoch: 6| Step: 1
Training loss: 3.552161490884701
Validation loss: 3.3904593850537554

Epoch: 6| Step: 2
Training loss: 3.5758743870752947
Validation loss: 3.3921981828208416

Epoch: 6| Step: 3
Training loss: 3.3631597446021506
Validation loss: 3.3893100030946997

Epoch: 6| Step: 4
Training loss: 3.8885546464939296
Validation loss: 3.3881029404709335

Epoch: 6| Step: 5
Training loss: 3.6070869096142864
Validation loss: 3.384693376818019

Epoch: 6| Step: 6
Training loss: 3.688315867023393
Validation loss: 3.3854960503117497

Epoch: 6| Step: 7
Training loss: 3.2607783075361683
Validation loss: 3.382613763487341

Epoch: 6| Step: 8
Training loss: 3.911366278339332
Validation loss: 3.381558962214897

Epoch: 6| Step: 9
Training loss: 3.40064807773942
Validation loss: 3.3795212041374327

Epoch: 6| Step: 10
Training loss: 2.7606236122340313
Validation loss: 3.3781503317745845

Epoch: 6| Step: 11
Training loss: 4.006484497634448
Validation loss: 3.378790262623764

Epoch: 6| Step: 12
Training loss: 3.786589076720301
Validation loss: 3.3786278250455624

Epoch: 6| Step: 13
Training loss: 4.316874179246294
Validation loss: 3.3797557310445923

Epoch: 22| Step: 0
Training loss: 3.674965973780882
Validation loss: 3.3749206181180105

Epoch: 6| Step: 1
Training loss: 4.042934546579354
Validation loss: 3.3743003034843344

Epoch: 6| Step: 2
Training loss: 3.027971362614736
Validation loss: 3.3713486812858426

Epoch: 6| Step: 3
Training loss: 4.084410752342087
Validation loss: 3.3679877765988966

Epoch: 6| Step: 4
Training loss: 3.3318695351107346
Validation loss: 3.369706763017827

Epoch: 6| Step: 5
Training loss: 4.14601055641873
Validation loss: 3.376385145138241

Epoch: 6| Step: 6
Training loss: 3.6792143499294863
Validation loss: 3.366595685785873

Epoch: 6| Step: 7
Training loss: 3.921726664743348
Validation loss: 3.3666513154703184

Epoch: 6| Step: 8
Training loss: 3.1510005391276925
Validation loss: 3.3624887141373674

Epoch: 6| Step: 9
Training loss: 4.42915354475851
Validation loss: 3.364562949868077

Epoch: 6| Step: 10
Training loss: 2.6201433940405767
Validation loss: 3.3640157244360664

Epoch: 6| Step: 11
Training loss: 3.179665905178512
Validation loss: 3.3656142990108697

Epoch: 6| Step: 12
Training loss: 3.7074288254514847
Validation loss: 3.3676171139242843

Epoch: 6| Step: 13
Training loss: 2.194244994047517
Validation loss: 3.3693234078272023

Epoch: 23| Step: 0
Training loss: 3.6421999164829515
Validation loss: 3.4031817264187563

Epoch: 6| Step: 1
Training loss: 3.9824309748853857
Validation loss: 3.403536188623402

Epoch: 6| Step: 2
Training loss: 2.7421089008945714
Validation loss: 3.381431196214469

Epoch: 6| Step: 3
Training loss: 3.7278694723960837
Validation loss: 3.3877426665978168

Epoch: 6| Step: 4
Training loss: 3.686975215488168
Validation loss: 3.398507742131696

Epoch: 6| Step: 5
Training loss: 3.98048612012433
Validation loss: 3.3801830649855487

Epoch: 6| Step: 6
Training loss: 4.00968309439238
Validation loss: 3.357964650661633

Epoch: 6| Step: 7
Training loss: 3.1105025657516907
Validation loss: 3.354553559316203

Epoch: 6| Step: 8
Training loss: 4.073864812646432
Validation loss: 3.355162116977026

Epoch: 6| Step: 9
Training loss: 3.216402549639601
Validation loss: 3.3568217161983944

Epoch: 6| Step: 10
Training loss: 3.286542130664955
Validation loss: 3.3624679624287177

Epoch: 6| Step: 11
Training loss: 3.0187818379431155
Validation loss: 3.366328362027276

Epoch: 6| Step: 12
Training loss: 3.510760523465678
Validation loss: 3.3882993938754864

Epoch: 6| Step: 13
Training loss: 4.4537903405781405
Validation loss: 3.3539171905058995

Epoch: 24| Step: 0
Training loss: 3.425023272358705
Validation loss: 3.351783910922028

Epoch: 6| Step: 1
Training loss: 3.768524573117564
Validation loss: 3.3489552294687845

Epoch: 6| Step: 2
Training loss: 3.4121703048008674
Validation loss: 3.345200544581407

Epoch: 6| Step: 3
Training loss: 3.9584325811425263
Validation loss: 3.342612319011308

Epoch: 6| Step: 4
Training loss: 3.9752684400593914
Validation loss: 3.341690791059378

Epoch: 6| Step: 5
Training loss: 3.079477700374609
Validation loss: 3.3400527467493166

Epoch: 6| Step: 6
Training loss: 3.9024554323514393
Validation loss: 3.341544751165674

Epoch: 6| Step: 7
Training loss: 3.3909740356243248
Validation loss: 3.3483721704091263

Epoch: 6| Step: 8
Training loss: 3.368761584203616
Validation loss: 3.3423470118460568

Epoch: 6| Step: 9
Training loss: 4.098066311256454
Validation loss: 3.334297779493553

Epoch: 6| Step: 10
Training loss: 3.4830998709042724
Validation loss: 3.3342574827874683

Epoch: 6| Step: 11
Training loss: 2.995777655567362
Validation loss: 3.3327953294124097

Epoch: 6| Step: 12
Training loss: 4.000749994538378
Validation loss: 3.331770665725975

Epoch: 6| Step: 13
Training loss: 2.338345718387243
Validation loss: 3.3308311274320666

Epoch: 25| Step: 0
Training loss: 3.9998658873009783
Validation loss: 3.3295636924465675

Epoch: 6| Step: 1
Training loss: 3.904527696481711
Validation loss: 3.3270506984472887

Epoch: 6| Step: 2
Training loss: 4.293699332525495
Validation loss: 3.3228319293392445

Epoch: 6| Step: 3
Training loss: 1.955480939923895
Validation loss: 3.3176634007234536

Epoch: 6| Step: 4
Training loss: 3.025090044431158
Validation loss: 3.3179083315202904

Epoch: 6| Step: 5
Training loss: 3.738722947512864
Validation loss: 3.3120785702640725

Epoch: 6| Step: 6
Training loss: 3.200188309374013
Validation loss: 3.3079558036643113

Epoch: 6| Step: 7
Training loss: 3.1999299280124016
Validation loss: 3.303563603547002

Epoch: 6| Step: 8
Training loss: 3.720100478179188
Validation loss: 3.3006512690037852

Epoch: 6| Step: 9
Training loss: 3.335382276870423
Validation loss: 3.2987963150843416

Epoch: 6| Step: 10
Training loss: 4.1716525700740315
Validation loss: 3.2967310045237785

Epoch: 6| Step: 11
Training loss: 3.2336548819043247
Validation loss: 3.2916743313591224

Epoch: 6| Step: 12
Training loss: 3.0022995400827925
Validation loss: 3.2900311534803097

Epoch: 6| Step: 13
Training loss: 4.628241768960243
Validation loss: 3.288967075941006

Epoch: 26| Step: 0
Training loss: 3.084409233915893
Validation loss: 3.277237430535486

Epoch: 6| Step: 1
Training loss: 3.8851446443434643
Validation loss: 3.2788882301767757

Epoch: 6| Step: 2
Training loss: 3.2427219180222764
Validation loss: 3.274581719773201

Epoch: 6| Step: 3
Training loss: 4.133441033549654
Validation loss: 3.2781039389651623

Epoch: 6| Step: 4
Training loss: 3.2316744675000297
Validation loss: 3.269508440440916

Epoch: 6| Step: 5
Training loss: 3.0561186030875334
Validation loss: 3.2680377967747245

Epoch: 6| Step: 6
Training loss: 3.194860300463471
Validation loss: 3.266639670770469

Epoch: 6| Step: 7
Training loss: 3.295577096603598
Validation loss: 3.2647194646802586

Epoch: 6| Step: 8
Training loss: 3.0270345419206826
Validation loss: 3.258905319889638

Epoch: 6| Step: 9
Training loss: 3.990812598638118
Validation loss: 3.255911594479998

Epoch: 6| Step: 10
Training loss: 3.7363893829923414
Validation loss: 3.252089797992328

Epoch: 6| Step: 11
Training loss: 3.5130535300476806
Validation loss: 3.247938824570893

Epoch: 6| Step: 12
Training loss: 4.211455417694635
Validation loss: 3.246310729785162

Epoch: 6| Step: 13
Training loss: 3.008122732834127
Validation loss: 3.2433562719063853

Epoch: 27| Step: 0
Training loss: 4.345656600874557
Validation loss: 3.244852691241411

Epoch: 6| Step: 1
Training loss: 3.6314810333029772
Validation loss: 3.242264778648405

Epoch: 6| Step: 2
Training loss: 3.294710289312693
Validation loss: 3.240766425498934

Epoch: 6| Step: 3
Training loss: 3.2061684640849384
Validation loss: 3.242254611093047

Epoch: 6| Step: 4
Training loss: 3.3981400282883385
Validation loss: 3.2369335886349684

Epoch: 6| Step: 5
Training loss: 2.9057337804934207
Validation loss: 3.236833465242971

Epoch: 6| Step: 6
Training loss: 3.4992350696098846
Validation loss: 3.2349519790126053

Epoch: 6| Step: 7
Training loss: 3.282797021842973
Validation loss: 3.23229728577342

Epoch: 6| Step: 8
Training loss: 3.7699280525040697
Validation loss: 3.2305191404529254

Epoch: 6| Step: 9
Training loss: 3.449010270277898
Validation loss: 3.2316539959084607

Epoch: 6| Step: 10
Training loss: 3.1781004898191423
Validation loss: 3.2313352439710195

Epoch: 6| Step: 11
Training loss: 3.1682393702808285
Validation loss: 3.2288938493761132

Epoch: 6| Step: 12
Training loss: 4.222565006819481
Validation loss: 3.231987949222974

Epoch: 6| Step: 13
Training loss: 2.875226385076816
Validation loss: 3.223874873963433

Epoch: 28| Step: 0
Training loss: 2.9764085464512737
Validation loss: 3.2236213431754313

Epoch: 6| Step: 1
Training loss: 3.9130031956796834
Validation loss: 3.228401238384419

Epoch: 6| Step: 2
Training loss: 3.9573969620227456
Validation loss: 3.2227852052186696

Epoch: 6| Step: 3
Training loss: 3.630719900915157
Validation loss: 3.2225123605335404

Epoch: 6| Step: 4
Training loss: 3.0288740461879393
Validation loss: 3.22156309896555

Epoch: 6| Step: 5
Training loss: 2.2645426302296006
Validation loss: 3.221052255014245

Epoch: 6| Step: 6
Training loss: 3.9216045879136403
Validation loss: 3.221883928487035

Epoch: 6| Step: 7
Training loss: 3.8470293647789693
Validation loss: 3.2209989968185497

Epoch: 6| Step: 8
Training loss: 2.481632566386402
Validation loss: 3.221552513543905

Epoch: 6| Step: 9
Training loss: 3.3598873723545
Validation loss: 3.2192770891459457

Epoch: 6| Step: 10
Training loss: 3.397924766008527
Validation loss: 3.2218534690944587

Epoch: 6| Step: 11
Training loss: 3.9660641450374032
Validation loss: 3.2212730401014293

Epoch: 6| Step: 12
Training loss: 4.09690490758296
Validation loss: 3.221475761432488

Epoch: 6| Step: 13
Training loss: 2.968386657966965
Validation loss: 3.2200402122019223

Epoch: 29| Step: 0
Training loss: 3.0796923060115975
Validation loss: 3.218160810903474

Epoch: 6| Step: 1
Training loss: 3.6000279531453274
Validation loss: 3.2184019839445086

Epoch: 6| Step: 2
Training loss: 3.3139237996689372
Validation loss: 3.2159427340389355

Epoch: 6| Step: 3
Training loss: 3.658644193912068
Validation loss: 3.214404473240698

Epoch: 6| Step: 4
Training loss: 3.4393000658021906
Validation loss: 3.2130743551759458

Epoch: 6| Step: 5
Training loss: 2.65850985268831
Validation loss: 3.2120194346483415

Epoch: 6| Step: 6
Training loss: 4.033497265303273
Validation loss: 3.2104316394589287

Epoch: 6| Step: 7
Training loss: 2.94339533975622
Validation loss: 3.2080439493124326

Epoch: 6| Step: 8
Training loss: 3.7703313897391233
Validation loss: 3.2065253352637013

Epoch: 6| Step: 9
Training loss: 4.335321826010499
Validation loss: 3.204427305208558

Epoch: 6| Step: 10
Training loss: 3.643266235482917
Validation loss: 3.205159073856907

Epoch: 6| Step: 11
Training loss: 2.9259215704522887
Validation loss: 3.203619772342439

Epoch: 6| Step: 12
Training loss: 3.120830500915084
Validation loss: 3.229792176211348

Epoch: 6| Step: 13
Training loss: 3.775978386008909
Validation loss: 3.2608293129813117

Epoch: 30| Step: 0
Training loss: 3.169702847870574
Validation loss: 3.1930675553760026

Epoch: 6| Step: 1
Training loss: 3.4623440538674193
Validation loss: 3.1953674242686865

Epoch: 6| Step: 2
Training loss: 2.833241255516884
Validation loss: 3.2068480169914313

Epoch: 6| Step: 3
Training loss: 3.129373770276059
Validation loss: 3.2247159954457554

Epoch: 6| Step: 4
Training loss: 3.320323701727428
Validation loss: 3.219765609348233

Epoch: 6| Step: 5
Training loss: 2.6395881016504283
Validation loss: 3.2236590370344462

Epoch: 6| Step: 6
Training loss: 3.1223673603116047
Validation loss: 3.2479567221959367

Epoch: 6| Step: 7
Training loss: 4.2606167299387065
Validation loss: 3.246526714315491

Epoch: 6| Step: 8
Training loss: 4.330379408496812
Validation loss: 3.227104364182281

Epoch: 6| Step: 9
Training loss: 3.571465170536522
Validation loss: 3.2086519313005932

Epoch: 6| Step: 10
Training loss: 3.986235419863057
Validation loss: 3.19774091346582

Epoch: 6| Step: 11
Training loss: 3.629815290601476
Validation loss: 3.189060904319329

Epoch: 6| Step: 12
Training loss: 3.1195111708516703
Validation loss: 3.18394843553533

Epoch: 6| Step: 13
Training loss: 3.646067729862827
Validation loss: 3.184653978669175

Epoch: 31| Step: 0
Training loss: 3.877714744342184
Validation loss: 3.177644291897682

Epoch: 6| Step: 1
Training loss: 3.449352015580981
Validation loss: 3.1799309137405842

Epoch: 6| Step: 2
Training loss: 3.6955350845110444
Validation loss: 3.182884820946118

Epoch: 6| Step: 3
Training loss: 3.6020965511211154
Validation loss: 3.1835190606781634

Epoch: 6| Step: 4
Training loss: 3.866178993734858
Validation loss: 3.1914483375599194

Epoch: 6| Step: 5
Training loss: 3.331203415994056
Validation loss: 3.180539586638997

Epoch: 6| Step: 6
Training loss: 3.3917524159781984
Validation loss: 3.1724628473766283

Epoch: 6| Step: 7
Training loss: 3.2981936452725615
Validation loss: 3.168260088981712

Epoch: 6| Step: 8
Training loss: 3.008365253339022
Validation loss: 3.1674613608523834

Epoch: 6| Step: 9
Training loss: 3.696041494970524
Validation loss: 3.1681505012553606

Epoch: 6| Step: 10
Training loss: 2.6022315095890853
Validation loss: 3.1663244744747163

Epoch: 6| Step: 11
Training loss: 4.179040591365705
Validation loss: 3.170133375935429

Epoch: 6| Step: 12
Training loss: 2.3274436824225484
Validation loss: 3.166901274271279

Epoch: 6| Step: 13
Training loss: 3.2778210843632376
Validation loss: 3.1603464716070766

Epoch: 32| Step: 0
Training loss: 3.2806968586036347
Validation loss: 3.159730792440585

Epoch: 6| Step: 1
Training loss: 3.6342148565957637
Validation loss: 3.1559538912007996

Epoch: 6| Step: 2
Training loss: 3.324518819998089
Validation loss: 3.153365313200805

Epoch: 6| Step: 3
Training loss: 3.149627082185435
Validation loss: 3.1550999018911856

Epoch: 6| Step: 4
Training loss: 3.3397703642339587
Validation loss: 3.1516385093459287

Epoch: 6| Step: 5
Training loss: 4.214027757116004
Validation loss: 3.1504200257680264

Epoch: 6| Step: 6
Training loss: 3.2672364853808498
Validation loss: 3.14956037172135

Epoch: 6| Step: 7
Training loss: 3.0252144099141383
Validation loss: 3.164131526581481

Epoch: 6| Step: 8
Training loss: 2.667206193068465
Validation loss: 3.170253353468497

Epoch: 6| Step: 9
Training loss: 4.399072956913653
Validation loss: 3.1759302659581103

Epoch: 6| Step: 10
Training loss: 3.4192567327731123
Validation loss: 3.1450300037821735

Epoch: 6| Step: 11
Training loss: 1.9218743797239217
Validation loss: 3.146923958090141

Epoch: 6| Step: 12
Training loss: 3.897552450926998
Validation loss: 3.1477613823137025

Epoch: 6| Step: 13
Training loss: 3.717714309723207
Validation loss: 3.1517733131378827

Epoch: 33| Step: 0
Training loss: 3.1117369915357864
Validation loss: 3.15402818614422

Epoch: 6| Step: 1
Training loss: 3.2747775227931903
Validation loss: 3.1604525426199426

Epoch: 6| Step: 2
Training loss: 3.6226997970125683
Validation loss: 3.1618151187279504

Epoch: 6| Step: 3
Training loss: 3.2184053995791206
Validation loss: 3.1711024607404616

Epoch: 6| Step: 4
Training loss: 4.30996541162052
Validation loss: 3.163877220912205

Epoch: 6| Step: 5
Training loss: 3.0718900010760373
Validation loss: 3.1541931523376183

Epoch: 6| Step: 6
Training loss: 3.1915165147911377
Validation loss: 3.1505617168592024

Epoch: 6| Step: 7
Training loss: 3.474275604050489
Validation loss: 3.150349146095865

Epoch: 6| Step: 8
Training loss: 2.687392654049381
Validation loss: 3.146412929206694

Epoch: 6| Step: 9
Training loss: 3.6360143190276117
Validation loss: 3.145705170694024

Epoch: 6| Step: 10
Training loss: 3.23264329042464
Validation loss: 3.1447792713101825

Epoch: 6| Step: 11
Training loss: 3.5696910091858105
Validation loss: 3.143845543312366

Epoch: 6| Step: 12
Training loss: 3.790421138102573
Validation loss: 3.143388270767101

Epoch: 6| Step: 13
Training loss: 3.4232909177723467
Validation loss: 3.141065004802403

Epoch: 34| Step: 0
Training loss: 2.931225019726731
Validation loss: 3.1418143693476974

Epoch: 6| Step: 1
Training loss: 2.65855451359298
Validation loss: 3.1384849581253507

Epoch: 6| Step: 2
Training loss: 3.277474692892201
Validation loss: 3.143613033539872

Epoch: 6| Step: 3
Training loss: 3.475836723092462
Validation loss: 3.1440938943138668

Epoch: 6| Step: 4
Training loss: 3.6020144760289985
Validation loss: 3.1424370137487156

Epoch: 6| Step: 5
Training loss: 3.9837753742272923
Validation loss: 3.139781611939195

Epoch: 6| Step: 6
Training loss: 2.967484696436358
Validation loss: 3.135488936447467

Epoch: 6| Step: 7
Training loss: 3.765264470106475
Validation loss: 3.1324477817229974

Epoch: 6| Step: 8
Training loss: 3.6158835118359374
Validation loss: 3.132417570625042

Epoch: 6| Step: 9
Training loss: 3.2953011611591463
Validation loss: 3.1300975258586208

Epoch: 6| Step: 10
Training loss: 3.3339563423323533
Validation loss: 3.125600979350063

Epoch: 6| Step: 11
Training loss: 2.6798645494877302
Validation loss: 3.1235494663991337

Epoch: 6| Step: 12
Training loss: 3.809864196159263
Validation loss: 3.1232130950986225

Epoch: 6| Step: 13
Training loss: 4.220412993267392
Validation loss: 3.1221008881263357

Epoch: 35| Step: 0
Training loss: 2.9983654337577046
Validation loss: 3.124900388052956

Epoch: 6| Step: 1
Training loss: 3.8641266394450566
Validation loss: 3.116855796649972

Epoch: 6| Step: 2
Training loss: 2.5040333636745467
Validation loss: 3.113300546736673

Epoch: 6| Step: 3
Training loss: 3.8089816008444157
Validation loss: 3.115779516269633

Epoch: 6| Step: 4
Training loss: 3.386110596573745
Validation loss: 3.112908807126057

Epoch: 6| Step: 5
Training loss: 3.9592088768363713
Validation loss: 3.110066170153536

Epoch: 6| Step: 6
Training loss: 3.0540136974654586
Validation loss: 3.1077671239894333

Epoch: 6| Step: 7
Training loss: 2.9909566633578897
Validation loss: 3.101129783275062

Epoch: 6| Step: 8
Training loss: 2.8745319151262003
Validation loss: 3.09819092542034

Epoch: 6| Step: 9
Training loss: 3.3748729823194163
Validation loss: 3.0960531734335905

Epoch: 6| Step: 10
Training loss: 3.1340128817801727
Validation loss: 3.093789377269564

Epoch: 6| Step: 11
Training loss: 3.8556498105281527
Validation loss: 3.094958247892258

Epoch: 6| Step: 12
Training loss: 3.343817166518383
Validation loss: 3.094469759219157

Epoch: 6| Step: 13
Training loss: 4.047636571680596
Validation loss: 3.0922615080923332

Epoch: 36| Step: 0
Training loss: 3.3099178110388965
Validation loss: 3.0927807203225406

Epoch: 6| Step: 1
Training loss: 3.009020119536084
Validation loss: 3.089558507849043

Epoch: 6| Step: 2
Training loss: 3.386974144691914
Validation loss: 3.0881204581252653

Epoch: 6| Step: 3
Training loss: 2.3657941588942815
Validation loss: 3.0873186008757134

Epoch: 6| Step: 4
Training loss: 3.8025668459502353
Validation loss: 3.087023859175224

Epoch: 6| Step: 5
Training loss: 3.1684920587835954
Validation loss: 3.088130303002189

Epoch: 6| Step: 6
Training loss: 3.05607709961145
Validation loss: 3.0873301198542022

Epoch: 6| Step: 7
Training loss: 3.871811077584728
Validation loss: 3.0847266304872933

Epoch: 6| Step: 8
Training loss: 2.5295562728953356
Validation loss: 3.084692995848561

Epoch: 6| Step: 9
Training loss: 4.027141044243965
Validation loss: 3.080595256332695

Epoch: 6| Step: 10
Training loss: 3.7041912877595125
Validation loss: 3.0796668184414164

Epoch: 6| Step: 11
Training loss: 3.5668065325921985
Validation loss: 3.0780238602427783

Epoch: 6| Step: 12
Training loss: 3.259714134179908
Validation loss: 3.0766779165998064

Epoch: 6| Step: 13
Training loss: 3.672256774534596
Validation loss: 3.0748181872005107

Epoch: 37| Step: 0
Training loss: 3.1846977332393114
Validation loss: 3.0740798931552984

Epoch: 6| Step: 1
Training loss: 3.294701171429815
Validation loss: 3.0871927645296022

Epoch: 6| Step: 2
Training loss: 2.8707094103933435
Validation loss: 3.116819253202043

Epoch: 6| Step: 3
Training loss: 2.730288520071099
Validation loss: 3.0920157047769616

Epoch: 6| Step: 4
Training loss: 3.7438293550516017
Validation loss: 3.0800129920119192

Epoch: 6| Step: 5
Training loss: 4.311657809521328
Validation loss: 3.12327381326801

Epoch: 6| Step: 6
Training loss: 2.2248207105773417
Validation loss: 3.1204889088670122

Epoch: 6| Step: 7
Training loss: 3.583415156176933
Validation loss: 3.0981671506410797

Epoch: 6| Step: 8
Training loss: 3.7529606893560783
Validation loss: 3.0721969726682423

Epoch: 6| Step: 9
Training loss: 3.1742478688787137
Validation loss: 3.073198657952086

Epoch: 6| Step: 10
Training loss: 3.430863928137634
Validation loss: 3.078169102839775

Epoch: 6| Step: 11
Training loss: 3.6652764950653203
Validation loss: 3.0800775823209596

Epoch: 6| Step: 12
Training loss: 3.4117714463993365
Validation loss: 3.0835993606846106

Epoch: 6| Step: 13
Training loss: 3.133575270490575
Validation loss: 3.087260057859766

Epoch: 38| Step: 0
Training loss: 2.530681781805393
Validation loss: 3.090518352833037

Epoch: 6| Step: 1
Training loss: 3.815686629513865
Validation loss: 3.085874013480058

Epoch: 6| Step: 2
Training loss: 2.791840182553334
Validation loss: 3.086539967093652

Epoch: 6| Step: 3
Training loss: 3.170692862474922
Validation loss: 3.082407336438619

Epoch: 6| Step: 4
Training loss: 2.500582436426023
Validation loss: 3.0775905070328697

Epoch: 6| Step: 5
Training loss: 4.113316491420731
Validation loss: 3.079641597043579

Epoch: 6| Step: 6
Training loss: 2.93564027395289
Validation loss: 3.074828504883608

Epoch: 6| Step: 7
Training loss: 3.1960063451481973
Validation loss: 3.07157367428548

Epoch: 6| Step: 8
Training loss: 3.806312292431756
Validation loss: 3.070645982598864

Epoch: 6| Step: 9
Training loss: 3.6104224860747394
Validation loss: 3.0679289693218146

Epoch: 6| Step: 10
Training loss: 3.3515616463613425
Validation loss: 3.068333647911435

Epoch: 6| Step: 11
Training loss: 4.113078605971017
Validation loss: 3.0668180794362474

Epoch: 6| Step: 12
Training loss: 3.105228438766041
Validation loss: 3.063403204201269

Epoch: 6| Step: 13
Training loss: 3.308060460083576
Validation loss: 3.0639913182981275

Epoch: 39| Step: 0
Training loss: 3.2696590056805213
Validation loss: 3.0635027270369837

Epoch: 6| Step: 1
Training loss: 3.3127139040421496
Validation loss: 3.0639837796245013

Epoch: 6| Step: 2
Training loss: 4.556933207628686
Validation loss: 3.0626887049243976

Epoch: 6| Step: 3
Training loss: 3.541044711684178
Validation loss: 3.062253579226428

Epoch: 6| Step: 4
Training loss: 2.738929834977555
Validation loss: 3.062819801761793

Epoch: 6| Step: 5
Training loss: 2.915583400286447
Validation loss: 3.061028638339075

Epoch: 6| Step: 6
Training loss: 3.090599845267008
Validation loss: 3.0603074090972173

Epoch: 6| Step: 7
Training loss: 2.699426314547841
Validation loss: 3.0581311096137216

Epoch: 6| Step: 8
Training loss: 3.229101775142889
Validation loss: 3.0595610443776424

Epoch: 6| Step: 9
Training loss: 4.188144008022359
Validation loss: 3.059823316955399

Epoch: 6| Step: 10
Training loss: 2.958115815954985
Validation loss: 3.0572652555511675

Epoch: 6| Step: 11
Training loss: 2.8928270355218766
Validation loss: 3.058464225558118

Epoch: 6| Step: 12
Training loss: 3.736719137929888
Validation loss: 3.0572348079951914

Epoch: 6| Step: 13
Training loss: 2.9263920267437604
Validation loss: 3.0550525645307047

Epoch: 40| Step: 0
Training loss: 3.6819329345579503
Validation loss: 3.054999931049059

Epoch: 6| Step: 1
Training loss: 4.533347860948809
Validation loss: 3.05339569454596

Epoch: 6| Step: 2
Training loss: 3.137763394550045
Validation loss: 3.053630190059026

Epoch: 6| Step: 3
Training loss: 3.3691932740451525
Validation loss: 3.05059599776457

Epoch: 6| Step: 4
Training loss: 2.8378150126497865
Validation loss: 3.0544594224611545

Epoch: 6| Step: 5
Training loss: 2.8050660964331815
Validation loss: 3.0512119244629945

Epoch: 6| Step: 6
Training loss: 3.77045583503898
Validation loss: 3.0513881210888854

Epoch: 6| Step: 7
Training loss: 3.1345280162090456
Validation loss: 3.049741475186491

Epoch: 6| Step: 8
Training loss: 2.662641487481357
Validation loss: 3.0484078959402043

Epoch: 6| Step: 9
Training loss: 2.720991766982011
Validation loss: 3.048531993012148

Epoch: 6| Step: 10
Training loss: 3.6325462982104684
Validation loss: 3.045955542575206

Epoch: 6| Step: 11
Training loss: 2.8177189195096792
Validation loss: 3.0495980042049595

Epoch: 6| Step: 12
Training loss: 3.444743345137223
Validation loss: 3.053043760481994

Epoch: 6| Step: 13
Training loss: 3.6971833410845036
Validation loss: 3.0499430390379305

Epoch: 41| Step: 0
Training loss: 4.180081757106403
Validation loss: 3.057634796449155

Epoch: 6| Step: 1
Training loss: 3.0112698587829274
Validation loss: 3.053025061146962

Epoch: 6| Step: 2
Training loss: 4.024572238345357
Validation loss: 3.0471377006808877

Epoch: 6| Step: 3
Training loss: 3.1598467586880084
Validation loss: 3.0462864107711436

Epoch: 6| Step: 4
Training loss: 3.8101678187539023
Validation loss: 3.0452037012750037

Epoch: 6| Step: 5
Training loss: 2.809702605261095
Validation loss: 3.0449295517965838

Epoch: 6| Step: 6
Training loss: 2.958278458493771
Validation loss: 3.0439878000045075

Epoch: 6| Step: 7
Training loss: 3.4675095548271218
Validation loss: 3.0538470880859347

Epoch: 6| Step: 8
Training loss: 2.9602368816751614
Validation loss: 3.0559894082848436

Epoch: 6| Step: 9
Training loss: 2.323783974894202
Validation loss: 3.0477231578735213

Epoch: 6| Step: 10
Training loss: 4.098453993187839
Validation loss: 3.04421499129821

Epoch: 6| Step: 11
Training loss: 2.758369195096095
Validation loss: 3.0436558682804886

Epoch: 6| Step: 12
Training loss: 3.034377068028791
Validation loss: 3.041828424858664

Epoch: 6| Step: 13
Training loss: 3.460248684848899
Validation loss: 3.0418951803066876

Epoch: 42| Step: 0
Training loss: 3.540555862061483
Validation loss: 3.0434837330463447

Epoch: 6| Step: 1
Training loss: 3.5817005666267816
Validation loss: 3.040997135802878

Epoch: 6| Step: 2
Training loss: 3.1416932372193105
Validation loss: 3.038506317554585

Epoch: 6| Step: 3
Training loss: 3.5922689288427314
Validation loss: 3.0402287247616195

Epoch: 6| Step: 4
Training loss: 2.5451122338629752
Validation loss: 3.042035593900929

Epoch: 6| Step: 5
Training loss: 3.344054591486186
Validation loss: 3.040903128484493

Epoch: 6| Step: 6
Training loss: 4.100973497514869
Validation loss: 3.040915826513006

Epoch: 6| Step: 7
Training loss: 2.6941815201027084
Validation loss: 3.040667592445608

Epoch: 6| Step: 8
Training loss: 3.7819485610215393
Validation loss: 3.0392808433738994

Epoch: 6| Step: 9
Training loss: 3.6566126716913736
Validation loss: 3.040995105794813

Epoch: 6| Step: 10
Training loss: 3.0396822025429
Validation loss: 3.041548382904417

Epoch: 6| Step: 11
Training loss: 2.7697832990914257
Validation loss: 3.0372912320787955

Epoch: 6| Step: 12
Training loss: 2.830828981063981
Validation loss: 3.0365626594552455

Epoch: 6| Step: 13
Training loss: 3.5951386795566234
Validation loss: 3.035253974275813

Epoch: 43| Step: 0
Training loss: 3.214519201608503
Validation loss: 3.034772799211772

Epoch: 6| Step: 1
Training loss: 3.169041763507155
Validation loss: 3.034702249491305

Epoch: 6| Step: 2
Training loss: 3.8407243434886102
Validation loss: 3.0319455575827194

Epoch: 6| Step: 3
Training loss: 3.3359562250188026
Validation loss: 3.0326272169879296

Epoch: 6| Step: 4
Training loss: 3.096340751565416
Validation loss: 3.032566952861669

Epoch: 6| Step: 5
Training loss: 3.421227798919506
Validation loss: 3.031199745883942

Epoch: 6| Step: 6
Training loss: 3.333359877162787
Validation loss: 3.0309481481596863

Epoch: 6| Step: 7
Training loss: 2.9626812392539374
Validation loss: 3.029873123274183

Epoch: 6| Step: 8
Training loss: 3.425576772644391
Validation loss: 3.0298132722823943

Epoch: 6| Step: 9
Training loss: 3.411187189795254
Validation loss: 3.029657022918748

Epoch: 6| Step: 10
Training loss: 2.7090910414066713
Validation loss: 3.028107513187941

Epoch: 6| Step: 11
Training loss: 3.4632957122590264
Validation loss: 3.0277957380106506

Epoch: 6| Step: 12
Training loss: 3.6072924662512125
Validation loss: 3.0300704645219625

Epoch: 6| Step: 13
Training loss: 3.170740084252376
Validation loss: 3.028692226276608

Epoch: 44| Step: 0
Training loss: 3.2331117383654324
Validation loss: 3.0282981428284392

Epoch: 6| Step: 1
Training loss: 2.278242349414837
Validation loss: 3.028291180698613

Epoch: 6| Step: 2
Training loss: 2.973117065804019
Validation loss: 3.025731424300824

Epoch: 6| Step: 3
Training loss: 4.0946155826914366
Validation loss: 3.028612189011293

Epoch: 6| Step: 4
Training loss: 3.3121236911288374
Validation loss: 3.0263876889846717

Epoch: 6| Step: 5
Training loss: 3.621154192077478
Validation loss: 3.0275926958789285

Epoch: 6| Step: 6
Training loss: 3.261803686440892
Validation loss: 3.0318555025233476

Epoch: 6| Step: 7
Training loss: 2.9478790676203888
Validation loss: 3.0324189165359963

Epoch: 6| Step: 8
Training loss: 2.9621899857054363
Validation loss: 3.0368067278512285

Epoch: 6| Step: 9
Training loss: 3.264833345234602
Validation loss: 3.0357743583809564

Epoch: 6| Step: 10
Training loss: 3.615575707313083
Validation loss: 3.050746667164964

Epoch: 6| Step: 11
Training loss: 3.6306283599265337
Validation loss: 3.040557757520452

Epoch: 6| Step: 12
Training loss: 3.5301328259082103
Validation loss: 3.0408894490857232

Epoch: 6| Step: 13
Training loss: 3.288143944858834
Validation loss: 3.024607676217806

Epoch: 45| Step: 0
Training loss: 3.5955246234040565
Validation loss: 3.0203020069149757

Epoch: 6| Step: 1
Training loss: 3.4834749573264214
Validation loss: 3.0191239937727055

Epoch: 6| Step: 2
Training loss: 3.0869892887168144
Validation loss: 3.0238002126985397

Epoch: 6| Step: 3
Training loss: 3.292398749599931
Validation loss: 3.025313020547099

Epoch: 6| Step: 4
Training loss: 2.9270189669626303
Validation loss: 3.024677059502472

Epoch: 6| Step: 5
Training loss: 2.6638688271564535
Validation loss: 3.0348017716485876

Epoch: 6| Step: 6
Training loss: 3.999014852325949
Validation loss: 3.047913159539774

Epoch: 6| Step: 7
Training loss: 3.1743851674625514
Validation loss: 3.019959588965177

Epoch: 6| Step: 8
Training loss: 3.776340418430465
Validation loss: 3.018719699131507

Epoch: 6| Step: 9
Training loss: 3.7806754187994573
Validation loss: 3.020259257510967

Epoch: 6| Step: 10
Training loss: 3.0331088000465662
Validation loss: 3.0210992742017764

Epoch: 6| Step: 11
Training loss: 3.2157792390806232
Validation loss: 3.0272713266760887

Epoch: 6| Step: 12
Training loss: 3.2409327273544735
Validation loss: 3.022082322148976

Epoch: 6| Step: 13
Training loss: 2.1494556580695217
Validation loss: 3.018843566155133

Epoch: 46| Step: 0
Training loss: 3.499613876842316
Validation loss: 3.0162984674195896

Epoch: 6| Step: 1
Training loss: 2.880580461869143
Validation loss: 3.0158635799092157

Epoch: 6| Step: 2
Training loss: 3.588129840283434
Validation loss: 3.0156960325712805

Epoch: 6| Step: 3
Training loss: 2.990566362306377
Validation loss: 3.016550539136464

Epoch: 6| Step: 4
Training loss: 2.754114887098999
Validation loss: 3.015922703841124

Epoch: 6| Step: 5
Training loss: 3.836099345411457
Validation loss: 3.021494215545898

Epoch: 6| Step: 6
Training loss: 3.4143270219856685
Validation loss: 3.0273545148633616

Epoch: 6| Step: 7
Training loss: 3.519809521376471
Validation loss: 3.035988993118803

Epoch: 6| Step: 8
Training loss: 2.435570172991515
Validation loss: 3.0294165098882466

Epoch: 6| Step: 9
Training loss: 3.681123036395555
Validation loss: 3.0210344348768197

Epoch: 6| Step: 10
Training loss: 3.9656860058287737
Validation loss: 3.0118697316811374

Epoch: 6| Step: 11
Training loss: 2.8533453397706214
Validation loss: 3.0108375503479943

Epoch: 6| Step: 12
Training loss: 2.9179363938341623
Validation loss: 3.0090571610690233

Epoch: 6| Step: 13
Training loss: 3.548939108490926
Validation loss: 3.0103547191040527

Epoch: 47| Step: 0
Training loss: 2.9194413928463523
Validation loss: 3.0101555709174015

Epoch: 6| Step: 1
Training loss: 2.976826973927547
Validation loss: 3.0112015381272363

Epoch: 6| Step: 2
Training loss: 3.620575407884731
Validation loss: 3.011802718454484

Epoch: 6| Step: 3
Training loss: 3.216028933646397
Validation loss: 3.0108320149304193

Epoch: 6| Step: 4
Training loss: 2.8117361090978275
Validation loss: 3.0102491826471467

Epoch: 6| Step: 5
Training loss: 2.9263340182099533
Validation loss: 3.0086143734155386

Epoch: 6| Step: 6
Training loss: 3.4784596956480676
Validation loss: 3.0077032620479693

Epoch: 6| Step: 7
Training loss: 3.645939431236163
Validation loss: 3.0088229960772916

Epoch: 6| Step: 8
Training loss: 3.1694064752561335
Validation loss: 3.007996481148296

Epoch: 6| Step: 9
Training loss: 2.9687047051437725
Validation loss: 3.008865722223267

Epoch: 6| Step: 10
Training loss: 3.513240157911999
Validation loss: 3.008190945300246

Epoch: 6| Step: 11
Training loss: 3.89850257100628
Validation loss: 3.0080004970660963

Epoch: 6| Step: 12
Training loss: 3.1581791185022197
Validation loss: 3.0068279383577337

Epoch: 6| Step: 13
Training loss: 3.7948369337187104
Validation loss: 3.0062875607483885

Epoch: 48| Step: 0
Training loss: 3.0720759561804445
Validation loss: 3.006417210672474

Epoch: 6| Step: 1
Training loss: 3.506736811333985
Validation loss: 3.0046868237085915

Epoch: 6| Step: 2
Training loss: 4.02094412273829
Validation loss: 3.0054545388135163

Epoch: 6| Step: 3
Training loss: 3.3464549879429315
Validation loss: 3.002700770953891

Epoch: 6| Step: 4
Training loss: 3.1305705964762214
Validation loss: 3.0036042688111615

Epoch: 6| Step: 5
Training loss: 3.388917695289571
Validation loss: 3.0031247204783256

Epoch: 6| Step: 6
Training loss: 2.919168289565988
Validation loss: 3.0023011283221592

Epoch: 6| Step: 7
Training loss: 3.2734063267646043
Validation loss: 3.006815541435646

Epoch: 6| Step: 8
Training loss: 2.875840437408784
Validation loss: 3.0078358306640474

Epoch: 6| Step: 9
Training loss: 3.5295368191124883
Validation loss: 3.0106539727287114

Epoch: 6| Step: 10
Training loss: 3.7829143549849076
Validation loss: 3.0032309972780475

Epoch: 6| Step: 11
Training loss: 2.6638191537101568
Validation loss: 3.0003993886257985

Epoch: 6| Step: 12
Training loss: 3.222026157625789
Validation loss: 2.9975701100008374

Epoch: 6| Step: 13
Training loss: 2.8566384483317635
Validation loss: 2.9961463299083317

Epoch: 49| Step: 0
Training loss: 3.050534911229325
Validation loss: 2.9978665290843907

Epoch: 6| Step: 1
Training loss: 3.6773386462281343
Validation loss: 2.9999941155844234

Epoch: 6| Step: 2
Training loss: 3.436976444948362
Validation loss: 2.9992547784537247

Epoch: 6| Step: 3
Training loss: 3.03884502505536
Validation loss: 2.998984741025826

Epoch: 6| Step: 4
Training loss: 3.982738083824763
Validation loss: 3.0012157841075022

Epoch: 6| Step: 5
Training loss: 3.0202433744474226
Validation loss: 3.0029282225278355

Epoch: 6| Step: 6
Training loss: 3.06392278513215
Validation loss: 2.9983114357970955

Epoch: 6| Step: 7
Training loss: 3.1535994476174656
Validation loss: 2.995583455340948

Epoch: 6| Step: 8
Training loss: 3.618516846625358
Validation loss: 2.9972998575017247

Epoch: 6| Step: 9
Training loss: 3.0847916805717066
Validation loss: 2.9947908836816706

Epoch: 6| Step: 10
Training loss: 2.5598810350075087
Validation loss: 2.993730284662997

Epoch: 6| Step: 11
Training loss: 3.0853680435322937
Validation loss: 2.9949723777803103

Epoch: 6| Step: 12
Training loss: 3.880469492203158
Validation loss: 2.994551412496332

Epoch: 6| Step: 13
Training loss: 2.6762327829561716
Validation loss: 2.9982270741143537

Epoch: 50| Step: 0
Training loss: 3.303627511509469
Validation loss: 2.998157985101122

Epoch: 6| Step: 1
Training loss: 3.2117614431473562
Validation loss: 2.9977916447887827

Epoch: 6| Step: 2
Training loss: 3.1600442873591645
Validation loss: 2.9970018862741568

Epoch: 6| Step: 3
Training loss: 2.4318656357678288
Validation loss: 3.0002297498035393

Epoch: 6| Step: 4
Training loss: 3.249985768213656
Validation loss: 3.000571470795264

Epoch: 6| Step: 5
Training loss: 3.4920191372219196
Validation loss: 3.0000424963152783

Epoch: 6| Step: 6
Training loss: 3.007863071561467
Validation loss: 3.000699216444956

Epoch: 6| Step: 7
Training loss: 3.1385416740943324
Validation loss: 2.995027451116938

Epoch: 6| Step: 8
Training loss: 3.4714435738537066
Validation loss: 2.9952190083928603

Epoch: 6| Step: 9
Training loss: 3.4262015803637573
Validation loss: 2.9931773279199194

Epoch: 6| Step: 10
Training loss: 3.855492619804845
Validation loss: 2.9941941861680546

Epoch: 6| Step: 11
Training loss: 3.1846323016045885
Validation loss: 2.994858691021478

Epoch: 6| Step: 12
Training loss: 2.909898662047988
Validation loss: 2.9930140515874126

Epoch: 6| Step: 13
Training loss: 4.118975546049065
Validation loss: 2.9950707678016593

Epoch: 51| Step: 0
Training loss: 3.6531478894171703
Validation loss: 2.991847206954771

Epoch: 6| Step: 1
Training loss: 3.334523242919197
Validation loss: 2.9922147642675743

Epoch: 6| Step: 2
Training loss: 3.1821502970476563
Validation loss: 3.0047796613346547

Epoch: 6| Step: 3
Training loss: 3.3746357473973845
Validation loss: 3.0086236842990224

Epoch: 6| Step: 4
Training loss: 3.0475771363958475
Validation loss: 3.000612521108595

Epoch: 6| Step: 5
Training loss: 3.3084039374696004
Validation loss: 2.9998666774699085

Epoch: 6| Step: 6
Training loss: 3.444725349894539
Validation loss: 2.990720845419273

Epoch: 6| Step: 7
Training loss: 3.322952190595936
Validation loss: 2.988090264639939

Epoch: 6| Step: 8
Training loss: 2.5885826941653747
Validation loss: 2.9863810485362334

Epoch: 6| Step: 9
Training loss: 3.45283127307924
Validation loss: 2.9869871471553147

Epoch: 6| Step: 10
Training loss: 3.647226005862784
Validation loss: 2.9859307882304864

Epoch: 6| Step: 11
Training loss: 2.831521539529728
Validation loss: 2.985127845492023

Epoch: 6| Step: 12
Training loss: 3.568303383908355
Validation loss: 2.9856685993232226

Epoch: 6| Step: 13
Training loss: 2.4831542848731996
Validation loss: 2.984882251711044

Epoch: 52| Step: 0
Training loss: 3.73915311557691
Validation loss: 2.9837556615221974

Epoch: 6| Step: 1
Training loss: 2.712192915308768
Validation loss: 2.983802438540461

Epoch: 6| Step: 2
Training loss: 3.506751768822488
Validation loss: 2.983440180386901

Epoch: 6| Step: 3
Training loss: 3.2910772029198303
Validation loss: 2.9818318879258356

Epoch: 6| Step: 4
Training loss: 2.6723127396925577
Validation loss: 2.9809905089416993

Epoch: 6| Step: 5
Training loss: 2.926557572865246
Validation loss: 2.9813717845325396

Epoch: 6| Step: 6
Training loss: 3.45522192897811
Validation loss: 2.9808904105784895

Epoch: 6| Step: 7
Training loss: 2.666205296738548
Validation loss: 2.979697995801058

Epoch: 6| Step: 8
Training loss: 3.6889146580491827
Validation loss: 2.982608840585184

Epoch: 6| Step: 9
Training loss: 4.02657644545509
Validation loss: 2.9814926468356266

Epoch: 6| Step: 10
Training loss: 3.3009262865694584
Validation loss: 2.9834471148500152

Epoch: 6| Step: 11
Training loss: 3.66997631574675
Validation loss: 2.989670337635669

Epoch: 6| Step: 12
Training loss: 2.8877881125180034
Validation loss: 2.9834716714845886

Epoch: 6| Step: 13
Training loss: 2.273371849554141
Validation loss: 2.9877876828007155

Epoch: 53| Step: 0
Training loss: 3.2962815170893376
Validation loss: 2.985777665472361

Epoch: 6| Step: 1
Training loss: 3.8566516735034946
Validation loss: 2.987671217077641

Epoch: 6| Step: 2
Training loss: 3.7214618700199265
Validation loss: 2.9922316631565553

Epoch: 6| Step: 3
Training loss: 2.8233652262892392
Validation loss: 2.989086335483631

Epoch: 6| Step: 4
Training loss: 3.5511023247214504
Validation loss: 2.9960790214706527

Epoch: 6| Step: 5
Training loss: 2.9596374395352103
Validation loss: 2.977427940654911

Epoch: 6| Step: 6
Training loss: 2.7347622842363717
Validation loss: 2.977011615311252

Epoch: 6| Step: 7
Training loss: 2.316578953498138
Validation loss: 2.9745518327601137

Epoch: 6| Step: 8
Training loss: 3.1271769760990105
Validation loss: 2.9764274368647086

Epoch: 6| Step: 9
Training loss: 3.394948145789219
Validation loss: 2.974868498650206

Epoch: 6| Step: 10
Training loss: 3.5522589467658365
Validation loss: 2.9756444970385396

Epoch: 6| Step: 11
Training loss: 3.515931925621289
Validation loss: 2.9751699782541765

Epoch: 6| Step: 12
Training loss: 3.210481857307952
Validation loss: 2.974405975268423

Epoch: 6| Step: 13
Training loss: 3.1594827544932005
Validation loss: 2.9746918537741163

Epoch: 54| Step: 0
Training loss: 3.238288465245656
Validation loss: 2.977125167257102

Epoch: 6| Step: 1
Training loss: 3.065091963068226
Validation loss: 2.975431287220179

Epoch: 6| Step: 2
Training loss: 3.467091894357353
Validation loss: 2.973037152653163

Epoch: 6| Step: 3
Training loss: 2.877118698296849
Validation loss: 2.974838043682582

Epoch: 6| Step: 4
Training loss: 3.3204431844686306
Validation loss: 2.972840894305815

Epoch: 6| Step: 5
Training loss: 2.676057809612981
Validation loss: 2.9758121887433187

Epoch: 6| Step: 6
Training loss: 3.228738342098703
Validation loss: 2.9762278670087836

Epoch: 6| Step: 7
Training loss: 3.7592707162093317
Validation loss: 2.979801272740283

Epoch: 6| Step: 8
Training loss: 3.510694785189373
Validation loss: 2.98860791628819

Epoch: 6| Step: 9
Training loss: 3.8658230310658985
Validation loss: 2.98001921198625

Epoch: 6| Step: 10
Training loss: 3.027907268621046
Validation loss: 2.9786400226589653

Epoch: 6| Step: 11
Training loss: 2.661643622132804
Validation loss: 2.9794432545171343

Epoch: 6| Step: 12
Training loss: 3.651500649473176
Validation loss: 2.978782347341783

Epoch: 6| Step: 13
Training loss: 2.978277078049941
Validation loss: 2.979076848539529

Epoch: 55| Step: 0
Training loss: 2.746419656658639
Validation loss: 2.978994682218895

Epoch: 6| Step: 1
Training loss: 2.9911690116532053
Validation loss: 2.9774380421860025

Epoch: 6| Step: 2
Training loss: 3.572626411652062
Validation loss: 2.9766287537489964

Epoch: 6| Step: 3
Training loss: 3.453352562496108
Validation loss: 2.9752370617706667

Epoch: 6| Step: 4
Training loss: 3.600415227043807
Validation loss: 2.9716963736180118

Epoch: 6| Step: 5
Training loss: 3.079571534116432
Validation loss: 2.973158549502035

Epoch: 6| Step: 6
Training loss: 3.4322334867340385
Validation loss: 2.9711772734507567

Epoch: 6| Step: 7
Training loss: 3.302574690754578
Validation loss: 2.9700759629440676

Epoch: 6| Step: 8
Training loss: 3.5733253237886005
Validation loss: 2.9696598215365415

Epoch: 6| Step: 9
Training loss: 3.059828858420396
Validation loss: 2.9723200749502063

Epoch: 6| Step: 10
Training loss: 2.7988193509163324
Validation loss: 2.981918663311358

Epoch: 6| Step: 11
Training loss: 2.9309691207128514
Validation loss: 2.9876335868980544

Epoch: 6| Step: 12
Training loss: 3.7870163259343186
Validation loss: 2.9671274601136304

Epoch: 6| Step: 13
Training loss: 3.0063201769213723
Validation loss: 2.967687005240902

Epoch: 56| Step: 0
Training loss: 3.838185818800162
Validation loss: 2.9694052611564747

Epoch: 6| Step: 1
Training loss: 3.354262324957442
Validation loss: 2.968542387718652

Epoch: 6| Step: 2
Training loss: 2.986930352332893
Validation loss: 2.9665879602650733

Epoch: 6| Step: 3
Training loss: 2.7228067758728334
Validation loss: 2.9652444760870447

Epoch: 6| Step: 4
Training loss: 3.0204977090236778
Validation loss: 2.965690610632203

Epoch: 6| Step: 5
Training loss: 2.9300200006629082
Validation loss: 2.96549745371839

Epoch: 6| Step: 6
Training loss: 3.193445681650977
Validation loss: 2.96657892793127

Epoch: 6| Step: 7
Training loss: 4.079956111297913
Validation loss: 2.9654288254460863

Epoch: 6| Step: 8
Training loss: 2.7397037571498344
Validation loss: 2.963924595519326

Epoch: 6| Step: 9
Training loss: 2.8868251259578104
Validation loss: 2.9644816483907466

Epoch: 6| Step: 10
Training loss: 3.4692370098629794
Validation loss: 2.964597945917788

Epoch: 6| Step: 11
Training loss: 3.3253857439046315
Validation loss: 2.962971858732766

Epoch: 6| Step: 12
Training loss: 3.344987586758194
Validation loss: 2.962814819491886

Epoch: 6| Step: 13
Training loss: 3.4223320364019054
Validation loss: 2.9625899129244844

Epoch: 57| Step: 0
Training loss: 3.2272341123901
Validation loss: 2.962653241984577

Epoch: 6| Step: 1
Training loss: 3.2888606863559624
Validation loss: 2.9615227455345097

Epoch: 6| Step: 2
Training loss: 3.2198469644514636
Validation loss: 2.9605727272327305

Epoch: 6| Step: 3
Training loss: 3.015226031382176
Validation loss: 2.9616466978870553

Epoch: 6| Step: 4
Training loss: 2.789083015943451
Validation loss: 2.9604278722425437

Epoch: 6| Step: 5
Training loss: 3.1957321078015886
Validation loss: 2.958212856235343

Epoch: 6| Step: 6
Training loss: 3.62619682812162
Validation loss: 2.959042053624361

Epoch: 6| Step: 7
Training loss: 2.719315393347394
Validation loss: 2.958859237612632

Epoch: 6| Step: 8
Training loss: 3.605113234097379
Validation loss: 2.9574784735453576

Epoch: 6| Step: 9
Training loss: 2.5965368167728595
Validation loss: 2.9569139196546788

Epoch: 6| Step: 10
Training loss: 3.598415630106821
Validation loss: 2.956668971961718

Epoch: 6| Step: 11
Training loss: 3.040307424962359
Validation loss: 2.954383144126855

Epoch: 6| Step: 12
Training loss: 3.6873029235935846
Validation loss: 2.956350604660893

Epoch: 6| Step: 13
Training loss: 3.805688495278575
Validation loss: 2.956149960397238

Epoch: 58| Step: 0
Training loss: 3.080718366400306
Validation loss: 2.9551473571394147

Epoch: 6| Step: 1
Training loss: 3.807317744982008
Validation loss: 2.9545263717899073

Epoch: 6| Step: 2
Training loss: 3.7294253183239983
Validation loss: 2.9528364657030126

Epoch: 6| Step: 3
Training loss: 3.3159330320233806
Validation loss: 2.9524302036652905

Epoch: 6| Step: 4
Training loss: 2.6699620587799946
Validation loss: 2.9532181590067665

Epoch: 6| Step: 5
Training loss: 2.824366057842472
Validation loss: 2.9521269289329637

Epoch: 6| Step: 6
Training loss: 3.370071344497679
Validation loss: 2.952858945814955

Epoch: 6| Step: 7
Training loss: 3.1531197917430194
Validation loss: 2.956563093813444

Epoch: 6| Step: 8
Training loss: 2.9727104673316247
Validation loss: 2.959255678441429

Epoch: 6| Step: 9
Training loss: 3.6448188169474247
Validation loss: 2.9603883439288197

Epoch: 6| Step: 10
Training loss: 2.9793219003492855
Validation loss: 2.9615421879580928

Epoch: 6| Step: 11
Training loss: 3.3118615164898935
Validation loss: 2.9679680295816686

Epoch: 6| Step: 12
Training loss: 3.3192171331986304
Validation loss: 2.965109981617919

Epoch: 6| Step: 13
Training loss: 2.8538458056749247
Validation loss: 2.964841380776277

Epoch: 59| Step: 0
Training loss: 3.23618196147005
Validation loss: 2.9579429721328343

Epoch: 6| Step: 1
Training loss: 3.831669003846953
Validation loss: 2.9485147228201596

Epoch: 6| Step: 2
Training loss: 3.2826148691292314
Validation loss: 2.9462073583423054

Epoch: 6| Step: 3
Training loss: 3.5251896259355626
Validation loss: 2.9447190556277545

Epoch: 6| Step: 4
Training loss: 3.4196091208808963
Validation loss: 2.946240317677824

Epoch: 6| Step: 5
Training loss: 3.5312267741561967
Validation loss: 2.947033017932722

Epoch: 6| Step: 6
Training loss: 2.879907814245916
Validation loss: 2.945383400443267

Epoch: 6| Step: 7
Training loss: 2.9469824794614796
Validation loss: 2.943405637343433

Epoch: 6| Step: 8
Training loss: 2.7880088033879225
Validation loss: 2.9438258505980333

Epoch: 6| Step: 9
Training loss: 2.8811816226019897
Validation loss: 2.9436404949459023

Epoch: 6| Step: 10
Training loss: 2.819942629751377
Validation loss: 2.943207919638683

Epoch: 6| Step: 11
Training loss: 3.850345814024143
Validation loss: 2.943567449227314

Epoch: 6| Step: 12
Training loss: 2.906241304117955
Validation loss: 2.9435425231106516

Epoch: 6| Step: 13
Training loss: 3.0760030645645413
Validation loss: 2.942325249922408

Epoch: 60| Step: 0
Training loss: 3.924633985814145
Validation loss: 2.9415336550462614

Epoch: 6| Step: 1
Training loss: 3.0079122155244606
Validation loss: 2.9427011977463238

Epoch: 6| Step: 2
Training loss: 2.981286652857512
Validation loss: 2.9401272457906424

Epoch: 6| Step: 3
Training loss: 3.3687850808774633
Validation loss: 2.941455834055281

Epoch: 6| Step: 4
Training loss: 3.215159367101322
Validation loss: 2.939732689482338

Epoch: 6| Step: 5
Training loss: 2.7249512379334404
Validation loss: 2.9390015840965376

Epoch: 6| Step: 6
Training loss: 3.164609357882974
Validation loss: 2.9400538599138177

Epoch: 6| Step: 7
Training loss: 2.476067622948349
Validation loss: 2.93843786784456

Epoch: 6| Step: 8
Training loss: 2.8144305914586316
Validation loss: 2.939932797378008

Epoch: 6| Step: 9
Training loss: 3.3732190554816697
Validation loss: 2.938915963055344

Epoch: 6| Step: 10
Training loss: 3.5144906481581666
Validation loss: 2.937857901702338

Epoch: 6| Step: 11
Training loss: 3.7128225578157106
Validation loss: 2.9389126831745003

Epoch: 6| Step: 12
Training loss: 3.073751993384225
Validation loss: 2.9368968022271162

Epoch: 6| Step: 13
Training loss: 3.791610773254472
Validation loss: 2.938300992928146

Epoch: 61| Step: 0
Training loss: 3.0591142584221243
Validation loss: 2.9388288626583705

Epoch: 6| Step: 1
Training loss: 3.4426120546452896
Validation loss: 2.9365780233761147

Epoch: 6| Step: 2
Training loss: 3.0301431424413074
Validation loss: 2.938919143489496

Epoch: 6| Step: 3
Training loss: 3.874972804804709
Validation loss: 2.9435283929918663

Epoch: 6| Step: 4
Training loss: 3.0897511541909357
Validation loss: 2.944334574850286

Epoch: 6| Step: 5
Training loss: 3.3345547027928584
Validation loss: 2.9462607885130447

Epoch: 6| Step: 6
Training loss: 2.430192508528804
Validation loss: 2.951609543705927

Epoch: 6| Step: 7
Training loss: 2.737873302769027
Validation loss: 2.93743140097561

Epoch: 6| Step: 8
Training loss: 3.478683270586459
Validation loss: 2.935708144614274

Epoch: 6| Step: 9
Training loss: 3.6265577718103197
Validation loss: 2.93859481918452

Epoch: 6| Step: 10
Training loss: 3.4849900870271133
Validation loss: 2.937757927142529

Epoch: 6| Step: 11
Training loss: 3.2985910586812834
Validation loss: 2.9392442222307418

Epoch: 6| Step: 12
Training loss: 2.9468711553651685
Validation loss: 2.938486783973885

Epoch: 6| Step: 13
Training loss: 2.936222041919781
Validation loss: 2.938003650462503

Epoch: 62| Step: 0
Training loss: 2.908261331215283
Validation loss: 2.9395861648063715

Epoch: 6| Step: 1
Training loss: 3.77581371101619
Validation loss: 2.938407569238635

Epoch: 6| Step: 2
Training loss: 2.8183852608933364
Validation loss: 2.9392149079508565

Epoch: 6| Step: 3
Training loss: 3.917557851708686
Validation loss: 2.938843546621617

Epoch: 6| Step: 4
Training loss: 2.8692016179591686
Validation loss: 2.938024431733294

Epoch: 6| Step: 5
Training loss: 3.703855804569735
Validation loss: 2.939695661330998

Epoch: 6| Step: 6
Training loss: 3.346960362646743
Validation loss: 2.9382899253612815

Epoch: 6| Step: 7
Training loss: 2.3915458351829693
Validation loss: 2.937910731533137

Epoch: 6| Step: 8
Training loss: 2.6875727444052053
Validation loss: 2.93791394621452

Epoch: 6| Step: 9
Training loss: 3.723831423573227
Validation loss: 2.9361078877397597

Epoch: 6| Step: 10
Training loss: 3.1651901684559545
Validation loss: 2.9362025837576606

Epoch: 6| Step: 11
Training loss: 3.6817507132910747
Validation loss: 2.933816454368872

Epoch: 6| Step: 12
Training loss: 2.860470087858839
Validation loss: 2.9350127837521507

Epoch: 6| Step: 13
Training loss: 2.7699817888232765
Validation loss: 2.9343054232765913

Epoch: 63| Step: 0
Training loss: 3.7033279298959814
Validation loss: 2.933110826150575

Epoch: 6| Step: 1
Training loss: 3.7455351634831398
Validation loss: 2.9346889615803056

Epoch: 6| Step: 2
Training loss: 2.4823698192934045
Validation loss: 2.9350628767318496

Epoch: 6| Step: 3
Training loss: 2.914525544959536
Validation loss: 2.934435370520091

Epoch: 6| Step: 4
Training loss: 3.3786505277148353
Validation loss: 2.9336882859852307

Epoch: 6| Step: 5
Training loss: 3.731231771197751
Validation loss: 2.9325249187797366

Epoch: 6| Step: 6
Training loss: 3.0604967065727062
Validation loss: 2.9316147745890384

Epoch: 6| Step: 7
Training loss: 3.227860381367441
Validation loss: 2.9310279838901643

Epoch: 6| Step: 8
Training loss: 2.3518872211107347
Validation loss: 2.9288630269795015

Epoch: 6| Step: 9
Training loss: 3.1991002546450495
Validation loss: 2.9296136215903394

Epoch: 6| Step: 10
Training loss: 3.212401267586554
Validation loss: 2.927311988447488

Epoch: 6| Step: 11
Training loss: 3.8053779993766255
Validation loss: 2.927775039428212

Epoch: 6| Step: 12
Training loss: 2.6764684977951716
Validation loss: 2.9269816649881726

Epoch: 6| Step: 13
Training loss: 3.198190153441218
Validation loss: 2.926067431014217

Epoch: 64| Step: 0
Training loss: 3.406792133830217
Validation loss: 2.927736861815872

Epoch: 6| Step: 1
Training loss: 3.801545210429369
Validation loss: 2.9259860182063684

Epoch: 6| Step: 2
Training loss: 3.5180025326544584
Validation loss: 2.925994539755124

Epoch: 6| Step: 3
Training loss: 2.992040406438758
Validation loss: 2.9271903385039244

Epoch: 6| Step: 4
Training loss: 3.0936673856551558
Validation loss: 2.9271392052037757

Epoch: 6| Step: 5
Training loss: 3.508965861248193
Validation loss: 2.928142352673351

Epoch: 6| Step: 6
Training loss: 3.647742652482523
Validation loss: 2.926374302620015

Epoch: 6| Step: 7
Training loss: 3.083766666238975
Validation loss: 2.9235369641139166

Epoch: 6| Step: 8
Training loss: 2.729655175981161
Validation loss: 2.919873906903953

Epoch: 6| Step: 9
Training loss: 2.0309727406177376
Validation loss: 2.923812617703887

Epoch: 6| Step: 10
Training loss: 2.8823405554048507
Validation loss: 2.9211131386865636

Epoch: 6| Step: 11
Training loss: 3.374511683423618
Validation loss: 2.9221545170117906

Epoch: 6| Step: 12
Training loss: 3.4000655560624797
Validation loss: 2.921023925032369

Epoch: 6| Step: 13
Training loss: 3.0554134355111184
Validation loss: 2.921337729975016

Epoch: 65| Step: 0
Training loss: 3.214115843749795
Validation loss: 2.9207866353264564

Epoch: 6| Step: 1
Training loss: 2.752737676630142
Validation loss: 2.917236526182484

Epoch: 6| Step: 2
Training loss: 3.1061206445297684
Validation loss: 2.9156752397047505

Epoch: 6| Step: 3
Training loss: 3.5449474323286703
Validation loss: 2.9205637265160003

Epoch: 6| Step: 4
Training loss: 2.9601866240565244
Validation loss: 2.921654817143116

Epoch: 6| Step: 5
Training loss: 3.4025693833944777
Validation loss: 2.9241570030539497

Epoch: 6| Step: 6
Training loss: 2.998040513022566
Validation loss: 2.922324913191714

Epoch: 6| Step: 7
Training loss: 3.5769734091171617
Validation loss: 2.9227877385571

Epoch: 6| Step: 8
Training loss: 2.72361618042385
Validation loss: 2.9190058830783228

Epoch: 6| Step: 9
Training loss: 2.8829271247219412
Validation loss: 2.9180626817086934

Epoch: 6| Step: 10
Training loss: 3.4219179194297533
Validation loss: 2.914979533459233

Epoch: 6| Step: 11
Training loss: 3.167995090586779
Validation loss: 2.9153232914578773

Epoch: 6| Step: 12
Training loss: 3.6469062025864973
Validation loss: 2.9135871905794772

Epoch: 6| Step: 13
Training loss: 3.4367804034184086
Validation loss: 2.9174555635978923

Epoch: 66| Step: 0
Training loss: 2.991641320959771
Validation loss: 2.92010321140989

Epoch: 6| Step: 1
Training loss: 3.4591611001755576
Validation loss: 2.9178350021803285

Epoch: 6| Step: 2
Training loss: 2.8259985922710693
Validation loss: 2.9136496542881614

Epoch: 6| Step: 3
Training loss: 3.235523996499081
Validation loss: 2.915401409025608

Epoch: 6| Step: 4
Training loss: 3.011630877092337
Validation loss: 2.9125769360530605

Epoch: 6| Step: 5
Training loss: 2.764944219043818
Validation loss: 2.9127810993261845

Epoch: 6| Step: 6
Training loss: 2.8080409836400184
Validation loss: 2.9119061594816387

Epoch: 6| Step: 7
Training loss: 2.6335378490977903
Validation loss: 2.9128433488503274

Epoch: 6| Step: 8
Training loss: 3.033224190505569
Validation loss: 2.9143636688016854

Epoch: 6| Step: 9
Training loss: 3.524605906215391
Validation loss: 2.9138202178877806

Epoch: 6| Step: 10
Training loss: 3.3529860667716536
Validation loss: 2.912456702221638

Epoch: 6| Step: 11
Training loss: 3.339767508724088
Validation loss: 2.912844629419125

Epoch: 6| Step: 12
Training loss: 4.248944095264448
Validation loss: 2.914925467463975

Epoch: 6| Step: 13
Training loss: 3.311648277330209
Validation loss: 2.9163522820449375

Epoch: 67| Step: 0
Training loss: 3.1775511517072874
Validation loss: 2.921156087561585

Epoch: 6| Step: 1
Training loss: 3.089226700890867
Validation loss: 2.9236944084748644

Epoch: 6| Step: 2
Training loss: 3.247916213829363
Validation loss: 2.9290482788592844

Epoch: 6| Step: 3
Training loss: 2.896533762432964
Validation loss: 2.9306420568437472

Epoch: 6| Step: 4
Training loss: 3.4509951552183225
Validation loss: 2.93247898921044

Epoch: 6| Step: 5
Training loss: 3.173383682823917
Validation loss: 2.9094171546129153

Epoch: 6| Step: 6
Training loss: 3.068325652016704
Validation loss: 2.9119085295160434

Epoch: 6| Step: 7
Training loss: 2.5710101354837662
Validation loss: 2.9120095746492463

Epoch: 6| Step: 8
Training loss: 3.7771165181781896
Validation loss: 2.9141289466083427

Epoch: 6| Step: 9
Training loss: 2.9340655763938868
Validation loss: 2.9200064331590103

Epoch: 6| Step: 10
Training loss: 3.9582546560934344
Validation loss: 2.912800652340042

Epoch: 6| Step: 11
Training loss: 3.43357708507048
Validation loss: 2.910410324339813

Epoch: 6| Step: 12
Training loss: 2.6956898300756236
Validation loss: 2.91197285425999

Epoch: 6| Step: 13
Training loss: 3.1096634467437405
Validation loss: 2.9137368193279216

Epoch: 68| Step: 0
Training loss: 2.913192169063277
Validation loss: 2.9094278843889483

Epoch: 6| Step: 1
Training loss: 3.0103365525581967
Validation loss: 2.9089064492262313

Epoch: 6| Step: 2
Training loss: 3.9461742706330827
Validation loss: 2.9091875973610373

Epoch: 6| Step: 3
Training loss: 2.830468318727541
Validation loss: 2.9083072324691615

Epoch: 6| Step: 4
Training loss: 2.8765311103198057
Validation loss: 2.9082754740125294

Epoch: 6| Step: 5
Training loss: 3.9448942963685965
Validation loss: 2.9076659208749

Epoch: 6| Step: 6
Training loss: 3.6844700148272524
Validation loss: 2.9081327611834906

Epoch: 6| Step: 7
Training loss: 3.4393835282744245
Validation loss: 2.9054793633817066

Epoch: 6| Step: 8
Training loss: 2.743728422110482
Validation loss: 2.9045728558456245

Epoch: 6| Step: 9
Training loss: 3.491301217145661
Validation loss: 2.9043962748355625

Epoch: 6| Step: 10
Training loss: 2.5744041642372872
Validation loss: 2.90375091231637

Epoch: 6| Step: 11
Training loss: 3.530502645351368
Validation loss: 2.9052312015487356

Epoch: 6| Step: 12
Training loss: 2.588693308594024
Validation loss: 2.903250886439621

Epoch: 6| Step: 13
Training loss: 2.5736603891076837
Validation loss: 2.9021209819889195

Epoch: 69| Step: 0
Training loss: 3.5603213424525935
Validation loss: 2.902115803681431

Epoch: 6| Step: 1
Training loss: 3.2176953411899984
Validation loss: 2.90276801397858

Epoch: 6| Step: 2
Training loss: 2.7879191814733004
Validation loss: 2.90329832034322

Epoch: 6| Step: 3
Training loss: 3.3878592888302026
Validation loss: 2.9056681883005453

Epoch: 6| Step: 4
Training loss: 2.6706063454313704
Validation loss: 2.915043767571197

Epoch: 6| Step: 5
Training loss: 3.110012276677374
Validation loss: 2.911389528698276

Epoch: 6| Step: 6
Training loss: 3.5210870655132633
Validation loss: 2.922124727737824

Epoch: 6| Step: 7
Training loss: 3.3504389233358522
Validation loss: 2.9175695056211954

Epoch: 6| Step: 8
Training loss: 3.0600683718254698
Validation loss: 2.9100894184453714

Epoch: 6| Step: 9
Training loss: 2.890822945080637
Validation loss: 2.9012220317821504

Epoch: 6| Step: 10
Training loss: 2.6272557874843234
Validation loss: 2.9028191341175495

Epoch: 6| Step: 11
Training loss: 3.7142817476272363
Validation loss: 2.898241322197507

Epoch: 6| Step: 12
Training loss: 3.663862210718807
Validation loss: 2.896452141722665

Epoch: 6| Step: 13
Training loss: 2.630920545380871
Validation loss: 2.896266904503102

Epoch: 70| Step: 0
Training loss: 3.129965537372052
Validation loss: 2.89475359248238

Epoch: 6| Step: 1
Training loss: 3.2537978063787127
Validation loss: 2.895698236722685

Epoch: 6| Step: 2
Training loss: 2.5964393002330945
Validation loss: 2.8954850650863526

Epoch: 6| Step: 3
Training loss: 3.3660553978425867
Validation loss: 2.8915928708845753

Epoch: 6| Step: 4
Training loss: 3.1491736221203017
Validation loss: 2.8928483575593225

Epoch: 6| Step: 5
Training loss: 3.2659414037714534
Validation loss: 2.8929615327639717

Epoch: 6| Step: 6
Training loss: 3.616378924500823
Validation loss: 2.8924338966944925

Epoch: 6| Step: 7
Training loss: 3.328448212738605
Validation loss: 2.8926513345321494

Epoch: 6| Step: 8
Training loss: 2.8644088044607505
Validation loss: 2.8912907032016997

Epoch: 6| Step: 9
Training loss: 3.600098682746446
Validation loss: 2.892821028811467

Epoch: 6| Step: 10
Training loss: 3.389004227667969
Validation loss: 2.8914740302491557

Epoch: 6| Step: 11
Training loss: 3.0726474105199575
Validation loss: 2.8913956253204955

Epoch: 6| Step: 12
Training loss: 2.658499449638925
Validation loss: 2.891444596066413

Epoch: 6| Step: 13
Training loss: 3.149212838775152
Validation loss: 2.8897355200815853

Epoch: 71| Step: 0
Training loss: 2.9291763877074275
Validation loss: 2.8921790932098776

Epoch: 6| Step: 1
Training loss: 3.3324934537097826
Validation loss: 2.8915401501160867

Epoch: 6| Step: 2
Training loss: 3.0282886630178605
Validation loss: 2.8905730531343425

Epoch: 6| Step: 3
Training loss: 3.130926082707156
Validation loss: 2.890921142804554

Epoch: 6| Step: 4
Training loss: 3.060005573442158
Validation loss: 2.8928657358784204

Epoch: 6| Step: 5
Training loss: 3.580678503429465
Validation loss: 2.892514796781489

Epoch: 6| Step: 6
Training loss: 3.4758700592020166
Validation loss: 2.8898164770796186

Epoch: 6| Step: 7
Training loss: 3.1588857994581816
Validation loss: 2.8898490185704238

Epoch: 6| Step: 8
Training loss: 3.019164543042308
Validation loss: 2.8898556417950028

Epoch: 6| Step: 9
Training loss: 3.2801064087889764
Validation loss: 2.891522923419122

Epoch: 6| Step: 10
Training loss: 3.0883282249423534
Validation loss: 2.8896832289731194

Epoch: 6| Step: 11
Training loss: 3.470282551147996
Validation loss: 2.8906784411863984

Epoch: 6| Step: 12
Training loss: 3.0590872920570287
Validation loss: 2.889844884591856

Epoch: 6| Step: 13
Training loss: 2.642851212763669
Validation loss: 2.8892790960515558

Epoch: 72| Step: 0
Training loss: 2.731650602872614
Validation loss: 2.8879549074870097

Epoch: 6| Step: 1
Training loss: 3.059123610863171
Validation loss: 2.8889272824389978

Epoch: 6| Step: 2
Training loss: 2.998894646778714
Validation loss: 2.889033291344281

Epoch: 6| Step: 3
Training loss: 3.5197491001529277
Validation loss: 2.8858787676285043

Epoch: 6| Step: 4
Training loss: 3.6785145568684072
Validation loss: 2.8869173181256436

Epoch: 6| Step: 5
Training loss: 2.7912808526499733
Validation loss: 2.8854564084869008

Epoch: 6| Step: 6
Training loss: 3.459748281241811
Validation loss: 2.886007303076782

Epoch: 6| Step: 7
Training loss: 3.9625221709103475
Validation loss: 2.8868358500112117

Epoch: 6| Step: 8
Training loss: 3.091752611663966
Validation loss: 2.886247348206747

Epoch: 6| Step: 9
Training loss: 3.039785735459801
Validation loss: 2.891209551620929

Epoch: 6| Step: 10
Training loss: 3.3196384598460953
Validation loss: 2.891202995340586

Epoch: 6| Step: 11
Training loss: 2.81044092038272
Validation loss: 2.8885000518447956

Epoch: 6| Step: 12
Training loss: 2.86188567786673
Validation loss: 2.8924061811339605

Epoch: 6| Step: 13
Training loss: 2.7069589404292187
Validation loss: 2.8875157638919977

Epoch: 73| Step: 0
Training loss: 3.0117474070965566
Validation loss: 2.8843592134321736

Epoch: 6| Step: 1
Training loss: 3.2127980134828666
Validation loss: 2.8835936644384406

Epoch: 6| Step: 2
Training loss: 2.970020544321437
Validation loss: 2.8816262171081655

Epoch: 6| Step: 3
Training loss: 3.233179433509309
Validation loss: 2.881692107440552

Epoch: 6| Step: 4
Training loss: 2.9084405334594554
Validation loss: 2.8833920871932737

Epoch: 6| Step: 5
Training loss: 3.3837498870387375
Validation loss: 2.882543586482745

Epoch: 6| Step: 6
Training loss: 2.8841265239712377
Validation loss: 2.8871050137227936

Epoch: 6| Step: 7
Training loss: 2.7791386852161657
Validation loss: 2.8924870057734617

Epoch: 6| Step: 8
Training loss: 3.221195514116014
Validation loss: 2.890525836124993

Epoch: 6| Step: 9
Training loss: 4.083736607366435
Validation loss: 2.884158843444901

Epoch: 6| Step: 10
Training loss: 3.492117315692246
Validation loss: 2.8788471243401923

Epoch: 6| Step: 11
Training loss: 3.487076469053323
Validation loss: 2.8796487499875276

Epoch: 6| Step: 12
Training loss: 2.7713613556757464
Validation loss: 2.8788017934890853

Epoch: 6| Step: 13
Training loss: 2.438188211168751
Validation loss: 2.879157028109689

Epoch: 74| Step: 0
Training loss: 3.167526345929998
Validation loss: 2.879503762788537

Epoch: 6| Step: 1
Training loss: 3.2984096336181503
Validation loss: 2.8797782676705728

Epoch: 6| Step: 2
Training loss: 3.0937965466629436
Validation loss: 2.8788426628842756

Epoch: 6| Step: 3
Training loss: 3.1989787737185984
Validation loss: 2.8808279101873144

Epoch: 6| Step: 4
Training loss: 3.4631493520715244
Validation loss: 2.8809739902250238

Epoch: 6| Step: 5
Training loss: 3.0362551551922707
Validation loss: 2.8807996219968457

Epoch: 6| Step: 6
Training loss: 3.6855933222348143
Validation loss: 2.878146081575356

Epoch: 6| Step: 7
Training loss: 3.342269284396664
Validation loss: 2.878081760614127

Epoch: 6| Step: 8
Training loss: 2.4515434074752482
Validation loss: 2.8770819834672534

Epoch: 6| Step: 9
Training loss: 2.7584749026046187
Validation loss: 2.8773622113296757

Epoch: 6| Step: 10
Training loss: 3.2453725589783717
Validation loss: 2.8772145579345194

Epoch: 6| Step: 11
Training loss: 3.470876368469173
Validation loss: 2.8760142256146057

Epoch: 6| Step: 12
Training loss: 2.8064390360960942
Validation loss: 2.874769157854581

Epoch: 6| Step: 13
Training loss: 3.3803257777300733
Validation loss: 2.8750172730899375

Epoch: 75| Step: 0
Training loss: 3.650878873597783
Validation loss: 2.874764485853643

Epoch: 6| Step: 1
Training loss: 3.0092820578034836
Validation loss: 2.872466366899942

Epoch: 6| Step: 2
Training loss: 2.705826924931964
Validation loss: 2.8726907420160672

Epoch: 6| Step: 3
Training loss: 2.729408331113478
Validation loss: 2.872241155780789

Epoch: 6| Step: 4
Training loss: 2.769589271529479
Validation loss: 2.8734942751567596

Epoch: 6| Step: 5
Training loss: 2.7161950569898266
Validation loss: 2.8770680401920523

Epoch: 6| Step: 6
Training loss: 3.804302846275412
Validation loss: 2.877342066449254

Epoch: 6| Step: 7
Training loss: 3.7251554827915143
Validation loss: 2.8722434130580394

Epoch: 6| Step: 8
Training loss: 2.9574435512285966
Validation loss: 2.8718132130496814

Epoch: 6| Step: 9
Training loss: 3.3626429077184365
Validation loss: 2.870822176919127

Epoch: 6| Step: 10
Training loss: 3.5299777549496616
Validation loss: 2.8680611454867835

Epoch: 6| Step: 11
Training loss: 3.6663178942715087
Validation loss: 2.8709143713094156

Epoch: 6| Step: 12
Training loss: 2.6687913913777783
Validation loss: 2.870336468634182

Epoch: 6| Step: 13
Training loss: 2.235890654706958
Validation loss: 2.8701092842953253

Epoch: 76| Step: 0
Training loss: 2.4808600169694395
Validation loss: 2.869112467299025

Epoch: 6| Step: 1
Training loss: 2.972791470674119
Validation loss: 2.869109701819567

Epoch: 6| Step: 2
Training loss: 3.6942903746281655
Validation loss: 2.8681701101227564

Epoch: 6| Step: 3
Training loss: 3.505834484808929
Validation loss: 2.8716982518397054

Epoch: 6| Step: 4
Training loss: 2.190268372417611
Validation loss: 2.869085047385374

Epoch: 6| Step: 5
Training loss: 3.1424813169714545
Validation loss: 2.8657632089716505

Epoch: 6| Step: 6
Training loss: 3.014296322973717
Validation loss: 2.868356609473723

Epoch: 6| Step: 7
Training loss: 3.5545728057131876
Validation loss: 2.8657662335287344

Epoch: 6| Step: 8
Training loss: 3.0877340374789495
Validation loss: 2.86547308623919

Epoch: 6| Step: 9
Training loss: 3.2036242584426513
Validation loss: 2.8659448314986435

Epoch: 6| Step: 10
Training loss: 3.5063601335442427
Validation loss: 2.863324851452398

Epoch: 6| Step: 11
Training loss: 3.7027567104901826
Validation loss: 2.8629368828160398

Epoch: 6| Step: 12
Training loss: 3.057433004323682
Validation loss: 2.862353043564035

Epoch: 6| Step: 13
Training loss: 2.51552595808405
Validation loss: 2.8646845419149427

Epoch: 77| Step: 0
Training loss: 2.895433210727404
Validation loss: 2.8634810208236057

Epoch: 6| Step: 1
Training loss: 2.638292264138756
Validation loss: 2.873087640661073

Epoch: 6| Step: 2
Training loss: 3.2594929484516237
Validation loss: 2.8864132490009324

Epoch: 6| Step: 3
Training loss: 3.5204944033638528
Validation loss: 2.8717506793929206

Epoch: 6| Step: 4
Training loss: 3.1772272963295376
Validation loss: 2.8651930555954768

Epoch: 6| Step: 5
Training loss: 2.8810662664057034
Validation loss: 2.862122408515676

Epoch: 6| Step: 6
Training loss: 3.3614952316284405
Validation loss: 2.8609583860672743

Epoch: 6| Step: 7
Training loss: 3.2562940246769
Validation loss: 2.859361418668215

Epoch: 6| Step: 8
Training loss: 2.9615983452015873
Validation loss: 2.859528292074886

Epoch: 6| Step: 9
Training loss: 3.8972722760339034
Validation loss: 2.856883473733715

Epoch: 6| Step: 10
Training loss: 3.389412236755651
Validation loss: 2.8569021503366043

Epoch: 6| Step: 11
Training loss: 2.129401081217712
Validation loss: 2.8577156777428705

Epoch: 6| Step: 12
Training loss: 2.9153819024731678
Validation loss: 2.8553176147906574

Epoch: 6| Step: 13
Training loss: 3.8635732696603773
Validation loss: 2.8550384809165226

Epoch: 78| Step: 0
Training loss: 2.7636277050357227
Validation loss: 2.8543273854183218

Epoch: 6| Step: 1
Training loss: 3.0361006162352884
Validation loss: 2.8546881532026496

Epoch: 6| Step: 2
Training loss: 3.604487292778104
Validation loss: 2.854686094880991

Epoch: 6| Step: 3
Training loss: 2.940989916999807
Validation loss: 2.858146454211247

Epoch: 6| Step: 4
Training loss: 3.5152020687446184
Validation loss: 2.8629345026868505

Epoch: 6| Step: 5
Training loss: 3.087178350211666
Validation loss: 2.8721447213476483

Epoch: 6| Step: 6
Training loss: 3.075794867770527
Validation loss: 2.874075987656004

Epoch: 6| Step: 7
Training loss: 3.298778400306115
Validation loss: 2.8711402356344964

Epoch: 6| Step: 8
Training loss: 3.643518435937655
Validation loss: 2.858316621133904

Epoch: 6| Step: 9
Training loss: 3.0639823906992576
Validation loss: 2.8497650995259067

Epoch: 6| Step: 10
Training loss: 3.5779561498523305
Validation loss: 2.848907875789568

Epoch: 6| Step: 11
Training loss: 3.2137269760606855
Validation loss: 2.8521103648852697

Epoch: 6| Step: 12
Training loss: 2.5556261863715073
Validation loss: 2.8498741340153315

Epoch: 6| Step: 13
Training loss: 2.252315389538649
Validation loss: 2.857807943306092

Epoch: 79| Step: 0
Training loss: 3.0388083069706244
Validation loss: 2.8562170008156014

Epoch: 6| Step: 1
Training loss: 3.023336877060243
Validation loss: 2.8552653030051545

Epoch: 6| Step: 2
Training loss: 3.544545353841857
Validation loss: 2.847097096435385

Epoch: 6| Step: 3
Training loss: 2.6107181587063777
Validation loss: 2.8501765833497177

Epoch: 6| Step: 4
Training loss: 3.6468803137680865
Validation loss: 2.8488354948985872

Epoch: 6| Step: 5
Training loss: 2.945659586644496
Validation loss: 2.8465436438102087

Epoch: 6| Step: 6
Training loss: 3.0652876642095874
Validation loss: 2.85927976255452

Epoch: 6| Step: 7
Training loss: 3.4440530910143625
Validation loss: 2.8546546505103656

Epoch: 6| Step: 8
Training loss: 3.105180681411145
Validation loss: 2.8530259604033863

Epoch: 6| Step: 9
Training loss: 2.75251299738089
Validation loss: 2.8522448020271907

Epoch: 6| Step: 10
Training loss: 3.4596600726073024
Validation loss: 2.853050948598803

Epoch: 6| Step: 11
Training loss: 3.011347133008906
Validation loss: 2.8462663966158352

Epoch: 6| Step: 12
Training loss: 3.1333439630639246
Validation loss: 2.845873744995187

Epoch: 6| Step: 13
Training loss: 3.1775425980276446
Validation loss: 2.8465494365616477

Epoch: 80| Step: 0
Training loss: 3.0864887759179016
Validation loss: 2.8471822741013955

Epoch: 6| Step: 1
Training loss: 3.6250816862176345
Validation loss: 2.846596594091152

Epoch: 6| Step: 2
Training loss: 2.979851455058434
Validation loss: 2.8467399234365387

Epoch: 6| Step: 3
Training loss: 2.41001795243664
Validation loss: 2.8449110284180557

Epoch: 6| Step: 4
Training loss: 3.089412538553895
Validation loss: 2.8455958018917995

Epoch: 6| Step: 5
Training loss: 3.245122330392028
Validation loss: 2.8446509160118083

Epoch: 6| Step: 6
Training loss: 3.1297779940521697
Validation loss: 2.8438007395735476

Epoch: 6| Step: 7
Training loss: 3.2701113606660592
Validation loss: 2.8464644606154765

Epoch: 6| Step: 8
Training loss: 3.3229282263352435
Validation loss: 2.844857931417249

Epoch: 6| Step: 9
Training loss: 3.5418766782240683
Validation loss: 2.843645427682869

Epoch: 6| Step: 10
Training loss: 2.6564311246266588
Validation loss: 2.844390449042946

Epoch: 6| Step: 11
Training loss: 3.0982574610648395
Validation loss: 2.843615685948535

Epoch: 6| Step: 12
Training loss: 3.4457370902985307
Validation loss: 2.841619708525742

Epoch: 6| Step: 13
Training loss: 2.7988266768521637
Validation loss: 2.8402918817360328

Epoch: 81| Step: 0
Training loss: 3.5159776298844188
Validation loss: 2.8435417512830874

Epoch: 6| Step: 1
Training loss: 3.112834596841747
Validation loss: 2.842383015471136

Epoch: 6| Step: 2
Training loss: 3.2232320745027834
Validation loss: 2.842756230919021

Epoch: 6| Step: 3
Training loss: 3.4873926070984496
Validation loss: 2.84498670628711

Epoch: 6| Step: 4
Training loss: 3.354048227308069
Validation loss: 2.8445054242787435

Epoch: 6| Step: 5
Training loss: 2.624913713762741
Validation loss: 2.8409091679488214

Epoch: 6| Step: 6
Training loss: 3.1541635396547996
Validation loss: 2.8409948045584814

Epoch: 6| Step: 7
Training loss: 2.9793380652431565
Validation loss: 2.8391286113126255

Epoch: 6| Step: 8
Training loss: 3.0087158431938117
Validation loss: 2.838561391785429

Epoch: 6| Step: 9
Training loss: 3.166600845723644
Validation loss: 2.8387925042353923

Epoch: 6| Step: 10
Training loss: 2.9932588496920487
Validation loss: 2.8367628668669798

Epoch: 6| Step: 11
Training loss: 2.5499771042338204
Validation loss: 2.838548343075211

Epoch: 6| Step: 12
Training loss: 3.283035083398544
Validation loss: 2.837434458620521

Epoch: 6| Step: 13
Training loss: 3.5732205690791785
Validation loss: 2.8356967680230896

Epoch: 82| Step: 0
Training loss: 2.9900876637751854
Validation loss: 2.8358369897202156

Epoch: 6| Step: 1
Training loss: 3.659943630430623
Validation loss: 2.838315530744185

Epoch: 6| Step: 2
Training loss: 3.324338666498959
Validation loss: 2.8352172012755066

Epoch: 6| Step: 3
Training loss: 3.442478528146261
Validation loss: 2.8344577296094

Epoch: 6| Step: 4
Training loss: 3.210477550076988
Validation loss: 2.8333729542731305

Epoch: 6| Step: 5
Training loss: 2.943430818071647
Validation loss: 2.8332230640273592

Epoch: 6| Step: 6
Training loss: 3.219173959013951
Validation loss: 2.83219970021105

Epoch: 6| Step: 7
Training loss: 2.9839953435702977
Validation loss: 2.8346891151333624

Epoch: 6| Step: 8
Training loss: 3.177471316468487
Validation loss: 2.835869303570679

Epoch: 6| Step: 9
Training loss: 3.2644109340021386
Validation loss: 2.8342404900879683

Epoch: 6| Step: 10
Training loss: 2.5363677293912863
Validation loss: 2.8329680609696894

Epoch: 6| Step: 11
Training loss: 2.804718442443347
Validation loss: 2.830531537989469

Epoch: 6| Step: 12
Training loss: 3.3303839668938116
Validation loss: 2.8305179405330234

Epoch: 6| Step: 13
Training loss: 2.7298171940057103
Validation loss: 2.8302484994353296

Epoch: 83| Step: 0
Training loss: 2.998344282378017
Validation loss: 2.830435523858484

Epoch: 6| Step: 1
Training loss: 3.3288950141264118
Validation loss: 2.8320414347283376

Epoch: 6| Step: 2
Training loss: 3.2854799163348494
Validation loss: 2.8313511991425866

Epoch: 6| Step: 3
Training loss: 2.8073125683932907
Validation loss: 2.8328633404182564

Epoch: 6| Step: 4
Training loss: 3.495685370265142
Validation loss: 2.832355986390422

Epoch: 6| Step: 5
Training loss: 2.3627021016864305
Validation loss: 2.8335526295244513

Epoch: 6| Step: 6
Training loss: 3.111318929482645
Validation loss: 2.8330620817409597

Epoch: 6| Step: 7
Training loss: 3.1879695471693577
Validation loss: 2.8331108563884695

Epoch: 6| Step: 8
Training loss: 3.3640576750157716
Validation loss: 2.8337853383016607

Epoch: 6| Step: 9
Training loss: 2.808436021898865
Validation loss: 2.832320937862848

Epoch: 6| Step: 10
Training loss: 3.6603164882047072
Validation loss: 2.83198227299372

Epoch: 6| Step: 11
Training loss: 3.5648354354049157
Validation loss: 2.8282473994357393

Epoch: 6| Step: 12
Training loss: 2.7534062357742344
Validation loss: 2.8301395431194294

Epoch: 6| Step: 13
Training loss: 2.8377706524666464
Validation loss: 2.8236477627168854

Epoch: 84| Step: 0
Training loss: 3.6133196524563997
Validation loss: 2.825531536316603

Epoch: 6| Step: 1
Training loss: 3.481762920514257
Validation loss: 2.8270307178002034

Epoch: 6| Step: 2
Training loss: 3.529127715405129
Validation loss: 2.8301236157704603

Epoch: 6| Step: 3
Training loss: 2.3522880170054665
Validation loss: 2.8303622176918743

Epoch: 6| Step: 4
Training loss: 2.9540050345799567
Validation loss: 2.837758084344741

Epoch: 6| Step: 5
Training loss: 3.86932400341561
Validation loss: 2.8385638040923276

Epoch: 6| Step: 6
Training loss: 2.664746328165073
Validation loss: 2.846215408263932

Epoch: 6| Step: 7
Training loss: 3.066236901922044
Validation loss: 2.840394705598602

Epoch: 6| Step: 8
Training loss: 3.7122361009095965
Validation loss: 2.8269804453328136

Epoch: 6| Step: 9
Training loss: 3.0102031768459674
Validation loss: 2.8230409431747376

Epoch: 6| Step: 10
Training loss: 2.410625096846033
Validation loss: 2.8241175539512287

Epoch: 6| Step: 11
Training loss: 3.1482712013114176
Validation loss: 2.824035098458067

Epoch: 6| Step: 12
Training loss: 3.215712363907141
Validation loss: 2.8246440060941356

Epoch: 6| Step: 13
Training loss: 1.647308541549151
Validation loss: 2.8263444568387124

Epoch: 85| Step: 0
Training loss: 3.2926882514634883
Validation loss: 2.8262644401374755

Epoch: 6| Step: 1
Training loss: 2.714923577541524
Validation loss: 2.826607535856871

Epoch: 6| Step: 2
Training loss: 3.166967645362431
Validation loss: 2.82649753490707

Epoch: 6| Step: 3
Training loss: 2.9385088547681426
Validation loss: 2.826543934965633

Epoch: 6| Step: 4
Training loss: 2.9417408300746217
Validation loss: 2.826347634239145

Epoch: 6| Step: 5
Training loss: 2.6734857890384744
Validation loss: 2.82588882526168

Epoch: 6| Step: 6
Training loss: 3.882203574375706
Validation loss: 2.8217013246016416

Epoch: 6| Step: 7
Training loss: 3.0469232017421204
Validation loss: 2.8218865198271286

Epoch: 6| Step: 8
Training loss: 2.6270014988866275
Validation loss: 2.8221566702491683

Epoch: 6| Step: 9
Training loss: 3.414525888800389
Validation loss: 2.8222746050587078

Epoch: 6| Step: 10
Training loss: 2.9056461486243683
Validation loss: 2.8222797627206173

Epoch: 6| Step: 11
Training loss: 3.634716691595319
Validation loss: 2.8221296289368065

Epoch: 6| Step: 12
Training loss: 3.0156463464169194
Validation loss: 2.821870386910294

Epoch: 6| Step: 13
Training loss: 3.490458835072188
Validation loss: 2.823984700038005

Epoch: 86| Step: 0
Training loss: 2.9632610775949626
Validation loss: 2.8207795358038847

Epoch: 6| Step: 1
Training loss: 3.0509283247699055
Validation loss: 2.821108519857385

Epoch: 6| Step: 2
Training loss: 3.4071970331820856
Validation loss: 2.8207632211484683

Epoch: 6| Step: 3
Training loss: 2.7025436922929558
Validation loss: 2.8235333391243342

Epoch: 6| Step: 4
Training loss: 3.395120479597725
Validation loss: 2.8216549630225805

Epoch: 6| Step: 5
Training loss: 2.733679808390113
Validation loss: 2.818945737968894

Epoch: 6| Step: 6
Training loss: 3.67392391098217
Validation loss: 2.8197520654818535

Epoch: 6| Step: 7
Training loss: 2.9326952334145266
Validation loss: 2.819060578300554

Epoch: 6| Step: 8
Training loss: 2.5212505300102377
Validation loss: 2.8188610330703945

Epoch: 6| Step: 9
Training loss: 3.1589543304958054
Validation loss: 2.8174451388497963

Epoch: 6| Step: 10
Training loss: 2.694851335519371
Validation loss: 2.8181160807374086

Epoch: 6| Step: 11
Training loss: 3.584039721984086
Validation loss: 2.817635749050478

Epoch: 6| Step: 12
Training loss: 2.7775234158934072
Validation loss: 2.81951274661459

Epoch: 6| Step: 13
Training loss: 4.346124014028189
Validation loss: 2.816453755673719

Epoch: 87| Step: 0
Training loss: 2.4399924617400743
Validation loss: 2.8172999151171925

Epoch: 6| Step: 1
Training loss: 3.3201344161801503
Validation loss: 2.8167416944545476

Epoch: 6| Step: 2
Training loss: 3.696820264009611
Validation loss: 2.8154854483209144

Epoch: 6| Step: 3
Training loss: 2.6369813237315474
Validation loss: 2.814800574871973

Epoch: 6| Step: 4
Training loss: 3.5606704832750684
Validation loss: 2.8167279257620197

Epoch: 6| Step: 5
Training loss: 3.622792064826617
Validation loss: 2.816101983509971

Epoch: 6| Step: 6
Training loss: 2.7504388285680568
Validation loss: 2.815351867448253

Epoch: 6| Step: 7
Training loss: 2.770961806299433
Validation loss: 2.814711304170609

Epoch: 6| Step: 8
Training loss: 2.939515903347474
Validation loss: 2.8153817547839304

Epoch: 6| Step: 9
Training loss: 3.0464367673626613
Validation loss: 2.8163770034375415

Epoch: 6| Step: 10
Training loss: 3.6776887361082187
Validation loss: 2.816106455149449

Epoch: 6| Step: 11
Training loss: 3.151791889426999
Validation loss: 2.8190252248791965

Epoch: 6| Step: 12
Training loss: 2.566616009133872
Validation loss: 2.818096507560901

Epoch: 6| Step: 13
Training loss: 3.2235609229715028
Validation loss: 2.815314052985035

Epoch: 88| Step: 0
Training loss: 2.6926427030158933
Validation loss: 2.8171628248414367

Epoch: 6| Step: 1
Training loss: 2.713838196195004
Validation loss: 2.818615812958397

Epoch: 6| Step: 2
Training loss: 1.8998796299400413
Validation loss: 2.8133718609058658

Epoch: 6| Step: 3
Training loss: 3.2568217355856017
Validation loss: 2.821012127758445

Epoch: 6| Step: 4
Training loss: 3.2210393375054154
Validation loss: 2.8294976515118475

Epoch: 6| Step: 5
Training loss: 3.256498149415036
Validation loss: 2.842809419478956

Epoch: 6| Step: 6
Training loss: 3.01360573637325
Validation loss: 2.8242071754543923

Epoch: 6| Step: 7
Training loss: 3.0615497594063843
Validation loss: 2.8137999835625793

Epoch: 6| Step: 8
Training loss: 3.913173795455855
Validation loss: 2.8118943504587763

Epoch: 6| Step: 9
Training loss: 3.312634303411291
Validation loss: 2.808798555840645

Epoch: 6| Step: 10
Training loss: 2.9174137430261835
Validation loss: 2.8087686084949595

Epoch: 6| Step: 11
Training loss: 3.359667672116608
Validation loss: 2.811522044218404

Epoch: 6| Step: 12
Training loss: 3.322176780163088
Validation loss: 2.8108831555054135

Epoch: 6| Step: 13
Training loss: 3.432100251127444
Validation loss: 2.813332838853424

Epoch: 89| Step: 0
Training loss: 3.688175979983354
Validation loss: 2.812610050723622

Epoch: 6| Step: 1
Training loss: 3.594229359376663
Validation loss: 2.811647197907079

Epoch: 6| Step: 2
Training loss: 3.2867142002880323
Validation loss: 2.8102911667128967

Epoch: 6| Step: 3
Training loss: 3.348131108295337
Validation loss: 2.809940167667618

Epoch: 6| Step: 4
Training loss: 3.2164639252594016
Validation loss: 2.807949138861568

Epoch: 6| Step: 5
Training loss: 2.895365853391898
Validation loss: 2.8074511053283966

Epoch: 6| Step: 6
Training loss: 3.601846348630189
Validation loss: 2.8060572162261614

Epoch: 6| Step: 7
Training loss: 3.6196045019854663
Validation loss: 2.8039991480295154

Epoch: 6| Step: 8
Training loss: 2.560478995185068
Validation loss: 2.804145767296643

Epoch: 6| Step: 9
Training loss: 2.6775757056039935
Validation loss: 2.806609807879405

Epoch: 6| Step: 10
Training loss: 3.3821316005158653
Validation loss: 2.8105990266985676

Epoch: 6| Step: 11
Training loss: 2.4224341946729435
Validation loss: 2.812329444590464

Epoch: 6| Step: 12
Training loss: 2.4334922512190507
Validation loss: 2.8038287210386685

Epoch: 6| Step: 13
Training loss: 1.7140961496810971
Validation loss: 2.8024311608400545

Epoch: 90| Step: 0
Training loss: 3.147648639153742
Validation loss: 2.8009011410904106

Epoch: 6| Step: 1
Training loss: 3.20893325811387
Validation loss: 2.804374082033534

Epoch: 6| Step: 2
Training loss: 3.5198985256393884
Validation loss: 2.80309904108006

Epoch: 6| Step: 3
Training loss: 2.9745090239761955
Validation loss: 2.8028341186332595

Epoch: 6| Step: 4
Training loss: 3.7518809369682224
Validation loss: 2.8046953718367624

Epoch: 6| Step: 5
Training loss: 3.1676562586707075
Validation loss: 2.8042265888384343

Epoch: 6| Step: 6
Training loss: 2.789214143450607
Validation loss: 2.8070742867898932

Epoch: 6| Step: 7
Training loss: 2.2585807997847884
Validation loss: 2.8072007675350426

Epoch: 6| Step: 8
Training loss: 2.5837989100462426
Validation loss: 2.8087823979497153

Epoch: 6| Step: 9
Training loss: 3.4562421857252303
Validation loss: 2.8041136812162577

Epoch: 6| Step: 10
Training loss: 2.9431545943195805
Validation loss: 2.8020850801918

Epoch: 6| Step: 11
Training loss: 3.9885508476995826
Validation loss: 2.799295803665147

Epoch: 6| Step: 12
Training loss: 2.6071565071539933
Validation loss: 2.8002713562328356

Epoch: 6| Step: 13
Training loss: 2.494212891107532
Validation loss: 2.80133718948248

Epoch: 91| Step: 0
Training loss: 3.0094297346641703
Validation loss: 2.8050517778185866

Epoch: 6| Step: 1
Training loss: 2.8964667599451723
Validation loss: 2.80368210713673

Epoch: 6| Step: 2
Training loss: 3.256381299086313
Validation loss: 2.80102877007201

Epoch: 6| Step: 3
Training loss: 3.394290893614039
Validation loss: 2.806174789828817

Epoch: 6| Step: 4
Training loss: 2.810243846046667
Validation loss: 2.802401751963668

Epoch: 6| Step: 5
Training loss: 3.7715757843903788
Validation loss: 2.799823439945348

Epoch: 6| Step: 6
Training loss: 2.7053841207796716
Validation loss: 2.7995134169631344

Epoch: 6| Step: 7
Training loss: 3.338494279180964
Validation loss: 2.8034784893987745

Epoch: 6| Step: 8
Training loss: 2.9866873685369097
Validation loss: 2.8005115632453266

Epoch: 6| Step: 9
Training loss: 2.340974512221378
Validation loss: 2.8059936712224913

Epoch: 6| Step: 10
Training loss: 2.808408685988238
Validation loss: 2.808665608947495

Epoch: 6| Step: 11
Training loss: 3.3903995562021594
Validation loss: 2.805374344306868

Epoch: 6| Step: 12
Training loss: 3.1077809297196137
Validation loss: 2.804030516804455

Epoch: 6| Step: 13
Training loss: 3.6474364906727588
Validation loss: 2.8028322115662276

Epoch: 92| Step: 0
Training loss: 3.0425413955467757
Validation loss: 2.8003397622649175

Epoch: 6| Step: 1
Training loss: 2.905235195389066
Validation loss: 2.799491096503596

Epoch: 6| Step: 2
Training loss: 2.7292898795776783
Validation loss: 2.7976728162932414

Epoch: 6| Step: 3
Training loss: 3.063799212716905
Validation loss: 2.797643316160979

Epoch: 6| Step: 4
Training loss: 3.573298368093125
Validation loss: 2.800695694577639

Epoch: 6| Step: 5
Training loss: 3.8401278665234573
Validation loss: 2.799268070779548

Epoch: 6| Step: 6
Training loss: 3.4760804945884667
Validation loss: 2.7978776747823253

Epoch: 6| Step: 7
Training loss: 3.146642130443581
Validation loss: 2.79509517107517

Epoch: 6| Step: 8
Training loss: 2.8766981997332692
Validation loss: 2.797586661802565

Epoch: 6| Step: 9
Training loss: 2.628015511825512
Validation loss: 2.7971391322264525

Epoch: 6| Step: 10
Training loss: 2.8862198539206982
Validation loss: 2.795867682611935

Epoch: 6| Step: 11
Training loss: 2.4953751701267404
Validation loss: 2.7954009940547193

Epoch: 6| Step: 12
Training loss: 3.417953403983407
Validation loss: 2.7975737921916286

Epoch: 6| Step: 13
Training loss: 3.10672789184533
Validation loss: 2.7988947792921954

Epoch: 93| Step: 0
Training loss: 2.238362202670023
Validation loss: 2.8008773196159815

Epoch: 6| Step: 1
Training loss: 3.4479895331451793
Validation loss: 2.805214864223192

Epoch: 6| Step: 2
Training loss: 3.2761519291712795
Validation loss: 2.805498269058492

Epoch: 6| Step: 3
Training loss: 2.9732458504891874
Validation loss: 2.8067334415141785

Epoch: 6| Step: 4
Training loss: 3.4785189149338738
Validation loss: 2.8022305261265332

Epoch: 6| Step: 5
Training loss: 3.446274257681079
Validation loss: 2.80090009399689

Epoch: 6| Step: 6
Training loss: 3.183186922817399
Validation loss: 2.8028753036472653

Epoch: 6| Step: 7
Training loss: 3.005376765898892
Validation loss: 2.8025521851625688

Epoch: 6| Step: 8
Training loss: 2.3931032188462424
Validation loss: 2.802715750880328

Epoch: 6| Step: 9
Training loss: 2.7782550931492707
Validation loss: 2.802594386935242

Epoch: 6| Step: 10
Training loss: 4.011631267303201
Validation loss: 2.803387843086583

Epoch: 6| Step: 11
Training loss: 3.131130765978519
Validation loss: 2.799189190547374

Epoch: 6| Step: 12
Training loss: 2.907883215961132
Validation loss: 2.800409815355487

Epoch: 6| Step: 13
Training loss: 3.0055446249276754
Validation loss: 2.7979179037865918

Epoch: 94| Step: 0
Training loss: 3.627700063182331
Validation loss: 2.7985871986753104

Epoch: 6| Step: 1
Training loss: 3.258397623844156
Validation loss: 2.79576166225927

Epoch: 6| Step: 2
Training loss: 2.898860766822436
Validation loss: 2.794530456321401

Epoch: 6| Step: 3
Training loss: 3.57766840657669
Validation loss: 2.793448990542911

Epoch: 6| Step: 4
Training loss: 2.947232781512246
Validation loss: 2.793586544336931

Epoch: 6| Step: 5
Training loss: 2.994717875138218
Validation loss: 2.7930929745935384

Epoch: 6| Step: 6
Training loss: 3.423158169889189
Validation loss: 2.7925048351052277

Epoch: 6| Step: 7
Training loss: 3.083727390436819
Validation loss: 2.7916163215144287

Epoch: 6| Step: 8
Training loss: 2.8697066297353584
Validation loss: 2.7909020708547936

Epoch: 6| Step: 9
Training loss: 3.095536149873844
Validation loss: 2.791135990674947

Epoch: 6| Step: 10
Training loss: 3.2432577182257742
Validation loss: 2.7872633192837477

Epoch: 6| Step: 11
Training loss: 2.828539233141448
Validation loss: 2.7869594181313384

Epoch: 6| Step: 12
Training loss: 2.4515725830337582
Validation loss: 2.7886472016945913

Epoch: 6| Step: 13
Training loss: 3.071103370280738
Validation loss: 2.7886425343367445

Epoch: 95| Step: 0
Training loss: 3.246574357095852
Validation loss: 2.7866704885139915

Epoch: 6| Step: 1
Training loss: 3.5615582476191627
Validation loss: 2.7878306500615118

Epoch: 6| Step: 2
Training loss: 2.259036989372739
Validation loss: 2.7913147917773746

Epoch: 6| Step: 3
Training loss: 2.9528969974400114
Validation loss: 2.794276166847594

Epoch: 6| Step: 4
Training loss: 3.3240012827295797
Validation loss: 2.801811065663557

Epoch: 6| Step: 5
Training loss: 3.4309040944441214
Validation loss: 2.788912429373031

Epoch: 6| Step: 6
Training loss: 3.3767900311704038
Validation loss: 2.785862098795078

Epoch: 6| Step: 7
Training loss: 2.72625538317793
Validation loss: 2.7863582752208673

Epoch: 6| Step: 8
Training loss: 3.1485294300222617
Validation loss: 2.7842730916393617

Epoch: 6| Step: 9
Training loss: 2.832513933812453
Validation loss: 2.785227911010181

Epoch: 6| Step: 10
Training loss: 2.288079685490818
Validation loss: 2.785653428277595

Epoch: 6| Step: 11
Training loss: 3.1024130320444
Validation loss: 2.7852344203681105

Epoch: 6| Step: 12
Training loss: 3.447297439212261
Validation loss: 2.7860346131072955

Epoch: 6| Step: 13
Training loss: 3.5543047688446108
Validation loss: 2.7869392416275547

Epoch: 96| Step: 0
Training loss: 3.40892679570837
Validation loss: 2.783588695865464

Epoch: 6| Step: 1
Training loss: 3.697503438436007
Validation loss: 2.7836744897282935

Epoch: 6| Step: 2
Training loss: 2.865216234977938
Validation loss: 2.784597710671273

Epoch: 6| Step: 3
Training loss: 2.74659327254644
Validation loss: 2.784244327943829

Epoch: 6| Step: 4
Training loss: 2.4773984635349326
Validation loss: 2.7853432492039834

Epoch: 6| Step: 5
Training loss: 3.2799664121164134
Validation loss: 2.786063675776916

Epoch: 6| Step: 6
Training loss: 3.135181777283628
Validation loss: 2.785791803193697

Epoch: 6| Step: 7
Training loss: 2.974170755169952
Validation loss: 2.7847905857470967

Epoch: 6| Step: 8
Training loss: 3.6082549235669066
Validation loss: 2.7832318874816617

Epoch: 6| Step: 9
Training loss: 3.414037080229309
Validation loss: 2.7791326246559533

Epoch: 6| Step: 10
Training loss: 2.656257898655536
Validation loss: 2.7796064283467703

Epoch: 6| Step: 11
Training loss: 3.35852309669775
Validation loss: 2.7796523457677305

Epoch: 6| Step: 12
Training loss: 2.7090509979922675
Validation loss: 2.7784814036408587

Epoch: 6| Step: 13
Training loss: 2.565692494627863
Validation loss: 2.7805769058511567

Epoch: 97| Step: 0
Training loss: 2.962383148850476
Validation loss: 2.7835630408170946

Epoch: 6| Step: 1
Training loss: 3.309489771768222
Validation loss: 2.7877649092438928

Epoch: 6| Step: 2
Training loss: 3.298351517663001
Validation loss: 2.798723460727027

Epoch: 6| Step: 3
Training loss: 3.175780198963925
Validation loss: 2.798898131657985

Epoch: 6| Step: 4
Training loss: 3.140792007181158
Validation loss: 2.8074233858866062

Epoch: 6| Step: 5
Training loss: 2.9689024233588865
Validation loss: 2.824394521858801

Epoch: 6| Step: 6
Training loss: 3.505635764978903
Validation loss: 2.820125155134556

Epoch: 6| Step: 7
Training loss: 2.945006498838032
Validation loss: 2.8066599547196036

Epoch: 6| Step: 8
Training loss: 3.1502133796718246
Validation loss: 2.792010597589221

Epoch: 6| Step: 9
Training loss: 2.473560619844431
Validation loss: 2.781365978758136

Epoch: 6| Step: 10
Training loss: 3.095814334063206
Validation loss: 2.7747915010577633

Epoch: 6| Step: 11
Training loss: 1.8380111995310149
Validation loss: 2.774204935638092

Epoch: 6| Step: 12
Training loss: 3.9028166063458007
Validation loss: 2.7728655740607846

Epoch: 6| Step: 13
Training loss: 3.160529530738932
Validation loss: 2.772429204132131

Epoch: 98| Step: 0
Training loss: 2.614856649959077
Validation loss: 2.7718619544454786

Epoch: 6| Step: 1
Training loss: 3.185240599259481
Validation loss: 2.7727846363095745

Epoch: 6| Step: 2
Training loss: 3.0740310631040653
Validation loss: 2.774231123562471

Epoch: 6| Step: 3
Training loss: 3.3245463585262627
Validation loss: 2.7744564270843157

Epoch: 6| Step: 4
Training loss: 2.660369013093416
Validation loss: 2.784977605821755

Epoch: 6| Step: 5
Training loss: 3.5542222609351475
Validation loss: 2.775601424821215

Epoch: 6| Step: 6
Training loss: 3.0963794053794675
Validation loss: 2.770203253137478

Epoch: 6| Step: 7
Training loss: 3.363418771233888
Validation loss: 2.7705223697910273

Epoch: 6| Step: 8
Training loss: 2.8625180839400453
Validation loss: 2.7697221142426263

Epoch: 6| Step: 9
Training loss: 2.4543069312572507
Validation loss: 2.772061716776962

Epoch: 6| Step: 10
Training loss: 3.3306322280023664
Validation loss: 2.7793991771874964

Epoch: 6| Step: 11
Training loss: 3.2766517026707667
Validation loss: 2.7940201980612764

Epoch: 6| Step: 12
Training loss: 3.223251898077765
Validation loss: 2.814635043628135

Epoch: 6| Step: 13
Training loss: 3.2093439533399724
Validation loss: 2.834242351147005

Epoch: 99| Step: 0
Training loss: 3.244443104219668
Validation loss: 2.8312351817425747

Epoch: 6| Step: 1
Training loss: 2.791625824434991
Validation loss: 2.822707948406834

Epoch: 6| Step: 2
Training loss: 2.7734645788455787
Validation loss: 2.8143668483780506

Epoch: 6| Step: 3
Training loss: 2.8776080699681295
Validation loss: 2.7825066627651385

Epoch: 6| Step: 4
Training loss: 3.577968943828396
Validation loss: 2.775399911908875

Epoch: 6| Step: 5
Training loss: 3.0161094474057917
Validation loss: 2.7659575494900785

Epoch: 6| Step: 6
Training loss: 3.415985613299054
Validation loss: 2.7664827453818672

Epoch: 6| Step: 7
Training loss: 3.5438922994794946
Validation loss: 2.7669387773511582

Epoch: 6| Step: 8
Training loss: 3.275934910007666
Validation loss: 2.7673004972420614

Epoch: 6| Step: 9
Training loss: 2.8326221770344078
Validation loss: 2.7653507546038982

Epoch: 6| Step: 10
Training loss: 2.6534067532271206
Validation loss: 2.7675558656347974

Epoch: 6| Step: 11
Training loss: 3.0528352785427253
Validation loss: 2.772510039450431

Epoch: 6| Step: 12
Training loss: 2.6993885124912325
Validation loss: 2.771310377694391

Epoch: 6| Step: 13
Training loss: 3.401505552068371
Validation loss: 2.773423654977251

Epoch: 100| Step: 0
Training loss: 3.057780463392473
Validation loss: 2.773607040924193

Epoch: 6| Step: 1
Training loss: 3.2013699817627823
Validation loss: 2.7759423173017637

Epoch: 6| Step: 2
Training loss: 2.778969933801885
Validation loss: 2.776279827034763

Epoch: 6| Step: 3
Training loss: 2.9409814859720007
Validation loss: 2.7708263583715786

Epoch: 6| Step: 4
Training loss: 3.3284285859097933
Validation loss: 2.7737594045626848

Epoch: 6| Step: 5
Training loss: 3.251291018604562
Validation loss: 2.7727764797183068

Epoch: 6| Step: 6
Training loss: 2.8516260427423656
Validation loss: 2.7686495067596355

Epoch: 6| Step: 7
Training loss: 2.737600984844519
Validation loss: 2.7687003402128716

Epoch: 6| Step: 8
Training loss: 3.2538430893573667
Validation loss: 2.763146930685884

Epoch: 6| Step: 9
Training loss: 3.0945917390854984
Validation loss: 2.7637172928162546

Epoch: 6| Step: 10
Training loss: 3.4194816685115628
Validation loss: 2.7669224018827014

Epoch: 6| Step: 11
Training loss: 2.86226087345987
Validation loss: 2.761614347471214

Epoch: 6| Step: 12
Training loss: 3.122598870012434
Validation loss: 2.7612013466397842

Epoch: 6| Step: 13
Training loss: 3.2418146493536857
Validation loss: 2.761445746881663

Epoch: 101| Step: 0
Training loss: 3.258218643888755
Validation loss: 2.7588115896019794

Epoch: 6| Step: 1
Training loss: 2.6934315185622086
Validation loss: 2.7583949153152405

Epoch: 6| Step: 2
Training loss: 3.3203145105692444
Validation loss: 2.7593394909180553

Epoch: 6| Step: 3
Training loss: 3.039914048636195
Validation loss: 2.759151057317823

Epoch: 6| Step: 4
Training loss: 2.6492423575948845
Validation loss: 2.7610308898124734

Epoch: 6| Step: 5
Training loss: 3.359494229352207
Validation loss: 2.7577257695550927

Epoch: 6| Step: 6
Training loss: 2.681498457772151
Validation loss: 2.7588730768189795

Epoch: 6| Step: 7
Training loss: 3.743455898852074
Validation loss: 2.7599993256569126

Epoch: 6| Step: 8
Training loss: 3.091469126214493
Validation loss: 2.760796690538658

Epoch: 6| Step: 9
Training loss: 3.2334097928579677
Validation loss: 2.757547490314335

Epoch: 6| Step: 10
Training loss: 2.8837298662651043
Validation loss: 2.7592633538128104

Epoch: 6| Step: 11
Training loss: 2.930121875350365
Validation loss: 2.757807363069427

Epoch: 6| Step: 12
Training loss: 2.799528940630675
Validation loss: 2.75545653389835

Epoch: 6| Step: 13
Training loss: 3.3334338331966773
Validation loss: 2.75918347857672

Epoch: 102| Step: 0
Training loss: 2.8140367336247936
Validation loss: 2.757335496210694

Epoch: 6| Step: 1
Training loss: 2.9992601753985006
Validation loss: 2.758872792473142

Epoch: 6| Step: 2
Training loss: 2.7116034401632776
Validation loss: 2.7613310742181554

Epoch: 6| Step: 3
Training loss: 3.485408065307973
Validation loss: 2.7624140368084276

Epoch: 6| Step: 4
Training loss: 3.11506140536653
Validation loss: 2.771817479367613

Epoch: 6| Step: 5
Training loss: 2.756469658988924
Validation loss: 2.7753805215024747

Epoch: 6| Step: 6
Training loss: 2.8344423330230937
Validation loss: 2.7626318771710765

Epoch: 6| Step: 7
Training loss: 3.5955591043434607
Validation loss: 2.7644042035578456

Epoch: 6| Step: 8
Training loss: 4.106059197996441
Validation loss: 2.7646151650802877

Epoch: 6| Step: 9
Training loss: 3.1911904905264072
Validation loss: 2.761089074184226

Epoch: 6| Step: 10
Training loss: 3.019499192555006
Validation loss: 2.7611233992780573

Epoch: 6| Step: 11
Training loss: 2.503916533593352
Validation loss: 2.7589191367408112

Epoch: 6| Step: 12
Training loss: 3.321178368257896
Validation loss: 2.7578068443560357

Epoch: 6| Step: 13
Training loss: 1.3354536373755739
Validation loss: 2.7565568149117228

Epoch: 103| Step: 0
Training loss: 2.8015932318666144
Validation loss: 2.755905362499283

Epoch: 6| Step: 1
Training loss: 2.0657711098571188
Validation loss: 2.754333028289143

Epoch: 6| Step: 2
Training loss: 3.2093585139281107
Validation loss: 2.755245949991057

Epoch: 6| Step: 3
Training loss: 3.9123058526859755
Validation loss: 2.7533050525536464

Epoch: 6| Step: 4
Training loss: 2.405351248011869
Validation loss: 2.7539127793995033

Epoch: 6| Step: 5
Training loss: 3.1158080143872042
Validation loss: 2.7531253212180418

Epoch: 6| Step: 6
Training loss: 3.1457180650489627
Validation loss: 2.7540793594949404

Epoch: 6| Step: 7
Training loss: 4.038579384338448
Validation loss: 2.757903890400666

Epoch: 6| Step: 8
Training loss: 3.1268491233290225
Validation loss: 2.755271002924029

Epoch: 6| Step: 9
Training loss: 3.154706218601598
Validation loss: 2.7517226296947737

Epoch: 6| Step: 10
Training loss: 2.506312792364789
Validation loss: 2.7517240569812276

Epoch: 6| Step: 11
Training loss: 2.9009426426495204
Validation loss: 2.752670064859463

Epoch: 6| Step: 12
Training loss: 2.9872287068426586
Validation loss: 2.7536674824805045

Epoch: 6| Step: 13
Training loss: 3.0818704966889534
Validation loss: 2.753696353302233

Epoch: 104| Step: 0
Training loss: 3.0357425079316083
Validation loss: 2.7577194583488147

Epoch: 6| Step: 1
Training loss: 3.7204557722077682
Validation loss: 2.762085817478629

Epoch: 6| Step: 2
Training loss: 2.5494637467746357
Validation loss: 2.765210242410112

Epoch: 6| Step: 3
Training loss: 3.2704002109799997
Validation loss: 2.7636239703705385

Epoch: 6| Step: 4
Training loss: 3.0134288321471963
Validation loss: 2.7634315049059497

Epoch: 6| Step: 5
Training loss: 3.1370083305873315
Validation loss: 2.7623754317814804

Epoch: 6| Step: 6
Training loss: 2.549886596252382
Validation loss: 2.7617399164963206

Epoch: 6| Step: 7
Training loss: 3.3277212265154312
Validation loss: 2.7599654185063796

Epoch: 6| Step: 8
Training loss: 2.9233675321915107
Validation loss: 2.7502555821623553

Epoch: 6| Step: 9
Training loss: 3.2142711699625988
Validation loss: 2.7576012049236134

Epoch: 6| Step: 10
Training loss: 3.74247393377957
Validation loss: 2.7562813240365767

Epoch: 6| Step: 11
Training loss: 2.421425956197388
Validation loss: 2.753735586449312

Epoch: 6| Step: 12
Training loss: 2.838318216937302
Validation loss: 2.747420593781553

Epoch: 6| Step: 13
Training loss: 2.7943894407632537
Validation loss: 2.7467517136018973

Epoch: 105| Step: 0
Training loss: 2.324659289755392
Validation loss: 2.745825240626052

Epoch: 6| Step: 1
Training loss: 2.98531658238216
Validation loss: 2.745183946830676

Epoch: 6| Step: 2
Training loss: 2.405833914315929
Validation loss: 2.7482274608482227

Epoch: 6| Step: 3
Training loss: 2.6801893470547324
Validation loss: 2.744442113188366

Epoch: 6| Step: 4
Training loss: 3.6242888180504473
Validation loss: 2.7447712953869345

Epoch: 6| Step: 5
Training loss: 2.8344127244552286
Validation loss: 2.74500265363444

Epoch: 6| Step: 6
Training loss: 2.7496090524388483
Validation loss: 2.74496259801362

Epoch: 6| Step: 7
Training loss: 3.575552469527095
Validation loss: 2.744612849291204

Epoch: 6| Step: 8
Training loss: 3.1756998687489455
Validation loss: 2.7428352528831237

Epoch: 6| Step: 9
Training loss: 3.125711283798151
Validation loss: 2.742580289743871

Epoch: 6| Step: 10
Training loss: 2.8591763786996705
Validation loss: 2.7433529793087654

Epoch: 6| Step: 11
Training loss: 2.946578424119213
Validation loss: 2.742769741213094

Epoch: 6| Step: 12
Training loss: 3.770888579299345
Validation loss: 2.7446628632256527

Epoch: 6| Step: 13
Training loss: 3.7977452163932344
Validation loss: 2.7434223934098028

Epoch: 106| Step: 0
Training loss: 3.380467965725657
Validation loss: 2.7435291244079374

Epoch: 6| Step: 1
Training loss: 3.7056060077130994
Validation loss: 2.7440315564438698

Epoch: 6| Step: 2
Training loss: 2.419321498333486
Validation loss: 2.7463858982950287

Epoch: 6| Step: 3
Training loss: 3.247563842897671
Validation loss: 2.744985212434191

Epoch: 6| Step: 4
Training loss: 3.2787252249383405
Validation loss: 2.7421427502431257

Epoch: 6| Step: 5
Training loss: 2.998400579705279
Validation loss: 2.7447183309710153

Epoch: 6| Step: 6
Training loss: 2.986224175808982
Validation loss: 2.743120924921575

Epoch: 6| Step: 7
Training loss: 2.590651810418746
Validation loss: 2.7429517474421683

Epoch: 6| Step: 8
Training loss: 3.266702428609021
Validation loss: 2.7425035798716166

Epoch: 6| Step: 9
Training loss: 3.3382367467469325
Validation loss: 2.7426217654443072

Epoch: 6| Step: 10
Training loss: 2.822081288584268
Validation loss: 2.7489546749568428

Epoch: 6| Step: 11
Training loss: 3.2925044735912152
Validation loss: 2.7485508908902547

Epoch: 6| Step: 12
Training loss: 2.4025168255743745
Validation loss: 2.7414147933412423

Epoch: 6| Step: 13
Training loss: 2.6192095332855962
Validation loss: 2.7402796433376104

Epoch: 107| Step: 0
Training loss: 3.3980850212323173
Validation loss: 2.740909822514288

Epoch: 6| Step: 1
Training loss: 2.9873516157641196
Validation loss: 2.739565223482083

Epoch: 6| Step: 2
Training loss: 2.8339010866573164
Validation loss: 2.7379533671074494

Epoch: 6| Step: 3
Training loss: 3.4751596427857354
Validation loss: 2.7417012697932335

Epoch: 6| Step: 4
Training loss: 2.590854729381747
Validation loss: 2.747628603714251

Epoch: 6| Step: 5
Training loss: 2.972631707509972
Validation loss: 2.744555317895112

Epoch: 6| Step: 6
Training loss: 2.6524660871604704
Validation loss: 2.75319124387261

Epoch: 6| Step: 7
Training loss: 2.7523757036158747
Validation loss: 2.7681787045752566

Epoch: 6| Step: 8
Training loss: 2.7994069833838315
Validation loss: 2.768324305763314

Epoch: 6| Step: 9
Training loss: 3.4576929870719697
Validation loss: 2.7758934496888585

Epoch: 6| Step: 10
Training loss: 2.9784323758857796
Validation loss: 2.7825519260935043

Epoch: 6| Step: 11
Training loss: 3.483889695656139
Validation loss: 2.771882458041972

Epoch: 6| Step: 12
Training loss: 2.768684892771553
Validation loss: 2.7647450060172485

Epoch: 6| Step: 13
Training loss: 3.8518627119386712
Validation loss: 2.7628391352995543

Epoch: 108| Step: 0
Training loss: 3.31574349582635
Validation loss: 2.765901504801743

Epoch: 6| Step: 1
Training loss: 2.533852828451171
Validation loss: 2.759451426709535

Epoch: 6| Step: 2
Training loss: 2.8302028041463134
Validation loss: 2.764263606152365

Epoch: 6| Step: 3
Training loss: 2.5892535841879183
Validation loss: 2.7652314378066456

Epoch: 6| Step: 4
Training loss: 3.6207172482007564
Validation loss: 2.7593386129395414

Epoch: 6| Step: 5
Training loss: 3.4723751610876348
Validation loss: 2.757814751471079

Epoch: 6| Step: 6
Training loss: 3.4674281445506656
Validation loss: 2.7655793001934224

Epoch: 6| Step: 7
Training loss: 3.206772527817652
Validation loss: 2.736053397963259

Epoch: 6| Step: 8
Training loss: 2.615462551746559
Validation loss: 2.734849187984458

Epoch: 6| Step: 9
Training loss: 3.4347809181146234
Validation loss: 2.7344446345074975

Epoch: 6| Step: 10
Training loss: 2.4712675754074573
Validation loss: 2.7399310418459017

Epoch: 6| Step: 11
Training loss: 2.92514507879432
Validation loss: 2.7395710917757334

Epoch: 6| Step: 12
Training loss: 3.0580982571790467
Validation loss: 2.7651905969823596

Epoch: 6| Step: 13
Training loss: 2.9991290099661283
Validation loss: 2.75388519272077

Epoch: 109| Step: 0
Training loss: 3.0811715323030313
Validation loss: 2.7386262187877475

Epoch: 6| Step: 1
Training loss: 2.9545297662278456
Validation loss: 2.736346896479604

Epoch: 6| Step: 2
Training loss: 3.720928932206348
Validation loss: 2.7344065187105535

Epoch: 6| Step: 3
Training loss: 2.9473237069223037
Validation loss: 2.730536413899877

Epoch: 6| Step: 4
Training loss: 3.7948236143512766
Validation loss: 2.7283471167074764

Epoch: 6| Step: 5
Training loss: 3.2990286062063587
Validation loss: 2.728355267997741

Epoch: 6| Step: 6
Training loss: 3.1156956824393633
Validation loss: 2.731171271383253

Epoch: 6| Step: 7
Training loss: 2.724914314952716
Validation loss: 2.729429070029504

Epoch: 6| Step: 8
Training loss: 2.5019451203765395
Validation loss: 2.7288334632212057

Epoch: 6| Step: 9
Training loss: 2.6924292138729125
Validation loss: 2.730691085918265

Epoch: 6| Step: 10
Training loss: 3.197791446052461
Validation loss: 2.7312674015945975

Epoch: 6| Step: 11
Training loss: 3.272303856085234
Validation loss: 2.7379402452820787

Epoch: 6| Step: 12
Training loss: 2.567226238271898
Validation loss: 2.7353132597090606

Epoch: 6| Step: 13
Training loss: 2.2017493315585575
Validation loss: 2.739402287455382

Epoch: 110| Step: 0
Training loss: 3.1528791802484504
Validation loss: 2.7470211291217446

Epoch: 6| Step: 1
Training loss: 3.17430525259779
Validation loss: 2.750759137437276

Epoch: 6| Step: 2
Training loss: 3.515878625834043
Validation loss: 2.74858095056966

Epoch: 6| Step: 3
Training loss: 2.652522444850292
Validation loss: 2.7372249085773435

Epoch: 6| Step: 4
Training loss: 2.9360386886334355
Validation loss: 2.7312095562315273

Epoch: 6| Step: 5
Training loss: 3.0245195369786306
Validation loss: 2.73442472585534

Epoch: 6| Step: 6
Training loss: 2.62990674596889
Validation loss: 2.7276623974923297

Epoch: 6| Step: 7
Training loss: 3.709130419386406
Validation loss: 2.7294776386767943

Epoch: 6| Step: 8
Training loss: 2.754351034837047
Validation loss: 2.7253855040550796

Epoch: 6| Step: 9
Training loss: 2.694761712008926
Validation loss: 2.7256711793510204

Epoch: 6| Step: 10
Training loss: 3.7839860081484553
Validation loss: 2.7280129088117815

Epoch: 6| Step: 11
Training loss: 2.604723776671682
Validation loss: 2.7228284397577784

Epoch: 6| Step: 12
Training loss: 2.8607204586184927
Validation loss: 2.723139842470895

Epoch: 6| Step: 13
Training loss: 2.7423232172667404
Validation loss: 2.7209870165496413

Epoch: 111| Step: 0
Training loss: 3.210005650500497
Validation loss: 2.7226030775878236

Epoch: 6| Step: 1
Training loss: 3.031546037513446
Validation loss: 2.721759432285863

Epoch: 6| Step: 2
Training loss: 3.6779453178601544
Validation loss: 2.7223974910508417

Epoch: 6| Step: 3
Training loss: 3.163715861606177
Validation loss: 2.7200922733030692

Epoch: 6| Step: 4
Training loss: 2.693978064987952
Validation loss: 2.721473842807068

Epoch: 6| Step: 5
Training loss: 3.0902304618346794
Validation loss: 2.720946727989596

Epoch: 6| Step: 6
Training loss: 2.7777519087116684
Validation loss: 2.7217230876711063

Epoch: 6| Step: 7
Training loss: 2.4654077044950484
Validation loss: 2.720230571622804

Epoch: 6| Step: 8
Training loss: 3.199091311421266
Validation loss: 2.722077262622023

Epoch: 6| Step: 9
Training loss: 3.1991091978438315
Validation loss: 2.7247122852880494

Epoch: 6| Step: 10
Training loss: 2.020347563047679
Validation loss: 2.7254307979769585

Epoch: 6| Step: 11
Training loss: 3.1369113506697075
Validation loss: 2.7373959740179203

Epoch: 6| Step: 12
Training loss: 3.515504012675105
Validation loss: 2.730309351830724

Epoch: 6| Step: 13
Training loss: 3.1648096026723302
Validation loss: 2.7256571838731793

Epoch: 112| Step: 0
Training loss: 3.0968926391715113
Validation loss: 2.72450998564362

Epoch: 6| Step: 1
Training loss: 3.6318558940867405
Validation loss: 2.7188692520535707

Epoch: 6| Step: 2
Training loss: 2.9836982638824288
Validation loss: 2.718406537682595

Epoch: 6| Step: 3
Training loss: 2.9954986180133716
Validation loss: 2.7228564992651036

Epoch: 6| Step: 4
Training loss: 2.5145830164426926
Validation loss: 2.726583321677516

Epoch: 6| Step: 5
Training loss: 3.4480819124727984
Validation loss: 2.7285508042795334

Epoch: 6| Step: 6
Training loss: 2.722888821666476
Validation loss: 2.7181508468775184

Epoch: 6| Step: 7
Training loss: 3.188694150548495
Validation loss: 2.7135457152672866

Epoch: 6| Step: 8
Training loss: 2.8810672594486224
Validation loss: 2.7157917743855498

Epoch: 6| Step: 9
Training loss: 2.4826067503751084
Validation loss: 2.713981497509341

Epoch: 6| Step: 10
Training loss: 3.231821867698418
Validation loss: 2.7131031645646884

Epoch: 6| Step: 11
Training loss: 3.7218385580922826
Validation loss: 2.715123132822414

Epoch: 6| Step: 12
Training loss: 2.6815188186443244
Validation loss: 2.722638210855323

Epoch: 6| Step: 13
Training loss: 2.6004483239911327
Validation loss: 2.7258062263765854

Epoch: 113| Step: 0
Training loss: 2.3704944839976596
Validation loss: 2.726758991258661

Epoch: 6| Step: 1
Training loss: 2.8545596740867696
Validation loss: 2.7240769097295443

Epoch: 6| Step: 2
Training loss: 2.8842759798355715
Validation loss: 2.726795988918593

Epoch: 6| Step: 3
Training loss: 2.8895146067247324
Validation loss: 2.7390729532553095

Epoch: 6| Step: 4
Training loss: 3.2099631657373617
Validation loss: 2.7314904233449604

Epoch: 6| Step: 5
Training loss: 2.6580793476646716
Validation loss: 2.7285102628494777

Epoch: 6| Step: 6
Training loss: 3.2151673757788197
Validation loss: 2.708253976370788

Epoch: 6| Step: 7
Training loss: 3.0905163752614673
Validation loss: 2.7107339415962226

Epoch: 6| Step: 8
Training loss: 2.9523101166754846
Validation loss: 2.713045838107196

Epoch: 6| Step: 9
Training loss: 2.907112403809207
Validation loss: 2.71499316233067

Epoch: 6| Step: 10
Training loss: 3.5897374848254486
Validation loss: 2.7306716456029996

Epoch: 6| Step: 11
Training loss: 2.872415956972563
Validation loss: 2.7254386212423958

Epoch: 6| Step: 12
Training loss: 3.604555553705074
Validation loss: 2.7265567626102953

Epoch: 6| Step: 13
Training loss: 3.7121822799207895
Validation loss: 2.7349435044766266

Epoch: 114| Step: 0
Training loss: 3.335827720676122
Validation loss: 2.7370222327585747

Epoch: 6| Step: 1
Training loss: 3.538565426038217
Validation loss: 2.726180235765499

Epoch: 6| Step: 2
Training loss: 2.6471090670411144
Validation loss: 2.7166307681251123

Epoch: 6| Step: 3
Training loss: 2.782062540411298
Validation loss: 2.7115048457328155

Epoch: 6| Step: 4
Training loss: 1.8000676857620064
Validation loss: 2.7135276448447287

Epoch: 6| Step: 5
Training loss: 3.42581187183435
Validation loss: 2.7144753317754313

Epoch: 6| Step: 6
Training loss: 3.047335702349267
Validation loss: 2.707344884480807

Epoch: 6| Step: 7
Training loss: 3.7938189982592387
Validation loss: 2.7053644730270494

Epoch: 6| Step: 8
Training loss: 3.3501630942655183
Validation loss: 2.707350890791494

Epoch: 6| Step: 9
Training loss: 3.5509620007797107
Validation loss: 2.7059577013882623

Epoch: 6| Step: 10
Training loss: 2.56029490053825
Validation loss: 2.707196813298562

Epoch: 6| Step: 11
Training loss: 2.6304973984810416
Validation loss: 2.7057925975874495

Epoch: 6| Step: 12
Training loss: 2.193813694738384
Validation loss: 2.705272056362955

Epoch: 6| Step: 13
Training loss: 3.286292279981026
Validation loss: 2.7047377349138455

Epoch: 115| Step: 0
Training loss: 2.743593556456084
Validation loss: 2.7106736785823564

Epoch: 6| Step: 1
Training loss: 3.2360553891283055
Validation loss: 2.7104045857971517

Epoch: 6| Step: 2
Training loss: 2.848830160341382
Validation loss: 2.709563146631491

Epoch: 6| Step: 3
Training loss: 2.652664457322963
Validation loss: 2.7087565133253526

Epoch: 6| Step: 4
Training loss: 2.96637751495292
Validation loss: 2.7048806056443797

Epoch: 6| Step: 5
Training loss: 3.2193368913708924
Validation loss: 2.709642907404822

Epoch: 6| Step: 6
Training loss: 2.618781580768705
Validation loss: 2.705130060180924

Epoch: 6| Step: 7
Training loss: 2.763950164047532
Validation loss: 2.7049901851807854

Epoch: 6| Step: 8
Training loss: 2.8999253230510025
Validation loss: 2.7050401213983033

Epoch: 6| Step: 9
Training loss: 3.2301008944505245
Validation loss: 2.705584419457124

Epoch: 6| Step: 10
Training loss: 3.5165791890863534
Validation loss: 2.7064021669505465

Epoch: 6| Step: 11
Training loss: 3.176322637490802
Validation loss: 2.7054571480667047

Epoch: 6| Step: 12
Training loss: 3.1859005673799574
Validation loss: 2.704864247803141

Epoch: 6| Step: 13
Training loss: 3.4223727208302726
Validation loss: 2.7027150690380055

Epoch: 116| Step: 0
Training loss: 3.7125244602206755
Validation loss: 2.703687721304221

Epoch: 6| Step: 1
Training loss: 3.4051255636268305
Validation loss: 2.7046296389947533

Epoch: 6| Step: 2
Training loss: 3.213634091886954
Validation loss: 2.704269971880486

Epoch: 6| Step: 3
Training loss: 2.7443988284885945
Validation loss: 2.7021339938192592

Epoch: 6| Step: 4
Training loss: 3.4040742977564395
Validation loss: 2.703298718325279

Epoch: 6| Step: 5
Training loss: 2.908218537463357
Validation loss: 2.70366253505982

Epoch: 6| Step: 6
Training loss: 3.3191425730674964
Validation loss: 2.7032049934139963

Epoch: 6| Step: 7
Training loss: 2.7638096427951884
Validation loss: 2.70151042927551

Epoch: 6| Step: 8
Training loss: 2.6897864263333453
Validation loss: 2.7039810021238457

Epoch: 6| Step: 9
Training loss: 3.2723727804915432
Validation loss: 2.707225933489899

Epoch: 6| Step: 10
Training loss: 3.0008098780689867
Validation loss: 2.700865794008451

Epoch: 6| Step: 11
Training loss: 2.575692618837861
Validation loss: 2.704869668203117

Epoch: 6| Step: 12
Training loss: 2.0266893098637047
Validation loss: 2.715369120877186

Epoch: 6| Step: 13
Training loss: 2.9316705528119305
Validation loss: 2.7264417696864633

Epoch: 117| Step: 0
Training loss: 3.125805865331252
Validation loss: 2.753319535061328

Epoch: 6| Step: 1
Training loss: 3.404598850813549
Validation loss: 2.7503077669471594

Epoch: 6| Step: 2
Training loss: 2.6439082934739884
Validation loss: 2.713883520360138

Epoch: 6| Step: 3
Training loss: 3.122762413024052
Validation loss: 2.7014039257087394

Epoch: 6| Step: 4
Training loss: 3.1633854647951067
Validation loss: 2.6991996509803573

Epoch: 6| Step: 5
Training loss: 3.1456177155493528
Validation loss: 2.6990413373289104

Epoch: 6| Step: 6
Training loss: 3.138278065291202
Validation loss: 2.696931789801575

Epoch: 6| Step: 7
Training loss: 3.3580944370715686
Validation loss: 2.698127117557165

Epoch: 6| Step: 8
Training loss: 2.596545448003906
Validation loss: 2.7002283476400284

Epoch: 6| Step: 9
Training loss: 2.9764529230568773
Validation loss: 2.6988696712601685

Epoch: 6| Step: 10
Training loss: 2.5297432641803823
Validation loss: 2.7010555953971216

Epoch: 6| Step: 11
Training loss: 2.8848771969262774
Validation loss: 2.6974618819596716

Epoch: 6| Step: 12
Training loss: 3.202255354268749
Validation loss: 2.7008417983240647

Epoch: 6| Step: 13
Training loss: 3.089213735055328
Validation loss: 2.697852997514177

Epoch: 118| Step: 0
Training loss: 2.9542269795174487
Validation loss: 2.6987763624902303

Epoch: 6| Step: 1
Training loss: 2.921433196095794
Validation loss: 2.698171174963255

Epoch: 6| Step: 2
Training loss: 2.8580390852864315
Validation loss: 2.6971920232951265

Epoch: 6| Step: 3
Training loss: 2.6827174370374647
Validation loss: 2.7015004451893208

Epoch: 6| Step: 4
Training loss: 2.6891038234268576
Validation loss: 2.697171906204489

Epoch: 6| Step: 5
Training loss: 2.81444694100097
Validation loss: 2.6999913771904485

Epoch: 6| Step: 6
Training loss: 3.002100209372475
Validation loss: 2.7009173128199326

Epoch: 6| Step: 7
Training loss: 3.0494508467786368
Validation loss: 2.7016544727291834

Epoch: 6| Step: 8
Training loss: 2.9129724995198605
Validation loss: 2.7066599659291484

Epoch: 6| Step: 9
Training loss: 3.750357801533924
Validation loss: 2.723845449397282

Epoch: 6| Step: 10
Training loss: 2.445140893539228
Validation loss: 2.726321291676923

Epoch: 6| Step: 11
Training loss: 3.312340066755597
Validation loss: 2.7222248747344406

Epoch: 6| Step: 12
Training loss: 2.785014487319604
Validation loss: 2.7201668782891226

Epoch: 6| Step: 13
Training loss: 4.4374226308176
Validation loss: 2.7089822589661265

Epoch: 119| Step: 0
Training loss: 3.489152857101174
Validation loss: 2.6980236369750275

Epoch: 6| Step: 1
Training loss: 2.583248711297258
Validation loss: 2.698804300649727

Epoch: 6| Step: 2
Training loss: 2.8716158645159773
Validation loss: 2.6985670949496163

Epoch: 6| Step: 3
Training loss: 2.225559477169657
Validation loss: 2.695660118310852

Epoch: 6| Step: 4
Training loss: 3.7775216124829623
Validation loss: 2.6964132535716305

Epoch: 6| Step: 5
Training loss: 3.54141110264841
Validation loss: 2.6958673781962643

Epoch: 6| Step: 6
Training loss: 3.283723607242206
Validation loss: 2.695102382303167

Epoch: 6| Step: 7
Training loss: 2.514930297462045
Validation loss: 2.6966407322122947

Epoch: 6| Step: 8
Training loss: 2.3227515967411527
Validation loss: 2.698437296082049

Epoch: 6| Step: 9
Training loss: 2.844699407697377
Validation loss: 2.69430830411097

Epoch: 6| Step: 10
Training loss: 2.82777849466764
Validation loss: 2.6941315672226063

Epoch: 6| Step: 11
Training loss: 2.95933453090111
Validation loss: 2.6950034553036444

Epoch: 6| Step: 12
Training loss: 3.684721465641319
Validation loss: 2.6937449805796785

Epoch: 6| Step: 13
Training loss: 2.7618422851558617
Validation loss: 2.6963295616639424

Epoch: 120| Step: 0
Training loss: 2.858763415693355
Validation loss: 2.6942005871362005

Epoch: 6| Step: 1
Training loss: 2.825968304666256
Validation loss: 2.697233936507745

Epoch: 6| Step: 2
Training loss: 3.4242389473829675
Validation loss: 2.6998146353548265

Epoch: 6| Step: 3
Training loss: 3.0018165175082165
Validation loss: 2.7003186460578616

Epoch: 6| Step: 4
Training loss: 2.0196862520984005
Validation loss: 2.7031064075250466

Epoch: 6| Step: 5
Training loss: 3.171517337872563
Validation loss: 2.701890970918121

Epoch: 6| Step: 6
Training loss: 3.2879803614807237
Validation loss: 2.6998516547143376

Epoch: 6| Step: 7
Training loss: 3.138296146371713
Validation loss: 2.6941729533104692

Epoch: 6| Step: 8
Training loss: 3.122303218703521
Validation loss: 2.6919573874094787

Epoch: 6| Step: 9
Training loss: 2.839247608186158
Validation loss: 2.6921679248295383

Epoch: 6| Step: 10
Training loss: 2.9516345910415813
Validation loss: 2.6954345152375896

Epoch: 6| Step: 11
Training loss: 3.158841268581759
Validation loss: 2.7130446474940983

Epoch: 6| Step: 12
Training loss: 3.2662163158012736
Validation loss: 2.736977582136278

Epoch: 6| Step: 13
Training loss: 3.041844053626358
Validation loss: 2.744025133861691

Epoch: 121| Step: 0
Training loss: 3.029628988785984
Validation loss: 2.7453377413151503

Epoch: 6| Step: 1
Training loss: 2.5359180875118628
Validation loss: 2.7570863316340013

Epoch: 6| Step: 2
Training loss: 3.345759848377151
Validation loss: 2.761059098684951

Epoch: 6| Step: 3
Training loss: 3.071335483800611
Validation loss: 2.7672448299403984

Epoch: 6| Step: 4
Training loss: 3.029337171314835
Validation loss: 2.779191625538704

Epoch: 6| Step: 5
Training loss: 3.967403393670771
Validation loss: 2.776435422562179

Epoch: 6| Step: 6
Training loss: 2.124739238222972
Validation loss: 2.754288040258587

Epoch: 6| Step: 7
Training loss: 3.12600935847565
Validation loss: 2.7409957447703683

Epoch: 6| Step: 8
Training loss: 3.3249672966976513
Validation loss: 2.735431610677158

Epoch: 6| Step: 9
Training loss: 2.497670805229133
Validation loss: 2.7282164625303604

Epoch: 6| Step: 10
Training loss: 3.0471253903525612
Validation loss: 2.719376986423665

Epoch: 6| Step: 11
Training loss: 2.9002928026958985
Validation loss: 2.7048847199685064

Epoch: 6| Step: 12
Training loss: 3.1888074998146285
Validation loss: 2.6953690527543834

Epoch: 6| Step: 13
Training loss: 3.2697021731383105
Validation loss: 2.688163991998081

Epoch: 122| Step: 0
Training loss: 2.758794593467907
Validation loss: 2.688283294365023

Epoch: 6| Step: 1
Training loss: 3.023102813254428
Validation loss: 2.6888108944760307

Epoch: 6| Step: 2
Training loss: 3.5309029467696837
Validation loss: 2.6887540874603735

Epoch: 6| Step: 3
Training loss: 3.2081221143544942
Validation loss: 2.6925951056665456

Epoch: 6| Step: 4
Training loss: 3.3986019401667327
Validation loss: 2.7058447521266187

Epoch: 6| Step: 5
Training loss: 2.8597133415454405
Validation loss: 2.7049664118434036

Epoch: 6| Step: 6
Training loss: 3.1289009160866676
Validation loss: 2.6989349509993823

Epoch: 6| Step: 7
Training loss: 2.8321826131425585
Validation loss: 2.6930145459597585

Epoch: 6| Step: 8
Training loss: 2.7140108216701755
Validation loss: 2.692925713350876

Epoch: 6| Step: 9
Training loss: 3.141732243697554
Validation loss: 2.6901206403078852

Epoch: 6| Step: 10
Training loss: 3.516505152411763
Validation loss: 2.6872289634914117

Epoch: 6| Step: 11
Training loss: 2.918343761199615
Validation loss: 2.689709052405767

Epoch: 6| Step: 12
Training loss: 2.426605625100982
Validation loss: 2.690116961788985

Epoch: 6| Step: 13
Training loss: 2.228851747698849
Validation loss: 2.6990215265730586

Epoch: 123| Step: 0
Training loss: 3.03427177905787
Validation loss: 2.7289793984657194

Epoch: 6| Step: 1
Training loss: 2.5321674332664528
Validation loss: 2.7339633614226444

Epoch: 6| Step: 2
Training loss: 2.6235504689524975
Validation loss: 2.7283738068069967

Epoch: 6| Step: 3
Training loss: 3.0091852399629113
Validation loss: 2.709309285827866

Epoch: 6| Step: 4
Training loss: 3.581045100290548
Validation loss: 2.703179835865178

Epoch: 6| Step: 5
Training loss: 3.1701014779873065
Validation loss: 2.6977654460362652

Epoch: 6| Step: 6
Training loss: 2.8726408857651067
Validation loss: 2.697319742647306

Epoch: 6| Step: 7
Training loss: 2.744921850679744
Validation loss: 2.68866105313024

Epoch: 6| Step: 8
Training loss: 3.495554962411442
Validation loss: 2.6989004600051123

Epoch: 6| Step: 9
Training loss: 2.792143074113427
Validation loss: 2.69006588036453

Epoch: 6| Step: 10
Training loss: 2.7001479850056693
Validation loss: 2.682188552290576

Epoch: 6| Step: 11
Training loss: 3.046181311257537
Validation loss: 2.6824062817931065

Epoch: 6| Step: 12
Training loss: 3.267638247541621
Validation loss: 2.6898508075982512

Epoch: 6| Step: 13
Training loss: 3.197280538870226
Validation loss: 2.68761892835406

Epoch: 124| Step: 0
Training loss: 2.8614624408534595
Validation loss: 2.6881009169572403

Epoch: 6| Step: 1
Training loss: 2.8722345071116275
Validation loss: 2.6866832693109077

Epoch: 6| Step: 2
Training loss: 3.5517872139713096
Validation loss: 2.686895878269665

Epoch: 6| Step: 3
Training loss: 2.9404201197017206
Validation loss: 2.6843877611436295

Epoch: 6| Step: 4
Training loss: 2.940621199083456
Validation loss: 2.687059641592354

Epoch: 6| Step: 5
Training loss: 2.91950786806808
Validation loss: 2.686461470987478

Epoch: 6| Step: 6
Training loss: 2.829663780108773
Validation loss: 2.687544726690932

Epoch: 6| Step: 7
Training loss: 3.4839392419503477
Validation loss: 2.687180864788838

Epoch: 6| Step: 8
Training loss: 2.942261428430931
Validation loss: 2.685627328034883

Epoch: 6| Step: 9
Training loss: 2.7584577027217723
Validation loss: 2.6867114734885384

Epoch: 6| Step: 10
Training loss: 3.634670774932838
Validation loss: 2.6859852785491327

Epoch: 6| Step: 11
Training loss: 2.729027363568335
Validation loss: 2.685441860498709

Epoch: 6| Step: 12
Training loss: 2.9191787437503494
Validation loss: 2.6873604084076725

Epoch: 6| Step: 13
Training loss: 2.723882894158199
Validation loss: 2.6855345443188936

Epoch: 125| Step: 0
Training loss: 2.9348814635896736
Validation loss: 2.6781031024253164

Epoch: 6| Step: 1
Training loss: 3.0674924056651673
Validation loss: 2.6849709850362973

Epoch: 6| Step: 2
Training loss: 3.027840496039712
Validation loss: 2.722445251948825

Epoch: 6| Step: 3
Training loss: 2.7064092012231504
Validation loss: 2.768978248876326

Epoch: 6| Step: 4
Training loss: 2.7762633635342295
Validation loss: 2.775969075266191

Epoch: 6| Step: 5
Training loss: 3.2632963648238955
Validation loss: 2.7386850879019016

Epoch: 6| Step: 6
Training loss: 3.443957972953534
Validation loss: 2.7288368875651163

Epoch: 6| Step: 7
Training loss: 3.111946001501274
Validation loss: 2.679997019473007

Epoch: 6| Step: 8
Training loss: 3.2805006352269785
Validation loss: 2.672187256810454

Epoch: 6| Step: 9
Training loss: 2.9125013490600082
Validation loss: 2.6730133560017197

Epoch: 6| Step: 10
Training loss: 2.823027004511413
Validation loss: 2.6766550851473596

Epoch: 6| Step: 11
Training loss: 3.2172806728631116
Validation loss: 2.67733264724751

Epoch: 6| Step: 12
Training loss: 2.208378365495367
Validation loss: 2.68258766829329

Epoch: 6| Step: 13
Training loss: 3.7482361778015107
Validation loss: 2.6822028711190615

Epoch: 126| Step: 0
Training loss: 3.414042387669592
Validation loss: 2.6852004192532912

Epoch: 6| Step: 1
Training loss: 3.089354041026717
Validation loss: 2.683125277110226

Epoch: 6| Step: 2
Training loss: 2.8676321739857644
Validation loss: 2.684128638680894

Epoch: 6| Step: 3
Training loss: 2.3867205480890323
Validation loss: 2.6842129106169303

Epoch: 6| Step: 4
Training loss: 3.2785297562117264
Validation loss: 2.6846204194135006

Epoch: 6| Step: 5
Training loss: 3.5179801681506073
Validation loss: 2.682985919422935

Epoch: 6| Step: 6
Training loss: 2.970373091463467
Validation loss: 2.6834209801065065

Epoch: 6| Step: 7
Training loss: 2.972144344731664
Validation loss: 2.6800856234580435

Epoch: 6| Step: 8
Training loss: 3.1914328453795457
Validation loss: 2.679816738573314

Epoch: 6| Step: 9
Training loss: 3.2107328549255296
Validation loss: 2.6780724488742353

Epoch: 6| Step: 10
Training loss: 2.8556956815498666
Validation loss: 2.6790674427920953

Epoch: 6| Step: 11
Training loss: 2.9027764676794314
Validation loss: 2.6761089390468804

Epoch: 6| Step: 12
Training loss: 2.770619080561074
Validation loss: 2.675759462932993

Epoch: 6| Step: 13
Training loss: 2.5923961185253805
Validation loss: 2.6729374157207313

Epoch: 127| Step: 0
Training loss: 3.411612393149865
Validation loss: 2.672247851467475

Epoch: 6| Step: 1
Training loss: 2.7375508203535794
Validation loss: 2.672995207219812

Epoch: 6| Step: 2
Training loss: 3.1101915063802523
Validation loss: 2.6716363849845077

Epoch: 6| Step: 3
Training loss: 2.857141007695281
Validation loss: 2.673118490488416

Epoch: 6| Step: 4
Training loss: 2.721083330369397
Validation loss: 2.675622656409513

Epoch: 6| Step: 5
Training loss: 3.0323754806930165
Validation loss: 2.6775865362386444

Epoch: 6| Step: 6
Training loss: 2.8093993155134727
Validation loss: 2.684614552280418

Epoch: 6| Step: 7
Training loss: 3.104277453056379
Validation loss: 2.6803942868516946

Epoch: 6| Step: 8
Training loss: 3.0055135288774903
Validation loss: 2.6811742634069153

Epoch: 6| Step: 9
Training loss: 3.4807838442877053
Validation loss: 2.6850870073794093

Epoch: 6| Step: 10
Training loss: 3.4378234711086986
Validation loss: 2.6749509855787763

Epoch: 6| Step: 11
Training loss: 2.635934399397767
Validation loss: 2.6684561987857967

Epoch: 6| Step: 12
Training loss: 2.858981746459203
Validation loss: 2.666145832076904

Epoch: 6| Step: 13
Training loss: 2.642036557299119
Validation loss: 2.6688480459955417

Epoch: 128| Step: 0
Training loss: 3.219016943667455
Validation loss: 2.667045977428713

Epoch: 6| Step: 1
Training loss: 2.6201708742286733
Validation loss: 2.663902904635547

Epoch: 6| Step: 2
Training loss: 2.6950833872844275
Validation loss: 2.662820775591301

Epoch: 6| Step: 3
Training loss: 2.606519404330489
Validation loss: 2.6656396888593927

Epoch: 6| Step: 4
Training loss: 2.875670313437706
Validation loss: 2.665493659731836

Epoch: 6| Step: 5
Training loss: 3.190823486610483
Validation loss: 2.6641748919650263

Epoch: 6| Step: 6
Training loss: 3.0967848563523432
Validation loss: 2.6660383148171394

Epoch: 6| Step: 7
Training loss: 3.4023734615881223
Validation loss: 2.6649750033980584

Epoch: 6| Step: 8
Training loss: 2.7854739913424633
Validation loss: 2.6653915783751025

Epoch: 6| Step: 9
Training loss: 2.550256648892367
Validation loss: 2.664736341983883

Epoch: 6| Step: 10
Training loss: 3.492373741013958
Validation loss: 2.671459388995419

Epoch: 6| Step: 11
Training loss: 2.7512405371774027
Validation loss: 2.672111423531338

Epoch: 6| Step: 12
Training loss: 3.4813820339620936
Validation loss: 2.6762265583271603

Epoch: 6| Step: 13
Training loss: 3.1108919210270747
Validation loss: 2.682207931101984

Epoch: 129| Step: 0
Training loss: 3.482286725548059
Validation loss: 2.6732385228112787

Epoch: 6| Step: 1
Training loss: 3.4932832300315595
Validation loss: 2.6674356742522582

Epoch: 6| Step: 2
Training loss: 2.328409881571353
Validation loss: 2.662901553014418

Epoch: 6| Step: 3
Training loss: 3.132106634894648
Validation loss: 2.6666974977920845

Epoch: 6| Step: 4
Training loss: 2.8766962106306666
Validation loss: 2.6721639735373675

Epoch: 6| Step: 5
Training loss: 2.548355701848172
Validation loss: 2.671852691735727

Epoch: 6| Step: 6
Training loss: 3.188524717285676
Validation loss: 2.6757835187573775

Epoch: 6| Step: 7
Training loss: 2.0847469747136897
Validation loss: 2.6739215996736423

Epoch: 6| Step: 8
Training loss: 3.3523227211820052
Validation loss: 2.6699660742441993

Epoch: 6| Step: 9
Training loss: 3.1806591152191337
Validation loss: 2.686218184974144

Epoch: 6| Step: 10
Training loss: 2.995570568574714
Validation loss: 2.6755542169885613

Epoch: 6| Step: 11
Training loss: 3.2100433812522664
Validation loss: 2.66634668332641

Epoch: 6| Step: 12
Training loss: 3.2029412937983355
Validation loss: 2.6662440856025245

Epoch: 6| Step: 13
Training loss: 2.1848228421179665
Validation loss: 2.6605201327635624

Epoch: 130| Step: 0
Training loss: 3.4093707426413467
Validation loss: 2.6593151371280643

Epoch: 6| Step: 1
Training loss: 2.6317969834199744
Validation loss: 2.6594896937700594

Epoch: 6| Step: 2
Training loss: 3.036001198297196
Validation loss: 2.660380596996564

Epoch: 6| Step: 3
Training loss: 3.120139805767001
Validation loss: 2.663150124827897

Epoch: 6| Step: 4
Training loss: 3.171080391106916
Validation loss: 2.6591896338120513

Epoch: 6| Step: 5
Training loss: 3.4526147249622103
Validation loss: 2.6617698592266197

Epoch: 6| Step: 6
Training loss: 2.976539751902084
Validation loss: 2.6606733799990234

Epoch: 6| Step: 7
Training loss: 2.8304403532637443
Validation loss: 2.658699486162551

Epoch: 6| Step: 8
Training loss: 3.1297738804659163
Validation loss: 2.661619537719855

Epoch: 6| Step: 9
Training loss: 2.9165225038776916
Validation loss: 2.662182842096135

Epoch: 6| Step: 10
Training loss: 2.5359270190799763
Validation loss: 2.6646266954862083

Epoch: 6| Step: 11
Training loss: 3.245315109494317
Validation loss: 2.6603004346983044

Epoch: 6| Step: 12
Training loss: 2.864582759972717
Validation loss: 2.66018484143392

Epoch: 6| Step: 13
Training loss: 2.178831527156349
Validation loss: 2.658222909164647

Epoch: 131| Step: 0
Training loss: 2.700347796751224
Validation loss: 2.657150338915499

Epoch: 6| Step: 1
Training loss: 2.9231579253907753
Validation loss: 2.6560809280085262

Epoch: 6| Step: 2
Training loss: 3.4686550093007757
Validation loss: 2.658558968649196

Epoch: 6| Step: 3
Training loss: 2.927505697998965
Validation loss: 2.673424916539754

Epoch: 6| Step: 4
Training loss: 2.9326557229298835
Validation loss: 2.685414917449342

Epoch: 6| Step: 5
Training loss: 2.820410560319147
Validation loss: 2.7174245205579455

Epoch: 6| Step: 6
Training loss: 2.6628621996738593
Validation loss: 2.7393366272392523

Epoch: 6| Step: 7
Training loss: 3.3884011284131117
Validation loss: 2.7496667671226818

Epoch: 6| Step: 8
Training loss: 3.0587507380588703
Validation loss: 2.7168806205320406

Epoch: 6| Step: 9
Training loss: 2.8522075602800974
Validation loss: 2.672539116154463

Epoch: 6| Step: 10
Training loss: 2.4780263335127253
Validation loss: 2.6538418880133006

Epoch: 6| Step: 11
Training loss: 3.0095053132582748
Validation loss: 2.6494387261918457

Epoch: 6| Step: 12
Training loss: 3.2450274059860553
Validation loss: 2.6516737903628624

Epoch: 6| Step: 13
Training loss: 3.587735525235332
Validation loss: 2.6533881582640615

Epoch: 132| Step: 0
Training loss: 3.2148751944467673
Validation loss: 2.6494644366052023

Epoch: 6| Step: 1
Training loss: 2.6228512643462674
Validation loss: 2.652475011918422

Epoch: 6| Step: 2
Training loss: 2.8628075846702834
Validation loss: 2.650215295894625

Epoch: 6| Step: 3
Training loss: 2.89509360839037
Validation loss: 2.650076069807089

Epoch: 6| Step: 4
Training loss: 3.4940678869857047
Validation loss: 2.6501219214673633

Epoch: 6| Step: 5
Training loss: 3.778827994977411
Validation loss: 2.6484541656989067

Epoch: 6| Step: 6
Training loss: 3.324848406784975
Validation loss: 2.6481755461936265

Epoch: 6| Step: 7
Training loss: 2.525847898831643
Validation loss: 2.6459697736332686

Epoch: 6| Step: 8
Training loss: 3.223391103479944
Validation loss: 2.6475129978172633

Epoch: 6| Step: 9
Training loss: 3.040262098307284
Validation loss: 2.6470227819081957

Epoch: 6| Step: 10
Training loss: 2.774369633878471
Validation loss: 2.6489164840257597

Epoch: 6| Step: 11
Training loss: 2.7019245811852945
Validation loss: 2.647623505067593

Epoch: 6| Step: 12
Training loss: 2.4910928360995315
Validation loss: 2.6468157453895333

Epoch: 6| Step: 13
Training loss: 2.2578310850229903
Validation loss: 2.6476961386200775

Epoch: 133| Step: 0
Training loss: 2.8422966900991073
Validation loss: 2.6475375078277708

Epoch: 6| Step: 1
Training loss: 2.770790147564337
Validation loss: 2.6502854846455426

Epoch: 6| Step: 2
Training loss: 3.0665763662007848
Validation loss: 2.65611610340536

Epoch: 6| Step: 3
Training loss: 2.9003511676609013
Validation loss: 2.6688679875507906

Epoch: 6| Step: 4
Training loss: 2.8112279770507116
Validation loss: 2.666582640418736

Epoch: 6| Step: 5
Training loss: 3.3659121760098447
Validation loss: 2.6641979640784754

Epoch: 6| Step: 6
Training loss: 3.4647470007014407
Validation loss: 2.6591976114659075

Epoch: 6| Step: 7
Training loss: 2.8834760362301735
Validation loss: 2.648608357885288

Epoch: 6| Step: 8
Training loss: 3.249204538272523
Validation loss: 2.653726976576952

Epoch: 6| Step: 9
Training loss: 2.745878772813059
Validation loss: 2.644596174610106

Epoch: 6| Step: 10
Training loss: 3.0148942289255998
Validation loss: 2.6476926383819315

Epoch: 6| Step: 11
Training loss: 2.9362426664180448
Validation loss: 2.6446742412072237

Epoch: 6| Step: 12
Training loss: 2.7291317614781425
Validation loss: 2.6446439000744926

Epoch: 6| Step: 13
Training loss: 3.0069258534887267
Validation loss: 2.646880663360012

Epoch: 134| Step: 0
Training loss: 2.7286426730330904
Validation loss: 2.6471363254033466

Epoch: 6| Step: 1
Training loss: 2.759195904735735
Validation loss: 2.6497319234109584

Epoch: 6| Step: 2
Training loss: 2.175115569102625
Validation loss: 2.6469474673985363

Epoch: 6| Step: 3
Training loss: 2.5854732407848853
Validation loss: 2.645637011412532

Epoch: 6| Step: 4
Training loss: 3.121854190547043
Validation loss: 2.647322845800506

Epoch: 6| Step: 5
Training loss: 2.699901268178182
Validation loss: 2.6456984912817703

Epoch: 6| Step: 6
Training loss: 3.200187415356826
Validation loss: 2.6482850480790168

Epoch: 6| Step: 7
Training loss: 3.3533300616158006
Validation loss: 2.644957853863447

Epoch: 6| Step: 8
Training loss: 3.644157954782127
Validation loss: 2.643684538484116

Epoch: 6| Step: 9
Training loss: 3.050408295365166
Validation loss: 2.6434726766386785

Epoch: 6| Step: 10
Training loss: 2.851132044244149
Validation loss: 2.646606222613341

Epoch: 6| Step: 11
Training loss: 3.170199999592226
Validation loss: 2.642539299197794

Epoch: 6| Step: 12
Training loss: 3.2182723496472305
Validation loss: 2.645552873139684

Epoch: 6| Step: 13
Training loss: 2.9623868510210714
Validation loss: 2.647124423994912

Epoch: 135| Step: 0
Training loss: 3.353430451970581
Validation loss: 2.6444566614104854

Epoch: 6| Step: 1
Training loss: 2.8709776562944365
Validation loss: 2.6443369300184645

Epoch: 6| Step: 2
Training loss: 3.290523539805729
Validation loss: 2.645963608610323

Epoch: 6| Step: 3
Training loss: 2.372364388741483
Validation loss: 2.649807247303632

Epoch: 6| Step: 4
Training loss: 2.776022037248235
Validation loss: 2.6510916688120294

Epoch: 6| Step: 5
Training loss: 2.8185241608747247
Validation loss: 2.6564298217825253

Epoch: 6| Step: 6
Training loss: 2.597909005854084
Validation loss: 2.6647755033775478

Epoch: 6| Step: 7
Training loss: 3.5072664035438263
Validation loss: 2.6669773650162156

Epoch: 6| Step: 8
Training loss: 3.1896797655620444
Validation loss: 2.68048844878744

Epoch: 6| Step: 9
Training loss: 3.288277937945662
Validation loss: 2.671003017922793

Epoch: 6| Step: 10
Training loss: 3.602756525736958
Validation loss: 2.6816334836922247

Epoch: 6| Step: 11
Training loss: 2.1103176694987726
Validation loss: 2.6457845037242205

Epoch: 6| Step: 12
Training loss: 2.8979562529532363
Validation loss: 2.641636461961454

Epoch: 6| Step: 13
Training loss: 2.6199354634089707
Validation loss: 2.642503838298017

Epoch: 136| Step: 0
Training loss: 2.933609029067235
Validation loss: 2.642991503272256

Epoch: 6| Step: 1
Training loss: 3.196740314111276
Validation loss: 2.6409753046586935

Epoch: 6| Step: 2
Training loss: 3.1853117069560386
Validation loss: 2.6426938597785834

Epoch: 6| Step: 3
Training loss: 3.5124459367711602
Validation loss: 2.6428664528353387

Epoch: 6| Step: 4
Training loss: 2.9678478275577174
Validation loss: 2.639216518806737

Epoch: 6| Step: 5
Training loss: 2.4346698078094864
Validation loss: 2.6430056920558784

Epoch: 6| Step: 6
Training loss: 2.915321221425982
Validation loss: 2.6421568577000727

Epoch: 6| Step: 7
Training loss: 3.207613893242539
Validation loss: 2.64164742247691

Epoch: 6| Step: 8
Training loss: 2.586208917025073
Validation loss: 2.640526390285389

Epoch: 6| Step: 9
Training loss: 3.141622963625816
Validation loss: 2.6408445467609702

Epoch: 6| Step: 10
Training loss: 3.015063614055557
Validation loss: 2.639342908728241

Epoch: 6| Step: 11
Training loss: 2.817548670919544
Validation loss: 2.639726971879647

Epoch: 6| Step: 12
Training loss: 2.8520417111250445
Validation loss: 2.640338460568654

Epoch: 6| Step: 13
Training loss: 2.771822692996858
Validation loss: 2.636692912386474

Epoch: 137| Step: 0
Training loss: 3.005333133708786
Validation loss: 2.638567929124046

Epoch: 6| Step: 1
Training loss: 3.278949330619269
Validation loss: 2.639499225065233

Epoch: 6| Step: 2
Training loss: 2.9375089280013094
Validation loss: 2.635765436523422

Epoch: 6| Step: 3
Training loss: 3.7529680586120637
Validation loss: 2.636657487589778

Epoch: 6| Step: 4
Training loss: 2.7129803526659413
Validation loss: 2.636434625397703

Epoch: 6| Step: 5
Training loss: 2.5743286850280693
Validation loss: 2.6366866760855365

Epoch: 6| Step: 6
Training loss: 2.789480738976582
Validation loss: 2.636938739624937

Epoch: 6| Step: 7
Training loss: 3.3535709365433473
Validation loss: 2.6395585907369234

Epoch: 6| Step: 8
Training loss: 2.9209252104047154
Validation loss: 2.6367604256712367

Epoch: 6| Step: 9
Training loss: 2.3261150926502694
Validation loss: 2.635861934848411

Epoch: 6| Step: 10
Training loss: 2.8608633034885744
Validation loss: 2.63333367669241

Epoch: 6| Step: 11
Training loss: 2.8080811437310413
Validation loss: 2.6422820009042516

Epoch: 6| Step: 12
Training loss: 2.584152666004991
Validation loss: 2.6487078785036613

Epoch: 6| Step: 13
Training loss: 3.850215529316818
Validation loss: 2.6620516341597216

Epoch: 138| Step: 0
Training loss: 2.5978056671078416
Validation loss: 2.660773159446195

Epoch: 6| Step: 1
Training loss: 3.133812647202074
Validation loss: 2.683507729469825

Epoch: 6| Step: 2
Training loss: 3.305853743865581
Validation loss: 2.6778933384697607

Epoch: 6| Step: 3
Training loss: 2.7350729787180406
Validation loss: 2.6487543548933936

Epoch: 6| Step: 4
Training loss: 2.3728714489556832
Validation loss: 2.6367302209869705

Epoch: 6| Step: 5
Training loss: 3.2267271281586125
Validation loss: 2.636125494462031

Epoch: 6| Step: 6
Training loss: 2.24538159566071
Validation loss: 2.6349070484822916

Epoch: 6| Step: 7
Training loss: 3.3208492787615302
Validation loss: 2.6362858184190854

Epoch: 6| Step: 8
Training loss: 3.1050162123596254
Validation loss: 2.6415207701419257

Epoch: 6| Step: 9
Training loss: 3.2947803369681674
Validation loss: 2.6405206475096663

Epoch: 6| Step: 10
Training loss: 2.941462502315278
Validation loss: 2.6407033296187947

Epoch: 6| Step: 11
Training loss: 2.747971393386334
Validation loss: 2.644985060732708

Epoch: 6| Step: 12
Training loss: 3.5317047636513528
Validation loss: 2.644747052689613

Epoch: 6| Step: 13
Training loss: 3.1174392789725762
Validation loss: 2.644414115278685

Epoch: 139| Step: 0
Training loss: 2.427408308503414
Validation loss: 2.6385830754004487

Epoch: 6| Step: 1
Training loss: 2.819880824986486
Validation loss: 2.6349762400971533

Epoch: 6| Step: 2
Training loss: 3.395362041197979
Validation loss: 2.6356115464091467

Epoch: 6| Step: 3
Training loss: 3.125415011504972
Validation loss: 2.631275914481858

Epoch: 6| Step: 4
Training loss: 3.3373578730692057
Validation loss: 2.634436202255214

Epoch: 6| Step: 5
Training loss: 2.6287324799785057
Validation loss: 2.630434427419624

Epoch: 6| Step: 6
Training loss: 2.937546100660526
Validation loss: 2.631675628851758

Epoch: 6| Step: 7
Training loss: 3.5655501843425834
Validation loss: 2.6335685002171476

Epoch: 6| Step: 8
Training loss: 3.4737371386673934
Validation loss: 2.631078770066477

Epoch: 6| Step: 9
Training loss: 2.8169428172728166
Validation loss: 2.6373443174990827

Epoch: 6| Step: 10
Training loss: 2.661495818131075
Validation loss: 2.636754568715789

Epoch: 6| Step: 11
Training loss: 2.922720067832304
Validation loss: 2.6349555351473772

Epoch: 6| Step: 12
Training loss: 2.83570747388397
Validation loss: 2.638508279795644

Epoch: 6| Step: 13
Training loss: 1.7573665477067262
Validation loss: 2.6397513871423657

Epoch: 140| Step: 0
Training loss: 2.7393128197462717
Validation loss: 2.6415299550982083

Epoch: 6| Step: 1
Training loss: 3.0536347353180147
Validation loss: 2.6472992508760926

Epoch: 6| Step: 2
Training loss: 2.6378421904971026
Validation loss: 2.6514179083549414

Epoch: 6| Step: 3
Training loss: 2.8397503907023482
Validation loss: 2.6500060931766645

Epoch: 6| Step: 4
Training loss: 3.145594219358067
Validation loss: 2.640607311123758

Epoch: 6| Step: 5
Training loss: 2.973958475855586
Validation loss: 2.6340635568658315

Epoch: 6| Step: 6
Training loss: 3.0824269861389952
Validation loss: 2.6312886387520726

Epoch: 6| Step: 7
Training loss: 2.863606807836952
Validation loss: 2.6352658403525204

Epoch: 6| Step: 8
Training loss: 2.8320408472358936
Validation loss: 2.6381109796220343

Epoch: 6| Step: 9
Training loss: 2.944158596182879
Validation loss: 2.6423252653730978

Epoch: 6| Step: 10
Training loss: 3.328812076048524
Validation loss: 2.638634828003654

Epoch: 6| Step: 11
Training loss: 2.421049112583632
Validation loss: 2.626699392697753

Epoch: 6| Step: 12
Training loss: 3.460314141273712
Validation loss: 2.6279883351085442

Epoch: 6| Step: 13
Training loss: 3.3975819179379796
Validation loss: 2.6314622847906812

Epoch: 141| Step: 0
Training loss: 2.88853387199934
Validation loss: 2.6376001447980744

Epoch: 6| Step: 1
Training loss: 3.0092180411186793
Validation loss: 2.636635433629278

Epoch: 6| Step: 2
Training loss: 2.689500197453659
Validation loss: 2.6417694155533176

Epoch: 6| Step: 3
Training loss: 3.4097055528435716
Validation loss: 2.641228463384189

Epoch: 6| Step: 4
Training loss: 3.4281523794716944
Validation loss: 2.6380047512148335

Epoch: 6| Step: 5
Training loss: 2.8431275074181075
Validation loss: 2.6403721543132357

Epoch: 6| Step: 6
Training loss: 3.060990564919368
Validation loss: 2.633035745689523

Epoch: 6| Step: 7
Training loss: 2.852934374086912
Validation loss: 2.6391957140447335

Epoch: 6| Step: 8
Training loss: 3.2578183546859862
Validation loss: 2.631269838767269

Epoch: 6| Step: 9
Training loss: 2.947768100908448
Validation loss: 2.631787642732287

Epoch: 6| Step: 10
Training loss: 2.2900205306419674
Validation loss: 2.631050949746066

Epoch: 6| Step: 11
Training loss: 2.690684007092879
Validation loss: 2.629614573521661

Epoch: 6| Step: 12
Training loss: 2.849075528837127
Validation loss: 2.6296046430576747

Epoch: 6| Step: 13
Training loss: 3.585657578390638
Validation loss: 2.6330220571866456

Epoch: 142| Step: 0
Training loss: 3.230784611787618
Validation loss: 2.634052072319315

Epoch: 6| Step: 1
Training loss: 3.2317101746716355
Validation loss: 2.631185594752152

Epoch: 6| Step: 2
Training loss: 3.3162591584816434
Validation loss: 2.635874334503019

Epoch: 6| Step: 3
Training loss: 2.7240604845857663
Validation loss: 2.6354635625931793

Epoch: 6| Step: 4
Training loss: 2.8633793375614633
Validation loss: 2.6317775071378553

Epoch: 6| Step: 5
Training loss: 3.080405692592622
Validation loss: 2.632707100705317

Epoch: 6| Step: 6
Training loss: 2.959735878166472
Validation loss: 2.636277083911555

Epoch: 6| Step: 7
Training loss: 2.6401584371072437
Validation loss: 2.6324439866984566

Epoch: 6| Step: 8
Training loss: 2.795749032748428
Validation loss: 2.635706543721783

Epoch: 6| Step: 9
Training loss: 2.7833739325328213
Validation loss: 2.6293744614349026

Epoch: 6| Step: 10
Training loss: 2.9252668470942926
Validation loss: 2.634106090129018

Epoch: 6| Step: 11
Training loss: 3.024911289648293
Validation loss: 2.6262890335998414

Epoch: 6| Step: 12
Training loss: 2.9528215847870785
Validation loss: 2.6297308915010817

Epoch: 6| Step: 13
Training loss: 2.9488054604871494
Validation loss: 2.6274348518593262

Epoch: 143| Step: 0
Training loss: 2.320860313199351
Validation loss: 2.625854466406888

Epoch: 6| Step: 1
Training loss: 3.500606756750217
Validation loss: 2.6277217612852386

Epoch: 6| Step: 2
Training loss: 3.4117448914515434
Validation loss: 2.6261613594297804

Epoch: 6| Step: 3
Training loss: 2.8439951361334264
Validation loss: 2.6290543844863574

Epoch: 6| Step: 4
Training loss: 3.0496997748025403
Validation loss: 2.6267097030692392

Epoch: 6| Step: 5
Training loss: 2.4982039675854466
Validation loss: 2.633487702836393

Epoch: 6| Step: 6
Training loss: 2.8664989008346624
Validation loss: 2.6293916213824926

Epoch: 6| Step: 7
Training loss: 3.43040538738881
Validation loss: 2.627693296633691

Epoch: 6| Step: 8
Training loss: 3.199583449670255
Validation loss: 2.6321514930000873

Epoch: 6| Step: 9
Training loss: 3.3288304114146436
Validation loss: 2.6263806510809364

Epoch: 6| Step: 10
Training loss: 2.8823633852079107
Validation loss: 2.6286900070315085

Epoch: 6| Step: 11
Training loss: 2.9540939759716633
Validation loss: 2.6210469445187585

Epoch: 6| Step: 12
Training loss: 2.33393779372973
Validation loss: 2.6232767518476092

Epoch: 6| Step: 13
Training loss: 2.332094226798312
Validation loss: 2.6227991924850786

Epoch: 144| Step: 0
Training loss: 3.1311517818069583
Validation loss: 2.6212177050768264

Epoch: 6| Step: 1
Training loss: 2.7273497223822822
Validation loss: 2.6255549651387153

Epoch: 6| Step: 2
Training loss: 2.8974420118083453
Validation loss: 2.6302384504658884

Epoch: 6| Step: 3
Training loss: 3.1796063686958287
Validation loss: 2.6388796922933286

Epoch: 6| Step: 4
Training loss: 2.385277645496632
Validation loss: 2.6581491252663234

Epoch: 6| Step: 5
Training loss: 2.9515001782147925
Validation loss: 2.6539685135871762

Epoch: 6| Step: 6
Training loss: 3.6989939378625305
Validation loss: 2.650101330979632

Epoch: 6| Step: 7
Training loss: 3.0357616709368824
Validation loss: 2.647788288591834

Epoch: 6| Step: 8
Training loss: 3.6686641858542104
Validation loss: 2.649178795198976

Epoch: 6| Step: 9
Training loss: 2.9043590998188713
Validation loss: 2.6337967579200865

Epoch: 6| Step: 10
Training loss: 2.091838704464765
Validation loss: 2.6236935541940154

Epoch: 6| Step: 11
Training loss: 3.1163764988532723
Validation loss: 2.619583063516092

Epoch: 6| Step: 12
Training loss: 2.49308621934636
Validation loss: 2.6185991521074223

Epoch: 6| Step: 13
Training loss: 2.9065425274380816
Validation loss: 2.6170963247595815

Epoch: 145| Step: 0
Training loss: 3.705038485719691
Validation loss: 2.6154418530699592

Epoch: 6| Step: 1
Training loss: 2.907636250315357
Validation loss: 2.6177315604567304

Epoch: 6| Step: 2
Training loss: 3.0054886200746043
Validation loss: 2.619405982568273

Epoch: 6| Step: 3
Training loss: 2.7747649119005917
Validation loss: 2.6186997515153503

Epoch: 6| Step: 4
Training loss: 2.7523060579775254
Validation loss: 2.618581059898628

Epoch: 6| Step: 5
Training loss: 3.08280565712542
Validation loss: 2.619842139014983

Epoch: 6| Step: 6
Training loss: 3.1601057013204583
Validation loss: 2.6179296644544254

Epoch: 6| Step: 7
Training loss: 2.835675188023596
Validation loss: 2.617417904184921

Epoch: 6| Step: 8
Training loss: 2.758887926878983
Validation loss: 2.619053733629702

Epoch: 6| Step: 9
Training loss: 2.7296540405109373
Validation loss: 2.6187354016130233

Epoch: 6| Step: 10
Training loss: 2.8719682049492223
Validation loss: 2.615891623502534

Epoch: 6| Step: 11
Training loss: 3.0610531873197804
Validation loss: 2.6196475642043233

Epoch: 6| Step: 12
Training loss: 2.9581042098026646
Validation loss: 2.6161997528297034

Epoch: 6| Step: 13
Training loss: 2.636234221974199
Validation loss: 2.6131625810787007

Epoch: 146| Step: 0
Training loss: 2.568623645951231
Validation loss: 2.6148245039652074

Epoch: 6| Step: 1
Training loss: 3.0614176803404294
Validation loss: 2.6176711973628026

Epoch: 6| Step: 2
Training loss: 3.2290685495216365
Validation loss: 2.6203465151941296

Epoch: 6| Step: 3
Training loss: 2.754016717088502
Validation loss: 2.6219907535476827

Epoch: 6| Step: 4
Training loss: 2.621758776010837
Validation loss: 2.633907664472599

Epoch: 6| Step: 5
Training loss: 3.158625549111048
Validation loss: 2.637163282785455

Epoch: 6| Step: 6
Training loss: 2.9239324985545605
Validation loss: 2.6278841344406527

Epoch: 6| Step: 7
Training loss: 2.8918764446874095
Validation loss: 2.621671641874769

Epoch: 6| Step: 8
Training loss: 2.829913337917271
Validation loss: 2.6247725722728728

Epoch: 6| Step: 9
Training loss: 3.5803985702025956
Validation loss: 2.616841663180671

Epoch: 6| Step: 10
Training loss: 3.127289353068395
Validation loss: 2.624688833714097

Epoch: 6| Step: 11
Training loss: 2.503942242391957
Validation loss: 2.6311675900635114

Epoch: 6| Step: 12
Training loss: 2.9441647506723467
Validation loss: 2.6297903529057596

Epoch: 6| Step: 13
Training loss: 3.147768919881768
Validation loss: 2.644164093603121

Epoch: 147| Step: 0
Training loss: 3.707203353568821
Validation loss: 2.6566753059025743

Epoch: 6| Step: 1
Training loss: 3.211381199385036
Validation loss: 2.682828631815331

Epoch: 6| Step: 2
Training loss: 2.6476475260465047
Validation loss: 2.683393289727655

Epoch: 6| Step: 3
Training loss: 2.3472739620889134
Validation loss: 2.7148138172538343

Epoch: 6| Step: 4
Training loss: 2.9288849812302917
Validation loss: 2.710795714523662

Epoch: 6| Step: 5
Training loss: 2.39065322360663
Validation loss: 2.7335451812969014

Epoch: 6| Step: 6
Training loss: 2.81671961973476
Validation loss: 2.767888133124701

Epoch: 6| Step: 7
Training loss: 3.096456865554445
Validation loss: 2.7350628678205013

Epoch: 6| Step: 8
Training loss: 3.322654705823104
Validation loss: 2.7100072043904757

Epoch: 6| Step: 9
Training loss: 3.0004861755612016
Validation loss: 2.6892512301820135

Epoch: 6| Step: 10
Training loss: 3.300020281411472
Validation loss: 2.6836404781569443

Epoch: 6| Step: 11
Training loss: 2.5224297462865386
Validation loss: 2.6751843581844703

Epoch: 6| Step: 12
Training loss: 3.6723375394345275
Validation loss: 2.672489761662455

Epoch: 6| Step: 13
Training loss: 2.424744315284982
Validation loss: 2.6750482918067395

Epoch: 148| Step: 0
Training loss: 3.432640663815524
Validation loss: 2.6799771014196327

Epoch: 6| Step: 1
Training loss: 2.3892004218997323
Validation loss: 2.6719131798023183

Epoch: 6| Step: 2
Training loss: 3.181532715711498
Validation loss: 2.6710137417966062

Epoch: 6| Step: 3
Training loss: 3.0382016097695765
Validation loss: 2.659141531185291

Epoch: 6| Step: 4
Training loss: 2.3369269173408456
Validation loss: 2.6543412706819876

Epoch: 6| Step: 5
Training loss: 2.904957966065419
Validation loss: 2.6570508267265907

Epoch: 6| Step: 6
Training loss: 2.9989192923446724
Validation loss: 2.6602119561757953

Epoch: 6| Step: 7
Training loss: 3.6447908200705172
Validation loss: 2.676136903096365

Epoch: 6| Step: 8
Training loss: 2.731662822051152
Validation loss: 2.6490208948233303

Epoch: 6| Step: 9
Training loss: 3.304523581188794
Validation loss: 2.630985824374842

Epoch: 6| Step: 10
Training loss: 2.9458290679195733
Validation loss: 2.6163796777404427

Epoch: 6| Step: 11
Training loss: 3.133509836568895
Validation loss: 2.6200452042673548

Epoch: 6| Step: 12
Training loss: 2.7571706916567402
Validation loss: 2.617654892938374

Epoch: 6| Step: 13
Training loss: 2.466350403263094
Validation loss: 2.6191018100078867

Epoch: 149| Step: 0
Training loss: 2.927938605597702
Validation loss: 2.616611891634931

Epoch: 6| Step: 1
Training loss: 3.2948058084736584
Validation loss: 2.6216646286184417

Epoch: 6| Step: 2
Training loss: 2.789459029360918
Validation loss: 2.621561758850721

Epoch: 6| Step: 3
Training loss: 3.224310950663317
Validation loss: 2.6263490102326315

Epoch: 6| Step: 4
Training loss: 2.9536692607239567
Validation loss: 2.636003485269614

Epoch: 6| Step: 5
Training loss: 2.8756583745354964
Validation loss: 2.6319585626213247

Epoch: 6| Step: 6
Training loss: 3.744858204865485
Validation loss: 2.6339677274968145

Epoch: 6| Step: 7
Training loss: 2.9467643579482927
Validation loss: 2.620217191479427

Epoch: 6| Step: 8
Training loss: 2.7638908164711453
Validation loss: 2.6245896789769865

Epoch: 6| Step: 9
Training loss: 2.5198656436888958
Validation loss: 2.6182687929567603

Epoch: 6| Step: 10
Training loss: 2.959169045908115
Validation loss: 2.6249332087428736

Epoch: 6| Step: 11
Training loss: 2.9722972357326487
Validation loss: 2.614556889011532

Epoch: 6| Step: 12
Training loss: 2.3544704162527763
Validation loss: 2.617003355617604

Epoch: 6| Step: 13
Training loss: 3.000213456507209
Validation loss: 2.6195867226654332

Epoch: 150| Step: 0
Training loss: 3.6743938491112016
Validation loss: 2.6345324865330917

Epoch: 6| Step: 1
Training loss: 2.681926181423072
Validation loss: 2.644497044072259

Epoch: 6| Step: 2
Training loss: 2.949825643785638
Validation loss: 2.645252554198483

Epoch: 6| Step: 3
Training loss: 2.8249963135821843
Validation loss: 2.6406438848319334

Epoch: 6| Step: 4
Training loss: 2.5712695905192255
Validation loss: 2.6508949468532315

Epoch: 6| Step: 5
Training loss: 3.019263725717674
Validation loss: 2.652373080967591

Epoch: 6| Step: 6
Training loss: 2.7709086319484526
Validation loss: 2.6463135495137027

Epoch: 6| Step: 7
Training loss: 3.315184027625605
Validation loss: 2.6288234193784232

Epoch: 6| Step: 8
Training loss: 2.826822729241031
Validation loss: 2.627268538055111

Epoch: 6| Step: 9
Training loss: 2.942409551975662
Validation loss: 2.6184247352672334

Epoch: 6| Step: 10
Training loss: 3.1691097739970377
Validation loss: 2.6112407512906772

Epoch: 6| Step: 11
Training loss: 2.7759671562076793
Validation loss: 2.61391667775493

Epoch: 6| Step: 12
Training loss: 2.4708363855181195
Validation loss: 2.611516418547974

Epoch: 6| Step: 13
Training loss: 3.5299970716512923
Validation loss: 2.6098770858154143

Epoch: 151| Step: 0
Training loss: 3.3796879740594328
Validation loss: 2.609215054378954

Epoch: 6| Step: 1
Training loss: 2.722868595024869
Validation loss: 2.6102905799106413

Epoch: 6| Step: 2
Training loss: 3.159702339156382
Validation loss: 2.607173781870472

Epoch: 6| Step: 3
Training loss: 2.3138516574086325
Validation loss: 2.6071722970831943

Epoch: 6| Step: 4
Training loss: 3.320276596772797
Validation loss: 2.6045494425035414

Epoch: 6| Step: 5
Training loss: 2.4974270932359675
Validation loss: 2.6078891877529515

Epoch: 6| Step: 6
Training loss: 2.8322183060530643
Validation loss: 2.6062311946481316

Epoch: 6| Step: 7
Training loss: 2.47259916748882
Validation loss: 2.6040770668284745

Epoch: 6| Step: 8
Training loss: 2.88232880956616
Validation loss: 2.6043347021874874

Epoch: 6| Step: 9
Training loss: 2.865886008253763
Validation loss: 2.6060955387525735

Epoch: 6| Step: 10
Training loss: 3.3932296663148773
Validation loss: 2.614931590709072

Epoch: 6| Step: 11
Training loss: 3.217460299871624
Validation loss: 2.6125281479454445

Epoch: 6| Step: 12
Training loss: 3.432569261978737
Validation loss: 2.616127789199951

Epoch: 6| Step: 13
Training loss: 2.186867976846508
Validation loss: 2.6097287016976853

Epoch: 152| Step: 0
Training loss: 2.3727181163732083
Validation loss: 2.6126509776930313

Epoch: 6| Step: 1
Training loss: 3.1686922086904445
Validation loss: 2.616702508168196

Epoch: 6| Step: 2
Training loss: 3.2229742089830657
Validation loss: 2.619458767818751

Epoch: 6| Step: 3
Training loss: 3.11635553639562
Validation loss: 2.6163360880931488

Epoch: 6| Step: 4
Training loss: 3.0138677507431755
Validation loss: 2.6091819614655622

Epoch: 6| Step: 5
Training loss: 2.7261411674706113
Validation loss: 2.6089086785835076

Epoch: 6| Step: 6
Training loss: 2.7059664042460327
Validation loss: 2.6048969654180274

Epoch: 6| Step: 7
Training loss: 3.256599767720796
Validation loss: 2.601627483921737

Epoch: 6| Step: 8
Training loss: 2.4449660570717855
Validation loss: 2.602332256057529

Epoch: 6| Step: 9
Training loss: 3.3070378884497362
Validation loss: 2.5992378023612055

Epoch: 6| Step: 10
Training loss: 2.6062610799796326
Validation loss: 2.60057012433887

Epoch: 6| Step: 11
Training loss: 2.9173199239953833
Validation loss: 2.603586714288153

Epoch: 6| Step: 12
Training loss: 3.357558074017179
Validation loss: 2.5976608193673685

Epoch: 6| Step: 13
Training loss: 2.752072247105769
Validation loss: 2.599360927759517

Epoch: 153| Step: 0
Training loss: 2.8261213423317924
Validation loss: 2.5996180275866996

Epoch: 6| Step: 1
Training loss: 2.8770949981990706
Validation loss: 2.5957281400244514

Epoch: 6| Step: 2
Training loss: 2.6620171265771266
Validation loss: 2.594390001444759

Epoch: 6| Step: 3
Training loss: 2.876467454656874
Validation loss: 2.59829451178325

Epoch: 6| Step: 4
Training loss: 3.1964953781660186
Validation loss: 2.5962743354493525

Epoch: 6| Step: 5
Training loss: 2.881984684878973
Validation loss: 2.6007027750606406

Epoch: 6| Step: 6
Training loss: 2.7725978386198094
Validation loss: 2.6061253646504046

Epoch: 6| Step: 7
Training loss: 3.3660527062916294
Validation loss: 2.606102080411763

Epoch: 6| Step: 8
Training loss: 3.3372391388062197
Validation loss: 2.6182907822955865

Epoch: 6| Step: 9
Training loss: 2.491199357302319
Validation loss: 2.612009608819556

Epoch: 6| Step: 10
Training loss: 3.054681724289217
Validation loss: 2.6166025775699926

Epoch: 6| Step: 11
Training loss: 2.8954720763498782
Validation loss: 2.5935632307580545

Epoch: 6| Step: 12
Training loss: 2.6886844242883257
Validation loss: 2.5948900162981516

Epoch: 6| Step: 13
Training loss: 3.389297717783935
Validation loss: 2.593247312661845

Epoch: 154| Step: 0
Training loss: 3.151265353415469
Validation loss: 2.5945877756306595

Epoch: 6| Step: 1
Training loss: 2.1152621027008824
Validation loss: 2.5960243000656735

Epoch: 6| Step: 2
Training loss: 3.6708603776043067
Validation loss: 2.597805060195941

Epoch: 6| Step: 3
Training loss: 2.7577625302550635
Validation loss: 2.5983164412589335

Epoch: 6| Step: 4
Training loss: 3.2148594722618284
Validation loss: 2.5994175768182655

Epoch: 6| Step: 5
Training loss: 3.1767411511532795
Validation loss: 2.5986829121795

Epoch: 6| Step: 6
Training loss: 3.1700786145206576
Validation loss: 2.5993493845696896

Epoch: 6| Step: 7
Training loss: 2.401177546586152
Validation loss: 2.6009795232194524

Epoch: 6| Step: 8
Training loss: 2.712475167437679
Validation loss: 2.594677247010307

Epoch: 6| Step: 9
Training loss: 2.5654151895764685
Validation loss: 2.5948420278025877

Epoch: 6| Step: 10
Training loss: 2.722488376252833
Validation loss: 2.592156886744488

Epoch: 6| Step: 11
Training loss: 2.943867052994752
Validation loss: 2.5920259538126804

Epoch: 6| Step: 12
Training loss: 3.0695445723813717
Validation loss: 2.5956542576992105

Epoch: 6| Step: 13
Training loss: 3.483632098318585
Validation loss: 2.5947524415676724

Epoch: 155| Step: 0
Training loss: 2.8620023069872245
Validation loss: 2.604626693619656

Epoch: 6| Step: 1
Training loss: 3.0100133993161062
Validation loss: 2.5981310837044926

Epoch: 6| Step: 2
Training loss: 2.6295360247299873
Validation loss: 2.5988182131863646

Epoch: 6| Step: 3
Training loss: 2.6706410732093597
Validation loss: 2.591800284550935

Epoch: 6| Step: 4
Training loss: 3.257390642182231
Validation loss: 2.588856078787089

Epoch: 6| Step: 5
Training loss: 3.065348798809332
Validation loss: 2.5974233101746202

Epoch: 6| Step: 6
Training loss: 2.714370356939404
Validation loss: 2.5907864581992226

Epoch: 6| Step: 7
Training loss: 2.9340072320122186
Validation loss: 2.589667399423617

Epoch: 6| Step: 8
Training loss: 3.2940878996988503
Validation loss: 2.5922228551070794

Epoch: 6| Step: 9
Training loss: 3.2449345360781345
Validation loss: 2.5928687006745683

Epoch: 6| Step: 10
Training loss: 2.866520526029329
Validation loss: 2.585871570563234

Epoch: 6| Step: 11
Training loss: 2.6838938449498095
Validation loss: 2.588374329906096

Epoch: 6| Step: 12
Training loss: 2.8098279339656465
Validation loss: 2.588414957612973

Epoch: 6| Step: 13
Training loss: 3.2311166761625283
Validation loss: 2.586918077051665

Epoch: 156| Step: 0
Training loss: 2.710310629887234
Validation loss: 2.590032056393993

Epoch: 6| Step: 1
Training loss: 2.5856969439128976
Validation loss: 2.5919703993249663

Epoch: 6| Step: 2
Training loss: 3.2272747445191783
Validation loss: 2.5893822128513326

Epoch: 6| Step: 3
Training loss: 2.891162059483906
Validation loss: 2.5904576369269545

Epoch: 6| Step: 4
Training loss: 2.6280363777813074
Validation loss: 2.596947827805001

Epoch: 6| Step: 5
Training loss: 2.529245124199098
Validation loss: 2.5915096326652947

Epoch: 6| Step: 6
Training loss: 3.201926551476821
Validation loss: 2.604151691680839

Epoch: 6| Step: 7
Training loss: 3.109290653790825
Validation loss: 2.599258768157085

Epoch: 6| Step: 8
Training loss: 3.1011296890335895
Validation loss: 2.6054155356873236

Epoch: 6| Step: 9
Training loss: 2.788565198656288
Validation loss: 2.6004507935332817

Epoch: 6| Step: 10
Training loss: 2.425853095472644
Validation loss: 2.6017416615475835

Epoch: 6| Step: 11
Training loss: 3.093519414149951
Validation loss: 2.597373304640703

Epoch: 6| Step: 12
Training loss: 3.4520510561317925
Validation loss: 2.5946931188098765

Epoch: 6| Step: 13
Training loss: 3.4308667078279687
Validation loss: 2.5903116785715294

Epoch: 157| Step: 0
Training loss: 2.854100433100868
Validation loss: 2.585203161620247

Epoch: 6| Step: 1
Training loss: 3.183056295699433
Validation loss: 2.5871362190764966

Epoch: 6| Step: 2
Training loss: 2.879933146919403
Validation loss: 2.5863125833322242

Epoch: 6| Step: 3
Training loss: 2.478996741190773
Validation loss: 2.588243229395808

Epoch: 6| Step: 4
Training loss: 2.477185192104673
Validation loss: 2.5885493434230047

Epoch: 6| Step: 5
Training loss: 2.431609641494374
Validation loss: 2.585094650004151

Epoch: 6| Step: 6
Training loss: 3.239764013291154
Validation loss: 2.586600389915439

Epoch: 6| Step: 7
Training loss: 2.690717678268292
Validation loss: 2.5857074465319934

Epoch: 6| Step: 8
Training loss: 3.168333284263336
Validation loss: 2.594641361209141

Epoch: 6| Step: 9
Training loss: 3.141449018337629
Validation loss: 2.6003617288260665

Epoch: 6| Step: 10
Training loss: 3.4911517969204127
Validation loss: 2.612509731080893

Epoch: 6| Step: 11
Training loss: 3.3196199300676787
Validation loss: 2.6248183883448193

Epoch: 6| Step: 12
Training loss: 2.36735508895212
Validation loss: 2.621203406177407

Epoch: 6| Step: 13
Training loss: 3.352170804535951
Validation loss: 2.6145193669593008

Epoch: 158| Step: 0
Training loss: 3.181321832411709
Validation loss: 2.5996448214296306

Epoch: 6| Step: 1
Training loss: 3.2448446025581834
Validation loss: 2.5923001244608552

Epoch: 6| Step: 2
Training loss: 2.925577520756552
Validation loss: 2.588060357844266

Epoch: 6| Step: 3
Training loss: 2.7148645633476005
Validation loss: 2.5867014815538845

Epoch: 6| Step: 4
Training loss: 2.5700444136763556
Validation loss: 2.5825353363112917

Epoch: 6| Step: 5
Training loss: 2.5938470661430797
Validation loss: 2.585584085408027

Epoch: 6| Step: 6
Training loss: 2.5673513312602503
Validation loss: 2.5846753228798667

Epoch: 6| Step: 7
Training loss: 2.9743732401246863
Validation loss: 2.585092919485539

Epoch: 6| Step: 8
Training loss: 2.7028134557868078
Validation loss: 2.5852426392736754

Epoch: 6| Step: 9
Training loss: 2.919870923468501
Validation loss: 2.5869100875823023

Epoch: 6| Step: 10
Training loss: 3.1568891425789274
Validation loss: 2.5841886885308774

Epoch: 6| Step: 11
Training loss: 3.1105931641840994
Validation loss: 2.5869629670646033

Epoch: 6| Step: 12
Training loss: 3.0977296760390485
Validation loss: 2.584673807314641

Epoch: 6| Step: 13
Training loss: 3.409422630585741
Validation loss: 2.5914010418418787

Epoch: 159| Step: 0
Training loss: 2.762668386997635
Validation loss: 2.5854879703023137

Epoch: 6| Step: 1
Training loss: 3.037956448391619
Validation loss: 2.589154892304053

Epoch: 6| Step: 2
Training loss: 2.538987566502444
Validation loss: 2.5828148648735

Epoch: 6| Step: 3
Training loss: 2.837023314376517
Validation loss: 2.5810314909622702

Epoch: 6| Step: 4
Training loss: 3.067663083393105
Validation loss: 2.580772965673587

Epoch: 6| Step: 5
Training loss: 2.708063190387836
Validation loss: 2.5800803507281636

Epoch: 6| Step: 6
Training loss: 2.904301964679047
Validation loss: 2.5841488267207415

Epoch: 6| Step: 7
Training loss: 3.187321676614214
Validation loss: 2.583685379241413

Epoch: 6| Step: 8
Training loss: 2.940873826107469
Validation loss: 2.5862752313877477

Epoch: 6| Step: 9
Training loss: 2.901941859477225
Validation loss: 2.584141765200605

Epoch: 6| Step: 10
Training loss: 3.0678051521467404
Validation loss: 2.5811066480209868

Epoch: 6| Step: 11
Training loss: 3.0507735912896026
Validation loss: 2.580462898046406

Epoch: 6| Step: 12
Training loss: 2.6215027718828567
Validation loss: 2.5796550716172755

Epoch: 6| Step: 13
Training loss: 3.7348535462535732
Validation loss: 2.5809744651713604

Epoch: 160| Step: 0
Training loss: 2.6637223997077997
Validation loss: 2.5788973459650593

Epoch: 6| Step: 1
Training loss: 2.6763666779457025
Validation loss: 2.579103231434367

Epoch: 6| Step: 2
Training loss: 3.3648108217476214
Validation loss: 2.5841824306810612

Epoch: 6| Step: 3
Training loss: 3.4662308351720825
Validation loss: 2.581931016081757

Epoch: 6| Step: 4
Training loss: 3.2242704290745663
Validation loss: 2.5896720858415674

Epoch: 6| Step: 5
Training loss: 3.4410008030352532
Validation loss: 2.5897517714677223

Epoch: 6| Step: 6
Training loss: 2.8799591416533628
Validation loss: 2.5989651536976366

Epoch: 6| Step: 7
Training loss: 3.310261959992655
Validation loss: 2.5925590161825114

Epoch: 6| Step: 8
Training loss: 2.40013395571395
Validation loss: 2.5871663467812027

Epoch: 6| Step: 9
Training loss: 1.8211869525665756
Validation loss: 2.5819627286313582

Epoch: 6| Step: 10
Training loss: 2.91633840257689
Validation loss: 2.582757901288205

Epoch: 6| Step: 11
Training loss: 3.267117392008071
Validation loss: 2.5814350058993987

Epoch: 6| Step: 12
Training loss: 2.2184398595547785
Validation loss: 2.578887033316838

Epoch: 6| Step: 13
Training loss: 2.8507599001602744
Validation loss: 2.5799580003977005

Epoch: 161| Step: 0
Training loss: 3.0901168914709523
Validation loss: 2.580585407230551

Epoch: 6| Step: 1
Training loss: 3.117787238916549
Validation loss: 2.5837011369854115

Epoch: 6| Step: 2
Training loss: 2.698195797731649
Validation loss: 2.585260394600489

Epoch: 6| Step: 3
Training loss: 3.1140907604047263
Validation loss: 2.5810883128722795

Epoch: 6| Step: 4
Training loss: 3.198360118293289
Validation loss: 2.5830160234566857

Epoch: 6| Step: 5
Training loss: 3.2689080048806143
Validation loss: 2.5798141519457003

Epoch: 6| Step: 6
Training loss: 2.745014179241754
Validation loss: 2.5825204896917637

Epoch: 6| Step: 7
Training loss: 3.0705018118620204
Validation loss: 2.581864376656867

Epoch: 6| Step: 8
Training loss: 2.5206556546565038
Validation loss: 2.580701124766315

Epoch: 6| Step: 9
Training loss: 2.6839471442735965
Validation loss: 2.5916604141061272

Epoch: 6| Step: 10
Training loss: 2.4509058348217563
Validation loss: 2.5934309344952085

Epoch: 6| Step: 11
Training loss: 3.2762380924175836
Validation loss: 2.5997379764528503

Epoch: 6| Step: 12
Training loss: 2.4877417442131886
Validation loss: 2.6108089979664

Epoch: 6| Step: 13
Training loss: 3.2087669740056284
Validation loss: 2.626187436346969

Epoch: 162| Step: 0
Training loss: 2.8185327044381707
Validation loss: 2.627794025929411

Epoch: 6| Step: 1
Training loss: 2.3148123031885155
Validation loss: 2.639793478175444

Epoch: 6| Step: 2
Training loss: 3.432264884570246
Validation loss: 2.6632335146383213

Epoch: 6| Step: 3
Training loss: 3.5192608152552456
Validation loss: 2.6761746676546485

Epoch: 6| Step: 4
Training loss: 2.773495783663554
Validation loss: 2.6336922935447626

Epoch: 6| Step: 5
Training loss: 2.387664757281487
Validation loss: 2.601786948095404

Epoch: 6| Step: 6
Training loss: 3.310163141477072
Validation loss: 2.581500490530621

Epoch: 6| Step: 7
Training loss: 2.534011276617453
Validation loss: 2.579793672067516

Epoch: 6| Step: 8
Training loss: 2.7370492119844068
Validation loss: 2.583225752793205

Epoch: 6| Step: 9
Training loss: 3.0014203206215617
Validation loss: 2.583022916352547

Epoch: 6| Step: 10
Training loss: 2.7881598200587323
Validation loss: 2.5811069261262483

Epoch: 6| Step: 11
Training loss: 2.874394560380519
Validation loss: 2.58719897614431

Epoch: 6| Step: 12
Training loss: 3.3730714727497726
Validation loss: 2.5839099683731126

Epoch: 6| Step: 13
Training loss: 3.061017514517375
Validation loss: 2.5831647143739653

Epoch: 163| Step: 0
Training loss: 2.8423361145390063
Validation loss: 2.585568696086541

Epoch: 6| Step: 1
Training loss: 3.4442170146662088
Validation loss: 2.5851144343609707

Epoch: 6| Step: 2
Training loss: 2.630600540580337
Validation loss: 2.583902372418999

Epoch: 6| Step: 3
Training loss: 2.5782566846104134
Validation loss: 2.5798164424940473

Epoch: 6| Step: 4
Training loss: 1.9903659646029739
Validation loss: 2.5788165634443607

Epoch: 6| Step: 5
Training loss: 3.013482948853739
Validation loss: 2.5747550709283615

Epoch: 6| Step: 6
Training loss: 2.661088374055565
Validation loss: 2.5767263656487422

Epoch: 6| Step: 7
Training loss: 3.2699028360006
Validation loss: 2.574173283202282

Epoch: 6| Step: 8
Training loss: 3.2758273411898724
Validation loss: 2.573971387734332

Epoch: 6| Step: 9
Training loss: 2.8752112932929124
Validation loss: 2.569571877486124

Epoch: 6| Step: 10
Training loss: 3.2534355198597016
Validation loss: 2.568912432364618

Epoch: 6| Step: 11
Training loss: 3.2317966375107186
Validation loss: 2.5760024505590966

Epoch: 6| Step: 12
Training loss: 2.6123104373476442
Validation loss: 2.5718541323814605

Epoch: 6| Step: 13
Training loss: 3.2046780426614934
Validation loss: 2.573841749860821

Epoch: 164| Step: 0
Training loss: 2.4329611750592535
Validation loss: 2.5704120350282307

Epoch: 6| Step: 1
Training loss: 3.2681331949720356
Validation loss: 2.5700827735692875

Epoch: 6| Step: 2
Training loss: 2.4908688683100544
Validation loss: 2.5750068231180228

Epoch: 6| Step: 3
Training loss: 3.2283801854058325
Validation loss: 2.5744019475431914

Epoch: 6| Step: 4
Training loss: 3.3950515190339203
Validation loss: 2.5770453505914754

Epoch: 6| Step: 5
Training loss: 3.3279139492115677
Validation loss: 2.583414351046005

Epoch: 6| Step: 6
Training loss: 2.318981366811808
Validation loss: 2.580511567223879

Epoch: 6| Step: 7
Training loss: 2.8118475263126324
Validation loss: 2.589565688997368

Epoch: 6| Step: 8
Training loss: 3.158319531278891
Validation loss: 2.5840915671370985

Epoch: 6| Step: 9
Training loss: 2.8510206569965595
Validation loss: 2.583663321612007

Epoch: 6| Step: 10
Training loss: 3.456797308468626
Validation loss: 2.5769564508871547

Epoch: 6| Step: 11
Training loss: 2.377789114492294
Validation loss: 2.571612765320768

Epoch: 6| Step: 12
Training loss: 2.758343956073079
Validation loss: 2.564017886993191

Epoch: 6| Step: 13
Training loss: 2.6689261063444056
Validation loss: 2.5656678322482462

Epoch: 165| Step: 0
Training loss: 3.2216674027406733
Validation loss: 2.5685761707902643

Epoch: 6| Step: 1
Training loss: 2.5938004638174954
Validation loss: 2.56318806580337

Epoch: 6| Step: 2
Training loss: 2.6627305804060137
Validation loss: 2.566004721717754

Epoch: 6| Step: 3
Training loss: 3.5778078163523475
Validation loss: 2.5649595809638717

Epoch: 6| Step: 4
Training loss: 2.9338086248910904
Validation loss: 2.5690536630517036

Epoch: 6| Step: 5
Training loss: 2.544245479981923
Validation loss: 2.567848510417005

Epoch: 6| Step: 6
Training loss: 2.7418032645968875
Validation loss: 2.563751257363653

Epoch: 6| Step: 7
Training loss: 2.452328303526338
Validation loss: 2.5624207345071537

Epoch: 6| Step: 8
Training loss: 3.008422472646716
Validation loss: 2.5667220199054017

Epoch: 6| Step: 9
Training loss: 2.604405679542654
Validation loss: 2.5651729618031758

Epoch: 6| Step: 10
Training loss: 3.1598221610523494
Validation loss: 2.5683890781551093

Epoch: 6| Step: 11
Training loss: 2.47156894877373
Validation loss: 2.5658307722255187

Epoch: 6| Step: 12
Training loss: 3.192483633741759
Validation loss: 2.5604998918709883

Epoch: 6| Step: 13
Training loss: 3.9360176808184972
Validation loss: 2.5666662563243205

Epoch: 166| Step: 0
Training loss: 2.6302878389837416
Validation loss: 2.5629955545904854

Epoch: 6| Step: 1
Training loss: 2.754671550494675
Validation loss: 2.56319546809944

Epoch: 6| Step: 2
Training loss: 3.40240177144485
Validation loss: 2.5649029769606844

Epoch: 6| Step: 3
Training loss: 1.782720460781003
Validation loss: 2.566816784251314

Epoch: 6| Step: 4
Training loss: 3.077790372832686
Validation loss: 2.571777832698087

Epoch: 6| Step: 5
Training loss: 2.3512195831391858
Validation loss: 2.567673351932571

Epoch: 6| Step: 6
Training loss: 2.9943024255042876
Validation loss: 2.579946917912864

Epoch: 6| Step: 7
Training loss: 3.1349390284983762
Validation loss: 2.5807842919571353

Epoch: 6| Step: 8
Training loss: 3.1406102725770206
Validation loss: 2.58836994223407

Epoch: 6| Step: 9
Training loss: 3.305838165882278
Validation loss: 2.6043887989099317

Epoch: 6| Step: 10
Training loss: 2.5993246815372695
Validation loss: 2.5859712125685297

Epoch: 6| Step: 11
Training loss: 3.2310039256859238
Validation loss: 2.577158072714028

Epoch: 6| Step: 12
Training loss: 2.974636305688991
Validation loss: 2.567857659883047

Epoch: 6| Step: 13
Training loss: 3.3924156417984443
Validation loss: 2.5678771732106114

Epoch: 167| Step: 0
Training loss: 3.445854992012369
Validation loss: 2.5638709854015618

Epoch: 6| Step: 1
Training loss: 3.247929426995627
Validation loss: 2.56967182130782

Epoch: 6| Step: 2
Training loss: 2.699861353387364
Validation loss: 2.570086624888466

Epoch: 6| Step: 3
Training loss: 3.314091713869647
Validation loss: 2.5723870107418914

Epoch: 6| Step: 4
Training loss: 3.063076665653011
Validation loss: 2.570219476405817

Epoch: 6| Step: 5
Training loss: 2.599778121870977
Validation loss: 2.572078586440555

Epoch: 6| Step: 6
Training loss: 2.622969795963558
Validation loss: 2.5738276818011614

Epoch: 6| Step: 7
Training loss: 2.9163926858737272
Validation loss: 2.570102845053352

Epoch: 6| Step: 8
Training loss: 2.73607665382888
Validation loss: 2.565662699301981

Epoch: 6| Step: 9
Training loss: 3.0605964194099298
Validation loss: 2.5638627521281223

Epoch: 6| Step: 10
Training loss: 2.886267599694016
Validation loss: 2.5719423781372934

Epoch: 6| Step: 11
Training loss: 2.4795915148786016
Validation loss: 2.569496927794218

Epoch: 6| Step: 12
Training loss: 2.8853659137618624
Validation loss: 2.572472375083051

Epoch: 6| Step: 13
Training loss: 2.7422975697393848
Validation loss: 2.574041381722696

Epoch: 168| Step: 0
Training loss: 2.837498931212371
Validation loss: 2.573388104846019

Epoch: 6| Step: 1
Training loss: 2.6586981767160123
Validation loss: 2.5761598616936627

Epoch: 6| Step: 2
Training loss: 2.379989803196197
Validation loss: 2.595313242467264

Epoch: 6| Step: 3
Training loss: 3.05705243831304
Validation loss: 2.5757448527478304

Epoch: 6| Step: 4
Training loss: 2.849922272810185
Validation loss: 2.577272386417754

Epoch: 6| Step: 5
Training loss: 2.558749547976038
Validation loss: 2.5806516614570585

Epoch: 6| Step: 6
Training loss: 2.676103246764091
Validation loss: 2.573876405725643

Epoch: 6| Step: 7
Training loss: 3.2603287527563545
Validation loss: 2.5808781962774545

Epoch: 6| Step: 8
Training loss: 2.9967465242884592
Validation loss: 2.576205877567778

Epoch: 6| Step: 9
Training loss: 3.6740648597968626
Validation loss: 2.5702327024309386

Epoch: 6| Step: 10
Training loss: 2.5549540249444957
Validation loss: 2.5636382417492185

Epoch: 6| Step: 11
Training loss: 3.0211322680361477
Validation loss: 2.567754344248809

Epoch: 6| Step: 12
Training loss: 3.229182401229097
Validation loss: 2.5664047815836835

Epoch: 6| Step: 13
Training loss: 2.890211251005617
Validation loss: 2.56358141306629

Epoch: 169| Step: 0
Training loss: 3.0948422748267297
Validation loss: 2.559826437358217

Epoch: 6| Step: 1
Training loss: 2.8290836964399624
Validation loss: 2.5646804278845488

Epoch: 6| Step: 2
Training loss: 2.888950172002535
Validation loss: 2.565059749971829

Epoch: 6| Step: 3
Training loss: 3.512527118184491
Validation loss: 2.56241511782832

Epoch: 6| Step: 4
Training loss: 2.2566450327968357
Validation loss: 2.564095298432988

Epoch: 6| Step: 5
Training loss: 2.935087308868537
Validation loss: 2.563033463849187

Epoch: 6| Step: 6
Training loss: 2.47565248539129
Validation loss: 2.562762212255882

Epoch: 6| Step: 7
Training loss: 2.5746857793991835
Validation loss: 2.5622838547191082

Epoch: 6| Step: 8
Training loss: 3.095007438589102
Validation loss: 2.564403255320048

Epoch: 6| Step: 9
Training loss: 2.687615325582451
Validation loss: 2.5636042574922344

Epoch: 6| Step: 10
Training loss: 3.239600636394121
Validation loss: 2.5727376514811806

Epoch: 6| Step: 11
Training loss: 2.8136461253843525
Validation loss: 2.5759723226580977

Epoch: 6| Step: 12
Training loss: 3.250785879339485
Validation loss: 2.5958500413625742

Epoch: 6| Step: 13
Training loss: 2.909295404084979
Validation loss: 2.5913989465301253

Epoch: 170| Step: 0
Training loss: 3.033371802145472
Validation loss: 2.6001383497331445

Epoch: 6| Step: 1
Training loss: 2.7627577061651376
Validation loss: 2.6216959299702465

Epoch: 6| Step: 2
Training loss: 2.9393309710395004
Validation loss: 2.6675113752030137

Epoch: 6| Step: 3
Training loss: 3.3906230311234204
Validation loss: 2.680353702813924

Epoch: 6| Step: 4
Training loss: 2.681593592398688
Validation loss: 2.6477256469445023

Epoch: 6| Step: 5
Training loss: 3.2929348655396335
Validation loss: 2.6665220016288917

Epoch: 6| Step: 6
Training loss: 2.855818574405495
Validation loss: 2.6556652663275995

Epoch: 6| Step: 7
Training loss: 2.996763868130996
Validation loss: 2.6294265815042235

Epoch: 6| Step: 8
Training loss: 2.884878519234345
Validation loss: 2.571031753249697

Epoch: 6| Step: 9
Training loss: 2.44124296328951
Validation loss: 2.5602291639044203

Epoch: 6| Step: 10
Training loss: 3.3946454519501446
Validation loss: 2.5672100618458105

Epoch: 6| Step: 11
Training loss: 2.9991940369398944
Validation loss: 2.578824768857821

Epoch: 6| Step: 12
Training loss: 2.6501937939301237
Validation loss: 2.5817695261507954

Epoch: 6| Step: 13
Training loss: 2.4148960094295244
Validation loss: 2.583819940593766

Epoch: 171| Step: 0
Training loss: 3.2693272097417703
Validation loss: 2.5848410130367534

Epoch: 6| Step: 1
Training loss: 2.157641859993473
Validation loss: 2.584126874238612

Epoch: 6| Step: 2
Training loss: 3.0304693416271333
Validation loss: 2.583032830378862

Epoch: 6| Step: 3
Training loss: 3.194724478863492
Validation loss: 2.5883786234786332

Epoch: 6| Step: 4
Training loss: 2.904591897475676
Validation loss: 2.5851646076043333

Epoch: 6| Step: 5
Training loss: 2.908219521234841
Validation loss: 2.586382807333734

Epoch: 6| Step: 6
Training loss: 3.1590442940944627
Validation loss: 2.586543353097991

Epoch: 6| Step: 7
Training loss: 2.8309814190997593
Validation loss: 2.5877209959432292

Epoch: 6| Step: 8
Training loss: 3.252322907373012
Validation loss: 2.5897363138596097

Epoch: 6| Step: 9
Training loss: 2.4286873773736626
Validation loss: 2.5877493217217777

Epoch: 6| Step: 10
Training loss: 3.011797912586395
Validation loss: 2.5904157626118716

Epoch: 6| Step: 11
Training loss: 2.673435580834258
Validation loss: 2.5850040823266203

Epoch: 6| Step: 12
Training loss: 3.015651722527731
Validation loss: 2.585157242430732

Epoch: 6| Step: 13
Training loss: 3.523679602313227
Validation loss: 2.590101491651811

Epoch: 172| Step: 0
Training loss: 2.540689739232971
Validation loss: 2.5850240637387385

Epoch: 6| Step: 1
Training loss: 2.439608908719273
Validation loss: 2.5855795046131904

Epoch: 6| Step: 2
Training loss: 3.0878198990753942
Validation loss: 2.594254302482808

Epoch: 6| Step: 3
Training loss: 2.716675416273135
Validation loss: 2.5923488196246947

Epoch: 6| Step: 4
Training loss: 2.5609314002010373
Validation loss: 2.589963326018127

Epoch: 6| Step: 5
Training loss: 3.160932636492953
Validation loss: 2.580971922363073

Epoch: 6| Step: 6
Training loss: 2.922525914765025
Validation loss: 2.5816397664678346

Epoch: 6| Step: 7
Training loss: 2.8595410908472956
Validation loss: 2.5779698837019214

Epoch: 6| Step: 8
Training loss: 3.3907067073698416
Validation loss: 2.5711157656606947

Epoch: 6| Step: 9
Training loss: 3.1539657938668
Validation loss: 2.5748046176442045

Epoch: 6| Step: 10
Training loss: 3.1442056617640706
Validation loss: 2.5708981609229893

Epoch: 6| Step: 11
Training loss: 3.096390031243793
Validation loss: 2.570259231078727

Epoch: 6| Step: 12
Training loss: 2.734081056326732
Validation loss: 2.5737220912081717

Epoch: 6| Step: 13
Training loss: 3.0341268828885988
Validation loss: 2.575400978286652

Epoch: 173| Step: 0
Training loss: 2.9123477748661095
Validation loss: 2.5928945295692434

Epoch: 6| Step: 1
Training loss: 2.7272462178878163
Validation loss: 2.618967187855951

Epoch: 6| Step: 2
Training loss: 2.416642967195609
Validation loss: 2.6375769070869186

Epoch: 6| Step: 3
Training loss: 2.3036900317645106
Validation loss: 2.6320780944556503

Epoch: 6| Step: 4
Training loss: 3.0734434204354835
Validation loss: 2.6274144689902443

Epoch: 6| Step: 5
Training loss: 2.8268514895594814
Validation loss: 2.6185754951486655

Epoch: 6| Step: 6
Training loss: 2.869770435363179
Validation loss: 2.6091036897149085

Epoch: 6| Step: 7
Training loss: 3.227542903742041
Validation loss: 2.599261866113524

Epoch: 6| Step: 8
Training loss: 2.5854596851918696
Validation loss: 2.583963275349197

Epoch: 6| Step: 9
Training loss: 2.943736335090945
Validation loss: 2.555025241263884

Epoch: 6| Step: 10
Training loss: 2.9795360380663682
Validation loss: 2.5501110566655347

Epoch: 6| Step: 11
Training loss: 3.1125683512708613
Validation loss: 2.562181864713185

Epoch: 6| Step: 12
Training loss: 3.2943260137990094
Validation loss: 2.568354847329813

Epoch: 6| Step: 13
Training loss: 3.8741203047900212
Validation loss: 2.571368418519138

Epoch: 174| Step: 0
Training loss: 3.039480146330376
Validation loss: 2.5656343255246945

Epoch: 6| Step: 1
Training loss: 2.628224345358229
Validation loss: 2.565027186790513

Epoch: 6| Step: 2
Training loss: 3.385236686421749
Validation loss: 2.5625715648423246

Epoch: 6| Step: 3
Training loss: 2.8270986812871164
Validation loss: 2.55908332705384

Epoch: 6| Step: 4
Training loss: 2.6850958428068434
Validation loss: 2.551954092771841

Epoch: 6| Step: 5
Training loss: 2.2602845488815877
Validation loss: 2.5485719500422888

Epoch: 6| Step: 6
Training loss: 2.494965729716975
Validation loss: 2.547554582242166

Epoch: 6| Step: 7
Training loss: 3.402672665241937
Validation loss: 2.5497614166021325

Epoch: 6| Step: 8
Training loss: 2.7476755201733987
Validation loss: 2.5514745850569964

Epoch: 6| Step: 9
Training loss: 2.9939759489735764
Validation loss: 2.557923789548119

Epoch: 6| Step: 10
Training loss: 2.4291520586659647
Validation loss: 2.557643547298621

Epoch: 6| Step: 11
Training loss: 3.0373495810355764
Validation loss: 2.5588956275145915

Epoch: 6| Step: 12
Training loss: 3.1913901133695473
Validation loss: 2.5627917672124303

Epoch: 6| Step: 13
Training loss: 3.7748063094614794
Validation loss: 2.5744801401242423

Epoch: 175| Step: 0
Training loss: 1.944202152173072
Validation loss: 2.56563878205507

Epoch: 6| Step: 1
Training loss: 2.886002922865563
Validation loss: 2.566845158940283

Epoch: 6| Step: 2
Training loss: 2.6821421955028732
Validation loss: 2.5618478929218504

Epoch: 6| Step: 3
Training loss: 2.752148049397638
Validation loss: 2.5601732348688078

Epoch: 6| Step: 4
Training loss: 3.044845609462231
Validation loss: 2.568624068130596

Epoch: 6| Step: 5
Training loss: 3.3029490558461747
Validation loss: 2.5565582828426856

Epoch: 6| Step: 6
Training loss: 3.100283572855344
Validation loss: 2.5497841515855835

Epoch: 6| Step: 7
Training loss: 2.253280367633183
Validation loss: 2.549748247271253

Epoch: 6| Step: 8
Training loss: 3.4617797653341205
Validation loss: 2.553075895149632

Epoch: 6| Step: 9
Training loss: 2.1747147910248477
Validation loss: 2.5517863445913496

Epoch: 6| Step: 10
Training loss: 3.048013327772183
Validation loss: 2.550335990884959

Epoch: 6| Step: 11
Training loss: 2.859924763843656
Validation loss: 2.557521538982999

Epoch: 6| Step: 12
Training loss: 3.197763412398548
Validation loss: 2.554618815208433

Epoch: 6| Step: 13
Training loss: 3.983728333896961
Validation loss: 2.5539760044753477

Epoch: 176| Step: 0
Training loss: 2.952578862466998
Validation loss: 2.557961655708934

Epoch: 6| Step: 1
Training loss: 2.856594380458621
Validation loss: 2.5583901631269974

Epoch: 6| Step: 2
Training loss: 3.664325371200733
Validation loss: 2.561164782214306

Epoch: 6| Step: 3
Training loss: 3.002154212624967
Validation loss: 2.551234217597218

Epoch: 6| Step: 4
Training loss: 2.3356706856007565
Validation loss: 2.546880153698856

Epoch: 6| Step: 5
Training loss: 2.343548473595031
Validation loss: 2.5482971108474746

Epoch: 6| Step: 6
Training loss: 3.008073433791312
Validation loss: 2.5484643241748333

Epoch: 6| Step: 7
Training loss: 2.8994979358027004
Validation loss: 2.5475360981938353

Epoch: 6| Step: 8
Training loss: 2.530867747890437
Validation loss: 2.558719430338655

Epoch: 6| Step: 9
Training loss: 3.186075228735062
Validation loss: 2.5700723537319807

Epoch: 6| Step: 10
Training loss: 3.2257918575941176
Validation loss: 2.577852254481672

Epoch: 6| Step: 11
Training loss: 2.537633687523805
Validation loss: 2.5849115259508197

Epoch: 6| Step: 12
Training loss: 3.046907864906887
Validation loss: 2.591042582362974

Epoch: 6| Step: 13
Training loss: 2.896015810991827
Validation loss: 2.602008287073444

Epoch: 177| Step: 0
Training loss: 2.8237533080278787
Validation loss: 2.6222435033397105

Epoch: 6| Step: 1
Training loss: 3.0626574106050266
Validation loss: 2.6249983709889877

Epoch: 6| Step: 2
Training loss: 2.877985689351633
Validation loss: 2.6313264701966363

Epoch: 6| Step: 3
Training loss: 3.1187220264472226
Validation loss: 2.6227735969986083

Epoch: 6| Step: 4
Training loss: 2.4933943262986817
Validation loss: 2.6268736895330407

Epoch: 6| Step: 5
Training loss: 3.309649842748324
Validation loss: 2.6286353395712663

Epoch: 6| Step: 6
Training loss: 2.8269392868447576
Validation loss: 2.6218359806078406

Epoch: 6| Step: 7
Training loss: 3.203283985193152
Validation loss: 2.6107321674185253

Epoch: 6| Step: 8
Training loss: 2.9672783667464904
Validation loss: 2.5997929192421725

Epoch: 6| Step: 9
Training loss: 2.083092510291635
Validation loss: 2.596369197158209

Epoch: 6| Step: 10
Training loss: 3.0742631106829577
Validation loss: 2.5964880480999395

Epoch: 6| Step: 11
Training loss: 3.2178384916128824
Validation loss: 2.5827238390665306

Epoch: 6| Step: 12
Training loss: 2.6835615886332462
Validation loss: 2.5786228528304265

Epoch: 6| Step: 13
Training loss: 3.4057114201594922
Validation loss: 2.580043262294809

Epoch: 178| Step: 0
Training loss: 2.447892263304364
Validation loss: 2.5639729342140813

Epoch: 6| Step: 1
Training loss: 2.7243114896522695
Validation loss: 2.5664408119821114

Epoch: 6| Step: 2
Training loss: 3.283812911611189
Validation loss: 2.5692595211252724

Epoch: 6| Step: 3
Training loss: 3.0328352410919677
Validation loss: 2.573887706580156

Epoch: 6| Step: 4
Training loss: 2.8096325986426534
Validation loss: 2.5770447019828255

Epoch: 6| Step: 5
Training loss: 2.6418398257843148
Validation loss: 2.5897766766827024

Epoch: 6| Step: 6
Training loss: 2.88939776788513
Validation loss: 2.601304656109718

Epoch: 6| Step: 7
Training loss: 2.997548055001123
Validation loss: 2.6042297795349083

Epoch: 6| Step: 8
Training loss: 3.0353251327994832
Validation loss: 2.6177237335859775

Epoch: 6| Step: 9
Training loss: 2.5953445129441177
Validation loss: 2.6222285462047648

Epoch: 6| Step: 10
Training loss: 3.313190316299606
Validation loss: 2.6272891386781994

Epoch: 6| Step: 11
Training loss: 2.844829312586086
Validation loss: 2.6123736985753037

Epoch: 6| Step: 12
Training loss: 3.256198254428553
Validation loss: 2.578315061124552

Epoch: 6| Step: 13
Training loss: 2.715736209536935
Validation loss: 2.5671184188049083

Epoch: 179| Step: 0
Training loss: 2.481298304935578
Validation loss: 2.565922791960908

Epoch: 6| Step: 1
Training loss: 2.778618585702617
Validation loss: 2.565979684683641

Epoch: 6| Step: 2
Training loss: 2.5988340991542263
Validation loss: 2.562811430647943

Epoch: 6| Step: 3
Training loss: 2.7093970239573517
Validation loss: 2.559364513490074

Epoch: 6| Step: 4
Training loss: 3.5204008088800873
Validation loss: 2.5759736960513995

Epoch: 6| Step: 5
Training loss: 3.3282735728739476
Validation loss: 2.5821347146945164

Epoch: 6| Step: 6
Training loss: 3.083798364848374
Validation loss: 2.5691857946558856

Epoch: 6| Step: 7
Training loss: 2.7121610930768485
Validation loss: 2.565482624011396

Epoch: 6| Step: 8
Training loss: 3.1699682057227276
Validation loss: 2.5562208564573847

Epoch: 6| Step: 9
Training loss: 3.181374741902168
Validation loss: 2.5439961606396135

Epoch: 6| Step: 10
Training loss: 2.8242517577546837
Validation loss: 2.5442053450278226

Epoch: 6| Step: 11
Training loss: 2.9153837016224036
Validation loss: 2.543127500164849

Epoch: 6| Step: 12
Training loss: 2.8420292605263566
Validation loss: 2.543273702846081

Epoch: 6| Step: 13
Training loss: 2.0845875461537577
Validation loss: 2.5444986357256374

Epoch: 180| Step: 0
Training loss: 3.2476607487151608
Validation loss: 2.545485564884408

Epoch: 6| Step: 1
Training loss: 2.9516177897729743
Validation loss: 2.5460392702937766

Epoch: 6| Step: 2
Training loss: 2.30928661708992
Validation loss: 2.5457373918926507

Epoch: 6| Step: 3
Training loss: 2.765651896717727
Validation loss: 2.5443045612791275

Epoch: 6| Step: 4
Training loss: 2.6318902910667505
Validation loss: 2.5449970084961584

Epoch: 6| Step: 5
Training loss: 2.721302369033937
Validation loss: 2.5511259609168504

Epoch: 6| Step: 6
Training loss: 2.953617438377902
Validation loss: 2.550280518396654

Epoch: 6| Step: 7
Training loss: 3.658708316525131
Validation loss: 2.549620842699105

Epoch: 6| Step: 8
Training loss: 2.4068014330481353
Validation loss: 2.5487563030122318

Epoch: 6| Step: 9
Training loss: 2.9450317572806584
Validation loss: 2.5536835512792213

Epoch: 6| Step: 10
Training loss: 3.1375130945669536
Validation loss: 2.5593785979440855

Epoch: 6| Step: 11
Training loss: 2.3539544293992773
Validation loss: 2.5576505777351817

Epoch: 6| Step: 12
Training loss: 3.4220958621021276
Validation loss: 2.5552912624550346

Epoch: 6| Step: 13
Training loss: 2.7937175467225526
Validation loss: 2.5577675323369276

Epoch: 181| Step: 0
Training loss: 2.4711929981563485
Validation loss: 2.543850793610552

Epoch: 6| Step: 1
Training loss: 2.41612397600865
Validation loss: 2.5491406999776745

Epoch: 6| Step: 2
Training loss: 3.301060916406743
Validation loss: 2.546345034365195

Epoch: 6| Step: 3
Training loss: 2.4725297410370013
Validation loss: 2.541470507135089

Epoch: 6| Step: 4
Training loss: 2.934203388042469
Validation loss: 2.5436100922335796

Epoch: 6| Step: 5
Training loss: 3.0617752774708085
Validation loss: 2.545382786976401

Epoch: 6| Step: 6
Training loss: 2.4514671603762754
Validation loss: 2.5508280865070767

Epoch: 6| Step: 7
Training loss: 3.0508522093820294
Validation loss: 2.5460631662465074

Epoch: 6| Step: 8
Training loss: 2.8771626175423597
Validation loss: 2.5470731184952684

Epoch: 6| Step: 9
Training loss: 3.2487183024264366
Validation loss: 2.5469814328375686

Epoch: 6| Step: 10
Training loss: 3.140159610409193
Validation loss: 2.554328169910274

Epoch: 6| Step: 11
Training loss: 3.138271227880671
Validation loss: 2.5458518385791513

Epoch: 6| Step: 12
Training loss: 2.8953614067644904
Validation loss: 2.5448761144650045

Epoch: 6| Step: 13
Training loss: 2.941852024135337
Validation loss: 2.544726276348813

Epoch: 182| Step: 0
Training loss: 2.742266705447771
Validation loss: 2.5495645683335972

Epoch: 6| Step: 1
Training loss: 2.355440813344903
Validation loss: 2.547093515731177

Epoch: 6| Step: 2
Training loss: 2.8247658185190994
Validation loss: 2.549399683706529

Epoch: 6| Step: 3
Training loss: 2.966023689057094
Validation loss: 2.545401993691682

Epoch: 6| Step: 4
Training loss: 3.259065309406825
Validation loss: 2.545936580190521

Epoch: 6| Step: 5
Training loss: 2.93364023712751
Validation loss: 2.5534731645121362

Epoch: 6| Step: 6
Training loss: 3.1030648001894523
Validation loss: 2.5468597723694826

Epoch: 6| Step: 7
Training loss: 3.4600579584372033
Validation loss: 2.5561964687576455

Epoch: 6| Step: 8
Training loss: 2.836662935313525
Validation loss: 2.547036578595916

Epoch: 6| Step: 9
Training loss: 2.5880559904418345
Validation loss: 2.541175979165646

Epoch: 6| Step: 10
Training loss: 2.5022511837000145
Validation loss: 2.5406641812991317

Epoch: 6| Step: 11
Training loss: 2.841853924470317
Validation loss: 2.541647110300125

Epoch: 6| Step: 12
Training loss: 3.2626042608796966
Validation loss: 2.5433357046719953

Epoch: 6| Step: 13
Training loss: 2.429088162897984
Validation loss: 2.5369045692732404

Epoch: 183| Step: 0
Training loss: 3.2052036890775852
Validation loss: 2.542543418057715

Epoch: 6| Step: 1
Training loss: 2.394512929426244
Validation loss: 2.5407380321183473

Epoch: 6| Step: 2
Training loss: 2.8300413941500113
Validation loss: 2.535818953586472

Epoch: 6| Step: 3
Training loss: 3.0453794281182853
Validation loss: 2.535255087266915

Epoch: 6| Step: 4
Training loss: 2.714946673521135
Validation loss: 2.5368244696675535

Epoch: 6| Step: 5
Training loss: 2.9421123249905548
Validation loss: 2.5362026994330864

Epoch: 6| Step: 6
Training loss: 3.252240215837199
Validation loss: 2.5368803000560436

Epoch: 6| Step: 7
Training loss: 2.7989288120300615
Validation loss: 2.5358051315467542

Epoch: 6| Step: 8
Training loss: 2.660118786160109
Validation loss: 2.539791515563921

Epoch: 6| Step: 9
Training loss: 2.8564461471686813
Validation loss: 2.5457016883072168

Epoch: 6| Step: 10
Training loss: 2.9597813102766706
Validation loss: 2.547409674897958

Epoch: 6| Step: 11
Training loss: 3.2187251117818128
Validation loss: 2.547763348686833

Epoch: 6| Step: 12
Training loss: 3.04910775563422
Validation loss: 2.551988229157772

Epoch: 6| Step: 13
Training loss: 2.1616911858447736
Validation loss: 2.545224714334378

Epoch: 184| Step: 0
Training loss: 2.3666598798985845
Validation loss: 2.5426783973021285

Epoch: 6| Step: 1
Training loss: 2.7575721527924606
Validation loss: 2.5400858568746703

Epoch: 6| Step: 2
Training loss: 2.237224122840148
Validation loss: 2.5430105164429855

Epoch: 6| Step: 3
Training loss: 3.5773551812440205
Validation loss: 2.5397763847599313

Epoch: 6| Step: 4
Training loss: 3.066106268915465
Validation loss: 2.5361665280455603

Epoch: 6| Step: 5
Training loss: 3.155246083959506
Validation loss: 2.539654300402105

Epoch: 6| Step: 6
Training loss: 3.163135534064317
Validation loss: 2.5416194498513502

Epoch: 6| Step: 7
Training loss: 3.112318782816372
Validation loss: 2.5496712699750135

Epoch: 6| Step: 8
Training loss: 2.8430176515034606
Validation loss: 2.5501206000126575

Epoch: 6| Step: 9
Training loss: 2.6916301838987837
Validation loss: 2.5523197807053517

Epoch: 6| Step: 10
Training loss: 3.2493416045935035
Validation loss: 2.549012049101079

Epoch: 6| Step: 11
Training loss: 2.518148731944531
Validation loss: 2.536885137547202

Epoch: 6| Step: 12
Training loss: 3.074725292309696
Validation loss: 2.5356693658344995

Epoch: 6| Step: 13
Training loss: 2.3614210137333753
Validation loss: 2.531600545038483

Epoch: 185| Step: 0
Training loss: 2.6706565175516697
Validation loss: 2.539698747883266

Epoch: 6| Step: 1
Training loss: 2.781572130386075
Validation loss: 2.5667602596576886

Epoch: 6| Step: 2
Training loss: 3.02078438203985
Validation loss: 2.5925717336948764

Epoch: 6| Step: 3
Training loss: 2.852753690894229
Validation loss: 2.659004234107801

Epoch: 6| Step: 4
Training loss: 3.2591804541427307
Validation loss: 2.7330080821270477

Epoch: 6| Step: 5
Training loss: 3.0573676563980916
Validation loss: 2.707514858967682

Epoch: 6| Step: 6
Training loss: 2.9066793473285
Validation loss: 2.6722220422315477

Epoch: 6| Step: 7
Training loss: 3.1538687306181123
Validation loss: 2.600917864523926

Epoch: 6| Step: 8
Training loss: 2.434240852156202
Validation loss: 2.5704176571721753

Epoch: 6| Step: 9
Training loss: 3.04730534571039
Validation loss: 2.5553379390484103

Epoch: 6| Step: 10
Training loss: 3.0053594717611394
Validation loss: 2.546091443975335

Epoch: 6| Step: 11
Training loss: 2.9645719340773864
Validation loss: 2.5367823456967775

Epoch: 6| Step: 12
Training loss: 2.5274027090845532
Validation loss: 2.5318527010549814

Epoch: 6| Step: 13
Training loss: 3.2372627082968255
Validation loss: 2.5303682001366172

Epoch: 186| Step: 0
Training loss: 3.3043749505900375
Validation loss: 2.528428868826413

Epoch: 6| Step: 1
Training loss: 2.238649774008642
Validation loss: 2.530505740527117

Epoch: 6| Step: 2
Training loss: 2.6277583933628983
Validation loss: 2.535644876520485

Epoch: 6| Step: 3
Training loss: 2.939612095991977
Validation loss: 2.529466385236407

Epoch: 6| Step: 4
Training loss: 2.655805662801195
Validation loss: 2.5329918104017284

Epoch: 6| Step: 5
Training loss: 3.4352689959216907
Validation loss: 2.5313247017400333

Epoch: 6| Step: 6
Training loss: 2.878998008311286
Validation loss: 2.5341177732436293

Epoch: 6| Step: 7
Training loss: 3.0057692684675037
Validation loss: 2.538695977878395

Epoch: 6| Step: 8
Training loss: 2.744375198492826
Validation loss: 2.5414236051015795

Epoch: 6| Step: 9
Training loss: 2.7350844852432723
Validation loss: 2.548051926682703

Epoch: 6| Step: 10
Training loss: 2.4938911187725257
Validation loss: 2.5485630255700795

Epoch: 6| Step: 11
Training loss: 3.2290531917856136
Validation loss: 2.5510455270086796

Epoch: 6| Step: 12
Training loss: 3.2495646551966346
Validation loss: 2.553564654732394

Epoch: 6| Step: 13
Training loss: 2.6900397431795042
Validation loss: 2.558693222896478

Epoch: 187| Step: 0
Training loss: 3.250072331724017
Validation loss: 2.5523040059968274

Epoch: 6| Step: 1
Training loss: 2.7178746710731776
Validation loss: 2.5463717142220164

Epoch: 6| Step: 2
Training loss: 3.001154359614709
Validation loss: 2.541538729205535

Epoch: 6| Step: 3
Training loss: 2.572505305426551
Validation loss: 2.531687295771551

Epoch: 6| Step: 4
Training loss: 3.484766369381156
Validation loss: 2.531941641329628

Epoch: 6| Step: 5
Training loss: 2.673802177130533
Validation loss: 2.527052342593985

Epoch: 6| Step: 6
Training loss: 2.742680084241439
Validation loss: 2.5254702842943506

Epoch: 6| Step: 7
Training loss: 2.837672519900807
Validation loss: 2.5269772162902036

Epoch: 6| Step: 8
Training loss: 3.063393287390233
Validation loss: 2.528068486623757

Epoch: 6| Step: 9
Training loss: 2.463110941895424
Validation loss: 2.5298462452646597

Epoch: 6| Step: 10
Training loss: 2.4490138307354545
Validation loss: 2.5288491367853645

Epoch: 6| Step: 11
Training loss: 3.1553760489447065
Validation loss: 2.5286761827699427

Epoch: 6| Step: 12
Training loss: 2.7715574097637696
Validation loss: 2.530496740182426

Epoch: 6| Step: 13
Training loss: 3.222078250723309
Validation loss: 2.524135616848208

Epoch: 188| Step: 0
Training loss: 3.02944121518027
Validation loss: 2.536558145027849

Epoch: 6| Step: 1
Training loss: 2.907912732364128
Validation loss: 2.5299675925148803

Epoch: 6| Step: 2
Training loss: 3.0208151630425153
Validation loss: 2.5319831725195456

Epoch: 6| Step: 3
Training loss: 3.1726382986094888
Validation loss: 2.5396871162286394

Epoch: 6| Step: 4
Training loss: 2.6697401474650246
Validation loss: 2.537559835263041

Epoch: 6| Step: 5
Training loss: 3.073675202106897
Validation loss: 2.538012341832594

Epoch: 6| Step: 6
Training loss: 2.68560555688728
Validation loss: 2.5346812806583197

Epoch: 6| Step: 7
Training loss: 2.792376262003141
Validation loss: 2.5319664570518383

Epoch: 6| Step: 8
Training loss: 3.178927093985024
Validation loss: 2.533216488628429

Epoch: 6| Step: 9
Training loss: 2.296875415205107
Validation loss: 2.5416733069075077

Epoch: 6| Step: 10
Training loss: 2.9114730006595178
Validation loss: 2.534356557965778

Epoch: 6| Step: 11
Training loss: 2.897049316955624
Validation loss: 2.5277361081133387

Epoch: 6| Step: 12
Training loss: 3.000404966360075
Validation loss: 2.5315014526782744

Epoch: 6| Step: 13
Training loss: 2.5860946930189903
Validation loss: 2.527384806969605

Epoch: 189| Step: 0
Training loss: 3.191777071192846
Validation loss: 2.525316414693893

Epoch: 6| Step: 1
Training loss: 2.550720214113507
Validation loss: 2.5286758664558437

Epoch: 6| Step: 2
Training loss: 2.9912815565141635
Validation loss: 2.528298439047202

Epoch: 6| Step: 3
Training loss: 3.260377893836866
Validation loss: 2.5275783599514305

Epoch: 6| Step: 4
Training loss: 3.006680203623723
Validation loss: 2.5306696781692177

Epoch: 6| Step: 5
Training loss: 2.6723655562667323
Validation loss: 2.5317142455330175

Epoch: 6| Step: 6
Training loss: 3.0948673889147917
Validation loss: 2.527789832982706

Epoch: 6| Step: 7
Training loss: 2.125635949510135
Validation loss: 2.524354250613415

Epoch: 6| Step: 8
Training loss: 2.012225100300303
Validation loss: 2.532980189444574

Epoch: 6| Step: 9
Training loss: 3.5911534756290298
Validation loss: 2.5345541483966967

Epoch: 6| Step: 10
Training loss: 2.7338544949626864
Validation loss: 2.5332386525643544

Epoch: 6| Step: 11
Training loss: 3.355078073835356
Validation loss: 2.5315538307834013

Epoch: 6| Step: 12
Training loss: 2.65353119776938
Validation loss: 2.529766002736849

Epoch: 6| Step: 13
Training loss: 2.661066512935573
Validation loss: 2.5308209573052656

Epoch: 190| Step: 0
Training loss: 2.8869291856020065
Validation loss: 2.5253265288722013

Epoch: 6| Step: 1
Training loss: 2.550716942623528
Validation loss: 2.5246584116711204

Epoch: 6| Step: 2
Training loss: 2.541209466388591
Validation loss: 2.5264816998680386

Epoch: 6| Step: 3
Training loss: 2.9059136308829565
Validation loss: 2.524099100886918

Epoch: 6| Step: 4
Training loss: 3.228113720588883
Validation loss: 2.520011400388084

Epoch: 6| Step: 5
Training loss: 3.010439510764771
Validation loss: 2.5224290165559107

Epoch: 6| Step: 6
Training loss: 3.174781857903922
Validation loss: 2.5244658899948362

Epoch: 6| Step: 7
Training loss: 2.8244093623543285
Validation loss: 2.5254345154786577

Epoch: 6| Step: 8
Training loss: 2.1753267810047516
Validation loss: 2.519735471654545

Epoch: 6| Step: 9
Training loss: 2.967007898858243
Validation loss: 2.520033115860171

Epoch: 6| Step: 10
Training loss: 2.9140690453177163
Validation loss: 2.524666107683647

Epoch: 6| Step: 11
Training loss: 3.1791754832880867
Validation loss: 2.5191016595769518

Epoch: 6| Step: 12
Training loss: 3.0721372661222306
Validation loss: 2.5260250319776905

Epoch: 6| Step: 13
Training loss: 2.722615968250258
Validation loss: 2.517635706963942

Epoch: 191| Step: 0
Training loss: 3.3385332715449163
Validation loss: 2.526339433831863

Epoch: 6| Step: 1
Training loss: 2.802386942207043
Validation loss: 2.525930219060209

Epoch: 6| Step: 2
Training loss: 2.785410137829848
Validation loss: 2.5244417296896953

Epoch: 6| Step: 3
Training loss: 2.860758295702072
Validation loss: 2.5447165646784007

Epoch: 6| Step: 4
Training loss: 2.9672788488419264
Validation loss: 2.5382585321355355

Epoch: 6| Step: 5
Training loss: 2.378728950796244
Validation loss: 2.554641775907616

Epoch: 6| Step: 6
Training loss: 2.9774338455602165
Validation loss: 2.546783548295176

Epoch: 6| Step: 7
Training loss: 3.3380307636340447
Validation loss: 2.5453471922290585

Epoch: 6| Step: 8
Training loss: 2.3826642099733215
Validation loss: 2.560290643979602

Epoch: 6| Step: 9
Training loss: 2.2877090150156842
Validation loss: 2.5378212251467547

Epoch: 6| Step: 10
Training loss: 2.6440932391487277
Validation loss: 2.535698523804316

Epoch: 6| Step: 11
Training loss: 3.0450690761805284
Validation loss: 2.525242366670279

Epoch: 6| Step: 12
Training loss: 3.438384895868796
Validation loss: 2.5271964106865004

Epoch: 6| Step: 13
Training loss: 3.0007839767972024
Validation loss: 2.53352618020472

Epoch: 192| Step: 0
Training loss: 3.606793558023891
Validation loss: 2.532008725942085

Epoch: 6| Step: 1
Training loss: 2.673127711689153
Validation loss: 2.536304904265816

Epoch: 6| Step: 2
Training loss: 2.509657421822438
Validation loss: 2.528934043661522

Epoch: 6| Step: 3
Training loss: 2.914093590128218
Validation loss: 2.533014690839735

Epoch: 6| Step: 4
Training loss: 3.1144358792480005
Validation loss: 2.5329309252852603

Epoch: 6| Step: 5
Training loss: 2.718730531820114
Validation loss: 2.5347310888165575

Epoch: 6| Step: 6
Training loss: 2.3208623677691342
Validation loss: 2.5311056663354052

Epoch: 6| Step: 7
Training loss: 3.1850609516916957
Validation loss: 2.5340057669331797

Epoch: 6| Step: 8
Training loss: 2.882114894580708
Validation loss: 2.532604722466274

Epoch: 6| Step: 9
Training loss: 2.879899866694587
Validation loss: 2.5285713285617155

Epoch: 6| Step: 10
Training loss: 2.249692048085307
Validation loss: 2.532785345256616

Epoch: 6| Step: 11
Training loss: 2.602283732931224
Validation loss: 2.52915687162471

Epoch: 6| Step: 12
Training loss: 2.9372673754196414
Validation loss: 2.5304277209416624

Epoch: 6| Step: 13
Training loss: 4.019667672232424
Validation loss: 2.5330182078525088

Epoch: 193| Step: 0
Training loss: 2.780562069284298
Validation loss: 2.5290914487813003

Epoch: 6| Step: 1
Training loss: 3.067616140192468
Validation loss: 2.538125009678731

Epoch: 6| Step: 2
Training loss: 2.259345250441676
Validation loss: 2.5362678286659337

Epoch: 6| Step: 3
Training loss: 2.521358992150337
Validation loss: 2.5476123158526565

Epoch: 6| Step: 4
Training loss: 2.594324438989613
Validation loss: 2.540539129480795

Epoch: 6| Step: 5
Training loss: 2.409835126310208
Validation loss: 2.5527748930520295

Epoch: 6| Step: 6
Training loss: 3.2689319275507174
Validation loss: 2.5509006903380094

Epoch: 6| Step: 7
Training loss: 3.398259581370006
Validation loss: 2.562899953752217

Epoch: 6| Step: 8
Training loss: 3.420507009524973
Validation loss: 2.5570958034541205

Epoch: 6| Step: 9
Training loss: 2.9371912367856123
Validation loss: 2.542213746865458

Epoch: 6| Step: 10
Training loss: 3.3148070165004517
Validation loss: 2.5492415403469075

Epoch: 6| Step: 11
Training loss: 2.6187508084607756
Validation loss: 2.5365915598062894

Epoch: 6| Step: 12
Training loss: 2.3399356575621395
Validation loss: 2.5374301597496656

Epoch: 6| Step: 13
Training loss: 3.215668916541401
Validation loss: 2.535432935295099

Epoch: 194| Step: 0
Training loss: 2.885648825953795
Validation loss: 2.530583121503567

Epoch: 6| Step: 1
Training loss: 3.3643507901702
Validation loss: 2.525244620426095

Epoch: 6| Step: 2
Training loss: 2.7892255121031257
Validation loss: 2.528193502247078

Epoch: 6| Step: 3
Training loss: 2.296426327019277
Validation loss: 2.52238768479704

Epoch: 6| Step: 4
Training loss: 2.784265576405612
Validation loss: 2.524990792238903

Epoch: 6| Step: 5
Training loss: 2.193201536646069
Validation loss: 2.5257170607003285

Epoch: 6| Step: 6
Training loss: 3.2976502867398256
Validation loss: 2.5276889238498863

Epoch: 6| Step: 7
Training loss: 2.9025878803574994
Validation loss: 2.5216318518533165

Epoch: 6| Step: 8
Training loss: 3.230143409592398
Validation loss: 2.529404256282301

Epoch: 6| Step: 9
Training loss: 3.268366488830477
Validation loss: 2.5276871509871897

Epoch: 6| Step: 10
Training loss: 2.7713508600679937
Validation loss: 2.5180627090211343

Epoch: 6| Step: 11
Training loss: 2.726870106831055
Validation loss: 2.5220800225738293

Epoch: 6| Step: 12
Training loss: 2.6128317955353064
Validation loss: 2.5210570077929244

Epoch: 6| Step: 13
Training loss: 3.0022250507127133
Validation loss: 2.519931324366303

Epoch: 195| Step: 0
Training loss: 2.129627014778977
Validation loss: 2.5203691848652228

Epoch: 6| Step: 1
Training loss: 3.2932652965524296
Validation loss: 2.5220507112235624

Epoch: 6| Step: 2
Training loss: 2.3396962012639557
Validation loss: 2.5240271328432917

Epoch: 6| Step: 3
Training loss: 3.3562857684568366
Validation loss: 2.5165718501494467

Epoch: 6| Step: 4
Training loss: 2.799975674387305
Validation loss: 2.5245642491243445

Epoch: 6| Step: 5
Training loss: 1.5961580223403615
Validation loss: 2.5190037568104344

Epoch: 6| Step: 6
Training loss: 3.2037412469322364
Validation loss: 2.527788996281867

Epoch: 6| Step: 7
Training loss: 3.4614261600829423
Validation loss: 2.531292052978663

Epoch: 6| Step: 8
Training loss: 2.7222963201943773
Validation loss: 2.5429328331331758

Epoch: 6| Step: 9
Training loss: 3.242985418098125
Validation loss: 2.5580562485058755

Epoch: 6| Step: 10
Training loss: 3.1334827495688726
Validation loss: 2.566712585228112

Epoch: 6| Step: 11
Training loss: 2.460435410400452
Validation loss: 2.5649310709732034

Epoch: 6| Step: 12
Training loss: 2.74487060394762
Validation loss: 2.5972408451356372

Epoch: 6| Step: 13
Training loss: 3.3473193645670802
Validation loss: 2.6096481240233196

Epoch: 196| Step: 0
Training loss: 3.0954378706350925
Validation loss: 2.6329152135372085

Epoch: 6| Step: 1
Training loss: 2.66954527893935
Validation loss: 2.660991772213151

Epoch: 6| Step: 2
Training loss: 2.729513151194092
Validation loss: 2.6553537380414944

Epoch: 6| Step: 3
Training loss: 3.097650862276604
Validation loss: 2.6244038746324008

Epoch: 6| Step: 4
Training loss: 2.4398291781305166
Validation loss: 2.571172522539234

Epoch: 6| Step: 5
Training loss: 3.027863488651396
Validation loss: 2.5472736289519866

Epoch: 6| Step: 6
Training loss: 3.4182285057546564
Validation loss: 2.5266649595936634

Epoch: 6| Step: 7
Training loss: 2.3970121938739832
Validation loss: 2.5216301926646882

Epoch: 6| Step: 8
Training loss: 2.7397636286559033
Validation loss: 2.5200542777362793

Epoch: 6| Step: 9
Training loss: 2.7600996783127982
Validation loss: 2.515185338674823

Epoch: 6| Step: 10
Training loss: 3.0449909351633626
Validation loss: 2.5174033548395975

Epoch: 6| Step: 11
Training loss: 2.427960435158453
Validation loss: 2.5174127849008454

Epoch: 6| Step: 12
Training loss: 3.208039472589206
Validation loss: 2.512502102704822

Epoch: 6| Step: 13
Training loss: 3.2678199218012
Validation loss: 2.5170906692391655

Epoch: 197| Step: 0
Training loss: 2.9908224233997154
Validation loss: 2.520335751325623

Epoch: 6| Step: 1
Training loss: 3.4698020095846642
Validation loss: 2.520115472422202

Epoch: 6| Step: 2
Training loss: 2.53817404828543
Validation loss: 2.5208232421456063

Epoch: 6| Step: 3
Training loss: 2.993251203105509
Validation loss: 2.529398019991587

Epoch: 6| Step: 4
Training loss: 2.9242953307519266
Validation loss: 2.530018133869948

Epoch: 6| Step: 5
Training loss: 3.016057907418775
Validation loss: 2.5385672576775216

Epoch: 6| Step: 6
Training loss: 2.7683872717238596
Validation loss: 2.5355350589258383

Epoch: 6| Step: 7
Training loss: 2.708372986332064
Validation loss: 2.5349936188612667

Epoch: 6| Step: 8
Training loss: 2.9657645221847613
Validation loss: 2.534965899970843

Epoch: 6| Step: 9
Training loss: 2.326116732593165
Validation loss: 2.5333768537547114

Epoch: 6| Step: 10
Training loss: 3.1128244866664163
Validation loss: 2.529735165078372

Epoch: 6| Step: 11
Training loss: 2.8970140936090276
Validation loss: 2.531131892029561

Epoch: 6| Step: 12
Training loss: 2.877594979157892
Validation loss: 2.522485172674473

Epoch: 6| Step: 13
Training loss: 2.3391903074687326
Validation loss: 2.526877486077686

Epoch: 198| Step: 0
Training loss: 2.893009995823986
Validation loss: 2.514019525599739

Epoch: 6| Step: 1
Training loss: 3.499465220331259
Validation loss: 2.514082490558609

Epoch: 6| Step: 2
Training loss: 2.826665427894441
Validation loss: 2.5133219139070575

Epoch: 6| Step: 3
Training loss: 2.1267181631009953
Validation loss: 2.512385924595423

Epoch: 6| Step: 4
Training loss: 2.390235420347765
Validation loss: 2.5096595894661298

Epoch: 6| Step: 5
Training loss: 2.3863844816940576
Validation loss: 2.512898120735142

Epoch: 6| Step: 6
Training loss: 2.850332669033163
Validation loss: 2.5190901404250394

Epoch: 6| Step: 7
Training loss: 3.002701337862601
Validation loss: 2.515541131821446

Epoch: 6| Step: 8
Training loss: 3.18282843442064
Validation loss: 2.5171612987396044

Epoch: 6| Step: 9
Training loss: 2.3396075452693657
Validation loss: 2.5201304049004203

Epoch: 6| Step: 10
Training loss: 3.408579178752089
Validation loss: 2.5222787830867204

Epoch: 6| Step: 11
Training loss: 3.0585023907771673
Validation loss: 2.521892275018324

Epoch: 6| Step: 12
Training loss: 3.114490996728225
Validation loss: 2.5274635280598905

Epoch: 6| Step: 13
Training loss: 2.8077103415252718
Validation loss: 2.5252466498198136

Epoch: 199| Step: 0
Training loss: 2.544759046918305
Validation loss: 2.5244435068626365

Epoch: 6| Step: 1
Training loss: 2.6473082889239072
Validation loss: 2.5312872321437734

Epoch: 6| Step: 2
Training loss: 3.150862675566925
Validation loss: 2.535293811745756

Epoch: 6| Step: 3
Training loss: 2.6998383049761254
Validation loss: 2.5309059064146915

Epoch: 6| Step: 4
Training loss: 2.9002434792745775
Validation loss: 2.535097059658014

Epoch: 6| Step: 5
Training loss: 2.915095005744597
Validation loss: 2.55296905865123

Epoch: 6| Step: 6
Training loss: 2.525846577350258
Validation loss: 2.554587781809604

Epoch: 6| Step: 7
Training loss: 3.1146721120235883
Validation loss: 2.5437410914251557

Epoch: 6| Step: 8
Training loss: 2.9031371807257584
Validation loss: 2.542868693240958

Epoch: 6| Step: 9
Training loss: 2.599834062709674
Validation loss: 2.529020645616892

Epoch: 6| Step: 10
Training loss: 3.165359494973971
Validation loss: 2.52194628397415

Epoch: 6| Step: 11
Training loss: 2.6162234224517795
Validation loss: 2.516418262661903

Epoch: 6| Step: 12
Training loss: 3.0947975928165206
Validation loss: 2.516078746273177

Epoch: 6| Step: 13
Training loss: 3.5362095396519133
Validation loss: 2.522256163034346

Epoch: 200| Step: 0
Training loss: 2.9011149006245818
Validation loss: 2.5187868082262925

Epoch: 6| Step: 1
Training loss: 3.0749751206298686
Validation loss: 2.5156992893234227

Epoch: 6| Step: 2
Training loss: 2.972104075174184
Validation loss: 2.5219755548607576

Epoch: 6| Step: 3
Training loss: 2.70229137112932
Validation loss: 2.5196890359718886

Epoch: 6| Step: 4
Training loss: 2.87032036777637
Validation loss: 2.52164130880099

Epoch: 6| Step: 5
Training loss: 3.0414640454950415
Validation loss: 2.519956013184435

Epoch: 6| Step: 6
Training loss: 2.996413789488921
Validation loss: 2.5201512526445558

Epoch: 6| Step: 7
Training loss: 2.9432495339698717
Validation loss: 2.516643189965415

Epoch: 6| Step: 8
Training loss: 3.1480061351517605
Validation loss: 2.513880192929273

Epoch: 6| Step: 9
Training loss: 2.83582652481731
Validation loss: 2.50941334767418

Epoch: 6| Step: 10
Training loss: 2.5369372114892914
Validation loss: 2.510768997561627

Epoch: 6| Step: 11
Training loss: 2.740655280786518
Validation loss: 2.506331909795337

Epoch: 6| Step: 12
Training loss: 2.751706894092038
Validation loss: 2.5130080716519307

Epoch: 6| Step: 13
Training loss: 2.5904054334704862
Validation loss: 2.504739434308331

Epoch: 201| Step: 0
Training loss: 3.0770926511326864
Validation loss: 2.5094793836464753

Epoch: 6| Step: 1
Training loss: 2.1689034311509694
Validation loss: 2.513128789518731

Epoch: 6| Step: 2
Training loss: 3.19889738637009
Validation loss: 2.5173226571225364

Epoch: 6| Step: 3
Training loss: 2.9544077514356686
Validation loss: 2.526135668936435

Epoch: 6| Step: 4
Training loss: 2.607537267753266
Validation loss: 2.5349971826821704

Epoch: 6| Step: 5
Training loss: 3.009620341186492
Validation loss: 2.5483741950415553

Epoch: 6| Step: 6
Training loss: 2.5473576187910276
Validation loss: 2.542934144727239

Epoch: 6| Step: 7
Training loss: 2.968714342405102
Validation loss: 2.531188619748803

Epoch: 6| Step: 8
Training loss: 3.2991982902237527
Validation loss: 2.5326178999616307

Epoch: 6| Step: 9
Training loss: 2.577517813649674
Validation loss: 2.5329655300806486

Epoch: 6| Step: 10
Training loss: 3.152202465951789
Validation loss: 2.5216019171573145

Epoch: 6| Step: 11
Training loss: 2.8233238480223566
Validation loss: 2.5202904369775303

Epoch: 6| Step: 12
Training loss: 2.8201074076549726
Validation loss: 2.505793288644219

Epoch: 6| Step: 13
Training loss: 2.9207382846954206
Validation loss: 2.5120607819190424

Epoch: 202| Step: 0
Training loss: 2.7449453891123197
Validation loss: 2.509808528254613

Epoch: 6| Step: 1
Training loss: 3.2325212999248394
Validation loss: 2.513645755768435

Epoch: 6| Step: 2
Training loss: 2.8286226793630553
Validation loss: 2.512376063422631

Epoch: 6| Step: 3
Training loss: 2.7394168256821234
Validation loss: 2.5179669395863993

Epoch: 6| Step: 4
Training loss: 3.084656422925827
Validation loss: 2.51128873475762

Epoch: 6| Step: 5
Training loss: 3.158477601419233
Validation loss: 2.517179059178527

Epoch: 6| Step: 6
Training loss: 2.6390332723459227
Validation loss: 2.5138041436800873

Epoch: 6| Step: 7
Training loss: 3.297533737831386
Validation loss: 2.5104492012468373

Epoch: 6| Step: 8
Training loss: 2.331414478216664
Validation loss: 2.5143956277391086

Epoch: 6| Step: 9
Training loss: 2.611187699279142
Validation loss: 2.5130245979982657

Epoch: 6| Step: 10
Training loss: 2.393741745100404
Validation loss: 2.5125103624538627

Epoch: 6| Step: 11
Training loss: 2.5793201797312975
Validation loss: 2.511626373415722

Epoch: 6| Step: 12
Training loss: 2.971905125927584
Validation loss: 2.5139693713372853

Epoch: 6| Step: 13
Training loss: 3.6440569373748253
Validation loss: 2.513009923220213

Epoch: 203| Step: 0
Training loss: 2.8571730509933686
Validation loss: 2.5145802484735658

Epoch: 6| Step: 1
Training loss: 2.5824376881440863
Validation loss: 2.5285974325177274

Epoch: 6| Step: 2
Training loss: 2.605550738964857
Validation loss: 2.5422486241321383

Epoch: 6| Step: 3
Training loss: 3.361181438820709
Validation loss: 2.5348038644566384

Epoch: 6| Step: 4
Training loss: 3.2327230906671574
Validation loss: 2.5438824709457837

Epoch: 6| Step: 5
Training loss: 2.3783709044274612
Validation loss: 2.558726855581516

Epoch: 6| Step: 6
Training loss: 2.9906403448494454
Validation loss: 2.5519127690616443

Epoch: 6| Step: 7
Training loss: 2.7150201753881853
Validation loss: 2.5318246683088894

Epoch: 6| Step: 8
Training loss: 3.368134615430133
Validation loss: 2.526050788770738

Epoch: 6| Step: 9
Training loss: 2.791246600834459
Validation loss: 2.5187144848254475

Epoch: 6| Step: 10
Training loss: 2.8879996259694374
Validation loss: 2.518792132372801

Epoch: 6| Step: 11
Training loss: 2.6710358132803864
Validation loss: 2.5188184150286386

Epoch: 6| Step: 12
Training loss: 2.8314492936549405
Validation loss: 2.518408808826827

Epoch: 6| Step: 13
Training loss: 2.6054703056182107
Validation loss: 2.514169118717704

Epoch: 204| Step: 0
Training loss: 3.123882246389361
Validation loss: 2.512512213368577

Epoch: 6| Step: 1
Training loss: 2.625794063537986
Validation loss: 2.5208461923524665

Epoch: 6| Step: 2
Training loss: 2.583448058831581
Validation loss: 2.5132922199060648

Epoch: 6| Step: 3
Training loss: 3.409767504510308
Validation loss: 2.5143649828987966

Epoch: 6| Step: 4
Training loss: 2.9376077835112864
Validation loss: 2.5134774785853486

Epoch: 6| Step: 5
Training loss: 2.7208489394701822
Validation loss: 2.5167908567859723

Epoch: 6| Step: 6
Training loss: 2.8375747200290684
Validation loss: 2.510797065266621

Epoch: 6| Step: 7
Training loss: 2.7492863856259113
Validation loss: 2.5135716734811093

Epoch: 6| Step: 8
Training loss: 2.2839104802414196
Validation loss: 2.509287686553497

Epoch: 6| Step: 9
Training loss: 2.484696661320914
Validation loss: 2.524482830809824

Epoch: 6| Step: 10
Training loss: 2.6891245700160424
Validation loss: 2.5256964385569227

Epoch: 6| Step: 11
Training loss: 3.3692173338187734
Validation loss: 2.5433882946637207

Epoch: 6| Step: 12
Training loss: 2.8354999635575666
Validation loss: 2.5483629731910478

Epoch: 6| Step: 13
Training loss: 3.5092198324845136
Validation loss: 2.548949810199406

Epoch: 205| Step: 0
Training loss: 2.5575554757613137
Validation loss: 2.556734371259748

Epoch: 6| Step: 1
Training loss: 2.4194755234919936
Validation loss: 2.562523608395332

Epoch: 6| Step: 2
Training loss: 2.7033890611742626
Validation loss: 2.5672460594726068

Epoch: 6| Step: 3
Training loss: 3.30153554389951
Validation loss: 2.584028004408101

Epoch: 6| Step: 4
Training loss: 2.641547408756375
Validation loss: 2.581319461297

Epoch: 6| Step: 5
Training loss: 2.0937801757459935
Validation loss: 2.5824583446041602

Epoch: 6| Step: 6
Training loss: 2.5967214637658156
Validation loss: 2.594342994830575

Epoch: 6| Step: 7
Training loss: 3.11749434335252
Validation loss: 2.575451383563969

Epoch: 6| Step: 8
Training loss: 2.6919847373303005
Validation loss: 2.560154797865913

Epoch: 6| Step: 9
Training loss: 3.3193590657751906
Validation loss: 2.5452044325599554

Epoch: 6| Step: 10
Training loss: 3.314579149231986
Validation loss: 2.545328560208312

Epoch: 6| Step: 11
Training loss: 2.779397411766475
Validation loss: 2.5318222908018235

Epoch: 6| Step: 12
Training loss: 3.2244263013029433
Validation loss: 2.5325810679916514

Epoch: 6| Step: 13
Training loss: 3.3134436073092233
Validation loss: 2.5261056648133615

Epoch: 206| Step: 0
Training loss: 2.8522229409630753
Validation loss: 2.520061745693691

Epoch: 6| Step: 1
Training loss: 2.715029220283308
Validation loss: 2.510359093062858

Epoch: 6| Step: 2
Training loss: 3.218145369248373
Validation loss: 2.5122024804444227

Epoch: 6| Step: 3
Training loss: 2.906747426768852
Validation loss: 2.5137141669779726

Epoch: 6| Step: 4
Training loss: 3.0343046233229685
Validation loss: 2.513348287426551

Epoch: 6| Step: 5
Training loss: 2.957304242734291
Validation loss: 2.5124152752329136

Epoch: 6| Step: 6
Training loss: 2.550253470295913
Validation loss: 2.512020558824178

Epoch: 6| Step: 7
Training loss: 2.5976413812426906
Validation loss: 2.518008658509231

Epoch: 6| Step: 8
Training loss: 2.794873933627527
Validation loss: 2.51508386674872

Epoch: 6| Step: 9
Training loss: 3.0874189852691822
Validation loss: 2.5087217984378514

Epoch: 6| Step: 10
Training loss: 3.1236167898240033
Validation loss: 2.5068613013829837

Epoch: 6| Step: 11
Training loss: 2.8973036036445845
Validation loss: 2.5071541864506104

Epoch: 6| Step: 12
Training loss: 2.87267557801111
Validation loss: 2.5083527704849278

Epoch: 6| Step: 13
Training loss: 2.3775935818679255
Validation loss: 2.5110180835236475

Epoch: 207| Step: 0
Training loss: 2.8165033458633637
Validation loss: 2.5222065232256514

Epoch: 6| Step: 1
Training loss: 2.5989951906412916
Validation loss: 2.5357004649609993

Epoch: 6| Step: 2
Training loss: 3.0708904935640273
Validation loss: 2.54374038998029

Epoch: 6| Step: 3
Training loss: 2.9470025432408713
Validation loss: 2.577789986907642

Epoch: 6| Step: 4
Training loss: 3.063703806422672
Validation loss: 2.596411067283888

Epoch: 6| Step: 5
Training loss: 2.5720826520557902
Validation loss: 2.6146321658395237

Epoch: 6| Step: 6
Training loss: 2.3465098090561187
Validation loss: 2.6143836223902777

Epoch: 6| Step: 7
Training loss: 2.7039513179414607
Validation loss: 2.648693728009183

Epoch: 6| Step: 8
Training loss: 3.286062870726708
Validation loss: 2.640483143915888

Epoch: 6| Step: 9
Training loss: 3.193183469447953
Validation loss: 2.6143633015273013

Epoch: 6| Step: 10
Training loss: 3.1652308438020227
Validation loss: 2.5604709522534104

Epoch: 6| Step: 11
Training loss: 2.5024583173971267
Validation loss: 2.5242443643111288

Epoch: 6| Step: 12
Training loss: 3.0416078082795632
Validation loss: 2.5111623272842616

Epoch: 6| Step: 13
Training loss: 2.930835549797787
Validation loss: 2.504695989775683

Epoch: 208| Step: 0
Training loss: 3.07328407979074
Validation loss: 2.5019573143014937

Epoch: 6| Step: 1
Training loss: 2.9246493137465963
Validation loss: 2.504554570791482

Epoch: 6| Step: 2
Training loss: 2.430294929942184
Validation loss: 2.508308907146228

Epoch: 6| Step: 3
Training loss: 3.0279090009089846
Validation loss: 2.512337694888154

Epoch: 6| Step: 4
Training loss: 2.9504758871257115
Validation loss: 2.5115054552286935

Epoch: 6| Step: 5
Training loss: 2.2847332424321896
Validation loss: 2.515085103166864

Epoch: 6| Step: 6
Training loss: 3.286573904738951
Validation loss: 2.506459359697227

Epoch: 6| Step: 7
Training loss: 2.50908649919145
Validation loss: 2.5068887021058517

Epoch: 6| Step: 8
Training loss: 3.168171792632053
Validation loss: 2.50961406549084

Epoch: 6| Step: 9
Training loss: 2.6601899490798675
Validation loss: 2.509155053098346

Epoch: 6| Step: 10
Training loss: 3.2227311189219874
Validation loss: 2.5201461948393877

Epoch: 6| Step: 11
Training loss: 2.984305655587524
Validation loss: 2.514327783622846

Epoch: 6| Step: 12
Training loss: 2.5511386498276667
Validation loss: 2.5318001094038745

Epoch: 6| Step: 13
Training loss: 2.9603030851204957
Validation loss: 2.536666480199635

Epoch: 209| Step: 0
Training loss: 2.6032046155901543
Validation loss: 2.5437090374144637

Epoch: 6| Step: 1
Training loss: 3.0366505757759406
Validation loss: 2.5525302806159442

Epoch: 6| Step: 2
Training loss: 3.050099705801768
Validation loss: 2.5590977506536734

Epoch: 6| Step: 3
Training loss: 2.9120497719839404
Validation loss: 2.5745094082067856

Epoch: 6| Step: 4
Training loss: 3.03603826444936
Validation loss: 2.5667373189709406

Epoch: 6| Step: 5
Training loss: 2.8972803978236694
Validation loss: 2.562959983393036

Epoch: 6| Step: 6
Training loss: 2.788656937206105
Validation loss: 2.5658387633861577

Epoch: 6| Step: 7
Training loss: 2.398499329605629
Validation loss: 2.548788495718885

Epoch: 6| Step: 8
Training loss: 2.7918470144139507
Validation loss: 2.5473703294917973

Epoch: 6| Step: 9
Training loss: 3.1889719836684156
Validation loss: 2.529474103106773

Epoch: 6| Step: 10
Training loss: 2.905371748599238
Validation loss: 2.511813657420691

Epoch: 6| Step: 11
Training loss: 2.2492516650712804
Validation loss: 2.502911752713985

Epoch: 6| Step: 12
Training loss: 3.193470617567369
Validation loss: 2.5044867185543733

Epoch: 6| Step: 13
Training loss: 2.841614308998235
Validation loss: 2.5035414110704917

Epoch: 210| Step: 0
Training loss: 2.864305258461022
Validation loss: 2.507172746325863

Epoch: 6| Step: 1
Training loss: 3.1317203739494928
Validation loss: 2.5050181375348424

Epoch: 6| Step: 2
Training loss: 2.85582608806343
Validation loss: 2.5115991172648617

Epoch: 6| Step: 3
Training loss: 2.6213253277099824
Validation loss: 2.508595631560465

Epoch: 6| Step: 4
Training loss: 3.027135829553475
Validation loss: 2.5238171028458134

Epoch: 6| Step: 5
Training loss: 3.299835033339306
Validation loss: 2.5194764474955087

Epoch: 6| Step: 6
Training loss: 2.653900453720074
Validation loss: 2.530016861178103

Epoch: 6| Step: 7
Training loss: 2.9233665535176367
Validation loss: 2.526189127454325

Epoch: 6| Step: 8
Training loss: 3.201192877876875
Validation loss: 2.5314225746067325

Epoch: 6| Step: 9
Training loss: 3.2034122989486797
Validation loss: 2.53012006062724

Epoch: 6| Step: 10
Training loss: 2.650306604750124
Validation loss: 2.5185189466883577

Epoch: 6| Step: 11
Training loss: 2.3869355098608893
Validation loss: 2.5135383489220957

Epoch: 6| Step: 12
Training loss: 2.0282528406417404
Validation loss: 2.5112296454179575

Epoch: 6| Step: 13
Training loss: 3.131044569148472
Validation loss: 2.5094398378699365

Epoch: 211| Step: 0
Training loss: 2.7959498574941106
Validation loss: 2.498716714112186

Epoch: 6| Step: 1
Training loss: 2.687284416600812
Validation loss: 2.5063752400523636

Epoch: 6| Step: 2
Training loss: 2.146683743549132
Validation loss: 2.5097192122132967

Epoch: 6| Step: 3
Training loss: 2.623657428186095
Validation loss: 2.5089865636199673

Epoch: 6| Step: 4
Training loss: 2.95000118966806
Validation loss: 2.5110192892731735

Epoch: 6| Step: 5
Training loss: 3.0819678161049695
Validation loss: 2.5073205169280723

Epoch: 6| Step: 6
Training loss: 2.8869818746898286
Validation loss: 2.5005925860577305

Epoch: 6| Step: 7
Training loss: 2.9487229896851046
Validation loss: 2.5050517949545417

Epoch: 6| Step: 8
Training loss: 2.782265809821021
Validation loss: 2.5033159005261436

Epoch: 6| Step: 9
Training loss: 3.0264907127299634
Validation loss: 2.520848205964581

Epoch: 6| Step: 10
Training loss: 2.7525504163235732
Validation loss: 2.516613586087122

Epoch: 6| Step: 11
Training loss: 2.9633474884152835
Validation loss: 2.5177087588505493

Epoch: 6| Step: 12
Training loss: 3.166084152317829
Validation loss: 2.526615100992645

Epoch: 6| Step: 13
Training loss: 3.1358944010374468
Validation loss: 2.52002702016517

Epoch: 212| Step: 0
Training loss: 3.001722953673905
Validation loss: 2.5240917220655263

Epoch: 6| Step: 1
Training loss: 2.934017958364414
Validation loss: 2.5246952647875966

Epoch: 6| Step: 2
Training loss: 2.6973856596095933
Validation loss: 2.511004485365075

Epoch: 6| Step: 3
Training loss: 3.413869751960319
Validation loss: 2.5082913695680924

Epoch: 6| Step: 4
Training loss: 3.1592590793733626
Validation loss: 2.5053531431848834

Epoch: 6| Step: 5
Training loss: 2.581052655303305
Validation loss: 2.5096280848997576

Epoch: 6| Step: 6
Training loss: 3.1540773675557396
Validation loss: 2.5054549232584167

Epoch: 6| Step: 7
Training loss: 2.9541249676242236
Validation loss: 2.5051339276809013

Epoch: 6| Step: 8
Training loss: 2.0422894313039524
Validation loss: 2.509494084177961

Epoch: 6| Step: 9
Training loss: 3.5649625064114123
Validation loss: 2.5146907273266974

Epoch: 6| Step: 10
Training loss: 2.1450206983230093
Validation loss: 2.522265545476557

Epoch: 6| Step: 11
Training loss: 2.7395491120457742
Validation loss: 2.5215340737599066

Epoch: 6| Step: 12
Training loss: 2.095559093008947
Validation loss: 2.5217972467411345

Epoch: 6| Step: 13
Training loss: 3.1851620046953317
Validation loss: 2.5416437812378705

Epoch: 213| Step: 0
Training loss: 3.6853300272388045
Validation loss: 2.536783046033847

Epoch: 6| Step: 1
Training loss: 2.8285257466523257
Validation loss: 2.548314238298963

Epoch: 6| Step: 2
Training loss: 2.5828210774006375
Validation loss: 2.540352628093631

Epoch: 6| Step: 3
Training loss: 2.576611531232374
Validation loss: 2.5233923983165014

Epoch: 6| Step: 4
Training loss: 2.9896302612733057
Validation loss: 2.523585403157962

Epoch: 6| Step: 5
Training loss: 2.755247657846186
Validation loss: 2.509276887576572

Epoch: 6| Step: 6
Training loss: 2.630112891149433
Validation loss: 2.5046994902583295

Epoch: 6| Step: 7
Training loss: 2.8833057012685583
Validation loss: 2.502963563512183

Epoch: 6| Step: 8
Training loss: 2.8890926114004265
Validation loss: 2.500457294233014

Epoch: 6| Step: 9
Training loss: 2.846942827943015
Validation loss: 2.497905945273587

Epoch: 6| Step: 10
Training loss: 3.0231168512846134
Validation loss: 2.500108305318104

Epoch: 6| Step: 11
Training loss: 2.3440613603404796
Validation loss: 2.503611186869462

Epoch: 6| Step: 12
Training loss: 2.9918795992447547
Validation loss: 2.5059282483952163

Epoch: 6| Step: 13
Training loss: 2.8525987388378575
Validation loss: 2.499389143116647

Epoch: 214| Step: 0
Training loss: 2.8399532249789536
Validation loss: 2.5080229165848777

Epoch: 6| Step: 1
Training loss: 2.5203563669813147
Validation loss: 2.510955679835255

Epoch: 6| Step: 2
Training loss: 2.6392815236460794
Validation loss: 2.518050511130773

Epoch: 6| Step: 3
Training loss: 2.43548696485558
Validation loss: 2.521729592606999

Epoch: 6| Step: 4
Training loss: 2.7243650484089295
Validation loss: 2.5301412354080925

Epoch: 6| Step: 5
Training loss: 3.126235260011623
Validation loss: 2.539918943840889

Epoch: 6| Step: 6
Training loss: 2.963460928962998
Validation loss: 2.5255923549120736

Epoch: 6| Step: 7
Training loss: 3.068516485027297
Validation loss: 2.5258155629376846

Epoch: 6| Step: 8
Training loss: 2.9554337453319564
Validation loss: 2.5081510399974705

Epoch: 6| Step: 9
Training loss: 2.879151373977642
Validation loss: 2.5170891364058914

Epoch: 6| Step: 10
Training loss: 3.336874193819116
Validation loss: 2.5132846706315757

Epoch: 6| Step: 11
Training loss: 2.563062838638009
Validation loss: 2.503485485399405

Epoch: 6| Step: 12
Training loss: 3.323466591288476
Validation loss: 2.504773462910296

Epoch: 6| Step: 13
Training loss: 1.9940048007122932
Validation loss: 2.504029696404128

Epoch: 215| Step: 0
Training loss: 2.57769697855602
Validation loss: 2.5040195791327653

Epoch: 6| Step: 1
Training loss: 2.887842767360963
Validation loss: 2.4991646406723

Epoch: 6| Step: 2
Training loss: 3.2452448757511148
Validation loss: 2.5015231476267337

Epoch: 6| Step: 3
Training loss: 3.0366490055021487
Validation loss: 2.503010877928404

Epoch: 6| Step: 4
Training loss: 2.8228783599018654
Validation loss: 2.5002661512071347

Epoch: 6| Step: 5
Training loss: 2.3847485290964303
Validation loss: 2.4982122263769617

Epoch: 6| Step: 6
Training loss: 2.815769075863009
Validation loss: 2.4992031334840314

Epoch: 6| Step: 7
Training loss: 3.027434789457726
Validation loss: 2.4957463778942635

Epoch: 6| Step: 8
Training loss: 2.875628858703399
Validation loss: 2.5002113765653178

Epoch: 6| Step: 9
Training loss: 2.334580655722507
Validation loss: 2.497213354906404

Epoch: 6| Step: 10
Training loss: 3.2182213802874196
Validation loss: 2.4979336997807895

Epoch: 6| Step: 11
Training loss: 2.8816881752719103
Validation loss: 2.5148486763239735

Epoch: 6| Step: 12
Training loss: 2.6339739040510026
Validation loss: 2.5252298329086678

Epoch: 6| Step: 13
Training loss: 3.3733307277784976
Validation loss: 2.5405082601246693

Epoch: 216| Step: 0
Training loss: 2.5862068888784826
Validation loss: 2.4992505673015133

Epoch: 6| Step: 1
Training loss: 2.870162875242435
Validation loss: 2.5004142171969197

Epoch: 6| Step: 2
Training loss: 2.4416286031557486
Validation loss: 2.5079660696711175

Epoch: 6| Step: 3
Training loss: 2.770243522185494
Validation loss: 2.517113374413684

Epoch: 6| Step: 4
Training loss: 3.1068519055174457
Validation loss: 2.5364496394708316

Epoch: 6| Step: 5
Training loss: 2.926080624755716
Validation loss: 2.579936815152535

Epoch: 6| Step: 6
Training loss: 2.888119988535149
Validation loss: 2.6306562937531535

Epoch: 6| Step: 7
Training loss: 2.753330468121655
Validation loss: 2.621368185015929

Epoch: 6| Step: 8
Training loss: 1.918484309685328
Validation loss: 2.5797586311147525

Epoch: 6| Step: 9
Training loss: 3.8397044159454583
Validation loss: 2.5615216760446864

Epoch: 6| Step: 10
Training loss: 2.7218722250362575
Validation loss: 2.5348927365825

Epoch: 6| Step: 11
Training loss: 3.153646169337479
Validation loss: 2.529531966114241

Epoch: 6| Step: 12
Training loss: 2.785426743307744
Validation loss: 2.5162141049385554

Epoch: 6| Step: 13
Training loss: 3.7363943601601037
Validation loss: 2.5071962315134817

Epoch: 217| Step: 0
Training loss: 3.0003193049576673
Validation loss: 2.4913056485919123

Epoch: 6| Step: 1
Training loss: 2.4965651757969294
Validation loss: 2.4951276521888923

Epoch: 6| Step: 2
Training loss: 2.6565093867493124
Validation loss: 2.4928720131910933

Epoch: 6| Step: 3
Training loss: 2.400961575996251
Validation loss: 2.506948755826214

Epoch: 6| Step: 4
Training loss: 2.997005398551653
Validation loss: 2.508929852982684

Epoch: 6| Step: 5
Training loss: 2.799627047632409
Validation loss: 2.5206326854247494

Epoch: 6| Step: 6
Training loss: 2.529262374583717
Validation loss: 2.526856821662311

Epoch: 6| Step: 7
Training loss: 2.9924588790018634
Validation loss: 2.5541335696358285

Epoch: 6| Step: 8
Training loss: 3.0968492185441416
Validation loss: 2.5652549924598302

Epoch: 6| Step: 9
Training loss: 3.2721096067654156
Validation loss: 2.5747011302160363

Epoch: 6| Step: 10
Training loss: 2.8624559490695693
Validation loss: 2.557323568808562

Epoch: 6| Step: 11
Training loss: 2.781573844657677
Validation loss: 2.5457734675741768

Epoch: 6| Step: 12
Training loss: 2.895006972124997
Validation loss: 2.530845281588881

Epoch: 6| Step: 13
Training loss: 3.255089516060712
Validation loss: 2.51863624452059

Epoch: 218| Step: 0
Training loss: 2.777628051113401
Validation loss: 2.5155829979802724

Epoch: 6| Step: 1
Training loss: 2.7678279400528685
Validation loss: 2.509978493604605

Epoch: 6| Step: 2
Training loss: 2.3133390811698518
Validation loss: 2.5101981658743386

Epoch: 6| Step: 3
Training loss: 2.620495700971676
Validation loss: 2.5073607832139895

Epoch: 6| Step: 4
Training loss: 2.8798614532206397
Validation loss: 2.50758655158786

Epoch: 6| Step: 5
Training loss: 2.8499493778484606
Validation loss: 2.4973454523197804

Epoch: 6| Step: 6
Training loss: 2.6335815755313194
Validation loss: 2.502414990005308

Epoch: 6| Step: 7
Training loss: 3.28477535693201
Validation loss: 2.5258846046799905

Epoch: 6| Step: 8
Training loss: 3.5730087817063074
Validation loss: 2.5299949892201887

Epoch: 6| Step: 9
Training loss: 2.5007299311293183
Validation loss: 2.529544537847536

Epoch: 6| Step: 10
Training loss: 3.076237598504246
Validation loss: 2.5063533305547163

Epoch: 6| Step: 11
Training loss: 2.603132810729766
Validation loss: 2.5066960040604194

Epoch: 6| Step: 12
Training loss: 2.8345614370920615
Validation loss: 2.508589453910098

Epoch: 6| Step: 13
Training loss: 3.0767495427347122
Validation loss: 2.5290783654286657

Epoch: 219| Step: 0
Training loss: 1.9930358277281195
Validation loss: 2.5270022481564727

Epoch: 6| Step: 1
Training loss: 3.398542731398791
Validation loss: 2.5438391426452776

Epoch: 6| Step: 2
Training loss: 2.7075219528421317
Validation loss: 2.5470629623410463

Epoch: 6| Step: 3
Training loss: 3.25796998738796
Validation loss: 2.5538867223372486

Epoch: 6| Step: 4
Training loss: 2.9330529172840336
Validation loss: 2.566795604403986

Epoch: 6| Step: 5
Training loss: 2.569164077538064
Validation loss: 2.5595399721487233

Epoch: 6| Step: 6
Training loss: 2.6782827003723884
Validation loss: 2.5763384911552105

Epoch: 6| Step: 7
Training loss: 2.4858784474972224
Validation loss: 2.582952059086254

Epoch: 6| Step: 8
Training loss: 3.2605791305348646
Validation loss: 2.580011504291432

Epoch: 6| Step: 9
Training loss: 2.712244515758662
Validation loss: 2.5408069962907858

Epoch: 6| Step: 10
Training loss: 2.752602472849132
Validation loss: 2.511304323037241

Epoch: 6| Step: 11
Training loss: 3.237768484640592
Validation loss: 2.500912423933551

Epoch: 6| Step: 12
Training loss: 2.630100562780236
Validation loss: 2.496551478379142

Epoch: 6| Step: 13
Training loss: 2.991436019833016
Validation loss: 2.492984404253024

Epoch: 220| Step: 0
Training loss: 2.7660739340344684
Validation loss: 2.4918263651044694

Epoch: 6| Step: 1
Training loss: 3.3230425931374494
Validation loss: 2.4957639676733896

Epoch: 6| Step: 2
Training loss: 2.921230143004977
Validation loss: 2.4966684467118694

Epoch: 6| Step: 3
Training loss: 2.92826658250622
Validation loss: 2.4969789689451063

Epoch: 6| Step: 4
Training loss: 3.1156467081153534
Validation loss: 2.4917456467003922

Epoch: 6| Step: 5
Training loss: 2.2774353532378235
Validation loss: 2.4941462381661608

Epoch: 6| Step: 6
Training loss: 2.8611206396082096
Validation loss: 2.4969965931623666

Epoch: 6| Step: 7
Training loss: 2.8608054663433102
Validation loss: 2.5032766690751718

Epoch: 6| Step: 8
Training loss: 2.8783539820734636
Validation loss: 2.5101112132577716

Epoch: 6| Step: 9
Training loss: 2.3433666678707987
Validation loss: 2.539969218546147

Epoch: 6| Step: 10
Training loss: 2.610700441986887
Validation loss: 2.576424131543131

Epoch: 6| Step: 11
Training loss: 2.8356064111891914
Validation loss: 2.637001521824489

Epoch: 6| Step: 12
Training loss: 3.2487933046126822
Validation loss: 2.6513971490548913

Epoch: 6| Step: 13
Training loss: 3.014185903029211
Validation loss: 2.639763349955965

Epoch: 221| Step: 0
Training loss: 3.0058384349904146
Validation loss: 2.6312283752455397

Epoch: 6| Step: 1
Training loss: 3.1215955882238267
Validation loss: 2.589613602024705

Epoch: 6| Step: 2
Training loss: 2.7690956192782608
Validation loss: 2.5685587582538427

Epoch: 6| Step: 3
Training loss: 2.923209472114321
Validation loss: 2.5259456428939697

Epoch: 6| Step: 4
Training loss: 2.9629434116919398
Validation loss: 2.5101062373549152

Epoch: 6| Step: 5
Training loss: 2.2497176946920576
Validation loss: 2.5031021867435834

Epoch: 6| Step: 6
Training loss: 2.641515818559894
Validation loss: 2.5039445562732685

Epoch: 6| Step: 7
Training loss: 3.6522988382933863
Validation loss: 2.5052110526457065

Epoch: 6| Step: 8
Training loss: 2.6571336061928967
Validation loss: 2.509531449088445

Epoch: 6| Step: 9
Training loss: 2.64027682384688
Validation loss: 2.5096934941526166

Epoch: 6| Step: 10
Training loss: 3.3678040260873083
Validation loss: 2.510858647911916

Epoch: 6| Step: 11
Training loss: 3.047080165117716
Validation loss: 2.512977768987398

Epoch: 6| Step: 12
Training loss: 2.410189092032114
Validation loss: 2.5080245837532513

Epoch: 6| Step: 13
Training loss: 2.639589908133018
Validation loss: 2.5059023144418253

Epoch: 222| Step: 0
Training loss: 2.841770866773168
Validation loss: 2.5066037665846763

Epoch: 6| Step: 1
Training loss: 2.7329544300979824
Validation loss: 2.511416754849231

Epoch: 6| Step: 2
Training loss: 2.313019359106842
Validation loss: 2.5144367686860036

Epoch: 6| Step: 3
Training loss: 2.3303349394176376
Validation loss: 2.5224987384165276

Epoch: 6| Step: 4
Training loss: 2.841198289889874
Validation loss: 2.514855565430204

Epoch: 6| Step: 5
Training loss: 3.0121028274269066
Validation loss: 2.517106101406273

Epoch: 6| Step: 6
Training loss: 3.1891813144857473
Validation loss: 2.5182482906851074

Epoch: 6| Step: 7
Training loss: 3.2948263592038787
Validation loss: 2.527124267091862

Epoch: 6| Step: 8
Training loss: 2.3281819381407804
Validation loss: 2.5306043896630186

Epoch: 6| Step: 9
Training loss: 3.3029084884435154
Validation loss: 2.545024434802456

Epoch: 6| Step: 10
Training loss: 2.9964585063575075
Validation loss: 2.5615619049799965

Epoch: 6| Step: 11
Training loss: 3.0854093075462083
Validation loss: 2.572274937652046

Epoch: 6| Step: 12
Training loss: 2.859968947128629
Validation loss: 2.5756729074277946

Epoch: 6| Step: 13
Training loss: 2.329102995610146
Validation loss: 2.575060051571133

Epoch: 223| Step: 0
Training loss: 3.226606835159991
Validation loss: 2.5646588075624135

Epoch: 6| Step: 1
Training loss: 2.771107729372954
Validation loss: 2.575711275064809

Epoch: 6| Step: 2
Training loss: 2.924147594176268
Validation loss: 2.6145563046180555

Epoch: 6| Step: 3
Training loss: 2.3881221459937496
Validation loss: 2.6499975731889442

Epoch: 6| Step: 4
Training loss: 2.9705702170712582
Validation loss: 2.677934012446924

Epoch: 6| Step: 5
Training loss: 2.9932747800179333
Validation loss: 2.6881190696131876

Epoch: 6| Step: 6
Training loss: 2.7658168920120434
Validation loss: 2.68889570994122

Epoch: 6| Step: 7
Training loss: 2.9771053590131054
Validation loss: 2.683283970892856

Epoch: 6| Step: 8
Training loss: 2.774564358306985
Validation loss: 2.614780269733537

Epoch: 6| Step: 9
Training loss: 3.064511008655046
Validation loss: 2.600559612737938

Epoch: 6| Step: 10
Training loss: 2.8307678351032046
Validation loss: 2.545377969663726

Epoch: 6| Step: 11
Training loss: 3.0917044919177252
Validation loss: 2.5127178783347293

Epoch: 6| Step: 12
Training loss: 2.632975677957419
Validation loss: 2.506071145291405

Epoch: 6| Step: 13
Training loss: 2.552118251847107
Validation loss: 2.4982917964026403

Epoch: 224| Step: 0
Training loss: 3.2320563072171966
Validation loss: 2.494714627894127

Epoch: 6| Step: 1
Training loss: 2.9973218407710385
Validation loss: 2.4960883743567432

Epoch: 6| Step: 2
Training loss: 3.0703903071904017
Validation loss: 2.5008182058351003

Epoch: 6| Step: 3
Training loss: 2.6295293151822965
Validation loss: 2.5056194951855777

Epoch: 6| Step: 4
Training loss: 3.009847849045173
Validation loss: 2.511285428233217

Epoch: 6| Step: 5
Training loss: 2.6298402031337482
Validation loss: 2.5085176919005603

Epoch: 6| Step: 6
Training loss: 3.136286685587645
Validation loss: 2.51232763046159

Epoch: 6| Step: 7
Training loss: 2.8762507827671517
Validation loss: 2.5254186357730872

Epoch: 6| Step: 8
Training loss: 2.294939847835207
Validation loss: 2.5254765566769297

Epoch: 6| Step: 9
Training loss: 3.2059846348099823
Validation loss: 2.5132338131662277

Epoch: 6| Step: 10
Training loss: 3.1075418714063927
Validation loss: 2.5127744417556244

Epoch: 6| Step: 11
Training loss: 2.6285700363398354
Validation loss: 2.5380766650543056

Epoch: 6| Step: 12
Training loss: 2.5204614622457564
Validation loss: 2.5358380042614432

Epoch: 6| Step: 13
Training loss: 2.3301522050514327
Validation loss: 2.550406708918235

Epoch: 225| Step: 0
Training loss: 2.939916550107203
Validation loss: 2.543555217895558

Epoch: 6| Step: 1
Training loss: 2.8765579646301154
Validation loss: 2.577159683221717

Epoch: 6| Step: 2
Training loss: 2.566356641037364
Validation loss: 2.601576638816917

Epoch: 6| Step: 3
Training loss: 2.8248162066331544
Validation loss: 2.6079188879541078

Epoch: 6| Step: 4
Training loss: 2.564986162650279
Validation loss: 2.6862893846540454

Epoch: 6| Step: 5
Training loss: 2.9764934541799146
Validation loss: 2.758089000737387

Epoch: 6| Step: 6
Training loss: 3.3135852115715543
Validation loss: 2.8267901605228336

Epoch: 6| Step: 7
Training loss: 2.4572120199735097
Validation loss: 2.770032648729535

Epoch: 6| Step: 8
Training loss: 2.5379452169170764
Validation loss: 2.6266208679944816

Epoch: 6| Step: 9
Training loss: 2.871763646869541
Validation loss: 2.5360863090974584

Epoch: 6| Step: 10
Training loss: 3.3381000450871365
Validation loss: 2.488621641361288

Epoch: 6| Step: 11
Training loss: 2.8608066330984308
Validation loss: 2.4830199054650652

Epoch: 6| Step: 12
Training loss: 3.0086426221057345
Validation loss: 2.493322256501363

Epoch: 6| Step: 13
Training loss: 2.6909504408963216
Validation loss: 2.5095210127947696

Epoch: 226| Step: 0
Training loss: 3.3233576913423706
Validation loss: 2.517639384963577

Epoch: 6| Step: 1
Training loss: 2.6629383926169856
Validation loss: 2.5189184429468887

Epoch: 6| Step: 2
Training loss: 3.220486070896273
Validation loss: 2.5177680973108147

Epoch: 6| Step: 3
Training loss: 3.2215130252056756
Validation loss: 2.5240886547445744

Epoch: 6| Step: 4
Training loss: 2.8801445749870176
Validation loss: 2.5242157148863327

Epoch: 6| Step: 5
Training loss: 2.7151570749948393
Validation loss: 2.518514119726242

Epoch: 6| Step: 6
Training loss: 2.9506341026406537
Validation loss: 2.5236101263222546

Epoch: 6| Step: 7
Training loss: 2.730783076060069
Validation loss: 2.524338393563797

Epoch: 6| Step: 8
Training loss: 3.1244762744732264
Validation loss: 2.538105714564021

Epoch: 6| Step: 9
Training loss: 3.053410958493028
Validation loss: 2.5511424161921528

Epoch: 6| Step: 10
Training loss: 2.6134741103278607
Validation loss: 2.556332138117447

Epoch: 6| Step: 11
Training loss: 2.5911586639751163
Validation loss: 2.5475927071808964

Epoch: 6| Step: 12
Training loss: 2.604694119761384
Validation loss: 2.556416815118536

Epoch: 6| Step: 13
Training loss: 3.0381807357236608
Validation loss: 2.525635047173936

Epoch: 227| Step: 0
Training loss: 2.986564112957508
Validation loss: 2.515378967128318

Epoch: 6| Step: 1
Training loss: 2.802236266849275
Validation loss: 2.513083659415422

Epoch: 6| Step: 2
Training loss: 2.770875763149985
Validation loss: 2.509646541693796

Epoch: 6| Step: 3
Training loss: 2.0125556464232117
Validation loss: 2.5036964888563227

Epoch: 6| Step: 4
Training loss: 3.532301214608904
Validation loss: 2.502474166595652

Epoch: 6| Step: 5
Training loss: 2.9662161202792676
Validation loss: 2.4975097374327615

Epoch: 6| Step: 6
Training loss: 3.0399239307222206
Validation loss: 2.493932388268308

Epoch: 6| Step: 7
Training loss: 2.9166390735592564
Validation loss: 2.495344041021708

Epoch: 6| Step: 8
Training loss: 2.910181155514233
Validation loss: 2.5072697051505437

Epoch: 6| Step: 9
Training loss: 2.6033891559856475
Validation loss: 2.515243228698865

Epoch: 6| Step: 10
Training loss: 3.390034567057499
Validation loss: 2.5082117866289786

Epoch: 6| Step: 11
Training loss: 2.6546766221405664
Validation loss: 2.4953427362619616

Epoch: 6| Step: 12
Training loss: 2.3549774821636413
Validation loss: 2.5034673600282864

Epoch: 6| Step: 13
Training loss: 2.5675560917062
Validation loss: 2.5284598861638714

Epoch: 228| Step: 0
Training loss: 2.856804364453018
Validation loss: 2.5350936051936794

Epoch: 6| Step: 1
Training loss: 2.9243351172515646
Validation loss: 2.553280610606603

Epoch: 6| Step: 2
Training loss: 2.4283995327100336
Validation loss: 2.5710737961928203

Epoch: 6| Step: 3
Training loss: 3.2322579794646633
Validation loss: 2.606077779786567

Epoch: 6| Step: 4
Training loss: 2.9740049733759757
Validation loss: 2.6179091473534584

Epoch: 6| Step: 5
Training loss: 2.4723719814626763
Validation loss: 2.649641111903022

Epoch: 6| Step: 6
Training loss: 3.168565348224145
Validation loss: 2.684449305666236

Epoch: 6| Step: 7
Training loss: 2.771227576716121
Validation loss: 2.638696740140023

Epoch: 6| Step: 8
Training loss: 3.2525425282306792
Validation loss: 2.6010365164908977

Epoch: 6| Step: 9
Training loss: 3.007343840314398
Validation loss: 2.5444115268275262

Epoch: 6| Step: 10
Training loss: 2.110138931401071
Validation loss: 2.5187650341718184

Epoch: 6| Step: 11
Training loss: 2.663226670511346
Validation loss: 2.4861346128915

Epoch: 6| Step: 12
Training loss: 2.7429471172891082
Validation loss: 2.4789388325637285

Epoch: 6| Step: 13
Training loss: 3.507741404877043
Validation loss: 2.475756237216511

Epoch: 229| Step: 0
Training loss: 3.2426404521702343
Validation loss: 2.4748896584888342

Epoch: 6| Step: 1
Training loss: 2.5750031961958224
Validation loss: 2.477720020715218

Epoch: 6| Step: 2
Training loss: 3.0032974241299586
Validation loss: 2.4816925825350653

Epoch: 6| Step: 3
Training loss: 3.260854055948278
Validation loss: 2.480378539731923

Epoch: 6| Step: 4
Training loss: 3.536879921205464
Validation loss: 2.4829640937032007

Epoch: 6| Step: 5
Training loss: 2.8008338572138354
Validation loss: 2.4847892518537336

Epoch: 6| Step: 6
Training loss: 3.2257519458965036
Validation loss: 2.4776158244518998

Epoch: 6| Step: 7
Training loss: 2.556064432958804
Validation loss: 2.475817567967975

Epoch: 6| Step: 8
Training loss: 2.0842542393144705
Validation loss: 2.467491942557938

Epoch: 6| Step: 9
Training loss: 2.3895384868835765
Validation loss: 2.4740425939194757

Epoch: 6| Step: 10
Training loss: 2.9029128080250866
Validation loss: 2.4783044544401047

Epoch: 6| Step: 11
Training loss: 2.7138345942233597
Validation loss: 2.488484288365086

Epoch: 6| Step: 12
Training loss: 2.765946708976768
Validation loss: 2.50448375415148

Epoch: 6| Step: 13
Training loss: 2.3833163369735377
Validation loss: 2.5258838018562746

Epoch: 230| Step: 0
Training loss: 3.1543392025023813
Validation loss: 2.5474130019601455

Epoch: 6| Step: 1
Training loss: 3.331185666262875
Validation loss: 2.5886386055847788

Epoch: 6| Step: 2
Training loss: 2.75499410583641
Validation loss: 2.565643731192848

Epoch: 6| Step: 3
Training loss: 3.2538700536796044
Validation loss: 2.5931581784946953

Epoch: 6| Step: 4
Training loss: 2.751858343437429
Validation loss: 2.6036520878188023

Epoch: 6| Step: 5
Training loss: 2.8932453547636308
Validation loss: 2.6339726407103377

Epoch: 6| Step: 6
Training loss: 2.835296137983381
Validation loss: 2.6015414433869877

Epoch: 6| Step: 7
Training loss: 2.6996216756181384
Validation loss: 2.5399078289694805

Epoch: 6| Step: 8
Training loss: 2.673988175878867
Validation loss: 2.507925614793631

Epoch: 6| Step: 9
Training loss: 3.4357142578433164
Validation loss: 2.489649857524579

Epoch: 6| Step: 10
Training loss: 2.2769349976225577
Validation loss: 2.4736606248224207

Epoch: 6| Step: 11
Training loss: 2.4876546265356194
Validation loss: 2.472618591201186

Epoch: 6| Step: 12
Training loss: 2.8621012713990646
Validation loss: 2.4696881344747585

Epoch: 6| Step: 13
Training loss: 2.360128118302531
Validation loss: 2.475632257042981

Epoch: 231| Step: 0
Training loss: 2.663015926323487
Validation loss: 2.471190754237231

Epoch: 6| Step: 1
Training loss: 3.032986802089714
Validation loss: 2.4689056401422116

Epoch: 6| Step: 2
Training loss: 2.825169573395325
Validation loss: 2.4698884851116696

Epoch: 6| Step: 3
Training loss: 3.035242499227001
Validation loss: 2.4684668436073127

Epoch: 6| Step: 4
Training loss: 2.7760349199643675
Validation loss: 2.4660009860583103

Epoch: 6| Step: 5
Training loss: 3.066748649772881
Validation loss: 2.4647452418261984

Epoch: 6| Step: 6
Training loss: 3.291253816491568
Validation loss: 2.4616766592242247

Epoch: 6| Step: 7
Training loss: 2.845590854961896
Validation loss: 2.4630344169304808

Epoch: 6| Step: 8
Training loss: 2.3362451050994357
Validation loss: 2.4605719817553804

Epoch: 6| Step: 9
Training loss: 2.6676547087662295
Validation loss: 2.4721558373641317

Epoch: 6| Step: 10
Training loss: 2.7270871944609008
Validation loss: 2.477246255666574

Epoch: 6| Step: 11
Training loss: 2.7341052112999455
Validation loss: 2.4802901846055225

Epoch: 6| Step: 12
Training loss: 3.089585863773873
Validation loss: 2.496087113122755

Epoch: 6| Step: 13
Training loss: 2.3943180655190424
Validation loss: 2.506649102842412

Epoch: 232| Step: 0
Training loss: 3.164111629151759
Validation loss: 2.506838312115206

Epoch: 6| Step: 1
Training loss: 3.062311594870311
Validation loss: 2.5279946652421414

Epoch: 6| Step: 2
Training loss: 2.8087959482044798
Validation loss: 2.5412527628554735

Epoch: 6| Step: 3
Training loss: 2.6982155024354535
Validation loss: 2.5555119807984066

Epoch: 6| Step: 4
Training loss: 3.107561512320624
Validation loss: 2.5609438072827206

Epoch: 6| Step: 5
Training loss: 2.6497957690731284
Validation loss: 2.5736125137769803

Epoch: 6| Step: 6
Training loss: 2.210920893199005
Validation loss: 2.557967373368324

Epoch: 6| Step: 7
Training loss: 3.299103620915549
Validation loss: 2.5728650532335284

Epoch: 6| Step: 8
Training loss: 2.7055156037263646
Validation loss: 2.5682710460601155

Epoch: 6| Step: 9
Training loss: 3.0933398350559616
Validation loss: 2.545149354881883

Epoch: 6| Step: 10
Training loss: 2.6895330856282404
Validation loss: 2.506072745219117

Epoch: 6| Step: 11
Training loss: 2.9568264485922615
Validation loss: 2.4875324750703425

Epoch: 6| Step: 12
Training loss: 2.768966122151031
Validation loss: 2.479338224215461

Epoch: 6| Step: 13
Training loss: 1.9741902345168683
Validation loss: 2.466493578779799

Epoch: 233| Step: 0
Training loss: 3.038100063250671
Validation loss: 2.4607336410099356

Epoch: 6| Step: 1
Training loss: 3.036974191876919
Validation loss: 2.4654512839927727

Epoch: 6| Step: 2
Training loss: 2.996926163444502
Validation loss: 2.4691585764989257

Epoch: 6| Step: 3
Training loss: 2.7695140326950725
Validation loss: 2.4707064661206637

Epoch: 6| Step: 4
Training loss: 2.6371827572046387
Validation loss: 2.4675202916258065

Epoch: 6| Step: 5
Training loss: 3.0058174948349508
Validation loss: 2.4698549173202284

Epoch: 6| Step: 6
Training loss: 2.9886552564153694
Validation loss: 2.47605072361779

Epoch: 6| Step: 7
Training loss: 3.359598551564359
Validation loss: 2.4755435637153926

Epoch: 6| Step: 8
Training loss: 2.206701095327841
Validation loss: 2.485011734219106

Epoch: 6| Step: 9
Training loss: 2.701166579102726
Validation loss: 2.481750620077128

Epoch: 6| Step: 10
Training loss: 2.4570963597729976
Validation loss: 2.4798838824981537

Epoch: 6| Step: 11
Training loss: 2.925040911526956
Validation loss: 2.4809426137089265

Epoch: 6| Step: 12
Training loss: 2.4006224381428947
Validation loss: 2.479475518299159

Epoch: 6| Step: 13
Training loss: 2.9174796106824052
Validation loss: 2.47749987506445

Epoch: 234| Step: 0
Training loss: 3.2559422675223337
Validation loss: 2.480430159730055

Epoch: 6| Step: 1
Training loss: 2.757951511413252
Validation loss: 2.473640970924201

Epoch: 6| Step: 2
Training loss: 3.0843130737395676
Validation loss: 2.470630791742741

Epoch: 6| Step: 3
Training loss: 3.013494974656549
Validation loss: 2.477214018060448

Epoch: 6| Step: 4
Training loss: 2.998190970173169
Validation loss: 2.4706577050254634

Epoch: 6| Step: 5
Training loss: 2.558993289415476
Validation loss: 2.47712734669078

Epoch: 6| Step: 6
Training loss: 2.3596916744097753
Validation loss: 2.47321556940114

Epoch: 6| Step: 7
Training loss: 2.348966566072798
Validation loss: 2.4760662862881855

Epoch: 6| Step: 8
Training loss: 2.6559886130582924
Validation loss: 2.4732438715209684

Epoch: 6| Step: 9
Training loss: 2.5963482998571554
Validation loss: 2.476192004767776

Epoch: 6| Step: 10
Training loss: 3.040946944973482
Validation loss: 2.4791162099139017

Epoch: 6| Step: 11
Training loss: 2.9178154635733518
Validation loss: 2.496570061625798

Epoch: 6| Step: 12
Training loss: 3.0354489218508567
Validation loss: 2.5019973651451797

Epoch: 6| Step: 13
Training loss: 2.6449903712250618
Validation loss: 2.5176022931297553

Epoch: 235| Step: 0
Training loss: 2.6702651142985125
Validation loss: 2.523090354544628

Epoch: 6| Step: 1
Training loss: 2.8486917337281397
Validation loss: 2.525910862254081

Epoch: 6| Step: 2
Training loss: 2.625601744935864
Validation loss: 2.5262760376275306

Epoch: 6| Step: 3
Training loss: 2.85404630161251
Validation loss: 2.534037992244974

Epoch: 6| Step: 4
Training loss: 3.0207414459635262
Validation loss: 2.5235232635129696

Epoch: 6| Step: 5
Training loss: 2.5524616402219813
Validation loss: 2.5221129745652258

Epoch: 6| Step: 6
Training loss: 3.013904139826365
Validation loss: 2.5102133202423325

Epoch: 6| Step: 7
Training loss: 2.7278365953901824
Validation loss: 2.5102932262712336

Epoch: 6| Step: 8
Training loss: 2.7921793642443204
Validation loss: 2.5092715524357208

Epoch: 6| Step: 9
Training loss: 2.773065160553223
Validation loss: 2.502438302659202

Epoch: 6| Step: 10
Training loss: 3.5974514682404286
Validation loss: 2.5098724394854637

Epoch: 6| Step: 11
Training loss: 3.091242535092742
Validation loss: 2.5032874703820283

Epoch: 6| Step: 12
Training loss: 2.1173694715386606
Validation loss: 2.485640827834762

Epoch: 6| Step: 13
Training loss: 2.282873124943619
Validation loss: 2.4743121407860587

Epoch: 236| Step: 0
Training loss: 2.597334992470234
Validation loss: 2.4697632554120883

Epoch: 6| Step: 1
Training loss: 3.301056294014084
Validation loss: 2.4690534146392924

Epoch: 6| Step: 2
Training loss: 3.1795852232284103
Validation loss: 2.4685873058745798

Epoch: 6| Step: 3
Training loss: 3.239223660601546
Validation loss: 2.466657913855422

Epoch: 6| Step: 4
Training loss: 2.059638726304166
Validation loss: 2.4612811521676683

Epoch: 6| Step: 5
Training loss: 2.1231430017911386
Validation loss: 2.466730652533263

Epoch: 6| Step: 6
Training loss: 2.556895850186783
Validation loss: 2.4643653826793916

Epoch: 6| Step: 7
Training loss: 2.8938751918661993
Validation loss: 2.4618788822898647

Epoch: 6| Step: 8
Training loss: 2.939312477168758
Validation loss: 2.458548086125594

Epoch: 6| Step: 9
Training loss: 2.68143764097139
Validation loss: 2.4741917220401435

Epoch: 6| Step: 10
Training loss: 3.1445467172562145
Validation loss: 2.4813752760376375

Epoch: 6| Step: 11
Training loss: 2.705852741923352
Validation loss: 2.485474316244425

Epoch: 6| Step: 12
Training loss: 3.1305282522381943
Validation loss: 2.510429322722244

Epoch: 6| Step: 13
Training loss: 2.279393629620848
Validation loss: 2.5091230742457538

Epoch: 237| Step: 0
Training loss: 2.747098432356967
Validation loss: 2.504754061331344

Epoch: 6| Step: 1
Training loss: 2.8050594667601163
Validation loss: 2.5023965567094586

Epoch: 6| Step: 2
Training loss: 2.9645396040164043
Validation loss: 2.5095322081085025

Epoch: 6| Step: 3
Training loss: 2.774564959817585
Validation loss: 2.4929522961231485

Epoch: 6| Step: 4
Training loss: 2.3391651322165323
Validation loss: 2.491879493828277

Epoch: 6| Step: 5
Training loss: 2.783680571712493
Validation loss: 2.4833953653392324

Epoch: 6| Step: 6
Training loss: 2.60550599307504
Validation loss: 2.4747190888438584

Epoch: 6| Step: 7
Training loss: 2.7776953451852964
Validation loss: 2.4728077212872326

Epoch: 6| Step: 8
Training loss: 3.313489802047673
Validation loss: 2.4538825000544304

Epoch: 6| Step: 9
Training loss: 2.032120972749453
Validation loss: 2.46175385122863

Epoch: 6| Step: 10
Training loss: 2.764022276538783
Validation loss: 2.470808696003186

Epoch: 6| Step: 11
Training loss: 3.3432374365286766
Validation loss: 2.467999943679615

Epoch: 6| Step: 12
Training loss: 3.1558236315705446
Validation loss: 2.4713650279642416

Epoch: 6| Step: 13
Training loss: 2.5839591857651216
Validation loss: 2.475801815276999

Epoch: 238| Step: 0
Training loss: 2.6345763142005736
Validation loss: 2.490586657923832

Epoch: 6| Step: 1
Training loss: 2.7780187459907775
Validation loss: 2.4975598927330904

Epoch: 6| Step: 2
Training loss: 2.702932185534289
Validation loss: 2.5130519202990267

Epoch: 6| Step: 3
Training loss: 2.71681074060759
Validation loss: 2.523824293535735

Epoch: 6| Step: 4
Training loss: 3.1115147881270624
Validation loss: 2.5206081456245983

Epoch: 6| Step: 5
Training loss: 2.968706632598541
Validation loss: 2.5193318168437306

Epoch: 6| Step: 6
Training loss: 2.369491412805475
Validation loss: 2.5073417891654297

Epoch: 6| Step: 7
Training loss: 2.650208457809032
Validation loss: 2.512763705460116

Epoch: 6| Step: 8
Training loss: 2.759274535548142
Validation loss: 2.5095834889332647

Epoch: 6| Step: 9
Training loss: 3.1376495690429222
Validation loss: 2.5070511388614984

Epoch: 6| Step: 10
Training loss: 3.030525199519766
Validation loss: 2.5012844569967383

Epoch: 6| Step: 11
Training loss: 2.593006992776418
Validation loss: 2.5057922676047393

Epoch: 6| Step: 12
Training loss: 2.9504222309081807
Validation loss: 2.495185519019802

Epoch: 6| Step: 13
Training loss: 2.863624291993166
Validation loss: 2.483834746898006

Epoch: 239| Step: 0
Training loss: 2.87718747719551
Validation loss: 2.476406618497435

Epoch: 6| Step: 1
Training loss: 2.352435282709894
Validation loss: 2.4793795860176955

Epoch: 6| Step: 2
Training loss: 2.944845228289443
Validation loss: 2.470474625205692

Epoch: 6| Step: 3
Training loss: 2.724923676988065
Validation loss: 2.474925114706626

Epoch: 6| Step: 4
Training loss: 2.8091506511994035
Validation loss: 2.4781449552104284

Epoch: 6| Step: 5
Training loss: 2.6965631651692417
Validation loss: 2.4826401374879348

Epoch: 6| Step: 6
Training loss: 2.705884197788146
Validation loss: 2.485113037262671

Epoch: 6| Step: 7
Training loss: 2.787466923128269
Validation loss: 2.48359609250097

Epoch: 6| Step: 8
Training loss: 2.403842167190767
Validation loss: 2.494525359232776

Epoch: 6| Step: 9
Training loss: 3.2499391109924956
Validation loss: 2.493801295354059

Epoch: 6| Step: 10
Training loss: 3.1956489964074195
Validation loss: 2.4950822709799527

Epoch: 6| Step: 11
Training loss: 2.8292527453025045
Validation loss: 2.485015969102868

Epoch: 6| Step: 12
Training loss: 2.5490545764167205
Validation loss: 2.4858250688211943

Epoch: 6| Step: 13
Training loss: 3.133813864472203
Validation loss: 2.477635774823381

Epoch: 240| Step: 0
Training loss: 2.843444640145087
Validation loss: 2.4777348858792463

Epoch: 6| Step: 1
Training loss: 2.93443300557518
Validation loss: 2.4957871801575915

Epoch: 6| Step: 2
Training loss: 2.548704929224578
Validation loss: 2.5049117352367185

Epoch: 6| Step: 3
Training loss: 3.0908088961084577
Validation loss: 2.5233993656923315

Epoch: 6| Step: 4
Training loss: 2.3780385707232874
Validation loss: 2.5389802420569687

Epoch: 6| Step: 5
Training loss: 2.6050864973003773
Validation loss: 2.5394994922881144

Epoch: 6| Step: 6
Training loss: 2.886950327420471
Validation loss: 2.5468087941738466

Epoch: 6| Step: 7
Training loss: 3.136228910324325
Validation loss: 2.54989280756883

Epoch: 6| Step: 8
Training loss: 2.9319584297470263
Validation loss: 2.5158274304227706

Epoch: 6| Step: 9
Training loss: 2.8132318180384503
Validation loss: 2.505898401307211

Epoch: 6| Step: 10
Training loss: 2.259437899947299
Validation loss: 2.486843745886965

Epoch: 6| Step: 11
Training loss: 2.9393810985776887
Validation loss: 2.474091387777658

Epoch: 6| Step: 12
Training loss: 2.9475830392569824
Validation loss: 2.4619826293508056

Epoch: 6| Step: 13
Training loss: 2.980593537484331
Validation loss: 2.464041484999325

Epoch: 241| Step: 0
Training loss: 2.7045141630642893
Validation loss: 2.4550543960397118

Epoch: 6| Step: 1
Training loss: 3.3571753108998097
Validation loss: 2.455067955324499

Epoch: 6| Step: 2
Training loss: 2.1774194874643813
Validation loss: 2.4571771136108222

Epoch: 6| Step: 3
Training loss: 2.493798862064624
Validation loss: 2.464658468995681

Epoch: 6| Step: 4
Training loss: 2.8955493119918145
Validation loss: 2.4587494081092895

Epoch: 6| Step: 5
Training loss: 2.353952201144067
Validation loss: 2.4534553455369994

Epoch: 6| Step: 6
Training loss: 2.6615323667935633
Validation loss: 2.465329651491675

Epoch: 6| Step: 7
Training loss: 3.210389324833422
Validation loss: 2.461990222433902

Epoch: 6| Step: 8
Training loss: 2.776431592475369
Validation loss: 2.4629821023913494

Epoch: 6| Step: 9
Training loss: 2.376973486682252
Validation loss: 2.4672937050457215

Epoch: 6| Step: 10
Training loss: 2.7642741379437368
Validation loss: 2.484571320551104

Epoch: 6| Step: 11
Training loss: 2.9104272498609887
Validation loss: 2.492304800691261

Epoch: 6| Step: 12
Training loss: 3.104009705400533
Validation loss: 2.506507932642822

Epoch: 6| Step: 13
Training loss: 3.29823152376955
Validation loss: 2.503491564025555

Epoch: 242| Step: 0
Training loss: 2.191949950308118
Validation loss: 2.536444615176234

Epoch: 6| Step: 1
Training loss: 2.5225994029274936
Validation loss: 2.5630010869766133

Epoch: 6| Step: 2
Training loss: 3.32610764948269
Validation loss: 2.5898714398311466

Epoch: 6| Step: 3
Training loss: 3.0140712075431506
Validation loss: 2.566242394528238

Epoch: 6| Step: 4
Training loss: 2.8652799741812904
Validation loss: 2.5374131548362677

Epoch: 6| Step: 5
Training loss: 2.685653229428139
Validation loss: 2.525914909819977

Epoch: 6| Step: 6
Training loss: 2.6761784390998353
Validation loss: 2.501174673346356

Epoch: 6| Step: 7
Training loss: 2.5020488926160613
Validation loss: 2.508773497422856

Epoch: 6| Step: 8
Training loss: 3.042313668054953
Validation loss: 2.500550565289459

Epoch: 6| Step: 9
Training loss: 2.6907657032683567
Validation loss: 2.5014542113613962

Epoch: 6| Step: 10
Training loss: 2.999005629729774
Validation loss: 2.50010169037763

Epoch: 6| Step: 11
Training loss: 2.6837850222103623
Validation loss: 2.4979022751651647

Epoch: 6| Step: 12
Training loss: 3.231116971315681
Validation loss: 2.4808739539606015

Epoch: 6| Step: 13
Training loss: 2.2838024335081726
Validation loss: 2.4779352780442054

Epoch: 243| Step: 0
Training loss: 2.6528589481453557
Validation loss: 2.4838062516864214

Epoch: 6| Step: 1
Training loss: 3.328504084099374
Validation loss: 2.50216267471835

Epoch: 6| Step: 2
Training loss: 2.0797067230046973
Validation loss: 2.5109627205174854

Epoch: 6| Step: 3
Training loss: 2.939331133265922
Validation loss: 2.5167444808600976

Epoch: 6| Step: 4
Training loss: 2.538112803159564
Validation loss: 2.544878879703627

Epoch: 6| Step: 5
Training loss: 2.8894287933484457
Validation loss: 2.5781179309299342

Epoch: 6| Step: 6
Training loss: 3.0079543835752287
Validation loss: 2.6035381013039607

Epoch: 6| Step: 7
Training loss: 3.079622320823775
Validation loss: 2.5986131991357837

Epoch: 6| Step: 8
Training loss: 2.3722635868088253
Validation loss: 2.549584089442958

Epoch: 6| Step: 9
Training loss: 1.780726439511209
Validation loss: 2.5171031019593424

Epoch: 6| Step: 10
Training loss: 3.236789557667443
Validation loss: 2.489349931638261

Epoch: 6| Step: 11
Training loss: 2.94549122882781
Validation loss: 2.4833464807213415

Epoch: 6| Step: 12
Training loss: 3.012132272397083
Validation loss: 2.483273731146026

Epoch: 6| Step: 13
Training loss: 2.620865608667543
Validation loss: 2.467969040605001

Epoch: 244| Step: 0
Training loss: 2.7041849693145257
Validation loss: 2.463703112677991

Epoch: 6| Step: 1
Training loss: 2.8751622029863717
Validation loss: 2.46200300420973

Epoch: 6| Step: 2
Training loss: 2.6157207877099213
Validation loss: 2.4691722639069145

Epoch: 6| Step: 3
Training loss: 3.2431883220919673
Validation loss: 2.48098810062411

Epoch: 6| Step: 4
Training loss: 3.3931757038829975
Validation loss: 2.4688045007108657

Epoch: 6| Step: 5
Training loss: 2.406849377777332
Validation loss: 2.4875121433924035

Epoch: 6| Step: 6
Training loss: 3.0044976534009793
Validation loss: 2.496028789598236

Epoch: 6| Step: 7
Training loss: 2.956854508836338
Validation loss: 2.5062568098795115

Epoch: 6| Step: 8
Training loss: 2.6990917302896666
Validation loss: 2.4858579579104894

Epoch: 6| Step: 9
Training loss: 2.87421738297144
Validation loss: 2.4829322240834535

Epoch: 6| Step: 10
Training loss: 2.4945017434467913
Validation loss: 2.472579841085726

Epoch: 6| Step: 11
Training loss: 2.268089900392982
Validation loss: 2.473276974556368

Epoch: 6| Step: 12
Training loss: 2.730633950318109
Validation loss: 2.464051425162012

Epoch: 6| Step: 13
Training loss: 2.803054291546748
Validation loss: 2.4689105827844133

Epoch: 245| Step: 0
Training loss: 2.694964400217324
Validation loss: 2.4723697448351003

Epoch: 6| Step: 1
Training loss: 2.718849794156719
Validation loss: 2.477184439731766

Epoch: 6| Step: 2
Training loss: 3.4462222327662366
Validation loss: 2.490959224580129

Epoch: 6| Step: 3
Training loss: 3.205833964283736
Validation loss: 2.4911450604509295

Epoch: 6| Step: 4
Training loss: 2.923400806908288
Validation loss: 2.5049406402411147

Epoch: 6| Step: 5
Training loss: 2.408989078077337
Validation loss: 2.540353607994826

Epoch: 6| Step: 6
Training loss: 2.9548820637309845
Validation loss: 2.5501968389451717

Epoch: 6| Step: 7
Training loss: 1.8443234731779592
Validation loss: 2.5687748575780565

Epoch: 6| Step: 8
Training loss: 2.950386513427229
Validation loss: 2.5671409471444306

Epoch: 6| Step: 9
Training loss: 2.040540371552244
Validation loss: 2.5702878131286213

Epoch: 6| Step: 10
Training loss: 3.1310742662041475
Validation loss: 2.5495396272694872

Epoch: 6| Step: 11
Training loss: 2.6509461351330685
Validation loss: 2.5508451004829733

Epoch: 6| Step: 12
Training loss: 2.5976142134169202
Validation loss: 2.5237864139414166

Epoch: 6| Step: 13
Training loss: 3.2397598921734225
Validation loss: 2.5111276461183034

Epoch: 246| Step: 0
Training loss: 3.2702024948930886
Validation loss: 2.4932807064847085

Epoch: 6| Step: 1
Training loss: 2.7385785734568264
Validation loss: 2.4742478150893654

Epoch: 6| Step: 2
Training loss: 2.4514557814604387
Validation loss: 2.4619686957949765

Epoch: 6| Step: 3
Training loss: 3.039573646061089
Validation loss: 2.4646178607912654

Epoch: 6| Step: 4
Training loss: 3.035955807350392
Validation loss: 2.467105077076077

Epoch: 6| Step: 5
Training loss: 3.00457034068582
Validation loss: 2.4619664778313517

Epoch: 6| Step: 6
Training loss: 3.3677816552721898
Validation loss: 2.463537022667928

Epoch: 6| Step: 7
Training loss: 2.7079239951642706
Validation loss: 2.461141736888407

Epoch: 6| Step: 8
Training loss: 2.2340248740577926
Validation loss: 2.4693258373826494

Epoch: 6| Step: 9
Training loss: 3.0427484199959247
Validation loss: 2.4629132583826103

Epoch: 6| Step: 10
Training loss: 2.4425378236994892
Validation loss: 2.465982861704209

Epoch: 6| Step: 11
Training loss: 2.34628138850926
Validation loss: 2.462295974517182

Epoch: 6| Step: 12
Training loss: 3.1049546302023856
Validation loss: 2.4734305429633174

Epoch: 6| Step: 13
Training loss: 1.9496877102332806
Validation loss: 2.4972989205973795

Epoch: 247| Step: 0
Training loss: 2.5826861175798537
Validation loss: 2.504843084642392

Epoch: 6| Step: 1
Training loss: 2.7770197554625002
Validation loss: 2.529198524563811

Epoch: 6| Step: 2
Training loss: 3.5273054929836345
Validation loss: 2.5251769550997687

Epoch: 6| Step: 3
Training loss: 3.0779504097159216
Validation loss: 2.540339855031836

Epoch: 6| Step: 4
Training loss: 2.4411464705539982
Validation loss: 2.5424042419443484

Epoch: 6| Step: 5
Training loss: 2.6306751302817237
Validation loss: 2.5616490921932527

Epoch: 6| Step: 6
Training loss: 3.1034203641374414
Validation loss: 2.57753089580163

Epoch: 6| Step: 7
Training loss: 2.676369261349357
Validation loss: 2.553171617834896

Epoch: 6| Step: 8
Training loss: 2.903330987987016
Validation loss: 2.504758720344179

Epoch: 6| Step: 9
Training loss: 2.660453253255232
Validation loss: 2.488671853202576

Epoch: 6| Step: 10
Training loss: 2.404592364178638
Validation loss: 2.4711430951132685

Epoch: 6| Step: 11
Training loss: 2.9323916556530363
Validation loss: 2.475381484907866

Epoch: 6| Step: 12
Training loss: 2.3995356825861944
Validation loss: 2.47451915418352

Epoch: 6| Step: 13
Training loss: 2.6535701921867565
Validation loss: 2.4799322967851123

Epoch: 248| Step: 0
Training loss: 3.183378359757456
Validation loss: 2.485739188614505

Epoch: 6| Step: 1
Training loss: 2.8351356907149303
Validation loss: 2.4865582599211526

Epoch: 6| Step: 2
Training loss: 2.336722965931764
Validation loss: 2.484227611637651

Epoch: 6| Step: 3
Training loss: 2.5190052518407477
Validation loss: 2.481352667961257

Epoch: 6| Step: 4
Training loss: 3.179357563118712
Validation loss: 2.478754586517074

Epoch: 6| Step: 5
Training loss: 2.98686330227458
Validation loss: 2.4756148110730294

Epoch: 6| Step: 6
Training loss: 2.9963937382919967
Validation loss: 2.479551678531945

Epoch: 6| Step: 7
Training loss: 2.4690899192408677
Validation loss: 2.4890953588364195

Epoch: 6| Step: 8
Training loss: 2.4811547479675298
Validation loss: 2.502066568213257

Epoch: 6| Step: 9
Training loss: 2.8282243911391687
Validation loss: 2.5103230262121103

Epoch: 6| Step: 10
Training loss: 2.956231153883754
Validation loss: 2.5107220815527906

Epoch: 6| Step: 11
Training loss: 2.464670698133533
Validation loss: 2.521995496887177

Epoch: 6| Step: 12
Training loss: 2.422126215549622
Validation loss: 2.5390344186244387

Epoch: 6| Step: 13
Training loss: 3.440299957194313
Validation loss: 2.555379051868169

Epoch: 249| Step: 0
Training loss: 3.155328294990859
Validation loss: 2.547366732661767

Epoch: 6| Step: 1
Training loss: 2.787727955619238
Validation loss: 2.5185257972534623

Epoch: 6| Step: 2
Training loss: 2.906186010825288
Validation loss: 2.521225326137281

Epoch: 6| Step: 3
Training loss: 2.8687586832018983
Validation loss: 2.5067010654817787

Epoch: 6| Step: 4
Training loss: 2.814989641079044
Validation loss: 2.5089580281147543

Epoch: 6| Step: 5
Training loss: 3.2167841268911026
Validation loss: 2.503109967467735

Epoch: 6| Step: 6
Training loss: 2.391882571887971
Validation loss: 2.5093738846302673

Epoch: 6| Step: 7
Training loss: 2.7151250240701232
Validation loss: 2.514554984369967

Epoch: 6| Step: 8
Training loss: 2.411471559778005
Validation loss: 2.5143603172156075

Epoch: 6| Step: 9
Training loss: 2.916071222468978
Validation loss: 2.500848086901333

Epoch: 6| Step: 10
Training loss: 2.23897053222892
Validation loss: 2.5023481744245846

Epoch: 6| Step: 11
Training loss: 2.743188745883964
Validation loss: 2.4984438390585404

Epoch: 6| Step: 12
Training loss: 2.636990365061049
Validation loss: 2.486947189578181

Epoch: 6| Step: 13
Training loss: 3.190852178991347
Validation loss: 2.483124763881885

Epoch: 250| Step: 0
Training loss: 2.437364721212278
Validation loss: 2.4900810192870257

Epoch: 6| Step: 1
Training loss: 2.742224190404025
Validation loss: 2.4918402345873956

Epoch: 6| Step: 2
Training loss: 2.920883581697009
Validation loss: 2.491107175856478

Epoch: 6| Step: 3
Training loss: 3.242103961649677
Validation loss: 2.4791040923640004

Epoch: 6| Step: 4
Training loss: 2.8675061290512502
Validation loss: 2.508172217800183

Epoch: 6| Step: 5
Training loss: 2.8733469315610547
Validation loss: 2.487790241562189

Epoch: 6| Step: 6
Training loss: 2.2380445531615396
Validation loss: 2.5292774953070816

Epoch: 6| Step: 7
Training loss: 2.5035098233678776
Validation loss: 2.52414524113788

Epoch: 6| Step: 8
Training loss: 2.644617256783198
Validation loss: 2.532551626122154

Epoch: 6| Step: 9
Training loss: 3.21035991588011
Validation loss: 2.5468344182834657

Epoch: 6| Step: 10
Training loss: 3.163583526150165
Validation loss: 2.512993378414597

Epoch: 6| Step: 11
Training loss: 2.921743134975651
Validation loss: 2.492443753422654

Epoch: 6| Step: 12
Training loss: 2.6385177239738455
Validation loss: 2.491010560483017

Epoch: 6| Step: 13
Training loss: 2.087256996493048
Validation loss: 2.479478134177936

Epoch: 251| Step: 0
Training loss: 2.984234711710055
Validation loss: 2.47343441729131

Epoch: 6| Step: 1
Training loss: 3.0333903513429665
Validation loss: 2.4658514972194334

Epoch: 6| Step: 2
Training loss: 2.6491165415903724
Validation loss: 2.455122874622039

Epoch: 6| Step: 3
Training loss: 2.622996519376574
Validation loss: 2.4590201877441107

Epoch: 6| Step: 4
Training loss: 3.0862128412567538
Validation loss: 2.4510940234127307

Epoch: 6| Step: 5
Training loss: 2.871355649460031
Validation loss: 2.4539647365586146

Epoch: 6| Step: 6
Training loss: 2.473957990679801
Validation loss: 2.451444729816958

Epoch: 6| Step: 7
Training loss: 2.529324022537707
Validation loss: 2.4570327816953252

Epoch: 6| Step: 8
Training loss: 2.70955981335929
Validation loss: 2.4549158165862965

Epoch: 6| Step: 9
Training loss: 2.2703344397853242
Validation loss: 2.4550362430840607

Epoch: 6| Step: 10
Training loss: 3.409785264712814
Validation loss: 2.4707715755670767

Epoch: 6| Step: 11
Training loss: 2.9159700015792107
Validation loss: 2.5103468383369107

Epoch: 6| Step: 12
Training loss: 2.762942289961238
Validation loss: 2.5393995613162446

Epoch: 6| Step: 13
Training loss: 2.1535322227786375
Validation loss: 2.558956590625546

Epoch: 252| Step: 0
Training loss: 2.616144684240651
Validation loss: 2.6272342683772996

Epoch: 6| Step: 1
Training loss: 2.840055476170677
Validation loss: 2.6634977980744936

Epoch: 6| Step: 2
Training loss: 3.3006021123727134
Validation loss: 2.6949278378804635

Epoch: 6| Step: 3
Training loss: 2.5640125927667943
Validation loss: 2.723089757088722

Epoch: 6| Step: 4
Training loss: 2.2518574147592583
Validation loss: 2.717044813730237

Epoch: 6| Step: 5
Training loss: 2.93323548182646
Validation loss: 2.6920081539138137

Epoch: 6| Step: 6
Training loss: 3.180382804861928
Validation loss: 2.6704778121503057

Epoch: 6| Step: 7
Training loss: 2.7522167461284144
Validation loss: 2.5830652052803647

Epoch: 6| Step: 8
Training loss: 2.4706981070848255
Validation loss: 2.5189352053080905

Epoch: 6| Step: 9
Training loss: 2.3956801876933707
Validation loss: 2.4905051170224564

Epoch: 6| Step: 10
Training loss: 2.6651117043049695
Validation loss: 2.4802311722863437

Epoch: 6| Step: 11
Training loss: 2.8484002961006327
Validation loss: 2.4587950574430537

Epoch: 6| Step: 12
Training loss: 3.3157738396029828
Validation loss: 2.465515291738182

Epoch: 6| Step: 13
Training loss: 2.9811060712767543
Validation loss: 2.454464675869158

Epoch: 253| Step: 0
Training loss: 2.462180462548891
Validation loss: 2.4545158465272783

Epoch: 6| Step: 1
Training loss: 2.667931217136251
Validation loss: 2.4559700147169106

Epoch: 6| Step: 2
Training loss: 1.9679781899522997
Validation loss: 2.457296470516339

Epoch: 6| Step: 3
Training loss: 2.5474221045627083
Validation loss: 2.4572865551927103

Epoch: 6| Step: 4
Training loss: 2.997933947893552
Validation loss: 2.4571355491754083

Epoch: 6| Step: 5
Training loss: 3.1539367659186013
Validation loss: 2.4549072513161425

Epoch: 6| Step: 6
Training loss: 2.6277821647207764
Validation loss: 2.4689393412894844

Epoch: 6| Step: 7
Training loss: 2.7881782903925125
Validation loss: 2.489276221564213

Epoch: 6| Step: 8
Training loss: 2.9572942458075797
Validation loss: 2.5082614330610253

Epoch: 6| Step: 9
Training loss: 2.5688486307704625
Validation loss: 2.5247313055449494

Epoch: 6| Step: 10
Training loss: 3.4106702209684787
Validation loss: 2.5496286956324488

Epoch: 6| Step: 11
Training loss: 2.9167893156876064
Validation loss: 2.5456349715922135

Epoch: 6| Step: 12
Training loss: 2.5890650894805907
Validation loss: 2.526886950786137

Epoch: 6| Step: 13
Training loss: 3.1092612087571907
Validation loss: 2.53466986366444

Epoch: 254| Step: 0
Training loss: 2.5807271136838033
Validation loss: 2.489780506947225

Epoch: 6| Step: 1
Training loss: 2.561476433250348
Validation loss: 2.4830990610067465

Epoch: 6| Step: 2
Training loss: 2.6041102492261174
Validation loss: 2.4542355656769517

Epoch: 6| Step: 3
Training loss: 2.5674400163606284
Validation loss: 2.464631151106411

Epoch: 6| Step: 4
Training loss: 2.788465419938601
Validation loss: 2.4687216276690886

Epoch: 6| Step: 5
Training loss: 3.0349031438565435
Validation loss: 2.4698928964294424

Epoch: 6| Step: 6
Training loss: 2.791983477327704
Validation loss: 2.469016453673516

Epoch: 6| Step: 7
Training loss: 2.7884151444762195
Validation loss: 2.468805237984546

Epoch: 6| Step: 8
Training loss: 2.94636399499716
Validation loss: 2.453112012072291

Epoch: 6| Step: 9
Training loss: 2.9310075151235857
Validation loss: 2.4523366760443124

Epoch: 6| Step: 10
Training loss: 2.6633124316385617
Validation loss: 2.4449803297339257

Epoch: 6| Step: 11
Training loss: 2.8413553740483257
Validation loss: 2.4584310340828908

Epoch: 6| Step: 12
Training loss: 3.1841234761070734
Validation loss: 2.4653617398202488

Epoch: 6| Step: 13
Training loss: 2.507897301306688
Validation loss: 2.500689575500888

Epoch: 255| Step: 0
Training loss: 2.891772068385682
Validation loss: 2.5016298682663027

Epoch: 6| Step: 1
Training loss: 2.7535074581047314
Validation loss: 2.5307566087081708

Epoch: 6| Step: 2
Training loss: 3.294235546943345
Validation loss: 2.557498662277031

Epoch: 6| Step: 3
Training loss: 3.4306529430683734
Validation loss: 2.6131776411190817

Epoch: 6| Step: 4
Training loss: 2.4685815681269463
Validation loss: 2.5827994421780267

Epoch: 6| Step: 5
Training loss: 2.466966975033959
Validation loss: 2.5715680469909317

Epoch: 6| Step: 6
Training loss: 2.617899054974453
Validation loss: 2.5565046661597437

Epoch: 6| Step: 7
Training loss: 2.762734319493096
Validation loss: 2.5405078484096277

Epoch: 6| Step: 8
Training loss: 2.377427918056444
Validation loss: 2.5411820750756053

Epoch: 6| Step: 9
Training loss: 2.7636232189842356
Validation loss: 2.517508444052513

Epoch: 6| Step: 10
Training loss: 2.6677304073454713
Validation loss: 2.5108778103701

Epoch: 6| Step: 11
Training loss: 3.319148175910118
Validation loss: 2.5090503854383397

Epoch: 6| Step: 12
Training loss: 2.442406533365167
Validation loss: 2.504159642680737

Epoch: 6| Step: 13
Training loss: 2.1071428709976896
Validation loss: 2.498813649148861

Epoch: 256| Step: 0
Training loss: 2.3058717949952974
Validation loss: 2.504627301537467

Epoch: 6| Step: 1
Training loss: 3.0630000737682486
Validation loss: 2.5000824022556487

Epoch: 6| Step: 2
Training loss: 2.46785256214044
Validation loss: 2.5028540798805166

Epoch: 6| Step: 3
Training loss: 2.4407331103266343
Validation loss: 2.509006001950659

Epoch: 6| Step: 4
Training loss: 2.627756488015744
Validation loss: 2.5352885849463838

Epoch: 6| Step: 5
Training loss: 2.9023637937775244
Validation loss: 2.556844065421141

Epoch: 6| Step: 6
Training loss: 3.1562436547546056
Validation loss: 2.5612792597157727

Epoch: 6| Step: 7
Training loss: 2.7497490855101963
Validation loss: 2.5536180560616217

Epoch: 6| Step: 8
Training loss: 2.747447997165979
Validation loss: 2.5105860826625435

Epoch: 6| Step: 9
Training loss: 2.684641093697896
Validation loss: 2.5162595665609158

Epoch: 6| Step: 10
Training loss: 2.9104531360726957
Validation loss: 2.5260990793858396

Epoch: 6| Step: 11
Training loss: 3.0890498051553763
Validation loss: 2.489429774117831

Epoch: 6| Step: 12
Training loss: 3.143450173249008
Validation loss: 2.4760366958019584

Epoch: 6| Step: 13
Training loss: 1.746436783038266
Validation loss: 2.4599378204891127

Epoch: 257| Step: 0
Training loss: 2.874494757002042
Validation loss: 2.4529622738981165

Epoch: 6| Step: 1
Training loss: 3.1632267354430628
Validation loss: 2.446444410923188

Epoch: 6| Step: 2
Training loss: 2.1482618225404497
Validation loss: 2.4409199900077496

Epoch: 6| Step: 3
Training loss: 2.683858133810704
Validation loss: 2.44381292668265

Epoch: 6| Step: 4
Training loss: 2.917439730690997
Validation loss: 2.44913180599057

Epoch: 6| Step: 5
Training loss: 3.2757145284184785
Validation loss: 2.4496111654803054

Epoch: 6| Step: 6
Training loss: 2.6502466914675633
Validation loss: 2.4550344929415733

Epoch: 6| Step: 7
Training loss: 3.182043753715766
Validation loss: 2.4587564888058546

Epoch: 6| Step: 8
Training loss: 2.6119558397330955
Validation loss: 2.4594808861405504

Epoch: 6| Step: 9
Training loss: 2.3407891454042136
Validation loss: 2.4743165747821125

Epoch: 6| Step: 10
Training loss: 2.888837601948176
Validation loss: 2.4824252943254512

Epoch: 6| Step: 11
Training loss: 2.140159612033184
Validation loss: 2.4901929742121047

Epoch: 6| Step: 12
Training loss: 3.013914107194237
Validation loss: 2.4900558139353897

Epoch: 6| Step: 13
Training loss: 2.399662562331508
Validation loss: 2.4941354311911628

Epoch: 258| Step: 0
Training loss: 2.846669134575208
Validation loss: 2.489531929212083

Epoch: 6| Step: 1
Training loss: 2.894602745089537
Validation loss: 2.5043991228586244

Epoch: 6| Step: 2
Training loss: 2.2666113449339202
Validation loss: 2.5054065724065504

Epoch: 6| Step: 3
Training loss: 2.7226054598697007
Validation loss: 2.4907245393094235

Epoch: 6| Step: 4
Training loss: 2.957342778958141
Validation loss: 2.5024401927818

Epoch: 6| Step: 5
Training loss: 2.8618100330104133
Validation loss: 2.4960203849248894

Epoch: 6| Step: 6
Training loss: 2.8493873138395944
Validation loss: 2.5020298930797473

Epoch: 6| Step: 7
Training loss: 2.9276597800495407
Validation loss: 2.497801230118124

Epoch: 6| Step: 8
Training loss: 2.0582300548923835
Validation loss: 2.4786554934804585

Epoch: 6| Step: 9
Training loss: 3.161438256356572
Validation loss: 2.476641500148596

Epoch: 6| Step: 10
Training loss: 2.5935423434676403
Validation loss: 2.479394577716993

Epoch: 6| Step: 11
Training loss: 2.704700077232591
Validation loss: 2.481187617338441

Epoch: 6| Step: 12
Training loss: 2.4042972716541104
Validation loss: 2.476325358130836

Epoch: 6| Step: 13
Training loss: 3.3165481590939327
Validation loss: 2.47799053060329

Epoch: 259| Step: 0
Training loss: 2.5768032500506197
Validation loss: 2.4813171863229013

Epoch: 6| Step: 1
Training loss: 3.3314249933883047
Validation loss: 2.490989051011536

Epoch: 6| Step: 2
Training loss: 2.3958668803202174
Validation loss: 2.492505393537775

Epoch: 6| Step: 3
Training loss: 2.7928500917211183
Validation loss: 2.483777034672318

Epoch: 6| Step: 4
Training loss: 2.7066226447178887
Validation loss: 2.492105403513233

Epoch: 6| Step: 5
Training loss: 2.855932112017824
Validation loss: 2.4999503171762636

Epoch: 6| Step: 6
Training loss: 2.7997026694332106
Validation loss: 2.4916234447442567

Epoch: 6| Step: 7
Training loss: 2.270302830128774
Validation loss: 2.478749286003511

Epoch: 6| Step: 8
Training loss: 2.577667935632742
Validation loss: 2.4832133340620794

Epoch: 6| Step: 9
Training loss: 2.740097945196043
Validation loss: 2.48126661177778

Epoch: 6| Step: 10
Training loss: 2.5293979226919516
Validation loss: 2.488409593503171

Epoch: 6| Step: 11
Training loss: 3.133621682095109
Validation loss: 2.498716107756215

Epoch: 6| Step: 12
Training loss: 2.771981042254908
Validation loss: 2.5082156813340064

Epoch: 6| Step: 13
Training loss: 2.9328127861530895
Validation loss: 2.4996329786729907

Epoch: 260| Step: 0
Training loss: 2.859382337550353
Validation loss: 2.50059013374645

Epoch: 6| Step: 1
Training loss: 2.5539924072594875
Validation loss: 2.4885951417754426

Epoch: 6| Step: 2
Training loss: 2.5411602099346142
Validation loss: 2.500882331441485

Epoch: 6| Step: 3
Training loss: 2.783001637443584
Validation loss: 2.517706243787792

Epoch: 6| Step: 4
Training loss: 3.3962740621883216
Validation loss: 2.5215328740550516

Epoch: 6| Step: 5
Training loss: 2.5723989071273796
Validation loss: 2.5220897106137605

Epoch: 6| Step: 6
Training loss: 1.7881544715668638
Validation loss: 2.539952570774628

Epoch: 6| Step: 7
Training loss: 3.1516840172311396
Validation loss: 2.5539553806429094

Epoch: 6| Step: 8
Training loss: 2.3485412452914174
Validation loss: 2.5755732114057412

Epoch: 6| Step: 9
Training loss: 2.901226172523987
Validation loss: 2.6103503466531035

Epoch: 6| Step: 10
Training loss: 3.0144176536925924
Validation loss: 2.5961918234527066

Epoch: 6| Step: 11
Training loss: 2.8423528907305537
Validation loss: 2.5355933007784173

Epoch: 6| Step: 12
Training loss: 2.78132226400041
Validation loss: 2.5080779437997656

Epoch: 6| Step: 13
Training loss: 2.7682377601889683
Validation loss: 2.490330641653404

Epoch: 261| Step: 0
Training loss: 2.6717097359571094
Validation loss: 2.467060984356825

Epoch: 6| Step: 1
Training loss: 2.4641417941129404
Validation loss: 2.456586514010247

Epoch: 6| Step: 2
Training loss: 2.910443961239191
Validation loss: 2.4557953834099195

Epoch: 6| Step: 3
Training loss: 2.8038584724494586
Validation loss: 2.4512983708429097

Epoch: 6| Step: 4
Training loss: 2.456172920551282
Validation loss: 2.4553899477986065

Epoch: 6| Step: 5
Training loss: 3.118436099597904
Validation loss: 2.457583110817977

Epoch: 6| Step: 6
Training loss: 2.277202830853923
Validation loss: 2.473528958134434

Epoch: 6| Step: 7
Training loss: 2.426199319537156
Validation loss: 2.482031400635226

Epoch: 6| Step: 8
Training loss: 2.3991706050810886
Validation loss: 2.5167006486721206

Epoch: 6| Step: 9
Training loss: 2.848454534884608
Validation loss: 2.549960343850592

Epoch: 6| Step: 10
Training loss: 3.3795877993088603
Validation loss: 2.6351974569937817

Epoch: 6| Step: 11
Training loss: 2.7045343506645576
Validation loss: 2.6960156660575696

Epoch: 6| Step: 12
Training loss: 3.521088284322569
Validation loss: 2.7356000452501865

Epoch: 6| Step: 13
Training loss: 2.8635222163163676
Validation loss: 2.701346647071826

Epoch: 262| Step: 0
Training loss: 2.4463116734234482
Validation loss: 2.6347758639137515

Epoch: 6| Step: 1
Training loss: 2.482181180244516
Validation loss: 2.565496150257038

Epoch: 6| Step: 2
Training loss: 3.383476350765071
Validation loss: 2.5101135449428464

Epoch: 6| Step: 3
Training loss: 2.52291836432713
Validation loss: 2.47352430041178

Epoch: 6| Step: 4
Training loss: 3.104878457066282
Validation loss: 2.4493474007880436

Epoch: 6| Step: 5
Training loss: 3.211227069801082
Validation loss: 2.4494230544950732

Epoch: 6| Step: 6
Training loss: 2.6414418057629856
Validation loss: 2.4526892847850754

Epoch: 6| Step: 7
Training loss: 3.1036523653206944
Validation loss: 2.4533279457268313

Epoch: 6| Step: 8
Training loss: 2.2553534927226444
Validation loss: 2.453215574984661

Epoch: 6| Step: 9
Training loss: 2.701925110626917
Validation loss: 2.4589833095026656

Epoch: 6| Step: 10
Training loss: 2.171577707704835
Validation loss: 2.4650174563636225

Epoch: 6| Step: 11
Training loss: 2.6467848040673325
Validation loss: 2.4674661456724887

Epoch: 6| Step: 12
Training loss: 3.009083348102075
Validation loss: 2.4788733078111056

Epoch: 6| Step: 13
Training loss: 2.7355540322190124
Validation loss: 2.4854664710289986

Epoch: 263| Step: 0
Training loss: 2.87587459364012
Validation loss: 2.505336629676983

Epoch: 6| Step: 1
Training loss: 2.746765401864906
Validation loss: 2.5380198902820887

Epoch: 6| Step: 2
Training loss: 2.863205475474577
Validation loss: 2.541329092292194

Epoch: 6| Step: 3
Training loss: 2.744670732549671
Validation loss: 2.5562654631716355

Epoch: 6| Step: 4
Training loss: 2.1651471996703213
Validation loss: 2.530597636631471

Epoch: 6| Step: 5
Training loss: 3.3151249112031786
Validation loss: 2.525260759086336

Epoch: 6| Step: 6
Training loss: 2.597115688439659
Validation loss: 2.502960228577711

Epoch: 6| Step: 7
Training loss: 2.4020452050267886
Validation loss: 2.4860118886573783

Epoch: 6| Step: 8
Training loss: 3.036490560701932
Validation loss: 2.4719592235628367

Epoch: 6| Step: 9
Training loss: 2.4013706624555478
Validation loss: 2.4711095329526747

Epoch: 6| Step: 10
Training loss: 2.663158184955772
Validation loss: 2.4782996184597463

Epoch: 6| Step: 11
Training loss: 2.858481512501351
Validation loss: 2.4727041453739784

Epoch: 6| Step: 12
Training loss: 3.112790173099235
Validation loss: 2.4767541484823337

Epoch: 6| Step: 13
Training loss: 2.2146442733901788
Validation loss: 2.48061073135232

Epoch: 264| Step: 0
Training loss: 2.7669882997210986
Validation loss: 2.4733078030181086

Epoch: 6| Step: 1
Training loss: 2.419802264812862
Validation loss: 2.484563887278969

Epoch: 6| Step: 2
Training loss: 2.533344485442394
Validation loss: 2.4734601029581333

Epoch: 6| Step: 3
Training loss: 3.0425830836616257
Validation loss: 2.4749147562275544

Epoch: 6| Step: 4
Training loss: 2.664155930477684
Validation loss: 2.4652758497266922

Epoch: 6| Step: 5
Training loss: 2.91761918635962
Validation loss: 2.4725097323574223

Epoch: 6| Step: 6
Training loss: 2.1325582834845327
Validation loss: 2.4688799735482414

Epoch: 6| Step: 7
Training loss: 2.8302090379594516
Validation loss: 2.4731454139075173

Epoch: 6| Step: 8
Training loss: 3.1031689843386436
Validation loss: 2.4836444158451485

Epoch: 6| Step: 9
Training loss: 3.15159096882283
Validation loss: 2.4792728413400873

Epoch: 6| Step: 10
Training loss: 2.6482769852780077
Validation loss: 2.4787617579646017

Epoch: 6| Step: 11
Training loss: 2.693120889153733
Validation loss: 2.489364481223513

Epoch: 6| Step: 12
Training loss: 2.661069021597809
Validation loss: 2.491713733525561

Epoch: 6| Step: 13
Training loss: 1.8914389631490516
Validation loss: 2.488991003272191

Epoch: 265| Step: 0
Training loss: 2.7757061343413088
Validation loss: 2.50951301290088

Epoch: 6| Step: 1
Training loss: 2.696394285852014
Validation loss: 2.5109188772471787

Epoch: 6| Step: 2
Training loss: 2.5300461531941427
Validation loss: 2.5094112824896295

Epoch: 6| Step: 3
Training loss: 2.108878070083128
Validation loss: 2.519120107003823

Epoch: 6| Step: 4
Training loss: 2.8587999443091556
Validation loss: 2.4920910345240324

Epoch: 6| Step: 5
Training loss: 2.9358608461192226
Validation loss: 2.4936870669710016

Epoch: 6| Step: 6
Training loss: 2.951656238688984
Validation loss: 2.499073599351149

Epoch: 6| Step: 7
Training loss: 3.128570957768573
Validation loss: 2.4889327132866046

Epoch: 6| Step: 8
Training loss: 2.8750573857426702
Validation loss: 2.4870237961840553

Epoch: 6| Step: 9
Training loss: 2.5735078099089486
Validation loss: 2.4826408076626096

Epoch: 6| Step: 10
Training loss: 2.632147096488897
Validation loss: 2.4789103234747367

Epoch: 6| Step: 11
Training loss: 2.7366649521122657
Validation loss: 2.4864430358262997

Epoch: 6| Step: 12
Training loss: 2.612976603862025
Validation loss: 2.4975859985060556

Epoch: 6| Step: 13
Training loss: 2.153421066591265
Validation loss: 2.5014939879156928

Epoch: 266| Step: 0
Training loss: 3.095368549546165
Validation loss: 2.519263259003978

Epoch: 6| Step: 1
Training loss: 2.919583814564767
Validation loss: 2.524309293272659

Epoch: 6| Step: 2
Training loss: 2.3341404563397368
Validation loss: 2.5260109219056

Epoch: 6| Step: 3
Training loss: 3.0549331917458153
Validation loss: 2.5303426625678402

Epoch: 6| Step: 4
Training loss: 2.779015833142102
Validation loss: 2.525895059634063

Epoch: 6| Step: 5
Training loss: 2.6340895818308576
Validation loss: 2.5056968865640252

Epoch: 6| Step: 6
Training loss: 2.713604760977104
Validation loss: 2.4952777511718205

Epoch: 6| Step: 7
Training loss: 2.2598697569122845
Validation loss: 2.4681294965833023

Epoch: 6| Step: 8
Training loss: 2.186243840989194
Validation loss: 2.469111173022489

Epoch: 6| Step: 9
Training loss: 2.322119834179966
Validation loss: 2.4708451144937387

Epoch: 6| Step: 10
Training loss: 2.3213792397424062
Validation loss: 2.4541839410414967

Epoch: 6| Step: 11
Training loss: 3.173128979484883
Validation loss: 2.4575323743541175

Epoch: 6| Step: 12
Training loss: 2.7659307623339284
Validation loss: 2.456508329959163

Epoch: 6| Step: 13
Training loss: 3.434450218480777
Validation loss: 2.4618030854727033

Epoch: 267| Step: 0
Training loss: 2.6713725727468858
Validation loss: 2.4757818967240133

Epoch: 6| Step: 1
Training loss: 2.882378274112488
Validation loss: 2.4978656969442548

Epoch: 6| Step: 2
Training loss: 2.408708480690927
Validation loss: 2.5173397447930843

Epoch: 6| Step: 3
Training loss: 2.80145519453198
Validation loss: 2.5303720997450627

Epoch: 6| Step: 4
Training loss: 2.0818767669221314
Validation loss: 2.5405220434581066

Epoch: 6| Step: 5
Training loss: 2.3731724584182707
Validation loss: 2.5344058819112223

Epoch: 6| Step: 6
Training loss: 2.710409679203473
Validation loss: 2.5292446893650378

Epoch: 6| Step: 7
Training loss: 3.1224814374874375
Validation loss: 2.533828853769134

Epoch: 6| Step: 8
Training loss: 2.336510527378287
Validation loss: 2.533661928209088

Epoch: 6| Step: 9
Training loss: 2.7207116252166657
Validation loss: 2.554424473927309

Epoch: 6| Step: 10
Training loss: 2.858542566083601
Validation loss: 2.552624479124628

Epoch: 6| Step: 11
Training loss: 2.942053978109073
Validation loss: 2.520098938660798

Epoch: 6| Step: 12
Training loss: 3.1015425136123986
Validation loss: 2.5086839483255456

Epoch: 6| Step: 13
Training loss: 2.6103891925832383
Validation loss: 2.4845332211848983

Epoch: 268| Step: 0
Training loss: 1.1272468382485845
Validation loss: 2.466348381537765

Epoch: 6| Step: 1
Training loss: 2.525979477159457
Validation loss: 2.4629931168378283

Epoch: 6| Step: 2
Training loss: 2.8120416055751374
Validation loss: 2.4560391932189387

Epoch: 6| Step: 3
Training loss: 2.2260633477985
Validation loss: 2.4505026220343904

Epoch: 6| Step: 4
Training loss: 3.125141903516424
Validation loss: 2.457628693148634

Epoch: 6| Step: 5
Training loss: 2.5855679435234675
Validation loss: 2.46998043298994

Epoch: 6| Step: 6
Training loss: 2.3762997534056787
Validation loss: 2.5113209024496768

Epoch: 6| Step: 7
Training loss: 2.9097803474716484
Validation loss: 2.510606557303557

Epoch: 6| Step: 8
Training loss: 2.9356392993704628
Validation loss: 2.53139723806947

Epoch: 6| Step: 9
Training loss: 2.9066660593481335
Validation loss: 2.55722842459818

Epoch: 6| Step: 10
Training loss: 3.301173151891911
Validation loss: 2.567147406317149

Epoch: 6| Step: 11
Training loss: 2.4826575526771197
Validation loss: 2.5712348676134904

Epoch: 6| Step: 12
Training loss: 3.3278249685953205
Validation loss: 2.5741976340418726

Epoch: 6| Step: 13
Training loss: 2.2987467087789004
Validation loss: 2.542473353511287

Epoch: 269| Step: 0
Training loss: 2.2499977747588282
Validation loss: 2.549824729588649

Epoch: 6| Step: 1
Training loss: 3.2268474166728556
Validation loss: 2.581399174357691

Epoch: 6| Step: 2
Training loss: 2.3633141381363454
Validation loss: 2.5629215499007683

Epoch: 6| Step: 3
Training loss: 2.839006093146654
Validation loss: 2.541315108552595

Epoch: 6| Step: 4
Training loss: 3.067592512879317
Validation loss: 2.5311994467806445

Epoch: 6| Step: 5
Training loss: 2.8083733696352353
Validation loss: 2.495018952909463

Epoch: 6| Step: 6
Training loss: 2.458886445317139
Validation loss: 2.4908896501410163

Epoch: 6| Step: 7
Training loss: 2.8326916996594993
Validation loss: 2.4812037563584055

Epoch: 6| Step: 8
Training loss: 2.6481005248900757
Validation loss: 2.4766830674295592

Epoch: 6| Step: 9
Training loss: 2.382827008312645
Validation loss: 2.4866045121961977

Epoch: 6| Step: 10
Training loss: 2.6965784610457617
Validation loss: 2.485162853720608

Epoch: 6| Step: 11
Training loss: 2.5507364780299793
Validation loss: 2.4902819250892594

Epoch: 6| Step: 12
Training loss: 2.7623610552199276
Validation loss: 2.4763539270015036

Epoch: 6| Step: 13
Training loss: 2.642363929385001
Validation loss: 2.475291000168381

Epoch: 270| Step: 0
Training loss: 2.959987195992485
Validation loss: 2.4719845252829864

Epoch: 6| Step: 1
Training loss: 3.0241723559877838
Validation loss: 2.495886302780821

Epoch: 6| Step: 2
Training loss: 2.7138532190008005
Validation loss: 2.5236308061483674

Epoch: 6| Step: 3
Training loss: 3.0249584226667157
Validation loss: 2.5390871269855495

Epoch: 6| Step: 4
Training loss: 2.6624404578199994
Validation loss: 2.5442878632813053

Epoch: 6| Step: 5
Training loss: 1.902858030138173
Validation loss: 2.539425204664375

Epoch: 6| Step: 6
Training loss: 2.231148370730996
Validation loss: 2.5144318084801442

Epoch: 6| Step: 7
Training loss: 2.473295156367609
Validation loss: 2.489013446695056

Epoch: 6| Step: 8
Training loss: 2.677507765159424
Validation loss: 2.4812772516318513

Epoch: 6| Step: 9
Training loss: 2.9692844913589873
Validation loss: 2.47244246893132

Epoch: 6| Step: 10
Training loss: 2.464616042559906
Validation loss: 2.4732318454400355

Epoch: 6| Step: 11
Training loss: 3.0754987482779406
Validation loss: 2.475762309369345

Epoch: 6| Step: 12
Training loss: 2.7776931135202734
Validation loss: 2.4804834457296736

Epoch: 6| Step: 13
Training loss: 2.791909695954762
Validation loss: 2.5032756715879554

Epoch: 271| Step: 0
Training loss: 2.2874480403147723
Validation loss: 2.528456750633177

Epoch: 6| Step: 1
Training loss: 2.3667535667404644
Validation loss: 2.5275016629206983

Epoch: 6| Step: 2
Training loss: 2.8004762278608473
Validation loss: 2.54869329843752

Epoch: 6| Step: 3
Training loss: 2.7225587846558947
Validation loss: 2.580657316923995

Epoch: 6| Step: 4
Training loss: 3.0174551830740337
Validation loss: 2.6055985253137295

Epoch: 6| Step: 5
Training loss: 2.6678159343245618
Validation loss: 2.6677799320489717

Epoch: 6| Step: 6
Training loss: 3.2817083129513422
Validation loss: 2.6618207902201436

Epoch: 6| Step: 7
Training loss: 2.0573434815139
Validation loss: 2.629073804882764

Epoch: 6| Step: 8
Training loss: 2.7190797101620325
Validation loss: 2.6159803015716867

Epoch: 6| Step: 9
Training loss: 2.4969484779135875
Validation loss: 2.578361019643411

Epoch: 6| Step: 10
Training loss: 3.2258981385583154
Validation loss: 2.5359731442904527

Epoch: 6| Step: 11
Training loss: 3.0787246042645333
Validation loss: 2.5030964277426317

Epoch: 6| Step: 12
Training loss: 2.076051064364888
Validation loss: 2.487951485719611

Epoch: 6| Step: 13
Training loss: 2.626557660027469
Validation loss: 2.466380443099717

Epoch: 272| Step: 0
Training loss: 2.8748795857298597
Validation loss: 2.4677469072661133

Epoch: 6| Step: 1
Training loss: 3.0056829667207996
Validation loss: 2.451899932003244

Epoch: 6| Step: 2
Training loss: 2.7445218401801044
Validation loss: 2.448116803458781

Epoch: 6| Step: 3
Training loss: 2.6025190914454193
Validation loss: 2.4545386365121358

Epoch: 6| Step: 4
Training loss: 3.093698982819962
Validation loss: 2.454722828641924

Epoch: 6| Step: 5
Training loss: 2.067851666175711
Validation loss: 2.4482636557722706

Epoch: 6| Step: 6
Training loss: 2.7894926193640175
Validation loss: 2.456570500247431

Epoch: 6| Step: 7
Training loss: 2.7265585650658837
Validation loss: 2.471437774363933

Epoch: 6| Step: 8
Training loss: 2.2028797635423754
Validation loss: 2.4894443191172253

Epoch: 6| Step: 9
Training loss: 2.797590622375846
Validation loss: 2.518282347475379

Epoch: 6| Step: 10
Training loss: 2.571725381645294
Validation loss: 2.5469591348424334

Epoch: 6| Step: 11
Training loss: 2.9052696625500687
Validation loss: 2.5659173657855545

Epoch: 6| Step: 12
Training loss: 2.7977186241323295
Validation loss: 2.548822222891294

Epoch: 6| Step: 13
Training loss: 2.863169669231911
Validation loss: 2.5125802891460776

Epoch: 273| Step: 0
Training loss: 2.612410373154201
Validation loss: 2.5006682589778566

Epoch: 6| Step: 1
Training loss: 2.8393433351659274
Validation loss: 2.4772790351206546

Epoch: 6| Step: 2
Training loss: 2.884850254767419
Validation loss: 2.4589338697101084

Epoch: 6| Step: 3
Training loss: 2.4521838283985313
Validation loss: 2.4482918295834915

Epoch: 6| Step: 4
Training loss: 3.0747848435470155
Validation loss: 2.4483055791987343

Epoch: 6| Step: 5
Training loss: 2.3351066413069095
Validation loss: 2.443022661935721

Epoch: 6| Step: 6
Training loss: 2.87265217324041
Validation loss: 2.44357962317456

Epoch: 6| Step: 7
Training loss: 2.7689394298361014
Validation loss: 2.4306864812681415

Epoch: 6| Step: 8
Training loss: 2.7371553073370087
Validation loss: 2.4486674319751196

Epoch: 6| Step: 9
Training loss: 2.9471581946954504
Validation loss: 2.4556899760475184

Epoch: 6| Step: 10
Training loss: 2.618631539590234
Validation loss: 2.4901170714946437

Epoch: 6| Step: 11
Training loss: 2.478475030757498
Validation loss: 2.525244770168809

Epoch: 6| Step: 12
Training loss: 2.2832833203409657
Validation loss: 2.5767056085164675

Epoch: 6| Step: 13
Training loss: 3.1309227321256294
Validation loss: 2.6076473170424177

Epoch: 274| Step: 0
Training loss: 2.6934975525706992
Validation loss: 2.6310839040098175

Epoch: 6| Step: 1
Training loss: 2.709519600886905
Validation loss: 2.642141921116963

Epoch: 6| Step: 2
Training loss: 2.7678485272532733
Validation loss: 2.628187084763263

Epoch: 6| Step: 3
Training loss: 2.6840882047096777
Validation loss: 2.618972998449532

Epoch: 6| Step: 4
Training loss: 2.794574665332746
Validation loss: 2.5760723356224227

Epoch: 6| Step: 5
Training loss: 3.1110592981595575
Validation loss: 2.520851052985631

Epoch: 6| Step: 6
Training loss: 2.0485603441172997
Validation loss: 2.489705109592418

Epoch: 6| Step: 7
Training loss: 2.63393588677007
Validation loss: 2.463371323171248

Epoch: 6| Step: 8
Training loss: 2.920591837594519
Validation loss: 2.451149118557482

Epoch: 6| Step: 9
Training loss: 2.663482871442902
Validation loss: 2.4367771154803286

Epoch: 6| Step: 10
Training loss: 2.5539137108788044
Validation loss: 2.4342641773915465

Epoch: 6| Step: 11
Training loss: 2.367877922468321
Validation loss: 2.4474753078592033

Epoch: 6| Step: 12
Training loss: 3.0850094715634553
Validation loss: 2.436708105547511

Epoch: 6| Step: 13
Training loss: 2.795469389042209
Validation loss: 2.444530417689879

Epoch: 275| Step: 0
Training loss: 2.564662021284042
Validation loss: 2.441866187039925

Epoch: 6| Step: 1
Training loss: 2.7987444719376686
Validation loss: 2.455484654056558

Epoch: 6| Step: 2
Training loss: 2.7434712852781513
Validation loss: 2.476390712198132

Epoch: 6| Step: 3
Training loss: 2.600291265165556
Validation loss: 2.500590949816859

Epoch: 6| Step: 4
Training loss: 2.7411481403677196
Validation loss: 2.522462753672492

Epoch: 6| Step: 5
Training loss: 2.4989378580195645
Validation loss: 2.5694533599488945

Epoch: 6| Step: 6
Training loss: 2.4351161156762466
Validation loss: 2.591920405301386

Epoch: 6| Step: 7
Training loss: 2.467754018244478
Validation loss: 2.5911007875651615

Epoch: 6| Step: 8
Training loss: 3.033657258592319
Validation loss: 2.5629079520505917

Epoch: 6| Step: 9
Training loss: 2.9188115180841305
Validation loss: 2.5474057097909455

Epoch: 6| Step: 10
Training loss: 2.552778831742763
Validation loss: 2.5119911943896867

Epoch: 6| Step: 11
Training loss: 3.079789539429234
Validation loss: 2.461198471615622

Epoch: 6| Step: 12
Training loss: 2.978815942851575
Validation loss: 2.4494505367619874

Epoch: 6| Step: 13
Training loss: 1.7313126342680845
Validation loss: 2.4347795292955468

Epoch: 276| Step: 0
Training loss: 3.048933849664323
Validation loss: 2.4374579990534655

Epoch: 6| Step: 1
Training loss: 2.7958443730037335
Validation loss: 2.438637767929446

Epoch: 6| Step: 2
Training loss: 2.450857487308412
Validation loss: 2.4332076553387023

Epoch: 6| Step: 3
Training loss: 2.4448630800505153
Validation loss: 2.4343730230775043

Epoch: 6| Step: 4
Training loss: 2.950512896417962
Validation loss: 2.4390640825419125

Epoch: 6| Step: 5
Training loss: 2.8393198235751593
Validation loss: 2.4427256714849914

Epoch: 6| Step: 6
Training loss: 3.074636738727728
Validation loss: 2.458079572302655

Epoch: 6| Step: 7
Training loss: 2.9236634029042134
Validation loss: 2.48123150034892

Epoch: 6| Step: 8
Training loss: 2.4402108401523366
Validation loss: 2.512858628760522

Epoch: 6| Step: 9
Training loss: 2.2121392209146196
Validation loss: 2.543044769858102

Epoch: 6| Step: 10
Training loss: 2.6442064905719285
Validation loss: 2.6053574224917084

Epoch: 6| Step: 11
Training loss: 3.0342034178445214
Validation loss: 2.6411015230531114

Epoch: 6| Step: 12
Training loss: 2.2405313895235177
Validation loss: 2.637161047879351

Epoch: 6| Step: 13
Training loss: 2.204898201804851
Validation loss: 2.601027038725742

Epoch: 277| Step: 0
Training loss: 2.7925712676076806
Validation loss: 2.5971736321773506

Epoch: 6| Step: 1
Training loss: 2.4455804160090486
Validation loss: 2.551355647867957

Epoch: 6| Step: 2
Training loss: 2.786446848812976
Validation loss: 2.5366100508392373

Epoch: 6| Step: 3
Training loss: 3.018157370072419
Validation loss: 2.5035809281619716

Epoch: 6| Step: 4
Training loss: 2.718149403848255
Validation loss: 2.4836381740682243

Epoch: 6| Step: 5
Training loss: 1.8437987498934483
Validation loss: 2.4649457789329703

Epoch: 6| Step: 6
Training loss: 3.3160493656436634
Validation loss: 2.4637013562054224

Epoch: 6| Step: 7
Training loss: 2.8000682311600213
Validation loss: 2.452672852565271

Epoch: 6| Step: 8
Training loss: 2.3667787507429296
Validation loss: 2.447371656025478

Epoch: 6| Step: 9
Training loss: 1.9100778637738072
Validation loss: 2.435339397366525

Epoch: 6| Step: 10
Training loss: 2.698375432151604
Validation loss: 2.447709607906366

Epoch: 6| Step: 11
Training loss: 2.5022828170022366
Validation loss: 2.4572726774282483

Epoch: 6| Step: 12
Training loss: 3.040406074758151
Validation loss: 2.4577218559333236

Epoch: 6| Step: 13
Training loss: 3.106171918229206
Validation loss: 2.467031782056605

Epoch: 278| Step: 0
Training loss: 3.0231490280966207
Validation loss: 2.478561866003276

Epoch: 6| Step: 1
Training loss: 2.4727247087062456
Validation loss: 2.5053884179571098

Epoch: 6| Step: 2
Training loss: 2.7105680978056603
Validation loss: 2.512160267107585

Epoch: 6| Step: 3
Training loss: 2.2285376638782055
Validation loss: 2.5068494253253797

Epoch: 6| Step: 4
Training loss: 2.0583961580189487
Validation loss: 2.5093305336161333

Epoch: 6| Step: 5
Training loss: 3.0336151334493744
Validation loss: 2.4918841933731017

Epoch: 6| Step: 6
Training loss: 2.7115495414112103
Validation loss: 2.472130986425512

Epoch: 6| Step: 7
Training loss: 3.229872513608331
Validation loss: 2.458874773356815

Epoch: 6| Step: 8
Training loss: 2.1714121373350603
Validation loss: 2.4465240189492237

Epoch: 6| Step: 9
Training loss: 2.112806679399268
Validation loss: 2.4517241680004913

Epoch: 6| Step: 10
Training loss: 2.7163034590241106
Validation loss: 2.442489481631775

Epoch: 6| Step: 11
Training loss: 2.6227004560256884
Validation loss: 2.4378030923518943

Epoch: 6| Step: 12
Training loss: 3.0255487054710004
Validation loss: 2.4548595898769876

Epoch: 6| Step: 13
Training loss: 3.248332843131323
Validation loss: 2.4616278744370526

Epoch: 279| Step: 0
Training loss: 2.533336391781751
Validation loss: 2.4853916112041214

Epoch: 6| Step: 1
Training loss: 2.78812971999336
Validation loss: 2.519789190078801

Epoch: 6| Step: 2
Training loss: 2.387455753096158
Validation loss: 2.5463071132499344

Epoch: 6| Step: 3
Training loss: 2.42022323887084
Validation loss: 2.578282382967919

Epoch: 6| Step: 4
Training loss: 2.2574027458525032
Validation loss: 2.6006564740093645

Epoch: 6| Step: 5
Training loss: 3.288464707078321
Validation loss: 2.6257393055178277

Epoch: 6| Step: 6
Training loss: 3.009180803064147
Validation loss: 2.6149786027053965

Epoch: 6| Step: 7
Training loss: 3.0683861044746004
Validation loss: 2.5845525770714857

Epoch: 6| Step: 8
Training loss: 2.205018116191047
Validation loss: 2.5376137986835747

Epoch: 6| Step: 9
Training loss: 2.886993271262583
Validation loss: 2.5141755589899173

Epoch: 6| Step: 10
Training loss: 2.2569202389193443
Validation loss: 2.483323449264295

Epoch: 6| Step: 11
Training loss: 3.2087810914004864
Validation loss: 2.4645170987942353

Epoch: 6| Step: 12
Training loss: 2.259972829064622
Validation loss: 2.4333351951397586

Epoch: 6| Step: 13
Training loss: 2.6078957573529435
Validation loss: 2.435514491747886

Epoch: 280| Step: 0
Training loss: 2.323773407143606
Validation loss: 2.43119637014477

Epoch: 6| Step: 1
Training loss: 2.491272091535511
Validation loss: 2.430434893197654

Epoch: 6| Step: 2
Training loss: 2.6630406363606625
Validation loss: 2.4412371360699012

Epoch: 6| Step: 3
Training loss: 2.5453557825125963
Validation loss: 2.4514962489996095

Epoch: 6| Step: 4
Training loss: 2.310202204453945
Validation loss: 2.4632930464094094

Epoch: 6| Step: 5
Training loss: 2.6026403811774212
Validation loss: 2.4987663157894393

Epoch: 6| Step: 6
Training loss: 2.817363856630338
Validation loss: 2.5286882949342164

Epoch: 6| Step: 7
Training loss: 2.6487982850221585
Validation loss: 2.613719492704962

Epoch: 6| Step: 8
Training loss: 2.9786145603445706
Validation loss: 2.5998264738379806

Epoch: 6| Step: 9
Training loss: 2.9496487941843523
Validation loss: 2.613084343208825

Epoch: 6| Step: 10
Training loss: 2.4575553783801447
Validation loss: 2.6402181423699362

Epoch: 6| Step: 11
Training loss: 2.7436727213132523
Validation loss: 2.5925226540962636

Epoch: 6| Step: 12
Training loss: 3.0936344009534635
Validation loss: 2.5532713923377357

Epoch: 6| Step: 13
Training loss: 2.832474877699764
Validation loss: 2.511664804871826

Epoch: 281| Step: 0
Training loss: 2.0734760801151215
Validation loss: 2.474884323801101

Epoch: 6| Step: 1
Training loss: 2.584312458503946
Validation loss: 2.454571612681615

Epoch: 6| Step: 2
Training loss: 2.7048306238308677
Validation loss: 2.439598532694913

Epoch: 6| Step: 3
Training loss: 2.471586505244207
Validation loss: 2.4267306056766853

Epoch: 6| Step: 4
Training loss: 2.8868872318475303
Validation loss: 2.4304291086271577

Epoch: 6| Step: 5
Training loss: 2.5387286626988788
Validation loss: 2.430141046711264

Epoch: 6| Step: 6
Training loss: 3.0897526974771594
Validation loss: 2.4338156929889276

Epoch: 6| Step: 7
Training loss: 3.0832464532382504
Validation loss: 2.4264883243046467

Epoch: 6| Step: 8
Training loss: 3.0951359274354586
Validation loss: 2.4440899747806317

Epoch: 6| Step: 9
Training loss: 2.3101683537950164
Validation loss: 2.462438524785515

Epoch: 6| Step: 10
Training loss: 2.73644235115239
Validation loss: 2.4575343814253654

Epoch: 6| Step: 11
Training loss: 2.9185827954775614
Validation loss: 2.4743009389400927

Epoch: 6| Step: 12
Training loss: 2.6472019250373378
Validation loss: 2.462317567010762

Epoch: 6| Step: 13
Training loss: 1.9046136054709415
Validation loss: 2.4684594926981913

Epoch: 282| Step: 0
Training loss: 2.7163636707548706
Validation loss: 2.4776610641018273

Epoch: 6| Step: 1
Training loss: 2.864894854628381
Validation loss: 2.4895802207498603

Epoch: 6| Step: 2
Training loss: 3.190470190523819
Validation loss: 2.4978912843076606

Epoch: 6| Step: 3
Training loss: 2.978179732597299
Validation loss: 2.5062245045626548

Epoch: 6| Step: 4
Training loss: 2.64198322465236
Validation loss: 2.527566851031676

Epoch: 6| Step: 5
Training loss: 2.802879409493276
Validation loss: 2.553793993855097

Epoch: 6| Step: 6
Training loss: 2.4932085295498387
Validation loss: 2.552140118032284

Epoch: 6| Step: 7
Training loss: 2.4139244262319153
Validation loss: 2.567163927664576

Epoch: 6| Step: 8
Training loss: 2.8374957382909556
Validation loss: 2.56024129401743

Epoch: 6| Step: 9
Training loss: 2.8148705558760407
Validation loss: 2.552473018814147

Epoch: 6| Step: 10
Training loss: 1.7681293112903513
Validation loss: 2.5410887634285033

Epoch: 6| Step: 11
Training loss: 2.685339746984016
Validation loss: 2.529957960988099

Epoch: 6| Step: 12
Training loss: 1.931061722549799
Validation loss: 2.520008918142872

Epoch: 6| Step: 13
Training loss: 2.5398313326665565
Validation loss: 2.503729704298894

Epoch: 283| Step: 0
Training loss: 2.6288101156038954
Validation loss: 2.4709670347132784

Epoch: 6| Step: 1
Training loss: 2.5990421584886927
Validation loss: 2.4698684783892277

Epoch: 6| Step: 2
Training loss: 2.510624814934471
Validation loss: 2.469476018039897

Epoch: 6| Step: 3
Training loss: 2.219397974091425
Validation loss: 2.4623421255220443

Epoch: 6| Step: 4
Training loss: 2.242377402740404
Validation loss: 2.451951467760192

Epoch: 6| Step: 5
Training loss: 3.1696346996670606
Validation loss: 2.4568923281497015

Epoch: 6| Step: 6
Training loss: 2.8324450802171417
Validation loss: 2.461414482221819

Epoch: 6| Step: 7
Training loss: 2.4953258688418685
Validation loss: 2.463082719018185

Epoch: 6| Step: 8
Training loss: 2.750430160171133
Validation loss: 2.465741127844007

Epoch: 6| Step: 9
Training loss: 2.6201222832367517
Validation loss: 2.476188184449633

Epoch: 6| Step: 10
Training loss: 2.5868327731777945
Validation loss: 2.4648945991046762

Epoch: 6| Step: 11
Training loss: 2.471054643194298
Validation loss: 2.4484883440511256

Epoch: 6| Step: 12
Training loss: 3.0202365855836444
Validation loss: 2.4659525072191335

Epoch: 6| Step: 13
Training loss: 2.6501229923424754
Validation loss: 2.472903910586888

Epoch: 284| Step: 0
Training loss: 2.931304241402462
Validation loss: 2.4928394752842875

Epoch: 6| Step: 1
Training loss: 2.321195594918309
Validation loss: 2.5167257073717706

Epoch: 6| Step: 2
Training loss: 2.8344063316556585
Validation loss: 2.527383006506242

Epoch: 6| Step: 3
Training loss: 3.038227348997164
Validation loss: 2.5398247232746227

Epoch: 6| Step: 4
Training loss: 2.7622050891725762
Validation loss: 2.5439225293659686

Epoch: 6| Step: 5
Training loss: 2.474597042688292
Validation loss: 2.56749653896958

Epoch: 6| Step: 6
Training loss: 2.7666399111851985
Validation loss: 2.558623758901087

Epoch: 6| Step: 7
Training loss: 1.970286662743833
Validation loss: 2.5592266448195926

Epoch: 6| Step: 8
Training loss: 2.7719520566738325
Validation loss: 2.5335931064978183

Epoch: 6| Step: 9
Training loss: 2.853944384604409
Validation loss: 2.546329324329305

Epoch: 6| Step: 10
Training loss: 2.501429911810189
Validation loss: 2.5127440209847545

Epoch: 6| Step: 11
Training loss: 2.283349416727192
Validation loss: 2.5188190877910035

Epoch: 6| Step: 12
Training loss: 2.2115686816444047
Validation loss: 2.4862507370184495

Epoch: 6| Step: 13
Training loss: 2.9920281350348032
Validation loss: 2.4701370905399025

Epoch: 285| Step: 0
Training loss: 2.630132290083958
Validation loss: 2.4652477197481883

Epoch: 6| Step: 1
Training loss: 2.8402643325184824
Validation loss: 2.454483869168858

Epoch: 6| Step: 2
Training loss: 2.4096671277385817
Validation loss: 2.4595814740144717

Epoch: 6| Step: 3
Training loss: 3.155178076891923
Validation loss: 2.4682224894439195

Epoch: 6| Step: 4
Training loss: 2.681058038273294
Validation loss: 2.4655396000422227

Epoch: 6| Step: 5
Training loss: 2.897390335811977
Validation loss: 2.4480299417909364

Epoch: 6| Step: 6
Training loss: 2.4397338021576505
Validation loss: 2.4594980859026823

Epoch: 6| Step: 7
Training loss: 2.6896184511696664
Validation loss: 2.450404470556471

Epoch: 6| Step: 8
Training loss: 2.7079392268688003
Validation loss: 2.4663962330968934

Epoch: 6| Step: 9
Training loss: 2.6433071983106906
Validation loss: 2.4849915294428984

Epoch: 6| Step: 10
Training loss: 2.1630677508758596
Validation loss: 2.504284616242059

Epoch: 6| Step: 11
Training loss: 2.7158731608373827
Validation loss: 2.511246226344283

Epoch: 6| Step: 12
Training loss: 2.160903773730735
Validation loss: 2.523283521680451

Epoch: 6| Step: 13
Training loss: 2.1507911690214088
Validation loss: 2.545977066461964

Epoch: 286| Step: 0
Training loss: 2.1458484933064557
Validation loss: 2.5559854428061346

Epoch: 6| Step: 1
Training loss: 2.197864935629247
Validation loss: 2.567837712118233

Epoch: 6| Step: 2
Training loss: 3.1802741032153237
Validation loss: 2.524053886604136

Epoch: 6| Step: 3
Training loss: 2.498830330928075
Validation loss: 2.4951827839866514

Epoch: 6| Step: 4
Training loss: 2.8914714501818612
Validation loss: 2.470176429028953

Epoch: 6| Step: 5
Training loss: 2.8803503588977577
Validation loss: 2.4551879702650266

Epoch: 6| Step: 6
Training loss: 2.9236418741822123
Validation loss: 2.447867694400656

Epoch: 6| Step: 7
Training loss: 2.1308931650477385
Validation loss: 2.452717946050719

Epoch: 6| Step: 8
Training loss: 2.153875729991822
Validation loss: 2.449692385834993

Epoch: 6| Step: 9
Training loss: 2.621364619305409
Validation loss: 2.4468106974583557

Epoch: 6| Step: 10
Training loss: 2.9336776213460007
Validation loss: 2.4484433941191326

Epoch: 6| Step: 11
Training loss: 2.5777957590433336
Validation loss: 2.442408811076723

Epoch: 6| Step: 12
Training loss: 2.807257364850274
Validation loss: 2.4883071172490814

Epoch: 6| Step: 13
Training loss: 2.455965766282952
Validation loss: 2.505439497091757

Epoch: 287| Step: 0
Training loss: 2.4017313354948655
Validation loss: 2.5116965002756872

Epoch: 6| Step: 1
Training loss: 2.9009597374095506
Validation loss: 2.5354692415148166

Epoch: 6| Step: 2
Training loss: 2.3566493781110753
Validation loss: 2.558789375652608

Epoch: 6| Step: 3
Training loss: 2.596817225285231
Validation loss: 2.5404128948459777

Epoch: 6| Step: 4
Training loss: 2.676799140619481
Validation loss: 2.509015485541201

Epoch: 6| Step: 5
Training loss: 2.268996893109363
Validation loss: 2.4684078809728853

Epoch: 6| Step: 6
Training loss: 2.646405636224891
Validation loss: 2.4480015586597665

Epoch: 6| Step: 7
Training loss: 2.7680596448943926
Validation loss: 2.4375031131780247

Epoch: 6| Step: 8
Training loss: 2.5970119509063943
Validation loss: 2.443605541874082

Epoch: 6| Step: 9
Training loss: 2.502936926930615
Validation loss: 2.4345325784448404

Epoch: 6| Step: 10
Training loss: 3.016456449852207
Validation loss: 2.4348583194636677

Epoch: 6| Step: 11
Training loss: 2.439461236944829
Validation loss: 2.4465573158593954

Epoch: 6| Step: 12
Training loss: 2.5543078219151036
Validation loss: 2.442532647686628

Epoch: 6| Step: 13
Training loss: 2.9518743218028014
Validation loss: 2.483216315597982

Epoch: 288| Step: 0
Training loss: 2.3893807358289996
Validation loss: 2.5117931676135186

Epoch: 6| Step: 1
Training loss: 2.7540400912179264
Validation loss: 2.5297026893645995

Epoch: 6| Step: 2
Training loss: 2.099883703008838
Validation loss: 2.530316539129169

Epoch: 6| Step: 3
Training loss: 2.517258297512447
Validation loss: 2.517641235162359

Epoch: 6| Step: 4
Training loss: 2.918917377908737
Validation loss: 2.504991651750408

Epoch: 6| Step: 5
Training loss: 2.765721378694512
Validation loss: 2.468560242281965

Epoch: 6| Step: 6
Training loss: 2.235858344830229
Validation loss: 2.4745540552335044

Epoch: 6| Step: 7
Training loss: 2.3871482550067635
Validation loss: 2.470982357577007

Epoch: 6| Step: 8
Training loss: 2.357324681968838
Validation loss: 2.487261985637302

Epoch: 6| Step: 9
Training loss: 2.463238902503796
Validation loss: 2.5135880834215127

Epoch: 6| Step: 10
Training loss: 2.987991139410279
Validation loss: 2.5490712084924274

Epoch: 6| Step: 11
Training loss: 2.911359008477848
Validation loss: 2.518820735600031

Epoch: 6| Step: 12
Training loss: 2.5116566699292515
Validation loss: 2.4878362421686826

Epoch: 6| Step: 13
Training loss: 3.442211736662149
Validation loss: 2.462543446522095

Epoch: 289| Step: 0
Training loss: 2.44991281704609
Validation loss: 2.443495919791879

Epoch: 6| Step: 1
Training loss: 2.681182355405356
Validation loss: 2.4564538236068136

Epoch: 6| Step: 2
Training loss: 3.0977877075471576
Validation loss: 2.47466920096485

Epoch: 6| Step: 3
Training loss: 2.9003948995128432
Validation loss: 2.4857032049241825

Epoch: 6| Step: 4
Training loss: 3.004381477058528
Validation loss: 2.4838805317677948

Epoch: 6| Step: 5
Training loss: 2.5996817357333786
Validation loss: 2.4621450185510447

Epoch: 6| Step: 6
Training loss: 2.2921515443110216
Validation loss: 2.4416831118217357

Epoch: 6| Step: 7
Training loss: 1.933173178199773
Validation loss: 2.4353849154848906

Epoch: 6| Step: 8
Training loss: 1.8966212748686606
Validation loss: 2.426972753005653

Epoch: 6| Step: 9
Training loss: 2.8082900009057132
Validation loss: 2.426762959302811

Epoch: 6| Step: 10
Training loss: 2.581541352535786
Validation loss: 2.4406733505948917

Epoch: 6| Step: 11
Training loss: 2.897153009368401
Validation loss: 2.447958428823656

Epoch: 6| Step: 12
Training loss: 2.424206011852712
Validation loss: 2.4686044307651387

Epoch: 6| Step: 13
Training loss: 2.7116672731886147
Validation loss: 2.466287975362458

Epoch: 290| Step: 0
Training loss: 2.9183311799057954
Validation loss: 2.482481930929921

Epoch: 6| Step: 1
Training loss: 2.555251126424132
Validation loss: 2.5076864172076965

Epoch: 6| Step: 2
Training loss: 2.307446293066372
Validation loss: 2.497479804106996

Epoch: 6| Step: 3
Training loss: 2.4055291619540244
Validation loss: 2.4741306561404364

Epoch: 6| Step: 4
Training loss: 2.7683248326926844
Validation loss: 2.446315522583287

Epoch: 6| Step: 5
Training loss: 1.885297915545959
Validation loss: 2.4564323183744885

Epoch: 6| Step: 6
Training loss: 2.971719802350013
Validation loss: 2.4404637766285067

Epoch: 6| Step: 7
Training loss: 2.1870612658172686
Validation loss: 2.4494291589592847

Epoch: 6| Step: 8
Training loss: 2.3979226221385703
Validation loss: 2.450310675926054

Epoch: 6| Step: 9
Training loss: 2.668008695110696
Validation loss: 2.472472971851387

Epoch: 6| Step: 10
Training loss: 2.7827273099305123
Validation loss: 2.4741289609520654

Epoch: 6| Step: 11
Training loss: 2.9187126794426272
Validation loss: 2.470944395213117

Epoch: 6| Step: 12
Training loss: 2.5828551393325117
Validation loss: 2.5005924650825646

Epoch: 6| Step: 13
Training loss: 2.996510860846722
Validation loss: 2.5134695300426495

Epoch: 291| Step: 0
Training loss: 2.838944115529764
Validation loss: 2.541662841207637

Epoch: 6| Step: 1
Training loss: 2.98539388949181
Validation loss: 2.5439198487467265

Epoch: 6| Step: 2
Training loss: 2.5916596227552193
Validation loss: 2.5556823994885667

Epoch: 6| Step: 3
Training loss: 2.3825049029817196
Validation loss: 2.5124080600527074

Epoch: 6| Step: 4
Training loss: 2.181516802628425
Validation loss: 2.4946799503187664

Epoch: 6| Step: 5
Training loss: 2.8705839989124184
Validation loss: 2.490210018469135

Epoch: 6| Step: 6
Training loss: 2.805010933676233
Validation loss: 2.469446866099535

Epoch: 6| Step: 7
Training loss: 2.6678497153853766
Validation loss: 2.4653408857817762

Epoch: 6| Step: 8
Training loss: 2.8644990295951853
Validation loss: 2.4551282496384434

Epoch: 6| Step: 9
Training loss: 2.06057094180258
Validation loss: 2.4623756999464654

Epoch: 6| Step: 10
Training loss: 2.610138650039576
Validation loss: 2.4432614758860094

Epoch: 6| Step: 11
Training loss: 2.134763056272757
Validation loss: 2.4533918763450804

Epoch: 6| Step: 12
Training loss: 2.6698898168395866
Validation loss: 2.451513633407533

Epoch: 6| Step: 13
Training loss: 2.076132026641639
Validation loss: 2.445582284034258

Epoch: 292| Step: 0
Training loss: 1.7809398448023008
Validation loss: 2.4509113702326766

Epoch: 6| Step: 1
Training loss: 2.676934343241788
Validation loss: 2.4462854019336437

Epoch: 6| Step: 2
Training loss: 3.025001614152462
Validation loss: 2.448248702766705

Epoch: 6| Step: 3
Training loss: 2.8176787275544113
Validation loss: 2.4362598595315808

Epoch: 6| Step: 4
Training loss: 2.4592793040094887
Validation loss: 2.440090307099021

Epoch: 6| Step: 5
Training loss: 2.6842289912668353
Validation loss: 2.4554320481563185

Epoch: 6| Step: 6
Training loss: 2.454777446533946
Validation loss: 2.46103360948273

Epoch: 6| Step: 7
Training loss: 2.5455774851934443
Validation loss: 2.469250877559928

Epoch: 6| Step: 8
Training loss: 3.0474851339727103
Validation loss: 2.4878120878344085

Epoch: 6| Step: 9
Training loss: 2.900820510808156
Validation loss: 2.4717165095892653

Epoch: 6| Step: 10
Training loss: 2.3677942486699353
Validation loss: 2.4881750747308806

Epoch: 6| Step: 11
Training loss: 1.9333657486708367
Validation loss: 2.498779805108501

Epoch: 6| Step: 12
Training loss: 2.007648030829144
Validation loss: 2.4897772665883635

Epoch: 6| Step: 13
Training loss: 3.1219346843585436
Validation loss: 2.49631706313548

Epoch: 293| Step: 0
Training loss: 1.964929779778206
Validation loss: 2.5226082851065987

Epoch: 6| Step: 1
Training loss: 1.3544715929287796
Validation loss: 2.5577791188545635

Epoch: 6| Step: 2
Training loss: 2.8420562730623278
Validation loss: 2.5992601420681805

Epoch: 6| Step: 3
Training loss: 2.5382396127485825
Validation loss: 2.6124610270333832

Epoch: 6| Step: 4
Training loss: 2.7311413636414645
Validation loss: 2.5641673406440186

Epoch: 6| Step: 5
Training loss: 2.1604992557975478
Validation loss: 2.5047730054048625

Epoch: 6| Step: 6
Training loss: 2.4601928553155052
Validation loss: 2.4473312637955416

Epoch: 6| Step: 7
Training loss: 2.350285180015115
Validation loss: 2.4334620650812013

Epoch: 6| Step: 8
Training loss: 3.1825461694285653
Validation loss: 2.4236168003396497

Epoch: 6| Step: 9
Training loss: 2.590436174346756
Validation loss: 2.416021972507846

Epoch: 6| Step: 10
Training loss: 2.755044818105155
Validation loss: 2.4211255467681263

Epoch: 6| Step: 11
Training loss: 2.8770117977087395
Validation loss: 2.4279026196305384

Epoch: 6| Step: 12
Training loss: 2.8224143018797005
Validation loss: 2.4595884788331936

Epoch: 6| Step: 13
Training loss: 3.2512449667663215
Validation loss: 2.4692938234078685

Epoch: 294| Step: 0
Training loss: 2.5847399378989415
Validation loss: 2.4690040965409796

Epoch: 6| Step: 1
Training loss: 2.0679586596903907
Validation loss: 2.4799542081441146

Epoch: 6| Step: 2
Training loss: 3.0370683967794188
Validation loss: 2.495560588811079

Epoch: 6| Step: 3
Training loss: 2.7520072720509194
Validation loss: 2.5174553317573944

Epoch: 6| Step: 4
Training loss: 2.3842984928440725
Validation loss: 2.5314942098682676

Epoch: 6| Step: 5
Training loss: 1.9609595065762793
Validation loss: 2.5542382436745887

Epoch: 6| Step: 6
Training loss: 2.587828621751336
Validation loss: 2.5668930865832333

Epoch: 6| Step: 7
Training loss: 2.820624421430478
Validation loss: 2.547864298909975

Epoch: 6| Step: 8
Training loss: 2.644189990069315
Validation loss: 2.5289260970681475

Epoch: 6| Step: 9
Training loss: 2.876637531485124
Validation loss: 2.515178162019016

Epoch: 6| Step: 10
Training loss: 1.9933642932099331
Validation loss: 2.4982329430166508

Epoch: 6| Step: 11
Training loss: 2.4182130754866473
Validation loss: 2.460537931575204

Epoch: 6| Step: 12
Training loss: 2.7762734970616747
Validation loss: 2.448375819774046

Epoch: 6| Step: 13
Training loss: 2.5265953689352783
Validation loss: 2.4442398741807465

Epoch: 295| Step: 0
Training loss: 2.856442140756786
Validation loss: 2.471084547775109

Epoch: 6| Step: 1
Training loss: 2.570291536471786
Validation loss: 2.464314765566157

Epoch: 6| Step: 2
Training loss: 2.493086793137711
Validation loss: 2.471297551323972

Epoch: 6| Step: 3
Training loss: 2.636880601224626
Validation loss: 2.4657870833672755

Epoch: 6| Step: 4
Training loss: 2.890063422012042
Validation loss: 2.4831687499688817

Epoch: 6| Step: 5
Training loss: 2.8682694641426396
Validation loss: 2.491710065614007

Epoch: 6| Step: 6
Training loss: 2.1780570984248837
Validation loss: 2.5369242898623225

Epoch: 6| Step: 7
Training loss: 2.5970326987445476
Validation loss: 2.5839297697378596

Epoch: 6| Step: 8
Training loss: 2.593758824344929
Validation loss: 2.620258113061287

Epoch: 6| Step: 9
Training loss: 2.7167728294114726
Validation loss: 2.5639030853163343

Epoch: 6| Step: 10
Training loss: 2.392417385384986
Validation loss: 2.507322483122253

Epoch: 6| Step: 11
Training loss: 1.9408131236422788
Validation loss: 2.455824732893292

Epoch: 6| Step: 12
Training loss: 2.7318893906304407
Validation loss: 2.4423000170133307

Epoch: 6| Step: 13
Training loss: 2.1218516644864653
Validation loss: 2.41327173189878

Epoch: 296| Step: 0
Training loss: 2.6321835997759897
Validation loss: 2.4195891740583866

Epoch: 6| Step: 1
Training loss: 2.2501083983694743
Validation loss: 2.4229292782891467

Epoch: 6| Step: 2
Training loss: 2.4634589946873198
Validation loss: 2.403604504002382

Epoch: 6| Step: 3
Training loss: 2.9315596231939103
Validation loss: 2.419655823221331

Epoch: 6| Step: 4
Training loss: 2.6945043264422615
Validation loss: 2.4302443442700605

Epoch: 6| Step: 5
Training loss: 2.9078564869599193
Validation loss: 2.455915618549275

Epoch: 6| Step: 6
Training loss: 2.863872222490118
Validation loss: 2.4837154112119793

Epoch: 6| Step: 7
Training loss: 2.7519098065921717
Validation loss: 2.550502965000616

Epoch: 6| Step: 8
Training loss: 2.318904667962946
Validation loss: 2.592285438595235

Epoch: 6| Step: 9
Training loss: 1.8402810518567532
Validation loss: 2.6132408744863707

Epoch: 6| Step: 10
Training loss: 2.6517422293161386
Validation loss: 2.5839008861651767

Epoch: 6| Step: 11
Training loss: 2.4589691525231263
Validation loss: 2.5610554102545415

Epoch: 6| Step: 12
Training loss: 2.9367593683801463
Validation loss: 2.527594785960548

Epoch: 6| Step: 13
Training loss: 1.7336293585181535
Validation loss: 2.4962165382892363

Epoch: 297| Step: 0
Training loss: 1.8670536775396827
Validation loss: 2.4758424119314206

Epoch: 6| Step: 1
Training loss: 2.4560366317055
Validation loss: 2.456754840570763

Epoch: 6| Step: 2
Training loss: 2.7236392902284927
Validation loss: 2.45853994748133

Epoch: 6| Step: 3
Training loss: 2.5015545779977817
Validation loss: 2.435174210521405

Epoch: 6| Step: 4
Training loss: 2.810303996329993
Validation loss: 2.4548204816275945

Epoch: 6| Step: 5
Training loss: 2.463182763267141
Validation loss: 2.4583453565178033

Epoch: 6| Step: 6
Training loss: 1.886066584684972
Validation loss: 2.4662198171922536

Epoch: 6| Step: 7
Training loss: 2.8271707010133746
Validation loss: 2.5127235494769273

Epoch: 6| Step: 8
Training loss: 1.9006722565997687
Validation loss: 2.5232968118614987

Epoch: 6| Step: 9
Training loss: 2.331991581922881
Validation loss: 2.547874450360685

Epoch: 6| Step: 10
Training loss: 3.015246431771626
Validation loss: 2.5497565311482617

Epoch: 6| Step: 11
Training loss: 2.913055491376263
Validation loss: 2.528763307548936

Epoch: 6| Step: 12
Training loss: 3.1455211526610944
Validation loss: 2.503139852925484

Epoch: 6| Step: 13
Training loss: 2.103842253903339
Validation loss: 2.492427083412481

Epoch: 298| Step: 0
Training loss: 2.2722265420181924
Validation loss: 2.453125623895344

Epoch: 6| Step: 1
Training loss: 2.432574259143
Validation loss: 2.4421806882421686

Epoch: 6| Step: 2
Training loss: 2.985180491449105
Validation loss: 2.4274671454333414

Epoch: 6| Step: 3
Training loss: 2.9986764849372993
Validation loss: 2.4236861512906023

Epoch: 6| Step: 4
Training loss: 2.714803176686474
Validation loss: 2.418374001267399

Epoch: 6| Step: 5
Training loss: 2.4459522129609113
Validation loss: 2.42472409043656

Epoch: 6| Step: 6
Training loss: 2.199628287037438
Validation loss: 2.426993618248467

Epoch: 6| Step: 7
Training loss: 2.746512716139241
Validation loss: 2.434617363943538

Epoch: 6| Step: 8
Training loss: 2.759414164523345
Validation loss: 2.452869402751332

Epoch: 6| Step: 9
Training loss: 2.703492420782066
Validation loss: 2.500308165476708

Epoch: 6| Step: 10
Training loss: 2.363240088742787
Validation loss: 2.5397697802719974

Epoch: 6| Step: 11
Training loss: 2.412908877179732
Validation loss: 2.557577507963154

Epoch: 6| Step: 12
Training loss: 2.129165381663234
Validation loss: 2.600092542466985

Epoch: 6| Step: 13
Training loss: 1.822311482562899
Validation loss: 2.624230102478947

Epoch: 299| Step: 0
Training loss: 2.554262365028431
Validation loss: 2.651568351859665

Epoch: 6| Step: 1
Training loss: 2.963070385583899
Validation loss: 2.6198820404635295

Epoch: 6| Step: 2
Training loss: 2.749254559139791
Validation loss: 2.5418348944264673

Epoch: 6| Step: 3
Training loss: 1.8868331084729608
Validation loss: 2.5012212047126883

Epoch: 6| Step: 4
Training loss: 2.591975512812765
Validation loss: 2.4788830747380355

Epoch: 6| Step: 5
Training loss: 2.649968157882839
Validation loss: 2.4470466656123557

Epoch: 6| Step: 6
Training loss: 2.594297512131447
Validation loss: 2.4513707207966466

Epoch: 6| Step: 7
Training loss: 3.0815667598932057
Validation loss: 2.43224735952625

Epoch: 6| Step: 8
Training loss: 1.9574266593903562
Validation loss: 2.4492996955295965

Epoch: 6| Step: 9
Training loss: 2.569563086809173
Validation loss: 2.4648898241801978

Epoch: 6| Step: 10
Training loss: 2.600900560084854
Validation loss: 2.4642495125690784

Epoch: 6| Step: 11
Training loss: 2.126488556932219
Validation loss: 2.4550430932717733

Epoch: 6| Step: 12
Training loss: 2.702876614310668
Validation loss: 2.474194550217545

Epoch: 6| Step: 13
Training loss: 2.4363054135921343
Validation loss: 2.478260076854554

Epoch: 300| Step: 0
Training loss: 2.2857129062920905
Validation loss: 2.469497375425164

Epoch: 6| Step: 1
Training loss: 2.42147233138187
Validation loss: 2.4701554490637503

Epoch: 6| Step: 2
Training loss: 2.389273666719654
Validation loss: 2.4853090674229374

Epoch: 6| Step: 3
Training loss: 2.814552914228942
Validation loss: 2.485706248448795

Epoch: 6| Step: 4
Training loss: 2.7289668196872787
Validation loss: 2.467583341835408

Epoch: 6| Step: 5
Training loss: 2.92789935664448
Validation loss: 2.461778593959731

Epoch: 6| Step: 6
Training loss: 2.4290484112265096
Validation loss: 2.471558077308215

Epoch: 6| Step: 7
Training loss: 2.350211227339013
Validation loss: 2.5055906900977276

Epoch: 6| Step: 8
Training loss: 2.7718754197456876
Validation loss: 2.530720888270357

Epoch: 6| Step: 9
Training loss: 2.3658090739021427
Validation loss: 2.532598187342514

Epoch: 6| Step: 10
Training loss: 2.493031517297813
Validation loss: 2.5464383864654687

Epoch: 6| Step: 11
Training loss: 2.334971965155891
Validation loss: 2.526456908405936

Epoch: 6| Step: 12
Training loss: 2.4250060484505958
Validation loss: 2.520562845835935

Epoch: 6| Step: 13
Training loss: 2.2953853837108524
Validation loss: 2.5385532662983463

Epoch: 301| Step: 0
Training loss: 2.6585835696823343
Validation loss: 2.5340256294607215

Epoch: 6| Step: 1
Training loss: 2.560525738405563
Validation loss: 2.4980638718274752

Epoch: 6| Step: 2
Training loss: 2.4691636909864325
Validation loss: 2.4726908403901016

Epoch: 6| Step: 3
Training loss: 2.284936512872707
Validation loss: 2.452532274768226

Epoch: 6| Step: 4
Training loss: 2.600680914994889
Validation loss: 2.433335266781167

Epoch: 6| Step: 5
Training loss: 2.962711819186497
Validation loss: 2.4655054417014233

Epoch: 6| Step: 6
Training loss: 2.3842418948477047
Validation loss: 2.4618439744106504

Epoch: 6| Step: 7
Training loss: 2.580358289340298
Validation loss: 2.4869851942375356

Epoch: 6| Step: 8
Training loss: 1.8607901949679122
Validation loss: 2.5156573456121847

Epoch: 6| Step: 9
Training loss: 2.5183253988178445
Validation loss: 2.5938915575314163

Epoch: 6| Step: 10
Training loss: 2.7812542861734
Validation loss: 2.6516817084504996

Epoch: 6| Step: 11
Training loss: 3.190761020014006
Validation loss: 2.728226174068713

Epoch: 6| Step: 12
Training loss: 2.4148030055794645
Validation loss: 2.6354623174760636

Epoch: 6| Step: 13
Training loss: 2.0216021959550265
Validation loss: 2.5847497729356523

Epoch: 302| Step: 0
Training loss: 2.6982619802250896
Validation loss: 2.454613357351325

Epoch: 6| Step: 1
Training loss: 2.466760630579189
Validation loss: 2.412275647623575

Epoch: 6| Step: 2
Training loss: 2.0558498561377108
Validation loss: 2.4112633007652375

Epoch: 6| Step: 3
Training loss: 2.2870409895839448
Validation loss: 2.410213207388832

Epoch: 6| Step: 4
Training loss: 2.980788067552289
Validation loss: 2.428846087142219

Epoch: 6| Step: 5
Training loss: 2.886911512244324
Validation loss: 2.437034095430014

Epoch: 6| Step: 6
Training loss: 2.336343481194831
Validation loss: 2.4328476096406044

Epoch: 6| Step: 7
Training loss: 2.7380586933674733
Validation loss: 2.4268395552633666

Epoch: 6| Step: 8
Training loss: 2.0798846374211406
Validation loss: 2.414702504292762

Epoch: 6| Step: 9
Training loss: 2.884667438135234
Validation loss: 2.4143785635559127

Epoch: 6| Step: 10
Training loss: 3.192428966619176
Validation loss: 2.400081796516958

Epoch: 6| Step: 11
Training loss: 3.1605833917813033
Validation loss: 2.3953893334796637

Epoch: 6| Step: 12
Training loss: 2.66068714014618
Validation loss: 2.403577435072388

Epoch: 6| Step: 13
Training loss: 2.7392510235544214
Validation loss: 2.4281984267732892

Epoch: 303| Step: 0
Training loss: 2.9590138651067592
Validation loss: 2.4828846555932094

Epoch: 6| Step: 1
Training loss: 2.9587803534242907
Validation loss: 2.51921276239545

Epoch: 6| Step: 2
Training loss: 2.6979853107060996
Validation loss: 2.5463302123254588

Epoch: 6| Step: 3
Training loss: 2.7182548335107923
Validation loss: 2.56610920823521

Epoch: 6| Step: 4
Training loss: 2.3411839997967996
Validation loss: 2.5689878441807745

Epoch: 6| Step: 5
Training loss: 2.2992603605434523
Validation loss: 2.5537285265670424

Epoch: 6| Step: 6
Training loss: 2.5784632605390576
Validation loss: 2.5721375646416527

Epoch: 6| Step: 7
Training loss: 2.2694375417670005
Validation loss: 2.5889166998143662

Epoch: 6| Step: 8
Training loss: 2.292620812813409
Validation loss: 2.597168430214913

Epoch: 6| Step: 9
Training loss: 2.2380253777040955
Validation loss: 2.6130967773670237

Epoch: 6| Step: 10
Training loss: 2.696193738977336
Validation loss: 2.589347192254787

Epoch: 6| Step: 11
Training loss: 2.5197859761012333
Validation loss: 2.552122396471936

Epoch: 6| Step: 12
Training loss: 2.5677278735879105
Validation loss: 2.4916159656318784

Epoch: 6| Step: 13
Training loss: 2.0690753047139556
Validation loss: 2.4774033395623314

Epoch: 304| Step: 0
Training loss: 2.4671185088220358
Validation loss: 2.4557347072125197

Epoch: 6| Step: 1
Training loss: 2.260378109182658
Validation loss: 2.452145587554896

Epoch: 6| Step: 2
Training loss: 2.0637104066208076
Validation loss: 2.4623350738769023

Epoch: 6| Step: 3
Training loss: 2.5575692724726133
Validation loss: 2.4563613380828446

Epoch: 6| Step: 4
Training loss: 2.4175213475354864
Validation loss: 2.459671555889853

Epoch: 6| Step: 5
Training loss: 2.358594752763533
Validation loss: 2.4688648577745407

Epoch: 6| Step: 6
Training loss: 2.839076299219182
Validation loss: 2.4841513997140034

Epoch: 6| Step: 7
Training loss: 2.535348846690345
Validation loss: 2.4769583314880497

Epoch: 6| Step: 8
Training loss: 2.4683383646760704
Validation loss: 2.463963892296787

Epoch: 6| Step: 9
Training loss: 2.8463277347287903
Validation loss: 2.4533677125739395

Epoch: 6| Step: 10
Training loss: 2.432815941800211
Validation loss: 2.4459728942902084

Epoch: 6| Step: 11
Training loss: 2.090505448873262
Validation loss: 2.451586497247732

Epoch: 6| Step: 12
Training loss: 2.569971682322008
Validation loss: 2.4432280889401055

Epoch: 6| Step: 13
Training loss: 3.521572659909694
Validation loss: 2.4581050168885734

Epoch: 305| Step: 0
Training loss: 2.5848705476262905
Validation loss: 2.4689895038102443

Epoch: 6| Step: 1
Training loss: 2.407047486366552
Validation loss: 2.4883535873694

Epoch: 6| Step: 2
Training loss: 2.497332675892339
Validation loss: 2.4840452336908303

Epoch: 6| Step: 3
Training loss: 2.4502611877416407
Validation loss: 2.5076797353604756

Epoch: 6| Step: 4
Training loss: 2.6184019089558674
Validation loss: 2.5824491510703185

Epoch: 6| Step: 5
Training loss: 2.420664232380801
Validation loss: 2.617510512867866

Epoch: 6| Step: 6
Training loss: 1.9230721939468924
Validation loss: 2.6492110139878506

Epoch: 6| Step: 7
Training loss: 3.1213274929095736
Validation loss: 2.627612215174896

Epoch: 6| Step: 8
Training loss: 3.298921212237537
Validation loss: 2.571893328503679

Epoch: 6| Step: 9
Training loss: 1.8011847517702801
Validation loss: 2.5008065245568694

Epoch: 6| Step: 10
Training loss: 2.2871931860444334
Validation loss: 2.4679265775911925

Epoch: 6| Step: 11
Training loss: 2.9709509470924114
Validation loss: 2.4495697395402383

Epoch: 6| Step: 12
Training loss: 1.9789435478397304
Validation loss: 2.4317765943586336

Epoch: 6| Step: 13
Training loss: 2.112095187975402
Validation loss: 2.4247358728665453

Epoch: 306| Step: 0
Training loss: 2.6845438467797846
Validation loss: 2.420756748408441

Epoch: 6| Step: 1
Training loss: 2.6023944979197013
Validation loss: 2.4216568715299327

Epoch: 6| Step: 2
Training loss: 2.4176141481956264
Validation loss: 2.428268988730043

Epoch: 6| Step: 3
Training loss: 2.1116254316648027
Validation loss: 2.4413615629310814

Epoch: 6| Step: 4
Training loss: 2.500241935467518
Validation loss: 2.4331488397424677

Epoch: 6| Step: 5
Training loss: 2.6570765387408493
Validation loss: 2.457771301331031

Epoch: 6| Step: 6
Training loss: 2.568576771633447
Validation loss: 2.473623952412548

Epoch: 6| Step: 7
Training loss: 2.882450732350211
Validation loss: 2.4913150611570094

Epoch: 6| Step: 8
Training loss: 2.9765048284275206
Validation loss: 2.521881959003387

Epoch: 6| Step: 9
Training loss: 2.2306395563840815
Validation loss: 2.5599826399986205

Epoch: 6| Step: 10
Training loss: 2.5061147296578437
Validation loss: 2.58484928362862

Epoch: 6| Step: 11
Training loss: 1.9950258268630168
Validation loss: 2.6149439111828023

Epoch: 6| Step: 12
Training loss: 2.5618390417169623
Validation loss: 2.661345092940711

Epoch: 6| Step: 13
Training loss: 1.9916262565354563
Validation loss: 2.617844492193063

Epoch: 307| Step: 0
Training loss: 2.6676374595568837
Validation loss: 2.586273061544555

Epoch: 6| Step: 1
Training loss: 2.4915424337216585
Validation loss: 2.569247506430449

Epoch: 6| Step: 2
Training loss: 2.427400647378398
Validation loss: 2.5427371772570244

Epoch: 6| Step: 3
Training loss: 2.238090573589098
Validation loss: 2.5350025668334197

Epoch: 6| Step: 4
Training loss: 2.4901269508079578
Validation loss: 2.545352706571981

Epoch: 6| Step: 5
Training loss: 2.628826984723946
Validation loss: 2.53556021660986

Epoch: 6| Step: 6
Training loss: 2.839974548601896
Validation loss: 2.518871419704677

Epoch: 6| Step: 7
Training loss: 2.3674988998201063
Validation loss: 2.5073134230747853

Epoch: 6| Step: 8
Training loss: 1.7142054732026468
Validation loss: 2.4789520502370244

Epoch: 6| Step: 9
Training loss: 2.394485448302785
Validation loss: 2.4786274051949357

Epoch: 6| Step: 10
Training loss: 2.6490619114646425
Validation loss: 2.4470295150501356

Epoch: 6| Step: 11
Training loss: 2.594686775634694
Validation loss: 2.4647785505315296

Epoch: 6| Step: 12
Training loss: 2.2013303332424843
Validation loss: 2.4754082067279377

Epoch: 6| Step: 13
Training loss: 2.4802964037997364
Validation loss: 2.474044405223049

Epoch: 308| Step: 0
Training loss: 2.8912428736815343
Validation loss: 2.4578327825518125

Epoch: 6| Step: 1
Training loss: 1.9818504073566936
Validation loss: 2.4365888638049076

Epoch: 6| Step: 2
Training loss: 1.9533544787064179
Validation loss: 2.4405963647447275

Epoch: 6| Step: 3
Training loss: 2.570140055985111
Validation loss: 2.4256936624992336

Epoch: 6| Step: 4
Training loss: 2.7848050831056583
Validation loss: 2.4309834935545998

Epoch: 6| Step: 5
Training loss: 2.8621180983408245
Validation loss: 2.442311788129331

Epoch: 6| Step: 6
Training loss: 2.7888198875243395
Validation loss: 2.4428086330525924

Epoch: 6| Step: 7
Training loss: 2.4622023465497764
Validation loss: 2.4423112622406613

Epoch: 6| Step: 8
Training loss: 1.461066255658542
Validation loss: 2.4687379956424107

Epoch: 6| Step: 9
Training loss: 2.0717144519862885
Validation loss: 2.5097609058219406

Epoch: 6| Step: 10
Training loss: 2.605610581959971
Validation loss: 2.537184073975598

Epoch: 6| Step: 11
Training loss: 2.561058476344613
Validation loss: 2.5745077343028973

Epoch: 6| Step: 12
Training loss: 2.0255695436884804
Validation loss: 2.5920786488178504

Epoch: 6| Step: 13
Training loss: 2.798731097438234
Validation loss: 2.6372194396477933

Epoch: 309| Step: 0
Training loss: 2.1203128508284297
Validation loss: 2.617769906105079

Epoch: 6| Step: 1
Training loss: 2.5903201118216574
Validation loss: 2.6230740129981687

Epoch: 6| Step: 2
Training loss: 2.867463558534177
Validation loss: 2.5718669951389628

Epoch: 6| Step: 3
Training loss: 1.926570459799554
Validation loss: 2.502521722808768

Epoch: 6| Step: 4
Training loss: 1.918673073285832
Validation loss: 2.467862726917843

Epoch: 6| Step: 5
Training loss: 2.1740009688135706
Validation loss: 2.426089072634892

Epoch: 6| Step: 6
Training loss: 2.7769720201631567
Validation loss: 2.4139260707722867

Epoch: 6| Step: 7
Training loss: 2.961709598737428
Validation loss: 2.420460703313707

Epoch: 6| Step: 8
Training loss: 2.939525149657466
Validation loss: 2.4140737822490994

Epoch: 6| Step: 9
Training loss: 3.0555838516158205
Validation loss: 2.4190007011091974

Epoch: 6| Step: 10
Training loss: 1.7249404399375032
Validation loss: 2.4301105562636414

Epoch: 6| Step: 11
Training loss: 2.364980846271014
Validation loss: 2.4429900954945625

Epoch: 6| Step: 12
Training loss: 2.0071123735627365
Validation loss: 2.468851027440671

Epoch: 6| Step: 13
Training loss: 2.782918879399622
Validation loss: 2.5002152883471234

Epoch: 310| Step: 0
Training loss: 2.3774273163508597
Validation loss: 2.5484810581826642

Epoch: 6| Step: 1
Training loss: 2.5788663780737986
Validation loss: 2.611100747473275

Epoch: 6| Step: 2
Training loss: 2.436801516884465
Validation loss: 2.645499493156032

Epoch: 6| Step: 3
Training loss: 2.1604672530556623
Validation loss: 2.6056187413674623

Epoch: 6| Step: 4
Training loss: 2.836538372014926
Validation loss: 2.610936370282032

Epoch: 6| Step: 5
Training loss: 2.3610040964545873
Validation loss: 2.586366931123156

Epoch: 6| Step: 6
Training loss: 2.727099521512175
Validation loss: 2.540567563548486

Epoch: 6| Step: 7
Training loss: 3.0653234428765006
Validation loss: 2.490356339378006

Epoch: 6| Step: 8
Training loss: 1.8190571791022694
Validation loss: 2.4516031783056245

Epoch: 6| Step: 9
Training loss: 2.6746414764291875
Validation loss: 2.4432819397104604

Epoch: 6| Step: 10
Training loss: 2.2827853953836645
Validation loss: 2.451226771773197

Epoch: 6| Step: 11
Training loss: 2.6426226942726174
Validation loss: 2.4285945712638193

Epoch: 6| Step: 12
Training loss: 2.256630347150734
Validation loss: 2.4334689912756198

Epoch: 6| Step: 13
Training loss: 1.2841197184785762
Validation loss: 2.4361771916417467

Epoch: 311| Step: 0
Training loss: 2.278071658500278
Validation loss: 2.4449201652638406

Epoch: 6| Step: 1
Training loss: 2.9765097946346746
Validation loss: 2.4628603063087664

Epoch: 6| Step: 2
Training loss: 2.569273393682419
Validation loss: 2.483751178045517

Epoch: 6| Step: 3
Training loss: 2.2589727146481655
Validation loss: 2.5209671801271076

Epoch: 6| Step: 4
Training loss: 2.3617486192818937
Validation loss: 2.5707674994885927

Epoch: 6| Step: 5
Training loss: 2.5266425502837353
Validation loss: 2.6080645981604578

Epoch: 6| Step: 6
Training loss: 2.5117863338982884
Validation loss: 2.663014755700485

Epoch: 6| Step: 7
Training loss: 2.057592390913116
Validation loss: 2.6288195458629824

Epoch: 6| Step: 8
Training loss: 2.5453844447825014
Validation loss: 2.572012217029315

Epoch: 6| Step: 9
Training loss: 2.5382929648155144
Validation loss: 2.5036580927751255

Epoch: 6| Step: 10
Training loss: 2.0374351818797396
Validation loss: 2.496976593167286

Epoch: 6| Step: 11
Training loss: 2.166826046681447
Validation loss: 2.447570919491854

Epoch: 6| Step: 12
Training loss: 2.556563782028923
Validation loss: 2.4245380115889708

Epoch: 6| Step: 13
Training loss: 2.5662170990750104
Validation loss: 2.441600948847738

Epoch: 312| Step: 0
Training loss: 2.34987359214232
Validation loss: 2.452831079575459

Epoch: 6| Step: 1
Training loss: 1.871997591057882
Validation loss: 2.505438758319652

Epoch: 6| Step: 2
Training loss: 2.275044191371427
Validation loss: 2.5752144382264075

Epoch: 6| Step: 3
Training loss: 2.4251755405089166
Validation loss: 2.611474118155428

Epoch: 6| Step: 4
Training loss: 2.5869698207054843
Validation loss: 2.617537207787527

Epoch: 6| Step: 5
Training loss: 2.2616223988409216
Validation loss: 2.599402685589871

Epoch: 6| Step: 6
Training loss: 2.414453073651866
Validation loss: 2.5554875431964903

Epoch: 6| Step: 7
Training loss: 2.3599373860862407
Validation loss: 2.563089919598519

Epoch: 6| Step: 8
Training loss: 2.813101640564899
Validation loss: 2.5410237688594255

Epoch: 6| Step: 9
Training loss: 3.052402588135876
Validation loss: 2.5267950830768715

Epoch: 6| Step: 10
Training loss: 2.6579098171782354
Validation loss: 2.5103641358652116

Epoch: 6| Step: 11
Training loss: 2.143947945845381
Validation loss: 2.513073033849015

Epoch: 6| Step: 12
Training loss: 1.7811809994902108
Validation loss: 2.461631594462133

Epoch: 6| Step: 13
Training loss: 2.399710053572523
Validation loss: 2.439464196289926

Epoch: 313| Step: 0
Training loss: 2.120268771930146
Validation loss: 2.4386076323441204

Epoch: 6| Step: 1
Training loss: 3.216533008493238
Validation loss: 2.452925418499445

Epoch: 6| Step: 2
Training loss: 2.147869132028088
Validation loss: 2.486799779443087

Epoch: 6| Step: 3
Training loss: 2.3764534568474627
Validation loss: 2.495294596314595

Epoch: 6| Step: 4
Training loss: 2.3572378015593984
Validation loss: 2.5155128215016305

Epoch: 6| Step: 5
Training loss: 2.6365296698698004
Validation loss: 2.53081459484528

Epoch: 6| Step: 6
Training loss: 2.599833512477778
Validation loss: 2.5288105295508876

Epoch: 6| Step: 7
Training loss: 1.546760863129576
Validation loss: 2.508232049147783

Epoch: 6| Step: 8
Training loss: 2.1944808742326845
Validation loss: 2.5156414683913804

Epoch: 6| Step: 9
Training loss: 2.484980191587407
Validation loss: 2.5013750304410474

Epoch: 6| Step: 10
Training loss: 2.7519007962776767
Validation loss: 2.5100914147845224

Epoch: 6| Step: 11
Training loss: 2.0071763986597975
Validation loss: 2.521208428511193

Epoch: 6| Step: 12
Training loss: 2.4136392660634582
Validation loss: 2.560371931411776

Epoch: 6| Step: 13
Training loss: 2.587412065126694
Validation loss: 2.561404575581685

Epoch: 314| Step: 0
Training loss: 2.8091530276178376
Validation loss: 2.5640643637326326

Epoch: 6| Step: 1
Training loss: 1.830499785710072
Validation loss: 2.512517028393357

Epoch: 6| Step: 2
Training loss: 2.09348466245191
Validation loss: 2.4896261398857944

Epoch: 6| Step: 3
Training loss: 2.761187425407768
Validation loss: 2.467924269413871

Epoch: 6| Step: 4
Training loss: 2.481499693483714
Validation loss: 2.4613069250834148

Epoch: 6| Step: 5
Training loss: 2.0584404035923902
Validation loss: 2.435063107645093

Epoch: 6| Step: 6
Training loss: 2.7467269493018405
Validation loss: 2.415504227620852

Epoch: 6| Step: 7
Training loss: 1.7131539537111693
Validation loss: 2.4093374978126363

Epoch: 6| Step: 8
Training loss: 1.9580456813280012
Validation loss: 2.4187952239044734

Epoch: 6| Step: 9
Training loss: 2.756952167780959
Validation loss: 2.437094567139226

Epoch: 6| Step: 10
Training loss: 2.665292763437357
Validation loss: 2.4607074391064963

Epoch: 6| Step: 11
Training loss: 1.910183022902386
Validation loss: 2.498217740090244

Epoch: 6| Step: 12
Training loss: 2.5582555649293415
Validation loss: 2.554559646301726

Epoch: 6| Step: 13
Training loss: 2.6264109679563323
Validation loss: 2.5769523909715626

Epoch: 315| Step: 0
Training loss: 2.6034670894646035
Validation loss: 2.554335050896331

Epoch: 6| Step: 1
Training loss: 2.187238296112967
Validation loss: 2.516200149224327

Epoch: 6| Step: 2
Training loss: 2.368159632727816
Validation loss: 2.4974929277604305

Epoch: 6| Step: 3
Training loss: 2.63853760327552
Validation loss: 2.4846259426563555

Epoch: 6| Step: 4
Training loss: 1.7423234552955214
Validation loss: 2.4720504006334836

Epoch: 6| Step: 5
Training loss: 2.0836541755304707
Validation loss: 2.4913511891473465

Epoch: 6| Step: 6
Training loss: 1.8627523315316799
Validation loss: 2.490690487570034

Epoch: 6| Step: 7
Training loss: 2.6874544893891397
Validation loss: 2.475193724452026

Epoch: 6| Step: 8
Training loss: 2.4640700974525687
Validation loss: 2.4663653307169153

Epoch: 6| Step: 9
Training loss: 2.738940977108931
Validation loss: 2.4749221584011196

Epoch: 6| Step: 10
Training loss: 2.4143254899160853
Validation loss: 2.4772342748877803

Epoch: 6| Step: 11
Training loss: 2.2530370983484547
Validation loss: 2.500285247198513

Epoch: 6| Step: 12
Training loss: 2.3718165092644465
Validation loss: 2.519666775741121

Epoch: 6| Step: 13
Training loss: 2.6256384300246234
Validation loss: 2.515811220039608

Epoch: 316| Step: 0
Training loss: 2.243427531837543
Validation loss: 2.48441812605913

Epoch: 6| Step: 1
Training loss: 1.888263583307793
Validation loss: 2.471115593699892

Epoch: 6| Step: 2
Training loss: 2.630746002133326
Validation loss: 2.506049411133845

Epoch: 6| Step: 3
Training loss: 2.3855390114761605
Validation loss: 2.519083579400313

Epoch: 6| Step: 4
Training loss: 2.942479235528039
Validation loss: 2.5032322815334656

Epoch: 6| Step: 5
Training loss: 2.204930208446765
Validation loss: 2.4780540065198817

Epoch: 6| Step: 6
Training loss: 2.267877340495019
Validation loss: 2.474087109325622

Epoch: 6| Step: 7
Training loss: 2.6315510158562296
Validation loss: 2.468464754032095

Epoch: 6| Step: 8
Training loss: 2.3466494110224376
Validation loss: 2.4549345928237716

Epoch: 6| Step: 9
Training loss: 1.796264743837334
Validation loss: 2.4619809893167544

Epoch: 6| Step: 10
Training loss: 2.4095975701310977
Validation loss: 2.4764177554342104

Epoch: 6| Step: 11
Training loss: 2.0626468028217815
Validation loss: 2.4869170600512245

Epoch: 6| Step: 12
Training loss: 2.625030335750587
Validation loss: 2.490746463800861

Epoch: 6| Step: 13
Training loss: 2.1130871921644534
Validation loss: 2.484521395239083

Epoch: 317| Step: 0
Training loss: 2.622913712269334
Validation loss: 2.4917920382909458

Epoch: 6| Step: 1
Training loss: 2.0427444364037552
Validation loss: 2.4715191134834087

Epoch: 6| Step: 2
Training loss: 2.6057157156367907
Validation loss: 2.455400378205221

Epoch: 6| Step: 3
Training loss: 1.6740844957545546
Validation loss: 2.4377049753538995

Epoch: 6| Step: 4
Training loss: 3.1147047208438354
Validation loss: 2.4576664043071372

Epoch: 6| Step: 5
Training loss: 2.341518713280668
Validation loss: 2.4549127390658225

Epoch: 6| Step: 6
Training loss: 2.325210385391874
Validation loss: 2.4721844544183

Epoch: 6| Step: 7
Training loss: 2.1785447054258076
Validation loss: 2.4888833791490637

Epoch: 6| Step: 8
Training loss: 2.234920195108411
Validation loss: 2.5015497203510537

Epoch: 6| Step: 9
Training loss: 1.9048914836904045
Validation loss: 2.487770589027641

Epoch: 6| Step: 10
Training loss: 2.2975450433709366
Validation loss: 2.5024204176235934

Epoch: 6| Step: 11
Training loss: 2.8195845491355853
Validation loss: 2.458284279188061

Epoch: 6| Step: 12
Training loss: 2.0964946691844224
Validation loss: 2.41599364097482

Epoch: 6| Step: 13
Training loss: 2.566508809309198
Validation loss: 2.4052393932105782

Epoch: 318| Step: 0
Training loss: 1.8419874139246013
Validation loss: 2.4124967506723034

Epoch: 6| Step: 1
Training loss: 1.9796921149653934
Validation loss: 2.4106378904218766

Epoch: 6| Step: 2
Training loss: 2.2556780061019155
Validation loss: 2.439814251187843

Epoch: 6| Step: 3
Training loss: 2.1355612232932675
Validation loss: 2.4400172081778777

Epoch: 6| Step: 4
Training loss: 2.321920229649685
Validation loss: 2.4254528408107188

Epoch: 6| Step: 5
Training loss: 2.188506412600421
Validation loss: 2.426260244086228

Epoch: 6| Step: 6
Training loss: 2.509352926914906
Validation loss: 2.460048079237168

Epoch: 6| Step: 7
Training loss: 2.347329216900486
Validation loss: 2.475738014455619

Epoch: 6| Step: 8
Training loss: 2.158602329807302
Validation loss: 2.533443206186604

Epoch: 6| Step: 9
Training loss: 2.5966722503360495
Validation loss: 2.620838838094106

Epoch: 6| Step: 10
Training loss: 3.029806206174358
Validation loss: 2.6307915192811016

Epoch: 6| Step: 11
Training loss: 2.2891643618680972
Validation loss: 2.5900728125058783

Epoch: 6| Step: 12
Training loss: 2.6617132215383683
Validation loss: 2.5299380472722097

Epoch: 6| Step: 13
Training loss: 2.4183877757503915
Validation loss: 2.507916733768952

Epoch: 319| Step: 0
Training loss: 2.0770623494589753
Validation loss: 2.502140742678317

Epoch: 6| Step: 1
Training loss: 1.656589545227242
Validation loss: 2.477866211130094

Epoch: 6| Step: 2
Training loss: 2.402251054169464
Validation loss: 2.459006888996692

Epoch: 6| Step: 3
Training loss: 2.4086538420539103
Validation loss: 2.469467479394238

Epoch: 6| Step: 4
Training loss: 1.9856704928596232
Validation loss: 2.459692817053434

Epoch: 6| Step: 5
Training loss: 2.6414598578558905
Validation loss: 2.4976526571630795

Epoch: 6| Step: 6
Training loss: 2.1011256788557815
Validation loss: 2.567123420015488

Epoch: 6| Step: 7
Training loss: 2.4138795851262462
Validation loss: 2.593718099465896

Epoch: 6| Step: 8
Training loss: 2.313020492951104
Validation loss: 2.583577424054755

Epoch: 6| Step: 9
Training loss: 2.5362870761047085
Validation loss: 2.5694160363037506

Epoch: 6| Step: 10
Training loss: 2.6971279056644977
Validation loss: 2.583689686559483

Epoch: 6| Step: 11
Training loss: 1.7337414383350247
Validation loss: 2.480176464763155

Epoch: 6| Step: 12
Training loss: 2.6543157378951716
Validation loss: 2.4527957157842373

Epoch: 6| Step: 13
Training loss: 2.940196321640791
Validation loss: 2.420617144306696

Epoch: 320| Step: 0
Training loss: 2.452266081096241
Validation loss: 2.4052335256620285

Epoch: 6| Step: 1
Training loss: 1.923129780849878
Validation loss: 2.4045753058213575

Epoch: 6| Step: 2
Training loss: 2.0368749350131954
Validation loss: 2.424859805357851

Epoch: 6| Step: 3
Training loss: 2.430296009072028
Validation loss: 2.4185535997817524

Epoch: 6| Step: 4
Training loss: 2.1912443539796413
Validation loss: 2.4394467459805207

Epoch: 6| Step: 5
Training loss: 2.265858079167894
Validation loss: 2.486686397501044

Epoch: 6| Step: 6
Training loss: 2.446205731645821
Validation loss: 2.533478454134073

Epoch: 6| Step: 7
Training loss: 2.4480717603101283
Validation loss: 2.588729696739792

Epoch: 6| Step: 8
Training loss: 2.517639869660803
Validation loss: 2.5857700330478957

Epoch: 6| Step: 9
Training loss: 1.8963662610658862
Validation loss: 2.550535061280766

Epoch: 6| Step: 10
Training loss: 2.466803447264602
Validation loss: 2.4873488150799856

Epoch: 6| Step: 11
Training loss: 2.598501242970031
Validation loss: 2.4665217319671293

Epoch: 6| Step: 12
Training loss: 2.316201932751121
Validation loss: 2.484366024468316

Epoch: 6| Step: 13
Training loss: 2.6653750589770833
Validation loss: 2.5101606643309236

Epoch: 321| Step: 0
Training loss: 1.3177566619976762
Validation loss: 2.5021187172085413

Epoch: 6| Step: 1
Training loss: 2.3816253206131406
Validation loss: 2.4775729628413328

Epoch: 6| Step: 2
Training loss: 2.7940169921554903
Validation loss: 2.4756640430418537

Epoch: 6| Step: 3
Training loss: 1.8590064444838066
Validation loss: 2.4911862416575135

Epoch: 6| Step: 4
Training loss: 2.4385212446159077
Validation loss: 2.480829936486395

Epoch: 6| Step: 5
Training loss: 1.089008626604197
Validation loss: 2.4503770638542477

Epoch: 6| Step: 6
Training loss: 2.367139859868956
Validation loss: 2.4286418978722653

Epoch: 6| Step: 7
Training loss: 2.2534557930364274
Validation loss: 2.428111185140741

Epoch: 6| Step: 8
Training loss: 2.6822120630001125
Validation loss: 2.420445372011004

Epoch: 6| Step: 9
Training loss: 2.3407137722808224
Validation loss: 2.4322052963326786

Epoch: 6| Step: 10
Training loss: 2.6671520228560093
Validation loss: 2.4689193891776484

Epoch: 6| Step: 11
Training loss: 2.248598509982215
Validation loss: 2.4977247754702154

Epoch: 6| Step: 12
Training loss: 2.638288920501231
Validation loss: 2.512696440924084

Epoch: 6| Step: 13
Training loss: 2.2549396968653115
Validation loss: 2.576846130528848

Epoch: 322| Step: 0
Training loss: 2.8854382969749004
Validation loss: 2.623929594125703

Epoch: 6| Step: 1
Training loss: 1.600556443729939
Validation loss: 2.662055769415476

Epoch: 6| Step: 2
Training loss: 2.490651198264915
Validation loss: 2.7325996779053803

Epoch: 6| Step: 3
Training loss: 2.8247164423595383
Validation loss: 2.683613624970239

Epoch: 6| Step: 4
Training loss: 2.600841525414385
Validation loss: 2.5777513976009057

Epoch: 6| Step: 5
Training loss: 2.3243732304885585
Validation loss: 2.4501387038489

Epoch: 6| Step: 6
Training loss: 2.0411378084689975
Validation loss: 2.424471043012843

Epoch: 6| Step: 7
Training loss: 2.697672731032681
Validation loss: 2.3984279784026636

Epoch: 6| Step: 8
Training loss: 2.039804608580568
Validation loss: 2.3870404789607496

Epoch: 6| Step: 9
Training loss: 2.4731193217341763
Validation loss: 2.368725411693364

Epoch: 6| Step: 10
Training loss: 2.357915060291416
Validation loss: 2.3749924655831496

Epoch: 6| Step: 11
Training loss: 2.317744211212095
Validation loss: 2.3885765127415377

Epoch: 6| Step: 12
Training loss: 2.3305821093548333
Validation loss: 2.413802404795317

Epoch: 6| Step: 13
Training loss: 2.4744754505122875
Validation loss: 2.4593431481999657

Epoch: 323| Step: 0
Training loss: 2.3249556711544526
Validation loss: 2.5253080912520907

Epoch: 6| Step: 1
Training loss: 2.9200144673341804
Validation loss: 2.610925033407117

Epoch: 6| Step: 2
Training loss: 1.9734840997674423
Validation loss: 2.6306361687579582

Epoch: 6| Step: 3
Training loss: 1.789392965521714
Validation loss: 2.6294124988427185

Epoch: 6| Step: 4
Training loss: 2.4088671434757445
Validation loss: 2.659764863974904

Epoch: 6| Step: 5
Training loss: 2.089392497462688
Validation loss: 2.6206864339024696

Epoch: 6| Step: 6
Training loss: 2.7107239564895083
Validation loss: 2.6248902699808383

Epoch: 6| Step: 7
Training loss: 2.4454307649428864
Validation loss: 2.559727598399765

Epoch: 6| Step: 8
Training loss: 1.9320884933660543
Validation loss: 2.5045945104994654

Epoch: 6| Step: 9
Training loss: 2.11193330827088
Validation loss: 2.4585170736278283

Epoch: 6| Step: 10
Training loss: 2.160418696266136
Validation loss: 2.4111920848541235

Epoch: 6| Step: 11
Training loss: 3.094049304394237
Validation loss: 2.410659206516639

Epoch: 6| Step: 12
Training loss: 2.3775991973880735
Validation loss: 2.413641100391296

Epoch: 6| Step: 13
Training loss: 2.1304339325944617
Validation loss: 2.428267053542805

Epoch: 324| Step: 0
Training loss: 1.7925730416115069
Validation loss: 2.442978482956816

Epoch: 6| Step: 1
Training loss: 2.282344607759603
Validation loss: 2.460080070763189

Epoch: 6| Step: 2
Training loss: 2.2676009407834186
Validation loss: 2.4670381427464894

Epoch: 6| Step: 3
Training loss: 2.4245629929509174
Validation loss: 2.4680174060828723

Epoch: 6| Step: 4
Training loss: 2.255088244993153
Validation loss: 2.5050611538228353

Epoch: 6| Step: 5
Training loss: 2.279449902311349
Validation loss: 2.50981050067126

Epoch: 6| Step: 6
Training loss: 2.3519998441553387
Validation loss: 2.472644482334983

Epoch: 6| Step: 7
Training loss: 2.1504037078819778
Validation loss: 2.4282801849139863

Epoch: 6| Step: 8
Training loss: 2.2468990574001113
Validation loss: 2.43532143484214

Epoch: 6| Step: 9
Training loss: 2.5118985267480847
Validation loss: 2.428140152358287

Epoch: 6| Step: 10
Training loss: 2.5685314744502743
Validation loss: 2.419334187641675

Epoch: 6| Step: 11
Training loss: 2.600303734864411
Validation loss: 2.4337920295426687

Epoch: 6| Step: 12
Training loss: 2.1018873906628164
Validation loss: 2.4340921627449346

Epoch: 6| Step: 13
Training loss: 2.5063926979594155
Validation loss: 2.4317412301106875

Epoch: 325| Step: 0
Training loss: 2.625518021105624
Validation loss: 2.4704405444401414

Epoch: 6| Step: 1
Training loss: 2.4629436732242955
Validation loss: 2.4681138319323317

Epoch: 6| Step: 2
Training loss: 2.425386700816704
Validation loss: 2.509910246139825

Epoch: 6| Step: 3
Training loss: 2.5241471464910026
Validation loss: 2.5495150921997745

Epoch: 6| Step: 4
Training loss: 2.2326605561587503
Validation loss: 2.58208069283849

Epoch: 6| Step: 5
Training loss: 2.159189514938343
Validation loss: 2.617197875270319

Epoch: 6| Step: 6
Training loss: 1.8745530549460303
Validation loss: 2.600981790200349

Epoch: 6| Step: 7
Training loss: 2.238230546573399
Validation loss: 2.600046183220912

Epoch: 6| Step: 8
Training loss: 2.6047218544747666
Validation loss: 2.5841773364944114

Epoch: 6| Step: 9
Training loss: 2.400471970721687
Validation loss: 2.51994385294422

Epoch: 6| Step: 10
Training loss: 1.6612283992008816
Validation loss: 2.4574464667256293

Epoch: 6| Step: 11
Training loss: 2.491118964363323
Validation loss: 2.412601168691426

Epoch: 6| Step: 12
Training loss: 2.3694546861664483
Validation loss: 2.3944028467206038

Epoch: 6| Step: 13
Training loss: 1.7209799432378214
Validation loss: 2.3993808411267676

Epoch: 326| Step: 0
Training loss: 2.2106596971010077
Validation loss: 2.401335237957221

Epoch: 6| Step: 1
Training loss: 2.379243372689994
Validation loss: 2.421072968876689

Epoch: 6| Step: 2
Training loss: 2.2083675693761147
Validation loss: 2.449430834086495

Epoch: 6| Step: 3
Training loss: 2.311830475258034
Validation loss: 2.495340383583214

Epoch: 6| Step: 4
Training loss: 2.4953344679733145
Validation loss: 2.5565617263534683

Epoch: 6| Step: 5
Training loss: 2.0838585255170554
Validation loss: 2.595530862633116

Epoch: 6| Step: 6
Training loss: 2.860961807289387
Validation loss: 2.6298109761796815

Epoch: 6| Step: 7
Training loss: 2.5200074684698452
Validation loss: 2.583887898770639

Epoch: 6| Step: 8
Training loss: 2.186802998262635
Validation loss: 2.541314807430246

Epoch: 6| Step: 9
Training loss: 2.271896206889287
Validation loss: 2.4908444799021905

Epoch: 6| Step: 10
Training loss: 2.2700484666397664
Validation loss: 2.4710466007276524

Epoch: 6| Step: 11
Training loss: 2.1110733541938114
Validation loss: 2.4461047928688195

Epoch: 6| Step: 12
Training loss: 2.5016749493154524
Validation loss: 2.4260892977113064

Epoch: 6| Step: 13
Training loss: 1.1580721956454825
Validation loss: 2.426398620677365

Epoch: 327| Step: 0
Training loss: 1.660341355719054
Validation loss: 2.4255949684712284

Epoch: 6| Step: 1
Training loss: 1.98963495423888
Validation loss: 2.422266188304007

Epoch: 6| Step: 2
Training loss: 1.7043168683379908
Validation loss: 2.4276838711419106

Epoch: 6| Step: 3
Training loss: 2.4053479770474033
Validation loss: 2.4301027654590657

Epoch: 6| Step: 4
Training loss: 2.8316106233969
Validation loss: 2.4482352868691377

Epoch: 6| Step: 5
Training loss: 2.2975278173180183
Validation loss: 2.4676467291157755

Epoch: 6| Step: 6
Training loss: 1.8520720219418678
Validation loss: 2.5131805758505545

Epoch: 6| Step: 7
Training loss: 2.4295732771834855
Validation loss: 2.5355820628055135

Epoch: 6| Step: 8
Training loss: 2.404480717166614
Validation loss: 2.5727396324509924

Epoch: 6| Step: 9
Training loss: 2.237762550848117
Validation loss: 2.558158380946896

Epoch: 6| Step: 10
Training loss: 2.1026239940535905
Validation loss: 2.538432965229084

Epoch: 6| Step: 11
Training loss: 2.962587727080738
Validation loss: 2.5435026414343467

Epoch: 6| Step: 12
Training loss: 1.9842753948534588
Validation loss: 2.5305358880041116

Epoch: 6| Step: 13
Training loss: 1.8081608495181236
Validation loss: 2.4974788443376914

Epoch: 328| Step: 0
Training loss: 2.521945287771997
Validation loss: 2.5201243582695834

Epoch: 6| Step: 1
Training loss: 1.4300812559450413
Validation loss: 2.499270775791462

Epoch: 6| Step: 2
Training loss: 2.0678245710343726
Validation loss: 2.5299089637644596

Epoch: 6| Step: 3
Training loss: 2.545977007052631
Validation loss: 2.544566428015687

Epoch: 6| Step: 4
Training loss: 2.062198501282407
Validation loss: 2.566811011396926

Epoch: 6| Step: 5
Training loss: 2.4434813446900194
Validation loss: 2.55678635778061

Epoch: 6| Step: 6
Training loss: 2.0802224265894487
Validation loss: 2.546341796519022

Epoch: 6| Step: 7
Training loss: 2.6851413933945363
Validation loss: 2.473793689752135

Epoch: 6| Step: 8
Training loss: 2.229895416168014
Validation loss: 2.473708775384035

Epoch: 6| Step: 9
Training loss: 1.5504270672810254
Validation loss: 2.475361196347832

Epoch: 6| Step: 10
Training loss: 2.583365183808243
Validation loss: 2.458852738796723

Epoch: 6| Step: 11
Training loss: 2.125908152680358
Validation loss: 2.451859046617071

Epoch: 6| Step: 12
Training loss: 2.187810167393928
Validation loss: 2.4570969847466744

Epoch: 6| Step: 13
Training loss: 2.363403518918702
Validation loss: 2.456236602818475

Epoch: 329| Step: 0
Training loss: 2.179739783969149
Validation loss: 2.457603360463563

Epoch: 6| Step: 1
Training loss: 2.1107914442787177
Validation loss: 2.430530161532065

Epoch: 6| Step: 2
Training loss: 2.2765026076796433
Validation loss: 2.424772752855653

Epoch: 6| Step: 3
Training loss: 2.2964731500685125
Validation loss: 2.470911577374074

Epoch: 6| Step: 4
Training loss: 2.480071941685866
Validation loss: 2.5135352034468457

Epoch: 6| Step: 5
Training loss: 2.2547929365073496
Validation loss: 2.5649636123866095

Epoch: 6| Step: 6
Training loss: 2.1730672733515912
Validation loss: 2.5504802796465476

Epoch: 6| Step: 7
Training loss: 2.0181093504420904
Validation loss: 2.5447393961119253

Epoch: 6| Step: 8
Training loss: 2.4829346902210943
Validation loss: 2.509456137425273

Epoch: 6| Step: 9
Training loss: 2.3933072470019905
Validation loss: 2.46744378808434

Epoch: 6| Step: 10
Training loss: 2.28662521228342
Validation loss: 2.4444454914972047

Epoch: 6| Step: 11
Training loss: 1.960079719810106
Validation loss: 2.4221684230819416

Epoch: 6| Step: 12
Training loss: 2.0939475578365094
Validation loss: 2.3976158216868693

Epoch: 6| Step: 13
Training loss: 2.3905037244565475
Validation loss: 2.377214295455136

Epoch: 330| Step: 0
Training loss: 1.6891370532779362
Validation loss: 2.385941412025773

Epoch: 6| Step: 1
Training loss: 2.13199764796945
Validation loss: 2.4259721283481417

Epoch: 6| Step: 2
Training loss: 2.335220073645822
Validation loss: 2.461905643412472

Epoch: 6| Step: 3
Training loss: 2.005325617807507
Validation loss: 2.544395682938249

Epoch: 6| Step: 4
Training loss: 2.4428639203091507
Validation loss: 2.6340313970895712

Epoch: 6| Step: 5
Training loss: 2.4936143384091056
Validation loss: 2.703350800541154

Epoch: 6| Step: 6
Training loss: 2.0944394926399945
Validation loss: 2.6529076497965582

Epoch: 6| Step: 7
Training loss: 2.281987946180091
Validation loss: 2.617876135944034

Epoch: 6| Step: 8
Training loss: 2.8703898079417947
Validation loss: 2.5373806288710776

Epoch: 6| Step: 9
Training loss: 2.5904241173399645
Validation loss: 2.4772698010345056

Epoch: 6| Step: 10
Training loss: 2.659795840323262
Validation loss: 2.410891286009242

Epoch: 6| Step: 11
Training loss: 1.3544138560510723
Validation loss: 2.39023787379854

Epoch: 6| Step: 12
Training loss: 2.0437884172567715
Validation loss: 2.3573443268704644

Epoch: 6| Step: 13
Training loss: 1.8319238171666599
Validation loss: 2.3558208390378925

Epoch: 331| Step: 0
Training loss: 2.5556709659703283
Validation loss: 2.354906617256019

Epoch: 6| Step: 1
Training loss: 2.0824890206037243
Validation loss: 2.3514543521470808

Epoch: 6| Step: 2
Training loss: 2.740560804461236
Validation loss: 2.3616549618544767

Epoch: 6| Step: 3
Training loss: 2.697897912233972
Validation loss: 2.391013865351937

Epoch: 6| Step: 4
Training loss: 2.458572656221575
Validation loss: 2.441578858145588

Epoch: 6| Step: 5
Training loss: 2.45370729180906
Validation loss: 2.508043173985477

Epoch: 6| Step: 6
Training loss: 2.6436400045684896
Validation loss: 2.5170928223336295

Epoch: 6| Step: 7
Training loss: 1.936911155065347
Validation loss: 2.51415054217196

Epoch: 6| Step: 8
Training loss: 1.63528707521321
Validation loss: 2.5037742693738725

Epoch: 6| Step: 9
Training loss: 2.101285214194304
Validation loss: 2.4935098481086424

Epoch: 6| Step: 10
Training loss: 2.2125915163585255
Validation loss: 2.509222659050142

Epoch: 6| Step: 11
Training loss: 2.3783990729624316
Validation loss: 2.5179043222339983

Epoch: 6| Step: 12
Training loss: 1.3684036077852701
Validation loss: 2.5499149994795407

Epoch: 6| Step: 13
Training loss: 2.1223229768257816
Validation loss: 2.5637485364796158

Epoch: 332| Step: 0
Training loss: 2.721981364470181
Validation loss: 2.6001942778921534

Epoch: 6| Step: 1
Training loss: 2.0093119325128868
Validation loss: 2.5880974834390194

Epoch: 6| Step: 2
Training loss: 1.677244459037595
Validation loss: 2.6115823101802462

Epoch: 6| Step: 3
Training loss: 2.355691219217895
Validation loss: 2.6101629226798218

Epoch: 6| Step: 4
Training loss: 1.7231300031266275
Validation loss: 2.6210809429828945

Epoch: 6| Step: 5
Training loss: 2.807308152149797
Validation loss: 2.583007900832684

Epoch: 6| Step: 6
Training loss: 2.3523493366054757
Validation loss: 2.48203866693551

Epoch: 6| Step: 7
Training loss: 1.5332678908743107
Validation loss: 2.42304038524419

Epoch: 6| Step: 8
Training loss: 2.526005810879678
Validation loss: 2.391323392138753

Epoch: 6| Step: 9
Training loss: 2.131021830854649
Validation loss: 2.3698898345580814

Epoch: 6| Step: 10
Training loss: 2.378520264028209
Validation loss: 2.386709205282493

Epoch: 6| Step: 11
Training loss: 2.2684384470999537
Validation loss: 2.3897752146253572

Epoch: 6| Step: 12
Training loss: 2.593584170268357
Validation loss: 2.4132530840519624

Epoch: 6| Step: 13
Training loss: 1.6453519028512742
Validation loss: 2.442130719332446

Epoch: 333| Step: 0
Training loss: 2.4931454147914547
Validation loss: 2.4734825411629444

Epoch: 6| Step: 1
Training loss: 2.7944722003792823
Validation loss: 2.5034711131173166

Epoch: 6| Step: 2
Training loss: 1.6591578454639422
Validation loss: 2.5184802737282235

Epoch: 6| Step: 3
Training loss: 2.287594060579485
Validation loss: 2.530464956066092

Epoch: 6| Step: 4
Training loss: 2.1488012387400657
Validation loss: 2.5426328393817874

Epoch: 6| Step: 5
Training loss: 1.517280618184869
Validation loss: 2.5498270259631832

Epoch: 6| Step: 6
Training loss: 1.5706021625332436
Validation loss: 2.573461811539014

Epoch: 6| Step: 7
Training loss: 2.298454934993462
Validation loss: 2.6022545683779135

Epoch: 6| Step: 8
Training loss: 2.4397711321320816
Validation loss: 2.589128281010922

Epoch: 6| Step: 9
Training loss: 2.3936112645037166
Validation loss: 2.58219678119604

Epoch: 6| Step: 10
Training loss: 2.545134435224489
Validation loss: 2.534515195145982

Epoch: 6| Step: 11
Training loss: 1.668928026854238
Validation loss: 2.5135337734986245

Epoch: 6| Step: 12
Training loss: 2.3510643314141784
Validation loss: 2.500942076308549

Epoch: 6| Step: 13
Training loss: 2.1257167056321875
Validation loss: 2.4656024368022953

Epoch: 334| Step: 0
Training loss: 2.2529630224492547
Validation loss: 2.4724441984563295

Epoch: 6| Step: 1
Training loss: 1.8748418741306623
Validation loss: 2.46914000187034

Epoch: 6| Step: 2
Training loss: 2.260457848614694
Validation loss: 2.483939980654982

Epoch: 6| Step: 3
Training loss: 2.1724014193135996
Validation loss: 2.499921475479571

Epoch: 6| Step: 4
Training loss: 1.9932855310204955
Validation loss: 2.507706151861822

Epoch: 6| Step: 5
Training loss: 2.3160313629372307
Validation loss: 2.531875966429076

Epoch: 6| Step: 6
Training loss: 1.9185115877327963
Validation loss: 2.5343341600195983

Epoch: 6| Step: 7
Training loss: 2.243287883126196
Validation loss: 2.5426598273934466

Epoch: 6| Step: 8
Training loss: 2.355867722157634
Validation loss: 2.5045546997640007

Epoch: 6| Step: 9
Training loss: 2.0016333347862414
Validation loss: 2.48672609893379

Epoch: 6| Step: 10
Training loss: 2.28996430948089
Validation loss: 2.428670087135538

Epoch: 6| Step: 11
Training loss: 2.479595841731083
Validation loss: 2.4345825369279686

Epoch: 6| Step: 12
Training loss: 2.282172865556255
Validation loss: 2.4084322063209185

Epoch: 6| Step: 13
Training loss: 2.2027883069477716
Validation loss: 2.4072757985401108

Epoch: 335| Step: 0
Training loss: 2.041657532133052
Validation loss: 2.408470818708824

Epoch: 6| Step: 1
Training loss: 2.1032136578174097
Validation loss: 2.4723997239791315

Epoch: 6| Step: 2
Training loss: 1.9431779786375687
Validation loss: 2.521235071352876

Epoch: 6| Step: 3
Training loss: 2.5855921027709727
Validation loss: 2.5671740647128694

Epoch: 6| Step: 4
Training loss: 2.4075642749291326
Validation loss: 2.6107572063558417

Epoch: 6| Step: 5
Training loss: 1.671252482376024
Validation loss: 2.5944654029392034

Epoch: 6| Step: 6
Training loss: 2.024051528907998
Validation loss: 2.530201935869699

Epoch: 6| Step: 7
Training loss: 2.3781705072487656
Validation loss: 2.466866008651819

Epoch: 6| Step: 8
Training loss: 1.6303853516756388
Validation loss: 2.4213344503972896

Epoch: 6| Step: 9
Training loss: 2.672391072007996
Validation loss: 2.414520544646276

Epoch: 6| Step: 10
Training loss: 2.104209282572554
Validation loss: 2.3918582224131724

Epoch: 6| Step: 11
Training loss: 1.9303950815567361
Validation loss: 2.375973260806743

Epoch: 6| Step: 12
Training loss: 2.639862130928905
Validation loss: 2.395898519719738

Epoch: 6| Step: 13
Training loss: 1.7526718587589274
Validation loss: 2.4003785158747024

Epoch: 336| Step: 0
Training loss: 2.4193440656524676
Validation loss: 2.4053216674174496

Epoch: 6| Step: 1
Training loss: 2.190399645915257
Validation loss: 2.4114439944444257

Epoch: 6| Step: 2
Training loss: 2.0148176602008983
Validation loss: 2.468338758309187

Epoch: 6| Step: 3
Training loss: 2.1671675567699444
Validation loss: 2.509617900303421

Epoch: 6| Step: 4
Training loss: 2.189958553183289
Validation loss: 2.505446903218912

Epoch: 6| Step: 5
Training loss: 1.8799273914154286
Validation loss: 2.5186194526870573

Epoch: 6| Step: 6
Training loss: 2.2002306383787467
Validation loss: 2.498419647726605

Epoch: 6| Step: 7
Training loss: 2.08120293091482
Validation loss: 2.4759989108476637

Epoch: 6| Step: 8
Training loss: 2.057283335479736
Validation loss: 2.464349658211775

Epoch: 6| Step: 9
Training loss: 2.112201633487919
Validation loss: 2.4307472458902115

Epoch: 6| Step: 10
Training loss: 1.954569778129736
Validation loss: 2.434066371295686

Epoch: 6| Step: 11
Training loss: 2.496585230430793
Validation loss: 2.4106939516448613

Epoch: 6| Step: 12
Training loss: 2.2478427081688177
Validation loss: 2.4437084029860237

Epoch: 6| Step: 13
Training loss: 2.2799043213695636
Validation loss: 2.4645841900078342

Epoch: 337| Step: 0
Training loss: 2.389077676908239
Validation loss: 2.4814702488879976

Epoch: 6| Step: 1
Training loss: 2.168683678220316
Validation loss: 2.4982171633726185

Epoch: 6| Step: 2
Training loss: 2.1415762910686906
Validation loss: 2.529096286979245

Epoch: 6| Step: 3
Training loss: 2.044943444139173
Validation loss: 2.5484428368837193

Epoch: 6| Step: 4
Training loss: 1.852406562888938
Validation loss: 2.5429625550395256

Epoch: 6| Step: 5
Training loss: 2.2321963058612004
Validation loss: 2.494351560767149

Epoch: 6| Step: 6
Training loss: 1.7618195701559294
Validation loss: 2.47245715844966

Epoch: 6| Step: 7
Training loss: 2.368123992895545
Validation loss: 2.443727951426612

Epoch: 6| Step: 8
Training loss: 2.4453120124987033
Validation loss: 2.4436669357295204

Epoch: 6| Step: 9
Training loss: 1.9646393383318652
Validation loss: 2.412851938799694

Epoch: 6| Step: 10
Training loss: 2.2355441789145893
Validation loss: 2.411859744209455

Epoch: 6| Step: 11
Training loss: 2.019965414752053
Validation loss: 2.4338611221581874

Epoch: 6| Step: 12
Training loss: 2.0040632933712175
Validation loss: 2.4450893117432586

Epoch: 6| Step: 13
Training loss: 2.2081532554859353
Validation loss: 2.4776116038221496

Epoch: 338| Step: 0
Training loss: 2.47225413736419
Validation loss: 2.529510465462686

Epoch: 6| Step: 1
Training loss: 1.8505807197114765
Validation loss: 2.5328890994142563

Epoch: 6| Step: 2
Training loss: 2.251517314047152
Validation loss: 2.5483977396411657

Epoch: 6| Step: 3
Training loss: 2.235697215009431
Validation loss: 2.5342322793375343

Epoch: 6| Step: 4
Training loss: 2.0843394583856063
Validation loss: 2.5089362985293127

Epoch: 6| Step: 5
Training loss: 1.892498128832115
Validation loss: 2.4984045023724186

Epoch: 6| Step: 6
Training loss: 2.1001174666839115
Validation loss: 2.4738713213002925

Epoch: 6| Step: 7
Training loss: 2.2693192453555997
Validation loss: 2.466158452541889

Epoch: 6| Step: 8
Training loss: 2.128871084500277
Validation loss: 2.4408149905684144

Epoch: 6| Step: 9
Training loss: 1.8954212733014504
Validation loss: 2.4228554341171207

Epoch: 6| Step: 10
Training loss: 2.0375152212873253
Validation loss: 2.431768516870258

Epoch: 6| Step: 11
Training loss: 2.084184803213312
Validation loss: 2.4404790893213897

Epoch: 6| Step: 12
Training loss: 2.2646871796222565
Validation loss: 2.449158360447432

Epoch: 6| Step: 13
Training loss: 1.8338314232304764
Validation loss: 2.4687729197495205

Epoch: 339| Step: 0
Training loss: 2.326719128400723
Validation loss: 2.4689361016132816

Epoch: 6| Step: 1
Training loss: 1.8187048365697651
Validation loss: 2.4848078714807986

Epoch: 6| Step: 2
Training loss: 2.5452552746825927
Validation loss: 2.491272424432786

Epoch: 6| Step: 3
Training loss: 2.0498488858979558
Validation loss: 2.4891164335583764

Epoch: 6| Step: 4
Training loss: 2.2698786300612506
Validation loss: 2.546564990865723

Epoch: 6| Step: 5
Training loss: 1.7492248998468267
Validation loss: 2.513365095096763

Epoch: 6| Step: 6
Training loss: 1.7718568723582182
Validation loss: 2.506141011259826

Epoch: 6| Step: 7
Training loss: 1.940334584593827
Validation loss: 2.498307561722243

Epoch: 6| Step: 8
Training loss: 2.247066174519495
Validation loss: 2.479924410778019

Epoch: 6| Step: 9
Training loss: 1.8899230915144667
Validation loss: 2.4921327874829

Epoch: 6| Step: 10
Training loss: 2.4159237498004473
Validation loss: 2.4815197469326167

Epoch: 6| Step: 11
Training loss: 1.8615288321008945
Validation loss: 2.45381652352694

Epoch: 6| Step: 12
Training loss: 2.2087926806744838
Validation loss: 2.436364958476234

Epoch: 6| Step: 13
Training loss: 2.3396850939728493
Validation loss: 2.441960220458438

Epoch: 340| Step: 0
Training loss: 2.182071271038338
Validation loss: 2.4258719465910645

Epoch: 6| Step: 1
Training loss: 2.115656675836944
Validation loss: 2.430257694922162

Epoch: 6| Step: 2
Training loss: 2.1187576158774903
Validation loss: 2.432757849124935

Epoch: 6| Step: 3
Training loss: 2.345638175783016
Validation loss: 2.4211838131887133

Epoch: 6| Step: 4
Training loss: 1.6562530949401728
Validation loss: 2.411816235391385

Epoch: 6| Step: 5
Training loss: 2.2301311604883147
Validation loss: 2.3991520453145023

Epoch: 6| Step: 6
Training loss: 2.400235573810191
Validation loss: 2.3996796593506478

Epoch: 6| Step: 7
Training loss: 2.2561089976202537
Validation loss: 2.40728690972349

Epoch: 6| Step: 8
Training loss: 1.680708322158358
Validation loss: 2.398774080427989

Epoch: 6| Step: 9
Training loss: 1.8120929655601337
Validation loss: 2.421438787463313

Epoch: 6| Step: 10
Training loss: 1.9760014035378233
Validation loss: 2.429177887517281

Epoch: 6| Step: 11
Training loss: 2.0878957635942963
Validation loss: 2.47117643999788

Epoch: 6| Step: 12
Training loss: 1.6450945326707944
Validation loss: 2.5259375194362463

Epoch: 6| Step: 13
Training loss: 2.466434696820084
Validation loss: 2.592376918810145

Epoch: 341| Step: 0
Training loss: 2.3525816271055984
Validation loss: 2.670138625959581

Epoch: 6| Step: 1
Training loss: 2.157644180483987
Validation loss: 2.7032576910196244

Epoch: 6| Step: 2
Training loss: 2.230073001847001
Validation loss: 2.693803126047267

Epoch: 6| Step: 3
Training loss: 1.6230667792429867
Validation loss: 2.6714849498576094

Epoch: 6| Step: 4
Training loss: 1.9837775344716488
Validation loss: 2.561702869405602

Epoch: 6| Step: 5
Training loss: 2.1371069072638718
Validation loss: 2.4929227430741836

Epoch: 6| Step: 6
Training loss: 2.0214583095768206
Validation loss: 2.4556464707420433

Epoch: 6| Step: 7
Training loss: 1.7321649853356145
Validation loss: 2.4266308651396846

Epoch: 6| Step: 8
Training loss: 2.547887308404382
Validation loss: 2.4156806870080856

Epoch: 6| Step: 9
Training loss: 2.1503335250494087
Validation loss: 2.395709264538007

Epoch: 6| Step: 10
Training loss: 2.5080600509390143
Validation loss: 2.3630230766589744

Epoch: 6| Step: 11
Training loss: 2.0420678451730128
Validation loss: 2.339377148888045

Epoch: 6| Step: 12
Training loss: 2.116827452052121
Validation loss: 2.3467934458467647

Epoch: 6| Step: 13
Training loss: 1.8352285761443388
Validation loss: 2.31777776872453

Epoch: 342| Step: 0
Training loss: 2.059998237646145
Validation loss: 2.343037121280039

Epoch: 6| Step: 1
Training loss: 1.8637574425081163
Validation loss: 2.3506879198475334

Epoch: 6| Step: 2
Training loss: 2.2582274586914375
Validation loss: 2.403965741952593

Epoch: 6| Step: 3
Training loss: 1.9640984458334916
Validation loss: 2.4483448600973783

Epoch: 6| Step: 4
Training loss: 2.273694839857029
Validation loss: 2.478668990886327

Epoch: 6| Step: 5
Training loss: 2.284936512872707
Validation loss: 2.4860435708185635

Epoch: 6| Step: 6
Training loss: 2.177783640488153
Validation loss: 2.4848004925662113

Epoch: 6| Step: 7
Training loss: 2.0293090937432914
Validation loss: 2.463299492727009

Epoch: 6| Step: 8
Training loss: 2.1379858301405066
Validation loss: 2.4412793030251434

Epoch: 6| Step: 9
Training loss: 2.264807402314837
Validation loss: 2.477594878510145

Epoch: 6| Step: 10
Training loss: 2.0282006483267496
Validation loss: 2.4910229360636564

Epoch: 6| Step: 11
Training loss: 1.9896638930489885
Validation loss: 2.5204071387035656

Epoch: 6| Step: 12
Training loss: 1.6647463544034304
Validation loss: 2.526682139321234

Epoch: 6| Step: 13
Training loss: 2.301399083237396
Validation loss: 2.4854536954253486

Epoch: 343| Step: 0
Training loss: 2.309691708622472
Validation loss: 2.47617781158319

Epoch: 6| Step: 1
Training loss: 2.250175893054278
Validation loss: 2.4468766156260946

Epoch: 6| Step: 2
Training loss: 2.005940674320056
Validation loss: 2.443575525256643

Epoch: 6| Step: 3
Training loss: 2.0266834278835733
Validation loss: 2.434340216654474

Epoch: 6| Step: 4
Training loss: 2.3320815497873135
Validation loss: 2.4820238130870234

Epoch: 6| Step: 5
Training loss: 1.8853299101650522
Validation loss: 2.484202623465769

Epoch: 6| Step: 6
Training loss: 2.0195584027883298
Validation loss: 2.4840812052770804

Epoch: 6| Step: 7
Training loss: 1.5242288734807647
Validation loss: 2.486405887941909

Epoch: 6| Step: 8
Training loss: 1.914588575663842
Validation loss: 2.466590213865723

Epoch: 6| Step: 9
Training loss: 2.248781722111689
Validation loss: 2.473256230274296

Epoch: 6| Step: 10
Training loss: 2.353184542972806
Validation loss: 2.488864687007158

Epoch: 6| Step: 11
Training loss: 2.183034862860275
Validation loss: 2.4722730909350257

Epoch: 6| Step: 12
Training loss: 1.9091701341472935
Validation loss: 2.4613872387324793

Epoch: 6| Step: 13
Training loss: 1.7348263127569745
Validation loss: 2.4285056358288104

Epoch: 344| Step: 0
Training loss: 2.142102699075997
Validation loss: 2.414720849517488

Epoch: 6| Step: 1
Training loss: 2.4786027753221114
Validation loss: 2.367300295063926

Epoch: 6| Step: 2
Training loss: 2.147133171183698
Validation loss: 2.366056709541178

Epoch: 6| Step: 3
Training loss: 1.1925286681050142
Validation loss: 2.3548654718264794

Epoch: 6| Step: 4
Training loss: 2.2775999157424875
Validation loss: 2.3367808498017264

Epoch: 6| Step: 5
Training loss: 1.8836380664195795
Validation loss: 2.354524838004902

Epoch: 6| Step: 6
Training loss: 2.186597692498909
Validation loss: 2.3888061207742166

Epoch: 6| Step: 7
Training loss: 2.015323350202538
Validation loss: 2.431349496471307

Epoch: 6| Step: 8
Training loss: 2.471308191566535
Validation loss: 2.446183718160549

Epoch: 6| Step: 9
Training loss: 2.504161803822125
Validation loss: 2.50493248960197

Epoch: 6| Step: 10
Training loss: 1.9041853182468367
Validation loss: 2.5647628221420318

Epoch: 6| Step: 11
Training loss: 1.8497030844711009
Validation loss: 2.5505618098826117

Epoch: 6| Step: 12
Training loss: 1.6618492918117058
Validation loss: 2.5557367997846585

Epoch: 6| Step: 13
Training loss: 1.0462223124970849
Validation loss: 2.5525898460698557

Epoch: 345| Step: 0
Training loss: 2.2152733226427053
Validation loss: 2.557579109750955

Epoch: 6| Step: 1
Training loss: 1.7230739649318885
Validation loss: 2.56025160366711

Epoch: 6| Step: 2
Training loss: 1.982555967409221
Validation loss: 2.5357017914172117

Epoch: 6| Step: 3
Training loss: 2.1443057749466905
Validation loss: 2.507587394007248

Epoch: 6| Step: 4
Training loss: 1.5729886305895893
Validation loss: 2.44476489091087

Epoch: 6| Step: 5
Training loss: 1.9042866085460437
Validation loss: 2.4185898405401294

Epoch: 6| Step: 6
Training loss: 2.006867776511423
Validation loss: 2.3801006968570224

Epoch: 6| Step: 7
Training loss: 2.150840275706581
Validation loss: 2.3756962939091837

Epoch: 6| Step: 8
Training loss: 2.041802680746421
Validation loss: 2.3905788274814523

Epoch: 6| Step: 9
Training loss: 1.7980639297568242
Validation loss: 2.3796998623890904

Epoch: 6| Step: 10
Training loss: 2.2546257576317004
Validation loss: 2.3714103967759015

Epoch: 6| Step: 11
Training loss: 2.0639816510915208
Validation loss: 2.3877803105988566

Epoch: 6| Step: 12
Training loss: 2.0518549551610716
Validation loss: 2.4043833664392262

Epoch: 6| Step: 13
Training loss: 2.6863268576127135
Validation loss: 2.433794915726488

Epoch: 346| Step: 0
Training loss: 1.927032250079557
Validation loss: 2.441645551738124

Epoch: 6| Step: 1
Training loss: 2.0480259578669116
Validation loss: 2.4537916414812173

Epoch: 6| Step: 2
Training loss: 1.7896413741138373
Validation loss: 2.4410207798011814

Epoch: 6| Step: 3
Training loss: 2.326635101599753
Validation loss: 2.4441273960809515

Epoch: 6| Step: 4
Training loss: 1.9160596121153344
Validation loss: 2.4215148912106743

Epoch: 6| Step: 5
Training loss: 2.0794019862798137
Validation loss: 2.4258123829823535

Epoch: 6| Step: 6
Training loss: 1.7722111297361258
Validation loss: 2.383899964396245

Epoch: 6| Step: 7
Training loss: 2.229383321435882
Validation loss: 2.3841778696882017

Epoch: 6| Step: 8
Training loss: 1.9159323764646035
Validation loss: 2.4431747647843385

Epoch: 6| Step: 9
Training loss: 2.0068030287371705
Validation loss: 2.490894600620939

Epoch: 6| Step: 10
Training loss: 2.087485435572087
Validation loss: 2.5432935544812296

Epoch: 6| Step: 11
Training loss: 1.9130578966407834
Validation loss: 2.5652719447287224

Epoch: 6| Step: 12
Training loss: 2.2598698624133085
Validation loss: 2.568759305676793

Epoch: 6| Step: 13
Training loss: 1.6788809325739864
Validation loss: 2.5437656479204787

Epoch: 347| Step: 0
Training loss: 1.7646595163425052
Validation loss: 2.4824752721193244

Epoch: 6| Step: 1
Training loss: 1.8290947844241738
Validation loss: 2.4045504750337585

Epoch: 6| Step: 2
Training loss: 2.1277026772698595
Validation loss: 2.387815426215373

Epoch: 6| Step: 3
Training loss: 2.3149564944107275
Validation loss: 2.4169679297651774

Epoch: 6| Step: 4
Training loss: 2.04528269093985
Validation loss: 2.407825697182563

Epoch: 6| Step: 5
Training loss: 1.9226687893231897
Validation loss: 2.4378363206643754

Epoch: 6| Step: 6
Training loss: 2.0041629857315657
Validation loss: 2.4181234444212176

Epoch: 6| Step: 7
Training loss: 2.228182019631669
Validation loss: 2.4444932872924103

Epoch: 6| Step: 8
Training loss: 1.9131223276911618
Validation loss: 2.4231358935188116

Epoch: 6| Step: 9
Training loss: 1.5246334761117877
Validation loss: 2.419178093398405

Epoch: 6| Step: 10
Training loss: 1.8491410142799112
Validation loss: 2.4255802345435575

Epoch: 6| Step: 11
Training loss: 2.2506270064811376
Validation loss: 2.4430795582465197

Epoch: 6| Step: 12
Training loss: 2.0253068102836296
Validation loss: 2.4656773765363185

Epoch: 6| Step: 13
Training loss: 1.69527642699507
Validation loss: 2.465671136064344

Epoch: 348| Step: 0
Training loss: 1.7538403199172192
Validation loss: 2.4883497816016837

Epoch: 6| Step: 1
Training loss: 2.04354260993516
Validation loss: 2.4692721559115602

Epoch: 6| Step: 2
Training loss: 2.3047886713095784
Validation loss: 2.478800982333444

Epoch: 6| Step: 3
Training loss: 1.7103788953258783
Validation loss: 2.4371727060293007

Epoch: 6| Step: 4
Training loss: 1.8197621180627042
Validation loss: 2.4124685360765628

Epoch: 6| Step: 5
Training loss: 2.854693807293251
Validation loss: 2.400920993458788

Epoch: 6| Step: 6
Training loss: 1.693299676355403
Validation loss: 2.434707000624128

Epoch: 6| Step: 7
Training loss: 1.5038077185914558
Validation loss: 2.469325910056267

Epoch: 6| Step: 8
Training loss: 2.0533447519620656
Validation loss: 2.4805047000718004

Epoch: 6| Step: 9
Training loss: 1.5104664586070438
Validation loss: 2.466157763334763

Epoch: 6| Step: 10
Training loss: 2.271670569204037
Validation loss: 2.4641755146366293

Epoch: 6| Step: 11
Training loss: 2.2544710453261243
Validation loss: 2.422717219161981

Epoch: 6| Step: 12
Training loss: 1.6253718904287857
Validation loss: 2.370783695007177

Epoch: 6| Step: 13
Training loss: 1.463730778360271
Validation loss: 2.3459967336339322

Epoch: 349| Step: 0
Training loss: 2.2176205621434883
Validation loss: 2.348518032547064

Epoch: 6| Step: 1
Training loss: 2.1235656385236044
Validation loss: 2.3220855014617845

Epoch: 6| Step: 2
Training loss: 1.606705831720433
Validation loss: 2.333703304732982

Epoch: 6| Step: 3
Training loss: 1.678660944027245
Validation loss: 2.336160577596431

Epoch: 6| Step: 4
Training loss: 2.2205611882273413
Validation loss: 2.3397846917396037

Epoch: 6| Step: 5
Training loss: 1.6784821199584652
Validation loss: 2.370426607224151

Epoch: 6| Step: 6
Training loss: 1.8303858804606667
Validation loss: 2.406251942772701

Epoch: 6| Step: 7
Training loss: 2.317148639664348
Validation loss: 2.473451552154433

Epoch: 6| Step: 8
Training loss: 1.567424642890023
Validation loss: 2.510966586962627

Epoch: 6| Step: 9
Training loss: 2.4919582727897343
Validation loss: 2.5656714493854462

Epoch: 6| Step: 10
Training loss: 1.9882912026626516
Validation loss: 2.543880876657996

Epoch: 6| Step: 11
Training loss: 1.9281475393501912
Validation loss: 2.510412500502514

Epoch: 6| Step: 12
Training loss: 1.0184481776316556
Validation loss: 2.4888322321628977

Epoch: 6| Step: 13
Training loss: 2.38229104261525
Validation loss: 2.46071302956386

Epoch: 350| Step: 0
Training loss: 1.9364192778814655
Validation loss: 2.4466175783841466

Epoch: 6| Step: 1
Training loss: 2.460049520474837
Validation loss: 2.443391519981333

Epoch: 6| Step: 2
Training loss: 1.6266931369587239
Validation loss: 2.4343128302401684

Epoch: 6| Step: 3
Training loss: 1.4787829622285487
Validation loss: 2.462804897512033

Epoch: 6| Step: 4
Training loss: 2.0189381656407677
Validation loss: 2.4645896146028856

Epoch: 6| Step: 5
Training loss: 1.9873968829389745
Validation loss: 2.478716475313761

Epoch: 6| Step: 6
Training loss: 1.588683808851477
Validation loss: 2.480660820112587

Epoch: 6| Step: 7
Training loss: 2.154374786102488
Validation loss: 2.4889519539119997

Epoch: 6| Step: 8
Training loss: 2.1092578996720865
Validation loss: 2.473195430997654

Epoch: 6| Step: 9
Training loss: 1.3587132739707293
Validation loss: 2.4297799182950826

Epoch: 6| Step: 10
Training loss: 1.9948513994826949
Validation loss: 2.4178992096141143

Epoch: 6| Step: 11
Training loss: 1.776803875766668
Validation loss: 2.4299168294679285

Epoch: 6| Step: 12
Training loss: 2.3484311974923746
Validation loss: 2.4026686107178343

Epoch: 6| Step: 13
Training loss: 2.0381604534248594
Validation loss: 2.3746529300201162

Epoch: 351| Step: 0
Training loss: 2.4207496243403397
Validation loss: 2.372073730943983

Epoch: 6| Step: 1
Training loss: 2.2430183386561082
Validation loss: 2.4044627709381823

Epoch: 6| Step: 2
Training loss: 1.8611522483391312
Validation loss: 2.406246068637227

Epoch: 6| Step: 3
Training loss: 1.6687577322448581
Validation loss: 2.382976025141738

Epoch: 6| Step: 4
Training loss: 2.212718017526284
Validation loss: 2.3549461616963465

Epoch: 6| Step: 5
Training loss: 1.6710973339211803
Validation loss: 2.4272269390840124

Epoch: 6| Step: 6
Training loss: 1.460322122964596
Validation loss: 2.5112395304889867

Epoch: 6| Step: 7
Training loss: 2.6644660890110323
Validation loss: 2.6412080510754308

Epoch: 6| Step: 8
Training loss: 2.052968049110591
Validation loss: 2.607354911708468

Epoch: 6| Step: 9
Training loss: 2.032595145050199
Validation loss: 2.5501150225925935

Epoch: 6| Step: 10
Training loss: 1.893978077464536
Validation loss: 2.4035273974396243

Epoch: 6| Step: 11
Training loss: 2.069731548058896
Validation loss: 2.322549364814057

Epoch: 6| Step: 12
Training loss: 1.9064588588674551
Validation loss: 2.2931745168204034

Epoch: 6| Step: 13
Training loss: 1.5574142850064692
Validation loss: 2.2989647573659195

Epoch: 352| Step: 0
Training loss: 1.9067641643569748
Validation loss: 2.3136433926160387

Epoch: 6| Step: 1
Training loss: 2.043174135230524
Validation loss: 2.3201493040503323

Epoch: 6| Step: 2
Training loss: 1.8617599962974487
Validation loss: 2.3262295067528918

Epoch: 6| Step: 3
Training loss: 2.6458421441679905
Validation loss: 2.332146432448198

Epoch: 6| Step: 4
Training loss: 2.02592792208042
Validation loss: 2.3649330207653585

Epoch: 6| Step: 5
Training loss: 1.3503403623108114
Validation loss: 2.3953515355278228

Epoch: 6| Step: 6
Training loss: 2.199616689234587
Validation loss: 2.462328296032699

Epoch: 6| Step: 7
Training loss: 2.4085899964240536
Validation loss: 2.567622808940625

Epoch: 6| Step: 8
Training loss: 1.6060538977465983
Validation loss: 2.6454057497357706

Epoch: 6| Step: 9
Training loss: 1.940185162861144
Validation loss: 2.7190790520638632

Epoch: 6| Step: 10
Training loss: 2.5029352123305197
Validation loss: 2.787023252705662

Epoch: 6| Step: 11
Training loss: 2.267941467983084
Validation loss: 2.7219062770696016

Epoch: 6| Step: 12
Training loss: 1.8320534385524991
Validation loss: 2.6087067020714136

Epoch: 6| Step: 13
Training loss: 1.7459544013143975
Validation loss: 2.4950436354757657

Epoch: 353| Step: 0
Training loss: 1.692127523301582
Validation loss: 2.4130232237479246

Epoch: 6| Step: 1
Training loss: 1.7925658594053904
Validation loss: 2.3599486229248776

Epoch: 6| Step: 2
Training loss: 2.212589361250423
Validation loss: 2.3312195492597985

Epoch: 6| Step: 3
Training loss: 2.288371427718571
Validation loss: 2.3087261295184454

Epoch: 6| Step: 4
Training loss: 2.504445034387326
Validation loss: 2.305640829479268

Epoch: 6| Step: 5
Training loss: 1.9369301727108077
Validation loss: 2.293053052344459

Epoch: 6| Step: 6
Training loss: 2.2347264580310764
Validation loss: 2.3078106569384764

Epoch: 6| Step: 7
Training loss: 2.1980587761182058
Validation loss: 2.319657756902428

Epoch: 6| Step: 8
Training loss: 1.850062797099182
Validation loss: 2.332305634271507

Epoch: 6| Step: 9
Training loss: 2.042718058680821
Validation loss: 2.3851558548812264

Epoch: 6| Step: 10
Training loss: 1.7010598216944142
Validation loss: 2.436020860118717

Epoch: 6| Step: 11
Training loss: 1.6353838809993273
Validation loss: 2.526754951984474

Epoch: 6| Step: 12
Training loss: 2.106733688825506
Validation loss: 2.558235930110114

Epoch: 6| Step: 13
Training loss: 1.3384562612319075
Validation loss: 2.5717434745234025

Epoch: 354| Step: 0
Training loss: 2.13526657941657
Validation loss: 2.53386306335353

Epoch: 6| Step: 1
Training loss: 2.0869273148268976
Validation loss: 2.4690580060378755

Epoch: 6| Step: 2
Training loss: 2.253488379604865
Validation loss: 2.4008314931226558

Epoch: 6| Step: 3
Training loss: 2.307974123864261
Validation loss: 2.3478024980973102

Epoch: 6| Step: 4
Training loss: 1.733590713367665
Validation loss: 2.3293992138679593

Epoch: 6| Step: 5
Training loss: 1.4511694105905217
Validation loss: 2.304861944711219

Epoch: 6| Step: 6
Training loss: 1.528247848596592
Validation loss: 2.3169420288767775

Epoch: 6| Step: 7
Training loss: 1.8395794397171075
Validation loss: 2.313805712880096

Epoch: 6| Step: 8
Training loss: 2.0411282302968248
Validation loss: 2.3258064927890247

Epoch: 6| Step: 9
Training loss: 2.0649699824555277
Validation loss: 2.359149341023313

Epoch: 6| Step: 10
Training loss: 1.3759649965275302
Validation loss: 2.395268312004137

Epoch: 6| Step: 11
Training loss: 2.2135959992565954
Validation loss: 2.403616387826572

Epoch: 6| Step: 12
Training loss: 1.9995027758499646
Validation loss: 2.493086166903058

Epoch: 6| Step: 13
Training loss: 2.1437824658307156
Validation loss: 2.548898682705819

Epoch: 355| Step: 0
Training loss: 2.0653634279413247
Validation loss: 2.5082034238014215

Epoch: 6| Step: 1
Training loss: 2.0078981136370726
Validation loss: 2.4870265999765278

Epoch: 6| Step: 2
Training loss: 2.6806660191818907
Validation loss: 2.458308777878561

Epoch: 6| Step: 3
Training loss: 1.7251904589786533
Validation loss: 2.388969576902953

Epoch: 6| Step: 4
Training loss: 1.7717279605304783
Validation loss: 2.366429386249188

Epoch: 6| Step: 5
Training loss: 1.808216162663626
Validation loss: 2.3653572425698077

Epoch: 6| Step: 6
Training loss: 1.590902439945735
Validation loss: 2.36384377065978

Epoch: 6| Step: 7
Training loss: 1.5574313540202507
Validation loss: 2.3669603080975965

Epoch: 6| Step: 8
Training loss: 1.8705581185071836
Validation loss: 2.3820550961181803

Epoch: 6| Step: 9
Training loss: 1.7693550072621471
Validation loss: 2.4040556587949227

Epoch: 6| Step: 10
Training loss: 1.6139596616438256
Validation loss: 2.4484921426728476

Epoch: 6| Step: 11
Training loss: 2.1263877600659873
Validation loss: 2.4759037022371015

Epoch: 6| Step: 12
Training loss: 1.9625042739141298
Validation loss: 2.5228764705206714

Epoch: 6| Step: 13
Training loss: 1.5826740983891903
Validation loss: 2.5252383779236363

Epoch: 356| Step: 0
Training loss: 2.1722597289146854
Validation loss: 2.5043326990533696

Epoch: 6| Step: 1
Training loss: 1.7293215839282927
Validation loss: 2.4721715915103104

Epoch: 6| Step: 2
Training loss: 1.7479974324144234
Validation loss: 2.4223817499588556

Epoch: 6| Step: 3
Training loss: 1.4489076182715723
Validation loss: 2.420029955774909

Epoch: 6| Step: 4
Training loss: 2.2970790642635763
Validation loss: 2.421086810067438

Epoch: 6| Step: 5
Training loss: 1.435550860963854
Validation loss: 2.3894909329568077

Epoch: 6| Step: 6
Training loss: 1.6960123612790108
Validation loss: 2.396549603225838

Epoch: 6| Step: 7
Training loss: 1.4479103454159123
Validation loss: 2.412927253571814

Epoch: 6| Step: 8
Training loss: 1.8570789939253944
Validation loss: 2.3859049595570188

Epoch: 6| Step: 9
Training loss: 2.0258980302144787
Validation loss: 2.4132157486196792

Epoch: 6| Step: 10
Training loss: 1.9957312685911637
Validation loss: 2.4214034358087706

Epoch: 6| Step: 11
Training loss: 1.9441762769548505
Validation loss: 2.426380136054362

Epoch: 6| Step: 12
Training loss: 2.2441584733298066
Validation loss: 2.4266612477085974

Epoch: 6| Step: 13
Training loss: 1.7930610317176479
Validation loss: 2.404169137243656

Epoch: 357| Step: 0
Training loss: 1.6724535930222364
Validation loss: 2.3876033686491303

Epoch: 6| Step: 1
Training loss: 1.494642066336828
Validation loss: 2.389818117958943

Epoch: 6| Step: 2
Training loss: 1.609455439955361
Validation loss: 2.3779425206018874

Epoch: 6| Step: 3
Training loss: 1.4050233365221643
Validation loss: 2.3916907286515303

Epoch: 6| Step: 4
Training loss: 2.1383385246057247
Validation loss: 2.41244967586298

Epoch: 6| Step: 5
Training loss: 2.2762144766585597
Validation loss: 2.4073901278071363

Epoch: 6| Step: 6
Training loss: 2.3006129567588376
Validation loss: 2.3735001733737593

Epoch: 6| Step: 7
Training loss: 1.7652781998321778
Validation loss: 2.363161640738852

Epoch: 6| Step: 8
Training loss: 2.128015622368452
Validation loss: 2.3737251862887536

Epoch: 6| Step: 9
Training loss: 2.188375679220394
Validation loss: 2.392121708865569

Epoch: 6| Step: 10
Training loss: 1.5198906716129308
Validation loss: 2.390824429384395

Epoch: 6| Step: 11
Training loss: 1.4555751694060681
Validation loss: 2.3940779277227646

Epoch: 6| Step: 12
Training loss: 2.0420850078661776
Validation loss: 2.415652477762559

Epoch: 6| Step: 13
Training loss: 1.1684278523571494
Validation loss: 2.412669648323207

Epoch: 358| Step: 0
Training loss: 2.084549917405265
Validation loss: 2.432356790303745

Epoch: 6| Step: 1
Training loss: 2.002765055436871
Validation loss: 2.4520032481333107

Epoch: 6| Step: 2
Training loss: 2.3127680442732097
Validation loss: 2.4386849248632276

Epoch: 6| Step: 3
Training loss: 1.52865505269881
Validation loss: 2.4540650632004386

Epoch: 6| Step: 4
Training loss: 1.3926126227044955
Validation loss: 2.4621124416091558

Epoch: 6| Step: 5
Training loss: 2.1091380798661348
Validation loss: 2.4505650660386897

Epoch: 6| Step: 6
Training loss: 1.5494688231392768
Validation loss: 2.444927408691879

Epoch: 6| Step: 7
Training loss: 1.7329559019171554
Validation loss: 2.4887038517390665

Epoch: 6| Step: 8
Training loss: 2.0238422003814125
Validation loss: 2.5088527013243773

Epoch: 6| Step: 9
Training loss: 1.5800511153922197
Validation loss: 2.5095722805682152

Epoch: 6| Step: 10
Training loss: 1.17474598472349
Validation loss: 2.5247515817035873

Epoch: 6| Step: 11
Training loss: 2.1348315173814023
Validation loss: 2.4862670452719606

Epoch: 6| Step: 12
Training loss: 1.8123360921476124
Validation loss: 2.4330628319180096

Epoch: 6| Step: 13
Training loss: 1.651842045651935
Validation loss: 2.396183051702702

Epoch: 359| Step: 0
Training loss: 2.098096634369375
Validation loss: 2.328381817341564

Epoch: 6| Step: 1
Training loss: 1.7345932831739626
Validation loss: 2.3371960146444506

Epoch: 6| Step: 2
Training loss: 1.5734424428095075
Validation loss: 2.323942289027087

Epoch: 6| Step: 3
Training loss: 1.9065737840174422
Validation loss: 2.347914792972633

Epoch: 6| Step: 4
Training loss: 2.202991021593857
Validation loss: 2.359183566851389

Epoch: 6| Step: 5
Training loss: 1.3340120773455022
Validation loss: 2.365828831483193

Epoch: 6| Step: 6
Training loss: 1.5220712648768353
Validation loss: 2.4041451254770885

Epoch: 6| Step: 7
Training loss: 1.7513384469002045
Validation loss: 2.4145735741835805

Epoch: 6| Step: 8
Training loss: 2.1791895362524367
Validation loss: 2.460097562289421

Epoch: 6| Step: 9
Training loss: 2.1456149338870296
Validation loss: 2.4958853300729884

Epoch: 6| Step: 10
Training loss: 1.974929677942636
Validation loss: 2.4888318984242024

Epoch: 6| Step: 11
Training loss: 1.652229323156325
Validation loss: 2.465933066346401

Epoch: 6| Step: 12
Training loss: 1.6120360512831582
Validation loss: 2.432817575150923

Epoch: 6| Step: 13
Training loss: 1.633315524503713
Validation loss: 2.413573221897608

Epoch: 360| Step: 0
Training loss: 1.7960242869852618
Validation loss: 2.40375802074005

Epoch: 6| Step: 1
Training loss: 1.9881192424250689
Validation loss: 2.4237637157739935

Epoch: 6| Step: 2
Training loss: 1.3647343015758433
Validation loss: 2.409391675121862

Epoch: 6| Step: 3
Training loss: 1.3372955112468372
Validation loss: 2.4271716515889463

Epoch: 6| Step: 4
Training loss: 1.79420458519545
Validation loss: 2.4368446569254734

Epoch: 6| Step: 5
Training loss: 1.2993161310068762
Validation loss: 2.469469517252413

Epoch: 6| Step: 6
Training loss: 1.9760500880738783
Validation loss: 2.4817117202089345

Epoch: 6| Step: 7
Training loss: 1.9328540350383834
Validation loss: 2.4997738274432435

Epoch: 6| Step: 8
Training loss: 1.7329105002068903
Validation loss: 2.4786988235125347

Epoch: 6| Step: 9
Training loss: 2.0747036412032496
Validation loss: 2.447633097886113

Epoch: 6| Step: 10
Training loss: 2.2058638194184463
Validation loss: 2.4244483822524465

Epoch: 6| Step: 11
Training loss: 1.4391315157863838
Validation loss: 2.371002564744094

Epoch: 6| Step: 12
Training loss: 2.016741775921516
Validation loss: 2.367748200455861

Epoch: 6| Step: 13
Training loss: 2.3430821802475377
Validation loss: 2.3659482901943503

Epoch: 361| Step: 0
Training loss: 1.5161213799350926
Validation loss: 2.3491727273071286

Epoch: 6| Step: 1
Training loss: 2.0176313011052605
Validation loss: 2.3518189272131016

Epoch: 6| Step: 2
Training loss: 1.6735903772500529
Validation loss: 2.3756098652366204

Epoch: 6| Step: 3
Training loss: 1.8076839259526154
Validation loss: 2.426949465437824

Epoch: 6| Step: 4
Training loss: 2.206067007975224
Validation loss: 2.4299591406406824

Epoch: 6| Step: 5
Training loss: 1.3498736287062438
Validation loss: 2.453330166275411

Epoch: 6| Step: 6
Training loss: 1.8087487700167508
Validation loss: 2.4676705645061268

Epoch: 6| Step: 7
Training loss: 2.072469027187703
Validation loss: 2.511022516513552

Epoch: 6| Step: 8
Training loss: 1.882529842955787
Validation loss: 2.5131691682905215

Epoch: 6| Step: 9
Training loss: 1.951587163129474
Validation loss: 2.5037250121413503

Epoch: 6| Step: 10
Training loss: 1.838179757120757
Validation loss: 2.5060224718105184

Epoch: 6| Step: 11
Training loss: 1.550457899076225
Validation loss: 2.4762796219913907

Epoch: 6| Step: 12
Training loss: 1.5376954179335192
Validation loss: 2.4537128365720915

Epoch: 6| Step: 13
Training loss: 1.766253671716544
Validation loss: 2.4154657563216864

Epoch: 362| Step: 0
Training loss: 1.4995805630769161
Validation loss: 2.3781614715313673

Epoch: 6| Step: 1
Training loss: 1.615071630985673
Validation loss: 2.351975021833853

Epoch: 6| Step: 2
Training loss: 1.9612056959118913
Validation loss: 2.3542858517948426

Epoch: 6| Step: 3
Training loss: 2.4958495974342476
Validation loss: 2.3485021453571453

Epoch: 6| Step: 4
Training loss: 1.4881035806331209
Validation loss: 2.3666909240277927

Epoch: 6| Step: 5
Training loss: 2.234532917551035
Validation loss: 2.3731898181150712

Epoch: 6| Step: 6
Training loss: 1.4099224456804555
Validation loss: 2.3775852383536273

Epoch: 6| Step: 7
Training loss: 1.6206448220638063
Validation loss: 2.4013404787490717

Epoch: 6| Step: 8
Training loss: 1.6679160044993828
Validation loss: 2.417619706811658

Epoch: 6| Step: 9
Training loss: 1.9009815642031318
Validation loss: 2.408291661581519

Epoch: 6| Step: 10
Training loss: 1.7173833094994946
Validation loss: 2.43765159453159

Epoch: 6| Step: 11
Training loss: 1.8157927758967374
Validation loss: 2.4349403804125673

Epoch: 6| Step: 12
Training loss: 1.804931161788326
Validation loss: 2.4548743318705895

Epoch: 6| Step: 13
Training loss: 1.3935380919978029
Validation loss: 2.4861201212270148

Epoch: 363| Step: 0
Training loss: 1.293178483715229
Validation loss: 2.525591184034219

Epoch: 6| Step: 1
Training loss: 1.8226099537358593
Validation loss: 2.5670163801977477

Epoch: 6| Step: 2
Training loss: 2.2380723572830092
Validation loss: 2.5679916195280827

Epoch: 6| Step: 3
Training loss: 2.0403029370240837
Validation loss: 2.502851515064816

Epoch: 6| Step: 4
Training loss: 1.739295783423598
Validation loss: 2.4349731977007294

Epoch: 6| Step: 5
Training loss: 1.9796138325196964
Validation loss: 2.3644814259025946

Epoch: 6| Step: 6
Training loss: 1.383494279108603
Validation loss: 2.3324265944942253

Epoch: 6| Step: 7
Training loss: 1.7417689620401624
Validation loss: 2.3380976060587053

Epoch: 6| Step: 8
Training loss: 2.114983794779278
Validation loss: 2.3435028164589844

Epoch: 6| Step: 9
Training loss: 1.902415311434755
Validation loss: 2.3759981817338

Epoch: 6| Step: 10
Training loss: 1.870348310008254
Validation loss: 2.3940369779195647

Epoch: 6| Step: 11
Training loss: 1.6747225460450723
Validation loss: 2.4055953896652147

Epoch: 6| Step: 12
Training loss: 1.5443830358218225
Validation loss: 2.431175255205789

Epoch: 6| Step: 13
Training loss: 2.0585209002986957
Validation loss: 2.4250918234924095

Epoch: 364| Step: 0
Training loss: 1.455100081105322
Validation loss: 2.4246207844938428

Epoch: 6| Step: 1
Training loss: 1.9717906903653157
Validation loss: 2.429748407777007

Epoch: 6| Step: 2
Training loss: 1.3889893760357248
Validation loss: 2.4336639932993

Epoch: 6| Step: 3
Training loss: 1.989407563226163
Validation loss: 2.427168153367509

Epoch: 6| Step: 4
Training loss: 1.7364620676288447
Validation loss: 2.413996506706981

Epoch: 6| Step: 5
Training loss: 1.8404292574103418
Validation loss: 2.382688738404353

Epoch: 6| Step: 6
Training loss: 1.9739573201065348
Validation loss: 2.3549246880317942

Epoch: 6| Step: 7
Training loss: 2.0481677450236764
Validation loss: 2.3432831089304966

Epoch: 6| Step: 8
Training loss: 1.5483968165468145
Validation loss: 2.4110870965041125

Epoch: 6| Step: 9
Training loss: 1.7290219012716133
Validation loss: 2.4463031471932113

Epoch: 6| Step: 10
Training loss: 1.675722205626848
Validation loss: 2.4800747507533627

Epoch: 6| Step: 11
Training loss: 1.8474452601932216
Validation loss: 2.5018882998270118

Epoch: 6| Step: 12
Training loss: 1.9301061755212847
Validation loss: 2.4931418641532264

Epoch: 6| Step: 13
Training loss: 1.7952235054554613
Validation loss: 2.4834600884390126

Epoch: 365| Step: 0
Training loss: 1.4580606296423804
Validation loss: 2.4398688928520795

Epoch: 6| Step: 1
Training loss: 1.4525368433365125
Validation loss: 2.422768945011953

Epoch: 6| Step: 2
Training loss: 1.6358568931330122
Validation loss: 2.424146537388248

Epoch: 6| Step: 3
Training loss: 1.741519406434238
Validation loss: 2.3783459735998425

Epoch: 6| Step: 4
Training loss: 1.9782310951551194
Validation loss: 2.3767131623929583

Epoch: 6| Step: 5
Training loss: 1.8819312728226958
Validation loss: 2.3629037640834274

Epoch: 6| Step: 6
Training loss: 1.8764643990493552
Validation loss: 2.3847586729171697

Epoch: 6| Step: 7
Training loss: 2.036238428390904
Validation loss: 2.377615367812387

Epoch: 6| Step: 8
Training loss: 1.6896259197445112
Validation loss: 2.4357141516136447

Epoch: 6| Step: 9
Training loss: 2.0132898806415462
Validation loss: 2.4577928709913355

Epoch: 6| Step: 10
Training loss: 1.983101744180312
Validation loss: 2.491077230431287

Epoch: 6| Step: 11
Training loss: 1.7603302958892715
Validation loss: 2.429173741031054

Epoch: 6| Step: 12
Training loss: 1.743180953940394
Validation loss: 2.3827754471868636

Epoch: 6| Step: 13
Training loss: 1.4507517970335482
Validation loss: 2.3636924413730362

Epoch: 366| Step: 0
Training loss: 1.4678749562052087
Validation loss: 2.377573587791331

Epoch: 6| Step: 1
Training loss: 1.84493295253099
Validation loss: 2.363838250436222

Epoch: 6| Step: 2
Training loss: 1.7892737118177313
Validation loss: 2.3523805597812264

Epoch: 6| Step: 3
Training loss: 1.7100602082478031
Validation loss: 2.356040645039915

Epoch: 6| Step: 4
Training loss: 1.8559239521807127
Validation loss: 2.362550003170201

Epoch: 6| Step: 5
Training loss: 2.1696359633168583
Validation loss: 2.387952565106731

Epoch: 6| Step: 6
Training loss: 1.4489002134768567
Validation loss: 2.381096287317674

Epoch: 6| Step: 7
Training loss: 1.600885908913991
Validation loss: 2.3859127206147757

Epoch: 6| Step: 8
Training loss: 1.2822178232399248
Validation loss: 2.3913155135615063

Epoch: 6| Step: 9
Training loss: 1.910820157182696
Validation loss: 2.4499879144031884

Epoch: 6| Step: 10
Training loss: 1.968273650170826
Validation loss: 2.4937274999387613

Epoch: 6| Step: 11
Training loss: 1.6936423517343853
Validation loss: 2.490247035483972

Epoch: 6| Step: 12
Training loss: 1.7409054268310147
Validation loss: 2.5188297247406117

Epoch: 6| Step: 13
Training loss: 2.2302021461863055
Validation loss: 2.5220321083619726

Epoch: 367| Step: 0
Training loss: 1.5384393195235089
Validation loss: 2.5205399347502184

Epoch: 6| Step: 1
Training loss: 1.416971407632136
Validation loss: 2.478238201205466

Epoch: 6| Step: 2
Training loss: 2.093964067589848
Validation loss: 2.4536689514201857

Epoch: 6| Step: 3
Training loss: 1.4697540584793027
Validation loss: 2.416724178519547

Epoch: 6| Step: 4
Training loss: 1.529142837269449
Validation loss: 2.415428714062797

Epoch: 6| Step: 5
Training loss: 1.9173524569529072
Validation loss: 2.3623171220167025

Epoch: 6| Step: 6
Training loss: 1.9062371800726383
Validation loss: 2.3266598626057946

Epoch: 6| Step: 7
Training loss: 1.445718821553999
Validation loss: 2.32755177784333

Epoch: 6| Step: 8
Training loss: 1.9341331269088489
Validation loss: 2.3016691097384876

Epoch: 6| Step: 9
Training loss: 1.72299613108231
Validation loss: 2.31599236391987

Epoch: 6| Step: 10
Training loss: 1.815777872973818
Validation loss: 2.327490491692889

Epoch: 6| Step: 11
Training loss: 2.0072945843371683
Validation loss: 2.3735939585289874

Epoch: 6| Step: 12
Training loss: 1.6943269317123772
Validation loss: 2.392034531318865

Epoch: 6| Step: 13
Training loss: 1.8854468819179981
Validation loss: 2.439142479956582

Epoch: 368| Step: 0
Training loss: 1.8612872636598976
Validation loss: 2.5245961420551297

Epoch: 6| Step: 1
Training loss: 2.0359540023778986
Validation loss: 2.5600395065093355

Epoch: 6| Step: 2
Training loss: 2.006667942709955
Validation loss: 2.5437679961241852

Epoch: 6| Step: 3
Training loss: 1.5115501447783475
Validation loss: 2.524635669761164

Epoch: 6| Step: 4
Training loss: 1.599314978107952
Validation loss: 2.486308610418401

Epoch: 6| Step: 5
Training loss: 1.3809727213525078
Validation loss: 2.4375802850661357

Epoch: 6| Step: 6
Training loss: 1.9896495135686265
Validation loss: 2.4490937687168706

Epoch: 6| Step: 7
Training loss: 1.546719552908979
Validation loss: 2.4278954362810485

Epoch: 6| Step: 8
Training loss: 2.030735126678051
Validation loss: 2.4016858611111576

Epoch: 6| Step: 9
Training loss: 1.887179806057665
Validation loss: 2.374671706095179

Epoch: 6| Step: 10
Training loss: 1.8595007845863354
Validation loss: 2.3701984408439873

Epoch: 6| Step: 11
Training loss: 1.3194796853071875
Validation loss: 2.368703904389166

Epoch: 6| Step: 12
Training loss: 1.8806862756413851
Validation loss: 2.3789839692218036

Epoch: 6| Step: 13
Training loss: 0.9576249130282843
Validation loss: 2.3890976702106403

Epoch: 369| Step: 0
Training loss: 2.1467518245004693
Validation loss: 2.4121357211273

Epoch: 6| Step: 1
Training loss: 1.9502432353588586
Validation loss: 2.409425387291817

Epoch: 6| Step: 2
Training loss: 2.0582988607425983
Validation loss: 2.429893919334478

Epoch: 6| Step: 3
Training loss: 1.9009071894770062
Validation loss: 2.4034804290810787

Epoch: 6| Step: 4
Training loss: 1.472104563699897
Validation loss: 2.4230414967006424

Epoch: 6| Step: 5
Training loss: 1.4811336262374717
Validation loss: 2.4392644639675507

Epoch: 6| Step: 6
Training loss: 1.6797232690595547
Validation loss: 2.463233161664688

Epoch: 6| Step: 7
Training loss: 1.5673143603627253
Validation loss: 2.4677114840038916

Epoch: 6| Step: 8
Training loss: 1.080246151759032
Validation loss: 2.5061365788417587

Epoch: 6| Step: 9
Training loss: 1.8776261058977062
Validation loss: 2.483794931127683

Epoch: 6| Step: 10
Training loss: 1.8563040369048383
Validation loss: 2.464578688946565

Epoch: 6| Step: 11
Training loss: 1.9542362561337352
Validation loss: 2.428006148099747

Epoch: 6| Step: 12
Training loss: 1.4891793652494536
Validation loss: 2.374771135202003

Epoch: 6| Step: 13
Training loss: 1.3368867769654424
Validation loss: 2.34224366487499

Epoch: 370| Step: 0
Training loss: 2.276344773793022
Validation loss: 2.330689498793872

Epoch: 6| Step: 1
Training loss: 1.9510474790645063
Validation loss: 2.3005269746106114

Epoch: 6| Step: 2
Training loss: 1.540409331479234
Validation loss: 2.3342252497445743

Epoch: 6| Step: 3
Training loss: 1.7401135335253575
Validation loss: 2.3245315585300097

Epoch: 6| Step: 4
Training loss: 1.458222830082588
Validation loss: 2.3449726713852286

Epoch: 6| Step: 5
Training loss: 0.9657065668809318
Validation loss: 2.4016680306309803

Epoch: 6| Step: 6
Training loss: 1.9530639028529813
Validation loss: 2.4346614356098253

Epoch: 6| Step: 7
Training loss: 1.9354696402744405
Validation loss: 2.44609814822148

Epoch: 6| Step: 8
Training loss: 1.691223839489128
Validation loss: 2.46402604510253

Epoch: 6| Step: 9
Training loss: 1.2949870511736863
Validation loss: 2.4579002940302384

Epoch: 6| Step: 10
Training loss: 1.4380756552402596
Validation loss: 2.4792903711759817

Epoch: 6| Step: 11
Training loss: 1.7966776863897298
Validation loss: 2.4591639005383215

Epoch: 6| Step: 12
Training loss: 1.5731364806055255
Validation loss: 2.45621096091981

Epoch: 6| Step: 13
Training loss: 2.135324640539608
Validation loss: 2.4665174346681016

Epoch: 371| Step: 0
Training loss: 1.6071609526326964
Validation loss: 2.428604516641726

Epoch: 6| Step: 1
Training loss: 1.8683186061844719
Validation loss: 2.392832480616461

Epoch: 6| Step: 2
Training loss: 1.527256175308619
Validation loss: 2.3580048392501882

Epoch: 6| Step: 3
Training loss: 1.6040312557124217
Validation loss: 2.3482789164639564

Epoch: 6| Step: 4
Training loss: 2.061901930592388
Validation loss: 2.3377978600955664

Epoch: 6| Step: 5
Training loss: 1.587025687179889
Validation loss: 2.3421001815891165

Epoch: 6| Step: 6
Training loss: 1.99534022372469
Validation loss: 2.3552231174616405

Epoch: 6| Step: 7
Training loss: 1.3456973669540726
Validation loss: 2.411522819893374

Epoch: 6| Step: 8
Training loss: 1.92427291762899
Validation loss: 2.4270235600285575

Epoch: 6| Step: 9
Training loss: 1.8651911705565647
Validation loss: 2.4835153275035133

Epoch: 6| Step: 10
Training loss: 1.4195838326439383
Validation loss: 2.5053090196017673

Epoch: 6| Step: 11
Training loss: 1.4920683009286908
Validation loss: 2.57158730736075

Epoch: 6| Step: 12
Training loss: 2.1336293874395236
Validation loss: 2.55156269769138

Epoch: 6| Step: 13
Training loss: 1.555222922288858
Validation loss: 2.483381404302704

Epoch: 372| Step: 0
Training loss: 1.316596767324564
Validation loss: 2.4427655532095955

Epoch: 6| Step: 1
Training loss: 1.6717843004384216
Validation loss: 2.3993143104527372

Epoch: 6| Step: 2
Training loss: 1.3997559539074187
Validation loss: 2.3525706296883495

Epoch: 6| Step: 3
Training loss: 1.3255020719848003
Validation loss: 2.3573255851550456

Epoch: 6| Step: 4
Training loss: 1.3792948837071437
Validation loss: 2.340985614489684

Epoch: 6| Step: 5
Training loss: 1.7527380368334966
Validation loss: 2.347257368572146

Epoch: 6| Step: 6
Training loss: 2.0923171193408905
Validation loss: 2.34441872412225

Epoch: 6| Step: 7
Training loss: 1.6377517244635331
Validation loss: 2.3794928606961534

Epoch: 6| Step: 8
Training loss: 1.9865016205073174
Validation loss: 2.3905955814227324

Epoch: 6| Step: 9
Training loss: 2.2290787248704165
Validation loss: 2.3986768133837186

Epoch: 6| Step: 10
Training loss: 1.4524976134814094
Validation loss: 2.4096117926914533

Epoch: 6| Step: 11
Training loss: 1.7003954090951106
Validation loss: 2.4200108599912764

Epoch: 6| Step: 12
Training loss: 1.9086020920360764
Validation loss: 2.421180226902858

Epoch: 6| Step: 13
Training loss: 1.498422190217059
Validation loss: 2.427646768204781

Epoch: 373| Step: 0
Training loss: 2.3037970422918668
Validation loss: 2.411451581879371

Epoch: 6| Step: 1
Training loss: 2.1171823198881508
Validation loss: 2.438466609549949

Epoch: 6| Step: 2
Training loss: 1.2520364385488065
Validation loss: 2.4271043257844354

Epoch: 6| Step: 3
Training loss: 1.5201242265632668
Validation loss: 2.397438919136362

Epoch: 6| Step: 4
Training loss: 1.6573510019297095
Validation loss: 2.382397933769265

Epoch: 6| Step: 5
Training loss: 1.7494841223969548
Validation loss: 2.3889796094400797

Epoch: 6| Step: 6
Training loss: 1.4608405585943585
Validation loss: 2.4015165857654224

Epoch: 6| Step: 7
Training loss: 1.6596298280728894
Validation loss: 2.437677732960432

Epoch: 6| Step: 8
Training loss: 1.0624589351123406
Validation loss: 2.4391810087415773

Epoch: 6| Step: 9
Training loss: 1.8119661268390235
Validation loss: 2.449179219340039

Epoch: 6| Step: 10
Training loss: 1.5721430949925685
Validation loss: 2.459842950094852

Epoch: 6| Step: 11
Training loss: 1.7868123792661417
Validation loss: 2.423912168053556

Epoch: 6| Step: 12
Training loss: 1.6895338447118358
Validation loss: 2.432970792270607

Epoch: 6| Step: 13
Training loss: 1.6506380696990763
Validation loss: 2.411842434846489

Epoch: 374| Step: 0
Training loss: 2.1694221092742665
Validation loss: 2.4055704148791714

Epoch: 6| Step: 1
Training loss: 1.7380028662487843
Validation loss: 2.4025400938721844

Epoch: 6| Step: 2
Training loss: 1.3473561713013193
Validation loss: 2.430381974518048

Epoch: 6| Step: 3
Training loss: 1.8933756971432893
Validation loss: 2.453443441890568

Epoch: 6| Step: 4
Training loss: 1.5178644997554689
Validation loss: 2.4523351403704754

Epoch: 6| Step: 5
Training loss: 1.9149557092589535
Validation loss: 2.4801499214582376

Epoch: 6| Step: 6
Training loss: 1.7668621488899272
Validation loss: 2.486533756032309

Epoch: 6| Step: 7
Training loss: 1.3904862066721246
Validation loss: 2.497782095635021

Epoch: 6| Step: 8
Training loss: 1.509655710342438
Validation loss: 2.4597445835026095

Epoch: 6| Step: 9
Training loss: 1.6630604193763057
Validation loss: 2.452924370227823

Epoch: 6| Step: 10
Training loss: 1.5474631992580183
Validation loss: 2.415271949213416

Epoch: 6| Step: 11
Training loss: 1.5365445991049047
Validation loss: 2.4081117916929027

Epoch: 6| Step: 12
Training loss: 1.5790437346882922
Validation loss: 2.3654190400148116

Epoch: 6| Step: 13
Training loss: 1.6074755672419363
Validation loss: 2.3350481280113637

Epoch: 375| Step: 0
Training loss: 1.7179982015003032
Validation loss: 2.344774411466265

Epoch: 6| Step: 1
Training loss: 1.6172976249019313
Validation loss: 2.3492404379170373

Epoch: 6| Step: 2
Training loss: 1.9132531771113206
Validation loss: 2.3213199894678893

Epoch: 6| Step: 3
Training loss: 1.5012833350654984
Validation loss: 2.3512206494964034

Epoch: 6| Step: 4
Training loss: 1.5927569717688144
Validation loss: 2.346979138558925

Epoch: 6| Step: 5
Training loss: 2.1570165626056235
Validation loss: 2.3921340800208677

Epoch: 6| Step: 6
Training loss: 2.075786910158824
Validation loss: 2.403377083621141

Epoch: 6| Step: 7
Training loss: 1.828824683728847
Validation loss: 2.4405569738396844

Epoch: 6| Step: 8
Training loss: 1.1646796517073157
Validation loss: 2.4634368835350124

Epoch: 6| Step: 9
Training loss: 1.6121195381274933
Validation loss: 2.449498009877689

Epoch: 6| Step: 10
Training loss: 1.2799344170428606
Validation loss: 2.4298629684192696

Epoch: 6| Step: 11
Training loss: 1.291407538642402
Validation loss: 2.4326193310525417

Epoch: 6| Step: 12
Training loss: 1.669047022756508
Validation loss: 2.4288214284876966

Epoch: 6| Step: 13
Training loss: 1.4792339238022885
Validation loss: 2.4429065744509044

Epoch: 376| Step: 0
Training loss: 1.6943855388317828
Validation loss: 2.4246065230939546

Epoch: 6| Step: 1
Training loss: 1.815619316683096
Validation loss: 2.4025071792911

Epoch: 6| Step: 2
Training loss: 2.0441410355555676
Validation loss: 2.400189126887834

Epoch: 6| Step: 3
Training loss: 1.5786925702133865
Validation loss: 2.3700062810211353

Epoch: 6| Step: 4
Training loss: 1.322860291048251
Validation loss: 2.374239318866752

Epoch: 6| Step: 5
Training loss: 1.846569749937675
Validation loss: 2.381290935904868

Epoch: 6| Step: 6
Training loss: 1.9594085325447212
Validation loss: 2.406506880925527

Epoch: 6| Step: 7
Training loss: 1.2289490049070333
Validation loss: 2.4208645568170386

Epoch: 6| Step: 8
Training loss: 1.7109783289666773
Validation loss: 2.4355146949011104

Epoch: 6| Step: 9
Training loss: 1.761161090022649
Validation loss: 2.4437539650663247

Epoch: 6| Step: 10
Training loss: 1.597565515455274
Validation loss: 2.4693940894257524

Epoch: 6| Step: 11
Training loss: 1.2704653076755785
Validation loss: 2.4601725498717792

Epoch: 6| Step: 12
Training loss: 1.518326151538087
Validation loss: 2.4568299103539486

Epoch: 6| Step: 13
Training loss: 1.7901975537616346
Validation loss: 2.466559105004871

Epoch: 377| Step: 0
Training loss: 1.7113228977857569
Validation loss: 2.4639174928219596

Epoch: 6| Step: 1
Training loss: 1.3430482673293855
Validation loss: 2.4323509138650223

Epoch: 6| Step: 2
Training loss: 2.107699484654951
Validation loss: 2.4030276124437773

Epoch: 6| Step: 3
Training loss: 1.6961087936514372
Validation loss: 2.416831222747794

Epoch: 6| Step: 4
Training loss: 1.300261980948821
Validation loss: 2.4035144337545233

Epoch: 6| Step: 5
Training loss: 1.5069767508532788
Validation loss: 2.4034853201390756

Epoch: 6| Step: 6
Training loss: 1.8123397756329547
Validation loss: 2.4304696752217674

Epoch: 6| Step: 7
Training loss: 1.3938644909555336
Validation loss: 2.423153167172996

Epoch: 6| Step: 8
Training loss: 1.8542431447690715
Validation loss: 2.3969180180145524

Epoch: 6| Step: 9
Training loss: 1.7963254005147011
Validation loss: 2.400756058378013

Epoch: 6| Step: 10
Training loss: 1.4047119206394498
Validation loss: 2.387531710075175

Epoch: 6| Step: 11
Training loss: 1.9744314534278666
Validation loss: 2.378429777395759

Epoch: 6| Step: 12
Training loss: 1.3113181833407959
Validation loss: 2.3879177241983713

Epoch: 6| Step: 13
Training loss: 1.4754741229971733
Validation loss: 2.3810883059941204

Epoch: 378| Step: 0
Training loss: 0.9686458593198214
Validation loss: 2.4289787342064324

Epoch: 6| Step: 1
Training loss: 1.8558498272322017
Validation loss: 2.454977193882311

Epoch: 6| Step: 2
Training loss: 1.478143965295012
Validation loss: 2.471876641932525

Epoch: 6| Step: 3
Training loss: 1.255081576625472
Validation loss: 2.4688760297700854

Epoch: 6| Step: 4
Training loss: 1.6096294905545168
Validation loss: 2.483593842240095

Epoch: 6| Step: 5
Training loss: 1.7549812403923377
Validation loss: 2.476071812042839

Epoch: 6| Step: 6
Training loss: 1.382497029499636
Validation loss: 2.497176102887231

Epoch: 6| Step: 7
Training loss: 2.3444627822391824
Validation loss: 2.464162855449329

Epoch: 6| Step: 8
Training loss: 1.5487642407320623
Validation loss: 2.464747476011499

Epoch: 6| Step: 9
Training loss: 1.6820725651622273
Validation loss: 2.4160991769018882

Epoch: 6| Step: 10
Training loss: 1.846308339513773
Validation loss: 2.3799979691666096

Epoch: 6| Step: 11
Training loss: 1.7301017423711498
Validation loss: 2.341850943203205

Epoch: 6| Step: 12
Training loss: 1.8097165538080688
Validation loss: 2.311587435481851

Epoch: 6| Step: 13
Training loss: 1.169477069341262
Validation loss: 2.307097849053316

Epoch: 379| Step: 0
Training loss: 1.5849458948762443
Validation loss: 2.36024137890067

Epoch: 6| Step: 1
Training loss: 1.8751247364514707
Validation loss: 2.3844872140883644

Epoch: 6| Step: 2
Training loss: 1.9956809137661042
Validation loss: 2.4207055879841577

Epoch: 6| Step: 3
Training loss: 1.645962778465501
Validation loss: 2.458307262620988

Epoch: 6| Step: 4
Training loss: 1.8546296159666638
Validation loss: 2.432447742337191

Epoch: 6| Step: 5
Training loss: 1.6855618685058804
Validation loss: 2.4207857803312067

Epoch: 6| Step: 6
Training loss: 1.4568345497043933
Validation loss: 2.4523853989529347

Epoch: 6| Step: 7
Training loss: 1.5389398051505956
Validation loss: 2.4766529139597306

Epoch: 6| Step: 8
Training loss: 1.6787309628768499
Validation loss: 2.4607318709577313

Epoch: 6| Step: 9
Training loss: 1.4211745999884546
Validation loss: 2.473366016579084

Epoch: 6| Step: 10
Training loss: 1.392771318257792
Validation loss: 2.430772422885645

Epoch: 6| Step: 11
Training loss: 1.6308067450340147
Validation loss: 2.4002744504941345

Epoch: 6| Step: 12
Training loss: 1.4626128845991042
Validation loss: 2.4112337416649123

Epoch: 6| Step: 13
Training loss: 1.8040931680815857
Validation loss: 2.3762528925698545

Epoch: 380| Step: 0
Training loss: 1.6354948215478442
Validation loss: 2.423604208556412

Epoch: 6| Step: 1
Training loss: 1.439885109583205
Validation loss: 2.47072452573349

Epoch: 6| Step: 2
Training loss: 1.4331331682533894
Validation loss: 2.498216788813947

Epoch: 6| Step: 3
Training loss: 1.6089761480504046
Validation loss: 2.5178593525637516

Epoch: 6| Step: 4
Training loss: 1.311925944174692
Validation loss: 2.5002584841624746

Epoch: 6| Step: 5
Training loss: 1.3518819266118458
Validation loss: 2.473749898647819

Epoch: 6| Step: 6
Training loss: 1.9286558041961688
Validation loss: 2.43417811840184

Epoch: 6| Step: 7
Training loss: 1.5812623215749397
Validation loss: 2.40512153747676

Epoch: 6| Step: 8
Training loss: 1.5199668279591871
Validation loss: 2.3702814278742745

Epoch: 6| Step: 9
Training loss: 1.959142646215018
Validation loss: 2.3379338269271877

Epoch: 6| Step: 10
Training loss: 1.7988996957463874
Validation loss: 2.3194361636964302

Epoch: 6| Step: 11
Training loss: 1.65557170869996
Validation loss: 2.3048142353999865

Epoch: 6| Step: 12
Training loss: 1.9199277115167517
Validation loss: 2.3560554923076498

Epoch: 6| Step: 13
Training loss: 1.7777438541328114
Validation loss: 2.3916716981571704

Epoch: 381| Step: 0
Training loss: 1.4530628970421824
Validation loss: 2.439731479917209

Epoch: 6| Step: 1
Training loss: 1.2122445712480319
Validation loss: 2.502162451362095

Epoch: 6| Step: 2
Training loss: 1.6725141070217153
Validation loss: 2.5255891178674217

Epoch: 6| Step: 3
Training loss: 1.6394180217745011
Validation loss: 2.5597408250542735

Epoch: 6| Step: 4
Training loss: 1.494238597176009
Validation loss: 2.521879947233239

Epoch: 6| Step: 5
Training loss: 1.90183735399348
Validation loss: 2.497124230014726

Epoch: 6| Step: 6
Training loss: 1.5252188416096313
Validation loss: 2.4413506861116634

Epoch: 6| Step: 7
Training loss: 1.458223647579432
Validation loss: 2.4279447647575267

Epoch: 6| Step: 8
Training loss: 1.6732089701383581
Validation loss: 2.4042375574135058

Epoch: 6| Step: 9
Training loss: 1.4624880146285402
Validation loss: 2.3710150369013974

Epoch: 6| Step: 10
Training loss: 1.727664302514944
Validation loss: 2.3694229814604775

Epoch: 6| Step: 11
Training loss: 1.767536917358923
Validation loss: 2.3820952338010324

Epoch: 6| Step: 12
Training loss: 1.6285989960987923
Validation loss: 2.380755450319936

Epoch: 6| Step: 13
Training loss: 2.0978069570949183
Validation loss: 2.407081865599781

Epoch: 382| Step: 0
Training loss: 1.75696614553178
Validation loss: 2.3846336985957874

Epoch: 6| Step: 1
Training loss: 1.2725062797706204
Validation loss: 2.389439353621617

Epoch: 6| Step: 2
Training loss: 1.2614669312305642
Validation loss: 2.3851749591284337

Epoch: 6| Step: 3
Training loss: 1.6470577739363619
Validation loss: 2.3876154002969066

Epoch: 6| Step: 4
Training loss: 2.003328057767213
Validation loss: 2.37967246013569

Epoch: 6| Step: 5
Training loss: 1.3442829760663568
Validation loss: 2.402242901947401

Epoch: 6| Step: 6
Training loss: 1.2750758298127864
Validation loss: 2.411785979386101

Epoch: 6| Step: 7
Training loss: 1.87477695410001
Validation loss: 2.4423260448125497

Epoch: 6| Step: 8
Training loss: 1.9608131156470288
Validation loss: 2.468697419754751

Epoch: 6| Step: 9
Training loss: 1.62308359850527
Validation loss: 2.4589269573805366

Epoch: 6| Step: 10
Training loss: 1.6317291316127984
Validation loss: 2.4528488422804435

Epoch: 6| Step: 11
Training loss: 0.9736488823057146
Validation loss: 2.429698233832469

Epoch: 6| Step: 12
Training loss: 1.8245910656679438
Validation loss: 2.4408677056388126

Epoch: 6| Step: 13
Training loss: 1.5374118066319729
Validation loss: 2.436215636837064

Epoch: 383| Step: 0
Training loss: 1.670002824929412
Validation loss: 2.46253507122865

Epoch: 6| Step: 1
Training loss: 1.727275304244825
Validation loss: 2.4470310634824846

Epoch: 6| Step: 2
Training loss: 1.1357933026371072
Validation loss: 2.5029380536086525

Epoch: 6| Step: 3
Training loss: 1.9026812306929144
Validation loss: 2.5230854367529423

Epoch: 6| Step: 4
Training loss: 1.6873208410030969
Validation loss: 2.5263459506437793

Epoch: 6| Step: 5
Training loss: 1.2440480627483725
Validation loss: 2.481988452079649

Epoch: 6| Step: 6
Training loss: 1.4698462757515904
Validation loss: 2.4759041702542772

Epoch: 6| Step: 7
Training loss: 0.894960625224575
Validation loss: 2.434539341006755

Epoch: 6| Step: 8
Training loss: 1.6532717143902218
Validation loss: 2.431713527669384

Epoch: 6| Step: 9
Training loss: 1.5596310025076938
Validation loss: 2.3974313953560182

Epoch: 6| Step: 10
Training loss: 2.081155617896485
Validation loss: 2.380126950297606

Epoch: 6| Step: 11
Training loss: 1.7615767800248183
Validation loss: 2.346682746916655

Epoch: 6| Step: 12
Training loss: 1.5521166070362653
Validation loss: 2.3334470895499337

Epoch: 6| Step: 13
Training loss: 1.7853284623367112
Validation loss: 2.339894423082556

Epoch: 384| Step: 0
Training loss: 1.6695257776766013
Validation loss: 2.3272062907248254

Epoch: 6| Step: 1
Training loss: 1.6792408903896257
Validation loss: 2.381469593178018

Epoch: 6| Step: 2
Training loss: 1.6425092503535401
Validation loss: 2.386978406238487

Epoch: 6| Step: 3
Training loss: 1.3693975406186178
Validation loss: 2.4138054768470325

Epoch: 6| Step: 4
Training loss: 1.6870129200203754
Validation loss: 2.4542516401138466

Epoch: 6| Step: 5
Training loss: 1.8933757601045325
Validation loss: 2.4608307346012057

Epoch: 6| Step: 6
Training loss: 1.665996877871149
Validation loss: 2.5073027014821307

Epoch: 6| Step: 7
Training loss: 1.485803097844999
Validation loss: 2.5156946740106396

Epoch: 6| Step: 8
Training loss: 1.623398138015166
Validation loss: 2.5082987856718106

Epoch: 6| Step: 9
Training loss: 1.3678790713924796
Validation loss: 2.4971025822488264

Epoch: 6| Step: 10
Training loss: 1.6325666616712518
Validation loss: 2.5088324882685575

Epoch: 6| Step: 11
Training loss: 1.4012188238100811
Validation loss: 2.5014963204591223

Epoch: 6| Step: 12
Training loss: 1.1206874842331802
Validation loss: 2.4468243464314647

Epoch: 6| Step: 13
Training loss: 2.028348287978115
Validation loss: 2.4675804608872705

Epoch: 385| Step: 0
Training loss: 1.128719750016969
Validation loss: 2.426222835142569

Epoch: 6| Step: 1
Training loss: 1.8136240006158226
Validation loss: 2.407334203696552

Epoch: 6| Step: 2
Training loss: 2.046653910337244
Validation loss: 2.3573393906475735

Epoch: 6| Step: 3
Training loss: 0.9948067822065262
Validation loss: 2.3718473178265698

Epoch: 6| Step: 4
Training loss: 1.2801831618778727
Validation loss: 2.3500779360447956

Epoch: 6| Step: 5
Training loss: 1.3953510941211797
Validation loss: 2.3907287626611566

Epoch: 6| Step: 6
Training loss: 1.7604681003738982
Validation loss: 2.388900262284572

Epoch: 6| Step: 7
Training loss: 1.926950281722227
Validation loss: 2.412583762105833

Epoch: 6| Step: 8
Training loss: 1.6695533390395747
Validation loss: 2.4357391046570136

Epoch: 6| Step: 9
Training loss: 1.5515142673398248
Validation loss: 2.4313037757442175

Epoch: 6| Step: 10
Training loss: 1.298445153242525
Validation loss: 2.4479149149249393

Epoch: 6| Step: 11
Training loss: 1.781736207157432
Validation loss: 2.4181806254914386

Epoch: 6| Step: 12
Training loss: 1.576241303797306
Validation loss: 2.429313768883059

Epoch: 6| Step: 13
Training loss: 1.506492946548738
Validation loss: 2.4407590056859734

Epoch: 386| Step: 0
Training loss: 1.378000626606792
Validation loss: 2.4806740875170625

Epoch: 6| Step: 1
Training loss: 1.4108580641917605
Validation loss: 2.509891331648265

Epoch: 6| Step: 2
Training loss: 1.5992587011403807
Validation loss: 2.5288328993739317

Epoch: 6| Step: 3
Training loss: 1.7614895487552986
Validation loss: 2.5507024314293756

Epoch: 6| Step: 4
Training loss: 1.4282582961632262
Validation loss: 2.5536857889693496

Epoch: 6| Step: 5
Training loss: 1.984168935574459
Validation loss: 2.5253320788111076

Epoch: 6| Step: 6
Training loss: 1.5576124424398727
Validation loss: 2.4945156843823457

Epoch: 6| Step: 7
Training loss: 1.3199305235756351
Validation loss: 2.439342733031379

Epoch: 6| Step: 8
Training loss: 1.7502779058774451
Validation loss: 2.400473744625142

Epoch: 6| Step: 9
Training loss: 1.1014277057828077
Validation loss: 2.396796353878551

Epoch: 6| Step: 10
Training loss: 1.1303537981263205
Validation loss: 2.3911553612990324

Epoch: 6| Step: 11
Training loss: 1.8967434581414002
Validation loss: 2.387758274901956

Epoch: 6| Step: 12
Training loss: 1.7582657293307415
Validation loss: 2.3566096425051675

Epoch: 6| Step: 13
Training loss: 1.6633952061007862
Validation loss: 2.3421424389691845

Epoch: 387| Step: 0
Training loss: 1.5382097854404184
Validation loss: 2.36449021790368

Epoch: 6| Step: 1
Training loss: 1.5863523645340876
Validation loss: 2.3838678979707497

Epoch: 6| Step: 2
Training loss: 1.7070174925924102
Validation loss: 2.3961246475660674

Epoch: 6| Step: 3
Training loss: 1.6101878067322515
Validation loss: 2.4243261344210616

Epoch: 6| Step: 4
Training loss: 1.8867488250546798
Validation loss: 2.428813564939793

Epoch: 6| Step: 5
Training loss: 1.181164808077449
Validation loss: 2.435798002424519

Epoch: 6| Step: 6
Training loss: 1.1699246771114973
Validation loss: 2.4426695204896713

Epoch: 6| Step: 7
Training loss: 1.51244390084133
Validation loss: 2.4615141302901002

Epoch: 6| Step: 8
Training loss: 1.7888181427905645
Validation loss: 2.4473944371167415

Epoch: 6| Step: 9
Training loss: 1.5619772990453973
Validation loss: 2.422730001791722

Epoch: 6| Step: 10
Training loss: 1.037857848810307
Validation loss: 2.418062736821912

Epoch: 6| Step: 11
Training loss: 1.4981851725296658
Validation loss: 2.4110347829697725

Epoch: 6| Step: 12
Training loss: 1.5584032138244968
Validation loss: 2.3818046979034393

Epoch: 6| Step: 13
Training loss: 2.248941808454034
Validation loss: 2.39533551212851

Epoch: 388| Step: 0
Training loss: 1.7623784422383242
Validation loss: 2.406478321252513

Epoch: 6| Step: 1
Training loss: 1.765959581389967
Validation loss: 2.438924779520512

Epoch: 6| Step: 2
Training loss: 1.8256017764036878
Validation loss: 2.4696806138471845

Epoch: 6| Step: 3
Training loss: 1.6888994136421016
Validation loss: 2.5306882995915196

Epoch: 6| Step: 4
Training loss: 1.25586065645286
Validation loss: 2.4987526843009733

Epoch: 6| Step: 5
Training loss: 1.2694254200180155
Validation loss: 2.5226768241927493

Epoch: 6| Step: 6
Training loss: 1.7171325008342084
Validation loss: 2.503297970555348

Epoch: 6| Step: 7
Training loss: 1.383770368472661
Validation loss: 2.5028974682973306

Epoch: 6| Step: 8
Training loss: 1.697880430556485
Validation loss: 2.4629093591769076

Epoch: 6| Step: 9
Training loss: 1.2017033091411056
Validation loss: 2.4385519247890635

Epoch: 6| Step: 10
Training loss: 0.9847949207129213
Validation loss: 2.4210456881096567

Epoch: 6| Step: 11
Training loss: 1.7344911553604652
Validation loss: 2.38154259915749

Epoch: 6| Step: 12
Training loss: 1.463059704613768
Validation loss: 2.3541605338857883

Epoch: 6| Step: 13
Training loss: 1.611425482380775
Validation loss: 2.351979064621237

Epoch: 389| Step: 0
Training loss: 1.2931937860305969
Validation loss: 2.3276621811434173

Epoch: 6| Step: 1
Training loss: 1.1303604949388366
Validation loss: 2.311055486930367

Epoch: 6| Step: 2
Training loss: 1.6152638959666255
Validation loss: 2.316165807768068

Epoch: 6| Step: 3
Training loss: 1.843741724028036
Validation loss: 2.3449421225102807

Epoch: 6| Step: 4
Training loss: 1.7727944977113739
Validation loss: 2.3407357010501477

Epoch: 6| Step: 5
Training loss: 1.230571730406703
Validation loss: 2.3571977680875653

Epoch: 6| Step: 6
Training loss: 1.2213293315691403
Validation loss: 2.4166046720904504

Epoch: 6| Step: 7
Training loss: 1.2759207635810046
Validation loss: 2.420872523490231

Epoch: 6| Step: 8
Training loss: 1.5960870698778773
Validation loss: 2.4695989889112977

Epoch: 6| Step: 9
Training loss: 1.620925490138297
Validation loss: 2.486034581202328

Epoch: 6| Step: 10
Training loss: 2.0092307696037457
Validation loss: 2.5000392828695572

Epoch: 6| Step: 11
Training loss: 1.70227743635002
Validation loss: 2.5436333891540066

Epoch: 6| Step: 12
Training loss: 1.6000156282615343
Validation loss: 2.506218153310065

Epoch: 6| Step: 13
Training loss: 1.0981950082538003
Validation loss: 2.4681931461240127

Epoch: 390| Step: 0
Training loss: 1.6184159924775308
Validation loss: 2.457666012094039

Epoch: 6| Step: 1
Training loss: 1.4859605853576912
Validation loss: 2.4047304897696296

Epoch: 6| Step: 2
Training loss: 1.4953332467069926
Validation loss: 2.3702437059721224

Epoch: 6| Step: 3
Training loss: 1.158291535115065
Validation loss: 2.35519523068539

Epoch: 6| Step: 4
Training loss: 1.4023572235735267
Validation loss: 2.3309698266020544

Epoch: 6| Step: 5
Training loss: 1.8318114321666292
Validation loss: 2.3255341406628878

Epoch: 6| Step: 6
Training loss: 1.9306042304485542
Validation loss: 2.3484693521718465

Epoch: 6| Step: 7
Training loss: 1.6541046787565477
Validation loss: 2.4028838400172154

Epoch: 6| Step: 8
Training loss: 1.3085621388730893
Validation loss: 2.439667960004694

Epoch: 6| Step: 9
Training loss: 1.5643505581917356
Validation loss: 2.4857077861956656

Epoch: 6| Step: 10
Training loss: 0.973981972609813
Validation loss: 2.492510205041633

Epoch: 6| Step: 11
Training loss: 1.4502983904339017
Validation loss: 2.5028684096131637

Epoch: 6| Step: 12
Training loss: 1.6513659602994775
Validation loss: 2.484666651017043

Epoch: 6| Step: 13
Training loss: 1.5718028270010154
Validation loss: 2.485917265663828

Epoch: 391| Step: 0
Training loss: 1.6586278005402832
Validation loss: 2.4894316911091257

Epoch: 6| Step: 1
Training loss: 1.5010712295293003
Validation loss: 2.4996110926403983

Epoch: 6| Step: 2
Training loss: 1.8272580430447096
Validation loss: 2.4931063790869503

Epoch: 6| Step: 3
Training loss: 1.446697169801213
Validation loss: 2.4697018168717952

Epoch: 6| Step: 4
Training loss: 1.7530001400361601
Validation loss: 2.462919162347034

Epoch: 6| Step: 5
Training loss: 1.609102837224949
Validation loss: 2.405391751541191

Epoch: 6| Step: 6
Training loss: 1.5619158606586263
Validation loss: 2.4014206852446143

Epoch: 6| Step: 7
Training loss: 1.4580958672600124
Validation loss: 2.386738734598584

Epoch: 6| Step: 8
Training loss: 1.6283774123510353
Validation loss: 2.3875771737958096

Epoch: 6| Step: 9
Training loss: 1.6251545612483038
Validation loss: 2.374405998726828

Epoch: 6| Step: 10
Training loss: 1.3501451149406163
Validation loss: 2.370153069932783

Epoch: 6| Step: 11
Training loss: 0.8163813902067896
Validation loss: 2.401325737458172

Epoch: 6| Step: 12
Training loss: 1.3713787250031835
Validation loss: 2.452510758146053

Epoch: 6| Step: 13
Training loss: 1.4222897773500287
Validation loss: 2.4647721840104513

Epoch: 392| Step: 0
Training loss: 1.970011715539477
Validation loss: 2.4658197500381958

Epoch: 6| Step: 1
Training loss: 1.4430799407334614
Validation loss: 2.466411517834288

Epoch: 6| Step: 2
Training loss: 1.5994974360348566
Validation loss: 2.4622202665466753

Epoch: 6| Step: 3
Training loss: 1.4978846893646576
Validation loss: 2.445891243317422

Epoch: 6| Step: 4
Training loss: 1.8574565960419667
Validation loss: 2.472258890806483

Epoch: 6| Step: 5
Training loss: 1.212423090117754
Validation loss: 2.474061714089166

Epoch: 6| Step: 6
Training loss: 1.3228156384116112
Validation loss: 2.4793644887606665

Epoch: 6| Step: 7
Training loss: 1.1769873430840407
Validation loss: 2.474030927144602

Epoch: 6| Step: 8
Training loss: 1.5596360471627266
Validation loss: 2.4458215052625487

Epoch: 6| Step: 9
Training loss: 1.6383249054178113
Validation loss: 2.4091627850618336

Epoch: 6| Step: 10
Training loss: 1.0525531789796077
Validation loss: 2.3951936171812513

Epoch: 6| Step: 11
Training loss: 1.5103845351736744
Validation loss: 2.382718881872349

Epoch: 6| Step: 12
Training loss: 1.6553366679940118
Validation loss: 2.3455192073934517

Epoch: 6| Step: 13
Training loss: 1.5161807427623895
Validation loss: 2.3677065895535794

Epoch: 393| Step: 0
Training loss: 1.1967213126131584
Validation loss: 2.378403378031143

Epoch: 6| Step: 1
Training loss: 1.508097093041763
Validation loss: 2.3875969778014356

Epoch: 6| Step: 2
Training loss: 1.7953300136578438
Validation loss: 2.3711742454967264

Epoch: 6| Step: 3
Training loss: 1.3352663016010724
Validation loss: 2.3720710906476565

Epoch: 6| Step: 4
Training loss: 1.7119426126487667
Validation loss: 2.3712050651065337

Epoch: 6| Step: 5
Training loss: 1.922336926036159
Validation loss: 2.3743153477390053

Epoch: 6| Step: 6
Training loss: 1.3867408858130927
Validation loss: 2.392698248601166

Epoch: 6| Step: 7
Training loss: 1.3703231167354812
Validation loss: 2.4019283047172446

Epoch: 6| Step: 8
Training loss: 1.3737475152726477
Validation loss: 2.4350932802526812

Epoch: 6| Step: 9
Training loss: 1.2698505645602898
Validation loss: 2.4676824047179635

Epoch: 6| Step: 10
Training loss: 1.1372674096385604
Validation loss: 2.5014607520100607

Epoch: 6| Step: 11
Training loss: 1.3300486377914873
Validation loss: 2.5382269250046865

Epoch: 6| Step: 12
Training loss: 1.9211461615810794
Validation loss: 2.5296995913506493

Epoch: 6| Step: 13
Training loss: 1.5915126429758815
Validation loss: 2.535417590409626

Epoch: 394| Step: 0
Training loss: 1.5040751572913929
Validation loss: 2.5478300901652307

Epoch: 6| Step: 1
Training loss: 1.586406319012467
Validation loss: 2.502859037936324

Epoch: 6| Step: 2
Training loss: 1.8050332006639844
Validation loss: 2.5051619014377335

Epoch: 6| Step: 3
Training loss: 1.234039985488066
Validation loss: 2.451638175532396

Epoch: 6| Step: 4
Training loss: 1.5524887562465934
Validation loss: 2.4202839600694213

Epoch: 6| Step: 5
Training loss: 1.6924556445757157
Validation loss: 2.381051484754112

Epoch: 6| Step: 6
Training loss: 1.583725311881727
Validation loss: 2.3739054801878874

Epoch: 6| Step: 7
Training loss: 1.4108696820931224
Validation loss: 2.372259386230092

Epoch: 6| Step: 8
Training loss: 1.415181597052731
Validation loss: 2.3612396341177955

Epoch: 6| Step: 9
Training loss: 1.9143068741480935
Validation loss: 2.350354314723676

Epoch: 6| Step: 10
Training loss: 1.2022811605659547
Validation loss: 2.3620827630179453

Epoch: 6| Step: 11
Training loss: 1.226542138580623
Validation loss: 2.376580465914879

Epoch: 6| Step: 12
Training loss: 1.4223285831890318
Validation loss: 2.3895607454095784

Epoch: 6| Step: 13
Training loss: 0.7655134314387134
Validation loss: 2.4188247849286277

Epoch: 395| Step: 0
Training loss: 1.0910089205089604
Validation loss: 2.417580876822636

Epoch: 6| Step: 1
Training loss: 1.6260412988004527
Validation loss: 2.4313476639050267

Epoch: 6| Step: 2
Training loss: 1.3777633123168274
Validation loss: 2.4332177888939843

Epoch: 6| Step: 3
Training loss: 1.3032513326246222
Validation loss: 2.4191347400469336

Epoch: 6| Step: 4
Training loss: 1.3906170276884804
Validation loss: 2.4266076207755654

Epoch: 6| Step: 5
Training loss: 1.1471435107819874
Validation loss: 2.4319856393231016

Epoch: 6| Step: 6
Training loss: 1.8134207524353412
Validation loss: 2.4454722688589845

Epoch: 6| Step: 7
Training loss: 1.7024354851328225
Validation loss: 2.442471273601802

Epoch: 6| Step: 8
Training loss: 1.738196758831436
Validation loss: 2.445151300564386

Epoch: 6| Step: 9
Training loss: 1.3397941913837002
Validation loss: 2.447200397190843

Epoch: 6| Step: 10
Training loss: 1.4514858065445704
Validation loss: 2.4531946464325465

Epoch: 6| Step: 11
Training loss: 1.1925552580884293
Validation loss: 2.452429008104073

Epoch: 6| Step: 12
Training loss: 1.4083910431784814
Validation loss: 2.4736581675754947

Epoch: 6| Step: 13
Training loss: 2.0515452678389603
Validation loss: 2.4817862633783485

Epoch: 396| Step: 0
Training loss: 1.6351472507161726
Validation loss: 2.452383467638248

Epoch: 6| Step: 1
Training loss: 1.4187238379935718
Validation loss: 2.4538720161829604

Epoch: 6| Step: 2
Training loss: 1.1910163116202872
Validation loss: 2.426850465956958

Epoch: 6| Step: 3
Training loss: 1.443912714916989
Validation loss: 2.4276481843255833

Epoch: 6| Step: 4
Training loss: 1.7998040251541783
Validation loss: 2.3944526274968205

Epoch: 6| Step: 5
Training loss: 1.312628966761866
Validation loss: 2.4063635209229197

Epoch: 6| Step: 6
Training loss: 1.5773076121785121
Validation loss: 2.403047629971027

Epoch: 6| Step: 7
Training loss: 1.224175529958598
Validation loss: 2.3802233468630996

Epoch: 6| Step: 8
Training loss: 1.6387232339333146
Validation loss: 2.377107974669555

Epoch: 6| Step: 9
Training loss: 1.6632956587067451
Validation loss: 2.3887514433113726

Epoch: 6| Step: 10
Training loss: 1.6248220933215054
Validation loss: 2.392518015397956

Epoch: 6| Step: 11
Training loss: 1.0955835504955034
Validation loss: 2.396225376519912

Epoch: 6| Step: 12
Training loss: 1.6364090291865365
Validation loss: 2.449606656938633

Epoch: 6| Step: 13
Training loss: 0.919060111096237
Validation loss: 2.485171852163806

Epoch: 397| Step: 0
Training loss: 1.3641660600745162
Validation loss: 2.4987042094012386

Epoch: 6| Step: 1
Training loss: 1.554814702489972
Validation loss: 2.5001654283078163

Epoch: 6| Step: 2
Training loss: 1.3031071211139553
Validation loss: 2.4598509301833795

Epoch: 6| Step: 3
Training loss: 1.258341044387601
Validation loss: 2.466331227989213

Epoch: 6| Step: 4
Training loss: 1.8070148472220848
Validation loss: 2.443180995561973

Epoch: 6| Step: 5
Training loss: 2.1103549517701845
Validation loss: 2.3934043509421024

Epoch: 6| Step: 6
Training loss: 0.9388388927648839
Validation loss: 2.3507410626877174

Epoch: 6| Step: 7
Training loss: 1.1906153320560768
Validation loss: 2.3528002200742577

Epoch: 6| Step: 8
Training loss: 1.6671889043228256
Validation loss: 2.3244159888135623

Epoch: 6| Step: 9
Training loss: 1.5652725036104997
Validation loss: 2.326879828643568

Epoch: 6| Step: 10
Training loss: 1.01061857637854
Validation loss: 2.3306819905268235

Epoch: 6| Step: 11
Training loss: 1.6066661369882136
Validation loss: 2.3600044500136232

Epoch: 6| Step: 12
Training loss: 1.522100399801273
Validation loss: 2.384111919094567

Epoch: 6| Step: 13
Training loss: 1.1968801353882261
Validation loss: 2.413159692863797

Epoch: 398| Step: 0
Training loss: 2.106160971913547
Validation loss: 2.463653747829781

Epoch: 6| Step: 1
Training loss: 1.5930132191331645
Validation loss: 2.445756204348434

Epoch: 6| Step: 2
Training loss: 0.9827165104941831
Validation loss: 2.443977421075041

Epoch: 6| Step: 3
Training loss: 0.978305360051889
Validation loss: 2.453944940584525

Epoch: 6| Step: 4
Training loss: 1.1951163137164338
Validation loss: 2.454829500437737

Epoch: 6| Step: 5
Training loss: 1.8323360100159234
Validation loss: 2.4705336038887475

Epoch: 6| Step: 6
Training loss: 1.4974496140704325
Validation loss: 2.4600997267073446

Epoch: 6| Step: 7
Training loss: 1.5784902622042163
Validation loss: 2.4488724168662785

Epoch: 6| Step: 8
Training loss: 1.4007288738443426
Validation loss: 2.4163409435436707

Epoch: 6| Step: 9
Training loss: 1.4877898438749182
Validation loss: 2.400763961502134

Epoch: 6| Step: 10
Training loss: 1.220917461651644
Validation loss: 2.37295082323607

Epoch: 6| Step: 11
Training loss: 1.6154050725298292
Validation loss: 2.384420433423876

Epoch: 6| Step: 12
Training loss: 1.4860374376964234
Validation loss: 2.377398426216161

Epoch: 6| Step: 13
Training loss: 0.969826500113745
Validation loss: 2.3754823623386363

Epoch: 399| Step: 0
Training loss: 1.3526652693825079
Validation loss: 2.4170829354680117

Epoch: 6| Step: 1
Training loss: 1.604586393593949
Validation loss: 2.3970673117683092

Epoch: 6| Step: 2
Training loss: 1.4536812650744546
Validation loss: 2.3908570201348653

Epoch: 6| Step: 3
Training loss: 0.9592896575743214
Validation loss: 2.4045776257650573

Epoch: 6| Step: 4
Training loss: 1.3225937496769635
Validation loss: 2.39238448048518

Epoch: 6| Step: 5
Training loss: 1.8109004098354058
Validation loss: 2.4262234522194173

Epoch: 6| Step: 6
Training loss: 1.1210230363083356
Validation loss: 2.4382375916394055

Epoch: 6| Step: 7
Training loss: 1.4335921700700167
Validation loss: 2.4536353686089587

Epoch: 6| Step: 8
Training loss: 1.2918436739241985
Validation loss: 2.4564793664351514

Epoch: 6| Step: 9
Training loss: 1.6304648281867289
Validation loss: 2.439061754408446

Epoch: 6| Step: 10
Training loss: 1.872941094714086
Validation loss: 2.4455512318609087

Epoch: 6| Step: 11
Training loss: 1.610886983884162
Validation loss: 2.434715847548821

Epoch: 6| Step: 12
Training loss: 1.34905340775286
Validation loss: 2.4249878841089445

Epoch: 6| Step: 13
Training loss: 1.2400155903236079
Validation loss: 2.43330667273643

Epoch: 400| Step: 0
Training loss: 1.0524200366490293
Validation loss: 2.421261345335961

Epoch: 6| Step: 1
Training loss: 1.4236734774608308
Validation loss: 2.4223090569802825

Epoch: 6| Step: 2
Training loss: 1.6513940413066428
Validation loss: 2.4184102076153047

Epoch: 6| Step: 3
Training loss: 1.3837044204744964
Validation loss: 2.4473358351902887

Epoch: 6| Step: 4
Training loss: 1.1679137354113216
Validation loss: 2.4094393842368067

Epoch: 6| Step: 5
Training loss: 2.1201576710494585
Validation loss: 2.4136752832125636

Epoch: 6| Step: 6
Training loss: 1.7401690229995412
Validation loss: 2.416443674098568

Epoch: 6| Step: 7
Training loss: 1.376308771969492
Validation loss: 2.4378212232517895

Epoch: 6| Step: 8
Training loss: 1.2740565942323783
Validation loss: 2.4311934397514428

Epoch: 6| Step: 9
Training loss: 1.2634929548005993
Validation loss: 2.4474163621979517

Epoch: 6| Step: 10
Training loss: 1.373338388939845
Validation loss: 2.4660388706637693

Epoch: 6| Step: 11
Training loss: 1.471019857681022
Validation loss: 2.487047062411831

Epoch: 6| Step: 12
Training loss: 1.1174355611634441
Validation loss: 2.4882433630148366

Epoch: 6| Step: 13
Training loss: 1.3266420050745777
Validation loss: 2.4772175025280334

Epoch: 401| Step: 0
Training loss: 2.2401965935472
Validation loss: 2.493713658429089

Epoch: 6| Step: 1
Training loss: 1.609967613368347
Validation loss: 2.488119679469171

Epoch: 6| Step: 2
Training loss: 1.33245780133674
Validation loss: 2.4567356712741657

Epoch: 6| Step: 3
Training loss: 1.2684304497356764
Validation loss: 2.460445620407331

Epoch: 6| Step: 4
Training loss: 1.3128385561305285
Validation loss: 2.41659241931086

Epoch: 6| Step: 5
Training loss: 1.7407673748419714
Validation loss: 2.4134545632496205

Epoch: 6| Step: 6
Training loss: 1.4475734862021072
Validation loss: 2.398623518433873

Epoch: 6| Step: 7
Training loss: 1.4254476078484777
Validation loss: 2.3743468445934663

Epoch: 6| Step: 8
Training loss: 0.9824640101958487
Validation loss: 2.394455425125385

Epoch: 6| Step: 9
Training loss: 1.6867228943922712
Validation loss: 2.412736904085349

Epoch: 6| Step: 10
Training loss: 1.4069467302065113
Validation loss: 2.425874424765656

Epoch: 6| Step: 11
Training loss: 0.6359434263435926
Validation loss: 2.4426160634420184

Epoch: 6| Step: 12
Training loss: 1.0190503385649292
Validation loss: 2.4586137010708047

Epoch: 6| Step: 13
Training loss: 1.2407787179722907
Validation loss: 2.456175464178785

Epoch: 402| Step: 0
Training loss: 1.74401773017655
Validation loss: 2.4631343517752557

Epoch: 6| Step: 1
Training loss: 1.45169784851104
Validation loss: 2.4498092725296443

Epoch: 6| Step: 2
Training loss: 1.0969770509028525
Validation loss: 2.459827700622909

Epoch: 6| Step: 3
Training loss: 1.3678431219586817
Validation loss: 2.4356109581500505

Epoch: 6| Step: 4
Training loss: 1.6788857609211763
Validation loss: 2.4361118447826615

Epoch: 6| Step: 5
Training loss: 1.1031748557779288
Validation loss: 2.4403360872777546

Epoch: 6| Step: 6
Training loss: 1.5991831899918745
Validation loss: 2.4762536756896716

Epoch: 6| Step: 7
Training loss: 1.007076911690098
Validation loss: 2.451263273069886

Epoch: 6| Step: 8
Training loss: 1.6310722166500582
Validation loss: 2.4516786275129507

Epoch: 6| Step: 9
Training loss: 1.2074668616729276
Validation loss: 2.473873161745281

Epoch: 6| Step: 10
Training loss: 0.9351503810204435
Validation loss: 2.418297551142677

Epoch: 6| Step: 11
Training loss: 1.9006688697415932
Validation loss: 2.440112268392379

Epoch: 6| Step: 12
Training loss: 1.5443750081511944
Validation loss: 2.4408919663722437

Epoch: 6| Step: 13
Training loss: 1.0533198213213613
Validation loss: 2.4087188876057457

Epoch: 403| Step: 0
Training loss: 1.3135097343481996
Validation loss: 2.405473108252408

Epoch: 6| Step: 1
Training loss: 1.687697081183615
Validation loss: 2.4205397143829437

Epoch: 6| Step: 2
Training loss: 1.39337922711209
Validation loss: 2.401380519878891

Epoch: 6| Step: 3
Training loss: 1.2065502801022912
Validation loss: 2.41810074113854

Epoch: 6| Step: 4
Training loss: 1.2738738453324259
Validation loss: 2.4129003264148907

Epoch: 6| Step: 5
Training loss: 1.1903902818699719
Validation loss: 2.459096825639494

Epoch: 6| Step: 6
Training loss: 1.864289784544462
Validation loss: 2.4647763142941748

Epoch: 6| Step: 7
Training loss: 1.5857394992144507
Validation loss: 2.483465217861958

Epoch: 6| Step: 8
Training loss: 1.5643627507350881
Validation loss: 2.4610469399875368

Epoch: 6| Step: 9
Training loss: 1.5631694122679713
Validation loss: 2.4633613844270448

Epoch: 6| Step: 10
Training loss: 1.1586961388441066
Validation loss: 2.462487399702669

Epoch: 6| Step: 11
Training loss: 1.279038870616731
Validation loss: 2.4471158475630452

Epoch: 6| Step: 12
Training loss: 1.0151062447513757
Validation loss: 2.4519000930214974

Epoch: 6| Step: 13
Training loss: 1.6502324316288473
Validation loss: 2.437631148645589

Epoch: 404| Step: 0
Training loss: 1.5150113780787284
Validation loss: 2.4385972962130382

Epoch: 6| Step: 1
Training loss: 1.4866544387867613
Validation loss: 2.4373129685351915

Epoch: 6| Step: 2
Training loss: 1.4448869233288344
Validation loss: 2.422408310850057

Epoch: 6| Step: 3
Training loss: 1.7229434788134848
Validation loss: 2.402450800045513

Epoch: 6| Step: 4
Training loss: 1.5933440944409325
Validation loss: 2.406685488110877

Epoch: 6| Step: 5
Training loss: 1.3657930074390159
Validation loss: 2.388338736623246

Epoch: 6| Step: 6
Training loss: 1.3936414684924243
Validation loss: 2.3520700195055437

Epoch: 6| Step: 7
Training loss: 1.314083098296611
Validation loss: 2.388207124607446

Epoch: 6| Step: 8
Training loss: 1.3774633882506893
Validation loss: 2.3853306410680575

Epoch: 6| Step: 9
Training loss: 0.8159737057142548
Validation loss: 2.3989344785392843

Epoch: 6| Step: 10
Training loss: 1.2730849544498761
Validation loss: 2.431589620297196

Epoch: 6| Step: 11
Training loss: 0.982343363421282
Validation loss: 2.468440881652108

Epoch: 6| Step: 12
Training loss: 1.7654214252152398
Validation loss: 2.462749317791064

Epoch: 6| Step: 13
Training loss: 1.4719723193478849
Validation loss: 2.4818253159900676

Epoch: 405| Step: 0
Training loss: 1.6414364215995587
Validation loss: 2.4963825520997376

Epoch: 6| Step: 1
Training loss: 1.1836363529809408
Validation loss: 2.4817870525765016

Epoch: 6| Step: 2
Training loss: 1.493766548352373
Validation loss: 2.4763498398387314

Epoch: 6| Step: 3
Training loss: 1.7559159962453674
Validation loss: 2.4555430740384203

Epoch: 6| Step: 4
Training loss: 1.2864832650470168
Validation loss: 2.423415960790043

Epoch: 6| Step: 5
Training loss: 1.1506076472029112
Validation loss: 2.3987796239215258

Epoch: 6| Step: 6
Training loss: 1.3053465680440837
Validation loss: 2.3891876637534244

Epoch: 6| Step: 7
Training loss: 1.513326573517836
Validation loss: 2.3952146586492646

Epoch: 6| Step: 8
Training loss: 0.9598069402165171
Validation loss: 2.376412662906212

Epoch: 6| Step: 9
Training loss: 0.8423176015603294
Validation loss: 2.40515474457576

Epoch: 6| Step: 10
Training loss: 1.1756119210115483
Validation loss: 2.399123633174215

Epoch: 6| Step: 11
Training loss: 1.825432383906375
Validation loss: 2.441974426703028

Epoch: 6| Step: 12
Training loss: 1.8185066138947785
Validation loss: 2.4519377584554087

Epoch: 6| Step: 13
Training loss: 1.4710285287783709
Validation loss: 2.4954938598892324

Epoch: 406| Step: 0
Training loss: 2.0424535623265108
Validation loss: 2.502957849259031

Epoch: 6| Step: 1
Training loss: 1.319780998919498
Validation loss: 2.4925747912277565

Epoch: 6| Step: 2
Training loss: 1.6488075021892377
Validation loss: 2.4975305245671136

Epoch: 6| Step: 3
Training loss: 1.1301264520801844
Validation loss: 2.4934475573293495

Epoch: 6| Step: 4
Training loss: 1.143605766165501
Validation loss: 2.4662974938015996

Epoch: 6| Step: 5
Training loss: 1.8354674691289719
Validation loss: 2.454425712257138

Epoch: 6| Step: 6
Training loss: 1.4358881330669089
Validation loss: 2.4265593744337366

Epoch: 6| Step: 7
Training loss: 1.4036129279399299
Validation loss: 2.4060606938615683

Epoch: 6| Step: 8
Training loss: 1.3267702261283503
Validation loss: 2.408596886107281

Epoch: 6| Step: 9
Training loss: 1.2723518377508696
Validation loss: 2.40517428766761

Epoch: 6| Step: 10
Training loss: 1.0206207650932477
Validation loss: 2.4221155233095994

Epoch: 6| Step: 11
Training loss: 1.2683576118026991
Validation loss: 2.4298890466171743

Epoch: 6| Step: 12
Training loss: 1.3475361203818035
Validation loss: 2.4343230939945437

Epoch: 6| Step: 13
Training loss: 0.8238402668260323
Validation loss: 2.4357407486776372

Epoch: 407| Step: 0
Training loss: 1.6143863024520873
Validation loss: 2.4236728130960716

Epoch: 6| Step: 1
Training loss: 1.13916099342286
Validation loss: 2.41838378514424

Epoch: 6| Step: 2
Training loss: 1.1116037680596025
Validation loss: 2.425189525833791

Epoch: 6| Step: 3
Training loss: 1.3551445389123604
Validation loss: 2.408807744734871

Epoch: 6| Step: 4
Training loss: 1.592057994183972
Validation loss: 2.4023527075687805

Epoch: 6| Step: 5
Training loss: 1.42132901618748
Validation loss: 2.3956114781737825

Epoch: 6| Step: 6
Training loss: 1.6889057661908653
Validation loss: 2.4369156849403963

Epoch: 6| Step: 7
Training loss: 1.2746165147652133
Validation loss: 2.4280205394629375

Epoch: 6| Step: 8
Training loss: 1.1307229073361624
Validation loss: 2.4407415016127376

Epoch: 6| Step: 9
Training loss: 1.027057564330256
Validation loss: 2.442899405836657

Epoch: 6| Step: 10
Training loss: 1.312404538270637
Validation loss: 2.444919918852695

Epoch: 6| Step: 11
Training loss: 1.7048757811012496
Validation loss: 2.4487179521891367

Epoch: 6| Step: 12
Training loss: 1.4906759545276298
Validation loss: 2.4488768948303883

Epoch: 6| Step: 13
Training loss: 1.3879456156759078
Validation loss: 2.4345162911448885

Epoch: 408| Step: 0
Training loss: 1.3272378988197544
Validation loss: 2.441638142653878

Epoch: 6| Step: 1
Training loss: 1.6740685449419515
Validation loss: 2.447864849420983

Epoch: 6| Step: 2
Training loss: 1.2695721898446937
Validation loss: 2.430321328928291

Epoch: 6| Step: 3
Training loss: 1.1653943731098493
Validation loss: 2.4418626201059683

Epoch: 6| Step: 4
Training loss: 1.4184778733946402
Validation loss: 2.443254164562661

Epoch: 6| Step: 5
Training loss: 1.3931193751156983
Validation loss: 2.4554935357457217

Epoch: 6| Step: 6
Training loss: 1.8471636448163442
Validation loss: 2.4300479189649327

Epoch: 6| Step: 7
Training loss: 1.2920311700615839
Validation loss: 2.462530569691852

Epoch: 6| Step: 8
Training loss: 1.1311791582213602
Validation loss: 2.4632379491674086

Epoch: 6| Step: 9
Training loss: 1.6622774821347681
Validation loss: 2.476379486109322

Epoch: 6| Step: 10
Training loss: 1.2423145541105844
Validation loss: 2.477327599658771

Epoch: 6| Step: 11
Training loss: 1.1099005515423284
Validation loss: 2.476782843860787

Epoch: 6| Step: 12
Training loss: 1.0977331928694494
Validation loss: 2.4650490256383066

Epoch: 6| Step: 13
Training loss: 1.5645599519258333
Validation loss: 2.476321177229723

Epoch: 409| Step: 0
Training loss: 1.5624780271892527
Validation loss: 2.455641060842628

Epoch: 6| Step: 1
Training loss: 1.2669029847767759
Validation loss: 2.4487106330781496

Epoch: 6| Step: 2
Training loss: 1.4205101085546203
Validation loss: 2.4204339277524918

Epoch: 6| Step: 3
Training loss: 1.0685016321179603
Validation loss: 2.429061066080495

Epoch: 6| Step: 4
Training loss: 1.257556391640358
Validation loss: 2.415855125767549

Epoch: 6| Step: 5
Training loss: 1.6313958844543452
Validation loss: 2.4197469740116393

Epoch: 6| Step: 6
Training loss: 1.8761877112878846
Validation loss: 2.384773633791499

Epoch: 6| Step: 7
Training loss: 1.4621129330697005
Validation loss: 2.4109076946313373

Epoch: 6| Step: 8
Training loss: 1.251722293706365
Validation loss: 2.3994949925968148

Epoch: 6| Step: 9
Training loss: 1.056344602512891
Validation loss: 2.397853868891918

Epoch: 6| Step: 10
Training loss: 0.9136755686763163
Validation loss: 2.4319447485643364

Epoch: 6| Step: 11
Training loss: 1.2839718262442479
Validation loss: 2.4198082803181977

Epoch: 6| Step: 12
Training loss: 1.2832409346539175
Validation loss: 2.434164476980892

Epoch: 6| Step: 13
Training loss: 1.9172438982414934
Validation loss: 2.451045238225783

Epoch: 410| Step: 0
Training loss: 1.0483516129222634
Validation loss: 2.4269939129569855

Epoch: 6| Step: 1
Training loss: 1.482093905430064
Validation loss: 2.4311695894451018

Epoch: 6| Step: 2
Training loss: 1.1573837495434587
Validation loss: 2.413210867190971

Epoch: 6| Step: 3
Training loss: 1.9019753101282688
Validation loss: 2.400617934776381

Epoch: 6| Step: 4
Training loss: 1.1190570047771453
Validation loss: 2.4247755028145943

Epoch: 6| Step: 5
Training loss: 1.6476337226930242
Validation loss: 2.396744880417795

Epoch: 6| Step: 6
Training loss: 1.0797607617841087
Validation loss: 2.412533008031473

Epoch: 6| Step: 7
Training loss: 1.322437449888806
Validation loss: 2.4189313133297965

Epoch: 6| Step: 8
Training loss: 1.374914946959957
Validation loss: 2.4540438760270518

Epoch: 6| Step: 9
Training loss: 1.184822829236761
Validation loss: 2.469082593029287

Epoch: 6| Step: 10
Training loss: 1.7196083699757623
Validation loss: 2.4725574278678097

Epoch: 6| Step: 11
Training loss: 1.048783455861804
Validation loss: 2.490769223855803

Epoch: 6| Step: 12
Training loss: 1.494803487307855
Validation loss: 2.4664892975422426

Epoch: 6| Step: 13
Training loss: 1.3761172090750438
Validation loss: 2.4816706142125415

Epoch: 411| Step: 0
Training loss: 1.2546060100994645
Validation loss: 2.4838261027932766

Epoch: 6| Step: 1
Training loss: 0.8314815370869147
Validation loss: 2.47201390967488

Epoch: 6| Step: 2
Training loss: 1.8414912207852765
Validation loss: 2.4642244430117386

Epoch: 6| Step: 3
Training loss: 1.068476417727536
Validation loss: 2.4394577027506505

Epoch: 6| Step: 4
Training loss: 1.6464221078268821
Validation loss: 2.431306179844362

Epoch: 6| Step: 5
Training loss: 1.259281603660641
Validation loss: 2.391074665719213

Epoch: 6| Step: 6
Training loss: 1.4936474752954738
Validation loss: 2.402710104812921

Epoch: 6| Step: 7
Training loss: 1.155968966998102
Validation loss: 2.3753164983975954

Epoch: 6| Step: 8
Training loss: 1.419869150392331
Validation loss: 2.3987436887745304

Epoch: 6| Step: 9
Training loss: 1.1013060467386298
Validation loss: 2.4203251468706144

Epoch: 6| Step: 10
Training loss: 1.5972765632267925
Validation loss: 2.4451834324730775

Epoch: 6| Step: 11
Training loss: 1.5537973280409505
Validation loss: 2.4919878290465447

Epoch: 6| Step: 12
Training loss: 1.2766631293351558
Validation loss: 2.521484266211083

Epoch: 6| Step: 13
Training loss: 1.4931414685432918
Validation loss: 2.5387368686766782

Epoch: 412| Step: 0
Training loss: 1.035433347070042
Validation loss: 2.5103817493405285

Epoch: 6| Step: 1
Training loss: 0.9613697971455669
Validation loss: 2.491633704951045

Epoch: 6| Step: 2
Training loss: 1.468710878541067
Validation loss: 2.465467606089304

Epoch: 6| Step: 3
Training loss: 1.1718549599523471
Validation loss: 2.4285998107618894

Epoch: 6| Step: 4
Training loss: 1.71654473059954
Validation loss: 2.4100878063881157

Epoch: 6| Step: 5
Training loss: 1.3700272196829226
Validation loss: 2.3847005764915674

Epoch: 6| Step: 6
Training loss: 1.2739959147730653
Validation loss: 2.3658255708922806

Epoch: 6| Step: 7
Training loss: 1.6350313287469103
Validation loss: 2.378024662241403

Epoch: 6| Step: 8
Training loss: 1.0725182963413438
Validation loss: 2.400705987568494

Epoch: 6| Step: 9
Training loss: 1.1103147368082438
Validation loss: 2.413417282984219

Epoch: 6| Step: 10
Training loss: 1.4420431740602921
Validation loss: 2.4310134948123605

Epoch: 6| Step: 11
Training loss: 1.6313471447311005
Validation loss: 2.4548829964643484

Epoch: 6| Step: 12
Training loss: 1.6138910429621534
Validation loss: 2.498015094665792

Epoch: 6| Step: 13
Training loss: 1.1300685403511677
Validation loss: 2.478096641526512

Epoch: 413| Step: 0
Training loss: 0.9814420329935879
Validation loss: 2.4939102265712667

Epoch: 6| Step: 1
Training loss: 1.4641846661808329
Validation loss: 2.470999147359147

Epoch: 6| Step: 2
Training loss: 1.2509399694589431
Validation loss: 2.4318003860009147

Epoch: 6| Step: 3
Training loss: 1.079336729359679
Validation loss: 2.4179453852556705

Epoch: 6| Step: 4
Training loss: 1.204581827756314
Validation loss: 2.4090468995012273

Epoch: 6| Step: 5
Training loss: 0.8404645178100214
Validation loss: 2.406201928794151

Epoch: 6| Step: 6
Training loss: 1.7263193088680477
Validation loss: 2.415904219384134

Epoch: 6| Step: 7
Training loss: 1.3589467218045184
Validation loss: 2.421302742091794

Epoch: 6| Step: 8
Training loss: 1.3618545280693028
Validation loss: 2.4080176198215435

Epoch: 6| Step: 9
Training loss: 1.5614925951652348
Validation loss: 2.4453089836981476

Epoch: 6| Step: 10
Training loss: 1.6840789166668069
Validation loss: 2.4036803826282727

Epoch: 6| Step: 11
Training loss: 1.2913871380637354
Validation loss: 2.4152888025304957

Epoch: 6| Step: 12
Training loss: 1.7109940053588444
Validation loss: 2.4260907268932175

Epoch: 6| Step: 13
Training loss: 0.32744099076287647
Validation loss: 2.4158887870070793

Epoch: 414| Step: 0
Training loss: 1.3272282883044322
Validation loss: 2.4439355618684973

Epoch: 6| Step: 1
Training loss: 1.1847841426761831
Validation loss: 2.4758148136099916

Epoch: 6| Step: 2
Training loss: 1.7556093778421038
Validation loss: 2.4692040904970325

Epoch: 6| Step: 3
Training loss: 0.9915499403452964
Validation loss: 2.488437854682821

Epoch: 6| Step: 4
Training loss: 1.394207743244615
Validation loss: 2.48758422281071

Epoch: 6| Step: 5
Training loss: 1.6247238511415598
Validation loss: 2.502996568471735

Epoch: 6| Step: 6
Training loss: 1.2049906249097129
Validation loss: 2.4743217397377046

Epoch: 6| Step: 7
Training loss: 1.3362399645607836
Validation loss: 2.4680068669540316

Epoch: 6| Step: 8
Training loss: 1.1738689498022403
Validation loss: 2.438927931874107

Epoch: 6| Step: 9
Training loss: 1.5366674851989772
Validation loss: 2.4136168705819387

Epoch: 6| Step: 10
Training loss: 1.2118323188651228
Validation loss: 2.417670554512255

Epoch: 6| Step: 11
Training loss: 1.1590087558919178
Validation loss: 2.3870127356734763

Epoch: 6| Step: 12
Training loss: 1.4070611098031887
Validation loss: 2.3843869504625212

Epoch: 6| Step: 13
Training loss: 1.1092277214180781
Validation loss: 2.36307632831105

Epoch: 415| Step: 0
Training loss: 1.5446941531017029
Validation loss: 2.3919160474559624

Epoch: 6| Step: 1
Training loss: 1.0126206785269212
Validation loss: 2.4358476534202373

Epoch: 6| Step: 2
Training loss: 1.1014167202200085
Validation loss: 2.474259021838402

Epoch: 6| Step: 3
Training loss: 1.4451944663849068
Validation loss: 2.5278205726724474

Epoch: 6| Step: 4
Training loss: 1.2123325310901012
Validation loss: 2.5384780077255753

Epoch: 6| Step: 5
Training loss: 1.2498579898275315
Validation loss: 2.509469732736485

Epoch: 6| Step: 6
Training loss: 1.7178766285760134
Validation loss: 2.488782085362002

Epoch: 6| Step: 7
Training loss: 1.6295274606540495
Validation loss: 2.5068286847853662

Epoch: 6| Step: 8
Training loss: 1.1758483664788277
Validation loss: 2.446509715473477

Epoch: 6| Step: 9
Training loss: 1.5633980268473995
Validation loss: 2.4450422992994403

Epoch: 6| Step: 10
Training loss: 0.8061887200302899
Validation loss: 2.395925615485351

Epoch: 6| Step: 11
Training loss: 1.1639344317757265
Validation loss: 2.381765370130277

Epoch: 6| Step: 12
Training loss: 1.2857569070593802
Validation loss: 2.342538863328846

Epoch: 6| Step: 13
Training loss: 1.6163156711722353
Validation loss: 2.3298612975984487

Epoch: 416| Step: 0
Training loss: 2.009642720519183
Validation loss: 2.3400980597396446

Epoch: 6| Step: 1
Training loss: 1.000545353004035
Validation loss: 2.311049842279523

Epoch: 6| Step: 2
Training loss: 1.5681088296140901
Validation loss: 2.352740127174988

Epoch: 6| Step: 3
Training loss: 1.5281532269388636
Validation loss: 2.384487674245198

Epoch: 6| Step: 4
Training loss: 1.5483560889097716
Validation loss: 2.382876076632689

Epoch: 6| Step: 5
Training loss: 0.9989599541474294
Validation loss: 2.440005195895573

Epoch: 6| Step: 6
Training loss: 1.2322281142566807
Validation loss: 2.4703750485267544

Epoch: 6| Step: 7
Training loss: 0.9469328935002658
Validation loss: 2.483641733131968

Epoch: 6| Step: 8
Training loss: 1.7404935667318513
Validation loss: 2.4911192175248837

Epoch: 6| Step: 9
Training loss: 1.2040880485574526
Validation loss: 2.498273310621613

Epoch: 6| Step: 10
Training loss: 0.7791089283022877
Validation loss: 2.507578677406543

Epoch: 6| Step: 11
Training loss: 0.9126086614525869
Validation loss: 2.4984787978693115

Epoch: 6| Step: 12
Training loss: 1.460988905711157
Validation loss: 2.4940286257668456

Epoch: 6| Step: 13
Training loss: 0.41178606557943337
Validation loss: 2.4657249198468394

Epoch: 417| Step: 0
Training loss: 1.5024706837972466
Validation loss: 2.435671889365664

Epoch: 6| Step: 1
Training loss: 0.8418062922046116
Validation loss: 2.4161610129136455

Epoch: 6| Step: 2
Training loss: 1.406242752056517
Validation loss: 2.4063971902879704

Epoch: 6| Step: 3
Training loss: 1.5484911250154807
Validation loss: 2.365319140828147

Epoch: 6| Step: 4
Training loss: 0.925734699865581
Validation loss: 2.361566435454277

Epoch: 6| Step: 5
Training loss: 1.626219951753739
Validation loss: 2.342597523847554

Epoch: 6| Step: 6
Training loss: 1.3555531764053006
Validation loss: 2.374166723506529

Epoch: 6| Step: 7
Training loss: 1.5704880042238887
Validation loss: 2.365066593499308

Epoch: 6| Step: 8
Training loss: 1.241540896469956
Validation loss: 2.398367109512026

Epoch: 6| Step: 9
Training loss: 1.3542599963769384
Validation loss: 2.410749326721354

Epoch: 6| Step: 10
Training loss: 1.1848267028540074
Validation loss: 2.44135070186303

Epoch: 6| Step: 11
Training loss: 0.8433416932776008
Validation loss: 2.4700169270047403

Epoch: 6| Step: 12
Training loss: 1.4124957093030188
Validation loss: 2.5091738014932896

Epoch: 6| Step: 13
Training loss: 1.3395344012841983
Validation loss: 2.516477938193252

Epoch: 418| Step: 0
Training loss: 1.724236902816342
Validation loss: 2.511956883909888

Epoch: 6| Step: 1
Training loss: 1.1236311213803707
Validation loss: 2.506449416906832

Epoch: 6| Step: 2
Training loss: 1.290485590686187
Validation loss: 2.4768920091258515

Epoch: 6| Step: 3
Training loss: 1.1646312373936907
Validation loss: 2.448778769794641

Epoch: 6| Step: 4
Training loss: 1.4038426881049964
Validation loss: 2.454141059835355

Epoch: 6| Step: 5
Training loss: 1.5534476699143205
Validation loss: 2.4258723365470636

Epoch: 6| Step: 6
Training loss: 1.6975858713264975
Validation loss: 2.4109307958168773

Epoch: 6| Step: 7
Training loss: 0.5393427797420728
Validation loss: 2.407804686066562

Epoch: 6| Step: 8
Training loss: 1.2745013327698231
Validation loss: 2.4277155974786417

Epoch: 6| Step: 9
Training loss: 1.4721868358813808
Validation loss: 2.414693059040819

Epoch: 6| Step: 10
Training loss: 0.7703719605561226
Validation loss: 2.38493179170096

Epoch: 6| Step: 11
Training loss: 0.8739735168180814
Validation loss: 2.34786706314764

Epoch: 6| Step: 12
Training loss: 1.6634757570105996
Validation loss: 2.375542260350401

Epoch: 6| Step: 13
Training loss: 1.0183942747116972
Validation loss: 2.3750467452331803

Epoch: 419| Step: 0
Training loss: 1.349434605280722
Validation loss: 2.3837488468667964

Epoch: 6| Step: 1
Training loss: 1.556410405115441
Validation loss: 2.379578559023716

Epoch: 6| Step: 2
Training loss: 1.4081089871880672
Validation loss: 2.3816099965799333

Epoch: 6| Step: 3
Training loss: 0.8382301265204928
Validation loss: 2.3959429066244877

Epoch: 6| Step: 4
Training loss: 2.039677903421771
Validation loss: 2.446309860449251

Epoch: 6| Step: 5
Training loss: 1.3790214857843965
Validation loss: 2.4594502064528685

Epoch: 6| Step: 6
Training loss: 0.8738048770354575
Validation loss: 2.4806361845927176

Epoch: 6| Step: 7
Training loss: 1.1343829614449226
Validation loss: 2.523834505113156

Epoch: 6| Step: 8
Training loss: 1.259936795693036
Validation loss: 2.5198419479672864

Epoch: 6| Step: 9
Training loss: 1.3033184703766438
Validation loss: 2.511657972338391

Epoch: 6| Step: 10
Training loss: 0.8845439237337928
Validation loss: 2.512719077657134

Epoch: 6| Step: 11
Training loss: 1.3416357485049974
Validation loss: 2.487173072090508

Epoch: 6| Step: 12
Training loss: 1.0298091764438693
Validation loss: 2.4612613473358973

Epoch: 6| Step: 13
Training loss: 1.3856426523174237
Validation loss: 2.4422589173821088

Epoch: 420| Step: 0
Training loss: 1.3470305386191719
Validation loss: 2.4283287919066687

Epoch: 6| Step: 1
Training loss: 1.5268791253014267
Validation loss: 2.4143609117599762

Epoch: 6| Step: 2
Training loss: 1.6336933297191514
Validation loss: 2.4153090809123947

Epoch: 6| Step: 3
Training loss: 1.1133060921022189
Validation loss: 2.4121993055215314

Epoch: 6| Step: 4
Training loss: 0.9727042619123376
Validation loss: 2.41533267866328

Epoch: 6| Step: 5
Training loss: 1.7575266287727582
Validation loss: 2.4182751775989937

Epoch: 6| Step: 6
Training loss: 1.0504282532148388
Validation loss: 2.4330008280299644

Epoch: 6| Step: 7
Training loss: 0.9416758677502888
Validation loss: 2.452625970850651

Epoch: 6| Step: 8
Training loss: 1.4177643599733938
Validation loss: 2.471652620427889

Epoch: 6| Step: 9
Training loss: 1.316280053312776
Validation loss: 2.4762699255479883

Epoch: 6| Step: 10
Training loss: 1.2413160998366795
Validation loss: 2.49031211273251

Epoch: 6| Step: 11
Training loss: 1.2170173359578875
Validation loss: 2.4827790952144797

Epoch: 6| Step: 12
Training loss: 0.9898791757700992
Validation loss: 2.4592133138146224

Epoch: 6| Step: 13
Training loss: 1.2700583904089677
Validation loss: 2.4511949429016715

Epoch: 421| Step: 0
Training loss: 1.7514394562080091
Validation loss: 2.4539485354007

Epoch: 6| Step: 1
Training loss: 1.4099776981835563
Validation loss: 2.406774963552466

Epoch: 6| Step: 2
Training loss: 1.0168501287137337
Validation loss: 2.4180971571714025

Epoch: 6| Step: 3
Training loss: 1.1088025402535409
Validation loss: 2.4029954758745418

Epoch: 6| Step: 4
Training loss: 0.8968624738822031
Validation loss: 2.4022250809378223

Epoch: 6| Step: 5
Training loss: 1.3219983776042177
Validation loss: 2.420991473509192

Epoch: 6| Step: 6
Training loss: 1.110441903739455
Validation loss: 2.455971277241507

Epoch: 6| Step: 7
Training loss: 1.776181958457055
Validation loss: 2.468827202408742

Epoch: 6| Step: 8
Training loss: 1.5323982604514543
Validation loss: 2.484569254838342

Epoch: 6| Step: 9
Training loss: 0.9532618815204071
Validation loss: 2.4607249157549833

Epoch: 6| Step: 10
Training loss: 1.4539430018171136
Validation loss: 2.482461378197392

Epoch: 6| Step: 11
Training loss: 1.0348688842356815
Validation loss: 2.478477761471935

Epoch: 6| Step: 12
Training loss: 1.131568488711207
Validation loss: 2.5008351417976695

Epoch: 6| Step: 13
Training loss: 1.026624594658261
Validation loss: 2.4853685079275287

Epoch: 422| Step: 0
Training loss: 1.3550252931071147
Validation loss: 2.4590463872963157

Epoch: 6| Step: 1
Training loss: 1.3693994122431081
Validation loss: 2.4394720023861183

Epoch: 6| Step: 2
Training loss: 1.3108572897851005
Validation loss: 2.432695682024079

Epoch: 6| Step: 3
Training loss: 1.2279033256990872
Validation loss: 2.4103488358208307

Epoch: 6| Step: 4
Training loss: 1.491773777673298
Validation loss: 2.4258026306521634

Epoch: 6| Step: 5
Training loss: 1.382951287670178
Validation loss: 2.4412457745058176

Epoch: 6| Step: 6
Training loss: 1.019798389967257
Validation loss: 2.4684726366649437

Epoch: 6| Step: 7
Training loss: 1.171825153562271
Validation loss: 2.430294266430048

Epoch: 6| Step: 8
Training loss: 1.6647322475519686
Validation loss: 2.42781373487615

Epoch: 6| Step: 9
Training loss: 1.0764175383880843
Validation loss: 2.4231799200930215

Epoch: 6| Step: 10
Training loss: 1.359420293294574
Validation loss: 2.4129861578048564

Epoch: 6| Step: 11
Training loss: 1.1380369532976171
Validation loss: 2.4079504792468094

Epoch: 6| Step: 12
Training loss: 1.1619391821606504
Validation loss: 2.4359164075193402

Epoch: 6| Step: 13
Training loss: 1.1459121445804314
Validation loss: 2.420492913296471

Epoch: 423| Step: 0
Training loss: 1.033354951775944
Validation loss: 2.46214728112636

Epoch: 6| Step: 1
Training loss: 1.0341710422575974
Validation loss: 2.4855543430409934

Epoch: 6| Step: 2
Training loss: 1.019513126372977
Validation loss: 2.4728502456236465

Epoch: 6| Step: 3
Training loss: 1.477429493675742
Validation loss: 2.4853009029458404

Epoch: 6| Step: 4
Training loss: 0.755169852142362
Validation loss: 2.4679693958627134

Epoch: 6| Step: 5
Training loss: 1.5701887546955349
Validation loss: 2.4818547553403323

Epoch: 6| Step: 6
Training loss: 1.6075420867726105
Validation loss: 2.4533708996619654

Epoch: 6| Step: 7
Training loss: 1.776465163168743
Validation loss: 2.4548730238766487

Epoch: 6| Step: 8
Training loss: 1.2192681995978814
Validation loss: 2.422027768316135

Epoch: 6| Step: 9
Training loss: 1.3494758595119731
Validation loss: 2.418385558099971

Epoch: 6| Step: 10
Training loss: 1.327211851467405
Validation loss: 2.383357920054807

Epoch: 6| Step: 11
Training loss: 1.0399099923579014
Validation loss: 2.399004377909478

Epoch: 6| Step: 12
Training loss: 1.0479179425291836
Validation loss: 2.393112439180856

Epoch: 6| Step: 13
Training loss: 1.14700560280879
Validation loss: 2.3934209940595443

Epoch: 424| Step: 0
Training loss: 1.3403023249212587
Validation loss: 2.4033813018139774

Epoch: 6| Step: 1
Training loss: 1.3225305649627233
Validation loss: 2.4160627534155217

Epoch: 6| Step: 2
Training loss: 1.2434309008534183
Validation loss: 2.419036187496274

Epoch: 6| Step: 3
Training loss: 0.9773287399200529
Validation loss: 2.4624692692683654

Epoch: 6| Step: 4
Training loss: 1.2112305317387915
Validation loss: 2.481375407248082

Epoch: 6| Step: 5
Training loss: 1.2898529403608647
Validation loss: 2.513852419698496

Epoch: 6| Step: 6
Training loss: 0.8909029945052597
Validation loss: 2.4840760915745186

Epoch: 6| Step: 7
Training loss: 1.154158065892386
Validation loss: 2.4721701728946255

Epoch: 6| Step: 8
Training loss: 1.5439587471248986
Validation loss: 2.4585262467610307

Epoch: 6| Step: 9
Training loss: 1.7870095814008817
Validation loss: 2.4603974311785715

Epoch: 6| Step: 10
Training loss: 1.5229256577058927
Validation loss: 2.4591748049036584

Epoch: 6| Step: 11
Training loss: 1.3340432641364255
Validation loss: 2.4212830475395313

Epoch: 6| Step: 12
Training loss: 0.6275361579568977
Validation loss: 2.4311287002509965

Epoch: 6| Step: 13
Training loss: 0.9527905299430338
Validation loss: 2.4320528595146045

Epoch: 425| Step: 0
Training loss: 1.2271494341901938
Validation loss: 2.452404003263395

Epoch: 6| Step: 1
Training loss: 1.3088523495357036
Validation loss: 2.4548932796902707

Epoch: 6| Step: 2
Training loss: 1.3783757645527124
Validation loss: 2.4559543173953435

Epoch: 6| Step: 3
Training loss: 1.1001187867269915
Validation loss: 2.4424841066165546

Epoch: 6| Step: 4
Training loss: 0.8749986376070588
Validation loss: 2.456006713782254

Epoch: 6| Step: 5
Training loss: 1.6118488741854462
Validation loss: 2.483208734767507

Epoch: 6| Step: 6
Training loss: 1.2350822064611404
Validation loss: 2.4708629956723627

Epoch: 6| Step: 7
Training loss: 1.5614682415051309
Validation loss: 2.4951216913800742

Epoch: 6| Step: 8
Training loss: 1.5481735327840078
Validation loss: 2.473786080046355

Epoch: 6| Step: 9
Training loss: 0.8424841604243658
Validation loss: 2.459735424293153

Epoch: 6| Step: 10
Training loss: 0.9038948170458996
Validation loss: 2.4688229309292042

Epoch: 6| Step: 11
Training loss: 1.2047864663011136
Validation loss: 2.4513254278766223

Epoch: 6| Step: 12
Training loss: 1.0925860069517044
Validation loss: 2.4610295104187174

Epoch: 6| Step: 13
Training loss: 1.2602959987582616
Validation loss: 2.438025797256845

Epoch: 426| Step: 0
Training loss: 1.7284514851712143
Validation loss: 2.440688997568012

Epoch: 6| Step: 1
Training loss: 1.0825905025964113
Validation loss: 2.4209583581508918

Epoch: 6| Step: 2
Training loss: 0.9978427267588721
Validation loss: 2.4322470886427494

Epoch: 6| Step: 3
Training loss: 1.266793124051912
Validation loss: 2.4267685798905796

Epoch: 6| Step: 4
Training loss: 1.4215411119074317
Validation loss: 2.4488485251798084

Epoch: 6| Step: 5
Training loss: 1.330467850421057
Validation loss: 2.4244819088518943

Epoch: 6| Step: 6
Training loss: 1.0702345325445628
Validation loss: 2.4257067924767446

Epoch: 6| Step: 7
Training loss: 1.252901524430166
Validation loss: 2.4027146618748607

Epoch: 6| Step: 8
Training loss: 1.0877448211981504
Validation loss: 2.40931386794399

Epoch: 6| Step: 9
Training loss: 1.277967574817114
Validation loss: 2.3941790254732345

Epoch: 6| Step: 10
Training loss: 1.2153569453050996
Validation loss: 2.397945378015473

Epoch: 6| Step: 11
Training loss: 1.3164797346393158
Validation loss: 2.3770882774041984

Epoch: 6| Step: 12
Training loss: 1.1460087844152458
Validation loss: 2.395972676837322

Epoch: 6| Step: 13
Training loss: 0.9826247383120239
Validation loss: 2.420023277670439

Epoch: 427| Step: 0
Training loss: 1.530365824877464
Validation loss: 2.4404903923108234

Epoch: 6| Step: 1
Training loss: 0.8926413615925044
Validation loss: 2.460821447648939

Epoch: 6| Step: 2
Training loss: 0.8968417384130634
Validation loss: 2.520913933245376

Epoch: 6| Step: 3
Training loss: 1.0764499865730592
Validation loss: 2.5248521127342975

Epoch: 6| Step: 4
Training loss: 1.3363489331696932
Validation loss: 2.493888069817134

Epoch: 6| Step: 5
Training loss: 1.3493882258916854
Validation loss: 2.4782796713633783

Epoch: 6| Step: 6
Training loss: 1.5194642510635155
Validation loss: 2.40407681357933

Epoch: 6| Step: 7
Training loss: 1.3143588481496558
Validation loss: 2.402688493061049

Epoch: 6| Step: 8
Training loss: 1.5585198635858482
Validation loss: 2.3660155900671054

Epoch: 6| Step: 9
Training loss: 1.735704891576356
Validation loss: 2.3619520226497297

Epoch: 6| Step: 10
Training loss: 1.1064072254760045
Validation loss: 2.395395189823855

Epoch: 6| Step: 11
Training loss: 0.7899388272105067
Validation loss: 2.390825683955295

Epoch: 6| Step: 12
Training loss: 1.0337433006872152
Validation loss: 2.424168667444431

Epoch: 6| Step: 13
Training loss: 0.6493527949982034
Validation loss: 2.4593288989532867

Epoch: 428| Step: 0
Training loss: 1.1351571909407663
Validation loss: 2.4933125677286494

Epoch: 6| Step: 1
Training loss: 1.6269016875966218
Validation loss: 2.5051526069050123

Epoch: 6| Step: 2
Training loss: 0.9717618514551036
Validation loss: 2.508989531898773

Epoch: 6| Step: 3
Training loss: 1.4427198095129166
Validation loss: 2.4945245041805846

Epoch: 6| Step: 4
Training loss: 1.6460554077723335
Validation loss: 2.5007845703719678

Epoch: 6| Step: 5
Training loss: 1.0310871111220652
Validation loss: 2.5217837237348246

Epoch: 6| Step: 6
Training loss: 1.2520095407804939
Validation loss: 2.4967296714061225

Epoch: 6| Step: 7
Training loss: 1.2586701117188241
Validation loss: 2.4789134715180787

Epoch: 6| Step: 8
Training loss: 0.5328026969209209
Validation loss: 2.4481171752107964

Epoch: 6| Step: 9
Training loss: 1.1788766866102987
Validation loss: 2.424372960644919

Epoch: 6| Step: 10
Training loss: 1.6032094535369983
Validation loss: 2.396531891781521

Epoch: 6| Step: 11
Training loss: 1.2350183090211877
Validation loss: 2.408995265846915

Epoch: 6| Step: 12
Training loss: 1.0705473148022397
Validation loss: 2.415708392897619

Epoch: 6| Step: 13
Training loss: 0.6923579331247169
Validation loss: 2.4020642451212795

Epoch: 429| Step: 0
Training loss: 1.1371430853640128
Validation loss: 2.4373179941771532

Epoch: 6| Step: 1
Training loss: 1.1453598720438665
Validation loss: 2.4347509243095806

Epoch: 6| Step: 2
Training loss: 1.2891305616501645
Validation loss: 2.434744896234733

Epoch: 6| Step: 3
Training loss: 0.7829928984045936
Validation loss: 2.436950362893824

Epoch: 6| Step: 4
Training loss: 1.178494589228746
Validation loss: 2.435117929614868

Epoch: 6| Step: 5
Training loss: 1.5095017216089166
Validation loss: 2.417208173491489

Epoch: 6| Step: 6
Training loss: 1.2566988736147982
Validation loss: 2.4291426870119026

Epoch: 6| Step: 7
Training loss: 1.1508405806092035
Validation loss: 2.4165370619634765

Epoch: 6| Step: 8
Training loss: 0.9934486724042885
Validation loss: 2.4085132112577528

Epoch: 6| Step: 9
Training loss: 1.2748367953096165
Validation loss: 2.4420497335366202

Epoch: 6| Step: 10
Training loss: 1.1543130889631654
Validation loss: 2.4669131144098304

Epoch: 6| Step: 11
Training loss: 1.1640585060819173
Validation loss: 2.441872832179372

Epoch: 6| Step: 12
Training loss: 1.8044466460709903
Validation loss: 2.443998635200321

Epoch: 6| Step: 13
Training loss: 1.0987017664992986
Validation loss: 2.4328483124992832

Epoch: 430| Step: 0
Training loss: 1.2150285586387672
Validation loss: 2.4331803262425122

Epoch: 6| Step: 1
Training loss: 1.4752095800957568
Validation loss: 2.415136749044891

Epoch: 6| Step: 2
Training loss: 1.1475563042151762
Validation loss: 2.428593153583644

Epoch: 6| Step: 3
Training loss: 0.9121108780058214
Validation loss: 2.439514293380124

Epoch: 6| Step: 4
Training loss: 1.1569817263908413
Validation loss: 2.4376235164945035

Epoch: 6| Step: 5
Training loss: 1.4356900305959628
Validation loss: 2.4724254960884213

Epoch: 6| Step: 6
Training loss: 1.2282726247649869
Validation loss: 2.4372045434137064

Epoch: 6| Step: 7
Training loss: 1.2734427890784765
Validation loss: 2.455867918744123

Epoch: 6| Step: 8
Training loss: 1.2911920239412549
Validation loss: 2.4496138572055

Epoch: 6| Step: 9
Training loss: 0.945369718727291
Validation loss: 2.4391120762817398

Epoch: 6| Step: 10
Training loss: 1.4720333006139688
Validation loss: 2.4004938138858627

Epoch: 6| Step: 11
Training loss: 1.3740619580821083
Validation loss: 2.365926457496775

Epoch: 6| Step: 12
Training loss: 1.2049389825306547
Validation loss: 2.365542415480476

Epoch: 6| Step: 13
Training loss: 0.48944882986950045
Validation loss: 2.346396735666993

Epoch: 431| Step: 0
Training loss: 1.2737329994392363
Validation loss: 2.3170268553027773

Epoch: 6| Step: 1
Training loss: 1.1509706754354259
Validation loss: 2.346416759408391

Epoch: 6| Step: 2
Training loss: 0.8635951373422328
Validation loss: 2.357908201915167

Epoch: 6| Step: 3
Training loss: 1.552375032122214
Validation loss: 2.3690487867055845

Epoch: 6| Step: 4
Training loss: 1.3039971998161253
Validation loss: 2.4154489254662996

Epoch: 6| Step: 5
Training loss: 1.0448427544702164
Validation loss: 2.4361217905157524

Epoch: 6| Step: 6
Training loss: 1.1580033797476668
Validation loss: 2.42487471916249

Epoch: 6| Step: 7
Training loss: 1.0351571712849674
Validation loss: 2.4335678774201157

Epoch: 6| Step: 8
Training loss: 1.3545889073873918
Validation loss: 2.4501053509758663

Epoch: 6| Step: 9
Training loss: 0.965020013068017
Validation loss: 2.4521951610726775

Epoch: 6| Step: 10
Training loss: 1.2051198200945028
Validation loss: 2.49917617267826

Epoch: 6| Step: 11
Training loss: 1.5706936957155262
Validation loss: 2.447412875106059

Epoch: 6| Step: 12
Training loss: 1.2144716925810533
Validation loss: 2.4656496384428332

Epoch: 6| Step: 13
Training loss: 1.1080711116693889
Validation loss: 2.4446139293967275

Epoch: 432| Step: 0
Training loss: 1.3845497038334356
Validation loss: 2.4278085216642697

Epoch: 6| Step: 1
Training loss: 1.1898150715468268
Validation loss: 2.4167660518432212

Epoch: 6| Step: 2
Training loss: 0.9755901225843198
Validation loss: 2.364865574090892

Epoch: 6| Step: 3
Training loss: 1.434525937717791
Validation loss: 2.37903351551688

Epoch: 6| Step: 4
Training loss: 1.0633085203913035
Validation loss: 2.3633056953946956

Epoch: 6| Step: 5
Training loss: 0.6860262507067663
Validation loss: 2.3949712496152435

Epoch: 6| Step: 6
Training loss: 0.9991145386087925
Validation loss: 2.375352403739946

Epoch: 6| Step: 7
Training loss: 1.4082713540488287
Validation loss: 2.409671940809449

Epoch: 6| Step: 8
Training loss: 0.7714333046535828
Validation loss: 2.4510292823941326

Epoch: 6| Step: 9
Training loss: 1.0049241542189773
Validation loss: 2.4441075162339985

Epoch: 6| Step: 10
Training loss: 1.4138192657852495
Validation loss: 2.4866939038111733

Epoch: 6| Step: 11
Training loss: 1.6278281177306877
Validation loss: 2.4617978911283402

Epoch: 6| Step: 12
Training loss: 0.8738974027494455
Validation loss: 2.4718263295364986

Epoch: 6| Step: 13
Training loss: 1.7770368038524396
Validation loss: 2.471387435398875

Epoch: 433| Step: 0
Training loss: 1.3277003787548791
Validation loss: 2.475919835317951

Epoch: 6| Step: 1
Training loss: 1.1301102603018225
Validation loss: 2.491350958647716

Epoch: 6| Step: 2
Training loss: 0.7616963701139392
Validation loss: 2.4953344818428573

Epoch: 6| Step: 3
Training loss: 0.7605717165612113
Validation loss: 2.51010254831712

Epoch: 6| Step: 4
Training loss: 1.1963280745392741
Validation loss: 2.4935926077399366

Epoch: 6| Step: 5
Training loss: 1.5142837567458134
Validation loss: 2.4834483905485425

Epoch: 6| Step: 6
Training loss: 1.3388735981794007
Validation loss: 2.452716935318519

Epoch: 6| Step: 7
Training loss: 1.184800442499391
Validation loss: 2.435084637361948

Epoch: 6| Step: 8
Training loss: 1.521321396919339
Validation loss: 2.394448205138532

Epoch: 6| Step: 9
Training loss: 0.7328630263228626
Validation loss: 2.387855199205016

Epoch: 6| Step: 10
Training loss: 1.4656457765322581
Validation loss: 2.4057780232951753

Epoch: 6| Step: 11
Training loss: 0.7094547613398309
Validation loss: 2.3612873563751213

Epoch: 6| Step: 12
Training loss: 1.453532008114889
Validation loss: 2.3624595000556754

Epoch: 6| Step: 13
Training loss: 1.1919345372357064
Validation loss: 2.369834931059913

Epoch: 434| Step: 0
Training loss: 1.4867117708716904
Validation loss: 2.371718820880746

Epoch: 6| Step: 1
Training loss: 1.034576368755282
Validation loss: 2.4214845139446037

Epoch: 6| Step: 2
Training loss: 1.006764539819667
Validation loss: 2.4413087220103353

Epoch: 6| Step: 3
Training loss: 1.1572602472352245
Validation loss: 2.491158967687161

Epoch: 6| Step: 4
Training loss: 1.1583696988569934
Validation loss: 2.4986607851060847

Epoch: 6| Step: 5
Training loss: 1.460019644382997
Validation loss: 2.530668858628988

Epoch: 6| Step: 6
Training loss: 0.9754561909800936
Validation loss: 2.5069546005691263

Epoch: 6| Step: 7
Training loss: 1.0630363905554991
Validation loss: 2.525697458655094

Epoch: 6| Step: 8
Training loss: 0.7425906642314656
Validation loss: 2.517464733110362

Epoch: 6| Step: 9
Training loss: 1.2885683441895506
Validation loss: 2.4748384450119043

Epoch: 6| Step: 10
Training loss: 1.48407003381921
Validation loss: 2.456358390745502

Epoch: 6| Step: 11
Training loss: 1.1403967223945544
Validation loss: 2.4083025195170227

Epoch: 6| Step: 12
Training loss: 1.086125090060042
Validation loss: 2.383717788284292

Epoch: 6| Step: 13
Training loss: 1.5498350701722161
Validation loss: 2.353363599987252

Epoch: 435| Step: 0
Training loss: 1.1577026932882004
Validation loss: 2.3725113353927205

Epoch: 6| Step: 1
Training loss: 1.654355675238947
Validation loss: 2.3744943422658777

Epoch: 6| Step: 2
Training loss: 1.393463923085487
Validation loss: 2.3499147066081933

Epoch: 6| Step: 3
Training loss: 0.9354333669337068
Validation loss: 2.3911929253874518

Epoch: 6| Step: 4
Training loss: 1.0397781546271512
Validation loss: 2.405722083022002

Epoch: 6| Step: 5
Training loss: 0.8230483798758749
Validation loss: 2.453116385629814

Epoch: 6| Step: 6
Training loss: 0.6251397453480595
Validation loss: 2.492837131555454

Epoch: 6| Step: 7
Training loss: 0.6637273503693795
Validation loss: 2.5041243275643947

Epoch: 6| Step: 8
Training loss: 0.9924252443001901
Validation loss: 2.5394935594128922

Epoch: 6| Step: 9
Training loss: 1.5212192132948692
Validation loss: 2.5368961878501426

Epoch: 6| Step: 10
Training loss: 1.0890996984097332
Validation loss: 2.517166836127618

Epoch: 6| Step: 11
Training loss: 0.8928521401401421
Validation loss: 2.4695085175681526

Epoch: 6| Step: 12
Training loss: 1.665921744130966
Validation loss: 2.4265457662500074

Epoch: 6| Step: 13
Training loss: 1.909750803723936
Validation loss: 2.3926835429959485

Epoch: 436| Step: 0
Training loss: 0.8119639315510458
Validation loss: 2.3604971109252815

Epoch: 6| Step: 1
Training loss: 1.0211618764109258
Validation loss: 2.287924218970578

Epoch: 6| Step: 2
Training loss: 1.4626236431316684
Validation loss: 2.3112075750463137

Epoch: 6| Step: 3
Training loss: 1.380642238524865
Validation loss: 2.3011313122540273

Epoch: 6| Step: 4
Training loss: 0.8345168332481483
Validation loss: 2.328659452152563

Epoch: 6| Step: 5
Training loss: 1.3813034703188392
Validation loss: 2.3524309497343476

Epoch: 6| Step: 6
Training loss: 1.293654982906174
Validation loss: 2.3842755669358473

Epoch: 6| Step: 7
Training loss: 1.200395087926819
Validation loss: 2.4090031467298463

Epoch: 6| Step: 8
Training loss: 1.0034146422542185
Validation loss: 2.449400475433349

Epoch: 6| Step: 9
Training loss: 1.1788281474902556
Validation loss: 2.4669673408278454

Epoch: 6| Step: 10
Training loss: 1.0242983859111205
Validation loss: 2.4809577571623236

Epoch: 6| Step: 11
Training loss: 1.8823922982378918
Validation loss: 2.520376858882762

Epoch: 6| Step: 12
Training loss: 1.0123485828725294
Validation loss: 2.545802911613884

Epoch: 6| Step: 13
Training loss: 0.7733615105801122
Validation loss: 2.541517050212847

Epoch: 437| Step: 0
Training loss: 1.051456107075567
Validation loss: 2.57864797687942

Epoch: 6| Step: 1
Training loss: 1.161251283445768
Validation loss: 2.529185506636948

Epoch: 6| Step: 2
Training loss: 1.2633722294948504
Validation loss: 2.5098592896554237

Epoch: 6| Step: 3
Training loss: 1.1009630235912493
Validation loss: 2.496135389788309

Epoch: 6| Step: 4
Training loss: 1.3004867632763162
Validation loss: 2.416025243876575

Epoch: 6| Step: 5
Training loss: 1.110413615858934
Validation loss: 2.3777094143816675

Epoch: 6| Step: 6
Training loss: 1.772829733068343
Validation loss: 2.341257581717866

Epoch: 6| Step: 7
Training loss: 0.8516128245191221
Validation loss: 2.342377247653791

Epoch: 6| Step: 8
Training loss: 1.1551390801124668
Validation loss: 2.3603541366186565

Epoch: 6| Step: 9
Training loss: 1.4161879441216698
Validation loss: 2.3856677134481235

Epoch: 6| Step: 10
Training loss: 1.0316931032687362
Validation loss: 2.3587621207796157

Epoch: 6| Step: 11
Training loss: 0.9942698216753703
Validation loss: 2.382497475152769

Epoch: 6| Step: 12
Training loss: 1.1076213246663278
Validation loss: 2.3785686764282574

Epoch: 6| Step: 13
Training loss: 1.403675647577021
Validation loss: 2.3872158120422946

Epoch: 438| Step: 0
Training loss: 0.9928608209163525
Validation loss: 2.3867412013108353

Epoch: 6| Step: 1
Training loss: 0.9611070684912695
Validation loss: 2.411338148460051

Epoch: 6| Step: 2
Training loss: 1.3820673772339152
Validation loss: 2.4089492852682914

Epoch: 6| Step: 3
Training loss: 1.3111406280316462
Validation loss: 2.381072489694524

Epoch: 6| Step: 4
Training loss: 0.8638479866724608
Validation loss: 2.365522666344713

Epoch: 6| Step: 5
Training loss: 0.9466669766891223
Validation loss: 2.3776956109860996

Epoch: 6| Step: 6
Training loss: 1.1135732167517196
Validation loss: 2.394287863571972

Epoch: 6| Step: 7
Training loss: 1.2722023432556075
Validation loss: 2.391726028027563

Epoch: 6| Step: 8
Training loss: 1.2042189739618605
Validation loss: 2.4392879681770347

Epoch: 6| Step: 9
Training loss: 1.7170855699299525
Validation loss: 2.457128661000597

Epoch: 6| Step: 10
Training loss: 1.2942263200909925
Validation loss: 2.4860931190818465

Epoch: 6| Step: 11
Training loss: 1.1540736258471718
Validation loss: 2.490043669316577

Epoch: 6| Step: 12
Training loss: 0.8152846521466468
Validation loss: 2.475456970561587

Epoch: 6| Step: 13
Training loss: 1.6437987374742382
Validation loss: 2.480305837472078

Epoch: 439| Step: 0
Training loss: 0.9523766503350413
Validation loss: 2.4600241215333027

Epoch: 6| Step: 1
Training loss: 1.1805752073160753
Validation loss: 2.4524562267123264

Epoch: 6| Step: 2
Training loss: 0.6579366761567785
Validation loss: 2.4294062372740757

Epoch: 6| Step: 3
Training loss: 0.9826331091637058
Validation loss: 2.392814142750517

Epoch: 6| Step: 4
Training loss: 0.9859382689846322
Validation loss: 2.3742721793854593

Epoch: 6| Step: 5
Training loss: 1.2143481062239112
Validation loss: 2.3830136632975614

Epoch: 6| Step: 6
Training loss: 0.9038449305355952
Validation loss: 2.3814140574876523

Epoch: 6| Step: 7
Training loss: 1.6969695540862622
Validation loss: 2.3878661710031777

Epoch: 6| Step: 8
Training loss: 1.4893513034179262
Validation loss: 2.393112508812619

Epoch: 6| Step: 9
Training loss: 1.361037804885042
Validation loss: 2.388010406355076

Epoch: 6| Step: 10
Training loss: 1.0927232009753842
Validation loss: 2.4230858524430485

Epoch: 6| Step: 11
Training loss: 1.0976425115736936
Validation loss: 2.4173858192773783

Epoch: 6| Step: 12
Training loss: 1.2495234057709839
Validation loss: 2.4086656110290026

Epoch: 6| Step: 13
Training loss: 1.1042208148466837
Validation loss: 2.4157932012749046

Epoch: 440| Step: 0
Training loss: 1.3824074362038243
Validation loss: 2.4624410983792417

Epoch: 6| Step: 1
Training loss: 1.032594901981363
Validation loss: 2.4857100964239183

Epoch: 6| Step: 2
Training loss: 0.8678007277396642
Validation loss: 2.4893128672978153

Epoch: 6| Step: 3
Training loss: 0.7154552991460342
Validation loss: 2.511214712077716

Epoch: 6| Step: 4
Training loss: 1.2713868650205864
Validation loss: 2.5068545641585542

Epoch: 6| Step: 5
Training loss: 1.368041943172026
Validation loss: 2.4983407390139143

Epoch: 6| Step: 6
Training loss: 1.310111824970297
Validation loss: 2.4426201094427853

Epoch: 6| Step: 7
Training loss: 1.157455537572355
Validation loss: 2.4103312427928514

Epoch: 6| Step: 8
Training loss: 1.0648362336484711
Validation loss: 2.344260341634306

Epoch: 6| Step: 9
Training loss: 1.1550145121071427
Validation loss: 2.330923380310365

Epoch: 6| Step: 10
Training loss: 1.397953439826735
Validation loss: 2.326142795186357

Epoch: 6| Step: 11
Training loss: 0.7723430635239693
Validation loss: 2.321894113034714

Epoch: 6| Step: 12
Training loss: 1.506749148783642
Validation loss: 2.3231861214446354

Epoch: 6| Step: 13
Training loss: 1.0454690516637761
Validation loss: 2.3805200150074532

Epoch: 441| Step: 0
Training loss: 1.207731469756233
Validation loss: 2.3822292938181926

Epoch: 6| Step: 1
Training loss: 0.9676719943403738
Validation loss: 2.4070439993703174

Epoch: 6| Step: 2
Training loss: 1.4768862899109825
Validation loss: 2.452560893966494

Epoch: 6| Step: 3
Training loss: 0.6364519461286826
Validation loss: 2.432799340572112

Epoch: 6| Step: 4
Training loss: 1.0286091021325492
Validation loss: 2.4662466273644843

Epoch: 6| Step: 5
Training loss: 1.0919641356395131
Validation loss: 2.46616271252374

Epoch: 6| Step: 6
Training loss: 1.0375581908854905
Validation loss: 2.4892502217466363

Epoch: 6| Step: 7
Training loss: 1.3212686721796032
Validation loss: 2.487729343035143

Epoch: 6| Step: 8
Training loss: 1.1449933469987177
Validation loss: 2.471532902955377

Epoch: 6| Step: 9
Training loss: 0.9567466156867033
Validation loss: 2.4644920782491355

Epoch: 6| Step: 10
Training loss: 1.5304846115809236
Validation loss: 2.468814961150007

Epoch: 6| Step: 11
Training loss: 1.3594758445779633
Validation loss: 2.4518641422972944

Epoch: 6| Step: 12
Training loss: 0.9211006791984183
Validation loss: 2.4452262715653847

Epoch: 6| Step: 13
Training loss: 1.2293581840323091
Validation loss: 2.4563483129959156

Epoch: 442| Step: 0
Training loss: 1.0026508006690442
Validation loss: 2.4266109486570056

Epoch: 6| Step: 1
Training loss: 1.407226520143888
Validation loss: 2.4306751316344073

Epoch: 6| Step: 2
Training loss: 0.7682302873678708
Validation loss: 2.4133270626987176

Epoch: 6| Step: 3
Training loss: 1.5007965833763324
Validation loss: 2.4105178259434767

Epoch: 6| Step: 4
Training loss: 1.1312248943767613
Validation loss: 2.3704700651515327

Epoch: 6| Step: 5
Training loss: 1.0170066825137025
Validation loss: 2.4062980824974782

Epoch: 6| Step: 6
Training loss: 0.8150466110497891
Validation loss: 2.4053944607759012

Epoch: 6| Step: 7
Training loss: 1.1278594024029525
Validation loss: 2.4377761644409097

Epoch: 6| Step: 8
Training loss: 0.8933014724574972
Validation loss: 2.4473203307528943

Epoch: 6| Step: 9
Training loss: 0.9368348941273071
Validation loss: 2.4420489645649504

Epoch: 6| Step: 10
Training loss: 1.0774661829303886
Validation loss: 2.4559234135874757

Epoch: 6| Step: 11
Training loss: 1.5864029375182793
Validation loss: 2.4653456364355404

Epoch: 6| Step: 12
Training loss: 1.4116616284499324
Validation loss: 2.42672297833048

Epoch: 6| Step: 13
Training loss: 1.0754349915220307
Validation loss: 2.431097474535882

Epoch: 443| Step: 0
Training loss: 0.9640911425720667
Validation loss: 2.42429790099202

Epoch: 6| Step: 1
Training loss: 0.9126706081437166
Validation loss: 2.409428140935158

Epoch: 6| Step: 2
Training loss: 1.0700566898016868
Validation loss: 2.397000392815784

Epoch: 6| Step: 3
Training loss: 0.7725018322870444
Validation loss: 2.3835246608319887

Epoch: 6| Step: 4
Training loss: 1.2500626548323366
Validation loss: 2.3583253121211545

Epoch: 6| Step: 5
Training loss: 1.1910410336905406
Validation loss: 2.3825591040190623

Epoch: 6| Step: 6
Training loss: 0.9534283764908092
Validation loss: 2.3961935017830025

Epoch: 6| Step: 7
Training loss: 1.0317175989925949
Validation loss: 2.385438673304168

Epoch: 6| Step: 8
Training loss: 0.6443406256637854
Validation loss: 2.407647243793076

Epoch: 6| Step: 9
Training loss: 1.7072551240049514
Validation loss: 2.435617862182055

Epoch: 6| Step: 10
Training loss: 1.394049082941386
Validation loss: 2.464384729290859

Epoch: 6| Step: 11
Training loss: 1.289598434474861
Validation loss: 2.4646927233265714

Epoch: 6| Step: 12
Training loss: 1.1126711595862455
Validation loss: 2.485209260910496

Epoch: 6| Step: 13
Training loss: 1.5126090964072427
Validation loss: 2.4930913341054652

Epoch: 444| Step: 0
Training loss: 1.0425036246879373
Validation loss: 2.4569011369262195

Epoch: 6| Step: 1
Training loss: 1.0552193889936259
Validation loss: 2.462667735860269

Epoch: 6| Step: 2
Training loss: 1.2028064058248062
Validation loss: 2.442570680078508

Epoch: 6| Step: 3
Training loss: 0.8240000357766746
Validation loss: 2.422911115307466

Epoch: 6| Step: 4
Training loss: 0.6682295931316471
Validation loss: 2.369719417912633

Epoch: 6| Step: 5
Training loss: 0.9443855469857588
Validation loss: 2.3870235024528172

Epoch: 6| Step: 6
Training loss: 1.2241407650742928
Validation loss: 2.4052357804864206

Epoch: 6| Step: 7
Training loss: 1.6892081904502487
Validation loss: 2.402590407087703

Epoch: 6| Step: 8
Training loss: 1.4377604538854718
Validation loss: 2.3796582568621

Epoch: 6| Step: 9
Training loss: 1.1587344104166697
Validation loss: 2.408313430628386

Epoch: 6| Step: 10
Training loss: 0.872414413178382
Validation loss: 2.4162082859748746

Epoch: 6| Step: 11
Training loss: 0.9863528711217333
Validation loss: 2.4181002136951073

Epoch: 6| Step: 12
Training loss: 1.3575212840173294
Validation loss: 2.444068930849269

Epoch: 6| Step: 13
Training loss: 1.1801451748914538
Validation loss: 2.450394397614201

Epoch: 445| Step: 0
Training loss: 0.8255450167959482
Validation loss: 2.4170826103836314

Epoch: 6| Step: 1
Training loss: 1.1511820481714552
Validation loss: 2.427814805605339

Epoch: 6| Step: 2
Training loss: 0.6071552046954767
Validation loss: 2.419592233994988

Epoch: 6| Step: 3
Training loss: 1.5260330390903283
Validation loss: 2.3917792976713197

Epoch: 6| Step: 4
Training loss: 1.3318966884270278
Validation loss: 2.401166049998368

Epoch: 6| Step: 5
Training loss: 1.2211957990162396
Validation loss: 2.4301936552185017

Epoch: 6| Step: 6
Training loss: 1.1186089709168587
Validation loss: 2.442409306504946

Epoch: 6| Step: 7
Training loss: 0.888342291111063
Validation loss: 2.448667613098047

Epoch: 6| Step: 8
Training loss: 0.8929196962514924
Validation loss: 2.456788805963916

Epoch: 6| Step: 9
Training loss: 1.4120290899603185
Validation loss: 2.4739454851750593

Epoch: 6| Step: 10
Training loss: 1.0990491832526204
Validation loss: 2.4666158419258832

Epoch: 6| Step: 11
Training loss: 1.0576204562290785
Validation loss: 2.456540994263865

Epoch: 6| Step: 12
Training loss: 1.173835386231571
Validation loss: 2.452419285307312

Epoch: 6| Step: 13
Training loss: 1.0872830075788185
Validation loss: 2.4153568981594455

Epoch: 446| Step: 0
Training loss: 1.051326114108066
Validation loss: 2.4030435157418912

Epoch: 6| Step: 1
Training loss: 0.8787803729303791
Validation loss: 2.406090475269876

Epoch: 6| Step: 2
Training loss: 1.0824649643899682
Validation loss: 2.3787058946889523

Epoch: 6| Step: 3
Training loss: 1.0612641608345965
Validation loss: 2.385501965548275

Epoch: 6| Step: 4
Training loss: 1.1405316667387462
Validation loss: 2.414130000494107

Epoch: 6| Step: 5
Training loss: 1.1242494198537003
Validation loss: 2.4069682065442506

Epoch: 6| Step: 6
Training loss: 1.2000188984972229
Validation loss: 2.444215022605965

Epoch: 6| Step: 7
Training loss: 1.212632893623823
Validation loss: 2.445850304655819

Epoch: 6| Step: 8
Training loss: 1.1721900007952966
Validation loss: 2.4289014325712754

Epoch: 6| Step: 9
Training loss: 1.3635909376380955
Validation loss: 2.4317652856565495

Epoch: 6| Step: 10
Training loss: 0.8624645875488735
Validation loss: 2.4041320787487725

Epoch: 6| Step: 11
Training loss: 1.0293000020336158
Validation loss: 2.423473544845892

Epoch: 6| Step: 12
Training loss: 0.6501422442170101
Validation loss: 2.4211463300449325

Epoch: 6| Step: 13
Training loss: 1.909453467522044
Validation loss: 2.4101686195301695

Epoch: 447| Step: 0
Training loss: 1.0936353895901845
Validation loss: 2.4104341986326125

Epoch: 6| Step: 1
Training loss: 1.546861282441939
Validation loss: 2.413517110712244

Epoch: 6| Step: 2
Training loss: 0.7722426152986118
Validation loss: 2.4150614256857765

Epoch: 6| Step: 3
Training loss: 1.1164498728404104
Validation loss: 2.4282171245454114

Epoch: 6| Step: 4
Training loss: 0.7747974961805087
Validation loss: 2.4621272026500858

Epoch: 6| Step: 5
Training loss: 1.3634688021563732
Validation loss: 2.4609550646031226

Epoch: 6| Step: 6
Training loss: 1.1295351171011774
Validation loss: 2.4885507766917514

Epoch: 6| Step: 7
Training loss: 0.8619423404137524
Validation loss: 2.4877489587973014

Epoch: 6| Step: 8
Training loss: 1.1101504557254995
Validation loss: 2.4748836287370564

Epoch: 6| Step: 9
Training loss: 1.191005701991476
Validation loss: 2.4525868191450044

Epoch: 6| Step: 10
Training loss: 1.2384431654910981
Validation loss: 2.4401782390739477

Epoch: 6| Step: 11
Training loss: 0.9980390514806194
Validation loss: 2.3955805156013774

Epoch: 6| Step: 12
Training loss: 1.1701834613877258
Validation loss: 2.4027590914421344

Epoch: 6| Step: 13
Training loss: 0.9748992488842148
Validation loss: 2.3871198181283364

Epoch: 448| Step: 0
Training loss: 1.1317693708854786
Validation loss: 2.3868448707380217

Epoch: 6| Step: 1
Training loss: 0.9283551839406287
Validation loss: 2.424769528178566

Epoch: 6| Step: 2
Training loss: 1.4700671843661748
Validation loss: 2.432898986810445

Epoch: 6| Step: 3
Training loss: 1.0788251289736577
Validation loss: 2.410876012949318

Epoch: 6| Step: 4
Training loss: 0.8338136877988351
Validation loss: 2.4293324285227507

Epoch: 6| Step: 5
Training loss: 1.3918536469869012
Validation loss: 2.4446969789404913

Epoch: 6| Step: 6
Training loss: 1.0556882843146556
Validation loss: 2.443115717461481

Epoch: 6| Step: 7
Training loss: 0.6521337479510433
Validation loss: 2.450906714505242

Epoch: 6| Step: 8
Training loss: 1.3512271619449467
Validation loss: 2.455142868892595

Epoch: 6| Step: 9
Training loss: 0.7012131872731269
Validation loss: 2.4591679391205665

Epoch: 6| Step: 10
Training loss: 1.248225860417297
Validation loss: 2.4303965770179405

Epoch: 6| Step: 11
Training loss: 0.7740404495344956
Validation loss: 2.4540440013862073

Epoch: 6| Step: 12
Training loss: 1.6163774756059428
Validation loss: 2.463310452677089

Epoch: 6| Step: 13
Training loss: 0.9568590593162607
Validation loss: 2.4787059072088096

Epoch: 449| Step: 0
Training loss: 1.2846006914455568
Validation loss: 2.4949091257836993

Epoch: 6| Step: 1
Training loss: 0.9650541994953247
Validation loss: 2.4857222209616316

Epoch: 6| Step: 2
Training loss: 0.9815994369421279
Validation loss: 2.4744435964066813

Epoch: 6| Step: 3
Training loss: 0.9363873554922433
Validation loss: 2.4457878975057032

Epoch: 6| Step: 4
Training loss: 1.3573020827312618
Validation loss: 2.441308107696403

Epoch: 6| Step: 5
Training loss: 1.3635266364628933
Validation loss: 2.4398990790544732

Epoch: 6| Step: 6
Training loss: 0.9261121520660974
Validation loss: 2.4342162228746953

Epoch: 6| Step: 7
Training loss: 0.8586258831033512
Validation loss: 2.418888143147467

Epoch: 6| Step: 8
Training loss: 0.42465470395812793
Validation loss: 2.42605635972219

Epoch: 6| Step: 9
Training loss: 1.0889585448117023
Validation loss: 2.4266744247446836

Epoch: 6| Step: 10
Training loss: 1.0244474596483493
Validation loss: 2.4160536843308695

Epoch: 6| Step: 11
Training loss: 0.9984168395291229
Validation loss: 2.3999486183661856

Epoch: 6| Step: 12
Training loss: 1.8373222810088006
Validation loss: 2.3817076274774767

Epoch: 6| Step: 13
Training loss: 0.9899507676993674
Validation loss: 2.421438652475721

Epoch: 450| Step: 0
Training loss: 1.0880015674502639
Validation loss: 2.4131203789060707

Epoch: 6| Step: 1
Training loss: 1.014235205851079
Validation loss: 2.416802252578768

Epoch: 6| Step: 2
Training loss: 1.4147616180897393
Validation loss: 2.4340869587669935

Epoch: 6| Step: 3
Training loss: 0.9555631003032682
Validation loss: 2.465493352398995

Epoch: 6| Step: 4
Training loss: 0.9974178115906572
Validation loss: 2.480847537989584

Epoch: 6| Step: 5
Training loss: 1.1247168290537137
Validation loss: 2.502075269692473

Epoch: 6| Step: 6
Training loss: 1.2625522281683417
Validation loss: 2.5085411890238314

Epoch: 6| Step: 7
Training loss: 1.3354969748373842
Validation loss: 2.4902640906951072

Epoch: 6| Step: 8
Training loss: 0.9959393549920705
Validation loss: 2.4671921452046526

Epoch: 6| Step: 9
Training loss: 0.5717029343945934
Validation loss: 2.426795526944625

Epoch: 6| Step: 10
Training loss: 1.0395238898845405
Validation loss: 2.4035104200537396

Epoch: 6| Step: 11
Training loss: 0.9172051033267333
Validation loss: 2.394044747952541

Epoch: 6| Step: 12
Training loss: 1.3217613802658574
Validation loss: 2.359883292299996

Epoch: 6| Step: 13
Training loss: 1.4384777227061682
Validation loss: 2.380276229865471

Epoch: 451| Step: 0
Training loss: 1.1492518437727386
Validation loss: 2.380129122812312

Epoch: 6| Step: 1
Training loss: 1.1887755319639273
Validation loss: 2.3866027327995005

Epoch: 6| Step: 2
Training loss: 0.9376251772916113
Validation loss: 2.4174626736403506

Epoch: 6| Step: 3
Training loss: 1.2525669443967107
Validation loss: 2.4530593594710193

Epoch: 6| Step: 4
Training loss: 1.173003302040233
Validation loss: 2.468962338714899

Epoch: 6| Step: 5
Training loss: 1.201883344140251
Validation loss: 2.5021812962075285

Epoch: 6| Step: 6
Training loss: 1.1510736222240119
Validation loss: 2.50735825777146

Epoch: 6| Step: 7
Training loss: 0.8345637575870118
Validation loss: 2.5025342709337774

Epoch: 6| Step: 8
Training loss: 0.9678708671236239
Validation loss: 2.507844777705028

Epoch: 6| Step: 9
Training loss: 0.8772306619047188
Validation loss: 2.4825339987430652

Epoch: 6| Step: 10
Training loss: 1.1457415746303732
Validation loss: 2.457123262711354

Epoch: 6| Step: 11
Training loss: 0.770066863971584
Validation loss: 2.437165807716744

Epoch: 6| Step: 12
Training loss: 1.4486578089663715
Validation loss: 2.4281748648415236

Epoch: 6| Step: 13
Training loss: 1.1595621867872612
Validation loss: 2.3953738684668373

Epoch: 452| Step: 0
Training loss: 1.226793109572457
Validation loss: 2.36347946682218

Epoch: 6| Step: 1
Training loss: 1.2282239995371123
Validation loss: 2.38173261299435

Epoch: 6| Step: 2
Training loss: 0.9571643347557056
Validation loss: 2.3892923343365777

Epoch: 6| Step: 3
Training loss: 1.585500422039475
Validation loss: 2.3948650042195716

Epoch: 6| Step: 4
Training loss: 0.6576321216379637
Validation loss: 2.4197211567964754

Epoch: 6| Step: 5
Training loss: 1.0708060136172322
Validation loss: 2.4231475048727757

Epoch: 6| Step: 6
Training loss: 0.665353261076166
Validation loss: 2.471111451188039

Epoch: 6| Step: 7
Training loss: 1.1466624237044885
Validation loss: 2.500070298139685

Epoch: 6| Step: 8
Training loss: 1.169318398553899
Validation loss: 2.5027121445180125

Epoch: 6| Step: 9
Training loss: 1.098122711439793
Validation loss: 2.504436997806508

Epoch: 6| Step: 10
Training loss: 0.8815225950646053
Validation loss: 2.5291733340088838

Epoch: 6| Step: 11
Training loss: 0.9383969784275785
Validation loss: 2.5090231483052206

Epoch: 6| Step: 12
Training loss: 1.0097682812653952
Validation loss: 2.4916143924328686

Epoch: 6| Step: 13
Training loss: 1.445178711343669
Validation loss: 2.501323923651907

Epoch: 453| Step: 0
Training loss: 1.1566403735211122
Validation loss: 2.45823738664532

Epoch: 6| Step: 1
Training loss: 1.2607084309663141
Validation loss: 2.431419024365313

Epoch: 6| Step: 2
Training loss: 0.6587634998002334
Validation loss: 2.3889399978966734

Epoch: 6| Step: 3
Training loss: 1.6705108496260244
Validation loss: 2.383100506560885

Epoch: 6| Step: 4
Training loss: 0.7264462449782203
Validation loss: 2.37542199604703

Epoch: 6| Step: 5
Training loss: 1.3707726257393822
Validation loss: 2.375130722645153

Epoch: 6| Step: 6
Training loss: 1.1314749351823588
Validation loss: 2.3718360708859767

Epoch: 6| Step: 7
Training loss: 0.9600885874882564
Validation loss: 2.4163247829497587

Epoch: 6| Step: 8
Training loss: 0.9992951650979905
Validation loss: 2.4151505345607323

Epoch: 6| Step: 9
Training loss: 0.9197332751761665
Validation loss: 2.4241419635079

Epoch: 6| Step: 10
Training loss: 0.8102552509790953
Validation loss: 2.435114691264995

Epoch: 6| Step: 11
Training loss: 0.8901012955573339
Validation loss: 2.447914642633366

Epoch: 6| Step: 12
Training loss: 0.992312716294777
Validation loss: 2.4579311411708673

Epoch: 6| Step: 13
Training loss: 1.2808556764019345
Validation loss: 2.4766355905965485

Epoch: 454| Step: 0
Training loss: 1.0426761631126666
Validation loss: 2.4754981289917195

Epoch: 6| Step: 1
Training loss: 0.9769244324422313
Validation loss: 2.469525285708244

Epoch: 6| Step: 2
Training loss: 0.7888676242208535
Validation loss: 2.4494167705180807

Epoch: 6| Step: 3
Training loss: 1.46138409810982
Validation loss: 2.459496509879548

Epoch: 6| Step: 4
Training loss: 1.0808816580066072
Validation loss: 2.4542227883648136

Epoch: 6| Step: 5
Training loss: 0.6697030558094462
Validation loss: 2.4403958121977265

Epoch: 6| Step: 6
Training loss: 1.157951546375081
Validation loss: 2.4532208648316023

Epoch: 6| Step: 7
Training loss: 1.0629639454107387
Validation loss: 2.4617019156255955

Epoch: 6| Step: 8
Training loss: 1.0638735251870846
Validation loss: 2.4216618904935197

Epoch: 6| Step: 9
Training loss: 1.029569412429624
Validation loss: 2.438332543022832

Epoch: 6| Step: 10
Training loss: 0.9672661153121801
Validation loss: 2.430234870283842

Epoch: 6| Step: 11
Training loss: 1.1873577434258864
Validation loss: 2.4587404297442133

Epoch: 6| Step: 12
Training loss: 0.808007105807889
Validation loss: 2.4647035938699635

Epoch: 6| Step: 13
Training loss: 1.7476194402563838
Validation loss: 2.465059159856556

Epoch: 455| Step: 0
Training loss: 1.0386425689889798
Validation loss: 2.47031200834135

Epoch: 6| Step: 1
Training loss: 0.8857509356048836
Validation loss: 2.491409939103315

Epoch: 6| Step: 2
Training loss: 1.687783111559373
Validation loss: 2.47725801389033

Epoch: 6| Step: 3
Training loss: 0.3648418214081266
Validation loss: 2.481772135242783

Epoch: 6| Step: 4
Training loss: 0.9779933670244171
Validation loss: 2.464094406488276

Epoch: 6| Step: 5
Training loss: 1.0281809597381277
Validation loss: 2.486436022631972

Epoch: 6| Step: 6
Training loss: 1.0475430990015384
Validation loss: 2.4688684277512873

Epoch: 6| Step: 7
Training loss: 1.0756233049520096
Validation loss: 2.4569487279811355

Epoch: 6| Step: 8
Training loss: 0.7871135399189979
Validation loss: 2.4665062166503766

Epoch: 6| Step: 9
Training loss: 1.1923567185604587
Validation loss: 2.455279507538326

Epoch: 6| Step: 10
Training loss: 0.9181867300098762
Validation loss: 2.391315471751053

Epoch: 6| Step: 11
Training loss: 1.2607129697125126
Validation loss: 2.403825172831284

Epoch: 6| Step: 12
Training loss: 1.0796085599314722
Validation loss: 2.39259389417155

Epoch: 6| Step: 13
Training loss: 1.2329837829965102
Validation loss: 2.3818911676392025

Epoch: 456| Step: 0
Training loss: 0.7440861959901829
Validation loss: 2.364827343553635

Epoch: 6| Step: 1
Training loss: 0.9968259924917179
Validation loss: 2.3599417161427323

Epoch: 6| Step: 2
Training loss: 1.2711074668927258
Validation loss: 2.3829165802590926

Epoch: 6| Step: 3
Training loss: 0.9140238305413849
Validation loss: 2.4309036750553012

Epoch: 6| Step: 4
Training loss: 0.9500291920242463
Validation loss: 2.4758854960932255

Epoch: 6| Step: 5
Training loss: 0.8322973049833808
Validation loss: 2.504004506554523

Epoch: 6| Step: 6
Training loss: 1.1467128441535468
Validation loss: 2.4889728073683273

Epoch: 6| Step: 7
Training loss: 1.4614207238677945
Validation loss: 2.5114714800717253

Epoch: 6| Step: 8
Training loss: 0.6713481878148079
Validation loss: 2.5035706227102215

Epoch: 6| Step: 9
Training loss: 0.9879539460402291
Validation loss: 2.4675654202678543

Epoch: 6| Step: 10
Training loss: 1.206947941050106
Validation loss: 2.4722018857087766

Epoch: 6| Step: 11
Training loss: 0.7702473827640749
Validation loss: 2.4191255468323507

Epoch: 6| Step: 12
Training loss: 1.4318026545950118
Validation loss: 2.441675636179553

Epoch: 6| Step: 13
Training loss: 1.3327598480879728
Validation loss: 2.4168137002444525

Epoch: 457| Step: 0
Training loss: 1.3604759493534702
Validation loss: 2.40779004717062

Epoch: 6| Step: 1
Training loss: 0.9257952532131712
Validation loss: 2.400049955906056

Epoch: 6| Step: 2
Training loss: 1.0828676262016284
Validation loss: 2.385690463714978

Epoch: 6| Step: 3
Training loss: 1.2994530572606255
Validation loss: 2.38896677928882

Epoch: 6| Step: 4
Training loss: 0.8539649601164496
Validation loss: 2.3954242594256963

Epoch: 6| Step: 5
Training loss: 1.5587928281527548
Validation loss: 2.4479757409613914

Epoch: 6| Step: 6
Training loss: 0.8998058016856876
Validation loss: 2.4723694679784165

Epoch: 6| Step: 7
Training loss: 0.7812185662621601
Validation loss: 2.5166641205865306

Epoch: 6| Step: 8
Training loss: 1.045304957250002
Validation loss: 2.5124991100058494

Epoch: 6| Step: 9
Training loss: 1.2255712500676204
Validation loss: 2.5102687876047107

Epoch: 6| Step: 10
Training loss: 0.6903135641771078
Validation loss: 2.523945969925063

Epoch: 6| Step: 11
Training loss: 0.7166346644493949
Validation loss: 2.4533701922332756

Epoch: 6| Step: 12
Training loss: 1.0822238131056034
Validation loss: 2.4730456477720058

Epoch: 6| Step: 13
Training loss: 0.9698436470455744
Validation loss: 2.4516760164798392

Epoch: 458| Step: 0
Training loss: 1.5170924368088154
Validation loss: 2.4548110617604095

Epoch: 6| Step: 1
Training loss: 1.0215669966884915
Validation loss: 2.4474919823711483

Epoch: 6| Step: 2
Training loss: 0.9294798162237817
Validation loss: 2.4481821435062927

Epoch: 6| Step: 3
Training loss: 1.0003986756024295
Validation loss: 2.4303834855620354

Epoch: 6| Step: 4
Training loss: 0.6545785781457764
Validation loss: 2.437835711259256

Epoch: 6| Step: 5
Training loss: 1.1498127701975653
Validation loss: 2.440902457681006

Epoch: 6| Step: 6
Training loss: 1.4630969402453058
Validation loss: 2.4641283503027105

Epoch: 6| Step: 7
Training loss: 1.1261030193956738
Validation loss: 2.4426753400941124

Epoch: 6| Step: 8
Training loss: 0.7671720872251472
Validation loss: 2.48317288682002

Epoch: 6| Step: 9
Training loss: 1.0584836107227646
Validation loss: 2.483129100064031

Epoch: 6| Step: 10
Training loss: 0.7175346963581292
Validation loss: 2.444167222418162

Epoch: 6| Step: 11
Training loss: 0.8520347265791363
Validation loss: 2.443593198921124

Epoch: 6| Step: 12
Training loss: 1.2226814048056307
Validation loss: 2.434995753670808

Epoch: 6| Step: 13
Training loss: 0.8289502548344393
Validation loss: 2.409336970046852

Epoch: 459| Step: 0
Training loss: 1.5018801032720595
Validation loss: 2.367129126113686

Epoch: 6| Step: 1
Training loss: 1.3030745077985566
Validation loss: 2.3634573824470326

Epoch: 6| Step: 2
Training loss: 0.888461916088541
Validation loss: 2.390455533393046

Epoch: 6| Step: 3
Training loss: 1.0671810926298089
Validation loss: 2.3767144298058676

Epoch: 6| Step: 4
Training loss: 1.2155110283700068
Validation loss: 2.4062503132302537

Epoch: 6| Step: 5
Training loss: 0.9024153181486287
Validation loss: 2.4441893222415674

Epoch: 6| Step: 6
Training loss: 1.1000589159880094
Validation loss: 2.4484442364700487

Epoch: 6| Step: 7
Training loss: 0.9772004447057667
Validation loss: 2.4936872360855933

Epoch: 6| Step: 8
Training loss: 1.045682085101302
Validation loss: 2.51269240879519

Epoch: 6| Step: 9
Training loss: 1.0640721750589766
Validation loss: 2.519086360739545

Epoch: 6| Step: 10
Training loss: 1.0411427261028832
Validation loss: 2.50905215512142

Epoch: 6| Step: 11
Training loss: 1.1184682374041608
Validation loss: 2.508034602072788

Epoch: 6| Step: 12
Training loss: 0.4878953553238461
Validation loss: 2.477667987282635

Epoch: 6| Step: 13
Training loss: 0.42847180485855346
Validation loss: 2.4658201160022677

Epoch: 460| Step: 0
Training loss: 1.3960237610387896
Validation loss: 2.423728535798855

Epoch: 6| Step: 1
Training loss: 0.9605070871471961
Validation loss: 2.4213799750392

Epoch: 6| Step: 2
Training loss: 1.2027157669635
Validation loss: 2.422541476561258

Epoch: 6| Step: 3
Training loss: 0.6439409269137844
Validation loss: 2.431682401712451

Epoch: 6| Step: 4
Training loss: 1.1068937465258455
Validation loss: 2.4497114281539263

Epoch: 6| Step: 5
Training loss: 0.7421923988582156
Validation loss: 2.4564467383601025

Epoch: 6| Step: 6
Training loss: 0.9096759625839721
Validation loss: 2.478208804754398

Epoch: 6| Step: 7
Training loss: 1.316623658471731
Validation loss: 2.4818949493026974

Epoch: 6| Step: 8
Training loss: 1.1847176330485474
Validation loss: 2.472382987258465

Epoch: 6| Step: 9
Training loss: 0.46072728810914554
Validation loss: 2.451074095477236

Epoch: 6| Step: 10
Training loss: 0.7809030143752889
Validation loss: 2.4559407979732426

Epoch: 6| Step: 11
Training loss: 1.471142950060785
Validation loss: 2.464816839540804

Epoch: 6| Step: 12
Training loss: 0.8523410073296522
Validation loss: 2.4383682995136184

Epoch: 6| Step: 13
Training loss: 1.0346630721001109
Validation loss: 2.430340394860174

Epoch: 461| Step: 0
Training loss: 0.4128822924910897
Validation loss: 2.4427328657970184

Epoch: 6| Step: 1
Training loss: 1.1795895769517042
Validation loss: 2.4466266672494297

Epoch: 6| Step: 2
Training loss: 0.9716584016394978
Validation loss: 2.389607334010175

Epoch: 6| Step: 3
Training loss: 0.9931166796038639
Validation loss: 2.440497287528855

Epoch: 6| Step: 4
Training loss: 1.037323837951049
Validation loss: 2.389421118464305

Epoch: 6| Step: 5
Training loss: 1.0665074115322168
Validation loss: 2.413154253582308

Epoch: 6| Step: 6
Training loss: 1.2208973478301108
Validation loss: 2.4428352063954986

Epoch: 6| Step: 7
Training loss: 0.9331308597960705
Validation loss: 2.4529946175449617

Epoch: 6| Step: 8
Training loss: 1.2094115949116238
Validation loss: 2.475752363933207

Epoch: 6| Step: 9
Training loss: 0.6875715651977794
Validation loss: 2.4803060224862197

Epoch: 6| Step: 10
Training loss: 0.8614742302187002
Validation loss: 2.4456136492432994

Epoch: 6| Step: 11
Training loss: 0.8201484879518671
Validation loss: 2.465885964738698

Epoch: 6| Step: 12
Training loss: 1.5545853624387715
Validation loss: 2.4457936342209585

Epoch: 6| Step: 13
Training loss: 1.2201510958831996
Validation loss: 2.4203222848745303

Epoch: 462| Step: 0
Training loss: 1.445558269327796
Validation loss: 2.430958445294814

Epoch: 6| Step: 1
Training loss: 1.0069419590418751
Validation loss: 2.4387035611565295

Epoch: 6| Step: 2
Training loss: 0.7548222486670784
Validation loss: 2.4251030544300507

Epoch: 6| Step: 3
Training loss: 1.0518963650796294
Validation loss: 2.443050928717429

Epoch: 6| Step: 4
Training loss: 1.019000152580392
Validation loss: 2.4137448072173426

Epoch: 6| Step: 5
Training loss: 0.9448282562090737
Validation loss: 2.4400183103251947

Epoch: 6| Step: 6
Training loss: 0.9184392169885723
Validation loss: 2.421076253009857

Epoch: 6| Step: 7
Training loss: 1.2028775146388322
Validation loss: 2.41492209266872

Epoch: 6| Step: 8
Training loss: 1.2887467893603022
Validation loss: 2.4446312631218303

Epoch: 6| Step: 9
Training loss: 0.8631865160301676
Validation loss: 2.436860755079009

Epoch: 6| Step: 10
Training loss: 0.7280581676934862
Validation loss: 2.4347346674262416

Epoch: 6| Step: 11
Training loss: 1.056384099539937
Validation loss: 2.4328901066719393

Epoch: 6| Step: 12
Training loss: 1.1852946633752635
Validation loss: 2.4428492606290955

Epoch: 6| Step: 13
Training loss: 0.5454439239840523
Validation loss: 2.4575694105007884

Epoch: 463| Step: 0
Training loss: 1.104777359174151
Validation loss: 2.4518436941630415

Epoch: 6| Step: 1
Training loss: 0.9132357387771095
Validation loss: 2.482960232180009

Epoch: 6| Step: 2
Training loss: 0.9964539418943572
Validation loss: 2.4855587358380564

Epoch: 6| Step: 3
Training loss: 0.8052127938354701
Validation loss: 2.484022290244634

Epoch: 6| Step: 4
Training loss: 0.9007982833059123
Validation loss: 2.4682719675300464

Epoch: 6| Step: 5
Training loss: 0.8381678693874871
Validation loss: 2.4396078778442067

Epoch: 6| Step: 6
Training loss: 1.0810409035014978
Validation loss: 2.4761999197441984

Epoch: 6| Step: 7
Training loss: 1.704285812254592
Validation loss: 2.4524361248198128

Epoch: 6| Step: 8
Training loss: 1.1160585261007825
Validation loss: 2.467098875026352

Epoch: 6| Step: 9
Training loss: 1.0135462688617305
Validation loss: 2.457339406201912

Epoch: 6| Step: 10
Training loss: 0.9326343794431445
Validation loss: 2.44720288152792

Epoch: 6| Step: 11
Training loss: 1.0440792500974285
Validation loss: 2.4479565683715885

Epoch: 6| Step: 12
Training loss: 0.6346442473345963
Validation loss: 2.44858050398721

Epoch: 6| Step: 13
Training loss: 0.9021595688484354
Validation loss: 2.4202525896705898

Epoch: 464| Step: 0
Training loss: 1.102819820908341
Validation loss: 2.4234409886274344

Epoch: 6| Step: 1
Training loss: 0.7689432909112681
Validation loss: 2.4221208937793555

Epoch: 6| Step: 2
Training loss: 1.0130163877466454
Validation loss: 2.439291111653451

Epoch: 6| Step: 3
Training loss: 1.2043884381117156
Validation loss: 2.4116274735535947

Epoch: 6| Step: 4
Training loss: 1.469877337962803
Validation loss: 2.4206791153747402

Epoch: 6| Step: 5
Training loss: 1.1205071699124987
Validation loss: 2.444218947438873

Epoch: 6| Step: 6
Training loss: 1.0769486021459536
Validation loss: 2.440429278860367

Epoch: 6| Step: 7
Training loss: 0.6873154826073947
Validation loss: 2.466974902980778

Epoch: 6| Step: 8
Training loss: 0.943177136496282
Validation loss: 2.479298548724995

Epoch: 6| Step: 9
Training loss: 0.9540821959795606
Validation loss: 2.4979716676277905

Epoch: 6| Step: 10
Training loss: 0.92895536685894
Validation loss: 2.499554243648454

Epoch: 6| Step: 11
Training loss: 1.0540107533849157
Validation loss: 2.507869635854876

Epoch: 6| Step: 12
Training loss: 0.991498693029607
Validation loss: 2.4673016735045414

Epoch: 6| Step: 13
Training loss: 0.3280303455248371
Validation loss: 2.465850958676867

Epoch: 465| Step: 0
Training loss: 0.8435671219612567
Validation loss: 2.4482399288282766

Epoch: 6| Step: 1
Training loss: 1.1859905788922316
Validation loss: 2.430985893225927

Epoch: 6| Step: 2
Training loss: 1.336212129975149
Validation loss: 2.405681125754482

Epoch: 6| Step: 3
Training loss: 0.8354353064711372
Validation loss: 2.4012914119347544

Epoch: 6| Step: 4
Training loss: 1.0255370989133248
Validation loss: 2.390490886398969

Epoch: 6| Step: 5
Training loss: 1.1047456890573706
Validation loss: 2.3818588632111637

Epoch: 6| Step: 6
Training loss: 1.3472947672465196
Validation loss: 2.401967467792504

Epoch: 6| Step: 7
Training loss: 0.31796004402932854
Validation loss: 2.3942086901973054

Epoch: 6| Step: 8
Training loss: 0.9907586329486143
Validation loss: 2.407961585719996

Epoch: 6| Step: 9
Training loss: 0.7848221556760736
Validation loss: 2.455024467712908

Epoch: 6| Step: 10
Training loss: 1.228126840371653
Validation loss: 2.453256297733926

Epoch: 6| Step: 11
Training loss: 0.715251285305155
Validation loss: 2.4800474228105784

Epoch: 6| Step: 12
Training loss: 0.7788997393520604
Validation loss: 2.4691915910248956

Epoch: 6| Step: 13
Training loss: 1.4117648177871474
Validation loss: 2.4709965380666232

Epoch: 466| Step: 0
Training loss: 0.875076563074029
Validation loss: 2.449966338288246

Epoch: 6| Step: 1
Training loss: 1.4580727298947889
Validation loss: 2.4182250629723367

Epoch: 6| Step: 2
Training loss: 0.9146867886179825
Validation loss: 2.408136886501297

Epoch: 6| Step: 3
Training loss: 0.9894546960576502
Validation loss: 2.404684760800227

Epoch: 6| Step: 4
Training loss: 1.1739271886982299
Validation loss: 2.3917908693900714

Epoch: 6| Step: 5
Training loss: 1.1833370925055597
Validation loss: 2.3875897601602007

Epoch: 6| Step: 6
Training loss: 1.0847577609531633
Validation loss: 2.3925133564067744

Epoch: 6| Step: 7
Training loss: 0.8074587536248458
Validation loss: 2.3832919322499047

Epoch: 6| Step: 8
Training loss: 0.9946000811782579
Validation loss: 2.3877642315604066

Epoch: 6| Step: 9
Training loss: 0.8758930349342852
Validation loss: 2.4133556401149776

Epoch: 6| Step: 10
Training loss: 1.0735169493745698
Validation loss: 2.4399896806000765

Epoch: 6| Step: 11
Training loss: 0.9920331579596491
Validation loss: 2.4294137453946427

Epoch: 6| Step: 12
Training loss: 0.8594483430949762
Validation loss: 2.4681402335789278

Epoch: 6| Step: 13
Training loss: 0.49482924837304537
Validation loss: 2.510008797752102

Epoch: 467| Step: 0
Training loss: 1.014834404389164
Validation loss: 2.5152018486767242

Epoch: 6| Step: 1
Training loss: 0.7714619693641229
Validation loss: 2.53666957779004

Epoch: 6| Step: 2
Training loss: 0.9574137020812807
Validation loss: 2.550214534680986

Epoch: 6| Step: 3
Training loss: 1.153442221326733
Validation loss: 2.5770742115215413

Epoch: 6| Step: 4
Training loss: 1.5498840657838269
Validation loss: 2.5444234300826816

Epoch: 6| Step: 5
Training loss: 1.2115743623614756
Validation loss: 2.5043375113784463

Epoch: 6| Step: 6
Training loss: 0.6134413977803765
Validation loss: 2.490896443926023

Epoch: 6| Step: 7
Training loss: 0.9226235082697234
Validation loss: 2.441011964129258

Epoch: 6| Step: 8
Training loss: 0.6367796184254745
Validation loss: 2.4091282817564856

Epoch: 6| Step: 9
Training loss: 0.6027096054119985
Validation loss: 2.3857682284227875

Epoch: 6| Step: 10
Training loss: 1.371613971668303
Validation loss: 2.377125505141589

Epoch: 6| Step: 11
Training loss: 0.8363733314152021
Validation loss: 2.3839120136597787

Epoch: 6| Step: 12
Training loss: 1.0643832962510242
Validation loss: 2.3927180632567797

Epoch: 6| Step: 13
Training loss: 0.9768139324759856
Validation loss: 2.419484055787368

Epoch: 468| Step: 0
Training loss: 1.0372166120185273
Validation loss: 2.384152015698683

Epoch: 6| Step: 1
Training loss: 1.2125287337683706
Validation loss: 2.426248757518212

Epoch: 6| Step: 2
Training loss: 0.8537380531000154
Validation loss: 2.426821931249553

Epoch: 6| Step: 3
Training loss: 0.8830517807484807
Validation loss: 2.4493711264238818

Epoch: 6| Step: 4
Training loss: 0.8369831426146636
Validation loss: 2.4653157753283415

Epoch: 6| Step: 5
Training loss: 0.45889393341504275
Validation loss: 2.4783719528793093

Epoch: 6| Step: 6
Training loss: 0.5929629480130859
Validation loss: 2.4898608772060484

Epoch: 6| Step: 7
Training loss: 1.4035617140250387
Validation loss: 2.5020576971303483

Epoch: 6| Step: 8
Training loss: 0.7511864258561476
Validation loss: 2.489942136503124

Epoch: 6| Step: 9
Training loss: 0.6835383801515448
Validation loss: 2.457437589486721

Epoch: 6| Step: 10
Training loss: 1.3288037529136212
Validation loss: 2.4611809290614026

Epoch: 6| Step: 11
Training loss: 1.2268495163138902
Validation loss: 2.4535201667328934

Epoch: 6| Step: 12
Training loss: 1.1161165773251434
Validation loss: 2.4583590446894874

Epoch: 6| Step: 13
Training loss: 1.150466320610875
Validation loss: 2.4313815940991432

Epoch: 469| Step: 0
Training loss: 0.6258570993010905
Validation loss: 2.4016841852395263

Epoch: 6| Step: 1
Training loss: 0.9819065509488646
Validation loss: 2.4110615023555826

Epoch: 6| Step: 2
Training loss: 0.8520718372443078
Validation loss: 2.394938441889462

Epoch: 6| Step: 3
Training loss: 0.850350874119384
Validation loss: 2.397344165472197

Epoch: 6| Step: 4
Training loss: 0.9976408070778277
Validation loss: 2.4163979169444363

Epoch: 6| Step: 5
Training loss: 1.0517181417338486
Validation loss: 2.4163155015934152

Epoch: 6| Step: 6
Training loss: 0.6241067224840674
Validation loss: 2.458093476278286

Epoch: 6| Step: 7
Training loss: 1.371029061641733
Validation loss: 2.4721316864115535

Epoch: 6| Step: 8
Training loss: 1.0990211987103997
Validation loss: 2.498771437389189

Epoch: 6| Step: 9
Training loss: 0.9960933311311926
Validation loss: 2.4976785356432156

Epoch: 6| Step: 10
Training loss: 1.1417589168914546
Validation loss: 2.487307444594832

Epoch: 6| Step: 11
Training loss: 1.3030171923787666
Validation loss: 2.466288871388327

Epoch: 6| Step: 12
Training loss: 0.8130141978672237
Validation loss: 2.3970302065789104

Epoch: 6| Step: 13
Training loss: 0.9668230766059656
Validation loss: 2.3658464119398093

Epoch: 470| Step: 0
Training loss: 0.712552635858693
Validation loss: 2.3420933381992413

Epoch: 6| Step: 1
Training loss: 1.0672195742522028
Validation loss: 2.379321199421268

Epoch: 6| Step: 2
Training loss: 0.7516746104286574
Validation loss: 2.414734806212485

Epoch: 6| Step: 3
Training loss: 0.9393353616418683
Validation loss: 2.457355829124983

Epoch: 6| Step: 4
Training loss: 0.9060928274203579
Validation loss: 2.502835593482354

Epoch: 6| Step: 5
Training loss: 1.1277684480430494
Validation loss: 2.5299791442187876

Epoch: 6| Step: 6
Training loss: 0.6525147265383799
Validation loss: 2.5474932436274966

Epoch: 6| Step: 7
Training loss: 1.0385370288210931
Validation loss: 2.550545469969842

Epoch: 6| Step: 8
Training loss: 1.0805824026931077
Validation loss: 2.5323048121532614

Epoch: 6| Step: 9
Training loss: 0.9160132824963385
Validation loss: 2.5133444904360895

Epoch: 6| Step: 10
Training loss: 1.026883214266446
Validation loss: 2.504326604042541

Epoch: 6| Step: 11
Training loss: 0.8140449507390427
Validation loss: 2.4611178820173767

Epoch: 6| Step: 12
Training loss: 0.8091373551308075
Validation loss: 2.4204482825828815

Epoch: 6| Step: 13
Training loss: 2.113256993745093
Validation loss: 2.402765195495386

Epoch: 471| Step: 0
Training loss: 0.57588682720707
Validation loss: 2.421859351619324

Epoch: 6| Step: 1
Training loss: 0.45720602426919543
Validation loss: 2.3788838572976894

Epoch: 6| Step: 2
Training loss: 1.411463123984377
Validation loss: 2.4110766296349437

Epoch: 6| Step: 3
Training loss: 0.8454484093467642
Validation loss: 2.4142808580138646

Epoch: 6| Step: 4
Training loss: 0.7302928855654973
Validation loss: 2.419410775607877

Epoch: 6| Step: 5
Training loss: 1.0101083435830347
Validation loss: 2.457681858079276

Epoch: 6| Step: 6
Training loss: 0.7727183842530277
Validation loss: 2.476082147044955

Epoch: 6| Step: 7
Training loss: 1.077674384554282
Validation loss: 2.507149336585628

Epoch: 6| Step: 8
Training loss: 0.956444821426736
Validation loss: 2.518080302752575

Epoch: 6| Step: 9
Training loss: 0.7717235725531744
Validation loss: 2.5224544197980245

Epoch: 6| Step: 10
Training loss: 1.7809464714706544
Validation loss: 2.493619346192709

Epoch: 6| Step: 11
Training loss: 0.944569697832034
Validation loss: 2.492681307723915

Epoch: 6| Step: 12
Training loss: 0.7233773422770188
Validation loss: 2.4493952464140785

Epoch: 6| Step: 13
Training loss: 0.838629727843657
Validation loss: 2.4167936530040257

Epoch: 472| Step: 0
Training loss: 0.8333584225374598
Validation loss: 2.420801565909192

Epoch: 6| Step: 1
Training loss: 0.8811351403670152
Validation loss: 2.4222895949810406

Epoch: 6| Step: 2
Training loss: 1.0059813194057263
Validation loss: 2.4273351814770456

Epoch: 6| Step: 3
Training loss: 0.7009646606285213
Validation loss: 2.4485659586278663

Epoch: 6| Step: 4
Training loss: 0.7108027990818456
Validation loss: 2.464065411446106

Epoch: 6| Step: 5
Training loss: 1.0044041449087187
Validation loss: 2.4607851907475764

Epoch: 6| Step: 6
Training loss: 0.9026152957700476
Validation loss: 2.491956554750799

Epoch: 6| Step: 7
Training loss: 0.7947298235016578
Validation loss: 2.466957395267662

Epoch: 6| Step: 8
Training loss: 0.8829427639889452
Validation loss: 2.4417716145460724

Epoch: 6| Step: 9
Training loss: 1.2363892550670141
Validation loss: 2.4494238917992517

Epoch: 6| Step: 10
Training loss: 1.3390813499023086
Validation loss: 2.456491563237671

Epoch: 6| Step: 11
Training loss: 1.0097187555234068
Validation loss: 2.460478425719769

Epoch: 6| Step: 12
Training loss: 1.1348340642516532
Validation loss: 2.4590795474880616

Epoch: 6| Step: 13
Training loss: 0.9826607082057759
Validation loss: 2.4546231059229697

Epoch: 473| Step: 0
Training loss: 0.6148187595896876
Validation loss: 2.45813019630867

Epoch: 6| Step: 1
Training loss: 1.1061296947171404
Validation loss: 2.4385031265429027

Epoch: 6| Step: 2
Training loss: 1.1107177130664239
Validation loss: 2.4611850242275297

Epoch: 6| Step: 3
Training loss: 1.27051128413366
Validation loss: 2.4710629709375804

Epoch: 6| Step: 4
Training loss: 1.3232843483827672
Validation loss: 2.4649067215053506

Epoch: 6| Step: 5
Training loss: 1.0267606755870355
Validation loss: 2.4901513071218075

Epoch: 6| Step: 6
Training loss: 0.7627139901232147
Validation loss: 2.449010134463183

Epoch: 6| Step: 7
Training loss: 0.8769819429076263
Validation loss: 2.45532504962754

Epoch: 6| Step: 8
Training loss: 0.9591211660371394
Validation loss: 2.438964533144516

Epoch: 6| Step: 9
Training loss: 0.8719514464632299
Validation loss: 2.447071897531889

Epoch: 6| Step: 10
Training loss: 0.7441010151731469
Validation loss: 2.43287642984118

Epoch: 6| Step: 11
Training loss: 0.8978567817408497
Validation loss: 2.4515839227162743

Epoch: 6| Step: 12
Training loss: 0.8458266663562625
Validation loss: 2.453083695058129

Epoch: 6| Step: 13
Training loss: 0.7478320258939415
Validation loss: 2.4676100213539898

Epoch: 474| Step: 0
Training loss: 0.5068404945359772
Validation loss: 2.4390477624371623

Epoch: 6| Step: 1
Training loss: 0.4007311977490023
Validation loss: 2.456187864977484

Epoch: 6| Step: 2
Training loss: 0.8169573516313201
Validation loss: 2.4560969163306856

Epoch: 6| Step: 3
Training loss: 0.8622733398822333
Validation loss: 2.447685916439196

Epoch: 6| Step: 4
Training loss: 1.2023473926709614
Validation loss: 2.438762645926958

Epoch: 6| Step: 5
Training loss: 1.4689328505955321
Validation loss: 2.4360315060587525

Epoch: 6| Step: 6
Training loss: 1.1725419753151858
Validation loss: 2.4069282290794676

Epoch: 6| Step: 7
Training loss: 1.2670781776317477
Validation loss: 2.459392043456483

Epoch: 6| Step: 8
Training loss: 0.9935093882308655
Validation loss: 2.5071210000163875

Epoch: 6| Step: 9
Training loss: 0.7552339396027115
Validation loss: 2.494357524958026

Epoch: 6| Step: 10
Training loss: 0.659114987059105
Validation loss: 2.50015075905829

Epoch: 6| Step: 11
Training loss: 0.9852682632306188
Validation loss: 2.504781402202686

Epoch: 6| Step: 12
Training loss: 1.0622070694074934
Validation loss: 2.488005546237046

Epoch: 6| Step: 13
Training loss: 0.662868053836529
Validation loss: 2.4853815047074614

Epoch: 475| Step: 0
Training loss: 1.0978543791694932
Validation loss: 2.4788052505808222

Epoch: 6| Step: 1
Training loss: 0.6767515372113347
Validation loss: 2.4550591211744095

Epoch: 6| Step: 2
Training loss: 0.9086315498131723
Validation loss: 2.454312408859224

Epoch: 6| Step: 3
Training loss: 0.6069181506278324
Validation loss: 2.4608775985623272

Epoch: 6| Step: 4
Training loss: 0.8351968353944142
Validation loss: 2.424295551275737

Epoch: 6| Step: 5
Training loss: 0.8709089485144992
Validation loss: 2.4278591021238873

Epoch: 6| Step: 6
Training loss: 0.8591266620053228
Validation loss: 2.4618417896578815

Epoch: 6| Step: 7
Training loss: 1.007290904778893
Validation loss: 2.457996915473312

Epoch: 6| Step: 8
Training loss: 1.063297589447696
Validation loss: 2.4531386138410762

Epoch: 6| Step: 9
Training loss: 1.1772674090284394
Validation loss: 2.4767908521751125

Epoch: 6| Step: 10
Training loss: 1.480342326138577
Validation loss: 2.4892751721224773

Epoch: 6| Step: 11
Training loss: 0.6753854198707527
Validation loss: 2.4869124284339157

Epoch: 6| Step: 12
Training loss: 1.0188680662299003
Validation loss: 2.500935940232142

Epoch: 6| Step: 13
Training loss: 0.7055499751411819
Validation loss: 2.5048572771098554

Epoch: 476| Step: 0
Training loss: 1.0820627586652196
Validation loss: 2.475651649709241

Epoch: 6| Step: 1
Training loss: 0.8975941888057557
Validation loss: 2.4324209717261884

Epoch: 6| Step: 2
Training loss: 0.68312765307666
Validation loss: 2.415626064924809

Epoch: 6| Step: 3
Training loss: 0.754336338206077
Validation loss: 2.389055754046963

Epoch: 6| Step: 4
Training loss: 0.8814056800065465
Validation loss: 2.421324028884031

Epoch: 6| Step: 5
Training loss: 1.1434461638233686
Validation loss: 2.4025311786173233

Epoch: 6| Step: 6
Training loss: 0.48686918930973916
Validation loss: 2.4207349472325057

Epoch: 6| Step: 7
Training loss: 0.6455200009486584
Validation loss: 2.4253199776515233

Epoch: 6| Step: 8
Training loss: 1.1213001765630772
Validation loss: 2.4304402379007164

Epoch: 6| Step: 9
Training loss: 1.0225521072504014
Validation loss: 2.4156537268678324

Epoch: 6| Step: 10
Training loss: 0.9534260321333492
Validation loss: 2.4051607626072204

Epoch: 6| Step: 11
Training loss: 1.0054711638972214
Validation loss: 2.416797867934485

Epoch: 6| Step: 12
Training loss: 1.0216279083998419
Validation loss: 2.4361698569527146

Epoch: 6| Step: 13
Training loss: 1.5720881960251285
Validation loss: 2.44102478643688

Epoch: 477| Step: 0
Training loss: 1.1495994347088458
Validation loss: 2.4295557822121783

Epoch: 6| Step: 1
Training loss: 0.6192879967734664
Validation loss: 2.4339609203105494

Epoch: 6| Step: 2
Training loss: 1.001181679155596
Validation loss: 2.443147054525209

Epoch: 6| Step: 3
Training loss: 1.3365745141107266
Validation loss: 2.4231847973088394

Epoch: 6| Step: 4
Training loss: 1.0356461427380201
Validation loss: 2.399162618703646

Epoch: 6| Step: 5
Training loss: 0.9010830614287175
Validation loss: 2.415120643021462

Epoch: 6| Step: 6
Training loss: 0.8189941711917026
Validation loss: 2.4089025716178027

Epoch: 6| Step: 7
Training loss: 0.9501942774736623
Validation loss: 2.436134679603466

Epoch: 6| Step: 8
Training loss: 0.8946935514777717
Validation loss: 2.4274951534907836

Epoch: 6| Step: 9
Training loss: 1.039313264574337
Validation loss: 2.4499705432362457

Epoch: 6| Step: 10
Training loss: 0.6901787459662828
Validation loss: 2.441216086974068

Epoch: 6| Step: 11
Training loss: 0.8436662137851633
Validation loss: 2.437275161764765

Epoch: 6| Step: 12
Training loss: 0.9271753815520168
Validation loss: 2.4767360158707157

Epoch: 6| Step: 13
Training loss: 0.7681565374320545
Validation loss: 2.480121144097344

Epoch: 478| Step: 0
Training loss: 0.44631999636899655
Validation loss: 2.4968856117016567

Epoch: 6| Step: 1
Training loss: 0.851562220022173
Validation loss: 2.5138903368024867

Epoch: 6| Step: 2
Training loss: 0.8388040183533634
Validation loss: 2.489776049522077

Epoch: 6| Step: 3
Training loss: 1.061712534186643
Validation loss: 2.4853824258258728

Epoch: 6| Step: 4
Training loss: 0.7203321458367488
Validation loss: 2.493373291847455

Epoch: 6| Step: 5
Training loss: 1.1897144750849098
Validation loss: 2.4636798934246595

Epoch: 6| Step: 6
Training loss: 1.3090823499714037
Validation loss: 2.4477195646430863

Epoch: 6| Step: 7
Training loss: 1.1202025376838554
Validation loss: 2.429639476254961

Epoch: 6| Step: 8
Training loss: 0.6858461818866614
Validation loss: 2.4031232162761906

Epoch: 6| Step: 9
Training loss: 1.1447791133859948
Validation loss: 2.398667091806245

Epoch: 6| Step: 10
Training loss: 0.9808795569868077
Validation loss: 2.40576111081067

Epoch: 6| Step: 11
Training loss: 0.7353184909146884
Validation loss: 2.38401231500311

Epoch: 6| Step: 12
Training loss: 0.8289072193136489
Validation loss: 2.423301238715099

Epoch: 6| Step: 13
Training loss: 0.9506434043692793
Validation loss: 2.4464354025937123

Epoch: 479| Step: 0
Training loss: 0.7366053618372403
Validation loss: 2.439037894328318

Epoch: 6| Step: 1
Training loss: 1.4241250648173738
Validation loss: 2.473782670542368

Epoch: 6| Step: 2
Training loss: 1.048284464325286
Validation loss: 2.4712540572871116

Epoch: 6| Step: 3
Training loss: 0.8239850621443473
Validation loss: 2.4814804994198587

Epoch: 6| Step: 4
Training loss: 1.0115856539692856
Validation loss: 2.5030323870254354

Epoch: 6| Step: 5
Training loss: 0.6600446888937312
Validation loss: 2.471583825001788

Epoch: 6| Step: 6
Training loss: 1.0336664959947268
Validation loss: 2.43789244469798

Epoch: 6| Step: 7
Training loss: 0.879582903319928
Validation loss: 2.4451596987057282

Epoch: 6| Step: 8
Training loss: 1.1837700942206089
Validation loss: 2.3882077633150183

Epoch: 6| Step: 9
Training loss: 0.8826334273753523
Validation loss: 2.3797177863688885

Epoch: 6| Step: 10
Training loss: 0.6256488769578484
Validation loss: 2.397398873661496

Epoch: 6| Step: 11
Training loss: 0.8760165032134285
Validation loss: 2.4096135024145933

Epoch: 6| Step: 12
Training loss: 0.7099517443873725
Validation loss: 2.4127710179019974

Epoch: 6| Step: 13
Training loss: 0.7051217866096385
Validation loss: 2.4235179688437487

Epoch: 480| Step: 0
Training loss: 0.8556443125716611
Validation loss: 2.428226293897137

Epoch: 6| Step: 1
Training loss: 0.9620907074282358
Validation loss: 2.470543488875456

Epoch: 6| Step: 2
Training loss: 0.8635588324803621
Validation loss: 2.464865381539109

Epoch: 6| Step: 3
Training loss: 0.7878372196978326
Validation loss: 2.4831139079069455

Epoch: 6| Step: 4
Training loss: 0.40187450933945573
Validation loss: 2.4795021060452376

Epoch: 6| Step: 5
Training loss: 1.0179439187406396
Validation loss: 2.453524946021446

Epoch: 6| Step: 6
Training loss: 1.0019670452020968
Validation loss: 2.4152985951898787

Epoch: 6| Step: 7
Training loss: 1.2223965792605587
Validation loss: 2.3854412778480443

Epoch: 6| Step: 8
Training loss: 0.6563325557552373
Validation loss: 2.3723449525074995

Epoch: 6| Step: 9
Training loss: 1.3546147363254004
Validation loss: 2.39236511688617

Epoch: 6| Step: 10
Training loss: 0.7436310232190745
Validation loss: 2.4026479877078044

Epoch: 6| Step: 11
Training loss: 0.9286211132810854
Validation loss: 2.45301683797631

Epoch: 6| Step: 12
Training loss: 0.9987239444661679
Validation loss: 2.4670975942962055

Epoch: 6| Step: 13
Training loss: 0.8789885079779415
Validation loss: 2.50034968483956

Epoch: 481| Step: 0
Training loss: 0.719365395515815
Validation loss: 2.4925890741193393

Epoch: 6| Step: 1
Training loss: 0.7251837168782838
Validation loss: 2.4851911838002123

Epoch: 6| Step: 2
Training loss: 0.7844977203053988
Validation loss: 2.4605732466071935

Epoch: 6| Step: 3
Training loss: 0.9803382209125058
Validation loss: 2.4500274513729163

Epoch: 6| Step: 4
Training loss: 1.0148677643951325
Validation loss: 2.4017183610477937

Epoch: 6| Step: 5
Training loss: 1.4602009757730054
Validation loss: 2.3822903770324446

Epoch: 6| Step: 6
Training loss: 0.6670182364028282
Validation loss: 2.385345657466034

Epoch: 6| Step: 7
Training loss: 0.9874085504704447
Validation loss: 2.379431557521024

Epoch: 6| Step: 8
Training loss: 1.0027427016158836
Validation loss: 2.4089885087315004

Epoch: 6| Step: 9
Training loss: 0.9471806124264038
Validation loss: 2.3927268634677032

Epoch: 6| Step: 10
Training loss: 0.7315606101499295
Validation loss: 2.427325081979966

Epoch: 6| Step: 11
Training loss: 1.14319488311781
Validation loss: 2.464517581456392

Epoch: 6| Step: 12
Training loss: 0.725778546446332
Validation loss: 2.4897307368044213

Epoch: 6| Step: 13
Training loss: 0.7777694609931549
Validation loss: 2.5158786369390063

Epoch: 482| Step: 0
Training loss: 0.8159188088504614
Validation loss: 2.5178035148096547

Epoch: 6| Step: 1
Training loss: 1.0929969374953186
Validation loss: 2.5060414441460765

Epoch: 6| Step: 2
Training loss: 0.7514091604917704
Validation loss: 2.51574446982296

Epoch: 6| Step: 3
Training loss: 0.6956304830316206
Validation loss: 2.5092647951192486

Epoch: 6| Step: 4
Training loss: 0.9639413915205743
Validation loss: 2.4627115137453095

Epoch: 6| Step: 5
Training loss: 0.7077847675338987
Validation loss: 2.450428193280913

Epoch: 6| Step: 6
Training loss: 0.8570091279477379
Validation loss: 2.412051281564283

Epoch: 6| Step: 7
Training loss: 0.8172126328522115
Validation loss: 2.405160894777774

Epoch: 6| Step: 8
Training loss: 1.0023729065886184
Validation loss: 2.4289095681459267

Epoch: 6| Step: 9
Training loss: 1.3157506832879908
Validation loss: 2.428579935761002

Epoch: 6| Step: 10
Training loss: 1.0784865616167647
Validation loss: 2.441561783100212

Epoch: 6| Step: 11
Training loss: 0.9717009115536952
Validation loss: 2.4321685248301184

Epoch: 6| Step: 12
Training loss: 0.8031815816934171
Validation loss: 2.4644713546834467

Epoch: 6| Step: 13
Training loss: 0.7089672664543244
Validation loss: 2.4631278925357774

Epoch: 483| Step: 0
Training loss: 1.2950761567923679
Validation loss: 2.462748010336233

Epoch: 6| Step: 1
Training loss: 0.6313594572140042
Validation loss: 2.469486582042591

Epoch: 6| Step: 2
Training loss: 0.9662636259235986
Validation loss: 2.4777443975922466

Epoch: 6| Step: 3
Training loss: 1.065654447713593
Validation loss: 2.477087424143176

Epoch: 6| Step: 4
Training loss: 0.8003628265632325
Validation loss: 2.4858760167653666

Epoch: 6| Step: 5
Training loss: 0.9381761337973196
Validation loss: 2.469105038828187

Epoch: 6| Step: 6
Training loss: 0.5535373853068761
Validation loss: 2.4671780722164423

Epoch: 6| Step: 7
Training loss: 0.9131632236676431
Validation loss: 2.471995040193924

Epoch: 6| Step: 8
Training loss: 1.0495416639980395
Validation loss: 2.454620109499831

Epoch: 6| Step: 9
Training loss: 0.8338972488383555
Validation loss: 2.4542108957528264

Epoch: 6| Step: 10
Training loss: 0.7796467160736716
Validation loss: 2.4518252163016125

Epoch: 6| Step: 11
Training loss: 1.06521931642157
Validation loss: 2.4699584165452766

Epoch: 6| Step: 12
Training loss: 0.6826598190944252
Validation loss: 2.4637359256029905

Epoch: 6| Step: 13
Training loss: 0.8994713515468797
Validation loss: 2.438851143207453

Epoch: 484| Step: 0
Training loss: 0.7212278528631187
Validation loss: 2.4245403420375835

Epoch: 6| Step: 1
Training loss: 0.8085696083187487
Validation loss: 2.4333155263327026

Epoch: 6| Step: 2
Training loss: 0.6458950525961634
Validation loss: 2.4441085158418345

Epoch: 6| Step: 3
Training loss: 0.8968612443885893
Validation loss: 2.4669691292681954

Epoch: 6| Step: 4
Training loss: 0.913103954117038
Validation loss: 2.4673758031480713

Epoch: 6| Step: 5
Training loss: 0.9542224069553059
Validation loss: 2.4732150334986622

Epoch: 6| Step: 6
Training loss: 1.2932062766417498
Validation loss: 2.4346054745446026

Epoch: 6| Step: 7
Training loss: 1.0660027938970773
Validation loss: 2.4478216051133814

Epoch: 6| Step: 8
Training loss: 0.7470205651967105
Validation loss: 2.438358559551741

Epoch: 6| Step: 9
Training loss: 0.5681776562451606
Validation loss: 2.4546869981099344

Epoch: 6| Step: 10
Training loss: 1.0190213269219048
Validation loss: 2.4308326369493716

Epoch: 6| Step: 11
Training loss: 0.5803959037077544
Validation loss: 2.4401330958746734

Epoch: 6| Step: 12
Training loss: 1.053397626141998
Validation loss: 2.4439710286892806

Epoch: 6| Step: 13
Training loss: 1.2251412485394004
Validation loss: 2.430781505608362

Epoch: 485| Step: 0
Training loss: 0.8207530700505332
Validation loss: 2.4190824834426032

Epoch: 6| Step: 1
Training loss: 0.7846549792066178
Validation loss: 2.4163880327251768

Epoch: 6| Step: 2
Training loss: 0.5576233604610569
Validation loss: 2.4531668915550835

Epoch: 6| Step: 3
Training loss: 0.7552746623058662
Validation loss: 2.465770813290701

Epoch: 6| Step: 4
Training loss: 1.4718427358926052
Validation loss: 2.4912345217084235

Epoch: 6| Step: 5
Training loss: 0.8550361340678393
Validation loss: 2.491260465314681

Epoch: 6| Step: 6
Training loss: 1.2038517528084047
Validation loss: 2.5079829001226703

Epoch: 6| Step: 7
Training loss: 0.9888223968313424
Validation loss: 2.4881597325594385

Epoch: 6| Step: 8
Training loss: 1.186919672859997
Validation loss: 2.484991008459772

Epoch: 6| Step: 9
Training loss: 0.4053881379479622
Validation loss: 2.4768045181065346

Epoch: 6| Step: 10
Training loss: 0.8318573317740116
Validation loss: 2.4132069046746607

Epoch: 6| Step: 11
Training loss: 0.6702080607470511
Validation loss: 2.4076678165282335

Epoch: 6| Step: 12
Training loss: 0.7118803207292396
Validation loss: 2.4408498189832235

Epoch: 6| Step: 13
Training loss: 1.0655596939614709
Validation loss: 2.429682076616304

Epoch: 486| Step: 0
Training loss: 0.9154603491112998
Validation loss: 2.4354789333569173

Epoch: 6| Step: 1
Training loss: 0.7962810696539198
Validation loss: 2.436955658591731

Epoch: 6| Step: 2
Training loss: 1.3946674184274441
Validation loss: 2.44042866852701

Epoch: 6| Step: 3
Training loss: 0.4380674088701451
Validation loss: 2.4701683847408256

Epoch: 6| Step: 4
Training loss: 1.1992843560281146
Validation loss: 2.4694698733324003

Epoch: 6| Step: 5
Training loss: 0.9355113872893188
Validation loss: 2.492006242633349

Epoch: 6| Step: 6
Training loss: 1.0541849705208965
Validation loss: 2.4947601904844334

Epoch: 6| Step: 7
Training loss: 0.2758090310517185
Validation loss: 2.5149936009760303

Epoch: 6| Step: 8
Training loss: 0.9644336523884439
Validation loss: 2.52835141634163

Epoch: 6| Step: 9
Training loss: 0.9425135388401121
Validation loss: 2.4682211568445136

Epoch: 6| Step: 10
Training loss: 0.6904579815064765
Validation loss: 2.4590099619144965

Epoch: 6| Step: 11
Training loss: 0.6393560075968833
Validation loss: 2.433352198326062

Epoch: 6| Step: 12
Training loss: 0.788179602368878
Validation loss: 2.398438596670099

Epoch: 6| Step: 13
Training loss: 0.8903910681032352
Validation loss: 2.4326353791823614

Epoch: 487| Step: 0
Training loss: 0.850985270156419
Validation loss: 2.4514282265082943

Epoch: 6| Step: 1
Training loss: 0.7416827442983978
Validation loss: 2.457729899235923

Epoch: 6| Step: 2
Training loss: 0.5721043434322918
Validation loss: 2.4954917806171126

Epoch: 6| Step: 3
Training loss: 0.6839076384194086
Validation loss: 2.479815067312285

Epoch: 6| Step: 4
Training loss: 0.7230146189645478
Validation loss: 2.486304890195459

Epoch: 6| Step: 5
Training loss: 0.7829856665798672
Validation loss: 2.4854888730451536

Epoch: 6| Step: 6
Training loss: 0.7667644740685989
Validation loss: 2.4679636992679765

Epoch: 6| Step: 7
Training loss: 0.8626093256120134
Validation loss: 2.440418351138901

Epoch: 6| Step: 8
Training loss: 1.422217862218558
Validation loss: 2.4041773255872343

Epoch: 6| Step: 9
Training loss: 1.0425960717884426
Validation loss: 2.419697411665481

Epoch: 6| Step: 10
Training loss: 0.8050408929899067
Validation loss: 2.4233843315556047

Epoch: 6| Step: 11
Training loss: 0.9546500340678653
Validation loss: 2.416016361405142

Epoch: 6| Step: 12
Training loss: 1.0728231901663496
Validation loss: 2.434302487457657

Epoch: 6| Step: 13
Training loss: 0.8950492325353446
Validation loss: 2.4619022861826503

Epoch: 488| Step: 0
Training loss: 0.7972447528564762
Validation loss: 2.4889040634828588

Epoch: 6| Step: 1
Training loss: 0.696793725102526
Validation loss: 2.476035813139745

Epoch: 6| Step: 2
Training loss: 0.8084985059583987
Validation loss: 2.476023715717648

Epoch: 6| Step: 3
Training loss: 0.6470891192714456
Validation loss: 2.4485803223343434

Epoch: 6| Step: 4
Training loss: 1.0203815290809248
Validation loss: 2.433463050625773

Epoch: 6| Step: 5
Training loss: 1.3530604710510623
Validation loss: 2.436992023335578

Epoch: 6| Step: 6
Training loss: 1.3136442736795209
Validation loss: 2.420178376763595

Epoch: 6| Step: 7
Training loss: 1.0297680813136614
Validation loss: 2.408459241976258

Epoch: 6| Step: 8
Training loss: 0.632638883910567
Validation loss: 2.3871075890602893

Epoch: 6| Step: 9
Training loss: 0.6992624151991403
Validation loss: 2.3920830035137133

Epoch: 6| Step: 10
Training loss: 0.7222953101206444
Validation loss: 2.4174638571218083

Epoch: 6| Step: 11
Training loss: 0.6270325512353289
Validation loss: 2.406251962482753

Epoch: 6| Step: 12
Training loss: 0.9906712758901306
Validation loss: 2.4104342560648346

Epoch: 6| Step: 13
Training loss: 0.777626906154242
Validation loss: 2.418871242838745

Epoch: 489| Step: 0
Training loss: 0.521377781178518
Validation loss: 2.463989810385269

Epoch: 6| Step: 1
Training loss: 0.7605273196738805
Validation loss: 2.481883082896331

Epoch: 6| Step: 2
Training loss: 0.7516940772971797
Validation loss: 2.5085584744758322

Epoch: 6| Step: 3
Training loss: 0.9503099111705517
Validation loss: 2.4826645042619555

Epoch: 6| Step: 4
Training loss: 0.8576459656979839
Validation loss: 2.5062578910805904

Epoch: 6| Step: 5
Training loss: 1.071170602123992
Validation loss: 2.459868418128044

Epoch: 6| Step: 6
Training loss: 0.8558553231586076
Validation loss: 2.4572802451596583

Epoch: 6| Step: 7
Training loss: 0.7852944779064313
Validation loss: 2.422350931128575

Epoch: 6| Step: 8
Training loss: 0.5221469969824826
Validation loss: 2.382654192806661

Epoch: 6| Step: 9
Training loss: 1.0429252586869369
Validation loss: 2.398546883959811

Epoch: 6| Step: 10
Training loss: 1.026095832647165
Validation loss: 2.3988631360045236

Epoch: 6| Step: 11
Training loss: 1.3974308247923959
Validation loss: 2.4293904822808554

Epoch: 6| Step: 12
Training loss: 0.7809581211354859
Validation loss: 2.424259407445657

Epoch: 6| Step: 13
Training loss: 0.5068220309369104
Validation loss: 2.4526647989500057

Epoch: 490| Step: 0
Training loss: 1.1214839774529348
Validation loss: 2.4907177319322304

Epoch: 6| Step: 1
Training loss: 0.8595249045282888
Validation loss: 2.4841485245643873

Epoch: 6| Step: 2
Training loss: 0.6925591592617755
Validation loss: 2.513095294848762

Epoch: 6| Step: 3
Training loss: 0.8485231317683841
Validation loss: 2.49990790976861

Epoch: 6| Step: 4
Training loss: 0.723735271824485
Validation loss: 2.497603668735408

Epoch: 6| Step: 5
Training loss: 0.6989598141089348
Validation loss: 2.4842873256838978

Epoch: 6| Step: 6
Training loss: 0.7788878780176433
Validation loss: 2.4530158273672646

Epoch: 6| Step: 7
Training loss: 1.0076481884814152
Validation loss: 2.430961446628201

Epoch: 6| Step: 8
Training loss: 0.5846562682740084
Validation loss: 2.4070015127804703

Epoch: 6| Step: 9
Training loss: 0.5218009702062305
Validation loss: 2.4223672113259926

Epoch: 6| Step: 10
Training loss: 0.7512972659127916
Validation loss: 2.442941638546562

Epoch: 6| Step: 11
Training loss: 1.61490126730217
Validation loss: 2.419963176019657

Epoch: 6| Step: 12
Training loss: 0.7239124823305471
Validation loss: 2.4247991136370683

Epoch: 6| Step: 13
Training loss: 0.7489585798649565
Validation loss: 2.4417986264832474

Epoch: 491| Step: 0
Training loss: 0.8591422372657
Validation loss: 2.4548184676379643

Epoch: 6| Step: 1
Training loss: 0.9880191922949215
Validation loss: 2.455715373360484

Epoch: 6| Step: 2
Training loss: 0.7318989832700487
Validation loss: 2.4594871162603926

Epoch: 6| Step: 3
Training loss: 1.027283583355053
Validation loss: 2.472892369063711

Epoch: 6| Step: 4
Training loss: 1.4327148737038629
Validation loss: 2.4617476987013194

Epoch: 6| Step: 5
Training loss: 0.603695567937205
Validation loss: 2.472907123812826

Epoch: 6| Step: 6
Training loss: 0.9844562557531834
Validation loss: 2.470948241276371

Epoch: 6| Step: 7
Training loss: 0.893607549719222
Validation loss: 2.4542024868004795

Epoch: 6| Step: 8
Training loss: 0.6951438613579952
Validation loss: 2.443226463598336

Epoch: 6| Step: 9
Training loss: 0.5629099305844244
Validation loss: 2.457611234121628

Epoch: 6| Step: 10
Training loss: 0.7914366555280593
Validation loss: 2.445141295624893

Epoch: 6| Step: 11
Training loss: 0.7568152246409635
Validation loss: 2.456448438445468

Epoch: 6| Step: 12
Training loss: 0.43907415367761227
Validation loss: 2.4299251383602583

Epoch: 6| Step: 13
Training loss: 0.996600990544944
Validation loss: 2.4175279668040015

Epoch: 492| Step: 0
Training loss: 1.3993991976132831
Validation loss: 2.4243829344439707

Epoch: 6| Step: 1
Training loss: 0.5574846527741275
Validation loss: 2.4257221058500895

Epoch: 6| Step: 2
Training loss: 0.8005255314116818
Validation loss: 2.4576064471324695

Epoch: 6| Step: 3
Training loss: 0.6880944456407664
Validation loss: 2.4762116021824623

Epoch: 6| Step: 4
Training loss: 0.8003945510194554
Validation loss: 2.490120191471679

Epoch: 6| Step: 5
Training loss: 0.8138822755085612
Validation loss: 2.4806110630966676

Epoch: 6| Step: 6
Training loss: 0.7582125050486801
Validation loss: 2.4868567607289247

Epoch: 6| Step: 7
Training loss: 0.6190121634756521
Validation loss: 2.486841836694123

Epoch: 6| Step: 8
Training loss: 0.6872634480736667
Validation loss: 2.4680366175960877

Epoch: 6| Step: 9
Training loss: 1.0364735408926071
Validation loss: 2.478129689048816

Epoch: 6| Step: 10
Training loss: 0.8203673571454808
Validation loss: 2.4482099973044047

Epoch: 6| Step: 11
Training loss: 1.2383610552272861
Validation loss: 2.4232487905492084

Epoch: 6| Step: 12
Training loss: 0.6333445208172082
Validation loss: 2.4249235603980432

Epoch: 6| Step: 13
Training loss: 0.8798465700126361
Validation loss: 2.401596571817333

Epoch: 493| Step: 0
Training loss: 1.398130628278622
Validation loss: 2.4432217481074447

Epoch: 6| Step: 1
Training loss: 0.878423770293776
Validation loss: 2.418836358684998

Epoch: 6| Step: 2
Training loss: 0.9510940425916848
Validation loss: 2.437929467418449

Epoch: 6| Step: 3
Training loss: 0.7325534549776687
Validation loss: 2.4544798918147706

Epoch: 6| Step: 4
Training loss: 0.9311188970358876
Validation loss: 2.477401490356975

Epoch: 6| Step: 5
Training loss: 0.9094313980913968
Validation loss: 2.4683423716297708

Epoch: 6| Step: 6
Training loss: 0.5278451866747803
Validation loss: 2.479936102031712

Epoch: 6| Step: 7
Training loss: 0.9152545492022193
Validation loss: 2.4690735281621508

Epoch: 6| Step: 8
Training loss: 0.8084434332701753
Validation loss: 2.460217379808169

Epoch: 6| Step: 9
Training loss: 0.6113828689390131
Validation loss: 2.450077335090577

Epoch: 6| Step: 10
Training loss: 0.8758822148949904
Validation loss: 2.471764677279301

Epoch: 6| Step: 11
Training loss: 0.8764334245325993
Validation loss: 2.4428359850894696

Epoch: 6| Step: 12
Training loss: 0.5695112687989602
Validation loss: 2.4471636938677417

Epoch: 6| Step: 13
Training loss: 0.5631942173865514
Validation loss: 2.4619367475541982

Epoch: 494| Step: 0
Training loss: 1.3345913713832247
Validation loss: 2.4506864600405533

Epoch: 6| Step: 1
Training loss: 0.921842089566656
Validation loss: 2.4873440296655525

Epoch: 6| Step: 2
Training loss: 0.9050172774630957
Validation loss: 2.4590265503915725

Epoch: 6| Step: 3
Training loss: 0.7450890292025432
Validation loss: 2.4488625784022884

Epoch: 6| Step: 4
Training loss: 0.9778333710600622
Validation loss: 2.4246109819051127

Epoch: 6| Step: 5
Training loss: 0.6150231619481841
Validation loss: 2.426628351289663

Epoch: 6| Step: 6
Training loss: 1.374528240423018
Validation loss: 2.4349514637983316

Epoch: 6| Step: 7
Training loss: 0.2990222499831307
Validation loss: 2.4274863114050307

Epoch: 6| Step: 8
Training loss: 0.863565872705945
Validation loss: 2.455252970731151

Epoch: 6| Step: 9
Training loss: 0.6186718294105363
Validation loss: 2.4661803449033024

Epoch: 6| Step: 10
Training loss: 0.5491188881002297
Validation loss: 2.482269674618067

Epoch: 6| Step: 11
Training loss: 0.8174846772557346
Validation loss: 2.4653116563472595

Epoch: 6| Step: 12
Training loss: 0.615310639998074
Validation loss: 2.4715442931630154

Epoch: 6| Step: 13
Training loss: 0.636091004761385
Validation loss: 2.457033278348373

Epoch: 495| Step: 0
Training loss: 0.7068982078189556
Validation loss: 2.4653321326379483

Epoch: 6| Step: 1
Training loss: 0.927668679571578
Validation loss: 2.431459877046236

Epoch: 6| Step: 2
Training loss: 1.4329001596440467
Validation loss: 2.4449109966553655

Epoch: 6| Step: 3
Training loss: 1.0635846716206283
Validation loss: 2.440542887497713

Epoch: 6| Step: 4
Training loss: 0.5092350036049768
Validation loss: 2.440273675417422

Epoch: 6| Step: 5
Training loss: 0.608107814291147
Validation loss: 2.43111087164688

Epoch: 6| Step: 6
Training loss: 0.541358618684624
Validation loss: 2.446760707850264

Epoch: 6| Step: 7
Training loss: 0.5526443246337247
Validation loss: 2.4901185931338246

Epoch: 6| Step: 8
Training loss: 0.8923276720984843
Validation loss: 2.4895403135700667

Epoch: 6| Step: 9
Training loss: 0.8652800468291251
Validation loss: 2.478955499168427

Epoch: 6| Step: 10
Training loss: 0.7362436099333729
Validation loss: 2.4819995092269336

Epoch: 6| Step: 11
Training loss: 0.9669194307580092
Validation loss: 2.478013428510012

Epoch: 6| Step: 12
Training loss: 0.8614345493439096
Validation loss: 2.455054494719413

Epoch: 6| Step: 13
Training loss: 0.7456051489848692
Validation loss: 2.4374059464930378

Epoch: 496| Step: 0
Training loss: 0.6098279980974052
Validation loss: 2.438663576208722

Epoch: 6| Step: 1
Training loss: 0.6748125045478173
Validation loss: 2.4179635394175727

Epoch: 6| Step: 2
Training loss: 0.7155733398048273
Validation loss: 2.42368518239647

Epoch: 6| Step: 3
Training loss: 1.403662016804196
Validation loss: 2.433374852024202

Epoch: 6| Step: 4
Training loss: 0.78699342995389
Validation loss: 2.458606557399759

Epoch: 6| Step: 5
Training loss: 0.6671010678340672
Validation loss: 2.476602543840036

Epoch: 6| Step: 6
Training loss: 0.7097698725907617
Validation loss: 2.473307032363074

Epoch: 6| Step: 7
Training loss: 0.9439501442796431
Validation loss: 2.4785492378866723

Epoch: 6| Step: 8
Training loss: 0.7541470711271635
Validation loss: 2.481867704412029

Epoch: 6| Step: 9
Training loss: 0.6578093123188844
Validation loss: 2.4536015314400297

Epoch: 6| Step: 10
Training loss: 0.7110331544348881
Validation loss: 2.428904204242607

Epoch: 6| Step: 11
Training loss: 1.1125723740256488
Validation loss: 2.399109343094351

Epoch: 6| Step: 12
Training loss: 0.9112798606888393
Validation loss: 2.404365284604274

Epoch: 6| Step: 13
Training loss: 0.7963869807034172
Validation loss: 2.399841814570645

Epoch: 497| Step: 0
Training loss: 0.837940419102442
Validation loss: 2.439904082558222

Epoch: 6| Step: 1
Training loss: 0.9230877286480298
Validation loss: 2.4367870311446196

Epoch: 6| Step: 2
Training loss: 0.6758950639261451
Validation loss: 2.4684297066485326

Epoch: 6| Step: 3
Training loss: 1.3190087195709046
Validation loss: 2.48726309880161

Epoch: 6| Step: 4
Training loss: 0.7747558763003598
Validation loss: 2.4769418488717094

Epoch: 6| Step: 5
Training loss: 0.778327817414021
Validation loss: 2.5028237075412045

Epoch: 6| Step: 6
Training loss: 0.8286978341855121
Validation loss: 2.4988621019200945

Epoch: 6| Step: 7
Training loss: 0.6651353136226166
Validation loss: 2.4734750196348685

Epoch: 6| Step: 8
Training loss: 0.9388243222435395
Validation loss: 2.490828569054491

Epoch: 6| Step: 9
Training loss: 0.727737829719243
Validation loss: 2.4620821206239216

Epoch: 6| Step: 10
Training loss: 0.6880121057742775
Validation loss: 2.4226978186412644

Epoch: 6| Step: 11
Training loss: 0.7288590917838402
Validation loss: 2.4139872551616164

Epoch: 6| Step: 12
Training loss: 0.7123634793176141
Validation loss: 2.4005615816438928

Epoch: 6| Step: 13
Training loss: 1.029606521038636
Validation loss: 2.376871748791392

Epoch: 498| Step: 0
Training loss: 0.9373175125532379
Validation loss: 2.4351281604981683

Epoch: 6| Step: 1
Training loss: 0.42341769689444486
Validation loss: 2.439811247084934

Epoch: 6| Step: 2
Training loss: 0.39888366327468305
Validation loss: 2.454219139631928

Epoch: 6| Step: 3
Training loss: 0.7917326514870181
Validation loss: 2.479638618232307

Epoch: 6| Step: 4
Training loss: 0.9909124817662925
Validation loss: 2.457089466271499

Epoch: 6| Step: 5
Training loss: 1.4840040847742668
Validation loss: 2.447790736352205

Epoch: 6| Step: 6
Training loss: 0.6517092194245591
Validation loss: 2.458664140991462

Epoch: 6| Step: 7
Training loss: 0.657706891459964
Validation loss: 2.449659566894405

Epoch: 6| Step: 8
Training loss: 0.7062798189940563
Validation loss: 2.4580869959705844

Epoch: 6| Step: 9
Training loss: 0.8669510596364942
Validation loss: 2.455240542761302

Epoch: 6| Step: 10
Training loss: 0.6210376786167184
Validation loss: 2.458179416569117

Epoch: 6| Step: 11
Training loss: 0.8586146024995486
Validation loss: 2.4685988301393524

Epoch: 6| Step: 12
Training loss: 0.9510872115851587
Validation loss: 2.4764225050254014

Epoch: 6| Step: 13
Training loss: 0.7933085047285334
Validation loss: 2.452703059919687

Epoch: 499| Step: 0
Training loss: 0.855489582522276
Validation loss: 2.462289121601725

Epoch: 6| Step: 1
Training loss: 0.720809473807835
Validation loss: 2.4497571579985085

Epoch: 6| Step: 2
Training loss: 0.654808095235775
Validation loss: 2.4592986776013634

Epoch: 6| Step: 3
Training loss: 0.7981937939801418
Validation loss: 2.461022154482787

Epoch: 6| Step: 4
Training loss: 0.8107843625635084
Validation loss: 2.4663140098746887

Epoch: 6| Step: 5
Training loss: 1.332113134826183
Validation loss: 2.4697452001883287

Epoch: 6| Step: 6
Training loss: 0.9260533894561039
Validation loss: 2.4796079796234323

Epoch: 6| Step: 7
Training loss: 0.893809531303284
Validation loss: 2.453139712183294

Epoch: 6| Step: 8
Training loss: 0.7881131267938933
Validation loss: 2.4229289037306057

Epoch: 6| Step: 9
Training loss: 0.6139586042885322
Validation loss: 2.4342210216337095

Epoch: 6| Step: 10
Training loss: 0.7756837151594667
Validation loss: 2.418846370151562

Epoch: 6| Step: 11
Training loss: 0.7390620628823406
Validation loss: 2.4321812662197524

Epoch: 6| Step: 12
Training loss: 0.7184263827677946
Validation loss: 2.4473867924648234

Epoch: 6| Step: 13
Training loss: 0.8019055916829687
Validation loss: 2.4417083965418644

Epoch: 500| Step: 0
Training loss: 0.7482262538247968
Validation loss: 2.444841947876107

Epoch: 6| Step: 1
Training loss: 0.6247291216359281
Validation loss: 2.443755493543942

Epoch: 6| Step: 2
Training loss: 0.8326530819269071
Validation loss: 2.459888033555228

Epoch: 6| Step: 3
Training loss: 0.44819770542410237
Validation loss: 2.457773817227463

Epoch: 6| Step: 4
Training loss: 0.8530144169160412
Validation loss: 2.4726728843024857

Epoch: 6| Step: 5
Training loss: 0.92908756549485
Validation loss: 2.4688089555020007

Epoch: 6| Step: 6
Training loss: 0.972149912476326
Validation loss: 2.44750531749962

Epoch: 6| Step: 7
Training loss: 0.7864484639001145
Validation loss: 2.4511576990517496

Epoch: 6| Step: 8
Training loss: 1.3213828448996547
Validation loss: 2.426215491493369

Epoch: 6| Step: 9
Training loss: 0.6319324119060455
Validation loss: 2.396882753388664

Epoch: 6| Step: 10
Training loss: 0.7956140677157247
Validation loss: 2.382592588457714

Epoch: 6| Step: 11
Training loss: 0.9158781229046362
Validation loss: 2.432606498163334

Epoch: 6| Step: 12
Training loss: 0.7352911733119581
Validation loss: 2.4076305456858416

Epoch: 6| Step: 13
Training loss: 0.640331387108634
Validation loss: 2.4123763897603343

Testing loss: 2.3361369977381887
