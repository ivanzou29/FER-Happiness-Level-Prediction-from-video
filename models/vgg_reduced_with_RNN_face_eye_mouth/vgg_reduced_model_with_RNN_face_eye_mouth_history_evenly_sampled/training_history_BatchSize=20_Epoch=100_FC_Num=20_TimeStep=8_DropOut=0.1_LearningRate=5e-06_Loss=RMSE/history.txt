Epoch: 1| Step: 0
Training loss: 5.231369750043474
Validation loss: 5.8410113431287245

Epoch: 5| Step: 1
Training loss: 6.2892338510236145
Validation loss: 5.836431801365722

Epoch: 5| Step: 2
Training loss: 4.777321791266991
Validation loss: 5.8320103541175285

Epoch: 5| Step: 3
Training loss: 6.021958541884508
Validation loss: 5.82744536912482

Epoch: 5| Step: 4
Training loss: 5.507117954047293
Validation loss: 5.822981951505328

Epoch: 5| Step: 5
Training loss: 6.68829854315309
Validation loss: 5.81876301120351

Epoch: 5| Step: 6
Training loss: 6.791643887659109
Validation loss: 5.813935064651477

Epoch: 5| Step: 7
Training loss: 5.479988800371518
Validation loss: 5.809765801929226

Epoch: 5| Step: 8
Training loss: 5.727316521811557
Validation loss: 5.804863749267226

Epoch: 5| Step: 9
Training loss: 5.473979607518672
Validation loss: 5.8003988697436375

Epoch: 5| Step: 10
Training loss: 6.084952709355896
Validation loss: 5.7952087040041755

Epoch: 2| Step: 0
Training loss: 5.044173991216214
Validation loss: 5.790392428819577

Epoch: 5| Step: 1
Training loss: 4.966585467568744
Validation loss: 5.785031874902974

Epoch: 5| Step: 2
Training loss: 5.99983151517184
Validation loss: 5.779600034474411

Epoch: 5| Step: 3
Training loss: 5.0851189442454565
Validation loss: 5.773881068860115

Epoch: 5| Step: 4
Training loss: 6.016437267604436
Validation loss: 5.767807417711179

Epoch: 5| Step: 5
Training loss: 5.764713204918432
Validation loss: 5.761502353782158

Epoch: 5| Step: 6
Training loss: 5.838189238348109
Validation loss: 5.754192879840997

Epoch: 5| Step: 7
Training loss: 6.309024874007063
Validation loss: 5.747201646125288

Epoch: 5| Step: 8
Training loss: 6.60570956557629
Validation loss: 5.739699866264591

Epoch: 5| Step: 9
Training loss: 6.130996882417801
Validation loss: 5.731728892512949

Epoch: 5| Step: 10
Training loss: 5.688313520329765
Validation loss: 5.72303445880728

Epoch: 3| Step: 0
Training loss: 6.697059145347984
Validation loss: 5.714874046117025

Epoch: 5| Step: 1
Training loss: 5.790337755435471
Validation loss: 5.70589633685768

Epoch: 5| Step: 2
Training loss: 5.467110524340217
Validation loss: 5.695957203333153

Epoch: 5| Step: 3
Training loss: 5.482614435688054
Validation loss: 5.6858633040007

Epoch: 5| Step: 4
Training loss: 6.289560466504508
Validation loss: 5.675609034197723

Epoch: 5| Step: 5
Training loss: 5.49586296545933
Validation loss: 5.664202890434884

Epoch: 5| Step: 6
Training loss: 5.988996588674947
Validation loss: 5.652990966532853

Epoch: 5| Step: 7
Training loss: 4.599891760838051
Validation loss: 5.641158658322456

Epoch: 5| Step: 8
Training loss: 6.1102800016036944
Validation loss: 5.628935482017018

Epoch: 5| Step: 9
Training loss: 4.241670411913304
Validation loss: 5.615573271680704

Epoch: 5| Step: 10
Training loss: 6.149425150979561
Validation loss: 5.601358881018854

Epoch: 4| Step: 0
Training loss: 5.803406852652338
Validation loss: 5.588100970312491

Epoch: 5| Step: 1
Training loss: 5.3191814816879335
Validation loss: 5.573270146596162

Epoch: 5| Step: 2
Training loss: 5.710601838524053
Validation loss: 5.557455413722024

Epoch: 5| Step: 3
Training loss: 5.440912337934861
Validation loss: 5.542058472711514

Epoch: 5| Step: 4
Training loss: 5.606892751126227
Validation loss: 5.524756469021728

Epoch: 5| Step: 5
Training loss: 6.155372518365054
Validation loss: 5.508697810513247

Epoch: 5| Step: 6
Training loss: 6.195350059982298
Validation loss: 5.489431491166916

Epoch: 5| Step: 7
Training loss: 4.987656424992557
Validation loss: 5.469067474853869

Epoch: 5| Step: 8
Training loss: 4.544233570838749
Validation loss: 5.450553280338453

Epoch: 5| Step: 9
Training loss: 5.53981002261539
Validation loss: 5.431404783319242

Epoch: 5| Step: 10
Training loss: 5.460989715806784
Validation loss: 5.41030156294432

Epoch: 5| Step: 0
Training loss: 5.727405106196722
Validation loss: 5.389151948223192

Epoch: 5| Step: 1
Training loss: 6.128446893636674
Validation loss: 5.3665515488084194

Epoch: 5| Step: 2
Training loss: 5.584125102065459
Validation loss: 5.343709490126637

Epoch: 5| Step: 3
Training loss: 5.48209257533258
Validation loss: 5.321731223787316

Epoch: 5| Step: 4
Training loss: 5.125288234141786
Validation loss: 5.297785400110563

Epoch: 5| Step: 5
Training loss: 5.65983510077104
Validation loss: 5.272602891099466

Epoch: 5| Step: 6
Training loss: 4.856047346484466
Validation loss: 5.248345455675577

Epoch: 5| Step: 7
Training loss: 4.43034731947912
Validation loss: 5.22387685172287

Epoch: 5| Step: 8
Training loss: 4.733364488382741
Validation loss: 5.199221175962359

Epoch: 5| Step: 9
Training loss: 5.907173205686661
Validation loss: 5.175479069481335

Epoch: 5| Step: 10
Training loss: 4.48479563371852
Validation loss: 5.1502100417332635

Epoch: 6| Step: 0
Training loss: 5.3079762664586285
Validation loss: 5.126791772134571

Epoch: 5| Step: 1
Training loss: 4.984691454369435
Validation loss: 5.102792799655589

Epoch: 5| Step: 2
Training loss: 5.007152210333364
Validation loss: 5.078276177136727

Epoch: 5| Step: 3
Training loss: 3.8429472790649695
Validation loss: 5.0553710787699035

Epoch: 5| Step: 4
Training loss: 5.868883560822133
Validation loss: 5.031316423649629

Epoch: 5| Step: 5
Training loss: 6.4733354468821815
Validation loss: 5.009571190947114

Epoch: 5| Step: 6
Training loss: 4.596601366810724
Validation loss: 4.985683270882719

Epoch: 5| Step: 7
Training loss: 4.615843911425996
Validation loss: 4.963949625251066

Epoch: 5| Step: 8
Training loss: 4.3384010808117175
Validation loss: 4.941168528573966

Epoch: 5| Step: 9
Training loss: 5.51844883893025
Validation loss: 4.918288730681481

Epoch: 5| Step: 10
Training loss: 4.654160818143543
Validation loss: 4.897699518892494

Epoch: 7| Step: 0
Training loss: 5.420878293991803
Validation loss: 4.875973274335315

Epoch: 5| Step: 1
Training loss: 4.4376089593109525
Validation loss: 4.852773031232142

Epoch: 5| Step: 2
Training loss: 4.600382059236209
Validation loss: 4.83103769896625

Epoch: 5| Step: 3
Training loss: 4.43584443492218
Validation loss: 4.811595276095609

Epoch: 5| Step: 4
Training loss: 5.133168851190654
Validation loss: 4.791817003685433

Epoch: 5| Step: 5
Training loss: 5.033811687113292
Validation loss: 4.771322856198538

Epoch: 5| Step: 6
Training loss: 4.104926773143001
Validation loss: 4.753450769079667

Epoch: 5| Step: 7
Training loss: 5.471407348238781
Validation loss: 4.735447259707613

Epoch: 5| Step: 8
Training loss: 4.523992580161515
Validation loss: 4.7183573428469865

Epoch: 5| Step: 9
Training loss: 4.793859074233242
Validation loss: 4.700523979897927

Epoch: 5| Step: 10
Training loss: 5.259792640863129
Validation loss: 4.682879168106534

Epoch: 8| Step: 0
Training loss: 5.6254863952575285
Validation loss: 4.664943730063598

Epoch: 5| Step: 1
Training loss: 5.023482872741729
Validation loss: 4.648178976633709

Epoch: 5| Step: 2
Training loss: 3.85926787810754
Validation loss: 4.632221208469128

Epoch: 5| Step: 3
Training loss: 5.0336584167257925
Validation loss: 4.615642047919775

Epoch: 5| Step: 4
Training loss: 4.853500888118975
Validation loss: 4.600731242796251

Epoch: 5| Step: 5
Training loss: 5.132381798543966
Validation loss: 4.5842006090268494

Epoch: 5| Step: 6
Training loss: 4.388911337064053
Validation loss: 4.56911846921952

Epoch: 5| Step: 7
Training loss: 4.205504470664988
Validation loss: 4.5550893581208145

Epoch: 5| Step: 8
Training loss: 4.956217958363581
Validation loss: 4.542704467123175

Epoch: 5| Step: 9
Training loss: 3.7575130224351225
Validation loss: 4.530849958787096

Epoch: 5| Step: 10
Training loss: 4.256007940772544
Validation loss: 4.515040337688496

Epoch: 9| Step: 0
Training loss: 5.888459715809137
Validation loss: 4.502611095495469

Epoch: 5| Step: 1
Training loss: 4.749456073336579
Validation loss: 4.487062486790753

Epoch: 5| Step: 2
Training loss: 5.187331782911228
Validation loss: 4.473243989940016

Epoch: 5| Step: 3
Training loss: 4.54947003642234
Validation loss: 4.459976952892991

Epoch: 5| Step: 4
Training loss: 3.412039360284458
Validation loss: 4.445559851765566

Epoch: 5| Step: 5
Training loss: 4.3410108972855115
Validation loss: 4.4334995447872725

Epoch: 5| Step: 6
Training loss: 4.800153475533035
Validation loss: 4.421803847402521

Epoch: 5| Step: 7
Training loss: 3.7379706402192503
Validation loss: 4.409883393826795

Epoch: 5| Step: 8
Training loss: 3.50208846860952
Validation loss: 4.396260034616761

Epoch: 5| Step: 9
Training loss: 4.534247939092981
Validation loss: 4.387173275579151

Epoch: 5| Step: 10
Training loss: 4.731282347715954
Validation loss: 4.3734933769866124

Epoch: 10| Step: 0
Training loss: 4.650082798702625
Validation loss: 4.360284188350661

Epoch: 5| Step: 1
Training loss: 2.6654343638613534
Validation loss: 4.346807756773236

Epoch: 5| Step: 2
Training loss: 5.092660611915377
Validation loss: 4.3332961501300264

Epoch: 5| Step: 3
Training loss: 3.9588162311666397
Validation loss: 4.319504347380571

Epoch: 5| Step: 4
Training loss: 4.302510065646591
Validation loss: 4.308376338714985

Epoch: 5| Step: 5
Training loss: 4.236184947442161
Validation loss: 4.296932471702956

Epoch: 5| Step: 6
Training loss: 4.724405499554282
Validation loss: 4.283667600132166

Epoch: 5| Step: 7
Training loss: 5.123626897207398
Validation loss: 4.272970280939115

Epoch: 5| Step: 8
Training loss: 3.656651010285634
Validation loss: 4.259877278034747

Epoch: 5| Step: 9
Training loss: 4.1429901853348925
Validation loss: 4.24734660712401

Epoch: 5| Step: 10
Training loss: 5.450885301832214
Validation loss: 4.238419666679204

Epoch: 11| Step: 0
Training loss: 3.7929160745972204
Validation loss: 4.2248198128388035

Epoch: 5| Step: 1
Training loss: 4.747894422750464
Validation loss: 4.21369013490584

Epoch: 5| Step: 2
Training loss: 3.6143955471425113
Validation loss: 4.203555817762128

Epoch: 5| Step: 3
Training loss: 4.097671145111155
Validation loss: 4.190708406101987

Epoch: 5| Step: 4
Training loss: 4.040412839436824
Validation loss: 4.182163183478413

Epoch: 5| Step: 5
Training loss: 4.927879521866505
Validation loss: 4.168532717013364

Epoch: 5| Step: 6
Training loss: 5.162524295777424
Validation loss: 4.159469969545946

Epoch: 5| Step: 7
Training loss: 3.451142307191534
Validation loss: 4.145988073546345

Epoch: 5| Step: 8
Training loss: 4.41825929153511
Validation loss: 4.133514461921751

Epoch: 5| Step: 9
Training loss: 4.445279246978548
Validation loss: 4.125313936768659

Epoch: 5| Step: 10
Training loss: 4.23338120400904
Validation loss: 4.113095171738444

Epoch: 12| Step: 0
Training loss: 3.3441333016287644
Validation loss: 4.102626208903808

Epoch: 5| Step: 1
Training loss: 3.4331330737871992
Validation loss: 4.091761944453067

Epoch: 5| Step: 2
Training loss: 4.261756344357556
Validation loss: 4.079557134748128

Epoch: 5| Step: 3
Training loss: 3.993580793399047
Validation loss: 4.067966077339115

Epoch: 5| Step: 4
Training loss: 5.087943857686974
Validation loss: 4.059458635546294

Epoch: 5| Step: 5
Training loss: 3.9918919881301225
Validation loss: 4.04562797976129

Epoch: 5| Step: 6
Training loss: 4.515118738854179
Validation loss: 4.034466811308841

Epoch: 5| Step: 7
Training loss: 3.9728845401312465
Validation loss: 4.023850657293458

Epoch: 5| Step: 8
Training loss: 3.46375210153825
Validation loss: 4.011177210560061

Epoch: 5| Step: 9
Training loss: 5.052081277853427
Validation loss: 3.997921737040717

Epoch: 5| Step: 10
Training loss: 4.528733179333347
Validation loss: 3.9876442397780894

Epoch: 13| Step: 0
Training loss: 3.917691617465329
Validation loss: 3.9737799533782314

Epoch: 5| Step: 1
Training loss: 4.059431589861279
Validation loss: 3.960396766503636

Epoch: 5| Step: 2
Training loss: 4.117296365822319
Validation loss: 3.9505202916868973

Epoch: 5| Step: 3
Training loss: 4.447549535294293
Validation loss: 3.9355880384613866

Epoch: 5| Step: 4
Training loss: 4.731560906256956
Validation loss: 3.9242839891944676

Epoch: 5| Step: 5
Training loss: 3.6877097377289894
Validation loss: 3.9109942155937354

Epoch: 5| Step: 6
Training loss: 3.2901425434527596
Validation loss: 3.897284375658797

Epoch: 5| Step: 7
Training loss: 4.471364356954875
Validation loss: 3.8843846401942104

Epoch: 5| Step: 8
Training loss: 4.12057026073839
Validation loss: 3.873503926453027

Epoch: 5| Step: 9
Training loss: 3.6096828048711185
Validation loss: 3.8606434571309465

Epoch: 5| Step: 10
Training loss: 4.0702490041982395
Validation loss: 3.848635262478399

Epoch: 14| Step: 0
Training loss: 3.5076629674768074
Validation loss: 3.8389009866397763

Epoch: 5| Step: 1
Training loss: 4.287801143647049
Validation loss: 3.826150635067146

Epoch: 5| Step: 2
Training loss: 4.020635306797132
Validation loss: 3.8158096964170545

Epoch: 5| Step: 3
Training loss: 4.511147572746396
Validation loss: 3.8068891781370953

Epoch: 5| Step: 4
Training loss: 4.470584946149909
Validation loss: 3.793779745588595

Epoch: 5| Step: 5
Training loss: 4.0985182154651945
Validation loss: 3.7876280789044507

Epoch: 5| Step: 6
Training loss: 2.632842021289888
Validation loss: 3.775041272718

Epoch: 5| Step: 7
Training loss: 4.233577413856538
Validation loss: 3.7697806381521577

Epoch: 5| Step: 8
Training loss: 3.4034846568551242
Validation loss: 3.7558343436734027

Epoch: 5| Step: 9
Training loss: 4.3514364830412475
Validation loss: 3.7495469937450516

Epoch: 5| Step: 10
Training loss: 3.5581456393218365
Validation loss: 3.742621989407085

Epoch: 15| Step: 0
Training loss: 4.282480995683875
Validation loss: 3.7344505785361854

Epoch: 5| Step: 1
Training loss: 4.301617810399148
Validation loss: 3.7242207293662415

Epoch: 5| Step: 2
Training loss: 4.725851210361535
Validation loss: 3.7172951710472986

Epoch: 5| Step: 3
Training loss: 4.18302587364634
Validation loss: 3.7129483340576557

Epoch: 5| Step: 4
Training loss: 3.9265981251337285
Validation loss: 3.7034739107595516

Epoch: 5| Step: 5
Training loss: 2.5259215231308403
Validation loss: 3.695045953970751

Epoch: 5| Step: 6
Training loss: 3.6913425662082724
Validation loss: 3.6889299165147746

Epoch: 5| Step: 7
Training loss: 4.238108885463991
Validation loss: 3.680821907702725

Epoch: 5| Step: 8
Training loss: 3.5868939888068168
Validation loss: 3.6742582491607436

Epoch: 5| Step: 9
Training loss: 3.0412094260259717
Validation loss: 3.6665243324404546

Epoch: 5| Step: 10
Training loss: 3.640395521536452
Validation loss: 3.6588881960662056

Epoch: 16| Step: 0
Training loss: 3.648393977883815
Validation loss: 3.6525685108116264

Epoch: 5| Step: 1
Training loss: 3.1559096048944646
Validation loss: 3.6458905971735365

Epoch: 5| Step: 2
Training loss: 3.942769959277643
Validation loss: 3.639966696503794

Epoch: 5| Step: 3
Training loss: 2.880963650125549
Validation loss: 3.6322276727580136

Epoch: 5| Step: 4
Training loss: 4.145115903699502
Validation loss: 3.6279183770007593

Epoch: 5| Step: 5
Training loss: 3.1925377024886523
Validation loss: 3.6230124617850725

Epoch: 5| Step: 6
Training loss: 4.046883247985683
Validation loss: 3.617276031715509

Epoch: 5| Step: 7
Training loss: 4.554176995538212
Validation loss: 3.613247227662405

Epoch: 5| Step: 8
Training loss: 4.018198576452474
Validation loss: 3.606899522554467

Epoch: 5| Step: 9
Training loss: 4.255236821291318
Validation loss: 3.600615660801177

Epoch: 5| Step: 10
Training loss: 3.762350597773797
Validation loss: 3.594098170295949

Epoch: 17| Step: 0
Training loss: 3.185596870296671
Validation loss: 3.5912581526930576

Epoch: 5| Step: 1
Training loss: 3.785673218373265
Validation loss: 3.5868071172929934

Epoch: 5| Step: 2
Training loss: 3.460598276705815
Validation loss: 3.5805757165807917

Epoch: 5| Step: 3
Training loss: 2.999615008764569
Validation loss: 3.575361972723694

Epoch: 5| Step: 4
Training loss: 4.066562675230415
Validation loss: 3.571417368242825

Epoch: 5| Step: 5
Training loss: 4.039814921379323
Validation loss: 3.5688735583644355

Epoch: 5| Step: 6
Training loss: 3.436103398375994
Validation loss: 3.5668703382951747

Epoch: 5| Step: 7
Training loss: 4.5555435867979375
Validation loss: 3.569412676333338

Epoch: 5| Step: 8
Training loss: 4.020186034495558
Validation loss: 3.5561186150652273

Epoch: 5| Step: 9
Training loss: 3.485294101077885
Validation loss: 3.5552200201575266

Epoch: 5| Step: 10
Training loss: 4.177095611376646
Validation loss: 3.5520133547875044

Epoch: 18| Step: 0
Training loss: 4.071593216743519
Validation loss: 3.5499699359939716

Epoch: 5| Step: 1
Training loss: 3.1510787751505975
Validation loss: 3.5476182783399697

Epoch: 5| Step: 2
Training loss: 3.226260265761149
Validation loss: 3.5421835496236675

Epoch: 5| Step: 3
Training loss: 3.927580676303425
Validation loss: 3.539497890364721

Epoch: 5| Step: 4
Training loss: 4.046068972879822
Validation loss: 3.5355316885546184

Epoch: 5| Step: 5
Training loss: 3.5737712642521395
Validation loss: 3.533951650317119

Epoch: 5| Step: 6
Training loss: 3.5030241571454277
Validation loss: 3.5307853568003638

Epoch: 5| Step: 7
Training loss: 3.7976071001210285
Validation loss: 3.5282820806044093

Epoch: 5| Step: 8
Training loss: 4.323072217724127
Validation loss: 3.5256435032371227

Epoch: 5| Step: 9
Training loss: 3.427808381501651
Validation loss: 3.522515891655791

Epoch: 5| Step: 10
Training loss: 3.949149564142673
Validation loss: 3.5188735927094505

Epoch: 19| Step: 0
Training loss: 4.238805726117281
Validation loss: 3.516623687909188

Epoch: 5| Step: 1
Training loss: 3.5967996677228835
Validation loss: 3.5146083573237448

Epoch: 5| Step: 2
Training loss: 3.815321831683572
Validation loss: 3.5130568022321653

Epoch: 5| Step: 3
Training loss: 3.9939357565124203
Validation loss: 3.5107015676278017

Epoch: 5| Step: 4
Training loss: 4.3678862365887285
Validation loss: 3.5079322544370606

Epoch: 5| Step: 5
Training loss: 2.7368447621328764
Validation loss: 3.5039308465965524

Epoch: 5| Step: 6
Training loss: 4.338561327806904
Validation loss: 3.503795509766455

Epoch: 5| Step: 7
Training loss: 3.3529109776320905
Validation loss: 3.500543506747348

Epoch: 5| Step: 8
Training loss: 3.181486103761916
Validation loss: 3.497431731295429

Epoch: 5| Step: 9
Training loss: 3.0317970647410526
Validation loss: 3.49728145584443

Epoch: 5| Step: 10
Training loss: 3.838389186168415
Validation loss: 3.4949084338322614

Epoch: 20| Step: 0
Training loss: 3.5845032194263857
Validation loss: 3.49264400273651

Epoch: 5| Step: 1
Training loss: 4.270354056409122
Validation loss: 3.4934373819226225

Epoch: 5| Step: 2
Training loss: 3.211873829892063
Validation loss: 3.4915581825956923

Epoch: 5| Step: 3
Training loss: 4.700920526166653
Validation loss: 3.4889896236109217

Epoch: 5| Step: 4
Training loss: 4.491473915809973
Validation loss: 3.487152252402147

Epoch: 5| Step: 5
Training loss: 3.9448432869963237
Validation loss: 3.4857963415874145

Epoch: 5| Step: 6
Training loss: 2.825198350542784
Validation loss: 3.4848604258222826

Epoch: 5| Step: 7
Training loss: 3.3151623085758786
Validation loss: 3.483526490650535

Epoch: 5| Step: 8
Training loss: 3.348039816534168
Validation loss: 3.4840694311712963

Epoch: 5| Step: 9
Training loss: 3.8804601532126815
Validation loss: 3.483534109016266

Epoch: 5| Step: 10
Training loss: 2.205368739153334
Validation loss: 3.4781682394089444

Epoch: 21| Step: 0
Training loss: 3.2329773762669762
Validation loss: 3.4799427161466054

Epoch: 5| Step: 1
Training loss: 4.643202557133629
Validation loss: 3.4816630598792058

Epoch: 5| Step: 2
Training loss: 3.8478499465442524
Validation loss: 3.477678862234639

Epoch: 5| Step: 3
Training loss: 3.588719304988898
Validation loss: 3.474335976384469

Epoch: 5| Step: 4
Training loss: 4.117828145573174
Validation loss: 3.473377374334366

Epoch: 5| Step: 5
Training loss: 3.757607690380885
Validation loss: 3.472757005971056

Epoch: 5| Step: 6
Training loss: 3.5189087853931356
Validation loss: 3.4702735813409658

Epoch: 5| Step: 7
Training loss: 3.793009733220271
Validation loss: 3.4714232474822904

Epoch: 5| Step: 8
Training loss: 3.5023960358943613
Validation loss: 3.4697928700786234

Epoch: 5| Step: 9
Training loss: 3.1650607571186438
Validation loss: 3.4679946941799686

Epoch: 5| Step: 10
Training loss: 3.0306399016545957
Validation loss: 3.4677620363714126

Epoch: 22| Step: 0
Training loss: 3.492818958788106
Validation loss: 3.465401033975272

Epoch: 5| Step: 1
Training loss: 3.3315267594619784
Validation loss: 3.4631433722234646

Epoch: 5| Step: 2
Training loss: 3.7517343960758645
Validation loss: 3.463621404733671

Epoch: 5| Step: 3
Training loss: 3.1615791276775607
Validation loss: 3.461496340114376

Epoch: 5| Step: 4
Training loss: 3.9622888310238746
Validation loss: 3.460426275957551

Epoch: 5| Step: 5
Training loss: 3.2091635748617935
Validation loss: 3.4585439991207787

Epoch: 5| Step: 6
Training loss: 4.412794515058333
Validation loss: 3.457151961126652

Epoch: 5| Step: 7
Training loss: 3.701225340766531
Validation loss: 3.454419538317147

Epoch: 5| Step: 8
Training loss: 3.524064577045727
Validation loss: 3.452423379296803

Epoch: 5| Step: 9
Training loss: 3.8387714180928008
Validation loss: 3.447875292759375

Epoch: 5| Step: 10
Training loss: 3.8898661536011914
Validation loss: 3.447373505074769

Epoch: 23| Step: 0
Training loss: 3.453220417896552
Validation loss: 3.4517053564526226

Epoch: 5| Step: 1
Training loss: 3.7006720937713027
Validation loss: 3.451333707539426

Epoch: 5| Step: 2
Training loss: 3.5446911781424455
Validation loss: 3.445906153890243

Epoch: 5| Step: 3
Training loss: 4.200214725636664
Validation loss: 3.4419694052623515

Epoch: 5| Step: 4
Training loss: 3.7107187949533076
Validation loss: 3.441230062747154

Epoch: 5| Step: 5
Training loss: 3.861323926322325
Validation loss: 3.4404610895225467

Epoch: 5| Step: 6
Training loss: 3.1256488889297334
Validation loss: 3.440964579601752

Epoch: 5| Step: 7
Training loss: 3.300215777654114
Validation loss: 3.440044552380271

Epoch: 5| Step: 8
Training loss: 4.2143427681005035
Validation loss: 3.439090468958206

Epoch: 5| Step: 9
Training loss: 3.7969865193884966
Validation loss: 3.4400807035265375

Epoch: 5| Step: 10
Training loss: 3.1265194060154826
Validation loss: 3.441579545462348

Epoch: 24| Step: 0
Training loss: 3.970848429845644
Validation loss: 3.441822949335574

Epoch: 5| Step: 1
Training loss: 3.460829756805558
Validation loss: 3.4340759645795367

Epoch: 5| Step: 2
Training loss: 3.7000426006442186
Validation loss: 3.4333508954513436

Epoch: 5| Step: 3
Training loss: 3.9185312310439726
Validation loss: 3.431675826275536

Epoch: 5| Step: 4
Training loss: 2.980080595526732
Validation loss: 3.4351497980032333

Epoch: 5| Step: 5
Training loss: 3.498772814731823
Validation loss: 3.4313371738365874

Epoch: 5| Step: 6
Training loss: 3.651198067718583
Validation loss: 3.4292907328369635

Epoch: 5| Step: 7
Training loss: 3.968402757246999
Validation loss: 3.4303549243898406

Epoch: 5| Step: 8
Training loss: 3.3813425442763703
Validation loss: 3.427566004106418

Epoch: 5| Step: 9
Training loss: 4.47511616987612
Validation loss: 3.428534563693953

Epoch: 5| Step: 10
Training loss: 2.7475759920227314
Validation loss: 3.4288522166305113

Epoch: 25| Step: 0
Training loss: 3.0786635803905473
Validation loss: 3.4286983223145375

Epoch: 5| Step: 1
Training loss: 2.903581932744646
Validation loss: 3.427036426586112

Epoch: 5| Step: 2
Training loss: 4.013981226673331
Validation loss: 3.426385726166964

Epoch: 5| Step: 3
Training loss: 3.3968339315702485
Validation loss: 3.4255929107198493

Epoch: 5| Step: 4
Training loss: 3.706330790933768
Validation loss: 3.423413443144212

Epoch: 5| Step: 5
Training loss: 4.266232625421284
Validation loss: 3.422979198709956

Epoch: 5| Step: 6
Training loss: 4.129567940489909
Validation loss: 3.4203796145979584

Epoch: 5| Step: 7
Training loss: 3.0277000168391472
Validation loss: 3.420535876814466

Epoch: 5| Step: 8
Training loss: 3.7770525120808305
Validation loss: 3.4194864636927034

Epoch: 5| Step: 9
Training loss: 3.6701913423057038
Validation loss: 3.420341487836205

Epoch: 5| Step: 10
Training loss: 3.8673616004055034
Validation loss: 3.4190302196218925

Epoch: 26| Step: 0
Training loss: 3.5003149708304155
Validation loss: 3.4190232140918275

Epoch: 5| Step: 1
Training loss: 4.299470540651679
Validation loss: 3.4177865134790033

Epoch: 5| Step: 2
Training loss: 4.02898846258167
Validation loss: 3.4182629024190994

Epoch: 5| Step: 3
Training loss: 3.2001863723364594
Validation loss: 3.4163103470583143

Epoch: 5| Step: 4
Training loss: 3.5865016651370403
Validation loss: 3.417355464732454

Epoch: 5| Step: 5
Training loss: 3.1848393724021515
Validation loss: 3.415640621155023

Epoch: 5| Step: 6
Training loss: 4.046326824751688
Validation loss: 3.4152352275564586

Epoch: 5| Step: 7
Training loss: 3.175349545198433
Validation loss: 3.4157805315389576

Epoch: 5| Step: 8
Training loss: 3.347739148532366
Validation loss: 3.4145377559921424

Epoch: 5| Step: 9
Training loss: 3.9222222284659822
Validation loss: 3.413621157903295

Epoch: 5| Step: 10
Training loss: 3.532158118764242
Validation loss: 3.411559227969496

Epoch: 27| Step: 0
Training loss: 3.542242983134062
Validation loss: 3.4100145691749955

Epoch: 5| Step: 1
Training loss: 3.2523784737310573
Validation loss: 3.4097386197365016

Epoch: 5| Step: 2
Training loss: 3.0747485546490476
Validation loss: 3.411919762576685

Epoch: 5| Step: 3
Training loss: 3.394167969538976
Validation loss: 3.4112607737003997

Epoch: 5| Step: 4
Training loss: 4.3449626300289
Validation loss: 3.4090591607552967

Epoch: 5| Step: 5
Training loss: 3.9609978123875265
Validation loss: 3.4093531156293055

Epoch: 5| Step: 6
Training loss: 2.9941028809081365
Validation loss: 3.40984176863814

Epoch: 5| Step: 7
Training loss: 3.38381851425675
Validation loss: 3.409328699939093

Epoch: 5| Step: 8
Training loss: 3.8457429262874987
Validation loss: 3.4083414331945607

Epoch: 5| Step: 9
Training loss: 4.2736372264656035
Validation loss: 3.4080595741795023

Epoch: 5| Step: 10
Training loss: 3.649678642026374
Validation loss: 3.406481011467132

Epoch: 28| Step: 0
Training loss: 3.2752004896922973
Validation loss: 3.406503143944099

Epoch: 5| Step: 1
Training loss: 3.651159410668652
Validation loss: 3.405815468593833

Epoch: 5| Step: 2
Training loss: 3.4572751061591798
Validation loss: 3.4046460240204124

Epoch: 5| Step: 3
Training loss: 3.8323364758427343
Validation loss: 3.4041213110443964

Epoch: 5| Step: 4
Training loss: 3.51426093871436
Validation loss: 3.405297806982204

Epoch: 5| Step: 5
Training loss: 4.168253837924587
Validation loss: 3.4026308833422565

Epoch: 5| Step: 6
Training loss: 3.1945259599835447
Validation loss: 3.4032829859465927

Epoch: 5| Step: 7
Training loss: 3.6980138345050078
Validation loss: 3.403834728212111

Epoch: 5| Step: 8
Training loss: 3.085266812995765
Validation loss: 3.402699226196549

Epoch: 5| Step: 9
Training loss: 3.6088196958940943
Validation loss: 3.4016037428638075

Epoch: 5| Step: 10
Training loss: 4.360435876319492
Validation loss: 3.401475951981333

Epoch: 29| Step: 0
Training loss: 3.243765352833895
Validation loss: 3.401126457933425

Epoch: 5| Step: 1
Training loss: 2.999209299790562
Validation loss: 3.4025795608815503

Epoch: 5| Step: 2
Training loss: 3.0186208756594124
Validation loss: 3.40427929852853

Epoch: 5| Step: 3
Training loss: 3.3634669732221325
Validation loss: 3.4074059028782178

Epoch: 5| Step: 4
Training loss: 4.066678759030567
Validation loss: 3.403577661134809

Epoch: 5| Step: 5
Training loss: 3.378613550815902
Validation loss: 3.4053459025081563

Epoch: 5| Step: 6
Training loss: 3.8445184451228918
Validation loss: 3.399691863456441

Epoch: 5| Step: 7
Training loss: 3.843522972287401
Validation loss: 3.401752514410342

Epoch: 5| Step: 8
Training loss: 3.7590525399260923
Validation loss: 3.3980381341660966

Epoch: 5| Step: 9
Training loss: 4.289873557194752
Validation loss: 3.3986143065011416

Epoch: 5| Step: 10
Training loss: 3.8600179159904915
Validation loss: 3.397350376814425

Epoch: 30| Step: 0
Training loss: 3.0898284718826607
Validation loss: 3.3971215985349636

Epoch: 5| Step: 1
Training loss: 3.6763938855416387
Validation loss: 3.396102878470505

Epoch: 5| Step: 2
Training loss: 3.330943315713667
Validation loss: 3.3971042083167156

Epoch: 5| Step: 3
Training loss: 3.754952149067238
Validation loss: 3.3966735946774778

Epoch: 5| Step: 4
Training loss: 3.7321793873186184
Validation loss: 3.3959701684655905

Epoch: 5| Step: 5
Training loss: 3.9752972281790657
Validation loss: 3.3952338220903653

Epoch: 5| Step: 6
Training loss: 3.8152549670450613
Validation loss: 3.3931947778995597

Epoch: 5| Step: 7
Training loss: 4.131886831072463
Validation loss: 3.394766170240821

Epoch: 5| Step: 8
Training loss: 3.1519595151905726
Validation loss: 3.3957063334230804

Epoch: 5| Step: 9
Training loss: 3.187824606728953
Validation loss: 3.3936162495866498

Epoch: 5| Step: 10
Training loss: 3.8709703227516514
Validation loss: 3.394845954993006

Epoch: 31| Step: 0
Training loss: 4.326843071874451
Validation loss: 3.3938296972674533

Epoch: 5| Step: 1
Training loss: 2.9679921036072847
Validation loss: 3.3952825509654505

Epoch: 5| Step: 2
Training loss: 3.330004237633377
Validation loss: 3.3917385446741117

Epoch: 5| Step: 3
Training loss: 3.5581057032750882
Validation loss: 3.39211210073336

Epoch: 5| Step: 4
Training loss: 3.445689347259823
Validation loss: 3.3941460610179686

Epoch: 5| Step: 5
Training loss: 3.6168647770451257
Validation loss: 3.3928879668218586

Epoch: 5| Step: 6
Training loss: 3.4756819735081113
Validation loss: 3.393944483299106

Epoch: 5| Step: 7
Training loss: 3.9036941101197082
Validation loss: 3.3938510473402244

Epoch: 5| Step: 8
Training loss: 4.039297189295096
Validation loss: 3.3930392647979826

Epoch: 5| Step: 9
Training loss: 3.575675159003178
Validation loss: 3.3915572011790114

Epoch: 5| Step: 10
Training loss: 3.387432511561779
Validation loss: 3.3925144478314215

Epoch: 32| Step: 0
Training loss: 3.68331581272659
Validation loss: 3.393562909742882

Epoch: 5| Step: 1
Training loss: 3.2946102806781705
Validation loss: 3.391114895661793

Epoch: 5| Step: 2
Training loss: 3.358757920477685
Validation loss: 3.3886219253256007

Epoch: 5| Step: 3
Training loss: 3.8803237522377145
Validation loss: 3.3883134426873243

Epoch: 5| Step: 4
Training loss: 3.3408381537725154
Validation loss: 3.3877060568287147

Epoch: 5| Step: 5
Training loss: 3.7202592880371994
Validation loss: 3.388069049517683

Epoch: 5| Step: 6
Training loss: 3.307647605825955
Validation loss: 3.386801154141661

Epoch: 5| Step: 7
Training loss: 4.179550368296562
Validation loss: 3.385817705480041

Epoch: 5| Step: 8
Training loss: 3.4940281738472962
Validation loss: 3.386110679855274

Epoch: 5| Step: 9
Training loss: 3.94174498358595
Validation loss: 3.3861123606275036

Epoch: 5| Step: 10
Training loss: 3.43927081186495
Validation loss: 3.385108055013497

Epoch: 33| Step: 0
Training loss: 4.162246623074364
Validation loss: 3.3853911751796293

Epoch: 5| Step: 1
Training loss: 3.7830201096349385
Validation loss: 3.3854752321438943

Epoch: 5| Step: 2
Training loss: 4.042098241881496
Validation loss: 3.384230430146092

Epoch: 5| Step: 3
Training loss: 3.620059362525428
Validation loss: 3.384069259741483

Epoch: 5| Step: 4
Training loss: 3.072522481862467
Validation loss: 3.383594333828587

Epoch: 5| Step: 5
Training loss: 3.5497153584444714
Validation loss: 3.3853507127166664

Epoch: 5| Step: 6
Training loss: 4.161422837559166
Validation loss: 3.3839510220199966

Epoch: 5| Step: 7
Training loss: 3.018928734205144
Validation loss: 3.3828706063520113

Epoch: 5| Step: 8
Training loss: 3.134113602848742
Validation loss: 3.3813066810147103

Epoch: 5| Step: 9
Training loss: 3.630761139573453
Validation loss: 3.3809329441159974

Epoch: 5| Step: 10
Training loss: 3.274816400171769
Validation loss: 3.3821234368941533

Epoch: 34| Step: 0
Training loss: 4.0856312624244495
Validation loss: 3.379943405476566

Epoch: 5| Step: 1
Training loss: 3.8482914589087405
Validation loss: 3.3803757347162326

Epoch: 5| Step: 2
Training loss: 2.914770290949018
Validation loss: 3.379477444349514

Epoch: 5| Step: 3
Training loss: 3.044992344538143
Validation loss: 3.3801243633184987

Epoch: 5| Step: 4
Training loss: 4.419662946735208
Validation loss: 3.3790012099454687

Epoch: 5| Step: 5
Training loss: 3.4292895666249437
Validation loss: 3.379483649616894

Epoch: 5| Step: 6
Training loss: 3.2120691982810547
Validation loss: 3.3784416528500634

Epoch: 5| Step: 7
Training loss: 3.576329209571509
Validation loss: 3.377364262926456

Epoch: 5| Step: 8
Training loss: 3.1704053057702963
Validation loss: 3.377711048478603

Epoch: 5| Step: 9
Training loss: 3.5976551896713964
Validation loss: 3.3787944266144367

Epoch: 5| Step: 10
Training loss: 4.172733290031992
Validation loss: 3.3764971865001834

Epoch: 35| Step: 0
Training loss: 3.384126685447331
Validation loss: 3.3762466531593978

Epoch: 5| Step: 1
Training loss: 3.0286696945042064
Validation loss: 3.3758081982353922

Epoch: 5| Step: 2
Training loss: 3.718847449812975
Validation loss: 3.3768109089563736

Epoch: 5| Step: 3
Training loss: 3.8970970647292567
Validation loss: 3.3759168733822302

Epoch: 5| Step: 4
Training loss: 3.428671579941798
Validation loss: 3.37546324199857

Epoch: 5| Step: 5
Training loss: 3.8813284603425964
Validation loss: 3.3778682888234446

Epoch: 5| Step: 6
Training loss: 3.40935787542782
Validation loss: 3.376568873588498

Epoch: 5| Step: 7
Training loss: 3.7762839754780293
Validation loss: 3.3770558845678984

Epoch: 5| Step: 8
Training loss: 4.143617175060581
Validation loss: 3.374875369062879

Epoch: 5| Step: 9
Training loss: 4.004933652483024
Validation loss: 3.375599193061092

Epoch: 5| Step: 10
Training loss: 2.5784967327885013
Validation loss: 3.373070515109923

Epoch: 36| Step: 0
Training loss: 2.5195976780850593
Validation loss: 3.3747383040523973

Epoch: 5| Step: 1
Training loss: 3.940066757411154
Validation loss: 3.3739750018527723

Epoch: 5| Step: 2
Training loss: 3.6166517219293284
Validation loss: 3.374156448456209

Epoch: 5| Step: 3
Training loss: 3.4535901891216008
Validation loss: 3.3761081630929284

Epoch: 5| Step: 4
Training loss: 3.846120460071914
Validation loss: 3.3809916431180214

Epoch: 5| Step: 5
Training loss: 3.4207913847259
Validation loss: 3.378071760821091

Epoch: 5| Step: 6
Training loss: 3.39143129948924
Validation loss: 3.37294601049355

Epoch: 5| Step: 7
Training loss: 4.064080972420533
Validation loss: 3.371676245141571

Epoch: 5| Step: 8
Training loss: 3.5020376813289364
Validation loss: 3.371791929804884

Epoch: 5| Step: 9
Training loss: 4.106651651140315
Validation loss: 3.3717382158146076

Epoch: 5| Step: 10
Training loss: 3.506193267308887
Validation loss: 3.371143468125318

Epoch: 37| Step: 0
Training loss: 3.078352556676347
Validation loss: 3.37079538477883

Epoch: 5| Step: 1
Training loss: 3.9629898923696394
Validation loss: 3.371257397724098

Epoch: 5| Step: 2
Training loss: 4.355017449642921
Validation loss: 3.3700350509178616

Epoch: 5| Step: 3
Training loss: 3.742303707094443
Validation loss: 3.371607317549033

Epoch: 5| Step: 4
Training loss: 3.6377520706562008
Validation loss: 3.371019146340818

Epoch: 5| Step: 5
Training loss: 3.979130423548882
Validation loss: 3.3701270582998326

Epoch: 5| Step: 6
Training loss: 3.9269144576751285
Validation loss: 3.3716332260096458

Epoch: 5| Step: 7
Training loss: 3.23660584698731
Validation loss: 3.3726904656715706

Epoch: 5| Step: 8
Training loss: 2.904030064818649
Validation loss: 3.3698348244364187

Epoch: 5| Step: 9
Training loss: 3.17605781054791
Validation loss: 3.368191673460982

Epoch: 5| Step: 10
Training loss: 3.2957822606839287
Validation loss: 3.368233065122123

Epoch: 38| Step: 0
Training loss: 3.3964339741174934
Validation loss: 3.3688121540538702

Epoch: 5| Step: 1
Training loss: 3.8433329038021466
Validation loss: 3.3709043082339036

Epoch: 5| Step: 2
Training loss: 3.083133244251153
Validation loss: 3.368577829478221

Epoch: 5| Step: 3
Training loss: 3.9331144099545328
Validation loss: 3.3665739648760247

Epoch: 5| Step: 4
Training loss: 2.9304707611817444
Validation loss: 3.365495793794723

Epoch: 5| Step: 5
Training loss: 3.765980810553089
Validation loss: 3.366401322673619

Epoch: 5| Step: 6
Training loss: 3.6264270735818367
Validation loss: 3.366120608270328

Epoch: 5| Step: 7
Training loss: 4.063890893958406
Validation loss: 3.3672464926729453

Epoch: 5| Step: 8
Training loss: 3.253928964084512
Validation loss: 3.3657878483699624

Epoch: 5| Step: 9
Training loss: 3.846715635938905
Validation loss: 3.3652070277382005

Epoch: 5| Step: 10
Training loss: 3.680463899314889
Validation loss: 3.363098829414841

Epoch: 39| Step: 0
Training loss: 3.041336581639695
Validation loss: 3.3654864807200093

Epoch: 5| Step: 1
Training loss: 3.801089110652896
Validation loss: 3.363690449468108

Epoch: 5| Step: 2
Training loss: 3.5423956326527537
Validation loss: 3.364124513810129

Epoch: 5| Step: 3
Training loss: 2.910457887314394
Validation loss: 3.364934294099551

Epoch: 5| Step: 4
Training loss: 4.042349269418317
Validation loss: 3.3649287019731506

Epoch: 5| Step: 5
Training loss: 3.8902284964011336
Validation loss: 3.3648212780113695

Epoch: 5| Step: 6
Training loss: 3.8396443094982007
Validation loss: 3.362430164072295

Epoch: 5| Step: 7
Training loss: 3.5681757636976976
Validation loss: 3.3632574267446014

Epoch: 5| Step: 8
Training loss: 3.2588322276227983
Validation loss: 3.362969407659226

Epoch: 5| Step: 9
Training loss: 3.9705424428721843
Validation loss: 3.362247813207692

Epoch: 5| Step: 10
Training loss: 3.4846161215793208
Validation loss: 3.362029563516102

Epoch: 40| Step: 0
Training loss: 3.533851677882706
Validation loss: 3.3608046629582127

Epoch: 5| Step: 1
Training loss: 3.584146289130399
Validation loss: 3.3619826235089003

Epoch: 5| Step: 2
Training loss: 3.1002575798080434
Validation loss: 3.3616901407326134

Epoch: 5| Step: 3
Training loss: 3.61528634189082
Validation loss: 3.360583281852126

Epoch: 5| Step: 4
Training loss: 3.5733114456341473
Validation loss: 3.362178811273131

Epoch: 5| Step: 5
Training loss: 3.4085205629838424
Validation loss: 3.3615767776354484

Epoch: 5| Step: 6
Training loss: 3.2777605666949756
Validation loss: 3.364277519871914

Epoch: 5| Step: 7
Training loss: 3.3268645142743476
Validation loss: 3.358287748088836

Epoch: 5| Step: 8
Training loss: 3.4976762141786306
Validation loss: 3.359500744720601

Epoch: 5| Step: 9
Training loss: 4.562249581767518
Validation loss: 3.360030449667259

Epoch: 5| Step: 10
Training loss: 3.8916805934180316
Validation loss: 3.3593657035346056

Epoch: 41| Step: 0
Training loss: 3.8728323995866494
Validation loss: 3.359730285492781

Epoch: 5| Step: 1
Training loss: 3.6772155882021247
Validation loss: 3.3568958793244335

Epoch: 5| Step: 2
Training loss: 4.11997494810321
Validation loss: 3.3578473039404138

Epoch: 5| Step: 3
Training loss: 3.2873002720489777
Validation loss: 3.3595082673684615

Epoch: 5| Step: 4
Training loss: 3.6338170129182377
Validation loss: 3.358041911752295

Epoch: 5| Step: 5
Training loss: 3.8585750353077994
Validation loss: 3.3570655464199537

Epoch: 5| Step: 6
Training loss: 3.2918027213906935
Validation loss: 3.358580331755742

Epoch: 5| Step: 7
Training loss: 3.184926209365995
Validation loss: 3.3573692582185077

Epoch: 5| Step: 8
Training loss: 3.2285795765085528
Validation loss: 3.356198962337176

Epoch: 5| Step: 9
Training loss: 4.077491214071475
Validation loss: 3.358287490067298

Epoch: 5| Step: 10
Training loss: 2.9678748196014295
Validation loss: 3.3559344252421415

Epoch: 42| Step: 0
Training loss: 3.3090331451240838
Validation loss: 3.357283118488084

Epoch: 5| Step: 1
Training loss: 3.021637452186489
Validation loss: 3.35764091132414

Epoch: 5| Step: 2
Training loss: 2.279048536773886
Validation loss: 3.3598774134828306

Epoch: 5| Step: 3
Training loss: 3.998910517140472
Validation loss: 3.362421636967843

Epoch: 5| Step: 4
Training loss: 3.8848888594392648
Validation loss: 3.360746680078356

Epoch: 5| Step: 5
Training loss: 3.733622072044179
Validation loss: 3.359054096040038

Epoch: 5| Step: 6
Training loss: 3.2972112547440213
Validation loss: 3.3556239170679034

Epoch: 5| Step: 7
Training loss: 4.5447827536319005
Validation loss: 3.3549412239588956

Epoch: 5| Step: 8
Training loss: 3.383689150085199
Validation loss: 3.3578973968480126

Epoch: 5| Step: 9
Training loss: 3.722760001915293
Validation loss: 3.356547983488512

Epoch: 5| Step: 10
Training loss: 3.8259764578095474
Validation loss: 3.3557823176268258

Epoch: 43| Step: 0
Training loss: 4.409246197068971
Validation loss: 3.357618524715209

Epoch: 5| Step: 1
Training loss: 3.1796494090355125
Validation loss: 3.3549874479224893

Epoch: 5| Step: 2
Training loss: 4.210125506924659
Validation loss: 3.3560669996574686

Epoch: 5| Step: 3
Training loss: 3.025659183528946
Validation loss: 3.355252388228975

Epoch: 5| Step: 4
Training loss: 3.5505734960966633
Validation loss: 3.3544241494861833

Epoch: 5| Step: 5
Training loss: 3.0195481471369883
Validation loss: 3.35670719124425

Epoch: 5| Step: 6
Training loss: 3.2310998523882724
Validation loss: 3.3561744364746726

Epoch: 5| Step: 7
Training loss: 3.6982344513221173
Validation loss: 3.355744654816604

Epoch: 5| Step: 8
Training loss: 3.451952428797174
Validation loss: 3.3530359402371683

Epoch: 5| Step: 9
Training loss: 3.7812320929489465
Validation loss: 3.354414070455629

Epoch: 5| Step: 10
Training loss: 3.5912497406058876
Validation loss: 3.3526571692748144

Epoch: 44| Step: 0
Training loss: 3.7289941559569564
Validation loss: 3.349518373041827

Epoch: 5| Step: 1
Training loss: 3.489619939052212
Validation loss: 3.348609789950044

Epoch: 5| Step: 2
Training loss: 4.085051168730627
Validation loss: 3.347735647372152

Epoch: 5| Step: 3
Training loss: 3.0272716095235244
Validation loss: 3.348553477742691

Epoch: 5| Step: 4
Training loss: 3.0956470568660754
Validation loss: 3.348471369579779

Epoch: 5| Step: 5
Training loss: 4.191559375479363
Validation loss: 3.3479302058575424

Epoch: 5| Step: 6
Training loss: 3.0613019507202957
Validation loss: 3.346933082073597

Epoch: 5| Step: 7
Training loss: 3.897801410405735
Validation loss: 3.3482278659933846

Epoch: 5| Step: 8
Training loss: 3.6311306905925442
Validation loss: 3.3467588200211735

Epoch: 5| Step: 9
Training loss: 3.0151556568863747
Validation loss: 3.348307831707019

Epoch: 5| Step: 10
Training loss: 3.9495320634478506
Validation loss: 3.347084354093958

Epoch: 45| Step: 0
Training loss: 3.7566885744509295
Validation loss: 3.347042380730623

Epoch: 5| Step: 1
Training loss: 4.409310867200043
Validation loss: 3.3480558176193633

Epoch: 5| Step: 2
Training loss: 2.8097219522370995
Validation loss: 3.3501485579513766

Epoch: 5| Step: 3
Training loss: 4.095717095827388
Validation loss: 3.3492309536410616

Epoch: 5| Step: 4
Training loss: 3.8780686318283983
Validation loss: 3.346926238916507

Epoch: 5| Step: 5
Training loss: 2.8914503414211175
Validation loss: 3.3453660735363053

Epoch: 5| Step: 6
Training loss: 4.473496483917918
Validation loss: 3.344175486289002

Epoch: 5| Step: 7
Training loss: 2.6616211385382265
Validation loss: 3.3431179410303633

Epoch: 5| Step: 8
Training loss: 3.0878303999700973
Validation loss: 3.343459134987535

Epoch: 5| Step: 9
Training loss: 2.892957581352496
Validation loss: 3.3413212078061783

Epoch: 5| Step: 10
Training loss: 3.8012314909083273
Validation loss: 3.341579437733553

Epoch: 46| Step: 0
Training loss: 3.3488224806849813
Validation loss: 3.341836939641344

Epoch: 5| Step: 1
Training loss: 3.344727275319267
Validation loss: 3.3406069634017403

Epoch: 5| Step: 2
Training loss: 3.6088577494376626
Validation loss: 3.3417332343990847

Epoch: 5| Step: 3
Training loss: 3.265891324367381
Validation loss: 3.339518379117775

Epoch: 5| Step: 4
Training loss: 3.076381286274912
Validation loss: 3.342620059134562

Epoch: 5| Step: 5
Training loss: 3.7442386875036457
Validation loss: 3.3408766261381087

Epoch: 5| Step: 6
Training loss: 3.0948413503778816
Validation loss: 3.338434982700553

Epoch: 5| Step: 7
Training loss: 4.082041295965509
Validation loss: 3.3396615399474543

Epoch: 5| Step: 8
Training loss: 4.025934544462792
Validation loss: 3.3400738756600106

Epoch: 5| Step: 9
Training loss: 3.976286573148897
Validation loss: 3.340675735591016

Epoch: 5| Step: 10
Training loss: 3.5197881166670344
Validation loss: 3.3312030481329145

Epoch: 47| Step: 0
Training loss: 3.0340761204464015
Validation loss: 3.330589349931559

Epoch: 5| Step: 1
Training loss: 2.831950261503611
Validation loss: 3.331297491684308

Epoch: 5| Step: 2
Training loss: 3.2561578367812927
Validation loss: 3.330017506932394

Epoch: 5| Step: 3
Training loss: 3.5061436274911326
Validation loss: 3.330626707595244

Epoch: 5| Step: 4
Training loss: 2.9772320492445377
Validation loss: 3.3289301066601924

Epoch: 5| Step: 5
Training loss: 3.5929997199992987
Validation loss: 3.3295825149072926

Epoch: 5| Step: 6
Training loss: 3.5577118133517773
Validation loss: 3.3298863267033467

Epoch: 5| Step: 7
Training loss: 3.9537209525233776
Validation loss: 3.332699615986893

Epoch: 5| Step: 8
Training loss: 4.342881150107606
Validation loss: 3.3310687914950505

Epoch: 5| Step: 9
Training loss: 3.7211872737007132
Validation loss: 3.330180489582227

Epoch: 5| Step: 10
Training loss: 4.19918604638428
Validation loss: 3.330419270049495

Epoch: 48| Step: 0
Training loss: 3.030154630032794
Validation loss: 3.3290902024106575

Epoch: 5| Step: 1
Training loss: 3.4929113811234656
Validation loss: 3.3291654838418117

Epoch: 5| Step: 2
Training loss: 4.222705032673813
Validation loss: 3.3281042543294537

Epoch: 5| Step: 3
Training loss: 3.67062187726008
Validation loss: 3.32711610778631

Epoch: 5| Step: 4
Training loss: 3.841675857786712
Validation loss: 3.3283508261139585

Epoch: 5| Step: 5
Training loss: 3.5010219172009878
Validation loss: 3.3256338416068965

Epoch: 5| Step: 6
Training loss: 3.347718068000557
Validation loss: 3.3251310958758227

Epoch: 5| Step: 7
Training loss: 3.2180503899687354
Validation loss: 3.3253253625533326

Epoch: 5| Step: 8
Training loss: 3.2414339591658043
Validation loss: 3.3256787107257826

Epoch: 5| Step: 9
Training loss: 3.3536667698084557
Validation loss: 3.323920522472137

Epoch: 5| Step: 10
Training loss: 4.138858519121981
Validation loss: 3.323445345997114

Epoch: 49| Step: 0
Training loss: 4.016473465278968
Validation loss: 3.321681037700797

Epoch: 5| Step: 1
Training loss: 4.02785567869657
Validation loss: 3.3223040809423305

Epoch: 5| Step: 2
Training loss: 2.7868742065017917
Validation loss: 3.3214833092180474

Epoch: 5| Step: 3
Training loss: 3.233376169084826
Validation loss: 3.3247254613511306

Epoch: 5| Step: 4
Training loss: 3.1097536096147884
Validation loss: 3.3230756243998667

Epoch: 5| Step: 5
Training loss: 3.9473569501743624
Validation loss: 3.3224843200705205

Epoch: 5| Step: 6
Training loss: 3.3980133142687587
Validation loss: 3.3213269222859094

Epoch: 5| Step: 7
Training loss: 3.2624797367329
Validation loss: 3.3184112019631407

Epoch: 5| Step: 8
Training loss: 3.62051192694613
Validation loss: 3.3189306220316257

Epoch: 5| Step: 9
Training loss: 3.7084379431439074
Validation loss: 3.318655376917312

Epoch: 5| Step: 10
Training loss: 3.801803216239279
Validation loss: 3.3192300300916173

Epoch: 50| Step: 0
Training loss: 3.6692847672850597
Validation loss: 3.317425425418672

Epoch: 5| Step: 1
Training loss: 4.1366691838537815
Validation loss: 3.318442126247865

Epoch: 5| Step: 2
Training loss: 2.994076443834706
Validation loss: 3.3201080270887555

Epoch: 5| Step: 3
Training loss: 3.772143914245297
Validation loss: 3.320658483750339

Epoch: 5| Step: 4
Training loss: 3.2326009556700055
Validation loss: 3.3231531465944997

Epoch: 5| Step: 5
Training loss: 3.1091297762224506
Validation loss: 3.3266226396017324

Epoch: 5| Step: 6
Training loss: 3.680680256456482
Validation loss: 3.333552510736393

Epoch: 5| Step: 7
Training loss: 3.7989397125722197
Validation loss: 3.3188936116278893

Epoch: 5| Step: 8
Training loss: 3.6639039873595034
Validation loss: 3.3151066516048187

Epoch: 5| Step: 9
Training loss: 3.719647211143311
Validation loss: 3.3124662340687228

Epoch: 5| Step: 10
Training loss: 3.023000286338255
Validation loss: 3.3111116065624424

Epoch: 51| Step: 0
Training loss: 3.08076696730076
Validation loss: 3.3141904647540263

Epoch: 5| Step: 1
Training loss: 3.230605725632917
Validation loss: 3.31289520970836

Epoch: 5| Step: 2
Training loss: 3.4843796529011817
Validation loss: 3.313879246386212

Epoch: 5| Step: 3
Training loss: 4.252269811931834
Validation loss: 3.3122457126893963

Epoch: 5| Step: 4
Training loss: 4.106165804065105
Validation loss: 3.310938401464485

Epoch: 5| Step: 5
Training loss: 3.420451107501552
Validation loss: 3.3134196918824323

Epoch: 5| Step: 6
Training loss: 3.139081585200895
Validation loss: 3.3126814257175106

Epoch: 5| Step: 7
Training loss: 3.1282880651023364
Validation loss: 3.3120643219310923

Epoch: 5| Step: 8
Training loss: 3.624965667562028
Validation loss: 3.31281367415144

Epoch: 5| Step: 9
Training loss: 3.355222468724873
Validation loss: 3.315509449892818

Epoch: 5| Step: 10
Training loss: 4.02528211659308
Validation loss: 3.312428005223215

Epoch: 52| Step: 0
Training loss: 3.323296424586797
Validation loss: 3.310509509123388

Epoch: 5| Step: 1
Training loss: 3.8730690359615614
Validation loss: 3.3103243400045006

Epoch: 5| Step: 2
Training loss: 2.666766274101886
Validation loss: 3.308206220582783

Epoch: 5| Step: 3
Training loss: 2.9813978114562723
Validation loss: 3.3075975719260353

Epoch: 5| Step: 4
Training loss: 4.069490492512833
Validation loss: 3.3076423694852357

Epoch: 5| Step: 5
Training loss: 3.999689805401003
Validation loss: 3.3062911428633464

Epoch: 5| Step: 6
Training loss: 3.461360311406962
Validation loss: 3.307439215387586

Epoch: 5| Step: 7
Training loss: 3.078101143526683
Validation loss: 3.306237899237376

Epoch: 5| Step: 8
Training loss: 3.9637412356421406
Validation loss: 3.30582514694984

Epoch: 5| Step: 9
Training loss: 3.6595962731156764
Validation loss: 3.305671955056263

Epoch: 5| Step: 10
Training loss: 3.5988742286729267
Validation loss: 3.3044053584191286

Epoch: 53| Step: 0
Training loss: 3.0859909632433675
Validation loss: 3.3054245221689875

Epoch: 5| Step: 1
Training loss: 3.12334398260374
Validation loss: 3.305711512168188

Epoch: 5| Step: 2
Training loss: 4.029658276857614
Validation loss: 3.3040561659151577

Epoch: 5| Step: 3
Training loss: 4.3557590815509615
Validation loss: 3.3043613362577604

Epoch: 5| Step: 4
Training loss: 3.352399245873819
Validation loss: 3.3040004972154446

Epoch: 5| Step: 5
Training loss: 3.5356922396678505
Validation loss: 3.3048289178158607

Epoch: 5| Step: 6
Training loss: 3.496650455414243
Validation loss: 3.304928001322156

Epoch: 5| Step: 7
Training loss: 4.024813696299121
Validation loss: 3.30549184078797

Epoch: 5| Step: 8
Training loss: 3.5633241469785526
Validation loss: 3.3048089164445895

Epoch: 5| Step: 9
Training loss: 3.0431566290583754
Validation loss: 3.305829103507163

Epoch: 5| Step: 10
Training loss: 2.9496935733765377
Validation loss: 3.305161834748891

Epoch: 54| Step: 0
Training loss: 2.845012175093144
Validation loss: 3.303054201539678

Epoch: 5| Step: 1
Training loss: 3.960561520039313
Validation loss: 3.3048316592292513

Epoch: 5| Step: 2
Training loss: 4.034229921883738
Validation loss: 3.3053927198919713

Epoch: 5| Step: 3
Training loss: 2.8234467143682656
Validation loss: 3.3025494460641283

Epoch: 5| Step: 4
Training loss: 3.6802711104995165
Validation loss: 3.3035770038813146

Epoch: 5| Step: 5
Training loss: 3.7531484738139125
Validation loss: 3.3019646034208088

Epoch: 5| Step: 6
Training loss: 3.6682501899231985
Validation loss: 3.30104803084979

Epoch: 5| Step: 7
Training loss: 3.878268678325959
Validation loss: 3.3021744339984607

Epoch: 5| Step: 8
Training loss: 3.183963234646034
Validation loss: 3.3014059808659106

Epoch: 5| Step: 9
Training loss: 3.78828381274564
Validation loss: 3.3014332431669837

Epoch: 5| Step: 10
Training loss: 2.909984527232141
Validation loss: 3.302412547254582

Epoch: 55| Step: 0
Training loss: 4.0454367655752055
Validation loss: 3.303113841340674

Epoch: 5| Step: 1
Training loss: 3.437747738320702
Validation loss: 3.3046002027015042

Epoch: 5| Step: 2
Training loss: 3.24277750185141
Validation loss: 3.3042311500578254

Epoch: 5| Step: 3
Training loss: 3.5537207326311147
Validation loss: 3.3059775958370365

Epoch: 5| Step: 4
Training loss: 2.9791346372647687
Validation loss: 3.311199196732614

Epoch: 5| Step: 5
Training loss: 3.678755008280615
Validation loss: 3.3111689643332367

Epoch: 5| Step: 6
Training loss: 2.824969475505288
Validation loss: 3.297349160202735

Epoch: 5| Step: 7
Training loss: 3.6382805475124136
Validation loss: 3.299477180178436

Epoch: 5| Step: 8
Training loss: 3.280578253876833
Validation loss: 3.299011811704384

Epoch: 5| Step: 9
Training loss: 4.190682639366374
Validation loss: 3.3000073560556293

Epoch: 5| Step: 10
Training loss: 3.8105438717312614
Validation loss: 3.3006381247563854

Epoch: 56| Step: 0
Training loss: 3.6716863056153453
Validation loss: 3.3002825313699873

Epoch: 5| Step: 1
Training loss: 3.40253070444664
Validation loss: 3.3008465570099617

Epoch: 5| Step: 2
Training loss: 3.8881266588686736
Validation loss: 3.300649164125756

Epoch: 5| Step: 3
Training loss: 3.1109953832294734
Validation loss: 3.2987248869816974

Epoch: 5| Step: 4
Training loss: 3.0798308781847448
Validation loss: 3.299114335165159

Epoch: 5| Step: 5
Training loss: 4.168327737952169
Validation loss: 3.297689168111625

Epoch: 5| Step: 6
Training loss: 3.5537746724584864
Validation loss: 3.2988659744521356

Epoch: 5| Step: 7
Training loss: 3.551890989821712
Validation loss: 3.29726587181119

Epoch: 5| Step: 8
Training loss: 3.239597251019935
Validation loss: 3.2989007740538896

Epoch: 5| Step: 9
Training loss: 3.226146015322713
Validation loss: 3.2997943996843775

Epoch: 5| Step: 10
Training loss: 3.849146830167749
Validation loss: 3.2996861527035346

Epoch: 57| Step: 0
Training loss: 4.437819563413658
Validation loss: 3.2990268670795007

Epoch: 5| Step: 1
Training loss: 3.3297217035707325
Validation loss: 3.297847670999018

Epoch: 5| Step: 2
Training loss: 2.336367156151251
Validation loss: 3.298497441392655

Epoch: 5| Step: 3
Training loss: 3.032764803527571
Validation loss: 3.2975621050065524

Epoch: 5| Step: 4
Training loss: 3.644336167784306
Validation loss: 3.2959381718034986

Epoch: 5| Step: 5
Training loss: 3.031395662878238
Validation loss: 3.296906200160799

Epoch: 5| Step: 6
Training loss: 4.111289155100344
Validation loss: 3.2977951298446517

Epoch: 5| Step: 7
Training loss: 4.530588667391435
Validation loss: 3.2958504576356344

Epoch: 5| Step: 8
Training loss: 3.4585128798852307
Validation loss: 3.293868494502972

Epoch: 5| Step: 9
Training loss: 3.1806745567066668
Validation loss: 3.2970779979304847

Epoch: 5| Step: 10
Training loss: 3.003836404015679
Validation loss: 3.294128974189278

Epoch: 58| Step: 0
Training loss: 2.9451794176871746
Validation loss: 3.29287898079816

Epoch: 5| Step: 1
Training loss: 3.8181493208687107
Validation loss: 3.2939652055008124

Epoch: 5| Step: 2
Training loss: 3.2730328075280997
Validation loss: 3.2929990599631647

Epoch: 5| Step: 3
Training loss: 2.9351089160992365
Validation loss: 3.2923764364050303

Epoch: 5| Step: 4
Training loss: 3.4834137689773343
Validation loss: 3.292141410629262

Epoch: 5| Step: 5
Training loss: 3.366317317953887
Validation loss: 3.29307364917096

Epoch: 5| Step: 6
Training loss: 3.8129842481910576
Validation loss: 3.2935686139845184

Epoch: 5| Step: 7
Training loss: 3.7337078951085734
Validation loss: 3.2932613871768543

Epoch: 5| Step: 8
Training loss: 3.165962760055633
Validation loss: 3.294424611671129

Epoch: 5| Step: 9
Training loss: 3.9480124724480015
Validation loss: 3.2913353144293422

Epoch: 5| Step: 10
Training loss: 4.173612425696909
Validation loss: 3.2932458648393497

Epoch: 59| Step: 0
Training loss: 4.061041937112966
Validation loss: 3.292493309584592

Epoch: 5| Step: 1
Training loss: 3.3839401233416964
Validation loss: 3.2926709870545494

Epoch: 5| Step: 2
Training loss: 3.5685354939946183
Validation loss: 3.2925651905484994

Epoch: 5| Step: 3
Training loss: 2.979386079262263
Validation loss: 3.2923423698697376

Epoch: 5| Step: 4
Training loss: 3.7142906057933414
Validation loss: 3.3020815642429024

Epoch: 5| Step: 5
Training loss: 4.339765958320569
Validation loss: 3.292980555449691

Epoch: 5| Step: 6
Training loss: 2.3129016424328035
Validation loss: 3.2935558960453695

Epoch: 5| Step: 7
Training loss: 2.9865532560046786
Validation loss: 3.290346375919625

Epoch: 5| Step: 8
Training loss: 3.4455555248400596
Validation loss: 3.2925483895512317

Epoch: 5| Step: 9
Training loss: 3.89432089647874
Validation loss: 3.290877287423053

Epoch: 5| Step: 10
Training loss: 3.6327623589449645
Validation loss: 3.2898954021284923

Epoch: 60| Step: 0
Training loss: 3.2852616264869643
Validation loss: 3.2913727842653318

Epoch: 5| Step: 1
Training loss: 3.5877831058246703
Validation loss: 3.290976552608686

Epoch: 5| Step: 2
Training loss: 3.5020604199611682
Validation loss: 3.294452188540327

Epoch: 5| Step: 3
Training loss: 4.052606360930011
Validation loss: 3.295779388842101

Epoch: 5| Step: 4
Training loss: 3.5246153763681174
Validation loss: 3.292927889925064

Epoch: 5| Step: 5
Training loss: 3.800753900129629
Validation loss: 3.292434866505587

Epoch: 5| Step: 6
Training loss: 3.335795272189441
Validation loss: 3.2886126099027786

Epoch: 5| Step: 7
Training loss: 3.6070773915955785
Validation loss: 3.2884676445565852

Epoch: 5| Step: 8
Training loss: 3.2517610327087034
Validation loss: 3.286709829159057

Epoch: 5| Step: 9
Training loss: 3.4946537056917495
Validation loss: 3.2863031686158948

Epoch: 5| Step: 10
Training loss: 3.1824104216165723
Validation loss: 3.2869926839767083

Epoch: 61| Step: 0
Training loss: 3.5088195035034935
Validation loss: 3.2860461613097267

Epoch: 5| Step: 1
Training loss: 3.099982255454192
Validation loss: 3.2885236416831845

Epoch: 5| Step: 2
Training loss: 4.372310792854452
Validation loss: 3.287545793079403

Epoch: 5| Step: 3
Training loss: 3.5155464672218173
Validation loss: 3.2878056773706446

Epoch: 5| Step: 4
Training loss: 3.813873293823849
Validation loss: 3.2857556560214776

Epoch: 5| Step: 5
Training loss: 3.395611028279166
Validation loss: 3.284861048923806

Epoch: 5| Step: 6
Training loss: 3.7497185919396396
Validation loss: 3.2850186115244058

Epoch: 5| Step: 7
Training loss: 2.818109893859863
Validation loss: 3.2853109517847643

Epoch: 5| Step: 8
Training loss: 3.1197375429242373
Validation loss: 3.2855789622553684

Epoch: 5| Step: 9
Training loss: 3.5273974172706533
Validation loss: 3.2842071490000007

Epoch: 5| Step: 10
Training loss: 3.5674326695034386
Validation loss: 3.285081072880866

Epoch: 62| Step: 0
Training loss: 3.2362762612772475
Validation loss: 3.286139353179554

Epoch: 5| Step: 1
Training loss: 3.9021368726053662
Validation loss: 3.284524318147948

Epoch: 5| Step: 2
Training loss: 3.791475200360183
Validation loss: 3.284376749507911

Epoch: 5| Step: 3
Training loss: 3.531843017476521
Validation loss: 3.286649448640297

Epoch: 5| Step: 4
Training loss: 3.790170786690905
Validation loss: 3.285654532153483

Epoch: 5| Step: 5
Training loss: 3.9534575431785446
Validation loss: 3.2851806880070304

Epoch: 5| Step: 6
Training loss: 3.5091082722094606
Validation loss: 3.2838470104217263

Epoch: 5| Step: 7
Training loss: 3.432233903521356
Validation loss: 3.2830570321649377

Epoch: 5| Step: 8
Training loss: 2.8185342270507197
Validation loss: 3.282524518432824

Epoch: 5| Step: 9
Training loss: 3.5665628121012496
Validation loss: 3.2827706402984047

Epoch: 5| Step: 10
Training loss: 2.8275241108076314
Validation loss: 3.282420493498405

Epoch: 63| Step: 0
Training loss: 3.544091296034009
Validation loss: 3.2818216242960045

Epoch: 5| Step: 1
Training loss: 3.27329794647709
Validation loss: 3.282359699010981

Epoch: 5| Step: 2
Training loss: 2.894878495323344
Validation loss: 3.2830814045878727

Epoch: 5| Step: 3
Training loss: 2.992233395535745
Validation loss: 3.2840903306548235

Epoch: 5| Step: 4
Training loss: 3.9983777094280346
Validation loss: 3.2830335825560906

Epoch: 5| Step: 5
Training loss: 3.7059320683354664
Validation loss: 3.2812334613998524

Epoch: 5| Step: 6
Training loss: 3.3498926515602765
Validation loss: 3.281171461221141

Epoch: 5| Step: 7
Training loss: 3.533217430612968
Validation loss: 3.2799063920610623

Epoch: 5| Step: 8
Training loss: 2.8291715087249925
Validation loss: 3.2795735894929923

Epoch: 5| Step: 9
Training loss: 3.763693413031912
Validation loss: 3.2803084312171404

Epoch: 5| Step: 10
Training loss: 4.582947362195883
Validation loss: 3.2796040943876545

Epoch: 64| Step: 0
Training loss: 4.380822367348146
Validation loss: 3.2804737209978736

Epoch: 5| Step: 1
Training loss: 2.619988334862752
Validation loss: 3.279288302150079

Epoch: 5| Step: 2
Training loss: 3.3324738507056897
Validation loss: 3.2780003595207634

Epoch: 5| Step: 3
Training loss: 3.9166722534356277
Validation loss: 3.278399168251704

Epoch: 5| Step: 4
Training loss: 3.217504019449446
Validation loss: 3.277293494387026

Epoch: 5| Step: 5
Training loss: 3.3340081167688633
Validation loss: 3.27742642766932

Epoch: 5| Step: 6
Training loss: 3.3022014384202527
Validation loss: 3.2755339369403176

Epoch: 5| Step: 7
Training loss: 4.003708550759387
Validation loss: 3.2778824361999646

Epoch: 5| Step: 8
Training loss: 3.4521574157857082
Validation loss: 3.2763671702857833

Epoch: 5| Step: 9
Training loss: 3.1563983542447094
Validation loss: 3.275230959391826

Epoch: 5| Step: 10
Training loss: 3.6091529150340973
Validation loss: 3.2765024180288234

Epoch: 65| Step: 0
Training loss: 3.5829493886198187
Validation loss: 3.2747096354049843

Epoch: 5| Step: 1
Training loss: 3.0284179356846157
Validation loss: 3.274839451447703

Epoch: 5| Step: 2
Training loss: 3.0086121920384685
Validation loss: 3.2763830229759496

Epoch: 5| Step: 3
Training loss: 2.7240511195837924
Validation loss: 3.2739284745420685

Epoch: 5| Step: 4
Training loss: 4.224612309652818
Validation loss: 3.274156200249066

Epoch: 5| Step: 5
Training loss: 3.0312194822682534
Validation loss: 3.2754567732435773

Epoch: 5| Step: 6
Training loss: 3.0631560576583974
Validation loss: 3.2736775953891484

Epoch: 5| Step: 7
Training loss: 4.011424914689468
Validation loss: 3.2749937106124327

Epoch: 5| Step: 8
Training loss: 3.9996235193463883
Validation loss: 3.2726981145191796

Epoch: 5| Step: 9
Training loss: 3.6767829721914738
Validation loss: 3.273118568057607

Epoch: 5| Step: 10
Training loss: 3.9301192120435764
Validation loss: 3.2727853799619715

Epoch: 66| Step: 0
Training loss: 3.8164122473084916
Validation loss: 3.2710940762180196

Epoch: 5| Step: 1
Training loss: 3.1634810301934095
Validation loss: 3.2729566939886396

Epoch: 5| Step: 2
Training loss: 3.006091926209716
Validation loss: 3.2723913419970274

Epoch: 5| Step: 3
Training loss: 3.9898813533112705
Validation loss: 3.272313794739205

Epoch: 5| Step: 4
Training loss: 3.6455007492229994
Validation loss: 3.2734323083972128

Epoch: 5| Step: 5
Training loss: 3.165892272089972
Validation loss: 3.271327803098576

Epoch: 5| Step: 6
Training loss: 3.594504368430102
Validation loss: 3.271163800419382

Epoch: 5| Step: 7
Training loss: 3.5536013106974487
Validation loss: 3.273906134128267

Epoch: 5| Step: 8
Training loss: 3.1221384298168084
Validation loss: 3.273685063091298

Epoch: 5| Step: 9
Training loss: 3.6033128965670476
Validation loss: 3.2729534433761462

Epoch: 5| Step: 10
Training loss: 3.8099387899372936
Validation loss: 3.2703431039475714

Epoch: 67| Step: 0
Training loss: 2.8101903969008037
Validation loss: 3.2697512313652424

Epoch: 5| Step: 1
Training loss: 3.2891202001879134
Validation loss: 3.2718804692835004

Epoch: 5| Step: 2
Training loss: 3.7538668722733064
Validation loss: 3.2702861824907288

Epoch: 5| Step: 3
Training loss: 2.4810165641382405
Validation loss: 3.2700530632189064

Epoch: 5| Step: 4
Training loss: 3.4238459515365927
Validation loss: 3.2702231680940947

Epoch: 5| Step: 5
Training loss: 4.318753780468226
Validation loss: 3.2704438828807625

Epoch: 5| Step: 6
Training loss: 3.9708746081699173
Validation loss: 3.2707028090894044

Epoch: 5| Step: 7
Training loss: 3.622424032548099
Validation loss: 3.2706343683900014

Epoch: 5| Step: 8
Training loss: 3.8837174832714294
Validation loss: 3.271062186262087

Epoch: 5| Step: 9
Training loss: 3.4028642258508044
Validation loss: 3.267726750378999

Epoch: 5| Step: 10
Training loss: 3.1610973640177242
Validation loss: 3.2686674509134632

Epoch: 68| Step: 0
Training loss: 4.044425782893052
Validation loss: 3.2680982873930775

Epoch: 5| Step: 1
Training loss: 4.078023507327828
Validation loss: 3.2691928382933355

Epoch: 5| Step: 2
Training loss: 3.6130510906426094
Validation loss: 3.267365035376911

Epoch: 5| Step: 3
Training loss: 3.1043554841717036
Validation loss: 3.2668377249077314

Epoch: 5| Step: 4
Training loss: 3.2622968880871266
Validation loss: 3.265281383227054

Epoch: 5| Step: 5
Training loss: 3.74258223265548
Validation loss: 3.2662194773614655

Epoch: 5| Step: 6
Training loss: 3.9208541696598167
Validation loss: 3.266390382293213

Epoch: 5| Step: 7
Training loss: 3.566527917129907
Validation loss: 3.267086989452343

Epoch: 5| Step: 8
Training loss: 2.651879338771805
Validation loss: 3.2646726568034583

Epoch: 5| Step: 9
Training loss: 3.30105066046428
Validation loss: 3.2647649778023258

Epoch: 5| Step: 10
Training loss: 2.8800490451981164
Validation loss: 3.265132399998335

Epoch: 69| Step: 0
Training loss: 3.9346755054658558
Validation loss: 3.2652544683867952

Epoch: 5| Step: 1
Training loss: 4.1392513659751975
Validation loss: 3.265105550668851

Epoch: 5| Step: 2
Training loss: 3.593398898015469
Validation loss: 3.264259325619286

Epoch: 5| Step: 3
Training loss: 3.581434027452295
Validation loss: 3.2632983704561767

Epoch: 5| Step: 4
Training loss: 3.2077641828626438
Validation loss: 3.2647098751195753

Epoch: 5| Step: 5
Training loss: 3.186842457885139
Validation loss: 3.2655924458703134

Epoch: 5| Step: 6
Training loss: 3.957356355798935
Validation loss: 3.271867887216134

Epoch: 5| Step: 7
Training loss: 3.36270927146686
Validation loss: 3.2687042174770937

Epoch: 5| Step: 8
Training loss: 3.113410209942785
Validation loss: 3.2648551148407368

Epoch: 5| Step: 9
Training loss: 2.934849131409194
Validation loss: 3.2645398968167743

Epoch: 5| Step: 10
Training loss: 3.2395201224061134
Validation loss: 3.2653464800918885

Epoch: 70| Step: 0
Training loss: 3.5009278021360344
Validation loss: 3.2669726232461658

Epoch: 5| Step: 1
Training loss: 4.282473646841119
Validation loss: 3.2626491529038066

Epoch: 5| Step: 2
Training loss: 3.662205988308913
Validation loss: 3.2654388244348027

Epoch: 5| Step: 3
Training loss: 3.3562860526025684
Validation loss: 3.2605170536846737

Epoch: 5| Step: 4
Training loss: 3.3306612908091147
Validation loss: 3.2601177339717418

Epoch: 5| Step: 5
Training loss: 3.2758218098155285
Validation loss: 3.2625268133785075

Epoch: 5| Step: 6
Training loss: 3.6116529270175417
Validation loss: 3.2605759383454838

Epoch: 5| Step: 7
Training loss: 3.4233108364753972
Validation loss: 3.260784375461721

Epoch: 5| Step: 8
Training loss: 3.5615937268135918
Validation loss: 3.2606517810897095

Epoch: 5| Step: 9
Training loss: 3.1948937325871127
Validation loss: 3.260862916262237

Epoch: 5| Step: 10
Training loss: 3.0654206654056466
Validation loss: 3.2611136445193107

Epoch: 71| Step: 0
Training loss: 3.2390227164931993
Validation loss: 3.26012174285516

Epoch: 5| Step: 1
Training loss: 3.2101232976793446
Validation loss: 3.2591892387744608

Epoch: 5| Step: 2
Training loss: 3.311172075229523
Validation loss: 3.2580037775351096

Epoch: 5| Step: 3
Training loss: 3.4760798087050326
Validation loss: 3.2597557110041144

Epoch: 5| Step: 4
Training loss: 3.9557669635479615
Validation loss: 3.259100272832509

Epoch: 5| Step: 5
Training loss: 2.628418649060032
Validation loss: 3.2593603597474274

Epoch: 5| Step: 6
Training loss: 3.7542232891615295
Validation loss: 3.2598871448922333

Epoch: 5| Step: 7
Training loss: 3.377689137954926
Validation loss: 3.257068346705998

Epoch: 5| Step: 8
Training loss: 3.5415668847482618
Validation loss: 3.258701142966219

Epoch: 5| Step: 9
Training loss: 3.435907307032885
Validation loss: 3.259843580075637

Epoch: 5| Step: 10
Training loss: 4.385470476824646
Validation loss: 3.258148315336445

Epoch: 72| Step: 0
Training loss: 3.6014294382534087
Validation loss: 3.2563862116269613

Epoch: 5| Step: 1
Training loss: 3.234501490676496
Validation loss: 3.2582987446099523

Epoch: 5| Step: 2
Training loss: 3.8354193498697726
Validation loss: 3.258079598321955

Epoch: 5| Step: 3
Training loss: 2.7403608797309285
Validation loss: 3.256268881755899

Epoch: 5| Step: 4
Training loss: 4.362894804395213
Validation loss: 3.2579025791600804

Epoch: 5| Step: 5
Training loss: 2.9660937824097546
Validation loss: 3.257039634721681

Epoch: 5| Step: 6
Training loss: 3.2998548302364403
Validation loss: 3.2595991482912927

Epoch: 5| Step: 7
Training loss: 4.17295063453799
Validation loss: 3.2589339540781195

Epoch: 5| Step: 8
Training loss: 3.287840990143052
Validation loss: 3.2621506417136805

Epoch: 5| Step: 9
Training loss: 2.841151800711729
Validation loss: 3.2581344952536058

Epoch: 5| Step: 10
Training loss: 3.701743210149007
Validation loss: 3.2555821174217345

Epoch: 73| Step: 0
Training loss: 3.394908537271723
Validation loss: 3.254795430172093

Epoch: 5| Step: 1
Training loss: 2.551906833903252
Validation loss: 3.252524795351326

Epoch: 5| Step: 2
Training loss: 4.3841916122746785
Validation loss: 3.2545086624159563

Epoch: 5| Step: 3
Training loss: 3.720590600742705
Validation loss: 3.254529655078652

Epoch: 5| Step: 4
Training loss: 3.3724935195894523
Validation loss: 3.252575881356726

Epoch: 5| Step: 5
Training loss: 3.5300342188573346
Validation loss: 3.255014013122222

Epoch: 5| Step: 6
Training loss: 2.9134679602004803
Validation loss: 3.2522850412418567

Epoch: 5| Step: 7
Training loss: 3.8554506929510026
Validation loss: 3.253736906499412

Epoch: 5| Step: 8
Training loss: 3.4829235389502635
Validation loss: 3.2532655151353382

Epoch: 5| Step: 9
Training loss: 3.4556154962092647
Validation loss: 3.25484932863666

Epoch: 5| Step: 10
Training loss: 3.398326091474893
Validation loss: 3.253252537984229

Epoch: 74| Step: 0
Training loss: 3.186707192353474
Validation loss: 3.2520283647558075

Epoch: 5| Step: 1
Training loss: 3.3187483390617167
Validation loss: 3.253758999324197

Epoch: 5| Step: 2
Training loss: 3.880010749172776
Validation loss: 3.2519815318741565

Epoch: 5| Step: 3
Training loss: 3.2049129799204072
Validation loss: 3.2509386980358164

Epoch: 5| Step: 4
Training loss: 3.0189200469906567
Validation loss: 3.2500171629371275

Epoch: 5| Step: 5
Training loss: 3.520656528585677
Validation loss: 3.2503267199709485

Epoch: 5| Step: 6
Training loss: 3.4580548338990997
Validation loss: 3.2514457862911157

Epoch: 5| Step: 7
Training loss: 3.9255609099390627
Validation loss: 3.2513150314730375

Epoch: 5| Step: 8
Training loss: 3.2334155442578276
Validation loss: 3.2506651438304264

Epoch: 5| Step: 9
Training loss: 3.935684633328745
Validation loss: 3.250204046768188

Epoch: 5| Step: 10
Training loss: 3.5522204211379003
Validation loss: 3.250491266849802

Epoch: 75| Step: 0
Training loss: 3.8742779705108465
Validation loss: 3.2503374554009747

Epoch: 5| Step: 1
Training loss: 3.3128208508839214
Validation loss: 3.2481064671878888

Epoch: 5| Step: 2
Training loss: 3.8807806151969704
Validation loss: 3.2488536169637277

Epoch: 5| Step: 3
Training loss: 3.8511587554216002
Validation loss: 3.2493569800500057

Epoch: 5| Step: 4
Training loss: 3.323615515872899
Validation loss: 3.248982353005799

Epoch: 5| Step: 5
Training loss: 3.563848140011507
Validation loss: 3.247618538677379

Epoch: 5| Step: 6
Training loss: 3.4314330227649323
Validation loss: 3.2483144259030534

Epoch: 5| Step: 7
Training loss: 3.009573126398029
Validation loss: 3.2498800241366403

Epoch: 5| Step: 8
Training loss: 3.526083889158593
Validation loss: 3.247471893370042

Epoch: 5| Step: 9
Training loss: 3.3407408106314325
Validation loss: 3.2488997026983837

Epoch: 5| Step: 10
Training loss: 3.0359771678804837
Validation loss: 3.2478155678356124

Epoch: 76| Step: 0
Training loss: 3.7171138722462627
Validation loss: 3.247736153428805

Epoch: 5| Step: 1
Training loss: 4.105122153245431
Validation loss: 3.247148188655525

Epoch: 5| Step: 2
Training loss: 4.469787903944661
Validation loss: 3.245176591751266

Epoch: 5| Step: 3
Training loss: 3.1041654719066667
Validation loss: 3.2457906679437047

Epoch: 5| Step: 4
Training loss: 3.092262141486773
Validation loss: 3.246678026330275

Epoch: 5| Step: 5
Training loss: 3.4686066194061254
Validation loss: 3.2459026599439147

Epoch: 5| Step: 6
Training loss: 3.4201911022936273
Validation loss: 3.24607975855093

Epoch: 5| Step: 7
Training loss: 2.593342576717323
Validation loss: 3.2460408023618696

Epoch: 5| Step: 8
Training loss: 3.4324365950894244
Validation loss: 3.246687571238085

Epoch: 5| Step: 9
Training loss: 3.200247909956456
Validation loss: 3.245801600828029

Epoch: 5| Step: 10
Training loss: 3.3299821856597855
Validation loss: 3.242376682906382

Epoch: 77| Step: 0
Training loss: 3.7100081073024627
Validation loss: 3.2438890558740243

Epoch: 5| Step: 1
Training loss: 3.3859659698092144
Validation loss: 3.245254475431915

Epoch: 5| Step: 2
Training loss: 3.5095146823983
Validation loss: 3.243788039928283

Epoch: 5| Step: 3
Training loss: 4.3046489513076605
Validation loss: 3.2432975299037166

Epoch: 5| Step: 4
Training loss: 2.9979861175643223
Validation loss: 3.244224390643267

Epoch: 5| Step: 5
Training loss: 3.312814661591509
Validation loss: 3.2413543306702732

Epoch: 5| Step: 6
Training loss: 3.190288744925916
Validation loss: 3.2437928735407913

Epoch: 5| Step: 7
Training loss: 3.3601604164521657
Validation loss: 3.245333248303578

Epoch: 5| Step: 8
Training loss: 3.1244246906954163
Validation loss: 3.243330250901848

Epoch: 5| Step: 9
Training loss: 3.549765463590036
Validation loss: 3.2425351057977068

Epoch: 5| Step: 10
Training loss: 3.686731678721172
Validation loss: 3.240689593678323

Epoch: 78| Step: 0
Training loss: 3.1297811935044066
Validation loss: 3.2416919474337336

Epoch: 5| Step: 1
Training loss: 3.188523520902295
Validation loss: 3.241591922771298

Epoch: 5| Step: 2
Training loss: 3.3246028691666165
Validation loss: 3.2418705444941747

Epoch: 5| Step: 3
Training loss: 3.769276980980648
Validation loss: 3.241705730061676

Epoch: 5| Step: 4
Training loss: 2.658222946776987
Validation loss: 3.2445137108846325

Epoch: 5| Step: 5
Training loss: 3.260581031694444
Validation loss: 3.243194734372172

Epoch: 5| Step: 6
Training loss: 3.3267693422586118
Validation loss: 3.243601683499933

Epoch: 5| Step: 7
Training loss: 4.221799751249275
Validation loss: 3.240685907249305

Epoch: 5| Step: 8
Training loss: 2.8808469610431686
Validation loss: 3.23993899769682

Epoch: 5| Step: 9
Training loss: 4.2927976926509475
Validation loss: 3.237908961409344

Epoch: 5| Step: 10
Training loss: 3.8664119674939412
Validation loss: 3.23973557209118

Epoch: 79| Step: 0
Training loss: 3.8218299644730074
Validation loss: 3.2398925914302614

Epoch: 5| Step: 1
Training loss: 2.6804186654811075
Validation loss: 3.239008971520831

Epoch: 5| Step: 2
Training loss: 3.19046032636612
Validation loss: 3.2395917804440257

Epoch: 5| Step: 3
Training loss: 3.0675956217467077
Validation loss: 3.2386961488000376

Epoch: 5| Step: 4
Training loss: 3.389904596117178
Validation loss: 3.2403588520947135

Epoch: 5| Step: 5
Training loss: 3.075690221468986
Validation loss: 3.2372417477921873

Epoch: 5| Step: 6
Training loss: 3.6939798093201643
Validation loss: 3.2368178742686466

Epoch: 5| Step: 7
Training loss: 3.3359317824160604
Validation loss: 3.2371622521739734

Epoch: 5| Step: 8
Training loss: 3.7644642667337322
Validation loss: 3.2346136547939364

Epoch: 5| Step: 9
Training loss: 4.553907271964416
Validation loss: 3.2372467780722634

Epoch: 5| Step: 10
Training loss: 3.279181709562032
Validation loss: 3.2355828970614415

Epoch: 80| Step: 0
Training loss: 3.423658768272952
Validation loss: 3.2368702662975353

Epoch: 5| Step: 1
Training loss: 2.992132520046044
Validation loss: 3.2360380127122967

Epoch: 5| Step: 2
Training loss: 3.733580820077593
Validation loss: 3.2358445335555768

Epoch: 5| Step: 3
Training loss: 3.2511346743617686
Validation loss: 3.235046369352761

Epoch: 5| Step: 4
Training loss: 3.9309098331549204
Validation loss: 3.2369775995909342

Epoch: 5| Step: 5
Training loss: 3.403500768619662
Validation loss: 3.2362652645276215

Epoch: 5| Step: 6
Training loss: 2.922960701844342
Validation loss: 3.2355145232476565

Epoch: 5| Step: 7
Training loss: 3.653542845025164
Validation loss: 3.2347140061958117

Epoch: 5| Step: 8
Training loss: 3.255191031855063
Validation loss: 3.234709823166339

Epoch: 5| Step: 9
Training loss: 3.6076332282343295
Validation loss: 3.2331766559223585

Epoch: 5| Step: 10
Training loss: 3.964505185860321
Validation loss: 3.233272430151646

Epoch: 81| Step: 0
Training loss: 3.696793305888221
Validation loss: 3.232494936327629

Epoch: 5| Step: 1
Training loss: 3.4326590002343154
Validation loss: 3.233885927196148

Epoch: 5| Step: 2
Training loss: 2.7956881429055733
Validation loss: 3.236039544857406

Epoch: 5| Step: 3
Training loss: 4.118786380126698
Validation loss: 3.237444390938127

Epoch: 5| Step: 4
Training loss: 3.092412177699187
Validation loss: 3.2388636698394433

Epoch: 5| Step: 5
Training loss: 3.8843444626605983
Validation loss: 3.2333894305685176

Epoch: 5| Step: 6
Training loss: 3.7206029042440605
Validation loss: 3.23202217123362

Epoch: 5| Step: 7
Training loss: 2.716233766229029
Validation loss: 3.2331970266880456

Epoch: 5| Step: 8
Training loss: 3.4852050340013454
Validation loss: 3.2297478196887215

Epoch: 5| Step: 9
Training loss: 3.3358320089987656
Validation loss: 3.2312325328109557

Epoch: 5| Step: 10
Training loss: 3.6856034137571743
Validation loss: 3.231473131703755

Epoch: 82| Step: 0
Training loss: 3.1422228947281585
Validation loss: 3.2296259666885354

Epoch: 5| Step: 1
Training loss: 3.3848656465133575
Validation loss: 3.2292369145517132

Epoch: 5| Step: 2
Training loss: 3.84179315145028
Validation loss: 3.2279316851177

Epoch: 5| Step: 3
Training loss: 3.4160823477438864
Validation loss: 3.2302350262018527

Epoch: 5| Step: 4
Training loss: 3.362466214942666
Validation loss: 3.229949918634453

Epoch: 5| Step: 5
Training loss: 3.724585306522916
Validation loss: 3.2297656506363617

Epoch: 5| Step: 6
Training loss: 3.254524309642757
Validation loss: 3.2307117450770995

Epoch: 5| Step: 7
Training loss: 3.3645690508245054
Validation loss: 3.230564186303497

Epoch: 5| Step: 8
Training loss: 2.9025574883970355
Validation loss: 3.229711365318021

Epoch: 5| Step: 9
Training loss: 3.8630390766329006
Validation loss: 3.230036461927626

Epoch: 5| Step: 10
Training loss: 3.821754105559301
Validation loss: 3.2286004662026273

Epoch: 83| Step: 0
Training loss: 3.6871945529446433
Validation loss: 3.229532638013628

Epoch: 5| Step: 1
Training loss: 2.8254953878402533
Validation loss: 3.2299222783905694

Epoch: 5| Step: 2
Training loss: 3.729825109109468
Validation loss: 3.2254279435010758

Epoch: 5| Step: 3
Training loss: 3.38776273377166
Validation loss: 3.228755170237833

Epoch: 5| Step: 4
Training loss: 3.153343297473523
Validation loss: 3.2288508620368823

Epoch: 5| Step: 5
Training loss: 2.927344114875211
Validation loss: 3.229834314422978

Epoch: 5| Step: 6
Training loss: 4.142194112328512
Validation loss: 3.2240541510719716

Epoch: 5| Step: 7
Training loss: 3.8367711421905772
Validation loss: 3.2275620812890047

Epoch: 5| Step: 8
Training loss: 3.7977373062332473
Validation loss: 3.22838414158481

Epoch: 5| Step: 9
Training loss: 2.8571705476236464
Validation loss: 3.2266568139797953

Epoch: 5| Step: 10
Training loss: 3.525223036399238
Validation loss: 3.226660155725618

Epoch: 84| Step: 0
Training loss: 3.5500898537883097
Validation loss: 3.226625670267777

Epoch: 5| Step: 1
Training loss: 3.7870752530776497
Validation loss: 3.2247179686285468

Epoch: 5| Step: 2
Training loss: 3.2000902640009867
Validation loss: 3.227249483548942

Epoch: 5| Step: 3
Training loss: 3.2239610284764244
Validation loss: 3.226615679872067

Epoch: 5| Step: 4
Training loss: 3.4529253181271495
Validation loss: 3.2244433920558104

Epoch: 5| Step: 5
Training loss: 2.913592998737552
Validation loss: 3.224965573612248

Epoch: 5| Step: 6
Training loss: 3.953075544326882
Validation loss: 3.2260535546740217

Epoch: 5| Step: 7
Training loss: 3.3523525916227204
Validation loss: 3.226524414180963

Epoch: 5| Step: 8
Training loss: 3.59182528494406
Validation loss: 3.2245842998573635

Epoch: 5| Step: 9
Training loss: 3.5554092512892
Validation loss: 3.2254925078241596

Epoch: 5| Step: 10
Training loss: 3.412120974105571
Validation loss: 3.2268394290392544

Epoch: 85| Step: 0
Training loss: 3.2664814241267375
Validation loss: 3.229738589848632

Epoch: 5| Step: 1
Training loss: 3.4962672355698916
Validation loss: 3.225654052856847

Epoch: 5| Step: 2
Training loss: 3.42588369288107
Validation loss: 3.225250729919937

Epoch: 5| Step: 3
Training loss: 3.7051537988120766
Validation loss: 3.2288027655906837

Epoch: 5| Step: 4
Training loss: 3.887973234068806
Validation loss: 3.2294024526603464

Epoch: 5| Step: 5
Training loss: 3.6053534227898734
Validation loss: 3.228351253218145

Epoch: 5| Step: 6
Training loss: 3.4690952988326527
Validation loss: 3.2322675733000885

Epoch: 5| Step: 7
Training loss: 3.5193246321409513
Validation loss: 3.226116405921395

Epoch: 5| Step: 8
Training loss: 2.346727235005197
Validation loss: 3.2239916921969787

Epoch: 5| Step: 9
Training loss: 3.680398341885842
Validation loss: 3.2234878786546215

Epoch: 5| Step: 10
Training loss: 3.4555321498076808
Validation loss: 3.2214249000553212

Epoch: 86| Step: 0
Training loss: 3.1556018125997167
Validation loss: 3.2212401061905873

Epoch: 5| Step: 1
Training loss: 4.397149393701258
Validation loss: 3.221898959152236

Epoch: 5| Step: 2
Training loss: 3.8562879068993845
Validation loss: 3.22180134212523

Epoch: 5| Step: 3
Training loss: 2.9957617385508213
Validation loss: 3.221378384652468

Epoch: 5| Step: 4
Training loss: 3.430153782458372
Validation loss: 3.220393671439134

Epoch: 5| Step: 5
Training loss: 3.306569242298393
Validation loss: 3.2205586276716347

Epoch: 5| Step: 6
Training loss: 3.8199656198362515
Validation loss: 3.221180739621982

Epoch: 5| Step: 7
Training loss: 3.299243094598126
Validation loss: 3.220013117451727

Epoch: 5| Step: 8
Training loss: 3.4380595358708352
Validation loss: 3.221273325810506

Epoch: 5| Step: 9
Training loss: 2.8228932247150422
Validation loss: 3.21931772216208

Epoch: 5| Step: 10
Training loss: 3.267130673469369
Validation loss: 3.218591219614356

Epoch: 87| Step: 0
Training loss: 4.140223991121165
Validation loss: 3.218299661384807

Epoch: 5| Step: 1
Training loss: 2.900011319105486
Validation loss: 3.2182100143542356

Epoch: 5| Step: 2
Training loss: 3.6905294355896436
Validation loss: 3.217902535813085

Epoch: 5| Step: 3
Training loss: 2.678352134447114
Validation loss: 3.2168354728671287

Epoch: 5| Step: 4
Training loss: 2.9444000692642467
Validation loss: 3.2178708915026712

Epoch: 5| Step: 5
Training loss: 3.3244118191766563
Validation loss: 3.217851403647009

Epoch: 5| Step: 6
Training loss: 4.1103215160980096
Validation loss: 3.2154989401629424

Epoch: 5| Step: 7
Training loss: 3.125171351503358
Validation loss: 3.217743649871507

Epoch: 5| Step: 8
Training loss: 3.5364142271427284
Validation loss: 3.216404539081205

Epoch: 5| Step: 9
Training loss: 3.619564453605056
Validation loss: 3.2152459401343867

Epoch: 5| Step: 10
Training loss: 3.6923351592485014
Validation loss: 3.217750927103516

Epoch: 88| Step: 0
Training loss: 3.763551133044758
Validation loss: 3.2172738360147726

Epoch: 5| Step: 1
Training loss: 3.7734735143613274
Validation loss: 3.2178622617615984

Epoch: 5| Step: 2
Training loss: 3.1628242236009534
Validation loss: 3.2206211674536545

Epoch: 5| Step: 3
Training loss: 3.424607392244493
Validation loss: 3.216215935183431

Epoch: 5| Step: 4
Training loss: 3.5249201664102165
Validation loss: 3.2206088245279267

Epoch: 5| Step: 5
Training loss: 3.3531228725856774
Validation loss: 3.2208960571302954

Epoch: 5| Step: 6
Training loss: 3.0776001148688916
Validation loss: 3.220982536463391

Epoch: 5| Step: 7
Training loss: 3.470916071741752
Validation loss: 3.216402556016018

Epoch: 5| Step: 8
Training loss: 2.63550156367369
Validation loss: 3.215050694615796

Epoch: 5| Step: 9
Training loss: 3.083775016148183
Validation loss: 3.212742404116408

Epoch: 5| Step: 10
Training loss: 4.5875064693893846
Validation loss: 3.2129631618023065

Epoch: 89| Step: 0
Training loss: 3.6342962044909792
Validation loss: 3.2135488459825887

Epoch: 5| Step: 1
Training loss: 2.9267128453127165
Validation loss: 3.213041152916313

Epoch: 5| Step: 2
Training loss: 3.464109736539053
Validation loss: 3.213629568704719

Epoch: 5| Step: 3
Training loss: 3.7014603233163865
Validation loss: 3.213533402907956

Epoch: 5| Step: 4
Training loss: 3.423415581873726
Validation loss: 3.21447809880354

Epoch: 5| Step: 5
Training loss: 3.003056399765635
Validation loss: 3.214708503156245

Epoch: 5| Step: 6
Training loss: 3.3348215277871143
Validation loss: 3.2141543031241953

Epoch: 5| Step: 7
Training loss: 3.5683029830143163
Validation loss: 3.2179484880240072

Epoch: 5| Step: 8
Training loss: 3.0661925806329124
Validation loss: 3.220431500195467

Epoch: 5| Step: 9
Training loss: 4.543640874210772
Validation loss: 3.2231551921744783

Epoch: 5| Step: 10
Training loss: 3.007786817564867
Validation loss: 3.2186094134482084

Epoch: 90| Step: 0
Training loss: 3.622548556953426
Validation loss: 3.2109564286191463

Epoch: 5| Step: 1
Training loss: 4.214673142254916
Validation loss: 3.2111460120494733

Epoch: 5| Step: 2
Training loss: 3.3376483327070674
Validation loss: 3.210171552603884

Epoch: 5| Step: 3
Training loss: 4.1970336338719685
Validation loss: 3.212139362496122

Epoch: 5| Step: 4
Training loss: 2.755108163859973
Validation loss: 3.217719051845025

Epoch: 5| Step: 5
Training loss: 3.2958493919961938
Validation loss: 3.2172533779741155

Epoch: 5| Step: 6
Training loss: 3.1315936906915467
Validation loss: 3.2109640613528474

Epoch: 5| Step: 7
Training loss: 3.3068589455577673
Validation loss: 3.2114396215274246

Epoch: 5| Step: 8
Training loss: 3.513292683384915
Validation loss: 3.210199522622615

Epoch: 5| Step: 9
Training loss: 2.648270683323761
Validation loss: 3.2099089783996915

Epoch: 5| Step: 10
Training loss: 3.673685869122486
Validation loss: 3.210408954608836

Epoch: 91| Step: 0
Training loss: 3.6580649541778745
Validation loss: 3.210135452519824

Epoch: 5| Step: 1
Training loss: 3.1235778624391175
Validation loss: 3.2099557526492273

Epoch: 5| Step: 2
Training loss: 3.453736402144502
Validation loss: 3.2095463354392924

Epoch: 5| Step: 3
Training loss: 3.816617149687031
Validation loss: 3.208775554704643

Epoch: 5| Step: 4
Training loss: 3.4133990099171414
Validation loss: 3.2079542810018062

Epoch: 5| Step: 5
Training loss: 2.8736983960244467
Validation loss: 3.2078625299352175

Epoch: 5| Step: 6
Training loss: 3.3249310134958945
Validation loss: 3.2079377896744674

Epoch: 5| Step: 7
Training loss: 3.9665263997984246
Validation loss: 3.2076229645588

Epoch: 5| Step: 8
Training loss: 3.612751887954452
Validation loss: 3.2075454715136167

Epoch: 5| Step: 9
Training loss: 3.4337406756285223
Validation loss: 3.20714469617985

Epoch: 5| Step: 10
Training loss: 3.0940682603917096
Validation loss: 3.20684200129821

Epoch: 92| Step: 0
Training loss: 3.585374709036591
Validation loss: 3.2060031880548316

Epoch: 5| Step: 1
Training loss: 3.75341501505063
Validation loss: 3.2063946523216638

Epoch: 5| Step: 2
Training loss: 3.905860942539252
Validation loss: 3.2050733945749323

Epoch: 5| Step: 3
Training loss: 3.7063643696782314
Validation loss: 3.2062484243231117

Epoch: 5| Step: 4
Training loss: 2.9025527242230296
Validation loss: 3.2061801917433113

Epoch: 5| Step: 5
Training loss: 3.5069088186000927
Validation loss: 3.2054298814103315

Epoch: 5| Step: 6
Training loss: 3.9775063344544153
Validation loss: 3.205785378570168

Epoch: 5| Step: 7
Training loss: 2.9832253363755097
Validation loss: 3.2068828670192495

Epoch: 5| Step: 8
Training loss: 2.892487621758961
Validation loss: 3.2053457257912688

Epoch: 5| Step: 9
Training loss: 3.3945452971875634
Validation loss: 3.2031273258339845

Epoch: 5| Step: 10
Training loss: 3.0254440549167576
Validation loss: 3.204193038017943

Epoch: 93| Step: 0
Training loss: 3.5065385505953763
Validation loss: 3.2031240523782363

Epoch: 5| Step: 1
Training loss: 2.9814472317181835
Validation loss: 3.2050946374402227

Epoch: 5| Step: 2
Training loss: 3.7128058619006814
Validation loss: 3.2037797428260117

Epoch: 5| Step: 3
Training loss: 3.470391787087416
Validation loss: 3.203191073516784

Epoch: 5| Step: 4
Training loss: 4.170110322147
Validation loss: 3.202585431305634

Epoch: 5| Step: 5
Training loss: 3.809852306076472
Validation loss: 3.20358207716911

Epoch: 5| Step: 6
Training loss: 2.4899563263889224
Validation loss: 3.203440723321074

Epoch: 5| Step: 7
Training loss: 4.158183859748702
Validation loss: 3.202340050618019

Epoch: 5| Step: 8
Training loss: 3.03348954046561
Validation loss: 3.2009160302209283

Epoch: 5| Step: 9
Training loss: 2.7791269321451235
Validation loss: 3.2012455390256225

Epoch: 5| Step: 10
Training loss: 3.3638711338920415
Validation loss: 3.2004957884062724

Epoch: 94| Step: 0
Training loss: 3.199597309524315
Validation loss: 3.201473588527202

Epoch: 5| Step: 1
Training loss: 2.7446899298694394
Validation loss: 3.2010656091900347

Epoch: 5| Step: 2
Training loss: 3.6572465109185592
Validation loss: 3.200979797915023

Epoch: 5| Step: 3
Training loss: 3.1498562855709746
Validation loss: 3.201098529624337

Epoch: 5| Step: 4
Training loss: 3.765009026383602
Validation loss: 3.200168166689654

Epoch: 5| Step: 5
Training loss: 3.5984267611887906
Validation loss: 3.2006290967204647

Epoch: 5| Step: 6
Training loss: 3.6378102697859274
Validation loss: 3.1997587277736703

Epoch: 5| Step: 7
Training loss: 2.652493052711701
Validation loss: 3.1997159947860854

Epoch: 5| Step: 8
Training loss: 4.2002324357883385
Validation loss: 3.1983982220771265

Epoch: 5| Step: 9
Training loss: 4.030025799008467
Validation loss: 3.198839708096096

Epoch: 5| Step: 10
Training loss: 2.7732951382916795
Validation loss: 3.1977039146272688

Epoch: 95| Step: 0
Training loss: 3.7952648877564927
Validation loss: 3.1985813540483043

Epoch: 5| Step: 1
Training loss: 3.5719034669397534
Validation loss: 3.1951005154652337

Epoch: 5| Step: 2
Training loss: 3.327742433722928
Validation loss: 3.198869182889932

Epoch: 5| Step: 3
Training loss: 2.990503220584974
Validation loss: 3.1977415403980305

Epoch: 5| Step: 4
Training loss: 2.8623634938837106
Validation loss: 3.1971534207524765

Epoch: 5| Step: 5
Training loss: 3.737003821669358
Validation loss: 3.197895507860079

Epoch: 5| Step: 6
Training loss: 2.7799210534446854
Validation loss: 3.1977293208096955

Epoch: 5| Step: 7
Training loss: 3.283760636177742
Validation loss: 3.1968077224973626

Epoch: 5| Step: 8
Training loss: 3.5503007251002643
Validation loss: 3.1978625440304795

Epoch: 5| Step: 9
Training loss: 3.6729677562799097
Validation loss: 3.197035329976271

Epoch: 5| Step: 10
Training loss: 4.157069304746767
Validation loss: 3.1979887232963446

Epoch: 96| Step: 0
Training loss: 2.98131304340362
Validation loss: 3.1968051346433537

Epoch: 5| Step: 1
Training loss: 3.7564493034411806
Validation loss: 3.1963664795556923

Epoch: 5| Step: 2
Training loss: 3.0442919614834794
Validation loss: 3.1979649080405155

Epoch: 5| Step: 3
Training loss: 3.469183679912071
Validation loss: 3.1932908886898677

Epoch: 5| Step: 4
Training loss: 3.840943094711444
Validation loss: 3.19516690175197

Epoch: 5| Step: 5
Training loss: 3.5604188428365813
Validation loss: 3.1940506843283423

Epoch: 5| Step: 6
Training loss: 3.3065389582624496
Validation loss: 3.194749894295643

Epoch: 5| Step: 7
Training loss: 3.2237206753021588
Validation loss: 3.1950764138986383

Epoch: 5| Step: 8
Training loss: 3.4436284315525634
Validation loss: 3.1941907169029506

Epoch: 5| Step: 9
Training loss: 3.2468022974445807
Validation loss: 3.193001368718157

Epoch: 5| Step: 10
Training loss: 3.9017469161649547
Validation loss: 3.191420184727682

Epoch: 97| Step: 0
Training loss: 2.7912427570882836
Validation loss: 3.1919496424358376

Epoch: 5| Step: 1
Training loss: 3.8989186572903765
Validation loss: 3.187457177463454

Epoch: 5| Step: 2
Training loss: 3.75617447204316
Validation loss: 3.1874169248966346

Epoch: 5| Step: 3
Training loss: 2.9846309532134594
Validation loss: 3.18441263268172

Epoch: 5| Step: 4
Training loss: 3.0157663579037197
Validation loss: 3.1818252580710773

Epoch: 5| Step: 5
Training loss: 4.119993697596795
Validation loss: 3.1792780538540053

Epoch: 5| Step: 6
Training loss: 3.903274012852439
Validation loss: 3.177054724252649

Epoch: 5| Step: 7
Training loss: 3.242229709580285
Validation loss: 3.173312703702649

Epoch: 5| Step: 8
Training loss: 3.034400011110796
Validation loss: 3.1705656777710898

Epoch: 5| Step: 9
Training loss: 3.439706683628267
Validation loss: 3.172576996344985

Epoch: 5| Step: 10
Training loss: 3.1658595880348743
Validation loss: 3.1701005965112086

Epoch: 98| Step: 0
Training loss: 3.3580515538995916
Validation loss: 3.168991537771527

Epoch: 5| Step: 1
Training loss: 3.327303646264248
Validation loss: 3.168768936750786

Epoch: 5| Step: 2
Training loss: 3.2396406718553306
Validation loss: 3.1668225289432774

Epoch: 5| Step: 3
Training loss: 2.969193114288622
Validation loss: 3.1697073010941414

Epoch: 5| Step: 4
Training loss: 3.878723693424062
Validation loss: 3.1711726348324802

Epoch: 5| Step: 5
Training loss: 3.151712914633033
Validation loss: 3.167727639697549

Epoch: 5| Step: 6
Training loss: 2.912873462750752
Validation loss: 3.166770088717607

Epoch: 5| Step: 7
Training loss: 3.44011103561759
Validation loss: 3.1702294212389477

Epoch: 5| Step: 8
Training loss: 3.4822022373600015
Validation loss: 3.1669122997885437

Epoch: 5| Step: 9
Training loss: 3.913564197244265
Validation loss: 3.1660715724879434

Epoch: 5| Step: 10
Training loss: 3.7870880960512943
Validation loss: 3.16618756964533

Epoch: 99| Step: 0
Training loss: 3.303401326988357
Validation loss: 3.166611475590396

Epoch: 5| Step: 1
Training loss: 4.459866744304489
Validation loss: 3.166201128739102

Epoch: 5| Step: 2
Training loss: 3.2570611100945186
Validation loss: 3.1653199616418677

Epoch: 5| Step: 3
Training loss: 2.956136953761123
Validation loss: 3.164459506637332

Epoch: 5| Step: 4
Training loss: 3.10710697748424
Validation loss: 3.1638618497781192

Epoch: 5| Step: 5
Training loss: 3.4401060456187307
Validation loss: 3.1643719014343343

Epoch: 5| Step: 6
Training loss: 3.9660089593998697
Validation loss: 3.1649880523448357

Epoch: 5| Step: 7
Training loss: 3.416228770285341
Validation loss: 3.164274352068485

Epoch: 5| Step: 8
Training loss: 3.372309566067031
Validation loss: 3.1648716159288317

Epoch: 5| Step: 9
Training loss: 2.508114615332605
Validation loss: 3.162031622696781

Epoch: 5| Step: 10
Training loss: 3.3651895990564418
Validation loss: 3.1650768133410407

Epoch: 100| Step: 0
Training loss: 3.0391914712953403
Validation loss: 3.1660593796571312

Epoch: 5| Step: 1
Training loss: 3.5875870644242513
Validation loss: 3.1627366274106

Epoch: 5| Step: 2
Training loss: 3.425583871790457
Validation loss: 3.162169602493508

Epoch: 5| Step: 3
Training loss: 3.0869855815129346
Validation loss: 3.1624580677538368

Epoch: 5| Step: 4
Training loss: 3.7013506924151605
Validation loss: 3.1604084004698905

Epoch: 5| Step: 5
Training loss: 3.814637632346391
Validation loss: 3.1596851383812545

Epoch: 5| Step: 6
Training loss: 3.5616966814184563
Validation loss: 3.1589093517934828

Epoch: 5| Step: 7
Training loss: 3.7866847807043524
Validation loss: 3.1581200861263756

Epoch: 5| Step: 8
Training loss: 2.0845815987979743
Validation loss: 3.1592219690575623

Epoch: 5| Step: 9
Training loss: 3.6770785208320285
Validation loss: 3.158072237287746

Epoch: 5| Step: 10
Training loss: 3.3679383894388795
Validation loss: 3.158542684485316

Testing loss: 3.334886761137219
