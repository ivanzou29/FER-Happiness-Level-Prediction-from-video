Epoch: 1| Step: 0
Training loss: 6.350129325931456
Validation loss: 5.789887780180546

Epoch: 5| Step: 1
Training loss: 6.141587509549235
Validation loss: 5.779000616442474

Epoch: 5| Step: 2
Training loss: 5.3771929148765745
Validation loss: 5.768551986336143

Epoch: 5| Step: 3
Training loss: 5.088257994174746
Validation loss: 5.7587472350569415

Epoch: 5| Step: 4
Training loss: 6.118345421419159
Validation loss: 5.747730818560824

Epoch: 5| Step: 5
Training loss: 5.846024504091768
Validation loss: 5.735536948305567

Epoch: 5| Step: 6
Training loss: 6.271886422413459
Validation loss: 5.7233862581823916

Epoch: 5| Step: 7
Training loss: 5.714949882601293
Validation loss: 5.7105411864328115

Epoch: 5| Step: 8
Training loss: 5.857871551907941
Validation loss: 5.696155411841949

Epoch: 5| Step: 9
Training loss: 5.824741393803462
Validation loss: 5.681913090872459

Epoch: 5| Step: 10
Training loss: 4.428844984017397
Validation loss: 5.665972257529053

Epoch: 2| Step: 0
Training loss: 4.151279316620313
Validation loss: 5.649238936347828

Epoch: 5| Step: 1
Training loss: 6.149214233815519
Validation loss: 5.63131430197242

Epoch: 5| Step: 2
Training loss: 5.4438238092930575
Validation loss: 5.612596801212438

Epoch: 5| Step: 3
Training loss: 5.925687906112212
Validation loss: 5.591572912416327

Epoch: 5| Step: 4
Training loss: 6.179795834523701
Validation loss: 5.569778571201699

Epoch: 5| Step: 5
Training loss: 5.693563729179855
Validation loss: 5.5460698653941805

Epoch: 5| Step: 6
Training loss: 6.051504329576152
Validation loss: 5.521825292732541

Epoch: 5| Step: 7
Training loss: 5.269395514027387
Validation loss: 5.49458196772821

Epoch: 5| Step: 8
Training loss: 5.776971997209522
Validation loss: 5.466479784149457

Epoch: 5| Step: 9
Training loss: 4.528158672410278
Validation loss: 5.4369396146788125

Epoch: 5| Step: 10
Training loss: 5.857110890690038
Validation loss: 5.406149108389148

Epoch: 3| Step: 0
Training loss: 5.791171741150322
Validation loss: 5.373946471774129

Epoch: 5| Step: 1
Training loss: 3.790773363346949
Validation loss: 5.339400765729855

Epoch: 5| Step: 2
Training loss: 6.277885181029628
Validation loss: 5.305778367452334

Epoch: 5| Step: 3
Training loss: 5.379210663646814
Validation loss: 5.270317039055963

Epoch: 5| Step: 4
Training loss: 4.741278622553685
Validation loss: 5.236025643249794

Epoch: 5| Step: 5
Training loss: 5.72112054106198
Validation loss: 5.200805231684587

Epoch: 5| Step: 6
Training loss: 5.176433110483941
Validation loss: 5.16596648400312

Epoch: 5| Step: 7
Training loss: 5.69190623876214
Validation loss: 5.131651143326244

Epoch: 5| Step: 8
Training loss: 5.567484818751754
Validation loss: 5.097305783052215

Epoch: 5| Step: 9
Training loss: 4.6619467481192665
Validation loss: 5.063877450542779

Epoch: 5| Step: 10
Training loss: 4.406427041683731
Validation loss: 5.030055255875477

Epoch: 4| Step: 0
Training loss: 4.7232232522531685
Validation loss: 4.997541848817836

Epoch: 5| Step: 1
Training loss: 5.1826640188610975
Validation loss: 4.964869173375541

Epoch: 5| Step: 2
Training loss: 6.029757141992225
Validation loss: 4.930389060552862

Epoch: 5| Step: 3
Training loss: 4.996273177729967
Validation loss: 4.896671226433054

Epoch: 5| Step: 4
Training loss: 4.784000577920222
Validation loss: 4.8627705911116115

Epoch: 5| Step: 5
Training loss: 4.4262748907596485
Validation loss: 4.830246399265917

Epoch: 5| Step: 6
Training loss: 5.11756171103104
Validation loss: 4.797914265828521

Epoch: 5| Step: 7
Training loss: 5.270098769476627
Validation loss: 4.7661318112263515

Epoch: 5| Step: 8
Training loss: 4.182288043573631
Validation loss: 4.73585921105724

Epoch: 5| Step: 9
Training loss: 4.020307490037687
Validation loss: 4.705558463727608

Epoch: 5| Step: 10
Training loss: 5.07150202876414
Validation loss: 4.676894986891274

Epoch: 5| Step: 0
Training loss: 4.663320817873786
Validation loss: 4.648592658076102

Epoch: 5| Step: 1
Training loss: 4.862899042147205
Validation loss: 4.6195097677025325

Epoch: 5| Step: 2
Training loss: 5.17013363752176
Validation loss: 4.591529613729159

Epoch: 5| Step: 3
Training loss: 4.780013579026092
Validation loss: 4.563931629229426

Epoch: 5| Step: 4
Training loss: 5.536243663034023
Validation loss: 4.534771324340417

Epoch: 5| Step: 5
Training loss: 4.669289578430141
Validation loss: 4.50966506254897

Epoch: 5| Step: 6
Training loss: 4.185275953303181
Validation loss: 4.482370933868623

Epoch: 5| Step: 7
Training loss: 4.149353271096518
Validation loss: 4.45937933088124

Epoch: 5| Step: 8
Training loss: 3.88665421782169
Validation loss: 4.438070209477465

Epoch: 5| Step: 9
Training loss: 4.738966726359758
Validation loss: 4.416434617233869

Epoch: 5| Step: 10
Training loss: 3.8579366992287922
Validation loss: 4.396313802245111

Epoch: 6| Step: 0
Training loss: 5.182059502952342
Validation loss: 4.378150836654939

Epoch: 5| Step: 1
Training loss: 4.367326601164075
Validation loss: 4.36038763504018

Epoch: 5| Step: 2
Training loss: 4.307609549450551
Validation loss: 4.3419410194844765

Epoch: 5| Step: 3
Training loss: 3.8062235964405815
Validation loss: 4.326567134950167

Epoch: 5| Step: 4
Training loss: 3.884670250643907
Validation loss: 4.309695101650674

Epoch: 5| Step: 5
Training loss: 3.94398642434343
Validation loss: 4.296297508952168

Epoch: 5| Step: 6
Training loss: 4.420004081551579
Validation loss: 4.283960751151582

Epoch: 5| Step: 7
Training loss: 5.259460644356154
Validation loss: 4.273688057022692

Epoch: 5| Step: 8
Training loss: 4.261925514862769
Validation loss: 4.259798869776489

Epoch: 5| Step: 9
Training loss: 4.422784610644995
Validation loss: 4.243187672633513

Epoch: 5| Step: 10
Training loss: 4.593055724533709
Validation loss: 4.231855091502468

Epoch: 7| Step: 0
Training loss: 3.7513838439879867
Validation loss: 4.220157286784265

Epoch: 5| Step: 1
Training loss: 4.454348105055961
Validation loss: 4.207482953303236

Epoch: 5| Step: 2
Training loss: 4.919272082685235
Validation loss: 4.197423435064935

Epoch: 5| Step: 3
Training loss: 4.191574164419625
Validation loss: 4.186473107699266

Epoch: 5| Step: 4
Training loss: 4.474787761407635
Validation loss: 4.174473987975031

Epoch: 5| Step: 5
Training loss: 4.262607946734999
Validation loss: 4.16187873078429

Epoch: 5| Step: 6
Training loss: 5.23475048938889
Validation loss: 4.151320114530979

Epoch: 5| Step: 7
Training loss: 3.8112157941354847
Validation loss: 4.139377758284475

Epoch: 5| Step: 8
Training loss: 4.539500965469985
Validation loss: 4.132319477438873

Epoch: 5| Step: 9
Training loss: 3.247679542235905
Validation loss: 4.123971584044849

Epoch: 5| Step: 10
Training loss: 4.0438744456556215
Validation loss: 4.116333079803963

Epoch: 8| Step: 0
Training loss: 4.8725865576675895
Validation loss: 4.108820894981548

Epoch: 5| Step: 1
Training loss: 3.866312440453698
Validation loss: 4.101201085947306

Epoch: 5| Step: 2
Training loss: 4.049560362890079
Validation loss: 4.0934217080738655

Epoch: 5| Step: 3
Training loss: 4.006454505402179
Validation loss: 4.086949183772489

Epoch: 5| Step: 4
Training loss: 4.086226210596403
Validation loss: 4.079636653164885

Epoch: 5| Step: 5
Training loss: 3.7200471555120638
Validation loss: 4.0721911048007104

Epoch: 5| Step: 6
Training loss: 4.542909131433826
Validation loss: 4.066098738145025

Epoch: 5| Step: 7
Training loss: 4.358985145118222
Validation loss: 4.058217151039471

Epoch: 5| Step: 8
Training loss: 3.6231859864213027
Validation loss: 4.0486375659902025

Epoch: 5| Step: 9
Training loss: 4.500427013906027
Validation loss: 4.041742186902691

Epoch: 5| Step: 10
Training loss: 4.642517115120263
Validation loss: 4.030881841531759

Epoch: 9| Step: 0
Training loss: 4.018269302784131
Validation loss: 4.024011343743211

Epoch: 5| Step: 1
Training loss: 4.429987390986769
Validation loss: 4.0146971193523635

Epoch: 5| Step: 2
Training loss: 3.947397176068961
Validation loss: 4.004002650131143

Epoch: 5| Step: 3
Training loss: 3.1738354867703085
Validation loss: 3.9932869780494222

Epoch: 5| Step: 4
Training loss: 4.321990254727894
Validation loss: 3.9841024300343726

Epoch: 5| Step: 5
Training loss: 3.073635176801769
Validation loss: 3.974019097938924

Epoch: 5| Step: 6
Training loss: 4.356112445427348
Validation loss: 3.9649831012973547

Epoch: 5| Step: 7
Training loss: 4.301340674830598
Validation loss: 3.9590304000017174

Epoch: 5| Step: 8
Training loss: 4.868881298248659
Validation loss: 3.9476065236120026

Epoch: 5| Step: 9
Training loss: 4.431770386693785
Validation loss: 3.9414072998068894

Epoch: 5| Step: 10
Training loss: 4.179118180049158
Validation loss: 3.9316131473630045

Epoch: 10| Step: 0
Training loss: 4.702154014956453
Validation loss: 3.9264250686393014

Epoch: 5| Step: 1
Training loss: 3.565574791410166
Validation loss: 3.9179577101452945

Epoch: 5| Step: 2
Training loss: 4.152768849873949
Validation loss: 3.908543952979404

Epoch: 5| Step: 3
Training loss: 3.7110333560810647
Validation loss: 3.899009411926535

Epoch: 5| Step: 4
Training loss: 4.10786973195855
Validation loss: 3.8901116245407583

Epoch: 5| Step: 5
Training loss: 4.085299323518919
Validation loss: 3.8830105142262186

Epoch: 5| Step: 6
Training loss: 4.268723476880449
Validation loss: 3.874236407086492

Epoch: 5| Step: 7
Training loss: 3.7084105551462367
Validation loss: 3.86797025648877

Epoch: 5| Step: 8
Training loss: 4.0824062047439895
Validation loss: 3.8593464551778998

Epoch: 5| Step: 9
Training loss: 4.508899577477887
Validation loss: 3.852612026174603

Epoch: 5| Step: 10
Training loss: 3.354055193515739
Validation loss: 3.8424873215619395

Epoch: 11| Step: 0
Training loss: 4.165360640245411
Validation loss: 3.8371019020696835

Epoch: 5| Step: 1
Training loss: 4.291724318823866
Validation loss: 3.828899166807009

Epoch: 5| Step: 2
Training loss: 4.11854140081943
Validation loss: 3.821225938529066

Epoch: 5| Step: 3
Training loss: 4.117471471617026
Validation loss: 3.813951941721422

Epoch: 5| Step: 4
Training loss: 3.5426503030985073
Validation loss: 3.8074124215823844

Epoch: 5| Step: 5
Training loss: 4.572702575167379
Validation loss: 3.798826616034232

Epoch: 5| Step: 6
Training loss: 4.11395542166244
Validation loss: 3.78896790346094

Epoch: 5| Step: 7
Training loss: 3.6050596656041516
Validation loss: 3.781040645191366

Epoch: 5| Step: 8
Training loss: 3.296909856386015
Validation loss: 3.773621122773554

Epoch: 5| Step: 9
Training loss: 4.272707693767145
Validation loss: 3.7640779122328514

Epoch: 5| Step: 10
Training loss: 3.2317032398385996
Validation loss: 3.754920755373842

Epoch: 12| Step: 0
Training loss: 4.282996496668952
Validation loss: 3.7493867748752727

Epoch: 5| Step: 1
Training loss: 3.0137397526076724
Validation loss: 3.7388452317990626

Epoch: 5| Step: 2
Training loss: 4.083145967713173
Validation loss: 3.7381719925865626

Epoch: 5| Step: 3
Training loss: 3.6301750863886597
Validation loss: 3.726231433446384

Epoch: 5| Step: 4
Training loss: 3.8875827154945544
Validation loss: 3.7221891212144573

Epoch: 5| Step: 5
Training loss: 3.9023736870488945
Validation loss: 3.7207607211537765

Epoch: 5| Step: 6
Training loss: 4.647396400614365
Validation loss: 3.715214702776271

Epoch: 5| Step: 7
Training loss: 3.9378762443861888
Validation loss: 3.7103862981315867

Epoch: 5| Step: 8
Training loss: 3.599106884479226
Validation loss: 3.7014757960236677

Epoch: 5| Step: 9
Training loss: 3.834635900250217
Validation loss: 3.69503462967138

Epoch: 5| Step: 10
Training loss: 3.8807120523197827
Validation loss: 3.687074524429746

Epoch: 13| Step: 0
Training loss: 3.8095624268935944
Validation loss: 3.680626809860992

Epoch: 5| Step: 1
Training loss: 3.2922978017440423
Validation loss: 3.671501908365622

Epoch: 5| Step: 2
Training loss: 3.470747776205813
Validation loss: 3.668243039048751

Epoch: 5| Step: 3
Training loss: 3.793997722249008
Validation loss: 3.6613641070737772

Epoch: 5| Step: 4
Training loss: 4.4680834719955405
Validation loss: 3.6552961921582527

Epoch: 5| Step: 5
Training loss: 3.83992558466809
Validation loss: 3.6497236070484513

Epoch: 5| Step: 6
Training loss: 4.644130423200377
Validation loss: 3.6439940962572015

Epoch: 5| Step: 7
Training loss: 3.8639119157090525
Validation loss: 3.6376051606468076

Epoch: 5| Step: 8
Training loss: 3.1875484687261646
Validation loss: 3.6344938528204547

Epoch: 5| Step: 9
Training loss: 3.714842338040281
Validation loss: 3.6294571967504408

Epoch: 5| Step: 10
Training loss: 3.9455827374961654
Validation loss: 3.622501138596242

Epoch: 14| Step: 0
Training loss: 4.346589182843723
Validation loss: 3.618534263813774

Epoch: 5| Step: 1
Training loss: 3.660733204968839
Validation loss: 3.6101228709565745

Epoch: 5| Step: 2
Training loss: 3.787040753109273
Validation loss: 3.6080581400005194

Epoch: 5| Step: 3
Training loss: 3.686056986218723
Validation loss: 3.602573262818712

Epoch: 5| Step: 4
Training loss: 3.6009509049331356
Validation loss: 3.592784060887758

Epoch: 5| Step: 5
Training loss: 3.2642284856932924
Validation loss: 3.5892230883460785

Epoch: 5| Step: 6
Training loss: 4.172376509679513
Validation loss: 3.58036097746966

Epoch: 5| Step: 7
Training loss: 3.3393591456721423
Validation loss: 3.5756209974815043

Epoch: 5| Step: 8
Training loss: 3.9117185842164686
Validation loss: 3.572688563473437

Epoch: 5| Step: 9
Training loss: 4.341728124104237
Validation loss: 3.56665774832956

Epoch: 5| Step: 10
Training loss: 3.3027528551375354
Validation loss: 3.5615490772444356

Epoch: 15| Step: 0
Training loss: 3.4880790694575143
Validation loss: 3.5575297970840825

Epoch: 5| Step: 1
Training loss: 3.488659469758414
Validation loss: 3.5502623760778187

Epoch: 5| Step: 2
Training loss: 3.4428239688507403
Validation loss: 3.5492593155192416

Epoch: 5| Step: 3
Training loss: 4.6419094376052525
Validation loss: 3.5522613254653717

Epoch: 5| Step: 4
Training loss: 3.376464243548844
Validation loss: 3.5393776669411565

Epoch: 5| Step: 5
Training loss: 2.9777973647287928
Validation loss: 3.5432300444366116

Epoch: 5| Step: 6
Training loss: 4.266120183239882
Validation loss: 3.544633897558987

Epoch: 5| Step: 7
Training loss: 3.760837027741425
Validation loss: 3.542287187789162

Epoch: 5| Step: 8
Training loss: 3.2438639890895415
Validation loss: 3.540784323202611

Epoch: 5| Step: 9
Training loss: 3.8011853276740806
Validation loss: 3.5339524954449755

Epoch: 5| Step: 10
Training loss: 4.502418292128678
Validation loss: 3.5299606299712583

Epoch: 16| Step: 0
Training loss: 4.512563122759575
Validation loss: 3.5204492835103673

Epoch: 5| Step: 1
Training loss: 3.7300316998973035
Validation loss: 3.514396390450926

Epoch: 5| Step: 2
Training loss: 3.8281492894238984
Validation loss: 3.50895321020426

Epoch: 5| Step: 3
Training loss: 4.046134498038925
Validation loss: 3.50800323461091

Epoch: 5| Step: 4
Training loss: 3.144716548791196
Validation loss: 3.5005667062130277

Epoch: 5| Step: 5
Training loss: 3.5801656309630974
Validation loss: 3.4966334810117927

Epoch: 5| Step: 6
Training loss: 3.300806386276332
Validation loss: 3.4916474708755665

Epoch: 5| Step: 7
Training loss: 3.6206614082938358
Validation loss: 3.491898067637387

Epoch: 5| Step: 8
Training loss: 3.050290584792269
Validation loss: 3.4875153856029604

Epoch: 5| Step: 9
Training loss: 4.062474177351826
Validation loss: 3.48448347925918

Epoch: 5| Step: 10
Training loss: 3.679673504650933
Validation loss: 3.4787474059052577

Epoch: 17| Step: 0
Training loss: 3.7749289651212545
Validation loss: 3.476682785182125

Epoch: 5| Step: 1
Training loss: 2.751267401203897
Validation loss: 3.4711347765307927

Epoch: 5| Step: 2
Training loss: 4.207440398004325
Validation loss: 3.466963929272449

Epoch: 5| Step: 3
Training loss: 2.016581227197712
Validation loss: 3.462638961001421

Epoch: 5| Step: 4
Training loss: 3.433929392235929
Validation loss: 3.460528558515136

Epoch: 5| Step: 5
Training loss: 4.422298990687661
Validation loss: 3.4559878626421914

Epoch: 5| Step: 6
Training loss: 4.529193490424764
Validation loss: 3.455739148522251

Epoch: 5| Step: 7
Training loss: 3.3296715809850133
Validation loss: 3.4488558452831586

Epoch: 5| Step: 8
Training loss: 4.158743891710085
Validation loss: 3.447874561113814

Epoch: 5| Step: 9
Training loss: 3.4174597835337157
Validation loss: 3.4467085163565794

Epoch: 5| Step: 10
Training loss: 3.614108066296325
Validation loss: 3.4431441968199388

Epoch: 18| Step: 0
Training loss: 3.8943512625315972
Validation loss: 3.4421272434657344

Epoch: 5| Step: 1
Training loss: 3.5758135796840462
Validation loss: 3.4363956187585516

Epoch: 5| Step: 2
Training loss: 3.853518347296935
Validation loss: 3.432808215249957

Epoch: 5| Step: 3
Training loss: 3.8644519108363857
Validation loss: 3.43231242744035

Epoch: 5| Step: 4
Training loss: 3.6808646034350136
Validation loss: 3.4313195386331685

Epoch: 5| Step: 5
Training loss: 3.542157232679395
Validation loss: 3.4259166126025473

Epoch: 5| Step: 6
Training loss: 3.562513117180484
Validation loss: 3.4231118539270926

Epoch: 5| Step: 7
Training loss: 3.429975562717589
Validation loss: 3.4188125068625532

Epoch: 5| Step: 8
Training loss: 3.5720414998120327
Validation loss: 3.417869769232133

Epoch: 5| Step: 9
Training loss: 3.6940415114056693
Validation loss: 3.414365296999077

Epoch: 5| Step: 10
Training loss: 3.4274923124999264
Validation loss: 3.4122944616055633

Epoch: 19| Step: 0
Training loss: 3.73514309569426
Validation loss: 3.4119941015798565

Epoch: 5| Step: 1
Training loss: 3.745424658377476
Validation loss: 3.409559638153459

Epoch: 5| Step: 2
Training loss: 3.522500059345751
Validation loss: 3.4076673650797304

Epoch: 5| Step: 3
Training loss: 3.602852083641053
Validation loss: 3.40591205908602

Epoch: 5| Step: 4
Training loss: 2.7750584123666875
Validation loss: 3.404053227194104

Epoch: 5| Step: 5
Training loss: 3.4066763794742485
Validation loss: 3.403719905147674

Epoch: 5| Step: 6
Training loss: 3.607312690805049
Validation loss: 3.4016291485282033

Epoch: 5| Step: 7
Training loss: 3.815555786204888
Validation loss: 3.4009835642272987

Epoch: 5| Step: 8
Training loss: 3.5133048984986277
Validation loss: 3.39572073813149

Epoch: 5| Step: 9
Training loss: 4.225419713227278
Validation loss: 3.3973483137373655

Epoch: 5| Step: 10
Training loss: 3.8106121955094605
Validation loss: 3.3945655718591157

Epoch: 20| Step: 0
Training loss: 3.8784239623777337
Validation loss: 3.394303394988549

Epoch: 5| Step: 1
Training loss: 3.3279522058466244
Validation loss: 3.3925202635064093

Epoch: 5| Step: 2
Training loss: 3.733115905719986
Validation loss: 3.3911048810799556

Epoch: 5| Step: 3
Training loss: 3.9124153006163684
Validation loss: 3.3905724735500202

Epoch: 5| Step: 4
Training loss: 3.4338482967453636
Validation loss: 3.3912160785496597

Epoch: 5| Step: 5
Training loss: 4.032216983708954
Validation loss: 3.390814876291496

Epoch: 5| Step: 6
Training loss: 3.1170938807605086
Validation loss: 3.386208619029507

Epoch: 5| Step: 7
Training loss: 3.206208322116573
Validation loss: 3.3856269128731755

Epoch: 5| Step: 8
Training loss: 3.6969847171912287
Validation loss: 3.384282792929305

Epoch: 5| Step: 9
Training loss: 3.4367749923471074
Validation loss: 3.383271235194113

Epoch: 5| Step: 10
Training loss: 3.9052061593589045
Validation loss: 3.3796286053656837

Epoch: 21| Step: 0
Training loss: 3.636765951962742
Validation loss: 3.380167542870709

Epoch: 5| Step: 1
Training loss: 2.5544637879578636
Validation loss: 3.378465590608737

Epoch: 5| Step: 2
Training loss: 3.5804875332770183
Validation loss: 3.3798247822116445

Epoch: 5| Step: 3
Training loss: 4.201609965971657
Validation loss: 3.376249625123849

Epoch: 5| Step: 4
Training loss: 3.3451203007298527
Validation loss: 3.3760746969465187

Epoch: 5| Step: 5
Training loss: 3.6887853936023047
Validation loss: 3.369721555794353

Epoch: 5| Step: 6
Training loss: 3.0892958510946826
Validation loss: 3.368801927821723

Epoch: 5| Step: 7
Training loss: 3.821698208554101
Validation loss: 3.366423248788103

Epoch: 5| Step: 8
Training loss: 3.6096558564801824
Validation loss: 3.3649242313128265

Epoch: 5| Step: 9
Training loss: 4.102129564594673
Validation loss: 3.362303996706372

Epoch: 5| Step: 10
Training loss: 3.7127575717545973
Validation loss: 3.3584135167243283

Epoch: 22| Step: 0
Training loss: 4.34645446454389
Validation loss: 3.356788380061164

Epoch: 5| Step: 1
Training loss: 3.729922013886523
Validation loss: 3.359161658642098

Epoch: 5| Step: 2
Training loss: 3.568437680876577
Validation loss: 3.3563461443013716

Epoch: 5| Step: 3
Training loss: 3.3904598916633035
Validation loss: 3.3756255311140735

Epoch: 5| Step: 4
Training loss: 3.3070029946248187
Validation loss: 3.3565837385660764

Epoch: 5| Step: 5
Training loss: 3.5107523741594218
Validation loss: 3.348863620280261

Epoch: 5| Step: 6
Training loss: 2.9545704367054952
Validation loss: 3.3469911541316497

Epoch: 5| Step: 7
Training loss: 3.7757813813398746
Validation loss: 3.348955633655189

Epoch: 5| Step: 8
Training loss: 4.243251603850989
Validation loss: 3.347059655743934

Epoch: 5| Step: 9
Training loss: 3.0282425266130506
Validation loss: 3.346225972252038

Epoch: 5| Step: 10
Training loss: 3.2203270465313136
Validation loss: 3.34124221734989

Epoch: 23| Step: 0
Training loss: 4.393422386142895
Validation loss: 3.34608266782539

Epoch: 5| Step: 1
Training loss: 3.6529178922893433
Validation loss: 3.3425907137567337

Epoch: 5| Step: 2
Training loss: 3.1905809360192623
Validation loss: 3.349067118345133

Epoch: 5| Step: 3
Training loss: 3.7054097656085077
Validation loss: 3.347354398739432

Epoch: 5| Step: 4
Training loss: 3.6320685824754433
Validation loss: 3.3427808336706946

Epoch: 5| Step: 5
Training loss: 3.603995273167837
Validation loss: 3.3364883847534776

Epoch: 5| Step: 6
Training loss: 3.0595611172759205
Validation loss: 3.3349747559252987

Epoch: 5| Step: 7
Training loss: 3.5368025344891323
Validation loss: 3.336524516149905

Epoch: 5| Step: 8
Training loss: 3.447285405175192
Validation loss: 3.337974867406341

Epoch: 5| Step: 9
Training loss: 3.8712488291575133
Validation loss: 3.336353420262035

Epoch: 5| Step: 10
Training loss: 2.9211806834023477
Validation loss: 3.3338449613614527

Epoch: 24| Step: 0
Training loss: 3.6561943115166753
Validation loss: 3.3333978805650304

Epoch: 5| Step: 1
Training loss: 3.451523215129465
Validation loss: 3.3286896532388366

Epoch: 5| Step: 2
Training loss: 3.054540606232713
Validation loss: 3.3297978307128817

Epoch: 5| Step: 3
Training loss: 2.9226995110592195
Validation loss: 3.3290205956046335

Epoch: 5| Step: 4
Training loss: 3.5682635615472025
Validation loss: 3.3222027392073383

Epoch: 5| Step: 5
Training loss: 3.3529507978397737
Validation loss: 3.321504677431007

Epoch: 5| Step: 6
Training loss: 3.840146492309566
Validation loss: 3.317523686055156

Epoch: 5| Step: 7
Training loss: 3.5827911469479945
Validation loss: 3.315735578533748

Epoch: 5| Step: 8
Training loss: 4.116059758678404
Validation loss: 3.3172025141216994

Epoch: 5| Step: 9
Training loss: 3.240441718661741
Validation loss: 3.314754512142596

Epoch: 5| Step: 10
Training loss: 4.252145786502722
Validation loss: 3.3148967672662333

Epoch: 25| Step: 0
Training loss: 2.7499446863333574
Validation loss: 3.3122115919973676

Epoch: 5| Step: 1
Training loss: 4.648807799392063
Validation loss: 3.309777738425701

Epoch: 5| Step: 2
Training loss: 3.2712989686267857
Validation loss: 3.308426415327907

Epoch: 5| Step: 3
Training loss: 3.2098570999234077
Validation loss: 3.3121062695043566

Epoch: 5| Step: 4
Training loss: 3.803384859458763
Validation loss: 3.3070724113611742

Epoch: 5| Step: 5
Training loss: 3.2878708662862692
Validation loss: 3.3052635717678926

Epoch: 5| Step: 6
Training loss: 3.3026117970951434
Validation loss: 3.303846977842714

Epoch: 5| Step: 7
Training loss: 3.662386968645649
Validation loss: 3.3044210921148087

Epoch: 5| Step: 8
Training loss: 3.326512192201941
Validation loss: 3.3031688109570854

Epoch: 5| Step: 9
Training loss: 3.8777994687828783
Validation loss: 3.3091992746691723

Epoch: 5| Step: 10
Training loss: 3.5185063062608353
Validation loss: 3.3108402597596975

Epoch: 26| Step: 0
Training loss: 3.580196131016826
Validation loss: 3.309329218947068

Epoch: 5| Step: 1
Training loss: 2.971189119311466
Validation loss: 3.30326409871997

Epoch: 5| Step: 2
Training loss: 3.299856419763176
Validation loss: 3.2945686706019055

Epoch: 5| Step: 3
Training loss: 3.9190651604135627
Validation loss: 3.2961339801586953

Epoch: 5| Step: 4
Training loss: 3.998544189651614
Validation loss: 3.29406979120992

Epoch: 5| Step: 5
Training loss: 3.832097324186662
Validation loss: 3.2945401266914365

Epoch: 5| Step: 6
Training loss: 3.6392594424622686
Validation loss: 3.292752444466361

Epoch: 5| Step: 7
Training loss: 3.3069023483896025
Validation loss: 3.2895714594974357

Epoch: 5| Step: 8
Training loss: 3.322069129761974
Validation loss: 3.2895434769856395

Epoch: 5| Step: 9
Training loss: 3.3463072223067045
Validation loss: 3.283727662255

Epoch: 5| Step: 10
Training loss: 3.523474581030626
Validation loss: 3.285048360378243

Epoch: 27| Step: 0
Training loss: 3.218852217449307
Validation loss: 3.2868590666965725

Epoch: 5| Step: 1
Training loss: 3.683913474906894
Validation loss: 3.284988522142056

Epoch: 5| Step: 2
Training loss: 3.8098713301911267
Validation loss: 3.282491138466503

Epoch: 5| Step: 3
Training loss: 2.515211746675662
Validation loss: 3.2818119472231313

Epoch: 5| Step: 4
Training loss: 3.4787449533560935
Validation loss: 3.2772849288125085

Epoch: 5| Step: 5
Training loss: 3.428236113341075
Validation loss: 3.278272478884163

Epoch: 5| Step: 6
Training loss: 3.798484806345241
Validation loss: 3.2765540221485248

Epoch: 5| Step: 7
Training loss: 3.7549798325404686
Validation loss: 3.276809846994541

Epoch: 5| Step: 8
Training loss: 3.4794753312723197
Validation loss: 3.2750648656810637

Epoch: 5| Step: 9
Training loss: 3.5449856334658807
Validation loss: 3.2736757174974414

Epoch: 5| Step: 10
Training loss: 3.8534080927327414
Validation loss: 3.2775540601986775

Epoch: 28| Step: 0
Training loss: 3.187270511519007
Validation loss: 3.2752242364668507

Epoch: 5| Step: 1
Training loss: 3.279966993631046
Validation loss: 3.2824105854460237

Epoch: 5| Step: 2
Training loss: 3.0809014670697406
Validation loss: 3.269823198303294

Epoch: 5| Step: 3
Training loss: 4.0459845899966345
Validation loss: 3.269568020963786

Epoch: 5| Step: 4
Training loss: 3.4538609337568076
Validation loss: 3.2715330287968505

Epoch: 5| Step: 5
Training loss: 3.412532646945269
Validation loss: 3.2758590391968503

Epoch: 5| Step: 6
Training loss: 3.814971247973406
Validation loss: 3.272330347866253

Epoch: 5| Step: 7
Training loss: 3.598713507193974
Validation loss: 3.2687455827000873

Epoch: 5| Step: 8
Training loss: 3.700877606210768
Validation loss: 3.2692109716567006

Epoch: 5| Step: 9
Training loss: 3.8415934397792766
Validation loss: 3.2675394062884373

Epoch: 5| Step: 10
Training loss: 3.0138978113217183
Validation loss: 3.2687941282493527

Epoch: 29| Step: 0
Training loss: 3.51057512206805
Validation loss: 3.268335366845188

Epoch: 5| Step: 1
Training loss: 2.795187840845905
Validation loss: 3.2656427834237522

Epoch: 5| Step: 2
Training loss: 3.384841416220835
Validation loss: 3.2692506303927735

Epoch: 5| Step: 3
Training loss: 3.1533110882200948
Validation loss: 3.263768352818693

Epoch: 5| Step: 4
Training loss: 3.6786496263888013
Validation loss: 3.266900497775185

Epoch: 5| Step: 5
Training loss: 4.154033327912078
Validation loss: 3.2618767687108687

Epoch: 5| Step: 6
Training loss: 3.5492595437669805
Validation loss: 3.2590483608833942

Epoch: 5| Step: 7
Training loss: 4.072990839576301
Validation loss: 3.257825037199122

Epoch: 5| Step: 8
Training loss: 2.7018900790158864
Validation loss: 3.2594447378615077

Epoch: 5| Step: 9
Training loss: 3.518899028867724
Validation loss: 3.258986928236841

Epoch: 5| Step: 10
Training loss: 3.7724337615106447
Validation loss: 3.259467307956382

Epoch: 30| Step: 0
Training loss: 3.3872809026041777
Validation loss: 3.259410279940313

Epoch: 5| Step: 1
Training loss: 3.2928450845143553
Validation loss: 3.2591023306034352

Epoch: 5| Step: 2
Training loss: 3.1068374784387482
Validation loss: 3.2583919346362205

Epoch: 5| Step: 3
Training loss: 3.3888410102783424
Validation loss: 3.2757319166298045

Epoch: 5| Step: 4
Training loss: 3.728157006227868
Validation loss: 3.261720345535856

Epoch: 5| Step: 5
Training loss: 4.327595702489893
Validation loss: 3.257600603648657

Epoch: 5| Step: 6
Training loss: 3.2727635675402147
Validation loss: 3.255293080004036

Epoch: 5| Step: 7
Training loss: 3.6071618631339715
Validation loss: 3.2537475306140484

Epoch: 5| Step: 8
Training loss: 3.1052967719675664
Validation loss: 3.253231395235255

Epoch: 5| Step: 9
Training loss: 3.5703169073499192
Validation loss: 3.250751294934777

Epoch: 5| Step: 10
Training loss: 3.5317154299106055
Validation loss: 3.2522790662385526

Epoch: 31| Step: 0
Training loss: 3.875564287999238
Validation loss: 3.249118477133976

Epoch: 5| Step: 1
Training loss: 3.350455147868119
Validation loss: 3.2490605021043764

Epoch: 5| Step: 2
Training loss: 3.2471202416274063
Validation loss: 3.2494453512214756

Epoch: 5| Step: 3
Training loss: 3.4235953966200943
Validation loss: 3.250036417691611

Epoch: 5| Step: 4
Training loss: 3.3005139846493927
Validation loss: 3.2559327135258083

Epoch: 5| Step: 5
Training loss: 2.842521318206428
Validation loss: 3.2592981306882383

Epoch: 5| Step: 6
Training loss: 3.7793072209968206
Validation loss: 3.2553535412631396

Epoch: 5| Step: 7
Training loss: 2.9536064603187278
Validation loss: 3.256284101686053

Epoch: 5| Step: 8
Training loss: 3.641691125457356
Validation loss: 3.2507699570262005

Epoch: 5| Step: 9
Training loss: 4.23610277574619
Validation loss: 3.2439833055032277

Epoch: 5| Step: 10
Training loss: 3.5749364247037776
Validation loss: 3.2435356514904865

Epoch: 32| Step: 0
Training loss: 2.7810025908764318
Validation loss: 3.242325776985546

Epoch: 5| Step: 1
Training loss: 3.5578446337790455
Validation loss: 3.2452801587042615

Epoch: 5| Step: 2
Training loss: 3.238910977342976
Validation loss: 3.2465285131522985

Epoch: 5| Step: 3
Training loss: 3.0348027439525866
Validation loss: 3.2469067687043642

Epoch: 5| Step: 4
Training loss: 3.227246080452178
Validation loss: 3.246825816858463

Epoch: 5| Step: 5
Training loss: 3.9543467205658884
Validation loss: 3.241184635092275

Epoch: 5| Step: 6
Training loss: 3.3280706983264468
Validation loss: 3.237995345815879

Epoch: 5| Step: 7
Training loss: 3.938627898933501
Validation loss: 3.238317042653852

Epoch: 5| Step: 8
Training loss: 4.043952269411125
Validation loss: 3.235475651408095

Epoch: 5| Step: 9
Training loss: 3.247569128744095
Validation loss: 3.2375415679762813

Epoch: 5| Step: 10
Training loss: 3.8116680550805553
Validation loss: 3.2385800018720956

Epoch: 33| Step: 0
Training loss: 2.6636257316999736
Validation loss: 3.239275032353409

Epoch: 5| Step: 1
Training loss: 3.512791012692406
Validation loss: 3.244418580611483

Epoch: 5| Step: 2
Training loss: 3.75629176975073
Validation loss: 3.248360782883758

Epoch: 5| Step: 3
Training loss: 3.0559926866673544
Validation loss: 3.241515627750683

Epoch: 5| Step: 4
Training loss: 3.451798404283761
Validation loss: 3.2356440102729946

Epoch: 5| Step: 5
Training loss: 3.6418574134110053
Validation loss: 3.232408623029545

Epoch: 5| Step: 6
Training loss: 4.0836639789434095
Validation loss: 3.232003324741898

Epoch: 5| Step: 7
Training loss: 3.234471416418443
Validation loss: 3.2299268089176913

Epoch: 5| Step: 8
Training loss: 3.9346250907548184
Validation loss: 3.232319932804862

Epoch: 5| Step: 9
Training loss: 3.605765647690778
Validation loss: 3.230442101419167

Epoch: 5| Step: 10
Training loss: 3.0293341805911336
Validation loss: 3.231613439466952

Epoch: 34| Step: 0
Training loss: 3.8142106017691835
Validation loss: 3.232052904422483

Epoch: 5| Step: 1
Training loss: 4.285925991642292
Validation loss: 3.230367917532434

Epoch: 5| Step: 2
Training loss: 3.4945016997444145
Validation loss: 3.227601063527652

Epoch: 5| Step: 3
Training loss: 3.382809962740821
Validation loss: 3.226875831641221

Epoch: 5| Step: 4
Training loss: 2.4545538561770313
Validation loss: 3.2292984209495446

Epoch: 5| Step: 5
Training loss: 3.6897520526813334
Validation loss: 3.2261610674522205

Epoch: 5| Step: 6
Training loss: 3.452638065303885
Validation loss: 3.2249477876692856

Epoch: 5| Step: 7
Training loss: 3.1305360204686448
Validation loss: 3.227071597823795

Epoch: 5| Step: 8
Training loss: 2.4765444974515733
Validation loss: 3.227920220743017

Epoch: 5| Step: 9
Training loss: 3.898383436420589
Validation loss: 3.224724916893553

Epoch: 5| Step: 10
Training loss: 3.7374908345087765
Validation loss: 3.2229844246355555

Epoch: 35| Step: 0
Training loss: 3.33596808890762
Validation loss: 3.224991769820689

Epoch: 5| Step: 1
Training loss: 3.40784787837873
Validation loss: 3.226339265597027

Epoch: 5| Step: 2
Training loss: 4.467238163802529
Validation loss: 3.2254184771588386

Epoch: 5| Step: 3
Training loss: 2.929804196894583
Validation loss: 3.2236191657328335

Epoch: 5| Step: 4
Training loss: 3.403495724945051
Validation loss: 3.2252791366992017

Epoch: 5| Step: 5
Training loss: 3.4722213558619797
Validation loss: 3.222489537973141

Epoch: 5| Step: 6
Training loss: 3.225395083808381
Validation loss: 3.2210450584639605

Epoch: 5| Step: 7
Training loss: 3.6837287627282054
Validation loss: 3.220970381168161

Epoch: 5| Step: 8
Training loss: 2.5637126937376378
Validation loss: 3.221625273888443

Epoch: 5| Step: 9
Training loss: 3.674458864815165
Validation loss: 3.218586531352088

Epoch: 5| Step: 10
Training loss: 3.708483460777117
Validation loss: 3.2204606468217682

Epoch: 36| Step: 0
Training loss: 3.8706436280464924
Validation loss: 3.219894269502764

Epoch: 5| Step: 1
Training loss: 3.49325811373072
Validation loss: 3.2196286359537916

Epoch: 5| Step: 2
Training loss: 2.70322854609978
Validation loss: 3.22103955717513

Epoch: 5| Step: 3
Training loss: 3.550727667577354
Validation loss: 3.22555372001834

Epoch: 5| Step: 4
Training loss: 3.5502738632088904
Validation loss: 3.2208572643634636

Epoch: 5| Step: 5
Training loss: 3.3704028432707767
Validation loss: 3.2180193653140297

Epoch: 5| Step: 6
Training loss: 3.749342161334603
Validation loss: 3.2196430194452534

Epoch: 5| Step: 7
Training loss: 3.4548775898824227
Validation loss: 3.2150490727295917

Epoch: 5| Step: 8
Training loss: 3.5447619357428377
Validation loss: 3.2151213439502846

Epoch: 5| Step: 9
Training loss: 3.2819656318292396
Validation loss: 3.2176569910665

Epoch: 5| Step: 10
Training loss: 3.409564444281268
Validation loss: 3.2240295996016983

Epoch: 37| Step: 0
Training loss: 3.5216073233182086
Validation loss: 3.2371494337959463

Epoch: 5| Step: 1
Training loss: 3.7256540274741132
Validation loss: 3.232672225437014

Epoch: 5| Step: 2
Training loss: 3.7256349572872725
Validation loss: 3.221219397972152

Epoch: 5| Step: 3
Training loss: 3.87712322025324
Validation loss: 3.214932446281768

Epoch: 5| Step: 4
Training loss: 3.674964027488231
Validation loss: 3.21048210644683

Epoch: 5| Step: 5
Training loss: 3.9237554532997856
Validation loss: 3.2085954430954935

Epoch: 5| Step: 6
Training loss: 3.589416146365527
Validation loss: 3.208462478559208

Epoch: 5| Step: 7
Training loss: 3.2844980784837547
Validation loss: 3.2159165948551816

Epoch: 5| Step: 8
Training loss: 2.2020731910994105
Validation loss: 3.229122031092245

Epoch: 5| Step: 9
Training loss: 3.0853187423576447
Validation loss: 3.2304782570938606

Epoch: 5| Step: 10
Training loss: 3.203675906559529
Validation loss: 3.25084820352348

Epoch: 38| Step: 0
Training loss: 3.361424020821221
Validation loss: 3.2090219148427557

Epoch: 5| Step: 1
Training loss: 3.577216287022039
Validation loss: 3.203951075470419

Epoch: 5| Step: 2
Training loss: 3.3919880320319886
Validation loss: 3.205292660115545

Epoch: 5| Step: 3
Training loss: 3.2133070470069813
Validation loss: 3.2079735644632246

Epoch: 5| Step: 4
Training loss: 3.3315532381698127
Validation loss: 3.215538444953813

Epoch: 5| Step: 5
Training loss: 3.723407041206593
Validation loss: 3.227739003558975

Epoch: 5| Step: 6
Training loss: 3.579629640015874
Validation loss: 3.2254095973707404

Epoch: 5| Step: 7
Training loss: 3.602829451734924
Validation loss: 3.2192690986557366

Epoch: 5| Step: 8
Training loss: 3.6069539194656253
Validation loss: 3.2123501364391562

Epoch: 5| Step: 9
Training loss: 2.9111434593377097
Validation loss: 3.2054446725186314

Epoch: 5| Step: 10
Training loss: 3.825679823356869
Validation loss: 3.204421388975111

Epoch: 39| Step: 0
Training loss: 2.6061894508116112
Validation loss: 3.203649364803337

Epoch: 5| Step: 1
Training loss: 4.104032459420675
Validation loss: 3.2027180811147953

Epoch: 5| Step: 2
Training loss: 3.9331689660163818
Validation loss: 3.2053580027222957

Epoch: 5| Step: 3
Training loss: 3.5594264374215583
Validation loss: 3.2097566375009365

Epoch: 5| Step: 4
Training loss: 2.477219359114939
Validation loss: 3.212316973779943

Epoch: 5| Step: 5
Training loss: 3.25987299244616
Validation loss: 3.210815406607619

Epoch: 5| Step: 6
Training loss: 3.8423527604871146
Validation loss: 3.2030832363460364

Epoch: 5| Step: 7
Training loss: 4.069148799730197
Validation loss: 3.2006434214188726

Epoch: 5| Step: 8
Training loss: 3.4627153295222097
Validation loss: 3.200383900871637

Epoch: 5| Step: 9
Training loss: 2.737856321790742
Validation loss: 3.198333242260419

Epoch: 5| Step: 10
Training loss: 3.4422003774796
Validation loss: 3.1975175333828783

Epoch: 40| Step: 0
Training loss: 3.8635110661390257
Validation loss: 3.1965976095186477

Epoch: 5| Step: 1
Training loss: 4.287259972084421
Validation loss: 3.1957625835236056

Epoch: 5| Step: 2
Training loss: 3.5553148323930586
Validation loss: 3.1960009403325174

Epoch: 5| Step: 3
Training loss: 2.6292830448016424
Validation loss: 3.1933577709978582

Epoch: 5| Step: 4
Training loss: 3.8569261449656675
Validation loss: 3.192955739944009

Epoch: 5| Step: 5
Training loss: 3.2314945976900384
Validation loss: 3.1900470698229673

Epoch: 5| Step: 6
Training loss: 2.6087537928335696
Validation loss: 3.1925647846989214

Epoch: 5| Step: 7
Training loss: 3.936739045742049
Validation loss: 3.1943254432311847

Epoch: 5| Step: 8
Training loss: 2.9916961505538575
Validation loss: 3.1925196909169746

Epoch: 5| Step: 9
Training loss: 3.605830842885573
Validation loss: 3.1900277069284453

Epoch: 5| Step: 10
Training loss: 2.7322858404363326
Validation loss: 3.1900267988127182

Epoch: 41| Step: 0
Training loss: 3.516751935265599
Validation loss: 3.189285455468485

Epoch: 5| Step: 1
Training loss: 3.62104068128757
Validation loss: 3.18817198665389

Epoch: 5| Step: 2
Training loss: 3.9894384186855643
Validation loss: 3.1895343787825756

Epoch: 5| Step: 3
Training loss: 3.6703998605620036
Validation loss: 3.1850051252732414

Epoch: 5| Step: 4
Training loss: 3.514684118888411
Validation loss: 3.18550893135852

Epoch: 5| Step: 5
Training loss: 2.546604914474089
Validation loss: 3.1858280967875006

Epoch: 5| Step: 6
Training loss: 3.595031775067519
Validation loss: 3.1848773513885678

Epoch: 5| Step: 7
Training loss: 2.825502138325009
Validation loss: 3.185372664344732

Epoch: 5| Step: 8
Training loss: 3.3139180441042217
Validation loss: 3.184801615132037

Epoch: 5| Step: 9
Training loss: 4.077124929760075
Validation loss: 3.1847135012878547

Epoch: 5| Step: 10
Training loss: 2.6692896598834297
Validation loss: 3.1822308495142546

Epoch: 42| Step: 0
Training loss: 3.265303746533989
Validation loss: 3.1828819994688633

Epoch: 5| Step: 1
Training loss: 3.773751255678345
Validation loss: 3.182561350435725

Epoch: 5| Step: 2
Training loss: 2.631040797672304
Validation loss: 3.1827210567516446

Epoch: 5| Step: 3
Training loss: 3.8462296837885988
Validation loss: 3.187748760350378

Epoch: 5| Step: 4
Training loss: 3.183730945088308
Validation loss: 3.1845384239149386

Epoch: 5| Step: 5
Training loss: 3.3714607896489226
Validation loss: 3.190161893053182

Epoch: 5| Step: 6
Training loss: 3.6965056543625594
Validation loss: 3.1951647859555807

Epoch: 5| Step: 7
Training loss: 3.049880203646005
Validation loss: 3.194935987646098

Epoch: 5| Step: 8
Training loss: 3.583643227121929
Validation loss: 3.189564234546588

Epoch: 5| Step: 9
Training loss: 3.7218810932612407
Validation loss: 3.1822993692268233

Epoch: 5| Step: 10
Training loss: 3.4936367501071457
Validation loss: 3.1822339188912334

Epoch: 43| Step: 0
Training loss: 4.216164029486419
Validation loss: 3.1814569989484296

Epoch: 5| Step: 1
Training loss: 4.050563942534851
Validation loss: 3.175455394393814

Epoch: 5| Step: 2
Training loss: 3.414333725550083
Validation loss: 3.1763102103992917

Epoch: 5| Step: 3
Training loss: 4.129588493924109
Validation loss: 3.177620411299043

Epoch: 5| Step: 4
Training loss: 3.116352017137081
Validation loss: 3.177490773628637

Epoch: 5| Step: 5
Training loss: 2.2931053731790088
Validation loss: 3.179314199513468

Epoch: 5| Step: 6
Training loss: 3.6940966293427393
Validation loss: 3.1775201366426757

Epoch: 5| Step: 7
Training loss: 2.0687607041741813
Validation loss: 3.1733546046811436

Epoch: 5| Step: 8
Training loss: 3.3039617801238323
Validation loss: 3.1730839746799733

Epoch: 5| Step: 9
Training loss: 3.0039918091175957
Validation loss: 3.1728592982118795

Epoch: 5| Step: 10
Training loss: 3.780225504652842
Validation loss: 3.1733956156591536

Epoch: 44| Step: 0
Training loss: 3.0212596373272156
Validation loss: 3.172873465488245

Epoch: 5| Step: 1
Training loss: 3.650125443902659
Validation loss: 3.172120724150679

Epoch: 5| Step: 2
Training loss: 3.483635109662105
Validation loss: 3.170736492757063

Epoch: 5| Step: 3
Training loss: 3.458091375014081
Validation loss: 3.170541397783357

Epoch: 5| Step: 4
Training loss: 3.074889830809984
Validation loss: 3.169014677659449

Epoch: 5| Step: 5
Training loss: 4.375936135546077
Validation loss: 3.166869037769999

Epoch: 5| Step: 6
Training loss: 3.223188284681157
Validation loss: 3.1681108360553374

Epoch: 5| Step: 7
Training loss: 3.3365749491593055
Validation loss: 3.16845881898527

Epoch: 5| Step: 8
Training loss: 3.363928401416409
Validation loss: 3.166561656585971

Epoch: 5| Step: 9
Training loss: 2.9268099475044558
Validation loss: 3.166867118399884

Epoch: 5| Step: 10
Training loss: 3.530359071402606
Validation loss: 3.1690137263095357

Epoch: 45| Step: 0
Training loss: 3.6173973599354508
Validation loss: 3.167021361295664

Epoch: 5| Step: 1
Training loss: 3.248120277846168
Validation loss: 3.1659600830186094

Epoch: 5| Step: 2
Training loss: 3.4631229157055152
Validation loss: 3.1667237063475215

Epoch: 5| Step: 3
Training loss: 2.90162849084178
Validation loss: 3.1696944994749177

Epoch: 5| Step: 4
Training loss: 3.317479547410255
Validation loss: 3.1672625901175766

Epoch: 5| Step: 5
Training loss: 3.3358816101967013
Validation loss: 3.1709430318945007

Epoch: 5| Step: 6
Training loss: 4.133930595889445
Validation loss: 3.1700893993173507

Epoch: 5| Step: 7
Training loss: 3.6933451732441127
Validation loss: 3.1672671503775907

Epoch: 5| Step: 8
Training loss: 3.654151248935607
Validation loss: 3.167287635042859

Epoch: 5| Step: 9
Training loss: 2.6784966939763684
Validation loss: 3.164699368103876

Epoch: 5| Step: 10
Training loss: 3.2861821481251976
Validation loss: 3.162352447459298

Epoch: 46| Step: 0
Training loss: 4.053370620238145
Validation loss: 3.1639787365860177

Epoch: 5| Step: 1
Training loss: 3.4464203660078088
Validation loss: 3.161134942153653

Epoch: 5| Step: 2
Training loss: 3.228151535117148
Validation loss: 3.1604657661636106

Epoch: 5| Step: 3
Training loss: 3.0081866143148384
Validation loss: 3.1614727036087586

Epoch: 5| Step: 4
Training loss: 3.7195422186206026
Validation loss: 3.159585944876775

Epoch: 5| Step: 5
Training loss: 3.718180252154568
Validation loss: 3.1604108242564117

Epoch: 5| Step: 6
Training loss: 3.2861415188406213
Validation loss: 3.1600413765307076

Epoch: 5| Step: 7
Training loss: 2.9711546144111747
Validation loss: 3.1586608013257447

Epoch: 5| Step: 8
Training loss: 2.8104041873851826
Validation loss: 3.1597123106949363

Epoch: 5| Step: 9
Training loss: 3.6130865920961353
Validation loss: 3.1574979865469373

Epoch: 5| Step: 10
Training loss: 3.4973574608094036
Validation loss: 3.1565469857750994

Epoch: 47| Step: 0
Training loss: 3.0958429828423246
Validation loss: 3.1565542887647373

Epoch: 5| Step: 1
Training loss: 3.6096455526304796
Validation loss: 3.1554919745594887

Epoch: 5| Step: 2
Training loss: 3.385568249561146
Validation loss: 3.15743694407148

Epoch: 5| Step: 3
Training loss: 4.0195620936924
Validation loss: 3.1576899238373795

Epoch: 5| Step: 4
Training loss: 3.0160522158324663
Validation loss: 3.1633364167536575

Epoch: 5| Step: 5
Training loss: 3.572449026097837
Validation loss: 3.1612523093165854

Epoch: 5| Step: 6
Training loss: 3.877260840669211
Validation loss: 3.1627025765210592

Epoch: 5| Step: 7
Training loss: 3.3808301795479014
Validation loss: 3.158633843976167

Epoch: 5| Step: 8
Training loss: 2.9473554169038123
Validation loss: 3.1534198786971515

Epoch: 5| Step: 9
Training loss: 3.468916055639603
Validation loss: 3.152666848684613

Epoch: 5| Step: 10
Training loss: 2.849775198385909
Validation loss: 3.1532228651479675

Epoch: 48| Step: 0
Training loss: 2.922417738175254
Validation loss: 3.153056503380079

Epoch: 5| Step: 1
Training loss: 3.6243972277169383
Validation loss: 3.1514372926169787

Epoch: 5| Step: 2
Training loss: 2.4806089827178286
Validation loss: 3.1519693518084977

Epoch: 5| Step: 3
Training loss: 3.1116476523484664
Validation loss: 3.1492452283322523

Epoch: 5| Step: 4
Training loss: 4.0698757413224165
Validation loss: 3.149741117846216

Epoch: 5| Step: 5
Training loss: 3.2228403119784996
Validation loss: 3.1483343953267022

Epoch: 5| Step: 6
Training loss: 3.038592696957414
Validation loss: 3.1475760371615977

Epoch: 5| Step: 7
Training loss: 3.902063552526604
Validation loss: 3.153998969382665

Epoch: 5| Step: 8
Training loss: 3.8768847404233395
Validation loss: 3.1492494841787217

Epoch: 5| Step: 9
Training loss: 3.044631366684082
Validation loss: 3.1516276793062636

Epoch: 5| Step: 10
Training loss: 3.819299481656108
Validation loss: 3.1510075279074035

Epoch: 49| Step: 0
Training loss: 2.8161470291269675
Validation loss: 3.1491860203474893

Epoch: 5| Step: 1
Training loss: 3.3342599693413013
Validation loss: 3.1515564705026184

Epoch: 5| Step: 2
Training loss: 3.7537009731854973
Validation loss: 3.1457035480976443

Epoch: 5| Step: 3
Training loss: 3.21473102209712
Validation loss: 3.145788503054553

Epoch: 5| Step: 4
Training loss: 3.099767054757858
Validation loss: 3.1439289445340304

Epoch: 5| Step: 5
Training loss: 2.820532708275756
Validation loss: 3.1443769939530095

Epoch: 5| Step: 6
Training loss: 3.781043937680041
Validation loss: 3.1453012560971048

Epoch: 5| Step: 7
Training loss: 3.334960651537323
Validation loss: 3.143398130944719

Epoch: 5| Step: 8
Training loss: 3.4719057591652605
Validation loss: 3.1456763533881515

Epoch: 5| Step: 9
Training loss: 3.9743840634080243
Validation loss: 3.145078646087036

Epoch: 5| Step: 10
Training loss: 3.6283131947365184
Validation loss: 3.1450340175303473

Epoch: 50| Step: 0
Training loss: 3.962553578685421
Validation loss: 3.14281555586949

Epoch: 5| Step: 1
Training loss: 3.3664989077125633
Validation loss: 3.1391627634503094

Epoch: 5| Step: 2
Training loss: 3.2253517668745166
Validation loss: 3.1402901965022596

Epoch: 5| Step: 3
Training loss: 3.557718112717148
Validation loss: 3.1417626451097767

Epoch: 5| Step: 4
Training loss: 3.1048297728532552
Validation loss: 3.1400134722246444

Epoch: 5| Step: 5
Training loss: 3.2228432710884345
Validation loss: 3.1403226764555336

Epoch: 5| Step: 6
Training loss: 3.6247466426312616
Validation loss: 3.1397147282123354

Epoch: 5| Step: 7
Training loss: 3.3220953967815827
Validation loss: 3.1395683962094028

Epoch: 5| Step: 8
Training loss: 3.311830129008093
Validation loss: 3.1389978648952583

Epoch: 5| Step: 9
Training loss: 3.1273050580762876
Validation loss: 3.1374174212988684

Epoch: 5| Step: 10
Training loss: 3.4714596449253468
Validation loss: 3.137644658522503

Epoch: 51| Step: 0
Training loss: 3.2202130298161116
Validation loss: 3.1382879578623886

Epoch: 5| Step: 1
Training loss: 3.744279439996469
Validation loss: 3.136860677494702

Epoch: 5| Step: 2
Training loss: 2.865998980663728
Validation loss: 3.1367801645995836

Epoch: 5| Step: 3
Training loss: 3.1756079744972348
Validation loss: 3.1371128600548768

Epoch: 5| Step: 4
Training loss: 3.074413870177794
Validation loss: 3.1358211132335323

Epoch: 5| Step: 5
Training loss: 3.2262278976777052
Validation loss: 3.138893359814474

Epoch: 5| Step: 6
Training loss: 2.917307501737241
Validation loss: 3.1423750586751518

Epoch: 5| Step: 7
Training loss: 3.742665811763059
Validation loss: 3.1390330802745794

Epoch: 5| Step: 8
Training loss: 3.5757823754897045
Validation loss: 3.134554950232366

Epoch: 5| Step: 9
Training loss: 3.3655955363819583
Validation loss: 3.133720290360533

Epoch: 5| Step: 10
Training loss: 4.303235925645106
Validation loss: 3.1331210296089167

Epoch: 52| Step: 0
Training loss: 3.360132744074301
Validation loss: 3.132868649287413

Epoch: 5| Step: 1
Training loss: 3.6950147964532296
Validation loss: 3.133721520755846

Epoch: 5| Step: 2
Training loss: 3.3148352111087878
Validation loss: 3.130992677636968

Epoch: 5| Step: 3
Training loss: 3.284072388737461
Validation loss: 3.1333526513096093

Epoch: 5| Step: 4
Training loss: 3.4617203974391675
Validation loss: 3.1323415971912554

Epoch: 5| Step: 5
Training loss: 2.997568098476644
Validation loss: 3.1316982060590597

Epoch: 5| Step: 6
Training loss: 3.343959053135647
Validation loss: 3.1302626320166054

Epoch: 5| Step: 7
Training loss: 3.9258770831353353
Validation loss: 3.1293156519240095

Epoch: 5| Step: 8
Training loss: 3.391447890315375
Validation loss: 3.12956580147006

Epoch: 5| Step: 9
Training loss: 2.855844955606208
Validation loss: 3.129105877663027

Epoch: 5| Step: 10
Training loss: 3.529415362954643
Validation loss: 3.1274224799814547

Epoch: 53| Step: 0
Training loss: 2.7964185629980323
Validation loss: 3.127909256528444

Epoch: 5| Step: 1
Training loss: 3.533658851767707
Validation loss: 3.127915436321306

Epoch: 5| Step: 2
Training loss: 4.0378161043839365
Validation loss: 3.126687766808407

Epoch: 5| Step: 3
Training loss: 3.190881767738892
Validation loss: 3.127300829749632

Epoch: 5| Step: 4
Training loss: 3.2162071479584617
Validation loss: 3.129710663909255

Epoch: 5| Step: 5
Training loss: 3.142806173505785
Validation loss: 3.12926944107118

Epoch: 5| Step: 6
Training loss: 3.7953769570001263
Validation loss: 3.124072828673246

Epoch: 5| Step: 7
Training loss: 3.460728899522644
Validation loss: 3.1245979755998143

Epoch: 5| Step: 8
Training loss: 2.4366870404742853
Validation loss: 3.124745984982419

Epoch: 5| Step: 9
Training loss: 4.15992035532784
Validation loss: 3.1258477683332493

Epoch: 5| Step: 10
Training loss: 3.008306764888648
Validation loss: 3.127590038050467

Epoch: 54| Step: 0
Training loss: 3.2414967731846356
Validation loss: 3.1278418418994947

Epoch: 5| Step: 1
Training loss: 2.7878175836813304
Validation loss: 3.1304787614588907

Epoch: 5| Step: 2
Training loss: 3.391106215401656
Validation loss: 3.130447596132084

Epoch: 5| Step: 3
Training loss: 3.4792046611485383
Validation loss: 3.1296047043429907

Epoch: 5| Step: 4
Training loss: 3.080266681867156
Validation loss: 3.1260659776748625

Epoch: 5| Step: 5
Training loss: 3.654904501067883
Validation loss: 3.1231815634081816

Epoch: 5| Step: 6
Training loss: 2.714870974177798
Validation loss: 3.1245711214831484

Epoch: 5| Step: 7
Training loss: 3.7126675397785474
Validation loss: 3.1261360810573273

Epoch: 5| Step: 8
Training loss: 3.8931786915580764
Validation loss: 3.1219374451325113

Epoch: 5| Step: 9
Training loss: 3.788799095829972
Validation loss: 3.1203448679433623

Epoch: 5| Step: 10
Training loss: 3.238646409598654
Validation loss: 3.1204096396949748

Epoch: 55| Step: 0
Training loss: 3.7601938930191015
Validation loss: 3.1190543302434133

Epoch: 5| Step: 1
Training loss: 3.1793619125093846
Validation loss: 3.118405611353689

Epoch: 5| Step: 2
Training loss: 3.5763704087521675
Validation loss: 3.1195802315820074

Epoch: 5| Step: 3
Training loss: 3.7607808592776033
Validation loss: 3.116481001371342

Epoch: 5| Step: 4
Training loss: 2.998535593564229
Validation loss: 3.1198786356491097

Epoch: 5| Step: 5
Training loss: 3.2449739179459383
Validation loss: 3.1178133982772662

Epoch: 5| Step: 6
Training loss: 2.87195376017333
Validation loss: 3.1164442980539175

Epoch: 5| Step: 7
Training loss: 3.8817257502050153
Validation loss: 3.1183703644475846

Epoch: 5| Step: 8
Training loss: 3.051213701494056
Validation loss: 3.1173098689167373

Epoch: 5| Step: 9
Training loss: 2.987193110197649
Validation loss: 3.1196201834812394

Epoch: 5| Step: 10
Training loss: 3.7060745017586263
Validation loss: 3.1151036783924013

Epoch: 56| Step: 0
Training loss: 2.9227590600443425
Validation loss: 3.1149200911493993

Epoch: 5| Step: 1
Training loss: 3.0658401647064615
Validation loss: 3.1163495837624438

Epoch: 5| Step: 2
Training loss: 3.6188544434544694
Validation loss: 3.113291536557282

Epoch: 5| Step: 3
Training loss: 3.3526646506934994
Validation loss: 3.1146042166284946

Epoch: 5| Step: 4
Training loss: 3.7585697164581853
Validation loss: 3.113309410316692

Epoch: 5| Step: 5
Training loss: 3.5825112456992403
Validation loss: 3.1138550104376868

Epoch: 5| Step: 6
Training loss: 3.224210680985481
Validation loss: 3.111490788879912

Epoch: 5| Step: 7
Training loss: 3.22816719256558
Validation loss: 3.1172059764566864

Epoch: 5| Step: 8
Training loss: 3.81687338712042
Validation loss: 3.1169486877397765

Epoch: 5| Step: 9
Training loss: 3.2459048366546677
Validation loss: 3.112888280037896

Epoch: 5| Step: 10
Training loss: 3.127308565009025
Validation loss: 3.1097257369633797

Epoch: 57| Step: 0
Training loss: 2.8528452875043953
Validation loss: 3.107597071563228

Epoch: 5| Step: 1
Training loss: 3.465601411400364
Validation loss: 3.1082118709508553

Epoch: 5| Step: 2
Training loss: 3.5070764665754335
Validation loss: 3.107862591471124

Epoch: 5| Step: 3
Training loss: 3.473245817413261
Validation loss: 3.10816719967993

Epoch: 5| Step: 4
Training loss: 3.407788690329048
Validation loss: 3.107446399021482

Epoch: 5| Step: 5
Training loss: 2.9068442116621975
Validation loss: 3.1072293028118296

Epoch: 5| Step: 6
Training loss: 3.2300910036949237
Validation loss: 3.1077337609881948

Epoch: 5| Step: 7
Training loss: 3.9533471810246845
Validation loss: 3.107945587361203

Epoch: 5| Step: 8
Training loss: 3.333363596460929
Validation loss: 3.1063042335433066

Epoch: 5| Step: 9
Training loss: 3.731666380686463
Validation loss: 3.106385313503503

Epoch: 5| Step: 10
Training loss: 2.9549988952221558
Validation loss: 3.106676736248748

Epoch: 58| Step: 0
Training loss: 3.516385415809406
Validation loss: 3.1051304803294983

Epoch: 5| Step: 1
Training loss: 2.061791616224028
Validation loss: 3.1051576602642936

Epoch: 5| Step: 2
Training loss: 3.259686194218369
Validation loss: 3.1057951526761465

Epoch: 5| Step: 3
Training loss: 2.875606804541214
Validation loss: 3.1049715000666533

Epoch: 5| Step: 4
Training loss: 3.1512226819886107
Validation loss: 3.102507727239051

Epoch: 5| Step: 5
Training loss: 3.3407102654248018
Validation loss: 3.1031115359387753

Epoch: 5| Step: 6
Training loss: 3.6352205560613426
Validation loss: 3.101060670439521

Epoch: 5| Step: 7
Training loss: 3.8257593435883694
Validation loss: 3.102882384411052

Epoch: 5| Step: 8
Training loss: 3.433945083436771
Validation loss: 3.100545988386701

Epoch: 5| Step: 9
Training loss: 3.8975277376197255
Validation loss: 3.1030933208943043

Epoch: 5| Step: 10
Training loss: 3.631164176832792
Validation loss: 3.104861991282574

Epoch: 59| Step: 0
Training loss: 3.284525226674419
Validation loss: 3.104361687729676

Epoch: 5| Step: 1
Training loss: 3.527050390538454
Validation loss: 3.1052304127473223

Epoch: 5| Step: 2
Training loss: 3.470511736554425
Validation loss: 3.1088470886444672

Epoch: 5| Step: 3
Training loss: 3.9453871918208216
Validation loss: 3.103541698145069

Epoch: 5| Step: 4
Training loss: 3.606245261045413
Validation loss: 3.104795078631044

Epoch: 5| Step: 5
Training loss: 2.640686666457051
Validation loss: 3.0994831030045655

Epoch: 5| Step: 6
Training loss: 2.9887201921802578
Validation loss: 3.1046419291203895

Epoch: 5| Step: 7
Training loss: 3.4079966135500706
Validation loss: 3.0968085986964153

Epoch: 5| Step: 8
Training loss: 3.1515236393996515
Validation loss: 3.0959971729147053

Epoch: 5| Step: 9
Training loss: 3.432945980208157
Validation loss: 3.097659040688066

Epoch: 5| Step: 10
Training loss: 3.307044953683514
Validation loss: 3.0976207951320336

Epoch: 60| Step: 0
Training loss: 3.4338330216954684
Validation loss: 3.0991887141471937

Epoch: 5| Step: 1
Training loss: 3.0594289523579996
Validation loss: 3.0970535977980984

Epoch: 5| Step: 2
Training loss: 3.8045824729632423
Validation loss: 3.0958158643897087

Epoch: 5| Step: 3
Training loss: 3.3335258110423776
Validation loss: 3.097464141663306

Epoch: 5| Step: 4
Training loss: 3.705605106953411
Validation loss: 3.09820173704264

Epoch: 5| Step: 5
Training loss: 3.783028554753657
Validation loss: 3.0971680080675092

Epoch: 5| Step: 6
Training loss: 2.797797961828406
Validation loss: 3.0944779592932776

Epoch: 5| Step: 7
Training loss: 3.3317131078427495
Validation loss: 3.0917708785964972

Epoch: 5| Step: 8
Training loss: 3.580580888856995
Validation loss: 3.093597702532055

Epoch: 5| Step: 9
Training loss: 2.8357907091723162
Validation loss: 3.092102027845165

Epoch: 5| Step: 10
Training loss: 3.077358712021732
Validation loss: 3.0931983904299845

Epoch: 61| Step: 0
Training loss: 3.289463770801263
Validation loss: 3.0925677648699974

Epoch: 5| Step: 1
Training loss: 3.659191285301543
Validation loss: 3.0901406518619345

Epoch: 5| Step: 2
Training loss: 3.2099254340427064
Validation loss: 3.0931310928530014

Epoch: 5| Step: 3
Training loss: 2.972779761416526
Validation loss: 3.0920756973925423

Epoch: 5| Step: 4
Training loss: 3.1317777756136587
Validation loss: 3.092428154338736

Epoch: 5| Step: 5
Training loss: 2.8627799351171195
Validation loss: 3.0894420117798305

Epoch: 5| Step: 6
Training loss: 3.34026033357721
Validation loss: 3.0903840360170434

Epoch: 5| Step: 7
Training loss: 3.3997328821605888
Validation loss: 3.0911736357722077

Epoch: 5| Step: 8
Training loss: 3.5657141390999563
Validation loss: 3.0907276215287176

Epoch: 5| Step: 9
Training loss: 3.6126259699310976
Validation loss: 3.090839777665524

Epoch: 5| Step: 10
Training loss: 3.8181814166890384
Validation loss: 3.087422067529586

Epoch: 62| Step: 0
Training loss: 3.6951398426068938
Validation loss: 3.0872420806188896

Epoch: 5| Step: 1
Training loss: 3.607139654846065
Validation loss: 3.0864967812398696

Epoch: 5| Step: 2
Training loss: 3.0010571206747687
Validation loss: 3.0859965524232393

Epoch: 5| Step: 3
Training loss: 3.411034260179908
Validation loss: 3.0863606364431084

Epoch: 5| Step: 4
Training loss: 3.724571223831221
Validation loss: 3.0842158117016027

Epoch: 5| Step: 5
Training loss: 2.8804433955501123
Validation loss: 3.085551805486318

Epoch: 5| Step: 6
Training loss: 3.397210401665401
Validation loss: 3.0829188232588183

Epoch: 5| Step: 7
Training loss: 2.9623071728495542
Validation loss: 3.0833598493008485

Epoch: 5| Step: 8
Training loss: 3.2125630591471013
Validation loss: 3.0830625039852486

Epoch: 5| Step: 9
Training loss: 3.492297552708714
Validation loss: 3.0849551453384896

Epoch: 5| Step: 10
Training loss: 3.325154442893111
Validation loss: 3.0817182385507316

Epoch: 63| Step: 0
Training loss: 3.0409858324849237
Validation loss: 3.083088123134944

Epoch: 5| Step: 1
Training loss: 3.6552099069001462
Validation loss: 3.081572093376843

Epoch: 5| Step: 2
Training loss: 3.7033008903870086
Validation loss: 3.082601362800909

Epoch: 5| Step: 3
Training loss: 2.8148073692204716
Validation loss: 3.0832348657886017

Epoch: 5| Step: 4
Training loss: 2.9537278624684538
Validation loss: 3.083087733153378

Epoch: 5| Step: 5
Training loss: 3.8687950415138546
Validation loss: 3.083460457355993

Epoch: 5| Step: 6
Training loss: 3.1059738804000814
Validation loss: 3.0822026297778735

Epoch: 5| Step: 7
Training loss: 3.655157855339319
Validation loss: 3.07991156299144

Epoch: 5| Step: 8
Training loss: 3.000878205504592
Validation loss: 3.081065895407699

Epoch: 5| Step: 9
Training loss: 3.220032667859144
Validation loss: 3.080140504153285

Epoch: 5| Step: 10
Training loss: 3.6390763947093445
Validation loss: 3.0783576483887463

Epoch: 64| Step: 0
Training loss: 3.249670745603927
Validation loss: 3.0778182331654214

Epoch: 5| Step: 1
Training loss: 4.103840977999157
Validation loss: 3.0773580738936768

Epoch: 5| Step: 2
Training loss: 3.3321358596104473
Validation loss: 3.0773674208736375

Epoch: 5| Step: 3
Training loss: 3.0259023471261033
Validation loss: 3.0790343481402567

Epoch: 5| Step: 4
Training loss: 3.2489754455709345
Validation loss: 3.074112225374436

Epoch: 5| Step: 5
Training loss: 3.5561039041501328
Validation loss: 3.0783370266516723

Epoch: 5| Step: 6
Training loss: 3.077716935891861
Validation loss: 3.0792922089043553

Epoch: 5| Step: 7
Training loss: 3.387013705212076
Validation loss: 3.077410041742707

Epoch: 5| Step: 8
Training loss: 3.1437121349200616
Validation loss: 3.076255757558215

Epoch: 5| Step: 9
Training loss: 2.90910215809121
Validation loss: 3.074375312934794

Epoch: 5| Step: 10
Training loss: 3.6200149723396695
Validation loss: 3.074911105964224

Epoch: 65| Step: 0
Training loss: 2.9349142828256807
Validation loss: 3.074251854624708

Epoch: 5| Step: 1
Training loss: 3.6760330357193074
Validation loss: 3.0734793010120174

Epoch: 5| Step: 2
Training loss: 3.306028702654573
Validation loss: 3.0759645364099786

Epoch: 5| Step: 3
Training loss: 3.645882538962965
Validation loss: 3.073400397557202

Epoch: 5| Step: 4
Training loss: 3.433397515323558
Validation loss: 3.073593674644025

Epoch: 5| Step: 5
Training loss: 2.730539127256021
Validation loss: 3.072588446962525

Epoch: 5| Step: 6
Training loss: 4.037752806127274
Validation loss: 3.0731912845118097

Epoch: 5| Step: 7
Training loss: 2.991771858370732
Validation loss: 3.072257619311917

Epoch: 5| Step: 8
Training loss: 2.9769658493733115
Validation loss: 3.0717847226707087

Epoch: 5| Step: 9
Training loss: 3.615827465405743
Validation loss: 3.071273007614947

Epoch: 5| Step: 10
Training loss: 3.1240440432365917
Validation loss: 3.070199797732059

Epoch: 66| Step: 0
Training loss: 3.1163838433306266
Validation loss: 3.0697408114319273

Epoch: 5| Step: 1
Training loss: 3.4427856036511364
Validation loss: 3.0692766280087094

Epoch: 5| Step: 2
Training loss: 3.4853593607628506
Validation loss: 3.0671514095448824

Epoch: 5| Step: 3
Training loss: 3.368708220666903
Validation loss: 3.068868563543106

Epoch: 5| Step: 4
Training loss: 3.8428787856827067
Validation loss: 3.067717433382291

Epoch: 5| Step: 5
Training loss: 3.02023484889511
Validation loss: 3.0668510390839443

Epoch: 5| Step: 6
Training loss: 3.077959859842833
Validation loss: 3.0652635012462253

Epoch: 5| Step: 7
Training loss: 2.7244075796126896
Validation loss: 3.06911146113929

Epoch: 5| Step: 8
Training loss: 3.4655832492800442
Validation loss: 3.0745858296442132

Epoch: 5| Step: 9
Training loss: 3.532100878803151
Validation loss: 3.0818349500546818

Epoch: 5| Step: 10
Training loss: 3.4859326905029713
Validation loss: 3.0749123732310903

Epoch: 67| Step: 0
Training loss: 3.46328593674783
Validation loss: 3.070768171639716

Epoch: 5| Step: 1
Training loss: 3.6126505203303925
Validation loss: 3.0634630541941483

Epoch: 5| Step: 2
Training loss: 3.0971169693819594
Validation loss: 3.063820407576025

Epoch: 5| Step: 3
Training loss: 2.8554770995303715
Validation loss: 3.064666388637727

Epoch: 5| Step: 4
Training loss: 3.470501019588574
Validation loss: 3.06487845970396

Epoch: 5| Step: 5
Training loss: 3.3153057092062572
Validation loss: 3.0642958969940803

Epoch: 5| Step: 6
Training loss: 3.1665261555333406
Validation loss: 3.0650954107040174

Epoch: 5| Step: 7
Training loss: 3.507324592625363
Validation loss: 3.066913355414812

Epoch: 5| Step: 8
Training loss: 3.58739712664016
Validation loss: 3.0646486427486144

Epoch: 5| Step: 9
Training loss: 3.052429457340663
Validation loss: 3.0632453783186

Epoch: 5| Step: 10
Training loss: 3.509411555683244
Validation loss: 3.064207279615393

Epoch: 68| Step: 0
Training loss: 3.353134817942727
Validation loss: 3.0629845462525855

Epoch: 5| Step: 1
Training loss: 3.273889187260532
Validation loss: 3.0611247954846763

Epoch: 5| Step: 2
Training loss: 3.3637035782586633
Validation loss: 3.0609755632254343

Epoch: 5| Step: 3
Training loss: 3.454418647756772
Validation loss: 3.0565065581682673

Epoch: 5| Step: 4
Training loss: 3.428939981179497
Validation loss: 3.059795279368129

Epoch: 5| Step: 5
Training loss: 3.674603945611621
Validation loss: 3.063077723557059

Epoch: 5| Step: 6
Training loss: 2.784672292471547
Validation loss: 3.058010972558822

Epoch: 5| Step: 7
Training loss: 3.7415272681784573
Validation loss: 3.0589018061667526

Epoch: 5| Step: 8
Training loss: 3.5449511986562654
Validation loss: 3.0572982955441206

Epoch: 5| Step: 9
Training loss: 3.1802258234993546
Validation loss: 3.0557479593351777

Epoch: 5| Step: 10
Training loss: 2.487562426066506
Validation loss: 3.0579817094629758

Epoch: 69| Step: 0
Training loss: 3.93633882869966
Validation loss: 3.0618705261644017

Epoch: 5| Step: 1
Training loss: 2.8987452916826353
Validation loss: 3.061254317898543

Epoch: 5| Step: 2
Training loss: 2.5632596634429934
Validation loss: 3.059800763910403

Epoch: 5| Step: 3
Training loss: 3.014425562957124
Validation loss: 3.062787105085148

Epoch: 5| Step: 4
Training loss: 3.8537851230680045
Validation loss: 3.0529712338977872

Epoch: 5| Step: 5
Training loss: 3.93953664272216
Validation loss: 3.0537896310811767

Epoch: 5| Step: 6
Training loss: 3.4608617218883833
Validation loss: 3.0546459300809863

Epoch: 5| Step: 7
Training loss: 3.0385495417330155
Validation loss: 3.0570885263626106

Epoch: 5| Step: 8
Training loss: 3.5486906672694554
Validation loss: 3.0574143536345257

Epoch: 5| Step: 9
Training loss: 2.5654726231775378
Validation loss: 3.0568277811687623

Epoch: 5| Step: 10
Training loss: 3.380159319897964
Validation loss: 3.054166484764991

Epoch: 70| Step: 0
Training loss: 3.2385395163333333
Validation loss: 3.0560337634618944

Epoch: 5| Step: 1
Training loss: 3.1992633150417875
Validation loss: 3.054415491781157

Epoch: 5| Step: 2
Training loss: 3.34951954712825
Validation loss: 3.0549342054757984

Epoch: 5| Step: 3
Training loss: 3.2004183614956707
Validation loss: 3.052624105874589

Epoch: 5| Step: 4
Training loss: 3.3203112074905574
Validation loss: 3.0521531665953128

Epoch: 5| Step: 5
Training loss: 2.973152830977186
Validation loss: 3.0520032377791817

Epoch: 5| Step: 6
Training loss: 3.047338205976088
Validation loss: 3.0512809590483148

Epoch: 5| Step: 7
Training loss: 3.5677751001203903
Validation loss: 3.0517900283917845

Epoch: 5| Step: 8
Training loss: 3.647520681195787
Validation loss: 3.0523441422633697

Epoch: 5| Step: 9
Training loss: 3.5525115678828416
Validation loss: 3.05207164380962

Epoch: 5| Step: 10
Training loss: 3.3835838795114777
Validation loss: 3.0511908797994227

Epoch: 71| Step: 0
Training loss: 3.0460576452760586
Validation loss: 3.0499853110266497

Epoch: 5| Step: 1
Training loss: 3.0510260060070045
Validation loss: 3.051617932782155

Epoch: 5| Step: 2
Training loss: 2.6079486900501094
Validation loss: 3.050361718633477

Epoch: 5| Step: 3
Training loss: 3.406912363029791
Validation loss: 3.050290660433474

Epoch: 5| Step: 4
Training loss: 3.310916738188503
Validation loss: 3.0488698667355205

Epoch: 5| Step: 5
Training loss: 3.446537829290145
Validation loss: 3.0488971824492936

Epoch: 5| Step: 6
Training loss: 3.368465455446461
Validation loss: 3.047749424005116

Epoch: 5| Step: 7
Training loss: 4.154814278575292
Validation loss: 3.046011286492182

Epoch: 5| Step: 8
Training loss: 3.5201584810646698
Validation loss: 3.0448200676323696

Epoch: 5| Step: 9
Training loss: 3.3585138681002467
Validation loss: 3.0449530956482085

Epoch: 5| Step: 10
Training loss: 2.9171934106293897
Validation loss: 3.046408763096792

Epoch: 72| Step: 0
Training loss: 3.4780225109756016
Validation loss: 3.0429121373376846

Epoch: 5| Step: 1
Training loss: 3.65151501397404
Validation loss: 3.0432164189624866

Epoch: 5| Step: 2
Training loss: 3.338551982004751
Validation loss: 3.041188887897023

Epoch: 5| Step: 3
Training loss: 3.4219363133062863
Validation loss: 3.04238585126907

Epoch: 5| Step: 4
Training loss: 3.071556247072592
Validation loss: 3.0426781832731473

Epoch: 5| Step: 5
Training loss: 3.089621515396091
Validation loss: 3.041739943483201

Epoch: 5| Step: 6
Training loss: 2.598595470918525
Validation loss: 3.0407161438332655

Epoch: 5| Step: 7
Training loss: 3.3788471194699663
Validation loss: 3.040780745165352

Epoch: 5| Step: 8
Training loss: 3.3787161536573125
Validation loss: 3.0409737054820023

Epoch: 5| Step: 9
Training loss: 3.359566474603209
Validation loss: 3.0503068534912887

Epoch: 5| Step: 10
Training loss: 3.5795530442987213
Validation loss: 3.0556568472646064

Epoch: 73| Step: 0
Training loss: 2.625137143866752
Validation loss: 3.0548858657899145

Epoch: 5| Step: 1
Training loss: 3.639651712795347
Validation loss: 3.057687939612665

Epoch: 5| Step: 2
Training loss: 3.5667799286966693
Validation loss: 3.0591242075412355

Epoch: 5| Step: 3
Training loss: 3.1205348348704023
Validation loss: 3.0505071479616035

Epoch: 5| Step: 4
Training loss: 3.2346806036273366
Validation loss: 3.039841444931594

Epoch: 5| Step: 5
Training loss: 3.0931765863013654
Validation loss: 3.0354515552102836

Epoch: 5| Step: 6
Training loss: 3.3797149219714355
Validation loss: 3.0351243812390467

Epoch: 5| Step: 7
Training loss: 4.003190437157276
Validation loss: 3.036470193283404

Epoch: 5| Step: 8
Training loss: 3.2858957009552436
Validation loss: 3.035956849372148

Epoch: 5| Step: 9
Training loss: 3.3249439206090847
Validation loss: 3.0375043704154514

Epoch: 5| Step: 10
Training loss: 2.799207258400524
Validation loss: 3.035921515008607

Epoch: 74| Step: 0
Training loss: 3.0404363434496267
Validation loss: 3.034611529436092

Epoch: 5| Step: 1
Training loss: 3.6766159293673355
Validation loss: 3.0363130242179235

Epoch: 5| Step: 2
Training loss: 3.4671455315434705
Validation loss: 3.0380161701798643

Epoch: 5| Step: 3
Training loss: 2.728619955112114
Validation loss: 3.0347037244681214

Epoch: 5| Step: 4
Training loss: 3.5520895382704847
Validation loss: 3.035396416342266

Epoch: 5| Step: 5
Training loss: 3.4394381521181763
Validation loss: 3.033794440971496

Epoch: 5| Step: 6
Training loss: 3.4182735634173445
Validation loss: 3.0340822023857026

Epoch: 5| Step: 7
Training loss: 3.1115675054059557
Validation loss: 3.0330080575877987

Epoch: 5| Step: 8
Training loss: 3.001552656833727
Validation loss: 3.0303242078070953

Epoch: 5| Step: 9
Training loss: 3.333312241169637
Validation loss: 3.029231761332199

Epoch: 5| Step: 10
Training loss: 3.518064203731528
Validation loss: 3.0308989175743775

Epoch: 75| Step: 0
Training loss: 3.265107182237518
Validation loss: 3.032281767462984

Epoch: 5| Step: 1
Training loss: 3.479896712469433
Validation loss: 3.034834587369951

Epoch: 5| Step: 2
Training loss: 2.829957147280562
Validation loss: 3.040889725608137

Epoch: 5| Step: 3
Training loss: 3.513998918649315
Validation loss: 3.046293230786615

Epoch: 5| Step: 4
Training loss: 3.4340054869477434
Validation loss: 3.0337426039884376

Epoch: 5| Step: 5
Training loss: 3.2690916506480687
Validation loss: 3.028796839932068

Epoch: 5| Step: 6
Training loss: 3.648389011363079
Validation loss: 3.029033129763363

Epoch: 5| Step: 7
Training loss: 3.6048933998039656
Validation loss: 3.0294341566668566

Epoch: 5| Step: 8
Training loss: 2.843903757486906
Validation loss: 3.028352144505399

Epoch: 5| Step: 9
Training loss: 3.5766034618480176
Validation loss: 3.0309567586087347

Epoch: 5| Step: 10
Training loss: 2.4913053954492965
Validation loss: 3.0318913932992273

Epoch: 76| Step: 0
Training loss: 3.6901521358813523
Validation loss: 3.031872078997255

Epoch: 5| Step: 1
Training loss: 3.305810038782054
Validation loss: 3.0307263445420705

Epoch: 5| Step: 2
Training loss: 2.6513500121738818
Validation loss: 3.0278075579471695

Epoch: 5| Step: 3
Training loss: 3.7884549941870707
Validation loss: 3.027250139295576

Epoch: 5| Step: 4
Training loss: 3.5982334200009887
Validation loss: 3.0246630388844533

Epoch: 5| Step: 5
Training loss: 2.960569977912397
Validation loss: 3.0235118177964995

Epoch: 5| Step: 6
Training loss: 2.6974555742142665
Validation loss: 3.0269087809157753

Epoch: 5| Step: 7
Training loss: 3.1369481365086385
Validation loss: 3.0243206789921024

Epoch: 5| Step: 8
Training loss: 3.5747263396832896
Validation loss: 3.0255383536127844

Epoch: 5| Step: 9
Training loss: 3.9933110576468995
Validation loss: 3.0243775065814225

Epoch: 5| Step: 10
Training loss: 2.357442911049475
Validation loss: 3.0241924824046236

Epoch: 77| Step: 0
Training loss: 3.394335566632122
Validation loss: 3.024585968398823

Epoch: 5| Step: 1
Training loss: 3.626709896512528
Validation loss: 3.025688201715771

Epoch: 5| Step: 2
Training loss: 3.6944655240125974
Validation loss: 3.026356259868997

Epoch: 5| Step: 3
Training loss: 3.3016643719678824
Validation loss: 3.0302714155362103

Epoch: 5| Step: 4
Training loss: 3.1096445858125397
Validation loss: 3.045425633211302

Epoch: 5| Step: 5
Training loss: 2.3722990639495514
Validation loss: 3.043604870568192

Epoch: 5| Step: 6
Training loss: 3.647318306908403
Validation loss: 3.034366919486893

Epoch: 5| Step: 7
Training loss: 2.976119842054419
Validation loss: 3.0274418280754576

Epoch: 5| Step: 8
Training loss: 3.6113817325489808
Validation loss: 3.0239209433577874

Epoch: 5| Step: 9
Training loss: 3.6057218750020312
Validation loss: 3.021669958667007

Epoch: 5| Step: 10
Training loss: 2.503845880646563
Validation loss: 3.020160183924904

Epoch: 78| Step: 0
Training loss: 3.455733612831933
Validation loss: 3.0197060070979402

Epoch: 5| Step: 1
Training loss: 3.7225637674602186
Validation loss: 3.0211667800083153

Epoch: 5| Step: 2
Training loss: 3.2004641017536457
Validation loss: 3.0180594846495907

Epoch: 5| Step: 3
Training loss: 3.5233008110785375
Validation loss: 3.0183950049479304

Epoch: 5| Step: 4
Training loss: 2.7634622339325685
Validation loss: 3.0169055397703795

Epoch: 5| Step: 5
Training loss: 3.06489282666465
Validation loss: 3.0158846993752944

Epoch: 5| Step: 6
Training loss: 2.7520141161623135
Validation loss: 3.016675319556109

Epoch: 5| Step: 7
Training loss: 3.0448515604353275
Validation loss: 3.0195512443408696

Epoch: 5| Step: 8
Training loss: 3.292784553344797
Validation loss: 3.0231377818546954

Epoch: 5| Step: 9
Training loss: 3.9133854506973855
Validation loss: 3.0306342628308065

Epoch: 5| Step: 10
Training loss: 3.2856365129495155
Validation loss: 3.0225965831215262

Epoch: 79| Step: 0
Training loss: 3.2508504195075183
Validation loss: 3.019476796800228

Epoch: 5| Step: 1
Training loss: 3.575963196012487
Validation loss: 3.0170144088442212

Epoch: 5| Step: 2
Training loss: 3.2269369651612383
Validation loss: 3.015245918235134

Epoch: 5| Step: 3
Training loss: 3.224277675673451
Validation loss: 3.0141711591412963

Epoch: 5| Step: 4
Training loss: 3.7690917712562224
Validation loss: 3.0172665371521137

Epoch: 5| Step: 5
Training loss: 3.25863907754377
Validation loss: 3.0150981215185784

Epoch: 5| Step: 6
Training loss: 3.1243082425272526
Validation loss: 3.013036799848757

Epoch: 5| Step: 7
Training loss: 3.6618669190572373
Validation loss: 3.0134333921033707

Epoch: 5| Step: 8
Training loss: 3.281308709482213
Validation loss: 3.011409686152681

Epoch: 5| Step: 9
Training loss: 2.7182668497767946
Validation loss: 3.0153013312089514

Epoch: 5| Step: 10
Training loss: 2.79442271554267
Validation loss: 3.0119502606613637

Epoch: 80| Step: 0
Training loss: 2.9425644740946804
Validation loss: 3.0099819525345017

Epoch: 5| Step: 1
Training loss: 3.1561540645711643
Validation loss: 3.008660364315303

Epoch: 5| Step: 2
Training loss: 3.0768586472954866
Validation loss: 3.0095809921735723

Epoch: 5| Step: 3
Training loss: 2.926842694329272
Validation loss: 3.008973836787629

Epoch: 5| Step: 4
Training loss: 3.2373884969826388
Validation loss: 3.009002575405514

Epoch: 5| Step: 5
Training loss: 3.463830019006956
Validation loss: 3.008095665163701

Epoch: 5| Step: 6
Training loss: 3.2070007694482547
Validation loss: 3.008909586056806

Epoch: 5| Step: 7
Training loss: 3.504733018923916
Validation loss: 3.0074578666257135

Epoch: 5| Step: 8
Training loss: 3.434200576087797
Validation loss: 3.007157034930507

Epoch: 5| Step: 9
Training loss: 3.4565001688642223
Validation loss: 3.005562376042489

Epoch: 5| Step: 10
Training loss: 3.6447942215717117
Validation loss: 3.0060977441088093

Epoch: 81| Step: 0
Training loss: 2.9587373233808862
Validation loss: 3.0051962976873496

Epoch: 5| Step: 1
Training loss: 3.240094863068007
Validation loss: 3.00664333232906

Epoch: 5| Step: 2
Training loss: 3.4256541664623246
Validation loss: 3.0063088353200915

Epoch: 5| Step: 3
Training loss: 3.51536755784832
Validation loss: 3.0051673494950495

Epoch: 5| Step: 4
Training loss: 3.3612152027444115
Validation loss: 3.008083652291521

Epoch: 5| Step: 5
Training loss: 3.143936916126112
Validation loss: 3.005983120382436

Epoch: 5| Step: 6
Training loss: 3.221445084905002
Validation loss: 3.0036235054157365

Epoch: 5| Step: 7
Training loss: 3.3799247132894665
Validation loss: 3.001188748533451

Epoch: 5| Step: 8
Training loss: 3.2438210657820696
Validation loss: 3.002970989859332

Epoch: 5| Step: 9
Training loss: 3.6536905834732014
Validation loss: 3.001387418872392

Epoch: 5| Step: 10
Training loss: 2.7288421457331213
Validation loss: 3.0001848891925778

Epoch: 82| Step: 0
Training loss: 3.194333698361719
Validation loss: 3.0021790141727176

Epoch: 5| Step: 1
Training loss: 2.8425283637598584
Validation loss: 3.002648657584312

Epoch: 5| Step: 2
Training loss: 3.332374259940349
Validation loss: 2.9994426879598493

Epoch: 5| Step: 3
Training loss: 3.1327710993212046
Validation loss: 3.003100191376901

Epoch: 5| Step: 4
Training loss: 3.538387411036425
Validation loss: 3.000751749828487

Epoch: 5| Step: 5
Training loss: 3.4795500188149413
Validation loss: 3.001123111296536

Epoch: 5| Step: 6
Training loss: 4.093055491466685
Validation loss: 3.000282693006404

Epoch: 5| Step: 7
Training loss: 2.846186003235672
Validation loss: 3.0018229782363868

Epoch: 5| Step: 8
Training loss: 3.512167081972943
Validation loss: 2.9976093549782963

Epoch: 5| Step: 9
Training loss: 3.0842051605183416
Validation loss: 2.9965569630791626

Epoch: 5| Step: 10
Training loss: 2.5692235616875423
Validation loss: 2.9976597463221952

Epoch: 83| Step: 0
Training loss: 2.8115996721114196
Validation loss: 2.998081313671598

Epoch: 5| Step: 1
Training loss: 2.9307668910025875
Validation loss: 2.997267601624614

Epoch: 5| Step: 2
Training loss: 3.6227824564477515
Validation loss: 2.9954235478548497

Epoch: 5| Step: 3
Training loss: 2.9167889887272858
Validation loss: 2.9971577329979326

Epoch: 5| Step: 4
Training loss: 3.359100188614272
Validation loss: 2.996370536709701

Epoch: 5| Step: 5
Training loss: 3.6485538178225974
Validation loss: 2.9967587601171672

Epoch: 5| Step: 6
Training loss: 3.1185240210726812
Validation loss: 2.9976596351443705

Epoch: 5| Step: 7
Training loss: 3.569532313339399
Validation loss: 2.996779928675783

Epoch: 5| Step: 8
Training loss: 2.8176344734331504
Validation loss: 2.9953108941554025

Epoch: 5| Step: 9
Training loss: 3.199498649900914
Validation loss: 2.9946696035683225

Epoch: 5| Step: 10
Training loss: 3.8790436842313087
Validation loss: 2.996846893735468

Epoch: 84| Step: 0
Training loss: 3.1602415019113383
Validation loss: 2.995130079640685

Epoch: 5| Step: 1
Training loss: 2.9710905786738597
Validation loss: 3.0013428659808903

Epoch: 5| Step: 2
Training loss: 2.856738433144139
Validation loss: 3.0080013663854577

Epoch: 5| Step: 3
Training loss: 3.2483196316060323
Validation loss: 3.0122526706990795

Epoch: 5| Step: 4
Training loss: 4.032099198195873
Validation loss: 3.005950660888989

Epoch: 5| Step: 5
Training loss: 2.5816481128548827
Validation loss: 2.9964349048729764

Epoch: 5| Step: 6
Training loss: 3.857886146902334
Validation loss: 2.992977298880652

Epoch: 5| Step: 7
Training loss: 3.3382111781055595
Validation loss: 2.9928587925679153

Epoch: 5| Step: 8
Training loss: 3.168502894290218
Validation loss: 2.9904276795398452

Epoch: 5| Step: 9
Training loss: 3.594208928534963
Validation loss: 2.989766972830607

Epoch: 5| Step: 10
Training loss: 2.7341497709974414
Validation loss: 2.9914387005068663

Epoch: 85| Step: 0
Training loss: 3.986119744752638
Validation loss: 2.9900177436384716

Epoch: 5| Step: 1
Training loss: 3.5708489547144464
Validation loss: 2.989361502693998

Epoch: 5| Step: 2
Training loss: 2.4692164113285253
Validation loss: 2.9899276158420314

Epoch: 5| Step: 3
Training loss: 3.0661624106871668
Validation loss: 2.9902058598124257

Epoch: 5| Step: 4
Training loss: 3.1093401882964136
Validation loss: 2.9913731047220518

Epoch: 5| Step: 5
Training loss: 3.461985547789804
Validation loss: 2.98903767878245

Epoch: 5| Step: 6
Training loss: 2.723796764320711
Validation loss: 2.9887541357429273

Epoch: 5| Step: 7
Training loss: 2.853362051234011
Validation loss: 2.985531294795005

Epoch: 5| Step: 8
Training loss: 3.908574869681001
Validation loss: 2.9895106841273438

Epoch: 5| Step: 9
Training loss: 3.258881830227391
Validation loss: 2.9972411668055017

Epoch: 5| Step: 10
Training loss: 3.165257207173066
Validation loss: 3.0001926719158054

Epoch: 86| Step: 0
Training loss: 3.539265944673277
Validation loss: 3.0063927365744982

Epoch: 5| Step: 1
Training loss: 2.8850902459956194
Validation loss: 3.0049897744618

Epoch: 5| Step: 2
Training loss: 3.1458838924025057
Validation loss: 2.996655606487106

Epoch: 5| Step: 3
Training loss: 2.9407188149222123
Validation loss: 2.987658958618596

Epoch: 5| Step: 4
Training loss: 3.493665958274049
Validation loss: 2.9851429981966677

Epoch: 5| Step: 5
Training loss: 2.9396562170288565
Validation loss: 2.9843537821072097

Epoch: 5| Step: 6
Training loss: 3.3705426204325533
Validation loss: 2.984321736789965

Epoch: 5| Step: 7
Training loss: 3.3445564794802904
Validation loss: 2.9849970278367253

Epoch: 5| Step: 8
Training loss: 3.619101493776241
Validation loss: 2.9840323477985495

Epoch: 5| Step: 9
Training loss: 3.106105292958109
Validation loss: 2.9856443320933947

Epoch: 5| Step: 10
Training loss: 3.4351628074210354
Validation loss: 2.9864540789007994

Epoch: 87| Step: 0
Training loss: 2.9048599692653068
Validation loss: 2.9850657910833935

Epoch: 5| Step: 1
Training loss: 3.630153807016675
Validation loss: 2.985626995783725

Epoch: 5| Step: 2
Training loss: 3.144292559360935
Validation loss: 2.983807896083566

Epoch: 5| Step: 3
Training loss: 3.148506409906166
Validation loss: 2.983257491435054

Epoch: 5| Step: 4
Training loss: 2.762998465190714
Validation loss: 2.9819650057594957

Epoch: 5| Step: 5
Training loss: 3.098450913546908
Validation loss: 2.982347705774987

Epoch: 5| Step: 6
Training loss: 3.348869896052768
Validation loss: 2.9813075314189925

Epoch: 5| Step: 7
Training loss: 3.627827561020507
Validation loss: 2.9810146910779474

Epoch: 5| Step: 8
Training loss: 3.2820503348722068
Validation loss: 2.980595563904642

Epoch: 5| Step: 9
Training loss: 3.2483131726185555
Validation loss: 2.980144955956091

Epoch: 5| Step: 10
Training loss: 3.6249939490958387
Validation loss: 2.9803466909505083

Epoch: 88| Step: 0
Training loss: 2.680042832729752
Validation loss: 2.980573438347832

Epoch: 5| Step: 1
Training loss: 2.9599082587175594
Validation loss: 2.979979943544294

Epoch: 5| Step: 2
Training loss: 3.4155240978473675
Validation loss: 2.9783969581563285

Epoch: 5| Step: 3
Training loss: 3.6658586276402203
Validation loss: 2.9770130508407227

Epoch: 5| Step: 4
Training loss: 3.42494683885736
Validation loss: 2.976424785736953

Epoch: 5| Step: 5
Training loss: 3.214556137698415
Validation loss: 2.977302049213763

Epoch: 5| Step: 6
Training loss: 3.554112113244767
Validation loss: 2.975248686393354

Epoch: 5| Step: 7
Training loss: 3.18768040763587
Validation loss: 2.9754619411751504

Epoch: 5| Step: 8
Training loss: 2.9506176188868904
Validation loss: 2.97467288684048

Epoch: 5| Step: 9
Training loss: 3.702096015480543
Validation loss: 2.976155776154118

Epoch: 5| Step: 10
Training loss: 2.8368318686995764
Validation loss: 2.9752422196586683

Epoch: 89| Step: 0
Training loss: 2.4916942909606132
Validation loss: 2.975367396084162

Epoch: 5| Step: 1
Training loss: 3.380045898171011
Validation loss: 2.973550492299026

Epoch: 5| Step: 2
Training loss: 3.601089016124259
Validation loss: 2.9748719991417873

Epoch: 5| Step: 3
Training loss: 2.544448726581966
Validation loss: 2.9700973087297933

Epoch: 5| Step: 4
Training loss: 3.903068284293826
Validation loss: 2.972535706291679

Epoch: 5| Step: 5
Training loss: 2.8342734254513497
Validation loss: 2.969783309095076

Epoch: 5| Step: 6
Training loss: 2.684385935147165
Validation loss: 2.973572847712855

Epoch: 5| Step: 7
Training loss: 3.8937419370809625
Validation loss: 2.976394746347947

Epoch: 5| Step: 8
Training loss: 2.6464468977973707
Validation loss: 2.982966951556546

Epoch: 5| Step: 9
Training loss: 3.7193781218069337
Validation loss: 2.9804139727684444

Epoch: 5| Step: 10
Training loss: 3.6305264407015825
Validation loss: 2.9802587876536095

Epoch: 90| Step: 0
Training loss: 2.6382390365408934
Validation loss: 2.9727979272173326

Epoch: 5| Step: 1
Training loss: 3.532285960327927
Validation loss: 2.9723306466539925

Epoch: 5| Step: 2
Training loss: 3.206323431709669
Validation loss: 2.9721612680302103

Epoch: 5| Step: 3
Training loss: 3.7549694195148513
Validation loss: 2.9696495709612996

Epoch: 5| Step: 4
Training loss: 2.8046335199203463
Validation loss: 2.9717418506212687

Epoch: 5| Step: 5
Training loss: 2.6594246237727455
Validation loss: 2.9684700635824233

Epoch: 5| Step: 6
Training loss: 3.1234661152508307
Validation loss: 2.9707101116322234

Epoch: 5| Step: 7
Training loss: 3.321405926347408
Validation loss: 2.9695120869023413

Epoch: 5| Step: 8
Training loss: 3.5681570545920973
Validation loss: 2.9684631416316507

Epoch: 5| Step: 9
Training loss: 3.433618191750322
Validation loss: 2.9681461188514944

Epoch: 5| Step: 10
Training loss: 3.47308532329726
Validation loss: 2.9670533958811416

Epoch: 91| Step: 0
Training loss: 2.7349627925706055
Validation loss: 2.9656969244436313

Epoch: 5| Step: 1
Training loss: 3.4887697704360483
Validation loss: 2.9646209810797846

Epoch: 5| Step: 2
Training loss: 2.445875791563494
Validation loss: 2.9642588955005236

Epoch: 5| Step: 3
Training loss: 3.595484704672743
Validation loss: 2.9656949587266728

Epoch: 5| Step: 4
Training loss: 3.4019305638533095
Validation loss: 2.9666595629194195

Epoch: 5| Step: 5
Training loss: 3.3837968129871556
Validation loss: 2.9665116166480194

Epoch: 5| Step: 6
Training loss: 3.041027541924306
Validation loss: 2.9674484474021

Epoch: 5| Step: 7
Training loss: 3.577161767566618
Validation loss: 2.965246385041516

Epoch: 5| Step: 8
Training loss: 2.4932782408123644
Validation loss: 2.9678051207505227

Epoch: 5| Step: 9
Training loss: 3.876925451530642
Validation loss: 2.964384086013304

Epoch: 5| Step: 10
Training loss: 3.304106821397733
Validation loss: 2.964750157305646

Epoch: 92| Step: 0
Training loss: 2.913498729343507
Validation loss: 2.9635622388697094

Epoch: 5| Step: 1
Training loss: 3.713503173514485
Validation loss: 2.9624115614633886

Epoch: 5| Step: 2
Training loss: 2.951109183028688
Validation loss: 2.960202245648552

Epoch: 5| Step: 3
Training loss: 3.38130221229616
Validation loss: 2.9656468336964674

Epoch: 5| Step: 4
Training loss: 3.7972808746543394
Validation loss: 2.961861087814947

Epoch: 5| Step: 5
Training loss: 3.0931565457283012
Validation loss: 2.971082510904853

Epoch: 5| Step: 6
Training loss: 2.7241475688101136
Validation loss: 2.9702794554965943

Epoch: 5| Step: 7
Training loss: 2.8357895321246627
Validation loss: 2.9700608593916806

Epoch: 5| Step: 8
Training loss: 3.3438672196706745
Validation loss: 2.966167568100614

Epoch: 5| Step: 9
Training loss: 3.3965580796793766
Validation loss: 2.961972508913214

Epoch: 5| Step: 10
Training loss: 3.323878915272937
Validation loss: 2.966118264907704

Epoch: 93| Step: 0
Training loss: 3.0845029176354117
Validation loss: 2.959126090824918

Epoch: 5| Step: 1
Training loss: 3.6642461214234365
Validation loss: 2.9560530622716534

Epoch: 5| Step: 2
Training loss: 3.1543780526028704
Validation loss: 2.955358973399996

Epoch: 5| Step: 3
Training loss: 2.9861911220821984
Validation loss: 2.9546818997693096

Epoch: 5| Step: 4
Training loss: 2.9418260900363493
Validation loss: 2.96320031288165

Epoch: 5| Step: 5
Training loss: 3.641909655066823
Validation loss: 2.959870694783083

Epoch: 5| Step: 6
Training loss: 2.711364096900432
Validation loss: 2.955468693999191

Epoch: 5| Step: 7
Training loss: 3.594094301399321
Validation loss: 2.9562218653009076

Epoch: 5| Step: 8
Training loss: 3.111832304272997
Validation loss: 2.95341771082504

Epoch: 5| Step: 9
Training loss: 3.3871504036661353
Validation loss: 2.9583746130034902

Epoch: 5| Step: 10
Training loss: 3.1611405055223813
Validation loss: 2.9628828213014278

Epoch: 94| Step: 0
Training loss: 2.805623527895277
Validation loss: 2.977600566047047

Epoch: 5| Step: 1
Training loss: 2.786764443003932
Validation loss: 2.9836951878883453

Epoch: 5| Step: 2
Training loss: 3.2667399424165056
Validation loss: 2.982601116842042

Epoch: 5| Step: 3
Training loss: 2.855985372960009
Validation loss: 2.9797935193509293

Epoch: 5| Step: 4
Training loss: 2.8445252420288103
Validation loss: 2.9705572908348197

Epoch: 5| Step: 5
Training loss: 3.219214100387438
Validation loss: 2.9631428657399415

Epoch: 5| Step: 6
Training loss: 3.3597989546709646
Validation loss: 2.961743503894421

Epoch: 5| Step: 7
Training loss: 3.591301656232677
Validation loss: 2.9582027531849486

Epoch: 5| Step: 8
Training loss: 3.637235840319606
Validation loss: 2.9578987572491364

Epoch: 5| Step: 9
Training loss: 3.7565969297428903
Validation loss: 2.95502710208555

Epoch: 5| Step: 10
Training loss: 3.5497889711223616
Validation loss: 2.9546891320877418

Epoch: 95| Step: 0
Training loss: 3.4093552180624545
Validation loss: 2.954304431989254

Epoch: 5| Step: 1
Training loss: 3.619479217583457
Validation loss: 2.9550383967276956

Epoch: 5| Step: 2
Training loss: 2.98412285982895
Validation loss: 2.9533812283737566

Epoch: 5| Step: 3
Training loss: 3.331270262923174
Validation loss: 2.953500973220828

Epoch: 5| Step: 4
Training loss: 3.531634149502207
Validation loss: 2.955736503828681

Epoch: 5| Step: 5
Training loss: 2.986027764234093
Validation loss: 2.953090226736462

Epoch: 5| Step: 6
Training loss: 2.7696859426837284
Validation loss: 2.953774335625204

Epoch: 5| Step: 7
Training loss: 2.6970548885815218
Validation loss: 2.9542223663565936

Epoch: 5| Step: 8
Training loss: 3.1151373295033142
Validation loss: 2.9602467491533004

Epoch: 5| Step: 9
Training loss: 3.915572493825997
Validation loss: 2.965565946409783

Epoch: 5| Step: 10
Training loss: 2.9986416602589623
Validation loss: 2.95670701357095

Epoch: 96| Step: 0
Training loss: 3.0458392608070013
Validation loss: 2.9544110279981766

Epoch: 5| Step: 1
Training loss: 2.9849781006180653
Validation loss: 2.956554568458067

Epoch: 5| Step: 2
Training loss: 2.8184056479818387
Validation loss: 2.9568923278392845

Epoch: 5| Step: 3
Training loss: 3.278053688750098
Validation loss: 2.960625762204715

Epoch: 5| Step: 4
Training loss: 3.4225768323233794
Validation loss: 2.9510761790381155

Epoch: 5| Step: 5
Training loss: 3.532676341196973
Validation loss: 2.953023007336312

Epoch: 5| Step: 6
Training loss: 2.769613375071598
Validation loss: 2.9500675011544457

Epoch: 5| Step: 7
Training loss: 3.370260796572583
Validation loss: 2.9456570923314382

Epoch: 5| Step: 8
Training loss: 3.089764426427269
Validation loss: 2.94393131688847

Epoch: 5| Step: 9
Training loss: 3.7514302387302325
Validation loss: 2.9424004523912144

Epoch: 5| Step: 10
Training loss: 3.3330315612250896
Validation loss: 2.9439746852543656

Epoch: 97| Step: 0
Training loss: 3.40423230248391
Validation loss: 2.9457652675124413

Epoch: 5| Step: 1
Training loss: 3.7292949008027403
Validation loss: 2.945252089181318

Epoch: 5| Step: 2
Training loss: 3.1604566584558675
Validation loss: 2.9447699489625734

Epoch: 5| Step: 3
Training loss: 3.235405651760736
Validation loss: 2.9409059211960216

Epoch: 5| Step: 4
Training loss: 3.028121907298553
Validation loss: 2.941419194525068

Epoch: 5| Step: 5
Training loss: 2.6797746026921985
Validation loss: 2.942993219676775

Epoch: 5| Step: 6
Training loss: 3.9213594500534428
Validation loss: 2.9424525568025515

Epoch: 5| Step: 7
Training loss: 2.7277015558415623
Validation loss: 2.9405554539854903

Epoch: 5| Step: 8
Training loss: 3.223654260711365
Validation loss: 2.9396332792653603

Epoch: 5| Step: 9
Training loss: 2.6955182425437654
Validation loss: 2.9396932020731534

Epoch: 5| Step: 10
Training loss: 3.4903026845231984
Validation loss: 2.940001061617696

Epoch: 98| Step: 0
Training loss: 3.307537031708865
Validation loss: 2.9401029967925143

Epoch: 5| Step: 1
Training loss: 2.470126866623076
Validation loss: 2.9392546712978826

Epoch: 5| Step: 2
Training loss: 2.7264416512101652
Validation loss: 2.939409729169798

Epoch: 5| Step: 3
Training loss: 3.1047901491763277
Validation loss: 2.937062742582318

Epoch: 5| Step: 4
Training loss: 3.6130979419296225
Validation loss: 2.934480225484861

Epoch: 5| Step: 5
Training loss: 2.8562595091813807
Validation loss: 2.9349221198358473

Epoch: 5| Step: 6
Training loss: 3.5798282484060513
Validation loss: 2.944930264313268

Epoch: 5| Step: 7
Training loss: 2.7048134354087034
Validation loss: 2.9478064513220006

Epoch: 5| Step: 8
Training loss: 3.5036723081131833
Validation loss: 2.9486747441529

Epoch: 5| Step: 9
Training loss: 3.703944634619049
Validation loss: 2.9348913726407324

Epoch: 5| Step: 10
Training loss: 3.6613009524357105
Validation loss: 2.9351113914262874

Epoch: 99| Step: 0
Training loss: 2.8199696002160337
Validation loss: 2.937186511331787

Epoch: 5| Step: 1
Training loss: 2.738968919285907
Validation loss: 2.935746447356394

Epoch: 5| Step: 2
Training loss: 2.895472405717331
Validation loss: 2.9374716981437734

Epoch: 5| Step: 3
Training loss: 2.2552368890541703
Validation loss: 2.938212748754259

Epoch: 5| Step: 4
Training loss: 4.226391237071403
Validation loss: 2.9348107269826142

Epoch: 5| Step: 5
Training loss: 3.0377715440729727
Validation loss: 2.9389496705973706

Epoch: 5| Step: 6
Training loss: 3.5958706113813923
Validation loss: 2.939019351571909

Epoch: 5| Step: 7
Training loss: 3.086202798376594
Validation loss: 2.9411873715239096

Epoch: 5| Step: 8
Training loss: 3.1651839917836155
Validation loss: 2.9404027887773427

Epoch: 5| Step: 9
Training loss: 3.7065859045748777
Validation loss: 2.938479366516604

Epoch: 5| Step: 10
Training loss: 3.5759350600863935
Validation loss: 2.9349070956784784

Epoch: 100| Step: 0
Training loss: 2.8636476040353944
Validation loss: 2.9343641408983445

Epoch: 5| Step: 1
Training loss: 2.977417990630502
Validation loss: 2.9346402992561273

Epoch: 5| Step: 2
Training loss: 3.0758840081081487
Validation loss: 2.931969926049515

Epoch: 5| Step: 3
Training loss: 3.157005748348422
Validation loss: 2.9313201673403073

Epoch: 5| Step: 4
Training loss: 3.535344273746354
Validation loss: 2.9289044162330917

Epoch: 5| Step: 5
Training loss: 3.096579134730208
Validation loss: 2.9291693982824727

Epoch: 5| Step: 6
Training loss: 3.4408121971047225
Validation loss: 2.9304973574030595

Epoch: 5| Step: 7
Training loss: 2.995980112638792
Validation loss: 2.930120207302935

Epoch: 5| Step: 8
Training loss: 3.170742791211936
Validation loss: 2.9291278884914504

Epoch: 5| Step: 9
Training loss: 3.670149247463545
Validation loss: 2.9287748984643054

Epoch: 5| Step: 10
Training loss: 3.36579260731975
Validation loss: 2.9269557953268293

Epoch: 101| Step: 0
Training loss: 3.041195628303016
Validation loss: 2.928345435108272

Epoch: 5| Step: 1
Training loss: 2.967259404263871
Validation loss: 2.93149874531483

Epoch: 5| Step: 2
Training loss: 2.3574418997052375
Validation loss: 2.9303548913260684

Epoch: 5| Step: 3
Training loss: 3.506138187468375
Validation loss: 2.932017454929989

Epoch: 5| Step: 4
Training loss: 3.7348594191724866
Validation loss: 2.935622597806808

Epoch: 5| Step: 5
Training loss: 2.8461865058420885
Validation loss: 2.9363315224550623

Epoch: 5| Step: 6
Training loss: 3.235881657212962
Validation loss: 2.9334490589510613

Epoch: 5| Step: 7
Training loss: 3.8949073602239324
Validation loss: 2.9343418842901894

Epoch: 5| Step: 8
Training loss: 2.8874926942675097
Validation loss: 2.935004595848857

Epoch: 5| Step: 9
Training loss: 3.1804675146038193
Validation loss: 2.929518294284862

Epoch: 5| Step: 10
Training loss: 3.4022617614888135
Validation loss: 2.9277403538621996

Epoch: 102| Step: 0
Training loss: 3.235434243538678
Validation loss: 2.929130515910269

Epoch: 5| Step: 1
Training loss: 2.6845024602647474
Validation loss: 2.9277359353896424

Epoch: 5| Step: 2
Training loss: 3.6328820662862076
Validation loss: 2.926297330390018

Epoch: 5| Step: 3
Training loss: 2.7956159944003347
Validation loss: 2.9212341491978835

Epoch: 5| Step: 4
Training loss: 3.263071476370063
Validation loss: 2.9228335765792326

Epoch: 5| Step: 5
Training loss: 3.2280174097114007
Validation loss: 2.9203255715938456

Epoch: 5| Step: 6
Training loss: 3.4772907308745937
Validation loss: 2.923403960374871

Epoch: 5| Step: 7
Training loss: 3.4127292430297587
Validation loss: 2.9239383747169834

Epoch: 5| Step: 8
Training loss: 3.6677489128493406
Validation loss: 2.9273936017052087

Epoch: 5| Step: 9
Training loss: 2.8337821231025897
Validation loss: 2.9222208594542276

Epoch: 5| Step: 10
Training loss: 2.9395661899455168
Validation loss: 2.9213491311744733

Epoch: 103| Step: 0
Training loss: 2.8650238438224886
Validation loss: 2.9208628364589506

Epoch: 5| Step: 1
Training loss: 3.562135108865675
Validation loss: 2.9200857265416986

Epoch: 5| Step: 2
Training loss: 2.877461747777773
Validation loss: 2.9193543103163835

Epoch: 5| Step: 3
Training loss: 2.621486674162678
Validation loss: 2.9197644993995557

Epoch: 5| Step: 4
Training loss: 3.1250204467104528
Validation loss: 2.9192808843607247

Epoch: 5| Step: 5
Training loss: 2.541923905993227
Validation loss: 2.917940039938996

Epoch: 5| Step: 6
Training loss: 3.376673954400059
Validation loss: 2.9219250058640727

Epoch: 5| Step: 7
Training loss: 3.2207327356128213
Validation loss: 2.9195296419699974

Epoch: 5| Step: 8
Training loss: 3.8848895958883065
Validation loss: 2.920878901831333

Epoch: 5| Step: 9
Training loss: 3.5010243687897082
Validation loss: 2.921776845846338

Epoch: 5| Step: 10
Training loss: 3.499985149896998
Validation loss: 2.918052153242327

Epoch: 104| Step: 0
Training loss: 2.8567350948095456
Validation loss: 2.9163692451634793

Epoch: 5| Step: 1
Training loss: 4.007087865092221
Validation loss: 2.916684366573883

Epoch: 5| Step: 2
Training loss: 2.787575376030356
Validation loss: 2.9166547016185507

Epoch: 5| Step: 3
Training loss: 2.641509410216802
Validation loss: 2.9178768536154402

Epoch: 5| Step: 4
Training loss: 2.8560656799008868
Validation loss: 2.9151916757474394

Epoch: 5| Step: 5
Training loss: 3.215076609599034
Validation loss: 2.9167378813902145

Epoch: 5| Step: 6
Training loss: 3.0080726411956
Validation loss: 2.9141551509464745

Epoch: 5| Step: 7
Training loss: 2.689397629862723
Validation loss: 2.916659560539156

Epoch: 5| Step: 8
Training loss: 3.3926257721449
Validation loss: 2.9146058371309733

Epoch: 5| Step: 9
Training loss: 3.5886398471787038
Validation loss: 2.9156425441870084

Epoch: 5| Step: 10
Training loss: 3.987455366596364
Validation loss: 2.9142219763523602

Epoch: 105| Step: 0
Training loss: 3.216493871392736
Validation loss: 2.913672698061676

Epoch: 5| Step: 1
Training loss: 3.1746684584641263
Validation loss: 2.9153377024973044

Epoch: 5| Step: 2
Training loss: 3.770403730392958
Validation loss: 2.911697868886567

Epoch: 5| Step: 3
Training loss: 2.7214855594339498
Validation loss: 2.910490523924828

Epoch: 5| Step: 4
Training loss: 2.7622902803518
Validation loss: 2.913855621675504

Epoch: 5| Step: 5
Training loss: 3.3560771990002576
Validation loss: 2.910471593114618

Epoch: 5| Step: 6
Training loss: 2.886209445567678
Validation loss: 2.9162044076795635

Epoch: 5| Step: 7
Training loss: 3.145729585330474
Validation loss: 2.911420216783133

Epoch: 5| Step: 8
Training loss: 2.8820823013445733
Validation loss: 2.9147154391517947

Epoch: 5| Step: 9
Training loss: 2.985613820464517
Validation loss: 2.913712761590511

Epoch: 5| Step: 10
Training loss: 4.137711792103423
Validation loss: 2.920730503544803

Epoch: 106| Step: 0
Training loss: 2.79569479480167
Validation loss: 2.9204141201149416

Epoch: 5| Step: 1
Training loss: 3.4761927032961246
Validation loss: 2.91765082729451

Epoch: 5| Step: 2
Training loss: 3.3467087534300988
Validation loss: 2.9097459390279194

Epoch: 5| Step: 3
Training loss: 3.331848067942409
Validation loss: 2.914442427834151

Epoch: 5| Step: 4
Training loss: 2.9328062826668915
Validation loss: 2.908511505066346

Epoch: 5| Step: 5
Training loss: 2.8071164635014068
Validation loss: 2.9068449868808384

Epoch: 5| Step: 6
Training loss: 3.226933270965812
Validation loss: 2.903178606481401

Epoch: 5| Step: 7
Training loss: 2.8407253067217733
Validation loss: 2.9028660778676856

Epoch: 5| Step: 8
Training loss: 3.751322576627285
Validation loss: 2.906416668690433

Epoch: 5| Step: 9
Training loss: 3.1400817097522955
Validation loss: 2.9032699596985294

Epoch: 5| Step: 10
Training loss: 3.388708460717487
Validation loss: 2.904809653743291

Epoch: 107| Step: 0
Training loss: 3.0135995654704058
Validation loss: 2.904117501811167

Epoch: 5| Step: 1
Training loss: 3.1507467504949354
Validation loss: 2.9059892657206867

Epoch: 5| Step: 2
Training loss: 3.1242097999957763
Validation loss: 2.9081064346995342

Epoch: 5| Step: 3
Training loss: 3.1550094130386213
Validation loss: 2.9067006982850923

Epoch: 5| Step: 4
Training loss: 3.3492338186876727
Validation loss: 2.9093227190696496

Epoch: 5| Step: 5
Training loss: 3.114380454575954
Validation loss: 2.913003337261171

Epoch: 5| Step: 6
Training loss: 2.860226363713993
Validation loss: 2.902918639306711

Epoch: 5| Step: 7
Training loss: 3.8826481805490562
Validation loss: 2.906822292027037

Epoch: 5| Step: 8
Training loss: 3.075907726754146
Validation loss: 2.907177552484039

Epoch: 5| Step: 9
Training loss: 3.3291685948626903
Validation loss: 2.905068786312486

Epoch: 5| Step: 10
Training loss: 2.883862973411542
Validation loss: 2.900977727273362

Epoch: 108| Step: 0
Training loss: 2.8945289436773876
Validation loss: 2.9042028520353367

Epoch: 5| Step: 1
Training loss: 3.3304156090445054
Validation loss: 2.9004447135634197

Epoch: 5| Step: 2
Training loss: 3.1079539976900903
Validation loss: 2.9003564534198127

Epoch: 5| Step: 3
Training loss: 3.1312892949423574
Validation loss: 2.897074233383017

Epoch: 5| Step: 4
Training loss: 3.7014953632956926
Validation loss: 2.8995133733188942

Epoch: 5| Step: 5
Training loss: 2.4800394482705364
Validation loss: 2.899327150363943

Epoch: 5| Step: 6
Training loss: 3.2017117988176245
Validation loss: 2.8960482757419603

Epoch: 5| Step: 7
Training loss: 2.9519450741958826
Validation loss: 2.896978862754676

Epoch: 5| Step: 8
Training loss: 2.9459179324277875
Validation loss: 2.8941376818623765

Epoch: 5| Step: 9
Training loss: 3.3183182775008033
Validation loss: 2.897027506830959

Epoch: 5| Step: 10
Training loss: 3.9022127574360774
Validation loss: 2.900423500402568

Epoch: 109| Step: 0
Training loss: 3.066283555218502
Validation loss: 2.905367965835616

Epoch: 5| Step: 1
Training loss: 2.8140647773797003
Validation loss: 2.9435719345124114

Epoch: 5| Step: 2
Training loss: 3.523333021420766
Validation loss: 2.9376560153168683

Epoch: 5| Step: 3
Training loss: 3.099798743575361
Validation loss: 2.9337915039524214

Epoch: 5| Step: 4
Training loss: 2.9310911351081477
Validation loss: 2.94507228733143

Epoch: 5| Step: 5
Training loss: 3.5297632378992505
Validation loss: 2.9463726438099203

Epoch: 5| Step: 6
Training loss: 2.7486366013350567
Validation loss: 2.930233004629362

Epoch: 5| Step: 7
Training loss: 3.3978098322579746
Validation loss: 2.906613088511753

Epoch: 5| Step: 8
Training loss: 3.104280678790957
Validation loss: 2.8976327725227202

Epoch: 5| Step: 9
Training loss: 2.9435592816362366
Validation loss: 2.8946534027606865

Epoch: 5| Step: 10
Training loss: 3.90917371053284
Validation loss: 2.8924772696399126

Epoch: 110| Step: 0
Training loss: 3.3715289598579226
Validation loss: 2.8948009273948876

Epoch: 5| Step: 1
Training loss: 3.2186574089287983
Validation loss: 2.8971783593776608

Epoch: 5| Step: 2
Training loss: 2.6210911121156157
Validation loss: 2.8973929265351983

Epoch: 5| Step: 3
Training loss: 2.8325459190208755
Validation loss: 2.89604134268851

Epoch: 5| Step: 4
Training loss: 2.8105380526703088
Validation loss: 2.896646157302826

Epoch: 5| Step: 5
Training loss: 3.0925478670799365
Validation loss: 2.895390321231049

Epoch: 5| Step: 6
Training loss: 3.8452227492478257
Validation loss: 2.895245228013158

Epoch: 5| Step: 7
Training loss: 3.0935112446836017
Validation loss: 2.8960083378688948

Epoch: 5| Step: 8
Training loss: 3.184640387051013
Validation loss: 2.8948359128788135

Epoch: 5| Step: 9
Training loss: 3.8268150112316626
Validation loss: 2.8960364898953084

Epoch: 5| Step: 10
Training loss: 2.9538692767662607
Validation loss: 2.8951478437320017

Epoch: 111| Step: 0
Training loss: 3.6300039284004413
Validation loss: 2.8941354124299563

Epoch: 5| Step: 1
Training loss: 3.1450131254422615
Validation loss: 2.89184500311705

Epoch: 5| Step: 2
Training loss: 2.555207365844228
Validation loss: 2.892719593457706

Epoch: 5| Step: 3
Training loss: 3.61421401072823
Validation loss: 2.889815398330286

Epoch: 5| Step: 4
Training loss: 3.237336650247566
Validation loss: 2.888558336470935

Epoch: 5| Step: 5
Training loss: 3.501138229574475
Validation loss: 2.8871022317353208

Epoch: 5| Step: 6
Training loss: 3.2128409060077803
Validation loss: 2.8873717248788093

Epoch: 5| Step: 7
Training loss: 2.833486964230618
Validation loss: 2.88901692465098

Epoch: 5| Step: 8
Training loss: 2.9598908600146463
Validation loss: 2.890663451360567

Epoch: 5| Step: 9
Training loss: 2.988555377030372
Validation loss: 2.89140998892912

Epoch: 5| Step: 10
Training loss: 3.2070938457369422
Validation loss: 2.8922056267212186

Epoch: 112| Step: 0
Training loss: 3.550304620057642
Validation loss: 2.9032715941650262

Epoch: 5| Step: 1
Training loss: 3.1138889384962116
Validation loss: 2.8998443176297584

Epoch: 5| Step: 2
Training loss: 3.1930896890135987
Validation loss: 2.9005808020226853

Epoch: 5| Step: 3
Training loss: 2.365127523262529
Validation loss: 2.8889059989044936

Epoch: 5| Step: 4
Training loss: 2.9131396266633076
Validation loss: 2.8875179506313997

Epoch: 5| Step: 5
Training loss: 2.929132759979639
Validation loss: 2.886605583147501

Epoch: 5| Step: 6
Training loss: 3.247978755674743
Validation loss: 2.8851778357950604

Epoch: 5| Step: 7
Training loss: 3.9648206587997534
Validation loss: 2.882965483120189

Epoch: 5| Step: 8
Training loss: 3.6573925352442487
Validation loss: 2.881141795418918

Epoch: 5| Step: 9
Training loss: 3.050937389720355
Validation loss: 2.8834666670907847

Epoch: 5| Step: 10
Training loss: 2.5701600003439795
Validation loss: 2.8816619950765756

Epoch: 113| Step: 0
Training loss: 3.2628708318080073
Validation loss: 2.8810304454458744

Epoch: 5| Step: 1
Training loss: 2.4024205637490934
Validation loss: 2.885831074053389

Epoch: 5| Step: 2
Training loss: 2.9335454741263325
Validation loss: 2.893159749515698

Epoch: 5| Step: 3
Training loss: 3.1363669610288585
Validation loss: 2.9061892491312653

Epoch: 5| Step: 4
Training loss: 3.041365116447779
Validation loss: 2.91522535553067

Epoch: 5| Step: 5
Training loss: 3.573597538228721
Validation loss: 2.9251089194462403

Epoch: 5| Step: 6
Training loss: 3.448809520599101
Validation loss: 2.938352739902871

Epoch: 5| Step: 7
Training loss: 3.3945618727941222
Validation loss: 2.9286233348847803

Epoch: 5| Step: 8
Training loss: 3.369811697207099
Validation loss: 2.8976094375112367

Epoch: 5| Step: 9
Training loss: 3.6367900771737824
Validation loss: 2.901304920603447

Epoch: 5| Step: 10
Training loss: 2.5663761502943805
Validation loss: 2.8940685794161443

Epoch: 114| Step: 0
Training loss: 3.5716223119229555
Validation loss: 2.886532291331368

Epoch: 5| Step: 1
Training loss: 2.873939650335325
Validation loss: 2.8829254920599503

Epoch: 5| Step: 2
Training loss: 3.176953389162967
Validation loss: 2.882812747221096

Epoch: 5| Step: 3
Training loss: 3.5048501604950206
Validation loss: 2.8842130479712997

Epoch: 5| Step: 4
Training loss: 2.357429156730676
Validation loss: 2.883228797399901

Epoch: 5| Step: 5
Training loss: 3.3731555843892798
Validation loss: 2.8832783638729396

Epoch: 5| Step: 6
Training loss: 2.864870554078487
Validation loss: 2.884392318662038

Epoch: 5| Step: 7
Training loss: 3.0503613992669285
Validation loss: 2.8834304189569444

Epoch: 5| Step: 8
Training loss: 3.5677483697951264
Validation loss: 2.882401253037925

Epoch: 5| Step: 9
Training loss: 3.1161986960155983
Validation loss: 2.882305123847028

Epoch: 5| Step: 10
Training loss: 3.362668574195258
Validation loss: 2.881658604658051

Epoch: 115| Step: 0
Training loss: 2.8069924576688248
Validation loss: 2.8814439148063316

Epoch: 5| Step: 1
Training loss: 3.84618530040497
Validation loss: 2.881341425862313

Epoch: 5| Step: 2
Training loss: 2.547979197406737
Validation loss: 2.880370628704943

Epoch: 5| Step: 3
Training loss: 3.5190914442360697
Validation loss: 2.879086210862636

Epoch: 5| Step: 4
Training loss: 2.9369852142533297
Validation loss: 2.881051975803923

Epoch: 5| Step: 5
Training loss: 3.010977053815508
Validation loss: 2.878590024556018

Epoch: 5| Step: 6
Training loss: 2.9799409051450563
Validation loss: 2.8769498502213406

Epoch: 5| Step: 7
Training loss: 3.7601553420179274
Validation loss: 2.8768186127376834

Epoch: 5| Step: 8
Training loss: 3.237600588616689
Validation loss: 2.876057798045906

Epoch: 5| Step: 9
Training loss: 3.199210701397843
Validation loss: 2.8767635488312617

Epoch: 5| Step: 10
Training loss: 2.8310545190690704
Validation loss: 2.8743590790368545

Epoch: 116| Step: 0
Training loss: 3.349931938277085
Validation loss: 2.8724028630272387

Epoch: 5| Step: 1
Training loss: 3.460012893652734
Validation loss: 2.8723272086463516

Epoch: 5| Step: 2
Training loss: 3.092007232854953
Validation loss: 2.8724346727051704

Epoch: 5| Step: 3
Training loss: 2.32891351032629
Validation loss: 2.8724218385630933

Epoch: 5| Step: 4
Training loss: 3.0364929162352214
Validation loss: 2.870235718667841

Epoch: 5| Step: 5
Training loss: 3.1184709626705733
Validation loss: 2.8728645369294585

Epoch: 5| Step: 6
Training loss: 3.3968798345199755
Validation loss: 2.876266493012832

Epoch: 5| Step: 7
Training loss: 2.814951696980865
Validation loss: 2.8739190934284564

Epoch: 5| Step: 8
Training loss: 3.473617986948261
Validation loss: 2.8710484110260572

Epoch: 5| Step: 9
Training loss: 3.166839059520747
Validation loss: 2.873980572816232

Epoch: 5| Step: 10
Training loss: 3.5145479035791696
Validation loss: 2.86986974291324

Epoch: 117| Step: 0
Training loss: 3.384784502525979
Validation loss: 2.8708701600203397

Epoch: 5| Step: 1
Training loss: 3.4263344886714253
Validation loss: 2.8696231703616015

Epoch: 5| Step: 2
Training loss: 2.900031214578944
Validation loss: 2.8661548075489134

Epoch: 5| Step: 3
Training loss: 3.3880746276635034
Validation loss: 2.868805021692711

Epoch: 5| Step: 4
Training loss: 2.8659870014734445
Validation loss: 2.8669974658730144

Epoch: 5| Step: 5
Training loss: 3.049949933250858
Validation loss: 2.868782551362469

Epoch: 5| Step: 6
Training loss: 3.1287126993233536
Validation loss: 2.869264886218474

Epoch: 5| Step: 7
Training loss: 2.6797598336914206
Validation loss: 2.8698878160031933

Epoch: 5| Step: 8
Training loss: 2.9715394417284045
Validation loss: 2.8683399514080024

Epoch: 5| Step: 9
Training loss: 3.540759490271026
Validation loss: 2.8684305533863403

Epoch: 5| Step: 10
Training loss: 3.368029424996403
Validation loss: 2.870640919239308

Epoch: 118| Step: 0
Training loss: 3.1718783073220136
Validation loss: 2.8784778143880563

Epoch: 5| Step: 1
Training loss: 2.978224723243065
Validation loss: 2.911213017719205

Epoch: 5| Step: 2
Training loss: 3.7562830106328833
Validation loss: 2.9319201737009277

Epoch: 5| Step: 3
Training loss: 3.168309655526622
Validation loss: 2.9340879460634253

Epoch: 5| Step: 4
Training loss: 3.1117939956459026
Validation loss: 2.9092804220620967

Epoch: 5| Step: 5
Training loss: 3.6734903881009036
Validation loss: 2.888176224186106

Epoch: 5| Step: 6
Training loss: 2.4919795125912083
Validation loss: 2.8696817678114237

Epoch: 5| Step: 7
Training loss: 3.0434723463060234
Validation loss: 2.8690167694375464

Epoch: 5| Step: 8
Training loss: 2.899906413442695
Validation loss: 2.8628432423132484

Epoch: 5| Step: 9
Training loss: 3.444929798003348
Validation loss: 2.863206901805502

Epoch: 5| Step: 10
Training loss: 3.0307714340130456
Validation loss: 2.8637567867359177

Epoch: 119| Step: 0
Training loss: 3.3957809412996514
Validation loss: 2.861845433446805

Epoch: 5| Step: 1
Training loss: 2.6978796191721894
Validation loss: 2.862973964400154

Epoch: 5| Step: 2
Training loss: 3.594287732570167
Validation loss: 2.85895372274415

Epoch: 5| Step: 3
Training loss: 2.8287383199561047
Validation loss: 2.8628135827146792

Epoch: 5| Step: 4
Training loss: 2.9196171324043676
Validation loss: 2.860960882538292

Epoch: 5| Step: 5
Training loss: 3.638020512938798
Validation loss: 2.8604279154201646

Epoch: 5| Step: 6
Training loss: 3.0907075352154085
Validation loss: 2.862595261205223

Epoch: 5| Step: 7
Training loss: 3.5301070262472574
Validation loss: 2.8639403321648578

Epoch: 5| Step: 8
Training loss: 3.1906408655143923
Validation loss: 2.8583693874064062

Epoch: 5| Step: 9
Training loss: 2.704065589210882
Validation loss: 2.8634403440127283

Epoch: 5| Step: 10
Training loss: 2.9104721409929515
Validation loss: 2.861410159876377

Epoch: 120| Step: 0
Training loss: 2.7220841057009095
Validation loss: 2.8646748598454157

Epoch: 5| Step: 1
Training loss: 3.1672827639976666
Validation loss: 2.866973156318987

Epoch: 5| Step: 2
Training loss: 3.28981310328058
Validation loss: 2.8737364859781254

Epoch: 5| Step: 3
Training loss: 3.5424699358583074
Validation loss: 2.8759802564522072

Epoch: 5| Step: 4
Training loss: 3.247086319274456
Validation loss: 2.878561973537347

Epoch: 5| Step: 5
Training loss: 2.345534598897758
Validation loss: 2.8766567580291826

Epoch: 5| Step: 6
Training loss: 2.905521260438622
Validation loss: 2.8635292549619176

Epoch: 5| Step: 7
Training loss: 3.008369532937086
Validation loss: 2.8681494430388446

Epoch: 5| Step: 8
Training loss: 3.381993148282429
Validation loss: 2.873476874252647

Epoch: 5| Step: 9
Training loss: 3.297198094450476
Validation loss: 2.8623250868904986

Epoch: 5| Step: 10
Training loss: 3.6388436736063317
Validation loss: 2.857582124183762

Epoch: 121| Step: 0
Training loss: 2.932315553033724
Validation loss: 2.863644596935847

Epoch: 5| Step: 1
Training loss: 2.9204995901103907
Validation loss: 2.8569796767199103

Epoch: 5| Step: 2
Training loss: 3.407275964056809
Validation loss: 2.8557993117020533

Epoch: 5| Step: 3
Training loss: 3.248111322787778
Validation loss: 2.855975734108264

Epoch: 5| Step: 4
Training loss: 3.1852920963603544
Validation loss: 2.8577231182338596

Epoch: 5| Step: 5
Training loss: 3.0330515748118674
Validation loss: 2.8537736704024548

Epoch: 5| Step: 6
Training loss: 3.346310927214361
Validation loss: 2.856223965912115

Epoch: 5| Step: 7
Training loss: 2.9163745370525804
Validation loss: 2.8573757368062664

Epoch: 5| Step: 8
Training loss: 2.987967201635064
Validation loss: 2.8513295140132646

Epoch: 5| Step: 9
Training loss: 3.1590453506986877
Validation loss: 2.852071357800844

Epoch: 5| Step: 10
Training loss: 3.5353756999825148
Validation loss: 2.856568781579887

Epoch: 122| Step: 0
Training loss: 3.0539812212993107
Validation loss: 2.8573386776747793

Epoch: 5| Step: 1
Training loss: 2.609887809388364
Validation loss: 2.856169470758982

Epoch: 5| Step: 2
Training loss: 3.209413635556227
Validation loss: 2.854081848647138

Epoch: 5| Step: 3
Training loss: 3.152763934298767
Validation loss: 2.853211431592818

Epoch: 5| Step: 4
Training loss: 2.5085270419260906
Validation loss: 2.854816786381363

Epoch: 5| Step: 5
Training loss: 2.728987700051965
Validation loss: 2.8632361096474392

Epoch: 5| Step: 6
Training loss: 3.369329846362096
Validation loss: 2.864823867379547

Epoch: 5| Step: 7
Training loss: 3.3580336620831535
Validation loss: 2.8580039839465243

Epoch: 5| Step: 8
Training loss: 3.134324619728847
Validation loss: 2.8614730592743074

Epoch: 5| Step: 9
Training loss: 3.3890499552683195
Validation loss: 2.8524491493032618

Epoch: 5| Step: 10
Training loss: 3.982434447204591
Validation loss: 2.8558972226628585

Epoch: 123| Step: 0
Training loss: 3.487463980321243
Validation loss: 2.8553374463839685

Epoch: 5| Step: 1
Training loss: 3.071806177899263
Validation loss: 2.8505484870154496

Epoch: 5| Step: 2
Training loss: 3.3046140549887517
Validation loss: 2.8508036409621127

Epoch: 5| Step: 3
Training loss: 2.8940556144405893
Validation loss: 2.849518798966606

Epoch: 5| Step: 4
Training loss: 3.23641402246259
Validation loss: 2.8482410838599286

Epoch: 5| Step: 5
Training loss: 3.3662831802517736
Validation loss: 2.847800382120326

Epoch: 5| Step: 6
Training loss: 2.7802803835365024
Validation loss: 2.8512388937194264

Epoch: 5| Step: 7
Training loss: 3.239374250102412
Validation loss: 2.850209039542969

Epoch: 5| Step: 8
Training loss: 2.717303011579364
Validation loss: 2.8506205546132297

Epoch: 5| Step: 9
Training loss: 3.129329124192131
Validation loss: 2.8502889947571557

Epoch: 5| Step: 10
Training loss: 3.309350874023101
Validation loss: 2.853853993766525

Epoch: 124| Step: 0
Training loss: 2.6372491147731156
Validation loss: 2.8574456117674583

Epoch: 5| Step: 1
Training loss: 2.590179743770981
Validation loss: 2.856122158924553

Epoch: 5| Step: 2
Training loss: 3.5178722743648776
Validation loss: 2.8519855881584735

Epoch: 5| Step: 3
Training loss: 2.7589822941177733
Validation loss: 2.856208236976733

Epoch: 5| Step: 4
Training loss: 3.780693706859937
Validation loss: 2.848352081181061

Epoch: 5| Step: 5
Training loss: 3.0670558751566634
Validation loss: 2.8510386445566884

Epoch: 5| Step: 6
Training loss: 3.200401823326176
Validation loss: 2.847515159028628

Epoch: 5| Step: 7
Training loss: 3.0248777128360587
Validation loss: 2.8465145681987556

Epoch: 5| Step: 8
Training loss: 3.368699303070376
Validation loss: 2.8440891547280502

Epoch: 5| Step: 9
Training loss: 2.9555739486651036
Validation loss: 2.846677503161251

Epoch: 5| Step: 10
Training loss: 3.534031945266077
Validation loss: 2.84706911872094

Epoch: 125| Step: 0
Training loss: 2.6804876884429607
Validation loss: 2.847989734842011

Epoch: 5| Step: 1
Training loss: 3.37551946527663
Validation loss: 2.8524789445304584

Epoch: 5| Step: 2
Training loss: 2.8312911546423405
Validation loss: 2.8476019527974845

Epoch: 5| Step: 3
Training loss: 3.2290781480695587
Validation loss: 2.847788068014221

Epoch: 5| Step: 4
Training loss: 3.7850945214748632
Validation loss: 2.843182247135927

Epoch: 5| Step: 5
Training loss: 3.3815946787589923
Validation loss: 2.8432923563649153

Epoch: 5| Step: 6
Training loss: 3.234612497649252
Validation loss: 2.846391941935189

Epoch: 5| Step: 7
Training loss: 3.1762987679404806
Validation loss: 2.840850973286184

Epoch: 5| Step: 8
Training loss: 2.409427971758552
Validation loss: 2.8418849800462334

Epoch: 5| Step: 9
Training loss: 3.177831309504178
Validation loss: 2.8457433364521085

Epoch: 5| Step: 10
Training loss: 3.0477279642913886
Validation loss: 2.8453376941852

Epoch: 126| Step: 0
Training loss: 2.572385282637086
Validation loss: 2.848818175999019

Epoch: 5| Step: 1
Training loss: 3.44062219493173
Validation loss: 2.8526833684965154

Epoch: 5| Step: 2
Training loss: 3.4782425496406746
Validation loss: 2.8513625909438103

Epoch: 5| Step: 3
Training loss: 2.811881866344947
Validation loss: 2.8551405932226075

Epoch: 5| Step: 4
Training loss: 3.2419206992069207
Validation loss: 2.8532742071403683

Epoch: 5| Step: 5
Training loss: 3.0699144255798565
Validation loss: 2.8542218766974106

Epoch: 5| Step: 6
Training loss: 2.2979729551843704
Validation loss: 2.854870409366882

Epoch: 5| Step: 7
Training loss: 3.727537655349158
Validation loss: 2.8590657316692316

Epoch: 5| Step: 8
Training loss: 3.285146815301182
Validation loss: 2.8483063991094033

Epoch: 5| Step: 9
Training loss: 3.3945309690556558
Validation loss: 2.8498105360178485

Epoch: 5| Step: 10
Training loss: 2.9229634751378173
Validation loss: 2.84611551360808

Epoch: 127| Step: 0
Training loss: 2.911754686334952
Validation loss: 2.8467233144861464

Epoch: 5| Step: 1
Training loss: 3.292048532733094
Validation loss: 2.840649830291473

Epoch: 5| Step: 2
Training loss: 3.0755007638472946
Validation loss: 2.8430574960661232

Epoch: 5| Step: 3
Training loss: 3.1781522526505603
Validation loss: 2.8413491358174543

Epoch: 5| Step: 4
Training loss: 2.8499982331922977
Validation loss: 2.8387789689250833

Epoch: 5| Step: 5
Training loss: 3.4512270030879253
Validation loss: 2.8385169574662714

Epoch: 5| Step: 6
Training loss: 2.5869512962118493
Validation loss: 2.839874019614666

Epoch: 5| Step: 7
Training loss: 3.1276932364090793
Validation loss: 2.839452477321248

Epoch: 5| Step: 8
Training loss: 3.6800355523921393
Validation loss: 2.835999411344427

Epoch: 5| Step: 9
Training loss: 3.2683517534384365
Validation loss: 2.8373904837121713

Epoch: 5| Step: 10
Training loss: 2.914428197091741
Validation loss: 2.8325725468386667

Epoch: 128| Step: 0
Training loss: 3.1110980756426003
Validation loss: 2.8341453668612457

Epoch: 5| Step: 1
Training loss: 3.0947778708964604
Validation loss: 2.833087309362875

Epoch: 5| Step: 2
Training loss: 3.0508678389800585
Validation loss: 2.8351257865664206

Epoch: 5| Step: 3
Training loss: 3.302060645634221
Validation loss: 2.8382506648214085

Epoch: 5| Step: 4
Training loss: 3.038159861534327
Validation loss: 2.8352143331099904

Epoch: 5| Step: 5
Training loss: 3.2870548309497245
Validation loss: 2.8358542138755074

Epoch: 5| Step: 6
Training loss: 3.0212440123871582
Validation loss: 2.836166108206585

Epoch: 5| Step: 7
Training loss: 3.1061673128416976
Validation loss: 2.840253783738426

Epoch: 5| Step: 8
Training loss: 2.7999943222260812
Validation loss: 2.8451231199734455

Epoch: 5| Step: 9
Training loss: 3.28267239213078
Validation loss: 2.846782440935401

Epoch: 5| Step: 10
Training loss: 3.3981551831371153
Validation loss: 2.850919815215826

Epoch: 129| Step: 0
Training loss: 3.1865334634859894
Validation loss: 2.833275597748347

Epoch: 5| Step: 1
Training loss: 3.054699363587896
Validation loss: 2.8306127101759544

Epoch: 5| Step: 2
Training loss: 3.1707939222362023
Validation loss: 2.833886237971231

Epoch: 5| Step: 3
Training loss: 2.840768613636659
Validation loss: 2.832705524700462

Epoch: 5| Step: 4
Training loss: 2.553889251960487
Validation loss: 2.8312020878879376

Epoch: 5| Step: 5
Training loss: 3.564428376412371
Validation loss: 2.8343225917047223

Epoch: 5| Step: 6
Training loss: 2.905377328762196
Validation loss: 2.8294107246113844

Epoch: 5| Step: 7
Training loss: 3.563957853005971
Validation loss: 2.831233356284477

Epoch: 5| Step: 8
Training loss: 3.676556399073242
Validation loss: 2.831651238676698

Epoch: 5| Step: 9
Training loss: 2.807856392663284
Validation loss: 2.8321212338984694

Epoch: 5| Step: 10
Training loss: 2.9077064392327108
Validation loss: 2.828123473486145

Epoch: 130| Step: 0
Training loss: 3.008886685469982
Validation loss: 2.8306440774617356

Epoch: 5| Step: 1
Training loss: 3.635177269224504
Validation loss: 2.8280460979156423

Epoch: 5| Step: 2
Training loss: 2.947914815482018
Validation loss: 2.8278483394461706

Epoch: 5| Step: 3
Training loss: 3.2794130542161923
Validation loss: 2.8283100710087252

Epoch: 5| Step: 4
Training loss: 3.3448956389747533
Validation loss: 2.8286419930013973

Epoch: 5| Step: 5
Training loss: 2.9940794697766275
Validation loss: 2.824394857699623

Epoch: 5| Step: 6
Training loss: 3.2248810088214306
Validation loss: 2.828852543888585

Epoch: 5| Step: 7
Training loss: 2.472353562665434
Validation loss: 2.832116047088626

Epoch: 5| Step: 8
Training loss: 3.7581563621746383
Validation loss: 2.8305217055849528

Epoch: 5| Step: 9
Training loss: 2.973842549561513
Validation loss: 2.828068857469132

Epoch: 5| Step: 10
Training loss: 2.3534203980994195
Validation loss: 2.8268605928970136

Epoch: 131| Step: 0
Training loss: 3.3050751875781033
Validation loss: 2.8323441219666017

Epoch: 5| Step: 1
Training loss: 3.4178843460560713
Validation loss: 2.8283528311127206

Epoch: 5| Step: 2
Training loss: 3.5499575491502773
Validation loss: 2.8246056507514488

Epoch: 5| Step: 3
Training loss: 2.8872111188374796
Validation loss: 2.8221152542772177

Epoch: 5| Step: 4
Training loss: 2.7594868275500284
Validation loss: 2.8227406922830833

Epoch: 5| Step: 5
Training loss: 3.6409589753431493
Validation loss: 2.8242162156042965

Epoch: 5| Step: 6
Training loss: 3.0769206367996516
Validation loss: 2.8199252465879177

Epoch: 5| Step: 7
Training loss: 3.01434994953906
Validation loss: 2.820761346197622

Epoch: 5| Step: 8
Training loss: 2.9508102468086452
Validation loss: 2.8219065754633696

Epoch: 5| Step: 9
Training loss: 2.786074450898121
Validation loss: 2.8259343898201097

Epoch: 5| Step: 10
Training loss: 2.8125347559158915
Validation loss: 2.825534192926927

Epoch: 132| Step: 0
Training loss: 3.497087356623852
Validation loss: 2.824822613875621

Epoch: 5| Step: 1
Training loss: 2.9194201596555978
Validation loss: 2.825582263714069

Epoch: 5| Step: 2
Training loss: 3.4520966392418737
Validation loss: 2.8183223122231786

Epoch: 5| Step: 3
Training loss: 3.2431615630165767
Validation loss: 2.8216753237612657

Epoch: 5| Step: 4
Training loss: 3.3967593905964226
Validation loss: 2.823002936566868

Epoch: 5| Step: 5
Training loss: 3.3247405560456365
Validation loss: 2.8182220351614475

Epoch: 5| Step: 6
Training loss: 3.015066777086054
Validation loss: 2.81836003356598

Epoch: 5| Step: 7
Training loss: 3.2741980932262673
Validation loss: 2.825374482475309

Epoch: 5| Step: 8
Training loss: 2.4925026051652126
Validation loss: 2.8223333480719606

Epoch: 5| Step: 9
Training loss: 2.900336699835402
Validation loss: 2.820653436723008

Epoch: 5| Step: 10
Training loss: 2.5747393948427053
Validation loss: 2.8222171071179827

Epoch: 133| Step: 0
Training loss: 3.7898761308301534
Validation loss: 2.819320569268107

Epoch: 5| Step: 1
Training loss: 2.6433798961539043
Validation loss: 2.8182632973070465

Epoch: 5| Step: 2
Training loss: 3.3702922058201876
Validation loss: 2.81819402276885

Epoch: 5| Step: 3
Training loss: 2.6296116419621214
Validation loss: 2.8175759490904575

Epoch: 5| Step: 4
Training loss: 3.031589449723495
Validation loss: 2.8191173990240754

Epoch: 5| Step: 5
Training loss: 3.106332181461286
Validation loss: 2.8149618551644258

Epoch: 5| Step: 6
Training loss: 3.2761156875342343
Validation loss: 2.815496431355137

Epoch: 5| Step: 7
Training loss: 3.4146734952320883
Validation loss: 2.8169099950807577

Epoch: 5| Step: 8
Training loss: 2.765675775956246
Validation loss: 2.816360636881323

Epoch: 5| Step: 9
Training loss: 3.0796435333163745
Validation loss: 2.816071552139694

Epoch: 5| Step: 10
Training loss: 3.0773958998302433
Validation loss: 2.813823488818423

Epoch: 134| Step: 0
Training loss: 3.5631351908544904
Validation loss: 2.8148452314745245

Epoch: 5| Step: 1
Training loss: 2.650738731917979
Validation loss: 2.815282225319522

Epoch: 5| Step: 2
Training loss: 3.3579595378280587
Validation loss: 2.8132778719075726

Epoch: 5| Step: 3
Training loss: 3.595738399898264
Validation loss: 2.8183172264572023

Epoch: 5| Step: 4
Training loss: 2.507967554925956
Validation loss: 2.825727382047819

Epoch: 5| Step: 5
Training loss: 2.9971151786719967
Validation loss: 2.8271320426208097

Epoch: 5| Step: 6
Training loss: 3.2824491217128258
Validation loss: 2.8230517796682935

Epoch: 5| Step: 7
Training loss: 2.845761771766131
Validation loss: 2.825172579705808

Epoch: 5| Step: 8
Training loss: 3.350695944847777
Validation loss: 2.823294269045358

Epoch: 5| Step: 9
Training loss: 2.824794937388103
Validation loss: 2.818878933909711

Epoch: 5| Step: 10
Training loss: 3.1326528303976393
Validation loss: 2.8126760876586734

Epoch: 135| Step: 0
Training loss: 3.3166413240726507
Validation loss: 2.810251076518701

Epoch: 5| Step: 1
Training loss: 2.6315654212202495
Validation loss: 2.8154403975823494

Epoch: 5| Step: 2
Training loss: 2.8165191754731773
Validation loss: 2.8106847166562847

Epoch: 5| Step: 3
Training loss: 3.09495844503432
Validation loss: 2.811761924674011

Epoch: 5| Step: 4
Training loss: 2.6951428346168997
Validation loss: 2.8127458745204796

Epoch: 5| Step: 5
Training loss: 3.379507516273824
Validation loss: 2.8107644225905752

Epoch: 5| Step: 6
Training loss: 2.5460789846558094
Validation loss: 2.810209866866534

Epoch: 5| Step: 7
Training loss: 3.5216510583038514
Validation loss: 2.8134247839787494

Epoch: 5| Step: 8
Training loss: 3.390143153676109
Validation loss: 2.813646501687365

Epoch: 5| Step: 9
Training loss: 3.6788261685148176
Validation loss: 2.8175889165926367

Epoch: 5| Step: 10
Training loss: 2.9642473306977655
Validation loss: 2.8192090263655754

Epoch: 136| Step: 0
Training loss: 3.1917837939836433
Validation loss: 2.812502073699661

Epoch: 5| Step: 1
Training loss: 3.5200413070769256
Validation loss: 2.818674028301988

Epoch: 5| Step: 2
Training loss: 3.411803871107955
Validation loss: 2.8138230633403247

Epoch: 5| Step: 3
Training loss: 2.6852862089404512
Validation loss: 2.8119543423576743

Epoch: 5| Step: 4
Training loss: 3.4568854522133243
Validation loss: 2.811588323719236

Epoch: 5| Step: 5
Training loss: 2.775166748810531
Validation loss: 2.8077332887475017

Epoch: 5| Step: 6
Training loss: 3.124664746421103
Validation loss: 2.810216102609397

Epoch: 5| Step: 7
Training loss: 3.418157639869902
Validation loss: 2.8119455299140155

Epoch: 5| Step: 8
Training loss: 3.033523021957086
Validation loss: 2.8083478460639504

Epoch: 5| Step: 9
Training loss: 2.8953054116126804
Validation loss: 2.8081929305364515

Epoch: 5| Step: 10
Training loss: 2.477097606911908
Validation loss: 2.806224869531221

Epoch: 137| Step: 0
Training loss: 3.1420505002514476
Validation loss: 2.8072563612224637

Epoch: 5| Step: 1
Training loss: 2.7882633720630707
Validation loss: 2.806806322650083

Epoch: 5| Step: 2
Training loss: 3.013938155311175
Validation loss: 2.8069523614602563

Epoch: 5| Step: 3
Training loss: 2.102139418590706
Validation loss: 2.8071412777094173

Epoch: 5| Step: 4
Training loss: 3.5505412642790315
Validation loss: 2.8074084062888045

Epoch: 5| Step: 5
Training loss: 3.0402285341895103
Validation loss: 2.8053092311989545

Epoch: 5| Step: 6
Training loss: 3.5046157373776095
Validation loss: 2.8065104852615725

Epoch: 5| Step: 7
Training loss: 3.6716350071171675
Validation loss: 2.805307261844757

Epoch: 5| Step: 8
Training loss: 2.583559723645283
Validation loss: 2.8082582433469603

Epoch: 5| Step: 9
Training loss: 3.5078845452129612
Validation loss: 2.8123182085321643

Epoch: 5| Step: 10
Training loss: 2.8821938117019283
Validation loss: 2.816750178804412

Epoch: 138| Step: 0
Training loss: 3.3898989695570148
Validation loss: 2.8155354489161124

Epoch: 5| Step: 1
Training loss: 3.3136750062610454
Validation loss: 2.804858701980318

Epoch: 5| Step: 2
Training loss: 3.286424607447956
Validation loss: 2.8056890366638463

Epoch: 5| Step: 3
Training loss: 3.4749921016466137
Validation loss: 2.8039604471998762

Epoch: 5| Step: 4
Training loss: 3.234757405401796
Validation loss: 2.8009727022318045

Epoch: 5| Step: 5
Training loss: 2.445931938128997
Validation loss: 2.799216798744102

Epoch: 5| Step: 6
Training loss: 3.1939730273345797
Validation loss: 2.801217095579265

Epoch: 5| Step: 7
Training loss: 3.0426465550704425
Validation loss: 2.8019723895789865

Epoch: 5| Step: 8
Training loss: 3.1610569371782926
Validation loss: 2.803798550541967

Epoch: 5| Step: 9
Training loss: 2.580609875387788
Validation loss: 2.8093663577379693

Epoch: 5| Step: 10
Training loss: 2.8311436176313602
Validation loss: 2.8085570886870173

Epoch: 139| Step: 0
Training loss: 2.7861839848634844
Validation loss: 2.818956016355331

Epoch: 5| Step: 1
Training loss: 2.970368275527589
Validation loss: 2.8246220675553473

Epoch: 5| Step: 2
Training loss: 2.9420935244550988
Validation loss: 2.826771108120317

Epoch: 5| Step: 3
Training loss: 3.0409187198553336
Validation loss: 2.8117273397350115

Epoch: 5| Step: 4
Training loss: 2.972357716150805
Validation loss: 2.8104397783274986

Epoch: 5| Step: 5
Training loss: 2.7074516817608814
Validation loss: 2.8013196231443502

Epoch: 5| Step: 6
Training loss: 2.9930888678360623
Validation loss: 2.8024975272738897

Epoch: 5| Step: 7
Training loss: 3.010269707037302
Validation loss: 2.796642054301938

Epoch: 5| Step: 8
Training loss: 2.9354101010843188
Validation loss: 2.7978192356370077

Epoch: 5| Step: 9
Training loss: 3.829079520666284
Validation loss: 2.796391436897641

Epoch: 5| Step: 10
Training loss: 3.86965771011559
Validation loss: 2.7969285716131838

Epoch: 140| Step: 0
Training loss: 4.315246149956778
Validation loss: 2.796476428199209

Epoch: 5| Step: 1
Training loss: 2.8675018055119437
Validation loss: 2.7978135307499064

Epoch: 5| Step: 2
Training loss: 2.7665884635014644
Validation loss: 2.7973192542378618

Epoch: 5| Step: 3
Training loss: 2.6897734850842014
Validation loss: 2.79416229380069

Epoch: 5| Step: 4
Training loss: 2.776193716001657
Validation loss: 2.7952483242872663

Epoch: 5| Step: 5
Training loss: 2.9000527541525303
Validation loss: 2.797623444884218

Epoch: 5| Step: 6
Training loss: 2.185467675131666
Validation loss: 2.794727719562421

Epoch: 5| Step: 7
Training loss: 3.2998370563853374
Validation loss: 2.796501906109647

Epoch: 5| Step: 8
Training loss: 3.5801681615451257
Validation loss: 2.791294975557844

Epoch: 5| Step: 9
Training loss: 2.9247624618717367
Validation loss: 2.7945068493347716

Epoch: 5| Step: 10
Training loss: 3.3120302551011767
Validation loss: 2.7930635646861486

Epoch: 141| Step: 0
Training loss: 2.7612786056950216
Validation loss: 2.7910342279917892

Epoch: 5| Step: 1
Training loss: 3.350628773908263
Validation loss: 2.7899415041482096

Epoch: 5| Step: 2
Training loss: 3.4896774658867784
Validation loss: 2.791704752158262

Epoch: 5| Step: 3
Training loss: 3.342270568414567
Validation loss: 2.7904952081093444

Epoch: 5| Step: 4
Training loss: 3.448796938790715
Validation loss: 2.791458186074413

Epoch: 5| Step: 5
Training loss: 3.1143277849128026
Validation loss: 2.7910898525214507

Epoch: 5| Step: 6
Training loss: 2.8683185061733374
Validation loss: 2.7936274307054805

Epoch: 5| Step: 7
Training loss: 3.238888599605849
Validation loss: 2.7900918005885953

Epoch: 5| Step: 8
Training loss: 3.0200008604541084
Validation loss: 2.795334716845054

Epoch: 5| Step: 9
Training loss: 2.615196449967732
Validation loss: 2.795620943562269

Epoch: 5| Step: 10
Training loss: 2.6003878120818587
Validation loss: 2.806046841257074

Epoch: 142| Step: 0
Training loss: 3.0729510978881858
Validation loss: 2.8098859956267224

Epoch: 5| Step: 1
Training loss: 2.79173838584973
Validation loss: 2.8095274517657742

Epoch: 5| Step: 2
Training loss: 2.9153647287200353
Validation loss: 2.8020649215679496

Epoch: 5| Step: 3
Training loss: 2.9588588373225346
Validation loss: 2.795672700615401

Epoch: 5| Step: 4
Training loss: 3.599621562140248
Validation loss: 2.7894211129492508

Epoch: 5| Step: 5
Training loss: 3.0963810993602814
Validation loss: 2.791794252548855

Epoch: 5| Step: 6
Training loss: 3.0436904306085286
Validation loss: 2.7871918402964737

Epoch: 5| Step: 7
Training loss: 2.8590556315519784
Validation loss: 2.7903928303901546

Epoch: 5| Step: 8
Training loss: 3.319422416312434
Validation loss: 2.7873296964405596

Epoch: 5| Step: 9
Training loss: 3.1914337418491523
Validation loss: 2.7886029474368077

Epoch: 5| Step: 10
Training loss: 3.1499834453813813
Validation loss: 2.790093763224545

Epoch: 143| Step: 0
Training loss: 2.6104502033130323
Validation loss: 2.789494749685741

Epoch: 5| Step: 1
Training loss: 3.4239141928892662
Validation loss: 2.78945800002942

Epoch: 5| Step: 2
Training loss: 2.7140234716548792
Validation loss: 2.7900350379133076

Epoch: 5| Step: 3
Training loss: 3.3263322900156975
Validation loss: 2.7840459489663236

Epoch: 5| Step: 4
Training loss: 2.8985806247302355
Validation loss: 2.7847474890769246

Epoch: 5| Step: 5
Training loss: 2.542908276660706
Validation loss: 2.787082149096892

Epoch: 5| Step: 6
Training loss: 3.3015059358415475
Validation loss: 2.7900197968060136

Epoch: 5| Step: 7
Training loss: 3.7355828666129893
Validation loss: 2.7870136991372627

Epoch: 5| Step: 8
Training loss: 2.8423075947861283
Validation loss: 2.7868066787146772

Epoch: 5| Step: 9
Training loss: 3.1768718878419153
Validation loss: 2.7842850283154212

Epoch: 5| Step: 10
Training loss: 3.222543055540455
Validation loss: 2.783694962496202

Epoch: 144| Step: 0
Training loss: 3.488560783916286
Validation loss: 2.7882294003901693

Epoch: 5| Step: 1
Training loss: 2.708117686758549
Validation loss: 2.7868994879500337

Epoch: 5| Step: 2
Training loss: 3.0093720591561435
Validation loss: 2.783043093841702

Epoch: 5| Step: 3
Training loss: 3.1159798713690137
Validation loss: 2.7870045787879443

Epoch: 5| Step: 4
Training loss: 3.245338912217238
Validation loss: 2.781829814104102

Epoch: 5| Step: 5
Training loss: 3.302783029514847
Validation loss: 2.77839921959305

Epoch: 5| Step: 6
Training loss: 3.346345981137646
Validation loss: 2.7816590850199243

Epoch: 5| Step: 7
Training loss: 2.600309419560221
Validation loss: 2.7813946256680495

Epoch: 5| Step: 8
Training loss: 3.4354212631154737
Validation loss: 2.784774335506678

Epoch: 5| Step: 9
Training loss: 2.8406089790656233
Validation loss: 2.77965068933758

Epoch: 5| Step: 10
Training loss: 2.6920036904081583
Validation loss: 2.7810826497220917

Epoch: 145| Step: 0
Training loss: 3.420377917685775
Validation loss: 2.781594609379794

Epoch: 5| Step: 1
Training loss: 3.287041194795736
Validation loss: 2.7876348061073344

Epoch: 5| Step: 2
Training loss: 3.910001494463467
Validation loss: 2.7877404991601265

Epoch: 5| Step: 3
Training loss: 2.528076631627946
Validation loss: 2.7868431091688

Epoch: 5| Step: 4
Training loss: 3.2354560556529774
Validation loss: 2.7885140304583875

Epoch: 5| Step: 5
Training loss: 2.7271106245532146
Validation loss: 2.791800728231215

Epoch: 5| Step: 6
Training loss: 2.8138761756294293
Validation loss: 2.7971533685324683

Epoch: 5| Step: 7
Training loss: 3.311296640300213
Validation loss: 2.7965383688566554

Epoch: 5| Step: 8
Training loss: 2.2913700489783357
Validation loss: 2.787670090909052

Epoch: 5| Step: 9
Training loss: 3.3291181774849394
Validation loss: 2.785197720350289

Epoch: 5| Step: 10
Training loss: 2.7296977121023467
Validation loss: 2.7802156702944827

Epoch: 146| Step: 0
Training loss: 3.1357309346574795
Validation loss: 2.777828884645886

Epoch: 5| Step: 1
Training loss: 2.5130489262145486
Validation loss: 2.7752173899107238

Epoch: 5| Step: 2
Training loss: 2.6655120933027967
Validation loss: 2.7814711523948037

Epoch: 5| Step: 3
Training loss: 3.1758058741742157
Validation loss: 2.7788313003687604

Epoch: 5| Step: 4
Training loss: 2.9917320123901407
Validation loss: 2.7837692305034105

Epoch: 5| Step: 5
Training loss: 2.8983493184867584
Validation loss: 2.7817288786444547

Epoch: 5| Step: 6
Training loss: 3.3706849381861024
Validation loss: 2.7843736743045704

Epoch: 5| Step: 7
Training loss: 2.62806885576549
Validation loss: 2.7873184547991796

Epoch: 5| Step: 8
Training loss: 3.439448688597366
Validation loss: 2.786986648912842

Epoch: 5| Step: 9
Training loss: 3.4746586419269274
Validation loss: 2.7867639370399346

Epoch: 5| Step: 10
Training loss: 3.5545300123938732
Validation loss: 2.776155245340098

Epoch: 147| Step: 0
Training loss: 3.5674377487300957
Validation loss: 2.7750910773496393

Epoch: 5| Step: 1
Training loss: 3.009077326391127
Validation loss: 2.7765858370103014

Epoch: 5| Step: 2
Training loss: 2.7286943992860073
Validation loss: 2.778342022416218

Epoch: 5| Step: 3
Training loss: 2.4731261664082456
Validation loss: 2.777818582364979

Epoch: 5| Step: 4
Training loss: 3.2393368609871676
Validation loss: 2.7867953986264915

Epoch: 5| Step: 5
Training loss: 2.710516993204964
Validation loss: 2.7920650521779713

Epoch: 5| Step: 6
Training loss: 3.3211278295821143
Validation loss: 2.8035736088641303

Epoch: 5| Step: 7
Training loss: 3.65866804452746
Validation loss: 2.80562938960029

Epoch: 5| Step: 8
Training loss: 3.5642491112420505
Validation loss: 2.7838883080688235

Epoch: 5| Step: 9
Training loss: 2.6977841750988567
Validation loss: 2.774130685119789

Epoch: 5| Step: 10
Training loss: 2.728913263879254
Validation loss: 2.7722330720597257

Epoch: 148| Step: 0
Training loss: 2.7842526461415793
Validation loss: 2.772583042573178

Epoch: 5| Step: 1
Training loss: 3.0153506455611487
Validation loss: 2.778677921336892

Epoch: 5| Step: 2
Training loss: 3.1261408440020877
Validation loss: 2.77558586477263

Epoch: 5| Step: 3
Training loss: 3.487006455367611
Validation loss: 2.7805230975646533

Epoch: 5| Step: 4
Training loss: 2.9589713219080904
Validation loss: 2.7790612907767405

Epoch: 5| Step: 5
Training loss: 3.0601077954622173
Validation loss: 2.7861148825355917

Epoch: 5| Step: 6
Training loss: 3.2411003036443797
Validation loss: 2.7874804776725437

Epoch: 5| Step: 7
Training loss: 2.606511995242215
Validation loss: 2.78945743481598

Epoch: 5| Step: 8
Training loss: 3.253769522515671
Validation loss: 2.7819125566262253

Epoch: 5| Step: 9
Training loss: 3.354988108129219
Validation loss: 2.7717108239524815

Epoch: 5| Step: 10
Training loss: 3.0518912470828634
Validation loss: 2.76952188416966

Epoch: 149| Step: 0
Training loss: 3.1542853860084885
Validation loss: 2.7677818468427264

Epoch: 5| Step: 1
Training loss: 2.942361906922497
Validation loss: 2.766121674823881

Epoch: 5| Step: 2
Training loss: 3.3750751628276854
Validation loss: 2.7743348202884737

Epoch: 5| Step: 3
Training loss: 2.8526986980858227
Validation loss: 2.770689536270975

Epoch: 5| Step: 4
Training loss: 3.1702727983225185
Validation loss: 2.7686005974650154

Epoch: 5| Step: 5
Training loss: 3.236021645491249
Validation loss: 2.768594663843961

Epoch: 5| Step: 6
Training loss: 3.4880211061399042
Validation loss: 2.771262251724976

Epoch: 5| Step: 7
Training loss: 2.9994531768893413
Validation loss: 2.7686097849224636

Epoch: 5| Step: 8
Training loss: 3.1260554247999024
Validation loss: 2.76690435113804

Epoch: 5| Step: 9
Training loss: 2.6791701637668437
Validation loss: 2.7704981427595747

Epoch: 5| Step: 10
Training loss: 2.6544877433501077
Validation loss: 2.775523533649098

Epoch: 150| Step: 0
Training loss: 2.9178581165753
Validation loss: 2.783392252257612

Epoch: 5| Step: 1
Training loss: 3.298070320281909
Validation loss: 2.793644252545961

Epoch: 5| Step: 2
Training loss: 3.083814909846789
Validation loss: 2.8082757087706742

Epoch: 5| Step: 3
Training loss: 3.0071932068419494
Validation loss: 2.7959037776899733

Epoch: 5| Step: 4
Training loss: 3.2318833931198125
Validation loss: 2.8077956183805166

Epoch: 5| Step: 5
Training loss: 3.5369366793757524
Validation loss: 2.7724229809539827

Epoch: 5| Step: 6
Training loss: 3.4893087857930123
Validation loss: 2.768218706723001

Epoch: 5| Step: 7
Training loss: 3.4779312011249304
Validation loss: 2.7636476843883395

Epoch: 5| Step: 8
Training loss: 2.866262842907354
Validation loss: 2.7610845301556717

Epoch: 5| Step: 9
Training loss: 2.1428566319601265
Validation loss: 2.7643340485684242

Epoch: 5| Step: 10
Training loss: 2.5499581240039184
Validation loss: 2.7654321073850805

Epoch: 151| Step: 0
Training loss: 3.779281860637165
Validation loss: 2.765937660971347

Epoch: 5| Step: 1
Training loss: 2.798111541013576
Validation loss: 2.7687325385406565

Epoch: 5| Step: 2
Training loss: 3.036073131348935
Validation loss: 2.7670483998793634

Epoch: 5| Step: 3
Training loss: 3.143616120235002
Validation loss: 2.7646131593194947

Epoch: 5| Step: 4
Training loss: 3.0281215923593283
Validation loss: 2.7591618771446633

Epoch: 5| Step: 5
Training loss: 3.240103545947931
Validation loss: 2.7601351339980384

Epoch: 5| Step: 6
Training loss: 3.6145835385427865
Validation loss: 2.7591769858074002

Epoch: 5| Step: 7
Training loss: 2.614185946434687
Validation loss: 2.7581821916501585

Epoch: 5| Step: 8
Training loss: 2.9044997985177834
Validation loss: 2.7584655652200247

Epoch: 5| Step: 9
Training loss: 2.5397858044278157
Validation loss: 2.762332669388464

Epoch: 5| Step: 10
Training loss: 2.908051947359269
Validation loss: 2.76357044054261

Epoch: 152| Step: 0
Training loss: 2.843048009058504
Validation loss: 2.7681489410612388

Epoch: 5| Step: 1
Training loss: 3.01930715659596
Validation loss: 2.765947133477832

Epoch: 5| Step: 2
Training loss: 2.756391813128919
Validation loss: 2.765624076741605

Epoch: 5| Step: 3
Training loss: 3.6286289860609124
Validation loss: 2.777095162971486

Epoch: 5| Step: 4
Training loss: 3.316936760516637
Validation loss: 2.779278805926449

Epoch: 5| Step: 5
Training loss: 3.367498184350876
Validation loss: 2.767796757474442

Epoch: 5| Step: 6
Training loss: 3.251337363108091
Validation loss: 2.7596142045736154

Epoch: 5| Step: 7
Training loss: 3.021328133585609
Validation loss: 2.755178652398656

Epoch: 5| Step: 8
Training loss: 2.9615223490670197
Validation loss: 2.7592439405960105

Epoch: 5| Step: 9
Training loss: 3.0243981385296808
Validation loss: 2.7584003792277083

Epoch: 5| Step: 10
Training loss: 2.4245449976412394
Validation loss: 2.764345973039062

Epoch: 153| Step: 0
Training loss: 3.7599554791756913
Validation loss: 2.7587644731618384

Epoch: 5| Step: 1
Training loss: 3.107194452217563
Validation loss: 2.761489344602632

Epoch: 5| Step: 2
Training loss: 3.1107712874180433
Validation loss: 2.758852024926206

Epoch: 5| Step: 3
Training loss: 2.997345385664107
Validation loss: 2.759308001974306

Epoch: 5| Step: 4
Training loss: 3.08881238466046
Validation loss: 2.7644062790233583

Epoch: 5| Step: 5
Training loss: 3.0195396196217286
Validation loss: 2.753586368663562

Epoch: 5| Step: 6
Training loss: 2.0091431954193077
Validation loss: 2.7574814319402874

Epoch: 5| Step: 7
Training loss: 3.0880804033732274
Validation loss: 2.7598197831895295

Epoch: 5| Step: 8
Training loss: 2.947194922062396
Validation loss: 2.7627154461383117

Epoch: 5| Step: 9
Training loss: 3.2879021924361385
Validation loss: 2.771494531551072

Epoch: 5| Step: 10
Training loss: 3.1408878045652475
Validation loss: 2.768810167989642

Epoch: 154| Step: 0
Training loss: 2.776043422524265
Validation loss: 2.7696710255615

Epoch: 5| Step: 1
Training loss: 2.630717091723664
Validation loss: 2.7636052932583386

Epoch: 5| Step: 2
Training loss: 2.913366976208374
Validation loss: 2.760213595021773

Epoch: 5| Step: 3
Training loss: 3.6386308570470542
Validation loss: 2.752609625619898

Epoch: 5| Step: 4
Training loss: 2.6751843754339473
Validation loss: 2.755391860085857

Epoch: 5| Step: 5
Training loss: 3.416730802600844
Validation loss: 2.7567971660159314

Epoch: 5| Step: 6
Training loss: 2.844233377476996
Validation loss: 2.7517659939043435

Epoch: 5| Step: 7
Training loss: 3.44301149511842
Validation loss: 2.7560922088224995

Epoch: 5| Step: 8
Training loss: 3.1472059543687108
Validation loss: 2.7497756405962654

Epoch: 5| Step: 9
Training loss: 3.069017132166541
Validation loss: 2.750729491130932

Epoch: 5| Step: 10
Training loss: 3.0336344670764115
Validation loss: 2.7518372332230316

Epoch: 155| Step: 0
Training loss: 2.267807954613077
Validation loss: 2.7476945406860906

Epoch: 5| Step: 1
Training loss: 3.752037639152581
Validation loss: 2.7470624845794003

Epoch: 5| Step: 2
Training loss: 3.1979594937085865
Validation loss: 2.751091882026902

Epoch: 5| Step: 3
Training loss: 3.176587292245618
Validation loss: 2.7472002165161413

Epoch: 5| Step: 4
Training loss: 3.1651708851462876
Validation loss: 2.7515629002970976

Epoch: 5| Step: 5
Training loss: 2.9085228349072243
Validation loss: 2.747211310173661

Epoch: 5| Step: 6
Training loss: 3.2725846447354128
Validation loss: 2.7516728195424047

Epoch: 5| Step: 7
Training loss: 2.973421296613267
Validation loss: 2.7500725099880223

Epoch: 5| Step: 8
Training loss: 2.9470646753686394
Validation loss: 2.7485091436919915

Epoch: 5| Step: 9
Training loss: 3.1449687013751655
Validation loss: 2.7513124442171026

Epoch: 5| Step: 10
Training loss: 2.647415008765663
Validation loss: 2.750178833755912

Epoch: 156| Step: 0
Training loss: 3.2560728995108064
Validation loss: 2.747832369691381

Epoch: 5| Step: 1
Training loss: 3.253095179997362
Validation loss: 2.754725616193049

Epoch: 5| Step: 2
Training loss: 3.2351966588237953
Validation loss: 2.7550178708730257

Epoch: 5| Step: 3
Training loss: 2.7873408456023077
Validation loss: 2.7508723151683174

Epoch: 5| Step: 4
Training loss: 3.158705256831687
Validation loss: 2.7462478781387283

Epoch: 5| Step: 5
Training loss: 3.9019660346871357
Validation loss: 2.7458226011953073

Epoch: 5| Step: 6
Training loss: 2.0614437519757396
Validation loss: 2.7521708097052766

Epoch: 5| Step: 7
Training loss: 2.9238343222838465
Validation loss: 2.7514760054665564

Epoch: 5| Step: 8
Training loss: 3.0601037440447025
Validation loss: 2.750355258491279

Epoch: 5| Step: 9
Training loss: 2.15757743776043
Validation loss: 2.7463790420247634

Epoch: 5| Step: 10
Training loss: 3.5000463210174204
Validation loss: 2.757752728441237

Epoch: 157| Step: 0
Training loss: 3.0337149439398527
Validation loss: 2.7607129761993265

Epoch: 5| Step: 1
Training loss: 3.6591531036364207
Validation loss: 2.7686492919384205

Epoch: 5| Step: 2
Training loss: 2.923440442473716
Validation loss: 2.7666394886436834

Epoch: 5| Step: 3
Training loss: 2.6159076351110198
Validation loss: 2.785723035321518

Epoch: 5| Step: 4
Training loss: 2.6214542055788463
Validation loss: 2.791586662790504

Epoch: 5| Step: 5
Training loss: 3.0202386380324424
Validation loss: 2.8145908691682333

Epoch: 5| Step: 6
Training loss: 2.9161524909796768
Validation loss: 2.7782775879081427

Epoch: 5| Step: 7
Training loss: 3.5312880792505768
Validation loss: 2.761056021637522

Epoch: 5| Step: 8
Training loss: 3.336431176421165
Validation loss: 2.748181459609054

Epoch: 5| Step: 9
Training loss: 2.9664583697398172
Validation loss: 2.747600964204161

Epoch: 5| Step: 10
Training loss: 2.9269523365035472
Validation loss: 2.7425492211159983

Epoch: 158| Step: 0
Training loss: 2.9371441564721397
Validation loss: 2.741997123836128

Epoch: 5| Step: 1
Training loss: 2.9597953264252266
Validation loss: 2.7452398364198265

Epoch: 5| Step: 2
Training loss: 2.51013304399579
Validation loss: 2.740764926601027

Epoch: 5| Step: 3
Training loss: 3.421272259585101
Validation loss: 2.7416752190457605

Epoch: 5| Step: 4
Training loss: 2.55871097208811
Validation loss: 2.7450160228114355

Epoch: 5| Step: 5
Training loss: 3.331157466898691
Validation loss: 2.744828132038007

Epoch: 5| Step: 6
Training loss: 3.0847978636366227
Validation loss: 2.742559420324365

Epoch: 5| Step: 7
Training loss: 3.105703515349839
Validation loss: 2.7432638123980215

Epoch: 5| Step: 8
Training loss: 3.1182177378033695
Validation loss: 2.741937723707796

Epoch: 5| Step: 9
Training loss: 2.880300528422894
Validation loss: 2.740014768931472

Epoch: 5| Step: 10
Training loss: 3.6871670071526803
Validation loss: 2.739516352675292

Epoch: 159| Step: 0
Training loss: 3.207311954828519
Validation loss: 2.7411240764500797

Epoch: 5| Step: 1
Training loss: 3.401803290168319
Validation loss: 2.7371471204371836

Epoch: 5| Step: 2
Training loss: 3.2341522287506677
Validation loss: 2.7416924466029653

Epoch: 5| Step: 3
Training loss: 2.5875198732064417
Validation loss: 2.7373137458599675

Epoch: 5| Step: 4
Training loss: 3.3151208837686483
Validation loss: 2.7413389495617952

Epoch: 5| Step: 5
Training loss: 2.543985611784931
Validation loss: 2.7422621760381727

Epoch: 5| Step: 6
Training loss: 3.426389877208548
Validation loss: 2.746450159711319

Epoch: 5| Step: 7
Training loss: 2.565592132989748
Validation loss: 2.747055160581988

Epoch: 5| Step: 8
Training loss: 2.826192290279149
Validation loss: 2.751307406965157

Epoch: 5| Step: 9
Training loss: 3.768008668780226
Validation loss: 2.757634362095522

Epoch: 5| Step: 10
Training loss: 2.296963540790525
Validation loss: 2.7410050799375822

Epoch: 160| Step: 0
Training loss: 2.7818268595609443
Validation loss: 2.74295066046911

Epoch: 5| Step: 1
Training loss: 3.580586482124016
Validation loss: 2.738465037424615

Epoch: 5| Step: 2
Training loss: 2.8468116795085736
Validation loss: 2.738156259565425

Epoch: 5| Step: 3
Training loss: 2.4697732856889187
Validation loss: 2.73911481525769

Epoch: 5| Step: 4
Training loss: 2.4851001185122383
Validation loss: 2.7330052239514164

Epoch: 5| Step: 5
Training loss: 2.8221597724256173
Validation loss: 2.7353163207279776

Epoch: 5| Step: 6
Training loss: 3.183518410007693
Validation loss: 2.7344474424267595

Epoch: 5| Step: 7
Training loss: 3.2743676077360067
Validation loss: 2.7415635065945008

Epoch: 5| Step: 8
Training loss: 2.757969665371587
Validation loss: 2.7446161997722562

Epoch: 5| Step: 9
Training loss: 3.5447740424150855
Validation loss: 2.7403098713969647

Epoch: 5| Step: 10
Training loss: 3.7065444803567758
Validation loss: 2.746940477935615

Epoch: 161| Step: 0
Training loss: 2.8297107950449196
Validation loss: 2.7335915179310435

Epoch: 5| Step: 1
Training loss: 2.5168353657885305
Validation loss: 2.7343124246542145

Epoch: 5| Step: 2
Training loss: 2.7978141529185314
Validation loss: 2.7342047366150233

Epoch: 5| Step: 3
Training loss: 3.720147519416823
Validation loss: 2.7353956454730737

Epoch: 5| Step: 4
Training loss: 2.7615175942808965
Validation loss: 2.7371628563843617

Epoch: 5| Step: 5
Training loss: 3.018947056248283
Validation loss: 2.7370350452077226

Epoch: 5| Step: 6
Training loss: 3.2478962471650217
Validation loss: 2.7407706791459496

Epoch: 5| Step: 7
Training loss: 3.1561125168270014
Validation loss: 2.736101197828826

Epoch: 5| Step: 8
Training loss: 2.7209514605907827
Validation loss: 2.7403205457674016

Epoch: 5| Step: 9
Training loss: 3.416206158253046
Validation loss: 2.736177916671006

Epoch: 5| Step: 10
Training loss: 3.2610723711608625
Validation loss: 2.7410080560357053

Epoch: 162| Step: 0
Training loss: 3.9113595732484985
Validation loss: 2.7374151539892426

Epoch: 5| Step: 1
Training loss: 2.252786394513834
Validation loss: 2.743670418058651

Epoch: 5| Step: 2
Training loss: 2.668121199490094
Validation loss: 2.76083591564306

Epoch: 5| Step: 3
Training loss: 2.8612399663786743
Validation loss: 2.788102067294759

Epoch: 5| Step: 4
Training loss: 3.3896135500401403
Validation loss: 2.7956057695892675

Epoch: 5| Step: 5
Training loss: 2.593212669510602
Validation loss: 2.76497346816182

Epoch: 5| Step: 6
Training loss: 2.863762496328209
Validation loss: 2.7664109092430116

Epoch: 5| Step: 7
Training loss: 3.442630753482252
Validation loss: 2.774947441488009

Epoch: 5| Step: 8
Training loss: 3.3910217053082365
Validation loss: 2.7756007542626437

Epoch: 5| Step: 9
Training loss: 3.313702491008143
Validation loss: 2.7390225311884766

Epoch: 5| Step: 10
Training loss: 2.6540158019813576
Validation loss: 2.738658693000325

Epoch: 163| Step: 0
Training loss: 2.995108112810266
Validation loss: 2.7390263452601746

Epoch: 5| Step: 1
Training loss: 3.1002234347638535
Validation loss: 2.7386904965927474

Epoch: 5| Step: 2
Training loss: 2.4444862407906482
Validation loss: 2.739334934264648

Epoch: 5| Step: 3
Training loss: 3.1414705722905287
Validation loss: 2.740956443377067

Epoch: 5| Step: 4
Training loss: 2.7913260370703834
Validation loss: 2.736094176177876

Epoch: 5| Step: 5
Training loss: 3.1763966469687803
Validation loss: 2.7384526819608883

Epoch: 5| Step: 6
Training loss: 3.062098885562146
Validation loss: 2.735414057842232

Epoch: 5| Step: 7
Training loss: 3.2170450083602233
Validation loss: 2.731012491526713

Epoch: 5| Step: 8
Training loss: 2.9590987885264646
Validation loss: 2.7323475032971203

Epoch: 5| Step: 9
Training loss: 3.371030097440051
Validation loss: 2.7324073624172174

Epoch: 5| Step: 10
Training loss: 3.2952942154486946
Validation loss: 2.734338427414789

Epoch: 164| Step: 0
Training loss: 3.035723973106507
Validation loss: 2.7377750419822013

Epoch: 5| Step: 1
Training loss: 3.159967782302989
Validation loss: 2.743341280382018

Epoch: 5| Step: 2
Training loss: 3.0498309541976467
Validation loss: 2.73888185328204

Epoch: 5| Step: 3
Training loss: 2.9691017344060358
Validation loss: 2.745892304843745

Epoch: 5| Step: 4
Training loss: 3.146981103617929
Validation loss: 2.7571333777258333

Epoch: 5| Step: 5
Training loss: 3.0323619572730744
Validation loss: 2.751677207686838

Epoch: 5| Step: 6
Training loss: 3.079165520020419
Validation loss: 2.741855648586803

Epoch: 5| Step: 7
Training loss: 3.1947371657409476
Validation loss: 2.7347270048724033

Epoch: 5| Step: 8
Training loss: 2.9116893442366596
Validation loss: 2.7334403254440303

Epoch: 5| Step: 9
Training loss: 2.9172440820160417
Validation loss: 2.7291245819306296

Epoch: 5| Step: 10
Training loss: 3.0600409463873017
Validation loss: 2.7336978431322523

Epoch: 165| Step: 0
Training loss: 3.586446356146309
Validation loss: 2.728194243791307

Epoch: 5| Step: 1
Training loss: 2.78113727126817
Validation loss: 2.73011228224497

Epoch: 5| Step: 2
Training loss: 3.0705690543654858
Validation loss: 2.726407896539061

Epoch: 5| Step: 3
Training loss: 3.3960595240863634
Validation loss: 2.7301567963092324

Epoch: 5| Step: 4
Training loss: 2.970475187466724
Validation loss: 2.7282465404665825

Epoch: 5| Step: 5
Training loss: 2.4845210578257904
Validation loss: 2.7310549501857544

Epoch: 5| Step: 6
Training loss: 2.955152027847371
Validation loss: 2.731598016610449

Epoch: 5| Step: 7
Training loss: 3.3942587230576184
Validation loss: 2.7259461881381353

Epoch: 5| Step: 8
Training loss: 3.187745477536314
Validation loss: 2.7297813163626885

Epoch: 5| Step: 9
Training loss: 2.77900845498154
Validation loss: 2.723842947728202

Epoch: 5| Step: 10
Training loss: 2.592546482533943
Validation loss: 2.7237830443970545

Epoch: 166| Step: 0
Training loss: 3.239387056511168
Validation loss: 2.723736834560859

Epoch: 5| Step: 1
Training loss: 2.575070507973076
Validation loss: 2.7281133395531265

Epoch: 5| Step: 2
Training loss: 3.4847728006087846
Validation loss: 2.7244145645734514

Epoch: 5| Step: 3
Training loss: 3.430893670707343
Validation loss: 2.7243581903571865

Epoch: 5| Step: 4
Training loss: 2.3441158772036115
Validation loss: 2.721572790575093

Epoch: 5| Step: 5
Training loss: 2.8448247869671133
Validation loss: 2.7215314570770937

Epoch: 5| Step: 6
Training loss: 2.738460083262948
Validation loss: 2.7223323379173636

Epoch: 5| Step: 7
Training loss: 3.227985502406657
Validation loss: 2.722545970936661

Epoch: 5| Step: 8
Training loss: 3.4968626402226555
Validation loss: 2.719050462353087

Epoch: 5| Step: 9
Training loss: 2.4120334628743008
Validation loss: 2.720815554495751

Epoch: 5| Step: 10
Training loss: 3.4161776836291007
Validation loss: 2.7225872913866658

Epoch: 167| Step: 0
Training loss: 3.2278750061548056
Validation loss: 2.7246816913030076

Epoch: 5| Step: 1
Training loss: 2.887182381736165
Validation loss: 2.734773130247927

Epoch: 5| Step: 2
Training loss: 2.230319417306981
Validation loss: 2.753358792199679

Epoch: 5| Step: 3
Training loss: 3.251649144717086
Validation loss: 2.7478639896728123

Epoch: 5| Step: 4
Training loss: 2.8249622173652194
Validation loss: 2.7462238056974404

Epoch: 5| Step: 5
Training loss: 3.39076956867055
Validation loss: 2.7497665281927954

Epoch: 5| Step: 6
Training loss: 2.945454642106385
Validation loss: 2.7474796299688404

Epoch: 5| Step: 7
Training loss: 3.0378964891410227
Validation loss: 2.740414017703672

Epoch: 5| Step: 8
Training loss: 2.8181710606590635
Validation loss: 2.7309753153689926

Epoch: 5| Step: 9
Training loss: 3.1553736310403626
Validation loss: 2.721158553060878

Epoch: 5| Step: 10
Training loss: 3.5224369768470485
Validation loss: 2.719570426032924

Epoch: 168| Step: 0
Training loss: 2.7161684605261565
Validation loss: 2.716620865088535

Epoch: 5| Step: 1
Training loss: 2.728251636270784
Validation loss: 2.7135388837226158

Epoch: 5| Step: 2
Training loss: 3.0152654087541766
Validation loss: 2.714998994975634

Epoch: 5| Step: 3
Training loss: 2.8642926062815954
Validation loss: 2.719786098962142

Epoch: 5| Step: 4
Training loss: 2.8301028927811136
Validation loss: 2.722139500478732

Epoch: 5| Step: 5
Training loss: 3.207950288439736
Validation loss: 2.7198934143803384

Epoch: 5| Step: 6
Training loss: 3.4972046179442384
Validation loss: 2.7190265545506076

Epoch: 5| Step: 7
Training loss: 3.131855578311893
Validation loss: 2.7194087411849264

Epoch: 5| Step: 8
Training loss: 3.162744016619215
Validation loss: 2.7198503526145306

Epoch: 5| Step: 9
Training loss: 2.6259214509661724
Validation loss: 2.7174300404338463

Epoch: 5| Step: 10
Training loss: 3.633653506482942
Validation loss: 2.7149803138487094

Epoch: 169| Step: 0
Training loss: 3.120425118069727
Validation loss: 2.7161916941027555

Epoch: 5| Step: 1
Training loss: 3.4228072616605325
Validation loss: 2.7116792619216556

Epoch: 5| Step: 2
Training loss: 2.786626868929643
Validation loss: 2.7163858097775675

Epoch: 5| Step: 3
Training loss: 3.0029376270220247
Validation loss: 2.712978752858972

Epoch: 5| Step: 4
Training loss: 3.4105206236999384
Validation loss: 2.7286863626900826

Epoch: 5| Step: 5
Training loss: 3.308085252763414
Validation loss: 2.725207485403031

Epoch: 5| Step: 6
Training loss: 2.936159193145889
Validation loss: 2.7310469242909843

Epoch: 5| Step: 7
Training loss: 3.0161133998224234
Validation loss: 2.7223144642513466

Epoch: 5| Step: 8
Training loss: 3.052858239099803
Validation loss: 2.714219977136935

Epoch: 5| Step: 9
Training loss: 2.636097293661672
Validation loss: 2.710284148777259

Epoch: 5| Step: 10
Training loss: 2.5585462260018637
Validation loss: 2.7155470641685775

Epoch: 170| Step: 0
Training loss: 2.8754365009161273
Validation loss: 2.714330045727568

Epoch: 5| Step: 1
Training loss: 3.185451372821189
Validation loss: 2.707480154390359

Epoch: 5| Step: 2
Training loss: 2.6346082590896747
Validation loss: 2.7111345071616353

Epoch: 5| Step: 3
Training loss: 3.145925120515681
Validation loss: 2.7170489634162664

Epoch: 5| Step: 4
Training loss: 2.940635306556145
Validation loss: 2.709528958398877

Epoch: 5| Step: 5
Training loss: 3.3978176910997866
Validation loss: 2.7091739880159804

Epoch: 5| Step: 6
Training loss: 2.9116829573363527
Validation loss: 2.7078714063571008

Epoch: 5| Step: 7
Training loss: 3.069678476501518
Validation loss: 2.7105520495155946

Epoch: 5| Step: 8
Training loss: 2.9118573638126475
Validation loss: 2.7076463586915387

Epoch: 5| Step: 9
Training loss: 3.1676436138639597
Validation loss: 2.7090297614466876

Epoch: 5| Step: 10
Training loss: 3.1214613143036605
Validation loss: 2.711356690656266

Epoch: 171| Step: 0
Training loss: 2.793010577975687
Validation loss: 2.7075775338224313

Epoch: 5| Step: 1
Training loss: 2.8099747235121786
Validation loss: 2.7097730143629457

Epoch: 5| Step: 2
Training loss: 3.1797173426022027
Validation loss: 2.7099583567930656

Epoch: 5| Step: 3
Training loss: 3.215167820704762
Validation loss: 2.7084160488424605

Epoch: 5| Step: 4
Training loss: 3.387092120962858
Validation loss: 2.7063872003522578

Epoch: 5| Step: 5
Training loss: 2.7556988015764285
Validation loss: 2.7049146185294055

Epoch: 5| Step: 6
Training loss: 3.1817545252786017
Validation loss: 2.7106669192432995

Epoch: 5| Step: 7
Training loss: 2.999067161487273
Validation loss: 2.7199524156026214

Epoch: 5| Step: 8
Training loss: 3.65121896325084
Validation loss: 2.7224313792547674

Epoch: 5| Step: 9
Training loss: 2.195928412543901
Validation loss: 2.73761929341861

Epoch: 5| Step: 10
Training loss: 2.938050401134557
Validation loss: 2.724786378966196

Epoch: 172| Step: 0
Training loss: 2.7574026003087053
Validation loss: 2.730826343757983

Epoch: 5| Step: 1
Training loss: 2.8288291771057206
Validation loss: 2.731984881872756

Epoch: 5| Step: 2
Training loss: 3.0812640764328885
Validation loss: 2.724512518692652

Epoch: 5| Step: 3
Training loss: 3.3561641518750323
Validation loss: 2.72059444313509

Epoch: 5| Step: 4
Training loss: 3.0068687642837024
Validation loss: 2.7128822930554737

Epoch: 5| Step: 5
Training loss: 2.6109427122729523
Validation loss: 2.70628514678518

Epoch: 5| Step: 6
Training loss: 3.029356689649636
Validation loss: 2.711180080771231

Epoch: 5| Step: 7
Training loss: 3.070297435306156
Validation loss: 2.709379236221526

Epoch: 5| Step: 8
Training loss: 3.2939958339495736
Validation loss: 2.7054566989131255

Epoch: 5| Step: 9
Training loss: 3.105346370181012
Validation loss: 2.7024803704140092

Epoch: 5| Step: 10
Training loss: 3.096909884074466
Validation loss: 2.7055150901483414

Epoch: 173| Step: 0
Training loss: 2.7814979871282817
Validation loss: 2.7069358028148627

Epoch: 5| Step: 1
Training loss: 3.3090919380777075
Validation loss: 2.7065732406561334

Epoch: 5| Step: 2
Training loss: 2.676440259432441
Validation loss: 2.708768642708212

Epoch: 5| Step: 3
Training loss: 3.1121638840423707
Validation loss: 2.7126335069980176

Epoch: 5| Step: 4
Training loss: 3.0504620686704924
Validation loss: 2.712759213164085

Epoch: 5| Step: 5
Training loss: 3.3702046270531483
Validation loss: 2.7091446323189947

Epoch: 5| Step: 6
Training loss: 2.866265671059598
Validation loss: 2.7155357892309873

Epoch: 5| Step: 7
Training loss: 3.562399210257007
Validation loss: 2.7271862407853966

Epoch: 5| Step: 8
Training loss: 3.2992789376595435
Validation loss: 2.7251978346017656

Epoch: 5| Step: 9
Training loss: 2.767342416744569
Validation loss: 2.726365490571612

Epoch: 5| Step: 10
Training loss: 2.368091473597555
Validation loss: 2.709731285639708

Epoch: 174| Step: 0
Training loss: 3.3954614697010066
Validation loss: 2.7029244782845043

Epoch: 5| Step: 1
Training loss: 3.0198216465206076
Validation loss: 2.706587104648917

Epoch: 5| Step: 2
Training loss: 2.6495422039828003
Validation loss: 2.7118243061706075

Epoch: 5| Step: 3
Training loss: 3.4659826563661507
Validation loss: 2.7060007094904885

Epoch: 5| Step: 4
Training loss: 3.0301632850387095
Validation loss: 2.7195303700670697

Epoch: 5| Step: 5
Training loss: 3.092880897594361
Validation loss: 2.7242714328182323

Epoch: 5| Step: 6
Training loss: 2.51115304322055
Validation loss: 2.7205454181252193

Epoch: 5| Step: 7
Training loss: 2.96749530178042
Validation loss: 2.7268788181576875

Epoch: 5| Step: 8
Training loss: 2.6787397749541455
Validation loss: 2.7527053796859398

Epoch: 5| Step: 9
Training loss: 3.5460889844406456
Validation loss: 2.7390981826595233

Epoch: 5| Step: 10
Training loss: 2.8257330795708926
Validation loss: 2.7148982330211857

Epoch: 175| Step: 0
Training loss: 2.8877861310541153
Validation loss: 2.706785736412019

Epoch: 5| Step: 1
Training loss: 3.2274771587766202
Validation loss: 2.707552619527066

Epoch: 5| Step: 2
Training loss: 3.2510779133814918
Validation loss: 2.700638315273763

Epoch: 5| Step: 3
Training loss: 2.810993384441352
Validation loss: 2.700042992442888

Epoch: 5| Step: 4
Training loss: 3.148738723619599
Validation loss: 2.703204757269661

Epoch: 5| Step: 5
Training loss: 2.5385247702826104
Validation loss: 2.7015241161725956

Epoch: 5| Step: 6
Training loss: 3.2183105761373527
Validation loss: 2.7053024775284578

Epoch: 5| Step: 7
Training loss: 2.361369622483536
Validation loss: 2.704190350310994

Epoch: 5| Step: 8
Training loss: 2.917522595472531
Validation loss: 2.7039998303486334

Epoch: 5| Step: 9
Training loss: 3.300276028041759
Validation loss: 2.7043880594300536

Epoch: 5| Step: 10
Training loss: 3.5575330139472645
Validation loss: 2.7047005179812005

Testing loss: 2.9153488270065604
