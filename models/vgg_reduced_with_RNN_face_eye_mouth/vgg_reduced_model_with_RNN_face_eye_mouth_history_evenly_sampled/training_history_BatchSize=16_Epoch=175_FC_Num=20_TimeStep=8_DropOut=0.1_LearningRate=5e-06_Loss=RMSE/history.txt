Epoch: 1| Step: 0
Training loss: 5.534468754168655
Validation loss: 5.808530848021066

Epoch: 6| Step: 1
Training loss: 5.163581213980191
Validation loss: 5.804395304026411

Epoch: 6| Step: 2
Training loss: 6.108376189632746
Validation loss: 5.80079738282825

Epoch: 6| Step: 3
Training loss: 4.983151085284243
Validation loss: 5.797186629493034

Epoch: 6| Step: 4
Training loss: 6.7302465684453425
Validation loss: 5.793094183170166

Epoch: 6| Step: 5
Training loss: 5.094867419912834
Validation loss: 5.78920436007382

Epoch: 6| Step: 6
Training loss: 5.435224034834064
Validation loss: 5.785132398323044

Epoch: 6| Step: 7
Training loss: 6.359996718399833
Validation loss: 5.781153637793298

Epoch: 6| Step: 8
Training loss: 5.953174340551762
Validation loss: 5.7766997971406076

Epoch: 6| Step: 9
Training loss: 5.557737561981614
Validation loss: 5.7722979935843455

Epoch: 6| Step: 10
Training loss: 6.198371353354204
Validation loss: 5.767465752846302

Epoch: 6| Step: 11
Training loss: 5.590046087904158
Validation loss: 5.762634474655367

Epoch: 6| Step: 12
Training loss: 6.139304137917551
Validation loss: 5.757101423815131

Epoch: 6| Step: 13
Training loss: 6.596761729805331
Validation loss: 5.751936202669668

Epoch: 2| Step: 0
Training loss: 4.501962233925167
Validation loss: 5.7457777396111

Epoch: 6| Step: 1
Training loss: 4.55073556508721
Validation loss: 5.739534805039397

Epoch: 6| Step: 2
Training loss: 6.532521393336155
Validation loss: 5.733635681423875

Epoch: 6| Step: 3
Training loss: 5.6758834084061585
Validation loss: 5.726955330563281

Epoch: 6| Step: 4
Training loss: 5.361325812556423
Validation loss: 5.7198015879381705

Epoch: 6| Step: 5
Training loss: 4.892379104921696
Validation loss: 5.712720863408013

Epoch: 6| Step: 6
Training loss: 5.264613747769917
Validation loss: 5.705301501664183

Epoch: 6| Step: 7
Training loss: 6.5662543320655145
Validation loss: 5.697584174877871

Epoch: 6| Step: 8
Training loss: 5.872229389501886
Validation loss: 5.689155872155522

Epoch: 6| Step: 9
Training loss: 5.209676015082791
Validation loss: 5.6799708305302

Epoch: 6| Step: 10
Training loss: 6.034701135752421
Validation loss: 5.6714034698511435

Epoch: 6| Step: 11
Training loss: 6.498619226371494
Validation loss: 5.661840306543793

Epoch: 6| Step: 12
Training loss: 6.329041515901896
Validation loss: 5.65172333450487

Epoch: 6| Step: 13
Training loss: 6.802321082765581
Validation loss: 5.6410212773705535

Epoch: 3| Step: 0
Training loss: 6.528011121254218
Validation loss: 5.629533185729732

Epoch: 6| Step: 1
Training loss: 6.135370933306136
Validation loss: 5.6172217347883775

Epoch: 6| Step: 2
Training loss: 5.468930835458813
Validation loss: 5.605494493051862

Epoch: 6| Step: 3
Training loss: 4.983829671750579
Validation loss: 5.592543011117724

Epoch: 6| Step: 4
Training loss: 5.753477289042458
Validation loss: 5.580049232456551

Epoch: 6| Step: 5
Training loss: 6.730087012625451
Validation loss: 5.566326518010368

Epoch: 6| Step: 6
Training loss: 5.037728445017872
Validation loss: 5.552418300577237

Epoch: 6| Step: 7
Training loss: 4.75202898559978
Validation loss: 5.53814148190663

Epoch: 6| Step: 8
Training loss: 4.765871535631298
Validation loss: 5.523005215938653

Epoch: 6| Step: 9
Training loss: 6.046881308539991
Validation loss: 5.506995394013521

Epoch: 6| Step: 10
Training loss: 5.921739078461572
Validation loss: 5.491245880181804

Epoch: 6| Step: 11
Training loss: 4.056613119415056
Validation loss: 5.474292791001176

Epoch: 6| Step: 12
Training loss: 5.38010182110606
Validation loss: 5.457316134365241

Epoch: 6| Step: 13
Training loss: 6.252468079581186
Validation loss: 5.440563654709984

Epoch: 4| Step: 0
Training loss: 5.408959387862502
Validation loss: 5.4216159513862765

Epoch: 6| Step: 1
Training loss: 5.517159829276936
Validation loss: 5.403893189346399

Epoch: 6| Step: 2
Training loss: 5.891836188582953
Validation loss: 5.384362747094357

Epoch: 6| Step: 3
Training loss: 5.984424720338492
Validation loss: 5.364804975130586

Epoch: 6| Step: 4
Training loss: 5.869389878754701
Validation loss: 5.343536493583758

Epoch: 6| Step: 5
Training loss: 5.127832513868135
Validation loss: 5.322982882393331

Epoch: 6| Step: 6
Training loss: 5.121938768121381
Validation loss: 5.300832919322532

Epoch: 6| Step: 7
Training loss: 5.244380668388852
Validation loss: 5.279534294401547

Epoch: 6| Step: 8
Training loss: 4.6445604071572175
Validation loss: 5.258072170682563

Epoch: 6| Step: 9
Training loss: 6.215366382310654
Validation loss: 5.237599024050802

Epoch: 6| Step: 10
Training loss: 5.191412679583585
Validation loss: 5.21475667235175

Epoch: 6| Step: 11
Training loss: 4.665361130976023
Validation loss: 5.19205731800064

Epoch: 6| Step: 12
Training loss: 4.394242612048739
Validation loss: 5.169415542867849

Epoch: 6| Step: 13
Training loss: 5.104846312239188
Validation loss: 5.146046105710035

Epoch: 5| Step: 0
Training loss: 5.4242696173732
Validation loss: 5.12487239963926

Epoch: 6| Step: 1
Training loss: 4.678600968462124
Validation loss: 5.101322273380276

Epoch: 6| Step: 2
Training loss: 5.521815815960861
Validation loss: 5.0793870905817595

Epoch: 6| Step: 3
Training loss: 3.4929826415793994
Validation loss: 5.054256414423406

Epoch: 6| Step: 4
Training loss: 4.373122111972816
Validation loss: 5.031854571664723

Epoch: 6| Step: 5
Training loss: 5.110985178478696
Validation loss: 5.007714546692718

Epoch: 6| Step: 6
Training loss: 5.718313732078414
Validation loss: 4.984980998421082

Epoch: 6| Step: 7
Training loss: 4.287622317690792
Validation loss: 4.959917035647802

Epoch: 6| Step: 8
Training loss: 5.387309152006407
Validation loss: 4.933946497198865

Epoch: 6| Step: 9
Training loss: 5.516555491515226
Validation loss: 4.913669264147738

Epoch: 6| Step: 10
Training loss: 5.429876310509893
Validation loss: 4.887716054692581

Epoch: 6| Step: 11
Training loss: 5.098081093108385
Validation loss: 4.8612476100401105

Epoch: 6| Step: 12
Training loss: 4.743256047884302
Validation loss: 4.836795480622629

Epoch: 6| Step: 13
Training loss: 5.40691975761235
Validation loss: 4.812050453074633

Epoch: 6| Step: 0
Training loss: 5.220853644248056
Validation loss: 4.787185265424387

Epoch: 6| Step: 1
Training loss: 3.8711624832287286
Validation loss: 4.762424253094402

Epoch: 6| Step: 2
Training loss: 4.688648947733038
Validation loss: 4.733977183693466

Epoch: 6| Step: 3
Training loss: 4.544560948013029
Validation loss: 4.709202804382493

Epoch: 6| Step: 4
Training loss: 4.894661794323541
Validation loss: 4.68134931537867

Epoch: 6| Step: 5
Training loss: 4.887139879310922
Validation loss: 4.65446915245569

Epoch: 6| Step: 6
Training loss: 4.1466642278764265
Validation loss: 4.631997156429266

Epoch: 6| Step: 7
Training loss: 4.623631867825327
Validation loss: 4.60724484246489

Epoch: 6| Step: 8
Training loss: 4.727062053921134
Validation loss: 4.5829169538240935

Epoch: 6| Step: 9
Training loss: 5.241893322304165
Validation loss: 4.559036455102763

Epoch: 6| Step: 10
Training loss: 3.4123004058484385
Validation loss: 4.53871754388206

Epoch: 6| Step: 11
Training loss: 4.05221193921811
Validation loss: 4.519665006797353

Epoch: 6| Step: 12
Training loss: 5.821188390994339
Validation loss: 4.496284570120412

Epoch: 6| Step: 13
Training loss: 5.604087951939307
Validation loss: 4.478123094233871

Epoch: 7| Step: 0
Training loss: 4.496719860292958
Validation loss: 4.454260908096195

Epoch: 6| Step: 1
Training loss: 5.560020665740982
Validation loss: 4.437304778876506

Epoch: 6| Step: 2
Training loss: 4.228151597350287
Validation loss: 4.416371732504752

Epoch: 6| Step: 3
Training loss: 4.126183773458065
Validation loss: 4.397860967393052

Epoch: 6| Step: 4
Training loss: 3.99271635669619
Validation loss: 4.378573589234706

Epoch: 6| Step: 5
Training loss: 4.247750752969221
Validation loss: 4.3622451915135585

Epoch: 6| Step: 6
Training loss: 4.196633470165122
Validation loss: 4.343792129965044

Epoch: 6| Step: 7
Training loss: 4.087039718610406
Validation loss: 4.3264662725384735

Epoch: 6| Step: 8
Training loss: 2.908921685227805
Validation loss: 4.309352581644607

Epoch: 6| Step: 9
Training loss: 4.60328856965513
Validation loss: 4.293809438054235

Epoch: 6| Step: 10
Training loss: 4.944698446276514
Validation loss: 4.273461414397799

Epoch: 6| Step: 11
Training loss: 4.763617821418418
Validation loss: 4.257396439914678

Epoch: 6| Step: 12
Training loss: 5.290833755583673
Validation loss: 4.243292723386791

Epoch: 6| Step: 13
Training loss: 4.1561058994638955
Validation loss: 4.224799717845656

Epoch: 8| Step: 0
Training loss: 5.025233871559331
Validation loss: 4.209658230313611

Epoch: 6| Step: 1
Training loss: 3.849272691469896
Validation loss: 4.195119555491565

Epoch: 6| Step: 2
Training loss: 4.840925611466968
Validation loss: 4.181278875669306

Epoch: 6| Step: 3
Training loss: 3.9727203453992357
Validation loss: 4.165073522534761

Epoch: 6| Step: 4
Training loss: 4.130756869295555
Validation loss: 4.152984241597282

Epoch: 6| Step: 5
Training loss: 3.5243167837347222
Validation loss: 4.142648158593171

Epoch: 6| Step: 6
Training loss: 4.529973975100507
Validation loss: 4.125799769646346

Epoch: 6| Step: 7
Training loss: 3.9779906340844096
Validation loss: 4.111416701329984

Epoch: 6| Step: 8
Training loss: 3.7442565167738335
Validation loss: 4.1010593094314025

Epoch: 6| Step: 9
Training loss: 4.74580479122931
Validation loss: 4.089738453581862

Epoch: 6| Step: 10
Training loss: 4.438256212730273
Validation loss: 4.078525728301467

Epoch: 6| Step: 11
Training loss: 4.570554338887317
Validation loss: 4.0656264498955705

Epoch: 6| Step: 12
Training loss: 3.9324080224748563
Validation loss: 4.054786392767738

Epoch: 6| Step: 13
Training loss: 3.8736626563083587
Validation loss: 4.044319123965652

Epoch: 9| Step: 0
Training loss: 4.725773315120322
Validation loss: 4.031503285143287

Epoch: 6| Step: 1
Training loss: 2.5091855102290967
Validation loss: 4.022178596156955

Epoch: 6| Step: 2
Training loss: 3.598407016745952
Validation loss: 4.01130465374615

Epoch: 6| Step: 3
Training loss: 4.630500409497703
Validation loss: 4.00149389667842

Epoch: 6| Step: 4
Training loss: 3.8657239822630194
Validation loss: 3.991757311448907

Epoch: 6| Step: 5
Training loss: 4.035111581235698
Validation loss: 3.980286318540554

Epoch: 6| Step: 6
Training loss: 3.8637634531834064
Validation loss: 3.9693165488501663

Epoch: 6| Step: 7
Training loss: 3.813495818613355
Validation loss: 3.959867040180124

Epoch: 6| Step: 8
Training loss: 5.041927782763411
Validation loss: 3.9510205972840335

Epoch: 6| Step: 9
Training loss: 3.811558341380346
Validation loss: 3.9416556174619366

Epoch: 6| Step: 10
Training loss: 4.721084926507972
Validation loss: 3.9290888691259873

Epoch: 6| Step: 11
Training loss: 4.387192657226383
Validation loss: 3.921200143022742

Epoch: 6| Step: 12
Training loss: 3.9249700362890163
Validation loss: 3.9109052860772207

Epoch: 6| Step: 13
Training loss: 3.9647139805194853
Validation loss: 3.9044322782665017

Epoch: 10| Step: 0
Training loss: 4.2080258298015885
Validation loss: 3.8927180309005225

Epoch: 6| Step: 1
Training loss: 4.420486717526049
Validation loss: 3.884469060764058

Epoch: 6| Step: 2
Training loss: 4.69105273081284
Validation loss: 3.8756930247242236

Epoch: 6| Step: 3
Training loss: 2.261080057095982
Validation loss: 3.8663850222040845

Epoch: 6| Step: 4
Training loss: 2.861589085262856
Validation loss: 3.8601937025340467

Epoch: 6| Step: 5
Training loss: 5.261528255239962
Validation loss: 3.8549009883506096

Epoch: 6| Step: 6
Training loss: 4.478490923394591
Validation loss: 3.848769133641676

Epoch: 6| Step: 7
Training loss: 4.033182316834943
Validation loss: 3.841182226888429

Epoch: 6| Step: 8
Training loss: 4.241020140373621
Validation loss: 3.835011912348763

Epoch: 6| Step: 9
Training loss: 2.6684265190816174
Validation loss: 3.8276613418023637

Epoch: 6| Step: 10
Training loss: 4.2712302915114515
Validation loss: 3.821625263771975

Epoch: 6| Step: 11
Training loss: 3.4536194598351524
Validation loss: 3.815763522774673

Epoch: 6| Step: 12
Training loss: 3.7731309217299427
Validation loss: 3.8089085121388133

Epoch: 6| Step: 13
Training loss: 4.6616433673413225
Validation loss: 3.8032140318437357

Epoch: 11| Step: 0
Training loss: 4.575887608541741
Validation loss: 3.796284253430106

Epoch: 6| Step: 1
Training loss: 4.077626164938518
Validation loss: 3.791179380011809

Epoch: 6| Step: 2
Training loss: 3.2893047470079395
Validation loss: 3.786718753141319

Epoch: 6| Step: 3
Training loss: 3.57073905283246
Validation loss: 3.785824787930867

Epoch: 6| Step: 4
Training loss: 4.2468002840477315
Validation loss: 3.7754120038297048

Epoch: 6| Step: 5
Training loss: 3.861288978328055
Validation loss: 3.771376764687624

Epoch: 6| Step: 6
Training loss: 4.428408483504807
Validation loss: 3.7654601663411493

Epoch: 6| Step: 7
Training loss: 4.027419051642044
Validation loss: 3.762749724556011

Epoch: 6| Step: 8
Training loss: 3.2804680755461915
Validation loss: 3.754998217754969

Epoch: 6| Step: 9
Training loss: 4.195861212225192
Validation loss: 3.750974736295722

Epoch: 6| Step: 10
Training loss: 4.510411404202088
Validation loss: 3.746258956748086

Epoch: 6| Step: 11
Training loss: 3.8484520413568912
Validation loss: 3.742787780920372

Epoch: 6| Step: 12
Training loss: 3.692548238120218
Validation loss: 3.73909880031355

Epoch: 6| Step: 13
Training loss: 2.557863833145935
Validation loss: 3.7301161897694253

Epoch: 12| Step: 0
Training loss: 3.7033436384724356
Validation loss: 3.7270153352946402

Epoch: 6| Step: 1
Training loss: 3.8900815285423076
Validation loss: 3.7227425875517595

Epoch: 6| Step: 2
Training loss: 3.7945465357761012
Validation loss: 3.718926625216417

Epoch: 6| Step: 3
Training loss: 4.691390394045853
Validation loss: 3.7138360705346196

Epoch: 6| Step: 4
Training loss: 4.136626533438623
Validation loss: 3.7064856479309842

Epoch: 6| Step: 5
Training loss: 4.566884899261801
Validation loss: 3.7046141386712423

Epoch: 6| Step: 6
Training loss: 4.384536376941427
Validation loss: 3.697432170339141

Epoch: 6| Step: 7
Training loss: 2.7714151235346876
Validation loss: 3.691387843220522

Epoch: 6| Step: 8
Training loss: 3.725281693221018
Validation loss: 3.68694054649378

Epoch: 6| Step: 9
Training loss: 3.423532302358628
Validation loss: 3.6809638989416356

Epoch: 6| Step: 10
Training loss: 3.5298615823467276
Validation loss: 3.67489719298691

Epoch: 6| Step: 11
Training loss: 3.604788901064837
Validation loss: 3.670562561253592

Epoch: 6| Step: 12
Training loss: 3.764311882045974
Validation loss: 3.664188823537855

Epoch: 6| Step: 13
Training loss: 3.9804958234021637
Validation loss: 3.663871280347214

Epoch: 13| Step: 0
Training loss: 3.509541856258808
Validation loss: 3.6564161825403803

Epoch: 6| Step: 1
Training loss: 3.7653455195252254
Validation loss: 3.656443270081978

Epoch: 6| Step: 2
Training loss: 3.5410762219890897
Validation loss: 3.6523595220315075

Epoch: 6| Step: 3
Training loss: 2.8523443117039298
Validation loss: 3.6473882403559013

Epoch: 6| Step: 4
Training loss: 3.7331995690314757
Validation loss: 3.643695361705122

Epoch: 6| Step: 5
Training loss: 4.086721195605988
Validation loss: 3.638289000240821

Epoch: 6| Step: 6
Training loss: 5.110189483772455
Validation loss: 3.6335883434254894

Epoch: 6| Step: 7
Training loss: 3.9592275446024776
Validation loss: 3.628734076998548

Epoch: 6| Step: 8
Training loss: 3.401614333227899
Validation loss: 3.625944105860609

Epoch: 6| Step: 9
Training loss: 3.9379422378449784
Validation loss: 3.6198946992675247

Epoch: 6| Step: 10
Training loss: 3.714399598021098
Validation loss: 3.617098212001124

Epoch: 6| Step: 11
Training loss: 3.318420876600467
Validation loss: 3.6150281820990218

Epoch: 6| Step: 12
Training loss: 4.635924556496824
Validation loss: 3.6101712727923547

Epoch: 6| Step: 13
Training loss: 3.1774225439540063
Validation loss: 3.6039271367845784

Epoch: 14| Step: 0
Training loss: 4.2711802768124
Validation loss: 3.6025507800240355

Epoch: 6| Step: 1
Training loss: 4.602325738843449
Validation loss: 3.5989463051714172

Epoch: 6| Step: 2
Training loss: 3.9953614996873053
Validation loss: 3.5957674488836227

Epoch: 6| Step: 3
Training loss: 4.513388743283482
Validation loss: 3.5881739476110135

Epoch: 6| Step: 4
Training loss: 3.515351823153944
Validation loss: 3.5855838112296805

Epoch: 6| Step: 5
Training loss: 2.4853743936205754
Validation loss: 3.5813829451689614

Epoch: 6| Step: 6
Training loss: 3.1815877199311506
Validation loss: 3.5761985868091464

Epoch: 6| Step: 7
Training loss: 4.818691877714689
Validation loss: 3.574424977536305

Epoch: 6| Step: 8
Training loss: 3.1786558834998178
Validation loss: 3.569094461278572

Epoch: 6| Step: 9
Training loss: 3.411195017817797
Validation loss: 3.5686637550626057

Epoch: 6| Step: 10
Training loss: 3.5071194310275793
Validation loss: 3.56640250489252

Epoch: 6| Step: 11
Training loss: 3.7709812676230787
Validation loss: 3.558771136048244

Epoch: 6| Step: 12
Training loss: 3.3151157056313485
Validation loss: 3.556487651252918

Epoch: 6| Step: 13
Training loss: 3.5009844621598463
Validation loss: 3.5511781032641188

Epoch: 15| Step: 0
Training loss: 4.262301425279706
Validation loss: 3.5468753006800235

Epoch: 6| Step: 1
Training loss: 3.251383560294347
Validation loss: 3.5421041740797192

Epoch: 6| Step: 2
Training loss: 3.6685169204419443
Validation loss: 3.5406407766337584

Epoch: 6| Step: 3
Training loss: 4.806890612150201
Validation loss: 3.537473460251929

Epoch: 6| Step: 4
Training loss: 3.652670126627243
Validation loss: 3.5338841925027733

Epoch: 6| Step: 5
Training loss: 3.650472396171482
Validation loss: 3.527764272196994

Epoch: 6| Step: 6
Training loss: 2.995710166836325
Validation loss: 3.5242248460177703

Epoch: 6| Step: 7
Training loss: 3.765006999988305
Validation loss: 3.5198136263344546

Epoch: 6| Step: 8
Training loss: 3.684390810090522
Validation loss: 3.5173341697785108

Epoch: 6| Step: 9
Training loss: 4.310338017425419
Validation loss: 3.513752133597415

Epoch: 6| Step: 10
Training loss: 3.5817331836950292
Validation loss: 3.5075090811844176

Epoch: 6| Step: 11
Training loss: 2.8830285133542257
Validation loss: 3.504906302152548

Epoch: 6| Step: 12
Training loss: 3.9364216856887975
Validation loss: 3.501064780946711

Epoch: 6| Step: 13
Training loss: 2.9539094720604453
Validation loss: 3.4969435082082927

Epoch: 16| Step: 0
Training loss: 2.9124956188250812
Validation loss: 3.4953355148555

Epoch: 6| Step: 1
Training loss: 4.25136364770061
Validation loss: 3.4940097104519854

Epoch: 6| Step: 2
Training loss: 3.864688073287234
Validation loss: 3.488837866147377

Epoch: 6| Step: 3
Training loss: 3.542447860430986
Validation loss: 3.484508972226388

Epoch: 6| Step: 4
Training loss: 3.7805538324792356
Validation loss: 3.4795331510789835

Epoch: 6| Step: 5
Training loss: 4.314778265179004
Validation loss: 3.473622953898918

Epoch: 6| Step: 6
Training loss: 3.7174454652830504
Validation loss: 3.4706518562866986

Epoch: 6| Step: 7
Training loss: 3.505365890581962
Validation loss: 3.467182875962808

Epoch: 6| Step: 8
Training loss: 3.7626584346022427
Validation loss: 3.461721897830362

Epoch: 6| Step: 9
Training loss: 4.462189026156485
Validation loss: 3.4589191676429674

Epoch: 6| Step: 10
Training loss: 3.4398795474942916
Validation loss: 3.4609688063202606

Epoch: 6| Step: 11
Training loss: 3.416325497845099
Validation loss: 3.4600283005966745

Epoch: 6| Step: 12
Training loss: 3.1869635036977386
Validation loss: 3.452671560059469

Epoch: 6| Step: 13
Training loss: 2.5246522418465362
Validation loss: 3.453086235494375

Epoch: 17| Step: 0
Training loss: 3.759524647309879
Validation loss: 3.45282633710242

Epoch: 6| Step: 1
Training loss: 3.1219549984080426
Validation loss: 3.440672179501212

Epoch: 6| Step: 2
Training loss: 3.1883542281278903
Validation loss: 3.4471460580504876

Epoch: 6| Step: 3
Training loss: 4.0467873346561705
Validation loss: 3.448867936280101

Epoch: 6| Step: 4
Training loss: 3.6475822540902354
Validation loss: 3.4573191625821016

Epoch: 6| Step: 5
Training loss: 3.881353768206991
Validation loss: 3.455690729477818

Epoch: 6| Step: 6
Training loss: 4.143810730916318
Validation loss: 3.4475760903094796

Epoch: 6| Step: 7
Training loss: 2.708432141971361
Validation loss: 3.4419259433702725

Epoch: 6| Step: 8
Training loss: 4.548885569490225
Validation loss: 3.432168918447387

Epoch: 6| Step: 9
Training loss: 3.2399053055853586
Validation loss: 3.4263013990028237

Epoch: 6| Step: 10
Training loss: 3.40937759581134
Validation loss: 3.4251198967616543

Epoch: 6| Step: 11
Training loss: 3.9285709926060024
Validation loss: 3.423405446860056

Epoch: 6| Step: 12
Training loss: 3.7213505219249705
Validation loss: 3.419269246335929

Epoch: 6| Step: 13
Training loss: 3.3831853154568914
Validation loss: 3.421687717906344

Epoch: 18| Step: 0
Training loss: 3.1801802419768537
Validation loss: 3.419519310052902

Epoch: 6| Step: 1
Training loss: 2.9444739162321647
Validation loss: 3.416395400709069

Epoch: 6| Step: 2
Training loss: 3.727237152513462
Validation loss: 3.410749196238902

Epoch: 6| Step: 3
Training loss: 4.368386201350607
Validation loss: 3.409460846364644

Epoch: 6| Step: 4
Training loss: 2.828094650864438
Validation loss: 3.4037556045603763

Epoch: 6| Step: 5
Training loss: 3.036415339711347
Validation loss: 3.4013948680995005

Epoch: 6| Step: 6
Training loss: 4.318039584212965
Validation loss: 3.403304181802438

Epoch: 6| Step: 7
Training loss: 3.6506962778336245
Validation loss: 3.401950735731539

Epoch: 6| Step: 8
Training loss: 3.9722915827127823
Validation loss: 3.4000831890002727

Epoch: 6| Step: 9
Training loss: 4.008662856760334
Validation loss: 3.398130133240091

Epoch: 6| Step: 10
Training loss: 3.323678785280643
Validation loss: 3.3949551201993047

Epoch: 6| Step: 11
Training loss: 4.069598290866487
Validation loss: 3.3925006370747264

Epoch: 6| Step: 12
Training loss: 3.3401431300852313
Validation loss: 3.389328508885111

Epoch: 6| Step: 13
Training loss: 3.4884299730334005
Validation loss: 3.382190200642635

Epoch: 19| Step: 0
Training loss: 2.9592312448585147
Validation loss: 3.3797932977123013

Epoch: 6| Step: 1
Training loss: 3.780792208615999
Validation loss: 3.378056769348715

Epoch: 6| Step: 2
Training loss: 4.603235533216563
Validation loss: 3.3721212599891692

Epoch: 6| Step: 3
Training loss: 3.6592193023109156
Validation loss: 3.370206574388357

Epoch: 6| Step: 4
Training loss: 3.130515457463666
Validation loss: 3.3665191502530663

Epoch: 6| Step: 5
Training loss: 4.049236300954994
Validation loss: 3.3667597013923602

Epoch: 6| Step: 6
Training loss: 4.015654686250313
Validation loss: 3.3635919018773106

Epoch: 6| Step: 7
Training loss: 3.4589364012412878
Validation loss: 3.370029570713094

Epoch: 6| Step: 8
Training loss: 2.695513643140024
Validation loss: 3.356905532400432

Epoch: 6| Step: 9
Training loss: 3.5109619411403807
Validation loss: 3.357467942641025

Epoch: 6| Step: 10
Training loss: 3.8323380933629565
Validation loss: 3.361399440036626

Epoch: 6| Step: 11
Training loss: 2.849477847268723
Validation loss: 3.355163150024457

Epoch: 6| Step: 12
Training loss: 3.7389786567007404
Validation loss: 3.354426116681972

Epoch: 6| Step: 13
Training loss: 3.559608222749084
Validation loss: 3.34882626854975

Epoch: 20| Step: 0
Training loss: 3.867322391507902
Validation loss: 3.348004506217041

Epoch: 6| Step: 1
Training loss: 3.693816900534965
Validation loss: 3.345014872468315

Epoch: 6| Step: 2
Training loss: 2.8323534972912836
Validation loss: 3.3456442781156093

Epoch: 6| Step: 3
Training loss: 3.256710460710676
Validation loss: 3.341144597478484

Epoch: 6| Step: 4
Training loss: 3.5940351290166817
Validation loss: 3.339836892317226

Epoch: 6| Step: 5
Training loss: 3.289130928251959
Validation loss: 3.331445245889651

Epoch: 6| Step: 6
Training loss: 3.899743727064611
Validation loss: 3.331419057207385

Epoch: 6| Step: 7
Training loss: 3.9779532348277504
Validation loss: 3.32773691622576

Epoch: 6| Step: 8
Training loss: 3.1125340348799613
Validation loss: 3.3268469417476645

Epoch: 6| Step: 9
Training loss: 3.5841240712726963
Validation loss: 3.3196465099268213

Epoch: 6| Step: 10
Training loss: 3.7707767938973173
Validation loss: 3.322630196231829

Epoch: 6| Step: 11
Training loss: 3.8134616827094465
Validation loss: 3.330375524009624

Epoch: 6| Step: 12
Training loss: 4.113344313381714
Validation loss: 3.3366550035998044

Epoch: 6| Step: 13
Training loss: 2.1743832382392574
Validation loss: 3.3210765228383172

Epoch: 21| Step: 0
Training loss: 4.168416278984423
Validation loss: 3.3232870349104298

Epoch: 6| Step: 1
Training loss: 4.215202592028728
Validation loss: 3.3228175604673176

Epoch: 6| Step: 2
Training loss: 3.516079072238895
Validation loss: 3.315970302767997

Epoch: 6| Step: 3
Training loss: 3.262465120911047
Validation loss: 3.314185886973745

Epoch: 6| Step: 4
Training loss: 2.4932780495632816
Validation loss: 3.3137459805940077

Epoch: 6| Step: 5
Training loss: 3.7122593503078085
Validation loss: 3.310800834389237

Epoch: 6| Step: 6
Training loss: 3.227586339007003
Validation loss: 3.309879742522083

Epoch: 6| Step: 7
Training loss: 2.8601583439668996
Validation loss: 3.3082850265313413

Epoch: 6| Step: 8
Training loss: 4.18003681184904
Validation loss: 3.3098658812907242

Epoch: 6| Step: 9
Training loss: 3.320491435895369
Validation loss: 3.3044795730153083

Epoch: 6| Step: 10
Training loss: 3.156239877816767
Validation loss: 3.30237324406873

Epoch: 6| Step: 11
Training loss: 3.5472821913585326
Validation loss: 3.301677070320472

Epoch: 6| Step: 12
Training loss: 3.8063049011780996
Validation loss: 3.299385748108572

Epoch: 6| Step: 13
Training loss: 3.9411946477127553
Validation loss: 3.294816099416453

Epoch: 22| Step: 0
Training loss: 3.5169401294513825
Validation loss: 3.2944066575562565

Epoch: 6| Step: 1
Training loss: 4.0867160616986
Validation loss: 3.2930360025053536

Epoch: 6| Step: 2
Training loss: 3.368051369436138
Validation loss: 3.2931283644432985

Epoch: 6| Step: 3
Training loss: 3.0837521311579015
Validation loss: 3.28880082394257

Epoch: 6| Step: 4
Training loss: 3.629438116970983
Validation loss: 3.2885652931666507

Epoch: 6| Step: 5
Training loss: 3.9950390092188917
Validation loss: 3.289526164898619

Epoch: 6| Step: 6
Training loss: 3.720991468895982
Validation loss: 3.292961621867046

Epoch: 6| Step: 7
Training loss: 3.1362885100523092
Validation loss: 3.2865495823969737

Epoch: 6| Step: 8
Training loss: 3.0596309379466717
Validation loss: 3.281970834148525

Epoch: 6| Step: 9
Training loss: 3.2391937773950246
Validation loss: 3.282401431053845

Epoch: 6| Step: 10
Training loss: 4.094353784195529
Validation loss: 3.2793462446731043

Epoch: 6| Step: 11
Training loss: 3.7080719816428753
Validation loss: 3.27861403820346

Epoch: 6| Step: 12
Training loss: 2.8475683379241223
Validation loss: 3.2808752374276198

Epoch: 6| Step: 13
Training loss: 3.764188880429789
Validation loss: 3.283536315468599

Epoch: 23| Step: 0
Training loss: 3.2431628862727466
Validation loss: 3.284439952876975

Epoch: 6| Step: 1
Training loss: 3.9020190710073894
Validation loss: 3.283638806830415

Epoch: 6| Step: 2
Training loss: 3.3441258869842274
Validation loss: 3.2854887586158337

Epoch: 6| Step: 3
Training loss: 3.381913909321684
Validation loss: 3.2826826617579608

Epoch: 6| Step: 4
Training loss: 3.7299149826219753
Validation loss: 3.279174240305158

Epoch: 6| Step: 5
Training loss: 3.0021329291061445
Validation loss: 3.276240205153987

Epoch: 6| Step: 6
Training loss: 4.139349514264906
Validation loss: 3.271814805058377

Epoch: 6| Step: 7
Training loss: 3.183492796999831
Validation loss: 3.2718827086325533

Epoch: 6| Step: 8
Training loss: 3.5716622303412855
Validation loss: 3.2749824728234906

Epoch: 6| Step: 9
Training loss: 3.5934303473243747
Validation loss: 3.2686067574927455

Epoch: 6| Step: 10
Training loss: 3.0232879838272595
Validation loss: 3.2665841743453665

Epoch: 6| Step: 11
Training loss: 3.8903401588439115
Validation loss: 3.2709306167254875

Epoch: 6| Step: 12
Training loss: 3.5257631057553023
Validation loss: 3.2646552026208435

Epoch: 6| Step: 13
Training loss: 3.547919434691757
Validation loss: 3.2622147149949474

Epoch: 24| Step: 0
Training loss: 2.577345851725045
Validation loss: 3.2631627349302974

Epoch: 6| Step: 1
Training loss: 4.104136562075635
Validation loss: 3.2618667306650138

Epoch: 6| Step: 2
Training loss: 3.3061328369610807
Validation loss: 3.2617057907616327

Epoch: 6| Step: 3
Training loss: 3.6614819775067096
Validation loss: 3.2583809409277444

Epoch: 6| Step: 4
Training loss: 3.5411382991626277
Validation loss: 3.260359867820879

Epoch: 6| Step: 5
Training loss: 2.5926562841352525
Validation loss: 3.256124447911671

Epoch: 6| Step: 6
Training loss: 4.386335021548701
Validation loss: 3.2565453581896895

Epoch: 6| Step: 7
Training loss: 3.739401271854659
Validation loss: 3.2583785506783385

Epoch: 6| Step: 8
Training loss: 3.025514190100908
Validation loss: 3.258010395144333

Epoch: 6| Step: 9
Training loss: 3.4128005010741305
Validation loss: 3.2630563650926927

Epoch: 6| Step: 10
Training loss: 3.204967731664508
Validation loss: 3.2607641385165183

Epoch: 6| Step: 11
Training loss: 3.7665715590991304
Validation loss: 3.261760315419313

Epoch: 6| Step: 12
Training loss: 3.874999138616651
Validation loss: 3.2592612375670518

Epoch: 6| Step: 13
Training loss: 3.36957849283265
Validation loss: 3.2564808285480553

Epoch: 25| Step: 0
Training loss: 3.269397655387416
Validation loss: 3.2548022323130783

Epoch: 6| Step: 1
Training loss: 2.5258632845997453
Validation loss: 3.2515123917037285

Epoch: 6| Step: 2
Training loss: 3.9678124950006644
Validation loss: 3.250829754806268

Epoch: 6| Step: 3
Training loss: 3.5459137676961365
Validation loss: 3.249587328626044

Epoch: 6| Step: 4
Training loss: 3.829381246161655
Validation loss: 3.2494746131393613

Epoch: 6| Step: 5
Training loss: 3.8275534689748394
Validation loss: 3.247724515838859

Epoch: 6| Step: 6
Training loss: 4.046009810763432
Validation loss: 3.2491922928822534

Epoch: 6| Step: 7
Training loss: 4.127816365881536
Validation loss: 3.249395167483908

Epoch: 6| Step: 8
Training loss: 2.56936822955762
Validation loss: 3.246384847862194

Epoch: 6| Step: 9
Training loss: 3.424549468543271
Validation loss: 3.245427683490427

Epoch: 6| Step: 10
Training loss: 3.050619631502492
Validation loss: 3.244228751056672

Epoch: 6| Step: 11
Training loss: 2.4437164850692916
Validation loss: 3.242351443922997

Epoch: 6| Step: 12
Training loss: 4.308698000991148
Validation loss: 3.2429649356937764

Epoch: 6| Step: 13
Training loss: 3.21349016062772
Validation loss: 3.2428731166473774

Epoch: 26| Step: 0
Training loss: 3.5747856982896598
Validation loss: 3.2420800750801786

Epoch: 6| Step: 1
Training loss: 3.302289665506663
Validation loss: 3.2433411580913445

Epoch: 6| Step: 2
Training loss: 3.801038931318313
Validation loss: 3.2426123761618943

Epoch: 6| Step: 3
Training loss: 3.6983356650369337
Validation loss: 3.23827536949165

Epoch: 6| Step: 4
Training loss: 3.4495704272869254
Validation loss: 3.2369704067669485

Epoch: 6| Step: 5
Training loss: 3.141245614597889
Validation loss: 3.2369153694922113

Epoch: 6| Step: 6
Training loss: 3.1294987149751714
Validation loss: 3.238001906141796

Epoch: 6| Step: 7
Training loss: 2.4292755268322517
Validation loss: 3.23672874646974

Epoch: 6| Step: 8
Training loss: 4.250215861504539
Validation loss: 3.2394289258810747

Epoch: 6| Step: 9
Training loss: 3.230733839826306
Validation loss: 3.2401183931914286

Epoch: 6| Step: 10
Training loss: 3.3038487734049355
Validation loss: 3.235839223803066

Epoch: 6| Step: 11
Training loss: 3.8990446240986896
Validation loss: 3.235021665150967

Epoch: 6| Step: 12
Training loss: 3.768371466863115
Validation loss: 3.2362230642927208

Epoch: 6| Step: 13
Training loss: 3.6201469558055814
Validation loss: 3.2339764960301154

Epoch: 27| Step: 0
Training loss: 2.8560987369876347
Validation loss: 3.2335984959121187

Epoch: 6| Step: 1
Training loss: 3.5699855395967206
Validation loss: 3.2301085613129406

Epoch: 6| Step: 2
Training loss: 3.6062698548826533
Validation loss: 3.2278051077456316

Epoch: 6| Step: 3
Training loss: 2.9410298019191115
Validation loss: 3.227970380159161

Epoch: 6| Step: 4
Training loss: 3.386257188577439
Validation loss: 3.229427714254225

Epoch: 6| Step: 5
Training loss: 4.10592634298683
Validation loss: 3.231897419057583

Epoch: 6| Step: 6
Training loss: 3.9325460120126605
Validation loss: 3.2274557844241776

Epoch: 6| Step: 7
Training loss: 3.9487894883314225
Validation loss: 3.2272485795520653

Epoch: 6| Step: 8
Training loss: 3.2687415624330933
Validation loss: 3.227596570244596

Epoch: 6| Step: 9
Training loss: 3.870481255940647
Validation loss: 3.226495056949166

Epoch: 6| Step: 10
Training loss: 3.0092519511163984
Validation loss: 3.226041978728519

Epoch: 6| Step: 11
Training loss: 3.1053155057511934
Validation loss: 3.228670282282918

Epoch: 6| Step: 12
Training loss: 3.3215715960576278
Validation loss: 3.224532492118797

Epoch: 6| Step: 13
Training loss: 3.6088729443169174
Validation loss: 3.2223414976679425

Epoch: 28| Step: 0
Training loss: 3.4823120579116336
Validation loss: 3.224486751404598

Epoch: 6| Step: 1
Training loss: 4.208353527259846
Validation loss: 3.2221814112211646

Epoch: 6| Step: 2
Training loss: 2.973852009829539
Validation loss: 3.2198978603078814

Epoch: 6| Step: 3
Training loss: 3.682694099733829
Validation loss: 3.2175197558023543

Epoch: 6| Step: 4
Training loss: 3.2633612420431386
Validation loss: 3.216858965123213

Epoch: 6| Step: 5
Training loss: 3.427811998319802
Validation loss: 3.2196089302113657

Epoch: 6| Step: 6
Training loss: 3.6567927552713297
Validation loss: 3.2157573397390293

Epoch: 6| Step: 7
Training loss: 3.454913612533367
Validation loss: 3.21585148273133

Epoch: 6| Step: 8
Training loss: 3.1887906023563652
Validation loss: 3.220457924337117

Epoch: 6| Step: 9
Training loss: 3.385597826683342
Validation loss: 3.2258992447888906

Epoch: 6| Step: 10
Training loss: 3.7247909077582535
Validation loss: 3.2189657583222093

Epoch: 6| Step: 11
Training loss: 3.6093776422135893
Validation loss: 3.2181431689817463

Epoch: 6| Step: 12
Training loss: 2.5510722019231538
Validation loss: 3.2146683725101326

Epoch: 6| Step: 13
Training loss: 3.96240171196275
Validation loss: 3.22344710812605

Epoch: 29| Step: 0
Training loss: 3.761320827903725
Validation loss: 3.224501689636955

Epoch: 6| Step: 1
Training loss: 2.683393668055209
Validation loss: 3.229806773995294

Epoch: 6| Step: 2
Training loss: 3.401009965002081
Validation loss: 3.2316722193280185

Epoch: 6| Step: 3
Training loss: 3.354511093241848
Validation loss: 3.2343376814995985

Epoch: 6| Step: 4
Training loss: 3.9183598909785573
Validation loss: 3.231377619108682

Epoch: 6| Step: 5
Training loss: 3.772126596019344
Validation loss: 3.2340991965864805

Epoch: 6| Step: 6
Training loss: 3.3876026940351607
Validation loss: 3.226836740537482

Epoch: 6| Step: 7
Training loss: 3.200170726990166
Validation loss: 3.222611044289794

Epoch: 6| Step: 8
Training loss: 3.557776146771276
Validation loss: 3.2181061234991817

Epoch: 6| Step: 9
Training loss: 3.538013833406531
Validation loss: 3.2137255305994152

Epoch: 6| Step: 10
Training loss: 3.2096779387818843
Validation loss: 3.210330592901839

Epoch: 6| Step: 11
Training loss: 3.3657518056572675
Validation loss: 3.2086115075793145

Epoch: 6| Step: 12
Training loss: 3.927784878156168
Validation loss: 3.206919700802227

Epoch: 6| Step: 13
Training loss: 3.3330972269998047
Validation loss: 3.20489135029204

Epoch: 30| Step: 0
Training loss: 4.253985835960636
Validation loss: 3.207754164892583

Epoch: 6| Step: 1
Training loss: 3.262351553744214
Validation loss: 3.2075627944783527

Epoch: 6| Step: 2
Training loss: 2.7174949818611314
Validation loss: 3.207490727005167

Epoch: 6| Step: 3
Training loss: 2.807585597648371
Validation loss: 3.216109034537943

Epoch: 6| Step: 4
Training loss: 3.2048548051674026
Validation loss: 3.211702070593175

Epoch: 6| Step: 5
Training loss: 4.140215929085477
Validation loss: 3.216539964874911

Epoch: 6| Step: 6
Training loss: 3.5120819548948385
Validation loss: 3.2030554114825445

Epoch: 6| Step: 7
Training loss: 3.444194309490729
Validation loss: 3.2007510051920107

Epoch: 6| Step: 8
Training loss: 3.4273793441492835
Validation loss: 3.2039308060129663

Epoch: 6| Step: 9
Training loss: 3.351510427643997
Validation loss: 3.207817484171058

Epoch: 6| Step: 10
Training loss: 3.516841694843798
Validation loss: 3.2108377548408806

Epoch: 6| Step: 11
Training loss: 3.2615149519976896
Validation loss: 3.2173460596510806

Epoch: 6| Step: 12
Training loss: 3.8245227291565365
Validation loss: 3.2358157560503815

Epoch: 6| Step: 13
Training loss: 3.5391560051630724
Validation loss: 3.212034029400058

Epoch: 31| Step: 0
Training loss: 3.6301430359289855
Validation loss: 3.2126439630436736

Epoch: 6| Step: 1
Training loss: 3.2707144033268762
Validation loss: 3.209375224014755

Epoch: 6| Step: 2
Training loss: 2.9918556925810265
Validation loss: 3.2096978077308185

Epoch: 6| Step: 3
Training loss: 4.1990009482033575
Validation loss: 3.207698168379229

Epoch: 6| Step: 4
Training loss: 3.316552616120113
Validation loss: 3.2046455909857894

Epoch: 6| Step: 5
Training loss: 3.867172703570178
Validation loss: 3.206378399232269

Epoch: 6| Step: 6
Training loss: 3.144664387224234
Validation loss: 3.204169212869534

Epoch: 6| Step: 7
Training loss: 3.0993292236640033
Validation loss: 3.2051394759170098

Epoch: 6| Step: 8
Training loss: 3.9483606630675445
Validation loss: 3.2044045010486473

Epoch: 6| Step: 9
Training loss: 3.1028579581645244
Validation loss: 3.2021454960935647

Epoch: 6| Step: 10
Training loss: 3.4445548056967015
Validation loss: 3.200685505256205

Epoch: 6| Step: 11
Training loss: 3.254347900606005
Validation loss: 3.2021283215565357

Epoch: 6| Step: 12
Training loss: 3.872165627767586
Validation loss: 3.2003028184139235

Epoch: 6| Step: 13
Training loss: 2.743131295833807
Validation loss: 3.1994865844563867

Epoch: 32| Step: 0
Training loss: 3.9648208993337826
Validation loss: 3.19789866240997

Epoch: 6| Step: 1
Training loss: 3.909282392324327
Validation loss: 3.1971828084561955

Epoch: 6| Step: 2
Training loss: 3.5632343539225877
Validation loss: 3.195876607796974

Epoch: 6| Step: 3
Training loss: 3.3280116675337426
Validation loss: 3.195874735528507

Epoch: 6| Step: 4
Training loss: 3.8310732329321073
Validation loss: 3.1947938588566713

Epoch: 6| Step: 5
Training loss: 3.0954141475927237
Validation loss: 3.1955444996260827

Epoch: 6| Step: 6
Training loss: 3.3675412304229675
Validation loss: 3.1932338943205734

Epoch: 6| Step: 7
Training loss: 3.625218746556983
Validation loss: 3.1941050315429163

Epoch: 6| Step: 8
Training loss: 3.5681851182137114
Validation loss: 3.1949321729985103

Epoch: 6| Step: 9
Training loss: 3.459366900564635
Validation loss: 3.1920048028666814

Epoch: 6| Step: 10
Training loss: 2.9616424607071457
Validation loss: 3.193035048324835

Epoch: 6| Step: 11
Training loss: 3.046481219545744
Validation loss: 3.193857658842857

Epoch: 6| Step: 12
Training loss: 3.282204915922743
Validation loss: 3.1933300259684536

Epoch: 6| Step: 13
Training loss: 3.0414295539580483
Validation loss: 3.190581683276755

Epoch: 33| Step: 0
Training loss: 3.216053546194047
Validation loss: 3.190743750453361

Epoch: 6| Step: 1
Training loss: 3.1567038030430545
Validation loss: 3.191931232389723

Epoch: 6| Step: 2
Training loss: 2.87141443654413
Validation loss: 3.1920538505155553

Epoch: 6| Step: 3
Training loss: 3.9066816167794904
Validation loss: 3.1953782264064663

Epoch: 6| Step: 4
Training loss: 3.2108032495505263
Validation loss: 3.1921866311759217

Epoch: 6| Step: 5
Training loss: 3.4023029662183215
Validation loss: 3.194812510792169

Epoch: 6| Step: 6
Training loss: 3.3211585548914275
Validation loss: 3.193904935449513

Epoch: 6| Step: 7
Training loss: 3.087239669141228
Validation loss: 3.1900334738590996

Epoch: 6| Step: 8
Training loss: 3.544401406997145
Validation loss: 3.1905460397029146

Epoch: 6| Step: 9
Training loss: 4.083542072384414
Validation loss: 3.1904050620915703

Epoch: 6| Step: 10
Training loss: 4.029095687688104
Validation loss: 3.1889867457999963

Epoch: 6| Step: 11
Training loss: 3.100347093408958
Validation loss: 3.1865776701293966

Epoch: 6| Step: 12
Training loss: 3.2205799419287073
Validation loss: 3.187449609887788

Epoch: 6| Step: 13
Training loss: 4.203938572080028
Validation loss: 3.1865560077600694

Epoch: 34| Step: 0
Training loss: 3.908244363928478
Validation loss: 3.184425552245296

Epoch: 6| Step: 1
Training loss: 3.317237201736995
Validation loss: 3.18521843039619

Epoch: 6| Step: 2
Training loss: 3.6930647419332296
Validation loss: 3.1855413639129098

Epoch: 6| Step: 3
Training loss: 3.827816324050691
Validation loss: 3.18311143305848

Epoch: 6| Step: 4
Training loss: 3.371247925664018
Validation loss: 3.1822017563460165

Epoch: 6| Step: 5
Training loss: 3.6334972105486667
Validation loss: 3.181417303837278

Epoch: 6| Step: 6
Training loss: 3.335656326201169
Validation loss: 3.181334741963718

Epoch: 6| Step: 7
Training loss: 3.960995525108146
Validation loss: 3.181204981660336

Epoch: 6| Step: 8
Training loss: 2.8042136299391363
Validation loss: 3.185098261590566

Epoch: 6| Step: 9
Training loss: 3.4255869341626495
Validation loss: 3.182252774146014

Epoch: 6| Step: 10
Training loss: 2.9343839310092723
Validation loss: 3.182415279979518

Epoch: 6| Step: 11
Training loss: 3.1736506861457423
Validation loss: 3.1803509565106816

Epoch: 6| Step: 12
Training loss: 3.032365259509091
Validation loss: 3.183472936831582

Epoch: 6| Step: 13
Training loss: 3.6253081881301266
Validation loss: 3.1875870459725424

Epoch: 35| Step: 0
Training loss: 3.658931824571591
Validation loss: 3.1858945708751727

Epoch: 6| Step: 1
Training loss: 3.679425467133215
Validation loss: 3.1804687172418236

Epoch: 6| Step: 2
Training loss: 3.3654982008996512
Validation loss: 3.1791721077570867

Epoch: 6| Step: 3
Training loss: 3.1283962867620154
Validation loss: 3.179917056851097

Epoch: 6| Step: 4
Training loss: 2.7523524019753403
Validation loss: 3.186649391585558

Epoch: 6| Step: 5
Training loss: 3.8057215732519416
Validation loss: 3.1880228722446207

Epoch: 6| Step: 6
Training loss: 3.3773820735919866
Validation loss: 3.1875992111475475

Epoch: 6| Step: 7
Training loss: 3.185857611492253
Validation loss: 3.18886643199434

Epoch: 6| Step: 8
Training loss: 3.816379012105334
Validation loss: 3.1906665079172583

Epoch: 6| Step: 9
Training loss: 2.776748185611653
Validation loss: 3.189452485185565

Epoch: 6| Step: 10
Training loss: 3.308531489231193
Validation loss: 3.18494099588413

Epoch: 6| Step: 11
Training loss: 3.9731955073174636
Validation loss: 3.1893574536332965

Epoch: 6| Step: 12
Training loss: 3.539480424671924
Validation loss: 3.1830308110600845

Epoch: 6| Step: 13
Training loss: 3.80087132753935
Validation loss: 3.182489483684336

Epoch: 36| Step: 0
Training loss: 3.1471886820370014
Validation loss: 3.180248100521416

Epoch: 6| Step: 1
Training loss: 3.337577470316057
Validation loss: 3.18043048409309

Epoch: 6| Step: 2
Training loss: 3.4353607456952706
Validation loss: 3.1825105792445245

Epoch: 6| Step: 3
Training loss: 3.2642999178311185
Validation loss: 3.1851775627901424

Epoch: 6| Step: 4
Training loss: 2.855076461543075
Validation loss: 3.200308968961232

Epoch: 6| Step: 5
Training loss: 3.6099545232386343
Validation loss: 3.2101327420423007

Epoch: 6| Step: 6
Training loss: 3.827983744603704
Validation loss: 3.1886033013238144

Epoch: 6| Step: 7
Training loss: 3.1964446582678607
Validation loss: 3.176038886228093

Epoch: 6| Step: 8
Training loss: 3.419767941638468
Validation loss: 3.174956507566991

Epoch: 6| Step: 9
Training loss: 2.9082041087766974
Validation loss: 3.175196942987767

Epoch: 6| Step: 10
Training loss: 3.9941929149236115
Validation loss: 3.1766909680628532

Epoch: 6| Step: 11
Training loss: 3.590580612452739
Validation loss: 3.177620795326306

Epoch: 6| Step: 12
Training loss: 3.812149406947623
Validation loss: 3.1806868144120575

Epoch: 6| Step: 13
Training loss: 3.801792178916081
Validation loss: 3.1823748492481845

Epoch: 37| Step: 0
Training loss: 3.0849598555217317
Validation loss: 3.1838101692253233

Epoch: 6| Step: 1
Training loss: 3.2994632053164805
Validation loss: 3.1851810961492495

Epoch: 6| Step: 2
Training loss: 2.4369482736463106
Validation loss: 3.183917076974759

Epoch: 6| Step: 3
Training loss: 3.658163499184745
Validation loss: 3.178698549586262

Epoch: 6| Step: 4
Training loss: 3.487647465695279
Validation loss: 3.184389917050765

Epoch: 6| Step: 5
Training loss: 3.197367932751515
Validation loss: 3.1768522509707315

Epoch: 6| Step: 6
Training loss: 3.765970554562857
Validation loss: 3.175390287399953

Epoch: 6| Step: 7
Training loss: 3.691846710246514
Validation loss: 3.1754910571922004

Epoch: 6| Step: 8
Training loss: 3.143029047240397
Validation loss: 3.1736898249049923

Epoch: 6| Step: 9
Training loss: 3.5658406438988077
Validation loss: 3.173034394649447

Epoch: 6| Step: 10
Training loss: 2.8709195246351213
Validation loss: 3.170692346624624

Epoch: 6| Step: 11
Training loss: 4.071825562628584
Validation loss: 3.1729006137365996

Epoch: 6| Step: 12
Training loss: 3.350990086471661
Validation loss: 3.1703376497602056

Epoch: 6| Step: 13
Training loss: 4.629772095642806
Validation loss: 3.1722046903893895

Epoch: 38| Step: 0
Training loss: 2.9629366524729117
Validation loss: 3.1705705712641534

Epoch: 6| Step: 1
Training loss: 3.244834021980199
Validation loss: 3.171322222222782

Epoch: 6| Step: 2
Training loss: 3.7740538668283046
Validation loss: 3.169459295702828

Epoch: 6| Step: 3
Training loss: 3.294676278033788
Validation loss: 3.1670400958467164

Epoch: 6| Step: 4
Training loss: 2.689370147821268
Validation loss: 3.169900461126504

Epoch: 6| Step: 5
Training loss: 3.964171644850155
Validation loss: 3.166473802696092

Epoch: 6| Step: 6
Training loss: 3.399244050528186
Validation loss: 3.1671917231245192

Epoch: 6| Step: 7
Training loss: 3.7857734798934355
Validation loss: 3.1653180599604913

Epoch: 6| Step: 8
Training loss: 3.553747300111092
Validation loss: 3.1669425865735925

Epoch: 6| Step: 9
Training loss: 3.8217573495568242
Validation loss: 3.167292226024425

Epoch: 6| Step: 10
Training loss: 3.4127448919826846
Validation loss: 3.165181800058275

Epoch: 6| Step: 11
Training loss: 3.0685651237908105
Validation loss: 3.1645588827649163

Epoch: 6| Step: 12
Training loss: 3.5063992990404733
Validation loss: 3.164036789453776

Epoch: 6| Step: 13
Training loss: 3.2841503585517646
Validation loss: 3.165441478980519

Epoch: 39| Step: 0
Training loss: 3.2330334226070625
Validation loss: 3.1685938521820645

Epoch: 6| Step: 1
Training loss: 2.615105281774641
Validation loss: 3.168661634421747

Epoch: 6| Step: 2
Training loss: 2.2146225268776516
Validation loss: 3.1695043827118576

Epoch: 6| Step: 3
Training loss: 3.8642818748066223
Validation loss: 3.1731248817019746

Epoch: 6| Step: 4
Training loss: 3.9454745722047875
Validation loss: 3.164342709693182

Epoch: 6| Step: 5
Training loss: 3.340053333153611
Validation loss: 3.162601901829196

Epoch: 6| Step: 6
Training loss: 3.7785266495497187
Validation loss: 3.1615202609591573

Epoch: 6| Step: 7
Training loss: 4.228081224078169
Validation loss: 3.1623629521708163

Epoch: 6| Step: 8
Training loss: 3.2341231833207247
Validation loss: 3.1621818249155744

Epoch: 6| Step: 9
Training loss: 3.617954774227015
Validation loss: 3.1622178968374812

Epoch: 6| Step: 10
Training loss: 3.165524293402915
Validation loss: 3.1635169009145083

Epoch: 6| Step: 11
Training loss: 3.519808166651884
Validation loss: 3.1606383550221775

Epoch: 6| Step: 12
Training loss: 3.0663913216197125
Validation loss: 3.161438940764201

Epoch: 6| Step: 13
Training loss: 3.8522988132075415
Validation loss: 3.1606682574399723

Epoch: 40| Step: 0
Training loss: 3.226233218480849
Validation loss: 3.160654903343575

Epoch: 6| Step: 1
Training loss: 3.628303863821587
Validation loss: 3.161758174821879

Epoch: 6| Step: 2
Training loss: 2.760410543950806
Validation loss: 3.16045338055071

Epoch: 6| Step: 3
Training loss: 3.491135406744152
Validation loss: 3.1634022645591093

Epoch: 6| Step: 4
Training loss: 3.3923619475418425
Validation loss: 3.161585004072131

Epoch: 6| Step: 5
Training loss: 4.000631282582749
Validation loss: 3.1643277766912834

Epoch: 6| Step: 6
Training loss: 3.5620258751967664
Validation loss: 3.161600752788154

Epoch: 6| Step: 7
Training loss: 3.327933722358755
Validation loss: 3.1619638685938813

Epoch: 6| Step: 8
Training loss: 2.8480192562695272
Validation loss: 3.161676495864406

Epoch: 6| Step: 9
Training loss: 3.716140729245283
Validation loss: 3.162502023220489

Epoch: 6| Step: 10
Training loss: 3.5133247140372106
Validation loss: 3.1583819779734905

Epoch: 6| Step: 11
Training loss: 3.398992804398177
Validation loss: 3.156130848262758

Epoch: 6| Step: 12
Training loss: 3.3539752945100956
Validation loss: 3.1559529992746462

Epoch: 6| Step: 13
Training loss: 3.6565095206206766
Validation loss: 3.153168888132758

Epoch: 41| Step: 0
Training loss: 2.6853449853090594
Validation loss: 3.155017181121405

Epoch: 6| Step: 1
Training loss: 3.2584925977673462
Validation loss: 3.1539177763328

Epoch: 6| Step: 2
Training loss: 3.954351664571219
Validation loss: 3.1542101652402756

Epoch: 6| Step: 3
Training loss: 2.7049430951181113
Validation loss: 3.1539021924643613

Epoch: 6| Step: 4
Training loss: 3.892161115865512
Validation loss: 3.1552865072509015

Epoch: 6| Step: 5
Training loss: 3.786215304306717
Validation loss: 3.152385654819758

Epoch: 6| Step: 6
Training loss: 3.964585890629649
Validation loss: 3.153599443552839

Epoch: 6| Step: 7
Training loss: 3.419487804183039
Validation loss: 3.1565151698177147

Epoch: 6| Step: 8
Training loss: 3.382152889511322
Validation loss: 3.1532776672556615

Epoch: 6| Step: 9
Training loss: 3.0124656453686516
Validation loss: 3.153381081830349

Epoch: 6| Step: 10
Training loss: 2.685528764143477
Validation loss: 3.1510816633424628

Epoch: 6| Step: 11
Training loss: 3.7651137642054944
Validation loss: 3.1536730717725536

Epoch: 6| Step: 12
Training loss: 2.893976526477577
Validation loss: 3.15160035919858

Epoch: 6| Step: 13
Training loss: 4.376744385780032
Validation loss: 3.1533182848842913

Epoch: 42| Step: 0
Training loss: 3.862724302624501
Validation loss: 3.156833542347967

Epoch: 6| Step: 1
Training loss: 4.169913641678055
Validation loss: 3.1510013104163654

Epoch: 6| Step: 2
Training loss: 3.872559301760826
Validation loss: 3.1489048950362974

Epoch: 6| Step: 3
Training loss: 3.457437575432519
Validation loss: 3.147721614115246

Epoch: 6| Step: 4
Training loss: 3.8925827799614665
Validation loss: 3.1470371467414617

Epoch: 6| Step: 5
Training loss: 3.59747625474337
Validation loss: 3.147184922742661

Epoch: 6| Step: 6
Training loss: 2.6006643216864838
Validation loss: 3.1476684060877274

Epoch: 6| Step: 7
Training loss: 2.7587977910536696
Validation loss: 3.1481347019482926

Epoch: 6| Step: 8
Training loss: 3.4143893087646933
Validation loss: 3.1490932612126485

Epoch: 6| Step: 9
Training loss: 2.583264678124817
Validation loss: 3.1497550667944885

Epoch: 6| Step: 10
Training loss: 3.4249514332690127
Validation loss: 3.1493327178714132

Epoch: 6| Step: 11
Training loss: 2.9574775711718213
Validation loss: 3.1463872129519554

Epoch: 6| Step: 12
Training loss: 3.0153849609979644
Validation loss: 3.146967104900679

Epoch: 6| Step: 13
Training loss: 4.00991831403757
Validation loss: 3.144841601287445

Epoch: 43| Step: 0
Training loss: 2.899029036461699
Validation loss: 3.146522222981434

Epoch: 6| Step: 1
Training loss: 3.7461031693866196
Validation loss: 3.144358638835225

Epoch: 6| Step: 2
Training loss: 3.6887931495968562
Validation loss: 3.1433570849992445

Epoch: 6| Step: 3
Training loss: 2.9748105477668627
Validation loss: 3.140128949369723

Epoch: 6| Step: 4
Training loss: 4.430442032643499
Validation loss: 3.1428613954346694

Epoch: 6| Step: 5
Training loss: 3.872179050530235
Validation loss: 3.14162060123462

Epoch: 6| Step: 6
Training loss: 3.1373291941803383
Validation loss: 3.140010554257582

Epoch: 6| Step: 7
Training loss: 3.504874785576974
Validation loss: 3.141341515666933

Epoch: 6| Step: 8
Training loss: 2.9011720985298486
Validation loss: 3.1441016746885944

Epoch: 6| Step: 9
Training loss: 3.4670903815016096
Validation loss: 3.142145650613955

Epoch: 6| Step: 10
Training loss: 2.928815951091193
Validation loss: 3.1442438021617427

Epoch: 6| Step: 11
Training loss: 3.3915578376374533
Validation loss: 3.1436409539530166

Epoch: 6| Step: 12
Training loss: 3.5083298333543973
Validation loss: 3.1433729601090747

Epoch: 6| Step: 13
Training loss: 2.4568171809692245
Validation loss: 3.1384901042143007

Epoch: 44| Step: 0
Training loss: 2.797263347580591
Validation loss: 3.140542400810368

Epoch: 6| Step: 1
Training loss: 2.862887866799224
Validation loss: 3.1410684947401317

Epoch: 6| Step: 2
Training loss: 3.4101498178812477
Validation loss: 3.139315231698397

Epoch: 6| Step: 3
Training loss: 4.385646617717069
Validation loss: 3.143798933625072

Epoch: 6| Step: 4
Training loss: 2.087577717870502
Validation loss: 3.141199242185801

Epoch: 6| Step: 5
Training loss: 3.9154419438346357
Validation loss: 3.143335733196706

Epoch: 6| Step: 6
Training loss: 3.595441867800319
Validation loss: 3.1423585495165667

Epoch: 6| Step: 7
Training loss: 2.8957645398940524
Validation loss: 3.1429876816262734

Epoch: 6| Step: 8
Training loss: 3.5769080878764847
Validation loss: 3.1403337054890867

Epoch: 6| Step: 9
Training loss: 3.626657567386806
Validation loss: 3.1408311366754336

Epoch: 6| Step: 10
Training loss: 3.562654859958242
Validation loss: 3.1387376341980455

Epoch: 6| Step: 11
Training loss: 3.3400613278908917
Validation loss: 3.1385898010793545

Epoch: 6| Step: 12
Training loss: 3.714203948913023
Validation loss: 3.1384947307861153

Epoch: 6| Step: 13
Training loss: 3.2694236163398975
Validation loss: 3.137618014117166

Epoch: 45| Step: 0
Training loss: 3.3931771091655443
Validation loss: 3.1404807038683247

Epoch: 6| Step: 1
Training loss: 3.386604843952065
Validation loss: 3.1395763756069806

Epoch: 6| Step: 2
Training loss: 2.741302695265799
Validation loss: 3.140977870998201

Epoch: 6| Step: 3
Training loss: 4.371804078231034
Validation loss: 3.1399846794293382

Epoch: 6| Step: 4
Training loss: 3.4051483892744696
Validation loss: 3.1401225217472573

Epoch: 6| Step: 5
Training loss: 3.392054102808054
Validation loss: 3.141172814011756

Epoch: 6| Step: 6
Training loss: 3.429327665669379
Validation loss: 3.1371854655738884

Epoch: 6| Step: 7
Training loss: 2.897363180858491
Validation loss: 3.1401906058718714

Epoch: 6| Step: 8
Training loss: 3.3318857069528627
Validation loss: 3.136701835110946

Epoch: 6| Step: 9
Training loss: 3.216886851494753
Validation loss: 3.1353400768905866

Epoch: 6| Step: 10
Training loss: 3.5713452738176037
Validation loss: 3.1336318462511024

Epoch: 6| Step: 11
Training loss: 3.831583134914755
Validation loss: 3.1350420405512986

Epoch: 6| Step: 12
Training loss: 3.305616171643489
Validation loss: 3.138076491031019

Epoch: 6| Step: 13
Training loss: 2.930320895072023
Validation loss: 3.1356302867971735

Epoch: 46| Step: 0
Training loss: 3.2868383865943036
Validation loss: 3.1353972209577745

Epoch: 6| Step: 1
Training loss: 3.618074839697805
Validation loss: 3.1334618688238582

Epoch: 6| Step: 2
Training loss: 3.0866350761702983
Validation loss: 3.1326817118579022

Epoch: 6| Step: 3
Training loss: 2.760199273144209
Validation loss: 3.1354458884224985

Epoch: 6| Step: 4
Training loss: 3.7828801952230964
Validation loss: 3.137189737780382

Epoch: 6| Step: 5
Training loss: 4.1721607353284
Validation loss: 3.136914318920111

Epoch: 6| Step: 6
Training loss: 3.794753372762875
Validation loss: 3.1443458440815197

Epoch: 6| Step: 7
Training loss: 3.521795122650563
Validation loss: 3.1355015523093717

Epoch: 6| Step: 8
Training loss: 2.1884969346929415
Validation loss: 3.1341511773291963

Epoch: 6| Step: 9
Training loss: 3.2919233841723505
Validation loss: 3.1339622369974425

Epoch: 6| Step: 10
Training loss: 3.0766563978536996
Validation loss: 3.1307039834697172

Epoch: 6| Step: 11
Training loss: 3.742821880557187
Validation loss: 3.1328876486245867

Epoch: 6| Step: 12
Training loss: 3.621404772325846
Validation loss: 3.1311950427912802

Epoch: 6| Step: 13
Training loss: 3.001300688748094
Validation loss: 3.132061025903565

Epoch: 47| Step: 0
Training loss: 3.678131227966066
Validation loss: 3.1326003795707997

Epoch: 6| Step: 1
Training loss: 3.2123254157099366
Validation loss: 3.1326459774358444

Epoch: 6| Step: 2
Training loss: 3.087405394058374
Validation loss: 3.1306404155575978

Epoch: 6| Step: 3
Training loss: 3.307014241435044
Validation loss: 3.1309852822732767

Epoch: 6| Step: 4
Training loss: 3.9457103566412295
Validation loss: 3.130962006250983

Epoch: 6| Step: 5
Training loss: 3.558961683863977
Validation loss: 3.1307058930747678

Epoch: 6| Step: 6
Training loss: 3.432839025326371
Validation loss: 3.1276234630128013

Epoch: 6| Step: 7
Training loss: 3.265234818945119
Validation loss: 3.1293808106312406

Epoch: 6| Step: 8
Training loss: 3.1899468996896103
Validation loss: 3.1281958688661824

Epoch: 6| Step: 9
Training loss: 3.130741033857886
Validation loss: 3.1307345550257253

Epoch: 6| Step: 10
Training loss: 3.846659357889285
Validation loss: 3.135573487098535

Epoch: 6| Step: 11
Training loss: 3.382258768551189
Validation loss: 3.1313201244082576

Epoch: 6| Step: 12
Training loss: 3.2353673324868457
Validation loss: 3.127624940070187

Epoch: 6| Step: 13
Training loss: 3.010801895643347
Validation loss: 3.129063298947091

Epoch: 48| Step: 0
Training loss: 3.885203187752171
Validation loss: 3.1293468842312393

Epoch: 6| Step: 1
Training loss: 3.159773568841232
Validation loss: 3.1282047828474777

Epoch: 6| Step: 2
Training loss: 3.6603032004252007
Validation loss: 3.130712149234099

Epoch: 6| Step: 3
Training loss: 3.628358929014773
Validation loss: 3.1277821681020255

Epoch: 6| Step: 4
Training loss: 3.7257955789640453
Validation loss: 3.127928205668939

Epoch: 6| Step: 5
Training loss: 3.645079674706842
Validation loss: 3.128231205846616

Epoch: 6| Step: 6
Training loss: 3.7758007034062673
Validation loss: 3.128903919793819

Epoch: 6| Step: 7
Training loss: 2.899028871980017
Validation loss: 3.127920753883959

Epoch: 6| Step: 8
Training loss: 3.221128899426217
Validation loss: 3.127337502382446

Epoch: 6| Step: 9
Training loss: 3.2090493101026683
Validation loss: 3.1278724094649744

Epoch: 6| Step: 10
Training loss: 2.5233479297909502
Validation loss: 3.127726442241705

Epoch: 6| Step: 11
Training loss: 3.043448531556497
Validation loss: 3.1256003822391163

Epoch: 6| Step: 12
Training loss: 3.6751474934777675
Validation loss: 3.125047803943841

Epoch: 6| Step: 13
Training loss: 3.0632153668137483
Validation loss: 3.1266722882792672

Epoch: 49| Step: 0
Training loss: 3.519135345986855
Validation loss: 3.1230418824156962

Epoch: 6| Step: 1
Training loss: 4.155051610743175
Validation loss: 3.1267564919298527

Epoch: 6| Step: 2
Training loss: 3.3577087528324516
Validation loss: 3.1275245592369103

Epoch: 6| Step: 3
Training loss: 3.8926094846328363
Validation loss: 3.1255957086937247

Epoch: 6| Step: 4
Training loss: 2.8186292195294254
Validation loss: 3.1234646887559445

Epoch: 6| Step: 5
Training loss: 3.4933479309747697
Validation loss: 3.123628623061931

Epoch: 6| Step: 6
Training loss: 3.5969214998979644
Validation loss: 3.124217027589966

Epoch: 6| Step: 7
Training loss: 3.8233615432758365
Validation loss: 3.1302193966388274

Epoch: 6| Step: 8
Training loss: 2.6911085874946594
Validation loss: 3.1226684010167225

Epoch: 6| Step: 9
Training loss: 3.30178871806003
Validation loss: 3.1213567649818024

Epoch: 6| Step: 10
Training loss: 3.0417324390006346
Validation loss: 3.1216293336022267

Epoch: 6| Step: 11
Training loss: 2.9150668706797567
Validation loss: 3.1246329561661237

Epoch: 6| Step: 12
Training loss: 3.0789412757102825
Validation loss: 3.1235475360040166

Epoch: 6| Step: 13
Training loss: 3.5092877724491105
Validation loss: 3.1246168529293223

Epoch: 50| Step: 0
Training loss: 3.2333459368850095
Validation loss: 3.126589110575973

Epoch: 6| Step: 1
Training loss: 3.336239660367812
Validation loss: 3.1262387943857104

Epoch: 6| Step: 2
Training loss: 3.6973047027699124
Validation loss: 3.1240660192567105

Epoch: 6| Step: 3
Training loss: 3.44161241933514
Validation loss: 3.1262017972454044

Epoch: 6| Step: 4
Training loss: 3.1742466671143443
Validation loss: 3.1240502766297737

Epoch: 6| Step: 5
Training loss: 2.989207883291366
Validation loss: 3.1218652864690792

Epoch: 6| Step: 6
Training loss: 2.6232570129434576
Validation loss: 3.1229092107165264

Epoch: 6| Step: 7
Training loss: 3.8734789908811758
Validation loss: 3.1229943908998496

Epoch: 6| Step: 8
Training loss: 3.5665513141790575
Validation loss: 3.1227921051047907

Epoch: 6| Step: 9
Training loss: 3.4656985496098156
Validation loss: 3.1212438967990632

Epoch: 6| Step: 10
Training loss: 3.850167476429774
Validation loss: 3.120236524780427

Epoch: 6| Step: 11
Training loss: 2.287741009465801
Validation loss: 3.121837311727965

Epoch: 6| Step: 12
Training loss: 3.6003525826198253
Validation loss: 3.1206378459280115

Epoch: 6| Step: 13
Training loss: 4.2651715718828545
Validation loss: 3.1194784117512873

Epoch: 51| Step: 0
Training loss: 3.849316543752138
Validation loss: 3.12040522292173

Epoch: 6| Step: 1
Training loss: 3.5644545965322303
Validation loss: 3.12627069459619

Epoch: 6| Step: 2
Training loss: 2.7981610458196085
Validation loss: 3.123646148778065

Epoch: 6| Step: 3
Training loss: 3.225261139462138
Validation loss: 3.126832937218844

Epoch: 6| Step: 4
Training loss: 2.6259569512795036
Validation loss: 3.1274231324861117

Epoch: 6| Step: 5
Training loss: 3.739541410390046
Validation loss: 3.127164431587463

Epoch: 6| Step: 6
Training loss: 3.182631720538696
Validation loss: 3.1306346522258175

Epoch: 6| Step: 7
Training loss: 4.085143382288732
Validation loss: 3.1214428400387897

Epoch: 6| Step: 8
Training loss: 2.927180079335385
Validation loss: 3.115369914660322

Epoch: 6| Step: 9
Training loss: 4.403102535193202
Validation loss: 3.1144711657423945

Epoch: 6| Step: 10
Training loss: 3.248362642263307
Validation loss: 3.11425644764283

Epoch: 6| Step: 11
Training loss: 3.2168729179024282
Validation loss: 3.1153432492661794

Epoch: 6| Step: 12
Training loss: 2.9362312986022747
Validation loss: 3.112568319972482

Epoch: 6| Step: 13
Training loss: 2.8472759479529737
Validation loss: 3.115995197328194

Epoch: 52| Step: 0
Training loss: 2.9232345926564998
Validation loss: 3.1158761600011515

Epoch: 6| Step: 1
Training loss: 3.837228468443176
Validation loss: 3.1132295054333943

Epoch: 6| Step: 2
Training loss: 3.6074229324578853
Validation loss: 3.116252780307566

Epoch: 6| Step: 3
Training loss: 3.0018967354515946
Validation loss: 3.1130095760769145

Epoch: 6| Step: 4
Training loss: 2.888953968276884
Validation loss: 3.113722111964984

Epoch: 6| Step: 5
Training loss: 2.7543132941092474
Validation loss: 3.1155587548134895

Epoch: 6| Step: 6
Training loss: 3.076204581919378
Validation loss: 3.1148215724858916

Epoch: 6| Step: 7
Training loss: 3.3843607189831713
Validation loss: 3.1137433243307564

Epoch: 6| Step: 8
Training loss: 3.3116448216196956
Validation loss: 3.1118807751322755

Epoch: 6| Step: 9
Training loss: 3.776458478701629
Validation loss: 3.112534089240903

Epoch: 6| Step: 10
Training loss: 3.161983155246096
Validation loss: 3.113332328367597

Epoch: 6| Step: 11
Training loss: 3.7768834651212693
Validation loss: 3.1115117107826946

Epoch: 6| Step: 12
Training loss: 4.013581821146067
Validation loss: 3.112235092175263

Epoch: 6| Step: 13
Training loss: 3.602540915559296
Validation loss: 3.1148179757739176

Epoch: 53| Step: 0
Training loss: 3.0855330962769165
Validation loss: 3.1149932616804907

Epoch: 6| Step: 1
Training loss: 3.6025288706568355
Validation loss: 3.1317328388165975

Epoch: 6| Step: 2
Training loss: 3.44490820486962
Validation loss: 3.123242228016007

Epoch: 6| Step: 3
Training loss: 2.955907247727088
Validation loss: 3.12508373517477

Epoch: 6| Step: 4
Training loss: 3.8045669317234867
Validation loss: 3.1242080882810797

Epoch: 6| Step: 5
Training loss: 2.9175474381042834
Validation loss: 3.1183468060003943

Epoch: 6| Step: 6
Training loss: 3.758491819526323
Validation loss: 3.122113837268734

Epoch: 6| Step: 7
Training loss: 3.8641084994529376
Validation loss: 3.110828774017762

Epoch: 6| Step: 8
Training loss: 2.9331450951028284
Validation loss: 3.1164205095193713

Epoch: 6| Step: 9
Training loss: 3.306415079246635
Validation loss: 3.1170411516721694

Epoch: 6| Step: 10
Training loss: 3.6487012355325503
Validation loss: 3.1154007272083915

Epoch: 6| Step: 11
Training loss: 3.765669319873393
Validation loss: 3.115127794647313

Epoch: 6| Step: 12
Training loss: 2.483507208742847
Validation loss: 3.111757047558091

Epoch: 6| Step: 13
Training loss: 3.628236312538645
Validation loss: 3.1119522854891755

Epoch: 54| Step: 0
Training loss: 4.033386374090659
Validation loss: 3.11288675645725

Epoch: 6| Step: 1
Training loss: 3.273948174385106
Validation loss: 3.1152032431498204

Epoch: 6| Step: 2
Training loss: 2.9736098816336707
Validation loss: 3.113957271003338

Epoch: 6| Step: 3
Training loss: 3.6354925954735715
Validation loss: 3.1114771874666403

Epoch: 6| Step: 4
Training loss: 2.7492036533401927
Validation loss: 3.112504712779225

Epoch: 6| Step: 5
Training loss: 3.4500750713197097
Validation loss: 3.1120512376779743

Epoch: 6| Step: 6
Training loss: 3.160722792570106
Validation loss: 3.1090517593871496

Epoch: 6| Step: 7
Training loss: 3.265207364330798
Validation loss: 3.1115618220938557

Epoch: 6| Step: 8
Training loss: 3.9155942923277145
Validation loss: 3.1098539268336696

Epoch: 6| Step: 9
Training loss: 3.7708187770386923
Validation loss: 3.1115877355399397

Epoch: 6| Step: 10
Training loss: 3.4301985444640604
Validation loss: 3.1084185249600926

Epoch: 6| Step: 11
Training loss: 3.3879321959285114
Validation loss: 3.107065526372876

Epoch: 6| Step: 12
Training loss: 2.961427673188287
Validation loss: 3.1080087904751497

Epoch: 6| Step: 13
Training loss: 2.759767698380325
Validation loss: 3.10655005832126

Epoch: 55| Step: 0
Training loss: 3.909949420104234
Validation loss: 3.107008838166109

Epoch: 6| Step: 1
Training loss: 3.1207588407609292
Validation loss: 3.109789689529553

Epoch: 6| Step: 2
Training loss: 3.1894133565914755
Validation loss: 3.1067426214510294

Epoch: 6| Step: 3
Training loss: 2.8788509285941473
Validation loss: 3.1080844720034975

Epoch: 6| Step: 4
Training loss: 3.9183692613320473
Validation loss: 3.104367468456777

Epoch: 6| Step: 5
Training loss: 3.3413119831037355
Validation loss: 3.1056354593789597

Epoch: 6| Step: 6
Training loss: 3.535445699907873
Validation loss: 3.107172173704367

Epoch: 6| Step: 7
Training loss: 3.596092058040893
Validation loss: 3.1060316340714613

Epoch: 6| Step: 8
Training loss: 3.311480095235751
Validation loss: 3.1035299816124913

Epoch: 6| Step: 9
Training loss: 3.2682652363806817
Validation loss: 3.103491664673613

Epoch: 6| Step: 10
Training loss: 3.061859375259142
Validation loss: 3.1034604645919024

Epoch: 6| Step: 11
Training loss: 3.3070384652040796
Validation loss: 3.104776483729115

Epoch: 6| Step: 12
Training loss: 3.0917826861250544
Validation loss: 3.1010079803952464

Epoch: 6| Step: 13
Training loss: 3.688011263302631
Validation loss: 3.1041376713083126

Epoch: 56| Step: 0
Training loss: 3.2239518584071862
Validation loss: 3.1028445254646613

Epoch: 6| Step: 1
Training loss: 2.8273327808531
Validation loss: 3.101921169291

Epoch: 6| Step: 2
Training loss: 3.9992353185246015
Validation loss: 3.10140935370381

Epoch: 6| Step: 3
Training loss: 3.2977237422482784
Validation loss: 3.102564265497884

Epoch: 6| Step: 4
Training loss: 3.302232773023647
Validation loss: 3.1004443901708623

Epoch: 6| Step: 5
Training loss: 3.5008445810635065
Validation loss: 3.1022553347209922

Epoch: 6| Step: 6
Training loss: 3.5411698086347716
Validation loss: 3.104712530288163

Epoch: 6| Step: 7
Training loss: 3.1802438160257647
Validation loss: 3.1001223138766703

Epoch: 6| Step: 8
Training loss: 3.5975629398865716
Validation loss: 3.1030156868254934

Epoch: 6| Step: 9
Training loss: 2.526743515409424
Validation loss: 3.1016046941640663

Epoch: 6| Step: 10
Training loss: 3.4623648496616948
Validation loss: 3.1067851363951866

Epoch: 6| Step: 11
Training loss: 3.46227643224248
Validation loss: 3.1073948072714055

Epoch: 6| Step: 12
Training loss: 3.66845803861834
Validation loss: 3.1038650979555555

Epoch: 6| Step: 13
Training loss: 3.3931931293454416
Validation loss: 3.0989203729507997

Epoch: 57| Step: 0
Training loss: 2.934779916599286
Validation loss: 3.0991273685859184

Epoch: 6| Step: 1
Training loss: 3.383436326086345
Validation loss: 3.100835567286305

Epoch: 6| Step: 2
Training loss: 3.168805671518861
Validation loss: 3.1023877311356443

Epoch: 6| Step: 3
Training loss: 2.47225413736419
Validation loss: 3.1019525294858195

Epoch: 6| Step: 4
Training loss: 3.7445123574512316
Validation loss: 3.1041596453804003

Epoch: 6| Step: 5
Training loss: 3.4399653523940303
Validation loss: 3.1044705039824296

Epoch: 6| Step: 6
Training loss: 3.9056807446542017
Validation loss: 3.105040456500262

Epoch: 6| Step: 7
Training loss: 3.284696385768354
Validation loss: 3.1046228981312565

Epoch: 6| Step: 8
Training loss: 3.050372341754338
Validation loss: 3.1066606719699323

Epoch: 6| Step: 9
Training loss: 2.9827649631778774
Validation loss: 3.103100617499701

Epoch: 6| Step: 10
Training loss: 3.9451505420037227
Validation loss: 3.09983895952318

Epoch: 6| Step: 11
Training loss: 4.0807180528260165
Validation loss: 3.1013757313611303

Epoch: 6| Step: 12
Training loss: 3.087276892380969
Validation loss: 3.096392690601982

Epoch: 6| Step: 13
Training loss: 3.368851889801616
Validation loss: 3.0935491043183316

Epoch: 58| Step: 0
Training loss: 3.5142382790247297
Validation loss: 3.090916150797187

Epoch: 6| Step: 1
Training loss: 3.757675961494258
Validation loss: 3.0912574910798103

Epoch: 6| Step: 2
Training loss: 3.8964381165017286
Validation loss: 3.0921679383905825

Epoch: 6| Step: 3
Training loss: 3.877886035820486
Validation loss: 3.089113445499769

Epoch: 6| Step: 4
Training loss: 3.1346866775981654
Validation loss: 3.0852933295187617

Epoch: 6| Step: 5
Training loss: 3.190933472669393
Validation loss: 3.087271705767193

Epoch: 6| Step: 6
Training loss: 3.210657409183594
Validation loss: 3.0784959891736468

Epoch: 6| Step: 7
Training loss: 2.3140600973318994
Validation loss: 3.073665291747105

Epoch: 6| Step: 8
Training loss: 3.5587247956284154
Validation loss: 3.076149990188196

Epoch: 6| Step: 9
Training loss: 3.73052038985855
Validation loss: 3.0734119294960025

Epoch: 6| Step: 10
Training loss: 3.035202438415449
Validation loss: 3.0740248392016265

Epoch: 6| Step: 11
Training loss: 2.948057317355131
Validation loss: 3.0738642501554048

Epoch: 6| Step: 12
Training loss: 2.8884478644020306
Validation loss: 3.072622995055392

Epoch: 6| Step: 13
Training loss: 3.7134145721187433
Validation loss: 3.0738760797633002

Epoch: 59| Step: 0
Training loss: 4.520376484138197
Validation loss: 3.071359252597164

Epoch: 6| Step: 1
Training loss: 2.8368789329257824
Validation loss: 3.071210107783456

Epoch: 6| Step: 2
Training loss: 3.299977510549033
Validation loss: 3.0691467541948545

Epoch: 6| Step: 3
Training loss: 2.6573621329057904
Validation loss: 3.0747332982429074

Epoch: 6| Step: 4
Training loss: 2.733658876648993
Validation loss: 3.0765032816927063

Epoch: 6| Step: 5
Training loss: 3.010382646590636
Validation loss: 3.083360005612292

Epoch: 6| Step: 6
Training loss: 3.853561285089663
Validation loss: 3.0798989092044065

Epoch: 6| Step: 7
Training loss: 2.672341646190173
Validation loss: 3.077276728144366

Epoch: 6| Step: 8
Training loss: 3.6390459950499876
Validation loss: 3.0689310235200398

Epoch: 6| Step: 9
Training loss: 3.4516261373363366
Validation loss: 3.0666655354098693

Epoch: 6| Step: 10
Training loss: 2.927422301371363
Validation loss: 3.0645866158177424

Epoch: 6| Step: 11
Training loss: 3.917972401154206
Validation loss: 3.063417604860087

Epoch: 6| Step: 12
Training loss: 3.4986838182061883
Validation loss: 3.0633263091610554

Epoch: 6| Step: 13
Training loss: 3.0948290243668515
Validation loss: 3.0634486704859367

Epoch: 60| Step: 0
Training loss: 3.378142130452779
Validation loss: 3.0630500773243248

Epoch: 6| Step: 1
Training loss: 3.817005184658768
Validation loss: 3.064584188185894

Epoch: 6| Step: 2
Training loss: 3.9061901850889136
Validation loss: 3.0618147561606945

Epoch: 6| Step: 3
Training loss: 3.3678632089195872
Validation loss: 3.060683069103661

Epoch: 6| Step: 4
Training loss: 2.5277044637293007
Validation loss: 3.059239572052781

Epoch: 6| Step: 5
Training loss: 2.8272504771633016
Validation loss: 3.0562755136141906

Epoch: 6| Step: 6
Training loss: 3.0243098456878736
Validation loss: 3.057000226703258

Epoch: 6| Step: 7
Training loss: 3.2746294350676868
Validation loss: 3.059829625879831

Epoch: 6| Step: 8
Training loss: 3.0393285953557037
Validation loss: 3.0592410284952267

Epoch: 6| Step: 9
Training loss: 4.114399554176313
Validation loss: 3.059750202861519

Epoch: 6| Step: 10
Training loss: 2.698781487341733
Validation loss: 3.0601182255756814

Epoch: 6| Step: 11
Training loss: 2.9439376738833927
Validation loss: 3.0613894664253998

Epoch: 6| Step: 12
Training loss: 3.546554349277672
Validation loss: 3.0635455826364795

Epoch: 6| Step: 13
Training loss: 4.1836252077773874
Validation loss: 3.0594210019024297

Epoch: 61| Step: 0
Training loss: 2.8978486401169805
Validation loss: 3.0559536780496614

Epoch: 6| Step: 1
Training loss: 3.2811309792866945
Validation loss: 3.0541020885072716

Epoch: 6| Step: 2
Training loss: 3.5575346223777644
Validation loss: 3.0545318339772902

Epoch: 6| Step: 3
Training loss: 4.131461429235394
Validation loss: 3.0523759236261845

Epoch: 6| Step: 4
Training loss: 3.767723923112071
Validation loss: 3.053613822369204

Epoch: 6| Step: 5
Training loss: 3.4765065392265777
Validation loss: 3.056309852707732

Epoch: 6| Step: 6
Training loss: 2.4686631778950274
Validation loss: 3.059620661182631

Epoch: 6| Step: 7
Training loss: 3.0244265178242884
Validation loss: 3.058184339717506

Epoch: 6| Step: 8
Training loss: 3.705455963865511
Validation loss: 3.0598908577980883

Epoch: 6| Step: 9
Training loss: 3.682038999501181
Validation loss: 3.053583167135936

Epoch: 6| Step: 10
Training loss: 3.0961239116623203
Validation loss: 3.0545872921349773

Epoch: 6| Step: 11
Training loss: 2.417194396528825
Validation loss: 3.052250764118119

Epoch: 6| Step: 12
Training loss: 3.4262163327444237
Validation loss: 3.0515885084085492

Epoch: 6| Step: 13
Training loss: 3.21217370658323
Validation loss: 3.050495155456094

Epoch: 62| Step: 0
Training loss: 3.337010231228726
Validation loss: 3.0519487356272252

Epoch: 6| Step: 1
Training loss: 3.435778793826078
Validation loss: 3.0526688005212548

Epoch: 6| Step: 2
Training loss: 3.1083798757005483
Validation loss: 3.055718159443105

Epoch: 6| Step: 3
Training loss: 3.413393701476479
Validation loss: 3.0615109488762147

Epoch: 6| Step: 4
Training loss: 3.967708661289791
Validation loss: 3.0565028181859146

Epoch: 6| Step: 5
Training loss: 3.354697159858516
Validation loss: 3.053972548170454

Epoch: 6| Step: 6
Training loss: 3.8189839742503575
Validation loss: 3.049554308653146

Epoch: 6| Step: 7
Training loss: 3.936924120252445
Validation loss: 3.0491077968326294

Epoch: 6| Step: 8
Training loss: 3.276132280140712
Validation loss: 3.0485341348923773

Epoch: 6| Step: 9
Training loss: 3.3014127770490758
Validation loss: 3.0525455922058184

Epoch: 6| Step: 10
Training loss: 2.9971705445116372
Validation loss: 3.0493770484993186

Epoch: 6| Step: 11
Training loss: 1.9567585829418261
Validation loss: 3.049912412472781

Epoch: 6| Step: 12
Training loss: 3.220529305213245
Validation loss: 3.053411103743643

Epoch: 6| Step: 13
Training loss: 2.7514541422678978
Validation loss: 3.0489041092973634

Epoch: 63| Step: 0
Training loss: 3.9440079448999077
Validation loss: 3.0506283561821412

Epoch: 6| Step: 1
Training loss: 3.60746020765029
Validation loss: 3.048975025761941

Epoch: 6| Step: 2
Training loss: 3.9913508365269195
Validation loss: 3.0477448615574603

Epoch: 6| Step: 3
Training loss: 2.9772618390849805
Validation loss: 3.0477940849937024

Epoch: 6| Step: 4
Training loss: 2.537652008314283
Validation loss: 3.0495624899526645

Epoch: 6| Step: 5
Training loss: 2.972069580896276
Validation loss: 3.0491631863297157

Epoch: 6| Step: 6
Training loss: 2.025817061055134
Validation loss: 3.053589596415325

Epoch: 6| Step: 7
Training loss: 2.8139493810442984
Validation loss: 3.056253154159211

Epoch: 6| Step: 8
Training loss: 3.264075536779479
Validation loss: 3.0629649726992234

Epoch: 6| Step: 9
Training loss: 4.300337516490689
Validation loss: 3.0746977574767005

Epoch: 6| Step: 10
Training loss: 3.5424031707301507
Validation loss: 3.0509140365786394

Epoch: 6| Step: 11
Training loss: 3.6958935141725915
Validation loss: 3.0470652859242335

Epoch: 6| Step: 12
Training loss: 3.440358031515
Validation loss: 3.0465618114567783

Epoch: 6| Step: 13
Training loss: 2.207727265113158
Validation loss: 3.0551236395225136

Epoch: 64| Step: 0
Training loss: 3.3200699302478314
Validation loss: 3.0686388916956293

Epoch: 6| Step: 1
Training loss: 3.2236776317033518
Validation loss: 3.078865386567405

Epoch: 6| Step: 2
Training loss: 4.139393749352991
Validation loss: 3.0814056279305624

Epoch: 6| Step: 3
Training loss: 4.043126317883635
Validation loss: 3.070580574395326

Epoch: 6| Step: 4
Training loss: 2.9143652055621994
Validation loss: 3.058227274036097

Epoch: 6| Step: 5
Training loss: 3.036998528423336
Validation loss: 3.04919574239729

Epoch: 6| Step: 6
Training loss: 3.4192413925371596
Validation loss: 3.0488601111842706

Epoch: 6| Step: 7
Training loss: 3.0650054647823235
Validation loss: 3.047925697150499

Epoch: 6| Step: 8
Training loss: 2.469244702183539
Validation loss: 3.0509915889576287

Epoch: 6| Step: 9
Training loss: 3.258578935295456
Validation loss: 3.051676812601124

Epoch: 6| Step: 10
Training loss: 3.3703803482265062
Validation loss: 3.056042903028117

Epoch: 6| Step: 11
Training loss: 2.7075723214674365
Validation loss: 3.0559646424576754

Epoch: 6| Step: 12
Training loss: 3.431439414989027
Validation loss: 3.0630988899307248

Epoch: 6| Step: 13
Training loss: 4.394320090412945
Validation loss: 3.0606316766360733

Epoch: 65| Step: 0
Training loss: 3.4650980652862886
Validation loss: 3.0540659097671248

Epoch: 6| Step: 1
Training loss: 3.3244204252682046
Validation loss: 3.0501885195655327

Epoch: 6| Step: 2
Training loss: 2.690162936242925
Validation loss: 3.048959079559895

Epoch: 6| Step: 3
Training loss: 3.323037140355437
Validation loss: 3.0469683552657947

Epoch: 6| Step: 4
Training loss: 2.238396500155131
Validation loss: 3.0426584774029464

Epoch: 6| Step: 5
Training loss: 3.155898877243799
Validation loss: 3.042505477048431

Epoch: 6| Step: 6
Training loss: 3.6649369292407337
Validation loss: 3.042429063304576

Epoch: 6| Step: 7
Training loss: 3.59492738759187
Validation loss: 3.041623271296004

Epoch: 6| Step: 8
Training loss: 3.551527559685008
Validation loss: 3.04183154320203

Epoch: 6| Step: 9
Training loss: 2.554151566311962
Validation loss: 3.0413865553094785

Epoch: 6| Step: 10
Training loss: 3.835190710028329
Validation loss: 3.0430215309209023

Epoch: 6| Step: 11
Training loss: 3.5723046018581663
Validation loss: 3.043376029018945

Epoch: 6| Step: 12
Training loss: 3.335513228655398
Validation loss: 3.0412093147542625

Epoch: 6| Step: 13
Training loss: 4.198521926195705
Validation loss: 3.0447350243230185

Epoch: 66| Step: 0
Training loss: 3.086419871812983
Validation loss: 3.0417877428267723

Epoch: 6| Step: 1
Training loss: 3.457394269428545
Validation loss: 3.0408691212472245

Epoch: 6| Step: 2
Training loss: 3.043594707310848
Validation loss: 3.041425685014911

Epoch: 6| Step: 3
Training loss: 2.8111479158299892
Validation loss: 3.036078171529981

Epoch: 6| Step: 4
Training loss: 3.786867493041059
Validation loss: 3.0380562267984743

Epoch: 6| Step: 5
Training loss: 3.2601062923491546
Validation loss: 3.038043553103144

Epoch: 6| Step: 6
Training loss: 2.963297444467019
Validation loss: 3.038330373337732

Epoch: 6| Step: 7
Training loss: 3.0623889825122483
Validation loss: 3.037602376147346

Epoch: 6| Step: 8
Training loss: 4.206389226777336
Validation loss: 3.0379380030228065

Epoch: 6| Step: 9
Training loss: 3.7285899279281134
Validation loss: 3.0348448407846167

Epoch: 6| Step: 10
Training loss: 3.484416602189983
Validation loss: 3.0356554030659466

Epoch: 6| Step: 11
Training loss: 2.655479858051982
Validation loss: 3.036759257011009

Epoch: 6| Step: 12
Training loss: 3.8372146748887586
Validation loss: 3.0369963505509565

Epoch: 6| Step: 13
Training loss: 2.0806014141511753
Validation loss: 3.033770027175157

Epoch: 67| Step: 0
Training loss: 2.9649708033341615
Validation loss: 3.0349707662455665

Epoch: 6| Step: 1
Training loss: 3.914473034311584
Validation loss: 3.036078928949663

Epoch: 6| Step: 2
Training loss: 2.848834177458263
Validation loss: 3.0365067678315576

Epoch: 6| Step: 3
Training loss: 3.136826984823174
Validation loss: 3.035364580508121

Epoch: 6| Step: 4
Training loss: 3.314202932559507
Validation loss: 3.0326399141640024

Epoch: 6| Step: 5
Training loss: 3.662731978324915
Validation loss: 3.0346973143116602

Epoch: 6| Step: 6
Training loss: 3.440196280313453
Validation loss: 3.030659519874876

Epoch: 6| Step: 7
Training loss: 2.746345606143737
Validation loss: 3.0317961633478308

Epoch: 6| Step: 8
Training loss: 4.076029388905781
Validation loss: 3.0309776900177905

Epoch: 6| Step: 9
Training loss: 3.3088030067754843
Validation loss: 3.028276826334701

Epoch: 6| Step: 10
Training loss: 3.1326962114093533
Validation loss: 3.03150290036903

Epoch: 6| Step: 11
Training loss: 3.685502885435675
Validation loss: 3.02895080189498

Epoch: 6| Step: 12
Training loss: 2.0930414851451986
Validation loss: 3.0274280065586967

Epoch: 6| Step: 13
Training loss: 3.7614107094961984
Validation loss: 3.0284930691934493

Epoch: 68| Step: 0
Training loss: 3.774052350674257
Validation loss: 3.0280421572065768

Epoch: 6| Step: 1
Training loss: 3.3635543021237164
Validation loss: 3.0265718039158824

Epoch: 6| Step: 2
Training loss: 3.732187053134524
Validation loss: 3.027853145553826

Epoch: 6| Step: 3
Training loss: 3.960350820819085
Validation loss: 3.0289896250552166

Epoch: 6| Step: 4
Training loss: 2.978288925799025
Validation loss: 3.028014089496871

Epoch: 6| Step: 5
Training loss: 2.8986780113108175
Validation loss: 3.027042300498075

Epoch: 6| Step: 6
Training loss: 3.4431591267815183
Validation loss: 3.026343929387749

Epoch: 6| Step: 7
Training loss: 2.454901762509901
Validation loss: 3.028177538428192

Epoch: 6| Step: 8
Training loss: 2.7553399865197576
Validation loss: 3.0253033796981073

Epoch: 6| Step: 9
Training loss: 3.5178465203338534
Validation loss: 3.0260397971940334

Epoch: 6| Step: 10
Training loss: 3.305968412872637
Validation loss: 3.0227577747170886

Epoch: 6| Step: 11
Training loss: 2.7241141357989425
Validation loss: 3.024747940520984

Epoch: 6| Step: 12
Training loss: 3.085217973869766
Validation loss: 3.0233989023221524

Epoch: 6| Step: 13
Training loss: 4.32249552808699
Validation loss: 3.020609383490749

Epoch: 69| Step: 0
Training loss: 3.078461914213522
Validation loss: 3.024444742141287

Epoch: 6| Step: 1
Training loss: 3.5827178130716053
Validation loss: 3.021645447757687

Epoch: 6| Step: 2
Training loss: 3.316822039416964
Validation loss: 3.024601414183635

Epoch: 6| Step: 3
Training loss: 3.0989747290084044
Validation loss: 3.022792469130959

Epoch: 6| Step: 4
Training loss: 2.9115643877197512
Validation loss: 3.026278592924355

Epoch: 6| Step: 5
Training loss: 3.597683288273804
Validation loss: 3.0261207250988518

Epoch: 6| Step: 6
Training loss: 3.722202269340923
Validation loss: 3.0264501752165387

Epoch: 6| Step: 7
Training loss: 3.7635473320808637
Validation loss: 3.0225365753201405

Epoch: 6| Step: 8
Training loss: 3.4801558194408324
Validation loss: 3.022324893906161

Epoch: 6| Step: 9
Training loss: 2.8400158521720225
Validation loss: 3.0233540980420597

Epoch: 6| Step: 10
Training loss: 3.321969514149986
Validation loss: 3.025937349457469

Epoch: 6| Step: 11
Training loss: 3.157931644659027
Validation loss: 3.0192310659649357

Epoch: 6| Step: 12
Training loss: 2.75013784583274
Validation loss: 3.0195867447946516

Epoch: 6| Step: 13
Training loss: 3.5379255544314003
Validation loss: 3.0197650608927504

Epoch: 70| Step: 0
Training loss: 3.3120527145410783
Validation loss: 3.0207732950311508

Epoch: 6| Step: 1
Training loss: 2.4636819704089974
Validation loss: 3.0162354937958398

Epoch: 6| Step: 2
Training loss: 3.8985326598637613
Validation loss: 3.018754247177799

Epoch: 6| Step: 3
Training loss: 3.4543240912026465
Validation loss: 3.020022746389385

Epoch: 6| Step: 4
Training loss: 3.564079068558047
Validation loss: 3.018050650528936

Epoch: 6| Step: 5
Training loss: 3.1724269743707016
Validation loss: 3.017338915137022

Epoch: 6| Step: 6
Training loss: 2.509191591393885
Validation loss: 3.0210075613887852

Epoch: 6| Step: 7
Training loss: 3.557658335311381
Validation loss: 3.018708156135266

Epoch: 6| Step: 8
Training loss: 3.3554153171676964
Validation loss: 3.016814881090241

Epoch: 6| Step: 9
Training loss: 3.4273416408291464
Validation loss: 3.017513159463316

Epoch: 6| Step: 10
Training loss: 2.7241803887753795
Validation loss: 3.0168687637049043

Epoch: 6| Step: 11
Training loss: 3.7353297333920987
Validation loss: 3.0162069158888385

Epoch: 6| Step: 12
Training loss: 3.234565618675267
Validation loss: 3.012626092363897

Epoch: 6| Step: 13
Training loss: 3.54198491779651
Validation loss: 3.0128109555262115

Epoch: 71| Step: 0
Training loss: 3.5324025931565557
Validation loss: 3.0144632617986167

Epoch: 6| Step: 1
Training loss: 3.2479131307495
Validation loss: 3.022174917213179

Epoch: 6| Step: 2
Training loss: 3.331488543874757
Validation loss: 3.0240798746436917

Epoch: 6| Step: 3
Training loss: 3.74603417819552
Validation loss: 3.0201616112534055

Epoch: 6| Step: 4
Training loss: 3.403626437765526
Validation loss: 3.0267582775326303

Epoch: 6| Step: 5
Training loss: 3.5678876325934756
Validation loss: 3.0176261949266334

Epoch: 6| Step: 6
Training loss: 2.901973736718428
Validation loss: 3.0138558574230117

Epoch: 6| Step: 7
Training loss: 2.956438738421293
Validation loss: 3.011951606339276

Epoch: 6| Step: 8
Training loss: 3.685832535630572
Validation loss: 3.0106231610684295

Epoch: 6| Step: 9
Training loss: 3.146321610373504
Validation loss: 3.013714857353641

Epoch: 6| Step: 10
Training loss: 3.0391800178616006
Validation loss: 3.0137679243347333

Epoch: 6| Step: 11
Training loss: 3.0565373509909755
Validation loss: 3.0150847790878377

Epoch: 6| Step: 12
Training loss: 3.3007694041022644
Validation loss: 3.014173003938603

Epoch: 6| Step: 13
Training loss: 2.973952703698882
Validation loss: 3.0171348154021205

Epoch: 72| Step: 0
Training loss: 3.242792794589654
Validation loss: 3.0206871316995136

Epoch: 6| Step: 1
Training loss: 2.9625455571144412
Validation loss: 3.0191136631915847

Epoch: 6| Step: 2
Training loss: 2.866869667169681
Validation loss: 3.01967974918218

Epoch: 6| Step: 3
Training loss: 3.35312230375809
Validation loss: 3.0198242255924326

Epoch: 6| Step: 4
Training loss: 3.704836679171693
Validation loss: 3.0165893791123013

Epoch: 6| Step: 5
Training loss: 3.1059362671374986
Validation loss: 3.017483627666819

Epoch: 6| Step: 6
Training loss: 3.0026862515657204
Validation loss: 3.016781603370213

Epoch: 6| Step: 7
Training loss: 3.5140934977981293
Validation loss: 3.014094749179535

Epoch: 6| Step: 8
Training loss: 2.1358496870450963
Validation loss: 3.0111795574279494

Epoch: 6| Step: 9
Training loss: 3.4012065261367264
Validation loss: 3.0096552679663247

Epoch: 6| Step: 10
Training loss: 3.4474450256523337
Validation loss: 3.00950348519223

Epoch: 6| Step: 11
Training loss: 4.023027891771165
Validation loss: 3.0106272586355054

Epoch: 6| Step: 12
Training loss: 3.87273870137572
Validation loss: 3.0144089670850325

Epoch: 6| Step: 13
Training loss: 2.976699465506516
Validation loss: 3.013918111824649

Epoch: 73| Step: 0
Training loss: 2.8131070647465677
Validation loss: 3.01387103411467

Epoch: 6| Step: 1
Training loss: 3.575357357917724
Validation loss: 3.0142455973897193

Epoch: 6| Step: 2
Training loss: 3.647627746771333
Validation loss: 3.0112477721629847

Epoch: 6| Step: 3
Training loss: 3.029153944685788
Validation loss: 3.008940541361307

Epoch: 6| Step: 4
Training loss: 3.8709750036971364
Validation loss: 3.010522717839316

Epoch: 6| Step: 5
Training loss: 3.7777024959717633
Validation loss: 3.0085142193101073

Epoch: 6| Step: 6
Training loss: 2.5489538402904905
Validation loss: 3.0068726384719215

Epoch: 6| Step: 7
Training loss: 3.12910283646243
Validation loss: 3.007729395237837

Epoch: 6| Step: 8
Training loss: 3.4834927523939885
Validation loss: 3.008253327161033

Epoch: 6| Step: 9
Training loss: 2.9457130058637824
Validation loss: 3.006952262847476

Epoch: 6| Step: 10
Training loss: 3.5562265941741296
Validation loss: 3.0055200806038656

Epoch: 6| Step: 11
Training loss: 3.1675743675985855
Validation loss: 3.004003973618018

Epoch: 6| Step: 12
Training loss: 3.6066629368403733
Validation loss: 3.0073148633510245

Epoch: 6| Step: 13
Training loss: 1.8237599484105
Validation loss: 3.005494459613182

Epoch: 74| Step: 0
Training loss: 4.21001972112318
Validation loss: 3.0049351771923067

Epoch: 6| Step: 1
Training loss: 2.3712016400044544
Validation loss: 3.0057321923862115

Epoch: 6| Step: 2
Training loss: 2.2152057331717745
Validation loss: 3.0051551538744308

Epoch: 6| Step: 3
Training loss: 2.6583582869965925
Validation loss: 3.0043773453739906

Epoch: 6| Step: 4
Training loss: 3.586735389386706
Validation loss: 3.0099418025178326

Epoch: 6| Step: 5
Training loss: 3.0757128563781984
Validation loss: 3.0049859302649944

Epoch: 6| Step: 6
Training loss: 3.131699666459624
Validation loss: 3.008555036839324

Epoch: 6| Step: 7
Training loss: 3.8825066981408285
Validation loss: 3.0094487926225715

Epoch: 6| Step: 8
Training loss: 3.294091373827687
Validation loss: 3.0102856239887603

Epoch: 6| Step: 9
Training loss: 3.6249876350981194
Validation loss: 3.011750806842131

Epoch: 6| Step: 10
Training loss: 2.874002034674384
Validation loss: 3.0107428567772714

Epoch: 6| Step: 11
Training loss: 3.672403240759944
Validation loss: 3.016362780888854

Epoch: 6| Step: 12
Training loss: 3.97156550944652
Validation loss: 3.01417685853219

Epoch: 6| Step: 13
Training loss: 2.17877375000502
Validation loss: 3.009360333780299

Epoch: 75| Step: 0
Training loss: 2.89212986720206
Validation loss: 3.006471196071056

Epoch: 6| Step: 1
Training loss: 3.346615428101711
Validation loss: 3.0080832159392603

Epoch: 6| Step: 2
Training loss: 3.3008865610511706
Validation loss: 3.0036274691412945

Epoch: 6| Step: 3
Training loss: 3.8962238272460055
Validation loss: 3.003596897790976

Epoch: 6| Step: 4
Training loss: 3.042734629251761
Validation loss: 3.003252126192158

Epoch: 6| Step: 5
Training loss: 3.055846479803899
Validation loss: 3.0054391805816802

Epoch: 6| Step: 6
Training loss: 2.9590949210992195
Validation loss: 3.0083282689045747

Epoch: 6| Step: 7
Training loss: 3.674697505412741
Validation loss: 3.009521832246477

Epoch: 6| Step: 8
Training loss: 2.863343200429747
Validation loss: 3.0143580630956004

Epoch: 6| Step: 9
Training loss: 3.8575196536262513
Validation loss: 3.014828572898862

Epoch: 6| Step: 10
Training loss: 3.5553573480302063
Validation loss: 3.0219291122503127

Epoch: 6| Step: 11
Training loss: 2.938761501119379
Validation loss: 3.0224162957429943

Epoch: 6| Step: 12
Training loss: 3.324473782538544
Validation loss: 3.019479831248791

Epoch: 6| Step: 13
Training loss: 2.9880669410999863
Validation loss: 3.0072462746731414

Epoch: 76| Step: 0
Training loss: 3.013576938718534
Validation loss: 3.0045604907862837

Epoch: 6| Step: 1
Training loss: 3.8195090980066877
Validation loss: 3.0038352125915946

Epoch: 6| Step: 2
Training loss: 2.943407813915869
Validation loss: 3.0025062483523857

Epoch: 6| Step: 3
Training loss: 3.492004526281755
Validation loss: 3.0008071160632865

Epoch: 6| Step: 4
Training loss: 2.5525630785464433
Validation loss: 2.999500907380116

Epoch: 6| Step: 5
Training loss: 2.9400495462719145
Validation loss: 2.998790073124371

Epoch: 6| Step: 6
Training loss: 3.6526523724887983
Validation loss: 3.000421497855965

Epoch: 6| Step: 7
Training loss: 3.5713140305816427
Validation loss: 2.9979065038948076

Epoch: 6| Step: 8
Training loss: 3.2380415180035067
Validation loss: 2.9993848169908954

Epoch: 6| Step: 9
Training loss: 3.302176168362223
Validation loss: 3.0021915668680696

Epoch: 6| Step: 10
Training loss: 3.3708364448171495
Validation loss: 3.0064081287341016

Epoch: 6| Step: 11
Training loss: 3.5463813068443666
Validation loss: 3.01019305581601

Epoch: 6| Step: 12
Training loss: 3.459664758747576
Validation loss: 3.007333157265431

Epoch: 6| Step: 13
Training loss: 2.476822126480205
Validation loss: 3.000551247454835

Epoch: 77| Step: 0
Training loss: 3.7940123013310547
Validation loss: 3.0016482390379995

Epoch: 6| Step: 1
Training loss: 3.080607695884035
Validation loss: 3.001038221279745

Epoch: 6| Step: 2
Training loss: 2.882635509154374
Validation loss: 2.996940481486427

Epoch: 6| Step: 3
Training loss: 3.2196793186839483
Validation loss: 2.999223542825378

Epoch: 6| Step: 4
Training loss: 2.662674438779768
Validation loss: 2.996091393508623

Epoch: 6| Step: 5
Training loss: 2.616802312489686
Validation loss: 2.996707698320688

Epoch: 6| Step: 6
Training loss: 3.591169940442487
Validation loss: 2.997689334870753

Epoch: 6| Step: 7
Training loss: 3.0716764026914625
Validation loss: 2.997713920219846

Epoch: 6| Step: 8
Training loss: 2.863345198808391
Validation loss: 2.994895865761933

Epoch: 6| Step: 9
Training loss: 3.6101126309310367
Validation loss: 2.9958267290797123

Epoch: 6| Step: 10
Training loss: 4.562746224226092
Validation loss: 2.995775119119423

Epoch: 6| Step: 11
Training loss: 3.057547944660709
Validation loss: 2.9954104494321174

Epoch: 6| Step: 12
Training loss: 3.7687537147415098
Validation loss: 2.995505735095673

Epoch: 6| Step: 13
Training loss: 1.645273145474886
Validation loss: 2.9954746614956838

Epoch: 78| Step: 0
Training loss: 3.5214762505105948
Validation loss: 2.9938866630451355

Epoch: 6| Step: 1
Training loss: 3.4043893194203854
Validation loss: 2.9994394212730464

Epoch: 6| Step: 2
Training loss: 3.2741037205210057
Validation loss: 2.9952715694208365

Epoch: 6| Step: 3
Training loss: 2.564446152200393
Validation loss: 2.9967043439593124

Epoch: 6| Step: 4
Training loss: 2.609823588113146
Validation loss: 2.997153073007941

Epoch: 6| Step: 5
Training loss: 3.7247169131040914
Validation loss: 2.9997357052085705

Epoch: 6| Step: 6
Training loss: 3.3747692735713515
Validation loss: 2.993660004298163

Epoch: 6| Step: 7
Training loss: 3.022551650748968
Validation loss: 2.9947356056790806

Epoch: 6| Step: 8
Training loss: 3.1960385717134083
Validation loss: 2.992759366991265

Epoch: 6| Step: 9
Training loss: 3.027876402233445
Validation loss: 2.9927141631103504

Epoch: 6| Step: 10
Training loss: 3.492934998255561
Validation loss: 2.994087744436374

Epoch: 6| Step: 11
Training loss: 3.5224184309190223
Validation loss: 2.9954945605157612

Epoch: 6| Step: 12
Training loss: 3.7748591112536176
Validation loss: 2.997605843408452

Epoch: 6| Step: 13
Training loss: 3.0467829763747454
Validation loss: 2.9959578901968134

Epoch: 79| Step: 0
Training loss: 3.2141631693413437
Validation loss: 3.000019947621467

Epoch: 6| Step: 1
Training loss: 2.9634087951228936
Validation loss: 2.9987289922027

Epoch: 6| Step: 2
Training loss: 3.4234955316567066
Validation loss: 2.9968302757957375

Epoch: 6| Step: 3
Training loss: 3.1042307563327203
Validation loss: 2.9976608871774775

Epoch: 6| Step: 4
Training loss: 3.330849834977396
Validation loss: 2.995840922304722

Epoch: 6| Step: 5
Training loss: 3.3584715582055167
Validation loss: 2.99354335254876

Epoch: 6| Step: 6
Training loss: 3.223826432906529
Validation loss: 2.995310966049713

Epoch: 6| Step: 7
Training loss: 3.624021727002089
Validation loss: 2.994381331072807

Epoch: 6| Step: 8
Training loss: 3.0790140639823607
Validation loss: 2.9947197276388042

Epoch: 6| Step: 9
Training loss: 3.986879765695635
Validation loss: 2.991732514538488

Epoch: 6| Step: 10
Training loss: 2.7946045253532743
Validation loss: 2.9903640890939194

Epoch: 6| Step: 11
Training loss: 2.7173781167415223
Validation loss: 2.9924347764965256

Epoch: 6| Step: 12
Training loss: 3.7965567498599606
Validation loss: 2.991837913268431

Epoch: 6| Step: 13
Training loss: 2.827705310008712
Validation loss: 2.997262753633442

Epoch: 80| Step: 0
Training loss: 2.635009211428211
Validation loss: 3.003079457496999

Epoch: 6| Step: 1
Training loss: 3.0697651537805353
Validation loss: 3.00688721864125

Epoch: 6| Step: 2
Training loss: 3.271070111364462
Validation loss: 3.0094026485077676

Epoch: 6| Step: 3
Training loss: 3.1665955753042763
Validation loss: 3.0082568995912755

Epoch: 6| Step: 4
Training loss: 2.7816825273205232
Validation loss: 3.0068397469326866

Epoch: 6| Step: 5
Training loss: 3.4681703925242817
Validation loss: 3.0066351536155564

Epoch: 6| Step: 6
Training loss: 2.935725873513899
Validation loss: 2.99717684846109

Epoch: 6| Step: 7
Training loss: 3.3520269894571726
Validation loss: 2.9885523128980775

Epoch: 6| Step: 8
Training loss: 3.699319807885718
Validation loss: 2.988324122289247

Epoch: 6| Step: 9
Training loss: 3.7703076131372444
Validation loss: 2.988685124537725

Epoch: 6| Step: 10
Training loss: 3.0434999210463567
Validation loss: 2.989951191524812

Epoch: 6| Step: 11
Training loss: 3.4469430399704577
Validation loss: 2.987066150696921

Epoch: 6| Step: 12
Training loss: 3.4476163950435446
Validation loss: 2.989324277138696

Epoch: 6| Step: 13
Training loss: 3.8401883379128803
Validation loss: 2.989296573141683

Epoch: 81| Step: 0
Training loss: 3.1467913922413384
Validation loss: 2.9863064986193626

Epoch: 6| Step: 1
Training loss: 3.1860244926186487
Validation loss: 2.98769030914559

Epoch: 6| Step: 2
Training loss: 3.677239966726156
Validation loss: 2.98926036476941

Epoch: 6| Step: 3
Training loss: 3.231156521594244
Validation loss: 2.9857997533230987

Epoch: 6| Step: 4
Training loss: 3.5563014128979398
Validation loss: 2.9893768303255235

Epoch: 6| Step: 5
Training loss: 3.9675523047073216
Validation loss: 2.988413022807696

Epoch: 6| Step: 6
Training loss: 2.9681489034763753
Validation loss: 2.988734141236725

Epoch: 6| Step: 7
Training loss: 2.4248079322181773
Validation loss: 2.988373650195942

Epoch: 6| Step: 8
Training loss: 2.7351676446001227
Validation loss: 2.986911955773176

Epoch: 6| Step: 9
Training loss: 3.7321461686010786
Validation loss: 2.986012061396003

Epoch: 6| Step: 10
Training loss: 3.375038429324037
Validation loss: 2.989314999621485

Epoch: 6| Step: 11
Training loss: 3.411253587630731
Validation loss: 2.9863350733600913

Epoch: 6| Step: 12
Training loss: 2.9602040210210743
Validation loss: 2.9867701558132187

Epoch: 6| Step: 13
Training loss: 2.871701213904134
Validation loss: 2.9954348313925325

Epoch: 82| Step: 0
Training loss: 3.1865337627686685
Validation loss: 2.9874319303479786

Epoch: 6| Step: 1
Training loss: 3.306773868586836
Validation loss: 2.986675609038336

Epoch: 6| Step: 2
Training loss: 3.516245062506254
Validation loss: 2.9856536811224257

Epoch: 6| Step: 3
Training loss: 3.006891124351464
Validation loss: 2.983875300042029

Epoch: 6| Step: 4
Training loss: 2.8259696545385626
Validation loss: 2.9830415436814133

Epoch: 6| Step: 5
Training loss: 3.56177285787756
Validation loss: 2.9831069015704297

Epoch: 6| Step: 6
Training loss: 3.414564152575081
Validation loss: 2.984847401797073

Epoch: 6| Step: 7
Training loss: 3.02510249697221
Validation loss: 2.9839590399420417

Epoch: 6| Step: 8
Training loss: 2.975979645300546
Validation loss: 2.9831394497823913

Epoch: 6| Step: 9
Training loss: 3.2392623758729537
Validation loss: 2.983204374988078

Epoch: 6| Step: 10
Training loss: 3.4874648006946227
Validation loss: 2.987085762435295

Epoch: 6| Step: 11
Training loss: 3.8311556283302206
Validation loss: 2.9861108222027086

Epoch: 6| Step: 12
Training loss: 2.901786904806375
Validation loss: 2.9865180135556333

Epoch: 6| Step: 13
Training loss: 3.4015418595689666
Validation loss: 2.98610991388672

Epoch: 83| Step: 0
Training loss: 2.4855357403515526
Validation loss: 2.9834474740324244

Epoch: 6| Step: 1
Training loss: 3.3523154668919495
Validation loss: 2.981944749081197

Epoch: 6| Step: 2
Training loss: 3.0046268387581088
Validation loss: 2.9830536690010527

Epoch: 6| Step: 3
Training loss: 2.968194206814176
Validation loss: 2.9816498570615595

Epoch: 6| Step: 4
Training loss: 3.7972674382855587
Validation loss: 2.9846423557168045

Epoch: 6| Step: 5
Training loss: 2.8360316573556505
Validation loss: 2.9814902100157545

Epoch: 6| Step: 6
Training loss: 2.915066379949472
Validation loss: 2.9811328203028893

Epoch: 6| Step: 7
Training loss: 3.486048548839112
Validation loss: 2.9859768314477484

Epoch: 6| Step: 8
Training loss: 3.39332283380629
Validation loss: 2.979456201572518

Epoch: 6| Step: 9
Training loss: 3.6438442944321086
Validation loss: 2.983698597258133

Epoch: 6| Step: 10
Training loss: 3.299682578802029
Validation loss: 2.979972982086618

Epoch: 6| Step: 11
Training loss: 3.948873412355306
Validation loss: 2.9783546849421896

Epoch: 6| Step: 12
Training loss: 3.104742077912645
Validation loss: 2.979142129046788

Epoch: 6| Step: 13
Training loss: 3.1113773205562167
Validation loss: 2.9778301328258263

Epoch: 84| Step: 0
Training loss: 3.2573579978878295
Validation loss: 2.9802288626086595

Epoch: 6| Step: 1
Training loss: 2.7799653933449964
Validation loss: 2.9802882650946967

Epoch: 6| Step: 2
Training loss: 3.2522089860400105
Validation loss: 2.977041986902646

Epoch: 6| Step: 3
Training loss: 3.110384829835828
Validation loss: 2.9774420235505867

Epoch: 6| Step: 4
Training loss: 3.5123066479012905
Validation loss: 2.9835058878593244

Epoch: 6| Step: 5
Training loss: 2.658867477597884
Validation loss: 2.9828178184357568

Epoch: 6| Step: 6
Training loss: 2.9704642717093828
Validation loss: 2.984428124818543

Epoch: 6| Step: 7
Training loss: 2.4109153603150966
Validation loss: 2.9932422203969073

Epoch: 6| Step: 8
Training loss: 3.6055930664849
Validation loss: 3.0073423306071794

Epoch: 6| Step: 9
Training loss: 3.2426960373957936
Validation loss: 3.001768058614549

Epoch: 6| Step: 10
Training loss: 4.07045260900292
Validation loss: 2.9971380391876052

Epoch: 6| Step: 11
Training loss: 3.427913267678682
Validation loss: 2.9963966369798967

Epoch: 6| Step: 12
Training loss: 3.624024226960302
Validation loss: 2.981906544552965

Epoch: 6| Step: 13
Training loss: 3.5837442177285794
Validation loss: 2.977712087815289

Epoch: 85| Step: 0
Training loss: 3.3090600920241617
Validation loss: 2.9752968706637213

Epoch: 6| Step: 1
Training loss: 3.1457254926037166
Validation loss: 2.9773914191839395

Epoch: 6| Step: 2
Training loss: 2.63504431786809
Validation loss: 2.979342436443937

Epoch: 6| Step: 3
Training loss: 3.3982967654498473
Validation loss: 2.980700099864747

Epoch: 6| Step: 4
Training loss: 3.135864749629089
Validation loss: 2.983276539565185

Epoch: 6| Step: 5
Training loss: 2.9865107857806215
Validation loss: 2.9842044193357493

Epoch: 6| Step: 6
Training loss: 3.0861487207678078
Validation loss: 2.9848431314178403

Epoch: 6| Step: 7
Training loss: 3.0339470888677864
Validation loss: 2.9861647729296132

Epoch: 6| Step: 8
Training loss: 3.32157748191786
Validation loss: 2.9810687847719612

Epoch: 6| Step: 9
Training loss: 4.21383946344443
Validation loss: 2.9798241551011992

Epoch: 6| Step: 10
Training loss: 3.112374397409225
Validation loss: 2.9855974422526836

Epoch: 6| Step: 11
Training loss: 3.589790883468859
Validation loss: 2.982282507470754

Epoch: 6| Step: 12
Training loss: 3.3800024470484074
Validation loss: 2.9803983840008548

Epoch: 6| Step: 13
Training loss: 3.0733507959637913
Validation loss: 2.980862961890357

Epoch: 86| Step: 0
Training loss: 3.2449098486934056
Validation loss: 2.978382063785598

Epoch: 6| Step: 1
Training loss: 3.53942815310623
Validation loss: 2.975434024531771

Epoch: 6| Step: 2
Training loss: 3.2885479377313818
Validation loss: 2.9754954466602466

Epoch: 6| Step: 3
Training loss: 3.3010516716149527
Validation loss: 2.9731740236095727

Epoch: 6| Step: 4
Training loss: 3.0081374748346996
Validation loss: 2.9721496132184217

Epoch: 6| Step: 5
Training loss: 3.6983364386342785
Validation loss: 2.977670939617106

Epoch: 6| Step: 6
Training loss: 3.064876335101123
Validation loss: 2.973241402208555

Epoch: 6| Step: 7
Training loss: 3.2099598976553687
Validation loss: 2.9823430991488884

Epoch: 6| Step: 8
Training loss: 3.077987745294101
Validation loss: 2.977936816474645

Epoch: 6| Step: 9
Training loss: 2.835347263926531
Validation loss: 2.991267603910206

Epoch: 6| Step: 10
Training loss: 3.6110191398711287
Validation loss: 2.9925847307803144

Epoch: 6| Step: 11
Training loss: 3.6253832910408255
Validation loss: 3.0029256460191136

Epoch: 6| Step: 12
Training loss: 2.9697471148787344
Validation loss: 2.987100978158137

Epoch: 6| Step: 13
Training loss: 2.8175430014306593
Validation loss: 2.970374047745146

Epoch: 87| Step: 0
Training loss: 3.4786891647650426
Validation loss: 2.9682514525504535

Epoch: 6| Step: 1
Training loss: 3.184742351752477
Validation loss: 2.9713725278310665

Epoch: 6| Step: 2
Training loss: 3.2848215193432395
Validation loss: 2.973425531665275

Epoch: 6| Step: 3
Training loss: 2.663167674562699
Validation loss: 2.985252350625647

Epoch: 6| Step: 4
Training loss: 3.500071797315699
Validation loss: 2.989904259476044

Epoch: 6| Step: 5
Training loss: 3.4059669307015046
Validation loss: 2.991894894268119

Epoch: 6| Step: 6
Training loss: 3.6381901142091113
Validation loss: 3.0071541056942177

Epoch: 6| Step: 7
Training loss: 3.507795372052421
Validation loss: 2.9919347098034175

Epoch: 6| Step: 8
Training loss: 3.4423516454706102
Validation loss: 2.9836025938266615

Epoch: 6| Step: 9
Training loss: 2.959833508010476
Validation loss: 2.978730400756683

Epoch: 6| Step: 10
Training loss: 3.038291068342004
Validation loss: 2.9725229412552694

Epoch: 6| Step: 11
Training loss: 3.6760825865707334
Validation loss: 2.9726664367383093

Epoch: 6| Step: 12
Training loss: 2.8721508337807236
Validation loss: 2.9726087559847474

Epoch: 6| Step: 13
Training loss: 2.6545629192575873
Validation loss: 2.9728033644316407

Epoch: 88| Step: 0
Training loss: 2.855443033293054
Validation loss: 2.971175900677335

Epoch: 6| Step: 1
Training loss: 3.2931503300136993
Validation loss: 2.972186093869038

Epoch: 6| Step: 2
Training loss: 3.956323588622476
Validation loss: 2.9720317747423457

Epoch: 6| Step: 3
Training loss: 3.7209572532554307
Validation loss: 2.978277525655384

Epoch: 6| Step: 4
Training loss: 3.2523075128314693
Validation loss: 2.973663117733395

Epoch: 6| Step: 5
Training loss: 3.1006429928313484
Validation loss: 2.9707341573959916

Epoch: 6| Step: 6
Training loss: 3.264563867202171
Validation loss: 2.9711083225114203

Epoch: 6| Step: 7
Training loss: 2.946468379424715
Validation loss: 2.9694609140025805

Epoch: 6| Step: 8
Training loss: 3.809342749868292
Validation loss: 2.969266430981796

Epoch: 6| Step: 9
Training loss: 2.7027897268538426
Validation loss: 2.9715131559092574

Epoch: 6| Step: 10
Training loss: 2.8377800622604097
Validation loss: 2.970316461432505

Epoch: 6| Step: 11
Training loss: 2.6246457542081765
Validation loss: 2.9714219957703984

Epoch: 6| Step: 12
Training loss: 3.7302973363350356
Validation loss: 2.9704873442314903

Epoch: 6| Step: 13
Training loss: 3.1080104574962824
Validation loss: 2.970120819126929

Epoch: 89| Step: 0
Training loss: 3.517924866221546
Validation loss: 2.968566648804622

Epoch: 6| Step: 1
Training loss: 3.225707894634725
Validation loss: 2.969907174782376

Epoch: 6| Step: 2
Training loss: 2.8693144598249165
Validation loss: 2.9684460573417106

Epoch: 6| Step: 3
Training loss: 3.28975541524574
Validation loss: 2.966443329004647

Epoch: 6| Step: 4
Training loss: 3.2309835593426017
Validation loss: 2.9682315548592153

Epoch: 6| Step: 5
Training loss: 3.7888271612643627
Validation loss: 2.9688260969459703

Epoch: 6| Step: 6
Training loss: 2.9166730789840694
Validation loss: 2.9666568719532367

Epoch: 6| Step: 7
Training loss: 3.048975606768835
Validation loss: 2.9657925912186167

Epoch: 6| Step: 8
Training loss: 3.202542731233033
Validation loss: 2.9684872004149345

Epoch: 6| Step: 9
Training loss: 3.215282164630868
Validation loss: 2.96652179683228

Epoch: 6| Step: 10
Training loss: 3.1448220823387496
Validation loss: 2.9660602398667226

Epoch: 6| Step: 11
Training loss: 2.8965724486672895
Validation loss: 2.9674843837008082

Epoch: 6| Step: 12
Training loss: 3.875768277700776
Validation loss: 2.9671866254968258

Epoch: 6| Step: 13
Training loss: 3.1797984710749185
Validation loss: 2.965568921911526

Epoch: 90| Step: 0
Training loss: 3.375468892621609
Validation loss: 2.9643328738847643

Epoch: 6| Step: 1
Training loss: 2.3080255677378854
Validation loss: 2.9654645285984733

Epoch: 6| Step: 2
Training loss: 2.692536713217921
Validation loss: 2.9635773245037034

Epoch: 6| Step: 3
Training loss: 3.3889974740008557
Validation loss: 2.9675475694351263

Epoch: 6| Step: 4
Training loss: 3.7297770393148824
Validation loss: 2.96281568130265

Epoch: 6| Step: 5
Training loss: 2.9464499303530745
Validation loss: 2.965424268614354

Epoch: 6| Step: 6
Training loss: 3.820894099549306
Validation loss: 2.965081575840931

Epoch: 6| Step: 7
Training loss: 3.550712223871843
Validation loss: 2.964913348993209

Epoch: 6| Step: 8
Training loss: 3.1268988371692847
Validation loss: 2.962333727285708

Epoch: 6| Step: 9
Training loss: 3.2092607487118676
Validation loss: 2.9615239314740647

Epoch: 6| Step: 10
Training loss: 2.70431606975236
Validation loss: 2.963862836724123

Epoch: 6| Step: 11
Training loss: 3.2248795302017044
Validation loss: 2.9655227399208104

Epoch: 6| Step: 12
Training loss: 3.3320259550349927
Validation loss: 2.9652563793664237

Epoch: 6| Step: 13
Training loss: 4.0690306770328935
Validation loss: 2.9622697431869613

Epoch: 91| Step: 0
Training loss: 3.034613247759352
Validation loss: 2.9629325555757364

Epoch: 6| Step: 1
Training loss: 3.067962290555732
Validation loss: 2.962724052801741

Epoch: 6| Step: 2
Training loss: 3.2075296031034783
Validation loss: 2.965320402766034

Epoch: 6| Step: 3
Training loss: 4.01782047799956
Validation loss: 2.965477180511961

Epoch: 6| Step: 4
Training loss: 3.1080414485843275
Validation loss: 2.962239266005315

Epoch: 6| Step: 5
Training loss: 2.828435722690218
Validation loss: 2.9654425131893754

Epoch: 6| Step: 6
Training loss: 3.403387844559536
Validation loss: 2.9645474128661893

Epoch: 6| Step: 7
Training loss: 3.5964676905601647
Validation loss: 2.9664210425809006

Epoch: 6| Step: 8
Training loss: 3.4668763745286113
Validation loss: 2.964370402030991

Epoch: 6| Step: 9
Training loss: 3.4532630858278677
Validation loss: 2.9635626679363396

Epoch: 6| Step: 10
Training loss: 3.0713305156681865
Validation loss: 2.965180323089957

Epoch: 6| Step: 11
Training loss: 2.5264259806347424
Validation loss: 2.963649630501576

Epoch: 6| Step: 12
Training loss: 3.27606576365881
Validation loss: 2.9633050126237976

Epoch: 6| Step: 13
Training loss: 3.1916825024350555
Validation loss: 2.9609127512809965

Epoch: 92| Step: 0
Training loss: 2.634990029361399
Validation loss: 2.961256774906506

Epoch: 6| Step: 1
Training loss: 3.2388551799342484
Validation loss: 2.958743697086336

Epoch: 6| Step: 2
Training loss: 3.081904380904299
Validation loss: 2.962407997786206

Epoch: 6| Step: 3
Training loss: 2.98685691647624
Validation loss: 2.959120194436926

Epoch: 6| Step: 4
Training loss: 3.854734650421309
Validation loss: 2.9577245624636355

Epoch: 6| Step: 5
Training loss: 2.9582268780820433
Validation loss: 2.9573800837359534

Epoch: 6| Step: 6
Training loss: 3.7071292651195296
Validation loss: 2.956298848395312

Epoch: 6| Step: 7
Training loss: 3.1537377963319484
Validation loss: 2.9545429604196607

Epoch: 6| Step: 8
Training loss: 3.612496483612989
Validation loss: 2.9572221927302826

Epoch: 6| Step: 9
Training loss: 3.113873318956439
Validation loss: 2.954585570853217

Epoch: 6| Step: 10
Training loss: 3.4417509670570707
Validation loss: 2.958192034796972

Epoch: 6| Step: 11
Training loss: 3.3360489909281976
Validation loss: 2.955594478023153

Epoch: 6| Step: 12
Training loss: 2.7944246778890833
Validation loss: 2.956488633125861

Epoch: 6| Step: 13
Training loss: 3.31446736770474
Validation loss: 2.954227984414964

Epoch: 93| Step: 0
Training loss: 2.6958172753949987
Validation loss: 2.954494218147542

Epoch: 6| Step: 1
Training loss: 3.0199588606097585
Validation loss: 2.9576263750016842

Epoch: 6| Step: 2
Training loss: 2.794584135259518
Validation loss: 2.9585244375432733

Epoch: 6| Step: 3
Training loss: 2.901310650850201
Validation loss: 2.9610828443316235

Epoch: 6| Step: 4
Training loss: 2.835772717104841
Validation loss: 2.9689711638939325

Epoch: 6| Step: 5
Training loss: 3.1332779155727346
Validation loss: 2.9677892437508535

Epoch: 6| Step: 6
Training loss: 3.5107920339385537
Validation loss: 2.9719372136913265

Epoch: 6| Step: 7
Training loss: 3.251118394181959
Validation loss: 2.9725693292783943

Epoch: 6| Step: 8
Training loss: 2.8961017584863646
Validation loss: 2.9648027932915504

Epoch: 6| Step: 9
Training loss: 3.7020894465756466
Validation loss: 2.9707832398706104

Epoch: 6| Step: 10
Training loss: 3.1618472786491405
Validation loss: 2.956725646618935

Epoch: 6| Step: 11
Training loss: 3.8619020659693937
Validation loss: 2.9543516267224925

Epoch: 6| Step: 12
Training loss: 4.18313097420036
Validation loss: 2.95170790265411

Epoch: 6| Step: 13
Training loss: 2.94255880240362
Validation loss: 2.9527443452038784

Epoch: 94| Step: 0
Training loss: 3.629932861968312
Validation loss: 2.952701932204365

Epoch: 6| Step: 1
Training loss: 3.517721271726434
Validation loss: 2.9536562726743725

Epoch: 6| Step: 2
Training loss: 3.687479568683467
Validation loss: 2.953971795642445

Epoch: 6| Step: 3
Training loss: 3.508158847218075
Validation loss: 2.9563996727251793

Epoch: 6| Step: 4
Training loss: 2.969908799334954
Validation loss: 2.9551476364798828

Epoch: 6| Step: 5
Training loss: 3.5510868826453263
Validation loss: 2.9561920047938655

Epoch: 6| Step: 6
Training loss: 2.6383729619969727
Validation loss: 2.957738580557906

Epoch: 6| Step: 7
Training loss: 3.376295335642521
Validation loss: 2.957377259497965

Epoch: 6| Step: 8
Training loss: 2.1991103367483316
Validation loss: 2.955882703204841

Epoch: 6| Step: 9
Training loss: 3.512910464593565
Validation loss: 2.9572012013367988

Epoch: 6| Step: 10
Training loss: 3.3947180728401265
Validation loss: 2.9531705129788013

Epoch: 6| Step: 11
Training loss: 3.0051035386209293
Validation loss: 2.9547455761870354

Epoch: 6| Step: 12
Training loss: 2.825709032860799
Validation loss: 2.954185321962496

Epoch: 6| Step: 13
Training loss: 3.3257938154474718
Validation loss: 2.950113879898379

Epoch: 95| Step: 0
Training loss: 2.843777331545769
Validation loss: 2.950960592664452

Epoch: 6| Step: 1
Training loss: 3.4492107317821583
Validation loss: 2.9493953237718253

Epoch: 6| Step: 2
Training loss: 3.5148527526401017
Validation loss: 2.9487079454266656

Epoch: 6| Step: 3
Training loss: 3.040999474357
Validation loss: 2.9483881359247057

Epoch: 6| Step: 4
Training loss: 3.207673207197829
Validation loss: 2.948394394620935

Epoch: 6| Step: 5
Training loss: 3.1419905545331277
Validation loss: 2.9482106783591044

Epoch: 6| Step: 6
Training loss: 3.4248763904402333
Validation loss: 2.949684582306064

Epoch: 6| Step: 7
Training loss: 3.2832625257212036
Validation loss: 2.9519491055756695

Epoch: 6| Step: 8
Training loss: 3.650530261884173
Validation loss: 2.9516262772744244

Epoch: 6| Step: 9
Training loss: 2.824388427702456
Validation loss: 2.9506939619073447

Epoch: 6| Step: 10
Training loss: 3.5176906366480174
Validation loss: 2.951536240073254

Epoch: 6| Step: 11
Training loss: 3.272233910171829
Validation loss: 2.949732739185373

Epoch: 6| Step: 12
Training loss: 3.1175907036771675
Validation loss: 2.9491855892475867

Epoch: 6| Step: 13
Training loss: 2.7070644536259576
Validation loss: 2.9485046717473162

Epoch: 96| Step: 0
Training loss: 2.4448306062834724
Validation loss: 2.948803007957358

Epoch: 6| Step: 1
Training loss: 3.6862850450652456
Validation loss: 2.9496538864372157

Epoch: 6| Step: 2
Training loss: 3.6816493026671604
Validation loss: 2.948446713949701

Epoch: 6| Step: 3
Training loss: 2.542814797987221
Validation loss: 2.9472327641153124

Epoch: 6| Step: 4
Training loss: 2.7135952720301755
Validation loss: 2.9463989972993465

Epoch: 6| Step: 5
Training loss: 3.3673078688063547
Validation loss: 2.947247494062185

Epoch: 6| Step: 6
Training loss: 3.3976022680524274
Validation loss: 2.9454348967857262

Epoch: 6| Step: 7
Training loss: 3.1414909118006027
Validation loss: 2.9467487695167702

Epoch: 6| Step: 8
Training loss: 3.401162644357665
Validation loss: 2.946229828995336

Epoch: 6| Step: 9
Training loss: 3.5356695824641626
Validation loss: 2.9421519176051603

Epoch: 6| Step: 10
Training loss: 3.2864646528679997
Validation loss: 2.94463428774809

Epoch: 6| Step: 11
Training loss: 2.812633765536431
Validation loss: 2.945170804540882

Epoch: 6| Step: 12
Training loss: 3.3645690508245054
Validation loss: 2.94298312274234

Epoch: 6| Step: 13
Training loss: 3.831529248065866
Validation loss: 2.9399203442261914

Epoch: 97| Step: 0
Training loss: 3.808807335757855
Validation loss: 2.9450629391804193

Epoch: 6| Step: 1
Training loss: 3.6662760150765497
Validation loss: 2.9429602126513417

Epoch: 6| Step: 2
Training loss: 3.3520624103608365
Validation loss: 2.9418146566512786

Epoch: 6| Step: 3
Training loss: 3.3702166533514344
Validation loss: 2.9396433624149836

Epoch: 6| Step: 4
Training loss: 2.7003822303353444
Validation loss: 2.938872158897902

Epoch: 6| Step: 5
Training loss: 3.0502250838477134
Validation loss: 2.939039435694157

Epoch: 6| Step: 6
Training loss: 3.3677737263400243
Validation loss: 2.939371251759504

Epoch: 6| Step: 7
Training loss: 2.6452852016782185
Validation loss: 2.940144312396381

Epoch: 6| Step: 8
Training loss: 2.7079762932600424
Validation loss: 2.939113790674001

Epoch: 6| Step: 9
Training loss: 2.736958182726609
Validation loss: 2.940032724141589

Epoch: 6| Step: 10
Training loss: 3.5379945604747234
Validation loss: 2.9356567623364755

Epoch: 6| Step: 11
Training loss: 3.6425485400105524
Validation loss: 2.9353341893874805

Epoch: 6| Step: 12
Training loss: 3.277089269349352
Validation loss: 2.937493859474259

Epoch: 6| Step: 13
Training loss: 2.8003270673463394
Validation loss: 2.9338949507193806

Epoch: 98| Step: 0
Training loss: 3.183527546761801
Validation loss: 2.9346465200068006

Epoch: 6| Step: 1
Training loss: 2.206915874334951
Validation loss: 2.932835289502649

Epoch: 6| Step: 2
Training loss: 3.5627937865002113
Validation loss: 2.9337897571619114

Epoch: 6| Step: 3
Training loss: 2.7688765727232383
Validation loss: 2.9337052178991785

Epoch: 6| Step: 4
Training loss: 2.775890630128606
Validation loss: 2.9320742406057105

Epoch: 6| Step: 5
Training loss: 2.971603788722251
Validation loss: 2.933004251415564

Epoch: 6| Step: 6
Training loss: 3.8084863266100335
Validation loss: 2.93518940945088

Epoch: 6| Step: 7
Training loss: 3.288193105294316
Validation loss: 2.933562274031735

Epoch: 6| Step: 8
Training loss: 3.0777971896750254
Validation loss: 2.9327701286150987

Epoch: 6| Step: 9
Training loss: 3.1172031029332246
Validation loss: 2.931999523487312

Epoch: 6| Step: 10
Training loss: 2.7118245633075535
Validation loss: 2.9319521394632595

Epoch: 6| Step: 11
Training loss: 3.5932423108615192
Validation loss: 2.9316740821468916

Epoch: 6| Step: 12
Training loss: 3.7790334210499
Validation loss: 2.9322918295739577

Epoch: 6| Step: 13
Training loss: 4.238552608680554
Validation loss: 2.932274332579766

Epoch: 99| Step: 0
Training loss: 2.8255428096543596
Validation loss: 2.931855461158032

Epoch: 6| Step: 1
Training loss: 3.5622087326106397
Validation loss: 2.9297476542323477

Epoch: 6| Step: 2
Training loss: 2.69443300797525
Validation loss: 2.9320126555605506

Epoch: 6| Step: 3
Training loss: 3.4170205157889035
Validation loss: 2.9312078653307965

Epoch: 6| Step: 4
Training loss: 2.91460014885575
Validation loss: 2.9323416831512157

Epoch: 6| Step: 5
Training loss: 3.2524278815423084
Validation loss: 2.930710959994606

Epoch: 6| Step: 6
Training loss: 2.113488037371527
Validation loss: 2.9292945525007927

Epoch: 6| Step: 7
Training loss: 3.710627042934632
Validation loss: 2.9347156060557795

Epoch: 6| Step: 8
Training loss: 2.938896334309592
Validation loss: 2.9356488530587925

Epoch: 6| Step: 9
Training loss: 3.6675563657624846
Validation loss: 2.933522953502961

Epoch: 6| Step: 10
Training loss: 3.385393316726366
Validation loss: 2.93103175890218

Epoch: 6| Step: 11
Training loss: 3.4687344662430197
Validation loss: 2.932769298185559

Epoch: 6| Step: 12
Training loss: 3.834443650256792
Validation loss: 2.927313545559219

Epoch: 6| Step: 13
Training loss: 2.5434706700926557
Validation loss: 2.9302073841478316

Epoch: 100| Step: 0
Training loss: 3.8074980895951227
Validation loss: 2.9310523604460337

Epoch: 6| Step: 1
Training loss: 3.817303992175205
Validation loss: 2.9294582149791095

Epoch: 6| Step: 2
Training loss: 3.390469595868008
Validation loss: 2.927922473891561

Epoch: 6| Step: 3
Training loss: 3.095496407234573
Validation loss: 2.9281721525197333

Epoch: 6| Step: 4
Training loss: 3.7588556630157726
Validation loss: 2.9282207052115274

Epoch: 6| Step: 5
Training loss: 2.707269126932317
Validation loss: 2.9287348484025193

Epoch: 6| Step: 6
Training loss: 3.521121733702174
Validation loss: 2.930143412456548

Epoch: 6| Step: 7
Training loss: 3.479171082880259
Validation loss: 2.927446618627356

Epoch: 6| Step: 8
Training loss: 2.810275660531808
Validation loss: 2.928927056395749

Epoch: 6| Step: 9
Training loss: 2.6993560976893303
Validation loss: 2.9274060967610502

Epoch: 6| Step: 10
Training loss: 3.1422588596369327
Validation loss: 2.9277913356881498

Epoch: 6| Step: 11
Training loss: 2.055396360241224
Validation loss: 2.926641489931099

Epoch: 6| Step: 12
Training loss: 3.3643933095899725
Validation loss: 2.9280192522886055

Epoch: 6| Step: 13
Training loss: 2.6587251687336293
Validation loss: 2.9276647765730726

Epoch: 101| Step: 0
Training loss: 3.739705259979529
Validation loss: 2.9328659227663696

Epoch: 6| Step: 1
Training loss: 3.5883415325075254
Validation loss: 2.9276939385521206

Epoch: 6| Step: 2
Training loss: 3.121661119131959
Validation loss: 2.9293749308225934

Epoch: 6| Step: 3
Training loss: 3.3726176578027127
Validation loss: 2.9275633347914267

Epoch: 6| Step: 4
Training loss: 3.3539086157690234
Validation loss: 2.9268093921734484

Epoch: 6| Step: 5
Training loss: 3.678897456986731
Validation loss: 2.9303154831406397

Epoch: 6| Step: 6
Training loss: 3.3288642169811697
Validation loss: 2.9325406448891522

Epoch: 6| Step: 7
Training loss: 2.4815980758393907
Validation loss: 2.9319779466786406

Epoch: 6| Step: 8
Training loss: 3.0553191719711945
Validation loss: 2.927526848026105

Epoch: 6| Step: 9
Training loss: 2.948168273181195
Validation loss: 2.9290342048541693

Epoch: 6| Step: 10
Training loss: 3.060841481064413
Validation loss: 2.922369739112309

Epoch: 6| Step: 11
Training loss: 2.933987079365682
Validation loss: 2.9226545709024805

Epoch: 6| Step: 12
Training loss: 2.944509381551853
Validation loss: 2.926601318696196

Epoch: 6| Step: 13
Training loss: 3.1805417274792696
Validation loss: 2.9203288767395543

Epoch: 102| Step: 0
Training loss: 3.3792948769464384
Validation loss: 2.923705739105044

Epoch: 6| Step: 1
Training loss: 3.590454448105546
Validation loss: 2.920819874494724

Epoch: 6| Step: 2
Training loss: 3.3659320092681053
Validation loss: 2.9208083799468683

Epoch: 6| Step: 3
Training loss: 3.5993578073124426
Validation loss: 2.923961646027883

Epoch: 6| Step: 4
Training loss: 2.8642749597274832
Validation loss: 2.919277769470947

Epoch: 6| Step: 5
Training loss: 3.138848404824878
Validation loss: 2.923167822439219

Epoch: 6| Step: 6
Training loss: 2.950981694473994
Validation loss: 2.9243000691469385

Epoch: 6| Step: 7
Training loss: 2.6162566849886972
Validation loss: 2.9305346714894274

Epoch: 6| Step: 8
Training loss: 2.9587292652507546
Validation loss: 2.936684477145666

Epoch: 6| Step: 9
Training loss: 3.043346690064695
Validation loss: 2.9394202273616346

Epoch: 6| Step: 10
Training loss: 3.3777118666670836
Validation loss: 2.9230866384647842

Epoch: 6| Step: 11
Training loss: 2.7968997208339235
Validation loss: 2.920691915226692

Epoch: 6| Step: 12
Training loss: 3.4893981580804496
Validation loss: 2.920192862294404

Epoch: 6| Step: 13
Training loss: 3.890421053891532
Validation loss: 2.922363380817774

Epoch: 103| Step: 0
Training loss: 3.1450749845314014
Validation loss: 2.9249974482430265

Epoch: 6| Step: 1
Training loss: 3.198697039459058
Validation loss: 2.9350297901307396

Epoch: 6| Step: 2
Training loss: 2.587481910531763
Validation loss: 2.9500230804619454

Epoch: 6| Step: 3
Training loss: 3.380954857882252
Validation loss: 2.9498263686000117

Epoch: 6| Step: 4
Training loss: 3.676694653134483
Validation loss: 2.9505275100687345

Epoch: 6| Step: 5
Training loss: 3.14736594619882
Validation loss: 2.9377019773927646

Epoch: 6| Step: 6
Training loss: 3.6144223282690477
Validation loss: 2.9280869336256967

Epoch: 6| Step: 7
Training loss: 3.243235370480373
Validation loss: 2.918048255134788

Epoch: 6| Step: 8
Training loss: 2.6987322798160878
Validation loss: 2.918564115672998

Epoch: 6| Step: 9
Training loss: 3.275874794175482
Validation loss: 2.9191590982133593

Epoch: 6| Step: 10
Training loss: 3.700098015801485
Validation loss: 2.9202497620243864

Epoch: 6| Step: 11
Training loss: 2.8672028003253205
Validation loss: 2.924013004985508

Epoch: 6| Step: 12
Training loss: 3.208030851563008
Validation loss: 2.9194796683999513

Epoch: 6| Step: 13
Training loss: 3.1796089181398477
Validation loss: 2.9214090850256293

Epoch: 104| Step: 0
Training loss: 2.9596060222615503
Validation loss: 2.9193526822197025

Epoch: 6| Step: 1
Training loss: 2.9946823675140917
Validation loss: 2.920245702685801

Epoch: 6| Step: 2
Training loss: 2.590982914440221
Validation loss: 2.9184141107330914

Epoch: 6| Step: 3
Training loss: 3.208459050741593
Validation loss: 2.9164148851936327

Epoch: 6| Step: 4
Training loss: 3.4737124301214366
Validation loss: 2.9180342220802413

Epoch: 6| Step: 5
Training loss: 3.462532864080696
Validation loss: 2.918645300716218

Epoch: 6| Step: 6
Training loss: 3.2500962463212626
Validation loss: 2.9254250028260786

Epoch: 6| Step: 7
Training loss: 2.959232372806686
Validation loss: 2.920651907056065

Epoch: 6| Step: 8
Training loss: 3.0798994652329776
Validation loss: 2.921530101706263

Epoch: 6| Step: 9
Training loss: 4.300378986779147
Validation loss: 2.9242533362262026

Epoch: 6| Step: 10
Training loss: 2.731301722265956
Validation loss: 2.9262867334308664

Epoch: 6| Step: 11
Training loss: 3.2785530269093326
Validation loss: 2.929699617750477

Epoch: 6| Step: 12
Training loss: 3.1091882084086864
Validation loss: 2.92811012994039

Epoch: 6| Step: 13
Training loss: 3.2930851708735007
Validation loss: 2.9164602273992206

Epoch: 105| Step: 0
Training loss: 2.710038357565276
Validation loss: 2.9093075609502677

Epoch: 6| Step: 1
Training loss: 2.710523238397176
Validation loss: 2.9147138014275282

Epoch: 6| Step: 2
Training loss: 3.213894487216931
Validation loss: 2.9146705491659963

Epoch: 6| Step: 3
Training loss: 3.3470388619908134
Validation loss: 2.9205978679452023

Epoch: 6| Step: 4
Training loss: 3.5002645665038608
Validation loss: 2.919728828337492

Epoch: 6| Step: 5
Training loss: 3.8442623138161056
Validation loss: 2.926369922383092

Epoch: 6| Step: 6
Training loss: 3.1631629701275172
Validation loss: 2.921817834477083

Epoch: 6| Step: 7
Training loss: 3.096313185403255
Validation loss: 2.9309910224521825

Epoch: 6| Step: 8
Training loss: 3.5663754983100544
Validation loss: 2.9228639603186215

Epoch: 6| Step: 9
Training loss: 3.379749488350269
Validation loss: 2.9168534941247533

Epoch: 6| Step: 10
Training loss: 2.955384374105347
Validation loss: 2.9133055764905333

Epoch: 6| Step: 11
Training loss: 2.9709496630933963
Validation loss: 2.9106383441967236

Epoch: 6| Step: 12
Training loss: 3.117303143414104
Validation loss: 2.909949784664035

Epoch: 6| Step: 13
Training loss: 3.0621410860214597
Validation loss: 2.9112566374828996

Epoch: 106| Step: 0
Training loss: 3.0803369620157706
Validation loss: 2.91219715658381

Epoch: 6| Step: 1
Training loss: 3.679925024056635
Validation loss: 2.9119240227320655

Epoch: 6| Step: 2
Training loss: 2.540435325984075
Validation loss: 2.9129662228026194

Epoch: 6| Step: 3
Training loss: 2.426169347508394
Validation loss: 2.9117323951363274

Epoch: 6| Step: 4
Training loss: 3.4997087084943974
Validation loss: 2.9119947685791727

Epoch: 6| Step: 5
Training loss: 2.7873777970012124
Validation loss: 2.9116658374864954

Epoch: 6| Step: 6
Training loss: 3.0279367173812157
Validation loss: 2.9129467061035452

Epoch: 6| Step: 7
Training loss: 3.386813645314844
Validation loss: 2.914767258312952

Epoch: 6| Step: 8
Training loss: 2.806770762357831
Validation loss: 2.9152425925416763

Epoch: 6| Step: 9
Training loss: 3.0334928414741484
Validation loss: 2.916249487673044

Epoch: 6| Step: 10
Training loss: 4.207232542189996
Validation loss: 2.9147495584912444

Epoch: 6| Step: 11
Training loss: 3.1937274312455552
Validation loss: 2.9150130745400302

Epoch: 6| Step: 12
Training loss: 3.459249872909955
Validation loss: 2.911437076556531

Epoch: 6| Step: 13
Training loss: 3.4228363776856474
Validation loss: 2.910764564703341

Epoch: 107| Step: 0
Training loss: 2.934925005862852
Validation loss: 2.909598802966886

Epoch: 6| Step: 1
Training loss: 2.704343311749219
Validation loss: 2.9068044715081807

Epoch: 6| Step: 2
Training loss: 2.8307557068217846
Validation loss: 2.907159199749693

Epoch: 6| Step: 3
Training loss: 3.5682765239081764
Validation loss: 2.9052817144885257

Epoch: 6| Step: 4
Training loss: 3.079075700365144
Validation loss: 2.905844840235201

Epoch: 6| Step: 5
Training loss: 3.0514334202590634
Validation loss: 2.906492777323443

Epoch: 6| Step: 6
Training loss: 3.051468736308703
Validation loss: 2.908017311294103

Epoch: 6| Step: 7
Training loss: 3.099734288795221
Validation loss: 2.9111412269394807

Epoch: 6| Step: 8
Training loss: 3.4682710334086697
Validation loss: 2.9152469683923385

Epoch: 6| Step: 9
Training loss: 3.0405519263022835
Validation loss: 2.921067131489531

Epoch: 6| Step: 10
Training loss: 3.542138790002673
Validation loss: 2.931273727378683

Epoch: 6| Step: 11
Training loss: 3.879071711365871
Validation loss: 2.9405308013743565

Epoch: 6| Step: 12
Training loss: 3.466063412728435
Validation loss: 2.9350510763527553

Epoch: 6| Step: 13
Training loss: 2.835396034526292
Validation loss: 2.930452674178656

Epoch: 108| Step: 0
Training loss: 3.085508369836256
Validation loss: 2.9122314612404487

Epoch: 6| Step: 1
Training loss: 3.1115970818602636
Validation loss: 2.906771839373177

Epoch: 6| Step: 2
Training loss: 3.2459885709870444
Validation loss: 2.9047674957745695

Epoch: 6| Step: 3
Training loss: 3.3743599178728223
Validation loss: 2.9043804095753587

Epoch: 6| Step: 4
Training loss: 2.9579612247177267
Validation loss: 2.905421030844263

Epoch: 6| Step: 5
Training loss: 3.128756744584767
Validation loss: 2.9078467837726962

Epoch: 6| Step: 6
Training loss: 3.3338281899927935
Validation loss: 2.9081346300515403

Epoch: 6| Step: 7
Training loss: 3.6018627645644496
Validation loss: 2.9112034058551606

Epoch: 6| Step: 8
Training loss: 2.4965915332824506
Validation loss: 2.9143032418914254

Epoch: 6| Step: 9
Training loss: 3.4491432674179836
Validation loss: 2.911154346547616

Epoch: 6| Step: 10
Training loss: 3.826981105003232
Validation loss: 2.9093257238961665

Epoch: 6| Step: 11
Training loss: 3.446608803396803
Validation loss: 2.9089115766678773

Epoch: 6| Step: 12
Training loss: 2.908972992457924
Validation loss: 2.90723909749591

Epoch: 6| Step: 13
Training loss: 2.2016336790968642
Validation loss: 2.9089609364241764

Epoch: 109| Step: 0
Training loss: 3.3147218558191747
Validation loss: 2.906024406746441

Epoch: 6| Step: 1
Training loss: 3.5380767729490747
Validation loss: 2.906266701877786

Epoch: 6| Step: 2
Training loss: 3.3601368594679992
Validation loss: 2.908521399949268

Epoch: 6| Step: 3
Training loss: 2.102449931706349
Validation loss: 2.9057373589767916

Epoch: 6| Step: 4
Training loss: 3.096117751215953
Validation loss: 2.906233028098116

Epoch: 6| Step: 5
Training loss: 3.233166455029455
Validation loss: 2.903242093271856

Epoch: 6| Step: 6
Training loss: 3.2703490334049925
Validation loss: 2.9013063564797563

Epoch: 6| Step: 7
Training loss: 3.7826994332673864
Validation loss: 2.9001816929924282

Epoch: 6| Step: 8
Training loss: 3.0346999838038715
Validation loss: 2.903031097825254

Epoch: 6| Step: 9
Training loss: 3.3665238365871657
Validation loss: 2.906349332154799

Epoch: 6| Step: 10
Training loss: 2.9694036466886367
Validation loss: 2.912508869646159

Epoch: 6| Step: 11
Training loss: 3.141420481890791
Validation loss: 2.911473638163495

Epoch: 6| Step: 12
Training loss: 2.971003911568228
Validation loss: 2.90794076914307

Epoch: 6| Step: 13
Training loss: 3.469809705369949
Validation loss: 2.9031164005133236

Epoch: 110| Step: 0
Training loss: 3.2625414147799408
Validation loss: 2.904379519833041

Epoch: 6| Step: 1
Training loss: 3.014360073621329
Validation loss: 2.9011592651528435

Epoch: 6| Step: 2
Training loss: 2.855012160507466
Validation loss: 2.9029941764388436

Epoch: 6| Step: 3
Training loss: 3.088943909841908
Validation loss: 2.902065251537171

Epoch: 6| Step: 4
Training loss: 2.6304025005521283
Validation loss: 2.9016154792448754

Epoch: 6| Step: 5
Training loss: 3.1644188950997862
Validation loss: 2.900609336559889

Epoch: 6| Step: 6
Training loss: 2.2486190796804446
Validation loss: 2.898712264585856

Epoch: 6| Step: 7
Training loss: 3.201616034146278
Validation loss: 2.896760677128702

Epoch: 6| Step: 8
Training loss: 3.714025108396326
Validation loss: 2.8955351938025418

Epoch: 6| Step: 9
Training loss: 2.953719952108012
Validation loss: 2.8972692965519196

Epoch: 6| Step: 10
Training loss: 3.4057156204877526
Validation loss: 2.8958287531551727

Epoch: 6| Step: 11
Training loss: 3.050263071440343
Validation loss: 2.8954480740386104

Epoch: 6| Step: 12
Training loss: 3.8092628869323595
Validation loss: 2.898759269538044

Epoch: 6| Step: 13
Training loss: 4.380309452639038
Validation loss: 2.899810779679823

Epoch: 111| Step: 0
Training loss: 3.2038845743349778
Validation loss: 2.89645385261435

Epoch: 6| Step: 1
Training loss: 3.2362733144498645
Validation loss: 2.8988607217200033

Epoch: 6| Step: 2
Training loss: 3.094915305413165
Validation loss: 2.90023290026378

Epoch: 6| Step: 3
Training loss: 3.0597242894345817
Validation loss: 2.8966254473499826

Epoch: 6| Step: 4
Training loss: 2.707519663336899
Validation loss: 2.896739104225797

Epoch: 6| Step: 5
Training loss: 3.3079634497305768
Validation loss: 2.8999146049693136

Epoch: 6| Step: 6
Training loss: 3.3917997935518795
Validation loss: 2.8967468825608433

Epoch: 6| Step: 7
Training loss: 3.3785830657399103
Validation loss: 2.899176722212773

Epoch: 6| Step: 8
Training loss: 3.152937860294571
Validation loss: 2.897281965766483

Epoch: 6| Step: 9
Training loss: 3.615600633333043
Validation loss: 2.898290347990967

Epoch: 6| Step: 10
Training loss: 2.2951569651861568
Validation loss: 2.894123406199322

Epoch: 6| Step: 11
Training loss: 2.8616052486854646
Validation loss: 2.8944906127516266

Epoch: 6| Step: 12
Training loss: 4.0594200783708825
Validation loss: 2.894349468235145

Epoch: 6| Step: 13
Training loss: 2.8117712136281794
Validation loss: 2.8919104434316765

Epoch: 112| Step: 0
Training loss: 2.9547360178707565
Validation loss: 2.893304646941773

Epoch: 6| Step: 1
Training loss: 3.139293179502373
Validation loss: 2.893603713847084

Epoch: 6| Step: 2
Training loss: 3.479316495002992
Validation loss: 2.89657584021552

Epoch: 6| Step: 3
Training loss: 3.501548696930765
Validation loss: 2.892865996419483

Epoch: 6| Step: 4
Training loss: 2.8228444070236405
Validation loss: 2.893805225594565

Epoch: 6| Step: 5
Training loss: 3.243337992409643
Validation loss: 2.895546388489315

Epoch: 6| Step: 6
Training loss: 3.511632118387075
Validation loss: 2.8964322216647034

Epoch: 6| Step: 7
Training loss: 3.3943694222070264
Validation loss: 2.8958640856440496

Epoch: 6| Step: 8
Training loss: 2.9331763080992133
Validation loss: 2.894927977455371

Epoch: 6| Step: 9
Training loss: 3.3877160035131317
Validation loss: 2.8924934829208957

Epoch: 6| Step: 10
Training loss: 3.0533964350758462
Validation loss: 2.89451946329048

Epoch: 6| Step: 11
Training loss: 3.2592893038755277
Validation loss: 2.8951370920246364

Epoch: 6| Step: 12
Training loss: 2.730191938478879
Validation loss: 2.8955974448846593

Epoch: 6| Step: 13
Training loss: 3.074836019470121
Validation loss: 2.8939532089350735

Epoch: 113| Step: 0
Training loss: 3.164450087179137
Validation loss: 2.8956409298062966

Epoch: 6| Step: 1
Training loss: 2.7311884159503954
Validation loss: 2.8943696045746266

Epoch: 6| Step: 2
Training loss: 2.757811981287575
Validation loss: 2.8931039412568653

Epoch: 6| Step: 3
Training loss: 3.639856609412651
Validation loss: 2.892308701261855

Epoch: 6| Step: 4
Training loss: 2.753052837625499
Validation loss: 2.8936846157807485

Epoch: 6| Step: 5
Training loss: 3.3459169015546957
Validation loss: 2.890997154803701

Epoch: 6| Step: 6
Training loss: 3.227708220557686
Validation loss: 2.8925530661472503

Epoch: 6| Step: 7
Training loss: 3.7307965998360384
Validation loss: 2.8908040929920222

Epoch: 6| Step: 8
Training loss: 2.7988621988505074
Validation loss: 2.893424306829281

Epoch: 6| Step: 9
Training loss: 3.42381280524596
Validation loss: 2.8908680200343166

Epoch: 6| Step: 10
Training loss: 3.611326012370934
Validation loss: 2.8924957208481854

Epoch: 6| Step: 11
Training loss: 3.477693866561087
Validation loss: 2.895833123815645

Epoch: 6| Step: 12
Training loss: 2.595126602524409
Validation loss: 2.8956528084530935

Epoch: 6| Step: 13
Training loss: 3.0631769171772847
Validation loss: 2.8938915860076433

Epoch: 114| Step: 0
Training loss: 2.328472137173067
Validation loss: 2.892598902926334

Epoch: 6| Step: 1
Training loss: 3.568404274142814
Validation loss: 2.891611534752235

Epoch: 6| Step: 2
Training loss: 3.5312999620532195
Validation loss: 2.8935955717886275

Epoch: 6| Step: 3
Training loss: 2.948140292003664
Validation loss: 2.8913174470262297

Epoch: 6| Step: 4
Training loss: 3.3090021631228588
Validation loss: 2.8916733773746364

Epoch: 6| Step: 5
Training loss: 3.5018455544166
Validation loss: 2.8964451317472157

Epoch: 6| Step: 6
Training loss: 3.0723235166688845
Validation loss: 2.8952722585014907

Epoch: 6| Step: 7
Training loss: 3.0332361380407247
Validation loss: 2.889144357726546

Epoch: 6| Step: 8
Training loss: 3.346860490584066
Validation loss: 2.891968046774754

Epoch: 6| Step: 9
Training loss: 3.1194523205935596
Validation loss: 2.891134965739231

Epoch: 6| Step: 10
Training loss: 3.315125774224227
Validation loss: 2.891107960413944

Epoch: 6| Step: 11
Training loss: 2.7650820096703526
Validation loss: 2.8968562434395095

Epoch: 6| Step: 12
Training loss: 3.515841329064733
Validation loss: 2.886567738499965

Epoch: 6| Step: 13
Training loss: 2.8336431296531446
Validation loss: 2.8908831028004203

Epoch: 115| Step: 0
Training loss: 2.8857648251544394
Validation loss: 2.890042547795635

Epoch: 6| Step: 1
Training loss: 3.9723946964430175
Validation loss: 2.888876919258832

Epoch: 6| Step: 2
Training loss: 2.9668217872040796
Validation loss: 2.88832083107759

Epoch: 6| Step: 3
Training loss: 2.765269283543694
Validation loss: 2.891067365495361

Epoch: 6| Step: 4
Training loss: 2.7696200895924026
Validation loss: 2.8889232199085377

Epoch: 6| Step: 5
Training loss: 3.0424893629629466
Validation loss: 2.8893530249036092

Epoch: 6| Step: 6
Training loss: 3.2495398562479196
Validation loss: 2.887955060171588

Epoch: 6| Step: 7
Training loss: 3.3625144305859025
Validation loss: 2.8880748813441803

Epoch: 6| Step: 8
Training loss: 3.375855796536456
Validation loss: 2.8844370266065895

Epoch: 6| Step: 9
Training loss: 2.692957017484007
Validation loss: 2.8882209853980783

Epoch: 6| Step: 10
Training loss: 3.641142452287348
Validation loss: 2.883584677971227

Epoch: 6| Step: 11
Training loss: 2.771796974365556
Validation loss: 2.8882766172883767

Epoch: 6| Step: 12
Training loss: 3.1396040894029618
Validation loss: 2.890491963002109

Epoch: 6| Step: 13
Training loss: 3.9311175010197457
Validation loss: 2.9003293677811777

Epoch: 116| Step: 0
Training loss: 3.6143579476891103
Validation loss: 2.8884405855989055

Epoch: 6| Step: 1
Training loss: 3.1994682466243085
Validation loss: 2.894439248090127

Epoch: 6| Step: 2
Training loss: 3.8696769331108753
Validation loss: 2.888124918540825

Epoch: 6| Step: 3
Training loss: 2.811181501111222
Validation loss: 2.8877143837455144

Epoch: 6| Step: 4
Training loss: 3.3260660742678443
Validation loss: 2.8885705548725986

Epoch: 6| Step: 5
Training loss: 2.608569906148047
Validation loss: 2.891165077864746

Epoch: 6| Step: 6
Training loss: 2.626154691046152
Validation loss: 2.889560976117987

Epoch: 6| Step: 7
Training loss: 3.28417242788374
Validation loss: 2.896704701945524

Epoch: 6| Step: 8
Training loss: 3.4548515042800285
Validation loss: 2.8999940985286132

Epoch: 6| Step: 9
Training loss: 3.056332976730192
Validation loss: 2.9051901598002834

Epoch: 6| Step: 10
Training loss: 3.3507619759842906
Validation loss: 2.910294918994056

Epoch: 6| Step: 11
Training loss: 3.205098358406579
Validation loss: 2.9202178279402324

Epoch: 6| Step: 12
Training loss: 2.7068384495453834
Validation loss: 2.9032933666544674

Epoch: 6| Step: 13
Training loss: 3.2593729869510804
Validation loss: 2.89705986069142

Epoch: 117| Step: 0
Training loss: 3.3036874110066097
Validation loss: 2.8881163225369955

Epoch: 6| Step: 1
Training loss: 3.3733727099516564
Validation loss: 2.8852533260384976

Epoch: 6| Step: 2
Training loss: 2.992085826132396
Validation loss: 2.8839270916508237

Epoch: 6| Step: 3
Training loss: 2.7984178432709275
Validation loss: 2.882572339591202

Epoch: 6| Step: 4
Training loss: 2.6500829575707314
Validation loss: 2.882128763628291

Epoch: 6| Step: 5
Training loss: 3.8184972401581887
Validation loss: 2.883409010828005

Epoch: 6| Step: 6
Training loss: 3.1730885556592434
Validation loss: 2.88340289069764

Epoch: 6| Step: 7
Training loss: 3.448896624167552
Validation loss: 2.8847985371674594

Epoch: 6| Step: 8
Training loss: 3.620248113528052
Validation loss: 2.8829117806861846

Epoch: 6| Step: 9
Training loss: 3.64383133916872
Validation loss: 2.8838554243480217

Epoch: 6| Step: 10
Training loss: 2.4693353659138784
Validation loss: 2.880077144042233

Epoch: 6| Step: 11
Training loss: 3.5002893600741136
Validation loss: 2.88045858096264

Epoch: 6| Step: 12
Training loss: 2.7402516892661746
Validation loss: 2.8846606927978287

Epoch: 6| Step: 13
Training loss: 2.1232487811506484
Validation loss: 2.882302280302434

Epoch: 118| Step: 0
Training loss: 3.285552628017419
Validation loss: 2.8810644360380633

Epoch: 6| Step: 1
Training loss: 2.4583767601530973
Validation loss: 2.88967909919323

Epoch: 6| Step: 2
Training loss: 3.3167293108163087
Validation loss: 2.8871192059906092

Epoch: 6| Step: 3
Training loss: 3.1023738386029884
Validation loss: 2.886324374158646

Epoch: 6| Step: 4
Training loss: 3.29000311877442
Validation loss: 2.8853584876895217

Epoch: 6| Step: 5
Training loss: 3.613815152700224
Validation loss: 2.893893143384238

Epoch: 6| Step: 6
Training loss: 3.4916879864195822
Validation loss: 2.893949898470168

Epoch: 6| Step: 7
Training loss: 3.2064583158580824
Validation loss: 2.8808259786648365

Epoch: 6| Step: 8
Training loss: 3.308116819918256
Validation loss: 2.8797471106384536

Epoch: 6| Step: 9
Training loss: 2.975712532177414
Validation loss: 2.8803523766284362

Epoch: 6| Step: 10
Training loss: 2.3493573060705164
Validation loss: 2.8781307841998816

Epoch: 6| Step: 11
Training loss: 3.6035999153844327
Validation loss: 2.8760139920712984

Epoch: 6| Step: 12
Training loss: 3.151429375790564
Validation loss: 2.878539225801344

Epoch: 6| Step: 13
Training loss: 3.026510091868461
Validation loss: 2.8785181335323666

Epoch: 119| Step: 0
Training loss: 2.7742973606549306
Validation loss: 2.8778858405355705

Epoch: 6| Step: 1
Training loss: 3.361435794823719
Validation loss: 2.8794134843041324

Epoch: 6| Step: 2
Training loss: 2.357907173374459
Validation loss: 2.878278110918119

Epoch: 6| Step: 3
Training loss: 4.073996840493087
Validation loss: 2.877920498951897

Epoch: 6| Step: 4
Training loss: 3.10509238211636
Validation loss: 2.875500090246939

Epoch: 6| Step: 5
Training loss: 3.065930527638416
Validation loss: 2.8777462013807495

Epoch: 6| Step: 6
Training loss: 3.3041921113530957
Validation loss: 2.882557041692524

Epoch: 6| Step: 7
Training loss: 3.4039155852702203
Validation loss: 2.880523408654942

Epoch: 6| Step: 8
Training loss: 3.2191215226650804
Validation loss: 2.882878806961829

Epoch: 6| Step: 9
Training loss: 2.8584940235875504
Validation loss: 2.8767047516421522

Epoch: 6| Step: 10
Training loss: 2.4783304444402887
Validation loss: 2.8786972859883995

Epoch: 6| Step: 11
Training loss: 3.8657175680562856
Validation loss: 2.8778259473995558

Epoch: 6| Step: 12
Training loss: 3.1022825390193423
Validation loss: 2.8732394944842943

Epoch: 6| Step: 13
Training loss: 2.9394443651239905
Validation loss: 2.877437676308374

Epoch: 120| Step: 0
Training loss: 3.0058301858556766
Validation loss: 2.8751741867479486

Epoch: 6| Step: 1
Training loss: 2.3803317805247186
Validation loss: 2.872378261849599

Epoch: 6| Step: 2
Training loss: 4.256359055252101
Validation loss: 2.872443781519755

Epoch: 6| Step: 3
Training loss: 3.3708651609926124
Validation loss: 2.872990350347156

Epoch: 6| Step: 4
Training loss: 2.3665791853554916
Validation loss: 2.8715596366627723

Epoch: 6| Step: 5
Training loss: 3.0561413829513664
Validation loss: 2.8711756326443596

Epoch: 6| Step: 6
Training loss: 3.4632640450099936
Validation loss: 2.869281622901293

Epoch: 6| Step: 7
Training loss: 3.155575972999939
Validation loss: 2.8733490478921113

Epoch: 6| Step: 8
Training loss: 3.8178191054000474
Validation loss: 2.8712009209302813

Epoch: 6| Step: 9
Training loss: 3.612146939775065
Validation loss: 2.871290421922781

Epoch: 6| Step: 10
Training loss: 3.377136401999475
Validation loss: 2.871554344320765

Epoch: 6| Step: 11
Training loss: 2.962153122307339
Validation loss: 2.873209148987998

Epoch: 6| Step: 12
Training loss: 2.305353100886996
Validation loss: 2.8735777452149063

Epoch: 6| Step: 13
Training loss: 2.072834134655371
Validation loss: 2.876974372208048

Epoch: 121| Step: 0
Training loss: 3.661959892782505
Validation loss: 2.875277535702223

Epoch: 6| Step: 1
Training loss: 2.3086086214622528
Validation loss: 2.872333351037071

Epoch: 6| Step: 2
Training loss: 3.6553839285414416
Validation loss: 2.8724619776425353

Epoch: 6| Step: 3
Training loss: 3.3198793375539974
Validation loss: 2.8734400959388253

Epoch: 6| Step: 4
Training loss: 3.2041984434168436
Validation loss: 2.8746314933912305

Epoch: 6| Step: 5
Training loss: 3.208369729632401
Validation loss: 2.8737760384399507

Epoch: 6| Step: 6
Training loss: 2.919558172635181
Validation loss: 2.8702389225070823

Epoch: 6| Step: 7
Training loss: 3.032898444835331
Validation loss: 2.8710933606893434

Epoch: 6| Step: 8
Training loss: 3.1980825043628744
Validation loss: 2.868077159809724

Epoch: 6| Step: 9
Training loss: 3.524891623055192
Validation loss: 2.8701201583418796

Epoch: 6| Step: 10
Training loss: 3.0609746754498177
Validation loss: 2.871872224647614

Epoch: 6| Step: 11
Training loss: 3.016801199538853
Validation loss: 2.868870122549501

Epoch: 6| Step: 12
Training loss: 2.9357827219379993
Validation loss: 2.8708994702790216

Epoch: 6| Step: 13
Training loss: 3.131458475021844
Validation loss: 2.87476538743716

Epoch: 122| Step: 0
Training loss: 3.253672945192455
Validation loss: 2.872083823916086

Epoch: 6| Step: 1
Training loss: 3.67033763112006
Validation loss: 2.873697361182489

Epoch: 6| Step: 2
Training loss: 2.418849310203848
Validation loss: 2.87354732834988

Epoch: 6| Step: 3
Training loss: 3.009685775222419
Validation loss: 2.8701919649592007

Epoch: 6| Step: 4
Training loss: 3.2872364475215443
Validation loss: 2.876820525117891

Epoch: 6| Step: 5
Training loss: 2.6533267821737465
Validation loss: 2.871595170451431

Epoch: 6| Step: 6
Training loss: 2.6973331561739844
Validation loss: 2.8706480654576643

Epoch: 6| Step: 7
Training loss: 3.1161466691703934
Validation loss: 2.8700399856208723

Epoch: 6| Step: 8
Training loss: 2.9365351289466295
Validation loss: 2.871637094078649

Epoch: 6| Step: 9
Training loss: 3.62782335497773
Validation loss: 2.8723360089870185

Epoch: 6| Step: 10
Training loss: 3.1854046685188493
Validation loss: 2.8705353421049886

Epoch: 6| Step: 11
Training loss: 3.403003230162597
Validation loss: 2.870102083142099

Epoch: 6| Step: 12
Training loss: 3.6641132538295875
Validation loss: 2.8716153020822

Epoch: 6| Step: 13
Training loss: 3.1493512287821193
Validation loss: 2.866259314421278

Epoch: 123| Step: 0
Training loss: 3.0681082308900183
Validation loss: 2.864758732740493

Epoch: 6| Step: 1
Training loss: 3.275260181138346
Validation loss: 2.866286464422165

Epoch: 6| Step: 2
Training loss: 3.2246241624055245
Validation loss: 2.869196269444428

Epoch: 6| Step: 3
Training loss: 3.63044934268605
Validation loss: 2.866384719248451

Epoch: 6| Step: 4
Training loss: 2.686219198512753
Validation loss: 2.8663741226002797

Epoch: 6| Step: 5
Training loss: 2.834767334017502
Validation loss: 2.865563622299099

Epoch: 6| Step: 6
Training loss: 2.8531964363104767
Validation loss: 2.867552938814367

Epoch: 6| Step: 7
Training loss: 3.034394353928607
Validation loss: 2.866404214903782

Epoch: 6| Step: 8
Training loss: 3.3721369149319655
Validation loss: 2.86769005313504

Epoch: 6| Step: 9
Training loss: 3.2448037495803987
Validation loss: 2.8653858809466457

Epoch: 6| Step: 10
Training loss: 3.363939599654987
Validation loss: 2.8675394887463765

Epoch: 6| Step: 11
Training loss: 2.6258124048029945
Validation loss: 2.866614049093302

Epoch: 6| Step: 12
Training loss: 3.70547024788968
Validation loss: 2.8666196367346113

Epoch: 6| Step: 13
Training loss: 3.303831742683026
Validation loss: 2.867759869874455

Epoch: 124| Step: 0
Training loss: 2.606929523974277
Validation loss: 2.8659785126053343

Epoch: 6| Step: 1
Training loss: 3.1817082163151116
Validation loss: 2.867827680721149

Epoch: 6| Step: 2
Training loss: 3.4432552363010287
Validation loss: 2.864627996340767

Epoch: 6| Step: 3
Training loss: 3.0374447162134053
Validation loss: 2.8668616620122536

Epoch: 6| Step: 4
Training loss: 2.4310543226718515
Validation loss: 2.8633889192595

Epoch: 6| Step: 5
Training loss: 3.263061101025146
Validation loss: 2.862871923742042

Epoch: 6| Step: 6
Training loss: 3.1827117259758326
Validation loss: 2.861916702393389

Epoch: 6| Step: 7
Training loss: 2.4940200812380997
Validation loss: 2.863661507017859

Epoch: 6| Step: 8
Training loss: 3.1620953508317022
Validation loss: 2.8621176289863968

Epoch: 6| Step: 9
Training loss: 3.293891315939356
Validation loss: 2.8641848376279735

Epoch: 6| Step: 10
Training loss: 3.5101883962124165
Validation loss: 2.8637594096764056

Epoch: 6| Step: 11
Training loss: 4.005723910968318
Validation loss: 2.863779737831326

Epoch: 6| Step: 12
Training loss: 3.4114277534958553
Validation loss: 2.8619851121046938

Epoch: 6| Step: 13
Training loss: 2.728230750272674
Validation loss: 2.8682430917500565

Epoch: 125| Step: 0
Training loss: 1.943755909705301
Validation loss: 2.872723616718511

Epoch: 6| Step: 1
Training loss: 2.908042764950048
Validation loss: 2.8688902849193285

Epoch: 6| Step: 2
Training loss: 3.2361289166209426
Validation loss: 2.871508947892336

Epoch: 6| Step: 3
Training loss: 3.1249880981218663
Validation loss: 2.8714465321556055

Epoch: 6| Step: 4
Training loss: 3.6109375316928545
Validation loss: 2.870398653520072

Epoch: 6| Step: 5
Training loss: 2.9594954952535035
Validation loss: 2.8731631545621243

Epoch: 6| Step: 6
Training loss: 3.2757076867448083
Validation loss: 2.8741547178783224

Epoch: 6| Step: 7
Training loss: 2.790323608116574
Validation loss: 2.8635988633878418

Epoch: 6| Step: 8
Training loss: 3.2053955962321914
Validation loss: 2.865056700911809

Epoch: 6| Step: 9
Training loss: 3.6796465504953413
Validation loss: 2.862881302969876

Epoch: 6| Step: 10
Training loss: 3.1311636602562904
Validation loss: 2.864239603639526

Epoch: 6| Step: 11
Training loss: 3.3193751549150607
Validation loss: 2.8646697785132753

Epoch: 6| Step: 12
Training loss: 3.7145829134242145
Validation loss: 2.8625286912803447

Epoch: 6| Step: 13
Training loss: 2.814855987496817
Validation loss: 2.864416517544587

Epoch: 126| Step: 0
Training loss: 3.347426060493159
Validation loss: 2.8597448611759893

Epoch: 6| Step: 1
Training loss: 2.8894990944954184
Validation loss: 2.864100245277672

Epoch: 6| Step: 2
Training loss: 4.007603571095404
Validation loss: 2.8595123912506644

Epoch: 6| Step: 3
Training loss: 3.395773358585767
Validation loss: 2.8577954839375446

Epoch: 6| Step: 4
Training loss: 2.8871739587384715
Validation loss: 2.858721677228223

Epoch: 6| Step: 5
Training loss: 3.6989191693304457
Validation loss: 2.8607872462622876

Epoch: 6| Step: 6
Training loss: 3.4005565131760713
Validation loss: 2.8573016718960975

Epoch: 6| Step: 7
Training loss: 2.971893573626732
Validation loss: 2.8574738700795312

Epoch: 6| Step: 8
Training loss: 3.1900563180669654
Validation loss: 2.8593021022434795

Epoch: 6| Step: 9
Training loss: 3.0728640449458062
Validation loss: 2.8546862241996727

Epoch: 6| Step: 10
Training loss: 3.098214983007573
Validation loss: 2.858650507986745

Epoch: 6| Step: 11
Training loss: 2.499511098740522
Validation loss: 2.8566038126057895

Epoch: 6| Step: 12
Training loss: 2.467674600594196
Validation loss: 2.856076752828865

Epoch: 6| Step: 13
Training loss: 2.840601760886703
Validation loss: 2.8576503667324844

Epoch: 127| Step: 0
Training loss: 3.7347512793806565
Validation loss: 2.857936305997191

Epoch: 6| Step: 1
Training loss: 3.0181436249550706
Validation loss: 2.8581942967153293

Epoch: 6| Step: 2
Training loss: 2.9045917333090085
Validation loss: 2.8558573202514257

Epoch: 6| Step: 3
Training loss: 2.8353925028903455
Validation loss: 2.857793051084528

Epoch: 6| Step: 4
Training loss: 3.18666634223117
Validation loss: 2.854109928281824

Epoch: 6| Step: 5
Training loss: 3.3192286259407693
Validation loss: 2.856644143433734

Epoch: 6| Step: 6
Training loss: 2.8830945050181276
Validation loss: 2.856140766903459

Epoch: 6| Step: 7
Training loss: 3.035557311671754
Validation loss: 2.85623070660146

Epoch: 6| Step: 8
Training loss: 3.3565710386603236
Validation loss: 2.8566789994360264

Epoch: 6| Step: 9
Training loss: 3.612704900190689
Validation loss: 2.8557366275706535

Epoch: 6| Step: 10
Training loss: 3.5216021779900712
Validation loss: 2.8564588143578513

Epoch: 6| Step: 11
Training loss: 2.689488939145164
Validation loss: 2.8580421242966048

Epoch: 6| Step: 12
Training loss: 2.7988129620031517
Validation loss: 2.8630612440521044

Epoch: 6| Step: 13
Training loss: 3.0899517749368752
Validation loss: 2.865570674717724

Epoch: 128| Step: 0
Training loss: 2.867454745027847
Validation loss: 2.86939957121721

Epoch: 6| Step: 1
Training loss: 2.8677610400578244
Validation loss: 2.8705575745512864

Epoch: 6| Step: 2
Training loss: 2.871630477042561
Validation loss: 2.857417958777779

Epoch: 6| Step: 3
Training loss: 3.3951006764019933
Validation loss: 2.860217893601213

Epoch: 6| Step: 4
Training loss: 2.964566947872071
Validation loss: 2.858512078019788

Epoch: 6| Step: 5
Training loss: 3.862965014467893
Validation loss: 2.851747647448745

Epoch: 6| Step: 6
Training loss: 3.6647513907136053
Validation loss: 2.8568726704481597

Epoch: 6| Step: 7
Training loss: 3.4678364143464844
Validation loss: 2.8573233756706955

Epoch: 6| Step: 8
Training loss: 2.7381553457703602
Validation loss: 2.85481650081566

Epoch: 6| Step: 9
Training loss: 3.328946437561781
Validation loss: 2.853616525079354

Epoch: 6| Step: 10
Training loss: 3.189384053236312
Validation loss: 2.8540021712581938

Epoch: 6| Step: 11
Training loss: 3.122015787029734
Validation loss: 2.8536569565208025

Epoch: 6| Step: 12
Training loss: 2.587615422424928
Validation loss: 2.850890746467825

Epoch: 6| Step: 13
Training loss: 2.871814289634333
Validation loss: 2.8544160718806952

Epoch: 129| Step: 0
Training loss: 2.1929634531770508
Validation loss: 2.8507639595219865

Epoch: 6| Step: 1
Training loss: 3.052295733841361
Validation loss: 2.8523768564768206

Epoch: 6| Step: 2
Training loss: 3.524223155460974
Validation loss: 2.855599924585562

Epoch: 6| Step: 3
Training loss: 3.6255871527448402
Validation loss: 2.8498117054752914

Epoch: 6| Step: 4
Training loss: 2.921996415007453
Validation loss: 2.8535176104959907

Epoch: 6| Step: 5
Training loss: 3.3190743325585266
Validation loss: 2.855100360578527

Epoch: 6| Step: 6
Training loss: 3.494298378041743
Validation loss: 2.8505844769744977

Epoch: 6| Step: 7
Training loss: 2.629336725731235
Validation loss: 2.855597344424927

Epoch: 6| Step: 8
Training loss: 3.0401574836897454
Validation loss: 2.8542228144102095

Epoch: 6| Step: 9
Training loss: 2.724493165084434
Validation loss: 2.854895540360852

Epoch: 6| Step: 10
Training loss: 3.8067869311930176
Validation loss: 2.866850010140171

Epoch: 6| Step: 11
Training loss: 2.8694537195148313
Validation loss: 2.8617139090943597

Epoch: 6| Step: 12
Training loss: 3.531802919023892
Validation loss: 2.8577583324674722

Epoch: 6| Step: 13
Training loss: 2.8982695250665005
Validation loss: 2.859610726425816

Epoch: 130| Step: 0
Training loss: 3.192101093603501
Validation loss: 2.8518994401864433

Epoch: 6| Step: 1
Training loss: 2.6187244969403034
Validation loss: 2.8492950500228655

Epoch: 6| Step: 2
Training loss: 3.4217650513425606
Validation loss: 2.849447019297331

Epoch: 6| Step: 3
Training loss: 3.1690249111247297
Validation loss: 2.8482466535404

Epoch: 6| Step: 4
Training loss: 3.484894718019285
Validation loss: 2.8500263125822847

Epoch: 6| Step: 5
Training loss: 2.944032912215488
Validation loss: 2.8527648000425336

Epoch: 6| Step: 6
Training loss: 3.0137285188900624
Validation loss: 2.85013038813377

Epoch: 6| Step: 7
Training loss: 2.6898781655952098
Validation loss: 2.848090550749365

Epoch: 6| Step: 8
Training loss: 2.7813370080260995
Validation loss: 2.8504373935475846

Epoch: 6| Step: 9
Training loss: 3.4623356528819924
Validation loss: 2.8466193611303

Epoch: 6| Step: 10
Training loss: 3.7390987893434597
Validation loss: 2.8500842029630307

Epoch: 6| Step: 11
Training loss: 3.284640204758999
Validation loss: 2.8497525393224574

Epoch: 6| Step: 12
Training loss: 3.039844402547476
Validation loss: 2.8559251076102874

Epoch: 6| Step: 13
Training loss: 3.117194383656638
Validation loss: 2.857526565787277

Epoch: 131| Step: 0
Training loss: 2.8588112864327977
Validation loss: 2.872802293872354

Epoch: 6| Step: 1
Training loss: 3.0826605672852962
Validation loss: 2.878363697398622

Epoch: 6| Step: 2
Training loss: 3.810733448429321
Validation loss: 2.8924251238220955

Epoch: 6| Step: 3
Training loss: 3.2517431426199965
Validation loss: 2.8765035499007596

Epoch: 6| Step: 4
Training loss: 3.7946137653165293
Validation loss: 2.8561110754014303

Epoch: 6| Step: 5
Training loss: 3.5655666336511436
Validation loss: 2.8481906808166775

Epoch: 6| Step: 6
Training loss: 2.8058953619742546
Validation loss: 2.848740499050159

Epoch: 6| Step: 7
Training loss: 2.4689713390937937
Validation loss: 2.8521728491749623

Epoch: 6| Step: 8
Training loss: 2.9312295746244157
Validation loss: 2.8547160840857093

Epoch: 6| Step: 9
Training loss: 3.500574064859839
Validation loss: 2.8576510539223916

Epoch: 6| Step: 10
Training loss: 3.4233256013133517
Validation loss: 2.865747244338539

Epoch: 6| Step: 11
Training loss: 2.640834461459489
Validation loss: 2.8689842856414898

Epoch: 6| Step: 12
Training loss: 3.1671073673840118
Validation loss: 2.873497419156292

Epoch: 6| Step: 13
Training loss: 2.175692160955208
Validation loss: 2.870085240483455

Epoch: 132| Step: 0
Training loss: 2.744655444090369
Validation loss: 2.8700748647277003

Epoch: 6| Step: 1
Training loss: 3.627351721500771
Validation loss: 2.87980522523298

Epoch: 6| Step: 2
Training loss: 3.684043298597336
Validation loss: 2.867344569442551

Epoch: 6| Step: 3
Training loss: 3.5377378026609003
Validation loss: 2.85903868974464

Epoch: 6| Step: 4
Training loss: 2.9148594479839787
Validation loss: 2.8644743802259764

Epoch: 6| Step: 5
Training loss: 3.186741009274659
Validation loss: 2.853219375313727

Epoch: 6| Step: 6
Training loss: 2.870253085630905
Validation loss: 2.8508258195584

Epoch: 6| Step: 7
Training loss: 2.4431164908193845
Validation loss: 2.8497826380184788

Epoch: 6| Step: 8
Training loss: 3.5302449374281815
Validation loss: 2.8483567596030754

Epoch: 6| Step: 9
Training loss: 2.5346469455729714
Validation loss: 2.8497379657467117

Epoch: 6| Step: 10
Training loss: 3.1169020443193007
Validation loss: 2.847022224749993

Epoch: 6| Step: 11
Training loss: 2.665069300339177
Validation loss: 2.847348219028464

Epoch: 6| Step: 12
Training loss: 3.5421249242773767
Validation loss: 2.8470076101839576

Epoch: 6| Step: 13
Training loss: 3.7115095159466978
Validation loss: 2.848131688015227

Epoch: 133| Step: 0
Training loss: 3.4683799202567522
Validation loss: 2.850107379294444

Epoch: 6| Step: 1
Training loss: 2.0855058659224324
Validation loss: 2.850338785069304

Epoch: 6| Step: 2
Training loss: 3.5137408145335294
Validation loss: 2.8510604787340905

Epoch: 6| Step: 3
Training loss: 2.8348958437992797
Validation loss: 2.8617577064254514

Epoch: 6| Step: 4
Training loss: 3.292299394919322
Validation loss: 2.858746270380797

Epoch: 6| Step: 5
Training loss: 3.218937988717322
Validation loss: 2.863307906254506

Epoch: 6| Step: 6
Training loss: 3.273728824297923
Validation loss: 2.856907794661408

Epoch: 6| Step: 7
Training loss: 2.7209269259733557
Validation loss: 2.8539176840102694

Epoch: 6| Step: 8
Training loss: 3.449748602290658
Validation loss: 2.8510151718651624

Epoch: 6| Step: 9
Training loss: 3.876849071730235
Validation loss: 2.849328334566675

Epoch: 6| Step: 10
Training loss: 2.705929662761623
Validation loss: 2.8440926827761097

Epoch: 6| Step: 11
Training loss: 3.1133627312502297
Validation loss: 2.842863993983222

Epoch: 6| Step: 12
Training loss: 3.111982469543662
Validation loss: 2.842097218042406

Epoch: 6| Step: 13
Training loss: 3.056323615749722
Validation loss: 2.842438224092117

Epoch: 134| Step: 0
Training loss: 2.4456989604510544
Validation loss: 2.8391881153390375

Epoch: 6| Step: 1
Training loss: 2.819850387121542
Validation loss: 2.8396609248148246

Epoch: 6| Step: 2
Training loss: 3.290306743943227
Validation loss: 2.842740864849158

Epoch: 6| Step: 3
Training loss: 2.6545483692480976
Validation loss: 2.842877706431503

Epoch: 6| Step: 4
Training loss: 3.684864201314467
Validation loss: 2.8389841554247233

Epoch: 6| Step: 5
Training loss: 3.0026945093376134
Validation loss: 2.8427274673793086

Epoch: 6| Step: 6
Training loss: 4.001435499101141
Validation loss: 2.8400632933057772

Epoch: 6| Step: 7
Training loss: 3.2547557953670787
Validation loss: 2.840326389637847

Epoch: 6| Step: 8
Training loss: 3.175368916862844
Validation loss: 2.8385957482251083

Epoch: 6| Step: 9
Training loss: 3.148793997826322
Validation loss: 2.840442313694304

Epoch: 6| Step: 10
Training loss: 3.641201644874963
Validation loss: 2.8396304443800275

Epoch: 6| Step: 11
Training loss: 2.8977696556758885
Validation loss: 2.8401804520713374

Epoch: 6| Step: 12
Training loss: 3.205815817898554
Validation loss: 2.838258923194258

Epoch: 6| Step: 13
Training loss: 1.6841879944329377
Validation loss: 2.8424822282352373

Epoch: 135| Step: 0
Training loss: 3.5739536541461843
Validation loss: 2.8408682329180017

Epoch: 6| Step: 1
Training loss: 3.233645444402868
Validation loss: 2.842280609893724

Epoch: 6| Step: 2
Training loss: 3.5894354088861147
Validation loss: 2.8411387503637475

Epoch: 6| Step: 3
Training loss: 2.344039899063341
Validation loss: 2.8433568106363456

Epoch: 6| Step: 4
Training loss: 2.840292537021815
Validation loss: 2.84365965203742

Epoch: 6| Step: 5
Training loss: 3.200183094270237
Validation loss: 2.8463441343280524

Epoch: 6| Step: 6
Training loss: 2.731696424510303
Validation loss: 2.846031891635691

Epoch: 6| Step: 7
Training loss: 2.996462484694273
Validation loss: 2.847757677267457

Epoch: 6| Step: 8
Training loss: 3.599073099973808
Validation loss: 2.854523193592432

Epoch: 6| Step: 9
Training loss: 4.031352670234476
Validation loss: 2.8570042453856805

Epoch: 6| Step: 10
Training loss: 3.3154965648170225
Validation loss: 2.8482626145569627

Epoch: 6| Step: 11
Training loss: 2.835735723710262
Validation loss: 2.840626938696022

Epoch: 6| Step: 12
Training loss: 2.4543141198239256
Validation loss: 2.8395255831185686

Epoch: 6| Step: 13
Training loss: 2.565150866914408
Validation loss: 2.838059971288169

Epoch: 136| Step: 0
Training loss: 2.739810619909922
Validation loss: 2.8358920211307037

Epoch: 6| Step: 1
Training loss: 3.1595855310703986
Validation loss: 2.8394011327627617

Epoch: 6| Step: 2
Training loss: 3.264173559305411
Validation loss: 2.8383850376567756

Epoch: 6| Step: 3
Training loss: 3.606832690574972
Validation loss: 2.837359452128887

Epoch: 6| Step: 4
Training loss: 2.6093385431175613
Validation loss: 2.837351887761956

Epoch: 6| Step: 5
Training loss: 3.1826080481323977
Validation loss: 2.835481418126652

Epoch: 6| Step: 6
Training loss: 3.166396648205125
Validation loss: 2.838993328219667

Epoch: 6| Step: 7
Training loss: 3.1330191907931124
Validation loss: 2.835961392182595

Epoch: 6| Step: 8
Training loss: 2.8935767696592434
Validation loss: 2.839359997217638

Epoch: 6| Step: 9
Training loss: 2.3372122561983284
Validation loss: 2.834230817083918

Epoch: 6| Step: 10
Training loss: 2.5943135947595275
Validation loss: 2.8362978356562687

Epoch: 6| Step: 11
Training loss: 3.73502398481928
Validation loss: 2.8407186501698574

Epoch: 6| Step: 12
Training loss: 3.6481507411229672
Validation loss: 2.843230849978814

Epoch: 6| Step: 13
Training loss: 3.8925625675883917
Validation loss: 2.8330973129363954

Epoch: 137| Step: 0
Training loss: 3.331168202725379
Validation loss: 2.8344583392122824

Epoch: 6| Step: 1
Training loss: 3.321512736881659
Validation loss: 2.835248842229203

Epoch: 6| Step: 2
Training loss: 2.6151091109026923
Validation loss: 2.842566542202673

Epoch: 6| Step: 3
Training loss: 2.9104903266194193
Validation loss: 2.840230064861508

Epoch: 6| Step: 4
Training loss: 3.4521922236880136
Validation loss: 2.850429691204037

Epoch: 6| Step: 5
Training loss: 3.0130901850722798
Validation loss: 2.8457001304690945

Epoch: 6| Step: 6
Training loss: 3.660388137164864
Validation loss: 2.848354108078191

Epoch: 6| Step: 7
Training loss: 3.441439226839022
Validation loss: 2.8429168017860578

Epoch: 6| Step: 8
Training loss: 3.3441535492281793
Validation loss: 2.8419652542418814

Epoch: 6| Step: 9
Training loss: 3.0618662275697526
Validation loss: 2.8369710601536178

Epoch: 6| Step: 10
Training loss: 3.255638073847168
Validation loss: 2.8349566131586283

Epoch: 6| Step: 11
Training loss: 2.673461443082074
Validation loss: 2.832679527123873

Epoch: 6| Step: 12
Training loss: 3.2174666725928343
Validation loss: 2.8343172162648242

Epoch: 6| Step: 13
Training loss: 1.7214927290542135
Validation loss: 2.8312167405775464

Epoch: 138| Step: 0
Training loss: 3.1540324664237955
Validation loss: 2.8323780016982223

Epoch: 6| Step: 1
Training loss: 3.0203821481093542
Validation loss: 2.830774427208084

Epoch: 6| Step: 2
Training loss: 3.20001754755931
Validation loss: 2.830961802660218

Epoch: 6| Step: 3
Training loss: 3.0448413811321737
Validation loss: 2.833245497421198

Epoch: 6| Step: 4
Training loss: 3.0738833873423848
Validation loss: 2.836386078977776

Epoch: 6| Step: 5
Training loss: 3.6412885986126162
Validation loss: 2.831175900838141

Epoch: 6| Step: 6
Training loss: 3.0906351766235547
Validation loss: 2.832432960927773

Epoch: 6| Step: 7
Training loss: 3.1775987217511608
Validation loss: 2.8309889416268663

Epoch: 6| Step: 8
Training loss: 2.704273134397634
Validation loss: 2.830991996091358

Epoch: 6| Step: 9
Training loss: 2.9186751035437957
Validation loss: 2.830928415823207

Epoch: 6| Step: 10
Training loss: 3.5569205511752786
Validation loss: 2.829220901371268

Epoch: 6| Step: 11
Training loss: 3.4612574031223025
Validation loss: 2.8293623111317943

Epoch: 6| Step: 12
Training loss: 2.4394267365591347
Validation loss: 2.8289154476428777

Epoch: 6| Step: 13
Training loss: 3.3495682338490207
Validation loss: 2.8314225484334896

Epoch: 139| Step: 0
Training loss: 3.59614045624337
Validation loss: 2.8293327617578385

Epoch: 6| Step: 1
Training loss: 2.5685689746342444
Validation loss: 2.8310098175083644

Epoch: 6| Step: 2
Training loss: 3.6853390843815332
Validation loss: 2.8322736702693527

Epoch: 6| Step: 3
Training loss: 3.0974173339453306
Validation loss: 2.8292107753555316

Epoch: 6| Step: 4
Training loss: 3.522314463616647
Validation loss: 2.8301798769656683

Epoch: 6| Step: 5
Training loss: 3.2640466115372186
Validation loss: 2.8295248924068073

Epoch: 6| Step: 6
Training loss: 2.7200025106867254
Validation loss: 2.8298136500644366

Epoch: 6| Step: 7
Training loss: 3.4091216415407195
Validation loss: 2.830116835546079

Epoch: 6| Step: 8
Training loss: 3.0443229746969322
Validation loss: 2.8292035888072964

Epoch: 6| Step: 9
Training loss: 2.827028177763903
Validation loss: 2.82649635761744

Epoch: 6| Step: 10
Training loss: 3.8265170710317578
Validation loss: 2.8267349546363874

Epoch: 6| Step: 11
Training loss: 2.582876370119707
Validation loss: 2.8245141576328647

Epoch: 6| Step: 12
Training loss: 2.470823165932676
Validation loss: 2.829725415594047

Epoch: 6| Step: 13
Training loss: 2.747256557797315
Validation loss: 2.830183153323785

Epoch: 140| Step: 0
Training loss: 3.2297451034450906
Validation loss: 2.835884198825465

Epoch: 6| Step: 1
Training loss: 3.309768846398394
Validation loss: 2.8406947925842325

Epoch: 6| Step: 2
Training loss: 3.0832483090886544
Validation loss: 2.8492206688841586

Epoch: 6| Step: 3
Training loss: 2.886494422631002
Validation loss: 2.856524899305408

Epoch: 6| Step: 4
Training loss: 2.9822034674653413
Validation loss: 2.849997451506193

Epoch: 6| Step: 5
Training loss: 2.7314109213624174
Validation loss: 2.8375795354768862

Epoch: 6| Step: 6
Training loss: 3.518807695637395
Validation loss: 2.832599552716539

Epoch: 6| Step: 7
Training loss: 3.449726071747259
Validation loss: 2.828317172811094

Epoch: 6| Step: 8
Training loss: 3.4329593146091493
Validation loss: 2.8284873931910735

Epoch: 6| Step: 9
Training loss: 2.730124521454823
Validation loss: 2.825108133435905

Epoch: 6| Step: 10
Training loss: 2.7404611919169874
Validation loss: 2.827616074998932

Epoch: 6| Step: 11
Training loss: 3.0723786136247897
Validation loss: 2.828209323200451

Epoch: 6| Step: 12
Training loss: 3.3391266705528064
Validation loss: 2.825287417826743

Epoch: 6| Step: 13
Training loss: 3.3429070952226656
Validation loss: 2.831324468387274

Epoch: 141| Step: 0
Training loss: 3.556803381692683
Validation loss: 2.829880690622774

Epoch: 6| Step: 1
Training loss: 3.4218524252787033
Validation loss: 2.8311507847668667

Epoch: 6| Step: 2
Training loss: 3.146981103617929
Validation loss: 2.829531972133484

Epoch: 6| Step: 3
Training loss: 2.978696683789908
Validation loss: 2.8271671391531887

Epoch: 6| Step: 4
Training loss: 3.2336464766309314
Validation loss: 2.828810549878762

Epoch: 6| Step: 5
Training loss: 2.9620546030270063
Validation loss: 2.8287507260522986

Epoch: 6| Step: 6
Training loss: 2.820629662092106
Validation loss: 2.8260792514953077

Epoch: 6| Step: 7
Training loss: 2.7233511039437355
Validation loss: 2.8260869140699074

Epoch: 6| Step: 8
Training loss: 2.4981965235668167
Validation loss: 2.8248482309022434

Epoch: 6| Step: 9
Training loss: 2.9973219998587743
Validation loss: 2.8286243850589963

Epoch: 6| Step: 10
Training loss: 3.39684881149346
Validation loss: 2.827874542805307

Epoch: 6| Step: 11
Training loss: 3.4097356198201516
Validation loss: 2.8282498667682536

Epoch: 6| Step: 12
Training loss: 3.2853333270126606
Validation loss: 2.8265818087050514

Epoch: 6| Step: 13
Training loss: 3.431429965610069
Validation loss: 2.826496031096346

Epoch: 142| Step: 0
Training loss: 3.0362708599305304
Validation loss: 2.8294854779199525

Epoch: 6| Step: 1
Training loss: 2.6397964712641175
Validation loss: 2.8389803654751007

Epoch: 6| Step: 2
Training loss: 3.7008745139451498
Validation loss: 2.83280868184766

Epoch: 6| Step: 3
Training loss: 3.076795726671589
Validation loss: 2.8396721375457363

Epoch: 6| Step: 4
Training loss: 3.767657352799029
Validation loss: 2.845508120766675

Epoch: 6| Step: 5
Training loss: 3.4101818385262046
Validation loss: 2.827232143302014

Epoch: 6| Step: 6
Training loss: 2.8006870142194455
Validation loss: 2.82929143180331

Epoch: 6| Step: 7
Training loss: 2.992093794428611
Validation loss: 2.827111797352849

Epoch: 6| Step: 8
Training loss: 3.0627235798090497
Validation loss: 2.8242746041634708

Epoch: 6| Step: 9
Training loss: 2.708107122119708
Validation loss: 2.824108577937163

Epoch: 6| Step: 10
Training loss: 3.1598046558698587
Validation loss: 2.8236346714168645

Epoch: 6| Step: 11
Training loss: 3.218027867169866
Validation loss: 2.8231711699551876

Epoch: 6| Step: 12
Training loss: 2.877090689069408
Validation loss: 2.8246897250548195

Epoch: 6| Step: 13
Training loss: 3.2073583401255084
Validation loss: 2.822604723650399

Epoch: 143| Step: 0
Training loss: 2.6239757356045157
Validation loss: 2.822123237382091

Epoch: 6| Step: 1
Training loss: 3.2436046766241065
Validation loss: 2.826014416773658

Epoch: 6| Step: 2
Training loss: 3.6257991567579255
Validation loss: 2.8227586811364014

Epoch: 6| Step: 3
Training loss: 3.4296209029073013
Validation loss: 2.8284729112616027

Epoch: 6| Step: 4
Training loss: 2.646969909047297
Validation loss: 2.8263384421722764

Epoch: 6| Step: 5
Training loss: 3.0168038865664504
Validation loss: 2.82380871837244

Epoch: 6| Step: 6
Training loss: 2.6245348381975884
Validation loss: 2.8242950894349645

Epoch: 6| Step: 7
Training loss: 3.7778884195194746
Validation loss: 2.8203878798557995

Epoch: 6| Step: 8
Training loss: 3.5946892879162946
Validation loss: 2.8208665969023303

Epoch: 6| Step: 9
Training loss: 3.343410296430625
Validation loss: 2.821480241674846

Epoch: 6| Step: 10
Training loss: 2.672893129415094
Validation loss: 2.8275827366025474

Epoch: 6| Step: 11
Training loss: 3.1537436930275478
Validation loss: 2.8298791088890223

Epoch: 6| Step: 12
Training loss: 2.4297606037095734
Validation loss: 2.841988105289549

Epoch: 6| Step: 13
Training loss: 3.399438048653168
Validation loss: 2.845218114057815

Epoch: 144| Step: 0
Training loss: 3.5111022340149933
Validation loss: 2.85242175345323

Epoch: 6| Step: 1
Training loss: 2.499551351344439
Validation loss: 2.8742248485321107

Epoch: 6| Step: 2
Training loss: 3.0265537338641924
Validation loss: 2.8579046892752027

Epoch: 6| Step: 3
Training loss: 3.1614883312496866
Validation loss: 2.852291042092899

Epoch: 6| Step: 4
Training loss: 3.0326343010381267
Validation loss: 2.8352504797404436

Epoch: 6| Step: 5
Training loss: 3.029096015060769
Validation loss: 2.823868660513339

Epoch: 6| Step: 6
Training loss: 2.903060803971418
Validation loss: 2.823801907551609

Epoch: 6| Step: 7
Training loss: 2.6643812598544843
Validation loss: 2.81831289840946

Epoch: 6| Step: 8
Training loss: 2.9110995613561435
Validation loss: 2.8224352847815166

Epoch: 6| Step: 9
Training loss: 3.6196025259244573
Validation loss: 2.818543497323948

Epoch: 6| Step: 10
Training loss: 3.133878683423625
Validation loss: 2.8176657977692288

Epoch: 6| Step: 11
Training loss: 3.8312188550171684
Validation loss: 2.8218099753218424

Epoch: 6| Step: 12
Training loss: 3.089915201202544
Validation loss: 2.821068637913439

Epoch: 6| Step: 13
Training loss: 3.380653873150339
Validation loss: 2.8202842047646275

Epoch: 145| Step: 0
Training loss: 2.98843682576026
Validation loss: 2.8191560290960593

Epoch: 6| Step: 1
Training loss: 3.295907262719666
Validation loss: 2.8172913095774033

Epoch: 6| Step: 2
Training loss: 3.648249031116433
Validation loss: 2.814847422755558

Epoch: 6| Step: 3
Training loss: 3.758638731283533
Validation loss: 2.8153864716033614

Epoch: 6| Step: 4
Training loss: 3.058137082517118
Validation loss: 2.818074798242001

Epoch: 6| Step: 5
Training loss: 2.696244849782383
Validation loss: 2.816527026984891

Epoch: 6| Step: 6
Training loss: 3.723638447002687
Validation loss: 2.813703075949242

Epoch: 6| Step: 7
Training loss: 3.1655432732925783
Validation loss: 2.8130760313965792

Epoch: 6| Step: 8
Training loss: 2.7211146101698267
Validation loss: 2.8138301297305537

Epoch: 6| Step: 9
Training loss: 3.0623503667905037
Validation loss: 2.8173983359810686

Epoch: 6| Step: 10
Training loss: 2.4735082812613065
Validation loss: 2.820053900005253

Epoch: 6| Step: 11
Training loss: 2.6339758954172607
Validation loss: 2.8150160483723177

Epoch: 6| Step: 12
Training loss: 3.3013194711894354
Validation loss: 2.8180451305097804

Epoch: 6| Step: 13
Training loss: 2.706951277791478
Validation loss: 2.8204494526353048

Epoch: 146| Step: 0
Training loss: 3.305481583081919
Validation loss: 2.8208166571781113

Epoch: 6| Step: 1
Training loss: 2.3673395794150736
Validation loss: 2.8227550501346013

Epoch: 6| Step: 2
Training loss: 3.8558583164223297
Validation loss: 2.8246618875290417

Epoch: 6| Step: 3
Training loss: 3.3765030798743365
Validation loss: 2.815521139838606

Epoch: 6| Step: 4
Training loss: 2.639358487647777
Validation loss: 2.819005444303057

Epoch: 6| Step: 5
Training loss: 3.148695412193293
Validation loss: 2.819047574371479

Epoch: 6| Step: 6
Training loss: 2.150349601887878
Validation loss: 2.8124974714516195

Epoch: 6| Step: 7
Training loss: 3.8902921112921125
Validation loss: 2.8148415201363806

Epoch: 6| Step: 8
Training loss: 4.263073727654951
Validation loss: 2.8149863661621657

Epoch: 6| Step: 9
Training loss: 2.9484231646279753
Validation loss: 2.815795706645566

Epoch: 6| Step: 10
Training loss: 2.9284139484504244
Validation loss: 2.81006830388986

Epoch: 6| Step: 11
Training loss: 2.8707648886912662
Validation loss: 2.812434687249176

Epoch: 6| Step: 12
Training loss: 2.2453701280008938
Validation loss: 2.810179606600016

Epoch: 6| Step: 13
Training loss: 2.8655217708518763
Validation loss: 2.814014203126307

Epoch: 147| Step: 0
Training loss: 3.183775127837428
Validation loss: 2.811307653903985

Epoch: 6| Step: 1
Training loss: 3.2733798147139836
Validation loss: 2.8145462021539003

Epoch: 6| Step: 2
Training loss: 2.8847200032360703
Validation loss: 2.8133064636014966

Epoch: 6| Step: 3
Training loss: 3.188818415824131
Validation loss: 2.8158522887111874

Epoch: 6| Step: 4
Training loss: 3.445147521205891
Validation loss: 2.814330466316178

Epoch: 6| Step: 5
Training loss: 2.41345622032578
Validation loss: 2.8192289964749455

Epoch: 6| Step: 6
Training loss: 3.211183710241887
Validation loss: 2.8122525925555966

Epoch: 6| Step: 7
Training loss: 2.590148999851295
Validation loss: 2.812765257072742

Epoch: 6| Step: 8
Training loss: 3.1212815095764634
Validation loss: 2.816695775948768

Epoch: 6| Step: 9
Training loss: 3.6612224186320406
Validation loss: 2.8112249093195016

Epoch: 6| Step: 10
Training loss: 3.0554093778689673
Validation loss: 2.813343757391772

Epoch: 6| Step: 11
Training loss: 2.749533353573757
Validation loss: 2.8119497601821606

Epoch: 6| Step: 12
Training loss: 3.5346719821106687
Validation loss: 2.813973206649166

Epoch: 6| Step: 13
Training loss: 3.126317623830119
Validation loss: 2.811122236881432

Epoch: 148| Step: 0
Training loss: 2.715960332010564
Validation loss: 2.810414836346002

Epoch: 6| Step: 1
Training loss: 4.018588742451389
Validation loss: 2.8090693726458156

Epoch: 6| Step: 2
Training loss: 2.727804955655487
Validation loss: 2.8133150439690193

Epoch: 6| Step: 3
Training loss: 3.0426384057290767
Validation loss: 2.8174532835032076

Epoch: 6| Step: 4
Training loss: 3.341050243521688
Validation loss: 2.8093683561854053

Epoch: 6| Step: 5
Training loss: 2.989885764603052
Validation loss: 2.809832317964928

Epoch: 6| Step: 6
Training loss: 2.940428065841466
Validation loss: 2.8110446131316738

Epoch: 6| Step: 7
Training loss: 3.362450331991154
Validation loss: 2.813004249571731

Epoch: 6| Step: 8
Training loss: 2.9018403100547405
Validation loss: 2.8074701176271386

Epoch: 6| Step: 9
Training loss: 3.2113927810780716
Validation loss: 2.8166505238516475

Epoch: 6| Step: 10
Training loss: 3.2916061460186596
Validation loss: 2.813913146642746

Epoch: 6| Step: 11
Training loss: 2.566803272955141
Validation loss: 2.8111277597264483

Epoch: 6| Step: 12
Training loss: 3.522761582461992
Validation loss: 2.832896392242318

Epoch: 6| Step: 13
Training loss: 2.3492866732105737
Validation loss: 2.8353713581904882

Epoch: 149| Step: 0
Training loss: 3.034757177955164
Validation loss: 2.8353809432165775

Epoch: 6| Step: 1
Training loss: 3.3469444061120854
Validation loss: 2.8310455559936485

Epoch: 6| Step: 2
Training loss: 3.8321024259126406
Validation loss: 2.8442120280967127

Epoch: 6| Step: 3
Training loss: 3.050157236517565
Validation loss: 2.821358619053746

Epoch: 6| Step: 4
Training loss: 2.8378976820498973
Validation loss: 2.814065406887413

Epoch: 6| Step: 5
Training loss: 2.9305212029908945
Validation loss: 2.8096140248115784

Epoch: 6| Step: 6
Training loss: 3.0841454819579823
Validation loss: 2.8075418701912627

Epoch: 6| Step: 7
Training loss: 3.0392768215518737
Validation loss: 2.8069248302618783

Epoch: 6| Step: 8
Training loss: 3.191182272252522
Validation loss: 2.80776280521744

Epoch: 6| Step: 9
Training loss: 2.396970816118284
Validation loss: 2.8091031853792496

Epoch: 6| Step: 10
Training loss: 2.8224224113024374
Validation loss: 2.805790765799063

Epoch: 6| Step: 11
Training loss: 3.6354823648515318
Validation loss: 2.807126023540979

Epoch: 6| Step: 12
Training loss: 2.650824897062742
Validation loss: 2.8056337618851424

Epoch: 6| Step: 13
Training loss: 3.8313958344077412
Validation loss: 2.8062819588267867

Epoch: 150| Step: 0
Training loss: 3.3689291713535146
Validation loss: 2.8063391310046213

Epoch: 6| Step: 1
Training loss: 3.3805482259514354
Validation loss: 2.8084330414887537

Epoch: 6| Step: 2
Training loss: 1.9863185826075178
Validation loss: 2.806284832810737

Epoch: 6| Step: 3
Training loss: 2.380934278328515
Validation loss: 2.8074261326854315

Epoch: 6| Step: 4
Training loss: 3.336403450150736
Validation loss: 2.8073253394801805

Epoch: 6| Step: 5
Training loss: 3.4865340997452647
Validation loss: 2.8093929524855126

Epoch: 6| Step: 6
Training loss: 3.8175942827634377
Validation loss: 2.8067972684412466

Epoch: 6| Step: 7
Training loss: 2.3653073539783747
Validation loss: 2.806723541268774

Epoch: 6| Step: 8
Training loss: 2.85670020897965
Validation loss: 2.8074424855797275

Epoch: 6| Step: 9
Training loss: 3.9448215292434976
Validation loss: 2.804642796834993

Epoch: 6| Step: 10
Training loss: 3.7186376731000332
Validation loss: 2.805722224947799

Epoch: 6| Step: 11
Training loss: 2.6350624137884378
Validation loss: 2.804139881462916

Epoch: 6| Step: 12
Training loss: 2.728634896535278
Validation loss: 2.8067957906103795

Epoch: 6| Step: 13
Training loss: 2.7392934106699833
Validation loss: 2.8053016215335784

Epoch: 151| Step: 0
Training loss: 2.914444067470177
Validation loss: 2.807291815823936

Epoch: 6| Step: 1
Training loss: 3.3843424026736946
Validation loss: 2.805621570640463

Epoch: 6| Step: 2
Training loss: 3.3911430560810376
Validation loss: 2.8070177058758294

Epoch: 6| Step: 3
Training loss: 2.70665585335637
Validation loss: 2.804233892420266

Epoch: 6| Step: 4
Training loss: 3.088440934715534
Validation loss: 2.804370781921684

Epoch: 6| Step: 5
Training loss: 3.2427551507965533
Validation loss: 2.8042200796845087

Epoch: 6| Step: 6
Training loss: 2.6469634238361635
Validation loss: 2.803161214939183

Epoch: 6| Step: 7
Training loss: 3.109513629525851
Validation loss: 2.803989863499678

Epoch: 6| Step: 8
Training loss: 3.1019763430216574
Validation loss: 2.8036350306217996

Epoch: 6| Step: 9
Training loss: 2.5616364303257155
Validation loss: 2.8045334682419596

Epoch: 6| Step: 10
Training loss: 3.390225857212914
Validation loss: 2.807190897248236

Epoch: 6| Step: 11
Training loss: 3.4345360201852877
Validation loss: 2.803043168301877

Epoch: 6| Step: 12
Training loss: 3.115821022593632
Validation loss: 2.8091414265883707

Epoch: 6| Step: 13
Training loss: 3.6070131443123667
Validation loss: 2.8039694337686605

Epoch: 152| Step: 0
Training loss: 3.3273532312871197
Validation loss: 2.8045793559835452

Epoch: 6| Step: 1
Training loss: 2.792292244883218
Validation loss: 2.807355962456071

Epoch: 6| Step: 2
Training loss: 3.0059851706234846
Validation loss: 2.807414217695539

Epoch: 6| Step: 3
Training loss: 2.899622590072018
Validation loss: 2.8048605062155842

Epoch: 6| Step: 4
Training loss: 3.56274092010204
Validation loss: 2.8102754269988353

Epoch: 6| Step: 5
Training loss: 2.8816145395300796
Validation loss: 2.8042858351576383

Epoch: 6| Step: 6
Training loss: 3.0073714292065765
Validation loss: 2.806388191960569

Epoch: 6| Step: 7
Training loss: 3.7961389903599234
Validation loss: 2.8015050291680135

Epoch: 6| Step: 8
Training loss: 3.256505177872552
Validation loss: 2.80036052881951

Epoch: 6| Step: 9
Training loss: 3.1362004784224067
Validation loss: 2.8010623082798447

Epoch: 6| Step: 10
Training loss: 2.3913866213641315
Validation loss: 2.800899050564147

Epoch: 6| Step: 11
Training loss: 3.061453971500584
Validation loss: 2.80000757532809

Epoch: 6| Step: 12
Training loss: 2.7382045414039444
Validation loss: 2.8023033057272047

Epoch: 6| Step: 13
Training loss: 3.701862103763229
Validation loss: 2.8014473831391666

Epoch: 153| Step: 0
Training loss: 3.418852006412101
Validation loss: 2.802060931179823

Epoch: 6| Step: 1
Training loss: 3.27185632213956
Validation loss: 2.8041263507638248

Epoch: 6| Step: 2
Training loss: 3.0547614905720915
Validation loss: 2.8088710575616562

Epoch: 6| Step: 3
Training loss: 2.8503115901939298
Validation loss: 2.800570359055372

Epoch: 6| Step: 4
Training loss: 2.987210988386281
Validation loss: 2.8032081283926593

Epoch: 6| Step: 5
Training loss: 3.2380438741782847
Validation loss: 2.8024353844299363

Epoch: 6| Step: 6
Training loss: 3.3280503528802194
Validation loss: 2.8083755915259947

Epoch: 6| Step: 7
Training loss: 3.277882910154154
Validation loss: 2.8020066918957824

Epoch: 6| Step: 8
Training loss: 3.3055198108296975
Validation loss: 2.799972019334088

Epoch: 6| Step: 9
Training loss: 3.2563824705389868
Validation loss: 2.80001808437537

Epoch: 6| Step: 10
Training loss: 3.2925864435548613
Validation loss: 2.796620227023294

Epoch: 6| Step: 11
Training loss: 2.1779826617150664
Validation loss: 2.798453653531177

Epoch: 6| Step: 12
Training loss: 3.0776532581386653
Validation loss: 2.7980205494949075

Epoch: 6| Step: 13
Training loss: 2.521320033313539
Validation loss: 2.7985216798543147

Epoch: 154| Step: 0
Training loss: 3.301919846844831
Validation loss: 2.7970772305359732

Epoch: 6| Step: 1
Training loss: 2.926325056114821
Validation loss: 2.7966952591268166

Epoch: 6| Step: 2
Training loss: 2.9671422520020374
Validation loss: 2.799646238973031

Epoch: 6| Step: 3
Training loss: 2.7205218975670094
Validation loss: 2.802865165684954

Epoch: 6| Step: 4
Training loss: 2.6496289479296045
Validation loss: 2.8012678432165834

Epoch: 6| Step: 5
Training loss: 3.552165518040187
Validation loss: 2.8007843804287234

Epoch: 6| Step: 6
Training loss: 3.4668661964900283
Validation loss: 2.797958751600155

Epoch: 6| Step: 7
Training loss: 2.6206137022852536
Validation loss: 2.796522129127486

Epoch: 6| Step: 8
Training loss: 2.782499054311367
Validation loss: 2.7972538894735774

Epoch: 6| Step: 9
Training loss: 3.217264962433305
Validation loss: 2.7946370453506226

Epoch: 6| Step: 10
Training loss: 3.6425820521929233
Validation loss: 2.795574951874195

Epoch: 6| Step: 11
Training loss: 2.8688981360790335
Validation loss: 2.798700395662505

Epoch: 6| Step: 12
Training loss: 3.165585149154553
Validation loss: 2.794970242981041

Epoch: 6| Step: 13
Training loss: 3.5887001714964204
Validation loss: 2.801659994232411

Epoch: 155| Step: 0
Training loss: 2.938710713969715
Validation loss: 2.798212549751397

Epoch: 6| Step: 1
Training loss: 3.716245689556395
Validation loss: 2.7993445246666084

Epoch: 6| Step: 2
Training loss: 2.841783954813842
Validation loss: 2.7978664869755727

Epoch: 6| Step: 3
Training loss: 2.497811885753963
Validation loss: 2.799067382441885

Epoch: 6| Step: 4
Training loss: 3.4217612887784576
Validation loss: 2.7996306481936

Epoch: 6| Step: 5
Training loss: 3.201674118814396
Validation loss: 2.797722630335361

Epoch: 6| Step: 6
Training loss: 2.9095450149832476
Validation loss: 2.799062801151333

Epoch: 6| Step: 7
Training loss: 3.490583969052646
Validation loss: 2.7986422283530192

Epoch: 6| Step: 8
Training loss: 3.095234832482487
Validation loss: 2.799906397864957

Epoch: 6| Step: 9
Training loss: 3.3538227418339477
Validation loss: 2.796105307390139

Epoch: 6| Step: 10
Training loss: 2.6105581559310354
Validation loss: 2.800795292050731

Epoch: 6| Step: 11
Training loss: 3.16156283880935
Validation loss: 2.7971668825536447

Epoch: 6| Step: 12
Training loss: 3.094541352141662
Validation loss: 2.7964600826846686

Epoch: 6| Step: 13
Training loss: 2.886635496515986
Validation loss: 2.798087780997617

Epoch: 156| Step: 0
Training loss: 2.8037964832059905
Validation loss: 2.7960608227616577

Epoch: 6| Step: 1
Training loss: 2.713841710309074
Validation loss: 2.799813594927201

Epoch: 6| Step: 2
Training loss: 3.4841523377303996
Validation loss: 2.801695439131396

Epoch: 6| Step: 3
Training loss: 2.9901873325108412
Validation loss: 2.8012355649300296

Epoch: 6| Step: 4
Training loss: 2.805241692069996
Validation loss: 2.802503645248906

Epoch: 6| Step: 5
Training loss: 3.923226416229439
Validation loss: 2.8037730593874177

Epoch: 6| Step: 6
Training loss: 3.1441765437075078
Validation loss: 2.797228886740358

Epoch: 6| Step: 7
Training loss: 3.187846894181047
Validation loss: 2.797422403954405

Epoch: 6| Step: 8
Training loss: 3.371864557824569
Validation loss: 2.7961228285539237

Epoch: 6| Step: 9
Training loss: 3.221212685679391
Validation loss: 2.796772405745856

Epoch: 6| Step: 10
Training loss: 2.5842984355392593
Validation loss: 2.799538160285826

Epoch: 6| Step: 11
Training loss: 2.5888804489711266
Validation loss: 2.7988937827411533

Epoch: 6| Step: 12
Training loss: 2.713699912193672
Validation loss: 2.800290673157503

Epoch: 6| Step: 13
Training loss: 4.004805062987373
Validation loss: 2.7991559742608354

Epoch: 157| Step: 0
Training loss: 3.0837812012515387
Validation loss: 2.7955812482307887

Epoch: 6| Step: 1
Training loss: 2.5351925510811064
Validation loss: 2.795185314980059

Epoch: 6| Step: 2
Training loss: 2.921303759542574
Validation loss: 2.7936101058750107

Epoch: 6| Step: 3
Training loss: 3.6349604337656145
Validation loss: 2.7955774957286827

Epoch: 6| Step: 4
Training loss: 2.554606865126523
Validation loss: 2.795960331362964

Epoch: 6| Step: 5
Training loss: 2.8003763627104035
Validation loss: 2.7917703845893245

Epoch: 6| Step: 6
Training loss: 3.1812509353126694
Validation loss: 2.792238209720481

Epoch: 6| Step: 7
Training loss: 2.7467802445838534
Validation loss: 2.790568304797935

Epoch: 6| Step: 8
Training loss: 3.0274519574915524
Validation loss: 2.793651971966647

Epoch: 6| Step: 9
Training loss: 3.4917458888666273
Validation loss: 2.7932223719374596

Epoch: 6| Step: 10
Training loss: 3.8825472274825983
Validation loss: 2.7937379403881897

Epoch: 6| Step: 11
Training loss: 3.457475088475224
Validation loss: 2.792187028035297

Epoch: 6| Step: 12
Training loss: 3.0890292747150174
Validation loss: 2.791943115984878

Epoch: 6| Step: 13
Training loss: 2.462045184119792
Validation loss: 2.79033681435659

Epoch: 158| Step: 0
Training loss: 2.6996587678952557
Validation loss: 2.7926044447098306

Epoch: 6| Step: 1
Training loss: 2.7859411217135914
Validation loss: 2.793330712430872

Epoch: 6| Step: 2
Training loss: 2.7460080563454135
Validation loss: 2.791518105631482

Epoch: 6| Step: 3
Training loss: 2.590827582414178
Validation loss: 2.79536198618006

Epoch: 6| Step: 4
Training loss: 3.5064535588488503
Validation loss: 2.8008264230288975

Epoch: 6| Step: 5
Training loss: 3.279492734202801
Validation loss: 2.8001250715199775

Epoch: 6| Step: 6
Training loss: 2.931727642518941
Validation loss: 2.799894897697475

Epoch: 6| Step: 7
Training loss: 3.655046835624062
Validation loss: 2.7911089923425307

Epoch: 6| Step: 8
Training loss: 3.22715920017837
Validation loss: 2.789722969587846

Epoch: 6| Step: 9
Training loss: 2.7693199862674467
Validation loss: 2.7868381324594274

Epoch: 6| Step: 10
Training loss: 3.616851725143341
Validation loss: 2.788204912541048

Epoch: 6| Step: 11
Training loss: 3.540943984555222
Validation loss: 2.787306562845374

Epoch: 6| Step: 12
Training loss: 3.0027234113603996
Validation loss: 2.787605148245958

Epoch: 6| Step: 13
Training loss: 2.569348279052695
Validation loss: 2.7915407139210258

Epoch: 159| Step: 0
Training loss: 3.147819515187507
Validation loss: 2.7869197208544985

Epoch: 6| Step: 1
Training loss: 2.715331021497182
Validation loss: 2.7866507478249396

Epoch: 6| Step: 2
Training loss: 2.9253271588330176
Validation loss: 2.788268440011272

Epoch: 6| Step: 3
Training loss: 3.4578792932732836
Validation loss: 2.789104634731317

Epoch: 6| Step: 4
Training loss: 3.0991273636226357
Validation loss: 2.7888484183404585

Epoch: 6| Step: 5
Training loss: 2.7048916198115514
Validation loss: 2.7917509490214067

Epoch: 6| Step: 6
Training loss: 2.7185542595215733
Validation loss: 2.7885548624930534

Epoch: 6| Step: 7
Training loss: 3.433485565390742
Validation loss: 2.7910821958214593

Epoch: 6| Step: 8
Training loss: 3.111151872852264
Validation loss: 2.7934797830723053

Epoch: 6| Step: 9
Training loss: 2.411854348233891
Validation loss: 2.8027090287510443

Epoch: 6| Step: 10
Training loss: 3.2541827648772466
Validation loss: 2.815427941029724

Epoch: 6| Step: 11
Training loss: 3.3198152775678427
Validation loss: 2.8098072601919393

Epoch: 6| Step: 12
Training loss: 3.4863386565404655
Validation loss: 2.807222363689209

Epoch: 6| Step: 13
Training loss: 3.7315705434854505
Validation loss: 2.8015092184655273

Epoch: 160| Step: 0
Training loss: 3.3484441304107824
Validation loss: 2.7974152741231957

Epoch: 6| Step: 1
Training loss: 3.218289536807496
Validation loss: 2.790492684426813

Epoch: 6| Step: 2
Training loss: 2.7514093428990867
Validation loss: 2.7860176192553783

Epoch: 6| Step: 3
Training loss: 3.692376872019818
Validation loss: 2.7846328277337564

Epoch: 6| Step: 4
Training loss: 3.275165111077879
Validation loss: 2.7879614594606137

Epoch: 6| Step: 5
Training loss: 2.9992081868769933
Validation loss: 2.7888528187725363

Epoch: 6| Step: 6
Training loss: 3.512339909390764
Validation loss: 2.7876586855651033

Epoch: 6| Step: 7
Training loss: 2.7967723635802972
Validation loss: 2.791593524658538

Epoch: 6| Step: 8
Training loss: 2.9374152638002746
Validation loss: 2.788512513518486

Epoch: 6| Step: 9
Training loss: 2.418898888867455
Validation loss: 2.7924795392227915

Epoch: 6| Step: 10
Training loss: 2.580402270161475
Validation loss: 2.7923218134834626

Epoch: 6| Step: 11
Training loss: 3.1883032291611006
Validation loss: 2.7912195411162335

Epoch: 6| Step: 12
Training loss: 3.1688816622556106
Validation loss: 2.7899668276367233

Epoch: 6| Step: 13
Training loss: 3.4839259658024986
Validation loss: 2.7915610316540724

Epoch: 161| Step: 0
Training loss: 2.973421617346244
Validation loss: 2.792545792393152

Epoch: 6| Step: 1
Training loss: 3.265727502409703
Validation loss: 2.7902357676654317

Epoch: 6| Step: 2
Training loss: 3.0382295462381976
Validation loss: 2.79305060722995

Epoch: 6| Step: 3
Training loss: 3.051061326772466
Validation loss: 2.794742490100581

Epoch: 6| Step: 4
Training loss: 3.2417609612120803
Validation loss: 2.798764610052157

Epoch: 6| Step: 5
Training loss: 3.2259633244548116
Validation loss: 2.8020649888139237

Epoch: 6| Step: 6
Training loss: 2.37823125975287
Validation loss: 2.800661531358998

Epoch: 6| Step: 7
Training loss: 3.291361605515523
Validation loss: 2.8188990545975194

Epoch: 6| Step: 8
Training loss: 3.297373801731051
Validation loss: 2.792743771383391

Epoch: 6| Step: 9
Training loss: 2.8613487893878387
Validation loss: 2.7863496504848726

Epoch: 6| Step: 10
Training loss: 3.2346624716563537
Validation loss: 2.7809950373056567

Epoch: 6| Step: 11
Training loss: 3.271186145455158
Validation loss: 2.787246770736317

Epoch: 6| Step: 12
Training loss: 3.1009364036674216
Validation loss: 2.794711840825771

Epoch: 6| Step: 13
Training loss: 3.1522498134528574
Validation loss: 2.805099606476385

Epoch: 162| Step: 0
Training loss: 2.666134920350653
Validation loss: 2.818145484822119

Epoch: 6| Step: 1
Training loss: 3.8423898662998206
Validation loss: 2.831676647261857

Epoch: 6| Step: 2
Training loss: 3.132933654725569
Validation loss: 2.8265057160587537

Epoch: 6| Step: 3
Training loss: 2.7833756456947
Validation loss: 2.8089636497861203

Epoch: 6| Step: 4
Training loss: 3.2585304987605284
Validation loss: 2.800452902601102

Epoch: 6| Step: 5
Training loss: 3.484846553626047
Validation loss: 2.801223682180493

Epoch: 6| Step: 6
Training loss: 2.5011106884853995
Validation loss: 2.7950933660395303

Epoch: 6| Step: 7
Training loss: 3.0060966849142985
Validation loss: 2.7924452672238367

Epoch: 6| Step: 8
Training loss: 2.930408765381813
Validation loss: 2.789285654252162

Epoch: 6| Step: 9
Training loss: 2.9047439118273988
Validation loss: 2.7863356442026834

Epoch: 6| Step: 10
Training loss: 3.0603648936802785
Validation loss: 2.786685320157886

Epoch: 6| Step: 11
Training loss: 2.9391609528279354
Validation loss: 2.784259995673086

Epoch: 6| Step: 12
Training loss: 3.7903616339635913
Validation loss: 2.7829214900952506

Epoch: 6| Step: 13
Training loss: 3.070962851565183
Validation loss: 2.7827025571627155

Epoch: 163| Step: 0
Training loss: 3.0715609043546825
Validation loss: 2.788499807965211

Epoch: 6| Step: 1
Training loss: 3.498581735177105
Validation loss: 2.805816331818698

Epoch: 6| Step: 2
Training loss: 2.05107198924958
Validation loss: 2.8158640450886625

Epoch: 6| Step: 3
Training loss: 3.3173143920490564
Validation loss: 2.8149341217977875

Epoch: 6| Step: 4
Training loss: 2.8217296474192914
Validation loss: 2.822405620193648

Epoch: 6| Step: 5
Training loss: 2.9282364570632136
Validation loss: 2.811951310974988

Epoch: 6| Step: 6
Training loss: 3.0174207331526333
Validation loss: 2.8036065112911506

Epoch: 6| Step: 7
Training loss: 3.6557104250546195
Validation loss: 2.8015987378088654

Epoch: 6| Step: 8
Training loss: 3.1521092815722036
Validation loss: 2.794888558465827

Epoch: 6| Step: 9
Training loss: 2.9440539678934456
Validation loss: 2.788195706900423

Epoch: 6| Step: 10
Training loss: 3.308004964167458
Validation loss: 2.7903350898497368

Epoch: 6| Step: 11
Training loss: 2.8670206878948212
Validation loss: 2.7795449598304938

Epoch: 6| Step: 12
Training loss: 3.434078247467434
Validation loss: 2.7788909331319953

Epoch: 6| Step: 13
Training loss: 3.066680857031236
Validation loss: 2.7814440150867705

Epoch: 164| Step: 0
Training loss: 3.47421370467962
Validation loss: 2.780049067406762

Epoch: 6| Step: 1
Training loss: 3.1579841910625484
Validation loss: 2.777856310141066

Epoch: 6| Step: 2
Training loss: 2.8299883189145625
Validation loss: 2.7832683315673146

Epoch: 6| Step: 3
Training loss: 2.362199620925967
Validation loss: 2.787453511992386

Epoch: 6| Step: 4
Training loss: 2.79152077440734
Validation loss: 2.7934782229427766

Epoch: 6| Step: 5
Training loss: 3.8585457470772067
Validation loss: 2.798989123041007

Epoch: 6| Step: 6
Training loss: 3.348817212269342
Validation loss: 2.8013722687503138

Epoch: 6| Step: 7
Training loss: 3.03952360209987
Validation loss: 2.787681928433264

Epoch: 6| Step: 8
Training loss: 3.032773922768721
Validation loss: 2.7886685204899755

Epoch: 6| Step: 9
Training loss: 3.3773496007857604
Validation loss: 2.7832897845918927

Epoch: 6| Step: 10
Training loss: 2.4695997103766003
Validation loss: 2.7818106689589244

Epoch: 6| Step: 11
Training loss: 3.3611608681967264
Validation loss: 2.777963292548085

Epoch: 6| Step: 12
Training loss: 2.820657133142957
Validation loss: 2.7764136617262767

Epoch: 6| Step: 13
Training loss: 3.066092116672283
Validation loss: 2.776058872422539

Epoch: 165| Step: 0
Training loss: 3.5117890856937097
Validation loss: 2.773738587654553

Epoch: 6| Step: 1
Training loss: 3.007796963738284
Validation loss: 2.774275627404152

Epoch: 6| Step: 2
Training loss: 2.878469281309492
Validation loss: 2.776645502302462

Epoch: 6| Step: 3
Training loss: 3.3136954399691096
Validation loss: 2.7753002464388916

Epoch: 6| Step: 4
Training loss: 3.068415630949127
Validation loss: 2.775417931416244

Epoch: 6| Step: 5
Training loss: 2.620804931373521
Validation loss: 2.7776244174160167

Epoch: 6| Step: 6
Training loss: 2.567414386217036
Validation loss: 2.782105394858821

Epoch: 6| Step: 7
Training loss: 3.139901756401935
Validation loss: 2.7788898223924896

Epoch: 6| Step: 8
Training loss: 3.4416991508619614
Validation loss: 2.778748109977291

Epoch: 6| Step: 9
Training loss: 2.7008771425260676
Validation loss: 2.776799293648521

Epoch: 6| Step: 10
Training loss: 3.0956835628818045
Validation loss: 2.781201979658239

Epoch: 6| Step: 11
Training loss: 3.6273561910021144
Validation loss: 2.781758599155981

Epoch: 6| Step: 12
Training loss: 3.150238355065468
Validation loss: 2.7806295707831263

Epoch: 6| Step: 13
Training loss: 2.8092260166334992
Validation loss: 2.778643937651382

Epoch: 166| Step: 0
Training loss: 3.2047790722571716
Validation loss: 2.7837503533338

Epoch: 6| Step: 1
Training loss: 3.448617608466301
Validation loss: 2.7847126091371512

Epoch: 6| Step: 2
Training loss: 3.0957895357123792
Validation loss: 2.7763751026980694

Epoch: 6| Step: 3
Training loss: 3.4948025668675875
Validation loss: 2.7737910413796216

Epoch: 6| Step: 4
Training loss: 3.602471160455565
Validation loss: 2.7714296270336427

Epoch: 6| Step: 5
Training loss: 2.4733242681325174
Validation loss: 2.7749140809931667

Epoch: 6| Step: 6
Training loss: 2.484136222065004
Validation loss: 2.7700184664672123

Epoch: 6| Step: 7
Training loss: 2.7295041542951
Validation loss: 2.7734654578983986

Epoch: 6| Step: 8
Training loss: 3.1525198167606114
Validation loss: 2.772285952832771

Epoch: 6| Step: 9
Training loss: 3.1895906660484443
Validation loss: 2.772309566864502

Epoch: 6| Step: 10
Training loss: 3.090044056106119
Validation loss: 2.7685984343986383

Epoch: 6| Step: 11
Training loss: 2.941811502005198
Validation loss: 2.7697454669032515

Epoch: 6| Step: 12
Training loss: 3.128868912415722
Validation loss: 2.7702314093277725

Epoch: 6| Step: 13
Training loss: 3.0855378870018795
Validation loss: 2.7727483891293616

Epoch: 167| Step: 0
Training loss: 2.5260178922078422
Validation loss: 2.772093623590583

Epoch: 6| Step: 1
Training loss: 3.145343178127137
Validation loss: 2.774200287415088

Epoch: 6| Step: 2
Training loss: 3.619961624363611
Validation loss: 2.77131935913032

Epoch: 6| Step: 3
Training loss: 3.1926025240334637
Validation loss: 2.775506880005643

Epoch: 6| Step: 4
Training loss: 2.55248303040665
Validation loss: 2.7704496232864604

Epoch: 6| Step: 5
Training loss: 3.0992233718672213
Validation loss: 2.77002512169998

Epoch: 6| Step: 6
Training loss: 2.9159122762998497
Validation loss: 2.771883684423964

Epoch: 6| Step: 7
Training loss: 2.8699146574403933
Validation loss: 2.772516200480809

Epoch: 6| Step: 8
Training loss: 2.348266725301702
Validation loss: 2.77418738046954

Epoch: 6| Step: 9
Training loss: 3.486535740929429
Validation loss: 2.7776797964049944

Epoch: 6| Step: 10
Training loss: 3.0450169301932584
Validation loss: 2.777245428148582

Epoch: 6| Step: 11
Training loss: 3.6450026228781476
Validation loss: 2.778663620819442

Epoch: 6| Step: 12
Training loss: 3.1023563166690207
Validation loss: 2.801484539221791

Epoch: 6| Step: 13
Training loss: 3.5602758056442565
Validation loss: 2.7889582468941794

Epoch: 168| Step: 0
Training loss: 3.081641961908697
Validation loss: 2.7863765164403547

Epoch: 6| Step: 1
Training loss: 2.8550647705534065
Validation loss: 2.7911914092750907

Epoch: 6| Step: 2
Training loss: 2.647972943908212
Validation loss: 2.787414806772339

Epoch: 6| Step: 3
Training loss: 3.761445951621883
Validation loss: 2.792117454511947

Epoch: 6| Step: 4
Training loss: 2.733782894876768
Validation loss: 2.773501172534333

Epoch: 6| Step: 5
Training loss: 3.1559691351383337
Validation loss: 2.770993327954869

Epoch: 6| Step: 6
Training loss: 3.8337383609143556
Validation loss: 2.7672501281513124

Epoch: 6| Step: 7
Training loss: 3.0051078228640273
Validation loss: 2.7679534541121646

Epoch: 6| Step: 8
Training loss: 2.9345889987445832
Validation loss: 2.767380605090219

Epoch: 6| Step: 9
Training loss: 3.3021198515371935
Validation loss: 2.768657442169556

Epoch: 6| Step: 10
Training loss: 3.087546863277474
Validation loss: 2.7703593037739553

Epoch: 6| Step: 11
Training loss: 2.8619018396142453
Validation loss: 2.7703655760060566

Epoch: 6| Step: 12
Training loss: 2.4965757761234713
Validation loss: 2.7733081704858593

Epoch: 6| Step: 13
Training loss: 3.366392957936018
Validation loss: 2.7676368080912632

Epoch: 169| Step: 0
Training loss: 3.304628917274039
Validation loss: 2.7678334390649684

Epoch: 6| Step: 1
Training loss: 2.819762791876936
Validation loss: 2.769227372214488

Epoch: 6| Step: 2
Training loss: 2.929914541983714
Validation loss: 2.7717993226908035

Epoch: 6| Step: 3
Training loss: 3.3489537612306384
Validation loss: 2.7760065585164706

Epoch: 6| Step: 4
Training loss: 3.5466194228799783
Validation loss: 2.7774648300045253

Epoch: 6| Step: 5
Training loss: 2.8727912711333556
Validation loss: 2.778937738774616

Epoch: 6| Step: 6
Training loss: 3.294685395985557
Validation loss: 2.7897534825309123

Epoch: 6| Step: 7
Training loss: 3.109711901944961
Validation loss: 2.7869388515997815

Epoch: 6| Step: 8
Training loss: 3.1700602634610293
Validation loss: 2.7909416646417893

Epoch: 6| Step: 9
Training loss: 3.2001656608616385
Validation loss: 2.784148527842828

Epoch: 6| Step: 10
Training loss: 3.1736445259395967
Validation loss: 2.769422889349638

Epoch: 6| Step: 11
Training loss: 2.972474342023705
Validation loss: 2.7743712814490906

Epoch: 6| Step: 12
Training loss: 2.017909212079622
Validation loss: 2.7634201331127595

Epoch: 6| Step: 13
Training loss: 3.340235922470332
Validation loss: 2.764403250215702

Epoch: 170| Step: 0
Training loss: 3.510900960204968
Validation loss: 2.7645594112503296

Epoch: 6| Step: 1
Training loss: 3.223842998818378
Validation loss: 2.7665716485812273

Epoch: 6| Step: 2
Training loss: 2.3002638955689
Validation loss: 2.762101231286908

Epoch: 6| Step: 3
Training loss: 2.930290139841088
Validation loss: 2.7634857322602873

Epoch: 6| Step: 4
Training loss: 2.8940162354958336
Validation loss: 2.763581306147225

Epoch: 6| Step: 5
Training loss: 2.9453871335558106
Validation loss: 2.7629305858327853

Epoch: 6| Step: 6
Training loss: 2.801307703229877
Validation loss: 2.7659050371141576

Epoch: 6| Step: 7
Training loss: 3.3776040098042723
Validation loss: 2.7634439444326215

Epoch: 6| Step: 8
Training loss: 2.7258360149013106
Validation loss: 2.7625688858215125

Epoch: 6| Step: 9
Training loss: 3.6231415029337124
Validation loss: 2.7625559774286264

Epoch: 6| Step: 10
Training loss: 2.834007762599482
Validation loss: 2.76882777484326

Epoch: 6| Step: 11
Training loss: 3.14714080385003
Validation loss: 2.766439927861161

Epoch: 6| Step: 12
Training loss: 3.7711872475688057
Validation loss: 2.765353598816486

Epoch: 6| Step: 13
Training loss: 2.4430252444399145
Validation loss: 2.7651439276383134

Epoch: 171| Step: 0
Training loss: 2.8100529515717683
Validation loss: 2.7700981495895625

Epoch: 6| Step: 1
Training loss: 3.589972193830758
Validation loss: 2.771894271426037

Epoch: 6| Step: 2
Training loss: 3.035814447112966
Validation loss: 2.77447404245915

Epoch: 6| Step: 3
Training loss: 2.639754834784578
Validation loss: 2.7686832334836335

Epoch: 6| Step: 4
Training loss: 3.248302016155391
Validation loss: 2.768164394271725

Epoch: 6| Step: 5
Training loss: 3.198969233916747
Validation loss: 2.768684724250169

Epoch: 6| Step: 6
Training loss: 3.0404793150639966
Validation loss: 2.763633184576326

Epoch: 6| Step: 7
Training loss: 3.724278675875184
Validation loss: 2.7669590385468945

Epoch: 6| Step: 8
Training loss: 3.869480385803205
Validation loss: 2.764816324461535

Epoch: 6| Step: 9
Training loss: 2.017770143217655
Validation loss: 2.7617303831457645

Epoch: 6| Step: 10
Training loss: 3.370688333367273
Validation loss: 2.762671799097632

Epoch: 6| Step: 11
Training loss: 2.710044867788134
Validation loss: 2.7638653162114886

Epoch: 6| Step: 12
Training loss: 2.62889944815358
Validation loss: 2.763827230488159

Epoch: 6| Step: 13
Training loss: 2.4223274054520587
Validation loss: 2.7627116090940715

Epoch: 172| Step: 0
Training loss: 3.6851600076002415
Validation loss: 2.760616887903932

Epoch: 6| Step: 1
Training loss: 2.4958939211140567
Validation loss: 2.762903770257221

Epoch: 6| Step: 2
Training loss: 2.943789951191049
Validation loss: 2.7642763247971116

Epoch: 6| Step: 3
Training loss: 3.428037068187732
Validation loss: 2.763711617717158

Epoch: 6| Step: 4
Training loss: 3.0353032963897064
Validation loss: 2.7627586665706017

Epoch: 6| Step: 5
Training loss: 3.388323868792879
Validation loss: 2.7655085307451626

Epoch: 6| Step: 6
Training loss: 3.5918959105602997
Validation loss: 2.7651987518451038

Epoch: 6| Step: 7
Training loss: 3.091482545317526
Validation loss: 2.7664255307205794

Epoch: 6| Step: 8
Training loss: 2.945108340849834
Validation loss: 2.762841709295166

Epoch: 6| Step: 9
Training loss: 3.630279642478355
Validation loss: 2.763192140029461

Epoch: 6| Step: 10
Training loss: 2.841350003793122
Validation loss: 2.7615599385498704

Epoch: 6| Step: 11
Training loss: 2.485331417219436
Validation loss: 2.756223562764569

Epoch: 6| Step: 12
Training loss: 2.2181798712854044
Validation loss: 2.762135401797661

Epoch: 6| Step: 13
Training loss: 2.7227643072284615
Validation loss: 2.7586715807099593

Epoch: 173| Step: 0
Training loss: 3.2857912155291213
Validation loss: 2.759563044886794

Epoch: 6| Step: 1
Training loss: 3.3869003722385647
Validation loss: 2.759991920810697

Epoch: 6| Step: 2
Training loss: 3.304596883915729
Validation loss: 2.7596297575992885

Epoch: 6| Step: 3
Training loss: 3.006241028706891
Validation loss: 2.764728712136296

Epoch: 6| Step: 4
Training loss: 2.7728368834136354
Validation loss: 2.758082685714771

Epoch: 6| Step: 5
Training loss: 3.3798416166046183
Validation loss: 2.75977026502236

Epoch: 6| Step: 6
Training loss: 2.446931248355721
Validation loss: 2.760280999727017

Epoch: 6| Step: 7
Training loss: 2.439777874919964
Validation loss: 2.7593300301041794

Epoch: 6| Step: 8
Training loss: 3.296641120027379
Validation loss: 2.7650156093049185

Epoch: 6| Step: 9
Training loss: 3.200317939222504
Validation loss: 2.762258493251943

Epoch: 6| Step: 10
Training loss: 3.3289040383522046
Validation loss: 2.76159697590804

Epoch: 6| Step: 11
Training loss: 2.3693806274315037
Validation loss: 2.7666316614211017

Epoch: 6| Step: 12
Training loss: 3.2541240056001617
Validation loss: 2.7641265593672846

Epoch: 6| Step: 13
Training loss: 3.5188262605957545
Validation loss: 2.7598214450196767

Epoch: 174| Step: 0
Training loss: 3.0926012160467993
Validation loss: 2.757953865950281

Epoch: 6| Step: 1
Training loss: 2.812145634685144
Validation loss: 2.757366581393466

Epoch: 6| Step: 2
Training loss: 3.223182515031924
Validation loss: 2.756973938096123

Epoch: 6| Step: 3
Training loss: 3.192622388436961
Validation loss: 2.7568481956961683

Epoch: 6| Step: 4
Training loss: 2.4768564910158606
Validation loss: 2.7575011248533228

Epoch: 6| Step: 5
Training loss: 3.5299275040138927
Validation loss: 2.7533172706032767

Epoch: 6| Step: 6
Training loss: 3.342616949895765
Validation loss: 2.7591142928180283

Epoch: 6| Step: 7
Training loss: 2.955851592946839
Validation loss: 2.7601589792297183

Epoch: 6| Step: 8
Training loss: 3.0803995007116165
Validation loss: 2.758351700860446

Epoch: 6| Step: 9
Training loss: 3.365796432450249
Validation loss: 2.761685923137165

Epoch: 6| Step: 10
Training loss: 3.2745971082430088
Validation loss: 2.75802909202497

Epoch: 6| Step: 11
Training loss: 2.6039406843681214
Validation loss: 2.754327691269438

Epoch: 6| Step: 12
Training loss: 3.1744393942607365
Validation loss: 2.7532525260546623

Epoch: 6| Step: 13
Training loss: 2.7047735931075496
Validation loss: 2.753472368639612

Epoch: 175| Step: 0
Training loss: 2.57599676894939
Validation loss: 2.7566655818016867

Epoch: 6| Step: 1
Training loss: 3.5550548992397975
Validation loss: 2.758971214339413

Epoch: 6| Step: 2
Training loss: 2.919070279766791
Validation loss: 2.762610003893953

Epoch: 6| Step: 3
Training loss: 3.0662614727466555
Validation loss: 2.7787411139810216

Epoch: 6| Step: 4
Training loss: 2.9649534343388684
Validation loss: 2.7875404703167597

Epoch: 6| Step: 5
Training loss: 3.152963721514571
Validation loss: 2.80255682386688

Epoch: 6| Step: 6
Training loss: 2.7949884114852632
Validation loss: 2.798238968327928

Epoch: 6| Step: 7
Training loss: 3.574787298957532
Validation loss: 2.765054960918288

Epoch: 6| Step: 8
Training loss: 3.1611697690050877
Validation loss: 2.7544157647332734

Epoch: 6| Step: 9
Training loss: 2.700357243957754
Validation loss: 2.75677175172041

Epoch: 6| Step: 10
Training loss: 3.247025081921819
Validation loss: 2.7523671977994533

Epoch: 6| Step: 11
Training loss: 2.896470381740895
Validation loss: 2.7507115428911697

Epoch: 6| Step: 12
Training loss: 3.1120154129960698
Validation loss: 2.760793185119524

Epoch: 6| Step: 13
Training loss: 3.352973552031838
Validation loss: 2.7606228089555755

Testing loss: 2.9781217534360103
