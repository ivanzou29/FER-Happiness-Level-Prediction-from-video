Epoch: 1| Step: 0
Training loss: 6.063987313531574
Validation loss: 5.73412306417321

Epoch: 5| Step: 1
Training loss: 4.96148630545857
Validation loss: 5.724065632188466

Epoch: 5| Step: 2
Training loss: 5.129941465404509
Validation loss: 5.713675199290546

Epoch: 5| Step: 3
Training loss: 5.370578100247624
Validation loss: 5.704109248785408

Epoch: 5| Step: 4
Training loss: 6.3476225960646335
Validation loss: 5.693406622424715

Epoch: 5| Step: 5
Training loss: 6.328457143096705
Validation loss: 5.682908599392033

Epoch: 5| Step: 6
Training loss: 6.039420014886441
Validation loss: 5.671093025700947

Epoch: 5| Step: 7
Training loss: 4.5230392254366825
Validation loss: 5.6590163629994885

Epoch: 5| Step: 8
Training loss: 6.032631513266289
Validation loss: 5.646051691506121

Epoch: 5| Step: 9
Training loss: 6.0085953498811415
Validation loss: 5.630827876538044

Epoch: 5| Step: 10
Training loss: 5.772086474515702
Validation loss: 5.616124797914938

Epoch: 2| Step: 0
Training loss: 5.324131876068121
Validation loss: 5.599342885262713

Epoch: 5| Step: 1
Training loss: 5.6271575180901445
Validation loss: 5.5806719510631995

Epoch: 5| Step: 2
Training loss: 4.807470690974629
Validation loss: 5.560294816274788

Epoch: 5| Step: 3
Training loss: 4.340561609100539
Validation loss: 5.539309278808884

Epoch: 5| Step: 4
Training loss: 5.2618409095182725
Validation loss: 5.516459914999064

Epoch: 5| Step: 5
Training loss: 6.158607302685519
Validation loss: 5.491827810330393

Epoch: 5| Step: 6
Training loss: 6.585141895245506
Validation loss: 5.465845815546705

Epoch: 5| Step: 7
Training loss: 5.145568882045312
Validation loss: 5.437320342753979

Epoch: 5| Step: 8
Training loss: 5.59952081264985
Validation loss: 5.406028024589419

Epoch: 5| Step: 9
Training loss: 6.35898388308939
Validation loss: 5.375655404969459

Epoch: 5| Step: 10
Training loss: 5.0525424185005186
Validation loss: 5.340491023046723

Epoch: 3| Step: 0
Training loss: 5.843896221432667
Validation loss: 5.304853360470728

Epoch: 5| Step: 1
Training loss: 5.0885389387213875
Validation loss: 5.266859389258128

Epoch: 5| Step: 2
Training loss: 5.487981843757068
Validation loss: 5.228471649083172

Epoch: 5| Step: 3
Training loss: 5.044744744700624
Validation loss: 5.19055402167291

Epoch: 5| Step: 4
Training loss: 5.3628569655328
Validation loss: 5.150592678336923

Epoch: 5| Step: 5
Training loss: 4.466827192316222
Validation loss: 5.1091436729059785

Epoch: 5| Step: 6
Training loss: 4.564229350058619
Validation loss: 5.068470990452042

Epoch: 5| Step: 7
Training loss: 5.643750452863268
Validation loss: 5.0269629271136225

Epoch: 5| Step: 8
Training loss: 4.657287072532308
Validation loss: 4.987265282580404

Epoch: 5| Step: 9
Training loss: 5.172339657657807
Validation loss: 4.945692943957238

Epoch: 5| Step: 10
Training loss: 5.299776526004274
Validation loss: 4.90483389789036

Epoch: 4| Step: 0
Training loss: 5.906219643812532
Validation loss: 4.864212083449952

Epoch: 5| Step: 1
Training loss: 4.3142254459787415
Validation loss: 4.824971447047815

Epoch: 5| Step: 2
Training loss: 3.7534004053206385
Validation loss: 4.785263955681105

Epoch: 5| Step: 3
Training loss: 5.4310942000857505
Validation loss: 4.747668824957143

Epoch: 5| Step: 4
Training loss: 5.002385524067141
Validation loss: 4.712466534124475

Epoch: 5| Step: 5
Training loss: 5.058149375691817
Validation loss: 4.674601666077109

Epoch: 5| Step: 6
Training loss: 4.543282364363234
Validation loss: 4.634648346098918

Epoch: 5| Step: 7
Training loss: 5.3074054300271465
Validation loss: 4.5969871470229675

Epoch: 5| Step: 8
Training loss: 4.384978767091329
Validation loss: 4.5583343121321604

Epoch: 5| Step: 9
Training loss: 4.21440273519614
Validation loss: 4.515122440845435

Epoch: 5| Step: 10
Training loss: 3.880417881711523
Validation loss: 4.463683728650483

Epoch: 5| Step: 0
Training loss: 4.55002152154884
Validation loss: 4.412822298623457

Epoch: 5| Step: 1
Training loss: 3.8933654693252695
Validation loss: 4.367366546641791

Epoch: 5| Step: 2
Training loss: 4.2813787510578605
Validation loss: 4.323567021306927

Epoch: 5| Step: 3
Training loss: 5.009503488207614
Validation loss: 4.287036802542969

Epoch: 5| Step: 4
Training loss: 4.398213518039859
Validation loss: 4.251752652460163

Epoch: 5| Step: 5
Training loss: 4.052644247868331
Validation loss: 4.21751530732767

Epoch: 5| Step: 6
Training loss: 4.362841031536111
Validation loss: 4.1852913818823305

Epoch: 5| Step: 7
Training loss: 4.309867387045789
Validation loss: 4.155417765558481

Epoch: 5| Step: 8
Training loss: 4.345593836406668
Validation loss: 4.127282487823627

Epoch: 5| Step: 9
Training loss: 3.989493877845558
Validation loss: 4.0981239962104175

Epoch: 5| Step: 10
Training loss: 4.649633019845575
Validation loss: 4.0705715645982705

Epoch: 6| Step: 0
Training loss: 4.7497387864417036
Validation loss: 4.042218108003647

Epoch: 5| Step: 1
Training loss: 3.3376517614942784
Validation loss: 4.017920512975622

Epoch: 5| Step: 2
Training loss: 4.603989587661012
Validation loss: 3.9956142290315944

Epoch: 5| Step: 3
Training loss: 3.6373986613521545
Validation loss: 3.9750618843456547

Epoch: 5| Step: 4
Training loss: 4.237567894315742
Validation loss: 3.954017360425505

Epoch: 5| Step: 5
Training loss: 4.537136069591616
Validation loss: 3.9357003616070148

Epoch: 5| Step: 6
Training loss: 3.768023854611446
Validation loss: 3.9189331515358736

Epoch: 5| Step: 7
Training loss: 3.885762680778141
Validation loss: 3.9003991065050525

Epoch: 5| Step: 8
Training loss: 3.7940567923212978
Validation loss: 3.8841252450385966

Epoch: 5| Step: 9
Training loss: 4.12296360497391
Validation loss: 3.8678760202765923

Epoch: 5| Step: 10
Training loss: 4.125919124045461
Validation loss: 3.854189631497057

Epoch: 7| Step: 0
Training loss: 4.886331154068132
Validation loss: 3.8337758296189497

Epoch: 5| Step: 1
Training loss: 2.806501816493958
Validation loss: 3.818220759584609

Epoch: 5| Step: 2
Training loss: 3.901481831075271
Validation loss: 3.804143118721716

Epoch: 5| Step: 3
Training loss: 3.0948678511353616
Validation loss: 3.791477953679228

Epoch: 5| Step: 4
Training loss: 3.6728237793086373
Validation loss: 3.780300844670084

Epoch: 5| Step: 5
Training loss: 4.159650974303895
Validation loss: 3.769153391854117

Epoch: 5| Step: 6
Training loss: 4.601361255746368
Validation loss: 3.7595935750524823

Epoch: 5| Step: 7
Training loss: 4.214644857810184
Validation loss: 3.749842839383045

Epoch: 5| Step: 8
Training loss: 3.624206456111936
Validation loss: 3.73870445552172

Epoch: 5| Step: 9
Training loss: 3.7746767019311154
Validation loss: 3.729979939180136

Epoch: 5| Step: 10
Training loss: 4.249172803374729
Validation loss: 3.719441635741934

Epoch: 8| Step: 0
Training loss: 3.8324576635442287
Validation loss: 3.712390389772882

Epoch: 5| Step: 1
Training loss: 3.8697442128423876
Validation loss: 3.703340390432742

Epoch: 5| Step: 2
Training loss: 3.924361576714108
Validation loss: 3.6950399192516343

Epoch: 5| Step: 3
Training loss: 3.9538575952382065
Validation loss: 3.6872234737884275

Epoch: 5| Step: 4
Training loss: 3.533962591986862
Validation loss: 3.6800535561764973

Epoch: 5| Step: 5
Training loss: 4.6559226925911
Validation loss: 3.673872335298713

Epoch: 5| Step: 6
Training loss: 2.868728763942199
Validation loss: 3.6643495332475267

Epoch: 5| Step: 7
Training loss: 3.4780482856947965
Validation loss: 3.6603488669847306

Epoch: 5| Step: 8
Training loss: 4.49895380362462
Validation loss: 3.657306502723866

Epoch: 5| Step: 9
Training loss: 3.867262097804812
Validation loss: 3.6498154881110434

Epoch: 5| Step: 10
Training loss: 3.730154421680491
Validation loss: 3.642172056439458

Epoch: 9| Step: 0
Training loss: 3.641711682725932
Validation loss: 3.633788036701874

Epoch: 5| Step: 1
Training loss: 4.306137699163285
Validation loss: 3.6253866980225946

Epoch: 5| Step: 2
Training loss: 3.0427194280181604
Validation loss: 3.615996430169762

Epoch: 5| Step: 3
Training loss: 3.4816245954451204
Validation loss: 3.6099323392327913

Epoch: 5| Step: 4
Training loss: 3.7678283323556623
Validation loss: 3.6062261267022357

Epoch: 5| Step: 5
Training loss: 4.598216474006121
Validation loss: 3.59884905003285

Epoch: 5| Step: 6
Training loss: 2.761692678282612
Validation loss: 3.590335938117661

Epoch: 5| Step: 7
Training loss: 4.47662726283869
Validation loss: 3.5878534380234126

Epoch: 5| Step: 8
Training loss: 3.480279953756386
Validation loss: 3.5784663687605676

Epoch: 5| Step: 9
Training loss: 4.341754702055641
Validation loss: 3.5723432431552635

Epoch: 5| Step: 10
Training loss: 3.3446110837729366
Validation loss: 3.5657986084185

Epoch: 10| Step: 0
Training loss: 3.695357147011602
Validation loss: 3.5617220636756577

Epoch: 5| Step: 1
Training loss: 3.952187528763306
Validation loss: 3.5563792778321113

Epoch: 5| Step: 2
Training loss: 3.161997632319549
Validation loss: 3.551510877884506

Epoch: 5| Step: 3
Training loss: 3.6756481507351775
Validation loss: 3.547199015643537

Epoch: 5| Step: 4
Training loss: 3.339703259106521
Validation loss: 3.542872958292474

Epoch: 5| Step: 5
Training loss: 3.958190446918226
Validation loss: 3.537393244146315

Epoch: 5| Step: 6
Training loss: 4.149738689606443
Validation loss: 3.52757352175707

Epoch: 5| Step: 7
Training loss: 3.5090723982370804
Validation loss: 3.524955327817043

Epoch: 5| Step: 8
Training loss: 3.8852175473214685
Validation loss: 3.521192618368718

Epoch: 5| Step: 9
Training loss: 3.6928165708675835
Validation loss: 3.5154050682121847

Epoch: 5| Step: 10
Training loss: 4.111609949886405
Validation loss: 3.5085703798476584

Epoch: 11| Step: 0
Training loss: 3.4702402298850714
Validation loss: 3.5076520585154896

Epoch: 5| Step: 1
Training loss: 4.184868056611237
Validation loss: 3.5032854027578515

Epoch: 5| Step: 2
Training loss: 3.3427598859917396
Validation loss: 3.4979487471593016

Epoch: 5| Step: 3
Training loss: 3.0984139784450577
Validation loss: 3.4941659022390077

Epoch: 5| Step: 4
Training loss: 3.654198617190165
Validation loss: 3.4888981937075965

Epoch: 5| Step: 5
Training loss: 3.6115733136157684
Validation loss: 3.4820697136526566

Epoch: 5| Step: 6
Training loss: 3.6836617100454783
Validation loss: 3.4744657005242803

Epoch: 5| Step: 7
Training loss: 4.283438909592609
Validation loss: 3.471083226150494

Epoch: 5| Step: 8
Training loss: 3.475814498841802
Validation loss: 3.46325066147595

Epoch: 5| Step: 9
Training loss: 4.0428569391241895
Validation loss: 3.4601576987320635

Epoch: 5| Step: 10
Training loss: 3.6091953249380517
Validation loss: 3.4562685382411646

Epoch: 12| Step: 0
Training loss: 4.105033873256826
Validation loss: 3.451578287099216

Epoch: 5| Step: 1
Training loss: 3.630886560002789
Validation loss: 3.446000531885775

Epoch: 5| Step: 2
Training loss: 3.0961382346527446
Validation loss: 3.4414912197694125

Epoch: 5| Step: 3
Training loss: 3.3915887684667267
Validation loss: 3.438011517692699

Epoch: 5| Step: 4
Training loss: 4.064858793501737
Validation loss: 3.431236293929797

Epoch: 5| Step: 5
Training loss: 3.9083646619852
Validation loss: 3.427380383853263

Epoch: 5| Step: 6
Training loss: 4.019065718759645
Validation loss: 3.421948953420232

Epoch: 5| Step: 7
Training loss: 2.7890036867923653
Validation loss: 3.416185054455062

Epoch: 5| Step: 8
Training loss: 3.611848718349871
Validation loss: 3.414593660226542

Epoch: 5| Step: 9
Training loss: 3.1252665596762723
Validation loss: 3.4075950698122006

Epoch: 5| Step: 10
Training loss: 4.20241906573206
Validation loss: 3.4039217911760518

Epoch: 13| Step: 0
Training loss: 2.7606676575377116
Validation loss: 3.4005886633554026

Epoch: 5| Step: 1
Training loss: 3.915933310387991
Validation loss: 3.3955491052281674

Epoch: 5| Step: 2
Training loss: 3.962787865612627
Validation loss: 3.3927669663511626

Epoch: 5| Step: 3
Training loss: 3.4671469068450245
Validation loss: 3.3961271371175985

Epoch: 5| Step: 4
Training loss: 3.7940203449385477
Validation loss: 3.4013595192572645

Epoch: 5| Step: 5
Training loss: 3.815237594545329
Validation loss: 3.4013872963933363

Epoch: 5| Step: 6
Training loss: 3.5028167017253744
Validation loss: 3.394005787541381

Epoch: 5| Step: 7
Training loss: 3.322918324883664
Validation loss: 3.3887279729386397

Epoch: 5| Step: 8
Training loss: 4.157402853871619
Validation loss: 3.3850185890370166

Epoch: 5| Step: 9
Training loss: 3.6854569545949607
Validation loss: 3.377782410770215

Epoch: 5| Step: 10
Training loss: 3.126854918234535
Validation loss: 3.3712806427889315

Epoch: 14| Step: 0
Training loss: 3.9322040607049393
Validation loss: 3.3678799097570606

Epoch: 5| Step: 1
Training loss: 3.4091198232175963
Validation loss: 3.3601103252374656

Epoch: 5| Step: 2
Training loss: 3.7925815247113714
Validation loss: 3.35547946305212

Epoch: 5| Step: 3
Training loss: 3.8614840902919227
Validation loss: 3.3510745503863912

Epoch: 5| Step: 4
Training loss: 3.8287690535621417
Validation loss: 3.3480143089754626

Epoch: 5| Step: 5
Training loss: 3.615346485380148
Validation loss: 3.347190951815976

Epoch: 5| Step: 6
Training loss: 2.871295034398337
Validation loss: 3.3409525904167894

Epoch: 5| Step: 7
Training loss: 3.461856212051905
Validation loss: 3.3346240272517584

Epoch: 5| Step: 8
Training loss: 3.6209138663012754
Validation loss: 3.3320882876728084

Epoch: 5| Step: 9
Training loss: 3.8185129744521715
Validation loss: 3.3248413069039313

Epoch: 5| Step: 10
Training loss: 2.897138690160838
Validation loss: 3.3221978128692315

Epoch: 15| Step: 0
Training loss: 4.161255998271952
Validation loss: 3.3217900620723326

Epoch: 5| Step: 1
Training loss: 3.49488511318265
Validation loss: 3.316345780914427

Epoch: 5| Step: 2
Training loss: 3.956138095809811
Validation loss: 3.313446575255034

Epoch: 5| Step: 3
Training loss: 3.02311543171149
Validation loss: 3.3117852735292534

Epoch: 5| Step: 4
Training loss: 3.932500056456549
Validation loss: 3.3095583013081913

Epoch: 5| Step: 5
Training loss: 2.846593587891757
Validation loss: 3.30486012045802

Epoch: 5| Step: 6
Training loss: 4.081030267522356
Validation loss: 3.2999817289292217

Epoch: 5| Step: 7
Training loss: 2.6577656629092057
Validation loss: 3.2953277131184686

Epoch: 5| Step: 8
Training loss: 2.8995985805634823
Validation loss: 3.291389042922725

Epoch: 5| Step: 9
Training loss: 4.205576809071149
Validation loss: 3.287889863492223

Epoch: 5| Step: 10
Training loss: 3.2044692777511194
Validation loss: 3.2879607644245765

Epoch: 16| Step: 0
Training loss: 3.4752108228662473
Validation loss: 3.281189847161384

Epoch: 5| Step: 1
Training loss: 3.354667168152756
Validation loss: 3.2793195414259246

Epoch: 5| Step: 2
Training loss: 3.7253417248759946
Validation loss: 3.2759317703448088

Epoch: 5| Step: 3
Training loss: 4.083278863245127
Validation loss: 3.2714876161013473

Epoch: 5| Step: 4
Training loss: 3.4735951994027694
Validation loss: 3.2674735606725887

Epoch: 5| Step: 5
Training loss: 3.816362519340677
Validation loss: 3.2655686023629165

Epoch: 5| Step: 6
Training loss: 3.35446859071031
Validation loss: 3.2681062494916633

Epoch: 5| Step: 7
Training loss: 2.7575928165589016
Validation loss: 3.2610058981169567

Epoch: 5| Step: 8
Training loss: 3.8357425803328
Validation loss: 3.2549461467203225

Epoch: 5| Step: 9
Training loss: 3.5921772044508424
Validation loss: 3.2525141751247353

Epoch: 5| Step: 10
Training loss: 2.916791113968715
Validation loss: 3.2486425425105434

Epoch: 17| Step: 0
Training loss: 3.5346181554824163
Validation loss: 3.2457222595717523

Epoch: 5| Step: 1
Training loss: 4.123078100826214
Validation loss: 3.243464052920673

Epoch: 5| Step: 2
Training loss: 3.5073878109772516
Validation loss: 3.2364331474435692

Epoch: 5| Step: 3
Training loss: 3.630068950996559
Validation loss: 3.234767629016056

Epoch: 5| Step: 4
Training loss: 3.3286719790578703
Validation loss: 3.2313545243626076

Epoch: 5| Step: 5
Training loss: 3.035395825134933
Validation loss: 3.228484289584762

Epoch: 5| Step: 6
Training loss: 4.0917348779611125
Validation loss: 3.227027516910548

Epoch: 5| Step: 7
Training loss: 3.084925077446691
Validation loss: 3.2231428128203685

Epoch: 5| Step: 8
Training loss: 3.271359605829707
Validation loss: 3.2239959344578457

Epoch: 5| Step: 9
Training loss: 3.188899013696681
Validation loss: 3.2192602249996067

Epoch: 5| Step: 10
Training loss: 3.298056729672592
Validation loss: 3.214521919552632

Epoch: 18| Step: 0
Training loss: 2.772805413226673
Validation loss: 3.212562910718211

Epoch: 5| Step: 1
Training loss: 3.139182751233526
Validation loss: 3.2184204512690595

Epoch: 5| Step: 2
Training loss: 3.1719079227336175
Validation loss: 3.246776653059198

Epoch: 5| Step: 3
Training loss: 3.9924521759742353
Validation loss: 3.20911959706373

Epoch: 5| Step: 4
Training loss: 2.779067651299271
Validation loss: 3.207410808128128

Epoch: 5| Step: 5
Training loss: 3.508828064988143
Validation loss: 3.2332107297637354

Epoch: 5| Step: 6
Training loss: 3.719194401705921
Validation loss: 3.2514712408906226

Epoch: 5| Step: 7
Training loss: 3.7449475902765923
Validation loss: 3.234838440527087

Epoch: 5| Step: 8
Training loss: 4.025347743206213
Validation loss: 3.232043677199116

Epoch: 5| Step: 9
Training loss: 4.069150909032915
Validation loss: 3.225866316783346

Epoch: 5| Step: 10
Training loss: 2.970830409265678
Validation loss: 3.221307557792523

Epoch: 19| Step: 0
Training loss: 3.2464787407547218
Validation loss: 3.218798851966994

Epoch: 5| Step: 1
Training loss: 4.033030035632086
Validation loss: 3.21004905152842

Epoch: 5| Step: 2
Training loss: 2.9614595541793305
Validation loss: 3.2026127087188803

Epoch: 5| Step: 3
Training loss: 3.2329023021469503
Validation loss: 3.209930553452396

Epoch: 5| Step: 4
Training loss: 3.3308783232591836
Validation loss: 3.2046559730618505

Epoch: 5| Step: 5
Training loss: 3.7204183474514947
Validation loss: 3.1928123491035816

Epoch: 5| Step: 6
Training loss: 3.8745211643808144
Validation loss: 3.189792599190984

Epoch: 5| Step: 7
Training loss: 3.1949682073548558
Validation loss: 3.179463394183719

Epoch: 5| Step: 8
Training loss: 3.7816820134310616
Validation loss: 3.178764971144096

Epoch: 5| Step: 9
Training loss: 3.374281630180769
Validation loss: 3.1772072501436868

Epoch: 5| Step: 10
Training loss: 3.0203347858015266
Validation loss: 3.178248646879957

Epoch: 20| Step: 0
Training loss: 3.3274042486318787
Validation loss: 3.1709996483601848

Epoch: 5| Step: 1
Training loss: 3.426264903813054
Validation loss: 3.171351410346841

Epoch: 5| Step: 2
Training loss: 3.1645948927573833
Validation loss: 3.1748617413924434

Epoch: 5| Step: 3
Training loss: 3.069731756910888
Validation loss: 3.1769182616543747

Epoch: 5| Step: 4
Training loss: 3.763541630627825
Validation loss: 3.168654250922214

Epoch: 5| Step: 5
Training loss: 3.2574490497671045
Validation loss: 3.162730820433752

Epoch: 5| Step: 6
Training loss: 4.089206183142634
Validation loss: 3.159323407107684

Epoch: 5| Step: 7
Training loss: 3.5803243882244176
Validation loss: 3.153502883625555

Epoch: 5| Step: 8
Training loss: 2.6484118435047375
Validation loss: 3.1497944422471256

Epoch: 5| Step: 9
Training loss: 3.6241172504952037
Validation loss: 3.1495137586980415

Epoch: 5| Step: 10
Training loss: 3.5169718557212746
Validation loss: 3.1489562715597437

Epoch: 21| Step: 0
Training loss: 3.592355341431146
Validation loss: 3.141717536152994

Epoch: 5| Step: 1
Training loss: 4.174274340399886
Validation loss: 3.14168650353031

Epoch: 5| Step: 2
Training loss: 3.274092651939075
Validation loss: 3.1403143797558375

Epoch: 5| Step: 3
Training loss: 3.0347870316169647
Validation loss: 3.1381031380791247

Epoch: 5| Step: 4
Training loss: 3.1297092812171106
Validation loss: 3.1397894209627446

Epoch: 5| Step: 5
Training loss: 3.140548173714407
Validation loss: 3.135586120607352

Epoch: 5| Step: 6
Training loss: 3.369482970604953
Validation loss: 3.1422416221175773

Epoch: 5| Step: 7
Training loss: 3.321266234806511
Validation loss: 3.1373369913310456

Epoch: 5| Step: 8
Training loss: 3.144051423989349
Validation loss: 3.1356522274002123

Epoch: 5| Step: 9
Training loss: 2.6654739891647905
Validation loss: 3.1309229761319317

Epoch: 5| Step: 10
Training loss: 4.387284171944588
Validation loss: 3.1281293709279097

Epoch: 22| Step: 0
Training loss: 3.7016735210008864
Validation loss: 3.127021034292783

Epoch: 5| Step: 1
Training loss: 3.305287696678233
Validation loss: 3.123852927404866

Epoch: 5| Step: 2
Training loss: 3.6354495742022586
Validation loss: 3.1212144347555184

Epoch: 5| Step: 3
Training loss: 4.190966182192741
Validation loss: 3.122695723029868

Epoch: 5| Step: 4
Training loss: 2.933496872360099
Validation loss: 3.118905163034799

Epoch: 5| Step: 5
Training loss: 2.79610112741653
Validation loss: 3.1184991057184166

Epoch: 5| Step: 6
Training loss: 3.3730277904153936
Validation loss: 3.1131082097284963

Epoch: 5| Step: 7
Training loss: 2.9345438265755672
Validation loss: 3.111943301063141

Epoch: 5| Step: 8
Training loss: 3.66728722494025
Validation loss: 3.11577419526471

Epoch: 5| Step: 9
Training loss: 3.714603452401582
Validation loss: 3.112799346151621

Epoch: 5| Step: 10
Training loss: 2.5545841861097704
Validation loss: 3.1092813714455674

Epoch: 23| Step: 0
Training loss: 3.4834801589709588
Validation loss: 3.108329027711712

Epoch: 5| Step: 1
Training loss: 3.892210487962461
Validation loss: 3.1046521113576846

Epoch: 5| Step: 2
Training loss: 3.113081366848392
Validation loss: 3.101931601787365

Epoch: 5| Step: 3
Training loss: 3.393208025234328
Validation loss: 3.1047279515012813

Epoch: 5| Step: 4
Training loss: 2.630541991167859
Validation loss: 3.1031995066213787

Epoch: 5| Step: 5
Training loss: 3.540139950071023
Validation loss: 3.098052752444721

Epoch: 5| Step: 6
Training loss: 3.365494942166681
Validation loss: 3.099763008860876

Epoch: 5| Step: 7
Training loss: 3.070835525187552
Validation loss: 3.096395793735611

Epoch: 5| Step: 8
Training loss: 2.9912683255391075
Validation loss: 3.0961373652396755

Epoch: 5| Step: 9
Training loss: 3.8241810938040066
Validation loss: 3.09519294490944

Epoch: 5| Step: 10
Training loss: 3.5895853873210277
Validation loss: 3.0928671024410197

Epoch: 24| Step: 0
Training loss: 3.6782283279049097
Validation loss: 3.0909142448095417

Epoch: 5| Step: 1
Training loss: 3.5789290278587806
Validation loss: 3.092521952426668

Epoch: 5| Step: 2
Training loss: 3.0404173667404697
Validation loss: 3.095202765634459

Epoch: 5| Step: 3
Training loss: 3.319687872082886
Validation loss: 3.0958683869229477

Epoch: 5| Step: 4
Training loss: 2.8768173776209935
Validation loss: 3.098789403579557

Epoch: 5| Step: 5
Training loss: 3.2591609954069365
Validation loss: 3.092749224851514

Epoch: 5| Step: 6
Training loss: 3.4851964144860452
Validation loss: 3.0915627784301947

Epoch: 5| Step: 7
Training loss: 3.2500054286031133
Validation loss: 3.086381442130377

Epoch: 5| Step: 8
Training loss: 3.272662159724761
Validation loss: 3.083768017988057

Epoch: 5| Step: 9
Training loss: 3.2176634797221713
Validation loss: 3.0813213264669552

Epoch: 5| Step: 10
Training loss: 3.9406975977696983
Validation loss: 3.079698654146864

Epoch: 25| Step: 0
Training loss: 4.219637403051644
Validation loss: 3.0795946233252143

Epoch: 5| Step: 1
Training loss: 3.0923148785802157
Validation loss: 3.0773439517360575

Epoch: 5| Step: 2
Training loss: 3.3222446698890864
Validation loss: 3.077448317715735

Epoch: 5| Step: 3
Training loss: 3.136664023106022
Validation loss: 3.074494540382351

Epoch: 5| Step: 4
Training loss: 3.801259715435705
Validation loss: 3.0725288598300144

Epoch: 5| Step: 5
Training loss: 3.7600621331945296
Validation loss: 3.0772474891350754

Epoch: 5| Step: 6
Training loss: 2.904439710992473
Validation loss: 3.074951824988385

Epoch: 5| Step: 7
Training loss: 3.0065812402277365
Validation loss: 3.0843121170432926

Epoch: 5| Step: 8
Training loss: 3.146181571498212
Validation loss: 3.0772708773656126

Epoch: 5| Step: 9
Training loss: 3.5858452147200475
Validation loss: 3.0756470366407926

Epoch: 5| Step: 10
Training loss: 2.3808167150992525
Validation loss: 3.072405917250638

Epoch: 26| Step: 0
Training loss: 2.759900909801181
Validation loss: 3.0690712827608637

Epoch: 5| Step: 1
Training loss: 2.907932573777751
Validation loss: 3.0683287768516077

Epoch: 5| Step: 2
Training loss: 3.9710171449166736
Validation loss: 3.071312948514524

Epoch: 5| Step: 3
Training loss: 3.461769847798374
Validation loss: 3.070272103542023

Epoch: 5| Step: 4
Training loss: 3.7380285546368905
Validation loss: 3.06894231997742

Epoch: 5| Step: 5
Training loss: 3.5859462762862373
Validation loss: 3.066052838545829

Epoch: 5| Step: 6
Training loss: 3.4850223778070517
Validation loss: 3.0672972012417152

Epoch: 5| Step: 7
Training loss: 4.100905127751834
Validation loss: 3.0688693137052465

Epoch: 5| Step: 8
Training loss: 3.2400705803141823
Validation loss: 3.068202619557023

Epoch: 5| Step: 9
Training loss: 2.691325459146623
Validation loss: 3.065952816518013

Epoch: 5| Step: 10
Training loss: 2.1725905083699795
Validation loss: 3.0664403820104233

Epoch: 27| Step: 0
Training loss: 3.8856402103592083
Validation loss: 3.0681421835374976

Epoch: 5| Step: 1
Training loss: 3.7102758199156938
Validation loss: 3.0716914556147343

Epoch: 5| Step: 2
Training loss: 3.390031753886444
Validation loss: 3.066159693337385

Epoch: 5| Step: 3
Training loss: 3.7877393791669705
Validation loss: 3.059944306955975

Epoch: 5| Step: 4
Training loss: 2.9473118964848517
Validation loss: 3.056963203385055

Epoch: 5| Step: 5
Training loss: 3.401615735024262
Validation loss: 3.0547112841981434

Epoch: 5| Step: 6
Training loss: 3.198387103109993
Validation loss: 3.053691861947123

Epoch: 5| Step: 7
Training loss: 3.0864918657520413
Validation loss: 3.05429307325477

Epoch: 5| Step: 8
Training loss: 2.7448041554890117
Validation loss: 3.051917047257011

Epoch: 5| Step: 9
Training loss: 2.8314119069539885
Validation loss: 3.0506451382206907

Epoch: 5| Step: 10
Training loss: 3.5070842165313425
Validation loss: 3.051221459923929

Epoch: 28| Step: 0
Training loss: 3.192148446821195
Validation loss: 3.051674000865253

Epoch: 5| Step: 1
Training loss: 3.5177003965249676
Validation loss: 3.048085174154027

Epoch: 5| Step: 2
Training loss: 3.977500340277695
Validation loss: 3.0419675049213084

Epoch: 5| Step: 3
Training loss: 2.896628913179758
Validation loss: 3.042205670638705

Epoch: 5| Step: 4
Training loss: 2.8574273819260845
Validation loss: 3.0446425604779614

Epoch: 5| Step: 5
Training loss: 3.146895795524247
Validation loss: 3.0521297085226338

Epoch: 5| Step: 6
Training loss: 3.2354727093980067
Validation loss: 3.070243492541855

Epoch: 5| Step: 7
Training loss: 3.3155704878515415
Validation loss: 3.0486876609810953

Epoch: 5| Step: 8
Training loss: 3.4319868786967813
Validation loss: 3.0464110167100187

Epoch: 5| Step: 9
Training loss: 3.5308928182448565
Validation loss: 3.0430588586530405

Epoch: 5| Step: 10
Training loss: 3.35466446746467
Validation loss: 3.0456120290619517

Epoch: 29| Step: 0
Training loss: 3.9484584842512236
Validation loss: 3.0411489998310097

Epoch: 5| Step: 1
Training loss: 3.6151937506158904
Validation loss: 3.0358029961388753

Epoch: 5| Step: 2
Training loss: 3.094148552394055
Validation loss: 3.0362243280746624

Epoch: 5| Step: 3
Training loss: 3.2085763087888823
Validation loss: 3.034137274728953

Epoch: 5| Step: 4
Training loss: 3.016268330473676
Validation loss: 3.0348252935463016

Epoch: 5| Step: 5
Training loss: 3.731027419513769
Validation loss: 3.036526092756574

Epoch: 5| Step: 6
Training loss: 3.0965480289242358
Validation loss: 3.035327786536728

Epoch: 5| Step: 7
Training loss: 3.067724170654728
Validation loss: 3.0328606201245476

Epoch: 5| Step: 8
Training loss: 3.3413680674895674
Validation loss: 3.0281920397230286

Epoch: 5| Step: 9
Training loss: 2.7090859370043443
Validation loss: 3.0271820387187947

Epoch: 5| Step: 10
Training loss: 3.4643342375692803
Validation loss: 3.027786981406148

Epoch: 30| Step: 0
Training loss: 2.4237714664006362
Validation loss: 3.0258311923755756

Epoch: 5| Step: 1
Training loss: 2.822567954584238
Validation loss: 3.028515755496547

Epoch: 5| Step: 2
Training loss: 3.8650467312888193
Validation loss: 3.026965782660321

Epoch: 5| Step: 3
Training loss: 3.5938225780290094
Validation loss: 3.024364767936024

Epoch: 5| Step: 4
Training loss: 3.4920142213984082
Validation loss: 3.0222019364025843

Epoch: 5| Step: 5
Training loss: 3.5089924957986574
Validation loss: 3.022167169043658

Epoch: 5| Step: 6
Training loss: 3.19877977352142
Validation loss: 3.021676080000145

Epoch: 5| Step: 7
Training loss: 3.2867687499910865
Validation loss: 3.0235083914240217

Epoch: 5| Step: 8
Training loss: 3.6724103821375333
Validation loss: 3.0218453013174975

Epoch: 5| Step: 9
Training loss: 3.063254749949135
Validation loss: 3.020181239392304

Epoch: 5| Step: 10
Training loss: 3.0925475587017304
Validation loss: 3.018795284623795

Epoch: 31| Step: 0
Training loss: 3.285444358139722
Validation loss: 3.0205160571968164

Epoch: 5| Step: 1
Training loss: 2.971275139085648
Validation loss: 3.0140135800258023

Epoch: 5| Step: 2
Training loss: 3.194890598340383
Validation loss: 3.013876761292709

Epoch: 5| Step: 3
Training loss: 3.3705863349743934
Validation loss: 3.0101632290688585

Epoch: 5| Step: 4
Training loss: 2.9011576347982615
Validation loss: 3.0099446166136703

Epoch: 5| Step: 5
Training loss: 3.8504131838546063
Validation loss: 3.0167795043801617

Epoch: 5| Step: 6
Training loss: 3.745845273302601
Validation loss: 3.0065811379065766

Epoch: 5| Step: 7
Training loss: 3.422490312828694
Validation loss: 3.005969701673756

Epoch: 5| Step: 8
Training loss: 2.8647305722398886
Validation loss: 3.013357895014974

Epoch: 5| Step: 9
Training loss: 2.801547276912419
Validation loss: 3.04637894169562

Epoch: 5| Step: 10
Training loss: 3.752781154562969
Validation loss: 3.0894501405585975

Epoch: 32| Step: 0
Training loss: 3.6063770873420817
Validation loss: 3.11014933144477

Epoch: 5| Step: 1
Training loss: 2.4049607823717403
Validation loss: 3.098781535081939

Epoch: 5| Step: 2
Training loss: 2.596524053516921
Validation loss: 3.084357152928497

Epoch: 5| Step: 3
Training loss: 2.122946925473283
Validation loss: 3.02569506477112

Epoch: 5| Step: 4
Training loss: 3.9253429870417653
Validation loss: 3.0125355448783346

Epoch: 5| Step: 5
Training loss: 3.866996375090856
Validation loss: 3.026112583778037

Epoch: 5| Step: 6
Training loss: 3.5222558452821144
Validation loss: 3.0193998410106477

Epoch: 5| Step: 7
Training loss: 2.965007310057405
Validation loss: 3.0085859165457194

Epoch: 5| Step: 8
Training loss: 3.754642537419677
Validation loss: 3.0028666418276964

Epoch: 5| Step: 9
Training loss: 3.6969369942762667
Validation loss: 3.006888768648661

Epoch: 5| Step: 10
Training loss: 3.3386953777728094
Validation loss: 2.999471834990572

Epoch: 33| Step: 0
Training loss: 3.060239151977728
Validation loss: 2.9989490496935947

Epoch: 5| Step: 1
Training loss: 2.598297177744869
Validation loss: 3.0036043242900545

Epoch: 5| Step: 2
Training loss: 3.852605032507099
Validation loss: 3.0096048278863767

Epoch: 5| Step: 3
Training loss: 3.186381573899282
Validation loss: 3.0039467862122446

Epoch: 5| Step: 4
Training loss: 3.0018536880692896
Validation loss: 3.002966902334092

Epoch: 5| Step: 5
Training loss: 3.699813972126805
Validation loss: 3.002506413996094

Epoch: 5| Step: 6
Training loss: 2.580301094672143
Validation loss: 2.9963277076808734

Epoch: 5| Step: 7
Training loss: 3.1616160789656176
Validation loss: 2.992533440133164

Epoch: 5| Step: 8
Training loss: 3.740662457143939
Validation loss: 2.9870948383242015

Epoch: 5| Step: 9
Training loss: 3.6754296810650726
Validation loss: 2.986555236319938

Epoch: 5| Step: 10
Training loss: 3.240455698062159
Validation loss: 2.986276714874196

Epoch: 34| Step: 0
Training loss: 3.4009143441374214
Validation loss: 2.9849849593654008

Epoch: 5| Step: 1
Training loss: 2.97689969613393
Validation loss: 2.982650306584272

Epoch: 5| Step: 2
Training loss: 2.7664193774399064
Validation loss: 2.983556161674162

Epoch: 5| Step: 3
Training loss: 3.0190184479762943
Validation loss: 2.9836853945206996

Epoch: 5| Step: 4
Training loss: 3.2205458880849287
Validation loss: 2.9814869812693487

Epoch: 5| Step: 5
Training loss: 3.1928184867803506
Validation loss: 2.9830631499027342

Epoch: 5| Step: 6
Training loss: 3.4876395358265384
Validation loss: 2.9806325260510347

Epoch: 5| Step: 7
Training loss: 3.8284627960019533
Validation loss: 2.9794130631455613

Epoch: 5| Step: 8
Training loss: 3.1100001641178396
Validation loss: 2.976672824775209

Epoch: 5| Step: 9
Training loss: 3.6368106621457987
Validation loss: 2.9751173007831166

Epoch: 5| Step: 10
Training loss: 3.165780662934586
Validation loss: 2.9755422156818905

Epoch: 35| Step: 0
Training loss: 3.215011351285031
Validation loss: 2.97302638427033

Epoch: 5| Step: 1
Training loss: 3.6839341848750786
Validation loss: 2.9740054767934274

Epoch: 5| Step: 2
Training loss: 2.9280597691715275
Validation loss: 2.9742496742080706

Epoch: 5| Step: 3
Training loss: 3.094117113931158
Validation loss: 2.9803449129537434

Epoch: 5| Step: 4
Training loss: 2.9942228003645046
Validation loss: 2.983971753478923

Epoch: 5| Step: 5
Training loss: 3.3070785493845345
Validation loss: 2.984235776945912

Epoch: 5| Step: 6
Training loss: 2.9607123538452558
Validation loss: 2.9814304032625456

Epoch: 5| Step: 7
Training loss: 3.119549384710468
Validation loss: 2.97582955724803

Epoch: 5| Step: 8
Training loss: 3.7306082015411057
Validation loss: 2.9738777680885886

Epoch: 5| Step: 9
Training loss: 3.4850479639329337
Validation loss: 2.9709023946305106

Epoch: 5| Step: 10
Training loss: 3.2171097807646696
Validation loss: 2.965484124993357

Epoch: 36| Step: 0
Training loss: 3.9784707997137296
Validation loss: 2.9660733404149777

Epoch: 5| Step: 1
Training loss: 3.096648890673887
Validation loss: 2.964093287580816

Epoch: 5| Step: 2
Training loss: 3.6436969419512866
Validation loss: 2.9648370573704423

Epoch: 5| Step: 3
Training loss: 3.589562406089622
Validation loss: 2.9626843474493825

Epoch: 5| Step: 4
Training loss: 2.7536816660973513
Validation loss: 2.962486449616028

Epoch: 5| Step: 5
Training loss: 3.5753605587408943
Validation loss: 2.9645647392727255

Epoch: 5| Step: 6
Training loss: 3.04157974606693
Validation loss: 2.9636449074436007

Epoch: 5| Step: 7
Training loss: 2.395004051539552
Validation loss: 2.9622397047834115

Epoch: 5| Step: 8
Training loss: 3.6483747652529304
Validation loss: 2.964251200051243

Epoch: 5| Step: 9
Training loss: 3.0018268427102393
Validation loss: 2.965425695056457

Epoch: 5| Step: 10
Training loss: 2.5997984808073307
Validation loss: 2.980001359473887

Epoch: 37| Step: 0
Training loss: 3.1930801316172306
Validation loss: 3.0375212646304504

Epoch: 5| Step: 1
Training loss: 2.2830951492191875
Validation loss: 3.019508202431181

Epoch: 5| Step: 2
Training loss: 3.5127345431069674
Validation loss: 3.0110736352473637

Epoch: 5| Step: 3
Training loss: 2.991126447549808
Validation loss: 2.976835819290102

Epoch: 5| Step: 4
Training loss: 3.7163208793504228
Validation loss: 2.959850683586793

Epoch: 5| Step: 5
Training loss: 2.984921709883819
Validation loss: 2.956223989077115

Epoch: 5| Step: 6
Training loss: 3.149930765511307
Validation loss: 2.958197771843232

Epoch: 5| Step: 7
Training loss: 3.3659866917891637
Validation loss: 2.961306181547565

Epoch: 5| Step: 8
Training loss: 3.8643847857503615
Validation loss: 2.9639582184520155

Epoch: 5| Step: 9
Training loss: 3.0951246810228277
Validation loss: 2.9615040197456777

Epoch: 5| Step: 10
Training loss: 3.4997104797508087
Validation loss: 2.9622918029459124

Epoch: 38| Step: 0
Training loss: 2.0732794464975153
Validation loss: 2.9600010951094746

Epoch: 5| Step: 1
Training loss: 3.7660960302522866
Validation loss: 2.9559835564724373

Epoch: 5| Step: 2
Training loss: 2.983949001725308
Validation loss: 2.9547719708268594

Epoch: 5| Step: 3
Training loss: 2.739941059926534
Validation loss: 2.955516426150101

Epoch: 5| Step: 4
Training loss: 3.402500433659018
Validation loss: 2.9556589639832143

Epoch: 5| Step: 5
Training loss: 3.768642878235713
Validation loss: 2.9566034987384406

Epoch: 5| Step: 6
Training loss: 3.464532160806379
Validation loss: 2.958353733776373

Epoch: 5| Step: 7
Training loss: 3.4489458436239584
Validation loss: 2.957794657471064

Epoch: 5| Step: 8
Training loss: 3.3437193396758005
Validation loss: 2.951195104431336

Epoch: 5| Step: 9
Training loss: 3.11727453889488
Validation loss: 2.9504780193823668

Epoch: 5| Step: 10
Training loss: 3.1983622055248047
Validation loss: 2.9479890822658965

Epoch: 39| Step: 0
Training loss: 2.1859884216616225
Validation loss: 2.9495692803706315

Epoch: 5| Step: 1
Training loss: 3.1940712604826174
Validation loss: 2.9489815295827273

Epoch: 5| Step: 2
Training loss: 3.198620862601327
Validation loss: 2.951086740841735

Epoch: 5| Step: 3
Training loss: 3.122372247237248
Validation loss: 2.9496285137372853

Epoch: 5| Step: 4
Training loss: 3.0124457010147916
Validation loss: 2.952045469719833

Epoch: 5| Step: 5
Training loss: 3.5838897775748038
Validation loss: 2.9732187192365616

Epoch: 5| Step: 6
Training loss: 3.2663406974968217
Validation loss: 2.9646795219965933

Epoch: 5| Step: 7
Training loss: 3.605717643173137
Validation loss: 2.945543749422605

Epoch: 5| Step: 8
Training loss: 3.0303541609756413
Validation loss: 2.9411530411237674

Epoch: 5| Step: 9
Training loss: 3.5276089692131203
Validation loss: 2.9450991956343726

Epoch: 5| Step: 10
Training loss: 3.7210173546771577
Validation loss: 2.945934737486259

Epoch: 40| Step: 0
Training loss: 2.9725163711340863
Validation loss: 2.9466330951758093

Epoch: 5| Step: 1
Training loss: 3.0421823212550616
Validation loss: 2.9436071825188805

Epoch: 5| Step: 2
Training loss: 3.111794761823066
Validation loss: 2.937560865216311

Epoch: 5| Step: 3
Training loss: 3.2555187026517647
Validation loss: 2.9277927410622904

Epoch: 5| Step: 4
Training loss: 3.672891289501979
Validation loss: 2.9214485159466554

Epoch: 5| Step: 5
Training loss: 3.4890163283617914
Validation loss: 2.919079731796042

Epoch: 5| Step: 6
Training loss: 2.8097721858685825
Validation loss: 2.9197931774724752

Epoch: 5| Step: 7
Training loss: 3.146896250102811
Validation loss: 2.9202402949076394

Epoch: 5| Step: 8
Training loss: 3.404089005952873
Validation loss: 2.922438277631376

Epoch: 5| Step: 9
Training loss: 3.1670819227766454
Validation loss: 2.9321132343266822

Epoch: 5| Step: 10
Training loss: 3.369806744612028
Validation loss: 2.928258687411369

Epoch: 41| Step: 0
Training loss: 3.174334394717624
Validation loss: 2.9245196759076983

Epoch: 5| Step: 1
Training loss: 2.6834689226506403
Validation loss: 2.916100460826449

Epoch: 5| Step: 2
Training loss: 2.992485967745025
Validation loss: 2.9121749700086625

Epoch: 5| Step: 3
Training loss: 3.2891074424445814
Validation loss: 2.9075912536798505

Epoch: 5| Step: 4
Training loss: 3.7045120667518363
Validation loss: 2.908166425307515

Epoch: 5| Step: 5
Training loss: 2.9483162616978014
Validation loss: 2.9068157956553544

Epoch: 5| Step: 6
Training loss: 3.5809292528140886
Validation loss: 2.9087699720562337

Epoch: 5| Step: 7
Training loss: 3.221049996244719
Validation loss: 2.9087394613668964

Epoch: 5| Step: 8
Training loss: 3.5725196343450323
Validation loss: 2.9024171795782014

Epoch: 5| Step: 9
Training loss: 2.634212314202556
Validation loss: 2.906690675491061

Epoch: 5| Step: 10
Training loss: 3.250116052756313
Validation loss: 2.9184868206278862

Epoch: 42| Step: 0
Training loss: 3.121567481305544
Validation loss: 2.9299844150827994

Epoch: 5| Step: 1
Training loss: 3.002474241376501
Validation loss: 2.986639877045736

Epoch: 5| Step: 2
Training loss: 3.4760847470627363
Validation loss: 2.975072878403979

Epoch: 5| Step: 3
Training loss: 3.493761770266119
Validation loss: 2.89480886768888

Epoch: 5| Step: 4
Training loss: 3.6791027600680883
Validation loss: 2.89558915969176

Epoch: 5| Step: 5
Training loss: 3.518897944807675
Validation loss: 2.9304177622289886

Epoch: 5| Step: 6
Training loss: 3.4587848935367895
Validation loss: 2.9169665122419532

Epoch: 5| Step: 7
Training loss: 2.144020005730624
Validation loss: 2.9144719587339747

Epoch: 5| Step: 8
Training loss: 2.8398393843458534
Validation loss: 2.9289039645834363

Epoch: 5| Step: 9
Training loss: 3.021253639885032
Validation loss: 2.9155192536840837

Epoch: 5| Step: 10
Training loss: 3.4910631524664915
Validation loss: 2.9043967302962983

Epoch: 43| Step: 0
Training loss: 3.872070189352142
Validation loss: 2.899328835685184

Epoch: 5| Step: 1
Training loss: 3.4997231510205293
Validation loss: 2.897754936092797

Epoch: 5| Step: 2
Training loss: 2.590289737740849
Validation loss: 2.9063072803192394

Epoch: 5| Step: 3
Training loss: 2.685505415162923
Validation loss: 2.919756957112667

Epoch: 5| Step: 4
Training loss: 2.773163258063178
Validation loss: 2.9262214670208

Epoch: 5| Step: 5
Training loss: 3.6901260335844617
Validation loss: 2.917425192952342

Epoch: 5| Step: 6
Training loss: 3.138650301827696
Validation loss: 2.8976772054039595

Epoch: 5| Step: 7
Training loss: 3.3799635098536043
Validation loss: 2.8908528662446265

Epoch: 5| Step: 8
Training loss: 3.0959708209375423
Validation loss: 2.8869703137913856

Epoch: 5| Step: 9
Training loss: 3.4070573602387486
Validation loss: 2.884772647360316

Epoch: 5| Step: 10
Training loss: 2.672218434530928
Validation loss: 2.8837974367115664

Epoch: 44| Step: 0
Training loss: 2.7984271297976213
Validation loss: 2.8837984590393386

Epoch: 5| Step: 1
Training loss: 3.1494832538426603
Validation loss: 2.886539760567002

Epoch: 5| Step: 2
Training loss: 2.9990032447525183
Validation loss: 2.8842040812110423

Epoch: 5| Step: 3
Training loss: 2.7269157465028857
Validation loss: 2.8826999170446417

Epoch: 5| Step: 4
Training loss: 2.7829538334078405
Validation loss: 2.8775836041629512

Epoch: 5| Step: 5
Training loss: 2.8213796525132384
Validation loss: 2.8788590642664458

Epoch: 5| Step: 6
Training loss: 3.8351097690037004
Validation loss: 2.8774509584957526

Epoch: 5| Step: 7
Training loss: 3.5025551869348774
Validation loss: 2.875365126181764

Epoch: 5| Step: 8
Training loss: 3.3952635928764505
Validation loss: 2.877794112684688

Epoch: 5| Step: 9
Training loss: 3.4078035224191123
Validation loss: 2.8749223942066653

Epoch: 5| Step: 10
Training loss: 3.42866073219616
Validation loss: 2.879472934874029

Epoch: 45| Step: 0
Training loss: 3.8350065698281406
Validation loss: 2.8759902400830812

Epoch: 5| Step: 1
Training loss: 3.529101638164812
Validation loss: 2.8702127102274417

Epoch: 5| Step: 2
Training loss: 2.4795890149159487
Validation loss: 2.870511730547632

Epoch: 5| Step: 3
Training loss: 3.3795861061889676
Validation loss: 2.8691147181024705

Epoch: 5| Step: 4
Training loss: 2.673111568093418
Validation loss: 2.8652986363164814

Epoch: 5| Step: 5
Training loss: 2.9732803311206966
Validation loss: 2.8652794910291823

Epoch: 5| Step: 6
Training loss: 3.3322461898544957
Validation loss: 2.8684683683105385

Epoch: 5| Step: 7
Training loss: 3.2585856665998247
Validation loss: 2.8644642669603386

Epoch: 5| Step: 8
Training loss: 3.1689632186031087
Validation loss: 2.8669305331773542

Epoch: 5| Step: 9
Training loss: 2.5907400660160107
Validation loss: 2.866722852318942

Epoch: 5| Step: 10
Training loss: 3.4993221443982376
Validation loss: 2.8666471329939505

Epoch: 46| Step: 0
Training loss: 3.24854187166984
Validation loss: 2.8677072790702436

Epoch: 5| Step: 1
Training loss: 3.477574164822136
Validation loss: 2.859425799418795

Epoch: 5| Step: 2
Training loss: 3.5090974013474683
Validation loss: 2.8557295993429666

Epoch: 5| Step: 3
Training loss: 2.824101489153465
Validation loss: 2.8556992778497055

Epoch: 5| Step: 4
Training loss: 4.177996427031395
Validation loss: 2.857290351594048

Epoch: 5| Step: 5
Training loss: 2.6403117699474796
Validation loss: 2.8563663553299126

Epoch: 5| Step: 6
Training loss: 2.6560932786372127
Validation loss: 2.858119859248495

Epoch: 5| Step: 7
Training loss: 3.3399291267413553
Validation loss: 2.8531097354554036

Epoch: 5| Step: 8
Training loss: 2.636563218792497
Validation loss: 2.858887394433642

Epoch: 5| Step: 9
Training loss: 3.1318464430658692
Validation loss: 2.850620892760241

Epoch: 5| Step: 10
Training loss: 2.7368980756241146
Validation loss: 2.8501218034657927

Epoch: 47| Step: 0
Training loss: 3.4104456827882514
Validation loss: 2.8495191012573677

Epoch: 5| Step: 1
Training loss: 3.3234051830619786
Validation loss: 2.847138391223224

Epoch: 5| Step: 2
Training loss: 3.0357905722898133
Validation loss: 2.850840273367256

Epoch: 5| Step: 3
Training loss: 3.583950181844723
Validation loss: 2.8477976454568554

Epoch: 5| Step: 4
Training loss: 2.8429284218959725
Validation loss: 2.848088422850473

Epoch: 5| Step: 5
Training loss: 3.350211486973067
Validation loss: 2.8473464192067155

Epoch: 5| Step: 6
Training loss: 3.0097108077219255
Validation loss: 2.845010311617614

Epoch: 5| Step: 7
Training loss: 3.373051398737557
Validation loss: 2.848848498289869

Epoch: 5| Step: 8
Training loss: 2.770305745847572
Validation loss: 2.848574079047507

Epoch: 5| Step: 9
Training loss: 3.1364800729360303
Validation loss: 2.852534474518668

Epoch: 5| Step: 10
Training loss: 2.7671207327302536
Validation loss: 2.8518001810772726

Epoch: 48| Step: 0
Training loss: 2.9109157723206147
Validation loss: 2.8466426881506153

Epoch: 5| Step: 1
Training loss: 2.9998564685818363
Validation loss: 2.844552538187143

Epoch: 5| Step: 2
Training loss: 2.834150271354735
Validation loss: 2.844974850382811

Epoch: 5| Step: 3
Training loss: 2.791765372585749
Validation loss: 2.84613930368664

Epoch: 5| Step: 4
Training loss: 3.2892351626201934
Validation loss: 2.8465527643263053

Epoch: 5| Step: 5
Training loss: 3.3333999309244766
Validation loss: 2.8488091351775546

Epoch: 5| Step: 6
Training loss: 3.4930932152708563
Validation loss: 2.8491623479553687

Epoch: 5| Step: 7
Training loss: 3.4292937380738016
Validation loss: 2.8480251576378404

Epoch: 5| Step: 8
Training loss: 2.8211737081330495
Validation loss: 2.847469695813371

Epoch: 5| Step: 9
Training loss: 3.674915629346135
Validation loss: 2.8482600106482816

Epoch: 5| Step: 10
Training loss: 3.031754441908631
Validation loss: 2.8436493259095617

Epoch: 49| Step: 0
Training loss: 2.9336113046661847
Validation loss: 2.8437436498268838

Epoch: 5| Step: 1
Training loss: 3.578246934970323
Validation loss: 2.8439530781622127

Epoch: 5| Step: 2
Training loss: 2.6527023859500884
Validation loss: 2.840406503902803

Epoch: 5| Step: 3
Training loss: 3.433850657428831
Validation loss: 2.8415098619837256

Epoch: 5| Step: 4
Training loss: 2.928452050703416
Validation loss: 2.843718349961743

Epoch: 5| Step: 5
Training loss: 3.3359173454730016
Validation loss: 2.8469145461452285

Epoch: 5| Step: 6
Training loss: 3.581468111489779
Validation loss: 2.8436899666780837

Epoch: 5| Step: 7
Training loss: 2.853896432228442
Validation loss: 2.844162861539143

Epoch: 5| Step: 8
Training loss: 2.978032907861358
Validation loss: 2.8434602395304167

Epoch: 5| Step: 9
Training loss: 3.2095269959290973
Validation loss: 2.8419341129438744

Epoch: 5| Step: 10
Training loss: 3.0206356817017546
Validation loss: 2.8397144078792924

Epoch: 50| Step: 0
Training loss: 2.5473777415219967
Validation loss: 2.839479598336264

Epoch: 5| Step: 1
Training loss: 3.7279449393827337
Validation loss: 2.8358448835727024

Epoch: 5| Step: 2
Training loss: 2.6966766885666313
Validation loss: 2.835586377409717

Epoch: 5| Step: 3
Training loss: 3.2207312550886456
Validation loss: 2.831379769497442

Epoch: 5| Step: 4
Training loss: 3.221645941301737
Validation loss: 2.8326687274616713

Epoch: 5| Step: 5
Training loss: 3.0284999682177838
Validation loss: 2.8337213303655977

Epoch: 5| Step: 6
Training loss: 2.9680358027640534
Validation loss: 2.8309079042940457

Epoch: 5| Step: 7
Training loss: 3.7752327449367122
Validation loss: 2.8335684986953154

Epoch: 5| Step: 8
Training loss: 2.695963639928206
Validation loss: 2.834713119127765

Epoch: 5| Step: 9
Training loss: 2.9766688690803926
Validation loss: 2.8388229756058574

Epoch: 5| Step: 10
Training loss: 3.5158963925195703
Validation loss: 2.8344060367978323

Epoch: 51| Step: 0
Training loss: 3.344966346331942
Validation loss: 2.8299495567862274

Epoch: 5| Step: 1
Training loss: 3.000252713049867
Validation loss: 2.827823443129044

Epoch: 5| Step: 2
Training loss: 3.0307994389694963
Validation loss: 2.8296391860592562

Epoch: 5| Step: 3
Training loss: 3.2589184098355903
Validation loss: 2.836226595451742

Epoch: 5| Step: 4
Training loss: 3.268225697468693
Validation loss: 2.8340779115758488

Epoch: 5| Step: 5
Training loss: 3.4851125441211264
Validation loss: 2.8327485650708932

Epoch: 5| Step: 6
Training loss: 3.3652839679130175
Validation loss: 2.828734995703978

Epoch: 5| Step: 7
Training loss: 2.810363890819483
Validation loss: 2.8316264328332106

Epoch: 5| Step: 8
Training loss: 2.87196023542668
Validation loss: 2.8267876891955015

Epoch: 5| Step: 9
Training loss: 2.772148240995808
Validation loss: 2.8283255354211168

Epoch: 5| Step: 10
Training loss: 3.2502720058762185
Validation loss: 2.82745263503411

Epoch: 52| Step: 0
Training loss: 2.9406988704212105
Validation loss: 2.825104160622808

Epoch: 5| Step: 1
Training loss: 3.236016340782676
Validation loss: 2.827157160842764

Epoch: 5| Step: 2
Training loss: 3.2165015802532237
Validation loss: 2.824815547757255

Epoch: 5| Step: 3
Training loss: 3.2624657055451785
Validation loss: 2.823725870730213

Epoch: 5| Step: 4
Training loss: 3.498366655975836
Validation loss: 2.8260615840427548

Epoch: 5| Step: 5
Training loss: 2.7179823920863444
Validation loss: 2.8261306974793294

Epoch: 5| Step: 6
Training loss: 2.7347879152516104
Validation loss: 2.8275326752307164

Epoch: 5| Step: 7
Training loss: 3.7416253991743456
Validation loss: 2.824270417771908

Epoch: 5| Step: 8
Training loss: 3.4237158713949953
Validation loss: 2.8247177492665276

Epoch: 5| Step: 9
Training loss: 2.8461984008347105
Validation loss: 2.8246362951328527

Epoch: 5| Step: 10
Training loss: 2.6805080569928372
Validation loss: 2.8232523394631936

Epoch: 53| Step: 0
Training loss: 3.2369348098936093
Validation loss: 2.823255563929732

Epoch: 5| Step: 1
Training loss: 2.820986257790755
Validation loss: 2.833412482973599

Epoch: 5| Step: 2
Training loss: 3.3359881001907454
Validation loss: 2.845573536585358

Epoch: 5| Step: 3
Training loss: 3.307831983909832
Validation loss: 2.8426138235254492

Epoch: 5| Step: 4
Training loss: 2.6081900275922645
Validation loss: 2.830960214285931

Epoch: 5| Step: 5
Training loss: 3.0259890176960798
Validation loss: 2.8315076054925297

Epoch: 5| Step: 6
Training loss: 3.3758086189514818
Validation loss: 2.830958967311878

Epoch: 5| Step: 7
Training loss: 3.055399389803791
Validation loss: 2.8421946521306376

Epoch: 5| Step: 8
Training loss: 3.356713664670687
Validation loss: 2.828167013253876

Epoch: 5| Step: 9
Training loss: 3.1756908596261515
Validation loss: 2.8180803947937814

Epoch: 5| Step: 10
Training loss: 3.0846618333455345
Validation loss: 2.820537850944532

Epoch: 54| Step: 0
Training loss: 3.9041172156090975
Validation loss: 2.821080175355142

Epoch: 5| Step: 1
Training loss: 2.8925890049803824
Validation loss: 2.8200098913387714

Epoch: 5| Step: 2
Training loss: 2.5066359187161193
Validation loss: 2.8201795968290284

Epoch: 5| Step: 3
Training loss: 2.8646173833499513
Validation loss: 2.820556780938443

Epoch: 5| Step: 4
Training loss: 3.642535318322535
Validation loss: 2.8203842639811683

Epoch: 5| Step: 5
Training loss: 2.986809820791845
Validation loss: 2.823149864706612

Epoch: 5| Step: 6
Training loss: 3.2251205362667776
Validation loss: 2.8205265230634367

Epoch: 5| Step: 7
Training loss: 3.360225693979132
Validation loss: 2.8192446289134714

Epoch: 5| Step: 8
Training loss: 3.133373942686936
Validation loss: 2.8186193765294285

Epoch: 5| Step: 9
Training loss: 3.1117618160346794
Validation loss: 2.8156783581466023

Epoch: 5| Step: 10
Training loss: 2.5159927004661258
Validation loss: 2.8155918750505906

Epoch: 55| Step: 0
Training loss: 3.3731195368006004
Validation loss: 2.8176161952837817

Epoch: 5| Step: 1
Training loss: 2.976316426836409
Validation loss: 2.811481982518009

Epoch: 5| Step: 2
Training loss: 2.9494161577661253
Validation loss: 2.812979169929156

Epoch: 5| Step: 3
Training loss: 3.2387568328208207
Validation loss: 2.816212860231456

Epoch: 5| Step: 4
Training loss: 3.3396908373712066
Validation loss: 2.8129544400288524

Epoch: 5| Step: 5
Training loss: 3.4891495771940892
Validation loss: 2.813162417776736

Epoch: 5| Step: 6
Training loss: 2.647914778625952
Validation loss: 2.8164232443616126

Epoch: 5| Step: 7
Training loss: 2.775937782810639
Validation loss: 2.8162678936936305

Epoch: 5| Step: 8
Training loss: 3.1264190503659632
Validation loss: 2.8255791271886492

Epoch: 5| Step: 9
Training loss: 3.842732860927767
Validation loss: 2.8304994394461174

Epoch: 5| Step: 10
Training loss: 2.162814665375634
Validation loss: 2.848838216166836

Epoch: 56| Step: 0
Training loss: 2.448364400837492
Validation loss: 2.8742548541819795

Epoch: 5| Step: 1
Training loss: 3.590361482065478
Validation loss: 2.8557657125251903

Epoch: 5| Step: 2
Training loss: 2.596486038843353
Validation loss: 2.8564266553475797

Epoch: 5| Step: 3
Training loss: 3.071047474103225
Validation loss: 2.844010270072147

Epoch: 5| Step: 4
Training loss: 2.9658704746539954
Validation loss: 2.821323191295068

Epoch: 5| Step: 5
Training loss: 3.3931362152054794
Validation loss: 2.8122241907003778

Epoch: 5| Step: 6
Training loss: 2.990986635352362
Validation loss: 2.810313267297418

Epoch: 5| Step: 7
Training loss: 3.0973706877458387
Validation loss: 2.804855604432871

Epoch: 5| Step: 8
Training loss: 2.9452561593169007
Validation loss: 2.807405357213112

Epoch: 5| Step: 9
Training loss: 3.6441223634762587
Validation loss: 2.806516420931267

Epoch: 5| Step: 10
Training loss: 3.430115414560004
Validation loss: 2.8045046819848185

Epoch: 57| Step: 0
Training loss: 3.1884862832451364
Validation loss: 2.8054039961684434

Epoch: 5| Step: 1
Training loss: 4.022503731526125
Validation loss: 2.8045883734763675

Epoch: 5| Step: 2
Training loss: 3.1752831700722446
Validation loss: 2.8031598092702463

Epoch: 5| Step: 3
Training loss: 2.9705339392363914
Validation loss: 2.8048337396173633

Epoch: 5| Step: 4
Training loss: 2.4952819172627874
Validation loss: 2.8023621856153396

Epoch: 5| Step: 5
Training loss: 2.6607023734450554
Validation loss: 2.8055951091889098

Epoch: 5| Step: 6
Training loss: 3.1084714563957396
Validation loss: 2.8045751310519464

Epoch: 5| Step: 7
Training loss: 2.6497811928871076
Validation loss: 2.802767713520763

Epoch: 5| Step: 8
Training loss: 3.2402941219438866
Validation loss: 2.79872507380882

Epoch: 5| Step: 9
Training loss: 3.205872190349218
Validation loss: 2.803474574636002

Epoch: 5| Step: 10
Training loss: 3.371327415315778
Validation loss: 2.807534551473528

Epoch: 58| Step: 0
Training loss: 3.4786657250655177
Validation loss: 2.8125331844801322

Epoch: 5| Step: 1
Training loss: 2.413471433506426
Validation loss: 2.8314862072410807

Epoch: 5| Step: 2
Training loss: 3.6363522583610086
Validation loss: 2.8455900405329833

Epoch: 5| Step: 3
Training loss: 2.697292231070126
Validation loss: 2.823772677668

Epoch: 5| Step: 4
Training loss: 2.708558107487628
Validation loss: 2.8125175329685055

Epoch: 5| Step: 5
Training loss: 2.496184298166912
Validation loss: 2.8085727741355493

Epoch: 5| Step: 6
Training loss: 3.8164042508950753
Validation loss: 2.802838595891048

Epoch: 5| Step: 7
Training loss: 3.1506627551213393
Validation loss: 2.8004587810792034

Epoch: 5| Step: 8
Training loss: 3.2634119447377663
Validation loss: 2.8010668258944422

Epoch: 5| Step: 9
Training loss: 3.163288992064186
Validation loss: 2.7974916650117017

Epoch: 5| Step: 10
Training loss: 3.0963139554111163
Validation loss: 2.8020501013393626

Epoch: 59| Step: 0
Training loss: 3.1357795953078593
Validation loss: 2.7984334518003826

Epoch: 5| Step: 1
Training loss: 3.2968008023993023
Validation loss: 2.801365887489704

Epoch: 5| Step: 2
Training loss: 3.1426573293507007
Validation loss: 2.8014398883545004

Epoch: 5| Step: 3
Training loss: 2.9517964599033997
Validation loss: 2.8008334380002875

Epoch: 5| Step: 4
Training loss: 3.631644243647022
Validation loss: 2.804040989746337

Epoch: 5| Step: 5
Training loss: 3.207468948511281
Validation loss: 2.8007304459478384

Epoch: 5| Step: 6
Training loss: 2.7325644466132943
Validation loss: 2.800733687190226

Epoch: 5| Step: 7
Training loss: 2.698377729415485
Validation loss: 2.797783314629649

Epoch: 5| Step: 8
Training loss: 3.16200094997288
Validation loss: 2.795969672814225

Epoch: 5| Step: 9
Training loss: 2.9851015814233217
Validation loss: 2.7989018119281543

Epoch: 5| Step: 10
Training loss: 3.320477219029995
Validation loss: 2.793999608264585

Epoch: 60| Step: 0
Training loss: 3.278902212980747
Validation loss: 2.798991060203971

Epoch: 5| Step: 1
Training loss: 3.0046590548799004
Validation loss: 2.798212738482576

Epoch: 5| Step: 2
Training loss: 3.213045565223005
Validation loss: 2.7989158771470612

Epoch: 5| Step: 3
Training loss: 3.586989836355911
Validation loss: 2.794095678004039

Epoch: 5| Step: 4
Training loss: 3.4910061948268347
Validation loss: 2.7955451774167592

Epoch: 5| Step: 5
Training loss: 2.7650559696651458
Validation loss: 2.7985092038746244

Epoch: 5| Step: 6
Training loss: 2.8428225838997188
Validation loss: 2.795840774902057

Epoch: 5| Step: 7
Training loss: 2.9178135025007985
Validation loss: 2.797037869334022

Epoch: 5| Step: 8
Training loss: 3.2372342799658833
Validation loss: 2.794091396849151

Epoch: 5| Step: 9
Training loss: 2.7217588765614624
Validation loss: 2.799926215399425

Epoch: 5| Step: 10
Training loss: 2.9713690197657265
Validation loss: 2.799550005318674

Epoch: 61| Step: 0
Training loss: 2.4649922224931875
Validation loss: 2.797815569519922

Epoch: 5| Step: 1
Training loss: 3.001589036354588
Validation loss: 2.7989422689345425

Epoch: 5| Step: 2
Training loss: 2.621030167150977
Validation loss: 2.7998552126007348

Epoch: 5| Step: 3
Training loss: 2.7203275992354055
Validation loss: 2.788637611401104

Epoch: 5| Step: 4
Training loss: 3.6128855885567392
Validation loss: 2.7886064546707376

Epoch: 5| Step: 5
Training loss: 3.4050510641293785
Validation loss: 2.7851145047293584

Epoch: 5| Step: 6
Training loss: 3.4716537281466158
Validation loss: 2.789074768221421

Epoch: 5| Step: 7
Training loss: 3.080016199044569
Validation loss: 2.789199095470944

Epoch: 5| Step: 8
Training loss: 2.9703926761889305
Validation loss: 2.7866303519712687

Epoch: 5| Step: 9
Training loss: 3.2786014585191214
Validation loss: 2.7841747502276903

Epoch: 5| Step: 10
Training loss: 3.408496360952576
Validation loss: 2.7862387079064272

Epoch: 62| Step: 0
Training loss: 3.0902397201042446
Validation loss: 2.7875578765548092

Epoch: 5| Step: 1
Training loss: 3.422953675144117
Validation loss: 2.784999756319181

Epoch: 5| Step: 2
Training loss: 3.2765560908657365
Validation loss: 2.785081923248577

Epoch: 5| Step: 3
Training loss: 2.827064104420076
Validation loss: 2.7890572082960174

Epoch: 5| Step: 4
Training loss: 3.029998835698776
Validation loss: 2.7856615490049497

Epoch: 5| Step: 5
Training loss: 2.959534486301917
Validation loss: 2.783187466059043

Epoch: 5| Step: 6
Training loss: 2.511769533014763
Validation loss: 2.7902717288730945

Epoch: 5| Step: 7
Training loss: 3.394754031545199
Validation loss: 2.7799426780067846

Epoch: 5| Step: 8
Training loss: 3.4420556138825034
Validation loss: 2.7817410234594315

Epoch: 5| Step: 9
Training loss: 2.967388764556658
Validation loss: 2.790885574196339

Epoch: 5| Step: 10
Training loss: 3.1068270417868655
Validation loss: 2.7844216758546825

Epoch: 63| Step: 0
Training loss: 2.3417825197315953
Validation loss: 2.784111014246811

Epoch: 5| Step: 1
Training loss: 3.4670106118091795
Validation loss: 2.787205211300933

Epoch: 5| Step: 2
Training loss: 3.8666649051092237
Validation loss: 2.791980243373198

Epoch: 5| Step: 3
Training loss: 3.59572739310625
Validation loss: 2.790053912990891

Epoch: 5| Step: 4
Training loss: 2.9190924956096893
Validation loss: 2.7882847075846504

Epoch: 5| Step: 5
Training loss: 2.922907193078594
Validation loss: 2.7812397610885045

Epoch: 5| Step: 6
Training loss: 2.8791396151282553
Validation loss: 2.7846497379733206

Epoch: 5| Step: 7
Training loss: 3.236730335315224
Validation loss: 2.779944105559488

Epoch: 5| Step: 8
Training loss: 2.6602223930034152
Validation loss: 2.781171256749599

Epoch: 5| Step: 9
Training loss: 2.7818758828224524
Validation loss: 2.779065591395599

Epoch: 5| Step: 10
Training loss: 3.14090617425274
Validation loss: 2.779986832204568

Epoch: 64| Step: 0
Training loss: 3.0843027154709737
Validation loss: 2.775795874430371

Epoch: 5| Step: 1
Training loss: 3.2489154179706556
Validation loss: 2.7814308403596026

Epoch: 5| Step: 2
Training loss: 3.4026000739858877
Validation loss: 2.7792335759993447

Epoch: 5| Step: 3
Training loss: 2.8366456211742337
Validation loss: 2.7779853642398398

Epoch: 5| Step: 4
Training loss: 3.7075097244557016
Validation loss: 2.7821352615469848

Epoch: 5| Step: 5
Training loss: 2.762583466386571
Validation loss: 2.786678619156985

Epoch: 5| Step: 6
Training loss: 3.111277242796432
Validation loss: 2.786994250634697

Epoch: 5| Step: 7
Training loss: 3.084781014755599
Validation loss: 2.7945387429841833

Epoch: 5| Step: 8
Training loss: 2.8030921415276455
Validation loss: 2.784212408447826

Epoch: 5| Step: 9
Training loss: 2.8800134483659194
Validation loss: 2.7816562224578107

Epoch: 5| Step: 10
Training loss: 3.004592559155601
Validation loss: 2.778228183723115

Epoch: 65| Step: 0
Training loss: 3.2215960614051737
Validation loss: 2.7783030610787325

Epoch: 5| Step: 1
Training loss: 3.4430716010810607
Validation loss: 2.7767108194714853

Epoch: 5| Step: 2
Training loss: 3.206411173972725
Validation loss: 2.7746988116245563

Epoch: 5| Step: 3
Training loss: 2.914546977414694
Validation loss: 2.777796637631725

Epoch: 5| Step: 4
Training loss: 2.792491866794036
Validation loss: 2.780988359467397

Epoch: 5| Step: 5
Training loss: 3.3048844515501816
Validation loss: 2.781059348012782

Epoch: 5| Step: 6
Training loss: 3.4249667479300103
Validation loss: 2.778380098328069

Epoch: 5| Step: 7
Training loss: 2.7035975401525008
Validation loss: 2.776936444331772

Epoch: 5| Step: 8
Training loss: 2.817635658064953
Validation loss: 2.7720392367769513

Epoch: 5| Step: 9
Training loss: 3.139080218070019
Validation loss: 2.775318575118675

Epoch: 5| Step: 10
Training loss: 2.913145028262149
Validation loss: 2.7709335881416304

Epoch: 66| Step: 0
Training loss: 3.2784059824131697
Validation loss: 2.7749909296306026

Epoch: 5| Step: 1
Training loss: 2.7864144199987204
Validation loss: 2.7767065161287756

Epoch: 5| Step: 2
Training loss: 3.484471614849572
Validation loss: 2.773975933473922

Epoch: 5| Step: 3
Training loss: 3.559245848552332
Validation loss: 2.7720174696374675

Epoch: 5| Step: 4
Training loss: 2.9543059071886093
Validation loss: 2.7706547134514685

Epoch: 5| Step: 5
Training loss: 3.5951909369218216
Validation loss: 2.768860354078833

Epoch: 5| Step: 6
Training loss: 2.788335283289758
Validation loss: 2.7669076264461574

Epoch: 5| Step: 7
Training loss: 2.627300435190408
Validation loss: 2.767518591218225

Epoch: 5| Step: 8
Training loss: 2.5096164762953843
Validation loss: 2.768937715149288

Epoch: 5| Step: 9
Training loss: 3.3474113882243635
Validation loss: 2.768127524432187

Epoch: 5| Step: 10
Training loss: 2.701704589213619
Validation loss: 2.7732849180800976

Epoch: 67| Step: 0
Training loss: 3.2978112215755186
Validation loss: 2.7691051939297937

Epoch: 5| Step: 1
Training loss: 3.2437856389258015
Validation loss: 2.7796720775931827

Epoch: 5| Step: 2
Training loss: 3.454370886667535
Validation loss: 2.7953819679937952

Epoch: 5| Step: 3
Training loss: 3.042697644674735
Validation loss: 2.800785923673877

Epoch: 5| Step: 4
Training loss: 2.7179997603842296
Validation loss: 2.7962347615358847

Epoch: 5| Step: 5
Training loss: 3.584007924181829
Validation loss: 2.7843225754758296

Epoch: 5| Step: 6
Training loss: 2.880349531156047
Validation loss: 2.7762299828385486

Epoch: 5| Step: 7
Training loss: 2.40627328440312
Validation loss: 2.7662145395180593

Epoch: 5| Step: 8
Training loss: 2.6724665472151163
Validation loss: 2.7642796208400235

Epoch: 5| Step: 9
Training loss: 3.740525547576211
Validation loss: 2.763839325034713

Epoch: 5| Step: 10
Training loss: 2.6221556012083345
Validation loss: 2.762680453211062

Epoch: 68| Step: 0
Training loss: 3.447039597317332
Validation loss: 2.7624962045657124

Epoch: 5| Step: 1
Training loss: 3.2557110126196505
Validation loss: 2.762245716126868

Epoch: 5| Step: 2
Training loss: 3.362795769258399
Validation loss: 2.7619749240691402

Epoch: 5| Step: 3
Training loss: 3.043994970470389
Validation loss: 2.7635898720688745

Epoch: 5| Step: 4
Training loss: 3.389551933407296
Validation loss: 2.767242523144927

Epoch: 5| Step: 5
Training loss: 2.2718772122085062
Validation loss: 2.7657406727543217

Epoch: 5| Step: 6
Training loss: 2.5431604737934035
Validation loss: 2.7723908883665693

Epoch: 5| Step: 7
Training loss: 3.0862925651151984
Validation loss: 2.785368389921542

Epoch: 5| Step: 8
Training loss: 2.6542961564108665
Validation loss: 2.7867976680786644

Epoch: 5| Step: 9
Training loss: 3.315429831323635
Validation loss: 2.795930797574496

Epoch: 5| Step: 10
Training loss: 3.3856503606490422
Validation loss: 2.7687083652926767

Epoch: 69| Step: 0
Training loss: 2.939456044952869
Validation loss: 2.7635253737553143

Epoch: 5| Step: 1
Training loss: 2.5908284106309547
Validation loss: 2.7574962922838706

Epoch: 5| Step: 2
Training loss: 2.9902487267985114
Validation loss: 2.761884511203763

Epoch: 5| Step: 3
Training loss: 2.8509106034600418
Validation loss: 2.7641103392847968

Epoch: 5| Step: 4
Training loss: 3.5186270548344822
Validation loss: 2.768369089771485

Epoch: 5| Step: 5
Training loss: 2.4922607793767155
Validation loss: 2.7774677864187693

Epoch: 5| Step: 6
Training loss: 3.794669809966976
Validation loss: 2.7694767938902594

Epoch: 5| Step: 7
Training loss: 3.2918095296125576
Validation loss: 2.763458666028463

Epoch: 5| Step: 8
Training loss: 2.9740801695514922
Validation loss: 2.763067495238855

Epoch: 5| Step: 9
Training loss: 2.8508346673880003
Validation loss: 2.7574497576836894

Epoch: 5| Step: 10
Training loss: 3.570868050322288
Validation loss: 2.7602972242007753

Epoch: 70| Step: 0
Training loss: 3.135781420067559
Validation loss: 2.7563299692109755

Epoch: 5| Step: 1
Training loss: 3.1232291735607642
Validation loss: 2.759044104600867

Epoch: 5| Step: 2
Training loss: 3.0010663362650094
Validation loss: 2.7581295879368213

Epoch: 5| Step: 3
Training loss: 3.2836694425961555
Validation loss: 2.7602630578686496

Epoch: 5| Step: 4
Training loss: 2.6933528244458955
Validation loss: 2.759716970714169

Epoch: 5| Step: 5
Training loss: 3.690112594706141
Validation loss: 2.7591587171463803

Epoch: 5| Step: 6
Training loss: 3.640572346973729
Validation loss: 2.760454249034278

Epoch: 5| Step: 7
Training loss: 2.642506938914389
Validation loss: 2.7644842126456832

Epoch: 5| Step: 8
Training loss: 3.2343480205792785
Validation loss: 2.763460741276419

Epoch: 5| Step: 9
Training loss: 2.5730987566762544
Validation loss: 2.7669831575892188

Epoch: 5| Step: 10
Training loss: 2.5014413493339624
Validation loss: 2.760528085464107

Epoch: 71| Step: 0
Training loss: 2.2593142257262153
Validation loss: 2.7585332059429875

Epoch: 5| Step: 1
Training loss: 3.009493905290224
Validation loss: 2.7587193743279785

Epoch: 5| Step: 2
Training loss: 3.4754241794245364
Validation loss: 2.7563441884218034

Epoch: 5| Step: 3
Training loss: 2.9265567581926955
Validation loss: 2.757075017355264

Epoch: 5| Step: 4
Training loss: 3.315136849641074
Validation loss: 2.7587914971680187

Epoch: 5| Step: 5
Training loss: 3.272971327187843
Validation loss: 2.7558255713358504

Epoch: 5| Step: 6
Training loss: 2.9816580183295742
Validation loss: 2.7549329219510574

Epoch: 5| Step: 7
Training loss: 3.632336394582782
Validation loss: 2.7518153803472747

Epoch: 5| Step: 8
Training loss: 3.177049296879456
Validation loss: 2.75634652480003

Epoch: 5| Step: 9
Training loss: 2.235525301959677
Validation loss: 2.7556478334101495

Epoch: 5| Step: 10
Training loss: 3.235360847641747
Validation loss: 2.7591622004844774

Epoch: 72| Step: 0
Training loss: 3.1361468068034126
Validation loss: 2.7563536650646845

Epoch: 5| Step: 1
Training loss: 3.2318611142655644
Validation loss: 2.7630788480713235

Epoch: 5| Step: 2
Training loss: 2.860516263075741
Validation loss: 2.7656260864040623

Epoch: 5| Step: 3
Training loss: 2.870264216366314
Validation loss: 2.78087158873421

Epoch: 5| Step: 4
Training loss: 2.483119623431384
Validation loss: 2.789300788160058

Epoch: 5| Step: 5
Training loss: 3.5087451671951655
Validation loss: 2.770530810615945

Epoch: 5| Step: 6
Training loss: 2.901476970638406
Validation loss: 2.7594178928085196

Epoch: 5| Step: 7
Training loss: 3.2787560567389047
Validation loss: 2.75066488698538

Epoch: 5| Step: 8
Training loss: 2.8476286207828885
Validation loss: 2.7466727168235288

Epoch: 5| Step: 9
Training loss: 2.7773425481823173
Validation loss: 2.7502709177909486

Epoch: 5| Step: 10
Training loss: 3.7886196231591813
Validation loss: 2.746255458202202

Epoch: 73| Step: 0
Training loss: 3.5037587282559963
Validation loss: 2.7435359354722815

Epoch: 5| Step: 1
Training loss: 3.2020184350040006
Validation loss: 2.7471284892653425

Epoch: 5| Step: 2
Training loss: 3.362650281532939
Validation loss: 2.7474688611776052

Epoch: 5| Step: 3
Training loss: 3.1177935094867735
Validation loss: 2.742472256111358

Epoch: 5| Step: 4
Training loss: 2.9177587553600075
Validation loss: 2.7434958313382176

Epoch: 5| Step: 5
Training loss: 2.70806186978366
Validation loss: 2.7404612414973113

Epoch: 5| Step: 6
Training loss: 3.221589844865426
Validation loss: 2.7447326150065683

Epoch: 5| Step: 7
Training loss: 2.8064968043080953
Validation loss: 2.7423615595689665

Epoch: 5| Step: 8
Training loss: 2.653278438952342
Validation loss: 2.7436062681372038

Epoch: 5| Step: 9
Training loss: 2.578174752420036
Validation loss: 2.7418104053346246

Epoch: 5| Step: 10
Training loss: 3.5631952778473606
Validation loss: 2.7426318223028123

Epoch: 74| Step: 0
Training loss: 2.981461305947113
Validation loss: 2.7460042482366287

Epoch: 5| Step: 1
Training loss: 3.25564276072505
Validation loss: 2.7441970926237302

Epoch: 5| Step: 2
Training loss: 2.6203388428885095
Validation loss: 2.7493213271045227

Epoch: 5| Step: 3
Training loss: 3.313197800175223
Validation loss: 2.750304943528063

Epoch: 5| Step: 4
Training loss: 3.2039344323124994
Validation loss: 2.7504443222669743

Epoch: 5| Step: 5
Training loss: 3.0460052031223994
Validation loss: 2.748100602726819

Epoch: 5| Step: 6
Training loss: 3.1536591726704017
Validation loss: 2.7499162086929267

Epoch: 5| Step: 7
Training loss: 2.9741499127056574
Validation loss: 2.7396642744020605

Epoch: 5| Step: 8
Training loss: 2.639564436614318
Validation loss: 2.737310030549905

Epoch: 5| Step: 9
Training loss: 3.2360430115905086
Validation loss: 2.7379517229032926

Epoch: 5| Step: 10
Training loss: 3.274897356827219
Validation loss: 2.736510863195513

Epoch: 75| Step: 0
Training loss: 3.690597397122049
Validation loss: 2.736859494730044

Epoch: 5| Step: 1
Training loss: 2.631451806962408
Validation loss: 2.7437501179531614

Epoch: 5| Step: 2
Training loss: 3.166497242728629
Validation loss: 2.7363370854089033

Epoch: 5| Step: 3
Training loss: 3.3885714029593803
Validation loss: 2.741077845639156

Epoch: 5| Step: 4
Training loss: 2.9675258321047493
Validation loss: 2.7414408895800317

Epoch: 5| Step: 5
Training loss: 2.290540510963939
Validation loss: 2.74350790338153

Epoch: 5| Step: 6
Training loss: 3.3754082891961996
Validation loss: 2.744451697251687

Epoch: 5| Step: 7
Training loss: 2.699626621284533
Validation loss: 2.739488919547746

Epoch: 5| Step: 8
Training loss: 3.136752801807697
Validation loss: 2.7385659095840276

Epoch: 5| Step: 9
Training loss: 3.3476133755550124
Validation loss: 2.7416378125072707

Epoch: 5| Step: 10
Training loss: 2.649777053955473
Validation loss: 2.736293677182375

Epoch: 76| Step: 0
Training loss: 3.1216757832027606
Validation loss: 2.735856010295526

Epoch: 5| Step: 1
Training loss: 3.328034592237789
Validation loss: 2.742040766197331

Epoch: 5| Step: 2
Training loss: 2.7387114226402614
Validation loss: 2.742903370648966

Epoch: 5| Step: 3
Training loss: 3.0400958425070117
Validation loss: 2.7376162256102234

Epoch: 5| Step: 4
Training loss: 3.071957989306091
Validation loss: 2.7435410869767223

Epoch: 5| Step: 5
Training loss: 3.4570058703164426
Validation loss: 2.743148530134083

Epoch: 5| Step: 6
Training loss: 3.32239565855533
Validation loss: 2.7447618021047346

Epoch: 5| Step: 7
Training loss: 2.712971652463909
Validation loss: 2.7435656613792863

Epoch: 5| Step: 8
Training loss: 2.5674983332701924
Validation loss: 2.7393950552788318

Epoch: 5| Step: 9
Training loss: 3.1600426275058076
Validation loss: 2.7353471275463774

Epoch: 5| Step: 10
Training loss: 2.9602723192266436
Validation loss: 2.7340981507673696

Epoch: 77| Step: 0
Training loss: 2.800303994433939
Validation loss: 2.7286691403938756

Epoch: 5| Step: 1
Training loss: 3.092974787217444
Validation loss: 2.7325616057990954

Epoch: 5| Step: 2
Training loss: 2.9158375424418925
Validation loss: 2.732151257253949

Epoch: 5| Step: 3
Training loss: 3.330396423341955
Validation loss: 2.7324326946488786

Epoch: 5| Step: 4
Training loss: 2.7839571175780398
Validation loss: 2.73699042570436

Epoch: 5| Step: 5
Training loss: 2.8993500869183895
Validation loss: 2.7344772990086432

Epoch: 5| Step: 6
Training loss: 3.0870439694569223
Validation loss: 2.7440351715629747

Epoch: 5| Step: 7
Training loss: 3.3026265240096837
Validation loss: 2.7428072669078687

Epoch: 5| Step: 8
Training loss: 3.1665808180833808
Validation loss: 2.732200386471388

Epoch: 5| Step: 9
Training loss: 3.354901124773551
Validation loss: 2.7348226660700043

Epoch: 5| Step: 10
Training loss: 2.744321161487871
Validation loss: 2.7279074662748055

Epoch: 78| Step: 0
Training loss: 3.363544662031626
Validation loss: 2.72670936065548

Epoch: 5| Step: 1
Training loss: 2.6266288245165144
Validation loss: 2.725023786943924

Epoch: 5| Step: 2
Training loss: 2.677295384500317
Validation loss: 2.7271112252498537

Epoch: 5| Step: 3
Training loss: 3.540830461107829
Validation loss: 2.729590640326034

Epoch: 5| Step: 4
Training loss: 2.846154506389835
Validation loss: 2.724534870019521

Epoch: 5| Step: 5
Training loss: 3.0167152133920325
Validation loss: 2.722963833015355

Epoch: 5| Step: 6
Training loss: 2.945275263462394
Validation loss: 2.7246216172882627

Epoch: 5| Step: 7
Training loss: 3.321977695948293
Validation loss: 2.720673846586745

Epoch: 5| Step: 8
Training loss: 2.706059709514692
Validation loss: 2.7211703459430248

Epoch: 5| Step: 9
Training loss: 3.66239217658051
Validation loss: 2.721029269856331

Epoch: 5| Step: 10
Training loss: 2.5431855046351473
Validation loss: 2.720119366725982

Epoch: 79| Step: 0
Training loss: 3.081333405331135
Validation loss: 2.723031396255931

Epoch: 5| Step: 1
Training loss: 3.0877051590313616
Validation loss: 2.7240783580887573

Epoch: 5| Step: 2
Training loss: 3.065542616986438
Validation loss: 2.7242454054882996

Epoch: 5| Step: 3
Training loss: 2.9954664625577276
Validation loss: 2.7220013019725346

Epoch: 5| Step: 4
Training loss: 2.732680138795391
Validation loss: 2.7260763323315214

Epoch: 5| Step: 5
Training loss: 2.7069803428542145
Validation loss: 2.7278587465573545

Epoch: 5| Step: 6
Training loss: 3.3527852564442715
Validation loss: 2.720390397315047

Epoch: 5| Step: 7
Training loss: 2.5774055170600025
Validation loss: 2.71584232568587

Epoch: 5| Step: 8
Training loss: 3.179964770475812
Validation loss: 2.7172466662499035

Epoch: 5| Step: 9
Training loss: 3.55527164564175
Validation loss: 2.717079100816258

Epoch: 5| Step: 10
Training loss: 3.058156728885911
Validation loss: 2.716716882631759

Epoch: 80| Step: 0
Training loss: 3.3155277737699826
Validation loss: 2.7212624619738164

Epoch: 5| Step: 1
Training loss: 3.119115247724724
Validation loss: 2.717338749245818

Epoch: 5| Step: 2
Training loss: 3.479884517112803
Validation loss: 2.717565290399897

Epoch: 5| Step: 3
Training loss: 3.0135283618312
Validation loss: 2.716910507861741

Epoch: 5| Step: 4
Training loss: 2.8619458257638164
Validation loss: 2.716011383271888

Epoch: 5| Step: 5
Training loss: 2.8365456005339826
Validation loss: 2.716808454212082

Epoch: 5| Step: 6
Training loss: 2.5213442408169264
Validation loss: 2.7225099918225024

Epoch: 5| Step: 7
Training loss: 3.2755295070622923
Validation loss: 2.7221969028919695

Epoch: 5| Step: 8
Training loss: 2.935362667311735
Validation loss: 2.735282770236595

Epoch: 5| Step: 9
Training loss: 3.2762917977540953
Validation loss: 2.7379724982303877

Epoch: 5| Step: 10
Training loss: 2.7869198045638686
Validation loss: 2.739052126373633

Epoch: 81| Step: 0
Training loss: 2.5181252511697294
Validation loss: 2.723615602487969

Epoch: 5| Step: 1
Training loss: 3.483434438987284
Validation loss: 2.7208877605772246

Epoch: 5| Step: 2
Training loss: 2.656294788656173
Validation loss: 2.7157970908498172

Epoch: 5| Step: 3
Training loss: 3.4594828215821893
Validation loss: 2.7145697895077627

Epoch: 5| Step: 4
Training loss: 2.9171482960089983
Validation loss: 2.7127823105601694

Epoch: 5| Step: 5
Training loss: 2.9429397537022224
Validation loss: 2.715065063417309

Epoch: 5| Step: 6
Training loss: 3.0302720212794787
Validation loss: 2.7130163230324063

Epoch: 5| Step: 7
Training loss: 3.386382230343372
Validation loss: 2.7215656028615145

Epoch: 5| Step: 8
Training loss: 2.42561003100704
Validation loss: 2.7196849384224087

Epoch: 5| Step: 9
Training loss: 3.5617517053510745
Validation loss: 2.7223748942859682

Epoch: 5| Step: 10
Training loss: 2.8509637909579832
Validation loss: 2.7211157397821086

Epoch: 82| Step: 0
Training loss: 3.1077192489112835
Validation loss: 2.7152395681521693

Epoch: 5| Step: 1
Training loss: 3.7457061344285414
Validation loss: 2.7166877160186997

Epoch: 5| Step: 2
Training loss: 2.954193567782127
Validation loss: 2.715868157913064

Epoch: 5| Step: 3
Training loss: 3.00890681188978
Validation loss: 2.712296438482527

Epoch: 5| Step: 4
Training loss: 2.5009355701809453
Validation loss: 2.714739761137428

Epoch: 5| Step: 5
Training loss: 2.859944271264951
Validation loss: 2.709893703038676

Epoch: 5| Step: 6
Training loss: 3.110671036869952
Validation loss: 2.712831443731072

Epoch: 5| Step: 7
Training loss: 3.310341473624295
Validation loss: 2.710355247834603

Epoch: 5| Step: 8
Training loss: 3.234860001472394
Validation loss: 2.7122611419515814

Epoch: 5| Step: 9
Training loss: 2.4181522429177154
Validation loss: 2.7184078834394683

Epoch: 5| Step: 10
Training loss: 2.9704432427108425
Validation loss: 2.7129029305652645

Epoch: 83| Step: 0
Training loss: 3.0980709226504906
Validation loss: 2.7154734651610895

Epoch: 5| Step: 1
Training loss: 3.2477306365706697
Validation loss: 2.735370672456716

Epoch: 5| Step: 2
Training loss: 2.32625602102346
Validation loss: 2.7376752803178026

Epoch: 5| Step: 3
Training loss: 3.4462939051839734
Validation loss: 2.7237457441523643

Epoch: 5| Step: 4
Training loss: 3.3394893703619934
Validation loss: 2.718737896288939

Epoch: 5| Step: 5
Training loss: 2.7217885718655195
Validation loss: 2.7144907335484323

Epoch: 5| Step: 6
Training loss: 3.137218696780354
Validation loss: 2.707975816123297

Epoch: 5| Step: 7
Training loss: 3.400974212647425
Validation loss: 2.707447242768587

Epoch: 5| Step: 8
Training loss: 3.3289470105203747
Validation loss: 2.7093615893550713

Epoch: 5| Step: 9
Training loss: 2.454139159673951
Validation loss: 2.7090464262959912

Epoch: 5| Step: 10
Training loss: 2.5628913022380413
Validation loss: 2.705633653965604

Epoch: 84| Step: 0
Training loss: 3.1244021034476854
Validation loss: 2.70940897353355

Epoch: 5| Step: 1
Training loss: 3.095247773095955
Validation loss: 2.705554730125613

Epoch: 5| Step: 2
Training loss: 3.171772471307047
Validation loss: 2.706752642075257

Epoch: 5| Step: 3
Training loss: 3.022920470670221
Validation loss: 2.7123840138245843

Epoch: 5| Step: 4
Training loss: 2.9971277474437206
Validation loss: 2.708703783571358

Epoch: 5| Step: 5
Training loss: 3.0568911513746344
Validation loss: 2.703975536329822

Epoch: 5| Step: 6
Training loss: 2.523467261549292
Validation loss: 2.701548898171661

Epoch: 5| Step: 7
Training loss: 3.053556813497472
Validation loss: 2.700683843878996

Epoch: 5| Step: 8
Training loss: 3.2034228674859846
Validation loss: 2.7020915731250548

Epoch: 5| Step: 9
Training loss: 2.5740723170308257
Validation loss: 2.699803793237309

Epoch: 5| Step: 10
Training loss: 3.514792788870184
Validation loss: 2.702209786230484

Epoch: 85| Step: 0
Training loss: 3.0007305845131316
Validation loss: 2.706571024229305

Epoch: 5| Step: 1
Training loss: 2.7058120337907865
Validation loss: 2.701908173187666

Epoch: 5| Step: 2
Training loss: 2.7818690264742054
Validation loss: 2.7027446880699033

Epoch: 5| Step: 3
Training loss: 3.636938233927987
Validation loss: 2.705303060324221

Epoch: 5| Step: 4
Training loss: 3.382213795036392
Validation loss: 2.7010501834783245

Epoch: 5| Step: 5
Training loss: 2.6341743003624383
Validation loss: 2.7042772942017286

Epoch: 5| Step: 6
Training loss: 3.0106246682789126
Validation loss: 2.7006601446470118

Epoch: 5| Step: 7
Training loss: 2.719881896372047
Validation loss: 2.7037222071712614

Epoch: 5| Step: 8
Training loss: 3.141190814771087
Validation loss: 2.703955268708863

Epoch: 5| Step: 9
Training loss: 3.068012181482912
Validation loss: 2.7038138234679856

Epoch: 5| Step: 10
Training loss: 3.1030655685219393
Validation loss: 2.7101399841256546

Epoch: 86| Step: 0
Training loss: 2.6534471871119805
Validation loss: 2.700491218706316

Epoch: 5| Step: 1
Training loss: 3.740247123835975
Validation loss: 2.6982474093275157

Epoch: 5| Step: 2
Training loss: 3.3760258563710295
Validation loss: 2.6988230234528743

Epoch: 5| Step: 3
Training loss: 3.278472887749418
Validation loss: 2.7001232518633413

Epoch: 5| Step: 4
Training loss: 3.437092011255365
Validation loss: 2.7000839081354044

Epoch: 5| Step: 5
Training loss: 2.41548583899366
Validation loss: 2.6981878802748147

Epoch: 5| Step: 6
Training loss: 3.07318027895819
Validation loss: 2.7017348370487815

Epoch: 5| Step: 7
Training loss: 2.8893235034549503
Validation loss: 2.6978717502002336

Epoch: 5| Step: 8
Training loss: 3.4370209793635897
Validation loss: 2.699534258899436

Epoch: 5| Step: 9
Training loss: 2.4156377399695885
Validation loss: 2.6991259633425106

Epoch: 5| Step: 10
Training loss: 1.908613896741805
Validation loss: 2.696058199468085

Epoch: 87| Step: 0
Training loss: 3.0043037062316693
Validation loss: 2.706342005459364

Epoch: 5| Step: 1
Training loss: 3.1736165794883786
Validation loss: 2.709856175662319

Epoch: 5| Step: 2
Training loss: 2.657932870371654
Validation loss: 2.715508553780852

Epoch: 5| Step: 3
Training loss: 3.9742141714607744
Validation loss: 2.7083988983194582

Epoch: 5| Step: 4
Training loss: 3.1166327802750455
Validation loss: 2.7131164802158048

Epoch: 5| Step: 5
Training loss: 2.91563442674362
Validation loss: 2.71005274114487

Epoch: 5| Step: 6
Training loss: 2.8115669398173635
Validation loss: 2.71765280538134

Epoch: 5| Step: 7
Training loss: 2.7859185287163406
Validation loss: 2.7107203503797006

Epoch: 5| Step: 8
Training loss: 3.3164432015848515
Validation loss: 2.7126566243657773

Epoch: 5| Step: 9
Training loss: 2.388064041218266
Validation loss: 2.6993283865287014

Epoch: 5| Step: 10
Training loss: 2.788231135393887
Validation loss: 2.6945585014504543

Epoch: 88| Step: 0
Training loss: 3.009208850492732
Validation loss: 2.694201210395074

Epoch: 5| Step: 1
Training loss: 3.3400017951914824
Validation loss: 2.690678301816317

Epoch: 5| Step: 2
Training loss: 2.9665413119231427
Validation loss: 2.6938713863890666

Epoch: 5| Step: 3
Training loss: 2.9358207285561098
Validation loss: 2.688031179634131

Epoch: 5| Step: 4
Training loss: 2.299148161333069
Validation loss: 2.6915783215954376

Epoch: 5| Step: 5
Training loss: 3.3438650806623973
Validation loss: 2.691379227588837

Epoch: 5| Step: 6
Training loss: 2.896346579609614
Validation loss: 2.6868269865350287

Epoch: 5| Step: 7
Training loss: 3.376996332954492
Validation loss: 2.6878085921502657

Epoch: 5| Step: 8
Training loss: 2.831748369492777
Validation loss: 2.6912802608947572

Epoch: 5| Step: 9
Training loss: 3.1669187110848975
Validation loss: 2.6917114665790667

Epoch: 5| Step: 10
Training loss: 2.903722340669242
Validation loss: 2.6950472593766945

Epoch: 89| Step: 0
Training loss: 3.0153408410789018
Validation loss: 2.7021025123237807

Epoch: 5| Step: 1
Training loss: 3.0866356941080832
Validation loss: 2.697784098126467

Epoch: 5| Step: 2
Training loss: 3.133668093012259
Validation loss: 2.6990827117712413

Epoch: 5| Step: 3
Training loss: 3.029013683823424
Validation loss: 2.703586625967665

Epoch: 5| Step: 4
Training loss: 3.14384439679313
Validation loss: 2.687929922726275

Epoch: 5| Step: 5
Training loss: 2.772616412622815
Validation loss: 2.6877664976207405

Epoch: 5| Step: 6
Training loss: 2.7171979837067286
Validation loss: 2.6882245583993347

Epoch: 5| Step: 7
Training loss: 2.992164870692008
Validation loss: 2.681700310102153

Epoch: 5| Step: 8
Training loss: 3.226006780987381
Validation loss: 2.6845487323671713

Epoch: 5| Step: 9
Training loss: 2.8766325586211625
Validation loss: 2.6842833068010044

Epoch: 5| Step: 10
Training loss: 3.2680724979049196
Validation loss: 2.682597413136446

Epoch: 90| Step: 0
Training loss: 3.2188748826179516
Validation loss: 2.6832072187149825

Epoch: 5| Step: 1
Training loss: 2.913117529109205
Validation loss: 2.694083830602362

Epoch: 5| Step: 2
Training loss: 2.6310918148814535
Validation loss: 2.681559258853217

Epoch: 5| Step: 3
Training loss: 2.9488217926664855
Validation loss: 2.683290924369481

Epoch: 5| Step: 4
Training loss: 2.9787602358572953
Validation loss: 2.6840726972500026

Epoch: 5| Step: 5
Training loss: 2.9709836888798034
Validation loss: 2.686214164218816

Epoch: 5| Step: 6
Training loss: 3.1488047496825735
Validation loss: 2.6897801768367273

Epoch: 5| Step: 7
Training loss: 3.0660037803153806
Validation loss: 2.685089128877605

Epoch: 5| Step: 8
Training loss: 3.057170668400366
Validation loss: 2.6823863959656733

Epoch: 5| Step: 9
Training loss: 3.369932255276264
Validation loss: 2.6805176420267065

Epoch: 5| Step: 10
Training loss: 2.773672260503267
Validation loss: 2.6812391019737807

Epoch: 91| Step: 0
Training loss: 2.999911465927913
Validation loss: 2.684435639626502

Epoch: 5| Step: 1
Training loss: 2.592266163888446
Validation loss: 2.6834886905921267

Epoch: 5| Step: 2
Training loss: 3.0089481736369774
Validation loss: 2.6878926914844614

Epoch: 5| Step: 3
Training loss: 2.7808352386160196
Validation loss: 2.698595506471057

Epoch: 5| Step: 4
Training loss: 3.6686371508111186
Validation loss: 2.6813195905645264

Epoch: 5| Step: 5
Training loss: 2.7130169107857083
Validation loss: 2.699776814046504

Epoch: 5| Step: 6
Training loss: 2.729020985993363
Validation loss: 2.693370010811978

Epoch: 5| Step: 7
Training loss: 3.0156080808807277
Validation loss: 2.683411539194509

Epoch: 5| Step: 8
Training loss: 3.237978784219511
Validation loss: 2.6770797368124377

Epoch: 5| Step: 9
Training loss: 2.859228578581152
Validation loss: 2.680674484731463

Epoch: 5| Step: 10
Training loss: 3.462354245199426
Validation loss: 2.684107142867934

Epoch: 92| Step: 0
Training loss: 2.977221798907931
Validation loss: 2.678099847739771

Epoch: 5| Step: 1
Training loss: 3.5478124513998224
Validation loss: 2.681188334270235

Epoch: 5| Step: 2
Training loss: 2.876911688750311
Validation loss: 2.6788357406116035

Epoch: 5| Step: 3
Training loss: 3.436283798079312
Validation loss: 2.6816105434268263

Epoch: 5| Step: 4
Training loss: 3.4446202834855257
Validation loss: 2.676253613996225

Epoch: 5| Step: 5
Training loss: 2.688593265038803
Validation loss: 2.677876204035678

Epoch: 5| Step: 6
Training loss: 3.173311857049326
Validation loss: 2.686653242290138

Epoch: 5| Step: 7
Training loss: 2.0519530227518774
Validation loss: 2.682769725779954

Epoch: 5| Step: 8
Training loss: 2.54753300878461
Validation loss: 2.680855384037834

Epoch: 5| Step: 9
Training loss: 2.9652554473711135
Validation loss: 2.6794973072903026

Epoch: 5| Step: 10
Training loss: 3.1343818215688635
Validation loss: 2.6808531243540736

Epoch: 93| Step: 0
Training loss: 2.7346946311511586
Validation loss: 2.689712104324208

Epoch: 5| Step: 1
Training loss: 3.0678850435009326
Validation loss: 2.6824300381246986

Epoch: 5| Step: 2
Training loss: 3.0938017869718664
Validation loss: 2.6795510394503483

Epoch: 5| Step: 3
Training loss: 3.423516563432287
Validation loss: 2.6782424968948106

Epoch: 5| Step: 4
Training loss: 3.1354804724266345
Validation loss: 2.6720612681755016

Epoch: 5| Step: 5
Training loss: 2.9220612002523185
Validation loss: 2.6735527577340528

Epoch: 5| Step: 6
Training loss: 3.180485505762943
Validation loss: 2.677507798670969

Epoch: 5| Step: 7
Training loss: 3.3060337507921713
Validation loss: 2.674660680842123

Epoch: 5| Step: 8
Training loss: 2.753888502131419
Validation loss: 2.675591672620738

Epoch: 5| Step: 9
Training loss: 2.544062084951907
Validation loss: 2.6722089338935486

Epoch: 5| Step: 10
Training loss: 2.7819519871532083
Validation loss: 2.6786126053043247

Epoch: 94| Step: 0
Training loss: 2.480514694148814
Validation loss: 2.677193273393067

Epoch: 5| Step: 1
Training loss: 3.0051382884165787
Validation loss: 2.678352417769676

Epoch: 5| Step: 2
Training loss: 3.481073705842468
Validation loss: 2.699116919293674

Epoch: 5| Step: 3
Training loss: 2.530922950997663
Validation loss: 2.7002576939364293

Epoch: 5| Step: 4
Training loss: 3.144590540735674
Validation loss: 2.7040381292022606

Epoch: 5| Step: 5
Training loss: 2.570861572242429
Validation loss: 2.683412822250984

Epoch: 5| Step: 6
Training loss: 3.530365419574515
Validation loss: 2.6919008810729883

Epoch: 5| Step: 7
Training loss: 2.9637302725274948
Validation loss: 2.680244483823679

Epoch: 5| Step: 8
Training loss: 2.9085869366127723
Validation loss: 2.675876863808917

Epoch: 5| Step: 9
Training loss: 3.303880814016683
Validation loss: 2.6654338031262372

Epoch: 5| Step: 10
Training loss: 2.898176731604673
Validation loss: 2.6669929113195696

Epoch: 95| Step: 0
Training loss: 3.297462881022498
Validation loss: 2.6679622639437732

Epoch: 5| Step: 1
Training loss: 2.375153988313323
Validation loss: 2.667501152379619

Epoch: 5| Step: 2
Training loss: 3.6804518503097863
Validation loss: 2.6730728098308223

Epoch: 5| Step: 3
Training loss: 3.3041753710278945
Validation loss: 2.677138746021758

Epoch: 5| Step: 4
Training loss: 2.8797697224213614
Validation loss: 2.675453803489135

Epoch: 5| Step: 5
Training loss: 3.2040959073022326
Validation loss: 2.678013331004361

Epoch: 5| Step: 6
Training loss: 3.3364390369198293
Validation loss: 2.6727026517630743

Epoch: 5| Step: 7
Training loss: 3.155809126174257
Validation loss: 2.67161968061712

Epoch: 5| Step: 8
Training loss: 2.229901082877109
Validation loss: 2.6720968865669628

Epoch: 5| Step: 9
Training loss: 2.915509966413734
Validation loss: 2.669064622902847

Epoch: 5| Step: 10
Training loss: 2.331903859913063
Validation loss: 2.6688307132433424

Epoch: 96| Step: 0
Training loss: 3.049124645253933
Validation loss: 2.6647227133837323

Epoch: 5| Step: 1
Training loss: 3.1490544550025312
Validation loss: 2.671742614755538

Epoch: 5| Step: 2
Training loss: 3.2754800109858957
Validation loss: 2.6760242308422386

Epoch: 5| Step: 3
Training loss: 3.01984359487779
Validation loss: 2.6868657982849022

Epoch: 5| Step: 4
Training loss: 2.7967124337629543
Validation loss: 2.70314230822356

Epoch: 5| Step: 5
Training loss: 2.5884531928331325
Validation loss: 2.690140074430598

Epoch: 5| Step: 6
Training loss: 2.938839383861136
Validation loss: 2.679307312538984

Epoch: 5| Step: 7
Training loss: 3.6624501143563615
Validation loss: 2.667813075493531

Epoch: 5| Step: 8
Training loss: 3.1143902534847774
Validation loss: 2.6664572609184503

Epoch: 5| Step: 9
Training loss: 2.5733598541052713
Validation loss: 2.667883433558212

Epoch: 5| Step: 10
Training loss: 2.6560766724527194
Validation loss: 2.665623527805065

Epoch: 97| Step: 0
Training loss: 2.939483622142459
Validation loss: 2.673061080485611

Epoch: 5| Step: 1
Training loss: 2.751518003936876
Validation loss: 2.67222352781035

Epoch: 5| Step: 2
Training loss: 3.0442418384503687
Validation loss: 2.6661966996706834

Epoch: 5| Step: 3
Training loss: 2.9565980863591683
Validation loss: 2.6715275101273734

Epoch: 5| Step: 4
Training loss: 2.8045319325435996
Validation loss: 2.672400038625596

Epoch: 5| Step: 5
Training loss: 3.500452693545996
Validation loss: 2.6757780758442418

Epoch: 5| Step: 6
Training loss: 2.956041621471371
Validation loss: 2.6817448897517253

Epoch: 5| Step: 7
Training loss: 3.08235273147089
Validation loss: 2.6864370899373413

Epoch: 5| Step: 8
Training loss: 3.009538110925542
Validation loss: 2.6962876077705036

Epoch: 5| Step: 9
Training loss: 3.3722541376733717
Validation loss: 2.6859634205838088

Epoch: 5| Step: 10
Training loss: 2.4995673758973553
Validation loss: 2.6759987909378142

Epoch: 98| Step: 0
Training loss: 3.0514804561463547
Validation loss: 2.6752955086311863

Epoch: 5| Step: 1
Training loss: 2.7551699505291554
Validation loss: 2.674942014094677

Epoch: 5| Step: 2
Training loss: 3.233028555463421
Validation loss: 2.6696041454721344

Epoch: 5| Step: 3
Training loss: 2.628037466435323
Validation loss: 2.6742997008882243

Epoch: 5| Step: 4
Training loss: 3.479606341754639
Validation loss: 2.668338944112674

Epoch: 5| Step: 5
Training loss: 3.403179359527322
Validation loss: 2.6618514392655497

Epoch: 5| Step: 6
Training loss: 2.7167013934515585
Validation loss: 2.6613213516494763

Epoch: 5| Step: 7
Training loss: 2.649440699161161
Validation loss: 2.6606335020527467

Epoch: 5| Step: 8
Training loss: 3.2615381978938713
Validation loss: 2.663766749939005

Epoch: 5| Step: 9
Training loss: 2.8222390988697192
Validation loss: 2.663315297225781

Epoch: 5| Step: 10
Training loss: 2.793460573228505
Validation loss: 2.6709654058002137

Epoch: 99| Step: 0
Training loss: 3.2856759874706323
Validation loss: 2.6677415748927564

Epoch: 5| Step: 1
Training loss: 2.776959828642211
Validation loss: 2.667139244761639

Epoch: 5| Step: 2
Training loss: 2.6685382910917634
Validation loss: 2.6632948799698863

Epoch: 5| Step: 3
Training loss: 2.9712375859830527
Validation loss: 2.6661045532468086

Epoch: 5| Step: 4
Training loss: 3.4718696381315484
Validation loss: 2.6599610986069355

Epoch: 5| Step: 5
Training loss: 2.8830051926305758
Validation loss: 2.6636096960592712

Epoch: 5| Step: 6
Training loss: 3.282822876831678
Validation loss: 2.6607030103318694

Epoch: 5| Step: 7
Training loss: 3.0489951557785293
Validation loss: 2.657567815323139

Epoch: 5| Step: 8
Training loss: 3.0460682901402985
Validation loss: 2.6609957617136164

Epoch: 5| Step: 9
Training loss: 2.627679819329242
Validation loss: 2.6599703779490276

Epoch: 5| Step: 10
Training loss: 2.6723905367152265
Validation loss: 2.6609432984857486

Epoch: 100| Step: 0
Training loss: 3.1641477973649295
Validation loss: 2.6607307528193656

Epoch: 5| Step: 1
Training loss: 3.2432871229193285
Validation loss: 2.6626886228094406

Epoch: 5| Step: 2
Training loss: 2.6317746978032823
Validation loss: 2.668470992880124

Epoch: 5| Step: 3
Training loss: 2.326604461803895
Validation loss: 2.66161529487228

Epoch: 5| Step: 4
Training loss: 2.522520672323096
Validation loss: 2.6619138409526837

Epoch: 5| Step: 5
Training loss: 2.582560567228684
Validation loss: 2.6682926656916925

Epoch: 5| Step: 6
Training loss: 2.933614555518765
Validation loss: 2.6732331149944892

Epoch: 5| Step: 7
Training loss: 2.8576014286973206
Validation loss: 2.6652915264840784

Epoch: 5| Step: 8
Training loss: 3.109296174703588
Validation loss: 2.670876257377779

Epoch: 5| Step: 9
Training loss: 3.0374054693889048
Validation loss: 2.659888982134614

Epoch: 5| Step: 10
Training loss: 4.255723577313723
Validation loss: 2.6519954477531975

Epoch: 101| Step: 0
Training loss: 2.9399497997124207
Validation loss: 2.6460800198008823

Epoch: 5| Step: 1
Training loss: 2.537246947049597
Validation loss: 2.647083387016944

Epoch: 5| Step: 2
Training loss: 3.328142622780147
Validation loss: 2.64948934608183

Epoch: 5| Step: 3
Training loss: 2.908170496217648
Validation loss: 2.64861793349917

Epoch: 5| Step: 4
Training loss: 2.861472272659602
Validation loss: 2.647729002871058

Epoch: 5| Step: 5
Training loss: 3.0437195699999666
Validation loss: 2.651066989553307

Epoch: 5| Step: 6
Training loss: 3.0314258642404144
Validation loss: 2.6480154231783186

Epoch: 5| Step: 7
Training loss: 2.2772204200497805
Validation loss: 2.6523003125859907

Epoch: 5| Step: 8
Training loss: 3.4142893141905963
Validation loss: 2.651414794953743

Epoch: 5| Step: 9
Training loss: 3.1648789094296386
Validation loss: 2.6453876858056518

Epoch: 5| Step: 10
Training loss: 3.2489917364887178
Validation loss: 2.645919580065624

Epoch: 102| Step: 0
Training loss: 2.7726146928129496
Validation loss: 2.647837981030566

Epoch: 5| Step: 1
Training loss: 2.934390755998035
Validation loss: 2.64432101008439

Epoch: 5| Step: 2
Training loss: 3.2834307009077524
Validation loss: 2.645268386149209

Epoch: 5| Step: 3
Training loss: 2.948641972004221
Validation loss: 2.649588893114644

Epoch: 5| Step: 4
Training loss: 2.4302561790529813
Validation loss: 2.642103661383451

Epoch: 5| Step: 5
Training loss: 3.336949358031435
Validation loss: 2.6422870878536795

Epoch: 5| Step: 6
Training loss: 2.772200187522486
Validation loss: 2.6444292503677147

Epoch: 5| Step: 7
Training loss: 3.544195700845758
Validation loss: 2.6451017795816982

Epoch: 5| Step: 8
Training loss: 3.041104373604633
Validation loss: 2.6453857912178513

Epoch: 5| Step: 9
Training loss: 2.973983969413687
Validation loss: 2.648679788439954

Epoch: 5| Step: 10
Training loss: 2.607341590816902
Validation loss: 2.6551797543276314

Epoch: 103| Step: 0
Training loss: 2.4607921739084238
Validation loss: 2.6679226208253994

Epoch: 5| Step: 1
Training loss: 3.300598934036709
Validation loss: 2.701615624815945

Epoch: 5| Step: 2
Training loss: 3.17798255743734
Validation loss: 2.701933404249977

Epoch: 5| Step: 3
Training loss: 3.0996569105227856
Validation loss: 2.7018175995892144

Epoch: 5| Step: 4
Training loss: 3.0262482266773447
Validation loss: 2.69630896654357

Epoch: 5| Step: 5
Training loss: 3.1275813313375016
Validation loss: 2.6877893882065393

Epoch: 5| Step: 6
Training loss: 3.38292512419874
Validation loss: 2.6582715212234254

Epoch: 5| Step: 7
Training loss: 3.1686246406994094
Validation loss: 2.6483571059134245

Epoch: 5| Step: 8
Training loss: 2.71898851773418
Validation loss: 2.6392473031037453

Epoch: 5| Step: 9
Training loss: 2.678236499009919
Validation loss: 2.646360651620661

Epoch: 5| Step: 10
Training loss: 2.479533245863037
Validation loss: 2.647480176396543

Epoch: 104| Step: 0
Training loss: 3.019702112019812
Validation loss: 2.6476427660213995

Epoch: 5| Step: 1
Training loss: 2.7463157422995974
Validation loss: 2.6472459409700555

Epoch: 5| Step: 2
Training loss: 2.9003917758310007
Validation loss: 2.649447164761931

Epoch: 5| Step: 3
Training loss: 2.7475405879402675
Validation loss: 2.647370590864278

Epoch: 5| Step: 4
Training loss: 2.904456292646869
Validation loss: 2.645236413962145

Epoch: 5| Step: 5
Training loss: 2.956603892397168
Validation loss: 2.6422618567600042

Epoch: 5| Step: 6
Training loss: 2.9804490714967176
Validation loss: 2.6349715554474606

Epoch: 5| Step: 7
Training loss: 3.370593974350693
Validation loss: 2.6399070276773426

Epoch: 5| Step: 8
Training loss: 3.1635315249400553
Validation loss: 2.647656435094091

Epoch: 5| Step: 9
Training loss: 3.0938896378879877
Validation loss: 2.6511919558540393

Epoch: 5| Step: 10
Training loss: 2.925574260973344
Validation loss: 2.674882417796643

Epoch: 105| Step: 0
Training loss: 2.9890513904961313
Validation loss: 2.681271055034526

Epoch: 5| Step: 1
Training loss: 2.919520444291115
Validation loss: 2.695839921693108

Epoch: 5| Step: 2
Training loss: 3.119281419264828
Validation loss: 2.7111928876913636

Epoch: 5| Step: 3
Training loss: 2.7528926201388852
Validation loss: 2.6785851379879686

Epoch: 5| Step: 4
Training loss: 2.5536955327869504
Validation loss: 2.6559489572413804

Epoch: 5| Step: 5
Training loss: 3.010086111820346
Validation loss: 2.6439926382492933

Epoch: 5| Step: 6
Training loss: 3.341196100932673
Validation loss: 2.6380455985221443

Epoch: 5| Step: 7
Training loss: 3.154708788168406
Validation loss: 2.6360215230607063

Epoch: 5| Step: 8
Training loss: 2.699409798293834
Validation loss: 2.640041540492747

Epoch: 5| Step: 9
Training loss: 3.4143722707900555
Validation loss: 2.639456920515454

Epoch: 5| Step: 10
Training loss: 2.781071346417115
Validation loss: 2.636293115629642

Epoch: 106| Step: 0
Training loss: 3.016623850425514
Validation loss: 2.634621690248319

Epoch: 5| Step: 1
Training loss: 2.5667250622468343
Validation loss: 2.633413507241343

Epoch: 5| Step: 2
Training loss: 3.2460258834850473
Validation loss: 2.633528485380796

Epoch: 5| Step: 3
Training loss: 3.108840973201311
Validation loss: 2.6369496311964

Epoch: 5| Step: 4
Training loss: 3.182612393080924
Validation loss: 2.6354700391381867

Epoch: 5| Step: 5
Training loss: 2.864924813926733
Validation loss: 2.637259893273

Epoch: 5| Step: 6
Training loss: 3.2527392654318046
Validation loss: 2.636554988878627

Epoch: 5| Step: 7
Training loss: 2.553112232638575
Validation loss: 2.639541189001331

Epoch: 5| Step: 8
Training loss: 3.388989594705546
Validation loss: 2.6374454971270667

Epoch: 5| Step: 9
Training loss: 2.412132108635279
Validation loss: 2.630043310355208

Epoch: 5| Step: 10
Training loss: 3.026994057424236
Validation loss: 2.633056280744502

Epoch: 107| Step: 0
Training loss: 2.5580648792918175
Validation loss: 2.6318891816028382

Epoch: 5| Step: 1
Training loss: 3.131059036980012
Validation loss: 2.6347084389182007

Epoch: 5| Step: 2
Training loss: 2.490149355166303
Validation loss: 2.641778481253595

Epoch: 5| Step: 3
Training loss: 2.9404090923701696
Validation loss: 2.6377331317540995

Epoch: 5| Step: 4
Training loss: 3.2786362183025632
Validation loss: 2.639948014036175

Epoch: 5| Step: 5
Training loss: 3.2494978883651022
Validation loss: 2.6350357105875246

Epoch: 5| Step: 6
Training loss: 3.04788738939813
Validation loss: 2.6330392381498426

Epoch: 5| Step: 7
Training loss: 2.774063770345036
Validation loss: 2.633850185279968

Epoch: 5| Step: 8
Training loss: 3.1943466853419005
Validation loss: 2.632508556939988

Epoch: 5| Step: 9
Training loss: 2.788990436552604
Validation loss: 2.629162545375878

Epoch: 5| Step: 10
Training loss: 3.185100924151963
Validation loss: 2.6309848002770275

Epoch: 108| Step: 0
Training loss: 3.122326126571955
Validation loss: 2.6317267399344533

Epoch: 5| Step: 1
Training loss: 3.2241890885819124
Validation loss: 2.6330190378977845

Epoch: 5| Step: 2
Training loss: 3.092808127321635
Validation loss: 2.6390170629864333

Epoch: 5| Step: 3
Training loss: 2.6864765791306064
Validation loss: 2.642509747510872

Epoch: 5| Step: 4
Training loss: 3.309555616484043
Validation loss: 2.6410743159757395

Epoch: 5| Step: 5
Training loss: 3.143657074724722
Validation loss: 2.6348201769444115

Epoch: 5| Step: 6
Training loss: 2.558397404948404
Validation loss: 2.6270272181023335

Epoch: 5| Step: 7
Training loss: 2.565507565969144
Validation loss: 2.629004487178427

Epoch: 5| Step: 8
Training loss: 2.7009045074824134
Validation loss: 2.6314878785740325

Epoch: 5| Step: 9
Training loss: 3.1109060227446013
Validation loss: 2.629286452543625

Epoch: 5| Step: 10
Training loss: 3.1996236877903685
Validation loss: 2.635957345230665

Epoch: 109| Step: 0
Training loss: 2.955678491816196
Validation loss: 2.6329557907407737

Epoch: 5| Step: 1
Training loss: 3.1917210473855215
Validation loss: 2.6322762704060194

Epoch: 5| Step: 2
Training loss: 3.203386696150379
Validation loss: 2.6291157343516445

Epoch: 5| Step: 3
Training loss: 3.0953311155126273
Validation loss: 2.6286139956053516

Epoch: 5| Step: 4
Training loss: 3.214240609715389
Validation loss: 2.630169148835023

Epoch: 5| Step: 5
Training loss: 2.8946804981132592
Validation loss: 2.6215081123415436

Epoch: 5| Step: 6
Training loss: 2.8293985270875943
Validation loss: 2.625358276801637

Epoch: 5| Step: 7
Training loss: 2.6465162662400443
Validation loss: 2.6275198191069773

Epoch: 5| Step: 8
Training loss: 2.180259383457962
Validation loss: 2.6409618097111607

Epoch: 5| Step: 9
Training loss: 3.1131705117244706
Validation loss: 2.6566728741498706

Epoch: 5| Step: 10
Training loss: 3.246871616336062
Validation loss: 2.665792195569466

Epoch: 110| Step: 0
Training loss: 3.029291837922956
Validation loss: 2.659282285917496

Epoch: 5| Step: 1
Training loss: 3.013716810463763
Validation loss: 2.6574658848460246

Epoch: 5| Step: 2
Training loss: 3.528214221566162
Validation loss: 2.6557550556704173

Epoch: 5| Step: 3
Training loss: 3.0650851179690766
Validation loss: 2.651315182556721

Epoch: 5| Step: 4
Training loss: 3.101940679675324
Validation loss: 2.642974441323976

Epoch: 5| Step: 5
Training loss: 3.2338837328826053
Validation loss: 2.6247674377053505

Epoch: 5| Step: 6
Training loss: 2.327393589721831
Validation loss: 2.620262845541074

Epoch: 5| Step: 7
Training loss: 2.8955731903980855
Validation loss: 2.6219324548019465

Epoch: 5| Step: 8
Training loss: 2.557934671792118
Validation loss: 2.6238342026653174

Epoch: 5| Step: 9
Training loss: 2.902849895143204
Validation loss: 2.625956453382214

Epoch: 5| Step: 10
Training loss: 2.843569739361049
Validation loss: 2.627464119392317

Epoch: 111| Step: 0
Training loss: 3.2226901335813407
Validation loss: 2.6244496609981476

Epoch: 5| Step: 1
Training loss: 3.1254682571539663
Validation loss: 2.6257827322314573

Epoch: 5| Step: 2
Training loss: 2.848086226540305
Validation loss: 2.6319560943953775

Epoch: 5| Step: 3
Training loss: 2.92778323529109
Validation loss: 2.632484649073391

Epoch: 5| Step: 4
Training loss: 2.4210188798384915
Validation loss: 2.628865249470825

Epoch: 5| Step: 5
Training loss: 2.277622421776533
Validation loss: 2.640545794270016

Epoch: 5| Step: 6
Training loss: 2.8182378096346046
Validation loss: 2.633227130944095

Epoch: 5| Step: 7
Training loss: 3.3636053374450556
Validation loss: 2.6372221061163486

Epoch: 5| Step: 8
Training loss: 3.0424589579689143
Validation loss: 2.632388863022848

Epoch: 5| Step: 9
Training loss: 3.4732189087376417
Validation loss: 2.6290647304775945

Epoch: 5| Step: 10
Training loss: 2.8505026323901514
Validation loss: 2.6271931529561448

Epoch: 112| Step: 0
Training loss: 2.834759932753173
Validation loss: 2.623611884005718

Epoch: 5| Step: 1
Training loss: 2.5907700667126403
Validation loss: 2.6285090941013283

Epoch: 5| Step: 2
Training loss: 3.164667217724162
Validation loss: 2.6276877248391397

Epoch: 5| Step: 3
Training loss: 3.2463731335659594
Validation loss: 2.638245107866516

Epoch: 5| Step: 4
Training loss: 3.1450563359635195
Validation loss: 2.6327243450707525

Epoch: 5| Step: 5
Training loss: 3.043682440726659
Validation loss: 2.6284503430218087

Epoch: 5| Step: 6
Training loss: 3.143612328125632
Validation loss: 2.6346066331003803

Epoch: 5| Step: 7
Training loss: 3.034559507879249
Validation loss: 2.625241682076983

Epoch: 5| Step: 8
Training loss: 2.7119370961953937
Validation loss: 2.6232801488239565

Epoch: 5| Step: 9
Training loss: 2.5246965320386408
Validation loss: 2.6246531775494963

Epoch: 5| Step: 10
Training loss: 3.048112979667323
Validation loss: 2.6227589664258044

Epoch: 113| Step: 0
Training loss: 3.2274127421857357
Validation loss: 2.6225388900085043

Epoch: 5| Step: 1
Training loss: 2.163467490685255
Validation loss: 2.6174754121992456

Epoch: 5| Step: 2
Training loss: 3.359456048032132
Validation loss: 2.6162431585686723

Epoch: 5| Step: 3
Training loss: 3.054230404579493
Validation loss: 2.6220573137308327

Epoch: 5| Step: 4
Training loss: 2.2840381462666235
Validation loss: 2.6224846779284703

Epoch: 5| Step: 5
Training loss: 2.642577583668182
Validation loss: 2.618350431045536

Epoch: 5| Step: 6
Training loss: 3.034308709187542
Validation loss: 2.62358888980594

Epoch: 5| Step: 7
Training loss: 3.1531949507153527
Validation loss: 2.622574071491591

Epoch: 5| Step: 8
Training loss: 3.1675162597816993
Validation loss: 2.6355552054888616

Epoch: 5| Step: 9
Training loss: 2.8706974508593057
Validation loss: 2.6379982517384075

Epoch: 5| Step: 10
Training loss: 3.4424606595807643
Validation loss: 2.659269527850504

Epoch: 114| Step: 0
Training loss: 2.6924912877415608
Validation loss: 2.6186200186912805

Epoch: 5| Step: 1
Training loss: 2.9541895325228174
Validation loss: 2.6162860197553814

Epoch: 5| Step: 2
Training loss: 2.955096520204642
Validation loss: 2.6178425130381906

Epoch: 5| Step: 3
Training loss: 3.0599898346875456
Validation loss: 2.6164659171780262

Epoch: 5| Step: 4
Training loss: 2.783711576363625
Validation loss: 2.6220149722010793

Epoch: 5| Step: 5
Training loss: 3.052884010947969
Validation loss: 2.6258020489261646

Epoch: 5| Step: 6
Training loss: 2.7389420216814235
Validation loss: 2.627421938661748

Epoch: 5| Step: 7
Training loss: 3.087740986797677
Validation loss: 2.6151629220088366

Epoch: 5| Step: 8
Training loss: 3.1153920292200046
Validation loss: 2.6185874724652884

Epoch: 5| Step: 9
Training loss: 3.1058490640255365
Validation loss: 2.6176851943285184

Epoch: 5| Step: 10
Training loss: 3.1071448835043727
Validation loss: 2.612004941868075

Epoch: 115| Step: 0
Training loss: 2.9153827202684126
Validation loss: 2.6160248408640117

Epoch: 5| Step: 1
Training loss: 2.9894659748147654
Validation loss: 2.613562908678179

Epoch: 5| Step: 2
Training loss: 2.731076850902121
Validation loss: 2.6163852383420902

Epoch: 5| Step: 3
Training loss: 2.5699055358209595
Validation loss: 2.6127002227782468

Epoch: 5| Step: 4
Training loss: 3.332522929542681
Validation loss: 2.617486626677998

Epoch: 5| Step: 5
Training loss: 3.2256805470722383
Validation loss: 2.631709490006311

Epoch: 5| Step: 6
Training loss: 3.5677161594871203
Validation loss: 2.628705834382208

Epoch: 5| Step: 7
Training loss: 3.100907340625328
Validation loss: 2.6421498056717456

Epoch: 5| Step: 8
Training loss: 2.863704551226238
Validation loss: 2.64802329702154

Epoch: 5| Step: 9
Training loss: 2.6681946509414374
Validation loss: 2.6357115042721024

Epoch: 5| Step: 10
Training loss: 2.4008354600470816
Validation loss: 2.6177879089263514

Epoch: 116| Step: 0
Training loss: 3.0287133053813213
Validation loss: 2.607711209487799

Epoch: 5| Step: 1
Training loss: 2.4072286423989495
Validation loss: 2.6043043813080446

Epoch: 5| Step: 2
Training loss: 3.042079967132393
Validation loss: 2.6065943300480403

Epoch: 5| Step: 3
Training loss: 3.038520038899601
Validation loss: 2.609080827054489

Epoch: 5| Step: 4
Training loss: 2.7183397356242884
Validation loss: 2.610687576128426

Epoch: 5| Step: 5
Training loss: 3.3678295116449757
Validation loss: 2.6083714731208767

Epoch: 5| Step: 6
Training loss: 2.8121848035728023
Validation loss: 2.60657417958897

Epoch: 5| Step: 7
Training loss: 2.826188072258354
Validation loss: 2.6053898383012073

Epoch: 5| Step: 8
Training loss: 2.7969518896008383
Validation loss: 2.607392004939707

Epoch: 5| Step: 9
Training loss: 3.0936948212606112
Validation loss: 2.604973579335582

Epoch: 5| Step: 10
Training loss: 3.429462399405771
Validation loss: 2.608952901329318

Epoch: 117| Step: 0
Training loss: 2.9397076366663923
Validation loss: 2.6219125454222385

Epoch: 5| Step: 1
Training loss: 3.1636998851820595
Validation loss: 2.632712182785112

Epoch: 5| Step: 2
Training loss: 2.780857444234168
Validation loss: 2.642539663001342

Epoch: 5| Step: 3
Training loss: 3.232894189907806
Validation loss: 2.6407658310716036

Epoch: 5| Step: 4
Training loss: 3.5688815598698294
Validation loss: 2.6309874126513484

Epoch: 5| Step: 5
Training loss: 2.899036438127725
Validation loss: 2.6166024080716332

Epoch: 5| Step: 6
Training loss: 2.484065390434124
Validation loss: 2.6170741862838707

Epoch: 5| Step: 7
Training loss: 2.777015977878781
Validation loss: 2.6170415081800793

Epoch: 5| Step: 8
Training loss: 2.8340663148797756
Validation loss: 2.6174209140455664

Epoch: 5| Step: 9
Training loss: 3.036208982791306
Validation loss: 2.6200285124618707

Epoch: 5| Step: 10
Training loss: 2.7201523945695794
Validation loss: 2.6148940377587913

Epoch: 118| Step: 0
Training loss: 3.413042348165861
Validation loss: 2.612405486118673

Epoch: 5| Step: 1
Training loss: 2.7989664622563697
Validation loss: 2.6100813339687043

Epoch: 5| Step: 2
Training loss: 2.8527667285474507
Validation loss: 2.602332384124679

Epoch: 5| Step: 3
Training loss: 3.112162351869602
Validation loss: 2.6064910691013754

Epoch: 5| Step: 4
Training loss: 2.9717701858344547
Validation loss: 2.607359807227173

Epoch: 5| Step: 5
Training loss: 2.668760749026948
Validation loss: 2.604525374451911

Epoch: 5| Step: 6
Training loss: 2.778535010652182
Validation loss: 2.611213739192533

Epoch: 5| Step: 7
Training loss: 3.0256489396561657
Validation loss: 2.608462480591703

Epoch: 5| Step: 8
Training loss: 2.700765826087719
Validation loss: 2.6085933845677816

Epoch: 5| Step: 9
Training loss: 3.0226234306078017
Validation loss: 2.6123187161639065

Epoch: 5| Step: 10
Training loss: 3.1462061242191712
Validation loss: 2.6133973453783983

Epoch: 119| Step: 0
Training loss: 2.226671503979269
Validation loss: 2.6127851393500645

Epoch: 5| Step: 1
Training loss: 2.97887917222933
Validation loss: 2.6125549467635634

Epoch: 5| Step: 2
Training loss: 3.37393581425657
Validation loss: 2.6196798575009708

Epoch: 5| Step: 3
Training loss: 3.463936705277529
Validation loss: 2.625523102454466

Epoch: 5| Step: 4
Training loss: 3.1456850197968667
Validation loss: 2.622300535982637

Epoch: 5| Step: 5
Training loss: 2.679402060918207
Validation loss: 2.6310017918693163

Epoch: 5| Step: 6
Training loss: 3.230567497026527
Validation loss: 2.6376034193277476

Epoch: 5| Step: 7
Training loss: 2.588020799349849
Validation loss: 2.6314749721135073

Epoch: 5| Step: 8
Training loss: 2.999473525581458
Validation loss: 2.6182193598415324

Epoch: 5| Step: 9
Training loss: 3.0175558441228394
Validation loss: 2.6051014003228965

Epoch: 5| Step: 10
Training loss: 2.522653747349428
Validation loss: 2.604348159536325

Epoch: 120| Step: 0
Training loss: 2.8390218812664285
Validation loss: 2.6015188552302977

Epoch: 5| Step: 1
Training loss: 3.2866860546084435
Validation loss: 2.6011846947294055

Epoch: 5| Step: 2
Training loss: 2.841953758287704
Validation loss: 2.6027989352481353

Epoch: 5| Step: 3
Training loss: 2.921755538375069
Validation loss: 2.601906593017853

Epoch: 5| Step: 4
Training loss: 2.6553344944019095
Validation loss: 2.600473064655558

Epoch: 5| Step: 5
Training loss: 2.776209431935394
Validation loss: 2.6079751786048218

Epoch: 5| Step: 6
Training loss: 2.6148978622941876
Validation loss: 2.6034009225218404

Epoch: 5| Step: 7
Training loss: 2.4041391998079527
Validation loss: 2.6144519765230627

Epoch: 5| Step: 8
Training loss: 3.3010766613831635
Validation loss: 2.6232933272132914

Epoch: 5| Step: 9
Training loss: 3.2703424721195073
Validation loss: 2.6129502243859886

Epoch: 5| Step: 10
Training loss: 3.4524720554201496
Validation loss: 2.612997333840258

Epoch: 121| Step: 0
Training loss: 2.451392272524229
Validation loss: 2.6087930791985374

Epoch: 5| Step: 1
Training loss: 2.838759518350814
Validation loss: 2.617800259046726

Epoch: 5| Step: 2
Training loss: 2.921176602539651
Validation loss: 2.6076916029611885

Epoch: 5| Step: 3
Training loss: 3.104019844286693
Validation loss: 2.607972494520857

Epoch: 5| Step: 4
Training loss: 3.3373698748534886
Validation loss: 2.598750849645463

Epoch: 5| Step: 5
Training loss: 3.361313938995341
Validation loss: 2.5995826498238994

Epoch: 5| Step: 6
Training loss: 2.6975069262651643
Validation loss: 2.593986967914854

Epoch: 5| Step: 7
Training loss: 3.10525515799466
Validation loss: 2.5933851382526982

Epoch: 5| Step: 8
Training loss: 2.6724262226651607
Validation loss: 2.590197201982089

Epoch: 5| Step: 9
Training loss: 2.9427106379047023
Validation loss: 2.5926175591377913

Epoch: 5| Step: 10
Training loss: 2.877395792647648
Validation loss: 2.5966669496283385

Epoch: 122| Step: 0
Training loss: 3.3708357375191005
Validation loss: 2.5899777815522977

Epoch: 5| Step: 1
Training loss: 2.9598889268191204
Validation loss: 2.5933124199317734

Epoch: 5| Step: 2
Training loss: 3.007703427405462
Validation loss: 2.5912724698606886

Epoch: 5| Step: 3
Training loss: 3.1256964861058396
Validation loss: 2.5906617585830354

Epoch: 5| Step: 4
Training loss: 2.9351204507211794
Validation loss: 2.5933896676960737

Epoch: 5| Step: 5
Training loss: 3.034478424855429
Validation loss: 2.5994102510428134

Epoch: 5| Step: 6
Training loss: 2.7464509951381015
Validation loss: 2.5949050737122685

Epoch: 5| Step: 7
Training loss: 2.7686362387404815
Validation loss: 2.6016843284947675

Epoch: 5| Step: 8
Training loss: 3.01694929860837
Validation loss: 2.6028237747176046

Epoch: 5| Step: 9
Training loss: 2.5334261734999712
Validation loss: 2.603735138281898

Epoch: 5| Step: 10
Training loss: 2.796921372695175
Validation loss: 2.608811888842313

Epoch: 123| Step: 0
Training loss: 2.7347056161731387
Validation loss: 2.606187902508376

Epoch: 5| Step: 1
Training loss: 3.3464336143394005
Validation loss: 2.601974862096434

Epoch: 5| Step: 2
Training loss: 3.3105536446741257
Validation loss: 2.61380223898118

Epoch: 5| Step: 3
Training loss: 2.6968186745005243
Validation loss: 2.6045357509473788

Epoch: 5| Step: 4
Training loss: 2.47306321397348
Validation loss: 2.599125650185467

Epoch: 5| Step: 5
Training loss: 2.81333588788367
Validation loss: 2.6028957683433473

Epoch: 5| Step: 6
Training loss: 3.132274096259636
Validation loss: 2.596207329521371

Epoch: 5| Step: 7
Training loss: 2.8983251339089176
Validation loss: 2.592158224859825

Epoch: 5| Step: 8
Training loss: 2.9789632091984304
Validation loss: 2.5953463452833994

Epoch: 5| Step: 9
Training loss: 2.701487315219976
Validation loss: 2.5891260620706062

Epoch: 5| Step: 10
Training loss: 3.23035553407452
Validation loss: 2.5945541928077382

Epoch: 124| Step: 0
Training loss: 3.282927311483291
Validation loss: 2.5917271617071016

Epoch: 5| Step: 1
Training loss: 2.6886556048207866
Validation loss: 2.589722270767861

Epoch: 5| Step: 2
Training loss: 3.172634390892131
Validation loss: 2.5926447279042693

Epoch: 5| Step: 3
Training loss: 2.0268324719959847
Validation loss: 2.5954286609268644

Epoch: 5| Step: 4
Training loss: 3.3727970704491215
Validation loss: 2.59817556784237

Epoch: 5| Step: 5
Training loss: 3.1418583663885618
Validation loss: 2.594062633133743

Epoch: 5| Step: 6
Training loss: 2.447086166292726
Validation loss: 2.6092745343009334

Epoch: 5| Step: 7
Training loss: 3.6177461328718437
Validation loss: 2.602711273734178

Epoch: 5| Step: 8
Training loss: 1.9145691493037853
Validation loss: 2.6232142060424266

Epoch: 5| Step: 9
Training loss: 3.113356758073117
Validation loss: 2.631973656347321

Epoch: 5| Step: 10
Training loss: 3.1529667462048088
Validation loss: 2.6298372182101506

Epoch: 125| Step: 0
Training loss: 1.9556768607617343
Validation loss: 2.6121483562752883

Epoch: 5| Step: 1
Training loss: 2.639608514831748
Validation loss: 2.6177739712690915

Epoch: 5| Step: 2
Training loss: 2.989852113415514
Validation loss: 2.6065324137061365

Epoch: 5| Step: 3
Training loss: 3.228087427413619
Validation loss: 2.6037454558970032

Epoch: 5| Step: 4
Training loss: 3.078015165741499
Validation loss: 2.59015596977197

Epoch: 5| Step: 5
Training loss: 2.973019070232778
Validation loss: 2.5855144941291623

Epoch: 5| Step: 6
Training loss: 3.060120884620608
Validation loss: 2.5913182648568407

Epoch: 5| Step: 7
Training loss: 3.0940463762216703
Validation loss: 2.5905653053983455

Epoch: 5| Step: 8
Training loss: 3.0973985523917325
Validation loss: 2.58890196108761

Epoch: 5| Step: 9
Training loss: 3.2460558506925645
Validation loss: 2.590015671020995

Epoch: 5| Step: 10
Training loss: 2.7934732901745636
Validation loss: 2.5883685635328817

Epoch: 126| Step: 0
Training loss: 3.284130902570311
Validation loss: 2.589726695745775

Epoch: 5| Step: 1
Training loss: 2.925415179139008
Validation loss: 2.587356729629442

Epoch: 5| Step: 2
Training loss: 2.926097083775034
Validation loss: 2.5877355957650523

Epoch: 5| Step: 3
Training loss: 3.5426056159514707
Validation loss: 2.5868666148040105

Epoch: 5| Step: 4
Training loss: 2.7306345615058034
Validation loss: 2.5870039503973667

Epoch: 5| Step: 5
Training loss: 3.015442521498937
Validation loss: 2.59114732763394

Epoch: 5| Step: 6
Training loss: 2.7144695216161407
Validation loss: 2.587547186647687

Epoch: 5| Step: 7
Training loss: 2.332951503120428
Validation loss: 2.5922450238502663

Epoch: 5| Step: 8
Training loss: 2.415911611354893
Validation loss: 2.5970608795278776

Epoch: 5| Step: 9
Training loss: 3.0544770697580517
Validation loss: 2.6108876417942373

Epoch: 5| Step: 10
Training loss: 3.2520397827699252
Validation loss: 2.633412750341268

Epoch: 127| Step: 0
Training loss: 3.362706577237623
Validation loss: 2.6268155313640564

Epoch: 5| Step: 1
Training loss: 2.685237375631579
Validation loss: 2.649803118087528

Epoch: 5| Step: 2
Training loss: 3.486759071535774
Validation loss: 2.6675774204061966

Epoch: 5| Step: 3
Training loss: 2.968402239859851
Validation loss: 2.6603583542390483

Epoch: 5| Step: 4
Training loss: 2.425946560201123
Validation loss: 2.655406593612112

Epoch: 5| Step: 5
Training loss: 2.753694739910648
Validation loss: 2.659894252269271

Epoch: 5| Step: 6
Training loss: 3.3048916656698393
Validation loss: 2.667721789245872

Epoch: 5| Step: 7
Training loss: 2.5612968783838297
Validation loss: 2.6128254944331686

Epoch: 5| Step: 8
Training loss: 3.1777016626888788
Validation loss: 2.5887645791261096

Epoch: 5| Step: 9
Training loss: 2.7910921634886745
Validation loss: 2.587606144176937

Epoch: 5| Step: 10
Training loss: 2.616265980197385
Validation loss: 2.5858632080660504

Epoch: 128| Step: 0
Training loss: 2.8540309307558207
Validation loss: 2.5914296320926615

Epoch: 5| Step: 1
Training loss: 2.706525482886529
Validation loss: 2.591712342024544

Epoch: 5| Step: 2
Training loss: 3.3383627301536025
Validation loss: 2.5998326033129917

Epoch: 5| Step: 3
Training loss: 2.6540952132910753
Validation loss: 2.601276756843185

Epoch: 5| Step: 4
Training loss: 3.335297212639837
Validation loss: 2.5960746357361177

Epoch: 5| Step: 5
Training loss: 3.2618215213506083
Validation loss: 2.5936214426528728

Epoch: 5| Step: 6
Training loss: 2.9664783017940057
Validation loss: 2.5934806196567606

Epoch: 5| Step: 7
Training loss: 2.864785833426109
Validation loss: 2.5923401220076756

Epoch: 5| Step: 8
Training loss: 2.8216390686427997
Validation loss: 2.5889346576967833

Epoch: 5| Step: 9
Training loss: 2.591902385021516
Validation loss: 2.5979471950913364

Epoch: 5| Step: 10
Training loss: 3.025985708501717
Validation loss: 2.6042459681752295

Epoch: 129| Step: 0
Training loss: 2.786627724510794
Validation loss: 2.605555611307724

Epoch: 5| Step: 1
Training loss: 2.9981454839239268
Validation loss: 2.6091364131948716

Epoch: 5| Step: 2
Training loss: 3.3065546771538217
Validation loss: 2.615221990216139

Epoch: 5| Step: 3
Training loss: 2.753145846094195
Validation loss: 2.626572309458388

Epoch: 5| Step: 4
Training loss: 3.053235111183716
Validation loss: 2.6205280977875365

Epoch: 5| Step: 5
Training loss: 2.777972744351423
Validation loss: 2.6259727521473857

Epoch: 5| Step: 6
Training loss: 2.528528799431971
Validation loss: 2.6015927404983845

Epoch: 5| Step: 7
Training loss: 2.9452365693441087
Validation loss: 2.5919746266074783

Epoch: 5| Step: 8
Training loss: 2.8639060219631367
Validation loss: 2.5946465474890057

Epoch: 5| Step: 9
Training loss: 3.070819531379094
Validation loss: 2.5943830043611253

Epoch: 5| Step: 10
Training loss: 3.1772951316068387
Validation loss: 2.586193726703745

Epoch: 130| Step: 0
Training loss: 2.614081335826443
Validation loss: 2.5804686224770763

Epoch: 5| Step: 1
Training loss: 2.8459078807384848
Validation loss: 2.580295803055574

Epoch: 5| Step: 2
Training loss: 3.310548603428752
Validation loss: 2.5791682822550945

Epoch: 5| Step: 3
Training loss: 3.0258536529349023
Validation loss: 2.575922354529053

Epoch: 5| Step: 4
Training loss: 3.11119172203746
Validation loss: 2.5730308632585883

Epoch: 5| Step: 5
Training loss: 2.6029196741794998
Validation loss: 2.5752416791001287

Epoch: 5| Step: 6
Training loss: 2.7098781483694077
Validation loss: 2.5747450742485847

Epoch: 5| Step: 7
Training loss: 2.608745019210645
Validation loss: 2.5729639913281828

Epoch: 5| Step: 8
Training loss: 3.084108993979163
Validation loss: 2.5795631531615375

Epoch: 5| Step: 9
Training loss: 3.2781136191636926
Validation loss: 2.587931921039894

Epoch: 5| Step: 10
Training loss: 2.972634274054364
Validation loss: 2.5851871264403994

Epoch: 131| Step: 0
Training loss: 3.6229709339665837
Validation loss: 2.592636417907069

Epoch: 5| Step: 1
Training loss: 2.6722866878897835
Validation loss: 2.5903476431587635

Epoch: 5| Step: 2
Training loss: 2.2876136543097214
Validation loss: 2.572211087901903

Epoch: 5| Step: 3
Training loss: 3.1250805653677256
Validation loss: 2.576552519128507

Epoch: 5| Step: 4
Training loss: 3.0916233652652143
Validation loss: 2.576455915854843

Epoch: 5| Step: 5
Training loss: 2.311762821129366
Validation loss: 2.576456936253808

Epoch: 5| Step: 6
Training loss: 3.2514208108807927
Validation loss: 2.58142294359613

Epoch: 5| Step: 7
Training loss: 2.748346698729259
Validation loss: 2.577132801836505

Epoch: 5| Step: 8
Training loss: 2.882170980555669
Validation loss: 2.5725315555234136

Epoch: 5| Step: 9
Training loss: 2.8307888910239196
Validation loss: 2.5870055859911316

Epoch: 5| Step: 10
Training loss: 3.2340841116456343
Validation loss: 2.6088545085307078

Epoch: 132| Step: 0
Training loss: 3.436356232833777
Validation loss: 2.585349593811647

Epoch: 5| Step: 1
Training loss: 3.447397444584853
Validation loss: 2.5768225100905884

Epoch: 5| Step: 2
Training loss: 2.2147828216514864
Validation loss: 2.5788896865363267

Epoch: 5| Step: 3
Training loss: 2.674411038599218
Validation loss: 2.5745520172082057

Epoch: 5| Step: 4
Training loss: 3.093780671555268
Validation loss: 2.5722393582360765

Epoch: 5| Step: 5
Training loss: 3.1568699596110275
Validation loss: 2.573595766863308

Epoch: 5| Step: 6
Training loss: 2.8535436985272007
Validation loss: 2.570590284018519

Epoch: 5| Step: 7
Training loss: 3.008693338200575
Validation loss: 2.5783752250369085

Epoch: 5| Step: 8
Training loss: 2.7764066035223074
Validation loss: 2.578608108952983

Epoch: 5| Step: 9
Training loss: 2.7729790107106025
Validation loss: 2.5710644866684644

Epoch: 5| Step: 10
Training loss: 2.4964725403974497
Validation loss: 2.5781865450367136

Epoch: 133| Step: 0
Training loss: 2.643842373580144
Validation loss: 2.5722695029502773

Epoch: 5| Step: 1
Training loss: 2.8528317487746113
Validation loss: 2.583706324388705

Epoch: 5| Step: 2
Training loss: 3.598525879305069
Validation loss: 2.5901652260193404

Epoch: 5| Step: 3
Training loss: 3.001540742047636
Validation loss: 2.5796063594474936

Epoch: 5| Step: 4
Training loss: 2.6308204064601908
Validation loss: 2.603751841986985

Epoch: 5| Step: 5
Training loss: 3.0996667559768274
Validation loss: 2.6041455910763016

Epoch: 5| Step: 6
Training loss: 3.2585784962968622
Validation loss: 2.6222896304932157

Epoch: 5| Step: 7
Training loss: 2.814051052072338
Validation loss: 2.6140697585873176

Epoch: 5| Step: 8
Training loss: 2.8722798291481197
Validation loss: 2.606940425864949

Epoch: 5| Step: 9
Training loss: 2.5512998559053055
Validation loss: 2.602527688060502

Epoch: 5| Step: 10
Training loss: 2.7048242773492497
Validation loss: 2.5879315099352045

Epoch: 134| Step: 0
Training loss: 2.884988103409011
Validation loss: 2.577783174497924

Epoch: 5| Step: 1
Training loss: 2.962393933421492
Validation loss: 2.5799871477117136

Epoch: 5| Step: 2
Training loss: 2.428925618621764
Validation loss: 2.572745596276957

Epoch: 5| Step: 3
Training loss: 2.8814581607585676
Validation loss: 2.5751735733889585

Epoch: 5| Step: 4
Training loss: 2.861879346435605
Validation loss: 2.5712774954832205

Epoch: 5| Step: 5
Training loss: 3.1158491813485845
Validation loss: 2.580000672438479

Epoch: 5| Step: 6
Training loss: 3.3279992021596394
Validation loss: 2.5751334704844755

Epoch: 5| Step: 7
Training loss: 2.879219276253038
Validation loss: 2.5719142690079457

Epoch: 5| Step: 8
Training loss: 2.8493645545214092
Validation loss: 2.5960050165803015

Epoch: 5| Step: 9
Training loss: 2.9366174548987507
Validation loss: 2.5828940275699592

Epoch: 5| Step: 10
Training loss: 2.9423223641836715
Validation loss: 2.5930714451677535

Epoch: 135| Step: 0
Training loss: 2.5166926043691698
Validation loss: 2.5860640512170034

Epoch: 5| Step: 1
Training loss: 2.865755893126499
Validation loss: 2.5895931412370667

Epoch: 5| Step: 2
Training loss: 2.928658347883537
Validation loss: 2.5896116577222443

Epoch: 5| Step: 3
Training loss: 2.6597315691547703
Validation loss: 2.5935272692455418

Epoch: 5| Step: 4
Training loss: 3.215839143820129
Validation loss: 2.590592822254521

Epoch: 5| Step: 5
Training loss: 2.8351575551328287
Validation loss: 2.5811222457069354

Epoch: 5| Step: 6
Training loss: 3.3785534272078706
Validation loss: 2.5780488968471427

Epoch: 5| Step: 7
Training loss: 3.1914612334614847
Validation loss: 2.589202971353534

Epoch: 5| Step: 8
Training loss: 2.567052472418256
Validation loss: 2.5825317715818

Epoch: 5| Step: 9
Training loss: 3.0013636033158466
Validation loss: 2.576711400989986

Epoch: 5| Step: 10
Training loss: 2.8321267157939745
Validation loss: 2.571666998598394

Epoch: 136| Step: 0
Training loss: 2.987973904231455
Validation loss: 2.57867440602912

Epoch: 5| Step: 1
Training loss: 2.674272766370135
Validation loss: 2.575300930290614

Epoch: 5| Step: 2
Training loss: 2.9095004373259346
Validation loss: 2.590451820760454

Epoch: 5| Step: 3
Training loss: 2.535018376391015
Validation loss: 2.5825332496893907

Epoch: 5| Step: 4
Training loss: 3.2300551309988492
Validation loss: 2.5996531652343027

Epoch: 5| Step: 5
Training loss: 3.2364238938945684
Validation loss: 2.6011166306126943

Epoch: 5| Step: 6
Training loss: 2.259968292722831
Validation loss: 2.5829831864209143

Epoch: 5| Step: 7
Training loss: 2.7354127495053193
Validation loss: 2.5959650863636785

Epoch: 5| Step: 8
Training loss: 3.4680443123227085
Validation loss: 2.591019106184953

Epoch: 5| Step: 9
Training loss: 3.176038593221103
Validation loss: 2.580802724627351

Epoch: 5| Step: 10
Training loss: 2.714396707516941
Validation loss: 2.5797783137912362

Epoch: 137| Step: 0
Training loss: 3.299633156008922
Validation loss: 2.5708781205777735

Epoch: 5| Step: 1
Training loss: 2.574387864619945
Validation loss: 2.5669323724408626

Epoch: 5| Step: 2
Training loss: 2.900025624129116
Validation loss: 2.5782100003457065

Epoch: 5| Step: 3
Training loss: 2.6758958332560354
Validation loss: 2.570335331479499

Epoch: 5| Step: 4
Training loss: 2.9526342559445866
Validation loss: 2.5747369593853646

Epoch: 5| Step: 5
Training loss: 3.336944785352056
Validation loss: 2.5993044273806496

Epoch: 5| Step: 6
Training loss: 2.146106023652676
Validation loss: 2.596167327368596

Epoch: 5| Step: 7
Training loss: 2.9046716813779696
Validation loss: 2.6002051301326303

Epoch: 5| Step: 8
Training loss: 3.20199311889824
Validation loss: 2.587659836684628

Epoch: 5| Step: 9
Training loss: 3.0854606163368574
Validation loss: 2.5752261134907157

Epoch: 5| Step: 10
Training loss: 2.8706552598829678
Validation loss: 2.571592768426936

Epoch: 138| Step: 0
Training loss: 3.228517545040642
Validation loss: 2.5754301731928666

Epoch: 5| Step: 1
Training loss: 2.984826498180952
Validation loss: 2.571314925210115

Epoch: 5| Step: 2
Training loss: 2.770706422428163
Validation loss: 2.5737046437604727

Epoch: 5| Step: 3
Training loss: 2.951268818725407
Validation loss: 2.5741701122281815

Epoch: 5| Step: 4
Training loss: 2.740155197815933
Validation loss: 2.5793479755777655

Epoch: 5| Step: 5
Training loss: 3.098218676774803
Validation loss: 2.5936426792113974

Epoch: 5| Step: 6
Training loss: 2.6516636466683057
Validation loss: 2.5920797397164725

Epoch: 5| Step: 7
Training loss: 2.640791577383926
Validation loss: 2.5902378090151936

Epoch: 5| Step: 8
Training loss: 2.7623856533775
Validation loss: 2.602347011321962

Epoch: 5| Step: 9
Training loss: 3.0961839753720364
Validation loss: 2.587092368588069

Epoch: 5| Step: 10
Training loss: 3.159381031064579
Validation loss: 2.584190868060617

Epoch: 139| Step: 0
Training loss: 3.1655901199934733
Validation loss: 2.5713059012076944

Epoch: 5| Step: 1
Training loss: 3.0201939574855983
Validation loss: 2.5656749236309335

Epoch: 5| Step: 2
Training loss: 2.6962788052141007
Validation loss: 2.5640116079094977

Epoch: 5| Step: 3
Training loss: 3.3739098095012743
Validation loss: 2.5627941800102167

Epoch: 5| Step: 4
Training loss: 3.1768318118398673
Validation loss: 2.5646205194829386

Epoch: 5| Step: 5
Training loss: 2.945559544409701
Validation loss: 2.565818337818168

Epoch: 5| Step: 6
Training loss: 3.245021087389877
Validation loss: 2.5638680526633983

Epoch: 5| Step: 7
Training loss: 2.6160554629637987
Validation loss: 2.5584021346172943

Epoch: 5| Step: 8
Training loss: 2.6332196110502313
Validation loss: 2.560386468405581

Epoch: 5| Step: 9
Training loss: 2.445585192993232
Validation loss: 2.5597971616344815

Epoch: 5| Step: 10
Training loss: 2.5973789612047624
Validation loss: 2.570719128502525

Epoch: 140| Step: 0
Training loss: 3.252128197708549
Validation loss: 2.5778008091542084

Epoch: 5| Step: 1
Training loss: 2.6191544614194555
Validation loss: 2.5992650735449536

Epoch: 5| Step: 2
Training loss: 2.8934739378709087
Validation loss: 2.630712508633962

Epoch: 5| Step: 3
Training loss: 3.317005763778302
Validation loss: 2.6279920703507775

Epoch: 5| Step: 4
Training loss: 2.6599164902334564
Validation loss: 2.589907719367414

Epoch: 5| Step: 5
Training loss: 3.306894994461501
Validation loss: 2.565430838696372

Epoch: 5| Step: 6
Training loss: 2.3259914786263898
Validation loss: 2.5607733833401625

Epoch: 5| Step: 7
Training loss: 2.959583627180833
Validation loss: 2.571526249897167

Epoch: 5| Step: 8
Training loss: 3.134535166032164
Validation loss: 2.5704249279414797

Epoch: 5| Step: 9
Training loss: 2.690233570296498
Validation loss: 2.571437881191301

Epoch: 5| Step: 10
Training loss: 2.9973636805546806
Validation loss: 2.5747221275398204

Epoch: 141| Step: 0
Training loss: 3.373672648190099
Validation loss: 2.5774248282999865

Epoch: 5| Step: 1
Training loss: 2.26691216046313
Validation loss: 2.588153739643812

Epoch: 5| Step: 2
Training loss: 3.3554028114883243
Validation loss: 2.5981208829224443

Epoch: 5| Step: 3
Training loss: 2.164701622186796
Validation loss: 2.613922656007319

Epoch: 5| Step: 4
Training loss: 2.897051621271785
Validation loss: 2.6226645157472164

Epoch: 5| Step: 5
Training loss: 2.965262522920017
Validation loss: 2.5998145461695095

Epoch: 5| Step: 6
Training loss: 2.509652956797416
Validation loss: 2.574786380995161

Epoch: 5| Step: 7
Training loss: 3.1531374852639336
Validation loss: 2.5713832487722477

Epoch: 5| Step: 8
Training loss: 3.2660151344411186
Validation loss: 2.5761667201918494

Epoch: 5| Step: 9
Training loss: 2.9866573533980167
Validation loss: 2.584029752505747

Epoch: 5| Step: 10
Training loss: 2.971336121745346
Validation loss: 2.614650505002833

Epoch: 142| Step: 0
Training loss: 3.1708033964236844
Validation loss: 2.67183059437678

Epoch: 5| Step: 1
Training loss: 2.1021205912660217
Validation loss: 2.6931106045703617

Epoch: 5| Step: 2
Training loss: 2.897615629823217
Validation loss: 2.703066256485467

Epoch: 5| Step: 3
Training loss: 3.3784776360648205
Validation loss: 2.726024110636056

Epoch: 5| Step: 4
Training loss: 2.9807282381102396
Validation loss: 2.6649509442824444

Epoch: 5| Step: 5
Training loss: 2.9516688394852633
Validation loss: 2.606525862307948

Epoch: 5| Step: 6
Training loss: 2.6914279532699408
Validation loss: 2.573959845221435

Epoch: 5| Step: 7
Training loss: 2.8169680390906207
Validation loss: 2.5614639466788884

Epoch: 5| Step: 8
Training loss: 3.2676223414428396
Validation loss: 2.5743300353979

Epoch: 5| Step: 9
Training loss: 3.1282738893118505
Validation loss: 2.578717042643784

Epoch: 5| Step: 10
Training loss: 3.155736749294397
Validation loss: 2.587207808960737

Epoch: 143| Step: 0
Training loss: 2.9648234852938877
Validation loss: 2.612817056309339

Epoch: 5| Step: 1
Training loss: 3.0176196839270073
Validation loss: 2.6363038289950587

Epoch: 5| Step: 2
Training loss: 3.2171484657205798
Validation loss: 2.646652439506733

Epoch: 5| Step: 3
Training loss: 2.5965022915617557
Validation loss: 2.6483505824746176

Epoch: 5| Step: 4
Training loss: 2.582407682971563
Validation loss: 2.6401123667693884

Epoch: 5| Step: 5
Training loss: 2.5315302940875135
Validation loss: 2.6372676135603244

Epoch: 5| Step: 6
Training loss: 3.286210733427951
Validation loss: 2.604510663026357

Epoch: 5| Step: 7
Training loss: 2.9039903285283226
Validation loss: 2.5905540495879347

Epoch: 5| Step: 8
Training loss: 3.08576010664974
Validation loss: 2.5721894391838647

Epoch: 5| Step: 9
Training loss: 2.808855450445573
Validation loss: 2.5558154530702226

Epoch: 5| Step: 10
Training loss: 3.306297397093514
Validation loss: 2.557580002862491

Epoch: 144| Step: 0
Training loss: 2.8607029567145164
Validation loss: 2.5556700360793787

Epoch: 5| Step: 1
Training loss: 3.0670681573131047
Validation loss: 2.5567009590318666

Epoch: 5| Step: 2
Training loss: 2.990231504632032
Validation loss: 2.5514869607574298

Epoch: 5| Step: 3
Training loss: 2.5195363599148766
Validation loss: 2.5555384425653944

Epoch: 5| Step: 4
Training loss: 2.8509308415872145
Validation loss: 2.558252361197722

Epoch: 5| Step: 5
Training loss: 3.0475494420810816
Validation loss: 2.561757448078731

Epoch: 5| Step: 6
Training loss: 3.3332497268364216
Validation loss: 2.569925336356907

Epoch: 5| Step: 7
Training loss: 2.935083734724819
Validation loss: 2.5812711936952426

Epoch: 5| Step: 8
Training loss: 2.57265071549734
Validation loss: 2.5751812329199195

Epoch: 5| Step: 9
Training loss: 3.28700275214219
Validation loss: 2.5518459997430787

Epoch: 5| Step: 10
Training loss: 2.4242448594521804
Validation loss: 2.5472443307364814

Epoch: 145| Step: 0
Training loss: 2.720421551266542
Validation loss: 2.5452576869814587

Epoch: 5| Step: 1
Training loss: 2.6511333776972315
Validation loss: 2.550789085290344

Epoch: 5| Step: 2
Training loss: 2.9868320117322624
Validation loss: 2.55124172240481

Epoch: 5| Step: 3
Training loss: 3.360883507146357
Validation loss: 2.5505665058354707

Epoch: 5| Step: 4
Training loss: 3.3465179680342336
Validation loss: 2.555951392403354

Epoch: 5| Step: 5
Training loss: 2.9267038843776207
Validation loss: 2.567078560565945

Epoch: 5| Step: 6
Training loss: 2.853399651668787
Validation loss: 2.5593261892792905

Epoch: 5| Step: 7
Training loss: 2.664330074710954
Validation loss: 2.551394869518408

Epoch: 5| Step: 8
Training loss: 2.4994546295400912
Validation loss: 2.5620464515836803

Epoch: 5| Step: 9
Training loss: 2.9596050555709184
Validation loss: 2.574421698558903

Epoch: 5| Step: 10
Training loss: 2.9662288199792655
Validation loss: 2.570541368155477

Epoch: 146| Step: 0
Training loss: 2.4787375348538045
Validation loss: 2.586238655062237

Epoch: 5| Step: 1
Training loss: 1.7791439120455312
Validation loss: 2.587264973815249

Epoch: 5| Step: 2
Training loss: 2.826633629185965
Validation loss: 2.5975198181134407

Epoch: 5| Step: 3
Training loss: 3.1047104395502245
Validation loss: 2.606697263338498

Epoch: 5| Step: 4
Training loss: 2.9955817112062197
Validation loss: 2.6456106155316985

Epoch: 5| Step: 5
Training loss: 2.625673207741923
Validation loss: 2.633562585543581

Epoch: 5| Step: 6
Training loss: 3.384027910266246
Validation loss: 2.616836102569224

Epoch: 5| Step: 7
Training loss: 2.9023782514983307
Validation loss: 2.587228096381175

Epoch: 5| Step: 8
Training loss: 3.060584111282336
Validation loss: 2.5705702402757695

Epoch: 5| Step: 9
Training loss: 3.217003505905276
Validation loss: 2.5597088266786447

Epoch: 5| Step: 10
Training loss: 3.3087439204593574
Validation loss: 2.5475822396345733

Epoch: 147| Step: 0
Training loss: 2.663057646760254
Validation loss: 2.554000067075663

Epoch: 5| Step: 1
Training loss: 3.3016009695444977
Validation loss: 2.5521653892747733

Epoch: 5| Step: 2
Training loss: 3.066632810350477
Validation loss: 2.548923128160351

Epoch: 5| Step: 3
Training loss: 2.167820610964953
Validation loss: 2.555714664444707

Epoch: 5| Step: 4
Training loss: 2.905319228893332
Validation loss: 2.5560308093721567

Epoch: 5| Step: 5
Training loss: 2.6707175798570355
Validation loss: 2.564880991692001

Epoch: 5| Step: 6
Training loss: 3.127186429948072
Validation loss: 2.5742522495549958

Epoch: 5| Step: 7
Training loss: 2.853018945266712
Validation loss: 2.573090631639337

Epoch: 5| Step: 8
Training loss: 2.786228053955067
Validation loss: 2.576199302784512

Epoch: 5| Step: 9
Training loss: 3.2771560560638395
Validation loss: 2.590606399477868

Epoch: 5| Step: 10
Training loss: 3.1788400931422385
Validation loss: 2.5945929768386917

Epoch: 148| Step: 0
Training loss: 3.325917689522401
Validation loss: 2.607052732549489

Epoch: 5| Step: 1
Training loss: 3.0616143950802486
Validation loss: 2.605043378038181

Epoch: 5| Step: 2
Training loss: 3.0420857667689005
Validation loss: 2.5918966334211

Epoch: 5| Step: 3
Training loss: 2.9130792262850114
Validation loss: 2.5909956011003956

Epoch: 5| Step: 4
Training loss: 2.5133822851532197
Validation loss: 2.5759862844606736

Epoch: 5| Step: 5
Training loss: 2.5750644897977666
Validation loss: 2.5611021930043205

Epoch: 5| Step: 6
Training loss: 2.5014057975262043
Validation loss: 2.5521855594803404

Epoch: 5| Step: 7
Training loss: 2.709158981845845
Validation loss: 2.551714867082444

Epoch: 5| Step: 8
Training loss: 3.3969559169421006
Validation loss: 2.551620761587044

Epoch: 5| Step: 9
Training loss: 2.623714586430579
Validation loss: 2.5527266370695565

Epoch: 5| Step: 10
Training loss: 3.257341309646832
Validation loss: 2.553041593563622

Epoch: 149| Step: 0
Training loss: 3.0167917158929085
Validation loss: 2.553576130811607

Epoch: 5| Step: 1
Training loss: 2.8985967463834172
Validation loss: 2.561242027650862

Epoch: 5| Step: 2
Training loss: 2.881024889313141
Validation loss: 2.564408668703985

Epoch: 5| Step: 3
Training loss: 3.1579609378768843
Validation loss: 2.561716972026489

Epoch: 5| Step: 4
Training loss: 2.7322738858244433
Validation loss: 2.562329792619695

Epoch: 5| Step: 5
Training loss: 3.173503438920976
Validation loss: 2.572878901368168

Epoch: 5| Step: 6
Training loss: 2.9227448662867856
Validation loss: 2.5632765648989353

Epoch: 5| Step: 7
Training loss: 2.706847521779635
Validation loss: 2.56598318548714

Epoch: 5| Step: 8
Training loss: 2.979587409624325
Validation loss: 2.574609258438714

Epoch: 5| Step: 9
Training loss: 2.2870885260044593
Validation loss: 2.577638310559094

Epoch: 5| Step: 10
Training loss: 3.0881333662891377
Validation loss: 2.5997766091934738

Epoch: 150| Step: 0
Training loss: 3.1105468688681244
Validation loss: 2.639461493277966

Epoch: 5| Step: 1
Training loss: 2.2085295056234755
Validation loss: 2.6396669243287465

Epoch: 5| Step: 2
Training loss: 3.1112757101870296
Validation loss: 2.6200621601522185

Epoch: 5| Step: 3
Training loss: 2.748355286947937
Validation loss: 2.5956563317979344

Epoch: 5| Step: 4
Training loss: 3.38335416126574
Validation loss: 2.5762674978062563

Epoch: 5| Step: 5
Training loss: 3.3647496012103506
Validation loss: 2.57202784594537

Epoch: 5| Step: 6
Training loss: 2.8110302793703354
Validation loss: 2.575309625726119

Epoch: 5| Step: 7
Training loss: 2.595957540496953
Validation loss: 2.5676652706320655

Epoch: 5| Step: 8
Training loss: 2.733953650572109
Validation loss: 2.547604036575833

Epoch: 5| Step: 9
Training loss: 2.7718965789746286
Validation loss: 2.549445275562607

Epoch: 5| Step: 10
Training loss: 2.849235358476151
Validation loss: 2.5577574291714456

Epoch: 151| Step: 0
Training loss: 3.279672734053304
Validation loss: 2.5486689765128765

Epoch: 5| Step: 1
Training loss: 2.800291734211258
Validation loss: 2.5429811519731635

Epoch: 5| Step: 2
Training loss: 2.684311683272205
Validation loss: 2.543072294841511

Epoch: 5| Step: 3
Training loss: 3.231126563778458
Validation loss: 2.5405568248766652

Epoch: 5| Step: 4
Training loss: 2.97833327438733
Validation loss: 2.5485386339992298

Epoch: 5| Step: 5
Training loss: 2.9768755089893344
Validation loss: 2.5447339852126745

Epoch: 5| Step: 6
Training loss: 2.864941457846
Validation loss: 2.5483963000814263

Epoch: 5| Step: 7
Training loss: 2.6009241185777343
Validation loss: 2.551699760765044

Epoch: 5| Step: 8
Training loss: 2.446977432464933
Validation loss: 2.555664433654793

Epoch: 5| Step: 9
Training loss: 2.9242302688750885
Validation loss: 2.5570143010875617

Epoch: 5| Step: 10
Training loss: 3.038275374046131
Validation loss: 2.56841422944585

Epoch: 152| Step: 0
Training loss: 3.1832606229084313
Validation loss: 2.5670562523848774

Epoch: 5| Step: 1
Training loss: 2.9058433986613843
Validation loss: 2.588670793519287

Epoch: 5| Step: 2
Training loss: 2.575513129356184
Validation loss: 2.5757313902754824

Epoch: 5| Step: 3
Training loss: 3.347234318783026
Validation loss: 2.5920660030637803

Epoch: 5| Step: 4
Training loss: 2.0478177993312325
Validation loss: 2.5720069562031713

Epoch: 5| Step: 5
Training loss: 2.818014460849411
Validation loss: 2.580049868021688

Epoch: 5| Step: 6
Training loss: 2.9125745313546574
Validation loss: 2.562218454272378

Epoch: 5| Step: 7
Training loss: 2.883957054135879
Validation loss: 2.5529499389911954

Epoch: 5| Step: 8
Training loss: 2.6788619746712596
Validation loss: 2.5398958086637737

Epoch: 5| Step: 9
Training loss: 3.1026832227681846
Validation loss: 2.53988130024354

Epoch: 5| Step: 10
Training loss: 3.246574650843713
Validation loss: 2.5390680744371834

Epoch: 153| Step: 0
Training loss: 3.130102493265543
Validation loss: 2.5435651456576136

Epoch: 5| Step: 1
Training loss: 3.3407195432040107
Validation loss: 2.545443350585595

Epoch: 5| Step: 2
Training loss: 3.076729860107981
Validation loss: 2.5500763512733835

Epoch: 5| Step: 3
Training loss: 2.7410082767644126
Validation loss: 2.547583366694117

Epoch: 5| Step: 4
Training loss: 3.0930973482003985
Validation loss: 2.5374693642741097

Epoch: 5| Step: 5
Training loss: 2.7553129891395893
Validation loss: 2.537490952570246

Epoch: 5| Step: 6
Training loss: 2.337397294669578
Validation loss: 2.5397435468704153

Epoch: 5| Step: 7
Training loss: 2.914456501933106
Validation loss: 2.540218629352524

Epoch: 5| Step: 8
Training loss: 2.9528406399861487
Validation loss: 2.5470484202640797

Epoch: 5| Step: 9
Training loss: 2.5039418615227933
Validation loss: 2.5492139331379824

Epoch: 5| Step: 10
Training loss: 2.9897610459801878
Validation loss: 2.5510846790628707

Epoch: 154| Step: 0
Training loss: 2.9244655609946664
Validation loss: 2.562518565192952

Epoch: 5| Step: 1
Training loss: 2.9932790811913863
Validation loss: 2.574964509371551

Epoch: 5| Step: 2
Training loss: 3.0523460370600275
Validation loss: 2.591265344648865

Epoch: 5| Step: 3
Training loss: 2.8666098529893063
Validation loss: 2.590013635957163

Epoch: 5| Step: 4
Training loss: 3.2413445169634354
Validation loss: 2.57047662062335

Epoch: 5| Step: 5
Training loss: 2.3440617671874375
Validation loss: 2.543305910518746

Epoch: 5| Step: 6
Training loss: 2.860904638829828
Validation loss: 2.5417794219904497

Epoch: 5| Step: 7
Training loss: 3.1233406238884722
Validation loss: 2.5387924214768502

Epoch: 5| Step: 8
Training loss: 2.613002699531244
Validation loss: 2.5499090636926884

Epoch: 5| Step: 9
Training loss: 2.863518719369014
Validation loss: 2.5468183810998517

Epoch: 5| Step: 10
Training loss: 2.9050165655875166
Validation loss: 2.5419048000748306

Epoch: 155| Step: 0
Training loss: 3.496084475371776
Validation loss: 2.550626289022459

Epoch: 5| Step: 1
Training loss: 2.774318157661302
Validation loss: 2.5449302803590594

Epoch: 5| Step: 2
Training loss: 2.938007716678382
Validation loss: 2.553164679491724

Epoch: 5| Step: 3
Training loss: 2.505616744939651
Validation loss: 2.5498315764785886

Epoch: 5| Step: 4
Training loss: 2.8154048753188223
Validation loss: 2.557798152302047

Epoch: 5| Step: 5
Training loss: 2.733831035457775
Validation loss: 2.5563343845205706

Epoch: 5| Step: 6
Training loss: 3.0069464687686143
Validation loss: 2.560529367812828

Epoch: 5| Step: 7
Training loss: 3.129361275531774
Validation loss: 2.558470081558515

Epoch: 5| Step: 8
Training loss: 2.3963845876547993
Validation loss: 2.576244818410211

Epoch: 5| Step: 9
Training loss: 2.812961116713245
Validation loss: 2.5862822593278483

Epoch: 5| Step: 10
Training loss: 3.0788200097249456
Validation loss: 2.5983656866921727

Epoch: 156| Step: 0
Training loss: 2.7935475423279157
Validation loss: 2.594601389750851

Epoch: 5| Step: 1
Training loss: 2.842785011302015
Validation loss: 2.585575699176157

Epoch: 5| Step: 2
Training loss: 2.8750900586162182
Validation loss: 2.5758887811503244

Epoch: 5| Step: 3
Training loss: 3.068467379295451
Validation loss: 2.5722730510055483

Epoch: 5| Step: 4
Training loss: 2.6285331200538855
Validation loss: 2.569505417386828

Epoch: 5| Step: 5
Training loss: 2.888084656285643
Validation loss: 2.5628010082556534

Epoch: 5| Step: 6
Training loss: 2.6848790007593006
Validation loss: 2.5516533853390424

Epoch: 5| Step: 7
Training loss: 3.139130649614884
Validation loss: 2.5438605680449706

Epoch: 5| Step: 8
Training loss: 2.3271906469105343
Validation loss: 2.5371711879605923

Epoch: 5| Step: 9
Training loss: 2.6779966664140393
Validation loss: 2.5316031941453523

Epoch: 5| Step: 10
Training loss: 3.7037228129918245
Validation loss: 2.5392663320756506

Epoch: 157| Step: 0
Training loss: 2.8381597886161685
Validation loss: 2.5290414256510103

Epoch: 5| Step: 1
Training loss: 2.9252987961702304
Validation loss: 2.530696071477436

Epoch: 5| Step: 2
Training loss: 3.07128316275268
Validation loss: 2.5384470769474237

Epoch: 5| Step: 3
Training loss: 2.337836574863402
Validation loss: 2.5362322121294305

Epoch: 5| Step: 4
Training loss: 2.7853071645375085
Validation loss: 2.5482271718045992

Epoch: 5| Step: 5
Training loss: 2.8095601293480734
Validation loss: 2.5453377709843035

Epoch: 5| Step: 6
Training loss: 3.189270724461354
Validation loss: 2.5707264393061697

Epoch: 5| Step: 7
Training loss: 3.185388202095135
Validation loss: 2.5654421347833707

Epoch: 5| Step: 8
Training loss: 3.0760534451409134
Validation loss: 2.5563517619866065

Epoch: 5| Step: 9
Training loss: 2.5622317476124015
Validation loss: 2.551559031416039

Epoch: 5| Step: 10
Training loss: 2.915600082111083
Validation loss: 2.545545844057971

Epoch: 158| Step: 0
Training loss: 3.07202582081235
Validation loss: 2.5464285071554134

Epoch: 5| Step: 1
Training loss: 2.552052296560053
Validation loss: 2.554800879453805

Epoch: 5| Step: 2
Training loss: 2.997702354492175
Validation loss: 2.559261865218961

Epoch: 5| Step: 3
Training loss: 3.1065868356240984
Validation loss: 2.5430438020829733

Epoch: 5| Step: 4
Training loss: 2.509552349127524
Validation loss: 2.5475039661420915

Epoch: 5| Step: 5
Training loss: 2.3055271494186624
Validation loss: 2.5501707791545174

Epoch: 5| Step: 6
Training loss: 3.048399871328021
Validation loss: 2.559724984408542

Epoch: 5| Step: 7
Training loss: 3.5559754438292597
Validation loss: 2.566351258733904

Epoch: 5| Step: 8
Training loss: 2.80882328034621
Validation loss: 2.556327497884744

Epoch: 5| Step: 9
Training loss: 2.799480481997632
Validation loss: 2.5496515212876747

Epoch: 5| Step: 10
Training loss: 2.666755813856932
Validation loss: 2.5364785519652537

Epoch: 159| Step: 0
Training loss: 2.9527314746376647
Validation loss: 2.525431671086906

Epoch: 5| Step: 1
Training loss: 2.825395225627692
Validation loss: 2.5314162420152857

Epoch: 5| Step: 2
Training loss: 3.3706741867565015
Validation loss: 2.5360165281333304

Epoch: 5| Step: 3
Training loss: 3.0316397819424483
Validation loss: 2.5384818514495873

Epoch: 5| Step: 4
Training loss: 3.3743429604041006
Validation loss: 2.5475205313572427

Epoch: 5| Step: 5
Training loss: 2.4078210433224183
Validation loss: 2.5495194260755696

Epoch: 5| Step: 6
Training loss: 2.594597551600816
Validation loss: 2.548645875498894

Epoch: 5| Step: 7
Training loss: 2.55211395452904
Validation loss: 2.5503414406621276

Epoch: 5| Step: 8
Training loss: 3.1100561268148326
Validation loss: 2.541446702161344

Epoch: 5| Step: 9
Training loss: 2.5407581477448873
Validation loss: 2.534849416437346

Epoch: 5| Step: 10
Training loss: 2.7409939246849695
Validation loss: 2.5233931877095674

Epoch: 160| Step: 0
Training loss: 2.6133761310316763
Validation loss: 2.5348208575448132

Epoch: 5| Step: 1
Training loss: 2.6925387498197693
Validation loss: 2.5243579239019125

Epoch: 5| Step: 2
Training loss: 3.0039511728090065
Validation loss: 2.5194159271895606

Epoch: 5| Step: 3
Training loss: 3.480940284854601
Validation loss: 2.523100440051888

Epoch: 5| Step: 4
Training loss: 2.648383936157505
Validation loss: 2.5389604455522865

Epoch: 5| Step: 5
Training loss: 2.7770015543300413
Validation loss: 2.531822141954416

Epoch: 5| Step: 6
Training loss: 2.8533020566254064
Validation loss: 2.534457383700131

Epoch: 5| Step: 7
Training loss: 3.072269194759131
Validation loss: 2.5375679023192936

Epoch: 5| Step: 8
Training loss: 2.6345697079853725
Validation loss: 2.546673250666073

Epoch: 5| Step: 9
Training loss: 2.7211933775983126
Validation loss: 2.5468155535442647

Epoch: 5| Step: 10
Training loss: 3.098287626288102
Validation loss: 2.5785000028367415

Epoch: 161| Step: 0
Training loss: 2.9276851881500314
Validation loss: 2.584264510681087

Epoch: 5| Step: 1
Training loss: 2.4611957717276414
Validation loss: 2.5728768009363665

Epoch: 5| Step: 2
Training loss: 3.4351798810876977
Validation loss: 2.559698949511186

Epoch: 5| Step: 3
Training loss: 2.6663654475159686
Validation loss: 2.546690582316538

Epoch: 5| Step: 4
Training loss: 2.843717805449628
Validation loss: 2.5410599185229343

Epoch: 5| Step: 5
Training loss: 2.503605912357632
Validation loss: 2.538518696773537

Epoch: 5| Step: 6
Training loss: 3.0533931555849865
Validation loss: 2.5502804430037513

Epoch: 5| Step: 7
Training loss: 2.797523636432573
Validation loss: 2.556344309787886

Epoch: 5| Step: 8
Training loss: 3.1529272737690537
Validation loss: 2.5532520620791144

Epoch: 5| Step: 9
Training loss: 2.8124940660202156
Validation loss: 2.5698353094748265

Epoch: 5| Step: 10
Training loss: 2.952810926740754
Validation loss: 2.5733078327995065

Epoch: 162| Step: 0
Training loss: 3.3018053260685862
Validation loss: 2.570022246951306

Epoch: 5| Step: 1
Training loss: 2.7993534976638466
Validation loss: 2.5639165948977105

Epoch: 5| Step: 2
Training loss: 3.1522256103462754
Validation loss: 2.560942007388686

Epoch: 5| Step: 3
Training loss: 3.0035346189472087
Validation loss: 2.5825914292778207

Epoch: 5| Step: 4
Training loss: 2.1826755183061204
Validation loss: 2.560065561976871

Epoch: 5| Step: 5
Training loss: 2.479036846020939
Validation loss: 2.580003176457697

Epoch: 5| Step: 6
Training loss: 2.197641243935948
Validation loss: 2.5581355269726154

Epoch: 5| Step: 7
Training loss: 2.727626734935163
Validation loss: 2.5548341138347186

Epoch: 5| Step: 8
Training loss: 2.9456304484802014
Validation loss: 2.550140237500923

Epoch: 5| Step: 9
Training loss: 3.117752827026172
Validation loss: 2.539556961819732

Epoch: 5| Step: 10
Training loss: 3.510873117777585
Validation loss: 2.539425983016351

Epoch: 163| Step: 0
Training loss: 2.6909566428988003
Validation loss: 2.533709152505732

Epoch: 5| Step: 1
Training loss: 3.0177920762542487
Validation loss: 2.5374713939939753

Epoch: 5| Step: 2
Training loss: 3.1183972604527193
Validation loss: 2.536185076761946

Epoch: 5| Step: 3
Training loss: 3.1573262409837213
Validation loss: 2.550810539751952

Epoch: 5| Step: 4
Training loss: 2.0810001532624685
Validation loss: 2.545917986719827

Epoch: 5| Step: 5
Training loss: 3.2509909366233742
Validation loss: 2.5552136394740828

Epoch: 5| Step: 6
Training loss: 2.2130675283024375
Validation loss: 2.544805871359549

Epoch: 5| Step: 7
Training loss: 3.250321152298433
Validation loss: 2.5543977547338885

Epoch: 5| Step: 8
Training loss: 2.9520914196548858
Validation loss: 2.5519711223458343

Epoch: 5| Step: 9
Training loss: 2.563430803163015
Validation loss: 2.561048200974426

Epoch: 5| Step: 10
Training loss: 2.9253116735052345
Validation loss: 2.573141405974078

Epoch: 164| Step: 0
Training loss: 3.065112809412376
Validation loss: 2.596360111138227

Epoch: 5| Step: 1
Training loss: 3.1311977724756455
Validation loss: 2.567621337226257

Epoch: 5| Step: 2
Training loss: 2.672643272192211
Validation loss: 2.535258106697353

Epoch: 5| Step: 3
Training loss: 3.3960027983960597
Validation loss: 2.5341316409059953

Epoch: 5| Step: 4
Training loss: 2.270552439917601
Validation loss: 2.5297243743426128

Epoch: 5| Step: 5
Training loss: 2.5857904398150513
Validation loss: 2.5274511949907112

Epoch: 5| Step: 6
Training loss: 3.393339415384274
Validation loss: 2.5138764033708805

Epoch: 5| Step: 7
Training loss: 2.744842113825107
Validation loss: 2.5261759864473547

Epoch: 5| Step: 8
Training loss: 2.7181802788483904
Validation loss: 2.52215862361433

Epoch: 5| Step: 9
Training loss: 2.922713052441868
Validation loss: 2.5236835568674016

Epoch: 5| Step: 10
Training loss: 2.652287837971524
Validation loss: 2.5325850765539086

Epoch: 165| Step: 0
Training loss: 2.7083962262015926
Validation loss: 2.5347337680279676

Epoch: 5| Step: 1
Training loss: 2.916511549684966
Validation loss: 2.5374784661759446

Epoch: 5| Step: 2
Training loss: 3.4470813734400276
Validation loss: 2.5473442005295457

Epoch: 5| Step: 3
Training loss: 2.9830087460304306
Validation loss: 2.554346621870911

Epoch: 5| Step: 4
Training loss: 2.677574815176812
Validation loss: 2.562144387113624

Epoch: 5| Step: 5
Training loss: 2.959479544222
Validation loss: 2.5649052588360686

Epoch: 5| Step: 6
Training loss: 2.5529432962816743
Validation loss: 2.5687735721520664

Epoch: 5| Step: 7
Training loss: 3.05348216908722
Validation loss: 2.6073362321573885

Epoch: 5| Step: 8
Training loss: 2.5852219435782673
Validation loss: 2.64678995403796

Epoch: 5| Step: 9
Training loss: 2.9206829393298213
Validation loss: 2.6613936633831243

Epoch: 5| Step: 10
Training loss: 2.8915491224981507
Validation loss: 2.5614690560119353

Epoch: 166| Step: 0
Training loss: 2.77937905464194
Validation loss: 2.524685019120779

Epoch: 5| Step: 1
Training loss: 2.6971904017671813
Validation loss: 2.514645446335913

Epoch: 5| Step: 2
Training loss: 2.7676419591978916
Validation loss: 2.5244753779619904

Epoch: 5| Step: 3
Training loss: 3.393542181856454
Validation loss: 2.5237002672623006

Epoch: 5| Step: 4
Training loss: 2.927938605597702
Validation loss: 2.532372056207071

Epoch: 5| Step: 5
Training loss: 2.914777325456377
Validation loss: 2.536921277467628

Epoch: 5| Step: 6
Training loss: 3.083009204495647
Validation loss: 2.551848359599069

Epoch: 5| Step: 7
Training loss: 2.6747683201936248
Validation loss: 2.5518238376854927

Epoch: 5| Step: 8
Training loss: 3.050209763614755
Validation loss: 2.5480361647910423

Epoch: 5| Step: 9
Training loss: 3.096796866623622
Validation loss: 2.551151604972679

Epoch: 5| Step: 10
Training loss: 2.5730928265476085
Validation loss: 2.547667755873689

Epoch: 167| Step: 0
Training loss: 2.8646115573301816
Validation loss: 2.545031166677983

Epoch: 5| Step: 1
Training loss: 2.6020810638572582
Validation loss: 2.540845165973457

Epoch: 5| Step: 2
Training loss: 2.61448251800908
Validation loss: 2.542966203464779

Epoch: 5| Step: 3
Training loss: 2.9420794239746653
Validation loss: 2.5362710288331396

Epoch: 5| Step: 4
Training loss: 3.178993093036109
Validation loss: 2.535686060936401

Epoch: 5| Step: 5
Training loss: 2.6894245797209715
Validation loss: 2.526886755993481

Epoch: 5| Step: 6
Training loss: 3.179847657015375
Validation loss: 2.523176589105917

Epoch: 5| Step: 7
Training loss: 3.1095967429373417
Validation loss: 2.535440401434044

Epoch: 5| Step: 8
Training loss: 2.9551723588742327
Validation loss: 2.55741724592683

Epoch: 5| Step: 9
Training loss: 3.179312269110507
Validation loss: 2.5509709535463148

Epoch: 5| Step: 10
Training loss: 2.5545103612492905
Validation loss: 2.5733454780670866

Epoch: 168| Step: 0
Training loss: 2.7806484986416473
Validation loss: 2.563164287495416

Epoch: 5| Step: 1
Training loss: 2.8025858450952787
Validation loss: 2.5672180936503297

Epoch: 5| Step: 2
Training loss: 2.5610925484364078
Validation loss: 2.64325946762407

Epoch: 5| Step: 3
Training loss: 3.1426999653489975
Validation loss: 2.7363470801089345

Epoch: 5| Step: 4
Training loss: 3.034597377308991
Validation loss: 2.757810739352054

Epoch: 5| Step: 5
Training loss: 2.8434241810365233
Validation loss: 2.708576433489912

Epoch: 5| Step: 6
Training loss: 2.7865301865674907
Validation loss: 2.70063167700573

Epoch: 5| Step: 7
Training loss: 3.4863913137655955
Validation loss: 2.649460099786571

Epoch: 5| Step: 8
Training loss: 2.9494043557075718
Validation loss: 2.617617215500852

Epoch: 5| Step: 9
Training loss: 2.977883834120566
Validation loss: 2.588430396370554

Epoch: 5| Step: 10
Training loss: 3.0194518163973756
Validation loss: 2.5691118046287182

Epoch: 169| Step: 0
Training loss: 2.9660584144113202
Validation loss: 2.5628747033325667

Epoch: 5| Step: 1
Training loss: 2.470778103018701
Validation loss: 2.5614830838561025

Epoch: 5| Step: 2
Training loss: 2.7797050042375893
Validation loss: 2.5626071114192595

Epoch: 5| Step: 3
Training loss: 2.835982393271991
Validation loss: 2.571067366327861

Epoch: 5| Step: 4
Training loss: 2.7591774132082545
Validation loss: 2.5831856032044858

Epoch: 5| Step: 5
Training loss: 2.362351516820873
Validation loss: 2.6000442970058337

Epoch: 5| Step: 6
Training loss: 2.336969868320041
Validation loss: 2.5980751880977815

Epoch: 5| Step: 7
Training loss: 3.407613358938498
Validation loss: 2.614398875436317

Epoch: 5| Step: 8
Training loss: 3.43288180767896
Validation loss: 2.6259271983337866

Epoch: 5| Step: 9
Training loss: 2.936829023632512
Validation loss: 2.629327647358377

Epoch: 5| Step: 10
Training loss: 3.562387029630126
Validation loss: 2.611937028192483

Epoch: 170| Step: 0
Training loss: 3.1293783415115035
Validation loss: 2.5939583188792015

Epoch: 5| Step: 1
Training loss: 2.369319949867748
Validation loss: 2.570545316524333

Epoch: 5| Step: 2
Training loss: 2.796180937335792
Validation loss: 2.5608863592064015

Epoch: 5| Step: 3
Training loss: 3.2215663107134285
Validation loss: 2.5624143264498893

Epoch: 5| Step: 4
Training loss: 2.6943487683468046
Validation loss: 2.5648238337093368

Epoch: 5| Step: 5
Training loss: 3.1380972487562215
Validation loss: 2.573141722799912

Epoch: 5| Step: 6
Training loss: 2.5273985584100065
Validation loss: 2.5742047258282903

Epoch: 5| Step: 7
Training loss: 3.154815196626535
Validation loss: 2.56450012867232

Epoch: 5| Step: 8
Training loss: 3.1064516059646246
Validation loss: 2.55363875289255

Epoch: 5| Step: 9
Training loss: 2.285455041897599
Validation loss: 2.535441985862382

Epoch: 5| Step: 10
Training loss: 3.066378414732341
Validation loss: 2.516259623615393

Epoch: 171| Step: 0
Training loss: 2.7441164714795563
Validation loss: 2.5215482953024413

Epoch: 5| Step: 1
Training loss: 2.7690211419496618
Validation loss: 2.523967051763431

Epoch: 5| Step: 2
Training loss: 2.126528022256786
Validation loss: 2.530221255795241

Epoch: 5| Step: 3
Training loss: 2.629464848250228
Validation loss: 2.5295059483212587

Epoch: 5| Step: 4
Training loss: 3.104950330155762
Validation loss: 2.5223583749892637

Epoch: 5| Step: 5
Training loss: 3.0498753569101784
Validation loss: 2.5156495262463228

Epoch: 5| Step: 6
Training loss: 2.6009364935760586
Validation loss: 2.5167054291985935

Epoch: 5| Step: 7
Training loss: 3.2842383446107295
Validation loss: 2.514268074391938

Epoch: 5| Step: 8
Training loss: 2.998710037098732
Validation loss: 2.5135004989245675

Epoch: 5| Step: 9
Training loss: 3.163919478586644
Validation loss: 2.518590136688732

Epoch: 5| Step: 10
Training loss: 3.0792776360516267
Validation loss: 2.522926584893933

Epoch: 172| Step: 0
Training loss: 2.946140486600167
Validation loss: 2.5248676487510338

Epoch: 5| Step: 1
Training loss: 3.06778463496516
Validation loss: 2.534614985923659

Epoch: 5| Step: 2
Training loss: 2.750255399461669
Validation loss: 2.5675240329691578

Epoch: 5| Step: 3
Training loss: 3.4333718220550256
Validation loss: 2.590013493423449

Epoch: 5| Step: 4
Training loss: 2.7374859360982464
Validation loss: 2.5803821546024146

Epoch: 5| Step: 5
Training loss: 2.4944838703648693
Validation loss: 2.5778279530820325

Epoch: 5| Step: 6
Training loss: 2.4148836683604173
Validation loss: 2.5648800901280424

Epoch: 5| Step: 7
Training loss: 2.930399978469403
Validation loss: 2.5407479244738536

Epoch: 5| Step: 8
Training loss: 3.2131420280630114
Validation loss: 2.527670735720609

Epoch: 5| Step: 9
Training loss: 2.6913937594673425
Validation loss: 2.5155215330303573

Epoch: 5| Step: 10
Training loss: 2.8563633468475027
Validation loss: 2.5202082641489683

Epoch: 173| Step: 0
Training loss: 2.9451808748253496
Validation loss: 2.52552879885686

Epoch: 5| Step: 1
Training loss: 3.5807027401960445
Validation loss: 2.529517774762174

Epoch: 5| Step: 2
Training loss: 3.041844053626358
Validation loss: 2.541457779536392

Epoch: 5| Step: 3
Training loss: 2.689059758558987
Validation loss: 2.547097288077158

Epoch: 5| Step: 4
Training loss: 2.801919660550546
Validation loss: 2.558453482025518

Epoch: 5| Step: 5
Training loss: 2.776653735240241
Validation loss: 2.53957858789086

Epoch: 5| Step: 6
Training loss: 2.135237213285852
Validation loss: 2.5431700492711613

Epoch: 5| Step: 7
Training loss: 2.611083151169368
Validation loss: 2.5236427342787136

Epoch: 5| Step: 8
Training loss: 2.7055989669495544
Validation loss: 2.5303795098963815

Epoch: 5| Step: 9
Training loss: 3.1598988205368657
Validation loss: 2.5182494359633822

Epoch: 5| Step: 10
Training loss: 2.853033485908693
Validation loss: 2.5215555687140547

Epoch: 174| Step: 0
Training loss: 2.9413106023832953
Validation loss: 2.5248679706190056

Epoch: 5| Step: 1
Training loss: 2.6543257980511186
Validation loss: 2.526904788454161

Epoch: 5| Step: 2
Training loss: 2.9181800367468207
Validation loss: 2.540881098225297

Epoch: 5| Step: 3
Training loss: 2.7650609707447744
Validation loss: 2.5406729998193502

Epoch: 5| Step: 4
Training loss: 2.949413571017607
Validation loss: 2.5572039211928455

Epoch: 5| Step: 5
Training loss: 3.4533209421482938
Validation loss: 2.5472435698700866

Epoch: 5| Step: 6
Training loss: 2.9890984508627674
Validation loss: 2.540493762265842

Epoch: 5| Step: 7
Training loss: 2.712651043742934
Validation loss: 2.543025294320875

Epoch: 5| Step: 8
Training loss: 2.55475824007325
Validation loss: 2.53641748017479

Epoch: 5| Step: 9
Training loss: 2.755393980486532
Validation loss: 2.5315825804562246

Epoch: 5| Step: 10
Training loss: 2.7062219948674113
Validation loss: 2.5399042064314115

Epoch: 175| Step: 0
Training loss: 2.678060321182632
Validation loss: 2.5304908976407705

Epoch: 5| Step: 1
Training loss: 3.000577394234567
Validation loss: 2.551436932094035

Epoch: 5| Step: 2
Training loss: 3.301490915066717
Validation loss: 2.5415933878512513

Epoch: 5| Step: 3
Training loss: 3.0020285741474146
Validation loss: 2.5448507315495568

Epoch: 5| Step: 4
Training loss: 2.814371291803454
Validation loss: 2.5459691086198166

Epoch: 5| Step: 5
Training loss: 2.483560488593038
Validation loss: 2.538360090634709

Epoch: 5| Step: 6
Training loss: 2.9052230497206115
Validation loss: 2.5557076597789123

Epoch: 5| Step: 7
Training loss: 3.022467405839201
Validation loss: 2.578234737642418

Epoch: 5| Step: 8
Training loss: 2.677166612173388
Validation loss: 2.5666627404713362

Epoch: 5| Step: 9
Training loss: 2.7656224999712835
Validation loss: 2.567087766204358

Epoch: 5| Step: 10
Training loss: 2.7144025046096703
Validation loss: 2.5754695746925047

Epoch: 176| Step: 0
Training loss: 2.411356276349826
Validation loss: 2.574410204868384

Epoch: 5| Step: 1
Training loss: 3.135631634175044
Validation loss: 2.5662876342167227

Epoch: 5| Step: 2
Training loss: 2.8866563101120923
Validation loss: 2.5716965733338726

Epoch: 5| Step: 3
Training loss: 3.0181140806403866
Validation loss: 2.54417211589815

Epoch: 5| Step: 4
Training loss: 3.0058021069004472
Validation loss: 2.5365616268072615

Epoch: 5| Step: 5
Training loss: 2.954724075680049
Validation loss: 2.535973876189194

Epoch: 5| Step: 6
Training loss: 2.798376096118888
Validation loss: 2.5265285190658777

Epoch: 5| Step: 7
Training loss: 3.02278875443569
Validation loss: 2.5202441305347962

Epoch: 5| Step: 8
Training loss: 3.087884448127914
Validation loss: 2.512803181837705

Epoch: 5| Step: 9
Training loss: 2.326700171399734
Validation loss: 2.5176442176758598

Epoch: 5| Step: 10
Training loss: 2.7832972674593406
Validation loss: 2.5116606149203777

Epoch: 177| Step: 0
Training loss: 3.017862705280405
Validation loss: 2.51904375492638

Epoch: 5| Step: 1
Training loss: 2.259113715590311
Validation loss: 2.5176067756233014

Epoch: 5| Step: 2
Training loss: 2.5317266509948633
Validation loss: 2.528531919158102

Epoch: 5| Step: 3
Training loss: 2.870937960803102
Validation loss: 2.5450246463385433

Epoch: 5| Step: 4
Training loss: 2.570382717298148
Validation loss: 2.569134964098548

Epoch: 5| Step: 5
Training loss: 2.3632831668057825
Validation loss: 2.594397643768181

Epoch: 5| Step: 6
Training loss: 2.9409553820595673
Validation loss: 2.5723290049839638

Epoch: 5| Step: 7
Training loss: 3.117916318356528
Validation loss: 2.5624673812795042

Epoch: 5| Step: 8
Training loss: 3.0020131667913894
Validation loss: 2.523139127545627

Epoch: 5| Step: 9
Training loss: 3.3712303867696005
Validation loss: 2.5145704091597505

Epoch: 5| Step: 10
Training loss: 3.207173984338909
Validation loss: 2.4996660224807794

Epoch: 178| Step: 0
Training loss: 3.096808568894424
Validation loss: 2.497404447749818

Epoch: 5| Step: 1
Training loss: 3.134365543491935
Validation loss: 2.4967506909290367

Epoch: 5| Step: 2
Training loss: 2.3976018487421036
Validation loss: 2.4944876061383665

Epoch: 5| Step: 3
Training loss: 2.5436359239347706
Validation loss: 2.495213583245738

Epoch: 5| Step: 4
Training loss: 3.105968200059014
Validation loss: 2.4964340568284324

Epoch: 5| Step: 5
Training loss: 3.3638807730485403
Validation loss: 2.4957480994875554

Epoch: 5| Step: 6
Training loss: 2.8452786539443387
Validation loss: 2.4917997185257152

Epoch: 5| Step: 7
Training loss: 2.7074587265630625
Validation loss: 2.496785075862523

Epoch: 5| Step: 8
Training loss: 2.7773624639511048
Validation loss: 2.4940540772389785

Epoch: 5| Step: 9
Training loss: 2.609145194344715
Validation loss: 2.4969125048349388

Epoch: 5| Step: 10
Training loss: 2.772701799841358
Validation loss: 2.492878497171458

Epoch: 179| Step: 0
Training loss: 2.4590445852748144
Validation loss: 2.5023063214465906

Epoch: 5| Step: 1
Training loss: 2.2132336450823735
Validation loss: 2.5102639549910784

Epoch: 5| Step: 2
Training loss: 3.0667035584373052
Validation loss: 2.5395609179821554

Epoch: 5| Step: 3
Training loss: 3.1353694536238903
Validation loss: 2.546666603664459

Epoch: 5| Step: 4
Training loss: 3.1157137415270717
Validation loss: 2.5286575181427335

Epoch: 5| Step: 5
Training loss: 2.802672275825547
Validation loss: 2.5350687058094565

Epoch: 5| Step: 6
Training loss: 2.9993676472832296
Validation loss: 2.5056059383265334

Epoch: 5| Step: 7
Training loss: 2.995343886615437
Validation loss: 2.5102963135125145

Epoch: 5| Step: 8
Training loss: 3.0125618829346466
Validation loss: 2.5175737839988837

Epoch: 5| Step: 9
Training loss: 2.819279447173927
Validation loss: 2.509602847047027

Epoch: 5| Step: 10
Training loss: 2.7381479445808536
Validation loss: 2.51702147590966

Epoch: 180| Step: 0
Training loss: 2.8028253945913075
Validation loss: 2.511402301377047

Epoch: 5| Step: 1
Training loss: 2.4002044829042
Validation loss: 2.51439842955775

Epoch: 5| Step: 2
Training loss: 2.928167248790555
Validation loss: 2.510815702359796

Epoch: 5| Step: 3
Training loss: 3.3217241943808573
Validation loss: 2.517036057022052

Epoch: 5| Step: 4
Training loss: 2.7942077876098184
Validation loss: 2.5026848537701123

Epoch: 5| Step: 5
Training loss: 3.012381593268747
Validation loss: 2.509947646732094

Epoch: 5| Step: 6
Training loss: 2.949568286923297
Validation loss: 2.5125195068163735

Epoch: 5| Step: 7
Training loss: 2.932706452343998
Validation loss: 2.5101958031184886

Epoch: 5| Step: 8
Training loss: 2.915090589211688
Validation loss: 2.5012615322899125

Epoch: 5| Step: 9
Training loss: 2.774576818142794
Validation loss: 2.50009199814057

Epoch: 5| Step: 10
Training loss: 2.305894025089585
Validation loss: 2.5072213668010264

Epoch: 181| Step: 0
Training loss: 2.926608733847125
Validation loss: 2.5119593210420326

Epoch: 5| Step: 1
Training loss: 2.227554046968452
Validation loss: 2.5128096154084947

Epoch: 5| Step: 2
Training loss: 3.507712313914164
Validation loss: 2.506580989735337

Epoch: 5| Step: 3
Training loss: 2.6723023903766565
Validation loss: 2.515778086661591

Epoch: 5| Step: 4
Training loss: 2.5457202189071917
Validation loss: 2.5045021598020685

Epoch: 5| Step: 5
Training loss: 2.8776839623528185
Validation loss: 2.538058863479739

Epoch: 5| Step: 6
Training loss: 2.70238983212055
Validation loss: 2.5367730240201625

Epoch: 5| Step: 7
Training loss: 3.021446183400355
Validation loss: 2.556686213072714

Epoch: 5| Step: 8
Training loss: 2.9707602671608164
Validation loss: 2.544941212119603

Epoch: 5| Step: 9
Training loss: 2.834241459738321
Validation loss: 2.552632776766792

Epoch: 5| Step: 10
Training loss: 2.8624527839864466
Validation loss: 2.573471472510125

Epoch: 182| Step: 0
Training loss: 2.3762046368968126
Validation loss: 2.5741749065323605

Epoch: 5| Step: 1
Training loss: 2.9433036449601233
Validation loss: 2.5696345567051777

Epoch: 5| Step: 2
Training loss: 2.3396117233859197
Validation loss: 2.548140906195543

Epoch: 5| Step: 3
Training loss: 3.0085984033129103
Validation loss: 2.5450231212636916

Epoch: 5| Step: 4
Training loss: 3.2753990687316628
Validation loss: 2.5604904963432094

Epoch: 5| Step: 5
Training loss: 2.897719960194981
Validation loss: 2.5453825875561535

Epoch: 5| Step: 6
Training loss: 3.0372911797473896
Validation loss: 2.55744892363062

Epoch: 5| Step: 7
Training loss: 2.437889165867163
Validation loss: 2.531365277901115

Epoch: 5| Step: 8
Training loss: 3.032725496139821
Validation loss: 2.553200461459979

Epoch: 5| Step: 9
Training loss: 2.5916243886003496
Validation loss: 2.5260557840094675

Epoch: 5| Step: 10
Training loss: 3.1297397527270228
Validation loss: 2.5199116142387146

Epoch: 183| Step: 0
Training loss: 2.714888450199674
Validation loss: 2.5162689530238374

Epoch: 5| Step: 1
Training loss: 3.120175719570309
Validation loss: 2.525229248147171

Epoch: 5| Step: 2
Training loss: 3.3256680728078027
Validation loss: 2.5227789479705236

Epoch: 5| Step: 3
Training loss: 2.66738362409718
Validation loss: 2.516694172078195

Epoch: 5| Step: 4
Training loss: 2.3360050663697156
Validation loss: 2.5095741346714306

Epoch: 5| Step: 5
Training loss: 3.2214221417783095
Validation loss: 2.509647036106824

Epoch: 5| Step: 6
Training loss: 2.9157143991058727
Validation loss: 2.5078733176993184

Epoch: 5| Step: 7
Training loss: 2.8156413019620765
Validation loss: 2.4998737610969433

Epoch: 5| Step: 8
Training loss: 3.0785886153973228
Validation loss: 2.5046446047886195

Epoch: 5| Step: 9
Training loss: 2.6791060904086184
Validation loss: 2.508081242798

Epoch: 5| Step: 10
Training loss: 2.053807523436107
Validation loss: 2.5178249296103856

Epoch: 184| Step: 0
Training loss: 3.0810319370693335
Validation loss: 2.5219460298409855

Epoch: 5| Step: 1
Training loss: 3.024574558826721
Validation loss: 2.535890093640525

Epoch: 5| Step: 2
Training loss: 2.0907705943411443
Validation loss: 2.5878040445200576

Epoch: 5| Step: 3
Training loss: 2.72036283162733
Validation loss: 2.5894109234071836

Epoch: 5| Step: 4
Training loss: 2.9249078850220664
Validation loss: 2.628367898911313

Epoch: 5| Step: 5
Training loss: 2.921219206465287
Validation loss: 2.574387096838504

Epoch: 5| Step: 6
Training loss: 3.1924277716989384
Validation loss: 2.5899557547464855

Epoch: 5| Step: 7
Training loss: 3.2062587388423336
Validation loss: 2.541822424328335

Epoch: 5| Step: 8
Training loss: 2.302033114568791
Validation loss: 2.5303967444424904

Epoch: 5| Step: 9
Training loss: 2.7262591436443535
Validation loss: 2.5164565368891356

Epoch: 5| Step: 10
Training loss: 2.919541513426484
Validation loss: 2.5255296332612254

Epoch: 185| Step: 0
Training loss: 3.1771434006979655
Validation loss: 2.509864839067788

Epoch: 5| Step: 1
Training loss: 2.7800708800137435
Validation loss: 2.5198428575062026

Epoch: 5| Step: 2
Training loss: 2.374079274847257
Validation loss: 2.524999081191029

Epoch: 5| Step: 3
Training loss: 2.6414309744480238
Validation loss: 2.5474018956339606

Epoch: 5| Step: 4
Training loss: 2.447285304252979
Validation loss: 2.5607146319576564

Epoch: 5| Step: 5
Training loss: 2.6298965924026283
Validation loss: 2.558883065232454

Epoch: 5| Step: 6
Training loss: 2.9686680832653947
Validation loss: 2.591058161792028

Epoch: 5| Step: 7
Training loss: 2.887267270968579
Validation loss: 2.5923744020200377

Epoch: 5| Step: 8
Training loss: 2.989435349544533
Validation loss: 2.562322644954981

Epoch: 5| Step: 9
Training loss: 3.0998075117831787
Validation loss: 2.5487074126919946

Epoch: 5| Step: 10
Training loss: 3.1270376047496704
Validation loss: 2.55095213447213

Epoch: 186| Step: 0
Training loss: 2.1450201425740363
Validation loss: 2.534945610954627

Epoch: 5| Step: 1
Training loss: 2.5470245879071935
Validation loss: 2.5456603416526464

Epoch: 5| Step: 2
Training loss: 3.066883608843092
Validation loss: 2.5404404059614802

Epoch: 5| Step: 3
Training loss: 2.247576998366558
Validation loss: 2.542584679280669

Epoch: 5| Step: 4
Training loss: 3.0123393288973728
Validation loss: 2.564971137492205

Epoch: 5| Step: 5
Training loss: 2.767682447062361
Validation loss: 2.5457055130679356

Epoch: 5| Step: 6
Training loss: 2.12758400828517
Validation loss: 2.5319117130972715

Epoch: 5| Step: 7
Training loss: 3.3671291549832016
Validation loss: 2.523699009669258

Epoch: 5| Step: 8
Training loss: 3.510226024729738
Validation loss: 2.5138132241866367

Epoch: 5| Step: 9
Training loss: 3.269434700728721
Validation loss: 2.5208863249656313

Epoch: 5| Step: 10
Training loss: 2.6255422667844504
Validation loss: 2.510178375746645

Epoch: 187| Step: 0
Training loss: 2.6557631102479577
Validation loss: 2.516862572363981

Epoch: 5| Step: 1
Training loss: 2.653552132631515
Validation loss: 2.530769073565607

Epoch: 5| Step: 2
Training loss: 2.944399259528456
Validation loss: 2.56185970715627

Epoch: 5| Step: 3
Training loss: 3.184007114651653
Validation loss: 2.5778488533337818

Epoch: 5| Step: 4
Training loss: 3.0525909800174964
Validation loss: 2.615177414703658

Epoch: 5| Step: 5
Training loss: 3.000495233985537
Validation loss: 2.6254080276072016

Epoch: 5| Step: 6
Training loss: 2.7670219040125352
Validation loss: 2.608444678771041

Epoch: 5| Step: 7
Training loss: 3.237474219024401
Validation loss: 2.5806650674664913

Epoch: 5| Step: 8
Training loss: 2.7720126938192085
Validation loss: 2.5558430130453536

Epoch: 5| Step: 9
Training loss: 2.7198093148317235
Validation loss: 2.532604273025217

Epoch: 5| Step: 10
Training loss: 2.3618468416124836
Validation loss: 2.521451795051433

Epoch: 188| Step: 0
Training loss: 2.357594506643916
Validation loss: 2.5190623839272543

Epoch: 5| Step: 1
Training loss: 2.838075110680178
Validation loss: 2.5273806106200487

Epoch: 5| Step: 2
Training loss: 2.8011859936531915
Validation loss: 2.522505217384312

Epoch: 5| Step: 3
Training loss: 2.9725320917936555
Validation loss: 2.521434425142732

Epoch: 5| Step: 4
Training loss: 2.8068134039654606
Validation loss: 2.5212121978975808

Epoch: 5| Step: 5
Training loss: 2.867814912673419
Validation loss: 2.5248470897300686

Epoch: 5| Step: 6
Training loss: 2.807584663534444
Validation loss: 2.5188627609815586

Epoch: 5| Step: 7
Training loss: 3.1238595025758595
Validation loss: 2.5258138313890766

Epoch: 5| Step: 8
Training loss: 3.012711456601801
Validation loss: 2.5197861917908977

Epoch: 5| Step: 9
Training loss: 3.0158879456991077
Validation loss: 2.530528788314729

Epoch: 5| Step: 10
Training loss: 2.681451778333216
Validation loss: 2.523904098762227

Epoch: 189| Step: 0
Training loss: 2.9327020623332287
Validation loss: 2.5279537713090154

Epoch: 5| Step: 1
Training loss: 3.2846821591436637
Validation loss: 2.5441459047140453

Epoch: 5| Step: 2
Training loss: 2.7196831691163506
Validation loss: 2.540211776736299

Epoch: 5| Step: 3
Training loss: 2.550671515214735
Validation loss: 2.543117489040648

Epoch: 5| Step: 4
Training loss: 2.9830092255836207
Validation loss: 2.573024314238294

Epoch: 5| Step: 5
Training loss: 3.0143330232630694
Validation loss: 2.5648437764275975

Epoch: 5| Step: 6
Training loss: 2.087131115876729
Validation loss: 2.5412726585240324

Epoch: 5| Step: 7
Training loss: 2.9436418971077654
Validation loss: 2.524061897797372

Epoch: 5| Step: 8
Training loss: 2.9903040603102404
Validation loss: 2.5017166243016415

Epoch: 5| Step: 9
Training loss: 2.3244606212776775
Validation loss: 2.5011427359573317

Epoch: 5| Step: 10
Training loss: 3.148087323500846
Validation loss: 2.4898155976939536

Epoch: 190| Step: 0
Training loss: 3.2752855132768874
Validation loss: 2.5069951943383697

Epoch: 5| Step: 1
Training loss: 2.8320506128109626
Validation loss: 2.5009692169390507

Epoch: 5| Step: 2
Training loss: 3.014113289428383
Validation loss: 2.503929421812601

Epoch: 5| Step: 3
Training loss: 2.5152434065565252
Validation loss: 2.5145894556548467

Epoch: 5| Step: 4
Training loss: 2.2209580945248604
Validation loss: 2.5070917060150233

Epoch: 5| Step: 5
Training loss: 2.650815723036507
Validation loss: 2.515037582175539

Epoch: 5| Step: 6
Training loss: 2.891852865536323
Validation loss: 2.506079119345533

Epoch: 5| Step: 7
Training loss: 2.81970969227654
Validation loss: 2.5195094101355053

Epoch: 5| Step: 8
Training loss: 2.7609912394295173
Validation loss: 2.5266667194760397

Epoch: 5| Step: 9
Training loss: 3.0106655312776183
Validation loss: 2.5219180069280425

Epoch: 5| Step: 10
Training loss: 2.9716090840487213
Validation loss: 2.542267360406408

Epoch: 191| Step: 0
Training loss: 2.845115250061553
Validation loss: 2.5343660291360215

Epoch: 5| Step: 1
Training loss: 2.486369262259105
Validation loss: 2.5151617639818453

Epoch: 5| Step: 2
Training loss: 2.8444705930474856
Validation loss: 2.518184848581259

Epoch: 5| Step: 3
Training loss: 2.5784593769902724
Validation loss: 2.505368543278514

Epoch: 5| Step: 4
Training loss: 3.0854454710596997
Validation loss: 2.501740862657662

Epoch: 5| Step: 5
Training loss: 3.4519737015978897
Validation loss: 2.506199194587261

Epoch: 5| Step: 6
Training loss: 2.800482953518771
Validation loss: 2.491703766876436

Epoch: 5| Step: 7
Training loss: 2.698644728840304
Validation loss: 2.508392343619759

Epoch: 5| Step: 8
Training loss: 2.9880489084512782
Validation loss: 2.488723508235111

Epoch: 5| Step: 9
Training loss: 3.0300998668768444
Validation loss: 2.503596442579134

Epoch: 5| Step: 10
Training loss: 1.8300984482262683
Validation loss: 2.5112647284135856

Epoch: 192| Step: 0
Training loss: 2.8556689650118647
Validation loss: 2.5063079981526752

Epoch: 5| Step: 1
Training loss: 2.929301569632606
Validation loss: 2.5075541488972264

Epoch: 5| Step: 2
Training loss: 2.7117544916424707
Validation loss: 2.509714373433987

Epoch: 5| Step: 3
Training loss: 2.463152370112063
Validation loss: 2.5250598595784353

Epoch: 5| Step: 4
Training loss: 2.7808793924701387
Validation loss: 2.50811005659053

Epoch: 5| Step: 5
Training loss: 3.046662465043235
Validation loss: 2.527700256754016

Epoch: 5| Step: 6
Training loss: 2.9767508860168905
Validation loss: 2.509132370929192

Epoch: 5| Step: 7
Training loss: 2.6522569150572948
Validation loss: 2.5097761848948643

Epoch: 5| Step: 8
Training loss: 2.8869779106539775
Validation loss: 2.504895123637778

Epoch: 5| Step: 9
Training loss: 2.6905580908844144
Validation loss: 2.5197032801373136

Epoch: 5| Step: 10
Training loss: 2.8400153484735657
Validation loss: 2.5295143050772313

Epoch: 193| Step: 0
Training loss: 1.9648295529044122
Validation loss: 2.5423838670844443

Epoch: 5| Step: 1
Training loss: 3.067859708530223
Validation loss: 2.5682283039040703

Epoch: 5| Step: 2
Training loss: 2.991800865910806
Validation loss: 2.5636123395941794

Epoch: 5| Step: 3
Training loss: 2.4506238104290303
Validation loss: 2.544186881990671

Epoch: 5| Step: 4
Training loss: 2.481301667951059
Validation loss: 2.5043516033199427

Epoch: 5| Step: 5
Training loss: 2.6562117629945483
Validation loss: 2.509641484169812

Epoch: 5| Step: 6
Training loss: 3.341400176447017
Validation loss: 2.4890317216099103

Epoch: 5| Step: 7
Training loss: 3.027015796248395
Validation loss: 2.5051668354825734

Epoch: 5| Step: 8
Training loss: 2.727331014935088
Validation loss: 2.5000564681618194

Epoch: 5| Step: 9
Training loss: 3.077607242007916
Validation loss: 2.500329500449528

Epoch: 5| Step: 10
Training loss: 2.990847613779836
Validation loss: 2.5053127249075016

Epoch: 194| Step: 0
Training loss: 3.121165402464832
Validation loss: 2.5225544549630823

Epoch: 5| Step: 1
Training loss: 2.8939264363164168
Validation loss: 2.532296880187196

Epoch: 5| Step: 2
Training loss: 2.8437204883427474
Validation loss: 2.5501037460735607

Epoch: 5| Step: 3
Training loss: 3.131127567905304
Validation loss: 2.5521023925176722

Epoch: 5| Step: 4
Training loss: 2.347674326898478
Validation loss: 2.5659214231790344

Epoch: 5| Step: 5
Training loss: 3.0465025062769855
Validation loss: 2.545396468376692

Epoch: 5| Step: 6
Training loss: 2.2139665861494344
Validation loss: 2.541884880105919

Epoch: 5| Step: 7
Training loss: 2.8220894834469346
Validation loss: 2.556304375821606

Epoch: 5| Step: 8
Training loss: 2.51112313572453
Validation loss: 2.542476152621247

Epoch: 5| Step: 9
Training loss: 2.951017404751204
Validation loss: 2.55098969409485

Epoch: 5| Step: 10
Training loss: 2.758266681737908
Validation loss: 2.539574092190774

Epoch: 195| Step: 0
Training loss: 3.014991496059894
Validation loss: 2.529928442992733

Epoch: 5| Step: 1
Training loss: 2.804105310397039
Validation loss: 2.5174745071400557

Epoch: 5| Step: 2
Training loss: 2.419624513547517
Validation loss: 2.5051097753696667

Epoch: 5| Step: 3
Training loss: 3.2950065344136443
Validation loss: 2.499355215579963

Epoch: 5| Step: 4
Training loss: 2.5450738259870027
Validation loss: 2.498830013913752

Epoch: 5| Step: 5
Training loss: 3.100531803169156
Validation loss: 2.506251731194597

Epoch: 5| Step: 6
Training loss: 2.4452953398958592
Validation loss: 2.501875674172303

Epoch: 5| Step: 7
Training loss: 3.1356229661429675
Validation loss: 2.5055778482811455

Epoch: 5| Step: 8
Training loss: 2.7315133079164124
Validation loss: 2.5159654875410995

Epoch: 5| Step: 9
Training loss: 2.7625299581568985
Validation loss: 2.530327700184523

Epoch: 5| Step: 10
Training loss: 2.6254016024055393
Validation loss: 2.5440704714862403

Epoch: 196| Step: 0
Training loss: 2.1964109665965954
Validation loss: 2.539130441972979

Epoch: 5| Step: 1
Training loss: 2.6531504779216903
Validation loss: 2.533206858322149

Epoch: 5| Step: 2
Training loss: 2.93013538243116
Validation loss: 2.515100062453144

Epoch: 5| Step: 3
Training loss: 2.7884040290305436
Validation loss: 2.521657784667033

Epoch: 5| Step: 4
Training loss: 2.9580086185105374
Validation loss: 2.515497539564775

Epoch: 5| Step: 5
Training loss: 2.901767843002789
Validation loss: 2.5154212395773397

Epoch: 5| Step: 6
Training loss: 2.421983876395954
Validation loss: 2.5132812009770067

Epoch: 5| Step: 7
Training loss: 2.86989538394181
Validation loss: 2.5040630773763652

Epoch: 5| Step: 8
Training loss: 2.9131155648740616
Validation loss: 2.5290832644714794

Epoch: 5| Step: 9
Training loss: 3.248171071644618
Validation loss: 2.522861652863935

Epoch: 5| Step: 10
Training loss: 2.767513858584722
Validation loss: 2.5297512269546587

Epoch: 197| Step: 0
Training loss: 2.8797894265759183
Validation loss: 2.548009092865621

Epoch: 5| Step: 1
Training loss: 2.7387472020199795
Validation loss: 2.553029530662732

Epoch: 5| Step: 2
Training loss: 3.070784282594512
Validation loss: 2.558489037720724

Epoch: 5| Step: 3
Training loss: 2.5503851917528566
Validation loss: 2.5457948303721434

Epoch: 5| Step: 4
Training loss: 2.652201091092829
Validation loss: 2.552917958428847

Epoch: 5| Step: 5
Training loss: 3.101630913967207
Validation loss: 2.543605700919075

Epoch: 5| Step: 6
Training loss: 3.098301169762198
Validation loss: 2.5267529227875682

Epoch: 5| Step: 7
Training loss: 2.91725388927954
Validation loss: 2.531119490742636

Epoch: 5| Step: 8
Training loss: 2.681555272221424
Validation loss: 2.530282470047682

Epoch: 5| Step: 9
Training loss: 2.527288563050629
Validation loss: 2.526907406975081

Epoch: 5| Step: 10
Training loss: 2.462747059932724
Validation loss: 2.5599135765233823

Epoch: 198| Step: 0
Training loss: 3.0088868439462546
Validation loss: 2.5470319838326705

Epoch: 5| Step: 1
Training loss: 2.8171479707421114
Validation loss: 2.534081106730182

Epoch: 5| Step: 2
Training loss: 2.9034705868967587
Validation loss: 2.5342072379574114

Epoch: 5| Step: 3
Training loss: 2.7941039439358413
Validation loss: 2.5438304494847954

Epoch: 5| Step: 4
Training loss: 2.59237478176377
Validation loss: 2.539698240141405

Epoch: 5| Step: 5
Training loss: 2.873570957787275
Validation loss: 2.532171690528302

Epoch: 5| Step: 6
Training loss: 2.4497641118991385
Validation loss: 2.512749122256535

Epoch: 5| Step: 7
Training loss: 2.5056282585048635
Validation loss: 2.5099574816971173

Epoch: 5| Step: 8
Training loss: 2.708940897553505
Validation loss: 2.5044150733997377

Epoch: 5| Step: 9
Training loss: 3.2362204184419703
Validation loss: 2.5044501587049752

Epoch: 5| Step: 10
Training loss: 2.8394963236907733
Validation loss: 2.5027398836264965

Epoch: 199| Step: 0
Training loss: 3.0752748568130115
Validation loss: 2.517759731605301

Epoch: 5| Step: 1
Training loss: 2.7064800279219736
Validation loss: 2.5168593189986317

Epoch: 5| Step: 2
Training loss: 2.5119561399105335
Validation loss: 2.5432936310892504

Epoch: 5| Step: 3
Training loss: 2.778043291329964
Validation loss: 2.525128580858594

Epoch: 5| Step: 4
Training loss: 2.809429102833901
Validation loss: 2.539288594644617

Epoch: 5| Step: 5
Training loss: 2.337959664583415
Validation loss: 2.5532147978032396

Epoch: 5| Step: 6
Training loss: 2.819031569803118
Validation loss: 2.5781098962902598

Epoch: 5| Step: 7
Training loss: 3.3013431589948934
Validation loss: 2.589476767680284

Epoch: 5| Step: 8
Training loss: 2.2967863519909497
Validation loss: 2.5943282612388754

Epoch: 5| Step: 9
Training loss: 2.94231782645834
Validation loss: 2.549064528017916

Epoch: 5| Step: 10
Training loss: 3.0236376319118947
Validation loss: 2.5348725825014453

Epoch: 200| Step: 0
Training loss: 2.909501256774327
Validation loss: 2.525134634796164

Epoch: 5| Step: 1
Training loss: 2.3805250851632103
Validation loss: 2.5100564297804757

Epoch: 5| Step: 2
Training loss: 2.73671025419972
Validation loss: 2.517881551901579

Epoch: 5| Step: 3
Training loss: 2.7501098437479627
Validation loss: 2.517740364931107

Epoch: 5| Step: 4
Training loss: 2.726390931598375
Validation loss: 2.507137843298662

Epoch: 5| Step: 5
Training loss: 2.521550184317427
Validation loss: 2.4972764202358415

Epoch: 5| Step: 6
Training loss: 2.9449917646464563
Validation loss: 2.5054271916986197

Epoch: 5| Step: 7
Training loss: 3.0099622302046085
Validation loss: 2.5080147115653357

Epoch: 5| Step: 8
Training loss: 2.121247512555167
Validation loss: 2.503437703770835

Epoch: 5| Step: 9
Training loss: 3.547135532574164
Validation loss: 2.5155967803046906

Epoch: 5| Step: 10
Training loss: 2.8462945641608637
Validation loss: 2.5468302700861636

Epoch: 201| Step: 0
Training loss: 2.5782295899416963
Validation loss: 2.5578614928713885

Epoch: 5| Step: 1
Training loss: 2.8829019837589738
Validation loss: 2.5846768215825637

Epoch: 5| Step: 2
Training loss: 2.7146619557500307
Validation loss: 2.59006003224372

Epoch: 5| Step: 3
Training loss: 3.0428496546816266
Validation loss: 2.583223901932322

Epoch: 5| Step: 4
Training loss: 2.6725214126057404
Validation loss: 2.55874430797345

Epoch: 5| Step: 5
Training loss: 3.0913585320781767
Validation loss: 2.5378167551235356

Epoch: 5| Step: 6
Training loss: 2.987719833394096
Validation loss: 2.5234275804215027

Epoch: 5| Step: 7
Training loss: 2.7200154834194428
Validation loss: 2.5161739100305276

Epoch: 5| Step: 8
Training loss: 2.414130052528749
Validation loss: 2.5168921346078705

Epoch: 5| Step: 9
Training loss: 2.321064939419604
Validation loss: 2.51000045418965

Epoch: 5| Step: 10
Training loss: 3.259309639645703
Validation loss: 2.513850681949248

Epoch: 202| Step: 0
Training loss: 3.209680464340104
Validation loss: 2.509188796021579

Epoch: 5| Step: 1
Training loss: 2.036972670389102
Validation loss: 2.511949864384577

Epoch: 5| Step: 2
Training loss: 3.085802756156385
Validation loss: 2.5093782725084433

Epoch: 5| Step: 3
Training loss: 3.2890104529822737
Validation loss: 2.5076685143970594

Epoch: 5| Step: 4
Training loss: 2.844091373955521
Validation loss: 2.509961072895013

Epoch: 5| Step: 5
Training loss: 2.6277214656743535
Validation loss: 2.5094990143021767

Epoch: 5| Step: 6
Training loss: 2.4204120770651296
Validation loss: 2.523044111682991

Epoch: 5| Step: 7
Training loss: 2.392072351675558
Validation loss: 2.5284815559459357

Epoch: 5| Step: 8
Training loss: 2.72996112432502
Validation loss: 2.5500691712737784

Epoch: 5| Step: 9
Training loss: 2.918815928986809
Validation loss: 2.5742310213365434

Epoch: 5| Step: 10
Training loss: 2.8642556482795265
Validation loss: 2.5854816204082205

Epoch: 203| Step: 0
Training loss: 3.1620149745598645
Validation loss: 2.591966682396556

Epoch: 5| Step: 1
Training loss: 2.986434465589483
Validation loss: 2.596190363983537

Epoch: 5| Step: 2
Training loss: 2.9363436756480934
Validation loss: 2.585737921038292

Epoch: 5| Step: 3
Training loss: 2.2592954418478977
Validation loss: 2.591344247213922

Epoch: 5| Step: 4
Training loss: 2.0565169280004936
Validation loss: 2.548510791834251

Epoch: 5| Step: 5
Training loss: 2.703305188827042
Validation loss: 2.5550295096045557

Epoch: 5| Step: 6
Training loss: 2.616731518551233
Validation loss: 2.5330797431468466

Epoch: 5| Step: 7
Training loss: 3.1961962683215064
Validation loss: 2.5450998886094287

Epoch: 5| Step: 8
Training loss: 2.8005399081262987
Validation loss: 2.5644135612335783

Epoch: 5| Step: 9
Training loss: 2.6771697291424155
Validation loss: 2.5681234523930336

Epoch: 5| Step: 10
Training loss: 2.988339172998677
Validation loss: 2.5438909976475133

Epoch: 204| Step: 0
Training loss: 2.31657483675883
Validation loss: 2.5651529227025263

Epoch: 5| Step: 1
Training loss: 2.8678240576157132
Validation loss: 2.5653778481522784

Epoch: 5| Step: 2
Training loss: 2.5816074779597242
Validation loss: 2.558982343549535

Epoch: 5| Step: 3
Training loss: 2.9463839011501105
Validation loss: 2.581051977904051

Epoch: 5| Step: 4
Training loss: 3.220876047131638
Validation loss: 2.604380306873785

Epoch: 5| Step: 5
Training loss: 2.483384804757607
Validation loss: 2.5517677163867316

Epoch: 5| Step: 6
Training loss: 3.307814541231804
Validation loss: 2.5451300485546007

Epoch: 5| Step: 7
Training loss: 2.6214936771378414
Validation loss: 2.5216980980323016

Epoch: 5| Step: 8
Training loss: 2.4890242923886032
Validation loss: 2.514252039530102

Epoch: 5| Step: 9
Training loss: 2.774289282436863
Validation loss: 2.5076813373288354

Epoch: 5| Step: 10
Training loss: 3.0578292729264205
Validation loss: 2.5065373469955454

Epoch: 205| Step: 0
Training loss: 2.791976048041626
Validation loss: 2.5056273345976905

Epoch: 5| Step: 1
Training loss: 2.951770613175695
Validation loss: 2.5071883366785013

Epoch: 5| Step: 2
Training loss: 2.480752667375749
Validation loss: 2.503173630846932

Epoch: 5| Step: 3
Training loss: 2.597484428058021
Validation loss: 2.5207389061969128

Epoch: 5| Step: 4
Training loss: 2.6794758259885243
Validation loss: 2.5117959085450807

Epoch: 5| Step: 5
Training loss: 2.884374014708577
Validation loss: 2.5243866042103673

Epoch: 5| Step: 6
Training loss: 2.6740048491520305
Validation loss: 2.534008401385252

Epoch: 5| Step: 7
Training loss: 2.739947151036387
Validation loss: 2.5440027188852623

Epoch: 5| Step: 8
Training loss: 3.034153128152586
Validation loss: 2.5640725303698124

Epoch: 5| Step: 9
Training loss: 3.082338963221257
Validation loss: 2.597436204229279

Epoch: 5| Step: 10
Training loss: 2.764204274580018
Validation loss: 2.6110416984546485

Epoch: 206| Step: 0
Training loss: 2.7348989802085564
Validation loss: 2.589759079523458

Epoch: 5| Step: 1
Training loss: 2.6010316415964527
Validation loss: 2.5483523528787653

Epoch: 5| Step: 2
Training loss: 2.44888405589192
Validation loss: 2.553616966802922

Epoch: 5| Step: 3
Training loss: 3.101046809989979
Validation loss: 2.5412286531962214

Epoch: 5| Step: 4
Training loss: 2.7848780253630325
Validation loss: 2.5370044813033488

Epoch: 5| Step: 5
Training loss: 2.638426548348749
Validation loss: 2.531667963743335

Epoch: 5| Step: 6
Training loss: 3.2116440044475216
Validation loss: 2.5459121382824494

Epoch: 5| Step: 7
Training loss: 2.789068654798881
Validation loss: 2.5518726371564187

Epoch: 5| Step: 8
Training loss: 2.4558864528303332
Validation loss: 2.546303154480483

Epoch: 5| Step: 9
Training loss: 2.601118445087566
Validation loss: 2.5373445520736517

Epoch: 5| Step: 10
Training loss: 3.2441462103917904
Validation loss: 2.5450967458786633

Epoch: 207| Step: 0
Training loss: 2.1218544735709233
Validation loss: 2.544911647300702

Epoch: 5| Step: 1
Training loss: 2.838558950575724
Validation loss: 2.5224738529276713

Epoch: 5| Step: 2
Training loss: 2.824337356630549
Validation loss: 2.5166270082664832

Epoch: 5| Step: 3
Training loss: 2.7284636332119234
Validation loss: 2.4948409408302497

Epoch: 5| Step: 4
Training loss: 2.564224779199694
Validation loss: 2.5053652606618435

Epoch: 5| Step: 5
Training loss: 3.0893927822569798
Validation loss: 2.531073301390037

Epoch: 5| Step: 6
Training loss: 2.96735775073954
Validation loss: 2.5619182481555587

Epoch: 5| Step: 7
Training loss: 2.9025157605383196
Validation loss: 2.6191363094238276

Epoch: 5| Step: 8
Training loss: 3.0404154847463287
Validation loss: 2.701064193510982

Epoch: 5| Step: 9
Training loss: 3.010450915149492
Validation loss: 2.632555554011424

Epoch: 5| Step: 10
Training loss: 2.5505720581452906
Validation loss: 2.56939797792229

Epoch: 208| Step: 0
Training loss: 2.5732659992079023
Validation loss: 2.5223863279631202

Epoch: 5| Step: 1
Training loss: 2.7439088988292712
Validation loss: 2.4966656650424173

Epoch: 5| Step: 2
Training loss: 3.136096783419342
Validation loss: 2.4858840947887013

Epoch: 5| Step: 3
Training loss: 3.165113938436677
Validation loss: 2.4937406957687522

Epoch: 5| Step: 4
Training loss: 2.518474410435426
Validation loss: 2.4828859844526097

Epoch: 5| Step: 5
Training loss: 2.0375003604069493
Validation loss: 2.479732275872338

Epoch: 5| Step: 6
Training loss: 2.5237695812053316
Validation loss: 2.481472502107713

Epoch: 5| Step: 7
Training loss: 3.0568786723400105
Validation loss: 2.48773776438366

Epoch: 5| Step: 8
Training loss: 3.065209105236653
Validation loss: 2.495357936157003

Epoch: 5| Step: 9
Training loss: 2.721227196951401
Validation loss: 2.500204298429236

Epoch: 5| Step: 10
Training loss: 2.896113613113027
Validation loss: 2.508191133501498

Epoch: 209| Step: 0
Training loss: 3.3063167226364962
Validation loss: 2.5245317261859674

Epoch: 5| Step: 1
Training loss: 2.8464429910707882
Validation loss: 2.5476244456616004

Epoch: 5| Step: 2
Training loss: 2.7863539251333376
Validation loss: 2.5813733312446954

Epoch: 5| Step: 3
Training loss: 3.0424749441376777
Validation loss: 2.5478503047534216

Epoch: 5| Step: 4
Training loss: 2.6419135566968026
Validation loss: 2.5583136212224606

Epoch: 5| Step: 5
Training loss: 2.830193200677583
Validation loss: 2.574950309056527

Epoch: 5| Step: 6
Training loss: 3.0037662389144053
Validation loss: 2.5883899293570223

Epoch: 5| Step: 7
Training loss: 2.0625373374564884
Validation loss: 2.5944256555467837

Epoch: 5| Step: 8
Training loss: 2.2972856011873777
Validation loss: 2.6024279825233236

Epoch: 5| Step: 9
Training loss: 2.684576973294529
Validation loss: 2.612633225999179

Epoch: 5| Step: 10
Training loss: 2.7896494528294467
Validation loss: 2.6125612573496952

Epoch: 210| Step: 0
Training loss: 1.8756228366166896
Validation loss: 2.573582151199508

Epoch: 5| Step: 1
Training loss: 2.7225656152249704
Validation loss: 2.582139081190934

Epoch: 5| Step: 2
Training loss: 2.872023990987814
Validation loss: 2.5863662372739324

Epoch: 5| Step: 3
Training loss: 2.696152619719815
Validation loss: 2.610747864039143

Epoch: 5| Step: 4
Training loss: 2.386181859941396
Validation loss: 2.6159016589449493

Epoch: 5| Step: 5
Training loss: 2.857366638275492
Validation loss: 2.6154325235660134

Epoch: 5| Step: 6
Training loss: 2.8923343037959066
Validation loss: 2.5997717792694512

Epoch: 5| Step: 7
Training loss: 2.579130681721028
Validation loss: 2.5735613333443297

Epoch: 5| Step: 8
Training loss: 2.77942082979141
Validation loss: 2.5711466524142317

Epoch: 5| Step: 9
Training loss: 3.301707843085349
Validation loss: 2.55761891756432

Epoch: 5| Step: 10
Training loss: 3.1282374587599118
Validation loss: 2.529402776520253

Epoch: 211| Step: 0
Training loss: 2.579741277659809
Validation loss: 2.5134030807517873

Epoch: 5| Step: 1
Training loss: 2.7773265811266095
Validation loss: 2.500356723089642

Epoch: 5| Step: 2
Training loss: 2.4997862724498003
Validation loss: 2.510991018837694

Epoch: 5| Step: 3
Training loss: 2.960839262366879
Validation loss: 2.5051180738193737

Epoch: 5| Step: 4
Training loss: 2.848179312601037
Validation loss: 2.4984602483152827

Epoch: 5| Step: 5
Training loss: 2.924350607750511
Validation loss: 2.4982137328235634

Epoch: 5| Step: 6
Training loss: 2.8945090103839455
Validation loss: 2.4955944374727594

Epoch: 5| Step: 7
Training loss: 2.420663148957119
Validation loss: 2.5124661242681254

Epoch: 5| Step: 8
Training loss: 2.7414005378409247
Validation loss: 2.5202320805277347

Epoch: 5| Step: 9
Training loss: 2.6857545196713906
Validation loss: 2.555848531825449

Epoch: 5| Step: 10
Training loss: 2.904057814219627
Validation loss: 2.6037247389036864

Epoch: 212| Step: 0
Training loss: 3.1444417810447507
Validation loss: 2.654285178585484

Epoch: 5| Step: 1
Training loss: 2.766331986403039
Validation loss: 2.6269174322315614

Epoch: 5| Step: 2
Training loss: 2.8995308266316817
Validation loss: 2.6201718428692247

Epoch: 5| Step: 3
Training loss: 2.3879116841827086
Validation loss: 2.593739800767333

Epoch: 5| Step: 4
Training loss: 2.9797322374415027
Validation loss: 2.5855597857851818

Epoch: 5| Step: 5
Training loss: 2.3086484847704534
Validation loss: 2.5478428347321476

Epoch: 5| Step: 6
Training loss: 2.3005636270964853
Validation loss: 2.530141605240713

Epoch: 5| Step: 7
Training loss: 3.004646676312391
Validation loss: 2.4849634075460325

Epoch: 5| Step: 8
Training loss: 3.3037569796618005
Validation loss: 2.4800233326852013

Epoch: 5| Step: 9
Training loss: 2.67645460135106
Validation loss: 2.4963467552047125

Epoch: 5| Step: 10
Training loss: 2.5608964880684497
Validation loss: 2.4904810318064783

Epoch: 213| Step: 0
Training loss: 3.0814932582075234
Validation loss: 2.49730085875208

Epoch: 5| Step: 1
Training loss: 2.9992347377024062
Validation loss: 2.5191815075588417

Epoch: 5| Step: 2
Training loss: 2.3000599065525376
Validation loss: 2.536172191736128

Epoch: 5| Step: 3
Training loss: 2.7072773170653543
Validation loss: 2.565095092164391

Epoch: 5| Step: 4
Training loss: 3.0382840059188934
Validation loss: 2.563406947099415

Epoch: 5| Step: 5
Training loss: 2.868793588610504
Validation loss: 2.587412220684277

Epoch: 5| Step: 6
Training loss: 2.6998035112163303
Validation loss: 2.6233969577661864

Epoch: 5| Step: 7
Training loss: 2.775115201466183
Validation loss: 2.6603337879273825

Epoch: 5| Step: 8
Training loss: 2.710520247743546
Validation loss: 2.645292382964876

Epoch: 5| Step: 9
Training loss: 2.933029018858127
Validation loss: 2.623327040525269

Epoch: 5| Step: 10
Training loss: 2.308538807378143
Validation loss: 2.5957253035255845

Epoch: 214| Step: 0
Training loss: 2.4490811980101888
Validation loss: 2.5630067443817173

Epoch: 5| Step: 1
Training loss: 3.014552899259537
Validation loss: 2.5518609725854615

Epoch: 5| Step: 2
Training loss: 2.862087776453495
Validation loss: 2.541536586733755

Epoch: 5| Step: 3
Training loss: 2.721347488808842
Validation loss: 2.5216024397263768

Epoch: 5| Step: 4
Training loss: 2.6715475852193897
Validation loss: 2.519742576319904

Epoch: 5| Step: 5
Training loss: 2.774200248602855
Validation loss: 2.5195274017856595

Epoch: 5| Step: 6
Training loss: 2.8646678195400934
Validation loss: 2.518238215267913

Epoch: 5| Step: 7
Training loss: 2.5070240528244696
Validation loss: 2.525881323352117

Epoch: 5| Step: 8
Training loss: 2.9482103253184726
Validation loss: 2.5195235271101786

Epoch: 5| Step: 9
Training loss: 2.6967042729695168
Validation loss: 2.5204500886561596

Epoch: 5| Step: 10
Training loss: 2.623276008147655
Validation loss: 2.5128054467503276

Epoch: 215| Step: 0
Training loss: 2.825723882783128
Validation loss: 2.541689903062956

Epoch: 5| Step: 1
Training loss: 2.837868109533016
Validation loss: 2.522064105483559

Epoch: 5| Step: 2
Training loss: 3.046452576135893
Validation loss: 2.520417011174919

Epoch: 5| Step: 3
Training loss: 2.9954440172083823
Validation loss: 2.5219961352571176

Epoch: 5| Step: 4
Training loss: 2.5538342652163464
Validation loss: 2.511762575225767

Epoch: 5| Step: 5
Training loss: 2.5736913299913713
Validation loss: 2.5356729994777365

Epoch: 5| Step: 6
Training loss: 2.7476884490234204
Validation loss: 2.5186236096865215

Epoch: 5| Step: 7
Training loss: 2.856689359232783
Validation loss: 2.5285814114709853

Epoch: 5| Step: 8
Training loss: 2.715455788980321
Validation loss: 2.540118839709407

Epoch: 5| Step: 9
Training loss: 2.3935171347714603
Validation loss: 2.5365804081201446

Epoch: 5| Step: 10
Training loss: 2.524242449890917
Validation loss: 2.5364391077455157

Epoch: 216| Step: 0
Training loss: 1.9451037681768626
Validation loss: 2.5498766136760067

Epoch: 5| Step: 1
Training loss: 2.4873242416781425
Validation loss: 2.5422483720284754

Epoch: 5| Step: 2
Training loss: 3.083613889834788
Validation loss: 2.59129399773518

Epoch: 5| Step: 3
Training loss: 3.2727350104847384
Validation loss: 2.60185125836847

Epoch: 5| Step: 4
Training loss: 2.6064553744771124
Validation loss: 2.5847925146421327

Epoch: 5| Step: 5
Training loss: 2.7434512972894862
Validation loss: 2.5920724030929665

Epoch: 5| Step: 6
Training loss: 2.6365135734696303
Validation loss: 2.5731081918494065

Epoch: 5| Step: 7
Training loss: 2.5106368753134807
Validation loss: 2.589782127110383

Epoch: 5| Step: 8
Training loss: 2.8825031724500443
Validation loss: 2.5757044477016584

Epoch: 5| Step: 9
Training loss: 2.66017471284663
Validation loss: 2.561045385125404

Epoch: 5| Step: 10
Training loss: 3.128355894608623
Validation loss: 2.5400855985007125

Epoch: 217| Step: 0
Training loss: 3.010674083928088
Validation loss: 2.552910009167963

Epoch: 5| Step: 1
Training loss: 2.516695635883596
Validation loss: 2.5444340274996575

Epoch: 5| Step: 2
Training loss: 2.8326225137098273
Validation loss: 2.52065264316049

Epoch: 5| Step: 3
Training loss: 3.092272473093463
Validation loss: 2.5348593803183315

Epoch: 5| Step: 4
Training loss: 2.429732049368011
Validation loss: 2.5320705236992347

Epoch: 5| Step: 5
Training loss: 2.608750959687726
Validation loss: 2.5471406253693534

Epoch: 5| Step: 6
Training loss: 2.7179540587157294
Validation loss: 2.553018247937842

Epoch: 5| Step: 7
Training loss: 2.4058368873195564
Validation loss: 2.5647723099713517

Epoch: 5| Step: 8
Training loss: 2.234912940939011
Validation loss: 2.5900730173933963

Epoch: 5| Step: 9
Training loss: 2.9724029553407556
Validation loss: 2.5991138139906025

Epoch: 5| Step: 10
Training loss: 2.949719761614331
Validation loss: 2.611148480360519

Epoch: 218| Step: 0
Training loss: 2.74618977233658
Validation loss: 2.60367460823745

Epoch: 5| Step: 1
Training loss: 2.520031404753684
Validation loss: 2.557895500307832

Epoch: 5| Step: 2
Training loss: 2.8944421257681743
Validation loss: 2.511079546404265

Epoch: 5| Step: 3
Training loss: 2.613989855115449
Validation loss: 2.5077148577964223

Epoch: 5| Step: 4
Training loss: 3.1345074793923686
Validation loss: 2.4898603181157655

Epoch: 5| Step: 5
Training loss: 2.36981216813047
Validation loss: 2.484440082469699

Epoch: 5| Step: 6
Training loss: 2.47272519080309
Validation loss: 2.4880698315403365

Epoch: 5| Step: 7
Training loss: 2.937811165419682
Validation loss: 2.4878621841159108

Epoch: 5| Step: 8
Training loss: 2.9864030108845676
Validation loss: 2.5034115576380924

Epoch: 5| Step: 9
Training loss: 2.9437115514880627
Validation loss: 2.5234289133290337

Epoch: 5| Step: 10
Training loss: 2.474269732235195
Validation loss: 2.5594573666865608

Epoch: 219| Step: 0
Training loss: 2.9722949897517768
Validation loss: 2.570737665253506

Epoch: 5| Step: 1
Training loss: 2.7057783742229513
Validation loss: 2.561247871111494

Epoch: 5| Step: 2
Training loss: 2.9865074328424734
Validation loss: 2.5636901392723783

Epoch: 5| Step: 3
Training loss: 2.5464491224825863
Validation loss: 2.5427191113875645

Epoch: 5| Step: 4
Training loss: 3.236974583707201
Validation loss: 2.529487858391343

Epoch: 5| Step: 5
Training loss: 2.301536863434157
Validation loss: 2.5323699798814037

Epoch: 5| Step: 6
Training loss: 2.526779748639031
Validation loss: 2.5512083648557575

Epoch: 5| Step: 7
Training loss: 2.332982774921897
Validation loss: 2.526779440204233

Epoch: 5| Step: 8
Training loss: 3.135480168270901
Validation loss: 2.5434064167612696

Epoch: 5| Step: 9
Training loss: 1.9494749218134146
Validation loss: 2.5283796574324686

Epoch: 5| Step: 10
Training loss: 2.9865982801691584
Validation loss: 2.542353347848467

Epoch: 220| Step: 0
Training loss: 2.5769349096838976
Validation loss: 2.549205787284841

Epoch: 5| Step: 1
Training loss: 2.7241698864295145
Validation loss: 2.5494307299797168

Epoch: 5| Step: 2
Training loss: 2.7738072968144056
Validation loss: 2.5563739178839135

Epoch: 5| Step: 3
Training loss: 2.8925181195244645
Validation loss: 2.560770095661016

Epoch: 5| Step: 4
Training loss: 3.2920292682760333
Validation loss: 2.541986659815977

Epoch: 5| Step: 5
Training loss: 2.161630854941113
Validation loss: 2.526882058645194

Epoch: 5| Step: 6
Training loss: 2.0767135989956387
Validation loss: 2.5351916207573657

Epoch: 5| Step: 7
Training loss: 2.8320474137469764
Validation loss: 2.558380459234544

Epoch: 5| Step: 8
Training loss: 2.5656244721685093
Validation loss: 2.5770603700142085

Epoch: 5| Step: 9
Training loss: 2.9935051230543985
Validation loss: 2.5844841146142747

Epoch: 5| Step: 10
Training loss: 2.5463762789664948
Validation loss: 2.5717148757553425

Epoch: 221| Step: 0
Training loss: 2.5084111815208074
Validation loss: 2.560005024841271

Epoch: 5| Step: 1
Training loss: 2.4857213432856997
Validation loss: 2.583919525789924

Epoch: 5| Step: 2
Training loss: 2.768189184427034
Validation loss: 2.573931499163756

Epoch: 5| Step: 3
Training loss: 2.7630586948131715
Validation loss: 2.5792037879556893

Epoch: 5| Step: 4
Training loss: 2.890311394253137
Validation loss: 2.55538172548276

Epoch: 5| Step: 5
Training loss: 2.980786627820459
Validation loss: 2.5316589412020334

Epoch: 5| Step: 6
Training loss: 2.9346673171883118
Validation loss: 2.5338221184372003

Epoch: 5| Step: 7
Training loss: 2.4193060262944717
Validation loss: 2.515210368643338

Epoch: 5| Step: 8
Training loss: 2.177159638109533
Validation loss: 2.5174952343118857

Epoch: 5| Step: 9
Training loss: 2.990693598392
Validation loss: 2.507644145227687

Epoch: 5| Step: 10
Training loss: 2.621239921030178
Validation loss: 2.511908527065572

Epoch: 222| Step: 0
Training loss: 2.352123915865909
Validation loss: 2.5321939709255865

Epoch: 5| Step: 1
Training loss: 2.475130936983416
Validation loss: 2.5623381048564395

Epoch: 5| Step: 2
Training loss: 2.747663979604878
Validation loss: 2.5727487122086

Epoch: 5| Step: 3
Training loss: 2.694910257151043
Validation loss: 2.5944865495883698

Epoch: 5| Step: 4
Training loss: 3.0438989434429433
Validation loss: 2.583863573770571

Epoch: 5| Step: 5
Training loss: 2.838718028524706
Validation loss: 2.605440321676181

Epoch: 5| Step: 6
Training loss: 2.4929234485341634
Validation loss: 2.617021621837317

Epoch: 5| Step: 7
Training loss: 2.8418317759884344
Validation loss: 2.597496555923831

Epoch: 5| Step: 8
Training loss: 2.062471331772824
Validation loss: 2.5682475064689125

Epoch: 5| Step: 9
Training loss: 2.882743855307811
Validation loss: 2.561143009094308

Epoch: 5| Step: 10
Training loss: 2.955043754705524
Validation loss: 2.5496060859563703

Epoch: 223| Step: 0
Training loss: 2.788395649665281
Validation loss: 2.522242613266638

Epoch: 5| Step: 1
Training loss: 2.8478129779401278
Validation loss: 2.5288752682861615

Epoch: 5| Step: 2
Training loss: 2.7325895747434488
Validation loss: 2.512826677656333

Epoch: 5| Step: 3
Training loss: 3.2725228645569233
Validation loss: 2.5228681949178737

Epoch: 5| Step: 4
Training loss: 2.4972952516499873
Validation loss: 2.531696707056989

Epoch: 5| Step: 5
Training loss: 2.578754047754895
Validation loss: 2.542004932088932

Epoch: 5| Step: 6
Training loss: 2.981095674307109
Validation loss: 2.5365787081760076

Epoch: 5| Step: 7
Training loss: 2.6156075790353803
Validation loss: 2.5352344092288708

Epoch: 5| Step: 8
Training loss: 2.505241811506157
Validation loss: 2.507665191853614

Epoch: 5| Step: 9
Training loss: 2.3814118818390817
Validation loss: 2.5123768481138122

Epoch: 5| Step: 10
Training loss: 2.4826617781525755
Validation loss: 2.5189941657984014

Epoch: 224| Step: 0
Training loss: 3.1479293375288315
Validation loss: 2.5224041690004215

Epoch: 5| Step: 1
Training loss: 2.763378373052414
Validation loss: 2.535481942047264

Epoch: 5| Step: 2
Training loss: 2.394598756121748
Validation loss: 2.5556830444907472

Epoch: 5| Step: 3
Training loss: 2.461438131121691
Validation loss: 2.583554792951265

Epoch: 5| Step: 4
Training loss: 2.503467253528543
Validation loss: 2.6203842737246372

Epoch: 5| Step: 5
Training loss: 2.6022564303322073
Validation loss: 2.670546744534914

Epoch: 5| Step: 6
Training loss: 2.6817406443303518
Validation loss: 2.6356763678121933

Epoch: 5| Step: 7
Training loss: 2.1326599066506837
Validation loss: 2.618638861032522

Epoch: 5| Step: 8
Training loss: 3.185469934597348
Validation loss: 2.578810505299472

Epoch: 5| Step: 9
Training loss: 2.9308687397287247
Validation loss: 2.5731045752031747

Epoch: 5| Step: 10
Training loss: 2.6971508004444495
Validation loss: 2.52570112389995

Epoch: 225| Step: 0
Training loss: 2.7004242563712455
Validation loss: 2.5167175307251264

Epoch: 5| Step: 1
Training loss: 2.7047542006247296
Validation loss: 2.490940370995507

Epoch: 5| Step: 2
Training loss: 2.872025319213621
Validation loss: 2.5061072405988183

Epoch: 5| Step: 3
Training loss: 2.4932508920445917
Validation loss: 2.5111773130015105

Epoch: 5| Step: 4
Training loss: 2.620227380597244
Validation loss: 2.5172605411033446

Epoch: 5| Step: 5
Training loss: 2.739221256440567
Validation loss: 2.53115748037991

Epoch: 5| Step: 6
Training loss: 2.81518070894414
Validation loss: 2.551421455373456

Epoch: 5| Step: 7
Training loss: 3.1938226859523993
Validation loss: 2.5799475886465104

Epoch: 5| Step: 8
Training loss: 2.544792025598997
Validation loss: 2.6094743104167546

Epoch: 5| Step: 9
Training loss: 2.5605388673239586
Validation loss: 2.6414622550869056

Epoch: 5| Step: 10
Training loss: 2.6133678290789257
Validation loss: 2.6471640086335912

Epoch: 226| Step: 0
Training loss: 2.770438536623973
Validation loss: 2.62987767718675

Epoch: 5| Step: 1
Training loss: 2.430515749166378
Validation loss: 2.5899944591633197

Epoch: 5| Step: 2
Training loss: 2.343719380496603
Validation loss: 2.60240926268226

Epoch: 5| Step: 3
Training loss: 2.514791883803022
Validation loss: 2.5977445577691953

Epoch: 5| Step: 4
Training loss: 2.83489937605395
Validation loss: 2.5990632659274535

Epoch: 5| Step: 5
Training loss: 2.538980617670071
Validation loss: 2.5953526453597484

Epoch: 5| Step: 6
Training loss: 2.5805549036670086
Validation loss: 2.598571986023788

Epoch: 5| Step: 7
Training loss: 2.9195191376730616
Validation loss: 2.6020480102652144

Epoch: 5| Step: 8
Training loss: 2.743422357900016
Validation loss: 2.5940767456259497

Epoch: 5| Step: 9
Training loss: 3.096851528167311
Validation loss: 2.578136898745427

Epoch: 5| Step: 10
Training loss: 3.017753679915583
Validation loss: 2.6148717306353126

Epoch: 227| Step: 0
Training loss: 2.7834048549424737
Validation loss: 2.5945582360492847

Epoch: 5| Step: 1
Training loss: 3.414631462262258
Validation loss: 2.580024666208417

Epoch: 5| Step: 2
Training loss: 2.97788287336334
Validation loss: 2.539473663939099

Epoch: 5| Step: 3
Training loss: 1.9836336087537603
Validation loss: 2.551176440842791

Epoch: 5| Step: 4
Training loss: 2.778475116513282
Validation loss: 2.5622448697903115

Epoch: 5| Step: 5
Training loss: 2.527159694472909
Validation loss: 2.5882182866435888

Epoch: 5| Step: 6
Training loss: 2.4777567297588425
Validation loss: 2.5626018092762335

Epoch: 5| Step: 7
Training loss: 2.538799377892819
Validation loss: 2.5577013518683476

Epoch: 5| Step: 8
Training loss: 2.4390136713862396
Validation loss: 2.5452001245758353

Epoch: 5| Step: 9
Training loss: 2.892641426130452
Validation loss: 2.553539495725476

Epoch: 5| Step: 10
Training loss: 2.3950179882608436
Validation loss: 2.560179673569257

Epoch: 228| Step: 0
Training loss: 2.9029985513240026
Validation loss: 2.552442165225462

Epoch: 5| Step: 1
Training loss: 2.996100434416435
Validation loss: 2.5782588472795056

Epoch: 5| Step: 2
Training loss: 2.644251934046839
Validation loss: 2.5604827267843917

Epoch: 5| Step: 3
Training loss: 2.8685324526143434
Validation loss: 2.521897264262281

Epoch: 5| Step: 4
Training loss: 2.8278005845957797
Validation loss: 2.520446117753911

Epoch: 5| Step: 5
Training loss: 2.7593433140699153
Validation loss: 2.506591619298371

Epoch: 5| Step: 6
Training loss: 2.64181175876403
Validation loss: 2.524652386039449

Epoch: 5| Step: 7
Training loss: 2.708011598305819
Validation loss: 2.5425544276362713

Epoch: 5| Step: 8
Training loss: 2.300723011983114
Validation loss: 2.5785521709293855

Epoch: 5| Step: 9
Training loss: 2.370165572519356
Validation loss: 2.6193789641416325

Epoch: 5| Step: 10
Training loss: 2.2573902830919055
Validation loss: 2.623170306792029

Epoch: 229| Step: 0
Training loss: 2.985919333122718
Validation loss: 2.6258647019916785

Epoch: 5| Step: 1
Training loss: 3.0145383468114937
Validation loss: 2.6134234976653796

Epoch: 5| Step: 2
Training loss: 3.0380977089634533
Validation loss: 2.606341184984949

Epoch: 5| Step: 3
Training loss: 2.734573792996946
Validation loss: 2.6018618268256493

Epoch: 5| Step: 4
Training loss: 2.888730309690405
Validation loss: 2.5846732300506887

Epoch: 5| Step: 5
Training loss: 2.3136585529542173
Validation loss: 2.5655118978108895

Epoch: 5| Step: 6
Training loss: 2.445908543883337
Validation loss: 2.528545429139902

Epoch: 5| Step: 7
Training loss: 2.534716645906722
Validation loss: 2.532938721159759

Epoch: 5| Step: 8
Training loss: 2.6357774650867216
Validation loss: 2.5108506287963355

Epoch: 5| Step: 9
Training loss: 2.109580022950061
Validation loss: 2.506986093226759

Epoch: 5| Step: 10
Training loss: 2.5496302953755716
Validation loss: 2.50137825987539

Epoch: 230| Step: 0
Training loss: 2.4043859222060906
Validation loss: 2.4974036352575144

Epoch: 5| Step: 1
Training loss: 3.0290483167389657
Validation loss: 2.5364080267722113

Epoch: 5| Step: 2
Training loss: 2.518664401661043
Validation loss: 2.563705589927468

Epoch: 5| Step: 3
Training loss: 2.697844535030303
Validation loss: 2.5973098803993824

Epoch: 5| Step: 4
Training loss: 2.297541618924919
Validation loss: 2.6155589454145245

Epoch: 5| Step: 5
Training loss: 3.165282666448687
Validation loss: 2.6215064713813985

Epoch: 5| Step: 6
Training loss: 2.5646256725081518
Validation loss: 2.6145955871391626

Epoch: 5| Step: 7
Training loss: 2.842496323126006
Validation loss: 2.6166902998256805

Epoch: 5| Step: 8
Training loss: 2.491160405333245
Validation loss: 2.5891178779170905

Epoch: 5| Step: 9
Training loss: 2.195432612163995
Validation loss: 2.5708465894004093

Epoch: 5| Step: 10
Training loss: 3.006687657465548
Validation loss: 2.541990957109778

Epoch: 231| Step: 0
Training loss: 2.990225285491982
Validation loss: 2.5156938312489237

Epoch: 5| Step: 1
Training loss: 2.154440964058831
Validation loss: 2.494034445280854

Epoch: 5| Step: 2
Training loss: 2.867800446977879
Validation loss: 2.481941948773414

Epoch: 5| Step: 3
Training loss: 2.408935138613051
Validation loss: 2.475646043279872

Epoch: 5| Step: 4
Training loss: 2.8942060403720355
Validation loss: 2.4826303533301264

Epoch: 5| Step: 5
Training loss: 2.2300918180439875
Validation loss: 2.490520093219537

Epoch: 5| Step: 6
Training loss: 2.7905185008472095
Validation loss: 2.509023219829009

Epoch: 5| Step: 7
Training loss: 2.923199521710002
Validation loss: 2.5825812316399186

Epoch: 5| Step: 8
Training loss: 3.045048092617346
Validation loss: 2.6200607775799925

Epoch: 5| Step: 9
Training loss: 2.251409407102558
Validation loss: 2.6305934985031607

Epoch: 5| Step: 10
Training loss: 2.627179467189066
Validation loss: 2.641216906134881

Epoch: 232| Step: 0
Training loss: 2.314115424004964
Validation loss: 2.6284496290706376

Epoch: 5| Step: 1
Training loss: 3.0624015947997467
Validation loss: 2.6323414758496435

Epoch: 5| Step: 2
Training loss: 2.2150821725659484
Validation loss: 2.620037312879516

Epoch: 5| Step: 3
Training loss: 3.0522855793643564
Validation loss: 2.613267613021027

Epoch: 5| Step: 4
Training loss: 2.1950981062599357
Validation loss: 2.5589556819651658

Epoch: 5| Step: 5
Training loss: 2.4938963768240616
Validation loss: 2.509621643172917

Epoch: 5| Step: 6
Training loss: 2.8282075311410373
Validation loss: 2.480846871463968

Epoch: 5| Step: 7
Training loss: 2.4245350657464577
Validation loss: 2.4961651533431968

Epoch: 5| Step: 8
Training loss: 2.992279131011708
Validation loss: 2.4943517755728237

Epoch: 5| Step: 9
Training loss: 2.5975514326244618
Validation loss: 2.4877465979065603

Epoch: 5| Step: 10
Training loss: 2.7691343639172237
Validation loss: 2.490647126329571

Epoch: 233| Step: 0
Training loss: 2.678988440613622
Validation loss: 2.5117793955481287

Epoch: 5| Step: 1
Training loss: 2.340082885545802
Validation loss: 2.5368107865025435

Epoch: 5| Step: 2
Training loss: 2.9474015251968
Validation loss: 2.575701892225776

Epoch: 5| Step: 3
Training loss: 2.418208737396263
Validation loss: 2.5683781912969184

Epoch: 5| Step: 4
Training loss: 2.6307692027338656
Validation loss: 2.555707033841925

Epoch: 5| Step: 5
Training loss: 2.6502788073144767
Validation loss: 2.569108510656402

Epoch: 5| Step: 6
Training loss: 2.3213021065775177
Validation loss: 2.565482682969034

Epoch: 5| Step: 7
Training loss: 2.6947082726829117
Validation loss: 2.560965814338641

Epoch: 5| Step: 8
Training loss: 2.984663544931058
Validation loss: 2.5457012321149937

Epoch: 5| Step: 9
Training loss: 2.3836955451046404
Validation loss: 2.5657212744318496

Epoch: 5| Step: 10
Training loss: 2.739116459699617
Validation loss: 2.545912322556766

Epoch: 234| Step: 0
Training loss: 2.3149905840227016
Validation loss: 2.5438364347279654

Epoch: 5| Step: 1
Training loss: 2.9699654751193454
Validation loss: 2.519681727666329

Epoch: 5| Step: 2
Training loss: 2.7124546873465376
Validation loss: 2.5064809379021433

Epoch: 5| Step: 3
Training loss: 3.116040011422062
Validation loss: 2.4847795174278633

Epoch: 5| Step: 4
Training loss: 2.664982074870505
Validation loss: 2.495226954097061

Epoch: 5| Step: 5
Training loss: 2.4171989337081112
Validation loss: 2.4926018429777517

Epoch: 5| Step: 6
Training loss: 2.7508649332827213
Validation loss: 2.4793411349293293

Epoch: 5| Step: 7
Training loss: 2.3561207136307143
Validation loss: 2.4778875262022995

Epoch: 5| Step: 8
Training loss: 2.596071973417168
Validation loss: 2.5021540160628932

Epoch: 5| Step: 9
Training loss: 2.764109395579781
Validation loss: 2.52281886997368

Epoch: 5| Step: 10
Training loss: 2.185933560414885
Validation loss: 2.5520434053540137

Epoch: 235| Step: 0
Training loss: 2.7344247867956315
Validation loss: 2.5964766629502947

Epoch: 5| Step: 1
Training loss: 2.7903093388022904
Validation loss: 2.631229289151197

Epoch: 5| Step: 2
Training loss: 2.988169230437166
Validation loss: 2.661641058147678

Epoch: 5| Step: 3
Training loss: 2.75202199986447
Validation loss: 2.6652703519864414

Epoch: 5| Step: 4
Training loss: 2.468875447236759
Validation loss: 2.62737182349664

Epoch: 5| Step: 5
Training loss: 2.3256434585917245
Validation loss: 2.5969447734853475

Epoch: 5| Step: 6
Training loss: 2.5325607861889883
Validation loss: 2.548259463248172

Epoch: 5| Step: 7
Training loss: 3.0471845420687687
Validation loss: 2.5208337638554266

Epoch: 5| Step: 8
Training loss: 2.798187714999264
Validation loss: 2.487947942610088

Epoch: 5| Step: 9
Training loss: 2.068911326592086
Validation loss: 2.4827121311816085

Epoch: 5| Step: 10
Training loss: 2.148044952597055
Validation loss: 2.4882437153778927

Epoch: 236| Step: 0
Training loss: 2.341391228419865
Validation loss: 2.47452861402458

Epoch: 5| Step: 1
Training loss: 2.68562837234296
Validation loss: 2.4887511158626174

Epoch: 5| Step: 2
Training loss: 2.7133361582385955
Validation loss: 2.4949993162133457

Epoch: 5| Step: 3
Training loss: 2.259567370739668
Validation loss: 2.5099787132011926

Epoch: 5| Step: 4
Training loss: 2.1339144253076627
Validation loss: 2.5238464871322193

Epoch: 5| Step: 5
Training loss: 2.428403656237355
Validation loss: 2.538995046421647

Epoch: 5| Step: 6
Training loss: 2.553157990147936
Validation loss: 2.5548168865984837

Epoch: 5| Step: 7
Training loss: 2.4852584131917905
Validation loss: 2.6580809776202816

Epoch: 5| Step: 8
Training loss: 3.3624663567543953
Validation loss: 2.7353045846166317

Epoch: 5| Step: 9
Training loss: 3.356860830177312
Validation loss: 2.7846515479373464

Epoch: 5| Step: 10
Training loss: 2.5090572322249005
Validation loss: 2.7455638088897296

Epoch: 237| Step: 0
Training loss: 2.801168290001497
Validation loss: 2.682544700538279

Epoch: 5| Step: 1
Training loss: 2.4972180146420113
Validation loss: 2.639349661320654

Epoch: 5| Step: 2
Training loss: 2.4849712687928758
Validation loss: 2.6153360605430818

Epoch: 5| Step: 3
Training loss: 2.5814381897978076
Validation loss: 2.6097461087026854

Epoch: 5| Step: 4
Training loss: 2.4896315140364838
Validation loss: 2.538096369465947

Epoch: 5| Step: 5
Training loss: 2.86243146122999
Validation loss: 2.4916002984186214

Epoch: 5| Step: 6
Training loss: 1.9545135445036428
Validation loss: 2.471924148978847

Epoch: 5| Step: 7
Training loss: 2.980443951864809
Validation loss: 2.4868125615330694

Epoch: 5| Step: 8
Training loss: 3.0516093713898242
Validation loss: 2.4696689077813065

Epoch: 5| Step: 9
Training loss: 2.304623153564124
Validation loss: 2.468585488489895

Epoch: 5| Step: 10
Training loss: 3.0189716960620108
Validation loss: 2.479337968816959

Epoch: 238| Step: 0
Training loss: 2.810933927456344
Validation loss: 2.5155097365859445

Epoch: 5| Step: 1
Training loss: 2.4947341774280947
Validation loss: 2.554984658560063

Epoch: 5| Step: 2
Training loss: 2.7908322999515103
Validation loss: 2.6170374232659652

Epoch: 5| Step: 3
Training loss: 2.4426788675338065
Validation loss: 2.7143885832550425

Epoch: 5| Step: 4
Training loss: 3.2919781372530927
Validation loss: 2.7859077051407697

Epoch: 5| Step: 5
Training loss: 3.141374033715525
Validation loss: 2.701618159403346

Epoch: 5| Step: 6
Training loss: 2.1032417707065734
Validation loss: 2.6293489972312787

Epoch: 5| Step: 7
Training loss: 2.4603571131704873
Validation loss: 2.560166112225325

Epoch: 5| Step: 8
Training loss: 2.540892519596722
Validation loss: 2.5207339248304534

Epoch: 5| Step: 9
Training loss: 2.7654845638503005
Validation loss: 2.516060324436245

Epoch: 5| Step: 10
Training loss: 2.8826902616889707
Validation loss: 2.503651108348132

Epoch: 239| Step: 0
Training loss: 2.7321505844762037
Validation loss: 2.5033881700739724

Epoch: 5| Step: 1
Training loss: 2.8816832111237454
Validation loss: 2.5072054647884925

Epoch: 5| Step: 2
Training loss: 2.857927967239583
Validation loss: 2.4916687551943673

Epoch: 5| Step: 3
Training loss: 2.399621727061038
Validation loss: 2.4775304781753853

Epoch: 5| Step: 4
Training loss: 2.8885761319917638
Validation loss: 2.4700278986643567

Epoch: 5| Step: 5
Training loss: 2.016217639944844
Validation loss: 2.489029974771569

Epoch: 5| Step: 6
Training loss: 2.409807424171948
Validation loss: 2.512084937306013

Epoch: 5| Step: 7
Training loss: 2.8121900599620946
Validation loss: 2.506952934223113

Epoch: 5| Step: 8
Training loss: 2.86360181234414
Validation loss: 2.5123852307227756

Epoch: 5| Step: 9
Training loss: 2.9434321140750734
Validation loss: 2.5145272863912047

Epoch: 5| Step: 10
Training loss: 2.402452519133199
Validation loss: 2.5377721039577787

Epoch: 240| Step: 0
Training loss: 2.6920527552328517
Validation loss: 2.5268839203382703

Epoch: 5| Step: 1
Training loss: 2.2112238937743136
Validation loss: 2.5414186420862768

Epoch: 5| Step: 2
Training loss: 1.9781460054315838
Validation loss: 2.5506297536081206

Epoch: 5| Step: 3
Training loss: 3.17352447465709
Validation loss: 2.5599731884950807

Epoch: 5| Step: 4
Training loss: 2.280282220272165
Validation loss: 2.5622866321875506

Epoch: 5| Step: 5
Training loss: 2.5374444589032965
Validation loss: 2.5376333399982958

Epoch: 5| Step: 6
Training loss: 2.7191818595864734
Validation loss: 2.5122158945567192

Epoch: 5| Step: 7
Training loss: 3.231697190291245
Validation loss: 2.503446807541932

Epoch: 5| Step: 8
Training loss: 2.9757726227026096
Validation loss: 2.4828103529453607

Epoch: 5| Step: 9
Training loss: 2.206136822701837
Validation loss: 2.4964622025213883

Epoch: 5| Step: 10
Training loss: 2.545998919940009
Validation loss: 2.5147035980466805

Epoch: 241| Step: 0
Training loss: 3.096620403337045
Validation loss: 2.5101634974304976

Epoch: 5| Step: 1
Training loss: 2.6125055595959368
Validation loss: 2.513908406399438

Epoch: 5| Step: 2
Training loss: 2.3246087268026527
Validation loss: 2.5396398562164673

Epoch: 5| Step: 3
Training loss: 2.596880299256354
Validation loss: 2.558183054591875

Epoch: 5| Step: 4
Training loss: 2.6623749072279366
Validation loss: 2.5636361587464274

Epoch: 5| Step: 5
Training loss: 3.5173281464826482
Validation loss: 2.563806200404084

Epoch: 5| Step: 6
Training loss: 2.0069650724495607
Validation loss: 2.571938850558096

Epoch: 5| Step: 7
Training loss: 2.005698311792186
Validation loss: 2.5462843401733726

Epoch: 5| Step: 8
Training loss: 2.3641408318591703
Validation loss: 2.5440179736942676

Epoch: 5| Step: 9
Training loss: 2.827654045893747
Validation loss: 2.560596965959605

Epoch: 5| Step: 10
Training loss: 2.213489259585649
Validation loss: 2.5873587291313833

Epoch: 242| Step: 0
Training loss: 2.4019451523997626
Validation loss: 2.57074746510545

Epoch: 5| Step: 1
Training loss: 2.6274088751383484
Validation loss: 2.5589133833170794

Epoch: 5| Step: 2
Training loss: 2.5490066875012363
Validation loss: 2.5509519053380414

Epoch: 5| Step: 3
Training loss: 2.359869494628304
Validation loss: 2.538991451862793

Epoch: 5| Step: 4
Training loss: 2.5695423955260996
Validation loss: 2.51003976030753

Epoch: 5| Step: 5
Training loss: 2.5817466498196486
Validation loss: 2.5049407067643035

Epoch: 5| Step: 6
Training loss: 2.3631648263549025
Validation loss: 2.5404502066361063

Epoch: 5| Step: 7
Training loss: 2.6650565074490875
Validation loss: 2.5378236990613057

Epoch: 5| Step: 8
Training loss: 2.711609067377421
Validation loss: 2.5392130166143145

Epoch: 5| Step: 9
Training loss: 2.5203931650117197
Validation loss: 2.5710611742584795

Epoch: 5| Step: 10
Training loss: 3.076088168503978
Validation loss: 2.5585669716431996

Epoch: 243| Step: 0
Training loss: 2.837516744286963
Validation loss: 2.5624205804338334

Epoch: 5| Step: 1
Training loss: 2.7455705168641598
Validation loss: 2.5544721127438796

Epoch: 5| Step: 2
Training loss: 2.005938297193719
Validation loss: 2.57319797869318

Epoch: 5| Step: 3
Training loss: 2.227087982810448
Validation loss: 2.55836706872441

Epoch: 5| Step: 4
Training loss: 2.563052420268733
Validation loss: 2.535225055569289

Epoch: 5| Step: 5
Training loss: 2.5351416729947345
Validation loss: 2.533170149274784

Epoch: 5| Step: 6
Training loss: 2.278951453648888
Validation loss: 2.521767135086013

Epoch: 5| Step: 7
Training loss: 2.4272618589654735
Validation loss: 2.5215607385780188

Epoch: 5| Step: 8
Training loss: 3.235042042525373
Validation loss: 2.5387236772483144

Epoch: 5| Step: 9
Training loss: 2.4654598282291715
Validation loss: 2.522893601867068

Epoch: 5| Step: 10
Training loss: 2.8577025478395597
Validation loss: 2.4817800127961576

Epoch: 244| Step: 0
Training loss: 2.343259124213895
Validation loss: 2.477454496913876

Epoch: 5| Step: 1
Training loss: 2.29557161264424
Validation loss: 2.481353942366928

Epoch: 5| Step: 2
Training loss: 2.5706057859482243
Validation loss: 2.4855873110048843

Epoch: 5| Step: 3
Training loss: 2.40013743245499
Validation loss: 2.471932071398085

Epoch: 5| Step: 4
Training loss: 2.020122035844213
Validation loss: 2.4882823936168847

Epoch: 5| Step: 5
Training loss: 2.9098236098691204
Validation loss: 2.4977918235206804

Epoch: 5| Step: 6
Training loss: 2.7268666095066845
Validation loss: 2.5102630971296978

Epoch: 5| Step: 7
Training loss: 3.3194712571710965
Validation loss: 2.5640009984227934

Epoch: 5| Step: 8
Training loss: 2.0879870000851093
Validation loss: 2.62103314938901

Epoch: 5| Step: 9
Training loss: 2.8715738530878485
Validation loss: 2.6466326899305663

Epoch: 5| Step: 10
Training loss: 2.6059953194647187
Validation loss: 2.659240499501294

Epoch: 245| Step: 0
Training loss: 2.3605743795456195
Validation loss: 2.6659847959256244

Epoch: 5| Step: 1
Training loss: 2.434490791671615
Validation loss: 2.6567835890151765

Epoch: 5| Step: 2
Training loss: 2.6494496979726567
Validation loss: 2.6115888587102964

Epoch: 5| Step: 3
Training loss: 2.9808723706369675
Validation loss: 2.5583683779171658

Epoch: 5| Step: 4
Training loss: 2.5290884513848026
Validation loss: 2.5027645955533715

Epoch: 5| Step: 5
Training loss: 2.3267446432555103
Validation loss: 2.496027269507878

Epoch: 5| Step: 6
Training loss: 2.5634676339130222
Validation loss: 2.4966296201173375

Epoch: 5| Step: 7
Training loss: 2.4807161463117415
Validation loss: 2.4867971939458107

Epoch: 5| Step: 8
Training loss: 2.826536122162626
Validation loss: 2.5099910892252737

Epoch: 5| Step: 9
Training loss: 3.096829355713783
Validation loss: 2.4932308949062447

Epoch: 5| Step: 10
Training loss: 2.1329414971435146
Validation loss: 2.5164888784349775

Epoch: 246| Step: 0
Training loss: 2.73646239033662
Validation loss: 2.526874409963715

Epoch: 5| Step: 1
Training loss: 2.738289173239919
Validation loss: 2.5553470525475093

Epoch: 5| Step: 2
Training loss: 2.491113221911261
Validation loss: 2.5689450420994975

Epoch: 5| Step: 3
Training loss: 2.7169623801021126
Validation loss: 2.5711564806196447

Epoch: 5| Step: 4
Training loss: 2.4679417313138
Validation loss: 2.5627811586778013

Epoch: 5| Step: 5
Training loss: 2.6152225234864956
Validation loss: 2.5440991195177745

Epoch: 5| Step: 6
Training loss: 3.0356184166908937
Validation loss: 2.5011188510665203

Epoch: 5| Step: 7
Training loss: 2.3658304384793203
Validation loss: 2.5042587553540008

Epoch: 5| Step: 8
Training loss: 2.691473751024448
Validation loss: 2.470480965616568

Epoch: 5| Step: 9
Training loss: 1.8161433860325458
Validation loss: 2.5085396295051585

Epoch: 5| Step: 10
Training loss: 2.4411699104356113
Validation loss: 2.5100730705451695

Epoch: 247| Step: 0
Training loss: 2.5504365136015656
Validation loss: 2.52666674433456

Epoch: 5| Step: 1
Training loss: 3.067604948329976
Validation loss: 2.542881805449319

Epoch: 5| Step: 2
Training loss: 2.3770716817059308
Validation loss: 2.5522857481943104

Epoch: 5| Step: 3
Training loss: 2.0113691007582033
Validation loss: 2.5871999749655394

Epoch: 5| Step: 4
Training loss: 3.054229780085406
Validation loss: 2.61578773726101

Epoch: 5| Step: 5
Training loss: 2.6517808004960353
Validation loss: 2.6074014748084084

Epoch: 5| Step: 6
Training loss: 2.537318925081292
Validation loss: 2.6049827120744253

Epoch: 5| Step: 7
Training loss: 2.529768427778965
Validation loss: 2.5635263122012626

Epoch: 5| Step: 8
Training loss: 2.5295368566774337
Validation loss: 2.541973695277284

Epoch: 5| Step: 9
Training loss: 2.663301062629123
Validation loss: 2.504865509870888

Epoch: 5| Step: 10
Training loss: 2.178430776053517
Validation loss: 2.50326844747463

Epoch: 248| Step: 0
Training loss: 2.834670779641805
Validation loss: 2.4998977742778243

Epoch: 5| Step: 1
Training loss: 2.9228047406352484
Validation loss: 2.5048439331018186

Epoch: 5| Step: 2
Training loss: 2.5897725873695494
Validation loss: 2.5071527733136056

Epoch: 5| Step: 3
Training loss: 2.011709979880762
Validation loss: 2.48901202531861

Epoch: 5| Step: 4
Training loss: 2.770422529777679
Validation loss: 2.4883246844062343

Epoch: 5| Step: 5
Training loss: 2.228709688019981
Validation loss: 2.4994730014528104

Epoch: 5| Step: 6
Training loss: 2.272603409599708
Validation loss: 2.524011542899299

Epoch: 5| Step: 7
Training loss: 3.090589970929208
Validation loss: 2.542503118096568

Epoch: 5| Step: 8
Training loss: 2.45635783029179
Validation loss: 2.566984821559213

Epoch: 5| Step: 9
Training loss: 2.0449510224313605
Validation loss: 2.58094305038717

Epoch: 5| Step: 10
Training loss: 2.6259104648384612
Validation loss: 2.6050820039396965

Epoch: 249| Step: 0
Training loss: 2.563926020865737
Validation loss: 2.6305517836035035

Epoch: 5| Step: 1
Training loss: 2.7825741990882107
Validation loss: 2.623032468789003

Epoch: 5| Step: 2
Training loss: 2.4179806809138706
Validation loss: 2.5977648763915417

Epoch: 5| Step: 3
Training loss: 2.529855037652483
Validation loss: 2.5652756723540304

Epoch: 5| Step: 4
Training loss: 2.1895883673244962
Validation loss: 2.531053701324724

Epoch: 5| Step: 5
Training loss: 2.764479663996932
Validation loss: 2.5170005808531646

Epoch: 5| Step: 6
Training loss: 2.604878920745059
Validation loss: 2.5077161581635807

Epoch: 5| Step: 7
Training loss: 2.7632054666616397
Validation loss: 2.507206489342494

Epoch: 5| Step: 8
Training loss: 2.4092599447958913
Validation loss: 2.5021555221854483

Epoch: 5| Step: 9
Training loss: 2.2212205483668894
Validation loss: 2.5140865194383584

Epoch: 5| Step: 10
Training loss: 3.0726142001675525
Validation loss: 2.5163948910492393

Epoch: 250| Step: 0
Training loss: 2.7961690853657397
Validation loss: 2.544144727763875

Epoch: 5| Step: 1
Training loss: 2.1995282404275316
Validation loss: 2.5625760447065704

Epoch: 5| Step: 2
Training loss: 2.573536065998611
Validation loss: 2.6056894377805437

Epoch: 5| Step: 3
Training loss: 2.992923496654021
Validation loss: 2.6246798896834767

Epoch: 5| Step: 4
Training loss: 2.2788404516032985
Validation loss: 2.6180455962982183

Epoch: 5| Step: 5
Training loss: 2.5960592997145264
Validation loss: 2.6261104924425562

Epoch: 5| Step: 6
Training loss: 2.6216454643011367
Validation loss: 2.631637153634828

Epoch: 5| Step: 7
Training loss: 2.3064333752350605
Validation loss: 2.6129064852994124

Epoch: 5| Step: 8
Training loss: 2.5002030290178063
Validation loss: 2.556147309540332

Epoch: 5| Step: 9
Training loss: 2.2773552660381
Validation loss: 2.531467477522248

Epoch: 5| Step: 10
Training loss: 2.88102240666869
Validation loss: 2.501535413809265

Epoch: 251| Step: 0
Training loss: 2.49367696325288
Validation loss: 2.5015870286806146

Epoch: 5| Step: 1
Training loss: 2.0668707111084594
Validation loss: 2.5041991305653193

Epoch: 5| Step: 2
Training loss: 2.3478772254571387
Validation loss: 2.5050862982526216

Epoch: 5| Step: 3
Training loss: 2.6362175811322555
Validation loss: 2.502953816805462

Epoch: 5| Step: 4
Training loss: 2.4048808772986203
Validation loss: 2.5338435688439427

Epoch: 5| Step: 5
Training loss: 2.4386089443315884
Validation loss: 2.535237756313807

Epoch: 5| Step: 6
Training loss: 2.850602665140197
Validation loss: 2.5580829565449643

Epoch: 5| Step: 7
Training loss: 2.5575508146933794
Validation loss: 2.565663454706047

Epoch: 5| Step: 8
Training loss: 2.948492220889848
Validation loss: 2.5763261611965356

Epoch: 5| Step: 9
Training loss: 2.1972320960983516
Validation loss: 2.587660521270531

Epoch: 5| Step: 10
Training loss: 2.994819937309951
Validation loss: 2.5323019046122353

Epoch: 252| Step: 0
Training loss: 2.294444972056938
Validation loss: 2.4848279539442717

Epoch: 5| Step: 1
Training loss: 2.939085187728089
Validation loss: 2.493653502894799

Epoch: 5| Step: 2
Training loss: 2.708549393080787
Validation loss: 2.487553465127379

Epoch: 5| Step: 3
Training loss: 2.260611940261288
Validation loss: 2.4832306894827862

Epoch: 5| Step: 4
Training loss: 2.0965437967214147
Validation loss: 2.5026405991442036

Epoch: 5| Step: 5
Training loss: 2.635921736456968
Validation loss: 2.5260353787725243

Epoch: 5| Step: 6
Training loss: 2.8362727531909133
Validation loss: 2.5478229521334548

Epoch: 5| Step: 7
Training loss: 2.8296629375400686
Validation loss: 2.5668698289842906

Epoch: 5| Step: 8
Training loss: 2.794122374976442
Validation loss: 2.541765504270574

Epoch: 5| Step: 9
Training loss: 2.2094864144081314
Validation loss: 2.534369918546851

Epoch: 5| Step: 10
Training loss: 2.3828832396966284
Validation loss: 2.533450907388413

Epoch: 253| Step: 0
Training loss: 2.812664620562009
Validation loss: 2.510088664331701

Epoch: 5| Step: 1
Training loss: 2.7378599792411182
Validation loss: 2.4931640080017994

Epoch: 5| Step: 2
Training loss: 2.078437380150479
Validation loss: 2.5045041957672325

Epoch: 5| Step: 3
Training loss: 2.359300523807725
Validation loss: 2.4941333908734324

Epoch: 5| Step: 4
Training loss: 2.6709048645946436
Validation loss: 2.4789558238951543

Epoch: 5| Step: 5
Training loss: 1.9798909384621026
Validation loss: 2.4997242057606965

Epoch: 5| Step: 6
Training loss: 2.420093791972654
Validation loss: 2.516947895818295

Epoch: 5| Step: 7
Training loss: 2.631928519069655
Validation loss: 2.539411348747827

Epoch: 5| Step: 8
Training loss: 2.4925484231513235
Validation loss: 2.5766360620000985

Epoch: 5| Step: 9
Training loss: 2.8495677084749373
Validation loss: 2.5660194221194876

Epoch: 5| Step: 10
Training loss: 3.0384859847410475
Validation loss: 2.5703307544279337

Epoch: 254| Step: 0
Training loss: 2.6811170851835042
Validation loss: 2.576651273844159

Epoch: 5| Step: 1
Training loss: 2.7135552072217695
Validation loss: 2.590293696585513

Epoch: 5| Step: 2
Training loss: 2.4467384154101155
Validation loss: 2.5712710970356483

Epoch: 5| Step: 3
Training loss: 2.510604207696111
Validation loss: 2.5718596138139627

Epoch: 5| Step: 4
Training loss: 2.4281365942954363
Validation loss: 2.565730411000372

Epoch: 5| Step: 5
Training loss: 2.392694412830886
Validation loss: 2.564948861956193

Epoch: 5| Step: 6
Training loss: 2.372518548119157
Validation loss: 2.5981117803335514

Epoch: 5| Step: 7
Training loss: 2.482102416317734
Validation loss: 2.6004597932939855

Epoch: 5| Step: 8
Training loss: 2.237547109949729
Validation loss: 2.5581644038195206

Epoch: 5| Step: 9
Training loss: 2.86375916618169
Validation loss: 2.5384763544982976

Epoch: 5| Step: 10
Training loss: 2.677048253721379
Validation loss: 2.5293740355181487

Epoch: 255| Step: 0
Training loss: 2.4863468238385136
Validation loss: 2.5018245197141917

Epoch: 5| Step: 1
Training loss: 2.2639231636973656
Validation loss: 2.490106784448129

Epoch: 5| Step: 2
Training loss: 2.4445803585221864
Validation loss: 2.4990550757548333

Epoch: 5| Step: 3
Training loss: 2.4304377633268106
Validation loss: 2.4980695223592866

Epoch: 5| Step: 4
Training loss: 2.6995464297189806
Validation loss: 2.5035912489310808

Epoch: 5| Step: 5
Training loss: 2.127466789551205
Validation loss: 2.516764617129685

Epoch: 5| Step: 6
Training loss: 2.8141755093552416
Validation loss: 2.5199328748002725

Epoch: 5| Step: 7
Training loss: 2.485822819546768
Validation loss: 2.521117257875389

Epoch: 5| Step: 8
Training loss: 2.7093554010969334
Validation loss: 2.575131355963031

Epoch: 5| Step: 9
Training loss: 2.624620682694424
Validation loss: 2.5489369977462126

Epoch: 5| Step: 10
Training loss: 2.4984856787563707
Validation loss: 2.5644957351415427

Epoch: 256| Step: 0
Training loss: 2.7339798996081117
Validation loss: 2.564159113321137

Epoch: 5| Step: 1
Training loss: 2.4131041170652714
Validation loss: 2.5168520910936256

Epoch: 5| Step: 2
Training loss: 2.6516207579021915
Validation loss: 2.4881737899094345

Epoch: 5| Step: 3
Training loss: 2.5377721706305425
Validation loss: 2.4754307411941867

Epoch: 5| Step: 4
Training loss: 2.5410243509950576
Validation loss: 2.4813943448717053

Epoch: 5| Step: 5
Training loss: 2.613685109132492
Validation loss: 2.4621211598645343

Epoch: 5| Step: 6
Training loss: 2.2489306769909314
Validation loss: 2.4767525751590367

Epoch: 5| Step: 7
Training loss: 2.849359199361299
Validation loss: 2.5028184487829424

Epoch: 5| Step: 8
Training loss: 2.3798663827910516
Validation loss: 2.5250400107929813

Epoch: 5| Step: 9
Training loss: 2.7402374202306228
Validation loss: 2.5552146668509885

Epoch: 5| Step: 10
Training loss: 1.7929620347904953
Validation loss: 2.5448633489966084

Epoch: 257| Step: 0
Training loss: 2.035987962286237
Validation loss: 2.5778913971940454

Epoch: 5| Step: 1
Training loss: 2.9600970602875916
Validation loss: 2.6077831350340372

Epoch: 5| Step: 2
Training loss: 2.780757817641579
Validation loss: 2.5785266074928543

Epoch: 5| Step: 3
Training loss: 2.623352805537558
Validation loss: 2.5783685692823863

Epoch: 5| Step: 4
Training loss: 1.6983139259844238
Validation loss: 2.5796188426746296

Epoch: 5| Step: 5
Training loss: 2.091658045331759
Validation loss: 2.5606699325504345

Epoch: 5| Step: 6
Training loss: 2.6194911554387104
Validation loss: 2.5643272997897393

Epoch: 5| Step: 7
Training loss: 2.9510254839394987
Validation loss: 2.5443808102475454

Epoch: 5| Step: 8
Training loss: 2.3456694817333923
Validation loss: 2.5153988289591243

Epoch: 5| Step: 9
Training loss: 2.578649941378651
Validation loss: 2.51948933446877

Epoch: 5| Step: 10
Training loss: 2.7199479894714322
Validation loss: 2.5142053475834696

Epoch: 258| Step: 0
Training loss: 2.97407551994973
Validation loss: 2.4987796583966455

Epoch: 5| Step: 1
Training loss: 2.301704778371845
Validation loss: 2.4947180560614965

Epoch: 5| Step: 2
Training loss: 2.4061217831226425
Validation loss: 2.4976642526028816

Epoch: 5| Step: 3
Training loss: 2.487540765169513
Validation loss: 2.5044198835192364

Epoch: 5| Step: 4
Training loss: 2.4337026899272196
Validation loss: 2.4949863397361303

Epoch: 5| Step: 5
Training loss: 2.8251325255510173
Validation loss: 2.5321351932609013

Epoch: 5| Step: 6
Training loss: 2.1426582425768284
Validation loss: 2.528196089012652

Epoch: 5| Step: 7
Training loss: 2.123042495287858
Validation loss: 2.5438861754943316

Epoch: 5| Step: 8
Training loss: 3.061595861134997
Validation loss: 2.54282595661046

Epoch: 5| Step: 9
Training loss: 2.159072245284457
Validation loss: 2.5213928411927715

Epoch: 5| Step: 10
Training loss: 2.605463534096869
Validation loss: 2.502763250104069

Epoch: 259| Step: 0
Training loss: 2.3197905598846065
Validation loss: 2.5071052855164653

Epoch: 5| Step: 1
Training loss: 2.045471525603435
Validation loss: 2.472768392519352

Epoch: 5| Step: 2
Training loss: 2.554741535140267
Validation loss: 2.4643649691663447

Epoch: 5| Step: 3
Training loss: 2.6408601915705647
Validation loss: 2.4895779553028916

Epoch: 5| Step: 4
Training loss: 2.7857459943315153
Validation loss: 2.467813171025031

Epoch: 5| Step: 5
Training loss: 2.430264223592194
Validation loss: 2.490412941791162

Epoch: 5| Step: 6
Training loss: 2.1911143280175054
Validation loss: 2.5054799900650604

Epoch: 5| Step: 7
Training loss: 2.328029963454549
Validation loss: 2.5171834186833455

Epoch: 5| Step: 8
Training loss: 2.562717800653703
Validation loss: 2.5421729687176984

Epoch: 5| Step: 9
Training loss: 2.873793307289594
Validation loss: 2.5837891755713356

Epoch: 5| Step: 10
Training loss: 2.6899832851925827
Validation loss: 2.595676525531557

Epoch: 260| Step: 0
Training loss: 2.6287594168980037
Validation loss: 2.5594093899506944

Epoch: 5| Step: 1
Training loss: 2.5593791658882266
Validation loss: 2.5327498330958234

Epoch: 5| Step: 2
Training loss: 2.379148373864749
Validation loss: 2.5371934456736245

Epoch: 5| Step: 3
Training loss: 2.2728135344000617
Validation loss: 2.5476343515287683

Epoch: 5| Step: 4
Training loss: 2.5492465907080892
Validation loss: 2.5283888498508946

Epoch: 5| Step: 5
Training loss: 2.7805317154797162
Validation loss: 2.5024493852113485

Epoch: 5| Step: 6
Training loss: 2.223674306369277
Validation loss: 2.490812034386462

Epoch: 5| Step: 7
Training loss: 2.0476550297622507
Validation loss: 2.4803490942297897

Epoch: 5| Step: 8
Training loss: 2.990190521855527
Validation loss: 2.4596543135651285

Epoch: 5| Step: 9
Training loss: 2.1661359308127586
Validation loss: 2.461802339853777

Epoch: 5| Step: 10
Training loss: 2.5175320049172107
Validation loss: 2.4536103781520366

Epoch: 261| Step: 0
Training loss: 2.9065482694094773
Validation loss: 2.487494756007004

Epoch: 5| Step: 1
Training loss: 2.381694193583737
Validation loss: 2.5098120471428857

Epoch: 5| Step: 2
Training loss: 2.3998216244849746
Validation loss: 2.5055429619176275

Epoch: 5| Step: 3
Training loss: 2.338277505909235
Validation loss: 2.5241522399519103

Epoch: 5| Step: 4
Training loss: 2.2354176896073086
Validation loss: 2.564027947493002

Epoch: 5| Step: 5
Training loss: 2.430029645668321
Validation loss: 2.5647640835895458

Epoch: 5| Step: 6
Training loss: 2.012550670862552
Validation loss: 2.578625718083947

Epoch: 5| Step: 7
Training loss: 2.878476073218146
Validation loss: 2.569867838666273

Epoch: 5| Step: 8
Training loss: 2.3898307129029512
Validation loss: 2.5958273444248765

Epoch: 5| Step: 9
Training loss: 2.5782233941924675
Validation loss: 2.5806945733562

Epoch: 5| Step: 10
Training loss: 2.468307841819927
Validation loss: 2.5221574018447073

Epoch: 262| Step: 0
Training loss: 2.607466496575118
Validation loss: 2.5220994565553174

Epoch: 5| Step: 1
Training loss: 2.1970402445173947
Validation loss: 2.4799358342897486

Epoch: 5| Step: 2
Training loss: 2.495819124447769
Validation loss: 2.475969437075134

Epoch: 5| Step: 3
Training loss: 2.890071011631117
Validation loss: 2.4655746469167963

Epoch: 5| Step: 4
Training loss: 2.790722435833988
Validation loss: 2.450860137916165

Epoch: 5| Step: 5
Training loss: 2.439613990580204
Validation loss: 2.4537228467861882

Epoch: 5| Step: 6
Training loss: 2.091134102591695
Validation loss: 2.4367327632984477

Epoch: 5| Step: 7
Training loss: 2.0798712255889686
Validation loss: 2.471689883212494

Epoch: 5| Step: 8
Training loss: 2.815571104289598
Validation loss: 2.4737797802327237

Epoch: 5| Step: 9
Training loss: 2.1665304825850513
Validation loss: 2.5158330869129566

Epoch: 5| Step: 10
Training loss: 2.557165687912739
Validation loss: 2.5380960452352728

Epoch: 263| Step: 0
Training loss: 2.696536463489003
Validation loss: 2.606171571492818

Epoch: 5| Step: 1
Training loss: 3.012925753443679
Validation loss: 2.627721256893048

Epoch: 5| Step: 2
Training loss: 2.406258223878753
Validation loss: 2.5742423047001974

Epoch: 5| Step: 3
Training loss: 2.2810195388391925
Validation loss: 2.5069868898309937

Epoch: 5| Step: 4
Training loss: 2.3064469168107724
Validation loss: 2.4617295503224015

Epoch: 5| Step: 5
Training loss: 2.570683229372609
Validation loss: 2.4529890037489372

Epoch: 5| Step: 6
Training loss: 2.2811958620101103
Validation loss: 2.441819817541959

Epoch: 5| Step: 7
Training loss: 2.8124652436546014
Validation loss: 2.4439004669264426

Epoch: 5| Step: 8
Training loss: 2.5028114722558543
Validation loss: 2.461249213751056

Epoch: 5| Step: 9
Training loss: 2.4677264832172305
Validation loss: 2.4460877001582677

Epoch: 5| Step: 10
Training loss: 2.448581448372499
Validation loss: 2.4680051426294365

Epoch: 264| Step: 0
Training loss: 2.526764651523171
Validation loss: 2.465497358257504

Epoch: 5| Step: 1
Training loss: 2.1775144183692126
Validation loss: 2.4898679868054145

Epoch: 5| Step: 2
Training loss: 2.3608048508426545
Validation loss: 2.523269858049655

Epoch: 5| Step: 3
Training loss: 3.0094422520048223
Validation loss: 2.5350418200247824

Epoch: 5| Step: 4
Training loss: 1.8988714781746026
Validation loss: 2.543592729514311

Epoch: 5| Step: 5
Training loss: 2.5922785802180437
Validation loss: 2.533848344344903

Epoch: 5| Step: 6
Training loss: 2.3328565609981027
Validation loss: 2.5179617063459014

Epoch: 5| Step: 7
Training loss: 2.6015289579411465
Validation loss: 2.524820055499908

Epoch: 5| Step: 8
Training loss: 2.82990659795503
Validation loss: 2.5055797841244924

Epoch: 5| Step: 9
Training loss: 2.5106695425057954
Validation loss: 2.5242275884564096

Epoch: 5| Step: 10
Training loss: 2.526506665614893
Validation loss: 2.501348383092788

Epoch: 265| Step: 0
Training loss: 2.487030529403894
Validation loss: 2.496268667771707

Epoch: 5| Step: 1
Training loss: 2.774767661463525
Validation loss: 2.4983318906162553

Epoch: 5| Step: 2
Training loss: 2.7321000581126347
Validation loss: 2.470559532438075

Epoch: 5| Step: 3
Training loss: 2.302890503745502
Validation loss: 2.4464736598647736

Epoch: 5| Step: 4
Training loss: 2.3408764325967244
Validation loss: 2.4529779851410742

Epoch: 5| Step: 5
Training loss: 2.6552157913129206
Validation loss: 2.450114495961134

Epoch: 5| Step: 6
Training loss: 2.2256925255232733
Validation loss: 2.4684813480354433

Epoch: 5| Step: 7
Training loss: 2.4296225388849026
Validation loss: 2.477882878741746

Epoch: 5| Step: 8
Training loss: 1.8074524411266855
Validation loss: 2.4967308275820272

Epoch: 5| Step: 9
Training loss: 2.373903523362401
Validation loss: 2.496147056979791

Epoch: 5| Step: 10
Training loss: 2.766757797747259
Validation loss: 2.5099281493030423

Epoch: 266| Step: 0
Training loss: 2.4407375060659118
Validation loss: 2.538291170069564

Epoch: 5| Step: 1
Training loss: 1.8179834225090783
Validation loss: 2.576600613448319

Epoch: 5| Step: 2
Training loss: 3.1567899034473035
Validation loss: 2.5890429261853596

Epoch: 5| Step: 3
Training loss: 2.414846151123038
Validation loss: 2.5656420105367017

Epoch: 5| Step: 4
Training loss: 2.501036143161109
Validation loss: 2.5143623594726665

Epoch: 5| Step: 5
Training loss: 1.7698969515744427
Validation loss: 2.4603601265721347

Epoch: 5| Step: 6
Training loss: 2.861715390814982
Validation loss: 2.454739866446639

Epoch: 5| Step: 7
Training loss: 2.211759273005558
Validation loss: 2.4550314416758523

Epoch: 5| Step: 8
Training loss: 2.6721000353538393
Validation loss: 2.456763063391399

Epoch: 5| Step: 9
Training loss: 2.5069295214076472
Validation loss: 2.458925158920562

Epoch: 5| Step: 10
Training loss: 2.3320432116331102
Validation loss: 2.479619789714979

Epoch: 267| Step: 0
Training loss: 2.6354044937837746
Validation loss: 2.4880317445314595

Epoch: 5| Step: 1
Training loss: 2.5523474939352133
Validation loss: 2.498164577864189

Epoch: 5| Step: 2
Training loss: 2.6938580555496436
Validation loss: 2.4881918319564136

Epoch: 5| Step: 3
Training loss: 1.829630305359739
Validation loss: 2.5028967953524157

Epoch: 5| Step: 4
Training loss: 2.51818518352002
Validation loss: 2.485124666969105

Epoch: 5| Step: 5
Training loss: 2.248276792380389
Validation loss: 2.47998043308617

Epoch: 5| Step: 6
Training loss: 2.306389442094712
Validation loss: 2.492551622880895

Epoch: 5| Step: 7
Training loss: 2.768310449985254
Validation loss: 2.5124243576980123

Epoch: 5| Step: 8
Training loss: 2.583955587282951
Validation loss: 2.509433142302708

Epoch: 5| Step: 9
Training loss: 2.1584992770860287
Validation loss: 2.5506243461587563

Epoch: 5| Step: 10
Training loss: 2.261149438548294
Validation loss: 2.543494135604966

Epoch: 268| Step: 0
Training loss: 2.354588383624371
Validation loss: 2.532316066694767

Epoch: 5| Step: 1
Training loss: 2.548146872259325
Validation loss: 2.5286921474561

Epoch: 5| Step: 2
Training loss: 2.5425424994983605
Validation loss: 2.526435761599806

Epoch: 5| Step: 3
Training loss: 2.4482192048681934
Validation loss: 2.515806620217366

Epoch: 5| Step: 4
Training loss: 2.7170559220046946
Validation loss: 2.538985807587358

Epoch: 5| Step: 5
Training loss: 2.0862154543275246
Validation loss: 2.518667468462848

Epoch: 5| Step: 6
Training loss: 2.1978378161227012
Validation loss: 2.533831517746314

Epoch: 5| Step: 7
Training loss: 2.191221395981537
Validation loss: 2.5116058228790483

Epoch: 5| Step: 8
Training loss: 2.739391325010534
Validation loss: 2.494674387680469

Epoch: 5| Step: 9
Training loss: 2.311709088314657
Validation loss: 2.494254261144631

Epoch: 5| Step: 10
Training loss: 2.208207348762655
Validation loss: 2.492522997960326

Epoch: 269| Step: 0
Training loss: 2.4047255207548486
Validation loss: 2.488567602468962

Epoch: 5| Step: 1
Training loss: 2.3950945392338223
Validation loss: 2.4916968117017824

Epoch: 5| Step: 2
Training loss: 2.501617480596519
Validation loss: 2.4918564002925967

Epoch: 5| Step: 3
Training loss: 2.4680165034133394
Validation loss: 2.5246288164815636

Epoch: 5| Step: 4
Training loss: 2.349002090576593
Validation loss: 2.530018450016231

Epoch: 5| Step: 5
Training loss: 2.2150082266420132
Validation loss: 2.5315275942700968

Epoch: 5| Step: 6
Training loss: 2.27050392724802
Validation loss: 2.5571436551703033

Epoch: 5| Step: 7
Training loss: 2.8719982564915543
Validation loss: 2.579240853672036

Epoch: 5| Step: 8
Training loss: 2.232996588793625
Validation loss: 2.5458930381268505

Epoch: 5| Step: 9
Training loss: 2.470947639518825
Validation loss: 2.5073700900100966

Epoch: 5| Step: 10
Training loss: 2.286726244362559
Validation loss: 2.4873607986737967

Epoch: 270| Step: 0
Training loss: 2.708903228270489
Validation loss: 2.486052300021919

Epoch: 5| Step: 1
Training loss: 2.3322768090067196
Validation loss: 2.4828403505799868

Epoch: 5| Step: 2
Training loss: 2.145311668712569
Validation loss: 2.489767253059985

Epoch: 5| Step: 3
Training loss: 2.714663360969664
Validation loss: 2.5217930385522016

Epoch: 5| Step: 4
Training loss: 2.7818831676739495
Validation loss: 2.5364046933604407

Epoch: 5| Step: 5
Training loss: 2.3288894524747508
Validation loss: 2.55256413661818

Epoch: 5| Step: 6
Training loss: 2.4557956809255606
Validation loss: 2.537960642481391

Epoch: 5| Step: 7
Training loss: 2.3038645163941176
Validation loss: 2.4793438460778585

Epoch: 5| Step: 8
Training loss: 2.4351160177677396
Validation loss: 2.4565639214774735

Epoch: 5| Step: 9
Training loss: 1.970539067285458
Validation loss: 2.4467255900401264

Epoch: 5| Step: 10
Training loss: 2.448816877915231
Validation loss: 2.444241425953613

Epoch: 271| Step: 0
Training loss: 2.286613117328737
Validation loss: 2.433373116328015

Epoch: 5| Step: 1
Training loss: 2.617998048896733
Validation loss: 2.450845968532977

Epoch: 5| Step: 2
Training loss: 2.490693125636667
Validation loss: 2.4503898486649214

Epoch: 5| Step: 3
Training loss: 2.721611358803218
Validation loss: 2.47026854572855

Epoch: 5| Step: 4
Training loss: 2.752092432377164
Validation loss: 2.47388940029685

Epoch: 5| Step: 5
Training loss: 2.6529546604358636
Validation loss: 2.520936800254487

Epoch: 5| Step: 6
Training loss: 2.1500982350817623
Validation loss: 2.5248750176896673

Epoch: 5| Step: 7
Training loss: 2.213622494886091
Validation loss: 2.5570454103079334

Epoch: 5| Step: 8
Training loss: 1.962525230294127
Validation loss: 2.538424443422013

Epoch: 5| Step: 9
Training loss: 2.1494197195447478
Validation loss: 2.5457000770318916

Epoch: 5| Step: 10
Training loss: 2.508106535314354
Validation loss: 2.536518107758518

Epoch: 272| Step: 0
Training loss: 2.506333339761006
Validation loss: 2.5410055127358464

Epoch: 5| Step: 1
Training loss: 2.4872249355343494
Validation loss: 2.5336085798083454

Epoch: 5| Step: 2
Training loss: 2.3096697215326474
Validation loss: 2.533313039634694

Epoch: 5| Step: 3
Training loss: 2.5175832388791157
Validation loss: 2.5406789475985563

Epoch: 5| Step: 4
Training loss: 2.5798597568276227
Validation loss: 2.5420972283567553

Epoch: 5| Step: 5
Training loss: 2.7711572864046623
Validation loss: 2.567556927429661

Epoch: 5| Step: 6
Training loss: 2.0385252730838204
Validation loss: 2.528327138535995

Epoch: 5| Step: 7
Training loss: 1.7118740218550752
Validation loss: 2.496365862179016

Epoch: 5| Step: 8
Training loss: 2.1907927662472124
Validation loss: 2.4912284389016204

Epoch: 5| Step: 9
Training loss: 2.868104045007482
Validation loss: 2.4519102470830556

Epoch: 5| Step: 10
Training loss: 2.0352673051813217
Validation loss: 2.4602826949412786

Epoch: 273| Step: 0
Training loss: 2.3339075562672082
Validation loss: 2.4504889700099604

Epoch: 5| Step: 1
Training loss: 2.5777408198012894
Validation loss: 2.4481880353500496

Epoch: 5| Step: 2
Training loss: 2.88881251242333
Validation loss: 2.4656944051880556

Epoch: 5| Step: 3
Training loss: 2.5094572478956705
Validation loss: 2.441067859718288

Epoch: 5| Step: 4
Training loss: 1.7547693656377783
Validation loss: 2.437541618444119

Epoch: 5| Step: 5
Training loss: 1.8173599856673643
Validation loss: 2.43919733215888

Epoch: 5| Step: 6
Training loss: 2.4184940488567404
Validation loss: 2.4569413791309977

Epoch: 5| Step: 7
Training loss: 2.838709461723946
Validation loss: 2.4446978440796756

Epoch: 5| Step: 8
Training loss: 2.4805048902386884
Validation loss: 2.5101256976544795

Epoch: 5| Step: 9
Training loss: 2.227644807880216
Validation loss: 2.515067497656825

Epoch: 5| Step: 10
Training loss: 2.243208808768169
Validation loss: 2.5249160686048207

Epoch: 274| Step: 0
Training loss: 2.3391643168192187
Validation loss: 2.53873705321936

Epoch: 5| Step: 1
Training loss: 2.8945801765538532
Validation loss: 2.523936049805627

Epoch: 5| Step: 2
Training loss: 2.23244419570671
Validation loss: 2.4668943856971546

Epoch: 5| Step: 3
Training loss: 2.420650049341489
Validation loss: 2.443477378803606

Epoch: 5| Step: 4
Training loss: 2.6359038273368385
Validation loss: 2.4087797540657943

Epoch: 5| Step: 5
Training loss: 2.1305843354090745
Validation loss: 2.4355804125009137

Epoch: 5| Step: 6
Training loss: 2.243787241337112
Validation loss: 2.4443394059076917

Epoch: 5| Step: 7
Training loss: 2.3014358599615785
Validation loss: 2.463280222412612

Epoch: 5| Step: 8
Training loss: 2.509195202078505
Validation loss: 2.483887518117917

Epoch: 5| Step: 9
Training loss: 2.4498624062340237
Validation loss: 2.5334511649211353

Epoch: 5| Step: 10
Training loss: 2.068699161331288
Validation loss: 2.5350288108675

Epoch: 275| Step: 0
Training loss: 2.0857430699633515
Validation loss: 2.5693475626475863

Epoch: 5| Step: 1
Training loss: 2.467724840767299
Validation loss: 2.553083418140774

Epoch: 5| Step: 2
Training loss: 2.2025810273558317
Validation loss: 2.527624430605136

Epoch: 5| Step: 3
Training loss: 2.428617480987387
Validation loss: 2.5259813750395583

Epoch: 5| Step: 4
Training loss: 2.5899650809979224
Validation loss: 2.4901041838529787

Epoch: 5| Step: 5
Training loss: 2.2457696564752734
Validation loss: 2.5086603861148653

Epoch: 5| Step: 6
Training loss: 2.201841914122996
Validation loss: 2.4774150308130434

Epoch: 5| Step: 7
Training loss: 2.275119434617106
Validation loss: 2.490177345403004

Epoch: 5| Step: 8
Training loss: 2.5695140955193754
Validation loss: 2.48775981721705

Epoch: 5| Step: 9
Training loss: 2.640671407980235
Validation loss: 2.476195272222195

Epoch: 5| Step: 10
Training loss: 2.4439164829375266
Validation loss: 2.4704548836977986

Epoch: 276| Step: 0
Training loss: 2.0261146774146708
Validation loss: 2.4467866022825238

Epoch: 5| Step: 1
Training loss: 2.244478338077986
Validation loss: 2.4439075067252225

Epoch: 5| Step: 2
Training loss: 2.1682535620208974
Validation loss: 2.481128361850712

Epoch: 5| Step: 3
Training loss: 2.0897330851978695
Validation loss: 2.456937025946873

Epoch: 5| Step: 4
Training loss: 2.5916810573983806
Validation loss: 2.4681761897617447

Epoch: 5| Step: 5
Training loss: 2.7923838609879037
Validation loss: 2.4722346060541294

Epoch: 5| Step: 6
Training loss: 2.8089588336528704
Validation loss: 2.4860641073421306

Epoch: 5| Step: 7
Training loss: 2.5467134202124004
Validation loss: 2.4829624148705935

Epoch: 5| Step: 8
Training loss: 1.5490884069108313
Validation loss: 2.512849850868164

Epoch: 5| Step: 9
Training loss: 2.548025327805137
Validation loss: 2.511395011830351

Epoch: 5| Step: 10
Training loss: 2.3972674072219218
Validation loss: 2.5229650535389747

Epoch: 277| Step: 0
Training loss: 2.3556930409900905
Validation loss: 2.477766347957759

Epoch: 5| Step: 1
Training loss: 2.1510729352573406
Validation loss: 2.4575424785433473

Epoch: 5| Step: 2
Training loss: 2.434902567862651
Validation loss: 2.427931854366053

Epoch: 5| Step: 3
Training loss: 2.298348713086376
Validation loss: 2.437474077379801

Epoch: 5| Step: 4
Training loss: 1.4389336941508875
Validation loss: 2.441920483057963

Epoch: 5| Step: 5
Training loss: 2.613280520132559
Validation loss: 2.426978663064542

Epoch: 5| Step: 6
Training loss: 2.707741208026719
Validation loss: 2.4671743808168336

Epoch: 5| Step: 7
Training loss: 2.219985295668009
Validation loss: 2.4842595673187504

Epoch: 5| Step: 8
Training loss: 2.6784031406397846
Validation loss: 2.5089548237637542

Epoch: 5| Step: 9
Training loss: 2.8129592520552347
Validation loss: 2.5431764594482003

Epoch: 5| Step: 10
Training loss: 2.049579842472639
Validation loss: 2.5026466972368

Epoch: 278| Step: 0
Training loss: 2.3753575507610467
Validation loss: 2.5024242675578523

Epoch: 5| Step: 1
Training loss: 2.4987768995965847
Validation loss: 2.5019301162495178

Epoch: 5| Step: 2
Training loss: 2.2965687657913274
Validation loss: 2.481334600465488

Epoch: 5| Step: 3
Training loss: 2.2765598943796217
Validation loss: 2.455773029965029

Epoch: 5| Step: 4
Training loss: 2.463692712219387
Validation loss: 2.422713363196524

Epoch: 5| Step: 5
Training loss: 2.002252026085716
Validation loss: 2.4453856807052117

Epoch: 5| Step: 6
Training loss: 1.9266869695819073
Validation loss: 2.4174284934702217

Epoch: 5| Step: 7
Training loss: 2.5267990916869025
Validation loss: 2.43984221575147

Epoch: 5| Step: 8
Training loss: 2.650970418056314
Validation loss: 2.447269265244235

Epoch: 5| Step: 9
Training loss: 2.41035398788089
Validation loss: 2.4912422612893828

Epoch: 5| Step: 10
Training loss: 2.430918783264644
Validation loss: 2.4757207048831105

Epoch: 279| Step: 0
Training loss: 2.6962018743260194
Validation loss: 2.5037329143132285

Epoch: 5| Step: 1
Training loss: 2.446644185800547
Validation loss: 2.5287179419665455

Epoch: 5| Step: 2
Training loss: 2.126778251247757
Validation loss: 2.5105763767809126

Epoch: 5| Step: 3
Training loss: 2.2457905705709145
Validation loss: 2.5015182827451343

Epoch: 5| Step: 4
Training loss: 1.9494776735360368
Validation loss: 2.4925197405961192

Epoch: 5| Step: 5
Training loss: 1.766385885034364
Validation loss: 2.4885169548149983

Epoch: 5| Step: 6
Training loss: 2.396498502084991
Validation loss: 2.459073804236377

Epoch: 5| Step: 7
Training loss: 2.677475797826979
Validation loss: 2.4318353909606634

Epoch: 5| Step: 8
Training loss: 2.750547007863756
Validation loss: 2.4159353172928677

Epoch: 5| Step: 9
Training loss: 2.4261029163805814
Validation loss: 2.437474576966315

Epoch: 5| Step: 10
Training loss: 2.136521129779527
Validation loss: 2.408479427776553

Epoch: 280| Step: 0
Training loss: 2.3710607686647704
Validation loss: 2.4109531864762377

Epoch: 5| Step: 1
Training loss: 2.5370998837570253
Validation loss: 2.427819331384446

Epoch: 5| Step: 2
Training loss: 2.0606068100732404
Validation loss: 2.4283360742675444

Epoch: 5| Step: 3
Training loss: 2.0961761083073567
Validation loss: 2.417823299018612

Epoch: 5| Step: 4
Training loss: 2.5627798532398125
Validation loss: 2.4430442957020198

Epoch: 5| Step: 5
Training loss: 2.286012251199516
Validation loss: 2.454900077539998

Epoch: 5| Step: 6
Training loss: 2.5999600627472836
Validation loss: 2.473884482109906

Epoch: 5| Step: 7
Training loss: 2.0698258889729932
Validation loss: 2.4868071812904415

Epoch: 5| Step: 8
Training loss: 2.6257325921264765
Validation loss: 2.481272117685821

Epoch: 5| Step: 9
Training loss: 2.0770740576421862
Validation loss: 2.4733542792400716

Epoch: 5| Step: 10
Training loss: 2.3723974524505373
Validation loss: 2.436481247160013

Epoch: 281| Step: 0
Training loss: 2.2539551199072605
Validation loss: 2.4240064246763544

Epoch: 5| Step: 1
Training loss: 2.3690720915414656
Validation loss: 2.422664295394324

Epoch: 5| Step: 2
Training loss: 2.680876443089609
Validation loss: 2.420476038755891

Epoch: 5| Step: 3
Training loss: 1.974057868588552
Validation loss: 2.4050409235617196

Epoch: 5| Step: 4
Training loss: 2.4769700734837476
Validation loss: 2.4246422145001802

Epoch: 5| Step: 5
Training loss: 1.827120382643048
Validation loss: 2.4229814122524407

Epoch: 5| Step: 6
Training loss: 2.701923257580784
Validation loss: 2.453529973981776

Epoch: 5| Step: 7
Training loss: 2.206929270320918
Validation loss: 2.4805907335970794

Epoch: 5| Step: 8
Training loss: 1.877242400457403
Validation loss: 2.508263485394256

Epoch: 5| Step: 9
Training loss: 2.8213848917720408
Validation loss: 2.504739506977959

Epoch: 5| Step: 10
Training loss: 2.2380064151457204
Validation loss: 2.4480755135011676

Epoch: 282| Step: 0
Training loss: 2.188449217707623
Validation loss: 2.4725149254535186

Epoch: 5| Step: 1
Training loss: 2.4836529336209274
Validation loss: 2.458651001415684

Epoch: 5| Step: 2
Training loss: 2.32036223181658
Validation loss: 2.4350981741397515

Epoch: 5| Step: 3
Training loss: 2.4751039656564138
Validation loss: 2.449917749870518

Epoch: 5| Step: 4
Training loss: 2.2559052433783764
Validation loss: 2.4278387152663807

Epoch: 5| Step: 5
Training loss: 2.542985251002531
Validation loss: 2.424931956703399

Epoch: 5| Step: 6
Training loss: 2.1248784871981896
Validation loss: 2.4563106557034557

Epoch: 5| Step: 7
Training loss: 2.520685259881194
Validation loss: 2.479352641263166

Epoch: 5| Step: 8
Training loss: 2.3884129481368244
Validation loss: 2.4974858100988353

Epoch: 5| Step: 9
Training loss: 2.19079048086776
Validation loss: 2.4985385930270976

Epoch: 5| Step: 10
Training loss: 2.1336858170101918
Validation loss: 2.5239037056692397

Epoch: 283| Step: 0
Training loss: 2.440059980374398
Validation loss: 2.5268704572735103

Epoch: 5| Step: 1
Training loss: 1.9208767166810201
Validation loss: 2.5340106382392977

Epoch: 5| Step: 2
Training loss: 2.3830977472387254
Validation loss: 2.5260111380786294

Epoch: 5| Step: 3
Training loss: 2.4055979452100935
Validation loss: 2.4919272553176337

Epoch: 5| Step: 4
Training loss: 2.096141644875088
Validation loss: 2.4632347914981807

Epoch: 5| Step: 5
Training loss: 2.509062838585836
Validation loss: 2.4327600057260272

Epoch: 5| Step: 6
Training loss: 2.667315692200976
Validation loss: 2.3890662605201696

Epoch: 5| Step: 7
Training loss: 2.2857070650259135
Validation loss: 2.412853395478487

Epoch: 5| Step: 8
Training loss: 2.57837504705983
Validation loss: 2.3846334325167278

Epoch: 5| Step: 9
Training loss: 2.1259666936782886
Validation loss: 2.3972195852621927

Epoch: 5| Step: 10
Training loss: 2.1429356265454693
Validation loss: 2.416766412506079

Epoch: 284| Step: 0
Training loss: 2.4739159724306443
Validation loss: 2.451562937360648

Epoch: 5| Step: 1
Training loss: 2.306394197251466
Validation loss: 2.4684790518009243

Epoch: 5| Step: 2
Training loss: 1.91733952473705
Validation loss: 2.5117173088109275

Epoch: 5| Step: 3
Training loss: 2.2349088871282086
Validation loss: 2.5399397628977254

Epoch: 5| Step: 4
Training loss: 2.696217172252174
Validation loss: 2.5642006435855516

Epoch: 5| Step: 5
Training loss: 2.2793777307651437
Validation loss: 2.540927840771027

Epoch: 5| Step: 6
Training loss: 2.374849314677783
Validation loss: 2.489923797227486

Epoch: 5| Step: 7
Training loss: 2.5693518979929966
Validation loss: 2.469060032812643

Epoch: 5| Step: 8
Training loss: 2.53362624164912
Validation loss: 2.441578466498179

Epoch: 5| Step: 9
Training loss: 1.9932540731183899
Validation loss: 2.417785588822723

Epoch: 5| Step: 10
Training loss: 2.1957756449910786
Validation loss: 2.4101528228130698

Epoch: 285| Step: 0
Training loss: 2.3376391282725315
Validation loss: 2.3983844402355428

Epoch: 5| Step: 1
Training loss: 2.4223382322234657
Validation loss: 2.390912101932453

Epoch: 5| Step: 2
Training loss: 2.2634978733545705
Validation loss: 2.3876573744945153

Epoch: 5| Step: 3
Training loss: 2.357339953979988
Validation loss: 2.3937727410952934

Epoch: 5| Step: 4
Training loss: 2.5129255892768554
Validation loss: 2.4025046802144927

Epoch: 5| Step: 5
Training loss: 2.197638531724311
Validation loss: 2.420161187805656

Epoch: 5| Step: 6
Training loss: 2.0517090070349497
Validation loss: 2.451572577282338

Epoch: 5| Step: 7
Training loss: 2.068756555276033
Validation loss: 2.454625338877256

Epoch: 5| Step: 8
Training loss: 2.499649977022662
Validation loss: 2.49018729757149

Epoch: 5| Step: 9
Training loss: 2.205719198289225
Validation loss: 2.501997883611764

Epoch: 5| Step: 10
Training loss: 2.657021803083397
Validation loss: 2.509292837761502

Epoch: 286| Step: 0
Training loss: 2.253793908663135
Validation loss: 2.5776199820685437

Epoch: 5| Step: 1
Training loss: 2.4807749641820793
Validation loss: 2.6428927034611527

Epoch: 5| Step: 2
Training loss: 1.971897092474794
Validation loss: 2.6251933436330193

Epoch: 5| Step: 3
Training loss: 2.530043891556169
Validation loss: 2.641846329395254

Epoch: 5| Step: 4
Training loss: 2.306919891739168
Validation loss: 2.5198490787842824

Epoch: 5| Step: 5
Training loss: 2.364435188481292
Validation loss: 2.448887137848072

Epoch: 5| Step: 6
Training loss: 1.980893302119916
Validation loss: 2.388556573035077

Epoch: 5| Step: 7
Training loss: 2.4454902364956714
Validation loss: 2.394458790198199

Epoch: 5| Step: 8
Training loss: 2.167565220574254
Validation loss: 2.3760214672307263

Epoch: 5| Step: 9
Training loss: 2.156980418456377
Validation loss: 2.3801214786107296

Epoch: 5| Step: 10
Training loss: 2.9894224294145544
Validation loss: 2.3852146288990674

Epoch: 287| Step: 0
Training loss: 1.7826327929582215
Validation loss: 2.3994201878842065

Epoch: 5| Step: 1
Training loss: 2.3619695885466516
Validation loss: 2.4034053574784826

Epoch: 5| Step: 2
Training loss: 1.6325763732430516
Validation loss: 2.4361985347245834

Epoch: 5| Step: 3
Training loss: 2.377257729590279
Validation loss: 2.4694051946609727

Epoch: 5| Step: 4
Training loss: 2.3798228034404465
Validation loss: 2.5177949903812764

Epoch: 5| Step: 5
Training loss: 2.4884680853006853
Validation loss: 2.524852257931158

Epoch: 5| Step: 6
Training loss: 2.441891748601819
Validation loss: 2.5644199393026863

Epoch: 5| Step: 7
Training loss: 2.4397106416507945
Validation loss: 2.563029878997646

Epoch: 5| Step: 8
Training loss: 2.6459704586349315
Validation loss: 2.539045748343791

Epoch: 5| Step: 9
Training loss: 2.1832965245917544
Validation loss: 2.498512204778296

Epoch: 5| Step: 10
Training loss: 2.355170336999891
Validation loss: 2.4593995199727052

Epoch: 288| Step: 0
Training loss: 2.3464358390003786
Validation loss: 2.4376680764768777

Epoch: 5| Step: 1
Training loss: 2.5032894428162678
Validation loss: 2.3987586863988044

Epoch: 5| Step: 2
Training loss: 2.318989900173024
Validation loss: 2.382822546625904

Epoch: 5| Step: 3
Training loss: 2.27927543152804
Validation loss: 2.393276949817713

Epoch: 5| Step: 4
Training loss: 2.2835239938737066
Validation loss: 2.4007515680763367

Epoch: 5| Step: 5
Training loss: 1.9740485688237752
Validation loss: 2.4351211721715442

Epoch: 5| Step: 6
Training loss: 2.217453913849482
Validation loss: 2.442798614845125

Epoch: 5| Step: 7
Training loss: 2.1772541423271563
Validation loss: 2.474842042627528

Epoch: 5| Step: 8
Training loss: 2.4232900115928437
Validation loss: 2.522560543026182

Epoch: 5| Step: 9
Training loss: 2.1642967124922103
Validation loss: 2.5268676307309845

Epoch: 5| Step: 10
Training loss: 2.469464548737378
Validation loss: 2.5422091060735545

Epoch: 289| Step: 0
Training loss: 2.367411284995021
Validation loss: 2.498084204856493

Epoch: 5| Step: 1
Training loss: 2.1178039554211368
Validation loss: 2.4874888835758973

Epoch: 5| Step: 2
Training loss: 2.1936190443810744
Validation loss: 2.5024896151393254

Epoch: 5| Step: 3
Training loss: 2.425924054302284
Validation loss: 2.4830279669685367

Epoch: 5| Step: 4
Training loss: 2.5720731044779916
Validation loss: 2.4450606276335463

Epoch: 5| Step: 5
Training loss: 2.3364121583164756
Validation loss: 2.4196406902452487

Epoch: 5| Step: 6
Training loss: 2.283273818175531
Validation loss: 2.388316099602479

Epoch: 5| Step: 7
Training loss: 2.3501314897477554
Validation loss: 2.353772236977983

Epoch: 5| Step: 8
Training loss: 2.2765748703724586
Validation loss: 2.3657591585367537

Epoch: 5| Step: 9
Training loss: 2.079730224170522
Validation loss: 2.388971423734269

Epoch: 5| Step: 10
Training loss: 2.0852167262958012
Validation loss: 2.3867197113440657

Epoch: 290| Step: 0
Training loss: 2.0282328572563837
Validation loss: 2.4504281828189023

Epoch: 5| Step: 1
Training loss: 1.9588775757784909
Validation loss: 2.5471179100693346

Epoch: 5| Step: 2
Training loss: 2.2220136253152063
Validation loss: 2.641461329193079

Epoch: 5| Step: 3
Training loss: 2.0998515712417243
Validation loss: 2.5836199946405607

Epoch: 5| Step: 4
Training loss: 2.470760830292032
Validation loss: 2.506276831970288

Epoch: 5| Step: 5
Training loss: 2.586070815046837
Validation loss: 2.4450571917039134

Epoch: 5| Step: 6
Training loss: 2.3722461998010878
Validation loss: 2.3949969932336383

Epoch: 5| Step: 7
Training loss: 2.3331440326559183
Validation loss: 2.387937582279403

Epoch: 5| Step: 8
Training loss: 2.182803862437892
Validation loss: 2.392447085882428

Epoch: 5| Step: 9
Training loss: 2.562460829272595
Validation loss: 2.387984239585018

Epoch: 5| Step: 10
Training loss: 2.2602619756924165
Validation loss: 2.4100671181540236

Epoch: 291| Step: 0
Training loss: 2.2602873968847663
Validation loss: 2.4483037745072362

Epoch: 5| Step: 1
Training loss: 1.7439633201364073
Validation loss: 2.4677696332369745

Epoch: 5| Step: 2
Training loss: 2.532602961142757
Validation loss: 2.478990175399185

Epoch: 5| Step: 3
Training loss: 1.9793119343767631
Validation loss: 2.4842098318165253

Epoch: 5| Step: 4
Training loss: 2.0793987758734502
Validation loss: 2.423526460990796

Epoch: 5| Step: 5
Training loss: 2.593370800564858
Validation loss: 2.3945913090653494

Epoch: 5| Step: 6
Training loss: 2.2670312134857564
Validation loss: 2.393837792610401

Epoch: 5| Step: 7
Training loss: 2.2655276573579193
Validation loss: 2.4011491584130664

Epoch: 5| Step: 8
Training loss: 2.4850995428768226
Validation loss: 2.4006293229271134

Epoch: 5| Step: 9
Training loss: 2.309158178740859
Validation loss: 2.433064145841747

Epoch: 5| Step: 10
Training loss: 2.3515568223041923
Validation loss: 2.4618873785274347

Epoch: 292| Step: 0
Training loss: 2.426695130918355
Validation loss: 2.466809727481478

Epoch: 5| Step: 1
Training loss: 2.246565528747665
Validation loss: 2.4698382256335725

Epoch: 5| Step: 2
Training loss: 2.5563933950184574
Validation loss: 2.4516521761654437

Epoch: 5| Step: 3
Training loss: 2.163598296578813
Validation loss: 2.4683862140084916

Epoch: 5| Step: 4
Training loss: 2.511644899222914
Validation loss: 2.4444475019724203

Epoch: 5| Step: 5
Training loss: 2.2779819647700523
Validation loss: 2.4403954844410864

Epoch: 5| Step: 6
Training loss: 1.9348746940789499
Validation loss: 2.4467326232820654

Epoch: 5| Step: 7
Training loss: 2.1441636734590817
Validation loss: 2.436196686864239

Epoch: 5| Step: 8
Training loss: 2.1726416462857028
Validation loss: 2.4213109106094257

Epoch: 5| Step: 9
Training loss: 2.3006575183596247
Validation loss: 2.4317780070202497

Epoch: 5| Step: 10
Training loss: 2.0450147955622726
Validation loss: 2.4677207621677377

Epoch: 293| Step: 0
Training loss: 2.4968388598981237
Validation loss: 2.4492829474958087

Epoch: 5| Step: 1
Training loss: 2.3836100259860977
Validation loss: 2.451020562339194

Epoch: 5| Step: 2
Training loss: 2.2690802173582134
Validation loss: 2.442596251060832

Epoch: 5| Step: 3
Training loss: 2.217949628865106
Validation loss: 2.407920388666198

Epoch: 5| Step: 4
Training loss: 2.4337167968992954
Validation loss: 2.416339097472891

Epoch: 5| Step: 5
Training loss: 1.8993040391294884
Validation loss: 2.406844537759145

Epoch: 5| Step: 6
Training loss: 1.9102709527086599
Validation loss: 2.3919352314151032

Epoch: 5| Step: 7
Training loss: 2.238143836791434
Validation loss: 2.431975301401388

Epoch: 5| Step: 8
Training loss: 2.2463881855249146
Validation loss: 2.44942862360911

Epoch: 5| Step: 9
Training loss: 2.312235739790285
Validation loss: 2.47123112683391

Epoch: 5| Step: 10
Training loss: 2.185973479470416
Validation loss: 2.551781597637007

Epoch: 294| Step: 0
Training loss: 2.418944918247848
Validation loss: 2.6114749810549416

Epoch: 5| Step: 1
Training loss: 2.838372480384198
Validation loss: 2.6074136455277435

Epoch: 5| Step: 2
Training loss: 2.125279800843305
Validation loss: 2.5331431299911693

Epoch: 5| Step: 3
Training loss: 1.7979156797663463
Validation loss: 2.4468424775396063

Epoch: 5| Step: 4
Training loss: 2.1847583483488355
Validation loss: 2.396183265144777

Epoch: 5| Step: 5
Training loss: 2.272791610153917
Validation loss: 2.3981400647721376

Epoch: 5| Step: 6
Training loss: 1.9940433609245292
Validation loss: 2.411095962047108

Epoch: 5| Step: 7
Training loss: 2.3006989702366427
Validation loss: 2.4092890088485723

Epoch: 5| Step: 8
Training loss: 2.5771377060216127
Validation loss: 2.4453914047354117

Epoch: 5| Step: 9
Training loss: 2.018622837844778
Validation loss: 2.477333065683894

Epoch: 5| Step: 10
Training loss: 2.6609541582805787
Validation loss: 2.54193463687259

Epoch: 295| Step: 0
Training loss: 2.2434904453115787
Validation loss: 2.5444536474155544

Epoch: 5| Step: 1
Training loss: 2.666651835002979
Validation loss: 2.515972673159517

Epoch: 5| Step: 2
Training loss: 2.2841310467378784
Validation loss: 2.543048888946872

Epoch: 5| Step: 3
Training loss: 2.0885121889642275
Validation loss: 2.5184289989740205

Epoch: 5| Step: 4
Training loss: 2.0800239090278954
Validation loss: 2.511550817328443

Epoch: 5| Step: 5
Training loss: 2.5444074038993483
Validation loss: 2.468840889057893

Epoch: 5| Step: 6
Training loss: 2.3623989507469383
Validation loss: 2.435198815375536

Epoch: 5| Step: 7
Training loss: 1.9028603480940882
Validation loss: 2.4140352817817874

Epoch: 5| Step: 8
Training loss: 2.0069573507220295
Validation loss: 2.4048225026395325

Epoch: 5| Step: 9
Training loss: 2.1068461765794813
Validation loss: 2.4230357140532415

Epoch: 5| Step: 10
Training loss: 2.2220320805689635
Validation loss: 2.4109705782510895

Epoch: 296| Step: 0
Training loss: 2.5037751304824116
Validation loss: 2.414238920348532

Epoch: 5| Step: 1
Training loss: 2.042540758863194
Validation loss: 2.4102587719053425

Epoch: 5| Step: 2
Training loss: 2.336730720287848
Validation loss: 2.447287052604381

Epoch: 5| Step: 3
Training loss: 2.108595414388932
Validation loss: 2.4355043919587103

Epoch: 5| Step: 4
Training loss: 1.9751479322827024
Validation loss: 2.434172329561902

Epoch: 5| Step: 5
Training loss: 2.3192376623916235
Validation loss: 2.458223396402891

Epoch: 5| Step: 6
Training loss: 1.8981630103331477
Validation loss: 2.4499292091788734

Epoch: 5| Step: 7
Training loss: 2.5963939381840286
Validation loss: 2.4411521336374133

Epoch: 5| Step: 8
Training loss: 2.4908966260951275
Validation loss: 2.434546025625951

Epoch: 5| Step: 9
Training loss: 1.9906495983574186
Validation loss: 2.462443600655191

Epoch: 5| Step: 10
Training loss: 1.9338637038315156
Validation loss: 2.457920892557723

Epoch: 297| Step: 0
Training loss: 2.147094750853028
Validation loss: 2.4522626615348693

Epoch: 5| Step: 1
Training loss: 1.9352354536299525
Validation loss: 2.449119031884249

Epoch: 5| Step: 2
Training loss: 2.0665403153137114
Validation loss: 2.438109333558856

Epoch: 5| Step: 3
Training loss: 2.587032581809843
Validation loss: 2.4602545177714177

Epoch: 5| Step: 4
Training loss: 1.9490285409840864
Validation loss: 2.534632499149334

Epoch: 5| Step: 5
Training loss: 1.932525524646923
Validation loss: 2.535268569511711

Epoch: 5| Step: 6
Training loss: 2.385263651864047
Validation loss: 2.5170696158707484

Epoch: 5| Step: 7
Training loss: 2.393162197522329
Validation loss: 2.4741473820749205

Epoch: 5| Step: 8
Training loss: 2.0139809934520443
Validation loss: 2.455354338954501

Epoch: 5| Step: 9
Training loss: 2.0443074670574735
Validation loss: 2.408098849493515

Epoch: 5| Step: 10
Training loss: 2.7709753148312335
Validation loss: 2.388904213607766

Epoch: 298| Step: 0
Training loss: 2.4547780292797694
Validation loss: 2.371066986758443

Epoch: 5| Step: 1
Training loss: 2.4462326317405974
Validation loss: 2.3802520632330983

Epoch: 5| Step: 2
Training loss: 1.6882972953065694
Validation loss: 2.404310418781541

Epoch: 5| Step: 3
Training loss: 1.6385713348645208
Validation loss: 2.4257767077364436

Epoch: 5| Step: 4
Training loss: 2.4834317509992774
Validation loss: 2.487021669629054

Epoch: 5| Step: 5
Training loss: 2.1107983343528782
Validation loss: 2.479241892651483

Epoch: 5| Step: 6
Training loss: 2.173218455681739
Validation loss: 2.4690005059937725

Epoch: 5| Step: 7
Training loss: 2.7430505508398655
Validation loss: 2.5110403004632382

Epoch: 5| Step: 8
Training loss: 2.3216971944137823
Validation loss: 2.4785583327436176

Epoch: 5| Step: 9
Training loss: 1.7250620678778505
Validation loss: 2.444068825956945

Epoch: 5| Step: 10
Training loss: 2.2104989954806578
Validation loss: 2.431389600647009

Epoch: 299| Step: 0
Training loss: 1.6273670562965166
Validation loss: 2.439530427511672

Epoch: 5| Step: 1
Training loss: 2.1977873729504496
Validation loss: 2.441246773185169

Epoch: 5| Step: 2
Training loss: 1.9864608135184567
Validation loss: 2.485969687428705

Epoch: 5| Step: 3
Training loss: 2.0419492201660687
Validation loss: 2.5141056246632862

Epoch: 5| Step: 4
Training loss: 2.4314846249219197
Validation loss: 2.557865530971182

Epoch: 5| Step: 5
Training loss: 1.9926094954593219
Validation loss: 2.504597001880077

Epoch: 5| Step: 6
Training loss: 2.161893453042293
Validation loss: 2.4877358795786915

Epoch: 5| Step: 7
Training loss: 2.5721168561940813
Validation loss: 2.432420641841032

Epoch: 5| Step: 8
Training loss: 2.4795884380011324
Validation loss: 2.416284750745226

Epoch: 5| Step: 9
Training loss: 2.183924777848984
Validation loss: 2.4279807724237408

Epoch: 5| Step: 10
Training loss: 2.290136092027573
Validation loss: 2.4297545653642465

Epoch: 300| Step: 0
Training loss: 2.026523902072558
Validation loss: 2.4647708339439105

Epoch: 5| Step: 1
Training loss: 1.9819054442984334
Validation loss: 2.473517586393821

Epoch: 5| Step: 2
Training loss: 2.242156237872762
Validation loss: 2.490090062759216

Epoch: 5| Step: 3
Training loss: 2.6732514165597885
Validation loss: 2.5165718593177786

Epoch: 5| Step: 4
Training loss: 2.43356122382457
Validation loss: 2.4768108216123172

Epoch: 5| Step: 5
Training loss: 2.3003561407592117
Validation loss: 2.4496791117985843

Epoch: 5| Step: 6
Training loss: 1.4128359960447163
Validation loss: 2.4072158999278566

Epoch: 5| Step: 7
Training loss: 2.1039425444137234
Validation loss: 2.3987948842263203

Epoch: 5| Step: 8
Training loss: 1.9412988521719714
Validation loss: 2.3965417819443307

Epoch: 5| Step: 9
Training loss: 2.2610647675838984
Validation loss: 2.395213875176583

Epoch: 5| Step: 10
Training loss: 2.3721328293660644
Validation loss: 2.393016293994388

Testing loss: 2.711700771737076
