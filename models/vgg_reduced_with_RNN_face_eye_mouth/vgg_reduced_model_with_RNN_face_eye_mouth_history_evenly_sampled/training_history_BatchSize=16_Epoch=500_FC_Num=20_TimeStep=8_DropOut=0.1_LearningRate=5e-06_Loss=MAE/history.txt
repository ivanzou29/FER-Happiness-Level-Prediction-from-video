Epoch: 1| Step: 0
Training loss: 5.927054405212402
Validation loss: 5.187766121279809

Epoch: 6| Step: 1
Training loss: 5.582765579223633
Validation loss: 5.181594899905625

Epoch: 6| Step: 2
Training loss: 5.6385955810546875
Validation loss: 5.175125880907941

Epoch: 6| Step: 3
Training loss: 4.581692218780518
Validation loss: 5.169848521550496

Epoch: 6| Step: 4
Training loss: 3.0891144275665283
Validation loss: 5.164462976558234

Epoch: 6| Step: 5
Training loss: 3.7423014640808105
Validation loss: 5.159114058299731

Epoch: 6| Step: 6
Training loss: 6.2909393310546875
Validation loss: 5.154033630124984

Epoch: 6| Step: 7
Training loss: 4.8482747077941895
Validation loss: 5.149415487884193

Epoch: 6| Step: 8
Training loss: 4.374086380004883
Validation loss: 5.144540945688884

Epoch: 6| Step: 9
Training loss: 4.286218643188477
Validation loss: 5.139854077369936

Epoch: 6| Step: 10
Training loss: 4.776680946350098
Validation loss: 5.134939352671306

Epoch: 6| Step: 11
Training loss: 5.361742973327637
Validation loss: 5.130092349103702

Epoch: 6| Step: 12
Training loss: 5.953790664672852
Validation loss: 5.124882626277144

Epoch: 6| Step: 13
Training loss: 4.7510457038879395
Validation loss: 5.11985763939478

Epoch: 2| Step: 0
Training loss: 5.851465225219727
Validation loss: 5.114829350543278

Epoch: 6| Step: 1
Training loss: 4.717784881591797
Validation loss: 5.108840562963999

Epoch: 6| Step: 2
Training loss: 4.774609565734863
Validation loss: 5.103189842675322

Epoch: 6| Step: 3
Training loss: 4.642345428466797
Validation loss: 5.097110486799671

Epoch: 6| Step: 4
Training loss: 4.437732696533203
Validation loss: 5.09120237699119

Epoch: 6| Step: 5
Training loss: 6.244965553283691
Validation loss: 5.084452885453419

Epoch: 6| Step: 6
Training loss: 5.237251281738281
Validation loss: 5.077540459171418

Epoch: 6| Step: 7
Training loss: 3.944389820098877
Validation loss: 5.070219732099964

Epoch: 6| Step: 8
Training loss: 4.84763240814209
Validation loss: 5.062734639772805

Epoch: 6| Step: 9
Training loss: 4.980447769165039
Validation loss: 5.055503429905061

Epoch: 6| Step: 10
Training loss: 4.884265899658203
Validation loss: 5.0465096094275035

Epoch: 6| Step: 11
Training loss: 5.0647735595703125
Validation loss: 5.038094602605348

Epoch: 6| Step: 12
Training loss: 5.357344627380371
Validation loss: 5.029060286860312

Epoch: 6| Step: 13
Training loss: 1.80062997341156
Validation loss: 5.019455514928346

Epoch: 3| Step: 0
Training loss: 6.258303642272949
Validation loss: 5.008590400859874

Epoch: 6| Step: 1
Training loss: 5.414216995239258
Validation loss: 4.998113293801585

Epoch: 6| Step: 2
Training loss: 5.369429588317871
Validation loss: 4.986800768042124

Epoch: 6| Step: 3
Training loss: 4.662405967712402
Validation loss: 4.9750815668413715

Epoch: 6| Step: 4
Training loss: 5.467428207397461
Validation loss: 4.963564165176884

Epoch: 6| Step: 5
Training loss: 3.79412579536438
Validation loss: 4.949900324626635

Epoch: 6| Step: 6
Training loss: 3.785738229751587
Validation loss: 4.937751777710453

Epoch: 6| Step: 7
Training loss: 4.031670093536377
Validation loss: 4.923975657391292

Epoch: 6| Step: 8
Training loss: 3.4245290756225586
Validation loss: 4.909785147636168

Epoch: 6| Step: 9
Training loss: 3.4663801193237305
Validation loss: 4.894380405385007

Epoch: 6| Step: 10
Training loss: 5.353661060333252
Validation loss: 4.880067297207412

Epoch: 6| Step: 11
Training loss: 4.213315963745117
Validation loss: 4.863996541628274

Epoch: 6| Step: 12
Training loss: 5.663041114807129
Validation loss: 4.8470449037449335

Epoch: 6| Step: 13
Training loss: 5.519589900970459
Validation loss: 4.828678971977644

Epoch: 4| Step: 0
Training loss: 4.949853897094727
Validation loss: 4.8108419551644275

Epoch: 6| Step: 1
Training loss: 3.365530490875244
Validation loss: 4.7909086596581245

Epoch: 6| Step: 2
Training loss: 5.920275688171387
Validation loss: 4.771482590706118

Epoch: 6| Step: 3
Training loss: 4.368149757385254
Validation loss: 4.750368969414824

Epoch: 6| Step: 4
Training loss: 3.882690906524658
Validation loss: 4.731298538946336

Epoch: 6| Step: 5
Training loss: 4.458491325378418
Validation loss: 4.709206560606598

Epoch: 6| Step: 6
Training loss: 4.615546226501465
Validation loss: 4.68726909288796

Epoch: 6| Step: 7
Training loss: 5.285923957824707
Validation loss: 4.665354367225401

Epoch: 6| Step: 8
Training loss: 4.44310188293457
Validation loss: 4.641226594166089

Epoch: 6| Step: 9
Training loss: 5.352504253387451
Validation loss: 4.616943446538782

Epoch: 6| Step: 10
Training loss: 3.3001933097839355
Validation loss: 4.592293754700692

Epoch: 6| Step: 11
Training loss: 4.381799221038818
Validation loss: 4.566091035002021

Epoch: 6| Step: 12
Training loss: 3.7643826007843018
Validation loss: 4.541889980275144

Epoch: 6| Step: 13
Training loss: 4.175698280334473
Validation loss: 4.514098254583216

Epoch: 5| Step: 0
Training loss: 4.414190292358398
Validation loss: 4.487337507227416

Epoch: 6| Step: 1
Training loss: 3.2761096954345703
Validation loss: 4.460554245979555

Epoch: 6| Step: 2
Training loss: 4.896554946899414
Validation loss: 4.431250285076839

Epoch: 6| Step: 3
Training loss: 4.929821014404297
Validation loss: 4.404302191990678

Epoch: 6| Step: 4
Training loss: 3.858219623565674
Validation loss: 4.3772165493298605

Epoch: 6| Step: 5
Training loss: 4.039429664611816
Validation loss: 4.349722613570511

Epoch: 6| Step: 6
Training loss: 4.50819206237793
Validation loss: 4.323754287535144

Epoch: 6| Step: 7
Training loss: 4.377707481384277
Validation loss: 4.29628985927951

Epoch: 6| Step: 8
Training loss: 3.9866652488708496
Validation loss: 4.26939377220728

Epoch: 6| Step: 9
Training loss: 2.894017219543457
Validation loss: 4.243836705402662

Epoch: 6| Step: 10
Training loss: 3.671165704727173
Validation loss: 4.21697727582788

Epoch: 6| Step: 11
Training loss: 3.8907694816589355
Validation loss: 4.192637992161576

Epoch: 6| Step: 12
Training loss: 3.8750147819519043
Validation loss: 4.169486312456028

Epoch: 6| Step: 13
Training loss: 5.873448371887207
Validation loss: 4.146906719412855

Epoch: 6| Step: 0
Training loss: 4.00408935546875
Validation loss: 4.125378131866455

Epoch: 6| Step: 1
Training loss: 4.460487365722656
Validation loss: 4.1028884098094

Epoch: 6| Step: 2
Training loss: 3.477151393890381
Validation loss: 4.079751491546631

Epoch: 6| Step: 3
Training loss: 3.508640766143799
Validation loss: 4.057553137502363

Epoch: 6| Step: 4
Training loss: 3.927320957183838
Validation loss: 4.035254129799464

Epoch: 6| Step: 5
Training loss: 3.8675801753997803
Validation loss: 4.0118670822471705

Epoch: 6| Step: 6
Training loss: 5.150341033935547
Validation loss: 3.9910045900652484

Epoch: 6| Step: 7
Training loss: 3.161325454711914
Validation loss: 3.9699765225892425

Epoch: 6| Step: 8
Training loss: 3.0095083713531494
Validation loss: 3.9491246284977084

Epoch: 6| Step: 9
Training loss: 4.584426403045654
Validation loss: 3.9288155263470066

Epoch: 6| Step: 10
Training loss: 3.675150156021118
Validation loss: 3.9083888582004014

Epoch: 6| Step: 11
Training loss: 2.8922653198242188
Validation loss: 3.891459024080666

Epoch: 6| Step: 12
Training loss: 4.177151203155518
Validation loss: 3.874906929590369

Epoch: 6| Step: 13
Training loss: 3.685328245162964
Validation loss: 3.855106751124064

Epoch: 7| Step: 0
Training loss: 2.3793773651123047
Validation loss: 3.836294517722181

Epoch: 6| Step: 1
Training loss: 3.55375337600708
Validation loss: 3.8199735661988616

Epoch: 6| Step: 2
Training loss: 4.437734603881836
Validation loss: 3.8027073978095927

Epoch: 6| Step: 3
Training loss: 3.908094882965088
Validation loss: 3.7859761176570768

Epoch: 6| Step: 4
Training loss: 3.405768632888794
Validation loss: 3.7712680421849734

Epoch: 6| Step: 5
Training loss: 4.542830944061279
Validation loss: 3.755441209321381

Epoch: 6| Step: 6
Training loss: 3.198364734649658
Validation loss: 3.7395046090566986

Epoch: 6| Step: 7
Training loss: 3.0118565559387207
Validation loss: 3.7254404329484507

Epoch: 6| Step: 8
Training loss: 4.130847454071045
Validation loss: 3.7113514510534142

Epoch: 6| Step: 9
Training loss: 4.793847560882568
Validation loss: 3.6963367513431016

Epoch: 6| Step: 10
Training loss: 3.512942314147949
Validation loss: 3.6796549622730543

Epoch: 6| Step: 11
Training loss: 3.2282896041870117
Validation loss: 3.6675987653834845

Epoch: 6| Step: 12
Training loss: 3.652271270751953
Validation loss: 3.6535496455366894

Epoch: 6| Step: 13
Training loss: 2.5918872356414795
Validation loss: 3.639335911761048

Epoch: 8| Step: 0
Training loss: 3.9657673835754395
Validation loss: 3.624159110489712

Epoch: 6| Step: 1
Training loss: 3.2438602447509766
Validation loss: 3.6110083364671275

Epoch: 6| Step: 2
Training loss: 4.640458106994629
Validation loss: 3.596046450317547

Epoch: 6| Step: 3
Training loss: 3.515866279602051
Validation loss: 3.5798006826831448

Epoch: 6| Step: 4
Training loss: 2.588582992553711
Validation loss: 3.570043638188352

Epoch: 6| Step: 5
Training loss: 3.279585838317871
Validation loss: 3.554217589798794

Epoch: 6| Step: 6
Training loss: 4.058222770690918
Validation loss: 3.5404692747259654

Epoch: 6| Step: 7
Training loss: 2.2660341262817383
Validation loss: 3.5270386434370473

Epoch: 6| Step: 8
Training loss: 2.77933669090271
Validation loss: 3.5137271958012737

Epoch: 6| Step: 9
Training loss: 3.9511325359344482
Validation loss: 3.4998462200164795

Epoch: 6| Step: 10
Training loss: 2.3921494483947754
Validation loss: 3.489173327722857

Epoch: 6| Step: 11
Training loss: 4.808675765991211
Validation loss: 3.4766889285015803

Epoch: 6| Step: 12
Training loss: 3.1679677963256836
Validation loss: 3.4641328165608067

Epoch: 6| Step: 13
Training loss: 4.008634090423584
Validation loss: 3.4543742543907574

Epoch: 9| Step: 0
Training loss: 2.877511501312256
Validation loss: 3.442264715830485

Epoch: 6| Step: 1
Training loss: 3.6755940914154053
Validation loss: 3.4297619506876957

Epoch: 6| Step: 2
Training loss: 4.007073402404785
Validation loss: 3.4215699882917505

Epoch: 6| Step: 3
Training loss: 4.240872383117676
Validation loss: 3.4108387449736237

Epoch: 6| Step: 4
Training loss: 2.199033498764038
Validation loss: 3.4042997462775118

Epoch: 6| Step: 5
Training loss: 3.5006449222564697
Validation loss: 3.392793047812677

Epoch: 6| Step: 6
Training loss: 3.747404098510742
Validation loss: 3.386697241055068

Epoch: 6| Step: 7
Training loss: 3.115962266921997
Validation loss: 3.37853072022879

Epoch: 6| Step: 8
Training loss: 3.2354540824890137
Validation loss: 3.371147612089752

Epoch: 6| Step: 9
Training loss: 3.6611907482147217
Validation loss: 3.3649035576851136

Epoch: 6| Step: 10
Training loss: 3.7705483436584473
Validation loss: 3.3588387735428347

Epoch: 6| Step: 11
Training loss: 2.7548563480377197
Validation loss: 3.3482878746524936

Epoch: 6| Step: 12
Training loss: 2.7023544311523438
Validation loss: 3.3419954161490164

Epoch: 6| Step: 13
Training loss: 3.1010098457336426
Validation loss: 3.3374876617103495

Epoch: 10| Step: 0
Training loss: 2.9511139392852783
Validation loss: 3.3318696329670567

Epoch: 6| Step: 1
Training loss: 4.370445728302002
Validation loss: 3.323911346415038

Epoch: 6| Step: 2
Training loss: 3.3636438846588135
Validation loss: 3.3188533013866794

Epoch: 6| Step: 3
Training loss: 2.443061351776123
Validation loss: 3.3141066797317995

Epoch: 6| Step: 4
Training loss: 3.50630521774292
Validation loss: 3.3097820487073673

Epoch: 6| Step: 5
Training loss: 2.912275791168213
Validation loss: 3.3060484086313555

Epoch: 6| Step: 6
Training loss: 3.324583053588867
Validation loss: 3.301844730172106

Epoch: 6| Step: 7
Training loss: 3.5609986782073975
Validation loss: 3.3017314480197046

Epoch: 6| Step: 8
Training loss: 3.3385379314422607
Validation loss: 3.295107933782762

Epoch: 6| Step: 9
Training loss: 3.392888069152832
Validation loss: 3.290915245650917

Epoch: 6| Step: 10
Training loss: 3.717562198638916
Validation loss: 3.2814332157052974

Epoch: 6| Step: 11
Training loss: 3.2217228412628174
Validation loss: 3.2733936643087738

Epoch: 6| Step: 12
Training loss: 3.0165584087371826
Validation loss: 3.268234783603299

Epoch: 6| Step: 13
Training loss: 2.131119728088379
Validation loss: 3.265953604893018

Epoch: 11| Step: 0
Training loss: 2.8340282440185547
Validation loss: 3.2605052814688733

Epoch: 6| Step: 1
Training loss: 4.253137588500977
Validation loss: 3.2574650728574364

Epoch: 6| Step: 2
Training loss: 3.270966053009033
Validation loss: 3.2540758553371636

Epoch: 6| Step: 3
Training loss: 2.68814754486084
Validation loss: 3.2516707681840464

Epoch: 6| Step: 4
Training loss: 2.8267054557800293
Validation loss: 3.2437254433990805

Epoch: 6| Step: 5
Training loss: 2.9093754291534424
Validation loss: 3.239969245849117

Epoch: 6| Step: 6
Training loss: 3.313560724258423
Validation loss: 3.2398103667843725

Epoch: 6| Step: 7
Training loss: 3.9633431434631348
Validation loss: 3.2369225922451226

Epoch: 6| Step: 8
Training loss: 2.680570363998413
Validation loss: 3.2385696057350404

Epoch: 6| Step: 9
Training loss: 3.2355098724365234
Validation loss: 3.227762637599822

Epoch: 6| Step: 10
Training loss: 3.222970485687256
Validation loss: 3.224733655170728

Epoch: 6| Step: 11
Training loss: 3.1193625926971436
Validation loss: 3.221717793454406

Epoch: 6| Step: 12
Training loss: 3.2541661262512207
Validation loss: 3.2171880737427743

Epoch: 6| Step: 13
Training loss: 3.6907129287719727
Validation loss: 3.211593104946998

Epoch: 12| Step: 0
Training loss: 3.2796990871429443
Validation loss: 3.208585023880005

Epoch: 6| Step: 1
Training loss: 3.0497729778289795
Validation loss: 3.201962124916815

Epoch: 6| Step: 2
Training loss: 4.210029602050781
Validation loss: 3.2017355862484185

Epoch: 6| Step: 3
Training loss: 3.1919567584991455
Validation loss: 3.196360654728387

Epoch: 6| Step: 4
Training loss: 3.890742063522339
Validation loss: 3.191793575081774

Epoch: 6| Step: 5
Training loss: 2.6075830459594727
Validation loss: 3.190019904926259

Epoch: 6| Step: 6
Training loss: 2.6422553062438965
Validation loss: 3.1960396946117444

Epoch: 6| Step: 7
Training loss: 3.371619701385498
Validation loss: 3.1979813319380566

Epoch: 6| Step: 8
Training loss: 3.536769151687622
Validation loss: 3.192957773003527

Epoch: 6| Step: 9
Training loss: 3.0103492736816406
Validation loss: 3.1815087051801783

Epoch: 6| Step: 10
Training loss: 3.06162166595459
Validation loss: 3.1741354337302585

Epoch: 6| Step: 11
Training loss: 3.0791049003601074
Validation loss: 3.1695020173185613

Epoch: 6| Step: 12
Training loss: 2.5152735710144043
Validation loss: 3.170271876037762

Epoch: 6| Step: 13
Training loss: 3.1547813415527344
Validation loss: 3.179751996071108

Epoch: 13| Step: 0
Training loss: 2.712106704711914
Validation loss: 3.1767171916141304

Epoch: 6| Step: 1
Training loss: 3.167874336242676
Validation loss: 3.1674324004880843

Epoch: 6| Step: 2
Training loss: 2.8165671825408936
Validation loss: 3.1598185390554447

Epoch: 6| Step: 3
Training loss: 2.3541147708892822
Validation loss: 3.1568575982124574

Epoch: 6| Step: 4
Training loss: 3.5533134937286377
Validation loss: 3.1532674861210648

Epoch: 6| Step: 5
Training loss: 3.555115222930908
Validation loss: 3.14831103304381

Epoch: 6| Step: 6
Training loss: 4.039729118347168
Validation loss: 3.1447472059598534

Epoch: 6| Step: 7
Training loss: 2.4433536529541016
Validation loss: 3.139034237912906

Epoch: 6| Step: 8
Training loss: 3.2191672325134277
Validation loss: 3.1383542553071053

Epoch: 6| Step: 9
Training loss: 3.5048184394836426
Validation loss: 3.1341107993997555

Epoch: 6| Step: 10
Training loss: 3.1604058742523193
Validation loss: 3.131517961461057

Epoch: 6| Step: 11
Training loss: 3.0393407344818115
Validation loss: 3.1257530002183813

Epoch: 6| Step: 12
Training loss: 2.925107955932617
Validation loss: 3.123787198015439

Epoch: 6| Step: 13
Training loss: 4.108050346374512
Validation loss: 3.1256255129332184

Epoch: 14| Step: 0
Training loss: 3.506737232208252
Validation loss: 3.1223806591444117

Epoch: 6| Step: 1
Training loss: 2.5418167114257812
Validation loss: 3.1208719797031854

Epoch: 6| Step: 2
Training loss: 3.7213244438171387
Validation loss: 3.117185413196523

Epoch: 6| Step: 3
Training loss: 3.3242135047912598
Validation loss: 3.1190339903677664

Epoch: 6| Step: 4
Training loss: 2.5048372745513916
Validation loss: 3.115528081053047

Epoch: 6| Step: 5
Training loss: 4.365214824676514
Validation loss: 3.111988795700894

Epoch: 6| Step: 6
Training loss: 1.8184564113616943
Validation loss: 3.107539282050184

Epoch: 6| Step: 7
Training loss: 3.0343661308288574
Validation loss: 3.1049508048642065

Epoch: 6| Step: 8
Training loss: 3.7896852493286133
Validation loss: 3.100039666698825

Epoch: 6| Step: 9
Training loss: 3.1507997512817383
Validation loss: 3.0980129062488513

Epoch: 6| Step: 10
Training loss: 3.440971851348877
Validation loss: 3.096996315063969

Epoch: 6| Step: 11
Training loss: 3.089989423751831
Validation loss: 3.0933088359012397

Epoch: 6| Step: 12
Training loss: 2.348306179046631
Validation loss: 3.0961647187509844

Epoch: 6| Step: 13
Training loss: 3.090153455734253
Validation loss: 3.0924776882253666

Epoch: 15| Step: 0
Training loss: 2.713181495666504
Validation loss: 3.0914772659219723

Epoch: 6| Step: 1
Training loss: 3.560671329498291
Validation loss: 3.087557279935447

Epoch: 6| Step: 2
Training loss: 3.7710776329040527
Validation loss: 3.0791322518420476

Epoch: 6| Step: 3
Training loss: 2.5480551719665527
Validation loss: 3.0794348588553806

Epoch: 6| Step: 4
Training loss: 3.251638889312744
Validation loss: 3.0774780088855374

Epoch: 6| Step: 5
Training loss: 3.4069385528564453
Validation loss: 3.074193198193786

Epoch: 6| Step: 6
Training loss: 2.428241729736328
Validation loss: 3.0791326210062993

Epoch: 6| Step: 7
Training loss: 3.2582926750183105
Validation loss: 3.071778658897646

Epoch: 6| Step: 8
Training loss: 2.9854156970977783
Validation loss: 3.0694662550444245

Epoch: 6| Step: 9
Training loss: 3.4601666927337646
Validation loss: 3.0637335367100214

Epoch: 6| Step: 10
Training loss: 3.956533908843994
Validation loss: 3.0660227293609292

Epoch: 6| Step: 11
Training loss: 2.536538600921631
Validation loss: 3.058046717797556

Epoch: 6| Step: 12
Training loss: 2.431790828704834
Validation loss: 3.052887124399985

Epoch: 6| Step: 13
Training loss: 3.106717109680176
Validation loss: 3.0548431232411373

Epoch: 16| Step: 0
Training loss: 4.284619331359863
Validation loss: 3.0488684433762745

Epoch: 6| Step: 1
Training loss: 3.2038300037384033
Validation loss: 3.0507777583214546

Epoch: 6| Step: 2
Training loss: 3.0314362049102783
Validation loss: 3.050379558276105

Epoch: 6| Step: 3
Training loss: 3.6987102031707764
Validation loss: 3.0503543294886106

Epoch: 6| Step: 4
Training loss: 3.3859293460845947
Validation loss: 3.04549245167804

Epoch: 6| Step: 5
Training loss: 3.0794057846069336
Validation loss: 3.0434654041003157

Epoch: 6| Step: 6
Training loss: 1.95325767993927
Validation loss: 3.040967454192459

Epoch: 6| Step: 7
Training loss: 3.0617971420288086
Validation loss: 3.040760132574266

Epoch: 6| Step: 8
Training loss: 3.0409045219421387
Validation loss: 3.0347052851030902

Epoch: 6| Step: 9
Training loss: 2.7786402702331543
Validation loss: 3.0314900721273115

Epoch: 6| Step: 10
Training loss: 3.071155071258545
Validation loss: 3.033354354161088

Epoch: 6| Step: 11
Training loss: 2.5384974479675293
Validation loss: 3.028050181686237

Epoch: 6| Step: 12
Training loss: 2.9191904067993164
Validation loss: 3.026696974231351

Epoch: 6| Step: 13
Training loss: 3.041958808898926
Validation loss: 3.027848615441271

Epoch: 17| Step: 0
Training loss: 3.8616833686828613
Validation loss: 3.0255173149929253

Epoch: 6| Step: 1
Training loss: 3.5748825073242188
Validation loss: 3.018966251803983

Epoch: 6| Step: 2
Training loss: 3.4571521282196045
Validation loss: 3.0199681020552114

Epoch: 6| Step: 3
Training loss: 3.3235960006713867
Validation loss: 3.0163840068283903

Epoch: 6| Step: 4
Training loss: 2.628810167312622
Validation loss: 3.0192922007653022

Epoch: 6| Step: 5
Training loss: 2.519958972930908
Validation loss: 3.019667604918121

Epoch: 6| Step: 6
Training loss: 3.903660774230957
Validation loss: 3.015598661156111

Epoch: 6| Step: 7
Training loss: 3.3890738487243652
Validation loss: 3.0156460961987896

Epoch: 6| Step: 8
Training loss: 2.504279851913452
Validation loss: 3.0211369094028266

Epoch: 6| Step: 9
Training loss: 2.402109146118164
Validation loss: 3.0170225661288024

Epoch: 6| Step: 10
Training loss: 2.4781148433685303
Validation loss: 3.020023004983061

Epoch: 6| Step: 11
Training loss: 2.9002346992492676
Validation loss: 3.019435913332047

Epoch: 6| Step: 12
Training loss: 3.0487265586853027
Validation loss: 3.0173085915145053

Epoch: 6| Step: 13
Training loss: 2.8607356548309326
Validation loss: 3.0017734394278577

Epoch: 18| Step: 0
Training loss: 2.64186954498291
Validation loss: 2.995640539353894

Epoch: 6| Step: 1
Training loss: 3.3133621215820312
Validation loss: 2.99391310445724

Epoch: 6| Step: 2
Training loss: 3.0053975582122803
Validation loss: 2.9897015992031304

Epoch: 6| Step: 3
Training loss: 4.262386322021484
Validation loss: 2.9875293418925297

Epoch: 6| Step: 4
Training loss: 4.126188278198242
Validation loss: 2.9808121394085627

Epoch: 6| Step: 5
Training loss: 2.079289436340332
Validation loss: 2.9783611759062736

Epoch: 6| Step: 6
Training loss: 2.7288036346435547
Validation loss: 2.9767434776470227

Epoch: 6| Step: 7
Training loss: 2.806443214416504
Validation loss: 2.977682646884713

Epoch: 6| Step: 8
Training loss: 2.926870346069336
Validation loss: 2.9752794158074165

Epoch: 6| Step: 9
Training loss: 2.5133986473083496
Validation loss: 2.973256670018678

Epoch: 6| Step: 10
Training loss: 3.907010078430176
Validation loss: 2.9793722655183528

Epoch: 6| Step: 11
Training loss: 3.08182430267334
Validation loss: 2.9754968074060257

Epoch: 6| Step: 12
Training loss: 2.1352198123931885
Validation loss: 2.979196392079835

Epoch: 6| Step: 13
Training loss: 3.135793447494507
Validation loss: 2.9679101128732004

Epoch: 19| Step: 0
Training loss: 2.5522990226745605
Validation loss: 2.9709783215676584

Epoch: 6| Step: 1
Training loss: 3.654297351837158
Validation loss: 2.96204771021361

Epoch: 6| Step: 2
Training loss: 2.1726951599121094
Validation loss: 2.9612387816111245

Epoch: 6| Step: 3
Training loss: 2.2471303939819336
Validation loss: 2.958091066729638

Epoch: 6| Step: 4
Training loss: 4.301697731018066
Validation loss: 2.956654699899817

Epoch: 6| Step: 5
Training loss: 2.619194507598877
Validation loss: 2.9538487542060112

Epoch: 6| Step: 6
Training loss: 2.573169231414795
Validation loss: 2.949458158144387

Epoch: 6| Step: 7
Training loss: 2.806746006011963
Validation loss: 2.9551776480931107

Epoch: 6| Step: 8
Training loss: 3.24196195602417
Validation loss: 2.968373957500663

Epoch: 6| Step: 9
Training loss: 3.764922618865967
Validation loss: 2.9540297779985654

Epoch: 6| Step: 10
Training loss: 2.0775718688964844
Validation loss: 2.9436830243756695

Epoch: 6| Step: 11
Training loss: 3.093545436859131
Validation loss: 2.950075213627149

Epoch: 6| Step: 12
Training loss: 3.522212028503418
Validation loss: 2.965094648381715

Epoch: 6| Step: 13
Training loss: 4.314757823944092
Validation loss: 2.9692845908544396

Epoch: 20| Step: 0
Training loss: 2.7911624908447266
Validation loss: 2.9695855340650006

Epoch: 6| Step: 1
Training loss: 3.045799970626831
Validation loss: 2.98160155101489

Epoch: 6| Step: 2
Training loss: 3.30991530418396
Validation loss: 2.9689881955423663

Epoch: 6| Step: 3
Training loss: 2.7947075366973877
Validation loss: 2.9529239490468013

Epoch: 6| Step: 4
Training loss: 1.8897993564605713
Validation loss: 2.937020440255442

Epoch: 6| Step: 5
Training loss: 2.5786330699920654
Validation loss: 2.938403291086997

Epoch: 6| Step: 6
Training loss: 3.4727067947387695
Validation loss: 2.936680893744192

Epoch: 6| Step: 7
Training loss: 3.614915370941162
Validation loss: 2.9281856500974266

Epoch: 6| Step: 8
Training loss: 2.512033224105835
Validation loss: 2.931215158072851

Epoch: 6| Step: 9
Training loss: 4.29918098449707
Validation loss: 2.930270174498199

Epoch: 6| Step: 10
Training loss: 3.8086256980895996
Validation loss: 2.9254208790358676

Epoch: 6| Step: 11
Training loss: 2.120112180709839
Validation loss: 2.9206897904795985

Epoch: 6| Step: 12
Training loss: 2.556339740753174
Validation loss: 2.917047659556071

Epoch: 6| Step: 13
Training loss: 3.642483949661255
Validation loss: 2.9135545633172475

Epoch: 21| Step: 0
Training loss: 2.8616394996643066
Validation loss: 2.912805631596555

Epoch: 6| Step: 1
Training loss: 2.9944405555725098
Validation loss: 2.9126620215754353

Epoch: 6| Step: 2
Training loss: 3.227370023727417
Validation loss: 2.9198412664474978

Epoch: 6| Step: 3
Training loss: 2.4274120330810547
Validation loss: 2.936691596943845

Epoch: 6| Step: 4
Training loss: 3.140493392944336
Validation loss: 2.9281822122553343

Epoch: 6| Step: 5
Training loss: 2.845872402191162
Validation loss: 2.91275191819796

Epoch: 6| Step: 6
Training loss: 2.446251153945923
Validation loss: 2.908231977493532

Epoch: 6| Step: 7
Training loss: 3.0584139823913574
Validation loss: 2.9102273833367134

Epoch: 6| Step: 8
Training loss: 3.3640060424804688
Validation loss: 2.9061295217083347

Epoch: 6| Step: 9
Training loss: 3.4939351081848145
Validation loss: 2.9078222244016585

Epoch: 6| Step: 10
Training loss: 2.7764925956726074
Validation loss: 2.8995417548764135

Epoch: 6| Step: 11
Training loss: 2.765106678009033
Validation loss: 2.8966221681205173

Epoch: 6| Step: 12
Training loss: 3.116426944732666
Validation loss: 2.8912852707729546

Epoch: 6| Step: 13
Training loss: 3.6022884845733643
Validation loss: 2.8876448651795745

Epoch: 22| Step: 0
Training loss: 2.9178552627563477
Validation loss: 2.8821119826327086

Epoch: 6| Step: 1
Training loss: 2.9995105266571045
Validation loss: 2.8867682051914993

Epoch: 6| Step: 2
Training loss: 2.820207118988037
Validation loss: 2.8854547956938386

Epoch: 6| Step: 3
Training loss: 2.1447901725769043
Validation loss: 2.8768882315645934

Epoch: 6| Step: 4
Training loss: 3.7429139614105225
Validation loss: 2.876940211942119

Epoch: 6| Step: 5
Training loss: 2.9748430252075195
Validation loss: 2.8798219003985004

Epoch: 6| Step: 6
Training loss: 3.2796573638916016
Validation loss: 2.8772800455811205

Epoch: 6| Step: 7
Training loss: 3.845036506652832
Validation loss: 2.8785813008585284

Epoch: 6| Step: 8
Training loss: 3.577500343322754
Validation loss: 2.884711532182591

Epoch: 6| Step: 9
Training loss: 1.4980216026306152
Validation loss: 2.8774404500120427

Epoch: 6| Step: 10
Training loss: 2.876986503601074
Validation loss: 2.8749035199483237

Epoch: 6| Step: 11
Training loss: 2.8987350463867188
Validation loss: 2.884531536409932

Epoch: 6| Step: 12
Training loss: 2.992126941680908
Validation loss: 2.881418397349696

Epoch: 6| Step: 13
Training loss: 2.839961051940918
Validation loss: 2.872262539402131

Epoch: 23| Step: 0
Training loss: 2.338860511779785
Validation loss: 2.868122341812298

Epoch: 6| Step: 1
Training loss: 3.0767948627471924
Validation loss: 2.859883205865019

Epoch: 6| Step: 2
Training loss: 2.2360894680023193
Validation loss: 2.8620876573747203

Epoch: 6| Step: 3
Training loss: 3.335456609725952
Validation loss: 2.8644454351035495

Epoch: 6| Step: 4
Training loss: 2.448056936264038
Validation loss: 2.860946229709092

Epoch: 6| Step: 5
Training loss: 3.277174234390259
Validation loss: 2.8619327340074765

Epoch: 6| Step: 6
Training loss: 2.7451369762420654
Validation loss: 2.8761652156870854

Epoch: 6| Step: 7
Training loss: 2.8267273902893066
Validation loss: 2.867340031490531

Epoch: 6| Step: 8
Training loss: 3.5626587867736816
Validation loss: 2.8613654413530902

Epoch: 6| Step: 9
Training loss: 3.29048490524292
Validation loss: 2.8428973100518666

Epoch: 6| Step: 10
Training loss: 2.4671812057495117
Validation loss: 2.8437340080097155

Epoch: 6| Step: 11
Training loss: 2.9235072135925293
Validation loss: 2.8444937352211244

Epoch: 6| Step: 12
Training loss: 3.4998908042907715
Validation loss: 2.8493427384284233

Epoch: 6| Step: 13
Training loss: 3.7621753215789795
Validation loss: 2.8600548236600813

Epoch: 24| Step: 0
Training loss: 2.869704246520996
Validation loss: 2.869903395252843

Epoch: 6| Step: 1
Training loss: 2.789369583129883
Validation loss: 2.871044679354596

Epoch: 6| Step: 2
Training loss: 1.7657305002212524
Validation loss: 2.8631306643127115

Epoch: 6| Step: 3
Training loss: 4.005068302154541
Validation loss: 2.867067167835851

Epoch: 6| Step: 4
Training loss: 3.26997971534729
Validation loss: 2.869119615964992

Epoch: 6| Step: 5
Training loss: 3.483480215072632
Validation loss: 2.851789725724087

Epoch: 6| Step: 6
Training loss: 2.877108573913574
Validation loss: 2.8443598849799043

Epoch: 6| Step: 7
Training loss: 2.3999109268188477
Validation loss: 2.837986397486861

Epoch: 6| Step: 8
Training loss: 3.4652903079986572
Validation loss: 2.827949780289845

Epoch: 6| Step: 9
Training loss: 2.204413414001465
Validation loss: 2.82432823283698

Epoch: 6| Step: 10
Training loss: 3.049834966659546
Validation loss: 2.8212153783408542

Epoch: 6| Step: 11
Training loss: 3.801255226135254
Validation loss: 2.825792545913368

Epoch: 6| Step: 12
Training loss: 2.1697044372558594
Validation loss: 2.8210807179891937

Epoch: 6| Step: 13
Training loss: 3.2337701320648193
Validation loss: 2.818486503375474

Epoch: 25| Step: 0
Training loss: 2.875922203063965
Validation loss: 2.8218955275832966

Epoch: 6| Step: 1
Training loss: 3.2953391075134277
Validation loss: 2.8217550349491898

Epoch: 6| Step: 2
Training loss: 2.684183120727539
Validation loss: 2.820899783924062

Epoch: 6| Step: 3
Training loss: 3.5170822143554688
Validation loss: 2.817192828783425

Epoch: 6| Step: 4
Training loss: 2.9991331100463867
Validation loss: 2.816874106725057

Epoch: 6| Step: 5
Training loss: 3.0521161556243896
Validation loss: 2.816803209243282

Epoch: 6| Step: 6
Training loss: 2.766477108001709
Validation loss: 2.8194898354109896

Epoch: 6| Step: 7
Training loss: 2.5172955989837646
Validation loss: 2.8136976841957337

Epoch: 6| Step: 8
Training loss: 2.5681207180023193
Validation loss: 2.8086158024367465

Epoch: 6| Step: 9
Training loss: 2.411655902862549
Validation loss: 2.803707948295019

Epoch: 6| Step: 10
Training loss: 3.165811538696289
Validation loss: 2.808766959815897

Epoch: 6| Step: 11
Training loss: 3.4263930320739746
Validation loss: 2.797391863279445

Epoch: 6| Step: 12
Training loss: 2.600595474243164
Validation loss: 2.7948328525789323

Epoch: 6| Step: 13
Training loss: 3.1021158695220947
Validation loss: 2.7980491371564966

Epoch: 26| Step: 0
Training loss: 2.894129753112793
Validation loss: 2.80512894609923

Epoch: 6| Step: 1
Training loss: 2.721839427947998
Validation loss: 2.8108630411086546

Epoch: 6| Step: 2
Training loss: 3.234797477722168
Validation loss: 2.798649049574329

Epoch: 6| Step: 3
Training loss: 2.6473135948181152
Validation loss: 2.7962675991878716

Epoch: 6| Step: 4
Training loss: 2.697967529296875
Validation loss: 2.7958278374005388

Epoch: 6| Step: 5
Training loss: 2.045438051223755
Validation loss: 2.7942445919077885

Epoch: 6| Step: 6
Training loss: 3.057652711868286
Validation loss: 2.797290676383562

Epoch: 6| Step: 7
Training loss: 3.8714656829833984
Validation loss: 2.7875579095655874

Epoch: 6| Step: 8
Training loss: 3.7101824283599854
Validation loss: 2.785828951866396

Epoch: 6| Step: 9
Training loss: 2.706526756286621
Validation loss: 2.7889053693381687

Epoch: 6| Step: 10
Training loss: 3.0369105339050293
Validation loss: 2.7897434567892425

Epoch: 6| Step: 11
Training loss: 2.5862345695495605
Validation loss: 2.7839231491088867

Epoch: 6| Step: 12
Training loss: 2.9943480491638184
Validation loss: 2.7865054530482136

Epoch: 6| Step: 13
Training loss: 2.2644097805023193
Validation loss: 2.7802551433604252

Epoch: 27| Step: 0
Training loss: 3.180922508239746
Validation loss: 2.78291210820598

Epoch: 6| Step: 1
Training loss: 2.882401943206787
Validation loss: 2.777843472778156

Epoch: 6| Step: 2
Training loss: 3.0908217430114746
Validation loss: 2.7808199159560667

Epoch: 6| Step: 3
Training loss: 2.7188210487365723
Validation loss: 2.795752256147323

Epoch: 6| Step: 4
Training loss: 2.1665143966674805
Validation loss: 2.783472189339258

Epoch: 6| Step: 5
Training loss: 3.0978543758392334
Validation loss: 2.774320133270756

Epoch: 6| Step: 6
Training loss: 2.5953211784362793
Validation loss: 2.768155819626265

Epoch: 6| Step: 7
Training loss: 2.837233066558838
Validation loss: 2.7725949466869397

Epoch: 6| Step: 8
Training loss: 3.3446145057678223
Validation loss: 2.7730735860845095

Epoch: 6| Step: 9
Training loss: 2.850554943084717
Validation loss: 2.7721606787814888

Epoch: 6| Step: 10
Training loss: 2.4339237213134766
Validation loss: 2.7836908627581853

Epoch: 6| Step: 11
Training loss: 2.955002784729004
Validation loss: 2.791630780825051

Epoch: 6| Step: 12
Training loss: 2.780912399291992
Validation loss: 2.790628807519072

Epoch: 6| Step: 13
Training loss: 4.260899066925049
Validation loss: 2.78711639424806

Epoch: 28| Step: 0
Training loss: 3.272618293762207
Validation loss: 2.7793042121394986

Epoch: 6| Step: 1
Training loss: 2.3211827278137207
Validation loss: 2.769919777429232

Epoch: 6| Step: 2
Training loss: 2.6607775688171387
Validation loss: 2.767379909433344

Epoch: 6| Step: 3
Training loss: 3.431118965148926
Validation loss: 2.7722983078290055

Epoch: 6| Step: 4
Training loss: 3.2324891090393066
Validation loss: 2.779123149892335

Epoch: 6| Step: 5
Training loss: 2.726595401763916
Validation loss: 2.784082379392398

Epoch: 6| Step: 6
Training loss: 2.8130524158477783
Validation loss: 2.7997309905226513

Epoch: 6| Step: 7
Training loss: 2.7054288387298584
Validation loss: 2.8239077752636326

Epoch: 6| Step: 8
Training loss: 3.197420597076416
Validation loss: 2.854219264881585

Epoch: 6| Step: 9
Training loss: 2.960890769958496
Validation loss: 2.8364251941762944

Epoch: 6| Step: 10
Training loss: 2.1736435890197754
Validation loss: 2.806490336695025

Epoch: 6| Step: 11
Training loss: 3.8006956577301025
Validation loss: 2.7697690379235054

Epoch: 6| Step: 12
Training loss: 2.7603228092193604
Validation loss: 2.756665124688097

Epoch: 6| Step: 13
Training loss: 2.4785587787628174
Validation loss: 2.7557466953031478

Epoch: 29| Step: 0
Training loss: 2.194758653640747
Validation loss: 2.7637267958733345

Epoch: 6| Step: 1
Training loss: 3.4564735889434814
Validation loss: 2.7669587391679005

Epoch: 6| Step: 2
Training loss: 3.2329468727111816
Validation loss: 2.777096717588363

Epoch: 6| Step: 3
Training loss: 4.134284496307373
Validation loss: 2.790101910150179

Epoch: 6| Step: 4
Training loss: 3.8480663299560547
Validation loss: 2.7784290775176017

Epoch: 6| Step: 5
Training loss: 2.913085460662842
Validation loss: 2.765588355320756

Epoch: 6| Step: 6
Training loss: 3.359916925430298
Validation loss: 2.757959001807756

Epoch: 6| Step: 7
Training loss: 1.8379627466201782
Validation loss: 2.755200611647739

Epoch: 6| Step: 8
Training loss: 2.5702555179595947
Validation loss: 2.7484445366808163

Epoch: 6| Step: 9
Training loss: 2.555149555206299
Validation loss: 2.747635446568971

Epoch: 6| Step: 10
Training loss: 2.131995677947998
Validation loss: 2.7468897706718853

Epoch: 6| Step: 11
Training loss: 3.198864698410034
Validation loss: 2.756313544447704

Epoch: 6| Step: 12
Training loss: 2.5772695541381836
Validation loss: 2.7545720915640555

Epoch: 6| Step: 13
Training loss: 2.3817155361175537
Validation loss: 2.7553160575128373

Epoch: 30| Step: 0
Training loss: 2.4066648483276367
Validation loss: 2.7643876024471816

Epoch: 6| Step: 1
Training loss: 2.0247721672058105
Validation loss: 2.757100820541382

Epoch: 6| Step: 2
Training loss: 2.601433277130127
Validation loss: 2.7625624133694555

Epoch: 6| Step: 3
Training loss: 3.067613124847412
Validation loss: 2.769613899210448

Epoch: 6| Step: 4
Training loss: 2.8757519721984863
Validation loss: 2.775871989547565

Epoch: 6| Step: 5
Training loss: 3.1968026161193848
Validation loss: 2.7757548619342107

Epoch: 6| Step: 6
Training loss: 2.752110242843628
Validation loss: 2.781615908427905

Epoch: 6| Step: 7
Training loss: 2.9225149154663086
Validation loss: 2.7732152631205897

Epoch: 6| Step: 8
Training loss: 2.9469051361083984
Validation loss: 2.7592925051207184

Epoch: 6| Step: 9
Training loss: 2.507054090499878
Validation loss: 2.7507143071902695

Epoch: 6| Step: 10
Training loss: 3.3224587440490723
Validation loss: 2.746685207531016

Epoch: 6| Step: 11
Training loss: 2.862557888031006
Validation loss: 2.7388049838363484

Epoch: 6| Step: 12
Training loss: 3.7715485095977783
Validation loss: 2.7391348833678872

Epoch: 6| Step: 13
Training loss: 3.284818649291992
Validation loss: 2.7327754676982923

Epoch: 31| Step: 0
Training loss: 3.1893277168273926
Validation loss: 2.7271646812397945

Epoch: 6| Step: 1
Training loss: 2.8123979568481445
Validation loss: 2.7317949418098695

Epoch: 6| Step: 2
Training loss: 3.0174200534820557
Validation loss: 2.727421634940691

Epoch: 6| Step: 3
Training loss: 2.493856191635132
Validation loss: 2.7202217912161224

Epoch: 6| Step: 4
Training loss: 2.970693826675415
Validation loss: 2.718547890263219

Epoch: 6| Step: 5
Training loss: 2.3664462566375732
Validation loss: 2.714642547792004

Epoch: 6| Step: 6
Training loss: 2.4431655406951904
Validation loss: 2.715368168328398

Epoch: 6| Step: 7
Training loss: 3.429804801940918
Validation loss: 2.7141485342415432

Epoch: 6| Step: 8
Training loss: 2.684490203857422
Validation loss: 2.7156781868268083

Epoch: 6| Step: 9
Training loss: 3.784982204437256
Validation loss: 2.7124126777854016

Epoch: 6| Step: 10
Training loss: 3.4670119285583496
Validation loss: 2.7126420005675285

Epoch: 6| Step: 11
Training loss: 2.570148229598999
Validation loss: 2.715440744994789

Epoch: 6| Step: 12
Training loss: 2.074838399887085
Validation loss: 2.717906791676757

Epoch: 6| Step: 13
Training loss: 2.70131778717041
Validation loss: 2.7166538366707425

Epoch: 32| Step: 0
Training loss: 3.318793296813965
Validation loss: 2.7125007721685592

Epoch: 6| Step: 1
Training loss: 2.3712635040283203
Validation loss: 2.716188371822398

Epoch: 6| Step: 2
Training loss: 2.881063461303711
Validation loss: 2.7192470155736452

Epoch: 6| Step: 3
Training loss: 2.5581483840942383
Validation loss: 2.7206329402103218

Epoch: 6| Step: 4
Training loss: 3.1567349433898926
Validation loss: 2.7226808224954913

Epoch: 6| Step: 5
Training loss: 2.6970229148864746
Validation loss: 2.7232523067023164

Epoch: 6| Step: 6
Training loss: 3.142845630645752
Validation loss: 2.724237388180148

Epoch: 6| Step: 7
Training loss: 2.8675527572631836
Validation loss: 2.7180302912189114

Epoch: 6| Step: 8
Training loss: 2.5808897018432617
Validation loss: 2.709099418373518

Epoch: 6| Step: 9
Training loss: 2.750919818878174
Validation loss: 2.703379938679357

Epoch: 6| Step: 10
Training loss: 2.5947818756103516
Validation loss: 2.7007411782459547

Epoch: 6| Step: 11
Training loss: 2.675915241241455
Validation loss: 2.6975894512668734

Epoch: 6| Step: 12
Training loss: 4.055434703826904
Validation loss: 2.700404836285499

Epoch: 6| Step: 13
Training loss: 1.985888957977295
Validation loss: 2.70022782715418

Epoch: 33| Step: 0
Training loss: 2.3264241218566895
Validation loss: 2.7025069088064213

Epoch: 6| Step: 1
Training loss: 3.3237271308898926
Validation loss: 2.6979943219051568

Epoch: 6| Step: 2
Training loss: 2.9132251739501953
Validation loss: 2.6966595880446897

Epoch: 6| Step: 3
Training loss: 2.1909046173095703
Validation loss: 2.6962785285006285

Epoch: 6| Step: 4
Training loss: 2.825035810470581
Validation loss: 2.6917495983903126

Epoch: 6| Step: 5
Training loss: 2.593773126602173
Validation loss: 2.689590031100858

Epoch: 6| Step: 6
Training loss: 2.4993996620178223
Validation loss: 2.694979267735635

Epoch: 6| Step: 7
Training loss: 2.5536136627197266
Validation loss: 2.6839215781099055

Epoch: 6| Step: 8
Training loss: 3.5945398807525635
Validation loss: 2.6877547874245593

Epoch: 6| Step: 9
Training loss: 2.894421100616455
Validation loss: 2.6870779632240214

Epoch: 6| Step: 10
Training loss: 2.9668116569519043
Validation loss: 2.6907424978030625

Epoch: 6| Step: 11
Training loss: 3.82572078704834
Validation loss: 2.6838716845358572

Epoch: 6| Step: 12
Training loss: 2.4441161155700684
Validation loss: 2.678274928882558

Epoch: 6| Step: 13
Training loss: 2.940723180770874
Validation loss: 2.6852160615305745

Epoch: 34| Step: 0
Training loss: 2.8399951457977295
Validation loss: 2.681193364563809

Epoch: 6| Step: 1
Training loss: 2.925086259841919
Validation loss: 2.6799342093929166

Epoch: 6| Step: 2
Training loss: 1.8497687578201294
Validation loss: 2.6828381887046238

Epoch: 6| Step: 3
Training loss: 3.132591724395752
Validation loss: 2.6825246836549494

Epoch: 6| Step: 4
Training loss: 3.3310952186584473
Validation loss: 2.679178022569226

Epoch: 6| Step: 5
Training loss: 1.8760359287261963
Validation loss: 2.681737385770326

Epoch: 6| Step: 6
Training loss: 3.0813775062561035
Validation loss: 2.677968789172429

Epoch: 6| Step: 7
Training loss: 2.841754674911499
Validation loss: 2.674824606987738

Epoch: 6| Step: 8
Training loss: 3.340379238128662
Validation loss: 2.675253665575417

Epoch: 6| Step: 9
Training loss: 3.039177894592285
Validation loss: 2.670282056254725

Epoch: 6| Step: 10
Training loss: 3.3640050888061523
Validation loss: 2.673028810049898

Epoch: 6| Step: 11
Training loss: 2.5995941162109375
Validation loss: 2.6737055881049043

Epoch: 6| Step: 12
Training loss: 2.33935809135437
Validation loss: 2.678327780897899

Epoch: 6| Step: 13
Training loss: 3.378896474838257
Validation loss: 2.6767263181747927

Epoch: 35| Step: 0
Training loss: 3.5607492923736572
Validation loss: 2.682317356909475

Epoch: 6| Step: 1
Training loss: 4.246976375579834
Validation loss: 2.6790075430306057

Epoch: 6| Step: 2
Training loss: 2.234166145324707
Validation loss: 2.672935808858564

Epoch: 6| Step: 3
Training loss: 2.3210854530334473
Validation loss: 2.682902741175826

Epoch: 6| Step: 4
Training loss: 3.8458220958709717
Validation loss: 2.6826124780921528

Epoch: 6| Step: 5
Training loss: 2.584862232208252
Validation loss: 2.6875179377935265

Epoch: 6| Step: 6
Training loss: 3.145947217941284
Validation loss: 2.6795009387436735

Epoch: 6| Step: 7
Training loss: 2.7052929401397705
Validation loss: 2.6728222216329267

Epoch: 6| Step: 8
Training loss: 2.7004482746124268
Validation loss: 2.666248357424172

Epoch: 6| Step: 9
Training loss: 2.493131160736084
Validation loss: 2.6644842060663367

Epoch: 6| Step: 10
Training loss: 2.746966600418091
Validation loss: 2.6585476757377706

Epoch: 6| Step: 11
Training loss: 2.405836582183838
Validation loss: 2.6643208739578084

Epoch: 6| Step: 12
Training loss: 1.5965473651885986
Validation loss: 2.665133553166543

Epoch: 6| Step: 13
Training loss: 3.111412763595581
Validation loss: 2.667642826675087

Epoch: 36| Step: 0
Training loss: 2.5585036277770996
Validation loss: 2.6617270567083873

Epoch: 6| Step: 1
Training loss: 3.117788791656494
Validation loss: 2.664310562995172

Epoch: 6| Step: 2
Training loss: 3.526360034942627
Validation loss: 2.6589202957768596

Epoch: 6| Step: 3
Training loss: 2.579005241394043
Validation loss: 2.650833217046594

Epoch: 6| Step: 4
Training loss: 2.4896316528320312
Validation loss: 2.65269301783654

Epoch: 6| Step: 5
Training loss: 2.576859712600708
Validation loss: 2.6616857051849365

Epoch: 6| Step: 6
Training loss: 2.9110569953918457
Validation loss: 2.6634787385181715

Epoch: 6| Step: 7
Training loss: 2.9318013191223145
Validation loss: 2.6647874437352663

Epoch: 6| Step: 8
Training loss: 3.824147939682007
Validation loss: 2.6561910055016957

Epoch: 6| Step: 9
Training loss: 2.0532472133636475
Validation loss: 2.652755039994435

Epoch: 6| Step: 10
Training loss: 2.748108386993408
Validation loss: 2.6531585493395404

Epoch: 6| Step: 11
Training loss: 3.3115508556365967
Validation loss: 2.653096524618005

Epoch: 6| Step: 12
Training loss: 2.0978646278381348
Validation loss: 2.6476801005742883

Epoch: 6| Step: 13
Training loss: 2.739481210708618
Validation loss: 2.652294158935547

Epoch: 37| Step: 0
Training loss: 2.9104180335998535
Validation loss: 2.655967638056765

Epoch: 6| Step: 1
Training loss: 3.1837563514709473
Validation loss: 2.653326255018993

Epoch: 6| Step: 2
Training loss: 1.413528323173523
Validation loss: 2.6467175893886115

Epoch: 6| Step: 3
Training loss: 2.930767774581909
Validation loss: 2.659922981774935

Epoch: 6| Step: 4
Training loss: 2.951777935028076
Validation loss: 2.6573276058320077

Epoch: 6| Step: 5
Training loss: 2.380286693572998
Validation loss: 2.6505567002040085

Epoch: 6| Step: 6
Training loss: 2.9684371948242188
Validation loss: 2.654609180265857

Epoch: 6| Step: 7
Training loss: 2.615894317626953
Validation loss: 2.6469585844265517

Epoch: 6| Step: 8
Training loss: 2.6716229915618896
Validation loss: 2.6469464045698925

Epoch: 6| Step: 9
Training loss: 3.6877920627593994
Validation loss: 2.6412918670203096

Epoch: 6| Step: 10
Training loss: 2.2794976234436035
Validation loss: 2.6418998395243

Epoch: 6| Step: 11
Training loss: 3.659175395965576
Validation loss: 2.643006242731566

Epoch: 6| Step: 12
Training loss: 3.0391249656677246
Validation loss: 2.6409102050206994

Epoch: 6| Step: 13
Training loss: 2.5706048011779785
Validation loss: 2.6392849337670112

Epoch: 38| Step: 0
Training loss: 2.5547497272491455
Validation loss: 2.636564075305898

Epoch: 6| Step: 1
Training loss: 3.162649631500244
Validation loss: 2.6367084698010514

Epoch: 6| Step: 2
Training loss: 2.457078218460083
Validation loss: 2.637581411228385

Epoch: 6| Step: 3
Training loss: 3.0027153491973877
Validation loss: 2.6337549737704697

Epoch: 6| Step: 4
Training loss: 3.4888360500335693
Validation loss: 2.6344383403819096

Epoch: 6| Step: 5
Training loss: 1.958501935005188
Validation loss: 2.631463860952726

Epoch: 6| Step: 6
Training loss: 2.715853691101074
Validation loss: 2.6426181203575543

Epoch: 6| Step: 7
Training loss: 2.879380464553833
Validation loss: 2.6528839321546656

Epoch: 6| Step: 8
Training loss: 3.1747868061065674
Validation loss: 2.662440558915497

Epoch: 6| Step: 9
Training loss: 2.0194995403289795
Validation loss: 2.6450704066984114

Epoch: 6| Step: 10
Training loss: 3.2073299884796143
Validation loss: 2.6320784297040714

Epoch: 6| Step: 11
Training loss: 3.533843994140625
Validation loss: 2.636414797075333

Epoch: 6| Step: 12
Training loss: 2.819918632507324
Validation loss: 2.626823253529046

Epoch: 6| Step: 13
Training loss: 1.9111382961273193
Validation loss: 2.630957608581871

Epoch: 39| Step: 0
Training loss: 3.238872528076172
Validation loss: 2.6256477499520905

Epoch: 6| Step: 1
Training loss: 2.4678807258605957
Validation loss: 2.631372533818727

Epoch: 6| Step: 2
Training loss: 3.4930944442749023
Validation loss: 2.633886227043726

Epoch: 6| Step: 3
Training loss: 2.7906510829925537
Validation loss: 2.637199080118569

Epoch: 6| Step: 4
Training loss: 2.8085873126983643
Validation loss: 2.6358884226891304

Epoch: 6| Step: 5
Training loss: 2.4229533672332764
Validation loss: 2.634465261172223

Epoch: 6| Step: 6
Training loss: 2.2026853561401367
Validation loss: 2.6330256795370452

Epoch: 6| Step: 7
Training loss: 2.316288471221924
Validation loss: 2.6211073629317747

Epoch: 6| Step: 8
Training loss: 2.5710721015930176
Validation loss: 2.623848956118348

Epoch: 6| Step: 9
Training loss: 3.2190630435943604
Validation loss: 2.6263146887543383

Epoch: 6| Step: 10
Training loss: 2.8818840980529785
Validation loss: 2.623000334667903

Epoch: 6| Step: 11
Training loss: 2.5998916625976562
Validation loss: 2.6312920739573817

Epoch: 6| Step: 12
Training loss: 2.604339838027954
Validation loss: 2.6296581299074235

Epoch: 6| Step: 13
Training loss: 4.077703475952148
Validation loss: 2.6305556733121156

Epoch: 40| Step: 0
Training loss: 2.76222562789917
Validation loss: 2.6341027213681127

Epoch: 6| Step: 1
Training loss: 3.1206514835357666
Validation loss: 2.6382605773146435

Epoch: 6| Step: 2
Training loss: 3.0516982078552246
Validation loss: 2.654969822975897

Epoch: 6| Step: 3
Training loss: 2.5240063667297363
Validation loss: 2.650936480491392

Epoch: 6| Step: 4
Training loss: 2.68477463722229
Validation loss: 2.6276619947084816

Epoch: 6| Step: 5
Training loss: 3.542571544647217
Validation loss: 2.6271639536785822

Epoch: 6| Step: 6
Training loss: 2.8714077472686768
Validation loss: 2.621749395965248

Epoch: 6| Step: 7
Training loss: 3.0549304485321045
Validation loss: 2.6218050269670385

Epoch: 6| Step: 8
Training loss: 2.553999423980713
Validation loss: 2.6131942169640654

Epoch: 6| Step: 9
Training loss: 1.9847872257232666
Validation loss: 2.6231558297270086

Epoch: 6| Step: 10
Training loss: 2.348445415496826
Validation loss: 2.620955915861232

Epoch: 6| Step: 11
Training loss: 2.949460029602051
Validation loss: 2.6232996781667075

Epoch: 6| Step: 12
Training loss: 2.5369150638580322
Validation loss: 2.6207154104786534

Epoch: 6| Step: 13
Training loss: 3.518571376800537
Validation loss: 2.6235244915049565

Epoch: 41| Step: 0
Training loss: 1.942209243774414
Validation loss: 2.6212830338426816

Epoch: 6| Step: 1
Training loss: 3.1914193630218506
Validation loss: 2.615350359229631

Epoch: 6| Step: 2
Training loss: 2.1430907249450684
Validation loss: 2.6172310536907566

Epoch: 6| Step: 3
Training loss: 2.7578866481781006
Validation loss: 2.6127663376510784

Epoch: 6| Step: 4
Training loss: 3.3652100563049316
Validation loss: 2.6074554740741687

Epoch: 6| Step: 5
Training loss: 2.8839058876037598
Validation loss: 2.6033488063402075

Epoch: 6| Step: 6
Training loss: 2.534578800201416
Validation loss: 2.6074240335854153

Epoch: 6| Step: 7
Training loss: 2.8595337867736816
Validation loss: 2.6124348230259393

Epoch: 6| Step: 8
Training loss: 3.0840682983398438
Validation loss: 2.6019512709750923

Epoch: 6| Step: 9
Training loss: 3.446937322616577
Validation loss: 2.6001120510921685

Epoch: 6| Step: 10
Training loss: 2.555614948272705
Validation loss: 2.598197703720421

Epoch: 6| Step: 11
Training loss: 3.317781925201416
Validation loss: 2.5955962288764214

Epoch: 6| Step: 12
Training loss: 1.8770805597305298
Validation loss: 2.595198820996028

Epoch: 6| Step: 13
Training loss: 3.1179487705230713
Validation loss: 2.5935965545715822

Epoch: 42| Step: 0
Training loss: 3.0078258514404297
Validation loss: 2.5886695897707375

Epoch: 6| Step: 1
Training loss: 2.58349347114563
Validation loss: 2.5953009077297744

Epoch: 6| Step: 2
Training loss: 3.1523385047912598
Validation loss: 2.592009211099276

Epoch: 6| Step: 3
Training loss: 2.8033719062805176
Validation loss: 2.5850714842478433

Epoch: 6| Step: 4
Training loss: 2.2570133209228516
Validation loss: 2.5885508470637824

Epoch: 6| Step: 5
Training loss: 2.2763516902923584
Validation loss: 2.585775221547773

Epoch: 6| Step: 6
Training loss: 3.1661181449890137
Validation loss: 2.5859781003767446

Epoch: 6| Step: 7
Training loss: 2.5662271976470947
Validation loss: 2.583932102367442

Epoch: 6| Step: 8
Training loss: 2.7871131896972656
Validation loss: 2.5822689353778796

Epoch: 6| Step: 9
Training loss: 3.549752950668335
Validation loss: 2.5824322033953924

Epoch: 6| Step: 10
Training loss: 2.331984519958496
Validation loss: 2.590043995970039

Epoch: 6| Step: 11
Training loss: 3.3001327514648438
Validation loss: 2.586196017521684

Epoch: 6| Step: 12
Training loss: 2.70161771774292
Validation loss: 2.5938760772828133

Epoch: 6| Step: 13
Training loss: 1.9648308753967285
Validation loss: 2.594900341444118

Epoch: 43| Step: 0
Training loss: 3.9194188117980957
Validation loss: 2.590391828167823

Epoch: 6| Step: 1
Training loss: 2.7794837951660156
Validation loss: 2.5880212463358396

Epoch: 6| Step: 2
Training loss: 2.4337844848632812
Validation loss: 2.5811025814343522

Epoch: 6| Step: 3
Training loss: 2.7490224838256836
Validation loss: 2.5906266807228007

Epoch: 6| Step: 4
Training loss: 2.1402406692504883
Validation loss: 2.5897808408224456

Epoch: 6| Step: 5
Training loss: 2.918459177017212
Validation loss: 2.591832337840911

Epoch: 6| Step: 6
Training loss: 3.0933034420013428
Validation loss: 2.594739685776413

Epoch: 6| Step: 7
Training loss: 2.303300380706787
Validation loss: 2.5953821828288417

Epoch: 6| Step: 8
Training loss: 1.9885458946228027
Validation loss: 2.581658735070177

Epoch: 6| Step: 9
Training loss: 3.384873151779175
Validation loss: 2.5755913821599816

Epoch: 6| Step: 10
Training loss: 2.3890042304992676
Validation loss: 2.576667483134936

Epoch: 6| Step: 11
Training loss: 2.9937243461608887
Validation loss: 2.5733037071843303

Epoch: 6| Step: 12
Training loss: 2.990595817565918
Validation loss: 2.576039957743819

Epoch: 6| Step: 13
Training loss: 2.3587963581085205
Validation loss: 2.5822775620286182

Epoch: 44| Step: 0
Training loss: 3.531616687774658
Validation loss: 2.589273020785342

Epoch: 6| Step: 1
Training loss: 2.9207215309143066
Validation loss: 2.5878760968485186

Epoch: 6| Step: 2
Training loss: 2.265000104904175
Validation loss: 2.5779408793295584

Epoch: 6| Step: 3
Training loss: 2.6533889770507812
Validation loss: 2.574627989081926

Epoch: 6| Step: 4
Training loss: 3.1967921257019043
Validation loss: 2.5731342659201673

Epoch: 6| Step: 5
Training loss: 3.224492311477661
Validation loss: 2.576516761574694

Epoch: 6| Step: 6
Training loss: 2.2981576919555664
Validation loss: 2.5704221879282305

Epoch: 6| Step: 7
Training loss: 2.282108783721924
Validation loss: 2.576777401790824

Epoch: 6| Step: 8
Training loss: 3.39404296875
Validation loss: 2.5906723904353317

Epoch: 6| Step: 9
Training loss: 2.633671522140503
Validation loss: 2.6172472302631666

Epoch: 6| Step: 10
Training loss: 1.9353855848312378
Validation loss: 2.630711906699724

Epoch: 6| Step: 11
Training loss: 2.791138172149658
Validation loss: 2.609806396627939

Epoch: 6| Step: 12
Training loss: 3.0993924140930176
Validation loss: 2.5852791737484675

Epoch: 6| Step: 13
Training loss: 2.36651611328125
Validation loss: 2.5768108419192735

Epoch: 45| Step: 0
Training loss: 2.274017333984375
Validation loss: 2.569495424147575

Epoch: 6| Step: 1
Training loss: 2.4579720497131348
Validation loss: 2.5675227667695735

Epoch: 6| Step: 2
Training loss: 2.8278253078460693
Validation loss: 2.565157767265074

Epoch: 6| Step: 3
Training loss: 2.3495633602142334
Validation loss: 2.571041755778815

Epoch: 6| Step: 4
Training loss: 2.740750789642334
Validation loss: 2.5720181695876585

Epoch: 6| Step: 5
Training loss: 3.0555403232574463
Validation loss: 2.5692249113513577

Epoch: 6| Step: 6
Training loss: 3.6622517108917236
Validation loss: 2.5717939612685994

Epoch: 6| Step: 7
Training loss: 2.9194138050079346
Validation loss: 2.575629465041622

Epoch: 6| Step: 8
Training loss: 2.046668529510498
Validation loss: 2.5775471682189615

Epoch: 6| Step: 9
Training loss: 2.3528637886047363
Validation loss: 2.581591908649732

Epoch: 6| Step: 10
Training loss: 3.4398584365844727
Validation loss: 2.573793334345664

Epoch: 6| Step: 11
Training loss: 2.2921366691589355
Validation loss: 2.568541101230088

Epoch: 6| Step: 12
Training loss: 3.1339011192321777
Validation loss: 2.563343673624018

Epoch: 6| Step: 13
Training loss: 3.26004958152771
Validation loss: 2.5613158595177437

Epoch: 46| Step: 0
Training loss: 2.0387113094329834
Validation loss: 2.562312792706233

Epoch: 6| Step: 1
Training loss: 3.0322422981262207
Validation loss: 2.5607224433652815

Epoch: 6| Step: 2
Training loss: 3.2080488204956055
Validation loss: 2.5601122507485012

Epoch: 6| Step: 3
Training loss: 2.239722728729248
Validation loss: 2.5612531374859553

Epoch: 6| Step: 4
Training loss: 1.4989168643951416
Validation loss: 2.56889259687034

Epoch: 6| Step: 5
Training loss: 2.7833995819091797
Validation loss: 2.5706879759347565

Epoch: 6| Step: 6
Training loss: 2.5520477294921875
Validation loss: 2.5627918320317424

Epoch: 6| Step: 7
Training loss: 3.032182216644287
Validation loss: 2.5546694237698793

Epoch: 6| Step: 8
Training loss: 2.848064661026001
Validation loss: 2.5562008555217455

Epoch: 6| Step: 9
Training loss: 3.3536734580993652
Validation loss: 2.5545737692104873

Epoch: 6| Step: 10
Training loss: 3.0639913082122803
Validation loss: 2.557845018243277

Epoch: 6| Step: 11
Training loss: 3.731858253479004
Validation loss: 2.5555157892165647

Epoch: 6| Step: 12
Training loss: 2.153059720993042
Validation loss: 2.5583171947028047

Epoch: 6| Step: 13
Training loss: 2.9601428508758545
Validation loss: 2.555320426981936

Epoch: 47| Step: 0
Training loss: 2.832702875137329
Validation loss: 2.5555581097961753

Epoch: 6| Step: 1
Training loss: 2.9807093143463135
Validation loss: 2.5546628813589773

Epoch: 6| Step: 2
Training loss: 2.4164111614227295
Validation loss: 2.547860214787145

Epoch: 6| Step: 3
Training loss: 2.385080575942993
Validation loss: 2.548161078524846

Epoch: 6| Step: 4
Training loss: 2.470445156097412
Validation loss: 2.546123663584391

Epoch: 6| Step: 5
Training loss: 2.9392638206481934
Validation loss: 2.5435798398910032

Epoch: 6| Step: 6
Training loss: 2.422151803970337
Validation loss: 2.544544789098924

Epoch: 6| Step: 7
Training loss: 2.8409523963928223
Validation loss: 2.546345292880971

Epoch: 6| Step: 8
Training loss: 2.638504981994629
Validation loss: 2.5446023325766287

Epoch: 6| Step: 9
Training loss: 3.411924362182617
Validation loss: 2.558519385194266

Epoch: 6| Step: 10
Training loss: 2.7514615058898926
Validation loss: 2.5680627771603164

Epoch: 6| Step: 11
Training loss: 2.903446674346924
Validation loss: 2.5793544425759265

Epoch: 6| Step: 12
Training loss: 2.857994318008423
Validation loss: 2.568973097749936

Epoch: 6| Step: 13
Training loss: 2.3105573654174805
Validation loss: 2.548323280067854

Epoch: 48| Step: 0
Training loss: 2.6106178760528564
Validation loss: 2.55168794303812

Epoch: 6| Step: 1
Training loss: 3.8730735778808594
Validation loss: 2.5409531593322754

Epoch: 6| Step: 2
Training loss: 2.7157130241394043
Validation loss: 2.5374160607655845

Epoch: 6| Step: 3
Training loss: 2.1667144298553467
Validation loss: 2.538366407476446

Epoch: 6| Step: 4
Training loss: 2.5022737979888916
Validation loss: 2.5436519474111576

Epoch: 6| Step: 5
Training loss: 2.475766181945801
Validation loss: 2.54148543009194

Epoch: 6| Step: 6
Training loss: 2.823486804962158
Validation loss: 2.546967565372426

Epoch: 6| Step: 7
Training loss: 2.7028391361236572
Validation loss: 2.5461081740676716

Epoch: 6| Step: 8
Training loss: 2.6906681060791016
Validation loss: 2.5598934106929327

Epoch: 6| Step: 9
Training loss: 2.658001184463501
Validation loss: 2.5676359873945995

Epoch: 6| Step: 10
Training loss: 3.0152220726013184
Validation loss: 2.5630717277526855

Epoch: 6| Step: 11
Training loss: 2.470860481262207
Validation loss: 2.55271666537049

Epoch: 6| Step: 12
Training loss: 2.724797010421753
Validation loss: 2.5526111895038235

Epoch: 6| Step: 13
Training loss: 2.9803194999694824
Validation loss: 2.5482336603185183

Epoch: 49| Step: 0
Training loss: 2.7668418884277344
Validation loss: 2.5446212189171904

Epoch: 6| Step: 1
Training loss: 2.4655003547668457
Validation loss: 2.544132076283937

Epoch: 6| Step: 2
Training loss: 2.9160711765289307
Validation loss: 2.5360966164578675

Epoch: 6| Step: 3
Training loss: 2.2382612228393555
Validation loss: 2.5405830952429

Epoch: 6| Step: 4
Training loss: 3.181627035140991
Validation loss: 2.540296869893228

Epoch: 6| Step: 5
Training loss: 2.933746814727783
Validation loss: 2.5302570045635266

Epoch: 6| Step: 6
Training loss: 2.4358015060424805
Validation loss: 2.533358386767808

Epoch: 6| Step: 7
Training loss: 3.3910253047943115
Validation loss: 2.529915061048282

Epoch: 6| Step: 8
Training loss: 2.7273828983306885
Validation loss: 2.5332155278933945

Epoch: 6| Step: 9
Training loss: 2.6679422855377197
Validation loss: 2.5300515108211066

Epoch: 6| Step: 10
Training loss: 2.2708492279052734
Validation loss: 2.5272104842688448

Epoch: 6| Step: 11
Training loss: 2.2995314598083496
Validation loss: 2.5353341461509786

Epoch: 6| Step: 12
Training loss: 2.2543790340423584
Validation loss: 2.5345309549762356

Epoch: 6| Step: 13
Training loss: 4.335829734802246
Validation loss: 2.5321430890790877

Epoch: 50| Step: 0
Training loss: 2.610297679901123
Validation loss: 2.5311710911412395

Epoch: 6| Step: 1
Training loss: 2.449957847595215
Validation loss: 2.533548432011758

Epoch: 6| Step: 2
Training loss: 2.469775676727295
Validation loss: 2.5298963695444088

Epoch: 6| Step: 3
Training loss: 3.011714220046997
Validation loss: 2.533107729368312

Epoch: 6| Step: 4
Training loss: 2.878004550933838
Validation loss: 2.541263177830686

Epoch: 6| Step: 5
Training loss: 2.3406381607055664
Validation loss: 2.555792042004165

Epoch: 6| Step: 6
Training loss: 3.248239755630493
Validation loss: 2.555354061947074

Epoch: 6| Step: 7
Training loss: 2.3358020782470703
Validation loss: 2.5535859523280973

Epoch: 6| Step: 8
Training loss: 2.640390396118164
Validation loss: 2.533833339650144

Epoch: 6| Step: 9
Training loss: 3.0479438304901123
Validation loss: 2.523312653264692

Epoch: 6| Step: 10
Training loss: 2.550906181335449
Validation loss: 2.5231723836673203

Epoch: 6| Step: 11
Training loss: 1.607783555984497
Validation loss: 2.5242141780032905

Epoch: 6| Step: 12
Training loss: 3.148606300354004
Validation loss: 2.5310716167573006

Epoch: 6| Step: 13
Training loss: 4.633715629577637
Validation loss: 2.5347912798645678

Epoch: 51| Step: 0
Training loss: 2.663175106048584
Validation loss: 2.5232180536434217

Epoch: 6| Step: 1
Training loss: 2.880084991455078
Validation loss: 2.5198682687615834

Epoch: 6| Step: 2
Training loss: 2.167362689971924
Validation loss: 2.519091090848369

Epoch: 6| Step: 3
Training loss: 2.6365694999694824
Validation loss: 2.5175250717388686

Epoch: 6| Step: 4
Training loss: 2.5184099674224854
Validation loss: 2.514148194302795

Epoch: 6| Step: 5
Training loss: 2.783839225769043
Validation loss: 2.520721630383563

Epoch: 6| Step: 6
Training loss: 2.2324676513671875
Validation loss: 2.5147574922089935

Epoch: 6| Step: 7
Training loss: 2.6818389892578125
Validation loss: 2.516591787338257

Epoch: 6| Step: 8
Training loss: 3.614912986755371
Validation loss: 2.5217983620141142

Epoch: 6| Step: 9
Training loss: 2.7815022468566895
Validation loss: 2.529358430575299

Epoch: 6| Step: 10
Training loss: 3.4343934059143066
Validation loss: 2.5219718076849498

Epoch: 6| Step: 11
Training loss: 2.3630666732788086
Validation loss: 2.524318043903638

Epoch: 6| Step: 12
Training loss: 2.7364234924316406
Validation loss: 2.523037438751549

Epoch: 6| Step: 13
Training loss: 2.6620516777038574
Validation loss: 2.5215498734545965

Epoch: 52| Step: 0
Training loss: 2.570700168609619
Validation loss: 2.5142356477757937

Epoch: 6| Step: 1
Training loss: 2.0883312225341797
Validation loss: 2.513181486437398

Epoch: 6| Step: 2
Training loss: 2.3817906379699707
Validation loss: 2.510048871399254

Epoch: 6| Step: 3
Training loss: 2.8558669090270996
Validation loss: 2.509281719884565

Epoch: 6| Step: 4
Training loss: 2.4621479511260986
Validation loss: 2.5141872231678297

Epoch: 6| Step: 5
Training loss: 3.3500311374664307
Validation loss: 2.5084216671605266

Epoch: 6| Step: 6
Training loss: 1.9557764530181885
Validation loss: 2.5148073780921196

Epoch: 6| Step: 7
Training loss: 2.957761287689209
Validation loss: 2.51196942534498

Epoch: 6| Step: 8
Training loss: 2.4952280521392822
Validation loss: 2.5152866660907702

Epoch: 6| Step: 9
Training loss: 2.9247360229492188
Validation loss: 2.5081901268292497

Epoch: 6| Step: 10
Training loss: 3.724421977996826
Validation loss: 2.5071823032953406

Epoch: 6| Step: 11
Training loss: 2.829353094100952
Validation loss: 2.5076403797313733

Epoch: 6| Step: 12
Training loss: 3.122684955596924
Validation loss: 2.5073029738600536

Epoch: 6| Step: 13
Training loss: 2.039900779724121
Validation loss: 2.5077210344294065

Epoch: 53| Step: 0
Training loss: 2.1384270191192627
Validation loss: 2.510299221161873

Epoch: 6| Step: 1
Training loss: 3.2165465354919434
Validation loss: 2.5169644919774865

Epoch: 6| Step: 2
Training loss: 2.9910848140716553
Validation loss: 2.527216249896634

Epoch: 6| Step: 3
Training loss: 2.2437148094177246
Validation loss: 2.534674685488465

Epoch: 6| Step: 4
Training loss: 2.7774171829223633
Validation loss: 2.5309672073651384

Epoch: 6| Step: 5
Training loss: 2.5716195106506348
Validation loss: 2.5451824152341453

Epoch: 6| Step: 6
Training loss: 2.3190970420837402
Validation loss: 2.545311786795175

Epoch: 6| Step: 7
Training loss: 2.5689616203308105
Validation loss: 2.55167511458038

Epoch: 6| Step: 8
Training loss: 3.359468698501587
Validation loss: 2.536211459867416

Epoch: 6| Step: 9
Training loss: 3.2610044479370117
Validation loss: 2.5487001019139446

Epoch: 6| Step: 10
Training loss: 2.6867072582244873
Validation loss: 2.5237134477143646

Epoch: 6| Step: 11
Training loss: 2.4650566577911377
Validation loss: 2.5143401340771745

Epoch: 6| Step: 12
Training loss: 2.5953826904296875
Validation loss: 2.511935067433183

Epoch: 6| Step: 13
Training loss: 2.9515750408172607
Validation loss: 2.5114890375444965

Epoch: 54| Step: 0
Training loss: 3.0469970703125
Validation loss: 2.5220733406723186

Epoch: 6| Step: 1
Training loss: 2.8243236541748047
Validation loss: 2.5230843328660533

Epoch: 6| Step: 2
Training loss: 3.291043758392334
Validation loss: 2.5343744216426725

Epoch: 6| Step: 3
Training loss: 1.7628178596496582
Validation loss: 2.540422390866023

Epoch: 6| Step: 4
Training loss: 2.746976375579834
Validation loss: 2.53387612424871

Epoch: 6| Step: 5
Training loss: 2.754150152206421
Validation loss: 2.5219330249294156

Epoch: 6| Step: 6
Training loss: 3.065477132797241
Validation loss: 2.514662109395509

Epoch: 6| Step: 7
Training loss: 2.289498805999756
Validation loss: 2.505446216111542

Epoch: 6| Step: 8
Training loss: 2.527261257171631
Validation loss: 2.503310829080561

Epoch: 6| Step: 9
Training loss: 2.5439820289611816
Validation loss: 2.5086110048396613

Epoch: 6| Step: 10
Training loss: 2.5065720081329346
Validation loss: 2.5126449984888874

Epoch: 6| Step: 11
Training loss: 2.7839651107788086
Validation loss: 2.509418636239985

Epoch: 6| Step: 12
Training loss: 3.0843520164489746
Validation loss: 2.5089889187966623

Epoch: 6| Step: 13
Training loss: 3.0419037342071533
Validation loss: 2.5159611522510485

Epoch: 55| Step: 0
Training loss: 2.6981263160705566
Validation loss: 2.505548602791243

Epoch: 6| Step: 1
Training loss: 2.9059863090515137
Validation loss: 2.501171976007441

Epoch: 6| Step: 2
Training loss: 2.786452531814575
Validation loss: 2.4981969210409347

Epoch: 6| Step: 3
Training loss: 3.4199576377868652
Validation loss: 2.4991416520969842

Epoch: 6| Step: 4
Training loss: 3.5364718437194824
Validation loss: 2.4962689440737487

Epoch: 6| Step: 5
Training loss: 3.4928290843963623
Validation loss: 2.499855705486831

Epoch: 6| Step: 6
Training loss: 2.4274301528930664
Validation loss: 2.4986172876050396

Epoch: 6| Step: 7
Training loss: 2.2214834690093994
Validation loss: 2.4980960840819986

Epoch: 6| Step: 8
Training loss: 2.5878405570983887
Validation loss: 2.4999156254594044

Epoch: 6| Step: 9
Training loss: 2.0445117950439453
Validation loss: 2.498887200509348

Epoch: 6| Step: 10
Training loss: 2.052170991897583
Validation loss: 2.5003062704558014

Epoch: 6| Step: 11
Training loss: 2.4138782024383545
Validation loss: 2.5008685845200733

Epoch: 6| Step: 12
Training loss: 2.1835713386535645
Validation loss: 2.4979036931068666

Epoch: 6| Step: 13
Training loss: 3.5472631454467773
Validation loss: 2.5064641967896493

Epoch: 56| Step: 0
Training loss: 3.1667537689208984
Validation loss: 2.5070746714068997

Epoch: 6| Step: 1
Training loss: 3.2386255264282227
Validation loss: 2.50305954358911

Epoch: 6| Step: 2
Training loss: 3.199084520339966
Validation loss: 2.515084102589597

Epoch: 6| Step: 3
Training loss: 2.3851089477539062
Validation loss: 2.5171702805385796

Epoch: 6| Step: 4
Training loss: 3.0591816902160645
Validation loss: 2.528067760570075

Epoch: 6| Step: 5
Training loss: 2.7728657722473145
Validation loss: 2.522821513555383

Epoch: 6| Step: 6
Training loss: 1.5854744911193848
Validation loss: 2.511637559501074

Epoch: 6| Step: 7
Training loss: 2.2817068099975586
Validation loss: 2.4977847247995357

Epoch: 6| Step: 8
Training loss: 1.9749717712402344
Validation loss: 2.4958998644223778

Epoch: 6| Step: 9
Training loss: 2.9225945472717285
Validation loss: 2.501713773255707

Epoch: 6| Step: 10
Training loss: 3.393514394760132
Validation loss: 2.4955810603275093

Epoch: 6| Step: 11
Training loss: 2.0972204208374023
Validation loss: 2.493609372005668

Epoch: 6| Step: 12
Training loss: 2.405998706817627
Validation loss: 2.492448445289366

Epoch: 6| Step: 13
Training loss: 3.909668445587158
Validation loss: 2.4952319668185328

Epoch: 57| Step: 0
Training loss: 2.158052682876587
Validation loss: 2.4950983985777824

Epoch: 6| Step: 1
Training loss: 2.3172340393066406
Validation loss: 2.499510121601884

Epoch: 6| Step: 2
Training loss: 2.621126651763916
Validation loss: 2.4910402118518786

Epoch: 6| Step: 3
Training loss: 2.5778324604034424
Validation loss: 2.489913361046904

Epoch: 6| Step: 4
Training loss: 3.548882484436035
Validation loss: 2.4890694566952285

Epoch: 6| Step: 5
Training loss: 3.5812277793884277
Validation loss: 2.490659370217272

Epoch: 6| Step: 6
Training loss: 2.3695406913757324
Validation loss: 2.488965993286461

Epoch: 6| Step: 7
Training loss: 2.62766170501709
Validation loss: 2.4858097491725797

Epoch: 6| Step: 8
Training loss: 1.782017707824707
Validation loss: 2.491109930058961

Epoch: 6| Step: 9
Training loss: 3.1927309036254883
Validation loss: 2.4907057080217587

Epoch: 6| Step: 10
Training loss: 2.287973403930664
Validation loss: 2.4870009371029433

Epoch: 6| Step: 11
Training loss: 3.4878244400024414
Validation loss: 2.492078870855352

Epoch: 6| Step: 12
Training loss: 2.166846752166748
Validation loss: 2.4912588391252743

Epoch: 6| Step: 13
Training loss: 3.434130907058716
Validation loss: 2.49128649568045

Epoch: 58| Step: 0
Training loss: 3.477635383605957
Validation loss: 2.4884829239178727

Epoch: 6| Step: 1
Training loss: 3.0507779121398926
Validation loss: 2.4988601771734094

Epoch: 6| Step: 2
Training loss: 2.408812999725342
Validation loss: 2.4914642251947874

Epoch: 6| Step: 3
Training loss: 2.460153579711914
Validation loss: 2.491962981480424

Epoch: 6| Step: 4
Training loss: 2.723881959915161
Validation loss: 2.490707112896827

Epoch: 6| Step: 5
Training loss: 2.2289600372314453
Validation loss: 2.494774282619517

Epoch: 6| Step: 6
Training loss: 3.9754486083984375
Validation loss: 2.4840084634801394

Epoch: 6| Step: 7
Training loss: 2.1616153717041016
Validation loss: 2.4909805123524

Epoch: 6| Step: 8
Training loss: 2.501664638519287
Validation loss: 2.488861655676237

Epoch: 6| Step: 9
Training loss: 1.634415626525879
Validation loss: 2.492870997357112

Epoch: 6| Step: 10
Training loss: 2.579349994659424
Validation loss: 2.4887084473845777

Epoch: 6| Step: 11
Training loss: 2.9075093269348145
Validation loss: 2.4958461382055797

Epoch: 6| Step: 12
Training loss: 2.948558807373047
Validation loss: 2.4973393255664456

Epoch: 6| Step: 13
Training loss: 2.7442984580993652
Validation loss: 2.5023292726086033

Epoch: 59| Step: 0
Training loss: 2.248994827270508
Validation loss: 2.5036620427203435

Epoch: 6| Step: 1
Training loss: 2.3030495643615723
Validation loss: 2.4942215898985505

Epoch: 6| Step: 2
Training loss: 2.5274884700775146
Validation loss: 2.4921881511647213

Epoch: 6| Step: 3
Training loss: 2.9596033096313477
Validation loss: 2.4846007952126126

Epoch: 6| Step: 4
Training loss: 3.233189582824707
Validation loss: 2.486555658360963

Epoch: 6| Step: 5
Training loss: 2.3088841438293457
Validation loss: 2.4875485717609362

Epoch: 6| Step: 6
Training loss: 3.0194060802459717
Validation loss: 2.4826865939683813

Epoch: 6| Step: 7
Training loss: 2.7846484184265137
Validation loss: 2.480678512204078

Epoch: 6| Step: 8
Training loss: 2.401099920272827
Validation loss: 2.4810916223833637

Epoch: 6| Step: 9
Training loss: 2.752960681915283
Validation loss: 2.486029019919775

Epoch: 6| Step: 10
Training loss: 3.2295444011688232
Validation loss: 2.4929451032351424

Epoch: 6| Step: 11
Training loss: 2.924790382385254
Validation loss: 2.493407190486949

Epoch: 6| Step: 12
Training loss: 2.639228582382202
Validation loss: 2.488117864055018

Epoch: 6| Step: 13
Training loss: 2.2673380374908447
Validation loss: 2.4960952189660843

Epoch: 60| Step: 0
Training loss: 2.31093168258667
Validation loss: 2.4948913679328015

Epoch: 6| Step: 1
Training loss: 2.877326726913452
Validation loss: 2.4967315145718154

Epoch: 6| Step: 2
Training loss: 2.589442253112793
Validation loss: 2.5163851450848322

Epoch: 6| Step: 3
Training loss: 2.579322338104248
Validation loss: 2.5251648323510283

Epoch: 6| Step: 4
Training loss: 3.14401912689209
Validation loss: 2.5545830444623063

Epoch: 6| Step: 5
Training loss: 2.674624443054199
Validation loss: 2.5570810764066634

Epoch: 6| Step: 6
Training loss: 2.9290714263916016
Validation loss: 2.5408386773960565

Epoch: 6| Step: 7
Training loss: 3.674276351928711
Validation loss: 2.49760522637316

Epoch: 6| Step: 8
Training loss: 2.3517236709594727
Validation loss: 2.481968008061891

Epoch: 6| Step: 9
Training loss: 2.26271915435791
Validation loss: 2.4753757138406076

Epoch: 6| Step: 10
Training loss: 2.620943069458008
Validation loss: 2.4793313472501692

Epoch: 6| Step: 11
Training loss: 2.8454108238220215
Validation loss: 2.4780200860833608

Epoch: 6| Step: 12
Training loss: 2.311215877532959
Validation loss: 2.4770607589393534

Epoch: 6| Step: 13
Training loss: 2.4822003841400146
Validation loss: 2.478103255712858

Epoch: 61| Step: 0
Training loss: 1.851863145828247
Validation loss: 2.480280142958446

Epoch: 6| Step: 1
Training loss: 2.9149365425109863
Validation loss: 2.4811915812953824

Epoch: 6| Step: 2
Training loss: 2.5266265869140625
Validation loss: 2.4798427192113732

Epoch: 6| Step: 3
Training loss: 2.5171966552734375
Validation loss: 2.4788587375353743

Epoch: 6| Step: 4
Training loss: 2.628037214279175
Validation loss: 2.4882910149071806

Epoch: 6| Step: 5
Training loss: 2.2695631980895996
Validation loss: 2.480887802698279

Epoch: 6| Step: 6
Training loss: 3.214801073074341
Validation loss: 2.483437502256004

Epoch: 6| Step: 7
Training loss: 1.9511786699295044
Validation loss: 2.4788215134733464

Epoch: 6| Step: 8
Training loss: 2.9655704498291016
Validation loss: 2.480540370428434

Epoch: 6| Step: 9
Training loss: 2.7592039108276367
Validation loss: 2.480636135224373

Epoch: 6| Step: 10
Training loss: 3.364469051361084
Validation loss: 2.476966820737367

Epoch: 6| Step: 11
Training loss: 2.1065516471862793
Validation loss: 2.48650223465376

Epoch: 6| Step: 12
Training loss: 3.1937172412872314
Validation loss: 2.48983250382126

Epoch: 6| Step: 13
Training loss: 4.138210296630859
Validation loss: 2.488687274276569

Epoch: 62| Step: 0
Training loss: 2.5688562393188477
Validation loss: 2.4881858518046718

Epoch: 6| Step: 1
Training loss: 2.4006710052490234
Validation loss: 2.4914771126162623

Epoch: 6| Step: 2
Training loss: 2.9862332344055176
Validation loss: 2.502860556366623

Epoch: 6| Step: 3
Training loss: 2.5222558975219727
Validation loss: 2.4889630220269643

Epoch: 6| Step: 4
Training loss: 2.3491697311401367
Validation loss: 2.4795819969587427

Epoch: 6| Step: 5
Training loss: 2.7825136184692383
Validation loss: 2.478912522715907

Epoch: 6| Step: 6
Training loss: 2.2744436264038086
Validation loss: 2.4797579806338073

Epoch: 6| Step: 7
Training loss: 2.185284376144409
Validation loss: 2.4777929629048994

Epoch: 6| Step: 8
Training loss: 3.0996174812316895
Validation loss: 2.476511445096744

Epoch: 6| Step: 9
Training loss: 2.732797622680664
Validation loss: 2.4799187209016536

Epoch: 6| Step: 10
Training loss: 2.4736714363098145
Validation loss: 2.479304544387325

Epoch: 6| Step: 11
Training loss: 3.0152533054351807
Validation loss: 2.4737161949116695

Epoch: 6| Step: 12
Training loss: 3.3224472999572754
Validation loss: 2.480376374336981

Epoch: 6| Step: 13
Training loss: 3.1649351119995117
Validation loss: 2.476507302253477

Epoch: 63| Step: 0
Training loss: 2.5161538124084473
Validation loss: 2.482677344352968

Epoch: 6| Step: 1
Training loss: 2.980558156967163
Validation loss: 2.482771235127603

Epoch: 6| Step: 2
Training loss: 2.8454811573028564
Validation loss: 2.478806677684989

Epoch: 6| Step: 3
Training loss: 3.3701460361480713
Validation loss: 2.494344985613259

Epoch: 6| Step: 4
Training loss: 2.833223819732666
Validation loss: 2.485606949816468

Epoch: 6| Step: 5
Training loss: 2.597243547439575
Validation loss: 2.4898453604790474

Epoch: 6| Step: 6
Training loss: 1.9149298667907715
Validation loss: 2.484817045991139

Epoch: 6| Step: 7
Training loss: 2.719393730163574
Validation loss: 2.487137040784282

Epoch: 6| Step: 8
Training loss: 2.7641074657440186
Validation loss: 2.4932735966097925

Epoch: 6| Step: 9
Training loss: 2.126305341720581
Validation loss: 2.4886900301902526

Epoch: 6| Step: 10
Training loss: 3.3388898372650146
Validation loss: 2.4969529644135506

Epoch: 6| Step: 11
Training loss: 2.978461742401123
Validation loss: 2.4907068565327632

Epoch: 6| Step: 12
Training loss: 2.099248170852661
Validation loss: 2.4897672617307274

Epoch: 6| Step: 13
Training loss: 2.6182637214660645
Validation loss: 2.4754807769611316

Epoch: 64| Step: 0
Training loss: 2.6132891178131104
Validation loss: 2.4830318932892173

Epoch: 6| Step: 1
Training loss: 2.536709785461426
Validation loss: 2.474803609232749

Epoch: 6| Step: 2
Training loss: 2.295104742050171
Validation loss: 2.4829769288339922

Epoch: 6| Step: 3
Training loss: 2.039013385772705
Validation loss: 2.4835874213967273

Epoch: 6| Step: 4
Training loss: 2.160499334335327
Validation loss: 2.4804020927798365

Epoch: 6| Step: 5
Training loss: 3.3741602897644043
Validation loss: 2.484250501919818

Epoch: 6| Step: 6
Training loss: 2.477937936782837
Validation loss: 2.484357846680508

Epoch: 6| Step: 7
Training loss: 2.069153308868408
Validation loss: 2.4812437411277526

Epoch: 6| Step: 8
Training loss: 2.339615821838379
Validation loss: 2.4798984219951015

Epoch: 6| Step: 9
Training loss: 3.257495164871216
Validation loss: 2.483885988112419

Epoch: 6| Step: 10
Training loss: 3.3095786571502686
Validation loss: 2.480886495241555

Epoch: 6| Step: 11
Training loss: 2.770728588104248
Validation loss: 2.4778359461856145

Epoch: 6| Step: 12
Training loss: 3.2763891220092773
Validation loss: 2.4893590737414617

Epoch: 6| Step: 13
Training loss: 3.3464465141296387
Validation loss: 2.48768884904923

Epoch: 65| Step: 0
Training loss: 2.3597965240478516
Validation loss: 2.488451644938479

Epoch: 6| Step: 1
Training loss: 3.0403740406036377
Validation loss: 2.485802273596487

Epoch: 6| Step: 2
Training loss: 3.311455249786377
Validation loss: 2.482751484840147

Epoch: 6| Step: 3
Training loss: 2.5352609157562256
Validation loss: 2.4726930818250104

Epoch: 6| Step: 4
Training loss: 2.700491428375244
Validation loss: 2.485157133430563

Epoch: 6| Step: 5
Training loss: 1.7856388092041016
Validation loss: 2.4786178373521373

Epoch: 6| Step: 6
Training loss: 3.7509450912475586
Validation loss: 2.474779567410869

Epoch: 6| Step: 7
Training loss: 3.029818534851074
Validation loss: 2.474275742807696

Epoch: 6| Step: 8
Training loss: 2.555508613586426
Validation loss: 2.4713121639784945

Epoch: 6| Step: 9
Training loss: 2.419869899749756
Validation loss: 2.4743050734202066

Epoch: 6| Step: 10
Training loss: 1.5420442819595337
Validation loss: 2.4745766424363658

Epoch: 6| Step: 11
Training loss: 2.7512850761413574
Validation loss: 2.4711530413678897

Epoch: 6| Step: 12
Training loss: 3.118698835372925
Validation loss: 2.478061112024451

Epoch: 6| Step: 13
Training loss: 2.4877636432647705
Validation loss: 2.4764270859379924

Epoch: 66| Step: 0
Training loss: 2.349343776702881
Validation loss: 2.4848170844457482

Epoch: 6| Step: 1
Training loss: 3.5277249813079834
Validation loss: 2.4930707280353834

Epoch: 6| Step: 2
Training loss: 2.5587446689605713
Validation loss: 2.488930220245033

Epoch: 6| Step: 3
Training loss: 2.746894359588623
Validation loss: 2.483798647439608

Epoch: 6| Step: 4
Training loss: 1.948544979095459
Validation loss: 2.477314861871863

Epoch: 6| Step: 5
Training loss: 3.4873690605163574
Validation loss: 2.475841758071735

Epoch: 6| Step: 6
Training loss: 2.3484528064727783
Validation loss: 2.481664608883601

Epoch: 6| Step: 7
Training loss: 2.4866559505462646
Validation loss: 2.4794033599156204

Epoch: 6| Step: 8
Training loss: 2.7503421306610107
Validation loss: 2.4770627842154553

Epoch: 6| Step: 9
Training loss: 2.7203192710876465
Validation loss: 2.4743051093111754

Epoch: 6| Step: 10
Training loss: 3.4851269721984863
Validation loss: 2.472971265034009

Epoch: 6| Step: 11
Training loss: 2.323198080062866
Validation loss: 2.4663090346961893

Epoch: 6| Step: 12
Training loss: 2.076681613922119
Validation loss: 2.4657752026793776

Epoch: 6| Step: 13
Training loss: 2.7027766704559326
Validation loss: 2.464899624547651

Epoch: 67| Step: 0
Training loss: 3.144707679748535
Validation loss: 2.4674308043654247

Epoch: 6| Step: 1
Training loss: 2.886688232421875
Validation loss: 2.4672579201318885

Epoch: 6| Step: 2
Training loss: 2.3138058185577393
Validation loss: 2.468535090005526

Epoch: 6| Step: 3
Training loss: 2.1831836700439453
Validation loss: 2.468340196917134

Epoch: 6| Step: 4
Training loss: 3.5766029357910156
Validation loss: 2.4689820556230444

Epoch: 6| Step: 5
Training loss: 3.0257906913757324
Validation loss: 2.476270068076349

Epoch: 6| Step: 6
Training loss: 2.639247179031372
Validation loss: 2.480664263489426

Epoch: 6| Step: 7
Training loss: 1.9809975624084473
Validation loss: 2.4881773994814966

Epoch: 6| Step: 8
Training loss: 1.772235631942749
Validation loss: 2.5114619565266434

Epoch: 6| Step: 9
Training loss: 2.655242919921875
Validation loss: 2.4989343227878695

Epoch: 6| Step: 10
Training loss: 3.623836040496826
Validation loss: 2.4966938059817076

Epoch: 6| Step: 11
Training loss: 2.8290176391601562
Validation loss: 2.478911263968355

Epoch: 6| Step: 12
Training loss: 2.0563416481018066
Validation loss: 2.4603614960947344

Epoch: 6| Step: 13
Training loss: 2.8631362915039062
Validation loss: 2.461772113718012

Epoch: 68| Step: 0
Training loss: 2.687896728515625
Validation loss: 2.458912641771378

Epoch: 6| Step: 1
Training loss: 2.8747777938842773
Validation loss: 2.460382984530541

Epoch: 6| Step: 2
Training loss: 2.4096288681030273
Validation loss: 2.463518722082979

Epoch: 6| Step: 3
Training loss: 3.176501750946045
Validation loss: 2.46267681993464

Epoch: 6| Step: 4
Training loss: 2.569352865219116
Validation loss: 2.4631616274515786

Epoch: 6| Step: 5
Training loss: 3.416435480117798
Validation loss: 2.460402329762777

Epoch: 6| Step: 6
Training loss: 2.8812806606292725
Validation loss: 2.4630449138661867

Epoch: 6| Step: 7
Training loss: 2.9413399696350098
Validation loss: 2.459213845191463

Epoch: 6| Step: 8
Training loss: 2.054495334625244
Validation loss: 2.460165765977675

Epoch: 6| Step: 9
Training loss: 1.7904777526855469
Validation loss: 2.456885018656331

Epoch: 6| Step: 10
Training loss: 2.5540084838867188
Validation loss: 2.4589059942512104

Epoch: 6| Step: 11
Training loss: 2.255237102508545
Validation loss: 2.4638100913775864

Epoch: 6| Step: 12
Training loss: 2.9969844818115234
Validation loss: 2.475950179561492

Epoch: 6| Step: 13
Training loss: 3.186652898788452
Validation loss: 2.483816574978572

Epoch: 69| Step: 0
Training loss: 2.910745143890381
Validation loss: 2.4953888103526127

Epoch: 6| Step: 1
Training loss: 2.9798028469085693
Validation loss: 2.4921493914819535

Epoch: 6| Step: 2
Training loss: 2.092289447784424
Validation loss: 2.4833696490974835

Epoch: 6| Step: 3
Training loss: 2.209761142730713
Validation loss: 2.4810662987411662

Epoch: 6| Step: 4
Training loss: 2.459249496459961
Validation loss: 2.4747049398319696

Epoch: 6| Step: 5
Training loss: 3.4905402660369873
Validation loss: 2.4672554180186284

Epoch: 6| Step: 6
Training loss: 2.730098009109497
Validation loss: 2.4611034136946484

Epoch: 6| Step: 7
Training loss: 2.6972579956054688
Validation loss: 2.467272371374151

Epoch: 6| Step: 8
Training loss: 2.216153383255005
Validation loss: 2.467148070694298

Epoch: 6| Step: 9
Training loss: 2.7927069664001465
Validation loss: 2.4745670467294674

Epoch: 6| Step: 10
Training loss: 3.0839345455169678
Validation loss: 2.470129620644354

Epoch: 6| Step: 11
Training loss: 2.8427624702453613
Validation loss: 2.4781427844878166

Epoch: 6| Step: 12
Training loss: 2.364039421081543
Validation loss: 2.4876200716982604

Epoch: 6| Step: 13
Training loss: 2.673537254333496
Validation loss: 2.4847415877926733

Epoch: 70| Step: 0
Training loss: 2.9600443840026855
Validation loss: 2.4867805255356656

Epoch: 6| Step: 1
Training loss: 2.2855005264282227
Validation loss: 2.4916642019825597

Epoch: 6| Step: 2
Training loss: 2.3613624572753906
Validation loss: 2.4783539618215253

Epoch: 6| Step: 3
Training loss: 3.2717983722686768
Validation loss: 2.4797900261417514

Epoch: 6| Step: 4
Training loss: 2.436464548110962
Validation loss: 2.4792707889310774

Epoch: 6| Step: 5
Training loss: 2.9243733882904053
Validation loss: 2.471489332055533

Epoch: 6| Step: 6
Training loss: 3.0758280754089355
Validation loss: 2.474152509884168

Epoch: 6| Step: 7
Training loss: 2.2039172649383545
Validation loss: 2.4680526128379245

Epoch: 6| Step: 8
Training loss: 2.5423028469085693
Validation loss: 2.466520522230415

Epoch: 6| Step: 9
Training loss: 2.371558427810669
Validation loss: 2.466745140731976

Epoch: 6| Step: 10
Training loss: 2.7972466945648193
Validation loss: 2.465860438603227

Epoch: 6| Step: 11
Training loss: 2.4822473526000977
Validation loss: 2.464343745221374

Epoch: 6| Step: 12
Training loss: 2.6619205474853516
Validation loss: 2.459392727062266

Epoch: 6| Step: 13
Training loss: 3.4250993728637695
Validation loss: 2.463749216448876

Epoch: 71| Step: 0
Training loss: 2.703270435333252
Validation loss: 2.4587151235149753

Epoch: 6| Step: 1
Training loss: 3.1129961013793945
Validation loss: 2.4596500473637737

Epoch: 6| Step: 2
Training loss: 3.649531841278076
Validation loss: 2.459154587919994

Epoch: 6| Step: 3
Training loss: 2.05462384223938
Validation loss: 2.4576634155806674

Epoch: 6| Step: 4
Training loss: 3.2162253856658936
Validation loss: 2.4540544632942445

Epoch: 6| Step: 5
Training loss: 2.2350363731384277
Validation loss: 2.450032949447632

Epoch: 6| Step: 6
Training loss: 2.411742687225342
Validation loss: 2.4567025733250443

Epoch: 6| Step: 7
Training loss: 2.9599618911743164
Validation loss: 2.4533421557436705

Epoch: 6| Step: 8
Training loss: 3.070998430252075
Validation loss: 2.4492274535599576

Epoch: 6| Step: 9
Training loss: 3.159238338470459
Validation loss: 2.4649361769358316

Epoch: 6| Step: 10
Training loss: 2.328990936279297
Validation loss: 2.459665398443899

Epoch: 6| Step: 11
Training loss: 1.6207289695739746
Validation loss: 2.4581774306553665

Epoch: 6| Step: 12
Training loss: 2.473344326019287
Validation loss: 2.4551398164482525

Epoch: 6| Step: 13
Training loss: 2.035890817642212
Validation loss: 2.4659222761789956

Epoch: 72| Step: 0
Training loss: 2.73817777633667
Validation loss: 2.4857148098689255

Epoch: 6| Step: 1
Training loss: 2.752285957336426
Validation loss: 2.483712934678601

Epoch: 6| Step: 2
Training loss: 1.9824151992797852
Validation loss: 2.4859199395743747

Epoch: 6| Step: 3
Training loss: 3.1838109493255615
Validation loss: 2.5117743656199467

Epoch: 6| Step: 4
Training loss: 2.378537654876709
Validation loss: 2.5169138011112007

Epoch: 6| Step: 5
Training loss: 2.2847352027893066
Validation loss: 2.4932985972332697

Epoch: 6| Step: 6
Training loss: 3.049262285232544
Validation loss: 2.455710203416886

Epoch: 6| Step: 7
Training loss: 2.7677931785583496
Validation loss: 2.4484779860383723

Epoch: 6| Step: 8
Training loss: 2.6540918350219727
Validation loss: 2.451737653824591

Epoch: 6| Step: 9
Training loss: 2.225196599960327
Validation loss: 2.4477623483186126

Epoch: 6| Step: 10
Training loss: 3.3280811309814453
Validation loss: 2.4514036204225276

Epoch: 6| Step: 11
Training loss: 2.9588990211486816
Validation loss: 2.4525665570330877

Epoch: 6| Step: 12
Training loss: 3.165118455886841
Validation loss: 2.4452679669985207

Epoch: 6| Step: 13
Training loss: 1.3984112739562988
Validation loss: 2.450009294735488

Epoch: 73| Step: 0
Training loss: 3.0398333072662354
Validation loss: 2.4499824739271596

Epoch: 6| Step: 1
Training loss: 2.863887310028076
Validation loss: 2.4492152006395402

Epoch: 6| Step: 2
Training loss: 3.3108158111572266
Validation loss: 2.451800430974653

Epoch: 6| Step: 3
Training loss: 3.1074209213256836
Validation loss: 2.452842702147781

Epoch: 6| Step: 4
Training loss: 2.8414273262023926
Validation loss: 2.4499722834556334

Epoch: 6| Step: 5
Training loss: 2.9650144577026367
Validation loss: 2.4534571734807824

Epoch: 6| Step: 6
Training loss: 2.991159200668335
Validation loss: 2.457553707143312

Epoch: 6| Step: 7
Training loss: 2.928866386413574
Validation loss: 2.4590020384839786

Epoch: 6| Step: 8
Training loss: 2.5215702056884766
Validation loss: 2.451957033526513

Epoch: 6| Step: 9
Training loss: 2.4622297286987305
Validation loss: 2.4536951100954445

Epoch: 6| Step: 10
Training loss: 2.0393223762512207
Validation loss: 2.466131359018305

Epoch: 6| Step: 11
Training loss: 1.981675386428833
Validation loss: 2.4668899851460613

Epoch: 6| Step: 12
Training loss: 1.6971684694290161
Validation loss: 2.467075269709351

Epoch: 6| Step: 13
Training loss: 2.5985870361328125
Validation loss: 2.4664638888451362

Epoch: 74| Step: 0
Training loss: 2.2125535011291504
Validation loss: 2.4798408682628343

Epoch: 6| Step: 1
Training loss: 1.8715554475784302
Validation loss: 2.4835464210920435

Epoch: 6| Step: 2
Training loss: 2.6048166751861572
Validation loss: 2.500803344993181

Epoch: 6| Step: 3
Training loss: 3.4508285522460938
Validation loss: 2.51552152633667

Epoch: 6| Step: 4
Training loss: 2.7379517555236816
Validation loss: 2.519276347211612

Epoch: 6| Step: 5
Training loss: 3.291236400604248
Validation loss: 2.495867572804933

Epoch: 6| Step: 6
Training loss: 2.7089972496032715
Validation loss: 2.488614369464177

Epoch: 6| Step: 7
Training loss: 3.241568088531494
Validation loss: 2.4732332665433168

Epoch: 6| Step: 8
Training loss: 2.119957447052002
Validation loss: 2.4557059106006416

Epoch: 6| Step: 9
Training loss: 1.9873111248016357
Validation loss: 2.4534904110816216

Epoch: 6| Step: 10
Training loss: 3.0625391006469727
Validation loss: 2.4487193604951263

Epoch: 6| Step: 11
Training loss: 2.5024774074554443
Validation loss: 2.4528248361361924

Epoch: 6| Step: 12
Training loss: 2.9848859310150146
Validation loss: 2.4569291632662535

Epoch: 6| Step: 13
Training loss: 2.704101324081421
Validation loss: 2.461670373075752

Epoch: 75| Step: 0
Training loss: 3.130438804626465
Validation loss: 2.4682781234864266

Epoch: 6| Step: 1
Training loss: 3.0032620429992676
Validation loss: 2.4720911377219745

Epoch: 6| Step: 2
Training loss: 2.4241809844970703
Validation loss: 2.474341970618053

Epoch: 6| Step: 3
Training loss: 1.9149169921875
Validation loss: 2.4732149877855854

Epoch: 6| Step: 4
Training loss: 2.921037197113037
Validation loss: 2.474003327790127

Epoch: 6| Step: 5
Training loss: 2.34592342376709
Validation loss: 2.4616100865025676

Epoch: 6| Step: 6
Training loss: 2.995288610458374
Validation loss: 2.459043889917353

Epoch: 6| Step: 7
Training loss: 2.7193589210510254
Validation loss: 2.4536209080808904

Epoch: 6| Step: 8
Training loss: 2.5431747436523438
Validation loss: 2.4516365220469813

Epoch: 6| Step: 9
Training loss: 3.3623523712158203
Validation loss: 2.449173959352637

Epoch: 6| Step: 10
Training loss: 2.4211387634277344
Validation loss: 2.4519239446168304

Epoch: 6| Step: 11
Training loss: 2.699467658996582
Validation loss: 2.4646104535748883

Epoch: 6| Step: 12
Training loss: 2.28395414352417
Validation loss: 2.475154815181609

Epoch: 6| Step: 13
Training loss: 2.682095766067505
Validation loss: 2.4950340870888

Epoch: 76| Step: 0
Training loss: 2.054417133331299
Validation loss: 2.4876456465772403

Epoch: 6| Step: 1
Training loss: 2.863497257232666
Validation loss: 2.492961665635468

Epoch: 6| Step: 2
Training loss: 3.047767400741577
Validation loss: 2.495322004441292

Epoch: 6| Step: 3
Training loss: 2.268738031387329
Validation loss: 2.4743553720494753

Epoch: 6| Step: 4
Training loss: 2.432201623916626
Validation loss: 2.465621909787578

Epoch: 6| Step: 5
Training loss: 3.312570095062256
Validation loss: 2.464740804446641

Epoch: 6| Step: 6
Training loss: 2.9314193725585938
Validation loss: 2.445094664891561

Epoch: 6| Step: 7
Training loss: 2.507944107055664
Validation loss: 2.4436514992867746

Epoch: 6| Step: 8
Training loss: 2.535513162612915
Validation loss: 2.441692944495909

Epoch: 6| Step: 9
Training loss: 2.780773639678955
Validation loss: 2.438283069159395

Epoch: 6| Step: 10
Training loss: 3.064136028289795
Validation loss: 2.437850788075437

Epoch: 6| Step: 11
Training loss: 2.416398525238037
Validation loss: 2.4363204176707933

Epoch: 6| Step: 12
Training loss: 2.510340690612793
Validation loss: 2.4367714338405158

Epoch: 6| Step: 13
Training loss: 2.8015081882476807
Validation loss: 2.4352374897208264

Epoch: 77| Step: 0
Training loss: 3.157258987426758
Validation loss: 2.4334204735294467

Epoch: 6| Step: 1
Training loss: 2.8683085441589355
Validation loss: 2.4364322936663063

Epoch: 6| Step: 2
Training loss: 2.9706478118896484
Validation loss: 2.4368767533251035

Epoch: 6| Step: 3
Training loss: 2.589169502258301
Validation loss: 2.4395887159532115

Epoch: 6| Step: 4
Training loss: 2.0299816131591797
Validation loss: 2.437986050882647

Epoch: 6| Step: 5
Training loss: 1.902794599533081
Validation loss: 2.434658927302207

Epoch: 6| Step: 6
Training loss: 2.5624310970306396
Validation loss: 2.4404820242235736

Epoch: 6| Step: 7
Training loss: 2.8723092079162598
Validation loss: 2.4337933781326457

Epoch: 6| Step: 8
Training loss: 2.4537034034729004
Validation loss: 2.441829853160407

Epoch: 6| Step: 9
Training loss: 2.579153060913086
Validation loss: 2.432210563331522

Epoch: 6| Step: 10
Training loss: 2.7025985717773438
Validation loss: 2.4354501693479476

Epoch: 6| Step: 11
Training loss: 3.1446409225463867
Validation loss: 2.4341055808528775

Epoch: 6| Step: 12
Training loss: 2.942072868347168
Validation loss: 2.439393684428225

Epoch: 6| Step: 13
Training loss: 2.4332573413848877
Validation loss: 2.4394704885380243

Epoch: 78| Step: 0
Training loss: 1.8801193237304688
Validation loss: 2.4447850181210424

Epoch: 6| Step: 1
Training loss: 2.7412924766540527
Validation loss: 2.4432758926063456

Epoch: 6| Step: 2
Training loss: 2.4944193363189697
Validation loss: 2.4486123618259223

Epoch: 6| Step: 3
Training loss: 2.5329413414001465
Validation loss: 2.459608398458009

Epoch: 6| Step: 4
Training loss: 2.197661876678467
Validation loss: 2.468600760224045

Epoch: 6| Step: 5
Training loss: 2.2076830863952637
Validation loss: 2.480777730223953

Epoch: 6| Step: 6
Training loss: 2.6742050647735596
Validation loss: 2.492213805516561

Epoch: 6| Step: 7
Training loss: 2.3644518852233887
Validation loss: 2.4932697408942768

Epoch: 6| Step: 8
Training loss: 3.4351792335510254
Validation loss: 2.48736983729947

Epoch: 6| Step: 9
Training loss: 2.5549585819244385
Validation loss: 2.477246771576584

Epoch: 6| Step: 10
Training loss: 2.7576904296875
Validation loss: 2.4710167813044723

Epoch: 6| Step: 11
Training loss: 2.835537910461426
Validation loss: 2.4677457014719644

Epoch: 6| Step: 12
Training loss: 3.8330860137939453
Validation loss: 2.457533262109244

Epoch: 6| Step: 13
Training loss: 3.0148046016693115
Validation loss: 2.449321085406888

Epoch: 79| Step: 0
Training loss: 2.4016857147216797
Validation loss: 2.454267337758054

Epoch: 6| Step: 1
Training loss: 3.476470947265625
Validation loss: 2.444225013896983

Epoch: 6| Step: 2
Training loss: 2.55182147026062
Validation loss: 2.4449252338819605

Epoch: 6| Step: 3
Training loss: 3.184298038482666
Validation loss: 2.434021503694596

Epoch: 6| Step: 4
Training loss: 2.8043909072875977
Validation loss: 2.43217743596723

Epoch: 6| Step: 5
Training loss: 2.185978889465332
Validation loss: 2.4333013001308648

Epoch: 6| Step: 6
Training loss: 2.4933083057403564
Validation loss: 2.430610054282732

Epoch: 6| Step: 7
Training loss: 2.5756311416625977
Validation loss: 2.4325662761606197

Epoch: 6| Step: 8
Training loss: 2.2339015007019043
Validation loss: 2.432485939354025

Epoch: 6| Step: 9
Training loss: 2.244978427886963
Validation loss: 2.429454506084483

Epoch: 6| Step: 10
Training loss: 2.8111014366149902
Validation loss: 2.435395206174543

Epoch: 6| Step: 11
Training loss: 2.431547164916992
Validation loss: 2.4315649719648462

Epoch: 6| Step: 12
Training loss: 2.761204242706299
Validation loss: 2.437635367916476

Epoch: 6| Step: 13
Training loss: 3.3511953353881836
Validation loss: 2.4464433834116948

Epoch: 80| Step: 0
Training loss: 2.9150633811950684
Validation loss: 2.444716586861559

Epoch: 6| Step: 1
Training loss: 3.220466136932373
Validation loss: 2.441096882666311

Epoch: 6| Step: 2
Training loss: 3.0346453189849854
Validation loss: 2.4540834426879883

Epoch: 6| Step: 3
Training loss: 2.519766330718994
Validation loss: 2.454159939160911

Epoch: 6| Step: 4
Training loss: 2.485156536102295
Validation loss: 2.443030902134475

Epoch: 6| Step: 5
Training loss: 2.325664520263672
Validation loss: 2.4518841133322766

Epoch: 6| Step: 6
Training loss: 2.4427456855773926
Validation loss: 2.4519125979433776

Epoch: 6| Step: 7
Training loss: 2.437760353088379
Validation loss: 2.44460738858869

Epoch: 6| Step: 8
Training loss: 2.5696840286254883
Validation loss: 2.4415003022839947

Epoch: 6| Step: 9
Training loss: 2.42578125
Validation loss: 2.436825090839017

Epoch: 6| Step: 10
Training loss: 2.56820011138916
Validation loss: 2.4465951740100818

Epoch: 6| Step: 11
Training loss: 3.185269355773926
Validation loss: 2.436636378688197

Epoch: 6| Step: 12
Training loss: 2.541135549545288
Validation loss: 2.4349321601211384

Epoch: 6| Step: 13
Training loss: 2.337864875793457
Validation loss: 2.4246344720163653

Epoch: 81| Step: 0
Training loss: 2.6575863361358643
Validation loss: 2.4365539089325936

Epoch: 6| Step: 1
Training loss: 2.4461886882781982
Validation loss: 2.4300640603547454

Epoch: 6| Step: 2
Training loss: 1.8875923156738281
Validation loss: 2.4397563985598985

Epoch: 6| Step: 3
Training loss: 3.121344566345215
Validation loss: 2.4538473185672554

Epoch: 6| Step: 4
Training loss: 3.062873601913452
Validation loss: 2.4615963864070114

Epoch: 6| Step: 5
Training loss: 2.8477954864501953
Validation loss: 2.4579677684332735

Epoch: 6| Step: 6
Training loss: 2.0982298851013184
Validation loss: 2.4618614719760035

Epoch: 6| Step: 7
Training loss: 2.622645616531372
Validation loss: 2.4554565568124094

Epoch: 6| Step: 8
Training loss: 2.9467716217041016
Validation loss: 2.452024321402273

Epoch: 6| Step: 9
Training loss: 2.273197889328003
Validation loss: 2.447636606872723

Epoch: 6| Step: 10
Training loss: 2.7350387573242188
Validation loss: 2.4427153987269246

Epoch: 6| Step: 11
Training loss: 3.107243537902832
Validation loss: 2.437878611267254

Epoch: 6| Step: 12
Training loss: 3.1702051162719727
Validation loss: 2.4331199456286687

Epoch: 6| Step: 13
Training loss: 1.8814362287521362
Validation loss: 2.433420829875495

Epoch: 82| Step: 0
Training loss: 3.0958309173583984
Validation loss: 2.4324390413940593

Epoch: 6| Step: 1
Training loss: 2.4750635623931885
Validation loss: 2.431642609257852

Epoch: 6| Step: 2
Training loss: 2.9223246574401855
Validation loss: 2.434441030666392

Epoch: 6| Step: 3
Training loss: 2.378417730331421
Validation loss: 2.4366193561143774

Epoch: 6| Step: 4
Training loss: 2.8754420280456543
Validation loss: 2.444160084570608

Epoch: 6| Step: 5
Training loss: 2.190884828567505
Validation loss: 2.4670494371844875

Epoch: 6| Step: 6
Training loss: 2.3188986778259277
Validation loss: 2.486118011577155

Epoch: 6| Step: 7
Training loss: 2.6322736740112305
Validation loss: 2.4447781834551083

Epoch: 6| Step: 8
Training loss: 2.05047345161438
Validation loss: 2.442232249885477

Epoch: 6| Step: 9
Training loss: 2.60398268699646
Validation loss: 2.4472965809606735

Epoch: 6| Step: 10
Training loss: 2.197434663772583
Validation loss: 2.4497801180808776

Epoch: 6| Step: 11
Training loss: 2.983241319656372
Validation loss: 2.4319825608243226

Epoch: 6| Step: 12
Training loss: 3.370570659637451
Validation loss: 2.4280610930535103

Epoch: 6| Step: 13
Training loss: 3.2414350509643555
Validation loss: 2.4294538113378708

Epoch: 83| Step: 0
Training loss: 2.3602874279022217
Validation loss: 2.438316632342595

Epoch: 6| Step: 1
Training loss: 2.653947114944458
Validation loss: 2.4393319019707302

Epoch: 6| Step: 2
Training loss: 3.0200014114379883
Validation loss: 2.4442853863521288

Epoch: 6| Step: 3
Training loss: 2.4629557132720947
Validation loss: 2.4482197684626423

Epoch: 6| Step: 4
Training loss: 1.862343430519104
Validation loss: 2.4566091414420836

Epoch: 6| Step: 5
Training loss: 2.218637466430664
Validation loss: 2.44718175806025

Epoch: 6| Step: 6
Training loss: 3.7593040466308594
Validation loss: 2.44390078513853

Epoch: 6| Step: 7
Training loss: 2.5551161766052246
Validation loss: 2.4400579672987743

Epoch: 6| Step: 8
Training loss: 2.7316417694091797
Validation loss: 2.4322789048635833

Epoch: 6| Step: 9
Training loss: 2.465400457382202
Validation loss: 2.434138233943652

Epoch: 6| Step: 10
Training loss: 2.8661983013153076
Validation loss: 2.442850580779455

Epoch: 6| Step: 11
Training loss: 3.0063819885253906
Validation loss: 2.4332120495457805

Epoch: 6| Step: 12
Training loss: 2.617417812347412
Validation loss: 2.431418113811042

Epoch: 6| Step: 13
Training loss: 2.255885124206543
Validation loss: 2.4302032634776127

Epoch: 84| Step: 0
Training loss: 2.314344882965088
Validation loss: 2.432084045102519

Epoch: 6| Step: 1
Training loss: 3.1069135665893555
Validation loss: 2.4301069859535462

Epoch: 6| Step: 2
Training loss: 2.429234743118286
Validation loss: 2.427775203540761

Epoch: 6| Step: 3
Training loss: 2.6093099117279053
Validation loss: 2.4271773394717964

Epoch: 6| Step: 4
Training loss: 2.678114891052246
Validation loss: 2.4261353759355444

Epoch: 6| Step: 5
Training loss: 2.520944356918335
Validation loss: 2.4274557892994215

Epoch: 6| Step: 6
Training loss: 2.7292871475219727
Validation loss: 2.4247497102265716

Epoch: 6| Step: 7
Training loss: 3.053924322128296
Validation loss: 2.422957025548463

Epoch: 6| Step: 8
Training loss: 1.88020658493042
Validation loss: 2.4316716091607207

Epoch: 6| Step: 9
Training loss: 3.4718809127807617
Validation loss: 2.432588336288288

Epoch: 6| Step: 10
Training loss: 3.0578269958496094
Validation loss: 2.4379571971072944

Epoch: 6| Step: 11
Training loss: 2.342599868774414
Validation loss: 2.449003968187558

Epoch: 6| Step: 12
Training loss: 2.3879857063293457
Validation loss: 2.446608333177464

Epoch: 6| Step: 13
Training loss: 2.083735466003418
Validation loss: 2.4445335941929973

Epoch: 85| Step: 0
Training loss: 2.5206055641174316
Validation loss: 2.448924864492109

Epoch: 6| Step: 1
Training loss: 2.683962821960449
Validation loss: 2.445435385550222

Epoch: 6| Step: 2
Training loss: 2.739720344543457
Validation loss: 2.4372835082392537

Epoch: 6| Step: 3
Training loss: 2.877136468887329
Validation loss: 2.4343880440599177

Epoch: 6| Step: 4
Training loss: 2.0194451808929443
Validation loss: 2.430804903789233

Epoch: 6| Step: 5
Training loss: 2.418797492980957
Validation loss: 2.446253938059653

Epoch: 6| Step: 6
Training loss: 2.7968525886535645
Validation loss: 2.43705076812416

Epoch: 6| Step: 7
Training loss: 2.515076160430908
Validation loss: 2.4388946064056887

Epoch: 6| Step: 8
Training loss: 3.4750545024871826
Validation loss: 2.43413632915866

Epoch: 6| Step: 9
Training loss: 3.428027629852295
Validation loss: 2.430496536275392

Epoch: 6| Step: 10
Training loss: 3.1255125999450684
Validation loss: 2.424357860319076

Epoch: 6| Step: 11
Training loss: 2.0303869247436523
Validation loss: 2.4194812749021795

Epoch: 6| Step: 12
Training loss: 2.1381497383117676
Validation loss: 2.417910273357104

Epoch: 6| Step: 13
Training loss: 1.8166955709457397
Validation loss: 2.4183504786542667

Epoch: 86| Step: 0
Training loss: 3.3286221027374268
Validation loss: 2.4184711082007295

Epoch: 6| Step: 1
Training loss: 2.325320243835449
Validation loss: 2.4196385388733237

Epoch: 6| Step: 2
Training loss: 2.297846794128418
Validation loss: 2.424212763386388

Epoch: 6| Step: 3
Training loss: 2.698864459991455
Validation loss: 2.4251802480348976

Epoch: 6| Step: 4
Training loss: 2.613420009613037
Validation loss: 2.4261374191571305

Epoch: 6| Step: 5
Training loss: 2.228245735168457
Validation loss: 2.426631248125466

Epoch: 6| Step: 6
Training loss: 3.072979688644409
Validation loss: 2.4384713916368383

Epoch: 6| Step: 7
Training loss: 1.8880641460418701
Validation loss: 2.4309232055499987

Epoch: 6| Step: 8
Training loss: 3.3600566387176514
Validation loss: 2.4285818863940496

Epoch: 6| Step: 9
Training loss: 2.537015438079834
Validation loss: 2.4372979364087506

Epoch: 6| Step: 10
Training loss: 2.5655267238616943
Validation loss: 2.422330710195726

Epoch: 6| Step: 11
Training loss: 2.0779433250427246
Validation loss: 2.4175868726545766

Epoch: 6| Step: 12
Training loss: 2.9807801246643066
Validation loss: 2.4253598272159533

Epoch: 6| Step: 13
Training loss: 3.139052629470825
Validation loss: 2.432318769475465

Epoch: 87| Step: 0
Training loss: 2.4186668395996094
Validation loss: 2.430234509129678

Epoch: 6| Step: 1
Training loss: 2.6149404048919678
Validation loss: 2.4364898358621905

Epoch: 6| Step: 2
Training loss: 3.0087127685546875
Validation loss: 2.4339867612367034

Epoch: 6| Step: 3
Training loss: 2.3443541526794434
Validation loss: 2.4282191158622823

Epoch: 6| Step: 4
Training loss: 1.7946463823318481
Validation loss: 2.426809746731994

Epoch: 6| Step: 5
Training loss: 2.3151183128356934
Validation loss: 2.4268732763105825

Epoch: 6| Step: 6
Training loss: 3.041433095932007
Validation loss: 2.427775218922605

Epoch: 6| Step: 7
Training loss: 2.5134472846984863
Validation loss: 2.431654030276883

Epoch: 6| Step: 8
Training loss: 2.5224597454071045
Validation loss: 2.4343974513392292

Epoch: 6| Step: 9
Training loss: 2.8607263565063477
Validation loss: 2.4373780117240003

Epoch: 6| Step: 10
Training loss: 3.097522258758545
Validation loss: 2.4294317589011243

Epoch: 6| Step: 11
Training loss: 2.8836960792541504
Validation loss: 2.422288299888693

Epoch: 6| Step: 12
Training loss: 3.1073126792907715
Validation loss: 2.4142522401707147

Epoch: 6| Step: 13
Training loss: 2.1337404251098633
Validation loss: 2.4057106869195097

Epoch: 88| Step: 0
Training loss: 2.4900131225585938
Validation loss: 2.4077224731445312

Epoch: 6| Step: 1
Training loss: 2.880164384841919
Validation loss: 2.4072131674776793

Epoch: 6| Step: 2
Training loss: 2.649003505706787
Validation loss: 2.4044172379278366

Epoch: 6| Step: 3
Training loss: 2.3612141609191895
Validation loss: 2.4063105506281697

Epoch: 6| Step: 4
Training loss: 2.5484910011291504
Validation loss: 2.4084278691199517

Epoch: 6| Step: 5
Training loss: 2.315131664276123
Validation loss: 2.40548139233743

Epoch: 6| Step: 6
Training loss: 3.0419702529907227
Validation loss: 2.4098619068822553

Epoch: 6| Step: 7
Training loss: 2.0577869415283203
Validation loss: 2.413991828118601

Epoch: 6| Step: 8
Training loss: 2.5355067253112793
Validation loss: 2.4183799502670125

Epoch: 6| Step: 9
Training loss: 3.445361614227295
Validation loss: 2.427715265622703

Epoch: 6| Step: 10
Training loss: 2.101226806640625
Validation loss: 2.4166419172799714

Epoch: 6| Step: 11
Training loss: 2.852093458175659
Validation loss: 2.4188263544472317

Epoch: 6| Step: 12
Training loss: 2.719090700149536
Validation loss: 2.4159875377531974

Epoch: 6| Step: 13
Training loss: 2.8874995708465576
Validation loss: 2.422471679666991

Epoch: 89| Step: 0
Training loss: 2.08154559135437
Validation loss: 2.43246550713816

Epoch: 6| Step: 1
Training loss: 2.1788177490234375
Validation loss: 2.442551874345349

Epoch: 6| Step: 2
Training loss: 2.851977825164795
Validation loss: 2.4332101370698664

Epoch: 6| Step: 3
Training loss: 2.552582263946533
Validation loss: 2.4412335734213553

Epoch: 6| Step: 4
Training loss: 2.3276278972625732
Validation loss: 2.4445531983529367

Epoch: 6| Step: 5
Training loss: 3.4176130294799805
Validation loss: 2.4388389356674685

Epoch: 6| Step: 6
Training loss: 2.737912654876709
Validation loss: 2.4400225326579106

Epoch: 6| Step: 7
Training loss: 2.697902202606201
Validation loss: 2.446408656335646

Epoch: 6| Step: 8
Training loss: 2.475084066390991
Validation loss: 2.4333772159391835

Epoch: 6| Step: 9
Training loss: 1.8191275596618652
Validation loss: 2.413502154811736

Epoch: 6| Step: 10
Training loss: 3.209399700164795
Validation loss: 2.406027950266356

Epoch: 6| Step: 11
Training loss: 2.6250247955322266
Validation loss: 2.4089177423907864

Epoch: 6| Step: 12
Training loss: 3.1129398345947266
Validation loss: 2.4160162069464244

Epoch: 6| Step: 13
Training loss: 2.661983013153076
Validation loss: 2.4095976480873684

Epoch: 90| Step: 0
Training loss: 2.2001686096191406
Validation loss: 2.4080818622343

Epoch: 6| Step: 1
Training loss: 2.9144372940063477
Validation loss: 2.417453710750867

Epoch: 6| Step: 2
Training loss: 2.5278420448303223
Validation loss: 2.4125469012926986

Epoch: 6| Step: 3
Training loss: 3.0780553817749023
Validation loss: 2.419742489373812

Epoch: 6| Step: 4
Training loss: 2.4096715450286865
Validation loss: 2.4129250639228412

Epoch: 6| Step: 5
Training loss: 3.144441604614258
Validation loss: 2.410288877384637

Epoch: 6| Step: 6
Training loss: 1.8856945037841797
Validation loss: 2.41466542854104

Epoch: 6| Step: 7
Training loss: 3.2659802436828613
Validation loss: 2.407252450143137

Epoch: 6| Step: 8
Training loss: 2.1849453449249268
Validation loss: 2.404670920423282

Epoch: 6| Step: 9
Training loss: 2.77801251411438
Validation loss: 2.4047264719522126

Epoch: 6| Step: 10
Training loss: 2.2765936851501465
Validation loss: 2.408777408702399

Epoch: 6| Step: 11
Training loss: 2.7709951400756836
Validation loss: 2.4065790073845976

Epoch: 6| Step: 12
Training loss: 2.481386661529541
Validation loss: 2.410851587531387

Epoch: 6| Step: 13
Training loss: 2.885179042816162
Validation loss: 2.412708543962048

Epoch: 91| Step: 0
Training loss: 1.832771897315979
Validation loss: 2.4151639169262302

Epoch: 6| Step: 1
Training loss: 2.8753867149353027
Validation loss: 2.42157385938911

Epoch: 6| Step: 2
Training loss: 2.500713586807251
Validation loss: 2.443041233606236

Epoch: 6| Step: 3
Training loss: 2.8530611991882324
Validation loss: 2.4309953540884037

Epoch: 6| Step: 4
Training loss: 2.5498485565185547
Validation loss: 2.4465029649837042

Epoch: 6| Step: 5
Training loss: 2.4848592281341553
Validation loss: 2.4225169484333327

Epoch: 6| Step: 6
Training loss: 1.7418922185897827
Validation loss: 2.4160123602036507

Epoch: 6| Step: 7
Training loss: 3.683931827545166
Validation loss: 2.421839144922072

Epoch: 6| Step: 8
Training loss: 3.0340185165405273
Validation loss: 2.4116426180767756

Epoch: 6| Step: 9
Training loss: 3.1445884704589844
Validation loss: 2.4099039877614667

Epoch: 6| Step: 10
Training loss: 2.0954856872558594
Validation loss: 2.4015605449676514

Epoch: 6| Step: 11
Training loss: 2.8647704124450684
Validation loss: 2.3956524120864047

Epoch: 6| Step: 12
Training loss: 2.16619610786438
Validation loss: 2.3916940458359255

Epoch: 6| Step: 13
Training loss: 2.9180688858032227
Validation loss: 2.3969786372236026

Epoch: 92| Step: 0
Training loss: 2.6525630950927734
Validation loss: 2.392807037599625

Epoch: 6| Step: 1
Training loss: 2.3109822273254395
Validation loss: 2.396890232639928

Epoch: 6| Step: 2
Training loss: 3.014036178588867
Validation loss: 2.3948470546353247

Epoch: 6| Step: 3
Training loss: 2.719721555709839
Validation loss: 2.390933131658903

Epoch: 6| Step: 4
Training loss: 2.725322723388672
Validation loss: 2.392723973079394

Epoch: 6| Step: 5
Training loss: 2.222647190093994
Validation loss: 2.387637738258608

Epoch: 6| Step: 6
Training loss: 2.8802480697631836
Validation loss: 2.389499589961062

Epoch: 6| Step: 7
Training loss: 2.7214956283569336
Validation loss: 2.3892241139565744

Epoch: 6| Step: 8
Training loss: 2.9441699981689453
Validation loss: 2.401215640447473

Epoch: 6| Step: 9
Training loss: 3.0503249168395996
Validation loss: 2.4075581232706704

Epoch: 6| Step: 10
Training loss: 2.408163547515869
Validation loss: 2.415357202611944

Epoch: 6| Step: 11
Training loss: 2.0769903659820557
Validation loss: 2.4163135379873295

Epoch: 6| Step: 12
Training loss: 2.3435232639312744
Validation loss: 2.4156536389422674

Epoch: 6| Step: 13
Training loss: 2.477400541305542
Validation loss: 2.3971674980655795

Epoch: 93| Step: 0
Training loss: 3.005089282989502
Validation loss: 2.3967547262868574

Epoch: 6| Step: 1
Training loss: 2.5936083793640137
Validation loss: 2.4032134035582184

Epoch: 6| Step: 2
Training loss: 3.0337934494018555
Validation loss: 2.409334921067761

Epoch: 6| Step: 3
Training loss: 2.8798089027404785
Validation loss: 2.399450840488557

Epoch: 6| Step: 4
Training loss: 2.8081798553466797
Validation loss: 2.3950415913776686

Epoch: 6| Step: 5
Training loss: 2.2684884071350098
Validation loss: 2.394710817644673

Epoch: 6| Step: 6
Training loss: 2.487483263015747
Validation loss: 2.402183776260704

Epoch: 6| Step: 7
Training loss: 2.8142101764678955
Validation loss: 2.38677728304299

Epoch: 6| Step: 8
Training loss: 2.207606077194214
Validation loss: 2.3842816532299085

Epoch: 6| Step: 9
Training loss: 2.558271884918213
Validation loss: 2.384181025207684

Epoch: 6| Step: 10
Training loss: 2.900761842727661
Validation loss: 2.3805216461099605

Epoch: 6| Step: 11
Training loss: 2.257336378097534
Validation loss: 2.380946499045177

Epoch: 6| Step: 12
Training loss: 2.466892719268799
Validation loss: 2.3850725235477572

Epoch: 6| Step: 13
Training loss: 2.286194324493408
Validation loss: 2.383204798544607

Epoch: 94| Step: 0
Training loss: 1.6922309398651123
Validation loss: 2.3926363786061606

Epoch: 6| Step: 1
Training loss: 3.1890010833740234
Validation loss: 2.3979666156153523

Epoch: 6| Step: 2
Training loss: 2.775618553161621
Validation loss: 2.4004634734122985

Epoch: 6| Step: 3
Training loss: 2.9539899826049805
Validation loss: 2.4034824678974767

Epoch: 6| Step: 4
Training loss: 2.985762596130371
Validation loss: 2.391823809633973

Epoch: 6| Step: 5
Training loss: 2.083366870880127
Validation loss: 2.387679893483398

Epoch: 6| Step: 6
Training loss: 3.158564805984497
Validation loss: 2.387915021629744

Epoch: 6| Step: 7
Training loss: 2.4571995735168457
Validation loss: 2.3905910471434235

Epoch: 6| Step: 8
Training loss: 2.203082323074341
Validation loss: 2.3845219663394395

Epoch: 6| Step: 9
Training loss: 2.2238566875457764
Validation loss: 2.3855202198028564

Epoch: 6| Step: 10
Training loss: 3.158134937286377
Validation loss: 2.388434911286959

Epoch: 6| Step: 11
Training loss: 2.707158088684082
Validation loss: 2.389214164467268

Epoch: 6| Step: 12
Training loss: 2.226407527923584
Validation loss: 2.3894044763298443

Epoch: 6| Step: 13
Training loss: 3.061856269836426
Validation loss: 2.3927943527057605

Epoch: 95| Step: 0
Training loss: 2.8261072635650635
Validation loss: 2.393813007621355

Epoch: 6| Step: 1
Training loss: 2.7080516815185547
Validation loss: 2.3936576715079685

Epoch: 6| Step: 2
Training loss: 2.9711074829101562
Validation loss: 2.3917808455805623

Epoch: 6| Step: 3
Training loss: 2.3819878101348877
Validation loss: 2.402252403638696

Epoch: 6| Step: 4
Training loss: 2.143630266189575
Validation loss: 2.3923226146287817

Epoch: 6| Step: 5
Training loss: 1.8943382501602173
Validation loss: 2.388495091469057

Epoch: 6| Step: 6
Training loss: 2.849390745162964
Validation loss: 2.3901836820828017

Epoch: 6| Step: 7
Training loss: 2.9269180297851562
Validation loss: 2.3876664997428976

Epoch: 6| Step: 8
Training loss: 2.616848945617676
Validation loss: 2.3776736644006546

Epoch: 6| Step: 9
Training loss: 2.9145078659057617
Validation loss: 2.378004176642305

Epoch: 6| Step: 10
Training loss: 2.3931150436401367
Validation loss: 2.376763778348123

Epoch: 6| Step: 11
Training loss: 2.3802318572998047
Validation loss: 2.3756402282304663

Epoch: 6| Step: 12
Training loss: 3.4910106658935547
Validation loss: 2.381392648143153

Epoch: 6| Step: 13
Training loss: 1.7862120866775513
Validation loss: 2.3820063939658542

Epoch: 96| Step: 0
Training loss: 2.3192806243896484
Validation loss: 2.380767742792765

Epoch: 6| Step: 1
Training loss: 2.5701403617858887
Validation loss: 2.3942568199608916

Epoch: 6| Step: 2
Training loss: 2.681123733520508
Validation loss: 2.3902474116253596

Epoch: 6| Step: 3
Training loss: 2.495323896408081
Validation loss: 2.3961111781417683

Epoch: 6| Step: 4
Training loss: 2.3030457496643066
Validation loss: 2.4055694226295716

Epoch: 6| Step: 5
Training loss: 2.5917234420776367
Validation loss: 2.400982592695503

Epoch: 6| Step: 6
Training loss: 2.0483815670013428
Validation loss: 2.407684805572674

Epoch: 6| Step: 7
Training loss: 3.5775580406188965
Validation loss: 2.3993993010572208

Epoch: 6| Step: 8
Training loss: 2.883925199508667
Validation loss: 2.410476694824875

Epoch: 6| Step: 9
Training loss: 2.769920825958252
Validation loss: 2.398632364888345

Epoch: 6| Step: 10
Training loss: 1.963883876800537
Validation loss: 2.4046621886632775

Epoch: 6| Step: 11
Training loss: 3.0716300010681152
Validation loss: 2.3976586275203253

Epoch: 6| Step: 12
Training loss: 2.49599289894104
Validation loss: 2.399084550078197

Epoch: 6| Step: 13
Training loss: 2.8318512439727783
Validation loss: 2.3959082531672653

Epoch: 97| Step: 0
Training loss: 2.8696608543395996
Validation loss: 2.3915586830467306

Epoch: 6| Step: 1
Training loss: 2.700653553009033
Validation loss: 2.3888273726227465

Epoch: 6| Step: 2
Training loss: 2.8861563205718994
Validation loss: 2.3802406018780125

Epoch: 6| Step: 3
Training loss: 2.6839523315429688
Validation loss: 2.384070498968965

Epoch: 6| Step: 4
Training loss: 2.3029587268829346
Validation loss: 2.384849984158752

Epoch: 6| Step: 5
Training loss: 2.2133874893188477
Validation loss: 2.3954505869137344

Epoch: 6| Step: 6
Training loss: 2.404694080352783
Validation loss: 2.406007489850444

Epoch: 6| Step: 7
Training loss: 2.3030338287353516
Validation loss: 2.390396423237298

Epoch: 6| Step: 8
Training loss: 2.1114134788513184
Validation loss: 2.410707632700602

Epoch: 6| Step: 9
Training loss: 1.9522463083267212
Validation loss: 2.411358238548361

Epoch: 6| Step: 10
Training loss: 2.4380617141723633
Validation loss: 2.4136953584609495

Epoch: 6| Step: 11
Training loss: 2.5933785438537598
Validation loss: 2.405575221584689

Epoch: 6| Step: 12
Training loss: 3.700542449951172
Validation loss: 2.399883790682721

Epoch: 6| Step: 13
Training loss: 3.72609281539917
Validation loss: 2.3988961250551286

Epoch: 98| Step: 0
Training loss: 2.9160757064819336
Validation loss: 2.399043304945833

Epoch: 6| Step: 1
Training loss: 2.326988697052002
Validation loss: 2.3915870753667687

Epoch: 6| Step: 2
Training loss: 2.4940905570983887
Validation loss: 2.4029993831470446

Epoch: 6| Step: 3
Training loss: 2.646308422088623
Validation loss: 2.408448911482288

Epoch: 6| Step: 4
Training loss: 2.5586133003234863
Validation loss: 2.418890545445104

Epoch: 6| Step: 5
Training loss: 2.8582353591918945
Validation loss: 2.4188292641793527

Epoch: 6| Step: 6
Training loss: 3.123218297958374
Validation loss: 2.413704505530737

Epoch: 6| Step: 7
Training loss: 3.0306010246276855
Validation loss: 2.4173583856192966

Epoch: 6| Step: 8
Training loss: 2.826939105987549
Validation loss: 2.419967105311732

Epoch: 6| Step: 9
Training loss: 2.395815849304199
Validation loss: 2.4146352480816584

Epoch: 6| Step: 10
Training loss: 2.2505545616149902
Validation loss: 2.3996061612200994

Epoch: 6| Step: 11
Training loss: 2.6702730655670166
Validation loss: 2.392425262799827

Epoch: 6| Step: 12
Training loss: 1.8406786918640137
Validation loss: 2.3924669373419976

Epoch: 6| Step: 13
Training loss: 2.51412296295166
Validation loss: 2.391705607855192

Epoch: 99| Step: 0
Training loss: 2.517982006072998
Validation loss: 2.3928201454941944

Epoch: 6| Step: 1
Training loss: 1.6186633110046387
Validation loss: 2.405360608972529

Epoch: 6| Step: 2
Training loss: 2.14497971534729
Validation loss: 2.4093837686764297

Epoch: 6| Step: 3
Training loss: 2.735274314880371
Validation loss: 2.393848375607562

Epoch: 6| Step: 4
Training loss: 3.3859267234802246
Validation loss: 2.398201906552879

Epoch: 6| Step: 5
Training loss: 2.171527147293091
Validation loss: 2.383567112748341

Epoch: 6| Step: 6
Training loss: 2.950690269470215
Validation loss: 2.3868091875506985

Epoch: 6| Step: 7
Training loss: 2.1109275817871094
Validation loss: 2.4048644637548797

Epoch: 6| Step: 8
Training loss: 2.6389260292053223
Validation loss: 2.3973278768600954

Epoch: 6| Step: 9
Training loss: 2.285170078277588
Validation loss: 2.3902009969116538

Epoch: 6| Step: 10
Training loss: 3.3235414028167725
Validation loss: 2.3999130161859656

Epoch: 6| Step: 11
Training loss: 3.011898994445801
Validation loss: 2.3832940696388163

Epoch: 6| Step: 12
Training loss: 2.8988146781921387
Validation loss: 2.3767553708886586

Epoch: 6| Step: 13
Training loss: 2.465611457824707
Validation loss: 2.385378324857322

Epoch: 100| Step: 0
Training loss: 2.433706760406494
Validation loss: 2.377283121949883

Epoch: 6| Step: 1
Training loss: 2.223517417907715
Validation loss: 2.378210654822729

Epoch: 6| Step: 2
Training loss: 2.8583879470825195
Validation loss: 2.363584472287086

Epoch: 6| Step: 3
Training loss: 2.6801061630249023
Validation loss: 2.3667697714221094

Epoch: 6| Step: 4
Training loss: 3.4343769550323486
Validation loss: 2.3722641391138874

Epoch: 6| Step: 5
Training loss: 2.703958511352539
Validation loss: 2.378756405204855

Epoch: 6| Step: 6
Training loss: 2.9209461212158203
Validation loss: 2.3849044102494434

Epoch: 6| Step: 7
Training loss: 1.7240875959396362
Validation loss: 2.3925455642002884

Epoch: 6| Step: 8
Training loss: 2.5271286964416504
Validation loss: 2.3867949926725

Epoch: 6| Step: 9
Training loss: 2.546900510787964
Validation loss: 2.394575639437604

Epoch: 6| Step: 10
Training loss: 1.7580457925796509
Validation loss: 2.392926077688894

Epoch: 6| Step: 11
Training loss: 2.5747127532958984
Validation loss: 2.3886051972707114

Epoch: 6| Step: 12
Training loss: 3.178105115890503
Validation loss: 2.403954040619635

Epoch: 6| Step: 13
Training loss: 3.1387736797332764
Validation loss: 2.408022303735056

Epoch: 101| Step: 0
Training loss: 2.1705739498138428
Validation loss: 2.4047876686178227

Epoch: 6| Step: 1
Training loss: 3.070220470428467
Validation loss: 2.416788528042455

Epoch: 6| Step: 2
Training loss: 2.8508222103118896
Validation loss: 2.40251999773005

Epoch: 6| Step: 3
Training loss: 2.6961357593536377
Validation loss: 2.413244673000869

Epoch: 6| Step: 4
Training loss: 2.6834001541137695
Validation loss: 2.3972720894762265

Epoch: 6| Step: 5
Training loss: 2.3536670207977295
Validation loss: 2.3923555240836194

Epoch: 6| Step: 6
Training loss: 3.086775779724121
Validation loss: 2.387044204178677

Epoch: 6| Step: 7
Training loss: 2.680795192718506
Validation loss: 2.380259444636683

Epoch: 6| Step: 8
Training loss: 1.7673468589782715
Validation loss: 2.385420624927808

Epoch: 6| Step: 9
Training loss: 2.521461009979248
Validation loss: 2.382904247571063

Epoch: 6| Step: 10
Training loss: 3.0081229209899902
Validation loss: 2.3885333076600106

Epoch: 6| Step: 11
Training loss: 3.144529104232788
Validation loss: 2.390050595806491

Epoch: 6| Step: 12
Training loss: 1.6420252323150635
Validation loss: 2.390746367874966

Epoch: 6| Step: 13
Training loss: 2.9190759658813477
Validation loss: 2.3941373927618868

Epoch: 102| Step: 0
Training loss: 2.2062904834747314
Validation loss: 2.3847396950567923

Epoch: 6| Step: 1
Training loss: 2.1458935737609863
Validation loss: 2.3710108931346605

Epoch: 6| Step: 2
Training loss: 2.7186501026153564
Validation loss: 2.367764262742894

Epoch: 6| Step: 3
Training loss: 2.7789506912231445
Validation loss: 2.3685559764985116

Epoch: 6| Step: 4
Training loss: 2.2182531356811523
Validation loss: 2.3672201377089306

Epoch: 6| Step: 5
Training loss: 2.519615650177002
Validation loss: 2.391509855947187

Epoch: 6| Step: 6
Training loss: 2.502033233642578
Validation loss: 2.4025565808819187

Epoch: 6| Step: 7
Training loss: 3.1181540489196777
Validation loss: 2.4164523950187107

Epoch: 6| Step: 8
Training loss: 2.5613558292388916
Validation loss: 2.4015087312267673

Epoch: 6| Step: 9
Training loss: 3.034393072128296
Validation loss: 2.4050180732562976

Epoch: 6| Step: 10
Training loss: 2.4033894538879395
Validation loss: 2.3932016818754134

Epoch: 6| Step: 11
Training loss: 3.1702046394348145
Validation loss: 2.384723178801998

Epoch: 6| Step: 12
Training loss: 2.6770825386047363
Validation loss: 2.3897587432656238

Epoch: 6| Step: 13
Training loss: 2.478158712387085
Validation loss: 2.3858411619740147

Epoch: 103| Step: 0
Training loss: 2.191344738006592
Validation loss: 2.390740727865568

Epoch: 6| Step: 1
Training loss: 3.4999492168426514
Validation loss: 2.381672095226985

Epoch: 6| Step: 2
Training loss: 2.07814621925354
Validation loss: 2.36685013258329

Epoch: 6| Step: 3
Training loss: 2.7582788467407227
Validation loss: 2.3796818538378646

Epoch: 6| Step: 4
Training loss: 1.69026780128479
Validation loss: 2.3845486820385022

Epoch: 6| Step: 5
Training loss: 2.41487193107605
Validation loss: 2.3897226266963507

Epoch: 6| Step: 6
Training loss: 3.408257484436035
Validation loss: 2.398387865353656

Epoch: 6| Step: 7
Training loss: 2.45367169380188
Validation loss: 2.4007786576465895

Epoch: 6| Step: 8
Training loss: 3.0838558673858643
Validation loss: 2.394309589939733

Epoch: 6| Step: 9
Training loss: 2.9574060440063477
Validation loss: 2.387840409432688

Epoch: 6| Step: 10
Training loss: 2.3767144680023193
Validation loss: 2.380378255280115

Epoch: 6| Step: 11
Training loss: 2.287191390991211
Validation loss: 2.3710269774160078

Epoch: 6| Step: 12
Training loss: 2.390442371368408
Validation loss: 2.3730387098045758

Epoch: 6| Step: 13
Training loss: 3.062101364135742
Validation loss: 2.3709872768771265

Epoch: 104| Step: 0
Training loss: 2.6339311599731445
Validation loss: 2.3650873168822257

Epoch: 6| Step: 1
Training loss: 2.3971095085144043
Validation loss: 2.3727111918951875

Epoch: 6| Step: 2
Training loss: 2.997197151184082
Validation loss: 2.3674869691171954

Epoch: 6| Step: 3
Training loss: 2.97580623626709
Validation loss: 2.3715738224726852

Epoch: 6| Step: 4
Training loss: 3.0365896224975586
Validation loss: 2.380626347757155

Epoch: 6| Step: 5
Training loss: 2.390453815460205
Validation loss: 2.372783609615859

Epoch: 6| Step: 6
Training loss: 2.7904882431030273
Validation loss: 2.3802141194702475

Epoch: 6| Step: 7
Training loss: 1.767501711845398
Validation loss: 2.388350849510521

Epoch: 6| Step: 8
Training loss: 2.26476788520813
Validation loss: 2.389781766040351

Epoch: 6| Step: 9
Training loss: 3.147080421447754
Validation loss: 2.3861173122159895

Epoch: 6| Step: 10
Training loss: 2.792968273162842
Validation loss: 2.3849849111290387

Epoch: 6| Step: 11
Training loss: 2.0736021995544434
Validation loss: 2.385904883825651

Epoch: 6| Step: 12
Training loss: 2.543731451034546
Validation loss: 2.3890957178608065

Epoch: 6| Step: 13
Training loss: 2.8021109104156494
Validation loss: 2.3844185836853518

Epoch: 105| Step: 0
Training loss: 2.465888500213623
Validation loss: 2.3812171489961687

Epoch: 6| Step: 1
Training loss: 1.9012582302093506
Validation loss: 2.3920098658530944

Epoch: 6| Step: 2
Training loss: 2.4157204627990723
Validation loss: 2.3877663868729786

Epoch: 6| Step: 3
Training loss: 2.8612570762634277
Validation loss: 2.398200527314217

Epoch: 6| Step: 4
Training loss: 3.042013645172119
Validation loss: 2.394321233995499

Epoch: 6| Step: 5
Training loss: 2.252340078353882
Validation loss: 2.41063658396403

Epoch: 6| Step: 6
Training loss: 1.850603699684143
Validation loss: 2.407943146203154

Epoch: 6| Step: 7
Training loss: 2.7386372089385986
Validation loss: 2.4107897320101337

Epoch: 6| Step: 8
Training loss: 2.811006784439087
Validation loss: 2.4005813047450077

Epoch: 6| Step: 9
Training loss: 3.2763984203338623
Validation loss: 2.39081451969762

Epoch: 6| Step: 10
Training loss: 2.60494327545166
Validation loss: 2.3939077469610397

Epoch: 6| Step: 11
Training loss: 2.444873332977295
Validation loss: 2.3783043046151437

Epoch: 6| Step: 12
Training loss: 3.243256092071533
Validation loss: 2.3834733963012695

Epoch: 6| Step: 13
Training loss: 2.5209248065948486
Validation loss: 2.395131634127709

Epoch: 106| Step: 0
Training loss: 2.5135746002197266
Validation loss: 2.3740904408116497

Epoch: 6| Step: 1
Training loss: 2.506848096847534
Validation loss: 2.371077834918935

Epoch: 6| Step: 2
Training loss: 2.9864606857299805
Validation loss: 2.361978312974335

Epoch: 6| Step: 3
Training loss: 2.721848726272583
Validation loss: 2.3653595793631768

Epoch: 6| Step: 4
Training loss: 2.732820987701416
Validation loss: 2.360754051516133

Epoch: 6| Step: 5
Training loss: 2.6383309364318848
Validation loss: 2.3609370211119294

Epoch: 6| Step: 6
Training loss: 2.041539430618286
Validation loss: 2.3570928317244335

Epoch: 6| Step: 7
Training loss: 2.692542552947998
Validation loss: 2.360498771872572

Epoch: 6| Step: 8
Training loss: 2.6451008319854736
Validation loss: 2.3602928423112437

Epoch: 6| Step: 9
Training loss: 3.1815671920776367
Validation loss: 2.363538252410068

Epoch: 6| Step: 10
Training loss: 2.6707828044891357
Validation loss: 2.3572342293236845

Epoch: 6| Step: 11
Training loss: 1.8533917665481567
Validation loss: 2.354898847559447

Epoch: 6| Step: 12
Training loss: 2.6847922801971436
Validation loss: 2.3581036393360426

Epoch: 6| Step: 13
Training loss: 2.5427842140197754
Validation loss: 2.3646259205315703

Epoch: 107| Step: 0
Training loss: 2.5445504188537598
Validation loss: 2.3649715659438924

Epoch: 6| Step: 1
Training loss: 2.7565665245056152
Validation loss: 2.353319037345148

Epoch: 6| Step: 2
Training loss: 2.175910711288452
Validation loss: 2.3520982932018977

Epoch: 6| Step: 3
Training loss: 2.1411588191986084
Validation loss: 2.3517619691869265

Epoch: 6| Step: 4
Training loss: 3.1527276039123535
Validation loss: 2.3612913444478023

Epoch: 6| Step: 5
Training loss: 2.9074034690856934
Validation loss: 2.3626710471286567

Epoch: 6| Step: 6
Training loss: 2.65281343460083
Validation loss: 2.363365296394594

Epoch: 6| Step: 7
Training loss: 3.045759677886963
Validation loss: 2.37023595071608

Epoch: 6| Step: 8
Training loss: 2.3124265670776367
Validation loss: 2.3669435849753757

Epoch: 6| Step: 9
Training loss: 2.544856548309326
Validation loss: 2.371726910273234

Epoch: 6| Step: 10
Training loss: 2.291032314300537
Validation loss: 2.367142908034786

Epoch: 6| Step: 11
Training loss: 3.084994316101074
Validation loss: 2.359077121621819

Epoch: 6| Step: 12
Training loss: 2.367673873901367
Validation loss: 2.367311167460616

Epoch: 6| Step: 13
Training loss: 2.473302125930786
Validation loss: 2.3523911532535347

Epoch: 108| Step: 0
Training loss: 2.089918613433838
Validation loss: 2.356061643169772

Epoch: 6| Step: 1
Training loss: 2.1815333366394043
Validation loss: 2.362103300709878

Epoch: 6| Step: 2
Training loss: 3.1406021118164062
Validation loss: 2.3646853098305325

Epoch: 6| Step: 3
Training loss: 3.283573865890503
Validation loss: 2.361263467419532

Epoch: 6| Step: 4
Training loss: 2.853376865386963
Validation loss: 2.3675915118186706

Epoch: 6| Step: 5
Training loss: 2.50462007522583
Validation loss: 2.3703210866579445

Epoch: 6| Step: 6
Training loss: 2.2399423122406006
Validation loss: 2.3876123671890586

Epoch: 6| Step: 7
Training loss: 2.3595728874206543
Validation loss: 2.38867857122934

Epoch: 6| Step: 8
Training loss: 2.629063129425049
Validation loss: 2.3755807312585975

Epoch: 6| Step: 9
Training loss: 2.552922248840332
Validation loss: 2.371180372853433

Epoch: 6| Step: 10
Training loss: 3.7068264484405518
Validation loss: 2.3620454624135006

Epoch: 6| Step: 11
Training loss: 1.9896762371063232
Validation loss: 2.359924119005921

Epoch: 6| Step: 12
Training loss: 2.0960960388183594
Validation loss: 2.365435000388853

Epoch: 6| Step: 13
Training loss: 3.001908302307129
Validation loss: 2.3606393901250695

Epoch: 109| Step: 0
Training loss: 2.634373426437378
Validation loss: 2.355822273479995

Epoch: 6| Step: 1
Training loss: 3.2879912853240967
Validation loss: 2.3562078629770586

Epoch: 6| Step: 2
Training loss: 2.683201789855957
Validation loss: 2.357977699208003

Epoch: 6| Step: 3
Training loss: 1.9815788269042969
Validation loss: 2.355662352295332

Epoch: 6| Step: 4
Training loss: 2.1204729080200195
Validation loss: 2.3590719123040476

Epoch: 6| Step: 5
Training loss: 3.314640998840332
Validation loss: 2.3609552357786443

Epoch: 6| Step: 6
Training loss: 1.9178987741470337
Validation loss: 2.3591652429232033

Epoch: 6| Step: 7
Training loss: 2.246387481689453
Validation loss: 2.3577654361724854

Epoch: 6| Step: 8
Training loss: 1.8646174669265747
Validation loss: 2.3728973480962936

Epoch: 6| Step: 9
Training loss: 3.1483817100524902
Validation loss: 2.3679277871244695

Epoch: 6| Step: 10
Training loss: 2.9418833255767822
Validation loss: 2.3744953781045894

Epoch: 6| Step: 11
Training loss: 2.782747268676758
Validation loss: 2.3817951627956924

Epoch: 6| Step: 12
Training loss: 2.6784634590148926
Validation loss: 2.383631467819214

Epoch: 6| Step: 13
Training loss: 2.759049892425537
Validation loss: 2.383695407580304

Epoch: 110| Step: 0
Training loss: 2.357090950012207
Validation loss: 2.401537328638056

Epoch: 6| Step: 1
Training loss: 2.34930682182312
Validation loss: 2.4016956026836107

Epoch: 6| Step: 2
Training loss: 3.071197986602783
Validation loss: 2.420019554835494

Epoch: 6| Step: 3
Training loss: 3.1493430137634277
Validation loss: 2.4334206991298224

Epoch: 6| Step: 4
Training loss: 2.1760923862457275
Validation loss: 2.4316996092437417

Epoch: 6| Step: 5
Training loss: 3.137078285217285
Validation loss: 2.424154027815788

Epoch: 6| Step: 6
Training loss: 2.54203724861145
Validation loss: 2.4117101366801927

Epoch: 6| Step: 7
Training loss: 2.6062560081481934
Validation loss: 2.386071228211926

Epoch: 6| Step: 8
Training loss: 2.546917676925659
Validation loss: 2.3841982323636293

Epoch: 6| Step: 9
Training loss: 2.657417058944702
Validation loss: 2.3703373683396207

Epoch: 6| Step: 10
Training loss: 1.7730791568756104
Validation loss: 2.3603412207736763

Epoch: 6| Step: 11
Training loss: 2.9512765407562256
Validation loss: 2.3695869573982815

Epoch: 6| Step: 12
Training loss: 2.2680187225341797
Validation loss: 2.3616533510146605

Epoch: 6| Step: 13
Training loss: 2.8203823566436768
Validation loss: 2.366002141788442

Epoch: 111| Step: 0
Training loss: 2.3964219093322754
Validation loss: 2.365060956247391

Epoch: 6| Step: 1
Training loss: 3.1861534118652344
Validation loss: 2.3625085097487255

Epoch: 6| Step: 2
Training loss: 2.6993277072906494
Validation loss: 2.367074695966577

Epoch: 6| Step: 3
Training loss: 2.6121604442596436
Validation loss: 2.376703808384557

Epoch: 6| Step: 4
Training loss: 2.440429210662842
Validation loss: 2.370670085312218

Epoch: 6| Step: 5
Training loss: 2.4533896446228027
Validation loss: 2.3835809640986945

Epoch: 6| Step: 6
Training loss: 2.7047042846679688
Validation loss: 2.3728394533998225

Epoch: 6| Step: 7
Training loss: 1.871096134185791
Validation loss: 2.372330586115519

Epoch: 6| Step: 8
Training loss: 2.963322162628174
Validation loss: 2.3714149921171126

Epoch: 6| Step: 9
Training loss: 2.6265761852264404
Validation loss: 2.3680489755445913

Epoch: 6| Step: 10
Training loss: 2.8069846630096436
Validation loss: 2.3668245756497948

Epoch: 6| Step: 11
Training loss: 2.502462387084961
Validation loss: 2.3609948850447133

Epoch: 6| Step: 12
Training loss: 2.568903923034668
Validation loss: 2.3736874954674834

Epoch: 6| Step: 13
Training loss: 2.2762973308563232
Validation loss: 2.3731924564607683

Epoch: 112| Step: 0
Training loss: 3.4379358291625977
Validation loss: 2.372741089072279

Epoch: 6| Step: 1
Training loss: 2.473593235015869
Validation loss: 2.3660622450613205

Epoch: 6| Step: 2
Training loss: 3.211207628250122
Validation loss: 2.3555648506328626

Epoch: 6| Step: 3
Training loss: 1.9774739742279053
Validation loss: 2.3584011549590738

Epoch: 6| Step: 4
Training loss: 2.216585636138916
Validation loss: 2.3651208416108163

Epoch: 6| Step: 5
Training loss: 2.2148630619049072
Validation loss: 2.3698396016192693

Epoch: 6| Step: 6
Training loss: 2.5003368854522705
Validation loss: 2.369340988897508

Epoch: 6| Step: 7
Training loss: 2.270897388458252
Validation loss: 2.378683784956573

Epoch: 6| Step: 8
Training loss: 2.6726112365722656
Validation loss: 2.385196647336406

Epoch: 6| Step: 9
Training loss: 2.3573813438415527
Validation loss: 2.383393015912784

Epoch: 6| Step: 10
Training loss: 2.5506887435913086
Validation loss: 2.3803168945415045

Epoch: 6| Step: 11
Training loss: 2.5529086589813232
Validation loss: 2.40292981747658

Epoch: 6| Step: 12
Training loss: 3.1205344200134277
Validation loss: 2.4161179040067937

Epoch: 6| Step: 13
Training loss: 2.578399658203125
Validation loss: 2.399884282901723

Epoch: 113| Step: 0
Training loss: 2.6481072902679443
Validation loss: 2.40535315134192

Epoch: 6| Step: 1
Training loss: 2.332747459411621
Validation loss: 2.3943640634577763

Epoch: 6| Step: 2
Training loss: 2.4634740352630615
Validation loss: 2.383961726260442

Epoch: 6| Step: 3
Training loss: 3.0985426902770996
Validation loss: 2.389983662994959

Epoch: 6| Step: 4
Training loss: 2.9577178955078125
Validation loss: 2.3681570945247525

Epoch: 6| Step: 5
Training loss: 2.859623432159424
Validation loss: 2.3728842094380367

Epoch: 6| Step: 6
Training loss: 2.792630672454834
Validation loss: 2.37377490023131

Epoch: 6| Step: 7
Training loss: 2.195253849029541
Validation loss: 2.372242263568345

Epoch: 6| Step: 8
Training loss: 2.1929097175598145
Validation loss: 2.359468198591663

Epoch: 6| Step: 9
Training loss: 2.7134368419647217
Validation loss: 2.3591247015101935

Epoch: 6| Step: 10
Training loss: 2.555222511291504
Validation loss: 2.34873321876731

Epoch: 6| Step: 11
Training loss: 2.374372959136963
Validation loss: 2.3530627809545046

Epoch: 6| Step: 12
Training loss: 2.411567211151123
Validation loss: 2.3547001602829143

Epoch: 6| Step: 13
Training loss: 2.6413753032684326
Validation loss: 2.3600196351287184

Epoch: 114| Step: 0
Training loss: 3.070885181427002
Validation loss: 2.3688911596934

Epoch: 6| Step: 1
Training loss: 3.0704705715179443
Validation loss: 2.3718775600515385

Epoch: 6| Step: 2
Training loss: 1.8138500452041626
Validation loss: 2.3814568878501974

Epoch: 6| Step: 3
Training loss: 3.2552733421325684
Validation loss: 2.3743988467801

Epoch: 6| Step: 4
Training loss: 2.2740726470947266
Validation loss: 2.3802471647980394

Epoch: 6| Step: 5
Training loss: 2.5985751152038574
Validation loss: 2.3805230304759037

Epoch: 6| Step: 6
Training loss: 2.4731881618499756
Validation loss: 2.385642538788498

Epoch: 6| Step: 7
Training loss: 2.4963245391845703
Validation loss: 2.3844559295203096

Epoch: 6| Step: 8
Training loss: 2.3394336700439453
Validation loss: 2.3900621219347884

Epoch: 6| Step: 9
Training loss: 2.9995877742767334
Validation loss: 2.384171324391519

Epoch: 6| Step: 10
Training loss: 2.6943411827087402
Validation loss: 2.392396814079695

Epoch: 6| Step: 11
Training loss: 1.9363876581192017
Validation loss: 2.4044516624942904

Epoch: 6| Step: 12
Training loss: 2.495657205581665
Validation loss: 2.395048984917261

Epoch: 6| Step: 13
Training loss: 2.6853842735290527
Validation loss: 2.390573263168335

Epoch: 115| Step: 0
Training loss: 2.4270620346069336
Validation loss: 2.384272094695799

Epoch: 6| Step: 1
Training loss: 3.058867931365967
Validation loss: 2.3731382918614212

Epoch: 6| Step: 2
Training loss: 2.3472726345062256
Validation loss: 2.3703255550835722

Epoch: 6| Step: 3
Training loss: 2.632556200027466
Validation loss: 2.3632451103579615

Epoch: 6| Step: 4
Training loss: 2.53525972366333
Validation loss: 2.3574517132133566

Epoch: 6| Step: 5
Training loss: 2.588125228881836
Validation loss: 2.360045617626559

Epoch: 6| Step: 6
Training loss: 3.4763071537017822
Validation loss: 2.3604378802801973

Epoch: 6| Step: 7
Training loss: 2.6892049312591553
Validation loss: 2.34935579505018

Epoch: 6| Step: 8
Training loss: 2.286163091659546
Validation loss: 2.3567748121035996

Epoch: 6| Step: 9
Training loss: 2.341085433959961
Validation loss: 2.3669781428511425

Epoch: 6| Step: 10
Training loss: 2.7182674407958984
Validation loss: 2.3904655364251908

Epoch: 6| Step: 11
Training loss: 2.2545149326324463
Validation loss: 2.4013802979582097

Epoch: 6| Step: 12
Training loss: 2.2285735607147217
Validation loss: 2.405074360550091

Epoch: 6| Step: 13
Training loss: 2.5384373664855957
Validation loss: 2.4152606033509776

Epoch: 116| Step: 0
Training loss: 2.67348575592041
Validation loss: 2.4111159232354935

Epoch: 6| Step: 1
Training loss: 2.649751663208008
Validation loss: 2.3992279588535266

Epoch: 6| Step: 2
Training loss: 2.4738235473632812
Validation loss: 2.403083401341592

Epoch: 6| Step: 3
Training loss: 2.783761978149414
Validation loss: 2.383577372438164

Epoch: 6| Step: 4
Training loss: 2.5262374877929688
Validation loss: 2.374789680204084

Epoch: 6| Step: 5
Training loss: 1.889209270477295
Validation loss: 2.3773195282105477

Epoch: 6| Step: 6
Training loss: 2.25553822517395
Validation loss: 2.37076981606022

Epoch: 6| Step: 7
Training loss: 2.3530235290527344
Validation loss: 2.376462700546429

Epoch: 6| Step: 8
Training loss: 3.0658373832702637
Validation loss: 2.3673980748781593

Epoch: 6| Step: 9
Training loss: 2.5929441452026367
Validation loss: 2.3672875422303394

Epoch: 6| Step: 10
Training loss: 3.146244525909424
Validation loss: 2.3765788437217794

Epoch: 6| Step: 11
Training loss: 2.4454073905944824
Validation loss: 2.36938157901969

Epoch: 6| Step: 12
Training loss: 3.5673093795776367
Validation loss: 2.376723784272389

Epoch: 6| Step: 13
Training loss: 0.933727502822876
Validation loss: 2.377413941967872

Epoch: 117| Step: 0
Training loss: 1.8959481716156006
Validation loss: 2.380910619612663

Epoch: 6| Step: 1
Training loss: 2.3666536808013916
Validation loss: 2.393067272760535

Epoch: 6| Step: 2
Training loss: 2.3735525608062744
Validation loss: 2.385164717192291

Epoch: 6| Step: 3
Training loss: 2.4508280754089355
Validation loss: 2.3793899833515124

Epoch: 6| Step: 4
Training loss: 2.051433563232422
Validation loss: 2.382308160105059

Epoch: 6| Step: 5
Training loss: 2.829281806945801
Validation loss: 2.3905963359340543

Epoch: 6| Step: 6
Training loss: 2.8897571563720703
Validation loss: 2.379023862141435

Epoch: 6| Step: 7
Training loss: 3.146641254425049
Validation loss: 2.3796640570445726

Epoch: 6| Step: 8
Training loss: 2.8531439304351807
Validation loss: 2.3883760231797413

Epoch: 6| Step: 9
Training loss: 2.96134614944458
Validation loss: 2.370550012075773

Epoch: 6| Step: 10
Training loss: 2.668428897857666
Validation loss: 2.3670067248805875

Epoch: 6| Step: 11
Training loss: 2.8575081825256348
Validation loss: 2.368374232322939

Epoch: 6| Step: 12
Training loss: 2.259509801864624
Validation loss: 2.3573808952044417

Epoch: 6| Step: 13
Training loss: 2.1698811054229736
Validation loss: 2.35492104612371

Epoch: 118| Step: 0
Training loss: 2.298816204071045
Validation loss: 2.354437597336308

Epoch: 6| Step: 1
Training loss: 2.964989185333252
Validation loss: 2.3470672971458844

Epoch: 6| Step: 2
Training loss: 3.100337266921997
Validation loss: 2.348358169678719

Epoch: 6| Step: 3
Training loss: 3.146341323852539
Validation loss: 2.3475259042555288

Epoch: 6| Step: 4
Training loss: 1.7082526683807373
Validation loss: 2.3650707403818765

Epoch: 6| Step: 5
Training loss: 2.0270256996154785
Validation loss: 2.3585081331191526

Epoch: 6| Step: 6
Training loss: 1.8885353803634644
Validation loss: 2.363684577326621

Epoch: 6| Step: 7
Training loss: 3.055316925048828
Validation loss: 2.359094601805492

Epoch: 6| Step: 8
Training loss: 3.043546676635742
Validation loss: 2.352134022661435

Epoch: 6| Step: 9
Training loss: 2.7426857948303223
Validation loss: 2.3477957223051336

Epoch: 6| Step: 10
Training loss: 3.2829413414001465
Validation loss: 2.350705131407707

Epoch: 6| Step: 11
Training loss: 1.9513872861862183
Validation loss: 2.3475175980598695

Epoch: 6| Step: 12
Training loss: 3.030038833618164
Validation loss: 2.35066512579559

Epoch: 6| Step: 13
Training loss: 1.3323392868041992
Validation loss: 2.3417074552146335

Epoch: 119| Step: 0
Training loss: 3.129549741744995
Validation loss: 2.3392641672524075

Epoch: 6| Step: 1
Training loss: 3.1016452312469482
Validation loss: 2.3368702421906176

Epoch: 6| Step: 2
Training loss: 2.3089847564697266
Validation loss: 2.3446832421005412

Epoch: 6| Step: 3
Training loss: 2.491763114929199
Validation loss: 2.3605364650808354

Epoch: 6| Step: 4
Training loss: 2.015133857727051
Validation loss: 2.3511642461181967

Epoch: 6| Step: 5
Training loss: 2.3230624198913574
Validation loss: 2.366252560769358

Epoch: 6| Step: 6
Training loss: 2.7028510570526123
Validation loss: 2.3689693327872985

Epoch: 6| Step: 7
Training loss: 2.7659125328063965
Validation loss: 2.377480911952193

Epoch: 6| Step: 8
Training loss: 2.335599184036255
Validation loss: 2.3913814226786294

Epoch: 6| Step: 9
Training loss: 2.7678122520446777
Validation loss: 2.380179698749255

Epoch: 6| Step: 10
Training loss: 1.7299916744232178
Validation loss: 2.367700625491399

Epoch: 6| Step: 11
Training loss: 3.3154029846191406
Validation loss: 2.362690107796782

Epoch: 6| Step: 12
Training loss: 3.005215644836426
Validation loss: 2.3552717854899745

Epoch: 6| Step: 13
Training loss: 1.698966145515442
Validation loss: 2.342929965706282

Epoch: 120| Step: 0
Training loss: 2.5320849418640137
Validation loss: 2.347130888251848

Epoch: 6| Step: 1
Training loss: 2.681663990020752
Validation loss: 2.3422279332273748

Epoch: 6| Step: 2
Training loss: 2.0173559188842773
Validation loss: 2.352333817430722

Epoch: 6| Step: 3
Training loss: 2.7121357917785645
Validation loss: 2.3719074597922702

Epoch: 6| Step: 4
Training loss: 3.3020644187927246
Validation loss: 2.3677591431525444

Epoch: 6| Step: 5
Training loss: 2.7064552307128906
Validation loss: 2.3708971008177726

Epoch: 6| Step: 6
Training loss: 2.2147631645202637
Validation loss: 2.362861692264516

Epoch: 6| Step: 7
Training loss: 2.6504106521606445
Validation loss: 2.353600840414724

Epoch: 6| Step: 8
Training loss: 2.4552879333496094
Validation loss: 2.3437054618712394

Epoch: 6| Step: 9
Training loss: 2.4781863689422607
Validation loss: 2.342873893758302

Epoch: 6| Step: 10
Training loss: 2.564512252807617
Validation loss: 2.3432784183050996

Epoch: 6| Step: 11
Training loss: 2.886512041091919
Validation loss: 2.345091430089807

Epoch: 6| Step: 12
Training loss: 2.417837619781494
Validation loss: 2.342917931977139

Epoch: 6| Step: 13
Training loss: 2.4018349647521973
Validation loss: 2.3468978276816745

Epoch: 121| Step: 0
Training loss: 3.0418243408203125
Validation loss: 2.3488922836960002

Epoch: 6| Step: 1
Training loss: 2.037569761276245
Validation loss: 2.3552003496436664

Epoch: 6| Step: 2
Training loss: 2.9160900115966797
Validation loss: 2.3648025720350203

Epoch: 6| Step: 3
Training loss: 1.7452335357666016
Validation loss: 2.3700348664355535

Epoch: 6| Step: 4
Training loss: 2.302588939666748
Validation loss: 2.3818135415354083

Epoch: 6| Step: 5
Training loss: 2.5146665573120117
Validation loss: 2.387813578369797

Epoch: 6| Step: 6
Training loss: 3.4337525367736816
Validation loss: 2.3809738030997654

Epoch: 6| Step: 7
Training loss: 2.403846263885498
Validation loss: 2.3980614613461237

Epoch: 6| Step: 8
Training loss: 2.59611177444458
Validation loss: 2.3972152830452047

Epoch: 6| Step: 9
Training loss: 2.171001434326172
Validation loss: 2.396484209645179

Epoch: 6| Step: 10
Training loss: 3.2751760482788086
Validation loss: 2.3884682027242516

Epoch: 6| Step: 11
Training loss: 2.541388511657715
Validation loss: 2.3917717497835875

Epoch: 6| Step: 12
Training loss: 2.328077793121338
Validation loss: 2.3677069987020185

Epoch: 6| Step: 13
Training loss: 2.7219831943511963
Validation loss: 2.3819241677561114

Epoch: 122| Step: 0
Training loss: 1.9801744222640991
Validation loss: 2.356984830671741

Epoch: 6| Step: 1
Training loss: 2.821357250213623
Validation loss: 2.3468088142333494

Epoch: 6| Step: 2
Training loss: 2.011490821838379
Validation loss: 2.3353247270789197

Epoch: 6| Step: 3
Training loss: 2.572594404220581
Validation loss: 2.3300233605087444

Epoch: 6| Step: 4
Training loss: 1.959015130996704
Validation loss: 2.3255164495078464

Epoch: 6| Step: 5
Training loss: 2.8702259063720703
Validation loss: 2.325818020810363

Epoch: 6| Step: 6
Training loss: 2.9143893718719482
Validation loss: 2.3253873599472867

Epoch: 6| Step: 7
Training loss: 2.9711315631866455
Validation loss: 2.322801484856554

Epoch: 6| Step: 8
Training loss: 2.6673405170440674
Validation loss: 2.3215767901430846

Epoch: 6| Step: 9
Training loss: 2.4868478775024414
Validation loss: 2.3288858398314445

Epoch: 6| Step: 10
Training loss: 2.663099765777588
Validation loss: 2.3401206436977593

Epoch: 6| Step: 11
Training loss: 2.780932903289795
Validation loss: 2.3321327163327124

Epoch: 6| Step: 12
Training loss: 2.6559815406799316
Validation loss: 2.3370602464163177

Epoch: 6| Step: 13
Training loss: 2.8667783737182617
Validation loss: 2.3293107299394507

Epoch: 123| Step: 0
Training loss: 2.3933725357055664
Validation loss: 2.330807429487987

Epoch: 6| Step: 1
Training loss: 1.5567158460617065
Validation loss: 2.330127008499638

Epoch: 6| Step: 2
Training loss: 2.6500463485717773
Validation loss: 2.3255618874744703

Epoch: 6| Step: 3
Training loss: 2.625446081161499
Validation loss: 2.33692563990111

Epoch: 6| Step: 4
Training loss: 3.1980464458465576
Validation loss: 2.336410742934032

Epoch: 6| Step: 5
Training loss: 2.0631802082061768
Validation loss: 2.3303594332869335

Epoch: 6| Step: 6
Training loss: 2.2010445594787598
Validation loss: 2.3364290678372948

Epoch: 6| Step: 7
Training loss: 3.0368409156799316
Validation loss: 2.3342394546795915

Epoch: 6| Step: 8
Training loss: 3.252472400665283
Validation loss: 2.3399688223356843

Epoch: 6| Step: 9
Training loss: 3.1602344512939453
Validation loss: 2.3366061590051137

Epoch: 6| Step: 10
Training loss: 2.6234512329101562
Validation loss: 2.328362951996506

Epoch: 6| Step: 11
Training loss: 1.9247920513153076
Validation loss: 2.3292583573249077

Epoch: 6| Step: 12
Training loss: 2.8899145126342773
Validation loss: 2.3359406225142942

Epoch: 6| Step: 13
Training loss: 2.2658729553222656
Validation loss: 2.3439867086307977

Epoch: 124| Step: 0
Training loss: 2.513237476348877
Validation loss: 2.3457041607108167

Epoch: 6| Step: 1
Training loss: 2.2298359870910645
Validation loss: 2.3581028676802114

Epoch: 6| Step: 2
Training loss: 2.743460178375244
Validation loss: 2.3551436239673245

Epoch: 6| Step: 3
Training loss: 3.0483174324035645
Validation loss: 2.3652967381220993

Epoch: 6| Step: 4
Training loss: 2.9801688194274902
Validation loss: 2.3659425089436192

Epoch: 6| Step: 5
Training loss: 1.9131056070327759
Validation loss: 2.3730057490769254

Epoch: 6| Step: 6
Training loss: 2.674461841583252
Validation loss: 2.364616850371002

Epoch: 6| Step: 7
Training loss: 3.292248249053955
Validation loss: 2.3548802175829486

Epoch: 6| Step: 8
Training loss: 2.451509952545166
Validation loss: 2.342176286123132

Epoch: 6| Step: 9
Training loss: 2.025279998779297
Validation loss: 2.3564323789329937

Epoch: 6| Step: 10
Training loss: 2.580174207687378
Validation loss: 2.358662769358645

Epoch: 6| Step: 11
Training loss: 3.2402503490448
Validation loss: 2.3435010089669177

Epoch: 6| Step: 12
Training loss: 1.9851796627044678
Validation loss: 2.3538231336942284

Epoch: 6| Step: 13
Training loss: 1.9196572303771973
Validation loss: 2.3542933233322634

Epoch: 125| Step: 0
Training loss: 2.7072315216064453
Validation loss: 2.35366839490911

Epoch: 6| Step: 1
Training loss: 3.286912441253662
Validation loss: 2.3478808608106387

Epoch: 6| Step: 2
Training loss: 1.958465337753296
Validation loss: 2.3333399705989386

Epoch: 6| Step: 3
Training loss: 3.228816032409668
Validation loss: 2.3273370958143667

Epoch: 6| Step: 4
Training loss: 2.8549821376800537
Validation loss: 2.324833731497488

Epoch: 6| Step: 5
Training loss: 2.376249313354492
Validation loss: 2.326271444238642

Epoch: 6| Step: 6
Training loss: 2.1108107566833496
Validation loss: 2.325614090888731

Epoch: 6| Step: 7
Training loss: 2.646057367324829
Validation loss: 2.3154942194620767

Epoch: 6| Step: 8
Training loss: 2.671757936477661
Validation loss: 2.314438776303363

Epoch: 6| Step: 9
Training loss: 2.538724899291992
Validation loss: 2.313379615865728

Epoch: 6| Step: 10
Training loss: 2.472813129425049
Validation loss: 2.322041021880283

Epoch: 6| Step: 11
Training loss: 2.0765175819396973
Validation loss: 2.321528478335309

Epoch: 6| Step: 12
Training loss: 2.368429660797119
Validation loss: 2.339543299008441

Epoch: 6| Step: 13
Training loss: 2.573342800140381
Validation loss: 2.3546119159267795

Epoch: 126| Step: 0
Training loss: 2.8646421432495117
Validation loss: 2.361552349982723

Epoch: 6| Step: 1
Training loss: 1.9664640426635742
Validation loss: 2.375959880890385

Epoch: 6| Step: 2
Training loss: 3.299100399017334
Validation loss: 2.3929937603653118

Epoch: 6| Step: 3
Training loss: 2.7435460090637207
Validation loss: 2.4055897369179675

Epoch: 6| Step: 4
Training loss: 2.4650321006774902
Validation loss: 2.4454807568621892

Epoch: 6| Step: 5
Training loss: 2.7279622554779053
Validation loss: 2.4752924826837357

Epoch: 6| Step: 6
Training loss: 1.760905146598816
Validation loss: 2.4881688394854145

Epoch: 6| Step: 7
Training loss: 2.2754063606262207
Validation loss: 2.5072665445266233

Epoch: 6| Step: 8
Training loss: 2.8198153972625732
Validation loss: 2.5047243128540697

Epoch: 6| Step: 9
Training loss: 1.9940170049667358
Validation loss: 2.469800836296492

Epoch: 6| Step: 10
Training loss: 2.795539140701294
Validation loss: 2.4605526180677515

Epoch: 6| Step: 11
Training loss: 3.5398130416870117
Validation loss: 2.4587561212560183

Epoch: 6| Step: 12
Training loss: 2.1004104614257812
Validation loss: 2.4205347184211976

Epoch: 6| Step: 13
Training loss: 3.2874128818511963
Validation loss: 2.383248044598487

Epoch: 127| Step: 0
Training loss: 2.6513776779174805
Validation loss: 2.3841379816814134

Epoch: 6| Step: 1
Training loss: 3.0345685482025146
Validation loss: 2.3698612823281238

Epoch: 6| Step: 2
Training loss: 2.5552420616149902
Validation loss: 2.3661106863329486

Epoch: 6| Step: 3
Training loss: 3.0333712100982666
Validation loss: 2.357118873186009

Epoch: 6| Step: 4
Training loss: 2.7220423221588135
Validation loss: 2.3607674068020237

Epoch: 6| Step: 5
Training loss: 2.4272918701171875
Validation loss: 2.3536898782176356

Epoch: 6| Step: 6
Training loss: 3.005216598510742
Validation loss: 2.3422674517477713

Epoch: 6| Step: 7
Training loss: 1.957754135131836
Validation loss: 2.3434056851171676

Epoch: 6| Step: 8
Training loss: 2.311060905456543
Validation loss: 2.3326472184991323

Epoch: 6| Step: 9
Training loss: 2.6110010147094727
Validation loss: 2.327949400871031

Epoch: 6| Step: 10
Training loss: 2.6286773681640625
Validation loss: 2.3344211193823043

Epoch: 6| Step: 11
Training loss: 2.685558795928955
Validation loss: 2.332579123076572

Epoch: 6| Step: 12
Training loss: 1.5363965034484863
Validation loss: 2.3387903039173414

Epoch: 6| Step: 13
Training loss: 3.0422306060791016
Validation loss: 2.3378593639660905

Epoch: 128| Step: 0
Training loss: 2.6395044326782227
Validation loss: 2.33669473022543

Epoch: 6| Step: 1
Training loss: 2.0993101596832275
Validation loss: 2.3337092732870452

Epoch: 6| Step: 2
Training loss: 2.3104023933410645
Validation loss: 2.327041352948835

Epoch: 6| Step: 3
Training loss: 2.757927417755127
Validation loss: 2.3266194046184583

Epoch: 6| Step: 4
Training loss: 3.1543829441070557
Validation loss: 2.3257679221450642

Epoch: 6| Step: 5
Training loss: 3.1424412727355957
Validation loss: 2.328909276634134

Epoch: 6| Step: 6
Training loss: 2.3256418704986572
Validation loss: 2.3216890288937475

Epoch: 6| Step: 7
Training loss: 2.548522472381592
Validation loss: 2.320554707639961

Epoch: 6| Step: 8
Training loss: 3.6613900661468506
Validation loss: 2.3356401125590005

Epoch: 6| Step: 9
Training loss: 2.446080207824707
Validation loss: 2.3307372985347623

Epoch: 6| Step: 10
Training loss: 2.516134262084961
Validation loss: 2.3335337856764435

Epoch: 6| Step: 11
Training loss: 1.7945051193237305
Validation loss: 2.3363338439695296

Epoch: 6| Step: 12
Training loss: 2.4888205528259277
Validation loss: 2.338928057301429

Epoch: 6| Step: 13
Training loss: 1.554197907447815
Validation loss: 2.3419489783625447

Epoch: 129| Step: 0
Training loss: 3.288597583770752
Validation loss: 2.336199393836401

Epoch: 6| Step: 1
Training loss: 1.9550472497940063
Validation loss: 2.3398366487154396

Epoch: 6| Step: 2
Training loss: 2.445272445678711
Validation loss: 2.343572488395117

Epoch: 6| Step: 3
Training loss: 1.9592251777648926
Validation loss: 2.352539316300423

Epoch: 6| Step: 4
Training loss: 2.6198649406433105
Validation loss: 2.347315531904979

Epoch: 6| Step: 5
Training loss: 2.4554266929626465
Validation loss: 2.3520767624660204

Epoch: 6| Step: 6
Training loss: 2.5869851112365723
Validation loss: 2.3549547297980196

Epoch: 6| Step: 7
Training loss: 2.924915075302124
Validation loss: 2.3643333373531217

Epoch: 6| Step: 8
Training loss: 2.2935538291931152
Validation loss: 2.3810428419420795

Epoch: 6| Step: 9
Training loss: 2.694425106048584
Validation loss: 2.3858120185072704

Epoch: 6| Step: 10
Training loss: 2.250253915786743
Validation loss: 2.388406948376727

Epoch: 6| Step: 11
Training loss: 2.3185644149780273
Validation loss: 2.387821792274393

Epoch: 6| Step: 12
Training loss: 2.942800521850586
Validation loss: 2.378161043249151

Epoch: 6| Step: 13
Training loss: 3.488682985305786
Validation loss: 2.3640601737524873

Epoch: 130| Step: 0
Training loss: 2.8490242958068848
Validation loss: 2.365290705875684

Epoch: 6| Step: 1
Training loss: 2.908294677734375
Validation loss: 2.357957496437975

Epoch: 6| Step: 2
Training loss: 2.5607664585113525
Validation loss: 2.3454036328100387

Epoch: 6| Step: 3
Training loss: 3.069458484649658
Validation loss: 2.3420883481220534

Epoch: 6| Step: 4
Training loss: 2.281672954559326
Validation loss: 2.335658791244671

Epoch: 6| Step: 5
Training loss: 2.306910991668701
Validation loss: 2.3362704682093796

Epoch: 6| Step: 6
Training loss: 2.8060364723205566
Validation loss: 2.33815667193423

Epoch: 6| Step: 7
Training loss: 2.4066648483276367
Validation loss: 2.325517926164853

Epoch: 6| Step: 8
Training loss: 2.2886123657226562
Validation loss: 2.321173711489606

Epoch: 6| Step: 9
Training loss: 3.048053741455078
Validation loss: 2.3235024354791127

Epoch: 6| Step: 10
Training loss: 2.2554521560668945
Validation loss: 2.323963362683532

Epoch: 6| Step: 11
Training loss: 2.4457294940948486
Validation loss: 2.326046105354063

Epoch: 6| Step: 12
Training loss: 2.5358145236968994
Validation loss: 2.3248425119666645

Epoch: 6| Step: 13
Training loss: 1.6147443056106567
Validation loss: 2.3276778882549656

Epoch: 131| Step: 0
Training loss: 2.3962063789367676
Validation loss: 2.31969956685138

Epoch: 6| Step: 1
Training loss: 3.157620906829834
Validation loss: 2.316963521383142

Epoch: 6| Step: 2
Training loss: 1.8850637674331665
Validation loss: 2.3192683009691137

Epoch: 6| Step: 3
Training loss: 3.1950316429138184
Validation loss: 2.3292452532757997

Epoch: 6| Step: 4
Training loss: 2.9704298973083496
Validation loss: 2.332054474020517

Epoch: 6| Step: 5
Training loss: 2.4359171390533447
Validation loss: 2.3471769030376146

Epoch: 6| Step: 6
Training loss: 2.8587536811828613
Validation loss: 2.3540817050523657

Epoch: 6| Step: 7
Training loss: 1.9078574180603027
Validation loss: 2.3614701455639255

Epoch: 6| Step: 8
Training loss: 2.066135883331299
Validation loss: 2.3481528528275026

Epoch: 6| Step: 9
Training loss: 2.4814212322235107
Validation loss: 2.36049166546073

Epoch: 6| Step: 10
Training loss: 2.7582321166992188
Validation loss: 2.3513819376627603

Epoch: 6| Step: 11
Training loss: 3.13679838180542
Validation loss: 2.3575529424093102

Epoch: 6| Step: 12
Training loss: 2.125990390777588
Validation loss: 2.3555978267423567

Epoch: 6| Step: 13
Training loss: 2.217048168182373
Validation loss: 2.3529120363214964

Epoch: 132| Step: 0
Training loss: 2.650456666946411
Validation loss: 2.3357602934683523

Epoch: 6| Step: 1
Training loss: 2.0174648761749268
Validation loss: 2.339377659623341

Epoch: 6| Step: 2
Training loss: 2.482232093811035
Validation loss: 2.3269592382574595

Epoch: 6| Step: 3
Training loss: 2.4713916778564453
Validation loss: 2.3213891137030815

Epoch: 6| Step: 4
Training loss: 2.9402897357940674
Validation loss: 2.316245904532812

Epoch: 6| Step: 5
Training loss: 1.7244203090667725
Validation loss: 2.3147152623822613

Epoch: 6| Step: 6
Training loss: 2.5640013217926025
Validation loss: 2.323959882541369

Epoch: 6| Step: 7
Training loss: 2.8245351314544678
Validation loss: 2.3173107383071736

Epoch: 6| Step: 8
Training loss: 3.0609335899353027
Validation loss: 2.316203445516607

Epoch: 6| Step: 9
Training loss: 2.383910894393921
Validation loss: 2.3163846615822083

Epoch: 6| Step: 10
Training loss: 1.9187533855438232
Validation loss: 2.3148289060079925

Epoch: 6| Step: 11
Training loss: 3.356654405593872
Validation loss: 2.326813259432393

Epoch: 6| Step: 12
Training loss: 2.8999691009521484
Validation loss: 2.318505753753006

Epoch: 6| Step: 13
Training loss: 2.292323350906372
Validation loss: 2.3201452942304712

Epoch: 133| Step: 0
Training loss: 2.1235318183898926
Validation loss: 2.3213740241143013

Epoch: 6| Step: 1
Training loss: 3.006415843963623
Validation loss: 2.3307863819983696

Epoch: 6| Step: 2
Training loss: 2.2559657096862793
Validation loss: 2.3261709649075746

Epoch: 6| Step: 3
Training loss: 2.272716999053955
Validation loss: 2.3265484917548394

Epoch: 6| Step: 4
Training loss: 2.8237504959106445
Validation loss: 2.3335793672069425

Epoch: 6| Step: 5
Training loss: 2.8575820922851562
Validation loss: 2.3293623206435994

Epoch: 6| Step: 6
Training loss: 2.622697591781616
Validation loss: 2.3187690729736

Epoch: 6| Step: 7
Training loss: 2.3901686668395996
Validation loss: 2.327134342603786

Epoch: 6| Step: 8
Training loss: 2.4978175163269043
Validation loss: 2.3439032595644713

Epoch: 6| Step: 9
Training loss: 1.5227222442626953
Validation loss: 2.3442411512456913

Epoch: 6| Step: 10
Training loss: 3.5212738513946533
Validation loss: 2.359429238944925

Epoch: 6| Step: 11
Training loss: 3.1327877044677734
Validation loss: 2.372996343079434

Epoch: 6| Step: 12
Training loss: 1.9454998970031738
Validation loss: 2.3516090428957375

Epoch: 6| Step: 13
Training loss: 2.653435230255127
Validation loss: 2.369636917626986

Epoch: 134| Step: 0
Training loss: 2.731253147125244
Validation loss: 2.3594602218238254

Epoch: 6| Step: 1
Training loss: 2.3981223106384277
Validation loss: 2.3800428759667183

Epoch: 6| Step: 2
Training loss: 2.9447498321533203
Validation loss: 2.3766937281495784

Epoch: 6| Step: 3
Training loss: 2.2284536361694336
Validation loss: 2.383365290139311

Epoch: 6| Step: 4
Training loss: 2.2594716548919678
Validation loss: 2.3835375462808917

Epoch: 6| Step: 5
Training loss: 2.690560817718506
Validation loss: 2.394514059507719

Epoch: 6| Step: 6
Training loss: 2.435572862625122
Validation loss: 2.3637317380597516

Epoch: 6| Step: 7
Training loss: 2.6764626502990723
Validation loss: 2.363654352003528

Epoch: 6| Step: 8
Training loss: 3.0676567554473877
Validation loss: 2.3402923384020404

Epoch: 6| Step: 9
Training loss: 2.904759407043457
Validation loss: 2.3345562719529673

Epoch: 6| Step: 10
Training loss: 2.9880504608154297
Validation loss: 2.3265478431537585

Epoch: 6| Step: 11
Training loss: 1.6218571662902832
Validation loss: 2.3187385989773657

Epoch: 6| Step: 12
Training loss: 1.920698642730713
Validation loss: 2.318875306396074

Epoch: 6| Step: 13
Training loss: 2.768770933151245
Validation loss: 2.31233706525577

Epoch: 135| Step: 0
Training loss: 2.6435699462890625
Validation loss: 2.317617657364056

Epoch: 6| Step: 1
Training loss: 3.149841547012329
Validation loss: 2.3161202938325944

Epoch: 6| Step: 2
Training loss: 2.1185462474823
Validation loss: 2.3297064535079466

Epoch: 6| Step: 3
Training loss: 2.370049476623535
Validation loss: 2.3319743628142984

Epoch: 6| Step: 4
Training loss: 2.2133045196533203
Validation loss: 2.335496005191598

Epoch: 6| Step: 5
Training loss: 2.8382749557495117
Validation loss: 2.3275800084555023

Epoch: 6| Step: 6
Training loss: 3.649226665496826
Validation loss: 2.3479062152165238

Epoch: 6| Step: 7
Training loss: 2.6877756118774414
Validation loss: 2.3448327049132316

Epoch: 6| Step: 8
Training loss: 2.4085702896118164
Validation loss: 2.3482333331979732

Epoch: 6| Step: 9
Training loss: 2.5144336223602295
Validation loss: 2.3668298593131443

Epoch: 6| Step: 10
Training loss: 1.328540563583374
Validation loss: 2.3753544463906238

Epoch: 6| Step: 11
Training loss: 1.9496281147003174
Validation loss: 2.3659541235175183

Epoch: 6| Step: 12
Training loss: 2.833420753479004
Validation loss: 2.369387651002535

Epoch: 6| Step: 13
Training loss: 3.199941396713257
Validation loss: 2.359397378019107

Epoch: 136| Step: 0
Training loss: 2.2684266567230225
Validation loss: 2.3562198915789203

Epoch: 6| Step: 1
Training loss: 2.2455620765686035
Validation loss: 2.357707146675356

Epoch: 6| Step: 2
Training loss: 2.572709083557129
Validation loss: 2.3592539397619103

Epoch: 6| Step: 3
Training loss: 3.540722370147705
Validation loss: 2.346623336115191

Epoch: 6| Step: 4
Training loss: 2.3048062324523926
Validation loss: 2.344364394423782

Epoch: 6| Step: 5
Training loss: 2.9765381813049316
Validation loss: 2.332576408181139

Epoch: 6| Step: 6
Training loss: 2.9002115726470947
Validation loss: 2.325943218764438

Epoch: 6| Step: 7
Training loss: 2.0370681285858154
Validation loss: 2.3208058162402083

Epoch: 6| Step: 8
Training loss: 2.7041399478912354
Validation loss: 2.312262181312807

Epoch: 6| Step: 9
Training loss: 2.5967090129852295
Validation loss: 2.3080605178750973

Epoch: 6| Step: 10
Training loss: 2.03788685798645
Validation loss: 2.2931600642460648

Epoch: 6| Step: 11
Training loss: 2.4235968589782715
Validation loss: 2.2994028291394635

Epoch: 6| Step: 12
Training loss: 2.427128791809082
Validation loss: 2.294733723004659

Epoch: 6| Step: 13
Training loss: 3.0263617038726807
Validation loss: 2.2978120183431976

Epoch: 137| Step: 0
Training loss: 2.3774893283843994
Validation loss: 2.30873030231845

Epoch: 6| Step: 1
Training loss: 2.564816474914551
Validation loss: 2.3179155293331353

Epoch: 6| Step: 2
Training loss: 3.116219997406006
Validation loss: 2.324256617535827

Epoch: 6| Step: 3
Training loss: 2.3842434883117676
Validation loss: 2.3295789252045336

Epoch: 6| Step: 4
Training loss: 3.385594367980957
Validation loss: 2.344656308492025

Epoch: 6| Step: 5
Training loss: 2.359323263168335
Validation loss: 2.343174014040219

Epoch: 6| Step: 6
Training loss: 2.0153791904449463
Validation loss: 2.346977082631921

Epoch: 6| Step: 7
Training loss: 2.89163875579834
Validation loss: 2.3605468914073002

Epoch: 6| Step: 8
Training loss: 2.523019790649414
Validation loss: 2.3542679804627613

Epoch: 6| Step: 9
Training loss: 3.250974655151367
Validation loss: 2.3620608365663918

Epoch: 6| Step: 10
Training loss: 2.397845983505249
Validation loss: 2.3530594610398814

Epoch: 6| Step: 11
Training loss: 2.4312589168548584
Validation loss: 2.354130744934082

Epoch: 6| Step: 12
Training loss: 2.006290912628174
Validation loss: 2.3462841664591143

Epoch: 6| Step: 13
Training loss: 1.7772892713546753
Validation loss: 2.337791035252233

Epoch: 138| Step: 0
Training loss: 2.6894657611846924
Validation loss: 2.335622997694118

Epoch: 6| Step: 1
Training loss: 2.976396322250366
Validation loss: 2.327338992908437

Epoch: 6| Step: 2
Training loss: 2.6591572761535645
Validation loss: 2.3223639765093402

Epoch: 6| Step: 3
Training loss: 2.07578706741333
Validation loss: 2.3278209676024733

Epoch: 6| Step: 4
Training loss: 2.2762367725372314
Validation loss: 2.3253761888832174

Epoch: 6| Step: 5
Training loss: 2.7194738388061523
Validation loss: 2.337174618115989

Epoch: 6| Step: 6
Training loss: 2.969390392303467
Validation loss: 2.3348597403495543

Epoch: 6| Step: 7
Training loss: 2.796815872192383
Validation loss: 2.3416337402918006

Epoch: 6| Step: 8
Training loss: 2.3976235389709473
Validation loss: 2.3478430368567027

Epoch: 6| Step: 9
Training loss: 2.1226723194122314
Validation loss: 2.357392026532081

Epoch: 6| Step: 10
Training loss: 2.669729709625244
Validation loss: 2.360541771816951

Epoch: 6| Step: 11
Training loss: 2.6284635066986084
Validation loss: 2.3523055302199496

Epoch: 6| Step: 12
Training loss: 1.7875356674194336
Validation loss: 2.3463898384442894

Epoch: 6| Step: 13
Training loss: 2.8909685611724854
Validation loss: 2.349333360630979

Epoch: 139| Step: 0
Training loss: 2.8853280544281006
Validation loss: 2.3692927155443417

Epoch: 6| Step: 1
Training loss: 2.1844868659973145
Validation loss: 2.3756774599834154

Epoch: 6| Step: 2
Training loss: 2.3775157928466797
Validation loss: 2.3671700928800847

Epoch: 6| Step: 3
Training loss: 2.0488357543945312
Validation loss: 2.3654168421222317

Epoch: 6| Step: 4
Training loss: 2.6367127895355225
Validation loss: 2.3743549854524675

Epoch: 6| Step: 5
Training loss: 2.3320727348327637
Validation loss: 2.362580232722785

Epoch: 6| Step: 6
Training loss: 2.4069483280181885
Validation loss: 2.3469649284116683

Epoch: 6| Step: 7
Training loss: 2.1464638710021973
Validation loss: 2.327869133282733

Epoch: 6| Step: 8
Training loss: 3.015921115875244
Validation loss: 2.3151939709981284

Epoch: 6| Step: 9
Training loss: 2.631230354309082
Validation loss: 2.308288789564563

Epoch: 6| Step: 10
Training loss: 2.926474094390869
Validation loss: 2.295615229555356

Epoch: 6| Step: 11
Training loss: 2.4382877349853516
Validation loss: 2.301203784122262

Epoch: 6| Step: 12
Training loss: 3.552924156188965
Validation loss: 2.2906829029001217

Epoch: 6| Step: 13
Training loss: 1.6525802612304688
Validation loss: 2.294301676493819

Epoch: 140| Step: 0
Training loss: 2.3409934043884277
Validation loss: 2.293249771159182

Epoch: 6| Step: 1
Training loss: 2.4039857387542725
Validation loss: 2.303120736152895

Epoch: 6| Step: 2
Training loss: 2.3957691192626953
Validation loss: 2.2989781210499425

Epoch: 6| Step: 3
Training loss: 2.8970916271209717
Validation loss: 2.2948169964616016

Epoch: 6| Step: 4
Training loss: 2.3558363914489746
Validation loss: 2.2980896016602874

Epoch: 6| Step: 5
Training loss: 2.0783281326293945
Validation loss: 2.3053063167038785

Epoch: 6| Step: 6
Training loss: 2.2778425216674805
Validation loss: 2.2947634958451792

Epoch: 6| Step: 7
Training loss: 2.8741672039031982
Validation loss: 2.2984044936395462

Epoch: 6| Step: 8
Training loss: 3.1817984580993652
Validation loss: 2.3003903460758988

Epoch: 6| Step: 9
Training loss: 2.9126760959625244
Validation loss: 2.288448820831955

Epoch: 6| Step: 10
Training loss: 1.7196494340896606
Validation loss: 2.2936743433757494

Epoch: 6| Step: 11
Training loss: 3.243314504623413
Validation loss: 2.292127240088678

Epoch: 6| Step: 12
Training loss: 2.386014461517334
Validation loss: 2.2898487352555796

Epoch: 6| Step: 13
Training loss: 2.753591775894165
Validation loss: 2.291942301616874

Epoch: 141| Step: 0
Training loss: 2.7609639167785645
Validation loss: 2.3087191786817325

Epoch: 6| Step: 1
Training loss: 2.7520790100097656
Validation loss: 2.302215322371452

Epoch: 6| Step: 2
Training loss: 2.0196356773376465
Validation loss: 2.3043379565720916

Epoch: 6| Step: 3
Training loss: 2.498039722442627
Validation loss: 2.304676991637035

Epoch: 6| Step: 4
Training loss: 2.6927332878112793
Validation loss: 2.306854212155906

Epoch: 6| Step: 5
Training loss: 2.8864450454711914
Validation loss: 2.309705093342771

Epoch: 6| Step: 6
Training loss: 2.9395546913146973
Validation loss: 2.3129747606092885

Epoch: 6| Step: 7
Training loss: 2.413344144821167
Validation loss: 2.3158382061989076

Epoch: 6| Step: 8
Training loss: 2.256956100463867
Validation loss: 2.3179119274180424

Epoch: 6| Step: 9
Training loss: 2.697021722793579
Validation loss: 2.3219264937985327

Epoch: 6| Step: 10
Training loss: 2.325298309326172
Validation loss: 2.316790432058355

Epoch: 6| Step: 11
Training loss: 2.3434746265411377
Validation loss: 2.313957956529433

Epoch: 6| Step: 12
Training loss: 2.6589527130126953
Validation loss: 2.3297549345160045

Epoch: 6| Step: 13
Training loss: 1.896750569343567
Validation loss: 2.3174205851811234

Epoch: 142| Step: 0
Training loss: 2.348151206970215
Validation loss: 2.341319250804122

Epoch: 6| Step: 1
Training loss: 3.0010299682617188
Validation loss: 2.3253927717926683

Epoch: 6| Step: 2
Training loss: 2.466559410095215
Validation loss: 2.3481757128110496

Epoch: 6| Step: 3
Training loss: 2.9026565551757812
Validation loss: 2.3265975290729153

Epoch: 6| Step: 4
Training loss: 3.088087558746338
Validation loss: 2.351746725779708

Epoch: 6| Step: 5
Training loss: 3.2444753646850586
Validation loss: 2.342180331548055

Epoch: 6| Step: 6
Training loss: 1.8911709785461426
Validation loss: 2.3553674682494132

Epoch: 6| Step: 7
Training loss: 2.6869850158691406
Validation loss: 2.3293757310477634

Epoch: 6| Step: 8
Training loss: 2.0745630264282227
Validation loss: 2.329275925954183

Epoch: 6| Step: 9
Training loss: 2.2847752571105957
Validation loss: 2.3212391458531862

Epoch: 6| Step: 10
Training loss: 2.039738416671753
Validation loss: 2.30169935892987

Epoch: 6| Step: 11
Training loss: 2.5139126777648926
Validation loss: 2.2968902536617812

Epoch: 6| Step: 12
Training loss: 2.443484306335449
Validation loss: 2.2955753649434736

Epoch: 6| Step: 13
Training loss: 2.429582118988037
Validation loss: 2.302618824025636

Epoch: 143| Step: 0
Training loss: 1.9779423475265503
Validation loss: 2.3124412951930875

Epoch: 6| Step: 1
Training loss: 2.6490108966827393
Validation loss: 2.305555228264101

Epoch: 6| Step: 2
Training loss: 2.412994623184204
Validation loss: 2.3232049019105974

Epoch: 6| Step: 3
Training loss: 2.074516773223877
Validation loss: 2.320927266151674

Epoch: 6| Step: 4
Training loss: 2.324469804763794
Validation loss: 2.334751654696721

Epoch: 6| Step: 5
Training loss: 1.584826111793518
Validation loss: 2.3390493623671995

Epoch: 6| Step: 6
Training loss: 3.1359994411468506
Validation loss: 2.3451421722289054

Epoch: 6| Step: 7
Training loss: 2.633859157562256
Validation loss: 2.341106278921968

Epoch: 6| Step: 8
Training loss: 2.6302967071533203
Validation loss: 2.3595856235873316

Epoch: 6| Step: 9
Training loss: 2.7724132537841797
Validation loss: 2.3534726686375116

Epoch: 6| Step: 10
Training loss: 2.2777304649353027
Validation loss: 2.3327442048698344

Epoch: 6| Step: 11
Training loss: 3.370452880859375
Validation loss: 2.3312331912338093

Epoch: 6| Step: 12
Training loss: 2.6544346809387207
Validation loss: 2.3274180581492763

Epoch: 6| Step: 13
Training loss: 3.333106517791748
Validation loss: 2.309102876212007

Epoch: 144| Step: 0
Training loss: 2.306014060974121
Validation loss: 2.304646804768552

Epoch: 6| Step: 1
Training loss: 2.9559485912323
Validation loss: 2.31845776496395

Epoch: 6| Step: 2
Training loss: 3.031970500946045
Validation loss: 2.307043580598729

Epoch: 6| Step: 3
Training loss: 2.6968135833740234
Validation loss: 2.3094472654404177

Epoch: 6| Step: 4
Training loss: 3.350311756134033
Validation loss: 2.314187672830397

Epoch: 6| Step: 5
Training loss: 2.876345634460449
Validation loss: 2.3162869125284176

Epoch: 6| Step: 6
Training loss: 2.0411462783813477
Validation loss: 2.322243995563958

Epoch: 6| Step: 7
Training loss: 2.6272571086883545
Validation loss: 2.3207333216103176

Epoch: 6| Step: 8
Training loss: 2.5286381244659424
Validation loss: 2.3175041675567627

Epoch: 6| Step: 9
Training loss: 1.8151545524597168
Validation loss: 2.3195480377443376

Epoch: 6| Step: 10
Training loss: 3.0838639736175537
Validation loss: 2.3245562327805387

Epoch: 6| Step: 11
Training loss: 1.93338143825531
Validation loss: 2.3237873995175926

Epoch: 6| Step: 12
Training loss: 1.8769464492797852
Validation loss: 2.303096704585578

Epoch: 6| Step: 13
Training loss: 2.06803560256958
Validation loss: 2.3129897476524435

Epoch: 145| Step: 0
Training loss: 2.734320878982544
Validation loss: 2.302841123714242

Epoch: 6| Step: 1
Training loss: 3.122849464416504
Validation loss: 2.292260187928395

Epoch: 6| Step: 2
Training loss: 2.5192713737487793
Validation loss: 2.304045666930496

Epoch: 6| Step: 3
Training loss: 2.8272593021392822
Validation loss: 2.2984801876929497

Epoch: 6| Step: 4
Training loss: 2.4510738849639893
Validation loss: 2.3110246504506757

Epoch: 6| Step: 5
Training loss: 2.373715877532959
Validation loss: 2.303631664604269

Epoch: 6| Step: 6
Training loss: 1.9538575410842896
Validation loss: 2.310314752722299

Epoch: 6| Step: 7
Training loss: 2.9493322372436523
Validation loss: 2.3075948197354554

Epoch: 6| Step: 8
Training loss: 2.554886817932129
Validation loss: 2.3023740758178053

Epoch: 6| Step: 9
Training loss: 2.8774843215942383
Validation loss: 2.304666816547353

Epoch: 6| Step: 10
Training loss: 2.0391151905059814
Validation loss: 2.3154024872728574

Epoch: 6| Step: 11
Training loss: 3.009678840637207
Validation loss: 2.321998350081905

Epoch: 6| Step: 12
Training loss: 1.6684579849243164
Validation loss: 2.3040415984328075

Epoch: 6| Step: 13
Training loss: 1.9543641805648804
Validation loss: 2.312382782659223

Epoch: 146| Step: 0
Training loss: 2.512385606765747
Validation loss: 2.313041333229311

Epoch: 6| Step: 1
Training loss: 3.0383381843566895
Validation loss: 2.314724609416018

Epoch: 6| Step: 2
Training loss: 2.478527545928955
Validation loss: 2.30957128155616

Epoch: 6| Step: 3
Training loss: 2.297224998474121
Validation loss: 2.3260597785313926

Epoch: 6| Step: 4
Training loss: 2.8642725944519043
Validation loss: 2.330569585164388

Epoch: 6| Step: 5
Training loss: 2.8964967727661133
Validation loss: 2.3290389686502437

Epoch: 6| Step: 6
Training loss: 2.295205593109131
Validation loss: 2.3206305862754903

Epoch: 6| Step: 7
Training loss: 1.958469271659851
Validation loss: 2.322165089268838

Epoch: 6| Step: 8
Training loss: 2.4318361282348633
Validation loss: 2.332161568826245

Epoch: 6| Step: 9
Training loss: 2.3459243774414062
Validation loss: 2.322251166066816

Epoch: 6| Step: 10
Training loss: 2.999635696411133
Validation loss: 2.3070658355630855

Epoch: 6| Step: 11
Training loss: 2.337773084640503
Validation loss: 2.304742128618302

Epoch: 6| Step: 12
Training loss: 2.4536662101745605
Validation loss: 2.3083324816919144

Epoch: 6| Step: 13
Training loss: 2.447289228439331
Validation loss: 2.3079799631590485

Epoch: 147| Step: 0
Training loss: 2.1125760078430176
Validation loss: 2.294195782753729

Epoch: 6| Step: 1
Training loss: 2.2444427013397217
Validation loss: 2.3037347755124493

Epoch: 6| Step: 2
Training loss: 2.6966443061828613
Validation loss: 2.3081319268031786

Epoch: 6| Step: 3
Training loss: 2.593578815460205
Validation loss: 2.3030764159335884

Epoch: 6| Step: 4
Training loss: 2.7689170837402344
Validation loss: 2.297047786815192

Epoch: 6| Step: 5
Training loss: 2.3870296478271484
Validation loss: 2.3010383652102564

Epoch: 6| Step: 6
Training loss: 2.1022233963012695
Validation loss: 2.3042179435812016

Epoch: 6| Step: 7
Training loss: 2.1765711307525635
Validation loss: 2.296687505578482

Epoch: 6| Step: 8
Training loss: 2.526688575744629
Validation loss: 2.307044885491812

Epoch: 6| Step: 9
Training loss: 2.7977209091186523
Validation loss: 2.306000171169158

Epoch: 6| Step: 10
Training loss: 2.54337477684021
Validation loss: 2.3056457170876126

Epoch: 6| Step: 11
Training loss: 2.959277629852295
Validation loss: 2.300060959272487

Epoch: 6| Step: 12
Training loss: 2.7507476806640625
Validation loss: 2.296773654158397

Epoch: 6| Step: 13
Training loss: 2.7297794818878174
Validation loss: 2.283665612179746

Epoch: 148| Step: 0
Training loss: 2.520192861557007
Validation loss: 2.30008222979884

Epoch: 6| Step: 1
Training loss: 2.3375439643859863
Validation loss: 2.289914566983459

Epoch: 6| Step: 2
Training loss: 2.943971872329712
Validation loss: 2.299604341547976

Epoch: 6| Step: 3
Training loss: 1.9816945791244507
Validation loss: 2.2912699022600727

Epoch: 6| Step: 4
Training loss: 2.761723041534424
Validation loss: 2.2925211665450886

Epoch: 6| Step: 5
Training loss: 3.385585308074951
Validation loss: 2.3015122387998845

Epoch: 6| Step: 6
Training loss: 2.5506234169006348
Validation loss: 2.2906370086054646

Epoch: 6| Step: 7
Training loss: 2.5654823780059814
Validation loss: 2.2949293031487414

Epoch: 6| Step: 8
Training loss: 1.804294466972351
Validation loss: 2.2851037850943943

Epoch: 6| Step: 9
Training loss: 2.51255464553833
Validation loss: 2.2823906662643596

Epoch: 6| Step: 10
Training loss: 2.404069423675537
Validation loss: 2.28654065439778

Epoch: 6| Step: 11
Training loss: 2.917938232421875
Validation loss: 2.3006005158988376

Epoch: 6| Step: 12
Training loss: 2.2465837001800537
Validation loss: 2.2943003882643995

Epoch: 6| Step: 13
Training loss: 2.1930809020996094
Validation loss: 2.3038593953655613

Epoch: 149| Step: 0
Training loss: 2.7522692680358887
Validation loss: 2.3084648757852535

Epoch: 6| Step: 1
Training loss: 2.4578115940093994
Validation loss: 2.3162636167259625

Epoch: 6| Step: 2
Training loss: 2.9465651512145996
Validation loss: 2.3146428241524646

Epoch: 6| Step: 3
Training loss: 3.1942622661590576
Validation loss: 2.3158157897251908

Epoch: 6| Step: 4
Training loss: 2.949808120727539
Validation loss: 2.300403615479828

Epoch: 6| Step: 5
Training loss: 2.460700273513794
Validation loss: 2.294219095219848

Epoch: 6| Step: 6
Training loss: 2.3950748443603516
Validation loss: 2.302200681419783

Epoch: 6| Step: 7
Training loss: 3.1819632053375244
Validation loss: 2.308348212190854

Epoch: 6| Step: 8
Training loss: 2.171459436416626
Validation loss: 2.290071782245431

Epoch: 6| Step: 9
Training loss: 2.6266818046569824
Validation loss: 2.2981176145615114

Epoch: 6| Step: 10
Training loss: 2.550440788269043
Validation loss: 2.300483613885859

Epoch: 6| Step: 11
Training loss: 1.4595751762390137
Validation loss: 2.3091026685571157

Epoch: 6| Step: 12
Training loss: 1.7901281118392944
Validation loss: 2.3146180234929568

Epoch: 6| Step: 13
Training loss: 2.2774369716644287
Validation loss: 2.3307773656742548

Epoch: 150| Step: 0
Training loss: 3.1521482467651367
Validation loss: 2.328929023076129

Epoch: 6| Step: 1
Training loss: 2.362013339996338
Validation loss: 2.3196958726452244

Epoch: 6| Step: 2
Training loss: 2.490501880645752
Validation loss: 2.3342777862343738

Epoch: 6| Step: 3
Training loss: 2.3644509315490723
Validation loss: 2.3332631049617643

Epoch: 6| Step: 4
Training loss: 2.287540912628174
Validation loss: 2.319909462364771

Epoch: 6| Step: 5
Training loss: 2.4286017417907715
Validation loss: 2.319768382656959

Epoch: 6| Step: 6
Training loss: 2.6725523471832275
Validation loss: 2.3128367649611605

Epoch: 6| Step: 7
Training loss: 2.00826358795166
Validation loss: 2.317090739486038

Epoch: 6| Step: 8
Training loss: 3.295497179031372
Validation loss: 2.303767745212842

Epoch: 6| Step: 9
Training loss: 2.7219271659851074
Validation loss: 2.2989600960926344

Epoch: 6| Step: 10
Training loss: 2.158172845840454
Validation loss: 2.28306213501961

Epoch: 6| Step: 11
Training loss: 2.121567487716675
Validation loss: 2.2825362400342057

Epoch: 6| Step: 12
Training loss: 2.693453311920166
Validation loss: 2.2894363864775626

Epoch: 6| Step: 13
Training loss: 2.570543050765991
Validation loss: 2.287110833711522

Epoch: 151| Step: 0
Training loss: 1.9888179302215576
Validation loss: 2.2897086784403813

Epoch: 6| Step: 1
Training loss: 2.355637550354004
Validation loss: 2.2919522818698677

Epoch: 6| Step: 2
Training loss: 2.221102237701416
Validation loss: 2.320519934418381

Epoch: 6| Step: 3
Training loss: 3.1331381797790527
Validation loss: 2.3193668652606267

Epoch: 6| Step: 4
Training loss: 2.6978797912597656
Validation loss: 2.333153914379817

Epoch: 6| Step: 5
Training loss: 2.4387989044189453
Validation loss: 2.3387461734074417

Epoch: 6| Step: 6
Training loss: 2.431513786315918
Validation loss: 2.3204817413001932

Epoch: 6| Step: 7
Training loss: 3.1279408931732178
Validation loss: 2.3323261712187078

Epoch: 6| Step: 8
Training loss: 1.6641099452972412
Validation loss: 2.3213025857043523

Epoch: 6| Step: 9
Training loss: 2.5091662406921387
Validation loss: 2.305826694734635

Epoch: 6| Step: 10
Training loss: 2.4947471618652344
Validation loss: 2.306580217935706

Epoch: 6| Step: 11
Training loss: 2.618795394897461
Validation loss: 2.2926296328985565

Epoch: 6| Step: 12
Training loss: 3.052586317062378
Validation loss: 2.2946117372923

Epoch: 6| Step: 13
Training loss: 2.3788034915924072
Validation loss: 2.296843264692573

Epoch: 152| Step: 0
Training loss: 2.986973762512207
Validation loss: 2.2933512118554886

Epoch: 6| Step: 1
Training loss: 2.359809398651123
Validation loss: 2.301936326488372

Epoch: 6| Step: 2
Training loss: 2.2438607215881348
Validation loss: 2.304728268295206

Epoch: 6| Step: 3
Training loss: 2.910917282104492
Validation loss: 2.3132766036577124

Epoch: 6| Step: 4
Training loss: 2.1646552085876465
Validation loss: 2.317935892330703

Epoch: 6| Step: 5
Training loss: 2.439734935760498
Validation loss: 2.329128824254518

Epoch: 6| Step: 6
Training loss: 2.4555091857910156
Validation loss: 2.3056859662455897

Epoch: 6| Step: 7
Training loss: 3.0867862701416016
Validation loss: 2.3040308080693728

Epoch: 6| Step: 8
Training loss: 2.852980136871338
Validation loss: 2.292665332876226

Epoch: 6| Step: 9
Training loss: 2.913788318634033
Validation loss: 2.2770170755283807

Epoch: 6| Step: 10
Training loss: 1.6392462253570557
Validation loss: 2.27219646464112

Epoch: 6| Step: 11
Training loss: 2.2259578704833984
Validation loss: 2.272255707812566

Epoch: 6| Step: 12
Training loss: 2.416378974914551
Validation loss: 2.273606343935895

Epoch: 6| Step: 13
Training loss: 2.440723419189453
Validation loss: 2.268074002317203

Epoch: 153| Step: 0
Training loss: 2.035626173019409
Validation loss: 2.2789012796135357

Epoch: 6| Step: 1
Training loss: 2.5831360816955566
Validation loss: 2.279308074264116

Epoch: 6| Step: 2
Training loss: 2.4717440605163574
Validation loss: 2.28720587043352

Epoch: 6| Step: 3
Training loss: 2.3402891159057617
Validation loss: 2.3124889173815326

Epoch: 6| Step: 4
Training loss: 2.3090577125549316
Validation loss: 2.31120527175165

Epoch: 6| Step: 5
Training loss: 2.844783306121826
Validation loss: 2.3319684510589926

Epoch: 6| Step: 6
Training loss: 2.2082064151763916
Validation loss: 2.3355853416586436

Epoch: 6| Step: 7
Training loss: 2.979275703430176
Validation loss: 2.3347502370034494

Epoch: 6| Step: 8
Training loss: 2.9908881187438965
Validation loss: 2.343341960701891

Epoch: 6| Step: 9
Training loss: 3.040870428085327
Validation loss: 2.3434751777238745

Epoch: 6| Step: 10
Training loss: 2.0384554862976074
Validation loss: 2.334268393055085

Epoch: 6| Step: 11
Training loss: 3.286409378051758
Validation loss: 2.3423813107193157

Epoch: 6| Step: 12
Training loss: 1.824695110321045
Validation loss: 2.336029452662314

Epoch: 6| Step: 13
Training loss: 2.4809951782226562
Validation loss: 2.3328711012358307

Epoch: 154| Step: 0
Training loss: 2.1053924560546875
Validation loss: 2.329886431335121

Epoch: 6| Step: 1
Training loss: 1.2439980506896973
Validation loss: 2.324520275156985

Epoch: 6| Step: 2
Training loss: 3.3437442779541016
Validation loss: 2.3086842836872226

Epoch: 6| Step: 3
Training loss: 1.9400725364685059
Validation loss: 2.3017378699394966

Epoch: 6| Step: 4
Training loss: 2.967458724975586
Validation loss: 2.2949902267866236

Epoch: 6| Step: 5
Training loss: 2.274059295654297
Validation loss: 2.291315147953649

Epoch: 6| Step: 6
Training loss: 2.326536178588867
Validation loss: 2.283047322304018

Epoch: 6| Step: 7
Training loss: 1.8362371921539307
Validation loss: 2.2868232060504217

Epoch: 6| Step: 8
Training loss: 3.166832447052002
Validation loss: 2.2871302045801634

Epoch: 6| Step: 9
Training loss: 3.6371259689331055
Validation loss: 2.290036852641772

Epoch: 6| Step: 10
Training loss: 3.0301871299743652
Validation loss: 2.2759836309699604

Epoch: 6| Step: 11
Training loss: 2.741490364074707
Validation loss: 2.2691766254363523

Epoch: 6| Step: 12
Training loss: 1.5944347381591797
Validation loss: 2.2621528051232778

Epoch: 6| Step: 13
Training loss: 3.1764142513275146
Validation loss: 2.271807078392275

Epoch: 155| Step: 0
Training loss: 2.491661310195923
Validation loss: 2.271367803696663

Epoch: 6| Step: 1
Training loss: 2.517568349838257
Validation loss: 2.2658394203391126

Epoch: 6| Step: 2
Training loss: 2.818964958190918
Validation loss: 2.274065201000501

Epoch: 6| Step: 3
Training loss: 3.1837620735168457
Validation loss: 2.2750651913304485

Epoch: 6| Step: 4
Training loss: 2.6931495666503906
Validation loss: 2.2797119130370436

Epoch: 6| Step: 5
Training loss: 2.512355089187622
Validation loss: 2.2811385739234185

Epoch: 6| Step: 6
Training loss: 2.2265772819519043
Validation loss: 2.2874412562257502

Epoch: 6| Step: 7
Training loss: 1.5511033535003662
Validation loss: 2.292783160363474

Epoch: 6| Step: 8
Training loss: 2.4637484550476074
Validation loss: 2.293248076592722

Epoch: 6| Step: 9
Training loss: 2.5398330688476562
Validation loss: 2.3165847973157

Epoch: 6| Step: 10
Training loss: 2.387023448944092
Validation loss: 2.302425635758267

Epoch: 6| Step: 11
Training loss: 2.65291690826416
Validation loss: 2.3132331268761748

Epoch: 6| Step: 12
Training loss: 2.6030325889587402
Validation loss: 2.319464450241417

Epoch: 6| Step: 13
Training loss: 2.468625068664551
Validation loss: 2.3377760597454604

Epoch: 156| Step: 0
Training loss: 2.6161789894104004
Validation loss: 2.35999543692476

Epoch: 6| Step: 1
Training loss: 2.166893482208252
Validation loss: 2.3588535939493487

Epoch: 6| Step: 2
Training loss: 3.357642889022827
Validation loss: 2.3587041388275805

Epoch: 6| Step: 3
Training loss: 1.9217745065689087
Validation loss: 2.353351493035593

Epoch: 6| Step: 4
Training loss: 2.284677028656006
Validation loss: 2.3448796938824397

Epoch: 6| Step: 5
Training loss: 2.6060194969177246
Validation loss: 2.3429477189176824

Epoch: 6| Step: 6
Training loss: 3.1322410106658936
Validation loss: 2.3164288536194833

Epoch: 6| Step: 7
Training loss: 2.360358476638794
Validation loss: 2.304794515332868

Epoch: 6| Step: 8
Training loss: 2.2748775482177734
Validation loss: 2.3033934229163715

Epoch: 6| Step: 9
Training loss: 2.075765371322632
Validation loss: 2.268996815527639

Epoch: 6| Step: 10
Training loss: 3.442546844482422
Validation loss: 2.2800003020994124

Epoch: 6| Step: 11
Training loss: 2.462076425552368
Validation loss: 2.262170136615794

Epoch: 6| Step: 12
Training loss: 2.0685882568359375
Validation loss: 2.2678983442244993

Epoch: 6| Step: 13
Training loss: 2.2292323112487793
Validation loss: 2.2614421049753823

Epoch: 157| Step: 0
Training loss: 2.796483039855957
Validation loss: 2.263788516803454

Epoch: 6| Step: 1
Training loss: 3.0736937522888184
Validation loss: 2.244396976245347

Epoch: 6| Step: 2
Training loss: 2.6505017280578613
Validation loss: 2.2587822509068314

Epoch: 6| Step: 3
Training loss: 2.164393186569214
Validation loss: 2.2632365060108963

Epoch: 6| Step: 4
Training loss: 2.3374199867248535
Validation loss: 2.2517226665250716

Epoch: 6| Step: 5
Training loss: 2.261302947998047
Validation loss: 2.258097443529355

Epoch: 6| Step: 6
Training loss: 2.9080710411071777
Validation loss: 2.261393183021135

Epoch: 6| Step: 7
Training loss: 3.2122697830200195
Validation loss: 2.26807068240258

Epoch: 6| Step: 8
Training loss: 2.0311014652252197
Validation loss: 2.2876008941281225

Epoch: 6| Step: 9
Training loss: 2.4963321685791016
Validation loss: 2.274537911979101

Epoch: 6| Step: 10
Training loss: 1.7985775470733643
Validation loss: 2.28459959132697

Epoch: 6| Step: 11
Training loss: 2.7436938285827637
Validation loss: 2.2908828014968545

Epoch: 6| Step: 12
Training loss: 2.1923341751098633
Validation loss: 2.2777582471088698

Epoch: 6| Step: 13
Training loss: 2.712817430496216
Validation loss: 2.278594611793436

Epoch: 158| Step: 0
Training loss: 2.4144840240478516
Validation loss: 2.275583244139148

Epoch: 6| Step: 1
Training loss: 2.2624921798706055
Validation loss: 2.281851994094028

Epoch: 6| Step: 2
Training loss: 2.563581943511963
Validation loss: 2.293397283041349

Epoch: 6| Step: 3
Training loss: 1.9445180892944336
Validation loss: 2.2857969678858274

Epoch: 6| Step: 4
Training loss: 2.455064058303833
Validation loss: 2.299347451938096

Epoch: 6| Step: 5
Training loss: 2.3495445251464844
Validation loss: 2.310261872506911

Epoch: 6| Step: 6
Training loss: 2.7774710655212402
Validation loss: 2.325463556474255

Epoch: 6| Step: 7
Training loss: 2.8443353176116943
Validation loss: 2.3255788485209146

Epoch: 6| Step: 8
Training loss: 2.7029335498809814
Validation loss: 2.3280868043181715

Epoch: 6| Step: 9
Training loss: 2.7935919761657715
Validation loss: 2.338319170859552

Epoch: 6| Step: 10
Training loss: 1.9248392581939697
Validation loss: 2.331046753032233

Epoch: 6| Step: 11
Training loss: 2.8375236988067627
Validation loss: 2.3236230316982476

Epoch: 6| Step: 12
Training loss: 2.415102958679199
Validation loss: 2.3051918116948937

Epoch: 6| Step: 13
Training loss: 2.9419758319854736
Validation loss: 2.2889636460170952

Epoch: 159| Step: 0
Training loss: 1.979042887687683
Validation loss: 2.285798979061906

Epoch: 6| Step: 1
Training loss: 2.7285165786743164
Validation loss: 2.285387010984523

Epoch: 6| Step: 2
Training loss: 2.908937692642212
Validation loss: 2.2821239092016734

Epoch: 6| Step: 3
Training loss: 3.223314046859741
Validation loss: 2.264969313016502

Epoch: 6| Step: 4
Training loss: 2.15317440032959
Validation loss: 2.2707118706036638

Epoch: 6| Step: 5
Training loss: 2.1207780838012695
Validation loss: 2.2797247440584245

Epoch: 6| Step: 6
Training loss: 3.1180734634399414
Validation loss: 2.278713687773674

Epoch: 6| Step: 7
Training loss: 2.4528567790985107
Validation loss: 2.29539720730115

Epoch: 6| Step: 8
Training loss: 2.368267059326172
Validation loss: 2.300898431449808

Epoch: 6| Step: 9
Training loss: 2.3665223121643066
Validation loss: 2.3168074623230965

Epoch: 6| Step: 10
Training loss: 2.348799228668213
Validation loss: 2.3066319291309645

Epoch: 6| Step: 11
Training loss: 2.421700954437256
Validation loss: 2.3197992309447257

Epoch: 6| Step: 12
Training loss: 2.5299863815307617
Validation loss: 2.320027676961755

Epoch: 6| Step: 13
Training loss: 2.2037129402160645
Validation loss: 2.3269017870708177

Epoch: 160| Step: 0
Training loss: 2.7605180740356445
Validation loss: 2.305568661741031

Epoch: 6| Step: 1
Training loss: 2.5002050399780273
Validation loss: 2.290743217673353

Epoch: 6| Step: 2
Training loss: 2.265368938446045
Validation loss: 2.290464439699727

Epoch: 6| Step: 3
Training loss: 3.2577035427093506
Validation loss: 2.2956438500394105

Epoch: 6| Step: 4
Training loss: 2.884939670562744
Validation loss: 2.303606422998572

Epoch: 6| Step: 5
Training loss: 2.252748489379883
Validation loss: 2.2979346936748875

Epoch: 6| Step: 6
Training loss: 3.2662925720214844
Validation loss: 2.293771630974226

Epoch: 6| Step: 7
Training loss: 2.4571657180786133
Validation loss: 2.277425630118257

Epoch: 6| Step: 8
Training loss: 1.4794138669967651
Validation loss: 2.284886501168692

Epoch: 6| Step: 9
Training loss: 2.9114561080932617
Validation loss: 2.27153952147371

Epoch: 6| Step: 10
Training loss: 2.1110470294952393
Validation loss: 2.2648066346363356

Epoch: 6| Step: 11
Training loss: 1.7915947437286377
Validation loss: 2.264786169093142

Epoch: 6| Step: 12
Training loss: 2.337841510772705
Validation loss: 2.270157224388533

Epoch: 6| Step: 13
Training loss: 2.7920315265655518
Validation loss: 2.2754288373454923

Epoch: 161| Step: 0
Training loss: 2.068875551223755
Validation loss: 2.2892314798088482

Epoch: 6| Step: 1
Training loss: 2.708961009979248
Validation loss: 2.2962985679667485

Epoch: 6| Step: 2
Training loss: 2.927377462387085
Validation loss: 2.308657541069933

Epoch: 6| Step: 3
Training loss: 2.6864185333251953
Validation loss: 2.3201180581123597

Epoch: 6| Step: 4
Training loss: 2.4679198265075684
Validation loss: 2.3109310327037687

Epoch: 6| Step: 5
Training loss: 1.6272811889648438
Validation loss: 2.319813561695878

Epoch: 6| Step: 6
Training loss: 2.613126516342163
Validation loss: 2.3014988001956733

Epoch: 6| Step: 7
Training loss: 2.5480289459228516
Validation loss: 2.301514393539839

Epoch: 6| Step: 8
Training loss: 2.2409167289733887
Validation loss: 2.2759272642033075

Epoch: 6| Step: 9
Training loss: 2.852602958679199
Validation loss: 2.285171430598023

Epoch: 6| Step: 10
Training loss: 2.7983059883117676
Validation loss: 2.2897687496677523

Epoch: 6| Step: 11
Training loss: 2.368177890777588
Validation loss: 2.290925682231944

Epoch: 6| Step: 12
Training loss: 2.302910804748535
Validation loss: 2.286348863314557

Epoch: 6| Step: 13
Training loss: 3.0352890491485596
Validation loss: 2.2982622410661433

Epoch: 162| Step: 0
Training loss: 2.7040364742279053
Validation loss: 2.2870869046898297

Epoch: 6| Step: 1
Training loss: 2.083756685256958
Validation loss: 2.3043220376455658

Epoch: 6| Step: 2
Training loss: 2.745971202850342
Validation loss: 2.2919719142298542

Epoch: 6| Step: 3
Training loss: 2.785738468170166
Validation loss: 2.29184381423458

Epoch: 6| Step: 4
Training loss: 2.5640363693237305
Validation loss: 2.282938180431243

Epoch: 6| Step: 5
Training loss: 2.6567158699035645
Validation loss: 2.28769515919429

Epoch: 6| Step: 6
Training loss: 2.448991537094116
Validation loss: 2.292673546780822

Epoch: 6| Step: 7
Training loss: 2.405987501144409
Validation loss: 2.276700847892351

Epoch: 6| Step: 8
Training loss: 2.2189412117004395
Validation loss: 2.2753765083128408

Epoch: 6| Step: 9
Training loss: 2.784618616104126
Validation loss: 2.271204685652128

Epoch: 6| Step: 10
Training loss: 2.04878830909729
Validation loss: 2.2740545144645115

Epoch: 6| Step: 11
Training loss: 2.5104668140411377
Validation loss: 2.3032509152607252

Epoch: 6| Step: 12
Training loss: 2.6788699626922607
Validation loss: 2.294203278838947

Epoch: 6| Step: 13
Training loss: 2.071681499481201
Validation loss: 2.318569334604407

Epoch: 163| Step: 0
Training loss: 2.8485753536224365
Validation loss: 2.321633231255316

Epoch: 6| Step: 1
Training loss: 2.413069725036621
Validation loss: 2.332367630415065

Epoch: 6| Step: 2
Training loss: 2.4981765747070312
Validation loss: 2.3341559261404057

Epoch: 6| Step: 3
Training loss: 2.583501100540161
Validation loss: 2.3819020614829114

Epoch: 6| Step: 4
Training loss: 2.501607656478882
Validation loss: 2.3990331337016118

Epoch: 6| Step: 5
Training loss: 1.3584234714508057
Validation loss: 2.3838320547534573

Epoch: 6| Step: 6
Training loss: 2.46571683883667
Validation loss: 2.3903974743299585

Epoch: 6| Step: 7
Training loss: 2.410651206970215
Validation loss: 2.345142336301906

Epoch: 6| Step: 8
Training loss: 3.1491150856018066
Validation loss: 2.324556940345354

Epoch: 6| Step: 9
Training loss: 2.761852502822876
Validation loss: 2.3213214117993592

Epoch: 6| Step: 10
Training loss: 2.3212122917175293
Validation loss: 2.306720990006642

Epoch: 6| Step: 11
Training loss: 2.129457712173462
Validation loss: 2.2984879529604347

Epoch: 6| Step: 12
Training loss: 2.720461368560791
Validation loss: 2.2912937351452407

Epoch: 6| Step: 13
Training loss: 2.8143844604492188
Validation loss: 2.277670250144056

Epoch: 164| Step: 0
Training loss: 2.473811149597168
Validation loss: 2.274799270014609

Epoch: 6| Step: 1
Training loss: 2.327700138092041
Validation loss: 2.2718635989773657

Epoch: 6| Step: 2
Training loss: 1.9648479223251343
Validation loss: 2.2702905644652662

Epoch: 6| Step: 3
Training loss: 2.593248128890991
Validation loss: 2.2702002268965527

Epoch: 6| Step: 4
Training loss: 2.3451356887817383
Validation loss: 2.266769770653017

Epoch: 6| Step: 5
Training loss: 2.541666269302368
Validation loss: 2.257240249264625

Epoch: 6| Step: 6
Training loss: 2.9065065383911133
Validation loss: 2.2532176715071484

Epoch: 6| Step: 7
Training loss: 2.3866748809814453
Validation loss: 2.2654000789888444

Epoch: 6| Step: 8
Training loss: 2.6424031257629395
Validation loss: 2.2661172856566725

Epoch: 6| Step: 9
Training loss: 1.8386406898498535
Validation loss: 2.2665923180118686

Epoch: 6| Step: 10
Training loss: 2.95458984375
Validation loss: 2.2716585256720103

Epoch: 6| Step: 11
Training loss: 2.723470687866211
Validation loss: 2.2722861612996748

Epoch: 6| Step: 12
Training loss: 3.207329273223877
Validation loss: 2.2672058882251864

Epoch: 6| Step: 13
Training loss: 1.8335503339767456
Validation loss: 2.2628728881958993

Epoch: 165| Step: 0
Training loss: 2.3022196292877197
Validation loss: 2.2631249299613376

Epoch: 6| Step: 1
Training loss: 1.8638218641281128
Validation loss: 2.2565678447805424

Epoch: 6| Step: 2
Training loss: 2.3471436500549316
Validation loss: 2.2541456478898243

Epoch: 6| Step: 3
Training loss: 2.4947361946105957
Validation loss: 2.247714017027168

Epoch: 6| Step: 4
Training loss: 1.990921974182129
Validation loss: 2.2514819124693513

Epoch: 6| Step: 5
Training loss: 2.804069995880127
Validation loss: 2.2476457062587945

Epoch: 6| Step: 6
Training loss: 2.3695425987243652
Validation loss: 2.2553076026260213

Epoch: 6| Step: 7
Training loss: 2.973442316055298
Validation loss: 2.262233498275921

Epoch: 6| Step: 8
Training loss: 2.474520206451416
Validation loss: 2.2903623286113945

Epoch: 6| Step: 9
Training loss: 3.226388931274414
Validation loss: 2.3031619415488294

Epoch: 6| Step: 10
Training loss: 3.045217990875244
Validation loss: 2.310082447144293

Epoch: 6| Step: 11
Training loss: 2.745753288269043
Validation loss: 2.2941754761562554

Epoch: 6| Step: 12
Training loss: 2.2267379760742188
Validation loss: 2.2988796772495395

Epoch: 6| Step: 13
Training loss: 1.7118116617202759
Validation loss: 2.288290818532308

Epoch: 166| Step: 0
Training loss: 2.4421353340148926
Validation loss: 2.295504246988604

Epoch: 6| Step: 1
Training loss: 2.9421966075897217
Validation loss: 2.298491552311887

Epoch: 6| Step: 2
Training loss: 2.2742269039154053
Validation loss: 2.3022348880767822

Epoch: 6| Step: 3
Training loss: 2.6925621032714844
Validation loss: 2.2863064145529144

Epoch: 6| Step: 4
Training loss: 2.9048264026641846
Validation loss: 2.279402791812856

Epoch: 6| Step: 5
Training loss: 2.77872371673584
Validation loss: 2.2774919925197477

Epoch: 6| Step: 6
Training loss: 1.7270128726959229
Validation loss: 2.2720193452732538

Epoch: 6| Step: 7
Training loss: 2.1248717308044434
Validation loss: 2.2618722941285823

Epoch: 6| Step: 8
Training loss: 2.547903060913086
Validation loss: 2.261924538561093

Epoch: 6| Step: 9
Training loss: 2.0029022693634033
Validation loss: 2.2596770717251684

Epoch: 6| Step: 10
Training loss: 3.2565834522247314
Validation loss: 2.252689430790563

Epoch: 6| Step: 11
Training loss: 2.5828702449798584
Validation loss: 2.2630662379726285

Epoch: 6| Step: 12
Training loss: 1.9838075637817383
Validation loss: 2.2686180965874785

Epoch: 6| Step: 13
Training loss: 2.619579792022705
Validation loss: 2.2629275655233734

Epoch: 167| Step: 0
Training loss: 2.057006597518921
Validation loss: 2.2752542123999646

Epoch: 6| Step: 1
Training loss: 3.0779731273651123
Validation loss: 2.2746392129569926

Epoch: 6| Step: 2
Training loss: 1.7537147998809814
Validation loss: 2.283019006893199

Epoch: 6| Step: 3
Training loss: 3.3149030208587646
Validation loss: 2.278442918613393

Epoch: 6| Step: 4
Training loss: 2.149947166442871
Validation loss: 2.2847626619441535

Epoch: 6| Step: 5
Training loss: 2.15547513961792
Validation loss: 2.2813636538802937

Epoch: 6| Step: 6
Training loss: 3.020569086074829
Validation loss: 2.2902712334868727

Epoch: 6| Step: 7
Training loss: 2.4739441871643066
Validation loss: 2.2911998610342703

Epoch: 6| Step: 8
Training loss: 1.9993681907653809
Validation loss: 2.279978862372778

Epoch: 6| Step: 9
Training loss: 2.740868091583252
Validation loss: 2.279652537838105

Epoch: 6| Step: 10
Training loss: 2.1389431953430176
Validation loss: 2.279736944424209

Epoch: 6| Step: 11
Training loss: 2.840984344482422
Validation loss: 2.2796096442848124

Epoch: 6| Step: 12
Training loss: 2.935238838195801
Validation loss: 2.2563362967583442

Epoch: 6| Step: 13
Training loss: 1.7058615684509277
Validation loss: 2.2546983124107443

Epoch: 168| Step: 0
Training loss: 2.676252841949463
Validation loss: 2.2599274291787097

Epoch: 6| Step: 1
Training loss: 2.2451066970825195
Validation loss: 2.27469067676093

Epoch: 6| Step: 2
Training loss: 2.4213719367980957
Validation loss: 2.2857450951812086

Epoch: 6| Step: 3
Training loss: 2.790858268737793
Validation loss: 2.3072813864677184

Epoch: 6| Step: 4
Training loss: 2.4511375427246094
Validation loss: 2.30682046182694

Epoch: 6| Step: 5
Training loss: 2.594680070877075
Validation loss: 2.3215701118592293

Epoch: 6| Step: 6
Training loss: 3.2515673637390137
Validation loss: 2.324526879095262

Epoch: 6| Step: 7
Training loss: 2.2122390270233154
Validation loss: 2.3139253713751353

Epoch: 6| Step: 8
Training loss: 3.0072646141052246
Validation loss: 2.2970128649024555

Epoch: 6| Step: 9
Training loss: 2.1335580348968506
Validation loss: 2.287708354252641

Epoch: 6| Step: 10
Training loss: 2.268510341644287
Validation loss: 2.27960539889592

Epoch: 6| Step: 11
Training loss: 2.505323886871338
Validation loss: 2.268156151617727

Epoch: 6| Step: 12
Training loss: 2.3058040142059326
Validation loss: 2.278693390148942

Epoch: 6| Step: 13
Training loss: 1.9579874277114868
Validation loss: 2.2817011546063166

Epoch: 169| Step: 0
Training loss: 3.0043251514434814
Validation loss: 2.277786344610235

Epoch: 6| Step: 1
Training loss: 2.7528491020202637
Validation loss: 2.268797230976884

Epoch: 6| Step: 2
Training loss: 2.0849828720092773
Validation loss: 2.293029821047219

Epoch: 6| Step: 3
Training loss: 2.8702614307403564
Validation loss: 2.289006836952702

Epoch: 6| Step: 4
Training loss: 1.799931287765503
Validation loss: 2.2878802386663293

Epoch: 6| Step: 5
Training loss: 2.231536626815796
Validation loss: 2.273921807607015

Epoch: 6| Step: 6
Training loss: 3.253441333770752
Validation loss: 2.284595369010843

Epoch: 6| Step: 7
Training loss: 3.008852005004883
Validation loss: 2.266660608271117

Epoch: 6| Step: 8
Training loss: 2.5489554405212402
Validation loss: 2.2629343386619323

Epoch: 6| Step: 9
Training loss: 1.394599437713623
Validation loss: 2.262509963845694

Epoch: 6| Step: 10
Training loss: 2.501887798309326
Validation loss: 2.264821373006349

Epoch: 6| Step: 11
Training loss: 1.995509147644043
Validation loss: 2.249882536549722

Epoch: 6| Step: 12
Training loss: 2.9279489517211914
Validation loss: 2.263705053637105

Epoch: 6| Step: 13
Training loss: 2.2460944652557373
Validation loss: 2.2543849688704296

Epoch: 170| Step: 0
Training loss: 1.997894048690796
Validation loss: 2.261568589877057

Epoch: 6| Step: 1
Training loss: 3.003330707550049
Validation loss: 2.2540584238626624

Epoch: 6| Step: 2
Training loss: 2.5388894081115723
Validation loss: 2.2719107853469027

Epoch: 6| Step: 3
Training loss: 1.9284358024597168
Validation loss: 2.2695605806125108

Epoch: 6| Step: 4
Training loss: 3.0688083171844482
Validation loss: 2.272782882054647

Epoch: 6| Step: 5
Training loss: 1.9487724304199219
Validation loss: 2.2729912111836095

Epoch: 6| Step: 6
Training loss: 2.2833809852600098
Validation loss: 2.2757695951769428

Epoch: 6| Step: 7
Training loss: 2.6708412170410156
Validation loss: 2.254826802079396

Epoch: 6| Step: 8
Training loss: 2.6378860473632812
Validation loss: 2.250440523188601

Epoch: 6| Step: 9
Training loss: 2.2578060626983643
Validation loss: 2.258172950436992

Epoch: 6| Step: 10
Training loss: 3.1082816123962402
Validation loss: 2.262280438535957

Epoch: 6| Step: 11
Training loss: 2.874051570892334
Validation loss: 2.2524768472999654

Epoch: 6| Step: 12
Training loss: 2.0576016902923584
Validation loss: 2.2501834464329544

Epoch: 6| Step: 13
Training loss: 1.7485013008117676
Validation loss: 2.258018739761845

Epoch: 171| Step: 0
Training loss: 2.334949016571045
Validation loss: 2.241625214135775

Epoch: 6| Step: 1
Training loss: 2.3755908012390137
Validation loss: 2.2570808984900035

Epoch: 6| Step: 2
Training loss: 2.6619701385498047
Validation loss: 2.2555515227779264

Epoch: 6| Step: 3
Training loss: 3.161158323287964
Validation loss: 2.2567218529280795

Epoch: 6| Step: 4
Training loss: 2.3921048641204834
Validation loss: 2.2616185193420737

Epoch: 6| Step: 5
Training loss: 2.078664541244507
Validation loss: 2.2576394632298458

Epoch: 6| Step: 6
Training loss: 2.1562612056732178
Validation loss: 2.2751646400779806

Epoch: 6| Step: 7
Training loss: 2.468163013458252
Validation loss: 2.275043677258235

Epoch: 6| Step: 8
Training loss: 2.374318838119507
Validation loss: 2.2914656054589058

Epoch: 6| Step: 9
Training loss: 3.057532787322998
Validation loss: 2.3104101227175806

Epoch: 6| Step: 10
Training loss: 3.007030725479126
Validation loss: 2.308852239321637

Epoch: 6| Step: 11
Training loss: 2.5096120834350586
Validation loss: 2.3210321728901198

Epoch: 6| Step: 12
Training loss: 1.8452873229980469
Validation loss: 2.308402781845421

Epoch: 6| Step: 13
Training loss: 2.1550910472869873
Validation loss: 2.3020456401250695

Epoch: 172| Step: 0
Training loss: 2.3343851566314697
Validation loss: 2.29263807881263

Epoch: 6| Step: 1
Training loss: 2.783271312713623
Validation loss: 2.288486898586314

Epoch: 6| Step: 2
Training loss: 2.94525408744812
Validation loss: 2.278110134986139

Epoch: 6| Step: 3
Training loss: 2.343305826187134
Validation loss: 2.2540474899353518

Epoch: 6| Step: 4
Training loss: 2.6130051612854004
Validation loss: 2.2590395583901355

Epoch: 6| Step: 5
Training loss: 2.562946319580078
Validation loss: 2.2492182113791026

Epoch: 6| Step: 6
Training loss: 1.7641949653625488
Validation loss: 2.244999113903251

Epoch: 6| Step: 7
Training loss: 2.3006362915039062
Validation loss: 2.2487684911297214

Epoch: 6| Step: 8
Training loss: 2.9302351474761963
Validation loss: 2.246777390920988

Epoch: 6| Step: 9
Training loss: 2.165341854095459
Validation loss: 2.251585452787338

Epoch: 6| Step: 10
Training loss: 2.039607048034668
Validation loss: 2.258025914110163

Epoch: 6| Step: 11
Training loss: 3.0879640579223633
Validation loss: 2.2510620932425223

Epoch: 6| Step: 12
Training loss: 2.282064199447632
Validation loss: 2.266416101045506

Epoch: 6| Step: 13
Training loss: 2.274561882019043
Validation loss: 2.2614419562842256

Epoch: 173| Step: 0
Training loss: 3.2330706119537354
Validation loss: 2.2749691265885548

Epoch: 6| Step: 1
Training loss: 2.4302330017089844
Validation loss: 2.2977289948412167

Epoch: 6| Step: 2
Training loss: 3.031874179840088
Validation loss: 2.3035440701310352

Epoch: 6| Step: 3
Training loss: 3.1154448986053467
Validation loss: 2.3245147915296656

Epoch: 6| Step: 4
Training loss: 2.2813730239868164
Validation loss: 2.3193824509138703

Epoch: 6| Step: 5
Training loss: 2.4365017414093018
Validation loss: 2.3198318942900626

Epoch: 6| Step: 6
Training loss: 2.3445355892181396
Validation loss: 2.3192765917829288

Epoch: 6| Step: 7
Training loss: 1.9245498180389404
Validation loss: 2.3004029989242554

Epoch: 6| Step: 8
Training loss: 2.2487034797668457
Validation loss: 2.3002684526546027

Epoch: 6| Step: 9
Training loss: 1.8252675533294678
Validation loss: 2.300681059078504

Epoch: 6| Step: 10
Training loss: 2.10078763961792
Validation loss: 2.2969263061400382

Epoch: 6| Step: 11
Training loss: 2.1970741748809814
Validation loss: 2.291528078817552

Epoch: 6| Step: 12
Training loss: 2.8138585090637207
Validation loss: 2.2778044285312777

Epoch: 6| Step: 13
Training loss: 2.8187661170959473
Validation loss: 2.266556224515361

Epoch: 174| Step: 0
Training loss: 2.4894070625305176
Validation loss: 2.261554547535476

Epoch: 6| Step: 1
Training loss: 2.401309013366699
Validation loss: 2.2530466664221978

Epoch: 6| Step: 2
Training loss: 1.9065546989440918
Validation loss: 2.256806404359879

Epoch: 6| Step: 3
Training loss: 2.609301805496216
Validation loss: 2.2510763752845024

Epoch: 6| Step: 4
Training loss: 1.9609359502792358
Validation loss: 2.2421036586966565

Epoch: 6| Step: 5
Training loss: 3.124347686767578
Validation loss: 2.2442668253375637

Epoch: 6| Step: 6
Training loss: 2.283480644226074
Validation loss: 2.256916897271269

Epoch: 6| Step: 7
Training loss: 3.1051747798919678
Validation loss: 2.2787464434100735

Epoch: 6| Step: 8
Training loss: 2.1689562797546387
Validation loss: 2.2779226072372927

Epoch: 6| Step: 9
Training loss: 2.9794840812683105
Validation loss: 2.302114007293537

Epoch: 6| Step: 10
Training loss: 2.4863295555114746
Validation loss: 2.3003476101865052

Epoch: 6| Step: 11
Training loss: 2.412269115447998
Validation loss: 2.2944643036011727

Epoch: 6| Step: 12
Training loss: 1.894844651222229
Validation loss: 2.313765564272481

Epoch: 6| Step: 13
Training loss: 2.8862040042877197
Validation loss: 2.3113036437701155

Epoch: 175| Step: 0
Training loss: 1.7011576890945435
Validation loss: 2.3223499354495796

Epoch: 6| Step: 1
Training loss: 2.646857261657715
Validation loss: 2.3186959220517065

Epoch: 6| Step: 2
Training loss: 2.0294275283813477
Validation loss: 2.3174834148858183

Epoch: 6| Step: 3
Training loss: 2.181448459625244
Validation loss: 2.316620042247157

Epoch: 6| Step: 4
Training loss: 2.3134799003601074
Validation loss: 2.3110849101056337

Epoch: 6| Step: 5
Training loss: 2.5214109420776367
Validation loss: 2.295725789121402

Epoch: 6| Step: 6
Training loss: 3.1542038917541504
Validation loss: 2.2968452181867374

Epoch: 6| Step: 7
Training loss: 2.459224224090576
Validation loss: 2.290888235133181

Epoch: 6| Step: 8
Training loss: 2.0293290615081787
Validation loss: 2.2961438522543958

Epoch: 6| Step: 9
Training loss: 3.2812538146972656
Validation loss: 2.2814190874817553

Epoch: 6| Step: 10
Training loss: 2.577181816101074
Validation loss: 2.2682705079355547

Epoch: 6| Step: 11
Training loss: 2.673290729522705
Validation loss: 2.259589150387754

Epoch: 6| Step: 12
Training loss: 2.540335178375244
Validation loss: 2.2588302909687

Epoch: 6| Step: 13
Training loss: 2.6795127391815186
Validation loss: 2.2728108847013084

Epoch: 176| Step: 0
Training loss: 2.4125053882598877
Validation loss: 2.265743987534636

Epoch: 6| Step: 1
Training loss: 2.791611671447754
Validation loss: 2.2786688035534275

Epoch: 6| Step: 2
Training loss: 2.5007362365722656
Validation loss: 2.2662237587795464

Epoch: 6| Step: 3
Training loss: 2.831127882003784
Validation loss: 2.267846420247068

Epoch: 6| Step: 4
Training loss: 2.4535090923309326
Validation loss: 2.263505299886068

Epoch: 6| Step: 5
Training loss: 2.668203830718994
Validation loss: 2.2673528040609052

Epoch: 6| Step: 6
Training loss: 2.4615252017974854
Validation loss: 2.2607679520883868

Epoch: 6| Step: 7
Training loss: 2.504122018814087
Validation loss: 2.262690131382276

Epoch: 6| Step: 8
Training loss: 2.704444169998169
Validation loss: 2.276108682796519

Epoch: 6| Step: 9
Training loss: 2.308619499206543
Validation loss: 2.277668538913932

Epoch: 6| Step: 10
Training loss: 1.9160456657409668
Validation loss: 2.3008415724641536

Epoch: 6| Step: 11
Training loss: 2.9968550205230713
Validation loss: 2.305148273385981

Epoch: 6| Step: 12
Training loss: 2.7986583709716797
Validation loss: 2.3194367257497643

Epoch: 6| Step: 13
Training loss: 1.7300496101379395
Validation loss: 2.311411460240682

Epoch: 177| Step: 0
Training loss: 3.0131940841674805
Validation loss: 2.3086597445190593

Epoch: 6| Step: 1
Training loss: 2.148406744003296
Validation loss: 2.3235396467229372

Epoch: 6| Step: 2
Training loss: 1.932858943939209
Validation loss: 2.297068129303635

Epoch: 6| Step: 3
Training loss: 2.581951141357422
Validation loss: 2.284512973600818

Epoch: 6| Step: 4
Training loss: 3.132894992828369
Validation loss: 2.267446300034882

Epoch: 6| Step: 5
Training loss: 2.1908633708953857
Validation loss: 2.273171078774237

Epoch: 6| Step: 6
Training loss: 2.2127110958099365
Validation loss: 2.264470197821176

Epoch: 6| Step: 7
Training loss: 3.1738414764404297
Validation loss: 2.269602011608821

Epoch: 6| Step: 8
Training loss: 2.3705484867095947
Validation loss: 2.276200125294347

Epoch: 6| Step: 9
Training loss: 2.486051559448242
Validation loss: 2.253643687053393

Epoch: 6| Step: 10
Training loss: 2.1841087341308594
Validation loss: 2.276335331701463

Epoch: 6| Step: 11
Training loss: 2.830766439437866
Validation loss: 2.285292410081433

Epoch: 6| Step: 12
Training loss: 1.8596742153167725
Validation loss: 2.287837338703935

Epoch: 6| Step: 13
Training loss: 2.5862436294555664
Validation loss: 2.3003649891063733

Epoch: 178| Step: 0
Training loss: 2.69401478767395
Validation loss: 2.305496592675486

Epoch: 6| Step: 1
Training loss: 2.601997137069702
Validation loss: 2.3026961613726873

Epoch: 6| Step: 2
Training loss: 1.7783688306808472
Validation loss: 2.309674452709895

Epoch: 6| Step: 3
Training loss: 2.583888530731201
Validation loss: 2.2905255774016022

Epoch: 6| Step: 4
Training loss: 2.3402764797210693
Validation loss: 2.2885812277434976

Epoch: 6| Step: 5
Training loss: 3.3592395782470703
Validation loss: 2.2939964545670377

Epoch: 6| Step: 6
Training loss: 1.6095516681671143
Validation loss: 2.2914573787361063

Epoch: 6| Step: 7
Training loss: 2.559142589569092
Validation loss: 2.288650053803639

Epoch: 6| Step: 8
Training loss: 2.223214626312256
Validation loss: 2.2918190443387596

Epoch: 6| Step: 9
Training loss: 1.8581995964050293
Validation loss: 2.2770266340624903

Epoch: 6| Step: 10
Training loss: 3.0854313373565674
Validation loss: 2.264976668101485

Epoch: 6| Step: 11
Training loss: 2.617767333984375
Validation loss: 2.2565190856174757

Epoch: 6| Step: 12
Training loss: 2.4729604721069336
Validation loss: 2.251408476983347

Epoch: 6| Step: 13
Training loss: 2.783642292022705
Validation loss: 2.25061362020431

Epoch: 179| Step: 0
Training loss: 2.5777840614318848
Validation loss: 2.2633009879819808

Epoch: 6| Step: 1
Training loss: 2.9784488677978516
Validation loss: 2.275478627092095

Epoch: 6| Step: 2
Training loss: 2.2996416091918945
Validation loss: 2.268498028478315

Epoch: 6| Step: 3
Training loss: 2.9697821140289307
Validation loss: 2.2723981129225863

Epoch: 6| Step: 4
Training loss: 2.237794876098633
Validation loss: 2.268573396949358

Epoch: 6| Step: 5
Training loss: 2.5096170902252197
Validation loss: 2.2802232478254583

Epoch: 6| Step: 6
Training loss: 2.462944507598877
Validation loss: 2.2588058005097094

Epoch: 6| Step: 7
Training loss: 2.066166400909424
Validation loss: 2.2718197837952645

Epoch: 6| Step: 8
Training loss: 2.647524118423462
Validation loss: 2.266668332520352

Epoch: 6| Step: 9
Training loss: 2.4081742763519287
Validation loss: 2.2635603591959965

Epoch: 6| Step: 10
Training loss: 2.489321708679199
Validation loss: 2.267372621003018

Epoch: 6| Step: 11
Training loss: 2.318206787109375
Validation loss: 2.2721363152227094

Epoch: 6| Step: 12
Training loss: 2.153353214263916
Validation loss: 2.2811449266249135

Epoch: 6| Step: 13
Training loss: 1.9479601383209229
Validation loss: 2.283298130958311

Epoch: 180| Step: 0
Training loss: 1.825229525566101
Validation loss: 2.2958763696814097

Epoch: 6| Step: 1
Training loss: 2.5006260871887207
Validation loss: 2.2865306485083794

Epoch: 6| Step: 2
Training loss: 2.8544211387634277
Validation loss: 2.285611629486084

Epoch: 6| Step: 3
Training loss: 2.8461551666259766
Validation loss: 2.2737094176712858

Epoch: 6| Step: 4
Training loss: 2.222658634185791
Validation loss: 2.2724969515236477

Epoch: 6| Step: 5
Training loss: 2.391286849975586
Validation loss: 2.253026472624912

Epoch: 6| Step: 6
Training loss: 2.8137292861938477
Validation loss: 2.2590022035824355

Epoch: 6| Step: 7
Training loss: 2.863351821899414
Validation loss: 2.2462899710542414

Epoch: 6| Step: 8
Training loss: 2.0435190200805664
Validation loss: 2.2324956488865677

Epoch: 6| Step: 9
Training loss: 2.8510031700134277
Validation loss: 2.237781786149548

Epoch: 6| Step: 10
Training loss: 2.571758985519409
Validation loss: 2.2338499381978023

Epoch: 6| Step: 11
Training loss: 2.0228989124298096
Validation loss: 2.23984980967737

Epoch: 6| Step: 12
Training loss: 2.204713821411133
Validation loss: 2.236108051833286

Epoch: 6| Step: 13
Training loss: 2.091991901397705
Validation loss: 2.2350952804729505

Epoch: 181| Step: 0
Training loss: 2.6089138984680176
Validation loss: 2.245732858616819

Epoch: 6| Step: 1
Training loss: 1.6866354942321777
Validation loss: 2.238908754881992

Epoch: 6| Step: 2
Training loss: 2.8150789737701416
Validation loss: 2.2392699795384563

Epoch: 6| Step: 3
Training loss: 2.9083995819091797
Validation loss: 2.257231330358854

Epoch: 6| Step: 4
Training loss: 2.1435210704803467
Validation loss: 2.2479493618011475

Epoch: 6| Step: 5
Training loss: 2.3282928466796875
Validation loss: 2.2423129081726074

Epoch: 6| Step: 6
Training loss: 2.4356529712677
Validation loss: 2.2617772984248337

Epoch: 6| Step: 7
Training loss: 2.3367185592651367
Validation loss: 2.254086817464521

Epoch: 6| Step: 8
Training loss: 1.6959929466247559
Validation loss: 2.2610729125238236

Epoch: 6| Step: 9
Training loss: 2.358487606048584
Validation loss: 2.274327888283678

Epoch: 6| Step: 10
Training loss: 2.5985846519470215
Validation loss: 2.2708329539145193

Epoch: 6| Step: 11
Training loss: 2.939152240753174
Validation loss: 2.275903530018304

Epoch: 6| Step: 12
Training loss: 2.6751465797424316
Validation loss: 2.2791650090166318

Epoch: 6| Step: 13
Training loss: 2.9028520584106445
Validation loss: 2.2751059891075216

Epoch: 182| Step: 0
Training loss: 2.736097812652588
Validation loss: 2.268315484446864

Epoch: 6| Step: 1
Training loss: 1.969866394996643
Validation loss: 2.2752032972151235

Epoch: 6| Step: 2
Training loss: 2.0680758953094482
Validation loss: 2.2448462670849216

Epoch: 6| Step: 3
Training loss: 2.6502127647399902
Validation loss: 2.245715259223856

Epoch: 6| Step: 4
Training loss: 2.1163883209228516
Validation loss: 2.241495388810353

Epoch: 6| Step: 5
Training loss: 2.156822919845581
Validation loss: 2.2313626773895754

Epoch: 6| Step: 6
Training loss: 2.6394877433776855
Validation loss: 2.24176138318995

Epoch: 6| Step: 7
Training loss: 2.349155902862549
Validation loss: 2.235236644744873

Epoch: 6| Step: 8
Training loss: 2.7107748985290527
Validation loss: 2.233944854428691

Epoch: 6| Step: 9
Training loss: 2.467378616333008
Validation loss: 2.2317713537523822

Epoch: 6| Step: 10
Training loss: 2.5133469104766846
Validation loss: 2.2341772099976898

Epoch: 6| Step: 11
Training loss: 2.9913392066955566
Validation loss: 2.246011551990304

Epoch: 6| Step: 12
Training loss: 2.4367473125457764
Validation loss: 2.2613295201332337

Epoch: 6| Step: 13
Training loss: 2.545212745666504
Validation loss: 2.2845264224595923

Epoch: 183| Step: 0
Training loss: 2.7573766708374023
Validation loss: 2.287907341475128

Epoch: 6| Step: 1
Training loss: 3.1320533752441406
Validation loss: 2.3029147194277857

Epoch: 6| Step: 2
Training loss: 1.9454386234283447
Validation loss: 2.293064912160238

Epoch: 6| Step: 3
Training loss: 2.0412697792053223
Validation loss: 2.2947303530990437

Epoch: 6| Step: 4
Training loss: 2.5369362831115723
Validation loss: 2.2808194596280336

Epoch: 6| Step: 5
Training loss: 3.075225830078125
Validation loss: 2.276069361676452

Epoch: 6| Step: 6
Training loss: 2.4358482360839844
Validation loss: 2.2730647979244107

Epoch: 6| Step: 7
Training loss: 1.8797789812088013
Validation loss: 2.2522002240662933

Epoch: 6| Step: 8
Training loss: 2.098320245742798
Validation loss: 2.2487652840152865

Epoch: 6| Step: 9
Training loss: 3.0409255027770996
Validation loss: 2.243286044366898

Epoch: 6| Step: 10
Training loss: 2.298586368560791
Validation loss: 2.23340093961326

Epoch: 6| Step: 11
Training loss: 2.8588662147521973
Validation loss: 2.2353691490747596

Epoch: 6| Step: 12
Training loss: 2.29266357421875
Validation loss: 2.231456564318749

Epoch: 6| Step: 13
Training loss: 1.7045658826828003
Validation loss: 2.24540868754028

Epoch: 184| Step: 0
Training loss: 2.2158544063568115
Validation loss: 2.243368564113494

Epoch: 6| Step: 1
Training loss: 2.309194564819336
Validation loss: 2.255000150331887

Epoch: 6| Step: 2
Training loss: 2.6202728748321533
Validation loss: 2.2511920877682265

Epoch: 6| Step: 3
Training loss: 2.169693946838379
Validation loss: 2.2459929502138527

Epoch: 6| Step: 4
Training loss: 2.1450624465942383
Validation loss: 2.2521367611423617

Epoch: 6| Step: 5
Training loss: 2.4086413383483887
Validation loss: 2.238171544126285

Epoch: 6| Step: 6
Training loss: 2.7548604011535645
Validation loss: 2.2420926376055648

Epoch: 6| Step: 7
Training loss: 2.5818939208984375
Validation loss: 2.238871077055572

Epoch: 6| Step: 8
Training loss: 2.7919387817382812
Validation loss: 2.2279243366692656

Epoch: 6| Step: 9
Training loss: 2.593355178833008
Validation loss: 2.215415446988998

Epoch: 6| Step: 10
Training loss: 2.277475118637085
Validation loss: 2.2068080004825386

Epoch: 6| Step: 11
Training loss: 2.1801977157592773
Validation loss: 2.2083446095066686

Epoch: 6| Step: 12
Training loss: 2.5860795974731445
Validation loss: 2.2200226655570408

Epoch: 6| Step: 13
Training loss: 3.0400257110595703
Validation loss: 2.2322691794364684

Epoch: 185| Step: 0
Training loss: 2.8454816341400146
Validation loss: 2.250204760541198

Epoch: 6| Step: 1
Training loss: 1.8929948806762695
Validation loss: 2.253391783724549

Epoch: 6| Step: 2
Training loss: 2.4523255825042725
Validation loss: 2.2704911219176425

Epoch: 6| Step: 3
Training loss: 2.299908399581909
Validation loss: 2.294961937012211

Epoch: 6| Step: 4
Training loss: 1.5894098281860352
Validation loss: 2.292636622664749

Epoch: 6| Step: 5
Training loss: 2.5688586235046387
Validation loss: 2.2770959728507587

Epoch: 6| Step: 6
Training loss: 2.6914825439453125
Validation loss: 2.269494997557773

Epoch: 6| Step: 7
Training loss: 3.3392560482025146
Validation loss: 2.2741848268816547

Epoch: 6| Step: 8
Training loss: 2.556708335876465
Validation loss: 2.2529857902116674

Epoch: 6| Step: 9
Training loss: 2.4425899982452393
Validation loss: 2.2485741543513473

Epoch: 6| Step: 10
Training loss: 2.5437588691711426
Validation loss: 2.2419003825033865

Epoch: 6| Step: 11
Training loss: 2.2982616424560547
Validation loss: 2.252462997231432

Epoch: 6| Step: 12
Training loss: 2.5424227714538574
Validation loss: 2.2506750193975305

Epoch: 6| Step: 13
Training loss: 2.1694042682647705
Validation loss: 2.2480641436833206

Epoch: 186| Step: 0
Training loss: 2.8983702659606934
Validation loss: 2.2511459653095534

Epoch: 6| Step: 1
Training loss: 2.6401171684265137
Validation loss: 2.2501963312907884

Epoch: 6| Step: 2
Training loss: 1.9287084341049194
Validation loss: 2.2495133902436946

Epoch: 6| Step: 3
Training loss: 2.419494152069092
Validation loss: 2.2486402821797196

Epoch: 6| Step: 4
Training loss: 2.1670587062835693
Validation loss: 2.2414044077678392

Epoch: 6| Step: 5
Training loss: 2.207000494003296
Validation loss: 2.2413969091189805

Epoch: 6| Step: 6
Training loss: 2.7238621711730957
Validation loss: 2.225694760199516

Epoch: 6| Step: 7
Training loss: 2.025515556335449
Validation loss: 2.2080471618201143

Epoch: 6| Step: 8
Training loss: 2.8292675018310547
Validation loss: 2.2246049142652944

Epoch: 6| Step: 9
Training loss: 2.742640972137451
Validation loss: 2.227834295201045

Epoch: 6| Step: 10
Training loss: 2.8182010650634766
Validation loss: 2.253840546454153

Epoch: 6| Step: 11
Training loss: 2.704105854034424
Validation loss: 2.261627479266095

Epoch: 6| Step: 12
Training loss: 2.0245327949523926
Validation loss: 2.2770525511874946

Epoch: 6| Step: 13
Training loss: 2.286444664001465
Validation loss: 2.281584603812105

Epoch: 187| Step: 0
Training loss: 2.8160548210144043
Validation loss: 2.2720035353014545

Epoch: 6| Step: 1
Training loss: 2.871640205383301
Validation loss: 2.289258349326349

Epoch: 6| Step: 2
Training loss: 2.3695693016052246
Validation loss: 2.285276407836586

Epoch: 6| Step: 3
Training loss: 2.253077983856201
Validation loss: 2.2942499652985604

Epoch: 6| Step: 4
Training loss: 2.1322720050811768
Validation loss: 2.307150935613981

Epoch: 6| Step: 5
Training loss: 2.2082128524780273
Validation loss: 2.3038803685096

Epoch: 6| Step: 6
Training loss: 2.910095453262329
Validation loss: 2.3061547381903535

Epoch: 6| Step: 7
Training loss: 2.4752283096313477
Validation loss: 2.3065772928217405

Epoch: 6| Step: 8
Training loss: 2.257441520690918
Validation loss: 2.2980600915929323

Epoch: 6| Step: 9
Training loss: 2.3183979988098145
Validation loss: 2.277804051676104

Epoch: 6| Step: 10
Training loss: 2.7545716762542725
Validation loss: 2.2731760522370696

Epoch: 6| Step: 11
Training loss: 2.3359375
Validation loss: 2.2501120874958653

Epoch: 6| Step: 12
Training loss: 2.153903007507324
Validation loss: 2.2372932510991252

Epoch: 6| Step: 13
Training loss: 2.496497631072998
Validation loss: 2.237732038703016

Epoch: 188| Step: 0
Training loss: 2.6362972259521484
Validation loss: 2.247958057670183

Epoch: 6| Step: 1
Training loss: 2.335733413696289
Validation loss: 2.249663153002339

Epoch: 6| Step: 2
Training loss: 2.4141929149627686
Validation loss: 2.257246571202432

Epoch: 6| Step: 3
Training loss: 2.5856285095214844
Validation loss: 2.26018859494117

Epoch: 6| Step: 4
Training loss: 2.487576723098755
Validation loss: 2.264781344321466

Epoch: 6| Step: 5
Training loss: 1.7808107137680054
Validation loss: 2.261927689275434

Epoch: 6| Step: 6
Training loss: 2.8070621490478516
Validation loss: 2.270392846035701

Epoch: 6| Step: 7
Training loss: 2.601740837097168
Validation loss: 2.271609006389495

Epoch: 6| Step: 8
Training loss: 2.4654135704040527
Validation loss: 2.263175102972215

Epoch: 6| Step: 9
Training loss: 2.716644525527954
Validation loss: 2.266342629668533

Epoch: 6| Step: 10
Training loss: 2.3106164932250977
Validation loss: 2.252431695179273

Epoch: 6| Step: 11
Training loss: 2.053274393081665
Validation loss: 2.255577248911704

Epoch: 6| Step: 12
Training loss: 2.931281328201294
Validation loss: 2.2292114278321624

Epoch: 6| Step: 13
Training loss: 2.642491340637207
Validation loss: 2.238334596797984

Epoch: 189| Step: 0
Training loss: 2.7483668327331543
Validation loss: 2.2391800624068066

Epoch: 6| Step: 1
Training loss: 2.7406225204467773
Validation loss: 2.242309508785125

Epoch: 6| Step: 2
Training loss: 2.0675714015960693
Validation loss: 2.2506557895291235

Epoch: 6| Step: 3
Training loss: 2.1400556564331055
Validation loss: 2.245290237088357

Epoch: 6| Step: 4
Training loss: 3.1940770149230957
Validation loss: 2.256003136275917

Epoch: 6| Step: 5
Training loss: 2.4009857177734375
Validation loss: 2.2699418170477754

Epoch: 6| Step: 6
Training loss: 2.4595794677734375
Validation loss: 2.274756611034434

Epoch: 6| Step: 7
Training loss: 2.697625160217285
Validation loss: 2.288016544875278

Epoch: 6| Step: 8
Training loss: 2.7502248287200928
Validation loss: 2.288077849213795

Epoch: 6| Step: 9
Training loss: 2.3652610778808594
Validation loss: 2.2845417453396704

Epoch: 6| Step: 10
Training loss: 1.5403482913970947
Validation loss: 2.267962139139893

Epoch: 6| Step: 11
Training loss: 2.986987590789795
Validation loss: 2.252456934221329

Epoch: 6| Step: 12
Training loss: 1.9876344203948975
Validation loss: 2.2292385793501333

Epoch: 6| Step: 13
Training loss: 2.2405176162719727
Validation loss: 2.2314702259596957

Epoch: 190| Step: 0
Training loss: 1.9035706520080566
Validation loss: 2.231604447928808

Epoch: 6| Step: 1
Training loss: 2.4814467430114746
Validation loss: 2.2289793337545087

Epoch: 6| Step: 2
Training loss: 2.2368500232696533
Validation loss: 2.231531386734337

Epoch: 6| Step: 3
Training loss: 1.7132174968719482
Validation loss: 2.2336437753451768

Epoch: 6| Step: 4
Training loss: 2.139631748199463
Validation loss: 2.2341558292347896

Epoch: 6| Step: 5
Training loss: 2.350851535797119
Validation loss: 2.2494855644882366

Epoch: 6| Step: 6
Training loss: 2.497643232345581
Validation loss: 2.265128484336279

Epoch: 6| Step: 7
Training loss: 2.869971513748169
Validation loss: 2.2793869972229004

Epoch: 6| Step: 8
Training loss: 2.1446142196655273
Validation loss: 2.2891406448938514

Epoch: 6| Step: 9
Training loss: 3.1483163833618164
Validation loss: 2.283999135417323

Epoch: 6| Step: 10
Training loss: 2.320901870727539
Validation loss: 2.30021712728726

Epoch: 6| Step: 11
Training loss: 1.9781992435455322
Validation loss: 2.2981201192384124

Epoch: 6| Step: 12
Training loss: 3.1288037300109863
Validation loss: 2.2969232733531664

Epoch: 6| Step: 13
Training loss: 3.852431058883667
Validation loss: 2.3027787990467523

Epoch: 191| Step: 0
Training loss: 2.367027997970581
Validation loss: 2.301736057445567

Epoch: 6| Step: 1
Training loss: 2.520334005355835
Validation loss: 2.305133258142779

Epoch: 6| Step: 2
Training loss: 3.2902889251708984
Validation loss: 2.2783101566376223

Epoch: 6| Step: 3
Training loss: 2.6692137718200684
Validation loss: 2.2681966750852522

Epoch: 6| Step: 4
Training loss: 2.3672237396240234
Validation loss: 2.2586780799332487

Epoch: 6| Step: 5
Training loss: 2.248081922531128
Validation loss: 2.22762232442056

Epoch: 6| Step: 6
Training loss: 2.4348361492156982
Validation loss: 2.2314079961469098

Epoch: 6| Step: 7
Training loss: 1.8190206289291382
Validation loss: 2.22132602301977

Epoch: 6| Step: 8
Training loss: 2.4171643257141113
Validation loss: 2.2141957462474866

Epoch: 6| Step: 9
Training loss: 2.5722830295562744
Validation loss: 2.209843494558847

Epoch: 6| Step: 10
Training loss: 2.1580097675323486
Validation loss: 2.2224594187992874

Epoch: 6| Step: 11
Training loss: 2.3480091094970703
Validation loss: 2.2143052957391225

Epoch: 6| Step: 12
Training loss: 2.203504800796509
Validation loss: 2.211603731237432

Epoch: 6| Step: 13
Training loss: 2.824470043182373
Validation loss: 2.2294254020978044

Epoch: 192| Step: 0
Training loss: 1.918954610824585
Validation loss: 2.2270124266224522

Epoch: 6| Step: 1
Training loss: 2.5076982975006104
Validation loss: 2.2474432658123713

Epoch: 6| Step: 2
Training loss: 2.7650258541107178
Validation loss: 2.2490982509428457

Epoch: 6| Step: 3
Training loss: 2.607571840286255
Validation loss: 2.2519878495124077

Epoch: 6| Step: 4
Training loss: 2.3803813457489014
Validation loss: 2.247567976674726

Epoch: 6| Step: 5
Training loss: 2.211308002471924
Validation loss: 2.260082132072859

Epoch: 6| Step: 6
Training loss: 2.3167247772216797
Validation loss: 2.247137684975901

Epoch: 6| Step: 7
Training loss: 2.2790462970733643
Validation loss: 2.250118840125299

Epoch: 6| Step: 8
Training loss: 2.374218463897705
Validation loss: 2.2504063678044144

Epoch: 6| Step: 9
Training loss: 2.5023193359375
Validation loss: 2.23398877984734

Epoch: 6| Step: 10
Training loss: 3.31764817237854
Validation loss: 2.24068146879955

Epoch: 6| Step: 11
Training loss: 2.521533966064453
Validation loss: 2.23368102247997

Epoch: 6| Step: 12
Training loss: 1.9976438283920288
Validation loss: 2.2406482427350936

Epoch: 6| Step: 13
Training loss: 2.4159185886383057
Validation loss: 2.2454787582479496

Epoch: 193| Step: 0
Training loss: 2.6287729740142822
Validation loss: 2.2520660431154313

Epoch: 6| Step: 1
Training loss: 2.9770894050598145
Validation loss: 2.2506319476712133

Epoch: 6| Step: 2
Training loss: 2.7295050621032715
Validation loss: 2.248736766076857

Epoch: 6| Step: 3
Training loss: 1.4322494268417358
Validation loss: 2.2514529048755603

Epoch: 6| Step: 4
Training loss: 2.4764068126678467
Validation loss: 2.2436408214671637

Epoch: 6| Step: 5
Training loss: 2.1713685989379883
Validation loss: 2.2633389760089178

Epoch: 6| Step: 6
Training loss: 2.7614612579345703
Validation loss: 2.2543167657749628

Epoch: 6| Step: 7
Training loss: 2.1287033557891846
Validation loss: 2.26903639301177

Epoch: 6| Step: 8
Training loss: 2.6379666328430176
Validation loss: 2.2612058680544616

Epoch: 6| Step: 9
Training loss: 2.7005481719970703
Validation loss: 2.2747198138185727

Epoch: 6| Step: 10
Training loss: 2.3882241249084473
Validation loss: 2.2661042033985095

Epoch: 6| Step: 11
Training loss: 1.870630145072937
Validation loss: 2.263917492282006

Epoch: 6| Step: 12
Training loss: 2.1609296798706055
Validation loss: 2.2655690562340522

Epoch: 6| Step: 13
Training loss: 3.051823377609253
Validation loss: 2.265660870459772

Epoch: 194| Step: 0
Training loss: 2.781379222869873
Validation loss: 2.2835620603253766

Epoch: 6| Step: 1
Training loss: 2.8220272064208984
Validation loss: 2.2609612557195846

Epoch: 6| Step: 2
Training loss: 2.56300687789917
Validation loss: 2.2452542833102647

Epoch: 6| Step: 3
Training loss: 2.163130283355713
Validation loss: 2.255500273037982

Epoch: 6| Step: 4
Training loss: 2.1882128715515137
Validation loss: 2.2397334729471514

Epoch: 6| Step: 5
Training loss: 1.9742614030838013
Validation loss: 2.2438444270882556

Epoch: 6| Step: 6
Training loss: 3.3479514122009277
Validation loss: 2.2469493689075595

Epoch: 6| Step: 7
Training loss: 1.8832049369812012
Validation loss: 2.229958330431292

Epoch: 6| Step: 8
Training loss: 1.7125300168991089
Validation loss: 2.2515134644764725

Epoch: 6| Step: 9
Training loss: 2.263540267944336
Validation loss: 2.2564133495412846

Epoch: 6| Step: 10
Training loss: 2.2978034019470215
Validation loss: 2.253220914512552

Epoch: 6| Step: 11
Training loss: 2.7468152046203613
Validation loss: 2.2518096303427093

Epoch: 6| Step: 12
Training loss: 2.965273380279541
Validation loss: 2.2502183375820035

Epoch: 6| Step: 13
Training loss: 1.7744349241256714
Validation loss: 2.252453583543019

Epoch: 195| Step: 0
Training loss: 3.458935260772705
Validation loss: 2.2646248763607395

Epoch: 6| Step: 1
Training loss: 2.0156164169311523
Validation loss: 2.2632119988882415

Epoch: 6| Step: 2
Training loss: 1.669877052307129
Validation loss: 2.2710659068117858

Epoch: 6| Step: 3
Training loss: 2.4627771377563477
Validation loss: 2.3017942995153446

Epoch: 6| Step: 4
Training loss: 1.934361219406128
Validation loss: 2.303981747678531

Epoch: 6| Step: 5
Training loss: 2.5817835330963135
Validation loss: 2.3029806075557584

Epoch: 6| Step: 6
Training loss: 1.5031404495239258
Validation loss: 2.308087989848147

Epoch: 6| Step: 7
Training loss: 2.168199062347412
Validation loss: 2.3166561331800235

Epoch: 6| Step: 8
Training loss: 2.6110076904296875
Validation loss: 2.3168227749486126

Epoch: 6| Step: 9
Training loss: 2.818913221359253
Validation loss: 2.3113320104537474

Epoch: 6| Step: 10
Training loss: 2.522364854812622
Validation loss: 2.2952657566275647

Epoch: 6| Step: 11
Training loss: 2.638021945953369
Validation loss: 2.2704182004415863

Epoch: 6| Step: 12
Training loss: 2.8935346603393555
Validation loss: 2.256791853135632

Epoch: 6| Step: 13
Training loss: 3.123157024383545
Validation loss: 2.2416991520953435

Epoch: 196| Step: 0
Training loss: 3.2096405029296875
Validation loss: 2.2426578434564735

Epoch: 6| Step: 1
Training loss: 3.1731791496276855
Validation loss: 2.2412511302578833

Epoch: 6| Step: 2
Training loss: 2.311622142791748
Validation loss: 2.2406980991363525

Epoch: 6| Step: 3
Training loss: 1.9136202335357666
Validation loss: 2.230152835128128

Epoch: 6| Step: 4
Training loss: 2.338902473449707
Validation loss: 2.230683575394333

Epoch: 6| Step: 5
Training loss: 2.412687063217163
Validation loss: 2.235630981383785

Epoch: 6| Step: 6
Training loss: 2.4217529296875
Validation loss: 2.204770267650645

Epoch: 6| Step: 7
Training loss: 3.045210838317871
Validation loss: 2.2033106819275887

Epoch: 6| Step: 8
Training loss: 2.1990790367126465
Validation loss: 2.208244505748954

Epoch: 6| Step: 9
Training loss: 2.0002574920654297
Validation loss: 2.1986804867303498

Epoch: 6| Step: 10
Training loss: 2.1239171028137207
Validation loss: 2.214909763746364

Epoch: 6| Step: 11
Training loss: 2.5249216556549072
Validation loss: 2.21996441066906

Epoch: 6| Step: 12
Training loss: 2.260075569152832
Validation loss: 2.21540972622492

Epoch: 6| Step: 13
Training loss: 2.000291109085083
Validation loss: 2.2308176922541794

Epoch: 197| Step: 0
Training loss: 1.8120667934417725
Validation loss: 2.2508653953511226

Epoch: 6| Step: 1
Training loss: 2.297201156616211
Validation loss: 2.2656444016323296

Epoch: 6| Step: 2
Training loss: 1.6369394063949585
Validation loss: 2.265006842151765

Epoch: 6| Step: 3
Training loss: 2.0009231567382812
Validation loss: 2.275332058629682

Epoch: 6| Step: 4
Training loss: 2.433418035507202
Validation loss: 2.258693120812857

Epoch: 6| Step: 5
Training loss: 2.9781150817871094
Validation loss: 2.254737987313219

Epoch: 6| Step: 6
Training loss: 2.5051913261413574
Validation loss: 2.2489463693352154

Epoch: 6| Step: 7
Training loss: 2.45750093460083
Validation loss: 2.2496091024850005

Epoch: 6| Step: 8
Training loss: 3.1114587783813477
Validation loss: 2.2501843693435832

Epoch: 6| Step: 9
Training loss: 2.062316417694092
Validation loss: 2.253787959775617

Epoch: 6| Step: 10
Training loss: 2.9540886878967285
Validation loss: 2.247540861047724

Epoch: 6| Step: 11
Training loss: 2.3994901180267334
Validation loss: 2.251701860017674

Epoch: 6| Step: 12
Training loss: 2.68646502494812
Validation loss: 2.2612401131660707

Epoch: 6| Step: 13
Training loss: 2.626077890396118
Validation loss: 2.247925619925222

Epoch: 198| Step: 0
Training loss: 3.093421697616577
Validation loss: 2.2604694751001175

Epoch: 6| Step: 1
Training loss: 2.965177536010742
Validation loss: 2.2641170947782454

Epoch: 6| Step: 2
Training loss: 2.163379669189453
Validation loss: 2.2720351219177246

Epoch: 6| Step: 3
Training loss: 2.40981388092041
Validation loss: 2.263515264757218

Epoch: 6| Step: 4
Training loss: 1.577404499053955
Validation loss: 2.271736693638627

Epoch: 6| Step: 5
Training loss: 2.538789749145508
Validation loss: 2.2621797951318885

Epoch: 6| Step: 6
Training loss: 1.754966378211975
Validation loss: 2.258713729919926

Epoch: 6| Step: 7
Training loss: 2.413374662399292
Validation loss: 2.2616694306814544

Epoch: 6| Step: 8
Training loss: 2.476684808731079
Validation loss: 2.2645948753562024

Epoch: 6| Step: 9
Training loss: 2.368224620819092
Validation loss: 2.2650958671364734

Epoch: 6| Step: 10
Training loss: 2.0847415924072266
Validation loss: 2.262971249959802

Epoch: 6| Step: 11
Training loss: 3.3105483055114746
Validation loss: 2.2527585773057837

Epoch: 6| Step: 12
Training loss: 1.8432607650756836
Validation loss: 2.2576790907049693

Epoch: 6| Step: 13
Training loss: 2.8496501445770264
Validation loss: 2.2680212836111746

Epoch: 199| Step: 0
Training loss: 1.9933786392211914
Validation loss: 2.264870907670708

Epoch: 6| Step: 1
Training loss: 1.9434468746185303
Validation loss: 2.282073300371888

Epoch: 6| Step: 2
Training loss: 2.2387442588806152
Validation loss: 2.294309077724334

Epoch: 6| Step: 3
Training loss: 3.0203254222869873
Validation loss: 2.2906900682756977

Epoch: 6| Step: 4
Training loss: 1.969947338104248
Validation loss: 2.3098107973734536

Epoch: 6| Step: 5
Training loss: 2.005466938018799
Validation loss: 2.3249849273312475

Epoch: 6| Step: 6
Training loss: 2.7037556171417236
Validation loss: 2.3273486347608667

Epoch: 6| Step: 7
Training loss: 2.4765095710754395
Validation loss: 2.3358723578914518

Epoch: 6| Step: 8
Training loss: 2.74680233001709
Validation loss: 2.329555544801938

Epoch: 6| Step: 9
Training loss: 2.4324212074279785
Validation loss: 2.319038906405049

Epoch: 6| Step: 10
Training loss: 2.3124208450317383
Validation loss: 2.2807314139540478

Epoch: 6| Step: 11
Training loss: 3.2626237869262695
Validation loss: 2.2425115005944365

Epoch: 6| Step: 12
Training loss: 2.1316494941711426
Validation loss: 2.2284525671312885

Epoch: 6| Step: 13
Training loss: 3.228724718093872
Validation loss: 2.2258436551658054

Epoch: 200| Step: 0
Training loss: 3.023934841156006
Validation loss: 2.210109081319583

Epoch: 6| Step: 1
Training loss: 2.3829076290130615
Validation loss: 2.207428680953159

Epoch: 6| Step: 2
Training loss: 2.523715019226074
Validation loss: 2.2055529381639216

Epoch: 6| Step: 3
Training loss: 2.1129493713378906
Validation loss: 2.209923328891877

Epoch: 6| Step: 4
Training loss: 2.888547658920288
Validation loss: 2.2178845097941737

Epoch: 6| Step: 5
Training loss: 1.9255695343017578
Validation loss: 2.218197786679832

Epoch: 6| Step: 6
Training loss: 2.508892059326172
Validation loss: 2.2285167581291607

Epoch: 6| Step: 7
Training loss: 2.4323081970214844
Validation loss: 2.23839206593011

Epoch: 6| Step: 8
Training loss: 3.2622387409210205
Validation loss: 2.2303506148758756

Epoch: 6| Step: 9
Training loss: 2.5034093856811523
Validation loss: 2.2320281818348873

Epoch: 6| Step: 10
Training loss: 2.0610225200653076
Validation loss: 2.215061528708345

Epoch: 6| Step: 11
Training loss: 2.233956813812256
Validation loss: 2.2282249748065905

Epoch: 6| Step: 12
Training loss: 1.6740760803222656
Validation loss: 2.2275966623777985

Epoch: 6| Step: 13
Training loss: 2.317760944366455
Validation loss: 2.234325844754455

Epoch: 201| Step: 0
Training loss: 2.923206329345703
Validation loss: 2.225655722361739

Epoch: 6| Step: 1
Training loss: 2.7086148262023926
Validation loss: 2.222923422372469

Epoch: 6| Step: 2
Training loss: 2.557297706604004
Validation loss: 2.2314662394985074

Epoch: 6| Step: 3
Training loss: 2.5934886932373047
Validation loss: 2.236024484839491

Epoch: 6| Step: 4
Training loss: 1.1750277280807495
Validation loss: 2.245182878227644

Epoch: 6| Step: 5
Training loss: 2.5279831886291504
Validation loss: 2.241321861103017

Epoch: 6| Step: 6
Training loss: 2.1238512992858887
Validation loss: 2.2565091527918333

Epoch: 6| Step: 7
Training loss: 2.952667713165283
Validation loss: 2.2583462756167174

Epoch: 6| Step: 8
Training loss: 1.6864511966705322
Validation loss: 2.262921631977122

Epoch: 6| Step: 9
Training loss: 2.7318809032440186
Validation loss: 2.2614072984264744

Epoch: 6| Step: 10
Training loss: 2.3381285667419434
Validation loss: 2.255868432342365

Epoch: 6| Step: 11
Training loss: 2.938668727874756
Validation loss: 2.271160738442534

Epoch: 6| Step: 12
Training loss: 1.930267095565796
Validation loss: 2.28186906537702

Epoch: 6| Step: 13
Training loss: 2.4158313274383545
Validation loss: 2.2743909435887493

Epoch: 202| Step: 0
Training loss: 1.9899179935455322
Validation loss: 2.257242618068572

Epoch: 6| Step: 1
Training loss: 1.7229763269424438
Validation loss: 2.25275924897963

Epoch: 6| Step: 2
Training loss: 2.4980390071868896
Validation loss: 2.236705650565445

Epoch: 6| Step: 3
Training loss: 2.3606810569763184
Validation loss: 2.239688922000188

Epoch: 6| Step: 4
Training loss: 2.122347116470337
Validation loss: 2.2306554702020462

Epoch: 6| Step: 5
Training loss: 1.9697728157043457
Validation loss: 2.231695649444416

Epoch: 6| Step: 6
Training loss: 2.435551166534424
Validation loss: 2.223911916055987

Epoch: 6| Step: 7
Training loss: 2.553690195083618
Validation loss: 2.2206410272147066

Epoch: 6| Step: 8
Training loss: 2.759352684020996
Validation loss: 2.208348753631756

Epoch: 6| Step: 9
Training loss: 2.9030160903930664
Validation loss: 2.213993041746078

Epoch: 6| Step: 10
Training loss: 2.6027016639709473
Validation loss: 2.222933191125111

Epoch: 6| Step: 11
Training loss: 2.7014241218566895
Validation loss: 2.2372132834567817

Epoch: 6| Step: 12
Training loss: 2.2705061435699463
Validation loss: 2.246598729523279

Epoch: 6| Step: 13
Training loss: 2.9841713905334473
Validation loss: 2.266384163210469

Epoch: 203| Step: 0
Training loss: 2.259387969970703
Validation loss: 2.2614979128683768

Epoch: 6| Step: 1
Training loss: 2.9370741844177246
Validation loss: 2.2849307931879514

Epoch: 6| Step: 2
Training loss: 2.456327438354492
Validation loss: 2.2699151423669632

Epoch: 6| Step: 3
Training loss: 3.015014171600342
Validation loss: 2.262789880075762

Epoch: 6| Step: 4
Training loss: 1.793721079826355
Validation loss: 2.2465888069521998

Epoch: 6| Step: 5
Training loss: 2.57161283493042
Validation loss: 2.2381107294431297

Epoch: 6| Step: 6
Training loss: 1.9877804517745972
Validation loss: 2.254238592681064

Epoch: 6| Step: 7
Training loss: 2.0402772426605225
Validation loss: 2.263800836378528

Epoch: 6| Step: 8
Training loss: 1.7618811130523682
Validation loss: 2.287787970676217

Epoch: 6| Step: 9
Training loss: 1.653011679649353
Validation loss: 2.260145324532704

Epoch: 6| Step: 10
Training loss: 2.9707045555114746
Validation loss: 2.2899432925767798

Epoch: 6| Step: 11
Training loss: 3.2125635147094727
Validation loss: 2.286957379310362

Epoch: 6| Step: 12
Training loss: 2.2992959022521973
Validation loss: 2.2838420534646637

Epoch: 6| Step: 13
Training loss: 3.3330535888671875
Validation loss: 2.2646409209056566

Epoch: 204| Step: 0
Training loss: 2.6196157932281494
Validation loss: 2.2492838239157074

Epoch: 6| Step: 1
Training loss: 2.3610825538635254
Validation loss: 2.2256455395811345

Epoch: 6| Step: 2
Training loss: 1.6935842037200928
Validation loss: 2.225699301688902

Epoch: 6| Step: 3
Training loss: 2.5028882026672363
Validation loss: 2.2393295559831845

Epoch: 6| Step: 4
Training loss: 2.857942581176758
Validation loss: 2.244516603408321

Epoch: 6| Step: 5
Training loss: 2.337965726852417
Validation loss: 2.251249997846542

Epoch: 6| Step: 6
Training loss: 2.3009066581726074
Validation loss: 2.25226483550123

Epoch: 6| Step: 7
Training loss: 2.2842774391174316
Validation loss: 2.270632178552689

Epoch: 6| Step: 8
Training loss: 2.6299166679382324
Validation loss: 2.2701370587912937

Epoch: 6| Step: 9
Training loss: 1.731256127357483
Validation loss: 2.2609008922371814

Epoch: 6| Step: 10
Training loss: 2.8378310203552246
Validation loss: 2.2647233932249007

Epoch: 6| Step: 11
Training loss: 3.01047420501709
Validation loss: 2.265671806950723

Epoch: 6| Step: 12
Training loss: 2.2749319076538086
Validation loss: 2.245475781861172

Epoch: 6| Step: 13
Training loss: 2.485074281692505
Validation loss: 2.2457467432945006

Epoch: 205| Step: 0
Training loss: 1.8112173080444336
Validation loss: 2.2469644572145198

Epoch: 6| Step: 1
Training loss: 2.985785961151123
Validation loss: 2.2550699018662974

Epoch: 6| Step: 2
Training loss: 2.0443787574768066
Validation loss: 2.24861325499832

Epoch: 6| Step: 3
Training loss: 2.134376287460327
Validation loss: 2.271673422987743

Epoch: 6| Step: 4
Training loss: 2.5963473320007324
Validation loss: 2.2694420481240876

Epoch: 6| Step: 5
Training loss: 1.7130789756774902
Validation loss: 2.268703155620124

Epoch: 6| Step: 6
Training loss: 2.5552453994750977
Validation loss: 2.2558794470243555

Epoch: 6| Step: 7
Training loss: 2.356088876724243
Validation loss: 2.244433024878143

Epoch: 6| Step: 8
Training loss: 2.3267362117767334
Validation loss: 2.242408155113138

Epoch: 6| Step: 9
Training loss: 2.3376708030700684
Validation loss: 2.2384785529105895

Epoch: 6| Step: 10
Training loss: 3.11729097366333
Validation loss: 2.2410934189314484

Epoch: 6| Step: 11
Training loss: 2.7829995155334473
Validation loss: 2.2309986647739204

Epoch: 6| Step: 12
Training loss: 2.112612247467041
Validation loss: 2.2306306823607414

Epoch: 6| Step: 13
Training loss: 2.706422805786133
Validation loss: 2.239908150447312

Epoch: 206| Step: 0
Training loss: 2.6704490184783936
Validation loss: 2.2317205372677056

Epoch: 6| Step: 1
Training loss: 2.1655468940734863
Validation loss: 2.219612257454985

Epoch: 6| Step: 2
Training loss: 1.6909191608428955
Validation loss: 2.216947296614288

Epoch: 6| Step: 3
Training loss: 2.515036106109619
Validation loss: 2.2218577490057996

Epoch: 6| Step: 4
Training loss: 3.003368616104126
Validation loss: 2.224906293294763

Epoch: 6| Step: 5
Training loss: 2.3607349395751953
Validation loss: 2.2271356198095504

Epoch: 6| Step: 6
Training loss: 2.3711204528808594
Validation loss: 2.2548898368753414

Epoch: 6| Step: 7
Training loss: 1.7246041297912598
Validation loss: 2.2273535779727403

Epoch: 6| Step: 8
Training loss: 3.081418037414551
Validation loss: 2.2253317281764042

Epoch: 6| Step: 9
Training loss: 1.9430538415908813
Validation loss: 2.2241594919594387

Epoch: 6| Step: 10
Training loss: 3.1526641845703125
Validation loss: 2.2359708624501384

Epoch: 6| Step: 11
Training loss: 2.6348109245300293
Validation loss: 2.248267589076873

Epoch: 6| Step: 12
Training loss: 1.973632574081421
Validation loss: 2.2618754012610323

Epoch: 6| Step: 13
Training loss: 1.5861375331878662
Validation loss: 2.251831898125269

Epoch: 207| Step: 0
Training loss: 2.813997745513916
Validation loss: 2.258581098689828

Epoch: 6| Step: 1
Training loss: 1.8225810527801514
Validation loss: 2.2613716407488753

Epoch: 6| Step: 2
Training loss: 2.5538902282714844
Validation loss: 2.259523739096939

Epoch: 6| Step: 3
Training loss: 2.144926071166992
Validation loss: 2.2548003735080844

Epoch: 6| Step: 4
Training loss: 2.5723633766174316
Validation loss: 2.2451449030189106

Epoch: 6| Step: 5
Training loss: 2.5545549392700195
Validation loss: 2.243563239292432

Epoch: 6| Step: 6
Training loss: 2.5187301635742188
Validation loss: 2.246103091906476

Epoch: 6| Step: 7
Training loss: 2.332965612411499
Validation loss: 2.236281846159248

Epoch: 6| Step: 8
Training loss: 2.395048141479492
Validation loss: 2.222970998415383

Epoch: 6| Step: 9
Training loss: 2.5563459396362305
Validation loss: 2.230909478279852

Epoch: 6| Step: 10
Training loss: 1.830878496170044
Validation loss: 2.2150476658216087

Epoch: 6| Step: 11
Training loss: 2.0346827507019043
Validation loss: 2.2006736929698656

Epoch: 6| Step: 12
Training loss: 2.614511728286743
Validation loss: 2.2041251403029247

Epoch: 6| Step: 13
Training loss: 2.3928675651550293
Validation loss: 2.1951222676102833

Epoch: 208| Step: 0
Training loss: 2.8761305809020996
Validation loss: 2.196616558618443

Epoch: 6| Step: 1
Training loss: 1.7775063514709473
Validation loss: 2.1906352286697715

Epoch: 6| Step: 2
Training loss: 2.202662944793701
Validation loss: 2.1932071332008607

Epoch: 6| Step: 3
Training loss: 2.4080379009246826
Validation loss: 2.1971942173537387

Epoch: 6| Step: 4
Training loss: 1.888660192489624
Validation loss: 2.2059076063094603

Epoch: 6| Step: 5
Training loss: 2.657527208328247
Validation loss: 2.2214389488261235

Epoch: 6| Step: 6
Training loss: 2.9214730262756348
Validation loss: 2.253789024968301

Epoch: 6| Step: 7
Training loss: 1.7607064247131348
Validation loss: 2.2628015343860914

Epoch: 6| Step: 8
Training loss: 2.530806303024292
Validation loss: 2.2940129208308395

Epoch: 6| Step: 9
Training loss: 2.136216878890991
Validation loss: 2.300537242684313

Epoch: 6| Step: 10
Training loss: 2.5151071548461914
Validation loss: 2.2863838416273876

Epoch: 6| Step: 11
Training loss: 2.197298288345337
Validation loss: 2.288675137745437

Epoch: 6| Step: 12
Training loss: 2.875175952911377
Validation loss: 2.2838198036275883

Epoch: 6| Step: 13
Training loss: 2.890244960784912
Validation loss: 2.267433818950448

Epoch: 209| Step: 0
Training loss: 2.717325210571289
Validation loss: 2.265993023431429

Epoch: 6| Step: 1
Training loss: 2.800680160522461
Validation loss: 2.252381524732036

Epoch: 6| Step: 2
Training loss: 2.3938300609588623
Validation loss: 2.230588488681342

Epoch: 6| Step: 3
Training loss: 2.1440892219543457
Validation loss: 2.2110942743157826

Epoch: 6| Step: 4
Training loss: 2.016666889190674
Validation loss: 2.2078159970621907

Epoch: 6| Step: 5
Training loss: 2.8264381885528564
Validation loss: 2.202788496530184

Epoch: 6| Step: 6
Training loss: 1.655988335609436
Validation loss: 2.201091863775766

Epoch: 6| Step: 7
Training loss: 2.9927003383636475
Validation loss: 2.206139110749768

Epoch: 6| Step: 8
Training loss: 1.889528751373291
Validation loss: 2.206578211117816

Epoch: 6| Step: 9
Training loss: 1.9476854801177979
Validation loss: 2.212448145753594

Epoch: 6| Step: 10
Training loss: 2.3569531440734863
Validation loss: 2.226056304029239

Epoch: 6| Step: 11
Training loss: 2.647207260131836
Validation loss: 2.246056651556364

Epoch: 6| Step: 12
Training loss: 2.967611789703369
Validation loss: 2.2573935395927838

Epoch: 6| Step: 13
Training loss: 1.4039969444274902
Validation loss: 2.263618471801922

Epoch: 210| Step: 0
Training loss: 3.5642666816711426
Validation loss: 2.2781591979406213

Epoch: 6| Step: 1
Training loss: 1.6618077754974365
Validation loss: 2.2574225394956526

Epoch: 6| Step: 2
Training loss: 2.2953853607177734
Validation loss: 2.256582029404179

Epoch: 6| Step: 3
Training loss: 2.163740634918213
Validation loss: 2.222298804149833

Epoch: 6| Step: 4
Training loss: 2.247328996658325
Validation loss: 2.2269512261113813

Epoch: 6| Step: 5
Training loss: 2.1400771141052246
Validation loss: 2.230061279830112

Epoch: 6| Step: 6
Training loss: 2.1802403926849365
Validation loss: 2.224177869417334

Epoch: 6| Step: 7
Training loss: 1.5568073987960815
Validation loss: 2.2344306194654076

Epoch: 6| Step: 8
Training loss: 2.481178045272827
Validation loss: 2.243377588128531

Epoch: 6| Step: 9
Training loss: 2.4260334968566895
Validation loss: 2.2602386628427813

Epoch: 6| Step: 10
Training loss: 2.67396879196167
Validation loss: 2.2421985262183735

Epoch: 6| Step: 11
Training loss: 2.442213535308838
Validation loss: 2.2292176574789067

Epoch: 6| Step: 12
Training loss: 3.453198194503784
Validation loss: 2.2184383715352705

Epoch: 6| Step: 13
Training loss: 1.8309224843978882
Validation loss: 2.2112767106743267

Epoch: 211| Step: 0
Training loss: 2.602994203567505
Validation loss: 2.2056422054126696

Epoch: 6| Step: 1
Training loss: 2.3295505046844482
Validation loss: 2.2106660386567474

Epoch: 6| Step: 2
Training loss: 2.5753626823425293
Validation loss: 2.2102358084852978

Epoch: 6| Step: 3
Training loss: 2.2192916870117188
Validation loss: 2.208426388361121

Epoch: 6| Step: 4
Training loss: 2.522611379623413
Validation loss: 2.204438614588912

Epoch: 6| Step: 5
Training loss: 2.4663195610046387
Validation loss: 2.217468794956002

Epoch: 6| Step: 6
Training loss: 2.4321751594543457
Validation loss: 2.2133985745009555

Epoch: 6| Step: 7
Training loss: 2.1098413467407227
Validation loss: 2.227921647410239

Epoch: 6| Step: 8
Training loss: 2.5479869842529297
Validation loss: 2.2382356889786257

Epoch: 6| Step: 9
Training loss: 2.5268630981445312
Validation loss: 2.2303990997293943

Epoch: 6| Step: 10
Training loss: 2.9348511695861816
Validation loss: 2.229793089692311

Epoch: 6| Step: 11
Training loss: 2.3746097087860107
Validation loss: 2.214057340416857

Epoch: 6| Step: 12
Training loss: 1.5697845220565796
Validation loss: 2.230415444220266

Epoch: 6| Step: 13
Training loss: 1.2156647443771362
Validation loss: 2.2187652305890153

Epoch: 212| Step: 0
Training loss: 2.922900676727295
Validation loss: 2.2295960380185034

Epoch: 6| Step: 1
Training loss: 2.4453485012054443
Validation loss: 2.247299293036102

Epoch: 6| Step: 2
Training loss: 2.966679573059082
Validation loss: 2.2282984872018137

Epoch: 6| Step: 3
Training loss: 1.5458296537399292
Validation loss: 2.2231835549877537

Epoch: 6| Step: 4
Training loss: 1.9089329242706299
Validation loss: 2.2203028125147664

Epoch: 6| Step: 5
Training loss: 3.1176390647888184
Validation loss: 2.231252393414897

Epoch: 6| Step: 6
Training loss: 2.328946590423584
Validation loss: 2.2490588106134886

Epoch: 6| Step: 7
Training loss: 2.149348258972168
Validation loss: 2.230977478847709

Epoch: 6| Step: 8
Training loss: 2.178272247314453
Validation loss: 2.2507835767602407

Epoch: 6| Step: 9
Training loss: 2.2778589725494385
Validation loss: 2.2389746558281685

Epoch: 6| Step: 10
Training loss: 1.9853330850601196
Validation loss: 2.2424207259249944

Epoch: 6| Step: 11
Training loss: 2.3413593769073486
Validation loss: 2.235992737995681

Epoch: 6| Step: 12
Training loss: 2.1604764461517334
Validation loss: 2.229173260350381

Epoch: 6| Step: 13
Training loss: 2.7214279174804688
Validation loss: 2.228657009781048

Epoch: 213| Step: 0
Training loss: 2.681718111038208
Validation loss: 2.2274411365550053

Epoch: 6| Step: 1
Training loss: 2.390474319458008
Validation loss: 2.230861674072922

Epoch: 6| Step: 2
Training loss: 3.0096676349639893
Validation loss: 2.240377110819663

Epoch: 6| Step: 3
Training loss: 2.1842167377471924
Validation loss: 2.2460672035012195

Epoch: 6| Step: 4
Training loss: 3.218414783477783
Validation loss: 2.244025150934855

Epoch: 6| Step: 5
Training loss: 2.033799648284912
Validation loss: 2.2339877749002106

Epoch: 6| Step: 6
Training loss: 1.7928826808929443
Validation loss: 2.2150842143643286

Epoch: 6| Step: 7
Training loss: 2.27424955368042
Validation loss: 2.2177284276613625

Epoch: 6| Step: 8
Training loss: 2.419471263885498
Validation loss: 2.224807713621406

Epoch: 6| Step: 9
Training loss: 2.72175931930542
Validation loss: 2.2357786778480775

Epoch: 6| Step: 10
Training loss: 2.0714292526245117
Validation loss: 2.2422870051476265

Epoch: 6| Step: 11
Training loss: 1.5984017848968506
Validation loss: 2.238577437657182

Epoch: 6| Step: 12
Training loss: 1.8743854761123657
Validation loss: 2.2507862352555796

Epoch: 6| Step: 13
Training loss: 3.074700355529785
Validation loss: 2.2745765896253687

Epoch: 214| Step: 0
Training loss: 2.380420684814453
Validation loss: 2.2675195086386895

Epoch: 6| Step: 1
Training loss: 2.894144058227539
Validation loss: 2.2477223232228267

Epoch: 6| Step: 2
Training loss: 2.3355445861816406
Validation loss: 2.2238491273695424

Epoch: 6| Step: 3
Training loss: 1.9572737216949463
Validation loss: 2.2148765594728532

Epoch: 6| Step: 4
Training loss: 2.437467098236084
Validation loss: 2.213303981288787

Epoch: 6| Step: 5
Training loss: 3.121717929840088
Validation loss: 2.2092500271335727

Epoch: 6| Step: 6
Training loss: 1.7145304679870605
Validation loss: 2.1855062746232554

Epoch: 6| Step: 7
Training loss: 2.201181411743164
Validation loss: 2.206107213932981

Epoch: 6| Step: 8
Training loss: 2.6400306224823
Validation loss: 2.2033962716338453

Epoch: 6| Step: 9
Training loss: 2.5371828079223633
Validation loss: 2.2019566412894958

Epoch: 6| Step: 10
Training loss: 2.028899908065796
Validation loss: 2.1949878251680763

Epoch: 6| Step: 11
Training loss: 2.9388437271118164
Validation loss: 2.2114279603445404

Epoch: 6| Step: 12
Training loss: 2.136465549468994
Validation loss: 2.210049911211896

Epoch: 6| Step: 13
Training loss: 1.3044184446334839
Validation loss: 2.2203318995814167

Epoch: 215| Step: 0
Training loss: 1.8750998973846436
Validation loss: 2.234936770572457

Epoch: 6| Step: 1
Training loss: 2.218222141265869
Validation loss: 2.2379486176275436

Epoch: 6| Step: 2
Training loss: 3.2348151206970215
Validation loss: 2.2715110266080467

Epoch: 6| Step: 3
Training loss: 3.02392315864563
Validation loss: 2.269620869749336

Epoch: 6| Step: 4
Training loss: 2.4417779445648193
Validation loss: 2.2756486041571504

Epoch: 6| Step: 5
Training loss: 3.068723678588867
Validation loss: 2.249875132755567

Epoch: 6| Step: 6
Training loss: 3.125765562057495
Validation loss: 2.2148509769029516

Epoch: 6| Step: 7
Training loss: 2.4103097915649414
Validation loss: 2.2172712690086773

Epoch: 6| Step: 8
Training loss: 2.1702165603637695
Validation loss: 2.1990779907472673

Epoch: 6| Step: 9
Training loss: 1.7952131032943726
Validation loss: 2.1748530428896666

Epoch: 6| Step: 10
Training loss: 2.4627127647399902
Validation loss: 2.170386575883435

Epoch: 6| Step: 11
Training loss: 1.7490248680114746
Validation loss: 2.171890599753267

Epoch: 6| Step: 12
Training loss: 1.8765509128570557
Validation loss: 2.169761662842125

Epoch: 6| Step: 13
Training loss: 1.468529462814331
Validation loss: 2.1814453294200282

Epoch: 216| Step: 0
Training loss: 1.8518916368484497
Validation loss: 2.1777204672495523

Epoch: 6| Step: 1
Training loss: 2.1443066596984863
Validation loss: 2.1902788287849835

Epoch: 6| Step: 2
Training loss: 2.5691611766815186
Validation loss: 2.192470009608935

Epoch: 6| Step: 3
Training loss: 2.9803466796875
Validation loss: 2.203704757075156

Epoch: 6| Step: 4
Training loss: 3.0906291007995605
Validation loss: 2.2018275824926232

Epoch: 6| Step: 5
Training loss: 2.987356662750244
Validation loss: 2.2065760422778387

Epoch: 6| Step: 6
Training loss: 1.6970725059509277
Validation loss: 2.195579533935875

Epoch: 6| Step: 7
Training loss: 2.6428444385528564
Validation loss: 2.2150359487020843

Epoch: 6| Step: 8
Training loss: 1.8710484504699707
Validation loss: 2.20788154550778

Epoch: 6| Step: 9
Training loss: 2.1214866638183594
Validation loss: 2.2053753240134126

Epoch: 6| Step: 10
Training loss: 2.688255786895752
Validation loss: 2.2182477187084895

Epoch: 6| Step: 11
Training loss: 2.015526533126831
Validation loss: 2.223636019614435

Epoch: 6| Step: 12
Training loss: 1.6837118864059448
Validation loss: 2.2592862780376146

Epoch: 6| Step: 13
Training loss: 3.125645875930786
Validation loss: 2.2791860975244993

Epoch: 217| Step: 0
Training loss: 2.32405686378479
Validation loss: 2.276598363794306

Epoch: 6| Step: 1
Training loss: 2.717573642730713
Validation loss: 2.2744341947699107

Epoch: 6| Step: 2
Training loss: 1.7847877740859985
Validation loss: 2.2575249697572444

Epoch: 6| Step: 3
Training loss: 2.551603317260742
Validation loss: 2.248115321641327

Epoch: 6| Step: 4
Training loss: 1.5764625072479248
Validation loss: 2.236436782344695

Epoch: 6| Step: 5
Training loss: 2.029477596282959
Validation loss: 2.208559351582681

Epoch: 6| Step: 6
Training loss: 2.068969249725342
Validation loss: 2.1982137490344305

Epoch: 6| Step: 7
Training loss: 2.889754295349121
Validation loss: 2.213274822440199

Epoch: 6| Step: 8
Training loss: 2.2801260948181152
Validation loss: 2.2001192723551104

Epoch: 6| Step: 9
Training loss: 2.526736259460449
Validation loss: 2.1878610580198226

Epoch: 6| Step: 10
Training loss: 2.3822145462036133
Validation loss: 2.1761375832301315

Epoch: 6| Step: 11
Training loss: 2.8869752883911133
Validation loss: 2.167604955293799

Epoch: 6| Step: 12
Training loss: 2.816767930984497
Validation loss: 2.182352727459323

Epoch: 6| Step: 13
Training loss: 2.6192331314086914
Validation loss: 2.1704953357737553

Epoch: 218| Step: 0
Training loss: 2.363219738006592
Validation loss: 2.189123212650258

Epoch: 6| Step: 1
Training loss: 1.859323501586914
Validation loss: 2.1990495830453853

Epoch: 6| Step: 2
Training loss: 2.2840168476104736
Validation loss: 2.207074039725847

Epoch: 6| Step: 3
Training loss: 2.3722734451293945
Validation loss: 2.2181255919958955

Epoch: 6| Step: 4
Training loss: 2.599813938140869
Validation loss: 2.224235209085608

Epoch: 6| Step: 5
Training loss: 2.003793716430664
Validation loss: 2.2265026351457

Epoch: 6| Step: 6
Training loss: 2.1418557167053223
Validation loss: 2.223916587009225

Epoch: 6| Step: 7
Training loss: 2.839421272277832
Validation loss: 2.239067385273595

Epoch: 6| Step: 8
Training loss: 2.5988659858703613
Validation loss: 2.222532054429413

Epoch: 6| Step: 9
Training loss: 2.3671579360961914
Validation loss: 2.241572480047903

Epoch: 6| Step: 10
Training loss: 2.457202672958374
Validation loss: 2.2550676945717103

Epoch: 6| Step: 11
Training loss: 2.3569278717041016
Validation loss: 2.2583099411379908

Epoch: 6| Step: 12
Training loss: 2.2730603218078613
Validation loss: 2.254316641438392

Epoch: 6| Step: 13
Training loss: 2.6626875400543213
Validation loss: 2.2582386744919645

Epoch: 219| Step: 0
Training loss: 2.222193479537964
Validation loss: 2.2585082131047405

Epoch: 6| Step: 1
Training loss: 2.66817569732666
Validation loss: 2.2653349496984996

Epoch: 6| Step: 2
Training loss: 2.1178390979766846
Validation loss: 2.25111747044389

Epoch: 6| Step: 3
Training loss: 1.696335792541504
Validation loss: 2.263398831890475

Epoch: 6| Step: 4
Training loss: 2.5514285564422607
Validation loss: 2.2315629361778178

Epoch: 6| Step: 5
Training loss: 2.2024688720703125
Validation loss: 2.2387706669428016

Epoch: 6| Step: 6
Training loss: 2.9193100929260254
Validation loss: 2.214778971928422

Epoch: 6| Step: 7
Training loss: 2.7157363891601562
Validation loss: 2.196004731680757

Epoch: 6| Step: 8
Training loss: 2.6997222900390625
Validation loss: 2.1915714471570906

Epoch: 6| Step: 9
Training loss: 1.6227374076843262
Validation loss: 2.204419844893999

Epoch: 6| Step: 10
Training loss: 1.3381013870239258
Validation loss: 2.1848662848113687

Epoch: 6| Step: 11
Training loss: 3.1089487075805664
Validation loss: 2.195756058539114

Epoch: 6| Step: 12
Training loss: 2.923521041870117
Validation loss: 2.1953059473345355

Epoch: 6| Step: 13
Training loss: 2.128757953643799
Validation loss: 2.1929863396511284

Epoch: 220| Step: 0
Training loss: 2.6897222995758057
Validation loss: 2.2022422436744935

Epoch: 6| Step: 1
Training loss: 2.4037513732910156
Validation loss: 2.199233789597788

Epoch: 6| Step: 2
Training loss: 2.104503870010376
Validation loss: 2.2055796320720384

Epoch: 6| Step: 3
Training loss: 3.010981321334839
Validation loss: 2.2217983507340953

Epoch: 6| Step: 4
Training loss: 2.285776376724243
Validation loss: 2.2279154254544165

Epoch: 6| Step: 5
Training loss: 1.8420151472091675
Validation loss: 2.208740298466016

Epoch: 6| Step: 6
Training loss: 2.144925355911255
Validation loss: 2.198114983497127

Epoch: 6| Step: 7
Training loss: 2.6755666732788086
Validation loss: 2.201063812419932

Epoch: 6| Step: 8
Training loss: 2.4099199771881104
Validation loss: 2.205072260672046

Epoch: 6| Step: 9
Training loss: 2.3602728843688965
Validation loss: 2.1849163783493863

Epoch: 6| Step: 10
Training loss: 1.9891304969787598
Validation loss: 2.205570659329814

Epoch: 6| Step: 11
Training loss: 1.2330832481384277
Validation loss: 2.222810299165787

Epoch: 6| Step: 12
Training loss: 2.887373208999634
Validation loss: 2.2233380707361365

Epoch: 6| Step: 13
Training loss: 3.305621862411499
Validation loss: 2.2312676880949285

Epoch: 221| Step: 0
Training loss: 1.523514747619629
Validation loss: 2.211308967682623

Epoch: 6| Step: 1
Training loss: 2.15275239944458
Validation loss: 2.2179701917914936

Epoch: 6| Step: 2
Training loss: 2.537202835083008
Validation loss: 2.224144871516894

Epoch: 6| Step: 3
Training loss: 2.7401208877563477
Validation loss: 2.2248002482998754

Epoch: 6| Step: 4
Training loss: 2.8319785594940186
Validation loss: 2.2170551335939797

Epoch: 6| Step: 5
Training loss: 2.8211212158203125
Validation loss: 2.2183153578030166

Epoch: 6| Step: 6
Training loss: 2.7547872066497803
Validation loss: 2.226647202686597

Epoch: 6| Step: 7
Training loss: 2.0530967712402344
Validation loss: 2.232414677578916

Epoch: 6| Step: 8
Training loss: 2.02787446975708
Validation loss: 2.2106212980003765

Epoch: 6| Step: 9
Training loss: 1.974961280822754
Validation loss: 2.2291758880820325

Epoch: 6| Step: 10
Training loss: 2.2206783294677734
Validation loss: 2.23791911268747

Epoch: 6| Step: 11
Training loss: 2.4747369289398193
Validation loss: 2.2322192704805763

Epoch: 6| Step: 12
Training loss: 2.4498023986816406
Validation loss: 2.2119127140250257

Epoch: 6| Step: 13
Training loss: 2.109030246734619
Validation loss: 2.2011601412168114

Epoch: 222| Step: 0
Training loss: 2.232607364654541
Validation loss: 2.1851619456403997

Epoch: 6| Step: 1
Training loss: 2.620905876159668
Validation loss: 2.1691491270578034

Epoch: 6| Step: 2
Training loss: 2.416226863861084
Validation loss: 2.1865980958425872

Epoch: 6| Step: 3
Training loss: 2.091695547103882
Validation loss: 2.183476189131378

Epoch: 6| Step: 4
Training loss: 2.2442193031311035
Validation loss: 2.191520158962537

Epoch: 6| Step: 5
Training loss: 2.2814903259277344
Validation loss: 2.21570263883119

Epoch: 6| Step: 6
Training loss: 2.446986675262451
Validation loss: 2.2197168027201006

Epoch: 6| Step: 7
Training loss: 2.145314931869507
Validation loss: 2.2283396900341077

Epoch: 6| Step: 8
Training loss: 1.6653934717178345
Validation loss: 2.2295132606260237

Epoch: 6| Step: 9
Training loss: 2.1769094467163086
Validation loss: 2.240452097308251

Epoch: 6| Step: 10
Training loss: 2.1870622634887695
Validation loss: 2.2662709015671925

Epoch: 6| Step: 11
Training loss: 2.820673942565918
Validation loss: 2.2689073624149447

Epoch: 6| Step: 12
Training loss: 2.5940260887145996
Validation loss: 2.274821840306764

Epoch: 6| Step: 13
Training loss: 3.297741413116455
Validation loss: 2.2794042607789398

Epoch: 223| Step: 0
Training loss: 2.921487331390381
Validation loss: 2.2564433774640484

Epoch: 6| Step: 1
Training loss: 1.8013556003570557
Validation loss: 2.215483852612075

Epoch: 6| Step: 2
Training loss: 2.7814388275146484
Validation loss: 2.202821967422321

Epoch: 6| Step: 3
Training loss: 2.674935817718506
Validation loss: 2.193800260943751

Epoch: 6| Step: 4
Training loss: 1.8985931873321533
Validation loss: 2.187428817954115

Epoch: 6| Step: 5
Training loss: 2.164689540863037
Validation loss: 2.189344201036679

Epoch: 6| Step: 6
Training loss: 2.908540964126587
Validation loss: 2.1777073978095927

Epoch: 6| Step: 7
Training loss: 2.269007444381714
Validation loss: 2.1696956721685265

Epoch: 6| Step: 8
Training loss: 2.5332775115966797
Validation loss: 2.1891848310347526

Epoch: 6| Step: 9
Training loss: 1.9969922304153442
Validation loss: 2.1814613521740003

Epoch: 6| Step: 10
Training loss: 2.0592339038848877
Validation loss: 2.179855256952265

Epoch: 6| Step: 11
Training loss: 2.2093589305877686
Validation loss: 2.18800348876625

Epoch: 6| Step: 12
Training loss: 2.2403969764709473
Validation loss: 2.183435893827869

Epoch: 6| Step: 13
Training loss: 2.399059772491455
Validation loss: 2.1853226282263316

Epoch: 224| Step: 0
Training loss: 2.2086825370788574
Validation loss: 2.224843212353286

Epoch: 6| Step: 1
Training loss: 2.3752846717834473
Validation loss: 2.241615326173844

Epoch: 6| Step: 2
Training loss: 2.194227933883667
Validation loss: 2.2778282729528283

Epoch: 6| Step: 3
Training loss: 2.33198881149292
Validation loss: 2.300434439413009

Epoch: 6| Step: 4
Training loss: 2.419194221496582
Validation loss: 2.3097654004250803

Epoch: 6| Step: 5
Training loss: 1.7439687252044678
Validation loss: 2.3318409586465485

Epoch: 6| Step: 6
Training loss: 2.483783006668091
Validation loss: 2.340936630002914

Epoch: 6| Step: 7
Training loss: 2.256563186645508
Validation loss: 2.34365314309315

Epoch: 6| Step: 8
Training loss: 2.1673877239227295
Validation loss: 2.3264925864435013

Epoch: 6| Step: 9
Training loss: 2.1933488845825195
Validation loss: 2.32911580352373

Epoch: 6| Step: 10
Training loss: 2.728699207305908
Validation loss: 2.295460767643426

Epoch: 6| Step: 11
Training loss: 2.3354859352111816
Validation loss: 2.263427524156468

Epoch: 6| Step: 12
Training loss: 3.2927188873291016
Validation loss: 2.225878111777767

Epoch: 6| Step: 13
Training loss: 2.0349464416503906
Validation loss: 2.217550777619885

Epoch: 225| Step: 0
Training loss: 2.270095109939575
Validation loss: 2.2003206360724663

Epoch: 6| Step: 1
Training loss: 2.4740214347839355
Validation loss: 2.1935866237968527

Epoch: 6| Step: 2
Training loss: 2.722935199737549
Validation loss: 2.1978420801060174

Epoch: 6| Step: 3
Training loss: 2.0731019973754883
Validation loss: 2.194491923496287

Epoch: 6| Step: 4
Training loss: 2.4112281799316406
Validation loss: 2.2000068233859156

Epoch: 6| Step: 5
Training loss: 2.479670763015747
Validation loss: 2.1933757361545356

Epoch: 6| Step: 6
Training loss: 2.514554023742676
Validation loss: 2.1880030760201077

Epoch: 6| Step: 7
Training loss: 2.1561689376831055
Validation loss: 2.1880056499153056

Epoch: 6| Step: 8
Training loss: 1.9102356433868408
Validation loss: 2.2004204309114845

Epoch: 6| Step: 9
Training loss: 1.2901856899261475
Validation loss: 2.192958524150233

Epoch: 6| Step: 10
Training loss: 2.724212884902954
Validation loss: 2.1995146787294777

Epoch: 6| Step: 11
Training loss: 3.001136541366577
Validation loss: 2.1965603059337986

Epoch: 6| Step: 12
Training loss: 2.288463592529297
Validation loss: 2.2259380509776454

Epoch: 6| Step: 13
Training loss: 2.638854742050171
Validation loss: 2.2392684977541686

Epoch: 226| Step: 0
Training loss: 2.228933334350586
Validation loss: 2.249557605353735

Epoch: 6| Step: 1
Training loss: 2.5282363891601562
Validation loss: 2.263209275020066

Epoch: 6| Step: 2
Training loss: 2.1719982624053955
Validation loss: 2.2731795926247873

Epoch: 6| Step: 3
Training loss: 1.8931008577346802
Validation loss: 2.2866118582346107

Epoch: 6| Step: 4
Training loss: 2.219348907470703
Validation loss: 2.26793364555605

Epoch: 6| Step: 5
Training loss: 2.9566407203674316
Validation loss: 2.2976137809855963

Epoch: 6| Step: 6
Training loss: 2.2036659717559814
Validation loss: 2.290087643490043

Epoch: 6| Step: 7
Training loss: 2.5526952743530273
Validation loss: 2.297067816539477

Epoch: 6| Step: 8
Training loss: 2.642718553543091
Validation loss: 2.268764462522281

Epoch: 6| Step: 9
Training loss: 2.186760425567627
Validation loss: 2.259545691551701

Epoch: 6| Step: 10
Training loss: 2.2283926010131836
Validation loss: 2.2609227126644504

Epoch: 6| Step: 11
Training loss: 2.180147647857666
Validation loss: 2.2490044396410704

Epoch: 6| Step: 12
Training loss: 2.786116123199463
Validation loss: 2.2169450790651384

Epoch: 6| Step: 13
Training loss: 2.2868130207061768
Validation loss: 2.2241431179866997

Epoch: 227| Step: 0
Training loss: 3.0702571868896484
Validation loss: 2.201580424462595

Epoch: 6| Step: 1
Training loss: 1.805980920791626
Validation loss: 2.189660805527882

Epoch: 6| Step: 2
Training loss: 3.2039542198181152
Validation loss: 2.186446528280935

Epoch: 6| Step: 3
Training loss: 2.409900665283203
Validation loss: 2.177307598052486

Epoch: 6| Step: 4
Training loss: 1.904900312423706
Validation loss: 2.192196951117567

Epoch: 6| Step: 5
Training loss: 2.9133379459381104
Validation loss: 2.1897212895013953

Epoch: 6| Step: 6
Training loss: 1.8764350414276123
Validation loss: 2.1873431410840762

Epoch: 6| Step: 7
Training loss: 2.6336374282836914
Validation loss: 2.1871896354101037

Epoch: 6| Step: 8
Training loss: 2.2728142738342285
Validation loss: 2.1934680759265857

Epoch: 6| Step: 9
Training loss: 2.09251070022583
Validation loss: 2.1963122480659076

Epoch: 6| Step: 10
Training loss: 1.8189404010772705
Validation loss: 2.2043177414965887

Epoch: 6| Step: 11
Training loss: 1.8820844888687134
Validation loss: 2.2040933037316925

Epoch: 6| Step: 12
Training loss: 2.2218356132507324
Validation loss: 2.2178394397099814

Epoch: 6| Step: 13
Training loss: 2.761894941329956
Validation loss: 2.2178604218267624

Epoch: 228| Step: 0
Training loss: 2.7974648475646973
Validation loss: 2.2228164134487027

Epoch: 6| Step: 1
Training loss: 3.149671792984009
Validation loss: 2.2170510663781116

Epoch: 6| Step: 2
Training loss: 2.239826202392578
Validation loss: 2.223873428119126

Epoch: 6| Step: 3
Training loss: 2.2013092041015625
Validation loss: 2.2265172107245332

Epoch: 6| Step: 4
Training loss: 2.3085925579071045
Validation loss: 2.218927396241055

Epoch: 6| Step: 5
Training loss: 2.4186227321624756
Validation loss: 2.2066940940836424

Epoch: 6| Step: 6
Training loss: 1.719829797744751
Validation loss: 2.180877880383563

Epoch: 6| Step: 7
Training loss: 2.752610206604004
Validation loss: 2.1767299867445424

Epoch: 6| Step: 8
Training loss: 1.5255814790725708
Validation loss: 2.1722896893819175

Epoch: 6| Step: 9
Training loss: 1.8929344415664673
Validation loss: 2.1594892419794554

Epoch: 6| Step: 10
Training loss: 3.014493227005005
Validation loss: 2.16947663727627

Epoch: 6| Step: 11
Training loss: 2.302314281463623
Validation loss: 2.166691421180643

Epoch: 6| Step: 12
Training loss: 2.0738167762756348
Validation loss: 2.153864922062043

Epoch: 6| Step: 13
Training loss: 2.05513596534729
Validation loss: 2.18272917245024

Epoch: 229| Step: 0
Training loss: 2.447770595550537
Validation loss: 2.1819948662993727

Epoch: 6| Step: 1
Training loss: 2.5242795944213867
Validation loss: 2.191815963355444

Epoch: 6| Step: 2
Training loss: 1.5669879913330078
Validation loss: 2.203274926831645

Epoch: 6| Step: 3
Training loss: 2.8131535053253174
Validation loss: 2.2157274548725416

Epoch: 6| Step: 4
Training loss: 2.837481737136841
Validation loss: 2.216304102251607

Epoch: 6| Step: 5
Training loss: 2.614520311355591
Validation loss: 2.215443616272301

Epoch: 6| Step: 6
Training loss: 2.418287515640259
Validation loss: 2.2234405471432592

Epoch: 6| Step: 7
Training loss: 2.805086135864258
Validation loss: 2.209359602261615

Epoch: 6| Step: 8
Training loss: 1.940130352973938
Validation loss: 2.2088002748386835

Epoch: 6| Step: 9
Training loss: 1.4865763187408447
Validation loss: 2.219243505949615

Epoch: 6| Step: 10
Training loss: 1.791076898574829
Validation loss: 2.2084963398595012

Epoch: 6| Step: 11
Training loss: 2.0287866592407227
Validation loss: 2.212226883057625

Epoch: 6| Step: 12
Training loss: 2.656470775604248
Validation loss: 2.2122686165635304

Epoch: 6| Step: 13
Training loss: 2.4050509929656982
Validation loss: 2.244731672348515

Epoch: 230| Step: 0
Training loss: 1.6467214822769165
Validation loss: 2.243917170391288

Epoch: 6| Step: 1
Training loss: 1.8813810348510742
Validation loss: 2.219220656220631

Epoch: 6| Step: 2
Training loss: 2.9106810092926025
Validation loss: 2.2376762231191

Epoch: 6| Step: 3
Training loss: 2.8483731746673584
Validation loss: 2.221097820548601

Epoch: 6| Step: 4
Training loss: 2.603231430053711
Validation loss: 2.2106525923616145

Epoch: 6| Step: 5
Training loss: 1.892223834991455
Validation loss: 2.201399349397229

Epoch: 6| Step: 6
Training loss: 2.090364694595337
Validation loss: 2.2068454847540906

Epoch: 6| Step: 7
Training loss: 2.55875301361084
Validation loss: 2.210704502239022

Epoch: 6| Step: 8
Training loss: 2.1465020179748535
Validation loss: 2.221326267847451

Epoch: 6| Step: 9
Training loss: 3.019110679626465
Validation loss: 2.2074108918507895

Epoch: 6| Step: 10
Training loss: 2.2831759452819824
Validation loss: 2.193929861950618

Epoch: 6| Step: 11
Training loss: 1.5710136890411377
Validation loss: 2.199069724288038

Epoch: 6| Step: 12
Training loss: 2.518364906311035
Validation loss: 2.2040327595126246

Epoch: 6| Step: 13
Training loss: 2.004939317703247
Validation loss: 2.213672568721156

Epoch: 231| Step: 0
Training loss: 1.3993301391601562
Validation loss: 2.206623269665626

Epoch: 6| Step: 1
Training loss: 2.6023807525634766
Validation loss: 2.210914126006506

Epoch: 6| Step: 2
Training loss: 1.8269542455673218
Validation loss: 2.2086745974838093

Epoch: 6| Step: 3
Training loss: 2.716197967529297
Validation loss: 2.2149146910636657

Epoch: 6| Step: 4
Training loss: 2.7948813438415527
Validation loss: 2.221179590430311

Epoch: 6| Step: 5
Training loss: 2.787761688232422
Validation loss: 2.2324896807311685

Epoch: 6| Step: 6
Training loss: 2.068392276763916
Validation loss: 2.23282890935098

Epoch: 6| Step: 7
Training loss: 2.342194080352783
Validation loss: 2.2197867285820747

Epoch: 6| Step: 8
Training loss: 1.99337637424469
Validation loss: 2.1832416006313857

Epoch: 6| Step: 9
Training loss: 2.466280221939087
Validation loss: 2.192568766173496

Epoch: 6| Step: 10
Training loss: 2.0280497074127197
Validation loss: 2.1816062619609218

Epoch: 6| Step: 11
Training loss: 2.656797409057617
Validation loss: 2.1826861558421964

Epoch: 6| Step: 12
Training loss: 2.6870312690734863
Validation loss: 2.1913413770737185

Epoch: 6| Step: 13
Training loss: 1.648126244544983
Validation loss: 2.1837236573619228

Epoch: 232| Step: 0
Training loss: 2.4272570610046387
Validation loss: 2.179401615614532

Epoch: 6| Step: 1
Training loss: 1.9700957536697388
Validation loss: 2.193652178651543

Epoch: 6| Step: 2
Training loss: 2.039414882659912
Validation loss: 2.201062781836397

Epoch: 6| Step: 3
Training loss: 2.204834461212158
Validation loss: 2.211202485587007

Epoch: 6| Step: 4
Training loss: 1.9725263118743896
Validation loss: 2.205966916135562

Epoch: 6| Step: 5
Training loss: 2.479919910430908
Validation loss: 2.204933497213548

Epoch: 6| Step: 6
Training loss: 1.9316821098327637
Validation loss: 2.2090069555467173

Epoch: 6| Step: 7
Training loss: 2.843579053878784
Validation loss: 2.214993143594393

Epoch: 6| Step: 8
Training loss: 1.9589637517929077
Validation loss: 2.199984255657401

Epoch: 6| Step: 9
Training loss: 2.3790650367736816
Validation loss: 2.2112123863671416

Epoch: 6| Step: 10
Training loss: 2.600588798522949
Validation loss: 2.1925809152664675

Epoch: 6| Step: 11
Training loss: 2.8712565898895264
Validation loss: 2.1941751933866933

Epoch: 6| Step: 12
Training loss: 1.6153485774993896
Validation loss: 2.1991592543099516

Epoch: 6| Step: 13
Training loss: 3.185870885848999
Validation loss: 2.1962592037775184

Epoch: 233| Step: 0
Training loss: 2.361295700073242
Validation loss: 2.1892072962176417

Epoch: 6| Step: 1
Training loss: 2.619690418243408
Validation loss: 2.1924153297178206

Epoch: 6| Step: 2
Training loss: 1.888817548751831
Validation loss: 2.1929906978402087

Epoch: 6| Step: 3
Training loss: 2.025826930999756
Validation loss: 2.1924805384810253

Epoch: 6| Step: 4
Training loss: 2.4133665561676025
Validation loss: 2.182178076877389

Epoch: 6| Step: 5
Training loss: 2.131521701812744
Validation loss: 2.18112543577789

Epoch: 6| Step: 6
Training loss: 2.544032573699951
Validation loss: 2.1857966812708045

Epoch: 6| Step: 7
Training loss: 2.3130295276641846
Validation loss: 2.201432949753218

Epoch: 6| Step: 8
Training loss: 2.6076183319091797
Validation loss: 2.2135775601992043

Epoch: 6| Step: 9
Training loss: 2.3522329330444336
Validation loss: 2.2411317991954025

Epoch: 6| Step: 10
Training loss: 2.3170554637908936
Validation loss: 2.2419988852675243

Epoch: 6| Step: 11
Training loss: 1.9465746879577637
Validation loss: 2.269414230059552

Epoch: 6| Step: 12
Training loss: 2.5146684646606445
Validation loss: 2.271180124693019

Epoch: 6| Step: 13
Training loss: 2.1337668895721436
Validation loss: 2.265212200021231

Epoch: 234| Step: 0
Training loss: 2.697148084640503
Validation loss: 2.246291450274888

Epoch: 6| Step: 1
Training loss: 2.334127426147461
Validation loss: 2.2225556386414396

Epoch: 6| Step: 2
Training loss: 2.0177154541015625
Validation loss: 2.208469881806322

Epoch: 6| Step: 3
Training loss: 2.1207773685455322
Validation loss: 2.2023956186027935

Epoch: 6| Step: 4
Training loss: 2.8542418479919434
Validation loss: 2.195580418391894

Epoch: 6| Step: 5
Training loss: 2.265120506286621
Validation loss: 2.1805228430737733

Epoch: 6| Step: 6
Training loss: 2.700137138366699
Validation loss: 2.181397040685018

Epoch: 6| Step: 7
Training loss: 1.9798452854156494
Validation loss: 2.178973138973277

Epoch: 6| Step: 8
Training loss: 2.4550094604492188
Validation loss: 2.1745916669086744

Epoch: 6| Step: 9
Training loss: 1.8606126308441162
Validation loss: 2.1767719330326205

Epoch: 6| Step: 10
Training loss: 2.1424031257629395
Validation loss: 2.170157071082823

Epoch: 6| Step: 11
Training loss: 2.2956550121307373
Validation loss: 2.160073476452981

Epoch: 6| Step: 12
Training loss: 2.5584464073181152
Validation loss: 2.180269795079385

Epoch: 6| Step: 13
Training loss: 2.1703827381134033
Validation loss: 2.204803410396781

Epoch: 235| Step: 0
Training loss: 2.2605772018432617
Validation loss: 2.236407931132983

Epoch: 6| Step: 1
Training loss: 2.7311854362487793
Validation loss: 2.248698560140466

Epoch: 6| Step: 2
Training loss: 1.8154200315475464
Validation loss: 2.2579916984804216

Epoch: 6| Step: 3
Training loss: 3.005556106567383
Validation loss: 2.216154630466174

Epoch: 6| Step: 4
Training loss: 1.8704662322998047
Validation loss: 2.202570871640277

Epoch: 6| Step: 5
Training loss: 2.0902457237243652
Validation loss: 2.1929151281233756

Epoch: 6| Step: 6
Training loss: 3.328280448913574
Validation loss: 2.1782168521676013

Epoch: 6| Step: 7
Training loss: 2.3991641998291016
Validation loss: 2.197719427847093

Epoch: 6| Step: 8
Training loss: 2.294456958770752
Validation loss: 2.2041250351936585

Epoch: 6| Step: 9
Training loss: 2.395448684692383
Validation loss: 2.2239127453937324

Epoch: 6| Step: 10
Training loss: 1.9609088897705078
Validation loss: 2.2127555621567594

Epoch: 6| Step: 11
Training loss: 1.3247947692871094
Validation loss: 2.2446579099983297

Epoch: 6| Step: 12
Training loss: 2.4030699729919434
Validation loss: 2.2250144686750186

Epoch: 6| Step: 13
Training loss: 2.6346471309661865
Validation loss: 2.238436124658072

Epoch: 236| Step: 0
Training loss: 3.0973243713378906
Validation loss: 2.230107563798146

Epoch: 6| Step: 1
Training loss: 2.2379112243652344
Validation loss: 2.215976481796593

Epoch: 6| Step: 2
Training loss: 1.8428981304168701
Validation loss: 2.2142203136156966

Epoch: 6| Step: 3
Training loss: 2.166470527648926
Validation loss: 2.2003857666446316

Epoch: 6| Step: 4
Training loss: 2.5125160217285156
Validation loss: 2.2134379597120386

Epoch: 6| Step: 5
Training loss: 1.6458483934402466
Validation loss: 2.1975478177429526

Epoch: 6| Step: 6
Training loss: 2.155303955078125
Validation loss: 2.1884788441401657

Epoch: 6| Step: 7
Training loss: 2.3546009063720703
Validation loss: 2.1866782942125873

Epoch: 6| Step: 8
Training loss: 2.225876808166504
Validation loss: 2.182371275399321

Epoch: 6| Step: 9
Training loss: 2.238809823989868
Validation loss: 2.1841401361650035

Epoch: 6| Step: 10
Training loss: 2.4318079948425293
Validation loss: 2.187311964650308

Epoch: 6| Step: 11
Training loss: 2.470203399658203
Validation loss: 2.2087150837785456

Epoch: 6| Step: 12
Training loss: 2.0809881687164307
Validation loss: 2.1944151437410744

Epoch: 6| Step: 13
Training loss: 3.3523263931274414
Validation loss: 2.220687316310021

Epoch: 237| Step: 0
Training loss: 2.51684308052063
Validation loss: 2.2224340925934496

Epoch: 6| Step: 1
Training loss: 2.0912604331970215
Validation loss: 2.2269676577660347

Epoch: 6| Step: 2
Training loss: 2.4486629962921143
Validation loss: 2.226785329080397

Epoch: 6| Step: 3
Training loss: 2.293929100036621
Validation loss: 2.2385254854797036

Epoch: 6| Step: 4
Training loss: 2.5778331756591797
Validation loss: 2.233928688110844

Epoch: 6| Step: 5
Training loss: 2.3636419773101807
Validation loss: 2.2165053006141417

Epoch: 6| Step: 6
Training loss: 2.193756580352783
Validation loss: 2.2165431104680544

Epoch: 6| Step: 7
Training loss: 2.140442371368408
Validation loss: 2.2099388235358783

Epoch: 6| Step: 8
Training loss: 1.8083823919296265
Validation loss: 2.1796322343170003

Epoch: 6| Step: 9
Training loss: 2.5700905323028564
Validation loss: 2.1796895227124615

Epoch: 6| Step: 10
Training loss: 2.8126425743103027
Validation loss: 2.187679412544415

Epoch: 6| Step: 11
Training loss: 2.068086624145508
Validation loss: 2.184530031296515

Epoch: 6| Step: 12
Training loss: 2.0675182342529297
Validation loss: 2.199960939345821

Epoch: 6| Step: 13
Training loss: 2.008315324783325
Validation loss: 2.1897661250124694

Epoch: 238| Step: 0
Training loss: 2.171590805053711
Validation loss: 2.215658836467292

Epoch: 6| Step: 1
Training loss: 1.2065722942352295
Validation loss: 2.225232038446652

Epoch: 6| Step: 2
Training loss: 2.8471038341522217
Validation loss: 2.2436858864240747

Epoch: 6| Step: 3
Training loss: 2.4119584560394287
Validation loss: 2.2232369940768004

Epoch: 6| Step: 4
Training loss: 2.265608549118042
Validation loss: 2.253264698930966

Epoch: 6| Step: 5
Training loss: 2.4067788124084473
Validation loss: 2.2460199889316352

Epoch: 6| Step: 6
Training loss: 2.8313512802124023
Validation loss: 2.2316272104940107

Epoch: 6| Step: 7
Training loss: 2.264252185821533
Validation loss: 2.227821337279453

Epoch: 6| Step: 8
Training loss: 2.4566774368286133
Validation loss: 2.220328192557058

Epoch: 6| Step: 9
Training loss: 2.2184298038482666
Validation loss: 2.23285186418923

Epoch: 6| Step: 10
Training loss: 1.886365294456482
Validation loss: 2.1956612204992645

Epoch: 6| Step: 11
Training loss: 2.8465168476104736
Validation loss: 2.19231774217339

Epoch: 6| Step: 12
Training loss: 2.1006782054901123
Validation loss: 2.1819804099298294

Epoch: 6| Step: 13
Training loss: 1.8225574493408203
Validation loss: 2.1669289886310534

Epoch: 239| Step: 0
Training loss: 2.4531307220458984
Validation loss: 2.1626153479340258

Epoch: 6| Step: 1
Training loss: 2.2758398056030273
Validation loss: 2.1728169354059363

Epoch: 6| Step: 2
Training loss: 2.6717605590820312
Validation loss: 2.172180414199829

Epoch: 6| Step: 3
Training loss: 1.7127807140350342
Validation loss: 2.176535283365557

Epoch: 6| Step: 4
Training loss: 2.0604758262634277
Validation loss: 2.1852334468595442

Epoch: 6| Step: 5
Training loss: 3.0401411056518555
Validation loss: 2.189335307767314

Epoch: 6| Step: 6
Training loss: 2.1915502548217773
Validation loss: 2.2010944274164017

Epoch: 6| Step: 7
Training loss: 2.005638599395752
Validation loss: 2.194358751338015

Epoch: 6| Step: 8
Training loss: 1.9196555614471436
Validation loss: 2.2114760696247058

Epoch: 6| Step: 9
Training loss: 2.817518711090088
Validation loss: 2.188108713396134

Epoch: 6| Step: 10
Training loss: 2.2659332752227783
Validation loss: 2.200548630888744

Epoch: 6| Step: 11
Training loss: 2.5757193565368652
Validation loss: 2.2029952105655464

Epoch: 6| Step: 12
Training loss: 2.116368293762207
Validation loss: 2.197583157529113

Epoch: 6| Step: 13
Training loss: 2.1571311950683594
Validation loss: 2.2059191247468353

Epoch: 240| Step: 0
Training loss: 2.146026611328125
Validation loss: 2.2378271023432412

Epoch: 6| Step: 1
Training loss: 1.939826488494873
Validation loss: 2.2542104349341443

Epoch: 6| Step: 2
Training loss: 2.2285046577453613
Validation loss: 2.2391932574651574

Epoch: 6| Step: 3
Training loss: 2.1718029975891113
Validation loss: 2.226887784978395

Epoch: 6| Step: 4
Training loss: 2.126809597015381
Validation loss: 2.198658033083844

Epoch: 6| Step: 5
Training loss: 1.9715691804885864
Validation loss: 2.179685377305554

Epoch: 6| Step: 6
Training loss: 2.2792649269104004
Validation loss: 2.15147445150601

Epoch: 6| Step: 7
Training loss: 2.0741372108459473
Validation loss: 2.158525554082727

Epoch: 6| Step: 8
Training loss: 2.7166779041290283
Validation loss: 2.173315830128167

Epoch: 6| Step: 9
Training loss: 2.291682243347168
Validation loss: 2.2051864336895686

Epoch: 6| Step: 10
Training loss: 1.792982816696167
Validation loss: 2.2416517183344853

Epoch: 6| Step: 11
Training loss: 2.6485376358032227
Validation loss: 2.2863490658421672

Epoch: 6| Step: 12
Training loss: 3.249831199645996
Validation loss: 2.312122070661155

Epoch: 6| Step: 13
Training loss: 3.60748028755188
Validation loss: 2.3398487875538487

Epoch: 241| Step: 0
Training loss: 2.523740768432617
Validation loss: 2.3224302709743543

Epoch: 6| Step: 1
Training loss: 2.065499782562256
Validation loss: 2.3036749247581727

Epoch: 6| Step: 2
Training loss: 2.710904598236084
Validation loss: 2.2688703178077616

Epoch: 6| Step: 3
Training loss: 2.515768051147461
Validation loss: 2.2656357890816143

Epoch: 6| Step: 4
Training loss: 1.949588418006897
Validation loss: 2.212219671536517

Epoch: 6| Step: 5
Training loss: 1.9032622575759888
Validation loss: 2.202400493365462

Epoch: 6| Step: 6
Training loss: 1.9523868560791016
Validation loss: 2.1912128515140985

Epoch: 6| Step: 7
Training loss: 2.9166042804718018
Validation loss: 2.189789761779129

Epoch: 6| Step: 8
Training loss: 2.291473150253296
Validation loss: 2.169597266822733

Epoch: 6| Step: 9
Training loss: 1.6091736555099487
Validation loss: 2.182564668757941

Epoch: 6| Step: 10
Training loss: 2.631746292114258
Validation loss: 2.171397557822607

Epoch: 6| Step: 11
Training loss: 2.209592819213867
Validation loss: 2.1623609040373113

Epoch: 6| Step: 12
Training loss: 2.562001943588257
Validation loss: 2.1478154274725143

Epoch: 6| Step: 13
Training loss: 3.060542106628418
Validation loss: 2.1578458662955993

Epoch: 242| Step: 0
Training loss: 2.6019673347473145
Validation loss: 2.1463353198061705

Epoch: 6| Step: 1
Training loss: 1.47116219997406
Validation loss: 2.1522493311153945

Epoch: 6| Step: 2
Training loss: 2.478843927383423
Validation loss: 2.19606839969594

Epoch: 6| Step: 3
Training loss: 2.073686361312866
Validation loss: 2.2096307123861005

Epoch: 6| Step: 4
Training loss: 2.3961353302001953
Validation loss: 2.2382872335372435

Epoch: 6| Step: 5
Training loss: 2.335216999053955
Validation loss: 2.2663150577134985

Epoch: 6| Step: 6
Training loss: 2.9752111434936523
Validation loss: 2.265933785387265

Epoch: 6| Step: 7
Training loss: 3.4338736534118652
Validation loss: 2.2803958564676265

Epoch: 6| Step: 8
Training loss: 1.983033537864685
Validation loss: 2.2571987093135877

Epoch: 6| Step: 9
Training loss: 1.8246694803237915
Validation loss: 2.253284354363718

Epoch: 6| Step: 10
Training loss: 1.9468638896942139
Validation loss: 2.256690643166983

Epoch: 6| Step: 11
Training loss: 2.571807861328125
Validation loss: 2.257202943166097

Epoch: 6| Step: 12
Training loss: 2.00579571723938
Validation loss: 2.2331333416764454

Epoch: 6| Step: 13
Training loss: 2.2940673828125
Validation loss: 2.270776694820773

Epoch: 243| Step: 0
Training loss: 2.0761914253234863
Validation loss: 2.251088798687022

Epoch: 6| Step: 1
Training loss: 2.8387045860290527
Validation loss: 2.2428990076946955

Epoch: 6| Step: 2
Training loss: 2.368002414703369
Validation loss: 2.2352792421976724

Epoch: 6| Step: 3
Training loss: 2.459078550338745
Validation loss: 2.2205741738760345

Epoch: 6| Step: 4
Training loss: 2.0786850452423096
Validation loss: 2.1943358913544686

Epoch: 6| Step: 5
Training loss: 2.0752930641174316
Validation loss: 2.1743712553413967

Epoch: 6| Step: 6
Training loss: 2.1391563415527344
Validation loss: 2.1628582169932704

Epoch: 6| Step: 7
Training loss: 2.5333251953125
Validation loss: 2.141280512655935

Epoch: 6| Step: 8
Training loss: 1.9760816097259521
Validation loss: 2.1417854037336124

Epoch: 6| Step: 9
Training loss: 1.8998310565948486
Validation loss: 2.139249950326899

Epoch: 6| Step: 10
Training loss: 2.849522113800049
Validation loss: 2.14383505493082

Epoch: 6| Step: 11
Training loss: 2.763510227203369
Validation loss: 2.170101555444861

Epoch: 6| Step: 12
Training loss: 2.437211036682129
Validation loss: 2.185439455893732

Epoch: 6| Step: 13
Training loss: 1.598480224609375
Validation loss: 2.182035912749588

Epoch: 244| Step: 0
Training loss: 1.9017202854156494
Validation loss: 2.2216164809401318

Epoch: 6| Step: 1
Training loss: 2.25042724609375
Validation loss: 2.2533562491017003

Epoch: 6| Step: 2
Training loss: 2.4709181785583496
Validation loss: 2.248853478380429

Epoch: 6| Step: 3
Training loss: 2.4826221466064453
Validation loss: 2.2618490111443306

Epoch: 6| Step: 4
Training loss: 2.4831409454345703
Validation loss: 2.2664281757928992

Epoch: 6| Step: 5
Training loss: 2.4674930572509766
Validation loss: 2.249869987528811

Epoch: 6| Step: 6
Training loss: 2.0023789405822754
Validation loss: 2.2373865817182805

Epoch: 6| Step: 7
Training loss: 2.333829164505005
Validation loss: 2.21414428628901

Epoch: 6| Step: 8
Training loss: 2.5994391441345215
Validation loss: 2.217505519108106

Epoch: 6| Step: 9
Training loss: 1.8895151615142822
Validation loss: 2.2097774474851546

Epoch: 6| Step: 10
Training loss: 2.5666754245758057
Validation loss: 2.203164246774489

Epoch: 6| Step: 11
Training loss: 2.0121054649353027
Validation loss: 2.1881093773790585

Epoch: 6| Step: 12
Training loss: 2.3295347690582275
Validation loss: 2.182040778539514

Epoch: 6| Step: 13
Training loss: 2.4432618618011475
Validation loss: 2.191089942891111

Epoch: 245| Step: 0
Training loss: 2.1768250465393066
Validation loss: 2.186161938533988

Epoch: 6| Step: 1
Training loss: 2.599759578704834
Validation loss: 2.179357995269119

Epoch: 6| Step: 2
Training loss: 1.3587682247161865
Validation loss: 2.189101606286982

Epoch: 6| Step: 3
Training loss: 2.4678540229797363
Validation loss: 2.1952291509156585

Epoch: 6| Step: 4
Training loss: 2.5409326553344727
Validation loss: 2.2013791145816928

Epoch: 6| Step: 5
Training loss: 2.789240837097168
Validation loss: 2.2148386739915416

Epoch: 6| Step: 6
Training loss: 1.8789923191070557
Validation loss: 2.205309651231253

Epoch: 6| Step: 7
Training loss: 2.151304006576538
Validation loss: 2.2031964845554803

Epoch: 6| Step: 8
Training loss: 2.5144572257995605
Validation loss: 2.1912087048253706

Epoch: 6| Step: 9
Training loss: 2.1895370483398438
Validation loss: 2.198011024023897

Epoch: 6| Step: 10
Training loss: 2.5991697311401367
Validation loss: 2.2049959731358353

Epoch: 6| Step: 11
Training loss: 1.848968267440796
Validation loss: 2.1818490976928384

Epoch: 6| Step: 12
Training loss: 1.8824748992919922
Validation loss: 2.2064843075249785

Epoch: 6| Step: 13
Training loss: 3.636895179748535
Validation loss: 2.20028152004365

Epoch: 246| Step: 0
Training loss: 2.4040145874023438
Validation loss: 2.2164469303623324

Epoch: 6| Step: 1
Training loss: 2.588935375213623
Validation loss: 2.195013948666152

Epoch: 6| Step: 2
Training loss: 2.2873847484588623
Validation loss: 2.2140674873064925

Epoch: 6| Step: 3
Training loss: 2.476287841796875
Validation loss: 2.2142363773879183

Epoch: 6| Step: 4
Training loss: 1.9239109754562378
Validation loss: 2.194725926204394

Epoch: 6| Step: 5
Training loss: 2.4969019889831543
Validation loss: 2.2004011036247335

Epoch: 6| Step: 6
Training loss: 2.7481703758239746
Validation loss: 2.188440666403822

Epoch: 6| Step: 7
Training loss: 1.8478652238845825
Validation loss: 2.194201284839261

Epoch: 6| Step: 8
Training loss: 2.2592647075653076
Validation loss: 2.1855245559446272

Epoch: 6| Step: 9
Training loss: 1.7902796268463135
Validation loss: 2.1877131564642793

Epoch: 6| Step: 10
Training loss: 2.326801300048828
Validation loss: 2.169816452969787

Epoch: 6| Step: 11
Training loss: 2.06009840965271
Validation loss: 2.182170747428812

Epoch: 6| Step: 12
Training loss: 2.259054183959961
Validation loss: 2.1818746828263804

Epoch: 6| Step: 13
Training loss: 2.182842493057251
Validation loss: 2.17898847979884

Epoch: 247| Step: 0
Training loss: 2.4608020782470703
Validation loss: 2.175492801973897

Epoch: 6| Step: 1
Training loss: 1.9610635042190552
Validation loss: 2.189259377858972

Epoch: 6| Step: 2
Training loss: 2.4263691902160645
Validation loss: 2.1766837771220873

Epoch: 6| Step: 3
Training loss: 1.953094482421875
Validation loss: 2.1962013654811408

Epoch: 6| Step: 4
Training loss: 2.2256174087524414
Validation loss: 2.184964164610832

Epoch: 6| Step: 5
Training loss: 1.9613862037658691
Validation loss: 2.1859241813741703

Epoch: 6| Step: 6
Training loss: 2.8725028038024902
Validation loss: 2.17281836335377

Epoch: 6| Step: 7
Training loss: 2.7891907691955566
Validation loss: 2.180462514200518

Epoch: 6| Step: 8
Training loss: 1.4823362827301025
Validation loss: 2.1843721789698445

Epoch: 6| Step: 9
Training loss: 2.018630266189575
Validation loss: 2.1961349287340717

Epoch: 6| Step: 10
Training loss: 2.213547706604004
Validation loss: 2.185230335881633

Epoch: 6| Step: 11
Training loss: 1.6179314851760864
Validation loss: 2.212812021214475

Epoch: 6| Step: 12
Training loss: 3.133361339569092
Validation loss: 2.2105977304520144

Epoch: 6| Step: 13
Training loss: 2.686645030975342
Validation loss: 2.210399781503985

Epoch: 248| Step: 0
Training loss: 2.212390661239624
Validation loss: 2.204884067658455

Epoch: 6| Step: 1
Training loss: 1.9269959926605225
Validation loss: 2.221147524413242

Epoch: 6| Step: 2
Training loss: 2.2120397090911865
Validation loss: 2.200083094258462

Epoch: 6| Step: 3
Training loss: 2.2455086708068848
Validation loss: 2.2027338012572257

Epoch: 6| Step: 4
Training loss: 1.9981534481048584
Validation loss: 2.193294941738088

Epoch: 6| Step: 5
Training loss: 2.4820504188537598
Validation loss: 2.1955875273673766

Epoch: 6| Step: 6
Training loss: 2.179314136505127
Validation loss: 2.1869750791980374

Epoch: 6| Step: 7
Training loss: 2.02848482131958
Validation loss: 2.1696329860277075

Epoch: 6| Step: 8
Training loss: 2.383970260620117
Validation loss: 2.1772275996464554

Epoch: 6| Step: 9
Training loss: 1.9492807388305664
Validation loss: 2.1824887234677552

Epoch: 6| Step: 10
Training loss: 3.0678470134735107
Validation loss: 2.202600266343804

Epoch: 6| Step: 11
Training loss: 2.5533227920532227
Validation loss: 2.221088858060939

Epoch: 6| Step: 12
Training loss: 2.0348830223083496
Validation loss: 2.204437163568312

Epoch: 6| Step: 13
Training loss: 2.5758984088897705
Validation loss: 2.1911243136211107

Epoch: 249| Step: 0
Training loss: 1.6473075151443481
Validation loss: 2.17203083602331

Epoch: 6| Step: 1
Training loss: 1.8342883586883545
Validation loss: 2.169087476627801

Epoch: 6| Step: 2
Training loss: 2.5534183979034424
Validation loss: 2.1572033359158422

Epoch: 6| Step: 3
Training loss: 2.5966734886169434
Validation loss: 2.1604054435606925

Epoch: 6| Step: 4
Training loss: 2.6745123863220215
Validation loss: 2.146787443468648

Epoch: 6| Step: 5
Training loss: 1.872300148010254
Validation loss: 2.1501567568830264

Epoch: 6| Step: 6
Training loss: 1.882850170135498
Validation loss: 2.1537571004641953

Epoch: 6| Step: 7
Training loss: 2.3078882694244385
Validation loss: 2.171417097891531

Epoch: 6| Step: 8
Training loss: 2.5632405281066895
Validation loss: 2.1742580808619016

Epoch: 6| Step: 9
Training loss: 1.5603969097137451
Validation loss: 2.1899159364802863

Epoch: 6| Step: 10
Training loss: 3.303708076477051
Validation loss: 2.204628498323502

Epoch: 6| Step: 11
Training loss: 1.9957908391952515
Validation loss: 2.226678991830477

Epoch: 6| Step: 12
Training loss: 2.257596492767334
Validation loss: 2.2346624558971775

Epoch: 6| Step: 13
Training loss: 2.5896382331848145
Validation loss: 2.2592027802621164

Epoch: 250| Step: 0
Training loss: 2.346585512161255
Validation loss: 2.2624967072599675

Epoch: 6| Step: 1
Training loss: 2.5444250106811523
Validation loss: 2.269362452209637

Epoch: 6| Step: 2
Training loss: 1.4592344760894775
Validation loss: 2.2356075291992514

Epoch: 6| Step: 3
Training loss: 2.066326141357422
Validation loss: 2.2238182431908062

Epoch: 6| Step: 4
Training loss: 2.8450112342834473
Validation loss: 2.202410295445432

Epoch: 6| Step: 5
Training loss: 2.630671977996826
Validation loss: 2.1893271630810154

Epoch: 6| Step: 6
Training loss: 1.976035475730896
Validation loss: 2.1715615052048878

Epoch: 6| Step: 7
Training loss: 2.2526440620422363
Validation loss: 2.1657195039974746

Epoch: 6| Step: 8
Training loss: 2.6188621520996094
Validation loss: 2.1698821616429154

Epoch: 6| Step: 9
Training loss: 1.7928260564804077
Validation loss: 2.1575355734876407

Epoch: 6| Step: 10
Training loss: 2.498255729675293
Validation loss: 2.16451124734776

Epoch: 6| Step: 11
Training loss: 2.039182424545288
Validation loss: 2.1714537118070867

Epoch: 6| Step: 12
Training loss: 2.575974225997925
Validation loss: 2.162965182335146

Epoch: 6| Step: 13
Training loss: 1.6038850545883179
Validation loss: 2.177686281101678

Epoch: 251| Step: 0
Training loss: 1.9180541038513184
Validation loss: 2.2003129579687632

Epoch: 6| Step: 1
Training loss: 2.1309332847595215
Validation loss: 2.1958026668076873

Epoch: 6| Step: 2
Training loss: 2.0566601753234863
Validation loss: 2.215923393926313

Epoch: 6| Step: 3
Training loss: 2.3370397090911865
Validation loss: 2.236613635093935

Epoch: 6| Step: 4
Training loss: 2.225039005279541
Validation loss: 2.2520431549318376

Epoch: 6| Step: 5
Training loss: 2.5176494121551514
Validation loss: 2.2289087682641964

Epoch: 6| Step: 6
Training loss: 2.4558839797973633
Validation loss: 2.2239524600326375

Epoch: 6| Step: 7
Training loss: 2.0445797443389893
Validation loss: 2.202049142570906

Epoch: 6| Step: 8
Training loss: 2.3328635692596436
Validation loss: 2.208635607073384

Epoch: 6| Step: 9
Training loss: 1.6756598949432373
Validation loss: 2.208504117945189

Epoch: 6| Step: 10
Training loss: 2.192596197128296
Validation loss: 2.1866759177177184

Epoch: 6| Step: 11
Training loss: 2.1318142414093018
Validation loss: 2.172436470626503

Epoch: 6| Step: 12
Training loss: 2.8229947090148926
Validation loss: 2.1796217336449573

Epoch: 6| Step: 13
Training loss: 2.7424097061157227
Validation loss: 2.1695755502229095

Epoch: 252| Step: 0
Training loss: 2.1048812866210938
Validation loss: 2.1497480869293213

Epoch: 6| Step: 1
Training loss: 2.445237636566162
Validation loss: 2.1414338414387037

Epoch: 6| Step: 2
Training loss: 1.8806114196777344
Validation loss: 2.1603520403626146

Epoch: 6| Step: 3
Training loss: 2.663817882537842
Validation loss: 2.172937339352023

Epoch: 6| Step: 4
Training loss: 2.8070878982543945
Validation loss: 2.159549254243092

Epoch: 6| Step: 5
Training loss: 2.7498691082000732
Validation loss: 2.172352585741269

Epoch: 6| Step: 6
Training loss: 2.1872963905334473
Validation loss: 2.1975314181338073

Epoch: 6| Step: 7
Training loss: 1.879492998123169
Validation loss: 2.1878788061039423

Epoch: 6| Step: 8
Training loss: 2.6256048679351807
Validation loss: 2.1952103722480034

Epoch: 6| Step: 9
Training loss: 1.915422797203064
Validation loss: 2.189276090232275

Epoch: 6| Step: 10
Training loss: 2.4561069011688232
Validation loss: 2.1966780513845463

Epoch: 6| Step: 11
Training loss: 1.6719136238098145
Validation loss: 2.19252654685769

Epoch: 6| Step: 12
Training loss: 1.8374013900756836
Validation loss: 2.208863296816426

Epoch: 6| Step: 13
Training loss: 2.0944483280181885
Validation loss: 2.2015439874382428

Epoch: 253| Step: 0
Training loss: 2.0878853797912598
Validation loss: 2.1964064605774416

Epoch: 6| Step: 1
Training loss: 1.6359989643096924
Validation loss: 2.180894440220248

Epoch: 6| Step: 2
Training loss: 2.3697619438171387
Validation loss: 2.181874373907684

Epoch: 6| Step: 3
Training loss: 1.8557565212249756
Validation loss: 2.1868333149981756

Epoch: 6| Step: 4
Training loss: 1.696836233139038
Validation loss: 2.1805266487982964

Epoch: 6| Step: 5
Training loss: 1.5467867851257324
Validation loss: 2.1937664785692768

Epoch: 6| Step: 6
Training loss: 2.8895773887634277
Validation loss: 2.2004724369254163

Epoch: 6| Step: 7
Training loss: 2.3626277446746826
Validation loss: 2.2245826439190934

Epoch: 6| Step: 8
Training loss: 2.3502020835876465
Validation loss: 2.2197774699939194

Epoch: 6| Step: 9
Training loss: 2.633758068084717
Validation loss: 2.2161008722038678

Epoch: 6| Step: 10
Training loss: 2.693686008453369
Validation loss: 2.2113886725518013

Epoch: 6| Step: 11
Training loss: 2.553877830505371
Validation loss: 2.2022008152418238

Epoch: 6| Step: 12
Training loss: 2.2479214668273926
Validation loss: 2.1800643346642934

Epoch: 6| Step: 13
Training loss: 2.400692939758301
Validation loss: 2.1851971687809115

Epoch: 254| Step: 0
Training loss: 2.689478874206543
Validation loss: 2.186718302388345

Epoch: 6| Step: 1
Training loss: 2.227499008178711
Validation loss: 2.1777161680242068

Epoch: 6| Step: 2
Training loss: 1.986464023590088
Validation loss: 2.2099482782425417

Epoch: 6| Step: 3
Training loss: 2.701794385910034
Validation loss: 2.212698136606524

Epoch: 6| Step: 4
Training loss: 1.9669854640960693
Validation loss: 2.212271982623685

Epoch: 6| Step: 5
Training loss: 2.160081624984741
Validation loss: 2.2084015223287765

Epoch: 6| Step: 6
Training loss: 2.270794153213501
Validation loss: 2.208588400194722

Epoch: 6| Step: 7
Training loss: 2.3257336616516113
Validation loss: 2.214654880185281

Epoch: 6| Step: 8
Training loss: 2.0937399864196777
Validation loss: 2.1756436388979674

Epoch: 6| Step: 9
Training loss: 2.743313789367676
Validation loss: 2.1779073489609586

Epoch: 6| Step: 10
Training loss: 1.721658706665039
Validation loss: 2.167110719988423

Epoch: 6| Step: 11
Training loss: 2.2172489166259766
Validation loss: 2.1644620216020973

Epoch: 6| Step: 12
Training loss: 1.7659392356872559
Validation loss: 2.188155108882535

Epoch: 6| Step: 13
Training loss: 2.2918946743011475
Validation loss: 2.177152241429975

Epoch: 255| Step: 0
Training loss: 2.9561171531677246
Validation loss: 2.1799140258501937

Epoch: 6| Step: 1
Training loss: 1.7363908290863037
Validation loss: 2.1757548086104856

Epoch: 6| Step: 2
Training loss: 2.156888008117676
Validation loss: 2.189400872876567

Epoch: 6| Step: 3
Training loss: 2.815920829772949
Validation loss: 2.172856048871112

Epoch: 6| Step: 4
Training loss: 2.3124289512634277
Validation loss: 2.1768121616814726

Epoch: 6| Step: 5
Training loss: 2.1981639862060547
Validation loss: 2.166072248130716

Epoch: 6| Step: 6
Training loss: 1.521300196647644
Validation loss: 2.172255253279081

Epoch: 6| Step: 7
Training loss: 2.2758195400238037
Validation loss: 2.1872288770573114

Epoch: 6| Step: 8
Training loss: 2.3927667140960693
Validation loss: 2.1786477463219756

Epoch: 6| Step: 9
Training loss: 2.420267105102539
Validation loss: 2.2121985573922434

Epoch: 6| Step: 10
Training loss: 2.74572491645813
Validation loss: 2.203889681446937

Epoch: 6| Step: 11
Training loss: 2.0665769577026367
Validation loss: 2.2369204823688795

Epoch: 6| Step: 12
Training loss: 2.149690628051758
Validation loss: 2.253727559120424

Epoch: 6| Step: 13
Training loss: 1.1110026836395264
Validation loss: 2.2229997163177817

Epoch: 256| Step: 0
Training loss: 2.0492377281188965
Validation loss: 2.2065645635768933

Epoch: 6| Step: 1
Training loss: 2.227827787399292
Validation loss: 2.178592812630438

Epoch: 6| Step: 2
Training loss: 1.8219976425170898
Validation loss: 2.1780154858866045

Epoch: 6| Step: 3
Training loss: 1.7528049945831299
Validation loss: 2.1775921083265737

Epoch: 6| Step: 4
Training loss: 1.9606794118881226
Validation loss: 2.183144105378018

Epoch: 6| Step: 5
Training loss: 2.6516692638397217
Validation loss: 2.1770255104187997

Epoch: 6| Step: 6
Training loss: 2.2343552112579346
Validation loss: 2.1593538843175417

Epoch: 6| Step: 7
Training loss: 2.260317802429199
Validation loss: 2.1877783062637493

Epoch: 6| Step: 8
Training loss: 2.235373020172119
Validation loss: 2.1764806714109195

Epoch: 6| Step: 9
Training loss: 2.5341665744781494
Validation loss: 2.199352936078143

Epoch: 6| Step: 10
Training loss: 1.95636785030365
Validation loss: 2.1925057570139566

Epoch: 6| Step: 11
Training loss: 2.8721864223480225
Validation loss: 2.2171665442887174

Epoch: 6| Step: 12
Training loss: 2.092238187789917
Validation loss: 2.2115184696771766

Epoch: 6| Step: 13
Training loss: 2.6626064777374268
Validation loss: 2.1942580489702124

Epoch: 257| Step: 0
Training loss: 2.5818638801574707
Validation loss: 2.1947687672030542

Epoch: 6| Step: 1
Training loss: 2.17451548576355
Validation loss: 2.2147868115414857

Epoch: 6| Step: 2
Training loss: 1.871024489402771
Validation loss: 2.2225703962387575

Epoch: 6| Step: 3
Training loss: 2.194584369659424
Validation loss: 2.2114770643172728

Epoch: 6| Step: 4
Training loss: 2.485555648803711
Validation loss: 2.226061322355783

Epoch: 6| Step: 5
Training loss: 1.7256062030792236
Validation loss: 2.257514774158437

Epoch: 6| Step: 6
Training loss: 2.2097654342651367
Validation loss: 2.2267311978083786

Epoch: 6| Step: 7
Training loss: 1.3160563707351685
Validation loss: 2.228537592836606

Epoch: 6| Step: 8
Training loss: 2.4029881954193115
Validation loss: 2.185782168501167

Epoch: 6| Step: 9
Training loss: 1.7723166942596436
Validation loss: 2.1695826143346806

Epoch: 6| Step: 10
Training loss: 2.6717629432678223
Validation loss: 2.1602951762496785

Epoch: 6| Step: 11
Training loss: 2.410977363586426
Validation loss: 2.139167842044625

Epoch: 6| Step: 12
Training loss: 2.630556583404541
Validation loss: 2.164474327077148

Epoch: 6| Step: 13
Training loss: 3.1397640705108643
Validation loss: 2.179451947571129

Epoch: 258| Step: 0
Training loss: 2.028296947479248
Validation loss: 2.169177939814906

Epoch: 6| Step: 1
Training loss: 2.4032845497131348
Validation loss: 2.1715783021783315

Epoch: 6| Step: 2
Training loss: 1.827566146850586
Validation loss: 2.193092002663561

Epoch: 6| Step: 3
Training loss: 2.5250654220581055
Validation loss: 2.1969595545081684

Epoch: 6| Step: 4
Training loss: 2.84092378616333
Validation loss: 2.1957572890866186

Epoch: 6| Step: 5
Training loss: 1.4318082332611084
Validation loss: 2.19788239079137

Epoch: 6| Step: 6
Training loss: 2.753870725631714
Validation loss: 2.2010870659223167

Epoch: 6| Step: 7
Training loss: 2.6147265434265137
Validation loss: 2.1988636985901864

Epoch: 6| Step: 8
Training loss: 2.1460978984832764
Validation loss: 2.2108980481342604

Epoch: 6| Step: 9
Training loss: 3.710772752761841
Validation loss: 2.216061556211082

Epoch: 6| Step: 10
Training loss: 1.6118569374084473
Validation loss: 2.2256114867425736

Epoch: 6| Step: 11
Training loss: 2.018521308898926
Validation loss: 2.2090259239237797

Epoch: 6| Step: 12
Training loss: 1.8413159847259521
Validation loss: 2.220267939311202

Epoch: 6| Step: 13
Training loss: 1.54578697681427
Validation loss: 2.2217281018534014

Epoch: 259| Step: 0
Training loss: 1.955657958984375
Validation loss: 2.206949749300557

Epoch: 6| Step: 1
Training loss: 1.9286305904388428
Validation loss: 2.2085843470788773

Epoch: 6| Step: 2
Training loss: 2.2771530151367188
Validation loss: 2.195028015362319

Epoch: 6| Step: 3
Training loss: 2.1836705207824707
Validation loss: 2.192256899290187

Epoch: 6| Step: 4
Training loss: 2.506314277648926
Validation loss: 2.1958709737306

Epoch: 6| Step: 5
Training loss: 1.952418565750122
Validation loss: 2.1925183137257895

Epoch: 6| Step: 6
Training loss: 2.147845983505249
Validation loss: 2.186595232255997

Epoch: 6| Step: 7
Training loss: 2.000670909881592
Validation loss: 2.191323172661566

Epoch: 6| Step: 8
Training loss: 2.1497764587402344
Validation loss: 2.1881975525168964

Epoch: 6| Step: 9
Training loss: 3.157681703567505
Validation loss: 2.2009934148480816

Epoch: 6| Step: 10
Training loss: 1.6976321935653687
Validation loss: 2.2011230299549718

Epoch: 6| Step: 11
Training loss: 2.149089813232422
Validation loss: 2.216902414957682

Epoch: 6| Step: 12
Training loss: 2.42785906791687
Validation loss: 2.2116906104549283

Epoch: 6| Step: 13
Training loss: 2.755166530609131
Validation loss: 2.1927184686865857

Epoch: 260| Step: 0
Training loss: 2.3823695182800293
Validation loss: 2.2084340818466677

Epoch: 6| Step: 1
Training loss: 2.1928224563598633
Validation loss: 2.1942145593704714

Epoch: 6| Step: 2
Training loss: 2.5292506217956543
Validation loss: 2.2020073616376488

Epoch: 6| Step: 3
Training loss: 2.5036404132843018
Validation loss: 2.213517463335427

Epoch: 6| Step: 4
Training loss: 2.2517294883728027
Validation loss: 2.2066231107199066

Epoch: 6| Step: 5
Training loss: 1.8610749244689941
Validation loss: 2.1858660226227133

Epoch: 6| Step: 6
Training loss: 1.455437183380127
Validation loss: 2.163279620550012

Epoch: 6| Step: 7
Training loss: 2.111295223236084
Validation loss: 2.1996435042350524

Epoch: 6| Step: 8
Training loss: 2.4856109619140625
Validation loss: 2.1805830527377386

Epoch: 6| Step: 9
Training loss: 2.3721938133239746
Validation loss: 2.176362681132491

Epoch: 6| Step: 10
Training loss: 2.184407949447632
Validation loss: 2.1673788319351854

Epoch: 6| Step: 11
Training loss: 2.1087422370910645
Validation loss: 2.1766341168393373

Epoch: 6| Step: 12
Training loss: 2.0093960762023926
Validation loss: 2.1740440066142748

Epoch: 6| Step: 13
Training loss: 2.3056652545928955
Validation loss: 2.194135260838334

Epoch: 261| Step: 0
Training loss: 2.2523045539855957
Validation loss: 2.2151920500622

Epoch: 6| Step: 1
Training loss: 2.013986110687256
Validation loss: 2.2383402137346167

Epoch: 6| Step: 2
Training loss: 1.9127190113067627
Validation loss: 2.2652264692450084

Epoch: 6| Step: 3
Training loss: 1.8578253984451294
Validation loss: 2.256327344525245

Epoch: 6| Step: 4
Training loss: 2.7169487476348877
Validation loss: 2.277039926539185

Epoch: 6| Step: 5
Training loss: 2.8187077045440674
Validation loss: 2.278726162449006

Epoch: 6| Step: 6
Training loss: 2.572556495666504
Validation loss: 2.2798447096219627

Epoch: 6| Step: 7
Training loss: 2.0096957683563232
Validation loss: 2.278396834609329

Epoch: 6| Step: 8
Training loss: 2.1282782554626465
Validation loss: 2.2577364957460793

Epoch: 6| Step: 9
Training loss: 1.7443549633026123
Validation loss: 2.222256819407145

Epoch: 6| Step: 10
Training loss: 2.0608932971954346
Validation loss: 2.1959090514849593

Epoch: 6| Step: 11
Training loss: 1.6665394306182861
Validation loss: 2.1526491975271576

Epoch: 6| Step: 12
Training loss: 2.8408074378967285
Validation loss: 2.1401127217918314

Epoch: 6| Step: 13
Training loss: 2.730818748474121
Validation loss: 2.145040012175037

Epoch: 262| Step: 0
Training loss: 2.7245755195617676
Validation loss: 2.1327638972190117

Epoch: 6| Step: 1
Training loss: 2.370777130126953
Validation loss: 2.1318041996289323

Epoch: 6| Step: 2
Training loss: 2.428874969482422
Validation loss: 2.1338383600276005

Epoch: 6| Step: 3
Training loss: 2.642573833465576
Validation loss: 2.142148381920271

Epoch: 6| Step: 4
Training loss: 2.6557979583740234
Validation loss: 2.13237073088205

Epoch: 6| Step: 5
Training loss: 1.8991444110870361
Validation loss: 2.1468943485649685

Epoch: 6| Step: 6
Training loss: 2.1857481002807617
Validation loss: 2.156731149201752

Epoch: 6| Step: 7
Training loss: 2.165795087814331
Validation loss: 2.16778403200129

Epoch: 6| Step: 8
Training loss: 1.7348392009735107
Validation loss: 2.173456084343695

Epoch: 6| Step: 9
Training loss: 1.645804524421692
Validation loss: 2.1921757985186834

Epoch: 6| Step: 10
Training loss: 2.9981555938720703
Validation loss: 2.189329929249261

Epoch: 6| Step: 11
Training loss: 1.7870019674301147
Validation loss: 2.210602560350972

Epoch: 6| Step: 12
Training loss: 1.8727588653564453
Validation loss: 2.187644831595882

Epoch: 6| Step: 13
Training loss: 1.7593883275985718
Validation loss: 2.194718357055418

Epoch: 263| Step: 0
Training loss: 2.199855089187622
Validation loss: 2.1903764522203835

Epoch: 6| Step: 1
Training loss: 1.698782205581665
Validation loss: 2.1949389532048214

Epoch: 6| Step: 2
Training loss: 2.440762758255005
Validation loss: 2.222185988580027

Epoch: 6| Step: 3
Training loss: 2.2119545936584473
Validation loss: 2.2388038635253906

Epoch: 6| Step: 4
Training loss: 2.0576419830322266
Validation loss: 2.236764338708693

Epoch: 6| Step: 5
Training loss: 2.9740490913391113
Validation loss: 2.2190375981792325

Epoch: 6| Step: 6
Training loss: 1.9731409549713135
Validation loss: 2.2000166882750807

Epoch: 6| Step: 7
Training loss: 2.374551773071289
Validation loss: 2.2019969737657936

Epoch: 6| Step: 8
Training loss: 2.2763843536376953
Validation loss: 2.178976907525011

Epoch: 6| Step: 9
Training loss: 2.5665996074676514
Validation loss: 2.1759298257930304

Epoch: 6| Step: 10
Training loss: 1.2996728420257568
Validation loss: 2.152803527411594

Epoch: 6| Step: 11
Training loss: 2.224306583404541
Validation loss: 2.1837230356790687

Epoch: 6| Step: 12
Training loss: 2.8693690299987793
Validation loss: 2.1673343694338234

Epoch: 6| Step: 13
Training loss: 1.2294121980667114
Validation loss: 2.1627784082966466

Epoch: 264| Step: 0
Training loss: 1.9704123735427856
Validation loss: 2.1590704956362323

Epoch: 6| Step: 1
Training loss: 2.005126953125
Validation loss: 2.145710822074644

Epoch: 6| Step: 2
Training loss: 2.6596100330352783
Validation loss: 2.1544656266448317

Epoch: 6| Step: 3
Training loss: 2.1287002563476562
Validation loss: 2.1757523039335847

Epoch: 6| Step: 4
Training loss: 2.182950496673584
Validation loss: 2.1776578708361556

Epoch: 6| Step: 5
Training loss: 2.339435577392578
Validation loss: 2.1945640733165126

Epoch: 6| Step: 6
Training loss: 2.122318983078003
Validation loss: 2.224591371833637

Epoch: 6| Step: 7
Training loss: 2.3629684448242188
Validation loss: 2.2755921630449194

Epoch: 6| Step: 8
Training loss: 2.650237560272217
Validation loss: 2.29240822022961

Epoch: 6| Step: 9
Training loss: 2.374816417694092
Validation loss: 2.288343439819992

Epoch: 6| Step: 10
Training loss: 2.34885573387146
Validation loss: 2.2615284099373767

Epoch: 6| Step: 11
Training loss: 1.698599100112915
Validation loss: 2.2197661989478656

Epoch: 6| Step: 12
Training loss: 2.0100345611572266
Validation loss: 2.181784217075635

Epoch: 6| Step: 13
Training loss: 1.8258920907974243
Validation loss: 2.168348107286679

Epoch: 265| Step: 0
Training loss: 2.0684866905212402
Validation loss: 2.1730900015882266

Epoch: 6| Step: 1
Training loss: 2.673994302749634
Validation loss: 2.16195539505251

Epoch: 6| Step: 2
Training loss: 2.652169942855835
Validation loss: 2.1558012141976306

Epoch: 6| Step: 3
Training loss: 1.6988089084625244
Validation loss: 2.154400715263941

Epoch: 6| Step: 4
Training loss: 2.353212833404541
Validation loss: 2.157121850598243

Epoch: 6| Step: 5
Training loss: 2.367733955383301
Validation loss: 2.173121767659341

Epoch: 6| Step: 6
Training loss: 2.20219087600708
Validation loss: 2.2061759169383715

Epoch: 6| Step: 7
Training loss: 1.6555949449539185
Validation loss: 2.2162403239998767

Epoch: 6| Step: 8
Training loss: 2.0838537216186523
Validation loss: 2.250495991399211

Epoch: 6| Step: 9
Training loss: 1.8532246351242065
Validation loss: 2.2785740231954925

Epoch: 6| Step: 10
Training loss: 2.2538561820983887
Validation loss: 2.2714143696651665

Epoch: 6| Step: 11
Training loss: 2.3548758029937744
Validation loss: 2.2433939492830666

Epoch: 6| Step: 12
Training loss: 2.2961997985839844
Validation loss: 2.2568893791526876

Epoch: 6| Step: 13
Training loss: 2.2235822677612305
Validation loss: 2.2450917228575675

Epoch: 266| Step: 0
Training loss: 2.591061592102051
Validation loss: 2.24551490301727

Epoch: 6| Step: 1
Training loss: 2.182788372039795
Validation loss: 2.2592506152327343

Epoch: 6| Step: 2
Training loss: 2.0209178924560547
Validation loss: 2.249368929093884

Epoch: 6| Step: 3
Training loss: 1.239085078239441
Validation loss: 2.2443055747657694

Epoch: 6| Step: 4
Training loss: 1.8197962045669556
Validation loss: 2.2350605123786518

Epoch: 6| Step: 5
Training loss: 2.3604578971862793
Validation loss: 2.2117964593313073

Epoch: 6| Step: 6
Training loss: 1.9787167310714722
Validation loss: 2.2008749797780025

Epoch: 6| Step: 7
Training loss: 3.2489194869995117
Validation loss: 2.1963255123425554

Epoch: 6| Step: 8
Training loss: 2.4865920543670654
Validation loss: 2.1820707141712146

Epoch: 6| Step: 9
Training loss: 2.293900966644287
Validation loss: 2.171411898828322

Epoch: 6| Step: 10
Training loss: 2.335583209991455
Validation loss: 2.149978647949875

Epoch: 6| Step: 11
Training loss: 1.9657163619995117
Validation loss: 2.1745563053315684

Epoch: 6| Step: 12
Training loss: 2.1714069843292236
Validation loss: 2.172037891162339

Epoch: 6| Step: 13
Training loss: 2.306515693664551
Validation loss: 2.1813448834162887

Epoch: 267| Step: 0
Training loss: 2.254800319671631
Validation loss: 2.2057777348385064

Epoch: 6| Step: 1
Training loss: 3.184479236602783
Validation loss: 2.195621121314264

Epoch: 6| Step: 2
Training loss: 1.4249728918075562
Validation loss: 2.1832005336720455

Epoch: 6| Step: 3
Training loss: 2.0099925994873047
Validation loss: 2.190771072141586

Epoch: 6| Step: 4
Training loss: 1.9216105937957764
Validation loss: 2.170660231703071

Epoch: 6| Step: 5
Training loss: 2.1529269218444824
Validation loss: 2.187567831367575

Epoch: 6| Step: 6
Training loss: 2.242128372192383
Validation loss: 2.1943623378712642

Epoch: 6| Step: 7
Training loss: 2.8485617637634277
Validation loss: 2.1801969851216962

Epoch: 6| Step: 8
Training loss: 2.4975013732910156
Validation loss: 2.207226103351962

Epoch: 6| Step: 9
Training loss: 1.9994020462036133
Validation loss: 2.210776472604403

Epoch: 6| Step: 10
Training loss: 1.8709774017333984
Validation loss: 2.202864029074228

Epoch: 6| Step: 11
Training loss: 2.35540771484375
Validation loss: 2.213033649229234

Epoch: 6| Step: 12
Training loss: 1.4174973964691162
Validation loss: 2.2176078365695093

Epoch: 6| Step: 13
Training loss: 2.4515268802642822
Validation loss: 2.244668242751911

Epoch: 268| Step: 0
Training loss: 2.157085657119751
Validation loss: 2.22128612508056

Epoch: 6| Step: 1
Training loss: 2.2903640270233154
Validation loss: 2.209393726882114

Epoch: 6| Step: 2
Training loss: 2.6972646713256836
Validation loss: 2.202716624864968

Epoch: 6| Step: 3
Training loss: 2.081036329269409
Validation loss: 2.203256130218506

Epoch: 6| Step: 4
Training loss: 1.874348521232605
Validation loss: 2.1882456951243903

Epoch: 6| Step: 5
Training loss: 2.399763345718384
Validation loss: 2.160316689040071

Epoch: 6| Step: 6
Training loss: 2.3265857696533203
Validation loss: 2.165526005529588

Epoch: 6| Step: 7
Training loss: 1.7235299348831177
Validation loss: 2.172239459970946

Epoch: 6| Step: 8
Training loss: 2.123548984527588
Validation loss: 2.1716190333007486

Epoch: 6| Step: 9
Training loss: 2.219501495361328
Validation loss: 2.1704591563952866

Epoch: 6| Step: 10
Training loss: 1.7043769359588623
Validation loss: 2.1637216152683383

Epoch: 6| Step: 11
Training loss: 2.328028917312622
Validation loss: 2.1455202102661133

Epoch: 6| Step: 12
Training loss: 2.5956227779388428
Validation loss: 2.1649356144730763

Epoch: 6| Step: 13
Training loss: 1.9504996538162231
Validation loss: 2.178339901790824

Epoch: 269| Step: 0
Training loss: 2.240187644958496
Validation loss: 2.1771513415921118

Epoch: 6| Step: 1
Training loss: 2.05324649810791
Validation loss: 2.18207428532262

Epoch: 6| Step: 2
Training loss: 3.038865327835083
Validation loss: 2.175431814244998

Epoch: 6| Step: 3
Training loss: 1.4744417667388916
Validation loss: 2.169033553010674

Epoch: 6| Step: 4
Training loss: 2.4765191078186035
Validation loss: 2.192851080689379

Epoch: 6| Step: 5
Training loss: 2.1979827880859375
Validation loss: 2.2155425728008313

Epoch: 6| Step: 6
Training loss: 2.2771642208099365
Validation loss: 2.220289986620667

Epoch: 6| Step: 7
Training loss: 1.6919147968292236
Validation loss: 2.2072411647406955

Epoch: 6| Step: 8
Training loss: 1.5885759592056274
Validation loss: 2.2190305981584775

Epoch: 6| Step: 9
Training loss: 2.8494129180908203
Validation loss: 2.2119397540246286

Epoch: 6| Step: 10
Training loss: 2.2407116889953613
Validation loss: 2.203533880172237

Epoch: 6| Step: 11
Training loss: 1.7285261154174805
Validation loss: 2.1741766493807555

Epoch: 6| Step: 12
Training loss: 2.425835371017456
Validation loss: 2.164032264422345

Epoch: 6| Step: 13
Training loss: 2.2180404663085938
Validation loss: 2.155382019217296

Epoch: 270| Step: 0
Training loss: 2.4799749851226807
Validation loss: 2.1502258367435907

Epoch: 6| Step: 1
Training loss: 1.8795653581619263
Validation loss: 2.149792003375228

Epoch: 6| Step: 2
Training loss: 1.6502256393432617
Validation loss: 2.1753739336485505

Epoch: 6| Step: 3
Training loss: 2.2848496437072754
Validation loss: 2.179012808748471

Epoch: 6| Step: 4
Training loss: 2.524582862854004
Validation loss: 2.196632772363642

Epoch: 6| Step: 5
Training loss: 1.6069414615631104
Validation loss: 2.2086972344306206

Epoch: 6| Step: 6
Training loss: 2.5588831901550293
Validation loss: 2.2108859644141248

Epoch: 6| Step: 7
Training loss: 2.3545846939086914
Validation loss: 2.2111260250050533

Epoch: 6| Step: 8
Training loss: 2.144230842590332
Validation loss: 2.2185464315516974

Epoch: 6| Step: 9
Training loss: 2.6310362815856934
Validation loss: 2.2113861140384468

Epoch: 6| Step: 10
Training loss: 2.703822135925293
Validation loss: 2.209442546290736

Epoch: 6| Step: 11
Training loss: 1.4170633554458618
Validation loss: 2.1790684653866674

Epoch: 6| Step: 12
Training loss: 2.324125289916992
Validation loss: 2.178913116455078

Epoch: 6| Step: 13
Training loss: 1.6284736394882202
Validation loss: 2.1595953626017415

Epoch: 271| Step: 0
Training loss: 1.9777390956878662
Validation loss: 2.170403545902621

Epoch: 6| Step: 1
Training loss: 2.1950454711914062
Validation loss: 2.158429168885754

Epoch: 6| Step: 2
Training loss: 1.7076339721679688
Validation loss: 2.1696804620886363

Epoch: 6| Step: 3
Training loss: 2.7478036880493164
Validation loss: 2.1833341685674523

Epoch: 6| Step: 4
Training loss: 2.173434257507324
Validation loss: 2.195096360739841

Epoch: 6| Step: 5
Training loss: 2.0669872760772705
Validation loss: 2.1754034385886243

Epoch: 6| Step: 6
Training loss: 2.279604196548462
Validation loss: 2.1962768185523247

Epoch: 6| Step: 7
Training loss: 2.523784637451172
Validation loss: 2.1948542902546544

Epoch: 6| Step: 8
Training loss: 2.328979015350342
Validation loss: 2.193921060972316

Epoch: 6| Step: 9
Training loss: 1.897891879081726
Validation loss: 2.202876170476278

Epoch: 6| Step: 10
Training loss: 2.392521858215332
Validation loss: 2.181679907665458

Epoch: 6| Step: 11
Training loss: 2.6500420570373535
Validation loss: 2.1814910775871685

Epoch: 6| Step: 12
Training loss: 1.4444175958633423
Validation loss: 2.1800332710307133

Epoch: 6| Step: 13
Training loss: 2.142286539077759
Validation loss: 2.160927616139894

Epoch: 272| Step: 0
Training loss: 2.1625380516052246
Validation loss: 2.159297581641905

Epoch: 6| Step: 1
Training loss: 2.0317883491516113
Validation loss: 2.1623353778675036

Epoch: 6| Step: 2
Training loss: 1.5609683990478516
Validation loss: 2.161702673922303

Epoch: 6| Step: 3
Training loss: 2.2521493434906006
Validation loss: 2.184992397985151

Epoch: 6| Step: 4
Training loss: 2.389739513397217
Validation loss: 2.1984555170100224

Epoch: 6| Step: 5
Training loss: 1.9069684743881226
Validation loss: 2.174482724999869

Epoch: 6| Step: 6
Training loss: 2.8305139541625977
Validation loss: 2.191510751683225

Epoch: 6| Step: 7
Training loss: 1.7578319311141968
Validation loss: 2.1880554588892127

Epoch: 6| Step: 8
Training loss: 2.233083486557007
Validation loss: 2.1747824530447684

Epoch: 6| Step: 9
Training loss: 2.361130714416504
Validation loss: 2.1775599807821293

Epoch: 6| Step: 10
Training loss: 2.499687671661377
Validation loss: 2.14433108093918

Epoch: 6| Step: 11
Training loss: 2.245152473449707
Validation loss: 2.140341507491245

Epoch: 6| Step: 12
Training loss: 1.7968273162841797
Validation loss: 2.138323676201605

Epoch: 6| Step: 13
Training loss: 2.410867929458618
Validation loss: 2.1553773290367535

Epoch: 273| Step: 0
Training loss: 1.3641574382781982
Validation loss: 2.1816754674398773

Epoch: 6| Step: 1
Training loss: 2.447394847869873
Validation loss: 2.206486560965097

Epoch: 6| Step: 2
Training loss: 2.4537501335144043
Validation loss: 2.2437786927787204

Epoch: 6| Step: 3
Training loss: 2.5130667686462402
Validation loss: 2.2550895726808937

Epoch: 6| Step: 4
Training loss: 2.8692264556884766
Validation loss: 2.256962855656942

Epoch: 6| Step: 5
Training loss: 1.7265608310699463
Validation loss: 2.253495452224567

Epoch: 6| Step: 6
Training loss: 1.398931622505188
Validation loss: 2.235857104742399

Epoch: 6| Step: 7
Training loss: 2.329176425933838
Validation loss: 2.218844272757089

Epoch: 6| Step: 8
Training loss: 2.874978542327881
Validation loss: 2.2069394280833583

Epoch: 6| Step: 9
Training loss: 2.139490842819214
Validation loss: 2.179321230098765

Epoch: 6| Step: 10
Training loss: 1.9181530475616455
Validation loss: 2.164348466421968

Epoch: 6| Step: 11
Training loss: 2.2410266399383545
Validation loss: 2.140788544890701

Epoch: 6| Step: 12
Training loss: 2.153503894805908
Validation loss: 2.140056933126142

Epoch: 6| Step: 13
Training loss: 1.7722104787826538
Validation loss: 2.1478892193045667

Epoch: 274| Step: 0
Training loss: 2.5542187690734863
Validation loss: 2.17003511100687

Epoch: 6| Step: 1
Training loss: 1.6357758045196533
Validation loss: 2.1681838868766703

Epoch: 6| Step: 2
Training loss: 1.922532558441162
Validation loss: 2.1934826938054894

Epoch: 6| Step: 3
Training loss: 3.3679256439208984
Validation loss: 2.20161174702388

Epoch: 6| Step: 4
Training loss: 2.0953335762023926
Validation loss: 2.21929225742176

Epoch: 6| Step: 5
Training loss: 1.7822613716125488
Validation loss: 2.2077148781027844

Epoch: 6| Step: 6
Training loss: 2.4162302017211914
Validation loss: 2.212878099051855

Epoch: 6| Step: 7
Training loss: 2.295379638671875
Validation loss: 2.1997637799991074

Epoch: 6| Step: 8
Training loss: 1.965071678161621
Validation loss: 2.198916255786855

Epoch: 6| Step: 9
Training loss: 2.30670428276062
Validation loss: 2.1825301390822216

Epoch: 6| Step: 10
Training loss: 2.043351888656616
Validation loss: 2.1874787192190848

Epoch: 6| Step: 11
Training loss: 1.7798807621002197
Validation loss: 2.2015269469189387

Epoch: 6| Step: 12
Training loss: 1.9686503410339355
Validation loss: 2.1929539865063084

Epoch: 6| Step: 13
Training loss: 1.8891377449035645
Validation loss: 2.172080893670359

Epoch: 275| Step: 0
Training loss: 1.991737723350525
Validation loss: 2.154397867059195

Epoch: 6| Step: 1
Training loss: 2.6586074829101562
Validation loss: 2.1552467756373908

Epoch: 6| Step: 2
Training loss: 1.5279223918914795
Validation loss: 2.1450710834995395

Epoch: 6| Step: 3
Training loss: 3.229203939437866
Validation loss: 2.1434214333052277

Epoch: 6| Step: 4
Training loss: 1.9920392036437988
Validation loss: 2.158836154527562

Epoch: 6| Step: 5
Training loss: 2.74992036819458
Validation loss: 2.1629351518487416

Epoch: 6| Step: 6
Training loss: 1.9788310527801514
Validation loss: 2.1801752018672165

Epoch: 6| Step: 7
Training loss: 1.703428030014038
Validation loss: 2.2107466036273586

Epoch: 6| Step: 8
Training loss: 2.2341861724853516
Validation loss: 2.2089065274884625

Epoch: 6| Step: 9
Training loss: 1.2519844770431519
Validation loss: 2.243711657421563

Epoch: 6| Step: 10
Training loss: 2.2559170722961426
Validation loss: 2.2173042169181247

Epoch: 6| Step: 11
Training loss: 2.2777113914489746
Validation loss: 2.210028809885825

Epoch: 6| Step: 12
Training loss: 2.45984148979187
Validation loss: 2.194603366236533

Epoch: 6| Step: 13
Training loss: 1.9067111015319824
Validation loss: 2.1904785351086686

Epoch: 276| Step: 0
Training loss: 1.9610700607299805
Validation loss: 2.2063630729593258

Epoch: 6| Step: 1
Training loss: 1.6954443454742432
Validation loss: 2.2181435400439846

Epoch: 6| Step: 2
Training loss: 2.5438876152038574
Validation loss: 2.2295758596030613

Epoch: 6| Step: 3
Training loss: 2.2482619285583496
Validation loss: 2.230083059239131

Epoch: 6| Step: 4
Training loss: 2.897773504257202
Validation loss: 2.231662332370717

Epoch: 6| Step: 5
Training loss: 2.4578311443328857
Validation loss: 2.216497290518976

Epoch: 6| Step: 6
Training loss: 1.6407625675201416
Validation loss: 2.188485776224444

Epoch: 6| Step: 7
Training loss: 1.9349758625030518
Validation loss: 2.1585313248377975

Epoch: 6| Step: 8
Training loss: 2.618032455444336
Validation loss: 2.1405397435670257

Epoch: 6| Step: 9
Training loss: 1.4830775260925293
Validation loss: 2.1339822661492134

Epoch: 6| Step: 10
Training loss: 2.4546782970428467
Validation loss: 2.1110052741983885

Epoch: 6| Step: 11
Training loss: 2.691436767578125
Validation loss: 2.1081512628063077

Epoch: 6| Step: 12
Training loss: 1.896850347518921
Validation loss: 2.10109446894738

Epoch: 6| Step: 13
Training loss: 1.9783638715744019
Validation loss: 2.1249640872401576

Epoch: 277| Step: 0
Training loss: 2.409440040588379
Validation loss: 2.146657905270976

Epoch: 6| Step: 1
Training loss: 2.4648401737213135
Validation loss: 2.1886903444925943

Epoch: 6| Step: 2
Training loss: 2.2553699016571045
Validation loss: 2.2112610442664034

Epoch: 6| Step: 3
Training loss: 2.0116629600524902
Validation loss: 2.2427487475897676

Epoch: 6| Step: 4
Training loss: 2.407949686050415
Validation loss: 2.2513116892947944

Epoch: 6| Step: 5
Training loss: 2.6156606674194336
Validation loss: 2.2333233664112706

Epoch: 6| Step: 6
Training loss: 1.555601716041565
Validation loss: 2.226944879818988

Epoch: 6| Step: 7
Training loss: 1.5869736671447754
Validation loss: 2.209498882293701

Epoch: 6| Step: 8
Training loss: 2.133836269378662
Validation loss: 2.1942674216403755

Epoch: 6| Step: 9
Training loss: 2.687727451324463
Validation loss: 2.179175146164433

Epoch: 6| Step: 10
Training loss: 2.2297418117523193
Validation loss: 2.1751873429103563

Epoch: 6| Step: 11
Training loss: 2.8221302032470703
Validation loss: 2.171941982802524

Epoch: 6| Step: 12
Training loss: 1.479604721069336
Validation loss: 2.1716005981609388

Epoch: 6| Step: 13
Training loss: 0.9280455112457275
Validation loss: 2.1745216808011456

Epoch: 278| Step: 0
Training loss: 2.13763427734375
Validation loss: 2.173252030085492

Epoch: 6| Step: 1
Training loss: 1.4620881080627441
Validation loss: 2.16960496030828

Epoch: 6| Step: 2
Training loss: 2.8214540481567383
Validation loss: 2.1649573926002748

Epoch: 6| Step: 3
Training loss: 1.9280719757080078
Validation loss: 2.156896068203834

Epoch: 6| Step: 4
Training loss: 2.0042593479156494
Validation loss: 2.1689718820715465

Epoch: 6| Step: 5
Training loss: 2.0021824836730957
Validation loss: 2.170885362932759

Epoch: 6| Step: 6
Training loss: 2.7179198265075684
Validation loss: 2.200795714573194

Epoch: 6| Step: 7
Training loss: 2.2752459049224854
Validation loss: 2.1781151935618412

Epoch: 6| Step: 8
Training loss: 2.303452253341675
Validation loss: 2.2036118994476976

Epoch: 6| Step: 9
Training loss: 2.3425822257995605
Validation loss: 2.2138189218377553

Epoch: 6| Step: 10
Training loss: 2.2207725048065186
Validation loss: 2.21884552509554

Epoch: 6| Step: 11
Training loss: 2.1355550289154053
Validation loss: 2.2028531784652383

Epoch: 6| Step: 12
Training loss: 1.6507035493850708
Validation loss: 2.2108993402091404

Epoch: 6| Step: 13
Training loss: 2.0509023666381836
Validation loss: 2.211502657141737

Epoch: 279| Step: 0
Training loss: 2.1977598667144775
Validation loss: 2.230668710124108

Epoch: 6| Step: 1
Training loss: 1.8632450103759766
Validation loss: 2.2232847393199964

Epoch: 6| Step: 2
Training loss: 2.0744524002075195
Validation loss: 2.2277130337171656

Epoch: 6| Step: 3
Training loss: 2.5221340656280518
Validation loss: 2.2105345815740605

Epoch: 6| Step: 4
Training loss: 2.16884183883667
Validation loss: 2.18611539307461

Epoch: 6| Step: 5
Training loss: 1.0389026403427124
Validation loss: 2.1941483482237785

Epoch: 6| Step: 6
Training loss: 2.118896484375
Validation loss: 2.182361915547361

Epoch: 6| Step: 7
Training loss: 1.921669602394104
Validation loss: 2.1849442348685315

Epoch: 6| Step: 8
Training loss: 1.7472656965255737
Validation loss: 2.173845315492281

Epoch: 6| Step: 9
Training loss: 2.176748752593994
Validation loss: 2.1882753833647697

Epoch: 6| Step: 10
Training loss: 2.654900074005127
Validation loss: 2.1951076087131294

Epoch: 6| Step: 11
Training loss: 2.8625309467315674
Validation loss: 2.2012644070450977

Epoch: 6| Step: 12
Training loss: 2.4497673511505127
Validation loss: 2.1794148965548445

Epoch: 6| Step: 13
Training loss: 2.6201112270355225
Validation loss: 2.1801372176857403

Epoch: 280| Step: 0
Training loss: 1.1725109815597534
Validation loss: 2.1380654419622114

Epoch: 6| Step: 1
Training loss: 2.4765636920928955
Validation loss: 2.1275245886977

Epoch: 6| Step: 2
Training loss: 2.427927255630493
Validation loss: 2.1231952764654674

Epoch: 6| Step: 3
Training loss: 2.5828778743743896
Validation loss: 2.1396640526351107

Epoch: 6| Step: 4
Training loss: 2.334470748901367
Validation loss: 2.1192285540283367

Epoch: 6| Step: 5
Training loss: 2.0406343936920166
Validation loss: 2.1357428425101825

Epoch: 6| Step: 6
Training loss: 1.69606614112854
Validation loss: 2.144946857165265

Epoch: 6| Step: 7
Training loss: 2.011253833770752
Validation loss: 2.16638627359944

Epoch: 6| Step: 8
Training loss: 1.7615150213241577
Validation loss: 2.2026690795857418

Epoch: 6| Step: 9
Training loss: 2.0812926292419434
Validation loss: 2.2150146589484265

Epoch: 6| Step: 10
Training loss: 2.718127727508545
Validation loss: 2.247590249584567

Epoch: 6| Step: 11
Training loss: 2.3500585556030273
Validation loss: 2.256957136174684

Epoch: 6| Step: 12
Training loss: 2.185831069946289
Validation loss: 2.223351668286067

Epoch: 6| Step: 13
Training loss: 2.6505353450775146
Validation loss: 2.186785864573653

Epoch: 281| Step: 0
Training loss: 1.005367636680603
Validation loss: 2.1608279046191963

Epoch: 6| Step: 1
Training loss: 1.6923741102218628
Validation loss: 2.1420087045238865

Epoch: 6| Step: 2
Training loss: 1.7326016426086426
Validation loss: 2.126803357114074

Epoch: 6| Step: 3
Training loss: 1.7217741012573242
Validation loss: 2.11279986750695

Epoch: 6| Step: 4
Training loss: 1.6053507328033447
Validation loss: 2.1352290453449374

Epoch: 6| Step: 5
Training loss: 2.5935158729553223
Validation loss: 2.150311387995238

Epoch: 6| Step: 6
Training loss: 2.374427080154419
Validation loss: 2.1460577493072837

Epoch: 6| Step: 7
Training loss: 2.1210134029388428
Validation loss: 2.1566322593278784

Epoch: 6| Step: 8
Training loss: 2.7852225303649902
Validation loss: 2.1638739698676654

Epoch: 6| Step: 9
Training loss: 2.486161231994629
Validation loss: 2.198015720613541

Epoch: 6| Step: 10
Training loss: 2.404972791671753
Validation loss: 2.1999480467970653

Epoch: 6| Step: 11
Training loss: 2.69108247756958
Validation loss: 2.233693772746671

Epoch: 6| Step: 12
Training loss: 2.512314796447754
Validation loss: 2.2644892264437932

Epoch: 6| Step: 13
Training loss: 2.9713547229766846
Validation loss: 2.2654719506540606

Epoch: 282| Step: 0
Training loss: 2.03933048248291
Validation loss: 2.274514030384761

Epoch: 6| Step: 1
Training loss: 1.8900790214538574
Validation loss: 2.2865148513547835

Epoch: 6| Step: 2
Training loss: 2.2556142807006836
Validation loss: 2.2818951273477204

Epoch: 6| Step: 3
Training loss: 1.9640491008758545
Validation loss: 2.270318933712539

Epoch: 6| Step: 4
Training loss: 2.1775193214416504
Validation loss: 2.259456572994109

Epoch: 6| Step: 5
Training loss: 2.4447216987609863
Validation loss: 2.2379350431503786

Epoch: 6| Step: 6
Training loss: 1.6985108852386475
Validation loss: 2.2054606406919417

Epoch: 6| Step: 7
Training loss: 1.9817557334899902
Validation loss: 2.189003534214471

Epoch: 6| Step: 8
Training loss: 2.486931800842285
Validation loss: 2.1962811305958736

Epoch: 6| Step: 9
Training loss: 3.0916171073913574
Validation loss: 2.2108587167596303

Epoch: 6| Step: 10
Training loss: 1.866417407989502
Validation loss: 2.197651086315032

Epoch: 6| Step: 11
Training loss: 2.244025230407715
Validation loss: 2.1729557744918333

Epoch: 6| Step: 12
Training loss: 2.0914196968078613
Validation loss: 2.1698317450861775

Epoch: 6| Step: 13
Training loss: 1.6114124059677124
Validation loss: 2.1385180104163384

Epoch: 283| Step: 0
Training loss: 2.313613176345825
Validation loss: 2.1402299391326083

Epoch: 6| Step: 1
Training loss: 1.8968102931976318
Validation loss: 2.1355880332249466

Epoch: 6| Step: 2
Training loss: 1.8757202625274658
Validation loss: 2.1392139696305796

Epoch: 6| Step: 3
Training loss: 1.6640875339508057
Validation loss: 2.165140346814227

Epoch: 6| Step: 4
Training loss: 2.5370702743530273
Validation loss: 2.167079758900468

Epoch: 6| Step: 5
Training loss: 2.0614776611328125
Validation loss: 2.175770087908673

Epoch: 6| Step: 6
Training loss: 1.8063418865203857
Validation loss: 2.192021785243865

Epoch: 6| Step: 7
Training loss: 2.385862350463867
Validation loss: 2.219896093491585

Epoch: 6| Step: 8
Training loss: 2.9764366149902344
Validation loss: 2.1945972724627425

Epoch: 6| Step: 9
Training loss: 2.1686601638793945
Validation loss: 2.1944876998983402

Epoch: 6| Step: 10
Training loss: 2.1521966457366943
Validation loss: 2.169687928691987

Epoch: 6| Step: 11
Training loss: 1.9465365409851074
Validation loss: 2.156158576729477

Epoch: 6| Step: 12
Training loss: 2.3498973846435547
Validation loss: 2.16906895688785

Epoch: 6| Step: 13
Training loss: 1.5107414722442627
Validation loss: 2.1629408662037184

Epoch: 284| Step: 0
Training loss: 1.8998403549194336
Validation loss: 2.174892005100045

Epoch: 6| Step: 1
Training loss: 2.8154478073120117
Validation loss: 2.1905570158394436

Epoch: 6| Step: 2
Training loss: 2.1399097442626953
Validation loss: 2.19932859559213

Epoch: 6| Step: 3
Training loss: 2.1310665607452393
Validation loss: 2.2337733391792542

Epoch: 6| Step: 4
Training loss: 2.428814172744751
Validation loss: 2.2210964028553297

Epoch: 6| Step: 5
Training loss: 2.1225578784942627
Validation loss: 2.222004249531736

Epoch: 6| Step: 6
Training loss: 1.8127672672271729
Validation loss: 2.219494399204049

Epoch: 6| Step: 7
Training loss: 2.279919147491455
Validation loss: 2.198276117283811

Epoch: 6| Step: 8
Training loss: 1.900728464126587
Validation loss: 2.1926778965098883

Epoch: 6| Step: 9
Training loss: 1.4733738899230957
Validation loss: 2.203764602702151

Epoch: 6| Step: 10
Training loss: 2.3531432151794434
Validation loss: 2.16941297951565

Epoch: 6| Step: 11
Training loss: 2.335617780685425
Validation loss: 2.152083187974909

Epoch: 6| Step: 12
Training loss: 2.13592267036438
Validation loss: 2.1677661736806235

Epoch: 6| Step: 13
Training loss: 1.882561206817627
Validation loss: 2.1606634483542493

Epoch: 285| Step: 0
Training loss: 1.8138837814331055
Validation loss: 2.1478233106674685

Epoch: 6| Step: 1
Training loss: 1.637700080871582
Validation loss: 2.150492124660041

Epoch: 6| Step: 2
Training loss: 2.788715124130249
Validation loss: 2.1621468733715754

Epoch: 6| Step: 3
Training loss: 2.128948450088501
Validation loss: 2.1476714354689403

Epoch: 6| Step: 4
Training loss: 1.6614747047424316
Validation loss: 2.148606636190927

Epoch: 6| Step: 5
Training loss: 1.3886535167694092
Validation loss: 2.160501072483678

Epoch: 6| Step: 6
Training loss: 1.7576732635498047
Validation loss: 2.1580546440616732

Epoch: 6| Step: 7
Training loss: 2.326033115386963
Validation loss: 2.15416576785426

Epoch: 6| Step: 8
Training loss: 2.966238021850586
Validation loss: 2.158160917220577

Epoch: 6| Step: 9
Training loss: 2.675960063934326
Validation loss: 2.1697127126878306

Epoch: 6| Step: 10
Training loss: 1.8636687994003296
Validation loss: 2.1698483600411365

Epoch: 6| Step: 11
Training loss: 1.4803041219711304
Validation loss: 2.194362860853954

Epoch: 6| Step: 12
Training loss: 2.5501155853271484
Validation loss: 2.1962916017860494

Epoch: 6| Step: 13
Training loss: 2.9322245121002197
Validation loss: 2.208303392574351

Epoch: 286| Step: 0
Training loss: 1.7009687423706055
Validation loss: 2.1770356752539195

Epoch: 6| Step: 1
Training loss: 1.881998062133789
Validation loss: 2.1655483963668987

Epoch: 6| Step: 2
Training loss: 2.1130027770996094
Validation loss: 2.1453111492177492

Epoch: 6| Step: 3
Training loss: 2.718867301940918
Validation loss: 2.1712666826863445

Epoch: 6| Step: 4
Training loss: 1.6020276546478271
Validation loss: 2.14667538673647

Epoch: 6| Step: 5
Training loss: 1.8573474884033203
Validation loss: 2.1650759238068775

Epoch: 6| Step: 6
Training loss: 2.203019142150879
Validation loss: 2.185254636631217

Epoch: 6| Step: 7
Training loss: 1.9886530637741089
Validation loss: 2.1890711476725917

Epoch: 6| Step: 8
Training loss: 1.9882616996765137
Validation loss: 2.2023995589184504

Epoch: 6| Step: 9
Training loss: 1.900930643081665
Validation loss: 2.210934369794784

Epoch: 6| Step: 10
Training loss: 1.9239118099212646
Validation loss: 2.208218023341189

Epoch: 6| Step: 11
Training loss: 2.2233872413635254
Validation loss: 2.21454030980346

Epoch: 6| Step: 12
Training loss: 3.0405287742614746
Validation loss: 2.219654852344144

Epoch: 6| Step: 13
Training loss: 2.9359123706817627
Validation loss: 2.220483051833286

Epoch: 287| Step: 0
Training loss: 2.5547547340393066
Validation loss: 2.1821796048072075

Epoch: 6| Step: 1
Training loss: 1.8336552381515503
Validation loss: 2.1919801235198975

Epoch: 6| Step: 2
Training loss: 2.1544461250305176
Validation loss: 2.2091126185591503

Epoch: 6| Step: 3
Training loss: 1.8489367961883545
Validation loss: 2.223990116068112

Epoch: 6| Step: 4
Training loss: 1.9181673526763916
Validation loss: 2.22165923477501

Epoch: 6| Step: 5
Training loss: 2.1600263118743896
Validation loss: 2.237600311156242

Epoch: 6| Step: 6
Training loss: 2.0966079235076904
Validation loss: 2.2221175624478247

Epoch: 6| Step: 7
Training loss: 2.8933615684509277
Validation loss: 2.195068041483561

Epoch: 6| Step: 8
Training loss: 2.7956182956695557
Validation loss: 2.192601639737365

Epoch: 6| Step: 9
Training loss: 1.6406259536743164
Validation loss: 2.1387241873689877

Epoch: 6| Step: 10
Training loss: 1.5728278160095215
Validation loss: 2.127568385934317

Epoch: 6| Step: 11
Training loss: 1.8637752532958984
Validation loss: 2.1008778515682427

Epoch: 6| Step: 12
Training loss: 2.4877500534057617
Validation loss: 2.1073407716648553

Epoch: 6| Step: 13
Training loss: 1.6876784563064575
Validation loss: 2.1154718091410976

Epoch: 288| Step: 0
Training loss: 2.195462465286255
Validation loss: 2.1223650632366056

Epoch: 6| Step: 1
Training loss: 1.7490710020065308
Validation loss: 2.1153430143992105

Epoch: 6| Step: 2
Training loss: 1.7860838174819946
Validation loss: 2.1258285084078388

Epoch: 6| Step: 3
Training loss: 1.7213610410690308
Validation loss: 2.155377444400582

Epoch: 6| Step: 4
Training loss: 2.3694589138031006
Validation loss: 2.180440689927788

Epoch: 6| Step: 5
Training loss: 2.8049964904785156
Validation loss: 2.200579294594385

Epoch: 6| Step: 6
Training loss: 1.6473889350891113
Validation loss: 2.2092295692813013

Epoch: 6| Step: 7
Training loss: 2.358003616333008
Validation loss: 2.214725153420561

Epoch: 6| Step: 8
Training loss: 2.4885706901550293
Validation loss: 2.2001336338699504

Epoch: 6| Step: 9
Training loss: 1.7854106426239014
Validation loss: 2.180833803710117

Epoch: 6| Step: 10
Training loss: 2.512552261352539
Validation loss: 2.1883978869325373

Epoch: 6| Step: 11
Training loss: 2.169358491897583
Validation loss: 2.201017468206344

Epoch: 6| Step: 12
Training loss: 2.1005637645721436
Validation loss: 2.2030651646275676

Epoch: 6| Step: 13
Training loss: 1.9355765581130981
Validation loss: 2.187711295261178

Epoch: 289| Step: 0
Training loss: 2.476442575454712
Validation loss: 2.1772031707148396

Epoch: 6| Step: 1
Training loss: 2.237359046936035
Validation loss: 2.2019907582190728

Epoch: 6| Step: 2
Training loss: 2.1022512912750244
Validation loss: 2.197037760929395

Epoch: 6| Step: 3
Training loss: 2.8133599758148193
Validation loss: 2.2130273901006228

Epoch: 6| Step: 4
Training loss: 1.8553069829940796
Validation loss: 2.1911523213950534

Epoch: 6| Step: 5
Training loss: 2.16178560256958
Validation loss: 2.1838155715696272

Epoch: 6| Step: 6
Training loss: 1.7126283645629883
Validation loss: 2.1658750682748775

Epoch: 6| Step: 7
Training loss: 2.4404242038726807
Validation loss: 2.142824629301666

Epoch: 6| Step: 8
Training loss: 2.242739200592041
Validation loss: 2.1242105755754697

Epoch: 6| Step: 9
Training loss: 2.640594959259033
Validation loss: 2.1332575864689325

Epoch: 6| Step: 10
Training loss: 1.7429344654083252
Validation loss: 2.13839917285468

Epoch: 6| Step: 11
Training loss: 0.9360642433166504
Validation loss: 2.1355305512746177

Epoch: 6| Step: 12
Training loss: 2.1863136291503906
Validation loss: 2.147954756213773

Epoch: 6| Step: 13
Training loss: 1.8580818176269531
Validation loss: 2.1550325424440446

Epoch: 290| Step: 0
Training loss: 2.433337926864624
Validation loss: 2.1876710332849973

Epoch: 6| Step: 1
Training loss: 1.9156534671783447
Validation loss: 2.1907147105022142

Epoch: 6| Step: 2
Training loss: 2.559569835662842
Validation loss: 2.1986032275743383

Epoch: 6| Step: 3
Training loss: 2.27043080329895
Validation loss: 2.199124126024144

Epoch: 6| Step: 4
Training loss: 2.365628242492676
Validation loss: 2.171432105443811

Epoch: 6| Step: 5
Training loss: 1.8974480628967285
Validation loss: 2.171996634493592

Epoch: 6| Step: 6
Training loss: 2.509732723236084
Validation loss: 2.1549131895906184

Epoch: 6| Step: 7
Training loss: 1.8545353412628174
Validation loss: 2.1303292397529847

Epoch: 6| Step: 8
Training loss: 1.8406282663345337
Validation loss: 2.116526981835724

Epoch: 6| Step: 9
Training loss: 2.1290993690490723
Validation loss: 2.122993112892233

Epoch: 6| Step: 10
Training loss: 1.9975765943527222
Validation loss: 2.1059246960506646

Epoch: 6| Step: 11
Training loss: 1.8373680114746094
Validation loss: 2.1396413310881583

Epoch: 6| Step: 12
Training loss: 1.708172082901001
Validation loss: 2.1738355826306086

Epoch: 6| Step: 13
Training loss: 2.0336802005767822
Validation loss: 2.211803574715891

Epoch: 291| Step: 0
Training loss: 2.181621789932251
Validation loss: 2.247347078015727

Epoch: 6| Step: 1
Training loss: 2.1251211166381836
Validation loss: 2.2561514633958057

Epoch: 6| Step: 2
Training loss: 1.9460663795471191
Validation loss: 2.2478427310143747

Epoch: 6| Step: 3
Training loss: 1.5042732954025269
Validation loss: 2.22207534697748

Epoch: 6| Step: 4
Training loss: 2.1772708892822266
Validation loss: 2.1831959216825423

Epoch: 6| Step: 5
Training loss: 2.4005863666534424
Validation loss: 2.1542665932768132

Epoch: 6| Step: 6
Training loss: 2.5573363304138184
Validation loss: 2.125231845404512

Epoch: 6| Step: 7
Training loss: 2.1467816829681396
Validation loss: 2.140800908047666

Epoch: 6| Step: 8
Training loss: 2.2530083656311035
Validation loss: 2.112759713203676

Epoch: 6| Step: 9
Training loss: 2.0291130542755127
Validation loss: 2.112892267524555

Epoch: 6| Step: 10
Training loss: 1.6568913459777832
Validation loss: 2.112103964692803

Epoch: 6| Step: 11
Training loss: 2.27274751663208
Validation loss: 2.1126806351446334

Epoch: 6| Step: 12
Training loss: 2.3173701763153076
Validation loss: 2.1219201575043383

Epoch: 6| Step: 13
Training loss: 1.8471990823745728
Validation loss: 2.114592722667161

Epoch: 292| Step: 0
Training loss: 2.2762579917907715
Validation loss: 2.130045288352556

Epoch: 6| Step: 1
Training loss: 2.263457775115967
Validation loss: 2.136536459768972

Epoch: 6| Step: 2
Training loss: 2.512235164642334
Validation loss: 2.151930650075277

Epoch: 6| Step: 3
Training loss: 2.228938341140747
Validation loss: 2.1562849808764715

Epoch: 6| Step: 4
Training loss: 2.476102828979492
Validation loss: 2.1794494095669

Epoch: 6| Step: 5
Training loss: 1.6998703479766846
Validation loss: 2.1739611279579902

Epoch: 6| Step: 6
Training loss: 1.564381718635559
Validation loss: 2.1576082783360637

Epoch: 6| Step: 7
Training loss: 1.7872958183288574
Validation loss: 2.15080290584154

Epoch: 6| Step: 8
Training loss: 2.3659605979919434
Validation loss: 2.1573031922822357

Epoch: 6| Step: 9
Training loss: 2.1208930015563965
Validation loss: 2.1489529609680176

Epoch: 6| Step: 10
Training loss: 1.5740869045257568
Validation loss: 2.150712646463866

Epoch: 6| Step: 11
Training loss: 2.011960983276367
Validation loss: 2.1741845402666318

Epoch: 6| Step: 12
Training loss: 2.4953551292419434
Validation loss: 2.1381612746946272

Epoch: 6| Step: 13
Training loss: 2.211104154586792
Validation loss: 2.1247609712744273

Epoch: 293| Step: 0
Training loss: 2.3784890174865723
Validation loss: 2.1149389359258834

Epoch: 6| Step: 1
Training loss: 2.310831069946289
Validation loss: 2.1271454531659364

Epoch: 6| Step: 2
Training loss: 2.086979627609253
Validation loss: 2.1232065077750915

Epoch: 6| Step: 3
Training loss: 1.859489917755127
Validation loss: 2.1170680920283

Epoch: 6| Step: 4
Training loss: 2.5658717155456543
Validation loss: 2.1339892392517417

Epoch: 6| Step: 5
Training loss: 2.200432777404785
Validation loss: 2.1211596817098637

Epoch: 6| Step: 6
Training loss: 1.4527473449707031
Validation loss: 2.145810901477773

Epoch: 6| Step: 7
Training loss: 2.535966396331787
Validation loss: 2.1721330919573383

Epoch: 6| Step: 8
Training loss: 2.22605562210083
Validation loss: 2.1567257283836283

Epoch: 6| Step: 9
Training loss: 1.8899694681167603
Validation loss: 2.1707497924886723

Epoch: 6| Step: 10
Training loss: 1.7009150981903076
Validation loss: 2.1749453121615994

Epoch: 6| Step: 11
Training loss: 2.1332945823669434
Validation loss: 2.171585049680484

Epoch: 6| Step: 12
Training loss: 1.3859672546386719
Validation loss: 2.1801360281564857

Epoch: 6| Step: 13
Training loss: 3.073819160461426
Validation loss: 2.168562460971135

Epoch: 294| Step: 0
Training loss: 2.5550265312194824
Validation loss: 2.1628369900488083

Epoch: 6| Step: 1
Training loss: 1.8833832740783691
Validation loss: 2.1455687938197965

Epoch: 6| Step: 2
Training loss: 1.7919713258743286
Validation loss: 2.155009774751561

Epoch: 6| Step: 3
Training loss: 1.7274816036224365
Validation loss: 2.1510966618855796

Epoch: 6| Step: 4
Training loss: 2.492035150527954
Validation loss: 2.1833254521892917

Epoch: 6| Step: 5
Training loss: 2.284420967102051
Validation loss: 2.164056211389521

Epoch: 6| Step: 6
Training loss: 2.232224464416504
Validation loss: 2.1492754631145026

Epoch: 6| Step: 7
Training loss: 1.9564132690429688
Validation loss: 2.1398592149057696

Epoch: 6| Step: 8
Training loss: 1.750119924545288
Validation loss: 2.119790195136942

Epoch: 6| Step: 9
Training loss: 2.526355743408203
Validation loss: 2.1063950920617707

Epoch: 6| Step: 10
Training loss: 2.0974631309509277
Validation loss: 2.100769947933894

Epoch: 6| Step: 11
Training loss: 2.204005718231201
Validation loss: 2.1000923059319936

Epoch: 6| Step: 12
Training loss: 1.3877443075180054
Validation loss: 2.113331284574283

Epoch: 6| Step: 13
Training loss: 2.5944032669067383
Validation loss: 2.131424319359564

Epoch: 295| Step: 0
Training loss: 1.568764328956604
Validation loss: 2.141213363216769

Epoch: 6| Step: 1
Training loss: 2.1714675426483154
Validation loss: 2.1490612594030236

Epoch: 6| Step: 2
Training loss: 2.2279868125915527
Validation loss: 2.151008100919826

Epoch: 6| Step: 3
Training loss: 1.9691485166549683
Validation loss: 2.140613281598655

Epoch: 6| Step: 4
Training loss: 1.9422575235366821
Validation loss: 2.1209285489974485

Epoch: 6| Step: 5
Training loss: 2.225656270980835
Validation loss: 2.1101567155571392

Epoch: 6| Step: 6
Training loss: 1.6439610719680786
Validation loss: 2.090076010714295

Epoch: 6| Step: 7
Training loss: 2.55291748046875
Validation loss: 2.104918905483779

Epoch: 6| Step: 8
Training loss: 2.5969600677490234
Validation loss: 2.096054620640252

Epoch: 6| Step: 9
Training loss: 2.100752830505371
Validation loss: 2.1045956098905174

Epoch: 6| Step: 10
Training loss: 1.8247758150100708
Validation loss: 2.12688023044217

Epoch: 6| Step: 11
Training loss: 1.7310364246368408
Validation loss: 2.1499190663778656

Epoch: 6| Step: 12
Training loss: 2.8174614906311035
Validation loss: 2.2094758120916222

Epoch: 6| Step: 13
Training loss: 1.6007746458053589
Validation loss: 2.1990659634272256

Epoch: 296| Step: 0
Training loss: 2.1940102577209473
Validation loss: 2.2294857348165205

Epoch: 6| Step: 1
Training loss: 1.6464424133300781
Validation loss: 2.2374233404795327

Epoch: 6| Step: 2
Training loss: 2.1789050102233887
Validation loss: 2.203807132218474

Epoch: 6| Step: 3
Training loss: 2.231598377227783
Validation loss: 2.21404625779839

Epoch: 6| Step: 4
Training loss: 2.173866033554077
Validation loss: 2.2015148234623734

Epoch: 6| Step: 5
Training loss: 2.5310683250427246
Validation loss: 2.1845668746579077

Epoch: 6| Step: 6
Training loss: 1.8551216125488281
Validation loss: 2.1647984571354364

Epoch: 6| Step: 7
Training loss: 1.8308128118515015
Validation loss: 2.1506729023430937

Epoch: 6| Step: 8
Training loss: 2.0146644115448
Validation loss: 2.134074544393888

Epoch: 6| Step: 9
Training loss: 2.2266998291015625
Validation loss: 2.142970021053027

Epoch: 6| Step: 10
Training loss: 1.9685101509094238
Validation loss: 2.1151810512747815

Epoch: 6| Step: 11
Training loss: 2.547372341156006
Validation loss: 2.120152393976847

Epoch: 6| Step: 12
Training loss: 1.7853515148162842
Validation loss: 2.0903878634975803

Epoch: 6| Step: 13
Training loss: 1.7107511758804321
Validation loss: 2.1093275905937277

Epoch: 297| Step: 0
Training loss: 2.0089645385742188
Validation loss: 2.117738982682587

Epoch: 6| Step: 1
Training loss: 2.2352523803710938
Validation loss: 2.1268509972480034

Epoch: 6| Step: 2
Training loss: 1.159517526626587
Validation loss: 2.1549690538837063

Epoch: 6| Step: 3
Training loss: 2.0388476848602295
Validation loss: 2.199250469925583

Epoch: 6| Step: 4
Training loss: 1.7056100368499756
Validation loss: 2.2144570722374866

Epoch: 6| Step: 5
Training loss: 2.438849925994873
Validation loss: 2.2548514566113873

Epoch: 6| Step: 6
Training loss: 2.2582221031188965
Validation loss: 2.2439666589101157

Epoch: 6| Step: 7
Training loss: 2.291853427886963
Validation loss: 2.2220787873832126

Epoch: 6| Step: 8
Training loss: 2.251704692840576
Validation loss: 2.1960275762824604

Epoch: 6| Step: 9
Training loss: 2.6058523654937744
Validation loss: 2.1741656282896638

Epoch: 6| Step: 10
Training loss: 2.068378210067749
Validation loss: 2.168042495686521

Epoch: 6| Step: 11
Training loss: 2.6089928150177
Validation loss: 2.1487261710628385

Epoch: 6| Step: 12
Training loss: 1.6929463148117065
Validation loss: 2.1514088082057174

Epoch: 6| Step: 13
Training loss: 1.887015461921692
Validation loss: 2.1287144127712456

Epoch: 298| Step: 0
Training loss: 2.675175189971924
Validation loss: 2.1168757471986996

Epoch: 6| Step: 1
Training loss: 2.396623373031616
Validation loss: 2.0983728721577632

Epoch: 6| Step: 2
Training loss: 1.3998031616210938
Validation loss: 2.0721993882169008

Epoch: 6| Step: 3
Training loss: 2.2734479904174805
Validation loss: 2.0836383809325514

Epoch: 6| Step: 4
Training loss: 1.9884989261627197
Validation loss: 2.058169021401354

Epoch: 6| Step: 5
Training loss: 2.077889919281006
Validation loss: 2.0669651159676175

Epoch: 6| Step: 6
Training loss: 2.3329901695251465
Validation loss: 2.098534660954629

Epoch: 6| Step: 7
Training loss: 1.9099730253219604
Validation loss: 2.1034150251778225

Epoch: 6| Step: 8
Training loss: 2.056063175201416
Validation loss: 2.1325114901347826

Epoch: 6| Step: 9
Training loss: 1.7301102876663208
Validation loss: 2.187086684729463

Epoch: 6| Step: 10
Training loss: 1.623126745223999
Validation loss: 2.220851549538233

Epoch: 6| Step: 11
Training loss: 2.7775650024414062
Validation loss: 2.2664061464289182

Epoch: 6| Step: 12
Training loss: 2.3874216079711914
Validation loss: 2.2908343038251324

Epoch: 6| Step: 13
Training loss: 1.7494641542434692
Validation loss: 2.283476621873917

Epoch: 299| Step: 0
Training loss: 2.392331123352051
Validation loss: 2.2578207523592058

Epoch: 6| Step: 1
Training loss: 2.368637800216675
Validation loss: 2.21165551934191

Epoch: 6| Step: 2
Training loss: 2.046005964279175
Validation loss: 2.179565275869062

Epoch: 6| Step: 3
Training loss: 1.5341342687606812
Validation loss: 2.1798685109743507

Epoch: 6| Step: 4
Training loss: 1.97542142868042
Validation loss: 2.176015243735365

Epoch: 6| Step: 5
Training loss: 1.8897464275360107
Validation loss: 2.1771873581794

Epoch: 6| Step: 6
Training loss: 2.2639153003692627
Validation loss: 2.180201650947653

Epoch: 6| Step: 7
Training loss: 2.1884043216705322
Validation loss: 2.17636546011894

Epoch: 6| Step: 8
Training loss: 2.2885689735412598
Validation loss: 2.1564071280981905

Epoch: 6| Step: 9
Training loss: 2.214200496673584
Validation loss: 2.155106798295052

Epoch: 6| Step: 10
Training loss: 2.005338191986084
Validation loss: 2.149498244767548

Epoch: 6| Step: 11
Training loss: 1.712035059928894
Validation loss: 2.145258620221128

Epoch: 6| Step: 12
Training loss: 2.7958028316497803
Validation loss: 2.1153867501084522

Epoch: 6| Step: 13
Training loss: 2.295480489730835
Validation loss: 2.130363360528023

Epoch: 300| Step: 0
Training loss: 1.5224162340164185
Validation loss: 2.1376979633044173

Epoch: 6| Step: 1
Training loss: 2.6463470458984375
Validation loss: 2.178260833986344

Epoch: 6| Step: 2
Training loss: 2.3473150730133057
Validation loss: 2.218257337488154

Epoch: 6| Step: 3
Training loss: 1.5691674947738647
Validation loss: 2.261812868938651

Epoch: 6| Step: 4
Training loss: 1.9179468154907227
Validation loss: 2.250794046668596

Epoch: 6| Step: 5
Training loss: 2.2528719902038574
Validation loss: 2.2416447849683863

Epoch: 6| Step: 6
Training loss: 2.0712218284606934
Validation loss: 2.2157645430616153

Epoch: 6| Step: 7
Training loss: 2.125845432281494
Validation loss: 2.206964587652555

Epoch: 6| Step: 8
Training loss: 1.7901453971862793
Validation loss: 2.1572610601302116

Epoch: 6| Step: 9
Training loss: 2.2627906799316406
Validation loss: 2.141829039460869

Epoch: 6| Step: 10
Training loss: 1.7299444675445557
Validation loss: 2.1293694024444907

Epoch: 6| Step: 11
Training loss: 2.52714204788208
Validation loss: 2.120692337712934

Epoch: 6| Step: 12
Training loss: 1.929410696029663
Validation loss: 2.1214416014250888

Epoch: 6| Step: 13
Training loss: 2.600795269012451
Validation loss: 2.1217830616940736

Epoch: 301| Step: 0
Training loss: 2.5152554512023926
Validation loss: 2.094205610213741

Epoch: 6| Step: 1
Training loss: 2.62393856048584
Validation loss: 2.098074725879136

Epoch: 6| Step: 2
Training loss: 1.7034711837768555
Validation loss: 2.118201078907136

Epoch: 6| Step: 3
Training loss: 2.644713878631592
Validation loss: 2.123090431254397

Epoch: 6| Step: 4
Training loss: 2.161022663116455
Validation loss: 2.116823216920258

Epoch: 6| Step: 5
Training loss: 2.4889798164367676
Validation loss: 2.1067063475167878

Epoch: 6| Step: 6
Training loss: 1.9055410623550415
Validation loss: 2.1179347448451544

Epoch: 6| Step: 7
Training loss: 1.7258086204528809
Validation loss: 2.1130528244920956

Epoch: 6| Step: 8
Training loss: 1.8085217475891113
Validation loss: 2.1209474250834477

Epoch: 6| Step: 9
Training loss: 1.524322748184204
Validation loss: 2.129529624856928

Epoch: 6| Step: 10
Training loss: 2.2392280101776123
Validation loss: 2.155242813530789

Epoch: 6| Step: 11
Training loss: 2.2613964080810547
Validation loss: 2.1512642932194534

Epoch: 6| Step: 12
Training loss: 1.6667089462280273
Validation loss: 2.1490204564986692

Epoch: 6| Step: 13
Training loss: 2.1557064056396484
Validation loss: 2.1722161128956783

Epoch: 302| Step: 0
Training loss: 1.5731077194213867
Validation loss: 2.1858250607726393

Epoch: 6| Step: 1
Training loss: 2.5569090843200684
Validation loss: 2.155786480954898

Epoch: 6| Step: 2
Training loss: 1.936349868774414
Validation loss: 2.154592373037851

Epoch: 6| Step: 3
Training loss: 2.669524908065796
Validation loss: 2.1192170753273913

Epoch: 6| Step: 4
Training loss: 1.4972364902496338
Validation loss: 2.125201643154185

Epoch: 6| Step: 5
Training loss: 2.674849510192871
Validation loss: 2.1358134028732136

Epoch: 6| Step: 6
Training loss: 1.8464765548706055
Validation loss: 2.1379849705644833

Epoch: 6| Step: 7
Training loss: 2.043422222137451
Validation loss: 2.13334196998227

Epoch: 6| Step: 8
Training loss: 1.9971652030944824
Validation loss: 2.134471636946483

Epoch: 6| Step: 9
Training loss: 1.4679588079452515
Validation loss: 2.1624265024738927

Epoch: 6| Step: 10
Training loss: 2.81270432472229
Validation loss: 2.147254033755231

Epoch: 6| Step: 11
Training loss: 2.39566707611084
Validation loss: 2.1297450629613732

Epoch: 6| Step: 12
Training loss: 1.3294388055801392
Validation loss: 2.1263166396848616

Epoch: 6| Step: 13
Training loss: 2.039801597595215
Validation loss: 2.133967773888701

Epoch: 303| Step: 0
Training loss: 2.6337363719940186
Validation loss: 2.156274612231921

Epoch: 6| Step: 1
Training loss: 2.033900260925293
Validation loss: 2.1531767383698495

Epoch: 6| Step: 2
Training loss: 2.5537405014038086
Validation loss: 2.1830044689998833

Epoch: 6| Step: 3
Training loss: 1.204742670059204
Validation loss: 2.1892552734703146

Epoch: 6| Step: 4
Training loss: 2.2733302116394043
Validation loss: 2.210082459193404

Epoch: 6| Step: 5
Training loss: 2.413647413253784
Validation loss: 2.197012791069605

Epoch: 6| Step: 6
Training loss: 1.9690914154052734
Validation loss: 2.163991653791038

Epoch: 6| Step: 7
Training loss: 1.3608787059783936
Validation loss: 2.1403437724677463

Epoch: 6| Step: 8
Training loss: 2.0843381881713867
Validation loss: 2.128773735415551

Epoch: 6| Step: 9
Training loss: 1.7639565467834473
Validation loss: 2.121008667894589

Epoch: 6| Step: 10
Training loss: 2.2747325897216797
Validation loss: 2.097198209454936

Epoch: 6| Step: 11
Training loss: 1.8605897426605225
Validation loss: 2.0946751717598207

Epoch: 6| Step: 12
Training loss: 2.546355724334717
Validation loss: 2.0850079239055677

Epoch: 6| Step: 13
Training loss: 1.69675612449646
Validation loss: 2.091106160994499

Epoch: 304| Step: 0
Training loss: 1.2319133281707764
Validation loss: 2.121159074127033

Epoch: 6| Step: 1
Training loss: 2.2263574600219727
Validation loss: 2.105672626085179

Epoch: 6| Step: 2
Training loss: 2.4583818912506104
Validation loss: 2.1176715961066623

Epoch: 6| Step: 3
Training loss: 2.7436439990997314
Validation loss: 2.118017236391703

Epoch: 6| Step: 4
Training loss: 1.8161637783050537
Validation loss: 2.145669501314881

Epoch: 6| Step: 5
Training loss: 2.1719143390655518
Validation loss: 2.185730068914352

Epoch: 6| Step: 6
Training loss: 1.8372218608856201
Validation loss: 2.223396393560594

Epoch: 6| Step: 7
Training loss: 2.1152000427246094
Validation loss: 2.260239452444097

Epoch: 6| Step: 8
Training loss: 2.4493160247802734
Validation loss: 2.2600986983186457

Epoch: 6| Step: 9
Training loss: 2.0798449516296387
Validation loss: 2.2574395620694725

Epoch: 6| Step: 10
Training loss: 1.9486178159713745
Validation loss: 2.1656490115709204

Epoch: 6| Step: 11
Training loss: 1.8664805889129639
Validation loss: 2.139859304633192

Epoch: 6| Step: 12
Training loss: 2.025639533996582
Validation loss: 2.1158809302955546

Epoch: 6| Step: 13
Training loss: 1.9436068534851074
Validation loss: 2.0589623758869786

Epoch: 305| Step: 0
Training loss: 1.4683295488357544
Validation loss: 2.0641061490581882

Epoch: 6| Step: 1
Training loss: 1.803088665008545
Validation loss: 2.065553454942601

Epoch: 6| Step: 2
Training loss: 2.035219669342041
Validation loss: 2.0681126143342707

Epoch: 6| Step: 3
Training loss: 2.8789687156677246
Validation loss: 2.082547149350566

Epoch: 6| Step: 4
Training loss: 2.176424741744995
Validation loss: 2.0633440671428556

Epoch: 6| Step: 5
Training loss: 2.6709299087524414
Validation loss: 2.095965544382731

Epoch: 6| Step: 6
Training loss: 2.638272285461426
Validation loss: 2.1214437125831522

Epoch: 6| Step: 7
Training loss: 2.510222911834717
Validation loss: 2.138617689891528

Epoch: 6| Step: 8
Training loss: 1.6428632736206055
Validation loss: 2.15156651055941

Epoch: 6| Step: 9
Training loss: 1.6380200386047363
Validation loss: 2.1904224247060795

Epoch: 6| Step: 10
Training loss: 2.2749829292297363
Validation loss: 2.2011266767337756

Epoch: 6| Step: 11
Training loss: 1.668165683746338
Validation loss: 2.192902131747174

Epoch: 6| Step: 12
Training loss: 1.9501290321350098
Validation loss: 2.243012794884302

Epoch: 6| Step: 13
Training loss: 1.4104137420654297
Validation loss: 2.2050820345519693

Epoch: 306| Step: 0
Training loss: 2.2215425968170166
Validation loss: 2.2033991326567945

Epoch: 6| Step: 1
Training loss: 2.1739416122436523
Validation loss: 2.1985177763046755

Epoch: 6| Step: 2
Training loss: 1.203881025314331
Validation loss: 2.153560302590811

Epoch: 6| Step: 3
Training loss: 2.1935410499572754
Validation loss: 2.1345961132357196

Epoch: 6| Step: 4
Training loss: 1.492897629737854
Validation loss: 2.112010609719061

Epoch: 6| Step: 5
Training loss: 1.8423004150390625
Validation loss: 2.0868440981834167

Epoch: 6| Step: 6
Training loss: 2.1048367023468018
Validation loss: 2.1048994564240977

Epoch: 6| Step: 7
Training loss: 2.706289052963257
Validation loss: 2.118239795008013

Epoch: 6| Step: 8
Training loss: 2.9794840812683105
Validation loss: 2.133120172767229

Epoch: 6| Step: 9
Training loss: 1.392382025718689
Validation loss: 2.1428701287956646

Epoch: 6| Step: 10
Training loss: 2.0379526615142822
Validation loss: 2.1498305836031513

Epoch: 6| Step: 11
Training loss: 2.169940948486328
Validation loss: 2.1623760602807485

Epoch: 6| Step: 12
Training loss: 2.654404878616333
Validation loss: 2.170069356118479

Epoch: 6| Step: 13
Training loss: 1.9174330234527588
Validation loss: 2.145992345707391

Epoch: 307| Step: 0
Training loss: 2.5989904403686523
Validation loss: 2.1595092101763655

Epoch: 6| Step: 1
Training loss: 1.832842230796814
Validation loss: 2.161915652213558

Epoch: 6| Step: 2
Training loss: 2.3137247562408447
Validation loss: 2.1662499045812957

Epoch: 6| Step: 3
Training loss: 2.0544209480285645
Validation loss: 2.189417903141309

Epoch: 6| Step: 4
Training loss: 2.5883095264434814
Validation loss: 2.204965909322103

Epoch: 6| Step: 5
Training loss: 2.08126163482666
Validation loss: 2.2243014253595823

Epoch: 6| Step: 6
Training loss: 1.3677947521209717
Validation loss: 2.2368002450594338

Epoch: 6| Step: 7
Training loss: 2.5979928970336914
Validation loss: 2.2335172545525337

Epoch: 6| Step: 8
Training loss: 2.038923501968384
Validation loss: 2.2355899785154607

Epoch: 6| Step: 9
Training loss: 1.993376612663269
Validation loss: 2.2083005418059645

Epoch: 6| Step: 10
Training loss: 1.9561467170715332
Validation loss: 2.199228045760944

Epoch: 6| Step: 11
Training loss: 1.9075665473937988
Validation loss: 2.157042336720292

Epoch: 6| Step: 12
Training loss: 1.6692850589752197
Validation loss: 2.11302690352163

Epoch: 6| Step: 13
Training loss: 1.9385533332824707
Validation loss: 2.092462037199287

Epoch: 308| Step: 0
Training loss: 1.7130591869354248
Validation loss: 2.0833378966136644

Epoch: 6| Step: 1
Training loss: 1.7776609659194946
Validation loss: 2.080398851825345

Epoch: 6| Step: 2
Training loss: 2.6965954303741455
Validation loss: 2.085625074243033

Epoch: 6| Step: 3
Training loss: 2.567803382873535
Validation loss: 2.104551469126055

Epoch: 6| Step: 4
Training loss: 2.497626781463623
Validation loss: 2.0998286636926795

Epoch: 6| Step: 5
Training loss: 2.510404586791992
Validation loss: 2.106954672003305

Epoch: 6| Step: 6
Training loss: 1.5657397508621216
Validation loss: 2.0952613020455964

Epoch: 6| Step: 7
Training loss: 1.9145535230636597
Validation loss: 2.0981725185148177

Epoch: 6| Step: 8
Training loss: 1.9653388261795044
Validation loss: 2.123384214216663

Epoch: 6| Step: 9
Training loss: 1.3328512907028198
Validation loss: 2.1255045116588636

Epoch: 6| Step: 10
Training loss: 2.069620370864868
Validation loss: 2.149275460550862

Epoch: 6| Step: 11
Training loss: 2.1657910346984863
Validation loss: 2.161955484779932

Epoch: 6| Step: 12
Training loss: 1.852107048034668
Validation loss: 2.181653299639302

Epoch: 6| Step: 13
Training loss: 2.871567726135254
Validation loss: 2.20064547241375

Epoch: 309| Step: 0
Training loss: 1.884131908416748
Validation loss: 2.1918771856574604

Epoch: 6| Step: 1
Training loss: 1.8161883354187012
Validation loss: 2.1594654539579987

Epoch: 6| Step: 2
Training loss: 1.4315885305404663
Validation loss: 2.154849813830468

Epoch: 6| Step: 3
Training loss: 2.2361936569213867
Validation loss: 2.13224115679341

Epoch: 6| Step: 4
Training loss: 2.215860605239868
Validation loss: 2.1252383698699293

Epoch: 6| Step: 5
Training loss: 2.5916190147399902
Validation loss: 2.1212624990811912

Epoch: 6| Step: 6
Training loss: 2.3679487705230713
Validation loss: 2.139916025182252

Epoch: 6| Step: 7
Training loss: 2.054368019104004
Validation loss: 2.126696353317589

Epoch: 6| Step: 8
Training loss: 2.0267691612243652
Validation loss: 2.121553321038523

Epoch: 6| Step: 9
Training loss: 2.4012045860290527
Validation loss: 2.1311761435642036

Epoch: 6| Step: 10
Training loss: 2.2580463886260986
Validation loss: 2.140468784557876

Epoch: 6| Step: 11
Training loss: 1.9191133975982666
Validation loss: 2.129294051918932

Epoch: 6| Step: 12
Training loss: 1.8116711378097534
Validation loss: 2.1265710771724744

Epoch: 6| Step: 13
Training loss: 2.0275344848632812
Validation loss: 2.1163420690003263

Epoch: 310| Step: 0
Training loss: 2.2830562591552734
Validation loss: 2.1087558730956046

Epoch: 6| Step: 1
Training loss: 2.084582567214966
Validation loss: 2.12001621594993

Epoch: 6| Step: 2
Training loss: 1.6747328042984009
Validation loss: 2.144028362407479

Epoch: 6| Step: 3
Training loss: 1.8569445610046387
Validation loss: 2.1390151182810464

Epoch: 6| Step: 4
Training loss: 1.732082486152649
Validation loss: 2.1645883565307944

Epoch: 6| Step: 5
Training loss: 2.610706329345703
Validation loss: 2.1548627730338805

Epoch: 6| Step: 6
Training loss: 1.8947608470916748
Validation loss: 2.1387875656927786

Epoch: 6| Step: 7
Training loss: 1.518296718597412
Validation loss: 2.121294856071472

Epoch: 6| Step: 8
Training loss: 2.607489585876465
Validation loss: 2.0874585413163707

Epoch: 6| Step: 9
Training loss: 1.6854195594787598
Validation loss: 2.0958236930190877

Epoch: 6| Step: 10
Training loss: 2.0170693397521973
Validation loss: 2.099175947968678

Epoch: 6| Step: 11
Training loss: 2.672382116317749
Validation loss: 2.1058050112057756

Epoch: 6| Step: 12
Training loss: 2.4963347911834717
Validation loss: 2.118737751437772

Epoch: 6| Step: 13
Training loss: 1.2921109199523926
Validation loss: 2.1153416505423923

Epoch: 311| Step: 0
Training loss: 1.8057352304458618
Validation loss: 2.1208595345097203

Epoch: 6| Step: 1
Training loss: 2.222198009490967
Validation loss: 2.1497016593974125

Epoch: 6| Step: 2
Training loss: 2.746332883834839
Validation loss: 2.1590578427878757

Epoch: 6| Step: 3
Training loss: 1.5901544094085693
Validation loss: 2.1521573989622054

Epoch: 6| Step: 4
Training loss: 1.807966709136963
Validation loss: 2.162915911725772

Epoch: 6| Step: 5
Training loss: 2.2107245922088623
Validation loss: 2.1558914517843597

Epoch: 6| Step: 6
Training loss: 1.7564575672149658
Validation loss: 2.156852679867898

Epoch: 6| Step: 7
Training loss: 2.3261008262634277
Validation loss: 2.1484741805702128

Epoch: 6| Step: 8
Training loss: 1.9202864170074463
Validation loss: 2.1421444492955364

Epoch: 6| Step: 9
Training loss: 2.204956293106079
Validation loss: 2.1371845481216267

Epoch: 6| Step: 10
Training loss: 1.6641027927398682
Validation loss: 2.116093043358095

Epoch: 6| Step: 11
Training loss: 1.9338401556015015
Validation loss: 2.11471575819036

Epoch: 6| Step: 12
Training loss: 1.5887573957443237
Validation loss: 2.12013086195915

Epoch: 6| Step: 13
Training loss: 3.150146484375
Validation loss: 2.105393978857225

Epoch: 312| Step: 0
Training loss: 1.8862080574035645
Validation loss: 2.127309588975804

Epoch: 6| Step: 1
Training loss: 2.3500099182128906
Validation loss: 2.110147523623641

Epoch: 6| Step: 2
Training loss: 2.1644039154052734
Validation loss: 2.1008378613379692

Epoch: 6| Step: 3
Training loss: 2.3504369258880615
Validation loss: 2.1246765146973314

Epoch: 6| Step: 4
Training loss: 1.9335660934448242
Validation loss: 2.1215116285508677

Epoch: 6| Step: 5
Training loss: 1.716623306274414
Validation loss: 2.1441185602577786

Epoch: 6| Step: 6
Training loss: 2.001972198486328
Validation loss: 2.1360051503745456

Epoch: 6| Step: 7
Training loss: 1.8322405815124512
Validation loss: 2.1395299588480303

Epoch: 6| Step: 8
Training loss: 2.142216444015503
Validation loss: 2.1259938260560394

Epoch: 6| Step: 9
Training loss: 1.692302942276001
Validation loss: 2.1216917037963867

Epoch: 6| Step: 10
Training loss: 2.154557704925537
Validation loss: 2.122007323849586

Epoch: 6| Step: 11
Training loss: 1.8155715465545654
Validation loss: 2.1515904549629457

Epoch: 6| Step: 12
Training loss: 2.060964584350586
Validation loss: 2.140489460319601

Epoch: 6| Step: 13
Training loss: 2.4704604148864746
Validation loss: 2.1639090943080124

Epoch: 313| Step: 0
Training loss: 2.0847716331481934
Validation loss: 2.1528932663702194

Epoch: 6| Step: 1
Training loss: 1.8618566989898682
Validation loss: 2.1488135912085093

Epoch: 6| Step: 2
Training loss: 2.187499761581421
Validation loss: 2.138853144902055

Epoch: 6| Step: 3
Training loss: 2.07377290725708
Validation loss: 2.1644098886879544

Epoch: 6| Step: 4
Training loss: 1.7998372316360474
Validation loss: 2.1656288305918374

Epoch: 6| Step: 5
Training loss: 2.2778472900390625
Validation loss: 2.1633040853725967

Epoch: 6| Step: 6
Training loss: 2.8296961784362793
Validation loss: 2.1541017383657475

Epoch: 6| Step: 7
Training loss: 1.7088186740875244
Validation loss: 2.1449196133562314

Epoch: 6| Step: 8
Training loss: 1.9164550304412842
Validation loss: 2.1519832047083045

Epoch: 6| Step: 9
Training loss: 2.9985642433166504
Validation loss: 2.1332069750755065

Epoch: 6| Step: 10
Training loss: 1.4574110507965088
Validation loss: 2.132666418629308

Epoch: 6| Step: 11
Training loss: 1.2543989419937134
Validation loss: 2.1317533946806386

Epoch: 6| Step: 12
Training loss: 2.358828544616699
Validation loss: 2.130091619747941

Epoch: 6| Step: 13
Training loss: 1.1359702348709106
Validation loss: 2.1248493463762346

Epoch: 314| Step: 0
Training loss: 1.4682292938232422
Validation loss: 2.1028633656040316

Epoch: 6| Step: 1
Training loss: 2.159939765930176
Validation loss: 2.089727222278554

Epoch: 6| Step: 2
Training loss: 2.337122917175293
Validation loss: 2.098314377569383

Epoch: 6| Step: 3
Training loss: 2.5735630989074707
Validation loss: 2.0967981405155633

Epoch: 6| Step: 4
Training loss: 2.368626356124878
Validation loss: 2.077858578774237

Epoch: 6| Step: 5
Training loss: 1.492849349975586
Validation loss: 2.082553227742513

Epoch: 6| Step: 6
Training loss: 2.280103921890259
Validation loss: 2.0851306274373043

Epoch: 6| Step: 7
Training loss: 2.1356887817382812
Validation loss: 2.0868500522387925

Epoch: 6| Step: 8
Training loss: 1.7861158847808838
Validation loss: 2.1226052186822377

Epoch: 6| Step: 9
Training loss: 2.1641616821289062
Validation loss: 2.139401871670959

Epoch: 6| Step: 10
Training loss: 1.8001718521118164
Validation loss: 2.1714915049973356

Epoch: 6| Step: 11
Training loss: 1.6339232921600342
Validation loss: 2.186838411515759

Epoch: 6| Step: 12
Training loss: 2.1353578567504883
Validation loss: 2.1641530221508396

Epoch: 6| Step: 13
Training loss: 2.1027066707611084
Validation loss: 2.175437340172388

Epoch: 315| Step: 0
Training loss: 2.0380001068115234
Validation loss: 2.156625774598891

Epoch: 6| Step: 1
Training loss: 1.7414350509643555
Validation loss: 2.177086942939348

Epoch: 6| Step: 2
Training loss: 2.581134796142578
Validation loss: 2.161165282290469

Epoch: 6| Step: 3
Training loss: 2.168158769607544
Validation loss: 2.1532930174181537

Epoch: 6| Step: 4
Training loss: 3.0556082725524902
Validation loss: 2.1384570675511516

Epoch: 6| Step: 5
Training loss: 2.1563923358917236
Validation loss: 2.112426342502717

Epoch: 6| Step: 6
Training loss: 1.6342226266860962
Validation loss: 2.091923580374769

Epoch: 6| Step: 7
Training loss: 1.7473361492156982
Validation loss: 2.10267888346026

Epoch: 6| Step: 8
Training loss: 1.3831548690795898
Validation loss: 2.1160516174890662

Epoch: 6| Step: 9
Training loss: 2.1034226417541504
Validation loss: 2.122554281706451

Epoch: 6| Step: 10
Training loss: 1.608996033668518
Validation loss: 2.1361921154042727

Epoch: 6| Step: 11
Training loss: 1.788563847541809
Validation loss: 2.1265177496017946

Epoch: 6| Step: 12
Training loss: 1.913219928741455
Validation loss: 2.1425770854437225

Epoch: 6| Step: 13
Training loss: 2.9070017337799072
Validation loss: 2.1032020045864965

Epoch: 316| Step: 0
Training loss: 2.031675338745117
Validation loss: 2.1094402959269862

Epoch: 6| Step: 1
Training loss: 1.4858940839767456
Validation loss: 2.100260442303073

Epoch: 6| Step: 2
Training loss: 1.9516546726226807
Validation loss: 2.081634875266783

Epoch: 6| Step: 3
Training loss: 2.531184673309326
Validation loss: 2.0892174243927

Epoch: 6| Step: 4
Training loss: 1.711495280265808
Validation loss: 2.1011678505969305

Epoch: 6| Step: 5
Training loss: 2.381213665008545
Validation loss: 2.0880269824817614

Epoch: 6| Step: 6
Training loss: 2.197094202041626
Validation loss: 2.0939402400806384

Epoch: 6| Step: 7
Training loss: 1.5596179962158203
Validation loss: 2.074797761055731

Epoch: 6| Step: 8
Training loss: 2.5064005851745605
Validation loss: 2.092457041945509

Epoch: 6| Step: 9
Training loss: 1.4840540885925293
Validation loss: 2.099914320053593

Epoch: 6| Step: 10
Training loss: 2.5514564514160156
Validation loss: 2.102706450288014

Epoch: 6| Step: 11
Training loss: 2.021881580352783
Validation loss: 2.120297678055302

Epoch: 6| Step: 12
Training loss: 2.1153223514556885
Validation loss: 2.1361273591236403

Epoch: 6| Step: 13
Training loss: 1.7154669761657715
Validation loss: 2.143519063149729

Epoch: 317| Step: 0
Training loss: 2.076084852218628
Validation loss: 2.1618822595124603

Epoch: 6| Step: 1
Training loss: 2.1815664768218994
Validation loss: 2.1604479384678665

Epoch: 6| Step: 2
Training loss: 2.3791141510009766
Validation loss: 2.166552077057541

Epoch: 6| Step: 3
Training loss: 2.332991361618042
Validation loss: 2.173645350240892

Epoch: 6| Step: 4
Training loss: 2.2471413612365723
Validation loss: 2.1446118995707524

Epoch: 6| Step: 5
Training loss: 2.1966705322265625
Validation loss: 2.116733597170922

Epoch: 6| Step: 6
Training loss: 2.7427425384521484
Validation loss: 2.0844781539773427

Epoch: 6| Step: 7
Training loss: 2.2406868934631348
Validation loss: 2.0669925405133154

Epoch: 6| Step: 8
Training loss: 1.1783968210220337
Validation loss: 2.070913830111104

Epoch: 6| Step: 9
Training loss: 1.1979055404663086
Validation loss: 2.080559610038675

Epoch: 6| Step: 10
Training loss: 1.4589779376983643
Validation loss: 2.0804692288880706

Epoch: 6| Step: 11
Training loss: 1.9644811153411865
Validation loss: 2.0742173271794475

Epoch: 6| Step: 12
Training loss: 2.24188232421875
Validation loss: 2.0724494149607997

Epoch: 6| Step: 13
Training loss: 1.891939401626587
Validation loss: 2.082497795422872

Epoch: 318| Step: 0
Training loss: 2.109828472137451
Validation loss: 2.1101732715483634

Epoch: 6| Step: 1
Training loss: 2.5208804607391357
Validation loss: 2.125891072775728

Epoch: 6| Step: 2
Training loss: 2.2530386447906494
Validation loss: 2.135690043049474

Epoch: 6| Step: 3
Training loss: 2.0740180015563965
Validation loss: 2.1713864252131474

Epoch: 6| Step: 4
Training loss: 1.4680068492889404
Validation loss: 2.203707900098575

Epoch: 6| Step: 5
Training loss: 2.115811347961426
Validation loss: 2.1906429670190297

Epoch: 6| Step: 6
Training loss: 2.0098814964294434
Validation loss: 2.1752007110144502

Epoch: 6| Step: 7
Training loss: 1.774064540863037
Validation loss: 2.126256458220943

Epoch: 6| Step: 8
Training loss: 1.9511160850524902
Validation loss: 2.1030793087456816

Epoch: 6| Step: 9
Training loss: 1.842669129371643
Validation loss: 2.064906813765085

Epoch: 6| Step: 10
Training loss: 2.042299747467041
Validation loss: 2.0628496113643853

Epoch: 6| Step: 11
Training loss: 1.4684480428695679
Validation loss: 2.054220755894979

Epoch: 6| Step: 12
Training loss: 2.1239013671875
Validation loss: 2.0448627510378437

Epoch: 6| Step: 13
Training loss: 2.551464319229126
Validation loss: 2.0540271933360765

Epoch: 319| Step: 0
Training loss: 1.8782005310058594
Validation loss: 2.0649158159891763

Epoch: 6| Step: 1
Training loss: 3.202488660812378
Validation loss: 2.0775371238749516

Epoch: 6| Step: 2
Training loss: 1.6233110427856445
Validation loss: 2.0619442514193955

Epoch: 6| Step: 3
Training loss: 2.301302909851074
Validation loss: 2.0759016839406823

Epoch: 6| Step: 4
Training loss: 2.465186357498169
Validation loss: 2.055639320804227

Epoch: 6| Step: 5
Training loss: 2.2134556770324707
Validation loss: 2.057779263424617

Epoch: 6| Step: 6
Training loss: 2.1674506664276123
Validation loss: 2.094546397527059

Epoch: 6| Step: 7
Training loss: 1.1636404991149902
Validation loss: 2.1254442789221324

Epoch: 6| Step: 8
Training loss: 1.4530805349349976
Validation loss: 2.117329212927049

Epoch: 6| Step: 9
Training loss: 2.2045748233795166
Validation loss: 2.178421098698852

Epoch: 6| Step: 10
Training loss: 1.3205018043518066
Validation loss: 2.1836440358110654

Epoch: 6| Step: 11
Training loss: 2.4517574310302734
Validation loss: 2.220742725556897

Epoch: 6| Step: 12
Training loss: 1.8652673959732056
Validation loss: 2.2175513364935435

Epoch: 6| Step: 13
Training loss: 2.142119884490967
Validation loss: 2.2141608397165933

Epoch: 320| Step: 0
Training loss: 2.221963882446289
Validation loss: 2.192567717644476

Epoch: 6| Step: 1
Training loss: 1.9545339345932007
Validation loss: 2.1452267336589035

Epoch: 6| Step: 2
Training loss: 2.499258041381836
Validation loss: 2.1402356445148425

Epoch: 6| Step: 3
Training loss: 1.5446027517318726
Validation loss: 2.0772569871717885

Epoch: 6| Step: 4
Training loss: 1.8267438411712646
Validation loss: 2.087387038815406

Epoch: 6| Step: 5
Training loss: 2.049792766571045
Validation loss: 2.067494817959365

Epoch: 6| Step: 6
Training loss: 1.7771098613739014
Validation loss: 2.0628327618363085

Epoch: 6| Step: 7
Training loss: 2.192335605621338
Validation loss: 2.077243851077172

Epoch: 6| Step: 8
Training loss: 2.3982486724853516
Validation loss: 2.0786263378717567

Epoch: 6| Step: 9
Training loss: 2.736673593521118
Validation loss: 2.0811360523264897

Epoch: 6| Step: 10
Training loss: 1.8322659730911255
Validation loss: 2.12190443213268

Epoch: 6| Step: 11
Training loss: 2.1232266426086426
Validation loss: 2.1264969456580376

Epoch: 6| Step: 12
Training loss: 1.4833111763000488
Validation loss: 2.1586960272122453

Epoch: 6| Step: 13
Training loss: 1.16460120677948
Validation loss: 2.153989794433758

Epoch: 321| Step: 0
Training loss: 2.0058655738830566
Validation loss: 2.1644513517297725

Epoch: 6| Step: 1
Training loss: 1.858982801437378
Validation loss: 2.158070038723689

Epoch: 6| Step: 2
Training loss: 2.1622142791748047
Validation loss: 2.1327969181922173

Epoch: 6| Step: 3
Training loss: 2.188001871109009
Validation loss: 2.133564296589103

Epoch: 6| Step: 4
Training loss: 1.748831033706665
Validation loss: 2.11679414010817

Epoch: 6| Step: 5
Training loss: 2.120818853378296
Validation loss: 2.1108637727716917

Epoch: 6| Step: 6
Training loss: 2.6215672492980957
Validation loss: 2.1134046892965994

Epoch: 6| Step: 7
Training loss: 1.7243775129318237
Validation loss: 2.09757706042259

Epoch: 6| Step: 8
Training loss: 1.3080552816390991
Validation loss: 2.1070646624411307

Epoch: 6| Step: 9
Training loss: 2.4270362854003906
Validation loss: 2.1093798439989806

Epoch: 6| Step: 10
Training loss: 2.348728895187378
Validation loss: 2.1224661078504337

Epoch: 6| Step: 11
Training loss: 1.4846028089523315
Validation loss: 2.1091645609947944

Epoch: 6| Step: 12
Training loss: 2.1563780307769775
Validation loss: 2.097202267698062

Epoch: 6| Step: 13
Training loss: 2.104867696762085
Validation loss: 2.1028353168118383

Epoch: 322| Step: 0
Training loss: 2.6055829524993896
Validation loss: 2.0794424587680447

Epoch: 6| Step: 1
Training loss: 2.0560598373413086
Validation loss: 2.0977097506164224

Epoch: 6| Step: 2
Training loss: 1.910066843032837
Validation loss: 2.105572885082614

Epoch: 6| Step: 3
Training loss: 1.6856589317321777
Validation loss: 2.112225846577716

Epoch: 6| Step: 4
Training loss: 1.993300199508667
Validation loss: 2.1235838654220744

Epoch: 6| Step: 5
Training loss: 1.899569034576416
Validation loss: 2.1081433103930567

Epoch: 6| Step: 6
Training loss: 1.2901904582977295
Validation loss: 2.134553773428804

Epoch: 6| Step: 7
Training loss: 2.5887908935546875
Validation loss: 2.1210650013339136

Epoch: 6| Step: 8
Training loss: 1.5161805152893066
Validation loss: 2.0952712566621843

Epoch: 6| Step: 9
Training loss: 2.3597397804260254
Validation loss: 2.104787693228773

Epoch: 6| Step: 10
Training loss: 1.7300360202789307
Validation loss: 2.099965887684976

Epoch: 6| Step: 11
Training loss: 1.964320421218872
Validation loss: 2.127899739050096

Epoch: 6| Step: 12
Training loss: 2.092499256134033
Validation loss: 2.125096531324489

Epoch: 6| Step: 13
Training loss: 2.6023683547973633
Validation loss: 2.13130505623356

Epoch: 323| Step: 0
Training loss: 1.8866817951202393
Validation loss: 2.136665819793619

Epoch: 6| Step: 1
Training loss: 1.8628056049346924
Validation loss: 2.129615673454859

Epoch: 6| Step: 2
Training loss: 1.8119864463806152
Validation loss: 2.1071620269488265

Epoch: 6| Step: 3
Training loss: 1.197187900543213
Validation loss: 2.1419327066790674

Epoch: 6| Step: 4
Training loss: 2.490579605102539
Validation loss: 2.142857964320849

Epoch: 6| Step: 5
Training loss: 2.1475887298583984
Validation loss: 2.1824657327385357

Epoch: 6| Step: 6
Training loss: 1.4973031282424927
Validation loss: 2.1536403753424205

Epoch: 6| Step: 7
Training loss: 1.6649351119995117
Validation loss: 2.146864560342604

Epoch: 6| Step: 8
Training loss: 2.2395424842834473
Validation loss: 2.1652547697867117

Epoch: 6| Step: 9
Training loss: 1.9749574661254883
Validation loss: 2.1499853390519337

Epoch: 6| Step: 10
Training loss: 2.5722429752349854
Validation loss: 2.135129039005567

Epoch: 6| Step: 11
Training loss: 2.548630714416504
Validation loss: 2.1042608932782243

Epoch: 6| Step: 12
Training loss: 1.4985966682434082
Validation loss: 2.1036238798531155

Epoch: 6| Step: 13
Training loss: 3.04032039642334
Validation loss: 2.0844726383045153

Epoch: 324| Step: 0
Training loss: 2.8463199138641357
Validation loss: 2.0922948724480084

Epoch: 6| Step: 1
Training loss: 2.2046568393707275
Validation loss: 2.1147769240922827

Epoch: 6| Step: 2
Training loss: 2.0585265159606934
Validation loss: 2.0916083423040246

Epoch: 6| Step: 3
Training loss: 2.3374366760253906
Validation loss: 2.0931859042054866

Epoch: 6| Step: 4
Training loss: 2.0721182823181152
Validation loss: 2.091175074218422

Epoch: 6| Step: 5
Training loss: 1.5459519624710083
Validation loss: 2.095387238328175

Epoch: 6| Step: 6
Training loss: 2.255810260772705
Validation loss: 2.088724324780126

Epoch: 6| Step: 7
Training loss: 1.3097885847091675
Validation loss: 2.068530117311785

Epoch: 6| Step: 8
Training loss: 1.9143040180206299
Validation loss: 2.053087129387804

Epoch: 6| Step: 9
Training loss: 1.4763184785842896
Validation loss: 2.073930137900896

Epoch: 6| Step: 10
Training loss: 2.1359810829162598
Validation loss: 2.140493321162398

Epoch: 6| Step: 11
Training loss: 2.2741260528564453
Validation loss: 2.255280726699419

Epoch: 6| Step: 12
Training loss: 2.218400001525879
Validation loss: 2.3160720256067093

Epoch: 6| Step: 13
Training loss: 2.2980313301086426
Validation loss: 2.3192813063180573

Epoch: 325| Step: 0
Training loss: 3.0933427810668945
Validation loss: 2.313606533952939

Epoch: 6| Step: 1
Training loss: 1.172005295753479
Validation loss: 2.275469281340158

Epoch: 6| Step: 2
Training loss: 1.453533411026001
Validation loss: 2.1934705677852837

Epoch: 6| Step: 3
Training loss: 1.9988279342651367
Validation loss: 2.1341032289689585

Epoch: 6| Step: 4
Training loss: 2.2079808712005615
Validation loss: 2.109293932555824

Epoch: 6| Step: 5
Training loss: 2.0663604736328125
Validation loss: 2.0506794170666764

Epoch: 6| Step: 6
Training loss: 2.114407777786255
Validation loss: 2.063077119088942

Epoch: 6| Step: 7
Training loss: 2.1826682090759277
Validation loss: 2.0445218522061586

Epoch: 6| Step: 8
Training loss: 1.5403797626495361
Validation loss: 2.038524894304173

Epoch: 6| Step: 9
Training loss: 1.8994004726409912
Validation loss: 2.047419182715877

Epoch: 6| Step: 10
Training loss: 2.146045207977295
Validation loss: 2.0440895467676143

Epoch: 6| Step: 11
Training loss: 2.142522096633911
Validation loss: 2.0548262724312405

Epoch: 6| Step: 12
Training loss: 2.3882977962493896
Validation loss: 2.060522010249476

Epoch: 6| Step: 13
Training loss: 2.269529342651367
Validation loss: 2.057690530694941

Epoch: 326| Step: 0
Training loss: 2.301586151123047
Validation loss: 2.0406596660614014

Epoch: 6| Step: 1
Training loss: 2.754408359527588
Validation loss: 2.078510497206001

Epoch: 6| Step: 2
Training loss: 1.460200309753418
Validation loss: 2.1058825369804137

Epoch: 6| Step: 3
Training loss: 1.8372184038162231
Validation loss: 2.130793804763466

Epoch: 6| Step: 4
Training loss: 2.3153176307678223
Validation loss: 2.163165210395731

Epoch: 6| Step: 5
Training loss: 1.6354706287384033
Validation loss: 2.190312321468066

Epoch: 6| Step: 6
Training loss: 2.1254236698150635
Validation loss: 2.184094562325426

Epoch: 6| Step: 7
Training loss: 1.9441368579864502
Validation loss: 2.140368184735698

Epoch: 6| Step: 8
Training loss: 2.205657958984375
Validation loss: 2.127596362944572

Epoch: 6| Step: 9
Training loss: 2.0539731979370117
Validation loss: 2.083568042324435

Epoch: 6| Step: 10
Training loss: 1.6928757429122925
Validation loss: 2.0540921303533737

Epoch: 6| Step: 11
Training loss: 2.223703145980835
Validation loss: 2.0596267061848796

Epoch: 6| Step: 12
Training loss: 1.9129185676574707
Validation loss: 2.047422088602538

Epoch: 6| Step: 13
Training loss: 1.2374200820922852
Validation loss: 2.0821732385184175

Epoch: 327| Step: 0
Training loss: 1.9782869815826416
Validation loss: 2.066428674164639

Epoch: 6| Step: 1
Training loss: 1.386423110961914
Validation loss: 2.051612477148733

Epoch: 6| Step: 2
Training loss: 1.6340078115463257
Validation loss: 2.071717575032224

Epoch: 6| Step: 3
Training loss: 2.277021884918213
Validation loss: 2.0866400387979325

Epoch: 6| Step: 4
Training loss: 1.6795217990875244
Validation loss: 2.098455467531758

Epoch: 6| Step: 5
Training loss: 2.086805820465088
Validation loss: 2.1179573228282313

Epoch: 6| Step: 6
Training loss: 2.073417901992798
Validation loss: 2.1320374396539505

Epoch: 6| Step: 7
Training loss: 1.8287627696990967
Validation loss: 2.154315174266856

Epoch: 6| Step: 8
Training loss: 1.7558047771453857
Validation loss: 2.1751734466962915

Epoch: 6| Step: 9
Training loss: 2.679159164428711
Validation loss: 2.1826552549997964

Epoch: 6| Step: 10
Training loss: 2.136960744857788
Validation loss: 2.1794166282940934

Epoch: 6| Step: 11
Training loss: 1.9743648767471313
Validation loss: 2.1830439247110838

Epoch: 6| Step: 12
Training loss: 2.6507532596588135
Validation loss: 2.1505425335258566

Epoch: 6| Step: 13
Training loss: 1.5599008798599243
Validation loss: 2.134626260367773

Epoch: 328| Step: 0
Training loss: 1.7061057090759277
Validation loss: 2.0941502637760614

Epoch: 6| Step: 1
Training loss: 1.5744411945343018
Validation loss: 2.085431086119785

Epoch: 6| Step: 2
Training loss: 1.5591535568237305
Validation loss: 2.070316383915563

Epoch: 6| Step: 3
Training loss: 2.029365301132202
Validation loss: 2.0314912155110347

Epoch: 6| Step: 4
Training loss: 2.395730495452881
Validation loss: 2.0167745313336773

Epoch: 6| Step: 5
Training loss: 2.664337158203125
Validation loss: 2.031933214074822

Epoch: 6| Step: 6
Training loss: 2.1780595779418945
Validation loss: 2.048272325146583

Epoch: 6| Step: 7
Training loss: 1.6518388986587524
Validation loss: 2.037345427338795

Epoch: 6| Step: 8
Training loss: 1.49214768409729
Validation loss: 2.037749563494036

Epoch: 6| Step: 9
Training loss: 2.4225564002990723
Validation loss: 2.048134765317363

Epoch: 6| Step: 10
Training loss: 2.1487932205200195
Validation loss: 2.0612896257831204

Epoch: 6| Step: 11
Training loss: 2.7059381008148193
Validation loss: 2.067206521188059

Epoch: 6| Step: 12
Training loss: 1.3063206672668457
Validation loss: 2.0766107907859226

Epoch: 6| Step: 13
Training loss: 2.298656702041626
Validation loss: 2.119897016914942

Epoch: 329| Step: 0
Training loss: 2.248737096786499
Validation loss: 2.150373193525499

Epoch: 6| Step: 1
Training loss: 1.1675872802734375
Validation loss: 2.18706053174952

Epoch: 6| Step: 2
Training loss: 2.359297037124634
Validation loss: 2.221127530579926

Epoch: 6| Step: 3
Training loss: 1.647568702697754
Validation loss: 2.220501953555692

Epoch: 6| Step: 4
Training loss: 2.101165294647217
Validation loss: 2.1699144968422512

Epoch: 6| Step: 5
Training loss: 2.4242451190948486
Validation loss: 2.130292455355326

Epoch: 6| Step: 6
Training loss: 1.7106395959854126
Validation loss: 2.087124511759768

Epoch: 6| Step: 7
Training loss: 2.0271787643432617
Validation loss: 2.0731949190939627

Epoch: 6| Step: 8
Training loss: 2.084002733230591
Validation loss: 2.04657175976743

Epoch: 6| Step: 9
Training loss: 2.162972927093506
Validation loss: 2.044900551919014

Epoch: 6| Step: 10
Training loss: 1.688832402229309
Validation loss: 2.026044853271977

Epoch: 6| Step: 11
Training loss: 2.3700766563415527
Validation loss: 2.022315009947746

Epoch: 6| Step: 12
Training loss: 2.1743454933166504
Validation loss: 2.019316270787229

Epoch: 6| Step: 13
Training loss: 1.724916696548462
Validation loss: 2.0300284201099026

Epoch: 330| Step: 0
Training loss: 1.956026315689087
Validation loss: 2.026259458193215

Epoch: 6| Step: 1
Training loss: 1.7721863985061646
Validation loss: 2.0474262840004376

Epoch: 6| Step: 2
Training loss: 1.8953847885131836
Validation loss: 2.050649945453931

Epoch: 6| Step: 3
Training loss: 2.656763792037964
Validation loss: 2.083040601463728

Epoch: 6| Step: 4
Training loss: 2.0828418731689453
Validation loss: 2.099221899945249

Epoch: 6| Step: 5
Training loss: 1.698652982711792
Validation loss: 2.1341047312623713

Epoch: 6| Step: 6
Training loss: 2.113219976425171
Validation loss: 2.129025178570901

Epoch: 6| Step: 7
Training loss: 1.640529751777649
Validation loss: 2.1231671020548832

Epoch: 6| Step: 8
Training loss: 1.5769356489181519
Validation loss: 2.1041882397026144

Epoch: 6| Step: 9
Training loss: 1.9395713806152344
Validation loss: 2.1288651061314408

Epoch: 6| Step: 10
Training loss: 2.0367696285247803
Validation loss: 2.149999459584554

Epoch: 6| Step: 11
Training loss: 1.537773609161377
Validation loss: 2.1294039167383665

Epoch: 6| Step: 12
Training loss: 2.458177089691162
Validation loss: 2.150071353040716

Epoch: 6| Step: 13
Training loss: 2.6038529872894287
Validation loss: 2.11711585521698

Epoch: 331| Step: 0
Training loss: 1.3875547647476196
Validation loss: 2.1012751158847602

Epoch: 6| Step: 1
Training loss: 1.8962719440460205
Validation loss: 2.0935518818516887

Epoch: 6| Step: 2
Training loss: 2.425832509994507
Validation loss: 2.0956039223619687

Epoch: 6| Step: 3
Training loss: 1.8145872354507446
Validation loss: 2.0920290165050055

Epoch: 6| Step: 4
Training loss: 2.143850564956665
Validation loss: 2.0785484288328435

Epoch: 6| Step: 5
Training loss: 1.7848572731018066
Validation loss: 2.0653467101435505

Epoch: 6| Step: 6
Training loss: 2.0520880222320557
Validation loss: 2.0617646683928785

Epoch: 6| Step: 7
Training loss: 1.9137626886367798
Validation loss: 2.07334719422043

Epoch: 6| Step: 8
Training loss: 2.25545334815979
Validation loss: 2.0812353062373337

Epoch: 6| Step: 9
Training loss: 2.197720527648926
Validation loss: 2.0751077872450634

Epoch: 6| Step: 10
Training loss: 1.9965996742248535
Validation loss: 2.1087433035655687

Epoch: 6| Step: 11
Training loss: 1.64853036403656
Validation loss: 2.0993667302593106

Epoch: 6| Step: 12
Training loss: 2.2895426750183105
Validation loss: 2.102864060350644

Epoch: 6| Step: 13
Training loss: 1.7076133489608765
Validation loss: 2.0646167237271547

Epoch: 332| Step: 0
Training loss: 1.983052372932434
Validation loss: 2.074651866830805

Epoch: 6| Step: 1
Training loss: 2.3722634315490723
Validation loss: 2.0687976473121235

Epoch: 6| Step: 2
Training loss: 2.590543270111084
Validation loss: 2.056373078335998

Epoch: 6| Step: 3
Training loss: 1.8893563747406006
Validation loss: 2.0508333483049945

Epoch: 6| Step: 4
Training loss: 2.2151622772216797
Validation loss: 2.0612422625223794

Epoch: 6| Step: 5
Training loss: 1.7926968336105347
Validation loss: 2.0515777462272236

Epoch: 6| Step: 6
Training loss: 1.8192906379699707
Validation loss: 2.0812879454705024

Epoch: 6| Step: 7
Training loss: 1.6439355611801147
Validation loss: 2.112425443946674

Epoch: 6| Step: 8
Training loss: 1.6361587047576904
Validation loss: 2.118844703961444

Epoch: 6| Step: 9
Training loss: 2.252950668334961
Validation loss: 2.1225382102433072

Epoch: 6| Step: 10
Training loss: 1.6984480619430542
Validation loss: 2.130203048388163

Epoch: 6| Step: 11
Training loss: 1.5628001689910889
Validation loss: 2.1453630565315165

Epoch: 6| Step: 12
Training loss: 1.8158286809921265
Validation loss: 2.122384399496099

Epoch: 6| Step: 13
Training loss: 2.699746608734131
Validation loss: 2.120325508938041

Epoch: 333| Step: 0
Training loss: 2.0831189155578613
Validation loss: 2.085745992199067

Epoch: 6| Step: 1
Training loss: 1.7423882484436035
Validation loss: 2.0850961208343506

Epoch: 6| Step: 2
Training loss: 1.4914474487304688
Validation loss: 2.0605563989249607

Epoch: 6| Step: 3
Training loss: 2.046257972717285
Validation loss: 2.049237637109654

Epoch: 6| Step: 4
Training loss: 2.386310577392578
Validation loss: 2.0453609343497985

Epoch: 6| Step: 5
Training loss: 1.7118927240371704
Validation loss: 2.048213921567445

Epoch: 6| Step: 6
Training loss: 1.6802444458007812
Validation loss: 2.0657003810328822

Epoch: 6| Step: 7
Training loss: 1.198925495147705
Validation loss: 2.0646643292519355

Epoch: 6| Step: 8
Training loss: 2.2504115104675293
Validation loss: 2.084742315353886

Epoch: 6| Step: 9
Training loss: 1.7980951070785522
Validation loss: 2.1176756530679683

Epoch: 6| Step: 10
Training loss: 1.7584049701690674
Validation loss: 2.156428519115653

Epoch: 6| Step: 11
Training loss: 2.845271587371826
Validation loss: 2.175771026201146

Epoch: 6| Step: 12
Training loss: 2.290811061859131
Validation loss: 2.2208022122742026

Epoch: 6| Step: 13
Training loss: 2.823024034500122
Validation loss: 2.1957714275647233

Epoch: 334| Step: 0
Training loss: 1.477309226989746
Validation loss: 2.2374567934261855

Epoch: 6| Step: 1
Training loss: 1.6910669803619385
Validation loss: 2.2290373899603404

Epoch: 6| Step: 2
Training loss: 1.9483002424240112
Validation loss: 2.2191359073885026

Epoch: 6| Step: 3
Training loss: 2.255699634552002
Validation loss: 2.2175548999540267

Epoch: 6| Step: 4
Training loss: 2.1483683586120605
Validation loss: 2.2036016692397413

Epoch: 6| Step: 5
Training loss: 2.4415950775146484
Validation loss: 2.182874966693181

Epoch: 6| Step: 6
Training loss: 1.992305040359497
Validation loss: 2.1539520755890877

Epoch: 6| Step: 7
Training loss: 1.6077930927276611
Validation loss: 2.1560483350548694

Epoch: 6| Step: 8
Training loss: 2.0144009590148926
Validation loss: 2.1232759952545166

Epoch: 6| Step: 9
Training loss: 2.0880517959594727
Validation loss: 2.1007677585847917

Epoch: 6| Step: 10
Training loss: 2.079077959060669
Validation loss: 2.068354352827995

Epoch: 6| Step: 11
Training loss: 1.7017251253128052
Validation loss: 2.068073848242401

Epoch: 6| Step: 12
Training loss: 1.8457906246185303
Validation loss: 2.0489689970529206

Epoch: 6| Step: 13
Training loss: 2.4594242572784424
Validation loss: 2.046573741461641

Epoch: 335| Step: 0
Training loss: 2.4334607124328613
Validation loss: 2.0177726002149683

Epoch: 6| Step: 1
Training loss: 1.2467060089111328
Validation loss: 2.0092755940652665

Epoch: 6| Step: 2
Training loss: 2.075324296951294
Validation loss: 2.012059853922936

Epoch: 6| Step: 3
Training loss: 1.8207039833068848
Validation loss: 2.017687907782934

Epoch: 6| Step: 4
Training loss: 2.0466415882110596
Validation loss: 2.0182818392271638

Epoch: 6| Step: 5
Training loss: 1.7107244729995728
Validation loss: 2.0656025717335362

Epoch: 6| Step: 6
Training loss: 2.202929973602295
Validation loss: 2.072533235755018

Epoch: 6| Step: 7
Training loss: 2.0596914291381836
Validation loss: 2.119894568638135

Epoch: 6| Step: 8
Training loss: 1.8912830352783203
Validation loss: 2.166690957161688

Epoch: 6| Step: 9
Training loss: 2.0595757961273193
Validation loss: 2.2255880486580635

Epoch: 6| Step: 10
Training loss: 1.9882361888885498
Validation loss: 2.2371756492122525

Epoch: 6| Step: 11
Training loss: 2.6164801120758057
Validation loss: 2.24843180307778

Epoch: 6| Step: 12
Training loss: 1.9538943767547607
Validation loss: 2.2036030318147395

Epoch: 6| Step: 13
Training loss: 2.0568110942840576
Validation loss: 2.1643678270360476

Epoch: 336| Step: 0
Training loss: 2.4295907020568848
Validation loss: 2.097081063896097

Epoch: 6| Step: 1
Training loss: 2.061173915863037
Validation loss: 2.0791244686290784

Epoch: 6| Step: 2
Training loss: 2.148613452911377
Validation loss: 2.0255791833323817

Epoch: 6| Step: 3
Training loss: 2.3137903213500977
Validation loss: 2.0281498714159896

Epoch: 6| Step: 4
Training loss: 2.3897547721862793
Validation loss: 2.0250032614636164

Epoch: 6| Step: 5
Training loss: 1.5926593542099
Validation loss: 2.0030864438702984

Epoch: 6| Step: 6
Training loss: 1.4788936376571655
Validation loss: 2.0196816126505532

Epoch: 6| Step: 7
Training loss: 2.3077316284179688
Validation loss: 2.0203843091123845

Epoch: 6| Step: 8
Training loss: 1.9955132007598877
Validation loss: 2.0096958093745734

Epoch: 6| Step: 9
Training loss: 2.171151876449585
Validation loss: 2.0403625939482

Epoch: 6| Step: 10
Training loss: 1.6959965229034424
Validation loss: 2.0611861957016813

Epoch: 6| Step: 11
Training loss: 1.7553737163543701
Validation loss: 2.065266009299986

Epoch: 6| Step: 12
Training loss: 1.5731658935546875
Validation loss: 2.1048318698842037

Epoch: 6| Step: 13
Training loss: 1.499470829963684
Validation loss: 2.130003442046463

Epoch: 337| Step: 0
Training loss: 1.9807796478271484
Validation loss: 2.126752979011946

Epoch: 6| Step: 1
Training loss: 2.008070230484009
Validation loss: 2.102698310728996

Epoch: 6| Step: 2
Training loss: 2.0123069286346436
Validation loss: 2.096285717461699

Epoch: 6| Step: 3
Training loss: 1.76817786693573
Validation loss: 2.071299377308097

Epoch: 6| Step: 4
Training loss: 1.368294596672058
Validation loss: 2.0552907977052914

Epoch: 6| Step: 5
Training loss: 2.1120169162750244
Validation loss: 2.045094152932526

Epoch: 6| Step: 6
Training loss: 2.217195749282837
Validation loss: 2.0566409864733295

Epoch: 6| Step: 7
Training loss: 2.2925217151641846
Validation loss: 2.089423715427358

Epoch: 6| Step: 8
Training loss: 1.7362868785858154
Validation loss: 2.058149699241884

Epoch: 6| Step: 9
Training loss: 2.0138638019561768
Validation loss: 2.0887806966740596

Epoch: 6| Step: 10
Training loss: 1.9883760213851929
Validation loss: 2.104636735813592

Epoch: 6| Step: 11
Training loss: 2.1940789222717285
Validation loss: 2.128040377811719

Epoch: 6| Step: 12
Training loss: 1.688402533531189
Validation loss: 2.144653335694344

Epoch: 6| Step: 13
Training loss: 1.9135174751281738
Validation loss: 2.1899290469384964

Epoch: 338| Step: 0
Training loss: 1.6838594675064087
Validation loss: 2.180643807175339

Epoch: 6| Step: 1
Training loss: 1.897751808166504
Validation loss: 2.175164350899317

Epoch: 6| Step: 2
Training loss: 1.5752959251403809
Validation loss: 2.1493321426453127

Epoch: 6| Step: 3
Training loss: 2.2735023498535156
Validation loss: 2.1293630805066837

Epoch: 6| Step: 4
Training loss: 1.7359471321105957
Validation loss: 2.11443591630587

Epoch: 6| Step: 5
Training loss: 2.5654308795928955
Validation loss: 2.0829902220797796

Epoch: 6| Step: 6
Training loss: 1.8416639566421509
Validation loss: 2.0784814152666318

Epoch: 6| Step: 7
Training loss: 1.926107406616211
Validation loss: 2.04883933836414

Epoch: 6| Step: 8
Training loss: 1.4728927612304688
Validation loss: 2.0373785675212903

Epoch: 6| Step: 9
Training loss: 2.1785693168640137
Validation loss: 2.062113365819377

Epoch: 6| Step: 10
Training loss: 2.7478156089782715
Validation loss: 2.0381442116152857

Epoch: 6| Step: 11
Training loss: 1.7859630584716797
Validation loss: 2.055399984441778

Epoch: 6| Step: 12
Training loss: 1.8535118103027344
Validation loss: 2.0517049656119397

Epoch: 6| Step: 13
Training loss: 2.013422966003418
Validation loss: 2.05692966522709

Epoch: 339| Step: 0
Training loss: 2.271186351776123
Validation loss: 2.064017080491589

Epoch: 6| Step: 1
Training loss: 1.7663172483444214
Validation loss: 2.055668930853567

Epoch: 6| Step: 2
Training loss: 1.6195532083511353
Validation loss: 2.060753342925861

Epoch: 6| Step: 3
Training loss: 2.3879048824310303
Validation loss: 2.0478331619693386

Epoch: 6| Step: 4
Training loss: 2.0804076194763184
Validation loss: 2.049014381183091

Epoch: 6| Step: 5
Training loss: 1.8379981517791748
Validation loss: 2.021486199030312

Epoch: 6| Step: 6
Training loss: 2.3114564418792725
Validation loss: 2.0366011845168246

Epoch: 6| Step: 7
Training loss: 1.1669199466705322
Validation loss: 2.0273221820913334

Epoch: 6| Step: 8
Training loss: 1.943800449371338
Validation loss: 2.0447611603685605

Epoch: 6| Step: 9
Training loss: 1.8764007091522217
Validation loss: 2.0368222754488707

Epoch: 6| Step: 10
Training loss: 1.8648346662521362
Validation loss: 2.0387877315603276

Epoch: 6| Step: 11
Training loss: 2.0995686054229736
Validation loss: 2.0570249147312616

Epoch: 6| Step: 12
Training loss: 2.041895866394043
Validation loss: 2.0761368813053256

Epoch: 6| Step: 13
Training loss: 2.3157546520233154
Validation loss: 2.0941154187725437

Epoch: 340| Step: 0
Training loss: 2.2917227745056152
Validation loss: 2.104184445514474

Epoch: 6| Step: 1
Training loss: 1.9630845785140991
Validation loss: 2.122974153487913

Epoch: 6| Step: 2
Training loss: 1.7965011596679688
Validation loss: 2.118327357435739

Epoch: 6| Step: 3
Training loss: 2.2403059005737305
Validation loss: 2.142371836528983

Epoch: 6| Step: 4
Training loss: 1.1778481006622314
Validation loss: 2.1775216697364725

Epoch: 6| Step: 5
Training loss: 1.8001600503921509
Validation loss: 2.169219393883982

Epoch: 6| Step: 6
Training loss: 1.862313151359558
Validation loss: 2.1393263878360873

Epoch: 6| Step: 7
Training loss: 2.006514310836792
Validation loss: 2.0851863712392826

Epoch: 6| Step: 8
Training loss: 1.8306764364242554
Validation loss: 2.047669874724521

Epoch: 6| Step: 9
Training loss: 1.304961085319519
Validation loss: 2.044121129538423

Epoch: 6| Step: 10
Training loss: 2.2157742977142334
Validation loss: 2.043628003007622

Epoch: 6| Step: 11
Training loss: 2.3825466632843018
Validation loss: 1.9926855538481025

Epoch: 6| Step: 12
Training loss: 1.9017891883850098
Validation loss: 2.011816388817244

Epoch: 6| Step: 13
Training loss: 2.772432327270508
Validation loss: 1.9969643136506439

Epoch: 341| Step: 0
Training loss: 1.6588720083236694
Validation loss: 1.995165615953425

Epoch: 6| Step: 1
Training loss: 2.3150129318237305
Validation loss: 2.005960556768602

Epoch: 6| Step: 2
Training loss: 2.1015625
Validation loss: 2.0207605951575824

Epoch: 6| Step: 3
Training loss: 1.8938357830047607
Validation loss: 2.036644107551985

Epoch: 6| Step: 4
Training loss: 2.08469557762146
Validation loss: 2.05486899293879

Epoch: 6| Step: 5
Training loss: 1.4818307161331177
Validation loss: 2.110707131765222

Epoch: 6| Step: 6
Training loss: 2.4700069427490234
Validation loss: 2.092428184324695

Epoch: 6| Step: 7
Training loss: 1.6795258522033691
Validation loss: 2.1311187513412966

Epoch: 6| Step: 8
Training loss: 1.8716986179351807
Validation loss: 2.1666309679708173

Epoch: 6| Step: 9
Training loss: 1.7330621480941772
Validation loss: 2.15649676322937

Epoch: 6| Step: 10
Training loss: 2.218616485595703
Validation loss: 2.1350720569651616

Epoch: 6| Step: 11
Training loss: 2.240356683731079
Validation loss: 2.114395256965391

Epoch: 6| Step: 12
Training loss: 1.6115472316741943
Validation loss: 2.084813011589871

Epoch: 6| Step: 13
Training loss: 1.9168930053710938
Validation loss: 2.0766932502869637

Epoch: 342| Step: 0
Training loss: 1.9771289825439453
Validation loss: 2.094674669286256

Epoch: 6| Step: 1
Training loss: 1.870119571685791
Validation loss: 2.094594786244054

Epoch: 6| Step: 2
Training loss: 1.6220160722732544
Validation loss: 2.1053155750356694

Epoch: 6| Step: 3
Training loss: 2.2402472496032715
Validation loss: 2.0964937363901446

Epoch: 6| Step: 4
Training loss: 1.8067142963409424
Validation loss: 2.101530603183213

Epoch: 6| Step: 5
Training loss: 2.3707776069641113
Validation loss: 2.0953533136716453

Epoch: 6| Step: 6
Training loss: 2.1354546546936035
Validation loss: 2.1017480845092447

Epoch: 6| Step: 7
Training loss: 2.074942111968994
Validation loss: 2.0762838496956775

Epoch: 6| Step: 8
Training loss: 2.0378520488739014
Validation loss: 2.0799448490142822

Epoch: 6| Step: 9
Training loss: 1.263843297958374
Validation loss: 2.072026453992372

Epoch: 6| Step: 10
Training loss: 2.4069015979766846
Validation loss: 2.047184322469978

Epoch: 6| Step: 11
Training loss: 1.246680736541748
Validation loss: 2.0741917792186944

Epoch: 6| Step: 12
Training loss: 2.1721866130828857
Validation loss: 2.041176285794986

Epoch: 6| Step: 13
Training loss: 1.8945761919021606
Validation loss: 2.0427700332416

Epoch: 343| Step: 0
Training loss: 1.7644919157028198
Validation loss: 2.04140902591008

Epoch: 6| Step: 1
Training loss: 1.7070558071136475
Validation loss: 2.013650549355374

Epoch: 6| Step: 2
Training loss: 2.1452484130859375
Validation loss: 2.0114592326584684

Epoch: 6| Step: 3
Training loss: 1.6873811483383179
Validation loss: 2.0301820244840396

Epoch: 6| Step: 4
Training loss: 1.7508373260498047
Validation loss: 2.0448961001570507

Epoch: 6| Step: 5
Training loss: 2.115482807159424
Validation loss: 2.044928868611654

Epoch: 6| Step: 6
Training loss: 1.5458943843841553
Validation loss: 2.0666877005689885

Epoch: 6| Step: 7
Training loss: 1.8163312673568726
Validation loss: 2.0955122042727727

Epoch: 6| Step: 8
Training loss: 1.9515091180801392
Validation loss: 2.0925149545874646

Epoch: 6| Step: 9
Training loss: 2.3237509727478027
Validation loss: 2.082440040444815

Epoch: 6| Step: 10
Training loss: 1.7159899473190308
Validation loss: 2.0888242144738474

Epoch: 6| Step: 11
Training loss: 1.8335373401641846
Validation loss: 2.083561087167391

Epoch: 6| Step: 12
Training loss: 2.6020519733428955
Validation loss: 2.0779916842778525

Epoch: 6| Step: 13
Training loss: 2.4062299728393555
Validation loss: 2.0876730180555776

Epoch: 344| Step: 0
Training loss: 1.3718887567520142
Validation loss: 2.0962744220610587

Epoch: 6| Step: 1
Training loss: 2.3173186779022217
Validation loss: 2.1025773838002193

Epoch: 6| Step: 2
Training loss: 1.6596057415008545
Validation loss: 2.0855252678676317

Epoch: 6| Step: 3
Training loss: 1.633558750152588
Validation loss: 2.113534491549256

Epoch: 6| Step: 4
Training loss: 2.2966511249542236
Validation loss: 2.094341548540259

Epoch: 6| Step: 5
Training loss: 1.6491272449493408
Validation loss: 2.0877542534182147

Epoch: 6| Step: 6
Training loss: 1.897986650466919
Validation loss: 2.1055441005255586

Epoch: 6| Step: 7
Training loss: 1.7802196741104126
Validation loss: 2.08696243070787

Epoch: 6| Step: 8
Training loss: 1.588525652885437
Validation loss: 2.0782056700798774

Epoch: 6| Step: 9
Training loss: 2.7799339294433594
Validation loss: 2.0816990444737096

Epoch: 6| Step: 10
Training loss: 1.684537649154663
Validation loss: 2.086802383904816

Epoch: 6| Step: 11
Training loss: 1.8653994798660278
Validation loss: 2.081865204277859

Epoch: 6| Step: 12
Training loss: 2.3558216094970703
Validation loss: 2.0739068472257225

Epoch: 6| Step: 13
Training loss: 2.2742655277252197
Validation loss: 2.0590889556433565

Epoch: 345| Step: 0
Training loss: 1.4553961753845215
Validation loss: 2.0757694526385237

Epoch: 6| Step: 1
Training loss: 1.8241194486618042
Validation loss: 2.0494936281634915

Epoch: 6| Step: 2
Training loss: 1.3914721012115479
Validation loss: 2.0529935923955773

Epoch: 6| Step: 3
Training loss: 1.7080109119415283
Validation loss: 2.0638826995767574

Epoch: 6| Step: 4
Training loss: 2.7408571243286133
Validation loss: 2.0880522061419744

Epoch: 6| Step: 5
Training loss: 1.6077207326889038
Validation loss: 2.0954232446609007

Epoch: 6| Step: 6
Training loss: 2.3902695178985596
Validation loss: 2.094646474366547

Epoch: 6| Step: 7
Training loss: 2.1160216331481934
Validation loss: 2.081447514154578

Epoch: 6| Step: 8
Training loss: 1.284970998764038
Validation loss: 2.1093508979325652

Epoch: 6| Step: 9
Training loss: 2.2345664501190186
Validation loss: 2.109752091028357

Epoch: 6| Step: 10
Training loss: 1.9921860694885254
Validation loss: 2.125247101629934

Epoch: 6| Step: 11
Training loss: 2.113358736038208
Validation loss: 2.119641201470488

Epoch: 6| Step: 12
Training loss: 1.9912481307983398
Validation loss: 2.109436742721065

Epoch: 6| Step: 13
Training loss: 2.419854164123535
Validation loss: 2.1126201204074326

Epoch: 346| Step: 0
Training loss: 1.8833191394805908
Validation loss: 2.0848190784454346

Epoch: 6| Step: 1
Training loss: 2.0440311431884766
Validation loss: 2.0840251035587762

Epoch: 6| Step: 2
Training loss: 1.7852119207382202
Validation loss: 2.0723638919091996

Epoch: 6| Step: 3
Training loss: 3.093334197998047
Validation loss: 2.0707704431267193

Epoch: 6| Step: 4
Training loss: 1.680577278137207
Validation loss: 2.100464423497518

Epoch: 6| Step: 5
Training loss: 1.9868144989013672
Validation loss: 2.0799000276032316

Epoch: 6| Step: 6
Training loss: 2.5024869441986084
Validation loss: 2.087752954934233

Epoch: 6| Step: 7
Training loss: 1.3962454795837402
Validation loss: 2.0659584729902205

Epoch: 6| Step: 8
Training loss: 1.3375439643859863
Validation loss: 2.072936309281216

Epoch: 6| Step: 9
Training loss: 1.494600772857666
Validation loss: 2.0725020747030936

Epoch: 6| Step: 10
Training loss: 2.3919694423675537
Validation loss: 2.0894174819351523

Epoch: 6| Step: 11
Training loss: 2.194075107574463
Validation loss: 2.1088353023734143

Epoch: 6| Step: 12
Training loss: 1.6653392314910889
Validation loss: 2.161327444097047

Epoch: 6| Step: 13
Training loss: 1.4458308219909668
Validation loss: 2.143723564763223

Epoch: 347| Step: 0
Training loss: 1.3931162357330322
Validation loss: 2.1102063732762493

Epoch: 6| Step: 1
Training loss: 2.0454676151275635
Validation loss: 2.0937026546847437

Epoch: 6| Step: 2
Training loss: 2.2054028511047363
Validation loss: 2.0880728037126604

Epoch: 6| Step: 3
Training loss: 1.8949625492095947
Validation loss: 2.0470254613507177

Epoch: 6| Step: 4
Training loss: 2.6463534832000732
Validation loss: 2.0620084321627052

Epoch: 6| Step: 5
Training loss: 2.3721861839294434
Validation loss: 2.021195770591818

Epoch: 6| Step: 6
Training loss: 1.4744336605072021
Validation loss: 2.02272016515014

Epoch: 6| Step: 7
Training loss: 1.6815129518508911
Validation loss: 2.018951310906359

Epoch: 6| Step: 8
Training loss: 1.753309726715088
Validation loss: 2.029609227693209

Epoch: 6| Step: 9
Training loss: 1.4824275970458984
Validation loss: 2.0382280054912774

Epoch: 6| Step: 10
Training loss: 1.988044261932373
Validation loss: 2.0393674040353424

Epoch: 6| Step: 11
Training loss: 2.312251567840576
Validation loss: 2.0555740940955376

Epoch: 6| Step: 12
Training loss: 2.089944362640381
Validation loss: 2.0589646306089175

Epoch: 6| Step: 13
Training loss: 1.6054965257644653
Validation loss: 2.090227655185166

Epoch: 348| Step: 0
Training loss: 2.043532371520996
Validation loss: 2.094666609200098

Epoch: 6| Step: 1
Training loss: 1.8963663578033447
Validation loss: 2.1448872089385986

Epoch: 6| Step: 2
Training loss: 1.8395709991455078
Validation loss: 2.12544096157115

Epoch: 6| Step: 3
Training loss: 2.8724923133850098
Validation loss: 2.1459481229064283

Epoch: 6| Step: 4
Training loss: 1.8561846017837524
Validation loss: 2.147819993316486

Epoch: 6| Step: 5
Training loss: 2.281270742416382
Validation loss: 2.1235221573101577

Epoch: 6| Step: 6
Training loss: 1.6339974403381348
Validation loss: 2.0707688357240412

Epoch: 6| Step: 7
Training loss: 1.4568655490875244
Validation loss: 2.06355885792804

Epoch: 6| Step: 8
Training loss: 2.0377683639526367
Validation loss: 2.0642049568955616

Epoch: 6| Step: 9
Training loss: 1.495187520980835
Validation loss: 2.039932289431172

Epoch: 6| Step: 10
Training loss: 1.2959884405136108
Validation loss: 2.030280920767015

Epoch: 6| Step: 11
Training loss: 2.2017312049865723
Validation loss: 2.049002018026126

Epoch: 6| Step: 12
Training loss: 1.8511525392532349
Validation loss: 2.0313368715265745

Epoch: 6| Step: 13
Training loss: 2.4587886333465576
Validation loss: 2.0359400831243044

Epoch: 349| Step: 0
Training loss: 1.4460893869400024
Validation loss: 2.031961173139593

Epoch: 6| Step: 1
Training loss: 2.203341007232666
Validation loss: 2.066942563620947

Epoch: 6| Step: 2
Training loss: 1.4532241821289062
Validation loss: 2.0483994740311817

Epoch: 6| Step: 3
Training loss: 1.90972101688385
Validation loss: 2.0557775728164183

Epoch: 6| Step: 4
Training loss: 2.070413112640381
Validation loss: 2.0686293673771683

Epoch: 6| Step: 5
Training loss: 1.932013750076294
Validation loss: 2.0882282154534453

Epoch: 6| Step: 6
Training loss: 1.7515052556991577
Validation loss: 2.1082824122521187

Epoch: 6| Step: 7
Training loss: 1.8506948947906494
Validation loss: 2.1374777388829056

Epoch: 6| Step: 8
Training loss: 1.5215058326721191
Validation loss: 2.11792339048078

Epoch: 6| Step: 9
Training loss: 2.3477635383605957
Validation loss: 2.125807624991222

Epoch: 6| Step: 10
Training loss: 1.9362993240356445
Validation loss: 2.125214094756752

Epoch: 6| Step: 11
Training loss: 1.8497254848480225
Validation loss: 2.114482125928325

Epoch: 6| Step: 12
Training loss: 2.677849054336548
Validation loss: 2.114928445508403

Epoch: 6| Step: 13
Training loss: 1.9366754293441772
Validation loss: 2.0833596670499412

Epoch: 350| Step: 0
Training loss: 1.606794834136963
Validation loss: 2.07632476540022

Epoch: 6| Step: 1
Training loss: 2.1673245429992676
Validation loss: 2.0642744802659556

Epoch: 6| Step: 2
Training loss: 2.501986503601074
Validation loss: 2.0476261415789203

Epoch: 6| Step: 3
Training loss: 1.4948152303695679
Validation loss: 2.0460907515659126

Epoch: 6| Step: 4
Training loss: 2.427794933319092
Validation loss: 2.0500588993872366

Epoch: 6| Step: 5
Training loss: 2.5904884338378906
Validation loss: 2.0448813540961153

Epoch: 6| Step: 6
Training loss: 1.9393404722213745
Validation loss: 2.0209198856866486

Epoch: 6| Step: 7
Training loss: 1.492882490158081
Validation loss: 2.03371343305034

Epoch: 6| Step: 8
Training loss: 2.039006471633911
Validation loss: 2.090913926401446

Epoch: 6| Step: 9
Training loss: 2.2315425872802734
Validation loss: 2.110994868381049

Epoch: 6| Step: 10
Training loss: 2.0044803619384766
Validation loss: 2.142650047938029

Epoch: 6| Step: 11
Training loss: 1.4659819602966309
Validation loss: 2.1428228360350414

Epoch: 6| Step: 12
Training loss: 1.5889965295791626
Validation loss: 2.161145758885209

Epoch: 6| Step: 13
Training loss: 1.017946720123291
Validation loss: 2.156671359974851

Epoch: 351| Step: 0
Training loss: 1.5314691066741943
Validation loss: 2.161999705017254

Epoch: 6| Step: 1
Training loss: 1.7773559093475342
Validation loss: 2.1544595867074947

Epoch: 6| Step: 2
Training loss: 1.935530185699463
Validation loss: 2.143694785333449

Epoch: 6| Step: 3
Training loss: 2.295588970184326
Validation loss: 2.110928735425395

Epoch: 6| Step: 4
Training loss: 2.1851389408111572
Validation loss: 2.0727964960118777

Epoch: 6| Step: 5
Training loss: 2.00942325592041
Validation loss: 2.0466557189982426

Epoch: 6| Step: 6
Training loss: 1.7496637105941772
Validation loss: 2.0220662855332896

Epoch: 6| Step: 7
Training loss: 1.9209728240966797
Validation loss: 2.0114669799804688

Epoch: 6| Step: 8
Training loss: 2.3130245208740234
Validation loss: 2.01869265110262

Epoch: 6| Step: 9
Training loss: 1.7405227422714233
Validation loss: 2.023660889235876

Epoch: 6| Step: 10
Training loss: 2.079202890396118
Validation loss: 2.0314009484424385

Epoch: 6| Step: 11
Training loss: 1.4913601875305176
Validation loss: 2.038355549176534

Epoch: 6| Step: 12
Training loss: 1.5574756860733032
Validation loss: 2.0480476874177174

Epoch: 6| Step: 13
Training loss: 2.5669162273406982
Validation loss: 2.0643357640953472

Epoch: 352| Step: 0
Training loss: 1.6521644592285156
Validation loss: 2.0767861566235943

Epoch: 6| Step: 1
Training loss: 1.9444169998168945
Validation loss: 2.0920000025021133

Epoch: 6| Step: 2
Training loss: 1.7786619663238525
Validation loss: 2.1338926297362133

Epoch: 6| Step: 3
Training loss: 2.1962642669677734
Validation loss: 2.1602041657252977

Epoch: 6| Step: 4
Training loss: 1.9539402723312378
Validation loss: 2.150540769741099

Epoch: 6| Step: 5
Training loss: 1.651167392730713
Validation loss: 2.1440449953079224

Epoch: 6| Step: 6
Training loss: 1.6218503713607788
Validation loss: 2.164421723734948

Epoch: 6| Step: 7
Training loss: 1.659307837486267
Validation loss: 2.1439191487527665

Epoch: 6| Step: 8
Training loss: 1.8972283601760864
Validation loss: 2.147686089238813

Epoch: 6| Step: 9
Training loss: 2.274014472961426
Validation loss: 2.135707416842061

Epoch: 6| Step: 10
Training loss: 1.7087373733520508
Validation loss: 2.1212477325111307

Epoch: 6| Step: 11
Training loss: 1.871260643005371
Validation loss: 2.107328745626634

Epoch: 6| Step: 12
Training loss: 2.6313910484313965
Validation loss: 2.0771411208696264

Epoch: 6| Step: 13
Training loss: 1.9926049709320068
Validation loss: 2.0592404975686023

Epoch: 353| Step: 0
Training loss: 1.779815435409546
Validation loss: 2.0443852639967397

Epoch: 6| Step: 1
Training loss: 2.274749279022217
Validation loss: 2.042430231648107

Epoch: 6| Step: 2
Training loss: 1.7286062240600586
Validation loss: 2.0282842536126413

Epoch: 6| Step: 3
Training loss: 1.6937167644500732
Validation loss: 2.023523276852023

Epoch: 6| Step: 4
Training loss: 1.8960058689117432
Validation loss: 2.0327108316524054

Epoch: 6| Step: 5
Training loss: 1.99649178981781
Validation loss: 2.0329731459258706

Epoch: 6| Step: 6
Training loss: 1.4333089590072632
Validation loss: 2.047020650679065

Epoch: 6| Step: 7
Training loss: 2.01254940032959
Validation loss: 2.05708324011936

Epoch: 6| Step: 8
Training loss: 2.0812954902648926
Validation loss: 2.1055098759230746

Epoch: 6| Step: 9
Training loss: 2.019637107849121
Validation loss: 2.1184568558969805

Epoch: 6| Step: 10
Training loss: 2.3099889755249023
Validation loss: 2.099436883003481

Epoch: 6| Step: 11
Training loss: 1.8313956260681152
Validation loss: 2.128001739901881

Epoch: 6| Step: 12
Training loss: 1.438817024230957
Validation loss: 2.1055632496392853

Epoch: 6| Step: 13
Training loss: 2.4049811363220215
Validation loss: 2.0927945106260237

Epoch: 354| Step: 0
Training loss: 1.7841918468475342
Validation loss: 2.0824833762261177

Epoch: 6| Step: 1
Training loss: 2.582693099975586
Validation loss: 2.037889390863398

Epoch: 6| Step: 2
Training loss: 2.024134874343872
Validation loss: 2.0331221767651138

Epoch: 6| Step: 3
Training loss: 2.396981954574585
Validation loss: 2.032962824708672

Epoch: 6| Step: 4
Training loss: 1.145419716835022
Validation loss: 2.0372673631996236

Epoch: 6| Step: 5
Training loss: 1.248936414718628
Validation loss: 2.027794207296064

Epoch: 6| Step: 6
Training loss: 2.1821227073669434
Validation loss: 2.040169987627255

Epoch: 6| Step: 7
Training loss: 2.5144574642181396
Validation loss: 2.0237983760013374

Epoch: 6| Step: 8
Training loss: 1.662756323814392
Validation loss: 1.9996107855150778

Epoch: 6| Step: 9
Training loss: 1.2424097061157227
Validation loss: 1.999075360195611

Epoch: 6| Step: 10
Training loss: 2.422121286392212
Validation loss: 2.026378828992126

Epoch: 6| Step: 11
Training loss: 1.592407464981079
Validation loss: 2.0215721335462344

Epoch: 6| Step: 12
Training loss: 2.1881351470947266
Validation loss: 2.034865753625029

Epoch: 6| Step: 13
Training loss: 1.5587866306304932
Validation loss: 2.0617444412682646

Epoch: 355| Step: 0
Training loss: 1.9073845148086548
Validation loss: 2.1354520756711244

Epoch: 6| Step: 1
Training loss: 1.5797784328460693
Validation loss: 2.168983751727689

Epoch: 6| Step: 2
Training loss: 1.9308950901031494
Validation loss: 2.206140446406539

Epoch: 6| Step: 3
Training loss: 2.0202841758728027
Validation loss: 2.2006658251567552

Epoch: 6| Step: 4
Training loss: 1.8648130893707275
Validation loss: 2.1512224904952513

Epoch: 6| Step: 5
Training loss: 1.8539384603500366
Validation loss: 2.155266026014923

Epoch: 6| Step: 6
Training loss: 2.1762685775756836
Validation loss: 2.109663268571259

Epoch: 6| Step: 7
Training loss: 1.9871476888656616
Validation loss: 2.082227494127007

Epoch: 6| Step: 8
Training loss: 1.6235179901123047
Validation loss: 2.0443937317017586

Epoch: 6| Step: 9
Training loss: 1.6781939268112183
Validation loss: 2.0153030862090406

Epoch: 6| Step: 10
Training loss: 1.6261937618255615
Validation loss: 2.0125488786287207

Epoch: 6| Step: 11
Training loss: 2.571791887283325
Validation loss: 1.9826346840909732

Epoch: 6| Step: 12
Training loss: 1.9892069101333618
Validation loss: 1.968531411181214

Epoch: 6| Step: 13
Training loss: 2.489394426345825
Validation loss: 1.9875651046793947

Epoch: 356| Step: 0
Training loss: 1.786026954650879
Validation loss: 1.9881499954449233

Epoch: 6| Step: 1
Training loss: 2.205996513366699
Validation loss: 1.9858619884778095

Epoch: 6| Step: 2
Training loss: 1.6077709197998047
Validation loss: 1.9872658303988877

Epoch: 6| Step: 3
Training loss: 2.440272808074951
Validation loss: 1.9976719899844098

Epoch: 6| Step: 4
Training loss: 1.8197554349899292
Validation loss: 1.9943895480966056

Epoch: 6| Step: 5
Training loss: 1.5498008728027344
Validation loss: 2.0172467744478615

Epoch: 6| Step: 6
Training loss: 2.221989393234253
Validation loss: 2.0565385292935114

Epoch: 6| Step: 7
Training loss: 2.236424207687378
Validation loss: 2.08459912320619

Epoch: 6| Step: 8
Training loss: 1.8545899391174316
Validation loss: 2.1304046671877623

Epoch: 6| Step: 9
Training loss: 1.3099578619003296
Validation loss: 2.144984382455067

Epoch: 6| Step: 10
Training loss: 1.8847278356552124
Validation loss: 2.1670912901560464

Epoch: 6| Step: 11
Training loss: 1.6898525953292847
Validation loss: 2.1677593441419702

Epoch: 6| Step: 12
Training loss: 2.5376691818237305
Validation loss: 2.201181404052242

Epoch: 6| Step: 13
Training loss: 1.8635889291763306
Validation loss: 2.148954955480432

Epoch: 357| Step: 0
Training loss: 2.078925609588623
Validation loss: 2.1414130862041185

Epoch: 6| Step: 1
Training loss: 2.366697311401367
Validation loss: 2.100383174034857

Epoch: 6| Step: 2
Training loss: 2.2944135665893555
Validation loss: 2.067543947568504

Epoch: 6| Step: 3
Training loss: 1.8898861408233643
Validation loss: 2.0840233731013473

Epoch: 6| Step: 4
Training loss: 1.8537063598632812
Validation loss: 2.043514318363641

Epoch: 6| Step: 5
Training loss: 1.771615982055664
Validation loss: 2.043974030402399

Epoch: 6| Step: 6
Training loss: 1.7463330030441284
Validation loss: 2.039419653595135

Epoch: 6| Step: 7
Training loss: 1.6269853115081787
Validation loss: 2.050764085144125

Epoch: 6| Step: 8
Training loss: 2.4330689907073975
Validation loss: 2.074236951848512

Epoch: 6| Step: 9
Training loss: 1.6913142204284668
Validation loss: 2.0799417764909807

Epoch: 6| Step: 10
Training loss: 1.5772838592529297
Validation loss: 2.0986865464077202

Epoch: 6| Step: 11
Training loss: 1.8361599445343018
Validation loss: 2.1057594655662455

Epoch: 6| Step: 12
Training loss: 2.059993028640747
Validation loss: 2.0818344751993814

Epoch: 6| Step: 13
Training loss: 0.8961544036865234
Validation loss: 2.1038199355525355

Epoch: 358| Step: 0
Training loss: 2.4367494583129883
Validation loss: 2.120457790231192

Epoch: 6| Step: 1
Training loss: 1.7841087579727173
Validation loss: 2.0812642420491865

Epoch: 6| Step: 2
Training loss: 2.4272875785827637
Validation loss: 2.090345755700142

Epoch: 6| Step: 3
Training loss: 2.369324207305908
Validation loss: 2.0791017137547976

Epoch: 6| Step: 4
Training loss: 1.8513472080230713
Validation loss: 2.085506753254962

Epoch: 6| Step: 5
Training loss: 1.5031371116638184
Validation loss: 2.0836447695250153

Epoch: 6| Step: 6
Training loss: 1.735799789428711
Validation loss: 2.1256427021436792

Epoch: 6| Step: 7
Training loss: 1.4009978771209717
Validation loss: 2.1283738279855378

Epoch: 6| Step: 8
Training loss: 1.82570219039917
Validation loss: 2.1310249502940843

Epoch: 6| Step: 9
Training loss: 1.1470447778701782
Validation loss: 2.108400349975914

Epoch: 6| Step: 10
Training loss: 1.9295685291290283
Validation loss: 2.1233152958654586

Epoch: 6| Step: 11
Training loss: 1.512223243713379
Validation loss: 2.097030549921015

Epoch: 6| Step: 12
Training loss: 1.8056848049163818
Validation loss: 2.101603541322934

Epoch: 6| Step: 13
Training loss: 3.33085560798645
Validation loss: 2.08870130713268

Epoch: 359| Step: 0
Training loss: 2.253495931625366
Validation loss: 2.0869560985155005

Epoch: 6| Step: 1
Training loss: 1.9401111602783203
Validation loss: 2.08202209267565

Epoch: 6| Step: 2
Training loss: 2.504044532775879
Validation loss: 2.085578090401106

Epoch: 6| Step: 3
Training loss: 1.0954021215438843
Validation loss: 2.0841884356673046

Epoch: 6| Step: 4
Training loss: 1.8257384300231934
Validation loss: 2.095570723215739

Epoch: 6| Step: 5
Training loss: 2.108391761779785
Validation loss: 2.095150870661582

Epoch: 6| Step: 6
Training loss: 1.6707031726837158
Validation loss: 2.0933291976169874

Epoch: 6| Step: 7
Training loss: 1.8730220794677734
Validation loss: 2.0788249174753823

Epoch: 6| Step: 8
Training loss: 1.603103518486023
Validation loss: 2.092096826081635

Epoch: 6| Step: 9
Training loss: 1.6563901901245117
Validation loss: 2.0817305426443777

Epoch: 6| Step: 10
Training loss: 2.078742504119873
Validation loss: 2.101121743520101

Epoch: 6| Step: 11
Training loss: 2.089526653289795
Validation loss: 2.071230544838854

Epoch: 6| Step: 12
Training loss: 1.9719197750091553
Validation loss: 2.0793649919571413

Epoch: 6| Step: 13
Training loss: 1.952585220336914
Validation loss: 2.0867918409327024

Epoch: 360| Step: 0
Training loss: 1.7053427696228027
Validation loss: 2.086725610558705

Epoch: 6| Step: 1
Training loss: 2.1167798042297363
Validation loss: 2.073125752069617

Epoch: 6| Step: 2
Training loss: 2.4131219387054443
Validation loss: 2.0652212788981776

Epoch: 6| Step: 3
Training loss: 1.775617003440857
Validation loss: 2.0710905533964916

Epoch: 6| Step: 4
Training loss: 1.9138374328613281
Validation loss: 2.0982950925827026

Epoch: 6| Step: 5
Training loss: 1.1429152488708496
Validation loss: 2.0979820861611316

Epoch: 6| Step: 6
Training loss: 1.8724820613861084
Validation loss: 2.099402209763886

Epoch: 6| Step: 7
Training loss: 2.3795394897460938
Validation loss: 2.102852613695206

Epoch: 6| Step: 8
Training loss: 1.7927711009979248
Validation loss: 2.098901000074161

Epoch: 6| Step: 9
Training loss: 2.219438314437866
Validation loss: 2.0893810577290033

Epoch: 6| Step: 10
Training loss: 2.323500871658325
Validation loss: 2.0539846856106996

Epoch: 6| Step: 11
Training loss: 1.247387409210205
Validation loss: 2.0530224077163206

Epoch: 6| Step: 12
Training loss: 1.3311880826950073
Validation loss: 2.067402316677955

Epoch: 6| Step: 13
Training loss: 2.430255889892578
Validation loss: 2.057782555139193

Epoch: 361| Step: 0
Training loss: 2.226223945617676
Validation loss: 2.0280647265013827

Epoch: 6| Step: 1
Training loss: 2.378960609436035
Validation loss: 2.0111944213990243

Epoch: 6| Step: 2
Training loss: 1.1922801733016968
Validation loss: 2.003795692997594

Epoch: 6| Step: 3
Training loss: 1.947515845298767
Validation loss: 2.012298114838139

Epoch: 6| Step: 4
Training loss: 1.9344539642333984
Validation loss: 2.0098174720682125

Epoch: 6| Step: 5
Training loss: 2.0443320274353027
Validation loss: 2.0422490873644428

Epoch: 6| Step: 6
Training loss: 1.5611834526062012
Validation loss: 2.0456259519823137

Epoch: 6| Step: 7
Training loss: 1.7778289318084717
Validation loss: 2.0571507766682613

Epoch: 6| Step: 8
Training loss: 1.6117604970932007
Validation loss: 2.067518928999542

Epoch: 6| Step: 9
Training loss: 2.6023449897766113
Validation loss: 2.0826483336828088

Epoch: 6| Step: 10
Training loss: 2.436371326446533
Validation loss: 2.122240399801603

Epoch: 6| Step: 11
Training loss: 1.698530673980713
Validation loss: 2.114420562662104

Epoch: 6| Step: 12
Training loss: 1.2609819173812866
Validation loss: 2.1168482226710164

Epoch: 6| Step: 13
Training loss: 1.179644227027893
Validation loss: 2.0944436032284974

Epoch: 362| Step: 0
Training loss: 1.5210015773773193
Validation loss: 2.1005863963916735

Epoch: 6| Step: 1
Training loss: 1.72739577293396
Validation loss: 2.092945703896143

Epoch: 6| Step: 2
Training loss: 2.409213066101074
Validation loss: 2.060920056476388

Epoch: 6| Step: 3
Training loss: 1.627028465270996
Validation loss: 2.0593519595361527

Epoch: 6| Step: 4
Training loss: 1.814147710800171
Validation loss: 2.0539517377012517

Epoch: 6| Step: 5
Training loss: 1.9314595460891724
Validation loss: 2.0629013071778

Epoch: 6| Step: 6
Training loss: 1.783024787902832
Validation loss: 2.0547316228189776

Epoch: 6| Step: 7
Training loss: 2.6265029907226562
Validation loss: 2.0462989525128434

Epoch: 6| Step: 8
Training loss: 2.1872360706329346
Validation loss: 2.0476966288781937

Epoch: 6| Step: 9
Training loss: 1.9041118621826172
Validation loss: 2.0609215485152377

Epoch: 6| Step: 10
Training loss: 2.2507712841033936
Validation loss: 2.058498800441783

Epoch: 6| Step: 11
Training loss: 1.3840141296386719
Validation loss: 2.0536414730933403

Epoch: 6| Step: 12
Training loss: 1.5944010019302368
Validation loss: 2.0632671822783766

Epoch: 6| Step: 13
Training loss: 1.1667180061340332
Validation loss: 2.0660779963257494

Epoch: 363| Step: 0
Training loss: 2.206475019454956
Validation loss: 2.0579296670934206

Epoch: 6| Step: 1
Training loss: 1.272996425628662
Validation loss: 2.0615873746974493

Epoch: 6| Step: 2
Training loss: 1.7361868619918823
Validation loss: 2.0848061782057568

Epoch: 6| Step: 3
Training loss: 1.876142144203186
Validation loss: 2.1048409618357176

Epoch: 6| Step: 4
Training loss: 2.0153989791870117
Validation loss: 2.112246569766793

Epoch: 6| Step: 5
Training loss: 1.982336401939392
Validation loss: 2.1278891101960213

Epoch: 6| Step: 6
Training loss: 2.08390474319458
Validation loss: 2.115817641699186

Epoch: 6| Step: 7
Training loss: 1.9374735355377197
Validation loss: 2.1159348846763693

Epoch: 6| Step: 8
Training loss: 1.4199254512786865
Validation loss: 2.09645620084578

Epoch: 6| Step: 9
Training loss: 1.7918281555175781
Validation loss: 2.0659086012071177

Epoch: 6| Step: 10
Training loss: 2.029996395111084
Validation loss: 2.0536905104114163

Epoch: 6| Step: 11
Training loss: 1.526672124862671
Validation loss: 2.0733055401873846

Epoch: 6| Step: 12
Training loss: 1.7373836040496826
Validation loss: 2.0573428010427826

Epoch: 6| Step: 13
Training loss: 2.530778169631958
Validation loss: 2.0657729884629608

Epoch: 364| Step: 0
Training loss: 1.5224995613098145
Validation loss: 2.0435293592432493

Epoch: 6| Step: 1
Training loss: 1.9922734498977661
Validation loss: 2.048984371205812

Epoch: 6| Step: 2
Training loss: 1.910758137702942
Validation loss: 2.0524257998312674

Epoch: 6| Step: 3
Training loss: 1.715846061706543
Validation loss: 2.068551383992677

Epoch: 6| Step: 4
Training loss: 1.4711380004882812
Validation loss: 2.053609707022226

Epoch: 6| Step: 5
Training loss: 2.2954823970794678
Validation loss: 2.0510229961846465

Epoch: 6| Step: 6
Training loss: 1.7349162101745605
Validation loss: 2.0779974332419773

Epoch: 6| Step: 7
Training loss: 2.0245251655578613
Validation loss: 2.0564822996816328

Epoch: 6| Step: 8
Training loss: 2.073833465576172
Validation loss: 2.043099562327067

Epoch: 6| Step: 9
Training loss: 1.566711664199829
Validation loss: 2.033469425734653

Epoch: 6| Step: 10
Training loss: 2.1883277893066406
Validation loss: 2.031880556896169

Epoch: 6| Step: 11
Training loss: 1.5401959419250488
Validation loss: 2.041878249055596

Epoch: 6| Step: 12
Training loss: 2.1591625213623047
Validation loss: 2.051649264110032

Epoch: 6| Step: 13
Training loss: 1.8753803968429565
Validation loss: 2.073154901945463

Epoch: 365| Step: 0
Training loss: 2.4476804733276367
Validation loss: 2.0779323770153906

Epoch: 6| Step: 1
Training loss: 1.9565130472183228
Validation loss: 2.0913241883759857

Epoch: 6| Step: 2
Training loss: 1.404581904411316
Validation loss: 2.1032223483567596

Epoch: 6| Step: 3
Training loss: 1.784337043762207
Validation loss: 2.1326014662301667

Epoch: 6| Step: 4
Training loss: 2.001004695892334
Validation loss: 2.1234426062594176

Epoch: 6| Step: 5
Training loss: 2.0128402709960938
Validation loss: 2.1492199897766113

Epoch: 6| Step: 6
Training loss: 1.9528504610061646
Validation loss: 2.1299429119274182

Epoch: 6| Step: 7
Training loss: 2.329862594604492
Validation loss: 2.0982127869001

Epoch: 6| Step: 8
Training loss: 1.881309986114502
Validation loss: 2.0687565008799234

Epoch: 6| Step: 9
Training loss: 1.7086243629455566
Validation loss: 2.03217980938573

Epoch: 6| Step: 10
Training loss: 2.1589677333831787
Validation loss: 2.0219112647477018

Epoch: 6| Step: 11
Training loss: 1.6594548225402832
Validation loss: 2.0286681229068386

Epoch: 6| Step: 12
Training loss: 1.165286660194397
Validation loss: 2.0018568910578245

Epoch: 6| Step: 13
Training loss: 1.350220799446106
Validation loss: 1.9967740158880911

Epoch: 366| Step: 0
Training loss: 1.9574211835861206
Validation loss: 1.9939221476995816

Epoch: 6| Step: 1
Training loss: 1.9354329109191895
Validation loss: 2.0044543691860732

Epoch: 6| Step: 2
Training loss: 2.2458369731903076
Validation loss: 1.9983430421480568

Epoch: 6| Step: 3
Training loss: 1.9199963808059692
Validation loss: 1.9921759046534055

Epoch: 6| Step: 4
Training loss: 1.7045650482177734
Validation loss: 1.9997336377379715

Epoch: 6| Step: 5
Training loss: 1.7253258228302002
Validation loss: 2.023982919672484

Epoch: 6| Step: 6
Training loss: 2.337594985961914
Validation loss: 2.0145548466713197

Epoch: 6| Step: 7
Training loss: 1.850569248199463
Validation loss: 2.0171257885553504

Epoch: 6| Step: 8
Training loss: 1.2618197202682495
Validation loss: 2.0420831736697944

Epoch: 6| Step: 9
Training loss: 1.9996479749679565
Validation loss: 2.0752777309827906

Epoch: 6| Step: 10
Training loss: 1.4715744256973267
Validation loss: 2.070267214569994

Epoch: 6| Step: 11
Training loss: 1.528707504272461
Validation loss: 2.106108534720636

Epoch: 6| Step: 12
Training loss: 1.8245038986206055
Validation loss: 2.1061838467915854

Epoch: 6| Step: 13
Training loss: 2.6020936965942383
Validation loss: 2.113267639631866

Epoch: 367| Step: 0
Training loss: 1.9283945560455322
Validation loss: 2.126281476789905

Epoch: 6| Step: 1
Training loss: 1.2675738334655762
Validation loss: 2.15801602537914

Epoch: 6| Step: 2
Training loss: 1.5342943668365479
Validation loss: 2.1522413402475338

Epoch: 6| Step: 3
Training loss: 1.788804531097412
Validation loss: 2.1549416037016016

Epoch: 6| Step: 4
Training loss: 1.6873111724853516
Validation loss: 2.1260571825888848

Epoch: 6| Step: 5
Training loss: 1.665094017982483
Validation loss: 2.076366373287734

Epoch: 6| Step: 6
Training loss: 2.120255470275879
Validation loss: 2.083031077538767

Epoch: 6| Step: 7
Training loss: 2.2985904216766357
Validation loss: 2.0689156209268877

Epoch: 6| Step: 8
Training loss: 2.1530447006225586
Validation loss: 2.06638240814209

Epoch: 6| Step: 9
Training loss: 1.9479161500930786
Validation loss: 2.062826442462142

Epoch: 6| Step: 10
Training loss: 1.7540619373321533
Validation loss: 2.054082506446428

Epoch: 6| Step: 11
Training loss: 1.3178935050964355
Validation loss: 2.0758660916359193

Epoch: 6| Step: 12
Training loss: 2.5421714782714844
Validation loss: 2.076277894358481

Epoch: 6| Step: 13
Training loss: 2.146702527999878
Validation loss: 2.0576889963560205

Epoch: 368| Step: 0
Training loss: 1.6426708698272705
Validation loss: 2.068462780726853

Epoch: 6| Step: 1
Training loss: 1.5360928773880005
Validation loss: 2.0877096306893135

Epoch: 6| Step: 2
Training loss: 1.5388541221618652
Validation loss: 2.0945403088805494

Epoch: 6| Step: 3
Training loss: 2.424968719482422
Validation loss: 2.09946515739605

Epoch: 6| Step: 4
Training loss: 2.8703360557556152
Validation loss: 2.0901524610416864

Epoch: 6| Step: 5
Training loss: 1.1942782402038574
Validation loss: 2.0890250616176154

Epoch: 6| Step: 6
Training loss: 1.6083266735076904
Validation loss: 2.070176778301116

Epoch: 6| Step: 7
Training loss: 2.06387996673584
Validation loss: 2.0657158026131253

Epoch: 6| Step: 8
Training loss: 2.0586934089660645
Validation loss: 2.0437122339843423

Epoch: 6| Step: 9
Training loss: 1.5737411975860596
Validation loss: 2.0320039615836194

Epoch: 6| Step: 10
Training loss: 1.4330558776855469
Validation loss: 2.0207613591224916

Epoch: 6| Step: 11
Training loss: 1.947395920753479
Validation loss: 2.0216317356273694

Epoch: 6| Step: 12
Training loss: 1.7186790704727173
Validation loss: 2.019668604737969

Epoch: 6| Step: 13
Training loss: 2.860274314880371
Validation loss: 1.978589791123585

Epoch: 369| Step: 0
Training loss: 1.568819284439087
Validation loss: 2.001378127323684

Epoch: 6| Step: 1
Training loss: 1.2388224601745605
Validation loss: 1.9956569453721404

Epoch: 6| Step: 2
Training loss: 2.3728811740875244
Validation loss: 1.9932724916806785

Epoch: 6| Step: 3
Training loss: 2.2257559299468994
Validation loss: 1.9974469702730897

Epoch: 6| Step: 4
Training loss: 2.2873120307922363
Validation loss: 2.0013873474572295

Epoch: 6| Step: 5
Training loss: 2.3008079528808594
Validation loss: 2.0441786653252056

Epoch: 6| Step: 6
Training loss: 1.3620998859405518
Validation loss: 2.060148080190023

Epoch: 6| Step: 7
Training loss: 1.0324337482452393
Validation loss: 2.1089326643174693

Epoch: 6| Step: 8
Training loss: 1.2517671585083008
Validation loss: 2.097431864789737

Epoch: 6| Step: 9
Training loss: 2.135145902633667
Validation loss: 2.120350109633579

Epoch: 6| Step: 10
Training loss: 1.7964627742767334
Validation loss: 2.127808996426162

Epoch: 6| Step: 11
Training loss: 2.0498554706573486
Validation loss: 2.144721484953357

Epoch: 6| Step: 12
Training loss: 2.329857110977173
Validation loss: 2.12080555833796

Epoch: 6| Step: 13
Training loss: 2.1872692108154297
Validation loss: 2.071501007644079

Epoch: 370| Step: 0
Training loss: 2.1190290451049805
Validation loss: 2.0424135320930072

Epoch: 6| Step: 1
Training loss: 1.6595499515533447
Validation loss: 1.9983846474719305

Epoch: 6| Step: 2
Training loss: 1.718029260635376
Validation loss: 1.9939023628029773

Epoch: 6| Step: 3
Training loss: 2.6115784645080566
Validation loss: 1.9887373985782746

Epoch: 6| Step: 4
Training loss: 1.795966625213623
Validation loss: 1.988377135287049

Epoch: 6| Step: 5
Training loss: 1.4079272747039795
Validation loss: 2.0075128770643667

Epoch: 6| Step: 6
Training loss: 1.7592090368270874
Validation loss: 1.999764362970988

Epoch: 6| Step: 7
Training loss: 1.5977126359939575
Validation loss: 2.010300858046419

Epoch: 6| Step: 8
Training loss: 2.085707902908325
Validation loss: 2.056759980417067

Epoch: 6| Step: 9
Training loss: 1.6273717880249023
Validation loss: 2.0451945258725073

Epoch: 6| Step: 10
Training loss: 2.00368595123291
Validation loss: 2.0783981559097127

Epoch: 6| Step: 11
Training loss: 1.913797378540039
Validation loss: 2.107215917238625

Epoch: 6| Step: 12
Training loss: 2.108053207397461
Validation loss: 2.1096713440392607

Epoch: 6| Step: 13
Training loss: 1.2909678220748901
Validation loss: 2.128701171567363

Epoch: 371| Step: 0
Training loss: 1.7095108032226562
Validation loss: 2.114085038503011

Epoch: 6| Step: 1
Training loss: 2.0190463066101074
Validation loss: 2.1420381261456396

Epoch: 6| Step: 2
Training loss: 2.1741559505462646
Validation loss: 2.1301004604626725

Epoch: 6| Step: 3
Training loss: 1.2318222522735596
Validation loss: 2.1295572096301663

Epoch: 6| Step: 4
Training loss: 1.9825892448425293
Validation loss: 2.094412419103807

Epoch: 6| Step: 5
Training loss: 2.3500070571899414
Validation loss: 2.039292363710301

Epoch: 6| Step: 6
Training loss: 1.214464545249939
Validation loss: 2.012716649681009

Epoch: 6| Step: 7
Training loss: 1.402956247329712
Validation loss: 2.0090408761014222

Epoch: 6| Step: 8
Training loss: 2.387336015701294
Validation loss: 1.9962671302979993

Epoch: 6| Step: 9
Training loss: 1.9321757555007935
Validation loss: 1.983749242239101

Epoch: 6| Step: 10
Training loss: 1.9659602642059326
Validation loss: 1.981031020482381

Epoch: 6| Step: 11
Training loss: 2.0049448013305664
Validation loss: 1.983175604574142

Epoch: 6| Step: 12
Training loss: 1.7134215831756592
Validation loss: 1.975965533205258

Epoch: 6| Step: 13
Training loss: 1.8623987436294556
Validation loss: 2.0139891383468465

Epoch: 372| Step: 0
Training loss: 1.3482751846313477
Validation loss: 2.0710536613259265

Epoch: 6| Step: 1
Training loss: 2.019303798675537
Validation loss: 2.095679789461115

Epoch: 6| Step: 2
Training loss: 1.843970775604248
Validation loss: 2.1122496422900947

Epoch: 6| Step: 3
Training loss: 2.282895088195801
Validation loss: 2.1486562682736303

Epoch: 6| Step: 4
Training loss: 2.0832126140594482
Validation loss: 2.1461096784119964

Epoch: 6| Step: 5
Training loss: 1.8512301445007324
Validation loss: 2.144347817667069

Epoch: 6| Step: 6
Training loss: 1.7337144613265991
Validation loss: 2.1263630749076925

Epoch: 6| Step: 7
Training loss: 1.5405817031860352
Validation loss: 2.0939540042672107

Epoch: 6| Step: 8
Training loss: 1.465081810951233
Validation loss: 2.0987025230161604

Epoch: 6| Step: 9
Training loss: 1.1597446203231812
Validation loss: 2.0891935492074616

Epoch: 6| Step: 10
Training loss: 2.202624797821045
Validation loss: 2.092690162761237

Epoch: 6| Step: 11
Training loss: 1.3954792022705078
Validation loss: 2.0616195150600967

Epoch: 6| Step: 12
Training loss: 2.7278618812561035
Validation loss: 2.043087581152557

Epoch: 6| Step: 13
Training loss: 2.3745477199554443
Validation loss: 2.012864443563646

Epoch: 373| Step: 0
Training loss: 1.6608450412750244
Validation loss: 1.989184041177073

Epoch: 6| Step: 1
Training loss: 2.047844409942627
Validation loss: 2.0101684959985877

Epoch: 6| Step: 2
Training loss: 2.6077141761779785
Validation loss: 2.0127370152422177

Epoch: 6| Step: 3
Training loss: 1.3297984600067139
Validation loss: 2.0030874129264586

Epoch: 6| Step: 4
Training loss: 1.5508655309677124
Validation loss: 1.9915087043598134

Epoch: 6| Step: 5
Training loss: 2.1824283599853516
Validation loss: 2.013098309116979

Epoch: 6| Step: 6
Training loss: 1.6367254257202148
Validation loss: 2.032381824267808

Epoch: 6| Step: 7
Training loss: 2.015571117401123
Validation loss: 2.0555858650515155

Epoch: 6| Step: 8
Training loss: 1.55112886428833
Validation loss: 2.0830318248400124

Epoch: 6| Step: 9
Training loss: 2.337946891784668
Validation loss: 2.0962846996963664

Epoch: 6| Step: 10
Training loss: 1.229954719543457
Validation loss: 2.113425383003809

Epoch: 6| Step: 11
Training loss: 1.9795050621032715
Validation loss: 2.1356717796735865

Epoch: 6| Step: 12
Training loss: 1.645447015762329
Validation loss: 2.1387974626274517

Epoch: 6| Step: 13
Training loss: 2.0587451457977295
Validation loss: 2.1113715325632403

Epoch: 374| Step: 0
Training loss: 1.507000207901001
Validation loss: 2.090661064271004

Epoch: 6| Step: 1
Training loss: 1.9801430702209473
Validation loss: 2.0733514319184008

Epoch: 6| Step: 2
Training loss: 1.8975363969802856
Validation loss: 2.065686595055365

Epoch: 6| Step: 3
Training loss: 1.866747260093689
Validation loss: 2.0468148672452537

Epoch: 6| Step: 4
Training loss: 2.365218162536621
Validation loss: 2.0368573742528118

Epoch: 6| Step: 5
Training loss: 2.006141185760498
Validation loss: 2.0102653041962655

Epoch: 6| Step: 6
Training loss: 2.0548927783966064
Validation loss: 2.008940976153138

Epoch: 6| Step: 7
Training loss: 1.4538137912750244
Validation loss: 2.029701635401736

Epoch: 6| Step: 8
Training loss: 2.056323528289795
Validation loss: 2.0172283457171534

Epoch: 6| Step: 9
Training loss: 2.445242404937744
Validation loss: 2.042181712324901

Epoch: 6| Step: 10
Training loss: 1.925887942314148
Validation loss: 2.061856524918669

Epoch: 6| Step: 11
Training loss: 0.8542972207069397
Validation loss: 2.0591162379069994

Epoch: 6| Step: 12
Training loss: 0.9099763631820679
Validation loss: 2.06030079882632

Epoch: 6| Step: 13
Training loss: 2.2882657051086426
Validation loss: 2.0778535232749036

Epoch: 375| Step: 0
Training loss: 1.3925946950912476
Validation loss: 2.073999424134531

Epoch: 6| Step: 1
Training loss: 2.0371553897857666
Validation loss: 2.059332092603048

Epoch: 6| Step: 2
Training loss: 1.6576164960861206
Validation loss: 2.051322688338577

Epoch: 6| Step: 3
Training loss: 1.5663729906082153
Validation loss: 2.050255125568759

Epoch: 6| Step: 4
Training loss: 1.0324362516403198
Validation loss: 2.04650721498715

Epoch: 6| Step: 5
Training loss: 2.719989776611328
Validation loss: 2.0286234617233276

Epoch: 6| Step: 6
Training loss: 1.8966156244277954
Validation loss: 2.0405987219143937

Epoch: 6| Step: 7
Training loss: 1.2551785707473755
Validation loss: 2.049126536615433

Epoch: 6| Step: 8
Training loss: 2.393995761871338
Validation loss: 2.0556491395478607

Epoch: 6| Step: 9
Training loss: 1.7023406028747559
Validation loss: 2.018872521256888

Epoch: 6| Step: 10
Training loss: 2.0915205478668213
Validation loss: 2.033063288657896

Epoch: 6| Step: 11
Training loss: 2.2058932781219482
Validation loss: 2.0374673438328568

Epoch: 6| Step: 12
Training loss: 1.3526315689086914
Validation loss: 2.031847902523574

Epoch: 6| Step: 13
Training loss: 2.3348424434661865
Validation loss: 2.029190586459252

Epoch: 376| Step: 0
Training loss: 1.5901925563812256
Validation loss: 2.0419806511171403

Epoch: 6| Step: 1
Training loss: 1.671112060546875
Validation loss: 2.051329446095292

Epoch: 6| Step: 2
Training loss: 1.420943021774292
Validation loss: 2.064146746871292

Epoch: 6| Step: 3
Training loss: 2.109297275543213
Validation loss: 2.0735299382158505

Epoch: 6| Step: 4
Training loss: 1.6201488971710205
Validation loss: 2.0460365690210813

Epoch: 6| Step: 5
Training loss: 1.7502543926239014
Validation loss: 2.053053735404886

Epoch: 6| Step: 6
Training loss: 1.9858052730560303
Validation loss: 2.033044720208773

Epoch: 6| Step: 7
Training loss: 2.1142358779907227
Validation loss: 2.0399182035077

Epoch: 6| Step: 8
Training loss: 1.4642798900604248
Validation loss: 2.041782017677061

Epoch: 6| Step: 9
Training loss: 1.6805849075317383
Validation loss: 2.05326319766301

Epoch: 6| Step: 10
Training loss: 2.816155433654785
Validation loss: 2.0511468174637004

Epoch: 6| Step: 11
Training loss: 1.625422477722168
Validation loss: 2.085523907856275

Epoch: 6| Step: 12
Training loss: 1.6959142684936523
Validation loss: 2.0756200026440363

Epoch: 6| Step: 13
Training loss: 1.8261752128601074
Validation loss: 2.1031776397458968

Epoch: 377| Step: 0
Training loss: 2.6857478618621826
Validation loss: 2.143194603663619

Epoch: 6| Step: 1
Training loss: 1.1578905582427979
Validation loss: 2.157085435364836

Epoch: 6| Step: 2
Training loss: 2.2616264820098877
Validation loss: 2.171818669124316

Epoch: 6| Step: 3
Training loss: 1.642263650894165
Validation loss: 2.133083107650921

Epoch: 6| Step: 4
Training loss: 2.1575987339019775
Validation loss: 2.0739621205996444

Epoch: 6| Step: 5
Training loss: 2.1742799282073975
Validation loss: 2.035070479557078

Epoch: 6| Step: 6
Training loss: 1.7758163213729858
Validation loss: 2.009719899905625

Epoch: 6| Step: 7
Training loss: 1.3674997091293335
Validation loss: 2.0020182696721887

Epoch: 6| Step: 8
Training loss: 2.381504535675049
Validation loss: 2.0019254453720583

Epoch: 6| Step: 9
Training loss: 1.4841303825378418
Validation loss: 2.034164777366064

Epoch: 6| Step: 10
Training loss: 1.7082040309906006
Validation loss: 2.032310034639092

Epoch: 6| Step: 11
Training loss: 1.7245283126831055
Validation loss: 2.0493007680421234

Epoch: 6| Step: 12
Training loss: 1.690298318862915
Validation loss: 2.0285883411284416

Epoch: 6| Step: 13
Training loss: 1.4347710609436035
Validation loss: 2.06211148154351

Epoch: 378| Step: 0
Training loss: 1.5654058456420898
Validation loss: 2.0693376295028196

Epoch: 6| Step: 1
Training loss: 1.213386058807373
Validation loss: 2.095894562300815

Epoch: 6| Step: 2
Training loss: 2.1256232261657715
Validation loss: 2.091465824393816

Epoch: 6| Step: 3
Training loss: 1.943816900253296
Validation loss: 2.099497050367376

Epoch: 6| Step: 4
Training loss: 2.4131083488464355
Validation loss: 2.107376580597252

Epoch: 6| Step: 5
Training loss: 1.5500935316085815
Validation loss: 2.0730031151925363

Epoch: 6| Step: 6
Training loss: 1.5643388032913208
Validation loss: 2.1044497118201306

Epoch: 6| Step: 7
Training loss: 1.7997121810913086
Validation loss: 2.1056210097446235

Epoch: 6| Step: 8
Training loss: 1.7271901369094849
Validation loss: 2.113074092454808

Epoch: 6| Step: 9
Training loss: 1.9884240627288818
Validation loss: 2.115098899410617

Epoch: 6| Step: 10
Training loss: 1.334402322769165
Validation loss: 2.093364341284639

Epoch: 6| Step: 11
Training loss: 1.8952224254608154
Validation loss: 2.059233775702856

Epoch: 6| Step: 12
Training loss: 2.192918300628662
Validation loss: 2.026671184006558

Epoch: 6| Step: 13
Training loss: 2.8451268672943115
Validation loss: 2.0397155413063626

Epoch: 379| Step: 0
Training loss: 1.8886032104492188
Validation loss: 2.0539372621044034

Epoch: 6| Step: 1
Training loss: 2.1940488815307617
Validation loss: 2.0506923685791674

Epoch: 6| Step: 2
Training loss: 2.212073802947998
Validation loss: 2.0765943655403714

Epoch: 6| Step: 3
Training loss: 2.1870994567871094
Validation loss: 2.064597955314062

Epoch: 6| Step: 4
Training loss: 1.6460970640182495
Validation loss: 2.0329660497685915

Epoch: 6| Step: 5
Training loss: 1.4641190767288208
Validation loss: 2.0454658603155487

Epoch: 6| Step: 6
Training loss: 1.7991868257522583
Validation loss: 2.0369356550196165

Epoch: 6| Step: 7
Training loss: 2.4013495445251465
Validation loss: 2.0148153638326995

Epoch: 6| Step: 8
Training loss: 1.3193821907043457
Validation loss: 2.010412694305502

Epoch: 6| Step: 9
Training loss: 1.7954084873199463
Validation loss: 2.008852284441712

Epoch: 6| Step: 10
Training loss: 1.7762452363967896
Validation loss: 1.9891793202328425

Epoch: 6| Step: 11
Training loss: 1.3351279497146606
Validation loss: 1.9903638849976242

Epoch: 6| Step: 12
Training loss: 2.1044676303863525
Validation loss: 2.0237776182031118

Epoch: 6| Step: 13
Training loss: 1.7954875230789185
Validation loss: 2.044306698665824

Epoch: 380| Step: 0
Training loss: 1.866278886795044
Validation loss: 2.081151190624442

Epoch: 6| Step: 1
Training loss: 1.9128497838974
Validation loss: 2.1030318890848467

Epoch: 6| Step: 2
Training loss: 1.7967591285705566
Validation loss: 2.099318096714635

Epoch: 6| Step: 3
Training loss: 1.5680475234985352
Validation loss: 2.112204933679232

Epoch: 6| Step: 4
Training loss: 1.470335602760315
Validation loss: 2.1143627474384923

Epoch: 6| Step: 5
Training loss: 2.191133975982666
Validation loss: 2.0874961537699543

Epoch: 6| Step: 6
Training loss: 1.3330910205841064
Validation loss: 2.094233516723879

Epoch: 6| Step: 7
Training loss: 1.6212211847305298
Validation loss: 2.0725062303645636

Epoch: 6| Step: 8
Training loss: 1.7344768047332764
Validation loss: 2.074920738897016

Epoch: 6| Step: 9
Training loss: 2.15492582321167
Validation loss: 2.0715710360516786

Epoch: 6| Step: 10
Training loss: 1.3975636959075928
Validation loss: 2.0311840157355032

Epoch: 6| Step: 11
Training loss: 2.1925668716430664
Validation loss: 2.0386344694322154

Epoch: 6| Step: 12
Training loss: 1.8299684524536133
Validation loss: 2.0310895442962646

Epoch: 6| Step: 13
Training loss: 2.840492010116577
Validation loss: 2.0088498579558505

Epoch: 381| Step: 0
Training loss: 1.614901065826416
Validation loss: 2.0286788171337498

Epoch: 6| Step: 1
Training loss: 1.7366633415222168
Validation loss: 2.002264829092128

Epoch: 6| Step: 2
Training loss: 2.103792428970337
Validation loss: 2.0027960782409995

Epoch: 6| Step: 3
Training loss: 1.8144168853759766
Validation loss: 2.0362159795658563

Epoch: 6| Step: 4
Training loss: 2.200411319732666
Validation loss: 2.0293697285395798

Epoch: 6| Step: 5
Training loss: 1.3989280462265015
Validation loss: 2.0784801347281343

Epoch: 6| Step: 6
Training loss: 2.0071492195129395
Validation loss: 2.10432517656716

Epoch: 6| Step: 7
Training loss: 1.89396333694458
Validation loss: 2.0761409933849047

Epoch: 6| Step: 8
Training loss: 0.9284393191337585
Validation loss: 2.096935640099228

Epoch: 6| Step: 9
Training loss: 1.7254735231399536
Validation loss: 2.1021855082563174

Epoch: 6| Step: 10
Training loss: 1.657012701034546
Validation loss: 2.099167921209848

Epoch: 6| Step: 11
Training loss: 2.036803722381592
Validation loss: 2.071495556062268

Epoch: 6| Step: 12
Training loss: 2.0734152793884277
Validation loss: 2.086887326291812

Epoch: 6| Step: 13
Training loss: 2.1411192417144775
Validation loss: 2.0415058699987267

Epoch: 382| Step: 0
Training loss: 1.6171233654022217
Validation loss: 2.036292770857452

Epoch: 6| Step: 1
Training loss: 2.0456202030181885
Validation loss: 2.0456653923116703

Epoch: 6| Step: 2
Training loss: 1.6232588291168213
Validation loss: 2.0339735810474684

Epoch: 6| Step: 3
Training loss: 1.6315052509307861
Validation loss: 2.051798261621947

Epoch: 6| Step: 4
Training loss: 1.952726125717163
Validation loss: 2.056064313457858

Epoch: 6| Step: 5
Training loss: 1.466292381286621
Validation loss: 2.064864081721152

Epoch: 6| Step: 6
Training loss: 1.4463697671890259
Validation loss: 2.0597356006663334

Epoch: 6| Step: 7
Training loss: 1.6357040405273438
Validation loss: 2.0686772561842397

Epoch: 6| Step: 8
Training loss: 1.7064826488494873
Validation loss: 2.0361872744816605

Epoch: 6| Step: 9
Training loss: 1.4528608322143555
Validation loss: 2.044911894747006

Epoch: 6| Step: 10
Training loss: 2.251032829284668
Validation loss: 2.0351710524610294

Epoch: 6| Step: 11
Training loss: 2.320934295654297
Validation loss: 2.04925658241395

Epoch: 6| Step: 12
Training loss: 2.1676414012908936
Validation loss: 2.047289022835352

Epoch: 6| Step: 13
Training loss: 1.4229496717453003
Validation loss: 2.042148055568818

Epoch: 383| Step: 0
Training loss: 2.0529732704162598
Validation loss: 2.0487891294622935

Epoch: 6| Step: 1
Training loss: 2.248293876647949
Validation loss: 2.032853723854147

Epoch: 6| Step: 2
Training loss: 1.3130303621292114
Validation loss: 2.02280822876961

Epoch: 6| Step: 3
Training loss: 1.7551627159118652
Validation loss: 2.01954286841936

Epoch: 6| Step: 4
Training loss: 1.7751274108886719
Validation loss: 2.026613700774408

Epoch: 6| Step: 5
Training loss: 1.6091668605804443
Validation loss: 2.0201688786988616

Epoch: 6| Step: 6
Training loss: 2.2377376556396484
Validation loss: 2.03517746925354

Epoch: 6| Step: 7
Training loss: 1.7256662845611572
Validation loss: 2.045065467075635

Epoch: 6| Step: 8
Training loss: 1.4932183027267456
Validation loss: 2.0491991940365044

Epoch: 6| Step: 9
Training loss: 1.2136800289154053
Validation loss: 2.0752032238950013

Epoch: 6| Step: 10
Training loss: 1.824114203453064
Validation loss: 2.095477645115186

Epoch: 6| Step: 11
Training loss: 2.175283432006836
Validation loss: 2.1013453058017197

Epoch: 6| Step: 12
Training loss: 1.7718621492385864
Validation loss: 2.118420811109645

Epoch: 6| Step: 13
Training loss: 2.0201399326324463
Validation loss: 2.130152121666939

Epoch: 384| Step: 0
Training loss: 2.1576504707336426
Validation loss: 2.075925814208164

Epoch: 6| Step: 1
Training loss: 1.7741535902023315
Validation loss: 2.069953981266227

Epoch: 6| Step: 2
Training loss: 1.4617186784744263
Validation loss: 2.0492794770066456

Epoch: 6| Step: 3
Training loss: 2.268496513366699
Validation loss: 2.0342058622708885

Epoch: 6| Step: 4
Training loss: 1.8586163520812988
Validation loss: 2.0396702827945834

Epoch: 6| Step: 5
Training loss: 1.5114127397537231
Validation loss: 2.053455871920432

Epoch: 6| Step: 6
Training loss: 1.8433654308319092
Validation loss: 2.0144565720711984

Epoch: 6| Step: 7
Training loss: 1.8875504732131958
Validation loss: 2.01149978048058

Epoch: 6| Step: 8
Training loss: 1.8816235065460205
Validation loss: 2.0036295895935385

Epoch: 6| Step: 9
Training loss: 1.7123908996582031
Validation loss: 1.9890227394719278

Epoch: 6| Step: 10
Training loss: 1.8470180034637451
Validation loss: 2.0034882951808233

Epoch: 6| Step: 11
Training loss: 1.5607696771621704
Validation loss: 2.0061811477907243

Epoch: 6| Step: 12
Training loss: 1.5290193557739258
Validation loss: 2.0432962115092943

Epoch: 6| Step: 13
Training loss: 1.4308240413665771
Validation loss: 2.0421779617186515

Epoch: 385| Step: 0
Training loss: 2.048977851867676
Validation loss: 2.04674949953633

Epoch: 6| Step: 1
Training loss: 2.0704345703125
Validation loss: 2.0175263599682878

Epoch: 6| Step: 2
Training loss: 1.0753726959228516
Validation loss: 2.029429328057074

Epoch: 6| Step: 3
Training loss: 2.032712936401367
Validation loss: 2.009330468793069

Epoch: 6| Step: 4
Training loss: 1.8869104385375977
Validation loss: 2.0056382917588755

Epoch: 6| Step: 5
Training loss: 1.6852800846099854
Validation loss: 2.0032727564534833

Epoch: 6| Step: 6
Training loss: 1.6943347454071045
Validation loss: 2.0427971065685315

Epoch: 6| Step: 7
Training loss: 2.219162702560425
Validation loss: 2.0452081439315632

Epoch: 6| Step: 8
Training loss: 1.2032670974731445
Validation loss: 2.0361920390077817

Epoch: 6| Step: 9
Training loss: 1.225841760635376
Validation loss: 2.033615586578205

Epoch: 6| Step: 10
Training loss: 2.1325998306274414
Validation loss: 2.0469883872616674

Epoch: 6| Step: 11
Training loss: 1.7978562116622925
Validation loss: 2.067160755075434

Epoch: 6| Step: 12
Training loss: 1.8557244539260864
Validation loss: 2.10845003333143

Epoch: 6| Step: 13
Training loss: 1.9639657735824585
Validation loss: 2.146108865737915

Epoch: 386| Step: 0
Training loss: 2.185093402862549
Validation loss: 2.1689134131195726

Epoch: 6| Step: 1
Training loss: 1.575382947921753
Validation loss: 2.177907148996989

Epoch: 6| Step: 2
Training loss: 2.229471206665039
Validation loss: 2.176657712587746

Epoch: 6| Step: 3
Training loss: 1.8253909349441528
Validation loss: 2.141906112752935

Epoch: 6| Step: 4
Training loss: 1.7114646434783936
Validation loss: 2.079036679319156

Epoch: 6| Step: 5
Training loss: 1.1336419582366943
Validation loss: 2.0562246230340775

Epoch: 6| Step: 6
Training loss: 1.9027951955795288
Validation loss: 1.988839372511833

Epoch: 6| Step: 7
Training loss: 1.5820984840393066
Validation loss: 1.9675138778583978

Epoch: 6| Step: 8
Training loss: 1.653569221496582
Validation loss: 1.9608023051292665

Epoch: 6| Step: 9
Training loss: 2.07187557220459
Validation loss: 1.9670746505901378

Epoch: 6| Step: 10
Training loss: 2.339451313018799
Validation loss: 1.9745615823294527

Epoch: 6| Step: 11
Training loss: 1.336507797241211
Validation loss: 1.9824364031514814

Epoch: 6| Step: 12
Training loss: 2.3124232292175293
Validation loss: 1.989380721122988

Epoch: 6| Step: 13
Training loss: 1.5838626623153687
Validation loss: 2.000355746156426

Epoch: 387| Step: 0
Training loss: 1.3277664184570312
Validation loss: 2.048294956966113

Epoch: 6| Step: 1
Training loss: 2.3741273880004883
Validation loss: 2.087778127321633

Epoch: 6| Step: 2
Training loss: 1.2982265949249268
Validation loss: 2.1166949374701387

Epoch: 6| Step: 3
Training loss: 2.5980589389801025
Validation loss: 2.1379610453882525

Epoch: 6| Step: 4
Training loss: 1.8479132652282715
Validation loss: 2.150752834094468

Epoch: 6| Step: 5
Training loss: 1.8047736883163452
Validation loss: 2.14695768971597

Epoch: 6| Step: 6
Training loss: 2.1334733963012695
Validation loss: 2.1468151512966362

Epoch: 6| Step: 7
Training loss: 0.9381964206695557
Validation loss: 2.1244878474102227

Epoch: 6| Step: 8
Training loss: 1.6094269752502441
Validation loss: 2.106447719758557

Epoch: 6| Step: 9
Training loss: 1.485358715057373
Validation loss: 2.0956754940812305

Epoch: 6| Step: 10
Training loss: 1.866065263748169
Validation loss: 2.062828266492454

Epoch: 6| Step: 11
Training loss: 2.078918695449829
Validation loss: 2.0741530054359028

Epoch: 6| Step: 12
Training loss: 1.5387792587280273
Validation loss: 2.047485274653281

Epoch: 6| Step: 13
Training loss: 2.218867540359497
Validation loss: 2.036365937161189

Epoch: 388| Step: 0
Training loss: 1.8827664852142334
Validation loss: 2.0394570494210846

Epoch: 6| Step: 1
Training loss: 1.3094813823699951
Validation loss: 2.028957536143641

Epoch: 6| Step: 2
Training loss: 1.7839272022247314
Validation loss: 2.0288459767577467

Epoch: 6| Step: 3
Training loss: 1.2795549631118774
Validation loss: 2.0281984780424382

Epoch: 6| Step: 4
Training loss: 2.2170138359069824
Validation loss: 2.0170663428562943

Epoch: 6| Step: 5
Training loss: 1.3886077404022217
Validation loss: 2.0191097490249144

Epoch: 6| Step: 6
Training loss: 1.7413338422775269
Validation loss: 2.0248454745097826

Epoch: 6| Step: 7
Training loss: 1.5290988683700562
Validation loss: 2.034085376288301

Epoch: 6| Step: 8
Training loss: 1.589198112487793
Validation loss: 2.0546795424594673

Epoch: 6| Step: 9
Training loss: 1.4281160831451416
Validation loss: 2.0596955719814507

Epoch: 6| Step: 10
Training loss: 2.1232404708862305
Validation loss: 2.097862169306765

Epoch: 6| Step: 11
Training loss: 2.434203624725342
Validation loss: 2.1053772716112036

Epoch: 6| Step: 12
Training loss: 1.9637457132339478
Validation loss: 2.13003856648681

Epoch: 6| Step: 13
Training loss: 2.227897882461548
Validation loss: 2.1546115567607265

Epoch: 389| Step: 0
Training loss: 1.4362916946411133
Validation loss: 2.1035810619272213

Epoch: 6| Step: 1
Training loss: 2.61950945854187
Validation loss: 2.073122775682839

Epoch: 6| Step: 2
Training loss: 1.6307964324951172
Validation loss: 2.039709457787134

Epoch: 6| Step: 3
Training loss: 1.385871410369873
Validation loss: 2.0162508923520326

Epoch: 6| Step: 4
Training loss: 1.730952262878418
Validation loss: 1.9894058255739109

Epoch: 6| Step: 5
Training loss: 1.5173707008361816
Validation loss: 2.0072261902593795

Epoch: 6| Step: 6
Training loss: 2.2294154167175293
Validation loss: 1.9918561263750958

Epoch: 6| Step: 7
Training loss: 1.0223281383514404
Validation loss: 2.015635992891045

Epoch: 6| Step: 8
Training loss: 1.9943042993545532
Validation loss: 2.027742583264587

Epoch: 6| Step: 9
Training loss: 1.458889365196228
Validation loss: 2.058700014186162

Epoch: 6| Step: 10
Training loss: 1.6079440116882324
Validation loss: 2.0719785190397695

Epoch: 6| Step: 11
Training loss: 1.453781008720398
Validation loss: 2.101993037808326

Epoch: 6| Step: 12
Training loss: 2.5841281414031982
Validation loss: 2.1217999560858614

Epoch: 6| Step: 13
Training loss: 2.293519973754883
Validation loss: 2.138499923931655

Epoch: 390| Step: 0
Training loss: 1.595521330833435
Validation loss: 2.1180888375928326

Epoch: 6| Step: 1
Training loss: 1.7813520431518555
Validation loss: 2.114946439702024

Epoch: 6| Step: 2
Training loss: 1.5077309608459473
Validation loss: 2.0973999269547

Epoch: 6| Step: 3
Training loss: 1.9260470867156982
Validation loss: 2.066130599667949

Epoch: 6| Step: 4
Training loss: 2.323824882507324
Validation loss: 2.063724894677439

Epoch: 6| Step: 5
Training loss: 1.3660634756088257
Validation loss: 2.078371706829276

Epoch: 6| Step: 6
Training loss: 2.0069615840911865
Validation loss: 2.061589156427691

Epoch: 6| Step: 7
Training loss: 2.1214635372161865
Validation loss: 2.045226340652794

Epoch: 6| Step: 8
Training loss: 1.4810293912887573
Validation loss: 2.0509664461176884

Epoch: 6| Step: 9
Training loss: 1.2677708864212036
Validation loss: 2.0350594507750643

Epoch: 6| Step: 10
Training loss: 1.7810920476913452
Validation loss: 2.0384626157822145

Epoch: 6| Step: 11
Training loss: 2.1873035430908203
Validation loss: 2.0163993207357263

Epoch: 6| Step: 12
Training loss: 1.7757989168167114
Validation loss: 2.0091393814292005

Epoch: 6| Step: 13
Training loss: 0.8974441885948181
Validation loss: 1.9956335239512946

Epoch: 391| Step: 0
Training loss: 1.8403995037078857
Validation loss: 1.9813271094393987

Epoch: 6| Step: 1
Training loss: 1.589784860610962
Validation loss: 1.9874218497225034

Epoch: 6| Step: 2
Training loss: 1.7586066722869873
Validation loss: 1.9756359618197206

Epoch: 6| Step: 3
Training loss: 1.2870032787322998
Validation loss: 1.9846787580879786

Epoch: 6| Step: 4
Training loss: 1.6768534183502197
Validation loss: 2.005260673902368

Epoch: 6| Step: 5
Training loss: 1.9079736471176147
Validation loss: 2.002455901074153

Epoch: 6| Step: 6
Training loss: 1.8636085987091064
Validation loss: 2.0316355510424544

Epoch: 6| Step: 7
Training loss: 1.5607664585113525
Validation loss: 2.0282971948705693

Epoch: 6| Step: 8
Training loss: 1.6054656505584717
Validation loss: 2.06019756614521

Epoch: 6| Step: 9
Training loss: 2.0554757118225098
Validation loss: 2.048153317102822

Epoch: 6| Step: 10
Training loss: 2.278379440307617
Validation loss: 2.0682066153454524

Epoch: 6| Step: 11
Training loss: 1.6938886642456055
Validation loss: 2.0802411802353395

Epoch: 6| Step: 12
Training loss: 1.805415153503418
Validation loss: 2.0864736110933366

Epoch: 6| Step: 13
Training loss: 2.0115602016448975
Validation loss: 2.085940980142163

Epoch: 392| Step: 0
Training loss: 1.529523491859436
Validation loss: 2.077840534589624

Epoch: 6| Step: 1
Training loss: 1.9580376148223877
Validation loss: 2.0505995391517557

Epoch: 6| Step: 2
Training loss: 1.8486603498458862
Validation loss: 2.056485911851288

Epoch: 6| Step: 3
Training loss: 1.5999782085418701
Validation loss: 2.0463122347349763

Epoch: 6| Step: 4
Training loss: 2.1623406410217285
Validation loss: 2.030411627984816

Epoch: 6| Step: 5
Training loss: 2.4547410011291504
Validation loss: 2.05133145342591

Epoch: 6| Step: 6
Training loss: 1.842604637145996
Validation loss: 2.033006432235882

Epoch: 6| Step: 7
Training loss: 1.715273380279541
Validation loss: 2.047538508651077

Epoch: 6| Step: 8
Training loss: 1.732175350189209
Validation loss: 2.0617996056874595

Epoch: 6| Step: 9
Training loss: 1.6162443161010742
Validation loss: 2.058089256286621

Epoch: 6| Step: 10
Training loss: 1.5134246349334717
Validation loss: 2.057672236555366

Epoch: 6| Step: 11
Training loss: 2.108520984649658
Validation loss: 2.0736632398379746

Epoch: 6| Step: 12
Training loss: 1.4007203578948975
Validation loss: 2.084249283677788

Epoch: 6| Step: 13
Training loss: 0.6638444066047668
Validation loss: 2.0978184489793676

Epoch: 393| Step: 0
Training loss: 1.9541023969650269
Validation loss: 2.0850438994746052

Epoch: 6| Step: 1
Training loss: 1.1954989433288574
Validation loss: 2.0724592439589964

Epoch: 6| Step: 2
Training loss: 1.8380036354064941
Validation loss: 2.0597559893003075

Epoch: 6| Step: 3
Training loss: 1.6137363910675049
Validation loss: 2.080254313766315

Epoch: 6| Step: 4
Training loss: 1.5991597175598145
Validation loss: 2.0845367985387004

Epoch: 6| Step: 5
Training loss: 1.2179465293884277
Validation loss: 2.0763124522342475

Epoch: 6| Step: 6
Training loss: 2.1611061096191406
Validation loss: 2.070160667101542

Epoch: 6| Step: 7
Training loss: 2.3974194526672363
Validation loss: 2.039230058270116

Epoch: 6| Step: 8
Training loss: 2.133615493774414
Validation loss: 1.9914515556827668

Epoch: 6| Step: 9
Training loss: 1.7971111536026
Validation loss: 1.9785970103356145

Epoch: 6| Step: 10
Training loss: 1.529621958732605
Validation loss: 1.9924799370509323

Epoch: 6| Step: 11
Training loss: 2.0107975006103516
Validation loss: 1.9885621493862522

Epoch: 6| Step: 12
Training loss: 1.3408596515655518
Validation loss: 1.9936273097991943

Epoch: 6| Step: 13
Training loss: 1.9817436933517456
Validation loss: 1.9925356872620121

Epoch: 394| Step: 0
Training loss: 2.6399805545806885
Validation loss: 1.980569935614063

Epoch: 6| Step: 1
Training loss: 2.1196553707122803
Validation loss: 2.012554273810438

Epoch: 6| Step: 2
Training loss: 2.2455227375030518
Validation loss: 2.028441761129646

Epoch: 6| Step: 3
Training loss: 2.019090175628662
Validation loss: 2.0617525090453444

Epoch: 6| Step: 4
Training loss: 2.1063127517700195
Validation loss: 2.0613226608563493

Epoch: 6| Step: 5
Training loss: 1.601339340209961
Validation loss: 2.052804118843489

Epoch: 6| Step: 6
Training loss: 1.5311381816864014
Validation loss: 2.0549291346662786

Epoch: 6| Step: 7
Training loss: 1.4516427516937256
Validation loss: 2.073018261181411

Epoch: 6| Step: 8
Training loss: 1.4339150190353394
Validation loss: 2.0644675044603247

Epoch: 6| Step: 9
Training loss: 1.6425886154174805
Validation loss: 2.1070221188247844

Epoch: 6| Step: 10
Training loss: 1.4778040647506714
Validation loss: 2.123790523057343

Epoch: 6| Step: 11
Training loss: 1.1557658910751343
Validation loss: 2.0720371584738455

Epoch: 6| Step: 12
Training loss: 1.2508258819580078
Validation loss: 2.0467306952322684

Epoch: 6| Step: 13
Training loss: 1.8332031965255737
Validation loss: 2.0230779570917927

Epoch: 395| Step: 0
Training loss: 1.5001717805862427
Validation loss: 2.0133987626721783

Epoch: 6| Step: 1
Training loss: 1.555606484413147
Validation loss: 2.0257664213898363

Epoch: 6| Step: 2
Training loss: 2.111457347869873
Validation loss: 2.0250599320216844

Epoch: 6| Step: 3
Training loss: 1.483567714691162
Validation loss: 2.0172805427223124

Epoch: 6| Step: 4
Training loss: 1.6688156127929688
Validation loss: 2.021141572665143

Epoch: 6| Step: 5
Training loss: 2.4463396072387695
Validation loss: 2.0149943392763854

Epoch: 6| Step: 6
Training loss: 1.7977633476257324
Validation loss: 2.049113204402308

Epoch: 6| Step: 7
Training loss: 1.2537689208984375
Validation loss: 2.0428682475961666

Epoch: 6| Step: 8
Training loss: 1.4489251375198364
Validation loss: 2.0507535549902145

Epoch: 6| Step: 9
Training loss: 1.884689450263977
Validation loss: 2.0677185238048597

Epoch: 6| Step: 10
Training loss: 2.7728350162506104
Validation loss: 2.07011245143029

Epoch: 6| Step: 11
Training loss: 1.5254658460617065
Validation loss: 2.082387511448194

Epoch: 6| Step: 12
Training loss: 1.0258002281188965
Validation loss: 2.0848521776096796

Epoch: 6| Step: 13
Training loss: 2.2224044799804688
Validation loss: 2.1169851300536946

Epoch: 396| Step: 0
Training loss: 2.163486957550049
Validation loss: 2.092953271763299

Epoch: 6| Step: 1
Training loss: 2.0694031715393066
Validation loss: 2.0776927368615263

Epoch: 6| Step: 2
Training loss: 1.9904062747955322
Validation loss: 2.07165386087151

Epoch: 6| Step: 3
Training loss: 1.9480488300323486
Validation loss: 2.0755492333442933

Epoch: 6| Step: 4
Training loss: 1.7368707656860352
Validation loss: 2.069075999721404

Epoch: 6| Step: 5
Training loss: 1.5077987909317017
Validation loss: 2.082802698176394

Epoch: 6| Step: 6
Training loss: 1.8888331651687622
Validation loss: 2.0673102973609843

Epoch: 6| Step: 7
Training loss: 1.8665273189544678
Validation loss: 2.0589111748562066

Epoch: 6| Step: 8
Training loss: 1.8153753280639648
Validation loss: 2.026267815661687

Epoch: 6| Step: 9
Training loss: 0.9257198572158813
Validation loss: 2.0133962746589416

Epoch: 6| Step: 10
Training loss: 1.329596757888794
Validation loss: 1.9987879235257384

Epoch: 6| Step: 11
Training loss: 1.7125253677368164
Validation loss: 2.000535052309754

Epoch: 6| Step: 12
Training loss: 1.442875623703003
Validation loss: 2.019442019924041

Epoch: 6| Step: 13
Training loss: 1.924506664276123
Validation loss: 2.02541180323529

Epoch: 397| Step: 0
Training loss: 1.7555497884750366
Validation loss: 2.034340557231698

Epoch: 6| Step: 1
Training loss: 2.4262518882751465
Validation loss: 2.0588654215617845

Epoch: 6| Step: 2
Training loss: 2.23793363571167
Validation loss: 2.076706927309754

Epoch: 6| Step: 3
Training loss: 1.76851224899292
Validation loss: 2.075704313093616

Epoch: 6| Step: 4
Training loss: 1.9905164241790771
Validation loss: 2.0946634097765853

Epoch: 6| Step: 5
Training loss: 1.2815513610839844
Validation loss: 2.0917617121050434

Epoch: 6| Step: 6
Training loss: 1.561323642730713
Validation loss: 2.0769208503025833

Epoch: 6| Step: 7
Training loss: 1.6504441499710083
Validation loss: 2.0938000089378765

Epoch: 6| Step: 8
Training loss: 1.1568607091903687
Validation loss: 2.0664567152659097

Epoch: 6| Step: 9
Training loss: 1.2369871139526367
Validation loss: 2.0733164536055697

Epoch: 6| Step: 10
Training loss: 1.9951953887939453
Validation loss: 2.077916019706316

Epoch: 6| Step: 11
Training loss: 1.4224393367767334
Validation loss: 2.0793045413109565

Epoch: 6| Step: 12
Training loss: 1.6762747764587402
Validation loss: 2.052400157656721

Epoch: 6| Step: 13
Training loss: 2.3254916667938232
Validation loss: 2.0637251254050963

Epoch: 398| Step: 0
Training loss: 1.6612372398376465
Validation loss: 2.0632146968636462

Epoch: 6| Step: 1
Training loss: 1.9745622873306274
Validation loss: 2.0465379248383226

Epoch: 6| Step: 2
Training loss: 1.4302806854248047
Validation loss: 2.038414421901908

Epoch: 6| Step: 3
Training loss: 1.578843593597412
Validation loss: 2.033375641351105

Epoch: 6| Step: 4
Training loss: 1.9532301425933838
Validation loss: 2.0557267537681003

Epoch: 6| Step: 5
Training loss: 1.649033784866333
Validation loss: 2.0882482464595506

Epoch: 6| Step: 6
Training loss: 1.5555047988891602
Validation loss: 2.0615473370398245

Epoch: 6| Step: 7
Training loss: 1.7232428789138794
Validation loss: 2.0456857437728555

Epoch: 6| Step: 8
Training loss: 1.590928554534912
Validation loss: 2.0449586427339943

Epoch: 6| Step: 9
Training loss: 1.3682188987731934
Validation loss: 2.016639854318352

Epoch: 6| Step: 10
Training loss: 1.9704869985580444
Validation loss: 1.9903781414031982

Epoch: 6| Step: 11
Training loss: 2.294907569885254
Validation loss: 1.999835592444225

Epoch: 6| Step: 12
Training loss: 1.50413978099823
Validation loss: 2.018359136837785

Epoch: 6| Step: 13
Training loss: 2.1661102771759033
Validation loss: 2.0132998856165076

Epoch: 399| Step: 0
Training loss: 1.5504931211471558
Validation loss: 2.0382422554877495

Epoch: 6| Step: 1
Training loss: 1.1277952194213867
Validation loss: 2.036571184794108

Epoch: 6| Step: 2
Training loss: 2.4104456901550293
Validation loss: 2.0266472934394755

Epoch: 6| Step: 3
Training loss: 1.6020830869674683
Validation loss: 2.041285535340668

Epoch: 6| Step: 4
Training loss: 1.7060472965240479
Validation loss: 2.0872090939552552

Epoch: 6| Step: 5
Training loss: 1.0803806781768799
Validation loss: 2.075826535942734

Epoch: 6| Step: 6
Training loss: 1.9911720752716064
Validation loss: 2.08870445271974

Epoch: 6| Step: 7
Training loss: 1.8848823308944702
Validation loss: 2.095703938955902

Epoch: 6| Step: 8
Training loss: 1.7158644199371338
Validation loss: 2.0853162273283927

Epoch: 6| Step: 9
Training loss: 1.75662362575531
Validation loss: 2.0759054691560808

Epoch: 6| Step: 10
Training loss: 2.242867946624756
Validation loss: 2.0537757027533745

Epoch: 6| Step: 11
Training loss: 1.7908011674880981
Validation loss: 2.0419917850084204

Epoch: 6| Step: 12
Training loss: 1.4455630779266357
Validation loss: 2.05032701646128

Epoch: 6| Step: 13
Training loss: 1.9548068046569824
Validation loss: 2.0234552916660102

Epoch: 400| Step: 0
Training loss: 1.8579668998718262
Validation loss: 2.018347106954103

Epoch: 6| Step: 1
Training loss: 1.3908817768096924
Validation loss: 1.993895430718699

Epoch: 6| Step: 2
Training loss: 1.879626989364624
Validation loss: 1.9923093498394053

Epoch: 6| Step: 3
Training loss: 1.2784589529037476
Validation loss: 1.9909699834803098

Epoch: 6| Step: 4
Training loss: 1.1007510423660278
Validation loss: 2.0226606976601387

Epoch: 6| Step: 5
Training loss: 1.4786382913589478
Validation loss: 2.070766830957064

Epoch: 6| Step: 6
Training loss: 1.5959184169769287
Validation loss: 2.121621548488576

Epoch: 6| Step: 7
Training loss: 1.9782676696777344
Validation loss: 2.148991734750809

Epoch: 6| Step: 8
Training loss: 2.2095866203308105
Validation loss: 2.1783247724656136

Epoch: 6| Step: 9
Training loss: 1.6025373935699463
Validation loss: 2.1730977501920474

Epoch: 6| Step: 10
Training loss: 2.1160244941711426
Validation loss: 2.116954526593608

Epoch: 6| Step: 11
Training loss: 2.1034932136535645
Validation loss: 2.050907752847159

Epoch: 6| Step: 12
Training loss: 2.046193838119507
Validation loss: 2.001573363939921

Epoch: 6| Step: 13
Training loss: 2.0951154232025146
Validation loss: 1.9851052696986864

Epoch: 401| Step: 0
Training loss: 1.838585615158081
Validation loss: 1.9914721212079447

Epoch: 6| Step: 1
Training loss: 2.2920877933502197
Validation loss: 2.014532345597462

Epoch: 6| Step: 2
Training loss: 1.7510346174240112
Validation loss: 1.9970985330561155

Epoch: 6| Step: 3
Training loss: 1.2909451723098755
Validation loss: 2.0245138957936275

Epoch: 6| Step: 4
Training loss: 1.856632947921753
Validation loss: 2.0115734813033894

Epoch: 6| Step: 5
Training loss: 2.2055819034576416
Validation loss: 2.033260101913124

Epoch: 6| Step: 6
Training loss: 1.8850510120391846
Validation loss: 2.0117963347383725

Epoch: 6| Step: 7
Training loss: 2.038970470428467
Validation loss: 2.007084318386611

Epoch: 6| Step: 8
Training loss: 2.105194568634033
Validation loss: 2.021733127614503

Epoch: 6| Step: 9
Training loss: 2.2050886154174805
Validation loss: 2.0334235186217935

Epoch: 6| Step: 10
Training loss: 1.3953582048416138
Validation loss: 2.0931991402820875

Epoch: 6| Step: 11
Training loss: 1.926958441734314
Validation loss: 2.1482842711992163

Epoch: 6| Step: 12
Training loss: 1.3449103832244873
Validation loss: 2.1792523091839207

Epoch: 6| Step: 13
Training loss: 1.0467320680618286
Validation loss: 2.1844006994719147

Epoch: 402| Step: 0
Training loss: 1.8525474071502686
Validation loss: 2.1436991665952947

Epoch: 6| Step: 1
Training loss: 1.3858020305633545
Validation loss: 2.0772059937959075

Epoch: 6| Step: 2
Training loss: 1.728442907333374
Validation loss: 2.0713598625634306

Epoch: 6| Step: 3
Training loss: 1.37992262840271
Validation loss: 2.0428049974544074

Epoch: 6| Step: 4
Training loss: 1.7631468772888184
Validation loss: 2.0294395210922405

Epoch: 6| Step: 5
Training loss: 2.147796154022217
Validation loss: 2.044301081729192

Epoch: 6| Step: 6
Training loss: 1.796270489692688
Validation loss: 2.016078045291285

Epoch: 6| Step: 7
Training loss: 1.4269461631774902
Validation loss: 2.0278688835841354

Epoch: 6| Step: 8
Training loss: 2.2114057540893555
Validation loss: 2.009684108918713

Epoch: 6| Step: 9
Training loss: 2.2043542861938477
Validation loss: 2.0170307338878675

Epoch: 6| Step: 10
Training loss: 1.327746033668518
Validation loss: 2.0379804257423646

Epoch: 6| Step: 11
Training loss: 1.4461426734924316
Validation loss: 2.048865992535827

Epoch: 6| Step: 12
Training loss: 1.9157021045684814
Validation loss: 2.0671556201032413

Epoch: 6| Step: 13
Training loss: 1.960223913192749
Validation loss: 2.1049110171615437

Epoch: 403| Step: 0
Training loss: 2.1708903312683105
Validation loss: 2.1258714096520537

Epoch: 6| Step: 1
Training loss: 1.7516731023788452
Validation loss: 2.1522645514498473

Epoch: 6| Step: 2
Training loss: 1.9391745328903198
Validation loss: 2.1315257139103387

Epoch: 6| Step: 3
Training loss: 1.3911559581756592
Validation loss: 2.113564691235942

Epoch: 6| Step: 4
Training loss: 1.574045181274414
Validation loss: 2.0964196792212864

Epoch: 6| Step: 5
Training loss: 1.547714352607727
Validation loss: 2.0686664299298356

Epoch: 6| Step: 6
Training loss: 1.7851606607437134
Validation loss: 2.0561115331547235

Epoch: 6| Step: 7
Training loss: 1.4606472253799438
Validation loss: 2.042563179487823

Epoch: 6| Step: 8
Training loss: 2.3439583778381348
Validation loss: 2.03457167584409

Epoch: 6| Step: 9
Training loss: 2.04591965675354
Validation loss: 2.0271225001222346

Epoch: 6| Step: 10
Training loss: 1.841819167137146
Validation loss: 2.03365219536648

Epoch: 6| Step: 11
Training loss: 1.0471808910369873
Validation loss: 2.0216507924500333

Epoch: 6| Step: 12
Training loss: 1.6924134492874146
Validation loss: 2.0649424124789495

Epoch: 6| Step: 13
Training loss: 1.5876045227050781
Validation loss: 2.061455190822642

Epoch: 404| Step: 0
Training loss: 2.203289031982422
Validation loss: 2.0846025738664853

Epoch: 6| Step: 1
Training loss: 1.485750436782837
Validation loss: 2.108998626791021

Epoch: 6| Step: 2
Training loss: 1.6303431987762451
Validation loss: 2.0925805517422256

Epoch: 6| Step: 3
Training loss: 1.5724635124206543
Validation loss: 2.093345134488998

Epoch: 6| Step: 4
Training loss: 2.41642689704895
Validation loss: 2.0884666250598047

Epoch: 6| Step: 5
Training loss: 1.8064258098602295
Validation loss: 2.0619793079232656

Epoch: 6| Step: 6
Training loss: 2.6736512184143066
Validation loss: 2.050352358048962

Epoch: 6| Step: 7
Training loss: 1.4891538619995117
Validation loss: 2.03772456799784

Epoch: 6| Step: 8
Training loss: 1.705785870552063
Validation loss: 2.0331148127073884

Epoch: 6| Step: 9
Training loss: 0.7538059949874878
Validation loss: 2.0505828088329685

Epoch: 6| Step: 10
Training loss: 1.8447623252868652
Validation loss: 2.069920004055064

Epoch: 6| Step: 11
Training loss: 1.548624038696289
Validation loss: 2.0689147364708687

Epoch: 6| Step: 12
Training loss: 1.371074914932251
Validation loss: 2.0701435894094486

Epoch: 6| Step: 13
Training loss: 1.2231985330581665
Validation loss: 2.095292265697192

Epoch: 405| Step: 0
Training loss: 1.4498720169067383
Validation loss: 2.0850062575391544

Epoch: 6| Step: 1
Training loss: 1.9614505767822266
Validation loss: 2.0482793905401744

Epoch: 6| Step: 2
Training loss: 1.4187006950378418
Validation loss: 2.0145977799610426

Epoch: 6| Step: 3
Training loss: 1.1863141059875488
Validation loss: 2.0079327860186176

Epoch: 6| Step: 4
Training loss: 1.8726221323013306
Validation loss: 2.0244885490786646

Epoch: 6| Step: 5
Training loss: 1.717264175415039
Validation loss: 2.0267387333736626

Epoch: 6| Step: 6
Training loss: 1.5499520301818848
Validation loss: 2.0476708988989554

Epoch: 6| Step: 7
Training loss: 1.769156813621521
Validation loss: 2.0509396842730943

Epoch: 6| Step: 8
Training loss: 1.5517572164535522
Validation loss: 2.0571512355599353

Epoch: 6| Step: 9
Training loss: 1.7903467416763306
Validation loss: 2.0670350469568723

Epoch: 6| Step: 10
Training loss: 1.7388591766357422
Validation loss: 2.0990467686806955

Epoch: 6| Step: 11
Training loss: 2.627577781677246
Validation loss: 2.1461256011839835

Epoch: 6| Step: 12
Training loss: 1.6989771127700806
Validation loss: 2.100031373321369

Epoch: 6| Step: 13
Training loss: 1.3053141832351685
Validation loss: 2.081813399509717

Epoch: 406| Step: 0
Training loss: 2.3918309211730957
Validation loss: 2.057366765955443

Epoch: 6| Step: 1
Training loss: 1.966378927230835
Validation loss: 2.022779110939272

Epoch: 6| Step: 2
Training loss: 1.4753692150115967
Validation loss: 2.0247959526636268

Epoch: 6| Step: 3
Training loss: 1.752899408340454
Validation loss: 2.0129821146688154

Epoch: 6| Step: 4
Training loss: 2.41225266456604
Validation loss: 2.0099135393737466

Epoch: 6| Step: 5
Training loss: 1.7208404541015625
Validation loss: 2.0048710274439987

Epoch: 6| Step: 6
Training loss: 1.860977053642273
Validation loss: 2.0319669733765306

Epoch: 6| Step: 7
Training loss: 1.4995448589324951
Validation loss: 2.028759010376469

Epoch: 6| Step: 8
Training loss: 2.1607820987701416
Validation loss: 2.059758194031254

Epoch: 6| Step: 9
Training loss: 1.6588001251220703
Validation loss: 2.0869038874103176

Epoch: 6| Step: 10
Training loss: 1.739707350730896
Validation loss: 2.118285071465277

Epoch: 6| Step: 11
Training loss: 1.1154804229736328
Validation loss: 2.1184152839004353

Epoch: 6| Step: 12
Training loss: 1.0573852062225342
Validation loss: 2.101387398217314

Epoch: 6| Step: 13
Training loss: 0.8979825973510742
Validation loss: 2.080353754822926

Epoch: 407| Step: 0
Training loss: 1.886762022972107
Validation loss: 2.0553118605767526

Epoch: 6| Step: 1
Training loss: 1.1723759174346924
Validation loss: 2.0587937524241786

Epoch: 6| Step: 2
Training loss: 1.535660982131958
Validation loss: 2.030477172584944

Epoch: 6| Step: 3
Training loss: 1.2718015909194946
Validation loss: 2.0224062781180105

Epoch: 6| Step: 4
Training loss: 2.3735408782958984
Validation loss: 2.0198241356880433

Epoch: 6| Step: 5
Training loss: 1.4806714057922363
Validation loss: 2.023891915557205

Epoch: 6| Step: 6
Training loss: 1.5944669246673584
Validation loss: 2.0186898477615847

Epoch: 6| Step: 7
Training loss: 1.9460012912750244
Validation loss: 2.019930278101275

Epoch: 6| Step: 8
Training loss: 2.2977333068847656
Validation loss: 2.0246135470687703

Epoch: 6| Step: 9
Training loss: 1.3176695108413696
Validation loss: 2.042255264456554

Epoch: 6| Step: 10
Training loss: 1.618704080581665
Validation loss: 2.058228741409958

Epoch: 6| Step: 11
Training loss: 1.5224287509918213
Validation loss: 2.1055704906422603

Epoch: 6| Step: 12
Training loss: 2.1101369857788086
Validation loss: 2.159563067138836

Epoch: 6| Step: 13
Training loss: 1.8639861345291138
Validation loss: 2.1646907355195735

Epoch: 408| Step: 0
Training loss: 2.1536922454833984
Validation loss: 2.1446672767721195

Epoch: 6| Step: 1
Training loss: 1.3472760915756226
Validation loss: 2.1157063720046834

Epoch: 6| Step: 2
Training loss: 1.4433622360229492
Validation loss: 2.1039613036699194

Epoch: 6| Step: 3
Training loss: 1.6784250736236572
Validation loss: 2.090362289900421

Epoch: 6| Step: 4
Training loss: 1.0259227752685547
Validation loss: 2.081094813603227

Epoch: 6| Step: 5
Training loss: 2.206605911254883
Validation loss: 2.0613833935030046

Epoch: 6| Step: 6
Training loss: 2.1353094577789307
Validation loss: 2.0660697978029967

Epoch: 6| Step: 7
Training loss: 1.7535374164581299
Validation loss: 2.083791648187945

Epoch: 6| Step: 8
Training loss: 1.2188888788223267
Validation loss: 2.0620715771951983

Epoch: 6| Step: 9
Training loss: 2.050792694091797
Validation loss: 2.053464181961552

Epoch: 6| Step: 10
Training loss: 1.675573706626892
Validation loss: 2.021403080673628

Epoch: 6| Step: 11
Training loss: 1.7943991422653198
Validation loss: 2.0122671011955506

Epoch: 6| Step: 12
Training loss: 2.035097599029541
Validation loss: 2.0152700383176088

Epoch: 6| Step: 13
Training loss: 1.1649267673492432
Validation loss: 2.0219566950234036

Epoch: 409| Step: 0
Training loss: 2.0070762634277344
Validation loss: 2.028034052541179

Epoch: 6| Step: 1
Training loss: 1.5744495391845703
Validation loss: 2.0277059808854134

Epoch: 6| Step: 2
Training loss: 1.1782865524291992
Validation loss: 2.057051068993025

Epoch: 6| Step: 3
Training loss: 2.3662238121032715
Validation loss: 2.0649283419373217

Epoch: 6| Step: 4
Training loss: 1.6534099578857422
Validation loss: 2.0616682729413434

Epoch: 6| Step: 5
Training loss: 1.7379319667816162
Validation loss: 2.077955477981157

Epoch: 6| Step: 6
Training loss: 1.944352626800537
Validation loss: 2.0776353023385488

Epoch: 6| Step: 7
Training loss: 2.0625762939453125
Validation loss: 2.0774311301528767

Epoch: 6| Step: 8
Training loss: 1.353463888168335
Validation loss: 2.063094239081106

Epoch: 6| Step: 9
Training loss: 1.0009737014770508
Validation loss: 2.0572850499101865

Epoch: 6| Step: 10
Training loss: 1.128088355064392
Validation loss: 2.0593848971910376

Epoch: 6| Step: 11
Training loss: 1.8706028461456299
Validation loss: 2.0392005623027845

Epoch: 6| Step: 12
Training loss: 1.9672343730926514
Validation loss: 2.0168676017433085

Epoch: 6| Step: 13
Training loss: 1.8860394954681396
Validation loss: 2.0204985154572355

Epoch: 410| Step: 0
Training loss: 1.9935474395751953
Validation loss: 1.9991812500902402

Epoch: 6| Step: 1
Training loss: 1.2307689189910889
Validation loss: 2.015712402200186

Epoch: 6| Step: 2
Training loss: 1.5367865562438965
Validation loss: 2.0088152577800136

Epoch: 6| Step: 3
Training loss: 1.6676928997039795
Validation loss: 2.0321526245404313

Epoch: 6| Step: 4
Training loss: 2.030979871749878
Validation loss: 2.042870867636896

Epoch: 6| Step: 5
Training loss: 1.4383454322814941
Validation loss: 2.027361228901853

Epoch: 6| Step: 6
Training loss: 1.2145826816558838
Validation loss: 2.057187126528832

Epoch: 6| Step: 7
Training loss: 1.8115973472595215
Validation loss: 2.063977576071216

Epoch: 6| Step: 8
Training loss: 2.473980188369751
Validation loss: 2.0912346224631033

Epoch: 6| Step: 9
Training loss: 1.522160291671753
Validation loss: 2.057135412769933

Epoch: 6| Step: 10
Training loss: 1.3466038703918457
Validation loss: 2.057397336088201

Epoch: 6| Step: 11
Training loss: 1.3004437685012817
Validation loss: 2.08197243367472

Epoch: 6| Step: 12
Training loss: 1.7776682376861572
Validation loss: 2.04843754794008

Epoch: 6| Step: 13
Training loss: 2.4122695922851562
Validation loss: 2.08762522410321

Epoch: 411| Step: 0
Training loss: 1.5423252582550049
Validation loss: 2.068922160774149

Epoch: 6| Step: 1
Training loss: 1.7278599739074707
Validation loss: 2.0471200737901913

Epoch: 6| Step: 2
Training loss: 1.173764944076538
Validation loss: 2.0569382226595314

Epoch: 6| Step: 3
Training loss: 2.0135746002197266
Validation loss: 2.0602705376122588

Epoch: 6| Step: 4
Training loss: 0.790626585483551
Validation loss: 2.08073531299509

Epoch: 6| Step: 5
Training loss: 1.7007588148117065
Validation loss: 2.0949127469011533

Epoch: 6| Step: 6
Training loss: 1.723620891571045
Validation loss: 2.080604373767812

Epoch: 6| Step: 7
Training loss: 2.2333996295928955
Validation loss: 2.057296778566094

Epoch: 6| Step: 8
Training loss: 1.6756091117858887
Validation loss: 2.0673160270978044

Epoch: 6| Step: 9
Training loss: 1.5711922645568848
Validation loss: 2.0161709708552205

Epoch: 6| Step: 10
Training loss: 1.7751964330673218
Validation loss: 2.0286948962878157

Epoch: 6| Step: 11
Training loss: 2.1343774795532227
Validation loss: 2.010228072443316

Epoch: 6| Step: 12
Training loss: 1.4090337753295898
Validation loss: 1.996011769899758

Epoch: 6| Step: 13
Training loss: 1.9952703714370728
Validation loss: 2.013583414016231

Epoch: 412| Step: 0
Training loss: 1.4707776308059692
Validation loss: 2.005541979625661

Epoch: 6| Step: 1
Training loss: 1.8603110313415527
Validation loss: 1.997460675495927

Epoch: 6| Step: 2
Training loss: 1.6923251152038574
Validation loss: 2.00117596503227

Epoch: 6| Step: 3
Training loss: 1.2022602558135986
Validation loss: 2.052510917827647

Epoch: 6| Step: 4
Training loss: 1.4871264696121216
Validation loss: 2.0831948300843597

Epoch: 6| Step: 5
Training loss: 1.5261175632476807
Validation loss: 2.0786890009398102

Epoch: 6| Step: 6
Training loss: 1.3962039947509766
Validation loss: 2.104040035637476

Epoch: 6| Step: 7
Training loss: 1.225957989692688
Validation loss: 2.1212417899921374

Epoch: 6| Step: 8
Training loss: 1.6396872997283936
Validation loss: 2.143503850506198

Epoch: 6| Step: 9
Training loss: 2.7386374473571777
Validation loss: 2.126006946768812

Epoch: 6| Step: 10
Training loss: 2.3132476806640625
Validation loss: 2.1051525710731425

Epoch: 6| Step: 11
Training loss: 1.6520483493804932
Validation loss: 2.046934550808322

Epoch: 6| Step: 12
Training loss: 2.075934648513794
Validation loss: 2.031687754456715

Epoch: 6| Step: 13
Training loss: 1.2180027961730957
Validation loss: 1.999664475840907

Epoch: 413| Step: 0
Training loss: 1.418236494064331
Validation loss: 1.9616420807376984

Epoch: 6| Step: 1
Training loss: 1.9705504179000854
Validation loss: 1.97209257207891

Epoch: 6| Step: 2
Training loss: 1.5205128192901611
Validation loss: 1.9709797822019106

Epoch: 6| Step: 3
Training loss: 1.6833124160766602
Validation loss: 1.96513537181321

Epoch: 6| Step: 4
Training loss: 1.5061510801315308
Validation loss: 1.9707853255733367

Epoch: 6| Step: 5
Training loss: 2.1658506393432617
Validation loss: 1.9735011221260153

Epoch: 6| Step: 6
Training loss: 1.5669679641723633
Validation loss: 2.008910902084843

Epoch: 6| Step: 7
Training loss: 1.4468308687210083
Validation loss: 2.0438662036772697

Epoch: 6| Step: 8
Training loss: 1.8011592626571655
Validation loss: 2.1054854008459274

Epoch: 6| Step: 9
Training loss: 1.6020281314849854
Validation loss: 2.1380232790464997

Epoch: 6| Step: 10
Training loss: 2.117647171020508
Validation loss: 2.1974511018363376

Epoch: 6| Step: 11
Training loss: 2.495663642883301
Validation loss: 2.2190986858901156

Epoch: 6| Step: 12
Training loss: 1.5985310077667236
Validation loss: 2.2299029275935185

Epoch: 6| Step: 13
Training loss: 1.3791300058364868
Validation loss: 2.206198146266322

Epoch: 414| Step: 0
Training loss: 1.464654803276062
Validation loss: 2.124704860871838

Epoch: 6| Step: 1
Training loss: 2.0627188682556152
Validation loss: 2.0834881169821626

Epoch: 6| Step: 2
Training loss: 1.5195205211639404
Validation loss: 2.0515572614567255

Epoch: 6| Step: 3
Training loss: 2.482074737548828
Validation loss: 2.026272899361067

Epoch: 6| Step: 4
Training loss: 1.2306960821151733
Validation loss: 1.9920329419515466

Epoch: 6| Step: 5
Training loss: 1.609321117401123
Validation loss: 1.9980153422201834

Epoch: 6| Step: 6
Training loss: 1.1671357154846191
Validation loss: 2.0161432643090524

Epoch: 6| Step: 7
Training loss: 2.087120294570923
Validation loss: 2.0057242621657667

Epoch: 6| Step: 8
Training loss: 0.9952055811882019
Validation loss: 2.014205568580217

Epoch: 6| Step: 9
Training loss: 2.104437828063965
Validation loss: 2.0353101838019585

Epoch: 6| Step: 10
Training loss: 2.2244338989257812
Validation loss: 2.05009602731274

Epoch: 6| Step: 11
Training loss: 1.542790174484253
Validation loss: 2.0794456005096436

Epoch: 6| Step: 12
Training loss: 1.3980891704559326
Validation loss: 2.078171173731486

Epoch: 6| Step: 13
Training loss: 1.4701323509216309
Validation loss: 2.110323803399199

Epoch: 415| Step: 0
Training loss: 2.224015235900879
Validation loss: 2.1243635531394713

Epoch: 6| Step: 1
Training loss: 2.325406312942505
Validation loss: 2.148298332768102

Epoch: 6| Step: 2
Training loss: 1.223287582397461
Validation loss: 2.1424952322436916

Epoch: 6| Step: 3
Training loss: 1.8321502208709717
Validation loss: 2.139446145744734

Epoch: 6| Step: 4
Training loss: 1.6241798400878906
Validation loss: 2.098682961156291

Epoch: 6| Step: 5
Training loss: 0.8962337970733643
Validation loss: 2.0699959083270003

Epoch: 6| Step: 6
Training loss: 1.6471115350723267
Validation loss: 2.0557792878920034

Epoch: 6| Step: 7
Training loss: 1.5465214252471924
Validation loss: 2.0368165969848633

Epoch: 6| Step: 8
Training loss: 1.7087275981903076
Validation loss: 2.00361374116713

Epoch: 6| Step: 9
Training loss: 1.6437647342681885
Validation loss: 1.993243073904386

Epoch: 6| Step: 10
Training loss: 1.759918212890625
Validation loss: 1.9969884323817428

Epoch: 6| Step: 11
Training loss: 2.1422119140625
Validation loss: 2.0072503910269788

Epoch: 6| Step: 12
Training loss: 1.5410269498825073
Validation loss: 2.052179659566572

Epoch: 6| Step: 13
Training loss: 1.3568118810653687
Validation loss: 2.091205830215126

Epoch: 416| Step: 0
Training loss: 1.744673252105713
Validation loss: 2.1462612280281643

Epoch: 6| Step: 1
Training loss: 1.4409728050231934
Validation loss: 2.188417398801414

Epoch: 6| Step: 2
Training loss: 1.4705588817596436
Validation loss: 2.2015075299047653

Epoch: 6| Step: 3
Training loss: 1.3276710510253906
Validation loss: 2.1768419076037664

Epoch: 6| Step: 4
Training loss: 1.1419167518615723
Validation loss: 2.1382938174791235

Epoch: 6| Step: 5
Training loss: 1.5937774181365967
Validation loss: 2.091167393551078

Epoch: 6| Step: 6
Training loss: 1.6999096870422363
Validation loss: 2.091813479700396

Epoch: 6| Step: 7
Training loss: 2.2045376300811768
Validation loss: 2.0459600930572837

Epoch: 6| Step: 8
Training loss: 1.6829102039337158
Validation loss: 2.031055651685243

Epoch: 6| Step: 9
Training loss: 2.0930042266845703
Validation loss: 2.0026097887305805

Epoch: 6| Step: 10
Training loss: 1.7721377611160278
Validation loss: 2.02747634918459

Epoch: 6| Step: 11
Training loss: 1.7814228534698486
Validation loss: 2.028231741279684

Epoch: 6| Step: 12
Training loss: 1.9100205898284912
Validation loss: 2.0212168975542952

Epoch: 6| Step: 13
Training loss: 1.8258579969406128
Validation loss: 2.0098099400920253

Epoch: 417| Step: 0
Training loss: 2.1810190677642822
Validation loss: 2.01166691318635

Epoch: 6| Step: 1
Training loss: 1.879857063293457
Validation loss: 2.000272244535467

Epoch: 6| Step: 2
Training loss: 1.1262651681900024
Validation loss: 2.058796028937063

Epoch: 6| Step: 3
Training loss: 1.6689825057983398
Validation loss: 2.084775117135817

Epoch: 6| Step: 4
Training loss: 1.220745325088501
Validation loss: 2.1206800681288525

Epoch: 6| Step: 5
Training loss: 1.3233885765075684
Validation loss: 2.1394688813917098

Epoch: 6| Step: 6
Training loss: 1.386582374572754
Validation loss: 2.127690394719442

Epoch: 6| Step: 7
Training loss: 1.8978502750396729
Validation loss: 2.1223017041401198

Epoch: 6| Step: 8
Training loss: 1.6035823822021484
Validation loss: 2.0669478319024526

Epoch: 6| Step: 9
Training loss: 2.2351462841033936
Validation loss: 2.0154693280496905

Epoch: 6| Step: 10
Training loss: 1.8218668699264526
Validation loss: 1.9960358963217786

Epoch: 6| Step: 11
Training loss: 1.569074273109436
Validation loss: 2.00346367589889

Epoch: 6| Step: 12
Training loss: 1.8881735801696777
Validation loss: 1.9840222238212504

Epoch: 6| Step: 13
Training loss: 1.6289288997650146
Validation loss: 1.9664493273663264

Epoch: 418| Step: 0
Training loss: 1.6365453004837036
Validation loss: 1.9942185160934285

Epoch: 6| Step: 1
Training loss: 2.1152591705322266
Validation loss: 1.9829398124448714

Epoch: 6| Step: 2
Training loss: 2.325298309326172
Validation loss: 2.0012786157669558

Epoch: 6| Step: 3
Training loss: 1.1004042625427246
Validation loss: 2.000849667415824

Epoch: 6| Step: 4
Training loss: 1.4533575773239136
Validation loss: 1.9990569904286375

Epoch: 6| Step: 5
Training loss: 1.7869354486465454
Validation loss: 1.9836370278430242

Epoch: 6| Step: 6
Training loss: 1.357924222946167
Validation loss: 1.9889313354287097

Epoch: 6| Step: 7
Training loss: 1.3719404935836792
Validation loss: 2.0154769138623307

Epoch: 6| Step: 8
Training loss: 1.6281836032867432
Validation loss: 2.0334466785512944

Epoch: 6| Step: 9
Training loss: 1.7020301818847656
Validation loss: 2.0659377177556357

Epoch: 6| Step: 10
Training loss: 1.735973834991455
Validation loss: 2.124553276646522

Epoch: 6| Step: 11
Training loss: 1.4293583631515503
Validation loss: 2.151245235114969

Epoch: 6| Step: 12
Training loss: 1.1579835414886475
Validation loss: 2.1960570658406904

Epoch: 6| Step: 13
Training loss: 3.027599334716797
Validation loss: 2.2067696561095533

Epoch: 419| Step: 0
Training loss: 1.6841297149658203
Validation loss: 2.172106860786356

Epoch: 6| Step: 1
Training loss: 1.6149091720581055
Validation loss: 2.1278602359115437

Epoch: 6| Step: 2
Training loss: 1.481729507446289
Validation loss: 2.1109025273271786

Epoch: 6| Step: 3
Training loss: 1.5271002054214478
Validation loss: 2.05914282542403

Epoch: 6| Step: 4
Training loss: 1.7402358055114746
Validation loss: 2.03068527354989

Epoch: 6| Step: 5
Training loss: 2.6617331504821777
Validation loss: 2.0354601901064635

Epoch: 6| Step: 6
Training loss: 1.5633659362792969
Validation loss: 1.9890116812080465

Epoch: 6| Step: 7
Training loss: 1.8079404830932617
Validation loss: 2.0258128335399013

Epoch: 6| Step: 8
Training loss: 1.246145486831665
Validation loss: 2.0132690488651233

Epoch: 6| Step: 9
Training loss: 1.469799518585205
Validation loss: 1.9913221738671745

Epoch: 6| Step: 10
Training loss: 2.0247983932495117
Validation loss: 2.042011514786751

Epoch: 6| Step: 11
Training loss: 1.844618558883667
Validation loss: 2.0643256684785247

Epoch: 6| Step: 12
Training loss: 0.9815322756767273
Validation loss: 2.054089461603472

Epoch: 6| Step: 13
Training loss: 1.03812575340271
Validation loss: 2.117533006975728

Epoch: 420| Step: 0
Training loss: 1.5235354900360107
Validation loss: 2.1102878970484578

Epoch: 6| Step: 1
Training loss: 1.3279972076416016
Validation loss: 2.0944387553840556

Epoch: 6| Step: 2
Training loss: 1.5595706701278687
Validation loss: 2.0987687213446504

Epoch: 6| Step: 3
Training loss: 1.353135108947754
Validation loss: 2.075338778957244

Epoch: 6| Step: 4
Training loss: 2.4848811626434326
Validation loss: 2.0461647536164973

Epoch: 6| Step: 5
Training loss: 1.7972313165664673
Validation loss: 2.03780060942455

Epoch: 6| Step: 6
Training loss: 1.6530169248580933
Validation loss: 2.0318569073113064

Epoch: 6| Step: 7
Training loss: 1.113520860671997
Validation loss: 2.039257918634722

Epoch: 6| Step: 8
Training loss: 1.5633838176727295
Validation loss: 2.0431878861560615

Epoch: 6| Step: 9
Training loss: 1.4495877027511597
Validation loss: 2.0734187249214417

Epoch: 6| Step: 10
Training loss: 1.5648233890533447
Validation loss: 2.068314980435115

Epoch: 6| Step: 11
Training loss: 1.700642704963684
Validation loss: 2.0509587385321177

Epoch: 6| Step: 12
Training loss: 1.9000166654586792
Validation loss: 2.0514621990983204

Epoch: 6| Step: 13
Training loss: 1.7235853672027588
Validation loss: 2.033583685915957

Epoch: 421| Step: 0
Training loss: 1.5287764072418213
Validation loss: 2.042458349658597

Epoch: 6| Step: 1
Training loss: 1.3828976154327393
Validation loss: 2.052976139130131

Epoch: 6| Step: 2
Training loss: 1.8622719049453735
Validation loss: 2.0393216686864055

Epoch: 6| Step: 3
Training loss: 2.2386701107025146
Validation loss: 2.029846687470713

Epoch: 6| Step: 4
Training loss: 1.5601623058319092
Validation loss: 2.0354463259379068

Epoch: 6| Step: 5
Training loss: 1.055080771446228
Validation loss: 2.0255807112622004

Epoch: 6| Step: 6
Training loss: 1.4015480279922485
Validation loss: 2.0062240631349626

Epoch: 6| Step: 7
Training loss: 2.165297746658325
Validation loss: 2.018463783366706

Epoch: 6| Step: 8
Training loss: 2.1209218502044678
Validation loss: 2.0308710195684947

Epoch: 6| Step: 9
Training loss: 1.6324976682662964
Validation loss: 2.0836827601155927

Epoch: 6| Step: 10
Training loss: 2.0341458320617676
Validation loss: 2.0929541369920135

Epoch: 6| Step: 11
Training loss: 1.052600622177124
Validation loss: 2.1108110309928976

Epoch: 6| Step: 12
Training loss: 1.0801197290420532
Validation loss: 2.0885976463235836

Epoch: 6| Step: 13
Training loss: 1.5563501119613647
Validation loss: 2.0687269472306773

Epoch: 422| Step: 0
Training loss: 1.1646554470062256
Validation loss: 2.054408152898153

Epoch: 6| Step: 1
Training loss: 1.3453567028045654
Validation loss: 2.0448394206262406

Epoch: 6| Step: 2
Training loss: 2.2278530597686768
Validation loss: 2.0644435062203357

Epoch: 6| Step: 3
Training loss: 1.4663589000701904
Validation loss: 2.06138958725878

Epoch: 6| Step: 4
Training loss: 2.108051300048828
Validation loss: 2.0453697968554754

Epoch: 6| Step: 5
Training loss: 1.7327791452407837
Validation loss: 2.0405884122335785

Epoch: 6| Step: 6
Training loss: 1.5848004817962646
Validation loss: 2.016439571175524

Epoch: 6| Step: 7
Training loss: 1.6398621797561646
Validation loss: 2.0132252195829987

Epoch: 6| Step: 8
Training loss: 2.2001543045043945
Validation loss: 2.0024729339025353

Epoch: 6| Step: 9
Training loss: 1.195923089981079
Validation loss: 1.9960865820607832

Epoch: 6| Step: 10
Training loss: 2.0148167610168457
Validation loss: 1.9842972370886034

Epoch: 6| Step: 11
Training loss: 1.621002435684204
Validation loss: 2.0071280822958997

Epoch: 6| Step: 12
Training loss: 1.0442938804626465
Validation loss: 2.009144729183566

Epoch: 6| Step: 13
Training loss: 1.0476021766662598
Validation loss: 2.0094052386540238

Epoch: 423| Step: 0
Training loss: 1.504262089729309
Validation loss: 2.022293493311892

Epoch: 6| Step: 1
Training loss: 1.9725708961486816
Validation loss: 2.030500768333353

Epoch: 6| Step: 2
Training loss: 1.3718103170394897
Validation loss: 2.0552250954412643

Epoch: 6| Step: 3
Training loss: 1.476249098777771
Validation loss: 2.0890964231183453

Epoch: 6| Step: 4
Training loss: 1.1859880685806274
Validation loss: 2.107844593704388

Epoch: 6| Step: 5
Training loss: 1.6883364915847778
Validation loss: 2.1008035726444696

Epoch: 6| Step: 6
Training loss: 1.680307388305664
Validation loss: 2.093469094204646

Epoch: 6| Step: 7
Training loss: 1.6550147533416748
Validation loss: 2.064473895616429

Epoch: 6| Step: 8
Training loss: 1.2738065719604492
Validation loss: 2.0541405254794705

Epoch: 6| Step: 9
Training loss: 2.173686981201172
Validation loss: 2.025843962546318

Epoch: 6| Step: 10
Training loss: 1.8888399600982666
Validation loss: 2.032331725602509

Epoch: 6| Step: 11
Training loss: 1.834329605102539
Validation loss: 1.9935154927674161

Epoch: 6| Step: 12
Training loss: 1.103278636932373
Validation loss: 2.0092055592485654

Epoch: 6| Step: 13
Training loss: 2.1914429664611816
Validation loss: 2.009710286253242

Epoch: 424| Step: 0
Training loss: 1.8019280433654785
Validation loss: 1.9822635496816328

Epoch: 6| Step: 1
Training loss: 1.5983059406280518
Validation loss: 2.0057646894967682

Epoch: 6| Step: 2
Training loss: 1.6728129386901855
Validation loss: 2.0097354009587276

Epoch: 6| Step: 3
Training loss: 1.6874291896820068
Validation loss: 2.020742767600603

Epoch: 6| Step: 4
Training loss: 1.1799672842025757
Validation loss: 2.036509531800465

Epoch: 6| Step: 5
Training loss: 2.307223320007324
Validation loss: 2.044972468447942

Epoch: 6| Step: 6
Training loss: 1.237426996231079
Validation loss: 2.0882238918735134

Epoch: 6| Step: 7
Training loss: 1.9839468002319336
Validation loss: 2.0650088774260653

Epoch: 6| Step: 8
Training loss: 2.1876368522644043
Validation loss: 2.077900917299332

Epoch: 6| Step: 9
Training loss: 1.3692541122436523
Validation loss: 2.0469664245523433

Epoch: 6| Step: 10
Training loss: 1.2545061111450195
Validation loss: 2.0272158576596166

Epoch: 6| Step: 11
Training loss: 1.717932105064392
Validation loss: 2.0140112702564528

Epoch: 6| Step: 12
Training loss: 1.326239824295044
Validation loss: 2.003025965024066

Epoch: 6| Step: 13
Training loss: 1.2440199851989746
Validation loss: 2.0071658524133826

Epoch: 425| Step: 0
Training loss: 2.401902198791504
Validation loss: 2.0239195054577244

Epoch: 6| Step: 1
Training loss: 1.6432911157608032
Validation loss: 2.0240385865652435

Epoch: 6| Step: 2
Training loss: 1.2619097232818604
Validation loss: 2.0406810416970202

Epoch: 6| Step: 3
Training loss: 2.0563130378723145
Validation loss: 2.0306804231418076

Epoch: 6| Step: 4
Training loss: 0.840208113193512
Validation loss: 2.09106788199435

Epoch: 6| Step: 5
Training loss: 1.9255789518356323
Validation loss: 2.091194821942237

Epoch: 6| Step: 6
Training loss: 1.6948027610778809
Validation loss: 2.1258132278278308

Epoch: 6| Step: 7
Training loss: 1.3604018688201904
Validation loss: 2.1070641292038785

Epoch: 6| Step: 8
Training loss: 1.589130163192749
Validation loss: 2.125782849968121

Epoch: 6| Step: 9
Training loss: 1.7714674472808838
Validation loss: 2.1071051320722027

Epoch: 6| Step: 10
Training loss: 1.50022292137146
Validation loss: 2.076620896657308

Epoch: 6| Step: 11
Training loss: 1.3371596336364746
Validation loss: 2.05095007342677

Epoch: 6| Step: 12
Training loss: 1.4023935794830322
Validation loss: 2.0426802250646774

Epoch: 6| Step: 13
Training loss: 1.6314610242843628
Validation loss: 2.0451036960847917

Epoch: 426| Step: 0
Training loss: 2.190887451171875
Validation loss: 2.035642546992148

Epoch: 6| Step: 1
Training loss: 1.1544101238250732
Validation loss: 2.027525004520211

Epoch: 6| Step: 2
Training loss: 1.1700167655944824
Validation loss: 2.033425672079927

Epoch: 6| Step: 3
Training loss: 1.8517024517059326
Validation loss: 2.0590258875200824

Epoch: 6| Step: 4
Training loss: 1.5410465002059937
Validation loss: 2.0434156797265493

Epoch: 6| Step: 5
Training loss: 1.7171928882598877
Validation loss: 2.0514302817724084

Epoch: 6| Step: 6
Training loss: 1.8513542413711548
Validation loss: 2.0813248772774973

Epoch: 6| Step: 7
Training loss: 2.0766148567199707
Validation loss: 2.084684964149229

Epoch: 6| Step: 8
Training loss: 1.1490662097930908
Validation loss: 2.0771111211469098

Epoch: 6| Step: 9
Training loss: 1.703425645828247
Validation loss: 2.0912460075911654

Epoch: 6| Step: 10
Training loss: 2.005906105041504
Validation loss: 2.0831726238291752

Epoch: 6| Step: 11
Training loss: 1.4035605192184448
Validation loss: 2.0702707408576884

Epoch: 6| Step: 12
Training loss: 1.0186394453048706
Validation loss: 2.0580350070871334

Epoch: 6| Step: 13
Training loss: 1.7336032390594482
Validation loss: 2.056097063966977

Epoch: 427| Step: 0
Training loss: 1.373610496520996
Validation loss: 2.046983439435241

Epoch: 6| Step: 1
Training loss: 1.0733861923217773
Validation loss: 2.0421578025305145

Epoch: 6| Step: 2
Training loss: 1.9322446584701538
Validation loss: 2.0581878667236655

Epoch: 6| Step: 3
Training loss: 1.4776002168655396
Validation loss: 2.0945807016024025

Epoch: 6| Step: 4
Training loss: 2.2505042552948
Validation loss: 2.110521065291538

Epoch: 6| Step: 5
Training loss: 2.2470388412475586
Validation loss: 2.112136294764857

Epoch: 6| Step: 6
Training loss: 1.4740209579467773
Validation loss: 2.092156030798471

Epoch: 6| Step: 7
Training loss: 1.5620685815811157
Validation loss: 2.090276974503712

Epoch: 6| Step: 8
Training loss: 1.9382587671279907
Validation loss: 2.040054141834218

Epoch: 6| Step: 9
Training loss: 1.2966086864471436
Validation loss: 1.9983971029199579

Epoch: 6| Step: 10
Training loss: 1.7615476846694946
Validation loss: 1.9853048862949494

Epoch: 6| Step: 11
Training loss: 1.2325440645217896
Validation loss: 1.965607989218927

Epoch: 6| Step: 12
Training loss: 1.5885447263717651
Validation loss: 1.9387127020025765

Epoch: 6| Step: 13
Training loss: 1.21602201461792
Validation loss: 1.9432882929360995

Epoch: 428| Step: 0
Training loss: 1.776798129081726
Validation loss: 1.9542665238021522

Epoch: 6| Step: 1
Training loss: 2.0202558040618896
Validation loss: 1.993965401444384

Epoch: 6| Step: 2
Training loss: 1.895142912864685
Validation loss: 2.037148678174583

Epoch: 6| Step: 3
Training loss: 1.5522329807281494
Validation loss: 2.0445789675558768

Epoch: 6| Step: 4
Training loss: 1.0017600059509277
Validation loss: 2.05557426329582

Epoch: 6| Step: 5
Training loss: 1.0365763902664185
Validation loss: 2.0535121579324045

Epoch: 6| Step: 6
Training loss: 1.9710890054702759
Validation loss: 2.045661449432373

Epoch: 6| Step: 7
Training loss: 1.9110379219055176
Validation loss: 2.053957931457027

Epoch: 6| Step: 8
Training loss: 1.2174582481384277
Validation loss: 2.0421411991119385

Epoch: 6| Step: 9
Training loss: 1.6124416589736938
Validation loss: 2.0483016070499214

Epoch: 6| Step: 10
Training loss: 1.6759440898895264
Validation loss: 2.0395371042272097

Epoch: 6| Step: 11
Training loss: 1.9222636222839355
Validation loss: 2.016424294440977

Epoch: 6| Step: 12
Training loss: 1.4384770393371582
Validation loss: 2.0132306903921147

Epoch: 6| Step: 13
Training loss: 1.1323994398117065
Validation loss: 2.005317877697688

Epoch: 429| Step: 0
Training loss: 1.6394331455230713
Validation loss: 2.0355383939640497

Epoch: 6| Step: 1
Training loss: 1.3405132293701172
Validation loss: 2.025704574841325

Epoch: 6| Step: 2
Training loss: 1.7598817348480225
Validation loss: 2.0160418287400277

Epoch: 6| Step: 3
Training loss: 1.5831482410430908
Validation loss: 2.010387010471795

Epoch: 6| Step: 4
Training loss: 1.3957819938659668
Validation loss: 1.9977986594682098

Epoch: 6| Step: 5
Training loss: 1.6973243951797485
Validation loss: 2.0054399454465477

Epoch: 6| Step: 6
Training loss: 1.429577112197876
Validation loss: 2.02681557081079

Epoch: 6| Step: 7
Training loss: 1.2615150213241577
Validation loss: 2.038113383836644

Epoch: 6| Step: 8
Training loss: 1.828645944595337
Validation loss: 2.049958928938835

Epoch: 6| Step: 9
Training loss: 1.8677122592926025
Validation loss: 2.079045937907311

Epoch: 6| Step: 10
Training loss: 1.773862361907959
Validation loss: 2.078104526765885

Epoch: 6| Step: 11
Training loss: 1.7269049882888794
Validation loss: 2.121793918712165

Epoch: 6| Step: 12
Training loss: 1.7860713005065918
Validation loss: 2.134826637083484

Epoch: 6| Step: 13
Training loss: 0.7085213661193848
Validation loss: 2.1211733356598885

Epoch: 430| Step: 0
Training loss: 2.1693692207336426
Validation loss: 2.122642737562938

Epoch: 6| Step: 1
Training loss: 1.3473554849624634
Validation loss: 2.112230977704448

Epoch: 6| Step: 2
Training loss: 1.2893407344818115
Validation loss: 2.1035453491313483

Epoch: 6| Step: 3
Training loss: 1.19308340549469
Validation loss: 2.092760618015002

Epoch: 6| Step: 4
Training loss: 1.8754212856292725
Validation loss: 2.0690553560051868

Epoch: 6| Step: 5
Training loss: 1.5970200300216675
Validation loss: 2.0737169276001635

Epoch: 6| Step: 6
Training loss: 1.9959025382995605
Validation loss: 2.0566413453830186

Epoch: 6| Step: 7
Training loss: 1.1543301343917847
Validation loss: 2.063071195797254

Epoch: 6| Step: 8
Training loss: 1.820320963859558
Validation loss: 2.0188523082322973

Epoch: 6| Step: 9
Training loss: 1.485581874847412
Validation loss: 2.001369648082282

Epoch: 6| Step: 10
Training loss: 1.5619184970855713
Validation loss: 1.9722165740946287

Epoch: 6| Step: 11
Training loss: 1.7632770538330078
Validation loss: 1.9701603125500422

Epoch: 6| Step: 12
Training loss: 1.4653902053833008
Validation loss: 1.945379784030299

Epoch: 6| Step: 13
Training loss: 1.1412197351455688
Validation loss: 1.9558125939420474

Epoch: 431| Step: 0
Training loss: 2.3680286407470703
Validation loss: 1.948023401280885

Epoch: 6| Step: 1
Training loss: 1.0430965423583984
Validation loss: 1.9733777097476426

Epoch: 6| Step: 2
Training loss: 1.8246474266052246
Validation loss: 2.015097943685388

Epoch: 6| Step: 3
Training loss: 2.186429023742676
Validation loss: 2.0231759522550847

Epoch: 6| Step: 4
Training loss: 2.2182257175445557
Validation loss: 2.051151603780767

Epoch: 6| Step: 5
Training loss: 1.2849338054656982
Validation loss: 2.081292627960123

Epoch: 6| Step: 6
Training loss: 1.3220751285552979
Validation loss: 2.107401599166214

Epoch: 6| Step: 7
Training loss: 1.7487192153930664
Validation loss: 2.0832416934351765

Epoch: 6| Step: 8
Training loss: 1.8010828495025635
Validation loss: 2.097120051742882

Epoch: 6| Step: 9
Training loss: 1.1426174640655518
Validation loss: 2.07151452443933

Epoch: 6| Step: 10
Training loss: 1.3211643695831299
Validation loss: 2.077446174877946

Epoch: 6| Step: 11
Training loss: 1.3210217952728271
Validation loss: 2.0412093529137234

Epoch: 6| Step: 12
Training loss: 0.9885698556900024
Validation loss: 2.013203026146017

Epoch: 6| Step: 13
Training loss: 1.608685851097107
Validation loss: 2.002558033953431

Epoch: 432| Step: 0
Training loss: 1.1403015851974487
Validation loss: 1.9594362602438977

Epoch: 6| Step: 1
Training loss: 2.062694549560547
Validation loss: 1.9665033355835946

Epoch: 6| Step: 2
Training loss: 0.9399739503860474
Validation loss: 1.9828116945041123

Epoch: 6| Step: 3
Training loss: 1.1270118951797485
Validation loss: 1.96397384776864

Epoch: 6| Step: 4
Training loss: 2.2186977863311768
Validation loss: 1.9967573483784993

Epoch: 6| Step: 5
Training loss: 1.437273621559143
Validation loss: 2.00106313408062

Epoch: 6| Step: 6
Training loss: 1.346761703491211
Validation loss: 2.0412989380539104

Epoch: 6| Step: 7
Training loss: 1.8223079442977905
Validation loss: 2.049227245392338

Epoch: 6| Step: 8
Training loss: 1.1007674932479858
Validation loss: 2.075228939774216

Epoch: 6| Step: 9
Training loss: 2.011166572570801
Validation loss: 2.1003730527816282

Epoch: 6| Step: 10
Training loss: 1.7386621236801147
Validation loss: 2.078664759153961

Epoch: 6| Step: 11
Training loss: 1.678604006767273
Validation loss: 2.071792729439274

Epoch: 6| Step: 12
Training loss: 1.7947403192520142
Validation loss: 2.0712987017887894

Epoch: 6| Step: 13
Training loss: 1.793365478515625
Validation loss: 2.0509687264760337

Epoch: 433| Step: 0
Training loss: 1.1680811643600464
Validation loss: 2.0678410004544

Epoch: 6| Step: 1
Training loss: 1.661655068397522
Validation loss: 2.057832915295837

Epoch: 6| Step: 2
Training loss: 1.8269355297088623
Validation loss: 2.080849366803323

Epoch: 6| Step: 3
Training loss: 1.7745929956436157
Validation loss: 2.0829639883451563

Epoch: 6| Step: 4
Training loss: 1.5950069427490234
Validation loss: 2.0822976071347474

Epoch: 6| Step: 5
Training loss: 2.366626739501953
Validation loss: 2.0402603995415474

Epoch: 6| Step: 6
Training loss: 1.3220020532608032
Validation loss: 2.042285574379788

Epoch: 6| Step: 7
Training loss: 1.2842988967895508
Validation loss: 2.023525825110815

Epoch: 6| Step: 8
Training loss: 1.5381560325622559
Validation loss: 2.0403614185189687

Epoch: 6| Step: 9
Training loss: 0.9983797669410706
Validation loss: 2.032189784511443

Epoch: 6| Step: 10
Training loss: 1.8192322254180908
Validation loss: 2.056478774675759

Epoch: 6| Step: 11
Training loss: 1.0481352806091309
Validation loss: 2.055799682935079

Epoch: 6| Step: 12
Training loss: 1.661844253540039
Validation loss: 2.0628464632136847

Epoch: 6| Step: 13
Training loss: 1.976136326789856
Validation loss: 2.0470693098601473

Epoch: 434| Step: 0
Training loss: 1.3814613819122314
Validation loss: 2.0422580370339016

Epoch: 6| Step: 1
Training loss: 1.6569087505340576
Validation loss: 2.047633578700404

Epoch: 6| Step: 2
Training loss: 2.2744927406311035
Validation loss: 2.0489785966052803

Epoch: 6| Step: 3
Training loss: 1.5108342170715332
Validation loss: 2.033532145202801

Epoch: 6| Step: 4
Training loss: 1.472705602645874
Validation loss: 2.039696237092377

Epoch: 6| Step: 5
Training loss: 1.3468244075775146
Validation loss: 2.1077873424817155

Epoch: 6| Step: 6
Training loss: 1.48381507396698
Validation loss: 2.1317784760587957

Epoch: 6| Step: 7
Training loss: 1.9398561716079712
Validation loss: 2.0890274381124847

Epoch: 6| Step: 8
Training loss: 1.8661243915557861
Validation loss: 2.06816662896064

Epoch: 6| Step: 9
Training loss: 1.8386207818984985
Validation loss: 2.0588107314161075

Epoch: 6| Step: 10
Training loss: 0.8631794452667236
Validation loss: 2.0396332356237594

Epoch: 6| Step: 11
Training loss: 1.694977045059204
Validation loss: 2.0130104223887124

Epoch: 6| Step: 12
Training loss: 1.042398452758789
Validation loss: 2.0022783125600507

Epoch: 6| Step: 13
Training loss: 1.2692492008209229
Validation loss: 2.0001995871143956

Epoch: 435| Step: 0
Training loss: 1.3203182220458984
Validation loss: 1.989194582867366

Epoch: 6| Step: 1
Training loss: 1.2638334035873413
Validation loss: 2.0245919381418536

Epoch: 6| Step: 2
Training loss: 1.0252668857574463
Validation loss: 2.028633104857578

Epoch: 6| Step: 3
Training loss: 2.0061004161834717
Validation loss: 2.0838083310793807

Epoch: 6| Step: 4
Training loss: 1.7945382595062256
Validation loss: 2.1158454238727527

Epoch: 6| Step: 5
Training loss: 1.949931263923645
Validation loss: 2.1050410578327794

Epoch: 6| Step: 6
Training loss: 2.293117046356201
Validation loss: 2.1152468906935824

Epoch: 6| Step: 7
Training loss: 1.6662023067474365
Validation loss: 2.0848205422842376

Epoch: 6| Step: 8
Training loss: 1.3310792446136475
Validation loss: 2.073459026634052

Epoch: 6| Step: 9
Training loss: 1.454721450805664
Validation loss: 2.0924164761779127

Epoch: 6| Step: 10
Training loss: 1.2023346424102783
Validation loss: 2.077110828891877

Epoch: 6| Step: 11
Training loss: 1.4747157096862793
Validation loss: 2.081109236645442

Epoch: 6| Step: 12
Training loss: 1.1800248622894287
Validation loss: 2.0451841392824726

Epoch: 6| Step: 13
Training loss: 1.7949252128601074
Validation loss: 2.033346403029657

Epoch: 436| Step: 0
Training loss: 2.0968918800354004
Validation loss: 2.0629678592886975

Epoch: 6| Step: 1
Training loss: 1.0787564516067505
Validation loss: 2.047283511007986

Epoch: 6| Step: 2
Training loss: 2.4020988941192627
Validation loss: 2.0715016959815897

Epoch: 6| Step: 3
Training loss: 1.869341254234314
Validation loss: 2.0384878753333964

Epoch: 6| Step: 4
Training loss: 1.3829940557479858
Validation loss: 2.0670180231012325

Epoch: 6| Step: 5
Training loss: 1.595809817314148
Validation loss: 2.0783502671026413

Epoch: 6| Step: 6
Training loss: 1.7942248582839966
Validation loss: 2.086590515669956

Epoch: 6| Step: 7
Training loss: 1.0698211193084717
Validation loss: 2.0417315947112216

Epoch: 6| Step: 8
Training loss: 1.69368577003479
Validation loss: 2.0250550752045005

Epoch: 6| Step: 9
Training loss: 0.8158148527145386
Validation loss: 2.0425940200846684

Epoch: 6| Step: 10
Training loss: 1.745050311088562
Validation loss: 2.0381208337763304

Epoch: 6| Step: 11
Training loss: 1.4141050577163696
Validation loss: 2.022810653973651

Epoch: 6| Step: 12
Training loss: 1.1198705434799194
Validation loss: 2.0221360370677006

Epoch: 6| Step: 13
Training loss: 1.7035952806472778
Validation loss: 2.041401499061174

Epoch: 437| Step: 0
Training loss: 1.8207330703735352
Validation loss: 2.048764410839286

Epoch: 6| Step: 1
Training loss: 1.1533002853393555
Validation loss: 2.012887111274145

Epoch: 6| Step: 2
Training loss: 1.0125439167022705
Validation loss: 2.007680126415786

Epoch: 6| Step: 3
Training loss: 1.4229055643081665
Validation loss: 2.005357201381396

Epoch: 6| Step: 4
Training loss: 1.7463066577911377
Validation loss: 2.0271067362959667

Epoch: 6| Step: 5
Training loss: 1.4615542888641357
Validation loss: 2.028895375549152

Epoch: 6| Step: 6
Training loss: 1.483076572418213
Validation loss: 2.059002205889712

Epoch: 6| Step: 7
Training loss: 1.447130799293518
Validation loss: 2.0457772260071128

Epoch: 6| Step: 8
Training loss: 1.6105718612670898
Validation loss: 2.041769935238746

Epoch: 6| Step: 9
Training loss: 2.346625804901123
Validation loss: 2.0540844881406395

Epoch: 6| Step: 10
Training loss: 1.6398507356643677
Validation loss: 2.0716636385968936

Epoch: 6| Step: 11
Training loss: 1.5479159355163574
Validation loss: 2.063000609797816

Epoch: 6| Step: 12
Training loss: 1.1389743089675903
Validation loss: 2.1151433837029243

Epoch: 6| Step: 13
Training loss: 1.6939061880111694
Validation loss: 2.132717150513844

Epoch: 438| Step: 0
Training loss: 1.110870361328125
Validation loss: 2.149693686475036

Epoch: 6| Step: 1
Training loss: 1.7202949523925781
Validation loss: 2.1174568104487594

Epoch: 6| Step: 2
Training loss: 1.6491672992706299
Validation loss: 2.0710288324663715

Epoch: 6| Step: 3
Training loss: 1.6109356880187988
Validation loss: 2.0601307115247174

Epoch: 6| Step: 4
Training loss: 1.9600589275360107
Validation loss: 1.996168557033744

Epoch: 6| Step: 5
Training loss: 1.6845945119857788
Validation loss: 1.9850628119643017

Epoch: 6| Step: 6
Training loss: 1.8579258918762207
Validation loss: 1.9632489796607726

Epoch: 6| Step: 7
Training loss: 1.4567348957061768
Validation loss: 1.9335664164635442

Epoch: 6| Step: 8
Training loss: 1.3876407146453857
Validation loss: 1.927849461955409

Epoch: 6| Step: 9
Training loss: 1.9847564697265625
Validation loss: 1.9179056562403196

Epoch: 6| Step: 10
Training loss: 1.2771916389465332
Validation loss: 1.938290819045036

Epoch: 6| Step: 11
Training loss: 1.1791073083877563
Validation loss: 1.978764126377721

Epoch: 6| Step: 12
Training loss: 1.7214586734771729
Validation loss: 2.031722452050896

Epoch: 6| Step: 13
Training loss: 1.4592084884643555
Validation loss: 2.0981660504494943

Epoch: 439| Step: 0
Training loss: 1.3166587352752686
Validation loss: 2.1935860546686317

Epoch: 6| Step: 1
Training loss: 1.4140981435775757
Validation loss: 2.224546495304313

Epoch: 6| Step: 2
Training loss: 1.874586582183838
Validation loss: 2.1871158922872236

Epoch: 6| Step: 3
Training loss: 1.855877161026001
Validation loss: 2.163508392149402

Epoch: 6| Step: 4
Training loss: 1.426225185394287
Validation loss: 2.069136119657947

Epoch: 6| Step: 5
Training loss: 1.4458560943603516
Validation loss: 2.017458733691964

Epoch: 6| Step: 6
Training loss: 1.4055719375610352
Validation loss: 1.9931594966560282

Epoch: 6| Step: 7
Training loss: 1.2403379678726196
Validation loss: 1.9781020764381654

Epoch: 6| Step: 8
Training loss: 1.127563714981079
Validation loss: 1.9638618000092045

Epoch: 6| Step: 9
Training loss: 1.9792895317077637
Validation loss: 1.9689902003093431

Epoch: 6| Step: 10
Training loss: 1.7024275064468384
Validation loss: 1.9828277659672562

Epoch: 6| Step: 11
Training loss: 1.6416171789169312
Validation loss: 2.007338713574153

Epoch: 6| Step: 12
Training loss: 1.3187518119812012
Validation loss: 2.0296289433715162

Epoch: 6| Step: 13
Training loss: 3.0277562141418457
Validation loss: 2.0729753791645007

Epoch: 440| Step: 0
Training loss: 1.331016182899475
Validation loss: 2.0520734133258944

Epoch: 6| Step: 1
Training loss: 2.2017300128936768
Validation loss: 2.0837804476420083

Epoch: 6| Step: 2
Training loss: 1.1339256763458252
Validation loss: 2.0825886329015098

Epoch: 6| Step: 3
Training loss: 1.641277551651001
Validation loss: 2.0516205115984847

Epoch: 6| Step: 4
Training loss: 1.6712989807128906
Validation loss: 2.0289481122006654

Epoch: 6| Step: 5
Training loss: 1.4557690620422363
Validation loss: 2.015641978991929

Epoch: 6| Step: 6
Training loss: 1.1675957441329956
Validation loss: 2.0176555597653953

Epoch: 6| Step: 7
Training loss: 2.190739631652832
Validation loss: 2.019910776486961

Epoch: 6| Step: 8
Training loss: 1.4866278171539307
Validation loss: 2.0055842425233577

Epoch: 6| Step: 9
Training loss: 1.170384407043457
Validation loss: 1.9975558378363167

Epoch: 6| Step: 10
Training loss: 1.2963531017303467
Validation loss: 1.9919783376878308

Epoch: 6| Step: 11
Training loss: 1.9571256637573242
Validation loss: 2.015585352015752

Epoch: 6| Step: 12
Training loss: 0.8846365213394165
Validation loss: 1.986240609999626

Epoch: 6| Step: 13
Training loss: 1.8948702812194824
Validation loss: 1.9722397237695672

Epoch: 441| Step: 0
Training loss: 1.4413937330245972
Validation loss: 1.97703637999873

Epoch: 6| Step: 1
Training loss: 0.9788986444473267
Validation loss: 1.9744186952549925

Epoch: 6| Step: 2
Training loss: 0.6647226810455322
Validation loss: 1.9916145647725751

Epoch: 6| Step: 3
Training loss: 1.4282171726226807
Validation loss: 2.0117513261815554

Epoch: 6| Step: 4
Training loss: 1.0802979469299316
Validation loss: 2.056142290433248

Epoch: 6| Step: 5
Training loss: 2.45638370513916
Validation loss: 2.073831137790475

Epoch: 6| Step: 6
Training loss: 1.0834128856658936
Validation loss: 2.1286101853975685

Epoch: 6| Step: 7
Training loss: 1.805755853652954
Validation loss: 2.1567779458979124

Epoch: 6| Step: 8
Training loss: 2.026766061782837
Validation loss: 2.1702279249827066

Epoch: 6| Step: 9
Training loss: 2.119046211242676
Validation loss: 2.188704320179519

Epoch: 6| Step: 10
Training loss: 1.181401014328003
Validation loss: 2.1341699233619114

Epoch: 6| Step: 11
Training loss: 1.8758748769760132
Validation loss: 2.0901692836515364

Epoch: 6| Step: 12
Training loss: 2.055523633956909
Validation loss: 2.037678413493659

Epoch: 6| Step: 13
Training loss: 1.0908247232437134
Validation loss: 2.014852335376124

Epoch: 442| Step: 0
Training loss: 0.9952679872512817
Validation loss: 1.989966518135481

Epoch: 6| Step: 1
Training loss: 1.859852910041809
Validation loss: 1.9748759808078888

Epoch: 6| Step: 2
Training loss: 1.0828473567962646
Validation loss: 1.9775697928602978

Epoch: 6| Step: 3
Training loss: 1.1507973670959473
Validation loss: 1.9704816469582178

Epoch: 6| Step: 4
Training loss: 1.9748103618621826
Validation loss: 1.9963918347512521

Epoch: 6| Step: 5
Training loss: 1.1683807373046875
Validation loss: 2.019023254353513

Epoch: 6| Step: 6
Training loss: 1.9953639507293701
Validation loss: 2.054077740638487

Epoch: 6| Step: 7
Training loss: 1.446150779724121
Validation loss: 2.091244077169767

Epoch: 6| Step: 8
Training loss: 1.764317512512207
Validation loss: 2.1229256788889566

Epoch: 6| Step: 9
Training loss: 1.831807017326355
Validation loss: 2.108514444802397

Epoch: 6| Step: 10
Training loss: 0.9738118648529053
Validation loss: 2.061823739800402

Epoch: 6| Step: 11
Training loss: 1.4889650344848633
Validation loss: 2.04841282034433

Epoch: 6| Step: 12
Training loss: 2.3339271545410156
Validation loss: 2.03509061695427

Epoch: 6| Step: 13
Training loss: 1.87491774559021
Validation loss: 1.998703633585284

Epoch: 443| Step: 0
Training loss: 1.428142786026001
Validation loss: 2.018775645122733

Epoch: 6| Step: 1
Training loss: 1.3946095705032349
Validation loss: 2.0034207759364957

Epoch: 6| Step: 2
Training loss: 1.21791672706604
Validation loss: 2.0014996246625016

Epoch: 6| Step: 3
Training loss: 1.604084849357605
Validation loss: 2.0168268821572743

Epoch: 6| Step: 4
Training loss: 1.9691367149353027
Validation loss: 2.0313118350121284

Epoch: 6| Step: 5
Training loss: 1.4815983772277832
Validation loss: 2.0475241214998308

Epoch: 6| Step: 6
Training loss: 1.3377299308776855
Validation loss: 2.0460361498658375

Epoch: 6| Step: 7
Training loss: 1.477308750152588
Validation loss: 2.045615415419302

Epoch: 6| Step: 8
Training loss: 2.0470378398895264
Validation loss: 2.048245455629082

Epoch: 6| Step: 9
Training loss: 1.7778141498565674
Validation loss: 2.0527151579497964

Epoch: 6| Step: 10
Training loss: 1.5010042190551758
Validation loss: 2.0387761003227642

Epoch: 6| Step: 11
Training loss: 1.3532706499099731
Validation loss: 2.065473371936429

Epoch: 6| Step: 12
Training loss: 1.0766905546188354
Validation loss: 2.059969687974581

Epoch: 6| Step: 13
Training loss: 1.7343534231185913
Validation loss: 2.050664242877755

Epoch: 444| Step: 0
Training loss: 1.5021487474441528
Validation loss: 2.050654488225137

Epoch: 6| Step: 1
Training loss: 1.6719181537628174
Validation loss: 2.0387171545336322

Epoch: 6| Step: 2
Training loss: 1.2928967475891113
Validation loss: 2.0849958747945805

Epoch: 6| Step: 3
Training loss: 1.1370747089385986
Validation loss: 2.0827585035754788

Epoch: 6| Step: 4
Training loss: 1.8102694749832153
Validation loss: 2.066449507590263

Epoch: 6| Step: 5
Training loss: 1.2278214693069458
Validation loss: 2.03760681357435

Epoch: 6| Step: 6
Training loss: 1.3875960111618042
Validation loss: 2.0311816161678684

Epoch: 6| Step: 7
Training loss: 1.4705212116241455
Validation loss: 1.9947413090736634

Epoch: 6| Step: 8
Training loss: 1.3705319166183472
Validation loss: 2.004917166566336

Epoch: 6| Step: 9
Training loss: 1.6677697896957397
Validation loss: 2.0067292182676253

Epoch: 6| Step: 10
Training loss: 1.9397029876708984
Validation loss: 1.981627377130652

Epoch: 6| Step: 11
Training loss: 1.7359390258789062
Validation loss: 1.990916605918638

Epoch: 6| Step: 12
Training loss: 1.3681135177612305
Validation loss: 2.0031481750549807

Epoch: 6| Step: 13
Training loss: 1.7313361167907715
Validation loss: 1.9881514041654524

Epoch: 445| Step: 0
Training loss: 1.472923755645752
Validation loss: 2.0197486262167654

Epoch: 6| Step: 1
Training loss: 1.5162906646728516
Validation loss: 2.0497451918099516

Epoch: 6| Step: 2
Training loss: 1.4815274477005005
Validation loss: 2.0661616633015294

Epoch: 6| Step: 3
Training loss: 1.6410610675811768
Validation loss: 2.0973911798128517

Epoch: 6| Step: 4
Training loss: 1.5327885150909424
Validation loss: 2.1105404669238674

Epoch: 6| Step: 5
Training loss: 1.3002829551696777
Validation loss: 2.0899721473775883

Epoch: 6| Step: 6
Training loss: 2.1710500717163086
Validation loss: 2.062812330902264

Epoch: 6| Step: 7
Training loss: 1.3409990072250366
Validation loss: 2.0078663633715723

Epoch: 6| Step: 8
Training loss: 2.232588291168213
Validation loss: 1.9848713438997987

Epoch: 6| Step: 9
Training loss: 0.9606074690818787
Validation loss: 1.9704885277696835

Epoch: 6| Step: 10
Training loss: 1.0987818241119385
Validation loss: 1.9513692702016523

Epoch: 6| Step: 11
Training loss: 1.6229994297027588
Validation loss: 1.9623068250635618

Epoch: 6| Step: 12
Training loss: 1.3088514804840088
Validation loss: 1.9687956122941868

Epoch: 6| Step: 13
Training loss: 1.7408989667892456
Validation loss: 1.9929481026946858

Epoch: 446| Step: 0
Training loss: 1.6878620386123657
Validation loss: 2.0040247735156806

Epoch: 6| Step: 1
Training loss: 1.4933876991271973
Validation loss: 2.0410414331702778

Epoch: 6| Step: 2
Training loss: 1.2946085929870605
Validation loss: 2.0622076629310526

Epoch: 6| Step: 3
Training loss: 1.4339537620544434
Validation loss: 2.0970754187594176

Epoch: 6| Step: 4
Training loss: 2.0185601711273193
Validation loss: 2.0940371008329492

Epoch: 6| Step: 5
Training loss: 1.3872973918914795
Validation loss: 2.082996863190846

Epoch: 6| Step: 6
Training loss: 1.231977939605713
Validation loss: 2.072277786911175

Epoch: 6| Step: 7
Training loss: 1.5379579067230225
Validation loss: 2.0558813054074525

Epoch: 6| Step: 8
Training loss: 2.164229393005371
Validation loss: 2.0509585283135854

Epoch: 6| Step: 9
Training loss: 1.2267905473709106
Validation loss: 2.03984369385627

Epoch: 6| Step: 10
Training loss: 1.1508007049560547
Validation loss: 2.006476815028857

Epoch: 6| Step: 11
Training loss: 1.3525923490524292
Validation loss: 1.981633509359052

Epoch: 6| Step: 12
Training loss: 1.4075214862823486
Validation loss: 2.0045054048620243

Epoch: 6| Step: 13
Training loss: 1.5822643041610718
Validation loss: 1.9919424826099026

Epoch: 447| Step: 0
Training loss: 1.2934547662734985
Validation loss: 2.0024825757549656

Epoch: 6| Step: 1
Training loss: 2.2233686447143555
Validation loss: 2.0145523445580595

Epoch: 6| Step: 2
Training loss: 1.2277214527130127
Validation loss: 2.0214373373216197

Epoch: 6| Step: 3
Training loss: 1.5469329357147217
Validation loss: 2.0485054882623817

Epoch: 6| Step: 4
Training loss: 1.6893130540847778
Validation loss: 2.048548689452551

Epoch: 6| Step: 5
Training loss: 1.3007091283798218
Validation loss: 2.0349011908295336

Epoch: 6| Step: 6
Training loss: 1.5747272968292236
Validation loss: 2.059883027948359

Epoch: 6| Step: 7
Training loss: 1.4839541912078857
Validation loss: 2.020390251631378

Epoch: 6| Step: 8
Training loss: 1.4661157131195068
Validation loss: 2.021486328494164

Epoch: 6| Step: 9
Training loss: 1.6494908332824707
Validation loss: 2.010419531535077

Epoch: 6| Step: 10
Training loss: 1.4244813919067383
Validation loss: 2.000483982024654

Epoch: 6| Step: 11
Training loss: 0.9241459369659424
Validation loss: 2.030478985078873

Epoch: 6| Step: 12
Training loss: 1.4589471817016602
Validation loss: 2.0284831113712762

Epoch: 6| Step: 13
Training loss: 1.7633116245269775
Validation loss: 2.045062215097489

Epoch: 448| Step: 0
Training loss: 0.8866061568260193
Validation loss: 2.0664916038513184

Epoch: 6| Step: 1
Training loss: 1.7246527671813965
Validation loss: 2.1006246113008067

Epoch: 6| Step: 2
Training loss: 1.841425895690918
Validation loss: 2.09078755558178

Epoch: 6| Step: 3
Training loss: 1.5026606321334839
Validation loss: 2.0823310421359156

Epoch: 6| Step: 4
Training loss: 1.6098171472549438
Validation loss: 2.038135201700272

Epoch: 6| Step: 5
Training loss: 2.016108512878418
Validation loss: 2.034332085681218

Epoch: 6| Step: 6
Training loss: 1.5158120393753052
Validation loss: 2.035568626978064

Epoch: 6| Step: 7
Training loss: 1.8289427757263184
Validation loss: 2.0200638360874628

Epoch: 6| Step: 8
Training loss: 1.7387440204620361
Validation loss: 1.996121855192287

Epoch: 6| Step: 9
Training loss: 1.2621514797210693
Validation loss: 2.029721713835193

Epoch: 6| Step: 10
Training loss: 0.7910915613174438
Validation loss: 2.070052541712279

Epoch: 6| Step: 11
Training loss: 1.5380523204803467
Validation loss: 2.0900926436147382

Epoch: 6| Step: 12
Training loss: 1.1725832223892212
Validation loss: 2.110065967805924

Epoch: 6| Step: 13
Training loss: 1.6724696159362793
Validation loss: 2.0919034686139835

Epoch: 449| Step: 0
Training loss: 1.108500599861145
Validation loss: 2.0816127356662544

Epoch: 6| Step: 1
Training loss: 0.8050086498260498
Validation loss: 2.0723758666746077

Epoch: 6| Step: 2
Training loss: 1.461774468421936
Validation loss: 2.0276293587940994

Epoch: 6| Step: 3
Training loss: 1.2272777557373047
Validation loss: 2.0087074669458533

Epoch: 6| Step: 4
Training loss: 1.817404866218567
Validation loss: 2.009225433872592

Epoch: 6| Step: 5
Training loss: 1.8757623434066772
Validation loss: 2.009984765001523

Epoch: 6| Step: 6
Training loss: 1.008058786392212
Validation loss: 1.996481357082244

Epoch: 6| Step: 7
Training loss: 1.5606746673583984
Validation loss: 2.0022953556429957

Epoch: 6| Step: 8
Training loss: 1.647428035736084
Validation loss: 2.018878718858124

Epoch: 6| Step: 9
Training loss: 1.554405927658081
Validation loss: 2.0025658543391893

Epoch: 6| Step: 10
Training loss: 1.497870922088623
Validation loss: 1.9826918096952542

Epoch: 6| Step: 11
Training loss: 2.0443472862243652
Validation loss: 2.0046514939236384

Epoch: 6| Step: 12
Training loss: 1.5793967247009277
Validation loss: 2.0110011792952016

Epoch: 6| Step: 13
Training loss: 1.4320428371429443
Validation loss: 2.0318553960451515

Epoch: 450| Step: 0
Training loss: 1.5182358026504517
Validation loss: 2.0488479752694406

Epoch: 6| Step: 1
Training loss: 1.5820538997650146
Validation loss: 2.1374478955422678

Epoch: 6| Step: 2
Training loss: 1.7730913162231445
Validation loss: 2.1963910620699645

Epoch: 6| Step: 3
Training loss: 1.2327330112457275
Validation loss: 2.2098836744985273

Epoch: 6| Step: 4
Training loss: 1.516763687133789
Validation loss: 2.1910713436783

Epoch: 6| Step: 5
Training loss: 1.6077630519866943
Validation loss: 2.165746263278428

Epoch: 6| Step: 6
Training loss: 1.5986604690551758
Validation loss: 2.109541049567602

Epoch: 6| Step: 7
Training loss: 1.3339555263519287
Validation loss: 2.044242605086296

Epoch: 6| Step: 8
Training loss: 2.073753833770752
Validation loss: 1.9964053297555575

Epoch: 6| Step: 9
Training loss: 1.6310436725616455
Validation loss: 1.9826618009997952

Epoch: 6| Step: 10
Training loss: 1.3634717464447021
Validation loss: 1.9528772677144697

Epoch: 6| Step: 11
Training loss: 1.4425578117370605
Validation loss: 1.9656855444754324

Epoch: 6| Step: 12
Training loss: 0.9789255857467651
Validation loss: 1.990415455192648

Epoch: 6| Step: 13
Training loss: 1.71992826461792
Validation loss: 1.9926342694990096

Epoch: 451| Step: 0
Training loss: 1.1165885925292969
Validation loss: 1.998142429577407

Epoch: 6| Step: 1
Training loss: 0.9954338073730469
Validation loss: 2.0031414672892582

Epoch: 6| Step: 2
Training loss: 1.2578516006469727
Validation loss: 2.0323293132166707

Epoch: 6| Step: 3
Training loss: 1.7307562828063965
Validation loss: 2.0498381596739574

Epoch: 6| Step: 4
Training loss: 2.140214443206787
Validation loss: 2.087091717668759

Epoch: 6| Step: 5
Training loss: 1.5599761009216309
Validation loss: 2.081157038288732

Epoch: 6| Step: 6
Training loss: 1.9209694862365723
Validation loss: 2.133929334661012

Epoch: 6| Step: 7
Training loss: 1.3619048595428467
Validation loss: 2.1079594986413115

Epoch: 6| Step: 8
Training loss: 1.8179500102996826
Validation loss: 2.102273230911583

Epoch: 6| Step: 9
Training loss: 1.2488253116607666
Validation loss: 2.0875339841329925

Epoch: 6| Step: 10
Training loss: 1.6046161651611328
Validation loss: 2.0362758585201797

Epoch: 6| Step: 11
Training loss: 1.3757855892181396
Validation loss: 2.04691844601785

Epoch: 6| Step: 12
Training loss: 1.3902151584625244
Validation loss: 2.025374151045276

Epoch: 6| Step: 13
Training loss: 1.1723198890686035
Validation loss: 1.993764542764233

Epoch: 452| Step: 0
Training loss: 0.7937743663787842
Validation loss: 1.9683797692739835

Epoch: 6| Step: 1
Training loss: 1.5453921556472778
Validation loss: 1.9615650766639299

Epoch: 6| Step: 2
Training loss: 0.9761499166488647
Validation loss: 1.9587768764906033

Epoch: 6| Step: 3
Training loss: 1.5709458589553833
Validation loss: 2.0019191682979627

Epoch: 6| Step: 4
Training loss: 0.9643425941467285
Validation loss: 2.0335819631494503

Epoch: 6| Step: 5
Training loss: 1.6795461177825928
Validation loss: 2.0678445959603913

Epoch: 6| Step: 6
Training loss: 2.0761029720306396
Validation loss: 2.1131829138725036

Epoch: 6| Step: 7
Training loss: 1.69545316696167
Validation loss: 2.1057167258313907

Epoch: 6| Step: 8
Training loss: 1.322112798690796
Validation loss: 2.068856353400856

Epoch: 6| Step: 9
Training loss: 1.09347665309906
Validation loss: 2.058573603630066

Epoch: 6| Step: 10
Training loss: 1.578989863395691
Validation loss: 2.004183353916291

Epoch: 6| Step: 11
Training loss: 2.044510841369629
Validation loss: 1.9907747827550417

Epoch: 6| Step: 12
Training loss: 1.760650873184204
Validation loss: 1.963448973112209

Epoch: 6| Step: 13
Training loss: 1.8320761919021606
Validation loss: 1.974225700542491

Epoch: 453| Step: 0
Training loss: 1.9461382627487183
Validation loss: 1.9895808940292687

Epoch: 6| Step: 1
Training loss: 1.4890066385269165
Validation loss: 1.9959487991948281

Epoch: 6| Step: 2
Training loss: 2.0894455909729004
Validation loss: 2.018248386280511

Epoch: 6| Step: 3
Training loss: 1.701743483543396
Validation loss: 2.024212114272579

Epoch: 6| Step: 4
Training loss: 1.9882630109786987
Validation loss: 2.0230000826620285

Epoch: 6| Step: 5
Training loss: 0.9228050112724304
Validation loss: 1.9931310658813806

Epoch: 6| Step: 6
Training loss: 1.2054386138916016
Validation loss: 2.050235999527798

Epoch: 6| Step: 7
Training loss: 1.2427424192428589
Validation loss: 2.057145590423256

Epoch: 6| Step: 8
Training loss: 1.528639554977417
Validation loss: 2.0927513619904876

Epoch: 6| Step: 9
Training loss: 0.9797244668006897
Validation loss: 2.137261276604027

Epoch: 6| Step: 10
Training loss: 1.3046990633010864
Validation loss: 2.144182361582274

Epoch: 6| Step: 11
Training loss: 1.463249921798706
Validation loss: 2.1482573196452153

Epoch: 6| Step: 12
Training loss: 1.6155219078063965
Validation loss: 2.11809633111441

Epoch: 6| Step: 13
Training loss: 1.6699186563491821
Validation loss: 2.03351415100918

Epoch: 454| Step: 0
Training loss: 1.6961140632629395
Validation loss: 1.973029544276576

Epoch: 6| Step: 1
Training loss: 1.467078685760498
Validation loss: 1.9540576806632421

Epoch: 6| Step: 2
Training loss: 1.623681902885437
Validation loss: 1.952599335742253

Epoch: 6| Step: 3
Training loss: 1.464902639389038
Validation loss: 1.9566056753999443

Epoch: 6| Step: 4
Training loss: 1.3663946390151978
Validation loss: 1.949312134455609

Epoch: 6| Step: 5
Training loss: 1.566847324371338
Validation loss: 1.9674662800245388

Epoch: 6| Step: 6
Training loss: 1.3524608612060547
Validation loss: 1.9687080511482813

Epoch: 6| Step: 7
Training loss: 1.3340303897857666
Validation loss: 1.9985371148714455

Epoch: 6| Step: 8
Training loss: 0.6689736843109131
Validation loss: 2.037312821675372

Epoch: 6| Step: 9
Training loss: 1.659812092781067
Validation loss: 2.077813063898394

Epoch: 6| Step: 10
Training loss: 1.3254953622817993
Validation loss: 2.147113871830766

Epoch: 6| Step: 11
Training loss: 1.841152310371399
Validation loss: 2.1850160091154036

Epoch: 6| Step: 12
Training loss: 2.4413046836853027
Validation loss: 2.169188742996544

Epoch: 6| Step: 13
Training loss: 0.9685671329498291
Validation loss: 2.156348036181542

Epoch: 455| Step: 0
Training loss: 1.6008760929107666
Validation loss: 2.1627157170285463

Epoch: 6| Step: 1
Training loss: 2.041450023651123
Validation loss: 2.1463065634491625

Epoch: 6| Step: 2
Training loss: 1.8039774894714355
Validation loss: 2.102214556868358

Epoch: 6| Step: 3
Training loss: 1.6527962684631348
Validation loss: 2.04346021785531

Epoch: 6| Step: 4
Training loss: 0.9613996148109436
Validation loss: 1.9952213533463017

Epoch: 6| Step: 5
Training loss: 1.7566852569580078
Validation loss: 1.9768529066475489

Epoch: 6| Step: 6
Training loss: 1.4205420017242432
Validation loss: 1.9712379132547686

Epoch: 6| Step: 7
Training loss: 1.1982042789459229
Validation loss: 1.981222568019744

Epoch: 6| Step: 8
Training loss: 1.4198143482208252
Validation loss: 1.998382342758999

Epoch: 6| Step: 9
Training loss: 1.7341501712799072
Validation loss: 2.003285769493349

Epoch: 6| Step: 10
Training loss: 1.1843936443328857
Validation loss: 2.003361543019613

Epoch: 6| Step: 11
Training loss: 1.8742990493774414
Validation loss: 2.0440930128097534

Epoch: 6| Step: 12
Training loss: 1.1169023513793945
Validation loss: 2.1002820602027317

Epoch: 6| Step: 13
Training loss: 0.698439359664917
Validation loss: 2.1289740890584965

Epoch: 456| Step: 0
Training loss: 1.5778510570526123
Validation loss: 2.140095019853243

Epoch: 6| Step: 1
Training loss: 1.0257261991500854
Validation loss: 2.1037466782395557

Epoch: 6| Step: 2
Training loss: 1.5870988368988037
Validation loss: 2.1152632877390873

Epoch: 6| Step: 3
Training loss: 1.135316014289856
Validation loss: 2.09464858424279

Epoch: 6| Step: 4
Training loss: 1.2524700164794922
Validation loss: 2.0535451558328446

Epoch: 6| Step: 5
Training loss: 1.1719110012054443
Validation loss: 2.0066084400300057

Epoch: 6| Step: 6
Training loss: 1.560454249382019
Validation loss: 1.9709744261157127

Epoch: 6| Step: 7
Training loss: 1.9487864971160889
Validation loss: 1.9670830657405238

Epoch: 6| Step: 8
Training loss: 2.4546360969543457
Validation loss: 1.9662394600529824

Epoch: 6| Step: 9
Training loss: 1.6295084953308105
Validation loss: 1.956962598267422

Epoch: 6| Step: 10
Training loss: 1.026897668838501
Validation loss: 1.9454384491007815

Epoch: 6| Step: 11
Training loss: 1.166443109512329
Validation loss: 1.9667010397039435

Epoch: 6| Step: 12
Training loss: 2.2806177139282227
Validation loss: 1.9817863369500766

Epoch: 6| Step: 13
Training loss: 0.9202783107757568
Validation loss: 1.9851391648733487

Epoch: 457| Step: 0
Training loss: 1.700767993927002
Validation loss: 2.0139337303817912

Epoch: 6| Step: 1
Training loss: 1.474515438079834
Validation loss: 2.0377396486138784

Epoch: 6| Step: 2
Training loss: 1.1190848350524902
Validation loss: 2.0870580237398864

Epoch: 6| Step: 3
Training loss: 1.7687312364578247
Validation loss: 2.1034960657037716

Epoch: 6| Step: 4
Training loss: 1.6970040798187256
Validation loss: 2.0761591529333465

Epoch: 6| Step: 5
Training loss: 1.501162052154541
Validation loss: 2.0746540049070954

Epoch: 6| Step: 6
Training loss: 1.5210049152374268
Validation loss: 2.090226956593093

Epoch: 6| Step: 7
Training loss: 1.0928633213043213
Validation loss: 2.0505341611882693

Epoch: 6| Step: 8
Training loss: 1.737895131111145
Validation loss: 2.02418202354062

Epoch: 6| Step: 9
Training loss: 1.130763053894043
Validation loss: 1.9851513421663673

Epoch: 6| Step: 10
Training loss: 1.5298099517822266
Validation loss: 1.9765641766209756

Epoch: 6| Step: 11
Training loss: 1.208350419998169
Validation loss: 1.948598378448076

Epoch: 6| Step: 12
Training loss: 1.1286413669586182
Validation loss: 1.9822037476365284

Epoch: 6| Step: 13
Training loss: 2.0806450843811035
Validation loss: 1.9911980346966816

Epoch: 458| Step: 0
Training loss: 1.40373957157135
Validation loss: 1.981201840985206

Epoch: 6| Step: 1
Training loss: 1.0517845153808594
Validation loss: 2.012186929743777

Epoch: 6| Step: 2
Training loss: 2.012637138366699
Validation loss: 2.0280819759573987

Epoch: 6| Step: 3
Training loss: 1.5438177585601807
Validation loss: 2.067922620363133

Epoch: 6| Step: 4
Training loss: 1.552236557006836
Validation loss: 2.0748465791825326

Epoch: 6| Step: 5
Training loss: 1.445370078086853
Validation loss: 2.0716089279420915

Epoch: 6| Step: 6
Training loss: 1.5824437141418457
Validation loss: 2.1494119910783667

Epoch: 6| Step: 7
Training loss: 1.3929977416992188
Validation loss: 2.1337198724028883

Epoch: 6| Step: 8
Training loss: 1.4661979675292969
Validation loss: 2.18819918171052

Epoch: 6| Step: 9
Training loss: 0.9919524788856506
Validation loss: 2.1357661959945515

Epoch: 6| Step: 10
Training loss: 1.8240561485290527
Validation loss: 2.116856633975942

Epoch: 6| Step: 11
Training loss: 1.5047938823699951
Validation loss: 2.089168385792804

Epoch: 6| Step: 12
Training loss: 1.2857972383499146
Validation loss: 2.071665956128028

Epoch: 6| Step: 13
Training loss: 1.1488146781921387
Validation loss: 2.0164602597554526

Epoch: 459| Step: 0
Training loss: 2.251270294189453
Validation loss: 1.9795190006174066

Epoch: 6| Step: 1
Training loss: 1.0630090236663818
Validation loss: 1.9542297265862907

Epoch: 6| Step: 2
Training loss: 1.6958189010620117
Validation loss: 1.9444897136380594

Epoch: 6| Step: 3
Training loss: 1.6889413595199585
Validation loss: 1.9435974474876159

Epoch: 6| Step: 4
Training loss: 1.9741392135620117
Validation loss: 1.948986579013127

Epoch: 6| Step: 5
Training loss: 1.2676199674606323
Validation loss: 1.9559210256863666

Epoch: 6| Step: 6
Training loss: 0.892538845539093
Validation loss: 2.0097635689602105

Epoch: 6| Step: 7
Training loss: 2.0732173919677734
Validation loss: 2.0587471377465034

Epoch: 6| Step: 8
Training loss: 1.130617380142212
Validation loss: 2.1081039469729186

Epoch: 6| Step: 9
Training loss: 0.868402898311615
Validation loss: 2.1713160237958355

Epoch: 6| Step: 10
Training loss: 1.40828275680542
Validation loss: 2.1833679458146453

Epoch: 6| Step: 11
Training loss: 1.4944335222244263
Validation loss: 2.1300485018760926

Epoch: 6| Step: 12
Training loss: 1.4809257984161377
Validation loss: 2.0909154363857803

Epoch: 6| Step: 13
Training loss: 1.2701579332351685
Validation loss: 2.0500092647408925

Epoch: 460| Step: 0
Training loss: 1.322082757949829
Validation loss: 2.0064177141394666

Epoch: 6| Step: 1
Training loss: 1.6048682928085327
Validation loss: 1.9688842194054716

Epoch: 6| Step: 2
Training loss: 1.4810771942138672
Validation loss: 1.9809291490944483

Epoch: 6| Step: 3
Training loss: 1.598839521408081
Validation loss: 1.9410505256345194

Epoch: 6| Step: 4
Training loss: 1.269371747970581
Validation loss: 1.9487392338373328

Epoch: 6| Step: 5
Training loss: 1.8434070348739624
Validation loss: 1.9586866594129992

Epoch: 6| Step: 6
Training loss: 2.0024547576904297
Validation loss: 1.977255545636659

Epoch: 6| Step: 7
Training loss: 1.1654391288757324
Validation loss: 2.0036101725793656

Epoch: 6| Step: 8
Training loss: 1.5835188627243042
Validation loss: 2.0145649525427047

Epoch: 6| Step: 9
Training loss: 1.6802929639816284
Validation loss: 2.028263645787393

Epoch: 6| Step: 10
Training loss: 1.1796371936798096
Validation loss: 2.0864572319933163

Epoch: 6| Step: 11
Training loss: 1.1316442489624023
Validation loss: 2.156565385480081

Epoch: 6| Step: 12
Training loss: 1.240189552307129
Validation loss: 2.165397672243016

Epoch: 6| Step: 13
Training loss: 1.263489007949829
Validation loss: 2.1527649587200535

Epoch: 461| Step: 0
Training loss: 0.846988320350647
Validation loss: 2.125150703614758

Epoch: 6| Step: 1
Training loss: 1.1405723094940186
Validation loss: 2.0909381207599433

Epoch: 6| Step: 2
Training loss: 0.9680416584014893
Validation loss: 2.016883856506758

Epoch: 6| Step: 3
Training loss: 1.8639229536056519
Validation loss: 1.9939130583117086

Epoch: 6| Step: 4
Training loss: 1.1548678874969482
Validation loss: 1.9464710656032767

Epoch: 6| Step: 5
Training loss: 1.3955227136611938
Validation loss: 1.9493581812868837

Epoch: 6| Step: 6
Training loss: 1.8794441223144531
Validation loss: 1.9390774439739924

Epoch: 6| Step: 7
Training loss: 1.9925804138183594
Validation loss: 1.9332118944455219

Epoch: 6| Step: 8
Training loss: 1.5777665376663208
Validation loss: 1.9456855097124655

Epoch: 6| Step: 9
Training loss: 1.6418877840042114
Validation loss: 1.9439503736393426

Epoch: 6| Step: 10
Training loss: 1.4544187784194946
Validation loss: 1.9457148813432263

Epoch: 6| Step: 11
Training loss: 1.1173679828643799
Validation loss: 1.9666555722554524

Epoch: 6| Step: 12
Training loss: 2.0174009799957275
Validation loss: 2.0257679723924205

Epoch: 6| Step: 13
Training loss: 1.2885680198669434
Validation loss: 2.0277276680033696

Epoch: 462| Step: 0
Training loss: 1.3485232591629028
Validation loss: 2.074810507476971

Epoch: 6| Step: 1
Training loss: 2.1916208267211914
Validation loss: 2.074173686324909

Epoch: 6| Step: 2
Training loss: 1.295418381690979
Validation loss: 2.056996714684271

Epoch: 6| Step: 3
Training loss: 1.0275866985321045
Validation loss: 2.0428886631483674

Epoch: 6| Step: 4
Training loss: 1.1085166931152344
Validation loss: 2.0417227078509588

Epoch: 6| Step: 5
Training loss: 2.195690870285034
Validation loss: 2.0187241685005928

Epoch: 6| Step: 6
Training loss: 1.235843300819397
Validation loss: 2.016689613301267

Epoch: 6| Step: 7
Training loss: 1.0605483055114746
Validation loss: 1.9862191395093036

Epoch: 6| Step: 8
Training loss: 1.611782431602478
Validation loss: 1.981294596067039

Epoch: 6| Step: 9
Training loss: 1.5870599746704102
Validation loss: 1.9880161413582422

Epoch: 6| Step: 10
Training loss: 1.9037649631500244
Validation loss: 1.9834148217273015

Epoch: 6| Step: 11
Training loss: 1.3943486213684082
Validation loss: 1.9648890213299823

Epoch: 6| Step: 12
Training loss: 1.0525484085083008
Validation loss: 1.9811970059589674

Epoch: 6| Step: 13
Training loss: 0.8707662224769592
Validation loss: 1.997622633493075

Epoch: 463| Step: 0
Training loss: 1.0804448127746582
Validation loss: 2.0170566779310986

Epoch: 6| Step: 1
Training loss: 1.3163164854049683
Validation loss: 2.0323924326127574

Epoch: 6| Step: 2
Training loss: 1.202458381652832
Validation loss: 2.0366075500365226

Epoch: 6| Step: 3
Training loss: 0.9342677593231201
Validation loss: 2.0812749452488397

Epoch: 6| Step: 4
Training loss: 1.1478700637817383
Validation loss: 2.0637180407842

Epoch: 6| Step: 5
Training loss: 2.089195489883423
Validation loss: 2.077406544839182

Epoch: 6| Step: 6
Training loss: 1.4411113262176514
Validation loss: 2.061015587981029

Epoch: 6| Step: 7
Training loss: 1.7501635551452637
Validation loss: 2.0188758270714873

Epoch: 6| Step: 8
Training loss: 1.335331916809082
Validation loss: 1.9883565851437148

Epoch: 6| Step: 9
Training loss: 1.8026673793792725
Validation loss: 1.9497710684294343

Epoch: 6| Step: 10
Training loss: 1.6915662288665771
Validation loss: 1.9378351255129742

Epoch: 6| Step: 11
Training loss: 1.742904782295227
Validation loss: 1.9323056205626457

Epoch: 6| Step: 12
Training loss: 1.3786251544952393
Validation loss: 1.93908836636492

Epoch: 6| Step: 13
Training loss: 1.2458281517028809
Validation loss: 1.9336808176450833

Epoch: 464| Step: 0
Training loss: 1.5632946491241455
Validation loss: 1.9571848043831446

Epoch: 6| Step: 1
Training loss: 1.7099964618682861
Validation loss: 1.961206918121666

Epoch: 6| Step: 2
Training loss: 1.6865159273147583
Validation loss: 2.0129085381825766

Epoch: 6| Step: 3
Training loss: 0.7592010498046875
Validation loss: 2.0292429206191853

Epoch: 6| Step: 4
Training loss: 1.4247643947601318
Validation loss: 2.053275615938248

Epoch: 6| Step: 5
Training loss: 1.5818867683410645
Validation loss: 2.0886322836722098

Epoch: 6| Step: 6
Training loss: 0.9793556928634644
Validation loss: 2.079299255083966

Epoch: 6| Step: 7
Training loss: 1.3750851154327393
Validation loss: 2.0744627393702024

Epoch: 6| Step: 8
Training loss: 1.7104032039642334
Validation loss: 2.0948933324506207

Epoch: 6| Step: 9
Training loss: 1.286062240600586
Validation loss: 2.088716121130092

Epoch: 6| Step: 10
Training loss: 2.011371612548828
Validation loss: 2.0598820460739957

Epoch: 6| Step: 11
Training loss: 1.448547124862671
Validation loss: 2.020805667805415

Epoch: 6| Step: 12
Training loss: 1.421644687652588
Validation loss: 2.011118515845268

Epoch: 6| Step: 13
Training loss: 0.9350561499595642
Validation loss: 1.995825534225792

Epoch: 465| Step: 0
Training loss: 1.9548871517181396
Validation loss: 1.9904589755560762

Epoch: 6| Step: 1
Training loss: 1.8765392303466797
Validation loss: 1.976346387658068

Epoch: 6| Step: 2
Training loss: 1.47865629196167
Validation loss: 1.9833411196226716

Epoch: 6| Step: 3
Training loss: 2.3244616985321045
Validation loss: 2.0020369983488515

Epoch: 6| Step: 4
Training loss: 1.4505016803741455
Validation loss: 1.9772713171538485

Epoch: 6| Step: 5
Training loss: 1.0242266654968262
Validation loss: 1.9948328951353669

Epoch: 6| Step: 6
Training loss: 1.539346694946289
Validation loss: 1.9935465999828872

Epoch: 6| Step: 7
Training loss: 1.7419577836990356
Validation loss: 1.9863083349761141

Epoch: 6| Step: 8
Training loss: 1.268205165863037
Validation loss: 2.0407251363159506

Epoch: 6| Step: 9
Training loss: 1.0073809623718262
Validation loss: 2.0842087909739506

Epoch: 6| Step: 10
Training loss: 0.8832590579986572
Validation loss: 2.163063318498673

Epoch: 6| Step: 11
Training loss: 1.4934413433074951
Validation loss: 2.149752461782066

Epoch: 6| Step: 12
Training loss: 1.166106104850769
Validation loss: 2.139805292570463

Epoch: 6| Step: 13
Training loss: 0.6530904769897461
Validation loss: 2.0868864392721527

Epoch: 466| Step: 0
Training loss: 1.853210687637329
Validation loss: 2.032298308546825

Epoch: 6| Step: 1
Training loss: 2.4058728218078613
Validation loss: 1.9732419906123992

Epoch: 6| Step: 2
Training loss: 0.7714530229568481
Validation loss: 1.9948433253072924

Epoch: 6| Step: 3
Training loss: 1.3675990104675293
Validation loss: 1.9557968903613347

Epoch: 6| Step: 4
Training loss: 1.0826690196990967
Validation loss: 1.9796326314249346

Epoch: 6| Step: 5
Training loss: 1.2312123775482178
Validation loss: 1.9651088483871952

Epoch: 6| Step: 6
Training loss: 1.128570318222046
Validation loss: 1.9779474222531883

Epoch: 6| Step: 7
Training loss: 1.2907500267028809
Validation loss: 2.002722414590979

Epoch: 6| Step: 8
Training loss: 1.115041732788086
Validation loss: 2.034730394681295

Epoch: 6| Step: 9
Training loss: 1.9853556156158447
Validation loss: 2.075017777822351

Epoch: 6| Step: 10
Training loss: 2.0437629222869873
Validation loss: 2.1313992008086173

Epoch: 6| Step: 11
Training loss: 1.3059842586517334
Validation loss: 2.1692369804587415

Epoch: 6| Step: 12
Training loss: 1.3740520477294922
Validation loss: 2.1499418661158574

Epoch: 6| Step: 13
Training loss: 0.9732807874679565
Validation loss: 2.1439215419112996

Epoch: 467| Step: 0
Training loss: 1.3505492210388184
Validation loss: 2.0666225084694485

Epoch: 6| Step: 1
Training loss: 1.5980260372161865
Validation loss: 2.0139015823282223

Epoch: 6| Step: 2
Training loss: 1.476554274559021
Validation loss: 1.9635701999869397

Epoch: 6| Step: 3
Training loss: 1.0026648044586182
Validation loss: 1.9237610755428192

Epoch: 6| Step: 4
Training loss: 1.5351678133010864
Validation loss: 1.929047910116052

Epoch: 6| Step: 5
Training loss: 1.630789041519165
Validation loss: 1.9253367121501634

Epoch: 6| Step: 6
Training loss: 1.7031182050704956
Validation loss: 1.950522074135401

Epoch: 6| Step: 7
Training loss: 1.8989489078521729
Validation loss: 1.9433211677817888

Epoch: 6| Step: 8
Training loss: 1.5890775918960571
Validation loss: 1.9791135967418712

Epoch: 6| Step: 9
Training loss: 1.1137874126434326
Validation loss: 2.0062708470129196

Epoch: 6| Step: 10
Training loss: 0.5819247364997864
Validation loss: 2.07010422214385

Epoch: 6| Step: 11
Training loss: 0.8445649743080139
Validation loss: 2.1148934595046507

Epoch: 6| Step: 12
Training loss: 1.940899133682251
Validation loss: 2.1175979234839

Epoch: 6| Step: 13
Training loss: 2.3493692874908447
Validation loss: 2.1096365887631654

Epoch: 468| Step: 0
Training loss: 1.6552866697311401
Validation loss: 2.0728337751921786

Epoch: 6| Step: 1
Training loss: 0.665838360786438
Validation loss: 2.0246973114628948

Epoch: 6| Step: 2
Training loss: 1.9374768733978271
Validation loss: 2.0144448280334473

Epoch: 6| Step: 3
Training loss: 1.706068515777588
Validation loss: 1.9651223651824459

Epoch: 6| Step: 4
Training loss: 0.8402787446975708
Validation loss: 1.9527067240848337

Epoch: 6| Step: 5
Training loss: 1.2985448837280273
Validation loss: 1.9454984549553163

Epoch: 6| Step: 6
Training loss: 2.1088452339172363
Validation loss: 1.9716678229711389

Epoch: 6| Step: 7
Training loss: 2.297184467315674
Validation loss: 1.9893577380846905

Epoch: 6| Step: 8
Training loss: 1.2467001676559448
Validation loss: 2.0079454734761226

Epoch: 6| Step: 9
Training loss: 1.0507291555404663
Validation loss: 2.053463469269455

Epoch: 6| Step: 10
Training loss: 1.5048367977142334
Validation loss: 2.0789375920449533

Epoch: 6| Step: 11
Training loss: 1.2666847705841064
Validation loss: 2.112010561009889

Epoch: 6| Step: 12
Training loss: 1.2929461002349854
Validation loss: 2.149111595205081

Epoch: 6| Step: 13
Training loss: 1.05685293674469
Validation loss: 2.12698354259614

Epoch: 469| Step: 0
Training loss: 1.307407259941101
Validation loss: 2.063284489416307

Epoch: 6| Step: 1
Training loss: 1.6808900833129883
Validation loss: 2.027735191006814

Epoch: 6| Step: 2
Training loss: 0.9728403687477112
Validation loss: 1.9919590347556657

Epoch: 6| Step: 3
Training loss: 1.3602735996246338
Validation loss: 1.9930280216278569

Epoch: 6| Step: 4
Training loss: 1.665259838104248
Validation loss: 1.980756866034641

Epoch: 6| Step: 5
Training loss: 2.0673513412475586
Validation loss: 1.977857655094516

Epoch: 6| Step: 6
Training loss: 1.2676634788513184
Validation loss: 1.9946641050359255

Epoch: 6| Step: 7
Training loss: 0.7141202092170715
Validation loss: 2.028156562518048

Epoch: 6| Step: 8
Training loss: 1.923034429550171
Validation loss: 2.049813429514567

Epoch: 6| Step: 9
Training loss: 1.5301657915115356
Validation loss: 2.04699436823527

Epoch: 6| Step: 10
Training loss: 1.6174721717834473
Validation loss: 2.0672285556793213

Epoch: 6| Step: 11
Training loss: 1.5188663005828857
Validation loss: 2.0477269003468175

Epoch: 6| Step: 12
Training loss: 0.7858859896659851
Validation loss: 2.0234520076423563

Epoch: 6| Step: 13
Training loss: 1.4529356956481934
Validation loss: 2.0264966180247646

Epoch: 470| Step: 0
Training loss: 1.4409525394439697
Validation loss: 1.994580194514285

Epoch: 6| Step: 1
Training loss: 1.6342742443084717
Validation loss: 1.9891499768021286

Epoch: 6| Step: 2
Training loss: 1.463151454925537
Validation loss: 1.9917070147811726

Epoch: 6| Step: 3
Training loss: 1.68838369846344
Validation loss: 1.9609520255878408

Epoch: 6| Step: 4
Training loss: 1.5021463632583618
Validation loss: 1.9835307290477138

Epoch: 6| Step: 5
Training loss: 1.2947434186935425
Validation loss: 1.980785108381702

Epoch: 6| Step: 6
Training loss: 1.1296756267547607
Validation loss: 2.0246653569641935

Epoch: 6| Step: 7
Training loss: 0.9685347080230713
Validation loss: 2.008245692458204

Epoch: 6| Step: 8
Training loss: 1.0761523246765137
Validation loss: 2.012514042597945

Epoch: 6| Step: 9
Training loss: 1.4581478834152222
Validation loss: 2.0412824012899913

Epoch: 6| Step: 10
Training loss: 1.4412741661071777
Validation loss: 2.082073550070486

Epoch: 6| Step: 11
Training loss: 1.4412503242492676
Validation loss: 2.066125246786302

Epoch: 6| Step: 12
Training loss: 1.968170166015625
Validation loss: 2.0596679423445012

Epoch: 6| Step: 13
Training loss: 1.0726306438446045
Validation loss: 2.0208493689055085

Epoch: 471| Step: 0
Training loss: 1.1503815650939941
Validation loss: 1.9990868158237909

Epoch: 6| Step: 1
Training loss: 1.4398759603500366
Validation loss: 2.034545406218498

Epoch: 6| Step: 2
Training loss: 1.919005274772644
Validation loss: 2.033920629050142

Epoch: 6| Step: 3
Training loss: 1.0767827033996582
Validation loss: 2.039488720637496

Epoch: 6| Step: 4
Training loss: 1.4443533420562744
Validation loss: 2.051952305660453

Epoch: 6| Step: 5
Training loss: 2.1844241619110107
Validation loss: 2.0647348665422007

Epoch: 6| Step: 6
Training loss: 0.7513812184333801
Validation loss: 2.051178014406594

Epoch: 6| Step: 7
Training loss: 1.0886937379837036
Validation loss: 2.0523763472034084

Epoch: 6| Step: 8
Training loss: 1.0031311511993408
Validation loss: 2.030205039567845

Epoch: 6| Step: 9
Training loss: 1.5677191019058228
Validation loss: 2.0092081651892713

Epoch: 6| Step: 10
Training loss: 1.6120927333831787
Validation loss: 1.9900001684824626

Epoch: 6| Step: 11
Training loss: 1.4166595935821533
Validation loss: 1.9817701693504088

Epoch: 6| Step: 12
Training loss: 1.6946508884429932
Validation loss: 2.0154914984139065

Epoch: 6| Step: 13
Training loss: 1.3114702701568604
Validation loss: 2.0065276097225886

Epoch: 472| Step: 0
Training loss: 1.3694939613342285
Validation loss: 1.9986683617356003

Epoch: 6| Step: 1
Training loss: 1.2752960920333862
Validation loss: 2.0092978041659117

Epoch: 6| Step: 2
Training loss: 1.4902163743972778
Validation loss: 2.043224620562728

Epoch: 6| Step: 3
Training loss: 1.0201003551483154
Validation loss: 2.0952001899801274

Epoch: 6| Step: 4
Training loss: 1.6678993701934814
Validation loss: 2.1295982355712564

Epoch: 6| Step: 5
Training loss: 1.2295763492584229
Validation loss: 2.144768912305114

Epoch: 6| Step: 6
Training loss: 1.5495238304138184
Validation loss: 2.096888331956761

Epoch: 6| Step: 7
Training loss: 1.5650193691253662
Validation loss: 2.0691377629515944

Epoch: 6| Step: 8
Training loss: 1.4711166620254517
Validation loss: 2.000455733268492

Epoch: 6| Step: 9
Training loss: 1.7947635650634766
Validation loss: 1.9583802582115255

Epoch: 6| Step: 10
Training loss: 1.723050594329834
Validation loss: 1.95675826585421

Epoch: 6| Step: 11
Training loss: 1.4471073150634766
Validation loss: 1.9202235783300092

Epoch: 6| Step: 12
Training loss: 1.0959217548370361
Validation loss: 1.9231114541330645

Epoch: 6| Step: 13
Training loss: 1.0068734884262085
Validation loss: 1.9274318038776357

Epoch: 473| Step: 0
Training loss: 1.7858219146728516
Validation loss: 1.9115037405362694

Epoch: 6| Step: 1
Training loss: 1.4442980289459229
Validation loss: 1.9704056657770628

Epoch: 6| Step: 2
Training loss: 1.1762210130691528
Validation loss: 1.9847544675232263

Epoch: 6| Step: 3
Training loss: 1.0186665058135986
Validation loss: 2.059085293482709

Epoch: 6| Step: 4
Training loss: 1.9336769580841064
Validation loss: 2.1332160734361216

Epoch: 6| Step: 5
Training loss: 1.797235369682312
Validation loss: 2.1457383273750223

Epoch: 6| Step: 6
Training loss: 1.1514769792556763
Validation loss: 2.1254632037173034

Epoch: 6| Step: 7
Training loss: 1.7939560413360596
Validation loss: 2.0843755737427743

Epoch: 6| Step: 8
Training loss: 1.0552043914794922
Validation loss: 2.033493862357191

Epoch: 6| Step: 9
Training loss: 1.4804372787475586
Validation loss: 1.9971504813881331

Epoch: 6| Step: 10
Training loss: 1.3146462440490723
Validation loss: 2.001343891184817

Epoch: 6| Step: 11
Training loss: 0.987387478351593
Validation loss: 1.9871971222662157

Epoch: 6| Step: 12
Training loss: 1.318793773651123
Validation loss: 1.9800533389532438

Epoch: 6| Step: 13
Training loss: 1.7580699920654297
Validation loss: 1.9483633477200744

Epoch: 474| Step: 0
Training loss: 1.028160572052002
Validation loss: 1.9526513635471303

Epoch: 6| Step: 1
Training loss: 1.0937252044677734
Validation loss: 1.9598122565977034

Epoch: 6| Step: 2
Training loss: 1.5091142654418945
Validation loss: 1.9540407426895634

Epoch: 6| Step: 3
Training loss: 2.1501197814941406
Validation loss: 1.9770327985927623

Epoch: 6| Step: 4
Training loss: 1.213907241821289
Validation loss: 1.9803186103861818

Epoch: 6| Step: 5
Training loss: 1.655369758605957
Validation loss: 1.9907099764834169

Epoch: 6| Step: 6
Training loss: 0.9783849716186523
Validation loss: 2.039021363822363

Epoch: 6| Step: 7
Training loss: 1.6070622205734253
Validation loss: 2.079050669106104

Epoch: 6| Step: 8
Training loss: 1.3318694829940796
Validation loss: 2.0703235505729594

Epoch: 6| Step: 9
Training loss: 1.283332347869873
Validation loss: 2.0558047320253108

Epoch: 6| Step: 10
Training loss: 1.4987527132034302
Validation loss: 2.0234613264760664

Epoch: 6| Step: 11
Training loss: 1.2994023561477661
Validation loss: 2.0246349406498734

Epoch: 6| Step: 12
Training loss: 1.822655439376831
Validation loss: 1.9984048156328098

Epoch: 6| Step: 13
Training loss: 0.9297214150428772
Validation loss: 1.9910410091441164

Epoch: 475| Step: 0
Training loss: 1.4782071113586426
Validation loss: 1.9800499613567064

Epoch: 6| Step: 1
Training loss: 1.8158035278320312
Validation loss: 1.9808083016385314

Epoch: 6| Step: 2
Training loss: 1.2266979217529297
Validation loss: 1.9732749718491749

Epoch: 6| Step: 3
Training loss: 1.5076580047607422
Validation loss: 1.9833633720233876

Epoch: 6| Step: 4
Training loss: 1.2029571533203125
Validation loss: 1.9744650189594557

Epoch: 6| Step: 5
Training loss: 1.5844088792800903
Validation loss: 1.9813489772940194

Epoch: 6| Step: 6
Training loss: 1.0891366004943848
Validation loss: 2.025161443218108

Epoch: 6| Step: 7
Training loss: 1.0968797206878662
Validation loss: 2.0452621880398003

Epoch: 6| Step: 8
Training loss: 1.4600054025650024
Validation loss: 2.083592076455393

Epoch: 6| Step: 9
Training loss: 1.3033709526062012
Validation loss: 2.109537260506743

Epoch: 6| Step: 10
Training loss: 1.1022000312805176
Validation loss: 2.092857350585281

Epoch: 6| Step: 11
Training loss: 1.7806396484375
Validation loss: 2.051149029885569

Epoch: 6| Step: 12
Training loss: 1.2713334560394287
Validation loss: 2.004972791159025

Epoch: 6| Step: 13
Training loss: 1.6063647270202637
Validation loss: 1.9770705071828698

Epoch: 476| Step: 0
Training loss: 1.3384861946105957
Validation loss: 1.9647062516981555

Epoch: 6| Step: 1
Training loss: 0.9861269593238831
Validation loss: 1.9284026853499874

Epoch: 6| Step: 2
Training loss: 1.2136379480361938
Validation loss: 1.9443433900033273

Epoch: 6| Step: 3
Training loss: 1.3964476585388184
Validation loss: 1.9401299927824287

Epoch: 6| Step: 4
Training loss: 1.687488079071045
Validation loss: 1.9646515628342986

Epoch: 6| Step: 5
Training loss: 1.6115525960922241
Validation loss: 1.9664333763942923

Epoch: 6| Step: 6
Training loss: 1.777167797088623
Validation loss: 1.9902355068473405

Epoch: 6| Step: 7
Training loss: 1.258502721786499
Validation loss: 1.9855547720386135

Epoch: 6| Step: 8
Training loss: 1.7819514274597168
Validation loss: 1.9887352758838284

Epoch: 6| Step: 9
Training loss: 1.2881574630737305
Validation loss: 2.001036843945903

Epoch: 6| Step: 10
Training loss: 1.2502923011779785
Validation loss: 2.0110383931026665

Epoch: 6| Step: 11
Training loss: 1.5091216564178467
Validation loss: 1.9869023343568206

Epoch: 6| Step: 12
Training loss: 1.2989137172698975
Validation loss: 2.0367296844400387

Epoch: 6| Step: 13
Training loss: 0.7317649126052856
Validation loss: 2.0729070940325336

Epoch: 477| Step: 0
Training loss: 1.1744167804718018
Validation loss: 2.045397743102043

Epoch: 6| Step: 1
Training loss: 1.486035704612732
Validation loss: 2.093740273547429

Epoch: 6| Step: 2
Training loss: 1.1444511413574219
Validation loss: 2.069538943229183

Epoch: 6| Step: 3
Training loss: 1.1512188911437988
Validation loss: 2.028744487352269

Epoch: 6| Step: 4
Training loss: 1.713266372680664
Validation loss: 2.0216976852827173

Epoch: 6| Step: 5
Training loss: 1.16648268699646
Validation loss: 2.034116892404454

Epoch: 6| Step: 6
Training loss: 1.8698246479034424
Validation loss: 1.9987520581932479

Epoch: 6| Step: 7
Training loss: 1.0617122650146484
Validation loss: 1.9642541498266242

Epoch: 6| Step: 8
Training loss: 1.1424965858459473
Validation loss: 1.9839197204959007

Epoch: 6| Step: 9
Training loss: 1.5807313919067383
Validation loss: 1.9730857649157125

Epoch: 6| Step: 10
Training loss: 1.2620773315429688
Validation loss: 1.9611954240388767

Epoch: 6| Step: 11
Training loss: 1.7416377067565918
Validation loss: 1.9435080482113747

Epoch: 6| Step: 12
Training loss: 1.4254721403121948
Validation loss: 1.9488573048704414

Epoch: 6| Step: 13
Training loss: 1.3360934257507324
Validation loss: 1.9667363025808846

Epoch: 478| Step: 0
Training loss: 1.273345947265625
Validation loss: 1.9870260992357809

Epoch: 6| Step: 1
Training loss: 1.0124356746673584
Validation loss: 1.991747094738868

Epoch: 6| Step: 2
Training loss: 1.7360252141952515
Validation loss: 2.0465762845931517

Epoch: 6| Step: 3
Training loss: 1.5814073085784912
Validation loss: 2.066249921757688

Epoch: 6| Step: 4
Training loss: 1.4433296918869019
Validation loss: 2.0399609176061486

Epoch: 6| Step: 5
Training loss: 1.031889796257019
Validation loss: 2.036194916694395

Epoch: 6| Step: 6
Training loss: 1.0116658210754395
Validation loss: 2.0300431469435334

Epoch: 6| Step: 7
Training loss: 1.98958420753479
Validation loss: 2.0376242783761795

Epoch: 6| Step: 8
Training loss: 1.0116970539093018
Validation loss: 2.046924114227295

Epoch: 6| Step: 9
Training loss: 1.775513768196106
Validation loss: 2.0517602928223146

Epoch: 6| Step: 10
Training loss: 1.1208888292312622
Validation loss: 2.026133014309791

Epoch: 6| Step: 11
Training loss: 1.2838382720947266
Validation loss: 2.0324695789685814

Epoch: 6| Step: 12
Training loss: 1.6549102067947388
Validation loss: 2.012065943851266

Epoch: 6| Step: 13
Training loss: 1.6429508924484253
Validation loss: 1.9878911690045429

Epoch: 479| Step: 0
Training loss: 1.130744218826294
Validation loss: 1.9662027128281132

Epoch: 6| Step: 1
Training loss: 0.9362069368362427
Validation loss: 1.9725366343734085

Epoch: 6| Step: 2
Training loss: 1.689814567565918
Validation loss: 1.99677748064841

Epoch: 6| Step: 3
Training loss: 1.347383975982666
Validation loss: 1.9787525605129939

Epoch: 6| Step: 4
Training loss: 1.300473690032959
Validation loss: 2.004616536119933

Epoch: 6| Step: 5
Training loss: 1.4043898582458496
Validation loss: 2.012625044392001

Epoch: 6| Step: 6
Training loss: 0.9331369400024414
Validation loss: 2.019293290312572

Epoch: 6| Step: 7
Training loss: 1.7134348154067993
Validation loss: 2.0294873201718895

Epoch: 6| Step: 8
Training loss: 1.480970859527588
Validation loss: 2.0527336699988252

Epoch: 6| Step: 9
Training loss: 1.0315580368041992
Validation loss: 2.0768450947218042

Epoch: 6| Step: 10
Training loss: 1.8136858940124512
Validation loss: 2.1074371184072187

Epoch: 6| Step: 11
Training loss: 1.4295225143432617
Validation loss: 2.15026286596893

Epoch: 6| Step: 12
Training loss: 2.271592617034912
Validation loss: 2.101164310209213

Epoch: 6| Step: 13
Training loss: 0.9443371891975403
Validation loss: 2.0525105525088567

Epoch: 480| Step: 0
Training loss: 1.7412710189819336
Validation loss: 2.0445863892955165

Epoch: 6| Step: 1
Training loss: 1.0521286725997925
Validation loss: 2.002302728673463

Epoch: 6| Step: 2
Training loss: 1.364870548248291
Validation loss: 1.9722719525778165

Epoch: 6| Step: 3
Training loss: 1.3992785215377808
Validation loss: 1.9941964162293302

Epoch: 6| Step: 4
Training loss: 1.302983283996582
Validation loss: 1.9853172340700704

Epoch: 6| Step: 5
Training loss: 0.9952389001846313
Validation loss: 1.9821425548163794

Epoch: 6| Step: 6
Training loss: 1.3307558298110962
Validation loss: 1.9871567192898

Epoch: 6| Step: 7
Training loss: 1.4859821796417236
Validation loss: 1.9944739162280996

Epoch: 6| Step: 8
Training loss: 1.1417628526687622
Validation loss: 2.02932547753857

Epoch: 6| Step: 9
Training loss: 1.4853966236114502
Validation loss: 2.066381892850322

Epoch: 6| Step: 10
Training loss: 1.3077492713928223
Validation loss: 2.083516543911349

Epoch: 6| Step: 11
Training loss: 1.5957695245742798
Validation loss: 2.04183046279415

Epoch: 6| Step: 12
Training loss: 1.9108390808105469
Validation loss: 2.030255103623995

Epoch: 6| Step: 13
Training loss: 1.0538522005081177
Validation loss: 2.0220333914602957

Epoch: 481| Step: 0
Training loss: 1.2689435482025146
Validation loss: 1.9532823485712851

Epoch: 6| Step: 1
Training loss: 1.3636654615402222
Validation loss: 1.933170969768237

Epoch: 6| Step: 2
Training loss: 1.1921758651733398
Validation loss: 1.928825278435984

Epoch: 6| Step: 3
Training loss: 1.699127197265625
Validation loss: 1.9354807804989558

Epoch: 6| Step: 4
Training loss: 1.330240249633789
Validation loss: 1.9491931828119422

Epoch: 6| Step: 5
Training loss: 1.1861698627471924
Validation loss: 1.9480184816545056

Epoch: 6| Step: 6
Training loss: 1.3663079738616943
Validation loss: 1.9417202754687237

Epoch: 6| Step: 7
Training loss: 1.3012983798980713
Validation loss: 2.00970035470942

Epoch: 6| Step: 8
Training loss: 1.241410255432129
Validation loss: 2.0477614107952324

Epoch: 6| Step: 9
Training loss: 1.6503117084503174
Validation loss: 2.108532977360551

Epoch: 6| Step: 10
Training loss: 1.445526123046875
Validation loss: 2.1714110374450684

Epoch: 6| Step: 11
Training loss: 1.2340145111083984
Validation loss: 2.1814478725515385

Epoch: 6| Step: 12
Training loss: 1.5706934928894043
Validation loss: 2.168611926417197

Epoch: 6| Step: 13
Training loss: 1.4957506656646729
Validation loss: 2.117010194768188

Epoch: 482| Step: 0
Training loss: 1.0816375017166138
Validation loss: 2.076543261927943

Epoch: 6| Step: 1
Training loss: 1.968717336654663
Validation loss: 2.003961358019101

Epoch: 6| Step: 2
Training loss: 0.9847418069839478
Validation loss: 1.957292756726665

Epoch: 6| Step: 3
Training loss: 2.1456637382507324
Validation loss: 1.9461805333373368

Epoch: 6| Step: 4
Training loss: 1.1833770275115967
Validation loss: 1.9436946838132796

Epoch: 6| Step: 5
Training loss: 1.1511259078979492
Validation loss: 1.9384519156589304

Epoch: 6| Step: 6
Training loss: 1.6546504497528076
Validation loss: 1.939020223515008

Epoch: 6| Step: 7
Training loss: 1.9183263778686523
Validation loss: 1.9957853004496584

Epoch: 6| Step: 8
Training loss: 1.334551215171814
Validation loss: 2.003977847355668

Epoch: 6| Step: 9
Training loss: 1.298707365989685
Validation loss: 2.0479871124349613

Epoch: 6| Step: 10
Training loss: 0.6953432559967041
Validation loss: 2.068230903276833

Epoch: 6| Step: 11
Training loss: 1.2873060703277588
Validation loss: 2.0706422944222727

Epoch: 6| Step: 12
Training loss: 1.1280081272125244
Validation loss: 2.0684850421003116

Epoch: 6| Step: 13
Training loss: 1.3244963884353638
Validation loss: 2.043960686652891

Epoch: 483| Step: 0
Training loss: 0.9096806049346924
Validation loss: 2.0544232117232455

Epoch: 6| Step: 1
Training loss: 1.6691571474075317
Validation loss: 2.058441831219581

Epoch: 6| Step: 2
Training loss: 1.0644587278366089
Validation loss: 1.998524114649783

Epoch: 6| Step: 3
Training loss: 1.4517852067947388
Validation loss: 1.9982546914008357

Epoch: 6| Step: 4
Training loss: 1.4009463787078857
Validation loss: 1.9867756802548644

Epoch: 6| Step: 5
Training loss: 1.1887590885162354
Validation loss: 1.9900835252577258

Epoch: 6| Step: 6
Training loss: 0.7697279453277588
Validation loss: 1.9854415924318376

Epoch: 6| Step: 7
Training loss: 1.6744451522827148
Validation loss: 1.9802907025942238

Epoch: 6| Step: 8
Training loss: 1.3328121900558472
Validation loss: 2.01528650329959

Epoch: 6| Step: 9
Training loss: 2.028087854385376
Validation loss: 2.0337902961238736

Epoch: 6| Step: 10
Training loss: 1.2561371326446533
Validation loss: 2.0223764988683883

Epoch: 6| Step: 11
Training loss: 1.7858240604400635
Validation loss: 2.066608380245906

Epoch: 6| Step: 12
Training loss: 1.4312437772750854
Validation loss: 2.075309358617311

Epoch: 6| Step: 13
Training loss: 0.872032880783081
Validation loss: 2.0528757302991805

Epoch: 484| Step: 0
Training loss: 1.2734646797180176
Validation loss: 2.033989862729144

Epoch: 6| Step: 1
Training loss: 1.4323742389678955
Validation loss: 2.048817116727111

Epoch: 6| Step: 2
Training loss: 1.2444732189178467
Validation loss: 2.0545867104684152

Epoch: 6| Step: 3
Training loss: 1.3937146663665771
Validation loss: 2.0579469973041165

Epoch: 6| Step: 4
Training loss: 1.5581238269805908
Validation loss: 2.064395449494803

Epoch: 6| Step: 5
Training loss: 1.1273846626281738
Validation loss: 2.060012591782437

Epoch: 6| Step: 6
Training loss: 1.345635175704956
Validation loss: 2.028966542213194

Epoch: 6| Step: 7
Training loss: 1.3195371627807617
Validation loss: 2.022976556131917

Epoch: 6| Step: 8
Training loss: 1.8479862213134766
Validation loss: 1.9958715643934024

Epoch: 6| Step: 9
Training loss: 1.1162638664245605
Validation loss: 1.9353285976635513

Epoch: 6| Step: 10
Training loss: 1.5367021560668945
Validation loss: 1.9451725739304737

Epoch: 6| Step: 11
Training loss: 1.4065150022506714
Validation loss: 1.9416460965269355

Epoch: 6| Step: 12
Training loss: 1.1024285554885864
Validation loss: 1.937028879760414

Epoch: 6| Step: 13
Training loss: 1.4802542924880981
Validation loss: 1.952098987435782

Epoch: 485| Step: 0
Training loss: 0.9541794061660767
Validation loss: 1.9531371644748154

Epoch: 6| Step: 1
Training loss: 1.4307771921157837
Validation loss: 1.9938424735940912

Epoch: 6| Step: 2
Training loss: 1.2109313011169434
Validation loss: 2.0202159599591325

Epoch: 6| Step: 3
Training loss: 2.059774398803711
Validation loss: 2.0570371740607807

Epoch: 6| Step: 4
Training loss: 1.9531389474868774
Validation loss: 2.057592145858272

Epoch: 6| Step: 5
Training loss: 1.2419034242630005
Validation loss: 2.06660855841893

Epoch: 6| Step: 6
Training loss: 1.3908381462097168
Validation loss: 2.06032016072222

Epoch: 6| Step: 7
Training loss: 1.4132853746414185
Validation loss: 2.030332419180101

Epoch: 6| Step: 8
Training loss: 1.2867107391357422
Validation loss: 2.0041901103911863

Epoch: 6| Step: 9
Training loss: 0.9996650218963623
Validation loss: 2.009246672353437

Epoch: 6| Step: 10
Training loss: 1.0887175798416138
Validation loss: 2.001284715949848

Epoch: 6| Step: 11
Training loss: 1.72075617313385
Validation loss: 2.02379854776526

Epoch: 6| Step: 12
Training loss: 1.2665989398956299
Validation loss: 2.0158724374668573

Epoch: 6| Step: 13
Training loss: 0.6954850554466248
Validation loss: 2.0045528411865234

Epoch: 486| Step: 0
Training loss: 1.3281750679016113
Validation loss: 1.9939173011369602

Epoch: 6| Step: 1
Training loss: 1.3738195896148682
Validation loss: 2.0077348421978694

Epoch: 6| Step: 2
Training loss: 1.4665076732635498
Validation loss: 1.9825947617971769

Epoch: 6| Step: 3
Training loss: 1.7157894372940063
Validation loss: 2.0018154805706394

Epoch: 6| Step: 4
Training loss: 0.4901890158653259
Validation loss: 2.007292104023759

Epoch: 6| Step: 5
Training loss: 1.3546254634857178
Validation loss: 2.033741343405939

Epoch: 6| Step: 6
Training loss: 1.3378053903579712
Validation loss: 2.0816645545344197

Epoch: 6| Step: 7
Training loss: 1.6293654441833496
Validation loss: 2.0609077228012906

Epoch: 6| Step: 8
Training loss: 1.2247185707092285
Validation loss: 2.0398975982460925

Epoch: 6| Step: 9
Training loss: 1.6158273220062256
Validation loss: 2.0332076857166905

Epoch: 6| Step: 10
Training loss: 1.9709928035736084
Validation loss: 2.0296961428016744

Epoch: 6| Step: 11
Training loss: 1.1935091018676758
Validation loss: 1.9800972835991972

Epoch: 6| Step: 12
Training loss: 1.1098984479904175
Validation loss: 1.9461438220034364

Epoch: 6| Step: 13
Training loss: 1.1735968589782715
Validation loss: 1.9464833031418503

Epoch: 487| Step: 0
Training loss: 1.6139495372772217
Validation loss: 1.9388545200388918

Epoch: 6| Step: 1
Training loss: 1.4613926410675049
Validation loss: 1.9549959859540385

Epoch: 6| Step: 2
Training loss: 1.280340313911438
Validation loss: 1.9868816034768217

Epoch: 6| Step: 3
Training loss: 1.531461238861084
Validation loss: 2.0046496570751233

Epoch: 6| Step: 4
Training loss: 1.6157313585281372
Validation loss: 2.0018890621841594

Epoch: 6| Step: 5
Training loss: 1.103665828704834
Validation loss: 1.9926005204518635

Epoch: 6| Step: 6
Training loss: 1.1909443140029907
Validation loss: 2.050593804287654

Epoch: 6| Step: 7
Training loss: 0.9275396466255188
Validation loss: 2.0533890237090406

Epoch: 6| Step: 8
Training loss: 0.8791882991790771
Validation loss: 2.0432341355149464

Epoch: 6| Step: 9
Training loss: 1.194401502609253
Validation loss: 1.9983790741171887

Epoch: 6| Step: 10
Training loss: 1.576448678970337
Validation loss: 1.980896706222206

Epoch: 6| Step: 11
Training loss: 1.4713118076324463
Validation loss: 1.964162503519366

Epoch: 6| Step: 12
Training loss: 1.3331315517425537
Validation loss: 1.9884655988344582

Epoch: 6| Step: 13
Training loss: 1.8877323865890503
Validation loss: 1.9820594954234299

Epoch: 488| Step: 0
Training loss: 0.6359071731567383
Validation loss: 1.966360950982699

Epoch: 6| Step: 1
Training loss: 1.3131217956542969
Validation loss: 1.9726159047054987

Epoch: 6| Step: 2
Training loss: 1.0630013942718506
Validation loss: 1.9868111559139785

Epoch: 6| Step: 3
Training loss: 1.1371703147888184
Validation loss: 2.0095436829392628

Epoch: 6| Step: 4
Training loss: 1.5965960025787354
Validation loss: 2.0115582648143975

Epoch: 6| Step: 5
Training loss: 1.1827919483184814
Validation loss: 1.9858241004328574

Epoch: 6| Step: 6
Training loss: 1.2141121625900269
Validation loss: 1.9896914112952448

Epoch: 6| Step: 7
Training loss: 1.791487693786621
Validation loss: 1.9647840274277555

Epoch: 6| Step: 8
Training loss: 1.6634652614593506
Validation loss: 1.9470664865227156

Epoch: 6| Step: 9
Training loss: 1.3747437000274658
Validation loss: 1.9433553718751477

Epoch: 6| Step: 10
Training loss: 1.4675016403198242
Validation loss: 1.9205506078658565

Epoch: 6| Step: 11
Training loss: 1.5453071594238281
Validation loss: 1.9679726157137143

Epoch: 6| Step: 12
Training loss: 1.2646976709365845
Validation loss: 1.9680787670996882

Epoch: 6| Step: 13
Training loss: 2.0885136127471924
Validation loss: 1.9777659395689606

Epoch: 489| Step: 0
Training loss: 1.1435836553573608
Validation loss: 2.012998209204725

Epoch: 6| Step: 1
Training loss: 1.6416118144989014
Validation loss: 2.0279351921491724

Epoch: 6| Step: 2
Training loss: 1.6913208961486816
Validation loss: 2.054491614782682

Epoch: 6| Step: 3
Training loss: 1.3182770013809204
Validation loss: 2.090294325223533

Epoch: 6| Step: 4
Training loss: 1.1320526599884033
Validation loss: 2.0564495542997956

Epoch: 6| Step: 5
Training loss: 0.9781994223594666
Validation loss: 2.069820821926158

Epoch: 6| Step: 6
Training loss: 1.2043827772140503
Validation loss: 2.055706820180339

Epoch: 6| Step: 7
Training loss: 1.3057222366333008
Validation loss: 1.9966555795361918

Epoch: 6| Step: 8
Training loss: 1.3123362064361572
Validation loss: 1.9602038373229325

Epoch: 6| Step: 9
Training loss: 1.7158446311950684
Validation loss: 1.976182645367038

Epoch: 6| Step: 10
Training loss: 1.4688841104507446
Validation loss: 1.9347126150643954

Epoch: 6| Step: 11
Training loss: 0.9985008239746094
Validation loss: 1.9519600842588691

Epoch: 6| Step: 12
Training loss: 1.3148149251937866
Validation loss: 1.9548377631812968

Epoch: 6| Step: 13
Training loss: 1.9231891632080078
Validation loss: 1.9729535015680457

Epoch: 490| Step: 0
Training loss: 1.143706202507019
Validation loss: 1.9622499122414538

Epoch: 6| Step: 1
Training loss: 1.381274700164795
Validation loss: 1.9736208492709744

Epoch: 6| Step: 2
Training loss: 1.427689790725708
Validation loss: 1.9781967427140923

Epoch: 6| Step: 3
Training loss: 1.3483810424804688
Validation loss: 1.9741451048081922

Epoch: 6| Step: 4
Training loss: 1.0294721126556396
Validation loss: 2.0037230009673745

Epoch: 6| Step: 5
Training loss: 1.5285305976867676
Validation loss: 2.028491635476389

Epoch: 6| Step: 6
Training loss: 1.2984284162521362
Validation loss: 2.018646909344581

Epoch: 6| Step: 7
Training loss: 0.8982325196266174
Validation loss: 1.999737593435472

Epoch: 6| Step: 8
Training loss: 1.9056763648986816
Validation loss: 1.984463486620175

Epoch: 6| Step: 9
Training loss: 1.3965139389038086
Validation loss: 1.9841240759818786

Epoch: 6| Step: 10
Training loss: 1.5416548252105713
Validation loss: 1.9690540811066986

Epoch: 6| Step: 11
Training loss: 0.7512307167053223
Validation loss: 1.9874448648063086

Epoch: 6| Step: 12
Training loss: 1.2586336135864258
Validation loss: 1.960777158378273

Epoch: 6| Step: 13
Training loss: 2.2586898803710938
Validation loss: 1.9488739480254471

Epoch: 491| Step: 0
Training loss: 1.397711992263794
Validation loss: 1.980813346883302

Epoch: 6| Step: 1
Training loss: 1.5624816417694092
Validation loss: 1.98495691181511

Epoch: 6| Step: 2
Training loss: 1.1296038627624512
Validation loss: 1.9716538485660349

Epoch: 6| Step: 3
Training loss: 0.90903639793396
Validation loss: 1.984255535628206

Epoch: 6| Step: 4
Training loss: 0.5146975517272949
Validation loss: 2.008493111979577

Epoch: 6| Step: 5
Training loss: 0.8557578921318054
Validation loss: 1.996725772016792

Epoch: 6| Step: 6
Training loss: 1.1701810359954834
Validation loss: 2.0508396843428254

Epoch: 6| Step: 7
Training loss: 1.4233043193817139
Validation loss: 2.058332807274275

Epoch: 6| Step: 8
Training loss: 1.650244951248169
Validation loss: 2.0726345841602614

Epoch: 6| Step: 9
Training loss: 0.8808528780937195
Validation loss: 2.0829121412769442

Epoch: 6| Step: 10
Training loss: 1.6865856647491455
Validation loss: 2.087288268150822

Epoch: 6| Step: 11
Training loss: 1.8845527172088623
Validation loss: 2.062566259855865

Epoch: 6| Step: 12
Training loss: 1.7854169607162476
Validation loss: 2.0210095426087737

Epoch: 6| Step: 13
Training loss: 1.9120044708251953
Validation loss: 2.0072911247130363

Epoch: 492| Step: 0
Training loss: 0.9787150025367737
Validation loss: 1.9937878142121017

Epoch: 6| Step: 1
Training loss: 1.428827166557312
Validation loss: 1.9619001585950133

Epoch: 6| Step: 2
Training loss: 1.0376307964324951
Validation loss: 1.9317809471520044

Epoch: 6| Step: 3
Training loss: 1.5042723417282104
Validation loss: 1.9416340833069177

Epoch: 6| Step: 4
Training loss: 1.186712622642517
Validation loss: 1.9447337786356609

Epoch: 6| Step: 5
Training loss: 1.026226282119751
Validation loss: 1.9305121937105734

Epoch: 6| Step: 6
Training loss: 1.7248847484588623
Validation loss: 1.9648859090702508

Epoch: 6| Step: 7
Training loss: 0.7690267562866211
Validation loss: 1.9803001239735594

Epoch: 6| Step: 8
Training loss: 1.3137433528900146
Validation loss: 2.0397947949747883

Epoch: 6| Step: 9
Training loss: 1.1132218837738037
Validation loss: 2.106507162893972

Epoch: 6| Step: 10
Training loss: 1.5578553676605225
Validation loss: 2.123079364017774

Epoch: 6| Step: 11
Training loss: 1.9988070726394653
Validation loss: 2.1032684362062843

Epoch: 6| Step: 12
Training loss: 1.5384759902954102
Validation loss: 2.0810540491534817

Epoch: 6| Step: 13
Training loss: 1.8001556396484375
Validation loss: 2.0613135842866797

Epoch: 493| Step: 0
Training loss: 1.6600275039672852
Validation loss: 2.0289238191420034

Epoch: 6| Step: 1
Training loss: 0.8038473129272461
Validation loss: 2.0327001361436743

Epoch: 6| Step: 2
Training loss: 1.1636426448822021
Validation loss: 1.9797296934230353

Epoch: 6| Step: 3
Training loss: 1.0726871490478516
Validation loss: 1.932946579430693

Epoch: 6| Step: 4
Training loss: 1.2964437007904053
Validation loss: 1.937719670675134

Epoch: 6| Step: 5
Training loss: 1.649451494216919
Validation loss: 1.969927969799247

Epoch: 6| Step: 6
Training loss: 1.7594549655914307
Validation loss: 1.95646043233974

Epoch: 6| Step: 7
Training loss: 0.998266339302063
Validation loss: 1.9519711707227974

Epoch: 6| Step: 8
Training loss: 1.8398789167404175
Validation loss: 1.960870437724616

Epoch: 6| Step: 9
Training loss: 1.3136000633239746
Validation loss: 2.0012276685366066

Epoch: 6| Step: 10
Training loss: 0.7831947207450867
Validation loss: 1.961077195341869

Epoch: 6| Step: 11
Training loss: 1.340242624282837
Validation loss: 1.9940221719844367

Epoch: 6| Step: 12
Training loss: 1.4042719602584839
Validation loss: 2.0042980947802143

Epoch: 6| Step: 13
Training loss: 1.4962934255599976
Validation loss: 1.9969355483208933

Epoch: 494| Step: 0
Training loss: 0.8529472351074219
Validation loss: 1.9829528152301747

Epoch: 6| Step: 1
Training loss: 0.969775378704071
Validation loss: 2.0155710622828495

Epoch: 6| Step: 2
Training loss: 1.3106943368911743
Validation loss: 1.9776784578959148

Epoch: 6| Step: 3
Training loss: 1.5262168645858765
Validation loss: 1.9839471552961616

Epoch: 6| Step: 4
Training loss: 1.4295508861541748
Validation loss: 1.9976542406184699

Epoch: 6| Step: 5
Training loss: 1.207115650177002
Validation loss: 1.9916093939094133

Epoch: 6| Step: 6
Training loss: 1.3018317222595215
Validation loss: 1.9712989612292218

Epoch: 6| Step: 7
Training loss: 1.284623146057129
Validation loss: 1.9854541670891546

Epoch: 6| Step: 8
Training loss: 2.2528858184814453
Validation loss: 1.9693361059311898

Epoch: 6| Step: 9
Training loss: 1.4659547805786133
Validation loss: 2.0006673797484367

Epoch: 6| Step: 10
Training loss: 0.8218609094619751
Validation loss: 1.9976064030842116

Epoch: 6| Step: 11
Training loss: 1.4540367126464844
Validation loss: 2.0039769282905002

Epoch: 6| Step: 12
Training loss: 1.1450378894805908
Validation loss: 1.9998120825777772

Epoch: 6| Step: 13
Training loss: 1.7455776929855347
Validation loss: 1.9971584594377907

Epoch: 495| Step: 0
Training loss: 1.162662148475647
Validation loss: 1.9850308843838271

Epoch: 6| Step: 1
Training loss: 0.967860221862793
Validation loss: 1.9666311176874305

Epoch: 6| Step: 2
Training loss: 1.8777439594268799
Validation loss: 1.9721358142873293

Epoch: 6| Step: 3
Training loss: 0.967460572719574
Validation loss: 1.9453368597133185

Epoch: 6| Step: 4
Training loss: 1.3564703464508057
Validation loss: 1.9588628481793147

Epoch: 6| Step: 5
Training loss: 1.2893518209457397
Validation loss: 1.971145893937798

Epoch: 6| Step: 6
Training loss: 1.4585049152374268
Validation loss: 1.975452079567858

Epoch: 6| Step: 7
Training loss: 1.752101182937622
Validation loss: 1.9590482365700506

Epoch: 6| Step: 8
Training loss: 1.385911464691162
Validation loss: 1.9570773788677749

Epoch: 6| Step: 9
Training loss: 0.7934720516204834
Validation loss: 1.9624679242410967

Epoch: 6| Step: 10
Training loss: 1.455854058265686
Validation loss: 1.9846865566827918

Epoch: 6| Step: 11
Training loss: 1.0985745191574097
Validation loss: 1.9628644476654709

Epoch: 6| Step: 12
Training loss: 1.6255528926849365
Validation loss: 1.973130682463287

Epoch: 6| Step: 13
Training loss: 1.1141581535339355
Validation loss: 1.9943959712982178

Epoch: 496| Step: 0
Training loss: 1.2199501991271973
Validation loss: 1.9680204186388242

Epoch: 6| Step: 1
Training loss: 1.8639304637908936
Validation loss: 2.0288179459110385

Epoch: 6| Step: 2
Training loss: 1.3082162141799927
Validation loss: 2.0763721248155

Epoch: 6| Step: 3
Training loss: 1.2102227210998535
Validation loss: 2.1344680068313435

Epoch: 6| Step: 4
Training loss: 0.8709840178489685
Validation loss: 2.1300985633686023

Epoch: 6| Step: 5
Training loss: 0.8533940315246582
Validation loss: 2.0940221778808104

Epoch: 6| Step: 6
Training loss: 1.4853379726409912
Validation loss: 2.063755581455846

Epoch: 6| Step: 7
Training loss: 0.9752126336097717
Validation loss: 2.0128985579295824

Epoch: 6| Step: 8
Training loss: 1.8395735025405884
Validation loss: 1.9650509934271536

Epoch: 6| Step: 9
Training loss: 1.3788878917694092
Validation loss: 1.9444944653459775

Epoch: 6| Step: 10
Training loss: 1.414982557296753
Validation loss: 1.9129216517171552

Epoch: 6| Step: 11
Training loss: 1.1219426393508911
Validation loss: 1.9011300430502942

Epoch: 6| Step: 12
Training loss: 1.7732348442077637
Validation loss: 1.9160402833774526

Epoch: 6| Step: 13
Training loss: 1.2892783880233765
Validation loss: 1.9287488998905304

Epoch: 497| Step: 0
Training loss: 1.6852355003356934
Validation loss: 1.9570255446177658

Epoch: 6| Step: 1
Training loss: 1.1981174945831299
Validation loss: 1.9367412251810874

Epoch: 6| Step: 2
Training loss: 1.5845911502838135
Validation loss: 1.95830112759785

Epoch: 6| Step: 3
Training loss: 1.0248223543167114
Validation loss: 2.007511281198071

Epoch: 6| Step: 4
Training loss: 0.8854953050613403
Validation loss: 2.0467326192445654

Epoch: 6| Step: 5
Training loss: 1.2574207782745361
Validation loss: 2.0516770924291303

Epoch: 6| Step: 6
Training loss: 1.756365418434143
Validation loss: 2.106853969635502

Epoch: 6| Step: 7
Training loss: 1.4756065607070923
Validation loss: 2.0662605057480516

Epoch: 6| Step: 8
Training loss: 0.6686756610870361
Validation loss: 2.05930781748987

Epoch: 6| Step: 9
Training loss: 1.4131077527999878
Validation loss: 2.010519899347777

Epoch: 6| Step: 10
Training loss: 1.6381499767303467
Validation loss: 1.9557713667551677

Epoch: 6| Step: 11
Training loss: 1.3478035926818848
Validation loss: 1.9457950733041252

Epoch: 6| Step: 12
Training loss: 1.6991243362426758
Validation loss: 1.9538887111089562

Epoch: 6| Step: 13
Training loss: 1.1265013217926025
Validation loss: 1.957916308474797

Epoch: 498| Step: 0
Training loss: 1.318468689918518
Validation loss: 1.9779552964754001

Epoch: 6| Step: 1
Training loss: 1.5023376941680908
Validation loss: 1.9994622917585476

Epoch: 6| Step: 2
Training loss: 1.117706060409546
Validation loss: 1.9733167630369945

Epoch: 6| Step: 3
Training loss: 1.299046277999878
Validation loss: 1.997770917031073

Epoch: 6| Step: 4
Training loss: 1.0767009258270264
Validation loss: 1.9712437878372848

Epoch: 6| Step: 5
Training loss: 1.3917396068572998
Validation loss: 1.9875397618098924

Epoch: 6| Step: 6
Training loss: 1.9569519758224487
Validation loss: 2.0199314727578113

Epoch: 6| Step: 7
Training loss: 0.8175587058067322
Validation loss: 2.061528668608717

Epoch: 6| Step: 8
Training loss: 1.7393304109573364
Validation loss: 2.0699545157852994

Epoch: 6| Step: 9
Training loss: 1.5813589096069336
Validation loss: 2.027724072497378

Epoch: 6| Step: 10
Training loss: 1.1153578758239746
Validation loss: 2.003360091999013

Epoch: 6| Step: 11
Training loss: 1.5167176723480225
Validation loss: 2.0026703470496723

Epoch: 6| Step: 12
Training loss: 1.4290250539779663
Validation loss: 1.973731134527473

Epoch: 6| Step: 13
Training loss: 0.708021879196167
Validation loss: 1.965774025968326

Epoch: 499| Step: 0
Training loss: 1.942258358001709
Validation loss: 1.9429240175472793

Epoch: 6| Step: 1
Training loss: 1.0813465118408203
Validation loss: 1.951384364917714

Epoch: 6| Step: 2
Training loss: 1.401257038116455
Validation loss: 1.9526412986939954

Epoch: 6| Step: 3
Training loss: 1.507493495941162
Validation loss: 1.9550161387330742

Epoch: 6| Step: 4
Training loss: 1.5030122995376587
Validation loss: 1.9305659430001372

Epoch: 6| Step: 5
Training loss: 0.9143167734146118
Validation loss: 1.935950106190097

Epoch: 6| Step: 6
Training loss: 1.1343965530395508
Validation loss: 1.925060749053955

Epoch: 6| Step: 7
Training loss: 1.2367382049560547
Validation loss: 1.9457221223462013

Epoch: 6| Step: 8
Training loss: 1.4316837787628174
Validation loss: 1.9275963037244734

Epoch: 6| Step: 9
Training loss: 1.5204672813415527
Validation loss: 1.9776728294228996

Epoch: 6| Step: 10
Training loss: 1.2929598093032837
Validation loss: 1.9519594266850462

Epoch: 6| Step: 11
Training loss: 1.4361953735351562
Validation loss: 2.02444206001938

Epoch: 6| Step: 12
Training loss: 1.0388318300247192
Validation loss: 2.0478944457987303

Epoch: 6| Step: 13
Training loss: 1.3387364149093628
Validation loss: 2.0374831409864527

Epoch: 500| Step: 0
Training loss: 1.1939430236816406
Validation loss: 2.050192125381962

Epoch: 6| Step: 1
Training loss: 1.422516107559204
Validation loss: 2.028784924937833

Epoch: 6| Step: 2
Training loss: 1.3523674011230469
Validation loss: 1.9923745252752816

Epoch: 6| Step: 3
Training loss: 0.970367968082428
Validation loss: 1.9955708416559363

Epoch: 6| Step: 4
Training loss: 1.34212064743042
Validation loss: 1.9838908282659387

Epoch: 6| Step: 5
Training loss: 1.1682924032211304
Validation loss: 1.9657434366082633

Epoch: 6| Step: 6
Training loss: 1.6672617197036743
Validation loss: 1.9627507514851068

Epoch: 6| Step: 7
Training loss: 1.2253438234329224
Validation loss: 1.9592634939378308

Epoch: 6| Step: 8
Training loss: 0.9281033277511597
Validation loss: 1.9573702966013262

Epoch: 6| Step: 9
Training loss: 1.2687749862670898
Validation loss: 1.9538876138707644

Epoch: 6| Step: 10
Training loss: 0.9751946926116943
Validation loss: 1.958361344952737

Epoch: 6| Step: 11
Training loss: 1.4671779870986938
Validation loss: 1.9641229414170789

Epoch: 6| Step: 12
Training loss: 1.5039689540863037
Validation loss: 1.9489890336990356

Epoch: 6| Step: 13
Training loss: 2.0473251342773438
Validation loss: 1.9486531070483628

Testing loss: 2.1678782092200386
