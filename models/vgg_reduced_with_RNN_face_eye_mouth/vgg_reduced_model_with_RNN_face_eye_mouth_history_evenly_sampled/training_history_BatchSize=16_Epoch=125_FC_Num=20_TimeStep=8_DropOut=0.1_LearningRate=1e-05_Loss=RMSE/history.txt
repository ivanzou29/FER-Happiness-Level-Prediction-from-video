Epoch: 1| Step: 0
Training loss: 6.1856100875953794
Validation loss: 5.814971431931143

Epoch: 6| Step: 1
Training loss: 6.201751633823844
Validation loss: 5.806031108997901

Epoch: 6| Step: 2
Training loss: 5.9504007028241315
Validation loss: 5.798333571418863

Epoch: 6| Step: 3
Training loss: 6.550341869488777
Validation loss: 5.790850151168785

Epoch: 6| Step: 4
Training loss: 4.540776203365756
Validation loss: 5.782615266721162

Epoch: 6| Step: 5
Training loss: 5.594222235325738
Validation loss: 5.774337617350134

Epoch: 6| Step: 6
Training loss: 5.764654310437674
Validation loss: 5.764848275006621

Epoch: 6| Step: 7
Training loss: 5.506083158807991
Validation loss: 5.754759756600904

Epoch: 6| Step: 8
Training loss: 6.429631136789713
Validation loss: 5.7435198342829095

Epoch: 6| Step: 9
Training loss: 6.2131500333890495
Validation loss: 5.732277987154104

Epoch: 6| Step: 10
Training loss: 5.581456148755315
Validation loss: 5.7192193245605525

Epoch: 6| Step: 11
Training loss: 5.019301733565947
Validation loss: 5.70576596562838

Epoch: 6| Step: 12
Training loss: 5.458363113127951
Validation loss: 5.691499086859115

Epoch: 6| Step: 13
Training loss: 5.717271290530254
Validation loss: 5.67636664311837

Epoch: 2| Step: 0
Training loss: 6.087222628374337
Validation loss: 5.6597424728877135

Epoch: 6| Step: 1
Training loss: 4.752003297489962
Validation loss: 5.642453733009515

Epoch: 6| Step: 2
Training loss: 5.522976652395452
Validation loss: 5.624176916794832

Epoch: 6| Step: 3
Training loss: 5.364139140976386
Validation loss: 5.604264153238251

Epoch: 6| Step: 4
Training loss: 5.577698250482675
Validation loss: 5.583085608217335

Epoch: 6| Step: 5
Training loss: 5.02176924512849
Validation loss: 5.561520976894216

Epoch: 6| Step: 6
Training loss: 6.128735395861876
Validation loss: 5.538952767630743

Epoch: 6| Step: 7
Training loss: 5.09779150772426
Validation loss: 5.51505297374392

Epoch: 6| Step: 8
Training loss: 5.0804445573822345
Validation loss: 5.490237531551165

Epoch: 6| Step: 9
Training loss: 6.542950967793001
Validation loss: 5.464141244413651

Epoch: 6| Step: 10
Training loss: 7.117605555092992
Validation loss: 5.438371817806211

Epoch: 6| Step: 11
Training loss: 5.499793655686271
Validation loss: 5.410186565393162

Epoch: 6| Step: 12
Training loss: 3.529797820874448
Validation loss: 5.382514700932978

Epoch: 6| Step: 13
Training loss: 5.8687116367764025
Validation loss: 5.354838067469958

Epoch: 3| Step: 0
Training loss: 5.491109945802365
Validation loss: 5.325742816508233

Epoch: 6| Step: 1
Training loss: 4.907515635919755
Validation loss: 5.2980219658268

Epoch: 6| Step: 2
Training loss: 4.888265899980394
Validation loss: 5.269130514249802

Epoch: 6| Step: 3
Training loss: 4.361911049685802
Validation loss: 5.241729337300424

Epoch: 6| Step: 4
Training loss: 4.795677806056912
Validation loss: 5.213847666126058

Epoch: 6| Step: 5
Training loss: 5.321566575364818
Validation loss: 5.186780403003249

Epoch: 6| Step: 6
Training loss: 4.585059424694354
Validation loss: 5.15929645472505

Epoch: 6| Step: 7
Training loss: 5.377442625512041
Validation loss: 5.131501656551473

Epoch: 6| Step: 8
Training loss: 5.57443824982818
Validation loss: 5.1063411672225545

Epoch: 6| Step: 9
Training loss: 4.160801052215566
Validation loss: 5.080751942067353

Epoch: 6| Step: 10
Training loss: 6.264032708561297
Validation loss: 5.055738622401036

Epoch: 6| Step: 11
Training loss: 5.0801580966167865
Validation loss: 5.031474891160644

Epoch: 6| Step: 12
Training loss: 5.607016064752323
Validation loss: 5.008504200382236

Epoch: 6| Step: 13
Training loss: 6.572893323015534
Validation loss: 4.985378795265485

Epoch: 4| Step: 0
Training loss: 5.110945993787844
Validation loss: 4.962706481699644

Epoch: 6| Step: 1
Training loss: 5.198840327430923
Validation loss: 4.940067473683899

Epoch: 6| Step: 2
Training loss: 5.076674973265443
Validation loss: 4.917291163930784

Epoch: 6| Step: 3
Training loss: 4.019184360790804
Validation loss: 4.89469430520575

Epoch: 6| Step: 4
Training loss: 5.308482008228855
Validation loss: 4.874729095327779

Epoch: 6| Step: 5
Training loss: 4.253611656896472
Validation loss: 4.851834831344318

Epoch: 6| Step: 6
Training loss: 4.346633941745631
Validation loss: 4.831851071406995

Epoch: 6| Step: 7
Training loss: 5.346610391246145
Validation loss: 4.811723362774741

Epoch: 6| Step: 8
Training loss: 4.595861248209411
Validation loss: 4.792162222826524

Epoch: 6| Step: 9
Training loss: 4.900059773606044
Validation loss: 4.772606314909287

Epoch: 6| Step: 10
Training loss: 4.997719244524919
Validation loss: 4.755556939560311

Epoch: 6| Step: 11
Training loss: 5.548683752741677
Validation loss: 4.737877545589337

Epoch: 6| Step: 12
Training loss: 4.740438374395907
Validation loss: 4.722136789924818

Epoch: 6| Step: 13
Training loss: 5.16158430277453
Validation loss: 4.702811120601263

Epoch: 5| Step: 0
Training loss: 4.848312296650711
Validation loss: 4.6833938826522905

Epoch: 6| Step: 1
Training loss: 4.732592760276247
Validation loss: 4.663807396609382

Epoch: 6| Step: 2
Training loss: 4.933312294030218
Validation loss: 4.642770996295206

Epoch: 6| Step: 3
Training loss: 4.1372450366796345
Validation loss: 4.620791495179722

Epoch: 6| Step: 4
Training loss: 4.414644942214528
Validation loss: 4.599576994469728

Epoch: 6| Step: 5
Training loss: 5.254742977633286
Validation loss: 4.576824929419507

Epoch: 6| Step: 6
Training loss: 4.7602993584111335
Validation loss: 4.553563073341529

Epoch: 6| Step: 7
Training loss: 4.742040289364593
Validation loss: 4.535828575561076

Epoch: 6| Step: 8
Training loss: 3.468749587600271
Validation loss: 4.51999202631375

Epoch: 6| Step: 9
Training loss: 5.007723374548168
Validation loss: 4.502665050718438

Epoch: 6| Step: 10
Training loss: 3.8875565895794515
Validation loss: 4.484353438354807

Epoch: 6| Step: 11
Training loss: 5.2682148255476555
Validation loss: 4.463050912467698

Epoch: 6| Step: 12
Training loss: 4.520378171916446
Validation loss: 4.441425369586197

Epoch: 6| Step: 13
Training loss: 4.976009416013192
Validation loss: 4.423973724968867

Epoch: 6| Step: 0
Training loss: 4.958462219272832
Validation loss: 4.400055042791402

Epoch: 6| Step: 1
Training loss: 5.095092596498569
Validation loss: 4.372380635397834

Epoch: 6| Step: 2
Training loss: 4.689459022604059
Validation loss: 4.344082406262924

Epoch: 6| Step: 3
Training loss: 4.242447369169803
Validation loss: 4.325191489438101

Epoch: 6| Step: 4
Training loss: 4.332664120180088
Validation loss: 4.30599906949093

Epoch: 6| Step: 5
Training loss: 3.8203219860247772
Validation loss: 4.290310552334846

Epoch: 6| Step: 6
Training loss: 5.096348386464636
Validation loss: 4.274255216791737

Epoch: 6| Step: 7
Training loss: 4.787121328014453
Validation loss: 4.26235656997364

Epoch: 6| Step: 8
Training loss: 3.69079636475535
Validation loss: 4.246934828973326

Epoch: 6| Step: 9
Training loss: 3.8139295555614496
Validation loss: 4.229945342019791

Epoch: 6| Step: 10
Training loss: 4.298508656064306
Validation loss: 4.218794953331971

Epoch: 6| Step: 11
Training loss: 3.1899791874699903
Validation loss: 4.206252156206352

Epoch: 6| Step: 12
Training loss: 4.113499881045617
Validation loss: 4.199335480441431

Epoch: 6| Step: 13
Training loss: 5.489602751821185
Validation loss: 4.186588286669466

Epoch: 7| Step: 0
Training loss: 4.408057525217869
Validation loss: 4.173335059350147

Epoch: 6| Step: 1
Training loss: 4.242151081076408
Validation loss: 4.169343282257876

Epoch: 6| Step: 2
Training loss: 4.984064265882345
Validation loss: 4.165314920668512

Epoch: 6| Step: 3
Training loss: 3.970795592335168
Validation loss: 4.146768387925534

Epoch: 6| Step: 4
Training loss: 4.835520983678362
Validation loss: 4.129697901929582

Epoch: 6| Step: 5
Training loss: 4.80679458687798
Validation loss: 4.1171112772672664

Epoch: 6| Step: 6
Training loss: 3.4372145100730673
Validation loss: 4.109415520216727

Epoch: 6| Step: 7
Training loss: 3.8155930276416914
Validation loss: 4.104368564771543

Epoch: 6| Step: 8
Training loss: 4.692939145772907
Validation loss: 4.091675264634234

Epoch: 6| Step: 9
Training loss: 3.5477742807007546
Validation loss: 4.085997584785126

Epoch: 6| Step: 10
Training loss: 4.6755913589913325
Validation loss: 4.088086498228122

Epoch: 6| Step: 11
Training loss: 3.0790733774082675
Validation loss: 4.076355597400088

Epoch: 6| Step: 12
Training loss: 3.7922205398182776
Validation loss: 4.065766453032642

Epoch: 6| Step: 13
Training loss: 5.028106275942064
Validation loss: 4.067783244048003

Epoch: 8| Step: 0
Training loss: 5.38975486919849
Validation loss: 4.053377373761192

Epoch: 6| Step: 1
Training loss: 2.793900426446066
Validation loss: 4.051428163025752

Epoch: 6| Step: 2
Training loss: 3.2506097074947315
Validation loss: 4.056088648716595

Epoch: 6| Step: 3
Training loss: 4.122726044851095
Validation loss: 4.048072184600622

Epoch: 6| Step: 4
Training loss: 4.986647132862475
Validation loss: 4.038189156390272

Epoch: 6| Step: 5
Training loss: 4.791341665552007
Validation loss: 4.024218497064468

Epoch: 6| Step: 6
Training loss: 4.74815292585184
Validation loss: 4.024226072255061

Epoch: 6| Step: 7
Training loss: 4.496076781027926
Validation loss: 4.013287284151359

Epoch: 6| Step: 8
Training loss: 3.8323137060625405
Validation loss: 4.0081332872984845

Epoch: 6| Step: 9
Training loss: 4.995300373137845
Validation loss: 4.005831285219816

Epoch: 6| Step: 10
Training loss: 3.2975315687679907
Validation loss: 4.0040359388828

Epoch: 6| Step: 11
Training loss: 3.305003338233543
Validation loss: 3.9969109046043845

Epoch: 6| Step: 12
Training loss: 2.5579758691551757
Validation loss: 3.990401544458697

Epoch: 6| Step: 13
Training loss: 4.871927711539329
Validation loss: 3.9832066701208677

Epoch: 9| Step: 0
Training loss: 4.389649415148668
Validation loss: 3.9776033383138407

Epoch: 6| Step: 1
Training loss: 3.9883375621560155
Validation loss: 3.976813980177989

Epoch: 6| Step: 2
Training loss: 4.37040687325482
Validation loss: 3.973427900885565

Epoch: 6| Step: 3
Training loss: 3.8567750644424517
Validation loss: 3.964099328597569

Epoch: 6| Step: 4
Training loss: 4.3447343547988675
Validation loss: 3.961096402322819

Epoch: 6| Step: 5
Training loss: 4.1866873336897426
Validation loss: 3.963389533363468

Epoch: 6| Step: 6
Training loss: 3.9427485529042077
Validation loss: 3.963574325898921

Epoch: 6| Step: 7
Training loss: 3.8488227431487037
Validation loss: 3.954080570177086

Epoch: 6| Step: 8
Training loss: 4.2160966229016354
Validation loss: 3.944718573413

Epoch: 6| Step: 9
Training loss: 3.6000250391619186
Validation loss: 3.9417653899239307

Epoch: 6| Step: 10
Training loss: 4.0786104461429895
Validation loss: 3.93948481821224

Epoch: 6| Step: 11
Training loss: 4.55040590760321
Validation loss: 3.935158729654641

Epoch: 6| Step: 12
Training loss: 4.3472109392620295
Validation loss: 3.9304459490112786

Epoch: 6| Step: 13
Training loss: 3.314957624714063
Validation loss: 3.92571402161432

Epoch: 10| Step: 0
Training loss: 4.282279454669074
Validation loss: 3.924282356004072

Epoch: 6| Step: 1
Training loss: 5.125380897323765
Validation loss: 3.920030354283306

Epoch: 6| Step: 2
Training loss: 4.143107580498482
Validation loss: 3.9144308812419735

Epoch: 6| Step: 3
Training loss: 3.403080016400211
Validation loss: 3.9089322633231136

Epoch: 6| Step: 4
Training loss: 3.373213542449738
Validation loss: 3.9101188051165545

Epoch: 6| Step: 5
Training loss: 4.5712902099242845
Validation loss: 3.906777945988775

Epoch: 6| Step: 6
Training loss: 4.380060157885316
Validation loss: 3.900085202283728

Epoch: 6| Step: 7
Training loss: 3.743630658573639
Validation loss: 3.8978004922361382

Epoch: 6| Step: 8
Training loss: 3.3775870686227956
Validation loss: 3.9007201892866306

Epoch: 6| Step: 9
Training loss: 3.813192961205505
Validation loss: 3.8947321136185793

Epoch: 6| Step: 10
Training loss: 3.7368204577125073
Validation loss: 3.8898371247008874

Epoch: 6| Step: 11
Training loss: 4.214133668609041
Validation loss: 3.886039088663005

Epoch: 6| Step: 12
Training loss: 3.6543858658492203
Validation loss: 3.8826113366683996

Epoch: 6| Step: 13
Training loss: 5.008371021469585
Validation loss: 3.877283979917163

Epoch: 11| Step: 0
Training loss: 4.26153144459781
Validation loss: 3.8738879163732123

Epoch: 6| Step: 1
Training loss: 4.735612864806652
Validation loss: 3.874318282874451

Epoch: 6| Step: 2
Training loss: 3.7982210512681953
Validation loss: 3.8677547200850064

Epoch: 6| Step: 3
Training loss: 2.9702620018886012
Validation loss: 3.8666427644628043

Epoch: 6| Step: 4
Training loss: 4.351044382586585
Validation loss: 3.863340115427135

Epoch: 6| Step: 5
Training loss: 4.876235414124799
Validation loss: 3.8580930727301963

Epoch: 6| Step: 6
Training loss: 4.109420486024402
Validation loss: 3.8605319849588278

Epoch: 6| Step: 7
Training loss: 4.134078237619102
Validation loss: 3.8743276829887496

Epoch: 6| Step: 8
Training loss: 4.684868646203193
Validation loss: 3.87364706528431

Epoch: 6| Step: 9
Training loss: 2.8070435895046066
Validation loss: 3.864589459752408

Epoch: 6| Step: 10
Training loss: 3.6733810907249076
Validation loss: 3.85623170738597

Epoch: 6| Step: 11
Training loss: 3.9386898846580096
Validation loss: 3.8497022337043574

Epoch: 6| Step: 12
Training loss: 3.9542810008834417
Validation loss: 3.849688142553449

Epoch: 6| Step: 13
Training loss: 3.0620721012050836
Validation loss: 3.8461641589958058

Epoch: 12| Step: 0
Training loss: 4.288041568284175
Validation loss: 3.84413330610678

Epoch: 6| Step: 1
Training loss: 4.024489063507322
Validation loss: 3.837569961693068

Epoch: 6| Step: 2
Training loss: 4.60182901591835
Validation loss: 3.834424587594732

Epoch: 6| Step: 3
Training loss: 4.336936601882153
Validation loss: 3.832971426495419

Epoch: 6| Step: 4
Training loss: 2.320463027952184
Validation loss: 3.8295226762810093

Epoch: 6| Step: 5
Training loss: 3.3740713466660095
Validation loss: 3.8262888037443417

Epoch: 6| Step: 6
Training loss: 4.504622098968636
Validation loss: 3.8193436176693116

Epoch: 6| Step: 7
Training loss: 3.8225146228617866
Validation loss: 3.8169939763696332

Epoch: 6| Step: 8
Training loss: 3.714331558489576
Validation loss: 3.8163725821389294

Epoch: 6| Step: 9
Training loss: 3.31841829010752
Validation loss: 3.8152954622538857

Epoch: 6| Step: 10
Training loss: 4.562398412958304
Validation loss: 3.814211499733099

Epoch: 6| Step: 11
Training loss: 4.23789893328928
Validation loss: 3.8053770616016647

Epoch: 6| Step: 12
Training loss: 3.8763500446004517
Validation loss: 3.802530699923652

Epoch: 6| Step: 13
Training loss: 4.533985233183558
Validation loss: 3.7985120389219422

Epoch: 13| Step: 0
Training loss: 3.4987061697670074
Validation loss: 3.7987333019381855

Epoch: 6| Step: 1
Training loss: 4.714176614332883
Validation loss: 3.7963599703040027

Epoch: 6| Step: 2
Training loss: 3.6293701926505504
Validation loss: 3.7956096485782047

Epoch: 6| Step: 3
Training loss: 4.04777275349247
Validation loss: 3.789438400000542

Epoch: 6| Step: 4
Training loss: 3.9541829619693263
Validation loss: 3.787213700637086

Epoch: 6| Step: 5
Training loss: 3.689146547115437
Validation loss: 3.7834139077863327

Epoch: 6| Step: 6
Training loss: 4.596964016693667
Validation loss: 3.7854405688579127

Epoch: 6| Step: 7
Training loss: 3.773937247534415
Validation loss: 3.7815189704906267

Epoch: 6| Step: 8
Training loss: 3.4092492014808555
Validation loss: 3.7783130781841234

Epoch: 6| Step: 9
Training loss: 3.937145156614489
Validation loss: 3.776058717999628

Epoch: 6| Step: 10
Training loss: 3.360820512495708
Validation loss: 3.77618230244514

Epoch: 6| Step: 11
Training loss: 4.3923857609891055
Validation loss: 3.7690684575181868

Epoch: 6| Step: 12
Training loss: 3.5201722978558587
Validation loss: 3.764463448158721

Epoch: 6| Step: 13
Training loss: 4.951543802290451
Validation loss: 3.7636897021236275

Epoch: 14| Step: 0
Training loss: 3.7503036376095706
Validation loss: 3.7621278109883316

Epoch: 6| Step: 1
Training loss: 3.704521334431851
Validation loss: 3.756958962855103

Epoch: 6| Step: 2
Training loss: 3.621636507412262
Validation loss: 3.7593410220328427

Epoch: 6| Step: 3
Training loss: 4.873820235476904
Validation loss: 3.755278455340024

Epoch: 6| Step: 4
Training loss: 3.3822632799679466
Validation loss: 3.7527345989057563

Epoch: 6| Step: 5
Training loss: 3.9644472121208616
Validation loss: 3.7483117545317017

Epoch: 6| Step: 6
Training loss: 4.2665502641614585
Validation loss: 3.74584237146344

Epoch: 6| Step: 7
Training loss: 4.1793094071834025
Validation loss: 3.7415378515403876

Epoch: 6| Step: 8
Training loss: 3.9519892934584666
Validation loss: 3.740662207678709

Epoch: 6| Step: 9
Training loss: 3.5699003219579986
Validation loss: 3.741426772711284

Epoch: 6| Step: 10
Training loss: 4.6388104420093015
Validation loss: 3.7356584701229076

Epoch: 6| Step: 11
Training loss: 3.433565280696466
Validation loss: 3.730835986056749

Epoch: 6| Step: 12
Training loss: 3.7630567221156612
Validation loss: 3.731267367072962

Epoch: 6| Step: 13
Training loss: 3.2210189081564953
Validation loss: 3.729419241623234

Epoch: 15| Step: 0
Training loss: 3.8837608238538395
Validation loss: 3.7265735262396826

Epoch: 6| Step: 1
Training loss: 3.7671771510965795
Validation loss: 3.723426195786858

Epoch: 6| Step: 2
Training loss: 3.0980219775430653
Validation loss: 3.7211585561972025

Epoch: 6| Step: 3
Training loss: 4.3862465309614205
Validation loss: 3.7186601227574076

Epoch: 6| Step: 4
Training loss: 4.601065694676984
Validation loss: 3.71326608927859

Epoch: 6| Step: 5
Training loss: 3.7643628042987163
Validation loss: 3.7109379780568807

Epoch: 6| Step: 6
Training loss: 4.203072359684304
Validation loss: 3.7092025671834548

Epoch: 6| Step: 7
Training loss: 3.5755373997685376
Validation loss: 3.706610001399209

Epoch: 6| Step: 8
Training loss: 3.6235324914611713
Validation loss: 3.7040045608220096

Epoch: 6| Step: 9
Training loss: 3.4804435412246444
Validation loss: 3.6996687989467656

Epoch: 6| Step: 10
Training loss: 3.709278257758704
Validation loss: 3.6994161382407333

Epoch: 6| Step: 11
Training loss: 4.1042810930802025
Validation loss: 3.6948771668333253

Epoch: 6| Step: 12
Training loss: 4.216543567252805
Validation loss: 3.6932843091474314

Epoch: 6| Step: 13
Training loss: 3.831244120507762
Validation loss: 3.6901367337978046

Epoch: 16| Step: 0
Training loss: 4.0374991307685795
Validation loss: 3.6849058066392244

Epoch: 6| Step: 1
Training loss: 4.281330414176935
Validation loss: 3.6833368545721044

Epoch: 6| Step: 2
Training loss: 3.7369592894270283
Validation loss: 3.6784167717256024

Epoch: 6| Step: 3
Training loss: 4.882446665982845
Validation loss: 3.6771867462083723

Epoch: 6| Step: 4
Training loss: 3.7459637855046077
Validation loss: 3.6743393928818047

Epoch: 6| Step: 5
Training loss: 4.160335282605994
Validation loss: 3.6706727499176623

Epoch: 6| Step: 6
Training loss: 2.9255635036629855
Validation loss: 3.6698029721033225

Epoch: 6| Step: 7
Training loss: 3.3582663902508068
Validation loss: 3.667927001483492

Epoch: 6| Step: 8
Training loss: 3.4242509231605127
Validation loss: 3.665039399651858

Epoch: 6| Step: 9
Training loss: 3.867605475754846
Validation loss: 3.663521324189245

Epoch: 6| Step: 10
Training loss: 3.7451725723170015
Validation loss: 3.6644827196831002

Epoch: 6| Step: 11
Training loss: 3.7550534848240393
Validation loss: 3.6602860688398495

Epoch: 6| Step: 12
Training loss: 4.1883812731422845
Validation loss: 3.6591160313511346

Epoch: 6| Step: 13
Training loss: 3.389010137115653
Validation loss: 3.6581844151989378

Epoch: 17| Step: 0
Training loss: 3.565431292368168
Validation loss: 3.657690563230801

Epoch: 6| Step: 1
Training loss: 3.9784837439659064
Validation loss: 3.655187496779037

Epoch: 6| Step: 2
Training loss: 3.595984253675973
Validation loss: 3.6515159491389992

Epoch: 6| Step: 3
Training loss: 3.434551014437894
Validation loss: 3.6497780933989605

Epoch: 6| Step: 4
Training loss: 4.0748020241043035
Validation loss: 3.646540691238488

Epoch: 6| Step: 5
Training loss: 4.177668631144695
Validation loss: 3.643875472990568

Epoch: 6| Step: 6
Training loss: 3.714411793654462
Validation loss: 3.642331231194036

Epoch: 6| Step: 7
Training loss: 4.709658118472667
Validation loss: 3.6409584993638275

Epoch: 6| Step: 8
Training loss: 3.032498132212945
Validation loss: 3.6384181097737742

Epoch: 6| Step: 9
Training loss: 4.207618325304179
Validation loss: 3.6367767499600494

Epoch: 6| Step: 10
Training loss: 3.899433261089415
Validation loss: 3.6359792233484067

Epoch: 6| Step: 11
Training loss: 3.6819141559529385
Validation loss: 3.6330024499330653

Epoch: 6| Step: 12
Training loss: 3.805780837235231
Validation loss: 3.6308268645704587

Epoch: 6| Step: 13
Training loss: 3.2966577539686703
Validation loss: 3.629479536182609

Epoch: 18| Step: 0
Training loss: 4.60948879295449
Validation loss: 3.62696603594064

Epoch: 6| Step: 1
Training loss: 4.19919740183527
Validation loss: 3.6245867104976917

Epoch: 6| Step: 2
Training loss: 2.8202723450060816
Validation loss: 3.6239549249898544

Epoch: 6| Step: 3
Training loss: 3.7753589232130595
Validation loss: 3.620740561305323

Epoch: 6| Step: 4
Training loss: 3.662920613271385
Validation loss: 3.6190206473080475

Epoch: 6| Step: 5
Training loss: 4.16871483371892
Validation loss: 3.617723000305492

Epoch: 6| Step: 6
Training loss: 4.006883658585857
Validation loss: 3.6152885117709475

Epoch: 6| Step: 7
Training loss: 3.8355747525307047
Validation loss: 3.6145604800671256

Epoch: 6| Step: 8
Training loss: 3.078957072460208
Validation loss: 3.6118597171811895

Epoch: 6| Step: 9
Training loss: 4.285715489160278
Validation loss: 3.6121133340135088

Epoch: 6| Step: 10
Training loss: 3.617899946078723
Validation loss: 3.6121422598277695

Epoch: 6| Step: 11
Training loss: 3.869598315385787
Validation loss: 3.6075961609103078

Epoch: 6| Step: 12
Training loss: 3.6691645581368384
Validation loss: 3.6062801115068046

Epoch: 6| Step: 13
Training loss: 3.0908289519034073
Validation loss: 3.6055190288694634

Epoch: 19| Step: 0
Training loss: 3.316174178883308
Validation loss: 3.610204994626783

Epoch: 6| Step: 1
Training loss: 3.802438435454271
Validation loss: 3.606472547893279

Epoch: 6| Step: 2
Training loss: 3.922468528062105
Validation loss: 3.6027314368486008

Epoch: 6| Step: 3
Training loss: 3.29306750528445
Validation loss: 3.5994588626954593

Epoch: 6| Step: 4
Training loss: 3.6179087766298954
Validation loss: 3.599226919123821

Epoch: 6| Step: 5
Training loss: 4.096133171792584
Validation loss: 3.6001363300045917

Epoch: 6| Step: 6
Training loss: 4.16092688358226
Validation loss: 3.595359392656232

Epoch: 6| Step: 7
Training loss: 4.729540481021501
Validation loss: 3.5975339424550024

Epoch: 6| Step: 8
Training loss: 3.6750805437253553
Validation loss: 3.601255332278593

Epoch: 6| Step: 9
Training loss: 2.8256079500658946
Validation loss: 3.608140546556608

Epoch: 6| Step: 10
Training loss: 3.481999019125286
Validation loss: 3.60603061589587

Epoch: 6| Step: 11
Training loss: 3.4607994448163577
Validation loss: 3.603703212204607

Epoch: 6| Step: 12
Training loss: 4.386186521586655
Validation loss: 3.5938694773997453

Epoch: 6| Step: 13
Training loss: 4.203101175800858
Validation loss: 3.588250556493508

Epoch: 20| Step: 0
Training loss: 4.301641532374226
Validation loss: 3.5893833762737404

Epoch: 6| Step: 1
Training loss: 4.1329569511912885
Validation loss: 3.5944407380199235

Epoch: 6| Step: 2
Training loss: 3.854876286244602
Validation loss: 3.5976563440613933

Epoch: 6| Step: 3
Training loss: 3.775886325490981
Validation loss: 3.5987450012421474

Epoch: 6| Step: 4
Training loss: 4.326163057270923
Validation loss: 3.5894421596716115

Epoch: 6| Step: 5
Training loss: 3.8538276866960617
Validation loss: 3.5815041708114026

Epoch: 6| Step: 6
Training loss: 3.1872773934217253
Validation loss: 3.578014471841472

Epoch: 6| Step: 7
Training loss: 4.21160917286388
Validation loss: 3.577941074454437

Epoch: 6| Step: 8
Training loss: 3.295683876117931
Validation loss: 3.578137009550314

Epoch: 6| Step: 9
Training loss: 2.643799628475067
Validation loss: 3.5792013661999627

Epoch: 6| Step: 10
Training loss: 4.569233980649478
Validation loss: 3.577752366513199

Epoch: 6| Step: 11
Training loss: 2.9679850345655843
Validation loss: 3.575450870391762

Epoch: 6| Step: 12
Training loss: 3.4092269627558593
Validation loss: 3.5728332735578885

Epoch: 6| Step: 13
Training loss: 4.002025091623536
Validation loss: 3.57111644330217

Epoch: 21| Step: 0
Training loss: 3.303993386675333
Validation loss: 3.565710243719674

Epoch: 6| Step: 1
Training loss: 3.667296326643391
Validation loss: 3.5642226637595766

Epoch: 6| Step: 2
Training loss: 3.8512105103882215
Validation loss: 3.5612760080798425

Epoch: 6| Step: 3
Training loss: 4.014221183518053
Validation loss: 3.5614449939958397

Epoch: 6| Step: 4
Training loss: 3.2733339279650777
Validation loss: 3.558741566077607

Epoch: 6| Step: 5
Training loss: 3.8249937369102116
Validation loss: 3.5572486302744633

Epoch: 6| Step: 6
Training loss: 3.9702638156973085
Validation loss: 3.5552670047581434

Epoch: 6| Step: 7
Training loss: 3.553431429436349
Validation loss: 3.553321060989533

Epoch: 6| Step: 8
Training loss: 4.762165352185153
Validation loss: 3.551375894621405

Epoch: 6| Step: 9
Training loss: 3.8787211117543055
Validation loss: 3.5492319459086064

Epoch: 6| Step: 10
Training loss: 2.927793984445703
Validation loss: 3.547842018523748

Epoch: 6| Step: 11
Training loss: 3.7941533133539
Validation loss: 3.547183889028799

Epoch: 6| Step: 12
Training loss: 3.8680310494913432
Validation loss: 3.5446505654363714

Epoch: 6| Step: 13
Training loss: 3.5685387009367022
Validation loss: 3.541874570492933

Epoch: 22| Step: 0
Training loss: 4.056577150291798
Validation loss: 3.5418428602793792

Epoch: 6| Step: 1
Training loss: 3.2331297315485115
Validation loss: 3.5403541005073405

Epoch: 6| Step: 2
Training loss: 3.6246032497725484
Validation loss: 3.5360678199636304

Epoch: 6| Step: 3
Training loss: 3.4361422544969886
Validation loss: 3.5358385218924306

Epoch: 6| Step: 4
Training loss: 3.066831056362819
Validation loss: 3.5341573818434453

Epoch: 6| Step: 5
Training loss: 3.6227012448851457
Validation loss: 3.532620269309758

Epoch: 6| Step: 6
Training loss: 4.383128870460959
Validation loss: 3.529863467749075

Epoch: 6| Step: 7
Training loss: 3.9249078338881542
Validation loss: 3.5281826734118367

Epoch: 6| Step: 8
Training loss: 4.083786348917328
Validation loss: 3.5246752763130336

Epoch: 6| Step: 9
Training loss: 3.217843381732229
Validation loss: 3.525267938074305

Epoch: 6| Step: 10
Training loss: 3.2762917977540953
Validation loss: 3.5217416364359586

Epoch: 6| Step: 11
Training loss: 3.4463022069120965
Validation loss: 3.523619477360469

Epoch: 6| Step: 12
Training loss: 4.329353461153474
Validation loss: 3.5191180138065876

Epoch: 6| Step: 13
Training loss: 4.676372901751458
Validation loss: 3.51737238656325

Epoch: 23| Step: 0
Training loss: 4.014452336300034
Validation loss: 3.5172266672653136

Epoch: 6| Step: 1
Training loss: 3.6801349343564564
Validation loss: 3.514343846459044

Epoch: 6| Step: 2
Training loss: 3.9293275823776503
Validation loss: 3.511804141384652

Epoch: 6| Step: 3
Training loss: 3.874768896287079
Validation loss: 3.5096128243322116

Epoch: 6| Step: 4
Training loss: 3.3897677273917313
Validation loss: 3.5095900002260274

Epoch: 6| Step: 5
Training loss: 3.770877198584138
Validation loss: 3.507398035154011

Epoch: 6| Step: 6
Training loss: 3.3587599080333224
Validation loss: 3.5061706666187944

Epoch: 6| Step: 7
Training loss: 3.271012675882081
Validation loss: 3.505033424712744

Epoch: 6| Step: 8
Training loss: 3.8634388643672897
Validation loss: 3.503556229138949

Epoch: 6| Step: 9
Training loss: 3.722130016747436
Validation loss: 3.5008504657574298

Epoch: 6| Step: 10
Training loss: 4.4433340486915585
Validation loss: 3.4999262601289023

Epoch: 6| Step: 11
Training loss: 3.7303703255176863
Validation loss: 3.498931371507439

Epoch: 6| Step: 12
Training loss: 3.0537388882335317
Validation loss: 3.4963390098178446

Epoch: 6| Step: 13
Training loss: 3.7762180611637066
Validation loss: 3.4961373568485103

Epoch: 24| Step: 0
Training loss: 4.2854500098717025
Validation loss: 3.494552040470626

Epoch: 6| Step: 1
Training loss: 4.261865992672922
Validation loss: 3.493274940879657

Epoch: 6| Step: 2
Training loss: 3.673034744542875
Validation loss: 3.4927386507605522

Epoch: 6| Step: 3
Training loss: 3.1562820281868156
Validation loss: 3.4913334701150105

Epoch: 6| Step: 4
Training loss: 3.768839117359814
Validation loss: 3.49225399921848

Epoch: 6| Step: 5
Training loss: 3.297271415417037
Validation loss: 3.4902782078322594

Epoch: 6| Step: 6
Training loss: 3.9959450672639156
Validation loss: 3.4892231583468343

Epoch: 6| Step: 7
Training loss: 3.8563592533604805
Validation loss: 3.4852865792399372

Epoch: 6| Step: 8
Training loss: 3.596002552799596
Validation loss: 3.481801806054798

Epoch: 6| Step: 9
Training loss: 3.6993705935870076
Validation loss: 3.4808630641383136

Epoch: 6| Step: 10
Training loss: 3.9057354397419632
Validation loss: 3.479989678373814

Epoch: 6| Step: 11
Training loss: 3.18727470050504
Validation loss: 3.47788589174992

Epoch: 6| Step: 12
Training loss: 3.5914528844335347
Validation loss: 3.476854894550212

Epoch: 6| Step: 13
Training loss: 3.028423918938743
Validation loss: 3.4736627040089396

Epoch: 25| Step: 0
Training loss: 3.9419639351645133
Validation loss: 3.4724090191763795

Epoch: 6| Step: 1
Training loss: 3.4644644442536925
Validation loss: 3.4718663965387417

Epoch: 6| Step: 2
Training loss: 3.1951546105360054
Validation loss: 3.4666702996590684

Epoch: 6| Step: 3
Training loss: 3.467333942774381
Validation loss: 3.4680500944807573

Epoch: 6| Step: 4
Training loss: 3.40823446439746
Validation loss: 3.4643120135293235

Epoch: 6| Step: 5
Training loss: 3.6486773197662816
Validation loss: 3.4643860363748633

Epoch: 6| Step: 6
Training loss: 3.673098615934891
Validation loss: 3.461153671093923

Epoch: 6| Step: 7
Training loss: 4.088788002838166
Validation loss: 3.4615350030321363

Epoch: 6| Step: 8
Training loss: 3.4505788124059706
Validation loss: 3.4596079881465167

Epoch: 6| Step: 9
Training loss: 3.6236642152199376
Validation loss: 3.4605471131290146

Epoch: 6| Step: 10
Training loss: 4.377391052807507
Validation loss: 3.457290661742873

Epoch: 6| Step: 11
Training loss: 3.3636478662879963
Validation loss: 3.4572254209573443

Epoch: 6| Step: 12
Training loss: 4.097793096797367
Validation loss: 3.4522396525288057

Epoch: 6| Step: 13
Training loss: 3.4096048615029386
Validation loss: 3.451903336875489

Epoch: 26| Step: 0
Training loss: 3.5636371336973274
Validation loss: 3.4495828308850496

Epoch: 6| Step: 1
Training loss: 4.275245409608427
Validation loss: 3.448015675122171

Epoch: 6| Step: 2
Training loss: 3.5195622755031652
Validation loss: 3.4468992927146016

Epoch: 6| Step: 3
Training loss: 2.5981762358436047
Validation loss: 3.4460018799168854

Epoch: 6| Step: 4
Training loss: 3.7240734304856846
Validation loss: 3.444171285587296

Epoch: 6| Step: 5
Training loss: 4.653526584980903
Validation loss: 3.443178544867288

Epoch: 6| Step: 6
Training loss: 3.257189354887325
Validation loss: 3.4408322840916985

Epoch: 6| Step: 7
Training loss: 3.626841636345176
Validation loss: 3.439704118277448

Epoch: 6| Step: 8
Training loss: 3.9296968433428314
Validation loss: 3.4391212302081042

Epoch: 6| Step: 9
Training loss: 3.6902186829810852
Validation loss: 3.4386578128620253

Epoch: 6| Step: 10
Training loss: 3.5479992668555362
Validation loss: 3.4388052064965837

Epoch: 6| Step: 11
Training loss: 3.237736967980587
Validation loss: 3.4420584619938746

Epoch: 6| Step: 12
Training loss: 3.7231363025011524
Validation loss: 3.4431061479087903

Epoch: 6| Step: 13
Training loss: 3.497648811801059
Validation loss: 3.4422560961005955

Epoch: 27| Step: 0
Training loss: 2.971764088515528
Validation loss: 3.4348289724994587

Epoch: 6| Step: 1
Training loss: 3.7761571967330063
Validation loss: 3.4327631631555415

Epoch: 6| Step: 2
Training loss: 3.6092106505128503
Validation loss: 3.433394654054228

Epoch: 6| Step: 3
Training loss: 3.0767467530787393
Validation loss: 3.432498784779303

Epoch: 6| Step: 4
Training loss: 3.8315989399206916
Validation loss: 3.434136641999643

Epoch: 6| Step: 5
Training loss: 3.835236961275444
Validation loss: 3.4328265657098065

Epoch: 6| Step: 6
Training loss: 4.496335975094358
Validation loss: 3.4311938183146737

Epoch: 6| Step: 7
Training loss: 2.9524829307792735
Validation loss: 3.4287066905721915

Epoch: 6| Step: 8
Training loss: 4.159698891012618
Validation loss: 3.425995404033733

Epoch: 6| Step: 9
Training loss: 3.0443342521507653
Validation loss: 3.4252232081758414

Epoch: 6| Step: 10
Training loss: 3.042723345869136
Validation loss: 3.424870890198949

Epoch: 6| Step: 11
Training loss: 4.044919045749856
Validation loss: 3.4247754429885293

Epoch: 6| Step: 12
Training loss: 4.005501778133285
Validation loss: 3.422740746410035

Epoch: 6| Step: 13
Training loss: 3.980879503194931
Validation loss: 3.4230220204133954

Epoch: 28| Step: 0
Training loss: 2.962975276373956
Validation loss: 3.4233397729816706

Epoch: 6| Step: 1
Training loss: 3.937030945950585
Validation loss: 3.4206468977379325

Epoch: 6| Step: 2
Training loss: 3.257604651830383
Validation loss: 3.4189360527902983

Epoch: 6| Step: 3
Training loss: 2.9828880560264337
Validation loss: 3.418375005858367

Epoch: 6| Step: 4
Training loss: 3.1592773422406766
Validation loss: 3.416368180829645

Epoch: 6| Step: 5
Training loss: 4.234480402574223
Validation loss: 3.416987873488685

Epoch: 6| Step: 6
Training loss: 3.864607626674964
Validation loss: 3.4154901757472986

Epoch: 6| Step: 7
Training loss: 2.8216034109014405
Validation loss: 3.4146437390121145

Epoch: 6| Step: 8
Training loss: 3.544184399442413
Validation loss: 3.4132190065126715

Epoch: 6| Step: 9
Training loss: 3.9462055668520986
Validation loss: 3.4132371723693873

Epoch: 6| Step: 10
Training loss: 3.3140807788422126
Validation loss: 3.412565162081928

Epoch: 6| Step: 11
Training loss: 4.212642515584645
Validation loss: 3.4106595685249794

Epoch: 6| Step: 12
Training loss: 4.040032570962575
Validation loss: 3.411551657781588

Epoch: 6| Step: 13
Training loss: 4.632179049692821
Validation loss: 3.4128376363971302

Epoch: 29| Step: 0
Training loss: 3.682257595021531
Validation loss: 3.40993477695913

Epoch: 6| Step: 1
Training loss: 3.4991836958311304
Validation loss: 3.406974732691844

Epoch: 6| Step: 2
Training loss: 3.193703691777624
Validation loss: 3.4072268597030146

Epoch: 6| Step: 3
Training loss: 4.029013316337221
Validation loss: 3.406270828175865

Epoch: 6| Step: 4
Training loss: 4.706253177393516
Validation loss: 3.4061146942868477

Epoch: 6| Step: 5
Training loss: 3.86853349169201
Validation loss: 3.40591179865073

Epoch: 6| Step: 6
Training loss: 3.2767902402449343
Validation loss: 3.4034645934965018

Epoch: 6| Step: 7
Training loss: 4.057813082853972
Validation loss: 3.4031706316950943

Epoch: 6| Step: 8
Training loss: 3.1389931761785044
Validation loss: 3.4017028984917728

Epoch: 6| Step: 9
Training loss: 3.390664096026759
Validation loss: 3.402457582734774

Epoch: 6| Step: 10
Training loss: 3.3388600467896734
Validation loss: 3.4014711253806134

Epoch: 6| Step: 11
Training loss: 3.728324809319738
Validation loss: 3.4013461891059324

Epoch: 6| Step: 12
Training loss: 3.6935893067391654
Validation loss: 3.400485457683524

Epoch: 6| Step: 13
Training loss: 2.0828491665588187
Validation loss: 3.399199885481882

Epoch: 30| Step: 0
Training loss: 4.029788913168081
Validation loss: 3.3977316200977987

Epoch: 6| Step: 1
Training loss: 3.0535202723196053
Validation loss: 3.398411696310954

Epoch: 6| Step: 2
Training loss: 4.067660531297563
Validation loss: 3.396434796098529

Epoch: 6| Step: 3
Training loss: 3.761871112974218
Validation loss: 3.3959817668323335

Epoch: 6| Step: 4
Training loss: 3.6040757154921828
Validation loss: 3.396121150978878

Epoch: 6| Step: 5
Training loss: 3.931325279206458
Validation loss: 3.3944432090609022

Epoch: 6| Step: 6
Training loss: 4.224607343316086
Validation loss: 3.3936987566840666

Epoch: 6| Step: 7
Training loss: 3.2848987455744747
Validation loss: 3.3933855605192464

Epoch: 6| Step: 8
Training loss: 3.495996228781266
Validation loss: 3.3927154334704035

Epoch: 6| Step: 9
Training loss: 2.6539048557317133
Validation loss: 3.3919726380062847

Epoch: 6| Step: 10
Training loss: 3.8291858682299753
Validation loss: 3.391807311077399

Epoch: 6| Step: 11
Training loss: 3.516169933895164
Validation loss: 3.3891161650169632

Epoch: 6| Step: 12
Training loss: 2.917181314748899
Validation loss: 3.3885221448184617

Epoch: 6| Step: 13
Training loss: 4.218217830294964
Validation loss: 3.3880922609604256

Epoch: 31| Step: 0
Training loss: 3.658347025666794
Validation loss: 3.384983593270902

Epoch: 6| Step: 1
Training loss: 3.481310399077704
Validation loss: 3.3864554251166985

Epoch: 6| Step: 2
Training loss: 3.88351734909636
Validation loss: 3.384937266947853

Epoch: 6| Step: 3
Training loss: 3.2438328256488242
Validation loss: 3.3833997166989853

Epoch: 6| Step: 4
Training loss: 3.316936616758343
Validation loss: 3.3825672334231056

Epoch: 6| Step: 5
Training loss: 3.488618464899843
Validation loss: 3.382213934504177

Epoch: 6| Step: 6
Training loss: 3.1694185112321187
Validation loss: 3.3812034091943297

Epoch: 6| Step: 7
Training loss: 3.2485555226444283
Validation loss: 3.3789020937343333

Epoch: 6| Step: 8
Training loss: 4.207262463179832
Validation loss: 3.379544575937782

Epoch: 6| Step: 9
Training loss: 3.6412723604216968
Validation loss: 3.377437261465059

Epoch: 6| Step: 10
Training loss: 3.7168440863396737
Validation loss: 3.3747034219820042

Epoch: 6| Step: 11
Training loss: 3.5471340538571017
Validation loss: 3.3726673017750306

Epoch: 6| Step: 12
Training loss: 4.027371218686635
Validation loss: 3.3707931153126185

Epoch: 6| Step: 13
Training loss: 3.9021847743127718
Validation loss: 3.370876987197473

Epoch: 32| Step: 0
Training loss: 3.204946307180384
Validation loss: 3.368604042062679

Epoch: 6| Step: 1
Training loss: 3.471132027610097
Validation loss: 3.3709575989803127

Epoch: 6| Step: 2
Training loss: 4.430340215910166
Validation loss: 3.380491220259307

Epoch: 6| Step: 3
Training loss: 2.637673347887306
Validation loss: 3.369654347193141

Epoch: 6| Step: 4
Training loss: 3.497623863181039
Validation loss: 3.3699743071728996

Epoch: 6| Step: 5
Training loss: 4.127881979593308
Validation loss: 3.3732093426898375

Epoch: 6| Step: 6
Training loss: 3.247504523364434
Validation loss: 3.3768571812619252

Epoch: 6| Step: 7
Training loss: 3.537182710794145
Validation loss: 3.3764986898354588

Epoch: 6| Step: 8
Training loss: 3.6359907132440363
Validation loss: 3.3684136778811333

Epoch: 6| Step: 9
Training loss: 3.520057156272161
Validation loss: 3.3678547107952905

Epoch: 6| Step: 10
Training loss: 3.181028491029621
Validation loss: 3.3698929506791786

Epoch: 6| Step: 11
Training loss: 4.077568863989445
Validation loss: 3.373112559803457

Epoch: 6| Step: 12
Training loss: 2.8776995382715618
Validation loss: 3.371508672878706

Epoch: 6| Step: 13
Training loss: 5.102154871152348
Validation loss: 3.379741366003626

Epoch: 33| Step: 0
Training loss: 3.2627384259441965
Validation loss: 3.364925718486109

Epoch: 6| Step: 1
Training loss: 3.7795127471858243
Validation loss: 3.37403267230415

Epoch: 6| Step: 2
Training loss: 4.58141284356567
Validation loss: 3.384553668993873

Epoch: 6| Step: 3
Training loss: 3.972763915276854
Validation loss: 3.386964354780777

Epoch: 6| Step: 4
Training loss: 3.690116729750837
Validation loss: 3.3687991836734783

Epoch: 6| Step: 5
Training loss: 3.016674274273407
Validation loss: 3.361169433584931

Epoch: 6| Step: 6
Training loss: 3.331646842293267
Validation loss: 3.3551036102139737

Epoch: 6| Step: 7
Training loss: 3.8079102201136257
Validation loss: 3.3529333788508917

Epoch: 6| Step: 8
Training loss: 3.3456147600341843
Validation loss: 3.3524784804465138

Epoch: 6| Step: 9
Training loss: 3.2679648161993717
Validation loss: 3.3532517064900995

Epoch: 6| Step: 10
Training loss: 3.0848641762286406
Validation loss: 3.3663601438079267

Epoch: 6| Step: 11
Training loss: 3.244999780405093
Validation loss: 3.3487933006623307

Epoch: 6| Step: 12
Training loss: 4.033510032965724
Validation loss: 3.344963010881461

Epoch: 6| Step: 13
Training loss: 3.6712418679967844
Validation loss: 3.342919808694033

Epoch: 34| Step: 0
Training loss: 3.081481652517939
Validation loss: 3.338700424125237

Epoch: 6| Step: 1
Training loss: 2.580047815160724
Validation loss: 3.3391356487007613

Epoch: 6| Step: 2
Training loss: 4.014906288278982
Validation loss: 3.337206295360929

Epoch: 6| Step: 3
Training loss: 3.476440564706804
Validation loss: 3.3337236111852726

Epoch: 6| Step: 4
Training loss: 2.9327092164214807
Validation loss: 3.332618172641729

Epoch: 6| Step: 5
Training loss: 3.5314636165857003
Validation loss: 3.3278819273719824

Epoch: 6| Step: 6
Training loss: 4.098591976766729
Validation loss: 3.324735247927326

Epoch: 6| Step: 7
Training loss: 3.272200248168093
Validation loss: 3.322749929339902

Epoch: 6| Step: 8
Training loss: 3.99808885694861
Validation loss: 3.321612579210933

Epoch: 6| Step: 9
Training loss: 3.5493964420939816
Validation loss: 3.3216799926967986

Epoch: 6| Step: 10
Training loss: 3.8785499800982475
Validation loss: 3.321739139097122

Epoch: 6| Step: 11
Training loss: 3.288225008428512
Validation loss: 3.3184262334465333

Epoch: 6| Step: 12
Training loss: 4.13948083580125
Validation loss: 3.317218647725702

Epoch: 6| Step: 13
Training loss: 3.7677122797201363
Validation loss: 3.316812728800334

Epoch: 35| Step: 0
Training loss: 3.9027586936861187
Validation loss: 3.316215426644035

Epoch: 6| Step: 1
Training loss: 3.0579990866081515
Validation loss: 3.3143313997417465

Epoch: 6| Step: 2
Training loss: 4.314724997800048
Validation loss: 3.312342687405525

Epoch: 6| Step: 3
Training loss: 4.121578300157134
Validation loss: 3.3131207290653055

Epoch: 6| Step: 4
Training loss: 3.6654417130354364
Validation loss: 3.31224021736532

Epoch: 6| Step: 5
Training loss: 3.311784918993142
Validation loss: 3.311907110945016

Epoch: 6| Step: 6
Training loss: 2.951039380091625
Validation loss: 3.3119759202128067

Epoch: 6| Step: 7
Training loss: 2.9664757299235713
Validation loss: 3.3127204680796596

Epoch: 6| Step: 8
Training loss: 4.3493980078863625
Validation loss: 3.3113765363117618

Epoch: 6| Step: 9
Training loss: 4.062851641181592
Validation loss: 3.31047721671172

Epoch: 6| Step: 10
Training loss: 2.9367169899007926
Validation loss: 3.308979436606241

Epoch: 6| Step: 11
Training loss: 2.9450286809434623
Validation loss: 3.3067083530208197

Epoch: 6| Step: 12
Training loss: 2.717902215777604
Validation loss: 3.306486251283456

Epoch: 6| Step: 13
Training loss: 4.034822285838113
Validation loss: 3.305158119395102

Epoch: 36| Step: 0
Training loss: 3.3183967359212274
Validation loss: 3.304029164237771

Epoch: 6| Step: 1
Training loss: 3.347724050327128
Validation loss: 3.3034387453292062

Epoch: 6| Step: 2
Training loss: 3.273639099176963
Validation loss: 3.302123206972397

Epoch: 6| Step: 3
Training loss: 3.1633740088122533
Validation loss: 3.3015381110057955

Epoch: 6| Step: 4
Training loss: 3.2064837454201376
Validation loss: 3.300635059078203

Epoch: 6| Step: 5
Training loss: 3.76460119235108
Validation loss: 3.2996809379137804

Epoch: 6| Step: 6
Training loss: 3.930505019103804
Validation loss: 3.2990530657861745

Epoch: 6| Step: 7
Training loss: 2.8806251559978566
Validation loss: 3.2974601708009574

Epoch: 6| Step: 8
Training loss: 4.716492776170235
Validation loss: 3.297247584843351

Epoch: 6| Step: 9
Training loss: 3.4052847798330603
Validation loss: 3.2970789278792973

Epoch: 6| Step: 10
Training loss: 3.6542055331649426
Validation loss: 3.2954587255844796

Epoch: 6| Step: 11
Training loss: 3.4921114441784376
Validation loss: 3.295771999205094

Epoch: 6| Step: 12
Training loss: 3.4843157433915195
Validation loss: 3.2940976994722164

Epoch: 6| Step: 13
Training loss: 3.681854193283344
Validation loss: 3.292581943186153

Epoch: 37| Step: 0
Training loss: 3.3216722284765874
Validation loss: 3.2929614287937676

Epoch: 6| Step: 1
Training loss: 3.1613356908464696
Validation loss: 3.2918184265401527

Epoch: 6| Step: 2
Training loss: 2.875225224173174
Validation loss: 3.2900693269869623

Epoch: 6| Step: 3
Training loss: 3.5127646784313855
Validation loss: 3.2886989549355636

Epoch: 6| Step: 4
Training loss: 3.1218971106554814
Validation loss: 3.288067443540887

Epoch: 6| Step: 5
Training loss: 3.6475400290538014
Validation loss: 3.2875631155949288

Epoch: 6| Step: 6
Training loss: 3.648563489025135
Validation loss: 3.2862588181486942

Epoch: 6| Step: 7
Training loss: 3.50369313079921
Validation loss: 3.2856293314569482

Epoch: 6| Step: 8
Training loss: 4.2289157035041205
Validation loss: 3.2855582194765254

Epoch: 6| Step: 9
Training loss: 4.2164739049544835
Validation loss: 3.283863186115348

Epoch: 6| Step: 10
Training loss: 3.208630552189949
Validation loss: 3.2833391998956527

Epoch: 6| Step: 11
Training loss: 3.6271532175049948
Validation loss: 3.282686511883673

Epoch: 6| Step: 12
Training loss: 3.2685681090066536
Validation loss: 3.28223651640967

Epoch: 6| Step: 13
Training loss: 4.064815389610127
Validation loss: 3.280760539983322

Epoch: 38| Step: 0
Training loss: 3.068173505469984
Validation loss: 3.2803420991096965

Epoch: 6| Step: 1
Training loss: 3.608884835916925
Validation loss: 3.280251377886596

Epoch: 6| Step: 2
Training loss: 2.926520097693188
Validation loss: 3.2792144414994313

Epoch: 6| Step: 3
Training loss: 3.725858929832777
Validation loss: 3.2786119660931865

Epoch: 6| Step: 4
Training loss: 3.5848514682533885
Validation loss: 3.2774704158199257

Epoch: 6| Step: 5
Training loss: 3.5310363704911687
Validation loss: 3.276702692614975

Epoch: 6| Step: 6
Training loss: 2.8168338022547843
Validation loss: 3.2762489816029206

Epoch: 6| Step: 7
Training loss: 3.531465776990854
Validation loss: 3.276486833509387

Epoch: 6| Step: 8
Training loss: 3.366238701564499
Validation loss: 3.275231038448144

Epoch: 6| Step: 9
Training loss: 4.33946224977099
Validation loss: 3.2741148861578475

Epoch: 6| Step: 10
Training loss: 3.686122572369274
Validation loss: 3.2740251904095454

Epoch: 6| Step: 11
Training loss: 3.8965418914144694
Validation loss: 3.273196658602725

Epoch: 6| Step: 12
Training loss: 3.2189636159584434
Validation loss: 3.2723652095167726

Epoch: 6| Step: 13
Training loss: 3.911283865879871
Validation loss: 3.272136219990961

Epoch: 39| Step: 0
Training loss: 3.400075934067043
Validation loss: 3.2715455087145306

Epoch: 6| Step: 1
Training loss: 4.08514058089484
Validation loss: 3.2715233056181465

Epoch: 6| Step: 2
Training loss: 3.5093457921376094
Validation loss: 3.270402172277252

Epoch: 6| Step: 3
Training loss: 2.711762228627915
Validation loss: 3.2702538942609327

Epoch: 6| Step: 4
Training loss: 3.4487701158811417
Validation loss: 3.269566805621668

Epoch: 6| Step: 5
Training loss: 3.2419951232459296
Validation loss: 3.2692537419685905

Epoch: 6| Step: 6
Training loss: 3.9188330049865203
Validation loss: 3.269269056712655

Epoch: 6| Step: 7
Training loss: 4.269973941339314
Validation loss: 3.2682895292852248

Epoch: 6| Step: 8
Training loss: 2.6318497071764093
Validation loss: 3.267877873114032

Epoch: 6| Step: 9
Training loss: 3.7208684449000518
Validation loss: 3.2669370590088587

Epoch: 6| Step: 10
Training loss: 3.8952989806771887
Validation loss: 3.266065455275837

Epoch: 6| Step: 11
Training loss: 3.3075872013882868
Validation loss: 3.26598377261776

Epoch: 6| Step: 12
Training loss: 3.5135981841998105
Validation loss: 3.265223148720888

Epoch: 6| Step: 13
Training loss: 2.9045183498796487
Validation loss: 3.2649328588839865

Epoch: 40| Step: 0
Training loss: 3.511668916715732
Validation loss: 3.2644505222596933

Epoch: 6| Step: 1
Training loss: 3.5949309689150706
Validation loss: 3.2640463492076295

Epoch: 6| Step: 2
Training loss: 3.4105878733773753
Validation loss: 3.2636011549411466

Epoch: 6| Step: 3
Training loss: 3.9574105776662356
Validation loss: 3.263405130690853

Epoch: 6| Step: 4
Training loss: 4.154687114369811
Validation loss: 3.2618648066764995

Epoch: 6| Step: 5
Training loss: 3.336452042431498
Validation loss: 3.2624473602419775

Epoch: 6| Step: 6
Training loss: 3.219418798795611
Validation loss: 3.260633560814113

Epoch: 6| Step: 7
Training loss: 3.8479152534177974
Validation loss: 3.260397266680254

Epoch: 6| Step: 8
Training loss: 2.8013210654276826
Validation loss: 3.2602041479868213

Epoch: 6| Step: 9
Training loss: 3.1208911586509243
Validation loss: 3.2599350784151615

Epoch: 6| Step: 10
Training loss: 3.461846294735164
Validation loss: 3.258918626952039

Epoch: 6| Step: 11
Training loss: 3.8159934126119315
Validation loss: 3.2582650834116387

Epoch: 6| Step: 12
Training loss: 3.719290301397477
Validation loss: 3.2588413199954824

Epoch: 6| Step: 13
Training loss: 2.3937669439687217
Validation loss: 3.257949665288676

Epoch: 41| Step: 0
Training loss: 3.2052846187670583
Validation loss: 3.2568285397917585

Epoch: 6| Step: 1
Training loss: 4.860342830920678
Validation loss: 3.2571412251146845

Epoch: 6| Step: 2
Training loss: 3.8850142992461016
Validation loss: 3.256200551801179

Epoch: 6| Step: 3
Training loss: 1.660141601497874
Validation loss: 3.2561996873342194

Epoch: 6| Step: 4
Training loss: 3.496924275041708
Validation loss: 3.2550244605852185

Epoch: 6| Step: 5
Training loss: 2.6994365598738734
Validation loss: 3.254860296467149

Epoch: 6| Step: 6
Training loss: 4.02403287463856
Validation loss: 3.2544262186263606

Epoch: 6| Step: 7
Training loss: 3.95237248310926
Validation loss: 3.2534552169247233

Epoch: 6| Step: 8
Training loss: 3.0400571004624677
Validation loss: 3.2533379239774995

Epoch: 6| Step: 9
Training loss: 3.044778112084862
Validation loss: 3.2528097156612295

Epoch: 6| Step: 10
Training loss: 3.0127909096461676
Validation loss: 3.2520725908119266

Epoch: 6| Step: 11
Training loss: 3.8385829776661367
Validation loss: 3.251525889864366

Epoch: 6| Step: 12
Training loss: 3.1093222455480802
Validation loss: 3.2506531137243138

Epoch: 6| Step: 13
Training loss: 4.564631760986128
Validation loss: 3.2508915884309277

Epoch: 42| Step: 0
Training loss: 3.8996264645617473
Validation loss: 3.2505455095665905

Epoch: 6| Step: 1
Training loss: 3.2448807526059893
Validation loss: 3.2492136134024707

Epoch: 6| Step: 2
Training loss: 3.1689108542521773
Validation loss: 3.248983675469378

Epoch: 6| Step: 3
Training loss: 4.229796464500805
Validation loss: 3.2489685333870066

Epoch: 6| Step: 4
Training loss: 3.6382296954387665
Validation loss: 3.248836286904439

Epoch: 6| Step: 5
Training loss: 2.3174810633868175
Validation loss: 3.2478934355937152

Epoch: 6| Step: 6
Training loss: 4.486474585726974
Validation loss: 3.24718790368619

Epoch: 6| Step: 7
Training loss: 3.0424299632328036
Validation loss: 3.2465541231738393

Epoch: 6| Step: 8
Training loss: 3.3233180904772213
Validation loss: 3.2463510220651246

Epoch: 6| Step: 9
Training loss: 3.0958064787064896
Validation loss: 3.2459927047312798

Epoch: 6| Step: 10
Training loss: 3.4645660185863907
Validation loss: 3.245896117165941

Epoch: 6| Step: 11
Training loss: 3.454248168008339
Validation loss: 3.2448283856277524

Epoch: 6| Step: 12
Training loss: 3.7330450139656697
Validation loss: 3.2434835331110907

Epoch: 6| Step: 13
Training loss: 3.286460880494176
Validation loss: 3.2436800057027377

Epoch: 43| Step: 0
Training loss: 3.180665861509316
Validation loss: 3.244023912767055

Epoch: 6| Step: 1
Training loss: 3.3356347404510736
Validation loss: 3.2429240669420847

Epoch: 6| Step: 2
Training loss: 4.128073269955263
Validation loss: 3.2415286518893947

Epoch: 6| Step: 3
Training loss: 3.666888938293442
Validation loss: 3.2419496700323607

Epoch: 6| Step: 4
Training loss: 2.8969574720048086
Validation loss: 3.242190144144051

Epoch: 6| Step: 5
Training loss: 4.053440732871562
Validation loss: 3.239930717920594

Epoch: 6| Step: 6
Training loss: 3.0328714025988885
Validation loss: 3.240490618609907

Epoch: 6| Step: 7
Training loss: 3.6303883986326806
Validation loss: 3.2399204188116153

Epoch: 6| Step: 8
Training loss: 3.532557152719747
Validation loss: 3.239721167021123

Epoch: 6| Step: 9
Training loss: 3.783886203337078
Validation loss: 3.2392878993024197

Epoch: 6| Step: 10
Training loss: 4.194263518910615
Validation loss: 3.2392844312935156

Epoch: 6| Step: 11
Training loss: 2.803067305193339
Validation loss: 3.2386196699898115

Epoch: 6| Step: 12
Training loss: 2.4722417933038234
Validation loss: 3.2383951768042873

Epoch: 6| Step: 13
Training loss: 3.8703186306156026
Validation loss: 3.2374306028384994

Epoch: 44| Step: 0
Training loss: 3.0858874353138246
Validation loss: 3.2367669466613247

Epoch: 6| Step: 1
Training loss: 3.24280249955921
Validation loss: 3.2363971105748663

Epoch: 6| Step: 2
Training loss: 2.91514097000471
Validation loss: 3.2359894273333407

Epoch: 6| Step: 3
Training loss: 3.785659740805655
Validation loss: 3.235314833710889

Epoch: 6| Step: 4
Training loss: 3.1379539556486478
Validation loss: 3.2350339102931107

Epoch: 6| Step: 5
Training loss: 3.0476802446544857
Validation loss: 3.2343122157076185

Epoch: 6| Step: 6
Training loss: 3.699581333908421
Validation loss: 3.233821016742705

Epoch: 6| Step: 7
Training loss: 3.9000394965886143
Validation loss: 3.234087862673756

Epoch: 6| Step: 8
Training loss: 2.9652866439825756
Validation loss: 3.2338256543793853

Epoch: 6| Step: 9
Training loss: 3.70548569001603
Validation loss: 3.2330838904423915

Epoch: 6| Step: 10
Training loss: 4.147293191620378
Validation loss: 3.2314959209637046

Epoch: 6| Step: 11
Training loss: 3.579978362929101
Validation loss: 3.231657908415176

Epoch: 6| Step: 12
Training loss: 3.5966299707651945
Validation loss: 3.230814517229396

Epoch: 6| Step: 13
Training loss: 3.958017691358261
Validation loss: 3.2303646542212916

Epoch: 45| Step: 0
Training loss: 3.643945448591679
Validation loss: 3.229857478775304

Epoch: 6| Step: 1
Training loss: 3.9031641864260247
Validation loss: 3.22968002721629

Epoch: 6| Step: 2
Training loss: 3.3945585014908706
Validation loss: 3.2290113339624082

Epoch: 6| Step: 3
Training loss: 2.6363484440488363
Validation loss: 3.228533595360529

Epoch: 6| Step: 4
Training loss: 4.046734781671327
Validation loss: 3.226914355824513

Epoch: 6| Step: 5
Training loss: 3.4318479367871864
Validation loss: 3.226600450298871

Epoch: 6| Step: 6
Training loss: 3.4696968779514044
Validation loss: 3.224940823985625

Epoch: 6| Step: 7
Training loss: 3.6296711783795486
Validation loss: 3.2249204590993377

Epoch: 6| Step: 8
Training loss: 2.8146479563679243
Validation loss: 3.2245152269278834

Epoch: 6| Step: 9
Training loss: 4.079529735914537
Validation loss: 3.222827366636052

Epoch: 6| Step: 10
Training loss: 3.945301501570375
Validation loss: 3.2215946751783275

Epoch: 6| Step: 11
Training loss: 2.493471203662407
Validation loss: 3.220616445529961

Epoch: 6| Step: 12
Training loss: 3.4898792805601886
Validation loss: 3.2204131144564343

Epoch: 6| Step: 13
Training loss: 3.2034819613407755
Validation loss: 3.2189594522823324

Epoch: 46| Step: 0
Training loss: 2.959714450723545
Validation loss: 3.217984619958703

Epoch: 6| Step: 1
Training loss: 3.2671083430694496
Validation loss: 3.2190843777435387

Epoch: 6| Step: 2
Training loss: 3.8131002985390707
Validation loss: 3.214649542306528

Epoch: 6| Step: 3
Training loss: 3.2468318168992067
Validation loss: 3.2134771425164037

Epoch: 6| Step: 4
Training loss: 3.6031228613867787
Validation loss: 3.211789640375933

Epoch: 6| Step: 5
Training loss: 3.425835533973422
Validation loss: 3.209112333012025

Epoch: 6| Step: 6
Training loss: 4.011541880838183
Validation loss: 3.207501401993893

Epoch: 6| Step: 7
Training loss: 3.4727801031590615
Validation loss: 3.2055196179369583

Epoch: 6| Step: 8
Training loss: 3.8645746825636347
Validation loss: 3.2037870981873544

Epoch: 6| Step: 9
Training loss: 2.826577116009578
Validation loss: 3.2077825675744926

Epoch: 6| Step: 10
Training loss: 3.0531587409475316
Validation loss: 3.206647533639121

Epoch: 6| Step: 11
Training loss: 3.8869082917429902
Validation loss: 3.209634652545664

Epoch: 6| Step: 12
Training loss: 2.78560460402203
Validation loss: 3.204075662764567

Epoch: 6| Step: 13
Training loss: 4.395679103562286
Validation loss: 3.2044233178524224

Epoch: 47| Step: 0
Training loss: 2.7878094591188947
Validation loss: 3.2055369910375004

Epoch: 6| Step: 1
Training loss: 4.021785537685073
Validation loss: 3.2027973942932535

Epoch: 6| Step: 2
Training loss: 3.1998035609032534
Validation loss: 3.2010127881078856

Epoch: 6| Step: 3
Training loss: 2.9380349828664185
Validation loss: 3.2030798131765312

Epoch: 6| Step: 4
Training loss: 3.5785023852568636
Validation loss: 3.2013081453878587

Epoch: 6| Step: 5
Training loss: 3.3449257182952636
Validation loss: 3.2000988727722843

Epoch: 6| Step: 6
Training loss: 3.6739550603569526
Validation loss: 3.1968499241903205

Epoch: 6| Step: 7
Training loss: 3.0263326814647074
Validation loss: 3.198925381235822

Epoch: 6| Step: 8
Training loss: 3.734628325612704
Validation loss: 3.197502834688874

Epoch: 6| Step: 9
Training loss: 3.2245525907326105
Validation loss: 3.1960019903337855

Epoch: 6| Step: 10
Training loss: 3.5212617572104703
Validation loss: 3.1966123035532132

Epoch: 6| Step: 11
Training loss: 3.085261867296668
Validation loss: 3.1951931649509278

Epoch: 6| Step: 12
Training loss: 4.216985715071627
Validation loss: 3.1969934955912214

Epoch: 6| Step: 13
Training loss: 3.9998879416981894
Validation loss: 3.19341832272403

Epoch: 48| Step: 0
Training loss: 3.812123264397281
Validation loss: 3.1934712678156263

Epoch: 6| Step: 1
Training loss: 3.6514394038308553
Validation loss: 3.1920012095968193

Epoch: 6| Step: 2
Training loss: 3.7403331773422077
Validation loss: 3.1924698249130326

Epoch: 6| Step: 3
Training loss: 3.035010296271517
Validation loss: 3.193807476598844

Epoch: 6| Step: 4
Training loss: 3.6793972151953778
Validation loss: 3.190972630827645

Epoch: 6| Step: 5
Training loss: 3.3836272846428277
Validation loss: 3.191132603864482

Epoch: 6| Step: 6
Training loss: 2.6922737129917724
Validation loss: 3.1888928925939277

Epoch: 6| Step: 7
Training loss: 3.5955776708661773
Validation loss: 3.190698108677363

Epoch: 6| Step: 8
Training loss: 3.430139325039811
Validation loss: 3.188783638500094

Epoch: 6| Step: 9
Training loss: 3.2922523235064016
Validation loss: 3.187287538490348

Epoch: 6| Step: 10
Training loss: 2.2664038010182606
Validation loss: 3.1864938613816176

Epoch: 6| Step: 11
Training loss: 3.614121655855369
Validation loss: 3.1885718309565516

Epoch: 6| Step: 12
Training loss: 3.723202772341599
Validation loss: 3.1872789699190873

Epoch: 6| Step: 13
Training loss: 4.436272679773713
Validation loss: 3.186212413525934

Epoch: 49| Step: 0
Training loss: 3.5727843027462765
Validation loss: 3.1873140548269667

Epoch: 6| Step: 1
Training loss: 3.4012045633855412
Validation loss: 3.1851482108072084

Epoch: 6| Step: 2
Training loss: 3.517771425924901
Validation loss: 3.182014745043159

Epoch: 6| Step: 3
Training loss: 3.5712224355881617
Validation loss: 3.1834207322318275

Epoch: 6| Step: 4
Training loss: 3.0696977383305857
Validation loss: 3.183213889684729

Epoch: 6| Step: 5
Training loss: 3.163982927240156
Validation loss: 3.182227356382416

Epoch: 6| Step: 6
Training loss: 3.0742168886986105
Validation loss: 3.1829497971918905

Epoch: 6| Step: 7
Training loss: 3.2340792460832324
Validation loss: 3.180995296802747

Epoch: 6| Step: 8
Training loss: 4.18882024648624
Validation loss: 3.181673154194595

Epoch: 6| Step: 9
Training loss: 3.638179891172539
Validation loss: 3.180392838920797

Epoch: 6| Step: 10
Training loss: 3.2964143114795577
Validation loss: 3.1814907725621113

Epoch: 6| Step: 11
Training loss: 3.652080016380381
Validation loss: 3.1794584539040462

Epoch: 6| Step: 12
Training loss: 3.66777400433159
Validation loss: 3.181755985264194

Epoch: 6| Step: 13
Training loss: 2.7178697586124825
Validation loss: 3.1851364403188533

Epoch: 50| Step: 0
Training loss: 3.536847834235884
Validation loss: 3.181859716653843

Epoch: 6| Step: 1
Training loss: 2.337103511210626
Validation loss: 3.181039465969974

Epoch: 6| Step: 2
Training loss: 3.6343185092409453
Validation loss: 3.183235131851335

Epoch: 6| Step: 3
Training loss: 3.5654341008857235
Validation loss: 3.183529255571883

Epoch: 6| Step: 4
Training loss: 3.4400171947049514
Validation loss: 3.1849886889804275

Epoch: 6| Step: 5
Training loss: 3.3506360318500916
Validation loss: 3.1763332864776035

Epoch: 6| Step: 6
Training loss: 3.0303198576951256
Validation loss: 3.1770690471153813

Epoch: 6| Step: 7
Training loss: 3.7000553590911793
Validation loss: 3.180640111076504

Epoch: 6| Step: 8
Training loss: 3.9841538311777422
Validation loss: 3.1859233559264304

Epoch: 6| Step: 9
Training loss: 3.8859111617805904
Validation loss: 3.184374939587644

Epoch: 6| Step: 10
Training loss: 2.6569900379388973
Validation loss: 3.180883530902868

Epoch: 6| Step: 11
Training loss: 3.2270126213533814
Validation loss: 3.1800012453112516

Epoch: 6| Step: 12
Training loss: 4.096683761358225
Validation loss: 3.1822363034970262

Epoch: 6| Step: 13
Training loss: 3.298672010071522
Validation loss: 3.1775849337567186

Epoch: 51| Step: 0
Training loss: 3.484952733336403
Validation loss: 3.1755801002214863

Epoch: 6| Step: 1
Training loss: 3.3491448349979516
Validation loss: 3.1745464043893152

Epoch: 6| Step: 2
Training loss: 3.4027505800020945
Validation loss: 3.17927577911342

Epoch: 6| Step: 3
Training loss: 3.378007184849309
Validation loss: 3.1767840721415648

Epoch: 6| Step: 4
Training loss: 3.4826538214083964
Validation loss: 3.174395170408384

Epoch: 6| Step: 5
Training loss: 3.5618877219357654
Validation loss: 3.173653985962763

Epoch: 6| Step: 6
Training loss: 3.6167856738877746
Validation loss: 3.174985470914973

Epoch: 6| Step: 7
Training loss: 3.8144688759755443
Validation loss: 3.1718595092078337

Epoch: 6| Step: 8
Training loss: 3.6712344645767976
Validation loss: 3.1705803080961954

Epoch: 6| Step: 9
Training loss: 3.391157398527369
Validation loss: 3.16996324174911

Epoch: 6| Step: 10
Training loss: 3.6134177022376925
Validation loss: 3.170948783408406

Epoch: 6| Step: 11
Training loss: 3.136012243607034
Validation loss: 3.1759022831151795

Epoch: 6| Step: 12
Training loss: 2.725026569761881
Validation loss: 3.1702249760267627

Epoch: 6| Step: 13
Training loss: 3.3825947116581085
Validation loss: 3.1679345562738095

Epoch: 52| Step: 0
Training loss: 3.5823306225855482
Validation loss: 3.16869384944995

Epoch: 6| Step: 1
Training loss: 2.6883034503156455
Validation loss: 3.167557440233688

Epoch: 6| Step: 2
Training loss: 3.181134468783721
Validation loss: 3.168917466990009

Epoch: 6| Step: 3
Training loss: 3.344903764694638
Validation loss: 3.1682315957768945

Epoch: 6| Step: 4
Training loss: 3.820118780236707
Validation loss: 3.166058723778994

Epoch: 6| Step: 5
Training loss: 2.2332387315821767
Validation loss: 3.1664830032048195

Epoch: 6| Step: 6
Training loss: 3.322051187689306
Validation loss: 3.164510951436676

Epoch: 6| Step: 7
Training loss: 3.408603520087562
Validation loss: 3.1638564645966634

Epoch: 6| Step: 8
Training loss: 3.0781888229027405
Validation loss: 3.166684805316713

Epoch: 6| Step: 9
Training loss: 4.619312604158385
Validation loss: 3.163470423844086

Epoch: 6| Step: 10
Training loss: 2.8560626746922098
Validation loss: 3.1639113693574004

Epoch: 6| Step: 11
Training loss: 2.8950577024200737
Validation loss: 3.1625343771924084

Epoch: 6| Step: 12
Training loss: 3.7242852056426545
Validation loss: 3.162788006208323

Epoch: 6| Step: 13
Training loss: 5.184779913267625
Validation loss: 3.161680430098867

Epoch: 53| Step: 0
Training loss: 2.9906846697204927
Validation loss: 3.16203480897188

Epoch: 6| Step: 1
Training loss: 3.462941573317396
Validation loss: 3.1621624292166373

Epoch: 6| Step: 2
Training loss: 3.5934177410943637
Validation loss: 3.1611534536980437

Epoch: 6| Step: 3
Training loss: 3.498242345616866
Validation loss: 3.1578789236509

Epoch: 6| Step: 4
Training loss: 3.0139440091000753
Validation loss: 3.1581799123901315

Epoch: 6| Step: 5
Training loss: 3.554461998127195
Validation loss: 3.1578690713443236

Epoch: 6| Step: 6
Training loss: 4.078359312144417
Validation loss: 3.1592341493260387

Epoch: 6| Step: 7
Training loss: 2.7474620551976647
Validation loss: 3.156323330032541

Epoch: 6| Step: 8
Training loss: 3.780381536453328
Validation loss: 3.159842914660862

Epoch: 6| Step: 9
Training loss: 4.028782052135409
Validation loss: 3.154246341330122

Epoch: 6| Step: 10
Training loss: 2.9619850580326683
Validation loss: 3.155313959563957

Epoch: 6| Step: 11
Training loss: 3.000210913555557
Validation loss: 3.154653653354336

Epoch: 6| Step: 12
Training loss: 3.634079841311936
Validation loss: 3.155253679209822

Epoch: 6| Step: 13
Training loss: 3.256877810825269
Validation loss: 3.1554454605335858

Epoch: 54| Step: 0
Training loss: 2.974483053990485
Validation loss: 3.1535528747857025

Epoch: 6| Step: 1
Training loss: 3.3494635992331503
Validation loss: 3.154522316047406

Epoch: 6| Step: 2
Training loss: 3.944330980940498
Validation loss: 3.151567600136363

Epoch: 6| Step: 3
Training loss: 3.8242825901208666
Validation loss: 3.154458031816647

Epoch: 6| Step: 4
Training loss: 3.3326843265686956
Validation loss: 3.151562644598988

Epoch: 6| Step: 5
Training loss: 2.3899469348969937
Validation loss: 3.151995920446294

Epoch: 6| Step: 6
Training loss: 3.2339148447483117
Validation loss: 3.1505160674498236

Epoch: 6| Step: 7
Training loss: 3.3668260845046305
Validation loss: 3.154453584697267

Epoch: 6| Step: 8
Training loss: 3.550500302588586
Validation loss: 3.1538507957157296

Epoch: 6| Step: 9
Training loss: 3.0990492008682042
Validation loss: 3.156266689916357

Epoch: 6| Step: 10
Training loss: 4.195492987417653
Validation loss: 3.153626335818577

Epoch: 6| Step: 11
Training loss: 3.41265574788024
Validation loss: 3.1515253313974596

Epoch: 6| Step: 12
Training loss: 3.966169704967385
Validation loss: 3.153495650799795

Epoch: 6| Step: 13
Training loss: 2.2365080781855142
Validation loss: 3.1527609923543842

Epoch: 55| Step: 0
Training loss: 2.8171143719601783
Validation loss: 3.1508531129432207

Epoch: 6| Step: 1
Training loss: 3.159845098730891
Validation loss: 3.152357367013084

Epoch: 6| Step: 2
Training loss: 2.8019991345618664
Validation loss: 3.1523559153694234

Epoch: 6| Step: 3
Training loss: 3.0452837579113594
Validation loss: 3.147677999562367

Epoch: 6| Step: 4
Training loss: 2.7793162620656395
Validation loss: 3.15058575047854

Epoch: 6| Step: 5
Training loss: 4.015039304776042
Validation loss: 3.1497301168699314

Epoch: 6| Step: 6
Training loss: 3.4533903960689316
Validation loss: 3.153178922610295

Epoch: 6| Step: 7
Training loss: 3.7919603730074742
Validation loss: 3.15075821007957

Epoch: 6| Step: 8
Training loss: 3.3197061142053497
Validation loss: 3.151058118399773

Epoch: 6| Step: 9
Training loss: 3.299894423674409
Validation loss: 3.145633306230821

Epoch: 6| Step: 10
Training loss: 4.208002713249695
Validation loss: 3.143985146436475

Epoch: 6| Step: 11
Training loss: 3.1367228544785566
Validation loss: 3.1470098959421087

Epoch: 6| Step: 12
Training loss: 3.7114179119543103
Validation loss: 3.1454734120972394

Epoch: 6| Step: 13
Training loss: 4.207474850756802
Validation loss: 3.143970020522716

Epoch: 56| Step: 0
Training loss: 2.835067068985235
Validation loss: 3.145719026703957

Epoch: 6| Step: 1
Training loss: 2.4753580624288367
Validation loss: 3.1475418776463333

Epoch: 6| Step: 2
Training loss: 2.6455704465811314
Validation loss: 3.1426183441438984

Epoch: 6| Step: 3
Training loss: 3.684398445915447
Validation loss: 3.145522382515473

Epoch: 6| Step: 4
Training loss: 3.9228270085738903
Validation loss: 3.1449968273978226

Epoch: 6| Step: 5
Training loss: 3.7867948372958504
Validation loss: 3.1442688054045234

Epoch: 6| Step: 6
Training loss: 3.6569140230690604
Validation loss: 3.1453831361465694

Epoch: 6| Step: 7
Training loss: 2.9621595613619083
Validation loss: 3.1464272921510985

Epoch: 6| Step: 8
Training loss: 3.6843198867571343
Validation loss: 3.1495096187939673

Epoch: 6| Step: 9
Training loss: 2.9630428669893067
Validation loss: 3.150673917204582

Epoch: 6| Step: 10
Training loss: 3.7461375372180217
Validation loss: 3.1508604527253077

Epoch: 6| Step: 11
Training loss: 4.372561401843389
Validation loss: 3.1460166839147203

Epoch: 6| Step: 12
Training loss: 2.5254670948036595
Validation loss: 3.140942430114414

Epoch: 6| Step: 13
Training loss: 4.123805480010289
Validation loss: 3.1399860722928077

Epoch: 57| Step: 0
Training loss: 4.219846229825103
Validation loss: 3.140430078491477

Epoch: 6| Step: 1
Training loss: 3.222870642726533
Validation loss: 3.1379669602840417

Epoch: 6| Step: 2
Training loss: 2.9425767897290545
Validation loss: 3.1422268353704745

Epoch: 6| Step: 3
Training loss: 3.2885731675132877
Validation loss: 3.1392323073204023

Epoch: 6| Step: 4
Training loss: 3.6085219923451044
Validation loss: 3.137648267469789

Epoch: 6| Step: 5
Training loss: 3.2337698992399675
Validation loss: 3.138801426082933

Epoch: 6| Step: 6
Training loss: 4.01996090504629
Validation loss: 3.1376816498311393

Epoch: 6| Step: 7
Training loss: 2.5791452874287195
Validation loss: 3.138137716489894

Epoch: 6| Step: 8
Training loss: 2.856584364938097
Validation loss: 3.146633186405547

Epoch: 6| Step: 9
Training loss: 3.823892550247698
Validation loss: 3.139563108989952

Epoch: 6| Step: 10
Training loss: 3.8037934241697884
Validation loss: 3.1349447234024903

Epoch: 6| Step: 11
Training loss: 3.7517723981232307
Validation loss: 3.135311718695165

Epoch: 6| Step: 12
Training loss: 2.421664616460735
Validation loss: 3.1364358173582425

Epoch: 6| Step: 13
Training loss: 3.3242303688931054
Validation loss: 3.132743583671784

Epoch: 58| Step: 0
Training loss: 3.815593777465545
Validation loss: 3.1366467286859008

Epoch: 6| Step: 1
Training loss: 3.2984239455992226
Validation loss: 3.1358389329732885

Epoch: 6| Step: 2
Training loss: 3.374264248370965
Validation loss: 3.1349856104494935

Epoch: 6| Step: 3
Training loss: 3.0114867916409707
Validation loss: 3.1355504519896877

Epoch: 6| Step: 4
Training loss: 3.171151515587745
Validation loss: 3.134668242021317

Epoch: 6| Step: 5
Training loss: 2.3876663549496597
Validation loss: 3.1355600097735006

Epoch: 6| Step: 6
Training loss: 3.055210702875473
Validation loss: 3.133946351028321

Epoch: 6| Step: 7
Training loss: 3.8272251862201156
Validation loss: 3.1326891613197705

Epoch: 6| Step: 8
Training loss: 3.4880454399141305
Validation loss: 3.134064666025927

Epoch: 6| Step: 9
Training loss: 3.4628841531330528
Validation loss: 3.135817968995876

Epoch: 6| Step: 10
Training loss: 3.3157627663138305
Validation loss: 3.143599307699804

Epoch: 6| Step: 11
Training loss: 3.6467060170906906
Validation loss: 3.1451707003683795

Epoch: 6| Step: 12
Training loss: 4.045734259469125
Validation loss: 3.1353919144397704

Epoch: 6| Step: 13
Training loss: 3.3491567945433722
Validation loss: 3.130447324244853

Epoch: 59| Step: 0
Training loss: 3.696005242158219
Validation loss: 3.1314710792866314

Epoch: 6| Step: 1
Training loss: 3.7816607039432473
Validation loss: 3.13083954288191

Epoch: 6| Step: 2
Training loss: 3.7793855720777154
Validation loss: 3.1305315147990616

Epoch: 6| Step: 3
Training loss: 3.6948994250411515
Validation loss: 3.1295699865973523

Epoch: 6| Step: 4
Training loss: 3.1591991583151913
Validation loss: 3.127826916590059

Epoch: 6| Step: 5
Training loss: 3.0111086532970623
Validation loss: 3.128857203873673

Epoch: 6| Step: 6
Training loss: 3.8861051602272956
Validation loss: 3.129651780997436

Epoch: 6| Step: 7
Training loss: 3.1234771069548275
Validation loss: 3.1332511055755514

Epoch: 6| Step: 8
Training loss: 3.341265174040641
Validation loss: 3.1344263515167916

Epoch: 6| Step: 9
Training loss: 3.0435072847131566
Validation loss: 3.1391407077332

Epoch: 6| Step: 10
Training loss: 3.005255546176922
Validation loss: 3.1409333359887026

Epoch: 6| Step: 11
Training loss: 2.8033381114228026
Validation loss: 3.13670636951323

Epoch: 6| Step: 12
Training loss: 3.480600408082581
Validation loss: 3.1276922233108952

Epoch: 6| Step: 13
Training loss: 3.525577817052376
Validation loss: 3.1269044844069063

Epoch: 60| Step: 0
Training loss: 3.601230432257939
Validation loss: 3.1252319668229878

Epoch: 6| Step: 1
Training loss: 3.0095932482273065
Validation loss: 3.126232400527854

Epoch: 6| Step: 2
Training loss: 3.0915211056342526
Validation loss: 3.1273256012027564

Epoch: 6| Step: 3
Training loss: 4.171756128339232
Validation loss: 3.127199002244171

Epoch: 6| Step: 4
Training loss: 4.30019935323225
Validation loss: 3.1280032470719212

Epoch: 6| Step: 5
Training loss: 3.658679252959679
Validation loss: 3.1230421073366337

Epoch: 6| Step: 6
Training loss: 3.0075797647377143
Validation loss: 3.1316917210209727

Epoch: 6| Step: 7
Training loss: 2.918652884523844
Validation loss: 3.140640690563884

Epoch: 6| Step: 8
Training loss: 3.0597967556543826
Validation loss: 3.1320221707296643

Epoch: 6| Step: 9
Training loss: 3.8888274793468964
Validation loss: 3.1267067627076623

Epoch: 6| Step: 10
Training loss: 3.9150380881297115
Validation loss: 3.1234300447569017

Epoch: 6| Step: 11
Training loss: 2.5444397312252067
Validation loss: 3.1235599538735275

Epoch: 6| Step: 12
Training loss: 2.6181161627821803
Validation loss: 3.124582381697532

Epoch: 6| Step: 13
Training loss: 2.7043167750502373
Validation loss: 3.123131744428639

Epoch: 61| Step: 0
Training loss: 3.6696318572207343
Validation loss: 3.1255542862420227

Epoch: 6| Step: 1
Training loss: 2.75083529184436
Validation loss: 3.1243642213587393

Epoch: 6| Step: 2
Training loss: 3.983954194230716
Validation loss: 3.1228279284772693

Epoch: 6| Step: 3
Training loss: 3.8832337056970347
Validation loss: 3.1202196930808763

Epoch: 6| Step: 4
Training loss: 3.427108455361039
Validation loss: 3.118907129181939

Epoch: 6| Step: 5
Training loss: 3.2558502947721313
Validation loss: 3.120142346285731

Epoch: 6| Step: 6
Training loss: 2.754157737990626
Validation loss: 3.117558289508178

Epoch: 6| Step: 7
Training loss: 2.9206249806693707
Validation loss: 3.1256811667050775

Epoch: 6| Step: 8
Training loss: 3.007344791659721
Validation loss: 3.1358847494407893

Epoch: 6| Step: 9
Training loss: 3.5572670767712897
Validation loss: 3.1561563697848256

Epoch: 6| Step: 10
Training loss: 3.6150462855413683
Validation loss: 3.1233891837308057

Epoch: 6| Step: 11
Training loss: 3.2068413737468386
Validation loss: 3.120465422279994

Epoch: 6| Step: 12
Training loss: 3.334493927769774
Validation loss: 3.1195932289896113

Epoch: 6| Step: 13
Training loss: 4.018517072462169
Validation loss: 3.1275583242523464

Epoch: 62| Step: 0
Training loss: 2.785306308550712
Validation loss: 3.122553724767662

Epoch: 6| Step: 1
Training loss: 3.4415321976545092
Validation loss: 3.1187752597746092

Epoch: 6| Step: 2
Training loss: 3.6169206755664196
Validation loss: 3.12230805318093

Epoch: 6| Step: 3
Training loss: 3.504883220648137
Validation loss: 3.1241619028119945

Epoch: 6| Step: 4
Training loss: 4.216467119604174
Validation loss: 3.1284414542253245

Epoch: 6| Step: 5
Training loss: 2.688711203947427
Validation loss: 3.1265602367921166

Epoch: 6| Step: 6
Training loss: 3.688830507408837
Validation loss: 3.128150106149844

Epoch: 6| Step: 7
Training loss: 3.4707252445922174
Validation loss: 3.1278816063136667

Epoch: 6| Step: 8
Training loss: 3.2999727421415095
Validation loss: 3.1180205933154572

Epoch: 6| Step: 9
Training loss: 3.248956072481296
Validation loss: 3.1126270368256668

Epoch: 6| Step: 10
Training loss: 3.66005749808418
Validation loss: 3.1102174955360176

Epoch: 6| Step: 11
Training loss: 3.5597899987935038
Validation loss: 3.111096173778933

Epoch: 6| Step: 12
Training loss: 2.9220328058885587
Validation loss: 3.1117178317512897

Epoch: 6| Step: 13
Training loss: 2.6877765956751833
Validation loss: 3.1113607622754325

Epoch: 63| Step: 0
Training loss: 2.8811301514695637
Validation loss: 3.113782345023959

Epoch: 6| Step: 1
Training loss: 4.076184508994555
Validation loss: 3.11162025804298

Epoch: 6| Step: 2
Training loss: 3.028555547538927
Validation loss: 3.114003899257543

Epoch: 6| Step: 3
Training loss: 3.3901037703304007
Validation loss: 3.113139589812682

Epoch: 6| Step: 4
Training loss: 3.4740730201896124
Validation loss: 3.1125156179972677

Epoch: 6| Step: 5
Training loss: 3.123183523579818
Validation loss: 3.108753476351989

Epoch: 6| Step: 6
Training loss: 3.3539620726049746
Validation loss: 3.1100509996218664

Epoch: 6| Step: 7
Training loss: 3.02472574551335
Validation loss: 3.108496349858712

Epoch: 6| Step: 8
Training loss: 3.4554728125682654
Validation loss: 3.108449097963773

Epoch: 6| Step: 9
Training loss: 3.4720948734241976
Validation loss: 3.106147418809747

Epoch: 6| Step: 10
Training loss: 2.558501869473828
Validation loss: 3.1074306563478395

Epoch: 6| Step: 11
Training loss: 4.318448373333808
Validation loss: 3.1076050060101936

Epoch: 6| Step: 12
Training loss: 3.0511279037407384
Validation loss: 3.1066519486859736

Epoch: 6| Step: 13
Training loss: 3.8457879347238046
Validation loss: 3.1084078816574694

Epoch: 64| Step: 0
Training loss: 3.317937023639007
Validation loss: 3.1084948455681722

Epoch: 6| Step: 1
Training loss: 3.082884231715039
Validation loss: 3.1156730368471193

Epoch: 6| Step: 2
Training loss: 3.7856936235712277
Validation loss: 3.116774317885051

Epoch: 6| Step: 3
Training loss: 2.5426592426074976
Validation loss: 3.1074553881992104

Epoch: 6| Step: 4
Training loss: 3.370995017293293
Validation loss: 3.1042019586786056

Epoch: 6| Step: 5
Training loss: 3.6081492006278926
Validation loss: 3.103590762709883

Epoch: 6| Step: 6
Training loss: 3.4796406010043914
Validation loss: 3.103893456029348

Epoch: 6| Step: 7
Training loss: 2.9860951524253845
Validation loss: 3.1026138883884915

Epoch: 6| Step: 8
Training loss: 3.903584417666303
Validation loss: 3.1030506677947405

Epoch: 6| Step: 9
Training loss: 3.5568877065723523
Validation loss: 3.103651385675452

Epoch: 6| Step: 10
Training loss: 2.9551926897612217
Validation loss: 3.1090750139124554

Epoch: 6| Step: 11
Training loss: 3.4639891524200097
Validation loss: 3.110577739082015

Epoch: 6| Step: 12
Training loss: 3.746083821431707
Validation loss: 3.1023309136555084

Epoch: 6| Step: 13
Training loss: 2.9203361498026625
Validation loss: 3.1019449376121617

Epoch: 65| Step: 0
Training loss: 4.116244184511341
Validation loss: 3.1072807009495986

Epoch: 6| Step: 1
Training loss: 3.1703594326495446
Validation loss: 3.104269974228242

Epoch: 6| Step: 2
Training loss: 2.6193596323773543
Validation loss: 3.100453900726658

Epoch: 6| Step: 3
Training loss: 3.6870204807723495
Validation loss: 3.098962056271571

Epoch: 6| Step: 4
Training loss: 3.643638836848223
Validation loss: 3.0975022302452166

Epoch: 6| Step: 5
Training loss: 3.746781557523059
Validation loss: 3.0980077526331007

Epoch: 6| Step: 6
Training loss: 3.0827153248076136
Validation loss: 3.0976114579538723

Epoch: 6| Step: 7
Training loss: 3.4351987591894475
Validation loss: 3.096557884262915

Epoch: 6| Step: 8
Training loss: 2.7120476024636004
Validation loss: 3.097264803778207

Epoch: 6| Step: 9
Training loss: 3.6526432342956654
Validation loss: 3.096199298303936

Epoch: 6| Step: 10
Training loss: 2.773438015790005
Validation loss: 3.098005780669805

Epoch: 6| Step: 11
Training loss: 2.9753925096611793
Validation loss: 3.0955682927721804

Epoch: 6| Step: 12
Training loss: 3.7833689907819137
Validation loss: 3.0967145529457225

Epoch: 6| Step: 13
Training loss: 3.1453219539161044
Validation loss: 3.0963872940564228

Epoch: 66| Step: 0
Training loss: 3.0492588205756492
Validation loss: 3.100954459422583

Epoch: 6| Step: 1
Training loss: 2.814420934171388
Validation loss: 3.1423646021777314

Epoch: 6| Step: 2
Training loss: 3.569935851816386
Validation loss: 3.2325569089185175

Epoch: 6| Step: 3
Training loss: 3.672754060748837
Validation loss: 3.1931253796627814

Epoch: 6| Step: 4
Training loss: 3.8002786333425655
Validation loss: 3.133810794300063

Epoch: 6| Step: 5
Training loss: 3.665452380396464
Validation loss: 3.128275361964598

Epoch: 6| Step: 6
Training loss: 2.9967805754073273
Validation loss: 3.09650173391207

Epoch: 6| Step: 7
Training loss: 2.957764387268408
Validation loss: 3.1172087726704487

Epoch: 6| Step: 8
Training loss: 3.011689459315656
Validation loss: 3.15229357213278

Epoch: 6| Step: 9
Training loss: 3.7697903084557054
Validation loss: 3.1921873009600894

Epoch: 6| Step: 10
Training loss: 3.7821171294360947
Validation loss: 3.1344870863883756

Epoch: 6| Step: 11
Training loss: 3.867533227128043
Validation loss: 3.0926617452358522

Epoch: 6| Step: 12
Training loss: 2.9449164733958617
Validation loss: 3.091461314548159

Epoch: 6| Step: 13
Training loss: 3.1805166901976754
Validation loss: 3.1136747170699444

Epoch: 67| Step: 0
Training loss: 1.6885834500671195
Validation loss: 3.161850601325057

Epoch: 6| Step: 1
Training loss: 4.133405271539913
Validation loss: 3.2477766008930073

Epoch: 6| Step: 2
Training loss: 3.5798397036846703
Validation loss: 3.1770658000675405

Epoch: 6| Step: 3
Training loss: 3.720152518314469
Validation loss: 3.106671517657188

Epoch: 6| Step: 4
Training loss: 3.893162156701046
Validation loss: 3.0886058879896643

Epoch: 6| Step: 5
Training loss: 2.890285327646307
Validation loss: 3.0914137035906757

Epoch: 6| Step: 6
Training loss: 3.8351402308801092
Validation loss: 3.104654340859407

Epoch: 6| Step: 7
Training loss: 3.768360205083095
Validation loss: 3.119261551340855

Epoch: 6| Step: 8
Training loss: 3.4689328257175607
Validation loss: 3.127109632583492

Epoch: 6| Step: 9
Training loss: 2.4059583809250333
Validation loss: 3.1234252793199713

Epoch: 6| Step: 10
Training loss: 2.6040435049814703
Validation loss: 3.127535051415139

Epoch: 6| Step: 11
Training loss: 3.6310889308484953
Validation loss: 3.137152830562008

Epoch: 6| Step: 12
Training loss: 3.7218110124675077
Validation loss: 3.121391827043686

Epoch: 6| Step: 13
Training loss: 3.136004945099104
Validation loss: 3.0958161558803856

Epoch: 68| Step: 0
Training loss: 3.1661927387226814
Validation loss: 3.0822690863685462

Epoch: 6| Step: 1
Training loss: 1.8810543858414317
Validation loss: 3.0806266859090385

Epoch: 6| Step: 2
Training loss: 3.4405099348876393
Validation loss: 3.0784254946110616

Epoch: 6| Step: 3
Training loss: 4.032198535602826
Validation loss: 3.0807908064595

Epoch: 6| Step: 4
Training loss: 3.4785254947922866
Validation loss: 3.090142802234673

Epoch: 6| Step: 5
Training loss: 3.107141046883693
Validation loss: 3.096820636194001

Epoch: 6| Step: 6
Training loss: 3.053673617406665
Validation loss: 3.1066049443617962

Epoch: 6| Step: 7
Training loss: 3.423092142267445
Validation loss: 3.095091345746459

Epoch: 6| Step: 8
Training loss: 3.6787178073917137
Validation loss: 3.0826506908022075

Epoch: 6| Step: 9
Training loss: 3.1128232611883875
Validation loss: 3.079912543528746

Epoch: 6| Step: 10
Training loss: 3.884587517323884
Validation loss: 3.0817024892301332

Epoch: 6| Step: 11
Training loss: 3.677372878708726
Validation loss: 3.080651045846626

Epoch: 6| Step: 12
Training loss: 3.159639257289676
Validation loss: 3.074331199867118

Epoch: 6| Step: 13
Training loss: 3.202204427785125
Validation loss: 3.0763259860030012

Epoch: 69| Step: 0
Training loss: 3.3496643239844235
Validation loss: 3.0773389483180402

Epoch: 6| Step: 1
Training loss: 3.724801533167481
Validation loss: 3.0811647844968473

Epoch: 6| Step: 2
Training loss: 2.7258723131419256
Validation loss: 3.082369144501459

Epoch: 6| Step: 3
Training loss: 2.8262655141169275
Validation loss: 3.0928910132826752

Epoch: 6| Step: 4
Training loss: 3.6492637989201175
Validation loss: 3.0936289233574046

Epoch: 6| Step: 5
Training loss: 2.363717434566499
Validation loss: 3.0931842311904756

Epoch: 6| Step: 6
Training loss: 3.5462637891424005
Validation loss: 3.0847887951371713

Epoch: 6| Step: 7
Training loss: 3.8451781062233126
Validation loss: 3.078203678244731

Epoch: 6| Step: 8
Training loss: 3.174360832697977
Validation loss: 3.0770726091167444

Epoch: 6| Step: 9
Training loss: 3.399999360477163
Validation loss: 3.073119374397816

Epoch: 6| Step: 10
Training loss: 3.5256097360925343
Validation loss: 3.0762900169592458

Epoch: 6| Step: 11
Training loss: 2.967989211728624
Validation loss: 3.0749730363516194

Epoch: 6| Step: 12
Training loss: 3.3771362608037663
Validation loss: 3.07913218347971

Epoch: 6| Step: 13
Training loss: 4.487802504860462
Validation loss: 3.0772318518952497

Epoch: 70| Step: 0
Training loss: 3.818436799886383
Validation loss: 3.0811575457734133

Epoch: 6| Step: 1
Training loss: 2.7990305175862065
Validation loss: 3.0796170730360104

Epoch: 6| Step: 2
Training loss: 4.037806656945941
Validation loss: 3.1005975527098077

Epoch: 6| Step: 3
Training loss: 2.7210448653599517
Validation loss: 3.0846161528155904

Epoch: 6| Step: 4
Training loss: 2.3982710889312364
Validation loss: 3.0768718951573564

Epoch: 6| Step: 5
Training loss: 4.147938613922951
Validation loss: 3.0765871535486333

Epoch: 6| Step: 6
Training loss: 4.0540411108686705
Validation loss: 3.0755848747627215

Epoch: 6| Step: 7
Training loss: 2.7011795540326045
Validation loss: 3.070950825408862

Epoch: 6| Step: 8
Training loss: 3.404182996831329
Validation loss: 3.0698626498500707

Epoch: 6| Step: 9
Training loss: 3.189805038856307
Validation loss: 3.0659559671839003

Epoch: 6| Step: 10
Training loss: 3.0240244529785
Validation loss: 3.0639126039254854

Epoch: 6| Step: 11
Training loss: 3.5145605213545776
Validation loss: 3.064510771072617

Epoch: 6| Step: 12
Training loss: 3.5632929672319547
Validation loss: 3.064668334371934

Epoch: 6| Step: 13
Training loss: 2.165621199611395
Validation loss: 3.0646403879557127

Epoch: 71| Step: 0
Training loss: 3.9555263538449488
Validation loss: 3.065017435642913

Epoch: 6| Step: 1
Training loss: 3.0332991762299164
Validation loss: 3.0637394211705122

Epoch: 6| Step: 2
Training loss: 2.9979640091866377
Validation loss: 3.06349752527771

Epoch: 6| Step: 3
Training loss: 3.3710640456215923
Validation loss: 3.0646362973579633

Epoch: 6| Step: 4
Training loss: 2.9262386927005313
Validation loss: 3.063995951100898

Epoch: 6| Step: 5
Training loss: 3.5034263733022013
Validation loss: 3.062222836349803

Epoch: 6| Step: 6
Training loss: 3.3266201288437514
Validation loss: 3.0617613773341428

Epoch: 6| Step: 7
Training loss: 3.0703799019518043
Validation loss: 3.0623689983008093

Epoch: 6| Step: 8
Training loss: 3.4489181923304146
Validation loss: 3.0600058959911105

Epoch: 6| Step: 9
Training loss: 3.2439210232905915
Validation loss: 3.059283174521897

Epoch: 6| Step: 10
Training loss: 3.3956136964005648
Validation loss: 3.0576023335908826

Epoch: 6| Step: 11
Training loss: 3.343903725200994
Validation loss: 3.059121017993939

Epoch: 6| Step: 12
Training loss: 3.2874026788150954
Validation loss: 3.056886935512923

Epoch: 6| Step: 13
Training loss: 3.8126094364656415
Validation loss: 3.057054077773337

Epoch: 72| Step: 0
Training loss: 3.396635152004843
Validation loss: 3.0590403488290914

Epoch: 6| Step: 1
Training loss: 3.0901286190387203
Validation loss: 3.057659638460998

Epoch: 6| Step: 2
Training loss: 3.472560679576362
Validation loss: 3.0594255988905372

Epoch: 6| Step: 3
Training loss: 3.475437899655287
Validation loss: 3.0621930040285545

Epoch: 6| Step: 4
Training loss: 3.6376902002900318
Validation loss: 3.0635363357455776

Epoch: 6| Step: 5
Training loss: 3.5495662477949828
Validation loss: 3.0589652331375214

Epoch: 6| Step: 6
Training loss: 3.475628330865014
Validation loss: 3.0609747374266147

Epoch: 6| Step: 7
Training loss: 3.0059764460023466
Validation loss: 3.0587232949394143

Epoch: 6| Step: 8
Training loss: 3.884035834975085
Validation loss: 3.054239045080004

Epoch: 6| Step: 9
Training loss: 2.6197913127517207
Validation loss: 3.0566668681803324

Epoch: 6| Step: 10
Training loss: 3.03273603056971
Validation loss: 3.0542289188877056

Epoch: 6| Step: 11
Training loss: 3.4837906009537867
Validation loss: 3.052846873889162

Epoch: 6| Step: 12
Training loss: 3.4024609130587495
Validation loss: 3.0530936777157285

Epoch: 6| Step: 13
Training loss: 2.22171649608931
Validation loss: 3.053616065627737

Epoch: 73| Step: 0
Training loss: 3.1627149184707712
Validation loss: 3.053663705937971

Epoch: 6| Step: 1
Training loss: 3.0055957105974054
Validation loss: 3.0537401105580835

Epoch: 6| Step: 2
Training loss: 3.997770880419375
Validation loss: 3.0514217960174337

Epoch: 6| Step: 3
Training loss: 3.1400807986220673
Validation loss: 3.051140670966231

Epoch: 6| Step: 4
Training loss: 4.025618293613296
Validation loss: 3.0534966601927587

Epoch: 6| Step: 5
Training loss: 3.253593805339948
Validation loss: 3.0504226220634485

Epoch: 6| Step: 6
Training loss: 3.051276524548415
Validation loss: 3.0505994206047164

Epoch: 6| Step: 7
Training loss: 3.4795676969160803
Validation loss: 3.050394687166609

Epoch: 6| Step: 8
Training loss: 3.5015845118064415
Validation loss: 3.050298145541625

Epoch: 6| Step: 9
Training loss: 3.054296287988337
Validation loss: 3.0494035946308955

Epoch: 6| Step: 10
Training loss: 3.322997248678018
Validation loss: 3.0478611581006168

Epoch: 6| Step: 11
Training loss: 3.4139800945611225
Validation loss: 3.048415819614299

Epoch: 6| Step: 12
Training loss: 2.9602510567466616
Validation loss: 3.050350752575604

Epoch: 6| Step: 13
Training loss: 2.4528553808466054
Validation loss: 3.046115080644161

Epoch: 74| Step: 0
Training loss: 3.3195626163773886
Validation loss: 3.0500944761413478

Epoch: 6| Step: 1
Training loss: 2.703176861745088
Validation loss: 3.0471719728037443

Epoch: 6| Step: 2
Training loss: 3.272231432893315
Validation loss: 3.047548456178353

Epoch: 6| Step: 3
Training loss: 2.980471469782917
Validation loss: 3.0472953394956126

Epoch: 6| Step: 4
Training loss: 3.588200538636149
Validation loss: 3.046057236245903

Epoch: 6| Step: 5
Training loss: 3.4920386638969747
Validation loss: 3.0454382702932756

Epoch: 6| Step: 6
Training loss: 3.192922131762996
Validation loss: 3.045712283075235

Epoch: 6| Step: 7
Training loss: 3.6521476488965803
Validation loss: 3.048545722211273

Epoch: 6| Step: 8
Training loss: 3.3075204524808464
Validation loss: 3.0470643343601087

Epoch: 6| Step: 9
Training loss: 3.293514618253487
Validation loss: 3.0496110998024832

Epoch: 6| Step: 10
Training loss: 2.411121539881
Validation loss: 3.049850924738874

Epoch: 6| Step: 11
Training loss: 4.201521897465585
Validation loss: 3.0467208819119413

Epoch: 6| Step: 12
Training loss: 3.466466891205613
Validation loss: 3.0521260849701237

Epoch: 6| Step: 13
Training loss: 3.0468868940072333
Validation loss: 3.049275272175064

Epoch: 75| Step: 0
Training loss: 4.398561519954475
Validation loss: 3.0474616820293896

Epoch: 6| Step: 1
Training loss: 3.005728497546702
Validation loss: 3.0429635788527145

Epoch: 6| Step: 2
Training loss: 2.363731354025128
Validation loss: 3.046153580687751

Epoch: 6| Step: 3
Training loss: 4.318060786545139
Validation loss: 3.046473417066523

Epoch: 6| Step: 4
Training loss: 2.3287646547799317
Validation loss: 3.048764923551195

Epoch: 6| Step: 5
Training loss: 3.129077692371191
Validation loss: 3.046591432479063

Epoch: 6| Step: 6
Training loss: 3.788531771585658
Validation loss: 3.0469440579640774

Epoch: 6| Step: 7
Training loss: 3.5724575685686784
Validation loss: 3.0482615910411943

Epoch: 6| Step: 8
Training loss: 2.579407898730293
Validation loss: 3.0431640078770954

Epoch: 6| Step: 9
Training loss: 3.3744859657193587
Validation loss: 3.039402312037818

Epoch: 6| Step: 10
Training loss: 2.8276615500739046
Validation loss: 3.045111058027079

Epoch: 6| Step: 11
Training loss: 3.05966460091507
Validation loss: 3.041966475071587

Epoch: 6| Step: 12
Training loss: 3.8013204288198956
Validation loss: 3.039480075480821

Epoch: 6| Step: 13
Training loss: 2.5951411182054973
Validation loss: 3.040028091251221

Epoch: 76| Step: 0
Training loss: 3.399108960696107
Validation loss: 3.0396589822129885

Epoch: 6| Step: 1
Training loss: 2.85330305933118
Validation loss: 3.0380201936707776

Epoch: 6| Step: 2
Training loss: 2.8510330335723064
Validation loss: 3.0417764694166647

Epoch: 6| Step: 3
Training loss: 3.2521152948490633
Validation loss: 3.039687714941527

Epoch: 6| Step: 4
Training loss: 3.6367035403481625
Validation loss: 3.0386532161704567

Epoch: 6| Step: 5
Training loss: 3.7169360697546394
Validation loss: 3.038553632014008

Epoch: 6| Step: 6
Training loss: 3.7089013225463066
Validation loss: 3.0360906305108855

Epoch: 6| Step: 7
Training loss: 3.5571610448638222
Validation loss: 3.037534062039154

Epoch: 6| Step: 8
Training loss: 3.387028769060914
Validation loss: 3.035755661609802

Epoch: 6| Step: 9
Training loss: 2.959228344418386
Validation loss: 3.035527688545434

Epoch: 6| Step: 10
Training loss: 3.236991671565917
Validation loss: 3.0351052040741076

Epoch: 6| Step: 11
Training loss: 3.0834706937418814
Validation loss: 3.033442999750393

Epoch: 6| Step: 12
Training loss: 2.8728930174748863
Validation loss: 3.032678507504512

Epoch: 6| Step: 13
Training loss: 3.71208195757001
Validation loss: 3.033911300150083

Epoch: 77| Step: 0
Training loss: 3.0351557786860157
Validation loss: 3.0325766204957336

Epoch: 6| Step: 1
Training loss: 3.2936617121002096
Validation loss: 3.030981398905964

Epoch: 6| Step: 2
Training loss: 3.6395728428643417
Validation loss: 3.0306717211392704

Epoch: 6| Step: 3
Training loss: 2.692060548841112
Validation loss: 3.031899444693737

Epoch: 6| Step: 4
Training loss: 2.8222361421200084
Validation loss: 3.0327515472736524

Epoch: 6| Step: 5
Training loss: 3.9950667000216744
Validation loss: 3.0313258768929927

Epoch: 6| Step: 6
Training loss: 2.5440765171299797
Validation loss: 3.029253435012846

Epoch: 6| Step: 7
Training loss: 3.788378592837693
Validation loss: 3.0285575867315764

Epoch: 6| Step: 8
Training loss: 3.5574752440030184
Validation loss: 3.0293034607624927

Epoch: 6| Step: 9
Training loss: 2.681262651604812
Validation loss: 3.0310320287933017

Epoch: 6| Step: 10
Training loss: 3.222932043123132
Validation loss: 3.028945749007574

Epoch: 6| Step: 11
Training loss: 3.3965643971489032
Validation loss: 3.029015234357338

Epoch: 6| Step: 12
Training loss: 3.478639269542408
Validation loss: 3.029392549099832

Epoch: 6| Step: 13
Training loss: 3.9236167900171885
Validation loss: 3.030305071328521

Epoch: 78| Step: 0
Training loss: 3.6462455879736604
Validation loss: 3.0281884078447403

Epoch: 6| Step: 1
Training loss: 2.978426772496436
Validation loss: 3.029094308841834

Epoch: 6| Step: 2
Training loss: 3.5547484004913623
Validation loss: 3.0307913711189443

Epoch: 6| Step: 3
Training loss: 3.4532534199996467
Validation loss: 3.0371122348279846

Epoch: 6| Step: 4
Training loss: 3.5215088837628126
Validation loss: 3.0420593539785403

Epoch: 6| Step: 5
Training loss: 3.576380141822628
Validation loss: 3.039838210694794

Epoch: 6| Step: 6
Training loss: 3.499618236974632
Validation loss: 3.0383064301103033

Epoch: 6| Step: 7
Training loss: 3.6073033055686765
Validation loss: 3.0245333073677596

Epoch: 6| Step: 8
Training loss: 2.7237047669434924
Validation loss: 3.0245708802243567

Epoch: 6| Step: 9
Training loss: 3.6978469770428575
Validation loss: 3.024782394288369

Epoch: 6| Step: 10
Training loss: 2.128464063165849
Validation loss: 3.027063684121874

Epoch: 6| Step: 11
Training loss: 2.8344413236451906
Validation loss: 3.0269913049127695

Epoch: 6| Step: 12
Training loss: 2.887489556628081
Validation loss: 3.027838276019133

Epoch: 6| Step: 13
Training loss: 3.9005314587117983
Validation loss: 3.0287011986476693

Epoch: 79| Step: 0
Training loss: 2.480461541112802
Validation loss: 3.0293673999693014

Epoch: 6| Step: 1
Training loss: 3.7504654913320246
Validation loss: 3.0398229637730596

Epoch: 6| Step: 2
Training loss: 4.053600246358216
Validation loss: 3.0369895771890474

Epoch: 6| Step: 3
Training loss: 3.171083849628084
Validation loss: 3.0374313622217812

Epoch: 6| Step: 4
Training loss: 2.8342776314393827
Validation loss: 3.033509983673732

Epoch: 6| Step: 5
Training loss: 3.9988165535237234
Validation loss: 3.0294192466562158

Epoch: 6| Step: 6
Training loss: 3.0970044213898693
Validation loss: 3.0286752845053755

Epoch: 6| Step: 7
Training loss: 2.140296632404634
Validation loss: 3.0275031731024273

Epoch: 6| Step: 8
Training loss: 3.6261747364122074
Validation loss: 3.0286320269044973

Epoch: 6| Step: 9
Training loss: 3.9939940185502087
Validation loss: 3.032834826897362

Epoch: 6| Step: 10
Training loss: 2.9536468206296473
Validation loss: 3.020571556813941

Epoch: 6| Step: 11
Training loss: 2.900667962066611
Validation loss: 3.0197896762041307

Epoch: 6| Step: 12
Training loss: 3.225631025220377
Validation loss: 3.023576227110797

Epoch: 6| Step: 13
Training loss: 3.2802610814462883
Validation loss: 3.0333624142543387

Epoch: 80| Step: 0
Training loss: 3.037315670746893
Validation loss: 3.0467540968347233

Epoch: 6| Step: 1
Training loss: 3.031432785343535
Validation loss: 3.0394686265084108

Epoch: 6| Step: 2
Training loss: 3.3947197584129354
Validation loss: 3.0368206721429107

Epoch: 6| Step: 3
Training loss: 3.588353359262799
Validation loss: 3.0272008087676916

Epoch: 6| Step: 4
Training loss: 3.686077037335343
Validation loss: 3.0227125020978023

Epoch: 6| Step: 5
Training loss: 3.4368678118513865
Validation loss: 3.0187522820405683

Epoch: 6| Step: 6
Training loss: 3.35931566762648
Validation loss: 3.0161614777936196

Epoch: 6| Step: 7
Training loss: 2.476847057661393
Validation loss: 3.014418720168827

Epoch: 6| Step: 8
Training loss: 3.7033768580294244
Validation loss: 3.015721320364687

Epoch: 6| Step: 9
Training loss: 3.077403027442221
Validation loss: 3.015297421938869

Epoch: 6| Step: 10
Training loss: 3.768598087216087
Validation loss: 3.01557867495013

Epoch: 6| Step: 11
Training loss: 2.1676339655640646
Validation loss: 3.0140806334057606

Epoch: 6| Step: 12
Training loss: 3.4275115111844277
Validation loss: 3.013423768545986

Epoch: 6| Step: 13
Training loss: 3.745245526239748
Validation loss: 3.0127128997979185

Epoch: 81| Step: 0
Training loss: 2.997525784315578
Validation loss: 3.013193967208394

Epoch: 6| Step: 1
Training loss: 3.6723829851406813
Validation loss: 3.010123991908443

Epoch: 6| Step: 2
Training loss: 3.361235773035869
Validation loss: 3.0133364779377625

Epoch: 6| Step: 3
Training loss: 3.2546160268421427
Validation loss: 3.0110484267673114

Epoch: 6| Step: 4
Training loss: 3.8014827445523025
Validation loss: 3.0118349974143968

Epoch: 6| Step: 5
Training loss: 2.6046197013978665
Validation loss: 3.0105543837818254

Epoch: 6| Step: 6
Training loss: 3.9592569311011085
Validation loss: 3.010037175392766

Epoch: 6| Step: 7
Training loss: 2.8657677068921203
Validation loss: 3.0104035124115414

Epoch: 6| Step: 8
Training loss: 3.3550426847695958
Validation loss: 3.010166225213114

Epoch: 6| Step: 9
Training loss: 3.0106173825697207
Validation loss: 3.0093350632421525

Epoch: 6| Step: 10
Training loss: 3.3408164587726237
Validation loss: 3.010593364980184

Epoch: 6| Step: 11
Training loss: 3.1414430985641157
Validation loss: 3.010246057136451

Epoch: 6| Step: 12
Training loss: 3.198529477793272
Validation loss: 3.008316263352617

Epoch: 6| Step: 13
Training loss: 3.0553069986530104
Validation loss: 3.0101609295814775

Epoch: 82| Step: 0
Training loss: 3.219165960304077
Validation loss: 3.0123522562649243

Epoch: 6| Step: 1
Training loss: 3.44633679723069
Validation loss: 3.01523941569927

Epoch: 6| Step: 2
Training loss: 3.6835804167391912
Validation loss: 3.030618006109077

Epoch: 6| Step: 3
Training loss: 3.1178869547828665
Validation loss: 3.0410324938073865

Epoch: 6| Step: 4
Training loss: 2.866185317176805
Validation loss: 3.0184229005095826

Epoch: 6| Step: 5
Training loss: 2.2888119921786436
Validation loss: 3.0141538261565493

Epoch: 6| Step: 6
Training loss: 3.873971741131629
Validation loss: 3.0115692291804135

Epoch: 6| Step: 7
Training loss: 3.3676400643880404
Validation loss: 3.0068903928304875

Epoch: 6| Step: 8
Training loss: 2.4310584416961554
Validation loss: 3.006432283363689

Epoch: 6| Step: 9
Training loss: 3.75553777610237
Validation loss: 3.0057094859391893

Epoch: 6| Step: 10
Training loss: 3.0822829613923113
Validation loss: 3.0102391486391706

Epoch: 6| Step: 11
Training loss: 3.2106440426271226
Validation loss: 3.006467155087343

Epoch: 6| Step: 12
Training loss: 3.716150224554314
Validation loss: 3.0068354208218735

Epoch: 6| Step: 13
Training loss: 3.5258270754330727
Validation loss: 3.003721245914013

Epoch: 83| Step: 0
Training loss: 3.3305622185251673
Validation loss: 3.0047545595985254

Epoch: 6| Step: 1
Training loss: 2.1951739175842953
Validation loss: 3.003935781288089

Epoch: 6| Step: 2
Training loss: 2.9166174929878674
Validation loss: 3.0033293506306866

Epoch: 6| Step: 3
Training loss: 3.583291667134135
Validation loss: 3.0033351038862626

Epoch: 6| Step: 4
Training loss: 3.8197093401670466
Validation loss: 3.0020869338511202

Epoch: 6| Step: 5
Training loss: 2.2193760593060494
Validation loss: 3.0017208552566492

Epoch: 6| Step: 6
Training loss: 3.7333129904964792
Validation loss: 3.003758171853956

Epoch: 6| Step: 7
Training loss: 2.8616574042615994
Validation loss: 3.0018834675705044

Epoch: 6| Step: 8
Training loss: 3.203322985973444
Validation loss: 3.0012011499053632

Epoch: 6| Step: 9
Training loss: 3.0464737065462644
Validation loss: 2.996979425051036

Epoch: 6| Step: 10
Training loss: 4.164648762669699
Validation loss: 2.99767677272972

Epoch: 6| Step: 11
Training loss: 3.458362318783056
Validation loss: 2.9991617262134724

Epoch: 6| Step: 12
Training loss: 3.6574778003240542
Validation loss: 3.001806530467607

Epoch: 6| Step: 13
Training loss: 2.7445760469719733
Validation loss: 2.9977468468940693

Epoch: 84| Step: 0
Training loss: 2.988769491364258
Validation loss: 2.9976334825846562

Epoch: 6| Step: 1
Training loss: 2.714681716584318
Validation loss: 2.9986494777650434

Epoch: 6| Step: 2
Training loss: 3.937008297206826
Validation loss: 2.997089089791511

Epoch: 6| Step: 3
Training loss: 3.070844220815446
Validation loss: 2.996601164073845

Epoch: 6| Step: 4
Training loss: 3.424194525237648
Validation loss: 3.0021771150392715

Epoch: 6| Step: 5
Training loss: 2.96874309338218
Validation loss: 2.999363761691582

Epoch: 6| Step: 6
Training loss: 3.5070335015969327
Validation loss: 3.0015491806250374

Epoch: 6| Step: 7
Training loss: 3.619932381435735
Validation loss: 3.0007223025411527

Epoch: 6| Step: 8
Training loss: 3.2830921633167764
Validation loss: 2.9994167150518685

Epoch: 6| Step: 9
Training loss: 3.5955832408042974
Validation loss: 2.997665102522803

Epoch: 6| Step: 10
Training loss: 3.034876747959491
Validation loss: 3.0021167861857556

Epoch: 6| Step: 11
Training loss: 3.6463686450150816
Validation loss: 3.002357212272662

Epoch: 6| Step: 12
Training loss: 2.5184843505409513
Validation loss: 2.9926328440897643

Epoch: 6| Step: 13
Training loss: 3.1082439569981988
Validation loss: 2.993133293488468

Epoch: 85| Step: 0
Training loss: 3.4886894030008393
Validation loss: 2.9928348594622407

Epoch: 6| Step: 1
Training loss: 3.1948429872619464
Validation loss: 2.9931101933963684

Epoch: 6| Step: 2
Training loss: 3.0644616831361535
Validation loss: 2.9920798267624686

Epoch: 6| Step: 3
Training loss: 3.0269874412293736
Validation loss: 2.9924614225441877

Epoch: 6| Step: 4
Training loss: 3.4573826842909314
Validation loss: 2.9921902811003274

Epoch: 6| Step: 5
Training loss: 3.431003326832452
Validation loss: 2.989984671830227

Epoch: 6| Step: 6
Training loss: 4.049706135202175
Validation loss: 2.991059152999643

Epoch: 6| Step: 7
Training loss: 3.1184975684374976
Validation loss: 2.990720165660994

Epoch: 6| Step: 8
Training loss: 3.224109520805464
Validation loss: 2.992880087217575

Epoch: 6| Step: 9
Training loss: 2.8305424427165073
Validation loss: 2.9908249914773073

Epoch: 6| Step: 10
Training loss: 2.958834019230706
Validation loss: 2.9889541763731464

Epoch: 6| Step: 11
Training loss: 3.2960658232958613
Validation loss: 2.990908728799186

Epoch: 6| Step: 12
Training loss: 3.463878750949828
Validation loss: 2.9908529230359577

Epoch: 6| Step: 13
Training loss: 2.7877385606165856
Validation loss: 2.9880108351649586

Epoch: 86| Step: 0
Training loss: 3.3929878123655026
Validation loss: 2.9882278367904997

Epoch: 6| Step: 1
Training loss: 3.504857915373747
Validation loss: 2.987643181120066

Epoch: 6| Step: 2
Training loss: 3.0848538198105286
Validation loss: 2.988542235209012

Epoch: 6| Step: 3
Training loss: 3.290650190671771
Validation loss: 2.988118862646295

Epoch: 6| Step: 4
Training loss: 2.6985001000684767
Validation loss: 2.987448962700671

Epoch: 6| Step: 5
Training loss: 2.227876616727316
Validation loss: 2.9880157410658836

Epoch: 6| Step: 6
Training loss: 2.92996564434858
Validation loss: 2.9873233047662193

Epoch: 6| Step: 7
Training loss: 3.7476405032274194
Validation loss: 2.985160880075514

Epoch: 6| Step: 8
Training loss: 3.30230294990469
Validation loss: 2.9854004347076937

Epoch: 6| Step: 9
Training loss: 3.6463770143123395
Validation loss: 2.9850531440415478

Epoch: 6| Step: 10
Training loss: 3.07437540549477
Validation loss: 2.984283834580162

Epoch: 6| Step: 11
Training loss: 3.6040885490521983
Validation loss: 2.9853999933225555

Epoch: 6| Step: 12
Training loss: 3.4847331183766475
Validation loss: 2.9842234012871725

Epoch: 6| Step: 13
Training loss: 3.4828761687519627
Validation loss: 2.9838662238112423

Epoch: 87| Step: 0
Training loss: 4.026287247379785
Validation loss: 2.984175264074019

Epoch: 6| Step: 1
Training loss: 2.9003263421432726
Validation loss: 2.9835786268561266

Epoch: 6| Step: 2
Training loss: 3.357190508634726
Validation loss: 2.983238027258734

Epoch: 6| Step: 3
Training loss: 2.8682363810788227
Validation loss: 2.9840023695291285

Epoch: 6| Step: 4
Training loss: 2.7973263339084493
Validation loss: 2.9839523025531265

Epoch: 6| Step: 5
Training loss: 3.183935678292421
Validation loss: 2.9871635695863183

Epoch: 6| Step: 6
Training loss: 3.345630152808999
Validation loss: 2.9975625282922733

Epoch: 6| Step: 7
Training loss: 2.6814178129735646
Validation loss: 2.997061279650222

Epoch: 6| Step: 8
Training loss: 2.9877469651043467
Validation loss: 2.9866891882508004

Epoch: 6| Step: 9
Training loss: 3.1564793267360876
Validation loss: 2.989659152392071

Epoch: 6| Step: 10
Training loss: 3.5733205198181586
Validation loss: 2.9944293179156185

Epoch: 6| Step: 11
Training loss: 3.6838053928711254
Validation loss: 2.9831122331970907

Epoch: 6| Step: 12
Training loss: 3.037375013503642
Validation loss: 2.9803253084691628

Epoch: 6| Step: 13
Training loss: 4.009430021650302
Validation loss: 2.9788365805447596

Epoch: 88| Step: 0
Training loss: 3.4323890838150724
Validation loss: 2.9785210750159465

Epoch: 6| Step: 1
Training loss: 2.9545849617404096
Validation loss: 2.9792654404177488

Epoch: 6| Step: 2
Training loss: 2.5416796532804646
Validation loss: 2.979821057901296

Epoch: 6| Step: 3
Training loss: 4.044647192734651
Validation loss: 2.9761630652552684

Epoch: 6| Step: 4
Training loss: 3.359598409631577
Validation loss: 2.978972296925239

Epoch: 6| Step: 5
Training loss: 2.9381618971496968
Validation loss: 2.976311048582119

Epoch: 6| Step: 6
Training loss: 3.5548905870042313
Validation loss: 2.9775386905509507

Epoch: 6| Step: 7
Training loss: 3.253667376154686
Validation loss: 2.975742029669432

Epoch: 6| Step: 8
Training loss: 2.9952679506908138
Validation loss: 2.9752289949055166

Epoch: 6| Step: 9
Training loss: 3.593245761160466
Validation loss: 2.976176780294147

Epoch: 6| Step: 10
Training loss: 3.114190288396608
Validation loss: 2.975367381436596

Epoch: 6| Step: 11
Training loss: 3.3427837080801903
Validation loss: 2.9737235945106026

Epoch: 6| Step: 12
Training loss: 2.932074223118837
Validation loss: 2.975648060371233

Epoch: 6| Step: 13
Training loss: 3.250415188605208
Validation loss: 2.97641073937155

Epoch: 89| Step: 0
Training loss: 2.7914733724907626
Validation loss: 2.975954932945952

Epoch: 6| Step: 1
Training loss: 3.0722677978973563
Validation loss: 2.9730464878644374

Epoch: 6| Step: 2
Training loss: 3.675959227060832
Validation loss: 2.9728281676612256

Epoch: 6| Step: 3
Training loss: 3.2130415582423884
Validation loss: 2.9721631621915745

Epoch: 6| Step: 4
Training loss: 3.582071984245624
Validation loss: 2.972415885625575

Epoch: 6| Step: 5
Training loss: 3.6458532423656558
Validation loss: 2.97503584804568

Epoch: 6| Step: 6
Training loss: 3.299029184360929
Validation loss: 2.9750901831503227

Epoch: 6| Step: 7
Training loss: 3.412503722471785
Validation loss: 2.9805970226511787

Epoch: 6| Step: 8
Training loss: 3.010249589729772
Validation loss: 2.9765741409781663

Epoch: 6| Step: 9
Training loss: 2.8363363022365253
Validation loss: 2.9770045099899227

Epoch: 6| Step: 10
Training loss: 3.2110895645257624
Validation loss: 2.9770338465646304

Epoch: 6| Step: 11
Training loss: 3.2774505415966697
Validation loss: 2.9812191198566755

Epoch: 6| Step: 12
Training loss: 2.9977990660003058
Validation loss: 2.986720962680028

Epoch: 6| Step: 13
Training loss: 3.3436842582157986
Validation loss: 2.989757558633746

Epoch: 90| Step: 0
Training loss: 3.3659264843007617
Validation loss: 2.9770337940351372

Epoch: 6| Step: 1
Training loss: 2.988393265363794
Validation loss: 2.9691830848635323

Epoch: 6| Step: 2
Training loss: 3.344709312227414
Validation loss: 2.9667616432733155

Epoch: 6| Step: 3
Training loss: 3.4188348512040077
Validation loss: 2.9665946031436143

Epoch: 6| Step: 4
Training loss: 3.270814996817797
Validation loss: 2.967381360596679

Epoch: 6| Step: 5
Training loss: 3.745593724775048
Validation loss: 2.9689961148430792

Epoch: 6| Step: 6
Training loss: 3.02559771977202
Validation loss: 2.97512000133079

Epoch: 6| Step: 7
Training loss: 2.808489589324829
Validation loss: 2.9813784056493944

Epoch: 6| Step: 8
Training loss: 2.9751452178133486
Validation loss: 2.9778352354288464

Epoch: 6| Step: 9
Training loss: 3.3887582729439836
Validation loss: 2.968643347179635

Epoch: 6| Step: 10
Training loss: 2.9630998350248374
Validation loss: 2.966938527861736

Epoch: 6| Step: 11
Training loss: 3.430676293833163
Validation loss: 2.9646394225704498

Epoch: 6| Step: 12
Training loss: 3.7717347024964023
Validation loss: 2.9680982028560643

Epoch: 6| Step: 13
Training loss: 2.3594938336692146
Validation loss: 2.9652116380736633

Epoch: 91| Step: 0
Training loss: 3.5438176224326856
Validation loss: 2.9686141418561967

Epoch: 6| Step: 1
Training loss: 3.730555284704781
Validation loss: 2.9671901350509646

Epoch: 6| Step: 2
Training loss: 2.899258314853148
Validation loss: 2.9712080222012274

Epoch: 6| Step: 3
Training loss: 2.8577425940354826
Validation loss: 2.965404948469118

Epoch: 6| Step: 4
Training loss: 3.495267393173271
Validation loss: 2.9652393898586022

Epoch: 6| Step: 5
Training loss: 4.116833318716788
Validation loss: 2.9690003648419636

Epoch: 6| Step: 6
Training loss: 2.5993228470710723
Validation loss: 2.972632098183707

Epoch: 6| Step: 7
Training loss: 3.3919059337852313
Validation loss: 2.9793116460165714

Epoch: 6| Step: 8
Training loss: 3.1537882958807453
Validation loss: 2.9947488555773023

Epoch: 6| Step: 9
Training loss: 3.312349711913534
Validation loss: 2.969687425570975

Epoch: 6| Step: 10
Training loss: 2.904065203068677
Validation loss: 2.9606738051965484

Epoch: 6| Step: 11
Training loss: 2.560653486440211
Validation loss: 2.9603920174187692

Epoch: 6| Step: 12
Training loss: 3.095223432373417
Validation loss: 2.958833270629813

Epoch: 6| Step: 13
Training loss: 3.4452070362791187
Validation loss: 2.960262105426508

Epoch: 92| Step: 0
Training loss: 3.004623347335001
Validation loss: 2.9616399417679014

Epoch: 6| Step: 1
Training loss: 3.1376966802342956
Validation loss: 2.96071812064323

Epoch: 6| Step: 2
Training loss: 3.2493385228660987
Validation loss: 2.9618190338750456

Epoch: 6| Step: 3
Training loss: 3.01754604680563
Validation loss: 2.9605647892668783

Epoch: 6| Step: 4
Training loss: 3.089820909958251
Validation loss: 2.959474027955191

Epoch: 6| Step: 5
Training loss: 3.1685018408398116
Validation loss: 2.9608867746007625

Epoch: 6| Step: 6
Training loss: 3.588901333808646
Validation loss: 2.960890643150879

Epoch: 6| Step: 7
Training loss: 3.6705505579709166
Validation loss: 2.959351650466056

Epoch: 6| Step: 8
Training loss: 3.0615089525674084
Validation loss: 2.9596123975610373

Epoch: 6| Step: 9
Training loss: 2.99989223286662
Validation loss: 2.9579905005539904

Epoch: 6| Step: 10
Training loss: 3.6175275935219315
Validation loss: 2.9552920068575825

Epoch: 6| Step: 11
Training loss: 2.9134273706211173
Validation loss: 2.9568294268195268

Epoch: 6| Step: 12
Training loss: 3.0387620164452387
Validation loss: 2.9567759145111294

Epoch: 6| Step: 13
Training loss: 4.0047514828122495
Validation loss: 2.9548645191746474

Epoch: 93| Step: 0
Training loss: 3.329545984791883
Validation loss: 2.95861204210306

Epoch: 6| Step: 1
Training loss: 2.9644303869244255
Validation loss: 2.9589705698763495

Epoch: 6| Step: 2
Training loss: 3.8088257391284475
Validation loss: 2.9595185432766864

Epoch: 6| Step: 3
Training loss: 3.4784411894144958
Validation loss: 2.9590745182575686

Epoch: 6| Step: 4
Training loss: 3.4288540394428737
Validation loss: 2.955621134402881

Epoch: 6| Step: 5
Training loss: 3.028782105380002
Validation loss: 2.9528633154086297

Epoch: 6| Step: 6
Training loss: 3.0285306708017368
Validation loss: 2.950801630116002

Epoch: 6| Step: 7
Training loss: 2.754170463278535
Validation loss: 2.951607926452662

Epoch: 6| Step: 8
Training loss: 3.4977052522847534
Validation loss: 2.9519989181075488

Epoch: 6| Step: 9
Training loss: 2.9629831620251954
Validation loss: 2.951705654903076

Epoch: 6| Step: 10
Training loss: 3.613180952999876
Validation loss: 2.9487510557507988

Epoch: 6| Step: 11
Training loss: 2.396006094190843
Validation loss: 2.9501679032202768

Epoch: 6| Step: 12
Training loss: 3.035891567791768
Validation loss: 2.952680502338013

Epoch: 6| Step: 13
Training loss: 3.9716365859706384
Validation loss: 2.9572334850569946

Epoch: 94| Step: 0
Training loss: 3.254888818954479
Validation loss: 2.9621014518494597

Epoch: 6| Step: 1
Training loss: 3.440298986970606
Validation loss: 2.9654445127893556

Epoch: 6| Step: 2
Training loss: 3.467854564666351
Validation loss: 2.9555820344804915

Epoch: 6| Step: 3
Training loss: 3.736172805963738
Validation loss: 2.9533312664146507

Epoch: 6| Step: 4
Training loss: 3.2685198205023327
Validation loss: 2.957042267362263

Epoch: 6| Step: 5
Training loss: 3.2800965234463755
Validation loss: 2.9574219286059926

Epoch: 6| Step: 6
Training loss: 3.7381179757969867
Validation loss: 2.9630109026692657

Epoch: 6| Step: 7
Training loss: 2.137959400801404
Validation loss: 2.96245442910047

Epoch: 6| Step: 8
Training loss: 3.623836462141428
Validation loss: 2.9445754893556018

Epoch: 6| Step: 9
Training loss: 2.7406940795126307
Validation loss: 2.9449908471302573

Epoch: 6| Step: 10
Training loss: 2.916850456623327
Validation loss: 2.9460832358735702

Epoch: 6| Step: 11
Training loss: 3.086782914259703
Validation loss: 2.946358041745295

Epoch: 6| Step: 12
Training loss: 3.210470569380051
Validation loss: 2.9462473118523476

Epoch: 6| Step: 13
Training loss: 2.7036192337419798
Validation loss: 2.9424998091985675

Epoch: 95| Step: 0
Training loss: 3.385414444360248
Validation loss: 2.942413566796774

Epoch: 6| Step: 1
Training loss: 3.4296154805401073
Validation loss: 2.9423111204925676

Epoch: 6| Step: 2
Training loss: 3.2379951304634145
Validation loss: 2.943274030543594

Epoch: 6| Step: 3
Training loss: 2.6271813729547007
Validation loss: 2.94449349734846

Epoch: 6| Step: 4
Training loss: 2.1445420339622414
Validation loss: 2.942193597409939

Epoch: 6| Step: 5
Training loss: 2.9898513159894144
Validation loss: 2.9449638995345873

Epoch: 6| Step: 6
Training loss: 2.59725972067497
Validation loss: 2.9406870089670556

Epoch: 6| Step: 7
Training loss: 4.0532981535572805
Validation loss: 2.940695516684026

Epoch: 6| Step: 8
Training loss: 3.0232512345219633
Validation loss: 2.939773050159288

Epoch: 6| Step: 9
Training loss: 3.0125441551929666
Validation loss: 2.9388152533425407

Epoch: 6| Step: 10
Training loss: 3.543460227246819
Validation loss: 2.9394021090830016

Epoch: 6| Step: 11
Training loss: 3.218029793468039
Validation loss: 2.9386137223644555

Epoch: 6| Step: 12
Training loss: 3.583489141107934
Validation loss: 2.939205808070449

Epoch: 6| Step: 13
Training loss: 4.2352226506854285
Validation loss: 2.9400061043101204

Epoch: 96| Step: 0
Training loss: 3.560385762648428
Validation loss: 2.9428866352088447

Epoch: 6| Step: 1
Training loss: 3.418531761665756
Validation loss: 2.9435143847376244

Epoch: 6| Step: 2
Training loss: 3.14465680552911
Validation loss: 2.942424086508228

Epoch: 6| Step: 3
Training loss: 3.278324966950077
Validation loss: 2.943269086649034

Epoch: 6| Step: 4
Training loss: 2.9366739613171435
Validation loss: 2.93679576662873

Epoch: 6| Step: 5
Training loss: 3.846726296445858
Validation loss: 2.9365480408172444

Epoch: 6| Step: 6
Training loss: 2.2909109314447362
Validation loss: 2.9383265376032632

Epoch: 6| Step: 7
Training loss: 3.53872052492016
Validation loss: 2.938704668445127

Epoch: 6| Step: 8
Training loss: 2.8849049652684178
Validation loss: 2.9375373316068085

Epoch: 6| Step: 9
Training loss: 3.1752155921608947
Validation loss: 2.937574039626656

Epoch: 6| Step: 10
Training loss: 2.8949993954461872
Validation loss: 2.936796845579905

Epoch: 6| Step: 11
Training loss: 3.3056243939181886
Validation loss: 2.937018586076743

Epoch: 6| Step: 12
Training loss: 2.991699657063478
Validation loss: 2.936710307373515

Epoch: 6| Step: 13
Training loss: 3.78115567176377
Validation loss: 2.934889662318547

Epoch: 97| Step: 0
Training loss: 3.702207298686324
Validation loss: 2.9364892655930666

Epoch: 6| Step: 1
Training loss: 3.2349245645728066
Validation loss: 2.9350302443315903

Epoch: 6| Step: 2
Training loss: 3.2490466260068214
Validation loss: 2.9334556667579887

Epoch: 6| Step: 3
Training loss: 3.331188099699357
Validation loss: 2.9340397062813786

Epoch: 6| Step: 4
Training loss: 3.6523275609601105
Validation loss: 2.932583872241538

Epoch: 6| Step: 5
Training loss: 2.8682807688206924
Validation loss: 2.935293241024594

Epoch: 6| Step: 6
Training loss: 3.5733325297321534
Validation loss: 2.930664531373689

Epoch: 6| Step: 7
Training loss: 2.9124997118511793
Validation loss: 2.931751047875683

Epoch: 6| Step: 8
Training loss: 3.2256613297274592
Validation loss: 2.9311083199247316

Epoch: 6| Step: 9
Training loss: 3.0257074080640822
Validation loss: 2.941531781251919

Epoch: 6| Step: 10
Training loss: 4.156998416374516
Validation loss: 2.9434662959594458

Epoch: 6| Step: 11
Training loss: 2.367753266561158
Validation loss: 2.933360581420612

Epoch: 6| Step: 12
Training loss: 2.5979653540247396
Validation loss: 2.9334128542671336

Epoch: 6| Step: 13
Training loss: 2.0327563055951914
Validation loss: 2.9373607022105572

Epoch: 98| Step: 0
Training loss: 2.8539858201549473
Validation loss: 2.9303443466591865

Epoch: 6| Step: 1
Training loss: 3.38915983968672
Validation loss: 2.93201212482273

Epoch: 6| Step: 2
Training loss: 3.477456652921675
Validation loss: 2.9312440054171205

Epoch: 6| Step: 3
Training loss: 3.424967583273186
Validation loss: 2.9311254364196797

Epoch: 6| Step: 4
Training loss: 3.126774093582682
Validation loss: 2.927757459400076

Epoch: 6| Step: 5
Training loss: 2.8556993550542957
Validation loss: 2.928047187599434

Epoch: 6| Step: 6
Training loss: 2.893575286534424
Validation loss: 2.9290259459724193

Epoch: 6| Step: 7
Training loss: 3.544007204870818
Validation loss: 2.927849898501726

Epoch: 6| Step: 8
Training loss: 3.8210787950471508
Validation loss: 2.9291419795508116

Epoch: 6| Step: 9
Training loss: 2.107659553651372
Validation loss: 2.9296367253104574

Epoch: 6| Step: 10
Training loss: 3.5619273478377425
Validation loss: 2.9290059586119863

Epoch: 6| Step: 11
Training loss: 3.1993335149020017
Validation loss: 2.9298310704208714

Epoch: 6| Step: 12
Training loss: 3.479878076851046
Validation loss: 2.932352211018855

Epoch: 6| Step: 13
Training loss: 2.510776562568552
Validation loss: 2.9364605043809315

Epoch: 99| Step: 0
Training loss: 2.9862728774933713
Validation loss: 2.945372342081421

Epoch: 6| Step: 1
Training loss: 3.4191598092169304
Validation loss: 2.952173313532419

Epoch: 6| Step: 2
Training loss: 2.7177234333905997
Validation loss: 2.9285984942922827

Epoch: 6| Step: 3
Training loss: 3.6342400483966544
Validation loss: 2.9264149141124776

Epoch: 6| Step: 4
Training loss: 3.1504611570878533
Validation loss: 2.9264387544201993

Epoch: 6| Step: 5
Training loss: 3.5723347685865807
Validation loss: 2.924652429051369

Epoch: 6| Step: 6
Training loss: 3.290634685621652
Validation loss: 2.9227525912009584

Epoch: 6| Step: 7
Training loss: 3.608686505331574
Validation loss: 2.924700196057992

Epoch: 6| Step: 8
Training loss: 3.0705106637307065
Validation loss: 2.924098392582221

Epoch: 6| Step: 9
Training loss: 2.9316095583068282
Validation loss: 2.9244328419024583

Epoch: 6| Step: 10
Training loss: 3.331454764938296
Validation loss: 2.924357426349335

Epoch: 6| Step: 11
Training loss: 2.960754549921829
Validation loss: 2.9223785519242695

Epoch: 6| Step: 12
Training loss: 2.5323685423463025
Validation loss: 2.9246157630888523

Epoch: 6| Step: 13
Training loss: 3.8877928203436993
Validation loss: 2.9232205748522944

Epoch: 100| Step: 0
Training loss: 3.1259829691827505
Validation loss: 2.922076436095841

Epoch: 6| Step: 1
Training loss: 3.1326753581558955
Validation loss: 2.9224813140521877

Epoch: 6| Step: 2
Training loss: 2.5878165525955845
Validation loss: 2.9197055215331162

Epoch: 6| Step: 3
Training loss: 2.9056614105444307
Validation loss: 2.9208824652706196

Epoch: 6| Step: 4
Training loss: 3.0630685706662715
Validation loss: 2.922385318980835

Epoch: 6| Step: 5
Training loss: 2.623434053819766
Validation loss: 2.9212446705839343

Epoch: 6| Step: 6
Training loss: 3.604639687487687
Validation loss: 2.9217784690825086

Epoch: 6| Step: 7
Training loss: 3.4964030720354127
Validation loss: 2.924067940133105

Epoch: 6| Step: 8
Training loss: 3.211369023713987
Validation loss: 2.932433378018149

Epoch: 6| Step: 9
Training loss: 2.9314898427351035
Validation loss: 2.9359881617428765

Epoch: 6| Step: 10
Training loss: 3.1817632175008264
Validation loss: 2.924079486745974

Epoch: 6| Step: 11
Training loss: 3.438237891327952
Validation loss: 2.918636522306921

Epoch: 6| Step: 12
Training loss: 4.468815302871852
Validation loss: 2.9160478046699616

Epoch: 6| Step: 13
Training loss: 2.112285950780862
Validation loss: 2.918305338977483

Epoch: 101| Step: 0
Training loss: 3.1394292728229467
Validation loss: 2.916651080275932

Epoch: 6| Step: 1
Training loss: 3.4522220587535117
Validation loss: 2.916256304115306

Epoch: 6| Step: 2
Training loss: 2.942035177200762
Validation loss: 2.917773005003582

Epoch: 6| Step: 3
Training loss: 3.6540766068035127
Validation loss: 2.917089115846037

Epoch: 6| Step: 4
Training loss: 3.1823468908501495
Validation loss: 2.915646940539894

Epoch: 6| Step: 5
Training loss: 2.8932788110978103
Validation loss: 2.9161957652166524

Epoch: 6| Step: 6
Training loss: 2.744123422154708
Validation loss: 2.9128018906814312

Epoch: 6| Step: 7
Training loss: 3.471517747409777
Validation loss: 2.914457525821153

Epoch: 6| Step: 8
Training loss: 2.778404237253971
Validation loss: 2.9162729873652475

Epoch: 6| Step: 9
Training loss: 3.4225711201536435
Validation loss: 2.913722230559468

Epoch: 6| Step: 10
Training loss: 3.246909799839074
Validation loss: 2.916280901722176

Epoch: 6| Step: 11
Training loss: 3.2022608638105328
Validation loss: 2.9180886961000088

Epoch: 6| Step: 12
Training loss: 3.505198840978201
Validation loss: 2.929321638116729

Epoch: 6| Step: 13
Training loss: 3.008780029045592
Validation loss: 2.9307115661965826

Epoch: 102| Step: 0
Training loss: 3.3658970176550964
Validation loss: 2.9321009254539563

Epoch: 6| Step: 1
Training loss: 3.8489907366154776
Validation loss: 2.939448555808672

Epoch: 6| Step: 2
Training loss: 3.420868189855213
Validation loss: 2.9367253249246086

Epoch: 6| Step: 3
Training loss: 3.3179015258561124
Validation loss: 2.94958377875337

Epoch: 6| Step: 4
Training loss: 3.6087034186913596
Validation loss: 2.9517251428823714

Epoch: 6| Step: 5
Training loss: 2.3293484538955367
Validation loss: 2.9304635237694323

Epoch: 6| Step: 6
Training loss: 2.7426631330239553
Validation loss: 2.910678625645554

Epoch: 6| Step: 7
Training loss: 2.937372732449176
Validation loss: 2.9111332510553742

Epoch: 6| Step: 8
Training loss: 3.124275581318015
Validation loss: 2.910588290632699

Epoch: 6| Step: 9
Training loss: 2.94993717967242
Validation loss: 2.911698835634175

Epoch: 6| Step: 10
Training loss: 3.1249548336579753
Validation loss: 2.911261204689911

Epoch: 6| Step: 11
Training loss: 2.8877436943761436
Validation loss: 2.916579622883036

Epoch: 6| Step: 12
Training loss: 3.4599344767722306
Validation loss: 2.9153509544703216

Epoch: 6| Step: 13
Training loss: 3.63151005192925
Validation loss: 2.9169112904241987

Epoch: 103| Step: 0
Training loss: 3.3673204718795855
Validation loss: 2.919415012032497

Epoch: 6| Step: 1
Training loss: 3.377708337373984
Validation loss: 2.923977789064898

Epoch: 6| Step: 2
Training loss: 3.189221683848658
Validation loss: 2.9226759463776437

Epoch: 6| Step: 3
Training loss: 2.9577850227671654
Validation loss: 2.9209875514227224

Epoch: 6| Step: 4
Training loss: 2.905525199175604
Validation loss: 2.9126257504733153

Epoch: 6| Step: 5
Training loss: 2.9610176981429577
Validation loss: 2.9162609861245814

Epoch: 6| Step: 6
Training loss: 2.8582783247953003
Validation loss: 2.911659661848393

Epoch: 6| Step: 7
Training loss: 3.746894567850541
Validation loss: 2.9097635503447346

Epoch: 6| Step: 8
Training loss: 3.386269017050323
Validation loss: 2.9076857692627747

Epoch: 6| Step: 9
Training loss: 3.3123111311132707
Validation loss: 2.907935624120811

Epoch: 6| Step: 10
Training loss: 2.8288687892351927
Validation loss: 2.905095180035008

Epoch: 6| Step: 11
Training loss: 3.026826442696869
Validation loss: 2.904503503856833

Epoch: 6| Step: 12
Training loss: 3.8787491412197173
Validation loss: 2.9053368679259814

Epoch: 6| Step: 13
Training loss: 2.4898887244795755
Validation loss: 2.9047778482214044

Epoch: 104| Step: 0
Training loss: 3.919476387319719
Validation loss: 2.902463160889228

Epoch: 6| Step: 1
Training loss: 3.344000405891065
Validation loss: 2.9040521909133075

Epoch: 6| Step: 2
Training loss: 2.1169275778814725
Validation loss: 2.906048454911489

Epoch: 6| Step: 3
Training loss: 2.826403858125387
Validation loss: 2.9025062276292504

Epoch: 6| Step: 4
Training loss: 3.279825246388988
Validation loss: 2.9044568063535903

Epoch: 6| Step: 5
Training loss: 3.745359983369996
Validation loss: 2.9010722966071247

Epoch: 6| Step: 6
Training loss: 3.4272285283800654
Validation loss: 2.9003906550524285

Epoch: 6| Step: 7
Training loss: 2.9945358742096766
Validation loss: 2.9021785522733303

Epoch: 6| Step: 8
Training loss: 3.7283854314454987
Validation loss: 2.904181969105441

Epoch: 6| Step: 9
Training loss: 3.009263835370967
Validation loss: 2.899112358498464

Epoch: 6| Step: 10
Training loss: 2.255119645017152
Validation loss: 2.901597905058815

Epoch: 6| Step: 11
Training loss: 3.017998112459901
Validation loss: 2.902118667563992

Epoch: 6| Step: 12
Training loss: 3.49751820448418
Validation loss: 2.9014331349294618

Epoch: 6| Step: 13
Training loss: 2.917523576106742
Validation loss: 2.902767453164918

Epoch: 105| Step: 0
Training loss: 3.1031600719671193
Validation loss: 2.9023173427389337

Epoch: 6| Step: 1
Training loss: 2.699164250619986
Validation loss: 2.90697350539561

Epoch: 6| Step: 2
Training loss: 3.6644249189848934
Validation loss: 2.9095310933498864

Epoch: 6| Step: 3
Training loss: 3.5449393616132068
Validation loss: 2.911257338437145

Epoch: 6| Step: 4
Training loss: 3.7326607700071266
Validation loss: 2.9075743954123796

Epoch: 6| Step: 5
Training loss: 3.2339988895242135
Validation loss: 2.9093910900007787

Epoch: 6| Step: 6
Training loss: 2.1762236825051753
Validation loss: 2.900228863293187

Epoch: 6| Step: 7
Training loss: 3.6260254823490996
Validation loss: 2.8978971904165243

Epoch: 6| Step: 8
Training loss: 3.4613246313709656
Validation loss: 2.8988580412192464

Epoch: 6| Step: 9
Training loss: 3.173758262452244
Validation loss: 2.899922121068029

Epoch: 6| Step: 10
Training loss: 2.328268161954754
Validation loss: 2.9029292164780918

Epoch: 6| Step: 11
Training loss: 3.86295847224173
Validation loss: 2.9330435089737037

Epoch: 6| Step: 12
Training loss: 2.8207451232310823
Validation loss: 2.932053819363176

Epoch: 6| Step: 13
Training loss: 2.570287733335513
Validation loss: 2.9016134727660923

Epoch: 106| Step: 0
Training loss: 3.373256091513887
Validation loss: 2.897729556624004

Epoch: 6| Step: 1
Training loss: 2.7893391960798444
Validation loss: 2.895615748720048

Epoch: 6| Step: 2
Training loss: 3.416457952932076
Validation loss: 2.893385326868558

Epoch: 6| Step: 3
Training loss: 2.880190931455021
Validation loss: 2.8940741565700527

Epoch: 6| Step: 4
Training loss: 3.0526864212184495
Validation loss: 2.893451381795033

Epoch: 6| Step: 5
Training loss: 3.0315701030545026
Validation loss: 2.892214228299026

Epoch: 6| Step: 6
Training loss: 3.0522588651173574
Validation loss: 2.895759648568712

Epoch: 6| Step: 7
Training loss: 3.627533914945131
Validation loss: 2.8914367857348955

Epoch: 6| Step: 8
Training loss: 3.3629599671421286
Validation loss: 2.892927483454052

Epoch: 6| Step: 9
Training loss: 3.0381258033385685
Validation loss: 2.893349553870779

Epoch: 6| Step: 10
Training loss: 3.2114097080927593
Validation loss: 2.8984928296639683

Epoch: 6| Step: 11
Training loss: 3.0470258626513194
Validation loss: 2.9015432248130315

Epoch: 6| Step: 12
Training loss: 3.4602233287642457
Validation loss: 2.8966806222302943

Epoch: 6| Step: 13
Training loss: 3.10358445683582
Validation loss: 2.8887116782366875

Epoch: 107| Step: 0
Training loss: 3.4729358058524875
Validation loss: 2.889494867744511

Epoch: 6| Step: 1
Training loss: 3.336970935277708
Validation loss: 2.8893504713350606

Epoch: 6| Step: 2
Training loss: 2.9460626350161796
Validation loss: 2.8902203871740553

Epoch: 6| Step: 3
Training loss: 3.25403227453281
Validation loss: 2.8870117273279936

Epoch: 6| Step: 4
Training loss: 3.5313036079051052
Validation loss: 2.8896866782885127

Epoch: 6| Step: 5
Training loss: 3.038273490725178
Validation loss: 2.889918800300759

Epoch: 6| Step: 6
Training loss: 3.154964978587446
Validation loss: 2.888720279568636

Epoch: 6| Step: 7
Training loss: 2.72882379799908
Validation loss: 2.8872971908003056

Epoch: 6| Step: 8
Training loss: 3.6511855303418286
Validation loss: 2.885635512203748

Epoch: 6| Step: 9
Training loss: 3.0328679436907877
Validation loss: 2.886877957253944

Epoch: 6| Step: 10
Training loss: 2.795422309949016
Validation loss: 2.888071033317375

Epoch: 6| Step: 11
Training loss: 2.457075012496548
Validation loss: 2.8892577321460426

Epoch: 6| Step: 12
Training loss: 3.664285811591831
Validation loss: 2.889068070703372

Epoch: 6| Step: 13
Training loss: 3.2937844783129324
Validation loss: 2.8878119556717454

Epoch: 108| Step: 0
Training loss: 3.0338934943579385
Validation loss: 2.882842517643923

Epoch: 6| Step: 1
Training loss: 2.878176385708662
Validation loss: 2.8851504406103685

Epoch: 6| Step: 2
Training loss: 2.746277717516438
Validation loss: 2.8843372784639074

Epoch: 6| Step: 3
Training loss: 3.168958704469006
Validation loss: 2.8853392853664777

Epoch: 6| Step: 4
Training loss: 2.723329479988326
Validation loss: 2.885288179838366

Epoch: 6| Step: 5
Training loss: 2.963282318477101
Validation loss: 2.884350898624295

Epoch: 6| Step: 6
Training loss: 3.780520408168641
Validation loss: 2.8832392591922575

Epoch: 6| Step: 7
Training loss: 3.4240278326133304
Validation loss: 2.8839429805360255

Epoch: 6| Step: 8
Training loss: 2.105772431789547
Validation loss: 2.8830991884179387

Epoch: 6| Step: 9
Training loss: 3.5264131621726116
Validation loss: 2.8821231847069635

Epoch: 6| Step: 10
Training loss: 3.3545338368502473
Validation loss: 2.882993640683911

Epoch: 6| Step: 11
Training loss: 3.0007405956387587
Validation loss: 2.882723694676361

Epoch: 6| Step: 12
Training loss: 3.3256150214653672
Validation loss: 2.880935529672485

Epoch: 6| Step: 13
Training loss: 4.557526268143109
Validation loss: 2.8817563033381166

Epoch: 109| Step: 0
Training loss: 3.3640819132626105
Validation loss: 2.8802844761438897

Epoch: 6| Step: 1
Training loss: 2.6879055693024827
Validation loss: 2.8821841528718406

Epoch: 6| Step: 2
Training loss: 3.5999331150199425
Validation loss: 2.880515687080489

Epoch: 6| Step: 3
Training loss: 3.691795562721304
Validation loss: 2.8799332305957264

Epoch: 6| Step: 4
Training loss: 2.9879263473890845
Validation loss: 2.881209171194425

Epoch: 6| Step: 5
Training loss: 3.1774986287495968
Validation loss: 2.8797424671889345

Epoch: 6| Step: 6
Training loss: 3.2470802983869005
Validation loss: 2.882100814653909

Epoch: 6| Step: 7
Training loss: 2.900832017392155
Validation loss: 2.8907221628414668

Epoch: 6| Step: 8
Training loss: 3.132424499381227
Validation loss: 2.895227063510731

Epoch: 6| Step: 9
Training loss: 3.4607509450814047
Validation loss: 2.895134455007788

Epoch: 6| Step: 10
Training loss: 3.0774608224688365
Validation loss: 2.9198141340099353

Epoch: 6| Step: 11
Training loss: 3.414097696293119
Validation loss: 2.920997885000295

Epoch: 6| Step: 12
Training loss: 2.4097189730702633
Validation loss: 2.8989841520711797

Epoch: 6| Step: 13
Training loss: 2.9236337193218747
Validation loss: 2.893060311866199

Epoch: 110| Step: 0
Training loss: 2.928071494412594
Validation loss: 2.8833417375811847

Epoch: 6| Step: 1
Training loss: 3.2889726132684776
Validation loss: 2.8773962318902226

Epoch: 6| Step: 2
Training loss: 3.2367182550008673
Validation loss: 2.8739062007964753

Epoch: 6| Step: 3
Training loss: 2.7584033365576848
Validation loss: 2.873243414124704

Epoch: 6| Step: 4
Training loss: 3.148410844335053
Validation loss: 2.87670976715753

Epoch: 6| Step: 5
Training loss: 2.9882418361881973
Validation loss: 2.8749904418401213

Epoch: 6| Step: 6
Training loss: 3.4178722084580064
Validation loss: 2.873450544300335

Epoch: 6| Step: 7
Training loss: 2.9126974800187235
Validation loss: 2.873012576288132

Epoch: 6| Step: 8
Training loss: 2.720156075824191
Validation loss: 2.8738211113646437

Epoch: 6| Step: 9
Training loss: 3.4463545073394277
Validation loss: 2.8740830878698955

Epoch: 6| Step: 10
Training loss: 3.225340530987778
Validation loss: 2.8725810733643833

Epoch: 6| Step: 11
Training loss: 2.6056661230819285
Validation loss: 2.8735117937210055

Epoch: 6| Step: 12
Training loss: 3.751420832719272
Validation loss: 2.872066015468971

Epoch: 6| Step: 13
Training loss: 4.039283731625596
Validation loss: 2.872452844788373

Epoch: 111| Step: 0
Training loss: 3.5399360168192064
Validation loss: 2.873773818941883

Epoch: 6| Step: 1
Training loss: 3.5732743479951323
Validation loss: 2.871685440295594

Epoch: 6| Step: 2
Training loss: 3.0435260854837467
Validation loss: 2.87781429092475

Epoch: 6| Step: 3
Training loss: 2.566955972030161
Validation loss: 2.8893611722628076

Epoch: 6| Step: 4
Training loss: 3.335000543093887
Validation loss: 2.8999054551404218

Epoch: 6| Step: 5
Training loss: 3.426067553467154
Validation loss: 2.9091288439225904

Epoch: 6| Step: 6
Training loss: 2.4604656433175003
Validation loss: 2.8773626799793504

Epoch: 6| Step: 7
Training loss: 3.447263135179696
Validation loss: 2.8699597141873823

Epoch: 6| Step: 8
Training loss: 3.008619165622735
Validation loss: 2.869372775888297

Epoch: 6| Step: 9
Training loss: 3.0958437529671365
Validation loss: 2.871234140374237

Epoch: 6| Step: 10
Training loss: 3.473681269649009
Validation loss: 2.875650598888691

Epoch: 6| Step: 11
Training loss: 3.2949376493120477
Validation loss: 2.8750869341917706

Epoch: 6| Step: 12
Training loss: 2.70051748826725
Validation loss: 2.8761929234723156

Epoch: 6| Step: 13
Training loss: 3.358474539792737
Validation loss: 2.8758866403987176

Epoch: 112| Step: 0
Training loss: 3.152564739436818
Validation loss: 2.874575376251247

Epoch: 6| Step: 1
Training loss: 2.888240180988869
Validation loss: 2.873745671846615

Epoch: 6| Step: 2
Training loss: 3.7509938512521384
Validation loss: 2.871240007421152

Epoch: 6| Step: 3
Training loss: 2.6971872195395177
Validation loss: 2.8716115668049196

Epoch: 6| Step: 4
Training loss: 3.4326542772267192
Validation loss: 2.870033457799949

Epoch: 6| Step: 5
Training loss: 2.8767744476295287
Validation loss: 2.8673243783218436

Epoch: 6| Step: 6
Training loss: 3.4809449423468894
Validation loss: 2.866498381219831

Epoch: 6| Step: 7
Training loss: 2.7593795171508453
Validation loss: 2.8682050119684006

Epoch: 6| Step: 8
Training loss: 3.844382381367004
Validation loss: 2.8682023233758445

Epoch: 6| Step: 9
Training loss: 2.6405998996241404
Validation loss: 2.8689191784393513

Epoch: 6| Step: 10
Training loss: 3.0516573420961497
Validation loss: 2.8658285989874828

Epoch: 6| Step: 11
Training loss: 3.492692130066675
Validation loss: 2.8666608989106193

Epoch: 6| Step: 12
Training loss: 3.089147515832281
Validation loss: 2.8671347663632294

Epoch: 6| Step: 13
Training loss: 2.6988861718217994
Validation loss: 2.8657263441859895

Epoch: 113| Step: 0
Training loss: 3.39391058722776
Validation loss: 2.86749173063875

Epoch: 6| Step: 1
Training loss: 2.576889944465745
Validation loss: 2.8656038887548045

Epoch: 6| Step: 2
Training loss: 4.086384210911825
Validation loss: 2.8646457740638307

Epoch: 6| Step: 3
Training loss: 2.975025170484218
Validation loss: 2.8642572056591886

Epoch: 6| Step: 4
Training loss: 2.6858756900974123
Validation loss: 2.8629970157921742

Epoch: 6| Step: 5
Training loss: 3.0127679602768453
Validation loss: 2.862778702898663

Epoch: 6| Step: 6
Training loss: 2.735057810951726
Validation loss: 2.8670027076103533

Epoch: 6| Step: 7
Training loss: 3.3514003047510674
Validation loss: 2.86574241896908

Epoch: 6| Step: 8
Training loss: 2.6705567080289345
Validation loss: 2.872988137380717

Epoch: 6| Step: 9
Training loss: 3.244962603055242
Validation loss: 2.8692365555059713

Epoch: 6| Step: 10
Training loss: 3.558290236224752
Validation loss: 2.8682788525343166

Epoch: 6| Step: 11
Training loss: 3.5308040911253102
Validation loss: 2.8715283440312764

Epoch: 6| Step: 12
Training loss: 3.295655517668328
Validation loss: 2.8632300520509286

Epoch: 6| Step: 13
Training loss: 2.17181187819273
Validation loss: 2.8592386852604106

Epoch: 114| Step: 0
Training loss: 3.4539470816016973
Validation loss: 2.8610569761991433

Epoch: 6| Step: 1
Training loss: 3.017506067100816
Validation loss: 2.8639926788457406

Epoch: 6| Step: 2
Training loss: 3.673320080086488
Validation loss: 2.8605651709608577

Epoch: 6| Step: 3
Training loss: 3.5105446962880604
Validation loss: 2.8591636464393066

Epoch: 6| Step: 4
Training loss: 3.4472838836272834
Validation loss: 2.861725880192536

Epoch: 6| Step: 5
Training loss: 2.846583704696174
Validation loss: 2.859428487297954

Epoch: 6| Step: 6
Training loss: 3.063200578549147
Validation loss: 2.8602559730592922

Epoch: 6| Step: 7
Training loss: 3.2573096895873124
Validation loss: 2.858108002210469

Epoch: 6| Step: 8
Training loss: 2.6906378414543206
Validation loss: 2.859292296149297

Epoch: 6| Step: 9
Training loss: 3.1237195252591663
Validation loss: 2.8643421836022975

Epoch: 6| Step: 10
Training loss: 3.234994580177354
Validation loss: 2.8669164922428543

Epoch: 6| Step: 11
Training loss: 2.818750598848199
Validation loss: 2.858299978102206

Epoch: 6| Step: 12
Training loss: 2.5608906227834782
Validation loss: 2.8619044517138565

Epoch: 6| Step: 13
Training loss: 3.3283520831511355
Validation loss: 2.8613559310386854

Epoch: 115| Step: 0
Training loss: 3.590405574830295
Validation loss: 2.8654898065986596

Epoch: 6| Step: 1
Training loss: 2.780496045048574
Validation loss: 2.858356555583808

Epoch: 6| Step: 2
Training loss: 2.9349869062661273
Validation loss: 2.8573139414127415

Epoch: 6| Step: 3
Training loss: 2.443594331978478
Validation loss: 2.8598607260016617

Epoch: 6| Step: 4
Training loss: 2.5596416627908156
Validation loss: 2.8655568302032544

Epoch: 6| Step: 5
Training loss: 3.5294866969999075
Validation loss: 2.8643312392892333

Epoch: 6| Step: 6
Training loss: 3.426202554579534
Validation loss: 2.8822823505071753

Epoch: 6| Step: 7
Training loss: 3.7964037693045563
Validation loss: 2.876903094886511

Epoch: 6| Step: 8
Training loss: 3.1787674906163574
Validation loss: 2.887452339738253

Epoch: 6| Step: 9
Training loss: 3.646828274072045
Validation loss: 2.858347232363507

Epoch: 6| Step: 10
Training loss: 2.2088561488811793
Validation loss: 2.8489983128738645

Epoch: 6| Step: 11
Training loss: 3.265443349650303
Validation loss: 2.8542815205460883

Epoch: 6| Step: 12
Training loss: 2.8507752886537596
Validation loss: 2.853422042784311

Epoch: 6| Step: 13
Training loss: 3.5917845285523935
Validation loss: 2.8549414896552463

Epoch: 116| Step: 0
Training loss: 3.132388878241923
Validation loss: 2.8540685044137435

Epoch: 6| Step: 1
Training loss: 2.634455951790857
Validation loss: 2.8559304226313422

Epoch: 6| Step: 2
Training loss: 3.470378596514999
Validation loss: 2.853103946139568

Epoch: 6| Step: 3
Training loss: 2.882585718182281
Validation loss: 2.8538580568119243

Epoch: 6| Step: 4
Training loss: 2.9816133993418337
Validation loss: 2.8519422646006523

Epoch: 6| Step: 5
Training loss: 3.1356638729612483
Validation loss: 2.8538101173585506

Epoch: 6| Step: 6
Training loss: 3.5013505509798883
Validation loss: 2.85254803622864

Epoch: 6| Step: 7
Training loss: 3.2072432676758025
Validation loss: 2.8514754114184626

Epoch: 6| Step: 8
Training loss: 3.961813925666374
Validation loss: 2.85155944869007

Epoch: 6| Step: 9
Training loss: 3.7272142524107763
Validation loss: 2.850796332589887

Epoch: 6| Step: 10
Training loss: 2.2074157919974584
Validation loss: 2.8505954713676065

Epoch: 6| Step: 11
Training loss: 3.120227373592354
Validation loss: 2.8492194236034916

Epoch: 6| Step: 12
Training loss: 3.0371963537585414
Validation loss: 2.8507750701291004

Epoch: 6| Step: 13
Training loss: 2.4849936236908006
Validation loss: 2.8496503571945295

Epoch: 117| Step: 0
Training loss: 3.0698145494146467
Validation loss: 2.848810826987267

Epoch: 6| Step: 1
Training loss: 2.9799991502696623
Validation loss: 2.8495098957695566

Epoch: 6| Step: 2
Training loss: 3.484533468842479
Validation loss: 2.8482356779831735

Epoch: 6| Step: 3
Training loss: 3.4091277958579393
Validation loss: 2.8480830184842123

Epoch: 6| Step: 4
Training loss: 3.712797128622913
Validation loss: 2.84802700833899

Epoch: 6| Step: 5
Training loss: 2.989851156504169
Validation loss: 2.8456758209595843

Epoch: 6| Step: 6
Training loss: 3.5574862351087573
Validation loss: 2.8465371233482792

Epoch: 6| Step: 7
Training loss: 2.9832838370481243
Validation loss: 2.846884877285567

Epoch: 6| Step: 8
Training loss: 3.1051315412439027
Validation loss: 2.8466641922122724

Epoch: 6| Step: 9
Training loss: 1.9386398900022432
Validation loss: 2.8496501349850716

Epoch: 6| Step: 10
Training loss: 3.048130813414752
Validation loss: 2.85067074742169

Epoch: 6| Step: 11
Training loss: 3.5083464150324573
Validation loss: 2.844993773669353

Epoch: 6| Step: 12
Training loss: 2.9328196147980763
Validation loss: 2.8428737548436294

Epoch: 6| Step: 13
Training loss: 2.6667092339773983
Validation loss: 2.8474463530598744

Epoch: 118| Step: 0
Training loss: 3.470215496440508
Validation loss: 2.8709141382442156

Epoch: 6| Step: 1
Training loss: 2.6989570192672216
Validation loss: 2.8665589877073523

Epoch: 6| Step: 2
Training loss: 2.792623004987576
Validation loss: 2.8513110769352012

Epoch: 6| Step: 3
Training loss: 3.565729250374332
Validation loss: 2.844711364782324

Epoch: 6| Step: 4
Training loss: 3.425020209482532
Validation loss: 2.848334848897031

Epoch: 6| Step: 5
Training loss: 2.921992498473056
Validation loss: 2.848984575894058

Epoch: 6| Step: 6
Training loss: 3.302048804326239
Validation loss: 2.8562094477954822

Epoch: 6| Step: 7
Training loss: 3.558393286409151
Validation loss: 2.852400461765474

Epoch: 6| Step: 8
Training loss: 2.2776615712779558
Validation loss: 2.846886757544204

Epoch: 6| Step: 9
Training loss: 3.1611758026791765
Validation loss: 2.8406599678746294

Epoch: 6| Step: 10
Training loss: 3.4538911685817113
Validation loss: 2.843186705940147

Epoch: 6| Step: 11
Training loss: 2.7961527142165723
Validation loss: 2.840197040612384

Epoch: 6| Step: 12
Training loss: 3.3955483970378006
Validation loss: 2.8388376792661725

Epoch: 6| Step: 13
Training loss: 2.6598447821798374
Validation loss: 2.8428520633960224

Epoch: 119| Step: 0
Training loss: 3.1038010827852713
Validation loss: 2.8390489395734013

Epoch: 6| Step: 1
Training loss: 2.622421905983974
Validation loss: 2.8382265399019335

Epoch: 6| Step: 2
Training loss: 3.1971558567748564
Validation loss: 2.840619354150382

Epoch: 6| Step: 3
Training loss: 2.282085422498429
Validation loss: 2.8428129004181732

Epoch: 6| Step: 4
Training loss: 2.6503469060160794
Validation loss: 2.8427594972916155

Epoch: 6| Step: 5
Training loss: 3.672205094454462
Validation loss: 2.8490541059632504

Epoch: 6| Step: 6
Training loss: 3.3703420072704313
Validation loss: 2.837730474392121

Epoch: 6| Step: 7
Training loss: 3.480380107465828
Validation loss: 2.837689898241653

Epoch: 6| Step: 8
Training loss: 3.459759582810576
Validation loss: 2.8371857584452536

Epoch: 6| Step: 9
Training loss: 3.2938064830938822
Validation loss: 2.835771984383565

Epoch: 6| Step: 10
Training loss: 2.6860123886311253
Validation loss: 2.8376063175294806

Epoch: 6| Step: 11
Training loss: 3.4083009197556096
Validation loss: 2.837017347651876

Epoch: 6| Step: 12
Training loss: 2.7175908741851384
Validation loss: 2.8338018104854896

Epoch: 6| Step: 13
Training loss: 3.9328918133794466
Validation loss: 2.8363124168275076

Epoch: 120| Step: 0
Training loss: 3.5176618990753012
Validation loss: 2.8391103794389214

Epoch: 6| Step: 1
Training loss: 2.4662051061149084
Validation loss: 2.833966733309478

Epoch: 6| Step: 2
Training loss: 3.574799570720741
Validation loss: 2.8375155625344126

Epoch: 6| Step: 3
Training loss: 3.5897938057597534
Validation loss: 2.8342666994755796

Epoch: 6| Step: 4
Training loss: 2.7924657408713953
Validation loss: 2.8374277229711518

Epoch: 6| Step: 5
Training loss: 3.361418062876532
Validation loss: 2.8346354829892384

Epoch: 6| Step: 6
Training loss: 2.942298865173202
Validation loss: 2.837196800241693

Epoch: 6| Step: 7
Training loss: 3.5424994144156545
Validation loss: 2.8369616765935386

Epoch: 6| Step: 8
Training loss: 2.689934359887644
Validation loss: 2.8439364042584803

Epoch: 6| Step: 9
Training loss: 2.8330554451894474
Validation loss: 2.848123785911383

Epoch: 6| Step: 10
Training loss: 2.534866386970422
Validation loss: 2.8502214052517685

Epoch: 6| Step: 11
Training loss: 3.325824354276402
Validation loss: 2.8511551437218694

Epoch: 6| Step: 12
Training loss: 3.434095326526321
Validation loss: 2.8544664907346187

Epoch: 6| Step: 13
Training loss: 2.8278993969711244
Validation loss: 2.849889968075007

Epoch: 121| Step: 0
Training loss: 3.374300283730711
Validation loss: 2.8321502219257386

Epoch: 6| Step: 1
Training loss: 3.27926633910366
Validation loss: 2.831587744735533

Epoch: 6| Step: 2
Training loss: 2.5887321744900986
Validation loss: 2.830180847101409

Epoch: 6| Step: 3
Training loss: 3.2341880560028966
Validation loss: 2.831809427289033

Epoch: 6| Step: 4
Training loss: 2.8592869479270417
Validation loss: 2.8321474248800826

Epoch: 6| Step: 5
Training loss: 2.9160548703822564
Validation loss: 2.83213578769219

Epoch: 6| Step: 6
Training loss: 3.6313213610572266
Validation loss: 2.834200744992323

Epoch: 6| Step: 7
Training loss: 2.4877141429029415
Validation loss: 2.832543634633699

Epoch: 6| Step: 8
Training loss: 3.3175266920796784
Validation loss: 2.831429016781985

Epoch: 6| Step: 9
Training loss: 3.5359039696128938
Validation loss: 2.831975458293604

Epoch: 6| Step: 10
Training loss: 2.8540402869393167
Validation loss: 2.8339856794422467

Epoch: 6| Step: 11
Training loss: 3.15247504470229
Validation loss: 2.8330627025029593

Epoch: 6| Step: 12
Training loss: 3.060019909663037
Validation loss: 2.831605991546705

Epoch: 6| Step: 13
Training loss: 3.659416457803827
Validation loss: 2.831799760465706

Epoch: 122| Step: 0
Training loss: 3.6556192489790096
Validation loss: 2.8335177441783705

Epoch: 6| Step: 1
Training loss: 3.4766154424515205
Validation loss: 2.829184429422178

Epoch: 6| Step: 2
Training loss: 3.0191130552095458
Validation loss: 2.8303525730987458

Epoch: 6| Step: 3
Training loss: 3.331260386266495
Validation loss: 2.8288887464333294

Epoch: 6| Step: 4
Training loss: 2.5419556083494723
Validation loss: 2.8282991449846566

Epoch: 6| Step: 5
Training loss: 2.6548772518425543
Validation loss: 2.8297955438949165

Epoch: 6| Step: 6
Training loss: 3.022430488790489
Validation loss: 2.8271968263227016

Epoch: 6| Step: 7
Training loss: 3.1645579762517535
Validation loss: 2.828694491716244

Epoch: 6| Step: 8
Training loss: 3.238887863493449
Validation loss: 2.8286598274115193

Epoch: 6| Step: 9
Training loss: 2.951172198151041
Validation loss: 2.827934629933345

Epoch: 6| Step: 10
Training loss: 3.6094846502385374
Validation loss: 2.8302842792365257

Epoch: 6| Step: 11
Training loss: 3.2454006221673555
Validation loss: 2.8287611545987743

Epoch: 6| Step: 12
Training loss: 2.7066352411459658
Validation loss: 2.826799342958671

Epoch: 6| Step: 13
Training loss: 2.9774336854098333
Validation loss: 2.8266190633878856

Epoch: 123| Step: 0
Training loss: 2.7508749003612913
Validation loss: 2.8262803937699794

Epoch: 6| Step: 1
Training loss: 3.215872654400558
Validation loss: 2.831862640396979

Epoch: 6| Step: 2
Training loss: 3.4990764489338324
Validation loss: 2.833278857858977

Epoch: 6| Step: 3
Training loss: 3.1552822026727525
Validation loss: 2.8273598503801365

Epoch: 6| Step: 4
Training loss: 3.2129597850649074
Validation loss: 2.8315874314767577

Epoch: 6| Step: 5
Training loss: 3.092508086037453
Validation loss: 2.835442451712486

Epoch: 6| Step: 6
Training loss: 3.7692258721024876
Validation loss: 2.8329076236028943

Epoch: 6| Step: 7
Training loss: 3.9839447387554863
Validation loss: 2.829775677345562

Epoch: 6| Step: 8
Training loss: 2.5409916987307923
Validation loss: 2.8241628720380776

Epoch: 6| Step: 9
Training loss: 2.8523082019405654
Validation loss: 2.824518615046963

Epoch: 6| Step: 10
Training loss: 2.729996931053365
Validation loss: 2.8290399052673294

Epoch: 6| Step: 11
Training loss: 2.4410467508754756
Validation loss: 2.825512574324945

Epoch: 6| Step: 12
Training loss: 2.8147657804466064
Validation loss: 2.8286744280162472

Epoch: 6| Step: 13
Training loss: 3.414728095426961
Validation loss: 2.82488742785211

Epoch: 124| Step: 0
Training loss: 2.8468832005404665
Validation loss: 2.8274828405508656

Epoch: 6| Step: 1
Training loss: 3.452539730962132
Validation loss: 2.827563248903393

Epoch: 6| Step: 2
Training loss: 2.993556095605055
Validation loss: 2.826445321912684

Epoch: 6| Step: 3
Training loss: 2.698551255541421
Validation loss: 2.8272954412731233

Epoch: 6| Step: 4
Training loss: 2.584855236375449
Validation loss: 2.8316380476697867

Epoch: 6| Step: 5
Training loss: 3.597921852471804
Validation loss: 2.8293163904092156

Epoch: 6| Step: 6
Training loss: 1.986617855820771
Validation loss: 2.8237118373949723

Epoch: 6| Step: 7
Training loss: 2.804278840706959
Validation loss: 2.828421936600338

Epoch: 6| Step: 8
Training loss: 3.1875107708917283
Validation loss: 2.8231568332895423

Epoch: 6| Step: 9
Training loss: 3.1404210873731673
Validation loss: 2.820924672190733

Epoch: 6| Step: 10
Training loss: 3.1285168504277943
Validation loss: 2.8184182369103272

Epoch: 6| Step: 11
Training loss: 3.551813795913959
Validation loss: 2.8197194860113504

Epoch: 6| Step: 12
Training loss: 3.5924978977481263
Validation loss: 2.8200720669025032

Epoch: 6| Step: 13
Training loss: 3.970493444337658
Validation loss: 2.8169631856783357

Epoch: 125| Step: 0
Training loss: 4.095560619838447
Validation loss: 2.819200209318581

Epoch: 6| Step: 1
Training loss: 3.6604949566468084
Validation loss: 2.816628564920447

Epoch: 6| Step: 2
Training loss: 2.7160926196748783
Validation loss: 2.8197648247778635

Epoch: 6| Step: 3
Training loss: 2.744796511641587
Validation loss: 2.8156777226260856

Epoch: 6| Step: 4
Training loss: 2.767922260907184
Validation loss: 2.8178573847081028

Epoch: 6| Step: 5
Training loss: 2.446167427739502
Validation loss: 2.8156900069027

Epoch: 6| Step: 6
Training loss: 2.7294251025968883
Validation loss: 2.816405086697153

Epoch: 6| Step: 7
Training loss: 3.047980161897675
Validation loss: 2.817452279867711

Epoch: 6| Step: 8
Training loss: 3.1668354457916905
Validation loss: 2.816134613934261

Epoch: 6| Step: 9
Training loss: 2.225746513890991
Validation loss: 2.815861061615498

Epoch: 6| Step: 10
Training loss: 3.1460333417421875
Validation loss: 2.814081474318076

Epoch: 6| Step: 11
Training loss: 4.000743796812585
Validation loss: 2.820113529243553

Epoch: 6| Step: 12
Training loss: 2.823189491141724
Validation loss: 2.8260764928907944

Epoch: 6| Step: 13
Training loss: 3.7421932339873214
Validation loss: 2.839411886052179

Testing loss: 3.027432972895546
