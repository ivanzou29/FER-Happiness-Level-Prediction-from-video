Epoch: 1| Step: 0
Training loss: 6.2825395010128755
Validation loss: 5.856166495247683

Epoch: 5| Step: 1
Training loss: 6.265462440417719
Validation loss: 5.850942573516705

Epoch: 5| Step: 2
Training loss: 5.900016926886637
Validation loss: 5.845822300974835

Epoch: 5| Step: 3
Training loss: 5.642992531944037
Validation loss: 5.841083645897042

Epoch: 5| Step: 4
Training loss: 5.3151796651135435
Validation loss: 5.836655708099788

Epoch: 5| Step: 5
Training loss: 5.205829089530256
Validation loss: 5.832076382318669

Epoch: 5| Step: 6
Training loss: 6.229470984468737
Validation loss: 5.827801312370337

Epoch: 5| Step: 7
Training loss: 5.834355437333299
Validation loss: 5.8232075781471115

Epoch: 5| Step: 8
Training loss: 4.954983624258995
Validation loss: 5.81920144751821

Epoch: 5| Step: 9
Training loss: 6.687780926944799
Validation loss: 5.814321193158427

Epoch: 5| Step: 10
Training loss: 5.980864209655318
Validation loss: 5.809824613300657

Epoch: 2| Step: 0
Training loss: 5.281597058331151
Validation loss: 5.805298140964675

Epoch: 5| Step: 1
Training loss: 5.655855786828063
Validation loss: 5.800173008226331

Epoch: 5| Step: 2
Training loss: 6.917199753896279
Validation loss: 5.795442294950012

Epoch: 5| Step: 3
Training loss: 5.734825345267514
Validation loss: 5.789875093663165

Epoch: 5| Step: 4
Training loss: 5.263489241961471
Validation loss: 5.784745723678578

Epoch: 5| Step: 5
Training loss: 6.654106833854387
Validation loss: 5.778712179075592

Epoch: 5| Step: 6
Training loss: 6.249059377460527
Validation loss: 5.772619929625798

Epoch: 5| Step: 7
Training loss: 4.795045982355163
Validation loss: 5.7666486641790575

Epoch: 5| Step: 8
Training loss: 6.020776380997758
Validation loss: 5.759640922383314

Epoch: 5| Step: 9
Training loss: 5.636969990989955
Validation loss: 5.7531044254049934

Epoch: 5| Step: 10
Training loss: 5.3004167356936644
Validation loss: 5.746218732336526

Epoch: 3| Step: 0
Training loss: 5.579670838796096
Validation loss: 5.73913351746676

Epoch: 5| Step: 1
Training loss: 5.615316405650824
Validation loss: 5.731482841231528

Epoch: 5| Step: 2
Training loss: 5.5543787960324105
Validation loss: 5.723443864470126

Epoch: 5| Step: 3
Training loss: 5.731069168016885
Validation loss: 5.714848189277605

Epoch: 5| Step: 4
Training loss: 6.259508757892805
Validation loss: 5.706720451112643

Epoch: 5| Step: 5
Training loss: 5.89453125
Validation loss: 5.697617969788818

Epoch: 5| Step: 6
Training loss: 5.520739207874901
Validation loss: 5.688824830738198

Epoch: 5| Step: 7
Training loss: 5.648418252366064
Validation loss: 5.679175487912884

Epoch: 5| Step: 8
Training loss: 5.93259524494399
Validation loss: 5.668826279213648

Epoch: 5| Step: 9
Training loss: 5.813877393712486
Validation loss: 5.658617369866354

Epoch: 5| Step: 10
Training loss: 5.398340514177189
Validation loss: 5.647890369243927

Epoch: 4| Step: 0
Training loss: 5.641753445760371
Validation loss: 5.636437795443654

Epoch: 5| Step: 1
Training loss: 5.49544995840753
Validation loss: 5.624562363822059

Epoch: 5| Step: 2
Training loss: 5.911086589759184
Validation loss: 5.613395596184892

Epoch: 5| Step: 3
Training loss: 6.448066705571675
Validation loss: 5.600821646535812

Epoch: 5| Step: 4
Training loss: 4.880259684235183
Validation loss: 5.586962774503283

Epoch: 5| Step: 5
Training loss: 6.202747708240283
Validation loss: 5.573382235486824

Epoch: 5| Step: 6
Training loss: 4.8367430180929905
Validation loss: 5.559824111067417

Epoch: 5| Step: 7
Training loss: 5.295583381826957
Validation loss: 5.546203297153308

Epoch: 5| Step: 8
Training loss: 5.120403368379021
Validation loss: 5.531699771622926

Epoch: 5| Step: 9
Training loss: 5.976620582846848
Validation loss: 5.516780789460777

Epoch: 5| Step: 10
Training loss: 5.7028781785202955
Validation loss: 5.500772606512886

Epoch: 5| Step: 0
Training loss: 5.058006647276819
Validation loss: 5.484591162619607

Epoch: 5| Step: 1
Training loss: 5.346028695385917
Validation loss: 5.467157783827642

Epoch: 5| Step: 2
Training loss: 4.98414635208566
Validation loss: 5.450043044983841

Epoch: 5| Step: 3
Training loss: 6.007494378565501
Validation loss: 5.432122360197895

Epoch: 5| Step: 4
Training loss: 4.653398498326628
Validation loss: 5.412434620796177

Epoch: 5| Step: 5
Training loss: 5.8007621790511426
Validation loss: 5.392293180728021

Epoch: 5| Step: 6
Training loss: 5.429779710604149
Validation loss: 5.373413279087338

Epoch: 5| Step: 7
Training loss: 6.31686733735668
Validation loss: 5.351460479633355

Epoch: 5| Step: 8
Training loss: 5.108005165067614
Validation loss: 5.3288884342353775

Epoch: 5| Step: 9
Training loss: 5.575886424118846
Validation loss: 5.307734045072488

Epoch: 5| Step: 10
Training loss: 5.256013967904818
Validation loss: 5.284800359919891

Epoch: 6| Step: 0
Training loss: 5.097974464744648
Validation loss: 5.261684572033463

Epoch: 5| Step: 1
Training loss: 5.186839601694941
Validation loss: 5.236369271727611

Epoch: 5| Step: 2
Training loss: 5.147547921415738
Validation loss: 5.2126531722109135

Epoch: 5| Step: 3
Training loss: 4.855692654984248
Validation loss: 5.187549678299234

Epoch: 5| Step: 4
Training loss: 5.713476866288278
Validation loss: 5.161800648791171

Epoch: 5| Step: 5
Training loss: 5.29549531775833
Validation loss: 5.133067234868199

Epoch: 5| Step: 6
Training loss: 5.337493982244668
Validation loss: 5.106135099489418

Epoch: 5| Step: 7
Training loss: 5.536080530242412
Validation loss: 5.077216760080021

Epoch: 5| Step: 8
Training loss: 4.7959703219834156
Validation loss: 5.047556044948761

Epoch: 5| Step: 9
Training loss: 5.347689598542384
Validation loss: 5.019006901994121

Epoch: 5| Step: 10
Training loss: 4.579586694051121
Validation loss: 4.988876475959205

Epoch: 7| Step: 0
Training loss: 3.7801855181021913
Validation loss: 4.957187386079986

Epoch: 5| Step: 1
Training loss: 5.068708780405669
Validation loss: 4.927549498522902

Epoch: 5| Step: 2
Training loss: 5.330911662734977
Validation loss: 4.895574484924665

Epoch: 5| Step: 3
Training loss: 4.566857752085475
Validation loss: 4.865194111016041

Epoch: 5| Step: 4
Training loss: 4.995204915071522
Validation loss: 4.8346982979754065

Epoch: 5| Step: 5
Training loss: 5.40686913621933
Validation loss: 4.8049872496209325

Epoch: 5| Step: 6
Training loss: 5.616042910539632
Validation loss: 4.775636046670851

Epoch: 5| Step: 7
Training loss: 4.713256669956523
Validation loss: 4.746322857898836

Epoch: 5| Step: 8
Training loss: 5.488754740751856
Validation loss: 4.721059895420022

Epoch: 5| Step: 9
Training loss: 3.922602126358398
Validation loss: 4.694209314988316

Epoch: 5| Step: 10
Training loss: 4.315405709829574
Validation loss: 4.667569492102078

Epoch: 8| Step: 0
Training loss: 5.7149695736533195
Validation loss: 4.645589221243268

Epoch: 5| Step: 1
Training loss: 5.218018988847085
Validation loss: 4.620193384995005

Epoch: 5| Step: 2
Training loss: 4.856541828828024
Validation loss: 4.596798170452124

Epoch: 5| Step: 3
Training loss: 3.9169835442671403
Validation loss: 4.573744008229454

Epoch: 5| Step: 4
Training loss: 4.534385911440718
Validation loss: 4.550252846236527

Epoch: 5| Step: 5
Training loss: 4.226404324602019
Validation loss: 4.528863483062382

Epoch: 5| Step: 6
Training loss: 4.440722947245128
Validation loss: 4.509890915059132

Epoch: 5| Step: 7
Training loss: 5.04397717121473
Validation loss: 4.488700000739436

Epoch: 5| Step: 8
Training loss: 4.2957895468482326
Validation loss: 4.471382559519178

Epoch: 5| Step: 9
Training loss: 3.8840249085653977
Validation loss: 4.45310039473887

Epoch: 5| Step: 10
Training loss: 4.542645456843625
Validation loss: 4.43765970254982

Epoch: 9| Step: 0
Training loss: 3.712959718337262
Validation loss: 4.420953641649319

Epoch: 5| Step: 1
Training loss: 4.679242197289381
Validation loss: 4.406457813918411

Epoch: 5| Step: 2
Training loss: 3.991676491955562
Validation loss: 4.389894306361484

Epoch: 5| Step: 3
Training loss: 5.022309504419129
Validation loss: 4.375821291104669

Epoch: 5| Step: 4
Training loss: 4.002619362551804
Validation loss: 4.36339874877592

Epoch: 5| Step: 5
Training loss: 5.543364281551718
Validation loss: 4.34598360659657

Epoch: 5| Step: 6
Training loss: 4.180012856057579
Validation loss: 4.333733061409149

Epoch: 5| Step: 7
Training loss: 4.247789144480549
Validation loss: 4.318769863614794

Epoch: 5| Step: 8
Training loss: 4.3533747681480675
Validation loss: 4.3055970317753935

Epoch: 5| Step: 9
Training loss: 4.329729684757052
Validation loss: 4.294037275383625

Epoch: 5| Step: 10
Training loss: 4.764119294986257
Validation loss: 4.281524258996657

Epoch: 10| Step: 0
Training loss: 4.284902086953142
Validation loss: 4.2680103463364665

Epoch: 5| Step: 1
Training loss: 4.586598961093855
Validation loss: 4.255119916948947

Epoch: 5| Step: 2
Training loss: 3.7553746172965687
Validation loss: 4.24623971359474

Epoch: 5| Step: 3
Training loss: 4.1454301698780265
Validation loss: 4.23288415431857

Epoch: 5| Step: 4
Training loss: 4.378698475082905
Validation loss: 4.221523278513501

Epoch: 5| Step: 5
Training loss: 4.839555068254414
Validation loss: 4.211509840269193

Epoch: 5| Step: 6
Training loss: 5.096144411828509
Validation loss: 4.201211131513119

Epoch: 5| Step: 7
Training loss: 4.4408661875503
Validation loss: 4.19009555409993

Epoch: 5| Step: 8
Training loss: 4.58549266002909
Validation loss: 4.181131201023198

Epoch: 5| Step: 9
Training loss: 3.7073070234620356
Validation loss: 4.169638274665249

Epoch: 5| Step: 10
Training loss: 3.5407104697352993
Validation loss: 4.158747758056993

Epoch: 11| Step: 0
Training loss: 4.430843249593222
Validation loss: 4.146832027636588

Epoch: 5| Step: 1
Training loss: 4.377257282493076
Validation loss: 4.140370140350767

Epoch: 5| Step: 2
Training loss: 3.4688838898533603
Validation loss: 4.129291937962698

Epoch: 5| Step: 3
Training loss: 4.421513087690586
Validation loss: 4.117925243101283

Epoch: 5| Step: 4
Training loss: 4.443948922084358
Validation loss: 4.103878696787738

Epoch: 5| Step: 5
Training loss: 4.519796906018596
Validation loss: 4.094854851255207

Epoch: 5| Step: 6
Training loss: 4.827567552896925
Validation loss: 4.085820058434667

Epoch: 5| Step: 7
Training loss: 4.27228381329275
Validation loss: 4.07443572455215

Epoch: 5| Step: 8
Training loss: 3.5112870643753564
Validation loss: 4.063382195415291

Epoch: 5| Step: 9
Training loss: 4.352868478286222
Validation loss: 4.057564338827693

Epoch: 5| Step: 10
Training loss: 3.697755679355923
Validation loss: 4.049379750080506

Epoch: 12| Step: 0
Training loss: 4.562848012532703
Validation loss: 4.036754327957258

Epoch: 5| Step: 1
Training loss: 3.911264969287193
Validation loss: 4.031336390504531

Epoch: 5| Step: 2
Training loss: 3.724336035009779
Validation loss: 4.025773659039091

Epoch: 5| Step: 3
Training loss: 4.403904933364181
Validation loss: 4.016758663574227

Epoch: 5| Step: 4
Training loss: 4.536965389651922
Validation loss: 4.008696910049828

Epoch: 5| Step: 5
Training loss: 4.384461118324087
Validation loss: 4.000608564556656

Epoch: 5| Step: 6
Training loss: 4.545254657858584
Validation loss: 3.992984372158851

Epoch: 5| Step: 7
Training loss: 4.217772872228776
Validation loss: 3.981996224840972

Epoch: 5| Step: 8
Training loss: 4.056044393774257
Validation loss: 3.9760931538938005

Epoch: 5| Step: 9
Training loss: 3.2313231292063995
Validation loss: 3.972014787323628

Epoch: 5| Step: 10
Training loss: 3.807153047820485
Validation loss: 3.9659619319999795

Epoch: 13| Step: 0
Training loss: 4.152814319893522
Validation loss: 3.96091328055047

Epoch: 5| Step: 1
Training loss: 4.068976770694227
Validation loss: 3.9480164711413055

Epoch: 5| Step: 2
Training loss: 4.3105541759821495
Validation loss: 3.944548103085081

Epoch: 5| Step: 3
Training loss: 4.369544851662854
Validation loss: 3.942526531488761

Epoch: 5| Step: 4
Training loss: 3.5534872522948047
Validation loss: 3.9336435809520216

Epoch: 5| Step: 5
Training loss: 4.987601357101756
Validation loss: 3.927580420434165

Epoch: 5| Step: 6
Training loss: 4.020452188139929
Validation loss: 3.9176107109763114

Epoch: 5| Step: 7
Training loss: 3.7013414167962684
Validation loss: 3.9127021436180955

Epoch: 5| Step: 8
Training loss: 3.8443089520705445
Validation loss: 3.9080817802677994

Epoch: 5| Step: 9
Training loss: 3.638212526150309
Validation loss: 3.90356488222477

Epoch: 5| Step: 10
Training loss: 4.086639285677795
Validation loss: 3.8975625981240145

Epoch: 14| Step: 0
Training loss: 4.079105186323804
Validation loss: 3.89255593284911

Epoch: 5| Step: 1
Training loss: 4.655051057824409
Validation loss: 3.8860271770056074

Epoch: 5| Step: 2
Training loss: 3.9095579255483317
Validation loss: 3.88001867792818

Epoch: 5| Step: 3
Training loss: 4.049653149104471
Validation loss: 3.87332715284249

Epoch: 5| Step: 4
Training loss: 4.978796824149597
Validation loss: 3.8691504312688854

Epoch: 5| Step: 5
Training loss: 3.206972667609735
Validation loss: 3.862161598258271

Epoch: 5| Step: 6
Training loss: 3.7712656409091307
Validation loss: 3.85550459255286

Epoch: 5| Step: 7
Training loss: 3.3388627602613963
Validation loss: 3.8527386379745177

Epoch: 5| Step: 8
Training loss: 4.527674454730328
Validation loss: 3.8497539789514086

Epoch: 5| Step: 9
Training loss: 4.005044617136481
Validation loss: 3.846231660726222

Epoch: 5| Step: 10
Training loss: 3.3284621090364697
Validation loss: 3.838085029465085

Epoch: 15| Step: 0
Training loss: 4.37773264965501
Validation loss: 3.8337355028674236

Epoch: 5| Step: 1
Training loss: 5.017510080674275
Validation loss: 3.8310227865235897

Epoch: 5| Step: 2
Training loss: 2.573319088331467
Validation loss: 3.830201547407233

Epoch: 5| Step: 3
Training loss: 4.820347914109678
Validation loss: 3.8280504297691107

Epoch: 5| Step: 4
Training loss: 3.710344961945358
Validation loss: 3.8234088870635548

Epoch: 5| Step: 5
Training loss: 4.393785092904175
Validation loss: 3.8156330126665603

Epoch: 5| Step: 6
Training loss: 3.883727059985658
Validation loss: 3.8085031563938507

Epoch: 5| Step: 7
Training loss: 3.243714196038778
Validation loss: 3.8075523205877553

Epoch: 5| Step: 8
Training loss: 3.968952564266479
Validation loss: 3.8072411336427057

Epoch: 5| Step: 9
Training loss: 3.1633403943073133
Validation loss: 3.7999588575008723

Epoch: 5| Step: 10
Training loss: 4.076017690318823
Validation loss: 3.794834925953392

Epoch: 16| Step: 0
Training loss: 3.703862112860902
Validation loss: 3.7930989761042007

Epoch: 5| Step: 1
Training loss: 4.324314023340689
Validation loss: 3.7887869961926235

Epoch: 5| Step: 2
Training loss: 3.0811936626739085
Validation loss: 3.787817971391098

Epoch: 5| Step: 3
Training loss: 4.673336145034648
Validation loss: 3.7832268476622573

Epoch: 5| Step: 4
Training loss: 3.9495301317262506
Validation loss: 3.7774210654289595

Epoch: 5| Step: 5
Training loss: 3.412440562865934
Validation loss: 3.774414365430113

Epoch: 5| Step: 6
Training loss: 3.8783217928105023
Validation loss: 3.773250767396469

Epoch: 5| Step: 7
Training loss: 4.126965603536506
Validation loss: 3.7681403643686093

Epoch: 5| Step: 8
Training loss: 3.9405505760963706
Validation loss: 3.7623576937973353

Epoch: 5| Step: 9
Training loss: 3.729860521833102
Validation loss: 3.7575644107047403

Epoch: 5| Step: 10
Training loss: 4.468088594587949
Validation loss: 3.7646459927902156

Epoch: 17| Step: 0
Training loss: 4.763868264517272
Validation loss: 3.7583206198552572

Epoch: 5| Step: 1
Training loss: 3.9142125875665035
Validation loss: 3.754547544801675

Epoch: 5| Step: 2
Training loss: 3.8805030386546293
Validation loss: 3.7483341919778046

Epoch: 5| Step: 3
Training loss: 3.1935396009444275
Validation loss: 3.741444596880793

Epoch: 5| Step: 4
Training loss: 3.9885649547493136
Validation loss: 3.7398809764190775

Epoch: 5| Step: 5
Training loss: 4.1914870226810566
Validation loss: 3.7348042548298057

Epoch: 5| Step: 6
Training loss: 3.794058551841261
Validation loss: 3.732619319227575

Epoch: 5| Step: 7
Training loss: 3.455846758147111
Validation loss: 3.727111938255271

Epoch: 5| Step: 8
Training loss: 3.5252889095437205
Validation loss: 3.7250450117793283

Epoch: 5| Step: 9
Training loss: 4.372146765965165
Validation loss: 3.721640125849374

Epoch: 5| Step: 10
Training loss: 3.7701841747516593
Validation loss: 3.720235573182079

Epoch: 18| Step: 0
Training loss: 3.778855503538866
Validation loss: 3.71767844202705

Epoch: 5| Step: 1
Training loss: 4.438512337417705
Validation loss: 3.712574877466712

Epoch: 5| Step: 2
Training loss: 4.159892386365025
Validation loss: 3.7109709002767914

Epoch: 5| Step: 3
Training loss: 4.656743580304275
Validation loss: 3.7063401799537643

Epoch: 5| Step: 4
Training loss: 4.099814080465694
Validation loss: 3.706977670182653

Epoch: 5| Step: 5
Training loss: 2.3922384963028582
Validation loss: 3.7055904277220373

Epoch: 5| Step: 6
Training loss: 3.9094342490264418
Validation loss: 3.7049278549555225

Epoch: 5| Step: 7
Training loss: 3.596222135020191
Validation loss: 3.7020313480307947

Epoch: 5| Step: 8
Training loss: 3.8494031319609894
Validation loss: 3.6991935807349097

Epoch: 5| Step: 9
Training loss: 3.939427464126886
Validation loss: 3.694295662498279

Epoch: 5| Step: 10
Training loss: 3.477308831846279
Validation loss: 3.6922250699291683

Epoch: 19| Step: 0
Training loss: 3.6894687634081618
Validation loss: 3.688803079470019

Epoch: 5| Step: 1
Training loss: 3.304853142088387
Validation loss: 3.6890489909785424

Epoch: 5| Step: 2
Training loss: 3.980114742331128
Validation loss: 3.6835463087606137

Epoch: 5| Step: 3
Training loss: 4.653766148795595
Validation loss: 3.6775643945799774

Epoch: 5| Step: 4
Training loss: 3.604758344532008
Validation loss: 3.6772965565158753

Epoch: 5| Step: 5
Training loss: 4.235345370319142
Validation loss: 3.676066923296042

Epoch: 5| Step: 6
Training loss: 3.9638076405588274
Validation loss: 3.6738377198997902

Epoch: 5| Step: 7
Training loss: 3.9723871340601584
Validation loss: 3.668583270203418

Epoch: 5| Step: 8
Training loss: 4.174706573225738
Validation loss: 3.668207914858085

Epoch: 5| Step: 9
Training loss: 2.885713601011117
Validation loss: 3.663026552652853

Epoch: 5| Step: 10
Training loss: 3.6965404833167734
Validation loss: 3.6627920594634156

Epoch: 20| Step: 0
Training loss: 3.731882708146557
Validation loss: 3.6631614206254985

Epoch: 5| Step: 1
Training loss: 4.96858147869192
Validation loss: 3.659597007266363

Epoch: 5| Step: 2
Training loss: 3.2152158723441766
Validation loss: 3.6530290356555484

Epoch: 5| Step: 3
Training loss: 3.3778392010954326
Validation loss: 3.6481547101021734

Epoch: 5| Step: 4
Training loss: 4.092097990113795
Validation loss: 3.648594614608892

Epoch: 5| Step: 5
Training loss: 4.251260682664352
Validation loss: 3.6482201554730773

Epoch: 5| Step: 6
Training loss: 4.011441556422791
Validation loss: 3.6437071424730365

Epoch: 5| Step: 7
Training loss: 3.6434511667399834
Validation loss: 3.64447300907092

Epoch: 5| Step: 8
Training loss: 3.1905189130372262
Validation loss: 3.6404117988494042

Epoch: 5| Step: 9
Training loss: 3.4638791639294646
Validation loss: 3.6374370220350842

Epoch: 5| Step: 10
Training loss: 3.946178016525655
Validation loss: 3.6346148602094557

Epoch: 21| Step: 0
Training loss: 3.786593106410514
Validation loss: 3.6341898931772607

Epoch: 5| Step: 1
Training loss: 3.9445988680082777
Validation loss: 3.6292131188830985

Epoch: 5| Step: 2
Training loss: 2.5040993459816843
Validation loss: 3.626409220654242

Epoch: 5| Step: 3
Training loss: 3.93481583916851
Validation loss: 3.6269510327814882

Epoch: 5| Step: 4
Training loss: 3.85047559896915
Validation loss: 3.6221960211141186

Epoch: 5| Step: 5
Training loss: 3.962097600005302
Validation loss: 3.6192008418580803

Epoch: 5| Step: 6
Training loss: 4.367517666969312
Validation loss: 3.617817647026319

Epoch: 5| Step: 7
Training loss: 3.807591389531738
Validation loss: 3.615516261103703

Epoch: 5| Step: 8
Training loss: 3.090089424098562
Validation loss: 3.6112068782525624

Epoch: 5| Step: 9
Training loss: 4.302358450725066
Validation loss: 3.6115403371197248

Epoch: 5| Step: 10
Training loss: 4.091323016640126
Validation loss: 3.609753108088591

Epoch: 22| Step: 0
Training loss: 3.6228816979277942
Validation loss: 3.6040442168113374

Epoch: 5| Step: 1
Training loss: 4.085026189003413
Validation loss: 3.605451376351647

Epoch: 5| Step: 2
Training loss: 3.6346097704696922
Validation loss: 3.6061505722108067

Epoch: 5| Step: 3
Training loss: 4.059802994106013
Validation loss: 3.6016466652627512

Epoch: 5| Step: 4
Training loss: 3.3529738364582617
Validation loss: 3.599007189714835

Epoch: 5| Step: 5
Training loss: 3.885951532906847
Validation loss: 3.5951473977272417

Epoch: 5| Step: 6
Training loss: 3.735381689012498
Validation loss: 3.5913668869975

Epoch: 5| Step: 7
Training loss: 4.102180477998532
Validation loss: 3.5924875689493474

Epoch: 5| Step: 8
Training loss: 3.4430749248824797
Validation loss: 3.588326317844645

Epoch: 5| Step: 9
Training loss: 4.271687095098111
Validation loss: 3.5866265118119167

Epoch: 5| Step: 10
Training loss: 3.3452123848813216
Validation loss: 3.5818224686264113

Epoch: 23| Step: 0
Training loss: 3.530199012657746
Validation loss: 3.5797646736647906

Epoch: 5| Step: 1
Training loss: 3.8357960350537645
Validation loss: 3.575118802482642

Epoch: 5| Step: 2
Training loss: 3.28244171300012
Validation loss: 3.5788525374904054

Epoch: 5| Step: 3
Training loss: 3.9487672692984224
Validation loss: 3.576855781287394

Epoch: 5| Step: 4
Training loss: 3.5576658410497557
Validation loss: 3.5717189683647277

Epoch: 5| Step: 5
Training loss: 3.2360349072246373
Validation loss: 3.567253959194456

Epoch: 5| Step: 6
Training loss: 3.016679174351624
Validation loss: 3.5700464663617257

Epoch: 5| Step: 7
Training loss: 4.491077903043007
Validation loss: 3.5699968483676763

Epoch: 5| Step: 8
Training loss: 4.14145338301148
Validation loss: 3.561134288168645

Epoch: 5| Step: 9
Training loss: 4.461763268784529
Validation loss: 3.562668431345928

Epoch: 5| Step: 10
Training loss: 3.679093039536632
Validation loss: 3.5639448792535955

Epoch: 24| Step: 0
Training loss: 3.412180226752583
Validation loss: 3.556289159482513

Epoch: 5| Step: 1
Training loss: 3.724716785084385
Validation loss: 3.552232970050791

Epoch: 5| Step: 2
Training loss: 3.78341839620497
Validation loss: 3.554798518352418

Epoch: 5| Step: 3
Training loss: 3.6840280254594435
Validation loss: 3.562828646089083

Epoch: 5| Step: 4
Training loss: 4.02819542893543
Validation loss: 3.556694180330778

Epoch: 5| Step: 5
Training loss: 3.6168165243249324
Validation loss: 3.5476173837151093

Epoch: 5| Step: 6
Training loss: 4.265588110460337
Validation loss: 3.5458431834644193

Epoch: 5| Step: 7
Training loss: 3.77538165758926
Validation loss: 3.54356938716601

Epoch: 5| Step: 8
Training loss: 3.3006679899207523
Validation loss: 3.5457713267700566

Epoch: 5| Step: 9
Training loss: 3.469844336192508
Validation loss: 3.540973862428429

Epoch: 5| Step: 10
Training loss: 4.182882467546117
Validation loss: 3.530904844685011

Epoch: 25| Step: 0
Training loss: 2.7391251639005443
Validation loss: 3.5234460798069547

Epoch: 5| Step: 1
Training loss: 4.069944632338717
Validation loss: 3.5221058763666355

Epoch: 5| Step: 2
Training loss: 3.5363238856396495
Validation loss: 3.522166755016277

Epoch: 5| Step: 3
Training loss: 4.188515611156576
Validation loss: 3.530650281132504

Epoch: 5| Step: 4
Training loss: 3.5734428856078924
Validation loss: 3.5203222806889425

Epoch: 5| Step: 5
Training loss: 4.024426740493559
Validation loss: 3.511397093785659

Epoch: 5| Step: 6
Training loss: 3.5346007527129712
Validation loss: 3.508885539933855

Epoch: 5| Step: 7
Training loss: 4.391517412712515
Validation loss: 3.507063298482423

Epoch: 5| Step: 8
Training loss: 3.2116922572775466
Validation loss: 3.503898387656886

Epoch: 5| Step: 9
Training loss: 4.026581656040726
Validation loss: 3.4991918193298783

Epoch: 5| Step: 10
Training loss: 3.2649773498497257
Validation loss: 3.49495364575559

Epoch: 26| Step: 0
Training loss: 4.342625753792284
Validation loss: 3.4923303984200094

Epoch: 5| Step: 1
Training loss: 3.154979034450896
Validation loss: 3.4896983544475058

Epoch: 5| Step: 2
Training loss: 3.7235407383958035
Validation loss: 3.4894996119989052

Epoch: 5| Step: 3
Training loss: 3.685646108353724
Validation loss: 3.4834963584966863

Epoch: 5| Step: 4
Training loss: 3.926358035403824
Validation loss: 3.484821297068006

Epoch: 5| Step: 5
Training loss: 3.9382381655548477
Validation loss: 3.480892746997447

Epoch: 5| Step: 6
Training loss: 3.8610826181752445
Validation loss: 3.4780289915280984

Epoch: 5| Step: 7
Training loss: 3.61776115861471
Validation loss: 3.4755235480777986

Epoch: 5| Step: 8
Training loss: 3.462529283530558
Validation loss: 3.4752837556499063

Epoch: 5| Step: 9
Training loss: 3.432060376692149
Validation loss: 3.47207785576301

Epoch: 5| Step: 10
Training loss: 3.3444191806750085
Validation loss: 3.4680978815559738

Epoch: 27| Step: 0
Training loss: 3.689435289379203
Validation loss: 3.4669422071706997

Epoch: 5| Step: 1
Training loss: 3.3822338146685547
Validation loss: 3.463020310017165

Epoch: 5| Step: 2
Training loss: 3.384464979164422
Validation loss: 3.4640219986427434

Epoch: 5| Step: 3
Training loss: 3.659991314570226
Validation loss: 3.459912240772327

Epoch: 5| Step: 4
Training loss: 4.015599350903008
Validation loss: 3.458581139919912

Epoch: 5| Step: 5
Training loss: 4.328196611052999
Validation loss: 3.4578372057320674

Epoch: 5| Step: 6
Training loss: 3.277886546929069
Validation loss: 3.4553514700088037

Epoch: 5| Step: 7
Training loss: 3.6684633679172114
Validation loss: 3.45244209702265

Epoch: 5| Step: 8
Training loss: 3.8247527547475184
Validation loss: 3.448388387895321

Epoch: 5| Step: 9
Training loss: 3.962278601782016
Validation loss: 3.4476108611828318

Epoch: 5| Step: 10
Training loss: 2.909741836841865
Validation loss: 3.444629970561849

Epoch: 28| Step: 0
Training loss: 2.9584086950311543
Validation loss: 3.4417751423181633

Epoch: 5| Step: 1
Training loss: 3.965611215361557
Validation loss: 3.4399037210022083

Epoch: 5| Step: 2
Training loss: 3.4599847795449357
Validation loss: 3.4384726825278227

Epoch: 5| Step: 3
Training loss: 2.884290528222892
Validation loss: 3.4369706463170853

Epoch: 5| Step: 4
Training loss: 4.152651957488046
Validation loss: 3.435952747667805

Epoch: 5| Step: 5
Training loss: 2.892156411801953
Validation loss: 3.434650959521004

Epoch: 5| Step: 6
Training loss: 3.4289986650759685
Validation loss: 3.4298341056231303

Epoch: 5| Step: 7
Training loss: 3.0098291547582097
Validation loss: 3.4262089700304244

Epoch: 5| Step: 8
Training loss: 4.131289686511581
Validation loss: 3.4250559323885077

Epoch: 5| Step: 9
Training loss: 4.3998665529301855
Validation loss: 3.4230867514982055

Epoch: 5| Step: 10
Training loss: 4.506970622818201
Validation loss: 3.4244695493551456

Epoch: 29| Step: 0
Training loss: 3.289561906535013
Validation loss: 3.4205854938664535

Epoch: 5| Step: 1
Training loss: 3.835804861226734
Validation loss: 3.4213810581682553

Epoch: 5| Step: 2
Training loss: 3.975402183099846
Validation loss: 3.4206865994420173

Epoch: 5| Step: 3
Training loss: 4.143535239061417
Validation loss: 3.4156812712016777

Epoch: 5| Step: 4
Training loss: 3.5371819019517665
Validation loss: 3.4131445229355335

Epoch: 5| Step: 5
Training loss: 3.8849605398248377
Validation loss: 3.4109934750854687

Epoch: 5| Step: 6
Training loss: 3.620284334681522
Validation loss: 3.4092949132080546

Epoch: 5| Step: 7
Training loss: 3.1937008549740553
Validation loss: 3.406495486510161

Epoch: 5| Step: 8
Training loss: 3.7668349985189016
Validation loss: 3.407047849256269

Epoch: 5| Step: 9
Training loss: 3.1349361385186674
Validation loss: 3.4104463698442915

Epoch: 5| Step: 10
Training loss: 3.4457642135852824
Validation loss: 3.4027948451219308

Epoch: 30| Step: 0
Training loss: 3.5250078241789
Validation loss: 3.400778684414435

Epoch: 5| Step: 1
Training loss: 3.5576894304101296
Validation loss: 3.399425944739267

Epoch: 5| Step: 2
Training loss: 3.990637312162878
Validation loss: 3.3998174713067115

Epoch: 5| Step: 3
Training loss: 3.628399143162457
Validation loss: 3.3969466478558914

Epoch: 5| Step: 4
Training loss: 3.4622612826138517
Validation loss: 3.3968588370653463

Epoch: 5| Step: 5
Training loss: 3.0710477846403554
Validation loss: 3.3931480892073393

Epoch: 5| Step: 6
Training loss: 3.364938786078822
Validation loss: 3.3943683180127704

Epoch: 5| Step: 7
Training loss: 3.0616938250034025
Validation loss: 3.396493452121424

Epoch: 5| Step: 8
Training loss: 3.2885599726514925
Validation loss: 3.394325526054711

Epoch: 5| Step: 9
Training loss: 4.572925309829828
Validation loss: 3.3883626191228586

Epoch: 5| Step: 10
Training loss: 4.108846536169012
Validation loss: 3.385141328858691

Epoch: 31| Step: 0
Training loss: 3.623430899037891
Validation loss: 3.384034195067532

Epoch: 5| Step: 1
Training loss: 3.653629896582796
Validation loss: 3.382340679540398

Epoch: 5| Step: 2
Training loss: 4.70171124573869
Validation loss: 3.3844784985144396

Epoch: 5| Step: 3
Training loss: 2.416082333481847
Validation loss: 3.3777754828711166

Epoch: 5| Step: 4
Training loss: 3.583770695690782
Validation loss: 3.376399269339511

Epoch: 5| Step: 5
Training loss: 3.85741507614116
Validation loss: 3.3768998757269

Epoch: 5| Step: 6
Training loss: 3.3537291879253432
Validation loss: 3.379543527585903

Epoch: 5| Step: 7
Training loss: 3.4923521681499756
Validation loss: 3.377593052694991

Epoch: 5| Step: 8
Training loss: 4.002468777784365
Validation loss: 3.3739951414133875

Epoch: 5| Step: 9
Training loss: 3.709324536386019
Validation loss: 3.37164481989385

Epoch: 5| Step: 10
Training loss: 2.6827784025661514
Validation loss: 3.3693040967139867

Epoch: 32| Step: 0
Training loss: 2.6892322901176056
Validation loss: 3.368687991280585

Epoch: 5| Step: 1
Training loss: 3.262636998833494
Validation loss: 3.367236800720685

Epoch: 5| Step: 2
Training loss: 4.464947556618063
Validation loss: 3.367428260717111

Epoch: 5| Step: 3
Training loss: 4.257101521058161
Validation loss: 3.364532428156861

Epoch: 5| Step: 4
Training loss: 2.9586939703821984
Validation loss: 3.3631634179862337

Epoch: 5| Step: 5
Training loss: 2.906209965912098
Validation loss: 3.3608716564555947

Epoch: 5| Step: 6
Training loss: 3.546720123270583
Validation loss: 3.359159573637236

Epoch: 5| Step: 7
Training loss: 4.186471157935474
Validation loss: 3.3588898888707113

Epoch: 5| Step: 8
Training loss: 3.7596628942945607
Validation loss: 3.3583050400669285

Epoch: 5| Step: 9
Training loss: 2.989552425707682
Validation loss: 3.357971626303902

Epoch: 5| Step: 10
Training loss: 4.056378491545729
Validation loss: 3.358898676809775

Epoch: 33| Step: 0
Training loss: 2.809350348206376
Validation loss: 3.3578547172980917

Epoch: 5| Step: 1
Training loss: 4.075900702602504
Validation loss: 3.3558328584676556

Epoch: 5| Step: 2
Training loss: 3.161198881376296
Validation loss: 3.3491017139910246

Epoch: 5| Step: 3
Training loss: 3.1923058874851673
Validation loss: 3.3476871729272712

Epoch: 5| Step: 4
Training loss: 3.7263242377481194
Validation loss: 3.347352655617279

Epoch: 5| Step: 5
Training loss: 4.272468415172027
Validation loss: 3.347286024169054

Epoch: 5| Step: 6
Training loss: 3.2261123158437117
Validation loss: 3.345093199812925

Epoch: 5| Step: 7
Training loss: 3.9163907677621994
Validation loss: 3.3445591070803027

Epoch: 5| Step: 8
Training loss: 3.0339587192229116
Validation loss: 3.342968718834182

Epoch: 5| Step: 9
Training loss: 4.028647358883169
Validation loss: 3.3418492736177825

Epoch: 5| Step: 10
Training loss: 3.6352579397329032
Validation loss: 3.3407196920780082

Epoch: 34| Step: 0
Training loss: 3.870585480396935
Validation loss: 3.3420456169052475

Epoch: 5| Step: 1
Training loss: 3.627948219796206
Validation loss: 3.336962363090684

Epoch: 5| Step: 2
Training loss: 3.4550977224394748
Validation loss: 3.3339372062257584

Epoch: 5| Step: 3
Training loss: 2.2974258073817277
Validation loss: 3.335747930739841

Epoch: 5| Step: 4
Training loss: 3.371784232317032
Validation loss: 3.333223244684693

Epoch: 5| Step: 5
Training loss: 3.3599238457451
Validation loss: 3.330862369728255

Epoch: 5| Step: 6
Training loss: 3.4450766554056664
Validation loss: 3.3325612732754677

Epoch: 5| Step: 7
Training loss: 3.6065598115116893
Validation loss: 3.331972133954212

Epoch: 5| Step: 8
Training loss: 3.5738725338210493
Validation loss: 3.3303129406941694

Epoch: 5| Step: 9
Training loss: 4.238917542962491
Validation loss: 3.327731105972414

Epoch: 5| Step: 10
Training loss: 4.158562267986227
Validation loss: 3.328898441147963

Epoch: 35| Step: 0
Training loss: 3.353859423353372
Validation loss: 3.3258950277194046

Epoch: 5| Step: 1
Training loss: 3.7376947052420864
Validation loss: 3.322231505357199

Epoch: 5| Step: 2
Training loss: 3.39521528053045
Validation loss: 3.3226319029434683

Epoch: 5| Step: 3
Training loss: 3.620821945705146
Validation loss: 3.3229543677538027

Epoch: 5| Step: 4
Training loss: 3.8189626231835456
Validation loss: 3.320912705858852

Epoch: 5| Step: 5
Training loss: 3.8270027851286983
Validation loss: 3.323847065892652

Epoch: 5| Step: 6
Training loss: 3.553238592286392
Validation loss: 3.318188123563307

Epoch: 5| Step: 7
Training loss: 3.6119993503101058
Validation loss: 3.3170707111686366

Epoch: 5| Step: 8
Training loss: 3.152885532264917
Validation loss: 3.3150772745674555

Epoch: 5| Step: 9
Training loss: 3.443997986548142
Validation loss: 3.315737333638329

Epoch: 5| Step: 10
Training loss: 3.6072502983527244
Validation loss: 3.3154950724832366

Epoch: 36| Step: 0
Training loss: 2.852174458094087
Validation loss: 3.312674575263919

Epoch: 5| Step: 1
Training loss: 3.576908754425781
Validation loss: 3.313985897244343

Epoch: 5| Step: 2
Training loss: 3.1365133671961445
Validation loss: 3.3127221025090474

Epoch: 5| Step: 3
Training loss: 4.419603391088558
Validation loss: 3.3134119408021845

Epoch: 5| Step: 4
Training loss: 4.5094490452302844
Validation loss: 3.3106247757505782

Epoch: 5| Step: 5
Training loss: 2.924963313467681
Validation loss: 3.3094883371472337

Epoch: 5| Step: 6
Training loss: 2.9016935665045755
Validation loss: 3.3100604180844284

Epoch: 5| Step: 7
Training loss: 4.018888461039976
Validation loss: 3.309657869099544

Epoch: 5| Step: 8
Training loss: 3.8718514725753095
Validation loss: 3.306612937347164

Epoch: 5| Step: 9
Training loss: 3.3119723781502723
Validation loss: 3.3059193353036522

Epoch: 5| Step: 10
Training loss: 2.915901810404445
Validation loss: 3.303290298744675

Epoch: 37| Step: 0
Training loss: 3.104951098021667
Validation loss: 3.3051864250112715

Epoch: 5| Step: 1
Training loss: 3.1029205039755205
Validation loss: 3.3049617147286083

Epoch: 5| Step: 2
Training loss: 3.603802230726386
Validation loss: 3.302421030576541

Epoch: 5| Step: 3
Training loss: 2.710502391713503
Validation loss: 3.3054977940586916

Epoch: 5| Step: 4
Training loss: 3.640610330576669
Validation loss: 3.304806399974319

Epoch: 5| Step: 5
Training loss: 3.4370846584128065
Validation loss: 3.302474713787108

Epoch: 5| Step: 6
Training loss: 4.117073998524458
Validation loss: 3.3006558671090542

Epoch: 5| Step: 7
Training loss: 4.108895509543849
Validation loss: 3.299400656478038

Epoch: 5| Step: 8
Training loss: 3.4742006658688602
Validation loss: 3.2997768228437674

Epoch: 5| Step: 9
Training loss: 3.8804283267473756
Validation loss: 3.2965984717426395

Epoch: 5| Step: 10
Training loss: 3.5536137898063784
Validation loss: 3.29904836287177

Epoch: 38| Step: 0
Training loss: 3.4496290366824454
Validation loss: 3.298016259111919

Epoch: 5| Step: 1
Training loss: 4.0420753560768885
Validation loss: 3.2958530385040348

Epoch: 5| Step: 2
Training loss: 3.2006212823477846
Validation loss: 3.2946761052920106

Epoch: 5| Step: 3
Training loss: 3.9782389945862824
Validation loss: 3.2972271627210414

Epoch: 5| Step: 4
Training loss: 2.951135035549352
Validation loss: 3.2950048118368325

Epoch: 5| Step: 5
Training loss: 3.7474206318762664
Validation loss: 3.2964978126971833

Epoch: 5| Step: 6
Training loss: 2.99528562148665
Validation loss: 3.293246624610431

Epoch: 5| Step: 7
Training loss: 2.992503973656281
Validation loss: 3.2940114632677937

Epoch: 5| Step: 8
Training loss: 4.244534063031117
Validation loss: 3.2927563380962206

Epoch: 5| Step: 9
Training loss: 3.498789441703094
Validation loss: 3.293092684870224

Epoch: 5| Step: 10
Training loss: 3.554067570213056
Validation loss: 3.2998988068603547

Epoch: 39| Step: 0
Training loss: 3.9877628060437127
Validation loss: 3.297354016372598

Epoch: 5| Step: 1
Training loss: 3.6440807526117167
Validation loss: 3.292280382665884

Epoch: 5| Step: 2
Training loss: 2.255711194740938
Validation loss: 3.2901995795432883

Epoch: 5| Step: 3
Training loss: 3.807808036942463
Validation loss: 3.2902807436239034

Epoch: 5| Step: 4
Training loss: 3.142984898559139
Validation loss: 3.2894901999818336

Epoch: 5| Step: 5
Training loss: 3.6751961480558517
Validation loss: 3.2894589092179727

Epoch: 5| Step: 6
Training loss: 3.224359753360626
Validation loss: 3.290372098348649

Epoch: 5| Step: 7
Training loss: 3.90088437641413
Validation loss: 3.2879867363075816

Epoch: 5| Step: 8
Training loss: 3.648688166827239
Validation loss: 3.2863853728223424

Epoch: 5| Step: 9
Training loss: 3.5736167525821703
Validation loss: 3.2852092921683593

Epoch: 5| Step: 10
Training loss: 3.7265193784765995
Validation loss: 3.284044957335985

Epoch: 40| Step: 0
Training loss: 3.270359531434388
Validation loss: 3.286453569752429

Epoch: 5| Step: 1
Training loss: 2.735301705409606
Validation loss: 3.2876780264257772

Epoch: 5| Step: 2
Training loss: 3.5416401282419465
Validation loss: 3.286353813789615

Epoch: 5| Step: 3
Training loss: 3.1047079821881938
Validation loss: 3.285615559083034

Epoch: 5| Step: 4
Training loss: 3.895897414280522
Validation loss: 3.2851623509347356

Epoch: 5| Step: 5
Training loss: 3.025778167510291
Validation loss: 3.282953454376912

Epoch: 5| Step: 6
Training loss: 3.776696355781006
Validation loss: 3.2820293167109775

Epoch: 5| Step: 7
Training loss: 3.436282132894589
Validation loss: 3.281035369869526

Epoch: 5| Step: 8
Training loss: 3.8246679772777106
Validation loss: 3.2812995606101167

Epoch: 5| Step: 9
Training loss: 3.7177435530795884
Validation loss: 3.2800800196723374

Epoch: 5| Step: 10
Training loss: 4.329523735019214
Validation loss: 3.2802442471274293

Epoch: 41| Step: 0
Training loss: 3.7477216793199215
Validation loss: 3.2791289115423345

Epoch: 5| Step: 1
Training loss: 3.5875477219441363
Validation loss: 3.278625419929971

Epoch: 5| Step: 2
Training loss: 3.313779475866318
Validation loss: 3.2777692108037706

Epoch: 5| Step: 3
Training loss: 3.105886371290358
Validation loss: 3.2777135727535254

Epoch: 5| Step: 4
Training loss: 3.132278054329045
Validation loss: 3.2767176814984866

Epoch: 5| Step: 5
Training loss: 4.136915394951334
Validation loss: 3.277034387978616

Epoch: 5| Step: 6
Training loss: 4.126731971343143
Validation loss: 3.2776409358951453

Epoch: 5| Step: 7
Training loss: 3.441974432779919
Validation loss: 3.2749859625227358

Epoch: 5| Step: 8
Training loss: 2.493767981595865
Validation loss: 3.2746621373517253

Epoch: 5| Step: 9
Training loss: 3.397781063128421
Validation loss: 3.272923659782599

Epoch: 5| Step: 10
Training loss: 4.010117609672839
Validation loss: 3.2742832555867563

Epoch: 42| Step: 0
Training loss: 3.2951256327780607
Validation loss: 3.2734857817465173

Epoch: 5| Step: 1
Training loss: 3.051835467761989
Validation loss: 3.2722978815968635

Epoch: 5| Step: 2
Training loss: 2.7601823431401797
Validation loss: 3.2704846334933837

Epoch: 5| Step: 3
Training loss: 3.7286320024235526
Validation loss: 3.270109033084238

Epoch: 5| Step: 4
Training loss: 4.032887917086493
Validation loss: 3.2720940984759355

Epoch: 5| Step: 5
Training loss: 3.264397933619392
Validation loss: 3.269421682684178

Epoch: 5| Step: 6
Training loss: 3.523047448875244
Validation loss: 3.267487422852596

Epoch: 5| Step: 7
Training loss: 4.027655366520929
Validation loss: 3.269190289702376

Epoch: 5| Step: 8
Training loss: 4.435307565580311
Validation loss: 3.2680198200700357

Epoch: 5| Step: 9
Training loss: 2.9950152946680273
Validation loss: 3.266296339693585

Epoch: 5| Step: 10
Training loss: 3.138312556001667
Validation loss: 3.267413047503957

Epoch: 43| Step: 0
Training loss: 3.4080150825632383
Validation loss: 3.2676211834344002

Epoch: 5| Step: 1
Training loss: 4.030328453063745
Validation loss: 3.2649403779955635

Epoch: 5| Step: 2
Training loss: 3.105783813616754
Validation loss: 3.264466267116845

Epoch: 5| Step: 3
Training loss: 2.8286437512519287
Validation loss: 3.2657292278692287

Epoch: 5| Step: 4
Training loss: 3.4430056783566725
Validation loss: 3.2622368384211327

Epoch: 5| Step: 5
Training loss: 3.7378373315970386
Validation loss: 3.2640211638980556

Epoch: 5| Step: 6
Training loss: 3.8448011000124866
Validation loss: 3.2633066372933377

Epoch: 5| Step: 7
Training loss: 3.598924576876596
Validation loss: 3.261543902836242

Epoch: 5| Step: 8
Training loss: 3.455550916722473
Validation loss: 3.2620989967836618

Epoch: 5| Step: 9
Training loss: 3.778329651545708
Validation loss: 3.2616214271248625

Epoch: 5| Step: 10
Training loss: 3.1906184481292916
Validation loss: 3.2597385120450726

Epoch: 44| Step: 0
Training loss: 3.353881887031534
Validation loss: 3.259473618997605

Epoch: 5| Step: 1
Training loss: 3.293449755887535
Validation loss: 3.258556392877222

Epoch: 5| Step: 2
Training loss: 3.2765936373866973
Validation loss: 3.257554330937233

Epoch: 5| Step: 3
Training loss: 3.834285963248102
Validation loss: 3.258403779601587

Epoch: 5| Step: 4
Training loss: 3.3778147792323208
Validation loss: 3.257973715636663

Epoch: 5| Step: 5
Training loss: 3.545994317374541
Validation loss: 3.2557608911278635

Epoch: 5| Step: 6
Training loss: 4.009256381675883
Validation loss: 3.2573148887848515

Epoch: 5| Step: 7
Training loss: 3.49247409404084
Validation loss: 3.254360318809315

Epoch: 5| Step: 8
Training loss: 3.9270605327777397
Validation loss: 3.2562980477151933

Epoch: 5| Step: 9
Training loss: 3.227704822710154
Validation loss: 3.2542413198449855

Epoch: 5| Step: 10
Training loss: 3.0463661747108413
Validation loss: 3.2529876203676333

Epoch: 45| Step: 0
Training loss: 3.7412591152927686
Validation loss: 3.2510413575301977

Epoch: 5| Step: 1
Training loss: 3.665293667673586
Validation loss: 3.2519793150842227

Epoch: 5| Step: 2
Training loss: 3.7937523830852533
Validation loss: 3.2510294707575187

Epoch: 5| Step: 3
Training loss: 3.4353678246228747
Validation loss: 3.2501522703761307

Epoch: 5| Step: 4
Training loss: 3.6623585852704936
Validation loss: 3.2503302400853697

Epoch: 5| Step: 5
Training loss: 3.3896449206352397
Validation loss: 3.2481490086891482

Epoch: 5| Step: 6
Training loss: 4.184848914113861
Validation loss: 3.2484376053097685

Epoch: 5| Step: 7
Training loss: 2.797512301502334
Validation loss: 3.2470722981527906

Epoch: 5| Step: 8
Training loss: 3.2644362042609214
Validation loss: 3.2464910911400082

Epoch: 5| Step: 9
Training loss: 3.0504544091587333
Validation loss: 3.247209141838478

Epoch: 5| Step: 10
Training loss: 3.2844555410278837
Validation loss: 3.2467393918279166

Epoch: 46| Step: 0
Training loss: 2.763046010460269
Validation loss: 3.246758740243471

Epoch: 5| Step: 1
Training loss: 3.6318417144179653
Validation loss: 3.2449361888494876

Epoch: 5| Step: 2
Training loss: 3.3210049255022134
Validation loss: 3.2467091087678

Epoch: 5| Step: 3
Training loss: 3.196759556152304
Validation loss: 3.2438083495878534

Epoch: 5| Step: 4
Training loss: 3.6378071239108274
Validation loss: 3.2424374696154725

Epoch: 5| Step: 5
Training loss: 3.9294338864949694
Validation loss: 3.2437589480043343

Epoch: 5| Step: 6
Training loss: 3.3915374512548375
Validation loss: 3.243487167355852

Epoch: 5| Step: 7
Training loss: 4.074063789149188
Validation loss: 3.2424809694317958

Epoch: 5| Step: 8
Training loss: 3.512122142735871
Validation loss: 3.2413768653849724

Epoch: 5| Step: 9
Training loss: 3.5793546870757464
Validation loss: 3.2402162567011685

Epoch: 5| Step: 10
Training loss: 3.18724941689853
Validation loss: 3.239340309946143

Epoch: 47| Step: 0
Training loss: 4.137744059668301
Validation loss: 3.2395084323513013

Epoch: 5| Step: 1
Training loss: 3.0971944111106176
Validation loss: 3.23978526450168

Epoch: 5| Step: 2
Training loss: 3.660710279615383
Validation loss: 3.23897232852933

Epoch: 5| Step: 3
Training loss: 2.7495260697242463
Validation loss: 3.23743872429919

Epoch: 5| Step: 4
Training loss: 3.2213133447271147
Validation loss: 3.2385227232038463

Epoch: 5| Step: 5
Training loss: 3.5491305670089464
Validation loss: 3.2376703468136694

Epoch: 5| Step: 6
Training loss: 3.716649848888534
Validation loss: 3.2380388039667247

Epoch: 5| Step: 7
Training loss: 3.7471896767214274
Validation loss: 3.237321401422475

Epoch: 5| Step: 8
Training loss: 3.1671718060669694
Validation loss: 3.2395397355200233

Epoch: 5| Step: 9
Training loss: 3.218569852361643
Validation loss: 3.2370814700438575

Epoch: 5| Step: 10
Training loss: 3.9823161471758026
Validation loss: 3.233070307356451

Epoch: 48| Step: 0
Training loss: 3.906351927381121
Validation loss: 3.233946095834895

Epoch: 5| Step: 1
Training loss: 2.989491495633634
Validation loss: 3.234811967426877

Epoch: 5| Step: 2
Training loss: 3.823013817213645
Validation loss: 3.236139974040402

Epoch: 5| Step: 3
Training loss: 3.157085043853126
Validation loss: 3.2338941923247617

Epoch: 5| Step: 4
Training loss: 4.0674919562562115
Validation loss: 3.2328993363844623

Epoch: 5| Step: 5
Training loss: 3.8092700220903595
Validation loss: 3.233638966411086

Epoch: 5| Step: 6
Training loss: 3.351106483718798
Validation loss: 3.2321446691648275

Epoch: 5| Step: 7
Training loss: 3.1295598141643066
Validation loss: 3.2299017433077872

Epoch: 5| Step: 8
Training loss: 3.3457426034320705
Validation loss: 3.230489811587632

Epoch: 5| Step: 9
Training loss: 3.5213451728241405
Validation loss: 3.227986992310722

Epoch: 5| Step: 10
Training loss: 2.9957757455298424
Validation loss: 3.229033827786674

Epoch: 49| Step: 0
Training loss: 3.750143175570804
Validation loss: 3.2296255166103043

Epoch: 5| Step: 1
Training loss: 2.7204161175621002
Validation loss: 3.2292169737031458

Epoch: 5| Step: 2
Training loss: 4.200464477287145
Validation loss: 3.2307886205675316

Epoch: 5| Step: 3
Training loss: 3.361806725714548
Validation loss: 3.2272990679458027

Epoch: 5| Step: 4
Training loss: 3.126991095422571
Validation loss: 3.2260387269348856

Epoch: 5| Step: 5
Training loss: 3.5634321365242485
Validation loss: 3.224633085697428

Epoch: 5| Step: 6
Training loss: 3.469311917816769
Validation loss: 3.22308022651958

Epoch: 5| Step: 7
Training loss: 3.4958107263669924
Validation loss: 3.2220514054425164

Epoch: 5| Step: 8
Training loss: 3.8561300002458925
Validation loss: 3.2229313351837816

Epoch: 5| Step: 9
Training loss: 3.054542323416389
Validation loss: 3.2209221837612287

Epoch: 5| Step: 10
Training loss: 3.449635533417339
Validation loss: 3.2213313560617634

Epoch: 50| Step: 0
Training loss: 2.858333710725127
Validation loss: 3.218812345543513

Epoch: 5| Step: 1
Training loss: 3.335213004062964
Validation loss: 3.21938110147637

Epoch: 5| Step: 2
Training loss: 4.014476804931619
Validation loss: 3.2189871595819066

Epoch: 5| Step: 3
Training loss: 2.8487432888030626
Validation loss: 3.220506182026506

Epoch: 5| Step: 4
Training loss: 3.104630574288609
Validation loss: 3.2195507407146193

Epoch: 5| Step: 5
Training loss: 3.6931423403890773
Validation loss: 3.2197208391986862

Epoch: 5| Step: 6
Training loss: 3.0386983069758458
Validation loss: 3.2181365872917844

Epoch: 5| Step: 7
Training loss: 3.5569779279580116
Validation loss: 3.2201392838010543

Epoch: 5| Step: 8
Training loss: 3.5972445539241984
Validation loss: 3.218606453631791

Epoch: 5| Step: 9
Training loss: 3.3772775947538527
Validation loss: 3.2172234277544365

Epoch: 5| Step: 10
Training loss: 4.609779469475969
Validation loss: 3.2166424709300356

Epoch: 51| Step: 0
Training loss: 3.8975156255950805
Validation loss: 3.216256816507298

Epoch: 5| Step: 1
Training loss: 4.149776838805871
Validation loss: 3.2166030896846323

Epoch: 5| Step: 2
Training loss: 3.818163807731525
Validation loss: 3.2169810634369114

Epoch: 5| Step: 3
Training loss: 2.4462200589070315
Validation loss: 3.2149622280605694

Epoch: 5| Step: 4
Training loss: 3.560568570370682
Validation loss: 3.214510757464605

Epoch: 5| Step: 5
Training loss: 2.4292577627210497
Validation loss: 3.2140555320027424

Epoch: 5| Step: 6
Training loss: 3.854733908211148
Validation loss: 3.2129947331677977

Epoch: 5| Step: 7
Training loss: 2.821562429291423
Validation loss: 3.2149787216312946

Epoch: 5| Step: 8
Training loss: 3.694220932116552
Validation loss: 3.217669971551711

Epoch: 5| Step: 9
Training loss: 3.8483501912294753
Validation loss: 3.2230902310554903

Epoch: 5| Step: 10
Training loss: 3.0811314496182503
Validation loss: 3.212954301848603

Epoch: 52| Step: 0
Training loss: 3.1186414497152963
Validation loss: 3.2131938854165605

Epoch: 5| Step: 1
Training loss: 3.847522156213491
Validation loss: 3.2121905911740694

Epoch: 5| Step: 2
Training loss: 2.782952719683958
Validation loss: 3.2122197471322864

Epoch: 5| Step: 3
Training loss: 3.8993000918574943
Validation loss: 3.2149748095591786

Epoch: 5| Step: 4
Training loss: 3.992981833546788
Validation loss: 3.212652715327622

Epoch: 5| Step: 5
Training loss: 3.0021218107900434
Validation loss: 3.2108605771847953

Epoch: 5| Step: 6
Training loss: 4.091722291981369
Validation loss: 3.2135945046524297

Epoch: 5| Step: 7
Training loss: 3.1411015542806315
Validation loss: 3.210472306969726

Epoch: 5| Step: 8
Training loss: 3.70993433192454
Validation loss: 3.2106529345074444

Epoch: 5| Step: 9
Training loss: 2.8758406032167123
Validation loss: 3.2093281721056597

Epoch: 5| Step: 10
Training loss: 3.3688571268858567
Validation loss: 3.212195643924097

Epoch: 53| Step: 0
Training loss: 3.58100701751064
Validation loss: 3.209826377847771

Epoch: 5| Step: 1
Training loss: 3.5184404416558612
Validation loss: 3.2090074501917836

Epoch: 5| Step: 2
Training loss: 3.399129161386212
Validation loss: 3.2086077946820386

Epoch: 5| Step: 3
Training loss: 3.692910573108502
Validation loss: 3.2081128990113075

Epoch: 5| Step: 4
Training loss: 3.5460183877914644
Validation loss: 3.210248276312606

Epoch: 5| Step: 5
Training loss: 3.508169449144544
Validation loss: 3.20884647961501

Epoch: 5| Step: 6
Training loss: 3.8742510164043775
Validation loss: 3.2080144820980037

Epoch: 5| Step: 7
Training loss: 3.2940266675767127
Validation loss: 3.20903533289325

Epoch: 5| Step: 8
Training loss: 3.045938044538495
Validation loss: 3.2076091681555727

Epoch: 5| Step: 9
Training loss: 3.916606632070162
Validation loss: 3.2061388844803207

Epoch: 5| Step: 10
Training loss: 2.3445807446979092
Validation loss: 3.2044913406364004

Epoch: 54| Step: 0
Training loss: 2.6537724328406864
Validation loss: 3.2076164811678023

Epoch: 5| Step: 1
Training loss: 3.0462742922459616
Validation loss: 3.2061594989980087

Epoch: 5| Step: 2
Training loss: 3.0712674817902377
Validation loss: 3.2053632845874707

Epoch: 5| Step: 3
Training loss: 3.845049630627322
Validation loss: 3.203311341490759

Epoch: 5| Step: 4
Training loss: 3.824252291133873
Validation loss: 3.2019403323324878

Epoch: 5| Step: 5
Training loss: 3.003276466257457
Validation loss: 3.2032273415003947

Epoch: 5| Step: 6
Training loss: 3.8893851024184465
Validation loss: 3.2039637706211193

Epoch: 5| Step: 7
Training loss: 3.3952043258912683
Validation loss: 3.2029822997313975

Epoch: 5| Step: 8
Training loss: 3.432624133172205
Validation loss: 3.202545191974059

Epoch: 5| Step: 9
Training loss: 3.630118341119505
Validation loss: 3.202962803729608

Epoch: 5| Step: 10
Training loss: 4.112817982725859
Validation loss: 3.202108725082708

Epoch: 55| Step: 0
Training loss: 3.0052154029661664
Validation loss: 3.2017146237190333

Epoch: 5| Step: 1
Training loss: 3.1876322400954136
Validation loss: 3.2016270418083006

Epoch: 5| Step: 2
Training loss: 3.0873735780354736
Validation loss: 3.202520842242008

Epoch: 5| Step: 3
Training loss: 3.6286777387435265
Validation loss: 3.2014048113450815

Epoch: 5| Step: 4
Training loss: 4.193924715180467
Validation loss: 3.2007313722521533

Epoch: 5| Step: 5
Training loss: 3.253117166852361
Validation loss: 3.1995910935097838

Epoch: 5| Step: 6
Training loss: 3.144718974889533
Validation loss: 3.1991095808942607

Epoch: 5| Step: 7
Training loss: 3.55950092096286
Validation loss: 3.200338994164572

Epoch: 5| Step: 8
Training loss: 3.5354799575550473
Validation loss: 3.2018670109652914

Epoch: 5| Step: 9
Training loss: 3.82905984479793
Validation loss: 3.200391361764388

Epoch: 5| Step: 10
Training loss: 3.468009388533647
Validation loss: 3.2006178733657804

Epoch: 56| Step: 0
Training loss: 3.569230264124847
Validation loss: 3.200285645202974

Epoch: 5| Step: 1
Training loss: 3.614959228201283
Validation loss: 3.1969312794628357

Epoch: 5| Step: 2
Training loss: 3.0324751747417165
Validation loss: 3.196484470728965

Epoch: 5| Step: 3
Training loss: 3.438717158447432
Validation loss: 3.1989821908584437

Epoch: 5| Step: 4
Training loss: 2.8889029657395877
Validation loss: 3.198868367043347

Epoch: 5| Step: 5
Training loss: 3.530545594843044
Validation loss: 3.1960706952819775

Epoch: 5| Step: 6
Training loss: 3.1578896673061436
Validation loss: 3.1962464740185794

Epoch: 5| Step: 7
Training loss: 3.4223954314480927
Validation loss: 3.1946981227376625

Epoch: 5| Step: 8
Training loss: 3.221232077593492
Validation loss: 3.195803391175328

Epoch: 5| Step: 9
Training loss: 4.366795285104595
Validation loss: 3.196345476245114

Epoch: 5| Step: 10
Training loss: 3.5963650684159227
Validation loss: 3.1960684806206254

Epoch: 57| Step: 0
Training loss: 3.2458666413295383
Validation loss: 3.1970424474606287

Epoch: 5| Step: 1
Training loss: 4.005395588095971
Validation loss: 3.1947597227401987

Epoch: 5| Step: 2
Training loss: 3.2978933488154425
Validation loss: 3.1949406865410297

Epoch: 5| Step: 3
Training loss: 3.358249209528069
Validation loss: 3.1947965695086804

Epoch: 5| Step: 4
Training loss: 3.228758131866907
Validation loss: 3.195397080317625

Epoch: 5| Step: 5
Training loss: 3.230842467236015
Validation loss: 3.1927254728936427

Epoch: 5| Step: 6
Training loss: 3.2347448754862977
Validation loss: 3.1925601401234087

Epoch: 5| Step: 7
Training loss: 3.2958723957304517
Validation loss: 3.1929775628316497

Epoch: 5| Step: 8
Training loss: 3.1332281507599085
Validation loss: 3.194109632136007

Epoch: 5| Step: 9
Training loss: 3.824373610325296
Validation loss: 3.1960301204532495

Epoch: 5| Step: 10
Training loss: 4.076632054687026
Validation loss: 3.193282931119284

Epoch: 58| Step: 0
Training loss: 3.237641974322368
Validation loss: 3.1913154024705177

Epoch: 5| Step: 1
Training loss: 3.5771864280589107
Validation loss: 3.1929150339987937

Epoch: 5| Step: 2
Training loss: 3.6746215936898214
Validation loss: 3.191895049697549

Epoch: 5| Step: 3
Training loss: 3.6987451332733223
Validation loss: 3.1920822989309605

Epoch: 5| Step: 4
Training loss: 3.7395814490070043
Validation loss: 3.191349874260023

Epoch: 5| Step: 5
Training loss: 3.157951274164945
Validation loss: 3.192598766019384

Epoch: 5| Step: 6
Training loss: 3.816868764754481
Validation loss: 3.1924229839831235

Epoch: 5| Step: 7
Training loss: 3.0229479174025022
Validation loss: 3.1894013590960686

Epoch: 5| Step: 8
Training loss: 3.7739162733679072
Validation loss: 3.1918218975626003

Epoch: 5| Step: 9
Training loss: 3.2054253482506825
Validation loss: 3.189221635617944

Epoch: 5| Step: 10
Training loss: 2.8502560483789523
Validation loss: 3.1902816296510506

Epoch: 59| Step: 0
Training loss: 4.236191476083901
Validation loss: 3.190506752566665

Epoch: 5| Step: 1
Training loss: 3.6750385048853755
Validation loss: 3.1881689342512747

Epoch: 5| Step: 2
Training loss: 3.4766099562245585
Validation loss: 3.190589636335446

Epoch: 5| Step: 3
Training loss: 2.924273317496982
Validation loss: 3.1904358747586725

Epoch: 5| Step: 4
Training loss: 2.5806462761853486
Validation loss: 3.1909744015298873

Epoch: 5| Step: 5
Training loss: 3.6931663555541827
Validation loss: 3.1926093687468873

Epoch: 5| Step: 6
Training loss: 2.66091813927695
Validation loss: 3.1964345077754017

Epoch: 5| Step: 7
Training loss: 3.08881053215312
Validation loss: 3.195621715709299

Epoch: 5| Step: 8
Training loss: 3.4837588462539335
Validation loss: 3.195924684772717

Epoch: 5| Step: 9
Training loss: 3.6472878452068267
Validation loss: 3.193143903252728

Epoch: 5| Step: 10
Training loss: 4.175878539705045
Validation loss: 3.1873486374544986

Epoch: 60| Step: 0
Training loss: 3.266473395280855
Validation loss: 3.190742696311339

Epoch: 5| Step: 1
Training loss: 2.6714332616952823
Validation loss: 3.1874955491146095

Epoch: 5| Step: 2
Training loss: 3.3771877968453476
Validation loss: 3.186411450354078

Epoch: 5| Step: 3
Training loss: 3.3241098746950906
Validation loss: 3.188880735569878

Epoch: 5| Step: 4
Training loss: 3.147481692793419
Validation loss: 3.188550439419788

Epoch: 5| Step: 5
Training loss: 4.172842763600892
Validation loss: 3.187736155033652

Epoch: 5| Step: 6
Training loss: 2.7054935728471587
Validation loss: 3.1874380023226343

Epoch: 5| Step: 7
Training loss: 3.6824324102990538
Validation loss: 3.1866219775266744

Epoch: 5| Step: 8
Training loss: 3.8261013365275534
Validation loss: 3.186966722964175

Epoch: 5| Step: 9
Training loss: 3.9035993203854527
Validation loss: 3.182100635920929

Epoch: 5| Step: 10
Training loss: 3.5370732457776577
Validation loss: 3.1830606400360915

Epoch: 61| Step: 0
Training loss: 3.220005716354319
Validation loss: 3.1845113990309994

Epoch: 5| Step: 1
Training loss: 3.9744837635633403
Validation loss: 3.1832489147008682

Epoch: 5| Step: 2
Training loss: 3.4834347127614276
Validation loss: 3.182744000162443

Epoch: 5| Step: 3
Training loss: 3.5641565319669666
Validation loss: 3.185876999731482

Epoch: 5| Step: 4
Training loss: 3.6760728580531215
Validation loss: 3.1830445561348952

Epoch: 5| Step: 5
Training loss: 3.9914685103913574
Validation loss: 3.1825558390119113

Epoch: 5| Step: 6
Training loss: 3.6075683299656425
Validation loss: 3.183278464594113

Epoch: 5| Step: 7
Training loss: 3.0001080811422707
Validation loss: 3.1820932981059125

Epoch: 5| Step: 8
Training loss: 2.7785514856043783
Validation loss: 3.180808415254625

Epoch: 5| Step: 9
Training loss: 2.6800134755265517
Validation loss: 3.1835231104546247

Epoch: 5| Step: 10
Training loss: 3.6668037620114826
Validation loss: 3.1826478613005884

Epoch: 62| Step: 0
Training loss: 3.4545909134826083
Validation loss: 3.180695503104128

Epoch: 5| Step: 1
Training loss: 3.5301306646873036
Validation loss: 3.1802301523557337

Epoch: 5| Step: 2
Training loss: 3.200668658491565
Validation loss: 3.1801376199536713

Epoch: 5| Step: 3
Training loss: 3.22945114031217
Validation loss: 3.181877919091641

Epoch: 5| Step: 4
Training loss: 3.035487722709759
Validation loss: 3.1797627437134595

Epoch: 5| Step: 5
Training loss: 3.053293207507386
Validation loss: 3.180397385190262

Epoch: 5| Step: 6
Training loss: 3.759938865732773
Validation loss: 3.1784486534420155

Epoch: 5| Step: 7
Training loss: 3.954326220965641
Validation loss: 3.1802547082261587

Epoch: 5| Step: 8
Training loss: 2.861094307052827
Validation loss: 3.179115640865698

Epoch: 5| Step: 9
Training loss: 4.127888448494326
Validation loss: 3.179247599127609

Epoch: 5| Step: 10
Training loss: 3.4179921874196433
Validation loss: 3.178706054925701

Epoch: 63| Step: 0
Training loss: 3.3381986079754244
Validation loss: 3.1780537613827753

Epoch: 5| Step: 1
Training loss: 3.36136926407495
Validation loss: 3.1778334166730198

Epoch: 5| Step: 2
Training loss: 3.5582011201999237
Validation loss: 3.1790414221173435

Epoch: 5| Step: 3
Training loss: 3.2565392949612115
Validation loss: 3.17577730417306

Epoch: 5| Step: 4
Training loss: 4.156628584290896
Validation loss: 3.1750175297306247

Epoch: 5| Step: 5
Training loss: 3.368126828902274
Validation loss: 3.1760239299221777

Epoch: 5| Step: 6
Training loss: 3.126190416575887
Validation loss: 3.17821188896945

Epoch: 5| Step: 7
Training loss: 2.8573694752329746
Validation loss: 3.1769443158109416

Epoch: 5| Step: 8
Training loss: 3.0617797938922093
Validation loss: 3.176534123847281

Epoch: 5| Step: 9
Training loss: 3.549990189229814
Validation loss: 3.1772644351775075

Epoch: 5| Step: 10
Training loss: 4.086492263739948
Validation loss: 3.1757831914290087

Epoch: 64| Step: 0
Training loss: 3.8324489540836337
Validation loss: 3.174871484443626

Epoch: 5| Step: 1
Training loss: 3.5380130247541595
Validation loss: 3.1760792474808275

Epoch: 5| Step: 2
Training loss: 3.7258896450177623
Validation loss: 3.176067143921192

Epoch: 5| Step: 3
Training loss: 3.4402001613225033
Validation loss: 3.1788076099590428

Epoch: 5| Step: 4
Training loss: 3.1859553465219403
Validation loss: 3.1769923080942077

Epoch: 5| Step: 5
Training loss: 2.86187851335152
Validation loss: 3.1804266488231288

Epoch: 5| Step: 6
Training loss: 3.2042017173751534
Validation loss: 3.1753160203300075

Epoch: 5| Step: 7
Training loss: 4.11023288373305
Validation loss: 3.1806305565715376

Epoch: 5| Step: 8
Training loss: 2.668681238079227
Validation loss: 3.1752568867147657

Epoch: 5| Step: 9
Training loss: 3.467490577602442
Validation loss: 3.176340225168378

Epoch: 5| Step: 10
Training loss: 3.552850873399175
Validation loss: 3.176115305241187

Epoch: 65| Step: 0
Training loss: 2.7489723539603186
Validation loss: 3.1733616589464044

Epoch: 5| Step: 1
Training loss: 3.1782413727676158
Validation loss: 3.175207094358773

Epoch: 5| Step: 2
Training loss: 3.9445644160429185
Validation loss: 3.1733472005940615

Epoch: 5| Step: 3
Training loss: 3.178187060805144
Validation loss: 3.171376958121848

Epoch: 5| Step: 4
Training loss: 3.327063736034778
Validation loss: 3.1740365468037104

Epoch: 5| Step: 5
Training loss: 3.6358131403817304
Validation loss: 3.1712964614005705

Epoch: 5| Step: 6
Training loss: 3.321200478686721
Validation loss: 3.1727266880157488

Epoch: 5| Step: 7
Training loss: 2.88321126852215
Validation loss: 3.1702275653615968

Epoch: 5| Step: 8
Training loss: 3.7725942866106323
Validation loss: 3.1727745364369033

Epoch: 5| Step: 9
Training loss: 4.070348347745813
Validation loss: 3.173114932922317

Epoch: 5| Step: 10
Training loss: 3.4913681400359105
Validation loss: 3.1697988002701774

Epoch: 66| Step: 0
Training loss: 3.3044827445155875
Validation loss: 3.171649775542507

Epoch: 5| Step: 1
Training loss: 3.1294143016641245
Validation loss: 3.170155807172205

Epoch: 5| Step: 2
Training loss: 3.1423181932491357
Validation loss: 3.1705934036919383

Epoch: 5| Step: 3
Training loss: 3.1170782772805588
Validation loss: 3.1712985518933956

Epoch: 5| Step: 4
Training loss: 3.791454071680301
Validation loss: 3.1718698110860792

Epoch: 5| Step: 5
Training loss: 3.165563910027602
Validation loss: 3.170841205572006

Epoch: 5| Step: 6
Training loss: 3.9561297791642076
Validation loss: 3.1695732390156683

Epoch: 5| Step: 7
Training loss: 3.6748911056474447
Validation loss: 3.170482395053424

Epoch: 5| Step: 8
Training loss: 3.9253058150387656
Validation loss: 3.1688778429414097

Epoch: 5| Step: 9
Training loss: 3.1992583965225014
Validation loss: 3.1714648216899164

Epoch: 5| Step: 10
Training loss: 3.131422233793908
Validation loss: 3.1718667591601575

Epoch: 67| Step: 0
Training loss: 3.687076608952964
Validation loss: 3.176209643359158

Epoch: 5| Step: 1
Training loss: 3.864765803852535
Validation loss: 3.1710115351914037

Epoch: 5| Step: 2
Training loss: 3.1619344454393516
Validation loss: 3.1678062184745603

Epoch: 5| Step: 3
Training loss: 4.230006593378939
Validation loss: 3.170802445610448

Epoch: 5| Step: 4
Training loss: 2.992857855462797
Validation loss: 3.167919049450289

Epoch: 5| Step: 5
Training loss: 3.718442246982011
Validation loss: 3.1672178540557856

Epoch: 5| Step: 6
Training loss: 3.0166998810458834
Validation loss: 3.167963750523808

Epoch: 5| Step: 7
Training loss: 3.2268014593054652
Validation loss: 3.1689995385419856

Epoch: 5| Step: 8
Training loss: 3.100886427368312
Validation loss: 3.1684221190336435

Epoch: 5| Step: 9
Training loss: 2.9574185600257143
Validation loss: 3.1680215054032037

Epoch: 5| Step: 10
Training loss: 3.552968978475849
Validation loss: 3.1671090243442594

Epoch: 68| Step: 0
Training loss: 3.4517718809833258
Validation loss: 3.166339197265546

Epoch: 5| Step: 1
Training loss: 3.394884238200721
Validation loss: 3.1674088308400896

Epoch: 5| Step: 2
Training loss: 3.383837819814671
Validation loss: 3.165084403629999

Epoch: 5| Step: 3
Training loss: 3.1850950855092774
Validation loss: 3.165072279894379

Epoch: 5| Step: 4
Training loss: 3.8289995712555003
Validation loss: 3.162707381667852

Epoch: 5| Step: 5
Training loss: 3.1957312125377637
Validation loss: 3.165198742557846

Epoch: 5| Step: 6
Training loss: 3.6448414497795047
Validation loss: 3.165230035483828

Epoch: 5| Step: 7
Training loss: 3.081051127919893
Validation loss: 3.1658258298666273

Epoch: 5| Step: 8
Training loss: 3.3914916165954194
Validation loss: 3.162210822576966

Epoch: 5| Step: 9
Training loss: 3.556767988778714
Validation loss: 3.163664259637419

Epoch: 5| Step: 10
Training loss: 3.561197544727852
Validation loss: 3.162907785777563

Epoch: 69| Step: 0
Training loss: 3.962745389349786
Validation loss: 3.1654445727361633

Epoch: 5| Step: 1
Training loss: 3.413034384669674
Validation loss: 3.161577173471896

Epoch: 5| Step: 2
Training loss: 3.1265584492883556
Validation loss: 3.1623372067292124

Epoch: 5| Step: 3
Training loss: 3.2569921544712246
Validation loss: 3.1599150611917968

Epoch: 5| Step: 4
Training loss: 3.945719782891651
Validation loss: 3.1625228354421475

Epoch: 5| Step: 5
Training loss: 3.3135531208920046
Validation loss: 3.1608607597497063

Epoch: 5| Step: 6
Training loss: 3.4579875420808737
Validation loss: 3.161349702166074

Epoch: 5| Step: 7
Training loss: 2.1306815768155047
Validation loss: 3.159440922707892

Epoch: 5| Step: 8
Training loss: 3.2609581705853907
Validation loss: 3.1614889142844014

Epoch: 5| Step: 9
Training loss: 3.316790123819092
Validation loss: 3.16013148278942

Epoch: 5| Step: 10
Training loss: 4.193601575518868
Validation loss: 3.1603631236662078

Epoch: 70| Step: 0
Training loss: 3.3360545653767995
Validation loss: 3.1588359641147603

Epoch: 5| Step: 1
Training loss: 3.691471999455788
Validation loss: 3.162896154609899

Epoch: 5| Step: 2
Training loss: 3.4460379254185307
Validation loss: 3.1589010909258084

Epoch: 5| Step: 3
Training loss: 4.191402609504477
Validation loss: 3.1608333329016305

Epoch: 5| Step: 4
Training loss: 3.288797037099266
Validation loss: 3.1590072396859026

Epoch: 5| Step: 5
Training loss: 3.066092427711297
Validation loss: 3.1590900020482304

Epoch: 5| Step: 6
Training loss: 3.0864722452527142
Validation loss: 3.160358564800597

Epoch: 5| Step: 7
Training loss: 3.0185453673323437
Validation loss: 3.1588442908903676

Epoch: 5| Step: 8
Training loss: 3.7087723689984515
Validation loss: 3.1599165572295447

Epoch: 5| Step: 9
Training loss: 3.1576894367140276
Validation loss: 3.156603412951018

Epoch: 5| Step: 10
Training loss: 3.505922211745373
Validation loss: 3.157093177112501

Epoch: 71| Step: 0
Training loss: 3.4648045276370047
Validation loss: 3.1574031396955013

Epoch: 5| Step: 1
Training loss: 2.751100926673963
Validation loss: 3.1564353206993614

Epoch: 5| Step: 2
Training loss: 3.6565198228179545
Validation loss: 3.1571664664487837

Epoch: 5| Step: 3
Training loss: 3.866963328019678
Validation loss: 3.159628709445072

Epoch: 5| Step: 4
Training loss: 3.1586158874324717
Validation loss: 3.1580637785923176

Epoch: 5| Step: 5
Training loss: 3.575431242855566
Validation loss: 3.1561491828411157

Epoch: 5| Step: 6
Training loss: 4.095205033866947
Validation loss: 3.1573230994868355

Epoch: 5| Step: 7
Training loss: 3.1019532848704467
Validation loss: 3.1573389823238966

Epoch: 5| Step: 8
Training loss: 3.6808674534212398
Validation loss: 3.15453371803145

Epoch: 5| Step: 9
Training loss: 2.8741697688282764
Validation loss: 3.1535037681151916

Epoch: 5| Step: 10
Training loss: 3.1048377589594676
Validation loss: 3.1562293982120253

Epoch: 72| Step: 0
Training loss: 2.3532449273784533
Validation loss: 3.1559794336493634

Epoch: 5| Step: 1
Training loss: 3.4641551609749066
Validation loss: 3.155764139200283

Epoch: 5| Step: 2
Training loss: 3.508447398478162
Validation loss: 3.1548714792557107

Epoch: 5| Step: 3
Training loss: 3.008514084673805
Validation loss: 3.1537905946948683

Epoch: 5| Step: 4
Training loss: 3.9312820991212387
Validation loss: 3.1545337976745293

Epoch: 5| Step: 5
Training loss: 3.726632491440137
Validation loss: 3.1547583165253528

Epoch: 5| Step: 6
Training loss: 4.035583768872952
Validation loss: 3.153911379250284

Epoch: 5| Step: 7
Training loss: 3.6667180635722527
Validation loss: 3.154125457436819

Epoch: 5| Step: 8
Training loss: 3.3843849527172156
Validation loss: 3.152537464856921

Epoch: 5| Step: 9
Training loss: 3.1695889658347354
Validation loss: 3.153770124785388

Epoch: 5| Step: 10
Training loss: 2.95082931499608
Validation loss: 3.1545180461847564

Epoch: 73| Step: 0
Training loss: 3.025419783036137
Validation loss: 3.1539620272064828

Epoch: 5| Step: 1
Training loss: 3.5914093356132737
Validation loss: 3.155623260135495

Epoch: 5| Step: 2
Training loss: 4.128191320332732
Validation loss: 3.1589752504910207

Epoch: 5| Step: 3
Training loss: 3.783168589720404
Validation loss: 3.1559959852795965

Epoch: 5| Step: 4
Training loss: 3.196561909518074
Validation loss: 3.1559408437094785

Epoch: 5| Step: 5
Training loss: 3.36988725875492
Validation loss: 3.151559507118326

Epoch: 5| Step: 6
Training loss: 3.249819970646646
Validation loss: 3.1496056719579015

Epoch: 5| Step: 7
Training loss: 3.399230583869958
Validation loss: 3.150464213475181

Epoch: 5| Step: 8
Training loss: 2.999911783828717
Validation loss: 3.150748952261591

Epoch: 5| Step: 9
Training loss: 2.9793002936710096
Validation loss: 3.150758283308818

Epoch: 5| Step: 10
Training loss: 3.7222473624473285
Validation loss: 3.150188633573312

Epoch: 74| Step: 0
Training loss: 3.20407313758917
Validation loss: 3.1501784805203266

Epoch: 5| Step: 1
Training loss: 2.7416283887917787
Validation loss: 3.1507319955267263

Epoch: 5| Step: 2
Training loss: 3.99886758987376
Validation loss: 3.1493637223643116

Epoch: 5| Step: 3
Training loss: 3.711796775516458
Validation loss: 3.1477999316331826

Epoch: 5| Step: 4
Training loss: 2.3016076150215943
Validation loss: 3.149115920470666

Epoch: 5| Step: 5
Training loss: 3.721514788027166
Validation loss: 3.149815167513987

Epoch: 5| Step: 6
Training loss: 4.162601980615422
Validation loss: 3.1493154132462

Epoch: 5| Step: 7
Training loss: 3.2913901458353507
Validation loss: 3.147565224908776

Epoch: 5| Step: 8
Training loss: 3.073530146681668
Validation loss: 3.149683555194884

Epoch: 5| Step: 9
Training loss: 3.6938140605399687
Validation loss: 3.148577707231859

Epoch: 5| Step: 10
Training loss: 3.1763495092856453
Validation loss: 3.1475978928668025

Epoch: 75| Step: 0
Training loss: 3.630243521054168
Validation loss: 3.1492753659184323

Epoch: 5| Step: 1
Training loss: 3.2660782056930486
Validation loss: 3.1478329188491676

Epoch: 5| Step: 2
Training loss: 3.2320409636781453
Validation loss: 3.1486271187088257

Epoch: 5| Step: 3
Training loss: 3.1273401272266987
Validation loss: 3.147018035689027

Epoch: 5| Step: 4
Training loss: 3.822278349732907
Validation loss: 3.1470518668975265

Epoch: 5| Step: 5
Training loss: 3.3472170814344535
Validation loss: 3.1494545980892448

Epoch: 5| Step: 6
Training loss: 3.403043725310404
Validation loss: 3.148648715529307

Epoch: 5| Step: 7
Training loss: 3.491360082041545
Validation loss: 3.1481349071610554

Epoch: 5| Step: 8
Training loss: 2.9473552551190583
Validation loss: 3.1499145726712148

Epoch: 5| Step: 9
Training loss: 3.541106385437099
Validation loss: 3.149263326222607

Epoch: 5| Step: 10
Training loss: 3.6740477281854105
Validation loss: 3.1472954343470025

Epoch: 76| Step: 0
Training loss: 3.3464726566854477
Validation loss: 3.1464834999438747

Epoch: 5| Step: 1
Training loss: 3.2144327190630855
Validation loss: 3.148189460707988

Epoch: 5| Step: 2
Training loss: 3.741094314083797
Validation loss: 3.1471721557708547

Epoch: 5| Step: 3
Training loss: 3.7561968147460534
Validation loss: 3.148779974601982

Epoch: 5| Step: 4
Training loss: 2.9807399161437873
Validation loss: 3.1479634846958437

Epoch: 5| Step: 5
Training loss: 3.3661862896182044
Validation loss: 3.1470262324385176

Epoch: 5| Step: 6
Training loss: 3.4750845864519047
Validation loss: 3.1492020557497633

Epoch: 5| Step: 7
Training loss: 3.39410193991218
Validation loss: 3.15212070855091

Epoch: 5| Step: 8
Training loss: 3.351653980349359
Validation loss: 3.1596560964449205

Epoch: 5| Step: 9
Training loss: 3.7349845356857267
Validation loss: 3.156237821211295

Epoch: 5| Step: 10
Training loss: 3.0568966109362634
Validation loss: 3.1522474354408057

Epoch: 77| Step: 0
Training loss: 2.8733246939308703
Validation loss: 3.147438642633948

Epoch: 5| Step: 1
Training loss: 3.846626755911209
Validation loss: 3.148935190564298

Epoch: 5| Step: 2
Training loss: 3.9907704206600307
Validation loss: 3.1473536988223616

Epoch: 5| Step: 3
Training loss: 2.9196001468865895
Validation loss: 3.146304595555843

Epoch: 5| Step: 4
Training loss: 3.199618918854418
Validation loss: 3.146768590782609

Epoch: 5| Step: 5
Training loss: 3.2568372552002582
Validation loss: 3.145671717819504

Epoch: 5| Step: 6
Training loss: 3.672080695701306
Validation loss: 3.143293338265381

Epoch: 5| Step: 7
Training loss: 3.30288481186437
Validation loss: 3.1430912814230916

Epoch: 5| Step: 8
Training loss: 3.3747490683625743
Validation loss: 3.141726469705247

Epoch: 5| Step: 9
Training loss: 3.191248017851008
Validation loss: 3.143060823531837

Epoch: 5| Step: 10
Training loss: 3.7437097563196575
Validation loss: 3.1416956950285204

Epoch: 78| Step: 0
Training loss: 2.8139464155841796
Validation loss: 3.1443428926302746

Epoch: 5| Step: 1
Training loss: 3.3662103708840543
Validation loss: 3.1439997650941085

Epoch: 5| Step: 2
Training loss: 2.642440984061526
Validation loss: 3.145908336618622

Epoch: 5| Step: 3
Training loss: 3.5784825308803616
Validation loss: 3.144837078614994

Epoch: 5| Step: 4
Training loss: 3.5364688354396177
Validation loss: 3.1437402672919625

Epoch: 5| Step: 5
Training loss: 3.206855202232545
Validation loss: 3.141485362597308

Epoch: 5| Step: 6
Training loss: 3.654073605427153
Validation loss: 3.1423269423452522

Epoch: 5| Step: 7
Training loss: 3.6913538046042946
Validation loss: 3.142802466885245

Epoch: 5| Step: 8
Training loss: 3.422803500242094
Validation loss: 3.141562387110984

Epoch: 5| Step: 9
Training loss: 3.9241723858514925
Validation loss: 3.1378380201855918

Epoch: 5| Step: 10
Training loss: 3.4405267048306474
Validation loss: 3.1402594534671966

Epoch: 79| Step: 0
Training loss: 3.5347739671584897
Validation loss: 3.139104282426509

Epoch: 5| Step: 1
Training loss: 3.4576237574871915
Validation loss: 3.140368291176872

Epoch: 5| Step: 2
Training loss: 3.12172038599471
Validation loss: 3.1370361585987747

Epoch: 5| Step: 3
Training loss: 3.489051998547998
Validation loss: 3.1377602408202763

Epoch: 5| Step: 4
Training loss: 3.080669145598656
Validation loss: 3.1360496138596474

Epoch: 5| Step: 5
Training loss: 3.90292705342421
Validation loss: 3.1373102707696248

Epoch: 5| Step: 6
Training loss: 3.6057336447500283
Validation loss: 3.137605483569752

Epoch: 5| Step: 7
Training loss: 3.7598003752452516
Validation loss: 3.1371502809374068

Epoch: 5| Step: 8
Training loss: 2.9347370220949918
Validation loss: 3.135572816667574

Epoch: 5| Step: 9
Training loss: 3.5764258735662016
Validation loss: 3.1375680092866136

Epoch: 5| Step: 10
Training loss: 2.6893614598916753
Validation loss: 3.140062499217586

Epoch: 80| Step: 0
Training loss: 3.7796271758925
Validation loss: 3.1365486701361345

Epoch: 5| Step: 1
Training loss: 3.225568937048372
Validation loss: 3.137034365623215

Epoch: 5| Step: 2
Training loss: 2.9539180276147117
Validation loss: 3.137873799239054

Epoch: 5| Step: 3
Training loss: 3.9760344928573135
Validation loss: 3.1375123853299702

Epoch: 5| Step: 4
Training loss: 2.8861488120348127
Validation loss: 3.136481866228452

Epoch: 5| Step: 5
Training loss: 3.11401297323652
Validation loss: 3.140122791980348

Epoch: 5| Step: 6
Training loss: 3.309687013839471
Validation loss: 3.137845320148906

Epoch: 5| Step: 7
Training loss: 3.321013540422403
Validation loss: 3.1367023467435438

Epoch: 5| Step: 8
Training loss: 4.103392216507595
Validation loss: 3.1366953808503912

Epoch: 5| Step: 9
Training loss: 3.136840513913483
Validation loss: 3.136910902816705

Epoch: 5| Step: 10
Training loss: 3.3468422539940716
Validation loss: 3.1338487102652586

Epoch: 81| Step: 0
Training loss: 3.422652343524862
Validation loss: 3.1334043253783053

Epoch: 5| Step: 1
Training loss: 3.2123114623321123
Validation loss: 3.1321922099166457

Epoch: 5| Step: 2
Training loss: 3.711176364639715
Validation loss: 3.131858366357478

Epoch: 5| Step: 3
Training loss: 3.686383353091774
Validation loss: 3.1317879899577075

Epoch: 5| Step: 4
Training loss: 2.914993587375608
Validation loss: 3.1320817129971137

Epoch: 5| Step: 5
Training loss: 3.5507033604974727
Validation loss: 3.1339362140691724

Epoch: 5| Step: 6
Training loss: 3.4122378014522474
Validation loss: 3.132341086483264

Epoch: 5| Step: 7
Training loss: 2.6944075239957654
Validation loss: 3.130931590033517

Epoch: 5| Step: 8
Training loss: 3.6540944845159684
Validation loss: 3.1329689947293833

Epoch: 5| Step: 9
Training loss: 3.2368635104266965
Validation loss: 3.1317415454481337

Epoch: 5| Step: 10
Training loss: 3.7533079180582547
Validation loss: 3.1312163144528022

Epoch: 82| Step: 0
Training loss: 3.0797223434141614
Validation loss: 3.1344634658665878

Epoch: 5| Step: 1
Training loss: 2.9211708893222976
Validation loss: 3.1359080845732583

Epoch: 5| Step: 2
Training loss: 3.353393623563399
Validation loss: 3.137253865123491

Epoch: 5| Step: 3
Training loss: 3.3169567428588187
Validation loss: 3.137059011183822

Epoch: 5| Step: 4
Training loss: 3.8175323293100147
Validation loss: 3.135953542783164

Epoch: 5| Step: 5
Training loss: 3.514639347506653
Validation loss: 3.1334015722530673

Epoch: 5| Step: 6
Training loss: 3.448095326630452
Validation loss: 3.1289629314850296

Epoch: 5| Step: 7
Training loss: 3.3995971104390685
Validation loss: 3.1305269976581607

Epoch: 5| Step: 8
Training loss: 4.136485899224415
Validation loss: 3.128150179088803

Epoch: 5| Step: 9
Training loss: 2.760968787680406
Validation loss: 3.127035137059053

Epoch: 5| Step: 10
Training loss: 3.397926449990626
Validation loss: 3.127391792435302

Epoch: 83| Step: 0
Training loss: 2.3336081229483407
Validation loss: 3.127672077670607

Epoch: 5| Step: 1
Training loss: 2.562797156991419
Validation loss: 3.1290699991728985

Epoch: 5| Step: 2
Training loss: 4.086987216527187
Validation loss: 3.1279178623374477

Epoch: 5| Step: 3
Training loss: 3.5507572118702972
Validation loss: 3.1274401893686044

Epoch: 5| Step: 4
Training loss: 2.764727171946019
Validation loss: 3.131172512570119

Epoch: 5| Step: 5
Training loss: 3.6623050728960918
Validation loss: 3.128676323045016

Epoch: 5| Step: 6
Training loss: 4.142549118091514
Validation loss: 3.1291776727341074

Epoch: 5| Step: 7
Training loss: 3.4584589709398488
Validation loss: 3.132850918214488

Epoch: 5| Step: 8
Training loss: 3.5885149433855457
Validation loss: 3.130677022866554

Epoch: 5| Step: 9
Training loss: 3.1912541440764257
Validation loss: 3.1303520639880618

Epoch: 5| Step: 10
Training loss: 3.5144351556396374
Validation loss: 3.130840528758956

Epoch: 84| Step: 0
Training loss: 2.9414663929255505
Validation loss: 3.1260238709336043

Epoch: 5| Step: 1
Training loss: 3.049024400863021
Validation loss: 3.1260616812452238

Epoch: 5| Step: 2
Training loss: 3.9368357022327602
Validation loss: 3.12799476279561

Epoch: 5| Step: 3
Training loss: 3.9833782071149066
Validation loss: 3.1255676016573424

Epoch: 5| Step: 4
Training loss: 3.821164400878355
Validation loss: 3.12503758479661

Epoch: 5| Step: 5
Training loss: 3.158806851067516
Validation loss: 3.1249290687960816

Epoch: 5| Step: 6
Training loss: 3.4515324713461464
Validation loss: 3.1275048026976453

Epoch: 5| Step: 7
Training loss: 3.4594428492562943
Validation loss: 3.1263084166404136

Epoch: 5| Step: 8
Training loss: 2.82625665649548
Validation loss: 3.125289980652293

Epoch: 5| Step: 9
Training loss: 3.4142564941040585
Validation loss: 3.12369756978117

Epoch: 5| Step: 10
Training loss: 2.9314721127035464
Validation loss: 3.1244787294157814

Epoch: 85| Step: 0
Training loss: 3.932644954078472
Validation loss: 3.1225542978309804

Epoch: 5| Step: 1
Training loss: 3.7874339585794212
Validation loss: 3.1228896811057356

Epoch: 5| Step: 2
Training loss: 3.7404095402031023
Validation loss: 3.1234488363978046

Epoch: 5| Step: 3
Training loss: 3.362694524080395
Validation loss: 3.1256387841147637

Epoch: 5| Step: 4
Training loss: 2.934023159005908
Validation loss: 3.1222578951137603

Epoch: 5| Step: 5
Training loss: 3.3701374204786005
Validation loss: 3.1254713068125928

Epoch: 5| Step: 6
Training loss: 3.3507137335363173
Validation loss: 3.125401441159084

Epoch: 5| Step: 7
Training loss: 3.3077920530153055
Validation loss: 3.126384856485556

Epoch: 5| Step: 8
Training loss: 3.2862118942471743
Validation loss: 3.121150267811333

Epoch: 5| Step: 9
Training loss: 3.117122333964046
Validation loss: 3.1235151327650366

Epoch: 5| Step: 10
Training loss: 2.833036089246163
Validation loss: 3.121230661501165

Epoch: 86| Step: 0
Training loss: 3.3320935009846586
Validation loss: 3.121370533602329

Epoch: 5| Step: 1
Training loss: 3.5818434138744975
Validation loss: 3.1214195150349995

Epoch: 5| Step: 2
Training loss: 3.7548149985748895
Validation loss: 3.1222520851074687

Epoch: 5| Step: 3
Training loss: 2.698404324520343
Validation loss: 3.1242145675183437

Epoch: 5| Step: 4
Training loss: 3.7637415564222843
Validation loss: 3.1218558575656745

Epoch: 5| Step: 5
Training loss: 3.0323765814338457
Validation loss: 3.1226997835466346

Epoch: 5| Step: 6
Training loss: 2.790444680739231
Validation loss: 3.1187176434527273

Epoch: 5| Step: 7
Training loss: 3.344428590741889
Validation loss: 3.120990075497864

Epoch: 5| Step: 8
Training loss: 3.6240668575612305
Validation loss: 3.120661776473324

Epoch: 5| Step: 9
Training loss: 3.6777888297548476
Validation loss: 3.122723507827161

Epoch: 5| Step: 10
Training loss: 3.4220213140273144
Validation loss: 3.1208193224533773

Epoch: 87| Step: 0
Training loss: 3.5472014020725178
Validation loss: 3.1199779214885037

Epoch: 5| Step: 1
Training loss: 2.6901273083253066
Validation loss: 3.1174945078205374

Epoch: 5| Step: 2
Training loss: 3.655688642136005
Validation loss: 3.125153804808803

Epoch: 5| Step: 3
Training loss: 2.909220991965088
Validation loss: 3.1266888482855695

Epoch: 5| Step: 4
Training loss: 3.845708828636578
Validation loss: 3.126782484423298

Epoch: 5| Step: 5
Training loss: 3.2626153684365553
Validation loss: 3.1256588165505494

Epoch: 5| Step: 6
Training loss: 3.644250987767009
Validation loss: 3.118669758918814

Epoch: 5| Step: 7
Training loss: 3.158803077194456
Validation loss: 3.120342488621068

Epoch: 5| Step: 8
Training loss: 3.6740630428115564
Validation loss: 3.117960664130001

Epoch: 5| Step: 9
Training loss: 3.679598991479662
Validation loss: 3.1200320980302507

Epoch: 5| Step: 10
Training loss: 2.881585415661223
Validation loss: 3.121382583970074

Epoch: 88| Step: 0
Training loss: 4.178220116981304
Validation loss: 3.1206342477045035

Epoch: 5| Step: 1
Training loss: 3.317807246499826
Validation loss: 3.12025167372536

Epoch: 5| Step: 2
Training loss: 2.822064476368844
Validation loss: 3.1195859134346593

Epoch: 5| Step: 3
Training loss: 3.5345836196702036
Validation loss: 3.11826753663516

Epoch: 5| Step: 4
Training loss: 3.5710804987636307
Validation loss: 3.117340603900804

Epoch: 5| Step: 5
Training loss: 3.1184653050931677
Validation loss: 3.116967051287461

Epoch: 5| Step: 6
Training loss: 2.9937446864962958
Validation loss: 3.115507953224301

Epoch: 5| Step: 7
Training loss: 3.589749439814625
Validation loss: 3.11423733957964

Epoch: 5| Step: 8
Training loss: 3.3307742467975645
Validation loss: 3.1177018046353986

Epoch: 5| Step: 9
Training loss: 3.2784234361107822
Validation loss: 3.1174444532236354

Epoch: 5| Step: 10
Training loss: 3.248993350899545
Validation loss: 3.1205699899633395

Epoch: 89| Step: 0
Training loss: 3.300628261293672
Validation loss: 3.1197208926052733

Epoch: 5| Step: 1
Training loss: 2.4162340982844364
Validation loss: 3.128774297293439

Epoch: 5| Step: 2
Training loss: 2.927971828366858
Validation loss: 3.1310692847822112

Epoch: 5| Step: 3
Training loss: 4.159571876136897
Validation loss: 3.1463378689635038

Epoch: 5| Step: 4
Training loss: 3.9467316445165266
Validation loss: 3.123360766276355

Epoch: 5| Step: 5
Training loss: 3.7138431778000527
Validation loss: 3.1144544642206284

Epoch: 5| Step: 6
Training loss: 3.5490455203948796
Validation loss: 3.1153989793837247

Epoch: 5| Step: 7
Training loss: 2.90503166667336
Validation loss: 3.1108554451449373

Epoch: 5| Step: 8
Training loss: 3.333724348658256
Validation loss: 3.1146477041583163

Epoch: 5| Step: 9
Training loss: 2.6928861007203104
Validation loss: 3.1155288127674394

Epoch: 5| Step: 10
Training loss: 3.960881279841708
Validation loss: 3.1185158595650697

Epoch: 90| Step: 0
Training loss: 3.018654048176644
Validation loss: 3.1159176740881027

Epoch: 5| Step: 1
Training loss: 3.2043035060465646
Validation loss: 3.1142139696629827

Epoch: 5| Step: 2
Training loss: 3.441493818054455
Validation loss: 3.112159933341588

Epoch: 5| Step: 3
Training loss: 3.49885104258013
Validation loss: 3.1113938540303065

Epoch: 5| Step: 4
Training loss: 3.2772164393944454
Validation loss: 3.1121798960264235

Epoch: 5| Step: 5
Training loss: 3.643776246069577
Validation loss: 3.1118561888454295

Epoch: 5| Step: 6
Training loss: 3.455207024429222
Validation loss: 3.110926665921984

Epoch: 5| Step: 7
Training loss: 3.6461065716760177
Validation loss: 3.1103259132252234

Epoch: 5| Step: 8
Training loss: 2.762740187754132
Validation loss: 3.112328497608646

Epoch: 5| Step: 9
Training loss: 3.4436077995503527
Validation loss: 3.1189575811457164

Epoch: 5| Step: 10
Training loss: 3.7112479310946993
Validation loss: 3.1200133162125696

Epoch: 91| Step: 0
Training loss: 3.7172089276652263
Validation loss: 3.1140819879587083

Epoch: 5| Step: 1
Training loss: 3.3204851172960512
Validation loss: 3.114275075668946

Epoch: 5| Step: 2
Training loss: 3.261544192091803
Validation loss: 3.1125165058977795

Epoch: 5| Step: 3
Training loss: 3.4131265924349083
Validation loss: 3.11272539433887

Epoch: 5| Step: 4
Training loss: 2.9028840620994014
Validation loss: 3.1133065167278473

Epoch: 5| Step: 5
Training loss: 3.4076098606146514
Validation loss: 3.111612623845585

Epoch: 5| Step: 6
Training loss: 2.741668391203024
Validation loss: 3.1116881163860346

Epoch: 5| Step: 7
Training loss: 3.0948975871802733
Validation loss: 3.1083163667201648

Epoch: 5| Step: 8
Training loss: 3.675022934822607
Validation loss: 3.110229734185346

Epoch: 5| Step: 9
Training loss: 3.4277544069927477
Validation loss: 3.110467814471055

Epoch: 5| Step: 10
Training loss: 4.077417538836407
Validation loss: 3.10902775102231

Epoch: 92| Step: 0
Training loss: 2.6726156178686162
Validation loss: 3.106428032227801

Epoch: 5| Step: 1
Training loss: 3.1412617052241933
Validation loss: 3.108427809881971

Epoch: 5| Step: 2
Training loss: 2.985391014469854
Validation loss: 3.1093974202061405

Epoch: 5| Step: 3
Training loss: 3.001334529323444
Validation loss: 3.1094700388638046

Epoch: 5| Step: 4
Training loss: 3.814249981589841
Validation loss: 3.1082119567296354

Epoch: 5| Step: 5
Training loss: 3.540776728100324
Validation loss: 3.108571926325754

Epoch: 5| Step: 6
Training loss: 3.7185134171313985
Validation loss: 3.108225119620339

Epoch: 5| Step: 7
Training loss: 3.4769238916361083
Validation loss: 3.1081963861926796

Epoch: 5| Step: 8
Training loss: 3.3991663359535647
Validation loss: 3.1084184804240707

Epoch: 5| Step: 9
Training loss: 3.2749116259583118
Validation loss: 3.1085596630060213

Epoch: 5| Step: 10
Training loss: 3.9620072163685105
Validation loss: 3.1068869414866307

Epoch: 93| Step: 0
Training loss: 3.0232313613209802
Validation loss: 3.1076856049179677

Epoch: 5| Step: 1
Training loss: 2.9182357563791124
Validation loss: 3.1033618117851614

Epoch: 5| Step: 2
Training loss: 3.1303578032712913
Validation loss: 3.1026066104692873

Epoch: 5| Step: 3
Training loss: 3.462548287946654
Validation loss: 3.1046208254994574

Epoch: 5| Step: 4
Training loss: 2.989714155535864
Validation loss: 3.103054983692481

Epoch: 5| Step: 5
Training loss: 3.7155666029105254
Validation loss: 3.1051681809594887

Epoch: 5| Step: 6
Training loss: 2.6078782957266746
Validation loss: 3.1011751362379907

Epoch: 5| Step: 7
Training loss: 3.9735564915716783
Validation loss: 3.102760756917471

Epoch: 5| Step: 8
Training loss: 3.8507292118840084
Validation loss: 3.101271032316357

Epoch: 5| Step: 9
Training loss: 3.6166133548539996
Validation loss: 3.10003728754838

Epoch: 5| Step: 10
Training loss: 3.5675363912243365
Validation loss: 3.1016581005991966

Epoch: 94| Step: 0
Training loss: 4.083818108463889
Validation loss: 3.1036272711064594

Epoch: 5| Step: 1
Training loss: 3.2648353899693308
Validation loss: 3.100337775191073

Epoch: 5| Step: 2
Training loss: 2.9352429423603543
Validation loss: 3.103116451537046

Epoch: 5| Step: 3
Training loss: 2.8071518805999105
Validation loss: 3.1039303886993217

Epoch: 5| Step: 4
Training loss: 4.299568136840033
Validation loss: 3.1066003198108567

Epoch: 5| Step: 5
Training loss: 2.790722606699115
Validation loss: 3.1070084784158025

Epoch: 5| Step: 6
Training loss: 2.9843123664075395
Validation loss: 3.106309449450699

Epoch: 5| Step: 7
Training loss: 3.468231574830728
Validation loss: 3.1044592583541135

Epoch: 5| Step: 8
Training loss: 3.2761065178998647
Validation loss: 3.1068309332560404

Epoch: 5| Step: 9
Training loss: 3.441590251182039
Validation loss: 3.1010737239733728

Epoch: 5| Step: 10
Training loss: 3.368725631144467
Validation loss: 3.1026394559931587

Epoch: 95| Step: 0
Training loss: 3.3841886826617626
Validation loss: 3.1019037485224095

Epoch: 5| Step: 1
Training loss: 3.3018154352502855
Validation loss: 3.102093727015453

Epoch: 5| Step: 2
Training loss: 3.428137913612656
Validation loss: 3.101424101129454

Epoch: 5| Step: 3
Training loss: 3.872987901601257
Validation loss: 3.100582904705993

Epoch: 5| Step: 4
Training loss: 3.7540800151640226
Validation loss: 3.1010407171925456

Epoch: 5| Step: 5
Training loss: 3.1512916823054913
Validation loss: 3.1000527907331366

Epoch: 5| Step: 6
Training loss: 3.083541210143513
Validation loss: 3.098147778678356

Epoch: 5| Step: 7
Training loss: 3.673504407006462
Validation loss: 3.0996250813056774

Epoch: 5| Step: 8
Training loss: 3.1285200511697684
Validation loss: 3.0993176243799945

Epoch: 5| Step: 9
Training loss: 3.2936756103917184
Validation loss: 3.0992596984461183

Epoch: 5| Step: 10
Training loss: 2.7284942167366566
Validation loss: 3.100091165888463

Epoch: 96| Step: 0
Training loss: 3.5877050892760387
Validation loss: 3.099842571134067

Epoch: 5| Step: 1
Training loss: 3.5453947902525607
Validation loss: 3.0994045770085425

Epoch: 5| Step: 2
Training loss: 3.9808792636312003
Validation loss: 3.101513150416301

Epoch: 5| Step: 3
Training loss: 3.825696400594789
Validation loss: 3.098589834900508

Epoch: 5| Step: 4
Training loss: 3.484440276898705
Validation loss: 3.0989750698372194

Epoch: 5| Step: 5
Training loss: 3.5150337230643727
Validation loss: 3.101451822727322

Epoch: 5| Step: 6
Training loss: 2.7216956306157547
Validation loss: 3.098907532055391

Epoch: 5| Step: 7
Training loss: 2.8282612298853613
Validation loss: 3.101133719920675

Epoch: 5| Step: 8
Training loss: 3.0667904752811044
Validation loss: 3.09915666173923

Epoch: 5| Step: 9
Training loss: 3.0960096333868883
Validation loss: 3.1001711778620136

Epoch: 5| Step: 10
Training loss: 3.071891398109605
Validation loss: 3.0972747147757484

Epoch: 97| Step: 0
Training loss: 3.36402422311342
Validation loss: 3.0978115299270454

Epoch: 5| Step: 1
Training loss: 2.7244595612934037
Validation loss: 3.0972716952936366

Epoch: 5| Step: 2
Training loss: 3.767270437029353
Validation loss: 3.0956684162749304

Epoch: 5| Step: 3
Training loss: 3.1288955821642426
Validation loss: 3.096123701346208

Epoch: 5| Step: 4
Training loss: 3.4324486811858685
Validation loss: 3.0967591700437294

Epoch: 5| Step: 5
Training loss: 3.406013410558636
Validation loss: 3.0950210030434313

Epoch: 5| Step: 6
Training loss: 3.056198643914039
Validation loss: 3.095179184908915

Epoch: 5| Step: 7
Training loss: 2.841046064369278
Validation loss: 3.09425269374922

Epoch: 5| Step: 8
Training loss: 4.207247049363158
Validation loss: 3.093782579091564

Epoch: 5| Step: 9
Training loss: 3.263893069722269
Validation loss: 3.0945431548257316

Epoch: 5| Step: 10
Training loss: 3.581538142517624
Validation loss: 3.0939629652254634

Epoch: 98| Step: 0
Training loss: 2.8535405235588094
Validation loss: 3.0975271175119534

Epoch: 5| Step: 1
Training loss: 3.6808535921038623
Validation loss: 3.0955246995275174

Epoch: 5| Step: 2
Training loss: 3.1562315685376126
Validation loss: 3.093563995288591

Epoch: 5| Step: 3
Training loss: 3.1611700706890655
Validation loss: 3.095888328789729

Epoch: 5| Step: 4
Training loss: 3.385291761392719
Validation loss: 3.097855043820716

Epoch: 5| Step: 5
Training loss: 3.937471177737393
Validation loss: 3.099432174402452

Epoch: 5| Step: 6
Training loss: 3.0182557959228014
Validation loss: 3.0981667666949364

Epoch: 5| Step: 7
Training loss: 3.3615244531566213
Validation loss: 3.092565913783235

Epoch: 5| Step: 8
Training loss: 3.343473619108547
Validation loss: 3.093132478635257

Epoch: 5| Step: 9
Training loss: 3.465310255640421
Validation loss: 3.0925466799894683

Epoch: 5| Step: 10
Training loss: 3.4928726104563244
Validation loss: 3.091182698810101

Epoch: 99| Step: 0
Training loss: 3.885878520988891
Validation loss: 3.0913876500614617

Epoch: 5| Step: 1
Training loss: 3.1231699353295346
Validation loss: 3.0929086750426458

Epoch: 5| Step: 2
Training loss: 3.544670865338431
Validation loss: 3.089810518712207

Epoch: 5| Step: 3
Training loss: 3.211327596389918
Validation loss: 3.0911380484950572

Epoch: 5| Step: 4
Training loss: 3.3444163291343627
Validation loss: 3.090112540910301

Epoch: 5| Step: 5
Training loss: 3.3400252086578948
Validation loss: 3.0912014725166377

Epoch: 5| Step: 6
Training loss: 2.463027405778797
Validation loss: 3.090490296747537

Epoch: 5| Step: 7
Training loss: 3.6616938566351007
Validation loss: 3.0925691019955726

Epoch: 5| Step: 8
Training loss: 2.978447745128154
Validation loss: 3.0902749137193797

Epoch: 5| Step: 9
Training loss: 3.646292666609647
Validation loss: 3.0909165970204087

Epoch: 5| Step: 10
Training loss: 3.528966519844181
Validation loss: 3.0900683413889283

Epoch: 100| Step: 0
Training loss: 3.80799136361978
Validation loss: 3.0899460767572915

Epoch: 5| Step: 1
Training loss: 3.8978503440598513
Validation loss: 3.094065198009215

Epoch: 5| Step: 2
Training loss: 3.1576867185643445
Validation loss: 3.0946135696936805

Epoch: 5| Step: 3
Training loss: 3.4254585905811403
Validation loss: 3.092756028616598

Epoch: 5| Step: 4
Training loss: 2.5769893109977353
Validation loss: 3.089918964628426

Epoch: 5| Step: 5
Training loss: 3.0504928628400023
Validation loss: 3.088772960541364

Epoch: 5| Step: 6
Training loss: 3.631514122396744
Validation loss: 3.0868692607470125

Epoch: 5| Step: 7
Training loss: 2.878707816791765
Validation loss: 3.091052556079539

Epoch: 5| Step: 8
Training loss: 4.067118674834255
Validation loss: 3.0889221694656728

Epoch: 5| Step: 9
Training loss: 2.5667629603698434
Validation loss: 3.0904620711825848

Epoch: 5| Step: 10
Training loss: 3.454990763230957
Validation loss: 3.087771194980622

Epoch: 101| Step: 0
Training loss: 3.9177762076473956
Validation loss: 3.0919524541636036

Epoch: 5| Step: 1
Training loss: 2.46594059112591
Validation loss: 3.088177306274035

Epoch: 5| Step: 2
Training loss: 3.579550779704747
Validation loss: 3.0860859546646626

Epoch: 5| Step: 3
Training loss: 4.468713079980245
Validation loss: 3.0881819318487693

Epoch: 5| Step: 4
Training loss: 3.601953580397298
Validation loss: 3.0879464155429095

Epoch: 5| Step: 5
Training loss: 3.2059862708775246
Validation loss: 3.0873384999836913

Epoch: 5| Step: 6
Training loss: 3.0418719566428747
Validation loss: 3.0856159981996196

Epoch: 5| Step: 7
Training loss: 3.37917549956861
Validation loss: 3.087431422237499

Epoch: 5| Step: 8
Training loss: 3.0078462673124844
Validation loss: 3.088031490859481

Epoch: 5| Step: 9
Training loss: 3.0501250319570983
Validation loss: 3.086182832136633

Epoch: 5| Step: 10
Training loss: 2.6399794472270055
Validation loss: 3.0860644790903327

Epoch: 102| Step: 0
Training loss: 3.1470271659965867
Validation loss: 3.086561745013601

Epoch: 5| Step: 1
Training loss: 3.4945606471803132
Validation loss: 3.0868927338705263

Epoch: 5| Step: 2
Training loss: 3.4353596352739304
Validation loss: 3.085859079586006

Epoch: 5| Step: 3
Training loss: 2.8184809351220967
Validation loss: 3.0849383912215678

Epoch: 5| Step: 4
Training loss: 3.716651901649148
Validation loss: 3.084641139062206

Epoch: 5| Step: 5
Training loss: 2.551639803797545
Validation loss: 3.084075695911177

Epoch: 5| Step: 6
Training loss: 3.7002116787131456
Validation loss: 3.0840432728001783

Epoch: 5| Step: 7
Training loss: 3.862331971893198
Validation loss: 3.083294978536518

Epoch: 5| Step: 8
Training loss: 3.371078049146881
Validation loss: 3.0824958713802815

Epoch: 5| Step: 9
Training loss: 3.0908642806410596
Validation loss: 3.084350242531593

Epoch: 5| Step: 10
Training loss: 3.4532385069544627
Validation loss: 3.084854481319257

Epoch: 103| Step: 0
Training loss: 3.6216143878850677
Validation loss: 3.0899332383916307

Epoch: 5| Step: 1
Training loss: 3.082705270533196
Validation loss: 3.094414207245617

Epoch: 5| Step: 2
Training loss: 3.313418566901457
Validation loss: 3.0899720984691044

Epoch: 5| Step: 3
Training loss: 4.061820574946244
Validation loss: 3.0914916671563115

Epoch: 5| Step: 4
Training loss: 3.4174790385788727
Validation loss: 3.0812434949479437

Epoch: 5| Step: 5
Training loss: 3.649442154569761
Validation loss: 3.0803388670578724

Epoch: 5| Step: 6
Training loss: 3.0598643892444657
Validation loss: 3.081040643859219

Epoch: 5| Step: 7
Training loss: 2.745788383598354
Validation loss: 3.0802125150224975

Epoch: 5| Step: 8
Training loss: 2.914999967022171
Validation loss: 3.0819575813820146

Epoch: 5| Step: 9
Training loss: 3.743196928664739
Validation loss: 3.0794761236343047

Epoch: 5| Step: 10
Training loss: 2.9905735374176365
Validation loss: 3.0818491156854693

Epoch: 104| Step: 0
Training loss: 3.7690153569419502
Validation loss: 3.0817954283575277

Epoch: 5| Step: 1
Training loss: 3.327243312046198
Validation loss: 3.0819063274011564

Epoch: 5| Step: 2
Training loss: 2.607435499291418
Validation loss: 3.0803451098284733

Epoch: 5| Step: 3
Training loss: 3.400910698714014
Validation loss: 3.079341518317541

Epoch: 5| Step: 4
Training loss: 3.7621845658093855
Validation loss: 3.079097660963339

Epoch: 5| Step: 5
Training loss: 3.0302959395816957
Validation loss: 3.0789375071926073

Epoch: 5| Step: 6
Training loss: 3.629597083815878
Validation loss: 3.079558357805917

Epoch: 5| Step: 7
Training loss: 2.985161482949401
Validation loss: 3.0782149706552566

Epoch: 5| Step: 8
Training loss: 2.6970914857685084
Validation loss: 3.0791612305836646

Epoch: 5| Step: 9
Training loss: 3.5023738440284986
Validation loss: 3.0793171168004325

Epoch: 5| Step: 10
Training loss: 3.930493008700419
Validation loss: 3.0801858349087956

Epoch: 105| Step: 0
Training loss: 3.1424068122102353
Validation loss: 3.079529442649414

Epoch: 5| Step: 1
Training loss: 3.266429893190936
Validation loss: 3.078964556154682

Epoch: 5| Step: 2
Training loss: 3.7595345403822464
Validation loss: 3.079167140213725

Epoch: 5| Step: 3
Training loss: 2.710288989856768
Validation loss: 3.0763933662020184

Epoch: 5| Step: 4
Training loss: 3.5848817954268197
Validation loss: 3.0778783342609413

Epoch: 5| Step: 5
Training loss: 3.607714911157475
Validation loss: 3.0783337937184077

Epoch: 5| Step: 6
Training loss: 3.408711515180712
Validation loss: 3.07705861395355

Epoch: 5| Step: 7
Training loss: 3.4154519193445676
Validation loss: 3.0783000484214766

Epoch: 5| Step: 8
Training loss: 3.222485642974573
Validation loss: 3.0799826011957356

Epoch: 5| Step: 9
Training loss: 2.9457479706464
Validation loss: 3.079290209969942

Epoch: 5| Step: 10
Training loss: 3.6284950770743825
Validation loss: 3.0798249082308136

Epoch: 106| Step: 0
Training loss: 3.8640470449691557
Validation loss: 3.0767441367324286

Epoch: 5| Step: 1
Training loss: 3.4299255149472176
Validation loss: 3.0763649487980396

Epoch: 5| Step: 2
Training loss: 3.6635265487056716
Validation loss: 3.0750932518770306

Epoch: 5| Step: 3
Training loss: 3.2441031438326227
Validation loss: 3.075999915855299

Epoch: 5| Step: 4
Training loss: 3.1950471576678927
Validation loss: 3.0763874362437287

Epoch: 5| Step: 5
Training loss: 2.5532174736841404
Validation loss: 3.0752905623575533

Epoch: 5| Step: 6
Training loss: 3.519515804887725
Validation loss: 3.0748888103192247

Epoch: 5| Step: 7
Training loss: 3.1616044657501927
Validation loss: 3.073397374638926

Epoch: 5| Step: 8
Training loss: 3.6556497716953
Validation loss: 3.072947383759766

Epoch: 5| Step: 9
Training loss: 3.3850831478843797
Validation loss: 3.073341276610426

Epoch: 5| Step: 10
Training loss: 2.8618170310766464
Validation loss: 3.0737057762245925

Epoch: 107| Step: 0
Training loss: 3.8265854834430613
Validation loss: 3.0729388809583043

Epoch: 5| Step: 1
Training loss: 3.424869429055523
Validation loss: 3.0739601800908813

Epoch: 5| Step: 2
Training loss: 3.465063524640979
Validation loss: 3.0706535825605523

Epoch: 5| Step: 3
Training loss: 3.219862662283105
Validation loss: 3.0728472240701645

Epoch: 5| Step: 4
Training loss: 3.4925988827621732
Validation loss: 3.0725181030513364

Epoch: 5| Step: 5
Training loss: 2.9286503698096884
Validation loss: 3.073592528610013

Epoch: 5| Step: 6
Training loss: 3.102938330069162
Validation loss: 3.076025440476397

Epoch: 5| Step: 7
Training loss: 3.939693142903607
Validation loss: 3.074974638744863

Epoch: 5| Step: 8
Training loss: 2.441796453192453
Validation loss: 3.0737303348851945

Epoch: 5| Step: 9
Training loss: 3.0420247916591423
Validation loss: 3.0752550397025473

Epoch: 5| Step: 10
Training loss: 3.6516089041833775
Validation loss: 3.0729301370304976

Epoch: 108| Step: 0
Training loss: 2.7354710589247855
Validation loss: 3.07274790711159

Epoch: 5| Step: 1
Training loss: 2.5964202005195567
Validation loss: 3.0727093965439924

Epoch: 5| Step: 2
Training loss: 3.3653429116819593
Validation loss: 3.0718758621258844

Epoch: 5| Step: 3
Training loss: 3.6636974421271105
Validation loss: 3.0753175283570298

Epoch: 5| Step: 4
Training loss: 3.816054016538696
Validation loss: 3.074923725250993

Epoch: 5| Step: 5
Training loss: 4.075263060521514
Validation loss: 3.076152961231377

Epoch: 5| Step: 6
Training loss: 3.268673144981484
Validation loss: 3.0744444294450375

Epoch: 5| Step: 7
Training loss: 3.1338499258852828
Validation loss: 3.0736771755007655

Epoch: 5| Step: 8
Training loss: 3.3966542443325007
Validation loss: 3.070015863394496

Epoch: 5| Step: 9
Training loss: 2.7957806710647857
Validation loss: 3.07008891171003

Epoch: 5| Step: 10
Training loss: 3.5933241882160663
Validation loss: 3.0694022918089927

Epoch: 109| Step: 0
Training loss: 3.269185147031861
Validation loss: 3.0682753049732847

Epoch: 5| Step: 1
Training loss: 2.5218045174015407
Validation loss: 3.0696321069773087

Epoch: 5| Step: 2
Training loss: 3.621192379362363
Validation loss: 3.068070173464471

Epoch: 5| Step: 3
Training loss: 2.8003233212037477
Validation loss: 3.0712513241215844

Epoch: 5| Step: 4
Training loss: 2.9424737257258413
Validation loss: 3.069870072205082

Epoch: 5| Step: 5
Training loss: 3.7286341764727267
Validation loss: 3.067765070310829

Epoch: 5| Step: 6
Training loss: 3.519348343003206
Validation loss: 3.067170317805986

Epoch: 5| Step: 7
Training loss: 3.6769537682260673
Validation loss: 3.070153422721208

Epoch: 5| Step: 8
Training loss: 3.830755583332536
Validation loss: 3.06806090678673

Epoch: 5| Step: 9
Training loss: 3.5595298565945184
Validation loss: 3.068819794256829

Epoch: 5| Step: 10
Training loss: 2.922345781393405
Validation loss: 3.0674900304777037

Epoch: 110| Step: 0
Training loss: 3.375310247784465
Validation loss: 3.0687388011117434

Epoch: 5| Step: 1
Training loss: 3.6389330423667614
Validation loss: 3.0656053554649807

Epoch: 5| Step: 2
Training loss: 3.2909831693503486
Validation loss: 3.0665341398334722

Epoch: 5| Step: 3
Training loss: 3.2960428209115724
Validation loss: 3.0671327000977944

Epoch: 5| Step: 4
Training loss: 3.0226904761890108
Validation loss: 3.065200677988245

Epoch: 5| Step: 5
Training loss: 3.1113152512680933
Validation loss: 3.0669219969630004

Epoch: 5| Step: 6
Training loss: 3.4282696341341317
Validation loss: 3.0667232151310686

Epoch: 5| Step: 7
Training loss: 3.0181221382094368
Validation loss: 3.0674570033137933

Epoch: 5| Step: 8
Training loss: 3.4057744245394717
Validation loss: 3.0682779368963473

Epoch: 5| Step: 9
Training loss: 3.765705281901599
Validation loss: 3.066628095425283

Epoch: 5| Step: 10
Training loss: 3.1988061585291083
Validation loss: 3.0735229550374137

Epoch: 111| Step: 0
Training loss: 3.3590699523110623
Validation loss: 3.0713087633002134

Epoch: 5| Step: 1
Training loss: 3.255816024006537
Validation loss: 3.0683965231583517

Epoch: 5| Step: 2
Training loss: 2.6360232191727415
Validation loss: 3.0711677280931986

Epoch: 5| Step: 3
Training loss: 3.8454913405054425
Validation loss: 3.066118521431039

Epoch: 5| Step: 4
Training loss: 3.5598221468700078
Validation loss: 3.065251470292639

Epoch: 5| Step: 5
Training loss: 3.350878665759416
Validation loss: 3.0630910310213935

Epoch: 5| Step: 6
Training loss: 4.0622844932322355
Validation loss: 3.063911394026389

Epoch: 5| Step: 7
Training loss: 3.3136706892643466
Validation loss: 3.0632975638258193

Epoch: 5| Step: 8
Training loss: 3.0398263633228844
Validation loss: 3.062849815468588

Epoch: 5| Step: 9
Training loss: 3.087948841412399
Validation loss: 3.0626300317893564

Epoch: 5| Step: 10
Training loss: 2.8724234272152223
Validation loss: 3.0624682734748174

Epoch: 112| Step: 0
Training loss: 3.5502459266262623
Validation loss: 3.063234466751942

Epoch: 5| Step: 1
Training loss: 2.425971326276452
Validation loss: 3.063653808515712

Epoch: 5| Step: 2
Training loss: 3.4470862150109127
Validation loss: 3.065038267438499

Epoch: 5| Step: 3
Training loss: 3.265176112520788
Validation loss: 3.063129588863628

Epoch: 5| Step: 4
Training loss: 3.4240846510610448
Validation loss: 3.0609510320478566

Epoch: 5| Step: 5
Training loss: 3.4337019312007184
Validation loss: 3.062836396470211

Epoch: 5| Step: 6
Training loss: 3.2222191346544697
Validation loss: 3.0630089489903383

Epoch: 5| Step: 7
Training loss: 3.057486186210762
Validation loss: 3.0629584191382686

Epoch: 5| Step: 8
Training loss: 3.521245913437167
Validation loss: 3.060631576121894

Epoch: 5| Step: 9
Training loss: 3.813676871339744
Validation loss: 3.061077669103922

Epoch: 5| Step: 10
Training loss: 3.2808180751805853
Validation loss: 3.0600853165618713

Epoch: 113| Step: 0
Training loss: 3.5685592787464993
Validation loss: 3.0594426829338173

Epoch: 5| Step: 1
Training loss: 3.5687538267205294
Validation loss: 3.0603164898265507

Epoch: 5| Step: 2
Training loss: 3.5506990630958746
Validation loss: 3.0596919693995686

Epoch: 5| Step: 3
Training loss: 3.6189419341371383
Validation loss: 3.0597393223992992

Epoch: 5| Step: 4
Training loss: 3.197552555657437
Validation loss: 3.0606165944465467

Epoch: 5| Step: 5
Training loss: 3.416052476216323
Validation loss: 3.060724072899278

Epoch: 5| Step: 6
Training loss: 3.0698872434306
Validation loss: 3.0616462091638232

Epoch: 5| Step: 7
Training loss: 3.21256573086595
Validation loss: 3.059520350108984

Epoch: 5| Step: 8
Training loss: 3.1590347846405313
Validation loss: 3.063967075664938

Epoch: 5| Step: 9
Training loss: 2.668304466919008
Validation loss: 3.0645437630647168

Epoch: 5| Step: 10
Training loss: 3.4823205476354953
Validation loss: 3.0635026182486724

Epoch: 114| Step: 0
Training loss: 3.2936618568743814
Validation loss: 3.0666287015109313

Epoch: 5| Step: 1
Training loss: 3.1661767747968046
Validation loss: 3.0585032340075444

Epoch: 5| Step: 2
Training loss: 3.7636736487249323
Validation loss: 3.0554523402730127

Epoch: 5| Step: 3
Training loss: 3.6058246275730066
Validation loss: 3.057811807623596

Epoch: 5| Step: 4
Training loss: 3.00835178049055
Validation loss: 3.0566834895833734

Epoch: 5| Step: 5
Training loss: 2.54902286881746
Validation loss: 3.0578720453939217

Epoch: 5| Step: 6
Training loss: 3.316088334336932
Validation loss: 3.0626699857935105

Epoch: 5| Step: 7
Training loss: 3.5400008079829615
Validation loss: 3.0619344634889316

Epoch: 5| Step: 8
Training loss: 3.2839052628432492
Validation loss: 3.0597874521904056

Epoch: 5| Step: 9
Training loss: 3.122925794781931
Validation loss: 3.0626349320026107

Epoch: 5| Step: 10
Training loss: 3.929603894294213
Validation loss: 3.0583269133333753

Epoch: 115| Step: 0
Training loss: 3.3423106580587545
Validation loss: 3.0577766729874276

Epoch: 5| Step: 1
Training loss: 3.171381719407626
Validation loss: 3.0549874476458276

Epoch: 5| Step: 2
Training loss: 3.473602749509703
Validation loss: 3.0556643980919294

Epoch: 5| Step: 3
Training loss: 3.5389442003027463
Validation loss: 3.0554056793351987

Epoch: 5| Step: 4
Training loss: 3.4108583966255552
Validation loss: 3.0566303708920337

Epoch: 5| Step: 5
Training loss: 2.915621670213047
Validation loss: 3.0572565548429

Epoch: 5| Step: 6
Training loss: 3.0963624655203565
Validation loss: 3.054936796863499

Epoch: 5| Step: 7
Training loss: 3.40352430566902
Validation loss: 3.058451685884706

Epoch: 5| Step: 8
Training loss: 3.744037847645514
Validation loss: 3.059032970593828

Epoch: 5| Step: 9
Training loss: 2.7563566952769194
Validation loss: 3.0636544059850572

Epoch: 5| Step: 10
Training loss: 3.63278703578105
Validation loss: 3.0573524641930137

Epoch: 116| Step: 0
Training loss: 3.456396012214097
Validation loss: 3.057906323802437

Epoch: 5| Step: 1
Training loss: 3.0338938086979996
Validation loss: 3.0621837530532647

Epoch: 5| Step: 2
Training loss: 3.534869609192353
Validation loss: 3.0647803031880265

Epoch: 5| Step: 3
Training loss: 3.331909893012752
Validation loss: 3.0643762128027516

Epoch: 5| Step: 4
Training loss: 3.6556172923859402
Validation loss: 3.061904810882885

Epoch: 5| Step: 5
Training loss: 3.2147259789143514
Validation loss: 3.0569419643370312

Epoch: 5| Step: 6
Training loss: 3.3628665256334624
Validation loss: 3.053149778314852

Epoch: 5| Step: 7
Training loss: 3.1191080625550627
Validation loss: 3.0525291061616135

Epoch: 5| Step: 8
Training loss: 2.8692395093898404
Validation loss: 3.051294573376441

Epoch: 5| Step: 9
Training loss: 2.9286448339905724
Validation loss: 3.051659968189541

Epoch: 5| Step: 10
Training loss: 4.012667624516607
Validation loss: 3.0524998442636773

Epoch: 117| Step: 0
Training loss: 3.0565112979330027
Validation loss: 3.0514688371247027

Epoch: 5| Step: 1
Training loss: 3.2382756544923006
Validation loss: 3.0528402893702746

Epoch: 5| Step: 2
Training loss: 3.3426292181038684
Validation loss: 3.0516831963324327

Epoch: 5| Step: 3
Training loss: 2.9289787554167437
Validation loss: 3.0508353360486846

Epoch: 5| Step: 4
Training loss: 3.839188016237735
Validation loss: 3.0497561463029625

Epoch: 5| Step: 5
Training loss: 3.8286314337365392
Validation loss: 3.0507176041376525

Epoch: 5| Step: 6
Training loss: 3.009807133372924
Validation loss: 3.050064488211155

Epoch: 5| Step: 7
Training loss: 3.295050093366996
Validation loss: 3.0505747437993698

Epoch: 5| Step: 8
Training loss: 3.5396480118064497
Validation loss: 3.0497425789061254

Epoch: 5| Step: 9
Training loss: 3.6049045108841336
Validation loss: 3.0487403395305552

Epoch: 5| Step: 10
Training loss: 2.537973399234067
Validation loss: 3.0503074611390053

Epoch: 118| Step: 0
Training loss: 3.1887472367882204
Validation loss: 3.0494124959739253

Epoch: 5| Step: 1
Training loss: 2.604097523089241
Validation loss: 3.048594560186668

Epoch: 5| Step: 2
Training loss: 3.4757992710324577
Validation loss: 3.0465264822827205

Epoch: 5| Step: 3
Training loss: 3.7821840756150324
Validation loss: 3.049475564624658

Epoch: 5| Step: 4
Training loss: 3.106371478462779
Validation loss: 3.051306441754376

Epoch: 5| Step: 5
Training loss: 3.578554219317928
Validation loss: 3.0514560477484185

Epoch: 5| Step: 6
Training loss: 3.8005938116198172
Validation loss: 3.04750574071103

Epoch: 5| Step: 7
Training loss: 2.780707231344468
Validation loss: 3.0521800934317067

Epoch: 5| Step: 8
Training loss: 3.4814883193346455
Validation loss: 3.0505206262377347

Epoch: 5| Step: 9
Training loss: 3.5318963463630464
Validation loss: 3.049291832140293

Epoch: 5| Step: 10
Training loss: 2.879806646903115
Validation loss: 3.0496931944169194

Epoch: 119| Step: 0
Training loss: 2.6267159620813363
Validation loss: 3.046338181577706

Epoch: 5| Step: 1
Training loss: 3.706870715702085
Validation loss: 3.045611766436277

Epoch: 5| Step: 2
Training loss: 2.897591439121687
Validation loss: 3.0456387645737943

Epoch: 5| Step: 3
Training loss: 3.6685275788608696
Validation loss: 3.044864556047094

Epoch: 5| Step: 4
Training loss: 3.2256682775499392
Validation loss: 3.0461940983736278

Epoch: 5| Step: 5
Training loss: 3.781369420207134
Validation loss: 3.0458639221105366

Epoch: 5| Step: 6
Training loss: 3.346036467951424
Validation loss: 3.0450066815638785

Epoch: 5| Step: 7
Training loss: 3.5065665634236436
Validation loss: 3.044260661632418

Epoch: 5| Step: 8
Training loss: 3.953231508531519
Validation loss: 3.0444118862488523

Epoch: 5| Step: 9
Training loss: 2.6228338113857763
Validation loss: 3.0446677703610048

Epoch: 5| Step: 10
Training loss: 2.739842382060314
Validation loss: 3.0443223885915587

Epoch: 120| Step: 0
Training loss: 3.9764076907258605
Validation loss: 3.0444236037798977

Epoch: 5| Step: 1
Training loss: 3.4008417153498587
Validation loss: 3.043806428089975

Epoch: 5| Step: 2
Training loss: 3.8896475793606258
Validation loss: 3.044753421779022

Epoch: 5| Step: 3
Training loss: 3.2992808165189578
Validation loss: 3.046495796125624

Epoch: 5| Step: 4
Training loss: 2.888225322302631
Validation loss: 3.0467058907343114

Epoch: 5| Step: 5
Training loss: 3.149248723857682
Validation loss: 3.044535704968156

Epoch: 5| Step: 6
Training loss: 3.370925421728066
Validation loss: 3.0586315934235113

Epoch: 5| Step: 7
Training loss: 3.216288690315769
Validation loss: 3.060985935105636

Epoch: 5| Step: 8
Training loss: 3.0692183313950614
Validation loss: 3.0557877893902785

Epoch: 5| Step: 9
Training loss: 3.0311000826228858
Validation loss: 3.060437631215187

Epoch: 5| Step: 10
Training loss: 2.997814176891617
Validation loss: 3.047481229814597

Epoch: 121| Step: 0
Training loss: 3.8568362638945017
Validation loss: 3.047040742878666

Epoch: 5| Step: 1
Training loss: 2.965281658979065
Validation loss: 3.0434908019348668

Epoch: 5| Step: 2
Training loss: 3.314596700171838
Validation loss: 3.04122587227697

Epoch: 5| Step: 3
Training loss: 3.3015296223091597
Validation loss: 3.0413772713922453

Epoch: 5| Step: 4
Training loss: 3.084761537952766
Validation loss: 3.0412267742471584

Epoch: 5| Step: 5
Training loss: 3.575798777728371
Validation loss: 3.0403074570046265

Epoch: 5| Step: 6
Training loss: 2.781868340838451
Validation loss: 3.0378298466723543

Epoch: 5| Step: 7
Training loss: 3.078086891519335
Validation loss: 3.040683351960623

Epoch: 5| Step: 8
Training loss: 3.5835222741519637
Validation loss: 3.039251590570462

Epoch: 5| Step: 9
Training loss: 3.4629079750517135
Validation loss: 3.041622003645156

Epoch: 5| Step: 10
Training loss: 3.284686078730085
Validation loss: 3.0405994559692235

Epoch: 122| Step: 0
Training loss: 3.187473371805901
Validation loss: 3.04046160844457

Epoch: 5| Step: 1
Training loss: 3.478522479025392
Validation loss: 3.0399142350113864

Epoch: 5| Step: 2
Training loss: 2.6286382439366913
Validation loss: 3.03902736539856

Epoch: 5| Step: 3
Training loss: 2.880865333680278
Validation loss: 3.0373821936723773

Epoch: 5| Step: 4
Training loss: 3.292847401474811
Validation loss: 3.0380149297149384

Epoch: 5| Step: 5
Training loss: 3.089297703311
Validation loss: 3.035531610611263

Epoch: 5| Step: 6
Training loss: 3.748635870457709
Validation loss: 3.0394146097861947

Epoch: 5| Step: 7
Training loss: 3.6145359149794416
Validation loss: 3.0388609475608486

Epoch: 5| Step: 8
Training loss: 3.8667015309789936
Validation loss: 3.0406353615717463

Epoch: 5| Step: 9
Training loss: 3.5262293951114754
Validation loss: 3.0383880286044396

Epoch: 5| Step: 10
Training loss: 2.801455960479236
Validation loss: 3.0405701956164584

Epoch: 123| Step: 0
Training loss: 3.0211177472803223
Validation loss: 3.042449122877538

Epoch: 5| Step: 1
Training loss: 2.729186099228338
Validation loss: 3.0375335944700694

Epoch: 5| Step: 2
Training loss: 3.741955074984616
Validation loss: 3.0411069430571724

Epoch: 5| Step: 3
Training loss: 3.5017567721549434
Validation loss: 3.0379808108239446

Epoch: 5| Step: 4
Training loss: 3.468610881043274
Validation loss: 3.0399929239577155

Epoch: 5| Step: 5
Training loss: 3.0817906584345653
Validation loss: 3.0369619990503316

Epoch: 5| Step: 6
Training loss: 3.4402927498116695
Validation loss: 3.0378268153630903

Epoch: 5| Step: 7
Training loss: 3.8133166329700625
Validation loss: 3.037334111454625

Epoch: 5| Step: 8
Training loss: 3.6496748531216174
Validation loss: 3.0371742792642604

Epoch: 5| Step: 9
Training loss: 2.968785175315872
Validation loss: 3.0377508645508153

Epoch: 5| Step: 10
Training loss: 2.6288936438973853
Validation loss: 3.0374181398385165

Epoch: 124| Step: 0
Training loss: 2.877390158219707
Validation loss: 3.0381866710620042

Epoch: 5| Step: 1
Training loss: 3.6895779719314667
Validation loss: 3.0369015693826364

Epoch: 5| Step: 2
Training loss: 3.3384245774103714
Validation loss: 3.03624826365729

Epoch: 5| Step: 3
Training loss: 3.6920630461082307
Validation loss: 3.037164207596332

Epoch: 5| Step: 4
Training loss: 2.992834753244738
Validation loss: 3.034370006634349

Epoch: 5| Step: 5
Training loss: 2.8030809992268004
Validation loss: 3.0367040456466827

Epoch: 5| Step: 6
Training loss: 3.511405073675019
Validation loss: 3.0365614352817025

Epoch: 5| Step: 7
Training loss: 3.103687548091657
Validation loss: 3.0365739480005733

Epoch: 5| Step: 8
Training loss: 3.5091233554746957
Validation loss: 3.0336381515896598

Epoch: 5| Step: 9
Training loss: 3.5375899394433605
Validation loss: 3.0350997340325114

Epoch: 5| Step: 10
Training loss: 3.1399916584365744
Validation loss: 3.0355064194421426

Epoch: 125| Step: 0
Training loss: 3.4293526940083523
Validation loss: 3.0363119688091675

Epoch: 5| Step: 1
Training loss: 3.7637349684157604
Validation loss: 3.0364054521165995

Epoch: 5| Step: 2
Training loss: 3.679145659706796
Validation loss: 3.0343490555374775

Epoch: 5| Step: 3
Training loss: 3.4872353620857104
Validation loss: 3.0349792318198983

Epoch: 5| Step: 4
Training loss: 2.822483484643913
Validation loss: 3.0349939565582686

Epoch: 5| Step: 5
Training loss: 3.0692582589399025
Validation loss: 3.0318043731191637

Epoch: 5| Step: 6
Training loss: 3.4361145001696856
Validation loss: 3.0344602776954233

Epoch: 5| Step: 7
Training loss: 3.6523857889458973
Validation loss: 3.036511507154265

Epoch: 5| Step: 8
Training loss: 2.9990827429723135
Validation loss: 3.0321768859669462

Epoch: 5| Step: 9
Training loss: 3.0140824399835333
Validation loss: 3.0318097366440377

Epoch: 5| Step: 10
Training loss: 2.7148966173472058
Validation loss: 3.0341297117303636

Epoch: 126| Step: 0
Training loss: 3.606999660169365
Validation loss: 3.035722757039668

Epoch: 5| Step: 1
Training loss: 3.7612930643260265
Validation loss: 3.0325151802800776

Epoch: 5| Step: 2
Training loss: 3.8668162158020327
Validation loss: 3.0365929293108427

Epoch: 5| Step: 3
Training loss: 2.705073894401024
Validation loss: 3.0334471459342387

Epoch: 5| Step: 4
Training loss: 2.617908344351702
Validation loss: 3.030328940302213

Epoch: 5| Step: 5
Training loss: 3.619827921660653
Validation loss: 3.030531016193422

Epoch: 5| Step: 6
Training loss: 2.607074934490816
Validation loss: 3.0298219629549994

Epoch: 5| Step: 7
Training loss: 3.0242860377125096
Validation loss: 3.0287470868313475

Epoch: 5| Step: 8
Training loss: 3.4340357577329015
Validation loss: 3.0316359647735407

Epoch: 5| Step: 9
Training loss: 3.8519887320808244
Validation loss: 3.0286293190515834

Epoch: 5| Step: 10
Training loss: 2.76883584399649
Validation loss: 3.029019344284003

Epoch: 127| Step: 0
Training loss: 3.1160214951426313
Validation loss: 3.0276679866147567

Epoch: 5| Step: 1
Training loss: 3.328133883039055
Validation loss: 3.0302896470019527

Epoch: 5| Step: 2
Training loss: 3.2304541369549327
Validation loss: 3.030287767177935

Epoch: 5| Step: 3
Training loss: 3.438228599320307
Validation loss: 3.0307578357657974

Epoch: 5| Step: 4
Training loss: 3.044192341145299
Validation loss: 3.0299087583155475

Epoch: 5| Step: 5
Training loss: 3.131749151042617
Validation loss: 3.0317332055263164

Epoch: 5| Step: 6
Training loss: 3.5776061635556298
Validation loss: 3.0292365116137017

Epoch: 5| Step: 7
Training loss: 3.8682773480081907
Validation loss: 3.0310170615160628

Epoch: 5| Step: 8
Training loss: 3.424719198925906
Validation loss: 3.0296325410879716

Epoch: 5| Step: 9
Training loss: 2.6681355861258114
Validation loss: 3.0307886829584754

Epoch: 5| Step: 10
Training loss: 3.3727915567274294
Validation loss: 3.0320010399219894

Epoch: 128| Step: 0
Training loss: 3.441311335905591
Validation loss: 3.0287809872507387

Epoch: 5| Step: 1
Training loss: 3.853489020633264
Validation loss: 3.026977411890538

Epoch: 5| Step: 2
Training loss: 3.2168244463185456
Validation loss: 3.0264588094745672

Epoch: 5| Step: 3
Training loss: 3.4642670677256278
Validation loss: 3.0278551911463247

Epoch: 5| Step: 4
Training loss: 3.449691377187147
Validation loss: 3.026183948783361

Epoch: 5| Step: 5
Training loss: 3.0302684020462514
Validation loss: 3.0262717447463996

Epoch: 5| Step: 6
Training loss: 2.4494466234516965
Validation loss: 3.0263815526156734

Epoch: 5| Step: 7
Training loss: 3.281751903113468
Validation loss: 3.0266957129605765

Epoch: 5| Step: 8
Training loss: 3.229686047203501
Validation loss: 3.026964672329471

Epoch: 5| Step: 9
Training loss: 3.26914824472242
Validation loss: 3.025329559145644

Epoch: 5| Step: 10
Training loss: 3.447083171738579
Validation loss: 3.02520140022612

Epoch: 129| Step: 0
Training loss: 3.112513965743878
Validation loss: 3.0258642604289117

Epoch: 5| Step: 1
Training loss: 3.2250547419197253
Validation loss: 3.0264832068593046

Epoch: 5| Step: 2
Training loss: 3.4705396279898957
Validation loss: 3.024813431244483

Epoch: 5| Step: 3
Training loss: 3.329021924007113
Validation loss: 3.024569197728466

Epoch: 5| Step: 4
Training loss: 2.954766841410193
Validation loss: 3.025472414232318

Epoch: 5| Step: 5
Training loss: 3.352673468713794
Validation loss: 3.024065201035435

Epoch: 5| Step: 6
Training loss: 2.9882024218565344
Validation loss: 3.0246245382145007

Epoch: 5| Step: 7
Training loss: 3.7646698432838255
Validation loss: 3.0281675680598483

Epoch: 5| Step: 8
Training loss: 3.1828411687160005
Validation loss: 3.0256897149784487

Epoch: 5| Step: 9
Training loss: 3.2740263853041074
Validation loss: 3.022020857750796

Epoch: 5| Step: 10
Training loss: 3.5857336447621426
Validation loss: 3.025114583362585

Epoch: 130| Step: 0
Training loss: 3.0426067484651487
Validation loss: 3.024321714850615

Epoch: 5| Step: 1
Training loss: 3.4082178153784404
Validation loss: 3.0234895348592308

Epoch: 5| Step: 2
Training loss: 3.072606130308087
Validation loss: 3.0237687126014436

Epoch: 5| Step: 3
Training loss: 3.1592302509960546
Validation loss: 3.0234378417127417

Epoch: 5| Step: 4
Training loss: 2.777816024093118
Validation loss: 3.023931152390695

Epoch: 5| Step: 5
Training loss: 3.506216522981756
Validation loss: 3.0223272994986115

Epoch: 5| Step: 6
Training loss: 3.35446674276194
Validation loss: 3.024828952993247

Epoch: 5| Step: 7
Training loss: 3.703658568495777
Validation loss: 3.0236105746795254

Epoch: 5| Step: 8
Training loss: 3.9039062793144637
Validation loss: 3.020946729410763

Epoch: 5| Step: 9
Training loss: 3.2647311068653537
Validation loss: 3.0206161740628037

Epoch: 5| Step: 10
Training loss: 2.815762386717126
Validation loss: 3.0233506329092563

Epoch: 131| Step: 0
Training loss: 3.6968231016951636
Validation loss: 3.022166074763681

Epoch: 5| Step: 1
Training loss: 3.2754928218068207
Validation loss: 3.021672593853659

Epoch: 5| Step: 2
Training loss: 3.8211364481647556
Validation loss: 3.0209166982404474

Epoch: 5| Step: 3
Training loss: 3.0069217304157885
Validation loss: 3.022386746542402

Epoch: 5| Step: 4
Training loss: 3.0365585563612862
Validation loss: 3.0225403564829216

Epoch: 5| Step: 5
Training loss: 2.6042441903337257
Validation loss: 3.022621939558238

Epoch: 5| Step: 6
Training loss: 3.2922740488575313
Validation loss: 3.0239918734667044

Epoch: 5| Step: 7
Training loss: 3.5550299510954946
Validation loss: 3.0226778559579315

Epoch: 5| Step: 8
Training loss: 3.1510017497579303
Validation loss: 3.021021065202141

Epoch: 5| Step: 9
Training loss: 3.3337363635235904
Validation loss: 3.0217283700179967

Epoch: 5| Step: 10
Training loss: 3.2826275068447606
Validation loss: 3.022615349415689

Epoch: 132| Step: 0
Training loss: 3.255210514322186
Validation loss: 3.0193390352272305

Epoch: 5| Step: 1
Training loss: 2.6430477787913937
Validation loss: 3.0198660286607555

Epoch: 5| Step: 2
Training loss: 3.084074670147421
Validation loss: 3.017616307784666

Epoch: 5| Step: 3
Training loss: 3.5759995990385987
Validation loss: 3.017944351095156

Epoch: 5| Step: 4
Training loss: 3.200271153882749
Validation loss: 3.016988133450674

Epoch: 5| Step: 5
Training loss: 3.4668176440839145
Validation loss: 3.0186017074514004

Epoch: 5| Step: 6
Training loss: 3.155511750855959
Validation loss: 3.0200947646145666

Epoch: 5| Step: 7
Training loss: 3.7032544077220764
Validation loss: 3.0187158877056106

Epoch: 5| Step: 8
Training loss: 3.0729635116541036
Validation loss: 3.0208115036246035

Epoch: 5| Step: 9
Training loss: 3.665710859276929
Validation loss: 3.0175312675111248

Epoch: 5| Step: 10
Training loss: 3.204685482357437
Validation loss: 3.0187202248157616

Epoch: 133| Step: 0
Training loss: 2.977808894126103
Validation loss: 3.0185217593395057

Epoch: 5| Step: 1
Training loss: 3.0909159616914157
Validation loss: 3.0198423231779947

Epoch: 5| Step: 2
Training loss: 2.718105020421134
Validation loss: 3.020313604933421

Epoch: 5| Step: 3
Training loss: 3.103692157158743
Validation loss: 3.020320047314649

Epoch: 5| Step: 4
Training loss: 3.3751521606053214
Validation loss: 3.021436273122325

Epoch: 5| Step: 5
Training loss: 3.116221342723932
Validation loss: 3.016421145428964

Epoch: 5| Step: 6
Training loss: 3.407550528495219
Validation loss: 3.0171041302552104

Epoch: 5| Step: 7
Training loss: 3.2713511516717286
Validation loss: 3.013727960860896

Epoch: 5| Step: 8
Training loss: 3.511559606898726
Validation loss: 3.015576371090896

Epoch: 5| Step: 9
Training loss: 3.428178390045449
Validation loss: 3.016896770251592

Epoch: 5| Step: 10
Training loss: 4.1053934861678645
Validation loss: 3.017672503836272

Epoch: 134| Step: 0
Training loss: 3.5006548405175515
Validation loss: 3.020208974154849

Epoch: 5| Step: 1
Training loss: 2.819389044139591
Validation loss: 3.018601383026097

Epoch: 5| Step: 2
Training loss: 3.827893059379775
Validation loss: 3.0166607280566917

Epoch: 5| Step: 3
Training loss: 2.4236874597201647
Validation loss: 3.0135416924374137

Epoch: 5| Step: 4
Training loss: 2.96979801351689
Validation loss: 3.015453687619175

Epoch: 5| Step: 5
Training loss: 3.8297027450625394
Validation loss: 3.0139806898631196

Epoch: 5| Step: 6
Training loss: 3.614017423949806
Validation loss: 3.0143252209169296

Epoch: 5| Step: 7
Training loss: 3.188197639264498
Validation loss: 3.01440340335672

Epoch: 5| Step: 8
Training loss: 3.5171097396463664
Validation loss: 3.014001199049823

Epoch: 5| Step: 9
Training loss: 2.935829174404427
Validation loss: 3.0135273741559874

Epoch: 5| Step: 10
Training loss: 3.211568134685613
Validation loss: 3.0123817277321936

Epoch: 135| Step: 0
Training loss: 3.1371790262003922
Validation loss: 3.011248672045011

Epoch: 5| Step: 1
Training loss: 3.147187924476423
Validation loss: 3.0131631832229258

Epoch: 5| Step: 2
Training loss: 3.288371178830885
Validation loss: 3.01254062529032

Epoch: 5| Step: 3
Training loss: 3.3826952202533707
Validation loss: 3.012488629379194

Epoch: 5| Step: 4
Training loss: 3.758398188830021
Validation loss: 3.012990026590996

Epoch: 5| Step: 5
Training loss: 3.2977289476946674
Validation loss: 3.0124182930565744

Epoch: 5| Step: 6
Training loss: 2.9193185648672726
Validation loss: 3.0130377102575068

Epoch: 5| Step: 7
Training loss: 3.3580259941326402
Validation loss: 3.0135553700715083

Epoch: 5| Step: 8
Training loss: 3.3150719788160625
Validation loss: 3.0129402932594798

Epoch: 5| Step: 9
Training loss: 3.550530654575052
Validation loss: 3.014072185684027

Epoch: 5| Step: 10
Training loss: 2.8099714144681567
Validation loss: 3.014770230249627

Epoch: 136| Step: 0
Training loss: 3.2958627023525704
Validation loss: 3.015885215353154

Epoch: 5| Step: 1
Training loss: 3.615497894822485
Validation loss: 3.0141043995132195

Epoch: 5| Step: 2
Training loss: 2.6729450425514716
Validation loss: 3.0108533893684886

Epoch: 5| Step: 3
Training loss: 2.9870845617553496
Validation loss: 3.0120496681262647

Epoch: 5| Step: 4
Training loss: 3.4452712560421075
Validation loss: 3.008229547211921

Epoch: 5| Step: 5
Training loss: 3.3612587548677793
Validation loss: 3.0102877522039813

Epoch: 5| Step: 6
Training loss: 3.598749282587741
Validation loss: 3.0101048828658685

Epoch: 5| Step: 7
Training loss: 3.231864655285776
Validation loss: 3.0077028392782568

Epoch: 5| Step: 8
Training loss: 3.0587067759787727
Validation loss: 3.008824130995725

Epoch: 5| Step: 9
Training loss: 3.288262566721617
Validation loss: 3.0105919267288024

Epoch: 5| Step: 10
Training loss: 3.464926184326239
Validation loss: 3.00801653000198

Epoch: 137| Step: 0
Training loss: 2.929523758445039
Validation loss: 3.0082249333482425

Epoch: 5| Step: 1
Training loss: 3.3732197622799838
Validation loss: 3.010007888785788

Epoch: 5| Step: 2
Training loss: 3.5905503334137157
Validation loss: 3.0077866385746055

Epoch: 5| Step: 3
Training loss: 3.343859519234473
Validation loss: 3.0072002365718395

Epoch: 5| Step: 4
Training loss: 2.8325427205162863
Validation loss: 3.007538454068418

Epoch: 5| Step: 5
Training loss: 3.302272049157293
Validation loss: 3.0075611978510297

Epoch: 5| Step: 6
Training loss: 3.3776596327526196
Validation loss: 3.0062737937655744

Epoch: 5| Step: 7
Training loss: 2.8909441797494546
Validation loss: 3.006485958960323

Epoch: 5| Step: 8
Training loss: 3.465958030116395
Validation loss: 3.004035114309821

Epoch: 5| Step: 9
Training loss: 3.160010033845061
Validation loss: 3.007991710108254

Epoch: 5| Step: 10
Training loss: 3.7897389860030266
Validation loss: 3.005386055251126

Epoch: 138| Step: 0
Training loss: 3.5055995834280695
Validation loss: 3.012121849748043

Epoch: 5| Step: 1
Training loss: 2.868515829531017
Validation loss: 3.0089586916274857

Epoch: 5| Step: 2
Training loss: 3.0217695342065527
Validation loss: 3.0194999855474483

Epoch: 5| Step: 3
Training loss: 3.1119040167551875
Validation loss: 3.010065296603957

Epoch: 5| Step: 4
Training loss: 2.8555883129465824
Validation loss: 3.0153853707879974

Epoch: 5| Step: 5
Training loss: 2.8180698766877694
Validation loss: 3.0080944264223692

Epoch: 5| Step: 6
Training loss: 3.932590875757832
Validation loss: 3.004490549086172

Epoch: 5| Step: 7
Training loss: 2.8838183294633235
Validation loss: 3.0051091477193284

Epoch: 5| Step: 8
Training loss: 3.8591409836218378
Validation loss: 3.004696519615981

Epoch: 5| Step: 9
Training loss: 3.9230786182578266
Validation loss: 3.0040321999507396

Epoch: 5| Step: 10
Training loss: 2.95929859872422
Validation loss: 3.0053060993465923

Epoch: 139| Step: 0
Training loss: 3.032071660948815
Validation loss: 3.0054967276985063

Epoch: 5| Step: 1
Training loss: 3.0526228461512774
Validation loss: 3.0048931391100107

Epoch: 5| Step: 2
Training loss: 3.05662299690404
Validation loss: 3.0040109689941916

Epoch: 5| Step: 3
Training loss: 3.346804213287302
Validation loss: 3.0069323961697876

Epoch: 5| Step: 4
Training loss: 3.5711453924991177
Validation loss: 3.005315243901221

Epoch: 5| Step: 5
Training loss: 3.4285959231546173
Validation loss: 3.0046838203940776

Epoch: 5| Step: 6
Training loss: 3.941709417927199
Validation loss: 3.004448987740012

Epoch: 5| Step: 7
Training loss: 2.988789274626935
Validation loss: 3.001381726799024

Epoch: 5| Step: 8
Training loss: 3.4725825127066674
Validation loss: 3.0023407059511786

Epoch: 5| Step: 9
Training loss: 3.1413901236840496
Validation loss: 2.999336374367202

Epoch: 5| Step: 10
Training loss: 2.8027859247763662
Validation loss: 3.0028697622132388

Epoch: 140| Step: 0
Training loss: 3.094399740404909
Validation loss: 3.0108032563096914

Epoch: 5| Step: 1
Training loss: 3.6960288516813473
Validation loss: 3.012463962068926

Epoch: 5| Step: 2
Training loss: 2.7681426749200226
Validation loss: 3.0275758889410405

Epoch: 5| Step: 3
Training loss: 3.224679466701127
Validation loss: 3.0372080594554016

Epoch: 5| Step: 4
Training loss: 3.5004080125861954
Validation loss: 3.029005582440089

Epoch: 5| Step: 5
Training loss: 3.209241878790764
Validation loss: 3.0101129857211264

Epoch: 5| Step: 6
Training loss: 3.6455101669226257
Validation loss: 3.004129925445241

Epoch: 5| Step: 7
Training loss: 3.8026899855363747
Validation loss: 3.0024572088745245

Epoch: 5| Step: 8
Training loss: 2.7736391665787017
Validation loss: 3.0027503033448038

Epoch: 5| Step: 9
Training loss: 3.1415088226034187
Validation loss: 3.0067239117609894

Epoch: 5| Step: 10
Training loss: 3.0986228098739437
Validation loss: 3.0094557796017605

Epoch: 141| Step: 0
Training loss: 3.2205069478135777
Validation loss: 3.010198533644594

Epoch: 5| Step: 1
Training loss: 3.5966628501761067
Validation loss: 3.0063852598304357

Epoch: 5| Step: 2
Training loss: 3.1402165541111757
Validation loss: 3.005668700560494

Epoch: 5| Step: 3
Training loss: 3.414806852226447
Validation loss: 2.999685882886224

Epoch: 5| Step: 4
Training loss: 3.2842164209122466
Validation loss: 2.9997603036976113

Epoch: 5| Step: 5
Training loss: 2.567751365027642
Validation loss: 3.001262722069138

Epoch: 5| Step: 6
Training loss: 2.8773788893307244
Validation loss: 3.000751507197963

Epoch: 5| Step: 7
Training loss: 3.412336179273434
Validation loss: 2.99814980376205

Epoch: 5| Step: 8
Training loss: 3.514740964154397
Validation loss: 2.998904700792117

Epoch: 5| Step: 9
Training loss: 3.617703164175031
Validation loss: 2.998744431820887

Epoch: 5| Step: 10
Training loss: 3.2912852553215397
Validation loss: 2.9981777577184663

Epoch: 142| Step: 0
Training loss: 4.147494393885838
Validation loss: 3.000292986745

Epoch: 5| Step: 1
Training loss: 3.6098180721862185
Validation loss: 2.999489062220932

Epoch: 5| Step: 2
Training loss: 3.047539741188143
Validation loss: 2.999508785038913

Epoch: 5| Step: 3
Training loss: 2.7821089886090933
Validation loss: 2.997413956288983

Epoch: 5| Step: 4
Training loss: 2.4803056317859484
Validation loss: 2.998411829809894

Epoch: 5| Step: 5
Training loss: 3.415571424896475
Validation loss: 2.9972804674093223

Epoch: 5| Step: 6
Training loss: 3.790987575767241
Validation loss: 2.999158542989737

Epoch: 5| Step: 7
Training loss: 2.776539016650086
Validation loss: 2.9960975919155186

Epoch: 5| Step: 8
Training loss: 2.7350703635919182
Validation loss: 2.9984380114904825

Epoch: 5| Step: 9
Training loss: 3.2409109520994983
Validation loss: 2.994910818389616

Epoch: 5| Step: 10
Training loss: 3.6326565616733384
Validation loss: 2.99801361128595

Epoch: 143| Step: 0
Training loss: 3.037051754125828
Validation loss: 2.998846309080517

Epoch: 5| Step: 1
Training loss: 3.349118210618474
Validation loss: 2.9998361925639956

Epoch: 5| Step: 2
Training loss: 3.213331235222771
Validation loss: 2.9972445299747505

Epoch: 5| Step: 3
Training loss: 4.098516819339431
Validation loss: 2.9967951747359782

Epoch: 5| Step: 4
Training loss: 3.3672969649858375
Validation loss: 2.995172206818501

Epoch: 5| Step: 5
Training loss: 2.9672745099801814
Validation loss: 2.998348458286774

Epoch: 5| Step: 6
Training loss: 2.758457184130674
Validation loss: 2.9955313516593467

Epoch: 5| Step: 7
Training loss: 3.6332563887915117
Validation loss: 2.9957788211004113

Epoch: 5| Step: 8
Training loss: 3.4184469531547808
Validation loss: 2.9946127703906953

Epoch: 5| Step: 9
Training loss: 2.983175306201722
Validation loss: 2.995700043908997

Epoch: 5| Step: 10
Training loss: 2.8595982865666056
Validation loss: 3.000219609655161

Epoch: 144| Step: 0
Training loss: 3.099238603671126
Validation loss: 3.0020295297390565

Epoch: 5| Step: 1
Training loss: 3.703358574434153
Validation loss: 3.007843838206037

Epoch: 5| Step: 2
Training loss: 3.5084018679438915
Validation loss: 3.001579501228637

Epoch: 5| Step: 3
Training loss: 3.777020193008122
Validation loss: 2.997558954234851

Epoch: 5| Step: 4
Training loss: 3.092570070229974
Validation loss: 2.996735627232761

Epoch: 5| Step: 5
Training loss: 3.2807718564385153
Validation loss: 2.9947598471785812

Epoch: 5| Step: 6
Training loss: 2.853726169722283
Validation loss: 2.994238747822827

Epoch: 5| Step: 7
Training loss: 3.3825483329122297
Validation loss: 2.9920832060148754

Epoch: 5| Step: 8
Training loss: 3.423116380403123
Validation loss: 2.9958048110004185

Epoch: 5| Step: 9
Training loss: 3.0119850446676786
Validation loss: 2.992049909416416

Epoch: 5| Step: 10
Training loss: 2.5777949266393114
Validation loss: 2.993040552862962

Epoch: 145| Step: 0
Training loss: 3.8357071506305
Validation loss: 2.995224811463227

Epoch: 5| Step: 1
Training loss: 3.568867263604385
Validation loss: 2.9953452662859887

Epoch: 5| Step: 2
Training loss: 2.937500811637604
Validation loss: 2.990085701232277

Epoch: 5| Step: 3
Training loss: 3.0030086054162584
Validation loss: 2.9937519019445804

Epoch: 5| Step: 4
Training loss: 3.5477033143658865
Validation loss: 2.9937368698837514

Epoch: 5| Step: 5
Training loss: 3.279356928099996
Validation loss: 2.987858744808819

Epoch: 5| Step: 6
Training loss: 2.932714907161037
Validation loss: 2.99556131382607

Epoch: 5| Step: 7
Training loss: 3.3420802430450633
Validation loss: 2.9918380272332272

Epoch: 5| Step: 8
Training loss: 3.2200818315616027
Validation loss: 2.9952034872641526

Epoch: 5| Step: 9
Training loss: 3.2445301095403427
Validation loss: 2.9965943896616998

Epoch: 5| Step: 10
Training loss: 2.796148791947851
Validation loss: 2.9891380540701302

Epoch: 146| Step: 0
Training loss: 3.2701583133370025
Validation loss: 2.9943776051041504

Epoch: 5| Step: 1
Training loss: 3.574247032845749
Validation loss: 3.0030470332053136

Epoch: 5| Step: 2
Training loss: 2.6812776790870814
Validation loss: 2.9968285340975527

Epoch: 5| Step: 3
Training loss: 3.4170362846361493
Validation loss: 2.994412883471703

Epoch: 5| Step: 4
Training loss: 4.041303533122224
Validation loss: 2.9981169413691338

Epoch: 5| Step: 5
Training loss: 3.4130459806316353
Validation loss: 2.9891822528461636

Epoch: 5| Step: 6
Training loss: 3.1923792276861183
Validation loss: 2.9921916193861318

Epoch: 5| Step: 7
Training loss: 3.0262061559691027
Validation loss: 2.9913959534137926

Epoch: 5| Step: 8
Training loss: 2.5323435928835196
Validation loss: 2.995134867744664

Epoch: 5| Step: 9
Training loss: 2.8925365828802896
Validation loss: 2.9890520303231063

Epoch: 5| Step: 10
Training loss: 3.6450519414688536
Validation loss: 2.9862156097933577

Epoch: 147| Step: 0
Training loss: 3.2766083357137674
Validation loss: 2.9871402388107464

Epoch: 5| Step: 1
Training loss: 3.8206383813829317
Validation loss: 2.985967569286777

Epoch: 5| Step: 2
Training loss: 3.406147666583865
Validation loss: 2.9849297849085583

Epoch: 5| Step: 3
Training loss: 2.88464627958528
Validation loss: 2.9846118106530164

Epoch: 5| Step: 4
Training loss: 3.2847095961503934
Validation loss: 2.9852298611118755

Epoch: 5| Step: 5
Training loss: 2.9472293838891748
Validation loss: 2.985559129903479

Epoch: 5| Step: 6
Training loss: 3.012334105169849
Validation loss: 2.986194207524257

Epoch: 5| Step: 7
Training loss: 3.9020507213711766
Validation loss: 2.985947492587092

Epoch: 5| Step: 8
Training loss: 3.0801737981534507
Validation loss: 2.9857945638734553

Epoch: 5| Step: 9
Training loss: 2.980737676524461
Validation loss: 2.9850262678261705

Epoch: 5| Step: 10
Training loss: 3.053221992506025
Validation loss: 2.98764019242153

Epoch: 148| Step: 0
Training loss: 3.045340596710914
Validation loss: 2.9868082801058278

Epoch: 5| Step: 1
Training loss: 3.5321478588394486
Validation loss: 2.985075392699645

Epoch: 5| Step: 2
Training loss: 3.1972627913567924
Validation loss: 2.985154509528903

Epoch: 5| Step: 3
Training loss: 2.849638491005297
Validation loss: 2.9905374799520263

Epoch: 5| Step: 4
Training loss: 3.4211785988261294
Validation loss: 2.990344355685848

Epoch: 5| Step: 5
Training loss: 2.8317751433228784
Validation loss: 2.9906520887583405

Epoch: 5| Step: 6
Training loss: 3.5090353009026507
Validation loss: 2.986338293431049

Epoch: 5| Step: 7
Training loss: 3.224974012639815
Validation loss: 2.9839283444055056

Epoch: 5| Step: 8
Training loss: 3.4716739187715784
Validation loss: 2.9837479579317505

Epoch: 5| Step: 9
Training loss: 3.09129868311326
Validation loss: 2.9826694892378973

Epoch: 5| Step: 10
Training loss: 3.642946739056655
Validation loss: 2.983213982595385

Epoch: 149| Step: 0
Training loss: 3.4395155113060105
Validation loss: 2.982691027674846

Epoch: 5| Step: 1
Training loss: 2.6149399857353903
Validation loss: 2.982718210285629

Epoch: 5| Step: 2
Training loss: 3.4100088675375275
Validation loss: 2.982567206398993

Epoch: 5| Step: 3
Training loss: 2.970015727813897
Validation loss: 2.982959533837813

Epoch: 5| Step: 4
Training loss: 3.1647529508042207
Validation loss: 2.9833053676123775

Epoch: 5| Step: 5
Training loss: 2.4214208361650416
Validation loss: 2.9832241676565716

Epoch: 5| Step: 6
Training loss: 4.16668813064133
Validation loss: 2.9839699991205886

Epoch: 5| Step: 7
Training loss: 3.315748241553811
Validation loss: 2.9827434484810706

Epoch: 5| Step: 8
Training loss: 2.950134700997282
Validation loss: 2.982913600465004

Epoch: 5| Step: 9
Training loss: 3.287684498530454
Validation loss: 2.9792570983450357

Epoch: 5| Step: 10
Training loss: 3.836793015556882
Validation loss: 2.983381529823357

Epoch: 150| Step: 0
Training loss: 3.4152419368446822
Validation loss: 2.979767854387016

Epoch: 5| Step: 1
Training loss: 3.0538522500382164
Validation loss: 2.979977689589189

Epoch: 5| Step: 2
Training loss: 2.0560052511541493
Validation loss: 2.9804682562757003

Epoch: 5| Step: 3
Training loss: 3.67457435893742
Validation loss: 2.9810369277374567

Epoch: 5| Step: 4
Training loss: 3.1783000346457997
Validation loss: 2.9832472257091447

Epoch: 5| Step: 5
Training loss: 3.4131162541124955
Validation loss: 2.985790945678046

Epoch: 5| Step: 6
Training loss: 3.0777466827119375
Validation loss: 2.9854591658282876

Epoch: 5| Step: 7
Training loss: 3.345274533123602
Validation loss: 2.983569098615059

Epoch: 5| Step: 8
Training loss: 3.9998958097239807
Validation loss: 2.981346844287118

Epoch: 5| Step: 9
Training loss: 3.1669417479312814
Validation loss: 2.9838934799138865

Epoch: 5| Step: 10
Training loss: 3.0585371574924847
Validation loss: 2.9840165348015497

Epoch: 151| Step: 0
Training loss: 2.510481130529442
Validation loss: 2.9808575711983867

Epoch: 5| Step: 1
Training loss: 2.7385582015180554
Validation loss: 2.985772369515584

Epoch: 5| Step: 2
Training loss: 3.1135057777607247
Validation loss: 2.982024532705376

Epoch: 5| Step: 3
Training loss: 3.570729037304444
Validation loss: 2.9780527366220317

Epoch: 5| Step: 4
Training loss: 3.0280171882010536
Validation loss: 2.9766191696720825

Epoch: 5| Step: 5
Training loss: 3.224340971803946
Validation loss: 2.9780053364190984

Epoch: 5| Step: 6
Training loss: 3.429329612324517
Validation loss: 2.9778448870469902

Epoch: 5| Step: 7
Training loss: 3.6180708859038133
Validation loss: 2.9790254767828785

Epoch: 5| Step: 8
Training loss: 3.169874490605874
Validation loss: 2.9772810168474435

Epoch: 5| Step: 9
Training loss: 3.3467157349149255
Validation loss: 2.9779642835251363

Epoch: 5| Step: 10
Training loss: 3.926094854933656
Validation loss: 2.97846730602388

Epoch: 152| Step: 0
Training loss: 2.509224182385273
Validation loss: 2.9762236083804336

Epoch: 5| Step: 1
Training loss: 3.637541418724605
Validation loss: 2.975491174921431

Epoch: 5| Step: 2
Training loss: 2.9388350030116963
Validation loss: 2.9763416056196177

Epoch: 5| Step: 3
Training loss: 3.5275559810357113
Validation loss: 2.978195268417721

Epoch: 5| Step: 4
Training loss: 3.4737198427036775
Validation loss: 2.979174022692729

Epoch: 5| Step: 5
Training loss: 3.5775288580817506
Validation loss: 2.975662410151382

Epoch: 5| Step: 6
Training loss: 2.897163872168308
Validation loss: 2.978004312858394

Epoch: 5| Step: 7
Training loss: 3.2469512137462493
Validation loss: 2.980022016486471

Epoch: 5| Step: 8
Training loss: 3.294833161177901
Validation loss: 2.9804153206429356

Epoch: 5| Step: 9
Training loss: 3.113569947453885
Validation loss: 2.980764888129316

Epoch: 5| Step: 10
Training loss: 3.400832180953693
Validation loss: 2.9812663829708725

Epoch: 153| Step: 0
Training loss: 3.024417846401411
Validation loss: 2.977391568143131

Epoch: 5| Step: 1
Training loss: 3.1313229489537693
Validation loss: 2.973595661614425

Epoch: 5| Step: 2
Training loss: 3.1520247173889295
Validation loss: 2.9736900035413267

Epoch: 5| Step: 3
Training loss: 2.983941331281544
Validation loss: 2.9740237566509005

Epoch: 5| Step: 4
Training loss: 3.506716414655936
Validation loss: 2.978437180504008

Epoch: 5| Step: 5
Training loss: 3.2689352825453315
Validation loss: 2.974225830118657

Epoch: 5| Step: 6
Training loss: 3.4840484602981707
Validation loss: 2.974642608269266

Epoch: 5| Step: 7
Training loss: 3.207847872249646
Validation loss: 2.974703021180568

Epoch: 5| Step: 8
Training loss: 3.4605051291540323
Validation loss: 2.975672247154495

Epoch: 5| Step: 9
Training loss: 3.297462447200611
Validation loss: 2.971760680981816

Epoch: 5| Step: 10
Training loss: 3.1896779716366574
Validation loss: 2.974147416427187

Epoch: 154| Step: 0
Training loss: 3.3779634251802473
Validation loss: 2.975851590576518

Epoch: 5| Step: 1
Training loss: 3.724052431567193
Validation loss: 2.9764852804737028

Epoch: 5| Step: 2
Training loss: 2.900312203011766
Validation loss: 2.9810701934084847

Epoch: 5| Step: 3
Training loss: 3.5068162212704594
Validation loss: 2.9835942419697803

Epoch: 5| Step: 4
Training loss: 2.965947002459573
Validation loss: 2.9782640303217223

Epoch: 5| Step: 5
Training loss: 3.534417141529063
Validation loss: 2.9741333644780004

Epoch: 5| Step: 6
Training loss: 3.0286574140717075
Validation loss: 2.9783623508371324

Epoch: 5| Step: 7
Training loss: 3.1553059289664915
Validation loss: 2.975152797192725

Epoch: 5| Step: 8
Training loss: 2.810737566281119
Validation loss: 2.9859149844287898

Epoch: 5| Step: 9
Training loss: 3.5465789536933015
Validation loss: 2.979437148808438

Epoch: 5| Step: 10
Training loss: 3.0014922880969346
Validation loss: 2.9728711739805114

Epoch: 155| Step: 0
Training loss: 3.27533268294382
Validation loss: 2.980036907822266

Epoch: 5| Step: 1
Training loss: 3.2943850692221703
Validation loss: 2.974210938132414

Epoch: 5| Step: 2
Training loss: 2.9824343458113534
Validation loss: 2.972449485818561

Epoch: 5| Step: 3
Training loss: 3.517859261825399
Validation loss: 2.9735642495629753

Epoch: 5| Step: 4
Training loss: 2.793308818894689
Validation loss: 2.9753993663796137

Epoch: 5| Step: 5
Training loss: 3.476952691630478
Validation loss: 2.971038659824287

Epoch: 5| Step: 6
Training loss: 3.002429931737811
Validation loss: 2.9728916934093155

Epoch: 5| Step: 7
Training loss: 3.592950615916947
Validation loss: 2.969872166407943

Epoch: 5| Step: 8
Training loss: 3.4045812036133123
Validation loss: 2.9700476245149203

Epoch: 5| Step: 9
Training loss: 3.3551701689314943
Validation loss: 2.9696527884060666

Epoch: 5| Step: 10
Training loss: 2.837988077946489
Validation loss: 2.968842675619671

Epoch: 156| Step: 0
Training loss: 3.0968575331794885
Validation loss: 2.9694471808951013

Epoch: 5| Step: 1
Training loss: 3.7330386272550307
Validation loss: 2.969954112944762

Epoch: 5| Step: 2
Training loss: 2.3643605691669562
Validation loss: 2.968981107687418

Epoch: 5| Step: 3
Training loss: 3.5734942593088737
Validation loss: 2.970020365644684

Epoch: 5| Step: 4
Training loss: 3.3340112632556633
Validation loss: 2.969086033575029

Epoch: 5| Step: 5
Training loss: 3.242102049655195
Validation loss: 2.970313466520143

Epoch: 5| Step: 6
Training loss: 2.6620654902265968
Validation loss: 2.9692169305838103

Epoch: 5| Step: 7
Training loss: 3.394622977085257
Validation loss: 2.9674389451212697

Epoch: 5| Step: 8
Training loss: 3.8518259449709773
Validation loss: 2.9656993673248953

Epoch: 5| Step: 9
Training loss: 3.4657626648400237
Validation loss: 2.9683076452318637

Epoch: 5| Step: 10
Training loss: 2.5875875043585292
Validation loss: 2.9676186081526383

Epoch: 157| Step: 0
Training loss: 3.670265007117762
Validation loss: 2.9666704529252685

Epoch: 5| Step: 1
Training loss: 3.5163284615212214
Validation loss: 2.9688659818021543

Epoch: 5| Step: 2
Training loss: 3.2386534767976394
Validation loss: 2.97190591954278

Epoch: 5| Step: 3
Training loss: 2.9852213832734953
Validation loss: 2.975805179630024

Epoch: 5| Step: 4
Training loss: 3.099426610278101
Validation loss: 2.97743341160432

Epoch: 5| Step: 5
Training loss: 2.7748357981996365
Validation loss: 2.972274762047269

Epoch: 5| Step: 6
Training loss: 3.0702718096262016
Validation loss: 2.969222542719526

Epoch: 5| Step: 7
Training loss: 3.18630360608747
Validation loss: 2.9700063675392703

Epoch: 5| Step: 8
Training loss: 3.554499560407761
Validation loss: 2.970483874820522

Epoch: 5| Step: 9
Training loss: 3.5724579689964977
Validation loss: 2.96660348765715

Epoch: 5| Step: 10
Training loss: 2.795154660471984
Validation loss: 2.966958858479738

Epoch: 158| Step: 0
Training loss: 3.2544457765681196
Validation loss: 2.964312582335649

Epoch: 5| Step: 1
Training loss: 3.1303910103216244
Validation loss: 2.9673417564405775

Epoch: 5| Step: 2
Training loss: 3.2697746523515416
Validation loss: 2.9626408999115896

Epoch: 5| Step: 3
Training loss: 2.958116299543677
Validation loss: 2.9646524420588776

Epoch: 5| Step: 4
Training loss: 3.2530324433541464
Validation loss: 2.961614341952488

Epoch: 5| Step: 5
Training loss: 3.4773666994721246
Validation loss: 2.9610147648208165

Epoch: 5| Step: 6
Training loss: 3.0796885900239066
Validation loss: 2.962825247731397

Epoch: 5| Step: 7
Training loss: 3.6287636785351234
Validation loss: 2.9657852852736886

Epoch: 5| Step: 8
Training loss: 3.1948889565908685
Validation loss: 2.961524478564269

Epoch: 5| Step: 9
Training loss: 3.093726726405909
Validation loss: 2.9641477134308727

Epoch: 5| Step: 10
Training loss: 3.2799255604554363
Validation loss: 2.9632513672289553

Epoch: 159| Step: 0
Training loss: 3.043544416123254
Validation loss: 2.962092071758449

Epoch: 5| Step: 1
Training loss: 3.0130765750952455
Validation loss: 2.963637241541172

Epoch: 5| Step: 2
Training loss: 3.39657253964785
Validation loss: 2.9661825601053007

Epoch: 5| Step: 3
Training loss: 3.495435053825938
Validation loss: 2.970854511009177

Epoch: 5| Step: 4
Training loss: 3.7557109579278745
Validation loss: 2.96499351741332

Epoch: 5| Step: 5
Training loss: 3.0931278720672033
Validation loss: 2.96235860519437

Epoch: 5| Step: 6
Training loss: 3.479415717129096
Validation loss: 2.9633580531984403

Epoch: 5| Step: 7
Training loss: 2.734611631781077
Validation loss: 2.959830732885313

Epoch: 5| Step: 8
Training loss: 3.186221894970477
Validation loss: 2.963005374807291

Epoch: 5| Step: 9
Training loss: 2.805765438937072
Validation loss: 2.9612994636086967

Epoch: 5| Step: 10
Training loss: 3.5544163862528535
Validation loss: 2.959483835607127

Epoch: 160| Step: 0
Training loss: 2.773495783663554
Validation loss: 2.961655302070302

Epoch: 5| Step: 1
Training loss: 3.1805351308493504
Validation loss: 2.9601991296506927

Epoch: 5| Step: 2
Training loss: 3.1158949387826365
Validation loss: 2.9602309615189006

Epoch: 5| Step: 3
Training loss: 3.108435867568389
Validation loss: 2.9613018070976076

Epoch: 5| Step: 4
Training loss: 3.465013020368501
Validation loss: 2.9619741412797844

Epoch: 5| Step: 5
Training loss: 2.92214948211504
Validation loss: 2.9606659818005014

Epoch: 5| Step: 6
Training loss: 3.2623516999078443
Validation loss: 2.961079515413014

Epoch: 5| Step: 7
Training loss: 3.9634372264654734
Validation loss: 2.9565932393145307

Epoch: 5| Step: 8
Training loss: 3.5424319768067156
Validation loss: 2.959348048452673

Epoch: 5| Step: 9
Training loss: 3.272678915543155
Validation loss: 2.9588652064340955

Epoch: 5| Step: 10
Training loss: 2.743981972448892
Validation loss: 2.960440534423426

Epoch: 161| Step: 0
Training loss: 3.3176314715829713
Validation loss: 2.9639136859101898

Epoch: 5| Step: 1
Training loss: 3.073906966301288
Validation loss: 2.9576711495612455

Epoch: 5| Step: 2
Training loss: 3.6088448007074594
Validation loss: 2.9599677572126706

Epoch: 5| Step: 3
Training loss: 3.316287484530512
Validation loss: 2.9568221776270525

Epoch: 5| Step: 4
Training loss: 2.8198056597738828
Validation loss: 2.9562669759221025

Epoch: 5| Step: 5
Training loss: 2.993387245706574
Validation loss: 2.9562206260694146

Epoch: 5| Step: 6
Training loss: 3.195620197879698
Validation loss: 2.9576216249892817

Epoch: 5| Step: 7
Training loss: 3.8825504206854853
Validation loss: 2.9577381021080007

Epoch: 5| Step: 8
Training loss: 2.7512576088633303
Validation loss: 2.9574681625460415

Epoch: 5| Step: 9
Training loss: 3.482159239342688
Validation loss: 2.956468510590506

Epoch: 5| Step: 10
Training loss: 2.991447656065453
Validation loss: 2.958845676239157

Epoch: 162| Step: 0
Training loss: 3.5754701852047495
Validation loss: 2.95457227967087

Epoch: 5| Step: 1
Training loss: 3.039354481926891
Validation loss: 2.9563446038803445

Epoch: 5| Step: 2
Training loss: 3.1991726938362977
Validation loss: 2.9543192620480734

Epoch: 5| Step: 3
Training loss: 2.407394038133369
Validation loss: 2.956073194573004

Epoch: 5| Step: 4
Training loss: 3.2650372281953333
Validation loss: 2.9557567076732347

Epoch: 5| Step: 5
Training loss: 3.3942642019075464
Validation loss: 2.9555481714028993

Epoch: 5| Step: 6
Training loss: 3.5069647021490167
Validation loss: 2.9560929373467233

Epoch: 5| Step: 7
Training loss: 3.644189358586871
Validation loss: 2.9531818069087468

Epoch: 5| Step: 8
Training loss: 2.82789416978179
Validation loss: 2.960931962206366

Epoch: 5| Step: 9
Training loss: 3.590973154424965
Validation loss: 2.9586578623272497

Epoch: 5| Step: 10
Training loss: 2.8365992254838583
Validation loss: 2.956990295188099

Epoch: 163| Step: 0
Training loss: 3.1190641867982114
Validation loss: 2.9571917025392382

Epoch: 5| Step: 1
Training loss: 3.5918657753638263
Validation loss: 2.9564163106767105

Epoch: 5| Step: 2
Training loss: 3.4734495477643343
Validation loss: 2.9549621763588862

Epoch: 5| Step: 3
Training loss: 3.3606647233564524
Validation loss: 2.9564448118502242

Epoch: 5| Step: 4
Training loss: 3.159162933446687
Validation loss: 2.9530005970569775

Epoch: 5| Step: 5
Training loss: 2.962366408543068
Validation loss: 2.957071173438186

Epoch: 5| Step: 6
Training loss: 2.652735460708344
Validation loss: 2.9563354674084197

Epoch: 5| Step: 7
Training loss: 3.2537054799068073
Validation loss: 2.9595325762618576

Epoch: 5| Step: 8
Training loss: 2.7070582004543184
Validation loss: 2.9525147555357134

Epoch: 5| Step: 9
Training loss: 3.5366162062151267
Validation loss: 2.9525097350755347

Epoch: 5| Step: 10
Training loss: 3.621160117717046
Validation loss: 2.9513673801269737

Epoch: 164| Step: 0
Training loss: 4.097905270525561
Validation loss: 2.9506861268210076

Epoch: 5| Step: 1
Training loss: 3.2582991348644312
Validation loss: 2.950327860955031

Epoch: 5| Step: 2
Training loss: 3.230455760629871
Validation loss: 2.9500150558841103

Epoch: 5| Step: 3
Training loss: 3.2743925099014817
Validation loss: 2.946348126012913

Epoch: 5| Step: 4
Training loss: 2.6430749306364243
Validation loss: 2.955798580729161

Epoch: 5| Step: 5
Training loss: 2.8778438600622427
Validation loss: 2.956296585056941

Epoch: 5| Step: 6
Training loss: 3.7341989132533735
Validation loss: 2.9491288809586877

Epoch: 5| Step: 7
Training loss: 3.353809234971858
Validation loss: 2.953495587272155

Epoch: 5| Step: 8
Training loss: 2.9921878187214257
Validation loss: 2.9534231550733043

Epoch: 5| Step: 9
Training loss: 2.6358095763256775
Validation loss: 2.9504098255060263

Epoch: 5| Step: 10
Training loss: 3.1036726453945667
Validation loss: 2.944965477781176

Epoch: 165| Step: 0
Training loss: 2.926702580966594
Validation loss: 2.9488831283814925

Epoch: 5| Step: 1
Training loss: 3.0195620437769217
Validation loss: 2.9438630540893733

Epoch: 5| Step: 2
Training loss: 3.1351936404643346
Validation loss: 2.9461178360094804

Epoch: 5| Step: 3
Training loss: 3.249972416687335
Validation loss: 2.942066380403704

Epoch: 5| Step: 4
Training loss: 2.879307381208786
Validation loss: 2.9442179009628933

Epoch: 5| Step: 5
Training loss: 3.2125121476355627
Validation loss: 2.9441737725315758

Epoch: 5| Step: 6
Training loss: 3.5733125131864036
Validation loss: 2.9418469802498537

Epoch: 5| Step: 7
Training loss: 2.8327497741521372
Validation loss: 2.9436497108820143

Epoch: 5| Step: 8
Training loss: 4.056897099725206
Validation loss: 2.941747402698517

Epoch: 5| Step: 9
Training loss: 2.87816064669624
Validation loss: 2.944361072832226

Epoch: 5| Step: 10
Training loss: 3.5396279394891503
Validation loss: 2.9411454883122277

Epoch: 166| Step: 0
Training loss: 3.16535587955577
Validation loss: 2.9415333648260997

Epoch: 5| Step: 1
Training loss: 2.655178706733534
Validation loss: 2.9477563200816483

Epoch: 5| Step: 2
Training loss: 3.9343559185895502
Validation loss: 2.9483820354655808

Epoch: 5| Step: 3
Training loss: 3.0827058892587225
Validation loss: 2.9530122449715104

Epoch: 5| Step: 4
Training loss: 3.080576893172929
Validation loss: 2.9509355378704356

Epoch: 5| Step: 5
Training loss: 2.493086314978261
Validation loss: 2.9509809386686827

Epoch: 5| Step: 6
Training loss: 3.2792967295916435
Validation loss: 2.9542260466459607

Epoch: 5| Step: 7
Training loss: 3.5056512712435173
Validation loss: 2.9434347356931636

Epoch: 5| Step: 8
Training loss: 3.2266378694095215
Validation loss: 2.9451004560845644

Epoch: 5| Step: 9
Training loss: 3.5978068134889485
Validation loss: 2.93826092089663

Epoch: 5| Step: 10
Training loss: 3.1589363676583533
Validation loss: 2.9397700607569033

Epoch: 167| Step: 0
Training loss: 3.1615806359018537
Validation loss: 2.938480026079548

Epoch: 5| Step: 1
Training loss: 3.6627185691217603
Validation loss: 2.938789564616683

Epoch: 5| Step: 2
Training loss: 3.515935587409071
Validation loss: 2.9384375206093694

Epoch: 5| Step: 3
Training loss: 2.972901984545874
Validation loss: 2.9365343100579917

Epoch: 5| Step: 4
Training loss: 2.9312344548640805
Validation loss: 2.939776336928705

Epoch: 5| Step: 5
Training loss: 2.6298552524781313
Validation loss: 2.939791896928365

Epoch: 5| Step: 6
Training loss: 3.504442256896436
Validation loss: 2.9354499570178225

Epoch: 5| Step: 7
Training loss: 2.984115030040264
Validation loss: 2.936290817622779

Epoch: 5| Step: 8
Training loss: 3.6192489253729807
Validation loss: 2.937052798959686

Epoch: 5| Step: 9
Training loss: 2.9357825595154985
Validation loss: 2.9400456415790823

Epoch: 5| Step: 10
Training loss: 3.3775433035106808
Validation loss: 2.9395375966343837

Epoch: 168| Step: 0
Training loss: 2.825986443521498
Validation loss: 2.9377965679235603

Epoch: 5| Step: 1
Training loss: 3.7197213066466546
Validation loss: 2.942106550478474

Epoch: 5| Step: 2
Training loss: 3.018999020748479
Validation loss: 2.9400938543189734

Epoch: 5| Step: 3
Training loss: 2.6845827459697524
Validation loss: 2.938818812480002

Epoch: 5| Step: 4
Training loss: 3.7336550222039935
Validation loss: 2.940037010776929

Epoch: 5| Step: 5
Training loss: 3.432538978260884
Validation loss: 2.9414223975279663

Epoch: 5| Step: 6
Training loss: 2.6637974045042636
Validation loss: 2.9452519385966385

Epoch: 5| Step: 7
Training loss: 2.9423982079853617
Validation loss: 2.9452372848426087

Epoch: 5| Step: 8
Training loss: 3.4748279830840443
Validation loss: 2.9409699778241087

Epoch: 5| Step: 9
Training loss: 3.262193547029552
Validation loss: 2.936730014456306

Epoch: 5| Step: 10
Training loss: 3.427078262526327
Validation loss: 2.935782246022582

Epoch: 169| Step: 0
Training loss: 2.4100970936444566
Validation loss: 2.9345070439585146

Epoch: 5| Step: 1
Training loss: 3.6364254285157234
Validation loss: 2.9327445407876316

Epoch: 5| Step: 2
Training loss: 2.909126908718957
Validation loss: 2.9339549994640652

Epoch: 5| Step: 3
Training loss: 3.385295423635232
Validation loss: 2.932636284813897

Epoch: 5| Step: 4
Training loss: 2.483960099033414
Validation loss: 2.932108693042391

Epoch: 5| Step: 5
Training loss: 3.725866096731922
Validation loss: 2.9345047306149183

Epoch: 5| Step: 6
Training loss: 3.4517522646612746
Validation loss: 2.934949984203187

Epoch: 5| Step: 7
Training loss: 3.197860783555691
Validation loss: 2.936837330404745

Epoch: 5| Step: 8
Training loss: 3.3460320501987173
Validation loss: 2.936128382069426

Epoch: 5| Step: 9
Training loss: 3.7412909785714787
Validation loss: 2.933290931203153

Epoch: 5| Step: 10
Training loss: 2.671456822915478
Validation loss: 2.9332728222602693

Epoch: 170| Step: 0
Training loss: 3.666621959298126
Validation loss: 2.933985202499255

Epoch: 5| Step: 1
Training loss: 3.198864890476685
Validation loss: 2.9347239782117573

Epoch: 5| Step: 2
Training loss: 3.7178223037814915
Validation loss: 2.937942572779657

Epoch: 5| Step: 3
Training loss: 2.5622787380060337
Validation loss: 2.937636772607423

Epoch: 5| Step: 4
Training loss: 2.6590795368523454
Validation loss: 2.937613958706686

Epoch: 5| Step: 5
Training loss: 3.5350062554505075
Validation loss: 2.9385659948289247

Epoch: 5| Step: 6
Training loss: 3.1428034424838565
Validation loss: 2.937286825655219

Epoch: 5| Step: 7
Training loss: 3.1168275400621295
Validation loss: 2.9309320063374678

Epoch: 5| Step: 8
Training loss: 2.729249521021859
Validation loss: 2.928924920703971

Epoch: 5| Step: 9
Training loss: 3.6834794448479924
Validation loss: 2.930515712696648

Epoch: 5| Step: 10
Training loss: 3.0345056099091043
Validation loss: 2.9330153153279137

Epoch: 171| Step: 0
Training loss: 3.7310548970956727
Validation loss: 2.9293337232493584

Epoch: 5| Step: 1
Training loss: 2.8013323849466576
Validation loss: 2.9276680392825747

Epoch: 5| Step: 2
Training loss: 2.573744780881165
Validation loss: 2.9284024215545426

Epoch: 5| Step: 3
Training loss: 3.3420947960422103
Validation loss: 2.9295473599294866

Epoch: 5| Step: 4
Training loss: 3.3282626844410985
Validation loss: 2.928436206340394

Epoch: 5| Step: 5
Training loss: 3.3641774471079677
Validation loss: 2.931170983127038

Epoch: 5| Step: 6
Training loss: 3.4544360403593513
Validation loss: 2.929868221492515

Epoch: 5| Step: 7
Training loss: 3.4679823017306743
Validation loss: 2.9298107997967353

Epoch: 5| Step: 8
Training loss: 3.0239203804272172
Validation loss: 2.9276870926978944

Epoch: 5| Step: 9
Training loss: 3.086227055738964
Validation loss: 2.9301083419593956

Epoch: 5| Step: 10
Training loss: 2.9719506928986066
Validation loss: 2.9320604180736014

Epoch: 172| Step: 0
Training loss: 2.9259308597220857
Validation loss: 2.933763846168246

Epoch: 5| Step: 1
Training loss: 3.5301583552300437
Validation loss: 2.934480833529067

Epoch: 5| Step: 2
Training loss: 3.1627832157741875
Validation loss: 2.937608133462645

Epoch: 5| Step: 3
Training loss: 3.1664288749422997
Validation loss: 2.929584476095143

Epoch: 5| Step: 4
Training loss: 3.3296095711419733
Validation loss: 2.9254953669779784

Epoch: 5| Step: 5
Training loss: 2.2095233182209704
Validation loss: 2.9290210795581104

Epoch: 5| Step: 6
Training loss: 2.617057227692971
Validation loss: 2.9253423601395756

Epoch: 5| Step: 7
Training loss: 3.849697071394567
Validation loss: 2.924421813897458

Epoch: 5| Step: 8
Training loss: 3.950274619684415
Validation loss: 2.9266191544456674

Epoch: 5| Step: 9
Training loss: 3.0434804934143975
Validation loss: 2.926995306552904

Epoch: 5| Step: 10
Training loss: 3.165044486168602
Validation loss: 2.924586044466953

Epoch: 173| Step: 0
Training loss: 3.4780953103552292
Validation loss: 2.926459069425903

Epoch: 5| Step: 1
Training loss: 3.179668454574795
Validation loss: 2.9278520813847098

Epoch: 5| Step: 2
Training loss: 2.949293446384361
Validation loss: 2.9227294497284797

Epoch: 5| Step: 3
Training loss: 3.742691802446547
Validation loss: 2.9285540919851756

Epoch: 5| Step: 4
Training loss: 3.418829830151208
Validation loss: 2.9344918979896235

Epoch: 5| Step: 5
Training loss: 3.03526197958743
Validation loss: 2.9323324369210564

Epoch: 5| Step: 6
Training loss: 2.864719919358545
Validation loss: 2.940764495497064

Epoch: 5| Step: 7
Training loss: 3.4441527752458074
Validation loss: 2.938357425964788

Epoch: 5| Step: 8
Training loss: 2.5866783901650257
Validation loss: 2.935818438951604

Epoch: 5| Step: 9
Training loss: 3.4123241616803064
Validation loss: 2.9364569790527058

Epoch: 5| Step: 10
Training loss: 3.010802529145151
Validation loss: 2.9273798700432208

Epoch: 174| Step: 0
Training loss: 3.5702805799397095
Validation loss: 2.9319403737808862

Epoch: 5| Step: 1
Training loss: 3.271397066232348
Validation loss: 2.927527912879344

Epoch: 5| Step: 2
Training loss: 2.7998878831214897
Validation loss: 2.931365501128778

Epoch: 5| Step: 3
Training loss: 3.0077126226315096
Validation loss: 2.922967000953048

Epoch: 5| Step: 4
Training loss: 3.1344330893522
Validation loss: 2.9248768633907023

Epoch: 5| Step: 5
Training loss: 2.7444540801846524
Validation loss: 2.9251051473075904

Epoch: 5| Step: 6
Training loss: 3.570366589827212
Validation loss: 2.9224644250080942

Epoch: 5| Step: 7
Training loss: 3.1988966410551325
Validation loss: 2.922618680734228

Epoch: 5| Step: 8
Training loss: 3.4965944070201496
Validation loss: 2.9234624286771576

Epoch: 5| Step: 9
Training loss: 3.620789022287946
Validation loss: 2.9250185357729954

Epoch: 5| Step: 10
Training loss: 2.546267665226839
Validation loss: 2.925509741054421

Epoch: 175| Step: 0
Training loss: 3.5246115883100804
Validation loss: 2.9251273453621454

Epoch: 5| Step: 1
Training loss: 3.5050189952907007
Validation loss: 2.922684974922986

Epoch: 5| Step: 2
Training loss: 3.7481860542000063
Validation loss: 2.9209784746251737

Epoch: 5| Step: 3
Training loss: 2.8004968304581253
Validation loss: 2.9220220127293306

Epoch: 5| Step: 4
Training loss: 2.406953188711597
Validation loss: 2.9217391514165625

Epoch: 5| Step: 5
Training loss: 3.305866869701935
Validation loss: 2.9252021696544643

Epoch: 5| Step: 6
Training loss: 3.640306057691379
Validation loss: 2.9220496088156795

Epoch: 5| Step: 7
Training loss: 3.3608796764242923
Validation loss: 2.921891582732156

Epoch: 5| Step: 8
Training loss: 3.4563172373517514
Validation loss: 2.9217166907101717

Epoch: 5| Step: 9
Training loss: 2.325483013556085
Validation loss: 2.924071800406703

Epoch: 5| Step: 10
Training loss: 2.7140472780634233
Validation loss: 2.919009774637483

Epoch: 176| Step: 0
Training loss: 3.26139550349049
Validation loss: 2.919873833152201

Epoch: 5| Step: 1
Training loss: 3.5090188583689135
Validation loss: 2.9239166340845286

Epoch: 5| Step: 2
Training loss: 3.0383124124542933
Validation loss: 2.9220434989905772

Epoch: 5| Step: 3
Training loss: 2.7367088603005185
Validation loss: 2.925465602959852

Epoch: 5| Step: 4
Training loss: 3.2012795691444658
Validation loss: 2.9267603229198507

Epoch: 5| Step: 5
Training loss: 3.437224082276957
Validation loss: 2.93017632588154

Epoch: 5| Step: 6
Training loss: 3.532771500117988
Validation loss: 2.921596148577437

Epoch: 5| Step: 7
Training loss: 2.958495247578378
Validation loss: 2.921225867386246

Epoch: 5| Step: 8
Training loss: 3.4128480056104777
Validation loss: 2.9233052594671722

Epoch: 5| Step: 9
Training loss: 2.5626505365581886
Validation loss: 2.9189721156145962

Epoch: 5| Step: 10
Training loss: 3.4853967100956535
Validation loss: 2.919556672853683

Epoch: 177| Step: 0
Training loss: 3.2373905590515237
Validation loss: 2.9173261280745084

Epoch: 5| Step: 1
Training loss: 2.5209175495130483
Validation loss: 2.9196612377410065

Epoch: 5| Step: 2
Training loss: 3.624628903040064
Validation loss: 2.9190532418853063

Epoch: 5| Step: 3
Training loss: 3.3219162601983974
Validation loss: 2.918043097184625

Epoch: 5| Step: 4
Training loss: 3.0057422994378413
Validation loss: 2.9179914732533674

Epoch: 5| Step: 5
Training loss: 3.156556520591385
Validation loss: 2.919204122040464

Epoch: 5| Step: 6
Training loss: 3.325398505860361
Validation loss: 2.9195630846776215

Epoch: 5| Step: 7
Training loss: 2.689254720180334
Validation loss: 2.9211981669822555

Epoch: 5| Step: 8
Training loss: 3.068815608983922
Validation loss: 2.9203304682997526

Epoch: 5| Step: 9
Training loss: 3.4276759476858003
Validation loss: 2.918784142583677

Epoch: 5| Step: 10
Training loss: 3.774304908269651
Validation loss: 2.929726460734442

Epoch: 178| Step: 0
Training loss: 3.2809436473430957
Validation loss: 2.9157733416428595

Epoch: 5| Step: 1
Training loss: 3.5172462624547562
Validation loss: 2.921768199685617

Epoch: 5| Step: 2
Training loss: 3.2144601623183693
Validation loss: 2.9173171796088644

Epoch: 5| Step: 3
Training loss: 3.115638137529505
Validation loss: 2.9241691156681577

Epoch: 5| Step: 4
Training loss: 3.846810711742591
Validation loss: 2.9222418073546876

Epoch: 5| Step: 5
Training loss: 2.9043582789196485
Validation loss: 2.916946342056332

Epoch: 5| Step: 6
Training loss: 3.060376112019809
Validation loss: 2.9177488461143817

Epoch: 5| Step: 7
Training loss: 2.958294577187999
Validation loss: 2.9145007812440293

Epoch: 5| Step: 8
Training loss: 3.096653202247981
Validation loss: 2.9164612171808875

Epoch: 5| Step: 9
Training loss: 3.0834779619543107
Validation loss: 2.9152996601185266

Epoch: 5| Step: 10
Training loss: 2.96810697317523
Validation loss: 2.912327532199541

Epoch: 179| Step: 0
Training loss: 3.396155422046494
Validation loss: 2.9113604138591334

Epoch: 5| Step: 1
Training loss: 3.2806381381718905
Validation loss: 2.9204043129300383

Epoch: 5| Step: 2
Training loss: 2.50255473257113
Validation loss: 2.9145532085068635

Epoch: 5| Step: 3
Training loss: 2.9623334105447165
Validation loss: 2.91565167452527

Epoch: 5| Step: 4
Training loss: 3.0514546724441045
Validation loss: 2.916222430969615

Epoch: 5| Step: 5
Training loss: 3.4802817349008786
Validation loss: 2.915516876912449

Epoch: 5| Step: 6
Training loss: 3.7363698571163266
Validation loss: 2.921986124442479

Epoch: 5| Step: 7
Training loss: 3.3740603233783326
Validation loss: 2.917011007441894

Epoch: 5| Step: 8
Training loss: 3.270726649656382
Validation loss: 2.9227116911138413

Epoch: 5| Step: 9
Training loss: 2.9588764032487314
Validation loss: 2.914830753032278

Epoch: 5| Step: 10
Training loss: 2.9958484852654816
Validation loss: 2.9183487262365437

Epoch: 180| Step: 0
Training loss: 2.95110433565585
Validation loss: 2.916161035989084

Epoch: 5| Step: 1
Training loss: 2.2939128849080914
Validation loss: 2.9188176135950337

Epoch: 5| Step: 2
Training loss: 3.3044704789851544
Validation loss: 2.9206182420117224

Epoch: 5| Step: 3
Training loss: 2.917316981886393
Validation loss: 2.916217317261383

Epoch: 5| Step: 4
Training loss: 3.948530942824852
Validation loss: 2.9115544327379217

Epoch: 5| Step: 5
Training loss: 3.425819944817813
Validation loss: 2.9137789205503037

Epoch: 5| Step: 6
Training loss: 3.3995488596784162
Validation loss: 2.9153636638209

Epoch: 5| Step: 7
Training loss: 3.3044945771018015
Validation loss: 2.913213514527576

Epoch: 5| Step: 8
Training loss: 3.2412115259678584
Validation loss: 2.911889548057083

Epoch: 5| Step: 9
Training loss: 3.1869480926815825
Validation loss: 2.911492014771997

Epoch: 5| Step: 10
Training loss: 2.8931121848303207
Validation loss: 2.9136506195082954

Epoch: 181| Step: 0
Training loss: 3.262488067722058
Validation loss: 2.912451285262433

Epoch: 5| Step: 1
Training loss: 2.970331192559788
Validation loss: 2.9109379940331865

Epoch: 5| Step: 2
Training loss: 3.6634242431171677
Validation loss: 2.9122363046532183

Epoch: 5| Step: 3
Training loss: 2.9481808888853593
Validation loss: 2.9110046969026717

Epoch: 5| Step: 4
Training loss: 3.3940217192117315
Validation loss: 2.9116876044372475

Epoch: 5| Step: 5
Training loss: 2.664478884735882
Validation loss: 2.910375929510136

Epoch: 5| Step: 6
Training loss: 3.178347443454456
Validation loss: 2.907996670862913

Epoch: 5| Step: 7
Training loss: 3.243985112072593
Validation loss: 2.9082805020759555

Epoch: 5| Step: 8
Training loss: 3.6176032533916977
Validation loss: 2.906737453525986

Epoch: 5| Step: 9
Training loss: 3.0489426077561093
Validation loss: 2.912126430619082

Epoch: 5| Step: 10
Training loss: 3.016109763599313
Validation loss: 2.9085053438849338

Epoch: 182| Step: 0
Training loss: 3.4366984039627053
Validation loss: 2.908768024274953

Epoch: 5| Step: 1
Training loss: 3.635440523930979
Validation loss: 2.909305778310761

Epoch: 5| Step: 2
Training loss: 3.1988534124904895
Validation loss: 2.9119544164178484

Epoch: 5| Step: 3
Training loss: 3.0424163277748875
Validation loss: 2.9134872173506037

Epoch: 5| Step: 4
Training loss: 3.115388355814399
Validation loss: 2.9083513065817863

Epoch: 5| Step: 5
Training loss: 2.752863520178576
Validation loss: 2.911340284965578

Epoch: 5| Step: 6
Training loss: 3.2505899040676094
Validation loss: 2.9144581257279

Epoch: 5| Step: 7
Training loss: 3.2980523922322975
Validation loss: 2.9139714288241807

Epoch: 5| Step: 8
Training loss: 3.0732541346188973
Validation loss: 2.911438969719746

Epoch: 5| Step: 9
Training loss: 2.6215984466885716
Validation loss: 2.9092859101335447

Epoch: 5| Step: 10
Training loss: 3.6405673697825978
Validation loss: 2.9112898375199125

Epoch: 183| Step: 0
Training loss: 3.5278128040674144
Validation loss: 2.911648067743649

Epoch: 5| Step: 1
Training loss: 2.4695392747294287
Validation loss: 2.911215159359715

Epoch: 5| Step: 2
Training loss: 2.3884736397582085
Validation loss: 2.9122330264154304

Epoch: 5| Step: 3
Training loss: 2.926115335252559
Validation loss: 2.9115943528373083

Epoch: 5| Step: 4
Training loss: 3.733337769051596
Validation loss: 2.905793864197821

Epoch: 5| Step: 5
Training loss: 2.8738233397468487
Validation loss: 2.9065212749890423

Epoch: 5| Step: 6
Training loss: 3.294472058248199
Validation loss: 2.911024825474724

Epoch: 5| Step: 7
Training loss: 2.8436420126732256
Validation loss: 2.911611133238875

Epoch: 5| Step: 8
Training loss: 3.2157151812928437
Validation loss: 2.910046304477356

Epoch: 5| Step: 9
Training loss: 3.6395846341586977
Validation loss: 2.9125759282276538

Epoch: 5| Step: 10
Training loss: 3.9144289374377457
Validation loss: 2.905420404365337

Epoch: 184| Step: 0
Training loss: 3.181195475592574
Validation loss: 2.904806222385692

Epoch: 5| Step: 1
Training loss: 2.90770873510326
Validation loss: 2.9081487805172506

Epoch: 5| Step: 2
Training loss: 2.47961949505786
Validation loss: 2.9039426631544174

Epoch: 5| Step: 3
Training loss: 3.2522729115007167
Validation loss: 2.9052755570466426

Epoch: 5| Step: 4
Training loss: 2.8211807224893115
Validation loss: 2.907120381024447

Epoch: 5| Step: 5
Training loss: 2.960833303585924
Validation loss: 2.9066362718606604

Epoch: 5| Step: 6
Training loss: 3.7106519729793033
Validation loss: 2.908473971898703

Epoch: 5| Step: 7
Training loss: 3.3242858808218707
Validation loss: 2.916475839715489

Epoch: 5| Step: 8
Training loss: 3.087375276957604
Validation loss: 2.9069283009542306

Epoch: 5| Step: 9
Training loss: 3.795005809191453
Validation loss: 2.905894005061474

Epoch: 5| Step: 10
Training loss: 3.3517571239382926
Validation loss: 2.904933647649156

Epoch: 185| Step: 0
Training loss: 3.1251077251940265
Validation loss: 2.903628261135365

Epoch: 5| Step: 1
Training loss: 2.8957945091517456
Validation loss: 2.9060262037493665

Epoch: 5| Step: 2
Training loss: 3.6416079786330577
Validation loss: 2.905066505122562

Epoch: 5| Step: 3
Training loss: 2.530586626699812
Validation loss: 2.9074981748967947

Epoch: 5| Step: 4
Training loss: 2.2793845296314834
Validation loss: 2.908460882509054

Epoch: 5| Step: 5
Training loss: 3.4577528378269027
Validation loss: 2.911721795355304

Epoch: 5| Step: 6
Training loss: 3.468158980873537
Validation loss: 2.9093807883346203

Epoch: 5| Step: 7
Training loss: 2.9017065485960223
Validation loss: 2.9072110565955986

Epoch: 5| Step: 8
Training loss: 3.6089627909910367
Validation loss: 2.9104752644259806

Epoch: 5| Step: 9
Training loss: 3.264303861891351
Validation loss: 2.911700934655199

Epoch: 5| Step: 10
Training loss: 3.647110691642732
Validation loss: 2.904523257347316

Epoch: 186| Step: 0
Training loss: 3.8351130017041015
Validation loss: 2.914202879765447

Epoch: 5| Step: 1
Training loss: 2.9472445922667343
Validation loss: 2.907726900982812

Epoch: 5| Step: 2
Training loss: 3.071039555395805
Validation loss: 2.90538526044597

Epoch: 5| Step: 3
Training loss: 2.7906651954276405
Validation loss: 2.90487162399933

Epoch: 5| Step: 4
Training loss: 3.2872902632845564
Validation loss: 2.9048771327555656

Epoch: 5| Step: 5
Training loss: 3.123340929226373
Validation loss: 2.917556581812557

Epoch: 5| Step: 6
Training loss: 3.558660479358579
Validation loss: 2.9078317352166714

Epoch: 5| Step: 7
Training loss: 3.0285516113599416
Validation loss: 2.9035708820534665

Epoch: 5| Step: 8
Training loss: 3.4252323767916786
Validation loss: 2.9046942068093364

Epoch: 5| Step: 9
Training loss: 2.823665833858973
Validation loss: 2.906662838331134

Epoch: 5| Step: 10
Training loss: 2.9910913755487853
Validation loss: 2.9091876819583655

Epoch: 187| Step: 0
Training loss: 3.473690878635072
Validation loss: 2.9066974032203996

Epoch: 5| Step: 1
Training loss: 3.524077296055553
Validation loss: 2.900882519443983

Epoch: 5| Step: 2
Training loss: 2.6861540506799635
Validation loss: 2.9015014806006008

Epoch: 5| Step: 3
Training loss: 3.2966612253893106
Validation loss: 2.9000368589421655

Epoch: 5| Step: 4
Training loss: 3.1656491669375373
Validation loss: 2.90089834462385

Epoch: 5| Step: 5
Training loss: 3.4978199027337658
Validation loss: 2.9052193055901125

Epoch: 5| Step: 6
Training loss: 3.562281551690661
Validation loss: 2.8980158194038803

Epoch: 5| Step: 7
Training loss: 2.6849537697333763
Validation loss: 2.9019038950318103

Epoch: 5| Step: 8
Training loss: 3.0887402904300765
Validation loss: 2.89832875161334

Epoch: 5| Step: 9
Training loss: 3.054034307161006
Validation loss: 2.9062034231831757

Epoch: 5| Step: 10
Training loss: 2.7532934061562164
Validation loss: 2.897515671780287

Epoch: 188| Step: 0
Training loss: 3.2695570640502005
Validation loss: 2.8983390350682923

Epoch: 5| Step: 1
Training loss: 2.7274124875526806
Validation loss: 2.8985286718539918

Epoch: 5| Step: 2
Training loss: 2.7589373577399514
Validation loss: 2.8986934257768806

Epoch: 5| Step: 3
Training loss: 2.8064516942325137
Validation loss: 2.8999692770264405

Epoch: 5| Step: 4
Training loss: 3.7408546829775777
Validation loss: 2.9014533104647997

Epoch: 5| Step: 5
Training loss: 3.4309266096074826
Validation loss: 2.900095739117376

Epoch: 5| Step: 6
Training loss: 2.859178213216455
Validation loss: 2.904920268726865

Epoch: 5| Step: 7
Training loss: 3.4765605797923067
Validation loss: 2.9062210453817103

Epoch: 5| Step: 8
Training loss: 3.3581219842507806
Validation loss: 2.903899442035124

Epoch: 5| Step: 9
Training loss: 2.841618000706372
Validation loss: 2.906783184814305

Epoch: 5| Step: 10
Training loss: 3.5821278932403118
Validation loss: 2.8986110796146503

Epoch: 189| Step: 0
Training loss: 3.7275164200992292
Validation loss: 2.8991277096398136

Epoch: 5| Step: 1
Training loss: 2.5329055081892666
Validation loss: 2.897047918790547

Epoch: 5| Step: 2
Training loss: 2.7940489060771254
Validation loss: 2.9004524793092603

Epoch: 5| Step: 3
Training loss: 3.2388622466776975
Validation loss: 2.901982106158871

Epoch: 5| Step: 4
Training loss: 3.624127776345948
Validation loss: 2.894135830530052

Epoch: 5| Step: 5
Training loss: 3.0238732312288623
Validation loss: 2.8962450482117075

Epoch: 5| Step: 6
Training loss: 3.371369705309753
Validation loss: 2.8963752824337807

Epoch: 5| Step: 7
Training loss: 2.6744355542057567
Validation loss: 2.8956038221119895

Epoch: 5| Step: 8
Training loss: 3.0643745446326367
Validation loss: 2.894661347001929

Epoch: 5| Step: 9
Training loss: 3.4836049961097624
Validation loss: 2.896584437666286

Epoch: 5| Step: 10
Training loss: 3.2355536188508736
Validation loss: 2.89450845239855

Epoch: 190| Step: 0
Training loss: 3.404841700611878
Validation loss: 2.893832752348011

Epoch: 5| Step: 1
Training loss: 3.4684808300159995
Validation loss: 2.892788059920047

Epoch: 5| Step: 2
Training loss: 3.4557533445377278
Validation loss: 2.893172138996307

Epoch: 5| Step: 3
Training loss: 3.269306352872221
Validation loss: 2.894435454581576

Epoch: 5| Step: 4
Training loss: 2.6801869452451266
Validation loss: 2.893795448714768

Epoch: 5| Step: 5
Training loss: 3.158691972351259
Validation loss: 2.8983887040135063

Epoch: 5| Step: 6
Training loss: 2.870051894300269
Validation loss: 2.906229362013154

Epoch: 5| Step: 7
Training loss: 3.140608450622986
Validation loss: 2.9064213594940758

Epoch: 5| Step: 8
Training loss: 3.341835686142248
Validation loss: 2.8969775450848014

Epoch: 5| Step: 9
Training loss: 3.247262829114338
Validation loss: 2.895668704710107

Epoch: 5| Step: 10
Training loss: 2.774431163462564
Validation loss: 2.896229940259251

Epoch: 191| Step: 0
Training loss: 3.037471403764408
Validation loss: 2.8906186676621193

Epoch: 5| Step: 1
Training loss: 2.74520646977719
Validation loss: 2.8920677728416346

Epoch: 5| Step: 2
Training loss: 3.220941926837106
Validation loss: 2.889040376095363

Epoch: 5| Step: 3
Training loss: 3.6497073853136617
Validation loss: 2.8880211487558927

Epoch: 5| Step: 4
Training loss: 3.6233329886185084
Validation loss: 2.8894705008130885

Epoch: 5| Step: 5
Training loss: 3.407790369436824
Validation loss: 2.889332954752236

Epoch: 5| Step: 6
Training loss: 3.1071459577573144
Validation loss: 2.8902428194495853

Epoch: 5| Step: 7
Training loss: 3.079156847892114
Validation loss: 2.8899953167963943

Epoch: 5| Step: 8
Training loss: 3.376918529997392
Validation loss: 2.891383426836845

Epoch: 5| Step: 9
Training loss: 2.8161147729990286
Validation loss: 2.8883880535929314

Epoch: 5| Step: 10
Training loss: 2.688605591226984
Validation loss: 2.888565427712014

Epoch: 192| Step: 0
Training loss: 2.838237575842845
Validation loss: 2.9008606917422908

Epoch: 5| Step: 1
Training loss: 3.331601042439122
Validation loss: 2.895601980570624

Epoch: 5| Step: 2
Training loss: 2.8869637061474798
Validation loss: 2.906247533611266

Epoch: 5| Step: 3
Training loss: 3.5142078849601117
Validation loss: 2.9165954780387557

Epoch: 5| Step: 4
Training loss: 3.6166124319296484
Validation loss: 2.8932703455954987

Epoch: 5| Step: 5
Training loss: 2.7016371673096784
Validation loss: 2.8889250275489435

Epoch: 5| Step: 6
Training loss: 3.491809798943389
Validation loss: 2.8871448181379518

Epoch: 5| Step: 7
Training loss: 3.120215453509318
Validation loss: 2.88733625295281

Epoch: 5| Step: 8
Training loss: 3.3339433270851098
Validation loss: 2.8892685385620167

Epoch: 5| Step: 9
Training loss: 3.047466514096753
Validation loss: 2.89244586562196

Epoch: 5| Step: 10
Training loss: 3.014827484458665
Validation loss: 2.8945001516888156

Epoch: 193| Step: 0
Training loss: 2.7879113137630838
Validation loss: 2.8960589036770163

Epoch: 5| Step: 1
Training loss: 3.670558872130626
Validation loss: 2.895503362549052

Epoch: 5| Step: 2
Training loss: 2.917495791343131
Validation loss: 2.8982581038398614

Epoch: 5| Step: 3
Training loss: 3.235898161409092
Validation loss: 2.8965844717409577

Epoch: 5| Step: 4
Training loss: 2.929486158446026
Validation loss: 2.8972702477625076

Epoch: 5| Step: 5
Training loss: 3.1377551883098107
Validation loss: 2.891988775896516

Epoch: 5| Step: 6
Training loss: 2.9836813235359907
Validation loss: 2.8940729066719775

Epoch: 5| Step: 7
Training loss: 3.215117543683613
Validation loss: 2.890967273264453

Epoch: 5| Step: 8
Training loss: 2.9427360780921514
Validation loss: 2.8885087274719825

Epoch: 5| Step: 9
Training loss: 3.208036648462486
Validation loss: 2.8880433974992625

Epoch: 5| Step: 10
Training loss: 3.978252299175606
Validation loss: 2.8866674894983317

Epoch: 194| Step: 0
Training loss: 3.584832048086532
Validation loss: 2.8876925426223803

Epoch: 5| Step: 1
Training loss: 3.1980194340366466
Validation loss: 2.8876521713545054

Epoch: 5| Step: 2
Training loss: 2.8323287491909643
Validation loss: 2.8858453125620485

Epoch: 5| Step: 3
Training loss: 3.3706598986193557
Validation loss: 2.8896196944732315

Epoch: 5| Step: 4
Training loss: 3.188139309068586
Validation loss: 2.8921244245805195

Epoch: 5| Step: 5
Training loss: 3.069528727191792
Validation loss: 2.894970034300177

Epoch: 5| Step: 6
Training loss: 3.221624183697013
Validation loss: 2.897167993933632

Epoch: 5| Step: 7
Training loss: 3.18937044801561
Validation loss: 2.8908406530552853

Epoch: 5| Step: 8
Training loss: 3.0190325049981412
Validation loss: 2.889848482750359

Epoch: 5| Step: 9
Training loss: 3.163406266342124
Validation loss: 2.8865215359533565

Epoch: 5| Step: 10
Training loss: 3.0283207848778253
Validation loss: 2.8871052854392687

Epoch: 195| Step: 0
Training loss: 2.995671328292428
Validation loss: 2.88222320337881

Epoch: 5| Step: 1
Training loss: 3.4743752446237153
Validation loss: 2.8873943426544164

Epoch: 5| Step: 2
Training loss: 3.164819094774443
Validation loss: 2.8886685345205865

Epoch: 5| Step: 3
Training loss: 3.7049849462782487
Validation loss: 2.8840530109307525

Epoch: 5| Step: 4
Training loss: 3.0806620255433734
Validation loss: 2.884009513069786

Epoch: 5| Step: 5
Training loss: 3.4328630557393995
Validation loss: 2.8835006262976717

Epoch: 5| Step: 6
Training loss: 2.339871261511363
Validation loss: 2.883881333945874

Epoch: 5| Step: 7
Training loss: 3.1293899219447447
Validation loss: 2.884008257920887

Epoch: 5| Step: 8
Training loss: 3.39356283722043
Validation loss: 2.884953205551426

Epoch: 5| Step: 9
Training loss: 2.7834541073786903
Validation loss: 2.887890346042596

Epoch: 5| Step: 10
Training loss: 3.2266326970553285
Validation loss: 2.88925179432313

Epoch: 196| Step: 0
Training loss: 3.766578395338074
Validation loss: 2.890749616522592

Epoch: 5| Step: 1
Training loss: 2.8958656437304002
Validation loss: 2.8910558821198578

Epoch: 5| Step: 2
Training loss: 3.3990062719984735
Validation loss: 2.8890968121193294

Epoch: 5| Step: 3
Training loss: 2.538265161765631
Validation loss: 2.8859935583762857

Epoch: 5| Step: 4
Training loss: 3.2441950086689397
Validation loss: 2.888778849059433

Epoch: 5| Step: 5
Training loss: 3.434373578252663
Validation loss: 2.882344986542526

Epoch: 5| Step: 6
Training loss: 3.2169975769394323
Validation loss: 2.8838988231928595

Epoch: 5| Step: 7
Training loss: 3.2036497105005615
Validation loss: 2.8827733125203867

Epoch: 5| Step: 8
Training loss: 2.945332737051249
Validation loss: 2.8871863277325356

Epoch: 5| Step: 9
Training loss: 3.2035391190951987
Validation loss: 2.882023888418888

Epoch: 5| Step: 10
Training loss: 2.7912000484412975
Validation loss: 2.881546099394826

Epoch: 197| Step: 0
Training loss: 3.078574365646686
Validation loss: 2.8836409585056333

Epoch: 5| Step: 1
Training loss: 2.5609207869630817
Validation loss: 2.88370076198192

Epoch: 5| Step: 2
Training loss: 2.8444342156895197
Validation loss: 2.882381941627446

Epoch: 5| Step: 3
Training loss: 3.3741161460671267
Validation loss: 2.883253316665813

Epoch: 5| Step: 4
Training loss: 3.2285797242011016
Validation loss: 2.8869325973592295

Epoch: 5| Step: 5
Training loss: 2.9700308195114165
Validation loss: 2.8906620882421508

Epoch: 5| Step: 6
Training loss: 3.516592341958892
Validation loss: 2.8886986590443757

Epoch: 5| Step: 7
Training loss: 2.5494500932344346
Validation loss: 2.880617069811614

Epoch: 5| Step: 8
Training loss: 3.606136570143235
Validation loss: 2.884156381275521

Epoch: 5| Step: 9
Training loss: 2.9467287579491948
Validation loss: 2.8829006249740283

Epoch: 5| Step: 10
Training loss: 4.010426997712275
Validation loss: 2.882858050573686

Epoch: 198| Step: 0
Training loss: 3.0222760318036057
Validation loss: 2.8796989683149086

Epoch: 5| Step: 1
Training loss: 2.543260689427493
Validation loss: 2.878662008184356

Epoch: 5| Step: 2
Training loss: 3.5827038382061898
Validation loss: 2.8771904879611427

Epoch: 5| Step: 3
Training loss: 3.403175296184082
Validation loss: 2.877383183773381

Epoch: 5| Step: 4
Training loss: 2.369624127065421
Validation loss: 2.879569114988394

Epoch: 5| Step: 5
Training loss: 3.2726285021259662
Validation loss: 2.879720345713991

Epoch: 5| Step: 6
Training loss: 3.1554380071114743
Validation loss: 2.8833036429262235

Epoch: 5| Step: 7
Training loss: 3.2597245201778526
Validation loss: 2.8816213605011773

Epoch: 5| Step: 8
Training loss: 3.493251971129662
Validation loss: 2.879228413465572

Epoch: 5| Step: 9
Training loss: 3.021598946902592
Validation loss: 2.88023979720049

Epoch: 5| Step: 10
Training loss: 3.53234009247845
Validation loss: 2.8764033982980703

Epoch: 199| Step: 0
Training loss: 3.9031315677486775
Validation loss: 2.877424881409175

Epoch: 5| Step: 1
Training loss: 2.8128256715199784
Validation loss: 2.8728353680822027

Epoch: 5| Step: 2
Training loss: 3.4951103660173723
Validation loss: 2.8793139289611798

Epoch: 5| Step: 3
Training loss: 2.9929520150724715
Validation loss: 2.8755394446016593

Epoch: 5| Step: 4
Training loss: 2.7779951444985764
Validation loss: 2.875462634371971

Epoch: 5| Step: 5
Training loss: 3.025942058313575
Validation loss: 2.8742185496338126

Epoch: 5| Step: 6
Training loss: 3.292244936854359
Validation loss: 2.874922893572712

Epoch: 5| Step: 7
Training loss: 2.983901061128291
Validation loss: 2.8740212610092177

Epoch: 5| Step: 8
Training loss: 3.0878483131786436
Validation loss: 2.876639746991282

Epoch: 5| Step: 9
Training loss: 3.354540375609123
Validation loss: 2.8728354305483106

Epoch: 5| Step: 10
Training loss: 2.9017252821445916
Validation loss: 2.877795769637904

Epoch: 200| Step: 0
Training loss: 3.503510894074671
Validation loss: 2.8748860731196872

Epoch: 5| Step: 1
Training loss: 3.3371386900360682
Validation loss: 2.8757711021138053

Epoch: 5| Step: 2
Training loss: 3.4626234783093386
Validation loss: 2.885463165291179

Epoch: 5| Step: 3
Training loss: 3.2242302027601295
Validation loss: 2.879158985238163

Epoch: 5| Step: 4
Training loss: 2.8965508832131652
Validation loss: 2.8815773802115787

Epoch: 5| Step: 5
Training loss: 2.7546105316193437
Validation loss: 2.883638868397535

Epoch: 5| Step: 6
Training loss: 3.5623456687291286
Validation loss: 2.8852267947877346

Epoch: 5| Step: 7
Training loss: 2.613710924072649
Validation loss: 2.887938758384156

Epoch: 5| Step: 8
Training loss: 3.367082988064111
Validation loss: 2.891340745038701

Epoch: 5| Step: 9
Training loss: 2.704443725671867
Validation loss: 2.886788408472276

Epoch: 5| Step: 10
Training loss: 3.1858811100809774
Validation loss: 2.8820315312324065

Epoch: 201| Step: 0
Training loss: 2.667648184467001
Validation loss: 2.8894359552074302

Epoch: 5| Step: 1
Training loss: 3.4120188167719503
Validation loss: 2.8740264203600994

Epoch: 5| Step: 2
Training loss: 3.730722979925191
Validation loss: 2.87265701020629

Epoch: 5| Step: 3
Training loss: 2.9572299099384165
Validation loss: 2.8738187634436536

Epoch: 5| Step: 4
Training loss: 3.6883415942840068
Validation loss: 2.8773937835352186

Epoch: 5| Step: 5
Training loss: 3.1831854248303757
Validation loss: 2.8740866232525195

Epoch: 5| Step: 6
Training loss: 2.9012958591030213
Validation loss: 2.8719652806511804

Epoch: 5| Step: 7
Training loss: 2.883403107638635
Validation loss: 2.8721438501820624

Epoch: 5| Step: 8
Training loss: 2.500713914026046
Validation loss: 2.8724225240041195

Epoch: 5| Step: 9
Training loss: 3.2906577258099357
Validation loss: 2.873400917144434

Epoch: 5| Step: 10
Training loss: 3.3659769169995695
Validation loss: 2.8750512081541837

Epoch: 202| Step: 0
Training loss: 3.237495428251478
Validation loss: 2.869362150963178

Epoch: 5| Step: 1
Training loss: 3.142646708193514
Validation loss: 2.872741865505321

Epoch: 5| Step: 2
Training loss: 3.038685596306114
Validation loss: 2.872980609712763

Epoch: 5| Step: 3
Training loss: 3.708905950905352
Validation loss: 2.879540566039403

Epoch: 5| Step: 4
Training loss: 2.6405462670862345
Validation loss: 2.877889663876352

Epoch: 5| Step: 5
Training loss: 3.037340318540602
Validation loss: 2.8881141353629998

Epoch: 5| Step: 6
Training loss: 3.3581285160230174
Validation loss: 2.884683490019661

Epoch: 5| Step: 7
Training loss: 3.5442049841144048
Validation loss: 2.8829194131425764

Epoch: 5| Step: 8
Training loss: 3.396738473908734
Validation loss: 2.8717309031195293

Epoch: 5| Step: 9
Training loss: 2.580641841597883
Validation loss: 2.8674123722293863

Epoch: 5| Step: 10
Training loss: 2.854428374457777
Validation loss: 2.869234922201667

Epoch: 203| Step: 0
Training loss: 3.153391837557895
Validation loss: 2.868947905462109

Epoch: 5| Step: 1
Training loss: 3.2775341974332224
Validation loss: 2.8709902754417014

Epoch: 5| Step: 2
Training loss: 3.854594246455724
Validation loss: 2.870876000128658

Epoch: 5| Step: 3
Training loss: 3.498434806710246
Validation loss: 2.8717009264465387

Epoch: 5| Step: 4
Training loss: 2.8171617655919556
Validation loss: 2.8703165254215164

Epoch: 5| Step: 5
Training loss: 3.001546620014685
Validation loss: 2.870784147422176

Epoch: 5| Step: 6
Training loss: 3.3966946747897606
Validation loss: 2.8698247169128153

Epoch: 5| Step: 7
Training loss: 2.8911412783251103
Validation loss: 2.8689059836428723

Epoch: 5| Step: 8
Training loss: 3.3791810028737888
Validation loss: 2.867706060590605

Epoch: 5| Step: 9
Training loss: 2.5333381799183043
Validation loss: 2.864442830299049

Epoch: 5| Step: 10
Training loss: 2.7827931955515064
Validation loss: 2.8679492840735774

Epoch: 204| Step: 0
Training loss: 3.542697143237911
Validation loss: 2.866687755359291

Epoch: 5| Step: 1
Training loss: 3.3356902055405064
Validation loss: 2.866893430337112

Epoch: 5| Step: 2
Training loss: 3.475390153018542
Validation loss: 2.8666423306024784

Epoch: 5| Step: 3
Training loss: 2.7814691864396996
Validation loss: 2.869943398617141

Epoch: 5| Step: 4
Training loss: 3.267547187727124
Validation loss: 2.8734878747339154

Epoch: 5| Step: 5
Training loss: 2.9752532402413907
Validation loss: 2.877214975820411

Epoch: 5| Step: 6
Training loss: 3.4448061893242756
Validation loss: 2.872401312741573

Epoch: 5| Step: 7
Training loss: 3.0993852251872283
Validation loss: 2.8733425632775194

Epoch: 5| Step: 8
Training loss: 3.2387088359894913
Validation loss: 2.86899087214443

Epoch: 5| Step: 9
Training loss: 2.6048644593281525
Validation loss: 2.866099043231442

Epoch: 5| Step: 10
Training loss: 2.765534911331744
Validation loss: 2.870454661188423

Epoch: 205| Step: 0
Training loss: 3.077856991326533
Validation loss: 2.872462820152

Epoch: 5| Step: 1
Training loss: 2.988581703390315
Validation loss: 2.864540260565369

Epoch: 5| Step: 2
Training loss: 2.739090346930875
Validation loss: 2.8693150048403413

Epoch: 5| Step: 3
Training loss: 3.3411427252802834
Validation loss: 2.871049836139414

Epoch: 5| Step: 4
Training loss: 3.186810287952731
Validation loss: 2.8775413297333974

Epoch: 5| Step: 5
Training loss: 3.1816541134037286
Validation loss: 2.8813259514873364

Epoch: 5| Step: 6
Training loss: 3.3003085367868685
Validation loss: 2.872855468713077

Epoch: 5| Step: 7
Training loss: 2.772750382533179
Validation loss: 2.869525948413629

Epoch: 5| Step: 8
Training loss: 3.6853327443839605
Validation loss: 2.8685804463114635

Epoch: 5| Step: 9
Training loss: 3.2067807061371405
Validation loss: 2.864161933637401

Epoch: 5| Step: 10
Training loss: 3.154200728991345
Validation loss: 2.8633151531457672

Epoch: 206| Step: 0
Training loss: 3.653944282912896
Validation loss: 2.865095439938259

Epoch: 5| Step: 1
Training loss: 2.3710340212694314
Validation loss: 2.864570345285156

Epoch: 5| Step: 2
Training loss: 3.09719102403773
Validation loss: 2.864309343377419

Epoch: 5| Step: 3
Training loss: 3.093990894533554
Validation loss: 2.868336190414867

Epoch: 5| Step: 4
Training loss: 3.157609703350984
Validation loss: 2.8651733637995336

Epoch: 5| Step: 5
Training loss: 3.1502438042159495
Validation loss: 2.8707253724357433

Epoch: 5| Step: 6
Training loss: 3.117151398796276
Validation loss: 2.873410931149852

Epoch: 5| Step: 7
Training loss: 3.4586286916576943
Validation loss: 2.8701976930119546

Epoch: 5| Step: 8
Training loss: 3.12897543765187
Validation loss: 2.860808545428759

Epoch: 5| Step: 9
Training loss: 2.6459675752321092
Validation loss: 2.8681583223413907

Epoch: 5| Step: 10
Training loss: 3.6937848859194906
Validation loss: 2.8725183056391828

Epoch: 207| Step: 0
Training loss: 3.324186188194298
Validation loss: 2.8626899226705476

Epoch: 5| Step: 1
Training loss: 3.3401060124093815
Validation loss: 2.863240263241424

Epoch: 5| Step: 2
Training loss: 3.368421854941373
Validation loss: 2.8740887332410106

Epoch: 5| Step: 3
Training loss: 3.397130675463026
Validation loss: 2.86629405618006

Epoch: 5| Step: 4
Training loss: 3.1382982735508067
Validation loss: 2.8694227568237087

Epoch: 5| Step: 5
Training loss: 2.941628659212643
Validation loss: 2.873001990701025

Epoch: 5| Step: 6
Training loss: 3.287898711767559
Validation loss: 2.8745395635898423

Epoch: 5| Step: 7
Training loss: 3.2132720257093164
Validation loss: 2.870288646312467

Epoch: 5| Step: 8
Training loss: 3.0258777637488765
Validation loss: 2.8631304994294426

Epoch: 5| Step: 9
Training loss: 3.0023637042845386
Validation loss: 2.8678863103873495

Epoch: 5| Step: 10
Training loss: 2.4606024620025853
Validation loss: 2.8617146956426454

Epoch: 208| Step: 0
Training loss: 3.1900155108322883
Validation loss: 2.86249766443063

Epoch: 5| Step: 1
Training loss: 3.472566721462637
Validation loss: 2.8623568088361657

Epoch: 5| Step: 2
Training loss: 3.442013222624114
Validation loss: 2.8610785663626945

Epoch: 5| Step: 3
Training loss: 3.4038814043841636
Validation loss: 2.8600641329414636

Epoch: 5| Step: 4
Training loss: 2.484481809227445
Validation loss: 2.86033191534889

Epoch: 5| Step: 5
Training loss: 3.2681470559230017
Validation loss: 2.858530351166645

Epoch: 5| Step: 6
Training loss: 3.4918761658619633
Validation loss: 2.8617177164160554

Epoch: 5| Step: 7
Training loss: 2.414263769357994
Validation loss: 2.8619222615832562

Epoch: 5| Step: 8
Training loss: 2.9432715673075256
Validation loss: 2.8581895500829804

Epoch: 5| Step: 9
Training loss: 2.8482516363610157
Validation loss: 2.8612658048038684

Epoch: 5| Step: 10
Training loss: 3.544977966369249
Validation loss: 2.860776480122097

Epoch: 209| Step: 0
Training loss: 2.5915989056363085
Validation loss: 2.8577519820241837

Epoch: 5| Step: 1
Training loss: 3.2934358566429207
Validation loss: 2.862622279383584

Epoch: 5| Step: 2
Training loss: 3.0591953119613127
Validation loss: 2.865590419250428

Epoch: 5| Step: 3
Training loss: 3.0673100591300404
Validation loss: 2.868382088851843

Epoch: 5| Step: 4
Training loss: 2.811527083918919
Validation loss: 2.868757305207007

Epoch: 5| Step: 5
Training loss: 3.1214935466816356
Validation loss: 2.8681696667857834

Epoch: 5| Step: 6
Training loss: 2.929157829723531
Validation loss: 2.868423308693869

Epoch: 5| Step: 7
Training loss: 4.092286758413435
Validation loss: 2.8805791447078772

Epoch: 5| Step: 8
Training loss: 3.1434480495562176
Validation loss: 2.8644368804157194

Epoch: 5| Step: 9
Training loss: 3.0373150427750137
Validation loss: 2.860962025932044

Epoch: 5| Step: 10
Training loss: 3.3454116542897547
Validation loss: 2.8576344662243023

Epoch: 210| Step: 0
Training loss: 2.802727995011249
Validation loss: 2.8571177879235696

Epoch: 5| Step: 1
Training loss: 2.620888259950943
Validation loss: 2.858053428166175

Epoch: 5| Step: 2
Training loss: 3.2475463701774356
Validation loss: 2.8569740356777644

Epoch: 5| Step: 3
Training loss: 3.168949074294763
Validation loss: 2.857803956744659

Epoch: 5| Step: 4
Training loss: 2.7155286624795636
Validation loss: 2.855699285031528

Epoch: 5| Step: 5
Training loss: 3.2484212121743234
Validation loss: 2.8561157348307495

Epoch: 5| Step: 6
Training loss: 3.0739604836618746
Validation loss: 2.8528258555519703

Epoch: 5| Step: 7
Training loss: 3.123675714275818
Validation loss: 2.8550205706372576

Epoch: 5| Step: 8
Training loss: 3.919022088590389
Validation loss: 2.8554831596580925

Epoch: 5| Step: 9
Training loss: 3.7170136829993634
Validation loss: 2.857208435306559

Epoch: 5| Step: 10
Training loss: 2.690032741389918
Validation loss: 2.854490215255408

Epoch: 211| Step: 0
Training loss: 3.5164105025246446
Validation loss: 2.852893854225847

Epoch: 5| Step: 1
Training loss: 2.9421891466197927
Validation loss: 2.8692095826350434

Epoch: 5| Step: 2
Training loss: 3.8319827202106698
Validation loss: 2.8622394686628585

Epoch: 5| Step: 3
Training loss: 3.7668410747513734
Validation loss: 2.856066460823771

Epoch: 5| Step: 4
Training loss: 2.9926179023531994
Validation loss: 2.8582024301932503

Epoch: 5| Step: 5
Training loss: 2.7186309086816403
Validation loss: 2.865426115007529

Epoch: 5| Step: 6
Training loss: 2.9796709465283175
Validation loss: 2.8691905644106157

Epoch: 5| Step: 7
Training loss: 2.4234026613074
Validation loss: 2.8698989624478557

Epoch: 5| Step: 8
Training loss: 3.271524311789817
Validation loss: 2.8633708982632107

Epoch: 5| Step: 9
Training loss: 2.6449685573331503
Validation loss: 2.8567943550529704

Epoch: 5| Step: 10
Training loss: 3.255867430019655
Validation loss: 2.860733144519438

Epoch: 212| Step: 0
Training loss: 4.0283966612083
Validation loss: 2.851196371643404

Epoch: 5| Step: 1
Training loss: 2.5576562459729995
Validation loss: 2.8534981076546937

Epoch: 5| Step: 2
Training loss: 2.78009780848949
Validation loss: 2.855725478813134

Epoch: 5| Step: 3
Training loss: 3.07119450992174
Validation loss: 2.8533553666604003

Epoch: 5| Step: 4
Training loss: 2.6782940057867255
Validation loss: 2.855111496512519

Epoch: 5| Step: 5
Training loss: 3.1870658429241447
Validation loss: 2.8548028618770553

Epoch: 5| Step: 6
Training loss: 3.0737744874355006
Validation loss: 2.8551980252443925

Epoch: 5| Step: 7
Training loss: 3.213617028208511
Validation loss: 2.856054720029607

Epoch: 5| Step: 8
Training loss: 3.0641541976474436
Validation loss: 2.858646154014572

Epoch: 5| Step: 9
Training loss: 3.587537886256694
Validation loss: 2.8538684457133323

Epoch: 5| Step: 10
Training loss: 3.165911400389655
Validation loss: 2.8521649438859673

Epoch: 213| Step: 0
Training loss: 3.0642169110084163
Validation loss: 2.8546116476578876

Epoch: 5| Step: 1
Training loss: 2.8728181604026486
Validation loss: 2.850988005921958

Epoch: 5| Step: 2
Training loss: 3.2326431429177465
Validation loss: 2.8487843675982756

Epoch: 5| Step: 3
Training loss: 3.5051812921456866
Validation loss: 2.8492469915067518

Epoch: 5| Step: 4
Training loss: 2.4942360234667604
Validation loss: 2.8528078433150794

Epoch: 5| Step: 5
Training loss: 3.2606521050187767
Validation loss: 2.8556390773842306

Epoch: 5| Step: 6
Training loss: 2.701459514889979
Validation loss: 2.8549729003361444

Epoch: 5| Step: 7
Training loss: 4.063864610804742
Validation loss: 2.861754664194376

Epoch: 5| Step: 8
Training loss: 2.950525825318942
Validation loss: 2.871434280172118

Epoch: 5| Step: 9
Training loss: 3.253630737510669
Validation loss: 2.8762638012600474

Epoch: 5| Step: 10
Training loss: 2.8968592045588957
Validation loss: 2.8977073088202383

Epoch: 214| Step: 0
Training loss: 3.5136045626542947
Validation loss: 2.8804866571217236

Epoch: 5| Step: 1
Training loss: 2.742044037546665
Validation loss: 2.8596957025926204

Epoch: 5| Step: 2
Training loss: 3.035186413942777
Validation loss: 2.8568903277282396

Epoch: 5| Step: 3
Training loss: 2.9553438761762796
Validation loss: 2.860142430511423

Epoch: 5| Step: 4
Training loss: 3.3382640292711985
Validation loss: 2.8514264033676215

Epoch: 5| Step: 5
Training loss: 3.378529998469974
Validation loss: 2.850205224943036

Epoch: 5| Step: 6
Training loss: 2.9322479046028582
Validation loss: 2.849023686429337

Epoch: 5| Step: 7
Training loss: 3.18679278138795
Validation loss: 2.8524709933550936

Epoch: 5| Step: 8
Training loss: 2.952257947439589
Validation loss: 2.8492694953342244

Epoch: 5| Step: 9
Training loss: 3.5812541488969614
Validation loss: 2.8492304556555403

Epoch: 5| Step: 10
Training loss: 2.7643063952466913
Validation loss: 2.846353033016577

Epoch: 215| Step: 0
Training loss: 2.9358767630571427
Validation loss: 2.8475832088948665

Epoch: 5| Step: 1
Training loss: 3.320611486997991
Validation loss: 2.848304716900718

Epoch: 5| Step: 2
Training loss: 3.167371587762222
Validation loss: 2.8609303154036394

Epoch: 5| Step: 3
Training loss: 2.970044626741973
Validation loss: 2.856285472541985

Epoch: 5| Step: 4
Training loss: 3.7236713574503186
Validation loss: 2.857331850774961

Epoch: 5| Step: 5
Training loss: 3.0752681894349774
Validation loss: 2.8614496345482916

Epoch: 5| Step: 6
Training loss: 2.6884891552670025
Validation loss: 2.8549659609221463

Epoch: 5| Step: 7
Training loss: 3.068446711141683
Validation loss: 2.8471225508651803

Epoch: 5| Step: 8
Training loss: 3.3339200139328113
Validation loss: 2.846922946877957

Epoch: 5| Step: 9
Training loss: 2.6183148589313103
Validation loss: 2.844492799392389

Epoch: 5| Step: 10
Training loss: 3.5646589998336746
Validation loss: 2.8461842414103278

Epoch: 216| Step: 0
Training loss: 3.0095694822728265
Validation loss: 2.8466598118017976

Epoch: 5| Step: 1
Training loss: 3.7093569310815973
Validation loss: 2.8470845235613247

Epoch: 5| Step: 2
Training loss: 2.939469671361237
Validation loss: 2.8463271384762026

Epoch: 5| Step: 3
Training loss: 3.543512708466484
Validation loss: 2.8467946162062523

Epoch: 5| Step: 4
Training loss: 2.8123824200953846
Validation loss: 2.8519630203668567

Epoch: 5| Step: 5
Training loss: 2.9349862563999083
Validation loss: 2.8460036016863777

Epoch: 5| Step: 6
Training loss: 3.006238173622138
Validation loss: 2.846704393690972

Epoch: 5| Step: 7
Training loss: 3.31437975252096
Validation loss: 2.8628677633452924

Epoch: 5| Step: 8
Training loss: 2.738366488927193
Validation loss: 2.8509070065149116

Epoch: 5| Step: 9
Training loss: 2.6082403034361596
Validation loss: 2.850104882311497

Epoch: 5| Step: 10
Training loss: 3.7756632998967232
Validation loss: 2.8516908165839685

Epoch: 217| Step: 0
Training loss: 3.1174585516161915
Validation loss: 2.8456998205655957

Epoch: 5| Step: 1
Training loss: 2.623066689763673
Validation loss: 2.843945957713255

Epoch: 5| Step: 2
Training loss: 2.7953399196279993
Validation loss: 2.8453169576644184

Epoch: 5| Step: 3
Training loss: 3.27876347377974
Validation loss: 2.8476365332634965

Epoch: 5| Step: 4
Training loss: 3.1429788299634067
Validation loss: 2.845824162130277

Epoch: 5| Step: 5
Training loss: 3.010251015370165
Validation loss: 2.851758940309783

Epoch: 5| Step: 6
Training loss: 3.1334404446846826
Validation loss: 2.8454054961022055

Epoch: 5| Step: 7
Training loss: 3.134617616005464
Validation loss: 2.841558331938617

Epoch: 5| Step: 8
Training loss: 3.74168593324545
Validation loss: 2.839479477353584

Epoch: 5| Step: 9
Training loss: 3.3425320697806638
Validation loss: 2.841351286808645

Epoch: 5| Step: 10
Training loss: 3.051488894401592
Validation loss: 2.845667981404785

Epoch: 218| Step: 0
Training loss: 3.3503653426726947
Validation loss: 2.842514973405464

Epoch: 5| Step: 1
Training loss: 3.0121788138596686
Validation loss: 2.8497418502416556

Epoch: 5| Step: 2
Training loss: 2.479810059564755
Validation loss: 2.8420835911292652

Epoch: 5| Step: 3
Training loss: 3.0716088739492737
Validation loss: 2.8440316146570983

Epoch: 5| Step: 4
Training loss: 2.9822744596630923
Validation loss: 2.8485821607963433

Epoch: 5| Step: 5
Training loss: 3.5147623996007145
Validation loss: 2.845303329052317

Epoch: 5| Step: 6
Training loss: 3.3924287138317553
Validation loss: 2.843083599826655

Epoch: 5| Step: 7
Training loss: 3.295365842384765
Validation loss: 2.8440049426897156

Epoch: 5| Step: 8
Training loss: 3.205253377768791
Validation loss: 2.846275803542251

Epoch: 5| Step: 9
Training loss: 3.177938144108271
Validation loss: 2.844087634979888

Epoch: 5| Step: 10
Training loss: 2.8311525441758794
Validation loss: 2.8436180398752495

Epoch: 219| Step: 0
Training loss: 3.2129583009589733
Validation loss: 2.843547507776334

Epoch: 5| Step: 1
Training loss: 3.171965198455816
Validation loss: 2.841387342736519

Epoch: 5| Step: 2
Training loss: 3.1870939706737977
Validation loss: 2.8445425748989006

Epoch: 5| Step: 3
Training loss: 3.1571693214633973
Validation loss: 2.841948771641519

Epoch: 5| Step: 4
Training loss: 3.1808653953108323
Validation loss: 2.847604397058112

Epoch: 5| Step: 5
Training loss: 3.1417336096743966
Validation loss: 2.837901225021992

Epoch: 5| Step: 6
Training loss: 3.454215175409219
Validation loss: 2.8410517456095454

Epoch: 5| Step: 7
Training loss: 3.1367874613037743
Validation loss: 2.837154678539394

Epoch: 5| Step: 8
Training loss: 2.993630800681436
Validation loss: 2.8437651884315014

Epoch: 5| Step: 9
Training loss: 2.5279832646986966
Validation loss: 2.8369456303085707

Epoch: 5| Step: 10
Training loss: 3.261175016664829
Validation loss: 2.8414070929119464

Epoch: 220| Step: 0
Training loss: 3.205455397509053
Validation loss: 2.846933620428333

Epoch: 5| Step: 1
Training loss: 2.6669989815914925
Validation loss: 2.8384482729719562

Epoch: 5| Step: 2
Training loss: 3.3047101536328305
Validation loss: 2.842270780250634

Epoch: 5| Step: 3
Training loss: 3.178145200952115
Validation loss: 2.8423375143626464

Epoch: 5| Step: 4
Training loss: 3.161848485126305
Validation loss: 2.837321149407923

Epoch: 5| Step: 5
Training loss: 3.514199607959474
Validation loss: 2.8448145011149766

Epoch: 5| Step: 6
Training loss: 3.3881441524423797
Validation loss: 2.8374679712877877

Epoch: 5| Step: 7
Training loss: 2.9099635527645304
Validation loss: 2.838374958785775

Epoch: 5| Step: 8
Training loss: 2.8090067892674946
Validation loss: 2.842920769545831

Epoch: 5| Step: 9
Training loss: 3.297624548005266
Validation loss: 2.839573864848854

Epoch: 5| Step: 10
Training loss: 2.890182543734634
Validation loss: 2.83845990956881

Epoch: 221| Step: 0
Training loss: 3.268851260773955
Validation loss: 2.838041110166529

Epoch: 5| Step: 1
Training loss: 3.0885974863978953
Validation loss: 2.83927262644859

Epoch: 5| Step: 2
Training loss: 3.233999184414319
Validation loss: 2.8369652116980135

Epoch: 5| Step: 3
Training loss: 2.2721566593667326
Validation loss: 2.835511496526659

Epoch: 5| Step: 4
Training loss: 3.59412680599316
Validation loss: 2.8358353534516625

Epoch: 5| Step: 5
Training loss: 3.225401440852112
Validation loss: 2.8369117689787937

Epoch: 5| Step: 6
Training loss: 2.760228382143067
Validation loss: 2.8408269200826126

Epoch: 5| Step: 7
Training loss: 2.8615284299556305
Validation loss: 2.838842003113959

Epoch: 5| Step: 8
Training loss: 3.8503932454797947
Validation loss: 2.8360545733872855

Epoch: 5| Step: 9
Training loss: 2.864338053981721
Validation loss: 2.840381497432774

Epoch: 5| Step: 10
Training loss: 3.148903937610797
Validation loss: 2.8377258958948532

Epoch: 222| Step: 0
Training loss: 3.1380957292453977
Validation loss: 2.8374290149882997

Epoch: 5| Step: 1
Training loss: 3.3967306125699928
Validation loss: 2.835911480524282

Epoch: 5| Step: 2
Training loss: 3.179155384875304
Validation loss: 2.841043070343867

Epoch: 5| Step: 3
Training loss: 2.9063541844880016
Validation loss: 2.842811440408176

Epoch: 5| Step: 4
Training loss: 2.730675947325676
Validation loss: 2.83526025776966

Epoch: 5| Step: 5
Training loss: 2.7836058850576597
Validation loss: 2.835272668783517

Epoch: 5| Step: 6
Training loss: 3.2628816461776378
Validation loss: 2.8400484389253404

Epoch: 5| Step: 7
Training loss: 3.382609795186146
Validation loss: 2.8329053286479757

Epoch: 5| Step: 8
Training loss: 2.934458680021066
Validation loss: 2.837704620420934

Epoch: 5| Step: 9
Training loss: 2.9542837947408107
Validation loss: 2.8474620646708253

Epoch: 5| Step: 10
Training loss: 3.7213146438083755
Validation loss: 2.845564031839293

Epoch: 223| Step: 0
Training loss: 2.587451042412417
Validation loss: 2.8357781250430607

Epoch: 5| Step: 1
Training loss: 3.026802339439854
Validation loss: 2.842113385879227

Epoch: 5| Step: 2
Training loss: 3.3367975988876495
Validation loss: 2.834498349315384

Epoch: 5| Step: 3
Training loss: 3.158680499345928
Validation loss: 2.8306561853910326

Epoch: 5| Step: 4
Training loss: 2.6581144184948666
Validation loss: 2.8324283177508924

Epoch: 5| Step: 5
Training loss: 3.368545152313721
Validation loss: 2.829305571566963

Epoch: 5| Step: 6
Training loss: 3.2649785182181934
Validation loss: 2.829169928407043

Epoch: 5| Step: 7
Training loss: 3.345158645676778
Validation loss: 2.8322012227175284

Epoch: 5| Step: 8
Training loss: 3.3528034607090493
Validation loss: 2.8295002600024337

Epoch: 5| Step: 9
Training loss: 3.543640140398163
Validation loss: 2.8292917661567554

Epoch: 5| Step: 10
Training loss: 2.5203032974103534
Validation loss: 2.837600984448285

Epoch: 224| Step: 0
Training loss: 2.899895396483617
Validation loss: 2.833556053979618

Epoch: 5| Step: 1
Training loss: 2.822349003282866
Validation loss: 2.8334066181248

Epoch: 5| Step: 2
Training loss: 3.0111059611871966
Validation loss: 2.840721906250889

Epoch: 5| Step: 3
Training loss: 3.3146366929499225
Validation loss: 2.843387384564402

Epoch: 5| Step: 4
Training loss: 3.1914778179609242
Validation loss: 2.846591950601476

Epoch: 5| Step: 5
Training loss: 3.0379781087723265
Validation loss: 2.8403837321930423

Epoch: 5| Step: 6
Training loss: 2.569768691581961
Validation loss: 2.8326954124987105

Epoch: 5| Step: 7
Training loss: 3.584120878275839
Validation loss: 2.828595469657815

Epoch: 5| Step: 8
Training loss: 3.6526834421744447
Validation loss: 2.8314371139672883

Epoch: 5| Step: 9
Training loss: 2.950960849813801
Validation loss: 2.82919448757186

Epoch: 5| Step: 10
Training loss: 3.323104869013162
Validation loss: 2.8332274864761193

Epoch: 225| Step: 0
Training loss: 3.5700173287278303
Validation loss: 2.8266464499284423

Epoch: 5| Step: 1
Training loss: 3.265071986341001
Validation loss: 2.8245702827793906

Epoch: 5| Step: 2
Training loss: 2.962317152859149
Validation loss: 2.8297516432456926

Epoch: 5| Step: 3
Training loss: 3.423219460212611
Validation loss: 2.827432459157688

Epoch: 5| Step: 4
Training loss: 2.9801945191460644
Validation loss: 2.828361777342051

Epoch: 5| Step: 5
Training loss: 3.083316046863933
Validation loss: 2.8360834913813946

Epoch: 5| Step: 6
Training loss: 3.244514237122053
Validation loss: 2.849993379358885

Epoch: 5| Step: 7
Training loss: 2.9946917619488778
Validation loss: 2.8549676832058175

Epoch: 5| Step: 8
Training loss: 3.3003218291593006
Validation loss: 2.8763714480160036

Epoch: 5| Step: 9
Training loss: 2.7483453107318017
Validation loss: 2.848909826702422

Epoch: 5| Step: 10
Training loss: 2.6644725316214344
Validation loss: 2.8320068159170266

Epoch: 226| Step: 0
Training loss: 3.6055491594500464
Validation loss: 2.828135417256636

Epoch: 5| Step: 1
Training loss: 2.5343363277998456
Validation loss: 2.8254295724907017

Epoch: 5| Step: 2
Training loss: 3.389051502960921
Validation loss: 2.8278985321194456

Epoch: 5| Step: 3
Training loss: 2.585308079023534
Validation loss: 2.827057733089701

Epoch: 5| Step: 4
Training loss: 3.267950808562243
Validation loss: 2.8288459894457185

Epoch: 5| Step: 5
Training loss: 2.9590821907821687
Validation loss: 2.8297295250618473

Epoch: 5| Step: 6
Training loss: 3.7484192377482786
Validation loss: 2.827786243296655

Epoch: 5| Step: 7
Training loss: 3.0660652116781835
Validation loss: 2.827023596443106

Epoch: 5| Step: 8
Training loss: 2.9263618820031327
Validation loss: 2.824234353004249

Epoch: 5| Step: 9
Training loss: 2.608779930743638
Validation loss: 2.825721817879245

Epoch: 5| Step: 10
Training loss: 3.5694460161719386
Validation loss: 2.824154465330555

Epoch: 227| Step: 0
Training loss: 3.3797994326160707
Validation loss: 2.824212796163509

Epoch: 5| Step: 1
Training loss: 2.5250410057741766
Validation loss: 2.823962021953431

Epoch: 5| Step: 2
Training loss: 2.5613840045566825
Validation loss: 2.8270779315903742

Epoch: 5| Step: 3
Training loss: 3.0006535136181687
Validation loss: 2.8242624933840714

Epoch: 5| Step: 4
Training loss: 3.4759197198093585
Validation loss: 2.8248279030161014

Epoch: 5| Step: 5
Training loss: 3.1221040658853405
Validation loss: 2.828376194579742

Epoch: 5| Step: 6
Training loss: 3.161854819123863
Validation loss: 2.8281269978826837

Epoch: 5| Step: 7
Training loss: 3.430242193807707
Validation loss: 2.8306519939467636

Epoch: 5| Step: 8
Training loss: 2.961677559435607
Validation loss: 2.8297757670347985

Epoch: 5| Step: 9
Training loss: 3.2521827410489648
Validation loss: 2.8259147501394515

Epoch: 5| Step: 10
Training loss: 3.4309974897125852
Validation loss: 2.8347641561065196

Epoch: 228| Step: 0
Training loss: 2.8857033560733387
Validation loss: 2.825417206252653

Epoch: 5| Step: 1
Training loss: 3.9423126599994442
Validation loss: 2.825232057353831

Epoch: 5| Step: 2
Training loss: 3.056121723626862
Validation loss: 2.825274242477365

Epoch: 5| Step: 3
Training loss: 2.636938105748287
Validation loss: 2.821928191711115

Epoch: 5| Step: 4
Training loss: 2.5683298551654308
Validation loss: 2.826170693039173

Epoch: 5| Step: 5
Training loss: 2.9295206658226416
Validation loss: 2.8220704202029254

Epoch: 5| Step: 6
Training loss: 3.4734303284303776
Validation loss: 2.82468057297209

Epoch: 5| Step: 7
Training loss: 3.1545772841209168
Validation loss: 2.8228309714301925

Epoch: 5| Step: 8
Training loss: 2.679575481242145
Validation loss: 2.8206765594906713

Epoch: 5| Step: 9
Training loss: 3.5725348503062686
Validation loss: 2.8252749883562225

Epoch: 5| Step: 10
Training loss: 3.213624298830404
Validation loss: 2.823669214014039

Epoch: 229| Step: 0
Training loss: 3.5003582907257007
Validation loss: 2.821757684675462

Epoch: 5| Step: 1
Training loss: 2.9865992381227304
Validation loss: 2.824679480238295

Epoch: 5| Step: 2
Training loss: 3.5539815683826106
Validation loss: 2.8247497937106703

Epoch: 5| Step: 3
Training loss: 3.2169084929121032
Validation loss: 2.8269175166587646

Epoch: 5| Step: 4
Training loss: 2.228579815300332
Validation loss: 2.8254587317006057

Epoch: 5| Step: 5
Training loss: 3.2141587186884375
Validation loss: 2.826268751473129

Epoch: 5| Step: 6
Training loss: 2.8821823961514057
Validation loss: 2.8381653545952825

Epoch: 5| Step: 7
Training loss: 3.2639256486558654
Validation loss: 2.8403279330605717

Epoch: 5| Step: 8
Training loss: 3.3671461487817633
Validation loss: 2.8701076782843007

Epoch: 5| Step: 9
Training loss: 2.595348371226835
Validation loss: 2.825577265413742

Epoch: 5| Step: 10
Training loss: 3.349503318064063
Validation loss: 2.825228511197732

Epoch: 230| Step: 0
Training loss: 3.0101334769731287
Validation loss: 2.820132568444517

Epoch: 5| Step: 1
Training loss: 3.3213463463984563
Validation loss: 2.8243152768311686

Epoch: 5| Step: 2
Training loss: 3.111589572838906
Validation loss: 2.8274688748235897

Epoch: 5| Step: 3
Training loss: 2.4240767776365817
Validation loss: 2.8238507776869026

Epoch: 5| Step: 4
Training loss: 2.666106483112945
Validation loss: 2.831110059983215

Epoch: 5| Step: 5
Training loss: 3.3561652884990014
Validation loss: 2.84612681035098

Epoch: 5| Step: 6
Training loss: 3.5144757236060697
Validation loss: 2.8508167981431414

Epoch: 5| Step: 7
Training loss: 2.8520321811930938
Validation loss: 2.8521954692361615

Epoch: 5| Step: 8
Training loss: 3.4848513427290424
Validation loss: 2.8590319789893424

Epoch: 5| Step: 9
Training loss: 3.1473335242691203
Validation loss: 2.839736208154795

Epoch: 5| Step: 10
Training loss: 3.4132171212718596
Validation loss: 2.8249516758772657

Epoch: 231| Step: 0
Training loss: 2.777801948018352
Validation loss: 2.825004974601882

Epoch: 5| Step: 1
Training loss: 3.2860099055302867
Validation loss: 2.825331943156781

Epoch: 5| Step: 2
Training loss: 3.1584220437614974
Validation loss: 2.8241151029793454

Epoch: 5| Step: 3
Training loss: 2.70733746534776
Validation loss: 2.824967326560534

Epoch: 5| Step: 4
Training loss: 3.1637408811271253
Validation loss: 2.822360238465995

Epoch: 5| Step: 5
Training loss: 2.8473151359801294
Validation loss: 2.8229127709897246

Epoch: 5| Step: 6
Training loss: 3.2380895247262083
Validation loss: 2.821615895614176

Epoch: 5| Step: 7
Training loss: 3.318295573069691
Validation loss: 2.822823191943512

Epoch: 5| Step: 8
Training loss: 3.745639809321868
Validation loss: 2.8195794338233657

Epoch: 5| Step: 9
Training loss: 3.483537924080325
Validation loss: 2.820093769936883

Epoch: 5| Step: 10
Training loss: 2.343074853929802
Validation loss: 2.819324695720706

Epoch: 232| Step: 0
Training loss: 2.957665076916985
Validation loss: 2.8244941141585307

Epoch: 5| Step: 1
Training loss: 3.686537406844394
Validation loss: 2.816259559000598

Epoch: 5| Step: 2
Training loss: 3.606448750167601
Validation loss: 2.8214744410676333

Epoch: 5| Step: 3
Training loss: 3.2406524333326074
Validation loss: 2.823042280825107

Epoch: 5| Step: 4
Training loss: 3.114610261492383
Validation loss: 2.8204752429953315

Epoch: 5| Step: 5
Training loss: 3.5130909921452074
Validation loss: 2.8239148840718613

Epoch: 5| Step: 6
Training loss: 2.383444080136135
Validation loss: 2.8267684290926436

Epoch: 5| Step: 7
Training loss: 3.0294545942380133
Validation loss: 2.8246754342152975

Epoch: 5| Step: 8
Training loss: 2.493308266736401
Validation loss: 2.8297367818455705

Epoch: 5| Step: 9
Training loss: 2.7733511038204766
Validation loss: 2.8232871282752043

Epoch: 5| Step: 10
Training loss: 3.2601146294034793
Validation loss: 2.82542670527766

Epoch: 233| Step: 0
Training loss: 2.9138658063435128
Validation loss: 2.8242473607370058

Epoch: 5| Step: 1
Training loss: 2.937439288871459
Validation loss: 2.8294170843007858

Epoch: 5| Step: 2
Training loss: 3.1428064769525195
Validation loss: 2.8241499937253636

Epoch: 5| Step: 3
Training loss: 3.742096519558834
Validation loss: 2.823850833973771

Epoch: 5| Step: 4
Training loss: 2.7095914021696013
Validation loss: 2.820203558877452

Epoch: 5| Step: 5
Training loss: 3.0724560580979627
Validation loss: 2.817217210033061

Epoch: 5| Step: 6
Training loss: 3.0214805874249047
Validation loss: 2.8152346443283105

Epoch: 5| Step: 7
Training loss: 3.4172769947307198
Validation loss: 2.8165363220687727

Epoch: 5| Step: 8
Training loss: 2.6549027560541654
Validation loss: 2.814391208793197

Epoch: 5| Step: 9
Training loss: 3.6184489808533398
Validation loss: 2.8136766367438715

Epoch: 5| Step: 10
Training loss: 2.8300125820028494
Validation loss: 2.8127561372822725

Epoch: 234| Step: 0
Training loss: 2.9726607414141495
Validation loss: 2.813621751229028

Epoch: 5| Step: 1
Training loss: 3.360726302076059
Validation loss: 2.818112920437298

Epoch: 5| Step: 2
Training loss: 2.8745772009405974
Validation loss: 2.8149341254407014

Epoch: 5| Step: 3
Training loss: 2.861796203448247
Validation loss: 2.8186709723128534

Epoch: 5| Step: 4
Training loss: 3.2248950556750198
Validation loss: 2.8276761567398263

Epoch: 5| Step: 5
Training loss: 2.8157395249593336
Validation loss: 2.823267714442057

Epoch: 5| Step: 6
Training loss: 2.8597898755545343
Validation loss: 2.8286114699605305

Epoch: 5| Step: 7
Training loss: 2.8031247176188283
Validation loss: 2.8441739222183657

Epoch: 5| Step: 8
Training loss: 3.2391360711125765
Validation loss: 2.8387655328893593

Epoch: 5| Step: 9
Training loss: 3.616165049583954
Validation loss: 2.824068282653577

Epoch: 5| Step: 10
Training loss: 3.686572200629482
Validation loss: 2.8138924090434925

Epoch: 235| Step: 0
Training loss: 3.271258300257623
Validation loss: 2.8130468750641584

Epoch: 5| Step: 1
Training loss: 2.622937618431499
Validation loss: 2.8106917407709955

Epoch: 5| Step: 2
Training loss: 2.740840831161393
Validation loss: 2.812681841697273

Epoch: 5| Step: 3
Training loss: 2.964704145881579
Validation loss: 2.8113736776609746

Epoch: 5| Step: 4
Training loss: 3.44116293212621
Validation loss: 2.8147280255084444

Epoch: 5| Step: 5
Training loss: 2.8220566193695062
Validation loss: 2.8096797434674756

Epoch: 5| Step: 6
Training loss: 2.7469579169872578
Validation loss: 2.809888353175973

Epoch: 5| Step: 7
Training loss: 3.3491669031734594
Validation loss: 2.8086332057424803

Epoch: 5| Step: 8
Training loss: 3.372847117664568
Validation loss: 2.811814981075074

Epoch: 5| Step: 9
Training loss: 3.5377518203662737
Validation loss: 2.8120510267081307

Epoch: 5| Step: 10
Training loss: 3.3297351649366536
Validation loss: 2.8113565989738953

Epoch: 236| Step: 0
Training loss: 3.1305405900069645
Validation loss: 2.8096535282723494

Epoch: 5| Step: 1
Training loss: 3.440987499796371
Validation loss: 2.8062214701911734

Epoch: 5| Step: 2
Training loss: 2.3753342644219186
Validation loss: 2.8113532970277118

Epoch: 5| Step: 3
Training loss: 3.5311438620491384
Validation loss: 2.8184045919282723

Epoch: 5| Step: 4
Training loss: 2.9826512976079784
Validation loss: 2.8371476810860248

Epoch: 5| Step: 5
Training loss: 3.5030441669594956
Validation loss: 2.834916208914234

Epoch: 5| Step: 6
Training loss: 3.028556649668126
Validation loss: 2.842117533360147

Epoch: 5| Step: 7
Training loss: 2.4669051218332156
Validation loss: 2.8517396429928548

Epoch: 5| Step: 8
Training loss: 2.924163248736505
Validation loss: 2.858850866935225

Epoch: 5| Step: 9
Training loss: 3.710994808356833
Validation loss: 2.844811413729989

Epoch: 5| Step: 10
Training loss: 2.9306652014430474
Validation loss: 2.831776231507955

Epoch: 237| Step: 0
Training loss: 2.6042898733875433
Validation loss: 2.8144025540815343

Epoch: 5| Step: 1
Training loss: 2.878570661304673
Validation loss: 2.809418493937498

Epoch: 5| Step: 2
Training loss: 3.598833419612069
Validation loss: 2.8074590557092765

Epoch: 5| Step: 3
Training loss: 2.641994685396542
Validation loss: 2.8088848875845085

Epoch: 5| Step: 4
Training loss: 3.6374311722473753
Validation loss: 2.809383305257164

Epoch: 5| Step: 5
Training loss: 3.4542336733906325
Validation loss: 2.807119865410699

Epoch: 5| Step: 6
Training loss: 3.044138143805931
Validation loss: 2.8088415207930555

Epoch: 5| Step: 7
Training loss: 2.9674732876148218
Validation loss: 2.806373606039591

Epoch: 5| Step: 8
Training loss: 3.06381913404777
Validation loss: 2.806937608592848

Epoch: 5| Step: 9
Training loss: 3.2775923915384597
Validation loss: 2.807498647476385

Epoch: 5| Step: 10
Training loss: 2.843568900912774
Validation loss: 2.805776905905687

Epoch: 238| Step: 0
Training loss: 3.441088381407433
Validation loss: 2.8073048143929196

Epoch: 5| Step: 1
Training loss: 2.9396190710529058
Validation loss: 2.8078713306113126

Epoch: 5| Step: 2
Training loss: 2.9955473280956255
Validation loss: 2.8040548051928127

Epoch: 5| Step: 3
Training loss: 3.4330219578206047
Validation loss: 2.80942959924094

Epoch: 5| Step: 4
Training loss: 2.851494106360881
Validation loss: 2.806224459345016

Epoch: 5| Step: 5
Training loss: 3.16660626671727
Validation loss: 2.8105988050501955

Epoch: 5| Step: 6
Training loss: 2.8820111574675726
Validation loss: 2.811925650303596

Epoch: 5| Step: 7
Training loss: 3.083650229038045
Validation loss: 2.8073406921035144

Epoch: 5| Step: 8
Training loss: 3.243775348895037
Validation loss: 2.8162357800477005

Epoch: 5| Step: 9
Training loss: 3.6599616097693364
Validation loss: 2.810359172867996

Epoch: 5| Step: 10
Training loss: 2.1619119803890507
Validation loss: 2.812356740568466

Epoch: 239| Step: 0
Training loss: 3.740941997152858
Validation loss: 2.812459174695063

Epoch: 5| Step: 1
Training loss: 2.6960183808750022
Validation loss: 2.816457837173817

Epoch: 5| Step: 2
Training loss: 3.3442055935514667
Validation loss: 2.8201379686490267

Epoch: 5| Step: 3
Training loss: 2.994901616386337
Validation loss: 2.8049845030224563

Epoch: 5| Step: 4
Training loss: 3.3298385578691603
Validation loss: 2.818914229597289

Epoch: 5| Step: 5
Training loss: 2.8935125002197974
Validation loss: 2.8093881635514797

Epoch: 5| Step: 6
Training loss: 3.0712649976700295
Validation loss: 2.807064174038683

Epoch: 5| Step: 7
Training loss: 2.6760692135195
Validation loss: 2.812968397616777

Epoch: 5| Step: 8
Training loss: 3.315320235905057
Validation loss: 2.8096015761882565

Epoch: 5| Step: 9
Training loss: 2.8184071706630283
Validation loss: 2.8057285314266167

Epoch: 5| Step: 10
Training loss: 3.165650522594238
Validation loss: 2.806548647616871

Epoch: 240| Step: 0
Training loss: 3.281949795168691
Validation loss: 2.8033356294803866

Epoch: 5| Step: 1
Training loss: 3.2065139334688357
Validation loss: 2.801119680345659

Epoch: 5| Step: 2
Training loss: 2.7741992173061845
Validation loss: 2.8025143059348223

Epoch: 5| Step: 3
Training loss: 3.0234605260952963
Validation loss: 2.7998641619861933

Epoch: 5| Step: 4
Training loss: 2.4754460944229915
Validation loss: 2.802325874576077

Epoch: 5| Step: 5
Training loss: 3.070350239063149
Validation loss: 2.803245968980215

Epoch: 5| Step: 6
Training loss: 3.2780445245368757
Validation loss: 2.8029135337891384

Epoch: 5| Step: 7
Training loss: 3.5472946926976365
Validation loss: 2.802792982406442

Epoch: 5| Step: 8
Training loss: 3.6643282340505947
Validation loss: 2.8010690846990087

Epoch: 5| Step: 9
Training loss: 2.96418459353756
Validation loss: 2.8018878948360015

Epoch: 5| Step: 10
Training loss: 2.600512226706031
Validation loss: 2.800188776250658

Epoch: 241| Step: 0
Training loss: 3.5047111139679696
Validation loss: 2.8038479247651553

Epoch: 5| Step: 1
Training loss: 3.5951500860513947
Validation loss: 2.8009921433715617

Epoch: 5| Step: 2
Training loss: 2.961896192608062
Validation loss: 2.8014918160935967

Epoch: 5| Step: 3
Training loss: 2.575903658030817
Validation loss: 2.8075694574308954

Epoch: 5| Step: 4
Training loss: 3.160767296938436
Validation loss: 2.802401866313822

Epoch: 5| Step: 5
Training loss: 3.14437748313871
Validation loss: 2.8006083597759504

Epoch: 5| Step: 6
Training loss: 3.0924511890059443
Validation loss: 2.800686352413114

Epoch: 5| Step: 7
Training loss: 3.094453057445119
Validation loss: 2.801179539667405

Epoch: 5| Step: 8
Training loss: 3.2821032186824866
Validation loss: 2.800884336290492

Epoch: 5| Step: 9
Training loss: 2.7293567057442605
Validation loss: 2.8038152043817557

Epoch: 5| Step: 10
Training loss: 2.8175553558246174
Validation loss: 2.809810911575186

Epoch: 242| Step: 0
Training loss: 3.105345755966495
Validation loss: 2.8078991729959433

Epoch: 5| Step: 1
Training loss: 2.9387668556239483
Validation loss: 2.8093642826362504

Epoch: 5| Step: 2
Training loss: 2.7985454664164555
Validation loss: 2.8071095245069344

Epoch: 5| Step: 3
Training loss: 3.0505819609704217
Validation loss: 2.8082246231046954

Epoch: 5| Step: 4
Training loss: 2.982472717211531
Validation loss: 2.801832362985627

Epoch: 5| Step: 5
Training loss: 3.313117635474433
Validation loss: 2.7980315653506316

Epoch: 5| Step: 6
Training loss: 3.40834247118433
Validation loss: 2.7969409602349176

Epoch: 5| Step: 7
Training loss: 3.247691288131144
Validation loss: 2.799221442059778

Epoch: 5| Step: 8
Training loss: 3.2585937148802744
Validation loss: 2.799198424143426

Epoch: 5| Step: 9
Training loss: 3.1296861226711585
Validation loss: 2.797582623331625

Epoch: 5| Step: 10
Training loss: 2.8569841238614857
Validation loss: 2.798478305454769

Epoch: 243| Step: 0
Training loss: 2.4807457476364854
Validation loss: 2.797685884295155

Epoch: 5| Step: 1
Training loss: 3.4164264098261103
Validation loss: 2.7949158798509712

Epoch: 5| Step: 2
Training loss: 3.3065862589206874
Validation loss: 2.7943049584741693

Epoch: 5| Step: 3
Training loss: 3.253271803534611
Validation loss: 2.7949732349954632

Epoch: 5| Step: 4
Training loss: 2.3676654597533586
Validation loss: 2.7959775040951635

Epoch: 5| Step: 5
Training loss: 3.545701425133172
Validation loss: 2.7946695814815348

Epoch: 5| Step: 6
Training loss: 2.680625995859044
Validation loss: 2.7961078214225843

Epoch: 5| Step: 7
Training loss: 3.06340075889439
Validation loss: 2.7985200932213177

Epoch: 5| Step: 8
Training loss: 3.556691302923546
Validation loss: 2.8030487591967135

Epoch: 5| Step: 9
Training loss: 3.2443361079913116
Validation loss: 2.797909165331869

Epoch: 5| Step: 10
Training loss: 2.8811455432550535
Validation loss: 2.8035204669073455

Epoch: 244| Step: 0
Training loss: 3.6304869068300003
Validation loss: 2.802638447706944

Epoch: 5| Step: 1
Training loss: 2.9244905076977523
Validation loss: 2.806914652125745

Epoch: 5| Step: 2
Training loss: 3.5037769646751884
Validation loss: 2.798442252744654

Epoch: 5| Step: 3
Training loss: 2.6879561281143487
Validation loss: 2.7962641032512363

Epoch: 5| Step: 4
Training loss: 3.0912035085326477
Validation loss: 2.797322712968488

Epoch: 5| Step: 5
Training loss: 3.2043921964632984
Validation loss: 2.8043388355412295

Epoch: 5| Step: 6
Training loss: 3.2638717398407153
Validation loss: 2.8024575798984794

Epoch: 5| Step: 7
Training loss: 2.8097468146027693
Validation loss: 2.800970911051789

Epoch: 5| Step: 8
Training loss: 3.0031280104734197
Validation loss: 2.7982153568973263

Epoch: 5| Step: 9
Training loss: 2.4817150919612945
Validation loss: 2.798107748843169

Epoch: 5| Step: 10
Training loss: 3.349234957663577
Validation loss: 2.797700183795361

Epoch: 245| Step: 0
Training loss: 3.6099125185270706
Validation loss: 2.7978651592795662

Epoch: 5| Step: 1
Training loss: 2.985611265077835
Validation loss: 2.7959406562646825

Epoch: 5| Step: 2
Training loss: 3.010421453733939
Validation loss: 2.795995606455839

Epoch: 5| Step: 3
Training loss: 3.1695781340409526
Validation loss: 2.801334014829162

Epoch: 5| Step: 4
Training loss: 2.942674988864365
Validation loss: 2.798942682019819

Epoch: 5| Step: 5
Training loss: 2.8848062872684324
Validation loss: 2.801556394757381

Epoch: 5| Step: 6
Training loss: 3.070169926019371
Validation loss: 2.7956720394560612

Epoch: 5| Step: 7
Training loss: 3.4338614887792276
Validation loss: 2.7947060268556108

Epoch: 5| Step: 8
Training loss: 2.2058208015680627
Validation loss: 2.793255333884014

Epoch: 5| Step: 9
Training loss: 3.3869403559814257
Validation loss: 2.7967068164512128

Epoch: 5| Step: 10
Training loss: 3.1698558375072223
Validation loss: 2.791997868471654

Epoch: 246| Step: 0
Training loss: 3.1437747779916307
Validation loss: 2.7954038333709366

Epoch: 5| Step: 1
Training loss: 2.8247034440475276
Validation loss: 2.799644634663309

Epoch: 5| Step: 2
Training loss: 1.9880115498489348
Validation loss: 2.800062385280138

Epoch: 5| Step: 3
Training loss: 2.9331330650051264
Validation loss: 2.80112471039003

Epoch: 5| Step: 4
Training loss: 3.0290119521672527
Validation loss: 2.8010189814597695

Epoch: 5| Step: 5
Training loss: 3.6457491329097653
Validation loss: 2.820504919705525

Epoch: 5| Step: 6
Training loss: 3.1059136989613068
Validation loss: 2.8165471772170134

Epoch: 5| Step: 7
Training loss: 3.055936358063782
Validation loss: 2.8027457702183254

Epoch: 5| Step: 8
Training loss: 3.5365580945932593
Validation loss: 2.7931959371187625

Epoch: 5| Step: 9
Training loss: 3.710205776954781
Validation loss: 2.791435243739038

Epoch: 5| Step: 10
Training loss: 2.7150394945450973
Validation loss: 2.791513180420061

Epoch: 247| Step: 0
Training loss: 2.599547926407954
Validation loss: 2.7924986695189413

Epoch: 5| Step: 1
Training loss: 3.134371476632569
Validation loss: 2.794233673380438

Epoch: 5| Step: 2
Training loss: 3.3614878552802017
Validation loss: 2.7945061796431268

Epoch: 5| Step: 3
Training loss: 3.016410448634089
Validation loss: 2.7942798183417388

Epoch: 5| Step: 4
Training loss: 3.7670284204426125
Validation loss: 2.7927435281226938

Epoch: 5| Step: 5
Training loss: 3.082945481384081
Validation loss: 2.794365581208936

Epoch: 5| Step: 6
Training loss: 2.511510101717258
Validation loss: 2.7932047114283822

Epoch: 5| Step: 7
Training loss: 3.7129548381809188
Validation loss: 2.794771568624149

Epoch: 5| Step: 8
Training loss: 3.335818429291481
Validation loss: 2.7932595759373187

Epoch: 5| Step: 9
Training loss: 2.859979784433905
Validation loss: 2.789191056735615

Epoch: 5| Step: 10
Training loss: 2.295465672772457
Validation loss: 2.79222611607193

Epoch: 248| Step: 0
Training loss: 3.2756267501165484
Validation loss: 2.792442341355573

Epoch: 5| Step: 1
Training loss: 3.341254042520586
Validation loss: 2.7935668204007573

Epoch: 5| Step: 2
Training loss: 2.59223618050658
Validation loss: 2.7989276176488085

Epoch: 5| Step: 3
Training loss: 3.004072921355487
Validation loss: 2.794303231828997

Epoch: 5| Step: 4
Training loss: 3.1502560647700695
Validation loss: 2.7974128217503176

Epoch: 5| Step: 5
Training loss: 3.4013691501573438
Validation loss: 2.809280300870122

Epoch: 5| Step: 6
Training loss: 2.936443707088127
Validation loss: 2.821726700129649

Epoch: 5| Step: 7
Training loss: 2.7935281686804996
Validation loss: 2.836722244341563

Epoch: 5| Step: 8
Training loss: 3.1807567101566483
Validation loss: 2.833427064516674

Epoch: 5| Step: 9
Training loss: 3.1063232781653105
Validation loss: 2.8257328826980737

Epoch: 5| Step: 10
Training loss: 3.239447702265071
Validation loss: 2.810544406720724

Epoch: 249| Step: 0
Training loss: 3.187213361231056
Validation loss: 2.792261784472264

Epoch: 5| Step: 1
Training loss: 3.322536307223351
Validation loss: 2.7926346397530537

Epoch: 5| Step: 2
Training loss: 3.436039562366171
Validation loss: 2.786748969663403

Epoch: 5| Step: 3
Training loss: 3.175271156326453
Validation loss: 2.789608854618676

Epoch: 5| Step: 4
Training loss: 2.8192980518973387
Validation loss: 2.7918576193752234

Epoch: 5| Step: 5
Training loss: 2.9666644349964906
Validation loss: 2.7930473846075454

Epoch: 5| Step: 6
Training loss: 3.457401165325361
Validation loss: 2.797764295606405

Epoch: 5| Step: 7
Training loss: 2.9837041769995776
Validation loss: 2.7932407335353386

Epoch: 5| Step: 8
Training loss: 2.8803033427916205
Validation loss: 2.793501473371105

Epoch: 5| Step: 9
Training loss: 2.969848750723318
Validation loss: 2.792651033361957

Epoch: 5| Step: 10
Training loss: 2.8446261554864356
Validation loss: 2.7904892695968346

Epoch: 250| Step: 0
Training loss: 2.8212391184409786
Validation loss: 2.790170933416785

Epoch: 5| Step: 1
Training loss: 3.3508381094080666
Validation loss: 2.7870550176711943

Epoch: 5| Step: 2
Training loss: 3.6339267129515065
Validation loss: 2.7896687890853378

Epoch: 5| Step: 3
Training loss: 3.351782873773652
Validation loss: 2.783422552762508

Epoch: 5| Step: 4
Training loss: 3.027985378073861
Validation loss: 2.787077165455708

Epoch: 5| Step: 5
Training loss: 2.866529841447526
Validation loss: 2.7863600923556735

Epoch: 5| Step: 6
Training loss: 2.5729921975934853
Validation loss: 2.7887848838580274

Epoch: 5| Step: 7
Training loss: 3.5403495284117352
Validation loss: 2.7898837312943177

Epoch: 5| Step: 8
Training loss: 3.317495789399454
Validation loss: 2.796147262646634

Epoch: 5| Step: 9
Training loss: 2.8458773861366247
Validation loss: 2.796343210847065

Epoch: 5| Step: 10
Training loss: 2.376700846340234
Validation loss: 2.798815667331825

Epoch: 251| Step: 0
Training loss: 2.9535709427889003
Validation loss: 2.8039787247661523

Epoch: 5| Step: 1
Training loss: 2.7843016266922085
Validation loss: 2.8112475551886646

Epoch: 5| Step: 2
Training loss: 3.064370965676839
Validation loss: 2.8144656988161945

Epoch: 5| Step: 3
Training loss: 3.1177161205911212
Validation loss: 2.8000435566114605

Epoch: 5| Step: 4
Training loss: 3.092730113220786
Validation loss: 2.8046597143967706

Epoch: 5| Step: 5
Training loss: 3.050935357923458
Validation loss: 2.79756691383499

Epoch: 5| Step: 6
Training loss: 2.4341762084495318
Validation loss: 2.8024516255694136

Epoch: 5| Step: 7
Training loss: 3.3980123319710804
Validation loss: 2.784002756051168

Epoch: 5| Step: 8
Training loss: 3.434145730082924
Validation loss: 2.785282766969868

Epoch: 5| Step: 9
Training loss: 3.4763844648058644
Validation loss: 2.7834688530063434

Epoch: 5| Step: 10
Training loss: 3.1207388245176895
Validation loss: 2.7868858381306225

Epoch: 252| Step: 0
Training loss: 3.8834237859012144
Validation loss: 2.7827738649528917

Epoch: 5| Step: 1
Training loss: 3.1258266118654583
Validation loss: 2.787765701023094

Epoch: 5| Step: 2
Training loss: 2.8594580466295656
Validation loss: 2.785057506218318

Epoch: 5| Step: 3
Training loss: 3.222274776190939
Validation loss: 2.7846947160593127

Epoch: 5| Step: 4
Training loss: 2.842506556037851
Validation loss: 2.782547111233653

Epoch: 5| Step: 5
Training loss: 2.942807050191324
Validation loss: 2.7827793777293914

Epoch: 5| Step: 6
Training loss: 3.4583397064763064
Validation loss: 2.785456712438147

Epoch: 5| Step: 7
Training loss: 3.1386729384624052
Validation loss: 2.7844603849320384

Epoch: 5| Step: 8
Training loss: 2.8969275147781843
Validation loss: 2.780489318067345

Epoch: 5| Step: 9
Training loss: 3.2707568279155144
Validation loss: 2.78119210098503

Epoch: 5| Step: 10
Training loss: 1.873133938767721
Validation loss: 2.7809060808049386

Epoch: 253| Step: 0
Training loss: 2.2990913337661327
Validation loss: 2.782904882565557

Epoch: 5| Step: 1
Training loss: 2.9589829246592982
Validation loss: 2.784311743854751

Epoch: 5| Step: 2
Training loss: 2.7627527009161854
Validation loss: 2.791374913708607

Epoch: 5| Step: 3
Training loss: 3.503229150236242
Validation loss: 2.7999024689515855

Epoch: 5| Step: 4
Training loss: 3.1272179933984234
Validation loss: 2.8202520077720408

Epoch: 5| Step: 5
Training loss: 2.8886208674819627
Validation loss: 2.7980538864583773

Epoch: 5| Step: 6
Training loss: 3.0986034200760875
Validation loss: 2.8085548705910313

Epoch: 5| Step: 7
Training loss: 3.4337540069434493
Validation loss: 2.7928044353500305

Epoch: 5| Step: 8
Training loss: 3.2722789380250252
Validation loss: 2.7901481605853102

Epoch: 5| Step: 9
Training loss: 3.5474264245606135
Validation loss: 2.7807065666268382

Epoch: 5| Step: 10
Training loss: 2.8534472781748974
Validation loss: 2.7819902587795218

Epoch: 254| Step: 0
Training loss: 2.6199370104374013
Validation loss: 2.7874800490931735

Epoch: 5| Step: 1
Training loss: 3.449079672751741
Validation loss: 2.7814466612693733

Epoch: 5| Step: 2
Training loss: 3.0266093489251262
Validation loss: 2.77996101665453

Epoch: 5| Step: 3
Training loss: 2.58964360587169
Validation loss: 2.7823536908892095

Epoch: 5| Step: 4
Training loss: 3.457293036080266
Validation loss: 2.781140736296396

Epoch: 5| Step: 5
Training loss: 3.4486268724817166
Validation loss: 2.7832406582016938

Epoch: 5| Step: 6
Training loss: 3.1809730274312478
Validation loss: 2.7846964818044597

Epoch: 5| Step: 7
Training loss: 3.1827581701571592
Validation loss: 2.785053686147849

Epoch: 5| Step: 8
Training loss: 2.7686688757867017
Validation loss: 2.780232139897995

Epoch: 5| Step: 9
Training loss: 2.8532323677108447
Validation loss: 2.7823192213713472

Epoch: 5| Step: 10
Training loss: 3.417490619459582
Validation loss: 2.782773358263327

Epoch: 255| Step: 0
Training loss: 2.859282945495661
Validation loss: 2.7815716336157736

Epoch: 5| Step: 1
Training loss: 3.2638935080060447
Validation loss: 2.7800185761310985

Epoch: 5| Step: 2
Training loss: 2.598529686040904
Validation loss: 2.7783110205892534

Epoch: 5| Step: 3
Training loss: 3.3928499436839887
Validation loss: 2.777974723855079

Epoch: 5| Step: 4
Training loss: 2.8259439224867062
Validation loss: 2.7793641102185895

Epoch: 5| Step: 5
Training loss: 3.1211230834040835
Validation loss: 2.780921609702599

Epoch: 5| Step: 6
Training loss: 3.209774057155089
Validation loss: 2.788899479287993

Epoch: 5| Step: 7
Training loss: 3.137038427193547
Validation loss: 2.7897259323096324

Epoch: 5| Step: 8
Training loss: 3.5270174029715613
Validation loss: 2.7908428646762853

Epoch: 5| Step: 9
Training loss: 2.7308938673719734
Validation loss: 2.788307734686014

Epoch: 5| Step: 10
Training loss: 3.2164818633232493
Validation loss: 2.788329119516728

Epoch: 256| Step: 0
Training loss: 2.9957037998964227
Validation loss: 2.79417165319058

Epoch: 5| Step: 1
Training loss: 2.8532328690760207
Validation loss: 2.7842064022085564

Epoch: 5| Step: 2
Training loss: 3.097039217785901
Validation loss: 2.7978583645631896

Epoch: 5| Step: 3
Training loss: 2.584464584329332
Validation loss: 2.785232305196628

Epoch: 5| Step: 4
Training loss: 3.4824352938082743
Validation loss: 2.7858662858494667

Epoch: 5| Step: 5
Training loss: 2.6355200183088607
Validation loss: 2.796903548556415

Epoch: 5| Step: 6
Training loss: 3.547578985451912
Validation loss: 2.801712023120046

Epoch: 5| Step: 7
Training loss: 3.3155794045264133
Validation loss: 2.7983939255361614

Epoch: 5| Step: 8
Training loss: 3.236914775491308
Validation loss: 2.7927175541840294

Epoch: 5| Step: 9
Training loss: 3.152260553521875
Validation loss: 2.7792911717566886

Epoch: 5| Step: 10
Training loss: 2.9051651109006245
Validation loss: 2.773385258664569

Epoch: 257| Step: 0
Training loss: 3.6637407824511947
Validation loss: 2.7773746573968268

Epoch: 5| Step: 1
Training loss: 2.985454583753582
Validation loss: 2.7765935082944058

Epoch: 5| Step: 2
Training loss: 3.1519475638292898
Validation loss: 2.7774039325245674

Epoch: 5| Step: 3
Training loss: 2.537084284211238
Validation loss: 2.779661859154519

Epoch: 5| Step: 4
Training loss: 3.206073278721226
Validation loss: 2.781280274069132

Epoch: 5| Step: 5
Training loss: 2.79125462997606
Validation loss: 2.781949652005755

Epoch: 5| Step: 6
Training loss: 3.4656966233828297
Validation loss: 2.787540492848879

Epoch: 5| Step: 7
Training loss: 3.1424323048731613
Validation loss: 2.786591795396206

Epoch: 5| Step: 8
Training loss: 2.7457510461667196
Validation loss: 2.7825911946222

Epoch: 5| Step: 9
Training loss: 3.048320407857409
Validation loss: 2.7886259811035066

Epoch: 5| Step: 10
Training loss: 3.2823153265016893
Validation loss: 2.7859582154138054

Epoch: 258| Step: 0
Training loss: 3.1555871550749357
Validation loss: 2.779357430306546

Epoch: 5| Step: 1
Training loss: 2.919328038485751
Validation loss: 2.7801855091176755

Epoch: 5| Step: 2
Training loss: 3.5370650222837003
Validation loss: 2.777612928366443

Epoch: 5| Step: 3
Training loss: 2.9100051738260424
Validation loss: 2.7752591048459827

Epoch: 5| Step: 4
Training loss: 2.0346709567900128
Validation loss: 2.7751470796393463

Epoch: 5| Step: 5
Training loss: 2.9088221826846885
Validation loss: 2.7776910258320155

Epoch: 5| Step: 6
Training loss: 3.4504660471279545
Validation loss: 2.772908694531777

Epoch: 5| Step: 7
Training loss: 2.9739636066521404
Validation loss: 2.775233467943447

Epoch: 5| Step: 8
Training loss: 3.3497521550746474
Validation loss: 2.773761430512813

Epoch: 5| Step: 9
Training loss: 3.245733247975964
Validation loss: 2.771815141231604

Epoch: 5| Step: 10
Training loss: 3.3494321370291957
Validation loss: 2.776911434995425

Epoch: 259| Step: 0
Training loss: 3.294617662027026
Validation loss: 2.7753367780511753

Epoch: 5| Step: 1
Training loss: 2.898619941665886
Validation loss: 2.7719916362838406

Epoch: 5| Step: 2
Training loss: 2.9458633838579447
Validation loss: 2.774605417804948

Epoch: 5| Step: 3
Training loss: 3.3794380960135366
Validation loss: 2.7731865299777976

Epoch: 5| Step: 4
Training loss: 2.774555679353808
Validation loss: 2.7772728686361634

Epoch: 5| Step: 5
Training loss: 3.2627853385701577
Validation loss: 2.7717315645225398

Epoch: 5| Step: 6
Training loss: 3.4831087694075715
Validation loss: 2.772902643468394

Epoch: 5| Step: 7
Training loss: 2.3963975214433915
Validation loss: 2.772371754327676

Epoch: 5| Step: 8
Training loss: 2.9531553559534394
Validation loss: 2.7742368057891573

Epoch: 5| Step: 9
Training loss: 3.574744214063978
Validation loss: 2.774523689050484

Epoch: 5| Step: 10
Training loss: 2.6563406536116156
Validation loss: 2.7808633019078415

Epoch: 260| Step: 0
Training loss: 2.577346776779539
Validation loss: 2.775360088087013

Epoch: 5| Step: 1
Training loss: 3.3852240091915964
Validation loss: 2.774941914076221

Epoch: 5| Step: 2
Training loss: 3.190004748397689
Validation loss: 2.7752155682512707

Epoch: 5| Step: 3
Training loss: 2.931207613445373
Validation loss: 2.773805607318342

Epoch: 5| Step: 4
Training loss: 2.7478561714768723
Validation loss: 2.772340492471296

Epoch: 5| Step: 5
Training loss: 3.1340795223661204
Validation loss: 2.7716491599817554

Epoch: 5| Step: 6
Training loss: 3.174204304629634
Validation loss: 2.7737530882469934

Epoch: 5| Step: 7
Training loss: 3.7783224579584886
Validation loss: 2.773132924963843

Epoch: 5| Step: 8
Training loss: 2.70220287669344
Validation loss: 2.775237977720213

Epoch: 5| Step: 9
Training loss: 2.692277255253038
Validation loss: 2.7781848906690296

Epoch: 5| Step: 10
Training loss: 3.3955250855632704
Validation loss: 2.768071934888134

Epoch: 261| Step: 0
Training loss: 3.033962805553317
Validation loss: 2.769028132877145

Epoch: 5| Step: 1
Training loss: 3.040946474556993
Validation loss: 2.768519411869493

Epoch: 5| Step: 2
Training loss: 3.3119254423678113
Validation loss: 2.7698356453850006

Epoch: 5| Step: 3
Training loss: 2.9163668523825637
Validation loss: 2.767951362782654

Epoch: 5| Step: 4
Training loss: 2.5926474560377137
Validation loss: 2.7692748019777262

Epoch: 5| Step: 5
Training loss: 3.420336512467817
Validation loss: 2.769946363847984

Epoch: 5| Step: 6
Training loss: 2.2418930445195606
Validation loss: 2.770711172740081

Epoch: 5| Step: 7
Training loss: 2.920560326834675
Validation loss: 2.7684281153951633

Epoch: 5| Step: 8
Training loss: 3.2046103406346824
Validation loss: 2.7751491295186157

Epoch: 5| Step: 9
Training loss: 3.5223275950728543
Validation loss: 2.7688592207978515

Epoch: 5| Step: 10
Training loss: 3.4831021982073307
Validation loss: 2.7655732321663695

Epoch: 262| Step: 0
Training loss: 3.9043084774636885
Validation loss: 2.769834619867709

Epoch: 5| Step: 1
Training loss: 2.8112361187420425
Validation loss: 2.767847073085238

Epoch: 5| Step: 2
Training loss: 3.332004202658028
Validation loss: 2.76564439206294

Epoch: 5| Step: 3
Training loss: 3.127822821748068
Validation loss: 2.7678829241249847

Epoch: 5| Step: 4
Training loss: 2.4742596145016016
Validation loss: 2.7628722212601637

Epoch: 5| Step: 5
Training loss: 2.8283989705112607
Validation loss: 2.7662328394292994

Epoch: 5| Step: 6
Training loss: 2.5516831583810284
Validation loss: 2.770084261037827

Epoch: 5| Step: 7
Training loss: 2.867077568087949
Validation loss: 2.766597375942271

Epoch: 5| Step: 8
Training loss: 3.38182254252148
Validation loss: 2.7701164525343

Epoch: 5| Step: 9
Training loss: 3.242216473185679
Validation loss: 2.768927267758093

Epoch: 5| Step: 10
Training loss: 3.0754708402588093
Validation loss: 2.7810124886595586

Epoch: 263| Step: 0
Training loss: 3.5720127990254134
Validation loss: 2.786891407625614

Epoch: 5| Step: 1
Training loss: 3.672376103398454
Validation loss: 2.7861841872912216

Epoch: 5| Step: 2
Training loss: 2.819699207523853
Validation loss: 2.780100548167408

Epoch: 5| Step: 3
Training loss: 2.6432620993881804
Validation loss: 2.7746938870480022

Epoch: 5| Step: 4
Training loss: 3.178470763055964
Validation loss: 2.77564481312623

Epoch: 5| Step: 5
Training loss: 2.8742890515534243
Validation loss: 2.7773839930540603

Epoch: 5| Step: 6
Training loss: 3.2103022854327876
Validation loss: 2.791265476903729

Epoch: 5| Step: 7
Training loss: 2.6583695874587097
Validation loss: 2.7745698698393295

Epoch: 5| Step: 8
Training loss: 3.1154240182773947
Validation loss: 2.771336059213908

Epoch: 5| Step: 9
Training loss: 2.6078174076754115
Validation loss: 2.7742418309784704

Epoch: 5| Step: 10
Training loss: 3.289144990661294
Validation loss: 2.766481817776332

Epoch: 264| Step: 0
Training loss: 3.029632766174141
Validation loss: 2.7678164158960636

Epoch: 5| Step: 1
Training loss: 2.3882400484184223
Validation loss: 2.763129053827072

Epoch: 5| Step: 2
Training loss: 2.94774965997137
Validation loss: 2.767571366619904

Epoch: 5| Step: 3
Training loss: 3.6424108226492176
Validation loss: 2.7673648279007557

Epoch: 5| Step: 4
Training loss: 3.123985736281964
Validation loss: 2.7649255573403213

Epoch: 5| Step: 5
Training loss: 2.3553657066365536
Validation loss: 2.767126477734037

Epoch: 5| Step: 6
Training loss: 3.0073441574295394
Validation loss: 2.767194666432574

Epoch: 5| Step: 7
Training loss: 3.7632075103954055
Validation loss: 2.767979513167918

Epoch: 5| Step: 8
Training loss: 3.2908397231366378
Validation loss: 2.7656962141811463

Epoch: 5| Step: 9
Training loss: 2.370850300742131
Validation loss: 2.7636371093938044

Epoch: 5| Step: 10
Training loss: 3.6373421598711433
Validation loss: 2.7608159252281657

Epoch: 265| Step: 0
Training loss: 2.9132537128500444
Validation loss: 2.766373740798869

Epoch: 5| Step: 1
Training loss: 3.3446745262831747
Validation loss: 2.762918848251287

Epoch: 5| Step: 2
Training loss: 3.1029951884766875
Validation loss: 2.773628677741765

Epoch: 5| Step: 3
Training loss: 2.9786763532453158
Validation loss: 2.7637202435292414

Epoch: 5| Step: 4
Training loss: 3.0877715636142744
Validation loss: 2.7648201966015042

Epoch: 5| Step: 5
Training loss: 2.840744442416738
Validation loss: 2.7606542582933664

Epoch: 5| Step: 6
Training loss: 3.248505762363729
Validation loss: 2.7667971533055993

Epoch: 5| Step: 7
Training loss: 2.7669676199542863
Validation loss: 2.7625595492825568

Epoch: 5| Step: 8
Training loss: 3.280799035463189
Validation loss: 2.765540071915342

Epoch: 5| Step: 9
Training loss: 3.1010584962230348
Validation loss: 2.764815657777885

Epoch: 5| Step: 10
Training loss: 3.059284624239689
Validation loss: 2.7732985974032407

Epoch: 266| Step: 0
Training loss: 2.9530600888823453
Validation loss: 2.779824323222562

Epoch: 5| Step: 1
Training loss: 3.174015318998832
Validation loss: 2.781108613411121

Epoch: 5| Step: 2
Training loss: 2.8469039697774785
Validation loss: 2.7839760974023653

Epoch: 5| Step: 3
Training loss: 3.302548701629658
Validation loss: 2.793834972518578

Epoch: 5| Step: 4
Training loss: 3.318391850286204
Validation loss: 2.7904361131916953

Epoch: 5| Step: 5
Training loss: 3.329909728146909
Validation loss: 2.800924635605983

Epoch: 5| Step: 6
Training loss: 2.833097017942331
Validation loss: 2.7872879607276295

Epoch: 5| Step: 7
Training loss: 3.034597220175404
Validation loss: 2.7803655602838577

Epoch: 5| Step: 8
Training loss: 2.834327766336125
Validation loss: 2.7670924948580518

Epoch: 5| Step: 9
Training loss: 3.3490549946663766
Validation loss: 2.7602993426907676

Epoch: 5| Step: 10
Training loss: 2.659820221727017
Validation loss: 2.769289016746481

Epoch: 267| Step: 0
Training loss: 2.4902477787629467
Validation loss: 2.760582995767945

Epoch: 5| Step: 1
Training loss: 3.4920259647430947
Validation loss: 2.7596922493710427

Epoch: 5| Step: 2
Training loss: 2.912080883600563
Validation loss: 2.7583276411096365

Epoch: 5| Step: 3
Training loss: 3.0238420082781827
Validation loss: 2.7587103974059106

Epoch: 5| Step: 4
Training loss: 2.842715232303048
Validation loss: 2.763445292377074

Epoch: 5| Step: 5
Training loss: 3.3516265222796875
Validation loss: 2.7623714736174243

Epoch: 5| Step: 6
Training loss: 2.910475745360379
Validation loss: 2.765127769615185

Epoch: 5| Step: 7
Training loss: 2.829017961851604
Validation loss: 2.761254642936692

Epoch: 5| Step: 8
Training loss: 2.91205763179215
Validation loss: 2.76392116195589

Epoch: 5| Step: 9
Training loss: 3.7688639153871715
Validation loss: 2.7621488133477334

Epoch: 5| Step: 10
Training loss: 3.1293556376430187
Validation loss: 2.7567545588803295

Epoch: 268| Step: 0
Training loss: 2.815030633681789
Validation loss: 2.755710341056667

Epoch: 5| Step: 1
Training loss: 3.179075289938362
Validation loss: 2.7565011789614875

Epoch: 5| Step: 2
Training loss: 3.064826859878103
Validation loss: 2.7602633225671696

Epoch: 5| Step: 3
Training loss: 3.412168488102358
Validation loss: 2.7629752225183637

Epoch: 5| Step: 4
Training loss: 3.6168696550165302
Validation loss: 2.771761091634317

Epoch: 5| Step: 5
Training loss: 2.5891442828709246
Validation loss: 2.76761643884886

Epoch: 5| Step: 6
Training loss: 3.1214599394554927
Validation loss: 2.7783854952568485

Epoch: 5| Step: 7
Training loss: 2.4561607868795234
Validation loss: 2.787291727149132

Epoch: 5| Step: 8
Training loss: 3.042958877802102
Validation loss: 2.804721268671011

Epoch: 5| Step: 9
Training loss: 3.358513016228429
Validation loss: 2.8176447893575864

Epoch: 5| Step: 10
Training loss: 2.866856028342486
Validation loss: 2.805002749239193

Epoch: 269| Step: 0
Training loss: 2.8287919243416795
Validation loss: 2.7885700481726627

Epoch: 5| Step: 1
Training loss: 2.2444651662018953
Validation loss: 2.765853970615919

Epoch: 5| Step: 2
Training loss: 3.0970370622683023
Validation loss: 2.76424526074436

Epoch: 5| Step: 3
Training loss: 2.9945366703883076
Validation loss: 2.761002333386042

Epoch: 5| Step: 4
Training loss: 3.0919913485604633
Validation loss: 2.7612951706077133

Epoch: 5| Step: 5
Training loss: 3.202674350206283
Validation loss: 2.7569957789093076

Epoch: 5| Step: 6
Training loss: 3.2166192863282266
Validation loss: 2.755126404945201

Epoch: 5| Step: 7
Training loss: 3.4926487150867422
Validation loss: 2.7544997579432615

Epoch: 5| Step: 8
Training loss: 3.2477401799636456
Validation loss: 2.754209545396759

Epoch: 5| Step: 9
Training loss: 3.0836816195795276
Validation loss: 2.7541048004969744

Epoch: 5| Step: 10
Training loss: 3.127289048116005
Validation loss: 2.7555685381085118

Epoch: 270| Step: 0
Training loss: 2.5104229136873344
Validation loss: 2.7564810138841063

Epoch: 5| Step: 1
Training loss: 3.005842559549294
Validation loss: 2.75478693310727

Epoch: 5| Step: 2
Training loss: 3.3072822790938785
Validation loss: 2.755656459345032

Epoch: 5| Step: 3
Training loss: 3.371484550376183
Validation loss: 2.761643707049049

Epoch: 5| Step: 4
Training loss: 2.6993878059056953
Validation loss: 2.7547206763846654

Epoch: 5| Step: 5
Training loss: 3.162566257431076
Validation loss: 2.7560899187373398

Epoch: 5| Step: 6
Training loss: 3.0778704697766512
Validation loss: 2.767600537026409

Epoch: 5| Step: 7
Training loss: 3.1932560428618055
Validation loss: 2.7628052926944155

Epoch: 5| Step: 8
Training loss: 2.9035306944777446
Validation loss: 2.7753337851891184

Epoch: 5| Step: 9
Training loss: 2.8613924507487867
Validation loss: 2.770222417886569

Epoch: 5| Step: 10
Training loss: 3.6130273348283426
Validation loss: 2.7696700527431557

Epoch: 271| Step: 0
Training loss: 3.111252414431158
Validation loss: 2.7555206521604627

Epoch: 5| Step: 1
Training loss: 2.5993442185219573
Validation loss: 2.753673642843445

Epoch: 5| Step: 2
Training loss: 3.1160139967832965
Validation loss: 2.7546331831674173

Epoch: 5| Step: 3
Training loss: 2.9127888286616277
Validation loss: 2.759361691139073

Epoch: 5| Step: 4
Training loss: 3.098426905780788
Validation loss: 2.758896189577215

Epoch: 5| Step: 5
Training loss: 3.2319491959912905
Validation loss: 2.760889588559579

Epoch: 5| Step: 6
Training loss: 3.0414731386532767
Validation loss: 2.764118468119233

Epoch: 5| Step: 7
Training loss: 3.288656685410417
Validation loss: 2.7661216090211043

Epoch: 5| Step: 8
Training loss: 3.240164619784875
Validation loss: 2.7625742273358207

Epoch: 5| Step: 9
Training loss: 3.297818161984769
Validation loss: 2.7631862365446644

Epoch: 5| Step: 10
Training loss: 2.825837363987662
Validation loss: 2.7605699926520186

Epoch: 272| Step: 0
Training loss: 2.7868792539787806
Validation loss: 2.7591766448158013

Epoch: 5| Step: 1
Training loss: 2.9195647056322516
Validation loss: 2.7560172080092684

Epoch: 5| Step: 2
Training loss: 3.5747300746358945
Validation loss: 2.755959045859436

Epoch: 5| Step: 3
Training loss: 3.424606835290492
Validation loss: 2.755372993193079

Epoch: 5| Step: 4
Training loss: 3.0566351649811456
Validation loss: 2.7559779887383455

Epoch: 5| Step: 5
Training loss: 3.245584128871943
Validation loss: 2.7550081309456558

Epoch: 5| Step: 6
Training loss: 3.2561563723643654
Validation loss: 2.757566487358805

Epoch: 5| Step: 7
Training loss: 3.125986935217873
Validation loss: 2.7572608899702846

Epoch: 5| Step: 8
Training loss: 2.4294042882191667
Validation loss: 2.7656590695023917

Epoch: 5| Step: 9
Training loss: 2.6704766255984027
Validation loss: 2.7644073306661467

Epoch: 5| Step: 10
Training loss: 3.0532090299477037
Validation loss: 2.76226122463667

Epoch: 273| Step: 0
Training loss: 2.71028661472095
Validation loss: 2.7644445292584683

Epoch: 5| Step: 1
Training loss: 3.1586439666039716
Validation loss: 2.7690818858631974

Epoch: 5| Step: 2
Training loss: 3.277294426820819
Validation loss: 2.8106283753426227

Epoch: 5| Step: 3
Training loss: 2.592935549163434
Validation loss: 2.7818480334103786

Epoch: 5| Step: 4
Training loss: 3.198185084175336
Validation loss: 2.784133243461521

Epoch: 5| Step: 5
Training loss: 3.1971752454582307
Validation loss: 2.781414361263291

Epoch: 5| Step: 6
Training loss: 3.306072116386017
Validation loss: 2.765179534663081

Epoch: 5| Step: 7
Training loss: 2.869108382966389
Validation loss: 2.7580230947614126

Epoch: 5| Step: 8
Training loss: 2.910496716136879
Validation loss: 2.756269614876038

Epoch: 5| Step: 9
Training loss: 3.1309326315606953
Validation loss: 2.7487564817876495

Epoch: 5| Step: 10
Training loss: 3.354822240858855
Validation loss: 2.751309396336015

Epoch: 274| Step: 0
Training loss: 3.1932712741096254
Validation loss: 2.75225895032731

Epoch: 5| Step: 1
Training loss: 3.067817742167503
Validation loss: 2.7509354951349305

Epoch: 5| Step: 2
Training loss: 3.2590457036716445
Validation loss: 2.74958651707222

Epoch: 5| Step: 3
Training loss: 2.62834662592721
Validation loss: 2.754436307915541

Epoch: 5| Step: 4
Training loss: 2.911718822056529
Validation loss: 2.7522921541602834

Epoch: 5| Step: 5
Training loss: 2.7352668397714726
Validation loss: 2.751667209042662

Epoch: 5| Step: 6
Training loss: 3.6090724537532397
Validation loss: 2.7535639505709795

Epoch: 5| Step: 7
Training loss: 3.3741880782460734
Validation loss: 2.7481254936458743

Epoch: 5| Step: 8
Training loss: 3.168750144461905
Validation loss: 2.7498912640624744

Epoch: 5| Step: 9
Training loss: 2.900000138118346
Validation loss: 2.754498386076291

Epoch: 5| Step: 10
Training loss: 2.7359838493773965
Validation loss: 2.7617976839980805

Epoch: 275| Step: 0
Training loss: 3.462283042968744
Validation loss: 2.7607418522733607

Epoch: 5| Step: 1
Training loss: 3.4926730166199915
Validation loss: 2.7702763799771857

Epoch: 5| Step: 2
Training loss: 2.771427425474174
Validation loss: 2.7899876815071725

Epoch: 5| Step: 3
Training loss: 3.065057892991605
Validation loss: 2.777745278452052

Epoch: 5| Step: 4
Training loss: 2.801113050484439
Validation loss: 2.772384761271832

Epoch: 5| Step: 5
Training loss: 2.570410172945913
Validation loss: 2.7635529541857737

Epoch: 5| Step: 6
Training loss: 2.8717639789561535
Validation loss: 2.7577569293556587

Epoch: 5| Step: 7
Training loss: 3.6419946279889395
Validation loss: 2.7507876408339955

Epoch: 5| Step: 8
Training loss: 3.041286096323386
Validation loss: 2.7488164041985925

Epoch: 5| Step: 9
Training loss: 3.0576235814668853
Validation loss: 2.74422946447908

Epoch: 5| Step: 10
Training loss: 2.6843555596283837
Validation loss: 2.7484360785062267

Epoch: 276| Step: 0
Training loss: 3.155497697365443
Validation loss: 2.7477114757918994

Epoch: 5| Step: 1
Training loss: 3.3303447359366065
Validation loss: 2.7475506062669997

Epoch: 5| Step: 2
Training loss: 3.4185526844945713
Validation loss: 2.745983536009452

Epoch: 5| Step: 3
Training loss: 2.8851254496413943
Validation loss: 2.7500892822300242

Epoch: 5| Step: 4
Training loss: 3.3407266799397157
Validation loss: 2.7471252109057893

Epoch: 5| Step: 5
Training loss: 3.0698246459086906
Validation loss: 2.745041475900732

Epoch: 5| Step: 6
Training loss: 2.9946677185061277
Validation loss: 2.747298826064031

Epoch: 5| Step: 7
Training loss: 2.384521171918973
Validation loss: 2.7473345607932567

Epoch: 5| Step: 8
Training loss: 2.71512897557444
Validation loss: 2.745493752342766

Epoch: 5| Step: 9
Training loss: 3.302235083397381
Validation loss: 2.7501702819935803

Epoch: 5| Step: 10
Training loss: 2.916127963498775
Validation loss: 2.748853453781604

Epoch: 277| Step: 0
Training loss: 3.225016003946028
Validation loss: 2.748768285440114

Epoch: 5| Step: 1
Training loss: 3.2758552890437422
Validation loss: 2.753886581649718

Epoch: 5| Step: 2
Training loss: 3.341039824891531
Validation loss: 2.745605514035665

Epoch: 5| Step: 3
Training loss: 3.11300217587413
Validation loss: 2.7523812754143537

Epoch: 5| Step: 4
Training loss: 2.7124914283441215
Validation loss: 2.7481544973178593

Epoch: 5| Step: 5
Training loss: 3.1479063130243587
Validation loss: 2.753683844605052

Epoch: 5| Step: 6
Training loss: 3.2779556448858282
Validation loss: 2.7490095058892408

Epoch: 5| Step: 7
Training loss: 2.996390714687168
Validation loss: 2.743934085637439

Epoch: 5| Step: 8
Training loss: 2.875568831188931
Validation loss: 2.747444214380535

Epoch: 5| Step: 9
Training loss: 3.39026186356453
Validation loss: 2.7450351383333085

Epoch: 5| Step: 10
Training loss: 1.8422071175990746
Validation loss: 2.747181911136742

Epoch: 278| Step: 0
Training loss: 2.7552326876760382
Validation loss: 2.7541011543804523

Epoch: 5| Step: 1
Training loss: 3.0971379080920376
Validation loss: 2.7461619064323384

Epoch: 5| Step: 2
Training loss: 2.6488397793498684
Validation loss: 2.7572642845878317

Epoch: 5| Step: 3
Training loss: 2.8960820006674264
Validation loss: 2.764376966406238

Epoch: 5| Step: 4
Training loss: 3.268665413281753
Validation loss: 2.7678985140465375

Epoch: 5| Step: 5
Training loss: 3.641057328516465
Validation loss: 2.7682499215919227

Epoch: 5| Step: 6
Training loss: 3.130510430930794
Validation loss: 2.7867906536532288

Epoch: 5| Step: 7
Training loss: 2.981208279555675
Validation loss: 2.7872486121257882

Epoch: 5| Step: 8
Training loss: 2.9536051687796716
Validation loss: 2.756339016201654

Epoch: 5| Step: 9
Training loss: 3.047665381008415
Validation loss: 2.7520205559646658

Epoch: 5| Step: 10
Training loss: 3.154189844352865
Validation loss: 2.7459729018578565

Epoch: 279| Step: 0
Training loss: 2.5246686736929007
Validation loss: 2.751229702038996

Epoch: 5| Step: 1
Training loss: 2.942240521990955
Validation loss: 2.7451030632939752

Epoch: 5| Step: 2
Training loss: 2.8399510422368635
Validation loss: 2.7445840118203164

Epoch: 5| Step: 3
Training loss: 2.8265110700745804
Validation loss: 2.7445156508680877

Epoch: 5| Step: 4
Training loss: 3.0263235428141213
Validation loss: 2.744216726724587

Epoch: 5| Step: 5
Training loss: 2.867239221423398
Validation loss: 2.744778493316571

Epoch: 5| Step: 6
Training loss: 3.3896347920443435
Validation loss: 2.743853719309737

Epoch: 5| Step: 7
Training loss: 3.579473782657163
Validation loss: 2.742726326368285

Epoch: 5| Step: 8
Training loss: 2.996859337026897
Validation loss: 2.741672310061431

Epoch: 5| Step: 9
Training loss: 3.239561189205785
Validation loss: 2.740518603459798

Epoch: 5| Step: 10
Training loss: 3.371090638125012
Validation loss: 2.7436009027758934

Epoch: 280| Step: 0
Training loss: 2.854163084004699
Validation loss: 2.7426561730396384

Epoch: 5| Step: 1
Training loss: 3.1243001535679893
Validation loss: 2.754240357765919

Epoch: 5| Step: 2
Training loss: 3.2515137888290297
Validation loss: 2.747383352248494

Epoch: 5| Step: 3
Training loss: 2.2828801222752464
Validation loss: 2.7626434804887148

Epoch: 5| Step: 4
Training loss: 3.3325815942595405
Validation loss: 2.7756257675578486

Epoch: 5| Step: 5
Training loss: 2.6986658438158604
Validation loss: 2.762062597755712

Epoch: 5| Step: 6
Training loss: 3.181581724967008
Validation loss: 2.747364867995781

Epoch: 5| Step: 7
Training loss: 3.171008212413036
Validation loss: 2.749219040529022

Epoch: 5| Step: 8
Training loss: 2.9951625605362535
Validation loss: 2.7457775521541503

Epoch: 5| Step: 9
Training loss: 3.274738499342307
Validation loss: 2.74200866114177

Epoch: 5| Step: 10
Training loss: 3.3054527316587765
Validation loss: 2.7396321517903637

Epoch: 281| Step: 0
Training loss: 2.762939787505088
Validation loss: 2.7441469571595185

Epoch: 5| Step: 1
Training loss: 3.6534064557305865
Validation loss: 2.741660688119277

Epoch: 5| Step: 2
Training loss: 3.1115356299487282
Validation loss: 2.736623190810932

Epoch: 5| Step: 3
Training loss: 2.92625238065692
Validation loss: 2.7382454645319037

Epoch: 5| Step: 4
Training loss: 3.2292518030244137
Validation loss: 2.741166697403933

Epoch: 5| Step: 5
Training loss: 3.076008025150223
Validation loss: 2.7414415366992593

Epoch: 5| Step: 6
Training loss: 2.95399793206661
Validation loss: 2.737749568156472

Epoch: 5| Step: 7
Training loss: 2.8865662819702442
Validation loss: 2.739218708916143

Epoch: 5| Step: 8
Training loss: 3.0154804728765536
Validation loss: 2.7398082385525373

Epoch: 5| Step: 9
Training loss: 2.860203357215865
Validation loss: 2.737670040988221

Epoch: 5| Step: 10
Training loss: 3.0302921630202126
Validation loss: 2.7373954636115747

Epoch: 282| Step: 0
Training loss: 2.627923155301246
Validation loss: 2.7366615778448913

Epoch: 5| Step: 1
Training loss: 2.4236414220372504
Validation loss: 2.7446474364829747

Epoch: 5| Step: 2
Training loss: 3.3878685782388267
Validation loss: 2.7452126631348497

Epoch: 5| Step: 3
Training loss: 3.1872112666984185
Validation loss: 2.7512015908617458

Epoch: 5| Step: 4
Training loss: 3.2969555596366837
Validation loss: 2.767415936923321

Epoch: 5| Step: 5
Training loss: 2.8478821297267367
Validation loss: 2.772178222357819

Epoch: 5| Step: 6
Training loss: 2.7850007900599896
Validation loss: 2.769542865140735

Epoch: 5| Step: 7
Training loss: 3.3673186309841903
Validation loss: 2.7658079705679004

Epoch: 5| Step: 8
Training loss: 3.1163752747720306
Validation loss: 2.7498204814976366

Epoch: 5| Step: 9
Training loss: 3.2586945362002298
Validation loss: 2.747379778393389

Epoch: 5| Step: 10
Training loss: 3.148320425426813
Validation loss: 2.7406139483795937

Epoch: 283| Step: 0
Training loss: 3.348231939360082
Validation loss: 2.734442280353266

Epoch: 5| Step: 1
Training loss: 2.969737320403484
Validation loss: 2.740578536676698

Epoch: 5| Step: 2
Training loss: 2.9077005355572605
Validation loss: 2.7355807672722436

Epoch: 5| Step: 3
Training loss: 3.293161334541231
Validation loss: 2.7362653422906127

Epoch: 5| Step: 4
Training loss: 3.0223883649405203
Validation loss: 2.7383050580357704

Epoch: 5| Step: 5
Training loss: 3.2761800198029047
Validation loss: 2.735153880486785

Epoch: 5| Step: 6
Training loss: 3.3477739026328246
Validation loss: 2.7369252537146602

Epoch: 5| Step: 7
Training loss: 2.7744904574410407
Validation loss: 2.738623809253415

Epoch: 5| Step: 8
Training loss: 2.4533483318547633
Validation loss: 2.7365822054827738

Epoch: 5| Step: 9
Training loss: 2.568713400921126
Validation loss: 2.7330361571885953

Epoch: 5| Step: 10
Training loss: 3.5476568091416647
Validation loss: 2.7346247677035205

Epoch: 284| Step: 0
Training loss: 2.9064312950110534
Validation loss: 2.738814705624122

Epoch: 5| Step: 1
Training loss: 3.0146946237756125
Validation loss: 2.7344489246694548

Epoch: 5| Step: 2
Training loss: 3.1354238989525878
Validation loss: 2.7454424163713074

Epoch: 5| Step: 3
Training loss: 2.7009200435923058
Validation loss: 2.7409161976799745

Epoch: 5| Step: 4
Training loss: 3.088043498647021
Validation loss: 2.7525270188331716

Epoch: 5| Step: 5
Training loss: 2.8441579337497798
Validation loss: 2.757375984792111

Epoch: 5| Step: 6
Training loss: 3.0325287943178214
Validation loss: 2.751533994045856

Epoch: 5| Step: 7
Training loss: 3.4326294118736813
Validation loss: 2.7531328711721295

Epoch: 5| Step: 8
Training loss: 3.6646687670983837
Validation loss: 2.7510323679549735

Epoch: 5| Step: 9
Training loss: 2.3282959126455642
Validation loss: 2.7500019381116374

Epoch: 5| Step: 10
Training loss: 3.2225803435662774
Validation loss: 2.7392888220631133

Epoch: 285| Step: 0
Training loss: 2.6082525523131284
Validation loss: 2.740248262346831

Epoch: 5| Step: 1
Training loss: 2.946033662695632
Validation loss: 2.7322173012653796

Epoch: 5| Step: 2
Training loss: 2.905655010394164
Validation loss: 2.7374666536077337

Epoch: 5| Step: 3
Training loss: 3.6698502822397505
Validation loss: 2.7349937702190568

Epoch: 5| Step: 4
Training loss: 2.6747702811884437
Validation loss: 2.735273458653404

Epoch: 5| Step: 5
Training loss: 3.2303280782457726
Validation loss: 2.7314450675343647

Epoch: 5| Step: 6
Training loss: 2.7213290905443555
Validation loss: 2.736573508182384

Epoch: 5| Step: 7
Training loss: 2.9049404023929783
Validation loss: 2.7319015805886693

Epoch: 5| Step: 8
Training loss: 3.683424685857149
Validation loss: 2.7332901975883135

Epoch: 5| Step: 9
Training loss: 3.0710558585947094
Validation loss: 2.734755429759869

Epoch: 5| Step: 10
Training loss: 2.9022752386660575
Validation loss: 2.729088110890282

Epoch: 286| Step: 0
Training loss: 2.729867413273981
Validation loss: 2.7335823562669206

Epoch: 5| Step: 1
Training loss: 2.9744723132511024
Validation loss: 2.74134070863157

Epoch: 5| Step: 2
Training loss: 3.4840596830421835
Validation loss: 2.7375247750608294

Epoch: 5| Step: 3
Training loss: 3.241686973083231
Validation loss: 2.7415273749626694

Epoch: 5| Step: 4
Training loss: 2.9459645488027744
Validation loss: 2.7481281569851155

Epoch: 5| Step: 5
Training loss: 2.9964290665012796
Validation loss: 2.745405402929721

Epoch: 5| Step: 6
Training loss: 2.7318216663985213
Validation loss: 2.7466329114350865

Epoch: 5| Step: 7
Training loss: 3.1787019369112204
Validation loss: 2.738740591533256

Epoch: 5| Step: 8
Training loss: 3.1539970893241693
Validation loss: 2.7510474700114185

Epoch: 5| Step: 9
Training loss: 3.4382083509778587
Validation loss: 2.74976940250953

Epoch: 5| Step: 10
Training loss: 2.344200497882739
Validation loss: 2.743979823609785

Epoch: 287| Step: 0
Training loss: 3.3481237025042114
Validation loss: 2.745664137336839

Epoch: 5| Step: 1
Training loss: 3.068836430033663
Validation loss: 2.730802915505107

Epoch: 5| Step: 2
Training loss: 2.902132789060796
Validation loss: 2.731465271963334

Epoch: 5| Step: 3
Training loss: 3.0828212793982153
Validation loss: 2.7336686166807267

Epoch: 5| Step: 4
Training loss: 3.0008124205130633
Validation loss: 2.7344347181698883

Epoch: 5| Step: 5
Training loss: 3.473191038818116
Validation loss: 2.7345836319561783

Epoch: 5| Step: 6
Training loss: 2.6136366712245835
Validation loss: 2.7293787018044906

Epoch: 5| Step: 7
Training loss: 2.9560437184922024
Validation loss: 2.732565564925075

Epoch: 5| Step: 8
Training loss: 2.777593201756838
Validation loss: 2.728937526597029

Epoch: 5| Step: 9
Training loss: 3.4128005010741305
Validation loss: 2.727716654550853

Epoch: 5| Step: 10
Training loss: 2.7260007088227165
Validation loss: 2.7293867636007754

Epoch: 288| Step: 0
Training loss: 3.162150693155781
Validation loss: 2.7288029558381686

Epoch: 5| Step: 1
Training loss: 2.881325769979685
Validation loss: 2.7328575262136026

Epoch: 5| Step: 2
Training loss: 3.2485655039658856
Validation loss: 2.7281165063804727

Epoch: 5| Step: 3
Training loss: 3.38118121346896
Validation loss: 2.7343420839452657

Epoch: 5| Step: 4
Training loss: 3.3538429309369135
Validation loss: 2.740081961327862

Epoch: 5| Step: 5
Training loss: 2.735427653824956
Validation loss: 2.7376974267923067

Epoch: 5| Step: 6
Training loss: 2.7584542454459435
Validation loss: 2.7322380592066704

Epoch: 5| Step: 7
Training loss: 3.2518286328929813
Validation loss: 2.7286291606845237

Epoch: 5| Step: 8
Training loss: 2.870692135494852
Validation loss: 2.731203863333806

Epoch: 5| Step: 9
Training loss: 2.6840784337597547
Validation loss: 2.737152789734453

Epoch: 5| Step: 10
Training loss: 3.054726212590372
Validation loss: 2.7370419913865307

Epoch: 289| Step: 0
Training loss: 3.234169921270507
Validation loss: 2.741839721715729

Epoch: 5| Step: 1
Training loss: 2.9295537078825102
Validation loss: 2.751613264929329

Epoch: 5| Step: 2
Training loss: 3.210600378154841
Validation loss: 2.7374998795299588

Epoch: 5| Step: 3
Training loss: 2.52747147722309
Validation loss: 2.7354464324210643

Epoch: 5| Step: 4
Training loss: 2.5978867966301897
Validation loss: 2.7435546641768016

Epoch: 5| Step: 5
Training loss: 3.089385373613065
Validation loss: 2.732517422689772

Epoch: 5| Step: 6
Training loss: 3.5700066433371913
Validation loss: 2.7309354022769723

Epoch: 5| Step: 7
Training loss: 3.0860487519503095
Validation loss: 2.7337728326605273

Epoch: 5| Step: 8
Training loss: 3.220267521425184
Validation loss: 2.730682157679393

Epoch: 5| Step: 9
Training loss: 3.0154766777602857
Validation loss: 2.72941640503267

Epoch: 5| Step: 10
Training loss: 2.811049786838229
Validation loss: 2.7285962110183606

Epoch: 290| Step: 0
Training loss: 2.8880541117028993
Validation loss: 2.7251211801186135

Epoch: 5| Step: 1
Training loss: 3.0271030650291038
Validation loss: 2.730889858884614

Epoch: 5| Step: 2
Training loss: 2.9132787555613313
Validation loss: 2.722345924838502

Epoch: 5| Step: 3
Training loss: 3.210927995728026
Validation loss: 2.723227910948669

Epoch: 5| Step: 4
Training loss: 3.5998565539285456
Validation loss: 2.724462038872011

Epoch: 5| Step: 5
Training loss: 2.9892589291181353
Validation loss: 2.7327167579652176

Epoch: 5| Step: 6
Training loss: 3.086820915383246
Validation loss: 2.726782165624163

Epoch: 5| Step: 7
Training loss: 2.345846941983561
Validation loss: 2.7322510263891564

Epoch: 5| Step: 8
Training loss: 3.0754553356943077
Validation loss: 2.740752523511869

Epoch: 5| Step: 9
Training loss: 3.32750269843149
Validation loss: 2.7416551478326254

Epoch: 5| Step: 10
Training loss: 2.8264551449153164
Validation loss: 2.7452788654451474

Epoch: 291| Step: 0
Training loss: 3.323950500064627
Validation loss: 2.7295071513862617

Epoch: 5| Step: 1
Training loss: 3.56641052847498
Validation loss: 2.7378199342943175

Epoch: 5| Step: 2
Training loss: 2.9861464111449636
Validation loss: 2.730358130164675

Epoch: 5| Step: 3
Training loss: 2.7173259995947725
Validation loss: 2.7322059581280818

Epoch: 5| Step: 4
Training loss: 2.8568208887704416
Validation loss: 2.7223823411818606

Epoch: 5| Step: 5
Training loss: 3.063613377812373
Validation loss: 2.7292331223113973

Epoch: 5| Step: 6
Training loss: 2.8818705190550515
Validation loss: 2.72536134705166

Epoch: 5| Step: 7
Training loss: 3.326786828887357
Validation loss: 2.7294492621433517

Epoch: 5| Step: 8
Training loss: 3.099983332189235
Validation loss: 2.7285482881333154

Epoch: 5| Step: 9
Training loss: 2.666734803839251
Validation loss: 2.7254520722775197

Epoch: 5| Step: 10
Training loss: 2.789452960894828
Validation loss: 2.726814999007052

Epoch: 292| Step: 0
Training loss: 3.2946327141381535
Validation loss: 2.72554372191307

Epoch: 5| Step: 1
Training loss: 2.708015208022718
Validation loss: 2.730518274716184

Epoch: 5| Step: 2
Training loss: 2.80103346621409
Validation loss: 2.7206633156283098

Epoch: 5| Step: 3
Training loss: 2.9743155261027567
Validation loss: 2.732489363877229

Epoch: 5| Step: 4
Training loss: 3.355725954654113
Validation loss: 2.7442820310296567

Epoch: 5| Step: 5
Training loss: 3.309274218414233
Validation loss: 2.730728220882508

Epoch: 5| Step: 6
Training loss: 2.884966616644011
Validation loss: 2.737791520623229

Epoch: 5| Step: 7
Training loss: 3.111017761268054
Validation loss: 2.7233448401592453

Epoch: 5| Step: 8
Training loss: 3.3450897955139065
Validation loss: 2.728690284221142

Epoch: 5| Step: 9
Training loss: 2.5798669652129393
Validation loss: 2.718388419410975

Epoch: 5| Step: 10
Training loss: 2.920132367256211
Validation loss: 2.726674219671546

Epoch: 293| Step: 0
Training loss: 2.501633396609402
Validation loss: 2.7226172252984417

Epoch: 5| Step: 1
Training loss: 3.4302977972626914
Validation loss: 2.7290326420360382

Epoch: 5| Step: 2
Training loss: 3.0008662880406267
Validation loss: 2.7307288921330612

Epoch: 5| Step: 3
Training loss: 2.8207907654232995
Validation loss: 2.724533550342206

Epoch: 5| Step: 4
Training loss: 3.2051794395264346
Validation loss: 2.724000140413026

Epoch: 5| Step: 5
Training loss: 3.1584643159812886
Validation loss: 2.7266266644815946

Epoch: 5| Step: 6
Training loss: 2.8247405819231566
Validation loss: 2.724940355650473

Epoch: 5| Step: 7
Training loss: 2.6249627610244564
Validation loss: 2.7300114292171624

Epoch: 5| Step: 8
Training loss: 3.14659969940155
Validation loss: 2.7224801348891607

Epoch: 5| Step: 9
Training loss: 2.9439367020477976
Validation loss: 2.721782582344913

Epoch: 5| Step: 10
Training loss: 3.693104897078169
Validation loss: 2.725279679537103

Epoch: 294| Step: 0
Training loss: 3.35051492178275
Validation loss: 2.7204448399292183

Epoch: 5| Step: 1
Training loss: 3.713866802318873
Validation loss: 2.7211599111173754

Epoch: 5| Step: 2
Training loss: 2.9376665433382043
Validation loss: 2.7188176434392464

Epoch: 5| Step: 3
Training loss: 3.188707160497451
Validation loss: 2.7196014847429795

Epoch: 5| Step: 4
Training loss: 2.5899574404426886
Validation loss: 2.7279470721954477

Epoch: 5| Step: 5
Training loss: 3.022764618982507
Validation loss: 2.7216679453345836

Epoch: 5| Step: 6
Training loss: 2.714776303119018
Validation loss: 2.720554578460679

Epoch: 5| Step: 7
Training loss: 2.8033059630567916
Validation loss: 2.7176913844326047

Epoch: 5| Step: 8
Training loss: 2.7804150131619307
Validation loss: 2.721347631058124

Epoch: 5| Step: 9
Training loss: 3.0502718257156025
Validation loss: 2.7238427105495244

Epoch: 5| Step: 10
Training loss: 3.112204945991586
Validation loss: 2.728704683162987

Epoch: 295| Step: 0
Training loss: 3.5545251830214113
Validation loss: 2.7228813808633614

Epoch: 5| Step: 1
Training loss: 2.4717447007821676
Validation loss: 2.7311143316872175

Epoch: 5| Step: 2
Training loss: 2.3313327682570066
Validation loss: 2.736129230845773

Epoch: 5| Step: 3
Training loss: 2.5550130000968805
Validation loss: 2.746173457980858

Epoch: 5| Step: 4
Training loss: 3.335720653767078
Validation loss: 2.767273575785817

Epoch: 5| Step: 5
Training loss: 3.655986809020171
Validation loss: 2.7546174828044667

Epoch: 5| Step: 6
Training loss: 3.400197943366996
Validation loss: 2.750679435585858

Epoch: 5| Step: 7
Training loss: 2.594606373063193
Validation loss: 2.7508596640897998

Epoch: 5| Step: 8
Training loss: 3.3585676775654822
Validation loss: 2.7396412838657223

Epoch: 5| Step: 9
Training loss: 2.6351326247829183
Validation loss: 2.7271483816989632

Epoch: 5| Step: 10
Training loss: 3.1331799070522672
Validation loss: 2.7227878780905104

Epoch: 296| Step: 0
Training loss: 2.8342915952748933
Validation loss: 2.717998284262435

Epoch: 5| Step: 1
Training loss: 3.498933629664873
Validation loss: 2.7171162623621066

Epoch: 5| Step: 2
Training loss: 3.031623424062947
Validation loss: 2.711551295224581

Epoch: 5| Step: 3
Training loss: 2.405679610384014
Validation loss: 2.7189805693658786

Epoch: 5| Step: 4
Training loss: 2.7561195948193657
Validation loss: 2.713484563780355

Epoch: 5| Step: 5
Training loss: 3.534228663699401
Validation loss: 2.719103076315163

Epoch: 5| Step: 6
Training loss: 2.9456226782543764
Validation loss: 2.7125497843951933

Epoch: 5| Step: 7
Training loss: 3.318553934573733
Validation loss: 2.720138505469625

Epoch: 5| Step: 8
Training loss: 3.302995541723455
Validation loss: 2.7149992537004075

Epoch: 5| Step: 9
Training loss: 2.7948974778918583
Validation loss: 2.7155356759432583

Epoch: 5| Step: 10
Training loss: 2.699255494503878
Validation loss: 2.717683740735678

Epoch: 297| Step: 0
Training loss: 2.406892170613273
Validation loss: 2.7194434047733593

Epoch: 5| Step: 1
Training loss: 3.6327112983635654
Validation loss: 2.7186289991270574

Epoch: 5| Step: 2
Training loss: 3.261020462304155
Validation loss: 2.717129469656508

Epoch: 5| Step: 3
Training loss: 3.516308120480448
Validation loss: 2.7226824855465823

Epoch: 5| Step: 4
Training loss: 2.777111360294507
Validation loss: 2.7219099992774343

Epoch: 5| Step: 5
Training loss: 3.1961937321083878
Validation loss: 2.719710418375776

Epoch: 5| Step: 6
Training loss: 3.166956804603069
Validation loss: 2.726325835815974

Epoch: 5| Step: 7
Training loss: 2.7791564434117033
Validation loss: 2.726895190600548

Epoch: 5| Step: 8
Training loss: 2.9331595636684926
Validation loss: 2.7189362353361353

Epoch: 5| Step: 9
Training loss: 2.8263714659890913
Validation loss: 2.718006152501113

Epoch: 5| Step: 10
Training loss: 2.5486111954201927
Validation loss: 2.7215738413427175

Epoch: 298| Step: 0
Training loss: 2.959214970129902
Validation loss: 2.7314690975261264

Epoch: 5| Step: 1
Training loss: 2.860993307789159
Validation loss: 2.726700652548256

Epoch: 5| Step: 2
Training loss: 2.9275959330801946
Validation loss: 2.730311730205503

Epoch: 5| Step: 3
Training loss: 2.644760324763958
Validation loss: 2.7349999370238627

Epoch: 5| Step: 4
Training loss: 2.5706870319237765
Validation loss: 2.73483490388492

Epoch: 5| Step: 5
Training loss: 3.446531050010506
Validation loss: 2.7422687892541324

Epoch: 5| Step: 6
Training loss: 3.034765819834834
Validation loss: 2.7472823633905232

Epoch: 5| Step: 7
Training loss: 3.482670251500776
Validation loss: 2.74106412897376

Epoch: 5| Step: 8
Training loss: 3.1792495763390995
Validation loss: 2.749645662459083

Epoch: 5| Step: 9
Training loss: 3.5126406061124387
Validation loss: 2.7354118779051664

Epoch: 5| Step: 10
Training loss: 2.416785620907812
Validation loss: 2.719891400146237

Epoch: 299| Step: 0
Training loss: 3.072458075663358
Validation loss: 2.7129813297478202

Epoch: 5| Step: 1
Training loss: 3.3688090020216417
Validation loss: 2.714852682166678

Epoch: 5| Step: 2
Training loss: 2.8843771557371074
Validation loss: 2.7120648376740513

Epoch: 5| Step: 3
Training loss: 2.847820680159264
Validation loss: 2.7130609900306255

Epoch: 5| Step: 4
Training loss: 3.2924080186883637
Validation loss: 2.7149565345069138

Epoch: 5| Step: 5
Training loss: 2.706447081404578
Validation loss: 2.7159890986671775

Epoch: 5| Step: 6
Training loss: 3.007395529640905
Validation loss: 2.712984947971558

Epoch: 5| Step: 7
Training loss: 3.110413651018838
Validation loss: 2.7109328217876967

Epoch: 5| Step: 8
Training loss: 3.4717766556429694
Validation loss: 2.714311918190315

Epoch: 5| Step: 9
Training loss: 2.7371503423752843
Validation loss: 2.711060361887596

Epoch: 5| Step: 10
Training loss: 2.723773918449489
Validation loss: 2.712699221009263

Epoch: 300| Step: 0
Training loss: 3.2590528729466954
Validation loss: 2.712288183163872

Epoch: 5| Step: 1
Training loss: 3.1833576887174346
Validation loss: 2.7075415404365866

Epoch: 5| Step: 2
Training loss: 2.7464547279525418
Validation loss: 2.715194326106792

Epoch: 5| Step: 3
Training loss: 2.984387143095387
Validation loss: 2.7333000533611305

Epoch: 5| Step: 4
Training loss: 2.5998876180569575
Validation loss: 2.724791745622422

Epoch: 5| Step: 5
Training loss: 2.8616165796901782
Validation loss: 2.728659546933035

Epoch: 5| Step: 6
Training loss: 3.8449066406741905
Validation loss: 2.734825983549715

Epoch: 5| Step: 7
Training loss: 3.134796655804358
Validation loss: 2.7562567392995647

Epoch: 5| Step: 8
Training loss: 2.5345467656227822
Validation loss: 2.720676513242085

Epoch: 5| Step: 9
Training loss: 3.110449217216983
Validation loss: 2.7111603161630953

Epoch: 5| Step: 10
Training loss: 2.903691303712545
Validation loss: 2.7140569789048516

Testing loss: 2.933607710663861
