Epoch: 1| Step: 0
Training loss: 5.623277187347412
Validation loss: 5.4867154359817505
Epoch: 1| Step: 1
Training loss: 5.303531646728516
Validation loss: 4.957589626312256
Epoch: 1| Step: 2
Training loss: 4.75067663192749
Validation loss: 4.833240628242493
Epoch: 1| Step: 3
Training loss: 4.774678707122803
Validation loss: 4.825552940368652
Epoch: 1| Step: 4
Training loss: 4.934232234954834
Validation loss: 4.895521640777588
Epoch: 1| Step: 5
Training loss: 5.045162677764893
Validation loss: 4.782446384429932
Epoch: 1| Step: 6
Training loss: 4.68361759185791
Validation loss: 4.756518721580505
Epoch: 1| Step: 7
Training loss: 5.703769683837891
Validation loss: 4.713280916213989
Epoch: 1| Step: 8
Training loss: 4.535165786743164
Validation loss: 4.670205116271973
Epoch: 1| Step: 9
Training loss: 5.078317165374756
Validation loss: 4.69176459312439
Epoch: 2| Step: 0
Training loss: 5.043193340301514
Validation loss: 4.678009390830994
Epoch: 2| Step: 1
Training loss: 4.42982816696167
Validation loss: 4.637569546699524
Epoch: 2| Step: 2
Training loss: 4.337988376617432
Validation loss: 4.648596286773682
Epoch: 2| Step: 3
Training loss: 4.187315464019775
Validation loss: 4.557306170463562
Epoch: 2| Step: 4
Training loss: 5.076850891113281
Validation loss: 4.608120799064636
Epoch: 2| Step: 5
Training loss: 5.475763320922852
Validation loss: 4.591582953929901
Epoch: 2| Step: 6
Training loss: 5.016080856323242
Validation loss: 4.479698538780212
Epoch: 2| Step: 7
Training loss: 4.792309761047363
Validation loss: 4.473487973213196
Epoch: 2| Step: 8
Training loss: 3.7974963188171387
Validation loss: 4.531860589981079
Epoch: 2| Step: 9
Training loss: 5.061416149139404
Validation loss: 4.420413017272949
Epoch: 3| Step: 0
Training loss: 4.190235137939453
Validation loss: 4.4041441679000854
Epoch: 3| Step: 1
Training loss: 4.347485542297363
Validation loss: 4.41089129447937
Epoch: 3| Step: 2
Training loss: 4.608791351318359
Validation loss: 4.348823547363281
Epoch: 3| Step: 3
Training loss: 4.492546081542969
Validation loss: 4.272104740142822
Epoch: 3| Step: 4
Training loss: 4.946572780609131
Validation loss: 4.314174294471741
Epoch: 3| Step: 5
Training loss: 5.187326431274414
Validation loss: 4.217995584011078
Epoch: 3| Step: 6
Training loss: 4.206623554229736
Validation loss: 4.1958178877830505
Epoch: 3| Step: 7
Training loss: 4.121753215789795
Validation loss: 4.318181872367859
Epoch: 3| Step: 8
Training loss: 4.112024307250977
Validation loss: 4.261552214622498
Epoch: 3| Step: 9
Training loss: 4.503511428833008
Validation loss: 4.1264413595199585
Epoch: 4| Step: 0
Training loss: 3.911444902420044
Validation loss: 4.126506268978119
Epoch: 4| Step: 1
Training loss: 3.8393447399139404
Validation loss: 4.1254812479019165
Epoch: 4| Step: 2
Training loss: 5.055251121520996
Validation loss: 4.0615004897117615
Epoch: 4| Step: 3
Training loss: 4.307612419128418
Validation loss: 3.9954686164855957
Epoch: 4| Step: 4
Training loss: 3.94472074508667
Validation loss: 3.9640594720840454
Epoch: 4| Step: 5
Training loss: 4.444628715515137
Validation loss: 3.9310197234153748
Epoch: 4| Step: 6
Training loss: 3.7980432510375977
Validation loss: 3.891235589981079
Epoch: 4| Step: 7
Training loss: 4.202933311462402
Validation loss: 3.957828938961029
Epoch: 4| Step: 8
Training loss: 4.529244422912598
Validation loss: 3.9603582620620728
Epoch: 4| Step: 9
Training loss: 4.324991226196289
Validation loss: 3.922074615955353
Epoch: 5| Step: 0
Training loss: 3.7339024543762207
Validation loss: 3.8707785606384277
Epoch: 5| Step: 1
Training loss: 4.0660552978515625
Validation loss: 3.821905791759491
Epoch: 5| Step: 2
Training loss: 3.975543975830078
Validation loss: 3.868236005306244
Epoch: 5| Step: 3
Training loss: 4.237984657287598
Validation loss: 3.821618139743805
Epoch: 5| Step: 4
Training loss: 4.108363151550293
Validation loss: 3.781404733657837
Epoch: 5| Step: 5
Training loss: 3.8485398292541504
Validation loss: 3.7326990365982056
Epoch: 5| Step: 6
Training loss: 4.54266357421875
Validation loss: 3.708551824092865
Epoch: 5| Step: 7
Training loss: 3.539186954498291
Validation loss: 3.677545964717865
Epoch: 5| Step: 8
Training loss: 4.261539936065674
Validation loss: 3.693373441696167
Epoch: 5| Step: 9
Training loss: 3.8170862197875977
Validation loss: 3.5589773654937744
Epoch: 6| Step: 0
Training loss: 3.767749786376953
Validation loss: 3.7047494053840637
Epoch: 6| Step: 1
Training loss: 3.8833823204040527
Validation loss: 3.663222014904022
Epoch: 6| Step: 2
Training loss: 3.897826671600342
Validation loss: 3.5613460540771484
Epoch: 6| Step: 3
Training loss: 3.812687873840332
Validation loss: 3.608832538127899
Epoch: 6| Step: 4
Training loss: 4.2137041091918945
Validation loss: 3.5599597096443176
Epoch: 6| Step: 5
Training loss: 3.4431991577148438
Validation loss: 3.535138785839081
Epoch: 6| Step: 6
Training loss: 3.5823090076446533
Validation loss: 3.5373626351356506
Epoch: 6| Step: 7
Training loss: 3.583988666534424
Validation loss: 3.4665451049804688
Epoch: 6| Step: 8
Training loss: 3.3870232105255127
Validation loss: 3.4287108182907104
Epoch: 6| Step: 9
Training loss: 4.6336493492126465
Validation loss: 3.445825934410095
Epoch: 7| Step: 0
Training loss: 4.0879693031311035
Validation loss: 3.44180691242218
Epoch: 7| Step: 1
Training loss: 3.2518885135650635
Validation loss: 3.4583321809768677
Epoch: 7| Step: 2
Training loss: 3.690685749053955
Validation loss: 3.3943143486976624
Epoch: 7| Step: 3
Training loss: 3.489118814468384
Validation loss: 3.3323894739151
Epoch: 7| Step: 4
Training loss: 3.3001718521118164
Validation loss: 3.280610144138336
Epoch: 7| Step: 5
Training loss: 3.537710666656494
Validation loss: 3.265645921230316
Epoch: 7| Step: 6
Training loss: 3.417741298675537
Validation loss: 3.284474790096283
Epoch: 7| Step: 7
Training loss: 3.9145145416259766
Validation loss: 3.286408007144928
Epoch: 7| Step: 8
Training loss: 3.883357524871826
Validation loss: 3.2323641777038574
Epoch: 7| Step: 9
Training loss: 3.7990431785583496
Validation loss: 3.20603346824646
Epoch: 8| Step: 0
Training loss: 4.528432369232178
Validation loss: 3.1472657918930054
Epoch: 8| Step: 1
Training loss: 3.5486998558044434
Validation loss: 3.155730724334717
Epoch: 8| Step: 2
Training loss: 3.0955545902252197
Validation loss: 3.2129955291748047
Epoch: 8| Step: 3
Training loss: 3.4765446186065674
Validation loss: 3.0439079999923706
Epoch: 8| Step: 4
Training loss: 3.0676827430725098
Validation loss: 3.126170337200165
Epoch: 8| Step: 5
Training loss: 3.6460678577423096
Validation loss: 3.101167321205139
Epoch: 8| Step: 6
Training loss: 3.388871669769287
Validation loss: 3.1044942140579224
Epoch: 8| Step: 7
Training loss: 3.059882640838623
Validation loss: 2.9726503491401672
Epoch: 8| Step: 8
Training loss: 3.9254567623138428
Validation loss: 3.071550488471985
Epoch: 8| Step: 9
Training loss: 2.957850933074951
Validation loss: 2.9576497077941895
Epoch: 9| Step: 0
Training loss: 3.810978651046753
Validation loss: 2.887365400791168
Epoch: 9| Step: 1
Training loss: 3.827315330505371
Validation loss: 3.0049904584884644
Epoch: 9| Step: 2
Training loss: 3.2103590965270996
Validation loss: 2.9016273617744446
Epoch: 9| Step: 3
Training loss: 2.9781455993652344
Validation loss: 2.8019853830337524
Epoch: 9| Step: 4
Training loss: 3.025839328765869
Validation loss: 2.8877063393592834
Epoch: 9| Step: 5
Training loss: 3.011479139328003
Validation loss: 2.871380031108856
Epoch: 9| Step: 6
Training loss: 3.344316005706787
Validation loss: 2.9088664054870605
Epoch: 9| Step: 7
Training loss: 2.7291173934936523
Validation loss: 2.798833429813385
Epoch: 9| Step: 8
Training loss: 3.6141715049743652
Validation loss: 2.808493733406067
Epoch: 9| Step: 9
Training loss: 3.560080051422119
Validation loss: 2.7545857429504395
Epoch: 10| Step: 0
Training loss: 3.146961212158203
Validation loss: 2.79156893491745
Epoch: 10| Step: 1
Training loss: 2.9057857990264893
Validation loss: 2.77931010723114
Epoch: 10| Step: 2
Training loss: 3.7816901206970215
Validation loss: 2.7162665724754333
Epoch: 10| Step: 3
Training loss: 3.3401780128479004
Validation loss: 2.7321423292160034
Epoch: 10| Step: 4
Training loss: 2.906200885772705
Validation loss: 2.686103880405426
Epoch: 10| Step: 5
Training loss: 3.578242778778076
Validation loss: 2.6642082929611206
Epoch: 10| Step: 6
Training loss: 3.5138072967529297
Validation loss: 2.6759023666381836
Epoch: 10| Step: 7
Training loss: 2.737576484680176
Validation loss: 2.6587997674942017
Epoch: 10| Step: 8
Training loss: 2.965798854827881
Validation loss: 2.6584876775741577
Epoch: 10| Step: 9
Training loss: 2.9488365650177
Validation loss: 2.657157778739929
Epoch: 11| Step: 0
Training loss: 2.7849950790405273
Validation loss: 2.638027787208557
Epoch: 11| Step: 1
Training loss: 3.1374588012695312
Validation loss: 2.649787485599518
Epoch: 11| Step: 2
Training loss: 2.850902795791626
Validation loss: 2.6074785590171814
Epoch: 11| Step: 3
Training loss: 2.9615416526794434
Validation loss: 2.5901843309402466
Epoch: 11| Step: 4
Training loss: 3.0099380016326904
Validation loss: 2.4941455125808716
Epoch: 11| Step: 5
Training loss: 3.1474058628082275
Validation loss: 2.5630062222480774
Epoch: 11| Step: 6
Training loss: 3.123931407928467
Validation loss: 2.512815833091736
Epoch: 11| Step: 7
Training loss: 3.149813175201416
Validation loss: 2.4932548999786377
Epoch: 11| Step: 8
Training loss: 2.7481493949890137
Validation loss: 2.490038573741913
Epoch: 11| Step: 9
Training loss: 3.7527267932891846
Validation loss: 2.5755484104156494
Epoch: 12| Step: 0
Training loss: 2.9879150390625
Validation loss: 2.4884822368621826
Epoch: 12| Step: 1
Training loss: 3.373338222503662
Validation loss: 2.51387882232666
Epoch: 12| Step: 2
Training loss: 2.826446533203125
Validation loss: 2.5170633494853973
Epoch: 12| Step: 3
Training loss: 2.969834327697754
Validation loss: 2.472135007381439
Epoch: 12| Step: 4
Training loss: 2.7026968002319336
Validation loss: 2.419177830219269
Epoch: 12| Step: 5
Training loss: 2.9914286136627197
Validation loss: 2.4775412678718567
Epoch: 12| Step: 6
Training loss: 3.220813751220703
Validation loss: 2.4906239211559296
Epoch: 12| Step: 7
Training loss: 3.1695327758789062
Validation loss: 2.447552263736725
Epoch: 12| Step: 8
Training loss: 2.6491141319274902
Validation loss: 2.3813387751579285
Epoch: 12| Step: 9
Training loss: 2.761359214782715
Validation loss: 2.428975760936737
Epoch: 13| Step: 0
Training loss: 2.5427932739257812
Validation loss: 2.358681380748749
Epoch: 13| Step: 1
Training loss: 2.6068367958068848
Validation loss: 2.410181939601898
Epoch: 13| Step: 2
Training loss: 3.0530810356140137
Validation loss: 2.397616595029831
Epoch: 13| Step: 3
Training loss: 3.0432448387145996
Validation loss: 2.3379275798797607
Epoch: 13| Step: 4
Training loss: 2.498790740966797
Validation loss: 2.3811488151550293
Epoch: 13| Step: 5
Training loss: 2.75235652923584
Validation loss: 2.342421442270279
Epoch: 13| Step: 6
Training loss: 2.7833259105682373
Validation loss: 2.359175384044647
Epoch: 13| Step: 7
Training loss: 2.958266258239746
Validation loss: 2.244593024253845
Epoch: 13| Step: 8
Training loss: 3.6306440830230713
Validation loss: 2.396077275276184
Epoch: 13| Step: 9
Training loss: 2.84950590133667
Validation loss: 2.328112840652466
Epoch: 14| Step: 0
Training loss: 2.490673542022705
Validation loss: 2.322773039340973
Epoch: 14| Step: 1
Training loss: 2.9638004302978516
Validation loss: 2.2430476546287537
Epoch: 14| Step: 2
Training loss: 2.4468674659729004
Validation loss: 2.2826731204986572
Epoch: 14| Step: 3
Training loss: 3.1132335662841797
Validation loss: 2.2471935153007507
Epoch: 14| Step: 4
Training loss: 3.0064754486083984
Validation loss: 2.1965659856796265
Epoch: 14| Step: 5
Training loss: 2.6353254318237305
Validation loss: 2.2736403942108154
Epoch: 14| Step: 6
Training loss: 2.852262020111084
Validation loss: 2.229351758956909
Epoch: 14| Step: 7
Training loss: 2.7036192417144775
Validation loss: 2.3035605549812317
Epoch: 14| Step: 8
Training loss: 2.972569465637207
Validation loss: 2.1925597190856934
Epoch: 14| Step: 9
Training loss: 2.605642318725586
Validation loss: 2.2515865564346313
Epoch: 15| Step: 0
Training loss: 2.6513543128967285
Validation loss: 2.2138543725013733
Epoch: 15| Step: 1
Training loss: 3.118715763092041
Validation loss: 2.17508864402771
Epoch: 15| Step: 2
Training loss: 3.2087228298187256
Validation loss: 2.176156610250473
Epoch: 15| Step: 3
Training loss: 2.7797679901123047
Validation loss: 2.144940197467804
Epoch: 15| Step: 4
Training loss: 3.143190860748291
Validation loss: 2.206837832927704
Epoch: 15| Step: 5
Training loss: 2.4965169429779053
Validation loss: 2.167918562889099
Epoch: 15| Step: 6
Training loss: 2.4753386974334717
Validation loss: 2.144751399755478
Epoch: 15| Step: 7
Training loss: 2.1638143062591553
Validation loss: 2.1681309938430786
Epoch: 15| Step: 8
Training loss: 2.285287380218506
Validation loss: 2.1672896444797516
Epoch: 15| Step: 9
Training loss: 2.6229753494262695
Validation loss: 2.1354467272758484
Epoch: 16| Step: 0
Training loss: 2.5695853233337402
Validation loss: 2.1099090576171875
Epoch: 16| Step: 1
Training loss: 2.5226192474365234
Validation loss: 2.121262311935425
Epoch: 16| Step: 2
Training loss: 2.623012065887451
Validation loss: 2.1173606514930725
Epoch: 16| Step: 3
Training loss: 2.342864513397217
Validation loss: 2.1570065915584564
Epoch: 16| Step: 4
Training loss: 2.4890458583831787
Validation loss: 2.1087786853313446
Epoch: 16| Step: 5
Training loss: 2.8271985054016113
Validation loss: 2.037086069583893
Epoch: 16| Step: 6
Training loss: 2.8636555671691895
Validation loss: 2.1075796484947205
Epoch: 16| Step: 7
Training loss: 2.7546982765197754
Validation loss: 2.0997523069381714
Epoch: 16| Step: 8
Training loss: 2.840047597885132
Validation loss: 2.068883627653122
Epoch: 16| Step: 9
Training loss: 2.312636613845825
Validation loss: 2.028533399105072
Epoch: 17| Step: 0
Training loss: 2.668886661529541
Validation loss: 1.9570704996585846
Epoch: 17| Step: 1
Training loss: 2.498292922973633
Validation loss: 2.0388322472572327
Epoch: 17| Step: 2
Training loss: 2.065702438354492
Validation loss: 2.055727005004883
Epoch: 17| Step: 3
Training loss: 2.571131706237793
Validation loss: 2.0937631726264954
Epoch: 17| Step: 4
Training loss: 2.6084067821502686
Validation loss: 1.9750298261642456
Epoch: 17| Step: 5
Training loss: 2.188631057739258
Validation loss: 2.0506260693073273
Epoch: 17| Step: 6
Training loss: 2.241184711456299
Validation loss: 1.9990462064743042
Epoch: 17| Step: 7
Training loss: 2.7006959915161133
Validation loss: 1.9401783049106598
Epoch: 17| Step: 8
Training loss: 2.869004249572754
Validation loss: 1.9705033004283905
Epoch: 17| Step: 9
Training loss: 2.891995906829834
Validation loss: 1.99154594540596
Epoch: 18| Step: 0
Training loss: 3.277897357940674
Validation loss: 1.9757250547409058
Epoch: 18| Step: 1
Training loss: 2.146775007247925
Validation loss: 2.016501307487488
Epoch: 18| Step: 2
Training loss: 2.6398823261260986
Validation loss: 1.9417701661586761
Epoch: 18| Step: 3
Training loss: 2.2320499420166016
Validation loss: 1.9038378596305847
Epoch: 18| Step: 4
Training loss: 2.600231647491455
Validation loss: 1.9788303971290588
Epoch: 18| Step: 5
Training loss: 2.252382516860962
Validation loss: 1.944875955581665
Epoch: 18| Step: 6
Training loss: 2.0030808448791504
Validation loss: 1.9055045247077942
Epoch: 18| Step: 7
Training loss: 2.2107815742492676
Validation loss: 1.9224527478218079
Epoch: 18| Step: 8
Training loss: 2.5024595260620117
Validation loss: 1.934074729681015
Epoch: 18| Step: 9
Training loss: 2.757530927658081
Validation loss: 1.906137228012085
Epoch: 19| Step: 0
Training loss: 2.2980000972747803
Validation loss: 1.8462785184383392
Epoch: 19| Step: 1
Training loss: 2.2613208293914795
Validation loss: 1.905123233795166
Epoch: 19| Step: 2
Training loss: 2.2184548377990723
Validation loss: 1.8660406172275543
Epoch: 19| Step: 3
Training loss: 2.2314655780792236
Validation loss: 1.954685628414154
Epoch: 19| Step: 4
Training loss: 2.915281295776367
Validation loss: 1.8946799039840698
Epoch: 19| Step: 5
Training loss: 2.3266239166259766
Validation loss: 1.8498640358448029
Epoch: 19| Step: 6
Training loss: 2.7875986099243164
Validation loss: 1.8080770671367645
Epoch: 19| Step: 7
Training loss: 1.9001423120498657
Validation loss: 1.896325170993805
Epoch: 19| Step: 8
Training loss: 2.8238885402679443
Validation loss: 1.8150168061256409
Epoch: 19| Step: 9
Training loss: 2.1269164085388184
Validation loss: 1.8383244276046753
Epoch: 20| Step: 0
Training loss: 2.0324301719665527
Validation loss: 1.864386647939682
Epoch: 20| Step: 1
Training loss: 2.221731424331665
Validation loss: 1.8311693966388702
Epoch: 20| Step: 2
Training loss: 2.4227890968322754
Validation loss: 1.8386423885822296
Epoch: 20| Step: 3
Training loss: 2.3940463066101074
Validation loss: 1.8261632025241852
Epoch: 20| Step: 4
Training loss: 2.4354233741760254
Validation loss: 1.8061945736408234
Epoch: 20| Step: 5
Training loss: 2.2852420806884766
Validation loss: 1.8339114785194397
Epoch: 20| Step: 6
Training loss: 2.19709849357605
Validation loss: 1.8124386370182037
Epoch: 20| Step: 7
Training loss: 2.415809392929077
Validation loss: 1.7886370420455933
Epoch: 20| Step: 8
Training loss: 2.167943000793457
Validation loss: 1.8180514872074127
Epoch: 20| Step: 9
Training loss: 2.7711639404296875
Validation loss: 1.7272301316261292
Epoch: 21| Step: 0
Training loss: 1.9395146369934082
Validation loss: 1.7678072452545166
Epoch: 21| Step: 1
Training loss: 2.521230697631836
Validation loss: 1.6901691854000092
Epoch: 21| Step: 2
Training loss: 2.3792433738708496
Validation loss: 1.77264603972435
Epoch: 21| Step: 3
Training loss: 2.39036226272583
Validation loss: 1.8537733852863312
Epoch: 21| Step: 4
Training loss: 2.3646111488342285
Validation loss: 1.7310381531715393
Epoch: 21| Step: 5
Training loss: 2.2784266471862793
Validation loss: 1.7902914881706238
Epoch: 21| Step: 6
Training loss: 2.2919578552246094
Validation loss: 1.8087213337421417
Epoch: 21| Step: 7
Training loss: 2.4218826293945312
Validation loss: 1.758964627981186
Epoch: 21| Step: 8
Training loss: 2.3581933975219727
Validation loss: 1.7540440559387207
Epoch: 21| Step: 9
Training loss: 2.0499391555786133
Validation loss: 1.8086860477924347
Epoch: 22| Step: 0
Training loss: 2.3776657581329346
Validation loss: 1.6850953698158264
Epoch: 22| Step: 1
Training loss: 2.1781251430511475
Validation loss: 1.775313287973404
Epoch: 22| Step: 2
Training loss: 2.4843552112579346
Validation loss: 1.6784921288490295
Epoch: 22| Step: 3
Training loss: 2.315624952316284
Validation loss: 1.6819753050804138
Epoch: 22| Step: 4
Training loss: 2.4451136589050293
Validation loss: 1.7060513198375702
Epoch: 22| Step: 5
Training loss: 2.2821850776672363
Validation loss: 1.766600102186203
Epoch: 22| Step: 6
Training loss: 2.359375
Validation loss: 1.7328560650348663
Epoch: 22| Step: 7
Training loss: 2.24501895904541
Validation loss: 1.7234231531620026
Epoch: 22| Step: 8
Training loss: 2.1735892295837402
Validation loss: 1.678642898797989
Epoch: 22| Step: 9
Training loss: 1.9053125381469727
Validation loss: 1.7418554723262787
Epoch: 23| Step: 0
Training loss: 1.9996051788330078
Validation loss: 1.7553532123565674
Epoch: 23| Step: 1
Training loss: 1.9551564455032349
Validation loss: 1.7121854722499847
Epoch: 23| Step: 2
Training loss: 2.376585006713867
Validation loss: 1.674319863319397
Epoch: 23| Step: 3
Training loss: 2.174220085144043
Validation loss: 1.6469820141792297
Epoch: 23| Step: 4
Training loss: 2.428929567337036
Validation loss: 1.668932467699051
Epoch: 23| Step: 5
Training loss: 2.534464120864868
Validation loss: 1.6561051309108734
Epoch: 23| Step: 6
Training loss: 2.72043514251709
Validation loss: 1.6371710896492004
Epoch: 23| Step: 7
Training loss: 2.202881097793579
Validation loss: 1.7361712157726288
Epoch: 23| Step: 8
Training loss: 2.070439577102661
Validation loss: 1.7139323353767395
Epoch: 23| Step: 9
Training loss: 2.135019302368164
Validation loss: 1.6632575690746307
Epoch: 24| Step: 0
Training loss: 2.5262746810913086
Validation loss: 1.6558561027050018
Epoch: 24| Step: 1
Training loss: 1.8812499046325684
Validation loss: 1.6474151015281677
Epoch: 24| Step: 2
Training loss: 2.378416061401367
Validation loss: 1.6867257356643677
Epoch: 24| Step: 3
Training loss: 2.0552899837493896
Validation loss: 1.7080729007720947
Epoch: 24| Step: 4
Training loss: 2.359478235244751
Validation loss: 1.651989370584488
Epoch: 24| Step: 5
Training loss: 2.4083361625671387
Validation loss: 1.732834905385971
Epoch: 24| Step: 6
Training loss: 1.7857364416122437
Validation loss: 1.6940593123435974
Epoch: 24| Step: 7
Training loss: 2.1976089477539062
Validation loss: 1.6709089279174805
Epoch: 24| Step: 8
Training loss: 2.661484718322754
Validation loss: 1.6705677211284637
Epoch: 24| Step: 9
Training loss: 2.2774276733398438
Validation loss: 1.7222323715686798
Epoch: 25| Step: 0
Training loss: 1.975000023841858
Validation loss: 1.7336655259132385
Epoch: 25| Step: 1
Training loss: 2.5796351432800293
Validation loss: 1.6910286843776703
Epoch: 25| Step: 2
Training loss: 2.2692079544067383
Validation loss: 1.6142697930335999
Epoch: 25| Step: 3
Training loss: 2.340851306915283
Validation loss: 1.7060113549232483
Epoch: 25| Step: 4
Training loss: 2.2173566818237305
Validation loss: 1.5978726744651794
Epoch: 25| Step: 5
Training loss: 2.226320266723633
Validation loss: 1.6508773863315582
Epoch: 25| Step: 6
Training loss: 2.573134183883667
Validation loss: 1.6279151737689972
Epoch: 25| Step: 7
Training loss: 1.844347596168518
Validation loss: 1.6764130890369415
Epoch: 25| Step: 8
Training loss: 2.190512180328369
Validation loss: 1.7005250453948975
Epoch: 25| Step: 9
Training loss: 2.2399754524230957
Validation loss: 1.6573613286018372
Epoch: 26| Step: 0
Training loss: 1.9693548679351807
Validation loss: 1.6719092726707458
Epoch: 26| Step: 1
Training loss: 2.272484540939331
Validation loss: 1.6890624463558197
Epoch: 26| Step: 2
Training loss: 2.765625
Validation loss: 1.6276203095912933
Epoch: 26| Step: 3
Training loss: 2.4534943103790283
Validation loss: 1.6768993735313416
Epoch: 26| Step: 4
Training loss: 1.6177115440368652
Validation loss: 1.718202382326126
Epoch: 26| Step: 5
Training loss: 2.558438301086426
Validation loss: 1.6674851179122925
Epoch: 26| Step: 6
Training loss: 2.1640431880950928
Validation loss: 1.643477588891983
Epoch: 26| Step: 7
Training loss: 1.9891674518585205
Validation loss: 1.6924654245376587
Epoch: 26| Step: 8
Training loss: 2.347161293029785
Validation loss: 1.696206271648407
Epoch: 26| Step: 9
Training loss: 2.3093042373657227
Validation loss: 1.7336530685424805
Epoch: 27| Step: 0
Training loss: 2.2689051628112793
Validation loss: 1.7143729031085968
Epoch: 27| Step: 1
Training loss: 2.546280860900879
Validation loss: 1.6869314014911652
Epoch: 27| Step: 2
Training loss: 2.0643553733825684
Validation loss: 1.706865817308426
Epoch: 27| Step: 3
Training loss: 2.382229804992676
Validation loss: 1.7040024995803833
Epoch: 27| Step: 4
Training loss: 2.082882881164551
Validation loss: 1.7023881673812866
Epoch: 27| Step: 5
Training loss: 2.1337027549743652
Validation loss: 1.6442875564098358
Epoch: 27| Step: 6
Training loss: 2.1604442596435547
Validation loss: 1.7127239406108856
Epoch: 27| Step: 7
Training loss: 2.07659649848938
Validation loss: 1.6731715500354767
Epoch: 27| Step: 8
Training loss: 2.315624952316284
Validation loss: 1.6649570763111115
Epoch: 27| Step: 9
Training loss: 2.407550573348999
Validation loss: 1.7030640840530396
Epoch: 28| Step: 0
Training loss: 2.163449287414551
Validation loss: 1.701786607503891
Epoch: 28| Step: 1
Training loss: 2.534374952316284
Validation loss: 1.6570174396038055
Epoch: 28| Step: 2
Training loss: 2.0228984355926514
Validation loss: 1.703999012708664
Epoch: 28| Step: 3
Training loss: 2.166541576385498
Validation loss: 1.6968646347522736
Epoch: 28| Step: 4
Training loss: 2.4098267555236816
Validation loss: 1.6794300377368927
Epoch: 28| Step: 5
Training loss: 1.944961667060852
Validation loss: 1.6665997207164764
Epoch: 28| Step: 6
Training loss: 2.232459545135498
Validation loss: 1.6605210900306702
Epoch: 28| Step: 7
Training loss: 2.4808127880096436
Validation loss: 1.650812417268753
Epoch: 28| Step: 8
Training loss: 2.334486961364746
Validation loss: 1.7194535434246063
Epoch: 28| Step: 9
Training loss: 2.1371030807495117
Validation loss: 1.7409099638462067
Epoch: 29| Step: 0
Training loss: 2.0752313137054443
Validation loss: 1.690206527709961
Epoch: 29| Step: 1
Training loss: 2.1312484741210938
Validation loss: 1.701170563697815
Epoch: 29| Step: 2
Training loss: 2.4543747901916504
Validation loss: 1.5919376611709595
Epoch: 29| Step: 3
Training loss: 2.347775936126709
Validation loss: 1.693074345588684
Epoch: 29| Step: 4
Training loss: 2.1218748092651367
Validation loss: 1.664340317249298
Epoch: 29| Step: 5
Training loss: 2.905294179916382
Validation loss: 1.6658182740211487
Epoch: 29| Step: 6
Training loss: 1.8170342445373535
Validation loss: 1.639448493719101
Epoch: 29| Step: 7
Training loss: 1.9836606979370117
Validation loss: 1.6912674009799957
Epoch: 29| Step: 8
Training loss: 2.3031249046325684
Validation loss: 1.6508184969425201
Epoch: 29| Step: 9
Training loss: 2.2918860912323
Validation loss: 1.6338914036750793
Epoch: 30| Step: 0
Training loss: 2.2143616676330566
Validation loss: 1.6151230931282043
Epoch: 30| Step: 1
Training loss: 2.0718750953674316
Validation loss: 1.7034863233566284
Epoch: 30| Step: 2
Training loss: 2.2327048778533936
Validation loss: 1.6691341698169708
Epoch: 30| Step: 3
Training loss: 2.4055228233337402
Validation loss: 1.667477309703827
Epoch: 30| Step: 4
Training loss: 2.242867946624756
Validation loss: 1.693264663219452
Epoch: 30| Step: 5
Training loss: 2.4333624839782715
Validation loss: 1.6451123654842377
Epoch: 30| Step: 6
Training loss: 2.3125
Validation loss: 1.6175175607204437
Epoch: 30| Step: 7
Training loss: 2.125
Validation loss: 1.6521017849445343
Epoch: 30| Step: 8
Training loss: 2.2759785652160645
Validation loss: 1.6750300824642181
Epoch: 30| Step: 9
Training loss: 2.112959146499634
Validation loss: 1.7043747007846832
