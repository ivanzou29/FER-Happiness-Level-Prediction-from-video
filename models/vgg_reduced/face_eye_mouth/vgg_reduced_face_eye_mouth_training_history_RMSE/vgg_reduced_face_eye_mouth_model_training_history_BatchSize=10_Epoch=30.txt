Epoch: 1| Step: 0
Training loss: 7.202098847816566
Validation loss: 5.847468528430947
Epoch: 1| Step: 1
Training loss: 6.97957109636466
Validation loss: 5.9583122874865815
Epoch: 1| Step: 2
Training loss: 5.197225989843231
Validation loss: 6.016645101132164
Epoch: 1| Step: 3
Training loss: 6.271590515588119
Validation loss: 5.977728968808695
Epoch: 1| Step: 4
Training loss: 6.162575507330106
Validation loss: 5.847676662458595
Epoch: 1| Step: 5
Training loss: 6.506382669494204
Validation loss: 5.766473639665699
Epoch: 1| Step: 6
Training loss: 5.808127450600742
Validation loss: 5.891434945198711
Epoch: 1| Step: 7
Training loss: 5.7788549462455014
Validation loss: 5.733935729930863
Epoch: 1| Step: 8
Training loss: 6.807548753533704
Validation loss: 5.785125894770223
Epoch: 1| Step: 9
Training loss: 5.648321844370483
Validation loss: 5.680511401746163
Epoch: 1| Step: 10
Training loss: 6.5507399046474015
Validation loss: 5.701266846664363
Epoch: 1| Step: 11
Training loss: 4.796606596852686
Validation loss: 5.60135344718846
Epoch: 1| Step: 12
Training loss: 7.507858482640795
Validation loss: 5.4007296359726995
Epoch: 1| Step: 13
Training loss: 5.1092895127357165
Validation loss: 5.406978145299603
Epoch: 1| Step: 14
Training loss: 5.4217337554211245
Validation loss: 5.406521348573449
Epoch: 1| Step: 15
Training loss: 6.214448140594519
Validation loss: 5.288233640870497
Epoch: 1| Step: 16
Training loss: 3.3226677652890926
Validation loss: 5.247474504056713
Epoch: 1| Step: 17
Training loss: 4.279611984205059
Validation loss: 5.068979611252686
Epoch: 1| Step: 18
Training loss: 5.689677398064232
Validation loss: 5.1648821629134725
Epoch: 1| Step: 19
Training loss: 3.747463894619866
Validation loss: 5.110741568990965
Epoch: 1| Step: 20
Training loss: 4.230477090899557
Validation loss: 5.038163500687157
Epoch: 1| Step: 21
Training loss: 4.872023627538656
Validation loss: 5.020375474014264
Epoch: 1| Step: 22
Training loss: 5.491054195505496
Validation loss: 5.06508285915081
Epoch: 1| Step: 23
Training loss: 5.3982396400065
Validation loss: 4.9816802008589445
Epoch: 1| Step: 24
Training loss: 5.346742026605759
Validation loss: 4.92007225366014
Epoch: 1| Step: 25
Training loss: 5.504254169716707
Validation loss: 4.786080947896587
Epoch: 1| Step: 26
Training loss: 4.445301987781398
Validation loss: 4.865361108369322
Epoch: 1| Step: 27
Training loss: 5.870545666886678
Validation loss: 4.829553079539019
Epoch: 1| Step: 28
Training loss: 6.454863602713745
Validation loss: 4.7166652726379406
Epoch: 1| Step: 29
Training loss: 6.614517267653175
Validation loss: 4.653192991905594
Epoch: 1| Step: 30
Training loss: 5.245945772880421
Validation loss: 4.604970884322757
Epoch: 1| Step: 31
Training loss: 4.895720633433845
Validation loss: 4.544469724766713
Epoch: 2| Step: 0
Training loss: 5.551330496280208
Validation loss: 4.524503056462228
Epoch: 2| Step: 1
Training loss: 6.687542211096339
Validation loss: 4.371150341482956
Epoch: 2| Step: 2
Training loss: 4.663212837769354
Validation loss: 4.422065557293641
Epoch: 2| Step: 3
Training loss: 5.67480628401393
Validation loss: 4.317794393231513
Epoch: 2| Step: 4
Training loss: 4.498741821722561
Validation loss: 4.248076476671952
Epoch: 2| Step: 5
Training loss: 4.218940108925486
Validation loss: 4.308695504974666
Epoch: 2| Step: 6
Training loss: 3.991784958224824
Validation loss: 4.287290947009838
Epoch: 2| Step: 7
Training loss: 5.094714863204173
Validation loss: 4.212481715580387
Epoch: 2| Step: 8
Training loss: 3.148247422001511
Validation loss: 4.0842400506705
Epoch: 2| Step: 9
Training loss: 4.784271482298324
Validation loss: 3.983018272099012
Epoch: 2| Step: 10
Training loss: 5.007522455585045
Validation loss: 4.067499748863124
Epoch: 2| Step: 11
Training loss: 2.2079350334229506
Validation loss: 3.9977047264542174
Epoch: 2| Step: 12
Training loss: 4.870515178713552
Validation loss: 4.035939704093877
Epoch: 2| Step: 13
Training loss: 4.7295856486287295
Validation loss: 3.934312364553035
Epoch: 2| Step: 14
Training loss: 4.4346611720968845
Validation loss: 3.8488570544953262
Epoch: 2| Step: 15
Training loss: 4.659665077845758
Validation loss: 3.860444567545314
Epoch: 2| Step: 16
Training loss: 3.5382500867593625
Validation loss: 3.857759871439306
Epoch: 2| Step: 17
Training loss: 3.9032197719335118
Validation loss: 3.7700552114138572
Epoch: 2| Step: 18
Training loss: 3.8869844738782913
Validation loss: 3.8096077995378064
Epoch: 2| Step: 19
Training loss: 4.221379343750425
Validation loss: 3.730945940410324
Epoch: 2| Step: 20
Training loss: 3.01551383806816
Validation loss: 3.69930839299243
Epoch: 2| Step: 21
Training loss: 3.982003736784488
Validation loss: 3.637208219054564
Epoch: 2| Step: 22
Training loss: 4.137201009129409
Validation loss: 3.5877175471515446
Epoch: 2| Step: 23
Training loss: 3.9229447930871237
Validation loss: 3.5915221367108137
Epoch: 2| Step: 24
Training loss: 3.67096923045432
Validation loss: 3.570133828697827
Epoch: 2| Step: 25
Training loss: 3.9372822534813405
Validation loss: 3.5191456932988996
Epoch: 2| Step: 26
Training loss: 4.333194119100102
Validation loss: 3.414691286615853
Epoch: 2| Step: 27
Training loss: 4.33109421222805
Validation loss: 3.456395710813652
Epoch: 2| Step: 28
Training loss: 4.258254393998648
Validation loss: 3.4618787011813765
Epoch: 2| Step: 29
Training loss: 3.2873484297357844
Validation loss: 3.44115685133272
Epoch: 2| Step: 30
Training loss: 4.7183934765459865
Validation loss: 3.374031468914604
Epoch: 2| Step: 31
Training loss: 3.4573417222430867
Validation loss: 3.310155817694889
Epoch: 3| Step: 0
Training loss: 2.227243740869844
Validation loss: 3.2844204560850203
Epoch: 3| Step: 1
Training loss: 3.8622208577738837
Validation loss: 3.2953227985725095
Epoch: 3| Step: 2
Training loss: 4.407693612903407
Validation loss: 3.2745272972611437
Epoch: 3| Step: 3
Training loss: 3.7876152499450377
Validation loss: 3.232476317270467
Epoch: 3| Step: 4
Training loss: 3.7091449463744786
Validation loss: 3.242084479259818
Epoch: 3| Step: 5
Training loss: 4.40872447556715
Validation loss: 3.2083661836082635
Epoch: 3| Step: 6
Training loss: 2.8696222180270237
Validation loss: 3.119469750985222
Epoch: 3| Step: 7
Training loss: 2.705182477680356
Validation loss: 3.0883427771712175
Epoch: 3| Step: 8
Training loss: 3.9405703003102244
Validation loss: 3.120281479978826
Epoch: 3| Step: 9
Training loss: 3.4675942634910863
Validation loss: 3.0919787174733604
Epoch: 3| Step: 10
Training loss: 3.651445410911573
Validation loss: 3.0366794889804396
Epoch: 3| Step: 11
Training loss: 4.444523585462608
Validation loss: 3.01381038842473
Epoch: 3| Step: 12
Training loss: 4.356908613246848
Validation loss: 2.9677288465937304
Epoch: 3| Step: 13
Training loss: 3.659738555492136
Validation loss: 2.970376163743968
Epoch: 3| Step: 14
Training loss: 3.3249377538834777
Validation loss: 2.8741914906453263
Epoch: 3| Step: 15
Training loss: 3.878983572720318
Validation loss: 2.7969363961227285
Epoch: 3| Step: 16
Training loss: 2.8142171068521904
Validation loss: 2.891060049527254
Epoch: 3| Step: 17
Training loss: 2.8862647911409787
Validation loss: 2.8684503789591833
Epoch: 3| Step: 18
Training loss: 4.179304615202198
Validation loss: 2.8104287958704286
Epoch: 3| Step: 19
Training loss: 2.2881273045302923
Validation loss: 2.7670495232549595
Epoch: 3| Step: 20
Training loss: 3.509524193273411
Validation loss: 2.7657779759399923
Epoch: 3| Step: 21
Training loss: 3.4923181701381463
Validation loss: 2.8615002800394556
Epoch: 3| Step: 22
Training loss: 3.9010482944216616
Validation loss: 2.78052975305401
Epoch: 3| Step: 23
Training loss: 2.0883205103296585
Validation loss: 2.776594371063721
Epoch: 3| Step: 24
Training loss: 2.36803559574231
Validation loss: 2.618363543279396
Epoch: 3| Step: 25
Training loss: 2.762690997533304
Validation loss: 2.6869700342525125
Epoch: 3| Step: 26
Training loss: 3.020426036518298
Validation loss: 2.67383459546879
Epoch: 3| Step: 27
Training loss: 3.579569562470253
Validation loss: 2.700775259933031
Epoch: 3| Step: 28
Training loss: 3.06423060507035
Validation loss: 2.640170243329569
Epoch: 3| Step: 29
Training loss: 2.887040013256999
Validation loss: 2.544509356340094
Epoch: 3| Step: 30
Training loss: 3.277283660010434
Validation loss: 2.6093647635330433
Epoch: 3| Step: 31
Training loss: 3.471194119304134
Validation loss: 2.6194715865580034
Epoch: 4| Step: 0
Training loss: 3.3058632637081287
Validation loss: 2.581052228086305
Epoch: 4| Step: 1
Training loss: 2.6923729830988963
Validation loss: 2.4943424397072196
Epoch: 4| Step: 2
Training loss: 2.8473015709548424
Validation loss: 2.5591617495899084
Epoch: 4| Step: 3
Training loss: 3.125658347400639
Validation loss: 2.4937526505288257
Epoch: 4| Step: 4
Training loss: 3.9311740255367957
Validation loss: 2.499656833554651
Epoch: 4| Step: 5
Training loss: 2.8557279080412448
Validation loss: 2.543722995128527
Epoch: 4| Step: 6
Training loss: 3.2692980392577593
Validation loss: 2.5191929795373236
Epoch: 4| Step: 7
Training loss: 3.0866126758420704
Validation loss: 2.496778172003697
Epoch: 4| Step: 8
Training loss: 2.9584913793621666
Validation loss: 2.4390960378284188
Epoch: 4| Step: 9
Training loss: 2.562395605426394
Validation loss: 2.51155328396801
Epoch: 4| Step: 10
Training loss: 3.5239038264544886
Validation loss: 2.4565855772718757
Epoch: 4| Step: 11
Training loss: 3.673185463667808
Validation loss: 2.4529241266758643
Epoch: 4| Step: 12
Training loss: 2.343459658123111
Validation loss: 2.4442055279144834
Epoch: 4| Step: 13
Training loss: 2.9578274218167255
Validation loss: 2.4567430994777073
Epoch: 4| Step: 14
Training loss: 2.459070472331085
Validation loss: 2.36364787447762
Epoch: 4| Step: 15
Training loss: 3.0286120705049697
Validation loss: 2.459061202872716
Epoch: 4| Step: 16
Training loss: 3.5488082389715268
Validation loss: 2.4044495435297364
Epoch: 4| Step: 17
Training loss: 2.6607878575160924
Validation loss: 2.3294701255437387
Epoch: 4| Step: 18
Training loss: 2.7763349844520446
Validation loss: 2.3850349727098683
Epoch: 4| Step: 19
Training loss: 2.922081598331842
Validation loss: 2.3462150476566883
Epoch: 4| Step: 20
Training loss: 2.7008028143743794
Validation loss: 2.40723939260465
Epoch: 4| Step: 21
Training loss: 2.799324880680636
Validation loss: 2.362617543152877
Epoch: 4| Step: 22
Training loss: 2.672418639440672
Validation loss: 2.348852572054415
Epoch: 4| Step: 23
Training loss: 2.9303562062354063
Validation loss: 2.3287217766640964
Epoch: 4| Step: 24
Training loss: 3.264543418096579
Validation loss: 2.3530001908114473
Epoch: 4| Step: 25
Training loss: 2.832024851824669
Validation loss: 2.365330619503645
Epoch: 4| Step: 26
Training loss: 2.8580983131108746
Validation loss: 2.2384168263898676
Epoch: 4| Step: 27
Training loss: 2.7023492482756115
Validation loss: 2.3083087597079373
Epoch: 4| Step: 28
Training loss: 1.8267427092871722
Validation loss: 2.305533551180087
Epoch: 4| Step: 29
Training loss: 2.754536701300648
Validation loss: 2.296499589705427
Epoch: 4| Step: 30
Training loss: 2.893821145289192
Validation loss: 2.3092889197961024
Epoch: 4| Step: 31
Training loss: 2.4524004406800604
Validation loss: 2.274665245131519
Epoch: 5| Step: 0
Training loss: 2.127760496586719
Validation loss: 2.246634299233109
Epoch: 5| Step: 1
Training loss: 3.5511493219312578
Validation loss: 2.262070743311889
Epoch: 5| Step: 2
Training loss: 2.2095267711777717
Validation loss: 2.293439383054926
Epoch: 5| Step: 3
Training loss: 3.3111143272890633
Validation loss: 2.2948628431289606
Epoch: 5| Step: 4
Training loss: 2.1178820832579905
Validation loss: 2.1912708821010565
Epoch: 5| Step: 5
Training loss: 1.9120507080305051
Validation loss: 2.2390915105662517
Epoch: 5| Step: 6
Training loss: 3.2933113399600074
Validation loss: 2.2419976761261555
Epoch: 5| Step: 7
Training loss: 2.547742824493057
Validation loss: 2.194963549166297
Epoch: 5| Step: 8
Training loss: 3.5157055654831146
Validation loss: 2.2375038021445155
Epoch: 5| Step: 9
Training loss: 2.3820333238732156
Validation loss: 2.1958250348959494
Epoch: 5| Step: 10
Training loss: 2.957977022733037
Validation loss: 2.2213716746872794
Epoch: 5| Step: 11
Training loss: 2.1013181182694542
Validation loss: 2.207762273358602
Epoch: 5| Step: 12
Training loss: 2.3502337481534625
Validation loss: 2.227896617290105
Epoch: 5| Step: 13
Training loss: 2.8239562781896446
Validation loss: 2.1858107497791295
Epoch: 5| Step: 14
Training loss: 2.7599098076112347
Validation loss: 2.1579869724931973
Epoch: 5| Step: 15
Training loss: 3.0655673489219524
Validation loss: 2.1826685438783326
Epoch: 5| Step: 16
Training loss: 2.7434559032302213
Validation loss: 2.190831489781827
Epoch: 5| Step: 17
Training loss: 2.9779669384475738
Validation loss: 2.188885049281343
Epoch: 5| Step: 18
Training loss: 2.6836699762304606
Validation loss: 2.1806309179105954
Epoch: 5| Step: 19
Training loss: 2.167068652006896
Validation loss: 2.2005484087990426
Epoch: 5| Step: 20
Training loss: 3.334840688031556
Validation loss: 2.222686512902542
Epoch: 5| Step: 21
Training loss: 2.8886905280098403
Validation loss: 2.1664722440478594
Epoch: 5| Step: 22
Training loss: 2.4641553398063785
Validation loss: 2.1122239087052703
Epoch: 5| Step: 23
Training loss: 2.4049785276790754
Validation loss: 2.193595075954519
Epoch: 5| Step: 24
Training loss: 2.52416650971288
Validation loss: 2.1623182377686274
Epoch: 5| Step: 25
Training loss: 2.6819945433160743
Validation loss: 2.1602242425203784
Epoch: 5| Step: 26
Training loss: 3.1095010549786095
Validation loss: 2.205407525370914
Epoch: 5| Step: 27
Training loss: 3.0998491988880956
Validation loss: 2.1225985025702454
Epoch: 5| Step: 28
Training loss: 2.4447792129838715
Validation loss: 2.1581894124500414
Epoch: 5| Step: 29
Training loss: 2.98362554756475
Validation loss: 2.1440748781581003
Epoch: 5| Step: 30
Training loss: 3.127571878682126
Validation loss: 2.1632165399720957
Epoch: 5| Step: 31
Training loss: 2.1981459824919405
Validation loss: 2.1674729683939713
Epoch: 6| Step: 0
Training loss: 2.793533716214413
Validation loss: 2.1888574439936312
Epoch: 6| Step: 1
Training loss: 2.7248280427205382
Validation loss: 2.1076755116169403
Epoch: 6| Step: 2
Training loss: 2.756705950957179
Validation loss: 2.1742869747739677
Epoch: 6| Step: 3
Training loss: 2.9665802103653376
Validation loss: 2.152440757193246
Epoch: 6| Step: 4
Training loss: 2.378762226724799
Validation loss: 2.1836596517204447
Epoch: 6| Step: 5
Training loss: 2.7531290459143087
Validation loss: 2.1523993635702983
Epoch: 6| Step: 6
Training loss: 2.7911815126851516
Validation loss: 2.123197429136007
Epoch: 6| Step: 7
Training loss: 2.8562424807793874
Validation loss: 2.093481616040827
Epoch: 6| Step: 8
Training loss: 2.8712322590952035
Validation loss: 2.101288757378202
Epoch: 6| Step: 9
Training loss: 2.828869463479404
Validation loss: 2.1710996481638243
Epoch: 6| Step: 10
Training loss: 1.7034546419357834
Validation loss: 2.1659375999434807
Epoch: 6| Step: 11
Training loss: 2.383036018269064
Validation loss: 2.1109228460779987
Epoch: 6| Step: 12
Training loss: 3.133258435862468
Validation loss: 2.1227243461279683
Epoch: 6| Step: 13
Training loss: 2.2910066752409377
Validation loss: 2.097180728474459
Epoch: 6| Step: 14
Training loss: 2.2916696953031006
Validation loss: 2.121698681032402
Epoch: 6| Step: 15
Training loss: 2.3058893722968863
Validation loss: 2.1343276862486857
Epoch: 6| Step: 16
Training loss: 2.678446134634123
Validation loss: 2.1620184392748447
Epoch: 6| Step: 17
Training loss: 2.945173912936451
Validation loss: 2.08876866173673
Epoch: 6| Step: 18
Training loss: 2.8616940625641387
Validation loss: 2.1287328820941553
Epoch: 6| Step: 19
Training loss: 2.86831933738697
Validation loss: 2.055223829622943
Epoch: 6| Step: 20
Training loss: 2.386110718440521
Validation loss: 2.114993221373044
Epoch: 6| Step: 21
Training loss: 3.0936128219863583
Validation loss: 2.1154569052998937
Epoch: 6| Step: 22
Training loss: 2.60665002035434
Validation loss: 2.1068188990580863
Epoch: 6| Step: 23
Training loss: 2.730802807544669
Validation loss: 2.116014347051926
Epoch: 6| Step: 24
Training loss: 2.9262256564920626
Validation loss: 2.1113220780643234
Epoch: 6| Step: 25
Training loss: 2.154174690551374
Validation loss: 2.164526823000675
Epoch: 6| Step: 26
Training loss: 3.017557266311403
Validation loss: 2.1629209534532325
Epoch: 6| Step: 27
Training loss: 2.8344901098326765
Validation loss: 2.1070723217132423
Epoch: 6| Step: 28
Training loss: 2.8413243271201485
Validation loss: 2.1423868519442544
Epoch: 6| Step: 29
Training loss: 2.658585811651341
Validation loss: 2.0808605037906505
Epoch: 6| Step: 30
Training loss: 2.5011929526774694
Validation loss: 2.1289336509112995
Epoch: 6| Step: 31
Training loss: 2.5280973793661716
Validation loss: 2.0960935178366733
Epoch: 7| Step: 0
Training loss: 2.3041929587254706
Validation loss: 2.103859184837576
Epoch: 7| Step: 1
Training loss: 2.705116728910013
Validation loss: 2.1272568039019912
Epoch: 7| Step: 2
Training loss: 2.605301652894667
Validation loss: 2.115764382500138
Epoch: 7| Step: 3
Training loss: 3.209243513197768
Validation loss: 2.117185754632195
Epoch: 7| Step: 4
Training loss: 2.565858733185787
Validation loss: 2.106437928332226
Epoch: 7| Step: 5
Training loss: 3.275274303101815
Validation loss: 2.1415150471406412
Epoch: 7| Step: 6
Training loss: 2.5649619952206444
Validation loss: 2.1059820479058065
Epoch: 7| Step: 7
Training loss: 2.2951290215687163
Validation loss: 2.1684000878254084
Epoch: 7| Step: 8
Training loss: 2.723308818882675
Validation loss: 2.127828826785831
Epoch: 7| Step: 9
Training loss: 2.949250924648584
Validation loss: 2.123919551777671
Epoch: 7| Step: 10
Training loss: 2.2579728963828507
Validation loss: 2.1403852815484834
Epoch: 7| Step: 11
Training loss: 3.2371410391800888
Validation loss: 2.1251404822565148
Epoch: 7| Step: 12
Training loss: 2.395718502665213
Validation loss: 2.048106272388051
Epoch: 7| Step: 13
Training loss: 2.4079031281740573
Validation loss: 2.132756758060441
Epoch: 7| Step: 14
Training loss: 2.709320641558624
Validation loss: 2.1523826475766246
Epoch: 7| Step: 15
Training loss: 2.033236896333363
Validation loss: 2.1604472984239704
Epoch: 7| Step: 16
Training loss: 2.5766862033368185
Validation loss: 2.125108654007391
Epoch: 7| Step: 17
Training loss: 3.143308489456244
Validation loss: 2.1348675984555543
Epoch: 7| Step: 18
Training loss: 3.047657870928097
Validation loss: 2.1414476873048574
Epoch: 7| Step: 19
Training loss: 2.2913552737361607
Validation loss: 2.1276750100211377
Epoch: 7| Step: 20
Training loss: 3.004557009525086
Validation loss: 2.0476267577926177
Epoch: 7| Step: 21
Training loss: 2.5141728160640917
Validation loss: 2.120551792968715
Epoch: 7| Step: 22
Training loss: 2.737059403588452
Validation loss: 2.091898714774559
Epoch: 7| Step: 23
Training loss: 2.8119707245313452
Validation loss: 2.119368943472705
Epoch: 7| Step: 24
Training loss: 2.219565443173677
Validation loss: 2.1127210879175853
Epoch: 7| Step: 25
Training loss: 3.3052765882585584
Validation loss: 2.136015768194209
Epoch: 7| Step: 26
Training loss: 2.853005073090919
Validation loss: 2.1310545724319327
Epoch: 7| Step: 27
Training loss: 2.243413397317723
Validation loss: 2.0502590312452997
Epoch: 7| Step: 28
Training loss: 2.732893275293473
Validation loss: 2.047465420963214
Epoch: 7| Step: 29
Training loss: 2.83161230737496
Validation loss: 2.1182384086287795
Epoch: 7| Step: 30
Training loss: 2.4228673071082545
Validation loss: 2.140195166415105
Epoch: 7| Step: 31
Training loss: 1.9945464286420889
Validation loss: 2.1403871140395747
Epoch: 8| Step: 0
Training loss: 2.6168204434477063
Validation loss: 2.113090814461005
Epoch: 8| Step: 1
Training loss: 2.3746489215161395
Validation loss: 2.1443649170962535
Epoch: 8| Step: 2
Training loss: 3.024081533675052
Validation loss: 2.095241454009829
Epoch: 8| Step: 3
Training loss: 2.4062444513430346
Validation loss: 2.076744822148961
Epoch: 8| Step: 4
Training loss: 2.237742627164636
Validation loss: 2.1192484367868696
Epoch: 8| Step: 5
Training loss: 2.4925618144704655
Validation loss: 2.1673167017516275
Epoch: 8| Step: 6
Training loss: 3.0258796547849847
Validation loss: 2.1588772409355816
Epoch: 8| Step: 7
Training loss: 2.562624486365038
Validation loss: 2.1114971767019046
Epoch: 8| Step: 8
Training loss: 1.6743360569986383
Validation loss: 2.132819122706966
Epoch: 8| Step: 9
Training loss: 3.7043650679489764
Validation loss: 2.165664748008926
Epoch: 8| Step: 10
Training loss: 2.17861857575405
Validation loss: 2.1546426971629034
Epoch: 8| Step: 11
Training loss: 2.604274310112514
Validation loss: 2.125394815931752
Epoch: 8| Step: 12
Training loss: 2.203959205637606
Validation loss: 2.079128467243921
Epoch: 8| Step: 13
Training loss: 2.827081224238809
Validation loss: 2.1908857087403115
Epoch: 8| Step: 14
Training loss: 2.7348978469154464
Validation loss: 2.1136147654256243
Epoch: 8| Step: 15
Training loss: 2.833840680045004
Validation loss: 2.1728457181374847
Epoch: 8| Step: 16
Training loss: 3.139688076878462
Validation loss: 2.2065137998650233
Epoch: 8| Step: 17
Training loss: 3.3119955578465547
Validation loss: 2.1191014387722222
Epoch: 8| Step: 18
Training loss: 2.275911224142322
Validation loss: 2.159186139588133
Epoch: 8| Step: 19
Training loss: 2.762822428395192
Validation loss: 2.1397616169876
Epoch: 8| Step: 20
Training loss: 2.3733504740849707
Validation loss: 2.1663898696810153
Epoch: 8| Step: 21
Training loss: 2.8612547985484964
Validation loss: 2.082764607911339
Epoch: 8| Step: 22
Training loss: 3.002340834033274
Validation loss: 2.130255958462261
Epoch: 8| Step: 23
Training loss: 2.802866820286323
Validation loss: 2.10002263429552
Epoch: 8| Step: 24
Training loss: 2.640159791676621
Validation loss: 2.1232369221719023
Epoch: 8| Step: 25
Training loss: 2.07239689532535
Validation loss: 2.164565204031704
Epoch: 8| Step: 26
Training loss: 2.534131329319434
Validation loss: 2.1020835252316554
Epoch: 8| Step: 27
Training loss: 2.6983080154214503
Validation loss: 2.109438654468663
Epoch: 8| Step: 28
Training loss: 2.433014973843268
Validation loss: 2.1128656886960644
Epoch: 8| Step: 29
Training loss: 2.4193639720211113
Validation loss: 2.1804221983152843
Epoch: 8| Step: 30
Training loss: 2.724362510517754
Validation loss: 2.175591079456626
Epoch: 8| Step: 31
Training loss: 2.38373785342886
Validation loss: 2.124940601088851
Epoch: 9| Step: 0
Training loss: 2.5529036987466767
Validation loss: 2.087864098773253
Epoch: 9| Step: 1
Training loss: 2.2135221113949317
Validation loss: 2.1328611619193074
Epoch: 9| Step: 2
Training loss: 3.1328496383786844
Validation loss: 2.102573949776687
Epoch: 9| Step: 3
Training loss: 3.0165498728474516
Validation loss: 2.0528849767127415
Epoch: 9| Step: 4
Training loss: 2.4603214522200942
Validation loss: 2.1253249396584715
Epoch: 9| Step: 5
Training loss: 3.09746690438411
Validation loss: 2.0888793671952355
Epoch: 9| Step: 6
Training loss: 2.60178564449235
Validation loss: 2.0732957255668727
Epoch: 9| Step: 7
Training loss: 2.773088374124919
Validation loss: 2.0569685191711375
Epoch: 9| Step: 8
Training loss: 2.7071470645939426
Validation loss: 2.13285469838237
Epoch: 9| Step: 9
Training loss: 2.402423441735886
Validation loss: 2.1266602461663764
Epoch: 9| Step: 10
Training loss: 2.7218794077017447
Validation loss: 2.135387535265436
Epoch: 9| Step: 11
Training loss: 2.911464484156536
Validation loss: 2.129849187748433
Epoch: 9| Step: 12
Training loss: 2.296327902064788
Validation loss: 2.0761882645301624
Epoch: 9| Step: 13
Training loss: 2.3326963054645224
Validation loss: 2.167891531718639
Epoch: 9| Step: 14
Training loss: 2.229495609529787
Validation loss: 2.119669306481177
Epoch: 9| Step: 15
Training loss: 2.249349500082846
Validation loss: 2.1590573910565998
Epoch: 9| Step: 16
Training loss: 3.044777485652078
Validation loss: 2.155368886777418
Epoch: 9| Step: 17
Training loss: 2.8978056925941824
Validation loss: 2.1508584367312356
Epoch: 9| Step: 18
Training loss: 2.691674826720853
Validation loss: 2.1196094347980954
Epoch: 9| Step: 19
Training loss: 2.678505506158424
Validation loss: 2.129591103385848
Epoch: 9| Step: 20
Training loss: 3.278164966437805
Validation loss: 2.157614943608597
Epoch: 9| Step: 21
Training loss: 2.1989537785812856
Validation loss: 2.125603532963975
Epoch: 9| Step: 22
Training loss: 2.8454829374963766
Validation loss: 2.08981167306265
Epoch: 9| Step: 23
Training loss: 2.4306809335493242
Validation loss: 2.136540589552261
Epoch: 9| Step: 24
Training loss: 2.424025042678342
Validation loss: 2.1690821333301455
Epoch: 9| Step: 25
Training loss: 2.0931978778789717
Validation loss: 2.0663286473651112
Epoch: 9| Step: 26
Training loss: 2.4329875356321207
Validation loss: 2.1209877061858196
Epoch: 9| Step: 27
Training loss: 2.4087149145068363
Validation loss: 2.1036825057495405
Epoch: 9| Step: 28
Training loss: 3.060794121663919
Validation loss: 2.1306523938401947
Epoch: 9| Step: 29
Training loss: 2.840339711785322
Validation loss: 2.1041507690566315
Epoch: 9| Step: 30
Training loss: 2.3661046336843863
Validation loss: 2.173167870230792
Epoch: 9| Step: 31
Training loss: 3.363712083821848
Validation loss: 2.0941687369595128
Epoch: 10| Step: 0
Training loss: 2.7583166423496217
Validation loss: 2.1331712210652607
Epoch: 10| Step: 1
Training loss: 2.575100135707996
Validation loss: 2.1477531385760638
Epoch: 10| Step: 2
Training loss: 2.843913146987767
Validation loss: 2.1019282235975063
Epoch: 10| Step: 3
Training loss: 2.902836918165041
Validation loss: 2.0703766162303086
Epoch: 10| Step: 4
Training loss: 2.555592787743215
Validation loss: 2.0960516352149074
Epoch: 10| Step: 5
Training loss: 2.7034222213424495
Validation loss: 2.1072588600944724
Epoch: 10| Step: 6
Training loss: 2.766172969002426
Validation loss: 2.1769270637959552
Epoch: 10| Step: 7
Training loss: 2.4036227659452845
Validation loss: 2.114906459976027
Epoch: 10| Step: 8
Training loss: 2.156291795408451
Validation loss: 2.0544782908477006
Epoch: 10| Step: 9
Training loss: 3.1228019613551785
Validation loss: 2.1028871548327044
Epoch: 10| Step: 10
Training loss: 2.1272684219141906
Validation loss: 2.0759515941531537
Epoch: 10| Step: 11
Training loss: 2.3231673739727525
Validation loss: 2.1517040679940305
Epoch: 10| Step: 12
Training loss: 2.7766883387946764
Validation loss: 2.0405001436295924
Epoch: 10| Step: 13
Training loss: 2.576294497679882
Validation loss: 2.112562616617746
Epoch: 10| Step: 14
Training loss: 2.201160826904949
Validation loss: 2.094091317645204
Epoch: 10| Step: 15
Training loss: 2.750332205387239
Validation loss: 2.0747672567472133
Epoch: 10| Step: 16
Training loss: 2.9063449967148083
Validation loss: 2.15213364213205
Epoch: 10| Step: 17
Training loss: 3.909678183187684
Validation loss: 2.1559076483213766
Epoch: 10| Step: 18
Training loss: 2.554638036779849
Validation loss: 2.1337700703428846
Epoch: 10| Step: 19
Training loss: 2.792061270159024
Validation loss: 2.1485600798808737
Epoch: 10| Step: 20
Training loss: 2.409184536660351
Validation loss: 2.1276629465396955
Epoch: 10| Step: 21
Training loss: 2.447139946830291
Validation loss: 2.1361748585828115
Epoch: 10| Step: 22
Training loss: 3.0777479221565347
Validation loss: 2.11746175785882
Epoch: 10| Step: 23
Training loss: 2.6531326850986496
Validation loss: 2.1252999918113304
Epoch: 10| Step: 24
Training loss: 2.373951329054521
Validation loss: 2.123732934739701
Epoch: 10| Step: 25
Training loss: 2.6466877876739376
Validation loss: 2.1770504450393817
Epoch: 10| Step: 26
Training loss: 3.27203266161074
Validation loss: 2.09121776562322
Epoch: 10| Step: 27
Training loss: 2.6761671247483294
Validation loss: 2.116568376633697
Epoch: 10| Step: 28
Training loss: 2.6640590992119972
Validation loss: 2.178895302299659
Epoch: 10| Step: 29
Training loss: 2.1106438105645546
Validation loss: 2.1383255617200563
Epoch: 10| Step: 30
Training loss: 2.010061466548772
Validation loss: 2.1254857838113463
Epoch: 10| Step: 31
Training loss: 2.5582269536701343
Validation loss: 2.1693471939838505
Epoch: 11| Step: 0
Training loss: 2.826304149893475
Validation loss: 2.162670912944626
Epoch: 11| Step: 1
Training loss: 2.6774406244157363
Validation loss: 2.1220618391075012
Epoch: 11| Step: 2
Training loss: 2.671259312771891
Validation loss: 2.081820010615328
Epoch: 11| Step: 3
Training loss: 2.747414674136869
Validation loss: 2.1203559121325273
Epoch: 11| Step: 4
Training loss: 2.586364802987877
Validation loss: 2.1563768662391496
Epoch: 11| Step: 5
Training loss: 2.7373648727719493
Validation loss: 2.102842989623853
Epoch: 11| Step: 6
Training loss: 2.7411075215117933
Validation loss: 2.123847465030877
Epoch: 11| Step: 7
Training loss: 2.643765720474002
Validation loss: 2.1506714395849564
Epoch: 11| Step: 8
Training loss: 2.9202566305809747
Validation loss: 2.088505089218421
Epoch: 11| Step: 9
Training loss: 2.5612248295021467
Validation loss: 2.1475197702511277
Epoch: 11| Step: 10
Training loss: 3.252551324484858
Validation loss: 2.091808703064784
Epoch: 11| Step: 11
Training loss: 2.1028016702002064
Validation loss: 2.129016317741118
Epoch: 11| Step: 12
Training loss: 2.911174253049139
Validation loss: 2.1336857621543093
Epoch: 11| Step: 13
Training loss: 2.5403542387240257
Validation loss: 2.051743622416385
Epoch: 11| Step: 14
Training loss: 1.8432763347930448
Validation loss: 2.111702665489682
Epoch: 11| Step: 15
Training loss: 2.262716386258144
Validation loss: 2.121439644447311
Epoch: 11| Step: 16
Training loss: 3.3236145115868747
Validation loss: 2.137409592062259
Epoch: 11| Step: 17
Training loss: 2.511614143245977
Validation loss: 2.158475780502635
Epoch: 11| Step: 18
Training loss: 3.116661237688147
Validation loss: 2.118948257005118
Epoch: 11| Step: 19
Training loss: 2.3062124605922834
Validation loss: 2.1447473255915583
Epoch: 11| Step: 20
Training loss: 2.4253119907051754
Validation loss: 2.1272061344331967
Epoch: 11| Step: 21
Training loss: 2.641649487637118
Validation loss: 2.1324188928044645
Epoch: 11| Step: 22
Training loss: 2.6790760109980227
Validation loss: 2.096316129870591
Epoch: 11| Step: 23
Training loss: 2.4798032333393554
Validation loss: 2.1606908319882603
Epoch: 11| Step: 24
Training loss: 3.1200331316924963
Validation loss: 2.0868954990923716
Epoch: 11| Step: 25
Training loss: 2.05789908282727
Validation loss: 2.0807327684576107
Epoch: 11| Step: 26
Training loss: 2.675205764699958
Validation loss: 2.1194789936012666
Epoch: 11| Step: 27
Training loss: 2.7974230692822
Validation loss: 2.076259265887177
Epoch: 11| Step: 28
Training loss: 2.847077654964978
Validation loss: 2.090636513439654
Epoch: 11| Step: 29
Training loss: 2.719990239125858
Validation loss: 2.122994178903405
Epoch: 11| Step: 30
Training loss: 2.713101098043858
Validation loss: 2.112409354265181
Epoch: 11| Step: 31
Training loss: 2.6935415448386855
Validation loss: 2.1301072212339403
Epoch: 12| Step: 0
Training loss: 2.78604244562966
Validation loss: 2.158324116919206
Epoch: 12| Step: 1
Training loss: 2.4785093723756337
Validation loss: 2.1702443231487525
Epoch: 12| Step: 2
Training loss: 2.375656338399452
Validation loss: 2.1513799276234766
Epoch: 12| Step: 3
Training loss: 2.228373222916568
Validation loss: 2.1547422790171455
Epoch: 12| Step: 4
Training loss: 3.160746025437174
Validation loss: 2.1243618732748826
Epoch: 12| Step: 5
Training loss: 2.529132758158878
Validation loss: 2.1600753061939595
Epoch: 12| Step: 6
Training loss: 2.72865403192265
Validation loss: 2.1406250126689885
Epoch: 12| Step: 7
Training loss: 3.0461097734474523
Validation loss: 2.0675901932115925
Epoch: 12| Step: 8
Training loss: 2.5585320618159804
Validation loss: 2.0920706256896056
Epoch: 12| Step: 9
Training loss: 2.263691254500738
Validation loss: 2.1494410815723737
Epoch: 12| Step: 10
Training loss: 2.4164673514770265
Validation loss: 2.16142533217063
Epoch: 12| Step: 11
Training loss: 3.311994694009852
Validation loss: 2.11009466267702
Epoch: 12| Step: 12
Training loss: 2.583105651502418
Validation loss: 2.127314003127031
Epoch: 12| Step: 13
Training loss: 2.2715891242372654
Validation loss: 2.0949716154219034
Epoch: 12| Step: 14
Training loss: 3.828721229676775
Validation loss: 2.1378791061813014
Epoch: 12| Step: 15
Training loss: 2.116303431765283
Validation loss: 2.1105790418103325
Epoch: 12| Step: 16
Training loss: 2.926312020291086
Validation loss: 2.1296607978420337
Epoch: 12| Step: 17
Training loss: 2.6353946328027362
Validation loss: 2.0963050484794654
Epoch: 12| Step: 18
Training loss: 2.5356267131059638
Validation loss: 2.1206082907671666
Epoch: 12| Step: 19
Training loss: 3.1188345551734455
Validation loss: 2.12337762207642
Epoch: 12| Step: 20
Training loss: 2.5553050563424398
Validation loss: 2.0744095374433673
Epoch: 12| Step: 21
Training loss: 2.036611904067765
Validation loss: 2.0879428852767075
Epoch: 12| Step: 22
Training loss: 2.133963585182686
Validation loss: 2.1366624140134283
Epoch: 12| Step: 23
Training loss: 2.1189484539882466
Validation loss: 2.1784516398775637
Epoch: 12| Step: 24
Training loss: 2.5873994411517733
Validation loss: 2.1230516336154945
Epoch: 12| Step: 25
Training loss: 2.332686697959021
Validation loss: 2.1555056695538046
Epoch: 12| Step: 26
Training loss: 3.2527902802892084
Validation loss: 2.1130260713702906
Epoch: 12| Step: 27
Training loss: 2.4738606537391417
Validation loss: 2.168440232446644
Epoch: 12| Step: 28
Training loss: 3.003765762675086
Validation loss: 2.1449223263231727
Epoch: 12| Step: 29
Training loss: 2.5822605140923294
Validation loss: 2.14412002317785
Epoch: 12| Step: 30
Training loss: 3.0768329212845615
Validation loss: 2.1379858992773224
Epoch: 12| Step: 31
Training loss: 1.9469038494293265
Validation loss: 2.1551627445354677
Epoch: 13| Step: 0
Training loss: 2.556541213630194
Validation loss: 2.1146586618713177
Epoch: 13| Step: 1
Training loss: 3.0978232647776025
Validation loss: 2.0762349525127917
Epoch: 13| Step: 2
Training loss: 2.7169677329620217
Validation loss: 2.090572630369735
Epoch: 13| Step: 3
Training loss: 2.935112490212291
Validation loss: 2.0667764760884744
Epoch: 13| Step: 4
Training loss: 2.413646674530101
Validation loss: 2.2027269381728205
Epoch: 13| Step: 5
Training loss: 2.5593281165219945
Validation loss: 2.111968241279266
Epoch: 13| Step: 6
Training loss: 3.31039649824397
Validation loss: 2.142489134656611
Epoch: 13| Step: 7
Training loss: 2.8202704006444956
Validation loss: 2.1773155886542788
Epoch: 13| Step: 8
Training loss: 2.5496234690605544
Validation loss: 2.091118579864711
Epoch: 13| Step: 9
Training loss: 2.859279943668449
Validation loss: 2.0878797732877787
Epoch: 13| Step: 10
Training loss: 2.7871670305989054
Validation loss: 2.1357676458930204
Epoch: 13| Step: 11
Training loss: 2.421876575100294
Validation loss: 2.122392575805748
Epoch: 13| Step: 12
Training loss: 3.339273183171108
Validation loss: 2.0335779416419375
Epoch: 13| Step: 13
Training loss: 1.7324752025288326
Validation loss: 2.0844388221352608
Epoch: 13| Step: 14
Training loss: 2.779303737693565
Validation loss: 2.1507799609550178
Epoch: 13| Step: 15
Training loss: 2.101588819828216
Validation loss: 2.0994469965148714
Epoch: 13| Step: 16
Training loss: 2.840034321053741
Validation loss: 2.129522813590275
Epoch: 13| Step: 17
Training loss: 1.958606383043653
Validation loss: 2.1003381407303676
Epoch: 13| Step: 18
Training loss: 2.7398410767737174
Validation loss: 2.0857931885423904
Epoch: 13| Step: 19
Training loss: 2.5494990024957467
Validation loss: 2.077741666134652
Epoch: 13| Step: 20
Training loss: 2.2200867830102227
Validation loss: 2.148679575751706
Epoch: 13| Step: 21
Training loss: 3.3776339390172194
Validation loss: 2.157176882749082
Epoch: 13| Step: 22
Training loss: 2.655453371753702
Validation loss: 2.124435599595987
Epoch: 13| Step: 23
Training loss: 3.142831511207197
Validation loss: 2.1642651669109436
Epoch: 13| Step: 24
Training loss: 3.3989641855703687
Validation loss: 2.1309903609479783
Epoch: 13| Step: 25
Training loss: 2.2631824876109756
Validation loss: 2.0573344234429176
Epoch: 13| Step: 26
Training loss: 2.7373869084378293
Validation loss: 2.0877283010589682
Epoch: 13| Step: 27
Training loss: 2.709406263617652
Validation loss: 2.126828136871161
Epoch: 13| Step: 28
Training loss: 1.9280169588110823
Validation loss: 2.080518472090448
Epoch: 13| Step: 29
Training loss: 1.8964625631348995
Validation loss: 2.1321073126745196
Epoch: 13| Step: 30
Training loss: 2.2986199633942324
Validation loss: 2.146223387592417
Epoch: 13| Step: 31
Training loss: 2.814859714298679
Validation loss: 2.1235468334501175
Epoch: 14| Step: 0
Training loss: 3.044210667772964
Validation loss: 2.136069414507475
Epoch: 14| Step: 1
Training loss: 2.29947115996462
Validation loss: 2.1573669095802965
Epoch: 14| Step: 2
Training loss: 1.7415388464985573
Validation loss: 2.0784630448335677
Epoch: 14| Step: 3
Training loss: 2.2281648993430783
Validation loss: 2.1362529870303
Epoch: 14| Step: 4
Training loss: 2.182365058144324
Validation loss: 2.0796802257095583
Epoch: 14| Step: 5
Training loss: 2.437324126329847
Validation loss: 2.093732781273537
Epoch: 14| Step: 6
Training loss: 3.084197430199978
Validation loss: 2.157221080106409
Epoch: 14| Step: 7
Training loss: 3.2347926363158703
Validation loss: 2.1119756153674376
Epoch: 14| Step: 8
Training loss: 2.690151857960881
Validation loss: 2.1417438024288575
Epoch: 14| Step: 9
Training loss: 2.250851681900608
Validation loss: 2.1005166499127537
Epoch: 14| Step: 10
Training loss: 2.3233947832071142
Validation loss: 2.1273428639988774
Epoch: 14| Step: 11
Training loss: 3.2356091784509866
Validation loss: 2.102574178453552
Epoch: 14| Step: 12
Training loss: 2.536327591071579
Validation loss: 2.080785632147976
Epoch: 14| Step: 13
Training loss: 2.751100320033101
Validation loss: 2.137435446855377
Epoch: 14| Step: 14
Training loss: 2.878658454820877
Validation loss: 2.0949063638826835
Epoch: 14| Step: 15
Training loss: 2.525755110280035
Validation loss: 2.089440602709227
Epoch: 14| Step: 16
Training loss: 2.1417547432962833
Validation loss: 2.13866882800575
Epoch: 14| Step: 17
Training loss: 3.0428424461311727
Validation loss: 2.166107915217687
Epoch: 14| Step: 18
Training loss: 2.578259643737873
Validation loss: 2.1211892609374483
Epoch: 14| Step: 19
Training loss: 3.154639862592669
Validation loss: 2.135655658335104
Epoch: 14| Step: 20
Training loss: 2.430233516854224
Validation loss: 2.1331520462992306
Epoch: 14| Step: 21
Training loss: 2.339841508307044
Validation loss: 2.15281501517101
Epoch: 14| Step: 22
Training loss: 2.7258175594659075
Validation loss: 2.0984206946726838
Epoch: 14| Step: 23
Training loss: 2.944968772683765
Validation loss: 2.1075298270734093
Epoch: 14| Step: 24
Training loss: 3.0365208684240916
Validation loss: 2.101601191300222
Epoch: 14| Step: 25
Training loss: 2.431737396888393
Validation loss: 2.1242268916697253
Epoch: 14| Step: 26
Training loss: 3.1199845311197087
Validation loss: 2.1168571245758785
Epoch: 14| Step: 27
Training loss: 2.1420867829467247
Validation loss: 2.1022745690035176
Epoch: 14| Step: 28
Training loss: 2.6805514619452318
Validation loss: 2.1440674460238025
Epoch: 14| Step: 29
Training loss: 2.5487670423415927
Validation loss: 2.1516194854386326
Epoch: 14| Step: 30
Training loss: 2.623088594901606
Validation loss: 2.0359899388928224
Epoch: 14| Step: 31
Training loss: 2.464341295298676
Validation loss: 2.123479419864647
Epoch: 15| Step: 0
Training loss: 2.645753654021121
Validation loss: 2.132663068800188
Epoch: 15| Step: 1
Training loss: 2.9277293260567707
Validation loss: 2.0725027220850576
Epoch: 15| Step: 2
Training loss: 2.017717207096604
Validation loss: 2.093322855572343
Epoch: 15| Step: 3
Training loss: 2.461948247760724
Validation loss: 2.1372778729941455
Epoch: 15| Step: 4
Training loss: 3.16907802591902
Validation loss: 2.0896911623599257
Epoch: 15| Step: 5
Training loss: 2.1008433419694956
Validation loss: 2.139407155853821
Epoch: 15| Step: 6
Training loss: 2.7144022411057236
Validation loss: 2.0931879285322674
Epoch: 15| Step: 7
Training loss: 2.421686472784419
Validation loss: 2.158965757848006
Epoch: 15| Step: 8
Training loss: 2.929126899489086
Validation loss: 2.0213281453072267
Epoch: 15| Step: 9
Training loss: 3.208002758747922
Validation loss: 2.161959352936025
Epoch: 15| Step: 10
Training loss: 3.1296465089716063
Validation loss: 2.1435621611943487
Epoch: 15| Step: 11
Training loss: 2.283567531668791
Validation loss: 2.104364690717639
Epoch: 15| Step: 12
Training loss: 2.6026898481764555
Validation loss: 2.1235567093617416
Epoch: 15| Step: 13
Training loss: 2.6951834385144235
Validation loss: 2.0500969549340016
Epoch: 15| Step: 14
Training loss: 2.74296058994732
Validation loss: 2.0355470544888035
Epoch: 15| Step: 15
Training loss: 2.7759786649977967
Validation loss: 2.1282356688504596
Epoch: 15| Step: 16
Training loss: 2.6284696264574703
Validation loss: 2.130242636125116
Epoch: 15| Step: 17
Training loss: 2.408528029899795
Validation loss: 2.185570503302748
Epoch: 15| Step: 18
Training loss: 2.653543237581517
Validation loss: 2.0485112667881613
Epoch: 15| Step: 19
Training loss: 2.9075084955775226
Validation loss: 2.1367430972123165
Epoch: 15| Step: 20
Training loss: 2.9879970440320123
Validation loss: 2.11906768334804
Epoch: 15| Step: 21
Training loss: 2.5554456606562095
Validation loss: 2.1210276852000525
Epoch: 15| Step: 22
Training loss: 2.376669146610944
Validation loss: 2.1604992360908097
Epoch: 15| Step: 23
Training loss: 2.8423988569880603
Validation loss: 2.142942561987722
Epoch: 15| Step: 24
Training loss: 2.902122109166193
Validation loss: 2.179830930592063
Epoch: 15| Step: 25
Training loss: 2.3287136690558397
Validation loss: 2.1877614317452196
Epoch: 15| Step: 26
Training loss: 2.779091672633766
Validation loss: 2.0678503321168016
Epoch: 15| Step: 27
Training loss: 2.5126223444212252
Validation loss: 2.158416709099463
Epoch: 15| Step: 28
Training loss: 2.7337694642011123
Validation loss: 2.11115776870733
Epoch: 15| Step: 29
Training loss: 3.034209389690072
Validation loss: 2.133354052273293
Epoch: 15| Step: 30
Training loss: 2.053575570238569
Validation loss: 2.1329664829985457
Epoch: 15| Step: 31
Training loss: 2.2079441039432353
Validation loss: 2.0980520692683378
Epoch: 16| Step: 0
Training loss: 3.285472949861627
Validation loss: 2.109638054327652
Epoch: 16| Step: 1
Training loss: 2.459016370981769
Validation loss: 2.1008522547091832
Epoch: 16| Step: 2
Training loss: 2.91212787788597
Validation loss: 2.0849908128616326
Epoch: 16| Step: 3
Training loss: 2.437614731656045
Validation loss: 2.137767840877483
Epoch: 16| Step: 4
Training loss: 2.130639279027589
Validation loss: 2.141117732118424
Epoch: 16| Step: 5
Training loss: 2.6185562426281557
Validation loss: 2.096804942829708
Epoch: 16| Step: 6
Training loss: 2.907985702185657
Validation loss: 2.1294013800233227
Epoch: 16| Step: 7
Training loss: 3.1898749984118755
Validation loss: 2.1061570211489613
Epoch: 16| Step: 8
Training loss: 2.725923917037497
Validation loss: 2.1098995088781702
Epoch: 16| Step: 9
Training loss: 2.2396041396009965
Validation loss: 2.116122203580473
Epoch: 16| Step: 10
Training loss: 2.4864404118092738
Validation loss: 2.104979111170645
Epoch: 16| Step: 11
Training loss: 2.964126681134179
Validation loss: 2.123689594480765
Epoch: 16| Step: 12
Training loss: 3.007694232151302
Validation loss: 2.042014275463242
Epoch: 16| Step: 13
Training loss: 2.7161902292682423
Validation loss: 2.1222196344999342
Epoch: 16| Step: 14
Training loss: 2.9179757767966765
Validation loss: 2.0748522183364675
Epoch: 16| Step: 15
Training loss: 2.9207928127320546
Validation loss: 2.1223572756808786
Epoch: 16| Step: 16
Training loss: 2.2189921931937007
Validation loss: 2.1128170498818126
Epoch: 16| Step: 17
Training loss: 3.0523844669107283
Validation loss: 2.1709805958122685
Epoch: 16| Step: 18
Training loss: 2.2283869178775535
Validation loss: 2.1263064112212113
Epoch: 16| Step: 19
Training loss: 2.337511125833889
Validation loss: 2.091357667018445
Epoch: 16| Step: 20
Training loss: 2.2946274329065206
Validation loss: 2.1199639894123647
Epoch: 16| Step: 21
Training loss: 3.0399879282159543
Validation loss: 2.098158004725431
Epoch: 16| Step: 22
Training loss: 2.7445974166630016
Validation loss: 2.173107080588428
Epoch: 16| Step: 23
Training loss: 2.7504270395415524
Validation loss: 2.1525671526275563
Epoch: 16| Step: 24
Training loss: 2.6916594144016823
Validation loss: 2.1801617952677064
Epoch: 16| Step: 25
Training loss: 1.9764550824435323
Validation loss: 2.1612782633205008
Epoch: 16| Step: 26
Training loss: 2.494711145257644
Validation loss: 2.1296899048476527
Epoch: 16| Step: 27
Training loss: 2.7810084205892265
Validation loss: 2.1133252407320677
Epoch: 16| Step: 28
Training loss: 2.5652900021747187
Validation loss: 2.153662864116618
Epoch: 16| Step: 29
Training loss: 2.2645871646384284
Validation loss: 2.1258397413973755
Epoch: 16| Step: 30
Training loss: 2.743876314840036
Validation loss: 2.1505937459300974
Epoch: 16| Step: 31
Training loss: 2.2972600704930937
Validation loss: 2.1056061699056325
Epoch: 17| Step: 0
Training loss: 2.440939213140822
Validation loss: 2.0851053388889755
Epoch: 17| Step: 1
Training loss: 2.390894556743066
Validation loss: 2.0984049537979903
Epoch: 17| Step: 2
Training loss: 2.7002723944976523
Validation loss: 2.0986351905351364
Epoch: 17| Step: 3
Training loss: 2.352308490834794
Validation loss: 2.1326209183670177
Epoch: 17| Step: 4
Training loss: 2.8423735253103617
Validation loss: 2.119294982419105
Epoch: 17| Step: 5
Training loss: 2.2234548196768116
Validation loss: 2.168480255661621
Epoch: 17| Step: 6
Training loss: 2.7857910117737292
Validation loss: 2.101725859395769
Epoch: 17| Step: 7
Training loss: 3.0586311659588836
Validation loss: 2.1002419542823647
Epoch: 17| Step: 8
Training loss: 2.6467409354422475
Validation loss: 2.1466075282246493
Epoch: 17| Step: 9
Training loss: 2.8664240431317807
Validation loss: 2.1609671108209367
Epoch: 17| Step: 10
Training loss: 2.394621357303642
Validation loss: 2.1250697540761876
Epoch: 17| Step: 11
Training loss: 3.29330381089336
Validation loss: 2.010166972178508
Epoch: 17| Step: 12
Training loss: 2.2363480612853177
Validation loss: 2.0927427970406045
Epoch: 17| Step: 13
Training loss: 3.444206215881902
Validation loss: 2.0980462695196476
Epoch: 17| Step: 14
Training loss: 2.521815295263087
Validation loss: 2.0917497784314807
Epoch: 17| Step: 15
Training loss: 2.3237870528707756
Validation loss: 2.112719363220095
Epoch: 17| Step: 16
Training loss: 2.1264836237151488
Validation loss: 2.1161474067701698
Epoch: 17| Step: 17
Training loss: 2.15659650147027
Validation loss: 2.1403818168046036
Epoch: 17| Step: 18
Training loss: 2.5482334188563494
Validation loss: 2.0751363015963196
Epoch: 17| Step: 19
Training loss: 3.1032278360804435
Validation loss: 2.1066473590931976
Epoch: 17| Step: 20
Training loss: 2.6487048528981316
Validation loss: 2.1472358270066603
Epoch: 17| Step: 21
Training loss: 3.1606755719958244
Validation loss: 2.1141356661142168
Epoch: 17| Step: 22
Training loss: 2.656235369473724
Validation loss: 2.08050062158638
Epoch: 17| Step: 23
Training loss: 2.146990590544409
Validation loss: 2.1460019777918684
Epoch: 17| Step: 24
Training loss: 3.2214327992510308
Validation loss: 2.138473326415689
Epoch: 17| Step: 25
Training loss: 2.110027523132451
Validation loss: 2.126577954381933
Epoch: 17| Step: 26
Training loss: 2.4460055310677276
Validation loss: 2.1261099298568706
Epoch: 17| Step: 27
Training loss: 2.608735514419178
Validation loss: 2.1371283052697105
Epoch: 17| Step: 28
Training loss: 2.668359060487099
Validation loss: 2.088325908276607
Epoch: 17| Step: 29
Training loss: 2.510549982311462
Validation loss: 2.092638516337886
Epoch: 17| Step: 30
Training loss: 2.4056695014958405
Validation loss: 2.1174328630928305
Epoch: 17| Step: 31
Training loss: 2.884995706379834
Validation loss: 2.1657882978671625
Epoch: 18| Step: 0
Training loss: 2.90732644767736
Validation loss: 2.1415015205562886
Epoch: 18| Step: 1
Training loss: 2.3784942019546085
Validation loss: 2.1336483145816065
Epoch: 18| Step: 2
Training loss: 2.900279978687049
Validation loss: 2.0975754767155785
Epoch: 18| Step: 3
Training loss: 1.3620231528926015
Validation loss: 2.120148544614092
Epoch: 18| Step: 4
Training loss: 2.401908127900963
Validation loss: 2.1382388972380646
Epoch: 18| Step: 5
Training loss: 2.513500098084842
Validation loss: 2.0967603901449254
Epoch: 18| Step: 6
Training loss: 2.926803919442047
Validation loss: 2.094394662851584
Epoch: 18| Step: 7
Training loss: 3.223310184599456
Validation loss: 2.1210235533183743
Epoch: 18| Step: 8
Training loss: 2.6657139645898846
Validation loss: 2.1089159374345723
Epoch: 18| Step: 9
Training loss: 2.839102332130198
Validation loss: 2.137984738765839
Epoch: 18| Step: 10
Training loss: 3.08899639485335
Validation loss: 2.1395302638177736
Epoch: 18| Step: 11
Training loss: 2.9308614184527397
Validation loss: 2.152070696357614
Epoch: 18| Step: 12
Training loss: 2.6348587370326766
Validation loss: 2.1515284406480153
Epoch: 18| Step: 13
Training loss: 2.862424964421062
Validation loss: 2.0981064268771776
Epoch: 18| Step: 14
Training loss: 2.8593097950322357
Validation loss: 2.175202881232937
Epoch: 18| Step: 15
Training loss: 2.591173753955388
Validation loss: 2.1215201933576315
Epoch: 18| Step: 16
Training loss: 2.342383024212031
Validation loss: 2.090170747569101
Epoch: 18| Step: 17
Training loss: 2.081111282445481
Validation loss: 2.1708005005364472
Epoch: 18| Step: 18
Training loss: 2.758086366536305
Validation loss: 2.1407949745835473
Epoch: 18| Step: 19
Training loss: 2.6518069638441695
Validation loss: 2.1618982619578713
Epoch: 18| Step: 20
Training loss: 2.1784928305426736
Validation loss: 2.1066657834292197
Epoch: 18| Step: 21
Training loss: 3.1242951170356044
Validation loss: 2.12986662746192
Epoch: 18| Step: 22
Training loss: 2.9096094219362527
Validation loss: 2.081298860919059
Epoch: 18| Step: 23
Training loss: 2.288528327978263
Validation loss: 2.082966610449695
Epoch: 18| Step: 24
Training loss: 2.979412006510851
Validation loss: 2.083388098338941
Epoch: 18| Step: 25
Training loss: 2.4958197931379855
Validation loss: 2.100141748427468
Epoch: 18| Step: 26
Training loss: 2.401504593339062
Validation loss: 2.061192578875399
Epoch: 18| Step: 27
Training loss: 2.824930315086589
Validation loss: 2.142241421956268
Epoch: 18| Step: 28
Training loss: 3.116578006673295
Validation loss: 2.142113716596494
Epoch: 18| Step: 29
Training loss: 2.232892805274403
Validation loss: 2.0842202282835545
Epoch: 18| Step: 30
Training loss: 2.366213758768438
Validation loss: 2.13329035183638
Epoch: 18| Step: 31
Training loss: 2.409397494239546
Validation loss: 2.101443083049557
Epoch: 19| Step: 0
Training loss: 2.5936729695475154
Validation loss: 2.1494869518298696
Epoch: 19| Step: 1
Training loss: 2.4535737811652583
Validation loss: 2.11709466193197
Epoch: 19| Step: 2
Training loss: 2.1372703384250946
Validation loss: 2.1366889115831507
Epoch: 19| Step: 3
Training loss: 2.710995632284903
Validation loss: 2.1594861796862577
Epoch: 19| Step: 4
Training loss: 2.934289192025722
Validation loss: 2.1107266364692303
Epoch: 19| Step: 5
Training loss: 2.312463502338144
Validation loss: 2.094886546530075
Epoch: 19| Step: 6
Training loss: 2.4705800866412035
Validation loss: 2.109977639077995
Epoch: 19| Step: 7
Training loss: 2.7307416045546944
Validation loss: 2.084708108433206
Epoch: 19| Step: 8
Training loss: 3.0275696110302386
Validation loss: 2.1257595807566356
Epoch: 19| Step: 9
Training loss: 3.2076137445846316
Validation loss: 2.0810017091484023
Epoch: 19| Step: 10
Training loss: 3.036392725938595
Validation loss: 2.1457643011473992
Epoch: 19| Step: 11
Training loss: 1.7635253980606864
Validation loss: 2.13343891618541
Epoch: 19| Step: 12
Training loss: 2.6105996187787723
Validation loss: 2.118681973561624
Epoch: 19| Step: 13
Training loss: 3.1168884286845553
Validation loss: 2.1012519666960734
Epoch: 19| Step: 14
Training loss: 3.079148795179675
Validation loss: 2.101046088917759
Epoch: 19| Step: 15
Training loss: 2.6320927482252614
Validation loss: 2.1004394838149283
Epoch: 19| Step: 16
Training loss: 2.7525936380339577
Validation loss: 2.146183785516072
Epoch: 19| Step: 17
Training loss: 2.5261969344932833
Validation loss: 2.141480242907941
Epoch: 19| Step: 18
Training loss: 2.7457810029835255
Validation loss: 2.1607856690129683
Epoch: 19| Step: 19
Training loss: 2.538574641382322
Validation loss: 2.140984806463339
Epoch: 19| Step: 20
Training loss: 2.6495605608225508
Validation loss: 2.144121486554496
Epoch: 19| Step: 21
Training loss: 2.7386429094821287
Validation loss: 2.12311124246978
Epoch: 19| Step: 22
Training loss: 2.6368896428994835
Validation loss: 2.1638636389915726
Epoch: 19| Step: 23
Training loss: 1.989458616119183
Validation loss: 2.1226045077829943
Epoch: 19| Step: 24
Training loss: 2.855961330526021
Validation loss: 2.167239519663279
Epoch: 19| Step: 25
Training loss: 3.2515129089240005
Validation loss: 2.1352187658506128
Epoch: 19| Step: 26
Training loss: 2.4572474349696733
Validation loss: 2.0254680049135363
Epoch: 19| Step: 27
Training loss: 2.3850024556401244
Validation loss: 2.111783110232656
Epoch: 19| Step: 28
Training loss: 2.453440846319544
Validation loss: 2.116367946810854
Epoch: 19| Step: 29
Training loss: 2.2881248037738815
Validation loss: 2.0627634265727557
Epoch: 19| Step: 30
Training loss: 2.6791723885086998
Validation loss: 2.1437434150442276
Epoch: 19| Step: 31
Training loss: 2.5346217363433134
Validation loss: 2.0875161972553453
Epoch: 20| Step: 0
Training loss: 2.10887354789025
Validation loss: 2.095586947241746
Epoch: 20| Step: 1
Training loss: 2.531221648634386
Validation loss: 2.1695543291448347
Epoch: 20| Step: 2
Training loss: 3.4760151978787133
Validation loss: 2.1112057459118323
Epoch: 20| Step: 3
Training loss: 2.444385194301196
Validation loss: 2.1065533846988953
Epoch: 20| Step: 4
Training loss: 2.502094345216767
Validation loss: 2.0595400798117875
Epoch: 20| Step: 5
Training loss: 2.614769755451412
Validation loss: 2.0853768004587976
Epoch: 20| Step: 6
Training loss: 2.8066251644167943
Validation loss: 2.0988745210197273
Epoch: 20| Step: 7
Training loss: 2.496867506185465
Validation loss: 2.1402629939534346
Epoch: 20| Step: 8
Training loss: 2.4275577938220527
Validation loss: 2.14094692049543
Epoch: 20| Step: 9
Training loss: 2.636076581956822
Validation loss: 2.1065126577943762
Epoch: 20| Step: 10
Training loss: 3.0081552285459474
Validation loss: 2.080531371025827
Epoch: 20| Step: 11
Training loss: 2.5508797642610106
Validation loss: 2.150982554611013
Epoch: 20| Step: 12
Training loss: 3.429335730376328
Validation loss: 2.1132851724353245
Epoch: 20| Step: 13
Training loss: 2.929308243681266
Validation loss: 2.0892971079042266
Epoch: 20| Step: 14
Training loss: 2.3784393704288855
Validation loss: 2.097465046849391
Epoch: 20| Step: 15
Training loss: 2.760262327857863
Validation loss: 2.0992612105936597
Epoch: 20| Step: 16
Training loss: 2.574475288632576
Validation loss: 2.088427755136823
Epoch: 20| Step: 17
Training loss: 2.6463608603845477
Validation loss: 2.1084519816791167
Epoch: 20| Step: 18
Training loss: 2.5168108307260426
Validation loss: 2.1292398786612585
Epoch: 20| Step: 19
Training loss: 2.143686708455788
Validation loss: 2.0763146257196614
Epoch: 20| Step: 20
Training loss: 2.0698265800993547
Validation loss: 2.146090528013428
Epoch: 20| Step: 21
Training loss: 2.6105469224910682
Validation loss: 2.1367410983791633
Epoch: 20| Step: 22
Training loss: 3.552717329406951
Validation loss: 2.1121740976137318
Epoch: 20| Step: 23
Training loss: 3.1204564442906957
Validation loss: 2.1036443148386854
Epoch: 20| Step: 24
Training loss: 3.024810715735421
Validation loss: 2.094840803481718
Epoch: 20| Step: 25
Training loss: 1.0892205866567108
Validation loss: 2.112404206583675
Epoch: 20| Step: 26
Training loss: 2.946056160779326
Validation loss: 2.1277643992278343
Epoch: 20| Step: 27
Training loss: 2.78796211141403
Validation loss: 2.099985185455088
Epoch: 20| Step: 28
Training loss: 2.5744709360242055
Validation loss: 2.1342124319133884
Epoch: 20| Step: 29
Training loss: 2.459384585680573
Validation loss: 2.099873039495706
Epoch: 20| Step: 30
Training loss: 1.7285732108830942
Validation loss: 2.176726202592816
Epoch: 20| Step: 31
Training loss: 2.777068090909741
Validation loss: 2.0792808643882603
Epoch: 21| Step: 0
Training loss: 2.7489615126795353
Validation loss: 2.068518700635337
Epoch: 21| Step: 1
Training loss: 2.3441662228074542
Validation loss: 2.1136921370711326
Epoch: 21| Step: 2
Training loss: 2.8329970403319846
Validation loss: 2.084229634664867
Epoch: 21| Step: 3
Training loss: 2.2857243801643357
Validation loss: 2.094980194994531
Epoch: 21| Step: 4
Training loss: 2.0423532875438952
Validation loss: 2.1043864601111166
Epoch: 21| Step: 5
Training loss: 2.824234029852554
Validation loss: 2.1283950471784907
Epoch: 21| Step: 6
Training loss: 2.265091405712562
Validation loss: 2.1318617976862955
Epoch: 21| Step: 7
Training loss: 3.178019468042607
Validation loss: 2.102081510239603
Epoch: 21| Step: 8
Training loss: 2.282421177216488
Validation loss: 2.173929735856352
Epoch: 21| Step: 9
Training loss: 2.723525314972561
Validation loss: 2.127242365788897
Epoch: 21| Step: 10
Training loss: 2.2930176191954823
Validation loss: 2.1002418725971683
Epoch: 21| Step: 11
Training loss: 3.301217062806407
Validation loss: 2.069633719053631
Epoch: 21| Step: 12
Training loss: 2.362883933220707
Validation loss: 2.078799318830443
Epoch: 21| Step: 13
Training loss: 2.65914050636187
Validation loss: 2.1292281764496654
Epoch: 21| Step: 14
Training loss: 2.821642955478365
Validation loss: 2.146767304966978
Epoch: 21| Step: 15
Training loss: 2.0582798640710482
Validation loss: 2.1205583815075473
Epoch: 21| Step: 16
Training loss: 2.8050837754847526
Validation loss: 2.071384236760289
Epoch: 21| Step: 17
Training loss: 2.690713513698378
Validation loss: 2.1189768784912526
Epoch: 21| Step: 18
Training loss: 1.4701948161362148
Validation loss: 2.0812366781857787
Epoch: 21| Step: 19
Training loss: 2.9380528355905513
Validation loss: 2.1132765522602828
Epoch: 21| Step: 20
Training loss: 2.981706314832599
Validation loss: 2.1317547584925025
Epoch: 21| Step: 21
Training loss: 2.191401027734419
Validation loss: 2.1045131476431527
Epoch: 21| Step: 22
Training loss: 3.1296052187741537
Validation loss: 2.122139863190137
Epoch: 21| Step: 23
Training loss: 3.159582059963016
Validation loss: 2.103787389365088
Epoch: 21| Step: 24
Training loss: 2.9847709033661283
Validation loss: 2.105661116789486
Epoch: 21| Step: 25
Training loss: 2.095139796616088
Validation loss: 2.1034024436003276
Epoch: 21| Step: 26
Training loss: 2.5008213601296596
Validation loss: 2.0918980704421406
Epoch: 21| Step: 27
Training loss: 2.604906195857173
Validation loss: 2.0838852907792793
Epoch: 21| Step: 28
Training loss: 2.9435984837765163
Validation loss: 2.1402776859720793
Epoch: 21| Step: 29
Training loss: 3.4940025170092803
Validation loss: 2.1453717475754237
Epoch: 21| Step: 30
Training loss: 1.7686932665888835
Validation loss: 2.1023735987710657
Epoch: 21| Step: 31
Training loss: 2.8305422742550967
Validation loss: 2.089384303741368
Epoch: 22| Step: 0
Training loss: 2.5344009567417882
Validation loss: 2.121628263944199
Epoch: 22| Step: 1
Training loss: 2.978197664893443
Validation loss: 2.0789989370054625
Epoch: 22| Step: 2
Training loss: 2.6957898587981726
Validation loss: 2.1417784260410624
Epoch: 22| Step: 3
Training loss: 2.6794969140611786
Validation loss: 2.1032221896450056
Epoch: 22| Step: 4
Training loss: 3.3002533439721584
Validation loss: 2.096516389722594
Epoch: 22| Step: 5
Training loss: 3.310260231414234
Validation loss: 2.126757291943096
Epoch: 22| Step: 6
Training loss: 2.5038847304920626
Validation loss: 2.1104620897847393
Epoch: 22| Step: 7
Training loss: 2.6920197207109715
Validation loss: 2.131094575548906
Epoch: 22| Step: 8
Training loss: 2.3338680222371075
Validation loss: 2.1096125223771
Epoch: 22| Step: 9
Training loss: 1.9871433801817795
Validation loss: 2.0793882137518658
Epoch: 22| Step: 10
Training loss: 2.9054652969737815
Validation loss: 2.1233938946833177
Epoch: 22| Step: 11
Training loss: 2.4585503520111245
Validation loss: 2.0956825368244885
Epoch: 22| Step: 12
Training loss: 2.632906677191727
Validation loss: 2.152744465378456
Epoch: 22| Step: 13
Training loss: 2.842802288049239
Validation loss: 2.0899513056147594
Epoch: 22| Step: 14
Training loss: 2.188709251769576
Validation loss: 2.124683726680622
Epoch: 22| Step: 15
Training loss: 2.6866818446857845
Validation loss: 2.137759043005676
Epoch: 22| Step: 16
Training loss: 2.7798364025801705
Validation loss: 2.0499344248488227
Epoch: 22| Step: 17
Training loss: 2.0786366227290873
Validation loss: 2.089879871769021
Epoch: 22| Step: 18
Training loss: 2.8163787374858953
Validation loss: 2.1125568285300167
Epoch: 22| Step: 19
Training loss: 2.9110898971593544
Validation loss: 2.0955237277204906
Epoch: 22| Step: 20
Training loss: 2.5114025433067453
Validation loss: 2.0720047761540537
Epoch: 22| Step: 21
Training loss: 2.9312289239251794
Validation loss: 2.132945568836349
Epoch: 22| Step: 22
Training loss: 3.0894994338912185
Validation loss: 2.139152511348168
Epoch: 22| Step: 23
Training loss: 3.1354384986565154
Validation loss: 2.065657540749345
Epoch: 22| Step: 24
Training loss: 2.8279558837233734
Validation loss: 2.1320910922138037
Epoch: 22| Step: 25
Training loss: 2.719561400954575
Validation loss: 2.100585019088005
Epoch: 22| Step: 26
Training loss: 3.068395584057915
Validation loss: 2.143750477031787
Epoch: 22| Step: 27
Training loss: 2.355060801439955
Validation loss: 2.1322552043282657
Epoch: 22| Step: 28
Training loss: 2.0790851640748915
Validation loss: 2.099632264444606
Epoch: 22| Step: 29
Training loss: 2.1421491111693514
Validation loss: 2.1110566916823292
Epoch: 22| Step: 30
Training loss: 1.7991802521204932
Validation loss: 2.034560028691982
Epoch: 22| Step: 31
Training loss: 2.087391778573409
Validation loss: 2.1156556216086586
Epoch: 23| Step: 0
Training loss: 3.0791407424461767
Validation loss: 2.1258245547158188
Epoch: 23| Step: 1
Training loss: 2.8937420509179765
Validation loss: 2.0873100764599974
Epoch: 23| Step: 2
Training loss: 2.2891643618680972
Validation loss: 2.118515878580851
Epoch: 23| Step: 3
Training loss: 2.5198020612090426
Validation loss: 2.118256906971378
Epoch: 23| Step: 4
Training loss: 2.4973166370000044
Validation loss: 2.151494000653756
Epoch: 23| Step: 5
Training loss: 2.8077850663124444
Validation loss: 2.124833236894596
Epoch: 23| Step: 6
Training loss: 2.788949403152726
Validation loss: 2.0858435097240675
Epoch: 23| Step: 7
Training loss: 2.2985113633849763
Validation loss: 2.086286707159539
Epoch: 23| Step: 8
Training loss: 2.625148678156721
Validation loss: 2.0568695119570837
Epoch: 23| Step: 9
Training loss: 2.58005576228717
Validation loss: 2.163234505169068
Epoch: 23| Step: 10
Training loss: 2.442584188488246
Validation loss: 2.1279137706220714
Epoch: 23| Step: 11
Training loss: 3.0392562686761067
Validation loss: 2.103587351882925
Epoch: 23| Step: 12
Training loss: 1.9985640258344233
Validation loss: 2.0620586460983565
Epoch: 23| Step: 13
Training loss: 2.5795812944237704
Validation loss: 2.0808245732542305
Epoch: 23| Step: 14
Training loss: 2.769122396186607
Validation loss: 2.1287837170417374
Epoch: 23| Step: 15
Training loss: 3.011701967264361
Validation loss: 2.1040089178016768
Epoch: 23| Step: 16
Training loss: 2.529264636920514
Validation loss: 2.1408968638874035
Epoch: 23| Step: 17
Training loss: 2.409683453201895
Validation loss: 2.0809428219174846
Epoch: 23| Step: 18
Training loss: 3.2497628932438576
Validation loss: 2.075603025329075
Epoch: 23| Step: 19
Training loss: 2.8608329683017097
Validation loss: 2.096156660088705
Epoch: 23| Step: 20
Training loss: 2.6669862873538728
Validation loss: 2.1250635411051584
Epoch: 23| Step: 21
Training loss: 2.5804113249433698
Validation loss: 2.115115005875979
Epoch: 23| Step: 22
Training loss: 1.869135140118977
Validation loss: 2.0953407452158967
Epoch: 23| Step: 23
Training loss: 3.107170358545525
Validation loss: 2.165990898766495
Epoch: 23| Step: 24
Training loss: 2.2869806294156736
Validation loss: 2.0633694802629203
Epoch: 23| Step: 25
Training loss: 2.3126462941676773
Validation loss: 2.124932717700309
Epoch: 23| Step: 26
Training loss: 2.962507893354628
Validation loss: 2.0860008327945616
Epoch: 23| Step: 27
Training loss: 3.3250775779909563
Validation loss: 2.1357785752580964
Epoch: 23| Step: 28
Training loss: 2.068559127253934
Validation loss: 2.094860239963384
Epoch: 23| Step: 29
Training loss: 3.144551418073911
Validation loss: 2.123625676958686
Epoch: 23| Step: 30
Training loss: 2.784262408068324
Validation loss: 2.1432923980436396
Epoch: 23| Step: 31
Training loss: 1.7297240435178187
Validation loss: 2.1245835696547375
Epoch: 24| Step: 0
Training loss: 1.80031316470144
Validation loss: 2.0389988436052793
Epoch: 24| Step: 1
Training loss: 2.445433007339148
Validation loss: 2.1128420531846475
Epoch: 24| Step: 2
Training loss: 1.9313970244407743
Validation loss: 2.115739661878693
Epoch: 24| Step: 3
Training loss: 3.3268659475670272
Validation loss: 2.0670478044841394
Epoch: 24| Step: 4
Training loss: 2.645663358580149
Validation loss: 2.0967233053385064
Epoch: 24| Step: 5
Training loss: 3.41527111736605
Validation loss: 2.079987410892078
Epoch: 24| Step: 6
Training loss: 2.5707378557262057
Validation loss: 2.1241955096634273
Epoch: 24| Step: 7
Training loss: 1.9624570756822335
Validation loss: 2.10809327928466
Epoch: 24| Step: 8
Training loss: 2.2854816433326475
Validation loss: 2.0757819581531787
Epoch: 24| Step: 9
Training loss: 2.4499605993099944
Validation loss: 2.0896113610057077
Epoch: 24| Step: 10
Training loss: 1.9780328882837004
Validation loss: 2.0924821200331007
Epoch: 24| Step: 11
Training loss: 2.38600230350687
Validation loss: 2.082859675147172
Epoch: 24| Step: 12
Training loss: 3.230814867954915
Validation loss: 2.1125891908805556
Epoch: 24| Step: 13
Training loss: 2.6338747864189456
Validation loss: 2.0931550579247085
Epoch: 24| Step: 14
Training loss: 2.659909857319635
Validation loss: 2.1394855551134757
Epoch: 24| Step: 15
Training loss: 2.5875915584858755
Validation loss: 2.065637474336831
Epoch: 24| Step: 16
Training loss: 2.5293008340340637
Validation loss: 2.1528609615228387
Epoch: 24| Step: 17
Training loss: 2.496885457691355
Validation loss: 2.1206629269997417
Epoch: 24| Step: 18
Training loss: 2.624550644696796
Validation loss: 2.1372207652268234
Epoch: 24| Step: 19
Training loss: 3.060828706561451
Validation loss: 2.1074404970502494
Epoch: 24| Step: 20
Training loss: 2.80624219047972
Validation loss: 2.1017021963825395
Epoch: 24| Step: 21
Training loss: 2.689696368130495
Validation loss: 2.101283488482071
Epoch: 24| Step: 22
Training loss: 2.194506731504075
Validation loss: 2.1579787821653325
Epoch: 24| Step: 23
Training loss: 2.9201800484212876
Validation loss: 2.1233365912518565
Epoch: 24| Step: 24
Training loss: 2.573802584406923
Validation loss: 2.0777755302399
Epoch: 24| Step: 25
Training loss: 3.1637665033230293
Validation loss: 2.104707952446517
Epoch: 24| Step: 26
Training loss: 3.3666949343360155
Validation loss: 2.127949158513897
Epoch: 24| Step: 27
Training loss: 2.3215565027890426
Validation loss: 2.1063268095462595
Epoch: 24| Step: 28
Training loss: 1.9041550177531559
Validation loss: 2.1034897727999144
Epoch: 24| Step: 29
Training loss: 2.5406003080437376
Validation loss: 2.05190327133683
Epoch: 24| Step: 30
Training loss: 3.0112058843577474
Validation loss: 2.1433675682186117
Epoch: 24| Step: 31
Training loss: 3.1881173227947257
Validation loss: 2.154573661346893
Epoch: 25| Step: 0
Training loss: 2.1288020957176674
Validation loss: 2.0851867727626656
Epoch: 25| Step: 1
Training loss: 2.8409973907619848
Validation loss: 2.0750869927679925
Epoch: 25| Step: 2
Training loss: 2.078744093381343
Validation loss: 2.126735070205941
Epoch: 25| Step: 3
Training loss: 2.3987884761712244
Validation loss: 2.0754464389920666
Epoch: 25| Step: 4
Training loss: 2.5113833664778524
Validation loss: 2.1308064492007834
Epoch: 25| Step: 5
Training loss: 2.038031189370078
Validation loss: 2.1267481797452517
Epoch: 25| Step: 6
Training loss: 2.8262038476238716
Validation loss: 2.149576158062121
Epoch: 25| Step: 7
Training loss: 2.384949273263744
Validation loss: 2.1087979490047006
Epoch: 25| Step: 8
Training loss: 2.45002764861407
Validation loss: 2.070588694044876
Epoch: 25| Step: 9
Training loss: 2.1603308498464626
Validation loss: 2.103953918879519
Epoch: 25| Step: 10
Training loss: 2.4346744103484386
Validation loss: 2.1285235297638874
Epoch: 25| Step: 11
Training loss: 2.589927522389001
Validation loss: 2.067246588979354
Epoch: 25| Step: 12
Training loss: 1.7871344559373905
Validation loss: 2.108918243273636
Epoch: 25| Step: 13
Training loss: 2.0108420230041673
Validation loss: 2.113460624931969
Epoch: 25| Step: 14
Training loss: 2.6756884036697386
Validation loss: 2.041535762139108
Epoch: 25| Step: 15
Training loss: 2.881874986498404
Validation loss: 2.1390892992438038
Epoch: 25| Step: 16
Training loss: 2.9167249037968443
Validation loss: 2.101845681798543
Epoch: 25| Step: 17
Training loss: 3.0590031180588793
Validation loss: 2.0963798833713643
Epoch: 25| Step: 18
Training loss: 2.6241982461776203
Validation loss: 2.0864768313872797
Epoch: 25| Step: 19
Training loss: 2.7962509396738615
Validation loss: 2.1412644691698093
Epoch: 25| Step: 20
Training loss: 3.172598169129086
Validation loss: 2.137966717739041
Epoch: 25| Step: 21
Training loss: 2.688035246311439
Validation loss: 2.0569642851198546
Epoch: 25| Step: 22
Training loss: 3.429048726373931
Validation loss: 2.106566950193087
Epoch: 25| Step: 23
Training loss: 2.344148423980163
Validation loss: 2.1763451998272774
Epoch: 25| Step: 24
Training loss: 3.1519766100969315
Validation loss: 2.112690898450824
Epoch: 25| Step: 25
Training loss: 2.400981237570949
Validation loss: 2.0918424899725485
Epoch: 25| Step: 26
Training loss: 3.5510474043367375
Validation loss: 2.132761309923804
Epoch: 25| Step: 27
Training loss: 3.102829374155477
Validation loss: 2.1287101862076465
Epoch: 25| Step: 28
Training loss: 2.6713500817864455
Validation loss: 2.111118453378727
Epoch: 25| Step: 29
Training loss: 2.4931668357370493
Validation loss: 2.1207598909626593
Epoch: 25| Step: 30
Training loss: 3.2675609052333177
Validation loss: 2.079292602111159
Epoch: 25| Step: 31
Training loss: 2.229461709815499
Validation loss: 2.1269672434900455
Epoch: 26| Step: 0
Training loss: 3.3475085373898525
Validation loss: 2.1115780950302976
Epoch: 26| Step: 1
Training loss: 2.164115602137858
Validation loss: 2.1166995998675153
Epoch: 26| Step: 2
Training loss: 2.6432683230852536
Validation loss: 2.0993936150745
Epoch: 26| Step: 3
Training loss: 1.799155339106276
Validation loss: 2.106676137089505
Epoch: 26| Step: 4
Training loss: 2.1552826190263765
Validation loss: 2.1146625095909246
Epoch: 26| Step: 5
Training loss: 2.3401996424680664
Validation loss: 2.1573917417544295
Epoch: 26| Step: 6
Training loss: 3.1093139642446967
Validation loss: 2.075569502899628
Epoch: 26| Step: 7
Training loss: 2.417487323021615
Validation loss: 2.136889218487286
Epoch: 26| Step: 8
Training loss: 3.143267985527994
Validation loss: 2.1537256370121756
Epoch: 26| Step: 9
Training loss: 2.079370799265346
Validation loss: 2.095313973903553
Epoch: 26| Step: 10
Training loss: 3.063408074724554
Validation loss: 2.071055321346272
Epoch: 26| Step: 11
Training loss: 2.5598866231965443
Validation loss: 2.1203256580309637
Epoch: 26| Step: 12
Training loss: 3.0641305436394766
Validation loss: 2.1190236126023314
Epoch: 26| Step: 13
Training loss: 3.4203052839583825
Validation loss: 2.147925896904201
Epoch: 26| Step: 14
Training loss: 2.0085839596616952
Validation loss: 2.0876183550318217
Epoch: 26| Step: 15
Training loss: 2.7123440218611696
Validation loss: 2.1225409757656215
Epoch: 26| Step: 16
Training loss: 1.8103069981880417
Validation loss: 2.12528020596723
Epoch: 26| Step: 17
Training loss: 2.467588803472175
Validation loss: 2.086456754223278
Epoch: 26| Step: 18
Training loss: 2.559370688782951
Validation loss: 2.1664922797501207
Epoch: 26| Step: 19
Training loss: 1.8758295131640497
Validation loss: 2.120891080200531
Epoch: 26| Step: 20
Training loss: 3.0313056862032255
Validation loss: 2.110089162278476
Epoch: 26| Step: 21
Training loss: 3.0742412406360438
Validation loss: 2.158923389819475
Epoch: 26| Step: 22
Training loss: 2.921699722663022
Validation loss: 2.074179314723349
Epoch: 26| Step: 23
Training loss: 3.156497454621225
Validation loss: 2.1325164981468787
Epoch: 26| Step: 24
Training loss: 2.8917468394251244
Validation loss: 2.0953934588896095
Epoch: 26| Step: 25
Training loss: 2.825461803938885
Validation loss: 2.0816973555264853
Epoch: 26| Step: 26
Training loss: 1.9499844746093882
Validation loss: 2.052506282790392
Epoch: 26| Step: 27
Training loss: 2.4283292353099557
Validation loss: 2.1338922558046183
Epoch: 26| Step: 28
Training loss: 2.439477558487025
Validation loss: 2.1245726860819936
Epoch: 26| Step: 29
Training loss: 2.5092459411497052
Validation loss: 2.115471062172399
Epoch: 26| Step: 30
Training loss: 2.7932412181345074
Validation loss: 2.0845576129250127
Epoch: 26| Step: 31
Training loss: 2.872180385354587
Validation loss: 2.051946166674831
Epoch: 27| Step: 0
Training loss: 2.06695607015124
Validation loss: 2.1195432165246384
Epoch: 27| Step: 1
Training loss: 2.0793584160563365
Validation loss: 2.1585859887513803
Epoch: 27| Step: 2
Training loss: 3.2109826449076984
Validation loss: 2.1368543841494705
Epoch: 27| Step: 3
Training loss: 3.3135826213040183
Validation loss: 2.118838420322256
Epoch: 27| Step: 4
Training loss: 2.656515938404992
Validation loss: 2.1463229969562883
Epoch: 27| Step: 5
Training loss: 2.19790919394526
Validation loss: 2.129832474241612
Epoch: 27| Step: 6
Training loss: 2.699011257825158
Validation loss: 2.132412216883365
Epoch: 27| Step: 7
Training loss: 2.952427534462521
Validation loss: 2.1146920766276733
Epoch: 27| Step: 8
Training loss: 2.6676486313373204
Validation loss: 2.0976515804607008
Epoch: 27| Step: 9
Training loss: 2.823110275855102
Validation loss: 2.1365118182807117
Epoch: 27| Step: 10
Training loss: 2.5246206999567087
Validation loss: 2.088630555531537
Epoch: 27| Step: 11
Training loss: 2.398573682068781
Validation loss: 2.111242075711225
Epoch: 27| Step: 12
Training loss: 2.7740589573871817
Validation loss: 2.0912214956639676
Epoch: 27| Step: 13
Training loss: 1.329128738786958
Validation loss: 2.1167891540970505
Epoch: 27| Step: 14
Training loss: 2.3318158278655345
Validation loss: 2.095050341276657
Epoch: 27| Step: 15
Training loss: 2.804856574187692
Validation loss: 2.1158594458429287
Epoch: 27| Step: 16
Training loss: 2.7670265568822607
Validation loss: 2.1666266687094184
Epoch: 27| Step: 17
Training loss: 2.264610958077098
Validation loss: 2.1577665921981746
Epoch: 27| Step: 18
Training loss: 3.0961547137102934
Validation loss: 2.106986570195066
Epoch: 27| Step: 19
Training loss: 2.999063027610307
Validation loss: 2.090750688151551
Epoch: 27| Step: 20
Training loss: 2.7892903894664713
Validation loss: 2.058656862983798
Epoch: 27| Step: 21
Training loss: 3.0316849229405194
Validation loss: 2.1365614370311388
Epoch: 27| Step: 22
Training loss: 2.6070594792928214
Validation loss: 2.066712814203726
Epoch: 27| Step: 23
Training loss: 2.5930177505244565
Validation loss: 2.1466784977167537
Epoch: 27| Step: 24
Training loss: 2.8707187122187046
Validation loss: 2.0865600618345
Epoch: 27| Step: 25
Training loss: 2.0709506221025675
Validation loss: 2.075720133526014
Epoch: 27| Step: 26
Training loss: 2.226388810728181
Validation loss: 2.1024256084461395
Epoch: 27| Step: 27
Training loss: 2.2277415583650404
Validation loss: 2.075227239503789
Epoch: 27| Step: 28
Training loss: 3.117981314866784
Validation loss: 2.1199582797294685
Epoch: 27| Step: 29
Training loss: 2.5846676200698986
Validation loss: 2.125244485464899
Epoch: 27| Step: 30
Training loss: 2.9946923988586436
Validation loss: 2.078307023835589
Epoch: 27| Step: 31
Training loss: 2.689493105611281
Validation loss: 2.1140368500598075
Epoch: 28| Step: 0
Training loss: 3.057127931403075
Validation loss: 2.0875851208184404
Epoch: 28| Step: 1
Training loss: 2.5884997993220105
Validation loss: 2.1040894670099926
Epoch: 28| Step: 2
Training loss: 2.353652886784393
Validation loss: 2.135776655920223
Epoch: 28| Step: 3
Training loss: 2.5281104880766376
Validation loss: 2.0353506099166805
Epoch: 28| Step: 4
Training loss: 2.9395749494584904
Validation loss: 2.1035480487662817
Epoch: 28| Step: 5
Training loss: 2.1662489659592525
Validation loss: 2.0873107393759356
Epoch: 28| Step: 6
Training loss: 3.217956148786477
Validation loss: 2.1340341450622153
Epoch: 28| Step: 7
Training loss: 2.584087897408996
Validation loss: 2.070427350894235
Epoch: 28| Step: 8
Training loss: 3.2059632171215147
Validation loss: 2.1086079876283144
Epoch: 28| Step: 9
Training loss: 2.1038726248676465
Validation loss: 2.0747725836593465
Epoch: 28| Step: 10
Training loss: 1.9238845119829824
Validation loss: 2.0874433735940094
Epoch: 28| Step: 11
Training loss: 2.4593329148527006
Validation loss: 2.0774061424046186
Epoch: 28| Step: 12
Training loss: 2.1235847248073383
Validation loss: 2.0932054980682375
Epoch: 28| Step: 13
Training loss: 2.3236247353446653
Validation loss: 2.064932227093571
Epoch: 28| Step: 14
Training loss: 2.3340156329627595
Validation loss: 2.1264654793866
Epoch: 28| Step: 15
Training loss: 2.5863761414583495
Validation loss: 2.1035548977957257
Epoch: 28| Step: 16
Training loss: 1.948307841253574
Validation loss: 2.078209956356084
Epoch: 28| Step: 17
Training loss: 3.0164774742303417
Validation loss: 2.1669046209626583
Epoch: 28| Step: 18
Training loss: 2.221896130425136
Validation loss: 2.0942521625121606
Epoch: 28| Step: 19
Training loss: 2.7780666349478462
Validation loss: 2.1541337895962656
Epoch: 28| Step: 20
Training loss: 2.658460437841167
Validation loss: 2.1370527572605846
Epoch: 28| Step: 21
Training loss: 3.2348647184548693
Validation loss: 2.0741027371740626
Epoch: 28| Step: 22
Training loss: 2.647073129852131
Validation loss: 2.1117803554740626
Epoch: 28| Step: 23
Training loss: 3.3094756517242225
Validation loss: 2.1214120110787262
Epoch: 28| Step: 24
Training loss: 3.234726449051807
Validation loss: 2.081128982250389
Epoch: 28| Step: 25
Training loss: 2.076631855721369
Validation loss: 2.1572985707853656
Epoch: 28| Step: 26
Training loss: 2.133868392761595
Validation loss: 2.107613982731801
Epoch: 28| Step: 27
Training loss: 2.7648735965304563
Validation loss: 2.00661197302527
Epoch: 28| Step: 28
Training loss: 2.4202434335388436
Validation loss: 2.145725739650284
Epoch: 28| Step: 29
Training loss: 3.3559567115547098
Validation loss: 2.148474559823919
Epoch: 28| Step: 30
Training loss: 2.7411798870202135
Validation loss: 2.1154669279079252
Epoch: 28| Step: 31
Training loss: 2.9057211446004625
Validation loss: 2.0778100682167806
Epoch: 29| Step: 0
Training loss: 2.8146393163060868
Validation loss: 2.0396823972268154
Epoch: 29| Step: 1
Training loss: 2.144076829024787
Validation loss: 2.1045392829759213
Epoch: 29| Step: 2
Training loss: 2.848913514356003
Validation loss: 2.1113496675966714
Epoch: 29| Step: 3
Training loss: 2.981727264396938
Validation loss: 2.1052471965328703
Epoch: 29| Step: 4
Training loss: 2.699901533097389
Validation loss: 2.0980763365726336
Epoch: 29| Step: 5
Training loss: 2.388842248338108
Validation loss: 2.1140072053764336
Epoch: 29| Step: 6
Training loss: 2.5411317814894994
Validation loss: 2.1241464831841963
Epoch: 29| Step: 7
Training loss: 2.795247632761844
Validation loss: 2.1067320575728177
Epoch: 29| Step: 8
Training loss: 2.650754562050206
Validation loss: 2.1427900164242595
Epoch: 29| Step: 9
Training loss: 3.0040651435645973
Validation loss: 2.1326419697095913
Epoch: 29| Step: 10
Training loss: 3.235495552891136
Validation loss: 2.136662620957697
Epoch: 29| Step: 11
Training loss: 3.156119768836293
Validation loss: 2.145643041995699
Epoch: 29| Step: 12
Training loss: 2.941529776726417
Validation loss: 2.0503077627638913
Epoch: 29| Step: 13
Training loss: 3.059307848122271
Validation loss: 2.1344774680553864
Epoch: 29| Step: 14
Training loss: 2.7091089947453493
Validation loss: 2.096145473544709
Epoch: 29| Step: 15
Training loss: 2.1015316418505856
Validation loss: 2.0754587090406718
Epoch: 29| Step: 16
Training loss: 2.547620044159705
Validation loss: 2.132474712879726
Epoch: 29| Step: 17
Training loss: 2.0178709306981313
Validation loss: 2.108667159994908
Epoch: 29| Step: 18
Training loss: 3.184802840282225
Validation loss: 2.124950028976076
Epoch: 29| Step: 19
Training loss: 2.6041822102400705
Validation loss: 2.125820347112642
Epoch: 29| Step: 20
Training loss: 2.661100648458146
Validation loss: 2.1245579073635796
Epoch: 29| Step: 21
Training loss: 2.904144180480802
Validation loss: 2.0994585664709535
Epoch: 29| Step: 22
Training loss: 2.033211802410037
Validation loss: 2.1130566159141795
Epoch: 29| Step: 23
Training loss: 1.9940130508669165
Validation loss: 2.094807061539455
Epoch: 29| Step: 24
Training loss: 2.0925080900594173
Validation loss: 2.055120015941547
Epoch: 29| Step: 25
Training loss: 3.0030009836556686
Validation loss: 2.0784749843642767
Epoch: 29| Step: 26
Training loss: 2.0735397808084644
Validation loss: 2.0856394544717465
Epoch: 29| Step: 27
Training loss: 2.666341125962693
Validation loss: 2.1095162895774533
Epoch: 29| Step: 28
Training loss: 2.464294565868079
Validation loss: 2.062867933325101
Epoch: 29| Step: 29
Training loss: 2.6124364744795074
Validation loss: 2.083914322329108
Epoch: 29| Step: 30
Training loss: 2.927747730227211
Validation loss: 2.08466214456553
Epoch: 29| Step: 31
Training loss: 2.0074925742956187
Validation loss: 2.0743045803957965
Epoch: 30| Step: 0
Training loss: 2.9088402146995493
Validation loss: 2.067856821181491
Epoch: 30| Step: 1
Training loss: 3.133121770114782
Validation loss: 2.125792295738854
Epoch: 30| Step: 2
Training loss: 2.539268320984813
Validation loss: 2.046805471134301
Epoch: 30| Step: 3
Training loss: 1.454089101272999
Validation loss: 2.098882417013451
Epoch: 30| Step: 4
Training loss: 2.3901224044355582
Validation loss: 2.1326357004661074
Epoch: 30| Step: 5
Training loss: 2.5714695885580974
Validation loss: 2.1180456635408578
Epoch: 30| Step: 6
Training loss: 2.303077885677677
Validation loss: 2.1343905940412964
Epoch: 30| Step: 7
Training loss: 2.51125235254112
Validation loss: 2.1121659567074653
Epoch: 30| Step: 8
Training loss: 2.7179969533941106
Validation loss: 2.144887768404527
Epoch: 30| Step: 9
Training loss: 2.789999924526419
Validation loss: 2.096958754836488
Epoch: 30| Step: 10
Training loss: 2.012554817163956
Validation loss: 2.1077013247763605
Epoch: 30| Step: 11
Training loss: 3.060929810619968
Validation loss: 2.1498238389086444
Epoch: 30| Step: 12
Training loss: 3.028675677260975
Validation loss: 2.0809719209650037
Epoch: 30| Step: 13
Training loss: 2.569225324847244
Validation loss: 2.114173806906383
Epoch: 30| Step: 14
Training loss: 2.794000693728689
Validation loss: 2.1104129122171793
Epoch: 30| Step: 15
Training loss: 3.2195608358451633
Validation loss: 2.0355945691312503
Epoch: 30| Step: 16
Training loss: 2.8518564569161775
Validation loss: 2.132382715843923
Epoch: 30| Step: 17
Training loss: 2.4930840198116244
Validation loss: 2.078662099892769
Epoch: 30| Step: 18
Training loss: 2.255965695208272
Validation loss: 2.025753415091865
Epoch: 30| Step: 19
Training loss: 3.0248569044836713
Validation loss: 2.0508858201973394
Epoch: 30| Step: 20
Training loss: 2.132228449965387
Validation loss: 2.110791644861163
Epoch: 30| Step: 21
Training loss: 2.1586307153839837
Validation loss: 2.1158472802653594
Epoch: 30| Step: 22
Training loss: 2.522110628561935
Validation loss: 2.1471225510709893
Epoch: 30| Step: 23
Training loss: 2.128464735252014
Validation loss: 2.1239134482440423
Epoch: 30| Step: 24
Training loss: 2.6100621946093554
Validation loss: 2.0963928015255706
Epoch: 30| Step: 25
Training loss: 2.4611577011168637
Validation loss: 2.1169747191567145
Epoch: 30| Step: 26
Training loss: 2.5468665748878094
Validation loss: 2.0655707109831214
Epoch: 30| Step: 27
Training loss: 2.8090957383992228
Validation loss: 2.1012663470044592
Epoch: 30| Step: 28
Training loss: 2.7418963068492266
Validation loss: 2.093395087169946
Epoch: 30| Step: 29
Training loss: 3.435190985865997
Validation loss: 2.0540850239324
Epoch: 30| Step: 30
Training loss: 3.066473426811938
Validation loss: 2.0787377112624856
Epoch: 30| Step: 31
Training loss: 2.791660840232425
Validation loss: 2.146387244968876
