Epoch: 1| Step: 0
Training loss: 4.927693843841553
Validation loss: 5.391005833943685
Epoch: 1| Step: 1
Training loss: 5.57193660736084
Validation loss: 5.365479628245036
Epoch: 1| Step: 2
Training loss: 5.4843854904174805
Validation loss: 5.247984727223714
Epoch: 1| Step: 3
Training loss: 4.650374412536621
Validation loss: 5.119871775309245
Epoch: 1| Step: 4
Training loss: 5.749905109405518
Validation loss: 5.068540096282959
Epoch: 1| Step: 5
Training loss: 5.909533977508545
Validation loss: 5.02358881632487
Epoch: 1| Step: 6
Training loss: 4.7178120613098145
Validation loss: 5.000034650166829
Epoch: 1| Step: 7
Training loss: 5.034979343414307
Validation loss: 5.0730438232421875
Epoch: 2| Step: 0
Training loss: 5.954709053039551
Validation loss: 4.724321365356445
Epoch: 2| Step: 1
Training loss: 4.515515327453613
Validation loss: 4.769430001576741
Epoch: 2| Step: 2
Training loss: 5.068511962890625
Validation loss: 4.72709854443868
Epoch: 2| Step: 3
Training loss: 4.914813995361328
Validation loss: 4.621289571126302
Epoch: 2| Step: 4
Training loss: 4.55703592300415
Validation loss: 4.668639183044434
Epoch: 2| Step: 5
Training loss: 4.533141136169434
Validation loss: 4.520866711934407
Epoch: 2| Step: 6
Training loss: 4.5362348556518555
Validation loss: 4.481474081675212
Epoch: 2| Step: 7
Training loss: 4.8451948165893555
Validation loss: 4.534897168477376
Epoch: 3| Step: 0
Training loss: 4.258205890655518
Validation loss: 4.479059219360352
Epoch: 3| Step: 1
Training loss: 5.039153099060059
Validation loss: 4.296848297119141
Epoch: 3| Step: 2
Training loss: 4.790696144104004
Validation loss: 4.28620982170105
Epoch: 3| Step: 3
Training loss: 4.345619201660156
Validation loss: 4.441834290822347
Epoch: 3| Step: 4
Training loss: 4.323718547821045
Validation loss: 4.348990599314372
Epoch: 3| Step: 5
Training loss: 4.787126064300537
Validation loss: 4.374917825063069
Epoch: 3| Step: 6
Training loss: 4.741649627685547
Validation loss: 4.290567954381307
Epoch: 3| Step: 7
Training loss: 4.123451232910156
Validation loss: 4.3319478034973145
Epoch: 4| Step: 0
Training loss: 4.342676639556885
Validation loss: 4.175745487213135
Epoch: 4| Step: 1
Training loss: 4.525487422943115
Validation loss: 4.214926481246948
Epoch: 4| Step: 2
Training loss: 4.420836925506592
Validation loss: 4.200764179229736
Epoch: 4| Step: 3
Training loss: 4.209419250488281
Validation loss: 4.276055335998535
Epoch: 4| Step: 4
Training loss: 4.453511714935303
Validation loss: 4.127264420191447
Epoch: 4| Step: 5
Training loss: 4.191028118133545
Validation loss: 4.178648948669434
Epoch: 4| Step: 6
Training loss: 3.783468723297119
Validation loss: 3.9717953205108643
Epoch: 4| Step: 7
Training loss: 4.750556468963623
Validation loss: 4.0850934982299805
Epoch: 5| Step: 0
Training loss: 4.464173316955566
Validation loss: 3.8866244157155356
Epoch: 5| Step: 1
Training loss: 4.630314826965332
Validation loss: 3.959664980570475
Epoch: 5| Step: 2
Training loss: 3.939188003540039
Validation loss: 3.9885667165120444
Epoch: 5| Step: 3
Training loss: 4.6960344314575195
Validation loss: 3.811203956604004
Epoch: 5| Step: 4
Training loss: 3.4846630096435547
Validation loss: 3.799891948699951
Epoch: 5| Step: 5
Training loss: 3.785490036010742
Validation loss: 3.7094465096791587
Epoch: 5| Step: 6
Training loss: 4.063775539398193
Validation loss: 3.78773824373881
Epoch: 5| Step: 7
Training loss: 3.923954486846924
Validation loss: 3.8145636717478433
Epoch: 6| Step: 0
Training loss: 4.164670944213867
Validation loss: 3.7787016232808432
Epoch: 6| Step: 1
Training loss: 3.7511978149414062
Validation loss: 3.6875181992848716
Epoch: 6| Step: 2
Training loss: 3.9499034881591797
Validation loss: 3.7649924755096436
Epoch: 6| Step: 3
Training loss: 4.072902679443359
Validation loss: 3.5763468742370605
Epoch: 6| Step: 4
Training loss: 3.636241912841797
Validation loss: 3.5969954331715903
Epoch: 6| Step: 5
Training loss: 4.060336112976074
Validation loss: 3.6945854028066
Epoch: 6| Step: 6
Training loss: 3.5144715309143066
Validation loss: 3.6527887980143228
Epoch: 6| Step: 7
Training loss: 4.320618152618408
Validation loss: 3.621509234110514
Epoch: 7| Step: 0
Training loss: 3.3968868255615234
Validation loss: 3.467113812764486
Epoch: 7| Step: 1
Training loss: 3.888303756713867
Validation loss: 3.4988080660502114
Epoch: 7| Step: 2
Training loss: 3.5311896800994873
Validation loss: 3.414482752482096
Epoch: 7| Step: 3
Training loss: 4.0679612159729
Validation loss: 3.493129094441732
Epoch: 7| Step: 4
Training loss: 3.593217134475708
Validation loss: 3.3397292296091714
Epoch: 7| Step: 5
Training loss: 3.867020845413208
Validation loss: 3.4317525227864585
Epoch: 7| Step: 6
Training loss: 3.8843696117401123
Validation loss: 3.2721035480499268
Epoch: 7| Step: 7
Training loss: 3.8165974617004395
Validation loss: 3.3968824545542398
Epoch: 8| Step: 0
Training loss: 4.2491888999938965
Validation loss: 3.3072516918182373
Epoch: 8| Step: 1
Training loss: 2.915086269378662
Validation loss: 3.353505849838257
Epoch: 8| Step: 2
Training loss: 3.3620822429656982
Validation loss: 3.26448917388916
Epoch: 8| Step: 3
Training loss: 3.7946536540985107
Validation loss: 3.1634296576182046
Epoch: 8| Step: 4
Training loss: 3.498818874359131
Validation loss: 3.301392396291097
Epoch: 8| Step: 5
Training loss: 3.4209983348846436
Validation loss: 3.3148022492726645
Epoch: 8| Step: 6
Training loss: 3.8187992572784424
Validation loss: 3.160065253575643
Epoch: 8| Step: 7
Training loss: 3.6434173583984375
Validation loss: 3.175989309946696
Epoch: 9| Step: 0
Training loss: 3.6112093925476074
Validation loss: 3.0223023096720376
Epoch: 9| Step: 1
Training loss: 3.9690608978271484
Validation loss: 3.204826911290487
Epoch: 9| Step: 2
Training loss: 3.5663154125213623
Validation loss: 3.1595442295074463
Epoch: 9| Step: 3
Training loss: 3.364976406097412
Validation loss: 3.0133074124654136
Epoch: 9| Step: 4
Training loss: 3.427443742752075
Validation loss: 3.075338284174601
Epoch: 9| Step: 5
Training loss: 2.8818793296813965
Validation loss: 2.9996086756388345
Epoch: 9| Step: 6
Training loss: 3.259368419647217
Validation loss: 3.0943685372670493
Epoch: 9| Step: 7
Training loss: 3.441429853439331
Validation loss: 2.9849323431650796
Epoch: 10| Step: 0
Training loss: 3.2836334705352783
Validation loss: 2.9640373388926187
Epoch: 10| Step: 1
Training loss: 3.3603553771972656
Validation loss: 2.8898353576660156
Epoch: 10| Step: 2
Training loss: 3.600963592529297
Validation loss: 2.961235682169596
Epoch: 10| Step: 3
Training loss: 3.5325927734375
Validation loss: 2.9646873474121094
Epoch: 10| Step: 4
Training loss: 3.1692757606506348
Validation loss: 2.933178981145223
Epoch: 10| Step: 5
Training loss: 3.5931332111358643
Validation loss: 2.8760886987050376
Epoch: 10| Step: 6
Training loss: 3.160198211669922
Validation loss: 2.8088533878326416
Epoch: 10| Step: 7
Training loss: 2.752967119216919
Validation loss: 2.769437074661255
Epoch: 11| Step: 0
Training loss: 3.132042407989502
Validation loss: 2.9189418156941733
Epoch: 11| Step: 1
Training loss: 3.5317795276641846
Validation loss: 2.7627302010854087
Epoch: 11| Step: 2
Training loss: 3.537102222442627
Validation loss: 2.813636223475138
Epoch: 11| Step: 3
Training loss: 2.646047830581665
Validation loss: 2.64772891998291
Epoch: 11| Step: 4
Training loss: 3.004901885986328
Validation loss: 2.6621131896972656
Epoch: 11| Step: 5
Training loss: 3.3988254070281982
Validation loss: 2.611679792404175
Epoch: 11| Step: 6
Training loss: 3.0563442707061768
Validation loss: 2.751855214436849
Epoch: 11| Step: 7
Training loss: 3.1550049781799316
Validation loss: 2.647377332051595
Epoch: 12| Step: 0
Training loss: 3.0496833324432373
Validation loss: 2.625279188156128
Epoch: 12| Step: 1
Training loss: 2.8266093730926514
Validation loss: 2.514451583226522
Epoch: 12| Step: 2
Training loss: 2.6816468238830566
Validation loss: 2.594167868296305
Epoch: 12| Step: 3
Training loss: 3.244901180267334
Validation loss: 2.586092392603556
Epoch: 12| Step: 4
Training loss: 3.3932251930236816
Validation loss: 2.6940202713012695
Epoch: 12| Step: 5
Training loss: 3.7053871154785156
Validation loss: 2.7056219577789307
Epoch: 12| Step: 6
Training loss: 2.8077118396759033
Validation loss: 2.615780750910441
Epoch: 12| Step: 7
Training loss: 2.897033214569092
Validation loss: 2.469759225845337
Epoch: 13| Step: 0
Training loss: 3.1614317893981934
Validation loss: 2.551431735356649
Epoch: 13| Step: 1
Training loss: 2.855379104614258
Validation loss: 2.5229299863179526
Epoch: 13| Step: 2
Training loss: 2.7348976135253906
Validation loss: 2.4570719401041665
Epoch: 13| Step: 3
Training loss: 2.889453411102295
Validation loss: 2.4002869923909507
Epoch: 13| Step: 4
Training loss: 2.7595341205596924
Validation loss: 2.376491149266561
Epoch: 13| Step: 5
Training loss: 3.257352828979492
Validation loss: 2.5028233528137207
Epoch: 13| Step: 6
Training loss: 3.2896485328674316
Validation loss: 2.4054818948109946
Epoch: 13| Step: 7
Training loss: 2.942732095718384
Validation loss: 2.412421941757202
Epoch: 14| Step: 0
Training loss: 3.0089828968048096
Validation loss: 2.2739941279093423
Epoch: 14| Step: 1
Training loss: 2.9701361656188965
Validation loss: 2.382398764292399
Epoch: 14| Step: 2
Training loss: 2.887924909591675
Validation loss: 2.284522374471029
Epoch: 14| Step: 3
Training loss: 2.716081142425537
Validation loss: 2.354836622873942
Epoch: 14| Step: 4
Training loss: 3.1369800567626953
Validation loss: 2.466036876042684
Epoch: 14| Step: 5
Training loss: 3.101670742034912
Validation loss: 2.406794786453247
Epoch: 14| Step: 6
Training loss: 2.7374510765075684
Validation loss: 2.292954365412394
Epoch: 14| Step: 7
Training loss: 2.6366539001464844
Validation loss: 2.352876822153727
Epoch: 15| Step: 0
Training loss: 2.858351230621338
Validation loss: 2.3533511956532798
Epoch: 15| Step: 1
Training loss: 3.032787799835205
Validation loss: 2.2529516220092773
Epoch: 15| Step: 2
Training loss: 3.5780091285705566
Validation loss: 2.255993048350016
Epoch: 15| Step: 3
Training loss: 2.398488998413086
Validation loss: 2.2366905212402344
Epoch: 15| Step: 4
Training loss: 2.645070791244507
Validation loss: 2.335646708806356
Epoch: 15| Step: 5
Training loss: 2.1794209480285645
Validation loss: 2.3019826412200928
Epoch: 15| Step: 6
Training loss: 2.9805378913879395
Validation loss: 2.270860433578491
Epoch: 15| Step: 7
Training loss: 2.8661038875579834
Validation loss: 2.273236115773519
Epoch: 16| Step: 0
Training loss: 2.4365346431732178
Validation loss: 2.199070413907369
Epoch: 16| Step: 1
Training loss: 2.7920384407043457
Validation loss: 2.2360618909200034
Epoch: 16| Step: 2
Training loss: 2.300710678100586
Validation loss: 2.179790178934733
Epoch: 16| Step: 3
Training loss: 3.0399105548858643
Validation loss: 2.2282737096150718
Epoch: 16| Step: 4
Training loss: 3.0262115001678467
Validation loss: 2.268531084060669
Epoch: 16| Step: 5
Training loss: 2.6341590881347656
Validation loss: 2.2126028140385947
Epoch: 16| Step: 6
Training loss: 2.7728657722473145
Validation loss: 2.09714945157369
Epoch: 16| Step: 7
Training loss: 2.9078311920166016
Validation loss: 2.1244646310806274
Epoch: 17| Step: 0
Training loss: 3.2368907928466797
Validation loss: 2.1527241865793862
Epoch: 17| Step: 1
Training loss: 2.699083089828491
Validation loss: 2.1697651147842407
Epoch: 17| Step: 2
Training loss: 2.7405736446380615
Validation loss: 2.0664082368214927
Epoch: 17| Step: 3
Training loss: 2.176978588104248
Validation loss: 2.203875780105591
Epoch: 17| Step: 4
Training loss: 2.3589186668395996
Validation loss: 2.1329815785090127
Epoch: 17| Step: 5
Training loss: 2.848801851272583
Validation loss: 2.147122542063395
Epoch: 17| Step: 6
Training loss: 2.6914358139038086
Validation loss: 2.082474152247111
Epoch: 17| Step: 7
Training loss: 2.5709378719329834
Validation loss: 2.091497619946798
Epoch: 18| Step: 0
Training loss: 2.824816942214966
Validation loss: 2.0953213373819985
Epoch: 18| Step: 1
Training loss: 2.5506389141082764
Validation loss: 2.108316977818807
Epoch: 18| Step: 2
Training loss: 2.7261197566986084
Validation loss: 2.0927915970484414
Epoch: 18| Step: 3
Training loss: 2.5157418251037598
Validation loss: 1.992443839708964
Epoch: 18| Step: 4
Training loss: 2.529181480407715
Validation loss: 2.1338533560434976
Epoch: 18| Step: 5
Training loss: 2.423334836959839
Validation loss: 2.0690759817759194
Epoch: 18| Step: 6
Training loss: 2.3822805881500244
Validation loss: 2.0628894170125327
Epoch: 18| Step: 7
Training loss: 2.7778141498565674
Validation loss: 2.09770933787028
Epoch: 19| Step: 0
Training loss: 2.6178505420684814
Validation loss: 2.0887173811594644
Epoch: 19| Step: 1
Training loss: 2.7808642387390137
Validation loss: 2.1042842070261636
Epoch: 19| Step: 2
Training loss: 2.420929431915283
Validation loss: 2.0270724296569824
Epoch: 19| Step: 3
Training loss: 2.0036792755126953
Validation loss: 1.9532862106959026
Epoch: 19| Step: 4
Training loss: 2.3466503620147705
Validation loss: 1.9771021604537964
Epoch: 19| Step: 5
Training loss: 2.6994051933288574
Validation loss: 1.891385595003764
Epoch: 19| Step: 6
Training loss: 2.715912342071533
Validation loss: 1.9422637224197388
Epoch: 19| Step: 7
Training loss: 2.5755555629730225
Validation loss: 1.9811300834019978
Epoch: 20| Step: 0
Training loss: 2.2955517768859863
Validation loss: 1.860367774963379
Epoch: 20| Step: 1
Training loss: 2.30171537399292
Validation loss: 1.945097287495931
Epoch: 20| Step: 2
Training loss: 2.760535717010498
Validation loss: 1.9664359490076702
Epoch: 20| Step: 3
Training loss: 2.073340892791748
Validation loss: 1.9846445719401042
Epoch: 20| Step: 4
Training loss: 2.719895839691162
Validation loss: 1.9779902299245198
Epoch: 20| Step: 5
Training loss: 2.6189000606536865
Validation loss: 2.008704662322998
Epoch: 20| Step: 6
Training loss: 2.568906784057617
Validation loss: 1.9104324579238892
Epoch: 20| Step: 7
Training loss: 2.3298678398132324
Validation loss: 1.8872780402501423
Epoch: 21| Step: 0
Training loss: 2.0316073894500732
Validation loss: 1.8779526948928833
Epoch: 21| Step: 1
Training loss: 2.3421549797058105
Validation loss: 1.9024712642033894
Epoch: 21| Step: 2
Training loss: 2.5074410438537598
Validation loss: 1.9229134321212769
Epoch: 21| Step: 3
Training loss: 2.5568625926971436
Validation loss: 1.855293909708659
Epoch: 21| Step: 4
Training loss: 2.4331469535827637
Validation loss: 1.9103748003641765
Epoch: 21| Step: 5
Training loss: 2.7822816371917725
Validation loss: 1.8354257345199585
Epoch: 21| Step: 6
Training loss: 2.3866310119628906
Validation loss: 1.9254030386606853
Epoch: 21| Step: 7
Training loss: 2.096998929977417
Validation loss: 1.7506628433863323
Epoch: 22| Step: 0
Training loss: 2.100843906402588
Validation loss: 1.8465646107991536
Epoch: 22| Step: 1
Training loss: 2.571410655975342
Validation loss: 1.8021647135416667
Epoch: 22| Step: 2
Training loss: 2.214033365249634
Validation loss: 1.7878777186075847
Epoch: 22| Step: 3
Training loss: 2.5415234565734863
Validation loss: 1.8344794511795044
Epoch: 22| Step: 4
Training loss: 2.435539722442627
Validation loss: 1.7944121360778809
Epoch: 22| Step: 5
Training loss: 2.5052897930145264
Validation loss: 1.768623153368632
Epoch: 22| Step: 6
Training loss: 2.3625729084014893
Validation loss: 1.8081406354904175
Epoch: 22| Step: 7
Training loss: 2.016326427459717
Validation loss: 1.734268585840861
Epoch: 23| Step: 0
Training loss: 2.255462646484375
Validation loss: 1.838795781135559
Epoch: 23| Step: 1
Training loss: 2.1406264305114746
Validation loss: 1.6987104018529255
Epoch: 23| Step: 2
Training loss: 2.561680555343628
Validation loss: 1.855076750119527
Epoch: 23| Step: 3
Training loss: 2.1090054512023926
Validation loss: 1.7623789707819622
Epoch: 23| Step: 4
Training loss: 2.101268768310547
Validation loss: 1.6893177032470703
Epoch: 23| Step: 5
Training loss: 2.5353963375091553
Validation loss: 1.7996769348780315
Epoch: 23| Step: 6
Training loss: 2.2727396488189697
Validation loss: 1.7473297119140625
Epoch: 23| Step: 7
Training loss: 2.5097079277038574
Validation loss: 1.8065080245335896
Epoch: 24| Step: 0
Training loss: 2.396817207336426
Validation loss: 1.7446935176849365
Epoch: 24| Step: 1
Training loss: 2.476438045501709
Validation loss: 1.7959881623586018
Epoch: 24| Step: 2
Training loss: 2.181162118911743
Validation loss: 1.729102373123169
Epoch: 24| Step: 3
Training loss: 2.5108821392059326
Validation loss: 1.7748456398646038
Epoch: 24| Step: 4
Training loss: 2.070500373840332
Validation loss: 1.7167227268218994
Epoch: 24| Step: 5
Training loss: 2.3358004093170166
Validation loss: 1.7576114336649578
Epoch: 24| Step: 6
Training loss: 1.7471427917480469
Validation loss: 1.7324990034103394
Epoch: 24| Step: 7
Training loss: 2.5503344535827637
Validation loss: 1.6624236901601155
Epoch: 25| Step: 0
Training loss: 2.6130306720733643
Validation loss: 1.7794184287389119
Epoch: 25| Step: 1
Training loss: 2.4649224281311035
Validation loss: 1.6194121837615967
Epoch: 25| Step: 2
Training loss: 2.387350559234619
Validation loss: 1.7014975547790527
Epoch: 25| Step: 3
Training loss: 2.205557107925415
Validation loss: 1.681010325749715
Epoch: 25| Step: 4
Training loss: 2.0038790702819824
Validation loss: 1.6785392761230469
Epoch: 25| Step: 5
Training loss: 1.9788738489151
Validation loss: 1.7350825468699138
Epoch: 25| Step: 6
Training loss: 2.0558528900146484
Validation loss: 1.715465784072876
Epoch: 25| Step: 7
Training loss: 2.4045844078063965
Validation loss: 1.6578831672668457
Epoch: 26| Step: 0
Training loss: 2.0887670516967773
Validation loss: 1.6224657694498699
Epoch: 26| Step: 1
Training loss: 2.046085834503174
Validation loss: 1.6412710348765056
Epoch: 26| Step: 2
Training loss: 2.0830562114715576
Validation loss: 1.6950625975926716
Epoch: 26| Step: 3
Training loss: 2.3524937629699707
Validation loss: 1.672495722770691
Epoch: 26| Step: 4
Training loss: 2.329005479812622
Validation loss: 1.743978500366211
Epoch: 26| Step: 5
Training loss: 2.3892691135406494
Validation loss: 1.6791878541310628
Epoch: 26| Step: 6
Training loss: 2.4897141456604004
Validation loss: 1.6318450768788655
Epoch: 26| Step: 7
Training loss: 2.252500057220459
Validation loss: 1.749862511952718
Epoch: 27| Step: 0
Training loss: 2.2839925289154053
Validation loss: 1.698306679725647
Epoch: 27| Step: 1
Training loss: 2.259807586669922
Validation loss: 1.6298716068267822
Epoch: 27| Step: 2
Training loss: 2.3400485515594482
Validation loss: 1.6891908248265584
Epoch: 27| Step: 3
Training loss: 2.081191062927246
Validation loss: 1.6958333253860474
Epoch: 27| Step: 4
Training loss: 2.021737575531006
Validation loss: 1.7572174469629924
Epoch: 27| Step: 5
Training loss: 2.3338472843170166
Validation loss: 1.7074350118637085
Epoch: 27| Step: 6
Training loss: 2.1846179962158203
Validation loss: 1.7188136577606201
Epoch: 27| Step: 7
Training loss: 2.4900002479553223
Validation loss: 1.7883333365122478
Epoch: 28| Step: 0
Training loss: 2.254999876022339
Validation loss: 1.6513241529464722
Epoch: 28| Step: 1
Training loss: 2.3766589164733887
Validation loss: 1.6524065335591633
Epoch: 28| Step: 2
Training loss: 2.170658588409424
Validation loss: 1.6599634091059368
Epoch: 28| Step: 3
Training loss: 2.127375841140747
Validation loss: 1.693540334701538
Epoch: 28| Step: 4
Training loss: 2.4964537620544434
Validation loss: 1.66094970703125
Epoch: 28| Step: 5
Training loss: 1.9805915355682373
Validation loss: 1.6733333667119343
Epoch: 28| Step: 6
Training loss: 2.235905408859253
Validation loss: 1.6947342157363892
Epoch: 28| Step: 7
Training loss: 2.3189902305603027
Validation loss: 1.7049999237060547
Epoch: 29| Step: 0
Training loss: 2.1615638732910156
Validation loss: 1.6974999904632568
Epoch: 29| Step: 1
Training loss: 2.3525002002716064
Validation loss: 1.6450000206629436
Epoch: 29| Step: 2
Training loss: 1.8953964710235596
Validation loss: 1.5927337010701497
Epoch: 29| Step: 3
Training loss: 2.7984845638275146
Validation loss: 1.6676640907923381
Epoch: 29| Step: 4
Training loss: 2.242499828338623
Validation loss: 1.65666663646698
Epoch: 29| Step: 5
Training loss: 2.102827548980713
Validation loss: 1.7066120306650798
Epoch: 29| Step: 6
Training loss: 2.180445432662964
Validation loss: 1.6321120659510295
Epoch: 29| Step: 7
Training loss: 2.220630168914795
Validation loss: 1.6553219159444172
Epoch: 30| Step: 0
Training loss: 2.218686580657959
Validation loss: 1.6950422525405884
Epoch: 30| Step: 1
Training loss: 2.0898594856262207
Validation loss: 1.6720132033030193
Epoch: 30| Step: 2
Training loss: 2.4225001335144043
Validation loss: 1.7382341623306274
Epoch: 30| Step: 3
Training loss: 2.004999876022339
Validation loss: 1.7134064435958862
Epoch: 30| Step: 4
Training loss: 2.3334386348724365
Validation loss: 1.672166109085083
Epoch: 30| Step: 5
Training loss: 2.3240578174591064
Validation loss: 1.5532484849294026
Epoch: 30| Step: 6
Training loss: 2.4846456050872803
Validation loss: 1.7023854653040569
Epoch: 30| Step: 7
Training loss: 2.064826250076294
Validation loss: 1.6118805011113484
