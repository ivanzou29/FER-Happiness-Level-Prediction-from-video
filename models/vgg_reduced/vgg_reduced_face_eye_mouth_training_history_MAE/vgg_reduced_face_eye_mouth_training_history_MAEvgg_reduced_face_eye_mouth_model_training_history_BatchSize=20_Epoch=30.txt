Epoch: 1| Step: 0
Training loss: 4.34888219833374
Validation loss: 4.96085246404012
Epoch: 1| Step: 1
Training loss: 4.559521675109863
Validation loss: 5.098173300425212
Epoch: 1| Step: 2
Training loss: 5.818172931671143
Validation loss: 5.02713672320048
Epoch: 1| Step: 3
Training loss: 5.66472864151001
Validation loss: 5.021827220916748
Epoch: 1| Step: 4
Training loss: 6.066924095153809
Validation loss: 4.9709311326344805
Epoch: 1| Step: 5
Training loss: 5.235323429107666
Validation loss: 5.075637102127075
Epoch: 1| Step: 6
Training loss: 5.499493598937988
Validation loss: 4.958640098571777
Epoch: 1| Step: 7
Training loss: 4.91455602645874
Validation loss: 4.854579925537109
Epoch: 1| Step: 8
Training loss: 5.3843889236450195
Validation loss: 4.587186892827352
Epoch: 1| Step: 9
Training loss: 4.246181488037109
Validation loss: 4.6360243161519366
Epoch: 1| Step: 10
Training loss: 5.279374122619629
Validation loss: 4.4985523621241255
Epoch: 1| Step: 11
Training loss: 3.641328811645508
Validation loss: 4.41005555788676
Epoch: 1| Step: 12
Training loss: 4.258866786956787
Validation loss: 4.502496083577474
Epoch: 1| Step: 13
Training loss: 4.684447288513184
Validation loss: 4.374061028162639
Epoch: 1| Step: 14
Training loss: 3.8716654777526855
Validation loss: 4.218725204467773
Epoch: 1| Step: 15
Training loss: 4.472268104553223
Validation loss: 4.228691736857097
Epoch: 2| Step: 0
Training loss: 4.17795991897583
Validation loss: 4.248825589815776
Epoch: 2| Step: 1
Training loss: 4.6985578536987305
Validation loss: 4.071121652921041
Epoch: 2| Step: 2
Training loss: 3.302136182785034
Validation loss: 4.137488563855489
Epoch: 2| Step: 3
Training loss: 4.189974784851074
Validation loss: 4.038348118464152
Epoch: 2| Step: 4
Training loss: 4.470393657684326
Validation loss: 4.16132406393687
Epoch: 2| Step: 5
Training loss: 4.225080490112305
Validation loss: 3.940564513206482
Epoch: 2| Step: 6
Training loss: 5.256163597106934
Validation loss: 3.971566637357076
Epoch: 2| Step: 7
Training loss: 3.761587619781494
Validation loss: 3.8916375239690146
Epoch: 2| Step: 8
Training loss: 3.8316402435302734
Validation loss: 3.9002229372660318
Epoch: 2| Step: 9
Training loss: 3.3815360069274902
Validation loss: 3.741762717564901
Epoch: 2| Step: 10
Training loss: 4.774742126464844
Validation loss: 3.8376046419143677
Epoch: 2| Step: 11
Training loss: 3.7331721782684326
Validation loss: 3.697598139444987
Epoch: 2| Step: 12
Training loss: 3.8853344917297363
Validation loss: 3.7071377833684287
Epoch: 2| Step: 13
Training loss: 3.703709840774536
Validation loss: 3.726586937904358
Epoch: 2| Step: 14
Training loss: 4.084294319152832
Validation loss: 3.614023526509603
Epoch: 2| Step: 15
Training loss: 4.458676815032959
Validation loss: 3.5555052757263184
Epoch: 3| Step: 0
Training loss: 4.445835113525391
Validation loss: 3.6135875384012857
Epoch: 3| Step: 1
Training loss: 3.103400707244873
Validation loss: 3.6405067443847656
Epoch: 3| Step: 2
Training loss: 2.698469877243042
Validation loss: 3.4340661764144897
Epoch: 3| Step: 3
Training loss: 4.292080879211426
Validation loss: 3.5189748207728067
Epoch: 3| Step: 4
Training loss: 3.863443374633789
Validation loss: 3.3644243478775024
Epoch: 3| Step: 5
Training loss: 4.176260948181152
Validation loss: 3.321898420651754
Epoch: 3| Step: 6
Training loss: 3.6172053813934326
Validation loss: 3.2895799477895102
Epoch: 3| Step: 7
Training loss: 3.9265408515930176
Validation loss: 3.2588966290156045
Epoch: 3| Step: 8
Training loss: 2.500267505645752
Validation loss: 3.1827588081359863
Epoch: 3| Step: 9
Training loss: 3.6036887168884277
Validation loss: 3.248855551083883
Epoch: 3| Step: 10
Training loss: 4.449810981750488
Validation loss: 3.023898482322693
Epoch: 3| Step: 11
Training loss: 2.778287410736084
Validation loss: 3.1316908995310464
Epoch: 3| Step: 12
Training loss: 3.2336807250976562
Validation loss: 3.1829036474227905
Epoch: 3| Step: 13
Training loss: 3.8215842247009277
Validation loss: 3.0522318283716836
Epoch: 3| Step: 14
Training loss: 3.523770570755005
Validation loss: 3.1078351736068726
Epoch: 3| Step: 15
Training loss: 3.421771287918091
Validation loss: 3.0204749504725137
Epoch: 4| Step: 0
Training loss: 2.7596817016601562
Validation loss: 3.0807932217915854
Epoch: 4| Step: 1
Training loss: 3.6647098064422607
Validation loss: 3.123297095298767
Epoch: 4| Step: 2
Training loss: 3.5118515491485596
Validation loss: 2.932288924853007
Epoch: 4| Step: 3
Training loss: 2.7327017784118652
Validation loss: 2.8728175163269043
Epoch: 4| Step: 4
Training loss: 4.051043510437012
Validation loss: 2.7908140818277993
Epoch: 4| Step: 5
Training loss: 3.037748336791992
Validation loss: 2.6948282718658447
Epoch: 4| Step: 6
Training loss: 3.8323051929473877
Validation loss: 2.7473843495051065
Epoch: 4| Step: 7
Training loss: 3.511875867843628
Validation loss: 2.661973754564921
Epoch: 4| Step: 8
Training loss: 3.230884552001953
Validation loss: 2.740492026011149
Epoch: 4| Step: 9
Training loss: 2.365334987640381
Validation loss: 2.766752282778422
Epoch: 4| Step: 10
Training loss: 2.328350782394409
Validation loss: 2.694142540295919
Epoch: 4| Step: 11
Training loss: 3.482348918914795
Validation loss: 2.724193572998047
Epoch: 4| Step: 12
Training loss: 3.659656524658203
Validation loss: 2.666864554087321
Epoch: 4| Step: 13
Training loss: 3.097566604614258
Validation loss: 2.594034194946289
Epoch: 4| Step: 14
Training loss: 2.2958524227142334
Validation loss: 2.599477847417196
Epoch: 4| Step: 15
Training loss: 3.1964542865753174
Validation loss: 2.499969005584717
Epoch: 5| Step: 0
Training loss: 2.709550380706787
Validation loss: 2.614184578259786
Epoch: 5| Step: 1
Training loss: 3.5353798866271973
Validation loss: 2.5325541297594705
Epoch: 5| Step: 2
Training loss: 2.837374210357666
Validation loss: 2.4877441922823587
Epoch: 5| Step: 3
Training loss: 2.967137098312378
Validation loss: 2.482451399167379
Epoch: 5| Step: 4
Training loss: 2.862571954727173
Validation loss: 2.458434224128723
Epoch: 5| Step: 5
Training loss: 2.370891571044922
Validation loss: 2.4800952672958374
Epoch: 5| Step: 6
Training loss: 3.2391345500946045
Validation loss: 2.3949323097864785
Epoch: 5| Step: 7
Training loss: 2.414628028869629
Validation loss: 2.401206096013387
Epoch: 5| Step: 8
Training loss: 2.7052512168884277
Validation loss: 2.358636418978373
Epoch: 5| Step: 9
Training loss: 3.167600154876709
Validation loss: 2.2996533314387
Epoch: 5| Step: 10
Training loss: 2.6664676666259766
Validation loss: 2.365480879942576
Epoch: 5| Step: 11
Training loss: 2.1304984092712402
Validation loss: 2.3313076893488565
Epoch: 5| Step: 12
Training loss: 3.2225940227508545
Validation loss: 2.2687653501828513
Epoch: 5| Step: 13
Training loss: 3.5213592052459717
Validation loss: 2.370711843172709
Epoch: 5| Step: 14
Training loss: 2.7431740760803223
Validation loss: 2.2953904072443643
Epoch: 5| Step: 15
Training loss: 3.1401305198669434
Validation loss: 2.232059876124064
Epoch: 6| Step: 0
Training loss: 3.051854372024536
Validation loss: 2.204351484775543
Epoch: 6| Step: 1
Training loss: 2.305804491043091
Validation loss: 2.1869176626205444
Epoch: 6| Step: 2
Training loss: 2.5369114875793457
Validation loss: 2.2455736001332602
Epoch: 6| Step: 3
Training loss: 2.8786911964416504
Validation loss: 2.2027634978294373
Epoch: 6| Step: 4
Training loss: 2.778784990310669
Validation loss: 2.2766301234563193
Epoch: 6| Step: 5
Training loss: 2.2646312713623047
Validation loss: 2.1060502330462136
Epoch: 6| Step: 6
Training loss: 2.315114974975586
Validation loss: 2.1476386189460754
Epoch: 6| Step: 7
Training loss: 2.852526903152466
Validation loss: 2.162473817666372
Epoch: 6| Step: 8
Training loss: 2.8923113346099854
Validation loss: 2.122415781021118
Epoch: 6| Step: 9
Training loss: 2.739818811416626
Validation loss: 2.1425676345825195
Epoch: 6| Step: 10
Training loss: 2.7515203952789307
Validation loss: 2.046072502930959
Epoch: 6| Step: 11
Training loss: 2.2805042266845703
Validation loss: 2.090778867403666
Epoch: 6| Step: 12
Training loss: 3.091461658477783
Validation loss: 2.1459609468777976
Epoch: 6| Step: 13
Training loss: 2.9221673011779785
Validation loss: 2.0476306478182473
Epoch: 6| Step: 14
Training loss: 2.430237293243408
Validation loss: 2.0140322049458823
Epoch: 6| Step: 15
Training loss: 2.6898555755615234
Validation loss: 2.078259209791819
Epoch: 7| Step: 0
Training loss: 2.5708439350128174
Validation loss: 2.086142361164093
Epoch: 7| Step: 1
Training loss: 2.2598185539245605
Validation loss: 2.042391022046407
Epoch: 7| Step: 2
Training loss: 2.6545557975769043
Validation loss: 1.9975464940071106
Epoch: 7| Step: 3
Training loss: 2.107466220855713
Validation loss: 1.9905821283658345
Epoch: 7| Step: 4
Training loss: 2.6144580841064453
Validation loss: 2.026720424493154
Epoch: 7| Step: 5
Training loss: 2.60931658744812
Validation loss: 1.9810349146525066
Epoch: 7| Step: 6
Training loss: 2.2258903980255127
Validation loss: 2.0263856053352356
Epoch: 7| Step: 7
Training loss: 2.9027247428894043
Validation loss: 1.9806556502978008
Epoch: 7| Step: 8
Training loss: 2.6138603687286377
Validation loss: 1.957110325495402
Epoch: 7| Step: 9
Training loss: 2.9082393646240234
Validation loss: 1.8704947431882222
Epoch: 7| Step: 10
Training loss: 2.5437204837799072
Validation loss: 1.9559507171312969
Epoch: 7| Step: 11
Training loss: 2.43119478225708
Validation loss: 1.9834174513816833
Epoch: 7| Step: 12
Training loss: 2.1351265907287598
Validation loss: 1.9262552460034688
Epoch: 7| Step: 13
Training loss: 2.511265516281128
Validation loss: 1.8207407593727112
Epoch: 7| Step: 14
Training loss: 2.3160159587860107
Validation loss: 1.9214459458986919
Epoch: 7| Step: 15
Training loss: 2.400709390640259
Validation loss: 1.9261074662208557
Epoch: 8| Step: 0
Training loss: 2.4166247844696045
Validation loss: 1.8863869309425354
Epoch: 8| Step: 1
Training loss: 2.161919355392456
Validation loss: 1.916711429754893
Epoch: 8| Step: 2
Training loss: 2.154545307159424
Validation loss: 1.847882370154063
Epoch: 8| Step: 3
Training loss: 2.5604825019836426
Validation loss: 1.967612584431966
Epoch: 8| Step: 4
Training loss: 2.674431324005127
Validation loss: 1.8231940666834514
Epoch: 8| Step: 5
Training loss: 2.643770217895508
Validation loss: 1.7693003217379253
Epoch: 8| Step: 6
Training loss: 2.118450880050659
Validation loss: 1.8660230835278828
Epoch: 8| Step: 7
Training loss: 2.1425817012786865
Validation loss: 1.8199394941329956
Epoch: 8| Step: 8
Training loss: 2.270967960357666
Validation loss: 1.8606374462445576
Epoch: 8| Step: 9
Training loss: 2.4238734245300293
Validation loss: 1.824105183283488
Epoch: 8| Step: 10
Training loss: 2.1313223838806152
Validation loss: 1.7624572118123372
Epoch: 8| Step: 11
Training loss: 2.4552407264709473
Validation loss: 1.8354607621828716
Epoch: 8| Step: 12
Training loss: 2.4189436435699463
Validation loss: 1.7541692455609639
Epoch: 8| Step: 13
Training loss: 2.4206743240356445
Validation loss: 1.7898164987564087
Epoch: 8| Step: 14
Training loss: 2.6751036643981934
Validation loss: 1.7609782616297405
Epoch: 8| Step: 15
Training loss: 2.034687042236328
Validation loss: 1.7523876031239827
Epoch: 9| Step: 0
Training loss: 1.9677488803863525
Validation loss: 1.8691187103589375
Epoch: 9| Step: 1
Training loss: 2.182068109512329
Validation loss: 1.7555301189422607
Epoch: 9| Step: 2
Training loss: 2.0091476440429688
Validation loss: 1.7805970708529155
Epoch: 9| Step: 3
Training loss: 2.0423476696014404
Validation loss: 1.6801931460698445
Epoch: 9| Step: 4
Training loss: 2.467491626739502
Validation loss: 1.7986711859703064
Epoch: 9| Step: 5
Training loss: 2.0016562938690186
Validation loss: 1.7353230714797974
Epoch: 9| Step: 6
Training loss: 2.2787671089172363
Validation loss: 1.7700439890225728
Epoch: 9| Step: 7
Training loss: 2.489457607269287
Validation loss: 1.6913758317629497
Epoch: 9| Step: 8
Training loss: 2.6510612964630127
Validation loss: 1.756758729616801
Epoch: 9| Step: 9
Training loss: 2.7306361198425293
Validation loss: 1.7325205206871033
Epoch: 9| Step: 10
Training loss: 2.5797500610351562
Validation loss: 1.7612462441126506
Epoch: 9| Step: 11
Training loss: 2.371567726135254
Validation loss: 1.7695031762123108
Epoch: 9| Step: 12
Training loss: 1.944440245628357
Validation loss: 1.6502673824628193
Epoch: 9| Step: 13
Training loss: 2.3065497875213623
Validation loss: 1.7079575061798096
Epoch: 9| Step: 14
Training loss: 2.3177058696746826
Validation loss: 1.7335024277369182
Epoch: 9| Step: 15
Training loss: 2.128727436065674
Validation loss: 1.6984322865804036
Epoch: 10| Step: 0
Training loss: 2.3708720207214355
Validation loss: 1.6837649544080098
Epoch: 10| Step: 1
Training loss: 1.4756016731262207
Validation loss: 1.7455631891886394
Epoch: 10| Step: 2
Training loss: 1.9872922897338867
Validation loss: 1.7199067672093709
Epoch: 10| Step: 3
Training loss: 1.8014882802963257
Validation loss: 1.828317662080129
Epoch: 10| Step: 4
Training loss: 1.9077972173690796
Validation loss: 1.701787809530894
Epoch: 10| Step: 5
Training loss: 2.712851047515869
Validation loss: 1.7240289251009624
Epoch: 10| Step: 6
Training loss: 2.51233172416687
Validation loss: 1.827429215113322
Epoch: 10| Step: 7
Training loss: 2.1839897632598877
Validation loss: 1.7309839526812236
Epoch: 10| Step: 8
Training loss: 2.727116823196411
Validation loss: 1.8305359482765198
Epoch: 10| Step: 9
Training loss: 2.269008159637451
Validation loss: 1.7366740703582764
Epoch: 10| Step: 10
Training loss: 2.6377005577087402
Validation loss: 1.6771769324938457
Epoch: 10| Step: 11
Training loss: 2.5886940956115723
Validation loss: 1.7430070042610168
Epoch: 10| Step: 12
Training loss: 2.2948474884033203
Validation loss: 1.746622920036316
Epoch: 10| Step: 13
Training loss: 2.423130750656128
Validation loss: 1.8090767065684001
Epoch: 10| Step: 14
Training loss: 2.2006242275238037
Validation loss: 1.6853217283884685
Epoch: 10| Step: 15
Training loss: 2.2714591026306152
Validation loss: 1.7412692308425903
Epoch: 11| Step: 0
Training loss: 1.9435628652572632
Validation loss: 1.7072547475496929
Epoch: 11| Step: 1
Training loss: 2.4693450927734375
Validation loss: 1.7734646201133728
Epoch: 11| Step: 2
Training loss: 1.6739765405654907
Validation loss: 1.7610798478126526
Epoch: 11| Step: 3
Training loss: 2.68765926361084
Validation loss: 1.7434959411621094
Epoch: 11| Step: 4
Training loss: 2.3382182121276855
Validation loss: 1.6330137054125469
Epoch: 11| Step: 5
Training loss: 1.9300349950790405
Validation loss: 1.7367960611979167
Epoch: 11| Step: 6
Training loss: 2.2857394218444824
Validation loss: 1.6932873725891113
Epoch: 11| Step: 7
Training loss: 2.3057074546813965
Validation loss: 1.7336440881093342
Epoch: 11| Step: 8
Training loss: 2.5643627643585205
Validation loss: 1.7210106253623962
Epoch: 11| Step: 9
Training loss: 2.8737568855285645
Validation loss: 1.7355956832567851
Epoch: 11| Step: 10
Training loss: 2.657174587249756
Validation loss: 1.749208668867747
Epoch: 11| Step: 11
Training loss: 2.227017402648926
Validation loss: 1.7908948858579
Epoch: 11| Step: 12
Training loss: 2.067952871322632
Validation loss: 1.6793016990025837
Epoch: 11| Step: 13
Training loss: 1.6348642110824585
Validation loss: 1.7487637599309285
Epoch: 11| Step: 14
Training loss: 2.272552967071533
Validation loss: 1.7165490587552388
Epoch: 11| Step: 15
Training loss: 2.3145363330841064
Validation loss: 1.7026353279749553
Epoch: 12| Step: 0
Training loss: 2.273372173309326
Validation loss: 1.656757076581319
Epoch: 12| Step: 1
Training loss: 2.1894240379333496
Validation loss: 1.760713001092275
Epoch: 12| Step: 2
Training loss: 2.568068504333496
Validation loss: 1.685109297434489
Epoch: 12| Step: 3
Training loss: 1.5438809394836426
Validation loss: 1.6983547806739807
Epoch: 12| Step: 4
Training loss: 1.9806045293807983
Validation loss: 1.6927542289098103
Epoch: 12| Step: 5
Training loss: 2.260139226913452
Validation loss: 1.6800252397855122
Epoch: 12| Step: 6
Training loss: 2.639383554458618
Validation loss: 1.7617148756980896
Epoch: 12| Step: 7
Training loss: 2.1025991439819336
Validation loss: 1.7258746027946472
Epoch: 12| Step: 8
Training loss: 1.980813980102539
Validation loss: 1.7090269923210144
Epoch: 12| Step: 9
Training loss: 2.3698861598968506
Validation loss: 1.7157039841016133
Epoch: 12| Step: 10
Training loss: 2.7154412269592285
Validation loss: 1.7125646471977234
Epoch: 12| Step: 11
Training loss: 2.5211374759674072
Validation loss: 1.7819475531578064
Epoch: 12| Step: 12
Training loss: 2.014505386352539
Validation loss: 1.7337061564127605
Epoch: 12| Step: 13
Training loss: 2.3960909843444824
Validation loss: 1.7031747102737427
Epoch: 12| Step: 14
Training loss: 1.8097858428955078
Validation loss: 1.7319055994351704
Epoch: 12| Step: 15
Training loss: 2.726362466812134
Validation loss: 1.6248830755551655
Epoch: 13| Step: 0
Training loss: 2.6459574699401855
Validation loss: 1.7468675374984741
Epoch: 13| Step: 1
Training loss: 2.241713047027588
Validation loss: 1.672613521416982
Epoch: 13| Step: 2
Training loss: 2.558669328689575
Validation loss: 1.7518924673398335
Epoch: 13| Step: 3
Training loss: 2.26879620552063
Validation loss: 1.683297574520111
Epoch: 13| Step: 4
Training loss: 2.4234635829925537
Validation loss: 1.6301987171173096
Epoch: 13| Step: 5
Training loss: 2.354221820831299
Validation loss: 1.7313413222630818
Epoch: 13| Step: 6
Training loss: 2.3696789741516113
Validation loss: 1.7533419529596965
Epoch: 13| Step: 7
Training loss: 2.1079936027526855
Validation loss: 1.706956426302592
Epoch: 13| Step: 8
Training loss: 2.157179594039917
Validation loss: 1.8020060261090596
Epoch: 13| Step: 9
Training loss: 2.534456729888916
Validation loss: 1.7090246081352234
Epoch: 13| Step: 10
Training loss: 2.05995774269104
Validation loss: 1.749734620253245
Epoch: 13| Step: 11
Training loss: 1.798770546913147
Validation loss: 1.7382776538530986
Epoch: 13| Step: 12
Training loss: 2.0284266471862793
Validation loss: 1.7129688262939453
Epoch: 13| Step: 13
Training loss: 2.0377273559570312
Validation loss: 1.6854066054026287
Epoch: 13| Step: 14
Training loss: 2.0555777549743652
Validation loss: 1.7517877419789631
Epoch: 13| Step: 15
Training loss: 2.5343048572540283
Validation loss: 1.7065723141034443
Epoch: 14| Step: 0
Training loss: 1.6681541204452515
Validation loss: 1.7563668290774028
Epoch: 14| Step: 1
Training loss: 2.6601340770721436
Validation loss: 1.6985567212104797
Epoch: 14| Step: 2
Training loss: 2.1197876930236816
Validation loss: 1.6974584857622783
Epoch: 14| Step: 3
Training loss: 2.3133621215820312
Validation loss: 1.65410582224528
Epoch: 14| Step: 4
Training loss: 2.176105260848999
Validation loss: 1.6754974921544392
Epoch: 14| Step: 5
Training loss: 1.9548345804214478
Validation loss: 1.6982492407162983
Epoch: 14| Step: 6
Training loss: 2.2634341716766357
Validation loss: 1.8020711342493694
Epoch: 14| Step: 7
Training loss: 2.0300002098083496
Validation loss: 1.7776716351509094
Epoch: 14| Step: 8
Training loss: 2.4704976081848145
Validation loss: 1.702426791191101
Epoch: 14| Step: 9
Training loss: 2.028557538986206
Validation loss: 1.6660446325937908
Epoch: 14| Step: 10
Training loss: 2.606931686401367
Validation loss: 1.7372020085652669
Epoch: 14| Step: 11
Training loss: 1.9558738470077515
Validation loss: 1.715351164340973
Epoch: 14| Step: 12
Training loss: 1.7063993215560913
Validation loss: 1.7195926904678345
Epoch: 14| Step: 13
Training loss: 2.672849178314209
Validation loss: 1.6690964301427205
Epoch: 14| Step: 14
Training loss: 2.745755672454834
Validation loss: 1.6606861154238384
Epoch: 14| Step: 15
Training loss: 2.6824710369110107
Validation loss: 1.7179890275001526
Epoch: 15| Step: 0
Training loss: 1.4314085245132446
Validation loss: 1.6828771630922954
Epoch: 15| Step: 1
Training loss: 2.3275275230407715
Validation loss: 1.7276962796847026
Epoch: 15| Step: 2
Training loss: 2.641838550567627
Validation loss: 1.6289140780766804
Epoch: 15| Step: 3
Training loss: 1.6014344692230225
Validation loss: 1.7044323086738586
Epoch: 15| Step: 4
Training loss: 2.535273313522339
Validation loss: 1.6424227158228557
Epoch: 15| Step: 5
Training loss: 1.6717971563339233
Validation loss: 1.6607444286346436
Epoch: 15| Step: 6
Training loss: 2.435393810272217
Validation loss: 1.6550798614819844
Epoch: 15| Step: 7
Training loss: 2.3980324268341064
Validation loss: 1.6994321942329407
Epoch: 15| Step: 8
Training loss: 2.3940815925598145
Validation loss: 1.670052429040273
Epoch: 15| Step: 9
Training loss: 1.80905282497406
Validation loss: 1.6989183624585469
Epoch: 15| Step: 10
Training loss: 1.9069318771362305
Validation loss: 1.6700783967971802
Epoch: 15| Step: 11
Training loss: 2.4990007877349854
Validation loss: 1.670081337292989
Epoch: 15| Step: 12
Training loss: 2.6972289085388184
Validation loss: 1.7098437547683716
Epoch: 15| Step: 13
Training loss: 2.2247228622436523
Validation loss: 1.819854160149892
Epoch: 15| Step: 14
Training loss: 2.716317653656006
Validation loss: 1.698643535375595
Epoch: 15| Step: 15
Training loss: 2.7627899646759033
Validation loss: 1.716784914334615
Epoch: 16| Step: 0
Training loss: 2.159250020980835
Validation loss: 1.6206260323524475
Epoch: 16| Step: 1
Training loss: 2.2314200401306152
Validation loss: 1.661859889825185
Epoch: 16| Step: 2
Training loss: 1.6478137969970703
Validation loss: 1.7197646299997966
Epoch: 16| Step: 3
Training loss: 2.216984272003174
Validation loss: 1.6470511953035991
Epoch: 16| Step: 4
Training loss: 2.2112224102020264
Validation loss: 1.659473955631256
Epoch: 16| Step: 5
Training loss: 2.4868626594543457
Validation loss: 1.717380702495575
Epoch: 16| Step: 6
Training loss: 2.4140923023223877
Validation loss: 1.7397612730662029
Epoch: 16| Step: 7
Training loss: 2.4136228561401367
Validation loss: 1.7038536071777344
Epoch: 16| Step: 8
Training loss: 2.3239617347717285
Validation loss: 1.6990663806597393
Epoch: 16| Step: 9
Training loss: 1.6378147602081299
Validation loss: 1.7012787262598674
Epoch: 16| Step: 10
Training loss: 2.108898401260376
Validation loss: 1.687749167283376
Epoch: 16| Step: 11
Training loss: 2.092876672744751
Validation loss: 1.6273539463678997
Epoch: 16| Step: 12
Training loss: 2.084031581878662
Validation loss: 1.7233615318934123
Epoch: 16| Step: 13
Training loss: 2.5513973236083984
Validation loss: 1.6808924476305644
Epoch: 16| Step: 14
Training loss: 2.3620543479919434
Validation loss: 1.6870343089103699
Epoch: 16| Step: 15
Training loss: 3.030672550201416
Validation loss: 1.6883435348669689
Epoch: 17| Step: 0
Training loss: 2.217355728149414
Validation loss: 1.6382579406102498
Epoch: 17| Step: 1
Training loss: 2.4675710201263428
Validation loss: 1.7130019267400105
Epoch: 17| Step: 2
Training loss: 2.4578592777252197
Validation loss: 1.7652865449587505
Epoch: 17| Step: 3
Training loss: 2.7603116035461426
Validation loss: 1.6666298906008403
Epoch: 17| Step: 4
Training loss: 2.013289213180542
Validation loss: 1.6516720453898113
Epoch: 17| Step: 5
Training loss: 2.3819825649261475
Validation loss: 1.6218223770459492
Epoch: 17| Step: 6
Training loss: 2.056250810623169
Validation loss: 1.661919891834259
Epoch: 17| Step: 7
Training loss: 2.7543060779571533
Validation loss: 1.7310582399368286
Epoch: 17| Step: 8
Training loss: 1.7653566598892212
Validation loss: 1.720039149125417
Epoch: 17| Step: 9
Training loss: 2.8625435829162598
Validation loss: 1.7364052534103394
Epoch: 17| Step: 10
Training loss: 1.7719659805297852
Validation loss: 1.69892422358195
Epoch: 17| Step: 11
Training loss: 2.1651225090026855
Validation loss: 1.7186065316200256
Epoch: 17| Step: 12
Training loss: 1.8072916269302368
Validation loss: 1.692427118619283
Epoch: 17| Step: 13
Training loss: 1.8675282001495361
Validation loss: 1.5866600275039673
Epoch: 17| Step: 14
Training loss: 2.2578811645507812
Validation loss: 1.8466545939445496
Epoch: 17| Step: 15
Training loss: 2.343543767929077
Validation loss: 1.6857298215230305
Epoch: 18| Step: 0
Training loss: 2.116176128387451
Validation loss: 1.7231964667638142
Epoch: 18| Step: 1
Training loss: 2.4035918712615967
Validation loss: 1.767627239227295
Epoch: 18| Step: 2
Training loss: 2.719825029373169
Validation loss: 1.7540926337242126
Epoch: 18| Step: 3
Training loss: 2.869213104248047
Validation loss: 1.5757903258005779
Epoch: 18| Step: 4
Training loss: 2.386770725250244
Validation loss: 1.6957016189893086
Epoch: 18| Step: 5
Training loss: 1.9854179620742798
Validation loss: 1.7430613835652669
Epoch: 18| Step: 6
Training loss: 1.8092905282974243
Validation loss: 1.7651407122612
Epoch: 18| Step: 7
Training loss: 2.5523154735565186
Validation loss: 1.700704296429952
Epoch: 18| Step: 8
Training loss: 2.3112285137176514
Validation loss: 1.7233797113100688
Epoch: 18| Step: 9
Training loss: 2.308652639389038
Validation loss: 1.652355432510376
Epoch: 18| Step: 10
Training loss: 1.4246238470077515
Validation loss: 1.6766449213027954
Epoch: 18| Step: 11
Training loss: 2.4615530967712402
Validation loss: 1.7124952872594197
Epoch: 18| Step: 12
Training loss: 2.6021294593811035
Validation loss: 1.71178271373113
Epoch: 18| Step: 13
Training loss: 1.9663200378417969
Validation loss: 1.777140736579895
Epoch: 18| Step: 14
Training loss: 2.2533795833587646
Validation loss: 1.6511622468630474
Epoch: 18| Step: 15
Training loss: 1.8570858240127563
Validation loss: 1.718223015467326
Epoch: 19| Step: 0
Training loss: 2.1499953269958496
Validation loss: 1.6381836136182149
Epoch: 19| Step: 1
Training loss: 2.0709991455078125
Validation loss: 1.7829213738441467
Epoch: 19| Step: 2
Training loss: 2.10286021232605
Validation loss: 1.64091952641805
Epoch: 19| Step: 3
Training loss: 2.6478309631347656
Validation loss: 1.748527189095815
Epoch: 19| Step: 4
Training loss: 2.3203847408294678
Validation loss: 1.686597208182017
Epoch: 19| Step: 5
Training loss: 2.2190160751342773
Validation loss: 1.6983945568402607
Epoch: 19| Step: 6
Training loss: 2.425963878631592
Validation loss: 1.639823059240977
Epoch: 19| Step: 7
Training loss: 2.3113067150115967
Validation loss: 1.661916156609853
Epoch: 19| Step: 8
Training loss: 1.8757816553115845
Validation loss: 1.6502652565638225
Epoch: 19| Step: 9
Training loss: 1.9242817163467407
Validation loss: 1.703880488872528
Epoch: 19| Step: 10
Training loss: 2.089625358581543
Validation loss: 1.7015628218650818
Epoch: 19| Step: 11
Training loss: 2.2504220008850098
Validation loss: 1.7259369889895122
Epoch: 19| Step: 12
Training loss: 2.15559458732605
Validation loss: 1.6663844585418701
Epoch: 19| Step: 13
Training loss: 2.4827075004577637
Validation loss: 1.7226306398709614
Epoch: 19| Step: 14
Training loss: 2.5429463386535645
Validation loss: 1.724931240081787
Epoch: 19| Step: 15
Training loss: 2.3411812782287598
Validation loss: 1.7879225214322407
Epoch: 20| Step: 0
Training loss: 2.868356704711914
Validation loss: 1.7507689396540325
Epoch: 20| Step: 1
Training loss: 1.9262573719024658
Validation loss: 1.6752368211746216
Epoch: 20| Step: 2
Training loss: 2.2488601207733154
Validation loss: 1.665669322013855
Epoch: 20| Step: 3
Training loss: 2.537682056427002
Validation loss: 1.6820786595344543
Epoch: 20| Step: 4
Training loss: 2.0406558513641357
Validation loss: 1.6820785403251648
Epoch: 20| Step: 5
Training loss: 2.154822587966919
Validation loss: 1.6766388813654582
Epoch: 20| Step: 6
Training loss: 2.3502936363220215
Validation loss: 1.7234041293462117
Epoch: 20| Step: 7
Training loss: 2.8751609325408936
Validation loss: 1.6440948645273845
Epoch: 20| Step: 8
Training loss: 2.323685884475708
Validation loss: 1.7283742626508076
Epoch: 20| Step: 9
Training loss: 2.186232328414917
Validation loss: 1.7006497383117676
Epoch: 20| Step: 10
Training loss: 1.964905023574829
Validation loss: 1.638652006785075
Epoch: 20| Step: 11
Training loss: 2.5135273933410645
Validation loss: 1.7276771267255147
Epoch: 20| Step: 12
Training loss: 2.450143814086914
Validation loss: 1.7086684902509053
Epoch: 20| Step: 13
Training loss: 1.7058693170547485
Validation loss: 1.702972372372945
Epoch: 20| Step: 14
Training loss: 1.8118922710418701
Validation loss: 1.6739339033762615
Epoch: 20| Step: 15
Training loss: 1.9346364736557007
Validation loss: 1.6501023173332214
Epoch: 21| Step: 0
Training loss: 2.1422157287597656
Validation loss: 1.6729413072268169
Epoch: 21| Step: 1
Training loss: 2.072706699371338
Validation loss: 1.6754717826843262
Epoch: 21| Step: 2
Training loss: 2.1472933292388916
Validation loss: 1.668149173259735
Epoch: 21| Step: 3
Training loss: 1.745976209640503
Validation loss: 1.6873639623324077
Epoch: 21| Step: 4
Training loss: 2.2534573078155518
Validation loss: 1.7256619930267334
Epoch: 21| Step: 5
Training loss: 2.2710041999816895
Validation loss: 1.6939992705980937
Epoch: 21| Step: 6
Training loss: 2.527675151824951
Validation loss: 1.6834476590156555
Epoch: 21| Step: 7
Training loss: 2.625316619873047
Validation loss: 1.6871522267659504
Epoch: 21| Step: 8
Training loss: 2.26928448677063
Validation loss: 1.644269545873006
Epoch: 21| Step: 9
Training loss: 2.3423819541931152
Validation loss: 1.7120894193649292
Epoch: 21| Step: 10
Training loss: 2.3101742267608643
Validation loss: 1.7142098744710286
Epoch: 21| Step: 11
Training loss: 2.2978949546813965
Validation loss: 1.7310356100400288
Epoch: 21| Step: 12
Training loss: 2.5565185546875
Validation loss: 1.7095137635866802
Epoch: 21| Step: 13
Training loss: 1.7222988605499268
Validation loss: 1.6669223308563232
Epoch: 21| Step: 14
Training loss: 2.7421658039093018
Validation loss: 1.6362578670183818
Epoch: 21| Step: 15
Training loss: 1.8314129114151
Validation loss: 1.696196436882019
Epoch: 22| Step: 0
Training loss: 1.9513314962387085
Validation loss: 1.7272802193959553
Epoch: 22| Step: 1
Training loss: 2.0753555297851562
Validation loss: 1.6792609492937725
Epoch: 22| Step: 2
Training loss: 2.3703927993774414
Validation loss: 1.692414144674937
Epoch: 22| Step: 3
Training loss: 2.7178523540496826
Validation loss: 1.7041696707407634
Epoch: 22| Step: 4
Training loss: 2.1629443168640137
Validation loss: 1.6987679402033489
Epoch: 22| Step: 5
Training loss: 1.830601453781128
Validation loss: 1.7280580004056294
Epoch: 22| Step: 6
Training loss: 2.0721278190612793
Validation loss: 1.7138072848320007
Epoch: 22| Step: 7
Training loss: 2.38311505317688
Validation loss: 1.6248401006062825
Epoch: 22| Step: 8
Training loss: 2.3316121101379395
Validation loss: 1.691781500975291
Epoch: 22| Step: 9
Training loss: 2.2037312984466553
Validation loss: 1.7053906718889873
Epoch: 22| Step: 10
Training loss: 2.1605663299560547
Validation loss: 1.6856627662976582
Epoch: 22| Step: 11
Training loss: 2.0193960666656494
Validation loss: 1.6730942130088806
Epoch: 22| Step: 12
Training loss: 2.0896010398864746
Validation loss: 1.718845506509145
Epoch: 22| Step: 13
Training loss: 2.704671859741211
Validation loss: 1.678976058959961
Epoch: 22| Step: 14
Training loss: 2.4672272205352783
Validation loss: 1.628242035706838
Epoch: 22| Step: 15
Training loss: 2.292729377746582
Validation loss: 1.623109479745229
Epoch: 23| Step: 0
Training loss: 2.113861083984375
Validation loss: 1.7281275391578674
Epoch: 23| Step: 1
Training loss: 2.456446886062622
Validation loss: 1.6630093852678935
Epoch: 23| Step: 2
Training loss: 2.1538379192352295
Validation loss: 1.7013473709424336
Epoch: 23| Step: 3
Training loss: 1.7478631734848022
Validation loss: 1.7236287991205852
Epoch: 23| Step: 4
Training loss: 2.0042672157287598
Validation loss: 1.6117810010910034
Epoch: 23| Step: 5
Training loss: 2.5472500324249268
Validation loss: 1.6466091871261597
Epoch: 23| Step: 6
Training loss: 2.5651450157165527
Validation loss: 1.7115997274716694
Epoch: 23| Step: 7
Training loss: 2.700993776321411
Validation loss: 1.6334102551142375
Epoch: 23| Step: 8
Training loss: 2.227834701538086
Validation loss: 1.6192538738250732
Epoch: 23| Step: 9
Training loss: 1.614241361618042
Validation loss: 1.6706910530726116
Epoch: 23| Step: 10
Training loss: 2.614614486694336
Validation loss: 1.691280722618103
Epoch: 23| Step: 11
Training loss: 2.7279858589172363
Validation loss: 1.7063637574513753
Epoch: 23| Step: 12
Training loss: 2.3631319999694824
Validation loss: 1.699900468190511
Epoch: 23| Step: 13
Training loss: 1.7963600158691406
Validation loss: 1.7382965485254924
Epoch: 23| Step: 14
Training loss: 1.9196786880493164
Validation loss: 1.7154986063639324
Epoch: 23| Step: 15
Training loss: 2.363675594329834
Validation loss: 1.7030723889668782
Epoch: 24| Step: 0
Training loss: 1.652502417564392
Validation loss: 1.6157257755597432
Epoch: 24| Step: 1
Training loss: 2.663353443145752
Validation loss: 1.7278537352879841
Epoch: 24| Step: 2
Training loss: 1.9156739711761475
Validation loss: 1.747163971265157
Epoch: 24| Step: 3
Training loss: 2.195228099822998
Validation loss: 1.6996929446856182
Epoch: 24| Step: 4
Training loss: 2.03493332862854
Validation loss: 1.7582165002822876
Epoch: 24| Step: 5
Training loss: 2.3272926807403564
Validation loss: 1.6512001752853394
Epoch: 24| Step: 6
Training loss: 2.5471529960632324
Validation loss: 1.6503957112630208
Epoch: 24| Step: 7
Training loss: 2.3110885620117188
Validation loss: 1.6723777453104656
Epoch: 24| Step: 8
Training loss: 2.8489818572998047
Validation loss: 1.653370161851247
Epoch: 24| Step: 9
Training loss: 2.2475152015686035
Validation loss: 1.696466048558553
Epoch: 24| Step: 10
Training loss: 2.2426860332489014
Validation loss: 1.7636982401212056
Epoch: 24| Step: 11
Training loss: 2.105868101119995
Validation loss: 1.6317118604977925
Epoch: 24| Step: 12
Training loss: 2.026721954345703
Validation loss: 1.7400192022323608
Epoch: 24| Step: 13
Training loss: 2.176503896713257
Validation loss: 1.7289915084838867
Epoch: 24| Step: 14
Training loss: 2.2963528633117676
Validation loss: 1.6395543416341145
Epoch: 24| Step: 15
Training loss: 2.2071995735168457
Validation loss: 1.7678984800974529
Epoch: 25| Step: 0
Training loss: 2.0075223445892334
Validation loss: 1.664525032043457
Epoch: 25| Step: 1
Training loss: 2.01235294342041
Validation loss: 1.6473057866096497
Epoch: 25| Step: 2
Training loss: 2.0358455181121826
Validation loss: 1.666633427143097
Epoch: 25| Step: 3
Training loss: 2.675436496734619
Validation loss: 1.6374680797259014
Epoch: 25| Step: 4
Training loss: 1.7716525793075562
Validation loss: 1.670468509197235
Epoch: 25| Step: 5
Training loss: 2.101398229598999
Validation loss: 1.706615646680196
Epoch: 25| Step: 6
Training loss: 2.674999952316284
Validation loss: 1.6771735151608784
Epoch: 25| Step: 7
Training loss: 2.2177798748016357
Validation loss: 1.5924379428227742
Epoch: 25| Step: 8
Training loss: 2.2533557415008545
Validation loss: 1.7416818737983704
Epoch: 25| Step: 9
Training loss: 2.6444880962371826
Validation loss: 1.7215131322542827
Epoch: 25| Step: 10
Training loss: 1.491921067237854
Validation loss: 1.727681299050649
Epoch: 25| Step: 11
Training loss: 2.4908719062805176
Validation loss: 1.6548432509104412
Epoch: 25| Step: 12
Training loss: 2.3952927589416504
Validation loss: 1.647997756799062
Epoch: 25| Step: 13
Training loss: 2.632627010345459
Validation loss: 1.6764681736628215
Epoch: 25| Step: 14
Training loss: 2.0315849781036377
Validation loss: 1.6785381038983662
Epoch: 25| Step: 15
Training loss: 2.3400001525878906
Validation loss: 1.585103988647461
Epoch: 26| Step: 0
Training loss: 1.8556108474731445
Validation loss: 1.6843790014584858
Epoch: 26| Step: 1
Training loss: 2.282388210296631
Validation loss: 1.7203319668769836
Epoch: 26| Step: 2
Training loss: 2.3938636779785156
Validation loss: 1.6979283889134724
Epoch: 26| Step: 3
Training loss: 2.19685959815979
Validation loss: 1.6659721334775288
Epoch: 26| Step: 4
Training loss: 2.651998281478882
Validation loss: 1.6141890684763591
Epoch: 26| Step: 5
Training loss: 2.3756613731384277
Validation loss: 1.6813298265139263
Epoch: 26| Step: 6
Training loss: 1.720867395401001
Validation loss: 1.7503218452135723
Epoch: 26| Step: 7
Training loss: 2.4322140216827393
Validation loss: 1.6158350706100464
Epoch: 26| Step: 8
Training loss: 1.7585757970809937
Validation loss: 1.6181235512097676
Epoch: 26| Step: 9
Training loss: 2.2506604194641113
Validation loss: 1.6456612745920818
Epoch: 26| Step: 10
Training loss: 2.340404510498047
Validation loss: 1.7074817816416423
Epoch: 26| Step: 11
Training loss: 1.9750597476959229
Validation loss: 1.7266284426053364
Epoch: 26| Step: 12
Training loss: 2.301539897918701
Validation loss: 1.6684042414029439
Epoch: 26| Step: 13
Training loss: 2.4736995697021484
Validation loss: 1.6542376279830933
Epoch: 26| Step: 14
Training loss: 2.230583906173706
Validation loss: 1.6927406191825867
Epoch: 26| Step: 15
Training loss: 2.5436861515045166
Validation loss: 1.5555148522059123
Epoch: 27| Step: 0
Training loss: 1.7791324853897095
Validation loss: 1.675224502881368
Epoch: 27| Step: 1
Training loss: 2.387855291366577
Validation loss: 1.6561771233876545
Epoch: 27| Step: 2
Training loss: 2.3678746223449707
Validation loss: 1.657985508441925
Epoch: 27| Step: 3
Training loss: 2.1311261653900146
Validation loss: 1.6347720225652058
Epoch: 27| Step: 4
Training loss: 2.380589246749878
Validation loss: 1.7326102058092754
Epoch: 27| Step: 5
Training loss: 2.228947162628174
Validation loss: 1.6651745835940044
Epoch: 27| Step: 6
Training loss: 2.247058868408203
Validation loss: 1.7376344402631123
Epoch: 27| Step: 7
Training loss: 2.7859129905700684
Validation loss: 1.629015028476715
Epoch: 27| Step: 8
Training loss: 2.5033416748046875
Validation loss: 1.6239363153775532
Epoch: 27| Step: 9
Training loss: 1.8414052724838257
Validation loss: 1.6798932154973347
Epoch: 27| Step: 10
Training loss: 2.0479016304016113
Validation loss: 1.6890433430671692
Epoch: 27| Step: 11
Training loss: 2.1471524238586426
Validation loss: 1.7124444047609966
Epoch: 27| Step: 12
Training loss: 2.158018112182617
Validation loss: 1.6929335792859395
Epoch: 27| Step: 13
Training loss: 2.0516960620880127
Validation loss: 1.61616055170695
Epoch: 27| Step: 14
Training loss: 2.4632821083068848
Validation loss: 1.658635437488556
Epoch: 27| Step: 15
Training loss: 2.299999713897705
Validation loss: 1.7247811555862427
Epoch: 28| Step: 0
Training loss: 2.176647186279297
Validation loss: 1.6260247429211934
Epoch: 28| Step: 1
Training loss: 2.827822685241699
Validation loss: 1.587061842282613
Epoch: 28| Step: 2
Training loss: 2.544006824493408
Validation loss: 1.7068753242492676
Epoch: 28| Step: 3
Training loss: 2.2028911113739014
Validation loss: 1.669014533360799
Epoch: 28| Step: 4
Training loss: 1.9576866626739502
Validation loss: 1.6851020852724712
Epoch: 28| Step: 5
Training loss: 2.133767604827881
Validation loss: 1.730629324913025
Epoch: 28| Step: 6
Training loss: 2.303053379058838
Validation loss: 1.6933337648709614
Epoch: 28| Step: 7
Training loss: 2.5766167640686035
Validation loss: 1.676397701104482
Epoch: 28| Step: 8
Training loss: 2.1886305809020996
Validation loss: 1.7286731402079265
Epoch: 28| Step: 9
Training loss: 2.9582386016845703
Validation loss: 1.6387615601221721
Epoch: 28| Step: 10
Training loss: 2.0578112602233887
Validation loss: 1.6771061420440674
Epoch: 28| Step: 11
Training loss: 1.300591230392456
Validation loss: 1.6113335092862446
Epoch: 28| Step: 12
Training loss: 2.221871852874756
Validation loss: 1.754907488822937
Epoch: 28| Step: 13
Training loss: 1.9063650369644165
Validation loss: 1.6651147603988647
Epoch: 28| Step: 14
Training loss: 2.3390402793884277
Validation loss: 1.6662999590237935
Epoch: 28| Step: 15
Training loss: 2.062408924102783
Validation loss: 1.6114656329154968
Epoch: 29| Step: 0
Training loss: 1.708733320236206
Validation loss: 1.669576088587443
Epoch: 29| Step: 1
Training loss: 2.045372486114502
Validation loss: 1.7171673973401387
Epoch: 29| Step: 2
Training loss: 2.4206223487854004
Validation loss: 1.7802468538284302
Epoch: 29| Step: 3
Training loss: 2.488668441772461
Validation loss: 1.5401996771494548
Epoch: 29| Step: 4
Training loss: 1.9960523843765259
Validation loss: 1.677423119544983
Epoch: 29| Step: 5
Training loss: 2.045555591583252
Validation loss: 1.6540226737658184
Epoch: 29| Step: 6
Training loss: 1.6989076137542725
Validation loss: 1.6773701906204224
Epoch: 29| Step: 7
Training loss: 1.7019771337509155
Validation loss: 1.6734967231750488
Epoch: 29| Step: 8
Training loss: 2.565305233001709
Validation loss: 1.622828185558319
Epoch: 29| Step: 9
Training loss: 2.284324884414673
Validation loss: 1.742556671301524
Epoch: 29| Step: 10
Training loss: 2.020719051361084
Validation loss: 1.7407202919324238
Epoch: 29| Step: 11
Training loss: 2.825249195098877
Validation loss: 1.731465458869934
Epoch: 29| Step: 12
Training loss: 2.5347399711608887
Validation loss: 1.5892266829808552
Epoch: 29| Step: 13
Training loss: 2.38421893119812
Validation loss: 1.6301950414975483
Epoch: 29| Step: 14
Training loss: 2.850508451461792
Validation loss: 1.6363641619682312
Epoch: 29| Step: 15
Training loss: 2.159914255142212
Validation loss: 1.6992742419242859
Epoch: 30| Step: 0
Training loss: 2.12545108795166
Validation loss: 1.6803009708722432
Epoch: 30| Step: 1
Training loss: 2.6206064224243164
Validation loss: 1.6363198359807332
Epoch: 30| Step: 2
Training loss: 2.0649466514587402
Validation loss: 1.649245063463847
Epoch: 30| Step: 3
Training loss: 2.32684063911438
Validation loss: 1.702167232831319
Epoch: 30| Step: 4
Training loss: 2.658043384552002
Validation loss: 1.7200481295585632
Epoch: 30| Step: 5
Training loss: 2.0562095642089844
Validation loss: 1.684234579404195
Epoch: 30| Step: 6
Training loss: 1.9430853128433228
Validation loss: 1.7009324431419373
Epoch: 30| Step: 7
Training loss: 2.2512714862823486
Validation loss: 1.7100000778834026
Epoch: 30| Step: 8
Training loss: 2.0278303623199463
Validation loss: 1.6851147413253784
Epoch: 30| Step: 9
Training loss: 2.036339282989502
Validation loss: 1.620213011900584
Epoch: 30| Step: 10
Training loss: 2.046653985977173
Validation loss: 1.6467580795288086
Epoch: 30| Step: 11
Training loss: 2.081090211868286
Validation loss: 1.6308794816335042
Epoch: 30| Step: 12
Training loss: 2.305685520172119
Validation loss: 1.63716721534729
Epoch: 30| Step: 13
Training loss: 2.6448824405670166
Validation loss: 1.5880035758018494
Epoch: 30| Step: 14
Training loss: 2.199291467666626
Validation loss: 1.6723275581995647
Epoch: 30| Step: 15
Training loss: 2.3482916355133057
Validation loss: 1.6790674328804016
