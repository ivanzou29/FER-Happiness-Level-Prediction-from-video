Epoch: 1| Step: 0
Training loss: 5.81501666315107
Validation loss: 5.207616265339156
Epoch: 1| Step: 1
Training loss: 5.52665390184966
Validation loss: 5.008542078888103
Epoch: 1| Step: 2
Training loss: 5.0055438778358
Validation loss: 4.979100760529441
Epoch: 1| Step: 3
Training loss: 5.037743210896676
Validation loss: 4.962910194276535
Epoch: 1| Step: 4
Training loss: 5.315070573799352
Validation loss: 4.531800057817322
Epoch: 1| Step: 5
Training loss: 5.392417366480574
Validation loss: 4.538783737292538
Epoch: 1| Step: 6
Training loss: 4.710758136225801
Validation loss: 4.594537130594653
Epoch: 1| Step: 7
Training loss: 4.756801754682405
Validation loss: 4.41893133120885
Epoch: 2| Step: 0
Training loss: 4.703236930250305
Validation loss: 4.506304469022166
Epoch: 2| Step: 1
Training loss: 4.03059819592782
Validation loss: 4.282564178982063
Epoch: 2| Step: 2
Training loss: 4.831597422041869
Validation loss: 4.340870321669361
Epoch: 2| Step: 3
Training loss: 4.752705857395232
Validation loss: 4.302653153906868
Epoch: 2| Step: 4
Training loss: 4.759021824577677
Validation loss: 4.19615111243249
Epoch: 2| Step: 5
Training loss: 5.237791489385511
Validation loss: 4.199983399220034
Epoch: 2| Step: 6
Training loss: 4.271073100485111
Validation loss: 4.096475273082401
Epoch: 2| Step: 7
Training loss: 4.52937099039188
Validation loss: 3.9059998363511794
Epoch: 3| Step: 0
Training loss: 4.000734261831078
Validation loss: 3.909350049177288
Epoch: 3| Step: 1
Training loss: 4.784855100536471
Validation loss: 3.9854784808220654
Epoch: 3| Step: 2
Training loss: 4.272844514031474
Validation loss: 3.865881872478505
Epoch: 3| Step: 3
Training loss: 4.364587654833904
Validation loss: 3.728281011967301
Epoch: 3| Step: 4
Training loss: 4.207670002141782
Validation loss: 3.654310887068539
Epoch: 3| Step: 5
Training loss: 3.1587512992007833
Validation loss: 3.650071884289389
Epoch: 3| Step: 6
Training loss: 4.29346455565025
Validation loss: 3.6746090812628665
Epoch: 3| Step: 7
Training loss: 4.3488307302185
Validation loss: 3.5805172978511024
Epoch: 4| Step: 0
Training loss: 3.558438043297002
Validation loss: 3.6190264105393126
Epoch: 4| Step: 1
Training loss: 3.941323739767551
Validation loss: 3.4946421580983014
Epoch: 4| Step: 2
Training loss: 4.415738758044555
Validation loss: 3.419441465349877
Epoch: 4| Step: 3
Training loss: 3.7309080494367657
Validation loss: 3.435165661861254
Epoch: 4| Step: 4
Training loss: 3.9121979861953458
Validation loss: 3.4188266908715748
Epoch: 4| Step: 5
Training loss: 4.382733077419303
Validation loss: 3.3362333318967767
Epoch: 4| Step: 6
Training loss: 3.4449634331920382
Validation loss: 3.3293712089038423
Epoch: 4| Step: 7
Training loss: 3.4556272252600535
Validation loss: 3.3263719311630346
Epoch: 5| Step: 0
Training loss: 3.87806801704145
Validation loss: 3.2932206734018035
Epoch: 5| Step: 1
Training loss: 3.5254620404816377
Validation loss: 3.2584822681891885
Epoch: 5| Step: 2
Training loss: 4.052248417777454
Validation loss: 3.2179694646720622
Epoch: 5| Step: 3
Training loss: 3.437113098565647
Validation loss: 3.117292417454454
Epoch: 5| Step: 4
Training loss: 3.329153412437234
Validation loss: 3.073804955158728
Epoch: 5| Step: 5
Training loss: 3.7197456629776733
Validation loss: 2.947073551461625
Epoch: 5| Step: 6
Training loss: 3.5797065005054174
Validation loss: 3.0938928986224763
Epoch: 5| Step: 7
Training loss: 3.0057175511741825
Validation loss: 2.9677871642580205
Epoch: 6| Step: 0
Training loss: 3.6896590038590693
Validation loss: 2.816223104623082
Epoch: 6| Step: 1
Training loss: 2.7631468796570244
Validation loss: 2.9194379589542234
Epoch: 6| Step: 2
Training loss: 3.4200366233515567
Validation loss: 2.8126858452826915
Epoch: 6| Step: 3
Training loss: 3.335970947669702
Validation loss: 2.6993762569546162
Epoch: 6| Step: 4
Training loss: 3.436249245330961
Validation loss: 2.8175692036774396
Epoch: 6| Step: 5
Training loss: 3.3954741087089144
Validation loss: 2.805685997297012
Epoch: 6| Step: 6
Training loss: 3.3170848282509295
Validation loss: 2.7532112333320904
Epoch: 6| Step: 7
Training loss: 3.1456013440281585
Validation loss: 2.745228523713499
Epoch: 7| Step: 0
Training loss: 3.4212827126357555
Validation loss: 2.5966494656390906
Epoch: 7| Step: 1
Training loss: 2.8583859259954227
Validation loss: 2.7132924210404687
Epoch: 7| Step: 2
Training loss: 2.903309144256185
Validation loss: 2.656049993475165
Epoch: 7| Step: 3
Training loss: 3.3183011773424433
Validation loss: 2.5513941944895104
Epoch: 7| Step: 4
Training loss: 2.8973630162822395
Validation loss: 2.658255802391699
Epoch: 7| Step: 5
Training loss: 3.380849925291892
Validation loss: 2.5692733349719545
Epoch: 7| Step: 6
Training loss: 3.1025515115720492
Validation loss: 2.6637212737844065
Epoch: 7| Step: 7
Training loss: 3.062258808213944
Validation loss: 2.6053924812963687
Epoch: 8| Step: 0
Training loss: 2.972698436943996
Validation loss: 2.529761495443568
Epoch: 8| Step: 1
Training loss: 3.25965869287052
Validation loss: 2.5113958424234615
Epoch: 8| Step: 2
Training loss: 2.828434205407877
Validation loss: 2.400655200431814
Epoch: 8| Step: 3
Training loss: 3.1445401967555178
Validation loss: 2.4407196991996494
Epoch: 8| Step: 4
Training loss: 3.096992873826911
Validation loss: 2.372171115247113
Epoch: 8| Step: 5
Training loss: 2.760882951233202
Validation loss: 2.317391476211425
Epoch: 8| Step: 6
Training loss: 2.7142224376157777
Validation loss: 2.294443125928256
Epoch: 8| Step: 7
Training loss: 2.9095561592908603
Validation loss: 2.3753368470898253
Epoch: 9| Step: 0
Training loss: 2.755613493139373
Validation loss: 2.353359259136033
Epoch: 9| Step: 1
Training loss: 2.8307610971754977
Validation loss: 2.2868025870449276
Epoch: 9| Step: 2
Training loss: 3.1003140259708126
Validation loss: 2.275138587436959
Epoch: 9| Step: 3
Training loss: 2.7842598391435516
Validation loss: 2.3513947726420525
Epoch: 9| Step: 4
Training loss: 2.815144037793045
Validation loss: 2.2534319991004854
Epoch: 9| Step: 5
Training loss: 3.0987843868044966
Validation loss: 2.3253633023051434
Epoch: 9| Step: 6
Training loss: 2.5863016569381756
Validation loss: 2.2417277928878416
Epoch: 9| Step: 7
Training loss: 2.84953206554229
Validation loss: 2.275742617641712
Epoch: 10| Step: 0
Training loss: 2.817278384383976
Validation loss: 2.2542681309301766
Epoch: 10| Step: 1
Training loss: 2.785699777949636
Validation loss: 2.24442484010328
Epoch: 10| Step: 2
Training loss: 2.75859668162192
Validation loss: 2.2044915770080027
Epoch: 10| Step: 3
Training loss: 2.8815766453475944
Validation loss: 2.243973164931377
Epoch: 10| Step: 4
Training loss: 2.411523564048956
Validation loss: 2.230988876629215
Epoch: 10| Step: 5
Training loss: 2.742124638285224
Validation loss: 2.2183903198166797
Epoch: 10| Step: 6
Training loss: 2.9829951586580137
Validation loss: 2.144163804471125
Epoch: 10| Step: 7
Training loss: 2.7395610349107873
Validation loss: 2.170674721072951
Epoch: 11| Step: 0
Training loss: 2.429531276378304
Validation loss: 2.135790202859705
Epoch: 11| Step: 1
Training loss: 2.785204615447211
Validation loss: 2.13377373476093
Epoch: 11| Step: 2
Training loss: 2.9548242917564167
Validation loss: 2.157423480769332
Epoch: 11| Step: 3
Training loss: 2.646801198315533
Validation loss: 2.1613106326448057
Epoch: 11| Step: 4
Training loss: 2.7534794036998207
Validation loss: 2.100802802677201
Epoch: 11| Step: 5
Training loss: 2.5481624976461763
Validation loss: 2.1559075710132465
Epoch: 11| Step: 6
Training loss: 2.9200771737025066
Validation loss: 2.129192106029774
Epoch: 11| Step: 7
Training loss: 2.6600800669960276
Validation loss: 2.08939318137433
Epoch: 12| Step: 0
Training loss: 2.893525354221888
Validation loss: 2.146086234605709
Epoch: 12| Step: 1
Training loss: 2.6041502583304688
Validation loss: 2.070089970146632
Epoch: 12| Step: 2
Training loss: 2.578415547962755
Validation loss: 2.1048090874989054
Epoch: 12| Step: 3
Training loss: 2.388505881554811
Validation loss: 2.136640924878618
Epoch: 12| Step: 4
Training loss: 2.4399031505749957
Validation loss: 2.1781085352282
Epoch: 12| Step: 5
Training loss: 3.158434272568955
Validation loss: 2.1922975168016654
Epoch: 12| Step: 6
Training loss: 2.692916202945503
Validation loss: 2.155719631426557
Epoch: 12| Step: 7
Training loss: 2.6253848020888872
Validation loss: 2.0899937747134114
Epoch: 13| Step: 0
Training loss: 2.86833978516649
Validation loss: 2.1572601372539957
Epoch: 13| Step: 1
Training loss: 2.5721946248861998
Validation loss: 2.093886135633788
Epoch: 13| Step: 2
Training loss: 2.804256055369832
Validation loss: 2.1236871816951415
Epoch: 13| Step: 3
Training loss: 2.3481743315489196
Validation loss: 2.1377950974952835
Epoch: 13| Step: 4
Training loss: 2.8781472270492503
Validation loss: 2.0847774582698473
Epoch: 13| Step: 5
Training loss: 2.4329488276295024
Validation loss: 2.099492592413013
Epoch: 13| Step: 6
Training loss: 2.6986109798752254
Validation loss: 2.1200007200165603
Epoch: 13| Step: 7
Training loss: 2.625841550807106
Validation loss: 2.137046125507013
Epoch: 14| Step: 0
Training loss: 2.525343231440921
Validation loss: 2.1103332262548764
Epoch: 14| Step: 1
Training loss: 2.7833659663162353
Validation loss: 2.0655827547404755
Epoch: 14| Step: 2
Training loss: 2.728339198422133
Validation loss: 2.1579243056983164
Epoch: 14| Step: 3
Training loss: 2.553080575432765
Validation loss: 2.132979563939704
Epoch: 14| Step: 4
Training loss: 2.828542773334187
Validation loss: 2.1352054139059558
Epoch: 14| Step: 5
Training loss: 2.445164587647886
Validation loss: 2.1582968785182763
Epoch: 14| Step: 6
Training loss: 2.8033442348792907
Validation loss: 2.123472026987534
Epoch: 14| Step: 7
Training loss: 2.487161093776695
Validation loss: 2.0765617251228057
Epoch: 15| Step: 0
Training loss: 2.6099491972381967
Validation loss: 2.1195083789367657
Epoch: 15| Step: 1
Training loss: 3.0101909794847224
Validation loss: 2.04597372667677
Epoch: 15| Step: 2
Training loss: 2.791619419058672
Validation loss: 2.0816088784802322
Epoch: 15| Step: 3
Training loss: 2.6310378979077917
Validation loss: 2.084713447768534
Epoch: 15| Step: 4
Training loss: 2.329016188490325
Validation loss: 2.110158006702363
Epoch: 15| Step: 5
Training loss: 2.92773551508275
Validation loss: 2.091048557889809
Epoch: 15| Step: 6
Training loss: 2.3450270161973736
Validation loss: 2.14445896320943
Epoch: 15| Step: 7
Training loss: 2.3985467444773962
Validation loss: 2.1837572769477873
Epoch: 16| Step: 0
Training loss: 2.8024640208783897
Validation loss: 2.100861968566269
Epoch: 16| Step: 1
Training loss: 2.722520865928759
Validation loss: 2.074663826151269
Epoch: 16| Step: 2
Training loss: 2.3947100673698882
Validation loss: 2.0762082368043817
Epoch: 16| Step: 3
Training loss: 2.884111313426946
Validation loss: 2.132983615324775
Epoch: 16| Step: 4
Training loss: 2.3955970868824004
Validation loss: 2.092597003634371
Epoch: 16| Step: 5
Training loss: 2.6527085874986738
Validation loss: 2.0948032389000826
Epoch: 16| Step: 6
Training loss: 2.7002023762339795
Validation loss: 2.0586661383493667
Epoch: 16| Step: 7
Training loss: 2.495003571135081
Validation loss: 2.062971755420064
Epoch: 17| Step: 0
Training loss: 2.897532854000908
Validation loss: 2.0847492124318245
Epoch: 17| Step: 1
Training loss: 2.6377677130763795
Validation loss: 2.0646814025030724
Epoch: 17| Step: 2
Training loss: 2.7348358637847467
Validation loss: 2.1601071649201145
Epoch: 17| Step: 3
Training loss: 2.6331546006529774
Validation loss: 2.147824019307852
Epoch: 17| Step: 4
Training loss: 2.556693779587334
Validation loss: 2.0699794718499565
Epoch: 17| Step: 5
Training loss: 2.745414639061786
Validation loss: 2.0805536324063536
Epoch: 17| Step: 6
Training loss: 2.559401150338112
Validation loss: 2.031873024681964
Epoch: 17| Step: 7
Training loss: 2.2804239946281655
Validation loss: 2.07755385274864
Epoch: 18| Step: 0
Training loss: 2.797169163754305
Validation loss: 2.0777782324435257
Epoch: 18| Step: 1
Training loss: 2.550419032504958
Validation loss: 2.170157265709197
Epoch: 18| Step: 2
Training loss: 2.6426846749872284
Validation loss: 2.151380854319045
Epoch: 18| Step: 3
Training loss: 2.6397771433487773
Validation loss: 2.094550381127259
Epoch: 18| Step: 4
Training loss: 2.552586616144957
Validation loss: 2.0261256576110815
Epoch: 18| Step: 5
Training loss: 2.727244294625239
Validation loss: 2.097421156888694
Epoch: 18| Step: 6
Training loss: 2.5427457884567137
Validation loss: 2.1137137685269853
Epoch: 18| Step: 7
Training loss: 2.6212031743820203
Validation loss: 2.068404362218757
Epoch: 19| Step: 0
Training loss: 2.6833835391763796
Validation loss: 2.1718376851926373
Epoch: 19| Step: 1
Training loss: 2.6101358183969117
Validation loss: 2.1311458082180414
Epoch: 19| Step: 2
Training loss: 2.5176766126973193
Validation loss: 2.05766879841113
Epoch: 19| Step: 3
Training loss: 2.557266193788745
Validation loss: 2.1169775994672797
Epoch: 19| Step: 4
Training loss: 2.5262864036900563
Validation loss: 2.144767032919626
Epoch: 19| Step: 5
Training loss: 2.546138259016407
Validation loss: 2.112563304617984
Epoch: 19| Step: 6
Training loss: 2.9997944761448054
Validation loss: 2.143674454763874
Epoch: 19| Step: 7
Training loss: 2.6012193608163723
Validation loss: 2.0722835500506522
Epoch: 20| Step: 0
Training loss: 2.5731606515782426
Validation loss: 2.077579491622007
Epoch: 20| Step: 1
Training loss: 2.7455086010027236
Validation loss: 2.1333466883887664
Epoch: 20| Step: 2
Training loss: 2.4949902884804613
Validation loss: 2.0774730625305495
Epoch: 20| Step: 3
Training loss: 3.1010918632513502
Validation loss: 2.144544718799514
Epoch: 20| Step: 4
Training loss: 2.3581024173693605
Validation loss: 2.1971881207928066
Epoch: 20| Step: 5
Training loss: 2.473075264716708
Validation loss: 2.040359969346565
Epoch: 20| Step: 6
Training loss: 2.7444327093775263
Validation loss: 2.0683126138952943
Epoch: 20| Step: 7
Training loss: 2.5129817557714356
Validation loss: 2.0917518624004714
Epoch: 21| Step: 0
Training loss: 2.678505506158424
Validation loss: 2.1487843368952944
Epoch: 21| Step: 1
Training loss: 2.2808133060057827
Validation loss: 2.1043131987673895
Epoch: 21| Step: 2
Training loss: 2.5645487898961985
Validation loss: 2.1267225644181664
Epoch: 21| Step: 3
Training loss: 2.579348094847004
Validation loss: 2.15988275616871
Epoch: 21| Step: 4
Training loss: 2.846901792364579
Validation loss: 2.079945735174118
Epoch: 21| Step: 5
Training loss: 2.7688361023201122
Validation loss: 2.115980861963285
Epoch: 21| Step: 6
Training loss: 2.756566444275658
Validation loss: 2.0414978371842896
Epoch: 21| Step: 7
Training loss: 2.5571414465721483
Validation loss: 2.1076427950057486
Epoch: 22| Step: 0
Training loss: 2.6127660953492082
Validation loss: 2.1236729823301093
Epoch: 22| Step: 1
Training loss: 2.681097343740762
Validation loss: 2.0739498766043503
Epoch: 22| Step: 2
Training loss: 2.4098561005744874
Validation loss: 2.103176978483152
Epoch: 22| Step: 3
Training loss: 2.784832993162191
Validation loss: 2.08893150837806
Epoch: 22| Step: 4
Training loss: 2.555610140157642
Validation loss: 2.0178243112924927
Epoch: 22| Step: 5
Training loss: 2.5883129077636835
Validation loss: 2.055798635536212
Epoch: 22| Step: 6
Training loss: 2.559399007794098
Validation loss: 2.1716179782978675
Epoch: 22| Step: 7
Training loss: 2.857760614640565
Validation loss: 2.0978278074383248
Epoch: 23| Step: 0
Training loss: 2.5923218069756753
Validation loss: 1.9886410828059964
Epoch: 23| Step: 1
Training loss: 2.461332937289475
Validation loss: 2.100096667013903
Epoch: 23| Step: 2
Training loss: 2.7259641499054648
Validation loss: 2.1357266228089298
Epoch: 23| Step: 3
Training loss: 2.5514299347751352
Validation loss: 2.0561665995038676
Epoch: 23| Step: 4
Training loss: 2.391623394493809
Validation loss: 2.055503945036985
Epoch: 23| Step: 5
Training loss: 2.8764154018439068
Validation loss: 2.0983550853161277
Epoch: 23| Step: 6
Training loss: 2.4646592834412973
Validation loss: 2.0650172298146003
Epoch: 23| Step: 7
Training loss: 2.956327609118124
Validation loss: 2.08992546330383
Epoch: 24| Step: 0
Training loss: 2.5075245154143664
Validation loss: 2.1613170082033943
Epoch: 24| Step: 1
Training loss: 3.048028502603863
Validation loss: 2.1228296321269258
Epoch: 24| Step: 2
Training loss: 2.778610091022731
Validation loss: 2.1114149656592454
Epoch: 24| Step: 3
Training loss: 2.3791923664083434
Validation loss: 2.0790527558635383
Epoch: 24| Step: 4
Training loss: 2.375974154206548
Validation loss: 2.152105434429525
Epoch: 24| Step: 5
Training loss: 2.5500081454876224
Validation loss: 2.0258694174415166
Epoch: 24| Step: 6
Training loss: 2.81979982571971
Validation loss: 2.1459603689095945
Epoch: 24| Step: 7
Training loss: 2.540841661812643
Validation loss: 2.1152660518973287
Epoch: 25| Step: 0
Training loss: 2.9803829955717047
Validation loss: 2.038222280061296
Epoch: 25| Step: 1
Training loss: 2.9505668742040725
Validation loss: 2.138053533761463
Epoch: 25| Step: 2
Training loss: 2.7189622993451033
Validation loss: 2.033596997625187
Epoch: 25| Step: 3
Training loss: 2.480152981100534
Validation loss: 2.055390754282387
Epoch: 25| Step: 4
Training loss: 2.4578443676725064
Validation loss: 2.1496019445767476
Epoch: 25| Step: 5
Training loss: 2.4298810973727467
Validation loss: 2.1063337489128893
Epoch: 25| Step: 6
Training loss: 2.2968021303412147
Validation loss: 2.1121236691524743
Epoch: 25| Step: 7
Training loss: 2.6784962489158994
Validation loss: 2.139220170775371
Epoch: 26| Step: 0
Training loss: 2.691390836142818
Validation loss: 2.116586807664234
Epoch: 26| Step: 1
Training loss: 2.4969961239651384
Validation loss: 2.1622316762950002
Epoch: 26| Step: 2
Training loss: 2.5661743616699524
Validation loss: 2.135343400442332
Epoch: 26| Step: 3
Training loss: 2.675419113268167
Validation loss: 2.130147174620165
Epoch: 26| Step: 4
Training loss: 2.677290397582197
Validation loss: 2.042707332496343
Epoch: 26| Step: 5
Training loss: 2.4624162378927115
Validation loss: 2.109755257582358
Epoch: 26| Step: 6
Training loss: 2.954356103444863
Validation loss: 2.1233964588503116
Epoch: 26| Step: 7
Training loss: 2.5199137079511313
Validation loss: 2.138763150713712
Epoch: 27| Step: 0
Training loss: 2.6236055394168423
Validation loss: 2.112648832833261
Epoch: 27| Step: 1
Training loss: 2.807036624757848
Validation loss: 2.1195235333926203
Epoch: 27| Step: 2
Training loss: 2.6528638911181597
Validation loss: 2.118223130694001
Epoch: 27| Step: 3
Training loss: 2.699493173431283
Validation loss: 2.0998666007133786
Epoch: 27| Step: 4
Training loss: 2.981894215969838
Validation loss: 2.053615221299937
Epoch: 27| Step: 5
Training loss: 2.4954840881170552
Validation loss: 2.052508439845422
Epoch: 27| Step: 6
Training loss: 2.2597120273732387
Validation loss: 2.016621514279302
Epoch: 27| Step: 7
Training loss: 2.4937371963516473
Validation loss: 2.1218587516535625
Epoch: 28| Step: 0
Training loss: 2.757830309067409
Validation loss: 2.160006433422122
Epoch: 28| Step: 1
Training loss: 2.6705616182447542
Validation loss: 2.0922898361474807
Epoch: 28| Step: 2
Training loss: 2.7044808399708677
Validation loss: 2.1169627242033178
Epoch: 28| Step: 3
Training loss: 2.717115415085278
Validation loss: 2.134235674958247
Epoch: 28| Step: 4
Training loss: 2.5974159531126095
Validation loss: 2.112935226706726
Epoch: 28| Step: 5
Training loss: 2.482821668700375
Validation loss: 1.9673040954680916
Epoch: 28| Step: 6
Training loss: 2.4844684703205813
Validation loss: 2.101153751773109
Epoch: 28| Step: 7
Training loss: 2.64718093995547
Validation loss: 2.0574003346673906
Epoch: 29| Step: 0
Training loss: 2.318232056384463
Validation loss: 2.1057723123063243
Epoch: 29| Step: 1
Training loss: 2.6535122394469974
Validation loss: 2.1104957649510783
Epoch: 29| Step: 2
Training loss: 2.612772482939803
Validation loss: 2.0823615611887054
Epoch: 29| Step: 3
Training loss: 2.476534196469279
Validation loss: 2.1044451035612544
Epoch: 29| Step: 4
Training loss: 3.0000058809858534
Validation loss: 2.0938026497611566
Epoch: 29| Step: 5
Training loss: 2.510127060094489
Validation loss: 2.1102189760085737
Epoch: 29| Step: 6
Training loss: 2.557009606950158
Validation loss: 2.06819525499188
Epoch: 29| Step: 7
Training loss: 2.880987152886603
Validation loss: 2.064479118908191
Epoch: 30| Step: 0
Training loss: 2.819522313721898
Validation loss: 2.0634335106812505
Epoch: 30| Step: 1
Training loss: 2.8766962106306666
Validation loss: 2.118196234052183
Epoch: 30| Step: 2
Training loss: 2.6144719397738325
Validation loss: 2.0452636076472124
Epoch: 30| Step: 3
Training loss: 2.2210282999405844
Validation loss: 2.091797124107201
Epoch: 30| Step: 4
Training loss: 2.6121993626547546
Validation loss: 2.0833024772664053
Epoch: 30| Step: 5
Training loss: 2.659123022601364
Validation loss: 2.137619553455664
Epoch: 30| Step: 6
Training loss: 2.8099629297220905
Validation loss: 2.12465058629034
Epoch: 30| Step: 7
Training loss: 2.395253108433573
Validation loss: 2.0979841911809562
Epoch: 31| Step: 0
Training loss: 2.7853655422162937
Validation loss: 2.0783810432619014
Epoch: 31| Step: 1
Training loss: 2.7788903159520424
Validation loss: 2.0775609540041273
Epoch: 31| Step: 2
Training loss: 2.8177075812056143
Validation loss: 2.016763597068083
Epoch: 31| Step: 3
Training loss: 2.5189424994956475
Validation loss: 2.091607367934795
Epoch: 31| Step: 4
Training loss: 2.3122228507907168
Validation loss: 2.121896664440403
Epoch: 31| Step: 5
Training loss: 2.704315981590112
Validation loss: 2.098671423993908
Epoch: 31| Step: 6
Training loss: 2.294169279023815
Validation loss: 2.145341098237248
Epoch: 31| Step: 7
Training loss: 2.8005295218716686
Validation loss: 2.0915525921406948
Epoch: 32| Step: 0
Training loss: 2.5019000462448826
Validation loss: 2.1188775259743835
Epoch: 32| Step: 1
Training loss: 2.2781442900417876
Validation loss: 2.1119612416006315
Epoch: 32| Step: 2
Training loss: 2.8421180150376175
Validation loss: 2.0804119323972423
Epoch: 32| Step: 3
Training loss: 2.3057551610351825
Validation loss: 2.031005177282196
Epoch: 32| Step: 4
Training loss: 2.7099303207729943
Validation loss: 2.0555407829665264
Epoch: 32| Step: 5
Training loss: 2.8292539250696414
Validation loss: 2.0586660005958293
Epoch: 32| Step: 6
Training loss: 3.1656381710339585
Validation loss: 2.0932813946601887
Epoch: 32| Step: 7
Training loss: 2.30251962891536
Validation loss: 2.131535524061043
Epoch: 33| Step: 0
Training loss: 3.009656306316939
Validation loss: 2.129221759266751
Epoch: 33| Step: 1
Training loss: 2.845854766303283
Validation loss: 2.080201147655236
Epoch: 33| Step: 2
Training loss: 2.702652024361019
Validation loss: 2.1034172347497475
Epoch: 33| Step: 3
Training loss: 2.5109115893600316
Validation loss: 2.0909831021638925
Epoch: 33| Step: 4
Training loss: 2.252199687181117
Validation loss: 2.0862383488500296
Epoch: 33| Step: 5
Training loss: 2.5054457479954904
Validation loss: 2.070957296270345
Epoch: 33| Step: 6
Training loss: 2.5290813810830826
Validation loss: 2.0930837688528676
Epoch: 33| Step: 7
Training loss: 2.647430498545506
Validation loss: 2.031267277698559
Epoch: 34| Step: 0
Training loss: 2.54010288931245
Validation loss: 2.0991548598599237
Epoch: 34| Step: 1
Training loss: 2.6992677720030605
Validation loss: 2.131959353542555
Epoch: 34| Step: 2
Training loss: 2.620165323617882
Validation loss: 2.0983428213688797
Epoch: 34| Step: 3
Training loss: 2.9392769491432156
Validation loss: 2.052330052514314
Epoch: 34| Step: 4
Training loss: 2.9559941961414724
Validation loss: 2.1175658698083755
Epoch: 34| Step: 5
Training loss: 2.4918173392508454
Validation loss: 2.112287454030933
Epoch: 34| Step: 6
Training loss: 2.545624033747208
Validation loss: 2.080286363319795
Epoch: 34| Step: 7
Training loss: 2.203097512364538
Validation loss: 2.130383401472278
Epoch: 35| Step: 0
Training loss: 3.13982764603243
Validation loss: 2.0907277061381233
Epoch: 35| Step: 1
Training loss: 2.528074745461482
Validation loss: 2.115707728860364
Epoch: 35| Step: 2
Training loss: 2.561210493953189
Validation loss: 2.061098635500256
Epoch: 35| Step: 3
Training loss: 2.645269969726727
Validation loss: 2.091981153289312
Epoch: 35| Step: 4
Training loss: 2.6984252646676326
Validation loss: 2.0407016592998026
Epoch: 35| Step: 5
Training loss: 2.862537740267039
Validation loss: 1.956720853904392
Epoch: 35| Step: 6
Training loss: 2.2737450670185653
Validation loss: 2.0615406243394934
Epoch: 35| Step: 7
Training loss: 2.2508286963364106
Validation loss: 2.1237620248184323
Epoch: 36| Step: 0
Training loss: 2.6712942998173324
Validation loss: 2.1115472020383663
Epoch: 36| Step: 1
Training loss: 2.3919947072484073
Validation loss: 2.0878931572136294
Epoch: 36| Step: 2
Training loss: 2.7906729699397936
Validation loss: 2.0515222366656065
Epoch: 36| Step: 3
Training loss: 2.8398415671737656
Validation loss: 2.071429753284036
Epoch: 36| Step: 4
Training loss: 2.564773481453954
Validation loss: 2.1002646773465625
Epoch: 36| Step: 5
Training loss: 2.75528599149489
Validation loss: 2.1023428006086005
Epoch: 36| Step: 6
Training loss: 2.8302122391014026
Validation loss: 2.0899833435394632
Epoch: 36| Step: 7
Training loss: 2.15108878489714
Validation loss: 2.1355445130171895
Epoch: 37| Step: 0
Training loss: 2.6503326027351455
Validation loss: 2.1261136384313284
Epoch: 37| Step: 1
Training loss: 2.793846408622773
Validation loss: 2.1039843036712997
Epoch: 37| Step: 2
Training loss: 2.4866457943726408
Validation loss: 2.127487690590601
Epoch: 37| Step: 3
Training loss: 2.456306095793126
Validation loss: 2.068952812421955
Epoch: 37| Step: 4
Training loss: 2.699892790749842
Validation loss: 2.152643869772015
Epoch: 37| Step: 5
Training loss: 3.0535443208362842
Validation loss: 1.9865163181924845
Epoch: 37| Step: 6
Training loss: 2.430875726835168
Validation loss: 2.075733648825594
Epoch: 37| Step: 7
Training loss: 2.441261421485509
Validation loss: 2.1195467553599174
Epoch: 38| Step: 0
Training loss: 2.319602780702269
Validation loss: 2.117109654214704
Epoch: 38| Step: 1
Training loss: 2.3199082353136036
Validation loss: 2.1311950199117913
Epoch: 38| Step: 2
Training loss: 2.5995361868101865
Validation loss: 2.1794893448606643
Epoch: 38| Step: 3
Training loss: 2.546702279629112
Validation loss: 1.9629677812842086
Epoch: 38| Step: 4
Training loss: 3.1205064127825146
Validation loss: 2.1138925957255963
Epoch: 38| Step: 5
Training loss: 2.6941264763463755
Validation loss: 2.050483350163675
Epoch: 38| Step: 6
Training loss: 2.9534784337630797
Validation loss: 2.122896849704522
Epoch: 38| Step: 7
Training loss: 2.4122670234097683
Validation loss: 2.1095322914528576
Epoch: 39| Step: 0
Training loss: 2.4616024995919457
Validation loss: 2.073210338650626
Epoch: 39| Step: 1
Training loss: 2.662284638197331
Validation loss: 2.053556477167113
Epoch: 39| Step: 2
Training loss: 2.827014937073601
Validation loss: 2.100086576937055
Epoch: 39| Step: 3
Training loss: 2.263003285950531
Validation loss: 2.1620298086274388
Epoch: 39| Step: 4
Training loss: 2.738983804254465
Validation loss: 2.0885417053420348
Epoch: 39| Step: 5
Training loss: 2.5317231666165263
Validation loss: 2.12784881694027
Epoch: 39| Step: 6
Training loss: 2.636102358507964
Validation loss: 2.1059018163758823
Epoch: 39| Step: 7
Training loss: 2.8970639657914368
Validation loss: 2.0695724953454153
Epoch: 40| Step: 0
Training loss: 2.889788367366459
Validation loss: 2.0307157777910945
Epoch: 40| Step: 1
Training loss: 2.4216434491123806
Validation loss: 2.0849223954314535
Epoch: 40| Step: 2
Training loss: 2.7268242915263006
Validation loss: 2.0807993301180177
Epoch: 40| Step: 3
Training loss: 2.3367596968644193
Validation loss: 2.1657097003130783
Epoch: 40| Step: 4
Training loss: 2.7922868656522373
Validation loss: 2.126053663155188
Epoch: 40| Step: 5
Training loss: 2.5940321803277007
Validation loss: 2.0750500892189545
Epoch: 40| Step: 6
Training loss: 2.6086046372306684
Validation loss: 2.1051392254013233
Epoch: 40| Step: 7
Training loss: 2.6625516752144467
Validation loss: 2.0352583055080355
Epoch: 41| Step: 0
Training loss: 2.478780625577824
Validation loss: 2.0724346212450904
Epoch: 41| Step: 1
Training loss: 2.853882898485255
Validation loss: 2.079034545956942
Epoch: 41| Step: 2
Training loss: 2.822584848268957
Validation loss: 2.1139870971081787
Epoch: 41| Step: 3
Training loss: 2.290452970989995
Validation loss: 2.151086176737069
Epoch: 41| Step: 4
Training loss: 2.6270165644930468
Validation loss: 2.117381733229951
Epoch: 41| Step: 5
Training loss: 2.5873930830680894
Validation loss: 2.132396841975579
Epoch: 41| Step: 6
Training loss: 2.7443897066393395
Validation loss: 2.110588308953877
Epoch: 41| Step: 7
Training loss: 2.625819487039356
Validation loss: 2.0582036513343276
Epoch: 42| Step: 0
Training loss: 2.706576222410388
Validation loss: 2.1503582397721934
Epoch: 42| Step: 1
Training loss: 2.721620644598631
Validation loss: 2.1391941771596708
Epoch: 42| Step: 2
Training loss: 2.495017140392681
Validation loss: 2.1148976450257155
Epoch: 42| Step: 3
Training loss: 2.3939196255097785
Validation loss: 2.06523716285257
Epoch: 42| Step: 4
Training loss: 2.6415787278068046
Validation loss: 2.1045006434012414
Epoch: 42| Step: 5
Training loss: 2.8297134912182917
Validation loss: 2.131780448329702
Epoch: 42| Step: 6
Training loss: 2.6709844878734224
Validation loss: 2.0592690569991148
Epoch: 42| Step: 7
Training loss: 2.589476040013539
Validation loss: 2.155630593927303
Epoch: 43| Step: 0
Training loss: 2.80458803983422
Validation loss: 2.0797688051040835
Epoch: 43| Step: 1
Training loss: 2.497016461582026
Validation loss: 2.1499132869042197
Epoch: 43| Step: 2
Training loss: 2.5868327731777945
Validation loss: 2.1491785491757547
Epoch: 43| Step: 3
Training loss: 2.798640029879817
Validation loss: 2.1068419428184235
Epoch: 43| Step: 4
Training loss: 2.372601050424685
Validation loss: 2.0577397188784903
Epoch: 43| Step: 5
Training loss: 2.8169179337816
Validation loss: 2.129389247311963
Epoch: 43| Step: 6
Training loss: 2.61548251512532
Validation loss: 2.039832053134623
Epoch: 43| Step: 7
Training loss: 2.5467995474468514
Validation loss: 2.059722388830916
Epoch: 44| Step: 0
Training loss: 2.3801807315709045
Validation loss: 2.063714504238958
Epoch: 44| Step: 1
Training loss: 2.8600022925521094
Validation loss: 2.1251058658517263
Epoch: 44| Step: 2
Training loss: 2.7205271557863733
Validation loss: 2.0223324772511764
Epoch: 44| Step: 3
Training loss: 2.663896393281958
Validation loss: 2.1010068339583756
Epoch: 44| Step: 4
Training loss: 2.9491783290897247
Validation loss: 2.1988358182501484
Epoch: 44| Step: 5
Training loss: 2.5341586132312557
Validation loss: 2.0720093064968794
Epoch: 44| Step: 6
Training loss: 2.6991440228553425
Validation loss: 2.114563708968874
Epoch: 44| Step: 7
Training loss: 2.1836367689886966
Validation loss: 2.025297918597287
Epoch: 45| Step: 0
Training loss: 2.6014933075739033
Validation loss: 2.0861505391523276
Epoch: 45| Step: 1
Training loss: 2.57151909888331
Validation loss: 2.154999154458234
Epoch: 45| Step: 2
Training loss: 2.7292071526317527
Validation loss: 2.05351047838792
Epoch: 45| Step: 3
Training loss: 2.665082272088104
Validation loss: 2.1404514762306186
Epoch: 45| Step: 4
Training loss: 2.679516133425875
Validation loss: 2.0456409981452226
Epoch: 45| Step: 5
Training loss: 2.547804212440909
Validation loss: 2.0712818102722967
Epoch: 45| Step: 6
Training loss: 2.6016284831159417
Validation loss: 2.10680219284107
Epoch: 45| Step: 7
Training loss: 2.6832862466823255
Validation loss: 2.1235476157801445
Epoch: 46| Step: 0
Training loss: 2.6819334710707334
Validation loss: 2.0848100025026075
Epoch: 46| Step: 1
Training loss: 2.420027686662164
Validation loss: 2.1728111071468725
Epoch: 46| Step: 2
Training loss: 2.6897720668613316
Validation loss: 2.07779817364629
Epoch: 46| Step: 3
Training loss: 2.773464492881408
Validation loss: 2.0803931060427656
Epoch: 46| Step: 4
Training loss: 2.6715682004162082
Validation loss: 2.08961682482323
Epoch: 46| Step: 5
Training loss: 2.800046603632416
Validation loss: 2.052232846508419
Epoch: 46| Step: 6
Training loss: 2.646520860709058
Validation loss: 2.0884999400970883
Epoch: 46| Step: 7
Training loss: 2.358738996665046
Validation loss: 2.0431491106628505
Epoch: 47| Step: 0
Training loss: 2.3250529867717824
Validation loss: 2.119687403300892
Epoch: 47| Step: 1
Training loss: 2.5691571175241785
Validation loss: 2.1259178574363746
Epoch: 47| Step: 2
Training loss: 2.7004548925860785
Validation loss: 2.1254138445670927
Epoch: 47| Step: 3
Training loss: 2.958825155576032
Validation loss: 2.091035201712233
Epoch: 47| Step: 4
Training loss: 2.392663024641645
Validation loss: 2.137118967835507
Epoch: 47| Step: 5
Training loss: 2.830403458644809
Validation loss: 2.1133455668198025
Epoch: 47| Step: 6
Training loss: 2.53806545928878
Validation loss: 2.175809876692135
Epoch: 47| Step: 7
Training loss: 2.698474124379381
Validation loss: 2.1329776672072027
Epoch: 48| Step: 0
Training loss: 2.775668254498942
Validation loss: 2.0689668162587904
Epoch: 48| Step: 1
Training loss: 2.5902512633938484
Validation loss: 2.1066047441749114
Epoch: 48| Step: 2
Training loss: 2.7622624014607893
Validation loss: 2.072175647796611
Epoch: 48| Step: 3
Training loss: 2.434899042844782
Validation loss: 2.168983151245161
Epoch: 48| Step: 4
Training loss: 2.475102328102096
Validation loss: 2.1478908545848077
Epoch: 48| Step: 5
Training loss: 2.8680697962356323
Validation loss: 2.1311124526743908
Epoch: 48| Step: 6
Training loss: 2.6511753750540934
Validation loss: 2.071389109761683
Epoch: 48| Step: 7
Training loss: 2.487742127562564
Validation loss: 2.0773927811874313
Epoch: 49| Step: 0
Training loss: 2.561832713261841
Validation loss: 2.093951962487472
Epoch: 49| Step: 1
Training loss: 2.6636705753509533
Validation loss: 2.0976463712921514
Epoch: 49| Step: 2
Training loss: 2.9579908862279836
Validation loss: 2.057221770834081
Epoch: 49| Step: 3
Training loss: 2.758438601218652
Validation loss: 2.063052936471308
Epoch: 49| Step: 4
Training loss: 2.8086994347564187
Validation loss: 2.118489056407352
Epoch: 49| Step: 5
Training loss: 2.1582653192042525
Validation loss: 2.09604758351738
Epoch: 49| Step: 6
Training loss: 2.659707635142866
Validation loss: 2.128513273525886
Epoch: 49| Step: 7
Training loss: 2.4260600693035994
Validation loss: 2.129963203479844
Epoch: 50| Step: 0
Training loss: 2.986786991091157
Validation loss: 2.1448771454678983
Epoch: 50| Step: 1
Training loss: 2.2768642123498477
Validation loss: 2.1186080513915684
Epoch: 50| Step: 2
Training loss: 3.106104064829099
Validation loss: 2.0861138138277218
Epoch: 50| Step: 3
Training loss: 2.5918449851589322
Validation loss: 2.0749937039653545
Epoch: 50| Step: 4
Training loss: 2.6853771253169976
Validation loss: 2.142081385431443
Epoch: 50| Step: 5
Training loss: 2.3748375686513863
Validation loss: 2.12687173364182
Epoch: 50| Step: 6
Training loss: 2.446221715795772
Validation loss: 2.1256404770501973
Epoch: 50| Step: 7
Training loss: 2.4947946717012552
Validation loss: 2.106380420399614
