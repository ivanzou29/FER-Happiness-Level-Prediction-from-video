Epoch: 1| Step: 0
Training loss: 5.936208484124542
Validation loss: 5.280511097193704
Epoch: 1| Step: 1
Training loss: 5.012422388860071
Validation loss: 5.243275209162338
Epoch: 1| Step: 2
Training loss: 5.209061818357104
Validation loss: 5.171007681553908
Epoch: 1| Step: 3
Training loss: 5.2855773893325075
Validation loss: 5.088814524090333
Epoch: 1| Step: 4
Training loss: 6.365009632807512
Validation loss: 5.18274352030468
Epoch: 1| Step: 5
Training loss: 5.975499037328781
Validation loss: 5.046892069470346
Epoch: 1| Step: 6
Training loss: 5.670923915179767
Validation loss: 5.036040260625605
Epoch: 1| Step: 7
Training loss: 4.4656203187847225
Validation loss: 4.981472750433629
Epoch: 1| Step: 8
Training loss: 5.498436965790593
Validation loss: 4.957866913145938
Epoch: 1| Step: 9
Training loss: 5.025206543582469
Validation loss: 4.89671795698073
Epoch: 2| Step: 0
Training loss: 5.270286602066336
Validation loss: 4.79608911681431
Epoch: 2| Step: 1
Training loss: 5.053682725615699
Validation loss: 4.8531047167658565
Epoch: 2| Step: 2
Training loss: 5.796917115749975
Validation loss: 4.693188070233891
Epoch: 2| Step: 3
Training loss: 4.746425287417174
Validation loss: 4.802623972979
Epoch: 2| Step: 4
Training loss: 5.018693882306606
Validation loss: 4.77453445996443
Epoch: 2| Step: 5
Training loss: 4.593403498238733
Validation loss: 4.553251210104188
Epoch: 2| Step: 6
Training loss: 5.150366553437301
Validation loss: 4.542877715419779
Epoch: 2| Step: 7
Training loss: 4.743811943443874
Validation loss: 4.542769591537845
Epoch: 2| Step: 8
Training loss: 5.310814803373623
Validation loss: 4.605958047029402
Epoch: 2| Step: 9
Training loss: 4.981412096628869
Validation loss: 4.5861201957137325
Epoch: 3| Step: 0
Training loss: 4.392123038064182
Validation loss: 4.501215825243313
Epoch: 3| Step: 1
Training loss: 4.669535073247975
Validation loss: 4.461692314865489
Epoch: 3| Step: 2
Training loss: 4.676047410775193
Validation loss: 4.466073493131151
Epoch: 3| Step: 3
Training loss: 4.897670558045079
Validation loss: 4.310120751303009
Epoch: 3| Step: 4
Training loss: 4.852077880611716
Validation loss: 4.365937216284678
Epoch: 3| Step: 5
Training loss: 5.1028499643619805
Validation loss: 4.402389956985995
Epoch: 3| Step: 6
Training loss: 5.132343706295951
Validation loss: 4.336060629118312
Epoch: 3| Step: 7
Training loss: 4.898375198965852
Validation loss: 4.270290351364739
Epoch: 3| Step: 8
Training loss: 4.025948994282643
Validation loss: 4.240283976496639
Epoch: 3| Step: 9
Training loss: 4.8182180543979705
Validation loss: 4.248283232007256
Epoch: 4| Step: 0
Training loss: 4.3530814295311435
Validation loss: 4.279618863448271
Epoch: 4| Step: 1
Training loss: 4.637518359865106
Validation loss: 4.10213389263158
Epoch: 4| Step: 2
Training loss: 3.8791889806010738
Validation loss: 4.071753091285266
Epoch: 4| Step: 3
Training loss: 5.115310068287802
Validation loss: 4.183216396321938
Epoch: 4| Step: 4
Training loss: 4.0302655104644
Validation loss: 4.078416305952991
Epoch: 4| Step: 5
Training loss: 4.764434165382052
Validation loss: 4.089891335452218
Epoch: 4| Step: 6
Training loss: 4.600286491428839
Validation loss: 3.962341151480438
Epoch: 4| Step: 7
Training loss: 4.166070107033576
Validation loss: 4.050819776124556
Epoch: 4| Step: 8
Training loss: 4.453860359377029
Validation loss: 3.9251205137102256
Epoch: 4| Step: 9
Training loss: 4.563437796586629
Validation loss: 3.933677295798224
Epoch: 5| Step: 0
Training loss: 4.340640485061696
Validation loss: 3.8459408321189126
Epoch: 5| Step: 1
Training loss: 4.347506428867915
Validation loss: 3.8900218850520045
Epoch: 5| Step: 2
Training loss: 4.0229015400762
Validation loss: 3.882714671089611
Epoch: 5| Step: 3
Training loss: 4.322490894844169
Validation loss: 3.83828186875008
Epoch: 5| Step: 4
Training loss: 4.175865750577442
Validation loss: 3.7686387288603234
Epoch: 5| Step: 5
Training loss: 3.9601592553993332
Validation loss: 3.666880001992478
Epoch: 5| Step: 6
Training loss: 4.2973960976636585
Validation loss: 3.671998621448549
Epoch: 5| Step: 7
Training loss: 4.454253900219114
Validation loss: 3.7463124394042913
Epoch: 5| Step: 8
Training loss: 4.009260901167797
Validation loss: 3.684309628704163
Epoch: 5| Step: 9
Training loss: 4.097898288847857
Validation loss: 3.6465239034436276
Epoch: 6| Step: 0
Training loss: 4.054781580074243
Validation loss: 3.613696622734276
Epoch: 6| Step: 1
Training loss: 3.7736647006361266
Validation loss: 3.666868825759924
Epoch: 6| Step: 2
Training loss: 4.124520938682796
Validation loss: 3.586492393911908
Epoch: 6| Step: 3
Training loss: 4.162243186199534
Validation loss: 3.556649080987575
Epoch: 6| Step: 4
Training loss: 4.570265758307989
Validation loss: 3.503632434263138
Epoch: 6| Step: 5
Training loss: 3.3810111308734023
Validation loss: 3.4702577241659163
Epoch: 6| Step: 6
Training loss: 3.5177516354347014
Validation loss: 3.4821712548804094
Epoch: 6| Step: 7
Training loss: 4.542556022336373
Validation loss: 3.4931561778056137
Epoch: 6| Step: 8
Training loss: 3.592021493282456
Validation loss: 3.4155314136504944
Epoch: 6| Step: 9
Training loss: 3.832820208386625
Validation loss: 3.5108624089691203
Epoch: 7| Step: 0
Training loss: 3.9288395901598627
Validation loss: 3.38600442767681
Epoch: 7| Step: 1
Training loss: 3.5396470688142254
Validation loss: 3.4467276819855512
Epoch: 7| Step: 2
Training loss: 3.8134853152908517
Validation loss: 3.4089734463970918
Epoch: 7| Step: 3
Training loss: 3.5120867068594737
Validation loss: 3.290670955402997
Epoch: 7| Step: 4
Training loss: 3.2765397914668943
Validation loss: 3.3255282909750523
Epoch: 7| Step: 5
Training loss: 3.8819292932956637
Validation loss: 3.2680618238993406
Epoch: 7| Step: 6
Training loss: 3.6692667036752993
Validation loss: 3.2641497845441996
Epoch: 7| Step: 7
Training loss: 4.118430715408138
Validation loss: 3.272139328367445
Epoch: 7| Step: 8
Training loss: 4.333938385219601
Validation loss: 3.2596531308416345
Epoch: 7| Step: 9
Training loss: 3.5314451180624635
Validation loss: 3.1925857375554916
Epoch: 8| Step: 0
Training loss: 3.7848215181505416
Validation loss: 3.0977760655570012
Epoch: 8| Step: 1
Training loss: 3.2679840766023873
Validation loss: 3.279719164019047
Epoch: 8| Step: 2
Training loss: 3.5627187025967975
Validation loss: 3.2118629916086334
Epoch: 8| Step: 3
Training loss: 3.7158378931499345
Validation loss: 3.244255378896072
Epoch: 8| Step: 4
Training loss: 3.835594394978824
Validation loss: 3.149589843571575
Epoch: 8| Step: 5
Training loss: 3.5750140529969916
Validation loss: 3.05597418151815
Epoch: 8| Step: 6
Training loss: 3.317919490368606
Validation loss: 3.118363127632214
Epoch: 8| Step: 7
Training loss: 3.6410210520893465
Validation loss: 3.061909619225292
Epoch: 8| Step: 8
Training loss: 3.1969706143486505
Validation loss: 3.0767407523829373
Epoch: 8| Step: 9
Training loss: 3.7732201428729324
Validation loss: 2.9691113096240698
Epoch: 9| Step: 0
Training loss: 3.405353673192605
Validation loss: 2.992220590456028
Epoch: 9| Step: 1
Training loss: 3.3248015093534713
Validation loss: 3.0201000564456075
Epoch: 9| Step: 2
Training loss: 3.0495703097480273
Validation loss: 3.022290813167827
Epoch: 9| Step: 3
Training loss: 3.800444004822208
Validation loss: 3.0171861995610714
Epoch: 9| Step: 4
Training loss: 4.0719302544756895
Validation loss: 2.924197212144193
Epoch: 9| Step: 5
Training loss: 3.2288674164621285
Validation loss: 2.9390480664756113
Epoch: 9| Step: 6
Training loss: 3.429133550793799
Validation loss: 2.9371878505329416
Epoch: 9| Step: 7
Training loss: 3.396959706981302
Validation loss: 2.939646984537382
Epoch: 9| Step: 8
Training loss: 3.5418263268479473
Validation loss: 2.832574017074874
Epoch: 9| Step: 9
Training loss: 2.963519819790318
Validation loss: 2.91763425780743
Epoch: 10| Step: 0
Training loss: 3.542331558347227
Validation loss: 2.7940436905961192
Epoch: 10| Step: 1
Training loss: 3.1595257671239394
Validation loss: 2.9265067688389346
Epoch: 10| Step: 2
Training loss: 3.186620703196802
Validation loss: 2.7927358811640466
Epoch: 10| Step: 3
Training loss: 3.3089793947695965
Validation loss: 2.7402181544116417
Epoch: 10| Step: 4
Training loss: 3.0715664930838704
Validation loss: 2.7809941874910398
Epoch: 10| Step: 5
Training loss: 3.007155150876062
Validation loss: 2.8286134335573503
Epoch: 10| Step: 6
Training loss: 3.3764535105219236
Validation loss: 2.8111412790363017
Epoch: 10| Step: 7
Training loss: 3.2002246658613367
Validation loss: 2.7894267269029744
Epoch: 10| Step: 8
Training loss: 3.411827770157124
Validation loss: 2.745238759382572
Epoch: 10| Step: 9
Training loss: 3.6330521699334306
Validation loss: 2.7249357462799604
Epoch: 11| Step: 0
Training loss: 3.294248284826898
Validation loss: 2.6902897359075024
Epoch: 11| Step: 1
Training loss: 2.8425890889964798
Validation loss: 2.695040557345757
Epoch: 11| Step: 2
Training loss: 3.065583836768113
Validation loss: 2.70008066365365
Epoch: 11| Step: 3
Training loss: 3.2434623693638702
Validation loss: 2.6338574907919234
Epoch: 11| Step: 4
Training loss: 2.8514937719136277
Validation loss: 2.6934147934295036
Epoch: 11| Step: 5
Training loss: 3.0671790054366896
Validation loss: 2.6797864747017095
Epoch: 11| Step: 6
Training loss: 3.4433608982820654
Validation loss: 2.601804037915035
Epoch: 11| Step: 7
Training loss: 3.3536866754844255
Validation loss: 2.6193708638614552
Epoch: 11| Step: 8
Training loss: 3.454069120703954
Validation loss: 2.590560434415361
Epoch: 11| Step: 9
Training loss: 3.2670229607211065
Validation loss: 2.6447174149815638
Epoch: 12| Step: 0
Training loss: 2.851838900613299
Validation loss: 2.6118117579313926
Epoch: 12| Step: 1
Training loss: 3.0925151788189473
Validation loss: 2.5950697986137308
Epoch: 12| Step: 2
Training loss: 3.0067090673339814
Validation loss: 2.4574395184780533
Epoch: 12| Step: 3
Training loss: 2.912579279135759
Validation loss: 2.5728207742915448
Epoch: 12| Step: 4
Training loss: 3.236406213696561
Validation loss: 2.6460759145182484
Epoch: 12| Step: 5
Training loss: 3.094254423692014
Validation loss: 2.6053481981082696
Epoch: 12| Step: 6
Training loss: 2.924999341394073
Validation loss: 2.5886402288719315
Epoch: 12| Step: 7
Training loss: 3.560214597899017
Validation loss: 2.5584965338886327
Epoch: 12| Step: 8
Training loss: 3.02432718912809
Validation loss: 2.536019829274043
Epoch: 12| Step: 9
Training loss: 2.9609265490810026
Validation loss: 2.517928146816158
Epoch: 13| Step: 0
Training loss: 3.159223157061831
Validation loss: 2.4813833635345484
Epoch: 13| Step: 1
Training loss: 2.888774547596406
Validation loss: 2.421141440957872
Epoch: 13| Step: 2
Training loss: 3.165278749650381
Validation loss: 2.4995999665324535
Epoch: 13| Step: 3
Training loss: 2.8543279746107504
Validation loss: 2.458367508492087
Epoch: 13| Step: 4
Training loss: 3.0433017220444847
Validation loss: 2.453476124662062
Epoch: 13| Step: 5
Training loss: 2.987473242731656
Validation loss: 2.4587005126397115
Epoch: 13| Step: 6
Training loss: 3.081178341664846
Validation loss: 2.496528941541938
Epoch: 13| Step: 7
Training loss: 3.0119576563499395
Validation loss: 2.4235331938695235
Epoch: 13| Step: 8
Training loss: 3.004155618662278
Validation loss: 2.444351530156311
Epoch: 13| Step: 9
Training loss: 2.6325236085592056
Validation loss: 2.383499288507239
Epoch: 14| Step: 0
Training loss: 2.7169534293947697
Validation loss: 2.33120608658875
Epoch: 14| Step: 1
Training loss: 3.0049416849631703
Validation loss: 2.3524025315583406
Epoch: 14| Step: 2
Training loss: 3.5006141123834773
Validation loss: 2.527532069036672
Epoch: 14| Step: 3
Training loss: 2.9012646318335427
Validation loss: 2.348531450776803
Epoch: 14| Step: 4
Training loss: 2.7589776276818245
Validation loss: 2.3067371451678107
Epoch: 14| Step: 5
Training loss: 2.5429132458420414
Validation loss: 2.3523597366371156
Epoch: 14| Step: 6
Training loss: 2.9769597626959854
Validation loss: 2.4046487129402716
Epoch: 14| Step: 7
Training loss: 2.542928715872706
Validation loss: 2.3301431011711524
Epoch: 14| Step: 8
Training loss: 2.954551392662643
Validation loss: 2.308223156351274
Epoch: 14| Step: 9
Training loss: 3.163116539727312
Validation loss: 2.2780445762981545
Epoch: 15| Step: 0
Training loss: 3.0282111912478675
Validation loss: 2.3121246959119777
Epoch: 15| Step: 1
Training loss: 3.0330298792483212
Validation loss: 2.296922177621475
Epoch: 15| Step: 2
Training loss: 2.5920983076702933
Validation loss: 2.216625014037878
Epoch: 15| Step: 3
Training loss: 3.2398227386492384
Validation loss: 2.364572788219702
Epoch: 15| Step: 4
Training loss: 2.8709045763039
Validation loss: 2.3485829143257018
Epoch: 15| Step: 5
Training loss: 2.7834363766020505
Validation loss: 2.2461158226099163
Epoch: 15| Step: 6
Training loss: 2.8921181611209703
Validation loss: 2.296360652779519
Epoch: 15| Step: 7
Training loss: 2.376317512078908
Validation loss: 2.273452632780944
Epoch: 15| Step: 8
Training loss: 2.97205995451471
Validation loss: 2.28864342553812
Epoch: 15| Step: 9
Training loss: 2.727862466281746
Validation loss: 2.357467157275773
Epoch: 16| Step: 0
Training loss: 2.8915321370106253
Validation loss: 2.2687318421639078
Epoch: 16| Step: 1
Training loss: 2.779195562514615
Validation loss: 2.34814625271943
Epoch: 16| Step: 2
Training loss: 2.5901401632080603
Validation loss: 2.297051878942697
Epoch: 16| Step: 3
Training loss: 2.795033109465398
Validation loss: 2.3153726050645522
Epoch: 16| Step: 4
Training loss: 2.3518619790224897
Validation loss: 2.2062169953344304
Epoch: 16| Step: 5
Training loss: 2.9057165497166726
Validation loss: 2.280715783489686
Epoch: 16| Step: 6
Training loss: 2.9811722911247713
Validation loss: 2.2309137219743125
Epoch: 16| Step: 7
Training loss: 2.811952749628592
Validation loss: 2.2920102205070885
Epoch: 16| Step: 8
Training loss: 3.1530667105845516
Validation loss: 2.2746389782201772
Epoch: 16| Step: 9
Training loss: 2.5516545668634247
Validation loss: 2.247716129071245
Epoch: 17| Step: 0
Training loss: 2.827096741620405
Validation loss: 2.2449296003674224
Epoch: 17| Step: 1
Training loss: 2.6658326473952667
Validation loss: 2.186573443496379
Epoch: 17| Step: 2
Training loss: 2.9051729893349596
Validation loss: 2.296859628722126
Epoch: 17| Step: 3
Training loss: 2.6135168040676615
Validation loss: 2.29493855915571
Epoch: 17| Step: 4
Training loss: 3.0539003416537565
Validation loss: 2.1117224114621496
Epoch: 17| Step: 5
Training loss: 2.800424720704523
Validation loss: 2.2587743289490154
Epoch: 17| Step: 6
Training loss: 2.7968228297988738
Validation loss: 2.235518452325428
Epoch: 17| Step: 7
Training loss: 3.001472906297635
Validation loss: 2.248425640036441
Epoch: 17| Step: 8
Training loss: 2.630777268519716
Validation loss: 2.2207892258098516
Epoch: 17| Step: 9
Training loss: 2.7578495876855067
Validation loss: 2.245191208500909
Epoch: 18| Step: 0
Training loss: 2.7737093080386934
Validation loss: 2.2205588404041388
Epoch: 18| Step: 1
Training loss: 3.0971848657138996
Validation loss: 2.249127181148547
Epoch: 18| Step: 2
Training loss: 2.4263364982614037
Validation loss: 2.268823943535501
Epoch: 18| Step: 3
Training loss: 2.6370731821968305
Validation loss: 2.1685319379997314
Epoch: 18| Step: 4
Training loss: 2.983315004970859
Validation loss: 2.1457723850007953
Epoch: 18| Step: 5
Training loss: 2.7344067380970567
Validation loss: 2.182640672975243
Epoch: 18| Step: 6
Training loss: 2.5700137999642796
Validation loss: 2.15591563888387
Epoch: 18| Step: 7
Training loss: 2.7375970657767663
Validation loss: 2.1876733021615142
Epoch: 18| Step: 8
Training loss: 3.0468870505070194
Validation loss: 2.198208887738716
Epoch: 18| Step: 9
Training loss: 2.5305545934830462
Validation loss: 2.2160953790198965
Epoch: 19| Step: 0
Training loss: 2.5527676242335415
Validation loss: 2.182993658153887
Epoch: 19| Step: 1
Training loss: 2.6292410604729928
Validation loss: 2.2606817471028893
Epoch: 19| Step: 2
Training loss: 2.5422082751268698
Validation loss: 2.177347840337948
Epoch: 19| Step: 3
Training loss: 2.9694805651772387
Validation loss: 2.148232129558016
Epoch: 19| Step: 4
Training loss: 2.860564104481773
Validation loss: 2.231897658035269
Epoch: 19| Step: 5
Training loss: 2.714901710824625
Validation loss: 2.1636426756698905
Epoch: 19| Step: 6
Training loss: 2.3503698828962607
Validation loss: 2.2098762487282144
Epoch: 19| Step: 7
Training loss: 2.719220964702337
Validation loss: 2.160808313733787
Epoch: 19| Step: 8
Training loss: 2.6713772137151546
Validation loss: 2.2492364995150753
Epoch: 19| Step: 9
Training loss: 3.149392714317181
Validation loss: 2.1034438754518936
Epoch: 20| Step: 0
Training loss: 2.883096324315787
Validation loss: 2.222418463620918
Epoch: 20| Step: 1
Training loss: 2.8210908867043156
Validation loss: 2.181213946428257
Epoch: 20| Step: 2
Training loss: 2.8795549549516197
Validation loss: 2.138640624333812
Epoch: 20| Step: 3
Training loss: 2.7259671236156175
Validation loss: 2.1943922106505087
Epoch: 20| Step: 4
Training loss: 2.6255479876423125
Validation loss: 2.2266233286356303
Epoch: 20| Step: 5
Training loss: 2.364729609285281
Validation loss: 2.155514654863995
Epoch: 20| Step: 6
Training loss: 2.7391383071915283
Validation loss: 2.0960381483086366
Epoch: 20| Step: 7
Training loss: 2.286767531729262
Validation loss: 2.117383987393501
Epoch: 20| Step: 8
Training loss: 2.7769168144682186
Validation loss: 2.0588730481282718
Epoch: 20| Step: 9
Training loss: 2.8673133926401855
Validation loss: 2.1656342959155093
Epoch: 21| Step: 0
Training loss: 2.6957489102649794
Validation loss: 2.077303216608079
Epoch: 21| Step: 1
Training loss: 2.9285528401705334
Validation loss: 2.2147709746767856
Epoch: 21| Step: 2
Training loss: 2.8969159926854555
Validation loss: 2.168039822881548
Epoch: 21| Step: 3
Training loss: 2.465165058358895
Validation loss: 2.2022897354581197
Epoch: 21| Step: 4
Training loss: 1.9613162583001835
Validation loss: 2.1842286645046696
Epoch: 21| Step: 5
Training loss: 2.7622479008737337
Validation loss: 2.104842202550587
Epoch: 21| Step: 6
Training loss: 2.9317043838836176
Validation loss: 2.2806628903939092
Epoch: 21| Step: 7
Training loss: 2.7910578239352715
Validation loss: 2.120165379337897
Epoch: 21| Step: 8
Training loss: 2.5039081543723256
Validation loss: 2.1162661347821397
Epoch: 21| Step: 9
Training loss: 2.703901058215183
Validation loss: 2.168857440604764
Epoch: 22| Step: 0
Training loss: 2.655804405984499
Validation loss: 2.111973191281144
Epoch: 22| Step: 1
Training loss: 2.8125084770922593
Validation loss: 2.141666499420063
Epoch: 22| Step: 2
Training loss: 2.663296318067524
Validation loss: 2.121679250308559
Epoch: 22| Step: 3
Training loss: 3.0690138693676663
Validation loss: 2.1695290421200375
Epoch: 22| Step: 4
Training loss: 2.4088690240075317
Validation loss: 2.1355848229451375
Epoch: 22| Step: 5
Training loss: 2.9022796747006763
Validation loss: 2.152712801070932
Epoch: 22| Step: 6
Training loss: 2.97709751076834
Validation loss: 2.1386024411240947
Epoch: 22| Step: 7
Training loss: 2.5556470836152654
Validation loss: 2.181444304443932
Epoch: 22| Step: 8
Training loss: 2.471476630555523
Validation loss: 2.1704512600058825
Epoch: 22| Step: 9
Training loss: 2.7426265354227826
Validation loss: 2.126494590554446
Epoch: 23| Step: 0
Training loss: 2.63973397113895
Validation loss: 2.1517481240195084
Epoch: 23| Step: 1
Training loss: 2.611968436303098
Validation loss: 2.0984803988359544
Epoch: 23| Step: 2
Training loss: 2.60779052871399
Validation loss: 2.023271571794675
Epoch: 23| Step: 3
Training loss: 2.3876106356406432
Validation loss: 2.1470094145623912
Epoch: 23| Step: 4
Training loss: 2.576955079012447
Validation loss: 2.159432162244393
Epoch: 23| Step: 5
Training loss: 2.7915760329228205
Validation loss: 2.2089478480761677
Epoch: 23| Step: 6
Training loss: 2.520038405837207
Validation loss: 2.179272711727192
Epoch: 23| Step: 7
Training loss: 2.914545014142916
Validation loss: 2.125153438477607
Epoch: 23| Step: 8
Training loss: 2.6428739462506083
Validation loss: 2.1840339109980835
Epoch: 23| Step: 9
Training loss: 2.508212333962907
Validation loss: 2.1249181985868058
Epoch: 24| Step: 0
Training loss: 2.1995259641245224
Validation loss: 2.1127472608298774
Epoch: 24| Step: 1
Training loss: 2.965617886726684
Validation loss: 2.0238030253825925
Epoch: 24| Step: 2
Training loss: 2.720910189732399
Validation loss: 2.228363584997517
Epoch: 24| Step: 3
Training loss: 2.4121924999910225
Validation loss: 2.100954323733572
Epoch: 24| Step: 4
Training loss: 2.6696319980828798
Validation loss: 2.1035556991128064
Epoch: 24| Step: 5
Training loss: 2.7188047206238846
Validation loss: 2.1512616009855874
Epoch: 24| Step: 6
Training loss: 2.6987547192658177
Validation loss: 2.0317282389842797
Epoch: 24| Step: 7
Training loss: 2.84359405425348
Validation loss: 2.1590872810875035
Epoch: 24| Step: 8
Training loss: 2.540078297406993
Validation loss: 2.1167394767449164
Epoch: 24| Step: 9
Training loss: 2.872291948106294
Validation loss: 2.186775428099893
Epoch: 25| Step: 0
Training loss: 2.842831641505237
Validation loss: 2.1834530916178916
Epoch: 25| Step: 1
Training loss: 2.9215138258038063
Validation loss: 2.1775732982316565
Epoch: 25| Step: 2
Training loss: 3.0123222330281507
Validation loss: 2.0980984960726294
Epoch: 25| Step: 3
Training loss: 2.510590057927587
Validation loss: 2.0365518654210892
Epoch: 25| Step: 4
Training loss: 2.465094261920588
Validation loss: 2.0799515721197923
Epoch: 25| Step: 5
Training loss: 2.1716625740947597
Validation loss: 2.0805672439032765
Epoch: 25| Step: 6
Training loss: 2.6082035564601074
Validation loss: 2.1860826790235293
Epoch: 25| Step: 7
Training loss: 2.6518755627374637
Validation loss: 2.1570030813084062
Epoch: 25| Step: 8
Training loss: 2.825872208974616
Validation loss: 2.0450127919651746
Epoch: 25| Step: 9
Training loss: 2.8255893868891815
Validation loss: 2.1922636219084746
Epoch: 26| Step: 0
Training loss: 1.8772277313590113
Validation loss: 2.1275074536001766
Epoch: 26| Step: 1
Training loss: 2.5871614170153494
Validation loss: 2.1409045254109293
Epoch: 26| Step: 2
Training loss: 2.6407378584541013
Validation loss: 2.1095440665931315
Epoch: 26| Step: 3
Training loss: 2.5976551486134882
Validation loss: 2.2036334962396236
Epoch: 26| Step: 4
Training loss: 2.646243646800578
Validation loss: 2.1251072894993044
Epoch: 26| Step: 5
Training loss: 2.9585366694099235
Validation loss: 2.049018883737254
Epoch: 26| Step: 6
Training loss: 2.7564809897030376
Validation loss: 2.138303280373421
Epoch: 26| Step: 7
Training loss: 2.799286213220762
Validation loss: 2.071796194938309
Epoch: 26| Step: 8
Training loss: 2.9782139959977743
Validation loss: 2.0989019172331536
Epoch: 26| Step: 9
Training loss: 2.864273794385177
Validation loss: 2.1577770822787308
Epoch: 27| Step: 0
Training loss: 2.647963579924291
Validation loss: 2.016119743354077
Epoch: 27| Step: 1
Training loss: 2.8687261044373464
Validation loss: 2.011645222194525
Epoch: 27| Step: 2
Training loss: 2.665977170338507
Validation loss: 2.1019537770889136
Epoch: 27| Step: 3
Training loss: 2.726289576995719
Validation loss: 2.1547849786613167
Epoch: 27| Step: 4
Training loss: 2.463883444134835
Validation loss: 2.1291735089241737
Epoch: 27| Step: 5
Training loss: 2.692990040508202
Validation loss: 2.0689520176090954
Epoch: 27| Step: 6
Training loss: 2.7259502433943417
Validation loss: 2.1550130899343443
Epoch: 27| Step: 7
Training loss: 2.365234274198749
Validation loss: 2.0937592901569495
Epoch: 27| Step: 8
Training loss: 2.517807292348119
Validation loss: 2.1700799499333394
Epoch: 27| Step: 9
Training loss: 2.9085733294634695
Validation loss: 2.215034244824202
Epoch: 28| Step: 0
Training loss: 2.57445491465766
Validation loss: 2.1338866599034607
Epoch: 28| Step: 1
Training loss: 2.7736260148574807
Validation loss: 2.209173892087509
Epoch: 28| Step: 2
Training loss: 2.429569744433447
Validation loss: 2.1413819825427627
Epoch: 28| Step: 3
Training loss: 2.7460228163347096
Validation loss: 2.1500900871804447
Epoch: 28| Step: 4
Training loss: 2.721568258281402
Validation loss: 2.1203565742533947
Epoch: 28| Step: 5
Training loss: 2.7534352434093012
Validation loss: 2.1279538783046137
Epoch: 28| Step: 6
Training loss: 2.8091232373699686
Validation loss: 2.1034379746883145
Epoch: 28| Step: 7
Training loss: 2.5803848996746104
Validation loss: 2.102699925194304
Epoch: 28| Step: 8
Training loss: 2.612754415143164
Validation loss: 2.172650311886729
Epoch: 28| Step: 9
Training loss: 2.8355653797160176
Validation loss: 2.1368693690698155
Epoch: 29| Step: 0
Training loss: 2.610211723626454
Validation loss: 2.196769802222989
Epoch: 29| Step: 1
Training loss: 3.023230888147936
Validation loss: 2.137311666934216
Epoch: 29| Step: 2
Training loss: 2.620290346000796
Validation loss: 2.1204464849479043
Epoch: 29| Step: 3
Training loss: 2.9519903031476797
Validation loss: 2.126404849356549
Epoch: 29| Step: 4
Training loss: 2.2377163105835405
Validation loss: 2.158656021152988
Epoch: 29| Step: 5
Training loss: 2.467714696199376
Validation loss: 2.1279080549060128
Epoch: 29| Step: 6
Training loss: 2.568318158533352
Validation loss: 2.117481662944197
Epoch: 29| Step: 7
Training loss: 2.498659537482634
Validation loss: 2.1589523222421114
Epoch: 29| Step: 8
Training loss: 2.7626457762769125
Validation loss: 2.2097186156610236
Epoch: 29| Step: 9
Training loss: 2.6616953963813508
Validation loss: 2.014440404747435
Epoch: 30| Step: 0
Training loss: 2.713494054531587
Validation loss: 2.0666448857525186
Epoch: 30| Step: 1
Training loss: 2.5580796984797822
Validation loss: 2.2005722251870807
Epoch: 30| Step: 2
Training loss: 2.8142081265892083
Validation loss: 2.123815856841782
Epoch: 30| Step: 3
Training loss: 2.621647555974174
Validation loss: 2.127146256256483
Epoch: 30| Step: 4
Training loss: 2.648260510137404
Validation loss: 2.1773841507402714
Epoch: 30| Step: 5
Training loss: 2.424552864459716
Validation loss: 2.070053870922937
Epoch: 30| Step: 6
Training loss: 2.650234726640779
Validation loss: 2.0826367675043116
Epoch: 30| Step: 7
Training loss: 2.752810515889018
Validation loss: 2.062970006338502
Epoch: 30| Step: 8
Training loss: 2.4048132632399315
Validation loss: 2.1716655993112584
Epoch: 30| Step: 9
Training loss: 2.9348145242082855
Validation loss: 2.0759436445045703
Epoch: 31| Step: 0
Training loss: 2.668602707525797
Validation loss: 2.076754820054447
Epoch: 31| Step: 1
Training loss: 2.7335555238277793
Validation loss: 2.159717162880471
Epoch: 31| Step: 2
Training loss: 2.491383389941964
Validation loss: 2.192503136206962
Epoch: 31| Step: 3
Training loss: 2.916125020187203
Validation loss: 2.111837000158889
Epoch: 31| Step: 4
Training loss: 2.7070194480825887
Validation loss: 2.1458561157473808
Epoch: 31| Step: 5
Training loss: 2.331388503145732
Validation loss: 2.1130154567967545
Epoch: 31| Step: 6
Training loss: 2.561643317700882
Validation loss: 2.075739423356261
Epoch: 31| Step: 7
Training loss: 2.49465208253755
Validation loss: 2.137790707879279
Epoch: 31| Step: 8
Training loss: 2.5381906743912386
Validation loss: 2.121965173482911
Epoch: 31| Step: 9
Training loss: 2.744087017798229
Validation loss: 2.1137341136572814
Epoch: 32| Step: 0
Training loss: 2.5072868960981913
Validation loss: 2.1698113216663337
Epoch: 32| Step: 1
Training loss: 2.4878578963712177
Validation loss: 2.1106415167882413
Epoch: 32| Step: 2
Training loss: 2.5437106267707774
Validation loss: 2.0460397534410593
Epoch: 32| Step: 3
Training loss: 2.788762950037867
Validation loss: 2.1038681465225166
Epoch: 32| Step: 4
Training loss: 2.7618078408985713
Validation loss: 2.124126138227127
Epoch: 32| Step: 5
Training loss: 2.9468831293796938
Validation loss: 2.115863677419282
Epoch: 32| Step: 6
Training loss: 2.3871967942004115
Validation loss: 2.1167260551214246
Epoch: 32| Step: 7
Training loss: 2.477254488084858
Validation loss: 2.1795371921595805
Epoch: 32| Step: 8
Training loss: 2.765964982854438
Validation loss: 2.056619505418094
Epoch: 32| Step: 9
Training loss: 2.7420116922475666
Validation loss: 2.1336663380336596
Epoch: 33| Step: 0
Training loss: 3.0843313165757915
Validation loss: 2.165060160862299
Epoch: 33| Step: 1
Training loss: 2.6907204251087498
Validation loss: 2.1901950855418333
Epoch: 33| Step: 2
Training loss: 2.7140225053386833
Validation loss: 2.0752178366815874
Epoch: 33| Step: 3
Training loss: 2.709774944349334
Validation loss: 2.180030124066677
Epoch: 33| Step: 4
Training loss: 2.6505036972990155
Validation loss: 2.0964621042430727
Epoch: 33| Step: 5
Training loss: 2.857513655715846
Validation loss: 2.205625826411397
Epoch: 33| Step: 6
Training loss: 2.7494535770274435
Validation loss: 2.188563919772244
Epoch: 33| Step: 7
Training loss: 2.2754758106707067
Validation loss: 2.1131962802976094
Epoch: 33| Step: 8
Training loss: 2.482738027542036
Validation loss: 2.1298985285933956
Epoch: 33| Step: 9
Training loss: 2.604359632336413
Validation loss: 2.2026187053767723
Epoch: 34| Step: 0
Training loss: 2.942466919485353
Validation loss: 2.051223695401088
Epoch: 34| Step: 1
Training loss: 2.599567003141254
Validation loss: 2.0988132225811773
Epoch: 34| Step: 2
Training loss: 2.7261957397378396
Validation loss: 2.141538488140746
Epoch: 34| Step: 3
Training loss: 2.5504669883818694
Validation loss: 2.163604856283336
Epoch: 34| Step: 4
Training loss: 2.6003202387856543
Validation loss: 2.1242559446670164
Epoch: 34| Step: 5
Training loss: 2.2116895279592743
Validation loss: 2.1663506093206353
Epoch: 34| Step: 6
Training loss: 2.713203911924403
Validation loss: 2.1458624115445946
Epoch: 34| Step: 7
Training loss: 2.890743108862416
Validation loss: 2.1499793835891245
Epoch: 34| Step: 8
Training loss: 2.2832073019102084
Validation loss: 2.065963015267482
Epoch: 34| Step: 9
Training loss: 2.749344140651612
Validation loss: 1.9677029035695377
Epoch: 35| Step: 0
Training loss: 2.3107262071810286
Validation loss: 2.053784595674626
Epoch: 35| Step: 1
Training loss: 2.321196519341391
Validation loss: 2.1366133756333197
Epoch: 35| Step: 2
Training loss: 2.8609198060834946
Validation loss: 2.1584904617582383
Epoch: 35| Step: 3
Training loss: 2.9481831532368026
Validation loss: 2.096419227197573
Epoch: 35| Step: 4
Training loss: 2.6059394193972274
Validation loss: 2.18515360674189
Epoch: 35| Step: 5
Training loss: 2.731227436452583
Validation loss: 2.1820229500023625
Epoch: 35| Step: 6
Training loss: 2.9729478570219303
Validation loss: 2.13581462335066
Epoch: 35| Step: 7
Training loss: 2.7806670188687135
Validation loss: 2.055452663680681
Epoch: 35| Step: 8
Training loss: 2.642550426712979
Validation loss: 2.0761073828778254
Epoch: 35| Step: 9
Training loss: 2.6152578043725057
Validation loss: 2.116054774077735
Epoch: 36| Step: 0
Training loss: 2.6235715521711187
Validation loss: 2.0226353980082097
Epoch: 36| Step: 1
Training loss: 2.6106418115733456
Validation loss: 2.129292932920897
Epoch: 36| Step: 2
Training loss: 2.3569110863754683
Validation loss: 2.124298624013358
Epoch: 36| Step: 3
Training loss: 2.4286122779456036
Validation loss: 2.069658886008548
Epoch: 36| Step: 4
Training loss: 2.6626739015336076
Validation loss: 2.1008713401424304
Epoch: 36| Step: 5
Training loss: 3.2333117225422905
Validation loss: 2.0074247065646595
Epoch: 36| Step: 6
Training loss: 2.176455929044229
Validation loss: 2.0786319114193126
Epoch: 36| Step: 7
Training loss: 3.319988351594644
Validation loss: 2.178184333146076
Epoch: 36| Step: 8
Training loss: 2.525048748338938
Validation loss: 2.150945807944908
Epoch: 36| Step: 9
Training loss: 2.446988734772399
Validation loss: 2.1294671458846026
Epoch: 37| Step: 0
Training loss: 2.8443280984343153
Validation loss: 2.089180951147525
Epoch: 37| Step: 1
Training loss: 2.2947782950430917
Validation loss: 2.123486527072816
Epoch: 37| Step: 2
Training loss: 2.882242451366976
Validation loss: 2.0399933288786714
Epoch: 37| Step: 3
Training loss: 2.6011300858845656
Validation loss: 2.135420798878987
Epoch: 37| Step: 4
Training loss: 2.1375341446140386
Validation loss: 2.204505947329919
Epoch: 37| Step: 5
Training loss: 2.809484263704449
Validation loss: 2.104986917681783
Epoch: 37| Step: 6
Training loss: 2.8873972424474883
Validation loss: 2.1175419958479975
Epoch: 37| Step: 7
Training loss: 2.5327536743788066
Validation loss: 2.1239195899806633
Epoch: 37| Step: 8
Training loss: 2.442213538403857
Validation loss: 2.186398542136283
Epoch: 37| Step: 9
Training loss: 2.712477540657127
Validation loss: 2.118026914194323
Epoch: 38| Step: 0
Training loss: 2.414601879909886
Validation loss: 2.147308146363095
Epoch: 38| Step: 1
Training loss: 2.384884193215945
Validation loss: 2.169383109544918
Epoch: 38| Step: 2
Training loss: 2.4513394606244563
Validation loss: 2.0555339894436058
Epoch: 38| Step: 3
Training loss: 2.7969373131315702
Validation loss: 2.126787244946962
Epoch: 38| Step: 4
Training loss: 2.671390690327312
Validation loss: 2.0956450927703356
Epoch: 38| Step: 5
Training loss: 2.585755125685208
Validation loss: 2.1200374869077345
Epoch: 38| Step: 6
Training loss: 2.62403679387534
Validation loss: 2.0953892596677592
Epoch: 38| Step: 7
Training loss: 2.9714630579519157
Validation loss: 2.1470413621144813
Epoch: 38| Step: 8
Training loss: 2.665801434418971
Validation loss: 2.1865230505707824
Epoch: 38| Step: 9
Training loss: 2.6165774417251484
Validation loss: 2.0712438840767975
Epoch: 39| Step: 0
Training loss: 2.642644888407367
Validation loss: 2.1014275043308652
Epoch: 39| Step: 1
Training loss: 2.31042727808211
Validation loss: 2.1530265441695784
Epoch: 39| Step: 2
Training loss: 2.7602467802540467
Validation loss: 2.1249015578557304
Epoch: 39| Step: 3
Training loss: 2.6431468230451802
Validation loss: 2.202111825369329
Epoch: 39| Step: 4
Training loss: 2.6106110346454616
Validation loss: 2.0975449514623667
Epoch: 39| Step: 5
Training loss: 2.640976831596695
Validation loss: 2.017615538115339
Epoch: 39| Step: 6
Training loss: 2.693803890246817
Validation loss: 2.0968290519607526
Epoch: 39| Step: 7
Training loss: 2.642447029239687
Validation loss: 2.098829816467555
Epoch: 39| Step: 8
Training loss: 3.0548357915372204
Validation loss: 2.1215251077191652
Epoch: 39| Step: 9
Training loss: 2.656230971324305
Validation loss: 2.059729881022067
Epoch: 40| Step: 0
Training loss: 2.739936100012794
Validation loss: 2.063372297806064
Epoch: 40| Step: 1
Training loss: 2.696394462694527
Validation loss: 2.1867270074193783
Epoch: 40| Step: 2
Training loss: 2.572286479752447
Validation loss: 2.148280673244499
Epoch: 40| Step: 3
Training loss: 2.2832078240234472
Validation loss: 2.1000288628929593
Epoch: 40| Step: 4
Training loss: 2.679591141016464
Validation loss: 2.0527151989581607
Epoch: 40| Step: 5
Training loss: 2.631614253911538
Validation loss: 2.146761386695973
Epoch: 40| Step: 6
Training loss: 2.7604340366800684
Validation loss: 2.107024365397332
Epoch: 40| Step: 7
Training loss: 2.7238810560498643
Validation loss: 2.0174939320114746
Epoch: 40| Step: 8
Training loss: 2.7109398745655575
Validation loss: 2.156192367953037
Epoch: 40| Step: 9
Training loss: 2.802006622361084
Validation loss: 2.0378117041600756
Epoch: 41| Step: 0
Training loss: 3.1498403902337264
Validation loss: 2.150133224441095
Epoch: 41| Step: 1
Training loss: 2.3180368483529907
Validation loss: 2.1390079722466675
Epoch: 41| Step: 2
Training loss: 2.5861517595574153
Validation loss: 2.102721430488539
Epoch: 41| Step: 3
Training loss: 2.541115643748782
Validation loss: 2.1797148827428905
Epoch: 41| Step: 4
Training loss: 2.680340478819335
Validation loss: 2.1104050524788
Epoch: 41| Step: 5
Training loss: 2.7119833388252808
Validation loss: 2.079902980736133
Epoch: 41| Step: 6
Training loss: 2.2315972407935054
Validation loss: 2.0521154468939797
Epoch: 41| Step: 7
Training loss: 2.4940239050789437
Validation loss: 2.1069823913151344
Epoch: 41| Step: 8
Training loss: 2.665391249430883
Validation loss: 2.211032571672873
Epoch: 41| Step: 9
Training loss: 2.929404934290063
Validation loss: 2.163207983042436
Epoch: 42| Step: 0
Training loss: 2.7157296251657996
Validation loss: 2.084225364471259
Epoch: 42| Step: 1
Training loss: 2.7033550186635855
Validation loss: 2.1324473475294865
Epoch: 42| Step: 2
Training loss: 2.566892348519497
Validation loss: 2.1115642531690364
Epoch: 42| Step: 3
Training loss: 2.990738241349698
Validation loss: 2.0994414700768416
Epoch: 42| Step: 4
Training loss: 2.623605085044803
Validation loss: 2.130589451328801
Epoch: 42| Step: 5
Training loss: 2.640504913308171
Validation loss: 2.1492352992031485
Epoch: 42| Step: 6
Training loss: 2.150377985529952
Validation loss: 2.1541668133105643
Epoch: 42| Step: 7
Training loss: 2.84747372475308
Validation loss: 2.073366789126183
Epoch: 42| Step: 8
Training loss: 2.6249151670281154
Validation loss: 2.022517367299277
Epoch: 42| Step: 9
Training loss: 2.3308020440043724
Validation loss: 2.019648422224514
Epoch: 43| Step: 0
Training loss: 2.8372833169219107
Validation loss: 2.1493880493495316
Epoch: 43| Step: 1
Training loss: 3.0188437563787973
Validation loss: 2.1011608626587903
Epoch: 43| Step: 2
Training loss: 2.84086093237546
Validation loss: 2.1263083170336223
Epoch: 43| Step: 3
Training loss: 2.7741964671798542
Validation loss: 2.156541785987898
Epoch: 43| Step: 4
Training loss: 2.7405380113426214
Validation loss: 2.028209291710326
Epoch: 43| Step: 5
Training loss: 2.3057120421998514
Validation loss: 2.097377465912323
Epoch: 43| Step: 6
Training loss: 2.4122932147807297
Validation loss: 2.0764115813839545
Epoch: 43| Step: 7
Training loss: 2.5269924196734177
Validation loss: 2.0678175034189223
Epoch: 43| Step: 8
Training loss: 2.5336505197757373
Validation loss: 2.136080187363922
Epoch: 43| Step: 9
Training loss: 2.3818433447891176
Validation loss: 2.1518184994141425
Epoch: 44| Step: 0
Training loss: 2.569808771462812
Validation loss: 2.1047654206457604
Epoch: 44| Step: 1
Training loss: 3.1582928080378663
Validation loss: 2.137151769144337
Epoch: 44| Step: 2
Training loss: 2.4282818128696726
Validation loss: 2.13818458174046
Epoch: 44| Step: 3
Training loss: 2.8530801157434373
Validation loss: 2.1757218457188783
Epoch: 44| Step: 4
Training loss: 2.5360600487131038
Validation loss: 2.1031159102875736
Epoch: 44| Step: 5
Training loss: 2.4204553196279384
Validation loss: 2.126530422796176
Epoch: 44| Step: 6
Training loss: 2.5020617566434322
Validation loss: 2.098993903962252
Epoch: 44| Step: 7
Training loss: 2.3962161435564666
Validation loss: 2.1091950517143947
Epoch: 44| Step: 8
Training loss: 2.644414856911699
Validation loss: 2.1437496000448033
Epoch: 44| Step: 9
Training loss: 3.177862670034243
Validation loss: 2.107063669990035
Epoch: 45| Step: 0
Training loss: 2.5573466515829066
Validation loss: 2.036905770386169
Epoch: 45| Step: 1
Training loss: 2.6823901013333615
Validation loss: 2.119892040177761
Epoch: 45| Step: 2
Training loss: 2.795773763538396
Validation loss: 2.08488190286124
Epoch: 45| Step: 3
Training loss: 2.486351330717021
Validation loss: 2.1133207512416368
Epoch: 45| Step: 4
Training loss: 2.7621710810177103
Validation loss: 2.1228017353642312
Epoch: 45| Step: 5
Training loss: 2.8283038846762394
Validation loss: 2.1814492767583227
Epoch: 45| Step: 6
Training loss: 2.321181728527908
Validation loss: 2.108475713202611
Epoch: 45| Step: 7
Training loss: 2.3924951157475185
Validation loss: 2.2248476377558712
Epoch: 45| Step: 8
Training loss: 2.6828303021577384
Validation loss: 2.1309212464039393
Epoch: 45| Step: 9
Training loss: 2.922748944959808
Validation loss: 2.1474780693635944
Epoch: 46| Step: 0
Training loss: 2.557127554315687
Validation loss: 2.177805837240669
Epoch: 46| Step: 1
Training loss: 2.6871954279575365
Validation loss: 2.1476834887630623
Epoch: 46| Step: 2
Training loss: 2.4994559649751
Validation loss: 2.128918973645051
Epoch: 46| Step: 3
Training loss: 3.0494728946159793
Validation loss: 2.093338035745187
Epoch: 46| Step: 4
Training loss: 2.8949396048720835
Validation loss: 2.0787836301732554
Epoch: 46| Step: 5
Training loss: 2.6876658898542134
Validation loss: 2.0974738770895316
Epoch: 46| Step: 6
Training loss: 2.7468607931453217
Validation loss: 2.0973481835157766
Epoch: 46| Step: 7
Training loss: 2.3388692262517212
Validation loss: 2.089957089364351
Epoch: 46| Step: 8
Training loss: 2.5868701923894344
Validation loss: 2.1441146349549696
Epoch: 46| Step: 9
Training loss: 2.5288620033671223
Validation loss: 2.1192636787469024
Epoch: 47| Step: 0
Training loss: 2.6846981080611285
Validation loss: 2.096635640777804
Epoch: 47| Step: 1
Training loss: 2.946528095364519
Validation loss: 2.047971101111057
Epoch: 47| Step: 2
Training loss: 2.4597019545341587
Validation loss: 2.0779668573250487
Epoch: 47| Step: 3
Training loss: 2.3152960292638607
Validation loss: 2.087785277608362
Epoch: 47| Step: 4
Training loss: 2.3853771978275318
Validation loss: 2.191906896057467
Epoch: 47| Step: 5
Training loss: 2.8218736211323456
Validation loss: 2.090689338661065
Epoch: 47| Step: 6
Training loss: 2.762898626090758
Validation loss: 2.100818620263884
Epoch: 47| Step: 7
Training loss: 2.403995200598269
Validation loss: 2.058891151747803
Epoch: 47| Step: 8
Training loss: 2.571626367984601
Validation loss: 2.0848312941288727
Epoch: 47| Step: 9
Training loss: 3.162698032375861
Validation loss: 2.1028463767763945
Epoch: 48| Step: 0
Training loss: 2.5428588655934385
Validation loss: 2.13798127815069
Epoch: 48| Step: 1
Training loss: 2.9890922293652724
Validation loss: 2.179198157398883
Epoch: 48| Step: 2
Training loss: 2.2412709346544553
Validation loss: 2.1157904935138374
Epoch: 48| Step: 3
Training loss: 2.516811209647745
Validation loss: 2.063702160341409
Epoch: 48| Step: 4
Training loss: 2.958052142753411
Validation loss: 2.100158319986112
Epoch: 48| Step: 5
Training loss: 2.4498730140007265
Validation loss: 2.0397668691186563
Epoch: 48| Step: 6
Training loss: 2.7461408065736195
Validation loss: 2.051510494925848
Epoch: 48| Step: 7
Training loss: 2.546656312505368
Validation loss: 2.0860503100837806
Epoch: 48| Step: 8
Training loss: 2.990029934124073
Validation loss: 2.087089173801661
Epoch: 48| Step: 9
Training loss: 2.824979687507994
Validation loss: 2.1126527706048126
Epoch: 49| Step: 0
Training loss: 2.639564436614318
Validation loss: 2.1331855910861983
Epoch: 49| Step: 1
Training loss: 2.66779627319277
Validation loss: 2.146601679104201
Epoch: 49| Step: 2
Training loss: 2.4582357441125966
Validation loss: 2.13197924585928
Epoch: 49| Step: 3
Training loss: 2.773565498944421
Validation loss: 2.0748056566231017
Epoch: 49| Step: 4
Training loss: 2.7165507925710064
Validation loss: 2.0474304350441885
Epoch: 49| Step: 5
Training loss: 3.11788297844434
Validation loss: 2.0516407742222755
Epoch: 49| Step: 6
Training loss: 2.380467596200902
Validation loss: 2.15210403503317
Epoch: 49| Step: 7
Training loss: 2.336815914479372
Validation loss: 2.1511435134219172
Epoch: 49| Step: 8
Training loss: 2.740031293982679
Validation loss: 2.165409367495234
Epoch: 49| Step: 9
Training loss: 2.331930851652168
Validation loss: 2.126047246975086
Epoch: 50| Step: 0
Training loss: 2.947854318846853
Validation loss: 2.1476982016127075
Epoch: 50| Step: 1
Training loss: 2.730067582464174
Validation loss: 2.110926756585842
Epoch: 50| Step: 2
Training loss: 2.5279942991518376
Validation loss: 2.0527600738404024
Epoch: 50| Step: 3
Training loss: 2.4294116486105315
Validation loss: 2.1199428717182043
Epoch: 50| Step: 4
Training loss: 2.7015963074050893
Validation loss: 2.1685986849983356
Epoch: 50| Step: 5
Training loss: 2.8503284867361875
Validation loss: 2.061725057717279
Epoch: 50| Step: 6
Training loss: 2.6274892720766587
Validation loss: 2.106498503026005
Epoch: 50| Step: 7
Training loss: 2.302123942527646
Validation loss: 2.2076489324541813
Epoch: 50| Step: 8
Training loss: 2.678958092891798
Validation loss: 2.0687150001842936
Epoch: 50| Step: 9
Training loss: 2.4816357368025996
Validation loss: 2.070665557099645
