Epoch: 1| Step: 0
Training loss: 6.309533356884693
Validation loss: 5.53966134273543
Epoch: 1| Step: 1
Training loss: 5.60576273183802
Validation loss: 5.226085385011418
Epoch: 1| Step: 2
Training loss: 3.884933168874792
Validation loss: 5.099003470804526
Epoch: 1| Step: 3
Training loss: 4.7754161873037715
Validation loss: 5.0940852653170525
Epoch: 1| Step: 4
Training loss: 5.349803685659658
Validation loss: 4.832783230297039
Epoch: 1| Step: 5
Training loss: 5.146245695366679
Validation loss: 4.9488693052257355
Epoch: 1| Step: 6
Training loss: 5.828670854548579
Validation loss: 4.820170805594595
Epoch: 1| Step: 7
Training loss: 4.620589550433916
Validation loss: 4.733453916667751
Epoch: 1| Step: 8
Training loss: 4.788706830058408
Validation loss: 4.786954659844669
Epoch: 1| Step: 9
Training loss: 5.716715466408745
Validation loss: 4.698766256768801
Epoch: 1| Step: 10
Training loss: 5.6855368107949396
Validation loss: 4.675427999158644
Epoch: 1| Step: 11
Training loss: 5.330799494287045
Validation loss: 4.672510892930526
Epoch: 1| Step: 12
Training loss: 5.32685277522212
Validation loss: 4.566201401914498
Epoch: 1| Step: 13
Training loss: 4.5735396509
Validation loss: 4.516498085956243
Epoch: 1| Step: 14
Training loss: 4.5259212335938095
Validation loss: 4.356287493280741
Epoch: 1| Step: 15
Training loss: 5.605177304869004
Validation loss: 4.418396413725284
Epoch: 1| Step: 16
Training loss: 4.442709001166177
Validation loss: 4.377559426034966
Epoch: 1| Step: 17
Training loss: 3.6896511204482465
Validation loss: 4.291356650278907
Epoch: 1| Step: 18
Training loss: 4.626204050408458
Validation loss: 4.244879108416023
Epoch: 1| Step: 19
Training loss: 5.182352476545966
Validation loss: 4.247297518530917
Epoch: 2| Step: 0
Training loss: 4.096249116042469
Validation loss: 4.092289698872234
Epoch: 2| Step: 1
Training loss: 3.8517977195859365
Validation loss: 4.076957572389239
Epoch: 2| Step: 2
Training loss: 4.483400883691611
Validation loss: 4.065337090836819
Epoch: 2| Step: 3
Training loss: 4.449259904331176
Validation loss: 3.9741951449003476
Epoch: 2| Step: 4
Training loss: 4.965402495174677
Validation loss: 4.020710824225363
Epoch: 2| Step: 5
Training loss: 4.640472101332168
Validation loss: 3.829400752601611
Epoch: 2| Step: 6
Training loss: 4.97956448592469
Validation loss: 3.828717733036536
Epoch: 2| Step: 7
Training loss: 4.1985253333730865
Validation loss: 3.782060412269246
Epoch: 2| Step: 8
Training loss: 4.2996129416208975
Validation loss: 3.7504874767512635
Epoch: 2| Step: 9
Training loss: 3.7608949704017998
Validation loss: 3.68056029282943
Epoch: 2| Step: 10
Training loss: 4.116129498564178
Validation loss: 3.6824674737516685
Epoch: 2| Step: 11
Training loss: 4.300468135457119
Validation loss: 3.636449716979637
Epoch: 2| Step: 12
Training loss: 4.012848246545674
Validation loss: 3.6560846785851604
Epoch: 2| Step: 13
Training loss: 4.0240504122054315
Validation loss: 3.580985042602874
Epoch: 2| Step: 14
Training loss: 4.067079281328954
Validation loss: 3.570452044467574
Epoch: 2| Step: 15
Training loss: 4.252396076419395
Validation loss: 3.561611298039468
Epoch: 2| Step: 16
Training loss: 3.7722021888596715
Validation loss: 3.415999197975219
Epoch: 2| Step: 17
Training loss: 4.344973823986507
Validation loss: 3.3864134210806283
Epoch: 2| Step: 18
Training loss: 2.991145099310121
Validation loss: 3.2899197965118225
Epoch: 2| Step: 19
Training loss: 3.2195146263561667
Validation loss: 3.2287447408843395
Epoch: 3| Step: 0
Training loss: 3.16709983941496
Validation loss: 3.2634036262276127
Epoch: 3| Step: 1
Training loss: 3.3645570043393853
Validation loss: 3.1881011018254175
Epoch: 3| Step: 2
Training loss: 3.677996917283559
Validation loss: 3.158640422734002
Epoch: 3| Step: 3
Training loss: 2.9429606551749403
Validation loss: 3.1197386858303684
Epoch: 3| Step: 4
Training loss: 2.9341078306534434
Validation loss: 3.0960127342407286
Epoch: 3| Step: 5
Training loss: 3.918440450948177
Validation loss: 3.0021536522173737
Epoch: 3| Step: 6
Training loss: 3.086574981129689
Validation loss: 3.004255365571775
Epoch: 3| Step: 7
Training loss: 3.190190993184898
Validation loss: 3.0685510045462987
Epoch: 3| Step: 8
Training loss: 3.6747897652417594
Validation loss: 3.049404454773912
Epoch: 3| Step: 9
Training loss: 3.784307961535596
Validation loss: 2.918262257983523
Epoch: 3| Step: 10
Training loss: 3.9152949481028436
Validation loss: 2.938244845574762
Epoch: 3| Step: 11
Training loss: 3.3246619604839913
Validation loss: 2.898284534905234
Epoch: 3| Step: 12
Training loss: 3.7896868948323763
Validation loss: 2.8849699037256045
Epoch: 3| Step: 13
Training loss: 3.415192790139854
Validation loss: 2.8866228763719572
Epoch: 3| Step: 14
Training loss: 3.1217536849238985
Validation loss: 2.821671469694758
Epoch: 3| Step: 15
Training loss: 3.4705317964272
Validation loss: 2.762812970421977
Epoch: 3| Step: 16
Training loss: 3.250375432557858
Validation loss: 2.633102191011544
Epoch: 3| Step: 17
Training loss: 3.419821902763162
Validation loss: 2.6256263036678806
Epoch: 3| Step: 18
Training loss: 3.4722379726476538
Validation loss: 2.712127146900924
Epoch: 3| Step: 19
Training loss: 3.564352925603647
Validation loss: 2.6325573672472755
Epoch: 4| Step: 0
Training loss: 3.003030200299546
Validation loss: 2.61198279258503
Epoch: 4| Step: 1
Training loss: 3.66921030305526
Validation loss: 2.5503033515512294
Epoch: 4| Step: 2
Training loss: 2.0785573638642423
Validation loss: 2.5655526209027677
Epoch: 4| Step: 3
Training loss: 3.4368218880153516
Validation loss: 2.5416525950843183
Epoch: 4| Step: 4
Training loss: 3.4656073278280966
Validation loss: 2.5183260539494494
Epoch: 4| Step: 5
Training loss: 2.3868118492736303
Validation loss: 2.524329246564501
Epoch: 4| Step: 6
Training loss: 2.791991675137676
Validation loss: 2.488478929059065
Epoch: 4| Step: 7
Training loss: 2.976097891684457
Validation loss: 2.410264363682284
Epoch: 4| Step: 8
Training loss: 2.945262311512875
Validation loss: 2.4308993617623367
Epoch: 4| Step: 9
Training loss: 2.714478480513908
Validation loss: 2.3933180130195293
Epoch: 4| Step: 10
Training loss: 3.2207996545949675
Validation loss: 2.4766577468843614
Epoch: 4| Step: 11
Training loss: 2.9022295635449242
Validation loss: 2.383780520987317
Epoch: 4| Step: 12
Training loss: 2.99964823249957
Validation loss: 2.412471748900672
Epoch: 4| Step: 13
Training loss: 3.7219345177696814
Validation loss: 2.4028614653665796
Epoch: 4| Step: 14
Training loss: 3.0707833509030875
Validation loss: 2.317359908999995
Epoch: 4| Step: 15
Training loss: 2.9110530418771265
Validation loss: 2.3911093528859304
Epoch: 4| Step: 16
Training loss: 3.042100500930841
Validation loss: 2.3234151688322395
Epoch: 4| Step: 17
Training loss: 2.767071448056794
Validation loss: 2.2913602943844698
Epoch: 4| Step: 18
Training loss: 2.5107253796294176
Validation loss: 2.322789573640162
Epoch: 4| Step: 19
Training loss: 2.7851401565322202
Validation loss: 2.2535408431139787
Epoch: 5| Step: 0
Training loss: 3.348904923190611
Validation loss: 2.2786913033407554
Epoch: 5| Step: 1
Training loss: 3.2443519812810666
Validation loss: 2.286472386542576
Epoch: 5| Step: 2
Training loss: 3.0913693294484705
Validation loss: 2.2469117822343248
Epoch: 5| Step: 3
Training loss: 2.524234799304828
Validation loss: 2.237940113132094
Epoch: 5| Step: 4
Training loss: 2.7838797834244873
Validation loss: 2.168695271876687
Epoch: 5| Step: 5
Training loss: 2.3772045745376817
Validation loss: 2.100101261423764
Epoch: 5| Step: 6
Training loss: 2.260664356449124
Validation loss: 2.1840494989728954
Epoch: 5| Step: 7
Training loss: 3.2132883492430087
Validation loss: 2.2225670140610196
Epoch: 5| Step: 8
Training loss: 2.514156694941417
Validation loss: 2.1997180010813957
Epoch: 5| Step: 9
Training loss: 2.558245686159399
Validation loss: 2.200312718182412
Epoch: 5| Step: 10
Training loss: 2.460994271728595
Validation loss: 2.2373377715611493
Epoch: 5| Step: 11
Training loss: 2.701597454667862
Validation loss: 2.175760869362693
Epoch: 5| Step: 12
Training loss: 3.075295789185002
Validation loss: 2.195600663977676
Epoch: 5| Step: 13
Training loss: 2.93149309594026
Validation loss: 2.117610131701013
Epoch: 5| Step: 14
Training loss: 2.2631549919814846
Validation loss: 2.1228218194199675
Epoch: 5| Step: 15
Training loss: 2.6294572317994267
Validation loss: 2.078534986262155
Epoch: 5| Step: 16
Training loss: 2.876420706632284
Validation loss: 2.1540854089961297
Epoch: 5| Step: 17
Training loss: 2.367595977287916
Validation loss: 2.17396119176727
Epoch: 5| Step: 18
Training loss: 2.938055919231915
Validation loss: 2.1346490195628958
Epoch: 5| Step: 19
Training loss: 2.7370184627268443
Validation loss: 2.072324508737401
Epoch: 6| Step: 0
Training loss: 2.9043919355975296
Validation loss: 2.112196961984681
Epoch: 6| Step: 1
Training loss: 2.605931734187807
Validation loss: 2.090055080907132
Epoch: 6| Step: 2
Training loss: 2.805109273920582
Validation loss: 2.128466913662188
Epoch: 6| Step: 3
Training loss: 2.9541461127839073
Validation loss: 2.1086443422086436
Epoch: 6| Step: 4
Training loss: 2.449220112826076
Validation loss: 2.115015105777058
Epoch: 6| Step: 5
Training loss: 2.8038549010899203
Validation loss: 2.1385274102981455
Epoch: 6| Step: 6
Training loss: 2.3260601538951167
Validation loss: 2.1267275591241037
Epoch: 6| Step: 7
Training loss: 2.123093928260489
Validation loss: 2.1418531534187473
Epoch: 6| Step: 8
Training loss: 3.10801413962193
Validation loss: 2.1305912738226747
Epoch: 6| Step: 9
Training loss: 2.575458233994733
Validation loss: 2.1309897788063887
Epoch: 6| Step: 10
Training loss: 2.6742645643111715
Validation loss: 2.0816472485352535
Epoch: 6| Step: 11
Training loss: 2.781154330890583
Validation loss: 2.1367375850943677
Epoch: 6| Step: 12
Training loss: 2.8922484092130993
Validation loss: 2.0664514414488555
Epoch: 6| Step: 13
Training loss: 2.3384175993385963
Validation loss: 2.0899683327286183
Epoch: 6| Step: 14
Training loss: 3.0786307447090935
Validation loss: 2.1471837333297503
Epoch: 6| Step: 15
Training loss: 3.0152160683511178
Validation loss: 2.100464759014481
Epoch: 6| Step: 16
Training loss: 2.4470300462107337
Validation loss: 2.095130495455884
Epoch: 6| Step: 17
Training loss: 2.5016778084212237
Validation loss: 2.058018204964574
Epoch: 6| Step: 18
Training loss: 2.5903491049301826
Validation loss: 2.067076277272014
Epoch: 6| Step: 19
Training loss: 2.2695576178747414
Validation loss: 2.0970640786467865
Epoch: 7| Step: 0
Training loss: 2.9459214934268987
Validation loss: 2.0689225395007815
Epoch: 7| Step: 1
Training loss: 2.2133956561831747
Validation loss: 2.153163497666434
Epoch: 7| Step: 2
Training loss: 2.45928880475045
Validation loss: 2.0847815165305326
Epoch: 7| Step: 3
Training loss: 2.2254181715372074
Validation loss: 2.1039549642040765
Epoch: 7| Step: 4
Training loss: 2.4615994002290975
Validation loss: 2.0990024474740925
Epoch: 7| Step: 5
Training loss: 2.5167934949971484
Validation loss: 2.0582515309415
Epoch: 7| Step: 6
Training loss: 2.5758790376825655
Validation loss: 2.065229579284371
Epoch: 7| Step: 7
Training loss: 3.3165698690682115
Validation loss: 2.0833280827671814
Epoch: 7| Step: 8
Training loss: 2.6576982925519212
Validation loss: 2.0396463827464486
Epoch: 7| Step: 9
Training loss: 2.4962645279753364
Validation loss: 2.0684050815799506
Epoch: 7| Step: 10
Training loss: 2.432725779139872
Validation loss: 2.0995417695462817
Epoch: 7| Step: 11
Training loss: 2.6539117731638235
Validation loss: 2.0234410520118167
Epoch: 7| Step: 12
Training loss: 2.8796832874782674
Validation loss: 2.067690128173461
Epoch: 7| Step: 13
Training loss: 2.4778454462950465
Validation loss: 2.073810390239805
Epoch: 7| Step: 14
Training loss: 2.615680408688479
Validation loss: 2.1183342451802076
Epoch: 7| Step: 15
Training loss: 2.5213189931421693
Validation loss: 2.056415541359613
Epoch: 7| Step: 16
Training loss: 2.931554906152304
Validation loss: 2.052845453539777
Epoch: 7| Step: 17
Training loss: 3.0736807869917566
Validation loss: 2.053617976947103
Epoch: 7| Step: 18
Training loss: 2.453969044870198
Validation loss: 2.036594865861935
Epoch: 7| Step: 19
Training loss: 2.7288143619735363
Validation loss: 2.1000503676526465
Epoch: 8| Step: 0
Training loss: 2.7520116904032603
Validation loss: 2.053363196282402
Epoch: 8| Step: 1
Training loss: 2.3347280171559635
Validation loss: 2.1073405907909
Epoch: 8| Step: 2
Training loss: 2.8712624844124806
Validation loss: 2.0250365020117
Epoch: 8| Step: 3
Training loss: 2.708029206635423
Validation loss: 2.1227723042376434
Epoch: 8| Step: 4
Training loss: 2.6511260932913996
Validation loss: 2.0464296294734634
Epoch: 8| Step: 5
Training loss: 2.680930069195985
Validation loss: 2.0907891461565353
Epoch: 8| Step: 6
Training loss: 2.7905465246360697
Validation loss: 2.1267850839405065
Epoch: 8| Step: 7
Training loss: 2.3784796672125976
Validation loss: 2.090773434976975
Epoch: 8| Step: 8
Training loss: 2.7685176571046455
Validation loss: 2.0783125871249033
Epoch: 8| Step: 9
Training loss: 3.0497351109278608
Validation loss: 2.044486545350169
Epoch: 8| Step: 10
Training loss: 2.126935414082024
Validation loss: 2.1231811825103772
Epoch: 8| Step: 11
Training loss: 2.315586401737394
Validation loss: 2.0714192403813545
Epoch: 8| Step: 12
Training loss: 2.554661741914296
Validation loss: 2.108788956645653
Epoch: 8| Step: 13
Training loss: 2.814247436207795
Validation loss: 2.1310366932596976
Epoch: 8| Step: 14
Training loss: 2.594409628949219
Validation loss: 2.0976329784823924
Epoch: 8| Step: 15
Training loss: 2.909688576620364
Validation loss: 2.0859123947792506
Epoch: 8| Step: 16
Training loss: 2.4488749042180142
Validation loss: 2.0719022026987632
Epoch: 8| Step: 17
Training loss: 2.733560495318767
Validation loss: 2.086337258982487
Epoch: 8| Step: 18
Training loss: 2.4363191140531013
Validation loss: 2.086705714787752
Epoch: 8| Step: 19
Training loss: 2.635160672466549
Validation loss: 2.1064710680833425
Epoch: 9| Step: 0
Training loss: 2.3141188239249724
Validation loss: 2.0815446487521814
Epoch: 9| Step: 1
Training loss: 2.923154826033491
Validation loss: 2.0808249992485646
Epoch: 9| Step: 2
Training loss: 2.104136199227004
Validation loss: 2.075585922998529
Epoch: 9| Step: 3
Training loss: 3.1499891977276335
Validation loss: 2.0450895013978165
Epoch: 9| Step: 4
Training loss: 2.7332890561247
Validation loss: 2.0984277406827907
Epoch: 9| Step: 5
Training loss: 2.4354960689430722
Validation loss: 2.088602368927494
Epoch: 9| Step: 6
Training loss: 2.5765387076533766
Validation loss: 2.108210026903031
Epoch: 9| Step: 7
Training loss: 2.342737207931621
Validation loss: 2.0987465566743992
Epoch: 9| Step: 8
Training loss: 2.680298849495597
Validation loss: 2.1004907926463856
Epoch: 9| Step: 9
Training loss: 2.4484441527061422
Validation loss: 2.0493962143905122
Epoch: 9| Step: 10
Training loss: 2.2530878918431836
Validation loss: 2.048378477537235
Epoch: 9| Step: 11
Training loss: 2.3345404182051332
Validation loss: 2.082681965334137
Epoch: 9| Step: 12
Training loss: 2.9361665012119724
Validation loss: 2.0919234940217306
Epoch: 9| Step: 13
Training loss: 2.74849442970082
Validation loss: 2.121730005198386
Epoch: 9| Step: 14
Training loss: 2.362549118257997
Validation loss: 1.98783365396164
Epoch: 9| Step: 15
Training loss: 2.6308849307987616
Validation loss: 2.0475444583324336
Epoch: 9| Step: 16
Training loss: 2.5809271178687405
Validation loss: 2.049958382888416
Epoch: 9| Step: 17
Training loss: 2.78963056490634
Validation loss: 2.061756329774513
Epoch: 9| Step: 18
Training loss: 2.649539324466986
Validation loss: 2.074936408507738
Epoch: 9| Step: 19
Training loss: 3.3599716721203428
Validation loss: 2.026439447243897
Epoch: 10| Step: 0
Training loss: 2.5182066755003785
Validation loss: 2.074265011012484
Epoch: 10| Step: 1
Training loss: 3.0033887161866972
Validation loss: 2.120125440760428
Epoch: 10| Step: 2
Training loss: 3.1219543874611135
Validation loss: 2.0931884095800255
Epoch: 10| Step: 3
Training loss: 2.599266069702126
Validation loss: 2.0805313247688377
Epoch: 10| Step: 4
Training loss: 2.444481656725687
Validation loss: 2.1187851597250904
Epoch: 10| Step: 5
Training loss: 2.5646548631259463
Validation loss: 2.04703986832116
Epoch: 10| Step: 6
Training loss: 2.6780367290322773
Validation loss: 2.151007644214885
Epoch: 10| Step: 7
Training loss: 2.9214431525161992
Validation loss: 2.12689108814656
Epoch: 10| Step: 8
Training loss: 2.8815549676654175
Validation loss: 2.1153914498615127
Epoch: 10| Step: 9
Training loss: 3.1351775186949893
Validation loss: 2.065832936483986
Epoch: 10| Step: 10
Training loss: 2.2147849746252306
Validation loss: 2.076821747998079
Epoch: 10| Step: 11
Training loss: 2.9950165683498216
Validation loss: 2.0234282445224405
Epoch: 10| Step: 12
Training loss: 2.664448371752101
Validation loss: 2.0964107027599628
Epoch: 10| Step: 13
Training loss: 2.3250410917198936
Validation loss: 2.0531187275642013
Epoch: 10| Step: 14
Training loss: 2.044891561230664
Validation loss: 2.079535397403297
Epoch: 10| Step: 15
Training loss: 2.5688734113094243
Validation loss: 2.0460864039716586
Epoch: 10| Step: 16
Training loss: 2.6551667641316095
Validation loss: 2.0368717380267882
Epoch: 10| Step: 17
Training loss: 2.516898739032368
Validation loss: 2.1102835452734907
Epoch: 10| Step: 18
Training loss: 2.3956322184751753
Validation loss: 2.0837015378202057
Epoch: 10| Step: 19
Training loss: 2.112425117745544
Validation loss: 2.0593824590354632
Epoch: 11| Step: 0
Training loss: 2.349296111344953
Validation loss: 2.0386445479116375
Epoch: 11| Step: 1
Training loss: 2.4630241146107466
Validation loss: 2.0746073717014086
Epoch: 11| Step: 2
Training loss: 2.741991171913766
Validation loss: 2.1046892772032257
Epoch: 11| Step: 3
Training loss: 2.904746045881542
Validation loss: 2.11127442856539
Epoch: 11| Step: 4
Training loss: 2.1732143964967814
Validation loss: 2.1031007512541064
Epoch: 11| Step: 5
Training loss: 2.6448099054341445
Validation loss: 2.0725775231090555
Epoch: 11| Step: 6
Training loss: 2.562310374617326
Validation loss: 2.0454453028419017
Epoch: 11| Step: 7
Training loss: 2.662343116400627
Validation loss: 2.093176799557044
Epoch: 11| Step: 8
Training loss: 3.262456936022208
Validation loss: 2.053110094591596
Epoch: 11| Step: 9
Training loss: 2.172720984489364
Validation loss: 2.1129092331219943
Epoch: 11| Step: 10
Training loss: 2.210008405781636
Validation loss: 2.0728566382717375
Epoch: 11| Step: 11
Training loss: 2.6976674282660995
Validation loss: 2.0941453918200352
Epoch: 11| Step: 12
Training loss: 2.5281132229788845
Validation loss: 2.09782403041853
Epoch: 11| Step: 13
Training loss: 3.3472789075456353
Validation loss: 2.063560634070683
Epoch: 11| Step: 14
Training loss: 2.62581930544379
Validation loss: 2.0096413441576724
Epoch: 11| Step: 15
Training loss: 3.063996552687018
Validation loss: 2.092727199187515
Epoch: 11| Step: 16
Training loss: 2.491862787121576
Validation loss: 1.9998809610001773
Epoch: 11| Step: 17
Training loss: 2.895267531925314
Validation loss: 2.0701394237546507
Epoch: 11| Step: 18
Training loss: 2.1454200223134756
Validation loss: 2.0487794184329795
Epoch: 11| Step: 19
Training loss: 2.300094735226274
Validation loss: 2.079480217684437
Epoch: 12| Step: 0
Training loss: 2.773662633220483
Validation loss: 2.1001387834049274
Epoch: 12| Step: 1
Training loss: 2.6002813627150436
Validation loss: 2.1097898992688395
Epoch: 12| Step: 2
Training loss: 2.630106726972058
Validation loss: 2.1154483294006226
Epoch: 12| Step: 3
Training loss: 2.8702602292421737
Validation loss: 2.0893284757710067
Epoch: 12| Step: 4
Training loss: 2.19058054227244
Validation loss: 2.0618286233498644
Epoch: 12| Step: 5
Training loss: 3.014346627567156
Validation loss: 2.0706011333735224
Epoch: 12| Step: 6
Training loss: 2.740292320807947
Validation loss: 2.081606460618052
Epoch: 12| Step: 7
Training loss: 2.1189142484213668
Validation loss: 2.069397398597153
Epoch: 12| Step: 8
Training loss: 2.4146661590071505
Validation loss: 2.0533445682334746
Epoch: 12| Step: 9
Training loss: 2.5078780026066365
Validation loss: 2.111845581972627
Epoch: 12| Step: 10
Training loss: 2.342823710186432
Validation loss: 2.0960732393705532
Epoch: 12| Step: 11
Training loss: 2.0517996448317604
Validation loss: 2.0961305642545183
Epoch: 12| Step: 12
Training loss: 2.760821724209115
Validation loss: 2.089677380409855
Epoch: 12| Step: 13
Training loss: 2.3861944493681384
Validation loss: 2.0420396616307084
Epoch: 12| Step: 14
Training loss: 3.2794890992090604
Validation loss: 2.1059632090603433
Epoch: 12| Step: 15
Training loss: 2.349456046437525
Validation loss: 2.1066501804034274
Epoch: 12| Step: 16
Training loss: 2.845011337069967
Validation loss: 2.1061492617593864
Epoch: 12| Step: 17
Training loss: 2.593404356205402
Validation loss: 2.114603557145351
Epoch: 12| Step: 18
Training loss: 2.7757960646856983
Validation loss: 2.127208852059976
Epoch: 12| Step: 19
Training loss: 3.117285552430683
Validation loss: 2.0787538876575153
Epoch: 13| Step: 0
Training loss: 2.7489115555052392
Validation loss: 2.0440532995161913
Epoch: 13| Step: 1
Training loss: 2.225472809350564
Validation loss: 2.0943447557240877
Epoch: 13| Step: 2
Training loss: 3.164357866229167
Validation loss: 1.9819678861855823
Epoch: 13| Step: 3
Training loss: 1.8121808527446148
Validation loss: 2.1387013661969627
Epoch: 13| Step: 4
Training loss: 2.614387494740642
Validation loss: 2.0654024776017748
Epoch: 13| Step: 5
Training loss: 2.0070735298832254
Validation loss: 2.071801752485378
Epoch: 13| Step: 6
Training loss: 3.276774233051409
Validation loss: 2.061290103909592
Epoch: 13| Step: 7
Training loss: 2.504892711359583
Validation loss: 2.119369481432864
Epoch: 13| Step: 8
Training loss: 2.5978703690242417
Validation loss: 2.0309905201169576
Epoch: 13| Step: 9
Training loss: 2.9672841518865547
Validation loss: 2.10487275010436
Epoch: 13| Step: 10
Training loss: 2.6108321273059008
Validation loss: 2.0660213320297673
Epoch: 13| Step: 11
Training loss: 2.977195372096089
Validation loss: 2.0548342638923818
Epoch: 13| Step: 12
Training loss: 2.588540326021539
Validation loss: 2.084104162614744
Epoch: 13| Step: 13
Training loss: 2.4149794334025545
Validation loss: 2.107394659055
Epoch: 13| Step: 14
Training loss: 2.7715563774836975
Validation loss: 2.0845730795794277
Epoch: 13| Step: 15
Training loss: 2.4771977040222755
Validation loss: 2.08945235739462
Epoch: 13| Step: 16
Training loss: 2.7940909738714264
Validation loss: 2.091458937162291
Epoch: 13| Step: 17
Training loss: 2.423557607600025
Validation loss: 2.1228752335974104
Epoch: 13| Step: 18
Training loss: 2.3157702854721327
Validation loss: 2.0759461118765117
Epoch: 13| Step: 19
Training loss: 2.9380452076216947
Validation loss: 2.056173029124079
Epoch: 14| Step: 0
Training loss: 2.3451076390140413
Validation loss: 2.12783775894193
Epoch: 14| Step: 1
Training loss: 3.14300386284528
Validation loss: 2.0867159818939247
Epoch: 14| Step: 2
Training loss: 2.6386376300343057
Validation loss: 2.037762686994421
Epoch: 14| Step: 3
Training loss: 2.9753566111478094
Validation loss: 2.0420468001616214
Epoch: 14| Step: 4
Training loss: 2.380097189770087
Validation loss: 2.0562791975766146
Epoch: 14| Step: 5
Training loss: 2.5014451618302656
Validation loss: 2.108860419005535
Epoch: 14| Step: 6
Training loss: 2.3153454569374605
Validation loss: 2.1143655306789313
Epoch: 14| Step: 7
Training loss: 2.3539838016571726
Validation loss: 2.1029177969372195
Epoch: 14| Step: 8
Training loss: 1.9958202077583986
Validation loss: 2.052926512640872
Epoch: 14| Step: 9
Training loss: 2.4514926411757325
Validation loss: 2.123777027365085
Epoch: 14| Step: 10
Training loss: 2.969166455421865
Validation loss: 2.0949044663203154
Epoch: 14| Step: 11
Training loss: 2.870976493672785
Validation loss: 2.066063922792674
Epoch: 14| Step: 12
Training loss: 2.496891568812849
Validation loss: 2.066429736302516
Epoch: 14| Step: 13
Training loss: 2.676183873535128
Validation loss: 2.087853541722801
Epoch: 14| Step: 14
Training loss: 3.255765935315609
Validation loss: 2.0548297275511636
Epoch: 14| Step: 15
Training loss: 2.6562526029686233
Validation loss: 2.069216374813961
Epoch: 14| Step: 16
Training loss: 2.3442463667097857
Validation loss: 2.0994240324464677
Epoch: 14| Step: 17
Training loss: 2.395520054334548
Validation loss: 2.0828757679768772
Epoch: 14| Step: 18
Training loss: 1.9164514697245338
Validation loss: 2.1146711712538226
Epoch: 14| Step: 19
Training loss: 3.4594424357470612
Validation loss: 2.075636578519017
Epoch: 15| Step: 0
Training loss: 2.490075822158365
Validation loss: 2.147841591164884
Epoch: 15| Step: 1
Training loss: 3.1973321403244546
Validation loss: 2.052629223090914
Epoch: 15| Step: 2
Training loss: 2.456573006937821
Validation loss: 2.0686717146805123
Epoch: 15| Step: 3
Training loss: 2.6160857201627126
Validation loss: 2.0361394340144154
Epoch: 15| Step: 4
Training loss: 2.302571608830862
Validation loss: 2.099811414441633
Epoch: 15| Step: 5
Training loss: 2.442273478785335
Validation loss: 2.088329269362232
Epoch: 15| Step: 6
Training loss: 2.318544478446587
Validation loss: 2.056138099526547
Epoch: 15| Step: 7
Training loss: 2.610572859791605
Validation loss: 2.0648495310985897
Epoch: 15| Step: 8
Training loss: 2.6667736945926603
Validation loss: 2.09093990897743
Epoch: 15| Step: 9
Training loss: 2.330064413792957
Validation loss: 2.078647465555982
Epoch: 15| Step: 10
Training loss: 2.8797233591729277
Validation loss: 2.119859174147188
Epoch: 15| Step: 11
Training loss: 2.636155177039402
Validation loss: 2.097353744642033
Epoch: 15| Step: 12
Training loss: 2.43434515997211
Validation loss: 2.069552038717325
Epoch: 15| Step: 13
Training loss: 2.458849502512726
Validation loss: 2.131920647887545
Epoch: 15| Step: 14
Training loss: 3.0330679249890955
Validation loss: 2.094384021915981
Epoch: 15| Step: 15
Training loss: 2.653530029724997
Validation loss: 2.0883606766618485
Epoch: 15| Step: 16
Training loss: 2.832986099806919
Validation loss: 2.065150765660446
Epoch: 15| Step: 17
Training loss: 2.469914994418002
Validation loss: 2.052717837394669
Epoch: 15| Step: 18
Training loss: 2.7132270225424358
Validation loss: 2.0250912298082175
Epoch: 15| Step: 19
Training loss: 2.916604250285459
Validation loss: 2.1031943418772214
Epoch: 16| Step: 0
Training loss: 2.65638194036975
Validation loss: 2.07802402484743
Epoch: 16| Step: 1
Training loss: 2.238692693525331
Validation loss: 2.059164248570043
Epoch: 16| Step: 2
Training loss: 2.4035101811300694
Validation loss: 2.077206002647002
Epoch: 16| Step: 3
Training loss: 2.3084018582342027
Validation loss: 2.073609004232263
Epoch: 16| Step: 4
Training loss: 2.2861590931851237
Validation loss: 2.052126223688315
Epoch: 16| Step: 5
Training loss: 2.664895741210796
Validation loss: 2.1130496905841474
Epoch: 16| Step: 6
Training loss: 3.0840646203045674
Validation loss: 2.0669363512884993
Epoch: 16| Step: 7
Training loss: 3.0665973579480443
Validation loss: 2.0992978765589774
Epoch: 16| Step: 8
Training loss: 2.682447785707464
Validation loss: 2.104668577175863
Epoch: 16| Step: 9
Training loss: 2.4473964598344313
Validation loss: 2.0654541021576334
Epoch: 16| Step: 10
Training loss: 1.9858238757963869
Validation loss: 2.0257060921849264
Epoch: 16| Step: 11
Training loss: 2.5459143576290693
Validation loss: 2.077962072208052
Epoch: 16| Step: 12
Training loss: 2.6103369487292016
Validation loss: 2.081470010949059
Epoch: 16| Step: 13
Training loss: 3.002960492728173
Validation loss: 2.044670168677164
Epoch: 16| Step: 14
Training loss: 2.4308090319991877
Validation loss: 2.0798031778861006
Epoch: 16| Step: 15
Training loss: 3.011157269219857
Validation loss: 2.0945389743354013
Epoch: 16| Step: 16
Training loss: 2.6146248640634955
Validation loss: 2.091073107201518
Epoch: 16| Step: 17
Training loss: 2.906250164072996
Validation loss: 2.1211378548264137
Epoch: 16| Step: 18
Training loss: 2.3365579757044603
Validation loss: 2.099367643108823
Epoch: 16| Step: 19
Training loss: 3.0559248113519937
Validation loss: 2.132665457329933
Epoch: 17| Step: 0
Training loss: 2.0313981222285435
Validation loss: 2.029720000575039
Epoch: 17| Step: 1
Training loss: 2.4724688948631233
Validation loss: 2.1124080913168917
Epoch: 17| Step: 2
Training loss: 2.583568213665094
Validation loss: 2.0523972962409522
Epoch: 17| Step: 3
Training loss: 2.892527021514307
Validation loss: 2.038635946091084
Epoch: 17| Step: 4
Training loss: 3.3672530661304245
Validation loss: 2.0979263303370157
Epoch: 17| Step: 5
Training loss: 2.285957913102263
Validation loss: 2.1011814363063963
Epoch: 17| Step: 6
Training loss: 2.7308407858858534
Validation loss: 2.0712381554889205
Epoch: 17| Step: 7
Training loss: 3.190743385681695
Validation loss: 2.0226909784901843
Epoch: 17| Step: 8
Training loss: 2.576786965608836
Validation loss: 2.1054264666797784
Epoch: 17| Step: 9
Training loss: 2.2029299818800228
Validation loss: 2.0258471182690463
Epoch: 17| Step: 10
Training loss: 2.6727424685730963
Validation loss: 2.093367192265772
Epoch: 17| Step: 11
Training loss: 2.2798572626106264
Validation loss: 2.059928326916667
Epoch: 17| Step: 12
Training loss: 3.3867618333656684
Validation loss: 2.1232427936798324
Epoch: 17| Step: 13
Training loss: 2.2567902993276006
Validation loss: 2.0394874902105293
Epoch: 17| Step: 14
Training loss: 2.2189909038589346
Validation loss: 2.0188021350613647
Epoch: 17| Step: 15
Training loss: 2.7919861245398057
Validation loss: 2.079699558108108
Epoch: 17| Step: 16
Training loss: 2.999720560410879
Validation loss: 2.0272015863089687
Epoch: 17| Step: 17
Training loss: 2.411689456110559
Validation loss: 2.129813141789257
Epoch: 17| Step: 18
Training loss: 2.6076663699157434
Validation loss: 2.0294540732182145
Epoch: 17| Step: 19
Training loss: 2.2029098513907672
Validation loss: 2.014384173078687
Epoch: 18| Step: 0
Training loss: 3.094043602160893
Validation loss: 2.039436488638094
Epoch: 18| Step: 1
Training loss: 2.685804852665957
Validation loss: 2.063427596466978
Epoch: 18| Step: 2
Training loss: 2.270561050283111
Validation loss: 2.0410735651793503
Epoch: 18| Step: 3
Training loss: 2.540311817042864
Validation loss: 2.086393147957235
Epoch: 18| Step: 4
Training loss: 2.7057401322163104
Validation loss: 2.0905176169561663
Epoch: 18| Step: 5
Training loss: 2.3620459993293945
Validation loss: 2.0542383396740735
Epoch: 18| Step: 6
Training loss: 2.5978300796514193
Validation loss: 2.1087683615102724
Epoch: 18| Step: 7
Training loss: 3.112369801199553
Validation loss: 2.0785652844509324
Epoch: 18| Step: 8
Training loss: 2.1839049088593443
Validation loss: 2.103819761493536
Epoch: 18| Step: 9
Training loss: 2.3854396657931645
Validation loss: 2.1096177179744027
Epoch: 18| Step: 10
Training loss: 2.766085656374082
Validation loss: 2.0635369995535493
Epoch: 18| Step: 11
Training loss: 2.6119958199413555
Validation loss: 2.0479628569139354
Epoch: 18| Step: 12
Training loss: 2.887435885951998
Validation loss: 2.123648586959521
Epoch: 18| Step: 13
Training loss: 2.1271666532581888
Validation loss: 2.085295371194829
Epoch: 18| Step: 14
Training loss: 2.984146508861879
Validation loss: 2.061111610564982
Epoch: 18| Step: 15
Training loss: 1.914660800145618
Validation loss: 2.083195330974959
Epoch: 18| Step: 16
Training loss: 3.6377019976868104
Validation loss: 2.114479743331561
Epoch: 18| Step: 17
Training loss: 2.1390388348136224
Validation loss: 2.1259563259235774
Epoch: 18| Step: 18
Training loss: 2.7056846186642427
Validation loss: 2.1141235004136667
Epoch: 18| Step: 19
Training loss: 2.4049794198977743
Validation loss: 2.0813247820228735
Epoch: 19| Step: 0
Training loss: 2.4516678874386417
Validation loss: 2.040088514321211
Epoch: 19| Step: 1
Training loss: 2.8019639076015865
Validation loss: 2.0741498699601255
Epoch: 19| Step: 2
Training loss: 2.6671525592001393
Validation loss: 2.0522585494015555
Epoch: 19| Step: 3
Training loss: 3.0159380656391943
Validation loss: 2.0845319095580535
Epoch: 19| Step: 4
Training loss: 2.742760231656149
Validation loss: 2.07120818162792
Epoch: 19| Step: 5
Training loss: 2.0882683350762723
Validation loss: 2.0452864886482156
Epoch: 19| Step: 6
Training loss: 2.052203050661659
Validation loss: 2.091316837091674
Epoch: 19| Step: 7
Training loss: 2.616632658945996
Validation loss: 2.072664626347163
Epoch: 19| Step: 8
Training loss: 2.7006408213509743
Validation loss: 2.0124891349837726
Epoch: 19| Step: 9
Training loss: 2.876218952009722
Validation loss: 2.0651735337674353
Epoch: 19| Step: 10
Training loss: 2.755082548812112
Validation loss: 2.10690746192038
Epoch: 19| Step: 11
Training loss: 2.97555821414924
Validation loss: 2.060668658842661
Epoch: 19| Step: 12
Training loss: 2.5108717087848342
Validation loss: 2.0618663206271126
Epoch: 19| Step: 13
Training loss: 2.978142106446394
Validation loss: 2.0381288931832646
Epoch: 19| Step: 14
Training loss: 2.5678417075739404
Validation loss: 2.0832910990414475
Epoch: 19| Step: 15
Training loss: 2.6867785705313807
Validation loss: 2.0880047204090113
Epoch: 19| Step: 16
Training loss: 2.4503786300494514
Validation loss: 2.0639261006804066
Epoch: 19| Step: 17
Training loss: 2.274025647618472
Validation loss: 2.0545899011140145
Epoch: 19| Step: 18
Training loss: 2.637523025484505
Validation loss: 2.0308728541170487
Epoch: 19| Step: 19
Training loss: 2.590273630129232
Validation loss: 2.101247761588061
Epoch: 20| Step: 0
Training loss: 2.160084949165163
Validation loss: 2.13219796899236
Epoch: 20| Step: 1
Training loss: 3.014021214765523
Validation loss: 2.0983795112368995
Epoch: 20| Step: 2
Training loss: 2.6849036871828833
Validation loss: 1.9958045088686234
Epoch: 20| Step: 3
Training loss: 2.869540296416196
Validation loss: 2.114583764981747
Epoch: 20| Step: 4
Training loss: 2.3260527739634766
Validation loss: 2.0425084938034006
Epoch: 20| Step: 5
Training loss: 2.467034721838366
Validation loss: 2.1293211074346545
Epoch: 20| Step: 6
Training loss: 2.2183637685811175
Validation loss: 2.0857994631882857
Epoch: 20| Step: 7
Training loss: 3.283505491077565
Validation loss: 2.0691361754078024
Epoch: 20| Step: 8
Training loss: 2.4349876563290027
Validation loss: 2.090286087829758
Epoch: 20| Step: 9
Training loss: 2.6426624811866226
Validation loss: 2.0312102629429143
Epoch: 20| Step: 10
Training loss: 2.2943423054734136
Validation loss: 2.0684508796863565
Epoch: 20| Step: 11
Training loss: 2.6314619545278326
Validation loss: 2.083933048865438
Epoch: 20| Step: 12
Training loss: 2.90468300854447
Validation loss: 2.0256886981649855
Epoch: 20| Step: 13
Training loss: 2.8120201549214703
Validation loss: 2.1002618150285772
Epoch: 20| Step: 14
Training loss: 3.047820741643668
Validation loss: 2.0621038794555973
Epoch: 20| Step: 15
Training loss: 2.2696839903287396
Validation loss: 2.1123453312146108
Epoch: 20| Step: 16
Training loss: 2.7677212976265237
Validation loss: 2.020575682022384
Epoch: 20| Step: 17
Training loss: 2.218299605096203
Validation loss: 2.0642240689207862
Epoch: 20| Step: 18
Training loss: 2.6395955082211904
Validation loss: 2.066676316056968
Epoch: 20| Step: 19
Training loss: 2.630563924691747
Validation loss: 2.0526697152160414
Epoch: 21| Step: 0
Training loss: 3.078731573919371
Validation loss: 2.071435035868727
Epoch: 21| Step: 1
Training loss: 2.676485244696052
Validation loss: 2.0713258336291256
Epoch: 21| Step: 2
Training loss: 2.448086855768694
Validation loss: 2.093619460752389
Epoch: 21| Step: 3
Training loss: 2.1471885796406673
Validation loss: 2.0861339893417474
Epoch: 21| Step: 4
Training loss: 2.734644326161391
Validation loss: 2.054745938245464
Epoch: 21| Step: 5
Training loss: 2.3672864030880603
Validation loss: 2.098683505714585
Epoch: 21| Step: 6
Training loss: 2.8655417393826323
Validation loss: 2.0743227925922882
Epoch: 21| Step: 7
Training loss: 2.549766163295723
Validation loss: 2.055466990528596
Epoch: 21| Step: 8
Training loss: 2.69153956732242
Validation loss: 2.0588067064667186
Epoch: 21| Step: 9
Training loss: 3.0135022534086198
Validation loss: 2.100426152960625
Epoch: 21| Step: 10
Training loss: 2.730533539053851
Validation loss: 2.0671143519617945
Epoch: 21| Step: 11
Training loss: 2.883696795213754
Validation loss: 2.0236848095502995
Epoch: 21| Step: 12
Training loss: 2.375391074658731
Validation loss: 2.0696143921444055
Epoch: 21| Step: 13
Training loss: 2.432762236617987
Validation loss: 2.0782303272599467
Epoch: 21| Step: 14
Training loss: 2.567730844849077
Validation loss: 2.1274659004245575
Epoch: 21| Step: 15
Training loss: 2.306552455680218
Validation loss: 2.0345067725028683
Epoch: 21| Step: 16
Training loss: 3.068097817911919
Validation loss: 2.0373783131426295
Epoch: 21| Step: 17
Training loss: 2.4675717982829593
Validation loss: 2.0197141441055146
Epoch: 21| Step: 18
Training loss: 2.858720214581831
Validation loss: 2.074893194559694
Epoch: 21| Step: 19
Training loss: 2.113690969408763
Validation loss: 2.0569764771262338
Epoch: 22| Step: 0
Training loss: 2.268629095045338
Validation loss: 2.075550934482287
Epoch: 22| Step: 1
Training loss: 3.007862913031255
Validation loss: 2.078328435545333
Epoch: 22| Step: 2
Training loss: 2.314989554132413
Validation loss: 2.1267885334535443
Epoch: 22| Step: 3
Training loss: 2.241338482720161
Validation loss: 2.1032415256265713
Epoch: 22| Step: 4
Training loss: 2.400154816084645
Validation loss: 2.0540085445360416
Epoch: 22| Step: 5
Training loss: 2.891096746767552
Validation loss: 2.0351911370728226
Epoch: 22| Step: 6
Training loss: 3.3211657336610494
Validation loss: 2.136436529795179
Epoch: 22| Step: 7
Training loss: 2.45333132513973
Validation loss: 2.134227326693921
Epoch: 22| Step: 8
Training loss: 2.958651422583682
Validation loss: 2.10189595570352
Epoch: 22| Step: 9
Training loss: 2.8304915669148314
Validation loss: 2.08964370251611
Epoch: 22| Step: 10
Training loss: 2.0938599970377254
Validation loss: 2.079910021557927
Epoch: 22| Step: 11
Training loss: 2.803577341519508
Validation loss: 2.092272708576827
Epoch: 22| Step: 12
Training loss: 3.2199746181838216
Validation loss: 2.1087097121671423
Epoch: 22| Step: 13
Training loss: 2.6686794512891407
Validation loss: 2.11380117290106
Epoch: 22| Step: 14
Training loss: 2.0492005859686904
Validation loss: 2.118567845001732
Epoch: 22| Step: 15
Training loss: 2.525545355945956
Validation loss: 2.029900603298618
Epoch: 22| Step: 16
Training loss: 2.557119535931968
Validation loss: 2.0914382842464
Epoch: 22| Step: 17
Training loss: 2.2064527985732085
Validation loss: 2.0592639386652003
Epoch: 22| Step: 18
Training loss: 2.696411085838999
Validation loss: 2.0795530018797552
Epoch: 22| Step: 19
Training loss: 2.7236858593906406
Validation loss: 2.1090621830984304
Epoch: 23| Step: 0
Training loss: 2.1521888857200464
Validation loss: 2.108703933844253
Epoch: 23| Step: 1
Training loss: 2.718217644146566
Validation loss: 2.1065329015240613
Epoch: 23| Step: 2
Training loss: 2.6389235031356275
Validation loss: 2.0858876764417627
Epoch: 23| Step: 3
Training loss: 3.1032329068049265
Validation loss: 2.081137996015804
Epoch: 23| Step: 4
Training loss: 3.1132604198644436
Validation loss: 2.0772449684159517
Epoch: 23| Step: 5
Training loss: 2.103052001411779
Validation loss: 2.0270930739936226
Epoch: 23| Step: 6
Training loss: 2.3342405553706143
Validation loss: 2.1650236029616985
Epoch: 23| Step: 7
Training loss: 2.188711212529096
Validation loss: 2.1229351949415816
Epoch: 23| Step: 8
Training loss: 2.6521306127832323
Validation loss: 2.112834154729479
Epoch: 23| Step: 9
Training loss: 2.7822717225790403
Validation loss: 2.0966624092182133
Epoch: 23| Step: 10
Training loss: 2.3909044289436343
Validation loss: 2.0784769719318366
Epoch: 23| Step: 11
Training loss: 2.329136980535211
Validation loss: 2.03911293408437
Epoch: 23| Step: 12
Training loss: 2.713974540484211
Validation loss: 2.115595866839831
Epoch: 23| Step: 13
Training loss: 2.3741774891528222
Validation loss: 2.121103718522314
Epoch: 23| Step: 14
Training loss: 2.664015783532385
Validation loss: 2.061471714058977
Epoch: 23| Step: 15
Training loss: 3.1538248848689974
Validation loss: 2.108913123366278
Epoch: 23| Step: 16
Training loss: 2.3616489795066467
Validation loss: 2.0808870538169426
Epoch: 23| Step: 17
Training loss: 3.36855208854157
Validation loss: 2.119404181242322
Epoch: 23| Step: 18
Training loss: 2.743636397875334
Validation loss: 2.1249550160121675
Epoch: 23| Step: 19
Training loss: 2.401627298844713
Validation loss: 2.0762761056426124
Epoch: 24| Step: 0
Training loss: 2.5185060293016783
Validation loss: 2.0786567213167473
Epoch: 24| Step: 1
Training loss: 2.458025465831025
Validation loss: 2.0845037451202444
Epoch: 24| Step: 2
Training loss: 2.7665067657161835
Validation loss: 2.0876497158000396
Epoch: 24| Step: 3
Training loss: 2.568748578073521
Validation loss: 2.1490946872850594
Epoch: 24| Step: 4
Training loss: 2.86476669187083
Validation loss: 1.993961424530336
Epoch: 24| Step: 5
Training loss: 2.6074685996223153
Validation loss: 2.07221905629072
Epoch: 24| Step: 6
Training loss: 2.825829854963257
Validation loss: 2.068652367531307
Epoch: 24| Step: 7
Training loss: 2.657363388985749
Validation loss: 2.1084102311896307
Epoch: 24| Step: 8
Training loss: 2.5566339106577227
Validation loss: 2.073623402447378
Epoch: 24| Step: 9
Training loss: 3.0662491873589617
Validation loss: 2.074350271627165
Epoch: 24| Step: 10
Training loss: 2.408615435893344
Validation loss: 2.0147999229159548
Epoch: 24| Step: 11
Training loss: 2.2904709788917352
Validation loss: 2.065660730163349
Epoch: 24| Step: 12
Training loss: 2.950903647431712
Validation loss: 2.072295675865362
Epoch: 24| Step: 13
Training loss: 2.8222312423565246
Validation loss: 2.0750821016575616
Epoch: 24| Step: 14
Training loss: 2.2519810750108515
Validation loss: 2.0898199937425828
Epoch: 24| Step: 15
Training loss: 2.1313954770730605
Validation loss: 2.10305064112434
Epoch: 24| Step: 16
Training loss: 2.4069642827451023
Validation loss: 2.0770767589480252
Epoch: 24| Step: 17
Training loss: 3.1938833011048886
Validation loss: 2.0448933952907318
Epoch: 24| Step: 18
Training loss: 2.740602127379924
Validation loss: 2.078075356755731
Epoch: 24| Step: 19
Training loss: 2.2554991595521012
Validation loss: 2.045344782309292
Epoch: 25| Step: 0
Training loss: 3.085543604954195
Validation loss: 2.0988796860010437
Epoch: 25| Step: 1
Training loss: 2.6062142422279106
Validation loss: 2.051084271976368
Epoch: 25| Step: 2
Training loss: 2.4572843048343342
Validation loss: 2.061541301138804
Epoch: 25| Step: 3
Training loss: 2.111750077986555
Validation loss: 2.0644714227300365
Epoch: 25| Step: 4
Training loss: 2.9563787387938616
Validation loss: 2.0477065972534474
Epoch: 25| Step: 5
Training loss: 2.860254371374988
Validation loss: 2.1098308585030545
Epoch: 25| Step: 6
Training loss: 2.4942292367224477
Validation loss: 2.0476115361299647
Epoch: 25| Step: 7
Training loss: 2.048255745908448
Validation loss: 2.052985635642503
Epoch: 25| Step: 8
Training loss: 2.611887196487025
Validation loss: 2.0347524790022504
Epoch: 25| Step: 9
Training loss: 2.6092545715683797
Validation loss: 2.078965860466602
Epoch: 25| Step: 10
Training loss: 2.677021446452767
Validation loss: 2.1043362664356895
Epoch: 25| Step: 11
Training loss: 2.6141091533540473
Validation loss: 2.0323554788292544
Epoch: 25| Step: 12
Training loss: 3.352303091890329
Validation loss: 2.095143972163992
Epoch: 25| Step: 13
Training loss: 2.3091880175474064
Validation loss: 2.030638344375407
Epoch: 25| Step: 14
Training loss: 2.5577576647119686
Validation loss: 2.129552182930784
Epoch: 25| Step: 15
Training loss: 2.787152830665957
Validation loss: 2.0780078705971246
Epoch: 25| Step: 16
Training loss: 2.8407936239185503
Validation loss: 2.005996277820157
Epoch: 25| Step: 17
Training loss: 2.5769608152146697
Validation loss: 2.0931815002076726
Epoch: 25| Step: 18
Training loss: 2.228639510620401
Validation loss: 2.08683016579437
Epoch: 25| Step: 19
Training loss: 2.569869075661256
Validation loss: 2.1037413479112406
Epoch: 26| Step: 0
Training loss: 2.7444903928005133
Validation loss: 2.0727761384646284
Epoch: 26| Step: 1
Training loss: 1.8489116895639646
Validation loss: 2.1021110594198142
Epoch: 26| Step: 2
Training loss: 2.503222867693126
Validation loss: 2.085117933989106
Epoch: 26| Step: 3
Training loss: 2.8554864509754028
Validation loss: 2.0816537248842857
Epoch: 26| Step: 4
Training loss: 2.719674490356538
Validation loss: 2.0658242720266586
Epoch: 26| Step: 5
Training loss: 2.3614951201676626
Validation loss: 2.063686809797828
Epoch: 26| Step: 6
Training loss: 2.188257140871519
Validation loss: 2.101509553119245
Epoch: 26| Step: 7
Training loss: 2.6342488793787693
Validation loss: 2.0249722462320285
Epoch: 26| Step: 8
Training loss: 2.843691647109069
Validation loss: 2.103416169005569
Epoch: 26| Step: 9
Training loss: 2.2024660680713923
Validation loss: 2.106079071081073
Epoch: 26| Step: 10
Training loss: 2.9421207527777953
Validation loss: 2.0227376085441557
Epoch: 26| Step: 11
Training loss: 2.4361897394860983
Validation loss: 2.0882744114069745
Epoch: 26| Step: 12
Training loss: 3.09793547517924
Validation loss: 2.076822995036875
Epoch: 26| Step: 13
Training loss: 2.232663012252798
Validation loss: 2.0395734822754448
Epoch: 26| Step: 14
Training loss: 2.668878135017175
Validation loss: 2.0664945325937216
Epoch: 26| Step: 15
Training loss: 3.0894721153718407
Validation loss: 2.024000326156578
Epoch: 26| Step: 16
Training loss: 2.37966380718056
Validation loss: 2.1242567193867314
Epoch: 26| Step: 17
Training loss: 2.3097857449405383
Validation loss: 2.0803345479790445
Epoch: 26| Step: 18
Training loss: 3.2191139682054457
Validation loss: 2.1161427555565244
Epoch: 26| Step: 19
Training loss: 3.085196490591658
Validation loss: 2.103195494387851
Epoch: 27| Step: 0
Training loss: 2.6866388050019823
Validation loss: 2.1125068352653527
Epoch: 27| Step: 1
Training loss: 2.2990130380108966
Validation loss: 2.073976440075067
Epoch: 27| Step: 2
Training loss: 2.2302713123060522
Validation loss: 2.0457418512301464
Epoch: 27| Step: 3
Training loss: 2.758163127276906
Validation loss: 2.0755252760468754
Epoch: 27| Step: 4
Training loss: 2.406307764722383
Validation loss: 2.111773148805397
Epoch: 27| Step: 5
Training loss: 2.728934319387561
Validation loss: 2.101280530754811
Epoch: 27| Step: 6
Training loss: 3.0115814771427383
Validation loss: 2.1151209880935338
Epoch: 27| Step: 7
Training loss: 2.794941409593901
Validation loss: 2.0743041906296336
Epoch: 27| Step: 8
Training loss: 2.954882225103633
Validation loss: 2.109397103758857
Epoch: 27| Step: 9
Training loss: 2.7575742278220257
Validation loss: 2.0991982014199975
Epoch: 27| Step: 10
Training loss: 2.594551238431266
Validation loss: 2.0888515464016173
Epoch: 27| Step: 11
Training loss: 2.421938593860133
Validation loss: 2.1031976158471997
Epoch: 27| Step: 12
Training loss: 2.57501162183787
Validation loss: 2.054383970482468
Epoch: 27| Step: 13
Training loss: 2.7204016568441776
Validation loss: 2.1042468377936236
Epoch: 27| Step: 14
Training loss: 2.381167184586103
Validation loss: 2.104057557269379
Epoch: 27| Step: 15
Training loss: 2.3019886831673215
Validation loss: 2.0898090225098302
Epoch: 27| Step: 16
Training loss: 2.4169034074603917
Validation loss: 2.0351950739757365
Epoch: 27| Step: 17
Training loss: 2.794128518629625
Validation loss: 2.066350458597095
Epoch: 27| Step: 18
Training loss: 2.6886710343587508
Validation loss: 2.085038937874038
Epoch: 27| Step: 19
Training loss: 2.9530208508730373
Validation loss: 2.0919598459847526
Epoch: 28| Step: 0
Training loss: 3.225451853243631
Validation loss: 2.0542980204973373
Epoch: 28| Step: 1
Training loss: 2.6224199967595383
Validation loss: 2.125401794049914
Epoch: 28| Step: 2
Training loss: 3.230010547915972
Validation loss: 2.0614276677498014
Epoch: 28| Step: 3
Training loss: 2.5305379172067632
Validation loss: 2.0787978387069543
Epoch: 28| Step: 4
Training loss: 2.705333182639313
Validation loss: 2.1293184189435994
Epoch: 28| Step: 5
Training loss: 2.6377358064505527
Validation loss: 2.079439844755349
Epoch: 28| Step: 6
Training loss: 2.8549894460292626
Validation loss: 2.062164148583112
Epoch: 28| Step: 7
Training loss: 2.2555191377958055
Validation loss: 2.0425144473386494
Epoch: 28| Step: 8
Training loss: 2.919240161327402
Validation loss: 2.0807043551077133
Epoch: 28| Step: 9
Training loss: 2.388434409988403
Validation loss: 2.059962118300242
Epoch: 28| Step: 10
Training loss: 1.8213090910845786
Validation loss: 2.11294407464075
Epoch: 28| Step: 11
Training loss: 2.57125790725998
Validation loss: 2.0959584662669215
Epoch: 28| Step: 12
Training loss: 2.3546246333548506
Validation loss: 2.106975196718799
Epoch: 28| Step: 13
Training loss: 2.916906201653664
Validation loss: 2.1408056612889776
Epoch: 28| Step: 14
Training loss: 2.6273626866198425
Validation loss: 2.0643288776359094
Epoch: 28| Step: 15
Training loss: 2.720033101693857
Validation loss: 2.0923627434726177
Epoch: 28| Step: 16
Training loss: 2.380982243259808
Validation loss: 2.0100051204790743
Epoch: 28| Step: 17
Training loss: 1.7755747281040546
Validation loss: 2.050315212910143
Epoch: 28| Step: 18
Training loss: 3.148797632260712
Validation loss: 2.0599798297461573
Epoch: 28| Step: 19
Training loss: 2.432909433029962
Validation loss: 2.0846289307642643
Epoch: 29| Step: 0
Training loss: 2.9463775894576383
Validation loss: 2.0921912704362033
Epoch: 29| Step: 1
Training loss: 2.27506263562846
Validation loss: 2.0778150669921223
Epoch: 29| Step: 2
Training loss: 2.24308753474705
Validation loss: 2.0871380524786263
Epoch: 29| Step: 3
Training loss: 2.8023514648875807
Validation loss: 2.0538889377508247
Epoch: 29| Step: 4
Training loss: 2.243476204916189
Validation loss: 2.0704066108388894
Epoch: 29| Step: 5
Training loss: 2.5389629637941855
Validation loss: 2.1126080249311645
Epoch: 29| Step: 6
Training loss: 2.8376968853237434
Validation loss: 2.0833107148607155
Epoch: 29| Step: 7
Training loss: 2.680365918643331
Validation loss: 2.064395701046344
Epoch: 29| Step: 8
Training loss: 2.799871107949502
Validation loss: 2.0617971932709356
Epoch: 29| Step: 9
Training loss: 2.3122760561170854
Validation loss: 2.065785988211764
Epoch: 29| Step: 10
Training loss: 2.8540610040936216
Validation loss: 2.1013915016474414
Epoch: 29| Step: 11
Training loss: 2.4056558246971687
Validation loss: 2.055453417307123
Epoch: 29| Step: 12
Training loss: 2.500235737176612
Validation loss: 2.0878894899073854
Epoch: 29| Step: 13
Training loss: 2.5828669547486602
Validation loss: 2.0682952375389374
Epoch: 29| Step: 14
Training loss: 2.667344027162736
Validation loss: 2.140693416399637
Epoch: 29| Step: 15
Training loss: 2.987957147712286
Validation loss: 2.0924909357580193
Epoch: 29| Step: 16
Training loss: 2.8129368760626994
Validation loss: 2.1274890777486757
Epoch: 29| Step: 17
Training loss: 2.3748604582901494
Validation loss: 2.0733070225098755
Epoch: 29| Step: 18
Training loss: 2.7431232127498664
Validation loss: 2.1150619555272003
Epoch: 29| Step: 19
Training loss: 2.8885866968932663
Validation loss: 1.9840990312490558
Epoch: 30| Step: 0
Training loss: 2.7575316894038417
Validation loss: 2.02077173756163
Epoch: 30| Step: 1
Training loss: 2.5150541996661424
Validation loss: 2.066800323914432
Epoch: 30| Step: 2
Training loss: 2.1060399570496515
Validation loss: 2.0913859192498414
Epoch: 30| Step: 3
Training loss: 2.237246502203343
Validation loss: 2.0647440211183277
Epoch: 30| Step: 4
Training loss: 2.3957190002582194
Validation loss: 2.0891774085142574
Epoch: 30| Step: 5
Training loss: 2.4189242199196457
Validation loss: 2.0415998845864327
Epoch: 30| Step: 6
Training loss: 2.7940670814898985
Validation loss: 2.0697202879453376
Epoch: 30| Step: 7
Training loss: 2.8126712323091674
Validation loss: 2.08133475938834
Epoch: 30| Step: 8
Training loss: 2.744490479672224
Validation loss: 2.110269412016817
Epoch: 30| Step: 9
Training loss: 2.847249319883174
Validation loss: 2.05411456206841
Epoch: 30| Step: 10
Training loss: 2.440796408208444
Validation loss: 2.0996703293606824
Epoch: 30| Step: 11
Training loss: 2.8204212114933647
Validation loss: 2.0544594438185713
Epoch: 30| Step: 12
Training loss: 2.7029833453332497
Validation loss: 2.103857817684622
Epoch: 30| Step: 13
Training loss: 2.920222340310015
Validation loss: 2.1112738831820135
Epoch: 30| Step: 14
Training loss: 3.0230070689955024
Validation loss: 2.066205862661689
Epoch: 30| Step: 15
Training loss: 2.945238512157148
Validation loss: 2.087977846038582
Epoch: 30| Step: 16
Training loss: 1.967432035074485
Validation loss: 2.0372981925923566
Epoch: 30| Step: 17
Training loss: 2.7386093922556443
Validation loss: 2.108403614258621
Epoch: 30| Step: 18
Training loss: 2.4160177960150917
Validation loss: 2.143017427367405
Epoch: 30| Step: 19
Training loss: 2.7964123391172895
Validation loss: 2.0672346748192885
