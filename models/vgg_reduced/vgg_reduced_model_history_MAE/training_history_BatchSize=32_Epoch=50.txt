Epoch: 1| Step: 0
Training loss: 4.7378339767456055
Validation loss: 5.054247736930847
Epoch: 1| Step: 1
Training loss: 4.831638336181641
Validation loss: 5.051169514656067
Epoch: 1| Step: 2
Training loss: 5.350438117980957
Validation loss: 5.05348813533783
Epoch: 1| Step: 3
Training loss: 5.679754734039307
Validation loss: 5.021161198616028
Epoch: 1| Step: 4
Training loss: 4.6287055015563965
Validation loss: 4.8931721448898315
Epoch: 1| Step: 5
Training loss: 5.150362014770508
Validation loss: 4.828115463256836
Epoch: 1| Step: 6
Training loss: 4.51086950302124
Validation loss: 4.473946928977966
Epoch: 1| Step: 7
Training loss: 4.9313530921936035
Validation loss: 4.38894510269165
Epoch: 1| Step: 8
Training loss: 4.1834397315979
Validation loss: 4.309041202068329
Epoch: 1| Step: 9
Training loss: 4.935602188110352
Validation loss: 4.303820013999939
Epoch: 2| Step: 0
Training loss: 4.503570556640625
Validation loss: 4.372662425041199
Epoch: 2| Step: 1
Training loss: 4.86817741394043
Validation loss: 4.237525582313538
Epoch: 2| Step: 2
Training loss: 4.24412202835083
Validation loss: 4.090505123138428
Epoch: 2| Step: 3
Training loss: 4.813208103179932
Validation loss: 4.106965243816376
Epoch: 2| Step: 4
Training loss: 4.025588035583496
Validation loss: 4.060545384883881
Epoch: 2| Step: 5
Training loss: 4.340636253356934
Validation loss: 3.9655741453170776
Epoch: 2| Step: 6
Training loss: 3.5802690982818604
Validation loss: 3.948849320411682
Epoch: 2| Step: 7
Training loss: 3.3417344093322754
Validation loss: 3.8226314783096313
Epoch: 2| Step: 8
Training loss: 4.685764312744141
Validation loss: 3.8217767477035522
Epoch: 2| Step: 9
Training loss: 3.9863510131835938
Validation loss: 3.8280497789382935
Epoch: 3| Step: 0
Training loss: 4.177241802215576
Validation loss: 3.7082356214523315
Epoch: 3| Step: 1
Training loss: 4.199177265167236
Validation loss: 3.6919902563095093
Epoch: 3| Step: 2
Training loss: 4.205522060394287
Validation loss: 3.6662113666534424
Epoch: 3| Step: 3
Training loss: 3.754948139190674
Validation loss: 3.6446422934532166
Epoch: 3| Step: 4
Training loss: 3.6374363899230957
Validation loss: 3.628502309322357
Epoch: 3| Step: 5
Training loss: 3.5212435722351074
Validation loss: 3.619499444961548
Epoch: 3| Step: 6
Training loss: 3.988388776779175
Validation loss: 3.4758278131484985
Epoch: 3| Step: 7
Training loss: 3.5583724975585938
Validation loss: 3.575253188610077
Epoch: 3| Step: 8
Training loss: 3.580673933029175
Validation loss: 3.4269402623176575
Epoch: 3| Step: 9
Training loss: 3.885807991027832
Validation loss: 3.34505432844162
Epoch: 4| Step: 0
Training loss: 4.190372943878174
Validation loss: 3.2667457461357117
Epoch: 4| Step: 1
Training loss: 3.4501991271972656
Validation loss: 3.28711998462677
Epoch: 4| Step: 2
Training loss: 3.2649383544921875
Validation loss: 3.2712197303771973
Epoch: 4| Step: 3
Training loss: 2.812009572982788
Validation loss: 3.1268272399902344
Epoch: 4| Step: 4
Training loss: 3.3004584312438965
Validation loss: 3.0723171830177307
Epoch: 4| Step: 5
Training loss: 3.344639301300049
Validation loss: 3.0771279335021973
Epoch: 4| Step: 6
Training loss: 4.462364196777344
Validation loss: 2.98737633228302
Epoch: 4| Step: 7
Training loss: 3.8614635467529297
Validation loss: 2.9832985401153564
Epoch: 4| Step: 8
Training loss: 2.961697816848755
Validation loss: 2.974868595600128
Epoch: 4| Step: 9
Training loss: 3.0808708667755127
Validation loss: 2.936719238758087
Epoch: 5| Step: 0
Training loss: 3.630497455596924
Validation loss: 2.8748629093170166
Epoch: 5| Step: 1
Training loss: 3.0298256874084473
Validation loss: 2.854853570461273
Epoch: 5| Step: 2
Training loss: 3.682345151901245
Validation loss: 2.7405661940574646
Epoch: 5| Step: 3
Training loss: 3.418247699737549
Validation loss: 2.7703399062156677
Epoch: 5| Step: 4
Training loss: 3.1218314170837402
Validation loss: 2.654059588909149
Epoch: 5| Step: 5
Training loss: 2.6879663467407227
Validation loss: 2.6770458817481995
Epoch: 5| Step: 6
Training loss: 2.992335796356201
Validation loss: 2.6837140321731567
Epoch: 5| Step: 7
Training loss: 2.9907546043395996
Validation loss: 2.619863450527191
Epoch: 5| Step: 8
Training loss: 2.7955517768859863
Validation loss: 2.6213080883026123
Epoch: 5| Step: 9
Training loss: 3.527637243270874
Validation loss: 2.56448757648468
Epoch: 6| Step: 0
Training loss: 3.29986310005188
Validation loss: 2.619020700454712
Epoch: 6| Step: 1
Training loss: 3.0995936393737793
Validation loss: 2.506624698638916
Epoch: 6| Step: 2
Training loss: 2.6690421104431152
Validation loss: 2.487821102142334
Epoch: 6| Step: 3
Training loss: 2.5832223892211914
Validation loss: 2.468553364276886
Epoch: 6| Step: 4
Training loss: 3.262904644012451
Validation loss: 2.429752230644226
Epoch: 6| Step: 5
Training loss: 3.706815242767334
Validation loss: 2.457257628440857
Epoch: 6| Step: 6
Training loss: 2.634207248687744
Validation loss: 2.435148298740387
Epoch: 6| Step: 7
Training loss: 2.700063705444336
Validation loss: 2.415811598300934
Epoch: 6| Step: 8
Training loss: 2.805485248565674
Validation loss: 2.3076112270355225
Epoch: 6| Step: 9
Training loss: 2.8569161891937256
Validation loss: 2.2853743135929108
Epoch: 7| Step: 0
Training loss: 2.739602565765381
Validation loss: 2.3729043006896973
Epoch: 7| Step: 1
Training loss: 2.9577975273132324
Validation loss: 2.351773738861084
Epoch: 7| Step: 2
Training loss: 2.6682822704315186
Validation loss: 2.3023838996887207
Epoch: 7| Step: 3
Training loss: 2.613339900970459
Validation loss: 2.1807980835437775
Epoch: 7| Step: 4
Training loss: 2.6820931434631348
Validation loss: 2.2685364484786987
Epoch: 7| Step: 5
Training loss: 2.94459867477417
Validation loss: 2.1781925559043884
Epoch: 7| Step: 6
Training loss: 2.8818421363830566
Validation loss: 2.243729531764984
Epoch: 7| Step: 7
Training loss: 2.980762481689453
Validation loss: 2.2049811482429504
Epoch: 7| Step: 8
Training loss: 2.441842794418335
Validation loss: 2.158736079931259
Epoch: 7| Step: 9
Training loss: 2.764881134033203
Validation loss: 2.1663878560066223
Epoch: 8| Step: 0
Training loss: 3.2033603191375732
Validation loss: 2.1715768575668335
Epoch: 8| Step: 1
Training loss: 2.689945697784424
Validation loss: 2.1198709905147552
Epoch: 8| Step: 2
Training loss: 2.366694450378418
Validation loss: 2.126156836748123
Epoch: 8| Step: 3
Training loss: 2.8379404544830322
Validation loss: 2.1333079040050507
Epoch: 8| Step: 4
Training loss: 2.404622793197632
Validation loss: 2.151716470718384
Epoch: 8| Step: 5
Training loss: 2.876469612121582
Validation loss: 2.029712975025177
Epoch: 8| Step: 6
Training loss: 2.319558620452881
Validation loss: 2.0427064895629883
Epoch: 8| Step: 7
Training loss: 2.0329251289367676
Validation loss: 2.006346434354782
Epoch: 8| Step: 8
Training loss: 2.691875457763672
Validation loss: 1.9617190062999725
Epoch: 8| Step: 9
Training loss: 2.6049857139587402
Validation loss: 1.9260795414447784
Epoch: 9| Step: 0
Training loss: 2.4030075073242188
Validation loss: 1.965826153755188
Epoch: 9| Step: 1
Training loss: 2.5435588359832764
Validation loss: 1.980314940214157
Epoch: 9| Step: 2
Training loss: 2.664771556854248
Validation loss: 1.9991772174835205
Epoch: 9| Step: 3
Training loss: 1.9667552709579468
Validation loss: 1.9131315648555756
Epoch: 9| Step: 4
Training loss: 2.5643563270568848
Validation loss: 1.901707410812378
Epoch: 9| Step: 5
Training loss: 2.3009591102600098
Validation loss: 1.874035507440567
Epoch: 9| Step: 6
Training loss: 2.4553518295288086
Validation loss: 1.9817437529563904
Epoch: 9| Step: 7
Training loss: 2.2702860832214355
Validation loss: 1.8816170692443848
Epoch: 9| Step: 8
Training loss: 2.574069023132324
Validation loss: 1.8497933745384216
Epoch: 9| Step: 9
Training loss: 2.756270170211792
Validation loss: 1.8743321895599365
Epoch: 10| Step: 0
Training loss: 2.098559856414795
Validation loss: 1.8893953561782837
Epoch: 10| Step: 1
Training loss: 2.389772415161133
Validation loss: 1.7866459488868713
Epoch: 10| Step: 2
Training loss: 2.457336902618408
Validation loss: 1.839911550283432
Epoch: 10| Step: 3
Training loss: 2.3225009441375732
Validation loss: 1.8325526416301727
Epoch: 10| Step: 4
Training loss: 2.787156343460083
Validation loss: 1.7862305045127869
Epoch: 10| Step: 5
Training loss: 2.390625
Validation loss: 1.811020016670227
Epoch: 10| Step: 6
Training loss: 2.296018600463867
Validation loss: 1.8037558794021606
Epoch: 10| Step: 7
Training loss: 2.1502456665039062
Validation loss: 1.7845855057239532
Epoch: 10| Step: 8
Training loss: 2.2138400077819824
Validation loss: 1.7623913288116455
Epoch: 10| Step: 9
Training loss: 2.2205142974853516
Validation loss: 1.789450615644455
Epoch: 11| Step: 0
Training loss: 2.269578695297241
Validation loss: 1.7276127934455872
Epoch: 11| Step: 1
Training loss: 2.276822090148926
Validation loss: 1.7224906086921692
Epoch: 11| Step: 2
Training loss: 2.4586265087127686
Validation loss: 1.7254506647586823
Epoch: 11| Step: 3
Training loss: 2.2102036476135254
Validation loss: 1.6636663675308228
Epoch: 11| Step: 4
Training loss: 2.180185079574585
Validation loss: 1.7403915524482727
Epoch: 11| Step: 5
Training loss: 2.266256093978882
Validation loss: 1.715128481388092
Epoch: 11| Step: 6
Training loss: 2.2086005210876465
Validation loss: 1.6971824169158936
Epoch: 11| Step: 7
Training loss: 2.0871591567993164
Validation loss: 1.7068181037902832
Epoch: 11| Step: 8
Training loss: 2.17852783203125
Validation loss: 1.618232637643814
Epoch: 11| Step: 9
Training loss: 2.5865414142608643
Validation loss: 1.6801247894763947
Epoch: 12| Step: 0
Training loss: 1.9367990493774414
Validation loss: 1.604147344827652
Epoch: 12| Step: 1
Training loss: 2.567484140396118
Validation loss: 1.6883211731910706
Epoch: 12| Step: 2
Training loss: 2.484628677368164
Validation loss: 1.6685392558574677
Epoch: 12| Step: 3
Training loss: 2.171875
Validation loss: 1.709982007741928
Epoch: 12| Step: 4
Training loss: 2.0374999046325684
Validation loss: 1.7078061401844025
Epoch: 12| Step: 5
Training loss: 2.3055005073547363
Validation loss: 1.6355415880680084
Epoch: 12| Step: 6
Training loss: 1.7562332153320312
Validation loss: 1.6640583276748657
Epoch: 12| Step: 7
Training loss: 2.6593666076660156
Validation loss: 1.6861333847045898
Epoch: 12| Step: 8
Training loss: 2.5796313285827637
Validation loss: 1.6758375465869904
Epoch: 12| Step: 9
Training loss: 1.9451799392700195
Validation loss: 1.6703124940395355
Epoch: 13| Step: 0
Training loss: 2.475360631942749
Validation loss: 1.6454927623271942
Epoch: 13| Step: 1
Training loss: 1.962499976158142
Validation loss: 1.7127718329429626
Epoch: 13| Step: 2
Training loss: 1.71875
Validation loss: 1.6571187376976013
Epoch: 13| Step: 3
Training loss: 2.026710033416748
Validation loss: 1.6405265629291534
Epoch: 13| Step: 4
Training loss: 2.418957471847534
Validation loss: 1.6766846179962158
Epoch: 13| Step: 5
Training loss: 2.409374952316284
Validation loss: 1.6750962138175964
Epoch: 13| Step: 6
Training loss: 2.6219539642333984
Validation loss: 1.6858881115913391
Epoch: 13| Step: 7
Training loss: 2.375988483428955
Validation loss: 1.6708904504776
Epoch: 13| Step: 8
Training loss: 2.234375
Validation loss: 1.7357281148433685
Epoch: 13| Step: 9
Training loss: 2.174999952316284
Validation loss: 1.6447287499904633
Epoch: 14| Step: 0
Training loss: 1.8219573497772217
Validation loss: 1.7270252108573914
Epoch: 14| Step: 1
Training loss: 2.1573171615600586
Validation loss: 1.6383575797080994
Epoch: 14| Step: 2
Training loss: 2.6574931144714355
Validation loss: 1.71860733628273
Epoch: 14| Step: 3
Training loss: 2.0218749046325684
Validation loss: 1.6429968178272247
Epoch: 14| Step: 4
Training loss: 2.1323306560516357
Validation loss: 1.6999123096466064
Epoch: 14| Step: 5
Training loss: 2.331043243408203
Validation loss: 1.7009364068508148
Epoch: 14| Step: 6
Training loss: 2.2586147785186768
Validation loss: 1.6594383120536804
Epoch: 14| Step: 7
Training loss: 2.730551242828369
Validation loss: 1.6883274614810944
Epoch: 14| Step: 8
Training loss: 1.8871866464614868
Validation loss: 1.7495298981666565
Epoch: 14| Step: 9
Training loss: 2.421875
Validation loss: 1.7084844708442688
Epoch: 15| Step: 0
Training loss: 2.0437498092651367
Validation loss: 1.6604483425617218
Epoch: 15| Step: 1
Training loss: 2.0221762657165527
Validation loss: 1.7163782715797424
Epoch: 15| Step: 2
Training loss: 2.319178819656372
Validation loss: 1.6769604086875916
Epoch: 15| Step: 3
Training loss: 1.8713704347610474
Validation loss: 1.690323919057846
Epoch: 15| Step: 4
Training loss: 2.2731001377105713
Validation loss: 1.6835625171661377
Epoch: 15| Step: 5
Training loss: 2.144380569458008
Validation loss: 1.6211079955101013
Epoch: 15| Step: 6
Training loss: 2.2837677001953125
Validation loss: 1.6672951877117157
Epoch: 15| Step: 7
Training loss: 2.4350011348724365
Validation loss: 1.7179717421531677
Epoch: 15| Step: 8
Training loss: 2.5681469440460205
Validation loss: 1.7310445010662079
Epoch: 15| Step: 9
Training loss: 2.4618773460388184
Validation loss: 1.6845244765281677
Epoch: 16| Step: 0
Training loss: 1.9680696725845337
Validation loss: 1.634242594242096
Epoch: 16| Step: 1
Training loss: 2.5858888626098633
Validation loss: 1.6923564672470093
Epoch: 16| Step: 2
Training loss: 1.884374976158142
Validation loss: 1.673408567905426
Epoch: 16| Step: 3
Training loss: 2.4384381771087646
Validation loss: 1.6690242290496826
Epoch: 16| Step: 4
Training loss: 1.9591178894042969
Validation loss: 1.7483634054660797
Epoch: 16| Step: 5
Training loss: 2.2186431884765625
Validation loss: 1.680735468864441
Epoch: 16| Step: 6
Training loss: 2.3843870162963867
Validation loss: 1.6554985642433167
Epoch: 16| Step: 7
Training loss: 2.3219900131225586
Validation loss: 1.725637674331665
Epoch: 16| Step: 8
Training loss: 2.2660012245178223
Validation loss: 1.6754521429538727
Epoch: 16| Step: 9
Training loss: 2.4001710414886475
Validation loss: 1.6261776387691498
Epoch: 17| Step: 0
Training loss: 1.8937500715255737
Validation loss: 1.717797875404358
Epoch: 17| Step: 1
Training loss: 2.043874740600586
Validation loss: 1.6772189140319824
Epoch: 17| Step: 2
Training loss: 2.4625680446624756
Validation loss: 1.6619057655334473
Epoch: 17| Step: 3
Training loss: 1.912930965423584
Validation loss: 1.639421671628952
Epoch: 17| Step: 4
Training loss: 1.9690911769866943
Validation loss: 1.6291621923446655
Epoch: 17| Step: 5
Training loss: 2.2688865661621094
Validation loss: 1.6996930837631226
Epoch: 17| Step: 6
Training loss: 2.5074269771575928
Validation loss: 1.6798803508281708
Epoch: 17| Step: 7
Training loss: 2.2724080085754395
Validation loss: 1.6790879666805267
Epoch: 17| Step: 8
Training loss: 2.865468978881836
Validation loss: 1.7169143557548523
Epoch: 17| Step: 9
Training loss: 2.2280256748199463
Validation loss: 1.6716268360614777
Epoch: 18| Step: 0
Training loss: 2.0655341148376465
Validation loss: 1.6943495869636536
Epoch: 18| Step: 1
Training loss: 2.7126264572143555
Validation loss: 1.6387783288955688
Epoch: 18| Step: 2
Training loss: 2.128124952316284
Validation loss: 1.6997985541820526
Epoch: 18| Step: 3
Training loss: 2.250420093536377
Validation loss: 1.7006237208843231
Epoch: 18| Step: 4
Training loss: 2.1186721324920654
Validation loss: 1.690838873386383
Epoch: 18| Step: 5
Training loss: 2.417031764984131
Validation loss: 1.654693752527237
Epoch: 18| Step: 6
Training loss: 2.4569859504699707
Validation loss: 1.6899369060993195
Epoch: 18| Step: 7
Training loss: 2.2076854705810547
Validation loss: 1.665519267320633
Epoch: 18| Step: 8
Training loss: 2.1209850311279297
Validation loss: 1.6885091960430145
Epoch: 18| Step: 9
Training loss: 1.9541726112365723
Validation loss: 1.7021000385284424
Epoch: 19| Step: 0
Training loss: 2.334040641784668
Validation loss: 1.6482101678848267
Epoch: 19| Step: 1
Training loss: 2.4824023246765137
Validation loss: 1.6400923132896423
Epoch: 19| Step: 2
Training loss: 1.8708211183547974
Validation loss: 1.710278868675232
Epoch: 19| Step: 3
Training loss: 2.0081429481506348
Validation loss: 1.6976676285266876
Epoch: 19| Step: 4
Training loss: 2.317699432373047
Validation loss: 1.6817587614059448
Epoch: 19| Step: 5
Training loss: 2.392245292663574
Validation loss: 1.6038194596767426
Epoch: 19| Step: 6
Training loss: 2.5332064628601074
Validation loss: 1.7248981595039368
Epoch: 19| Step: 7
Training loss: 2.0833377838134766
Validation loss: 1.6782571077346802
Epoch: 19| Step: 8
Training loss: 1.9031249284744263
Validation loss: 1.710091918706894
Epoch: 19| Step: 9
Training loss: 2.502976179122925
Validation loss: 1.6931734681129456
Epoch: 20| Step: 0
Training loss: 1.9967663288116455
Validation loss: 1.706209272146225
Epoch: 20| Step: 1
Training loss: 2.4943480491638184
Validation loss: 1.6898024678230286
Epoch: 20| Step: 2
Training loss: 2.128070831298828
Validation loss: 1.6811230182647705
Epoch: 20| Step: 3
Training loss: 2.8031251430511475
Validation loss: 1.6577825546264648
Epoch: 20| Step: 4
Training loss: 2.2008395195007324
Validation loss: 1.7103078961372375
Epoch: 20| Step: 5
Training loss: 2.25311279296875
Validation loss: 1.6601685583591461
Epoch: 20| Step: 6
Training loss: 1.9187500476837158
Validation loss: 1.7357080280780792
Epoch: 20| Step: 7
Training loss: 2.59375
Validation loss: 1.7395081520080566
Epoch: 20| Step: 8
Training loss: 2.25689435005188
Validation loss: 1.7188869714736938
Epoch: 20| Step: 9
Training loss: 1.7900199890136719
Validation loss: 1.6971775889396667
Epoch: 21| Step: 0
Training loss: 2.109375
Validation loss: 1.6558933854103088
Epoch: 21| Step: 1
Training loss: 2.425307273864746
Validation loss: 1.7209657728672028
Epoch: 21| Step: 2
Training loss: 2.1794862747192383
Validation loss: 1.6738126575946808
Epoch: 21| Step: 3
Training loss: 2.2458207607269287
Validation loss: 1.6947667300701141
Epoch: 21| Step: 4
Training loss: 2.3456480503082275
Validation loss: 1.7181077301502228
Epoch: 21| Step: 5
Training loss: 2.1156249046325684
Validation loss: 1.6941708326339722
Epoch: 21| Step: 6
Training loss: 2.2793080806732178
Validation loss: 1.6964732110500336
Epoch: 21| Step: 7
Training loss: 2.856940269470215
Validation loss: 1.7643260955810547
Epoch: 21| Step: 8
Training loss: 1.9561920166015625
Validation loss: 1.669473260641098
Epoch: 21| Step: 9
Training loss: 1.916273832321167
Validation loss: 1.673183411359787
Epoch: 22| Step: 0
Training loss: 2.1526858806610107
Validation loss: 1.6792722344398499
Epoch: 22| Step: 1
Training loss: 2.106250047683716
Validation loss: 1.6523832082748413
Epoch: 22| Step: 2
Training loss: 2.0753884315490723
Validation loss: 1.6907175481319427
Epoch: 22| Step: 3
Training loss: 2.458472490310669
Validation loss: 1.7301286160945892
Epoch: 22| Step: 4
Training loss: 2.4091172218322754
Validation loss: 1.6872346103191376
Epoch: 22| Step: 5
Training loss: 1.9467378854751587
Validation loss: 1.6667146980762482
Epoch: 22| Step: 6
Training loss: 2.2155492305755615
Validation loss: 1.6846022307872772
Epoch: 22| Step: 7
Training loss: 2.2966020107269287
Validation loss: 1.6689547002315521
Epoch: 22| Step: 8
Training loss: 2.365877866744995
Validation loss: 1.6826636791229248
Epoch: 22| Step: 9
Training loss: 2.398733139038086
Validation loss: 1.71664696931839
Epoch: 23| Step: 0
Training loss: 2.05601167678833
Validation loss: 1.6328057050704956
Epoch: 23| Step: 1
Training loss: 2.3713765144348145
Validation loss: 1.6919462978839874
Epoch: 23| Step: 2
Training loss: 2.3442416191101074
Validation loss: 1.6788012385368347
Epoch: 23| Step: 3
Training loss: 2.214268684387207
Validation loss: 1.6397810578346252
Epoch: 23| Step: 4
Training loss: 2.2683746814727783
Validation loss: 1.662124752998352
Epoch: 23| Step: 5
Training loss: 2.2281250953674316
Validation loss: 1.6502562761306763
Epoch: 23| Step: 6
Training loss: 2.230271339416504
Validation loss: 1.6238560378551483
Epoch: 23| Step: 7
Training loss: 2.418750286102295
Validation loss: 1.641379326581955
Epoch: 23| Step: 8
Training loss: 2.135983467102051
Validation loss: 1.611626297235489
Epoch: 23| Step: 9
Training loss: 2.170109272003174
Validation loss: 1.6728712022304535
Epoch: 24| Step: 0
Training loss: 2.151658058166504
Validation loss: 1.6756380796432495
Epoch: 24| Step: 1
Training loss: 2.235865831375122
Validation loss: 1.6411770582199097
Epoch: 24| Step: 2
Training loss: 2.1557064056396484
Validation loss: 1.641491174697876
Epoch: 24| Step: 3
Training loss: 2.577113151550293
Validation loss: 1.7198288440704346
Epoch: 24| Step: 4
Training loss: 2.578934669494629
Validation loss: 1.6825530529022217
Epoch: 24| Step: 5
Training loss: 2.396296977996826
Validation loss: 1.669156700372696
Epoch: 24| Step: 6
Training loss: 2.3235483169555664
Validation loss: 1.7021838128566742
Epoch: 24| Step: 7
Training loss: 1.8562499284744263
Validation loss: 1.6560982167720795
Epoch: 24| Step: 8
Training loss: 2.291090965270996
Validation loss: 1.6693906784057617
Epoch: 24| Step: 9
Training loss: 1.864147424697876
Validation loss: 1.7232134938240051
Epoch: 25| Step: 0
Training loss: 2.15625
Validation loss: 1.6854948699474335
Epoch: 25| Step: 1
Training loss: 2.2580208778381348
Validation loss: 1.6870377659797668
Epoch: 25| Step: 2
Training loss: 2.036484718322754
Validation loss: 1.702704757452011
Epoch: 25| Step: 3
Training loss: 2.362499952316284
Validation loss: 1.6770919263362885
Epoch: 25| Step: 4
Training loss: 2.15708065032959
Validation loss: 1.6704806089401245
Epoch: 25| Step: 5
Training loss: 2.639632225036621
Validation loss: 1.697050154209137
Epoch: 25| Step: 6
Training loss: 2.4010307788848877
Validation loss: 1.7161567211151123
Epoch: 25| Step: 7
Training loss: 1.8985390663146973
Validation loss: 1.6548549234867096
Epoch: 25| Step: 8
Training loss: 2.1875
Validation loss: 1.6731368601322174
Epoch: 25| Step: 9
Training loss: 2.331331729888916
Validation loss: 1.6779393553733826
Epoch: 26| Step: 0
Training loss: 1.9375
Validation loss: 1.665649652481079
Epoch: 26| Step: 1
Training loss: 2.28192400932312
Validation loss: 1.7200980186462402
Epoch: 26| Step: 2
Training loss: 1.9857368469238281
Validation loss: 1.7222286760807037
Epoch: 26| Step: 3
Training loss: 2.431352138519287
Validation loss: 1.671323150396347
Epoch: 26| Step: 4
Training loss: 2.373476028442383
Validation loss: 1.7017433941364288
Epoch: 26| Step: 5
Training loss: 2.28837251663208
Validation loss: 1.6955121457576752
Epoch: 26| Step: 6
Training loss: 2.474841594696045
Validation loss: 1.663785606622696
Epoch: 26| Step: 7
Training loss: 2.4567008018493652
Validation loss: 1.7389273047447205
Epoch: 26| Step: 8
Training loss: 2.20045804977417
Validation loss: 1.71781724691391
Epoch: 26| Step: 9
Training loss: 1.9997690916061401
Validation loss: 1.70473313331604
Epoch: 27| Step: 0
Training loss: 2.1624999046325684
Validation loss: 1.7200762033462524
Epoch: 27| Step: 1
Training loss: 2.8185415267944336
Validation loss: 1.6891875863075256
Epoch: 27| Step: 2
Training loss: 1.9853670597076416
Validation loss: 1.6801127195358276
Epoch: 27| Step: 3
Training loss: 2.375260829925537
Validation loss: 1.7263994812965393
Epoch: 27| Step: 4
Training loss: 2.4502720832824707
Validation loss: 1.6667111814022064
Epoch: 27| Step: 5
Training loss: 2.3555538654327393
Validation loss: 1.6907101273536682
Epoch: 27| Step: 6
Training loss: 1.9286454916000366
Validation loss: 1.645834058523178
Epoch: 27| Step: 7
Training loss: 2.1193737983703613
Validation loss: 1.6826578676700592
Epoch: 27| Step: 8
Training loss: 1.885040044784546
Validation loss: 1.689295083284378
Epoch: 27| Step: 9
Training loss: 2.3431005477905273
Validation loss: 1.7079134583473206
Epoch: 28| Step: 0
Training loss: 2.4750001430511475
Validation loss: 1.6724981665611267
Epoch: 28| Step: 1
Training loss: 2.300723075866699
Validation loss: 1.698134183883667
Epoch: 28| Step: 2
Training loss: 2.4499998092651367
Validation loss: 1.7501589059829712
Epoch: 28| Step: 3
Training loss: 2.128807544708252
Validation loss: 1.690894365310669
Epoch: 28| Step: 4
Training loss: 2.1350505352020264
Validation loss: 1.7339315712451935
Epoch: 28| Step: 5
Training loss: 2.2851359844207764
Validation loss: 1.6812905669212341
Epoch: 28| Step: 6
Training loss: 2.339783191680908
Validation loss: 1.7229559123516083
Epoch: 28| Step: 7
Training loss: 2.2904043197631836
Validation loss: 1.7490871250629425
Epoch: 28| Step: 8
Training loss: 2.096874952316284
Validation loss: 1.7228357791900635
Epoch: 28| Step: 9
Training loss: 1.921875
Validation loss: 1.646115481853485
Epoch: 29| Step: 0
Training loss: 1.9820929765701294
Validation loss: 1.6885792911052704
Epoch: 29| Step: 1
Training loss: 2.4327611923217773
Validation loss: 1.5922387540340424
Epoch: 29| Step: 2
Training loss: 2.233236074447632
Validation loss: 1.6982221603393555
Epoch: 29| Step: 3
Training loss: 2.238009214401245
Validation loss: 1.7768345773220062
Epoch: 29| Step: 4
Training loss: 2.4250001907348633
Validation loss: 1.69587242603302
Epoch: 29| Step: 5
Training loss: 2.3246965408325195
Validation loss: 1.697049468755722
Epoch: 29| Step: 6
Training loss: 2.1883087158203125
Validation loss: 1.717295080423355
Epoch: 29| Step: 7
Training loss: 2.221951484680176
Validation loss: 1.7029530107975006
Epoch: 29| Step: 8
Training loss: 2.065777063369751
Validation loss: 1.6971790194511414
Epoch: 29| Step: 9
Training loss: 2.313410758972168
Validation loss: 1.7382589876651764
Epoch: 30| Step: 0
Training loss: 2.317365884780884
Validation loss: 1.66645547747612
Epoch: 30| Step: 1
Training loss: 2.317699909210205
Validation loss: 1.6872503161430359
Epoch: 30| Step: 2
Training loss: 2.0656251907348633
Validation loss: 1.6517164409160614
Epoch: 30| Step: 3
Training loss: 2.215167760848999
Validation loss: 1.676623523235321
Epoch: 30| Step: 4
Training loss: 2.232405424118042
Validation loss: 1.698286384344101
Epoch: 30| Step: 5
Training loss: 2.1417226791381836
Validation loss: 1.729813665151596
Epoch: 30| Step: 6
Training loss: 2.298856735229492
Validation loss: 1.680849850177765
Epoch: 30| Step: 7
Training loss: 2.3687374591827393
Validation loss: 1.7195375263690948
Epoch: 30| Step: 8
Training loss: 2.109524726867676
Validation loss: 1.7290185689926147
Epoch: 30| Step: 9
Training loss: 2.362499952316284
Validation loss: 1.6545405089855194
Epoch: 31| Step: 0
Training loss: 2.4151668548583984
Validation loss: 1.6839579045772552
Epoch: 31| Step: 1
Training loss: 2.219109535217285
Validation loss: 1.7125272750854492
Epoch: 31| Step: 2
Training loss: 2.365410327911377
Validation loss: 1.644555538892746
Epoch: 31| Step: 3
Training loss: 1.9627801179885864
Validation loss: 1.7612526416778564
Epoch: 31| Step: 4
Training loss: 2.015625
Validation loss: 1.6796005368232727
Epoch: 31| Step: 5
Training loss: 2.168550491333008
Validation loss: 1.716638207435608
Epoch: 31| Step: 6
Training loss: 2.049999952316284
Validation loss: 1.6429482698440552
Epoch: 31| Step: 7
Training loss: 2.5441184043884277
Validation loss: 1.7183668613433838
Epoch: 31| Step: 8
Training loss: 2.2995901107788086
Validation loss: 1.6994878053665161
Epoch: 31| Step: 9
Training loss: 2.3828229904174805
Validation loss: 1.6915667355060577
Epoch: 32| Step: 0
Training loss: 2.1869988441467285
Validation loss: 1.6880602836608887
Epoch: 32| Step: 1
Training loss: 2.4139585494995117
Validation loss: 1.6952341496944427
Epoch: 32| Step: 2
Training loss: 2.536184787750244
Validation loss: 1.6731495261192322
Epoch: 32| Step: 3
Training loss: 2.4142065048217773
Validation loss: 1.65326526761055
Epoch: 32| Step: 4
Training loss: 2.3807356357574463
Validation loss: 1.6401534676551819
Epoch: 32| Step: 5
Training loss: 2.384305000305176
Validation loss: 1.7086420059204102
Epoch: 32| Step: 6
Training loss: 1.9770677089691162
Validation loss: 1.7078583538532257
Epoch: 32| Step: 7
Training loss: 1.6889634132385254
Validation loss: 1.6909413039684296
Epoch: 32| Step: 8
Training loss: 2.3226451873779297
Validation loss: 1.6195202767848969
Epoch: 32| Step: 9
Training loss: 2.1283044815063477
Validation loss: 1.7035285532474518
Epoch: 33| Step: 0
Training loss: 2.0530622005462646
Validation loss: 1.7577497065067291
Epoch: 33| Step: 1
Training loss: 2.262162208557129
Validation loss: 1.7291805148124695
Epoch: 33| Step: 2
Training loss: 2.0025720596313477
Validation loss: 1.6888792514801025
Epoch: 33| Step: 3
Training loss: 2.1819400787353516
Validation loss: 1.7475751340389252
Epoch: 33| Step: 4
Training loss: 2.666975259780884
Validation loss: 1.6766059398651123
Epoch: 33| Step: 5
Training loss: 2.630315065383911
Validation loss: 1.6785924285650253
Epoch: 33| Step: 6
Training loss: 2.2620925903320312
Validation loss: 1.6981317698955536
Epoch: 33| Step: 7
Training loss: 1.8874913454055786
Validation loss: 1.7382619380950928
Epoch: 33| Step: 8
Training loss: 2.4035654067993164
Validation loss: 1.676028996706009
Epoch: 33| Step: 9
Training loss: 2.0781121253967285
Validation loss: 1.727318286895752
Epoch: 34| Step: 0
Training loss: 2.4284870624542236
Validation loss: 1.6714224219322205
Epoch: 34| Step: 1
Training loss: 2.3725271224975586
Validation loss: 1.6520175635814667
Epoch: 34| Step: 2
Training loss: 2.1344523429870605
Validation loss: 1.652970552444458
Epoch: 34| Step: 3
Training loss: 2.2779111862182617
Validation loss: 1.6939906775951385
Epoch: 34| Step: 4
Training loss: 2.5281100273132324
Validation loss: 1.6962844133377075
Epoch: 34| Step: 5
Training loss: 1.8316097259521484
Validation loss: 1.7106957137584686
Epoch: 34| Step: 6
Training loss: 2.006498336791992
Validation loss: 1.669282853603363
Epoch: 34| Step: 7
Training loss: 2.257661819458008
Validation loss: 1.6588102877140045
Epoch: 34| Step: 8
Training loss: 2.309375047683716
Validation loss: 1.7028548419475555
Epoch: 34| Step: 9
Training loss: 2.281236171722412
Validation loss: 1.6703079044818878
Epoch: 35| Step: 0
Training loss: 2.7192118167877197
Validation loss: 1.65723517537117
Epoch: 35| Step: 1
Training loss: 2.339662551879883
Validation loss: 1.704045981168747
Epoch: 35| Step: 2
Training loss: 2.542597532272339
Validation loss: 1.6751218438148499
Epoch: 35| Step: 3
Training loss: 1.9718750715255737
Validation loss: 1.6572981178760529
Epoch: 35| Step: 4
Training loss: 2.1756534576416016
Validation loss: 1.7223830223083496
Epoch: 35| Step: 5
Training loss: 2.080047130584717
Validation loss: 1.6299163401126862
Epoch: 35| Step: 6
Training loss: 1.7684730291366577
Validation loss: 1.6806170046329498
Epoch: 35| Step: 7
Training loss: 2.1474905014038086
Validation loss: 1.6445233821868896
Epoch: 35| Step: 8
Training loss: 2.5843749046325684
Validation loss: 1.6752602458000183
Epoch: 35| Step: 9
Training loss: 2.102595806121826
Validation loss: 1.6924720406532288
Epoch: 36| Step: 0
Training loss: 2.853814125061035
Validation loss: 1.700424611568451
Epoch: 36| Step: 1
Training loss: 2.369767427444458
Validation loss: 1.7199793756008148
Epoch: 36| Step: 2
Training loss: 2.2790162563323975
Validation loss: 1.6970946788787842
Epoch: 36| Step: 3
Training loss: 2.346874952316284
Validation loss: 1.6668481826782227
Epoch: 36| Step: 4
Training loss: 2.1509203910827637
Validation loss: 1.7342360317707062
Epoch: 36| Step: 5
Training loss: 1.7776217460632324
Validation loss: 1.687324434518814
Epoch: 36| Step: 6
Training loss: 2.0875000953674316
Validation loss: 1.6710745692253113
Epoch: 36| Step: 7
Training loss: 2.082453966140747
Validation loss: 1.7224173247814178
Epoch: 36| Step: 8
Training loss: 2.417428731918335
Validation loss: 1.708892673254013
Epoch: 36| Step: 9
Training loss: 2.05995774269104
Validation loss: 1.704250454902649
Epoch: 37| Step: 0
Training loss: 2.342445135116577
Validation loss: 1.6738924980163574
Epoch: 37| Step: 1
Training loss: 2.6760544776916504
Validation loss: 1.7078409492969513
Epoch: 37| Step: 2
Training loss: 2.035301923751831
Validation loss: 1.6459965109825134
Epoch: 37| Step: 3
Training loss: 2.34000301361084
Validation loss: 1.6788983643054962
Epoch: 37| Step: 4
Training loss: 2.285322427749634
Validation loss: 1.653361827135086
Epoch: 37| Step: 5
Training loss: 2.4342472553253174
Validation loss: 1.6158167123794556
Epoch: 37| Step: 6
Training loss: 1.6415112018585205
Validation loss: 1.6894006729125977
Epoch: 37| Step: 7
Training loss: 1.8752968311309814
Validation loss: 1.656363308429718
Epoch: 37| Step: 8
Training loss: 2.472484588623047
Validation loss: 1.6650915443897247
Epoch: 37| Step: 9
Training loss: 2.3349509239196777
Validation loss: 1.7223683297634125
Epoch: 38| Step: 0
Training loss: 2.1374998092651367
Validation loss: 1.7048224210739136
Epoch: 38| Step: 1
Training loss: 2.3402810096740723
Validation loss: 1.6599771678447723
Epoch: 38| Step: 2
Training loss: 2.1537585258483887
Validation loss: 1.662827342748642
Epoch: 38| Step: 3
Training loss: 2.4187498092651367
Validation loss: 1.6126052737236023
Epoch: 38| Step: 4
Training loss: 2.205235481262207
Validation loss: 1.7007203698158264
Epoch: 38| Step: 5
Training loss: 2.3100240230560303
Validation loss: 1.6212260127067566
Epoch: 38| Step: 6
Training loss: 2.3046817779541016
Validation loss: 1.6683551669120789
Epoch: 38| Step: 7
Training loss: 2.0370731353759766
Validation loss: 1.6920370161533356
Epoch: 38| Step: 8
Training loss: 2.3645100593566895
Validation loss: 1.6477698385715485
Epoch: 38| Step: 9
Training loss: 2.154512405395508
Validation loss: 1.7089827954769135
Epoch: 39| Step: 0
Training loss: 2.5210556983947754
Validation loss: 1.7259986400604248
Epoch: 39| Step: 1
Training loss: 2.5504953861236572
Validation loss: 1.6312880516052246
Epoch: 39| Step: 2
Training loss: 2.034186840057373
Validation loss: 1.7004047632217407
Epoch: 39| Step: 3
Training loss: 2.0938329696655273
Validation loss: 1.6727391183376312
Epoch: 39| Step: 4
Training loss: 2.1814417839050293
Validation loss: 1.6977521777153015
Epoch: 39| Step: 5
Training loss: 2.4205846786499023
Validation loss: 1.675329566001892
Epoch: 39| Step: 6
Training loss: 2.269780397415161
Validation loss: 1.702244132757187
Epoch: 39| Step: 7
Training loss: 2.138537645339966
Validation loss: 1.7013039290904999
Epoch: 39| Step: 8
Training loss: 2.234375
Validation loss: 1.709258109331131
Epoch: 39| Step: 9
Training loss: 1.9893667697906494
Validation loss: 1.637429028749466
Epoch: 40| Step: 0
Training loss: 2.3820810317993164
Validation loss: 1.6635220348834991
Epoch: 40| Step: 1
Training loss: 1.942155361175537
Validation loss: 1.7386479377746582
Epoch: 40| Step: 2
Training loss: 1.96060049533844
Validation loss: 1.706387847661972
Epoch: 40| Step: 3
Training loss: 1.911795973777771
Validation loss: 1.6783503592014313
Epoch: 40| Step: 4
Training loss: 2.3504810333251953
Validation loss: 1.6407755017280579
Epoch: 40| Step: 5
Training loss: 2.3764808177948
Validation loss: 1.7031576931476593
Epoch: 40| Step: 6
Training loss: 2.4983136653900146
Validation loss: 1.6994662582874298
Epoch: 40| Step: 7
Training loss: 2.541904926300049
Validation loss: 1.7187125384807587
Epoch: 40| Step: 8
Training loss: 2.3092753887176514
Validation loss: 1.6936752796173096
Epoch: 40| Step: 9
Training loss: 2.1543054580688477
Validation loss: 1.6655729711055756
Epoch: 41| Step: 0
Training loss: 2.724362850189209
Validation loss: 1.630946695804596
Epoch: 41| Step: 1
Training loss: 2.279569387435913
Validation loss: 1.7247308194637299
Epoch: 41| Step: 2
Training loss: 2.3187499046325684
Validation loss: 1.7157300114631653
Epoch: 41| Step: 3
Training loss: 2.0021612644195557
Validation loss: 1.6651912927627563
Epoch: 41| Step: 4
Training loss: 2.0910322666168213
Validation loss: 1.6415767073631287
Epoch: 41| Step: 5
Training loss: 1.8573260307312012
Validation loss: 1.710130363702774
Epoch: 41| Step: 6
Training loss: 2.24953031539917
Validation loss: 1.716773808002472
Epoch: 41| Step: 7
Training loss: 2.3283376693725586
Validation loss: 1.7106719315052032
Epoch: 41| Step: 8
Training loss: 2.5533993244171143
Validation loss: 1.7098206877708435
Epoch: 41| Step: 9
Training loss: 2.0218749046325684
Validation loss: 1.751517117023468
Epoch: 42| Step: 0
Training loss: 2.2411231994628906
Validation loss: 1.6970900893211365
Epoch: 42| Step: 1
Training loss: 1.9455186128616333
Validation loss: 1.685362458229065
Epoch: 42| Step: 2
Training loss: 2.1730666160583496
Validation loss: 1.6178562343120575
Epoch: 42| Step: 3
Training loss: 2.1544036865234375
Validation loss: 1.6741124987602234
Epoch: 42| Step: 4
Training loss: 2.362499952316284
Validation loss: 1.6670961380004883
Epoch: 42| Step: 5
Training loss: 2.387500047683716
Validation loss: 1.7185214161872864
Epoch: 42| Step: 6
Training loss: 1.823642611503601
Validation loss: 1.6912682950496674
Epoch: 42| Step: 7
Training loss: 2.437638282775879
Validation loss: 1.7278209030628204
Epoch: 42| Step: 8
Training loss: 2.380563735961914
Validation loss: 1.765434980392456
Epoch: 42| Step: 9
Training loss: 2.5181174278259277
Validation loss: 1.7098690271377563
Epoch: 43| Step: 0
Training loss: 2.3536577224731445
Validation loss: 1.7747336030006409
Epoch: 43| Step: 1
Training loss: 2.529418468475342
Validation loss: 1.6522893905639648
Epoch: 43| Step: 2
Training loss: 2.458261489868164
Validation loss: 1.7228806912899017
Epoch: 43| Step: 3
Training loss: 2.117945671081543
Validation loss: 1.6447093188762665
Epoch: 43| Step: 4
Training loss: 2.1656250953674316
Validation loss: 1.662316381931305
Epoch: 43| Step: 5
Training loss: 2.363414764404297
Validation loss: 1.723618507385254
Epoch: 43| Step: 6
Training loss: 2.057560443878174
Validation loss: 1.6851058304309845
Epoch: 43| Step: 7
Training loss: 2.150862693786621
Validation loss: 1.7616924047470093
Epoch: 43| Step: 8
Training loss: 2.1031250953674316
Validation loss: 1.7080703377723694
Epoch: 43| Step: 9
Training loss: 2.1315760612487793
Validation loss: 1.7162160873413086
Epoch: 44| Step: 0
Training loss: 2.1501471996307373
Validation loss: 1.734043687582016
Epoch: 44| Step: 1
Training loss: 1.9907429218292236
Validation loss: 1.7146374881267548
Epoch: 44| Step: 2
Training loss: 1.8250000476837158
Validation loss: 1.6444770097732544
Epoch: 44| Step: 3
Training loss: 2.0468204021453857
Validation loss: 1.708730310201645
Epoch: 44| Step: 4
Training loss: 2.3626928329467773
Validation loss: 1.6707941889762878
Epoch: 44| Step: 5
Training loss: 2.553882598876953
Validation loss: 1.678164690732956
Epoch: 44| Step: 6
Training loss: 2.7159640789031982
Validation loss: 1.6978822946548462
Epoch: 44| Step: 7
Training loss: 2.346874952316284
Validation loss: 1.6214620769023895
Epoch: 44| Step: 8
Training loss: 2.0942444801330566
Validation loss: 1.7311659157276154
Epoch: 44| Step: 9
Training loss: 2.3395676612854004
Validation loss: 1.6429806351661682
Epoch: 45| Step: 0
Training loss: 2.3299098014831543
Validation loss: 1.70368230342865
Epoch: 45| Step: 1
Training loss: 2.0773422718048096
Validation loss: 1.658199280500412
Epoch: 45| Step: 2
Training loss: 2.2249999046325684
Validation loss: 1.7563886642456055
Epoch: 45| Step: 3
Training loss: 2.3354744911193848
Validation loss: 1.6681138277053833
Epoch: 45| Step: 4
Training loss: 2.4644556045532227
Validation loss: 1.6334022283554077
Epoch: 45| Step: 5
Training loss: 2.0198090076446533
Validation loss: 1.6955175995826721
Epoch: 45| Step: 6
Training loss: 1.9258956909179688
Validation loss: 1.6962884962558746
Epoch: 45| Step: 7
Training loss: 2.4919753074645996
Validation loss: 1.656018614768982
Epoch: 45| Step: 8
Training loss: 2.487230062484741
Validation loss: 1.7191808223724365
Epoch: 45| Step: 9
Training loss: 2.0718748569488525
Validation loss: 1.6448690295219421
Epoch: 46| Step: 0
Training loss: 2.299999952316284
Validation loss: 1.656038522720337
Epoch: 46| Step: 1
Training loss: 2.6734402179718018
Validation loss: 1.6740206480026245
Epoch: 46| Step: 2
Training loss: 1.9604897499084473
Validation loss: 1.730274647474289
Epoch: 46| Step: 3
Training loss: 2.403348445892334
Validation loss: 1.626840978860855
Epoch: 46| Step: 4
Training loss: 2.1159112453460693
Validation loss: 1.6987954080104828
Epoch: 46| Step: 5
Training loss: 1.9072760343551636
Validation loss: 1.713965266942978
Epoch: 46| Step: 6
Training loss: 2.519073963165283
Validation loss: 1.6617471277713776
Epoch: 46| Step: 7
Training loss: 2.296875
Validation loss: 1.6810729205608368
Epoch: 46| Step: 8
Training loss: 2.4781250953674316
Validation loss: 1.6793670058250427
Epoch: 46| Step: 9
Training loss: 1.771875023841858
Validation loss: 1.6806955337524414
Epoch: 47| Step: 0
Training loss: 1.8188718557357788
Validation loss: 1.7211749255657196
Epoch: 47| Step: 1
Training loss: 2.4377121925354004
Validation loss: 1.7035350501537323
Epoch: 47| Step: 2
Training loss: 2.29449725151062
Validation loss: 1.764971137046814
Epoch: 47| Step: 3
Training loss: 2.0832157135009766
Validation loss: 1.6547925174236298
Epoch: 47| Step: 4
Training loss: 2.0636942386627197
Validation loss: 1.677861213684082
Epoch: 47| Step: 5
Training loss: 2.4917874336242676
Validation loss: 1.6551052927970886
Epoch: 47| Step: 6
Training loss: 2.061184883117676
Validation loss: 1.688815176486969
Epoch: 47| Step: 7
Training loss: 2.277127265930176
Validation loss: 1.718317061662674
Epoch: 47| Step: 8
Training loss: 2.503124952316284
Validation loss: 1.698198139667511
Epoch: 47| Step: 9
Training loss: 2.395759105682373
Validation loss: 1.6562081277370453
Epoch: 48| Step: 0
Training loss: 2.335223436355591
Validation loss: 1.704257994890213
Epoch: 48| Step: 1
Training loss: 2.4926087856292725
Validation loss: 1.7086550295352936
Epoch: 48| Step: 2
Training loss: 2.4776175022125244
Validation loss: 1.6611623466014862
Epoch: 48| Step: 3
Training loss: 2.2294230461120605
Validation loss: 1.6915824711322784
Epoch: 48| Step: 4
Training loss: 2.487189531326294
Validation loss: 1.6364704370498657
Epoch: 48| Step: 5
Training loss: 2.3917665481567383
Validation loss: 1.6654003858566284
Epoch: 48| Step: 6
Training loss: 2.259533166885376
Validation loss: 1.7178228497505188
Epoch: 48| Step: 7
Training loss: 2.1843748092651367
Validation loss: 1.6838560104370117
Epoch: 48| Step: 8
Training loss: 2.2286925315856934
Validation loss: 1.6894898414611816
Epoch: 48| Step: 9
Training loss: 1.3406250476837158
Validation loss: 1.7381040751934052
Epoch: 49| Step: 0
Training loss: 2.1940484046936035
Validation loss: 1.7297975420951843
Epoch: 49| Step: 1
Training loss: 2.04652738571167
Validation loss: 1.7513017058372498
Epoch: 49| Step: 2
Training loss: 2.159837007522583
Validation loss: 1.7068002223968506
Epoch: 49| Step: 3
Training loss: 2.4375
Validation loss: 1.6640911102294922
Epoch: 49| Step: 4
Training loss: 2.0945794582366943
Validation loss: 1.6917795240879059
Epoch: 49| Step: 5
Training loss: 2.4781606197357178
Validation loss: 1.682741105556488
Epoch: 49| Step: 6
Training loss: 2.1311004161834717
Validation loss: 1.7091131210327148
Epoch: 49| Step: 7
Training loss: 2.3762805461883545
Validation loss: 1.6945121586322784
Epoch: 49| Step: 8
Training loss: 2.3372974395751953
Validation loss: 1.6917826533317566
Epoch: 49| Step: 9
Training loss: 2.1690785884857178
Validation loss: 1.6833884119987488
Epoch: 50| Step: 0
Training loss: 2.049999952316284
Validation loss: 1.6578307151794434
Epoch: 50| Step: 1
Training loss: 2.0657846927642822
Validation loss: 1.7144614458084106
Epoch: 50| Step: 2
Training loss: 2.3031251430511475
Validation loss: 1.6474492847919464
Epoch: 50| Step: 3
Training loss: 2.0127930641174316
Validation loss: 1.7124512493610382
Epoch: 50| Step: 4
Training loss: 2.3332481384277344
Validation loss: 1.73046213388443
Epoch: 50| Step: 5
Training loss: 2.3453845977783203
Validation loss: 1.7020070850849152
Epoch: 50| Step: 6
Training loss: 2.1875
Validation loss: 1.6606723964214325
Epoch: 50| Step: 7
Training loss: 2.6493947505950928
Validation loss: 1.7394919395446777
Epoch: 50| Step: 8
Training loss: 2.0552244186401367
Validation loss: 1.708780586719513
Epoch: 50| Step: 9
Training loss: 2.4212958812713623
Validation loss: 1.728791207075119
