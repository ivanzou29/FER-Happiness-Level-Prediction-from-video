Epoch: 1| Step: 0
Training loss: 5.852567986146825
Validation loss: 5.321059557083871
Epoch: 1| Step: 1
Training loss: 5.5003689728863305
Validation loss: 5.307354972819804
Epoch: 1| Step: 2
Training loss: 5.779353310070011
Validation loss: 5.353240154679737
Epoch: 1| Step: 3
Training loss: 6.0198126150984494
Validation loss: 5.197170784311444
Epoch: 1| Step: 4
Training loss: 4.33903192297135
Validation loss: 5.113416666318713
Epoch: 1| Step: 5
Training loss: 5.3320702408143985
Validation loss: 5.087775453618509
Epoch: 1| Step: 6
Training loss: 5.390016737082121
Validation loss: 5.078343206996031
Epoch: 1| Step: 7
Training loss: 5.497355605688567
Validation loss: 5.085895931127412
Epoch: 1| Step: 8
Training loss: 4.843247910595361
Validation loss: 5.1264969779448135
Epoch: 1| Step: 9
Training loss: 5.110269730647366
Validation loss: 5.043089827771533
Epoch: 1| Step: 10
Training loss: 6.013465711795766
Validation loss: 4.96432226744235
Epoch: 1| Step: 11
Training loss: 5.13218966207788
Validation loss: 5.062655893155538
Epoch: 1| Step: 12
Training loss: 5.595437248264659
Validation loss: 4.9322913738825385
Epoch: 1| Step: 13
Training loss: 4.093901653247176
Validation loss: 4.924307870495422
Epoch: 1| Step: 14
Training loss: 5.962054746625346
Validation loss: 4.966189050600826
Epoch: 1| Step: 15
Training loss: 5.159194383053318
Validation loss: 4.8313705915681275
Epoch: 1| Step: 16
Training loss: 4.462288833879189
Validation loss: 4.826832163619034
Epoch: 1| Step: 17
Training loss: 5.923653609776912
Validation loss: 4.743984105758515
Epoch: 1| Step: 18
Training loss: 5.919119241510078
Validation loss: 4.71758075519785
Epoch: 1| Step: 19
Training loss: 6.0285999227688505
Validation loss: 4.7806140073276575
Epoch: 2| Step: 0
Training loss: 5.4794155204547845
Validation loss: 4.815018638354237
Epoch: 2| Step: 1
Training loss: 5.255401738832479
Validation loss: 4.702331998353243
Epoch: 2| Step: 2
Training loss: 4.714978460301119
Validation loss: 4.778015868584265
Epoch: 2| Step: 3
Training loss: 5.411498063804113
Validation loss: 4.675953846218469
Epoch: 2| Step: 4
Training loss: 4.642221914579183
Validation loss: 4.6548971584971355
Epoch: 2| Step: 5
Training loss: 4.373745111602816
Validation loss: 4.664520912528841
Epoch: 2| Step: 6
Training loss: 5.060998010936106
Validation loss: 4.5323289120041075
Epoch: 2| Step: 7
Training loss: 5.346930912334141
Validation loss: 4.688856807231729
Epoch: 2| Step: 8
Training loss: 4.479139082476231
Validation loss: 4.619022728384181
Epoch: 2| Step: 9
Training loss: 4.653290083027466
Validation loss: 4.548148640545165
Epoch: 2| Step: 10
Training loss: 4.616990654843172
Validation loss: 4.527332024520016
Epoch: 2| Step: 11
Training loss: 5.327916832042805
Validation loss: 4.404487419259221
Epoch: 2| Step: 12
Training loss: 5.199003769738382
Validation loss: 4.411101869285711
Epoch: 2| Step: 13
Training loss: 3.7868206510218267
Validation loss: 4.526431526790278
Epoch: 2| Step: 14
Training loss: 5.547301713890424
Validation loss: 4.448601601394556
Epoch: 2| Step: 15
Training loss: 4.639840313366929
Validation loss: 4.463049465267424
Epoch: 2| Step: 16
Training loss: 5.772987854086282
Validation loss: 4.404043210062769
Epoch: 2| Step: 17
Training loss: 5.732402243897391
Validation loss: 4.418493273956455
Epoch: 2| Step: 18
Training loss: 4.2059679591490795
Validation loss: 4.267211892132284
Epoch: 2| Step: 19
Training loss: 4.226650046748108
Validation loss: 4.372125436465782
Epoch: 3| Step: 0
Training loss: 3.551798625435706
Validation loss: 4.294328482894247
Epoch: 3| Step: 1
Training loss: 4.4854052486649385
Validation loss: 4.352657623850536
Epoch: 3| Step: 2
Training loss: 3.472586494835129
Validation loss: 4.236654952851602
Epoch: 3| Step: 3
Training loss: 4.514927160070491
Validation loss: 4.253696251369893
Epoch: 3| Step: 4
Training loss: 4.948575502668948
Validation loss: 4.223740486577055
Epoch: 3| Step: 5
Training loss: 5.320679953009156
Validation loss: 4.160156047352924
Epoch: 3| Step: 6
Training loss: 3.5089093301038212
Validation loss: 4.146009186578125
Epoch: 3| Step: 7
Training loss: 4.584064471565357
Validation loss: 4.135192834364238
Epoch: 3| Step: 8
Training loss: 5.434156771243642
Validation loss: 4.139904665912223
Epoch: 3| Step: 9
Training loss: 5.299430478283967
Validation loss: 4.104698046505796
Epoch: 3| Step: 10
Training loss: 4.0987471736562
Validation loss: 4.021476081899051
Epoch: 3| Step: 11
Training loss: 4.434714289152799
Validation loss: 4.1445005482795425
Epoch: 3| Step: 12
Training loss: 4.894078799294221
Validation loss: 4.024995164276022
Epoch: 3| Step: 13
Training loss: 5.362328430134334
Validation loss: 4.051826398164623
Epoch: 3| Step: 14
Training loss: 3.956557882902981
Validation loss: 3.93703719268197
Epoch: 3| Step: 15
Training loss: 4.337454425671282
Validation loss: 3.9985325677623678
Epoch: 3| Step: 16
Training loss: 4.0049438918394635
Validation loss: 3.992719186195485
Epoch: 3| Step: 17
Training loss: 4.52000853343597
Validation loss: 3.9231332043531753
Epoch: 3| Step: 18
Training loss: 4.294777986164064
Validation loss: 3.8248412156466807
Epoch: 3| Step: 19
Training loss: 4.602597597860055
Validation loss: 3.883780894246013
Epoch: 4| Step: 0
Training loss: 5.084537530234417
Validation loss: 3.824180030847125
Epoch: 4| Step: 1
Training loss: 4.376960097328226
Validation loss: 3.8172350536747133
Epoch: 4| Step: 2
Training loss: 3.538594667615901
Validation loss: 3.833810420697753
Epoch: 4| Step: 3
Training loss: 3.1023615425193323
Validation loss: 3.769592165550967
Epoch: 4| Step: 4
Training loss: 4.7072168337377684
Validation loss: 3.726659329296724
Epoch: 4| Step: 5
Training loss: 4.508318735452782
Validation loss: 3.7599333465201275
Epoch: 4| Step: 6
Training loss: 4.155609310933499
Validation loss: 3.68291207850368
Epoch: 4| Step: 7
Training loss: 4.435172316720502
Validation loss: 3.766853905772729
Epoch: 4| Step: 8
Training loss: 4.377413492704156
Validation loss: 3.580183400232097
Epoch: 4| Step: 9
Training loss: 4.031938834074588
Validation loss: 3.7617368820606987
Epoch: 4| Step: 10
Training loss: 2.544267314074193
Validation loss: 3.62651437085913
Epoch: 4| Step: 11
Training loss: 4.455921031478176
Validation loss: 3.7199314562696095
Epoch: 4| Step: 12
Training loss: 4.338002745765109
Validation loss: 3.667834867970681
Epoch: 4| Step: 13
Training loss: 4.45615174344363
Validation loss: 3.6561336629905177
Epoch: 4| Step: 14
Training loss: 4.117862421702826
Validation loss: 3.5800871403352588
Epoch: 4| Step: 15
Training loss: 3.7509028301624663
Validation loss: 3.580650310648024
Epoch: 4| Step: 16
Training loss: 3.764073222308566
Validation loss: 3.5095874950217443
Epoch: 4| Step: 17
Training loss: 4.150294576094494
Validation loss: 3.607041436821052
Epoch: 4| Step: 18
Training loss: 4.165107180898127
Validation loss: 3.4912022488706365
Epoch: 4| Step: 19
Training loss: 4.065572193222103
Validation loss: 3.3998945641998173
Epoch: 5| Step: 0
Training loss: 3.8795918975616464
Validation loss: 3.4374032527044758
Epoch: 5| Step: 1
Training loss: 3.994870592487348
Validation loss: 3.5237522511073074
Epoch: 5| Step: 2
Training loss: 3.6736887246778536
Validation loss: 3.3967483513829935
Epoch: 5| Step: 3
Training loss: 3.8947619156552653
Validation loss: 3.461884337858935
Epoch: 5| Step: 4
Training loss: 4.203091646083389
Validation loss: 3.3636532324743635
Epoch: 5| Step: 5
Training loss: 4.839082696544268
Validation loss: 3.3368875256853223
Epoch: 5| Step: 6
Training loss: 3.6354730523372085
Validation loss: 3.4233134687179643
Epoch: 5| Step: 7
Training loss: 3.471920454687399
Validation loss: 3.2349343223165197
Epoch: 5| Step: 8
Training loss: 3.745884735354456
Validation loss: 3.381206146441578
Epoch: 5| Step: 9
Training loss: 2.915871720745908
Validation loss: 3.2390259432487434
Epoch: 5| Step: 10
Training loss: 3.795631990142069
Validation loss: 3.3842192911740128
Epoch: 5| Step: 11
Training loss: 3.9487811562086987
Validation loss: 3.3265456887122817
Epoch: 5| Step: 12
Training loss: 3.0294830835641045
Validation loss: 3.313457327788669
Epoch: 5| Step: 13
Training loss: 3.6738238418286437
Validation loss: 3.1649595885325326
Epoch: 5| Step: 14
Training loss: 3.0826274648085508
Validation loss: 3.282515334247764
Epoch: 5| Step: 15
Training loss: 4.2347808305579795
Validation loss: 3.3362261599835974
Epoch: 5| Step: 16
Training loss: 3.7220882530838946
Validation loss: 3.1973109311172885
Epoch: 5| Step: 17
Training loss: 4.42480220891428
Validation loss: 3.2017008559521525
Epoch: 5| Step: 18
Training loss: 3.823918487637734
Validation loss: 3.167710002962901
Epoch: 5| Step: 19
Training loss: 3.7260860882333717
Validation loss: 3.196125723623021
Epoch: 6| Step: 0
Training loss: 2.664409626022793
Validation loss: 3.1944733618382752
Epoch: 6| Step: 1
Training loss: 4.023636363031478
Validation loss: 3.0971979724878387
Epoch: 6| Step: 2
Training loss: 3.50503994601964
Validation loss: 3.053807043525969
Epoch: 6| Step: 3
Training loss: 3.2635370177572636
Validation loss: 3.0553282525288936
Epoch: 6| Step: 4
Training loss: 4.057029914819008
Validation loss: 3.1161250344298734
Epoch: 6| Step: 5
Training loss: 4.119979114664714
Validation loss: 3.027160271369386
Epoch: 6| Step: 6
Training loss: 3.5654179184446955
Validation loss: 3.1029472871232775
Epoch: 6| Step: 7
Training loss: 3.4002027114576427
Validation loss: 3.094319592995846
Epoch: 6| Step: 8
Training loss: 3.5741588483283024
Validation loss: 3.0615490571361543
Epoch: 6| Step: 9
Training loss: 2.223928613635371
Validation loss: 3.046795432856733
Epoch: 6| Step: 10
Training loss: 4.645016631229057
Validation loss: 3.071751643292656
Epoch: 6| Step: 11
Training loss: 3.09323192844031
Validation loss: 3.0028362634355363
Epoch: 6| Step: 12
Training loss: 3.8321483411408153
Validation loss: 3.0369510785701226
Epoch: 6| Step: 13
Training loss: 4.169975391196403
Validation loss: 2.936147869221551
Epoch: 6| Step: 14
Training loss: 3.606098752345798
Validation loss: 3.057645486192337
Epoch: 6| Step: 15
Training loss: 3.1136166572580017
Validation loss: 2.8827143520532807
Epoch: 6| Step: 16
Training loss: 3.033544871181838
Validation loss: 2.8628282377838588
Epoch: 6| Step: 17
Training loss: 3.076489938913872
Validation loss: 2.924365865484913
Epoch: 6| Step: 18
Training loss: 3.10247497204223
Validation loss: 2.9321854863003374
Epoch: 6| Step: 19
Training loss: 3.7291729179344135
Validation loss: 2.8876992353376276
Epoch: 7| Step: 0
Training loss: 3.5996785232269084
Validation loss: 2.9410505359625927
Epoch: 7| Step: 1
Training loss: 3.548150862384001
Validation loss: 2.895850282118183
Epoch: 7| Step: 2
Training loss: 3.064499027450589
Validation loss: 2.856623476713475
Epoch: 7| Step: 3
Training loss: 2.636102720282327
Validation loss: 2.8690569859576556
Epoch: 7| Step: 4
Training loss: 3.880887511890012
Validation loss: 2.810616277782937
Epoch: 7| Step: 5
Training loss: 3.5476374541866105
Validation loss: 2.7739351997688515
Epoch: 7| Step: 6
Training loss: 3.009488201289982
Validation loss: 2.769651281719753
Epoch: 7| Step: 7
Training loss: 2.6638329370655844
Validation loss: 2.819763183204322
Epoch: 7| Step: 8
Training loss: 2.409852835724591
Validation loss: 2.8154657444361053
Epoch: 7| Step: 9
Training loss: 4.033009226573981
Validation loss: 2.755519947918131
Epoch: 7| Step: 10
Training loss: 3.0306782920716246
Validation loss: 2.7268621473001473
Epoch: 7| Step: 11
Training loss: 3.0686201328371228
Validation loss: 2.7200128767013076
Epoch: 7| Step: 12
Training loss: 2.786131614473542
Validation loss: 2.7900801000154116
Epoch: 7| Step: 13
Training loss: 3.3035251746750642
Validation loss: 2.710608421358744
Epoch: 7| Step: 14
Training loss: 3.0511624419242707
Validation loss: 2.669453438218164
Epoch: 7| Step: 15
Training loss: 3.893440422867161
Validation loss: 2.7170298764713072
Epoch: 7| Step: 16
Training loss: 3.7232971600375064
Validation loss: 2.759234981146239
Epoch: 7| Step: 17
Training loss: 4.105884534577086
Validation loss: 2.7462260194442383
Epoch: 7| Step: 18
Training loss: 3.2681372803110618
Validation loss: 2.7089504806113007
Epoch: 7| Step: 19
Training loss: 2.655777833149424
Validation loss: 2.6981144769499803
Epoch: 8| Step: 0
Training loss: 2.9843853855451656
Validation loss: 2.643822182286441
Epoch: 8| Step: 1
Training loss: 3.777719536188996
Validation loss: 2.678319412369122
Epoch: 8| Step: 2
Training loss: 2.877505330363357
Validation loss: 2.53383300686993
Epoch: 8| Step: 3
Training loss: 2.948412652408797
Validation loss: 2.5678121181029923
Epoch: 8| Step: 4
Training loss: 3.23392147994161
Validation loss: 2.654661496051846
Epoch: 8| Step: 5
Training loss: 3.2606866174322935
Validation loss: 2.6183945087355163
Epoch: 8| Step: 6
Training loss: 3.0212777874086596
Validation loss: 2.5781798056377467
Epoch: 8| Step: 7
Training loss: 3.084964647136896
Validation loss: 2.608821286846923
Epoch: 8| Step: 8
Training loss: 3.566189378075406
Validation loss: 2.53731630616259
Epoch: 8| Step: 9
Training loss: 2.968601263235433
Validation loss: 2.5911776549056036
Epoch: 8| Step: 10
Training loss: 3.1316765226324423
Validation loss: 2.5425901791667864
Epoch: 8| Step: 11
Training loss: 2.7176479868526635
Validation loss: 2.475605084752724
Epoch: 8| Step: 12
Training loss: 3.1030142434936883
Validation loss: 2.5515679580129826
Epoch: 8| Step: 13
Training loss: 3.262783146406398
Validation loss: 2.4985468067994177
Epoch: 8| Step: 14
Training loss: 3.292832051581416
Validation loss: 2.6008822038167203
Epoch: 8| Step: 15
Training loss: 3.0464582109263225
Validation loss: 2.5370628271565243
Epoch: 8| Step: 16
Training loss: 3.015745486683865
Validation loss: 2.5453469004730516
Epoch: 8| Step: 17
Training loss: 3.5059717186909456
Validation loss: 2.5721810071760025
Epoch: 8| Step: 18
Training loss: 3.0540375859633833
Validation loss: 2.4296176605414965
Epoch: 8| Step: 19
Training loss: 2.3063337233318353
Validation loss: 2.4506616662523033
Epoch: 9| Step: 0
Training loss: 3.4986051777383036
Validation loss: 2.4690526640412163
Epoch: 9| Step: 1
Training loss: 2.7682494733657137
Validation loss: 2.427486320772839
Epoch: 9| Step: 2
Training loss: 2.9389344629104466
Validation loss: 2.4122074617883644
Epoch: 9| Step: 3
Training loss: 2.814469389699707
Validation loss: 2.449649121314323
Epoch: 9| Step: 4
Training loss: 3.1633009005760817
Validation loss: 2.4359979176273816
Epoch: 9| Step: 5
Training loss: 3.269906044173093
Validation loss: 2.4408281676657895
Epoch: 9| Step: 6
Training loss: 2.4034114790903964
Validation loss: 2.378316696355161
Epoch: 9| Step: 7
Training loss: 3.259110665506326
Validation loss: 2.4338690212440115
Epoch: 9| Step: 8
Training loss: 3.307414631797903
Validation loss: 2.460397014707894
Epoch: 9| Step: 9
Training loss: 3.1377492615674054
Validation loss: 2.399997741808845
Epoch: 9| Step: 10
Training loss: 2.5707277466922718
Validation loss: 2.34152476150075
Epoch: 9| Step: 11
Training loss: 2.6489502177012265
Validation loss: 2.41304839756929
Epoch: 9| Step: 12
Training loss: 3.3262094348840865
Validation loss: 2.3116213885261514
Epoch: 9| Step: 13
Training loss: 2.6504771612738116
Validation loss: 2.427871564882972
Epoch: 9| Step: 14
Training loss: 2.7533643256960874
Validation loss: 2.351455364848527
Epoch: 9| Step: 15
Training loss: 2.2830396973896834
Validation loss: 2.3945241880521553
Epoch: 9| Step: 16
Training loss: 2.8724644302011813
Validation loss: 2.3905267301525184
Epoch: 9| Step: 17
Training loss: 3.198565554978836
Validation loss: 2.321447420957783
Epoch: 9| Step: 18
Training loss: 2.6584564917883626
Validation loss: 2.319205329769221
Epoch: 9| Step: 19
Training loss: 3.5694184968222125
Validation loss: 2.277665710789286
Epoch: 10| Step: 0
Training loss: 3.4409536871660564
Validation loss: 2.395049532585081
Epoch: 10| Step: 1
Training loss: 3.440835340343311
Validation loss: 2.3965615770084554
Epoch: 10| Step: 2
Training loss: 3.2234456892921908
Validation loss: 2.362470001228795
Epoch: 10| Step: 3
Training loss: 2.497609903324979
Validation loss: 2.387005184560765
Epoch: 10| Step: 4
Training loss: 2.94835135733826
Validation loss: 2.3570736237114396
Epoch: 10| Step: 5
Training loss: 2.9164222796551673
Validation loss: 2.3207793738607676
Epoch: 10| Step: 6
Training loss: 2.728775044849217
Validation loss: 2.3701881639884834
Epoch: 10| Step: 7
Training loss: 2.350570520176901
Validation loss: 2.3042216021424355
Epoch: 10| Step: 8
Training loss: 2.3304493201555525
Validation loss: 2.2940622453320394
Epoch: 10| Step: 9
Training loss: 3.3345446928652525
Validation loss: 2.2890960418733606
Epoch: 10| Step: 10
Training loss: 2.7415790806687124
Validation loss: 2.318433636430939
Epoch: 10| Step: 11
Training loss: 2.842495987620076
Validation loss: 2.2988572828432536
Epoch: 10| Step: 12
Training loss: 2.977221959069712
Validation loss: 2.3341736073997903
Epoch: 10| Step: 13
Training loss: 2.800125705077077
Validation loss: 2.284123621287114
Epoch: 10| Step: 14
Training loss: 2.3951468990884233
Validation loss: 2.3104355289649487
Epoch: 10| Step: 15
Training loss: 2.752592771874081
Validation loss: 2.2695445815138298
Epoch: 10| Step: 16
Training loss: 2.7542739947283947
Validation loss: 2.2656738726568024
Epoch: 10| Step: 17
Training loss: 3.1689218387998093
Validation loss: 2.2689344662497737
Epoch: 10| Step: 18
Training loss: 2.769393766835065
Validation loss: 2.211874353892206
Epoch: 10| Step: 19
Training loss: 2.6856848331042333
Validation loss: 2.2796586393480833
Epoch: 11| Step: 0
Training loss: 2.367369792705102
Validation loss: 2.2476328559369003
Epoch: 11| Step: 1
Training loss: 2.9378772249893848
Validation loss: 2.199089342318923
Epoch: 11| Step: 2
Training loss: 2.5503288206633004
Validation loss: 2.2673464723114103
Epoch: 11| Step: 3
Training loss: 3.155241247949778
Validation loss: 2.2347460011848197
Epoch: 11| Step: 4
Training loss: 2.2641341993774415
Validation loss: 2.2037008806598726
Epoch: 11| Step: 5
Training loss: 2.680780571523199
Validation loss: 2.2372992034129418
Epoch: 11| Step: 6
Training loss: 3.164805233282424
Validation loss: 2.268347871492929
Epoch: 11| Step: 7
Training loss: 2.5817278108032045
Validation loss: 2.1812579912826613
Epoch: 11| Step: 8
Training loss: 2.6567817604504804
Validation loss: 2.1931612474708695
Epoch: 11| Step: 9
Training loss: 2.385232465758935
Validation loss: 2.204686232235032
Epoch: 11| Step: 10
Training loss: 3.3365287882098698
Validation loss: 2.1555861354757635
Epoch: 11| Step: 11
Training loss: 2.8832008493081385
Validation loss: 2.210454649833912
Epoch: 11| Step: 12
Training loss: 1.8198580850040047
Validation loss: 2.1684591690493797
Epoch: 11| Step: 13
Training loss: 2.824995132036994
Validation loss: 2.1674566861980766
Epoch: 11| Step: 14
Training loss: 2.744137410335083
Validation loss: 2.2667374812963006
Epoch: 11| Step: 15
Training loss: 3.0122536902818626
Validation loss: 2.2407034501114764
Epoch: 11| Step: 16
Training loss: 3.026196386657296
Validation loss: 2.1913303591370425
Epoch: 11| Step: 17
Training loss: 2.93218936143182
Validation loss: 2.1552804282541693
Epoch: 11| Step: 18
Training loss: 3.178985293219652
Validation loss: 2.227535381956261
Epoch: 11| Step: 19
Training loss: 2.847095910555415
Validation loss: 2.1923690990115468
Epoch: 12| Step: 0
Training loss: 2.2904481827379586
Validation loss: 2.134054693161672
Epoch: 12| Step: 1
Training loss: 3.098710524110222
Validation loss: 2.2183725482404584
Epoch: 12| Step: 2
Training loss: 2.9743551244550592
Validation loss: 2.1743288608615927
Epoch: 12| Step: 3
Training loss: 2.090791576460631
Validation loss: 2.1785033970837255
Epoch: 12| Step: 4
Training loss: 2.9633075820553456
Validation loss: 2.1924913488822564
Epoch: 12| Step: 5
Training loss: 2.8555458987312288
Validation loss: 2.167258663626753
Epoch: 12| Step: 6
Training loss: 2.935931334760607
Validation loss: 2.2410471702333696
Epoch: 12| Step: 7
Training loss: 2.606520136091151
Validation loss: 2.131628001632098
Epoch: 12| Step: 8
Training loss: 3.3855344468193773
Validation loss: 2.1560659706996748
Epoch: 12| Step: 9
Training loss: 2.476392866516437
Validation loss: 2.16506600908721
Epoch: 12| Step: 10
Training loss: 2.8081495758821937
Validation loss: 2.194197847210179
Epoch: 12| Step: 11
Training loss: 2.999694808695128
Validation loss: 2.141945774117192
Epoch: 12| Step: 12
Training loss: 2.664085947420184
Validation loss: 2.197096269864745
Epoch: 12| Step: 13
Training loss: 2.883517047416946
Validation loss: 2.15510600969073
Epoch: 12| Step: 14
Training loss: 2.752605591012423
Validation loss: 2.12465245341801
Epoch: 12| Step: 15
Training loss: 2.742252881610159
Validation loss: 2.1395517703290468
Epoch: 12| Step: 16
Training loss: 2.086286422749821
Validation loss: 2.14906495652928
Epoch: 12| Step: 17
Training loss: 2.81328673485346
Validation loss: 2.163135436921362
Epoch: 12| Step: 18
Training loss: 2.6996075450927997
Validation loss: 2.200313747309653
Epoch: 12| Step: 19
Training loss: 2.2858587244922646
Validation loss: 2.15294860212295
Epoch: 13| Step: 0
Training loss: 2.3886097910089066
Validation loss: 2.1443789495247456
Epoch: 13| Step: 1
Training loss: 2.569638056520045
Validation loss: 2.1748709330650273
Epoch: 13| Step: 2
Training loss: 2.6486141179701215
Validation loss: 2.129005344326837
Epoch: 13| Step: 3
Training loss: 2.861554758516134
Validation loss: 2.162748820409191
Epoch: 13| Step: 4
Training loss: 2.736528257230027
Validation loss: 2.1319916072053013
Epoch: 13| Step: 5
Training loss: 3.3087666904329702
Validation loss: 2.1210355826345344
Epoch: 13| Step: 6
Training loss: 2.7381866917629547
Validation loss: 2.091904543516165
Epoch: 13| Step: 7
Training loss: 2.405114240252839
Validation loss: 2.1181376104681853
Epoch: 13| Step: 8
Training loss: 2.7185974955263026
Validation loss: 2.1046317193158157
Epoch: 13| Step: 9
Training loss: 2.529020292853064
Validation loss: 2.121600786439358
Epoch: 13| Step: 10
Training loss: 2.96060186813946
Validation loss: 2.1584741881904597
Epoch: 13| Step: 11
Training loss: 3.2973403963763275
Validation loss: 2.1077228716529506
Epoch: 13| Step: 12
Training loss: 3.1563108834919147
Validation loss: 2.101059042700925
Epoch: 13| Step: 13
Training loss: 2.2300858310894403
Validation loss: 2.10197268392897
Epoch: 13| Step: 14
Training loss: 2.6839316875786663
Validation loss: 2.1354402086376725
Epoch: 13| Step: 15
Training loss: 2.3028544749745166
Validation loss: 2.099193251542996
Epoch: 13| Step: 16
Training loss: 2.5942942955938673
Validation loss: 2.1407314116578045
Epoch: 13| Step: 17
Training loss: 2.33559820970825
Validation loss: 2.022103027314892
Epoch: 13| Step: 18
Training loss: 2.426393096964821
Validation loss: 2.0984374341275194
Epoch: 13| Step: 19
Training loss: 2.757455084012111
Validation loss: 2.107777885926931
Epoch: 14| Step: 0
Training loss: 3.0783189431683553
Validation loss: 2.0793371397834695
Epoch: 14| Step: 1
Training loss: 2.8001535475727275
Validation loss: 2.1405740898732724
Epoch: 14| Step: 2
Training loss: 2.561253500359351
Validation loss: 2.093187937614233
Epoch: 14| Step: 3
Training loss: 3.170582475066872
Validation loss: 2.124657078899845
Epoch: 14| Step: 4
Training loss: 2.7087770147521213
Validation loss: 2.1276664676314505
Epoch: 14| Step: 5
Training loss: 2.7812244542695317
Validation loss: 2.107238932220124
Epoch: 14| Step: 6
Training loss: 2.852263064093491
Validation loss: 2.074948211073456
Epoch: 14| Step: 7
Training loss: 2.4660639576410563
Validation loss: 2.0848416261640637
Epoch: 14| Step: 8
Training loss: 1.9509106710368254
Validation loss: 2.1279748396163285
Epoch: 14| Step: 9
Training loss: 2.4406887617586355
Validation loss: 2.086332060487581
Epoch: 14| Step: 10
Training loss: 2.082778195487143
Validation loss: 2.0959456431368757
Epoch: 14| Step: 11
Training loss: 2.925300263211257
Validation loss: 2.092231361034168
Epoch: 14| Step: 12
Training loss: 2.746927886210746
Validation loss: 2.133655565582893
Epoch: 14| Step: 13
Training loss: 2.4246337928728567
Validation loss: 2.048921741936923
Epoch: 14| Step: 14
Training loss: 2.7976956149274317
Validation loss: 2.0810118946786926
Epoch: 14| Step: 15
Training loss: 2.6890023933533347
Validation loss: 2.0799262162427636
Epoch: 14| Step: 16
Training loss: 2.414803894168228
Validation loss: 2.0675560026309
Epoch: 14| Step: 17
Training loss: 2.844064548409121
Validation loss: 2.0913453667571087
Epoch: 14| Step: 18
Training loss: 2.9427101517843295
Validation loss: 2.1020802601220203
Epoch: 14| Step: 19
Training loss: 2.4877724119765263
Validation loss: 2.1278899280662253
Epoch: 15| Step: 0
Training loss: 2.588413862198525
Validation loss: 2.0895022366061733
Epoch: 15| Step: 1
Training loss: 2.2041591084091694
Validation loss: 2.1111482422173893
Epoch: 15| Step: 2
Training loss: 2.220569348227081
Validation loss: 2.1104799423242304
Epoch: 15| Step: 3
Training loss: 2.104637420670209
Validation loss: 2.069103429421194
Epoch: 15| Step: 4
Training loss: 2.9137715457756257
Validation loss: 2.105882378645254
Epoch: 15| Step: 5
Training loss: 2.647323329027009
Validation loss: 2.050500073791632
Epoch: 15| Step: 6
Training loss: 2.876574375474112
Validation loss: 2.114766287035592
Epoch: 15| Step: 7
Training loss: 2.921868798560431
Validation loss: 2.061794975891303
Epoch: 15| Step: 8
Training loss: 2.6214261021942113
Validation loss: 2.1026814383719934
Epoch: 15| Step: 9
Training loss: 2.7002368116725113
Validation loss: 2.105187628101044
Epoch: 15| Step: 10
Training loss: 3.033587311672282
Validation loss: 2.1100801829266023
Epoch: 15| Step: 11
Training loss: 2.391026481874244
Validation loss: 2.0697177732078056
Epoch: 15| Step: 12
Training loss: 2.453793574299484
Validation loss: 2.069017619442382
Epoch: 15| Step: 13
Training loss: 2.240637479398868
Validation loss: 2.1182060534341494
Epoch: 15| Step: 14
Training loss: 2.7245871484868505
Validation loss: 2.0378102853570104
Epoch: 15| Step: 15
Training loss: 2.5832866438881625
Validation loss: 2.0710610598846566
Epoch: 15| Step: 16
Training loss: 2.873026958632532
Validation loss: 2.089867035579248
Epoch: 15| Step: 17
Training loss: 2.769835031740674
Validation loss: 2.125573280821522
Epoch: 15| Step: 18
Training loss: 2.956936269063674
Validation loss: 2.1191581271626623
Epoch: 15| Step: 19
Training loss: 3.080958267855409
Validation loss: 2.0764239733946894
Epoch: 16| Step: 0
Training loss: 2.8701221716526986
Validation loss: 2.102160827995011
Epoch: 16| Step: 1
Training loss: 1.6084754429757788
Validation loss: 2.117164564109893
Epoch: 16| Step: 2
Training loss: 2.9451713224619622
Validation loss: 2.099647071231783
Epoch: 16| Step: 3
Training loss: 2.510102554445094
Validation loss: 2.0742184115007323
Epoch: 16| Step: 4
Training loss: 2.9555641072212477
Validation loss: 2.099225661116875
Epoch: 16| Step: 5
Training loss: 2.6831566067266186
Validation loss: 2.103331576678198
Epoch: 16| Step: 6
Training loss: 2.8264505055235905
Validation loss: 2.0563456283520396
Epoch: 16| Step: 7
Training loss: 2.713983588864122
Validation loss: 2.0160928826788553
Epoch: 16| Step: 8
Training loss: 2.876119810205877
Validation loss: 2.0341896940683672
Epoch: 16| Step: 9
Training loss: 2.422869767194052
Validation loss: 2.070108045471178
Epoch: 16| Step: 10
Training loss: 2.1665747207303543
Validation loss: 2.0422650017281683
Epoch: 16| Step: 11
Training loss: 2.769979723088384
Validation loss: 2.0622102238202693
Epoch: 16| Step: 12
Training loss: 2.491586834023059
Validation loss: 2.0339328901155667
Epoch: 16| Step: 13
Training loss: 2.5002426983330293
Validation loss: 2.085203671629275
Epoch: 16| Step: 14
Training loss: 2.681088095447316
Validation loss: 2.1109596436732203
Epoch: 16| Step: 15
Training loss: 2.6340919351601944
Validation loss: 2.064650060433416
Epoch: 16| Step: 16
Training loss: 2.5032686799492563
Validation loss: 2.090468138134
Epoch: 16| Step: 17
Training loss: 3.263735868145062
Validation loss: 2.112638834778455
Epoch: 16| Step: 18
Training loss: 2.7331522796337184
Validation loss: 2.0529959646484515
Epoch: 16| Step: 19
Training loss: 2.390507913352572
Validation loss: 2.0897722272358923
Epoch: 17| Step: 0
Training loss: 2.5556587449493304
Validation loss: 2.074718053419774
Epoch: 17| Step: 1
Training loss: 2.234796444287466
Validation loss: 2.0678170717060613
Epoch: 17| Step: 2
Training loss: 2.3457074955400063
Validation loss: 2.0944678975518696
Epoch: 17| Step: 3
Training loss: 2.3580589413382347
Validation loss: 2.0511666286277044
Epoch: 17| Step: 4
Training loss: 2.4354540723849194
Validation loss: 2.0603373727847725
Epoch: 17| Step: 5
Training loss: 2.8348297393642676
Validation loss: 2.109580913108055
Epoch: 17| Step: 6
Training loss: 2.680960750316716
Validation loss: 2.04605752430954
Epoch: 17| Step: 7
Training loss: 2.6038240334492593
Validation loss: 2.045330220406983
Epoch: 17| Step: 8
Training loss: 2.9282284778399066
Validation loss: 2.053166940037695
Epoch: 17| Step: 9
Training loss: 2.3187752200500515
Validation loss: 2.0956937563075213
Epoch: 17| Step: 10
Training loss: 2.7086541401545827
Validation loss: 2.0476842743773744
Epoch: 17| Step: 11
Training loss: 2.671223700487182
Validation loss: 2.1192400526557353
Epoch: 17| Step: 12
Training loss: 2.603447766575107
Validation loss: 2.050744911447381
Epoch: 17| Step: 13
Training loss: 2.7976221546437983
Validation loss: 2.111925390862707
Epoch: 17| Step: 14
Training loss: 2.6955938662299435
Validation loss: 2.132344515385669
Epoch: 17| Step: 15
Training loss: 2.726499540372663
Validation loss: 2.1045519276369653
Epoch: 17| Step: 16
Training loss: 3.4580216018328565
Validation loss: 2.0742967115397115
Epoch: 17| Step: 17
Training loss: 2.3471034155980353
Validation loss: 2.027733065462844
Epoch: 17| Step: 18
Training loss: 2.9334637121645017
Validation loss: 2.074895042479003
Epoch: 17| Step: 19
Training loss: 2.3279734312553613
Validation loss: 2.106289602765273
Epoch: 18| Step: 0
Training loss: 2.442586628715907
Validation loss: 2.1301211445113983
Epoch: 18| Step: 1
Training loss: 2.8368043021473373
Validation loss: 2.0736483320302934
Epoch: 18| Step: 2
Training loss: 2.6759943744959527
Validation loss: 2.0850909150958903
Epoch: 18| Step: 3
Training loss: 2.877416010210027
Validation loss: 2.1007486810322566
Epoch: 18| Step: 4
Training loss: 2.4379403132329207
Validation loss: 2.0735263823434145
Epoch: 18| Step: 5
Training loss: 2.5523568350669903
Validation loss: 2.1011332324471375
Epoch: 18| Step: 6
Training loss: 2.6013202726302502
Validation loss: 2.0792841914587528
Epoch: 18| Step: 7
Training loss: 2.7618121572450827
Validation loss: 2.0962920406298067
Epoch: 18| Step: 8
Training loss: 2.41637391476683
Validation loss: 2.111425952311566
Epoch: 18| Step: 9
Training loss: 2.573116361665159
Validation loss: 2.054935743107694
Epoch: 18| Step: 10
Training loss: 2.190375155188053
Validation loss: 2.054001413691568
Epoch: 18| Step: 11
Training loss: 2.2939116376838635
Validation loss: 2.089487178972868
Epoch: 18| Step: 12
Training loss: 2.9469074008814933
Validation loss: 2.062288675446845
Epoch: 18| Step: 13
Training loss: 2.1472173381759196
Validation loss: 2.0564200061704296
Epoch: 18| Step: 14
Training loss: 2.513657078554936
Validation loss: 2.0852297731693854
Epoch: 18| Step: 15
Training loss: 2.3682312128044054
Validation loss: 2.066817223974085
Epoch: 18| Step: 16
Training loss: 3.0985381709762865
Validation loss: 2.100051874245341
Epoch: 18| Step: 17
Training loss: 2.641915000610898
Validation loss: 2.08561223224379
Epoch: 18| Step: 18
Training loss: 3.0585737946347744
Validation loss: 2.0615096143887426
Epoch: 18| Step: 19
Training loss: 3.063535865450471
Validation loss: 2.1247481528711254
Epoch: 19| Step: 0
Training loss: 2.8521109275699748
Validation loss: 2.06826916470257
Epoch: 19| Step: 1
Training loss: 2.74138862297629
Validation loss: 2.074567354250374
Epoch: 19| Step: 2
Training loss: 2.822593717412958
Validation loss: 2.0949445389818133
Epoch: 19| Step: 3
Training loss: 2.9914023860847663
Validation loss: 2.0779497748096256
Epoch: 19| Step: 4
Training loss: 2.748096240589162
Validation loss: 2.067322595767082
Epoch: 19| Step: 5
Training loss: 2.667743991751023
Validation loss: 2.0721808483823336
Epoch: 19| Step: 6
Training loss: 2.47849215352854
Validation loss: 2.068726856149536
Epoch: 19| Step: 7
Training loss: 2.01704096775313
Validation loss: 2.080687101826892
Epoch: 19| Step: 8
Training loss: 2.349237553705507
Validation loss: 2.0806136881967
Epoch: 19| Step: 9
Training loss: 2.0611802705036326
Validation loss: 2.0574623422607576
Epoch: 19| Step: 10
Training loss: 3.218134552716783
Validation loss: 2.05157676130362
Epoch: 19| Step: 11
Training loss: 2.446155439370776
Validation loss: 2.076476014108846
Epoch: 19| Step: 12
Training loss: 2.5178963021399587
Validation loss: 2.118808296162788
Epoch: 19| Step: 13
Training loss: 2.3988885610695165
Validation loss: 2.1235748860685564
Epoch: 19| Step: 14
Training loss: 2.9801874790486456
Validation loss: 2.0979065288915546
Epoch: 19| Step: 15
Training loss: 2.500528470449949
Validation loss: 2.0792590365580907
Epoch: 19| Step: 16
Training loss: 2.6405710068097763
Validation loss: 2.0485222441488786
Epoch: 19| Step: 17
Training loss: 2.2899659753129127
Validation loss: 2.075839505299659
Epoch: 19| Step: 18
Training loss: 2.578431267319912
Validation loss: 2.089263417834436
Epoch: 19| Step: 19
Training loss: 3.0729590116697527
Validation loss: 2.074109618392555
Epoch: 20| Step: 0
Training loss: 2.6854544550858757
Validation loss: 2.0384561961987595
Epoch: 20| Step: 1
Training loss: 2.7486423262132837
Validation loss: 2.0890028493897663
Epoch: 20| Step: 2
Training loss: 2.494831751194128
Validation loss: 2.0828064948579055
Epoch: 20| Step: 3
Training loss: 2.863342700834868
Validation loss: 2.030170547832933
Epoch: 20| Step: 4
Training loss: 2.5076953706097047
Validation loss: 2.063436949520434
Epoch: 20| Step: 5
Training loss: 2.371100788640191
Validation loss: 2.0611118287817956
Epoch: 20| Step: 6
Training loss: 2.6022283028584856
Validation loss: 2.030621583154222
Epoch: 20| Step: 7
Training loss: 2.030704366319399
Validation loss: 2.123076220496541
Epoch: 20| Step: 8
Training loss: 2.7260362177322928
Validation loss: 2.048166829804229
Epoch: 20| Step: 9
Training loss: 3.1791238871071377
Validation loss: 2.133163592803137
Epoch: 20| Step: 10
Training loss: 2.569468443704051
Validation loss: 2.1211876920207224
Epoch: 20| Step: 11
Training loss: 2.506120247466826
Validation loss: 2.0765193340418966
Epoch: 20| Step: 12
Training loss: 2.988656532807634
Validation loss: 2.092340188146112
Epoch: 20| Step: 13
Training loss: 2.6019462783510354
Validation loss: 2.03637302446037
Epoch: 20| Step: 14
Training loss: 2.5577128284308475
Validation loss: 2.0412061495965967
Epoch: 20| Step: 15
Training loss: 2.9066683560404405
Validation loss: 2.0881406274860512
Epoch: 20| Step: 16
Training loss: 2.943985941314301
Validation loss: 2.1190838641825085
Epoch: 20| Step: 17
Training loss: 2.1804716279008463
Validation loss: 2.084931104144136
Epoch: 20| Step: 18
Training loss: 2.3774449663180626
Validation loss: 2.10189579133739
Epoch: 20| Step: 19
Training loss: 2.603529452883149
Validation loss: 2.0828710919096096
Epoch: 21| Step: 0
Training loss: 2.922018445415621
Validation loss: 2.0699510006790662
Epoch: 21| Step: 1
Training loss: 2.715640602901046
Validation loss: 2.059864075106297
Epoch: 21| Step: 2
Training loss: 2.866716642461634
Validation loss: 2.1019372490313426
Epoch: 21| Step: 3
Training loss: 1.9110045626359784
Validation loss: 2.068790915214878
Epoch: 21| Step: 4
Training loss: 2.701003990003738
Validation loss: 2.031666882091846
Epoch: 21| Step: 5
Training loss: 2.383944683316455
Validation loss: 2.084826304756106
Epoch: 21| Step: 6
Training loss: 2.475068998819968
Validation loss: 2.0367798053705712
Epoch: 21| Step: 7
Training loss: 2.894276719736334
Validation loss: 1.9985858242746775
Epoch: 21| Step: 8
Training loss: 2.710872506453658
Validation loss: 2.074824424793492
Epoch: 21| Step: 9
Training loss: 3.045538976164067
Validation loss: 2.0597415188465127
Epoch: 21| Step: 10
Training loss: 2.762796280796789
Validation loss: 2.116624976142118
Epoch: 21| Step: 11
Training loss: 2.7175613084771486
Validation loss: 2.119204116787147
Epoch: 21| Step: 12
Training loss: 2.746663757464649
Validation loss: 2.1107165210710552
Epoch: 21| Step: 13
Training loss: 2.684155001523681
Validation loss: 2.1477368242843484
Epoch: 21| Step: 14
Training loss: 2.273911049934165
Validation loss: 2.0715021692123528
Epoch: 21| Step: 15
Training loss: 2.2625564315249598
Validation loss: 2.093219619897126
Epoch: 21| Step: 16
Training loss: 2.150959545966355
Validation loss: 2.0693874633011546
Epoch: 21| Step: 17
Training loss: 2.98751202824298
Validation loss: 2.071361438157078
Epoch: 21| Step: 18
Training loss: 2.8503375204899664
Validation loss: 2.0684918208309924
Epoch: 21| Step: 19
Training loss: 2.3055402826725095
Validation loss: 2.0845194972496643
Epoch: 22| Step: 0
Training loss: 2.6921461884820985
Validation loss: 2.1021183590519072
Epoch: 22| Step: 1
Training loss: 2.224148696744877
Validation loss: 2.089375512710155
Epoch: 22| Step: 2
Training loss: 2.5000227927122607
Validation loss: 2.106628341609551
Epoch: 22| Step: 3
Training loss: 2.7308874941559393
Validation loss: 2.0567004189852964
Epoch: 22| Step: 4
Training loss: 2.26801904930713
Validation loss: 2.0434403463238944
Epoch: 22| Step: 5
Training loss: 3.153895037774998
Validation loss: 2.0687239599718916
Epoch: 22| Step: 6
Training loss: 2.8420874797718283
Validation loss: 2.087606487112276
Epoch: 22| Step: 7
Training loss: 2.8103017905595506
Validation loss: 2.094206022841062
Epoch: 22| Step: 8
Training loss: 2.3550229386105426
Validation loss: 2.069790722736631
Epoch: 22| Step: 9
Training loss: 2.7759626042103602
Validation loss: 2.0972083806326616
Epoch: 22| Step: 10
Training loss: 2.3835328060874916
Validation loss: 2.120982712064355
Epoch: 22| Step: 11
Training loss: 3.1272721232117275
Validation loss: 2.0789201554006747
Epoch: 22| Step: 12
Training loss: 2.47654882962759
Validation loss: 2.0216462165630134
Epoch: 22| Step: 13
Training loss: 2.6674843567637097
Validation loss: 2.084407222357207
Epoch: 22| Step: 14
Training loss: 2.3305123397019227
Validation loss: 2.113271316136123
Epoch: 22| Step: 15
Training loss: 2.9209439839415303
Validation loss: 2.084130244346226
Epoch: 22| Step: 16
Training loss: 2.2232094664529645
Validation loss: 2.1182463561237608
Epoch: 22| Step: 17
Training loss: 2.4533578555636875
Validation loss: 2.072062936326952
Epoch: 22| Step: 18
Training loss: 2.8240561537414344
Validation loss: 2.1182846319380886
Epoch: 22| Step: 19
Training loss: 2.65920909538917
Validation loss: 2.102569107755908
Epoch: 23| Step: 0
Training loss: 2.4496170523171434
Validation loss: 2.0730389529950637
Epoch: 23| Step: 1
Training loss: 2.5023866705141895
Validation loss: 2.109260318911163
Epoch: 23| Step: 2
Training loss: 2.836478862111452
Validation loss: 2.0922086992623976
Epoch: 23| Step: 3
Training loss: 2.24502065483396
Validation loss: 2.099330141833196
Epoch: 23| Step: 4
Training loss: 2.8639919340989746
Validation loss: 2.074868994842389
Epoch: 23| Step: 5
Training loss: 2.0624171153667166
Validation loss: 2.0465137180012936
Epoch: 23| Step: 6
Training loss: 2.987551611290917
Validation loss: 2.0935656988616365
Epoch: 23| Step: 7
Training loss: 2.723027164364361
Validation loss: 2.02807944974274
Epoch: 23| Step: 8
Training loss: 2.783440830720815
Validation loss: 2.0550146741458684
Epoch: 23| Step: 9
Training loss: 2.455380320253839
Validation loss: 2.102953539478137
Epoch: 23| Step: 10
Training loss: 2.546293414592718
Validation loss: 2.133284211189788
Epoch: 23| Step: 11
Training loss: 2.9912404287131724
Validation loss: 2.12552480028589
Epoch: 23| Step: 12
Training loss: 2.612570262493402
Validation loss: 2.1041011502110543
Epoch: 23| Step: 13
Training loss: 2.590493145245744
Validation loss: 2.103686589768602
Epoch: 23| Step: 14
Training loss: 2.8013351935420276
Validation loss: 2.071657292227222
Epoch: 23| Step: 15
Training loss: 2.619043676984388
Validation loss: 2.0736257458262015
Epoch: 23| Step: 16
Training loss: 2.356650895637428
Validation loss: 2.0495782703862337
Epoch: 23| Step: 17
Training loss: 2.7074155768619934
Validation loss: 2.1201821572942947
Epoch: 23| Step: 18
Training loss: 2.7154611448101016
Validation loss: 2.088982996576908
Epoch: 23| Step: 19
Training loss: 2.646969909047297
Validation loss: 2.1232070518938007
Epoch: 24| Step: 0
Training loss: 2.368711276983435
Validation loss: 2.102918741401955
Epoch: 24| Step: 1
Training loss: 2.583358262054594
Validation loss: 2.0998981263843204
Epoch: 24| Step: 2
Training loss: 2.8155378254087395
Validation loss: 2.0899288092423003
Epoch: 24| Step: 3
Training loss: 1.725504693545842
Validation loss: 2.1080112979740413
Epoch: 24| Step: 4
Training loss: 2.706506279138046
Validation loss: 2.091280800134972
Epoch: 24| Step: 5
Training loss: 2.2561379529019083
Validation loss: 2.0517563097362936
Epoch: 24| Step: 6
Training loss: 2.6546966498690443
Validation loss: 2.0116327671654575
Epoch: 24| Step: 7
Training loss: 2.618403001615609
Validation loss: 2.0389661397303502
Epoch: 24| Step: 8
Training loss: 2.57019896097065
Validation loss: 2.0543056072017327
Epoch: 24| Step: 9
Training loss: 2.8782572331738145
Validation loss: 2.0622824926966987
Epoch: 24| Step: 10
Training loss: 2.53546676732519
Validation loss: 2.032018966783082
Epoch: 24| Step: 11
Training loss: 2.521823993152854
Validation loss: 2.0118263188533416
Epoch: 24| Step: 12
Training loss: 2.8682629805571813
Validation loss: 2.079589399801387
Epoch: 24| Step: 13
Training loss: 2.5001020410693795
Validation loss: 2.10530046143666
Epoch: 24| Step: 14
Training loss: 2.926745267375933
Validation loss: 2.105624209045737
Epoch: 24| Step: 15
Training loss: 3.0712375169561668
Validation loss: 2.086837247701097
Epoch: 24| Step: 16
Training loss: 2.8899766349507954
Validation loss: 2.0445482409132776
Epoch: 24| Step: 17
Training loss: 2.403550057588461
Validation loss: 2.0596939117875825
Epoch: 24| Step: 18
Training loss: 2.3903247919014707
Validation loss: 2.0743861164312127
Epoch: 24| Step: 19
Training loss: 3.065801281386033
Validation loss: 2.0959706876521285
Epoch: 25| Step: 0
Training loss: 2.01020782914539
Validation loss: 2.0794539444600844
Epoch: 25| Step: 1
Training loss: 3.188049867362038
Validation loss: 2.074937287281032
Epoch: 25| Step: 2
Training loss: 2.7159103823049673
Validation loss: 2.0720263857612338
Epoch: 25| Step: 3
Training loss: 2.7157792270355037
Validation loss: 2.0899787647154673
Epoch: 25| Step: 4
Training loss: 2.4175107950563257
Validation loss: 2.0961630384409893
Epoch: 25| Step: 5
Training loss: 2.6100640215274735
Validation loss: 2.076157600092317
Epoch: 25| Step: 6
Training loss: 2.7942993409100083
Validation loss: 2.110146978284054
Epoch: 25| Step: 7
Training loss: 2.338732422069916
Validation loss: 2.0915754357997054
Epoch: 25| Step: 8
Training loss: 2.7555641756982547
Validation loss: 2.061769973481954
Epoch: 25| Step: 9
Training loss: 2.328054337421238
Validation loss: 2.0649352751182843
Epoch: 25| Step: 10
Training loss: 2.6963762478547233
Validation loss: 2.042086822631976
Epoch: 25| Step: 11
Training loss: 2.7050959286981806
Validation loss: 2.0379669532143807
Epoch: 25| Step: 12
Training loss: 2.629814909162129
Validation loss: 2.1037191284517354
Epoch: 25| Step: 13
Training loss: 2.9713715874007742
Validation loss: 2.1130641061793667
Epoch: 25| Step: 14
Training loss: 2.3776545496627004
Validation loss: 2.0969188265900023
Epoch: 25| Step: 15
Training loss: 2.486455370215792
Validation loss: 2.0968073852917803
Epoch: 25| Step: 16
Training loss: 2.4808210948693046
Validation loss: 2.0676646109443357
Epoch: 25| Step: 17
Training loss: 2.6889874977056665
Validation loss: 2.1152754795554385
Epoch: 25| Step: 18
Training loss: 2.6505062159587895
Validation loss: 2.092748255434096
Epoch: 25| Step: 19
Training loss: 2.8968399457240603
Validation loss: 2.119080444746487
Epoch: 26| Step: 0
Training loss: 2.993971489535491
Validation loss: 2.1429297666264215
Epoch: 26| Step: 1
Training loss: 2.7941937941104604
Validation loss: 2.1035758993850586
Epoch: 26| Step: 2
Training loss: 2.580003273836173
Validation loss: 2.096459306137924
Epoch: 26| Step: 3
Training loss: 2.430209677170307
Validation loss: 2.1204022698905476
Epoch: 26| Step: 4
Training loss: 2.900619631373725
Validation loss: 2.0379186289559392
Epoch: 26| Step: 5
Training loss: 1.9694214538693375
Validation loss: 2.0838666623188358
Epoch: 26| Step: 6
Training loss: 2.1850395534261207
Validation loss: 2.070224644639292
Epoch: 26| Step: 7
Training loss: 2.60724795329359
Validation loss: 2.080385432860967
Epoch: 26| Step: 8
Training loss: 3.040770063242969
Validation loss: 2.057725207087801
Epoch: 26| Step: 9
Training loss: 2.2911398773451253
Validation loss: 2.0682576162469486
Epoch: 26| Step: 10
Training loss: 2.809622840005803
Validation loss: 2.126212126618057
Epoch: 26| Step: 11
Training loss: 2.580815801054893
Validation loss: 2.1110093471669025
Epoch: 26| Step: 12
Training loss: 2.398414735965617
Validation loss: 2.0948952731250494
Epoch: 26| Step: 13
Training loss: 2.9857102847121384
Validation loss: 2.0698536519653676
Epoch: 26| Step: 14
Training loss: 3.3263279894459568
Validation loss: 2.0354202954402516
Epoch: 26| Step: 15
Training loss: 2.864634528425103
Validation loss: 2.0878076114711543
Epoch: 26| Step: 16
Training loss: 2.522856087328769
Validation loss: 2.0450123568333787
Epoch: 26| Step: 17
Training loss: 2.3652829607029884
Validation loss: 2.0708661507377517
Epoch: 26| Step: 18
Training loss: 2.433929175318943
Validation loss: 2.023614301609993
Epoch: 26| Step: 19
Training loss: 2.186429879153475
Validation loss: 2.0831353480876995
Epoch: 27| Step: 0
Training loss: 2.7048121132178586
Validation loss: 2.087777866513827
Epoch: 27| Step: 1
Training loss: 2.4212427113767467
Validation loss: 2.069269488567368
Epoch: 27| Step: 2
Training loss: 2.4508614757711604
Validation loss: 2.068474375672668
Epoch: 27| Step: 3
Training loss: 2.526762386948012
Validation loss: 2.0775728030611287
Epoch: 27| Step: 4
Training loss: 2.5321105624462095
Validation loss: 2.0660292903527653
Epoch: 27| Step: 5
Training loss: 2.6491058316545053
Validation loss: 2.1195114091741813
Epoch: 27| Step: 6
Training loss: 2.4321845369346673
Validation loss: 2.091608985195706
Epoch: 27| Step: 7
Training loss: 3.0076647437328115
Validation loss: 2.09003524688158
Epoch: 27| Step: 8
Training loss: 2.2083742629762684
Validation loss: 2.106589507472355
Epoch: 27| Step: 9
Training loss: 2.292570687205732
Validation loss: 2.1007643796488713
Epoch: 27| Step: 10
Training loss: 2.750890587603109
Validation loss: 2.08052393755644
Epoch: 27| Step: 11
Training loss: 2.7662166673778295
Validation loss: 2.0172411738221223
Epoch: 27| Step: 12
Training loss: 2.9348232979034687
Validation loss: 2.1172801065994356
Epoch: 27| Step: 13
Training loss: 2.8235103832099218
Validation loss: 2.062597608009975
Epoch: 27| Step: 14
Training loss: 2.3943241396973596
Validation loss: 2.074966889422258
Epoch: 27| Step: 15
Training loss: 2.841998556524631
Validation loss: 1.9809779900956677
Epoch: 27| Step: 16
Training loss: 2.8567212406792937
Validation loss: 2.0669932601809795
Epoch: 27| Step: 17
Training loss: 3.3632945770460405
Validation loss: 2.037844579322482
Epoch: 27| Step: 18
Training loss: 1.9287157584987216
Validation loss: 2.088887347105603
Epoch: 27| Step: 19
Training loss: 2.4327433219193138
Validation loss: 2.019640385676236
Epoch: 28| Step: 0
Training loss: 2.6655020753662413
Validation loss: 2.0488246118390308
Epoch: 28| Step: 1
Training loss: 2.854435891775099
Validation loss: 2.058903819728399
Epoch: 28| Step: 2
Training loss: 2.5054464141164123
Validation loss: 2.0832875576365573
Epoch: 28| Step: 3
Training loss: 2.6659288776523433
Validation loss: 2.111666064505445
Epoch: 28| Step: 4
Training loss: 2.344627724645278
Validation loss: 2.1111948669126055
Epoch: 28| Step: 5
Training loss: 2.5299123361349563
Validation loss: 2.0868136466422293
Epoch: 28| Step: 6
Training loss: 2.0164913710814623
Validation loss: 2.115079258560998
Epoch: 28| Step: 7
Training loss: 2.8885678781355786
Validation loss: 2.081341131945256
Epoch: 28| Step: 8
Training loss: 2.6187112045145695
Validation loss: 2.1113538859792893
Epoch: 28| Step: 9
Training loss: 3.1271900894948743
Validation loss: 2.1105278637193923
Epoch: 28| Step: 10
Training loss: 2.6718592950013584
Validation loss: 2.123318144791591
Epoch: 28| Step: 11
Training loss: 2.348685802091936
Validation loss: 2.0831884316979337
Epoch: 28| Step: 12
Training loss: 2.5316902060436703
Validation loss: 2.0463151365773427
Epoch: 28| Step: 13
Training loss: 3.1192633808323182
Validation loss: 2.092383008439906
Epoch: 28| Step: 14
Training loss: 2.6427323098323607
Validation loss: 2.1187967212203955
Epoch: 28| Step: 15
Training loss: 2.871767631906356
Validation loss: 2.087626751581301
Epoch: 28| Step: 16
Training loss: 2.5429164336136343
Validation loss: 2.07502734257517
Epoch: 28| Step: 17
Training loss: 2.3801058045278305
Validation loss: 2.080742949654467
Epoch: 28| Step: 18
Training loss: 2.260087922504333
Validation loss: 2.041673865052391
Epoch: 28| Step: 19
Training loss: 2.834241459738321
Validation loss: 2.0920910981021708
Epoch: 29| Step: 0
Training loss: 2.3571125829494717
Validation loss: 2.1041968994448332
Epoch: 29| Step: 1
Training loss: 2.283618063704276
Validation loss: 2.0213333091103958
Epoch: 29| Step: 2
Training loss: 2.350924383124578
Validation loss: 2.117765878764086
Epoch: 29| Step: 3
Training loss: 2.605908129474302
Validation loss: 2.086182048837569
Epoch: 29| Step: 4
Training loss: 2.221067588241489
Validation loss: 2.0112820262673345
Epoch: 29| Step: 5
Training loss: 2.724356909646105
Validation loss: 2.014017531924385
Epoch: 29| Step: 6
Training loss: 2.4740726698839506
Validation loss: 2.060182181299103
Epoch: 29| Step: 7
Training loss: 2.7913049397099154
Validation loss: 2.0414939006975987
Epoch: 29| Step: 8
Training loss: 2.7101071539946187
Validation loss: 2.0801838695912895
Epoch: 29| Step: 9
Training loss: 3.0706754280668758
Validation loss: 2.057996742510062
Epoch: 29| Step: 10
Training loss: 2.432819665838234
Validation loss: 2.0741836926438086
Epoch: 29| Step: 11
Training loss: 3.0003502959143553
Validation loss: 1.9983899295888983
Epoch: 29| Step: 12
Training loss: 2.751676135340511
Validation loss: 2.0782386793750662
Epoch: 29| Step: 13
Training loss: 3.025873508913312
Validation loss: 2.111361604876503
Epoch: 29| Step: 14
Training loss: 2.6624663373225
Validation loss: 2.0245710978937286
Epoch: 29| Step: 15
Training loss: 2.441497849844119
Validation loss: 2.116266922522776
Epoch: 29| Step: 16
Training loss: 2.495013604748162
Validation loss: 2.114063412033702
Epoch: 29| Step: 17
Training loss: 2.9511429528385063
Validation loss: 2.10783306237915
Epoch: 29| Step: 18
Training loss: 2.568270443149014
Validation loss: 1.991297134176816
Epoch: 29| Step: 19
Training loss: 2.5443593338118857
Validation loss: 2.047557955058457
Epoch: 30| Step: 0
Training loss: 2.3136875093451272
Validation loss: 2.0756837663133583
Epoch: 30| Step: 1
Training loss: 2.783296239533394
Validation loss: 2.092598170280553
Epoch: 30| Step: 2
Training loss: 2.426223100358836
Validation loss: 2.0445307449371644
Epoch: 30| Step: 3
Training loss: 2.462785686825672
Validation loss: 2.0361114842057795
Epoch: 30| Step: 4
Training loss: 2.904606508271905
Validation loss: 2.011428575825811
Epoch: 30| Step: 5
Training loss: 2.036893546063015
Validation loss: 2.0870120421640648
Epoch: 30| Step: 6
Training loss: 2.8938826067141825
Validation loss: 2.1249120422980377
Epoch: 30| Step: 7
Training loss: 2.5823871869302315
Validation loss: 2.118702860005828
Epoch: 30| Step: 8
Training loss: 2.3490409639179974
Validation loss: 2.0186952347301412
Epoch: 30| Step: 9
Training loss: 2.4564920631309977
Validation loss: 2.1172887020950917
Epoch: 30| Step: 10
Training loss: 2.9149911336616743
Validation loss: 2.064982187930691
Epoch: 30| Step: 11
Training loss: 2.0843237874890095
Validation loss: 2.058759789922136
Epoch: 30| Step: 12
Training loss: 2.5096607468359116
Validation loss: 2.072413946476987
Epoch: 30| Step: 13
Training loss: 3.3547407966008236
Validation loss: 2.1085192193039752
Epoch: 30| Step: 14
Training loss: 2.441795476785814
Validation loss: 2.110582322336283
Epoch: 30| Step: 15
Training loss: 2.8712394002702997
Validation loss: 2.0791863888841022
Epoch: 30| Step: 16
Training loss: 2.7488307200987823
Validation loss: 2.1100129656294015
Epoch: 30| Step: 17
Training loss: 2.5555904554204654
Validation loss: 2.06908379103463
Epoch: 30| Step: 18
Training loss: 2.802197214149951
Validation loss: 2.1102315643418716
Epoch: 30| Step: 19
Training loss: 2.8408627787196354
Validation loss: 2.1146903874114322
