Epoch: 1| Step: 0
Training loss: 5.941407534105712
Validation loss: 4.992702220893042
Epoch: 1| Step: 1
Training loss: 4.826265933927619
Validation loss: 4.911257030303556
Epoch: 1| Step: 2
Training loss: 5.57884301445047
Validation loss: 5.003667331524905
Epoch: 1| Step: 3
Training loss: 4.769899546207258
Validation loss: 4.993169249750303
Epoch: 1| Step: 4
Training loss: 4.535248564077151
Validation loss: 4.975612921459335
Epoch: 1| Step: 5
Training loss: 5.320236855303832
Validation loss: 4.823668754905699
Epoch: 1| Step: 6
Training loss: 5.274871405168514
Validation loss: 4.719083143643068
Epoch: 1| Step: 7
Training loss: 4.7958973438135075
Validation loss: 4.595030028583673
Epoch: 1| Step: 8
Training loss: 4.073779132711927
Validation loss: 4.529504092534364
Epoch: 1| Step: 9
Training loss: 4.245020923001293
Validation loss: 4.451706389202759
Epoch: 1| Step: 10
Training loss: 4.501532399673749
Validation loss: 4.46603102269091
Epoch: 1| Step: 11
Training loss: 5.023287520238746
Validation loss: 4.3767037206728805
Epoch: 1| Step: 12
Training loss: 5.162715857475057
Validation loss: 4.379417065732135
Epoch: 1| Step: 13
Training loss: 4.297611353809075
Validation loss: 4.300056641722416
Epoch: 1| Step: 14
Training loss: 6.001094718247898
Validation loss: 4.1718566471155265
Epoch: 1| Step: 15
Training loss: 4.455971968913644
Validation loss: 4.280331975980924
Epoch: 1| Step: 16
Training loss: 3.824182216013883
Validation loss: 4.1971453424519245
Epoch: 1| Step: 17
Training loss: 4.8653541406249445
Validation loss: 4.0415099358760065
Epoch: 1| Step: 18
Training loss: 5.779707089298379
Validation loss: 4.106649566777549
Epoch: 1| Step: 19
Training loss: 4.317469069873173
Validation loss: 4.099541080462992
Epoch: 1| Step: 20
Training loss: 4.366464626695336
Validation loss: 4.033040106481718
Epoch: 1| Step: 21
Training loss: 4.0461007927838635
Validation loss: 3.946702266470457
Epoch: 1| Step: 22
Training loss: 3.913025374071193
Validation loss: 3.8319273390392934
Epoch: 1| Step: 23
Training loss: 5.553608163090946
Validation loss: 3.881706627022667
Epoch: 1| Step: 24
Training loss: 4.773238906849858
Validation loss: 3.851612427379027
Epoch: 1| Step: 25
Training loss: 3.669521145464585
Validation loss: 3.71834419146945
Epoch: 1| Step: 26
Training loss: 4.760950215807498
Validation loss: 3.7372714613697577
Epoch: 1| Step: 27
Training loss: 2.270326563666222
Validation loss: 3.6910086109463385
Epoch: 1| Step: 28
Training loss: 3.7849684157874157
Validation loss: 3.537854043830698
Epoch: 1| Step: 29
Training loss: 5.080980266998959
Validation loss: 3.6123583832839445
Epoch: 1| Step: 30
Training loss: 4.540477118607648
Validation loss: 3.478419206231451
Epoch: 1| Step: 31
Training loss: 3.2653215623266734
Validation loss: 3.5332962807087815
Epoch: 2| Step: 0
Training loss: 3.598486788930172
Validation loss: 3.5598128208033013
Epoch: 2| Step: 1
Training loss: 3.8332614615516625
Validation loss: 3.4913542155798427
Epoch: 2| Step: 2
Training loss: 3.96602663331508
Validation loss: 3.3532592499471323
Epoch: 2| Step: 3
Training loss: 3.7836139950160415
Validation loss: 3.444205310267894
Epoch: 2| Step: 4
Training loss: 3.3262057075863014
Validation loss: 3.3659030957883567
Epoch: 2| Step: 5
Training loss: 3.6649184538758255
Validation loss: 3.3990677891101724
Epoch: 2| Step: 6
Training loss: 3.4828172973764064
Validation loss: 3.266577422140088
Epoch: 2| Step: 7
Training loss: 4.248844887329604
Validation loss: 3.3067105818789604
Epoch: 2| Step: 8
Training loss: 4.4080672608659635
Validation loss: 3.2775730947551747
Epoch: 2| Step: 9
Training loss: 3.549481345959911
Validation loss: 3.224159886326916
Epoch: 2| Step: 10
Training loss: 4.705668930515423
Validation loss: 3.176735354299962
Epoch: 2| Step: 11
Training loss: 3.6120703735424162
Validation loss: 3.1889910387180254
Epoch: 2| Step: 12
Training loss: 2.794016650828155
Validation loss: 3.13411289856028
Epoch: 2| Step: 13
Training loss: 3.575636752315492
Validation loss: 3.1358911831558296
Epoch: 2| Step: 14
Training loss: 3.8413070731076977
Validation loss: 3.1409069387861326
Epoch: 2| Step: 15
Training loss: 4.191198054081916
Validation loss: 3.0104280535679497
Epoch: 2| Step: 16
Training loss: 3.9101425917593624
Validation loss: 3.0180282221619126
Epoch: 2| Step: 17
Training loss: 2.5802759618806723
Validation loss: 2.9202854241582044
Epoch: 2| Step: 18
Training loss: 2.6205593877685307
Validation loss: 2.972846105359909
Epoch: 2| Step: 19
Training loss: 3.8056665684332267
Validation loss: 2.989278331772349
Epoch: 2| Step: 20
Training loss: 4.240152506694694
Validation loss: 2.8822015766401856
Epoch: 2| Step: 21
Training loss: 3.3822357884286887
Validation loss: 2.87011347489055
Epoch: 2| Step: 22
Training loss: 3.184624365868692
Validation loss: 2.7785227606813785
Epoch: 2| Step: 23
Training loss: 3.7610254332116844
Validation loss: 2.8242187134935435
Epoch: 2| Step: 24
Training loss: 4.195690741794639
Validation loss: 2.688351988630168
Epoch: 2| Step: 25
Training loss: 2.977497424581777
Validation loss: 2.716968825113088
Epoch: 2| Step: 26
Training loss: 2.981028972885473
Validation loss: 2.67303776736637
Epoch: 2| Step: 27
Training loss: 2.1401186156154544
Validation loss: 2.696360462441759
Epoch: 2| Step: 28
Training loss: 3.3527425898113856
Validation loss: 2.7341019062137333
Epoch: 2| Step: 29
Training loss: 2.1697136532705694
Validation loss: 2.674741575213977
Epoch: 2| Step: 30
Training loss: 3.381134815334244
Validation loss: 2.6000853389629786
Epoch: 2| Step: 31
Training loss: 3.1826416089600764
Validation loss: 2.6292164017716546
Epoch: 3| Step: 0
Training loss: 3.0899048617139266
Validation loss: 2.6061712464384947
Epoch: 3| Step: 1
Training loss: 2.7578300497128834
Validation loss: 2.593095330541841
Epoch: 3| Step: 2
Training loss: 3.7248624686639675
Validation loss: 2.518238760344422
Epoch: 3| Step: 3
Training loss: 3.6534624477412745
Validation loss: 2.5908172864012013
Epoch: 3| Step: 4
Training loss: 3.8305947569557133
Validation loss: 2.500865250118387
Epoch: 3| Step: 5
Training loss: 3.2531329972959457
Validation loss: 2.5072536386883826
Epoch: 3| Step: 6
Training loss: 2.899450736811252
Validation loss: 2.483450890259748
Epoch: 3| Step: 7
Training loss: 3.019184758883823
Validation loss: 2.4195446181364058
Epoch: 3| Step: 8
Training loss: 2.521588194088965
Validation loss: 2.5120848367097164
Epoch: 3| Step: 9
Training loss: 3.1388406571665186
Validation loss: 2.4536728736003335
Epoch: 3| Step: 10
Training loss: 2.3754033197968005
Validation loss: 2.4599145316631432
Epoch: 3| Step: 11
Training loss: 2.925938682242198
Validation loss: 2.3410040879860055
Epoch: 3| Step: 12
Training loss: 2.165167461024053
Validation loss: 2.4226289602551145
Epoch: 3| Step: 13
Training loss: 2.9490987791202907
Validation loss: 2.4130710696599844
Epoch: 3| Step: 14
Training loss: 2.879515708895063
Validation loss: 2.3483218764318194
Epoch: 3| Step: 15
Training loss: 2.373617773888065
Validation loss: 2.3353378265919247
Epoch: 3| Step: 16
Training loss: 3.0258448280137853
Validation loss: 2.4038813540163777
Epoch: 3| Step: 17
Training loss: 2.3281456863201146
Validation loss: 2.3387626950582527
Epoch: 3| Step: 18
Training loss: 3.0812990505809927
Validation loss: 2.3916829502475148
Epoch: 3| Step: 19
Training loss: 3.1925115643966198
Validation loss: 2.376718588458137
Epoch: 3| Step: 20
Training loss: 2.660211638155474
Validation loss: 2.2999635772242666
Epoch: 3| Step: 21
Training loss: 3.2253581240036233
Validation loss: 2.3408369378349168
Epoch: 3| Step: 22
Training loss: 1.813781416848979
Validation loss: 2.2569922247676297
Epoch: 3| Step: 23
Training loss: 2.752200113533771
Validation loss: 2.299825481913309
Epoch: 3| Step: 24
Training loss: 3.4513133548391424
Validation loss: 2.3013662621313564
Epoch: 3| Step: 25
Training loss: 3.1363604235224294
Validation loss: 2.264851847499868
Epoch: 3| Step: 26
Training loss: 2.6005392725758303
Validation loss: 2.278920886355445
Epoch: 3| Step: 27
Training loss: 2.2842079738188183
Validation loss: 2.264734589828531
Epoch: 3| Step: 28
Training loss: 2.671163363803399
Validation loss: 2.157798099058851
Epoch: 3| Step: 29
Training loss: 3.121974090439335
Validation loss: 2.181212803318012
Epoch: 3| Step: 30
Training loss: 3.0175335630811615
Validation loss: 2.245855359320046
Epoch: 3| Step: 31
Training loss: 3.201971376671173
Validation loss: 2.2082846775309184
Epoch: 4| Step: 0
Training loss: 2.848716004902369
Validation loss: 2.2125437151349536
Epoch: 4| Step: 1
Training loss: 2.317197616256681
Validation loss: 2.1994387281243357
Epoch: 4| Step: 2
Training loss: 2.406201845157865
Validation loss: 2.137381954698136
Epoch: 4| Step: 3
Training loss: 2.572165241759228
Validation loss: 2.184651490849148
Epoch: 4| Step: 4
Training loss: 2.831645986725852
Validation loss: 2.149159864699697
Epoch: 4| Step: 5
Training loss: 2.409446079972009
Validation loss: 2.180024132775906
Epoch: 4| Step: 6
Training loss: 3.0614873029167393
Validation loss: 2.1395263270907123
Epoch: 4| Step: 7
Training loss: 2.8800906018734898
Validation loss: 2.205090641883221
Epoch: 4| Step: 8
Training loss: 2.2673126249271522
Validation loss: 2.0695734223681717
Epoch: 4| Step: 9
Training loss: 1.6973513810910585
Validation loss: 2.1069552502494218
Epoch: 4| Step: 10
Training loss: 1.9788499946896314
Validation loss: 2.0975967350892986
Epoch: 4| Step: 11
Training loss: 3.4387751208337307
Validation loss: 2.0921180810008537
Epoch: 4| Step: 12
Training loss: 2.085857947043408
Validation loss: 2.159630303315841
Epoch: 4| Step: 13
Training loss: 2.810337676532864
Validation loss: 2.14963902624404
Epoch: 4| Step: 14
Training loss: 2.8673594576542745
Validation loss: 2.131437625697772
Epoch: 4| Step: 15
Training loss: 2.85238543615543
Validation loss: 2.1450898402291476
Epoch: 4| Step: 16
Training loss: 3.0573804453621904
Validation loss: 2.116892579824231
Epoch: 4| Step: 17
Training loss: 2.1490006142354012
Validation loss: 2.1103630839827874
Epoch: 4| Step: 18
Training loss: 2.9150290842061213
Validation loss: 2.1305452536068565
Epoch: 4| Step: 19
Training loss: 2.940533796106156
Validation loss: 2.0694985708097366
Epoch: 4| Step: 20
Training loss: 2.6346916035631627
Validation loss: 2.1034944398075925
Epoch: 4| Step: 21
Training loss: 2.8790493519386633
Validation loss: 2.108637358475163
Epoch: 4| Step: 22
Training loss: 2.262002192576296
Validation loss: 2.1292282676186596
Epoch: 4| Step: 23
Training loss: 2.517142365404393
Validation loss: 2.1023866845740136
Epoch: 4| Step: 24
Training loss: 2.9446013626734935
Validation loss: 2.0508111679664744
Epoch: 4| Step: 25
Training loss: 2.6483300111276455
Validation loss: 2.059513559132491
Epoch: 4| Step: 26
Training loss: 2.7216517430223566
Validation loss: 2.0883749042520416
Epoch: 4| Step: 27
Training loss: 3.2762098567385185
Validation loss: 2.123338164374221
Epoch: 4| Step: 28
Training loss: 2.8073902761566107
Validation loss: 2.1054580611051206
Epoch: 4| Step: 29
Training loss: 2.805430024447288
Validation loss: 2.082860540109675
Epoch: 4| Step: 30
Training loss: 3.1435916989705306
Validation loss: 2.0769536286486474
Epoch: 4| Step: 31
Training loss: 3.2218645452705315
Validation loss: 2.103558735796915
Epoch: 5| Step: 0
Training loss: 2.3011181103874003
Validation loss: 2.0555858496039674
Epoch: 5| Step: 1
Training loss: 2.6855132277721716
Validation loss: 2.04977973916145
Epoch: 5| Step: 2
Training loss: 2.7976054511082866
Validation loss: 2.0537408892051685
Epoch: 5| Step: 3
Training loss: 2.6428708790455286
Validation loss: 2.01842563506915
Epoch: 5| Step: 4
Training loss: 1.824538862417181
Validation loss: 2.123351178339757
Epoch: 5| Step: 5
Training loss: 2.849604856972515
Validation loss: 2.0912531874019837
Epoch: 5| Step: 6
Training loss: 3.133583031167391
Validation loss: 2.077610962698924
Epoch: 5| Step: 7
Training loss: 3.5347429402728276
Validation loss: 2.0522076494491452
Epoch: 5| Step: 8
Training loss: 3.2357142527522216
Validation loss: 2.097147678065664
Epoch: 5| Step: 9
Training loss: 3.02398313975806
Validation loss: 2.0853021401039054
Epoch: 5| Step: 10
Training loss: 2.600286680702414
Validation loss: 2.094976655324926
Epoch: 5| Step: 11
Training loss: 2.315851617964904
Validation loss: 2.04150495224119
Epoch: 5| Step: 12
Training loss: 2.332520093432657
Validation loss: 2.083684010628118
Epoch: 5| Step: 13
Training loss: 2.58403290741224
Validation loss: 2.076161091308885
Epoch: 5| Step: 14
Training loss: 2.0336482049170415
Validation loss: 2.071715776882802
Epoch: 5| Step: 15
Training loss: 2.064574383338701
Validation loss: 2.0217281037065478
Epoch: 5| Step: 16
Training loss: 2.938682480478171
Validation loss: 2.094296220457711
Epoch: 5| Step: 17
Training loss: 3.1361221753279933
Validation loss: 2.0732250586981227
Epoch: 5| Step: 18
Training loss: 3.192343827432883
Validation loss: 2.110310592913562
Epoch: 5| Step: 19
Training loss: 2.562421844034879
Validation loss: 2.0271149041498613
Epoch: 5| Step: 20
Training loss: 2.756619203367242
Validation loss: 2.080747719481987
Epoch: 5| Step: 21
Training loss: 2.854801209538746
Validation loss: 2.1045740187728565
Epoch: 5| Step: 22
Training loss: 2.2065593383749125
Validation loss: 2.084775438859427
Epoch: 5| Step: 23
Training loss: 2.6635790075718866
Validation loss: 2.0297634913228664
Epoch: 5| Step: 24
Training loss: 2.9076585535194774
Validation loss: 2.075181056456919
Epoch: 5| Step: 25
Training loss: 2.6081700998077655
Validation loss: 2.0871674343088773
Epoch: 5| Step: 26
Training loss: 2.2651661375305863
Validation loss: 2.012549372329303
Epoch: 5| Step: 27
Training loss: 2.010585072897356
Validation loss: 2.1069205720468314
Epoch: 5| Step: 28
Training loss: 2.4856057627247385
Validation loss: 2.0159762919246953
Epoch: 5| Step: 29
Training loss: 2.6326134490430833
Validation loss: 2.063821226851626
Epoch: 5| Step: 30
Training loss: 2.7479166462290667
Validation loss: 2.0444019918125695
Epoch: 5| Step: 31
Training loss: 1.7953907683121666
Validation loss: 2.047649997667496
Epoch: 6| Step: 0
Training loss: 2.978177811273451
Validation loss: 2.0558661006458783
Epoch: 6| Step: 1
Training loss: 3.1620746914597255
Validation loss: 2.0816337581124915
Epoch: 6| Step: 2
Training loss: 3.009993438713552
Validation loss: 2.0696497989921574
Epoch: 6| Step: 3
Training loss: 2.606437537309263
Validation loss: 2.08195530616489
Epoch: 6| Step: 4
Training loss: 2.645762575259688
Validation loss: 2.0762316300127592
Epoch: 6| Step: 5
Training loss: 3.0436570609627713
Validation loss: 2.0580844436600643
Epoch: 6| Step: 6
Training loss: 2.3033773545375147
Validation loss: 2.027624827345427
Epoch: 6| Step: 7
Training loss: 2.5671906687739594
Validation loss: 2.0977081563771893
Epoch: 6| Step: 8
Training loss: 2.1618944455827513
Validation loss: 2.1071891509954757
Epoch: 6| Step: 9
Training loss: 2.0348539805219192
Validation loss: 2.0451388813893923
Epoch: 6| Step: 10
Training loss: 2.4338241639516927
Validation loss: 2.085052762227413
Epoch: 6| Step: 11
Training loss: 2.9434742338757993
Validation loss: 2.085864971500152
Epoch: 6| Step: 12
Training loss: 2.764147606332467
Validation loss: 2.0469058437645358
Epoch: 6| Step: 13
Training loss: 2.579214802068401
Validation loss: 2.0887211579848084
Epoch: 6| Step: 14
Training loss: 2.93315192297417
Validation loss: 2.0487746730828666
Epoch: 6| Step: 15
Training loss: 2.7644789740483326
Validation loss: 2.1029306827169654
Epoch: 6| Step: 16
Training loss: 2.180764646555091
Validation loss: 2.049103131996544
Epoch: 6| Step: 17
Training loss: 2.6593174893428495
Validation loss: 2.087040569389539
Epoch: 6| Step: 18
Training loss: 2.317921340812411
Validation loss: 2.0867045734029137
Epoch: 6| Step: 19
Training loss: 2.9613777578159977
Validation loss: 2.0210305774349178
Epoch: 6| Step: 20
Training loss: 2.862794925871858
Validation loss: 2.04421388696315
Epoch: 6| Step: 21
Training loss: 2.7873220275720176
Validation loss: 2.0696482607942603
Epoch: 6| Step: 22
Training loss: 1.8865307068558828
Validation loss: 2.0552118262902774
Epoch: 6| Step: 23
Training loss: 2.0296702183787234
Validation loss: 2.0640942501474746
Epoch: 6| Step: 24
Training loss: 2.8482765809356274
Validation loss: 2.0717999845961867
Epoch: 6| Step: 25
Training loss: 2.7441786793958376
Validation loss: 2.103084845671286
Epoch: 6| Step: 26
Training loss: 2.291632033577672
Validation loss: 2.073149633606478
Epoch: 6| Step: 27
Training loss: 2.9359644670856877
Validation loss: 2.0244846532516956
Epoch: 6| Step: 28
Training loss: 2.713485180247958
Validation loss: 2.111338889151512
Epoch: 6| Step: 29
Training loss: 2.285044192965675
Validation loss: 2.1133526218442538
Epoch: 6| Step: 30
Training loss: 2.5878434547587865
Validation loss: 2.0907961604351315
Epoch: 6| Step: 31
Training loss: 2.6893770626839455
Validation loss: 2.0504934221420816
Epoch: 7| Step: 0
Training loss: 2.876945003542084
Validation loss: 2.092982727882181
Epoch: 7| Step: 1
Training loss: 2.8195107289891643
Validation loss: 2.0898030275722745
Epoch: 7| Step: 2
Training loss: 2.4606926690278637
Validation loss: 2.110771704392322
Epoch: 7| Step: 3
Training loss: 2.3140361941514693
Validation loss: 2.0967648185536207
Epoch: 7| Step: 4
Training loss: 2.299314073199735
Validation loss: 2.091820273176703
Epoch: 7| Step: 5
Training loss: 2.994942534696252
Validation loss: 2.116743072161595
Epoch: 7| Step: 6
Training loss: 2.998754083679141
Validation loss: 2.119090144857478
Epoch: 7| Step: 7
Training loss: 2.10315765763614
Validation loss: 2.067339074425312
Epoch: 7| Step: 8
Training loss: 1.9406531732697936
Validation loss: 2.058092414227744
Epoch: 7| Step: 9
Training loss: 2.81109287241806
Validation loss: 2.045420691466453
Epoch: 7| Step: 10
Training loss: 3.37661746791033
Validation loss: 2.095753089807962
Epoch: 7| Step: 11
Training loss: 3.065860694900717
Validation loss: 2.066427969082032
Epoch: 7| Step: 12
Training loss: 2.3589374060644297
Validation loss: 2.051998924448995
Epoch: 7| Step: 13
Training loss: 2.954705194009768
Validation loss: 2.1106402126595905
Epoch: 7| Step: 14
Training loss: 2.5794306367826882
Validation loss: 2.1007184713611813
Epoch: 7| Step: 15
Training loss: 2.2553180788279583
Validation loss: 2.103471116412771
Epoch: 7| Step: 16
Training loss: 2.068627013270333
Validation loss: 1.9968942429495742
Epoch: 7| Step: 17
Training loss: 2.4529762951918124
Validation loss: 2.0660371642631
Epoch: 7| Step: 18
Training loss: 2.941065957293193
Validation loss: 2.072851405743939
Epoch: 7| Step: 19
Training loss: 2.361075085633144
Validation loss: 2.031817082777931
Epoch: 7| Step: 20
Training loss: 2.5043256530393463
Validation loss: 2.105611159087562
Epoch: 7| Step: 21
Training loss: 3.0745965708506096
Validation loss: 2.0495416444433876
Epoch: 7| Step: 22
Training loss: 2.011600587207817
Validation loss: 2.105860264291279
Epoch: 7| Step: 23
Training loss: 2.883747559121847
Validation loss: 2.0517951273738793
Epoch: 7| Step: 24
Training loss: 2.675388279480922
Validation loss: 2.036729444180372
Epoch: 7| Step: 25
Training loss: 2.8766988627671646
Validation loss: 2.090378340095648
Epoch: 7| Step: 26
Training loss: 2.8706967864392876
Validation loss: 2.0651068004996254
Epoch: 7| Step: 27
Training loss: 2.077325882391897
Validation loss: 2.1084392942986314
Epoch: 7| Step: 28
Training loss: 2.6066031895914423
Validation loss: 2.0606059897099347
Epoch: 7| Step: 29
Training loss: 2.2675547832697216
Validation loss: 2.0805192747605625
Epoch: 7| Step: 30
Training loss: 3.102188008841454
Validation loss: 2.05236159496208
Epoch: 7| Step: 31
Training loss: 2.5338739052631323
Validation loss: 2.079823839956243
Epoch: 8| Step: 0
Training loss: 2.6469510838766537
Validation loss: 2.002671097148112
Epoch: 8| Step: 1
Training loss: 3.350489162202677
Validation loss: 2.071775512134305
Epoch: 8| Step: 2
Training loss: 2.9559437050730577
Validation loss: 2.034456729161983
Epoch: 8| Step: 3
Training loss: 2.2693269148480697
Validation loss: 2.0593286446640273
Epoch: 8| Step: 4
Training loss: 2.3048791837990987
Validation loss: 2.1057085623704443
Epoch: 8| Step: 5
Training loss: 2.3929756924151455
Validation loss: 2.096407352181698
Epoch: 8| Step: 6
Training loss: 1.965695388091616
Validation loss: 2.0840613579563296
Epoch: 8| Step: 7
Training loss: 3.1557097019758538
Validation loss: 2.0405584011009044
Epoch: 8| Step: 8
Training loss: 3.2104185849893043
Validation loss: 2.0928145661406754
Epoch: 8| Step: 9
Training loss: 2.2693911064330714
Validation loss: 2.0615623770671605
Epoch: 8| Step: 10
Training loss: 2.4592254981002846
Validation loss: 2.0742329928730032
Epoch: 8| Step: 11
Training loss: 1.866051044730861
Validation loss: 2.082648499877636
Epoch: 8| Step: 12
Training loss: 2.9257841835974947
Validation loss: 2.0052104053100237
Epoch: 8| Step: 13
Training loss: 2.210291468184369
Validation loss: 2.0149863583990344
Epoch: 8| Step: 14
Training loss: 2.9589801851249216
Validation loss: 2.055937004665421
Epoch: 8| Step: 15
Training loss: 2.3114240050434947
Validation loss: 2.0771887878597783
Epoch: 8| Step: 16
Training loss: 2.6996054255076194
Validation loss: 2.028715713762226
Epoch: 8| Step: 17
Training loss: 2.705815734555418
Validation loss: 2.0815268105412303
Epoch: 8| Step: 18
Training loss: 2.5966195468602007
Validation loss: 2.077769009765758
Epoch: 8| Step: 19
Training loss: 3.22463687952004
Validation loss: 2.1112386471164233
Epoch: 8| Step: 20
Training loss: 2.8157450287328034
Validation loss: 2.012351854775522
Epoch: 8| Step: 21
Training loss: 2.4719918128189753
Validation loss: 2.0698275064105154
Epoch: 8| Step: 22
Training loss: 2.6864387723504684
Validation loss: 2.089517692326954
Epoch: 8| Step: 23
Training loss: 2.4792995791242443
Validation loss: 2.1038717200067643
Epoch: 8| Step: 24
Training loss: 2.7067967873413448
Validation loss: 2.081066214321693
Epoch: 8| Step: 25
Training loss: 2.6153993789549594
Validation loss: 2.080900864915237
Epoch: 8| Step: 26
Training loss: 2.422102591372786
Validation loss: 2.080213120074394
Epoch: 8| Step: 27
Training loss: 2.3650312517613505
Validation loss: 2.0680672185610955
Epoch: 8| Step: 28
Training loss: 2.3348557637203053
Validation loss: 2.034681440859334
Epoch: 8| Step: 29
Training loss: 3.0987312981709403
Validation loss: 2.0775578779392156
Epoch: 8| Step: 30
Training loss: 2.2481832587186292
Validation loss: 2.0870163972400992
Epoch: 8| Step: 31
Training loss: 2.806144739568499
Validation loss: 2.0870049740370296
Epoch: 9| Step: 0
Training loss: 2.5313677348318544
Validation loss: 2.0859408811080558
Epoch: 9| Step: 1
Training loss: 2.55562152178484
Validation loss: 2.055734757703973
Epoch: 9| Step: 2
Training loss: 2.7632084865766657
Validation loss: 2.0450572510113685
Epoch: 9| Step: 3
Training loss: 2.865640581560777
Validation loss: 2.1204609206369494
Epoch: 9| Step: 4
Training loss: 2.1827136400318534
Validation loss: 2.0455411025310903
Epoch: 9| Step: 5
Training loss: 2.9870689176840464
Validation loss: 2.1104473581195338
Epoch: 9| Step: 6
Training loss: 2.528605551485574
Validation loss: 2.09996448140628
Epoch: 9| Step: 7
Training loss: 2.5631090696407663
Validation loss: 2.107174238124407
Epoch: 9| Step: 8
Training loss: 2.471004760181839
Validation loss: 2.098503734188078
Epoch: 9| Step: 9
Training loss: 3.2418415666352454
Validation loss: 2.0731514352966136
Epoch: 9| Step: 10
Training loss: 2.3953766318418537
Validation loss: 2.07788525866905
Epoch: 9| Step: 11
Training loss: 2.878199579885883
Validation loss: 2.0724819369250658
Epoch: 9| Step: 12
Training loss: 3.2118411683637
Validation loss: 2.0584469857998333
Epoch: 9| Step: 13
Training loss: 2.5572709486070972
Validation loss: 2.1099212915634564
Epoch: 9| Step: 14
Training loss: 3.3322450450717565
Validation loss: 2.0144051699336463
Epoch: 9| Step: 15
Training loss: 2.4665813336776417
Validation loss: 1.9706518878369794
Epoch: 9| Step: 16
Training loss: 2.346299171156063
Validation loss: 2.1210629976493514
Epoch: 9| Step: 17
Training loss: 2.9295890282930173
Validation loss: 2.039639393782152
Epoch: 9| Step: 18
Training loss: 2.686927024619821
Validation loss: 2.099479223656443
Epoch: 9| Step: 19
Training loss: 2.3452348201932622
Validation loss: 2.0754195875994506
Epoch: 9| Step: 20
Training loss: 2.8576504869458743
Validation loss: 2.1075955361744123
Epoch: 9| Step: 21
Training loss: 2.2544862738026703
Validation loss: 2.110272500495669
Epoch: 9| Step: 22
Training loss: 2.5041202923822774
Validation loss: 2.073797545086429
Epoch: 9| Step: 23
Training loss: 2.3437112423553215
Validation loss: 2.0289711574549645
Epoch: 9| Step: 24
Training loss: 2.106101201175358
Validation loss: 2.0797051542185683
Epoch: 9| Step: 25
Training loss: 2.5225698201674476
Validation loss: 2.0311306713021904
Epoch: 9| Step: 26
Training loss: 2.4253420716321052
Validation loss: 2.060135024075205
Epoch: 9| Step: 27
Training loss: 2.860203357215865
Validation loss: 2.0650887071602657
Epoch: 9| Step: 28
Training loss: 2.5442949578278022
Validation loss: 2.027451030904074
Epoch: 9| Step: 29
Training loss: 2.38803558733316
Validation loss: 2.090405560988683
Epoch: 9| Step: 30
Training loss: 2.719133547332676
Validation loss: 2.1018787911906176
Epoch: 9| Step: 31
Training loss: 2.4666262799470733
Validation loss: 2.1008067934897334
Epoch: 10| Step: 0
Training loss: 2.097713874579484
Validation loss: 2.0354734256405846
Epoch: 10| Step: 1
Training loss: 3.114913225511398
Validation loss: 2.025316706882269
Epoch: 10| Step: 2
Training loss: 2.581990805812691
Validation loss: 2.07395945930696
Epoch: 10| Step: 3
Training loss: 2.5032114383093593
Validation loss: 2.0976017919792946
Epoch: 10| Step: 4
Training loss: 3.169895099143692
Validation loss: 2.064523711431362
Epoch: 10| Step: 5
Training loss: 2.8768598097243334
Validation loss: 2.1236341994182335
Epoch: 10| Step: 6
Training loss: 3.2356075573621084
Validation loss: 2.0750555521570333
Epoch: 10| Step: 7
Training loss: 2.6801647951217498
Validation loss: 2.0593613366306522
Epoch: 10| Step: 8
Training loss: 2.317536308390971
Validation loss: 2.0935150633881827
Epoch: 10| Step: 9
Training loss: 2.6900017205839077
Validation loss: 2.0371602296554143
Epoch: 10| Step: 10
Training loss: 2.545923909658726
Validation loss: 2.050083956431623
Epoch: 10| Step: 11
Training loss: 2.3185737851371573
Validation loss: 2.0759279147750975
Epoch: 10| Step: 12
Training loss: 2.6958405350633634
Validation loss: 2.064061177459323
Epoch: 10| Step: 13
Training loss: 2.2199491027633638
Validation loss: 2.0879499662091145
Epoch: 10| Step: 14
Training loss: 2.190348160647036
Validation loss: 2.088998169108675
Epoch: 10| Step: 15
Training loss: 2.1274638758101623
Validation loss: 2.0529500511228047
Epoch: 10| Step: 16
Training loss: 3.163092721270512
Validation loss: 2.114008915252289
Epoch: 10| Step: 17
Training loss: 2.7187719234591103
Validation loss: 2.1427684960159166
Epoch: 10| Step: 18
Training loss: 2.2425839807951875
Validation loss: 2.080294605972951
Epoch: 10| Step: 19
Training loss: 3.1743470128720777
Validation loss: 2.1265411596185233
Epoch: 10| Step: 20
Training loss: 2.1020890607903913
Validation loss: 2.088508363117026
Epoch: 10| Step: 21
Training loss: 1.9814223301787546
Validation loss: 2.0885020641051364
Epoch: 10| Step: 22
Training loss: 2.9077699029867925
Validation loss: 2.0971372794473027
Epoch: 10| Step: 23
Training loss: 2.662921023324733
Validation loss: 2.061821177281764
Epoch: 10| Step: 24
Training loss: 2.663538906517185
Validation loss: 2.1080858830752125
Epoch: 10| Step: 25
Training loss: 2.2862804810007837
Validation loss: 2.1046562685741823
Epoch: 10| Step: 26
Training loss: 2.627894939645087
Validation loss: 2.1117329479953524
Epoch: 10| Step: 27
Training loss: 2.969662174830192
Validation loss: 2.053654975641965
Epoch: 10| Step: 28
Training loss: 2.954891907446427
Validation loss: 2.0552539317190073
Epoch: 10| Step: 29
Training loss: 2.3251108204671906
Validation loss: 2.0791186363486776
Epoch: 10| Step: 30
Training loss: 2.886499048113604
Validation loss: 2.0676289927381006
Epoch: 10| Step: 31
Training loss: 2.518383148966328
Validation loss: 2.0455237167034097
Epoch: 11| Step: 0
Training loss: 3.069778667759414
Validation loss: 2.0450643717828374
Epoch: 11| Step: 1
Training loss: 3.006791216377399
Validation loss: 2.0705341515185127
Epoch: 11| Step: 2
Training loss: 2.012544392161306
Validation loss: 2.0810861010992845
Epoch: 11| Step: 3
Training loss: 2.342165194984791
Validation loss: 2.051843676346385
Epoch: 11| Step: 4
Training loss: 2.3765872871265006
Validation loss: 2.049078203877956
Epoch: 11| Step: 5
Training loss: 2.6117164020716057
Validation loss: 2.077669570767439
Epoch: 11| Step: 6
Training loss: 2.4791020510504818
Validation loss: 2.014471538966219
Epoch: 11| Step: 7
Training loss: 3.3373290114588787
Validation loss: 2.007207156591971
Epoch: 11| Step: 8
Training loss: 3.4507913428261108
Validation loss: 2.126128695407028
Epoch: 11| Step: 9
Training loss: 2.6241023027318575
Validation loss: 2.05319071338055
Epoch: 11| Step: 10
Training loss: 2.7992521445315623
Validation loss: 2.057429898952072
Epoch: 11| Step: 11
Training loss: 2.7180580047750595
Validation loss: 2.065255093799507
Epoch: 11| Step: 12
Training loss: 2.523201662741085
Validation loss: 2.053251232828244
Epoch: 11| Step: 13
Training loss: 2.3354404903107593
Validation loss: 2.130539503966887
Epoch: 11| Step: 14
Training loss: 3.0122593890453873
Validation loss: 2.01554220081101
Epoch: 11| Step: 15
Training loss: 2.5455958424712253
Validation loss: 2.064874192798441
Epoch: 11| Step: 16
Training loss: 2.8290080172552243
Validation loss: 2.086895298900944
Epoch: 11| Step: 17
Training loss: 2.4214950755744877
Validation loss: 2.076457773381388
Epoch: 11| Step: 18
Training loss: 2.8335478832317946
Validation loss: 2.027881609314475
Epoch: 11| Step: 19
Training loss: 2.37189511578339
Validation loss: 2.0801089306865057
Epoch: 11| Step: 20
Training loss: 2.308796468699789
Validation loss: 2.028610662131963
Epoch: 11| Step: 21
Training loss: 2.3907931399587317
Validation loss: 2.069128937358246
Epoch: 11| Step: 22
Training loss: 2.670386362588846
Validation loss: 2.0778795390348863
Epoch: 11| Step: 23
Training loss: 2.6675013388261233
Validation loss: 2.0371216879318728
Epoch: 11| Step: 24
Training loss: 2.3495276889569823
Validation loss: 2.097801338116187
Epoch: 11| Step: 25
Training loss: 1.876187266521553
Validation loss: 2.0826388397158193
Epoch: 11| Step: 26
Training loss: 3.3779446506968385
Validation loss: 2.034236608501747
Epoch: 11| Step: 27
Training loss: 3.1179862086668253
Validation loss: 2.09366061596524
Epoch: 11| Step: 28
Training loss: 2.4153949307217237
Validation loss: 2.095860273896629
Epoch: 11| Step: 29
Training loss: 2.222053969159595
Validation loss: 2.1046846290408547
Epoch: 11| Step: 30
Training loss: 1.4885587658799868
Validation loss: 2.056721186529502
Epoch: 11| Step: 31
Training loss: 2.8184986146196334
Validation loss: 2.1060266459797634
Epoch: 12| Step: 0
Training loss: 2.4288232376278667
Validation loss: 2.0434252561744377
Epoch: 12| Step: 1
Training loss: 2.6735447356556885
Validation loss: 2.043702321124528
Epoch: 12| Step: 2
Training loss: 3.49900885580795
Validation loss: 2.0643444855362674
Epoch: 12| Step: 3
Training loss: 2.9158949421401714
Validation loss: 2.054354647867845
Epoch: 12| Step: 4
Training loss: 2.4426723279651408
Validation loss: 2.0824245675303312
Epoch: 12| Step: 5
Training loss: 2.4785473688496147
Validation loss: 2.0265547786428866
Epoch: 12| Step: 6
Training loss: 1.6570324758824584
Validation loss: 2.095846623324156
Epoch: 12| Step: 7
Training loss: 2.252997203488229
Validation loss: 2.0801245412619105
Epoch: 12| Step: 8
Training loss: 2.3797401507558824
Validation loss: 2.1271781266514864
Epoch: 12| Step: 9
Training loss: 2.5011389045502326
Validation loss: 2.092255263463628
Epoch: 12| Step: 10
Training loss: 2.0774750804668964
Validation loss: 2.0579569069365857
Epoch: 12| Step: 11
Training loss: 2.421684897560479
Validation loss: 2.046142993022806
Epoch: 12| Step: 12
Training loss: 1.9479664542895376
Validation loss: 2.0980471487884906
Epoch: 12| Step: 13
Training loss: 1.9881807013308446
Validation loss: 2.0627824444914604
Epoch: 12| Step: 14
Training loss: 3.2107693890374747
Validation loss: 2.0532453025784316
Epoch: 12| Step: 15
Training loss: 3.2010814567862775
Validation loss: 2.048399307521624
Epoch: 12| Step: 16
Training loss: 2.736241864104742
Validation loss: 2.1001528070837203
Epoch: 12| Step: 17
Training loss: 2.872850692762378
Validation loss: 2.1214535824283076
Epoch: 12| Step: 18
Training loss: 2.7126222152249175
Validation loss: 2.1022421945689507
Epoch: 12| Step: 19
Training loss: 2.6214992249360543
Validation loss: 2.068114042589965
Epoch: 12| Step: 20
Training loss: 3.0656829175231834
Validation loss: 2.062169725472388
Epoch: 12| Step: 21
Training loss: 2.550830320672
Validation loss: 2.034910487971523
Epoch: 12| Step: 22
Training loss: 2.8722869677187126
Validation loss: 2.117418070990894
Epoch: 12| Step: 23
Training loss: 2.9787957731980974
Validation loss: 2.083550267676051
Epoch: 12| Step: 24
Training loss: 2.3098140273432977
Validation loss: 2.0468786769470104
Epoch: 12| Step: 25
Training loss: 3.014929972985176
Validation loss: 2.0733728616907916
Epoch: 12| Step: 26
Training loss: 2.0161347446975997
Validation loss: 2.045001933580907
Epoch: 12| Step: 27
Training loss: 2.761140193525936
Validation loss: 2.061783227191213
Epoch: 12| Step: 28
Training loss: 2.989670773245352
Validation loss: 2.0623061117326484
Epoch: 12| Step: 29
Training loss: 2.8829666551348008
Validation loss: 2.054607533696933
Epoch: 12| Step: 30
Training loss: 2.612476264809289
Validation loss: 2.0446274999295784
Epoch: 12| Step: 31
Training loss: 2.4032148565153153
Validation loss: 2.104957156627573
Epoch: 13| Step: 0
Training loss: 2.45921793609437
Validation loss: 2.0961046955054035
Epoch: 13| Step: 1
Training loss: 2.3760242261390063
Validation loss: 2.0840737815734487
Epoch: 13| Step: 2
Training loss: 1.6063342951760966
Validation loss: 2.124781353835755
Epoch: 13| Step: 3
Training loss: 3.2541585872483094
Validation loss: 2.0778267236948866
Epoch: 13| Step: 4
Training loss: 2.484593507766256
Validation loss: 2.073222652246524
Epoch: 13| Step: 5
Training loss: 2.3943898593299116
Validation loss: 2.1045320284991598
Epoch: 13| Step: 6
Training loss: 3.4419791429986035
Validation loss: 2.096626448707271
Epoch: 13| Step: 7
Training loss: 2.301490143404483
Validation loss: 2.059723634754856
Epoch: 13| Step: 8
Training loss: 2.0060848417662953
Validation loss: 2.067607329723948
Epoch: 13| Step: 9
Training loss: 2.6563516933945786
Validation loss: 2.111863268732469
Epoch: 13| Step: 10
Training loss: 2.5071501525660977
Validation loss: 2.086880681709672
Epoch: 13| Step: 11
Training loss: 2.715113520769263
Validation loss: 2.0585693643046756
Epoch: 13| Step: 12
Training loss: 2.5073068649746335
Validation loss: 2.038976067381272
Epoch: 13| Step: 13
Training loss: 2.4033635649805616
Validation loss: 2.0659627039338093
Epoch: 13| Step: 14
Training loss: 3.221145627244522
Validation loss: 2.0564330147244023
Epoch: 13| Step: 15
Training loss: 1.8923361104855574
Validation loss: 2.080891694546821
Epoch: 13| Step: 16
Training loss: 2.3392569645203856
Validation loss: 2.060004450400513
Epoch: 13| Step: 17
Training loss: 2.318611729038871
Validation loss: 2.0271649025334706
Epoch: 13| Step: 18
Training loss: 2.9412877437635663
Validation loss: 2.087980352380413
Epoch: 13| Step: 19
Training loss: 2.268571502977928
Validation loss: 2.073411528187634
Epoch: 13| Step: 20
Training loss: 2.538300948743151
Validation loss: 2.113360350690147
Epoch: 13| Step: 21
Training loss: 3.4435625194880024
Validation loss: 2.0979275999531697
Epoch: 13| Step: 22
Training loss: 3.4390223513334703
Validation loss: 2.084830197607477
Epoch: 13| Step: 23
Training loss: 2.2309420162037124
Validation loss: 2.1102099486496355
Epoch: 13| Step: 24
Training loss: 3.098515548915732
Validation loss: 2.013647102067248
Epoch: 13| Step: 25
Training loss: 2.5332324894693588
Validation loss: 2.0870704429351528
Epoch: 13| Step: 26
Training loss: 2.35631772457509
Validation loss: 2.073732523639966
Epoch: 13| Step: 27
Training loss: 2.3247419521735218
Validation loss: 2.0027823360878987
Epoch: 13| Step: 28
Training loss: 2.891782786504922
Validation loss: 2.0352964369850755
Epoch: 13| Step: 29
Training loss: 2.8185733917463716
Validation loss: 2.084686325478654
Epoch: 13| Step: 30
Training loss: 2.6595655505254054
Validation loss: 2.0729824282632188
Epoch: 13| Step: 31
Training loss: 2.8307019711720214
Validation loss: 2.060013069295029
Epoch: 14| Step: 0
Training loss: 2.5698044109505243
Validation loss: 2.0401796453275725
Epoch: 14| Step: 1
Training loss: 2.478224235943338
Validation loss: 2.063657225956284
Epoch: 14| Step: 2
Training loss: 2.6109616144369086
Validation loss: 2.058247328575824
Epoch: 14| Step: 3
Training loss: 2.487476739822595
Validation loss: 2.0833615645009598
Epoch: 14| Step: 4
Training loss: 1.8242016287087999
Validation loss: 2.0764179298441294
Epoch: 14| Step: 5
Training loss: 2.6518199105601443
Validation loss: 2.085835700805912
Epoch: 14| Step: 6
Training loss: 2.038314389785154
Validation loss: 2.073131586619466
Epoch: 14| Step: 7
Training loss: 2.401607146186286
Validation loss: 2.09801296621449
Epoch: 14| Step: 8
Training loss: 2.6063662788926147
Validation loss: 2.0726651381356898
Epoch: 14| Step: 9
Training loss: 3.2417577251860927
Validation loss: 2.0776072068420626
Epoch: 14| Step: 10
Training loss: 3.0923802589912404
Validation loss: 2.0860264568345674
Epoch: 14| Step: 11
Training loss: 2.5859628543590403
Validation loss: 1.983906024324674
Epoch: 14| Step: 12
Training loss: 2.8322472641216394
Validation loss: 2.102416342018672
Epoch: 14| Step: 13
Training loss: 2.780425131558289
Validation loss: 2.049326977354525
Epoch: 14| Step: 14
Training loss: 2.59423354823526
Validation loss: 2.033799148924434
Epoch: 14| Step: 15
Training loss: 3.220000829518845
Validation loss: 2.0700733914985716
Epoch: 14| Step: 16
Training loss: 2.3069261960384657
Validation loss: 2.1233968907689014
Epoch: 14| Step: 17
Training loss: 3.3221820908259216
Validation loss: 2.0609293939427586
Epoch: 14| Step: 18
Training loss: 3.256662142804797
Validation loss: 2.055413210933725
Epoch: 14| Step: 19
Training loss: 2.4213608719034143
Validation loss: 2.1030467599162486
Epoch: 14| Step: 20
Training loss: 2.3418793397307875
Validation loss: 2.067406193113967
Epoch: 14| Step: 21
Training loss: 2.886619473248492
Validation loss: 2.128510215462224
Epoch: 14| Step: 22
Training loss: 2.5608803817775145
Validation loss: 2.0185519710381046
Epoch: 14| Step: 23
Training loss: 3.218007122347236
Validation loss: 2.089595829348379
Epoch: 14| Step: 24
Training loss: 2.1080667465399268
Validation loss: 2.1147312557198417
Epoch: 14| Step: 25
Training loss: 2.4257501916540316
Validation loss: 2.0550487170477885
Epoch: 14| Step: 26
Training loss: 2.460899909807156
Validation loss: 2.0821837646348986
Epoch: 14| Step: 27
Training loss: 2.8374747321394396
Validation loss: 2.085305403738317
Epoch: 14| Step: 28
Training loss: 2.8989433402412677
Validation loss: 2.1082797003929925
Epoch: 14| Step: 29
Training loss: 2.2641486257490255
Validation loss: 2.0852382897206647
Epoch: 14| Step: 30
Training loss: 1.9266943324169579
Validation loss: 2.043959912828807
Epoch: 14| Step: 31
Training loss: 2.1420999165444448
Validation loss: 2.0494119257293235
Epoch: 15| Step: 0
Training loss: 2.6912870117704135
Validation loss: 2.0721968181378925
Epoch: 15| Step: 1
Training loss: 3.5270388990030384
Validation loss: 2.0812886193534292
Epoch: 15| Step: 2
Training loss: 1.7101351454797524
Validation loss: 2.081693743642163
Epoch: 15| Step: 3
Training loss: 2.050899596659625
Validation loss: 2.0668918867851227
Epoch: 15| Step: 4
Training loss: 1.934516332143788
Validation loss: 2.04744383983798
Epoch: 15| Step: 5
Training loss: 2.7940090562841595
Validation loss: 2.0734775918501724
Epoch: 15| Step: 6
Training loss: 2.6046252851373004
Validation loss: 2.079118325897709
Epoch: 15| Step: 7
Training loss: 1.7568731892460054
Validation loss: 2.0930688845174044
Epoch: 15| Step: 8
Training loss: 2.3348191049497036
Validation loss: 2.037707927386962
Epoch: 15| Step: 9
Training loss: 2.5467347650593712
Validation loss: 2.077672019648354
Epoch: 15| Step: 10
Training loss: 3.343609958461257
Validation loss: 2.1165595171575275
Epoch: 15| Step: 11
Training loss: 2.371538048333014
Validation loss: 2.0456913234425356
Epoch: 15| Step: 12
Training loss: 2.725122896975361
Validation loss: 2.1287139519458216
Epoch: 15| Step: 13
Training loss: 2.369319949867748
Validation loss: 2.094343636383754
Epoch: 15| Step: 14
Training loss: 2.459552387204642
Validation loss: 2.1276839398559337
Epoch: 15| Step: 15
Training loss: 2.3977417573569393
Validation loss: 2.1048317836961252
Epoch: 15| Step: 16
Training loss: 3.09724706422188
Validation loss: 2.0876486080298946
Epoch: 15| Step: 17
Training loss: 2.827687688074021
Validation loss: 2.090299924989429
Epoch: 15| Step: 18
Training loss: 2.781104180445942
Validation loss: 2.109096737713374
Epoch: 15| Step: 19
Training loss: 2.5767853926743496
Validation loss: 2.1124063495920584
Epoch: 15| Step: 20
Training loss: 2.340325664127188
Validation loss: 2.0426471368875925
Epoch: 15| Step: 21
Training loss: 2.6100643869109437
Validation loss: 2.103080465085765
Epoch: 15| Step: 22
Training loss: 1.786271763022315
Validation loss: 2.124644483259828
Epoch: 15| Step: 23
Training loss: 2.6509871461629335
Validation loss: 2.0762609714111417
Epoch: 15| Step: 24
Training loss: 3.6006606290564522
Validation loss: 2.064789955003001
Epoch: 15| Step: 25
Training loss: 2.670326899829518
Validation loss: 2.1004482521867662
Epoch: 15| Step: 26
Training loss: 2.6277442393224804
Validation loss: 2.0689106639407835
Epoch: 15| Step: 27
Training loss: 2.0938650071171696
Validation loss: 2.0586948594829155
Epoch: 15| Step: 28
Training loss: 2.8208965003314592
Validation loss: 2.1219801051470735
Epoch: 15| Step: 29
Training loss: 2.6433954997727818
Validation loss: 2.1234969489584303
Epoch: 15| Step: 30
Training loss: 3.3536465796449915
Validation loss: 2.0541526077552743
Epoch: 15| Step: 31
Training loss: 2.9077462887284815
Validation loss: 2.0694783081312504
Epoch: 16| Step: 0
Training loss: 1.8234171443741174
Validation loss: 2.1165683550370664
Epoch: 16| Step: 1
Training loss: 2.183616679008082
Validation loss: 2.067656363343162
Epoch: 16| Step: 2
Training loss: 2.784785220563771
Validation loss: 2.0302105072411805
Epoch: 16| Step: 3
Training loss: 2.864039384464564
Validation loss: 2.1254900715573624
Epoch: 16| Step: 4
Training loss: 2.7405354884285265
Validation loss: 2.1033299686918854
Epoch: 16| Step: 5
Training loss: 2.6489836093198216
Validation loss: 2.0710303865556257
Epoch: 16| Step: 6
Training loss: 3.0429621685382933
Validation loss: 2.0476254211320035
Epoch: 16| Step: 7
Training loss: 3.034905814857145
Validation loss: 2.066354549597148
Epoch: 16| Step: 8
Training loss: 3.143222474873564
Validation loss: 2.079503397135007
Epoch: 16| Step: 9
Training loss: 2.1549575913011365
Validation loss: 2.0502106876654436
Epoch: 16| Step: 10
Training loss: 2.1065853180248646
Validation loss: 2.1121535076819278
Epoch: 16| Step: 11
Training loss: 3.2880512776146955
Validation loss: 2.055877769243111
Epoch: 16| Step: 12
Training loss: 2.373584526284659
Validation loss: 2.0856361691929877
Epoch: 16| Step: 13
Training loss: 1.7714079279949273
Validation loss: 2.0335357829193446
Epoch: 16| Step: 14
Training loss: 2.7913937696236095
Validation loss: 2.06768989104374
Epoch: 16| Step: 15
Training loss: 2.9242886452623904
Validation loss: 2.1067948585831306
Epoch: 16| Step: 16
Training loss: 2.703743483508648
Validation loss: 2.0956771490973556
Epoch: 16| Step: 17
Training loss: 2.3034919353300047
Validation loss: 2.0505703685689545
Epoch: 16| Step: 18
Training loss: 2.93970844769448
Validation loss: 2.0503524619683287
Epoch: 16| Step: 19
Training loss: 2.425953931083302
Validation loss: 2.04585471862481
Epoch: 16| Step: 20
Training loss: 3.3520651131453447
Validation loss: 2.0016230295691715
Epoch: 16| Step: 21
Training loss: 2.5968324660066826
Validation loss: 2.0837570305258533
Epoch: 16| Step: 22
Training loss: 3.0499000595478503
Validation loss: 2.127431473778915
Epoch: 16| Step: 23
Training loss: 2.7479405060592756
Validation loss: 2.0870511261174367
Epoch: 16| Step: 24
Training loss: 1.6519131290972853
Validation loss: 2.0946128766801957
Epoch: 16| Step: 25
Training loss: 3.013587381855893
Validation loss: 2.067921167222442
Epoch: 16| Step: 26
Training loss: 2.5349558323430275
Validation loss: 2.0605022474548167
Epoch: 16| Step: 27
Training loss: 1.0216146061521527
Validation loss: 2.0119391470554118
Epoch: 16| Step: 28
Training loss: 2.7397256869812323
Validation loss: 2.0949383583158943
Epoch: 16| Step: 29
Training loss: 2.7310843585523044
Validation loss: 1.991093649722131
Epoch: 16| Step: 30
Training loss: 3.159961142723586
Validation loss: 2.1007414359438332
Epoch: 16| Step: 31
Training loss: 2.1765509019749434
Validation loss: 2.0054959678436135
Epoch: 17| Step: 0
Training loss: 2.514443161372649
Validation loss: 2.0478645128857447
Epoch: 17| Step: 1
Training loss: 3.0027410382816826
Validation loss: 2.030778741818124
Epoch: 17| Step: 2
Training loss: 2.6776643906677875
Validation loss: 2.067833857129172
Epoch: 17| Step: 3
Training loss: 2.38755611333764
Validation loss: 2.116180583179951
Epoch: 17| Step: 4
Training loss: 2.576758930220803
Validation loss: 2.0418406858424727
Epoch: 17| Step: 5
Training loss: 2.433281304399792
Validation loss: 2.0799677841475837
Epoch: 17| Step: 6
Training loss: 3.3169738499482078
Validation loss: 2.1062784668297905
Epoch: 17| Step: 7
Training loss: 2.682027790212914
Validation loss: 2.0911746400416806
Epoch: 17| Step: 8
Training loss: 2.839005757228258
Validation loss: 2.0821386404259004
Epoch: 17| Step: 9
Training loss: 2.222382808552074
Validation loss: 2.0972949778310865
Epoch: 17| Step: 10
Training loss: 2.4840064585136448
Validation loss: 2.083762165161061
Epoch: 17| Step: 11
Training loss: 2.829412852060007
Validation loss: 2.098276826400798
Epoch: 17| Step: 12
Training loss: 1.6472886407522933
Validation loss: 2.0416765413701237
Epoch: 17| Step: 13
Training loss: 2.883714818983764
Validation loss: 2.08871213333544
Epoch: 17| Step: 14
Training loss: 2.634349793011493
Validation loss: 2.0699164538328394
Epoch: 17| Step: 15
Training loss: 2.552690851472406
Validation loss: 2.0656019785742266
Epoch: 17| Step: 16
Training loss: 2.2665628531000905
Validation loss: 2.0337962816793738
Epoch: 17| Step: 17
Training loss: 2.4402030238126327
Validation loss: 2.070855324933949
Epoch: 17| Step: 18
Training loss: 2.915131646352179
Validation loss: 2.0546686054130876
Epoch: 17| Step: 19
Training loss: 2.255085073249245
Validation loss: 2.036734746730829
Epoch: 17| Step: 20
Training loss: 3.3126839640654477
Validation loss: 2.0921843537237357
Epoch: 17| Step: 21
Training loss: 2.4851447298513833
Validation loss: 2.093972556246609
Epoch: 17| Step: 22
Training loss: 2.382070957552265
Validation loss: 2.0658426569605184
Epoch: 17| Step: 23
Training loss: 2.9482022384155795
Validation loss: 2.1307967647107025
Epoch: 17| Step: 24
Training loss: 2.3464277102806204
Validation loss: 2.0806467526339736
Epoch: 17| Step: 25
Training loss: 2.381551239904062
Validation loss: 2.0712378310894333
Epoch: 17| Step: 26
Training loss: 2.150642844505522
Validation loss: 2.0033869477707436
Epoch: 17| Step: 27
Training loss: 2.6841253339949964
Validation loss: 2.1181832887037273
Epoch: 17| Step: 28
Training loss: 3.1380522709243883
Validation loss: 2.0687240779913063
Epoch: 17| Step: 29
Training loss: 2.8414384438906857
Validation loss: 2.0488272966294248
Epoch: 17| Step: 30
Training loss: 2.622556184615934
Validation loss: 2.1134989659816616
Epoch: 17| Step: 31
Training loss: 2.7700605438171118
Validation loss: 2.0960783121558944
Epoch: 18| Step: 0
Training loss: 1.7724039704387033
Validation loss: 2.1106907165292634
Epoch: 18| Step: 1
Training loss: 2.125095814059476
Validation loss: 2.1098754300597404
Epoch: 18| Step: 2
Training loss: 2.213862987458797
Validation loss: 2.041328695338497
Epoch: 18| Step: 3
Training loss: 2.734766033005299
Validation loss: 1.9979008935818678
Epoch: 18| Step: 4
Training loss: 1.9850853677260416
Validation loss: 2.0769509709065934
Epoch: 18| Step: 5
Training loss: 1.9674636028951187
Validation loss: 2.091127287491747
Epoch: 18| Step: 6
Training loss: 2.6802044695102216
Validation loss: 2.102593851717762
Epoch: 18| Step: 7
Training loss: 1.968869947382305
Validation loss: 2.0471536161094592
Epoch: 18| Step: 8
Training loss: 3.3650070884142465
Validation loss: 2.0092220405438384
Epoch: 18| Step: 9
Training loss: 3.2367073532150608
Validation loss: 2.0848376353612994
Epoch: 18| Step: 10
Training loss: 2.453352219087361
Validation loss: 2.0427815215434544
Epoch: 18| Step: 11
Training loss: 2.300354586095639
Validation loss: 2.070036060985023
Epoch: 18| Step: 12
Training loss: 2.1702944266635766
Validation loss: 2.0942581459455463
Epoch: 18| Step: 13
Training loss: 1.8193195565469604
Validation loss: 2.0714523530327806
Epoch: 18| Step: 14
Training loss: 2.675758439683796
Validation loss: 2.0289512255148052
Epoch: 18| Step: 15
Training loss: 2.387552318698781
Validation loss: 2.092037735570192
Epoch: 18| Step: 16
Training loss: 2.99769296949225
Validation loss: 2.118807297176387
Epoch: 18| Step: 17
Training loss: 2.924122318407322
Validation loss: 2.1263887521801714
Epoch: 18| Step: 18
Training loss: 2.185713338094839
Validation loss: 2.072056801469397
Epoch: 18| Step: 19
Training loss: 2.781212710012699
Validation loss: 2.0653969182837835
Epoch: 18| Step: 20
Training loss: 3.301347636548776
Validation loss: 2.04481045289826
Epoch: 18| Step: 21
Training loss: 3.0963883372678653
Validation loss: 2.020083416803388
Epoch: 18| Step: 22
Training loss: 2.7619952504519785
Validation loss: 2.0956322625225003
Epoch: 18| Step: 23
Training loss: 3.042529014380097
Validation loss: 2.10212964508721
Epoch: 18| Step: 24
Training loss: 2.8026118766784007
Validation loss: 2.0536127538314064
Epoch: 18| Step: 25
Training loss: 2.7160359132103067
Validation loss: 2.0790375211780887
Epoch: 18| Step: 26
Training loss: 2.909969779575381
Validation loss: 2.0685814856567184
Epoch: 18| Step: 27
Training loss: 2.8718026667836702
Validation loss: 2.0604325469113856
Epoch: 18| Step: 28
Training loss: 2.1091401145988984
Validation loss: 2.0632728635835447
Epoch: 18| Step: 29
Training loss: 2.8520126196540603
Validation loss: 2.082928202444809
Epoch: 18| Step: 30
Training loss: 2.726979658246104
Validation loss: 2.0835730845417966
Epoch: 18| Step: 31
Training loss: 3.1680519855067932
Validation loss: 2.110011446112384
Epoch: 19| Step: 0
Training loss: 2.9385453656991536
Validation loss: 2.0262068047986324
Epoch: 19| Step: 1
Training loss: 3.3401287113447604
Validation loss: 2.045286803731488
Epoch: 19| Step: 2
Training loss: 3.319051633299313
Validation loss: 2.0991176152411506
Epoch: 19| Step: 3
Training loss: 2.697739544998539
Validation loss: 2.099897671989365
Epoch: 19| Step: 4
Training loss: 1.974545984354336
Validation loss: 2.087515655192246
Epoch: 19| Step: 5
Training loss: 2.685958952759823
Validation loss: 2.038830605350574
Epoch: 19| Step: 6
Training loss: 2.3995765193209437
Validation loss: 1.9850526995460835
Epoch: 19| Step: 7
Training loss: 2.2501036302225557
Validation loss: 2.0725625405310084
Epoch: 19| Step: 8
Training loss: 2.511490071329658
Validation loss: 2.021684461321968
Epoch: 19| Step: 9
Training loss: 2.850698512625931
Validation loss: 2.0829975613223572
Epoch: 19| Step: 10
Training loss: 2.9283131542027996
Validation loss: 2.0611078985038365
Epoch: 19| Step: 11
Training loss: 1.930220372065884
Validation loss: 2.075568449258509
Epoch: 19| Step: 12
Training loss: 2.624358144125938
Validation loss: 2.077224299581396
Epoch: 19| Step: 13
Training loss: 2.5272649785166896
Validation loss: 2.0067303683535105
Epoch: 19| Step: 14
Training loss: 2.754219545981148
Validation loss: 2.072216951696271
Epoch: 19| Step: 15
Training loss: 2.823571179702779
Validation loss: 2.0840404172436937
Epoch: 19| Step: 16
Training loss: 2.3749799225611063
Validation loss: 2.072446405735673
Epoch: 19| Step: 17
Training loss: 2.466176200338683
Validation loss: 2.001463952788854
Epoch: 19| Step: 18
Training loss: 2.5184745051032826
Validation loss: 2.051314359335826
Epoch: 19| Step: 19
Training loss: 2.339298955449326
Validation loss: 2.057610189541926
Epoch: 19| Step: 20
Training loss: 2.1252943844802124
Validation loss: 2.0803985472707605
Epoch: 19| Step: 21
Training loss: 2.8456002388959156
Validation loss: 2.060857558737248
Epoch: 19| Step: 22
Training loss: 2.3174309610990464
Validation loss: 2.0552055416051744
Epoch: 19| Step: 23
Training loss: 2.700522873723514
Validation loss: 2.100641106266783
Epoch: 19| Step: 24
Training loss: 2.389874309283307
Validation loss: 2.0773300569707542
Epoch: 19| Step: 25
Training loss: 2.732984265468847
Validation loss: 2.0356293441086994
Epoch: 19| Step: 26
Training loss: 2.2241506262618054
Validation loss: 2.0407997101007718
Epoch: 19| Step: 27
Training loss: 2.7246543525073426
Validation loss: 2.0091853920658003
Epoch: 19| Step: 28
Training loss: 2.3500199946100753
Validation loss: 2.0942934072522283
Epoch: 19| Step: 29
Training loss: 2.9264964717946045
Validation loss: 2.0730704021742072
Epoch: 19| Step: 30
Training loss: 3.442581443737408
Validation loss: 2.0763104149841016
Epoch: 19| Step: 31
Training loss: 2.6520158118327535
Validation loss: 2.089860938737028
Epoch: 20| Step: 0
Training loss: 2.5281689577560242
Validation loss: 2.0625310973348787
Epoch: 20| Step: 1
Training loss: 3.957598782027662
Validation loss: 2.024326700084414
Epoch: 20| Step: 2
Training loss: 2.794727630583039
Validation loss: 2.1002670639772103
Epoch: 20| Step: 3
Training loss: 2.9843537494641814
Validation loss: 2.1186883075060834
Epoch: 20| Step: 4
Training loss: 2.683453552048818
Validation loss: 2.072460547125602
Epoch: 20| Step: 5
Training loss: 2.2504067583106706
Validation loss: 2.12607418529194
Epoch: 20| Step: 6
Training loss: 2.7808681611679047
Validation loss: 2.0517438271090938
Epoch: 20| Step: 7
Training loss: 1.9945911940858103
Validation loss: 2.0678554609374373
Epoch: 20| Step: 8
Training loss: 2.7669678784523253
Validation loss: 2.089783883694539
Epoch: 20| Step: 9
Training loss: 2.9505823885946256
Validation loss: 2.0112949376978166
Epoch: 20| Step: 10
Training loss: 2.7891637105235616
Validation loss: 2.0967753863116796
Epoch: 20| Step: 11
Training loss: 2.3360146602275105
Validation loss: 2.073613633705807
Epoch: 20| Step: 12
Training loss: 2.833541825047231
Validation loss: 2.01674589124011
Epoch: 20| Step: 13
Training loss: 3.1411209853516784
Validation loss: 2.101020438371392
Epoch: 20| Step: 14
Training loss: 2.6004223773903576
Validation loss: 2.0864787847649438
Epoch: 20| Step: 15
Training loss: 2.7640015745807145
Validation loss: 2.095016203761757
Epoch: 20| Step: 16
Training loss: 2.3701051162393463
Validation loss: 2.082131975669399
Epoch: 20| Step: 17
Training loss: 2.65481043683073
Validation loss: 2.061568069426139
Epoch: 20| Step: 18
Training loss: 2.8982209898497837
Validation loss: 2.059652613267414
Epoch: 20| Step: 19
Training loss: 2.7008272669731013
Validation loss: 2.0581087645051017
Epoch: 20| Step: 20
Training loss: 2.4792478425229176
Validation loss: 2.0567299048615104
Epoch: 20| Step: 21
Training loss: 2.791959652305842
Validation loss: 2.0820502164735233
Epoch: 20| Step: 22
Training loss: 2.73153120116573
Validation loss: 2.0184188626197708
Epoch: 20| Step: 23
Training loss: 1.8093653571575208
Validation loss: 2.1081498343658476
Epoch: 20| Step: 24
Training loss: 2.6137395664993814
Validation loss: 2.0486441854877464
Epoch: 20| Step: 25
Training loss: 2.724309039226449
Validation loss: 2.0138355131044356
Epoch: 20| Step: 26
Training loss: 2.0794645882132285
Validation loss: 2.087584315772978
Epoch: 20| Step: 27
Training loss: 2.748949457125098
Validation loss: 2.1052530309034405
Epoch: 20| Step: 28
Training loss: 1.8752941536637666
Validation loss: 2.0999399605942757
Epoch: 20| Step: 29
Training loss: 1.52037264321717
Validation loss: 2.070526648285967
Epoch: 20| Step: 30
Training loss: 2.6346879838796666
Validation loss: 2.0585071582089265
Epoch: 20| Step: 31
Training loss: 2.416744187087312
Validation loss: 2.1118842149774495
Epoch: 21| Step: 0
Training loss: 2.326136411817733
Validation loss: 2.1069618367416947
Epoch: 21| Step: 1
Training loss: 2.2927227245701243
Validation loss: 2.0862457132612944
Epoch: 21| Step: 2
Training loss: 2.2634831268375994
Validation loss: 2.058425827873919
Epoch: 21| Step: 3
Training loss: 2.58340754453652
Validation loss: 2.0875961402836842
Epoch: 21| Step: 4
Training loss: 2.4404203087304777
Validation loss: 2.104445395421357
Epoch: 21| Step: 5
Training loss: 2.3163866939651947
Validation loss: 2.0730322763192146
Epoch: 21| Step: 6
Training loss: 2.382473580693271
Validation loss: 2.1063540255618
Epoch: 21| Step: 7
Training loss: 2.3632471507741397
Validation loss: 2.0938788439211837
Epoch: 21| Step: 8
Training loss: 2.4021557742133264
Validation loss: 2.044839191738553
Epoch: 21| Step: 9
Training loss: 3.0137620616973675
Validation loss: 2.0941361897760866
Epoch: 21| Step: 10
Training loss: 2.8533226120233395
Validation loss: 2.062433220322153
Epoch: 21| Step: 11
Training loss: 2.263590668874795
Validation loss: 2.0786175366030473
Epoch: 21| Step: 12
Training loss: 3.1169952103813903
Validation loss: 2.105635173721152
Epoch: 21| Step: 13
Training loss: 2.7386494387642246
Validation loss: 2.0842576436775855
Epoch: 21| Step: 14
Training loss: 3.1179339057812485
Validation loss: 2.0979918227789605
Epoch: 21| Step: 15
Training loss: 3.214749563142228
Validation loss: 2.0247385666405053
Epoch: 21| Step: 16
Training loss: 2.260441816573858
Validation loss: 2.0729651891183756
Epoch: 21| Step: 17
Training loss: 2.1760636151565635
Validation loss: 2.0961582127762677
Epoch: 21| Step: 18
Training loss: 1.4781917081139677
Validation loss: 2.1255713989041807
Epoch: 21| Step: 19
Training loss: 3.1537810385103127
Validation loss: 2.088607108477853
Epoch: 21| Step: 20
Training loss: 2.0058409514505056
Validation loss: 2.080357993847636
Epoch: 21| Step: 21
Training loss: 2.1019107572591977
Validation loss: 2.0538401568363294
Epoch: 21| Step: 22
Training loss: 2.736015307389209
Validation loss: 2.048396672791085
Epoch: 21| Step: 23
Training loss: 2.95385184249269
Validation loss: 2.0366890882517645
Epoch: 21| Step: 24
Training loss: 3.3750842048595735
Validation loss: 2.1111178410877054
Epoch: 21| Step: 25
Training loss: 3.2453143748395976
Validation loss: 2.058994288900317
Epoch: 21| Step: 26
Training loss: 3.0573490967087005
Validation loss: 2.055126505042041
Epoch: 21| Step: 27
Training loss: 1.6336332749666453
Validation loss: 2.0829819441284143
Epoch: 21| Step: 28
Training loss: 2.512795509686082
Validation loss: 2.019262578117029
Epoch: 21| Step: 29
Training loss: 2.345952436044652
Validation loss: 2.0806960165800943
Epoch: 21| Step: 30
Training loss: 3.321210959552856
Validation loss: 2.0720866232120034
Epoch: 21| Step: 31
Training loss: 2.911470216420899
Validation loss: 2.073072992035786
Epoch: 22| Step: 0
Training loss: 2.4516781956522395
Validation loss: 2.0895425401296874
Epoch: 22| Step: 1
Training loss: 2.1959108236442457
Validation loss: 2.064702884656968
Epoch: 22| Step: 2
Training loss: 1.988407033602657
Validation loss: 2.0932704716491544
Epoch: 22| Step: 3
Training loss: 2.6417910016118817
Validation loss: 2.065916372582308
Epoch: 22| Step: 4
Training loss: 2.6708578214747707
Validation loss: 2.032925999372176
Epoch: 22| Step: 5
Training loss: 2.366347765144732
Validation loss: 2.0869834994168786
Epoch: 22| Step: 6
Training loss: 2.8024415610870648
Validation loss: 2.0625315800967714
Epoch: 22| Step: 7
Training loss: 2.6092746738174752
Validation loss: 2.009211584092764
Epoch: 22| Step: 8
Training loss: 2.857869736988331
Validation loss: 2.101577952970901
Epoch: 22| Step: 9
Training loss: 2.33759343577618
Validation loss: 2.0473925635202503
Epoch: 22| Step: 10
Training loss: 3.406062549717831
Validation loss: 2.028342541972831
Epoch: 22| Step: 11
Training loss: 2.9978556916851327
Validation loss: 2.066760792490147
Epoch: 22| Step: 12
Training loss: 2.8287147202190237
Validation loss: 2.0545545884902325
Epoch: 22| Step: 13
Training loss: 2.412873503080946
Validation loss: 2.0317537665116596
Epoch: 22| Step: 14
Training loss: 3.437024725222673
Validation loss: 2.1084878987242637
Epoch: 22| Step: 15
Training loss: 2.3240701066898404
Validation loss: 2.0607197692011465
Epoch: 22| Step: 16
Training loss: 2.999116131596238
Validation loss: 2.088289597483755
Epoch: 22| Step: 17
Training loss: 2.6596655035874153
Validation loss: 2.083688770574082
Epoch: 22| Step: 18
Training loss: 2.225627502080062
Validation loss: 2.084675289339881
Epoch: 22| Step: 19
Training loss: 2.6609256656762126
Validation loss: 2.0949752617243456
Epoch: 22| Step: 20
Training loss: 2.901732019619331
Validation loss: 2.0662141745703595
Epoch: 22| Step: 21
Training loss: 2.34788260741241
Validation loss: 2.098041827327445
Epoch: 22| Step: 22
Training loss: 2.035171245146293
Validation loss: 2.03163740071442
Epoch: 22| Step: 23
Training loss: 3.0852023637329054
Validation loss: 2.065953747057963
Epoch: 22| Step: 24
Training loss: 2.946468055757787
Validation loss: 2.1231133549616854
Epoch: 22| Step: 25
Training loss: 3.066564393065772
Validation loss: 2.1144314542120393
Epoch: 22| Step: 26
Training loss: 2.346700819843468
Validation loss: 2.0629970265246915
Epoch: 22| Step: 27
Training loss: 2.5579876130783177
Validation loss: 2.0830956880506997
Epoch: 22| Step: 28
Training loss: 2.4815244815932367
Validation loss: 2.0847701948724526
Epoch: 22| Step: 29
Training loss: 2.2560269908643162
Validation loss: 2.0771420557993
Epoch: 22| Step: 30
Training loss: 2.2071594741167546
Validation loss: 2.095834050764058
Epoch: 22| Step: 31
Training loss: 2.497398071500208
Validation loss: 2.0822730678502746
Epoch: 23| Step: 0
Training loss: 3.659460630644736
Validation loss: 2.0512889176425486
Epoch: 23| Step: 1
Training loss: 2.64867712866657
Validation loss: 2.0391761965275528
Epoch: 23| Step: 2
Training loss: 2.8428487502369224
Validation loss: 2.073360681782587
Epoch: 23| Step: 3
Training loss: 1.9922857522110464
Validation loss: 2.0774851931532825
Epoch: 23| Step: 4
Training loss: 2.70001712369787
Validation loss: 2.050108166896237
Epoch: 23| Step: 5
Training loss: 2.130293144148214
Validation loss: 2.0682128623283194
Epoch: 23| Step: 6
Training loss: 1.4634210213273697
Validation loss: 2.0622583360840445
Epoch: 23| Step: 7
Training loss: 2.830866880789863
Validation loss: 2.1053671576377484
Epoch: 23| Step: 8
Training loss: 2.680763051024108
Validation loss: 2.0601813130770523
Epoch: 23| Step: 9
Training loss: 2.724582948180531
Validation loss: 2.084037315698398
Epoch: 23| Step: 10
Training loss: 2.260086762104767
Validation loss: 2.067232820905419
Epoch: 23| Step: 11
Training loss: 2.8555859751715897
Validation loss: 2.0702829195818553
Epoch: 23| Step: 12
Training loss: 2.31266340760945
Validation loss: 2.054430784693822
Epoch: 23| Step: 13
Training loss: 1.6843882940613482
Validation loss: 2.054172147607066
Epoch: 23| Step: 14
Training loss: 3.032739489628261
Validation loss: 2.1102167081821928
Epoch: 23| Step: 15
Training loss: 2.9878072923771097
Validation loss: 2.0111882903727416
Epoch: 23| Step: 16
Training loss: 3.0006106073137238
Validation loss: 2.0634336561092037
Epoch: 23| Step: 17
Training loss: 2.924974888098751
Validation loss: 2.1191899478310874
Epoch: 23| Step: 18
Training loss: 2.76577766988458
Validation loss: 2.104791788112103
Epoch: 23| Step: 19
Training loss: 2.687333745027872
Validation loss: 2.053529909345038
Epoch: 23| Step: 20
Training loss: 2.609911743513455
Validation loss: 2.0626550109618234
Epoch: 23| Step: 21
Training loss: 2.5807840217639653
Validation loss: 2.0785080230672537
Epoch: 23| Step: 22
Training loss: 2.1375798751451915
Validation loss: 2.0446413240310437
Epoch: 23| Step: 23
Training loss: 2.303969656148413
Validation loss: 2.075590444100847
Epoch: 23| Step: 24
Training loss: 2.9732577182865576
Validation loss: 2.0467757083238536
Epoch: 23| Step: 25
Training loss: 2.8783135599835123
Validation loss: 2.075607838472166
Epoch: 23| Step: 26
Training loss: 2.8708931158639195
Validation loss: 2.0125174250415303
Epoch: 23| Step: 27
Training loss: 2.8700417595991983
Validation loss: 2.0719308511111665
Epoch: 23| Step: 28
Training loss: 2.864805307746749
Validation loss: 2.0677089702054965
Epoch: 23| Step: 29
Training loss: 2.8075950236896916
Validation loss: 2.098422980971638
Epoch: 23| Step: 30
Training loss: 2.4524724784963405
Validation loss: 2.0493401354747585
Epoch: 23| Step: 31
Training loss: 1.5661231186994222
Validation loss: 2.025495627274009
Epoch: 24| Step: 0
Training loss: 2.818533804102872
Validation loss: 2.0671027151406607
Epoch: 24| Step: 1
Training loss: 2.755658656758554
Validation loss: 2.0591454001133886
Epoch: 24| Step: 2
Training loss: 2.4651948464164732
Validation loss: 2.054601816957292
Epoch: 24| Step: 3
Training loss: 2.0433559306120608
Validation loss: 2.094540005969232
Epoch: 24| Step: 4
Training loss: 2.586102898139992
Validation loss: 2.0996216815447277
Epoch: 24| Step: 5
Training loss: 2.5169698780971803
Validation loss: 2.06852151540668
Epoch: 24| Step: 6
Training loss: 2.863036266218458
Validation loss: 2.0480919008221243
Epoch: 24| Step: 7
Training loss: 2.656625249947468
Validation loss: 2.0999918363478267
Epoch: 24| Step: 8
Training loss: 3.3487884494215954
Validation loss: 2.1153693364555086
Epoch: 24| Step: 9
Training loss: 2.573051222604542
Validation loss: 2.137976727604001
Epoch: 24| Step: 10
Training loss: 2.6230080630796224
Validation loss: 2.0900410598451997
Epoch: 24| Step: 11
Training loss: 3.003315523993061
Validation loss: 2.1080867217533616
Epoch: 24| Step: 12
Training loss: 3.2663731060340098
Validation loss: 2.0768401221757213
Epoch: 24| Step: 13
Training loss: 2.2662066535149763
Validation loss: 2.0688119308597015
Epoch: 24| Step: 14
Training loss: 2.9458785992876084
Validation loss: 2.0157128500099732
Epoch: 24| Step: 15
Training loss: 2.427658755044626
Validation loss: 2.0612775043072538
Epoch: 24| Step: 16
Training loss: 2.8165191754731773
Validation loss: 2.08574587094505
Epoch: 24| Step: 17
Training loss: 2.163249059171041
Validation loss: 2.0597402116128984
Epoch: 24| Step: 18
Training loss: 2.420112805535336
Validation loss: 2.076555472818895
Epoch: 24| Step: 19
Training loss: 2.3716072142443836
Validation loss: 2.070441185783378
Epoch: 24| Step: 20
Training loss: 2.5773119945021
Validation loss: 2.0873767649296067
Epoch: 24| Step: 21
Training loss: 3.07376378339025
Validation loss: 2.0690423699577534
Epoch: 24| Step: 22
Training loss: 2.2571372107974956
Validation loss: 2.0927474801471893
Epoch: 24| Step: 23
Training loss: 2.7570043141494223
Validation loss: 2.088358876578444
Epoch: 24| Step: 24
Training loss: 2.561133043365829
Validation loss: 2.0870306860531387
Epoch: 24| Step: 25
Training loss: 2.3050896762441466
Validation loss: 2.0611684716360084
Epoch: 24| Step: 26
Training loss: 2.1437003883426593
Validation loss: 2.063427717296317
Epoch: 24| Step: 27
Training loss: 2.8032908242805643
Validation loss: 2.0862952682408396
Epoch: 24| Step: 28
Training loss: 3.056257776043757
Validation loss: 2.12173060635162
Epoch: 24| Step: 29
Training loss: 2.1176600755808823
Validation loss: 2.071700757804518
Epoch: 24| Step: 30
Training loss: 2.90359047236789
Validation loss: 2.024480578841228
Epoch: 24| Step: 31
Training loss: 2.1641732197886205
Validation loss: 2.041375996928014
Epoch: 25| Step: 0
Training loss: 2.8867243662200104
Validation loss: 2.06655185756419
Epoch: 25| Step: 1
Training loss: 3.467518905885143
Validation loss: 2.0952170586127257
Epoch: 25| Step: 2
Training loss: 3.210984575432363
Validation loss: 2.095687879970235
Epoch: 25| Step: 3
Training loss: 2.583494386472338
Validation loss: 2.0881424169181053
Epoch: 25| Step: 4
Training loss: 2.8129181445078375
Validation loss: 2.1074925857747546
Epoch: 25| Step: 5
Training loss: 1.8707157143348245
Validation loss: 2.0780071403530553
Epoch: 25| Step: 6
Training loss: 2.642296076099719
Validation loss: 2.06383073759103
Epoch: 25| Step: 7
Training loss: 2.7365597961070898
Validation loss: 2.0909456457062805
Epoch: 25| Step: 8
Training loss: 2.3486851930229586
Validation loss: 2.035710964755505
Epoch: 25| Step: 9
Training loss: 2.0220234175249523
Validation loss: 2.1057069693521373
Epoch: 25| Step: 10
Training loss: 2.1777932744977777
Validation loss: 2.044601488677314
Epoch: 25| Step: 11
Training loss: 2.158105245588731
Validation loss: 2.110694287553781
Epoch: 25| Step: 12
Training loss: 2.135296056799409
Validation loss: 2.09587970696672
Epoch: 25| Step: 13
Training loss: 2.948917681756209
Validation loss: 2.079354705343324
Epoch: 25| Step: 14
Training loss: 3.1293893124493266
Validation loss: 2.082310337033853
Epoch: 25| Step: 15
Training loss: 2.8687259382182115
Validation loss: 2.0446637456267363
Epoch: 25| Step: 16
Training loss: 2.9796605445510727
Validation loss: 2.0518364318819677
Epoch: 25| Step: 17
Training loss: 2.4699145117726418
Validation loss: 2.093124363186522
Epoch: 25| Step: 18
Training loss: 3.025070656195585
Validation loss: 2.0724614812799316
Epoch: 25| Step: 19
Training loss: 2.354763551735613
Validation loss: 2.112468806850995
Epoch: 25| Step: 20
Training loss: 3.3323517943706533
Validation loss: 2.0343279940633847
Epoch: 25| Step: 21
Training loss: 2.6244940497225
Validation loss: 2.0793951854310184
Epoch: 25| Step: 22
Training loss: 2.696813193239561
Validation loss: 2.088341981143744
Epoch: 25| Step: 23
Training loss: 2.9866758734129735
Validation loss: 2.089264006796802
Epoch: 25| Step: 24
Training loss: 3.0268985937830655
Validation loss: 2.0581095999937045
Epoch: 25| Step: 25
Training loss: 2.1470724312122837
Validation loss: 2.033612478586094
Epoch: 25| Step: 26
Training loss: 1.692676093943785
Validation loss: 2.051931882855048
Epoch: 25| Step: 27
Training loss: 2.6087483093226993
Validation loss: 2.1324901822184548
Epoch: 25| Step: 28
Training loss: 2.6915914751382433
Validation loss: 2.091084981463759
Epoch: 25| Step: 29
Training loss: 1.6793816576344107
Validation loss: 2.0688612272927593
Epoch: 25| Step: 30
Training loss: 2.4364341948836903
Validation loss: 2.043474612717503
Epoch: 25| Step: 31
Training loss: 2.483206996221617
Validation loss: 2.0998312012542995
Epoch: 26| Step: 0
Training loss: 2.508707332504845
Validation loss: 2.1084540447446303
Epoch: 26| Step: 1
Training loss: 3.121487894582548
Validation loss: 2.1052552276212975
Epoch: 26| Step: 2
Training loss: 2.601735793748553
Validation loss: 2.0809843450499215
Epoch: 26| Step: 3
Training loss: 2.059373971941725
Validation loss: 2.0518266687527573
Epoch: 26| Step: 4
Training loss: 3.0613288975771002
Validation loss: 2.0717150271896263
Epoch: 26| Step: 5
Training loss: 2.730951662158923
Validation loss: 2.0973004814953775
Epoch: 26| Step: 6
Training loss: 2.785762426638075
Validation loss: 2.039218664858021
Epoch: 26| Step: 7
Training loss: 2.872395040189761
Validation loss: 2.002682999779049
Epoch: 26| Step: 8
Training loss: 2.1757540743926755
Validation loss: 2.1247117240669358
Epoch: 26| Step: 9
Training loss: 2.291167765555249
Validation loss: 2.075735034700289
Epoch: 26| Step: 10
Training loss: 2.530820174280883
Validation loss: 2.0510763707316517
Epoch: 26| Step: 11
Training loss: 2.991035897180142
Validation loss: 2.0722614224463816
Epoch: 26| Step: 12
Training loss: 2.296305060227509
Validation loss: 2.0881486190202834
Epoch: 26| Step: 13
Training loss: 3.098120944366971
Validation loss: 2.087661802653852
Epoch: 26| Step: 14
Training loss: 1.73094229322005
Validation loss: 2.0615862104280636
Epoch: 26| Step: 15
Training loss: 2.8541562342395066
Validation loss: 2.0045513263340973
Epoch: 26| Step: 16
Training loss: 2.4048302165035977
Validation loss: 2.072930845033041
Epoch: 26| Step: 17
Training loss: 2.9345656002977973
Validation loss: 2.0249331970697146
Epoch: 26| Step: 18
Training loss: 2.3147679110826065
Validation loss: 2.0786840327338996
Epoch: 26| Step: 19
Training loss: 2.3426682073725216
Validation loss: 1.997564109677946
Epoch: 26| Step: 20
Training loss: 2.8359549866024243
Validation loss: 2.056152936232591
Epoch: 26| Step: 21
Training loss: 2.5300423837963963
Validation loss: 2.090446417311123
Epoch: 26| Step: 22
Training loss: 2.3133745344085974
Validation loss: 2.0709923566745525
Epoch: 26| Step: 23
Training loss: 2.95102273701796
Validation loss: 2.0784510961488643
Epoch: 26| Step: 24
Training loss: 2.6712298590365355
Validation loss: 2.085366048332199
Epoch: 26| Step: 25
Training loss: 2.788970689304271
Validation loss: 2.0562788832721646
Epoch: 26| Step: 26
Training loss: 2.273559147572318
Validation loss: 2.109371057585016
Epoch: 26| Step: 27
Training loss: 2.7952946295041716
Validation loss: 2.0809932742900745
Epoch: 26| Step: 28
Training loss: 2.112012669257976
Validation loss: 2.053896479091941
Epoch: 26| Step: 29
Training loss: 3.0135088992103736
Validation loss: 2.1038070295542406
Epoch: 26| Step: 30
Training loss: 2.3776683875300124
Validation loss: 2.0863167780990337
Epoch: 26| Step: 31
Training loss: 3.1879607222948234
Validation loss: 2.068770637877727
Epoch: 27| Step: 0
Training loss: 3.237643005276255
Validation loss: 2.075014645542775
Epoch: 27| Step: 1
Training loss: 2.8532330361977265
Validation loss: 2.0751655428861713
Epoch: 27| Step: 2
Training loss: 2.774130807104149
Validation loss: 2.0663338105852795
Epoch: 27| Step: 3
Training loss: 2.704486041221486
Validation loss: 2.074383609325053
Epoch: 27| Step: 4
Training loss: 2.334570647470799
Validation loss: 2.0676519916889955
Epoch: 27| Step: 5
Training loss: 2.834333654604729
Validation loss: 2.0987912424912167
Epoch: 27| Step: 6
Training loss: 1.7173537391675424
Validation loss: 2.0406068844581258
Epoch: 27| Step: 7
Training loss: 2.311901221207843
Validation loss: 2.037934349541989
Epoch: 27| Step: 8
Training loss: 2.467426283178718
Validation loss: 2.001362324063034
Epoch: 27| Step: 9
Training loss: 2.4478838871053004
Validation loss: 2.1109044114987685
Epoch: 27| Step: 10
Training loss: 2.669259380533103
Validation loss: 2.096609400925308
Epoch: 27| Step: 11
Training loss: 2.343593541327225
Validation loss: 2.101898928158764
Epoch: 27| Step: 12
Training loss: 2.1700053778375183
Validation loss: 2.116952334273025
Epoch: 27| Step: 13
Training loss: 2.316120200804875
Validation loss: 2.070756847035457
Epoch: 27| Step: 14
Training loss: 3.1630752341880504
Validation loss: 2.10920986561131
Epoch: 27| Step: 15
Training loss: 2.7460715237365108
Validation loss: 2.047823329844069
Epoch: 27| Step: 16
Training loss: 2.4708739210357913
Validation loss: 2.0613447599639296
Epoch: 27| Step: 17
Training loss: 2.8787589999549765
Validation loss: 2.116970439025723
Epoch: 27| Step: 18
Training loss: 2.2862501346510924
Validation loss: 2.1070841794878836
Epoch: 27| Step: 19
Training loss: 3.1653019490773717
Validation loss: 2.073340777875347
Epoch: 27| Step: 20
Training loss: 2.746348210533354
Validation loss: 2.0411104314403583
Epoch: 27| Step: 21
Training loss: 3.00720192793297
Validation loss: 2.0641908428010014
Epoch: 27| Step: 22
Training loss: 2.2921036968240833
Validation loss: 2.061081219185394
Epoch: 27| Step: 23
Training loss: 2.2141159449596604
Validation loss: 2.0925821144754035
Epoch: 27| Step: 24
Training loss: 2.229262792588435
Validation loss: 2.081530281500446
Epoch: 27| Step: 25
Training loss: 2.9682531643778898
Validation loss: 2.0721422895541335
Epoch: 27| Step: 26
Training loss: 2.992351955744976
Validation loss: 2.1108838393343095
Epoch: 27| Step: 27
Training loss: 2.6334178919032194
Validation loss: 2.060823299566798
Epoch: 27| Step: 28
Training loss: 2.753930317658572
Validation loss: 2.0774534168469883
Epoch: 27| Step: 29
Training loss: 2.794902596183946
Validation loss: 2.0634132505617733
Epoch: 27| Step: 30
Training loss: 2.5147974773794184
Validation loss: 2.1064409271482316
Epoch: 27| Step: 31
Training loss: 2.664231907444757
Validation loss: 2.084877629706608
Epoch: 28| Step: 0
Training loss: 2.880029342819779
Validation loss: 2.0521449393392754
Epoch: 28| Step: 1
Training loss: 1.9617941151813325
Validation loss: 2.0705077769789537
Epoch: 28| Step: 2
Training loss: 2.8620504567665535
Validation loss: 2.0986640031327553
Epoch: 28| Step: 3
Training loss: 2.4095321663385443
Validation loss: 2.0863802646297005
Epoch: 28| Step: 4
Training loss: 2.7429511156332893
Validation loss: 2.073916527309505
Epoch: 28| Step: 5
Training loss: 2.324732927139295
Validation loss: 2.068473816392195
Epoch: 28| Step: 6
Training loss: 2.642273788802723
Validation loss: 2.071053063466741
Epoch: 28| Step: 7
Training loss: 3.1222102110312298
Validation loss: 2.0874607272174828
Epoch: 28| Step: 8
Training loss: 2.2269397081453732
Validation loss: 2.092505978215758
Epoch: 28| Step: 9
Training loss: 2.303253451819376
Validation loss: 2.0532516058339265
Epoch: 28| Step: 10
Training loss: 2.91884582492927
Validation loss: 2.021293285030352
Epoch: 28| Step: 11
Training loss: 1.7693831021774562
Validation loss: 2.1036136138169876
Epoch: 28| Step: 12
Training loss: 2.6552449737291504
Validation loss: 2.1068519543599837
Epoch: 28| Step: 13
Training loss: 2.7323685614270365
Validation loss: 2.0882499005292585
Epoch: 28| Step: 14
Training loss: 3.107523764828615
Validation loss: 2.0973698322070606
Epoch: 28| Step: 15
Training loss: 2.772807992763633
Validation loss: 2.062962969275589
Epoch: 28| Step: 16
Training loss: 2.1919043751693352
Validation loss: 2.0556810457728556
Epoch: 28| Step: 17
Training loss: 2.965659691433848
Validation loss: 2.1023415292094225
Epoch: 28| Step: 18
Training loss: 3.501987846444923
Validation loss: 2.096691325797204
Epoch: 28| Step: 19
Training loss: 2.7385332152152917
Validation loss: 2.055562067976003
Epoch: 28| Step: 20
Training loss: 2.4620319173310463
Validation loss: 2.0888823898866447
Epoch: 28| Step: 21
Training loss: 2.2704186600440504
Validation loss: 2.0940517710416247
Epoch: 28| Step: 22
Training loss: 2.350487346031665
Validation loss: 2.048601721391454
Epoch: 28| Step: 23
Training loss: 2.2584167516675584
Validation loss: 2.0303339492817942
Epoch: 28| Step: 24
Training loss: 2.7926489586917174
Validation loss: 2.069723457072013
Epoch: 28| Step: 25
Training loss: 3.279812307104848
Validation loss: 2.026753366981914
Epoch: 28| Step: 26
Training loss: 2.5961273512615874
Validation loss: 2.0620870676722087
Epoch: 28| Step: 27
Training loss: 3.3207266515605838
Validation loss: 2.0535472217785764
Epoch: 28| Step: 28
Training loss: 2.4627078515646557
Validation loss: 2.096464250716235
Epoch: 28| Step: 29
Training loss: 2.418635607633909
Validation loss: 2.0498035869265685
Epoch: 28| Step: 30
Training loss: 2.3084020648001156
Validation loss: 2.0513925551331806
Epoch: 28| Step: 31
Training loss: 2.043887571785056
Validation loss: 2.0550354898975987
Epoch: 29| Step: 0
Training loss: 3.0214160401027423
Validation loss: 2.0078434634089355
Epoch: 29| Step: 1
Training loss: 2.523095264198171
Validation loss: 2.1034167295226265
Epoch: 29| Step: 2
Training loss: 3.08905860387376
Validation loss: 2.035626686371689
Epoch: 29| Step: 3
Training loss: 2.262534829393247
Validation loss: 2.056204412928504
Epoch: 29| Step: 4
Training loss: 2.662475202561359
Validation loss: 2.0469585854317383
Epoch: 29| Step: 5
Training loss: 2.42254471901953
Validation loss: 2.021808510306673
Epoch: 29| Step: 6
Training loss: 2.718428230975862
Validation loss: 2.1140276358201984
Epoch: 29| Step: 7
Training loss: 2.382971586326155
Validation loss: 2.0158464800229345
Epoch: 29| Step: 8
Training loss: 2.7128713784245733
Validation loss: 2.0875050919304465
Epoch: 29| Step: 9
Training loss: 2.8023357254053805
Validation loss: 2.0995764568591366
Epoch: 29| Step: 10
Training loss: 1.4099774445427355
Validation loss: 2.053684643626513
Epoch: 29| Step: 11
Training loss: 2.6170765411996566
Validation loss: 2.045773466869937
Epoch: 29| Step: 12
Training loss: 2.1566333153615824
Validation loss: 2.0936802181085623
Epoch: 29| Step: 13
Training loss: 2.394434866280021
Validation loss: 2.110362787088534
Epoch: 29| Step: 14
Training loss: 2.368725670359934
Validation loss: 2.0800748559999507
Epoch: 29| Step: 15
Training loss: 2.5189245158808
Validation loss: 2.0524777323291437
Epoch: 29| Step: 16
Training loss: 3.172753423815043
Validation loss: 2.0594047564039695
Epoch: 29| Step: 17
Training loss: 2.9671715003250667
Validation loss: 2.075156052394554
Epoch: 29| Step: 18
Training loss: 3.3724935195894523
Validation loss: 2.001406866050622
Epoch: 29| Step: 19
Training loss: 2.538883989367869
Validation loss: 2.1248167950948775
Epoch: 29| Step: 20
Training loss: 1.9736921857371572
Validation loss: 2.124068505995503
Epoch: 29| Step: 21
Training loss: 3.2024118513472644
Validation loss: 2.101163746422219
Epoch: 29| Step: 22
Training loss: 2.824970741458041
Validation loss: 2.062476556980643
Epoch: 29| Step: 23
Training loss: 2.235572440724261
Validation loss: 2.053093959678676
Epoch: 29| Step: 24
Training loss: 2.341849612039107
Validation loss: 2.1007534166017225
Epoch: 29| Step: 25
Training loss: 2.0912741071060594
Validation loss: 2.103708865526371
Epoch: 29| Step: 26
Training loss: 2.3282147076624153
Validation loss: 2.0517069827366856
Epoch: 29| Step: 27
Training loss: 3.3245945504016796
Validation loss: 2.061396223620468
Epoch: 29| Step: 28
Training loss: 2.9250510186856675
Validation loss: 2.107356207637013
Epoch: 29| Step: 29
Training loss: 2.406190747609049
Validation loss: 2.0691681637257195
Epoch: 29| Step: 30
Training loss: 2.867349479735672
Validation loss: 2.0584210325381984
Epoch: 29| Step: 31
Training loss: 2.696305597870114
Validation loss: 2.0700750243760613
Epoch: 30| Step: 0
Training loss: 1.7958137363624347
Validation loss: 2.078226554294902
Epoch: 30| Step: 1
Training loss: 2.0086001027740115
Validation loss: 2.1042611534290003
Epoch: 30| Step: 2
Training loss: 2.5004637288111864
Validation loss: 2.105928150672413
Epoch: 30| Step: 3
Training loss: 2.047173048843903
Validation loss: 2.0217515254703544
Epoch: 30| Step: 4
Training loss: 3.3974811479888953
Validation loss: 2.120803649457724
Epoch: 30| Step: 5
Training loss: 2.671055093526262
Validation loss: 2.0476281462750805
Epoch: 30| Step: 6
Training loss: 2.049199887885873
Validation loss: 2.0614711699008854
Epoch: 30| Step: 7
Training loss: 2.2526306033190986
Validation loss: 2.060558767554263
Epoch: 30| Step: 8
Training loss: 3.4216627638680457
Validation loss: 2.0997311517962056
Epoch: 30| Step: 9
Training loss: 2.2691661652690414
Validation loss: 2.0395908638681193
Epoch: 30| Step: 10
Training loss: 2.937531978351952
Validation loss: 2.0967811820656
Epoch: 30| Step: 11
Training loss: 2.0899005632610486
Validation loss: 2.085125930753311
Epoch: 30| Step: 12
Training loss: 2.1735181561771997
Validation loss: 2.0859549090493683
Epoch: 30| Step: 13
Training loss: 2.7378901965608615
Validation loss: 2.0352380757285062
Epoch: 30| Step: 14
Training loss: 2.608836958002071
Validation loss: 2.032848094831283
Epoch: 30| Step: 15
Training loss: 2.5491515674208314
Validation loss: 2.030660973652326
Epoch: 30| Step: 16
Training loss: 2.37508291802469
Validation loss: 2.0857123862330904
Epoch: 30| Step: 17
Training loss: 3.1010918632513502
Validation loss: 2.0547199626200445
Epoch: 30| Step: 18
Training loss: 2.84633946160476
Validation loss: 2.121879407282644
Epoch: 30| Step: 19
Training loss: 3.221967995871228
Validation loss: 2.025655882780777
Epoch: 30| Step: 20
Training loss: 2.708794794139152
Validation loss: 2.082973835402601
Epoch: 30| Step: 21
Training loss: 3.1351098367775996
Validation loss: 2.077275783003132
Epoch: 30| Step: 22
Training loss: 2.6483921283447653
Validation loss: 2.0937141121420044
Epoch: 30| Step: 23
Training loss: 3.3020893822904394
Validation loss: 2.0880981696388923
Epoch: 30| Step: 24
Training loss: 1.6170278276869312
Validation loss: 2.098003931307056
Epoch: 30| Step: 25
Training loss: 3.119446206217361
Validation loss: 2.0789288787488798
Epoch: 30| Step: 26
Training loss: 2.3425175796223696
Validation loss: 2.059611522028223
Epoch: 30| Step: 27
Training loss: 2.615378776819953
Validation loss: 2.0781962346725544
Epoch: 30| Step: 28
Training loss: 2.89278022219809
Validation loss: 2.071790122605083
Epoch: 30| Step: 29
Training loss: 2.282155941354933
Validation loss: 2.053207994857678
Epoch: 30| Step: 30
Training loss: 2.9122567398578814
Validation loss: 2.0510037195777104
Epoch: 30| Step: 31
Training loss: 2.390466024062008
Validation loss: 2.034628559628687
