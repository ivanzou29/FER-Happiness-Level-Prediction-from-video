Epoch: 1| Step: 0
Training loss: 5.845665928715606
Validation loss: 5.688128652374817
Epoch: 1| Step: 1
Training loss: 6.662261111215447
Validation loss: 5.339834728677956
Epoch: 1| Step: 2
Training loss: 5.629432965955672
Validation loss: 5.31821356625886
Epoch: 1| Step: 3
Training loss: 5.8184895163147665
Validation loss: 5.271115344547489
Epoch: 1| Step: 4
Training loss: 4.387863431044995
Validation loss: 5.239926545351687
Epoch: 1| Step: 5
Training loss: 5.767636328228165
Validation loss: 5.298083351940192
Epoch: 1| Step: 6
Training loss: 6.478419646183824
Validation loss: 5.168623075296499
Epoch: 1| Step: 7
Training loss: 5.264865175207277
Validation loss: 5.017405964942504
Epoch: 1| Step: 8
Training loss: 6.123588243611333
Validation loss: 5.028019156819751
Epoch: 1| Step: 9
Training loss: 5.26839023506662
Validation loss: 4.9460492776768765
Epoch: 1| Step: 10
Training loss: 4.675868952158911
Validation loss: 4.895101634618541
Epoch: 1| Step: 11
Training loss: 5.1736939334711645
Validation loss: 4.921008153808131
Epoch: 1| Step: 12
Training loss: 5.104183440926944
Validation loss: 4.866561358795027
Epoch: 1| Step: 13
Training loss: 4.100162056302098
Validation loss: 4.725790966293032
Epoch: 1| Step: 14
Training loss: 5.356716019110908
Validation loss: 4.755774068198488
Epoch: 1| Step: 15
Training loss: 5.304046007788241
Validation loss: 4.741255965279609
Epoch: 2| Step: 0
Training loss: 4.80677950835519
Validation loss: 4.614284007750865
Epoch: 2| Step: 1
Training loss: 4.701233340829485
Validation loss: 4.623108147279251
Epoch: 2| Step: 2
Training loss: 5.439515014515508
Validation loss: 4.403954549592181
Epoch: 2| Step: 3
Training loss: 4.188160175266286
Validation loss: 4.39484579406055
Epoch: 2| Step: 4
Training loss: 4.72034735516809
Validation loss: 4.303142401096754
Epoch: 2| Step: 5
Training loss: 4.226802797943169
Validation loss: 4.323175086696047
Epoch: 2| Step: 6
Training loss: 4.6440191219176015
Validation loss: 4.235738894965567
Epoch: 2| Step: 7
Training loss: 5.089802716222258
Validation loss: 4.13170748492452
Epoch: 2| Step: 8
Training loss: 4.519847967578602
Validation loss: 4.113778528271784
Epoch: 2| Step: 9
Training loss: 4.880084589553371
Validation loss: 4.036341405652183
Epoch: 2| Step: 10
Training loss: 4.286290674959427
Validation loss: 3.9855141899529056
Epoch: 2| Step: 11
Training loss: 5.020319087917304
Validation loss: 3.954427259119573
Epoch: 2| Step: 12
Training loss: 4.515936289686754
Validation loss: 3.769172703422528
Epoch: 2| Step: 13
Training loss: 4.662868225447791
Validation loss: 3.910693700177703
Epoch: 2| Step: 14
Training loss: 4.015754430443909
Validation loss: 3.811134573887292
Epoch: 2| Step: 15
Training loss: 3.0759441569980126
Validation loss: 3.652772611154266
Epoch: 3| Step: 0
Training loss: 4.698141810174088
Validation loss: 3.713419106176815
Epoch: 3| Step: 1
Training loss: 4.296129862593151
Validation loss: 3.7183593491808025
Epoch: 3| Step: 2
Training loss: 4.098119602243448
Validation loss: 3.7188314697900258
Epoch: 3| Step: 3
Training loss: 3.7162102754062714
Validation loss: 3.5454190172835034
Epoch: 3| Step: 4
Training loss: 4.418034803468416
Validation loss: 3.6289688518224836
Epoch: 3| Step: 5
Training loss: 3.393381852613119
Validation loss: 3.464478485776144
Epoch: 3| Step: 6
Training loss: 4.4137381915569485
Validation loss: 3.459668211947676
Epoch: 3| Step: 7
Training loss: 4.2594156869245055
Validation loss: 3.4197498693621284
Epoch: 3| Step: 8
Training loss: 2.8081205391185113
Validation loss: 3.3059829658810322
Epoch: 3| Step: 9
Training loss: 4.1332506838092895
Validation loss: 3.3579120502100164
Epoch: 3| Step: 10
Training loss: 3.5831045624798703
Validation loss: 3.3895521331192864
Epoch: 3| Step: 11
Training loss: 3.6967475153271745
Validation loss: 3.2393294500038117
Epoch: 3| Step: 12
Training loss: 3.574619091522214
Validation loss: 3.332000902562786
Epoch: 3| Step: 13
Training loss: 3.363400199107003
Validation loss: 3.316797902585074
Epoch: 3| Step: 14
Training loss: 3.987196697311503
Validation loss: 3.2234334364050263
Epoch: 3| Step: 15
Training loss: 3.518513082384814
Validation loss: 3.1067497248624076
Epoch: 4| Step: 0
Training loss: 3.4583736248809873
Validation loss: 3.1896951717112594
Epoch: 4| Step: 1
Training loss: 4.291992298599259
Validation loss: 3.117873125920639
Epoch: 4| Step: 2
Training loss: 2.8703153839678284
Validation loss: 3.000608870077114
Epoch: 4| Step: 3
Training loss: 3.239005050480937
Validation loss: 2.9710334986702596
Epoch: 4| Step: 4
Training loss: 3.0162865105896097
Validation loss: 3.0326806218596474
Epoch: 4| Step: 5
Training loss: 3.670740349956242
Validation loss: 2.9863330537083335
Epoch: 4| Step: 6
Training loss: 3.2187409632287434
Validation loss: 2.926176685955678
Epoch: 4| Step: 7
Training loss: 3.4643931477536074
Validation loss: 2.9297697211802993
Epoch: 4| Step: 8
Training loss: 3.0447361408033795
Validation loss: 2.8207476467364985
Epoch: 4| Step: 9
Training loss: 3.8538461225402165
Validation loss: 2.8386103927992097
Epoch: 4| Step: 10
Training loss: 3.1734207971791637
Validation loss: 2.804340111909546
Epoch: 4| Step: 11
Training loss: 2.8519870389774926
Validation loss: 2.7794428433465
Epoch: 4| Step: 12
Training loss: 3.577077120799804
Validation loss: 2.7732041774640948
Epoch: 4| Step: 13
Training loss: 3.5484817159460356
Validation loss: 2.763770468425019
Epoch: 4| Step: 14
Training loss: 3.3050987041929636
Validation loss: 2.78465606958795
Epoch: 4| Step: 15
Training loss: 3.6484228619888364
Validation loss: 2.7517550504194213
Epoch: 5| Step: 0
Training loss: 2.5440941355221014
Validation loss: 2.6194871323841444
Epoch: 5| Step: 1
Training loss: 3.1494882500952106
Validation loss: 2.538842276305105
Epoch: 5| Step: 2
Training loss: 2.8499060431268393
Validation loss: 2.70873158449994
Epoch: 5| Step: 3
Training loss: 3.196391550688448
Validation loss: 2.599552732797641
Epoch: 5| Step: 4
Training loss: 3.5079382383244613
Validation loss: 2.6160572199755365
Epoch: 5| Step: 5
Training loss: 3.4081611521412603
Validation loss: 2.5767277895661906
Epoch: 5| Step: 6
Training loss: 3.54358026007177
Validation loss: 2.6750221429002203
Epoch: 5| Step: 7
Training loss: 3.492672743569995
Validation loss: 2.609865126982232
Epoch: 5| Step: 8
Training loss: 2.8625467354903065
Validation loss: 2.5894011481845345
Epoch: 5| Step: 9
Training loss: 2.5664422019635054
Validation loss: 2.535306915564463
Epoch: 5| Step: 10
Training loss: 3.1557396202252144
Validation loss: 2.535042689990774
Epoch: 5| Step: 11
Training loss: 3.1188639098256106
Validation loss: 2.4643655736663406
Epoch: 5| Step: 12
Training loss: 3.3831443007204216
Validation loss: 2.356560000198774
Epoch: 5| Step: 13
Training loss: 2.203666890914614
Validation loss: 2.4926017219032803
Epoch: 5| Step: 14
Training loss: 3.0512518330544696
Validation loss: 2.3466933888586734
Epoch: 5| Step: 15
Training loss: 2.7990064118295863
Validation loss: 2.4522014878651137
Epoch: 6| Step: 0
Training loss: 2.83378532020826
Validation loss: 2.428103032371826
Epoch: 6| Step: 1
Training loss: 2.6122564978031813
Validation loss: 2.4107277486607623
Epoch: 6| Step: 2
Training loss: 2.9807938264726563
Validation loss: 2.2457324361650346
Epoch: 6| Step: 3
Training loss: 2.853626413564137
Validation loss: 2.3063944029028036
Epoch: 6| Step: 4
Training loss: 2.5762916288385775
Validation loss: 2.3931433886576183
Epoch: 6| Step: 5
Training loss: 3.185283264067903
Validation loss: 2.310736244822708
Epoch: 6| Step: 6
Training loss: 3.2031294659839293
Validation loss: 2.2803684252625325
Epoch: 6| Step: 7
Training loss: 3.1429258809685154
Validation loss: 2.2954370942712545
Epoch: 6| Step: 8
Training loss: 2.28102810969377
Validation loss: 2.2703153724119147
Epoch: 6| Step: 9
Training loss: 2.7907027862745974
Validation loss: 2.2309461470607843
Epoch: 6| Step: 10
Training loss: 2.9117047382464882
Validation loss: 2.3770229694263088
Epoch: 6| Step: 11
Training loss: 2.5776368574925375
Validation loss: 2.249822347331331
Epoch: 6| Step: 12
Training loss: 3.11073925051464
Validation loss: 2.2920244970877337
Epoch: 6| Step: 13
Training loss: 2.990617384945732
Validation loss: 2.201080726972616
Epoch: 6| Step: 14
Training loss: 2.662802837503373
Validation loss: 2.246824862767185
Epoch: 6| Step: 15
Training loss: 2.863554021689103
Validation loss: 2.304725117258951
Epoch: 7| Step: 0
Training loss: 3.020930076014657
Validation loss: 2.1963154498326802
Epoch: 7| Step: 1
Training loss: 3.2840877795737
Validation loss: 2.272746363406949
Epoch: 7| Step: 2
Training loss: 2.838057301110174
Validation loss: 2.2125574173727998
Epoch: 7| Step: 3
Training loss: 2.7529955068178156
Validation loss: 2.264389717175618
Epoch: 7| Step: 4
Training loss: 2.673054039017508
Validation loss: 2.1420447340662303
Epoch: 7| Step: 5
Training loss: 3.151519856805112
Validation loss: 2.1504363591748628
Epoch: 7| Step: 6
Training loss: 2.7851985377114885
Validation loss: 2.130334254164794
Epoch: 7| Step: 7
Training loss: 2.3383943529747957
Validation loss: 2.1516451408802166
Epoch: 7| Step: 8
Training loss: 2.2808572091342048
Validation loss: 2.131465397690382
Epoch: 7| Step: 9
Training loss: 2.2896881810746055
Validation loss: 2.18276926556839
Epoch: 7| Step: 10
Training loss: 2.645537913092416
Validation loss: 2.1488635690822586
Epoch: 7| Step: 11
Training loss: 2.696495437875684
Validation loss: 2.1388889973229706
Epoch: 7| Step: 12
Training loss: 2.5114172581009133
Validation loss: 2.190521562189024
Epoch: 7| Step: 13
Training loss: 2.7409407778454917
Validation loss: 2.1841309783793865
Epoch: 7| Step: 14
Training loss: 3.1658070217269905
Validation loss: 2.1287867994578953
Epoch: 7| Step: 15
Training loss: 2.409069638624562
Validation loss: 2.175846919885716
Epoch: 8| Step: 0
Training loss: 2.521211380367265
Validation loss: 2.139384405661585
Epoch: 8| Step: 1
Training loss: 3.2963351851831106
Validation loss: 2.1668341105849316
Epoch: 8| Step: 2
Training loss: 2.391011325313178
Validation loss: 2.095718747283535
Epoch: 8| Step: 3
Training loss: 2.9115090317426366
Validation loss: 2.067976920148429
Epoch: 8| Step: 4
Training loss: 2.7196875523178514
Validation loss: 2.075520873529973
Epoch: 8| Step: 5
Training loss: 2.820410137652674
Validation loss: 2.0388781943465744
Epoch: 8| Step: 6
Training loss: 2.865815127855581
Validation loss: 2.1383425867878283
Epoch: 8| Step: 7
Training loss: 2.412318714030956
Validation loss: 2.1238389336980052
Epoch: 8| Step: 8
Training loss: 2.085035493397661
Validation loss: 2.1366767334800714
Epoch: 8| Step: 9
Training loss: 2.7450039303166056
Validation loss: 2.0743888280740417
Epoch: 8| Step: 10
Training loss: 2.8577669551968095
Validation loss: 2.074974784888409
Epoch: 8| Step: 11
Training loss: 2.558607447929697
Validation loss: 2.097393223569526
Epoch: 8| Step: 12
Training loss: 2.456887730711271
Validation loss: 2.05539907727862
Epoch: 8| Step: 13
Training loss: 3.0811641038911612
Validation loss: 2.0827610415837263
Epoch: 8| Step: 14
Training loss: 2.5537475349911047
Validation loss: 2.124378970395606
Epoch: 8| Step: 15
Training loss: 2.415952269973183
Validation loss: 2.0767062375880836
Epoch: 9| Step: 0
Training loss: 2.099476626435729
Validation loss: 2.0497011247536863
Epoch: 9| Step: 1
Training loss: 2.3966903038433274
Validation loss: 2.0851619003526842
Epoch: 9| Step: 2
Training loss: 2.6123575308615536
Validation loss: 2.1243803894131754
Epoch: 9| Step: 3
Training loss: 2.284157767971463
Validation loss: 2.141614985395393
Epoch: 9| Step: 4
Training loss: 2.5024811829917977
Validation loss: 2.0590079806812938
Epoch: 9| Step: 5
Training loss: 3.0901761460945236
Validation loss: 2.121595334597952
Epoch: 9| Step: 6
Training loss: 3.054304093985266
Validation loss: 2.1530118764166004
Epoch: 9| Step: 7
Training loss: 2.6749404365824514
Validation loss: 2.08806364902983
Epoch: 9| Step: 8
Training loss: 2.526845608751898
Validation loss: 2.0802192217277526
Epoch: 9| Step: 9
Training loss: 2.636272839175502
Validation loss: 2.0767542223526667
Epoch: 9| Step: 10
Training loss: 2.875565017243741
Validation loss: 2.0552784869332856
Epoch: 9| Step: 11
Training loss: 2.5723595163969404
Validation loss: 2.086543086296819
Epoch: 9| Step: 12
Training loss: 3.0548701317087845
Validation loss: 2.092189502692288
Epoch: 9| Step: 13
Training loss: 2.6441893589005034
Validation loss: 2.1132338128921604
Epoch: 9| Step: 14
Training loss: 2.9075473637876406
Validation loss: 2.0050178035020148
Epoch: 9| Step: 15
Training loss: 2.3156393238607884
Validation loss: 2.1191962969545757
Epoch: 10| Step: 0
Training loss: 2.513905002362038
Validation loss: 2.0642454982006733
Epoch: 10| Step: 1
Training loss: 2.4843666508372384
Validation loss: 2.1188589592505385
Epoch: 10| Step: 2
Training loss: 2.4412424749755512
Validation loss: 2.0473448243069643
Epoch: 10| Step: 3
Training loss: 2.665109288907318
Validation loss: 2.0686744969768154
Epoch: 10| Step: 4
Training loss: 2.4735823067781193
Validation loss: 2.1737071913070274
Epoch: 10| Step: 5
Training loss: 2.474095990550687
Validation loss: 2.128262542514657
Epoch: 10| Step: 6
Training loss: 2.7535732636119588
Validation loss: 2.1036542382007317
Epoch: 10| Step: 7
Training loss: 2.380946094413814
Validation loss: 2.0576820644586626
Epoch: 10| Step: 8
Training loss: 2.656564761193263
Validation loss: 2.062199962982024
Epoch: 10| Step: 9
Training loss: 2.811539040747776
Validation loss: 2.1406232574858612
Epoch: 10| Step: 10
Training loss: 2.536538709637265
Validation loss: 2.0691893342622723
Epoch: 10| Step: 11
Training loss: 2.910046138856468
Validation loss: 2.0591361518573943
Epoch: 10| Step: 12
Training loss: 2.8640124127742363
Validation loss: 1.9976756824685318
Epoch: 10| Step: 13
Training loss: 2.2567556475062314
Validation loss: 2.073140142638179
Epoch: 10| Step: 14
Training loss: 2.9561084027887214
Validation loss: 2.1094654582523047
Epoch: 10| Step: 15
Training loss: 2.9520205092402554
Validation loss: 2.018784740050417
Epoch: 11| Step: 0
Training loss: 3.1045780464004133
Validation loss: 2.0899964913515485
Epoch: 11| Step: 1
Training loss: 2.3159454041669
Validation loss: 2.0608912901187613
Epoch: 11| Step: 2
Training loss: 2.7351702596332332
Validation loss: 2.1475271575268473
Epoch: 11| Step: 3
Training loss: 2.2438383504745394
Validation loss: 2.1331489471580825
Epoch: 11| Step: 4
Training loss: 2.68991246729816
Validation loss: 2.0991404949508436
Epoch: 11| Step: 5
Training loss: 2.727596403913006
Validation loss: 2.121591406931746
Epoch: 11| Step: 6
Training loss: 2.744141841358716
Validation loss: 2.1346981553198567
Epoch: 11| Step: 7
Training loss: 2.9336387742571013
Validation loss: 2.0296603531329707
Epoch: 11| Step: 8
Training loss: 2.312869892951965
Validation loss: 2.110851551729255
Epoch: 11| Step: 9
Training loss: 2.74254899209842
Validation loss: 2.1087495462789927
Epoch: 11| Step: 10
Training loss: 2.211290311127847
Validation loss: 2.0647829800737596
Epoch: 11| Step: 11
Training loss: 2.498005739161157
Validation loss: 2.073158502731349
Epoch: 11| Step: 12
Training loss: 2.1668887635864755
Validation loss: 2.0709336042590523
Epoch: 11| Step: 13
Training loss: 2.6360244854208084
Validation loss: 2.142159446632158
Epoch: 11| Step: 14
Training loss: 3.131461672757113
Validation loss: 2.13292824705765
Epoch: 11| Step: 15
Training loss: 2.698347511403482
Validation loss: 2.1098583006981078
Epoch: 12| Step: 0
Training loss: 2.058772562502067
Validation loss: 2.039517207338773
Epoch: 12| Step: 1
Training loss: 2.3886056985991067
Validation loss: 2.0555676204252915
Epoch: 12| Step: 2
Training loss: 2.561708932981676
Validation loss: 2.1176328004352825
Epoch: 12| Step: 3
Training loss: 2.687861928300163
Validation loss: 2.1053969661185166
Epoch: 12| Step: 4
Training loss: 2.374612274645067
Validation loss: 2.0935567613898853
Epoch: 12| Step: 5
Training loss: 2.9178193857145045
Validation loss: 2.0332303461604186
Epoch: 12| Step: 6
Training loss: 3.0295773640091452
Validation loss: 2.0770436200510876
Epoch: 12| Step: 7
Training loss: 2.707388453840755
Validation loss: 2.041322717877718
Epoch: 12| Step: 8
Training loss: 2.643721350837032
Validation loss: 2.1035757615880573
Epoch: 12| Step: 9
Training loss: 1.9458303107075492
Validation loss: 2.0816423778630866
Epoch: 12| Step: 10
Training loss: 2.5050389053460553
Validation loss: 2.0789920552180323
Epoch: 12| Step: 11
Training loss: 2.7408891087353893
Validation loss: 2.160112337573821
Epoch: 12| Step: 12
Training loss: 2.8816256263800737
Validation loss: 2.1433197194761693
Epoch: 12| Step: 13
Training loss: 2.9970882908694234
Validation loss: 2.119512463195767
Epoch: 12| Step: 14
Training loss: 2.4594985872696187
Validation loss: 2.105776492133817
Epoch: 12| Step: 15
Training loss: 2.942825035999402
Validation loss: 2.1029219610073255
Epoch: 13| Step: 0
Training loss: 2.4847956847045922
Validation loss: 1.9939603997084323
Epoch: 13| Step: 1
Training loss: 2.4811526339474432
Validation loss: 2.0465760037556233
Epoch: 13| Step: 2
Training loss: 2.5183267242459366
Validation loss: 2.0995271252154186
Epoch: 13| Step: 3
Training loss: 2.2501516291071115
Validation loss: 2.086485697839747
Epoch: 13| Step: 4
Training loss: 2.704234430280103
Validation loss: 2.1384870352838505
Epoch: 13| Step: 5
Training loss: 2.676307793482757
Validation loss: 2.024916024920556
Epoch: 13| Step: 6
Training loss: 2.794504023785372
Validation loss: 2.060736076646816
Epoch: 13| Step: 7
Training loss: 2.791981257083361
Validation loss: 2.0366378505146483
Epoch: 13| Step: 8
Training loss: 2.4729822314557675
Validation loss: 2.0685633244895247
Epoch: 13| Step: 9
Training loss: 2.9283183649759246
Validation loss: 2.0646526577175894
Epoch: 13| Step: 10
Training loss: 2.765876025860466
Validation loss: 2.0975624587293917
Epoch: 13| Step: 11
Training loss: 2.3024260206898095
Validation loss: 2.16016407818876
Epoch: 13| Step: 12
Training loss: 2.4572155129821214
Validation loss: 2.102713142544524
Epoch: 13| Step: 13
Training loss: 2.670689727048813
Validation loss: 2.000816489671462
Epoch: 13| Step: 14
Training loss: 3.0683578209536164
Validation loss: 2.1245244596199933
Epoch: 13| Step: 15
Training loss: 2.6341395443714046
Validation loss: 2.0212801822252273
Epoch: 14| Step: 0
Training loss: 2.686146417451731
Validation loss: 2.1417952266912805
Epoch: 14| Step: 1
Training loss: 2.634438847212698
Validation loss: 2.0392177781216003
Epoch: 14| Step: 2
Training loss: 2.925100575861666
Validation loss: 2.148827356674753
Epoch: 14| Step: 3
Training loss: 2.576993381798165
Validation loss: 2.1431352415169376
Epoch: 14| Step: 4
Training loss: 2.7526629299410383
Validation loss: 2.1349930081980566
Epoch: 14| Step: 5
Training loss: 2.3607611216030953
Validation loss: 2.142204555413654
Epoch: 14| Step: 6
Training loss: 2.43011627829567
Validation loss: 2.0802223901830685
Epoch: 14| Step: 7
Training loss: 2.4250795882230975
Validation loss: 2.1432454386891813
Epoch: 14| Step: 8
Training loss: 3.1659681821418344
Validation loss: 2.0647833045310104
Epoch: 14| Step: 9
Training loss: 2.6242905520910664
Validation loss: 2.1100147292691633
Epoch: 14| Step: 10
Training loss: 2.387765707838817
Validation loss: 2.0404169362256774
Epoch: 14| Step: 11
Training loss: 2.8321272208954373
Validation loss: 2.1492892074717767
Epoch: 14| Step: 12
Training loss: 2.75047046798499
Validation loss: 2.114153708653508
Epoch: 14| Step: 13
Training loss: 2.601594941907801
Validation loss: 2.124232509377489
Epoch: 14| Step: 14
Training loss: 2.3668609494622523
Validation loss: 1.9951129437613175
Epoch: 14| Step: 15
Training loss: 2.3661718424339444
Validation loss: 2.079457021058032
Epoch: 15| Step: 0
Training loss: 2.285809076421322
Validation loss: 2.077810524538998
Epoch: 15| Step: 1
Training loss: 2.280463723323832
Validation loss: 2.068710251660607
Epoch: 15| Step: 2
Training loss: 2.6241747149185257
Validation loss: 2.034729369877874
Epoch: 15| Step: 3
Training loss: 2.898780658489061
Validation loss: 2.0295052313711284
Epoch: 15| Step: 4
Training loss: 2.8403570034063175
Validation loss: 2.0196398528228943
Epoch: 15| Step: 5
Training loss: 2.5253254822297126
Validation loss: 2.1222160478805097
Epoch: 15| Step: 6
Training loss: 3.204624327544256
Validation loss: 2.105764328604646
Epoch: 15| Step: 7
Training loss: 2.921537328781605
Validation loss: 2.0689153902108086
Epoch: 15| Step: 8
Training loss: 2.0624092544475285
Validation loss: 2.1413096887532137
Epoch: 15| Step: 9
Training loss: 2.625389251912954
Validation loss: 2.089594356587287
Epoch: 15| Step: 10
Training loss: 2.556102395867662
Validation loss: 2.144068272090602
Epoch: 15| Step: 11
Training loss: 2.2114731641844996
Validation loss: 2.171138002484581
Epoch: 15| Step: 12
Training loss: 2.8800566612074037
Validation loss: 2.0711872805789864
Epoch: 15| Step: 13
Training loss: 2.4242910823671067
Validation loss: 2.1318061877887287
Epoch: 15| Step: 14
Training loss: 2.7205205830105803
Validation loss: 2.055294930291565
Epoch: 15| Step: 15
Training loss: 2.828476520421322
Validation loss: 2.0379936655570727
Epoch: 16| Step: 0
Training loss: 3.089455755012947
Validation loss: 2.1514878307477048
Epoch: 16| Step: 1
Training loss: 2.4155608530151214
Validation loss: 2.1201961353875034
Epoch: 16| Step: 2
Training loss: 3.000242382430546
Validation loss: 2.1014543441498224
Epoch: 16| Step: 3
Training loss: 2.8662445430312715
Validation loss: 2.1033906315101465
Epoch: 16| Step: 4
Training loss: 2.7100753072712838
Validation loss: 2.0895600637936838
Epoch: 16| Step: 5
Training loss: 2.505482003748172
Validation loss: 2.108408255208366
Epoch: 16| Step: 6
Training loss: 2.4336153032502623
Validation loss: 2.1308524326418294
Epoch: 16| Step: 7
Training loss: 2.5574159197070094
Validation loss: 2.146221007840476
Epoch: 16| Step: 8
Training loss: 2.5539728967577253
Validation loss: 2.06921164224431
Epoch: 16| Step: 9
Training loss: 2.349021578076195
Validation loss: 2.1257242115998145
Epoch: 16| Step: 10
Training loss: 2.4899105564583235
Validation loss: 2.0852751100259477
Epoch: 16| Step: 11
Training loss: 2.0946826281086115
Validation loss: 2.096260202014306
Epoch: 16| Step: 12
Training loss: 2.7853422597696746
Validation loss: 2.099631084508333
Epoch: 16| Step: 13
Training loss: 2.6581200692503093
Validation loss: 2.110412270271637
Epoch: 16| Step: 14
Training loss: 2.755082289198921
Validation loss: 1.9700075510191928
Epoch: 16| Step: 15
Training loss: 2.6918739388638495
Validation loss: 2.0977587968104223
Epoch: 17| Step: 0
Training loss: 2.8245850216060067
Validation loss: 2.1279398299786796
Epoch: 17| Step: 1
Training loss: 2.7061974148123435
Validation loss: 2.0845707546090235
Epoch: 17| Step: 2
Training loss: 2.56929390154111
Validation loss: 2.0723171152321975
Epoch: 17| Step: 3
Training loss: 2.6843515628240078
Validation loss: 2.081309604921258
Epoch: 17| Step: 4
Training loss: 2.8085715090066006
Validation loss: 2.1146297885124565
Epoch: 17| Step: 5
Training loss: 2.736996511204161
Validation loss: 2.0540306909521875
Epoch: 17| Step: 6
Training loss: 2.8689428459955186
Validation loss: 2.131781723275913
Epoch: 17| Step: 7
Training loss: 2.5079498728742275
Validation loss: 2.0772376815775666
Epoch: 17| Step: 8
Training loss: 2.629706931084906
Validation loss: 2.0851076046128036
Epoch: 17| Step: 9
Training loss: 2.5845627371741076
Validation loss: 2.0416233652644955
Epoch: 17| Step: 10
Training loss: 2.5860439866375002
Validation loss: 2.1576354807511158
Epoch: 17| Step: 11
Training loss: 2.271425805685685
Validation loss: 2.0661182955105803
Epoch: 17| Step: 12
Training loss: 2.5691481158782574
Validation loss: 2.047913275684744
Epoch: 17| Step: 13
Training loss: 2.360473074131012
Validation loss: 1.9977864375347554
Epoch: 17| Step: 14
Training loss: 2.851730717962086
Validation loss: 2.039932394339901
Epoch: 17| Step: 15
Training loss: 2.636168743272208
Validation loss: 2.171479681015892
Epoch: 18| Step: 0
Training loss: 2.4426535876116913
Validation loss: 2.0784169210010863
Epoch: 18| Step: 1
Training loss: 2.6070741114352445
Validation loss: 2.1253147738797433
Epoch: 18| Step: 2
Training loss: 2.231559313109563
Validation loss: 2.0461900727694817
Epoch: 18| Step: 3
Training loss: 2.5440079166960943
Validation loss: 2.1104109856873627
Epoch: 18| Step: 4
Training loss: 2.714656598343505
Validation loss: 2.125291956077604
Epoch: 18| Step: 5
Training loss: 2.22260207929786
Validation loss: 2.095708259874985
Epoch: 18| Step: 6
Training loss: 2.949982277768453
Validation loss: 2.1220288524838526
Epoch: 18| Step: 7
Training loss: 2.5437444625906696
Validation loss: 2.1352084242181273
Epoch: 18| Step: 8
Training loss: 2.9251595869300515
Validation loss: 2.008159645967703
Epoch: 18| Step: 9
Training loss: 3.1008119996329784
Validation loss: 2.07075318299617
Epoch: 18| Step: 10
Training loss: 2.2747559804312667
Validation loss: 2.0427785167469588
Epoch: 18| Step: 11
Training loss: 2.4512186600677044
Validation loss: 2.1336027419645025
Epoch: 18| Step: 12
Training loss: 2.5290657320783207
Validation loss: 2.0986750698195515
Epoch: 18| Step: 13
Training loss: 2.9309032308273366
Validation loss: 2.1142736085844036
Epoch: 18| Step: 14
Training loss: 2.85555341310664
Validation loss: 2.061563609096107
Epoch: 18| Step: 15
Training loss: 2.6742623354864543
Validation loss: 2.0862856850326423
Epoch: 19| Step: 0
Training loss: 2.5728793328133874
Validation loss: 2.0524630179133716
Epoch: 19| Step: 1
Training loss: 2.835827197407255
Validation loss: 2.1093259983978148
Epoch: 19| Step: 2
Training loss: 2.583154385019072
Validation loss: 2.06634605789641
Epoch: 19| Step: 3
Training loss: 2.7604029433191206
Validation loss: 2.1201703005134713
Epoch: 19| Step: 4
Training loss: 2.5712206317446533
Validation loss: 2.039661144542444
Epoch: 19| Step: 5
Training loss: 2.4780398995217623
Validation loss: 2.099919177673351
Epoch: 19| Step: 6
Training loss: 2.3156794779723184
Validation loss: 2.1112061360451317
Epoch: 19| Step: 7
Training loss: 2.3209807079192197
Validation loss: 2.088010782750659
Epoch: 19| Step: 8
Training loss: 2.3208226115209083
Validation loss: 2.08778106675333
Epoch: 19| Step: 9
Training loss: 2.369334339546644
Validation loss: 2.039122057796663
Epoch: 19| Step: 10
Training loss: 2.6467814711582998
Validation loss: 2.121005495034083
Epoch: 19| Step: 11
Training loss: 2.8478849761323355
Validation loss: 2.0558806454214182
Epoch: 19| Step: 12
Training loss: 3.2528440795737605
Validation loss: 2.07413893910363
Epoch: 19| Step: 13
Training loss: 2.8950114192968024
Validation loss: 2.1002241130715635
Epoch: 19| Step: 14
Training loss: 2.511931652105091
Validation loss: 2.092440900095878
Epoch: 19| Step: 15
Training loss: 2.6939097416858826
Validation loss: 2.092094278280921
Epoch: 20| Step: 0
Training loss: 2.671105346475997
Validation loss: 2.0842751998902025
Epoch: 20| Step: 1
Training loss: 2.1395628584266206
Validation loss: 2.1337470863739196
Epoch: 20| Step: 2
Training loss: 2.246654142048654
Validation loss: 2.1221716813281954
Epoch: 20| Step: 3
Training loss: 2.6514566592580904
Validation loss: 2.0633573966875782
Epoch: 20| Step: 4
Training loss: 2.647004856855997
Validation loss: 2.1220066271944815
Epoch: 20| Step: 5
Training loss: 2.242690186191627
Validation loss: 2.112311025792975
Epoch: 20| Step: 6
Training loss: 3.0946566091415404
Validation loss: 2.028893638946878
Epoch: 20| Step: 7
Training loss: 2.9576004266657585
Validation loss: 2.0647930613146404
Epoch: 20| Step: 8
Training loss: 2.600011689820053
Validation loss: 2.0630468000362208
Epoch: 20| Step: 9
Training loss: 2.5586630775435766
Validation loss: 2.077020123728085
Epoch: 20| Step: 10
Training loss: 2.6013772801171156
Validation loss: 2.0495731351022246
Epoch: 20| Step: 11
Training loss: 2.2418413592862225
Validation loss: 2.0638161268656408
Epoch: 20| Step: 12
Training loss: 2.9922026392302223
Validation loss: 2.026324700791035
Epoch: 20| Step: 13
Training loss: 2.7157089062404753
Validation loss: 2.111257203453061
Epoch: 20| Step: 14
Training loss: 2.666833772986554
Validation loss: 2.054037664964209
Epoch: 20| Step: 15
Training loss: 2.9772829800812426
Validation loss: 2.149090099762615
Epoch: 21| Step: 0
Training loss: 2.7200611504524908
Validation loss: 2.031290950455453
Epoch: 21| Step: 1
Training loss: 2.8191589363331193
Validation loss: 2.13331538364748
Epoch: 21| Step: 2
Training loss: 2.595494889861492
Validation loss: 2.053327503197405
Epoch: 21| Step: 3
Training loss: 2.1713974242378606
Validation loss: 2.1057489490621637
Epoch: 21| Step: 4
Training loss: 2.5268349467010847
Validation loss: 2.1041444993213294
Epoch: 21| Step: 5
Training loss: 2.467848021478774
Validation loss: 2.01438060056893
Epoch: 21| Step: 6
Training loss: 3.047953097025123
Validation loss: 2.1340306880630435
Epoch: 21| Step: 7
Training loss: 2.2713477109172784
Validation loss: 2.1260577305683364
Epoch: 21| Step: 8
Training loss: 2.627628100726962
Validation loss: 2.128386815083336
Epoch: 21| Step: 9
Training loss: 2.6000256280369576
Validation loss: 2.1269918630110003
Epoch: 21| Step: 10
Training loss: 2.782737591274479
Validation loss: 2.0726374353850208
Epoch: 21| Step: 11
Training loss: 2.607876101587357
Validation loss: 2.0452041944119723
Epoch: 21| Step: 12
Training loss: 2.373688888044375
Validation loss: 2.1198889109598227
Epoch: 21| Step: 13
Training loss: 2.399535086424336
Validation loss: 2.0905291378727484
Epoch: 21| Step: 14
Training loss: 2.843043983765979
Validation loss: 2.029997732976056
Epoch: 21| Step: 15
Training loss: 3.1627387397727893
Validation loss: 2.00448896846463
Epoch: 22| Step: 0
Training loss: 2.9058176354816676
Validation loss: 2.0691563458551085
Epoch: 22| Step: 1
Training loss: 2.6159653272459997
Validation loss: 2.0469048705029227
Epoch: 22| Step: 2
Training loss: 2.4177870181415884
Validation loss: 2.104517839362902
Epoch: 22| Step: 3
Training loss: 2.449033885349105
Validation loss: 2.083484315743185
Epoch: 22| Step: 4
Training loss: 2.370823249281459
Validation loss: 2.07282480304999
Epoch: 22| Step: 5
Training loss: 2.7959564234949226
Validation loss: 2.026036162654962
Epoch: 22| Step: 6
Training loss: 2.6007921149318247
Validation loss: 2.1136035435667386
Epoch: 22| Step: 7
Training loss: 2.654589324626669
Validation loss: 2.132286769545274
Epoch: 22| Step: 8
Training loss: 2.705102538952329
Validation loss: 2.146911512353905
Epoch: 22| Step: 9
Training loss: 2.8188714654638214
Validation loss: 2.0935093188794704
Epoch: 22| Step: 10
Training loss: 2.6102496297437985
Validation loss: 2.116047335105623
Epoch: 22| Step: 11
Training loss: 2.6514372364998384
Validation loss: 2.085755491453368
Epoch: 22| Step: 12
Training loss: 2.0948895442131583
Validation loss: 2.0668725069933007
Epoch: 22| Step: 13
Training loss: 2.5988422640540993
Validation loss: 2.0803330243180125
Epoch: 22| Step: 14
Training loss: 2.6537552730815173
Validation loss: 2.08558756726743
Epoch: 22| Step: 15
Training loss: 3.0894489638951304
Validation loss: 2.1176259828665907
Epoch: 23| Step: 0
Training loss: 2.5212268889941964
Validation loss: 2.065770295888714
Epoch: 23| Step: 1
Training loss: 2.3008439423029707
Validation loss: 2.076318994456286
Epoch: 23| Step: 2
Training loss: 2.4466528585842946
Validation loss: 2.1085060847341928
Epoch: 23| Step: 3
Training loss: 2.5250345850927087
Validation loss: 2.1561490518972892
Epoch: 23| Step: 4
Training loss: 2.758810062834894
Validation loss: 2.09437777588856
Epoch: 23| Step: 5
Training loss: 2.464410952432297
Validation loss: 2.1152403184168347
Epoch: 23| Step: 6
Training loss: 2.42759688241997
Validation loss: 2.1016600497923283
Epoch: 23| Step: 7
Training loss: 2.3539365020134837
Validation loss: 2.0617310302776635
Epoch: 23| Step: 8
Training loss: 2.5925292853795376
Validation loss: 1.997834246862686
Epoch: 23| Step: 9
Training loss: 2.9852640315717136
Validation loss: 2.0736569711089206
Epoch: 23| Step: 10
Training loss: 2.5367238704064623
Validation loss: 2.116282812179598
Epoch: 23| Step: 11
Training loss: 3.0222641987160586
Validation loss: 2.0929471829499646
Epoch: 23| Step: 12
Training loss: 2.6585068035228803
Validation loss: 2.105211424395706
Epoch: 23| Step: 13
Training loss: 2.863840420651272
Validation loss: 2.1451626428799035
Epoch: 23| Step: 14
Training loss: 2.820507095682341
Validation loss: 2.090263754498762
Epoch: 23| Step: 15
Training loss: 2.7396529349610192
Validation loss: 2.0828305808448633
Epoch: 24| Step: 0
Training loss: 2.277943239430933
Validation loss: 2.092563052250041
Epoch: 24| Step: 1
Training loss: 2.321376980218756
Validation loss: 2.1602174288012197
Epoch: 24| Step: 2
Training loss: 2.477574860551388
Validation loss: 2.044129680004675
Epoch: 24| Step: 3
Training loss: 2.0424428230042815
Validation loss: 2.0362756326774405
Epoch: 24| Step: 4
Training loss: 2.8315292860642205
Validation loss: 2.112617312625908
Epoch: 24| Step: 5
Training loss: 2.302004943709778
Validation loss: 2.0892272667620095
Epoch: 24| Step: 6
Training loss: 2.8829246437156093
Validation loss: 2.1052701782368466
Epoch: 24| Step: 7
Training loss: 2.88778266348904
Validation loss: 2.098067790249103
Epoch: 24| Step: 8
Training loss: 2.4059559035473725
Validation loss: 2.0602538918239244
Epoch: 24| Step: 9
Training loss: 2.8716093884860983
Validation loss: 2.0895800923510235
Epoch: 24| Step: 10
Training loss: 2.812233636746585
Validation loss: 2.1535863716467754
Epoch: 24| Step: 11
Training loss: 2.474646467910881
Validation loss: 2.086705174204343
Epoch: 24| Step: 12
Training loss: 2.506777540893162
Validation loss: 2.105323773832781
Epoch: 24| Step: 13
Training loss: 2.5180068971571266
Validation loss: 2.1137871811054514
Epoch: 24| Step: 14
Training loss: 3.119518355092855
Validation loss: 2.063175752058811
Epoch: 24| Step: 15
Training loss: 3.1254687148490223
Validation loss: 2.06957405344845
Epoch: 25| Step: 0
Training loss: 2.6395767207816823
Validation loss: 2.1456591844193746
Epoch: 25| Step: 1
Training loss: 2.7926659479924227
Validation loss: 2.1085087526203363
Epoch: 25| Step: 2
Training loss: 2.6189276987752743
Validation loss: 2.1658027984428734
Epoch: 25| Step: 3
Training loss: 2.6462959926322185
Validation loss: 2.0406703438575864
Epoch: 25| Step: 4
Training loss: 2.6479182001485118
Validation loss: 2.077671052404292
Epoch: 25| Step: 5
Training loss: 2.8478930130269045
Validation loss: 2.04351442892681
Epoch: 25| Step: 6
Training loss: 2.5797473773442055
Validation loss: 2.0761602026355335
Epoch: 25| Step: 7
Training loss: 2.9831770644648667
Validation loss: 2.1430439367999714
Epoch: 25| Step: 8
Training loss: 2.4516253899117046
Validation loss: 2.099243190721871
Epoch: 25| Step: 9
Training loss: 2.373850293202706
Validation loss: 2.1379500909568008
Epoch: 25| Step: 10
Training loss: 2.5161011997423652
Validation loss: 2.158727625847051
Epoch: 25| Step: 11
Training loss: 2.2320698404631245
Validation loss: 2.0516794131161444
Epoch: 25| Step: 12
Training loss: 2.870947095797426
Validation loss: 2.1107138113285036
Epoch: 25| Step: 13
Training loss: 2.6241567256283305
Validation loss: 2.1002258145728665
Epoch: 25| Step: 14
Training loss: 2.6703380603582576
Validation loss: 2.0126925237423485
Epoch: 25| Step: 15
Training loss: 2.6050868633819833
Validation loss: 2.169964750875574
Epoch: 26| Step: 0
Training loss: 3.183922499082472
Validation loss: 2.0473009625134804
Epoch: 26| Step: 1
Training loss: 2.7113467740295647
Validation loss: 2.1195863788126896
Epoch: 26| Step: 2
Training loss: 2.9160251093491105
Validation loss: 2.099566735172711
Epoch: 26| Step: 3
Training loss: 3.103919375680151
Validation loss: 2.158863108200807
Epoch: 26| Step: 4
Training loss: 2.1821146478227664
Validation loss: 2.0218917209185348
Epoch: 26| Step: 5
Training loss: 2.620729151011028
Validation loss: 2.139783043443455
Epoch: 26| Step: 6
Training loss: 2.0040737624917435
Validation loss: 2.0617939793706674
Epoch: 26| Step: 7
Training loss: 3.0372120536300753
Validation loss: 2.191526258836585
Epoch: 26| Step: 8
Training loss: 2.5767740120021085
Validation loss: 2.0943366658427003
Epoch: 26| Step: 9
Training loss: 2.5592163260322827
Validation loss: 2.0825142916059662
Epoch: 26| Step: 10
Training loss: 2.6457641071865163
Validation loss: 2.0741595600460148
Epoch: 26| Step: 11
Training loss: 2.010342795904086
Validation loss: 2.0504266646714218
Epoch: 26| Step: 12
Training loss: 2.4591423147562756
Validation loss: 2.1107648235398693
Epoch: 26| Step: 13
Training loss: 2.555585044423489
Validation loss: 2.0096654019858335
Epoch: 26| Step: 14
Training loss: 2.688454835404169
Validation loss: 2.1557751061004837
Epoch: 26| Step: 15
Training loss: 2.6356276677719483
Validation loss: 2.1014426904313384
Epoch: 27| Step: 0
Training loss: 2.3288876097354496
Validation loss: 2.1879038805665334
Epoch: 27| Step: 1
Training loss: 2.374476023646341
Validation loss: 2.034184371764703
Epoch: 27| Step: 2
Training loss: 2.4330683794741113
Validation loss: 2.0684179123877326
Epoch: 27| Step: 3
Training loss: 1.9729356624517254
Validation loss: 2.0897741381332926
Epoch: 27| Step: 4
Training loss: 2.7556570994046976
Validation loss: 2.0770758669510845
Epoch: 27| Step: 5
Training loss: 2.697453541324666
Validation loss: 2.09038034363077
Epoch: 27| Step: 6
Training loss: 2.21213307759518
Validation loss: 2.1422496660934
Epoch: 27| Step: 7
Training loss: 2.786325688042184
Validation loss: 2.036816713329472
Epoch: 27| Step: 8
Training loss: 2.76143609182715
Validation loss: 2.0595363847415555
Epoch: 27| Step: 9
Training loss: 2.519963568923645
Validation loss: 2.11289904216058
Epoch: 27| Step: 10
Training loss: 3.271012238552204
Validation loss: 2.084591120299596
Epoch: 27| Step: 11
Training loss: 2.7141237031298173
Validation loss: 2.1505172498566605
Epoch: 27| Step: 12
Training loss: 3.0711265047898713
Validation loss: 2.1419983426688725
Epoch: 27| Step: 13
Training loss: 2.709784974579989
Validation loss: 2.0721408890422386
Epoch: 27| Step: 14
Training loss: 2.7486846552459188
Validation loss: 2.102819860074548
Epoch: 27| Step: 15
Training loss: 2.6288473000796815
Validation loss: 2.1614550878223024
Epoch: 28| Step: 0
Training loss: 2.2758053119302755
Validation loss: 2.0101565858869668
Epoch: 28| Step: 1
Training loss: 2.471931725006676
Validation loss: 2.068666552398987
Epoch: 28| Step: 2
Training loss: 2.603001285466197
Validation loss: 2.0647386754503096
Epoch: 28| Step: 3
Training loss: 2.3864700012943043
Validation loss: 2.1004404760833473
Epoch: 28| Step: 4
Training loss: 2.624575626038784
Validation loss: 2.069661519961167
Epoch: 28| Step: 5
Training loss: 2.973393392711813
Validation loss: 2.0855500379430274
Epoch: 28| Step: 6
Training loss: 2.807607252020464
Validation loss: 2.078469100838261
Epoch: 28| Step: 7
Training loss: 2.62198338426669
Validation loss: 2.070708388887116
Epoch: 28| Step: 8
Training loss: 2.6776732946284008
Validation loss: 2.0985072252828796
Epoch: 28| Step: 9
Training loss: 2.8944622242634277
Validation loss: 2.03856304906552
Epoch: 28| Step: 10
Training loss: 2.486657587534239
Validation loss: 2.0577880838853506
Epoch: 28| Step: 11
Training loss: 3.1390662429202423
Validation loss: 2.0909049383288005
Epoch: 28| Step: 12
Training loss: 1.866230994994582
Validation loss: 2.078077348363949
Epoch: 28| Step: 13
Training loss: 3.0303878344604827
Validation loss: 2.0989307954231884
Epoch: 28| Step: 14
Training loss: 2.129376784655039
Validation loss: 2.1249851252047836
Epoch: 28| Step: 15
Training loss: 2.826162595278908
Validation loss: 2.036671039962229
Epoch: 29| Step: 0
Training loss: 2.9700423790576522
Validation loss: 2.084430048690079
Epoch: 29| Step: 1
Training loss: 2.607640037982234
Validation loss: 2.1220162653052825
Epoch: 29| Step: 2
Training loss: 2.3585351118523405
Validation loss: 2.0837341903400137
Epoch: 29| Step: 3
Training loss: 2.558728489713167
Validation loss: 2.0376082836937925
Epoch: 29| Step: 4
Training loss: 2.425007228250644
Validation loss: 2.0573707895641733
Epoch: 29| Step: 5
Training loss: 2.8569744435129674
Validation loss: 2.0334457665084087
Epoch: 29| Step: 6
Training loss: 2.225480844209978
Validation loss: 2.0446464888677016
Epoch: 29| Step: 7
Training loss: 2.8442489689311
Validation loss: 2.1191497235157892
Epoch: 29| Step: 8
Training loss: 2.5635653816458244
Validation loss: 2.065524285217713
Epoch: 29| Step: 9
Training loss: 2.471205347455612
Validation loss: 2.061194034233797
Epoch: 29| Step: 10
Training loss: 2.8838680991539594
Validation loss: 2.1257814560497494
Epoch: 29| Step: 11
Training loss: 2.573219209456231
Validation loss: 2.093921996390513
Epoch: 29| Step: 12
Training loss: 2.4058108238626836
Validation loss: 2.051380934832316
Epoch: 29| Step: 13
Training loss: 2.584401115091801
Validation loss: 2.0504420938382113
Epoch: 29| Step: 14
Training loss: 3.0217548587116494
Validation loss: 1.932053881284266
Epoch: 29| Step: 15
Training loss: 2.7579671584035
Validation loss: 2.1079918101838744
Epoch: 30| Step: 0
Training loss: 2.800663859143114
Validation loss: 2.053957220188893
Epoch: 30| Step: 1
Training loss: 2.8681291494300005
Validation loss: 2.130943410843009
Epoch: 30| Step: 2
Training loss: 2.856017095306266
Validation loss: 2.066555154831326
Epoch: 30| Step: 3
Training loss: 2.6793546330874927
Validation loss: 2.129369241956226
Epoch: 30| Step: 4
Training loss: 2.279528451643679
Validation loss: 2.1221548687400116
Epoch: 30| Step: 5
Training loss: 2.249039974971765
Validation loss: 2.0870201507313877
Epoch: 30| Step: 6
Training loss: 2.8693005002470153
Validation loss: 2.0557670268801673
Epoch: 30| Step: 7
Training loss: 2.6387924065157264
Validation loss: 2.1000339989963184
Epoch: 30| Step: 8
Training loss: 2.6399312208348396
Validation loss: 2.0503201122541532
Epoch: 30| Step: 9
Training loss: 2.99595050892105
Validation loss: 2.1319890890097133
Epoch: 30| Step: 10
Training loss: 2.4797104524969558
Validation loss: 2.024254094225066
Epoch: 30| Step: 11
Training loss: 2.7055015921079555
Validation loss: 2.084410338467586
Epoch: 30| Step: 12
Training loss: 2.5727287460663595
Validation loss: 2.077241146836856
Epoch: 30| Step: 13
Training loss: 2.904853074893591
Validation loss: 2.0788717324140515
Epoch: 30| Step: 14
Training loss: 2.347051914013142
Validation loss: 1.9885480049398847
Epoch: 30| Step: 15
Training loss: 2.1593257694180608
Validation loss: 2.1258298907643507
