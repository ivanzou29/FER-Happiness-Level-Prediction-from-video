Epoch: 1| Step: 0
Training loss: 5.7976037567316
Validation loss: 6.0312509861316865
Epoch: 1| Step: 1
Training loss: 5.742981649484731
Validation loss: 5.686032923497857
Epoch: 1| Step: 2
Training loss: 6.219689686384834
Validation loss: 5.826700004280609
Epoch: 1| Step: 3
Training loss: 5.226901877294358
Validation loss: 5.759809726408616
Epoch: 1| Step: 4
Training loss: 5.876864198396666
Validation loss: 5.704699611222246
Epoch: 1| Step: 5
Training loss: 5.742624611339123
Validation loss: 5.576203774564208
Epoch: 1| Step: 6
Training loss: 6.6382776756676565
Validation loss: 5.614750210196824
Epoch: 1| Step: 7
Training loss: 5.850515763459349
Validation loss: 5.504264244043989
Epoch: 1| Step: 8
Training loss: 5.879320868892472
Validation loss: 5.3616606247731475
Epoch: 1| Step: 9
Training loss: 5.711479526582264
Validation loss: 5.261529748216937
Epoch: 1| Step: 10
Training loss: 7.429508307348801
Validation loss: 5.052791654080729
Epoch: 1| Step: 11
Training loss: 6.291303342050773
Validation loss: 4.846399311925282
Epoch: 1| Step: 12
Training loss: 4.072235180491713
Validation loss: 4.716064304643664
Epoch: 1| Step: 13
Training loss: 5.387921791647514
Validation loss: 4.59821403677414
Epoch: 1| Step: 14
Training loss: 4.334244461129082
Validation loss: 4.5741823189250255
Epoch: 1| Step: 15
Training loss: 4.740822006286261
Validation loss: 4.417630714226834
Epoch: 1| Step: 16
Training loss: 4.918892868274379
Validation loss: 4.461817622074546
Epoch: 1| Step: 17
Training loss: 4.460042085320724
Validation loss: 4.313139605781036
Epoch: 1| Step: 18
Training loss: 5.398127457235116
Validation loss: 4.325081250558742
Epoch: 1| Step: 19
Training loss: 3.5476293895908393
Validation loss: 4.253569138339904
Epoch: 2| Step: 0
Training loss: 4.258063800640176
Validation loss: 4.094392391698014
Epoch: 2| Step: 1
Training loss: 3.7341387685970706
Validation loss: 4.1185779989126825
Epoch: 2| Step: 2
Training loss: 3.8378057650048922
Validation loss: 4.082626706359429
Epoch: 2| Step: 3
Training loss: 5.287565890142887
Validation loss: 3.9804437313532235
Epoch: 2| Step: 4
Training loss: 4.074853512992062
Validation loss: 3.9852537609131966
Epoch: 2| Step: 5
Training loss: 4.0151777797688375
Validation loss: 3.8701254301357126
Epoch: 2| Step: 6
Training loss: 4.989319074265455
Validation loss: 3.7874960658510224
Epoch: 2| Step: 7
Training loss: 3.8084611605526435
Validation loss: 3.7238749737400383
Epoch: 2| Step: 8
Training loss: 4.738480905727627
Validation loss: 3.7864475125554664
Epoch: 2| Step: 9
Training loss: 4.023476846743286
Validation loss: 3.6749391849137987
Epoch: 2| Step: 10
Training loss: 4.242793761711609
Validation loss: 3.552465047130208
Epoch: 2| Step: 11
Training loss: 4.304951349885145
Validation loss: 3.5849686683689805
Epoch: 2| Step: 12
Training loss: 4.165211359822821
Validation loss: 3.516097535860421
Epoch: 2| Step: 13
Training loss: 3.7897384827101175
Validation loss: 3.4641816613894574
Epoch: 2| Step: 14
Training loss: 3.7014792604052182
Validation loss: 3.3648757535122416
Epoch: 2| Step: 15
Training loss: 3.2474657595197103
Validation loss: 3.4462829316455705
Epoch: 2| Step: 16
Training loss: 4.156016407762582
Validation loss: 3.2813606161858546
Epoch: 2| Step: 17
Training loss: 3.2360116254788664
Validation loss: 3.2813034518936237
Epoch: 2| Step: 18
Training loss: 3.96506106528056
Validation loss: 3.174241506953682
Epoch: 2| Step: 19
Training loss: 4.076204629719858
Validation loss: 3.141535336275427
Epoch: 3| Step: 0
Training loss: 3.6451181346027677
Validation loss: 3.0907800093012345
Epoch: 3| Step: 1
Training loss: 3.5551186101041945
Validation loss: 3.068907263474568
Epoch: 3| Step: 2
Training loss: 3.8710825407017957
Validation loss: 2.9399217936707034
Epoch: 3| Step: 3
Training loss: 3.3646341010988614
Validation loss: 2.9292301868420103
Epoch: 3| Step: 4
Training loss: 2.766041783539235
Validation loss: 2.9648046514907325
Epoch: 3| Step: 5
Training loss: 3.4206774980840327
Validation loss: 2.8786811006055775
Epoch: 3| Step: 6
Training loss: 3.6817864588988134
Validation loss: 2.90309967323443
Epoch: 3| Step: 7
Training loss: 3.109094961773159
Validation loss: 2.809107360606781
Epoch: 3| Step: 8
Training loss: 2.785267788872589
Validation loss: 2.876152607508762
Epoch: 3| Step: 9
Training loss: 3.8803346890692736
Validation loss: 2.7071985498468347
Epoch: 3| Step: 10
Training loss: 3.4789417826141973
Validation loss: 2.618346659467961
Epoch: 3| Step: 11
Training loss: 2.9626934712648376
Validation loss: 2.6882667944783845
Epoch: 3| Step: 12
Training loss: 2.8110938053662244
Validation loss: 2.676350693755983
Epoch: 3| Step: 13
Training loss: 3.137258214867002
Validation loss: 2.674967440024969
Epoch: 3| Step: 14
Training loss: 3.5076955932982754
Validation loss: 2.6269188120466236
Epoch: 3| Step: 15
Training loss: 3.26781583606542
Validation loss: 2.572947612171059
Epoch: 3| Step: 16
Training loss: 3.255245523876092
Validation loss: 2.5832290609758077
Epoch: 3| Step: 17
Training loss: 3.179212080071608
Validation loss: 2.5674209564210995
Epoch: 3| Step: 18
Training loss: 3.406338471829828
Validation loss: 2.5241250244651767
Epoch: 3| Step: 19
Training loss: 2.7959505396767312
Validation loss: 2.5074144498289073
Epoch: 4| Step: 0
Training loss: 3.024611292053506
Validation loss: 2.450697878040744
Epoch: 4| Step: 1
Training loss: 3.12057639788769
Validation loss: 2.470390113438434
Epoch: 4| Step: 2
Training loss: 3.46931769047269
Validation loss: 2.4515195272219317
Epoch: 4| Step: 3
Training loss: 3.0488504901385802
Validation loss: 2.4034744918981494
Epoch: 4| Step: 4
Training loss: 3.004811084921462
Validation loss: 2.392262300998926
Epoch: 4| Step: 5
Training loss: 3.0103900912650694
Validation loss: 2.394722904410999
Epoch: 4| Step: 6
Training loss: 2.7344791065561087
Validation loss: 2.3590699645033544
Epoch: 4| Step: 7
Training loss: 2.246782333309456
Validation loss: 2.305007252135084
Epoch: 4| Step: 8
Training loss: 3.1174169470301627
Validation loss: 2.2883173679692597
Epoch: 4| Step: 9
Training loss: 2.5802359521892035
Validation loss: 2.2944977294285174
Epoch: 4| Step: 10
Training loss: 2.5316303108757454
Validation loss: 2.2485918447969278
Epoch: 4| Step: 11
Training loss: 3.259545320502713
Validation loss: 2.2875671925664873
Epoch: 4| Step: 12
Training loss: 2.885680883179202
Validation loss: 2.251075061679504
Epoch: 4| Step: 13
Training loss: 3.1764721558760223
Validation loss: 2.25181163774279
Epoch: 4| Step: 14
Training loss: 3.007689158895594
Validation loss: 2.2343149944188543
Epoch: 4| Step: 15
Training loss: 2.679163578520123
Validation loss: 2.2224692349160504
Epoch: 4| Step: 16
Training loss: 2.712958206642253
Validation loss: 2.2137757874350648
Epoch: 4| Step: 17
Training loss: 3.0741579469050597
Validation loss: 2.1803033307884814
Epoch: 4| Step: 18
Training loss: 2.487303728957903
Validation loss: 2.1719555856863573
Epoch: 4| Step: 19
Training loss: 2.604198689581756
Validation loss: 2.161795525268797
Epoch: 5| Step: 0
Training loss: 2.335690896786651
Validation loss: 2.1493736435033686
Epoch: 5| Step: 1
Training loss: 2.902035682727006
Validation loss: 2.162723353560733
Epoch: 5| Step: 2
Training loss: 2.4931571772084715
Validation loss: 2.152347857830075
Epoch: 5| Step: 3
Training loss: 2.971465304561603
Validation loss: 2.1150007282916348
Epoch: 5| Step: 4
Training loss: 2.6841781846037867
Validation loss: 2.136875241638451
Epoch: 5| Step: 5
Training loss: 3.4220788624971665
Validation loss: 2.1591976894820455
Epoch: 5| Step: 6
Training loss: 2.4891167260613254
Validation loss: 2.1447888302868723
Epoch: 5| Step: 7
Training loss: 2.8541244912105928
Validation loss: 2.1278317763026657
Epoch: 5| Step: 8
Training loss: 2.2133336107797716
Validation loss: 2.1362821494589457
Epoch: 5| Step: 9
Training loss: 2.5641769876438723
Validation loss: 2.1476922586443097
Epoch: 5| Step: 10
Training loss: 2.670694547747946
Validation loss: 2.149209326259326
Epoch: 5| Step: 11
Training loss: 2.6899759287271228
Validation loss: 2.0842042355771526
Epoch: 5| Step: 12
Training loss: 3.245261479262745
Validation loss: 2.087396256790756
Epoch: 5| Step: 13
Training loss: 2.63807799166596
Validation loss: 2.064195200376079
Epoch: 5| Step: 14
Training loss: 3.1523879188742705
Validation loss: 2.0820132537850666
Epoch: 5| Step: 15
Training loss: 2.8288411450841657
Validation loss: 2.087688791651665
Epoch: 5| Step: 16
Training loss: 2.1820556464437946
Validation loss: 2.1101898185492187
Epoch: 5| Step: 17
Training loss: 2.786190830593343
Validation loss: 2.0955882281303237
Epoch: 5| Step: 18
Training loss: 2.2801224521747994
Validation loss: 2.118259473016832
Epoch: 5| Step: 19
Training loss: 2.246791989805216
Validation loss: 2.054127926898931
Epoch: 6| Step: 0
Training loss: 2.1756696963520246
Validation loss: 2.0915202048482815
Epoch: 6| Step: 1
Training loss: 2.6908769017773366
Validation loss: 2.111684657750787
Epoch: 6| Step: 2
Training loss: 2.331827586112966
Validation loss: 2.1134895107660023
Epoch: 6| Step: 3
Training loss: 2.636568463598969
Validation loss: 2.045505404751373
Epoch: 6| Step: 4
Training loss: 2.8982591599867784
Validation loss: 2.0974442897436933
Epoch: 6| Step: 5
Training loss: 2.4064050599707
Validation loss: 2.0726576946849704
Epoch: 6| Step: 6
Training loss: 2.9403025467572697
Validation loss: 2.0146642380444613
Epoch: 6| Step: 7
Training loss: 2.559222381475564
Validation loss: 2.0834785910204263
Epoch: 6| Step: 8
Training loss: 2.46130213382464
Validation loss: 2.0993340418761064
Epoch: 6| Step: 9
Training loss: 2.320680531300449
Validation loss: 2.0768092216052505
Epoch: 6| Step: 10
Training loss: 2.6522068443415416
Validation loss: 2.090395746500711
Epoch: 6| Step: 11
Training loss: 3.3501821667690117
Validation loss: 2.0644034901477712
Epoch: 6| Step: 12
Training loss: 2.5119406689604435
Validation loss: 2.0732159126090846
Epoch: 6| Step: 13
Training loss: 2.840160409937228
Validation loss: 2.0834448016841423
Epoch: 6| Step: 14
Training loss: 2.1339058222130967
Validation loss: 2.070376765336552
Epoch: 6| Step: 15
Training loss: 2.624290097837631
Validation loss: 2.107185583265207
Epoch: 6| Step: 16
Training loss: 2.513333621678559
Validation loss: 2.125315737636604
Epoch: 6| Step: 17
Training loss: 2.798084189445626
Validation loss: 2.0829760965823056
Epoch: 6| Step: 18
Training loss: 2.9224774560638056
Validation loss: 2.022945003812289
Epoch: 6| Step: 19
Training loss: 2.91792511811631
Validation loss: 2.041670362286493
Epoch: 7| Step: 0
Training loss: 3.0180407715730007
Validation loss: 2.057143863919137
Epoch: 7| Step: 1
Training loss: 3.1985284342322617
Validation loss: 2.0647337564361976
Epoch: 7| Step: 2
Training loss: 2.9137821829715147
Validation loss: 2.0695003263923804
Epoch: 7| Step: 3
Training loss: 2.4088852559050924
Validation loss: 2.126812658184438
Epoch: 7| Step: 4
Training loss: 2.96744484571382
Validation loss: 2.045611975903996
Epoch: 7| Step: 5
Training loss: 2.527559014752985
Validation loss: 2.0602524922175274
Epoch: 7| Step: 6
Training loss: 2.4519518337030615
Validation loss: 2.138978841894851
Epoch: 7| Step: 7
Training loss: 2.5998549714354375
Validation loss: 2.0316212779231635
Epoch: 7| Step: 8
Training loss: 2.6625034994899335
Validation loss: 2.0778916043105453
Epoch: 7| Step: 9
Training loss: 2.49249323102669
Validation loss: 2.0100941427817745
Epoch: 7| Step: 10
Training loss: 2.344869422611916
Validation loss: 2.0732672388035764
Epoch: 7| Step: 11
Training loss: 2.465727102198678
Validation loss: 1.982968682007849
Epoch: 7| Step: 12
Training loss: 2.692737443915395
Validation loss: 2.060381317223303
Epoch: 7| Step: 13
Training loss: 2.6487437383443604
Validation loss: 2.1156590148967376
Epoch: 7| Step: 14
Training loss: 2.4915041569646967
Validation loss: 2.07645652360497
Epoch: 7| Step: 15
Training loss: 3.107086719826385
Validation loss: 2.1002792180246503
Epoch: 7| Step: 16
Training loss: 2.3190388378791322
Validation loss: 2.095966448831253
Epoch: 7| Step: 17
Training loss: 2.4095671937039067
Validation loss: 2.0695938503665454
Epoch: 7| Step: 18
Training loss: 2.4503734732145714
Validation loss: 2.062945560225123
Epoch: 7| Step: 19
Training loss: 2.3670311803790667
Validation loss: 1.9916781423524368
Epoch: 8| Step: 0
Training loss: 2.3660426629058127
Validation loss: 2.121989082789984
Epoch: 8| Step: 1
Training loss: 2.8022132096568755
Validation loss: 2.059365527546757
Epoch: 8| Step: 2
Training loss: 3.061551316908546
Validation loss: 2.0943263307451505
Epoch: 8| Step: 3
Training loss: 2.5161148447349837
Validation loss: 2.127413347485987
Epoch: 8| Step: 4
Training loss: 2.4626270125886105
Validation loss: 2.1381470692179048
Epoch: 8| Step: 5
Training loss: 2.7004172815071925
Validation loss: 2.1110565599252618
Epoch: 8| Step: 6
Training loss: 2.6523405139661778
Validation loss: 2.058398750422667
Epoch: 8| Step: 7
Training loss: 2.8159778708325383
Validation loss: 2.0617954533133678
Epoch: 8| Step: 8
Training loss: 2.1540771815038875
Validation loss: 2.0285497457921813
Epoch: 8| Step: 9
Training loss: 2.80229633377326
Validation loss: 2.0891631623972966
Epoch: 8| Step: 10
Training loss: 2.814975750888163
Validation loss: 2.0709163578959755
Epoch: 8| Step: 11
Training loss: 3.062865410627866
Validation loss: 2.1162451340614767
Epoch: 8| Step: 12
Training loss: 2.4287780826062186
Validation loss: 2.0297156449370215
Epoch: 8| Step: 13
Training loss: 3.0661675427092008
Validation loss: 2.122981064450776
Epoch: 8| Step: 14
Training loss: 2.7615080109603864
Validation loss: 2.103366971285533
Epoch: 8| Step: 15
Training loss: 2.8941788555415453
Validation loss: 2.0639826879296646
Epoch: 8| Step: 16
Training loss: 2.3482662176536517
Validation loss: 2.080078831999376
Epoch: 8| Step: 17
Training loss: 2.218710240827194
Validation loss: 2.056225503575452
Epoch: 8| Step: 18
Training loss: 2.505492090557208
Validation loss: 2.1216153985325117
Epoch: 8| Step: 19
Training loss: 2.4275367760745326
Validation loss: 2.0934188974360524
Epoch: 9| Step: 0
Training loss: 1.9508265284186428
Validation loss: 2.0990973665330124
Epoch: 9| Step: 1
Training loss: 2.591379944210958
Validation loss: 2.0827329440441398
Epoch: 9| Step: 2
Training loss: 2.8730847157178303
Validation loss: 2.044353487531976
Epoch: 9| Step: 3
Training loss: 2.8442414246897867
Validation loss: 2.017280646341624
Epoch: 9| Step: 4
Training loss: 2.702117202848479
Validation loss: 2.0437650629259307
Epoch: 9| Step: 5
Training loss: 3.037866352107446
Validation loss: 2.0954688002121418
Epoch: 9| Step: 6
Training loss: 2.083135659058658
Validation loss: 2.0783369649618333
Epoch: 9| Step: 7
Training loss: 1.8094795315447327
Validation loss: 2.1362210292671255
Epoch: 9| Step: 8
Training loss: 2.905318080014154
Validation loss: 2.164941594772165
Epoch: 9| Step: 9
Training loss: 2.5838189335205906
Validation loss: 2.118809416768197
Epoch: 9| Step: 10
Training loss: 3.0556220846928848
Validation loss: 2.1158927555613483
Epoch: 9| Step: 11
Training loss: 2.8522959980745903
Validation loss: 2.1095592490865718
Epoch: 9| Step: 12
Training loss: 2.277313808028401
Validation loss: 2.07311903785675
Epoch: 9| Step: 13
Training loss: 3.040622497118462
Validation loss: 2.0919949278046457
Epoch: 9| Step: 14
Training loss: 2.5927217582537962
Validation loss: 2.053940375982389
Epoch: 9| Step: 15
Training loss: 2.082347967453123
Validation loss: 2.0943108137683444
Epoch: 9| Step: 16
Training loss: 2.7677105297864286
Validation loss: 2.0665634241199875
Epoch: 9| Step: 17
Training loss: 2.629385781162901
Validation loss: 2.075153040445992
Epoch: 9| Step: 18
Training loss: 3.0542183830458898
Validation loss: 2.0957055182972932
Epoch: 9| Step: 19
Training loss: 2.795349642835741
Validation loss: 2.102102652767738
Epoch: 10| Step: 0
Training loss: 2.9814804979704013
Validation loss: 2.129851039040946
Epoch: 10| Step: 1
Training loss: 2.736716788092761
Validation loss: 2.0596197017354863
Epoch: 10| Step: 2
Training loss: 2.3091121291685344
Validation loss: 2.1258153813879526
Epoch: 10| Step: 3
Training loss: 2.6965884519471643
Validation loss: 2.0742203279941527
Epoch: 10| Step: 4
Training loss: 2.707330772486364
Validation loss: 2.060740301044195
Epoch: 10| Step: 5
Training loss: 3.00728009949219
Validation loss: 2.0592886413766864
Epoch: 10| Step: 6
Training loss: 2.5886039700804013
Validation loss: 2.0545039605723145
Epoch: 10| Step: 7
Training loss: 2.062573633902503
Validation loss: 2.1086799704819823
Epoch: 10| Step: 8
Training loss: 2.4565809652976025
Validation loss: 2.140385480085576
Epoch: 10| Step: 9
Training loss: 2.4195559319631257
Validation loss: 2.1203976083431213
Epoch: 10| Step: 10
Training loss: 2.8800111304174028
Validation loss: 2.0607085500915368
Epoch: 10| Step: 11
Training loss: 2.580139113231674
Validation loss: 2.0400022502058412
Epoch: 10| Step: 12
Training loss: 3.12470335506091
Validation loss: 2.087973316492241
Epoch: 10| Step: 13
Training loss: 2.339284686771612
Validation loss: 2.0536150289337893
Epoch: 10| Step: 14
Training loss: 2.7239953665224794
Validation loss: 2.0361304619398046
Epoch: 10| Step: 15
Training loss: 2.8806206866161905
Validation loss: 2.1097387567032877
Epoch: 10| Step: 16
Training loss: 2.817024745037582
Validation loss: 1.9784078835880576
Epoch: 10| Step: 17
Training loss: 2.302006393688878
Validation loss: 2.0615758175066707
Epoch: 10| Step: 18
Training loss: 2.517852365784911
Validation loss: 2.101291715434734
Epoch: 10| Step: 19
Training loss: 2.473326485239644
Validation loss: 2.0280768508798115
Epoch: 11| Step: 0
Training loss: 3.0880408736078535
Validation loss: 2.099476649310369
Epoch: 11| Step: 1
Training loss: 1.976211456366924
Validation loss: 2.0821193092299475
Epoch: 11| Step: 2
Training loss: 2.5584686947611366
Validation loss: 2.1239216265061382
Epoch: 11| Step: 3
Training loss: 2.8438462461176797
Validation loss: 2.069830224239567
Epoch: 11| Step: 4
Training loss: 3.048396117194926
Validation loss: 2.0633340097400703
Epoch: 11| Step: 5
Training loss: 2.561853839073072
Validation loss: 2.05351224344757
Epoch: 11| Step: 6
Training loss: 2.9441611875484335
Validation loss: 2.169687810616647
Epoch: 11| Step: 7
Training loss: 2.688206513265878
Validation loss: 2.0429485841443316
Epoch: 11| Step: 8
Training loss: 1.7476342422811764
Validation loss: 2.078008510462115
Epoch: 11| Step: 9
Training loss: 2.6750563927526345
Validation loss: 2.054557738894723
Epoch: 11| Step: 10
Training loss: 2.234182176072517
Validation loss: 2.090412139150197
Epoch: 11| Step: 11
Training loss: 2.7832104063775365
Validation loss: 2.108929727079013
Epoch: 11| Step: 12
Training loss: 2.9112269947130702
Validation loss: 2.0722243487069303
Epoch: 11| Step: 13
Training loss: 2.991007679339224
Validation loss: 2.0632405507064986
Epoch: 11| Step: 14
Training loss: 2.175904303038216
Validation loss: 2.053019987097963
Epoch: 11| Step: 15
Training loss: 2.8664370186070065
Validation loss: 2.0702899997561026
Epoch: 11| Step: 16
Training loss: 2.612667815736812
Validation loss: 2.09046973237169
Epoch: 11| Step: 17
Training loss: 2.231727151580489
Validation loss: 2.093902639180643
Epoch: 11| Step: 18
Training loss: 2.778468080154336
Validation loss: 2.0828087285763948
Epoch: 11| Step: 19
Training loss: 2.7033199173876237
Validation loss: 2.0582539009072267
Epoch: 12| Step: 0
Training loss: 2.848138462258342
Validation loss: 2.1112991078521275
Epoch: 12| Step: 1
Training loss: 2.274422134116474
Validation loss: 2.144892470338087
Epoch: 12| Step: 2
Training loss: 2.9050694190445387
Validation loss: 2.073297265167271
Epoch: 12| Step: 3
Training loss: 2.6576274217576885
Validation loss: 2.11686762665555
Epoch: 12| Step: 4
Training loss: 2.5183799301404424
Validation loss: 2.0483085530963043
Epoch: 12| Step: 5
Training loss: 2.813124947521427
Validation loss: 2.0300936072328275
Epoch: 12| Step: 6
Training loss: 2.924155747603516
Validation loss: 2.1075534545341905
Epoch: 12| Step: 7
Training loss: 3.180734822766014
Validation loss: 2.0287343343032407
Epoch: 12| Step: 8
Training loss: 2.316896949501504
Validation loss: 2.0832954909895105
Epoch: 12| Step: 9
Training loss: 2.2679088788305015
Validation loss: 2.0858464605354374
Epoch: 12| Step: 10
Training loss: 2.1524605001088424
Validation loss: 2.1412826668459872
Epoch: 12| Step: 11
Training loss: 2.2825228131962296
Validation loss: 2.0432221523528695
Epoch: 12| Step: 12
Training loss: 3.0132916371940657
Validation loss: 2.0541250660770527
Epoch: 12| Step: 13
Training loss: 2.5245649812842137
Validation loss: 2.0349811803598117
Epoch: 12| Step: 14
Training loss: 2.8893731783185133
Validation loss: 2.0890737079729402
Epoch: 12| Step: 15
Training loss: 2.64193115434604
Validation loss: 2.088576051813842
Epoch: 12| Step: 16
Training loss: 2.4908931803179346
Validation loss: 2.063218843645143
Epoch: 12| Step: 17
Training loss: 2.4909483121810294
Validation loss: 2.085635449179302
Epoch: 12| Step: 18
Training loss: 2.9183965366853273
Validation loss: 2.0568838393509585
Epoch: 12| Step: 19
Training loss: 2.666741777395387
Validation loss: 2.1215987727754455
Epoch: 13| Step: 0
Training loss: 2.757202340295469
Validation loss: 2.066438208767927
Epoch: 13| Step: 1
Training loss: 2.8099320450300516
Validation loss: 2.15275154674842
Epoch: 13| Step: 2
Training loss: 2.8764860210374104
Validation loss: 2.0937562337770146
Epoch: 13| Step: 3
Training loss: 2.6789213369795166
Validation loss: 2.0803334265963045
Epoch: 13| Step: 4
Training loss: 2.3451108923356
Validation loss: 2.0801683825089192
Epoch: 13| Step: 5
Training loss: 2.86160274919309
Validation loss: 2.016140966456576
Epoch: 13| Step: 6
Training loss: 2.0760489972015925
Validation loss: 2.061390461406938
Epoch: 13| Step: 7
Training loss: 3.431649517987908
Validation loss: 2.0886510201726134
Epoch: 13| Step: 8
Training loss: 2.822816366030232
Validation loss: 2.1067501850700747
Epoch: 13| Step: 9
Training loss: 2.6367890977305417
Validation loss: 2.1475345386900546
Epoch: 13| Step: 10
Training loss: 2.419490304661415
Validation loss: 2.026995077991902
Epoch: 13| Step: 11
Training loss: 2.8443014427670392
Validation loss: 2.0783079600993624
Epoch: 13| Step: 12
Training loss: 2.259269165261699
Validation loss: 2.152451046308884
Epoch: 13| Step: 13
Training loss: 2.9550703796164193
Validation loss: 2.1054712215082505
Epoch: 13| Step: 14
Training loss: 1.7292263832658001
Validation loss: 2.0684301258304645
Epoch: 13| Step: 15
Training loss: 2.202357489903985
Validation loss: 2.0992193714253804
Epoch: 13| Step: 16
Training loss: 2.51812051711603
Validation loss: 2.1058372640872545
Epoch: 13| Step: 17
Training loss: 2.3931497443756267
Validation loss: 2.089345724246855
Epoch: 13| Step: 18
Training loss: 3.141490001079087
Validation loss: 2.022298245124782
Epoch: 13| Step: 19
Training loss: 2.548379652535036
Validation loss: 2.0839914031451445
Epoch: 14| Step: 0
Training loss: 3.340688855066749
Validation loss: 2.084356023048718
Epoch: 14| Step: 1
Training loss: 2.962475057891278
Validation loss: 2.0869804888185284
Epoch: 14| Step: 2
Training loss: 2.497075754815393
Validation loss: 2.095419477684497
Epoch: 14| Step: 3
Training loss: 2.8060241744290924
Validation loss: 2.155610305067854
Epoch: 14| Step: 4
Training loss: 2.324297735330691
Validation loss: 2.0104556249835928
Epoch: 14| Step: 5
Training loss: 2.5598657605619026
Validation loss: 2.0921724047566403
Epoch: 14| Step: 6
Training loss: 3.3978697554676915
Validation loss: 2.0883542485879394
Epoch: 14| Step: 7
Training loss: 2.124722294332473
Validation loss: 2.1446084552055487
Epoch: 14| Step: 8
Training loss: 2.4495892160882167
Validation loss: 2.0865995671281374
Epoch: 14| Step: 9
Training loss: 2.2617446818866362
Validation loss: 2.1319831356974714
Epoch: 14| Step: 10
Training loss: 2.9000481502876494
Validation loss: 2.127805438739056
Epoch: 14| Step: 11
Training loss: 2.4449868274794144
Validation loss: 2.0559463446661126
Epoch: 14| Step: 12
Training loss: 2.716588619101786
Validation loss: 2.088601940855516
Epoch: 14| Step: 13
Training loss: 2.8568529356590773
Validation loss: 2.0957888223077052
Epoch: 14| Step: 14
Training loss: 2.636840817486929
Validation loss: 2.0848814637292867
Epoch: 14| Step: 15
Training loss: 2.690242698526945
Validation loss: 2.0954248048562274
Epoch: 14| Step: 16
Training loss: 2.6057174541040626
Validation loss: 2.0619967117540536
Epoch: 14| Step: 17
Training loss: 2.3840526917926232
Validation loss: 2.0433562695565866
Epoch: 14| Step: 18
Training loss: 2.489728808974248
Validation loss: 2.0778347660670278
Epoch: 14| Step: 19
Training loss: 2.122787782639445
Validation loss: 2.1069854483354726
Epoch: 15| Step: 0
Training loss: 3.120373008878678
Validation loss: 2.1023933608533576
Epoch: 15| Step: 1
Training loss: 2.6104932205004028
Validation loss: 2.0519840155657008
Epoch: 15| Step: 2
Training loss: 3.0939272434826046
Validation loss: 2.0860669851925775
Epoch: 15| Step: 3
Training loss: 2.10158995429616
Validation loss: 2.1004083186376326
Epoch: 15| Step: 4
Training loss: 3.116258372797852
Validation loss: 2.082770958184651
Epoch: 15| Step: 5
Training loss: 2.1989223355000593
Validation loss: 2.0477103573587865
Epoch: 15| Step: 6
Training loss: 2.4393112104687575
Validation loss: 2.088674121746431
Epoch: 15| Step: 7
Training loss: 2.625929350054386
Validation loss: 2.079080275560443
Epoch: 15| Step: 8
Training loss: 2.3678307996820323
Validation loss: 2.0821442564081156
Epoch: 15| Step: 9
Training loss: 2.966695938251688
Validation loss: 2.0468740125825753
Epoch: 15| Step: 10
Training loss: 2.935963492610875
Validation loss: 2.031896867206443
Epoch: 15| Step: 11
Training loss: 2.511890648733553
Validation loss: 2.102363992180239
Epoch: 15| Step: 12
Training loss: 2.521683972390297
Validation loss: 2.0703217004317223
Epoch: 15| Step: 13
Training loss: 2.676824435964025
Validation loss: 2.051862277852046
Epoch: 15| Step: 14
Training loss: 2.6450773545835964
Validation loss: 2.084917021509429
Epoch: 15| Step: 15
Training loss: 2.3461115828480077
Validation loss: 2.049825172552005
Epoch: 15| Step: 16
Training loss: 2.649455457195974
Validation loss: 2.1107502686782302
Epoch: 15| Step: 17
Training loss: 1.804105986998269
Validation loss: 2.0914620894427687
Epoch: 15| Step: 18
Training loss: 2.6722392229934777
Validation loss: 2.165630899566205
Epoch: 15| Step: 19
Training loss: 2.9557967437323542
Validation loss: 2.089662294588144
Epoch: 16| Step: 0
Training loss: 2.4161577236910574
Validation loss: 2.0568412383037487
Epoch: 16| Step: 1
Training loss: 2.603501156010526
Validation loss: 2.0577490158919396
Epoch: 16| Step: 2
Training loss: 2.3629985545666923
Validation loss: 2.107506390759318
Epoch: 16| Step: 3
Training loss: 2.3032878181535184
Validation loss: 2.109068911027823
Epoch: 16| Step: 4
Training loss: 2.2973998631352863
Validation loss: 2.0676244369822703
Epoch: 16| Step: 5
Training loss: 3.1448232953474444
Validation loss: 2.0885924760870127
Epoch: 16| Step: 6
Training loss: 3.0183676467649856
Validation loss: 2.078015607579452
Epoch: 16| Step: 7
Training loss: 2.702402183604558
Validation loss: 2.1170972844232394
Epoch: 16| Step: 8
Training loss: 3.0324188810287294
Validation loss: 2.0728495001168135
Epoch: 16| Step: 9
Training loss: 2.385596278284804
Validation loss: 2.1229819027140993
Epoch: 16| Step: 10
Training loss: 2.733217353996387
Validation loss: 2.069951055694493
Epoch: 16| Step: 11
Training loss: 2.108053514007631
Validation loss: 2.081643647176044
Epoch: 16| Step: 12
Training loss: 2.8135062219128266
Validation loss: 2.065099788890285
Epoch: 16| Step: 13
Training loss: 2.875810426016339
Validation loss: 2.051075077890262
Epoch: 16| Step: 14
Training loss: 2.4656961602408485
Validation loss: 2.0961182614986846
Epoch: 16| Step: 15
Training loss: 2.5242960033442987
Validation loss: 2.1044736927813394
Epoch: 16| Step: 16
Training loss: 2.749348650001956
Validation loss: 2.1247676547563703
Epoch: 16| Step: 17
Training loss: 2.9040000163517052
Validation loss: 2.0793980918406927
Epoch: 16| Step: 18
Training loss: 2.7428138647894253
Validation loss: 2.0934626707737998
Epoch: 16| Step: 19
Training loss: 2.5661015206262117
Validation loss: 2.0500439604524954
Epoch: 17| Step: 0
Training loss: 3.3055900621794723
Validation loss: 2.062969519371491
Epoch: 17| Step: 1
Training loss: 3.1050179016285226
Validation loss: 2.0957359007462557
Epoch: 17| Step: 2
Training loss: 2.586592208177356
Validation loss: 2.1356677233985244
Epoch: 17| Step: 3
Training loss: 2.6366786021249005
Validation loss: 2.081038931388955
Epoch: 17| Step: 4
Training loss: 2.651046503108821
Validation loss: 2.085523029705932
Epoch: 17| Step: 5
Training loss: 2.49524226463043
Validation loss: 2.0928723070852815
Epoch: 17| Step: 6
Training loss: 1.8340621785488422
Validation loss: 2.124747705947641
Epoch: 17| Step: 7
Training loss: 2.258907699273135
Validation loss: 2.0924513269630554
Epoch: 17| Step: 8
Training loss: 2.83949296508498
Validation loss: 2.129090487208961
Epoch: 17| Step: 9
Training loss: 2.6633258595399547
Validation loss: 2.087785972664995
Epoch: 17| Step: 10
Training loss: 2.857392170791436
Validation loss: 1.9924494245435171
Epoch: 17| Step: 11
Training loss: 2.6730587662595817
Validation loss: 2.100114519481262
Epoch: 17| Step: 12
Training loss: 2.625967392456795
Validation loss: 2.0814260935461233
Epoch: 17| Step: 13
Training loss: 2.9635384843984633
Validation loss: 2.052120857835633
Epoch: 17| Step: 14
Training loss: 3.1658507015283703
Validation loss: 2.0572394924800452
Epoch: 17| Step: 15
Training loss: 2.5369658748931396
Validation loss: 2.0836335823775953
Epoch: 17| Step: 16
Training loss: 2.4911533230916136
Validation loss: 2.074684550325868
Epoch: 17| Step: 17
Training loss: 1.9769624448691108
Validation loss: 2.1252638340245036
Epoch: 17| Step: 18
Training loss: 3.0115962022124854
Validation loss: 2.097663540838442
Epoch: 17| Step: 19
Training loss: 1.7843101048735905
Validation loss: 2.0676043977498733
Epoch: 18| Step: 0
Training loss: 2.153637395163399
Validation loss: 2.0348679101174243
Epoch: 18| Step: 1
Training loss: 2.699324212449934
Validation loss: 2.113191810571781
Epoch: 18| Step: 2
Training loss: 2.2776479632387883
Validation loss: 2.102895160525307
Epoch: 18| Step: 3
Training loss: 3.0930338329261735
Validation loss: 2.0744319563258156
Epoch: 18| Step: 4
Training loss: 2.4309208428924993
Validation loss: 2.1187327467646098
Epoch: 18| Step: 5
Training loss: 2.928540791208394
Validation loss: 2.0948050140730285
Epoch: 18| Step: 6
Training loss: 2.4791365763229947
Validation loss: 2.0825811513446437
Epoch: 18| Step: 7
Training loss: 2.70096029582495
Validation loss: 2.0850162190624597
Epoch: 18| Step: 8
Training loss: 2.4861394026962107
Validation loss: 1.9974609946575934
Epoch: 18| Step: 9
Training loss: 2.844702592533325
Validation loss: 2.0500748015218226
Epoch: 18| Step: 10
Training loss: 2.7855666020130427
Validation loss: 2.081042589542785
Epoch: 18| Step: 11
Training loss: 2.318946307733194
Validation loss: 2.052802793886594
Epoch: 18| Step: 12
Training loss: 2.581578571383612
Validation loss: 2.100289982171092
Epoch: 18| Step: 13
Training loss: 2.7636174388686996
Validation loss: 2.032056458565216
Epoch: 18| Step: 14
Training loss: 2.162712144092872
Validation loss: 2.054434989181816
Epoch: 18| Step: 15
Training loss: 2.736131376480814
Validation loss: 2.0699635960151133
Epoch: 18| Step: 16
Training loss: 2.9748922953623627
Validation loss: 2.0515741632893207
Epoch: 18| Step: 17
Training loss: 2.9396974176933197
Validation loss: 2.105939671248487
Epoch: 18| Step: 18
Training loss: 2.410903790004023
Validation loss: 2.064447246320981
Epoch: 18| Step: 19
Training loss: 2.6793864890213297
Validation loss: 2.071904424803431
Epoch: 19| Step: 0
Training loss: 2.242705494662867
Validation loss: 2.1156297706732485
Epoch: 19| Step: 1
Training loss: 2.7219938022338357
Validation loss: 2.0489377181207975
Epoch: 19| Step: 2
Training loss: 2.58221093272537
Validation loss: 2.1065248387516116
Epoch: 19| Step: 3
Training loss: 3.084558106217538
Validation loss: 2.063189222536814
Epoch: 19| Step: 4
Training loss: 2.4189438340541
Validation loss: 2.093209424537063
Epoch: 19| Step: 5
Training loss: 2.654898086287264
Validation loss: 2.0953537762078374
Epoch: 19| Step: 6
Training loss: 2.664237545225218
Validation loss: 2.088335330080967
Epoch: 19| Step: 7
Training loss: 2.2353720407810345
Validation loss: 2.088412918516428
Epoch: 19| Step: 8
Training loss: 2.8272605122701275
Validation loss: 2.0821178732058936
Epoch: 19| Step: 9
Training loss: 2.5436784776385
Validation loss: 2.105789292978739
Epoch: 19| Step: 10
Training loss: 2.6620742672391535
Validation loss: 2.0148512488598906
Epoch: 19| Step: 11
Training loss: 2.0763673161038434
Validation loss: 2.0344973996627536
Epoch: 19| Step: 12
Training loss: 3.031204852525014
Validation loss: 2.0893270938326736
Epoch: 19| Step: 13
Training loss: 2.4645498738364866
Validation loss: 2.0646173035016444
Epoch: 19| Step: 14
Training loss: 2.5883687279469987
Validation loss: 2.069546183336247
Epoch: 19| Step: 15
Training loss: 3.025217877572971
Validation loss: 2.087573417655513
Epoch: 19| Step: 16
Training loss: 2.8893391816602714
Validation loss: 2.0856240122204426
Epoch: 19| Step: 17
Training loss: 3.2238367866114106
Validation loss: 2.069116778602993
Epoch: 19| Step: 18
Training loss: 2.6121502582858422
Validation loss: 2.0087881228562843
Epoch: 19| Step: 19
Training loss: 2.236381216959846
Validation loss: 2.058299692693876
Epoch: 20| Step: 0
Training loss: 2.683327918511213
Validation loss: 2.108129525311787
Epoch: 20| Step: 1
Training loss: 3.1061872694715853
Validation loss: 2.1485788532014385
Epoch: 20| Step: 2
Training loss: 2.7563984733607207
Validation loss: 2.0871189072913583
Epoch: 20| Step: 3
Training loss: 2.8536334316993495
Validation loss: 2.097648872606985
Epoch: 20| Step: 4
Training loss: 2.240725050305841
Validation loss: 2.083986072750619
Epoch: 20| Step: 5
Training loss: 2.1995721400961834
Validation loss: 2.0929094521486276
Epoch: 20| Step: 6
Training loss: 2.961936600948702
Validation loss: 2.063579633016597
Epoch: 20| Step: 7
Training loss: 2.5481885085566924
Validation loss: 2.0850247795814387
Epoch: 20| Step: 8
Training loss: 2.2863880977980187
Validation loss: 2.040517579990907
Epoch: 20| Step: 9
Training loss: 2.2455136818903245
Validation loss: 2.071475138725084
Epoch: 20| Step: 10
Training loss: 3.1088550842219043
Validation loss: 2.000217086342285
Epoch: 20| Step: 11
Training loss: 3.1455595053091
Validation loss: 2.1037218463200116
Epoch: 20| Step: 12
Training loss: 2.6382287343011384
Validation loss: 2.037814599594092
Epoch: 20| Step: 13
Training loss: 2.6276072315290184
Validation loss: 2.0990685050932125
Epoch: 20| Step: 14
Training loss: 2.4895470482218363
Validation loss: 2.082993488286464
Epoch: 20| Step: 15
Training loss: 3.175784853549616
Validation loss: 2.0930756089122293
Epoch: 20| Step: 16
Training loss: 2.1821252460495986
Validation loss: 2.0925208588179993
Epoch: 20| Step: 17
Training loss: 2.135889314276795
Validation loss: 2.0830634059519335
Epoch: 20| Step: 18
Training loss: 2.6932763411217193
Validation loss: 2.0670001399791564
Epoch: 20| Step: 19
Training loss: 2.2514567427777976
Validation loss: 2.08301893009886
Epoch: 21| Step: 0
Training loss: 2.381766468018792
Validation loss: 2.0836573155407825
Epoch: 21| Step: 1
Training loss: 2.3133174379372474
Validation loss: 2.031419880903557
Epoch: 21| Step: 2
Training loss: 2.9544907091310675
Validation loss: 2.0511138483148676
Epoch: 21| Step: 3
Training loss: 2.9715468232498226
Validation loss: 2.0663430593023
Epoch: 21| Step: 4
Training loss: 2.1406319054262477
Validation loss: 2.0271638400309158
Epoch: 21| Step: 5
Training loss: 2.5316956681111216
Validation loss: 2.060838137960714
Epoch: 21| Step: 6
Training loss: 2.68145906927056
Validation loss: 2.0938219346689078
Epoch: 21| Step: 7
Training loss: 2.851710485511506
Validation loss: 2.107496720334268
Epoch: 21| Step: 8
Training loss: 3.306503049688982
Validation loss: 2.0693578010977047
Epoch: 21| Step: 9
Training loss: 2.5685179222689105
Validation loss: 2.085719108259269
Epoch: 21| Step: 10
Training loss: 2.439825073913371
Validation loss: 2.0833440248763013
Epoch: 21| Step: 11
Training loss: 2.9165015764289413
Validation loss: 2.116255736729528
Epoch: 21| Step: 12
Training loss: 2.510088876769308
Validation loss: 2.092736880518426
Epoch: 21| Step: 13
Training loss: 2.9109121684980397
Validation loss: 2.1121927772137736
Epoch: 21| Step: 14
Training loss: 2.3982553816748586
Validation loss: 2.0804001697951904
Epoch: 21| Step: 15
Training loss: 2.4485340286828605
Validation loss: 2.0816336664574395
Epoch: 21| Step: 16
Training loss: 2.331697424121541
Validation loss: 2.109700591293801
Epoch: 21| Step: 17
Training loss: 2.566366302783185
Validation loss: 2.143584881599754
Epoch: 21| Step: 18
Training loss: 2.7710941354489442
Validation loss: 2.0602132521796146
Epoch: 21| Step: 19
Training loss: 2.6451843446984453
Validation loss: 2.094731301832537
Epoch: 22| Step: 0
Training loss: 2.639948289827175
Validation loss: 2.1294206353366887
Epoch: 22| Step: 1
Training loss: 2.2089341863703353
Validation loss: 2.0740091466865413
Epoch: 22| Step: 2
Training loss: 2.892021213163502
Validation loss: 2.02580761124948
Epoch: 22| Step: 3
Training loss: 3.162668632263336
Validation loss: 2.091496630598728
Epoch: 22| Step: 4
Training loss: 2.417796583316789
Validation loss: 2.04256227223679
Epoch: 22| Step: 5
Training loss: 2.8281653807059763
Validation loss: 2.140293951684187
Epoch: 22| Step: 6
Training loss: 1.8795690180473597
Validation loss: 2.0508358228029024
Epoch: 22| Step: 7
Training loss: 2.690456006705431
Validation loss: 2.1061975383981846
Epoch: 22| Step: 8
Training loss: 2.346534397486827
Validation loss: 2.1332450768525475
Epoch: 22| Step: 9
Training loss: 2.5068332744921578
Validation loss: 2.106225125899482
Epoch: 22| Step: 10
Training loss: 2.7612972558374107
Validation loss: 2.1141087992786747
Epoch: 22| Step: 11
Training loss: 2.7247417677567634
Validation loss: 2.067454831678062
Epoch: 22| Step: 12
Training loss: 2.5933665716040095
Validation loss: 2.1282006734477634
Epoch: 22| Step: 13
Training loss: 2.9476767039050653
Validation loss: 2.052894472152742
Epoch: 22| Step: 14
Training loss: 2.5847751736590667
Validation loss: 2.111599906241332
Epoch: 22| Step: 15
Training loss: 2.665301887633309
Validation loss: 2.0993677171796645
Epoch: 22| Step: 16
Training loss: 2.3361399891333834
Validation loss: 2.1070993531480573
Epoch: 22| Step: 17
Training loss: 3.0719930694025064
Validation loss: 2.039055695142508
Epoch: 22| Step: 18
Training loss: 2.628889925539026
Validation loss: 2.1243184677119546
Epoch: 22| Step: 19
Training loss: 2.433107967478774
Validation loss: 2.123997286850476
Epoch: 23| Step: 0
Training loss: 2.8129763729596275
Validation loss: 2.1126171618090517
Epoch: 23| Step: 1
Training loss: 2.799256488312498
Validation loss: 2.0951947913761457
Epoch: 23| Step: 2
Training loss: 2.4011857878376723
Validation loss: 2.08101044473562
Epoch: 23| Step: 3
Training loss: 2.7223047278567174
Validation loss: 2.060531571605696
Epoch: 23| Step: 4
Training loss: 2.6060047427622455
Validation loss: 2.1258456651009454
Epoch: 23| Step: 5
Training loss: 3.143922507556525
Validation loss: 2.0880190507768743
Epoch: 23| Step: 6
Training loss: 2.2084079465916924
Validation loss: 2.076593168298605
Epoch: 23| Step: 7
Training loss: 1.8088203436532921
Validation loss: 2.0585612035411214
Epoch: 23| Step: 8
Training loss: 2.810772343989952
Validation loss: 2.091596141576949
Epoch: 23| Step: 9
Training loss: 3.341924579082082
Validation loss: 2.1014355679189283
Epoch: 23| Step: 10
Training loss: 2.540719111014482
Validation loss: 2.0751630559110117
Epoch: 23| Step: 11
Training loss: 2.386809751583206
Validation loss: 2.0113838180291363
Epoch: 23| Step: 12
Training loss: 2.741536294065513
Validation loss: 2.0580883410058117
Epoch: 23| Step: 13
Training loss: 2.5758006397428086
Validation loss: 2.0724889184924677
Epoch: 23| Step: 14
Training loss: 2.7264385905706874
Validation loss: 2.075189642204248
Epoch: 23| Step: 15
Training loss: 2.6712176311782754
Validation loss: 2.0829412850084212
Epoch: 23| Step: 16
Training loss: 2.3656050929412356
Validation loss: 2.0667166883127064
Epoch: 23| Step: 17
Training loss: 2.673840697588456
Validation loss: 2.0663111179312272
Epoch: 23| Step: 18
Training loss: 2.5965852982092588
Validation loss: 2.063974440137342
Epoch: 23| Step: 19
Training loss: 2.876590951989163
Validation loss: 2.0939222633981345
Epoch: 24| Step: 0
Training loss: 2.9525439785775536
Validation loss: 2.1321784310038203
Epoch: 24| Step: 1
Training loss: 2.7133471418618287
Validation loss: 2.0438802361154154
Epoch: 24| Step: 2
Training loss: 2.463633776845409
Validation loss: 2.0648697560307485
Epoch: 24| Step: 3
Training loss: 3.149469022049528
Validation loss: 2.088220997885161
Epoch: 24| Step: 4
Training loss: 2.530999630449103
Validation loss: 2.0367291505965843
Epoch: 24| Step: 5
Training loss: 2.938569868336254
Validation loss: 2.1330139857560595
Epoch: 24| Step: 6
Training loss: 2.6124445056040595
Validation loss: 2.076074681788893
Epoch: 24| Step: 7
Training loss: 2.354059560134087
Validation loss: 2.0601891898943734
Epoch: 24| Step: 8
Training loss: 2.3656299868169555
Validation loss: 2.0604356115239013
Epoch: 24| Step: 9
Training loss: 2.5830534096282616
Validation loss: 2.0929262962601554
Epoch: 24| Step: 10
Training loss: 1.8964776491778585
Validation loss: 2.057291159251989
Epoch: 24| Step: 11
Training loss: 3.077716161231247
Validation loss: 2.083920888176186
Epoch: 24| Step: 12
Training loss: 2.6683481597329637
Validation loss: 2.0783390077757917
Epoch: 24| Step: 13
Training loss: 2.724703179388809
Validation loss: 2.0780082759636445
Epoch: 24| Step: 14
Training loss: 2.888248765972742
Validation loss: 2.1114833353773963
Epoch: 24| Step: 15
Training loss: 2.7458278912580525
Validation loss: 2.0495206228441516
Epoch: 24| Step: 16
Training loss: 2.745578332231293
Validation loss: 2.036275684108898
Epoch: 24| Step: 17
Training loss: 2.5312586654703138
Validation loss: 2.0985396042445528
Epoch: 24| Step: 18
Training loss: 2.4585615041416427
Validation loss: 2.109334317857987
Epoch: 24| Step: 19
Training loss: 2.569348835813073
Validation loss: 2.0235626456593927
Epoch: 25| Step: 0
Training loss: 2.7046304380500863
Validation loss: 2.082776887154009
Epoch: 25| Step: 1
Training loss: 2.6899309918085517
Validation loss: 2.045313044698746
Epoch: 25| Step: 2
Training loss: 2.957944620590285
Validation loss: 2.1348994816758564
Epoch: 25| Step: 3
Training loss: 2.571781376447498
Validation loss: 2.080626199200996
Epoch: 25| Step: 4
Training loss: 2.9341534970728382
Validation loss: 2.071259486671034
Epoch: 25| Step: 5
Training loss: 2.674178708640668
Validation loss: 2.1228556733595902
Epoch: 25| Step: 6
Training loss: 2.7511504974466283
Validation loss: 2.0790742226921135
Epoch: 25| Step: 7
Training loss: 2.7292676038252086
Validation loss: 2.034199193224157
Epoch: 25| Step: 8
Training loss: 3.4153432996898463
Validation loss: 2.126713845067397
Epoch: 25| Step: 9
Training loss: 2.6671324462214576
Validation loss: 2.11525647213524
Epoch: 25| Step: 10
Training loss: 2.5012424242780917
Validation loss: 2.079365027872332
Epoch: 25| Step: 11
Training loss: 2.550642818883166
Validation loss: 2.046636498716193
Epoch: 25| Step: 12
Training loss: 2.3790807299840613
Validation loss: 2.1602867755302135
Epoch: 25| Step: 13
Training loss: 2.423909175971611
Validation loss: 2.048045221134248
Epoch: 25| Step: 14
Training loss: 2.5259565411149336
Validation loss: 2.115061012392147
Epoch: 25| Step: 15
Training loss: 2.220394545884152
Validation loss: 2.129058651100897
Epoch: 25| Step: 16
Training loss: 2.715003578366333
Validation loss: 2.080374286582863
Epoch: 25| Step: 17
Training loss: 2.7986640536020606
Validation loss: 2.058391392572993
Epoch: 25| Step: 18
Training loss: 1.9549167806567145
Validation loss: 2.086924289628678
Epoch: 25| Step: 19
Training loss: 2.3230226660750404
Validation loss: 2.085708516305717
Epoch: 26| Step: 0
Training loss: 2.667995558865124
Validation loss: 2.116984460755904
Epoch: 26| Step: 1
Training loss: 2.2976763099539252
Validation loss: 2.0863288947524747
Epoch: 26| Step: 2
Training loss: 3.1540552950253025
Validation loss: 2.089842718517497
Epoch: 26| Step: 3
Training loss: 2.848796182001175
Validation loss: 2.1338987402845233
Epoch: 26| Step: 4
Training loss: 2.564032770759771
Validation loss: 2.099481970406983
Epoch: 26| Step: 5
Training loss: 3.4283668564891565
Validation loss: 2.0796490695790855
Epoch: 26| Step: 6
Training loss: 1.7996481021649695
Validation loss: 1.9854065997401158
Epoch: 26| Step: 7
Training loss: 2.0967902130859137
Validation loss: 2.1359864669516253
Epoch: 26| Step: 8
Training loss: 2.7181058098560102
Validation loss: 2.0343173353183577
Epoch: 26| Step: 9
Training loss: 2.649330371247728
Validation loss: 2.098810916636791
Epoch: 26| Step: 10
Training loss: 2.3845023744890863
Validation loss: 2.131191462616371
Epoch: 26| Step: 11
Training loss: 2.7461461025581757
Validation loss: 2.097444254127971
Epoch: 26| Step: 12
Training loss: 2.0483919303009546
Validation loss: 2.096419664327935
Epoch: 26| Step: 13
Training loss: 2.813195290982967
Validation loss: 2.0664805876816947
Epoch: 26| Step: 14
Training loss: 2.402613778173998
Validation loss: 2.0803939186866347
Epoch: 26| Step: 15
Training loss: 3.3695070283100117
Validation loss: 2.0699882161747034
Epoch: 26| Step: 16
Training loss: 2.398798912229509
Validation loss: 2.0525651874996824
Epoch: 26| Step: 17
Training loss: 2.486771297588749
Validation loss: 2.0944732668186616
Epoch: 26| Step: 18
Training loss: 2.805256650338357
Validation loss: 2.1282541298274618
Epoch: 26| Step: 19
Training loss: 2.5057667026048733
Validation loss: 2.0659102462499224
Epoch: 27| Step: 0
Training loss: 2.725760355568921
Validation loss: 2.078492069591024
Epoch: 27| Step: 1
Training loss: 1.7914840102423069
Validation loss: 2.091034960759516
Epoch: 27| Step: 2
Training loss: 2.2642915155749894
Validation loss: 2.0992214795143527
Epoch: 27| Step: 3
Training loss: 2.624410835633761
Validation loss: 2.0758026680900485
Epoch: 27| Step: 4
Training loss: 2.041881965132581
Validation loss: 2.0652907121323594
Epoch: 27| Step: 5
Training loss: 2.547062591945875
Validation loss: 2.1275603439555733
Epoch: 27| Step: 6
Training loss: 2.6327419554544287
Validation loss: 2.113353555753413
Epoch: 27| Step: 7
Training loss: 2.6225153653664743
Validation loss: 2.1126796201471016
Epoch: 27| Step: 8
Training loss: 3.0172171861402095
Validation loss: 2.126014632629984
Epoch: 27| Step: 9
Training loss: 2.426191359788577
Validation loss: 2.113553042077245
Epoch: 27| Step: 10
Training loss: 2.736048594974603
Validation loss: 2.1282031582946805
Epoch: 27| Step: 11
Training loss: 2.7201296057396758
Validation loss: 2.0667903544353923
Epoch: 27| Step: 12
Training loss: 3.248529835279067
Validation loss: 2.1207284697102065
Epoch: 27| Step: 13
Training loss: 3.085425689361245
Validation loss: 2.105446867876442
Epoch: 27| Step: 14
Training loss: 2.8076419835861564
Validation loss: 2.061168203786297
Epoch: 27| Step: 15
Training loss: 2.477171332676019
Validation loss: 2.103512777576977
Epoch: 27| Step: 16
Training loss: 2.111927437922941
Validation loss: 2.1094954316599672
Epoch: 27| Step: 17
Training loss: 3.1487173708580083
Validation loss: 2.145299969748146
Epoch: 27| Step: 18
Training loss: 2.830661542424532
Validation loss: 2.0143408990335776
Epoch: 27| Step: 19
Training loss: 2.52222472534765
Validation loss: 2.0431909820322343
Epoch: 28| Step: 0
Training loss: 2.5990472955455086
Validation loss: 2.0612700755560516
Epoch: 28| Step: 1
Training loss: 2.3390282434109513
Validation loss: 2.006578804216656
Epoch: 28| Step: 2
Training loss: 2.552890810737238
Validation loss: 2.1444137809097668
Epoch: 28| Step: 3
Training loss: 2.864763695789732
Validation loss: 2.0152521285159466
Epoch: 28| Step: 4
Training loss: 2.4641690789336583
Validation loss: 2.0960695214750276
Epoch: 28| Step: 5
Training loss: 2.4403228064705442
Validation loss: 2.1106844241938423
Epoch: 28| Step: 6
Training loss: 2.838785722139081
Validation loss: 2.1217986377826903
Epoch: 28| Step: 7
Training loss: 2.2476796795708163
Validation loss: 2.0222174253608607
Epoch: 28| Step: 8
Training loss: 2.8249813754387705
Validation loss: 2.085449839525079
Epoch: 28| Step: 9
Training loss: 2.9790237143482785
Validation loss: 2.047265215154865
Epoch: 28| Step: 10
Training loss: 2.5961667487103703
Validation loss: 2.038022346923506
Epoch: 28| Step: 11
Training loss: 2.7805036765014073
Validation loss: 2.107561794464232
Epoch: 28| Step: 12
Training loss: 2.767062400949699
Validation loss: 2.110396101644432
Epoch: 28| Step: 13
Training loss: 2.2878317795581906
Validation loss: 2.0820372868493466
Epoch: 28| Step: 14
Training loss: 2.326727223505437
Validation loss: 2.062027667169674
Epoch: 28| Step: 15
Training loss: 3.4026816339382853
Validation loss: 2.1235935015135543
Epoch: 28| Step: 16
Training loss: 2.9153935151441446
Validation loss: 2.05757493259697
Epoch: 28| Step: 17
Training loss: 2.4385279908598614
Validation loss: 2.1070669244644074
Epoch: 28| Step: 18
Training loss: 2.5286791897795613
Validation loss: 2.068381822618612
Epoch: 28| Step: 19
Training loss: 2.500245845150802
Validation loss: 2.040905232462947
Epoch: 29| Step: 0
Training loss: 2.4530433592605143
Validation loss: 2.1104818595045463
Epoch: 29| Step: 1
Training loss: 2.983038318332934
Validation loss: 2.1023395163220013
Epoch: 29| Step: 2
Training loss: 2.311074513467559
Validation loss: 2.0727063574473785
Epoch: 29| Step: 3
Training loss: 2.46756696724192
Validation loss: 2.0759596337663044
Epoch: 29| Step: 4
Training loss: 2.9299871266052953
Validation loss: 2.082509166724105
Epoch: 29| Step: 5
Training loss: 1.919103282997655
Validation loss: 2.0497015477581746
Epoch: 29| Step: 6
Training loss: 2.596857897613801
Validation loss: 2.05204463289577
Epoch: 29| Step: 7
Training loss: 3.1332836985884063
Validation loss: 2.0877394471447888
Epoch: 29| Step: 8
Training loss: 2.6583902151625103
Validation loss: 2.064303933681803
Epoch: 29| Step: 9
Training loss: 2.470110361514052
Validation loss: 2.073923624425373
Epoch: 29| Step: 10
Training loss: 2.645388307966669
Validation loss: 2.068442647105595
Epoch: 29| Step: 11
Training loss: 3.0790360549941767
Validation loss: 2.0701522321583607
Epoch: 29| Step: 12
Training loss: 2.798603993909782
Validation loss: 2.0837281509932843
Epoch: 29| Step: 13
Training loss: 3.265396329183566
Validation loss: 2.0594536663900462
Epoch: 29| Step: 14
Training loss: 2.578410554735132
Validation loss: 2.057472351074094
Epoch: 29| Step: 15
Training loss: 2.208721654566522
Validation loss: 2.075020608536711
Epoch: 29| Step: 16
Training loss: 2.978628487871928
Validation loss: 2.076734304284307
Epoch: 29| Step: 17
Training loss: 1.9020993430169642
Validation loss: 2.07831970089807
Epoch: 29| Step: 18
Training loss: 2.570049330390066
Validation loss: 2.066241459555488
Epoch: 29| Step: 19
Training loss: 2.3830666328363725
Validation loss: 2.1175138490880476
Epoch: 30| Step: 0
Training loss: 2.7402597808203946
Validation loss: 2.111237311848819
Epoch: 30| Step: 1
Training loss: 2.296685866269646
Validation loss: 2.1162430931074794
Epoch: 30| Step: 2
Training loss: 2.5657667411281078
Validation loss: 2.092767380306091
Epoch: 30| Step: 3
Training loss: 2.7909660788770583
Validation loss: 2.11451039325161
Epoch: 30| Step: 4
Training loss: 3.0348077718828046
Validation loss: 2.1017777618768996
Epoch: 30| Step: 5
Training loss: 2.010591594879817
Validation loss: 2.029774544168581
Epoch: 30| Step: 6
Training loss: 2.4971997791036604
Validation loss: 2.0932695454658035
Epoch: 30| Step: 7
Training loss: 2.211123940522734
Validation loss: 2.0917898138404016
Epoch: 30| Step: 8
Training loss: 3.0676371248245857
Validation loss: 2.0442644782920216
Epoch: 30| Step: 9
Training loss: 2.4277241615332223
Validation loss: 2.0556617791523566
Epoch: 30| Step: 10
Training loss: 2.710650777907495
Validation loss: 2.12784593088526
Epoch: 30| Step: 11
Training loss: 2.8145805292988517
Validation loss: 2.0665617286546603
Epoch: 30| Step: 12
Training loss: 3.452275374478471
Validation loss: 2.1193713226562796
Epoch: 30| Step: 13
Training loss: 2.465564265790425
Validation loss: 2.0650687671899863
Epoch: 30| Step: 14
Training loss: 2.6588367208767205
Validation loss: 2.0661887919590605
Epoch: 30| Step: 15
Training loss: 2.576197418016849
Validation loss: 2.05839832594771
Epoch: 30| Step: 16
Training loss: 2.627376116763957
Validation loss: 2.0421243947246586
Epoch: 30| Step: 17
Training loss: 1.6411623120325531
Validation loss: 2.0351448877635505
Epoch: 30| Step: 18
Training loss: 2.7615001543394837
Validation loss: 2.1271455637135803
Epoch: 30| Step: 19
Training loss: 3.300751201786307
Validation loss: 2.0426677876067147
