Epoch: 1| Step: 0
Training loss: 4.964911460876465
Validation loss: 5.456049760182698
Epoch: 1| Step: 1
Training loss: 5.549470901489258
Validation loss: 5.031665722529094
Epoch: 1| Step: 2
Training loss: 5.3669562339782715
Validation loss: 5.017882347106934
Epoch: 1| Step: 3
Training loss: 5.71850061416626
Validation loss: 5.009155511856079
Epoch: 1| Step: 4
Training loss: 5.011629581451416
Validation loss: 4.961409091949463
Epoch: 1| Step: 5
Training loss: 5.477263450622559
Validation loss: 4.906105120976766
Epoch: 1| Step: 6
Training loss: 5.104760646820068
Validation loss: 4.83112374941508
Epoch: 1| Step: 7
Training loss: 5.695334434509277
Validation loss: 4.721071640650432
Epoch: 1| Step: 8
Training loss: 3.8810553550720215
Validation loss: 4.736677169799805
Epoch: 1| Step: 9
Training loss: 4.770986080169678
Validation loss: 4.7667562166849775
Epoch: 1| Step: 10
Training loss: 5.157484531402588
Validation loss: 4.673662980397542
Epoch: 1| Step: 11
Training loss: 4.289439678192139
Validation loss: 4.612426042556763
Epoch: 1| Step: 12
Training loss: 4.6718597412109375
Validation loss: 4.6375157833099365
Epoch: 1| Step: 13
Training loss: 5.7914228439331055
Validation loss: 4.661967833836873
Epoch: 1| Step: 14
Training loss: 4.85087251663208
Validation loss: 4.537658452987671
Epoch: 1| Step: 15
Training loss: 3.3086624145507812
Validation loss: 4.559339801470439
Epoch: 2| Step: 0
Training loss: 5.947628021240234
Validation loss: 4.4515024820963545
Epoch: 2| Step: 1
Training loss: 4.831550598144531
Validation loss: 4.518684943517049
Epoch: 2| Step: 2
Training loss: 5.140471935272217
Validation loss: 4.5065867106119795
Epoch: 2| Step: 3
Training loss: 3.8984909057617188
Validation loss: 4.401218732198079
Epoch: 2| Step: 4
Training loss: 4.815960884094238
Validation loss: 4.4005764325459795
Epoch: 2| Step: 5
Training loss: 5.003446102142334
Validation loss: 4.284883817036946
Epoch: 2| Step: 6
Training loss: 5.156134128570557
Validation loss: 4.301881869633992
Epoch: 2| Step: 7
Training loss: 3.9636199474334717
Validation loss: 4.307835578918457
Epoch: 2| Step: 8
Training loss: 4.7223334312438965
Validation loss: 4.2388505935668945
Epoch: 2| Step: 9
Training loss: 4.200284004211426
Validation loss: 4.16738224029541
Epoch: 2| Step: 10
Training loss: 4.2306647300720215
Validation loss: 4.13592803478241
Epoch: 2| Step: 11
Training loss: 4.061435699462891
Validation loss: 4.164647817611694
Epoch: 2| Step: 12
Training loss: 3.7496044635772705
Validation loss: 4.052645643552144
Epoch: 2| Step: 13
Training loss: 3.5918374061584473
Validation loss: 4.064119219779968
Epoch: 2| Step: 14
Training loss: 4.097315788269043
Validation loss: 4.16586446762085
Epoch: 2| Step: 15
Training loss: 4.082308292388916
Validation loss: 4.124165256818135
Epoch: 3| Step: 0
Training loss: 4.0640435218811035
Validation loss: 4.139304478963216
Epoch: 3| Step: 1
Training loss: 2.8828210830688477
Validation loss: 4.067017753918965
Epoch: 3| Step: 2
Training loss: 4.124490261077881
Validation loss: 4.103578567504883
Epoch: 3| Step: 3
Training loss: 4.336251258850098
Validation loss: 3.9835781256357827
Epoch: 3| Step: 4
Training loss: 4.1421709060668945
Validation loss: 3.999048113822937
Epoch: 3| Step: 5
Training loss: 4.93939208984375
Validation loss: 3.9010492165883384
Epoch: 3| Step: 6
Training loss: 4.069363594055176
Validation loss: 3.717383543650309
Epoch: 3| Step: 7
Training loss: 4.303744316101074
Validation loss: 3.828892389933268
Epoch: 3| Step: 8
Training loss: 4.65390157699585
Validation loss: 3.806804974873861
Epoch: 3| Step: 9
Training loss: 4.103302001953125
Validation loss: 3.8055188258488974
Epoch: 3| Step: 10
Training loss: 3.837070941925049
Validation loss: 3.8516724904378257
Epoch: 3| Step: 11
Training loss: 4.434936046600342
Validation loss: 3.7210360368092856
Epoch: 3| Step: 12
Training loss: 3.8573856353759766
Validation loss: 3.7038262287775674
Epoch: 3| Step: 13
Training loss: 2.9504520893096924
Validation loss: 3.709366202354431
Epoch: 3| Step: 14
Training loss: 4.785269737243652
Validation loss: 3.7269972960154214
Epoch: 3| Step: 15
Training loss: 3.60735821723938
Validation loss: 3.7207771142323813
Epoch: 4| Step: 0
Training loss: 4.325224876403809
Validation loss: 3.591491460800171
Epoch: 4| Step: 1
Training loss: 3.748493194580078
Validation loss: 3.447400609652201
Epoch: 4| Step: 2
Training loss: 2.6319167613983154
Validation loss: 3.5753304958343506
Epoch: 4| Step: 3
Training loss: 4.064344882965088
Validation loss: 3.5133031606674194
Epoch: 4| Step: 4
Training loss: 3.9072048664093018
Validation loss: 3.4513032833735147
Epoch: 4| Step: 5
Training loss: 3.5274555683135986
Validation loss: 3.553551435470581
Epoch: 4| Step: 6
Training loss: 4.115978240966797
Validation loss: 3.5066858927408853
Epoch: 4| Step: 7
Training loss: 3.6363606452941895
Validation loss: 3.4478614727656045
Epoch: 4| Step: 8
Training loss: 4.2334818840026855
Validation loss: 3.301417032877604
Epoch: 4| Step: 9
Training loss: 3.9094314575195312
Validation loss: 3.4852331082026162
Epoch: 4| Step: 10
Training loss: 3.5032944679260254
Validation loss: 3.337616523106893
Epoch: 4| Step: 11
Training loss: 3.067255735397339
Validation loss: 3.361815253893534
Epoch: 4| Step: 12
Training loss: 4.514123439788818
Validation loss: 3.4106737772623696
Epoch: 4| Step: 13
Training loss: 3.3735785484313965
Validation loss: 3.366376757621765
Epoch: 4| Step: 14
Training loss: 3.6538004875183105
Validation loss: 3.3300010363260903
Epoch: 4| Step: 15
Training loss: 3.4302775859832764
Validation loss: 3.2360800902048745
Epoch: 5| Step: 0
Training loss: 4.0458269119262695
Validation loss: 3.2472209135691323
Epoch: 5| Step: 1
Training loss: 4.3981146812438965
Validation loss: 3.135002374649048
Epoch: 5| Step: 2
Training loss: 2.924346446990967
Validation loss: 3.1872513691584268
Epoch: 5| Step: 3
Training loss: 3.7321784496307373
Validation loss: 3.153314153353373
Epoch: 5| Step: 4
Training loss: 3.644951343536377
Validation loss: 3.0091935793558755
Epoch: 5| Step: 5
Training loss: 3.9733543395996094
Validation loss: 3.065334916114807
Epoch: 5| Step: 6
Training loss: 3.233314037322998
Validation loss: 3.0756541093190513
Epoch: 5| Step: 7
Training loss: 2.943829298019409
Validation loss: 3.076797127723694
Epoch: 5| Step: 8
Training loss: 4.2743682861328125
Validation loss: 2.9941604137420654
Epoch: 5| Step: 9
Training loss: 3.5319690704345703
Validation loss: 3.045827110608419
Epoch: 5| Step: 10
Training loss: 3.3693175315856934
Validation loss: 3.0587745110193887
Epoch: 5| Step: 11
Training loss: 3.940047025680542
Validation loss: 2.8064823547999063
Epoch: 5| Step: 12
Training loss: 2.9188194274902344
Validation loss: 2.913122375806173
Epoch: 5| Step: 13
Training loss: 1.7120635509490967
Validation loss: 3.0185038248697915
Epoch: 5| Step: 14
Training loss: 3.4643187522888184
Validation loss: 2.8899248441060386
Epoch: 5| Step: 15
Training loss: 2.9352059364318848
Validation loss: 2.906391461690267
Epoch: 6| Step: 0
Training loss: 3.3367760181427
Validation loss: 2.881858507792155
Epoch: 6| Step: 1
Training loss: 3.1852455139160156
Validation loss: 2.886402408281962
Epoch: 6| Step: 2
Training loss: 3.078892469406128
Validation loss: 2.78769584496816
Epoch: 6| Step: 3
Training loss: 3.362696409225464
Validation loss: 2.660288174947103
Epoch: 6| Step: 4
Training loss: 2.991311550140381
Validation loss: 2.6578482389450073
Epoch: 6| Step: 5
Training loss: 3.2372384071350098
Validation loss: 2.757305939992269
Epoch: 6| Step: 6
Training loss: 3.2568106651306152
Validation loss: 2.6646602948506675
Epoch: 6| Step: 7
Training loss: 2.86360502243042
Validation loss: 2.7045292456944785
Epoch: 6| Step: 8
Training loss: 3.753979206085205
Validation loss: 2.769642432530721
Epoch: 6| Step: 9
Training loss: 3.0013012886047363
Validation loss: 2.750645160675049
Epoch: 6| Step: 10
Training loss: 3.2322936058044434
Validation loss: 2.624342759450277
Epoch: 6| Step: 11
Training loss: 3.6235885620117188
Validation loss: 2.755431572596232
Epoch: 6| Step: 12
Training loss: 3.0575695037841797
Validation loss: 2.7292730808258057
Epoch: 6| Step: 13
Training loss: 3.426884412765503
Validation loss: 2.551768938700358
Epoch: 6| Step: 14
Training loss: 2.8343868255615234
Validation loss: 2.6319947640101113
Epoch: 6| Step: 15
Training loss: 2.782219648361206
Validation loss: 2.68156890074412
Epoch: 7| Step: 0
Training loss: 2.634805202484131
Validation loss: 2.6642545064290366
Epoch: 7| Step: 1
Training loss: 2.7801730632781982
Validation loss: 2.6887364387512207
Epoch: 7| Step: 2
Training loss: 3.331554412841797
Validation loss: 2.623230973879496
Epoch: 7| Step: 3
Training loss: 3.326005220413208
Validation loss: 2.594507892926534
Epoch: 7| Step: 4
Training loss: 2.97282075881958
Validation loss: 2.559179107348124
Epoch: 7| Step: 5
Training loss: 2.9928488731384277
Validation loss: 2.5163336594899497
Epoch: 7| Step: 6
Training loss: 2.7948927879333496
Validation loss: 2.5407204627990723
Epoch: 7| Step: 7
Training loss: 2.9005959033966064
Validation loss: 2.4817035794258118
Epoch: 7| Step: 8
Training loss: 3.170945644378662
Validation loss: 2.6085100173950195
Epoch: 7| Step: 9
Training loss: 2.9793107509613037
Validation loss: 2.4889658292134604
Epoch: 7| Step: 10
Training loss: 3.0523111820220947
Validation loss: 2.511273423830668
Epoch: 7| Step: 11
Training loss: 3.4811203479766846
Validation loss: 2.4457634687423706
Epoch: 7| Step: 12
Training loss: 3.3676953315734863
Validation loss: 2.404878854751587
Epoch: 7| Step: 13
Training loss: 2.8998637199401855
Validation loss: 2.35007776816686
Epoch: 7| Step: 14
Training loss: 2.7461085319519043
Validation loss: 2.469255487124125
Epoch: 7| Step: 15
Training loss: 2.6612789630889893
Validation loss: 2.4680031538009644
Epoch: 8| Step: 0
Training loss: 3.1867566108703613
Validation loss: 2.3445679942766824
Epoch: 8| Step: 1
Training loss: 2.4165682792663574
Validation loss: 2.3733028570810952
Epoch: 8| Step: 2
Training loss: 3.5973334312438965
Validation loss: 2.414889097213745
Epoch: 8| Step: 3
Training loss: 2.260789394378662
Validation loss: 2.351096431414286
Epoch: 8| Step: 4
Training loss: 3.1977639198303223
Validation loss: 2.3177030881245932
Epoch: 8| Step: 5
Training loss: 3.2173659801483154
Validation loss: 2.383777896563212
Epoch: 8| Step: 6
Training loss: 2.566392421722412
Validation loss: 2.3356641928354898
Epoch: 8| Step: 7
Training loss: 2.3823513984680176
Validation loss: 2.328202168146769
Epoch: 8| Step: 8
Training loss: 3.2427124977111816
Validation loss: 2.3068183263142905
Epoch: 8| Step: 9
Training loss: 2.5204954147338867
Validation loss: 2.3693546454111734
Epoch: 8| Step: 10
Training loss: 2.8903019428253174
Validation loss: 2.1777422626813254
Epoch: 8| Step: 11
Training loss: 2.204894542694092
Validation loss: 2.3650967280069985
Epoch: 8| Step: 12
Training loss: 2.543578624725342
Validation loss: 2.2036736210187278
Epoch: 8| Step: 13
Training loss: 3.481677293777466
Validation loss: 2.2854464451471963
Epoch: 8| Step: 14
Training loss: 2.0173535346984863
Validation loss: 2.2300264636675515
Epoch: 8| Step: 15
Training loss: 3.6958580017089844
Validation loss: 2.2069767316182456
Epoch: 9| Step: 0
Training loss: 2.5289504528045654
Validation loss: 2.266686975955963
Epoch: 9| Step: 1
Training loss: 2.733297109603882
Validation loss: 2.302627464135488
Epoch: 9| Step: 2
Training loss: 2.915574550628662
Validation loss: 2.2256768544514975
Epoch: 9| Step: 3
Training loss: 2.9962995052337646
Validation loss: 2.1575682759284973
Epoch: 9| Step: 4
Training loss: 3.248415470123291
Validation loss: 2.2636369268099465
Epoch: 9| Step: 5
Training loss: 2.100233554840088
Validation loss: 2.125028073787689
Epoch: 9| Step: 6
Training loss: 2.6514649391174316
Validation loss: 2.2236328125
Epoch: 9| Step: 7
Training loss: 2.7040529251098633
Validation loss: 2.1599732637405396
Epoch: 9| Step: 8
Training loss: 2.7310454845428467
Validation loss: 2.1119226018587747
Epoch: 9| Step: 9
Training loss: 2.826421022415161
Validation loss: 2.1310964822769165
Epoch: 9| Step: 10
Training loss: 2.555150270462036
Validation loss: 2.123144050439199
Epoch: 9| Step: 11
Training loss: 2.1372578144073486
Validation loss: 2.1285481651624045
Epoch: 9| Step: 12
Training loss: 2.931810140609741
Validation loss: 2.032312293847402
Epoch: 9| Step: 13
Training loss: 2.7927048206329346
Validation loss: 2.055969854195913
Epoch: 9| Step: 14
Training loss: 2.2633070945739746
Validation loss: 2.124538997809092
Epoch: 9| Step: 15
Training loss: 2.933312177658081
Validation loss: 2.1410730878512063
Epoch: 10| Step: 0
Training loss: 2.7081844806671143
Validation loss: 2.097131331761678
Epoch: 10| Step: 1
Training loss: 2.5911858081817627
Validation loss: 2.073615074157715
Epoch: 10| Step: 2
Training loss: 2.824159622192383
Validation loss: 2.089355170726776
Epoch: 10| Step: 3
Training loss: 2.650531053543091
Validation loss: 2.1155375838279724
Epoch: 10| Step: 4
Training loss: 2.8450849056243896
Validation loss: 2.0623534520467124
Epoch: 10| Step: 5
Training loss: 2.704097032546997
Validation loss: 2.0315255920092263
Epoch: 10| Step: 6
Training loss: 2.5858469009399414
Validation loss: 2.0462303956349692
Epoch: 10| Step: 7
Training loss: 2.0894761085510254
Validation loss: 2.0593448678652444
Epoch: 10| Step: 8
Training loss: 3.07055401802063
Validation loss: 2.010954956213633
Epoch: 10| Step: 9
Training loss: 1.9750388860702515
Validation loss: 2.000157276789347
Epoch: 10| Step: 10
Training loss: 2.570323944091797
Validation loss: 1.9229563275973003
Epoch: 10| Step: 11
Training loss: 2.2136850357055664
Validation loss: 2.080867131551107
Epoch: 10| Step: 12
Training loss: 2.234834909439087
Validation loss: 2.0185970862706504
Epoch: 10| Step: 13
Training loss: 2.6904115676879883
Validation loss: 1.9706369042396545
Epoch: 10| Step: 14
Training loss: 2.372337818145752
Validation loss: 2.0212454795837402
Epoch: 10| Step: 15
Training loss: 2.792410135269165
Validation loss: 1.923027475674947
Epoch: 11| Step: 0
Training loss: 2.7026777267456055
Validation loss: 1.9203625520070393
Epoch: 11| Step: 1
Training loss: 2.467697858810425
Validation loss: 1.9817260305086772
Epoch: 11| Step: 2
Training loss: 1.9373668432235718
Validation loss: 1.9208160042762756
Epoch: 11| Step: 3
Training loss: 2.6116878986358643
Validation loss: 1.9679515560468037
Epoch: 11| Step: 4
Training loss: 2.353970766067505
Validation loss: 1.920872171719869
Epoch: 11| Step: 5
Training loss: 2.6100001335144043
Validation loss: 1.9474645853042603
Epoch: 11| Step: 6
Training loss: 2.4673049449920654
Validation loss: 1.9377671877543132
Epoch: 11| Step: 7
Training loss: 1.8593286275863647
Validation loss: 1.9071967204411824
Epoch: 11| Step: 8
Training loss: 3.0260062217712402
Validation loss: 1.895054558912913
Epoch: 11| Step: 9
Training loss: 1.839948296546936
Validation loss: 1.9197148283322651
Epoch: 11| Step: 10
Training loss: 2.315767765045166
Validation loss: 1.8699649969736736
Epoch: 11| Step: 11
Training loss: 2.308041572570801
Validation loss: 1.9340741435686748
Epoch: 11| Step: 12
Training loss: 1.931510329246521
Validation loss: 1.9508009155591328
Epoch: 11| Step: 13
Training loss: 2.5426225662231445
Validation loss: 1.8841025829315186
Epoch: 11| Step: 14
Training loss: 2.8108558654785156
Validation loss: 1.8677889307339985
Epoch: 11| Step: 15
Training loss: 2.9053587913513184
Validation loss: 1.8891041080156963
Epoch: 12| Step: 0
Training loss: 2.2196803092956543
Validation loss: 1.883530040582021
Epoch: 12| Step: 1
Training loss: 2.031149387359619
Validation loss: 1.8623513182004292
Epoch: 12| Step: 2
Training loss: 2.7976889610290527
Validation loss: 1.8632975021998088
Epoch: 12| Step: 3
Training loss: 1.9018961191177368
Validation loss: 1.7451295057932537
Epoch: 12| Step: 4
Training loss: 2.439959764480591
Validation loss: 1.86280357837677
Epoch: 12| Step: 5
Training loss: 2.3429055213928223
Validation loss: 1.8628787000974019
Epoch: 12| Step: 6
Training loss: 2.248396635055542
Validation loss: 1.7899743914604187
Epoch: 12| Step: 7
Training loss: 2.7018799781799316
Validation loss: 1.780973235766093
Epoch: 12| Step: 8
Training loss: 2.237913131713867
Validation loss: 1.7665756344795227
Epoch: 12| Step: 9
Training loss: 2.229276180267334
Validation loss: 1.858612835407257
Epoch: 12| Step: 10
Training loss: 2.106693744659424
Validation loss: 1.7221233248710632
Epoch: 12| Step: 11
Training loss: 2.1150002479553223
Validation loss: 1.7762651443481445
Epoch: 12| Step: 12
Training loss: 2.51350474357605
Validation loss: 1.8015709320704143
Epoch: 12| Step: 13
Training loss: 2.126055955886841
Validation loss: 1.7761122385660808
Epoch: 12| Step: 14
Training loss: 2.637983560562134
Validation loss: 1.7669559717178345
Epoch: 12| Step: 15
Training loss: 2.555032968521118
Validation loss: 1.7738231619199116
Epoch: 13| Step: 0
Training loss: 2.4150002002716064
Validation loss: 1.8008428414662678
Epoch: 13| Step: 1
Training loss: 2.427800416946411
Validation loss: 1.7281658053398132
Epoch: 13| Step: 2
Training loss: 3.166043758392334
Validation loss: 1.8227173288663228
Epoch: 13| Step: 3
Training loss: 1.915047287940979
Validation loss: 1.673771063486735
Epoch: 13| Step: 4
Training loss: 2.3509840965270996
Validation loss: 1.8172119657198589
Epoch: 13| Step: 5
Training loss: 2.1160929203033447
Validation loss: 1.7621978918711345
Epoch: 13| Step: 6
Training loss: 2.7745201587677
Validation loss: 1.6897829174995422
Epoch: 13| Step: 7
Training loss: 1.9864944219589233
Validation loss: 1.8248027761777241
Epoch: 13| Step: 8
Training loss: 2.549999952316284
Validation loss: 1.724726180235545
Epoch: 13| Step: 9
Training loss: 2.548386335372925
Validation loss: 1.8280325333277385
Epoch: 13| Step: 10
Training loss: 1.94638991355896
Validation loss: 1.6643656293551128
Epoch: 13| Step: 11
Training loss: 2.7237892150878906
Validation loss: 1.7683595418930054
Epoch: 13| Step: 12
Training loss: 1.756103277206421
Validation loss: 1.7410919864972432
Epoch: 13| Step: 13
Training loss: 2.2203378677368164
Validation loss: 1.7118550141652424
Epoch: 13| Step: 14
Training loss: 1.6605613231658936
Validation loss: 1.7333377997080486
Epoch: 13| Step: 15
Training loss: 1.830267310142517
Validation loss: 1.7616286873817444
Epoch: 14| Step: 0
Training loss: 2.4549999237060547
Validation loss: 1.725304623444875
Epoch: 14| Step: 1
Training loss: 2.0202903747558594
Validation loss: 1.7658902406692505
Epoch: 14| Step: 2
Training loss: 2.4649999141693115
Validation loss: 1.6784160534540813
Epoch: 14| Step: 3
Training loss: 2.003422737121582
Validation loss: 1.6815996567408245
Epoch: 14| Step: 4
Training loss: 1.880062460899353
Validation loss: 1.629892388979594
Epoch: 14| Step: 5
Training loss: 2.0669941902160645
Validation loss: 1.7023443579673767
Epoch: 14| Step: 6
Training loss: 2.653311252593994
Validation loss: 1.7807219823201497
Epoch: 14| Step: 7
Training loss: 1.9151283502578735
Validation loss: 1.6931296388308208
Epoch: 14| Step: 8
Training loss: 2.593864917755127
Validation loss: 1.6907650232315063
Epoch: 14| Step: 9
Training loss: 2.2224087715148926
Validation loss: 1.67815895875295
Epoch: 14| Step: 10
Training loss: 2.3299999237060547
Validation loss: 1.701579213142395
Epoch: 14| Step: 11
Training loss: 2.496793746948242
Validation loss: 1.7118202249209087
Epoch: 14| Step: 12
Training loss: 2.5964975357055664
Validation loss: 1.675406237443288
Epoch: 14| Step: 13
Training loss: 1.7107549905776978
Validation loss: 1.711941083272298
Epoch: 14| Step: 14
Training loss: 2.105034351348877
Validation loss: 1.7842353582382202
Epoch: 14| Step: 15
Training loss: 2.5030007362365723
Validation loss: 1.7138042847315471
Epoch: 15| Step: 0
Training loss: 2.100647211074829
Validation loss: 1.712159554163615
Epoch: 15| Step: 1
Training loss: 2.1600000858306885
Validation loss: 1.7314131458600361
Epoch: 15| Step: 2
Training loss: 2.641174793243408
Validation loss: 1.6698283751805623
Epoch: 15| Step: 3
Training loss: 2.141054630279541
Validation loss: 1.6997654835383098
Epoch: 15| Step: 4
Training loss: 2.1390697956085205
Validation loss: 1.7462444305419922
Epoch: 15| Step: 5
Training loss: 2.233731746673584
Validation loss: 1.7007277011871338
Epoch: 15| Step: 6
Training loss: 2.001410961151123
Validation loss: 1.6708332896232605
Epoch: 15| Step: 7
Training loss: 2.5555031299591064
Validation loss: 1.6730315486590068
Epoch: 15| Step: 8
Training loss: 1.9147398471832275
Validation loss: 1.695686141649882
Epoch: 15| Step: 9
Training loss: 2.268603801727295
Validation loss: 1.693228006362915
Epoch: 15| Step: 10
Training loss: 1.768803358078003
Validation loss: 1.7104343970616658
Epoch: 15| Step: 11
Training loss: 2.468301296234131
Validation loss: 1.7078726291656494
Epoch: 15| Step: 12
Training loss: 2.167203426361084
Validation loss: 1.6936199466387432
Epoch: 15| Step: 13
Training loss: 2.044785976409912
Validation loss: 1.5784046053886414
Epoch: 15| Step: 14
Training loss: 2.905773878097534
Validation loss: 1.7005491654078166
Epoch: 15| Step: 15
Training loss: 2.4086551666259766
Validation loss: 1.7731091777483623
Epoch: 16| Step: 0
Training loss: 2.2641255855560303
Validation loss: 1.6551457444826763
Epoch: 16| Step: 1
Training loss: 1.7300001382827759
Validation loss: 1.6733017166455586
Epoch: 16| Step: 2
Training loss: 2.525167942047119
Validation loss: 1.6399720509847004
Epoch: 16| Step: 3
Training loss: 2.0848124027252197
Validation loss: 1.6311148405075073
Epoch: 16| Step: 4
Training loss: 2.54331636428833
Validation loss: 1.6783419251441956
Epoch: 16| Step: 5
Training loss: 2.3881728649139404
Validation loss: 1.7023480137189229
Epoch: 16| Step: 6
Training loss: 1.9859634637832642
Validation loss: 1.6324998537699382
Epoch: 16| Step: 7
Training loss: 1.7511695623397827
Validation loss: 1.703661024570465
Epoch: 16| Step: 8
Training loss: 2.5349998474121094
Validation loss: 1.698283572991689
Epoch: 16| Step: 9
Training loss: 2.5764737129211426
Validation loss: 1.6727367838223774
Epoch: 16| Step: 10
Training loss: 2.2658286094665527
Validation loss: 1.7694920698801677
Epoch: 16| Step: 11
Training loss: 2.4405694007873535
Validation loss: 1.704748272895813
Epoch: 16| Step: 12
Training loss: 1.8567163944244385
Validation loss: 1.6783274014790852
Epoch: 16| Step: 13
Training loss: 2.569999933242798
Validation loss: 1.6671400268872578
Epoch: 16| Step: 14
Training loss: 2.262024402618408
Validation loss: 1.7226517001787822
Epoch: 16| Step: 15
Training loss: 2.1544904708862305
Validation loss: 1.691573401292165
Epoch: 17| Step: 0
Training loss: 2.6077849864959717
Validation loss: 1.7561472654342651
Epoch: 17| Step: 1
Training loss: 1.6869789361953735
Validation loss: 1.669667641321818
Epoch: 17| Step: 2
Training loss: 2.148597240447998
Validation loss: 1.6959609985351562
Epoch: 17| Step: 3
Training loss: 1.8328139781951904
Validation loss: 1.6690707206726074
Epoch: 17| Step: 4
Training loss: 2.1792895793914795
Validation loss: 1.7399064302444458
Epoch: 17| Step: 5
Training loss: 2.1099390983581543
Validation loss: 1.636784295241038
Epoch: 17| Step: 6
Training loss: 2.0490176677703857
Validation loss: 1.6501152912775676
Epoch: 17| Step: 7
Training loss: 2.614011287689209
Validation loss: 1.680217444896698
Epoch: 17| Step: 8
Training loss: 2.346492290496826
Validation loss: 1.673483928044637
Epoch: 17| Step: 9
Training loss: 2.2525668144226074
Validation loss: 1.7170913418134053
Epoch: 17| Step: 10
Training loss: 2.184999942779541
Validation loss: 1.756874183813731
Epoch: 17| Step: 11
Training loss: 2.271467924118042
Validation loss: 1.7289374073346455
Epoch: 17| Step: 12
Training loss: 2.765000104904175
Validation loss: 1.7246029178301494
Epoch: 17| Step: 13
Training loss: 2.387054920196533
Validation loss: 1.6289615233739216
Epoch: 17| Step: 14
Training loss: 2.3660876750946045
Validation loss: 1.7058855295181274
Epoch: 17| Step: 15
Training loss: 2.108957052230835
Validation loss: 1.7070677677790325
Epoch: 18| Step: 0
Training loss: 2.2149999141693115
Validation loss: 1.629898488521576
Epoch: 18| Step: 1
Training loss: 2.1500000953674316
Validation loss: 1.6685555577278137
Epoch: 18| Step: 2
Training loss: 2.0865397453308105
Validation loss: 1.7689735690752666
Epoch: 18| Step: 3
Training loss: 2.478224992752075
Validation loss: 1.6915628512700398
Epoch: 18| Step: 4
Training loss: 1.9562556743621826
Validation loss: 1.7377917170524597
Epoch: 18| Step: 5
Training loss: 2.5070724487304688
Validation loss: 1.698139985402425
Epoch: 18| Step: 6
Training loss: 1.9618215560913086
Validation loss: 1.700157642364502
Epoch: 18| Step: 7
Training loss: 1.900292992591858
Validation loss: 1.6764310399691265
Epoch: 18| Step: 8
Training loss: 2.1829395294189453
Validation loss: 1.683691640694936
Epoch: 18| Step: 9
Training loss: 2.0375866889953613
Validation loss: 1.738792876402537
Epoch: 18| Step: 10
Training loss: 2.413106679916382
Validation loss: 1.726042906443278
Epoch: 18| Step: 11
Training loss: 1.7389720678329468
Validation loss: 1.6742962797482808
Epoch: 18| Step: 12
Training loss: 2.511955976486206
Validation loss: 1.693344235420227
Epoch: 18| Step: 13
Training loss: 2.5675129890441895
Validation loss: 1.7019829154014587
Epoch: 18| Step: 14
Training loss: 2.315000057220459
Validation loss: 1.6590845982233684
Epoch: 18| Step: 15
Training loss: 2.8650002479553223
Validation loss: 1.6972304582595825
Epoch: 19| Step: 0
Training loss: 2.2699999809265137
Validation loss: 1.7219904859860737
Epoch: 19| Step: 1
Training loss: 2.5523974895477295
Validation loss: 1.5922029217084248
Epoch: 19| Step: 2
Training loss: 2.304763078689575
Validation loss: 1.7352039615313213
Epoch: 19| Step: 3
Training loss: 2.3194990158081055
Validation loss: 1.7374860644340515
Epoch: 19| Step: 4
Training loss: 2.1239237785339355
Validation loss: 1.6701503992080688
Epoch: 19| Step: 5
Training loss: 2.2850003242492676
Validation loss: 1.7129733562469482
Epoch: 19| Step: 6
Training loss: 2.36625337600708
Validation loss: 1.6614600817362468
Epoch: 19| Step: 7
Training loss: 2.4650001525878906
Validation loss: 1.712171157201131
Epoch: 19| Step: 8
Training loss: 2.7209999561309814
Validation loss: 1.6661454637845357
Epoch: 19| Step: 9
Training loss: 2.017493724822998
Validation loss: 1.6734812657038372
Epoch: 19| Step: 10
Training loss: 1.9682762622833252
Validation loss: 1.7012128035227458
Epoch: 19| Step: 11
Training loss: 1.6369926929473877
Validation loss: 1.7504755059878032
Epoch: 19| Step: 12
Training loss: 2.367391347885132
Validation loss: 1.6684341231981914
Epoch: 19| Step: 13
Training loss: 2.3716931343078613
Validation loss: 1.6723304788271587
Epoch: 19| Step: 14
Training loss: 2.293971300125122
Validation loss: 1.5879727800687153
Epoch: 19| Step: 15
Training loss: 1.8271316289901733
Validation loss: 1.7396488587061565
Epoch: 20| Step: 0
Training loss: 2.418386459350586
Validation loss: 1.701805015405019
Epoch: 20| Step: 1
Training loss: 2.049893617630005
Validation loss: 1.6755142013231914
Epoch: 20| Step: 2
Training loss: 2.5749056339263916
Validation loss: 1.647554914156596
Epoch: 20| Step: 3
Training loss: 2.122243881225586
Validation loss: 1.7289217114448547
Epoch: 20| Step: 4
Training loss: 2.2950000762939453
Validation loss: 1.651163379351298
Epoch: 20| Step: 5
Training loss: 2.181452751159668
Validation loss: 1.6724183162053425
Epoch: 20| Step: 6
Training loss: 2.121617317199707
Validation loss: 1.6814902822176616
Epoch: 20| Step: 7
Training loss: 1.9049999713897705
Validation loss: 1.7176169157028198
Epoch: 20| Step: 8
Training loss: 2.14644718170166
Validation loss: 1.7668049136797588
Epoch: 20| Step: 9
Training loss: 2.186932325363159
Validation loss: 1.724519948164622
Epoch: 20| Step: 10
Training loss: 2.7799999713897705
Validation loss: 1.6754361192385356
Epoch: 20| Step: 11
Training loss: 2.168743133544922
Validation loss: 1.6051632761955261
Epoch: 20| Step: 12
Training loss: 1.9293243885040283
Validation loss: 1.6695976654688518
Epoch: 20| Step: 13
Training loss: 2.6050000190734863
Validation loss: 1.7657436927159627
Epoch: 20| Step: 14
Training loss: 2.1904101371765137
Validation loss: 1.6639912128448486
Epoch: 20| Step: 15
Training loss: 2.207399845123291
Validation loss: 1.6633006930351257
Epoch: 21| Step: 0
Training loss: 2.299999713897705
Validation loss: 1.70922456185023
Epoch: 21| Step: 1
Training loss: 2.7949306964874268
Validation loss: 1.640889565149943
Epoch: 21| Step: 2
Training loss: 1.9423720836639404
Validation loss: 1.6764535307884216
Epoch: 21| Step: 3
Training loss: 2.1505448818206787
Validation loss: 1.6628793080647786
Epoch: 21| Step: 4
Training loss: 1.8349997997283936
Validation loss: 1.6192550857861836
Epoch: 21| Step: 5
Training loss: 2.9744210243225098
Validation loss: 1.7739726901054382
Epoch: 21| Step: 6
Training loss: 2.0350000858306885
Validation loss: 1.668839951356252
Epoch: 21| Step: 7
Training loss: 2.743034839630127
Validation loss: 1.6977086861928303
Epoch: 21| Step: 8
Training loss: 2.0850000381469727
Validation loss: 1.6582021713256836
Epoch: 21| Step: 9
Training loss: 1.8049999475479126
Validation loss: 1.6558211048444111
Epoch: 21| Step: 10
Training loss: 2.4331538677215576
Validation loss: 1.6177647511164348
Epoch: 21| Step: 11
Training loss: 2.4618754386901855
Validation loss: 1.7286467750867207
Epoch: 21| Step: 12
Training loss: 2.125
Validation loss: 1.6710053086280823
Epoch: 21| Step: 13
Training loss: 1.706382155418396
Validation loss: 1.6315916379292805
Epoch: 21| Step: 14
Training loss: 2.240000009536743
Validation loss: 1.7239746848742168
Epoch: 21| Step: 15
Training loss: 2.2480103969573975
Validation loss: 1.6286562879880269
Epoch: 22| Step: 0
Training loss: 2.2807424068450928
Validation loss: 1.6580552458763123
Epoch: 22| Step: 1
Training loss: 2.412135362625122
Validation loss: 1.6783118446667988
Epoch: 22| Step: 2
Training loss: 2.2699999809265137
Validation loss: 1.701684792836507
Epoch: 22| Step: 3
Training loss: 2.8326449394226074
Validation loss: 1.702129065990448
Epoch: 22| Step: 4
Training loss: 1.8469905853271484
Validation loss: 1.730558196703593
Epoch: 22| Step: 5
Training loss: 2.0330536365509033
Validation loss: 1.6884969472885132
Epoch: 22| Step: 6
Training loss: 3.0466740131378174
Validation loss: 1.6642990310986836
Epoch: 22| Step: 7
Training loss: 2.3276634216308594
Validation loss: 1.6635978817939758
Epoch: 22| Step: 8
Training loss: 2.32389760017395
Validation loss: 1.7282066543896992
Epoch: 22| Step: 9
Training loss: 2.119222640991211
Validation loss: 1.6891149481137593
Epoch: 22| Step: 10
Training loss: 1.7649999856948853
Validation loss: 1.6451704303423564
Epoch: 22| Step: 11
Training loss: 2.360339641571045
Validation loss: 1.7487703561782837
Epoch: 22| Step: 12
Training loss: 1.9849103689193726
Validation loss: 1.6781839927037556
Epoch: 22| Step: 13
Training loss: 2.314854383468628
Validation loss: 1.6511057217915852
Epoch: 22| Step: 14
Training loss: 2.0610363483428955
Validation loss: 1.6808162728945415
Epoch: 22| Step: 15
Training loss: 1.9116054773330688
Validation loss: 1.7757867177327473
Epoch: 23| Step: 0
Training loss: 1.5953974723815918
Validation loss: 1.6813434958457947
Epoch: 23| Step: 1
Training loss: 2.489778518676758
Validation loss: 1.615059773127238
Epoch: 23| Step: 2
Training loss: 2.2939674854278564
Validation loss: 1.6835643450419109
Epoch: 23| Step: 3
Training loss: 2.166008710861206
Validation loss: 1.6968043843905132
Epoch: 23| Step: 4
Training loss: 2.6613893508911133
Validation loss: 1.7170785466829936
Epoch: 23| Step: 5
Training loss: 2.635000228881836
Validation loss: 1.709291398525238
Epoch: 23| Step: 6
Training loss: 2.3438408374786377
Validation loss: 1.7082728544871013
Epoch: 23| Step: 7
Training loss: 1.9399999380111694
Validation loss: 1.6679805517196655
Epoch: 23| Step: 8
Training loss: 2.2478911876678467
Validation loss: 1.7188390692075093
Epoch: 23| Step: 9
Training loss: 2.017746686935425
Validation loss: 1.735274871190389
Epoch: 23| Step: 10
Training loss: 2.2124478816986084
Validation loss: 1.6922491192817688
Epoch: 23| Step: 11
Training loss: 2.8051178455352783
Validation loss: 1.6921360492706299
Epoch: 23| Step: 12
Training loss: 2.2625300884246826
Validation loss: 1.673293133576711
Epoch: 23| Step: 13
Training loss: 1.8798795938491821
Validation loss: 1.703518768151601
Epoch: 23| Step: 14
Training loss: 2.300541639328003
Validation loss: 1.6610243916511536
Epoch: 23| Step: 15
Training loss: 2.0371687412261963
Validation loss: 1.6468575596809387
Epoch: 24| Step: 0
Training loss: 2.615000009536743
Validation loss: 1.6182511448860168
Epoch: 24| Step: 1
Training loss: 2.329174757003784
Validation loss: 1.7363246480623882
Epoch: 24| Step: 2
Training loss: 2.447960376739502
Validation loss: 1.7239100337028503
Epoch: 24| Step: 3
Training loss: 2.3765788078308105
Validation loss: 1.682816704114278
Epoch: 24| Step: 4
Training loss: 2.2378180027008057
Validation loss: 1.662500540415446
Epoch: 24| Step: 5
Training loss: 1.7400001287460327
Validation loss: 1.7385810216267903
Epoch: 24| Step: 6
Training loss: 2.7761311531066895
Validation loss: 1.824850340684255
Epoch: 24| Step: 7
Training loss: 2.0160412788391113
Validation loss: 1.7293574213981628
Epoch: 24| Step: 8
Training loss: 2.0335476398468018
Validation loss: 1.6984352270762126
Epoch: 24| Step: 9
Training loss: 2.4874980449676514
Validation loss: 1.6925997535387676
Epoch: 24| Step: 10
Training loss: 2.5257675647735596
Validation loss: 1.7067253788312275
Epoch: 24| Step: 11
Training loss: 2.1838064193725586
Validation loss: 1.7388525207837422
Epoch: 24| Step: 12
Training loss: 1.6600000858306885
Validation loss: 1.6255575219790142
Epoch: 24| Step: 13
Training loss: 2.1435585021972656
Validation loss: 1.6673363248507183
Epoch: 24| Step: 14
Training loss: 1.9886443614959717
Validation loss: 1.672414779663086
Epoch: 24| Step: 15
Training loss: 2.3790717124938965
Validation loss: 1.7563897172609966
Epoch: 25| Step: 0
Training loss: 1.7450001239776611
Validation loss: 1.6778714060783386
Epoch: 25| Step: 1
Training loss: 2.2116026878356934
Validation loss: 1.6881248156229656
Epoch: 25| Step: 2
Training loss: 1.9450000524520874
Validation loss: 1.746505856513977
Epoch: 25| Step: 3
Training loss: 1.8777786493301392
Validation loss: 1.6708674629529316
Epoch: 25| Step: 4
Training loss: 2.4473061561584473
Validation loss: 1.7590803503990173
Epoch: 25| Step: 5
Training loss: 2.4700000286102295
Validation loss: 1.679971953233083
Epoch: 25| Step: 6
Training loss: 2.211561679840088
Validation loss: 1.6967666844526927
Epoch: 25| Step: 7
Training loss: 2.734999895095825
Validation loss: 1.7172813415527344
Epoch: 25| Step: 8
Training loss: 2.0250000953674316
Validation loss: 1.70170791943868
Epoch: 25| Step: 9
Training loss: 2.76749849319458
Validation loss: 1.771886686484019
Epoch: 25| Step: 10
Training loss: 2.2916839122772217
Validation loss: 1.6970731417338054
Epoch: 25| Step: 11
Training loss: 2.799999952316284
Validation loss: 1.6389355858167012
Epoch: 25| Step: 12
Training loss: 2.3461642265319824
Validation loss: 1.7114726901054382
Epoch: 25| Step: 13
Training loss: 2.1987767219543457
Validation loss: 1.72668453057607
Epoch: 25| Step: 14
Training loss: 1.6170079708099365
Validation loss: 1.7451329231262207
Epoch: 25| Step: 15
Training loss: 2.1886556148529053
Validation loss: 1.7238674362500508
Epoch: 26| Step: 0
Training loss: 2.3015224933624268
Validation loss: 1.7013126611709595
Epoch: 26| Step: 1
Training loss: 2.25984263420105
Validation loss: 1.6291462779045105
Epoch: 26| Step: 2
Training loss: 1.895181655883789
Validation loss: 1.7301666339238484
Epoch: 26| Step: 3
Training loss: 1.53000009059906
Validation loss: 1.7194361488024394
Epoch: 26| Step: 4
Training loss: 2.6494810581207275
Validation loss: 1.6465272307395935
Epoch: 26| Step: 5
Training loss: 2.2100000381469727
Validation loss: 1.6843698422114055
Epoch: 26| Step: 6
Training loss: 2.6093461513519287
Validation loss: 1.6977241436640422
Epoch: 26| Step: 7
Training loss: 2.1558899879455566
Validation loss: 1.7036866744359334
Epoch: 26| Step: 8
Training loss: 2.5351755619049072
Validation loss: 1.7118923862775166
Epoch: 26| Step: 9
Training loss: 2.8324782848358154
Validation loss: 1.6380962332089741
Epoch: 26| Step: 10
Training loss: 2.3650002479553223
Validation loss: 1.7114118536313374
Epoch: 26| Step: 11
Training loss: 2.0550804138183594
Validation loss: 1.734497308731079
Epoch: 26| Step: 12
Training loss: 1.8653061389923096
Validation loss: 1.6731858650843303
Epoch: 26| Step: 13
Training loss: 2.2711730003356934
Validation loss: 1.68613334496816
Epoch: 26| Step: 14
Training loss: 2.054999828338623
Validation loss: 1.7034948468208313
Epoch: 26| Step: 15
Training loss: 2.2974207401275635
Validation loss: 1.7068379124005635
Epoch: 27| Step: 0
Training loss: 2.6027820110321045
Validation loss: 1.7100219527880351
Epoch: 27| Step: 1
Training loss: 2.2753214836120605
Validation loss: 1.6680097381273906
Epoch: 27| Step: 2
Training loss: 2.309915542602539
Validation loss: 1.701949119567871
Epoch: 27| Step: 3
Training loss: 2.325000047683716
Validation loss: 1.6282873849074047
Epoch: 27| Step: 4
Training loss: 2.5299999713897705
Validation loss: 1.693073570728302
Epoch: 27| Step: 5
Training loss: 2.1712634563446045
Validation loss: 1.7589661478996277
Epoch: 27| Step: 6
Training loss: 2.65651273727417
Validation loss: 1.667730708916982
Epoch: 27| Step: 7
Training loss: 2.319995403289795
Validation loss: 1.6682721972465515
Epoch: 27| Step: 8
Training loss: 1.645969033241272
Validation loss: 1.697239100933075
Epoch: 27| Step: 9
Training loss: 2.5249335765838623
Validation loss: 1.7639365593592327
Epoch: 27| Step: 10
Training loss: 2.129999876022339
Validation loss: 1.764935811360677
Epoch: 27| Step: 11
Training loss: 2.309999942779541
Validation loss: 1.6530488928159077
Epoch: 27| Step: 12
Training loss: 1.9095834493637085
Validation loss: 1.7942593495051067
Epoch: 27| Step: 13
Training loss: 1.788182020187378
Validation loss: 1.759167234102885
Epoch: 27| Step: 14
Training loss: 2.076202869415283
Validation loss: 1.6867195566495259
Epoch: 27| Step: 15
Training loss: 2.3228888511657715
Validation loss: 1.7247113188107808
Epoch: 28| Step: 0
Training loss: 2.2950000762939453
Validation loss: 1.6714846690495808
Epoch: 28| Step: 1
Training loss: 2.1297852993011475
Validation loss: 1.6933528085549672
Epoch: 28| Step: 2
Training loss: 2.140918493270874
Validation loss: 1.7352583209673564
Epoch: 28| Step: 3
Training loss: 2.7912724018096924
Validation loss: 1.6455149451891582
Epoch: 28| Step: 4
Training loss: 1.9505335092544556
Validation loss: 1.6086893677711487
Epoch: 28| Step: 5
Training loss: 2.9182331562042236
Validation loss: 1.6898679931958516
Epoch: 28| Step: 6
Training loss: 2.566187620162964
Validation loss: 1.643154223759969
Epoch: 28| Step: 7
Training loss: 2.1111702919006348
Validation loss: 1.7467554012934368
Epoch: 28| Step: 8
Training loss: 2.118990421295166
Validation loss: 1.7078441381454468
Epoch: 28| Step: 9
Training loss: 1.926261305809021
Validation loss: 1.6337462266286213
Epoch: 28| Step: 10
Training loss: 2.318850517272949
Validation loss: 1.7232072154680889
Epoch: 28| Step: 11
Training loss: 1.9006555080413818
Validation loss: 1.7283966342608135
Epoch: 28| Step: 12
Training loss: 2.1177382469177246
Validation loss: 1.6538466215133667
Epoch: 28| Step: 13
Training loss: 2.0199999809265137
Validation loss: 1.7386877338091533
Epoch: 28| Step: 14
Training loss: 2.2329516410827637
Validation loss: 1.6970281799634297
Epoch: 28| Step: 15
Training loss: 2.343055248260498
Validation loss: 1.7182203729947407
Epoch: 29| Step: 0
Training loss: 2.6533989906311035
Validation loss: 1.7721675435702007
Epoch: 29| Step: 1
Training loss: 2.1542537212371826
Validation loss: 1.6535322864850361
Epoch: 29| Step: 2
Training loss: 2.495000123977661
Validation loss: 1.6746747295061748
Epoch: 29| Step: 3
Training loss: 2.0034232139587402
Validation loss: 1.6755385001500447
Epoch: 29| Step: 4
Training loss: 2.3487954139709473
Validation loss: 1.6611000299453735
Epoch: 29| Step: 5
Training loss: 1.6374247074127197
Validation loss: 1.75417160987854
Epoch: 29| Step: 6
Training loss: 2.7390646934509277
Validation loss: 1.6502578457196553
Epoch: 29| Step: 7
Training loss: 2.3062145709991455
Validation loss: 1.6379554867744446
Epoch: 29| Step: 8
Training loss: 2.034740447998047
Validation loss: 1.7400987943013508
Epoch: 29| Step: 9
Training loss: 1.8549998998641968
Validation loss: 1.6925980647404988
Epoch: 29| Step: 10
Training loss: 2.7472872734069824
Validation loss: 1.7535395224889119
Epoch: 29| Step: 11
Training loss: 2.225733518600464
Validation loss: 1.7086938619613647
Epoch: 29| Step: 12
Training loss: 2.8235926628112793
Validation loss: 1.7228870789210002
Epoch: 29| Step: 13
Training loss: 2.0850000381469727
Validation loss: 1.7428372303644817
Epoch: 29| Step: 14
Training loss: 1.6264995336532593
Validation loss: 1.6305423180262248
Epoch: 29| Step: 15
Training loss: 2.1500000953674316
Validation loss: 1.781159222126007
Epoch: 30| Step: 0
Training loss: 2.504999876022339
Validation loss: 1.75428307056427
Epoch: 30| Step: 1
Training loss: 2.7235889434814453
Validation loss: 1.6545499165852864
Epoch: 30| Step: 2
Training loss: 2.642080783843994
Validation loss: 1.7215498685836792
Epoch: 30| Step: 3
Training loss: 2.5116477012634277
Validation loss: 1.6662575205167134
Epoch: 30| Step: 4
Training loss: 2.7569799423217773
Validation loss: 1.7212975025177002
Epoch: 30| Step: 5
Training loss: 1.9765428304672241
Validation loss: 1.701914628346761
Epoch: 30| Step: 6
Training loss: 1.8087116479873657
Validation loss: 1.6480096181233723
Epoch: 30| Step: 7
Training loss: 2.243868589401245
Validation loss: 1.6958594123522441
Epoch: 30| Step: 8
Training loss: 1.994999885559082
Validation loss: 1.7285830179850261
Epoch: 30| Step: 9
Training loss: 2.0529983043670654
Validation loss: 1.735832651456197
Epoch: 30| Step: 10
Training loss: 1.8956369161605835
Validation loss: 1.6481820146242778
Epoch: 30| Step: 11
Training loss: 2.2293894290924072
Validation loss: 1.6744719942410786
Epoch: 30| Step: 12
Training loss: 2.066579580307007
Validation loss: 1.595393717288971
Epoch: 30| Step: 13
Training loss: 1.7301645278930664
Validation loss: 1.7412790457407634
Epoch: 30| Step: 14
Training loss: 2.67557954788208
Validation loss: 1.6462788383165996
Epoch: 30| Step: 15
Training loss: 2.068727970123291
Validation loss: 1.6150147914886475
