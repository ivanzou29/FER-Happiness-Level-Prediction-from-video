Epoch: 1| Step: 0
Training loss: 5.935690513748169
Validation loss: 5.67390752135704
Epoch: 1| Step: 1
Training loss: 6.9884493761218005
Validation loss: 5.3437944919687155
Epoch: 1| Step: 2
Training loss: 5.746095741629499
Validation loss: 5.356477908270561
Epoch: 1| Step: 3
Training loss: 6.020289765034609
Validation loss: 5.2380405231364495
Epoch: 1| Step: 4
Training loss: 5.4028041199360946
Validation loss: 5.261520220115742
Epoch: 1| Step: 5
Training loss: 5.559498180549324
Validation loss: 5.084588811439298
Epoch: 1| Step: 6
Training loss: 5.4925514415334
Validation loss: 5.1868967648068125
Epoch: 1| Step: 7
Training loss: 5.652137568047576
Validation loss: 5.091856157186186
Epoch: 1| Step: 8
Training loss: 4.326327064090106
Validation loss: 5.015932296260581
Epoch: 1| Step: 9
Training loss: 4.4847533169442855
Validation loss: 5.006129143470415
Epoch: 1| Step: 10
Training loss: 4.726856266697309
Validation loss: 4.963167537787482
Epoch: 1| Step: 11
Training loss: 6.263180377115072
Validation loss: 4.991783806687084
Epoch: 1| Step: 12
Training loss: 4.169049738641481
Validation loss: 4.8593472071325605
Epoch: 1| Step: 13
Training loss: 5.616808373147439
Validation loss: 4.869676589055626
Epoch: 1| Step: 14
Training loss: 5.577451008060443
Validation loss: 4.80938618374473
Epoch: 1| Step: 15
Training loss: 4.745869095120258
Validation loss: 4.721261763553199
Epoch: 1| Step: 16
Training loss: 5.568078833142527
Validation loss: 4.704655704441379
Epoch: 1| Step: 17
Training loss: 4.702838065180384
Validation loss: 4.604006023421547
Epoch: 1| Step: 18
Training loss: 5.29772042248406
Validation loss: 4.633695843017511
Epoch: 1| Step: 19
Training loss: 4.662260745866877
Validation loss: 4.620905244030431
Epoch: 2| Step: 0
Training loss: 5.086145259053403
Validation loss: 4.531505341907243
Epoch: 2| Step: 1
Training loss: 4.379427604027268
Validation loss: 4.497844027162463
Epoch: 2| Step: 2
Training loss: 6.086605637666741
Validation loss: 4.420480988248251
Epoch: 2| Step: 3
Training loss: 4.58352831801452
Validation loss: 4.303187566723535
Epoch: 2| Step: 4
Training loss: 3.846223856949004
Validation loss: 4.294270102667777
Epoch: 2| Step: 5
Training loss: 5.214900807272128
Validation loss: 4.302341568121172
Epoch: 2| Step: 6
Training loss: 4.651286917183449
Validation loss: 4.200633855090713
Epoch: 2| Step: 7
Training loss: 3.772896485017541
Validation loss: 4.214251544173353
Epoch: 2| Step: 8
Training loss: 4.711555098859076
Validation loss: 4.147914088348291
Epoch: 2| Step: 9
Training loss: 4.564843190101904
Validation loss: 4.039773184132534
Epoch: 2| Step: 10
Training loss: 4.749001046594089
Validation loss: 4.034127976086047
Epoch: 2| Step: 11
Training loss: 4.9951858232393525
Validation loss: 4.015655867418868
Epoch: 2| Step: 12
Training loss: 3.753807677881158
Validation loss: 4.014163888149614
Epoch: 2| Step: 13
Training loss: 4.854675571904601
Validation loss: 3.985456510213873
Epoch: 2| Step: 14
Training loss: 4.651295733658861
Validation loss: 3.9033634489506284
Epoch: 2| Step: 15
Training loss: 3.975819576391277
Validation loss: 3.8552286785102403
Epoch: 2| Step: 16
Training loss: 4.2266396675892155
Validation loss: 3.88662701342975
Epoch: 2| Step: 17
Training loss: 4.35629196256242
Validation loss: 3.844406718299153
Epoch: 2| Step: 18
Training loss: 4.466106353081087
Validation loss: 3.8270638240543047
Epoch: 2| Step: 19
Training loss: 3.489339260087053
Validation loss: 3.6216274881775274
Epoch: 3| Step: 0
Training loss: 4.344609237324898
Validation loss: 3.6827281947330723
Epoch: 3| Step: 1
Training loss: 4.563686686828655
Validation loss: 3.6902720168789163
Epoch: 3| Step: 2
Training loss: 3.6156847738667937
Validation loss: 3.6071428308084057
Epoch: 3| Step: 3
Training loss: 4.369581518322283
Validation loss: 3.5852961340676446
Epoch: 3| Step: 4
Training loss: 3.9331786647925986
Validation loss: 3.603830727652219
Epoch: 3| Step: 5
Training loss: 4.214856647121718
Validation loss: 3.51262946509835
Epoch: 3| Step: 6
Training loss: 4.429881688727482
Validation loss: 3.5280208553791055
Epoch: 3| Step: 7
Training loss: 3.296510504510437
Validation loss: 3.4079948200552153
Epoch: 3| Step: 8
Training loss: 4.184740210414753
Validation loss: 3.4306290160109416
Epoch: 3| Step: 9
Training loss: 4.5035581297055245
Validation loss: 3.3503785645202475
Epoch: 3| Step: 10
Training loss: 4.064278316084028
Validation loss: 3.367757454039919
Epoch: 3| Step: 11
Training loss: 3.882687603114171
Validation loss: 3.2460667572209307
Epoch: 3| Step: 12
Training loss: 4.121562565898902
Validation loss: 3.276753599320151
Epoch: 3| Step: 13
Training loss: 3.6887797058626024
Validation loss: 3.2369373865422544
Epoch: 3| Step: 14
Training loss: 3.7680148696687006
Validation loss: 3.1390892112297117
Epoch: 3| Step: 15
Training loss: 3.5522181391189567
Validation loss: 3.1639570671794397
Epoch: 3| Step: 16
Training loss: 3.420669412964089
Validation loss: 3.2266454185280997
Epoch: 3| Step: 17
Training loss: 3.1397099466661462
Validation loss: 3.150331591746774
Epoch: 3| Step: 18
Training loss: 3.1714850124899288
Validation loss: 3.0568072911620257
Epoch: 3| Step: 19
Training loss: 2.62051662680423
Validation loss: 3.070247247908159
Epoch: 4| Step: 0
Training loss: 3.4748004005246584
Validation loss: 3.0389534356751535
Epoch: 4| Step: 1
Training loss: 3.2214655115512656
Validation loss: 2.9884505612427064
Epoch: 4| Step: 2
Training loss: 3.573174262515437
Validation loss: 2.8916813971391253
Epoch: 4| Step: 3
Training loss: 3.562437090401919
Validation loss: 2.8923450278257583
Epoch: 4| Step: 4
Training loss: 3.5240321027698567
Validation loss: 2.8955636013446955
Epoch: 4| Step: 5
Training loss: 3.56550364442435
Validation loss: 2.99176003191378
Epoch: 4| Step: 6
Training loss: 3.0609421173574956
Validation loss: 2.8883817714134477
Epoch: 4| Step: 7
Training loss: 2.5071435909712654
Validation loss: 2.8948273259614856
Epoch: 4| Step: 8
Training loss: 3.6279534771679636
Validation loss: 2.8412707785162485
Epoch: 4| Step: 9
Training loss: 3.860851545932452
Validation loss: 2.8697042731746665
Epoch: 4| Step: 10
Training loss: 4.14053171880481
Validation loss: 2.743210619005569
Epoch: 4| Step: 11
Training loss: 3.0491359049484337
Validation loss: 2.756326944689017
Epoch: 4| Step: 12
Training loss: 3.32816540330889
Validation loss: 2.8101196714946575
Epoch: 4| Step: 13
Training loss: 2.8275774852547593
Validation loss: 2.7347162670108647
Epoch: 4| Step: 14
Training loss: 3.372722987896928
Validation loss: 2.6856232499811092
Epoch: 4| Step: 15
Training loss: 3.5803194604622703
Validation loss: 2.7073988871403514
Epoch: 4| Step: 16
Training loss: 3.323575487666377
Validation loss: 2.695968281638387
Epoch: 4| Step: 17
Training loss: 3.0949183868346175
Validation loss: 2.707047379831067
Epoch: 4| Step: 18
Training loss: 3.4115419489196204
Validation loss: 2.596609100563546
Epoch: 4| Step: 19
Training loss: 2.6251735629876602
Validation loss: 2.7148035352734072
Epoch: 5| Step: 0
Training loss: 2.8823599111191096
Validation loss: 2.697592624312205
Epoch: 5| Step: 1
Training loss: 3.496544630929098
Validation loss: 2.58835332355945
Epoch: 5| Step: 2
Training loss: 3.316001049579965
Validation loss: 2.568398567770382
Epoch: 5| Step: 3
Training loss: 3.780514984573396
Validation loss: 2.5632299393179983
Epoch: 5| Step: 4
Training loss: 2.5468964371042313
Validation loss: 2.555637576460369
Epoch: 5| Step: 5
Training loss: 3.3351812644551213
Validation loss: 2.552902614204652
Epoch: 5| Step: 6
Training loss: 3.0613471216174823
Validation loss: 2.485448525164583
Epoch: 5| Step: 7
Training loss: 2.6951961768660206
Validation loss: 2.4288422058236625
Epoch: 5| Step: 8
Training loss: 3.089784797655849
Validation loss: 2.47162540966849
Epoch: 5| Step: 9
Training loss: 2.8571556942515133
Validation loss: 2.5092815008730907
Epoch: 5| Step: 10
Training loss: 2.9286871664590493
Validation loss: 2.4896012591214625
Epoch: 5| Step: 11
Training loss: 2.7482063339374725
Validation loss: 2.4529567309374176
Epoch: 5| Step: 12
Training loss: 3.158883233289128
Validation loss: 2.415668790911835
Epoch: 5| Step: 13
Training loss: 3.249489083845378
Validation loss: 2.3606982977707602
Epoch: 5| Step: 14
Training loss: 3.0706647132185987
Validation loss: 2.4225303987169466
Epoch: 5| Step: 15
Training loss: 3.0876484823623893
Validation loss: 2.409757490923583
Epoch: 5| Step: 16
Training loss: 2.5911131174651563
Validation loss: 2.357319997721545
Epoch: 5| Step: 17
Training loss: 2.7112316664572282
Validation loss: 2.3405792674279553
Epoch: 5| Step: 18
Training loss: 3.172909121755912
Validation loss: 2.4141290005775966
Epoch: 5| Step: 19
Training loss: 2.3972628323192344
Validation loss: 2.3024285777754514
Epoch: 6| Step: 0
Training loss: 2.8839871460923128
Validation loss: 2.3347968802364063
Epoch: 6| Step: 1
Training loss: 2.6338898127107955
Validation loss: 2.2811946142649537
Epoch: 6| Step: 2
Training loss: 2.6103297331496993
Validation loss: 2.2779220801007165
Epoch: 6| Step: 3
Training loss: 3.045042768406674
Validation loss: 2.336795315927423
Epoch: 6| Step: 4
Training loss: 3.1072840728990943
Validation loss: 2.3405252371604672
Epoch: 6| Step: 5
Training loss: 3.250237382875895
Validation loss: 2.3109028019688984
Epoch: 6| Step: 6
Training loss: 2.469807941367594
Validation loss: 2.314216526881202
Epoch: 6| Step: 7
Training loss: 2.4949231096548043
Validation loss: 2.302500444783897
Epoch: 6| Step: 8
Training loss: 2.943676886490864
Validation loss: 2.267474322021637
Epoch: 6| Step: 9
Training loss: 3.013581210915464
Validation loss: 2.2368185124465843
Epoch: 6| Step: 10
Training loss: 3.2455084648345167
Validation loss: 2.239256719757801
Epoch: 6| Step: 11
Training loss: 2.846764946997231
Validation loss: 2.2562889913323723
Epoch: 6| Step: 12
Training loss: 3.140953692036866
Validation loss: 2.2096079989368245
Epoch: 6| Step: 13
Training loss: 2.8795718454948642
Validation loss: 2.222781827529682
Epoch: 6| Step: 14
Training loss: 2.3692724532443785
Validation loss: 2.1890432276446945
Epoch: 6| Step: 15
Training loss: 2.310816280752828
Validation loss: 2.206539804933095
Epoch: 6| Step: 16
Training loss: 3.041118485334911
Validation loss: 2.1860374149726884
Epoch: 6| Step: 17
Training loss: 2.7009102452606792
Validation loss: 2.2306778629140256
Epoch: 6| Step: 18
Training loss: 2.0962611839255407
Validation loss: 2.203473019345811
Epoch: 6| Step: 19
Training loss: 3.064759646974879
Validation loss: 2.2142940850496458
Epoch: 7| Step: 0
Training loss: 2.1865549498413106
Validation loss: 2.1751539165094433
Epoch: 7| Step: 1
Training loss: 2.754767706574821
Validation loss: 2.2160726507992345
Epoch: 7| Step: 2
Training loss: 2.5895961913579604
Validation loss: 2.1662707364611142
Epoch: 7| Step: 3
Training loss: 2.6684871856856383
Validation loss: 2.1281162448187514
Epoch: 7| Step: 4
Training loss: 2.5203182440335774
Validation loss: 2.161799998675281
Epoch: 7| Step: 5
Training loss: 2.837315080305534
Validation loss: 2.12083557717237
Epoch: 7| Step: 6
Training loss: 2.811935792067834
Validation loss: 2.1137244684867404
Epoch: 7| Step: 7
Training loss: 2.9862474888455295
Validation loss: 2.1404100759845663
Epoch: 7| Step: 8
Training loss: 2.8594440389334412
Validation loss: 2.1429536447809907
Epoch: 7| Step: 9
Training loss: 2.8448373581131507
Validation loss: 2.156435600864854
Epoch: 7| Step: 10
Training loss: 2.897533183134109
Validation loss: 2.133633811901532
Epoch: 7| Step: 11
Training loss: 2.7725303348295487
Validation loss: 2.0774550889472385
Epoch: 7| Step: 12
Training loss: 2.506369202173974
Validation loss: 2.1993790709483054
Epoch: 7| Step: 13
Training loss: 2.8820667491121523
Validation loss: 2.137737150389799
Epoch: 7| Step: 14
Training loss: 2.6951510615998
Validation loss: 2.1694985197890206
Epoch: 7| Step: 15
Training loss: 2.5731099682883802
Validation loss: 2.1674623701274895
Epoch: 7| Step: 16
Training loss: 2.2496129868709067
Validation loss: 2.101773332415164
Epoch: 7| Step: 17
Training loss: 2.864067354838101
Validation loss: 2.1088068206614987
Epoch: 7| Step: 18
Training loss: 2.8806412126081176
Validation loss: 2.107215076914126
Epoch: 7| Step: 19
Training loss: 2.829958832242529
Validation loss: 2.117044518966684
Epoch: 8| Step: 0
Training loss: 2.77391138460828
Validation loss: 2.1515455075603427
Epoch: 8| Step: 1
Training loss: 2.438210408294819
Validation loss: 2.073242143140479
Epoch: 8| Step: 2
Training loss: 2.6049910397659226
Validation loss: 2.1120994061088605
Epoch: 8| Step: 3
Training loss: 2.9513450788849145
Validation loss: 2.1195802090920752
Epoch: 8| Step: 4
Training loss: 2.790173221256031
Validation loss: 2.103035815193272
Epoch: 8| Step: 5
Training loss: 3.0050895751195483
Validation loss: 2.110776860403557
Epoch: 8| Step: 6
Training loss: 2.0437328886196537
Validation loss: 2.081010294669388
Epoch: 8| Step: 7
Training loss: 2.2391217369661036
Validation loss: 2.0751252182757662
Epoch: 8| Step: 8
Training loss: 2.722722188186703
Validation loss: 2.1229400000039353
Epoch: 8| Step: 9
Training loss: 2.7835774487862044
Validation loss: 2.1245471680693417
Epoch: 8| Step: 10
Training loss: 2.096377872941142
Validation loss: 2.1074367542365042
Epoch: 8| Step: 11
Training loss: 2.4864874921308067
Validation loss: 2.09915183889978
Epoch: 8| Step: 12
Training loss: 2.932538651701898
Validation loss: 2.1297722517615387
Epoch: 8| Step: 13
Training loss: 2.787638068094161
Validation loss: 2.0839380815097823
Epoch: 8| Step: 14
Training loss: 2.4885466477504066
Validation loss: 2.0605187614441602
Epoch: 8| Step: 15
Training loss: 3.286697080779679
Validation loss: 2.08449057218741
Epoch: 8| Step: 16
Training loss: 2.6791506749492107
Validation loss: 2.1123009175574032
Epoch: 8| Step: 17
Training loss: 2.5569084382743843
Validation loss: 2.0764337628715674
Epoch: 8| Step: 18
Training loss: 2.472325885994817
Validation loss: 2.1092573647041455
Epoch: 8| Step: 19
Training loss: 2.889534409449653
Validation loss: 2.0224648473994686
Epoch: 9| Step: 0
Training loss: 2.3919174590078955
Validation loss: 2.1069336492984077
Epoch: 9| Step: 1
Training loss: 2.987497024853873
Validation loss: 1.9686479984994034
Epoch: 9| Step: 2
Training loss: 2.314923125240911
Validation loss: 2.087283057252852
Epoch: 9| Step: 3
Training loss: 2.700737576935726
Validation loss: 2.1390632046035742
Epoch: 9| Step: 4
Training loss: 2.5458873869989365
Validation loss: 2.0882552165761745
Epoch: 9| Step: 5
Training loss: 3.0372244564712068
Validation loss: 2.0805775987896267
Epoch: 9| Step: 6
Training loss: 2.9036541903023423
Validation loss: 2.044080893689057
Epoch: 9| Step: 7
Training loss: 2.832888138145781
Validation loss: 2.0583241968610606
Epoch: 9| Step: 8
Training loss: 2.29456197310892
Validation loss: 2.0937782368311915
Epoch: 9| Step: 9
Training loss: 2.7389538601418315
Validation loss: 2.122435480154109
Epoch: 9| Step: 10
Training loss: 2.7637851435766017
Validation loss: 2.0531000014919316
Epoch: 9| Step: 11
Training loss: 1.9356146838092174
Validation loss: 2.0969486287880903
Epoch: 9| Step: 12
Training loss: 2.6431846176427243
Validation loss: 2.0900480471649394
Epoch: 9| Step: 13
Training loss: 1.952646547842697
Validation loss: 2.063203603784256
Epoch: 9| Step: 14
Training loss: 2.4318159292983625
Validation loss: 2.0589660712190914
Epoch: 9| Step: 15
Training loss: 3.1564895992171147
Validation loss: 2.0929565837106607
Epoch: 9| Step: 16
Training loss: 2.6446131097697845
Validation loss: 2.119219915102327
Epoch: 9| Step: 17
Training loss: 2.818564002419687
Validation loss: 2.112245088107913
Epoch: 9| Step: 18
Training loss: 3.0896449742477747
Validation loss: 2.0794238939641123
Epoch: 9| Step: 19
Training loss: 2.347829802789681
Validation loss: 2.1117911385622152
Epoch: 10| Step: 0
Training loss: 2.967538686884182
Validation loss: 2.1159114985887575
Epoch: 10| Step: 1
Training loss: 2.512216663990886
Validation loss: 2.115810957661113
Epoch: 10| Step: 2
Training loss: 2.4522948591663982
Validation loss: 2.113115880405384
Epoch: 10| Step: 3
Training loss: 2.5030314186309783
Validation loss: 2.0515145724063357
Epoch: 10| Step: 4
Training loss: 2.9752534005091418
Validation loss: 2.075457219710577
Epoch: 10| Step: 5
Training loss: 2.1615235345650334
Validation loss: 2.1045360587321404
Epoch: 10| Step: 6
Training loss: 2.6179238265738682
Validation loss: 2.0370864489062646
Epoch: 10| Step: 7
Training loss: 2.7909395969678994
Validation loss: 2.086007834380605
Epoch: 10| Step: 8
Training loss: 2.587523190306896
Validation loss: 2.111842179598031
Epoch: 10| Step: 9
Training loss: 2.8290616165306393
Validation loss: 2.057770951370343
Epoch: 10| Step: 10
Training loss: 2.8317322040388326
Validation loss: 2.063388863552181
Epoch: 10| Step: 11
Training loss: 2.643366186539916
Validation loss: 2.0409386689766027
Epoch: 10| Step: 12
Training loss: 2.977014382170975
Validation loss: 2.0623082660524896
Epoch: 10| Step: 13
Training loss: 2.691688556011311
Validation loss: 2.1299570666095358
Epoch: 10| Step: 14
Training loss: 2.776035692925434
Validation loss: 2.0731076330082896
Epoch: 10| Step: 15
Training loss: 2.3386985765815336
Validation loss: 2.0866983158163013
Epoch: 10| Step: 16
Training loss: 2.7281875795438344
Validation loss: 2.098603709335424
Epoch: 10| Step: 17
Training loss: 2.626117650019352
Validation loss: 2.1177106904551595
Epoch: 10| Step: 18
Training loss: 2.3744725093314516
Validation loss: 2.0704473252143636
Epoch: 10| Step: 19
Training loss: 2.2436890575240205
Validation loss: 2.018906596879473
Epoch: 11| Step: 0
Training loss: 2.891514326877711
Validation loss: 2.0783685225132933
Epoch: 11| Step: 1
Training loss: 2.739676779735499
Validation loss: 2.035751934395183
Epoch: 11| Step: 2
Training loss: 2.737687290003272
Validation loss: 2.0758120539248957
Epoch: 11| Step: 3
Training loss: 2.5530330421948273
Validation loss: 2.0292766813856864
Epoch: 11| Step: 4
Training loss: 2.945659748522382
Validation loss: 2.0472184121763473
Epoch: 11| Step: 5
Training loss: 2.384733232657771
Validation loss: 2.0902106447405027
Epoch: 11| Step: 6
Training loss: 2.4559083929156054
Validation loss: 2.092547938350527
Epoch: 11| Step: 7
Training loss: 2.3705580481707917
Validation loss: 2.097091293506918
Epoch: 11| Step: 8
Training loss: 2.527299506199624
Validation loss: 2.099172127295915
Epoch: 11| Step: 9
Training loss: 2.0515807128469703
Validation loss: 2.1186573078063744
Epoch: 11| Step: 10
Training loss: 3.2009022513626246
Validation loss: 2.0257710070916035
Epoch: 11| Step: 11
Training loss: 2.903383543658487
Validation loss: 2.0621379960136244
Epoch: 11| Step: 12
Training loss: 2.296860882981702
Validation loss: 2.0884372874574044
Epoch: 11| Step: 13
Training loss: 2.356880132062125
Validation loss: 2.0856045662885943
Epoch: 11| Step: 14
Training loss: 2.9484443506788955
Validation loss: 2.0745976546386484
Epoch: 11| Step: 15
Training loss: 2.6434980484327713
Validation loss: 2.146827367711408
Epoch: 11| Step: 16
Training loss: 2.5981301699970736
Validation loss: 2.056093346977692
Epoch: 11| Step: 17
Training loss: 2.116058499030587
Validation loss: 2.017173626100128
Epoch: 11| Step: 18
Training loss: 3.0564499865670536
Validation loss: 2.0700526593759037
Epoch: 11| Step: 19
Training loss: 2.6147394830244397
Validation loss: 2.0742327371461755
Epoch: 12| Step: 0
Training loss: 2.8509497415266614
Validation loss: 2.0750673134807087
Epoch: 12| Step: 1
Training loss: 2.683124440120032
Validation loss: 2.1365558547462395
Epoch: 12| Step: 2
Training loss: 2.9461424288171245
Validation loss: 2.06234525118611
Epoch: 12| Step: 3
Training loss: 2.7232493735561074
Validation loss: 2.0398956975723856
Epoch: 12| Step: 4
Training loss: 2.8322238619845237
Validation loss: 2.098217598095734
Epoch: 12| Step: 5
Training loss: 2.5828564316462854
Validation loss: 2.0579089650635147
Epoch: 12| Step: 6
Training loss: 2.8388959097811717
Validation loss: 2.084873647950222
Epoch: 12| Step: 7
Training loss: 2.7409773979549437
Validation loss: 2.0910538158099157
Epoch: 12| Step: 8
Training loss: 2.5298876451716947
Validation loss: 2.069914412197065
Epoch: 12| Step: 9
Training loss: 2.207647889001492
Validation loss: 2.1112647155578115
Epoch: 12| Step: 10
Training loss: 2.514394708073066
Validation loss: 2.1095759291353806
Epoch: 12| Step: 11
Training loss: 2.223513687554879
Validation loss: 2.1035006459787917
Epoch: 12| Step: 12
Training loss: 2.399546810913701
Validation loss: 2.098575190038075
Epoch: 12| Step: 13
Training loss: 2.6991309498089024
Validation loss: 2.0249898010449154
Epoch: 12| Step: 14
Training loss: 3.0684594539296355
Validation loss: 2.0832236053442585
Epoch: 12| Step: 15
Training loss: 3.194677910128483
Validation loss: 2.07919701601189
Epoch: 12| Step: 16
Training loss: 2.547262805831278
Validation loss: 2.1015813302926105
Epoch: 12| Step: 17
Training loss: 2.1268448394869903
Validation loss: 2.089423473279214
Epoch: 12| Step: 18
Training loss: 2.236985182541266
Validation loss: 2.067263607775364
Epoch: 12| Step: 19
Training loss: 2.4826673480865056
Validation loss: 2.105037362728348
Epoch: 13| Step: 0
Training loss: 2.307726288814268
Validation loss: 2.1223460483459933
Epoch: 13| Step: 1
Training loss: 2.963365671376876
Validation loss: 2.069328235371941
Epoch: 13| Step: 2
Training loss: 2.4800040703401693
Validation loss: 2.0562254254169163
Epoch: 13| Step: 3
Training loss: 2.5376708926829563
Validation loss: 2.0876383047213283
Epoch: 13| Step: 4
Training loss: 1.9130176417110112
Validation loss: 2.0924527928672054
Epoch: 13| Step: 5
Training loss: 2.8249225504563236
Validation loss: 2.0804012617306027
Epoch: 13| Step: 6
Training loss: 2.3849267803604923
Validation loss: 2.052835028462104
Epoch: 13| Step: 7
Training loss: 2.537180135326031
Validation loss: 2.0335690891711535
Epoch: 13| Step: 8
Training loss: 3.0417920091138684
Validation loss: 2.126203212380804
Epoch: 13| Step: 9
Training loss: 2.8000014747888224
Validation loss: 2.0456699389927264
Epoch: 13| Step: 10
Training loss: 2.577581544875622
Validation loss: 2.091631426621445
Epoch: 13| Step: 11
Training loss: 3.0036886109084726
Validation loss: 2.0973414069921055
Epoch: 13| Step: 12
Training loss: 2.8388871755509784
Validation loss: 2.063700114859329
Epoch: 13| Step: 13
Training loss: 3.152544017608475
Validation loss: 2.097479303835769
Epoch: 13| Step: 14
Training loss: 2.557547458719207
Validation loss: 2.1192362881013653
Epoch: 13| Step: 15
Training loss: 2.8058248354997724
Validation loss: 2.0811836857699033
Epoch: 13| Step: 16
Training loss: 2.8560883858197994
Validation loss: 2.0790231700087745
Epoch: 13| Step: 17
Training loss: 2.449351524635725
Validation loss: 2.092274501206346
Epoch: 13| Step: 18
Training loss: 2.2576625470587053
Validation loss: 2.050060081464715
Epoch: 13| Step: 19
Training loss: 2.000786269128381
Validation loss: 2.041108166986934
Epoch: 14| Step: 0
Training loss: 2.392646084812881
Validation loss: 2.0900893379900376
Epoch: 14| Step: 1
Training loss: 2.678175341067351
Validation loss: 2.1205879971049706
Epoch: 14| Step: 2
Training loss: 2.720030296802085
Validation loss: 2.0221965402684163
Epoch: 14| Step: 3
Training loss: 2.818657978864915
Validation loss: 2.0764258664781137
Epoch: 14| Step: 4
Training loss: 2.427121687382767
Validation loss: 2.082412075052896
Epoch: 14| Step: 5
Training loss: 2.737105395996198
Validation loss: 2.0567782800902727
Epoch: 14| Step: 6
Training loss: 2.964669565504627
Validation loss: 2.077323248258609
Epoch: 14| Step: 7
Training loss: 2.775995326892976
Validation loss: 2.073333334025137
Epoch: 14| Step: 8
Training loss: 2.926069380421963
Validation loss: 2.0195998730393505
Epoch: 14| Step: 9
Training loss: 2.478498406196345
Validation loss: 2.05703804776196
Epoch: 14| Step: 10
Training loss: 2.860883471209522
Validation loss: 2.0907649811511932
Epoch: 14| Step: 11
Training loss: 2.8588533186162737
Validation loss: 2.1012216200272738
Epoch: 14| Step: 12
Training loss: 2.320933352038199
Validation loss: 2.1047871771304125
Epoch: 14| Step: 13
Training loss: 2.5484967831207204
Validation loss: 2.0529910939030445
Epoch: 14| Step: 14
Training loss: 2.318280804402591
Validation loss: 2.11694487496213
Epoch: 14| Step: 15
Training loss: 2.473496907352745
Validation loss: 2.121269945868539
Epoch: 14| Step: 16
Training loss: 2.6693827287744716
Validation loss: 2.030846898062824
Epoch: 14| Step: 17
Training loss: 3.141754402804118
Validation loss: 2.0645755457676223
Epoch: 14| Step: 18
Training loss: 1.937709181783723
Validation loss: 2.059449038723096
Epoch: 14| Step: 19
Training loss: 2.364509502944355
Validation loss: 2.1295812834958285
Epoch: 15| Step: 0
Training loss: 2.6389622616745547
Validation loss: 2.0719448842380412
Epoch: 15| Step: 1
Training loss: 2.292499136721782
Validation loss: 2.0356958065972472
Epoch: 15| Step: 2
Training loss: 2.655237161852243
Validation loss: 2.024866020546465
Epoch: 15| Step: 3
Training loss: 3.3024583156360463
Validation loss: 2.134012136836977
Epoch: 15| Step: 4
Training loss: 1.6505226579027894
Validation loss: 2.0899270770382237
Epoch: 15| Step: 5
Training loss: 2.6419771784129558
Validation loss: 2.068464963812275
Epoch: 15| Step: 6
Training loss: 2.7628156110584015
Validation loss: 2.057083213092505
Epoch: 15| Step: 7
Training loss: 2.455860726374489
Validation loss: 1.9975605130009053
Epoch: 15| Step: 8
Training loss: 2.723624058788371
Validation loss: 2.0687870910599475
Epoch: 15| Step: 9
Training loss: 2.582010750970538
Validation loss: 2.0336527664651727
Epoch: 15| Step: 10
Training loss: 2.472104075700736
Validation loss: 2.083038933185608
Epoch: 15| Step: 11
Training loss: 2.6713076875961526
Validation loss: 2.097828538497347
Epoch: 15| Step: 12
Training loss: 3.1635648359585544
Validation loss: 2.0132160614918675
Epoch: 15| Step: 13
Training loss: 2.443327954621616
Validation loss: 2.0607796118167823
Epoch: 15| Step: 14
Training loss: 2.6685377550261493
Validation loss: 2.049832115016929
Epoch: 15| Step: 15
Training loss: 3.1312420873484887
Validation loss: 2.1135086245910557
Epoch: 15| Step: 16
Training loss: 2.770323818848493
Validation loss: 2.0984641062272478
Epoch: 15| Step: 17
Training loss: 2.6858637064527104
Validation loss: 2.116214303300525
Epoch: 15| Step: 18
Training loss: 1.9829223602377772
Validation loss: 2.091765032277671
Epoch: 15| Step: 19
Training loss: 2.4870165331098857
Validation loss: 2.0818484418767635
Epoch: 16| Step: 0
Training loss: 2.8472774551947606
Validation loss: 2.073808608749176
Epoch: 16| Step: 1
Training loss: 3.1097799832937745
Validation loss: 2.1384863370075635
Epoch: 16| Step: 2
Training loss: 2.2488822279811784
Validation loss: 2.06286584599186
Epoch: 16| Step: 3
Training loss: 2.827377136151408
Validation loss: 2.0644006535757566
Epoch: 16| Step: 4
Training loss: 2.7377014852430945
Validation loss: 2.0588291354696038
Epoch: 16| Step: 5
Training loss: 2.7585046348124886
Validation loss: 2.067071558890101
Epoch: 16| Step: 6
Training loss: 2.0371747980191404
Validation loss: 2.07951677365304
Epoch: 16| Step: 7
Training loss: 2.66041884057522
Validation loss: 2.0881934966495095
Epoch: 16| Step: 8
Training loss: 2.7651333991597813
Validation loss: 2.080572374941016
Epoch: 16| Step: 9
Training loss: 2.599600753941847
Validation loss: 2.1077496683552432
Epoch: 16| Step: 10
Training loss: 2.803271262819426
Validation loss: 2.1270698230644536
Epoch: 16| Step: 11
Training loss: 2.3601677175506537
Validation loss: 2.034418121331241
Epoch: 16| Step: 12
Training loss: 2.8809858287924857
Validation loss: 2.0851998307618116
Epoch: 16| Step: 13
Training loss: 2.7432608826697003
Validation loss: 2.079498745188083
Epoch: 16| Step: 14
Training loss: 2.9308532836801953
Validation loss: 2.0604685536901313
Epoch: 16| Step: 15
Training loss: 2.3804379497822814
Validation loss: 2.0715693882839648
Epoch: 16| Step: 16
Training loss: 2.1492217141189576
Validation loss: 2.1173655036050683
Epoch: 16| Step: 17
Training loss: 2.443372645597455
Validation loss: 2.0756509549324624
Epoch: 16| Step: 18
Training loss: 2.5492737128469933
Validation loss: 2.0739383741967727
Epoch: 16| Step: 19
Training loss: 2.590627882418622
Validation loss: 2.0278528018000057
Epoch: 17| Step: 0
Training loss: 2.746011181996827
Validation loss: 2.099914165235667
Epoch: 17| Step: 1
Training loss: 2.3414584337642848
Validation loss: 2.056153500448686
Epoch: 17| Step: 2
Training loss: 2.0548413585306355
Validation loss: 2.1147252809797474
Epoch: 17| Step: 3
Training loss: 2.1795341410403393
Validation loss: 2.060797193679019
Epoch: 17| Step: 4
Training loss: 2.7105142664263875
Validation loss: 2.0886978080551866
Epoch: 17| Step: 5
Training loss: 2.630893993079125
Validation loss: 2.077507943479515
Epoch: 17| Step: 6
Training loss: 2.6824464524924823
Validation loss: 2.08470314344431
Epoch: 17| Step: 7
Training loss: 2.6981695540237536
Validation loss: 2.023673033711336
Epoch: 17| Step: 8
Training loss: 2.6712013867836477
Validation loss: 2.049451907827507
Epoch: 17| Step: 9
Training loss: 2.434175620771597
Validation loss: 2.0942226289603316
Epoch: 17| Step: 10
Training loss: 2.5162445632261843
Validation loss: 2.0844921275244337
Epoch: 17| Step: 11
Training loss: 2.7500301706219616
Validation loss: 2.091930998312492
Epoch: 17| Step: 12
Training loss: 2.054545234425442
Validation loss: 2.0860867682152002
Epoch: 17| Step: 13
Training loss: 3.252358681073852
Validation loss: 2.121042082828317
Epoch: 17| Step: 14
Training loss: 2.724756905448011
Validation loss: 2.0611245609779463
Epoch: 17| Step: 15
Training loss: 2.4264151072151634
Validation loss: 2.0910739456652143
Epoch: 17| Step: 16
Training loss: 2.673110230221994
Validation loss: 2.1063490135689786
Epoch: 17| Step: 17
Training loss: 2.7492826566561295
Validation loss: 2.089260939414298
Epoch: 17| Step: 18
Training loss: 3.0738894372240897
Validation loss: 2.0638331535428094
Epoch: 17| Step: 19
Training loss: 2.9858001980835853
Validation loss: 2.1212551482454254
Epoch: 18| Step: 0
Training loss: 2.8350372987476775
Validation loss: 2.0759746764306684
Epoch: 18| Step: 1
Training loss: 2.2496223132713107
Validation loss: 2.030424097253004
Epoch: 18| Step: 2
Training loss: 2.1935489399382675
Validation loss: 2.0577540814676145
Epoch: 18| Step: 3
Training loss: 2.744209522183364
Validation loss: 2.091832980858669
Epoch: 18| Step: 4
Training loss: 3.052123571831503
Validation loss: 2.11668834310896
Epoch: 18| Step: 5
Training loss: 2.5219752560036213
Validation loss: 2.0755138872647594
Epoch: 18| Step: 6
Training loss: 2.701980701419969
Validation loss: 2.1046585017200092
Epoch: 18| Step: 7
Training loss: 2.6177497829116207
Validation loss: 2.0710590307660453
Epoch: 18| Step: 8
Training loss: 1.8625490041340935
Validation loss: 2.055812559867014
Epoch: 18| Step: 9
Training loss: 2.117796187510379
Validation loss: 2.0808531729599915
Epoch: 18| Step: 10
Training loss: 2.8212040472112214
Validation loss: 2.055909449148782
Epoch: 18| Step: 11
Training loss: 2.8377454475082002
Validation loss: 2.0769548691563555
Epoch: 18| Step: 12
Training loss: 2.5591423553070594
Validation loss: 2.1152290894838606
Epoch: 18| Step: 13
Training loss: 2.5708902283673445
Validation loss: 2.0030270673799104
Epoch: 18| Step: 14
Training loss: 2.6177396732695324
Validation loss: 2.033228079552677
Epoch: 18| Step: 15
Training loss: 2.7758350593640166
Validation loss: 2.0567964347861185
Epoch: 18| Step: 16
Training loss: 2.7395145615526455
Validation loss: 2.0646877918440545
Epoch: 18| Step: 17
Training loss: 2.6406251805773793
Validation loss: 2.0769429760933935
Epoch: 18| Step: 18
Training loss: 2.776453232211769
Validation loss: 2.004240539277054
Epoch: 18| Step: 19
Training loss: 3.027587565786638
Validation loss: 2.116482579051311
Epoch: 19| Step: 0
Training loss: 3.2639272556800485
Validation loss: 2.112101630580754
Epoch: 19| Step: 1
Training loss: 2.2624618021232745
Validation loss: 2.0695959725487647
Epoch: 19| Step: 2
Training loss: 2.4127710338399417
Validation loss: 2.0873662026586466
Epoch: 19| Step: 3
Training loss: 3.148816107237332
Validation loss: 2.087128575100977
Epoch: 19| Step: 4
Training loss: 2.3481679349237883
Validation loss: 2.063733016235242
Epoch: 19| Step: 5
Training loss: 2.5713053817607845
Validation loss: 2.0779669261242573
Epoch: 19| Step: 6
Training loss: 2.5266397194276733
Validation loss: 2.076252507691941
Epoch: 19| Step: 7
Training loss: 2.860193854477852
Validation loss: 2.0340335370091265
Epoch: 19| Step: 8
Training loss: 2.2753683064557246
Validation loss: 2.0686131743899896
Epoch: 19| Step: 9
Training loss: 2.930123339976593
Validation loss: 2.0838775009864126
Epoch: 19| Step: 10
Training loss: 2.5806607809286257
Validation loss: 2.0478894855571412
Epoch: 19| Step: 11
Training loss: 2.5648866099675764
Validation loss: 2.0831578291070523
Epoch: 19| Step: 12
Training loss: 2.0779955830825405
Validation loss: 2.0946259313905804
Epoch: 19| Step: 13
Training loss: 2.3839533841804785
Validation loss: 2.044768477100356
Epoch: 19| Step: 14
Training loss: 2.668087511225937
Validation loss: 2.1188394413705764
Epoch: 19| Step: 15
Training loss: 2.93828166544799
Validation loss: 2.0536463864025554
Epoch: 19| Step: 16
Training loss: 2.7646127346136016
Validation loss: 2.0461613828218783
Epoch: 19| Step: 17
Training loss: 2.907694303886837
Validation loss: 2.0820992579812736
Epoch: 19| Step: 18
Training loss: 1.9557098374171373
Validation loss: 1.9969923727607752
Epoch: 19| Step: 19
Training loss: 2.7646022133852086
Validation loss: 2.1026565145381872
Epoch: 20| Step: 0
Training loss: 2.750049937401706
Validation loss: 2.074467427315089
Epoch: 20| Step: 1
Training loss: 3.159075086415536
Validation loss: 2.129844698490794
Epoch: 20| Step: 2
Training loss: 2.1663797139614
Validation loss: 2.0638056014248902
Epoch: 20| Step: 3
Training loss: 2.7148873963723963
Validation loss: 2.071118417411662
Epoch: 20| Step: 4
Training loss: 2.947078913796763
Validation loss: 2.0828566635098804
Epoch: 20| Step: 5
Training loss: 3.077899130652543
Validation loss: 2.1106519851077556
Epoch: 20| Step: 6
Training loss: 2.6715298256798614
Validation loss: 1.9732960735716447
Epoch: 20| Step: 7
Training loss: 2.643314233673222
Validation loss: 2.0054422762560145
Epoch: 20| Step: 8
Training loss: 2.6656952717899802
Validation loss: 2.0975476564893265
Epoch: 20| Step: 9
Training loss: 2.448093965210486
Validation loss: 2.0876679710927113
Epoch: 20| Step: 10
Training loss: 2.359321037837479
Validation loss: 2.0598677078987833
Epoch: 20| Step: 11
Training loss: 2.7306112489640024
Validation loss: 2.013410433645438
Epoch: 20| Step: 12
Training loss: 2.745926180375891
Validation loss: 2.0641460231527713
Epoch: 20| Step: 13
Training loss: 2.3321956404056143
Validation loss: 2.044189458650352
Epoch: 20| Step: 14
Training loss: 2.6450964634977865
Validation loss: 2.0389782891796866
Epoch: 20| Step: 15
Training loss: 2.6004450233778442
Validation loss: 2.0571031241299536
Epoch: 20| Step: 16
Training loss: 2.2769035843115923
Validation loss: 2.0370786081600127
Epoch: 20| Step: 17
Training loss: 2.4368688304164574
Validation loss: 2.1079894180098404
Epoch: 20| Step: 18
Training loss: 2.404839833214072
Validation loss: 2.0920444850415443
Epoch: 20| Step: 19
Training loss: 2.7399345337223795
Validation loss: 2.046672025097343
Epoch: 21| Step: 0
Training loss: 3.0048136239800227
Validation loss: 1.9798643814098553
Epoch: 21| Step: 1
Training loss: 3.022652773092227
Validation loss: 2.0963004285437448
Epoch: 21| Step: 2
Training loss: 2.286002968967275
Validation loss: 2.063332291000936
Epoch: 21| Step: 3
Training loss: 2.0875249529963287
Validation loss: 2.0214649215949843
Epoch: 21| Step: 4
Training loss: 2.0988095769554285
Validation loss: 2.1409996323123432
Epoch: 21| Step: 5
Training loss: 2.547148520169421
Validation loss: 2.084952585646103
Epoch: 21| Step: 6
Training loss: 2.825271093813838
Validation loss: 2.1060509143514117
Epoch: 21| Step: 7
Training loss: 2.8377434311018535
Validation loss: 2.0465822908364295
Epoch: 21| Step: 8
Training loss: 2.7065973635979277
Validation loss: 2.0252915934317164
Epoch: 21| Step: 9
Training loss: 2.557332294294181
Validation loss: 2.138806728365946
Epoch: 21| Step: 10
Training loss: 3.102647413859887
Validation loss: 2.1638948486278204
Epoch: 21| Step: 11
Training loss: 3.1259642067176148
Validation loss: 2.1132408774048566
Epoch: 21| Step: 12
Training loss: 2.353404695421276
Validation loss: 2.1124061590340126
Epoch: 21| Step: 13
Training loss: 2.6825178230027733
Validation loss: 2.043484929592872
Epoch: 21| Step: 14
Training loss: 2.474403571503236
Validation loss: 2.1194207472938422
Epoch: 21| Step: 15
Training loss: 2.297155142587237
Validation loss: 2.0443879802260976
Epoch: 21| Step: 16
Training loss: 2.3190350339347923
Validation loss: 2.0712248712243655
Epoch: 21| Step: 17
Training loss: 2.811341958583705
Validation loss: 2.0909274988587394
Epoch: 21| Step: 18
Training loss: 2.448938089014188
Validation loss: 2.102137035369833
Epoch: 21| Step: 19
Training loss: 2.720758244489443
Validation loss: 2.0660169641204504
Epoch: 22| Step: 0
Training loss: 2.7070010405116762
Validation loss: 2.1460694014587194
Epoch: 22| Step: 1
Training loss: 2.9019863889284316
Validation loss: 2.0808064776595474
Epoch: 22| Step: 2
Training loss: 2.101081651323857
Validation loss: 2.129333166256954
Epoch: 22| Step: 3
Training loss: 3.0768947563335236
Validation loss: 2.0990325466245996
Epoch: 22| Step: 4
Training loss: 2.325499417390424
Validation loss: 2.0413175894298794
Epoch: 22| Step: 5
Training loss: 2.536665409938319
Validation loss: 2.0387582417534054
Epoch: 22| Step: 6
Training loss: 2.917047766356186
Validation loss: 2.0951771256535205
Epoch: 22| Step: 7
Training loss: 2.434722785444304
Validation loss: 2.0586554620862207
Epoch: 22| Step: 8
Training loss: 2.6003053852612488
Validation loss: 2.112235516684252
Epoch: 22| Step: 9
Training loss: 2.521111801361816
Validation loss: 2.1066837807950183
Epoch: 22| Step: 10
Training loss: 2.7436875807628898
Validation loss: 2.080271958102065
Epoch: 22| Step: 11
Training loss: 2.4064100137986664
Validation loss: 2.0822852917433465
Epoch: 22| Step: 12
Training loss: 3.0439501686779518
Validation loss: 2.0786137255399715
Epoch: 22| Step: 13
Training loss: 2.543169754920766
Validation loss: 2.039542836080463
Epoch: 22| Step: 14
Training loss: 2.313509128094983
Validation loss: 2.0843568745154624
Epoch: 22| Step: 15
Training loss: 2.8863348389419814
Validation loss: 2.014856822587242
Epoch: 22| Step: 16
Training loss: 2.825523064725261
Validation loss: 2.048651417046022
Epoch: 22| Step: 17
Training loss: 2.5264974176426502
Validation loss: 2.100956362213848
Epoch: 22| Step: 18
Training loss: 2.150834179000757
Validation loss: 2.021677749706442
Epoch: 22| Step: 19
Training loss: 2.7894887732009623
Validation loss: 2.1136058758601814
Epoch: 23| Step: 0
Training loss: 2.3502266470190483
Validation loss: 2.052632569189202
Epoch: 23| Step: 1
Training loss: 2.1749162855151516
Validation loss: 2.0566227060995304
Epoch: 23| Step: 2
Training loss: 2.613417366713859
Validation loss: 2.054669690225678
Epoch: 23| Step: 3
Training loss: 2.755629239925896
Validation loss: 1.992147019454259
Epoch: 23| Step: 4
Training loss: 2.501801509268584
Validation loss: 2.067409947181188
Epoch: 23| Step: 5
Training loss: 2.9410215331388225
Validation loss: 2.0292038042882665
Epoch: 23| Step: 6
Training loss: 2.3728437171911216
Validation loss: 2.0740105687938883
Epoch: 23| Step: 7
Training loss: 2.9129474541756797
Validation loss: 2.008783285815929
Epoch: 23| Step: 8
Training loss: 3.013931035822865
Validation loss: 2.050154934975443
Epoch: 23| Step: 9
Training loss: 2.908918570702274
Validation loss: 2.0957829724850474
Epoch: 23| Step: 10
Training loss: 2.1860414274431212
Validation loss: 2.037887999130979
Epoch: 23| Step: 11
Training loss: 2.5918152728717776
Validation loss: 2.0805012501896964
Epoch: 23| Step: 12
Training loss: 2.049489455498184
Validation loss: 2.1035526393434747
Epoch: 23| Step: 13
Training loss: 2.836283344797395
Validation loss: 2.0346786066204796
Epoch: 23| Step: 14
Training loss: 2.5289636340862076
Validation loss: 2.019184214715442
Epoch: 23| Step: 15
Training loss: 2.7581671900043254
Validation loss: 2.0359417659935186
Epoch: 23| Step: 16
Training loss: 3.297725043610646
Validation loss: 2.0533588804743736
Epoch: 23| Step: 17
Training loss: 2.4431124897126897
Validation loss: 2.064536474393155
Epoch: 23| Step: 18
Training loss: 2.7540152453774183
Validation loss: 2.041656248853871
Epoch: 23| Step: 19
Training loss: 2.237654832991748
Validation loss: 2.0550876749359848
Epoch: 24| Step: 0
Training loss: 2.2153077623443376
Validation loss: 2.0319832712513866
Epoch: 24| Step: 1
Training loss: 3.012290257160453
Validation loss: 2.0288509584638885
Epoch: 24| Step: 2
Training loss: 2.802334959698586
Validation loss: 2.1001675828571944
Epoch: 24| Step: 3
Training loss: 3.088348142448063
Validation loss: 2.09627436520726
Epoch: 24| Step: 4
Training loss: 3.069483987391454
Validation loss: 2.058615759510193
Epoch: 24| Step: 5
Training loss: 2.8059191536380603
Validation loss: 2.054420675524789
Epoch: 24| Step: 6
Training loss: 2.6275945284578146
Validation loss: 2.111377804308585
Epoch: 24| Step: 7
Training loss: 1.9535065545274075
Validation loss: 2.0953974093331187
Epoch: 24| Step: 8
Training loss: 2.867101517305355
Validation loss: 2.060792020043348
Epoch: 24| Step: 9
Training loss: 2.8407845598149826
Validation loss: 2.114279262793093
Epoch: 24| Step: 10
Training loss: 2.0819199408860056
Validation loss: 2.0909818373926865
Epoch: 24| Step: 11
Training loss: 2.5196639151724907
Validation loss: 2.0239743219770734
Epoch: 24| Step: 12
Training loss: 2.8520480643953205
Validation loss: 2.0455941415962866
Epoch: 24| Step: 13
Training loss: 2.281757141596967
Validation loss: 2.0862310899951733
Epoch: 24| Step: 14
Training loss: 2.228201707800928
Validation loss: 2.053006927913601
Epoch: 24| Step: 15
Training loss: 2.794316149531093
Validation loss: 2.0516010583577975
Epoch: 24| Step: 16
Training loss: 2.5429123082614007
Validation loss: 2.0658027578872122
Epoch: 24| Step: 17
Training loss: 2.7010219088262186
Validation loss: 2.0762134921389563
Epoch: 24| Step: 18
Training loss: 2.8219177242859437
Validation loss: 2.0876372325850996
Epoch: 24| Step: 19
Training loss: 2.110138027503696
Validation loss: 2.1148638378555114
Epoch: 25| Step: 0
Training loss: 1.9269716247623265
Validation loss: 2.038359647212383
Epoch: 25| Step: 1
Training loss: 2.265813780187334
Validation loss: 2.085169521545495
Epoch: 25| Step: 2
Training loss: 2.835756070137001
Validation loss: 2.0624864879259315
Epoch: 25| Step: 3
Training loss: 2.518882679816866
Validation loss: 2.0666531764790967
Epoch: 25| Step: 4
Training loss: 2.516648741736166
Validation loss: 2.111506129978574
Epoch: 25| Step: 5
Training loss: 2.9087002177582875
Validation loss: 2.0499546793945083
Epoch: 25| Step: 6
Training loss: 2.0481666973713217
Validation loss: 2.0687902908844316
Epoch: 25| Step: 7
Training loss: 1.9766904766885238
Validation loss: 2.072279269119999
Epoch: 25| Step: 8
Training loss: 2.8426441096376482
Validation loss: 2.1220756606305358
Epoch: 25| Step: 9
Training loss: 3.070361265615433
Validation loss: 2.0505956741917624
Epoch: 25| Step: 10
Training loss: 2.7672345493997437
Validation loss: 2.03570581503727
Epoch: 25| Step: 11
Training loss: 2.5575672216148324
Validation loss: 2.106822820372316
Epoch: 25| Step: 12
Training loss: 3.3154949827885423
Validation loss: 2.0486632784881227
Epoch: 25| Step: 13
Training loss: 2.552144782954929
Validation loss: 2.0102432942897055
Epoch: 25| Step: 14
Training loss: 2.277076770974278
Validation loss: 2.0539107281728683
Epoch: 25| Step: 15
Training loss: 2.7061519543372614
Validation loss: 2.080991414461906
Epoch: 25| Step: 16
Training loss: 2.764804438181909
Validation loss: 2.0424360568610873
Epoch: 25| Step: 17
Training loss: 3.0999410316027083
Validation loss: 2.128410770314132
Epoch: 25| Step: 18
Training loss: 2.8646654891746373
Validation loss: 2.0601340203998495
Epoch: 25| Step: 19
Training loss: 2.2612130187697184
Validation loss: 2.1020731401383204
Epoch: 26| Step: 0
Training loss: 2.9592181928555465
Validation loss: 2.0254738226564006
Epoch: 26| Step: 1
Training loss: 2.054032369973315
Validation loss: 2.079590573384616
Epoch: 26| Step: 2
Training loss: 2.9349089212924033
Validation loss: 2.101792774313009
Epoch: 26| Step: 3
Training loss: 2.8305614787913167
Validation loss: 2.056910530040536
Epoch: 26| Step: 4
Training loss: 2.701696029196028
Validation loss: 2.026518536105799
Epoch: 26| Step: 5
Training loss: 2.544817883583796
Validation loss: 2.02712522480485
Epoch: 26| Step: 6
Training loss: 3.0041757767777706
Validation loss: 2.0723136701071656
Epoch: 26| Step: 7
Training loss: 3.393416279776409
Validation loss: 2.120140752371823
Epoch: 26| Step: 8
Training loss: 2.3492316674149145
Validation loss: 2.057657333682066
Epoch: 26| Step: 9
Training loss: 2.5546163846538095
Validation loss: 2.06971589889834
Epoch: 26| Step: 10
Training loss: 2.6065256242895685
Validation loss: 2.0605623007394165
Epoch: 26| Step: 11
Training loss: 2.3371021850210103
Validation loss: 2.0907926323544785
Epoch: 26| Step: 12
Training loss: 3.0852291018399014
Validation loss: 2.079586789584596
Epoch: 26| Step: 13
Training loss: 2.5719409178656214
Validation loss: 2.0189647188196935
Epoch: 26| Step: 14
Training loss: 1.9147334577157389
Validation loss: 2.0978468383532216
Epoch: 26| Step: 15
Training loss: 2.662412607970554
Validation loss: 2.0896800108805067
Epoch: 26| Step: 16
Training loss: 2.1185292851987847
Validation loss: 2.0959945176694545
Epoch: 26| Step: 17
Training loss: 2.8501553342550165
Validation loss: 2.0991567593598512
Epoch: 26| Step: 18
Training loss: 2.177989886566025
Validation loss: 2.046554380479928
Epoch: 26| Step: 19
Training loss: 2.4349809981903046
Validation loss: 2.0721613740321856
Epoch: 27| Step: 0
Training loss: 2.902617450608191
Validation loss: 2.0935909586221677
Epoch: 27| Step: 1
Training loss: 1.7715718543208945
Validation loss: 2.079582551031372
Epoch: 27| Step: 2
Training loss: 2.3050897796755123
Validation loss: 2.0456870858568528
Epoch: 27| Step: 3
Training loss: 2.2764632287829145
Validation loss: 2.102372916907593
Epoch: 27| Step: 4
Training loss: 2.707209241335677
Validation loss: 2.0527416514821315
Epoch: 27| Step: 5
Training loss: 2.634044325088468
Validation loss: 2.085803498087615
Epoch: 27| Step: 6
Training loss: 2.865206748865624
Validation loss: 2.04115624134556
Epoch: 27| Step: 7
Training loss: 2.834347449928986
Validation loss: 2.0642633284310357
Epoch: 27| Step: 8
Training loss: 2.805657689173278
Validation loss: 2.072957516653794
Epoch: 27| Step: 9
Training loss: 2.6989002177848445
Validation loss: 2.040745216332498
Epoch: 27| Step: 10
Training loss: 2.20310638636308
Validation loss: 2.1250540620976524
Epoch: 27| Step: 11
Training loss: 2.908511194804017
Validation loss: 2.054433534212437
Epoch: 27| Step: 12
Training loss: 2.0860664242110563
Validation loss: 2.117306604004956
Epoch: 27| Step: 13
Training loss: 2.700713829763735
Validation loss: 2.0779470954053894
Epoch: 27| Step: 14
Training loss: 2.6311723711246713
Validation loss: 2.090894520000731
Epoch: 27| Step: 15
Training loss: 2.9309541532639427
Validation loss: 2.09638143411142
Epoch: 27| Step: 16
Training loss: 2.875718897625709
Validation loss: 2.042560800926656
Epoch: 27| Step: 17
Training loss: 2.7921732163023885
Validation loss: 2.1015235198700655
Epoch: 27| Step: 18
Training loss: 2.950747708752893
Validation loss: 2.102174740305119
Epoch: 27| Step: 19
Training loss: 2.2788718382153452
Validation loss: 2.0601355286026415
Epoch: 28| Step: 0
Training loss: 2.5037818913516507
Validation loss: 2.0751648590123284
Epoch: 28| Step: 1
Training loss: 2.4838948295615317
Validation loss: 2.087769115117019
Epoch: 28| Step: 2
Training loss: 3.021047983545491
Validation loss: 2.070614518712487
Epoch: 28| Step: 3
Training loss: 1.9257267756621013
Validation loss: 2.058926875800202
Epoch: 28| Step: 4
Training loss: 2.9354247209281876
Validation loss: 2.067689916106192
Epoch: 28| Step: 5
Training loss: 2.7152452350388847
Validation loss: 2.1215248730842347
Epoch: 28| Step: 6
Training loss: 2.863863564432851
Validation loss: 2.0557517691776064
Epoch: 28| Step: 7
Training loss: 2.056614773289862
Validation loss: 2.0710530824505344
Epoch: 28| Step: 8
Training loss: 2.8571892393979517
Validation loss: 2.061503286308971
Epoch: 28| Step: 9
Training loss: 2.5864865737174254
Validation loss: 2.098643100959997
Epoch: 28| Step: 10
Training loss: 2.393892934331542
Validation loss: 2.0739142186297483
Epoch: 28| Step: 11
Training loss: 2.3730728964301204
Validation loss: 2.0690287186821648
Epoch: 28| Step: 12
Training loss: 2.09242138057484
Validation loss: 2.060290863500997
Epoch: 28| Step: 13
Training loss: 3.0880328440624303
Validation loss: 2.0409518718652526
Epoch: 28| Step: 14
Training loss: 2.410018546005371
Validation loss: 2.100009554819034
Epoch: 28| Step: 15
Training loss: 2.91053390612674
Validation loss: 2.0961304838572037
Epoch: 28| Step: 16
Training loss: 2.574303586543063
Validation loss: 2.069904940687432
Epoch: 28| Step: 17
Training loss: 2.780183137446251
Validation loss: 2.004624856507028
Epoch: 28| Step: 18
Training loss: 2.75423088595207
Validation loss: 2.083852443778632
Epoch: 28| Step: 19
Training loss: 2.9295680314182855
Validation loss: 2.034764067077534
Epoch: 29| Step: 0
Training loss: 2.8842296890240644
Validation loss: 2.0703684279857475
Epoch: 29| Step: 1
Training loss: 2.839407991036686
Validation loss: 2.0735308545787747
Epoch: 29| Step: 2
Training loss: 2.3571635612800534
Validation loss: 2.058760080453502
Epoch: 29| Step: 3
Training loss: 2.798278626874137
Validation loss: 2.1120021774086846
Epoch: 29| Step: 4
Training loss: 2.855079300776198
Validation loss: 2.0814826538208884
Epoch: 29| Step: 5
Training loss: 2.406129908351637
Validation loss: 2.0946013106746504
Epoch: 29| Step: 6
Training loss: 2.317124048085801
Validation loss: 2.0330656539488396
Epoch: 29| Step: 7
Training loss: 2.645251042327517
Validation loss: 2.0329975764183805
Epoch: 29| Step: 8
Training loss: 2.8578909269305455
Validation loss: 2.0829106649182547
Epoch: 29| Step: 9
Training loss: 2.9839657807523
Validation loss: 2.0681332239352805
Epoch: 29| Step: 10
Training loss: 2.7084631277429754
Validation loss: 2.0994780242739033
Epoch: 29| Step: 11
Training loss: 1.8311774047419134
Validation loss: 2.0673382830011997
Epoch: 29| Step: 12
Training loss: 2.9158484991667133
Validation loss: 2.0665231865124167
Epoch: 29| Step: 13
Training loss: 2.2361611649602247
Validation loss: 2.0785299877564114
Epoch: 29| Step: 14
Training loss: 2.512960313980771
Validation loss: 2.0411707382125055
Epoch: 29| Step: 15
Training loss: 2.72367675570727
Validation loss: 2.073533799137044
Epoch: 29| Step: 16
Training loss: 2.8608371352420403
Validation loss: 2.0539333044743238
Epoch: 29| Step: 17
Training loss: 2.753291934058503
Validation loss: 2.0925673981498134
Epoch: 29| Step: 18
Training loss: 2.4868345741194053
Validation loss: 2.086309856351807
Epoch: 29| Step: 19
Training loss: 2.4603538184304377
Validation loss: 2.0705630853805377
Epoch: 30| Step: 0
Training loss: 2.726085457154315
Validation loss: 2.088649705467669
Epoch: 30| Step: 1
Training loss: 2.5550103873024925
Validation loss: 2.04188988124384
Epoch: 30| Step: 2
Training loss: 2.378718125996251
Validation loss: 2.0661294701365693
Epoch: 30| Step: 3
Training loss: 2.80955775327398
Validation loss: 2.036263690992477
Epoch: 30| Step: 4
Training loss: 2.5465465872184674
Validation loss: 2.0765628076161793
Epoch: 30| Step: 5
Training loss: 3.2871277979188873
Validation loss: 2.0758003241553764
Epoch: 30| Step: 6
Training loss: 2.996572443831921
Validation loss: 2.094894704927847
Epoch: 30| Step: 7
Training loss: 2.2850112216932676
Validation loss: 2.025917201750743
Epoch: 30| Step: 8
Training loss: 2.72191278056959
Validation loss: 2.0934010169929342
Epoch: 30| Step: 9
Training loss: 2.1981007527523593
Validation loss: 2.0837003709263873
Epoch: 30| Step: 10
Training loss: 2.2829175106389807
Validation loss: 2.0897849159973023
Epoch: 30| Step: 11
Training loss: 2.8467466892843944
Validation loss: 2.082186154931805
Epoch: 30| Step: 12
Training loss: 2.4077538088923958
Validation loss: 2.09117184870035
Epoch: 30| Step: 13
Training loss: 2.5494816084873766
Validation loss: 2.0258170861875673
Epoch: 30| Step: 14
Training loss: 2.496571574197614
Validation loss: 2.0539205233547584
Epoch: 30| Step: 15
Training loss: 2.7728220941899306
Validation loss: 2.080802991343
Epoch: 30| Step: 16
Training loss: 2.3762129647601125
Validation loss: 2.0816143147547184
Epoch: 30| Step: 17
Training loss: 2.9148035002183685
Validation loss: 2.0987146854682317
Epoch: 30| Step: 18
Training loss: 2.7036530965581216
Validation loss: 2.082487642471838
Epoch: 30| Step: 19
Training loss: 2.4711490032761727
Validation loss: 2.075367595131095
