Epoch: 1| Step: 0
Training loss: 6.07312779089579
Validation loss: 5.4476048730008015
Epoch: 1| Step: 1
Training loss: 5.112344514678914
Validation loss: 5.044729016451161
Epoch: 1| Step: 2
Training loss: 5.901275639105597
Validation loss: 5.022932245148573
Epoch: 1| Step: 3
Training loss: 5.829374368642415
Validation loss: 4.977562901273792
Epoch: 1| Step: 4
Training loss: 5.2355274355193835
Validation loss: 4.934084537248782
Epoch: 1| Step: 5
Training loss: 5.641856220315949
Validation loss: 4.846716326529522
Epoch: 1| Step: 6
Training loss: 5.11197402598867
Validation loss: 4.803509870089489
Epoch: 1| Step: 7
Training loss: 4.727728783343281
Validation loss: 4.778767280106195
Epoch: 1| Step: 8
Training loss: 4.858834092433386
Validation loss: 4.662420918256789
Epoch: 1| Step: 9
Training loss: 4.55402349797864
Validation loss: 4.69153925747726
Epoch: 2| Step: 0
Training loss: 4.612962884601071
Validation loss: 4.677128159367063
Epoch: 2| Step: 1
Training loss: 4.591944748522822
Validation loss: 4.620571448117641
Epoch: 2| Step: 2
Training loss: 5.091638045326783
Validation loss: 4.43127946349469
Epoch: 2| Step: 3
Training loss: 4.958065998125929
Validation loss: 4.50557199183281
Epoch: 2| Step: 4
Training loss: 4.3153314555534505
Validation loss: 4.394236696142439
Epoch: 2| Step: 5
Training loss: 5.155584118935688
Validation loss: 4.411595550115004
Epoch: 2| Step: 6
Training loss: 4.5246114574560305
Validation loss: 4.345757521060246
Epoch: 2| Step: 7
Training loss: 4.5339444272169676
Validation loss: 4.318219863049844
Epoch: 2| Step: 8
Training loss: 5.292757217290591
Validation loss: 4.254785492261206
Epoch: 2| Step: 9
Training loss: 4.677368608481629
Validation loss: 4.20773129166608
Epoch: 3| Step: 0
Training loss: 4.2168900522359465
Validation loss: 4.187818555302223
Epoch: 3| Step: 1
Training loss: 4.115803031575559
Validation loss: 4.110963466351932
Epoch: 3| Step: 2
Training loss: 4.498736098072717
Validation loss: 3.95290301770104
Epoch: 3| Step: 3
Training loss: 4.609560791409228
Validation loss: 3.9976923073999795
Epoch: 3| Step: 4
Training loss: 4.357756283391655
Validation loss: 3.8514652901022495
Epoch: 3| Step: 5
Training loss: 3.8669175795557935
Validation loss: 3.9170505130553503
Epoch: 3| Step: 6
Training loss: 4.7698027762340365
Validation loss: 3.829525294667869
Epoch: 3| Step: 7
Training loss: 4.133341360597097
Validation loss: 3.855168504692492
Epoch: 3| Step: 8
Training loss: 4.471212282264318
Validation loss: 3.6434235898747085
Epoch: 3| Step: 9
Training loss: 3.9872385543208346
Validation loss: 3.6769880166340156
Epoch: 4| Step: 0
Training loss: 4.135064764288269
Validation loss: 3.6546131437761735
Epoch: 4| Step: 1
Training loss: 3.824496795864411
Validation loss: 3.554333948106809
Epoch: 4| Step: 2
Training loss: 3.7264240487088824
Validation loss: 3.5037461260679414
Epoch: 4| Step: 3
Training loss: 3.778133526738013
Validation loss: 3.572221351274672
Epoch: 4| Step: 4
Training loss: 3.4006334948806094
Validation loss: 3.40754117301513
Epoch: 4| Step: 5
Training loss: 4.187129217784636
Validation loss: 3.472492756519701
Epoch: 4| Step: 6
Training loss: 4.1377187066027945
Validation loss: 3.305926546312736
Epoch: 4| Step: 7
Training loss: 3.8690422773499
Validation loss: 3.29270712921454
Epoch: 4| Step: 8
Training loss: 3.615317732696479
Validation loss: 3.263174424192308
Epoch: 4| Step: 9
Training loss: 3.965999821834589
Validation loss: 3.1881802852192287
Epoch: 5| Step: 0
Training loss: 3.2687720507722267
Validation loss: 3.2387019165738886
Epoch: 5| Step: 1
Training loss: 3.813485440330575
Validation loss: 3.183371595565511
Epoch: 5| Step: 2
Training loss: 3.8527598657415503
Validation loss: 3.0654873007841803
Epoch: 5| Step: 3
Training loss: 3.4354883029579275
Validation loss: 3.1197451911340734
Epoch: 5| Step: 4
Training loss: 3.680712903256146
Validation loss: 2.9680267441756234
Epoch: 5| Step: 5
Training loss: 3.3275633145448467
Validation loss: 2.994713907362087
Epoch: 5| Step: 6
Training loss: 2.9632185953739096
Validation loss: 2.947203344934615
Epoch: 5| Step: 7
Training loss: 3.434476875550541
Validation loss: 2.9702137473522856
Epoch: 5| Step: 8
Training loss: 3.4913883532280736
Validation loss: 2.999767483180019
Epoch: 5| Step: 9
Training loss: 3.6579636690432733
Validation loss: 2.857666756680055
Epoch: 6| Step: 0
Training loss: 3.3186575321742575
Validation loss: 2.867316975847165
Epoch: 6| Step: 1
Training loss: 3.13091633555094
Validation loss: 2.753855867792793
Epoch: 6| Step: 2
Training loss: 3.419339847764015
Validation loss: 2.804412237837477
Epoch: 6| Step: 3
Training loss: 3.3457196575408807
Validation loss: 2.814847360748393
Epoch: 6| Step: 4
Training loss: 2.9090449521921298
Validation loss: 2.7588382229712263
Epoch: 6| Step: 5
Training loss: 3.076479864294209
Validation loss: 2.6918208713911906
Epoch: 6| Step: 6
Training loss: 3.376623257818992
Validation loss: 2.713785106311628
Epoch: 6| Step: 7
Training loss: 3.6022646668423004
Validation loss: 2.6453719956042985
Epoch: 6| Step: 8
Training loss: 2.925628861862988
Validation loss: 2.653217392510848
Epoch: 6| Step: 9
Training loss: 3.049635981114725
Validation loss: 2.584185521850291
Epoch: 7| Step: 0
Training loss: 3.190218644975072
Validation loss: 2.5506658451762245
Epoch: 7| Step: 1
Training loss: 3.051657029585845
Validation loss: 2.615095685783273
Epoch: 7| Step: 2
Training loss: 3.252440929770739
Validation loss: 2.5342398284385554
Epoch: 7| Step: 3
Training loss: 3.108078422695994
Validation loss: 2.50695096279357
Epoch: 7| Step: 4
Training loss: 3.071306295907533
Validation loss: 2.4460885415096216
Epoch: 7| Step: 5
Training loss: 2.576298106862792
Validation loss: 2.5083882386787946
Epoch: 7| Step: 6
Training loss: 3.0432598870876024
Validation loss: 2.4486295007079293
Epoch: 7| Step: 7
Training loss: 3.113016114857079
Validation loss: 2.4419857236014444
Epoch: 7| Step: 8
Training loss: 2.879935961647147
Validation loss: 2.398446578714785
Epoch: 7| Step: 9
Training loss: 2.8002760682930505
Validation loss: 2.4429270949213264
Epoch: 8| Step: 0
Training loss: 2.678808129160968
Validation loss: 2.339181745467111
Epoch: 8| Step: 1
Training loss: 2.7892249137541483
Validation loss: 2.3695143085978394
Epoch: 8| Step: 2
Training loss: 3.0575969138580508
Validation loss: 2.3863499321753396
Epoch: 8| Step: 3
Training loss: 2.986801998046926
Validation loss: 2.3695445684622825
Epoch: 8| Step: 4
Training loss: 2.829057234238064
Validation loss: 2.312226852048964
Epoch: 8| Step: 5
Training loss: 2.68118609016563
Validation loss: 2.398425822164355
Epoch: 8| Step: 6
Training loss: 2.555134678704502
Validation loss: 2.393946791096282
Epoch: 8| Step: 7
Training loss: 3.2401431336987985
Validation loss: 2.352018938311
Epoch: 8| Step: 8
Training loss: 2.878063062898128
Validation loss: 2.3015647311538214
Epoch: 8| Step: 9
Training loss: 2.964052197685295
Validation loss: 2.307632624377648
Epoch: 9| Step: 0
Training loss: 3.2408824086382855
Validation loss: 2.3273343847696344
Epoch: 9| Step: 1
Training loss: 2.8093024833239406
Validation loss: 2.365720450692633
Epoch: 9| Step: 2
Training loss: 2.531047577475979
Validation loss: 2.3144260667875276
Epoch: 9| Step: 3
Training loss: 2.789422020059649
Validation loss: 2.2796926738318293
Epoch: 9| Step: 4
Training loss: 2.680123340985315
Validation loss: 2.2806319928134258
Epoch: 9| Step: 5
Training loss: 2.7721663019846727
Validation loss: 2.21471240150758
Epoch: 9| Step: 6
Training loss: 2.7644777666378704
Validation loss: 2.278338967615459
Epoch: 9| Step: 7
Training loss: 2.7898083285323976
Validation loss: 2.2949313119792323
Epoch: 9| Step: 8
Training loss: 2.5665574863876746
Validation loss: 2.218877633205041
Epoch: 9| Step: 9
Training loss: 2.8458959845315763
Validation loss: 2.2092926783824383
Epoch: 10| Step: 0
Training loss: 2.9604617418530483
Validation loss: 2.2088726184222702
Epoch: 10| Step: 1
Training loss: 2.7374445661392937
Validation loss: 2.2333691154422364
Epoch: 10| Step: 2
Training loss: 3.0215525505398424
Validation loss: 2.256454582038129
Epoch: 10| Step: 3
Training loss: 2.782040258712773
Validation loss: 2.212555304790259
Epoch: 10| Step: 4
Training loss: 2.5101149022828326
Validation loss: 2.2776831902454755
Epoch: 10| Step: 5
Training loss: 2.6934571888114736
Validation loss: 2.1912784038895623
Epoch: 10| Step: 6
Training loss: 3.258108880262747
Validation loss: 2.200185980809294
Epoch: 10| Step: 7
Training loss: 2.517926413250869
Validation loss: 2.2195096346538254
Epoch: 10| Step: 8
Training loss: 2.5204541785568795
Validation loss: 2.218690529080386
Epoch: 10| Step: 9
Training loss: 2.4513901328376972
Validation loss: 2.218405198069871
Epoch: 11| Step: 0
Training loss: 3.0593728428834006
Validation loss: 2.162550994355927
Epoch: 11| Step: 1
Training loss: 2.5610446053358813
Validation loss: 2.2150182160868934
Epoch: 11| Step: 2
Training loss: 2.507226037589043
Validation loss: 2.2036526226398334
Epoch: 11| Step: 3
Training loss: 2.7705888759840502
Validation loss: 2.1979455662601404
Epoch: 11| Step: 4
Training loss: 2.8585861034973914
Validation loss: 2.2675839122087478
Epoch: 11| Step: 5
Training loss: 2.4422950530577148
Validation loss: 2.1995280719689605
Epoch: 11| Step: 6
Training loss: 2.7557045117831858
Validation loss: 2.193002979060042
Epoch: 11| Step: 7
Training loss: 2.5061772324041547
Validation loss: 2.1118133764226936
Epoch: 11| Step: 8
Training loss: 2.8874907126008984
Validation loss: 2.221225950041312
Epoch: 11| Step: 9
Training loss: 2.754966672359978
Validation loss: 2.119590327595882
Epoch: 12| Step: 0
Training loss: 2.4198371435176087
Validation loss: 2.1589754868229223
Epoch: 12| Step: 1
Training loss: 2.7203562584545056
Validation loss: 2.1846380455648364
Epoch: 12| Step: 2
Training loss: 2.5551839456950827
Validation loss: 2.091274260331831
Epoch: 12| Step: 3
Training loss: 2.848386568837212
Validation loss: 2.122577954455087
Epoch: 12| Step: 4
Training loss: 2.540439830755967
Validation loss: 2.162381528988057
Epoch: 12| Step: 5
Training loss: 2.4784704133607858
Validation loss: 2.174208573734657
Epoch: 12| Step: 6
Training loss: 2.815732327700871
Validation loss: 2.1650666516064696
Epoch: 12| Step: 7
Training loss: 2.7593230090314123
Validation loss: 2.137034568723956
Epoch: 12| Step: 8
Training loss: 2.6198420029968417
Validation loss: 2.2208435822107315
Epoch: 12| Step: 9
Training loss: 3.0328847665249405
Validation loss: 2.1831242523261283
Epoch: 13| Step: 0
Training loss: 2.706860733716879
Validation loss: 2.11728105062793
Epoch: 13| Step: 1
Training loss: 2.6752927459532896
Validation loss: 2.1738596519417026
Epoch: 13| Step: 2
Training loss: 2.7541912391324366
Validation loss: 2.2238693673371475
Epoch: 13| Step: 3
Training loss: 2.248875018848943
Validation loss: 2.1456946239249324
Epoch: 13| Step: 4
Training loss: 2.531368017388864
Validation loss: 2.178619573836299
Epoch: 13| Step: 5
Training loss: 2.684459829710913
Validation loss: 2.116408285837381
Epoch: 13| Step: 6
Training loss: 2.881223162941887
Validation loss: 2.1542869244148934
Epoch: 13| Step: 7
Training loss: 3.0738864898473106
Validation loss: 2.1889138343394574
Epoch: 13| Step: 8
Training loss: 2.6011236697036866
Validation loss: 2.201956252174206
Epoch: 13| Step: 9
Training loss: 2.609244885883983
Validation loss: 2.162914427830869
Epoch: 14| Step: 0
Training loss: 2.789554926466704
Validation loss: 2.1612680243752456
Epoch: 14| Step: 1
Training loss: 2.3565487133473195
Validation loss: 2.1812253998344397
Epoch: 14| Step: 2
Training loss: 2.673107108519399
Validation loss: 2.1408878240668514
Epoch: 14| Step: 3
Training loss: 3.097965027859865
Validation loss: 2.1579564806725875
Epoch: 14| Step: 4
Training loss: 3.0956556827989306
Validation loss: 2.2110344694168838
Epoch: 14| Step: 5
Training loss: 2.6838590221532606
Validation loss: 2.1886251445021303
Epoch: 14| Step: 6
Training loss: 2.7334348969857634
Validation loss: 2.175769449836117
Epoch: 14| Step: 7
Training loss: 2.4670199356046756
Validation loss: 2.0948512569267583
Epoch: 14| Step: 8
Training loss: 2.420972102045845
Validation loss: 2.1480060230689038
Epoch: 14| Step: 9
Training loss: 2.588213975966474
Validation loss: 2.1420300811605433
Epoch: 15| Step: 0
Training loss: 2.1689521277611297
Validation loss: 2.146296019981822
Epoch: 15| Step: 1
Training loss: 2.6553329679964723
Validation loss: 2.1539882746243433
Epoch: 15| Step: 2
Training loss: 2.389604737225573
Validation loss: 2.212913606759923
Epoch: 15| Step: 3
Training loss: 2.820872665949965
Validation loss: 2.2056647119040846
Epoch: 15| Step: 4
Training loss: 2.850277294923949
Validation loss: 2.1928300278022808
Epoch: 15| Step: 5
Training loss: 2.594999540913271
Validation loss: 2.1789047949262987
Epoch: 15| Step: 6
Training loss: 2.706910762334832
Validation loss: 2.211744884999267
Epoch: 15| Step: 7
Training loss: 2.9431124699443934
Validation loss: 2.2242513990820347
Epoch: 15| Step: 8
Training loss: 2.5734080310053766
Validation loss: 2.2092197692132958
Epoch: 15| Step: 9
Training loss: 2.8271291254467776
Validation loss: 2.1611486974896543
Epoch: 16| Step: 0
Training loss: 2.6597901931280146
Validation loss: 2.2352905461089874
Epoch: 16| Step: 1
Training loss: 3.07236154143424
Validation loss: 2.137224668813594
Epoch: 16| Step: 2
Training loss: 2.957883039420277
Validation loss: 2.2270416699463347
Epoch: 16| Step: 3
Training loss: 2.5126541318161584
Validation loss: 2.1696249943227213
Epoch: 16| Step: 4
Training loss: 2.5681811368761824
Validation loss: 2.1639083163109225
Epoch: 16| Step: 5
Training loss: 2.566503607124069
Validation loss: 2.088206787724639
Epoch: 16| Step: 6
Training loss: 2.4944583508227307
Validation loss: 2.194364504519596
Epoch: 16| Step: 7
Training loss: 2.3349091680859173
Validation loss: 2.158971629481008
Epoch: 16| Step: 8
Training loss: 2.7228752496941038
Validation loss: 2.2116461508623364
Epoch: 16| Step: 9
Training loss: 2.7392492827964348
Validation loss: 2.052716380818313
Epoch: 17| Step: 0
Training loss: 2.4353101626022364
Validation loss: 2.13700698405047
Epoch: 17| Step: 1
Training loss: 2.715361138311108
Validation loss: 2.1389260779750288
Epoch: 17| Step: 2
Training loss: 2.660007018890299
Validation loss: 2.1837776357318734
Epoch: 17| Step: 3
Training loss: 2.8485926382365947
Validation loss: 2.1959480991313503
Epoch: 17| Step: 4
Training loss: 3.0660827854871986
Validation loss: 2.160143828926221
Epoch: 17| Step: 5
Training loss: 2.517311999547129
Validation loss: 2.1651152221329015
Epoch: 17| Step: 6
Training loss: 2.3505045896938546
Validation loss: 2.1400435522023167
Epoch: 17| Step: 7
Training loss: 2.8984470418685593
Validation loss: 2.193413038506492
Epoch: 17| Step: 8
Training loss: 2.525970604804793
Validation loss: 2.131565564936672
Epoch: 17| Step: 9
Training loss: 2.697847716482635
Validation loss: 2.1702035869036247
Epoch: 18| Step: 0
Training loss: 3.054918987742143
Validation loss: 2.201930994299431
Epoch: 18| Step: 1
Training loss: 2.8580782925751453
Validation loss: 2.146837950643579
Epoch: 18| Step: 2
Training loss: 2.659722784411374
Validation loss: 2.190318172905708
Epoch: 18| Step: 3
Training loss: 2.4603309489367278
Validation loss: 2.1783223147935082
Epoch: 18| Step: 4
Training loss: 3.085162642533419
Validation loss: 2.145019432569023
Epoch: 18| Step: 5
Training loss: 2.71117688092291
Validation loss: 2.1384898759671014
Epoch: 18| Step: 6
Training loss: 2.607158976241894
Validation loss: 2.117233717066763
Epoch: 18| Step: 7
Training loss: 2.7451287387752785
Validation loss: 2.1643130207718366
Epoch: 18| Step: 8
Training loss: 2.277292764658953
Validation loss: 2.207735985734878
Epoch: 18| Step: 9
Training loss: 2.3155082518764765
Validation loss: 2.172780969917447
Epoch: 19| Step: 0
Training loss: 2.621267571633691
Validation loss: 2.202687066967286
Epoch: 19| Step: 1
Training loss: 2.757256038384186
Validation loss: 2.1901175109455977
Epoch: 19| Step: 2
Training loss: 3.020992266102412
Validation loss: 2.204024587786176
Epoch: 19| Step: 3
Training loss: 2.4079611502773703
Validation loss: 2.1403448011357704
Epoch: 19| Step: 4
Training loss: 2.0018218802253425
Validation loss: 2.1614131711990003
Epoch: 19| Step: 5
Training loss: 3.0498109414961494
Validation loss: 2.069639298831195
Epoch: 19| Step: 6
Training loss: 2.5866075091463085
Validation loss: 2.145147943119998
Epoch: 19| Step: 7
Training loss: 2.9079761916160627
Validation loss: 2.1231926312485423
Epoch: 19| Step: 8
Training loss: 2.418911505144506
Validation loss: 2.121459782424451
Epoch: 19| Step: 9
Training loss: 2.8178971110418436
Validation loss: 2.1425013145360627
Epoch: 20| Step: 0
Training loss: 2.6007163931499484
Validation loss: 2.2331647258368257
Epoch: 20| Step: 1
Training loss: 3.0429709438174055
Validation loss: 2.143447064071931
Epoch: 20| Step: 2
Training loss: 2.8916126110583416
Validation loss: 2.0532227179291302
Epoch: 20| Step: 3
Training loss: 2.739987265007329
Validation loss: 2.0190055361826955
Epoch: 20| Step: 4
Training loss: 2.723441712578094
Validation loss: 2.1375723034839993
Epoch: 20| Step: 5
Training loss: 2.5676311200173294
Validation loss: 2.150786106041068
Epoch: 20| Step: 6
Training loss: 2.8361915495604912
Validation loss: 2.125710894249015
Epoch: 20| Step: 7
Training loss: 2.462962840002445
Validation loss: 2.144228151516345
Epoch: 20| Step: 8
Training loss: 2.253029585046808
Validation loss: 2.103120984074142
Epoch: 20| Step: 9
Training loss: 2.5689704893205763
Validation loss: 2.1653975435774413
Epoch: 21| Step: 0
Training loss: 2.528627332049388
Validation loss: 2.110916742266276
Epoch: 21| Step: 1
Training loss: 2.525152420882301
Validation loss: 2.1730960545914426
Epoch: 21| Step: 2
Training loss: 2.637402074360916
Validation loss: 2.1249029147327283
Epoch: 21| Step: 3
Training loss: 2.8727268686502785
Validation loss: 2.1880781085885515
Epoch: 21| Step: 4
Training loss: 2.174785392959988
Validation loss: 2.148507199131645
Epoch: 21| Step: 5
Training loss: 2.701134980033187
Validation loss: 2.1577317481460314
Epoch: 21| Step: 6
Training loss: 2.9229541764375493
Validation loss: 2.16082167762128
Epoch: 21| Step: 7
Training loss: 2.918306834131258
Validation loss: 2.112809617758117
Epoch: 21| Step: 8
Training loss: 2.2887199067367154
Validation loss: 2.106423976731707
Epoch: 21| Step: 9
Training loss: 2.9457240133401084
Validation loss: 2.1491550367986147
Epoch: 22| Step: 0
Training loss: 2.0475128577717108
Validation loss: 2.1645748277099535
Epoch: 22| Step: 1
Training loss: 2.5550392212068913
Validation loss: 2.1526856403711347
Epoch: 22| Step: 2
Training loss: 2.734301931222378
Validation loss: 2.1495214544834584
Epoch: 22| Step: 3
Training loss: 2.830268679693744
Validation loss: 2.172633070339886
Epoch: 22| Step: 4
Training loss: 2.1234753693045203
Validation loss: 2.1161878850609903
Epoch: 22| Step: 5
Training loss: 2.4912844370037575
Validation loss: 2.1502014385816106
Epoch: 22| Step: 6
Training loss: 2.9196502865438068
Validation loss: 2.1024970081732315
Epoch: 22| Step: 7
Training loss: 2.9830643736862523
Validation loss: 2.129112291871259
Epoch: 22| Step: 8
Training loss: 2.596712741304292
Validation loss: 2.1304233472471967
Epoch: 22| Step: 9
Training loss: 3.123846222554492
Validation loss: 2.190762262457983
Epoch: 23| Step: 0
Training loss: 2.37853098949094
Validation loss: 2.1774633792967295
Epoch: 23| Step: 1
Training loss: 2.5385057983452435
Validation loss: 2.135286287690506
Epoch: 23| Step: 2
Training loss: 2.6558799934737047
Validation loss: 2.0600474137165135
Epoch: 23| Step: 3
Training loss: 2.860790131803215
Validation loss: 2.1907547352541195
Epoch: 23| Step: 4
Training loss: 2.5524694864240742
Validation loss: 2.100433616097499
Epoch: 23| Step: 5
Training loss: 2.7479807636304
Validation loss: 2.1408596712408974
Epoch: 23| Step: 6
Training loss: 2.666096020279346
Validation loss: 2.160398984093559
Epoch: 23| Step: 7
Training loss: 2.5144371877286407
Validation loss: 2.156284936831799
Epoch: 23| Step: 8
Training loss: 3.1300471936650274
Validation loss: 2.1207502162180294
Epoch: 23| Step: 9
Training loss: 2.5371152012899807
Validation loss: 2.0800479162029055
Epoch: 24| Step: 0
Training loss: 2.7486917678472693
Validation loss: 2.1453158198759836
Epoch: 24| Step: 1
Training loss: 2.9840893034470777
Validation loss: 2.162079938188424
Epoch: 24| Step: 2
Training loss: 2.7985732394407106
Validation loss: 2.126422269161712
Epoch: 24| Step: 3
Training loss: 2.522138609692954
Validation loss: 2.145607643863513
Epoch: 24| Step: 4
Training loss: 2.434783204001597
Validation loss: 2.1514482847575187
Epoch: 24| Step: 5
Training loss: 2.463555484488342
Validation loss: 2.1315066035414594
Epoch: 24| Step: 6
Training loss: 3.0134838982609686
Validation loss: 2.169255025379705
Epoch: 24| Step: 7
Training loss: 2.7716538402316404
Validation loss: 2.1653000756065985
Epoch: 24| Step: 8
Training loss: 2.734065708651651
Validation loss: 2.1949395518096937
Epoch: 24| Step: 9
Training loss: 2.120660727121541
Validation loss: 2.156740238664593
Epoch: 25| Step: 0
Training loss: 2.9770750870978633
Validation loss: 2.1389577495447636
Epoch: 25| Step: 1
Training loss: 2.793485068234039
Validation loss: 2.0776778250181556
Epoch: 25| Step: 2
Training loss: 2.3191237567418588
Validation loss: 2.1215030866191915
Epoch: 25| Step: 3
Training loss: 2.6256140944289146
Validation loss: 2.171981319158168
Epoch: 25| Step: 4
Training loss: 2.6287713887736253
Validation loss: 2.1362035744576238
Epoch: 25| Step: 5
Training loss: 2.584536446599047
Validation loss: 2.1046518164740755
Epoch: 25| Step: 6
Training loss: 2.525187071867113
Validation loss: 2.1790878303140597
Epoch: 25| Step: 7
Training loss: 2.5689732735306428
Validation loss: 2.1492631854848288
Epoch: 25| Step: 8
Training loss: 2.6639119662267654
Validation loss: 2.1454248915712544
Epoch: 25| Step: 9
Training loss: 2.935452335990165
Validation loss: 2.1220103754301034
Epoch: 26| Step: 0
Training loss: 2.5721981471312563
Validation loss: 2.1382682887894053
Epoch: 26| Step: 1
Training loss: 2.8443116691846484
Validation loss: 2.159583352509938
Epoch: 26| Step: 2
Training loss: 2.578262880279643
Validation loss: 2.1213740619280133
Epoch: 26| Step: 3
Training loss: 2.416673550650778
Validation loss: 2.115713378297353
Epoch: 26| Step: 4
Training loss: 2.7177112392664897
Validation loss: 2.155297746071299
Epoch: 26| Step: 5
Training loss: 2.584157094567646
Validation loss: 2.0794810708646736
Epoch: 26| Step: 6
Training loss: 2.907993900927585
Validation loss: 2.1530198891462717
Epoch: 26| Step: 7
Training loss: 3.1160898977100056
Validation loss: 2.1180544516747712
Epoch: 26| Step: 8
Training loss: 2.5580386891962377
Validation loss: 2.136539201062488
Epoch: 26| Step: 9
Training loss: 2.277463932693925
Validation loss: 2.0928328541501307
Epoch: 27| Step: 0
Training loss: 2.656742364466284
Validation loss: 2.140237563795819
Epoch: 27| Step: 1
Training loss: 2.56102468308452
Validation loss: 2.2023479763380553
Epoch: 27| Step: 2
Training loss: 3.037331840978071
Validation loss: 2.1850776110722827
Epoch: 27| Step: 3
Training loss: 2.6851123583138974
Validation loss: 2.1293010877178817
Epoch: 27| Step: 4
Training loss: 2.6045794248899963
Validation loss: 2.177244518739315
Epoch: 27| Step: 5
Training loss: 2.569853489480959
Validation loss: 2.1368480317770917
Epoch: 27| Step: 6
Training loss: 2.684016787128282
Validation loss: 2.13850795798856
Epoch: 27| Step: 7
Training loss: 2.4165238853456517
Validation loss: 2.1573317592948884
Epoch: 27| Step: 8
Training loss: 2.6794502887332095
Validation loss: 2.17677166117676
Epoch: 27| Step: 9
Training loss: 2.6132759584564327
Validation loss: 2.1148429369300192
Epoch: 28| Step: 0
Training loss: 2.671161310904089
Validation loss: 2.0565723424693947
Epoch: 28| Step: 1
Training loss: 2.2881269919358904
Validation loss: 2.1013431953135067
Epoch: 28| Step: 2
Training loss: 2.6726010769320694
Validation loss: 2.1611145099840536
Epoch: 28| Step: 3
Training loss: 2.914565628430624
Validation loss: 2.1377317426184095
Epoch: 28| Step: 4
Training loss: 3.0800960832941913
Validation loss: 2.150002539775914
Epoch: 28| Step: 5
Training loss: 2.7507880555588473
Validation loss: 2.084719889122805
Epoch: 28| Step: 6
Training loss: 2.043870890830384
Validation loss: 2.0287792954441857
Epoch: 28| Step: 7
Training loss: 2.5016981079782417
Validation loss: 2.1118072097571354
Epoch: 28| Step: 8
Training loss: 2.8900497276489365
Validation loss: 2.158682499508802
Epoch: 28| Step: 9
Training loss: 2.497271956685329
Validation loss: 2.1488544250241364
Epoch: 29| Step: 0
Training loss: 1.9895529886165233
Validation loss: 2.137089374984075
Epoch: 29| Step: 1
Training loss: 2.7349842373744173
Validation loss: 2.1020475449408442
Epoch: 29| Step: 2
Training loss: 2.847995816302709
Validation loss: 2.155150161611191
Epoch: 29| Step: 3
Training loss: 2.6987924418572975
Validation loss: 2.130897470918536
Epoch: 29| Step: 4
Training loss: 2.7444804894074726
Validation loss: 2.152279891997267
Epoch: 29| Step: 5
Training loss: 2.510360516649644
Validation loss: 2.1617104999644288
Epoch: 29| Step: 6
Training loss: 2.5296043415314626
Validation loss: 2.11440531241616
Epoch: 29| Step: 7
Training loss: 2.881841728698434
Validation loss: 2.1507770283478918
Epoch: 29| Step: 8
Training loss: 3.12072873994956
Validation loss: 2.102802089097045
Epoch: 29| Step: 9
Training loss: 2.470815542927896
Validation loss: 2.144465876013032
Epoch: 30| Step: 0
Training loss: 2.559371340868969
Validation loss: 2.132759112853888
Epoch: 30| Step: 1
Training loss: 2.7525064143661333
Validation loss: 2.1380028908363897
Epoch: 30| Step: 2
Training loss: 2.7818866815366747
Validation loss: 2.0928026818235317
Epoch: 30| Step: 3
Training loss: 2.8594016819110295
Validation loss: 2.1193856242031477
Epoch: 30| Step: 4
Training loss: 2.801931913650021
Validation loss: 2.167121206058878
Epoch: 30| Step: 5
Training loss: 2.400544176397192
Validation loss: 2.135543811618305
Epoch: 30| Step: 6
Training loss: 2.5580677685741957
Validation loss: 2.121890297615765
Epoch: 30| Step: 7
Training loss: 2.400501270397941
Validation loss: 2.09648983531145
Epoch: 30| Step: 8
Training loss: 2.766412396600548
Validation loss: 2.147081754660154
Epoch: 30| Step: 9
Training loss: 2.6949728046807357
Validation loss: 2.158589285620973
