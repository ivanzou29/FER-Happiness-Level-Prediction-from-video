Epoch: 1| Step: 0
Training loss: 7.273931980133057
Validation loss: 5.43580049055594
Epoch: 1| Step: 1
Training loss: 3.292498826980591
Validation loss: 4.7597842922917115
Epoch: 1| Step: 2
Training loss: 6.002986907958984
Validation loss: 4.711898008982341
Epoch: 1| Step: 3
Training loss: 0.9648391008377075
Validation loss: 4.698424136197126
Epoch: 1| Step: 4
Training loss: 6.211717128753662
Validation loss: 4.805925254468565
Epoch: 1| Step: 5
Training loss: 4.413346290588379
Validation loss: 4.847626818550958
Epoch: 1| Step: 6
Training loss: 3.961360454559326
Validation loss: 4.779795125678733
Epoch: 1| Step: 7
Training loss: 4.6396379470825195
Validation loss: 4.778258385481657
Epoch: 1| Step: 8
Training loss: 6.012905120849609
Validation loss: 4.750093318797924
Epoch: 1| Step: 9
Training loss: 3.7558155059814453
Validation loss: 4.777424353140372
Epoch: 1| Step: 10
Training loss: 4.179262638092041
Validation loss: 4.8045572263223155
Epoch: 1| Step: 11
Training loss: 3.4207828044891357
Validation loss: 4.760179969999525
Epoch: 1| Step: 12
Training loss: 4.6888041496276855
Validation loss: 4.734009460166648
Epoch: 1| Step: 13
Training loss: 4.260037899017334
Validation loss: 4.666328491988005
Epoch: 1| Step: 14
Training loss: 2.083444356918335
Validation loss: 4.600818669354474
Epoch: 1| Step: 15
Training loss: 4.5721917152404785
Validation loss: 4.623496020281756
Epoch: 1| Step: 16
Training loss: 5.461304664611816
Validation loss: 4.579165432188246
Epoch: 1| Step: 17
Training loss: 4.427103042602539
Validation loss: 4.590705156326294
Epoch: 1| Step: 18
Training loss: 3.1982433795928955
Validation loss: 4.676872880370529
Epoch: 1| Step: 19
Training loss: 5.5105791091918945
Validation loss: 4.588626614323369
Epoch: 1| Step: 20
Training loss: 5.54006814956665
Validation loss: 4.611489869930126
Epoch: 1| Step: 21
Training loss: 5.339713096618652
Validation loss: 4.526345473748666
Epoch: 1| Step: 22
Training loss: 3.5524649620056152
Validation loss: 4.478855848312378
Epoch: 1| Step: 23
Training loss: 3.5940308570861816
Validation loss: 4.419239264947397
Epoch: 1| Step: 24
Training loss: 4.892938613891602
Validation loss: 4.47042970304136
Epoch: 1| Step: 25
Training loss: 4.23233699798584
Validation loss: 4.4098031079327615
Epoch: 1| Step: 26
Training loss: 4.88232946395874
Validation loss: 4.378496514426337
Epoch: 1| Step: 27
Training loss: 3.511276960372925
Validation loss: 4.331516627912168
Epoch: 1| Step: 28
Training loss: 3.878986358642578
Validation loss: 4.377254309477629
Epoch: 1| Step: 29
Training loss: 4.559109210968018
Validation loss: 4.292386249259666
Epoch: 1| Step: 30
Training loss: 4.451298713684082
Validation loss: 4.253326389524672
Epoch: 1| Step: 31
Training loss: 4.519869327545166
Validation loss: 4.256550956655432
Epoch: 1| Step: 32
Training loss: 5.783200740814209
Validation loss: 4.270490734665482
Epoch: 1| Step: 33
Training loss: 4.277686595916748
Validation loss: 4.137408159397267
Epoch: 1| Step: 34
Training loss: 6.352422714233398
Validation loss: 4.1218593429636075
Epoch: 1| Step: 35
Training loss: 4.795487880706787
Validation loss: 4.074567529890272
Epoch: 1| Step: 36
Training loss: 4.539116859436035
Validation loss: 3.9885991590994374
Epoch: 1| Step: 37
Training loss: 4.910088539123535
Validation loss: 4.034933129946391
Epoch: 1| Step: 38
Training loss: 2.9681649208068848
Validation loss: 4.005705559695208
Epoch: 1| Step: 39
Training loss: 4.54595422744751
Validation loss: 3.919060371540211
Epoch: 1| Step: 40
Training loss: 4.508014678955078
Validation loss: 3.914528652473732
Epoch: 1| Step: 41
Training loss: 3.475710391998291
Validation loss: 3.8634650398183754
Epoch: 1| Step: 42
Training loss: 4.6099653244018555
Validation loss: 3.8449896971384683
Epoch: 1| Step: 43
Training loss: 4.876950263977051
Validation loss: 3.8753063325528747
Epoch: 1| Step: 44
Training loss: 4.668875217437744
Validation loss: 3.8070876554206565
Epoch: 1| Step: 45
Training loss: 5.137459754943848
Validation loss: 3.80256364080641
Epoch: 1| Step: 46
Training loss: 5.369856834411621
Validation loss: 3.7505199997513383
Epoch: 1| Step: 47
Training loss: 4.393078327178955
Validation loss: 3.752097068009553
Epoch: 1| Step: 48
Training loss: 2.9936327934265137
Validation loss: 3.6941241025924683
Epoch: 1| Step: 49
Training loss: 3.806368350982666
Validation loss: 3.660957354086417
Epoch: 1| Step: 50
Training loss: 3.1213579177856445
Validation loss: 3.587477030577483
Epoch: 1| Step: 51
Training loss: 4.527003288269043
Validation loss: 3.5797263074804238
Epoch: 1| Step: 52
Training loss: 3.814176082611084
Validation loss: 3.5319332944022284
Epoch: 1| Step: 53
Training loss: 3.6099464893341064
Validation loss: 3.5634684960047402
Epoch: 1| Step: 54
Training loss: 6.579714775085449
Validation loss: 3.4691935424451477
Epoch: 1| Step: 55
Training loss: 5.940806865692139
Validation loss: 3.4934785763422647
Epoch: 1| Step: 56
Training loss: 3.0718257427215576
Validation loss: 3.4093263502474183
Epoch: 1| Step: 57
Training loss: 4.0359206199646
Validation loss: 3.4018954038619995
Epoch: 1| Step: 58
Training loss: 5.00082540512085
Validation loss: 3.4265617529551187
Epoch: 1| Step: 59
Training loss: 3.59867525100708
Validation loss: 3.31473790274726
Epoch: 1| Step: 60
Training loss: 3.6521968841552734
Validation loss: 3.3239697791911937
Epoch: 1| Step: 61
Training loss: 3.5242772102355957
Validation loss: 3.32978406658879
Epoch: 1| Step: 62
Training loss: 1.862666130065918
Validation loss: 3.286619195231685
Epoch: 1| Step: 63
Training loss: 4.4407639503479
Validation loss: 3.2701219585206776
Epoch: 2| Step: 0
Training loss: 6.224425315856934
Validation loss: 3.1881295795793885
Epoch: 2| Step: 1
Training loss: 5.0728583335876465
Validation loss: 3.1878728425061262
Epoch: 2| Step: 2
Training loss: 2.244112730026245
Validation loss: 3.2060031758414373
Epoch: 2| Step: 3
Training loss: 3.7460358142852783
Validation loss: 3.137670071036727
Epoch: 2| Step: 4
Training loss: 3.2046618461608887
Validation loss: 3.1176724742960045
Epoch: 2| Step: 5
Training loss: 3.560093402862549
Validation loss: 3.0721451618053295
Epoch: 2| Step: 6
Training loss: 2.1397690773010254
Validation loss: 3.047053928728457
Epoch: 2| Step: 7
Training loss: 5.392536163330078
Validation loss: 3.024304813808865
Epoch: 2| Step: 8
Training loss: 2.033817768096924
Validation loss: 3.004714771553322
Epoch: 2| Step: 9
Training loss: 3.4741382598876953
Validation loss: 3.0251373714870877
Epoch: 2| Step: 10
Training loss: 2.0651931762695312
Validation loss: 2.902661676760073
Epoch: 2| Step: 11
Training loss: 1.8671118021011353
Validation loss: 2.9731735476741084
Epoch: 2| Step: 12
Training loss: 4.263851165771484
Validation loss: 2.9275070605454623
Epoch: 2| Step: 13
Training loss: 3.9416797161102295
Validation loss: 2.8957210646735296
Epoch: 2| Step: 14
Training loss: 2.9598352909088135
Validation loss: 2.825762232144674
Epoch: 2| Step: 15
Training loss: 3.3882896900177
Validation loss: 2.848475694656372
Epoch: 2| Step: 16
Training loss: 1.552233099937439
Validation loss: 2.7993568032979965
Epoch: 2| Step: 17
Training loss: 4.625624656677246
Validation loss: 2.833167831103007
Epoch: 2| Step: 18
Training loss: 3.9038138389587402
Validation loss: 2.8187872657069453
Epoch: 2| Step: 19
Training loss: 2.7278664112091064
Validation loss: 2.7696288139731795
Epoch: 2| Step: 20
Training loss: 3.044381618499756
Validation loss: 2.757948071868331
Epoch: 2| Step: 21
Training loss: 3.2528278827667236
Validation loss: 2.7732653573707298
Epoch: 2| Step: 22
Training loss: 2.7958757877349854
Validation loss: 2.6892980337142944
Epoch: 2| Step: 23
Training loss: 3.691483974456787
Validation loss: 2.7069610158602395
Epoch: 2| Step: 24
Training loss: 2.222069501876831
Validation loss: 2.6553234259287515
Epoch: 2| Step: 25
Training loss: 2.9834342002868652
Validation loss: 2.6869633197784424
Epoch: 2| Step: 26
Training loss: 2.8177478313446045
Validation loss: 2.7089092996385364
Epoch: 2| Step: 27
Training loss: 3.3775086402893066
Validation loss: 2.640303196730437
Epoch: 2| Step: 28
Training loss: 4.097781181335449
Validation loss: 2.6299724137341536
Epoch: 2| Step: 29
Training loss: 3.630448579788208
Validation loss: 2.5678359358399003
Epoch: 2| Step: 30
Training loss: 2.7086234092712402
Validation loss: 2.628533367757444
Epoch: 2| Step: 31
Training loss: 3.0844807624816895
Validation loss: 2.5408277776506214
Epoch: 2| Step: 32
Training loss: 2.3657214641571045
Validation loss: 2.5650691853629217
Epoch: 2| Step: 33
Training loss: 3.716895341873169
Validation loss: 2.5704903646751687
Epoch: 2| Step: 34
Training loss: 2.094761610031128
Validation loss: 2.5338760437788785
Epoch: 2| Step: 35
Training loss: 3.683694362640381
Validation loss: 2.5440285172727375
Epoch: 2| Step: 36
Training loss: 1.4307224750518799
Validation loss: 2.4922771188947888
Epoch: 2| Step: 37
Training loss: 1.721027135848999
Validation loss: 2.4620714584986367
Epoch: 2| Step: 38
Training loss: 3.5952014923095703
Validation loss: 2.4916701449288263
Epoch: 2| Step: 39
Training loss: 2.6172001361846924
Validation loss: 2.462233821551005
Epoch: 2| Step: 40
Training loss: 2.4084157943725586
Validation loss: 2.443475043332135
Epoch: 2| Step: 41
Training loss: 2.138744354248047
Validation loss: 2.501333510434186
Epoch: 2| Step: 42
Training loss: 2.424886703491211
Validation loss: 2.430693663932659
Epoch: 2| Step: 43
Training loss: 2.588719367980957
Validation loss: 2.4383564260270862
Epoch: 2| Step: 44
Training loss: 2.9536592960357666
Validation loss: 2.4056032675283925
Epoch: 2| Step: 45
Training loss: 4.866381645202637
Validation loss: 2.4331631748764604
Epoch: 2| Step: 46
Training loss: 4.962471008300781
Validation loss: 2.3642433705153287
Epoch: 2| Step: 47
Training loss: 1.6313421726226807
Validation loss: 2.3808622051168373
Epoch: 2| Step: 48
Training loss: 3.5670037269592285
Validation loss: 2.343808575912758
Epoch: 2| Step: 49
Training loss: 4.435655117034912
Validation loss: 2.4222432926849082
Epoch: 2| Step: 50
Training loss: 2.3180108070373535
Validation loss: 2.3520648920977556
Epoch: 2| Step: 51
Training loss: 1.9078773260116577
Validation loss: 2.295674716984784
Epoch: 2| Step: 52
Training loss: 1.711128830909729
Validation loss: 2.307622719694067
Epoch: 2| Step: 53
Training loss: 1.982876181602478
Validation loss: 2.365286460629216
Epoch: 2| Step: 54
Training loss: 3.0191092491149902
Validation loss: 2.2589721900445445
Epoch: 2| Step: 55
Training loss: 3.7023608684539795
Validation loss: 2.2283563437285245
Epoch: 2| Step: 56
Training loss: 3.359509229660034
Validation loss: 2.2111885768395885
Epoch: 2| Step: 57
Training loss: 3.6843199729919434
Validation loss: 2.2789864385569536
Epoch: 2| Step: 58
Training loss: 2.9124255180358887
Validation loss: 2.2185330479233354
Epoch: 2| Step: 59
Training loss: 3.117020845413208
Validation loss: 2.203172864737334
Epoch: 2| Step: 60
Training loss: 2.782120943069458
Validation loss: 2.2498619026607938
Epoch: 2| Step: 61
Training loss: 3.072042226791382
Validation loss: 2.164142030256766
Epoch: 2| Step: 62
Training loss: 1.955876111984253
Validation loss: 2.238603510238506
Epoch: 2| Step: 63
Training loss: 2.931917190551758
Validation loss: 2.213439638967867
Epoch: 3| Step: 0
Training loss: 1.0798137187957764
Validation loss: 2.207156614021019
Epoch: 3| Step: 1
Training loss: 2.0403976440429688
Validation loss: 2.2290779330112316
Epoch: 3| Step: 2
Training loss: 1.9363504648208618
Validation loss: 2.13228918004919
Epoch: 3| Step: 3
Training loss: 2.578463554382324
Validation loss: 2.21651828289032
Epoch: 3| Step: 4
Training loss: 4.225409984588623
Validation loss: 2.2205419032662004
Epoch: 3| Step: 5
Training loss: 2.1729655265808105
Validation loss: 2.1932748710667647
Epoch: 3| Step: 6
Training loss: 2.828981876373291
Validation loss: 2.152512824093854
Epoch: 3| Step: 7
Training loss: 3.517975330352783
Validation loss: 2.1439138959955284
Epoch: 3| Step: 8
Training loss: 2.9513461589813232
Validation loss: 2.0919604301452637
Epoch: 3| Step: 9
Training loss: 3.1222891807556152
Validation loss: 2.1343096406371505
Epoch: 3| Step: 10
Training loss: 2.335334062576294
Validation loss: 2.132769180668725
Epoch: 3| Step: 11
Training loss: 3.5389411449432373
Validation loss: 2.067929773418992
Epoch: 3| Step: 12
Training loss: 4.1799635887146
Validation loss: 2.052947578606782
Epoch: 3| Step: 13
Training loss: 2.181161880493164
Validation loss: 2.109689783166956
Epoch: 3| Step: 14
Training loss: 2.240313768386841
Validation loss: 2.0664640355993202
Epoch: 3| Step: 15
Training loss: 2.26607084274292
Validation loss: 2.091363134207549
Epoch: 3| Step: 16
Training loss: 3.2577178478240967
Validation loss: 2.0857887268066406
Epoch: 3| Step: 17
Training loss: 2.9670023918151855
Validation loss: 2.0989336923316673
Epoch: 3| Step: 18
Training loss: 3.955026149749756
Validation loss: 2.018938077820672
Epoch: 3| Step: 19
Training loss: 2.5872864723205566
Validation loss: 2.077316579995332
Epoch: 3| Step: 20
Training loss: 2.903703451156616
Validation loss: 2.0158198409610324
Epoch: 3| Step: 21
Training loss: 1.5220146179199219
Validation loss: 1.987839694376345
Epoch: 3| Step: 22
Training loss: 2.234041690826416
Validation loss: 2.0386010585007845
Epoch: 3| Step: 23
Training loss: 2.5410702228546143
Validation loss: 2.0537155910774514
Epoch: 3| Step: 24
Training loss: 3.0281643867492676
Validation loss: 2.016053001085917
Epoch: 3| Step: 25
Training loss: 1.5397279262542725
Validation loss: 2.0014904340108237
Epoch: 3| Step: 26
Training loss: 2.7809977531433105
Validation loss: 2.0002460325205766
Epoch: 3| Step: 27
Training loss: 2.766146659851074
Validation loss: 1.9786064161194696
Epoch: 3| Step: 28
Training loss: 3.524324893951416
Validation loss: 2.0222746597396
Epoch: 3| Step: 29
Training loss: 3.3537323474884033
Validation loss: 1.9539888390788325
Epoch: 3| Step: 30
Training loss: 1.2785476446151733
Validation loss: 1.9981022278467815
Epoch: 3| Step: 31
Training loss: 2.3576343059539795
Validation loss: 1.9830151354825054
Epoch: 3| Step: 32
Training loss: 1.346340537071228
Validation loss: 1.919833117061191
Epoch: 3| Step: 33
Training loss: 1.9202572107315063
Validation loss: 1.946035881837209
Epoch: 3| Step: 34
Training loss: 3.28141713142395
Validation loss: 1.892595143229873
Epoch: 3| Step: 35
Training loss: 3.3677611351013184
Validation loss: 1.9140572614139981
Epoch: 3| Step: 36
Training loss: 2.359203815460205
Validation loss: 1.9294700412838548
Epoch: 3| Step: 37
Training loss: 2.617919921875
Validation loss: 1.946870243107831
Epoch: 3| Step: 38
Training loss: 2.4907381534576416
Validation loss: 1.9340211859455816
Epoch: 3| Step: 39
Training loss: 2.636549472808838
Validation loss: 1.9191668475115742
Epoch: 3| Step: 40
Training loss: 1.0496350526809692
Validation loss: 1.9062076586264152
Epoch: 3| Step: 41
Training loss: 2.067667007446289
Validation loss: 1.83919863347654
Epoch: 3| Step: 42
Training loss: 2.5500733852386475
Validation loss: 1.9184486667315166
Epoch: 3| Step: 43
Training loss: 2.1869959831237793
Validation loss: 1.8853637509875827
Epoch: 3| Step: 44
Training loss: 2.88140869140625
Validation loss: 1.8602746151111744
Epoch: 3| Step: 45
Training loss: 1.4222962856292725
Validation loss: 1.8632524808247883
Epoch: 3| Step: 46
Training loss: 2.020704984664917
Validation loss: 1.8837040353704382
Epoch: 3| Step: 47
Training loss: 2.1026530265808105
Validation loss: 1.8719395090032507
Epoch: 3| Step: 48
Training loss: 2.264242172241211
Validation loss: 1.8773059293075844
Epoch: 3| Step: 49
Training loss: 2.542886972427368
Validation loss: 1.896613151938827
Epoch: 3| Step: 50
Training loss: 3.2675297260284424
Validation loss: 1.8973760295797277
Epoch: 3| Step: 51
Training loss: 1.602744698524475
Validation loss: 1.8723499245113797
Epoch: 3| Step: 52
Training loss: 2.930976152420044
Validation loss: 1.8268335064252217
Epoch: 3| Step: 53
Training loss: 2.768723249435425
Validation loss: 1.8392756228093747
Epoch: 3| Step: 54
Training loss: 1.4936987161636353
Validation loss: 1.8127184355700459
Epoch: 3| Step: 55
Training loss: 2.2801432609558105
Validation loss: 1.8668524689144559
Epoch: 3| Step: 56
Training loss: 2.6602659225463867
Validation loss: 1.8584912264788593
Epoch: 3| Step: 57
Training loss: 1.0825034379959106
Validation loss: 1.8360233174429998
Epoch: 3| Step: 58
Training loss: 3.1826367378234863
Validation loss: 1.8272796979656927
Epoch: 3| Step: 59
Training loss: 1.8460719585418701
Validation loss: 1.8236582742797003
Epoch: 3| Step: 60
Training loss: 1.580494999885559
Validation loss: 1.8371163297582556
Epoch: 3| Step: 61
Training loss: 3.5522637367248535
Validation loss: 1.7666352347091392
Epoch: 3| Step: 62
Training loss: 2.029758930206299
Validation loss: 1.8510989833761144
Epoch: 3| Step: 63
Training loss: 3.3194243907928467
Validation loss: 1.8191621700922649
Epoch: 4| Step: 0
Training loss: 1.3080116510391235
Validation loss: 1.8008271521992154
Epoch: 4| Step: 1
Training loss: 3.1395516395568848
Validation loss: 1.8442402791093897
Epoch: 4| Step: 2
Training loss: 1.918827772140503
Validation loss: 1.7487743938410725
Epoch: 4| Step: 3
Training loss: 2.263059616088867
Validation loss: 1.7996342336689983
Epoch: 4| Step: 4
Training loss: 2.1699438095092773
Validation loss: 1.808198904549634
Epoch: 4| Step: 5
Training loss: 1.511686086654663
Validation loss: 1.7656326713385406
Epoch: 4| Step: 6
Training loss: 2.4587581157684326
Validation loss: 1.7517118939646967
Epoch: 4| Step: 7
Training loss: 2.170562982559204
Validation loss: 1.8407650523715549
Epoch: 4| Step: 8
Training loss: 1.440895676612854
Validation loss: 1.789316197236379
Epoch: 4| Step: 9
Training loss: 3.1249072551727295
Validation loss: 1.7585662029407643
Epoch: 4| Step: 10
Training loss: 2.525728464126587
Validation loss: 1.8000603251987033
Epoch: 4| Step: 11
Training loss: 2.8700108528137207
Validation loss: 1.804545329676734
Epoch: 4| Step: 12
Training loss: 2.447025775909424
Validation loss: 1.717497534222073
Epoch: 4| Step: 13
Training loss: 2.3322391510009766
Validation loss: 1.7713061791879159
Epoch: 4| Step: 14
Training loss: 3.6269874572753906
Validation loss: 1.7963840983532093
Epoch: 4| Step: 15
Training loss: 1.7088193893432617
Validation loss: 1.757486687766181
Epoch: 4| Step: 16
Training loss: 3.194674253463745
Validation loss: 1.7382972317713279
Epoch: 4| Step: 17
Training loss: 1.8479865789413452
Validation loss: 1.717253272180204
Epoch: 4| Step: 18
Training loss: 2.266932249069214
Validation loss: 1.7616927380915042
Epoch: 4| Step: 19
Training loss: 1.9958603382110596
Validation loss: 1.7879065650480765
Epoch: 4| Step: 20
Training loss: 1.5121783018112183
Validation loss: 1.7851009545502838
Epoch: 4| Step: 21
Training loss: 3.028486967086792
Validation loss: 1.7539540198114183
Epoch: 4| Step: 22
Training loss: 3.675262451171875
Validation loss: 1.7357497215270996
Epoch: 4| Step: 23
Training loss: 2.735368013381958
Validation loss: 1.7124685049057007
Epoch: 4| Step: 24
Training loss: 1.3750165700912476
Validation loss: 1.7999827641027946
Epoch: 4| Step: 25
Training loss: 1.5680691003799438
Validation loss: 1.7510507239235773
Epoch: 4| Step: 26
Training loss: 3.241198778152466
Validation loss: 1.714511544616134
Epoch: 4| Step: 27
Training loss: 2.4185144901275635
Validation loss: 1.7597853188161496
Epoch: 4| Step: 28
Training loss: 1.9987379312515259
Validation loss: 1.7348573870129056
Epoch: 4| Step: 29
Training loss: 2.090872049331665
Validation loss: 1.757990461808664
Epoch: 4| Step: 30
Training loss: 3.1102054119110107
Validation loss: 1.7764993497618922
Epoch: 4| Step: 31
Training loss: 2.321481943130493
Validation loss: 1.721663271939313
Epoch: 4| Step: 32
Training loss: 1.2643345594406128
Validation loss: 1.7014921285487987
Epoch: 4| Step: 33
Training loss: 2.851376533508301
Validation loss: 1.7548649774657354
Epoch: 4| Step: 34
Training loss: 3.2773959636688232
Validation loss: 1.718072944217258
Epoch: 4| Step: 35
Training loss: 1.3735644817352295
Validation loss: 1.7021793093946245
Epoch: 4| Step: 36
Training loss: 2.4606688022613525
Validation loss: 1.7417317032814026
Epoch: 4| Step: 37
Training loss: 2.5142741203308105
Validation loss: 1.7783181049205639
Epoch: 4| Step: 38
Training loss: 1.5695340633392334
Validation loss: 1.762794300361916
Epoch: 4| Step: 39
Training loss: 2.5202956199645996
Validation loss: 1.7165297269821167
Epoch: 4| Step: 40
Training loss: 2.956860065460205
Validation loss: 1.7011299883877788
Epoch: 4| Step: 41
Training loss: 1.7601150274276733
Validation loss: 1.7051183945602841
Epoch: 4| Step: 42
Training loss: 3.26483154296875
Validation loss: 1.7173552248213027
Epoch: 4| Step: 43
Training loss: 2.6981379985809326
Validation loss: 1.703706059190962
Epoch: 4| Step: 44
Training loss: 2.4350943565368652
Validation loss: 1.8161392741733127
Epoch: 4| Step: 45
Training loss: 2.260836124420166
Validation loss: 1.713054042171549
Epoch: 4| Step: 46
Training loss: 2.0569088459014893
Validation loss: 1.7283186150921717
Epoch: 4| Step: 47
Training loss: 1.521116018295288
Validation loss: 1.747468230900941
Epoch: 4| Step: 48
Training loss: 2.8714890480041504
Validation loss: 1.7323144872983296
Epoch: 4| Step: 49
Training loss: 1.2404509782791138
Validation loss: 1.7964488665262859
Epoch: 4| Step: 50
Training loss: 1.3981847763061523
Validation loss: 1.6732433261694732
Epoch: 4| Step: 51
Training loss: 2.6524758338928223
Validation loss: 1.7587175104353163
Epoch: 4| Step: 52
Training loss: 1.9284398555755615
Validation loss: 1.7167606817351446
Epoch: 4| Step: 53
Training loss: 1.9415092468261719
Validation loss: 1.7637442019250658
Epoch: 4| Step: 54
Training loss: 2.459021806716919
Validation loss: 1.7108717936056632
Epoch: 4| Step: 55
Training loss: 2.62451171875
Validation loss: 1.7239218023088243
Epoch: 4| Step: 56
Training loss: 2.2962563037872314
Validation loss: 1.7736361644886158
Epoch: 4| Step: 57
Training loss: 2.058537244796753
Validation loss: 1.7006727026568518
Epoch: 4| Step: 58
Training loss: 2.491532564163208
Validation loss: 1.7505625331843342
Epoch: 4| Step: 59
Training loss: 2.0953354835510254
Validation loss: 1.7804916236135695
Epoch: 4| Step: 60
Training loss: 2.174734115600586
Validation loss: 1.7465025848812528
Epoch: 4| Step: 61
Training loss: 1.975189208984375
Validation loss: 1.7733547290166218
Epoch: 4| Step: 62
Training loss: 1.2141715288162231
Validation loss: 1.6921768343007122
Epoch: 4| Step: 63
Training loss: 2.361449718475342
Validation loss: 1.7793946994675531
Epoch: 5| Step: 0
Training loss: 1.5362783670425415
Validation loss: 1.748541200602496
Epoch: 5| Step: 1
Training loss: 2.379178285598755
Validation loss: 1.773144295922032
Epoch: 5| Step: 2
Training loss: 1.4932917356491089
Validation loss: 1.7336032434746071
Epoch: 5| Step: 3
Training loss: 2.6984050273895264
Validation loss: 1.7377599985511214
Epoch: 5| Step: 4
Training loss: 1.6758944988250732
Validation loss: 1.7743337330994782
Epoch: 5| Step: 5
Training loss: 3.598599672317505
Validation loss: 1.7304384134433888
Epoch: 5| Step: 6
Training loss: 3.6815409660339355
Validation loss: 1.7283012204700046
Epoch: 5| Step: 7
Training loss: 1.7462871074676514
Validation loss: 1.7178305630330686
Epoch: 5| Step: 8
Training loss: 1.951438546180725
Validation loss: 1.7463831901550293
Epoch: 5| Step: 9
Training loss: 1.3801729679107666
Validation loss: 1.7563770082261827
Epoch: 5| Step: 10
Training loss: 2.7561776638031006
Validation loss: 1.7351639844753124
Epoch: 5| Step: 11
Training loss: 2.4972681999206543
Validation loss: 1.7692403705031783
Epoch: 5| Step: 12
Training loss: 1.6572545766830444
Validation loss: 1.7757847529870492
Epoch: 5| Step: 13
Training loss: 2.5467047691345215
Validation loss: 1.790862339514273
Epoch: 5| Step: 14
Training loss: 2.9146437644958496
Validation loss: 1.7876358385439273
Epoch: 5| Step: 15
Training loss: 1.0922906398773193
Validation loss: 1.7112108645615753
Epoch: 5| Step: 16
Training loss: 2.814143419265747
Validation loss: 1.7098458961204246
Epoch: 5| Step: 17
Training loss: 2.3998897075653076
Validation loss: 1.813971742435738
Epoch: 5| Step: 18
Training loss: 3.018239974975586
Validation loss: 1.7729466756184895
Epoch: 5| Step: 19
Training loss: 2.467197895050049
Validation loss: 1.7234575351079304
Epoch: 5| Step: 20
Training loss: 2.5701091289520264
Validation loss: 1.7194027746165241
Epoch: 5| Step: 21
Training loss: 3.1539788246154785
Validation loss: 1.7112962316583704
Epoch: 5| Step: 22
Training loss: 2.401615858078003
Validation loss: 1.7493658617690757
Epoch: 5| Step: 23
Training loss: 1.6395213603973389
Validation loss: 1.7283749845292833
Epoch: 5| Step: 24
Training loss: 1.9795547723770142
Validation loss: 1.7804412289902016
Epoch: 5| Step: 25
Training loss: 1.265113115310669
Validation loss: 1.782750089963277
Epoch: 5| Step: 26
Training loss: 1.9266307353973389
Validation loss: 1.7316179231361106
Epoch: 5| Step: 27
Training loss: 2.3174853324890137
Validation loss: 1.7528117497762044
Epoch: 5| Step: 28
Training loss: 2.2047789096832275
Validation loss: 1.7736478823202628
Epoch: 5| Step: 29
Training loss: 2.3452436923980713
Validation loss: 1.779753272180204
Epoch: 5| Step: 30
Training loss: 2.6763103008270264
Validation loss: 1.7823058940746166
Epoch: 5| Step: 31
Training loss: 2.0903849601745605
Validation loss: 1.7553508392086736
Epoch: 5| Step: 32
Training loss: 2.5028839111328125
Validation loss: 1.7819061279296875
Epoch: 5| Step: 33
Training loss: 1.6955044269561768
Validation loss: 1.7574045481505218
Epoch: 5| Step: 34
Training loss: 1.6075588464736938
Validation loss: 1.7438216695079096
Epoch: 5| Step: 35
Training loss: 2.214698076248169
Validation loss: 1.7747654385036893
Epoch: 5| Step: 36
Training loss: 3.1316585540771484
Validation loss: 1.785952510657134
Epoch: 5| Step: 37
Training loss: 2.6800589561462402
Validation loss: 1.7512973182731204
Epoch: 5| Step: 38
Training loss: 1.6598339080810547
Validation loss: 1.7494066490067377
Epoch: 5| Step: 39
Training loss: 2.6643218994140625
Validation loss: 1.7748391098446317
Epoch: 5| Step: 40
Training loss: 1.723371148109436
Validation loss: 1.8058918162628457
Epoch: 5| Step: 41
Training loss: 2.495126724243164
Validation loss: 1.7907819350560505
Epoch: 5| Step: 42
Training loss: 2.2757363319396973
Validation loss: 1.7646360132429335
Epoch: 5| Step: 43
Training loss: 1.6567398309707642
Validation loss: 1.8084024797987055
Epoch: 5| Step: 44
Training loss: 3.3462131023406982
Validation loss: 1.7457890311876934
Epoch: 5| Step: 45
Training loss: 2.3318634033203125
Validation loss: 1.7592659747159038
Epoch: 5| Step: 46
Training loss: 2.4804415702819824
Validation loss: 1.734343272668344
Epoch: 5| Step: 47
Training loss: 3.028076410293579
Validation loss: 1.7147001756562128
Epoch: 5| Step: 48
Training loss: 2.661134958267212
Validation loss: 1.7903842020917822
Epoch: 5| Step: 49
Training loss: 1.6084998846054077
Validation loss: 1.7809440162446764
Epoch: 5| Step: 50
Training loss: 2.3273472785949707
Validation loss: 1.745341490816187
Epoch: 5| Step: 51
Training loss: 2.3082611560821533
Validation loss: 1.7178337596080921
Epoch: 5| Step: 52
Training loss: 2.4172523021698
Validation loss: 1.757679749418188
Epoch: 5| Step: 53
Training loss: 2.4284090995788574
Validation loss: 1.825905523918293
Epoch: 5| Step: 54
Training loss: 2.664451837539673
Validation loss: 1.766492439640893
Epoch: 5| Step: 55
Training loss: 3.287085771560669
Validation loss: 1.7924237251281738
Epoch: 5| Step: 56
Training loss: 1.6607029438018799
Validation loss: 1.7563376868212666
Epoch: 5| Step: 57
Training loss: 2.13120698928833
Validation loss: 1.7094563047091167
Epoch: 5| Step: 58
Training loss: 2.8265843391418457
Validation loss: 1.7659582893053691
Epoch: 5| Step: 59
Training loss: 2.030825138092041
Validation loss: 1.76337347207246
Epoch: 5| Step: 60
Training loss: 2.078605890274048
Validation loss: 1.7766935030619304
Epoch: 5| Step: 61
Training loss: 1.9403667449951172
Validation loss: 1.760380537421615
Epoch: 5| Step: 62
Training loss: 2.860490083694458
Validation loss: 1.8069467213418748
Epoch: 5| Step: 63
Training loss: 2.7878098487854004
Validation loss: 1.7716851366890802
Epoch: 6| Step: 0
Training loss: 1.3106406927108765
Validation loss: 1.7088828042701438
Epoch: 6| Step: 1
Training loss: 2.565866231918335
Validation loss: 1.7483399907747905
Epoch: 6| Step: 2
Training loss: 1.6331779956817627
Validation loss: 1.7326920606471874
Epoch: 6| Step: 3
Training loss: 1.6884177923202515
Validation loss: 1.7839720403706585
Epoch: 6| Step: 4
Training loss: 2.9081015586853027
Validation loss: 1.7783278315155595
Epoch: 6| Step: 5
Training loss: 1.0872013568878174
Validation loss: 1.7995723397643477
Epoch: 6| Step: 6
Training loss: 2.886789560317993
Validation loss: 1.7567953864733379
Epoch: 6| Step: 7
Training loss: 2.0523598194122314
Validation loss: 1.7996065462077107
Epoch: 6| Step: 8
Training loss: 2.9145166873931885
Validation loss: 1.7518573270903692
Epoch: 6| Step: 9
Training loss: 2.7246956825256348
Validation loss: 1.7437592811054654
Epoch: 6| Step: 10
Training loss: 2.852540969848633
Validation loss: 1.7696955855245944
Epoch: 6| Step: 11
Training loss: 2.024115800857544
Validation loss: 1.7394354851157576
Epoch: 6| Step: 12
Training loss: 2.737368106842041
Validation loss: 1.7321986136613068
Epoch: 6| Step: 13
Training loss: 1.7786266803741455
Validation loss: 1.7399863026760243
Epoch: 6| Step: 14
Training loss: 2.569276809692383
Validation loss: 1.733601283144068
Epoch: 6| Step: 15
Training loss: 2.893214464187622
Validation loss: 1.7596613588156524
Epoch: 6| Step: 16
Training loss: 1.5785114765167236
Validation loss: 1.7467303651350516
Epoch: 6| Step: 17
Training loss: 3.666743040084839
Validation loss: 1.7550373121544167
Epoch: 6| Step: 18
Training loss: 3.1894118785858154
Validation loss: 1.7448435812084764
Epoch: 6| Step: 19
Training loss: 2.5288639068603516
Validation loss: 1.7404281474925853
Epoch: 6| Step: 20
Training loss: 2.036611795425415
Validation loss: 1.7667207011470087
Epoch: 6| Step: 21
Training loss: 2.515946626663208
Validation loss: 1.7575222253799438
Epoch: 6| Step: 22
Training loss: 1.3208078145980835
Validation loss: 1.6949823388346918
Epoch: 6| Step: 23
Training loss: 2.8170244693756104
Validation loss: 1.772825453016493
Epoch: 6| Step: 24
Training loss: 2.5680789947509766
Validation loss: 1.7274324496587117
Epoch: 6| Step: 25
Training loss: 1.0882203578948975
Validation loss: 1.7358404707025599
Epoch: 6| Step: 26
Training loss: 1.0153645277023315
Validation loss: 1.721196675742114
Epoch: 6| Step: 27
Training loss: 2.110243558883667
Validation loss: 1.7378651808809351
Epoch: 6| Step: 28
Training loss: 3.2738890647888184
Validation loss: 1.7418635421329074
Epoch: 6| Step: 29
Training loss: 2.283801555633545
Validation loss: 1.7076535489824083
Epoch: 6| Step: 30
Training loss: 3.2283763885498047
Validation loss: 1.7548049798718206
Epoch: 6| Step: 31
Training loss: 2.5817482471466064
Validation loss: 1.718723177909851
Epoch: 6| Step: 32
Training loss: 3.1601433753967285
Validation loss: 1.7322961158222623
Epoch: 6| Step: 33
Training loss: 2.6767578125
Validation loss: 1.7659423881106906
Epoch: 6| Step: 34
Training loss: 2.0543863773345947
Validation loss: 1.7564450634850397
Epoch: 6| Step: 35
Training loss: 1.3000770807266235
Validation loss: 1.7635069533630654
Epoch: 6| Step: 36
Training loss: 1.2652851343154907
Validation loss: 1.7544920091275815
Epoch: 6| Step: 37
Training loss: 1.523479700088501
Validation loss: 1.7805571578167103
Epoch: 6| Step: 38
Training loss: 2.2743308544158936
Validation loss: 1.7643612998503226
Epoch: 6| Step: 39
Training loss: 1.3391859531402588
Validation loss: 1.7483192880948384
Epoch: 6| Step: 40
Training loss: 2.343090057373047
Validation loss: 1.7030227956948456
Epoch: 6| Step: 41
Training loss: 2.695657253265381
Validation loss: 1.7594223199067291
Epoch: 6| Step: 42
Training loss: 3.339160919189453
Validation loss: 1.6971099862345942
Epoch: 6| Step: 43
Training loss: 2.99741530418396
Validation loss: 1.7280164824591742
Epoch: 6| Step: 44
Training loss: 2.0204968452453613
Validation loss: 1.7867934946660642
Epoch: 6| Step: 45
Training loss: 2.576707601547241
Validation loss: 1.7491623715118125
Epoch: 6| Step: 46
Training loss: 1.155070185661316
Validation loss: 1.7901715614177562
Epoch: 6| Step: 47
Training loss: 1.8670603036880493
Validation loss: 1.778229037920634
Epoch: 6| Step: 48
Training loss: 1.8728077411651611
Validation loss: 1.721998519367642
Epoch: 6| Step: 49
Training loss: 2.371617078781128
Validation loss: 1.7879826294051275
Epoch: 6| Step: 50
Training loss: 2.9215996265411377
Validation loss: 1.7722497427905048
Epoch: 6| Step: 51
Training loss: 1.5249826908111572
Validation loss: 1.740961233774821
Epoch: 6| Step: 52
Training loss: 1.9959499835968018
Validation loss: 1.7645662669782285
Epoch: 6| Step: 53
Training loss: 3.0650408267974854
Validation loss: 1.8038589314178184
Epoch: 6| Step: 54
Training loss: 2.534777879714966
Validation loss: 1.7830403358848006
Epoch: 6| Step: 55
Training loss: 2.984096050262451
Validation loss: 1.7681767808066473
Epoch: 6| Step: 56
Training loss: 2.124108076095581
Validation loss: 1.7833635012308757
Epoch: 6| Step: 57
Training loss: 1.8153207302093506
Validation loss: 1.7614316057275843
Epoch: 6| Step: 58
Training loss: 2.1858291625976562
Validation loss: 1.7558827930026584
Epoch: 6| Step: 59
Training loss: 2.458754301071167
Validation loss: 1.7251744800143771
Epoch: 6| Step: 60
Training loss: 2.691746950149536
Validation loss: 1.734250639323835
Epoch: 6| Step: 61
Training loss: 1.3946157693862915
Validation loss: 1.755265094615795
Epoch: 6| Step: 62
Training loss: 2.6203722953796387
Validation loss: 1.7542704034734655
Epoch: 6| Step: 63
Training loss: 2.0051562786102295
Validation loss: 1.733407817505024
Epoch: 7| Step: 0
Training loss: 2.825514316558838
Validation loss: 1.7224446490958885
Epoch: 7| Step: 1
Training loss: 3.387014389038086
Validation loss: 1.801697263011226
Epoch: 7| Step: 2
Training loss: 2.110325813293457
Validation loss: 1.745652719780251
Epoch: 7| Step: 3
Training loss: 1.9050657749176025
Validation loss: 1.7545104048870228
Epoch: 7| Step: 4
Training loss: 2.6550097465515137
Validation loss: 1.7290482344450775
Epoch: 7| Step: 5
Training loss: 3.603287935256958
Validation loss: 1.7408011356989543
Epoch: 7| Step: 6
Training loss: 3.3693222999572754
Validation loss: 1.7316677614494607
Epoch: 7| Step: 7
Training loss: 1.240248203277588
Validation loss: 1.684616016017066
Epoch: 7| Step: 8
Training loss: 2.559051036834717
Validation loss: 1.7560717198583815
Epoch: 7| Step: 9
Training loss: 1.2711185216903687
Validation loss: 1.715444681821046
Epoch: 7| Step: 10
Training loss: 2.2244255542755127
Validation loss: 1.779299506434688
Epoch: 7| Step: 11
Training loss: 1.7890427112579346
Validation loss: 1.7688306901190016
Epoch: 7| Step: 12
Training loss: 3.5277512073516846
Validation loss: 1.7473129453482452
Epoch: 7| Step: 13
Training loss: 3.1583335399627686
Validation loss: 1.8374234548321478
Epoch: 7| Step: 14
Training loss: 2.6521401405334473
Validation loss: 1.7445808737366288
Epoch: 7| Step: 15
Training loss: 2.1060118675231934
Validation loss: 1.7805130283037822
Epoch: 7| Step: 16
Training loss: 2.2299344539642334
Validation loss: 1.7808817006923534
Epoch: 7| Step: 17
Training loss: 1.9721667766571045
Validation loss: 1.8144023506729692
Epoch: 7| Step: 18
Training loss: 1.7158195972442627
Validation loss: 1.7830508395477578
Epoch: 7| Step: 19
Training loss: 1.5701899528503418
Validation loss: 1.7948173174151667
Epoch: 7| Step: 20
Training loss: 2.3445773124694824
Validation loss: 1.7632880343331232
Epoch: 7| Step: 21
Training loss: 2.2337937355041504
Validation loss: 1.79417265786065
Epoch: 7| Step: 22
Training loss: 3.086371421813965
Validation loss: 1.7598607186917905
Epoch: 7| Step: 23
Training loss: 2.3304965496063232
Validation loss: 1.7413958068247195
Epoch: 7| Step: 24
Training loss: 2.479637861251831
Validation loss: 1.806633432706197
Epoch: 7| Step: 25
Training loss: 2.1624701023101807
Validation loss: 1.7372971331631695
Epoch: 7| Step: 26
Training loss: 1.6355984210968018
Validation loss: 1.758752551343706
Epoch: 7| Step: 27
Training loss: 2.1104609966278076
Validation loss: 1.7621737806885331
Epoch: 7| Step: 28
Training loss: 2.55730938911438
Validation loss: 1.8058817187945049
Epoch: 7| Step: 29
Training loss: 1.811898946762085
Validation loss: 1.7528895095542625
Epoch: 7| Step: 30
Training loss: 2.8016180992126465
Validation loss: 1.74686716220997
Epoch: 7| Step: 31
Training loss: 2.6804847717285156
Validation loss: 1.7672155124169808
Epoch: 7| Step: 32
Training loss: 2.0207035541534424
Validation loss: 1.7116228386207863
Epoch: 7| Step: 33
Training loss: 1.895864486694336
Validation loss: 1.7991242519131414
Epoch: 7| Step: 34
Training loss: 1.9526615142822266
Validation loss: 1.734556167214005
Epoch: 7| Step: 35
Training loss: 1.4027270078659058
Validation loss: 1.8259345337196633
Epoch: 7| Step: 36
Training loss: 2.5429999828338623
Validation loss: 1.7841715172485069
Epoch: 7| Step: 37
Training loss: 2.099771499633789
Validation loss: 1.7965079060307256
Epoch: 7| Step: 38
Training loss: 2.3617770671844482
Validation loss: 1.7558837422618159
Epoch: 7| Step: 39
Training loss: 2.535292387008667
Validation loss: 1.7964179140550118
Epoch: 7| Step: 40
Training loss: 1.9428470134735107
Validation loss: 1.7799991722460147
Epoch: 7| Step: 41
Training loss: 2.298335552215576
Validation loss: 1.761261847284105
Epoch: 7| Step: 42
Training loss: 1.7591526508331299
Validation loss: 1.759461729614823
Epoch: 7| Step: 43
Training loss: 2.3015220165252686
Validation loss: 1.7433689523626257
Epoch: 7| Step: 44
Training loss: 2.250378131866455
Validation loss: 1.7787698728066903
Epoch: 7| Step: 45
Training loss: 1.929216980934143
Validation loss: 1.8119518911397015
Epoch: 7| Step: 46
Training loss: 1.960648536682129
Validation loss: 1.7478365942283913
Epoch: 7| Step: 47
Training loss: 1.4362437725067139
Validation loss: 1.7146941864932026
Epoch: 7| Step: 48
Training loss: 3.327540636062622
Validation loss: 1.7162577841016982
Epoch: 7| Step: 49
Training loss: 2.8294615745544434
Validation loss: 1.7799447841114469
Epoch: 7| Step: 50
Training loss: 2.9803099632263184
Validation loss: 1.741806639565362
Epoch: 7| Step: 51
Training loss: 1.4676687717437744
Validation loss: 1.7889798206311684
Epoch: 7| Step: 52
Training loss: 2.6378321647644043
Validation loss: 1.7787519075252392
Epoch: 7| Step: 53
Training loss: 2.3964130878448486
Validation loss: 1.7677731447749667
Epoch: 7| Step: 54
Training loss: 1.9275686740875244
Validation loss: 1.7729612743413006
Epoch: 7| Step: 55
Training loss: 1.8496761322021484
Validation loss: 1.699934341289379
Epoch: 7| Step: 56
Training loss: 2.014832019805908
Validation loss: 1.7219865145506683
Epoch: 7| Step: 57
Training loss: 2.6402785778045654
Validation loss: 1.726818323135376
Epoch: 7| Step: 58
Training loss: 2.159827947616577
Validation loss: 1.7559618971965931
Epoch: 7| Step: 59
Training loss: 2.5552456378936768
Validation loss: 1.7644153413949188
Epoch: 7| Step: 60
Training loss: 2.976163864135742
Validation loss: 1.8293121346720942
Epoch: 7| Step: 61
Training loss: 1.554736852645874
Validation loss: 1.7392746011416118
Epoch: 7| Step: 62
Training loss: 2.2230823040008545
Validation loss: 1.8305201994048224
Epoch: 7| Step: 63
Training loss: 2.4151902198791504
Validation loss: 1.7938439161689193
Epoch: 8| Step: 0
Training loss: 2.0431787967681885
Validation loss: 1.6993831705164026
Epoch: 8| Step: 1
Training loss: 2.335390329360962
Validation loss: 1.7529251156029877
Epoch: 8| Step: 2
Training loss: 1.156659483909607
Validation loss: 1.7523597213957045
Epoch: 8| Step: 3
Training loss: 2.8065192699432373
Validation loss: 1.7451130836098283
Epoch: 8| Step: 4
Training loss: 1.8407214879989624
Validation loss: 1.7696716432218198
Epoch: 8| Step: 5
Training loss: 3.0433812141418457
Validation loss: 1.7713338357430917
Epoch: 8| Step: 6
Training loss: 1.833041787147522
Validation loss: 1.838369561566247
Epoch: 8| Step: 7
Training loss: 2.6469717025756836
Validation loss: 1.7343883470252708
Epoch: 8| Step: 8
Training loss: 1.9439547061920166
Validation loss: 1.7688672012752957
Epoch: 8| Step: 9
Training loss: 1.8946892023086548
Validation loss: 1.7571053593247026
Epoch: 8| Step: 10
Training loss: 1.8705215454101562
Validation loss: 1.7952667033230816
Epoch: 8| Step: 11
Training loss: 2.3727192878723145
Validation loss: 1.7883622646331787
Epoch: 8| Step: 12
Training loss: 2.088733434677124
Validation loss: 1.7378871705796983
Epoch: 8| Step: 13
Training loss: 3.0782861709594727
Validation loss: 1.7832218496887773
Epoch: 8| Step: 14
Training loss: 2.4629173278808594
Validation loss: 1.7321891519758437
Epoch: 8| Step: 15
Training loss: 2.686121940612793
Validation loss: 1.8000821272532146
Epoch: 8| Step: 16
Training loss: 1.5178039073944092
Validation loss: 1.7433248118118003
Epoch: 8| Step: 17
Training loss: 2.5564208030700684
Validation loss: 1.739194393157959
Epoch: 8| Step: 18
Training loss: 2.250192642211914
Validation loss: 1.800775788448475
Epoch: 8| Step: 19
Training loss: 2.189364194869995
Validation loss: 1.8252397665271052
Epoch: 8| Step: 20
Training loss: 1.8347289562225342
Validation loss: 1.7727089987860785
Epoch: 8| Step: 21
Training loss: 2.7009522914886475
Validation loss: 1.732221058121434
Epoch: 8| Step: 22
Training loss: 1.4487107992172241
Validation loss: 1.7431194517347548
Epoch: 8| Step: 23
Training loss: 2.1244025230407715
Validation loss: 1.738701961658619
Epoch: 8| Step: 24
Training loss: 2.0631988048553467
Validation loss: 1.7687682973013983
Epoch: 8| Step: 25
Training loss: 1.7118412256240845
Validation loss: 1.7593076648535553
Epoch: 8| Step: 26
Training loss: 3.6599254608154297
Validation loss: 1.7252250181304083
Epoch: 8| Step: 27
Training loss: 2.5718042850494385
Validation loss: 1.7698152793778315
Epoch: 8| Step: 28
Training loss: 1.1027408838272095
Validation loss: 1.7612787705880624
Epoch: 8| Step: 29
Training loss: 2.182002544403076
Validation loss: 1.8079617553287082
Epoch: 8| Step: 30
Training loss: 2.270397663116455
Validation loss: 1.7861988412009344
Epoch: 8| Step: 31
Training loss: 3.119154930114746
Validation loss: 1.780465441721457
Epoch: 8| Step: 32
Training loss: 2.6318163871765137
Validation loss: 1.6861830993934914
Epoch: 8| Step: 33
Training loss: 2.9516234397888184
Validation loss: 1.7946421084580597
Epoch: 8| Step: 34
Training loss: 2.856816291809082
Validation loss: 1.7897754929683827
Epoch: 8| Step: 35
Training loss: 2.050478935241699
Validation loss: 1.7896236048804388
Epoch: 8| Step: 36
Training loss: 1.4166080951690674
Validation loss: 1.796082231733534
Epoch: 8| Step: 37
Training loss: 2.310438632965088
Validation loss: 1.7673478170677468
Epoch: 8| Step: 38
Training loss: 1.8209435939788818
Validation loss: 1.8139535475660253
Epoch: 8| Step: 39
Training loss: 2.072565793991089
Validation loss: 1.7943567942689966
Epoch: 8| Step: 40
Training loss: 2.2438571453094482
Validation loss: 1.7756615391484014
Epoch: 8| Step: 41
Training loss: 1.6906589269638062
Validation loss: 1.7570414697682415
Epoch: 8| Step: 42
Training loss: 4.163122653961182
Validation loss: 1.7785931626955669
Epoch: 8| Step: 43
Training loss: 2.589538335800171
Validation loss: 1.729574112980454
Epoch: 8| Step: 44
Training loss: 2.94815731048584
Validation loss: 1.7344247875390228
Epoch: 8| Step: 45
Training loss: 3.3235275745391846
Validation loss: 1.7704560072333724
Epoch: 8| Step: 46
Training loss: 0.8330762982368469
Validation loss: 1.7535513175858393
Epoch: 8| Step: 47
Training loss: 2.689302921295166
Validation loss: 1.7663806853470978
Epoch: 8| Step: 48
Training loss: 3.486706256866455
Validation loss: 1.7630018437350239
Epoch: 8| Step: 49
Training loss: 2.494535207748413
Validation loss: 1.7677218538743478
Epoch: 8| Step: 50
Training loss: 1.956064224243164
Validation loss: 1.7515978614489238
Epoch: 8| Step: 51
Training loss: 2.0068347454071045
Validation loss: 1.7308948040008545
Epoch: 8| Step: 52
Training loss: 1.8787009716033936
Validation loss: 1.7566957341300116
Epoch: 8| Step: 53
Training loss: 1.5158100128173828
Validation loss: 1.7026644702310916
Epoch: 8| Step: 54
Training loss: 1.5607370138168335
Validation loss: 1.7335449501320168
Epoch: 8| Step: 55
Training loss: 2.2933812141418457
Validation loss: 1.7042091621292963
Epoch: 8| Step: 56
Training loss: 2.2727885246276855
Validation loss: 1.6989750067392986
Epoch: 8| Step: 57
Training loss: 1.8811728954315186
Validation loss: 1.727518375273104
Epoch: 8| Step: 58
Training loss: 1.6698118448257446
Validation loss: 1.7147216995557149
Epoch: 8| Step: 59
Training loss: 2.264540433883667
Validation loss: 1.7368990425710324
Epoch: 8| Step: 60
Training loss: 2.937763214111328
Validation loss: 1.7607929110527039
Epoch: 8| Step: 61
Training loss: 1.8075088262557983
Validation loss: 1.7525202874784116
Epoch: 8| Step: 62
Training loss: 2.2622570991516113
Validation loss: 1.7134054722609344
Epoch: 8| Step: 63
Training loss: 1.3054362535476685
Validation loss: 1.7021102198848017
Epoch: 9| Step: 0
Training loss: 1.2306666374206543
Validation loss: 1.7363788308920685
Epoch: 9| Step: 1
Training loss: 1.480248212814331
Validation loss: 1.7372171039934512
Epoch: 9| Step: 2
Training loss: 3.421923875808716
Validation loss: 1.7575561978198864
Epoch: 9| Step: 3
Training loss: 2.465388536453247
Validation loss: 1.750988119178348
Epoch: 9| Step: 4
Training loss: 3.062981128692627
Validation loss: 1.7687137016543635
Epoch: 9| Step: 5
Training loss: 1.6425302028656006
Validation loss: 1.7782295567018014
Epoch: 9| Step: 6
Training loss: 2.754976272583008
Validation loss: 1.7337440053621929
Epoch: 9| Step: 7
Training loss: 2.6734604835510254
Validation loss: 1.7580070142392759
Epoch: 9| Step: 8
Training loss: 2.125340461730957
Validation loss: 1.7693566216362848
Epoch: 9| Step: 9
Training loss: 2.867974042892456
Validation loss: 1.7977699350427698
Epoch: 9| Step: 10
Training loss: 2.7181236743927
Validation loss: 1.7472507070612024
Epoch: 9| Step: 11
Training loss: 1.8306853771209717
Validation loss: 1.7296479874187045
Epoch: 9| Step: 12
Training loss: 2.9976305961608887
Validation loss: 1.768679349510758
Epoch: 9| Step: 13
Training loss: 3.688512086868286
Validation loss: 1.7907037999894884
Epoch: 9| Step: 14
Training loss: 2.2625675201416016
Validation loss: 1.7819727857907612
Epoch: 9| Step: 15
Training loss: 2.1891489028930664
Validation loss: 1.785507133713475
Epoch: 9| Step: 16
Training loss: 3.498314380645752
Validation loss: 1.7439132112043876
Epoch: 9| Step: 17
Training loss: 1.379126787185669
Validation loss: 1.7838234724821869
Epoch: 9| Step: 18
Training loss: 1.8815349340438843
Validation loss: 1.7665137184990778
Epoch: 9| Step: 19
Training loss: 1.6825282573699951
Validation loss: 1.8299995925691392
Epoch: 9| Step: 20
Training loss: 1.5894359350204468
Validation loss: 1.7474536763297186
Epoch: 9| Step: 21
Training loss: 2.6550352573394775
Validation loss: 1.7997667303791753
Epoch: 9| Step: 22
Training loss: 1.4769728183746338
Validation loss: 1.751968756869987
Epoch: 9| Step: 23
Training loss: 2.8383800983428955
Validation loss: 1.7731520511485912
Epoch: 9| Step: 24
Training loss: 1.350501537322998
Validation loss: 1.7783144889054474
Epoch: 9| Step: 25
Training loss: 1.023629903793335
Validation loss: 1.7500861176738032
Epoch: 9| Step: 26
Training loss: 2.033149003982544
Validation loss: 1.766326732105679
Epoch: 9| Step: 27
Training loss: 1.7736088037490845
Validation loss: 1.829940919522886
Epoch: 9| Step: 28
Training loss: 2.954875946044922
Validation loss: 1.768090146559256
Epoch: 9| Step: 29
Training loss: 1.7323452234268188
Validation loss: 1.7309622058161982
Epoch: 9| Step: 30
Training loss: 0.914618968963623
Validation loss: 1.7708629391811512
Epoch: 9| Step: 31
Training loss: 1.7625949382781982
Validation loss: 1.7244859293655113
Epoch: 9| Step: 32
Training loss: 1.519105076789856
Validation loss: 1.7293048214029383
Epoch: 9| Step: 33
Training loss: 1.5050488710403442
Validation loss: 1.768508423257757
Epoch: 9| Step: 34
Training loss: 1.5763095617294312
Validation loss: 1.7456276637536507
Epoch: 9| Step: 35
Training loss: 3.175992488861084
Validation loss: 1.816840061434993
Epoch: 9| Step: 36
Training loss: 2.466036319732666
Validation loss: 1.7110577137381942
Epoch: 9| Step: 37
Training loss: 2.088610887527466
Validation loss: 1.7344270966671131
Epoch: 9| Step: 38
Training loss: 2.806122303009033
Validation loss: 1.7489865080074027
Epoch: 9| Step: 39
Training loss: 2.69730544090271
Validation loss: 1.788050373395284
Epoch: 9| Step: 40
Training loss: 1.821549654006958
Validation loss: 1.7708970529061776
Epoch: 9| Step: 41
Training loss: 3.494716167449951
Validation loss: 1.6730237823945504
Epoch: 9| Step: 42
Training loss: 2.6108670234680176
Validation loss: 1.7170650561650593
Epoch: 9| Step: 43
Training loss: 1.6710771322250366
Validation loss: 1.7635659067719072
Epoch: 9| Step: 44
Training loss: 2.222702741622925
Validation loss: 1.7705927115899545
Epoch: 9| Step: 45
Training loss: 3.542938232421875
Validation loss: 1.7183618854593348
Epoch: 9| Step: 46
Training loss: 3.765150547027588
Validation loss: 1.7653220958179898
Epoch: 9| Step: 47
Training loss: 1.6378352642059326
Validation loss: 1.7891288487999528
Epoch: 9| Step: 48
Training loss: 1.9710429906845093
Validation loss: 1.7285487055778503
Epoch: 9| Step: 49
Training loss: 2.714076519012451
Validation loss: 1.739906116768166
Epoch: 9| Step: 50
Training loss: 1.797149896621704
Validation loss: 1.7334317653267473
Epoch: 9| Step: 51
Training loss: 2.7810826301574707
Validation loss: 1.7837866500571922
Epoch: 9| Step: 52
Training loss: 1.9129749536514282
Validation loss: 1.7514292840604428
Epoch: 9| Step: 53
Training loss: 2.5317442417144775
Validation loss: 1.71365487575531
Epoch: 9| Step: 54
Training loss: 1.7276229858398438
Validation loss: 1.6898371290277552
Epoch: 9| Step: 55
Training loss: 3.5711073875427246
Validation loss: 1.8070051581771285
Epoch: 9| Step: 56
Training loss: 1.7186946868896484
Validation loss: 1.7629926602045696
Epoch: 9| Step: 57
Training loss: 2.923952579498291
Validation loss: 1.7265524820045188
Epoch: 9| Step: 58
Training loss: 1.4515910148620605
Validation loss: 1.7490411268340216
Epoch: 9| Step: 59
Training loss: 2.546424627304077
Validation loss: 1.7372274310500533
Epoch: 9| Step: 60
Training loss: 2.614778995513916
Validation loss: 1.708110592983387
Epoch: 9| Step: 61
Training loss: 2.6873180866241455
Validation loss: 1.7125422844180354
Epoch: 9| Step: 62
Training loss: 2.540595531463623
Validation loss: 1.731200514016328
Epoch: 9| Step: 63
Training loss: 1.800825834274292
Validation loss: 1.698595267755014
Epoch: 10| Step: 0
Training loss: 1.735649824142456
Validation loss: 1.733859293990665
Epoch: 10| Step: 1
Training loss: 1.2483761310577393
Validation loss: 1.7564436969933686
Epoch: 10| Step: 2
Training loss: 2.8696796894073486
Validation loss: 1.7621302582599498
Epoch: 10| Step: 3
Training loss: 2.0290989875793457
Validation loss: 1.7660757568147447
Epoch: 10| Step: 4
Training loss: 2.270827054977417
Validation loss: 1.6988629742904946
Epoch: 10| Step: 5
Training loss: 2.0978055000305176
Validation loss: 1.67999596507461
Epoch: 10| Step: 6
Training loss: 1.9750635623931885
Validation loss: 1.725641135816221
Epoch: 10| Step: 7
Training loss: 3.049396514892578
Validation loss: 1.8038899170027838
Epoch: 10| Step: 8
Training loss: 2.5362956523895264
Validation loss: 1.8278986811637878
Epoch: 10| Step: 9
Training loss: 0.8816262483596802
Validation loss: 1.7219264220308375
Epoch: 10| Step: 10
Training loss: 3.3233044147491455
Validation loss: 1.769091718726688
Epoch: 10| Step: 11
Training loss: 2.4106361865997314
Validation loss: 1.7462763631785359
Epoch: 10| Step: 12
Training loss: 2.9524919986724854
Validation loss: 1.726981884903378
Epoch: 10| Step: 13
Training loss: 2.7901628017425537
Validation loss: 1.7136336962382
Epoch: 10| Step: 14
Training loss: 1.8173935413360596
Validation loss: 1.7381310242193717
Epoch: 10| Step: 15
Training loss: 2.0396533012390137
Validation loss: 1.7586976532582883
Epoch: 10| Step: 16
Training loss: 1.9498621225357056
Validation loss: 1.7482914516219386
Epoch: 10| Step: 17
Training loss: 3.575317859649658
Validation loss: 1.7186330512717918
Epoch: 10| Step: 18
Training loss: 1.9897197484970093
Validation loss: 1.7209505902396307
Epoch: 10| Step: 19
Training loss: 2.6695284843444824
Validation loss: 1.7351126979898523
Epoch: 10| Step: 20
Training loss: 2.143235683441162
Validation loss: 1.7115323267601155
Epoch: 10| Step: 21
Training loss: 2.8473458290100098
Validation loss: 1.7496146581791066
Epoch: 10| Step: 22
Training loss: 2.3204941749572754
Validation loss: 1.6979724301232233
Epoch: 10| Step: 23
Training loss: 2.3265717029571533
Validation loss: 1.7384857535362244
Epoch: 10| Step: 24
Training loss: 2.3370566368103027
Validation loss: 1.7089830416220206
Epoch: 10| Step: 25
Training loss: 2.1117050647735596
Validation loss: 1.775152583916982
Epoch: 10| Step: 26
Training loss: 2.4457449913024902
Validation loss: 1.687732497851054
Epoch: 10| Step: 27
Training loss: 2.3703575134277344
Validation loss: 1.7116143195717424
Epoch: 10| Step: 28
Training loss: 1.9308124780654907
Validation loss: 1.7365141201902319
Epoch: 10| Step: 29
Training loss: 1.6672413349151611
Validation loss: 1.7253049126377813
Epoch: 10| Step: 30
Training loss: 1.9156036376953125
Validation loss: 1.711236044212624
Epoch: 10| Step: 31
Training loss: 2.535773515701294
Validation loss: 1.753209858028977
Epoch: 10| Step: 32
Training loss: 2.9988722801208496
Validation loss: 1.745807040620733
Epoch: 10| Step: 33
Training loss: 1.3391149044036865
Validation loss: 1.7252388927671645
Epoch: 10| Step: 34
Training loss: 2.508808135986328
Validation loss: 1.7445710897445679
Epoch: 10| Step: 35
Training loss: 2.1609816551208496
Validation loss: 1.719151911912141
Epoch: 10| Step: 36
Training loss: 2.00492787361145
Validation loss: 1.6995219323370192
Epoch: 10| Step: 37
Training loss: 1.9367830753326416
Validation loss: 1.690555821966242
Epoch: 10| Step: 38
Training loss: 1.5482896566390991
Validation loss: 1.6868498612333227
Epoch: 10| Step: 39
Training loss: 1.8916618824005127
Validation loss: 1.7181233300103083
Epoch: 10| Step: 40
Training loss: 2.6683554649353027
Validation loss: 1.7401781291873366
Epoch: 10| Step: 41
Training loss: 2.415644884109497
Validation loss: 1.7314959278813116
Epoch: 10| Step: 42
Training loss: 2.694314479827881
Validation loss: 1.7508051196734111
Epoch: 10| Step: 43
Training loss: 1.3355388641357422
Validation loss: 1.7158741928912975
Epoch: 10| Step: 44
Training loss: 2.5370383262634277
Validation loss: 1.764620343844096
Epoch: 10| Step: 45
Training loss: 2.5647597312927246
Validation loss: 1.7729926330071908
Epoch: 10| Step: 46
Training loss: 1.7464039325714111
Validation loss: 1.750392218430837
Epoch: 10| Step: 47
Training loss: 1.7874500751495361
Validation loss: 1.7269933334103338
Epoch: 10| Step: 48
Training loss: 2.4807896614074707
Validation loss: 1.755518020303161
Epoch: 10| Step: 49
Training loss: 2.863750457763672
Validation loss: 1.7426541403487876
Epoch: 10| Step: 50
Training loss: 2.148589611053467
Validation loss: 1.7640596760643854
Epoch: 10| Step: 51
Training loss: 2.0198328495025635
Validation loss: 1.7176131517798812
Epoch: 10| Step: 52
Training loss: 2.5805912017822266
Validation loss: 1.692238946755727
Epoch: 10| Step: 53
Training loss: 2.465773820877075
Validation loss: 1.7349927138399195
Epoch: 10| Step: 54
Training loss: 1.6646283864974976
Validation loss: 1.7047333673194602
Epoch: 10| Step: 55
Training loss: 1.4878733158111572
Validation loss: 1.743949223447729
Epoch: 10| Step: 56
Training loss: 2.6128005981445312
Validation loss: 1.7898127105500963
Epoch: 10| Step: 57
Training loss: 1.7475532293319702
Validation loss: 1.7431301077206929
Epoch: 10| Step: 58
Training loss: 2.1435368061065674
Validation loss: 1.7380302371802154
Epoch: 10| Step: 59
Training loss: 2.6346521377563477
Validation loss: 1.739201600904818
Epoch: 10| Step: 60
Training loss: 3.046903371810913
Validation loss: 1.7290792950877436
Epoch: 10| Step: 61
Training loss: 2.8232054710388184
Validation loss: 1.7639801722985726
Epoch: 10| Step: 62
Training loss: 1.9477487802505493
Validation loss: 1.7425853963251468
Epoch: 10| Step: 63
Training loss: 2.183288097381592
Validation loss: 1.7108949798124808
