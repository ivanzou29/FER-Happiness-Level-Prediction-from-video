Epoch: 1| Step: 0
Training loss: 4.483952045440674
Validation loss: 5.0111178159713745
Epoch: 1| Step: 1
Training loss: 5.175886154174805
Validation loss: 4.754929423332214
Epoch: 1| Step: 2
Training loss: 5.055562973022461
Validation loss: 4.657193899154663
Epoch: 1| Step: 3
Training loss: 4.400973320007324
Validation loss: 4.659281134605408
Epoch: 1| Step: 4
Training loss: 4.722705841064453
Validation loss: 4.533897519111633
Epoch: 1| Step: 5
Training loss: 4.972263336181641
Validation loss: 4.500582575798035
Epoch: 1| Step: 6
Training loss: 4.789919853210449
Validation loss: 4.44831907749176
Epoch: 1| Step: 7
Training loss: 4.8388214111328125
Validation loss: 4.483609557151794
Epoch: 1| Step: 8
Training loss: 4.557490348815918
Validation loss: 4.403844594955444
Epoch: 1| Step: 9
Training loss: 4.551056861877441
Validation loss: 4.492047905921936
Epoch: 2| Step: 0
Training loss: 4.685138702392578
Validation loss: 4.419190764427185
Epoch: 2| Step: 1
Training loss: 3.6547625064849854
Validation loss: 4.344827890396118
Epoch: 2| Step: 2
Training loss: 4.568580627441406
Validation loss: 4.2935158014297485
Epoch: 2| Step: 3
Training loss: 4.215532302856445
Validation loss: 4.2864959836006165
Epoch: 2| Step: 4
Training loss: 4.631021499633789
Validation loss: 4.300889015197754
Epoch: 2| Step: 5
Training loss: 5.091722011566162
Validation loss: 4.207224607467651
Epoch: 2| Step: 6
Training loss: 5.3912811279296875
Validation loss: 4.183298230171204
Epoch: 2| Step: 7
Training loss: 3.6105570793151855
Validation loss: 4.155159115791321
Epoch: 2| Step: 8
Training loss: 3.9956603050231934
Validation loss: 4.174517035484314
Epoch: 2| Step: 9
Training loss: 4.545177936553955
Validation loss: 4.059586048126221
Epoch: 3| Step: 0
Training loss: 4.146393299102783
Validation loss: 4.147213399410248
Epoch: 3| Step: 1
Training loss: 3.826899290084839
Validation loss: 4.033670544624329
Epoch: 3| Step: 2
Training loss: 4.188665866851807
Validation loss: 3.924272298812866
Epoch: 3| Step: 3
Training loss: 4.073969841003418
Validation loss: 4.021799802780151
Epoch: 3| Step: 4
Training loss: 4.84428071975708
Validation loss: 3.934298574924469
Epoch: 3| Step: 5
Training loss: 3.477952480316162
Validation loss: 3.941997766494751
Epoch: 3| Step: 6
Training loss: 4.5811262130737305
Validation loss: 3.90883731842041
Epoch: 3| Step: 7
Training loss: 4.018614292144775
Validation loss: 3.9022741317749023
Epoch: 3| Step: 8
Training loss: 4.357237339019775
Validation loss: 3.8183743953704834
Epoch: 3| Step: 9
Training loss: 4.196927070617676
Validation loss: 3.838851809501648
Epoch: 4| Step: 0
Training loss: 4.308711051940918
Validation loss: 3.812437057495117
Epoch: 4| Step: 1
Training loss: 4.145893573760986
Validation loss: 3.7316097617149353
Epoch: 4| Step: 2
Training loss: 4.120872974395752
Validation loss: 3.684299409389496
Epoch: 4| Step: 3
Training loss: 3.6503286361694336
Validation loss: 3.628922760486603
Epoch: 4| Step: 4
Training loss: 4.6240129470825195
Validation loss: 3.748750388622284
Epoch: 4| Step: 5
Training loss: 3.35050892829895
Validation loss: 3.5731740593910217
Epoch: 4| Step: 6
Training loss: 4.03730583190918
Validation loss: 3.6022225618362427
Epoch: 4| Step: 7
Training loss: 3.6292309761047363
Validation loss: 3.5442309975624084
Epoch: 4| Step: 8
Training loss: 3.4808831214904785
Validation loss: 3.514391243457794
Epoch: 4| Step: 9
Training loss: 3.7941904067993164
Validation loss: 3.467425525188446
Epoch: 5| Step: 0
Training loss: 3.4397330284118652
Validation loss: 3.5068309903144836
Epoch: 5| Step: 1
Training loss: 3.638996124267578
Validation loss: 3.4510387778282166
Epoch: 5| Step: 2
Training loss: 4.003539085388184
Validation loss: 3.465937077999115
Epoch: 5| Step: 3
Training loss: 4.4960198402404785
Validation loss: 3.329651951789856
Epoch: 5| Step: 4
Training loss: 3.8154873847961426
Validation loss: 3.4080300331115723
Epoch: 5| Step: 5
Training loss: 3.324897050857544
Validation loss: 3.3850045204162598
Epoch: 5| Step: 6
Training loss: 3.470567464828491
Validation loss: 3.3266173005104065
Epoch: 5| Step: 7
Training loss: 3.556502103805542
Validation loss: 3.33107852935791
Epoch: 5| Step: 8
Training loss: 3.7282564640045166
Validation loss: 3.2640291452407837
Epoch: 5| Step: 9
Training loss: 3.4669084548950195
Validation loss: 3.2552183866500854
Epoch: 6| Step: 0
Training loss: 3.4039487838745117
Validation loss: 3.1602663397789
Epoch: 6| Step: 1
Training loss: 3.3001394271850586
Validation loss: 3.191622793674469
Epoch: 6| Step: 2
Training loss: 3.44736647605896
Validation loss: 3.2383121252059937
Epoch: 6| Step: 3
Training loss: 2.8148908615112305
Validation loss: 3.1920268535614014
Epoch: 6| Step: 4
Training loss: 3.355787754058838
Validation loss: 3.0010825991630554
Epoch: 6| Step: 5
Training loss: 3.7698264122009277
Validation loss: 2.9982481002807617
Epoch: 6| Step: 6
Training loss: 3.9427170753479004
Validation loss: 3.0551226139068604
Epoch: 6| Step: 7
Training loss: 3.4880728721618652
Validation loss: 3.0687500834465027
Epoch: 6| Step: 8
Training loss: 3.8233509063720703
Validation loss: 3.0833547115325928
Epoch: 6| Step: 9
Training loss: 3.4193530082702637
Validation loss: 3.029430568218231
Epoch: 7| Step: 0
Training loss: 3.6223011016845703
Validation loss: 3.0527674555778503
Epoch: 7| Step: 1
Training loss: 3.028108596801758
Validation loss: 2.9251425862312317
Epoch: 7| Step: 2
Training loss: 3.6706960201263428
Validation loss: 2.851523995399475
Epoch: 7| Step: 3
Training loss: 3.51314640045166
Validation loss: 2.7972007989883423
Epoch: 7| Step: 4
Training loss: 2.9870691299438477
Validation loss: 2.9174880981445312
Epoch: 7| Step: 5
Training loss: 3.446769952774048
Validation loss: 2.830953299999237
Epoch: 7| Step: 6
Training loss: 3.440816879272461
Validation loss: 2.859415352344513
Epoch: 7| Step: 7
Training loss: 3.4382429122924805
Validation loss: 2.872594654560089
Epoch: 7| Step: 8
Training loss: 2.8689537048339844
Validation loss: 2.753084659576416
Epoch: 7| Step: 9
Training loss: 2.831604480743408
Validation loss: 2.8716840147972107
Epoch: 8| Step: 0
Training loss: 3.347900390625
Validation loss: 2.7216891050338745
Epoch: 8| Step: 1
Training loss: 3.196437358856201
Validation loss: 2.7101747393608093
Epoch: 8| Step: 2
Training loss: 3.524186134338379
Validation loss: 2.6907761096954346
Epoch: 8| Step: 3
Training loss: 3.4063467979431152
Validation loss: 2.63994961977005
Epoch: 8| Step: 4
Training loss: 3.239675521850586
Validation loss: 2.6966323852539062
Epoch: 8| Step: 5
Training loss: 3.200131893157959
Validation loss: 2.668426811695099
Epoch: 8| Step: 6
Training loss: 3.0840578079223633
Validation loss: 2.6676949858665466
Epoch: 8| Step: 7
Training loss: 2.744640827178955
Validation loss: 2.6725929379463196
Epoch: 8| Step: 8
Training loss: 3.1607160568237305
Validation loss: 2.5698258876800537
Epoch: 8| Step: 9
Training loss: 2.416703462600708
Validation loss: 2.586569905281067
Epoch: 9| Step: 0
Training loss: 3.5823259353637695
Validation loss: 2.6304227709770203
Epoch: 9| Step: 1
Training loss: 2.5462915897369385
Validation loss: 2.616346299648285
Epoch: 9| Step: 2
Training loss: 2.782850980758667
Validation loss: 2.563955307006836
Epoch: 9| Step: 3
Training loss: 3.008554220199585
Validation loss: 2.4952600598335266
Epoch: 9| Step: 4
Training loss: 2.7341244220733643
Validation loss: 2.425226092338562
Epoch: 9| Step: 5
Training loss: 2.378532886505127
Validation loss: 2.3990715742111206
Epoch: 9| Step: 6
Training loss: 3.1542577743530273
Validation loss: 2.3823007941246033
Epoch: 9| Step: 7
Training loss: 3.0586698055267334
Validation loss: 2.4793508648872375
Epoch: 9| Step: 8
Training loss: 3.610128402709961
Validation loss: 2.5318078994750977
Epoch: 9| Step: 9
Training loss: 2.990464687347412
Validation loss: 2.4833876490592957
Epoch: 10| Step: 0
Training loss: 3.239896535873413
Validation loss: 2.3913981318473816
Epoch: 10| Step: 1
Training loss: 2.7967138290405273
Validation loss: 2.4447153210639954
Epoch: 10| Step: 2
Training loss: 2.9763717651367188
Validation loss: 2.4216986894607544
Epoch: 10| Step: 3
Training loss: 2.343715190887451
Validation loss: 2.3370165824890137
Epoch: 10| Step: 4
Training loss: 3.205380439758301
Validation loss: 2.3787590861320496
Epoch: 10| Step: 5
Training loss: 3.4442336559295654
Validation loss: 2.4113470315933228
Epoch: 10| Step: 6
Training loss: 2.4066567420959473
Validation loss: 2.362555742263794
Epoch: 10| Step: 7
Training loss: 2.90069842338562
Validation loss: 2.2256370782852173
Epoch: 10| Step: 8
Training loss: 2.563711643218994
Validation loss: 2.381677746772766
Epoch: 10| Step: 9
Training loss: 2.887803316116333
Validation loss: 2.276029586791992
Epoch: 11| Step: 0
Training loss: 2.9660420417785645
Validation loss: 2.28056538105011
Epoch: 11| Step: 1
Training loss: 2.9255452156066895
Validation loss: 2.332754671573639
Epoch: 11| Step: 2
Training loss: 2.5808348655700684
Validation loss: 2.222115308046341
Epoch: 11| Step: 3
Training loss: 3.472315549850464
Validation loss: 2.2927420139312744
Epoch: 11| Step: 4
Training loss: 2.224978446960449
Validation loss: 2.206210136413574
Epoch: 11| Step: 5
Training loss: 2.5482163429260254
Validation loss: 2.256733536720276
Epoch: 11| Step: 6
Training loss: 2.811349630355835
Validation loss: 2.3061605095863342
Epoch: 11| Step: 7
Training loss: 2.3523507118225098
Validation loss: 2.209213614463806
Epoch: 11| Step: 8
Training loss: 2.900991439819336
Validation loss: 2.1312128603458405
Epoch: 11| Step: 9
Training loss: 2.8190701007843018
Validation loss: 2.260031282901764
Epoch: 12| Step: 0
Training loss: 2.672499656677246
Validation loss: 2.140783876180649
Epoch: 12| Step: 1
Training loss: 3.0512845516204834
Validation loss: 2.1516902446746826
Epoch: 12| Step: 2
Training loss: 2.5619897842407227
Validation loss: 2.1806923151016235
Epoch: 12| Step: 3
Training loss: 2.69245982170105
Validation loss: 2.1671480536460876
Epoch: 12| Step: 4
Training loss: 2.1565980911254883
Validation loss: 2.1573126912117004
Epoch: 12| Step: 5
Training loss: 2.911987781524658
Validation loss: 2.0870537757873535
Epoch: 12| Step: 6
Training loss: 2.385830879211426
Validation loss: 2.1542190611362457
Epoch: 12| Step: 7
Training loss: 2.8629579544067383
Validation loss: 2.0617631673812866
Epoch: 12| Step: 8
Training loss: 2.4462647438049316
Validation loss: 2.172793388366699
Epoch: 12| Step: 9
Training loss: 2.8086891174316406
Validation loss: 2.0818880796432495
Epoch: 13| Step: 0
Training loss: 2.966146945953369
Validation loss: 2.1085013151168823
Epoch: 13| Step: 1
Training loss: 2.6461129188537598
Validation loss: 2.0224397778511047
Epoch: 13| Step: 2
Training loss: 2.1266818046569824
Validation loss: 2.061781644821167
Epoch: 13| Step: 3
Training loss: 2.751767635345459
Validation loss: 1.9964804649353027
Epoch: 13| Step: 4
Training loss: 2.5506017208099365
Validation loss: 1.9190853536128998
Epoch: 13| Step: 5
Training loss: 2.474666118621826
Validation loss: 2.089860588312149
Epoch: 13| Step: 6
Training loss: 2.595233678817749
Validation loss: 1.9596568048000336
Epoch: 13| Step: 7
Training loss: 2.4010140895843506
Validation loss: 2.071383833885193
Epoch: 13| Step: 8
Training loss: 2.7460803985595703
Validation loss: 2.0463991165161133
Epoch: 13| Step: 9
Training loss: 2.261165142059326
Validation loss: 2.0046925246715546
Epoch: 14| Step: 0
Training loss: 2.530198097229004
Validation loss: 2.027177780866623
Epoch: 14| Step: 1
Training loss: 2.3812267780303955
Validation loss: 2.0154552161693573
Epoch: 14| Step: 2
Training loss: 1.7662746906280518
Validation loss: 1.9467067122459412
Epoch: 14| Step: 3
Training loss: 2.7529702186584473
Validation loss: 2.0218812823295593
Epoch: 14| Step: 4
Training loss: 2.6523830890655518
Validation loss: 1.988698571920395
Epoch: 14| Step: 5
Training loss: 2.198868751525879
Validation loss: 1.957354724407196
Epoch: 14| Step: 6
Training loss: 3.3140978813171387
Validation loss: 1.9338887929916382
Epoch: 14| Step: 7
Training loss: 2.7355306148529053
Validation loss: 1.938882827758789
Epoch: 14| Step: 8
Training loss: 2.222294569015503
Validation loss: 2.0127666294574738
Epoch: 14| Step: 9
Training loss: 2.5555858612060547
Validation loss: 1.9327669441699982
Epoch: 15| Step: 0
Training loss: 2.631059408187866
Validation loss: 1.9826481938362122
Epoch: 15| Step: 1
Training loss: 2.4589266777038574
Validation loss: 1.9603631794452667
Epoch: 15| Step: 2
Training loss: 2.335054636001587
Validation loss: 1.8820598125457764
Epoch: 15| Step: 3
Training loss: 2.110579252243042
Validation loss: 1.9140413701534271
Epoch: 15| Step: 4
Training loss: 2.5597681999206543
Validation loss: 1.9719928205013275
Epoch: 15| Step: 5
Training loss: 2.6755127906799316
Validation loss: 1.9182657599449158
Epoch: 15| Step: 6
Training loss: 2.1881790161132812
Validation loss: 1.9659198820590973
Epoch: 15| Step: 7
Training loss: 2.3665523529052734
Validation loss: 1.981087476015091
Epoch: 15| Step: 8
Training loss: 2.559237241744995
Validation loss: 1.8536616265773773
Epoch: 15| Step: 9
Training loss: 2.4007389545440674
Validation loss: 1.9367998242378235
Epoch: 16| Step: 0
Training loss: 2.4246134757995605
Validation loss: 1.9063505232334137
Epoch: 16| Step: 1
Training loss: 2.52657151222229
Validation loss: 1.9545707404613495
Epoch: 16| Step: 2
Training loss: 2.7367053031921387
Validation loss: 1.9102093279361725
Epoch: 16| Step: 3
Training loss: 2.5376806259155273
Validation loss: 1.8918847441673279
Epoch: 16| Step: 4
Training loss: 2.5698537826538086
Validation loss: 1.933243751525879
Epoch: 16| Step: 5
Training loss: 2.0664868354797363
Validation loss: 1.8614555597305298
Epoch: 16| Step: 6
Training loss: 2.331418037414551
Validation loss: 1.8166126906871796
Epoch: 16| Step: 7
Training loss: 2.059755325317383
Validation loss: 1.9112262427806854
Epoch: 16| Step: 8
Training loss: 2.420278310775757
Validation loss: 1.8835952281951904
Epoch: 16| Step: 9
Training loss: 2.3498387336730957
Validation loss: 1.9159619212150574
Epoch: 17| Step: 0
Training loss: 2.2362616062164307
Validation loss: 1.9062661230564117
Epoch: 17| Step: 1
Training loss: 2.1048970222473145
Validation loss: 1.88679039478302
Epoch: 17| Step: 2
Training loss: 2.1643762588500977
Validation loss: 1.8769066333770752
Epoch: 17| Step: 3
Training loss: 2.485705614089966
Validation loss: 1.8963727951049805
Epoch: 17| Step: 4
Training loss: 2.3854598999023438
Validation loss: 1.9202339947223663
Epoch: 17| Step: 5
Training loss: 2.430431604385376
Validation loss: 1.7907186150550842
Epoch: 17| Step: 6
Training loss: 2.270897388458252
Validation loss: 1.869112640619278
Epoch: 17| Step: 7
Training loss: 2.6141767501831055
Validation loss: 1.7767388224601746
Epoch: 17| Step: 8
Training loss: 2.376952648162842
Validation loss: 1.9177304208278656
Epoch: 17| Step: 9
Training loss: 2.453125
Validation loss: 1.8909040689468384
Epoch: 18| Step: 0
Training loss: 1.836559772491455
Validation loss: 1.8281392753124237
Epoch: 18| Step: 1
Training loss: 2.405647039413452
Validation loss: 1.847579449415207
Epoch: 18| Step: 2
Training loss: 1.8641211986541748
Validation loss: 1.8463945388793945
Epoch: 18| Step: 3
Training loss: 2.60835599899292
Validation loss: 1.8495421409606934
Epoch: 18| Step: 4
Training loss: 2.8289828300476074
Validation loss: 1.8700372278690338
Epoch: 18| Step: 5
Training loss: 2.6651406288146973
Validation loss: 1.8205265402793884
Epoch: 18| Step: 6
Training loss: 2.0785317420959473
Validation loss: 1.8606975674629211
Epoch: 18| Step: 7
Training loss: 2.5326318740844727
Validation loss: 1.8281003534793854
Epoch: 18| Step: 8
Training loss: 2.269857168197632
Validation loss: 1.7932935059070587
Epoch: 18| Step: 9
Training loss: 1.9997235536575317
Validation loss: 1.853901594877243
Epoch: 19| Step: 0
Training loss: 2.306180953979492
Validation loss: 1.8131095468997955
Epoch: 19| Step: 1
Training loss: 2.4890213012695312
Validation loss: 1.8298201262950897
Epoch: 19| Step: 2
Training loss: 2.474742889404297
Validation loss: 1.791285753250122
Epoch: 19| Step: 3
Training loss: 2.2541935443878174
Validation loss: 1.7952891290187836
Epoch: 19| Step: 4
Training loss: 2.4543886184692383
Validation loss: 1.8291955888271332
Epoch: 19| Step: 5
Training loss: 2.2858588695526123
Validation loss: 1.8133903443813324
Epoch: 19| Step: 6
Training loss: 2.3496224880218506
Validation loss: 1.766025424003601
Epoch: 19| Step: 7
Training loss: 2.275142192840576
Validation loss: 1.816994547843933
Epoch: 19| Step: 8
Training loss: 2.2962145805358887
Validation loss: 1.8156098127365112
Epoch: 19| Step: 9
Training loss: 1.8636466264724731
Validation loss: 1.8089889585971832
Epoch: 20| Step: 0
Training loss: 2.064700126647949
Validation loss: 1.8276575207710266
Epoch: 20| Step: 1
Training loss: 2.256044387817383
Validation loss: 1.8481919169425964
Epoch: 20| Step: 2
Training loss: 1.8065176010131836
Validation loss: 1.8457148373126984
Epoch: 20| Step: 3
Training loss: 2.62858247756958
Validation loss: 1.7954676747322083
Epoch: 20| Step: 4
Training loss: 2.3758645057678223
Validation loss: 1.738729178905487
Epoch: 20| Step: 5
Training loss: 2.629549503326416
Validation loss: 1.808711677789688
Epoch: 20| Step: 6
Training loss: 2.1701760292053223
Validation loss: 1.7441498637199402
Epoch: 20| Step: 7
Training loss: 2.0513663291931152
Validation loss: 1.7887763977050781
Epoch: 20| Step: 8
Training loss: 2.6214487552642822
Validation loss: 1.771426796913147
Epoch: 20| Step: 9
Training loss: 2.1963295936584473
Validation loss: 1.7841461896896362
Epoch: 21| Step: 0
Training loss: 2.4167730808258057
Validation loss: 1.863236278295517
Epoch: 21| Step: 1
Training loss: 1.961143970489502
Validation loss: 1.7962889969348907
Epoch: 21| Step: 2
Training loss: 1.9704405069351196
Validation loss: 1.7561792135238647
Epoch: 21| Step: 3
Training loss: 2.434227466583252
Validation loss: 1.7738708853721619
Epoch: 21| Step: 4
Training loss: 2.4589245319366455
Validation loss: 1.7938496470451355
Epoch: 21| Step: 5
Training loss: 2.2328131198883057
Validation loss: 1.7846917510032654
Epoch: 21| Step: 6
Training loss: 1.7248154878616333
Validation loss: 1.74799644947052
Epoch: 21| Step: 7
Training loss: 2.435930013656616
Validation loss: 1.7990316450595856
Epoch: 21| Step: 8
Training loss: 2.3103809356689453
Validation loss: 1.7486025094985962
Epoch: 21| Step: 9
Training loss: 2.668815851211548
Validation loss: 1.8079997897148132
Epoch: 22| Step: 0
Training loss: 2.0490965843200684
Validation loss: 1.8336877226829529
Epoch: 22| Step: 1
Training loss: 2.386774778366089
Validation loss: 1.761408120393753
Epoch: 22| Step: 2
Training loss: 2.3952174186706543
Validation loss: 1.8179649114608765
Epoch: 22| Step: 3
Training loss: 1.9786720275878906
Validation loss: 1.7142575979232788
Epoch: 22| Step: 4
Training loss: 2.7947049140930176
Validation loss: 1.7349992990493774
Epoch: 22| Step: 5
Training loss: 2.1053812503814697
Validation loss: 1.7815194129943848
Epoch: 22| Step: 6
Training loss: 2.1303369998931885
Validation loss: 1.7889645993709564
Epoch: 22| Step: 7
Training loss: 2.5038211345672607
Validation loss: 1.7650898396968842
Epoch: 22| Step: 8
Training loss: 2.275057077407837
Validation loss: 1.7498916685581207
Epoch: 22| Step: 9
Training loss: 1.8884270191192627
Validation loss: 1.7972268164157867
Epoch: 23| Step: 0
Training loss: 2.5839602947235107
Validation loss: 1.7616578042507172
Epoch: 23| Step: 1
Training loss: 2.1097359657287598
Validation loss: 1.7897942066192627
Epoch: 23| Step: 2
Training loss: 2.84765362739563
Validation loss: 1.7853408753871918
Epoch: 23| Step: 3
Training loss: 2.28125
Validation loss: 1.795342206954956
Epoch: 23| Step: 4
Training loss: 1.9891257286071777
Validation loss: 1.8309108912944794
Epoch: 23| Step: 5
Training loss: 1.9804494380950928
Validation loss: 1.7886545658111572
Epoch: 23| Step: 6
Training loss: 2.2504587173461914
Validation loss: 1.7630878388881683
Epoch: 23| Step: 7
Training loss: 2.466358184814453
Validation loss: 1.797350525856018
Epoch: 23| Step: 8
Training loss: 1.7885582447052002
Validation loss: 1.7664014101028442
Epoch: 23| Step: 9
Training loss: 2.2558774948120117
Validation loss: 1.7847733199596405
Epoch: 24| Step: 0
Training loss: 2.5027377605438232
Validation loss: 1.835979849100113
Epoch: 24| Step: 1
Training loss: 2.492030620574951
Validation loss: 1.72097510099411
Epoch: 24| Step: 2
Training loss: 1.9595236778259277
Validation loss: 1.7954771518707275
Epoch: 24| Step: 3
Training loss: 2.284123659133911
Validation loss: 1.7499443292617798
Epoch: 24| Step: 4
Training loss: 1.6298034191131592
Validation loss: 1.8345687091350555
Epoch: 24| Step: 5
Training loss: 2.2057783603668213
Validation loss: 1.7606978714466095
Epoch: 24| Step: 6
Training loss: 2.369450807571411
Validation loss: 1.7499913573265076
Epoch: 24| Step: 7
Training loss: 2.6022677421569824
Validation loss: 1.7591062486171722
Epoch: 24| Step: 8
Training loss: 2.302427291870117
Validation loss: 1.74649316072464
Epoch: 24| Step: 9
Training loss: 2.3237500190734863
Validation loss: 1.771536946296692
Epoch: 25| Step: 0
Training loss: 2.312680244445801
Validation loss: 1.7450798749923706
Epoch: 25| Step: 1
Training loss: 1.786733865737915
Validation loss: 1.7471801936626434
Epoch: 25| Step: 2
Training loss: 2.3482728004455566
Validation loss: 1.7724657952785492
Epoch: 25| Step: 3
Training loss: 2.13240647315979
Validation loss: 1.7385947704315186
Epoch: 25| Step: 4
Training loss: 2.1718413829803467
Validation loss: 1.8081441223621368
Epoch: 25| Step: 5
Training loss: 2.351328134536743
Validation loss: 1.7523612976074219
Epoch: 25| Step: 6
Training loss: 2.2768490314483643
Validation loss: 1.744689553976059
Epoch: 25| Step: 7
Training loss: 2.4535155296325684
Validation loss: 1.7846899330615997
Epoch: 25| Step: 8
Training loss: 2.265016555786133
Validation loss: 1.797047197818756
Epoch: 25| Step: 9
Training loss: 2.3829870223999023
Validation loss: 1.7571923434734344
Epoch: 26| Step: 0
Training loss: 2.083439350128174
Validation loss: 1.6412395238876343
Epoch: 26| Step: 1
Training loss: 2.2937703132629395
Validation loss: 1.7509159445762634
Epoch: 26| Step: 2
Training loss: 2.3686270713806152
Validation loss: 1.73175647854805
Epoch: 26| Step: 3
Training loss: 2.459484815597534
Validation loss: 1.8121077418327332
Epoch: 26| Step: 4
Training loss: 2.1560263633728027
Validation loss: 1.8079225420951843
Epoch: 26| Step: 5
Training loss: 2.3153042793273926
Validation loss: 1.7352986931800842
Epoch: 26| Step: 6
Training loss: 2.2632856369018555
Validation loss: 1.8124648928642273
Epoch: 26| Step: 7
Training loss: 2.297318696975708
Validation loss: 1.7928324341773987
Epoch: 26| Step: 8
Training loss: 2.0662155151367188
Validation loss: 1.7668190896511078
Epoch: 26| Step: 9
Training loss: 2.367288589477539
Validation loss: 1.8156594336032867
Epoch: 27| Step: 0
Training loss: 1.865286111831665
Validation loss: 1.7459396719932556
Epoch: 27| Step: 1
Training loss: 2.3552451133728027
Validation loss: 1.8035208880901337
Epoch: 27| Step: 2
Training loss: 2.7249999046325684
Validation loss: 1.777868002653122
Epoch: 27| Step: 3
Training loss: 2.685647964477539
Validation loss: 1.7892358303070068
Epoch: 27| Step: 4
Training loss: 2.0218749046325684
Validation loss: 1.7484988570213318
Epoch: 27| Step: 5
Training loss: 2.3334672451019287
Validation loss: 1.7567179203033447
Epoch: 27| Step: 6
Training loss: 1.8860321044921875
Validation loss: 1.764867752790451
Epoch: 27| Step: 7
Training loss: 2.2051148414611816
Validation loss: 1.7244214713573456
Epoch: 27| Step: 8
Training loss: 2.2784667015075684
Validation loss: 1.7774843573570251
Epoch: 27| Step: 9
Training loss: 2.0966830253601074
Validation loss: 1.748474359512329
Epoch: 28| Step: 0
Training loss: 2.0163917541503906
Validation loss: 1.7779651284217834
Epoch: 28| Step: 1
Training loss: 1.9215363264083862
Validation loss: 1.7957801520824432
Epoch: 28| Step: 2
Training loss: 2.001934766769409
Validation loss: 1.7167377471923828
Epoch: 28| Step: 3
Training loss: 2.020723581314087
Validation loss: 1.7916922569274902
Epoch: 28| Step: 4
Training loss: 2.302034854888916
Validation loss: 1.750715047121048
Epoch: 28| Step: 5
Training loss: 2.7558093070983887
Validation loss: 1.7540949285030365
Epoch: 28| Step: 6
Training loss: 2.1656250953674316
Validation loss: 1.797025740146637
Epoch: 28| Step: 7
Training loss: 2.6371965408325195
Validation loss: 1.7147294878959656
Epoch: 28| Step: 8
Training loss: 2.368191957473755
Validation loss: 1.7840723395347595
Epoch: 28| Step: 9
Training loss: 2.40625
Validation loss: 1.6941094398498535
Epoch: 29| Step: 0
Training loss: 2.042313575744629
Validation loss: 1.8350855112075806
Epoch: 29| Step: 1
Training loss: 2.4281702041625977
Validation loss: 1.79056915640831
Epoch: 29| Step: 2
Training loss: 2.5099985599517822
Validation loss: 1.740729182958603
Epoch: 29| Step: 3
Training loss: 2.1634764671325684
Validation loss: 1.7960296869277954
Epoch: 29| Step: 4
Training loss: 2.147329092025757
Validation loss: 1.7349314391613007
Epoch: 29| Step: 5
Training loss: 2.3870739936828613
Validation loss: 1.7510491609573364
Epoch: 29| Step: 6
Training loss: 2.282013416290283
Validation loss: 1.6758232414722443
Epoch: 29| Step: 7
Training loss: 1.9326361417770386
Validation loss: 1.784235030412674
Epoch: 29| Step: 8
Training loss: 2.4331068992614746
Validation loss: 1.782282292842865
Epoch: 29| Step: 9
Training loss: 2.1831603050231934
Validation loss: 1.771402359008789
Epoch: 30| Step: 0
Training loss: 1.8399535417556763
Validation loss: 1.7444480061531067
Epoch: 30| Step: 1
Training loss: 2.3250131607055664
Validation loss: 1.7139062583446503
Epoch: 30| Step: 2
Training loss: 2.560914993286133
Validation loss: 1.7609676122665405
Epoch: 30| Step: 3
Training loss: 2.339024305343628
Validation loss: 1.7727490961551666
Epoch: 30| Step: 4
Training loss: 2.7341837882995605
Validation loss: 1.715699553489685
Epoch: 30| Step: 5
Training loss: 2.372605323791504
Validation loss: 1.7195307910442352
Epoch: 30| Step: 6
Training loss: 2.1143863201141357
Validation loss: 1.7509983777999878
Epoch: 30| Step: 7
Training loss: 1.755105972290039
Validation loss: 1.7442242205142975
Epoch: 30| Step: 8
Training loss: 2.119539976119995
Validation loss: 1.7814145684242249
Epoch: 30| Step: 9
Training loss: 2.2852418422698975
Validation loss: 1.7644417583942413
