Epoch: 1| Step: 0
Training loss: 5.138219577859421
Validation loss: 5.254836971314936
Epoch: 1| Step: 1
Training loss: 5.575677585907581
Validation loss: 5.013395202807517
Epoch: 1| Step: 2
Training loss: 5.235522517348492
Validation loss: 5.081786733503955
Epoch: 1| Step: 3
Training loss: 5.678276883803803
Validation loss: 5.197715260587921
Epoch: 1| Step: 4
Training loss: 5.372012172898215
Validation loss: 5.0946777519992
Epoch: 1| Step: 5
Training loss: 5.809753425342701
Validation loss: 5.025205159713543
Epoch: 1| Step: 6
Training loss: 5.438822968996687
Validation loss: 4.963814241244794
Epoch: 1| Step: 7
Training loss: 4.896610582487972
Validation loss: 4.649978475793184
Epoch: 2| Step: 0
Training loss: 5.263156935039232
Validation loss: 4.6565018568999745
Epoch: 2| Step: 1
Training loss: 5.028457340426317
Validation loss: 4.5735222583614155
Epoch: 2| Step: 2
Training loss: 5.604108372873175
Validation loss: 4.40724144077653
Epoch: 2| Step: 3
Training loss: 4.393693713591395
Validation loss: 4.616222638078802
Epoch: 2| Step: 4
Training loss: 4.5273667105355
Validation loss: 4.491355074241946
Epoch: 2| Step: 5
Training loss: 4.719666448865831
Validation loss: 4.442394310188926
Epoch: 2| Step: 6
Training loss: 4.569932292545182
Validation loss: 4.412526254919918
Epoch: 2| Step: 7
Training loss: 4.510583511802365
Validation loss: 4.27338255211254
Epoch: 3| Step: 0
Training loss: 4.051423215991294
Validation loss: 4.2606921437096075
Epoch: 3| Step: 1
Training loss: 4.61048674026699
Validation loss: 4.187663868919285
Epoch: 3| Step: 2
Training loss: 5.011328642626054
Validation loss: 4.144787772627592
Epoch: 3| Step: 3
Training loss: 3.9563386542585275
Validation loss: 4.056036068030437
Epoch: 3| Step: 4
Training loss: 4.608971115779936
Validation loss: 3.9791161848759806
Epoch: 3| Step: 5
Training loss: 3.812182804107588
Validation loss: 3.9561083069829004
Epoch: 3| Step: 6
Training loss: 4.858183196394158
Validation loss: 3.911066477779134
Epoch: 3| Step: 7
Training loss: 4.377184731085032
Validation loss: 3.7852862426309977
Epoch: 4| Step: 0
Training loss: 4.382799879521714
Validation loss: 3.7149245471882253
Epoch: 4| Step: 1
Training loss: 4.537185464681598
Validation loss: 3.860220992699531
Epoch: 4| Step: 2
Training loss: 3.8423675283952994
Validation loss: 3.6010474997170987
Epoch: 4| Step: 3
Training loss: 3.6599373767268886
Validation loss: 3.5975574037107756
Epoch: 4| Step: 4
Training loss: 3.9216833789716303
Validation loss: 3.547879169628425
Epoch: 4| Step: 5
Training loss: 4.286710055790687
Validation loss: 3.5467416023238285
Epoch: 4| Step: 6
Training loss: 4.041033560859181
Validation loss: 3.4596585754772833
Epoch: 4| Step: 7
Training loss: 3.768411831843091
Validation loss: 3.475876519840991
Epoch: 5| Step: 0
Training loss: 3.724961550725366
Validation loss: 3.549076931730394
Epoch: 5| Step: 1
Training loss: 3.594817425968919
Validation loss: 3.365937896161603
Epoch: 5| Step: 2
Training loss: 4.387111140133538
Validation loss: 3.3678493589558305
Epoch: 5| Step: 3
Training loss: 4.166077432294676
Validation loss: 3.395591355730115
Epoch: 5| Step: 4
Training loss: 3.436075921282358
Validation loss: 3.2705542784011308
Epoch: 5| Step: 5
Training loss: 3.7256171668907365
Validation loss: 3.210997076151168
Epoch: 5| Step: 6
Training loss: 3.2462067108146977
Validation loss: 3.2448683621800742
Epoch: 5| Step: 7
Training loss: 3.5985238916691347
Validation loss: 3.052979379611079
Epoch: 6| Step: 0
Training loss: 3.3143453676041785
Validation loss: 3.1989010084393636
Epoch: 6| Step: 1
Training loss: 3.2469194925029936
Validation loss: 3.0334327965297607
Epoch: 6| Step: 2
Training loss: 3.7358977592904083
Validation loss: 3.1033137190768265
Epoch: 6| Step: 3
Training loss: 3.7123797053618084
Validation loss: 3.0237801884778093
Epoch: 6| Step: 4
Training loss: 3.9986222994018736
Validation loss: 3.0736432243997136
Epoch: 6| Step: 5
Training loss: 3.483601574098707
Validation loss: 3.0635429139545702
Epoch: 6| Step: 6
Training loss: 2.8338188054667146
Validation loss: 2.93136916020542
Epoch: 6| Step: 7
Training loss: 3.3938712476003103
Validation loss: 2.8522811369564764
Epoch: 7| Step: 0
Training loss: 3.408788732372284
Validation loss: 2.860514966233772
Epoch: 7| Step: 1
Training loss: 3.464794068265218
Validation loss: 2.822552266546142
Epoch: 7| Step: 2
Training loss: 3.152238770808531
Validation loss: 2.772218891196006
Epoch: 7| Step: 3
Training loss: 3.2844783342041466
Validation loss: 2.6842171695897226
Epoch: 7| Step: 4
Training loss: 3.515327542754604
Validation loss: 2.6612885874991408
Epoch: 7| Step: 5
Training loss: 3.0202801603509033
Validation loss: 2.653006698923502
Epoch: 7| Step: 6
Training loss: 3.3375821849976623
Validation loss: 2.698139464209573
Epoch: 7| Step: 7
Training loss: 2.842552519810471
Validation loss: 2.596934334627611
Epoch: 8| Step: 0
Training loss: 3.0763950811878242
Validation loss: 2.6753666217490255
Epoch: 8| Step: 1
Training loss: 2.8914666677417573
Validation loss: 2.6227047788511038
Epoch: 8| Step: 2
Training loss: 3.4220805345932024
Validation loss: 2.5064032816051323
Epoch: 8| Step: 3
Training loss: 3.161045171060725
Validation loss: 2.5862626757898077
Epoch: 8| Step: 4
Training loss: 3.151461150355839
Validation loss: 2.5065056192437796
Epoch: 8| Step: 5
Training loss: 2.871125969738431
Validation loss: 2.5777558421794193
Epoch: 8| Step: 6
Training loss: 3.0235155672152363
Validation loss: 2.516967232118894
Epoch: 8| Step: 7
Training loss: 2.985329360554914
Validation loss: 2.4838366599705597
Epoch: 9| Step: 0
Training loss: 2.9358910557441895
Validation loss: 2.3792950912288213
Epoch: 9| Step: 1
Training loss: 2.636664315120968
Validation loss: 2.4294155385544403
Epoch: 9| Step: 2
Training loss: 3.12096403804889
Validation loss: 2.454627761471071
Epoch: 9| Step: 3
Training loss: 2.9779222641554193
Validation loss: 2.3234639062243194
Epoch: 9| Step: 4
Training loss: 3.1052523939471888
Validation loss: 2.3658397430021485
Epoch: 9| Step: 5
Training loss: 2.9424043661569517
Validation loss: 2.4292229383025443
Epoch: 9| Step: 6
Training loss: 2.865092746638122
Validation loss: 2.352424655292459
Epoch: 9| Step: 7
Training loss: 2.936732252718609
Validation loss: 2.326967511571933
Epoch: 10| Step: 0
Training loss: 3.2060990087935544
Validation loss: 2.342201844554797
Epoch: 10| Step: 1
Training loss: 2.7946132273563613
Validation loss: 2.3233384169650138
Epoch: 10| Step: 2
Training loss: 2.652384200089658
Validation loss: 2.2640872066163493
Epoch: 10| Step: 3
Training loss: 2.5752383631036055
Validation loss: 2.259422396792407
Epoch: 10| Step: 4
Training loss: 2.7397039311968063
Validation loss: 2.2564625521319894
Epoch: 10| Step: 5
Training loss: 2.885314186746011
Validation loss: 2.3279034225077506
Epoch: 10| Step: 6
Training loss: 3.1547255658767046
Validation loss: 2.2277585949071725
Epoch: 10| Step: 7
Training loss: 2.6735563286347293
Validation loss: 2.2422734198785066
Epoch: 11| Step: 0
Training loss: 2.4461869208965474
Validation loss: 2.202697734909521
Epoch: 11| Step: 1
Training loss: 3.0003003923704052
Validation loss: 2.2163425332603213
Epoch: 11| Step: 2
Training loss: 2.9862235370930907
Validation loss: 2.126933286438224
Epoch: 11| Step: 3
Training loss: 2.7921026847778627
Validation loss: 2.227815148807563
Epoch: 11| Step: 4
Training loss: 2.7014369213951857
Validation loss: 2.1931929277176736
Epoch: 11| Step: 5
Training loss: 2.6730221076162417
Validation loss: 2.220124639505888
Epoch: 11| Step: 6
Training loss: 2.7916844115950625
Validation loss: 2.219745523463719
Epoch: 11| Step: 7
Training loss: 2.723591319657498
Validation loss: 2.0974173841088017
Epoch: 12| Step: 0
Training loss: 2.697739544998539
Validation loss: 2.096566142739342
Epoch: 12| Step: 1
Training loss: 2.655366907863159
Validation loss: 2.192754905777795
Epoch: 12| Step: 2
Training loss: 2.5092969642372394
Validation loss: 2.1459363370407027
Epoch: 12| Step: 3
Training loss: 2.6609591758145337
Validation loss: 2.135011754572654
Epoch: 12| Step: 4
Training loss: 2.9748797929344417
Validation loss: 2.139764205359933
Epoch: 12| Step: 5
Training loss: 2.6870911752999747
Validation loss: 2.2305406541875157
Epoch: 12| Step: 6
Training loss: 2.763314871762784
Validation loss: 2.1647166541837066
Epoch: 12| Step: 7
Training loss: 2.771936918683116
Validation loss: 2.202592005906888
Epoch: 13| Step: 0
Training loss: 2.2990088898170367
Validation loss: 2.1102042841281325
Epoch: 13| Step: 1
Training loss: 2.7435899066490785
Validation loss: 2.1224800949865155
Epoch: 13| Step: 2
Training loss: 2.9233055488660864
Validation loss: 2.088398239460995
Epoch: 13| Step: 3
Training loss: 2.884661817910539
Validation loss: 2.156317675808656
Epoch: 13| Step: 4
Training loss: 2.7254834157536787
Validation loss: 2.1700663167168144
Epoch: 13| Step: 5
Training loss: 2.454338696791483
Validation loss: 2.1224898191806205
Epoch: 13| Step: 6
Training loss: 2.675783566661862
Validation loss: 2.0964254961170674
Epoch: 13| Step: 7
Training loss: 2.7256378092352196
Validation loss: 2.1157454472686346
Epoch: 14| Step: 0
Training loss: 2.617313393369026
Validation loss: 2.114496694630398
Epoch: 14| Step: 1
Training loss: 2.7788246809876322
Validation loss: 2.0939260670238506
Epoch: 14| Step: 2
Training loss: 2.5847974033025074
Validation loss: 2.105620710944566
Epoch: 14| Step: 3
Training loss: 2.963267353325987
Validation loss: 2.057893776351993
Epoch: 14| Step: 4
Training loss: 2.478233375440451
Validation loss: 2.1705157254894103
Epoch: 14| Step: 5
Training loss: 2.592860609410298
Validation loss: 2.0774698089243278
Epoch: 14| Step: 6
Training loss: 2.6203595879997774
Validation loss: 2.107155686067152
Epoch: 14| Step: 7
Training loss: 2.63742232366504
Validation loss: 2.1141163552149855
Epoch: 15| Step: 0
Training loss: 2.616370594582465
Validation loss: 2.0613066823869315
Epoch: 15| Step: 1
Training loss: 2.803464660138767
Validation loss: 2.035127934459452
Epoch: 15| Step: 2
Training loss: 3.006585363767605
Validation loss: 2.1041842009874365
Epoch: 15| Step: 3
Training loss: 2.5823860790314717
Validation loss: 2.0784042599612653
Epoch: 15| Step: 4
Training loss: 2.5737265317420324
Validation loss: 2.1214446104188993
Epoch: 15| Step: 5
Training loss: 2.525522982380816
Validation loss: 2.10692602930769
Epoch: 15| Step: 6
Training loss: 2.5712148827364794
Validation loss: 2.139295448751838
Epoch: 15| Step: 7
Training loss: 2.4898723503698887
Validation loss: 2.140859679082551
Epoch: 16| Step: 0
Training loss: 2.5829550148195657
Validation loss: 2.1433105691894982
Epoch: 16| Step: 1
Training loss: 2.607625226152784
Validation loss: 2.1157595902574244
Epoch: 16| Step: 2
Training loss: 2.909841963419181
Validation loss: 2.1364733508056806
Epoch: 16| Step: 3
Training loss: 2.6862814158807704
Validation loss: 2.079143279179986
Epoch: 16| Step: 4
Training loss: 2.5180650333432606
Validation loss: 2.0878488964840254
Epoch: 16| Step: 5
Training loss: 2.6182624089837447
Validation loss: 2.114738787170825
Epoch: 16| Step: 6
Training loss: 2.693589785030971
Validation loss: 2.0634318386800916
Epoch: 16| Step: 7
Training loss: 2.502185533793632
Validation loss: 2.1577719374316957
Epoch: 17| Step: 0
Training loss: 2.6202584085357765
Validation loss: 2.128954462124773
Epoch: 17| Step: 1
Training loss: 2.4127306180631427
Validation loss: 1.9702421282113711
Epoch: 17| Step: 2
Training loss: 2.530976928298314
Validation loss: 2.112023652816251
Epoch: 17| Step: 3
Training loss: 2.4986151674426305
Validation loss: 2.062792418184495
Epoch: 17| Step: 4
Training loss: 2.8288416507722807
Validation loss: 2.02815929910049
Epoch: 17| Step: 5
Training loss: 2.67957521431338
Validation loss: 2.162148021790337
Epoch: 17| Step: 6
Training loss: 2.8646851307669925
Validation loss: 2.1258575724295943
Epoch: 17| Step: 7
Training loss: 2.6547346392707216
Validation loss: 2.105062256595081
Epoch: 18| Step: 0
Training loss: 2.731967585593378
Validation loss: 2.0594346577503697
Epoch: 18| Step: 1
Training loss: 2.786086345810599
Validation loss: 2.090166110897713
Epoch: 18| Step: 2
Training loss: 2.6102247853145917
Validation loss: 2.0456000178557296
Epoch: 18| Step: 3
Training loss: 2.716105259963819
Validation loss: 2.0761370677590834
Epoch: 18| Step: 4
Training loss: 2.5044344673683865
Validation loss: 2.12734462638643
Epoch: 18| Step: 5
Training loss: 2.5533497892335864
Validation loss: 2.0048213659392555
Epoch: 18| Step: 6
Training loss: 2.785646029044843
Validation loss: 2.1257779113404642
Epoch: 18| Step: 7
Training loss: 2.385421075497569
Validation loss: 2.084702581824145
Epoch: 19| Step: 0
Training loss: 2.668574921986979
Validation loss: 2.0920410970854797
Epoch: 19| Step: 1
Training loss: 2.590117979418766
Validation loss: 2.0961949574061016
Epoch: 19| Step: 2
Training loss: 2.816442650759481
Validation loss: 2.0890301827286106
Epoch: 19| Step: 3
Training loss: 2.4535628978813366
Validation loss: 2.060125560824407
Epoch: 19| Step: 4
Training loss: 2.5869441075666533
Validation loss: 2.0854805153536633
Epoch: 19| Step: 5
Training loss: 2.6405833765846265
Validation loss: 2.1305984293422005
Epoch: 19| Step: 6
Training loss: 2.765281785261349
Validation loss: 2.1170016373658824
Epoch: 19| Step: 7
Training loss: 2.5451576668215887
Validation loss: 2.1366231705198078
Epoch: 20| Step: 0
Training loss: 2.8324859885452525
Validation loss: 2.073258863769624
Epoch: 20| Step: 1
Training loss: 2.4784404962694957
Validation loss: 2.1158367438698904
Epoch: 20| Step: 2
Training loss: 2.8521212931731497
Validation loss: 2.0720957032262883
Epoch: 20| Step: 3
Training loss: 2.5697261988033677
Validation loss: 2.0047368255153004
Epoch: 20| Step: 4
Training loss: 2.6482319709900928
Validation loss: 2.1311437961921396
Epoch: 20| Step: 5
Training loss: 2.40978071109417
Validation loss: 2.0358360914959466
Epoch: 20| Step: 6
Training loss: 2.629940198066118
Validation loss: 2.1329524225112877
Epoch: 20| Step: 7
Training loss: 2.6318292338156737
Validation loss: 2.099259747025999
Epoch: 21| Step: 0
Training loss: 2.638436397998204
Validation loss: 2.1141108389509875
Epoch: 21| Step: 1
Training loss: 2.492903268803482
Validation loss: 2.073862631234417
Epoch: 21| Step: 2
Training loss: 2.855193869827714
Validation loss: 2.148907977829302
Epoch: 21| Step: 3
Training loss: 2.493302529326632
Validation loss: 2.089339834105879
Epoch: 21| Step: 4
Training loss: 2.6138320593264583
Validation loss: 2.036898924362818
Epoch: 21| Step: 5
Training loss: 2.9380640340621427
Validation loss: 2.073055058460332
Epoch: 21| Step: 6
Training loss: 2.389825126123953
Validation loss: 2.064811787118067
Epoch: 21| Step: 7
Training loss: 2.6132720354085954
Validation loss: 2.080299497606552
Epoch: 22| Step: 0
Training loss: 2.788028728479392
Validation loss: 2.0748619349536805
Epoch: 22| Step: 1
Training loss: 2.5384885168531515
Validation loss: 1.9861170252691565
Epoch: 22| Step: 2
Training loss: 2.708735294346132
Validation loss: 2.1047253227487626
Epoch: 22| Step: 3
Training loss: 2.6290810967579676
Validation loss: 2.0885736955996177
Epoch: 22| Step: 4
Training loss: 2.7023929199968446
Validation loss: 2.0985847985327055
Epoch: 22| Step: 5
Training loss: 2.5110528754436703
Validation loss: 2.1008090507235835
Epoch: 22| Step: 6
Training loss: 2.5564411455613434
Validation loss: 2.0164621235390836
Epoch: 22| Step: 7
Training loss: 2.624401660119677
Validation loss: 2.068573548259975
Epoch: 23| Step: 0
Training loss: 2.8013690666825948
Validation loss: 2.0860134845589564
Epoch: 23| Step: 1
Training loss: 2.2586950141534534
Validation loss: 2.0359697388983933
Epoch: 23| Step: 2
Training loss: 2.4769690146881818
Validation loss: 2.1183588117956713
Epoch: 23| Step: 3
Training loss: 2.9211798672302645
Validation loss: 2.1197462859630467
Epoch: 23| Step: 4
Training loss: 2.675312708464887
Validation loss: 2.147912613328052
Epoch: 23| Step: 5
Training loss: 2.753339906720065
Validation loss: 2.058626809551343
Epoch: 23| Step: 6
Training loss: 2.4893973585652787
Validation loss: 2.1084701242873733
Epoch: 23| Step: 7
Training loss: 2.649871977826636
Validation loss: 2.0305177737144304
Epoch: 24| Step: 0
Training loss: 2.952437224855327
Validation loss: 2.0529959503322393
Epoch: 24| Step: 1
Training loss: 2.600085231411041
Validation loss: 2.1133840248833784
Epoch: 24| Step: 2
Training loss: 2.7127304963653587
Validation loss: 2.0953646221178435
Epoch: 24| Step: 3
Training loss: 2.814729103889696
Validation loss: 2.1133817370243904
Epoch: 24| Step: 4
Training loss: 2.6379253424143942
Validation loss: 2.0955672443776407
Epoch: 24| Step: 5
Training loss: 2.6400020248231924
Validation loss: 2.0668002499879
Epoch: 24| Step: 6
Training loss: 2.1629536676545826
Validation loss: 2.082257463305108
Epoch: 24| Step: 7
Training loss: 2.483264602973051
Validation loss: 2.1150348473950555
Epoch: 25| Step: 0
Training loss: 2.726076448942868
Validation loss: 2.0902258488199856
Epoch: 25| Step: 1
Training loss: 2.767492407398095
Validation loss: 2.1094979941842364
Epoch: 25| Step: 2
Training loss: 2.693566328898598
Validation loss: 2.088748283894923
Epoch: 25| Step: 3
Training loss: 2.897644428014102
Validation loss: 2.111153830097461
Epoch: 25| Step: 4
Training loss: 2.3146814933813253
Validation loss: 2.10644079383129
Epoch: 25| Step: 5
Training loss: 2.6612950602775456
Validation loss: 2.0976661726180326
Epoch: 25| Step: 6
Training loss: 2.3713244054177784
Validation loss: 2.132589679154702
Epoch: 25| Step: 7
Training loss: 2.603031053256009
Validation loss: 2.0862574209272573
Epoch: 26| Step: 0
Training loss: 2.5699557256781294
Validation loss: 2.076197830530154
Epoch: 26| Step: 1
Training loss: 2.428622291336854
Validation loss: 2.133260922531024
Epoch: 26| Step: 2
Training loss: 2.5427042505673505
Validation loss: 2.1057459300158494
Epoch: 26| Step: 3
Training loss: 2.6817392218593588
Validation loss: 2.128873920372264
Epoch: 26| Step: 4
Training loss: 2.6038363031010934
Validation loss: 2.074248646171348
Epoch: 26| Step: 5
Training loss: 2.910275532370845
Validation loss: 2.074298762998648
Epoch: 26| Step: 6
Training loss: 2.7990032601782158
Validation loss: 2.058005223796408
Epoch: 26| Step: 7
Training loss: 2.5132441656989233
Validation loss: 2.04687710763214
Epoch: 27| Step: 0
Training loss: 2.6381147743863784
Validation loss: 2.07732910853003
Epoch: 27| Step: 1
Training loss: 2.869620722521617
Validation loss: 2.118019460363534
Epoch: 27| Step: 2
Training loss: 2.647977986039684
Validation loss: 2.143289798497868
Epoch: 27| Step: 3
Training loss: 2.53144920412984
Validation loss: 2.11598106283156
Epoch: 27| Step: 4
Training loss: 2.6712543145851346
Validation loss: 2.073682206630494
Epoch: 27| Step: 5
Training loss: 2.507110877836453
Validation loss: 2.1500590262929404
Epoch: 27| Step: 6
Training loss: 2.3625633473456213
Validation loss: 2.1272411684264836
Epoch: 27| Step: 7
Training loss: 2.81978291534956
Validation loss: 2.0943281308355544
Epoch: 28| Step: 0
Training loss: 2.586319817346903
Validation loss: 2.071442604861058
Epoch: 28| Step: 1
Training loss: 2.733093048404421
Validation loss: 2.081840439845728
Epoch: 28| Step: 2
Training loss: 2.4425133232135967
Validation loss: 2.138051852150461
Epoch: 28| Step: 3
Training loss: 2.823242863087951
Validation loss: 2.0599899978116962
Epoch: 28| Step: 4
Training loss: 2.595213419787356
Validation loss: 2.116310326487636
Epoch: 28| Step: 5
Training loss: 2.6937238793755145
Validation loss: 2.118828047286136
Epoch: 28| Step: 6
Training loss: 2.2907731366103294
Validation loss: 2.0818803625798386
Epoch: 28| Step: 7
Training loss: 2.857936142738616
Validation loss: 2.1353739614384732
Epoch: 29| Step: 0
Training loss: 2.7857154402538327
Validation loss: 2.0435677291683274
Epoch: 29| Step: 1
Training loss: 2.872427909351493
Validation loss: 2.0555347087815843
Epoch: 29| Step: 2
Training loss: 2.4984075242678316
Validation loss: 2.0310891475676436
Epoch: 29| Step: 3
Training loss: 2.5637298051995656
Validation loss: 2.0767218762517863
Epoch: 29| Step: 4
Training loss: 2.81658503246701
Validation loss: 2.0945470753658926
Epoch: 29| Step: 5
Training loss: 2.2948912273551976
Validation loss: 2.068991330062291
Epoch: 29| Step: 6
Training loss: 2.6854813557348542
Validation loss: 2.1303248265672146
Epoch: 29| Step: 7
Training loss: 2.512631643461954
Validation loss: 2.066283362638654
Epoch: 30| Step: 0
Training loss: 2.527965722648401
Validation loss: 2.073662685961922
Epoch: 30| Step: 1
Training loss: 2.838182469777179
Validation loss: 2.133375589238312
Epoch: 30| Step: 2
Training loss: 2.3661873596251013
Validation loss: 2.119279307847997
Epoch: 30| Step: 3
Training loss: 2.6065159284645385
Validation loss: 2.1189959037015336
Epoch: 30| Step: 4
Training loss: 2.6265103672533927
Validation loss: 2.098500818780889
Epoch: 30| Step: 5
Training loss: 2.414274237275757
Validation loss: 2.1290890596932672
Epoch: 30| Step: 6
Training loss: 2.8148348970933066
Validation loss: 2.0900551385328074
Epoch: 30| Step: 7
Training loss: 2.829424143457736
Validation loss: 2.098218388260388
