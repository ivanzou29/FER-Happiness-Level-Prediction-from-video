Epoch: 1| Step: 0
Training loss: 6.237566673518753
Validation loss: 5.560038776229171
Epoch: 1| Step: 1
Training loss: 5.942283550552432
Validation loss: 5.466845851449218
Epoch: 1| Step: 2
Training loss: 5.542886853033115
Validation loss: 5.314682035614984
Epoch: 1| Step: 3
Training loss: 4.582584851733773
Validation loss: 5.1079432671471565
Epoch: 1| Step: 4
Training loss: 5.355839132888778
Validation loss: 4.998437758005208
Epoch: 1| Step: 5
Training loss: 5.873599920439817
Validation loss: 4.996075223257498
Epoch: 1| Step: 6
Training loss: 5.14882536890147
Validation loss: 4.91837243757243
Epoch: 1| Step: 7
Training loss: 5.585150731305848
Validation loss: 4.986016565260772
Epoch: 1| Step: 8
Training loss: 4.881807513763773
Validation loss: 4.8125223270933954
Epoch: 1| Step: 9
Training loss: 5.436186006879419
Validation loss: 4.779809461235983
Epoch: 2| Step: 0
Training loss: 4.446312548841165
Validation loss: 4.717296145927678
Epoch: 2| Step: 1
Training loss: 4.688227075773279
Validation loss: 4.666908740725759
Epoch: 2| Step: 2
Training loss: 5.512597136387743
Validation loss: 4.55345435387223
Epoch: 2| Step: 3
Training loss: 5.028957436967629
Validation loss: 4.572775851647223
Epoch: 2| Step: 4
Training loss: 4.701597047921631
Validation loss: 4.604859421200114
Epoch: 2| Step: 5
Training loss: 5.101053256311922
Validation loss: 4.4914488482830555
Epoch: 2| Step: 6
Training loss: 4.645614459209167
Validation loss: 4.474346143036786
Epoch: 2| Step: 7
Training loss: 5.270685769328685
Validation loss: 4.403027439736226
Epoch: 2| Step: 8
Training loss: 5.414081876205407
Validation loss: 4.3539975054521
Epoch: 2| Step: 9
Training loss: 4.423099415699596
Validation loss: 4.421053681090346
Epoch: 3| Step: 0
Training loss: 5.100014608025667
Validation loss: 4.368531707046715
Epoch: 3| Step: 1
Training loss: 4.997455330859451
Validation loss: 4.303040174472294
Epoch: 3| Step: 2
Training loss: 4.212512116457213
Validation loss: 4.201605843263296
Epoch: 3| Step: 3
Training loss: 4.827803221414699
Validation loss: 4.143004598959907
Epoch: 3| Step: 4
Training loss: 5.085480325194411
Validation loss: 4.166301581475847
Epoch: 3| Step: 5
Training loss: 4.220319667839734
Validation loss: 4.088220698038455
Epoch: 3| Step: 6
Training loss: 4.332651353625767
Validation loss: 3.9982293300665885
Epoch: 3| Step: 7
Training loss: 4.731321048581051
Validation loss: 4.040901430723668
Epoch: 3| Step: 8
Training loss: 3.452726453333344
Validation loss: 4.013873351355342
Epoch: 3| Step: 9
Training loss: 4.283024997721063
Validation loss: 3.919707385097045
Epoch: 4| Step: 0
Training loss: 4.139543269666994
Validation loss: 3.899637872114395
Epoch: 4| Step: 1
Training loss: 4.358429399432092
Validation loss: 3.9128115649079236
Epoch: 4| Step: 2
Training loss: 4.498435490227821
Validation loss: 3.8930384691398268
Epoch: 4| Step: 3
Training loss: 4.0682079417027825
Validation loss: 3.8051162747954876
Epoch: 4| Step: 4
Training loss: 4.015828762005665
Validation loss: 3.7339298391078866
Epoch: 4| Step: 5
Training loss: 4.1646705169228415
Validation loss: 3.6949045949193695
Epoch: 4| Step: 6
Training loss: 4.405052292824076
Validation loss: 3.5552983967296585
Epoch: 4| Step: 7
Training loss: 4.211630910991598
Validation loss: 3.6492232820253117
Epoch: 4| Step: 8
Training loss: 3.548415332693034
Validation loss: 3.5785273935986237
Epoch: 4| Step: 9
Training loss: 4.333079452902521
Validation loss: 3.568266194387533
Epoch: 5| Step: 0
Training loss: 3.5693932483001563
Validation loss: 3.5099388321513665
Epoch: 5| Step: 1
Training loss: 3.907068639804033
Validation loss: 3.5059468411834955
Epoch: 5| Step: 2
Training loss: 3.9634744017712658
Validation loss: 3.4188719146263242
Epoch: 5| Step: 3
Training loss: 3.875954664211257
Validation loss: 3.4232883538070045
Epoch: 5| Step: 4
Training loss: 4.372030503818376
Validation loss: 3.4185345760244656
Epoch: 5| Step: 5
Training loss: 3.7559246309496177
Validation loss: 3.365991253112599
Epoch: 5| Step: 6
Training loss: 4.050211234529814
Validation loss: 3.333459922422021
Epoch: 5| Step: 7
Training loss: 4.123264988235416
Validation loss: 3.368020168142482
Epoch: 5| Step: 8
Training loss: 3.4334851487553624
Validation loss: 3.312930690116838
Epoch: 5| Step: 9
Training loss: 3.4930746500560588
Validation loss: 3.265935291536695
Epoch: 6| Step: 0
Training loss: 3.775909182975811
Validation loss: 3.297426619547884
Epoch: 6| Step: 1
Training loss: 3.69657711786264
Validation loss: 3.15972675332414
Epoch: 6| Step: 2
Training loss: 3.539082171320192
Validation loss: 3.1997011533160995
Epoch: 6| Step: 3
Training loss: 3.6893352532123864
Validation loss: 3.0473715953676335
Epoch: 6| Step: 4
Training loss: 4.255710579948219
Validation loss: 3.057693284850184
Epoch: 6| Step: 5
Training loss: 3.977449029755348
Validation loss: 3.031124727496291
Epoch: 6| Step: 6
Training loss: 3.427512485027877
Validation loss: 3.0716494919962334
Epoch: 6| Step: 7
Training loss: 3.452331451787752
Validation loss: 3.03949874373044
Epoch: 6| Step: 8
Training loss: 2.873825828610439
Validation loss: 2.913310860333171
Epoch: 6| Step: 9
Training loss: 2.980931077448953
Validation loss: 2.956777621961744
Epoch: 7| Step: 0
Training loss: 3.3868097031291793
Validation loss: 2.9247971268320576
Epoch: 7| Step: 1
Training loss: 3.4343398393492035
Validation loss: 2.88018281761351
Epoch: 7| Step: 2
Training loss: 3.882800956110229
Validation loss: 2.861792115581292
Epoch: 7| Step: 3
Training loss: 3.3534719723152606
Validation loss: 2.875487597863383
Epoch: 7| Step: 4
Training loss: 2.9871769878107903
Validation loss: 2.773609812102314
Epoch: 7| Step: 5
Training loss: 3.561500275193739
Validation loss: 2.758609055304268
Epoch: 7| Step: 6
Training loss: 3.0059697835473345
Validation loss: 2.791735083613326
Epoch: 7| Step: 7
Training loss: 3.4264204936036116
Validation loss: 2.8115115097981795
Epoch: 7| Step: 8
Training loss: 3.4852066758113667
Validation loss: 2.7025095866386133
Epoch: 7| Step: 9
Training loss: 2.905866043815442
Validation loss: 2.6936650409255165
Epoch: 8| Step: 0
Training loss: 2.7570310355381222
Validation loss: 2.7451508253615042
Epoch: 8| Step: 1
Training loss: 3.143796619350223
Validation loss: 2.671139280991285
Epoch: 8| Step: 2
Training loss: 3.313440441291106
Validation loss: 2.641426342018592
Epoch: 8| Step: 3
Training loss: 3.265098419809124
Validation loss: 2.6830790503882915
Epoch: 8| Step: 4
Training loss: 3.5022137316758477
Validation loss: 2.6961214162805884
Epoch: 8| Step: 5
Training loss: 2.5365148351330604
Validation loss: 2.605732724828921
Epoch: 8| Step: 6
Training loss: 3.4242163882463905
Validation loss: 2.6342776801912686
Epoch: 8| Step: 7
Training loss: 3.2665564563870118
Validation loss: 2.6266706341623403
Epoch: 8| Step: 8
Training loss: 3.4315680907068167
Validation loss: 2.5956928928803658
Epoch: 8| Step: 9
Training loss: 2.8118216650238
Validation loss: 2.5551830147793124
Epoch: 9| Step: 0
Training loss: 3.0120673664355997
Validation loss: 2.5962255619268815
Epoch: 9| Step: 1
Training loss: 2.7692261434989183
Validation loss: 2.529959826731722
Epoch: 9| Step: 2
Training loss: 2.983223098622083
Validation loss: 2.500022763395243
Epoch: 9| Step: 3
Training loss: 3.637447820859441
Validation loss: 2.5097010040479466
Epoch: 9| Step: 4
Training loss: 2.9926056333173103
Validation loss: 2.5110416694355306
Epoch: 9| Step: 5
Training loss: 2.5908792074204943
Validation loss: 2.4509319382201147
Epoch: 9| Step: 6
Training loss: 2.6327149687227567
Validation loss: 2.4338820939814303
Epoch: 9| Step: 7
Training loss: 3.007411385084479
Validation loss: 2.4200857765326003
Epoch: 9| Step: 8
Training loss: 3.1465748466683636
Validation loss: 2.4482844078797554
Epoch: 9| Step: 9
Training loss: 3.237279794634687
Validation loss: 2.4116688211585484
Epoch: 10| Step: 0
Training loss: 2.8844870895808317
Validation loss: 2.3750577010807477
Epoch: 10| Step: 1
Training loss: 2.5977515181661
Validation loss: 2.3953916114949476
Epoch: 10| Step: 2
Training loss: 2.741728567644006
Validation loss: 2.3770817913444535
Epoch: 10| Step: 3
Training loss: 2.99743447277486
Validation loss: 2.3752910494177515
Epoch: 10| Step: 4
Training loss: 2.9431367725421205
Validation loss: 2.3800028275369938
Epoch: 10| Step: 5
Training loss: 2.9836252279286724
Validation loss: 2.282045654350606
Epoch: 10| Step: 6
Training loss: 2.897801743364728
Validation loss: 2.3230629882233784
Epoch: 10| Step: 7
Training loss: 3.168119415200015
Validation loss: 2.283370506355062
Epoch: 10| Step: 8
Training loss: 2.820388835180374
Validation loss: 2.2755350903241096
Epoch: 10| Step: 9
Training loss: 2.9136399686339574
Validation loss: 2.303418477984475
Epoch: 11| Step: 0
Training loss: 2.5791997345595306
Validation loss: 2.2477328877174814
Epoch: 11| Step: 1
Training loss: 2.622741090585777
Validation loss: 2.2632114731302564
Epoch: 11| Step: 2
Training loss: 2.840514637699025
Validation loss: 2.3149100850982807
Epoch: 11| Step: 3
Training loss: 2.9716002584993624
Validation loss: 2.2899951159812364
Epoch: 11| Step: 4
Training loss: 2.9175296233437593
Validation loss: 2.2453543252918156
Epoch: 11| Step: 5
Training loss: 2.8645091839065655
Validation loss: 2.2459906379184846
Epoch: 11| Step: 6
Training loss: 2.63182814673012
Validation loss: 2.241473517822323
Epoch: 11| Step: 7
Training loss: 2.8713373820419
Validation loss: 2.2418598253674267
Epoch: 11| Step: 8
Training loss: 2.9919073307353634
Validation loss: 2.2736529740477125
Epoch: 11| Step: 9
Training loss: 2.7970965420233838
Validation loss: 2.215765738796794
Epoch: 12| Step: 0
Training loss: 2.7435410682881693
Validation loss: 2.197964414192558
Epoch: 12| Step: 1
Training loss: 2.845981099959324
Validation loss: 2.2356962727254848
Epoch: 12| Step: 2
Training loss: 2.81056545269985
Validation loss: 2.2008882731999506
Epoch: 12| Step: 3
Training loss: 2.6746913945806714
Validation loss: 2.170297344721332
Epoch: 12| Step: 4
Training loss: 2.571913200456258
Validation loss: 2.087575556114783
Epoch: 12| Step: 5
Training loss: 2.875666831263015
Validation loss: 2.179805647610644
Epoch: 12| Step: 6
Training loss: 2.7992662830879116
Validation loss: 2.243795836278119
Epoch: 12| Step: 7
Training loss: 2.8625540649105883
Validation loss: 2.245455372316232
Epoch: 12| Step: 8
Training loss: 2.7789123655203127
Validation loss: 2.0971568595059935
Epoch: 12| Step: 9
Training loss: 2.548489579557954
Validation loss: 2.1299371124946047
Epoch: 13| Step: 0
Training loss: 2.9607357067100386
Validation loss: 2.166718921216495
Epoch: 13| Step: 1
Training loss: 2.6304649504817377
Validation loss: 2.148434709715658
Epoch: 13| Step: 2
Training loss: 2.7754729203030335
Validation loss: 2.1584735463911846
Epoch: 13| Step: 3
Training loss: 2.5459529401171217
Validation loss: 2.160221363482585
Epoch: 13| Step: 4
Training loss: 2.5228860447414143
Validation loss: 2.149203302119598
Epoch: 13| Step: 5
Training loss: 2.991812181962817
Validation loss: 2.138596338755328
Epoch: 13| Step: 6
Training loss: 2.6149538443815503
Validation loss: 2.1469804075631886
Epoch: 13| Step: 7
Training loss: 2.637975322686053
Validation loss: 2.1767663269712543
Epoch: 13| Step: 8
Training loss: 2.793812273598762
Validation loss: 2.1654658321068583
Epoch: 13| Step: 9
Training loss: 2.588468943341235
Validation loss: 2.055407390187127
Epoch: 14| Step: 0
Training loss: 2.7289767793790656
Validation loss: 2.1574725532653276
Epoch: 14| Step: 1
Training loss: 2.5117320391123954
Validation loss: 2.159935297693599
Epoch: 14| Step: 2
Training loss: 2.741502986145898
Validation loss: 2.1309682907068077
Epoch: 14| Step: 3
Training loss: 2.2084554482531327
Validation loss: 2.1144421753507507
Epoch: 14| Step: 4
Training loss: 2.986133317100896
Validation loss: 2.140207199069236
Epoch: 14| Step: 5
Training loss: 2.5252106758079327
Validation loss: 2.139293799261969
Epoch: 14| Step: 6
Training loss: 2.7167866951417836
Validation loss: 2.1343880604727032
Epoch: 14| Step: 7
Training loss: 2.976599345141872
Validation loss: 2.1076388258692527
Epoch: 14| Step: 8
Training loss: 2.6192193641746075
Validation loss: 2.035686082016133
Epoch: 14| Step: 9
Training loss: 2.7275215801220964
Validation loss: 2.134826577596444
Epoch: 15| Step: 0
Training loss: 2.821619127402221
Validation loss: 2.072030736999872
Epoch: 15| Step: 1
Training loss: 2.1935416576428852
Validation loss: 2.0695990255828165
Epoch: 15| Step: 2
Training loss: 2.50429947215832
Validation loss: 2.05867124569233
Epoch: 15| Step: 3
Training loss: 2.816353933665883
Validation loss: 2.0939767786583547
Epoch: 15| Step: 4
Training loss: 2.954487158460303
Validation loss: 2.118342529772128
Epoch: 15| Step: 5
Training loss: 2.5901465145484326
Validation loss: 2.10432009216661
Epoch: 15| Step: 6
Training loss: 2.6840794108563477
Validation loss: 2.067954199667902
Epoch: 15| Step: 7
Training loss: 2.7929879568013103
Validation loss: 2.0959823966574973
Epoch: 15| Step: 8
Training loss: 2.629626601948236
Validation loss: 2.1287538743298287
Epoch: 15| Step: 9
Training loss: 2.5779756444959876
Validation loss: 2.120904179291567
Epoch: 16| Step: 0
Training loss: 2.26905321349164
Validation loss: 2.095467634352342
Epoch: 16| Step: 1
Training loss: 2.913637186466069
Validation loss: 2.1011912418059615
Epoch: 16| Step: 2
Training loss: 2.7267755026264324
Validation loss: 2.07494110482449
Epoch: 16| Step: 3
Training loss: 2.6476344688782545
Validation loss: 2.0533066164021236
Epoch: 16| Step: 4
Training loss: 2.4867024585646833
Validation loss: 2.099241436200045
Epoch: 16| Step: 5
Training loss: 2.9388713476390276
Validation loss: 2.122713496155609
Epoch: 16| Step: 6
Training loss: 2.7082321343710802
Validation loss: 2.066053604204895
Epoch: 16| Step: 7
Training loss: 2.5438086650560146
Validation loss: 2.112280784084274
Epoch: 16| Step: 8
Training loss: 2.4841057973436316
Validation loss: 2.02790537178974
Epoch: 16| Step: 9
Training loss: 2.7132737704151153
Validation loss: 2.0900598519679257
Epoch: 17| Step: 0
Training loss: 2.5476247233967184
Validation loss: 2.081997282889821
Epoch: 17| Step: 1
Training loss: 2.6528932791481297
Validation loss: 2.1228411368581783
Epoch: 17| Step: 2
Training loss: 2.560827314090658
Validation loss: 2.0800834975724336
Epoch: 17| Step: 3
Training loss: 2.6751091551569246
Validation loss: 2.1215008738365237
Epoch: 17| Step: 4
Training loss: 2.811481545743394
Validation loss: 2.103308755712624
Epoch: 17| Step: 5
Training loss: 2.3985149358618743
Validation loss: 2.1222840594270718
Epoch: 17| Step: 6
Training loss: 2.639131744542373
Validation loss: 2.11830192112074
Epoch: 17| Step: 7
Training loss: 2.626637266094563
Validation loss: 2.0720528641758555
Epoch: 17| Step: 8
Training loss: 2.9459134002408742
Validation loss: 2.051268337769739
Epoch: 17| Step: 9
Training loss: 2.5622616168534944
Validation loss: 2.0300247843747856
Epoch: 18| Step: 0
Training loss: 2.6543893917260357
Validation loss: 2.044110377510563
Epoch: 18| Step: 1
Training loss: 2.7364770275610546
Validation loss: 2.1000396133992045
Epoch: 18| Step: 2
Training loss: 2.7682160562304685
Validation loss: 2.1131561707444844
Epoch: 18| Step: 3
Training loss: 2.46528092027443
Validation loss: 2.0583633468653284
Epoch: 18| Step: 4
Training loss: 2.67848699164138
Validation loss: 2.118212666101886
Epoch: 18| Step: 5
Training loss: 2.6707741772968605
Validation loss: 2.0881827771347172
Epoch: 18| Step: 6
Training loss: 2.7931979425465605
Validation loss: 2.0850309546522716
Epoch: 18| Step: 7
Training loss: 2.7239640322759957
Validation loss: 2.1267572879474916
Epoch: 18| Step: 8
Training loss: 2.233732437893012
Validation loss: 2.0458659366619307
Epoch: 18| Step: 9
Training loss: 2.6257519326223338
Validation loss: 2.016740629433183
Epoch: 19| Step: 0
Training loss: 2.8422779003863963
Validation loss: 2.059747615244911
Epoch: 19| Step: 1
Training loss: 2.6308051813854982
Validation loss: 2.1064738947454287
Epoch: 19| Step: 2
Training loss: 2.6313936389126877
Validation loss: 2.0546119268103338
Epoch: 19| Step: 3
Training loss: 2.808198988631934
Validation loss: 2.0894680984862646
Epoch: 19| Step: 4
Training loss: 2.2058284756681794
Validation loss: 2.077777243844936
Epoch: 19| Step: 5
Training loss: 2.2485392385108165
Validation loss: 2.0794216637412486
Epoch: 19| Step: 6
Training loss: 2.6474744457996398
Validation loss: 2.100615169239754
Epoch: 19| Step: 7
Training loss: 2.634620475871218
Validation loss: 2.083418087802311
Epoch: 19| Step: 8
Training loss: 2.9765751555566755
Validation loss: 2.1129132404955495
Epoch: 19| Step: 9
Training loss: 2.6500220495782165
Validation loss: 2.1158918528200648
Epoch: 20| Step: 0
Training loss: 2.78024479563531
Validation loss: 2.1183378152109245
Epoch: 20| Step: 1
Training loss: 2.5349959923827265
Validation loss: 2.1247512838673748
Epoch: 20| Step: 2
Training loss: 2.665491699606545
Validation loss: 2.0350453816037675
Epoch: 20| Step: 3
Training loss: 2.7585929652374714
Validation loss: 2.0851165671883773
Epoch: 20| Step: 4
Training loss: 2.697508163651919
Validation loss: 2.0320277633325143
Epoch: 20| Step: 5
Training loss: 2.688416080923844
Validation loss: 2.0379700573379864
Epoch: 20| Step: 6
Training loss: 2.572674161985929
Validation loss: 2.045096135001369
Epoch: 20| Step: 7
Training loss: 2.853707455264883
Validation loss: 2.117732833629912
Epoch: 20| Step: 8
Training loss: 2.259679319535458
Validation loss: 2.0980472366576484
Epoch: 20| Step: 9
Training loss: 2.4958668875840173
Validation loss: 2.0791395765379854
Epoch: 21| Step: 0
Training loss: 2.4829984486053083
Validation loss: 2.0868359565104995
Epoch: 21| Step: 1
Training loss: 2.2644416612693914
Validation loss: 2.127017824729131
Epoch: 21| Step: 2
Training loss: 2.476947068641813
Validation loss: 2.1250317030561705
Epoch: 21| Step: 3
Training loss: 2.56757689185369
Validation loss: 2.0987143033190945
Epoch: 21| Step: 4
Training loss: 2.7861718336515606
Validation loss: 2.0827941655394544
Epoch: 21| Step: 5
Training loss: 2.75136740240336
Validation loss: 2.091834079988465
Epoch: 21| Step: 6
Training loss: 2.920838687327689
Validation loss: 2.0893640412994285
Epoch: 21| Step: 7
Training loss: 2.671645037475658
Validation loss: 2.095327500401167
Epoch: 21| Step: 8
Training loss: 2.780760304062963
Validation loss: 2.059554820282727
Epoch: 21| Step: 9
Training loss: 2.590379570354886
Validation loss: 2.0742025960946586
Epoch: 22| Step: 0
Training loss: 2.8357313517317424
Validation loss: 2.1089107668049114
Epoch: 22| Step: 1
Training loss: 2.5201101185187222
Validation loss: 2.1203836953992283
Epoch: 22| Step: 2
Training loss: 2.740033208269906
Validation loss: 2.1349421934641164
Epoch: 22| Step: 3
Training loss: 2.528354071387695
Validation loss: 2.117964977465053
Epoch: 22| Step: 4
Training loss: 2.5509347212277564
Validation loss: 2.0870112532217053
Epoch: 22| Step: 5
Training loss: 2.3986305382795994
Validation loss: 2.0904942120838093
Epoch: 22| Step: 6
Training loss: 2.7647179446953905
Validation loss: 2.0528556535376796
Epoch: 22| Step: 7
Training loss: 2.740395506555328
Validation loss: 2.0912584159462018
Epoch: 22| Step: 8
Training loss: 2.7162471080611907
Validation loss: 2.109285642418796
Epoch: 22| Step: 9
Training loss: 2.516424016644049
Validation loss: 2.07705583851475
Epoch: 23| Step: 0
Training loss: 2.1855693471671986
Validation loss: 2.0697008419950924
Epoch: 23| Step: 1
Training loss: 3.036926931316792
Validation loss: 2.1068061966526237
Epoch: 23| Step: 2
Training loss: 2.6563446028075397
Validation loss: 2.0687206237398525
Epoch: 23| Step: 3
Training loss: 2.5903275672234156
Validation loss: 2.0878555654086512
Epoch: 23| Step: 4
Training loss: 2.5290773274345155
Validation loss: 2.0674706204727022
Epoch: 23| Step: 5
Training loss: 2.4547981339259684
Validation loss: 2.0882073428610495
Epoch: 23| Step: 6
Training loss: 2.463622067021935
Validation loss: 2.141843225497827
Epoch: 23| Step: 7
Training loss: 2.416030822064674
Validation loss: 2.1118837921318825
Epoch: 23| Step: 8
Training loss: 2.734059953251284
Validation loss: 2.1041438605540397
Epoch: 23| Step: 9
Training loss: 3.1363630081196234
Validation loss: 2.082181698065625
Epoch: 24| Step: 0
Training loss: 2.3596156925939953
Validation loss: 2.068513697061028
Epoch: 24| Step: 1
Training loss: 2.3727521799720797
Validation loss: 2.1177074821131017
Epoch: 24| Step: 2
Training loss: 2.712334880110045
Validation loss: 2.1310093527098353
Epoch: 24| Step: 3
Training loss: 2.946807401009197
Validation loss: 2.034060683962514
Epoch: 24| Step: 4
Training loss: 3.0094222876140178
Validation loss: 2.081707985355686
Epoch: 24| Step: 5
Training loss: 2.30935465348176
Validation loss: 2.1118334562625867
Epoch: 24| Step: 6
Training loss: 2.6097026322311736
Validation loss: 2.1038256496504664
Epoch: 24| Step: 7
Training loss: 2.8740053529523615
Validation loss: 2.120163312316394
Epoch: 24| Step: 8
Training loss: 2.440000767316854
Validation loss: 2.0815195968872007
Epoch: 24| Step: 9
Training loss: 2.598262033599645
Validation loss: 2.068691038160078
Epoch: 25| Step: 0
Training loss: 2.7087161062643568
Validation loss: 2.0921174369983695
Epoch: 25| Step: 1
Training loss: 2.8292016777677564
Validation loss: 2.1106890031256995
Epoch: 25| Step: 2
Training loss: 2.498386625400574
Validation loss: 2.071829021088618
Epoch: 25| Step: 3
Training loss: 2.844445279819975
Validation loss: 2.0823211447574286
Epoch: 25| Step: 4
Training loss: 2.811857192438212
Validation loss: 2.048927102727154
Epoch: 25| Step: 5
Training loss: 2.4543788159765505
Validation loss: 2.1591915759513274
Epoch: 25| Step: 6
Training loss: 2.7220788504890945
Validation loss: 2.016282364820761
Epoch: 25| Step: 7
Training loss: 2.555876382324872
Validation loss: 2.0997924255480225
Epoch: 25| Step: 8
Training loss: 2.5349168003130353
Validation loss: 2.1165915144045293
Epoch: 25| Step: 9
Training loss: 2.3317411871729545
Validation loss: 2.0954228182436268
Epoch: 26| Step: 0
Training loss: 2.6844108925530334
Validation loss: 2.0117078126898678
Epoch: 26| Step: 1
Training loss: 2.729842958789183
Validation loss: 2.034763127865172
Epoch: 26| Step: 2
Training loss: 2.6296122766299277
Validation loss: 2.1002417119182537
Epoch: 26| Step: 3
Training loss: 2.7490969822533495
Validation loss: 2.1148632960954736
Epoch: 26| Step: 4
Training loss: 2.1892183366807387
Validation loss: 2.1163949462758698
Epoch: 26| Step: 5
Training loss: 2.9941173734216227
Validation loss: 2.031316346209017
Epoch: 26| Step: 6
Training loss: 2.4312328073241822
Validation loss: 2.064501407937061
Epoch: 26| Step: 7
Training loss: 2.6749273343778257
Validation loss: 2.1215568793457753
Epoch: 26| Step: 8
Training loss: 2.5921752009637493
Validation loss: 2.0504639033531493
Epoch: 26| Step: 9
Training loss: 2.592510432752992
Validation loss: 2.0572799283088856
Epoch: 27| Step: 0
Training loss: 2.6148626677299225
Validation loss: 2.1256508191748384
Epoch: 27| Step: 1
Training loss: 2.575076896482245
Validation loss: 2.068481380280366
Epoch: 27| Step: 2
Training loss: 2.484783594851799
Validation loss: 2.0767984942480227
Epoch: 27| Step: 3
Training loss: 2.783811097247565
Validation loss: 2.0972048609186764
Epoch: 27| Step: 4
Training loss: 3.0805168347399454
Validation loss: 2.131220001778254
Epoch: 27| Step: 5
Training loss: 2.5884160728355248
Validation loss: 2.0698146380896207
Epoch: 27| Step: 6
Training loss: 2.768782370487885
Validation loss: 2.1353479686774772
Epoch: 27| Step: 7
Training loss: 2.285140391237706
Validation loss: 2.038877544996402
Epoch: 27| Step: 8
Training loss: 2.6282350496708546
Validation loss: 2.092567816499614
Epoch: 27| Step: 9
Training loss: 2.4594683424650725
Validation loss: 2.1211343574474797
Epoch: 28| Step: 0
Training loss: 2.714931042043115
Validation loss: 2.0788207606111277
Epoch: 28| Step: 1
Training loss: 2.6757452523810348
Validation loss: 2.0896702604600716
Epoch: 28| Step: 2
Training loss: 2.623102137820686
Validation loss: 2.1323374077522037
Epoch: 28| Step: 3
Training loss: 2.247842602103307
Validation loss: 2.0843187455280034
Epoch: 28| Step: 4
Training loss: 2.9019794877298133
Validation loss: 2.1227032783071236
Epoch: 28| Step: 5
Training loss: 2.6931982621545822
Validation loss: 2.0270943553498846
Epoch: 28| Step: 6
Training loss: 2.8845189944081775
Validation loss: 2.084156410196517
Epoch: 28| Step: 7
Training loss: 2.6764078339418313
Validation loss: 2.151682221522032
Epoch: 28| Step: 8
Training loss: 2.1650044838944797
Validation loss: 2.109363216928396
Epoch: 28| Step: 9
Training loss: 2.662642472444559
Validation loss: 2.1008081094624522
Epoch: 29| Step: 0
Training loss: 2.4641910420273154
Validation loss: 2.1227340248576905
Epoch: 29| Step: 1
Training loss: 2.9578116230023794
Validation loss: 2.0765108202430116
Epoch: 29| Step: 2
Training loss: 2.645795646659401
Validation loss: 2.0692881441324995
Epoch: 29| Step: 3
Training loss: 2.4975127244840936
Validation loss: 2.0997669212466827
Epoch: 29| Step: 4
Training loss: 2.737430282471428
Validation loss: 2.1258758141235337
Epoch: 29| Step: 5
Training loss: 2.632842292956663
Validation loss: 2.131011846872017
Epoch: 29| Step: 6
Training loss: 2.89233859021498
Validation loss: 2.1034467913749024
Epoch: 29| Step: 7
Training loss: 2.567811717543588
Validation loss: 2.0761187661556173
Epoch: 29| Step: 8
Training loss: 2.297959882434168
Validation loss: 2.069743595979699
Epoch: 29| Step: 9
Training loss: 2.584031431154587
Validation loss: 2.0870844346187085
Epoch: 30| Step: 0
Training loss: 2.278028538968076
Validation loss: 2.0869424922518025
Epoch: 30| Step: 1
Training loss: 2.550890138881106
Validation loss: 2.127175843060635
Epoch: 30| Step: 2
Training loss: 2.9573408440969504
Validation loss: 2.0935227421960896
Epoch: 30| Step: 3
Training loss: 2.9070748419954535
Validation loss: 2.1130793008389865
Epoch: 30| Step: 4
Training loss: 2.7799792869399997
Validation loss: 2.108127015080521
Epoch: 30| Step: 5
Training loss: 2.6179377604955336
Validation loss: 2.141602782791206
Epoch: 30| Step: 6
Training loss: 2.7365964748411997
Validation loss: 2.061802255552581
Epoch: 30| Step: 7
Training loss: 2.2715586865800206
Validation loss: 2.0965142275017232
Epoch: 30| Step: 8
Training loss: 2.724527030985749
Validation loss: 2.0722226862067865
Epoch: 30| Step: 9
Training loss: 2.4205982411444777
Validation loss: 2.135780415722869
