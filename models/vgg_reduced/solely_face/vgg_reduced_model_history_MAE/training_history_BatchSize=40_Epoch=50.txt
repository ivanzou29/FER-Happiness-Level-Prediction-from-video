Epoch: 1| Step: 0
Training loss: 5.902026176452637
Validation loss: 5.726911703745524
Epoch: 1| Step: 1
Training loss: 6.406622886657715
Validation loss: 5.704123179117839
Epoch: 1| Step: 2
Training loss: 6.324528694152832
Validation loss: 5.42702849706014
Epoch: 1| Step: 3
Training loss: 5.964812278747559
Validation loss: 5.409521738688151
Epoch: 1| Step: 4
Training loss: 5.121789932250977
Validation loss: 5.145956834157308
Epoch: 1| Step: 5
Training loss: 4.846189975738525
Validation loss: 5.32952340443929
Epoch: 1| Step: 6
Training loss: 4.220791339874268
Validation loss: 4.841624577840169
Epoch: 1| Step: 7
Training loss: 4.863002777099609
Validation loss: 4.946336269378662
Epoch: 2| Step: 0
Training loss: 4.9817914962768555
Validation loss: 4.909768263498942
Epoch: 2| Step: 1
Training loss: 3.84032940864563
Validation loss: 4.830911636352539
Epoch: 2| Step: 2
Training loss: 5.192870140075684
Validation loss: 4.85038963953654
Epoch: 2| Step: 3
Training loss: 5.495980262756348
Validation loss: 4.8047553698221845
Epoch: 2| Step: 4
Training loss: 4.942859649658203
Validation loss: 4.825196584065755
Epoch: 2| Step: 5
Training loss: 4.678171634674072
Validation loss: 4.664577007293701
Epoch: 2| Step: 6
Training loss: 4.979160785675049
Validation loss: 4.601258913675944
Epoch: 2| Step: 7
Training loss: 5.251357078552246
Validation loss: 4.691492875417073
Epoch: 3| Step: 0
Training loss: 4.240837097167969
Validation loss: 4.724421342213948
Epoch: 3| Step: 1
Training loss: 4.398207664489746
Validation loss: 4.764022032419841
Epoch: 3| Step: 2
Training loss: 5.616648197174072
Validation loss: 4.848837852478027
Epoch: 3| Step: 3
Training loss: 4.324592113494873
Validation loss: 4.631858825683594
Epoch: 3| Step: 4
Training loss: 5.07198429107666
Validation loss: 4.669484297434489
Epoch: 3| Step: 5
Training loss: 5.179078102111816
Validation loss: 4.614846547444661
Epoch: 3| Step: 6
Training loss: 5.24784517288208
Validation loss: 4.71057669321696
Epoch: 3| Step: 7
Training loss: 4.523036956787109
Validation loss: 4.643037001291911
Epoch: 4| Step: 0
Training loss: 4.563991069793701
Validation loss: 4.527647813161214
Epoch: 4| Step: 1
Training loss: 4.599982738494873
Validation loss: 4.563139915466309
Epoch: 4| Step: 2
Training loss: 4.583899021148682
Validation loss: 4.47185214360555
Epoch: 4| Step: 3
Training loss: 4.865059852600098
Validation loss: 4.495574474334717
Epoch: 4| Step: 4
Training loss: 4.981573104858398
Validation loss: 4.4093038241068525
Epoch: 4| Step: 5
Training loss: 4.912295818328857
Validation loss: 4.494966348012288
Epoch: 4| Step: 6
Training loss: 3.923381805419922
Validation loss: 4.377428372701009
Epoch: 4| Step: 7
Training loss: 4.5200934410095215
Validation loss: 4.299071153004964
Epoch: 5| Step: 0
Training loss: 4.445806980133057
Validation loss: 4.309292793273926
Epoch: 5| Step: 1
Training loss: 4.961045265197754
Validation loss: 4.179492076237996
Epoch: 5| Step: 2
Training loss: 4.1686224937438965
Validation loss: 4.131272554397583
Epoch: 5| Step: 3
Training loss: 4.78537130355835
Validation loss: 4.167775392532349
Epoch: 5| Step: 4
Training loss: 4.868785858154297
Validation loss: 4.2132571538289385
Epoch: 5| Step: 5
Training loss: 3.895813465118408
Validation loss: 4.200344244639079
Epoch: 5| Step: 6
Training loss: 4.023221492767334
Validation loss: 4.206128756205241
Epoch: 5| Step: 7
Training loss: 4.141244411468506
Validation loss: 4.0065867106119795
Epoch: 6| Step: 0
Training loss: 3.8426170349121094
Validation loss: 4.0369172890981035
Epoch: 6| Step: 1
Training loss: 4.358257293701172
Validation loss: 3.9317843119303384
Epoch: 6| Step: 2
Training loss: 4.787827014923096
Validation loss: 3.9453110694885254
Epoch: 6| Step: 3
Training loss: 4.830934524536133
Validation loss: 4.044704914093018
Epoch: 6| Step: 4
Training loss: 3.9665141105651855
Validation loss: 4.004433631896973
Epoch: 6| Step: 5
Training loss: 3.670473575592041
Validation loss: 4.074099938074748
Epoch: 6| Step: 6
Training loss: 4.043562889099121
Validation loss: 3.98891814549764
Epoch: 6| Step: 7
Training loss: 4.221426486968994
Validation loss: 3.934682607650757
Epoch: 7| Step: 0
Training loss: 4.370415210723877
Validation loss: 3.770905017852783
Epoch: 7| Step: 1
Training loss: 3.5630905628204346
Validation loss: 3.8725295066833496
Epoch: 7| Step: 2
Training loss: 4.286844253540039
Validation loss: 3.8156278928120932
Epoch: 7| Step: 3
Training loss: 4.363819122314453
Validation loss: 3.8200921217600503
Epoch: 7| Step: 4
Training loss: 3.9318175315856934
Validation loss: 3.768256902694702
Epoch: 7| Step: 5
Training loss: 4.4645280838012695
Validation loss: 3.6669236024220786
Epoch: 7| Step: 6
Training loss: 3.5177204608917236
Validation loss: 3.7653891245524087
Epoch: 7| Step: 7
Training loss: 3.7409005165100098
Validation loss: 3.6422313849131265
Epoch: 8| Step: 0
Training loss: 4.253619194030762
Validation loss: 3.604932943979899
Epoch: 8| Step: 1
Training loss: 4.372284889221191
Validation loss: 3.5668989022572837
Epoch: 8| Step: 2
Training loss: 3.8613076210021973
Validation loss: 3.6113454500834146
Epoch: 8| Step: 3
Training loss: 2.636753559112549
Validation loss: 3.559889316558838
Epoch: 8| Step: 4
Training loss: 3.664640426635742
Validation loss: 3.570401668548584
Epoch: 8| Step: 5
Training loss: 3.8622817993164062
Validation loss: 3.5159453550974527
Epoch: 8| Step: 6
Training loss: 3.8752105236053467
Validation loss: 3.6344474951426187
Epoch: 8| Step: 7
Training loss: 4.3498125076293945
Validation loss: 3.4798429012298584
Epoch: 9| Step: 0
Training loss: 3.4849705696105957
Validation loss: 3.583194096883138
Epoch: 9| Step: 1
Training loss: 3.60351300239563
Validation loss: 3.393864552179972
Epoch: 9| Step: 2
Training loss: 3.4828925132751465
Validation loss: 3.442305008570353
Epoch: 9| Step: 3
Training loss: 3.24737548828125
Validation loss: 3.384598890940348
Epoch: 9| Step: 4
Training loss: 3.879667282104492
Validation loss: 3.3421903451283774
Epoch: 9| Step: 5
Training loss: 3.8426284790039062
Validation loss: 3.3769823710123696
Epoch: 9| Step: 6
Training loss: 3.653820037841797
Validation loss: 3.333340644836426
Epoch: 9| Step: 7
Training loss: 4.445507049560547
Validation loss: 3.3379135131835938
Epoch: 10| Step: 0
Training loss: 3.6162381172180176
Validation loss: 3.2251522541046143
Epoch: 10| Step: 1
Training loss: 3.5412769317626953
Validation loss: 3.2731892267862954
Epoch: 10| Step: 2
Training loss: 3.857980728149414
Validation loss: 3.362653652826945
Epoch: 10| Step: 3
Training loss: 3.772256851196289
Validation loss: 3.1737349033355713
Epoch: 10| Step: 4
Training loss: 3.3575026988983154
Validation loss: 3.2065948645273843
Epoch: 10| Step: 5
Training loss: 3.5538229942321777
Validation loss: 3.3075031439463296
Epoch: 10| Step: 6
Training loss: 3.3973865509033203
Validation loss: 3.0684218406677246
Epoch: 10| Step: 7
Training loss: 3.308289051055908
Validation loss: 3.147538105646769
Epoch: 11| Step: 0
Training loss: 3.1738522052764893
Validation loss: 3.004711627960205
Epoch: 11| Step: 1
Training loss: 3.112222194671631
Validation loss: 3.0129321416219077
Epoch: 11| Step: 2
Training loss: 3.148346424102783
Validation loss: 2.9806506633758545
Epoch: 11| Step: 3
Training loss: 4.279550075531006
Validation loss: 3.043734391530355
Epoch: 11| Step: 4
Training loss: 3.087146282196045
Validation loss: 2.8526262442270913
Epoch: 11| Step: 5
Training loss: 3.1898245811462402
Validation loss: 3.0922951698303223
Epoch: 11| Step: 6
Training loss: 4.056443214416504
Validation loss: 2.9985390504201255
Epoch: 11| Step: 7
Training loss: 3.245386838912964
Validation loss: 3.0012282530466714
Epoch: 12| Step: 0
Training loss: 2.791351795196533
Validation loss: 2.829810698827108
Epoch: 12| Step: 1
Training loss: 3.683427333831787
Validation loss: 2.878448247909546
Epoch: 12| Step: 2
Training loss: 3.2526326179504395
Validation loss: 2.8443603515625
Epoch: 12| Step: 3
Training loss: 3.593998670578003
Validation loss: 2.8725104331970215
Epoch: 12| Step: 4
Training loss: 2.953895330429077
Validation loss: 2.7279940446217856
Epoch: 12| Step: 5
Training loss: 3.2866454124450684
Validation loss: 2.886314789454142
Epoch: 12| Step: 6
Training loss: 3.2795186042785645
Validation loss: 2.9468581676483154
Epoch: 12| Step: 7
Training loss: 3.465208053588867
Validation loss: 2.7948609987894693
Epoch: 13| Step: 0
Training loss: 3.3179733753204346
Validation loss: 2.818633715311686
Epoch: 13| Step: 1
Training loss: 3.3657443523406982
Validation loss: 2.815159638722738
Epoch: 13| Step: 2
Training loss: 3.331792116165161
Validation loss: 2.7238765557607016
Epoch: 13| Step: 3
Training loss: 3.6951041221618652
Validation loss: 2.647905190785726
Epoch: 13| Step: 4
Training loss: 3.1589789390563965
Validation loss: 2.725376923878988
Epoch: 13| Step: 5
Training loss: 2.8804092407226562
Validation loss: 2.75081467628479
Epoch: 13| Step: 6
Training loss: 3.11548113822937
Validation loss: 2.66678786277771
Epoch: 13| Step: 7
Training loss: 2.5564255714416504
Validation loss: 2.581244945526123
Epoch: 14| Step: 0
Training loss: 2.9843289852142334
Validation loss: 2.680877765019735
Epoch: 14| Step: 1
Training loss: 3.0404281616210938
Validation loss: 2.530313014984131
Epoch: 14| Step: 2
Training loss: 3.514669418334961
Validation loss: 2.5537259578704834
Epoch: 14| Step: 3
Training loss: 2.9850687980651855
Validation loss: 2.654555638631185
Epoch: 14| Step: 4
Training loss: 3.165256977081299
Validation loss: 2.572934627532959
Epoch: 14| Step: 5
Training loss: 2.94773530960083
Validation loss: 2.5984044075012207
Epoch: 14| Step: 6
Training loss: 2.9381625652313232
Validation loss: 2.4948456287384033
Epoch: 14| Step: 7
Training loss: 3.054990291595459
Validation loss: 2.511378844579061
Epoch: 15| Step: 0
Training loss: 2.8037590980529785
Validation loss: 2.4967904090881348
Epoch: 15| Step: 1
Training loss: 3.16701078414917
Validation loss: 2.6228315035502114
Epoch: 15| Step: 2
Training loss: 2.7246649265289307
Validation loss: 2.5269413789113364
Epoch: 15| Step: 3
Training loss: 3.3773512840270996
Validation loss: 2.4905855655670166
Epoch: 15| Step: 4
Training loss: 3.443242311477661
Validation loss: 2.5506743590037027
Epoch: 15| Step: 5
Training loss: 2.5773253440856934
Validation loss: 2.4486626784006753
Epoch: 15| Step: 6
Training loss: 3.0352699756622314
Validation loss: 2.492060581843058
Epoch: 15| Step: 7
Training loss: 2.80295467376709
Validation loss: 2.511841058731079
Epoch: 16| Step: 0
Training loss: 3.1052825450897217
Validation loss: 2.4032465616861978
Epoch: 16| Step: 1
Training loss: 2.740122079849243
Validation loss: 2.3713926474253335
Epoch: 16| Step: 2
Training loss: 3.2949695587158203
Validation loss: 2.397296984990438
Epoch: 16| Step: 3
Training loss: 2.8131256103515625
Validation loss: 2.3614888191223145
Epoch: 16| Step: 4
Training loss: 2.7874648571014404
Validation loss: 2.361629327138265
Epoch: 16| Step: 5
Training loss: 2.998094081878662
Validation loss: 2.2979222933451333
Epoch: 16| Step: 6
Training loss: 2.9302151203155518
Validation loss: 2.4428853591283164
Epoch: 16| Step: 7
Training loss: 2.6310367584228516
Validation loss: 2.3621833324432373
Epoch: 17| Step: 0
Training loss: 2.7468972206115723
Validation loss: 2.319033940633138
Epoch: 17| Step: 1
Training loss: 3.049586772918701
Validation loss: 2.320917288462321
Epoch: 17| Step: 2
Training loss: 2.71095871925354
Validation loss: 2.3393534819285073
Epoch: 17| Step: 3
Training loss: 2.727949619293213
Validation loss: 2.3182607094446817
Epoch: 17| Step: 4
Training loss: 2.7649588584899902
Validation loss: 2.2613770167032876
Epoch: 17| Step: 5
Training loss: 2.8336150646209717
Validation loss: 2.235422690709432
Epoch: 17| Step: 6
Training loss: 2.932241916656494
Validation loss: 2.290762980779012
Epoch: 17| Step: 7
Training loss: 2.9109485149383545
Validation loss: 2.3251154820124307
Epoch: 18| Step: 0
Training loss: 2.9748635292053223
Validation loss: 2.319221099217733
Epoch: 18| Step: 1
Training loss: 3.008855104446411
Validation loss: 2.2323792775472007
Epoch: 18| Step: 2
Training loss: 2.4491565227508545
Validation loss: 2.236687501271566
Epoch: 18| Step: 3
Training loss: 2.905735492706299
Validation loss: 2.2495411237080893
Epoch: 18| Step: 4
Training loss: 2.6989407539367676
Validation loss: 2.2586913108825684
Epoch: 18| Step: 5
Training loss: 2.853097677230835
Validation loss: 2.2065305709838867
Epoch: 18| Step: 6
Training loss: 2.6147549152374268
Validation loss: 2.2405880292256675
Epoch: 18| Step: 7
Training loss: 2.5749409198760986
Validation loss: 2.206607699394226
Epoch: 19| Step: 0
Training loss: 3.0021145343780518
Validation loss: 2.1587812105814614
Epoch: 19| Step: 1
Training loss: 2.519071578979492
Validation loss: 2.2189129988352456
Epoch: 19| Step: 2
Training loss: 2.504173755645752
Validation loss: 2.252184788386027
Epoch: 19| Step: 3
Training loss: 2.52213716506958
Validation loss: 2.148836533228556
Epoch: 19| Step: 4
Training loss: 3.2801640033721924
Validation loss: 2.0709524552027383
Epoch: 19| Step: 5
Training loss: 2.701436996459961
Validation loss: 2.1379504998524985
Epoch: 19| Step: 6
Training loss: 2.160459280014038
Validation loss: 2.2729249795277915
Epoch: 19| Step: 7
Training loss: 2.8406238555908203
Validation loss: 2.174790541330973
Epoch: 20| Step: 0
Training loss: 2.744596004486084
Validation loss: 2.136618137359619
Epoch: 20| Step: 1
Training loss: 3.0585498809814453
Validation loss: 2.1118834813435874
Epoch: 20| Step: 2
Training loss: 2.7358202934265137
Validation loss: 2.026097297668457
Epoch: 20| Step: 3
Training loss: 2.4379396438598633
Validation loss: 2.1293481985727944
Epoch: 20| Step: 4
Training loss: 2.2515194416046143
Validation loss: 2.068708817164103
Epoch: 20| Step: 5
Training loss: 2.6397318840026855
Validation loss: 2.131101051966349
Epoch: 20| Step: 6
Training loss: 2.352658748626709
Validation loss: 2.0497090816497803
Epoch: 20| Step: 7
Training loss: 2.731456756591797
Validation loss: 2.054639220237732
Epoch: 21| Step: 0
Training loss: 2.351088047027588
Validation loss: 1.9981489578882854
Epoch: 21| Step: 1
Training loss: 2.4674739837646484
Validation loss: 2.0466356674830117
Epoch: 21| Step: 2
Training loss: 2.6537270545959473
Validation loss: 2.082453966140747
Epoch: 21| Step: 3
Training loss: 2.2116539478302
Validation loss: 2.1167681217193604
Epoch: 21| Step: 4
Training loss: 2.785285472869873
Validation loss: 2.036529024442037
Epoch: 21| Step: 5
Training loss: 2.7048511505126953
Validation loss: 2.017845630645752
Epoch: 21| Step: 6
Training loss: 2.5096983909606934
Validation loss: 2.005430897076925
Epoch: 21| Step: 7
Training loss: 2.7212021350860596
Validation loss: 1.9510621627171834
Epoch: 22| Step: 0
Training loss: 2.566542863845825
Validation loss: 1.9418617089589436
Epoch: 22| Step: 1
Training loss: 2.894770383834839
Validation loss: 2.0171812375386557
Epoch: 22| Step: 2
Training loss: 2.2694506645202637
Validation loss: 1.9426114161809285
Epoch: 22| Step: 3
Training loss: 2.3848013877868652
Validation loss: 1.9379571278889973
Epoch: 22| Step: 4
Training loss: 2.279052972793579
Validation loss: 1.988765796025594
Epoch: 22| Step: 5
Training loss: 2.6702816486358643
Validation loss: 1.9342638651529949
Epoch: 22| Step: 6
Training loss: 2.5140388011932373
Validation loss: 1.9515389601389568
Epoch: 22| Step: 7
Training loss: 2.3445663452148438
Validation loss: 1.923790176709493
Epoch: 23| Step: 0
Training loss: 2.169628620147705
Validation loss: 1.9768646955490112
Epoch: 23| Step: 1
Training loss: 2.466615676879883
Validation loss: 1.9971049229303997
Epoch: 23| Step: 2
Training loss: 2.7290077209472656
Validation loss: 1.9359025955200195
Epoch: 23| Step: 3
Training loss: 2.3617024421691895
Validation loss: 1.8355186780293782
Epoch: 23| Step: 4
Training loss: 2.5344021320343018
Validation loss: 1.9319020907084148
Epoch: 23| Step: 5
Training loss: 2.45570707321167
Validation loss: 1.9066392580668132
Epoch: 23| Step: 6
Training loss: 2.236280918121338
Validation loss: 1.8596351146697998
Epoch: 23| Step: 7
Training loss: 2.4584803581237793
Validation loss: 1.9332990248998005
Epoch: 24| Step: 0
Training loss: 2.223670482635498
Validation loss: 1.7964231967926025
Epoch: 24| Step: 1
Training loss: 2.3002638816833496
Validation loss: 1.8502417008082073
Epoch: 24| Step: 2
Training loss: 2.1765811443328857
Validation loss: 1.90039857228597
Epoch: 24| Step: 3
Training loss: 2.3914952278137207
Validation loss: 1.8072600364685059
Epoch: 24| Step: 4
Training loss: 2.284789562225342
Validation loss: 1.8931860129038494
Epoch: 24| Step: 5
Training loss: 2.608646869659424
Validation loss: 1.8735956350962322
Epoch: 24| Step: 6
Training loss: 2.6539103984832764
Validation loss: 1.8036775588989258
Epoch: 24| Step: 7
Training loss: 2.306643486022949
Validation loss: 1.8517629305521648
Epoch: 25| Step: 0
Training loss: 2.3620219230651855
Validation loss: 1.8747747739156086
Epoch: 25| Step: 1
Training loss: 2.2274699211120605
Validation loss: 1.7819178501764934
Epoch: 25| Step: 2
Training loss: 2.290268659591675
Validation loss: 1.7700560490290325
Epoch: 25| Step: 3
Training loss: 2.4214470386505127
Validation loss: 1.7735074758529663
Epoch: 25| Step: 4
Training loss: 2.458000659942627
Validation loss: 1.807501196861267
Epoch: 25| Step: 5
Training loss: 2.472564220428467
Validation loss: 1.8164263566335042
Epoch: 25| Step: 6
Training loss: 1.9288780689239502
Validation loss: 1.7625195582707722
Epoch: 25| Step: 7
Training loss: 2.4900143146514893
Validation loss: 1.7981520493825276
Epoch: 26| Step: 0
Training loss: 2.0446243286132812
Validation loss: 1.7659464279810588
Epoch: 26| Step: 1
Training loss: 2.6393308639526367
Validation loss: 1.7486620744069417
Epoch: 26| Step: 2
Training loss: 2.405155897140503
Validation loss: 1.7215829292933147
Epoch: 26| Step: 3
Training loss: 2.233950138092041
Validation loss: 1.7428876558939617
Epoch: 26| Step: 4
Training loss: 2.3260624408721924
Validation loss: 1.7972499132156372
Epoch: 26| Step: 5
Training loss: 1.882202386856079
Validation loss: 1.7679497003555298
Epoch: 26| Step: 6
Training loss: 2.3866517543792725
Validation loss: 1.7528018554051716
Epoch: 26| Step: 7
Training loss: 2.4765563011169434
Validation loss: 1.6565562884012859
Epoch: 27| Step: 0
Training loss: 2.211758852005005
Validation loss: 1.7925151586532593
Epoch: 27| Step: 1
Training loss: 2.6750733852386475
Validation loss: 1.7253974278767903
Epoch: 27| Step: 2
Training loss: 2.2532947063446045
Validation loss: 1.7253111600875854
Epoch: 27| Step: 3
Training loss: 2.2190349102020264
Validation loss: 1.732777714729309
Epoch: 27| Step: 4
Training loss: 2.3990795612335205
Validation loss: 1.7547236283620198
Epoch: 27| Step: 5
Training loss: 2.2112255096435547
Validation loss: 1.7799206574757893
Epoch: 27| Step: 6
Training loss: 2.1009886264801025
Validation loss: 1.6987801790237427
Epoch: 27| Step: 7
Training loss: 2.164186954498291
Validation loss: 1.7465562025705974
Epoch: 28| Step: 0
Training loss: 2.4570870399475098
Validation loss: 1.684173822402954
Epoch: 28| Step: 1
Training loss: 2.490464687347412
Validation loss: 1.7387269735336304
Epoch: 28| Step: 2
Training loss: 2.315476179122925
Validation loss: 1.680317481358846
Epoch: 28| Step: 3
Training loss: 2.5835251808166504
Validation loss: 1.65138844648997
Epoch: 28| Step: 4
Training loss: 2.0694491863250732
Validation loss: 1.7655874490737915
Epoch: 28| Step: 5
Training loss: 1.96743905544281
Validation loss: 1.7155691782633464
Epoch: 28| Step: 6
Training loss: 2.284259557723999
Validation loss: 1.700107216835022
Epoch: 28| Step: 7
Training loss: 1.934861421585083
Validation loss: 1.687708854675293
Epoch: 29| Step: 0
Training loss: 2.322279453277588
Validation loss: 1.672279675801595
Epoch: 29| Step: 1
Training loss: 2.3503434658050537
Validation loss: 1.6856871843338013
Epoch: 29| Step: 2
Training loss: 2.4948673248291016
Validation loss: 1.6465781927108765
Epoch: 29| Step: 3
Training loss: 1.8870689868927002
Validation loss: 1.7491095463434856
Epoch: 29| Step: 4
Training loss: 2.4175000190734863
Validation loss: 1.6217902898788452
Epoch: 29| Step: 5
Training loss: 2.3069100379943848
Validation loss: 1.6565579970677693
Epoch: 29| Step: 6
Training loss: 2.1380791664123535
Validation loss: 1.6929299434026082
Epoch: 29| Step: 7
Training loss: 2.10383677482605
Validation loss: 1.6663943926493328
Epoch: 30| Step: 0
Training loss: 2.4572436809539795
Validation loss: 1.6373292605082195
Epoch: 30| Step: 1
Training loss: 2.217820167541504
Validation loss: 1.6675533056259155
Epoch: 30| Step: 2
Training loss: 2.4744577407836914
Validation loss: 1.6648695071538289
Epoch: 30| Step: 3
Training loss: 2.158780336380005
Validation loss: 1.5941667556762695
Epoch: 30| Step: 4
Training loss: 2.0350000858306885
Validation loss: 1.7186119953791301
Epoch: 30| Step: 5
Training loss: 2.2823386192321777
Validation loss: 1.6890215476353962
Epoch: 30| Step: 6
Training loss: 2.0899481773376465
Validation loss: 1.6916494766871135
Epoch: 30| Step: 7
Training loss: 2.264458656311035
Validation loss: 1.7258333762486775
Epoch: 31| Step: 0
Training loss: 2.442499876022339
Validation loss: 1.6609774827957153
Epoch: 31| Step: 1
Training loss: 2.225511074066162
Validation loss: 1.677992622057597
Epoch: 31| Step: 2
Training loss: 2.0808939933776855
Validation loss: 1.6234326759974163
Epoch: 31| Step: 3
Training loss: 2.1476356983184814
Validation loss: 1.6067344745000203
Epoch: 31| Step: 4
Training loss: 2.6571693420410156
Validation loss: 1.6658333539962769
Epoch: 31| Step: 5
Training loss: 1.8374077081680298
Validation loss: 1.7397325038909912
Epoch: 31| Step: 6
Training loss: 2.116239547729492
Validation loss: 1.7161914904912312
Epoch: 31| Step: 7
Training loss: 2.4574999809265137
Validation loss: 1.719332496325175
Epoch: 32| Step: 0
Training loss: 2.040618419647217
Validation loss: 1.7029210329055786
Epoch: 32| Step: 1
Training loss: 2.2513606548309326
Validation loss: 1.6825000445048015
Epoch: 32| Step: 2
Training loss: 2.262338161468506
Validation loss: 1.6871103048324585
Epoch: 32| Step: 3
Training loss: 1.9805599451065063
Validation loss: 1.7013433774312336
Epoch: 32| Step: 4
Training loss: 2.130816698074341
Validation loss: 1.6541666984558105
Epoch: 32| Step: 5
Training loss: 2.313004732131958
Validation loss: 1.636276642481486
Epoch: 32| Step: 6
Training loss: 2.413635015487671
Validation loss: 1.635189175605774
Epoch: 32| Step: 7
Training loss: 2.557720899581909
Validation loss: 1.647197683652242
Epoch: 33| Step: 0
Training loss: 2.4185891151428223
Validation loss: 1.7434240976969402
Epoch: 33| Step: 1
Training loss: 2.264604091644287
Validation loss: 1.62831449508667
Epoch: 33| Step: 2
Training loss: 2.3397231101989746
Validation loss: 1.6825923124949138
Epoch: 33| Step: 3
Training loss: 2.015434980392456
Validation loss: 1.6495291392008464
Epoch: 33| Step: 4
Training loss: 2.068962812423706
Validation loss: 1.754024823506673
Epoch: 33| Step: 5
Training loss: 2.1164982318878174
Validation loss: 1.6731692949930828
Epoch: 33| Step: 6
Training loss: 2.3054981231689453
Validation loss: 1.7190570433934529
Epoch: 33| Step: 7
Training loss: 2.415142297744751
Validation loss: 1.6664520104726155
Epoch: 34| Step: 0
Training loss: 2.1247429847717285
Validation loss: 1.7080466747283936
Epoch: 34| Step: 1
Training loss: 2.673464775085449
Validation loss: 1.7177626291910808
Epoch: 34| Step: 2
Training loss: 2.0967049598693848
Validation loss: 1.7062307993570964
Epoch: 34| Step: 3
Training loss: 2.113546848297119
Validation loss: 1.62932288646698
Epoch: 34| Step: 4
Training loss: 2.1213932037353516
Validation loss: 1.7370222012201946
Epoch: 34| Step: 5
Training loss: 2.441021680831909
Validation loss: 1.709355115890503
Epoch: 34| Step: 6
Training loss: 2.192722797393799
Validation loss: 1.6385830640792847
Epoch: 34| Step: 7
Training loss: 2.177500009536743
Validation loss: 1.6504552364349365
Epoch: 35| Step: 0
Training loss: 2.4851632118225098
Validation loss: 1.6367754141489665
Epoch: 35| Step: 1
Training loss: 2.3438632488250732
Validation loss: 1.6988633473714192
Epoch: 35| Step: 2
Training loss: 2.220256805419922
Validation loss: 1.6625540256500244
Epoch: 35| Step: 3
Training loss: 1.8450000286102295
Validation loss: 1.693486491839091
Epoch: 35| Step: 4
Training loss: 2.2570888996124268
Validation loss: 1.6290582815806072
Epoch: 35| Step: 5
Training loss: 2.285292387008667
Validation loss: 1.6501191854476929
Epoch: 35| Step: 6
Training loss: 2.180459976196289
Validation loss: 1.6931800444920857
Epoch: 35| Step: 7
Training loss: 2.3239870071411133
Validation loss: 1.723807414372762
Epoch: 36| Step: 0
Training loss: 2.43941068649292
Validation loss: 1.62507430712382
Epoch: 36| Step: 1
Training loss: 1.9232479333877563
Validation loss: 1.5593304634094238
Epoch: 36| Step: 2
Training loss: 2.070000171661377
Validation loss: 1.6216717958450317
Epoch: 36| Step: 3
Training loss: 2.3015847206115723
Validation loss: 1.5923179388046265
Epoch: 36| Step: 4
Training loss: 2.3082289695739746
Validation loss: 1.6166325410207112
Epoch: 36| Step: 5
Training loss: 2.330526113510132
Validation loss: 1.5821929375330608
Epoch: 36| Step: 6
Training loss: 2.3287291526794434
Validation loss: 1.7035173177719116
Epoch: 36| Step: 7
Training loss: 2.239428758621216
Validation loss: 1.707880973815918
Epoch: 37| Step: 0
Training loss: 2.2788524627685547
Validation loss: 1.7187841733296711
Epoch: 37| Step: 1
Training loss: 2.558159828186035
Validation loss: 1.701793630917867
Epoch: 37| Step: 2
Training loss: 2.42484974861145
Validation loss: 1.6875500281651814
Epoch: 37| Step: 3
Training loss: 2.225625514984131
Validation loss: 1.7293755213419597
Epoch: 37| Step: 4
Training loss: 2.0737109184265137
Validation loss: 1.6631577014923096
Epoch: 37| Step: 5
Training loss: 2.1738803386688232
Validation loss: 1.7055468559265137
Epoch: 37| Step: 6
Training loss: 2.0950000286102295
Validation loss: 1.7262238264083862
Epoch: 37| Step: 7
Training loss: 2.1110706329345703
Validation loss: 1.8249411980311077
Epoch: 38| Step: 0
Training loss: 2.1395034790039062
Validation loss: 1.7135103543599446
Epoch: 38| Step: 1
Training loss: 2.2434513568878174
Validation loss: 1.7650403181711833
Epoch: 38| Step: 2
Training loss: 2.0970711708068848
Validation loss: 1.6428804794947307
Epoch: 38| Step: 3
Training loss: 2.3641018867492676
Validation loss: 1.649898846944173
Epoch: 38| Step: 4
Training loss: 2.5984089374542236
Validation loss: 1.7067574262619019
Epoch: 38| Step: 5
Training loss: 1.9778152704238892
Validation loss: 1.599992831548055
Epoch: 38| Step: 6
Training loss: 2.188096523284912
Validation loss: 1.6684707403182983
Epoch: 38| Step: 7
Training loss: 2.3322458267211914
Validation loss: 1.672400673230489
Epoch: 39| Step: 0
Training loss: 2.284770965576172
Validation loss: 1.723479191462199
Epoch: 39| Step: 1
Training loss: 2.3545584678649902
Validation loss: 1.6467643578847249
Epoch: 39| Step: 2
Training loss: 2.204516649246216
Validation loss: 1.6792747577031453
Epoch: 39| Step: 3
Training loss: 2.2341315746307373
Validation loss: 1.691631515820821
Epoch: 39| Step: 4
Training loss: 2.338627338409424
Validation loss: 1.736873706181844
Epoch: 39| Step: 5
Training loss: 2.3562307357788086
Validation loss: 1.6426495711008708
Epoch: 39| Step: 6
Training loss: 2.328295946121216
Validation loss: 1.71450674533844
Epoch: 39| Step: 7
Training loss: 1.840358018875122
Validation loss: 1.7066646416982014
Epoch: 40| Step: 0
Training loss: 1.9487701654434204
Validation loss: 1.7450135548909504
Epoch: 40| Step: 1
Training loss: 2.6878199577331543
Validation loss: 1.721646785736084
Epoch: 40| Step: 2
Training loss: 2.4128165245056152
Validation loss: 1.7330056031545003
Epoch: 40| Step: 3
Training loss: 2.1050000190734863
Validation loss: 1.6831694841384888
Epoch: 40| Step: 4
Training loss: 2.0288665294647217
Validation loss: 1.7478610277175903
Epoch: 40| Step: 5
Training loss: 2.3409829139709473
Validation loss: 1.715396483739217
Epoch: 40| Step: 6
Training loss: 2.122823715209961
Validation loss: 1.5948625405629475
Epoch: 40| Step: 7
Training loss: 2.2934157848358154
Validation loss: 1.7167876561482747
Epoch: 41| Step: 0
Training loss: 2.2329893112182617
Validation loss: 1.6916845639546711
Epoch: 41| Step: 1
Training loss: 2.2874999046325684
Validation loss: 1.7185781399408977
Epoch: 41| Step: 2
Training loss: 2.2375845909118652
Validation loss: 1.7273024320602417
Epoch: 41| Step: 3
Training loss: 2.012493848800659
Validation loss: 1.6724965174992878
Epoch: 41| Step: 4
Training loss: 2.1600000858306885
Validation loss: 1.7050189971923828
Epoch: 41| Step: 5
Training loss: 2.1349716186523438
Validation loss: 1.6983712514241536
Epoch: 41| Step: 6
Training loss: 2.570056200027466
Validation loss: 1.571039080619812
Epoch: 41| Step: 7
Training loss: 2.304867744445801
Validation loss: 1.7159656683603923
Epoch: 42| Step: 0
Training loss: 2.3376049995422363
Validation loss: 1.6269116799036663
Epoch: 42| Step: 1
Training loss: 2.592625141143799
Validation loss: 1.7143752972284954
Epoch: 42| Step: 2
Training loss: 2.4103851318359375
Validation loss: 1.7477567195892334
Epoch: 42| Step: 3
Training loss: 2.562241315841675
Validation loss: 1.7068392038345337
Epoch: 42| Step: 4
Training loss: 2.107686758041382
Validation loss: 1.720062216122945
Epoch: 42| Step: 5
Training loss: 1.999791145324707
Validation loss: 1.7484958569208782
Epoch: 42| Step: 6
Training loss: 1.8124065399169922
Validation loss: 1.670186956723531
Epoch: 42| Step: 7
Training loss: 2.1173698902130127
Validation loss: 1.7368400891621907
Epoch: 43| Step: 0
Training loss: 2.3117873668670654
Validation loss: 1.6262489159901936
Epoch: 43| Step: 1
Training loss: 2.0091919898986816
Validation loss: 1.7016793489456177
Epoch: 43| Step: 2
Training loss: 2.150569200515747
Validation loss: 1.5907591581344604
Epoch: 43| Step: 3
Training loss: 2.2730135917663574
Validation loss: 1.6433558464050293
Epoch: 43| Step: 4
Training loss: 2.459195613861084
Validation loss: 1.6878352165222168
Epoch: 43| Step: 5
Training loss: 2.384364366531372
Validation loss: 1.7120198408762615
Epoch: 43| Step: 6
Training loss: 1.5994651317596436
Validation loss: 1.6531238953272502
Epoch: 43| Step: 7
Training loss: 2.7531957626342773
Validation loss: 1.733427882194519
Epoch: 44| Step: 0
Training loss: 2.122109889984131
Validation loss: 1.7659101486206055
Epoch: 44| Step: 1
Training loss: 2.276772975921631
Validation loss: 1.643776535987854
Epoch: 44| Step: 2
Training loss: 2.49664044380188
Validation loss: 1.6687893470128377
Epoch: 44| Step: 3
Training loss: 2.2108967304229736
Validation loss: 1.6943796873092651
Epoch: 44| Step: 4
Training loss: 2.2170653343200684
Validation loss: 1.752390702565511
Epoch: 44| Step: 5
Training loss: 2.3104374408721924
Validation loss: 1.660874565442403
Epoch: 44| Step: 6
Training loss: 2.0649540424346924
Validation loss: 1.7259900172551472
Epoch: 44| Step: 7
Training loss: 2.241011142730713
Validation loss: 1.668847958246867
Epoch: 45| Step: 0
Training loss: 2.474452257156372
Validation loss: 1.7083096504211426
Epoch: 45| Step: 1
Training loss: 2.711202383041382
Validation loss: 1.6503690481185913
Epoch: 45| Step: 2
Training loss: 2.4268550872802734
Validation loss: 1.683521827061971
Epoch: 45| Step: 3
Training loss: 2.050738573074341
Validation loss: 1.6568119128545125
Epoch: 45| Step: 4
Training loss: 2.3156826496124268
Validation loss: 1.6480802297592163
Epoch: 45| Step: 5
Training loss: 1.9513390064239502
Validation loss: 1.6221721569697063
Epoch: 45| Step: 6
Training loss: 1.898477554321289
Validation loss: 1.6604198217391968
Epoch: 45| Step: 7
Training loss: 2.1111557483673096
Validation loss: 1.7085889180501301
Epoch: 46| Step: 0
Training loss: 2.2079436779022217
Validation loss: 1.6606180270512898
Epoch: 46| Step: 1
Training loss: 2.1359543800354004
Validation loss: 1.6743636926015217
Epoch: 46| Step: 2
Training loss: 2.251765727996826
Validation loss: 1.7117659250895183
Epoch: 46| Step: 3
Training loss: 2.4755983352661133
Validation loss: 1.663169264793396
Epoch: 46| Step: 4
Training loss: 2.2170870304107666
Validation loss: 1.733058015505473
Epoch: 46| Step: 5
Training loss: 2.2321906089782715
Validation loss: 1.6794846455256145
Epoch: 46| Step: 6
Training loss: 2.2152788639068604
Validation loss: 1.7525915304819744
Epoch: 46| Step: 7
Training loss: 2.2048122882843018
Validation loss: 1.6981453498204548
Epoch: 47| Step: 0
Training loss: 2.291334629058838
Validation loss: 1.651052196820577
Epoch: 47| Step: 1
Training loss: 2.1050000190734863
Validation loss: 1.6940857966740925
Epoch: 47| Step: 2
Training loss: 1.9961334466934204
Validation loss: 1.618255615234375
Epoch: 47| Step: 3
Training loss: 2.3936829566955566
Validation loss: 1.6686383485794067
Epoch: 47| Step: 4
Training loss: 1.994349479675293
Validation loss: 1.7461416323979695
Epoch: 47| Step: 5
Training loss: 2.3624579906463623
Validation loss: 1.678186297416687
Epoch: 47| Step: 6
Training loss: 2.3136260509490967
Validation loss: 1.5947596629460652
Epoch: 47| Step: 7
Training loss: 2.4840035438537598
Validation loss: 1.6763227383295696
Epoch: 48| Step: 0
Training loss: 2.2983486652374268
Validation loss: 1.6780503590901692
Epoch: 48| Step: 1
Training loss: 2.4604430198669434
Validation loss: 1.6651583909988403
Epoch: 48| Step: 2
Training loss: 2.035090208053589
Validation loss: 1.6725903749465942
Epoch: 48| Step: 3
Training loss: 2.4432897567749023
Validation loss: 1.7305113871892293
Epoch: 48| Step: 4
Training loss: 2.3499999046325684
Validation loss: 1.7542489767074585
Epoch: 48| Step: 5
Training loss: 2.245861768722534
Validation loss: 1.6655887365341187
Epoch: 48| Step: 6
Training loss: 2.0299999713897705
Validation loss: 1.7307899395624797
Epoch: 48| Step: 7
Training loss: 2.081068992614746
Validation loss: 1.6159713665644329
Epoch: 49| Step: 0
Training loss: 2.62068247795105
Validation loss: 1.7646958033243816
Epoch: 49| Step: 1
Training loss: 2.1597366333007812
Validation loss: 1.6220940748850505
Epoch: 49| Step: 2
Training loss: 2.3400001525878906
Validation loss: 1.6291215817133586
Epoch: 49| Step: 3
Training loss: 2.087486982345581
Validation loss: 1.6491796573003132
Epoch: 49| Step: 4
Training loss: 1.6450001001358032
Validation loss: 1.6585957606633503
Epoch: 49| Step: 5
Training loss: 2.4391961097717285
Validation loss: 1.6710863908131917
Epoch: 49| Step: 6
Training loss: 2.527529239654541
Validation loss: 1.6897449493408203
Epoch: 49| Step: 7
Training loss: 2.119201183319092
Validation loss: 1.7143983443578084
Epoch: 50| Step: 0
Training loss: 2.3424999713897705
Validation loss: 1.6435964107513428
Epoch: 50| Step: 1
Training loss: 2.492500066757202
Validation loss: 1.6274964412053425
Epoch: 50| Step: 2
Training loss: 1.9733107089996338
Validation loss: 1.6619596083958943
Epoch: 50| Step: 3
Training loss: 2.0584890842437744
Validation loss: 1.6749038298924763
Epoch: 50| Step: 4
Training loss: 2.3089470863342285
Validation loss: 1.6878295342127483
Epoch: 50| Step: 5
Training loss: 2.040515422821045
Validation loss: 1.707843542098999
Epoch: 50| Step: 6
Training loss: 2.164466381072998
Validation loss: 1.7503557602564495
Epoch: 50| Step: 7
Training loss: 2.558199405670166
Validation loss: 1.6542328198750813
