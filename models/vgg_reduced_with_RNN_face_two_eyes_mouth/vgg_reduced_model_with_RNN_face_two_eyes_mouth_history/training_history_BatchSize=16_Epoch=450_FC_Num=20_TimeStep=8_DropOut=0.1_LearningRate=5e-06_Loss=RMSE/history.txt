Epoch: 1| Step: 0
Training loss: 6.392698963397314
Validation loss: 5.902645592300252

Epoch: 6| Step: 1
Training loss: 6.656231087671196
Validation loss: 5.900935370443807

Epoch: 6| Step: 2
Training loss: 5.609232186117226
Validation loss: 5.899288212141538

Epoch: 6| Step: 3
Training loss: 5.757946328583792
Validation loss: 5.897691934719917

Epoch: 6| Step: 4
Training loss: 6.055069922398644
Validation loss: 5.896142616741729

Epoch: 6| Step: 5
Training loss: 5.947001674664051
Validation loss: 5.894522675140798

Epoch: 6| Step: 6
Training loss: 5.808750050435765
Validation loss: 5.892964081667759

Epoch: 6| Step: 7
Training loss: 6.485318549574348
Validation loss: 5.89134510067397

Epoch: 6| Step: 8
Training loss: 5.509406628791089
Validation loss: 5.889663496395108

Epoch: 6| Step: 9
Training loss: 5.83086553780156
Validation loss: 5.887985056167103

Epoch: 6| Step: 10
Training loss: 5.731067171165432
Validation loss: 5.886255777231555

Epoch: 6| Step: 11
Training loss: 6.062034353090295
Validation loss: 5.884540197775303

Epoch: 6| Step: 12
Training loss: 5.970729639395659
Validation loss: 5.882633768839309

Epoch: 6| Step: 13
Training loss: 6.191272856902937
Validation loss: 5.8808327527194795

Epoch: 2| Step: 0
Training loss: 6.246148410388566
Validation loss: 5.878959998543059

Epoch: 6| Step: 1
Training loss: 6.021224311708879
Validation loss: 5.876889188855439

Epoch: 6| Step: 2
Training loss: 5.855434221671046
Validation loss: 5.87481429435553

Epoch: 6| Step: 3
Training loss: 6.36758949555377
Validation loss: 5.8727219405768745

Epoch: 6| Step: 4
Training loss: 4.931995268807845
Validation loss: 5.870444784128455

Epoch: 6| Step: 5
Training loss: 6.131974900504725
Validation loss: 5.86823164194771

Epoch: 6| Step: 6
Training loss: 5.114519894498476
Validation loss: 5.8658908269577115

Epoch: 6| Step: 7
Training loss: 6.617188652966251
Validation loss: 5.863495296101323

Epoch: 6| Step: 8
Training loss: 5.811502678740651
Validation loss: 5.860861817653255

Epoch: 6| Step: 9
Training loss: 6.692566280613899
Validation loss: 5.858234046901399

Epoch: 6| Step: 10
Training loss: 6.3227163300887925
Validation loss: 5.855485525482558

Epoch: 6| Step: 11
Training loss: 4.743102838452147
Validation loss: 5.852564428410184

Epoch: 6| Step: 12
Training loss: 6.302528285773
Validation loss: 5.849582610496297

Epoch: 6| Step: 13
Training loss: 6.163663631244884
Validation loss: 5.846395536303265

Epoch: 3| Step: 0
Training loss: 5.854530549420812
Validation loss: 5.8430811045311035

Epoch: 6| Step: 1
Training loss: 5.376867280462573
Validation loss: 5.839598297778619

Epoch: 6| Step: 2
Training loss: 6.115576520989826
Validation loss: 5.835938643898398

Epoch: 6| Step: 3
Training loss: 5.963281173236276
Validation loss: 5.832266637366085

Epoch: 6| Step: 4
Training loss: 5.504914082507204
Validation loss: 5.828208615927914

Epoch: 6| Step: 5
Training loss: 6.386583761952669
Validation loss: 5.824054158795585

Epoch: 6| Step: 6
Training loss: 5.897322755279013
Validation loss: 5.819940187293256

Epoch: 6| Step: 7
Training loss: 5.952069206430211
Validation loss: 5.815371552632387

Epoch: 6| Step: 8
Training loss: 5.486284494141657
Validation loss: 5.810861253969021

Epoch: 6| Step: 9
Training loss: 6.207545629449632
Validation loss: 5.805960062628775

Epoch: 6| Step: 10
Training loss: 6.34089122681449
Validation loss: 5.8010165354131304

Epoch: 6| Step: 11
Training loss: 6.315053895311076
Validation loss: 5.795998944956611

Epoch: 6| Step: 12
Training loss: 6.01674635703164
Validation loss: 5.790445606124328

Epoch: 6| Step: 13
Training loss: 5.501806482670388
Validation loss: 5.785007966876005

Epoch: 4| Step: 0
Training loss: 5.9835886625394545
Validation loss: 5.77922115983233

Epoch: 6| Step: 1
Training loss: 6.110121425289935
Validation loss: 5.773344033138119

Epoch: 6| Step: 2
Training loss: 6.457411111595742
Validation loss: 5.767450307326917

Epoch: 6| Step: 3
Training loss: 5.034044520342275
Validation loss: 5.76115833035456

Epoch: 6| Step: 4
Training loss: 5.977225313021666
Validation loss: 5.755062555966846

Epoch: 6| Step: 5
Training loss: 5.791676948959042
Validation loss: 5.748643908709591

Epoch: 6| Step: 6
Training loss: 6.52027723319752
Validation loss: 5.742151902968604

Epoch: 6| Step: 7
Training loss: 6.417524734526679
Validation loss: 5.735726289974678

Epoch: 6| Step: 8
Training loss: 5.2021413795533595
Validation loss: 5.729103985067855

Epoch: 6| Step: 9
Training loss: 4.924414957220648
Validation loss: 5.722287444120545

Epoch: 6| Step: 10
Training loss: 6.033216086806244
Validation loss: 5.715407098002594

Epoch: 6| Step: 11
Training loss: 6.401637952535413
Validation loss: 5.708815793256268

Epoch: 6| Step: 12
Training loss: 4.719216431055534
Validation loss: 5.701542241889952

Epoch: 6| Step: 13
Training loss: 6.004567632935455
Validation loss: 5.694535958193122

Epoch: 5| Step: 0
Training loss: 5.157575956997363
Validation loss: 5.687315242686841

Epoch: 6| Step: 1
Training loss: 5.742975339235779
Validation loss: 5.680202819310398

Epoch: 6| Step: 2
Training loss: 6.074356283611779
Validation loss: 5.672981287429066

Epoch: 6| Step: 3
Training loss: 4.794647793210415
Validation loss: 5.665597768087952

Epoch: 6| Step: 4
Training loss: 6.232954355778703
Validation loss: 5.65815778562047

Epoch: 6| Step: 5
Training loss: 5.757570010582399
Validation loss: 5.65076381392874

Epoch: 6| Step: 6
Training loss: 6.13171485748529
Validation loss: 5.643347874619116

Epoch: 6| Step: 7
Training loss: 6.3549627420337185
Validation loss: 5.635727098791027

Epoch: 6| Step: 8
Training loss: 5.79817945913053
Validation loss: 5.628194820035223

Epoch: 6| Step: 9
Training loss: 6.027651647292129
Validation loss: 5.620627816272122

Epoch: 6| Step: 10
Training loss: 5.066147043954772
Validation loss: 5.612826448163435

Epoch: 6| Step: 11
Training loss: 6.05189640809204
Validation loss: 5.605405573649502

Epoch: 6| Step: 12
Training loss: 4.770755994855655
Validation loss: 5.5979031962876356

Epoch: 6| Step: 13
Training loss: 6.30928002749379
Validation loss: 5.590391944788323

Epoch: 6| Step: 0
Training loss: 5.481167890744928
Validation loss: 5.582960011921121

Epoch: 6| Step: 1
Training loss: 4.581338321099843
Validation loss: 5.575616153031122

Epoch: 6| Step: 2
Training loss: 6.255128816029846
Validation loss: 5.568263950107832

Epoch: 6| Step: 3
Training loss: 4.870897963687625
Validation loss: 5.560732871543512

Epoch: 6| Step: 4
Training loss: 5.646773519274393
Validation loss: 5.553365515210774

Epoch: 6| Step: 5
Training loss: 6.6024344144984815
Validation loss: 5.545887346050055

Epoch: 6| Step: 6
Training loss: 5.833421034380724
Validation loss: 5.538246944846982

Epoch: 6| Step: 7
Training loss: 6.724110438849711
Validation loss: 5.5304781560220135

Epoch: 6| Step: 8
Training loss: 5.779827870904562
Validation loss: 5.521797163219884

Epoch: 6| Step: 9
Training loss: 6.067632331426732
Validation loss: 5.513844491740909

Epoch: 6| Step: 10
Training loss: 5.139424934724504
Validation loss: 5.506541927593566

Epoch: 6| Step: 11
Training loss: 5.635482007374732
Validation loss: 5.499211428204255

Epoch: 6| Step: 12
Training loss: 4.570177907673626
Validation loss: 5.492229434378272

Epoch: 6| Step: 13
Training loss: 5.456642568477176
Validation loss: 5.485419337871678

Epoch: 7| Step: 0
Training loss: 5.8096851383056896
Validation loss: 5.4785338158398975

Epoch: 6| Step: 1
Training loss: 5.815333178381608
Validation loss: 5.471395437625708

Epoch: 6| Step: 2
Training loss: 4.47537274220155
Validation loss: 5.464454257074266

Epoch: 6| Step: 3
Training loss: 5.084124123187355
Validation loss: 5.457640227751411

Epoch: 6| Step: 4
Training loss: 6.379526064976982
Validation loss: 5.450836080179055

Epoch: 6| Step: 5
Training loss: 6.236566985227568
Validation loss: 5.443590195562495

Epoch: 6| Step: 6
Training loss: 5.49562748583023
Validation loss: 5.4367884904850765

Epoch: 6| Step: 7
Training loss: 5.858382402904586
Validation loss: 5.429636710315887

Epoch: 6| Step: 8
Training loss: 5.935828686445071
Validation loss: 5.4229294102514505

Epoch: 6| Step: 9
Training loss: 5.072908039855933
Validation loss: 5.415951647393794

Epoch: 6| Step: 10
Training loss: 4.90513530144067
Validation loss: 5.409091739154205

Epoch: 6| Step: 11
Training loss: 5.603854637487995
Validation loss: 5.402355342106899

Epoch: 6| Step: 12
Training loss: 4.860600651173222
Validation loss: 5.395772199640361

Epoch: 6| Step: 13
Training loss: 5.875383405146485
Validation loss: 5.388752399214863

Epoch: 8| Step: 0
Training loss: 5.630711516821737
Validation loss: 5.382224676021567

Epoch: 6| Step: 1
Training loss: 6.355590293955325
Validation loss: 5.375876155681336

Epoch: 6| Step: 2
Training loss: 5.078392045262049
Validation loss: 5.3686178005345235

Epoch: 6| Step: 3
Training loss: 4.728215507049517
Validation loss: 5.361679990208588

Epoch: 6| Step: 4
Training loss: 5.45639945368454
Validation loss: 5.354564617325036

Epoch: 6| Step: 5
Training loss: 5.9474372024716455
Validation loss: 5.347805335987941

Epoch: 6| Step: 6
Training loss: 6.450429727596007
Validation loss: 5.34078495685637

Epoch: 6| Step: 7
Training loss: 5.534473578998355
Validation loss: 5.333602878593849

Epoch: 6| Step: 8
Training loss: 5.784359976956619
Validation loss: 5.326165996045145

Epoch: 6| Step: 9
Training loss: 5.10885048136729
Validation loss: 5.318973830310091

Epoch: 6| Step: 10
Training loss: 4.948731408215562
Validation loss: 5.311973007093351

Epoch: 6| Step: 11
Training loss: 5.606375144488833
Validation loss: 5.304916654046528

Epoch: 6| Step: 12
Training loss: 4.826742523679151
Validation loss: 5.2977764671617065

Epoch: 6| Step: 13
Training loss: 4.602147529860019
Validation loss: 5.291666146025545

Epoch: 9| Step: 0
Training loss: 5.850039437968025
Validation loss: 5.284893908101977

Epoch: 6| Step: 1
Training loss: 5.350562142759419
Validation loss: 5.278675813845418

Epoch: 6| Step: 2
Training loss: 4.5772254242312025
Validation loss: 5.272262902075529

Epoch: 6| Step: 3
Training loss: 5.853169891462259
Validation loss: 5.26589231633225

Epoch: 6| Step: 4
Training loss: 5.062115124801407
Validation loss: 5.259728364638957

Epoch: 6| Step: 5
Training loss: 5.775130048336168
Validation loss: 5.253429776014843

Epoch: 6| Step: 6
Training loss: 5.063562540705673
Validation loss: 5.247081187416999

Epoch: 6| Step: 7
Training loss: 5.413917704706092
Validation loss: 5.240971294828872

Epoch: 6| Step: 8
Training loss: 5.232567500714743
Validation loss: 5.235082504511321

Epoch: 6| Step: 9
Training loss: 5.623756610351801
Validation loss: 5.229091182736386

Epoch: 6| Step: 10
Training loss: 5.1272797515004465
Validation loss: 5.223102117815997

Epoch: 6| Step: 11
Training loss: 4.468327855798441
Validation loss: 5.217006765294796

Epoch: 6| Step: 12
Training loss: 5.444310625641832
Validation loss: 5.211134297297413

Epoch: 6| Step: 13
Training loss: 6.041845314629315
Validation loss: 5.205338046590308

Epoch: 10| Step: 0
Training loss: 4.844201639100469
Validation loss: 5.199045317384648

Epoch: 6| Step: 1
Training loss: 5.222581747318262
Validation loss: 5.193149936867283

Epoch: 6| Step: 2
Training loss: 4.943279119508541
Validation loss: 5.187254811815852

Epoch: 6| Step: 3
Training loss: 5.721945948345809
Validation loss: 5.181172138483435

Epoch: 6| Step: 4
Training loss: 5.6879389666838645
Validation loss: 5.175320955357918

Epoch: 6| Step: 5
Training loss: 6.0771408264906945
Validation loss: 5.16886462353971

Epoch: 6| Step: 6
Training loss: 5.388778060525011
Validation loss: 5.163366735451714

Epoch: 6| Step: 7
Training loss: 5.064727481541358
Validation loss: 5.157387933492024

Epoch: 6| Step: 8
Training loss: 4.097818464153962
Validation loss: 5.150751592364706

Epoch: 6| Step: 9
Training loss: 5.290968761328081
Validation loss: 5.144504246777239

Epoch: 6| Step: 10
Training loss: 5.017028232019807
Validation loss: 5.1384527221793235

Epoch: 6| Step: 11
Training loss: 6.008217905799061
Validation loss: 5.132480837065705

Epoch: 6| Step: 12
Training loss: 5.454513591615495
Validation loss: 5.12655163358517

Epoch: 6| Step: 13
Training loss: 4.8111292881043495
Validation loss: 5.120462347155865

Epoch: 11| Step: 0
Training loss: 5.4663490474510805
Validation loss: 5.114573378336348

Epoch: 6| Step: 1
Training loss: 5.272613506225841
Validation loss: 5.108181035238427

Epoch: 6| Step: 2
Training loss: 6.151692053777702
Validation loss: 5.103047846444297

Epoch: 6| Step: 3
Training loss: 6.047556284295232
Validation loss: 5.096523848021846

Epoch: 6| Step: 4
Training loss: 5.969346261325243
Validation loss: 5.0904079777383044

Epoch: 6| Step: 5
Training loss: 5.174869465678956
Validation loss: 5.084302726408555

Epoch: 6| Step: 6
Training loss: 5.619059668505714
Validation loss: 5.078613476856688

Epoch: 6| Step: 7
Training loss: 5.346446288427394
Validation loss: 5.0719819144408875

Epoch: 6| Step: 8
Training loss: 4.864333392086241
Validation loss: 5.066407034311893

Epoch: 6| Step: 9
Training loss: 4.619666658736515
Validation loss: 5.060450731741007

Epoch: 6| Step: 10
Training loss: 3.9775509308456005
Validation loss: 5.054552441010637

Epoch: 6| Step: 11
Training loss: 5.010968955749804
Validation loss: 5.048333208334514

Epoch: 6| Step: 12
Training loss: 3.851483760129467
Validation loss: 5.042169792775452

Epoch: 6| Step: 13
Training loss: 4.860865913141105
Validation loss: 5.037291569968978

Epoch: 12| Step: 0
Training loss: 5.302605603869248
Validation loss: 5.030860016993062

Epoch: 6| Step: 1
Training loss: 5.729781387179885
Validation loss: 5.025477760845409

Epoch: 6| Step: 2
Training loss: 4.548704637855297
Validation loss: 5.019691601281164

Epoch: 6| Step: 3
Training loss: 6.147343888505419
Validation loss: 5.01367764484394

Epoch: 6| Step: 4
Training loss: 5.562601324294416
Validation loss: 5.007788441362678

Epoch: 6| Step: 5
Training loss: 4.550969014366783
Validation loss: 5.001612466842399

Epoch: 6| Step: 6
Training loss: 3.3559041390260287
Validation loss: 4.995876360218268

Epoch: 6| Step: 7
Training loss: 4.902697789755736
Validation loss: 4.990061275816909

Epoch: 6| Step: 8
Training loss: 6.372740101891022
Validation loss: 4.985353188509774

Epoch: 6| Step: 9
Training loss: 4.365452839891235
Validation loss: 4.979732124855614

Epoch: 6| Step: 10
Training loss: 5.110486577526844
Validation loss: 4.973371455802405

Epoch: 6| Step: 11
Training loss: 5.065507537025882
Validation loss: 4.967579733789893

Epoch: 6| Step: 12
Training loss: 4.722970048120087
Validation loss: 4.9619090012602936

Epoch: 6| Step: 13
Training loss: 5.16154199167376
Validation loss: 4.9558551376082915

Epoch: 13| Step: 0
Training loss: 3.591607823668002
Validation loss: 4.949748495886032

Epoch: 6| Step: 1
Training loss: 5.506201628906612
Validation loss: 4.944515218240126

Epoch: 6| Step: 2
Training loss: 5.290967499608099
Validation loss: 4.9392147386293725

Epoch: 6| Step: 3
Training loss: 5.320995942301889
Validation loss: 4.933932371542228

Epoch: 6| Step: 4
Training loss: 5.661279960379536
Validation loss: 4.928541982390355

Epoch: 6| Step: 5
Training loss: 4.683904056911869
Validation loss: 4.92400473076567

Epoch: 6| Step: 6
Training loss: 4.733266165529887
Validation loss: 4.918543872125315

Epoch: 6| Step: 7
Training loss: 5.532079946893244
Validation loss: 4.913900028003129

Epoch: 6| Step: 8
Training loss: 5.377511081090033
Validation loss: 4.908596052944079

Epoch: 6| Step: 9
Training loss: 4.420524256068089
Validation loss: 4.903314736955769

Epoch: 6| Step: 10
Training loss: 5.2959595735971945
Validation loss: 4.898141141177505

Epoch: 6| Step: 11
Training loss: 5.6232125727258016
Validation loss: 4.892694784818

Epoch: 6| Step: 12
Training loss: 3.662221352454682
Validation loss: 4.887163946463827

Epoch: 6| Step: 13
Training loss: 5.270992452559245
Validation loss: 4.8820458382498275

Epoch: 14| Step: 0
Training loss: 4.586938076269107
Validation loss: 4.87717852048067

Epoch: 6| Step: 1
Training loss: 4.442699770753338
Validation loss: 4.871814648945881

Epoch: 6| Step: 2
Training loss: 4.56420908231855
Validation loss: 4.867057949605544

Epoch: 6| Step: 3
Training loss: 4.9067981195118
Validation loss: 4.861766198235424

Epoch: 6| Step: 4
Training loss: 5.925048943812386
Validation loss: 4.8564512036838385

Epoch: 6| Step: 5
Training loss: 4.672680431329547
Validation loss: 4.851636966905773

Epoch: 6| Step: 6
Training loss: 4.8478104830420286
Validation loss: 4.845826554997504

Epoch: 6| Step: 7
Training loss: 4.024867009400357
Validation loss: 4.8400947479032705

Epoch: 6| Step: 8
Training loss: 4.688910106914256
Validation loss: 4.834869053095381

Epoch: 6| Step: 9
Training loss: 5.493634788858773
Validation loss: 4.828866154841075

Epoch: 6| Step: 10
Training loss: 5.961216191367716
Validation loss: 4.822939626201031

Epoch: 6| Step: 11
Training loss: 4.904207229554542
Validation loss: 4.816558876723456

Epoch: 6| Step: 12
Training loss: 5.286331350621106
Validation loss: 4.8111848066165965

Epoch: 6| Step: 13
Training loss: 4.838112583851624
Validation loss: 4.805096732392145

Epoch: 15| Step: 0
Training loss: 5.6637035177188695
Validation loss: 4.799335507253868

Epoch: 6| Step: 1
Training loss: 4.724422859588373
Validation loss: 4.793089144105828

Epoch: 6| Step: 2
Training loss: 4.638396579001916
Validation loss: 4.78697261046859

Epoch: 6| Step: 3
Training loss: 4.700050743316086
Validation loss: 4.78187114861175

Epoch: 6| Step: 4
Training loss: 5.2731472359351566
Validation loss: 4.777112645911769

Epoch: 6| Step: 5
Training loss: 4.728920592685379
Validation loss: 4.771467119566459

Epoch: 6| Step: 6
Training loss: 4.903978538740035
Validation loss: 4.766470845519495

Epoch: 6| Step: 7
Training loss: 4.604113041952399
Validation loss: 4.760968394065002

Epoch: 6| Step: 8
Training loss: 4.892778111556438
Validation loss: 4.756240727085159

Epoch: 6| Step: 9
Training loss: 5.21138440093106
Validation loss: 4.751309933651138

Epoch: 6| Step: 10
Training loss: 4.908250145889969
Validation loss: 4.746232831091876

Epoch: 6| Step: 11
Training loss: 5.521221833385004
Validation loss: 4.741214222879054

Epoch: 6| Step: 12
Training loss: 4.11991430100873
Validation loss: 4.735557584711916

Epoch: 6| Step: 13
Training loss: 4.345697858142875
Validation loss: 4.73113993790075

Epoch: 16| Step: 0
Training loss: 4.491911931085789
Validation loss: 4.726515218535035

Epoch: 6| Step: 1
Training loss: 4.720470392742631
Validation loss: 4.721031092345203

Epoch: 6| Step: 2
Training loss: 5.632784902899195
Validation loss: 4.716410378995677

Epoch: 6| Step: 3
Training loss: 4.333788089854379
Validation loss: 4.711387094075345

Epoch: 6| Step: 4
Training loss: 4.7713410663983575
Validation loss: 4.705854905740317

Epoch: 6| Step: 5
Training loss: 5.111009808702037
Validation loss: 4.701098811436722

Epoch: 6| Step: 6
Training loss: 4.641504891462542
Validation loss: 4.695863104350446

Epoch: 6| Step: 7
Training loss: 4.781498123412705
Validation loss: 4.691017662045992

Epoch: 6| Step: 8
Training loss: 4.431806968905974
Validation loss: 4.685445343694229

Epoch: 6| Step: 9
Training loss: 4.895269851182216
Validation loss: 4.680337681338888

Epoch: 6| Step: 10
Training loss: 4.316459275692398
Validation loss: 4.676087078650959

Epoch: 6| Step: 11
Training loss: 5.654304296195475
Validation loss: 4.670911164305959

Epoch: 6| Step: 12
Training loss: 4.171451618556427
Validation loss: 4.665988288119088

Epoch: 6| Step: 13
Training loss: 5.23948925179057
Validation loss: 4.660777679134726

Epoch: 17| Step: 0
Training loss: 4.7269603719420115
Validation loss: 4.655085441496324

Epoch: 6| Step: 1
Training loss: 4.131109164285797
Validation loss: 4.650090933836936

Epoch: 6| Step: 2
Training loss: 5.139410460984276
Validation loss: 4.646195207994058

Epoch: 6| Step: 3
Training loss: 4.96860777453434
Validation loss: 4.641937960647173

Epoch: 6| Step: 4
Training loss: 5.072806898283288
Validation loss: 4.636879862187928

Epoch: 6| Step: 5
Training loss: 3.7753279789810255
Validation loss: 4.632628910571968

Epoch: 6| Step: 6
Training loss: 5.333243051400573
Validation loss: 4.630252141355507

Epoch: 6| Step: 7
Training loss: 4.510298917553425
Validation loss: 4.625050673336078

Epoch: 6| Step: 8
Training loss: 5.342752999441123
Validation loss: 4.618967108125498

Epoch: 6| Step: 9
Training loss: 4.41127798649338
Validation loss: 4.614136076436472

Epoch: 6| Step: 10
Training loss: 4.675857530575566
Validation loss: 4.609824155486502

Epoch: 6| Step: 11
Training loss: 4.58843749235138
Validation loss: 4.604669270189727

Epoch: 6| Step: 12
Training loss: 4.501367784954347
Validation loss: 4.598430403076254

Epoch: 6| Step: 13
Training loss: 5.083717248312598
Validation loss: 4.593353254351628

Epoch: 18| Step: 0
Training loss: 4.355470282721143
Validation loss: 4.589181821451863

Epoch: 6| Step: 1
Training loss: 4.408894496071576
Validation loss: 4.585733143782254

Epoch: 6| Step: 2
Training loss: 4.839414169545166
Validation loss: 4.581209812100796

Epoch: 6| Step: 3
Training loss: 4.829585869767915
Validation loss: 4.575976461074326

Epoch: 6| Step: 4
Training loss: 4.671140070747919
Validation loss: 4.569220866280098

Epoch: 6| Step: 5
Training loss: 4.077183640379463
Validation loss: 4.564672118518579

Epoch: 6| Step: 6
Training loss: 4.690566217205369
Validation loss: 4.56049206936979

Epoch: 6| Step: 7
Training loss: 5.457783193261121
Validation loss: 4.556746805226301

Epoch: 6| Step: 8
Training loss: 4.3367265962706
Validation loss: 4.551062474545565

Epoch: 6| Step: 9
Training loss: 3.9545751030427363
Validation loss: 4.545904486379345

Epoch: 6| Step: 10
Training loss: 4.707156459045274
Validation loss: 4.5416699972344645

Epoch: 6| Step: 11
Training loss: 3.784752224833397
Validation loss: 4.537383915420733

Epoch: 6| Step: 12
Training loss: 5.7360917102074085
Validation loss: 4.532774833094019

Epoch: 6| Step: 13
Training loss: 5.3098994453521415
Validation loss: 4.527775241146404

Epoch: 19| Step: 0
Training loss: 4.798906821699043
Validation loss: 4.522353776543413

Epoch: 6| Step: 1
Training loss: 4.728843554691368
Validation loss: 4.517158151234576

Epoch: 6| Step: 2
Training loss: 4.588980138167531
Validation loss: 4.513185363458825

Epoch: 6| Step: 3
Training loss: 5.201523909650518
Validation loss: 4.509113972335482

Epoch: 6| Step: 4
Training loss: 4.984895397990439
Validation loss: 4.5034450483454105

Epoch: 6| Step: 5
Training loss: 3.9182243225778963
Validation loss: 4.498859967534774

Epoch: 6| Step: 6
Training loss: 4.322424705118748
Validation loss: 4.494264426606084

Epoch: 6| Step: 7
Training loss: 4.209840309575757
Validation loss: 4.489931958935453

Epoch: 6| Step: 8
Training loss: 4.247998383343923
Validation loss: 4.485490578223926

Epoch: 6| Step: 9
Training loss: 5.3907828045289925
Validation loss: 4.480982526230207

Epoch: 6| Step: 10
Training loss: 3.7423895858958978
Validation loss: 4.475806402649677

Epoch: 6| Step: 11
Training loss: 4.675492229149661
Validation loss: 4.47097676601984

Epoch: 6| Step: 12
Training loss: 4.971596915897853
Validation loss: 4.466619201426939

Epoch: 6| Step: 13
Training loss: 4.60628040981736
Validation loss: 4.462160155590587

Epoch: 20| Step: 0
Training loss: 4.38826658502145
Validation loss: 4.457759101227843

Epoch: 6| Step: 1
Training loss: 5.384536976295797
Validation loss: 4.453331408262312

Epoch: 6| Step: 2
Training loss: 5.3190254973840165
Validation loss: 4.448146334696083

Epoch: 6| Step: 3
Training loss: 4.870441751047003
Validation loss: 4.443513619117702

Epoch: 6| Step: 4
Training loss: 3.772980277278095
Validation loss: 4.438624781227516

Epoch: 6| Step: 5
Training loss: 5.053152237384076
Validation loss: 4.434005184940833

Epoch: 6| Step: 6
Training loss: 3.6465400810052713
Validation loss: 4.429380824502961

Epoch: 6| Step: 7
Training loss: 4.527132044163069
Validation loss: 4.425169311847543

Epoch: 6| Step: 8
Training loss: 4.649080837834372
Validation loss: 4.420752500801175

Epoch: 6| Step: 9
Training loss: 4.951671880571429
Validation loss: 4.415108219835027

Epoch: 6| Step: 10
Training loss: 3.664231676698074
Validation loss: 4.410495975858263

Epoch: 6| Step: 11
Training loss: 4.656546154460734
Validation loss: 4.406177673467696

Epoch: 6| Step: 12
Training loss: 4.206800477508811
Validation loss: 4.400823764560676

Epoch: 6| Step: 13
Training loss: 4.249729372271701
Validation loss: 4.39644211204096

Epoch: 21| Step: 0
Training loss: 4.664432172326485
Validation loss: 4.391575593866636

Epoch: 6| Step: 1
Training loss: 4.923968545015271
Validation loss: 4.387168256602094

Epoch: 6| Step: 2
Training loss: 3.9872670168361943
Validation loss: 4.382163858268994

Epoch: 6| Step: 3
Training loss: 4.027826319142589
Validation loss: 4.37756869883998

Epoch: 6| Step: 4
Training loss: 4.346354629885323
Validation loss: 4.373054907608095

Epoch: 6| Step: 5
Training loss: 5.073803186469141
Validation loss: 4.368369645937227

Epoch: 6| Step: 6
Training loss: 5.142857029324485
Validation loss: 4.363964895833916

Epoch: 6| Step: 7
Training loss: 4.575660432767721
Validation loss: 4.35910376066133

Epoch: 6| Step: 8
Training loss: 3.8370399522408905
Validation loss: 4.354705205342307

Epoch: 6| Step: 9
Training loss: 4.010107383526904
Validation loss: 4.3497367055726945

Epoch: 6| Step: 10
Training loss: 4.968157654968202
Validation loss: 4.345221473776523

Epoch: 6| Step: 11
Training loss: 5.070355196216129
Validation loss: 4.340927524336868

Epoch: 6| Step: 12
Training loss: 4.18985192594881
Validation loss: 4.3348530097571665

Epoch: 6| Step: 13
Training loss: 3.6962076598945948
Validation loss: 4.330831129288725

Epoch: 22| Step: 0
Training loss: 4.420993892379853
Validation loss: 4.326319514181522

Epoch: 6| Step: 1
Training loss: 5.232219195169372
Validation loss: 4.32202609283771

Epoch: 6| Step: 2
Training loss: 3.4016003152325
Validation loss: 4.317017699786718

Epoch: 6| Step: 3
Training loss: 4.577274595051717
Validation loss: 4.312578394080545

Epoch: 6| Step: 4
Training loss: 4.468667196293596
Validation loss: 4.307493205892615

Epoch: 6| Step: 5
Training loss: 4.531537908418033
Validation loss: 4.302928364346484

Epoch: 6| Step: 6
Training loss: 3.761464206406093
Validation loss: 4.298104978286138

Epoch: 6| Step: 7
Training loss: 4.243948274230696
Validation loss: 4.293481603504616

Epoch: 6| Step: 8
Training loss: 3.5492810394376524
Validation loss: 4.289052345991131

Epoch: 6| Step: 9
Training loss: 4.117471240000523
Validation loss: 4.28448271464126

Epoch: 6| Step: 10
Training loss: 4.311986920338683
Validation loss: 4.280471303992088

Epoch: 6| Step: 11
Training loss: 4.919969946916796
Validation loss: 4.276657611503341

Epoch: 6| Step: 12
Training loss: 5.076181456500673
Validation loss: 4.2711665077820244

Epoch: 6| Step: 13
Training loss: 4.918466701855937
Validation loss: 4.266569226364265

Epoch: 23| Step: 0
Training loss: 4.531948693438721
Validation loss: 4.262344533521975

Epoch: 6| Step: 1
Training loss: 4.3502765173006575
Validation loss: 4.257613132487183

Epoch: 6| Step: 2
Training loss: 4.861826777985886
Validation loss: 4.253033509065716

Epoch: 6| Step: 3
Training loss: 4.694546502162048
Validation loss: 4.24825518451785

Epoch: 6| Step: 4
Training loss: 4.431687752820699
Validation loss: 4.243809136571832

Epoch: 6| Step: 5
Training loss: 5.0720745957000375
Validation loss: 4.239440290707599

Epoch: 6| Step: 6
Training loss: 3.9502807758832774
Validation loss: 4.234412611903412

Epoch: 6| Step: 7
Training loss: 4.104193027366499
Validation loss: 4.229640890258518

Epoch: 6| Step: 8
Training loss: 3.3786333095145338
Validation loss: 4.224920060644878

Epoch: 6| Step: 9
Training loss: 4.150603854816687
Validation loss: 4.220375369584188

Epoch: 6| Step: 10
Training loss: 3.95416318506718
Validation loss: 4.216133229184018

Epoch: 6| Step: 11
Training loss: 4.7298923333396665
Validation loss: 4.211320490456144

Epoch: 6| Step: 12
Training loss: 3.789797115884362
Validation loss: 4.207086353183169

Epoch: 6| Step: 13
Training loss: 4.76436811038053
Validation loss: 4.202732469648283

Epoch: 24| Step: 0
Training loss: 3.8609461501366957
Validation loss: 4.198217559455899

Epoch: 6| Step: 1
Training loss: 3.8173413414701813
Validation loss: 4.1935944120423

Epoch: 6| Step: 2
Training loss: 3.416426688969918
Validation loss: 4.189052332014781

Epoch: 6| Step: 3
Training loss: 4.233090589477232
Validation loss: 4.184783376984083

Epoch: 6| Step: 4
Training loss: 4.107335966321038
Validation loss: 4.180674974011008

Epoch: 6| Step: 5
Training loss: 4.157257875696906
Validation loss: 4.176254012558734

Epoch: 6| Step: 6
Training loss: 5.031339466886993
Validation loss: 4.171600828079238

Epoch: 6| Step: 7
Training loss: 5.169569164158419
Validation loss: 4.167209736083276

Epoch: 6| Step: 8
Training loss: 4.128279798147998
Validation loss: 4.162565075400964

Epoch: 6| Step: 9
Training loss: 4.3327356562109305
Validation loss: 4.157946801934445

Epoch: 6| Step: 10
Training loss: 3.6470291065909097
Validation loss: 4.153392603059936

Epoch: 6| Step: 11
Training loss: 4.662313724509223
Validation loss: 4.149170470155862

Epoch: 6| Step: 12
Training loss: 4.3862769701855
Validation loss: 4.144535506926713

Epoch: 6| Step: 13
Training loss: 4.845845808875222
Validation loss: 4.1398587843480446

Epoch: 25| Step: 0
Training loss: 4.347138544536006
Validation loss: 4.1351903794239515

Epoch: 6| Step: 1
Training loss: 4.818349478734263
Validation loss: 4.130525337102431

Epoch: 6| Step: 2
Training loss: 4.2580024326903425
Validation loss: 4.125612887695236

Epoch: 6| Step: 3
Training loss: 3.866768492530824
Validation loss: 4.121185349927399

Epoch: 6| Step: 4
Training loss: 3.525948519957866
Validation loss: 4.1167678184797785

Epoch: 6| Step: 5
Training loss: 4.051317523415945
Validation loss: 4.1123478317322615

Epoch: 6| Step: 6
Training loss: 3.855651665612511
Validation loss: 4.108092510420496

Epoch: 6| Step: 7
Training loss: 3.4736476379884635
Validation loss: 4.103785611711863

Epoch: 6| Step: 8
Training loss: 5.197872225380951
Validation loss: 4.099557576693569

Epoch: 6| Step: 9
Training loss: 4.259088783415374
Validation loss: 4.0946832228942505

Epoch: 6| Step: 10
Training loss: 4.236259238288466
Validation loss: 4.0900690550442445

Epoch: 6| Step: 11
Training loss: 4.549059995029622
Validation loss: 4.085502703492004

Epoch: 6| Step: 12
Training loss: 4.267106130935345
Validation loss: 4.080811513310503

Epoch: 6| Step: 13
Training loss: 4.294914769491621
Validation loss: 4.076285813498018

Epoch: 26| Step: 0
Training loss: 4.394863919699979
Validation loss: 4.071643692203703

Epoch: 6| Step: 1
Training loss: 4.077860973478443
Validation loss: 4.066653041087187

Epoch: 6| Step: 2
Training loss: 4.5990831207706835
Validation loss: 4.061859256392803

Epoch: 6| Step: 3
Training loss: 3.997139265377644
Validation loss: 4.057340034846215

Epoch: 6| Step: 4
Training loss: 4.837943257371654
Validation loss: 4.052670388080461

Epoch: 6| Step: 5
Training loss: 3.9200568981323123
Validation loss: 4.047732052574589

Epoch: 6| Step: 6
Training loss: 4.3694745730389135
Validation loss: 4.043213571209379

Epoch: 6| Step: 7
Training loss: 3.602292861860327
Validation loss: 4.038627360040465

Epoch: 6| Step: 8
Training loss: 4.257948231064785
Validation loss: 4.033927619647861

Epoch: 6| Step: 9
Training loss: 3.8497514471104246
Validation loss: 4.029326657758224

Epoch: 6| Step: 10
Training loss: 4.041858760293237
Validation loss: 4.024974778690653

Epoch: 6| Step: 11
Training loss: 4.311394370059943
Validation loss: 4.021045119220839

Epoch: 6| Step: 12
Training loss: 4.014231399184194
Validation loss: 4.01623142675448

Epoch: 6| Step: 13
Training loss: 4.033416166059229
Validation loss: 4.01237370023878

Epoch: 27| Step: 0
Training loss: 4.490608588011502
Validation loss: 4.008138820557545

Epoch: 6| Step: 1
Training loss: 3.8802119244381803
Validation loss: 4.0032661931243965

Epoch: 6| Step: 2
Training loss: 3.8382165047316996
Validation loss: 3.9991334930292535

Epoch: 6| Step: 3
Training loss: 3.3015413210505926
Validation loss: 3.9944679629771693

Epoch: 6| Step: 4
Training loss: 5.0774218263153745
Validation loss: 3.9899197362731824

Epoch: 6| Step: 5
Training loss: 3.917719611540734
Validation loss: 3.9853831293609656

Epoch: 6| Step: 6
Training loss: 3.9978202602788553
Validation loss: 3.980830911389794

Epoch: 6| Step: 7
Training loss: 4.119067926249176
Validation loss: 3.9761259567577953

Epoch: 6| Step: 8
Training loss: 3.751165590337597
Validation loss: 3.971831619662081

Epoch: 6| Step: 9
Training loss: 4.317285287683572
Validation loss: 3.9669337284253934

Epoch: 6| Step: 10
Training loss: 4.718792037271363
Validation loss: 3.962100287813797

Epoch: 6| Step: 11
Training loss: 3.7836170196605314
Validation loss: 3.9576445264646534

Epoch: 6| Step: 12
Training loss: 4.6810901813193615
Validation loss: 3.9531609253388065

Epoch: 6| Step: 13
Training loss: 3.2770472177567456
Validation loss: 3.94869143383119

Epoch: 28| Step: 0
Training loss: 3.4877096735228217
Validation loss: 3.944071478217258

Epoch: 6| Step: 1
Training loss: 4.345230399147977
Validation loss: 3.9403090977326953

Epoch: 6| Step: 2
Training loss: 4.224030531310511
Validation loss: 3.9354948357485324

Epoch: 6| Step: 3
Training loss: 3.057234616806055
Validation loss: 3.9309974140477997

Epoch: 6| Step: 4
Training loss: 3.8354616200169502
Validation loss: 3.9270185402838154

Epoch: 6| Step: 5
Training loss: 4.120631129617412
Validation loss: 3.9225742279089904

Epoch: 6| Step: 6
Training loss: 3.430587754675472
Validation loss: 3.9183909225829137

Epoch: 6| Step: 7
Training loss: 3.847411853754691
Validation loss: 3.9141367729485155

Epoch: 6| Step: 8
Training loss: 4.973400123256799
Validation loss: 3.9099211671366816

Epoch: 6| Step: 9
Training loss: 4.1867634139656715
Validation loss: 3.905558288365857

Epoch: 6| Step: 10
Training loss: 3.858135564911042
Validation loss: 3.9014061357307

Epoch: 6| Step: 11
Training loss: 3.7843082135431745
Validation loss: 3.8970077838723713

Epoch: 6| Step: 12
Training loss: 5.240432741190503
Validation loss: 3.89240562208582

Epoch: 6| Step: 13
Training loss: 3.759257143984323
Validation loss: 3.8880501720686778

Epoch: 29| Step: 0
Training loss: 3.7479026015256136
Validation loss: 3.883346919962373

Epoch: 6| Step: 1
Training loss: 3.7468624976985954
Validation loss: 3.8788728946251743

Epoch: 6| Step: 2
Training loss: 4.029669400041747
Validation loss: 3.874325970510102

Epoch: 6| Step: 3
Training loss: 3.775257500967106
Validation loss: 3.869917910721343

Epoch: 6| Step: 4
Training loss: 4.384783894728085
Validation loss: 3.8655842858331426

Epoch: 6| Step: 5
Training loss: 3.631269098385932
Validation loss: 3.8609435359959625

Epoch: 6| Step: 6
Training loss: 4.476247406899927
Validation loss: 3.856737767330437

Epoch: 6| Step: 7
Training loss: 4.302868245761292
Validation loss: 3.8521168937204586

Epoch: 6| Step: 8
Training loss: 4.720980085677163
Validation loss: 3.8479853713602807

Epoch: 6| Step: 9
Training loss: 3.671065610593899
Validation loss: 3.8433271552833292

Epoch: 6| Step: 10
Training loss: 4.067537676185973
Validation loss: 3.8385507211703476

Epoch: 6| Step: 11
Training loss: 2.911562094889522
Validation loss: 3.8341622838442504

Epoch: 6| Step: 12
Training loss: 3.5662508843999463
Validation loss: 3.8297642526207607

Epoch: 6| Step: 13
Training loss: 4.44373925230548
Validation loss: 3.825276047795448

Epoch: 30| Step: 0
Training loss: 2.7117793730056445
Validation loss: 3.8208802262274415

Epoch: 6| Step: 1
Training loss: 3.9370648582644856
Validation loss: 3.8166541933636022

Epoch: 6| Step: 2
Training loss: 3.945243245640622
Validation loss: 3.8123411343520197

Epoch: 6| Step: 3
Training loss: 4.5291579053712745
Validation loss: 3.8078180967636

Epoch: 6| Step: 4
Training loss: 4.291529878578322
Validation loss: 3.8033272297905225

Epoch: 6| Step: 5
Training loss: 4.08179504587244
Validation loss: 3.798943729161624

Epoch: 6| Step: 6
Training loss: 3.4298145731192884
Validation loss: 3.7943903324506714

Epoch: 6| Step: 7
Training loss: 4.335754940554299
Validation loss: 3.7898760050114855

Epoch: 6| Step: 8
Training loss: 3.6331905045273225
Validation loss: 3.7853677990365413

Epoch: 6| Step: 9
Training loss: 3.534921813272841
Validation loss: 3.7808217838663913

Epoch: 6| Step: 10
Training loss: 4.6746307716826685
Validation loss: 3.776615276396668

Epoch: 6| Step: 11
Training loss: 3.4956145741365034
Validation loss: 3.772034462563345

Epoch: 6| Step: 12
Training loss: 4.165202430302805
Validation loss: 3.7675520739619586

Epoch: 6| Step: 13
Training loss: 3.783411086259572
Validation loss: 3.76333398626934

Epoch: 31| Step: 0
Training loss: 4.137388180607574
Validation loss: 3.7585968446794817

Epoch: 6| Step: 1
Training loss: 4.069984701066939
Validation loss: 3.7543272271293926

Epoch: 6| Step: 2
Training loss: 3.2236853233851757
Validation loss: 3.749965943075873

Epoch: 6| Step: 3
Training loss: 3.2941919772192816
Validation loss: 3.7455456663909166

Epoch: 6| Step: 4
Training loss: 3.97564422857045
Validation loss: 3.7411217814561053

Epoch: 6| Step: 5
Training loss: 3.2087727695752433
Validation loss: 3.73674346853975

Epoch: 6| Step: 6
Training loss: 4.347347389074062
Validation loss: 3.7324853689081983

Epoch: 6| Step: 7
Training loss: 4.513773924838911
Validation loss: 3.728211108202133

Epoch: 6| Step: 8
Training loss: 3.843701990339463
Validation loss: 3.7239158503458905

Epoch: 6| Step: 9
Training loss: 3.144548385289105
Validation loss: 3.719325023826684

Epoch: 6| Step: 10
Training loss: 3.88829565216089
Validation loss: 3.715110194307728

Epoch: 6| Step: 11
Training loss: 4.408014471760722
Validation loss: 3.7107000763549958

Epoch: 6| Step: 12
Training loss: 3.949883741768399
Validation loss: 3.706380494229013

Epoch: 6| Step: 13
Training loss: 3.778486771218531
Validation loss: 3.702049303014683

Epoch: 32| Step: 0
Training loss: 3.7777696466046757
Validation loss: 3.6975429220676577

Epoch: 6| Step: 1
Training loss: 3.545504670800266
Validation loss: 3.6933508969886613

Epoch: 6| Step: 2
Training loss: 4.744125749384871
Validation loss: 3.689142626406957

Epoch: 6| Step: 3
Training loss: 4.242600001166438
Validation loss: 3.684695971924628

Epoch: 6| Step: 4
Training loss: 3.7785290472840662
Validation loss: 3.680207298804853

Epoch: 6| Step: 5
Training loss: 3.4518167770755155
Validation loss: 3.67557152350126

Epoch: 6| Step: 6
Training loss: 3.2758670794730804
Validation loss: 3.6709696850835596

Epoch: 6| Step: 7
Training loss: 3.987535367707203
Validation loss: 3.6669701248365367

Epoch: 6| Step: 8
Training loss: 4.102003324524989
Validation loss: 3.6626171956933082

Epoch: 6| Step: 9
Training loss: 3.160246481155429
Validation loss: 3.6581842897564694

Epoch: 6| Step: 10
Training loss: 3.7758685192881347
Validation loss: 3.6539690994448315

Epoch: 6| Step: 11
Training loss: 3.783769509019768
Validation loss: 3.649807168491541

Epoch: 6| Step: 12
Training loss: 4.177521616835856
Validation loss: 3.645631330434368

Epoch: 6| Step: 13
Training loss: 3.155640496049513
Validation loss: 3.6411406188732522

Epoch: 33| Step: 0
Training loss: 4.037339689774677
Validation loss: 3.636946515668725

Epoch: 6| Step: 1
Training loss: 2.566672579853463
Validation loss: 3.632555202546876

Epoch: 6| Step: 2
Training loss: 3.663443767305028
Validation loss: 3.628501384968761

Epoch: 6| Step: 3
Training loss: 3.9579925122684165
Validation loss: 3.624468512322324

Epoch: 6| Step: 4
Training loss: 3.599684749151504
Validation loss: 3.620488066430021

Epoch: 6| Step: 5
Training loss: 3.7364103125762007
Validation loss: 3.6162186293829666

Epoch: 6| Step: 6
Training loss: 3.782850446987359
Validation loss: 3.6122122178072305

Epoch: 6| Step: 7
Training loss: 3.5934667060979533
Validation loss: 3.608369365156903

Epoch: 6| Step: 8
Training loss: 3.557847314261347
Validation loss: 3.604233662124108

Epoch: 6| Step: 9
Training loss: 4.156798362409755
Validation loss: 3.599957310458785

Epoch: 6| Step: 10
Training loss: 3.048125494588718
Validation loss: 3.5956783925811213

Epoch: 6| Step: 11
Training loss: 4.352235040109892
Validation loss: 3.591780479439367

Epoch: 6| Step: 12
Training loss: 3.887770865960773
Validation loss: 3.5875818365069305

Epoch: 6| Step: 13
Training loss: 4.141896178693779
Validation loss: 3.5832559148424292

Epoch: 34| Step: 0
Training loss: 3.15254174878688
Validation loss: 3.579061127521422

Epoch: 6| Step: 1
Training loss: 3.77612562765851
Validation loss: 3.5749198406631657

Epoch: 6| Step: 2
Training loss: 4.059167522152835
Validation loss: 3.570776043272456

Epoch: 6| Step: 3
Training loss: 3.937388221728454
Validation loss: 3.5665906431586882

Epoch: 6| Step: 4
Training loss: 4.541647931448181
Validation loss: 3.562706255379691

Epoch: 6| Step: 5
Training loss: 3.8280941086126044
Validation loss: 3.5577530047446198

Epoch: 6| Step: 6
Training loss: 3.7869809440252213
Validation loss: 3.553294216880658

Epoch: 6| Step: 7
Training loss: 3.389030960801551
Validation loss: 3.5486599860129955

Epoch: 6| Step: 8
Training loss: 3.8232438088677916
Validation loss: 3.544411967782128

Epoch: 6| Step: 9
Training loss: 2.72600927998117
Validation loss: 3.5399010614265367

Epoch: 6| Step: 10
Training loss: 3.494923179338851
Validation loss: 3.535788913267675

Epoch: 6| Step: 11
Training loss: 4.341712309047679
Validation loss: 3.5315399500994977

Epoch: 6| Step: 12
Training loss: 2.947961562031605
Validation loss: 3.5273740984687314

Epoch: 6| Step: 13
Training loss: 3.4104221935068195
Validation loss: 3.523220554617189

Epoch: 35| Step: 0
Training loss: 3.218841995850447
Validation loss: 3.5192208444295843

Epoch: 6| Step: 1
Training loss: 3.4308451651689675
Validation loss: 3.515446637185512

Epoch: 6| Step: 2
Training loss: 3.2663987990602057
Validation loss: 3.5116273205445907

Epoch: 6| Step: 3
Training loss: 3.596988976443391
Validation loss: 3.5079327444467876

Epoch: 6| Step: 4
Training loss: 3.534687360996759
Validation loss: 3.50375718586793

Epoch: 6| Step: 5
Training loss: 3.603342406702278
Validation loss: 3.4999271339824265

Epoch: 6| Step: 6
Training loss: 4.402890487067931
Validation loss: 3.495561146436282

Epoch: 6| Step: 7
Training loss: 3.006946944504174
Validation loss: 3.491345331766391

Epoch: 6| Step: 8
Training loss: 2.873170519358882
Validation loss: 3.4878033021868777

Epoch: 6| Step: 9
Training loss: 4.264003347599512
Validation loss: 3.483750040660904

Epoch: 6| Step: 10
Training loss: 3.8090573385724604
Validation loss: 3.479611937455146

Epoch: 6| Step: 11
Training loss: 4.263760449148687
Validation loss: 3.4755880183083003

Epoch: 6| Step: 12
Training loss: 3.2509024907546107
Validation loss: 3.4712011594980083

Epoch: 6| Step: 13
Training loss: 3.9212644793334617
Validation loss: 3.4673292784593497

Epoch: 36| Step: 0
Training loss: 2.8416060865401476
Validation loss: 3.4628620752547965

Epoch: 6| Step: 1
Training loss: 3.6868264827843684
Validation loss: 3.4593827290895174

Epoch: 6| Step: 2
Training loss: 3.1060587772327346
Validation loss: 3.455383758799146

Epoch: 6| Step: 3
Training loss: 3.970575228318662
Validation loss: 3.451662021236588

Epoch: 6| Step: 4
Training loss: 3.7000357703464517
Validation loss: 3.447992990499926

Epoch: 6| Step: 5
Training loss: 3.7351745005011927
Validation loss: 3.4441146094480524

Epoch: 6| Step: 6
Training loss: 3.5734494241199446
Validation loss: 3.4397046619799387

Epoch: 6| Step: 7
Training loss: 3.7051235552120536
Validation loss: 3.435618608198257

Epoch: 6| Step: 8
Training loss: 3.621314970993358
Validation loss: 3.4317827710937756

Epoch: 6| Step: 9
Training loss: 4.153369335510412
Validation loss: 3.4279045968387862

Epoch: 6| Step: 10
Training loss: 3.4088949031547444
Validation loss: 3.423902169511551

Epoch: 6| Step: 11
Training loss: 3.5735362917876103
Validation loss: 3.419800011660181

Epoch: 6| Step: 12
Training loss: 3.167271773765491
Validation loss: 3.4156997328130254

Epoch: 6| Step: 13
Training loss: 3.6247236212242764
Validation loss: 3.411832661754736

Epoch: 37| Step: 0
Training loss: 3.3780255355095656
Validation loss: 3.408061907592506

Epoch: 6| Step: 1
Training loss: 3.8101103751146947
Validation loss: 3.40413646863588

Epoch: 6| Step: 2
Training loss: 3.550133103575215
Validation loss: 3.399828010304205

Epoch: 6| Step: 3
Training loss: 4.085917427203324
Validation loss: 3.3960018389187265

Epoch: 6| Step: 4
Training loss: 3.924895441885851
Validation loss: 3.3919064492484585

Epoch: 6| Step: 5
Training loss: 4.009783224967463
Validation loss: 3.3876107407752785

Epoch: 6| Step: 6
Training loss: 3.504328367393466
Validation loss: 3.3834010222355264

Epoch: 6| Step: 7
Training loss: 3.007262023490751
Validation loss: 3.378981561133855

Epoch: 6| Step: 8
Training loss: 4.002315327984433
Validation loss: 3.375191930329124

Epoch: 6| Step: 9
Training loss: 3.4825755035693806
Validation loss: 3.371366334387661

Epoch: 6| Step: 10
Training loss: 2.609694409951111
Validation loss: 3.3673045410207196

Epoch: 6| Step: 11
Training loss: 2.819148280389833
Validation loss: 3.3636389234620583

Epoch: 6| Step: 12
Training loss: 3.52060086237121
Validation loss: 3.359952974501278

Epoch: 6| Step: 13
Training loss: 3.2543789633559563
Validation loss: 3.356435332340323

Epoch: 38| Step: 0
Training loss: 2.7653598981621768
Validation loss: 3.3524237106484276

Epoch: 6| Step: 1
Training loss: 3.6264379871956427
Validation loss: 3.3492629810945505

Epoch: 6| Step: 2
Training loss: 4.049517737038312
Validation loss: 3.3462484419729646

Epoch: 6| Step: 3
Training loss: 3.887534756520422
Validation loss: 3.3421078865516822

Epoch: 6| Step: 4
Training loss: 3.205315710696345
Validation loss: 3.338334769961092

Epoch: 6| Step: 5
Training loss: 2.8706663890589845
Validation loss: 3.334677727115698

Epoch: 6| Step: 6
Training loss: 3.6940714584898986
Validation loss: 3.331030208930507

Epoch: 6| Step: 7
Training loss: 2.7444964738136193
Validation loss: 3.3273089726292002

Epoch: 6| Step: 8
Training loss: 3.7217213276255556
Validation loss: 3.3239469854164536

Epoch: 6| Step: 9
Training loss: 3.3608293091169523
Validation loss: 3.32052269363786

Epoch: 6| Step: 10
Training loss: 3.6663457267638004
Validation loss: 3.3171733542649964

Epoch: 6| Step: 11
Training loss: 4.370451388233722
Validation loss: 3.313617206005453

Epoch: 6| Step: 12
Training loss: 3.137327370320868
Validation loss: 3.309732624695179

Epoch: 6| Step: 13
Training loss: 2.997775206543153
Validation loss: 3.306346311650721

Epoch: 39| Step: 0
Training loss: 3.336640259380687
Validation loss: 3.3025091279813577

Epoch: 6| Step: 1
Training loss: 2.8856927806155457
Validation loss: 3.2990067567072936

Epoch: 6| Step: 2
Training loss: 3.9330569434176788
Validation loss: 3.2952209951937257

Epoch: 6| Step: 3
Training loss: 3.181803680981377
Validation loss: 3.291740794896359

Epoch: 6| Step: 4
Training loss: 4.063337503816521
Validation loss: 3.2881164640001512

Epoch: 6| Step: 5
Training loss: 3.5551800397091133
Validation loss: 3.284363870695636

Epoch: 6| Step: 6
Training loss: 3.4789826274020306
Validation loss: 3.280764613505352

Epoch: 6| Step: 7
Training loss: 3.2240928083649645
Validation loss: 3.2769212901379303

Epoch: 6| Step: 8
Training loss: 3.032620621536344
Validation loss: 3.2733040283960553

Epoch: 6| Step: 9
Training loss: 3.4463877135480168
Validation loss: 3.2698278319193954

Epoch: 6| Step: 10
Training loss: 3.6851434451461604
Validation loss: 3.2662146369079617

Epoch: 6| Step: 11
Training loss: 3.2403819744392783
Validation loss: 3.262499248753019

Epoch: 6| Step: 12
Training loss: 2.939149109589937
Validation loss: 3.2590691866464554

Epoch: 6| Step: 13
Training loss: 3.6440977633999214
Validation loss: 3.255461627515132

Epoch: 40| Step: 0
Training loss: 3.2929562967773123
Validation loss: 3.251922723362646

Epoch: 6| Step: 1
Training loss: 3.6170797970517246
Validation loss: 3.248451622116807

Epoch: 6| Step: 2
Training loss: 3.6867993222514444
Validation loss: 3.244796524329961

Epoch: 6| Step: 3
Training loss: 3.3068915337837947
Validation loss: 3.241601092763028

Epoch: 6| Step: 4
Training loss: 3.1250715629013035
Validation loss: 3.2379778760924305

Epoch: 6| Step: 5
Training loss: 3.2347559312966094
Validation loss: 3.234821282647961

Epoch: 6| Step: 6
Training loss: 3.7250067384390078
Validation loss: 3.231334885368292

Epoch: 6| Step: 7
Training loss: 3.2113307145941996
Validation loss: 3.2278800041730062

Epoch: 6| Step: 8
Training loss: 3.4382041903447784
Validation loss: 3.224506230960362

Epoch: 6| Step: 9
Training loss: 3.093107368694935
Validation loss: 3.221089472749732

Epoch: 6| Step: 10
Training loss: 3.4582123026677043
Validation loss: 3.2174009687373437

Epoch: 6| Step: 11
Training loss: 3.7035705040892317
Validation loss: 3.2140071950063223

Epoch: 6| Step: 12
Training loss: 2.742296787268678
Validation loss: 3.2101666591831712

Epoch: 6| Step: 13
Training loss: 3.414172557043299
Validation loss: 3.2069995303953083

Epoch: 41| Step: 0
Training loss: 2.728208203701943
Validation loss: 3.2036658225905965

Epoch: 6| Step: 1
Training loss: 3.3704716007771833
Validation loss: 3.200635398426234

Epoch: 6| Step: 2
Training loss: 3.4314538669300423
Validation loss: 3.1974762024042347

Epoch: 6| Step: 3
Training loss: 3.384983978008178
Validation loss: 3.194365195429292

Epoch: 6| Step: 4
Training loss: 3.8166728712361864
Validation loss: 3.1911360751978726

Epoch: 6| Step: 5
Training loss: 3.551493859624247
Validation loss: 3.1880080746899835

Epoch: 6| Step: 6
Training loss: 3.7755995217524365
Validation loss: 3.1843407501485195

Epoch: 6| Step: 7
Training loss: 2.688905126830884
Validation loss: 3.180938174810468

Epoch: 6| Step: 8
Training loss: 3.0495083897355295
Validation loss: 3.177627783646246

Epoch: 6| Step: 9
Training loss: 3.0598444421659585
Validation loss: 3.174140885030476

Epoch: 6| Step: 10
Training loss: 3.7629630782855203
Validation loss: 3.1709763454981337

Epoch: 6| Step: 11
Training loss: 3.51791537805811
Validation loss: 3.1675923567195934

Epoch: 6| Step: 12
Training loss: 2.982616765437728
Validation loss: 3.164179620027254

Epoch: 6| Step: 13
Training loss: 3.1487385721820833
Validation loss: 3.1607312911928034

Epoch: 42| Step: 0
Training loss: 3.2796909079640764
Validation loss: 3.1575989059699565

Epoch: 6| Step: 1
Training loss: 3.2183049459076303
Validation loss: 3.1544011684375572

Epoch: 6| Step: 2
Training loss: 3.6680011199400346
Validation loss: 3.15113728696063

Epoch: 6| Step: 3
Training loss: 3.613341030966617
Validation loss: 3.148239924665923

Epoch: 6| Step: 4
Training loss: 2.9491146246105453
Validation loss: 3.1447168773254552

Epoch: 6| Step: 5
Training loss: 3.142921632872964
Validation loss: 3.1417929279107035

Epoch: 6| Step: 6
Training loss: 2.2323932529059745
Validation loss: 3.138694802663192

Epoch: 6| Step: 7
Training loss: 2.923208330266365
Validation loss: 3.1358463250657396

Epoch: 6| Step: 8
Training loss: 3.305601458048245
Validation loss: 3.133208873657741

Epoch: 6| Step: 9
Training loss: 3.98495850123835
Validation loss: 3.1303669174738493

Epoch: 6| Step: 10
Training loss: 3.3609184090796127
Validation loss: 3.1274076469399947

Epoch: 6| Step: 11
Training loss: 3.1108224844639065
Validation loss: 3.1240702453967026

Epoch: 6| Step: 12
Training loss: 2.82310098607033
Validation loss: 3.1208884593812787

Epoch: 6| Step: 13
Training loss: 3.8753703770984758
Validation loss: 3.1177173059098386

Epoch: 43| Step: 0
Training loss: 2.819580997695132
Validation loss: 3.1147695547375367

Epoch: 6| Step: 1
Training loss: 2.7805337733752435
Validation loss: 3.1118528885805046

Epoch: 6| Step: 2
Training loss: 3.0308771592346195
Validation loss: 3.1085392069883024

Epoch: 6| Step: 3
Training loss: 3.49321252172321
Validation loss: 3.105687752285023

Epoch: 6| Step: 4
Training loss: 3.4182730054313457
Validation loss: 3.103083701113414

Epoch: 6| Step: 5
Training loss: 3.351436585948812
Validation loss: 3.0999640278113496

Epoch: 6| Step: 6
Training loss: 3.2273409368557697
Validation loss: 3.0967704337000668

Epoch: 6| Step: 7
Training loss: 3.503366894499225
Validation loss: 3.093901787832953

Epoch: 6| Step: 8
Training loss: 3.008724718356129
Validation loss: 3.090673773226112

Epoch: 6| Step: 9
Training loss: 3.386872777549182
Validation loss: 3.087628766256349

Epoch: 6| Step: 10
Training loss: 3.275184183547122
Validation loss: 3.084590614715959

Epoch: 6| Step: 11
Training loss: 3.3099139213317885
Validation loss: 3.0811822879926463

Epoch: 6| Step: 12
Training loss: 3.2116374717009686
Validation loss: 3.077950228975507

Epoch: 6| Step: 13
Training loss: 3.3931688179901056
Validation loss: 3.0751439616508236

Epoch: 44| Step: 0
Training loss: 3.781121117783538
Validation loss: 3.0720605250255684

Epoch: 6| Step: 1
Training loss: 3.6111189687268443
Validation loss: 3.0690172357474004

Epoch: 6| Step: 2
Training loss: 3.4797959967263896
Validation loss: 3.06590333608963

Epoch: 6| Step: 3
Training loss: 3.3678164857173747
Validation loss: 3.0626722014923415

Epoch: 6| Step: 4
Training loss: 2.959022083608735
Validation loss: 3.0595053349216874

Epoch: 6| Step: 5
Training loss: 3.041180889757075
Validation loss: 3.0563519326278317

Epoch: 6| Step: 6
Training loss: 3.137165346573745
Validation loss: 3.053549422012443

Epoch: 6| Step: 7
Training loss: 3.1418038807930406
Validation loss: 3.050294597135357

Epoch: 6| Step: 8
Training loss: 3.4547402587064275
Validation loss: 3.047235503429061

Epoch: 6| Step: 9
Training loss: 2.271883928577871
Validation loss: 3.0442109549414655

Epoch: 6| Step: 10
Training loss: 3.505189862516728
Validation loss: 3.0412638323461865

Epoch: 6| Step: 11
Training loss: 2.8740318990382576
Validation loss: 3.038628384557258

Epoch: 6| Step: 12
Training loss: 2.802639609406176
Validation loss: 3.0358161356213103

Epoch: 6| Step: 13
Training loss: 3.0314340437242233
Validation loss: 3.0332831024021214

Epoch: 45| Step: 0
Training loss: 3.086997320976615
Validation loss: 3.0306028219240053

Epoch: 6| Step: 1
Training loss: 2.793019370307227
Validation loss: 3.0280101018155103

Epoch: 6| Step: 2
Training loss: 3.016760103524441
Validation loss: 3.0252893314762277

Epoch: 6| Step: 3
Training loss: 3.352837593439103
Validation loss: 3.0228127188044756

Epoch: 6| Step: 4
Training loss: 3.5378461688612703
Validation loss: 3.0201966809654097

Epoch: 6| Step: 5
Training loss: 3.575845450353588
Validation loss: 3.01800094325306

Epoch: 6| Step: 6
Training loss: 2.816152108798482
Validation loss: 3.0155220607127085

Epoch: 6| Step: 7
Training loss: 3.7503188951321924
Validation loss: 3.012744153418764

Epoch: 6| Step: 8
Training loss: 3.002787725302936
Validation loss: 3.010366252402238

Epoch: 6| Step: 9
Training loss: 2.7187948990545423
Validation loss: 3.00732664998109

Epoch: 6| Step: 10
Training loss: 3.1613082389248506
Validation loss: 3.004797966418054

Epoch: 6| Step: 11
Training loss: 3.261919026878969
Validation loss: 3.0019057631453485

Epoch: 6| Step: 12
Training loss: 3.0616483477309364
Validation loss: 2.9994872900156273

Epoch: 6| Step: 13
Training loss: 2.854167260682724
Validation loss: 2.996849140563499

Epoch: 46| Step: 0
Training loss: 2.7979994916172397
Validation loss: 2.9944466610532476

Epoch: 6| Step: 1
Training loss: 3.0063934545728923
Validation loss: 2.991741695012235

Epoch: 6| Step: 2
Training loss: 3.0872750389522627
Validation loss: 2.9896507100522203

Epoch: 6| Step: 3
Training loss: 3.0973636060831757
Validation loss: 2.9872111480124834

Epoch: 6| Step: 4
Training loss: 3.0316492191404727
Validation loss: 2.984534840189624

Epoch: 6| Step: 5
Training loss: 3.0975537277131022
Validation loss: 2.9821963788122576

Epoch: 6| Step: 6
Training loss: 2.9443250867855615
Validation loss: 2.9798486013591177

Epoch: 6| Step: 7
Training loss: 3.7556945796367276
Validation loss: 2.977404991660494

Epoch: 6| Step: 8
Training loss: 2.895520822325326
Validation loss: 2.9752262483578353

Epoch: 6| Step: 9
Training loss: 3.0224806580031127
Validation loss: 2.972655568266902

Epoch: 6| Step: 10
Training loss: 3.078767815870188
Validation loss: 2.970304196082074

Epoch: 6| Step: 11
Training loss: 3.233508597536397
Validation loss: 2.9679512153944967

Epoch: 6| Step: 12
Training loss: 3.137898794415483
Validation loss: 2.9655505959891877

Epoch: 6| Step: 13
Training loss: 3.38704158031889
Validation loss: 2.963216704579081

Epoch: 47| Step: 0
Training loss: 2.7026333223922876
Validation loss: 2.9602912727732367

Epoch: 6| Step: 1
Training loss: 3.508715133249136
Validation loss: 2.9578758656142177

Epoch: 6| Step: 2
Training loss: 2.5173621961803216
Validation loss: 2.9556232360589356

Epoch: 6| Step: 3
Training loss: 3.3423140820630155
Validation loss: 2.9533496078304005

Epoch: 6| Step: 4
Training loss: 2.7895843274145844
Validation loss: 2.950672833712764

Epoch: 6| Step: 5
Training loss: 2.7191144326286625
Validation loss: 2.9483784604828496

Epoch: 6| Step: 6
Training loss: 3.2005959551908125
Validation loss: 2.945899938525538

Epoch: 6| Step: 7
Training loss: 2.768110203930605
Validation loss: 2.9432551773281945

Epoch: 6| Step: 8
Training loss: 2.824548303732331
Validation loss: 2.941090519995578

Epoch: 6| Step: 9
Training loss: 3.1294158253902795
Validation loss: 2.938958137548075

Epoch: 6| Step: 10
Training loss: 3.5532406052543255
Validation loss: 2.936816075024713

Epoch: 6| Step: 11
Training loss: 3.3602899769131342
Validation loss: 2.9344968121168393

Epoch: 6| Step: 12
Training loss: 3.4056591956455016
Validation loss: 2.9322007449177305

Epoch: 6| Step: 13
Training loss: 3.1508579841650994
Validation loss: 2.929661756614326

Epoch: 48| Step: 0
Training loss: 2.8658325985390567
Validation loss: 2.9273984384225957

Epoch: 6| Step: 1
Training loss: 3.6130528063342586
Validation loss: 2.925043411150103

Epoch: 6| Step: 2
Training loss: 2.846837306689098
Validation loss: 2.9227971952297254

Epoch: 6| Step: 3
Training loss: 2.567789712252087
Validation loss: 2.9203575668272896

Epoch: 6| Step: 4
Training loss: 3.079038223113596
Validation loss: 2.9179841245001943

Epoch: 6| Step: 5
Training loss: 3.0116291354412277
Validation loss: 2.9157631473719654

Epoch: 6| Step: 6
Training loss: 3.4905570574289415
Validation loss: 2.9136220754293722

Epoch: 6| Step: 7
Training loss: 2.919827320009578
Validation loss: 2.91145134085064

Epoch: 6| Step: 8
Training loss: 3.6989140128242477
Validation loss: 2.9092531172547273

Epoch: 6| Step: 9
Training loss: 2.773333308452215
Validation loss: 2.9070024644246133

Epoch: 6| Step: 10
Training loss: 3.0865635490357763
Validation loss: 2.9049610438008227

Epoch: 6| Step: 11
Training loss: 2.4062791302391564
Validation loss: 2.9028634880549573

Epoch: 6| Step: 12
Training loss: 3.2418477443404634
Validation loss: 2.9006380157628016

Epoch: 6| Step: 13
Training loss: 2.874937471456156
Validation loss: 2.8984085725915665

Epoch: 49| Step: 0
Training loss: 3.1878213159510116
Validation loss: 2.8959605420025625

Epoch: 6| Step: 1
Training loss: 3.473617575126476
Validation loss: 2.8939590060044464

Epoch: 6| Step: 2
Training loss: 3.0332952462065377
Validation loss: 2.8917399962377432

Epoch: 6| Step: 3
Training loss: 3.426943017624443
Validation loss: 2.8895374348540095

Epoch: 6| Step: 4
Training loss: 2.880805746322871
Validation loss: 2.8871164835100553

Epoch: 6| Step: 5
Training loss: 3.2653764694041754
Validation loss: 2.885050703360144

Epoch: 6| Step: 6
Training loss: 2.61556820095653
Validation loss: 2.8827767718822606

Epoch: 6| Step: 7
Training loss: 2.946631341207503
Validation loss: 2.880740171218477

Epoch: 6| Step: 8
Training loss: 2.7289084586574943
Validation loss: 2.878496504066266

Epoch: 6| Step: 9
Training loss: 3.0999050371945307
Validation loss: 2.8764896127340966

Epoch: 6| Step: 10
Training loss: 3.0060202274822148
Validation loss: 2.8742918303339837

Epoch: 6| Step: 11
Training loss: 2.9209909988781795
Validation loss: 2.87188917287291

Epoch: 6| Step: 12
Training loss: 2.913119657029116
Validation loss: 2.8696324234458905

Epoch: 6| Step: 13
Training loss: 2.7242388510940185
Validation loss: 2.8675954668803922

Epoch: 50| Step: 0
Training loss: 2.5229089141986996
Validation loss: 2.8659137387618783

Epoch: 6| Step: 1
Training loss: 2.784161875710299
Validation loss: 2.8638587358895444

Epoch: 6| Step: 2
Training loss: 3.061346342814557
Validation loss: 2.862067228471783

Epoch: 6| Step: 3
Training loss: 3.1029775163805304
Validation loss: 2.860109342627885

Epoch: 6| Step: 4
Training loss: 3.412802177716082
Validation loss: 2.8583333770781607

Epoch: 6| Step: 5
Training loss: 3.1156346174606293
Validation loss: 2.8563358714121767

Epoch: 6| Step: 6
Training loss: 3.0692217493375167
Validation loss: 2.854355942698921

Epoch: 6| Step: 7
Training loss: 3.0842218579398826
Validation loss: 2.8523312581886815

Epoch: 6| Step: 8
Training loss: 2.8632286243884852
Validation loss: 2.8504408768635616

Epoch: 6| Step: 9
Training loss: 2.603405548767802
Validation loss: 2.8484207194676796

Epoch: 6| Step: 10
Training loss: 3.0183349450407424
Validation loss: 2.8465268198171816

Epoch: 6| Step: 11
Training loss: 2.995500369043125
Validation loss: 2.844851249164916

Epoch: 6| Step: 12
Training loss: 2.959606183376625
Validation loss: 2.8433351877913813

Epoch: 6| Step: 13
Training loss: 3.235018901032738
Validation loss: 2.8415851387417868

Epoch: 51| Step: 0
Training loss: 2.766462123923888
Validation loss: 2.839624115689998

Epoch: 6| Step: 1
Training loss: 2.6714921643561502
Validation loss: 2.837687083167255

Epoch: 6| Step: 2
Training loss: 3.012979404403127
Validation loss: 2.836128263476649

Epoch: 6| Step: 3
Training loss: 3.1301274767866976
Validation loss: 2.834553278286557

Epoch: 6| Step: 4
Training loss: 3.431436079917072
Validation loss: 2.832752804092987

Epoch: 6| Step: 5
Training loss: 3.255821589369073
Validation loss: 2.8308200534991568

Epoch: 6| Step: 6
Training loss: 2.8438727383797624
Validation loss: 2.8289347660790973

Epoch: 6| Step: 7
Training loss: 2.5921193707729637
Validation loss: 2.8272396971139053

Epoch: 6| Step: 8
Training loss: 2.7549679704801617
Validation loss: 2.825138784617286

Epoch: 6| Step: 9
Training loss: 3.2155937349006214
Validation loss: 2.82352986074737

Epoch: 6| Step: 10
Training loss: 2.713035453297581
Validation loss: 2.8215713579815707

Epoch: 6| Step: 11
Training loss: 2.8979399631934126
Validation loss: 2.819797190527032

Epoch: 6| Step: 12
Training loss: 2.9120704039352456
Validation loss: 2.8183115362282836

Epoch: 6| Step: 13
Training loss: 3.2430992223362467
Validation loss: 2.816536585119564

Epoch: 52| Step: 0
Training loss: 2.809969632673608
Validation loss: 2.814584242347403

Epoch: 6| Step: 1
Training loss: 3.446133539544788
Validation loss: 2.813074477122801

Epoch: 6| Step: 2
Training loss: 3.0123491431488305
Validation loss: 2.8114427769388275

Epoch: 6| Step: 3
Training loss: 2.625948053547831
Validation loss: 2.8096058259535366

Epoch: 6| Step: 4
Training loss: 3.061475621386961
Validation loss: 2.807749091104442

Epoch: 6| Step: 5
Training loss: 2.9330709629051768
Validation loss: 2.806158177856661

Epoch: 6| Step: 6
Training loss: 3.026602259243315
Validation loss: 2.8047076607973964

Epoch: 6| Step: 7
Training loss: 2.4293146859335115
Validation loss: 2.8033811312564616

Epoch: 6| Step: 8
Training loss: 3.345825406861249
Validation loss: 2.8015923666722786

Epoch: 6| Step: 9
Training loss: 2.697596458570072
Validation loss: 2.800217916319323

Epoch: 6| Step: 10
Training loss: 3.2997096020630026
Validation loss: 2.7987397582148006

Epoch: 6| Step: 11
Training loss: 3.14910003279358
Validation loss: 2.796620149562781

Epoch: 6| Step: 12
Training loss: 2.74844671945072
Validation loss: 2.795200237182741

Epoch: 6| Step: 13
Training loss: 2.428984414576364
Validation loss: 2.793197999451127

Epoch: 53| Step: 0
Training loss: 2.7079244353881475
Validation loss: 2.7916264507376645

Epoch: 6| Step: 1
Training loss: 2.6619945565733363
Validation loss: 2.790147814190594

Epoch: 6| Step: 2
Training loss: 3.2008063134964218
Validation loss: 2.7886810896775067

Epoch: 6| Step: 3
Training loss: 3.06085223029999
Validation loss: 2.787122577153896

Epoch: 6| Step: 4
Training loss: 2.5981328311937038
Validation loss: 2.7853525742599268

Epoch: 6| Step: 5
Training loss: 2.6714855601830605
Validation loss: 2.7834629441728618

Epoch: 6| Step: 6
Training loss: 3.1599268883081972
Validation loss: 2.7818502571344306

Epoch: 6| Step: 7
Training loss: 2.8972229585029963
Validation loss: 2.780127781119936

Epoch: 6| Step: 8
Training loss: 2.8336512069409063
Validation loss: 2.7783504902341

Epoch: 6| Step: 9
Training loss: 3.0910450834048993
Validation loss: 2.776809905762635

Epoch: 6| Step: 10
Training loss: 2.974852223292318
Validation loss: 2.77507833020889

Epoch: 6| Step: 11
Training loss: 3.3051734368643815
Validation loss: 2.7733204848270017

Epoch: 6| Step: 12
Training loss: 2.563274080544921
Validation loss: 2.7718409998147786

Epoch: 6| Step: 13
Training loss: 3.086510404691921
Validation loss: 2.770026703830907

Epoch: 54| Step: 0
Training loss: 2.7039745958139343
Validation loss: 2.768619604319569

Epoch: 6| Step: 1
Training loss: 3.107360033610364
Validation loss: 2.767170246285158

Epoch: 6| Step: 2
Training loss: 2.8907777488146666
Validation loss: 2.7656862068946513

Epoch: 6| Step: 3
Training loss: 2.9390290521546705
Validation loss: 2.764234908301114

Epoch: 6| Step: 4
Training loss: 2.555726472925622
Validation loss: 2.762814489216558

Epoch: 6| Step: 5
Training loss: 2.9975809834972784
Validation loss: 2.7612539688940667

Epoch: 6| Step: 6
Training loss: 2.987719194997947
Validation loss: 2.7600716333261563

Epoch: 6| Step: 7
Training loss: 2.7732294568757556
Validation loss: 2.758538961861269

Epoch: 6| Step: 8
Training loss: 3.3035715081056565
Validation loss: 2.756979105870574

Epoch: 6| Step: 9
Training loss: 2.798885965115663
Validation loss: 2.755800444371434

Epoch: 6| Step: 10
Training loss: 2.823912206873671
Validation loss: 2.754439238787474

Epoch: 6| Step: 11
Training loss: 2.382526317983453
Validation loss: 2.753060213178985

Epoch: 6| Step: 12
Training loss: 3.1186590330506974
Validation loss: 2.7516272960906214

Epoch: 6| Step: 13
Training loss: 3.1161462101061286
Validation loss: 2.7502890781705163

Epoch: 55| Step: 0
Training loss: 2.8125379771741525
Validation loss: 2.749178200086915

Epoch: 6| Step: 1
Training loss: 2.9249336430774373
Validation loss: 2.7478974136090675

Epoch: 6| Step: 2
Training loss: 2.9472018791772605
Validation loss: 2.7463790868309417

Epoch: 6| Step: 3
Training loss: 3.334481200624669
Validation loss: 2.7454203561848844

Epoch: 6| Step: 4
Training loss: 3.131380205626187
Validation loss: 2.743805714869239

Epoch: 6| Step: 5
Training loss: 2.1297858704583206
Validation loss: 2.742832176888656

Epoch: 6| Step: 6
Training loss: 2.8897700514603897
Validation loss: 2.7417703802170394

Epoch: 6| Step: 7
Training loss: 2.971194736350332
Validation loss: 2.740246309384464

Epoch: 6| Step: 8
Training loss: 2.4864132754959503
Validation loss: 2.739158979458685

Epoch: 6| Step: 9
Training loss: 2.7180346720815933
Validation loss: 2.73788542160793

Epoch: 6| Step: 10
Training loss: 3.0696769231229393
Validation loss: 2.737097498364979

Epoch: 6| Step: 11
Training loss: 3.121517224282791
Validation loss: 2.7356277502527053

Epoch: 6| Step: 12
Training loss: 3.084013597520274
Validation loss: 2.7343139932275475

Epoch: 6| Step: 13
Training loss: 2.504000324261434
Validation loss: 2.733052876862286

Epoch: 56| Step: 0
Training loss: 2.7493739716011305
Validation loss: 2.7317259099640627

Epoch: 6| Step: 1
Training loss: 3.521922798813975
Validation loss: 2.730394849018179

Epoch: 6| Step: 2
Training loss: 2.2646532803015273
Validation loss: 2.72960458886874

Epoch: 6| Step: 3
Training loss: 2.9033437985196215
Validation loss: 2.728046949507438

Epoch: 6| Step: 4
Training loss: 2.828051992917739
Validation loss: 2.7269467262535794

Epoch: 6| Step: 5
Training loss: 2.7920958535428353
Validation loss: 2.725812603008574

Epoch: 6| Step: 6
Training loss: 2.0391256388392747
Validation loss: 2.72463456191222

Epoch: 6| Step: 7
Training loss: 2.9754197537795637
Validation loss: 2.7235034881377103

Epoch: 6| Step: 8
Training loss: 3.0378467314821944
Validation loss: 2.7222232921321434

Epoch: 6| Step: 9
Training loss: 2.963195744836442
Validation loss: 2.720949678917681

Epoch: 6| Step: 10
Training loss: 2.948794787925051
Validation loss: 2.719752817352516

Epoch: 6| Step: 11
Training loss: 2.891109281645709
Validation loss: 2.7186756635420055

Epoch: 6| Step: 12
Training loss: 3.1061418295740597
Validation loss: 2.7172397935342025

Epoch: 6| Step: 13
Training loss: 2.8013390234402666
Validation loss: 2.7156507724231127

Epoch: 57| Step: 0
Training loss: 2.5559866398803948
Validation loss: 2.714688127846314

Epoch: 6| Step: 1
Training loss: 3.3658319917886934
Validation loss: 2.7135219365804177

Epoch: 6| Step: 2
Training loss: 2.4719389587692793
Validation loss: 2.711797411118533

Epoch: 6| Step: 3
Training loss: 2.4821714789689855
Validation loss: 2.7110353098584

Epoch: 6| Step: 4
Training loss: 3.396704080417415
Validation loss: 2.7096160834211

Epoch: 6| Step: 5
Training loss: 3.5454692995880377
Validation loss: 2.7088167248229666

Epoch: 6| Step: 6
Training loss: 2.405305156738681
Validation loss: 2.7071433803276497

Epoch: 6| Step: 7
Training loss: 2.3883175154288834
Validation loss: 2.7056203066993048

Epoch: 6| Step: 8
Training loss: 2.7589451352423344
Validation loss: 2.704713093977932

Epoch: 6| Step: 9
Training loss: 2.744757423452687
Validation loss: 2.7030787087300663

Epoch: 6| Step: 10
Training loss: 3.1742360014356303
Validation loss: 2.7021185998862745

Epoch: 6| Step: 11
Training loss: 2.847208288722073
Validation loss: 2.7010254616820712

Epoch: 6| Step: 12
Training loss: 2.8245838398887706
Validation loss: 2.7002153999450607

Epoch: 6| Step: 13
Training loss: 2.570919997013225
Validation loss: 2.698862732274149

Epoch: 58| Step: 0
Training loss: 2.6115972684084348
Validation loss: 2.6977863403027667

Epoch: 6| Step: 1
Training loss: 2.45359409002134
Validation loss: 2.696446056002515

Epoch: 6| Step: 2
Training loss: 3.0791376452353774
Validation loss: 2.6954598796559144

Epoch: 6| Step: 3
Training loss: 2.531738045820264
Validation loss: 2.695005847238061

Epoch: 6| Step: 4
Training loss: 3.401149605892484
Validation loss: 2.6935299493609213

Epoch: 6| Step: 5
Training loss: 2.9361174556198875
Validation loss: 2.692552607526223

Epoch: 6| Step: 6
Training loss: 3.048003784798102
Validation loss: 2.6909058229738405

Epoch: 6| Step: 7
Training loss: 2.7315600046867177
Validation loss: 2.689903766347731

Epoch: 6| Step: 8
Training loss: 2.630340683631874
Validation loss: 2.6887425056612

Epoch: 6| Step: 9
Training loss: 2.679173100425704
Validation loss: 2.6881625815091725

Epoch: 6| Step: 10
Training loss: 2.322937684470119
Validation loss: 2.6868163429513237

Epoch: 6| Step: 11
Training loss: 3.0879954755186625
Validation loss: 2.686229183565467

Epoch: 6| Step: 12
Training loss: 2.7472815515454387
Validation loss: 2.6848805547674797

Epoch: 6| Step: 13
Training loss: 3.1695572225565747
Validation loss: 2.6841343053481377

Epoch: 59| Step: 0
Training loss: 2.8346325943383306
Validation loss: 2.683302062505949

Epoch: 6| Step: 1
Training loss: 2.778808550850575
Validation loss: 2.681684530240961

Epoch: 6| Step: 2
Training loss: 3.018333365238329
Validation loss: 2.6804357138435866

Epoch: 6| Step: 3
Training loss: 3.2717557606652563
Validation loss: 2.679341137209871

Epoch: 6| Step: 4
Training loss: 2.6860182469842466
Validation loss: 2.678428687879046

Epoch: 6| Step: 5
Training loss: 3.074822682796465
Validation loss: 2.677773076321954

Epoch: 6| Step: 6
Training loss: 1.9988549650208127
Validation loss: 2.6764872044329233

Epoch: 6| Step: 7
Training loss: 2.966319966863485
Validation loss: 2.6759190284916814

Epoch: 6| Step: 8
Training loss: 2.886710325649497
Validation loss: 2.6751790875057067

Epoch: 6| Step: 9
Training loss: 2.439232430657038
Validation loss: 2.674559087156579

Epoch: 6| Step: 10
Training loss: 3.2314242111259515
Validation loss: 2.674002100000957

Epoch: 6| Step: 11
Training loss: 2.485360579858396
Validation loss: 2.6733220812528242

Epoch: 6| Step: 12
Training loss: 3.0947171635724264
Validation loss: 2.6717611069228124

Epoch: 6| Step: 13
Training loss: 2.3955171680539897
Validation loss: 2.671192364556599

Epoch: 60| Step: 0
Training loss: 2.5923945550617424
Validation loss: 2.669379245448326

Epoch: 6| Step: 1
Training loss: 3.069282494861651
Validation loss: 2.667873725297296

Epoch: 6| Step: 2
Training loss: 2.898054976811276
Validation loss: 2.6669019853555564

Epoch: 6| Step: 3
Training loss: 2.797434319346413
Validation loss: 2.6651877583916432

Epoch: 6| Step: 4
Training loss: 2.5733920956690137
Validation loss: 2.6646532464617207

Epoch: 6| Step: 5
Training loss: 2.9989673108656296
Validation loss: 2.681482423846971

Epoch: 6| Step: 6
Training loss: 2.4035577947350957
Validation loss: 2.689231566087431

Epoch: 6| Step: 7
Training loss: 2.9565648627002106
Validation loss: 2.687423143101078

Epoch: 6| Step: 8
Training loss: 2.8451358646071245
Validation loss: 2.6830765745477487

Epoch: 6| Step: 9
Training loss: 2.935867505256811
Validation loss: 2.6809283498570906

Epoch: 6| Step: 10
Training loss: 2.939413218686755
Validation loss: 2.687857714954505

Epoch: 6| Step: 11
Training loss: 3.106009650957843
Validation loss: 2.6796631362445096

Epoch: 6| Step: 12
Training loss: 2.3130426543409834
Validation loss: 2.6777367344907774

Epoch: 6| Step: 13
Training loss: 2.892846156239041
Validation loss: 2.6783470901518935

Epoch: 61| Step: 0
Training loss: 3.0518248430138524
Validation loss: 2.6765360637724345

Epoch: 6| Step: 1
Training loss: 2.4669898796538865
Validation loss: 2.6765699871587243

Epoch: 6| Step: 2
Training loss: 2.8162167044888156
Validation loss: 2.675140363510413

Epoch: 6| Step: 3
Training loss: 2.5619770539899256
Validation loss: 2.6736326478253094

Epoch: 6| Step: 4
Training loss: 3.180170945665082
Validation loss: 2.671951872851903

Epoch: 6| Step: 5
Training loss: 2.8329337530176764
Validation loss: 2.6698215617394983

Epoch: 6| Step: 6
Training loss: 2.7978392063154294
Validation loss: 2.6653553351145707

Epoch: 6| Step: 7
Training loss: 3.2567841075336106
Validation loss: 2.6507187192575596

Epoch: 6| Step: 8
Training loss: 2.3095441949831406
Validation loss: 2.6496734960814106

Epoch: 6| Step: 9
Training loss: 2.683664912317256
Validation loss: 2.6507361535162772

Epoch: 6| Step: 10
Training loss: 2.5391718914235715
Validation loss: 2.6531023411706185

Epoch: 6| Step: 11
Training loss: 2.981536953789358
Validation loss: 2.6524132488660612

Epoch: 6| Step: 12
Training loss: 2.9158949421401714
Validation loss: 2.648269032809456

Epoch: 6| Step: 13
Training loss: 2.693237921595368
Validation loss: 2.64640230283833

Epoch: 62| Step: 0
Training loss: 2.9634778239921853
Validation loss: 2.6462156114729884

Epoch: 6| Step: 1
Training loss: 2.7139546866517006
Validation loss: 2.6452130819687008

Epoch: 6| Step: 2
Training loss: 2.9650645619868867
Validation loss: 2.6440801343715647

Epoch: 6| Step: 3
Training loss: 2.8109930451753904
Validation loss: 2.642635520580542

Epoch: 6| Step: 4
Training loss: 2.9394109475794634
Validation loss: 2.6431604886959277

Epoch: 6| Step: 5
Training loss: 2.469600096542114
Validation loss: 2.6405262825174387

Epoch: 6| Step: 6
Training loss: 3.389926539612581
Validation loss: 2.6369214090713466

Epoch: 6| Step: 7
Training loss: 2.75992915808941
Validation loss: 2.635277534601818

Epoch: 6| Step: 8
Training loss: 2.9125439161665243
Validation loss: 2.636590151064389

Epoch: 6| Step: 9
Training loss: 2.3776961632959734
Validation loss: 2.633783600937901

Epoch: 6| Step: 10
Training loss: 2.685752744239897
Validation loss: 2.6307971005808954

Epoch: 6| Step: 11
Training loss: 2.5993910883419153
Validation loss: 2.629529496521648

Epoch: 6| Step: 12
Training loss: 2.96423188782768
Validation loss: 2.6274019635485697

Epoch: 6| Step: 13
Training loss: 2.1453684577951053
Validation loss: 2.6254948951808625

Epoch: 63| Step: 0
Training loss: 3.0778537378986957
Validation loss: 2.6255757442201677

Epoch: 6| Step: 1
Training loss: 2.2240243465682696
Validation loss: 2.62426723364647

Epoch: 6| Step: 2
Training loss: 2.6739966462712736
Validation loss: 2.6237616872807354

Epoch: 6| Step: 3
Training loss: 2.302764504116667
Validation loss: 2.624691824004311

Epoch: 6| Step: 4
Training loss: 2.6949222005679974
Validation loss: 2.623296427081387

Epoch: 6| Step: 5
Training loss: 2.898917844715534
Validation loss: 2.623634543335841

Epoch: 6| Step: 6
Training loss: 2.4083454866553637
Validation loss: 2.6233864926773087

Epoch: 6| Step: 7
Training loss: 2.5204317597979795
Validation loss: 2.6243621868739226

Epoch: 6| Step: 8
Training loss: 2.8057098650488212
Validation loss: 2.624104104732307

Epoch: 6| Step: 9
Training loss: 2.6767326946673573
Validation loss: 2.622829735981575

Epoch: 6| Step: 10
Training loss: 3.227198207937565
Validation loss: 2.6212695574936604

Epoch: 6| Step: 11
Training loss: 3.2138993833372913
Validation loss: 2.621113670489456

Epoch: 6| Step: 12
Training loss: 3.295602561950984
Validation loss: 2.618730627214369

Epoch: 6| Step: 13
Training loss: 2.326645451406181
Validation loss: 2.6164997165008397

Epoch: 64| Step: 0
Training loss: 2.757717487546428
Validation loss: 2.613992241741635

Epoch: 6| Step: 1
Training loss: 3.143151173523409
Validation loss: 2.613998003078672

Epoch: 6| Step: 2
Training loss: 2.946971314879922
Validation loss: 2.610766133274483

Epoch: 6| Step: 3
Training loss: 2.326100640603511
Validation loss: 2.606858949699492

Epoch: 6| Step: 4
Training loss: 3.008794292382261
Validation loss: 2.6061233239678447

Epoch: 6| Step: 5
Training loss: 2.529379447855808
Validation loss: 2.6041614735869447

Epoch: 6| Step: 6
Training loss: 3.0223688016045624
Validation loss: 2.6055178582836076

Epoch: 6| Step: 7
Training loss: 3.118161156972887
Validation loss: 2.601864954690558

Epoch: 6| Step: 8
Training loss: 2.6339061967024078
Validation loss: 2.604223560983321

Epoch: 6| Step: 9
Training loss: 3.041867880937324
Validation loss: 2.6024263492341277

Epoch: 6| Step: 10
Training loss: 2.322229896828819
Validation loss: 2.600763406307497

Epoch: 6| Step: 11
Training loss: 2.4551916467949004
Validation loss: 2.599719107566754

Epoch: 6| Step: 12
Training loss: 2.211713351475882
Validation loss: 2.601058712619407

Epoch: 6| Step: 13
Training loss: 2.7898638773426856
Validation loss: 2.5992599546718784

Epoch: 65| Step: 0
Training loss: 3.051572963151705
Validation loss: 2.600450402152906

Epoch: 6| Step: 1
Training loss: 3.0688650199016534
Validation loss: 2.6006882795785096

Epoch: 6| Step: 2
Training loss: 2.5159183117958417
Validation loss: 2.6017720440701395

Epoch: 6| Step: 3
Training loss: 2.415212610335786
Validation loss: 2.6044390319808484

Epoch: 6| Step: 4
Training loss: 2.529654199994836
Validation loss: 2.600719235048409

Epoch: 6| Step: 5
Training loss: 2.4688504355558947
Validation loss: 2.594995720393695

Epoch: 6| Step: 6
Training loss: 2.8816941322384206
Validation loss: 2.596343815565121

Epoch: 6| Step: 7
Training loss: 2.8776440279632163
Validation loss: 2.596341397411253

Epoch: 6| Step: 8
Training loss: 2.8571647064190984
Validation loss: 2.59276733780866

Epoch: 6| Step: 9
Training loss: 2.5145779912765973
Validation loss: 2.5927967020201548

Epoch: 6| Step: 10
Training loss: 2.8056565844618406
Validation loss: 2.5936240659727967

Epoch: 6| Step: 11
Training loss: 2.7668402636501557
Validation loss: 2.5914070853921154

Epoch: 6| Step: 12
Training loss: 2.851537416948757
Validation loss: 2.5907489466265177

Epoch: 6| Step: 13
Training loss: 2.6078567199432046
Validation loss: 2.5907672292383146

Epoch: 66| Step: 0
Training loss: 2.466154738305734
Validation loss: 2.590895955419021

Epoch: 6| Step: 1
Training loss: 3.0185824898630664
Validation loss: 2.5912797187196497

Epoch: 6| Step: 2
Training loss: 3.079315420092735
Validation loss: 2.5899736804312194

Epoch: 6| Step: 3
Training loss: 2.659897577422012
Validation loss: 2.592850065565703

Epoch: 6| Step: 4
Training loss: 2.612698112167475
Validation loss: 2.5907598211150216

Epoch: 6| Step: 5
Training loss: 2.9301708585637076
Validation loss: 2.5906761523305595

Epoch: 6| Step: 6
Training loss: 3.1024345498016914
Validation loss: 2.589397455256661

Epoch: 6| Step: 7
Training loss: 2.331668486886431
Validation loss: 2.5891167035872122

Epoch: 6| Step: 8
Training loss: 2.7993976149398216
Validation loss: 2.585098814400711

Epoch: 6| Step: 9
Training loss: 2.8852199850058993
Validation loss: 2.584441152553953

Epoch: 6| Step: 10
Training loss: 2.921237325187873
Validation loss: 2.581965951098669

Epoch: 6| Step: 11
Training loss: 2.0314712403928374
Validation loss: 2.5797490408919925

Epoch: 6| Step: 12
Training loss: 2.3753846509545005
Validation loss: 2.582636421295662

Epoch: 6| Step: 13
Training loss: 2.7340010905064807
Validation loss: 2.584559493146853

Epoch: 67| Step: 0
Training loss: 2.5412269170175286
Validation loss: 2.583768705372

Epoch: 6| Step: 1
Training loss: 2.466839401108101
Validation loss: 2.5913890219709836

Epoch: 6| Step: 2
Training loss: 3.09444442815988
Validation loss: 2.631999855386446

Epoch: 6| Step: 3
Training loss: 3.009547934311879
Validation loss: 2.611593981885527

Epoch: 6| Step: 4
Training loss: 2.7785437629826992
Validation loss: 2.5782811743703102

Epoch: 6| Step: 5
Training loss: 2.518071945210967
Validation loss: 2.572324589444753

Epoch: 6| Step: 6
Training loss: 2.7181420358986643
Validation loss: 2.574512316375707

Epoch: 6| Step: 7
Training loss: 2.3171282667433446
Validation loss: 2.577393892449333

Epoch: 6| Step: 8
Training loss: 2.9549093355835057
Validation loss: 2.5888137725534452

Epoch: 6| Step: 9
Training loss: 2.5280134442853157
Validation loss: 2.598814619495492

Epoch: 6| Step: 10
Training loss: 2.777916786106493
Validation loss: 2.607852423049758

Epoch: 6| Step: 11
Training loss: 2.8101815734519793
Validation loss: 2.616532170631608

Epoch: 6| Step: 12
Training loss: 2.6255649685279514
Validation loss: 2.6117604786282387

Epoch: 6| Step: 13
Training loss: 2.8156049755201504
Validation loss: 2.615965631045344

Epoch: 68| Step: 0
Training loss: 2.6458773772010535
Validation loss: 2.6116107339799384

Epoch: 6| Step: 1
Training loss: 2.5451278778804816
Validation loss: 2.6012485074099025

Epoch: 6| Step: 2
Training loss: 2.3254361594669914
Validation loss: 2.5930538775354544

Epoch: 6| Step: 3
Training loss: 2.706615509652201
Validation loss: 2.584654014129736

Epoch: 6| Step: 4
Training loss: 2.5202391583626023
Validation loss: 2.574978088853567

Epoch: 6| Step: 5
Training loss: 2.7040186821444543
Validation loss: 2.5733870772529257

Epoch: 6| Step: 6
Training loss: 2.8706489477938133
Validation loss: 2.570285275207855

Epoch: 6| Step: 7
Training loss: 2.911131993510871
Validation loss: 2.566367200828225

Epoch: 6| Step: 8
Training loss: 2.56926262931099
Validation loss: 2.563050389301933

Epoch: 6| Step: 9
Training loss: 2.874612865090795
Validation loss: 2.5615158672368756

Epoch: 6| Step: 10
Training loss: 2.6124457832806893
Validation loss: 2.5622134319813394

Epoch: 6| Step: 11
Training loss: 2.851940725665588
Validation loss: 2.5655194457903283

Epoch: 6| Step: 12
Training loss: 2.9111308469257033
Validation loss: 2.562591659643356

Epoch: 6| Step: 13
Training loss: 3.0594071321290452
Validation loss: 2.558311792421725

Epoch: 69| Step: 0
Training loss: 2.1456418245157622
Validation loss: 2.560684010324866

Epoch: 6| Step: 1
Training loss: 3.3417843183574734
Validation loss: 2.5570982622300598

Epoch: 6| Step: 2
Training loss: 2.4994205757062806
Validation loss: 2.556376949475259

Epoch: 6| Step: 3
Training loss: 2.3825435299013953
Validation loss: 2.5547035831174583

Epoch: 6| Step: 4
Training loss: 2.3010874416575424
Validation loss: 2.559555859011279

Epoch: 6| Step: 5
Training loss: 2.5889266794017862
Validation loss: 2.5574570011266853

Epoch: 6| Step: 6
Training loss: 2.8276679581220954
Validation loss: 2.55780105541654

Epoch: 6| Step: 7
Training loss: 2.5337890323893855
Validation loss: 2.5677765739818117

Epoch: 6| Step: 8
Training loss: 3.046725694959615
Validation loss: 2.5675420546066756

Epoch: 6| Step: 9
Training loss: 2.725247916046989
Validation loss: 2.5710025004203247

Epoch: 6| Step: 10
Training loss: 2.888109256822827
Validation loss: 2.5559749489493386

Epoch: 6| Step: 11
Training loss: 2.6168145212893035
Validation loss: 2.5511890375559516

Epoch: 6| Step: 12
Training loss: 3.0813004433485833
Validation loss: 2.55027300925262

Epoch: 6| Step: 13
Training loss: 2.5822320764787303
Validation loss: 2.553542764352286

Epoch: 70| Step: 0
Training loss: 2.4586897984917737
Validation loss: 2.5567124766838343

Epoch: 6| Step: 1
Training loss: 3.13441772431819
Validation loss: 2.55977575745545

Epoch: 6| Step: 2
Training loss: 2.792400766520278
Validation loss: 2.5597713177584343

Epoch: 6| Step: 3
Training loss: 2.308336479194049
Validation loss: 2.5639231691816016

Epoch: 6| Step: 4
Training loss: 2.7216034746124316
Validation loss: 2.559644721059525

Epoch: 6| Step: 5
Training loss: 2.8979358496032184
Validation loss: 2.560554448127944

Epoch: 6| Step: 6
Training loss: 2.5492190941761566
Validation loss: 2.5602569377129596

Epoch: 6| Step: 7
Training loss: 2.640406311730797
Validation loss: 2.558102874647751

Epoch: 6| Step: 8
Training loss: 2.7102044513338446
Validation loss: 2.557435838995181

Epoch: 6| Step: 9
Training loss: 2.5888277710597993
Validation loss: 2.554617597924346

Epoch: 6| Step: 10
Training loss: 2.5688636661821715
Validation loss: 2.552423592026915

Epoch: 6| Step: 11
Training loss: 2.723651545348361
Validation loss: 2.5526087524978944

Epoch: 6| Step: 12
Training loss: 2.4307148714682585
Validation loss: 2.5513404283909176

Epoch: 6| Step: 13
Training loss: 3.076192646259238
Validation loss: 2.5541169971243667

Epoch: 71| Step: 0
Training loss: 2.7374686914334507
Validation loss: 2.5548215513999364

Epoch: 6| Step: 1
Training loss: 2.0796069833945308
Validation loss: 2.553545121887248

Epoch: 6| Step: 2
Training loss: 2.507713054455946
Validation loss: 2.552390353880088

Epoch: 6| Step: 3
Training loss: 2.9466588512449343
Validation loss: 2.5578787622430794

Epoch: 6| Step: 4
Training loss: 2.777502814565309
Validation loss: 2.565087430999432

Epoch: 6| Step: 5
Training loss: 2.822761127836831
Validation loss: 2.554048168509803

Epoch: 6| Step: 6
Training loss: 2.829215161034805
Validation loss: 2.5542522063459687

Epoch: 6| Step: 7
Training loss: 2.9977798193863436
Validation loss: 2.5465087627302814

Epoch: 6| Step: 8
Training loss: 2.347496395413005
Validation loss: 2.5463090045367793

Epoch: 6| Step: 9
Training loss: 3.4695830848290314
Validation loss: 2.5469720272000393

Epoch: 6| Step: 10
Training loss: 2.788788084747283
Validation loss: 2.547098458127304

Epoch: 6| Step: 11
Training loss: 2.656302776934328
Validation loss: 2.5504503176627074

Epoch: 6| Step: 12
Training loss: 2.09485016571517
Validation loss: 2.5511565309654105

Epoch: 6| Step: 13
Training loss: 2.225812176549468
Validation loss: 2.5492940542618077

Epoch: 72| Step: 0
Training loss: 2.9222025152234106
Validation loss: 2.552201472032769

Epoch: 6| Step: 1
Training loss: 2.3356915092441
Validation loss: 2.5499221733782886

Epoch: 6| Step: 2
Training loss: 2.3979996769310716
Validation loss: 2.5489809187769414

Epoch: 6| Step: 3
Training loss: 3.323970727151263
Validation loss: 2.546461902653254

Epoch: 6| Step: 4
Training loss: 2.534277530023523
Validation loss: 2.5496892222346337

Epoch: 6| Step: 5
Training loss: 2.729933089948936
Validation loss: 2.552046535512108

Epoch: 6| Step: 6
Training loss: 2.8154638991591177
Validation loss: 2.5525355632545015

Epoch: 6| Step: 7
Training loss: 2.289334954722028
Validation loss: 2.555598463053014

Epoch: 6| Step: 8
Training loss: 2.0321579297862207
Validation loss: 2.5545581625455

Epoch: 6| Step: 9
Training loss: 3.034089950545786
Validation loss: 2.5538723857505845

Epoch: 6| Step: 10
Training loss: 2.5131939816820723
Validation loss: 2.5528650345231663

Epoch: 6| Step: 11
Training loss: 3.189833142451901
Validation loss: 2.5524683655395375

Epoch: 6| Step: 12
Training loss: 2.7558266727661938
Validation loss: 2.550062560267747

Epoch: 6| Step: 13
Training loss: 2.461615865549527
Validation loss: 2.551128478706462

Epoch: 73| Step: 0
Training loss: 2.6926850269324776
Validation loss: 2.5473304918501793

Epoch: 6| Step: 1
Training loss: 2.623794551360263
Validation loss: 2.5473754484746323

Epoch: 6| Step: 2
Training loss: 2.8468590812363663
Validation loss: 2.542291976010472

Epoch: 6| Step: 3
Training loss: 2.8346310803729655
Validation loss: 2.54094639458298

Epoch: 6| Step: 4
Training loss: 2.1075456386706293
Validation loss: 2.5395286406045923

Epoch: 6| Step: 5
Training loss: 2.8469051422298883
Validation loss: 2.542406011098858

Epoch: 6| Step: 6
Training loss: 2.2907771956400946
Validation loss: 2.5415963074581374

Epoch: 6| Step: 7
Training loss: 2.912958421771202
Validation loss: 2.541352742512622

Epoch: 6| Step: 8
Training loss: 2.467472180303415
Validation loss: 2.5421667284547746

Epoch: 6| Step: 9
Training loss: 2.474001742868881
Validation loss: 2.550982698564067

Epoch: 6| Step: 10
Training loss: 3.1416354096035715
Validation loss: 2.5513498666578305

Epoch: 6| Step: 11
Training loss: 2.761082598894847
Validation loss: 2.5562715742449043

Epoch: 6| Step: 12
Training loss: 2.3316420033777234
Validation loss: 2.5518260800202883

Epoch: 6| Step: 13
Training loss: 3.0455006165041163
Validation loss: 2.5502197052547015

Epoch: 74| Step: 0
Training loss: 2.9657889607229135
Validation loss: 2.549560831312177

Epoch: 6| Step: 1
Training loss: 2.4425239628970217
Validation loss: 2.5442905223531027

Epoch: 6| Step: 2
Training loss: 2.7760122463439902
Validation loss: 2.5444167429467845

Epoch: 6| Step: 3
Training loss: 2.3096023137978516
Validation loss: 2.5461818477328446

Epoch: 6| Step: 4
Training loss: 2.6720270481682213
Validation loss: 2.5450662848603542

Epoch: 6| Step: 5
Training loss: 3.0494086270707497
Validation loss: 2.5443211800713006

Epoch: 6| Step: 6
Training loss: 2.9852863937317804
Validation loss: 2.5453030624511306

Epoch: 6| Step: 7
Training loss: 2.4911586826276744
Validation loss: 2.54311186450745

Epoch: 6| Step: 8
Training loss: 2.72516060452124
Validation loss: 2.54003792830807

Epoch: 6| Step: 9
Training loss: 2.1850212221839045
Validation loss: 2.5395417685441397

Epoch: 6| Step: 10
Training loss: 2.7397068029702476
Validation loss: 2.5441226011504936

Epoch: 6| Step: 11
Training loss: 3.0185426818549668
Validation loss: 2.5394149770366687

Epoch: 6| Step: 12
Training loss: 2.511936492736725
Validation loss: 2.5322786682079843

Epoch: 6| Step: 13
Training loss: 2.4919360760469944
Validation loss: 2.5288938380421837

Epoch: 75| Step: 0
Training loss: 2.666102458951035
Validation loss: 2.5280784077667464

Epoch: 6| Step: 1
Training loss: 2.6553763355269187
Validation loss: 2.5275974686792813

Epoch: 6| Step: 2
Training loss: 2.705958210145251
Validation loss: 2.5274681284750464

Epoch: 6| Step: 3
Training loss: 2.8258006623866665
Validation loss: 2.5299843343619144

Epoch: 6| Step: 4
Training loss: 2.438189971300662
Validation loss: 2.5304574706880367

Epoch: 6| Step: 5
Training loss: 2.905557201215652
Validation loss: 2.5300844750857925

Epoch: 6| Step: 6
Training loss: 3.520414760169342
Validation loss: 2.5317867479188405

Epoch: 6| Step: 7
Training loss: 2.803111023798944
Validation loss: 2.5319294429698975

Epoch: 6| Step: 8
Training loss: 2.74069790715988
Validation loss: 2.5329026686447946

Epoch: 6| Step: 9
Training loss: 2.1180575789422824
Validation loss: 2.532063278973372

Epoch: 6| Step: 10
Training loss: 2.331682393164381
Validation loss: 2.5313141426153996

Epoch: 6| Step: 11
Training loss: 2.245963184044759
Validation loss: 2.531574793570212

Epoch: 6| Step: 12
Training loss: 2.7577096201264535
Validation loss: 2.5298064240243505

Epoch: 6| Step: 13
Training loss: 2.220198252649275
Validation loss: 2.5323792752471284

Epoch: 76| Step: 0
Training loss: 3.017974254692996
Validation loss: 2.530818635581552

Epoch: 6| Step: 1
Training loss: 2.6435120279331796
Validation loss: 2.5280190400440734

Epoch: 6| Step: 2
Training loss: 2.5734825181295022
Validation loss: 2.526827461222601

Epoch: 6| Step: 3
Training loss: 1.7542397366827356
Validation loss: 2.5243069673371306

Epoch: 6| Step: 4
Training loss: 2.3830098054838604
Validation loss: 2.5218513629472112

Epoch: 6| Step: 5
Training loss: 2.7420576015908007
Validation loss: 2.522890517847164

Epoch: 6| Step: 6
Training loss: 3.1865898777742485
Validation loss: 2.522537527621193

Epoch: 6| Step: 7
Training loss: 2.72244485173973
Validation loss: 2.526989416236386

Epoch: 6| Step: 8
Training loss: 2.6282164531676093
Validation loss: 2.525238567513607

Epoch: 6| Step: 9
Training loss: 2.602308561556131
Validation loss: 2.5221870402637916

Epoch: 6| Step: 10
Training loss: 2.9272261796262775
Validation loss: 2.5232770177871955

Epoch: 6| Step: 11
Training loss: 2.7394082094408017
Validation loss: 2.518933807431169

Epoch: 6| Step: 12
Training loss: 2.506031295099936
Validation loss: 2.5240947233643727

Epoch: 6| Step: 13
Training loss: 2.4787147387883546
Validation loss: 2.5204238769239766

Epoch: 77| Step: 0
Training loss: 2.841154150363533
Validation loss: 2.5230996424386882

Epoch: 6| Step: 1
Training loss: 2.6200158166771956
Validation loss: 2.5203351613598843

Epoch: 6| Step: 2
Training loss: 2.269447837255342
Validation loss: 2.519512229670212

Epoch: 6| Step: 3
Training loss: 2.6728917022355922
Validation loss: 2.5192332325615507

Epoch: 6| Step: 4
Training loss: 2.7875037873246673
Validation loss: 2.518618900998562

Epoch: 6| Step: 5
Training loss: 3.0678118357444433
Validation loss: 2.5167592494768485

Epoch: 6| Step: 6
Training loss: 2.1716510465132894
Validation loss: 2.5170840500408187

Epoch: 6| Step: 7
Training loss: 2.7015794514112663
Validation loss: 2.5179260344969934

Epoch: 6| Step: 8
Training loss: 2.7832065515329782
Validation loss: 2.5160322471779883

Epoch: 6| Step: 9
Training loss: 2.6774403572741363
Validation loss: 2.505929432041044

Epoch: 6| Step: 10
Training loss: 2.688910712879544
Validation loss: 2.5125805299420287

Epoch: 6| Step: 11
Training loss: 2.643826862778022
Validation loss: 2.514918984485382

Epoch: 6| Step: 12
Training loss: 2.5684105233440704
Validation loss: 2.515800580517747

Epoch: 6| Step: 13
Training loss: 2.423930815335739
Validation loss: 2.513782244879704

Epoch: 78| Step: 0
Training loss: 2.541345127800187
Validation loss: 2.5160868439931683

Epoch: 6| Step: 1
Training loss: 2.976693858855106
Validation loss: 2.5153087788419763

Epoch: 6| Step: 2
Training loss: 2.7412199829517663
Validation loss: 2.5174802016812237

Epoch: 6| Step: 3
Training loss: 2.1544418493688826
Validation loss: 2.516110343790736

Epoch: 6| Step: 4
Training loss: 2.170283221383063
Validation loss: 2.5165607615370575

Epoch: 6| Step: 5
Training loss: 2.7123986080222924
Validation loss: 2.5190120822555655

Epoch: 6| Step: 6
Training loss: 2.483210164627675
Validation loss: 2.5126432513998758

Epoch: 6| Step: 7
Training loss: 2.7994311708579467
Validation loss: 2.510486781195093

Epoch: 6| Step: 8
Training loss: 2.4992349407676846
Validation loss: 2.5103462863622212

Epoch: 6| Step: 9
Training loss: 2.742927299323217
Validation loss: 2.508811553620639

Epoch: 6| Step: 10
Training loss: 2.738874036590907
Validation loss: 2.513096852050443

Epoch: 6| Step: 11
Training loss: 2.9914887810174258
Validation loss: 2.50855626755722

Epoch: 6| Step: 12
Training loss: 2.498775086727798
Validation loss: 2.5039620633780832

Epoch: 6| Step: 13
Training loss: 2.796974393474396
Validation loss: 2.5050375332307895

Epoch: 79| Step: 0
Training loss: 2.79908877940574
Validation loss: 2.505297420659823

Epoch: 6| Step: 1
Training loss: 2.3486248944123282
Validation loss: 2.5017353392885213

Epoch: 6| Step: 2
Training loss: 2.7360059833070793
Validation loss: 2.500086671598396

Epoch: 6| Step: 3
Training loss: 2.0295736584882778
Validation loss: 2.5008396963741713

Epoch: 6| Step: 4
Training loss: 3.516203158839921
Validation loss: 2.5024136494903715

Epoch: 6| Step: 5
Training loss: 2.1827443335449432
Validation loss: 2.5060580604222715

Epoch: 6| Step: 6
Training loss: 2.2002704064040874
Validation loss: 2.5061308073777284

Epoch: 6| Step: 7
Training loss: 2.4997001468125353
Validation loss: 2.5086500407250982

Epoch: 6| Step: 8
Training loss: 2.4721223034710667
Validation loss: 2.5047952280973997

Epoch: 6| Step: 9
Training loss: 2.8198225700076347
Validation loss: 2.505349935758123

Epoch: 6| Step: 10
Training loss: 2.592824655950087
Validation loss: 2.505644830967969

Epoch: 6| Step: 11
Training loss: 2.957527229912487
Validation loss: 2.508567767630915

Epoch: 6| Step: 12
Training loss: 2.9917517760628463
Validation loss: 2.5068207995308502

Epoch: 6| Step: 13
Training loss: 2.430479650371832
Validation loss: 2.5111220913293435

Epoch: 80| Step: 0
Training loss: 2.709475252085281
Validation loss: 2.5073482761138957

Epoch: 6| Step: 1
Training loss: 2.7326822327264093
Validation loss: 2.5101716698937624

Epoch: 6| Step: 2
Training loss: 2.3585078180509846
Validation loss: 2.513073830053969

Epoch: 6| Step: 3
Training loss: 2.3554566036689315
Validation loss: 2.5083026981278365

Epoch: 6| Step: 4
Training loss: 3.3811394692792214
Validation loss: 2.5098022299940825

Epoch: 6| Step: 5
Training loss: 2.7220386477830205
Validation loss: 2.509296631687886

Epoch: 6| Step: 6
Training loss: 2.5248590486673126
Validation loss: 2.503829105833315

Epoch: 6| Step: 7
Training loss: 2.8897396897027186
Validation loss: 2.5052573476161544

Epoch: 6| Step: 8
Training loss: 2.677811391266847
Validation loss: 2.506403272576402

Epoch: 6| Step: 9
Training loss: 2.404862040728433
Validation loss: 2.5026347263996263

Epoch: 6| Step: 10
Training loss: 2.150631425975987
Validation loss: 2.5012026754970447

Epoch: 6| Step: 11
Training loss: 2.612779235518594
Validation loss: 2.5039753936568103

Epoch: 6| Step: 12
Training loss: 2.23883465221878
Validation loss: 2.505601266564755

Epoch: 6| Step: 13
Training loss: 2.927986811060984
Validation loss: 2.512241117383957

Epoch: 81| Step: 0
Training loss: 2.558554799023647
Validation loss: 2.511031907749247

Epoch: 6| Step: 1
Training loss: 2.4950967388472245
Validation loss: 2.5115723594455237

Epoch: 6| Step: 2
Training loss: 2.1375167444476757
Validation loss: 2.5156047180495476

Epoch: 6| Step: 3
Training loss: 2.5220059801616146
Validation loss: 2.509871163728211

Epoch: 6| Step: 4
Training loss: 2.703384034198368
Validation loss: 2.506794898332877

Epoch: 6| Step: 5
Training loss: 3.0093831506858404
Validation loss: 2.506342995076515

Epoch: 6| Step: 6
Training loss: 2.219603038729253
Validation loss: 2.5098146109741957

Epoch: 6| Step: 7
Training loss: 2.384090893619219
Validation loss: 2.5104191148252673

Epoch: 6| Step: 8
Training loss: 2.527056764702528
Validation loss: 2.4960746306720405

Epoch: 6| Step: 9
Training loss: 3.0007661794747347
Validation loss: 2.5039702202475405

Epoch: 6| Step: 10
Training loss: 3.048891153606591
Validation loss: 2.503977266237899

Epoch: 6| Step: 11
Training loss: 2.6133232170350333
Validation loss: 2.5006872662965574

Epoch: 6| Step: 12
Training loss: 2.4259884265142433
Validation loss: 2.5055851695877966

Epoch: 6| Step: 13
Training loss: 2.862714807704649
Validation loss: 2.4992968285620734

Epoch: 82| Step: 0
Training loss: 2.525643627359544
Validation loss: 2.4990762990946056

Epoch: 6| Step: 1
Training loss: 3.05245601388043
Validation loss: 2.497339470114282

Epoch: 6| Step: 2
Training loss: 3.0085457836875187
Validation loss: 2.4971731813933893

Epoch: 6| Step: 3
Training loss: 2.272476884747439
Validation loss: 2.4950861640887703

Epoch: 6| Step: 4
Training loss: 1.822356684822911
Validation loss: 2.496250567537236

Epoch: 6| Step: 5
Training loss: 2.1576198704594867
Validation loss: 2.496698981722357

Epoch: 6| Step: 6
Training loss: 2.600223964435019
Validation loss: 2.497885906888054

Epoch: 6| Step: 7
Training loss: 2.5112323200976308
Validation loss: 2.5028148698710204

Epoch: 6| Step: 8
Training loss: 2.733153413650622
Validation loss: 2.502859927527572

Epoch: 6| Step: 9
Training loss: 3.089387225775709
Validation loss: 2.5084224921652334

Epoch: 6| Step: 10
Training loss: 2.63938107055573
Validation loss: 2.512015064691415

Epoch: 6| Step: 11
Training loss: 2.4556968473786798
Validation loss: 2.5040209541094054

Epoch: 6| Step: 12
Training loss: 3.053315071428928
Validation loss: 2.499660564267468

Epoch: 6| Step: 13
Training loss: 2.510295933607408
Validation loss: 2.4966330425746825

Epoch: 83| Step: 0
Training loss: 2.4240427467807195
Validation loss: 2.497559238109338

Epoch: 6| Step: 1
Training loss: 2.943743624346201
Validation loss: 2.4968763387244386

Epoch: 6| Step: 2
Training loss: 2.8129259422743376
Validation loss: 2.499449367283289

Epoch: 6| Step: 3
Training loss: 2.531918096088476
Validation loss: 2.4992877899393053

Epoch: 6| Step: 4
Training loss: 2.6111851426940738
Validation loss: 2.494654153260667

Epoch: 6| Step: 5
Training loss: 2.576324759133904
Validation loss: 2.4910045275581303

Epoch: 6| Step: 6
Training loss: 2.1701861065284227
Validation loss: 2.4952538818022405

Epoch: 6| Step: 7
Training loss: 2.624720058954558
Validation loss: 2.496200025959543

Epoch: 6| Step: 8
Training loss: 2.2801056173188887
Validation loss: 2.4885333306316784

Epoch: 6| Step: 9
Training loss: 2.5369707617362365
Validation loss: 2.489147313028588

Epoch: 6| Step: 10
Training loss: 2.8595812780465595
Validation loss: 2.486042015233153

Epoch: 6| Step: 11
Training loss: 2.6960572029406795
Validation loss: 2.4807576249085623

Epoch: 6| Step: 12
Training loss: 2.7100914946028394
Validation loss: 2.4843857003227456

Epoch: 6| Step: 13
Training loss: 2.534789448257403
Validation loss: 2.4846518340309887

Epoch: 84| Step: 0
Training loss: 2.593261672781138
Validation loss: 2.4827400601868295

Epoch: 6| Step: 1
Training loss: 2.8887616724548497
Validation loss: 2.485928287804728

Epoch: 6| Step: 2
Training loss: 3.1289152414333197
Validation loss: 2.4830686945580105

Epoch: 6| Step: 3
Training loss: 2.4460109895286193
Validation loss: 2.484860770599742

Epoch: 6| Step: 4
Training loss: 3.106420906016587
Validation loss: 2.488998732834592

Epoch: 6| Step: 5
Training loss: 2.4651078990975455
Validation loss: 2.4861289177037276

Epoch: 6| Step: 6
Training loss: 2.9774991861978055
Validation loss: 2.481329869058655

Epoch: 6| Step: 7
Training loss: 2.2896976566206577
Validation loss: 2.480497553300205

Epoch: 6| Step: 8
Training loss: 2.359091937535473
Validation loss: 2.4853507470989578

Epoch: 6| Step: 9
Training loss: 2.1402188772053647
Validation loss: 2.4829693862517015

Epoch: 6| Step: 10
Training loss: 2.1080621095081487
Validation loss: 2.4856977799947577

Epoch: 6| Step: 11
Training loss: 2.546176463560145
Validation loss: 2.4830795365345164

Epoch: 6| Step: 12
Training loss: 2.5532911491727392
Validation loss: 2.4855797363743606

Epoch: 6| Step: 13
Training loss: 2.5284722239451165
Validation loss: 2.484285077081083

Epoch: 85| Step: 0
Training loss: 3.1859474140815585
Validation loss: 2.48372057726602

Epoch: 6| Step: 1
Training loss: 2.242545813663434
Validation loss: 2.490497586171338

Epoch: 6| Step: 2
Training loss: 2.8737229537852644
Validation loss: 2.4835489847221384

Epoch: 6| Step: 3
Training loss: 2.507424107598272
Validation loss: 2.4830678944102673

Epoch: 6| Step: 4
Training loss: 2.4755503033061594
Validation loss: 2.484508558797882

Epoch: 6| Step: 5
Training loss: 2.36648508861816
Validation loss: 2.4829432922572776

Epoch: 6| Step: 6
Training loss: 2.6591939431942064
Validation loss: 2.4839157383756274

Epoch: 6| Step: 7
Training loss: 2.0017959160834646
Validation loss: 2.48537998945146

Epoch: 6| Step: 8
Training loss: 2.4107251848246922
Validation loss: 2.484806367223982

Epoch: 6| Step: 9
Training loss: 2.5562263543637234
Validation loss: 2.482688027157181

Epoch: 6| Step: 10
Training loss: 2.891833243578715
Validation loss: 2.486868177137581

Epoch: 6| Step: 11
Training loss: 2.405207023989218
Validation loss: 2.4792225187619232

Epoch: 6| Step: 12
Training loss: 2.801604124782277
Validation loss: 2.4854247476510873

Epoch: 6| Step: 13
Training loss: 2.69146994195659
Validation loss: 2.4882621664595996

Epoch: 86| Step: 0
Training loss: 2.8578737413988993
Validation loss: 2.48818093601196

Epoch: 6| Step: 1
Training loss: 2.225933427786861
Validation loss: 2.486625459826464

Epoch: 6| Step: 2
Training loss: 2.4489640829023407
Validation loss: 2.4876854231589602

Epoch: 6| Step: 3
Training loss: 2.2990209195586098
Validation loss: 2.484513764734613

Epoch: 6| Step: 4
Training loss: 2.4000640224818417
Validation loss: 2.487849782507757

Epoch: 6| Step: 5
Training loss: 2.3289401272341577
Validation loss: 2.4829812448853072

Epoch: 6| Step: 6
Training loss: 2.9776308240103706
Validation loss: 2.489231185800609

Epoch: 6| Step: 7
Training loss: 2.852291149948958
Validation loss: 2.4809603306618815

Epoch: 6| Step: 8
Training loss: 2.7287499689651744
Validation loss: 2.4842374591621543

Epoch: 6| Step: 9
Training loss: 2.4666411651977067
Validation loss: 2.4786933211968885

Epoch: 6| Step: 10
Training loss: 2.438625173810499
Validation loss: 2.4835741843698553

Epoch: 6| Step: 11
Training loss: 2.789078570835177
Validation loss: 2.4851104959167283

Epoch: 6| Step: 12
Training loss: 2.4879368614084605
Validation loss: 2.4823543080184423

Epoch: 6| Step: 13
Training loss: 2.885060330822874
Validation loss: 2.4806939771229244

Epoch: 87| Step: 0
Training loss: 2.5692131683005015
Validation loss: 2.4801905037918526

Epoch: 6| Step: 1
Training loss: 2.4933241401679678
Validation loss: 2.4845866786898654

Epoch: 6| Step: 2
Training loss: 3.0238358582650435
Validation loss: 2.4898610352545676

Epoch: 6| Step: 3
Training loss: 2.487237109377178
Validation loss: 2.4869830119850564

Epoch: 6| Step: 4
Training loss: 2.6800686312186097
Validation loss: 2.4847186988429826

Epoch: 6| Step: 5
Training loss: 2.446785869899458
Validation loss: 2.488832006580266

Epoch: 6| Step: 6
Training loss: 2.4927313040920867
Validation loss: 2.489355361481746

Epoch: 6| Step: 7
Training loss: 2.593176537050096
Validation loss: 2.4878941289208534

Epoch: 6| Step: 8
Training loss: 2.7318359793915774
Validation loss: 2.483991101431764

Epoch: 6| Step: 9
Training loss: 1.7711156358279498
Validation loss: 2.486734625226065

Epoch: 6| Step: 10
Training loss: 2.7725410839507543
Validation loss: 2.4877178646252527

Epoch: 6| Step: 11
Training loss: 2.7013858205673804
Validation loss: 2.48328919744847

Epoch: 6| Step: 12
Training loss: 2.3236512076239806
Validation loss: 2.4826969421523177

Epoch: 6| Step: 13
Training loss: 3.074287772464114
Validation loss: 2.485084160569931

Epoch: 88| Step: 0
Training loss: 2.5497996382442345
Validation loss: 2.4826906360369887

Epoch: 6| Step: 1
Training loss: 2.8306881580815686
Validation loss: 2.4877074262183267

Epoch: 6| Step: 2
Training loss: 2.1952679721212593
Validation loss: 2.4917146240093047

Epoch: 6| Step: 3
Training loss: 2.6812494913736495
Validation loss: 2.4821705984883065

Epoch: 6| Step: 4
Training loss: 1.9133303740718877
Validation loss: 2.4835068247397776

Epoch: 6| Step: 5
Training loss: 2.881948615585638
Validation loss: 2.482531257258462

Epoch: 6| Step: 6
Training loss: 2.374978818297043
Validation loss: 2.479590713608795

Epoch: 6| Step: 7
Training loss: 2.764248349080503
Validation loss: 2.4819920785814924

Epoch: 6| Step: 8
Training loss: 2.3337214237991057
Validation loss: 2.4835849521413538

Epoch: 6| Step: 9
Training loss: 2.5685699028496765
Validation loss: 2.484008250167013

Epoch: 6| Step: 10
Training loss: 2.8378953297018814
Validation loss: 2.484056496346781

Epoch: 6| Step: 11
Training loss: 2.2804246219287383
Validation loss: 2.478567841813733

Epoch: 6| Step: 12
Training loss: 2.8824862990835354
Validation loss: 2.480333363600392

Epoch: 6| Step: 13
Training loss: 2.9669424878889092
Validation loss: 2.480897761212963

Epoch: 89| Step: 0
Training loss: 2.454638069184477
Validation loss: 2.480660658894274

Epoch: 6| Step: 1
Training loss: 3.17494496575665
Validation loss: 2.4763791149766896

Epoch: 6| Step: 2
Training loss: 2.3693241762160686
Validation loss: 2.4848393899912575

Epoch: 6| Step: 3
Training loss: 2.658294339825757
Validation loss: 2.4818519880562775

Epoch: 6| Step: 4
Training loss: 2.7244206188816817
Validation loss: 2.479186728473776

Epoch: 6| Step: 5
Training loss: 2.4807872657825474
Validation loss: 2.484432739610497

Epoch: 6| Step: 6
Training loss: 2.052622638713811
Validation loss: 2.4838570108768696

Epoch: 6| Step: 7
Training loss: 2.2016715808537306
Validation loss: 2.485549233400644

Epoch: 6| Step: 8
Training loss: 2.3952844626819436
Validation loss: 2.4867476483710353

Epoch: 6| Step: 9
Training loss: 2.3306665053371196
Validation loss: 2.4891944060064

Epoch: 6| Step: 10
Training loss: 2.935572864572244
Validation loss: 2.48088883174402

Epoch: 6| Step: 11
Training loss: 2.888174471997958
Validation loss: 2.4784719364613466

Epoch: 6| Step: 12
Training loss: 2.8442563455032577
Validation loss: 2.477120482024771

Epoch: 6| Step: 13
Training loss: 2.5457146932758485
Validation loss: 2.4766150788864

Epoch: 90| Step: 0
Training loss: 2.5483477494218962
Validation loss: 2.4800458252169832

Epoch: 6| Step: 1
Training loss: 2.377158138113372
Validation loss: 2.4834503436417465

Epoch: 6| Step: 2
Training loss: 2.2994557109830276
Validation loss: 2.4828017269578595

Epoch: 6| Step: 3
Training loss: 3.1730505357547667
Validation loss: 2.479170716440008

Epoch: 6| Step: 4
Training loss: 2.442561640669328
Validation loss: 2.4805743658053405

Epoch: 6| Step: 5
Training loss: 2.1308546756793967
Validation loss: 2.4820211203591263

Epoch: 6| Step: 6
Training loss: 2.4667817973856314
Validation loss: 2.486356301059377

Epoch: 6| Step: 7
Training loss: 3.1622716285966557
Validation loss: 2.4818261464944196

Epoch: 6| Step: 8
Training loss: 2.5284229079464184
Validation loss: 2.4856833125989395

Epoch: 6| Step: 9
Training loss: 2.755695946468613
Validation loss: 2.48768981579979

Epoch: 6| Step: 10
Training loss: 2.2901115227075706
Validation loss: 2.4843423229443706

Epoch: 6| Step: 11
Training loss: 2.6994346167977863
Validation loss: 2.4866329464743973

Epoch: 6| Step: 12
Training loss: 2.4472058068931397
Validation loss: 2.4862433551682273

Epoch: 6| Step: 13
Training loss: 2.7491388706614814
Validation loss: 2.4847569841749286

Epoch: 91| Step: 0
Training loss: 2.9039983743500164
Validation loss: 2.488713105721944

Epoch: 6| Step: 1
Training loss: 1.9591487918213035
Validation loss: 2.489134653645659

Epoch: 6| Step: 2
Training loss: 2.4421389525524995
Validation loss: 2.484913845526015

Epoch: 6| Step: 3
Training loss: 2.406542475376451
Validation loss: 2.4865496892064924

Epoch: 6| Step: 4
Training loss: 3.0600195980067753
Validation loss: 2.487791211767453

Epoch: 6| Step: 5
Training loss: 2.8382404319207435
Validation loss: 2.485948452225078

Epoch: 6| Step: 6
Training loss: 2.503288490394944
Validation loss: 2.4862515382041157

Epoch: 6| Step: 7
Training loss: 3.327201894336848
Validation loss: 2.483063277552752

Epoch: 6| Step: 8
Training loss: 2.0704364091752434
Validation loss: 2.4848683984910793

Epoch: 6| Step: 9
Training loss: 2.816210101065527
Validation loss: 2.484312940418208

Epoch: 6| Step: 10
Training loss: 2.9495563238094333
Validation loss: 2.487543640520679

Epoch: 6| Step: 11
Training loss: 2.0572528561822487
Validation loss: 2.482275525572998

Epoch: 6| Step: 12
Training loss: 2.236833087265213
Validation loss: 2.48282554179712

Epoch: 6| Step: 13
Training loss: 2.305062783931538
Validation loss: 2.4876594505132132

Epoch: 92| Step: 0
Training loss: 2.27758484180928
Validation loss: 2.483496016629043

Epoch: 6| Step: 1
Training loss: 2.6879841568003098
Validation loss: 2.482416000379269

Epoch: 6| Step: 2
Training loss: 2.5114599779825877
Validation loss: 2.489514311361719

Epoch: 6| Step: 3
Training loss: 2.4696413193634763
Validation loss: 2.492335730661679

Epoch: 6| Step: 4
Training loss: 3.0008987034319032
Validation loss: 2.4916096877490665

Epoch: 6| Step: 5
Training loss: 2.847139120569102
Validation loss: 2.489810531549424

Epoch: 6| Step: 6
Training loss: 2.6718401990263754
Validation loss: 2.4912136810100205

Epoch: 6| Step: 7
Training loss: 2.3138019917405255
Validation loss: 2.484695253983402

Epoch: 6| Step: 8
Training loss: 2.9145860789688043
Validation loss: 2.4777656304223705

Epoch: 6| Step: 9
Training loss: 2.0825513007724736
Validation loss: 2.472114459438227

Epoch: 6| Step: 10
Training loss: 3.3044150670802352
Validation loss: 2.470812406874798

Epoch: 6| Step: 11
Training loss: 2.578789642665366
Validation loss: 2.469634127140919

Epoch: 6| Step: 12
Training loss: 1.9352375480074837
Validation loss: 2.468720431895181

Epoch: 6| Step: 13
Training loss: 2.426009457675899
Validation loss: 2.46720482157996

Epoch: 93| Step: 0
Training loss: 2.3702829599268584
Validation loss: 2.462854629644815

Epoch: 6| Step: 1
Training loss: 2.7445906409253245
Validation loss: 2.4691737974151664

Epoch: 6| Step: 2
Training loss: 2.9909882295989747
Validation loss: 2.46673744997929

Epoch: 6| Step: 3
Training loss: 2.947428542703497
Validation loss: 2.466849951979747

Epoch: 6| Step: 4
Training loss: 2.340285729137865
Validation loss: 2.464064517732938

Epoch: 6| Step: 5
Training loss: 2.8315092460727906
Validation loss: 2.4627434940946005

Epoch: 6| Step: 6
Training loss: 2.4373830131431515
Validation loss: 2.463226771374818

Epoch: 6| Step: 7
Training loss: 2.0582002846449727
Validation loss: 2.4647367346374685

Epoch: 6| Step: 8
Training loss: 2.454560072691573
Validation loss: 2.463550193938538

Epoch: 6| Step: 9
Training loss: 2.3770800065316253
Validation loss: 2.46389508820616

Epoch: 6| Step: 10
Training loss: 2.310846510843956
Validation loss: 2.457621783928513

Epoch: 6| Step: 11
Training loss: 2.6785368381264956
Validation loss: 2.4606095352830226

Epoch: 6| Step: 12
Training loss: 2.720006279797878
Validation loss: 2.466341509738153

Epoch: 6| Step: 13
Training loss: 2.5825129303511547
Validation loss: 2.4591913396238985

Epoch: 94| Step: 0
Training loss: 2.9959330012083867
Validation loss: 2.4659696930309223

Epoch: 6| Step: 1
Training loss: 2.797037301069512
Validation loss: 2.4660731422052953

Epoch: 6| Step: 2
Training loss: 2.8477724572268146
Validation loss: 2.4647617800020583

Epoch: 6| Step: 3
Training loss: 2.7734078419133867
Validation loss: 2.4691291550117067

Epoch: 6| Step: 4
Training loss: 1.7215788709492592
Validation loss: 2.466100196187847

Epoch: 6| Step: 5
Training loss: 2.593668649156054
Validation loss: 2.4624178193348802

Epoch: 6| Step: 6
Training loss: 2.7027989891015354
Validation loss: 2.4658932474258903

Epoch: 6| Step: 7
Training loss: 2.289487311097085
Validation loss: 2.4667755150191115

Epoch: 6| Step: 8
Training loss: 2.489522627299201
Validation loss: 2.468418952217674

Epoch: 6| Step: 9
Training loss: 2.603676243697482
Validation loss: 2.464452810262766

Epoch: 6| Step: 10
Training loss: 2.652054648732428
Validation loss: 2.46413482772732

Epoch: 6| Step: 11
Training loss: 2.1312216390473453
Validation loss: 2.4698721673192634

Epoch: 6| Step: 12
Training loss: 2.536308884705582
Validation loss: 2.470430679277259

Epoch: 6| Step: 13
Training loss: 2.65908428893788
Validation loss: 2.469932562644914

Epoch: 95| Step: 0
Training loss: 2.8218697346144985
Validation loss: 2.4687259849957686

Epoch: 6| Step: 1
Training loss: 2.303058009422078
Validation loss: 2.470662241561037

Epoch: 6| Step: 2
Training loss: 1.9879677156210158
Validation loss: 2.4689310385723435

Epoch: 6| Step: 3
Training loss: 2.7713744321150395
Validation loss: 2.4700542497533218

Epoch: 6| Step: 4
Training loss: 2.218804694562711
Validation loss: 2.4687861991192084

Epoch: 6| Step: 5
Training loss: 2.511308651396344
Validation loss: 2.480440378902914

Epoch: 6| Step: 6
Training loss: 2.139646766066497
Validation loss: 2.4799312940432543

Epoch: 6| Step: 7
Training loss: 3.1444405678888816
Validation loss: 2.4870728613228823

Epoch: 6| Step: 8
Training loss: 2.09590220505672
Validation loss: 2.4761040360477073

Epoch: 6| Step: 9
Training loss: 2.572767019102686
Validation loss: 2.4739477110517574

Epoch: 6| Step: 10
Training loss: 2.89692224754148
Validation loss: 2.473584700361372

Epoch: 6| Step: 11
Training loss: 2.8034318328619845
Validation loss: 2.4751275976922047

Epoch: 6| Step: 12
Training loss: 2.6478793025788376
Validation loss: 2.4772350068066746

Epoch: 6| Step: 13
Training loss: 2.9415223198795566
Validation loss: 2.4760550411271316

Epoch: 96| Step: 0
Training loss: 2.365843539303861
Validation loss: 2.477809235193035

Epoch: 6| Step: 1
Training loss: 2.7422980044452365
Validation loss: 2.474134825718627

Epoch: 6| Step: 2
Training loss: 2.9196640053879332
Validation loss: 2.4759775588087316

Epoch: 6| Step: 3
Training loss: 2.7897271398200285
Validation loss: 2.4763423047617183

Epoch: 6| Step: 4
Training loss: 2.5013965520671366
Validation loss: 2.477118011651088

Epoch: 6| Step: 5
Training loss: 2.466289984663634
Validation loss: 2.4790631334073265

Epoch: 6| Step: 6
Training loss: 2.619917900022145
Validation loss: 2.4815014389077983

Epoch: 6| Step: 7
Training loss: 2.6778862685425113
Validation loss: 2.485264792735695

Epoch: 6| Step: 8
Training loss: 2.4460045563412867
Validation loss: 2.4856319646535523

Epoch: 6| Step: 9
Training loss: 2.0242508244154145
Validation loss: 2.486245704597303

Epoch: 6| Step: 10
Training loss: 2.246726515828366
Validation loss: 2.4865690815274264

Epoch: 6| Step: 11
Training loss: 2.6558435465681436
Validation loss: 2.479173232852564

Epoch: 6| Step: 12
Training loss: 3.237105244610539
Validation loss: 2.475920456575621

Epoch: 6| Step: 13
Training loss: 2.493622847831356
Validation loss: 2.472721783983374

Epoch: 97| Step: 0
Training loss: 2.1344362442814027
Validation loss: 2.4733485919382328

Epoch: 6| Step: 1
Training loss: 2.907894202657252
Validation loss: 2.4767533638909724

Epoch: 6| Step: 2
Training loss: 2.359109219366269
Validation loss: 2.4737972702334106

Epoch: 6| Step: 3
Training loss: 1.9569008911330397
Validation loss: 2.4755973339131994

Epoch: 6| Step: 4
Training loss: 2.6448345151307215
Validation loss: 2.470018664455552

Epoch: 6| Step: 5
Training loss: 3.132197521855537
Validation loss: 2.469742394423356

Epoch: 6| Step: 6
Training loss: 2.421615488238374
Validation loss: 2.4719537638040747

Epoch: 6| Step: 7
Training loss: 2.6002941992177253
Validation loss: 2.4653736155571386

Epoch: 6| Step: 8
Training loss: 2.4895405359992235
Validation loss: 2.4731959858217816

Epoch: 6| Step: 9
Training loss: 2.8271394983127243
Validation loss: 2.484420168164152

Epoch: 6| Step: 10
Training loss: 2.245985900943354
Validation loss: 2.48556229473029

Epoch: 6| Step: 11
Training loss: 2.841403202435986
Validation loss: 2.480634740847346

Epoch: 6| Step: 12
Training loss: 2.4620583539999568
Validation loss: 2.4885762038348536

Epoch: 6| Step: 13
Training loss: 2.861496602068558
Validation loss: 2.4753118540104797

Epoch: 98| Step: 0
Training loss: 2.5669140828596033
Validation loss: 2.463567460767193

Epoch: 6| Step: 1
Training loss: 2.6716075562593145
Validation loss: 2.463100504068954

Epoch: 6| Step: 2
Training loss: 2.5101170868939544
Validation loss: 2.462681615493227

Epoch: 6| Step: 3
Training loss: 3.0245040865375636
Validation loss: 2.466649348825371

Epoch: 6| Step: 4
Training loss: 2.0992603952346482
Validation loss: 2.4689905878327694

Epoch: 6| Step: 5
Training loss: 2.822156815592797
Validation loss: 2.4702258627890146

Epoch: 6| Step: 6
Training loss: 2.9148759703643345
Validation loss: 2.4662727288399005

Epoch: 6| Step: 7
Training loss: 2.2827467515316755
Validation loss: 2.4708549764456142

Epoch: 6| Step: 8
Training loss: 2.5653733681841473
Validation loss: 2.4702794773533445

Epoch: 6| Step: 9
Training loss: 2.2396158496950593
Validation loss: 2.473133814425407

Epoch: 6| Step: 10
Training loss: 2.8633881636118943
Validation loss: 2.4687551345449883

Epoch: 6| Step: 11
Training loss: 2.583597005698451
Validation loss: 2.4668443141150163

Epoch: 6| Step: 12
Training loss: 2.4223510274363766
Validation loss: 2.4668177354363006

Epoch: 6| Step: 13
Training loss: 2.2251282472832683
Validation loss: 2.4675398568744904

Epoch: 99| Step: 0
Training loss: 2.931208264149339
Validation loss: 2.4651557575767025

Epoch: 6| Step: 1
Training loss: 2.16685069354134
Validation loss: 2.4646178483091328

Epoch: 6| Step: 2
Training loss: 2.655227284733597
Validation loss: 2.4710416499082855

Epoch: 6| Step: 3
Training loss: 2.7272249745031956
Validation loss: 2.4698892853771963

Epoch: 6| Step: 4
Training loss: 2.5322390849152865
Validation loss: 2.4692449113866064

Epoch: 6| Step: 5
Training loss: 2.3966843351403475
Validation loss: 2.469562557753729

Epoch: 6| Step: 6
Training loss: 2.3191576822947333
Validation loss: 2.4700918775914564

Epoch: 6| Step: 7
Training loss: 2.346647175830758
Validation loss: 2.47169880261133

Epoch: 6| Step: 8
Training loss: 3.0610790459472144
Validation loss: 2.46829650834265

Epoch: 6| Step: 9
Training loss: 2.1365120908116975
Validation loss: 2.4717910160758985

Epoch: 6| Step: 10
Training loss: 2.8504728560775425
Validation loss: 2.4670153450892607

Epoch: 6| Step: 11
Training loss: 2.5761309686266127
Validation loss: 2.4691975988569914

Epoch: 6| Step: 12
Training loss: 2.926585597462911
Validation loss: 2.4668949738943775

Epoch: 6| Step: 13
Training loss: 2.075346501845455
Validation loss: 2.465952547764109

Epoch: 100| Step: 0
Training loss: 2.186968275568323
Validation loss: 2.4683735073494173

Epoch: 6| Step: 1
Training loss: 2.0564289328225063
Validation loss: 2.467932779119027

Epoch: 6| Step: 2
Training loss: 1.9594137038890693
Validation loss: 2.4723225429149087

Epoch: 6| Step: 3
Training loss: 2.471212486866097
Validation loss: 2.4706370067167978

Epoch: 6| Step: 4
Training loss: 2.8324634301164027
Validation loss: 2.475173785469405

Epoch: 6| Step: 5
Training loss: 2.971355379167332
Validation loss: 2.4731032864846

Epoch: 6| Step: 6
Training loss: 2.460113871970467
Validation loss: 2.4744266561981156

Epoch: 6| Step: 7
Training loss: 2.837448012089997
Validation loss: 2.4766067516974317

Epoch: 6| Step: 8
Training loss: 2.449099402432577
Validation loss: 2.4783827773880414

Epoch: 6| Step: 9
Training loss: 2.669066978051543
Validation loss: 2.4761825253984293

Epoch: 6| Step: 10
Training loss: 2.8580574377012975
Validation loss: 2.4749261401936953

Epoch: 6| Step: 11
Training loss: 3.147555016967752
Validation loss: 2.4713337732940164

Epoch: 6| Step: 12
Training loss: 1.9183176504113282
Validation loss: 2.4730582651179187

Epoch: 6| Step: 13
Training loss: 2.692037433641742
Validation loss: 2.473592820856423

Epoch: 101| Step: 0
Training loss: 2.5853672839501782
Validation loss: 2.4701575439547545

Epoch: 6| Step: 1
Training loss: 1.94374309182856
Validation loss: 2.4664138653661487

Epoch: 6| Step: 2
Training loss: 2.7979199892101505
Validation loss: 2.466691571402048

Epoch: 6| Step: 3
Training loss: 2.124304713775256
Validation loss: 2.4634979491491436

Epoch: 6| Step: 4
Training loss: 2.6325089367373384
Validation loss: 2.4691038642652936

Epoch: 6| Step: 5
Training loss: 2.215330040241143
Validation loss: 2.4695811582705582

Epoch: 6| Step: 6
Training loss: 2.3325379809919013
Validation loss: 2.4685763205426383

Epoch: 6| Step: 7
Training loss: 2.890186338390256
Validation loss: 2.463165921246642

Epoch: 6| Step: 8
Training loss: 2.3956227638479017
Validation loss: 2.4703967883315645

Epoch: 6| Step: 9
Training loss: 2.825804543498046
Validation loss: 2.467113129274198

Epoch: 6| Step: 10
Training loss: 2.9000238154518643
Validation loss: 2.458856419230499

Epoch: 6| Step: 11
Training loss: 2.387443170320502
Validation loss: 2.459986394932453

Epoch: 6| Step: 12
Training loss: 2.723658023032301
Validation loss: 2.4593135582092738

Epoch: 6| Step: 13
Training loss: 2.819426843956777
Validation loss: 2.460158887942303

Epoch: 102| Step: 0
Training loss: 2.612643815604101
Validation loss: 2.459766452436392

Epoch: 6| Step: 1
Training loss: 2.9592402684318477
Validation loss: 2.4660608638854002

Epoch: 6| Step: 2
Training loss: 1.9496021696342383
Validation loss: 2.4670856515205295

Epoch: 6| Step: 3
Training loss: 2.2415245219073583
Validation loss: 2.4724921181568895

Epoch: 6| Step: 4
Training loss: 2.3283245845986205
Validation loss: 2.47184329456648

Epoch: 6| Step: 5
Training loss: 2.2575263135692394
Validation loss: 2.474658888291632

Epoch: 6| Step: 6
Training loss: 2.401130580841796
Validation loss: 2.4678916485190467

Epoch: 6| Step: 7
Training loss: 2.9976220243049565
Validation loss: 2.4704017264337472

Epoch: 6| Step: 8
Training loss: 2.487400156442273
Validation loss: 2.469265992527913

Epoch: 6| Step: 9
Training loss: 2.4610328292548074
Validation loss: 2.4712153008172653

Epoch: 6| Step: 10
Training loss: 2.602820473176815
Validation loss: 2.463650664054805

Epoch: 6| Step: 11
Training loss: 2.8369528894180362
Validation loss: 2.465084267724086

Epoch: 6| Step: 12
Training loss: 2.7662539871400833
Validation loss: 2.466714816869281

Epoch: 6| Step: 13
Training loss: 2.694316292912709
Validation loss: 2.463788934816433

Epoch: 103| Step: 0
Training loss: 1.7194361617519303
Validation loss: 2.4618274351175065

Epoch: 6| Step: 1
Training loss: 2.6558146400460094
Validation loss: 2.464856485776246

Epoch: 6| Step: 2
Training loss: 2.5731499034685514
Validation loss: 2.4609029616096914

Epoch: 6| Step: 3
Training loss: 2.920715591589768
Validation loss: 2.46451162931

Epoch: 6| Step: 4
Training loss: 2.52509699720147
Validation loss: 2.4629379134815137

Epoch: 6| Step: 5
Training loss: 2.135799565915913
Validation loss: 2.4681770931518847

Epoch: 6| Step: 6
Training loss: 2.8029902431115445
Validation loss: 2.4643176243244933

Epoch: 6| Step: 7
Training loss: 2.7224417866069466
Validation loss: 2.4713729654018555

Epoch: 6| Step: 8
Training loss: 2.637524019828005
Validation loss: 2.4673097972745395

Epoch: 6| Step: 9
Training loss: 2.8876325634668687
Validation loss: 2.4654162951553973

Epoch: 6| Step: 10
Training loss: 2.7355881098072046
Validation loss: 2.466289307966939

Epoch: 6| Step: 11
Training loss: 2.5882667584852674
Validation loss: 2.463438000961047

Epoch: 6| Step: 12
Training loss: 2.216800531728812
Validation loss: 2.468258933629528

Epoch: 6| Step: 13
Training loss: 2.404151298522313
Validation loss: 2.4691778689424417

Epoch: 104| Step: 0
Training loss: 3.1487412980562506
Validation loss: 2.4646660306916135

Epoch: 6| Step: 1
Training loss: 2.230154038655808
Validation loss: 2.4747935013087607

Epoch: 6| Step: 2
Training loss: 2.420061379907446
Validation loss: 2.4690930735752703

Epoch: 6| Step: 3
Training loss: 2.5320819382388806
Validation loss: 2.4674258080987523

Epoch: 6| Step: 4
Training loss: 2.546652942174442
Validation loss: 2.471127311067782

Epoch: 6| Step: 5
Training loss: 2.3884848196255177
Validation loss: 2.468081355587672

Epoch: 6| Step: 6
Training loss: 2.6790793037310285
Validation loss: 2.4681301223986374

Epoch: 6| Step: 7
Training loss: 2.748773648176345
Validation loss: 2.4673293327615884

Epoch: 6| Step: 8
Training loss: 2.292647435097188
Validation loss: 2.4729539512216707

Epoch: 6| Step: 9
Training loss: 2.005989048229075
Validation loss: 2.4732809698811735

Epoch: 6| Step: 10
Training loss: 2.7339783299054026
Validation loss: 2.471898586065822

Epoch: 6| Step: 11
Training loss: 2.0164480968391163
Validation loss: 2.473929705537832

Epoch: 6| Step: 12
Training loss: 2.7717641161014437
Validation loss: 2.4700583359165447

Epoch: 6| Step: 13
Training loss: 2.989958488150673
Validation loss: 2.4660602354658083

Epoch: 105| Step: 0
Training loss: 2.1346031189934243
Validation loss: 2.4620802552255663

Epoch: 6| Step: 1
Training loss: 2.9739812436977826
Validation loss: 2.4719041400643427

Epoch: 6| Step: 2
Training loss: 2.8086173490294195
Validation loss: 2.4741212864799116

Epoch: 6| Step: 3
Training loss: 2.296863789433739
Validation loss: 2.4615182584898627

Epoch: 6| Step: 4
Training loss: 2.702747384745887
Validation loss: 2.4570226785402127

Epoch: 6| Step: 5
Training loss: 2.6963506053959745
Validation loss: 2.4639337454832555

Epoch: 6| Step: 6
Training loss: 2.5525469196726096
Validation loss: 2.467494073736359

Epoch: 6| Step: 7
Training loss: 2.845152456693851
Validation loss: 2.477283617483026

Epoch: 6| Step: 8
Training loss: 2.0518578600741324
Validation loss: 2.4698323078477307

Epoch: 6| Step: 9
Training loss: 2.407613986952322
Validation loss: 2.4690932827911856

Epoch: 6| Step: 10
Training loss: 2.38308614191429
Validation loss: 2.4674224261709314

Epoch: 6| Step: 11
Training loss: 2.86183835841105
Validation loss: 2.473010840761246

Epoch: 6| Step: 12
Training loss: 2.816684492231616
Validation loss: 2.4643549850158037

Epoch: 6| Step: 13
Training loss: 2.163191306688684
Validation loss: 2.46050125372889

Epoch: 106| Step: 0
Training loss: 2.4408173117779826
Validation loss: 2.46887016808712

Epoch: 6| Step: 1
Training loss: 2.5625027912403815
Validation loss: 2.4688384285714595

Epoch: 6| Step: 2
Training loss: 2.6409047898359135
Validation loss: 2.466242067633954

Epoch: 6| Step: 3
Training loss: 2.898393245060983
Validation loss: 2.4633283032102247

Epoch: 6| Step: 4
Training loss: 2.439938523659369
Validation loss: 2.4651073349132337

Epoch: 6| Step: 5
Training loss: 2.1482307473315148
Validation loss: 2.4624174643173387

Epoch: 6| Step: 6
Training loss: 2.7139931643012707
Validation loss: 2.458960733257121

Epoch: 6| Step: 7
Training loss: 2.5582366461195156
Validation loss: 2.459734845848534

Epoch: 6| Step: 8
Training loss: 2.584965825841855
Validation loss: 2.462899240573997

Epoch: 6| Step: 9
Training loss: 2.8316565956384188
Validation loss: 2.4594356091538843

Epoch: 6| Step: 10
Training loss: 2.3065730253774595
Validation loss: 2.459291713133203

Epoch: 6| Step: 11
Training loss: 2.680271807879068
Validation loss: 2.4542607069753077

Epoch: 6| Step: 12
Training loss: 2.323575175964435
Validation loss: 2.457315797405662

Epoch: 6| Step: 13
Training loss: 2.4397938034608093
Validation loss: 2.4599865403104353

Epoch: 107| Step: 0
Training loss: 2.7219879337186295
Validation loss: 2.468782368379371

Epoch: 6| Step: 1
Training loss: 2.609302085725751
Validation loss: 2.4642689030036333

Epoch: 6| Step: 2
Training loss: 1.9744751655405919
Validation loss: 2.4691615988861444

Epoch: 6| Step: 3
Training loss: 2.506039191534002
Validation loss: 2.464689786992254

Epoch: 6| Step: 4
Training loss: 2.3419400156289654
Validation loss: 2.4659284732878826

Epoch: 6| Step: 5
Training loss: 2.5821387287341304
Validation loss: 2.468115906224097

Epoch: 6| Step: 6
Training loss: 2.4446930999672216
Validation loss: 2.4717125962667876

Epoch: 6| Step: 7
Training loss: 2.7864221208067246
Validation loss: 2.467318703414365

Epoch: 6| Step: 8
Training loss: 2.1078717562049856
Validation loss: 2.4658850371172183

Epoch: 6| Step: 9
Training loss: 2.745727861971101
Validation loss: 2.469713932285114

Epoch: 6| Step: 10
Training loss: 2.740136055735713
Validation loss: 2.4728565104837057

Epoch: 6| Step: 11
Training loss: 2.894043751383921
Validation loss: 2.471873468333468

Epoch: 6| Step: 12
Training loss: 2.566542716150359
Validation loss: 2.4662115671701783

Epoch: 6| Step: 13
Training loss: 2.436316961128623
Validation loss: 2.4671901974251584

Epoch: 108| Step: 0
Training loss: 2.5529549699660423
Validation loss: 2.462941059561173

Epoch: 6| Step: 1
Training loss: 2.46054703778625
Validation loss: 2.463628583239111

Epoch: 6| Step: 2
Training loss: 2.7818476859821333
Validation loss: 2.4538759997459763

Epoch: 6| Step: 3
Training loss: 1.7619918307094435
Validation loss: 2.4538505436953293

Epoch: 6| Step: 4
Training loss: 2.8086432398227967
Validation loss: 2.4531581738733577

Epoch: 6| Step: 5
Training loss: 2.711235975384878
Validation loss: 2.4623623391544744

Epoch: 6| Step: 6
Training loss: 2.574254592854364
Validation loss: 2.4557601802697375

Epoch: 6| Step: 7
Training loss: 2.21935607798961
Validation loss: 2.4587994203706143

Epoch: 6| Step: 8
Training loss: 2.9230058898866442
Validation loss: 2.4636057683389008

Epoch: 6| Step: 9
Training loss: 2.7556685199792073
Validation loss: 2.4605431780696763

Epoch: 6| Step: 10
Training loss: 1.9338286902525825
Validation loss: 2.4627345230039084

Epoch: 6| Step: 11
Training loss: 3.0510097520660513
Validation loss: 2.463748065670963

Epoch: 6| Step: 12
Training loss: 2.7112083629543333
Validation loss: 2.4612535707658703

Epoch: 6| Step: 13
Training loss: 2.127282879841489
Validation loss: 2.456230724540576

Epoch: 109| Step: 0
Training loss: 2.92719783536378
Validation loss: 2.4624836742034217

Epoch: 6| Step: 1
Training loss: 2.8594275297749143
Validation loss: 2.470351701554491

Epoch: 6| Step: 2
Training loss: 2.2505057084477933
Validation loss: 2.472671540882466

Epoch: 6| Step: 3
Training loss: 2.7716903126117605
Validation loss: 2.472666952824141

Epoch: 6| Step: 4
Training loss: 2.3787442858452454
Validation loss: 2.472031131126562

Epoch: 6| Step: 5
Training loss: 2.2520877900433853
Validation loss: 2.4673910303863993

Epoch: 6| Step: 6
Training loss: 2.3250482697757286
Validation loss: 2.4661297795955806

Epoch: 6| Step: 7
Training loss: 2.8335926460829803
Validation loss: 2.456899019775874

Epoch: 6| Step: 8
Training loss: 2.2283915185096235
Validation loss: 2.462722098957436

Epoch: 6| Step: 9
Training loss: 2.562275760422506
Validation loss: 2.4629873145351513

Epoch: 6| Step: 10
Training loss: 2.467938060273828
Validation loss: 2.457342309067441

Epoch: 6| Step: 11
Training loss: 2.4336966160668374
Validation loss: 2.460356160280436

Epoch: 6| Step: 12
Training loss: 2.5021077807330823
Validation loss: 2.4585993482770236

Epoch: 6| Step: 13
Training loss: 2.9356186706331795
Validation loss: 2.4579607524971685

Epoch: 110| Step: 0
Training loss: 2.6695674278659096
Validation loss: 2.460024152536376

Epoch: 6| Step: 1
Training loss: 2.4409726177400355
Validation loss: 2.4568204561912244

Epoch: 6| Step: 2
Training loss: 2.3260291990249815
Validation loss: 2.461442215444707

Epoch: 6| Step: 3
Training loss: 2.3165881132168504
Validation loss: 2.4598657928598957

Epoch: 6| Step: 4
Training loss: 2.2568300214926786
Validation loss: 2.4618266926300265

Epoch: 6| Step: 5
Training loss: 2.447396752086098
Validation loss: 2.4596495876169926

Epoch: 6| Step: 6
Training loss: 2.1911909300202432
Validation loss: 2.461953904907528

Epoch: 6| Step: 7
Training loss: 3.146005756292879
Validation loss: 2.465434733544829

Epoch: 6| Step: 8
Training loss: 2.385802247536322
Validation loss: 2.4666475123443603

Epoch: 6| Step: 9
Training loss: 1.7718573433132534
Validation loss: 2.463754758967334

Epoch: 6| Step: 10
Training loss: 2.643584539768416
Validation loss: 2.4623920965678034

Epoch: 6| Step: 11
Training loss: 2.554876384693485
Validation loss: 2.4639449942015315

Epoch: 6| Step: 12
Training loss: 3.2022995792422115
Validation loss: 2.4638685260960083

Epoch: 6| Step: 13
Training loss: 2.8741596486474243
Validation loss: 2.462935396614893

Epoch: 111| Step: 0
Training loss: 1.875768885319514
Validation loss: 2.458246816847671

Epoch: 6| Step: 1
Training loss: 2.6591120839850495
Validation loss: 2.4646455873530893

Epoch: 6| Step: 2
Training loss: 2.768860212418736
Validation loss: 2.4609807490025104

Epoch: 6| Step: 3
Training loss: 2.6841039269817073
Validation loss: 2.4605417730667423

Epoch: 6| Step: 4
Training loss: 2.6460642576193116
Validation loss: 2.463305203230301

Epoch: 6| Step: 5
Training loss: 2.43317930265319
Validation loss: 2.464333345875619

Epoch: 6| Step: 6
Training loss: 2.343874101532121
Validation loss: 2.4633922303075404

Epoch: 6| Step: 7
Training loss: 2.765847407304525
Validation loss: 2.4641419553716335

Epoch: 6| Step: 8
Training loss: 2.749603329573417
Validation loss: 2.4708552096354257

Epoch: 6| Step: 9
Training loss: 2.097869578050554
Validation loss: 2.470692863995903

Epoch: 6| Step: 10
Training loss: 2.323239929788205
Validation loss: 2.4713259910743353

Epoch: 6| Step: 11
Training loss: 2.805474556067335
Validation loss: 2.4722432639861247

Epoch: 6| Step: 12
Training loss: 2.2636531272816196
Validation loss: 2.468345158214007

Epoch: 6| Step: 13
Training loss: 3.0051459047564584
Validation loss: 2.4686239186214585

Epoch: 112| Step: 0
Training loss: 2.843753353578036
Validation loss: 2.466929879407259

Epoch: 6| Step: 1
Training loss: 2.018784759505679
Validation loss: 2.464611608795032

Epoch: 6| Step: 2
Training loss: 2.4708677455656463
Validation loss: 2.461590537966921

Epoch: 6| Step: 3
Training loss: 2.3266639989639044
Validation loss: 2.4563931443660474

Epoch: 6| Step: 4
Training loss: 2.436538408802952
Validation loss: 2.4601611411420667

Epoch: 6| Step: 5
Training loss: 2.550549997593101
Validation loss: 2.456865888326539

Epoch: 6| Step: 6
Training loss: 2.52654290224117
Validation loss: 2.461262127491379

Epoch: 6| Step: 7
Training loss: 2.506425135098837
Validation loss: 2.4575915807021405

Epoch: 6| Step: 8
Training loss: 2.9821356715367844
Validation loss: 2.46132860254847

Epoch: 6| Step: 9
Training loss: 2.701597631169784
Validation loss: 2.456355735373128

Epoch: 6| Step: 10
Training loss: 2.1671833987152525
Validation loss: 2.457211453976276

Epoch: 6| Step: 11
Training loss: 2.124623658008963
Validation loss: 2.464991319755865

Epoch: 6| Step: 12
Training loss: 2.828166645228168
Validation loss: 2.45814785553974

Epoch: 6| Step: 13
Training loss: 2.7806580159959635
Validation loss: 2.454399992424817

Epoch: 113| Step: 0
Training loss: 2.5865062998516675
Validation loss: 2.460627412181987

Epoch: 6| Step: 1
Training loss: 2.163603696146661
Validation loss: 2.4558854173052405

Epoch: 6| Step: 2
Training loss: 2.9008900427560387
Validation loss: 2.4600524118055622

Epoch: 6| Step: 3
Training loss: 2.6755606233176352
Validation loss: 2.461340993268309

Epoch: 6| Step: 4
Training loss: 2.4797548723593117
Validation loss: 2.461490274341273

Epoch: 6| Step: 5
Training loss: 2.8118917019312626
Validation loss: 2.4639879323851686

Epoch: 6| Step: 6
Training loss: 2.3616742179425034
Validation loss: 2.4604852492948375

Epoch: 6| Step: 7
Training loss: 2.284278114028102
Validation loss: 2.46537090776314

Epoch: 6| Step: 8
Training loss: 2.467710928206383
Validation loss: 2.4621347734215644

Epoch: 6| Step: 9
Training loss: 3.1351242858489243
Validation loss: 2.462414317568713

Epoch: 6| Step: 10
Training loss: 2.185468984243727
Validation loss: 2.4705625230188497

Epoch: 6| Step: 11
Training loss: 2.388722878486296
Validation loss: 2.467841661318067

Epoch: 6| Step: 12
Training loss: 2.1731043567834454
Validation loss: 2.4705478544033945

Epoch: 6| Step: 13
Training loss: 2.54643947879486
Validation loss: 2.4720541495675135

Epoch: 114| Step: 0
Training loss: 2.1484330610749596
Validation loss: 2.4737495709059543

Epoch: 6| Step: 1
Training loss: 1.7464539158570438
Validation loss: 2.4728308641630887

Epoch: 6| Step: 2
Training loss: 2.6116661018544627
Validation loss: 2.4803102137246795

Epoch: 6| Step: 3
Training loss: 2.755246532922932
Validation loss: 2.4751861791232255

Epoch: 6| Step: 4
Training loss: 2.346762183839163
Validation loss: 2.4801473013781057

Epoch: 6| Step: 5
Training loss: 2.486151102361233
Validation loss: 2.4729197092099153

Epoch: 6| Step: 6
Training loss: 2.5716749481971024
Validation loss: 2.472424167309713

Epoch: 6| Step: 7
Training loss: 3.0924596696596836
Validation loss: 2.47068721881717

Epoch: 6| Step: 8
Training loss: 2.4734187344136234
Validation loss: 2.470856697225083

Epoch: 6| Step: 9
Training loss: 2.6715962225498773
Validation loss: 2.463805530657102

Epoch: 6| Step: 10
Training loss: 3.313395828895985
Validation loss: 2.465391909206534

Epoch: 6| Step: 11
Training loss: 2.6117581203915403
Validation loss: 2.468266121809768

Epoch: 6| Step: 12
Training loss: 2.43356455483842
Validation loss: 2.459898197372973

Epoch: 6| Step: 13
Training loss: 2.007810362580939
Validation loss: 2.466602663120515

Epoch: 115| Step: 0
Training loss: 2.863275920868165
Validation loss: 2.4637946119290275

Epoch: 6| Step: 1
Training loss: 2.500529042533542
Validation loss: 2.463285103490517

Epoch: 6| Step: 2
Training loss: 2.4044561263643054
Validation loss: 2.456432032937862

Epoch: 6| Step: 3
Training loss: 2.7626559597541878
Validation loss: 2.4603596003732884

Epoch: 6| Step: 4
Training loss: 2.5593849414823326
Validation loss: 2.459297416784948

Epoch: 6| Step: 5
Training loss: 2.04783211963976
Validation loss: 2.458558441351416

Epoch: 6| Step: 6
Training loss: 2.231293053305142
Validation loss: 2.458666364019517

Epoch: 6| Step: 7
Training loss: 3.498670870590398
Validation loss: 2.4565737833643007

Epoch: 6| Step: 8
Training loss: 2.5681982185656445
Validation loss: 2.46273031174323

Epoch: 6| Step: 9
Training loss: 2.270514322907333
Validation loss: 2.462281117659684

Epoch: 6| Step: 10
Training loss: 2.3193505344935397
Validation loss: 2.464660589362155

Epoch: 6| Step: 11
Training loss: 2.9995429962479836
Validation loss: 2.4686760951701796

Epoch: 6| Step: 12
Training loss: 2.425808769721113
Validation loss: 2.472269133385857

Epoch: 6| Step: 13
Training loss: 1.7228295894268568
Validation loss: 2.467375891983858

Epoch: 116| Step: 0
Training loss: 3.0621259811268366
Validation loss: 2.463473318387125

Epoch: 6| Step: 1
Training loss: 2.2617233882454597
Validation loss: 2.464932866810471

Epoch: 6| Step: 2
Training loss: 2.205837338680161
Validation loss: 2.458731026459099

Epoch: 6| Step: 3
Training loss: 2.141117234264452
Validation loss: 2.4649039622356574

Epoch: 6| Step: 4
Training loss: 2.4747299971835233
Validation loss: 2.4591842784227245

Epoch: 6| Step: 5
Training loss: 2.6432755389475733
Validation loss: 2.4553266231076787

Epoch: 6| Step: 6
Training loss: 2.3220097663141726
Validation loss: 2.4564800442687966

Epoch: 6| Step: 7
Training loss: 2.8956683727089727
Validation loss: 2.4544580162520826

Epoch: 6| Step: 8
Training loss: 2.19044144279057
Validation loss: 2.4533252674813295

Epoch: 6| Step: 9
Training loss: 2.2022441428759763
Validation loss: 2.45460671223731

Epoch: 6| Step: 10
Training loss: 2.4180714919735955
Validation loss: 2.458435700327291

Epoch: 6| Step: 11
Training loss: 3.4135799110527745
Validation loss: 2.4712525250697417

Epoch: 6| Step: 12
Training loss: 2.6785115589535455
Validation loss: 2.4654901284710213

Epoch: 6| Step: 13
Training loss: 2.3644443644776167
Validation loss: 2.4574650400235667

Epoch: 117| Step: 0
Training loss: 2.523948027279718
Validation loss: 2.459619360824748

Epoch: 6| Step: 1
Training loss: 1.9492525697881755
Validation loss: 2.454443461855098

Epoch: 6| Step: 2
Training loss: 3.1481848679273083
Validation loss: 2.4506498837247435

Epoch: 6| Step: 3
Training loss: 2.144537364624423
Validation loss: 2.457927417109737

Epoch: 6| Step: 4
Training loss: 2.0989115846285404
Validation loss: 2.466860486698168

Epoch: 6| Step: 5
Training loss: 2.6723929455318447
Validation loss: 2.4615151025201727

Epoch: 6| Step: 6
Training loss: 2.5926174770654566
Validation loss: 2.4566306235862525

Epoch: 6| Step: 7
Training loss: 3.0530269236122485
Validation loss: 2.463462446577547

Epoch: 6| Step: 8
Training loss: 2.695944714689655
Validation loss: 2.464014662538495

Epoch: 6| Step: 9
Training loss: 2.4140178589875307
Validation loss: 2.4620062389516812

Epoch: 6| Step: 10
Training loss: 2.348479420179282
Validation loss: 2.466130899439828

Epoch: 6| Step: 11
Training loss: 2.361998659254658
Validation loss: 2.4599649515860005

Epoch: 6| Step: 12
Training loss: 2.457224924675056
Validation loss: 2.4643617250370524

Epoch: 6| Step: 13
Training loss: 2.6031582723737396
Validation loss: 2.4592041208312105

Epoch: 118| Step: 0
Training loss: 2.2028823610706745
Validation loss: 2.45189644893535

Epoch: 6| Step: 1
Training loss: 2.612710340145399
Validation loss: 2.4580183851145785

Epoch: 6| Step: 2
Training loss: 2.588386229076724
Validation loss: 2.4592711766458297

Epoch: 6| Step: 3
Training loss: 2.8801329857534355
Validation loss: 2.457310339800261

Epoch: 6| Step: 4
Training loss: 2.5189171330964784
Validation loss: 2.460261515463762

Epoch: 6| Step: 5
Training loss: 2.9241912962806746
Validation loss: 2.464954597410947

Epoch: 6| Step: 6
Training loss: 2.232508273050629
Validation loss: 2.4613977476184754

Epoch: 6| Step: 7
Training loss: 2.3229067906282372
Validation loss: 2.4593442492438835

Epoch: 6| Step: 8
Training loss: 2.3068595349525434
Validation loss: 2.4581369035983682

Epoch: 6| Step: 9
Training loss: 2.5100079489958227
Validation loss: 2.4603067225462656

Epoch: 6| Step: 10
Training loss: 2.6019152153035607
Validation loss: 2.4601625059824976

Epoch: 6| Step: 11
Training loss: 2.6778904530609484
Validation loss: 2.464975360595042

Epoch: 6| Step: 12
Training loss: 2.526393234065577
Validation loss: 2.4676226122100156

Epoch: 6| Step: 13
Training loss: 2.37377486502675
Validation loss: 2.4627151124206526

Epoch: 119| Step: 0
Training loss: 2.6605132951466985
Validation loss: 2.4614351041980873

Epoch: 6| Step: 1
Training loss: 3.0785622842846974
Validation loss: 2.462148749768819

Epoch: 6| Step: 2
Training loss: 2.816967615907621
Validation loss: 2.4595716288776703

Epoch: 6| Step: 3
Training loss: 2.0189014389822764
Validation loss: 2.4579393157286216

Epoch: 6| Step: 4
Training loss: 2.634127415870765
Validation loss: 2.466794861435037

Epoch: 6| Step: 5
Training loss: 2.6411401370335703
Validation loss: 2.4643320236567203

Epoch: 6| Step: 6
Training loss: 2.0673238811643833
Validation loss: 2.4669190228308824

Epoch: 6| Step: 7
Training loss: 2.8005972021009247
Validation loss: 2.4685234094603996

Epoch: 6| Step: 8
Training loss: 2.4049094292921187
Validation loss: 2.4683339858928934

Epoch: 6| Step: 9
Training loss: 2.2325627373469676
Validation loss: 2.465875183099274

Epoch: 6| Step: 10
Training loss: 2.68637265358048
Validation loss: 2.469469038153457

Epoch: 6| Step: 11
Training loss: 2.1317380776969475
Validation loss: 2.472420036840865

Epoch: 6| Step: 12
Training loss: 2.2179938088856073
Validation loss: 2.4704089968463565

Epoch: 6| Step: 13
Training loss: 2.7006789590026448
Validation loss: 2.4676689002022516

Epoch: 120| Step: 0
Training loss: 3.0611011658045606
Validation loss: 2.4636666882481877

Epoch: 6| Step: 1
Training loss: 1.8444579753353885
Validation loss: 2.457458523632814

Epoch: 6| Step: 2
Training loss: 2.5087350829877932
Validation loss: 2.4599834550647492

Epoch: 6| Step: 3
Training loss: 3.0466155112859905
Validation loss: 2.4554331747065783

Epoch: 6| Step: 4
Training loss: 2.884208692589645
Validation loss: 2.4521611743931957

Epoch: 6| Step: 5
Training loss: 2.445985061730896
Validation loss: 2.459215520448691

Epoch: 6| Step: 6
Training loss: 2.2889801114719437
Validation loss: 2.4599337352315294

Epoch: 6| Step: 7
Training loss: 2.3515146447061683
Validation loss: 2.468154996482139

Epoch: 6| Step: 8
Training loss: 2.173078244847051
Validation loss: 2.469767091377576

Epoch: 6| Step: 9
Training loss: 1.9021103733420646
Validation loss: 2.479353085622894

Epoch: 6| Step: 10
Training loss: 2.602181942254558
Validation loss: 2.474956244264937

Epoch: 6| Step: 11
Training loss: 2.707187928789024
Validation loss: 2.4610994235259485

Epoch: 6| Step: 12
Training loss: 2.856859778958509
Validation loss: 2.4592036522419765

Epoch: 6| Step: 13
Training loss: 2.4403364843771898
Validation loss: 2.4547936500537637

Epoch: 121| Step: 0
Training loss: 2.242992402858513
Validation loss: 2.455629418869878

Epoch: 6| Step: 1
Training loss: 2.988094548395577
Validation loss: 2.4590191827299632

Epoch: 6| Step: 2
Training loss: 3.0750869242469885
Validation loss: 2.4601352736385507

Epoch: 6| Step: 3
Training loss: 2.825839726373237
Validation loss: 2.458012128848142

Epoch: 6| Step: 4
Training loss: 2.4708993946869935
Validation loss: 2.464442168508858

Epoch: 6| Step: 5
Training loss: 2.5904304679841244
Validation loss: 2.465917725102459

Epoch: 6| Step: 6
Training loss: 1.9224329192881082
Validation loss: 2.4572265094582932

Epoch: 6| Step: 7
Training loss: 2.3275643512094346
Validation loss: 2.4622738716620085

Epoch: 6| Step: 8
Training loss: 2.9071914624602653
Validation loss: 2.460438624280541

Epoch: 6| Step: 9
Training loss: 2.1514364500666843
Validation loss: 2.4610614402280393

Epoch: 6| Step: 10
Training loss: 3.1224672353352543
Validation loss: 2.4599098603086063

Epoch: 6| Step: 11
Training loss: 2.260748093269824
Validation loss: 2.454964436094132

Epoch: 6| Step: 12
Training loss: 2.539158276438792
Validation loss: 2.450872273771881

Epoch: 6| Step: 13
Training loss: 1.5182312255985002
Validation loss: 2.4527811348002775

Epoch: 122| Step: 0
Training loss: 2.4979475179065664
Validation loss: 2.4509634387795027

Epoch: 6| Step: 1
Training loss: 2.796321707613103
Validation loss: 2.451900913796197

Epoch: 6| Step: 2
Training loss: 2.846599115765848
Validation loss: 2.4548358823015515

Epoch: 6| Step: 3
Training loss: 2.3388830897162944
Validation loss: 2.451969093075071

Epoch: 6| Step: 4
Training loss: 2.4580442829783435
Validation loss: 2.4573875213422536

Epoch: 6| Step: 5
Training loss: 2.7294467656104358
Validation loss: 2.4485286732187186

Epoch: 6| Step: 6
Training loss: 2.316402338806247
Validation loss: 2.4550102424796383

Epoch: 6| Step: 7
Training loss: 2.1467472710295006
Validation loss: 2.4532001751114545

Epoch: 6| Step: 8
Training loss: 2.767456827352464
Validation loss: 2.456566916834111

Epoch: 6| Step: 9
Training loss: 2.840545189872537
Validation loss: 2.459505663724684

Epoch: 6| Step: 10
Training loss: 2.900417422803391
Validation loss: 2.4512781289869827

Epoch: 6| Step: 11
Training loss: 1.9292632961034994
Validation loss: 2.453606997556216

Epoch: 6| Step: 12
Training loss: 1.632358615705677
Validation loss: 2.4565343147074343

Epoch: 6| Step: 13
Training loss: 2.691641344673717
Validation loss: 2.461043388873948

Epoch: 123| Step: 0
Training loss: 2.8804245235895682
Validation loss: 2.462056013769045

Epoch: 6| Step: 1
Training loss: 2.8558918734686607
Validation loss: 2.4587703467262383

Epoch: 6| Step: 2
Training loss: 2.7693544231830662
Validation loss: 2.4615387358726446

Epoch: 6| Step: 3
Training loss: 2.2751155572404684
Validation loss: 2.4608292490245676

Epoch: 6| Step: 4
Training loss: 2.417019215442315
Validation loss: 2.4586179913300623

Epoch: 6| Step: 5
Training loss: 2.489412873842227
Validation loss: 2.458274005454177

Epoch: 6| Step: 6
Training loss: 2.9813280779133144
Validation loss: 2.4569984195296852

Epoch: 6| Step: 7
Training loss: 2.522934145962693
Validation loss: 2.457508172273549

Epoch: 6| Step: 8
Training loss: 2.4633169145600444
Validation loss: 2.4516646296451423

Epoch: 6| Step: 9
Training loss: 2.176868872293001
Validation loss: 2.4623988903736773

Epoch: 6| Step: 10
Training loss: 2.0028530275432006
Validation loss: 2.456874112601562

Epoch: 6| Step: 11
Training loss: 2.17409824225164
Validation loss: 2.457395768126712

Epoch: 6| Step: 12
Training loss: 2.534852936972648
Validation loss: 2.4508107602003966

Epoch: 6| Step: 13
Training loss: 2.494331418284901
Validation loss: 2.4516828473004733

Epoch: 124| Step: 0
Training loss: 2.4246168797461185
Validation loss: 2.4586802469510824

Epoch: 6| Step: 1
Training loss: 2.0001108615667107
Validation loss: 2.4554918052439763

Epoch: 6| Step: 2
Training loss: 2.376401387408522
Validation loss: 2.464961416395197

Epoch: 6| Step: 3
Training loss: 2.834051845175917
Validation loss: 2.4575891068668314

Epoch: 6| Step: 4
Training loss: 2.634328162522446
Validation loss: 2.459286817353591

Epoch: 6| Step: 5
Training loss: 3.0299443844767944
Validation loss: 2.4591503940700137

Epoch: 6| Step: 6
Training loss: 2.485152500776948
Validation loss: 2.4520648520223434

Epoch: 6| Step: 7
Training loss: 2.6785049720876097
Validation loss: 2.4665859733304587

Epoch: 6| Step: 8
Training loss: 2.7220833174197843
Validation loss: 2.461528485095305

Epoch: 6| Step: 9
Training loss: 2.53345402965468
Validation loss: 2.4628842520372953

Epoch: 6| Step: 10
Training loss: 1.9553262741727937
Validation loss: 2.4593291824900727

Epoch: 6| Step: 11
Training loss: 2.1545288293077816
Validation loss: 2.4635744529515637

Epoch: 6| Step: 12
Training loss: 2.437582454753965
Validation loss: 2.4601511672851677

Epoch: 6| Step: 13
Training loss: 2.731203779794081
Validation loss: 2.462551334575405

Epoch: 125| Step: 0
Training loss: 2.529968313991265
Validation loss: 2.4553438263899454

Epoch: 6| Step: 1
Training loss: 2.3934171241005493
Validation loss: 2.457717274128446

Epoch: 6| Step: 2
Training loss: 3.047223193495843
Validation loss: 2.4588064665161626

Epoch: 6| Step: 3
Training loss: 2.334507737477598
Validation loss: 2.4585324276837626

Epoch: 6| Step: 4
Training loss: 2.753981049516091
Validation loss: 2.455185294309581

Epoch: 6| Step: 5
Training loss: 2.851513002566987
Validation loss: 2.4543828310969866

Epoch: 6| Step: 6
Training loss: 1.903127771134387
Validation loss: 2.4537590649062135

Epoch: 6| Step: 7
Training loss: 2.680216567413179
Validation loss: 2.457967687882259

Epoch: 6| Step: 8
Training loss: 2.3680621756432836
Validation loss: 2.4560052926144227

Epoch: 6| Step: 9
Training loss: 2.394930583768163
Validation loss: 2.4579057537154974

Epoch: 6| Step: 10
Training loss: 2.114839835809778
Validation loss: 2.4520339969499783

Epoch: 6| Step: 11
Training loss: 2.1479797985469555
Validation loss: 2.4528863875853713

Epoch: 6| Step: 12
Training loss: 2.7441197730524487
Validation loss: 2.459212296891063

Epoch: 6| Step: 13
Training loss: 2.7145606901952246
Validation loss: 2.458693370208964

Epoch: 126| Step: 0
Training loss: 2.75332882285807
Validation loss: 2.4578587887611274

Epoch: 6| Step: 1
Training loss: 2.0883310137241367
Validation loss: 2.4567763737630948

Epoch: 6| Step: 2
Training loss: 2.385350910818557
Validation loss: 2.449409635609936

Epoch: 6| Step: 3
Training loss: 2.47259058571356
Validation loss: 2.456253955763462

Epoch: 6| Step: 4
Training loss: 2.7338375762321716
Validation loss: 2.4540584108561556

Epoch: 6| Step: 5
Training loss: 2.2722049268931186
Validation loss: 2.4621407932667716

Epoch: 6| Step: 6
Training loss: 2.3994034303857337
Validation loss: 2.4603477619114837

Epoch: 6| Step: 7
Training loss: 2.832187158962761
Validation loss: 2.451141786833926

Epoch: 6| Step: 8
Training loss: 2.801896856028303
Validation loss: 2.4532485331473257

Epoch: 6| Step: 9
Training loss: 3.09379361825115
Validation loss: 2.4556277683288084

Epoch: 6| Step: 10
Training loss: 2.186260744289826
Validation loss: 2.4554198236432754

Epoch: 6| Step: 11
Training loss: 2.319494340807883
Validation loss: 2.453692182344569

Epoch: 6| Step: 12
Training loss: 2.435924509930185
Validation loss: 2.456416446847504

Epoch: 6| Step: 13
Training loss: 2.2142040263986558
Validation loss: 2.4544988458127808

Epoch: 127| Step: 0
Training loss: 2.7014547490903964
Validation loss: 2.4523870406998936

Epoch: 6| Step: 1
Training loss: 2.588564181213916
Validation loss: 2.4542716195462915

Epoch: 6| Step: 2
Training loss: 2.383126560213672
Validation loss: 2.456142553902716

Epoch: 6| Step: 3
Training loss: 2.9134344083709665
Validation loss: 2.461149240901161

Epoch: 6| Step: 4
Training loss: 2.8700072016609033
Validation loss: 2.4588892733742207

Epoch: 6| Step: 5
Training loss: 2.6946695196610713
Validation loss: 2.4584813208137746

Epoch: 6| Step: 6
Training loss: 2.070234534756907
Validation loss: 2.453879465116673

Epoch: 6| Step: 7
Training loss: 2.4830086267500433
Validation loss: 2.462616475895855

Epoch: 6| Step: 8
Training loss: 2.2666148161100015
Validation loss: 2.459586621445514

Epoch: 6| Step: 9
Training loss: 2.6068626689962215
Validation loss: 2.4620456844474092

Epoch: 6| Step: 10
Training loss: 1.8102057834214649
Validation loss: 2.4677423038186816

Epoch: 6| Step: 11
Training loss: 2.583701281851827
Validation loss: 2.467861273102731

Epoch: 6| Step: 12
Training loss: 2.2580918927884346
Validation loss: 2.472924353039394

Epoch: 6| Step: 13
Training loss: 2.6938529222833476
Validation loss: 2.4719629907841663

Epoch: 128| Step: 0
Training loss: 2.0979847002662506
Validation loss: 2.474998341184118

Epoch: 6| Step: 1
Training loss: 2.624456894412843
Validation loss: 2.4703977051786445

Epoch: 6| Step: 2
Training loss: 2.51449502717727
Validation loss: 2.4739400013026938

Epoch: 6| Step: 3
Training loss: 2.9368701015966545
Validation loss: 2.472060048812219

Epoch: 6| Step: 4
Training loss: 2.7907162846824463
Validation loss: 2.468450423465724

Epoch: 6| Step: 5
Training loss: 3.151902632356752
Validation loss: 2.4690782996681517

Epoch: 6| Step: 6
Training loss: 1.9170471587730857
Validation loss: 2.470048940948488

Epoch: 6| Step: 7
Training loss: 2.37017271450716
Validation loss: 2.4643609510642572

Epoch: 6| Step: 8
Training loss: 1.6761099397430919
Validation loss: 2.4584253881212765

Epoch: 6| Step: 9
Training loss: 2.5813574669290404
Validation loss: 2.46313738311569

Epoch: 6| Step: 10
Training loss: 2.179393242556442
Validation loss: 2.4645073243451097

Epoch: 6| Step: 11
Training loss: 3.0180766363607763
Validation loss: 2.483732704290521

Epoch: 6| Step: 12
Training loss: 2.6266062227385003
Validation loss: 2.491290769216317

Epoch: 6| Step: 13
Training loss: 2.7190480562139268
Validation loss: 2.504064895119032

Epoch: 129| Step: 0
Training loss: 2.103738105364043
Validation loss: 2.505025231747637

Epoch: 6| Step: 1
Training loss: 2.683118930883539
Validation loss: 2.492345503977304

Epoch: 6| Step: 2
Training loss: 2.8037147641529527
Validation loss: 2.4825919288396903

Epoch: 6| Step: 3
Training loss: 2.280835362206884
Validation loss: 2.4758844901592325

Epoch: 6| Step: 4
Training loss: 2.0691423672147895
Validation loss: 2.458288634157867

Epoch: 6| Step: 5
Training loss: 2.6598792022868363
Validation loss: 2.464080289277775

Epoch: 6| Step: 6
Training loss: 2.3242257254359613
Validation loss: 2.458216782948238

Epoch: 6| Step: 7
Training loss: 2.5294037667446787
Validation loss: 2.4582506478407478

Epoch: 6| Step: 8
Training loss: 2.420752283557152
Validation loss: 2.4612284816294023

Epoch: 6| Step: 9
Training loss: 2.83269068965779
Validation loss: 2.4669310391574

Epoch: 6| Step: 10
Training loss: 2.5214268849952703
Validation loss: 2.470839425047837

Epoch: 6| Step: 11
Training loss: 2.405346589364165
Validation loss: 2.46937480697689

Epoch: 6| Step: 12
Training loss: 2.562160283342047
Validation loss: 2.4698118509609874

Epoch: 6| Step: 13
Training loss: 2.877873353177007
Validation loss: 2.4706720201949315

Epoch: 130| Step: 0
Training loss: 3.092332611611332
Validation loss: 2.4672893275257057

Epoch: 6| Step: 1
Training loss: 2.281563828711808
Validation loss: 2.4710969673848964

Epoch: 6| Step: 2
Training loss: 2.455507906954429
Validation loss: 2.4748290821746

Epoch: 6| Step: 3
Training loss: 2.0242048892478213
Validation loss: 2.4733640632965317

Epoch: 6| Step: 4
Training loss: 2.2925465599665054
Validation loss: 2.464757515778687

Epoch: 6| Step: 5
Training loss: 2.7643974726585214
Validation loss: 2.453932829588135

Epoch: 6| Step: 6
Training loss: 2.7201812309307014
Validation loss: 2.457832727270202

Epoch: 6| Step: 7
Training loss: 2.3402226671420436
Validation loss: 2.460315347168616

Epoch: 6| Step: 8
Training loss: 2.4623234796915163
Validation loss: 2.460433682332538

Epoch: 6| Step: 9
Training loss: 2.386581891470482
Validation loss: 2.4597581409043445

Epoch: 6| Step: 10
Training loss: 2.5634248506688966
Validation loss: 2.4589310191584524

Epoch: 6| Step: 11
Training loss: 2.5998518534782282
Validation loss: 2.4672712251043554

Epoch: 6| Step: 12
Training loss: 2.489448501149254
Validation loss: 2.462097395179279

Epoch: 6| Step: 13
Training loss: 2.729324821568224
Validation loss: 2.4702516085418673

Epoch: 131| Step: 0
Training loss: 2.231933006231464
Validation loss: 2.472106101015188

Epoch: 6| Step: 1
Training loss: 2.423191623278572
Validation loss: 2.464823453228182

Epoch: 6| Step: 2
Training loss: 2.1625174505158102
Validation loss: 2.4693961444742145

Epoch: 6| Step: 3
Training loss: 2.0461723927186286
Validation loss: 2.471041070997913

Epoch: 6| Step: 4
Training loss: 2.55129574410876
Validation loss: 2.469753689087137

Epoch: 6| Step: 5
Training loss: 2.672997311460525
Validation loss: 2.476668073808656

Epoch: 6| Step: 6
Training loss: 2.7871010772859575
Validation loss: 2.465052995299082

Epoch: 6| Step: 7
Training loss: 2.7088902023217667
Validation loss: 2.47203129990781

Epoch: 6| Step: 8
Training loss: 2.2239087804296007
Validation loss: 2.4677343250954618

Epoch: 6| Step: 9
Training loss: 2.6250571290111973
Validation loss: 2.4676425558469606

Epoch: 6| Step: 10
Training loss: 2.6838689715698076
Validation loss: 2.4708451663715474

Epoch: 6| Step: 11
Training loss: 2.2874483530019574
Validation loss: 2.4674891539711807

Epoch: 6| Step: 12
Training loss: 2.530904769902492
Validation loss: 2.4613891510046746

Epoch: 6| Step: 13
Training loss: 3.101003139992471
Validation loss: 2.4646116732862144

Epoch: 132| Step: 0
Training loss: 2.300516265479998
Validation loss: 2.465438795129562

Epoch: 6| Step: 1
Training loss: 2.2847793659560724
Validation loss: 2.4660097519020963

Epoch: 6| Step: 2
Training loss: 2.9072293508027442
Validation loss: 2.4699826121007815

Epoch: 6| Step: 3
Training loss: 2.5885062467939233
Validation loss: 2.466742169882824

Epoch: 6| Step: 4
Training loss: 2.09057216606037
Validation loss: 2.470092408463225

Epoch: 6| Step: 5
Training loss: 2.915846046172196
Validation loss: 2.4618356266764723

Epoch: 6| Step: 6
Training loss: 2.0518807506451644
Validation loss: 2.470499263992617

Epoch: 6| Step: 7
Training loss: 2.844583913079346
Validation loss: 2.4663590148069554

Epoch: 6| Step: 8
Training loss: 2.865196264178631
Validation loss: 2.4703869764380015

Epoch: 6| Step: 9
Training loss: 2.2422387519322076
Validation loss: 2.466781894037299

Epoch: 6| Step: 10
Training loss: 2.7540297027404517
Validation loss: 2.471194718700441

Epoch: 6| Step: 11
Training loss: 2.0620521290329012
Validation loss: 2.4710409584319915

Epoch: 6| Step: 12
Training loss: 2.337993724719943
Validation loss: 2.464866271321644

Epoch: 6| Step: 13
Training loss: 2.6337777470963366
Validation loss: 2.4684501819998754

Epoch: 133| Step: 0
Training loss: 2.1288803798958544
Validation loss: 2.4646298274870198

Epoch: 6| Step: 1
Training loss: 1.7401904647544868
Validation loss: 2.464442474863022

Epoch: 6| Step: 2
Training loss: 2.6845895843535708
Validation loss: 2.4636477285596685

Epoch: 6| Step: 3
Training loss: 2.589348977354323
Validation loss: 2.468723119919344

Epoch: 6| Step: 4
Training loss: 2.1955551067708767
Validation loss: 2.467122970294428

Epoch: 6| Step: 5
Training loss: 2.839000214568987
Validation loss: 2.4585499317849275

Epoch: 6| Step: 6
Training loss: 2.6132480408250527
Validation loss: 2.4623129578377343

Epoch: 6| Step: 7
Training loss: 2.6155240822195482
Validation loss: 2.466151193507545

Epoch: 6| Step: 8
Training loss: 2.222485688273947
Validation loss: 2.455058168316487

Epoch: 6| Step: 9
Training loss: 2.953878962429337
Validation loss: 2.457898713071258

Epoch: 6| Step: 10
Training loss: 2.556958696762038
Validation loss: 2.458039966686665

Epoch: 6| Step: 11
Training loss: 3.331020474712532
Validation loss: 2.4587323193673183

Epoch: 6| Step: 12
Training loss: 2.2872430125480125
Validation loss: 2.4655346272469356

Epoch: 6| Step: 13
Training loss: 1.8978168116520069
Validation loss: 2.4615989482383562

Epoch: 134| Step: 0
Training loss: 1.9628388810810469
Validation loss: 2.4634892066278833

Epoch: 6| Step: 1
Training loss: 2.5751906833599842
Validation loss: 2.462867198230673

Epoch: 6| Step: 2
Training loss: 2.7090204589904823
Validation loss: 2.4617028070722697

Epoch: 6| Step: 3
Training loss: 2.421386177199854
Validation loss: 2.460830896076873

Epoch: 6| Step: 4
Training loss: 3.0766421391538197
Validation loss: 2.4646902706607405

Epoch: 6| Step: 5
Training loss: 2.0914768006170976
Validation loss: 2.4573199128363847

Epoch: 6| Step: 6
Training loss: 2.332988702209561
Validation loss: 2.4639947217909524

Epoch: 6| Step: 7
Training loss: 2.7668004528314967
Validation loss: 2.4595095089131913

Epoch: 6| Step: 8
Training loss: 2.7994986221465425
Validation loss: 2.456777554480523

Epoch: 6| Step: 9
Training loss: 2.4704318534687526
Validation loss: 2.4605815973217493

Epoch: 6| Step: 10
Training loss: 1.9321094094527425
Validation loss: 2.468423717199677

Epoch: 6| Step: 11
Training loss: 2.1242645337304715
Validation loss: 2.4632057514713264

Epoch: 6| Step: 12
Training loss: 2.895860868547194
Validation loss: 2.458979721004333

Epoch: 6| Step: 13
Training loss: 2.60029181530059
Validation loss: 2.460811535068813

Epoch: 135| Step: 0
Training loss: 2.2402181982306084
Validation loss: 2.4580679658670914

Epoch: 6| Step: 1
Training loss: 2.693678385408799
Validation loss: 2.460716600948908

Epoch: 6| Step: 2
Training loss: 2.8634324599824
Validation loss: 2.4592079664912068

Epoch: 6| Step: 3
Training loss: 2.4744413419667044
Validation loss: 2.461848176253352

Epoch: 6| Step: 4
Training loss: 2.476480765453052
Validation loss: 2.4691296860904646

Epoch: 6| Step: 5
Training loss: 2.89526819070672
Validation loss: 2.4782034073845094

Epoch: 6| Step: 6
Training loss: 1.7459429989453854
Validation loss: 2.4693595680933176

Epoch: 6| Step: 7
Training loss: 2.3681129182621627
Validation loss: 2.47499861412138

Epoch: 6| Step: 8
Training loss: 2.504434562566954
Validation loss: 2.477645837640407

Epoch: 6| Step: 9
Training loss: 2.68712347187482
Validation loss: 2.4690502805012766

Epoch: 6| Step: 10
Training loss: 2.919702058511045
Validation loss: 2.4678197387650975

Epoch: 6| Step: 11
Training loss: 2.279804764804434
Validation loss: 2.467483815491486

Epoch: 6| Step: 12
Training loss: 2.5800155643614655
Validation loss: 2.465727263353692

Epoch: 6| Step: 13
Training loss: 2.1888650177473186
Validation loss: 2.4658364917992306

Epoch: 136| Step: 0
Training loss: 2.368514189645638
Validation loss: 2.468088471834725

Epoch: 6| Step: 1
Training loss: 2.59128361372393
Validation loss: 2.466468795258828

Epoch: 6| Step: 2
Training loss: 2.7226600154374516
Validation loss: 2.4623818009307765

Epoch: 6| Step: 3
Training loss: 2.5126091549064737
Validation loss: 2.4710181235247384

Epoch: 6| Step: 4
Training loss: 2.700737665214786
Validation loss: 2.470750730354942

Epoch: 6| Step: 5
Training loss: 2.167992724036926
Validation loss: 2.463234208151132

Epoch: 6| Step: 6
Training loss: 2.0167056003732076
Validation loss: 2.4663205969390067

Epoch: 6| Step: 7
Training loss: 2.2540964347160286
Validation loss: 2.4682002360820543

Epoch: 6| Step: 8
Training loss: 2.8696930043914324
Validation loss: 2.4673407834162253

Epoch: 6| Step: 9
Training loss: 2.5686367334792792
Validation loss: 2.4637373402304297

Epoch: 6| Step: 10
Training loss: 2.8542653273262553
Validation loss: 2.4653598025530705

Epoch: 6| Step: 11
Training loss: 2.420354747465061
Validation loss: 2.4655715504676112

Epoch: 6| Step: 12
Training loss: 2.3113016683725385
Validation loss: 2.464256220628564

Epoch: 6| Step: 13
Training loss: 2.7089229431007658
Validation loss: 2.4713689859238714

Epoch: 137| Step: 0
Training loss: 2.109115471592242
Validation loss: 2.4651149755698056

Epoch: 6| Step: 1
Training loss: 2.10724108099897
Validation loss: 2.4596928915750578

Epoch: 6| Step: 2
Training loss: 2.0830964017290423
Validation loss: 2.470289209245191

Epoch: 6| Step: 3
Training loss: 2.433613343871763
Validation loss: 2.455766320916693

Epoch: 6| Step: 4
Training loss: 3.188820658835154
Validation loss: 2.458666161997234

Epoch: 6| Step: 5
Training loss: 2.455108132554532
Validation loss: 2.463456083159325

Epoch: 6| Step: 6
Training loss: 2.810564180258572
Validation loss: 2.4611807405263106

Epoch: 6| Step: 7
Training loss: 2.3750995815883043
Validation loss: 2.4580232995866065

Epoch: 6| Step: 8
Training loss: 2.8866138568244013
Validation loss: 2.4665115284032

Epoch: 6| Step: 9
Training loss: 2.4432916547994425
Validation loss: 2.46235086534861

Epoch: 6| Step: 10
Training loss: 2.1691186553100796
Validation loss: 2.464271982883978

Epoch: 6| Step: 11
Training loss: 2.4353569586890855
Validation loss: 2.459618141082683

Epoch: 6| Step: 12
Training loss: 2.3542734532625595
Validation loss: 2.4600139277536877

Epoch: 6| Step: 13
Training loss: 2.8499721324963616
Validation loss: 2.4616805957907184

Epoch: 138| Step: 0
Training loss: 2.521015717605324
Validation loss: 2.468057317977025

Epoch: 6| Step: 1
Training loss: 2.24737533495157
Validation loss: 2.4609156451188334

Epoch: 6| Step: 2
Training loss: 2.9744008142064926
Validation loss: 2.457936098580556

Epoch: 6| Step: 3
Training loss: 2.5331439244419682
Validation loss: 2.4595410133825424

Epoch: 6| Step: 4
Training loss: 2.299567998867351
Validation loss: 2.4603982324472216

Epoch: 6| Step: 5
Training loss: 2.5022969184659245
Validation loss: 2.4629964137720437

Epoch: 6| Step: 6
Training loss: 2.8319241628460547
Validation loss: 2.4701585413235896

Epoch: 6| Step: 7
Training loss: 2.7288659102338424
Validation loss: 2.464552888872991

Epoch: 6| Step: 8
Training loss: 2.320468370744416
Validation loss: 2.469662992444392

Epoch: 6| Step: 9
Training loss: 2.7906142761092765
Validation loss: 2.4632314173461665

Epoch: 6| Step: 10
Training loss: 2.415366700095237
Validation loss: 2.4737214359833706

Epoch: 6| Step: 11
Training loss: 2.3733355060131687
Validation loss: 2.4693999259873127

Epoch: 6| Step: 12
Training loss: 2.072431753620149
Validation loss: 2.4753513443225916

Epoch: 6| Step: 13
Training loss: 2.066186096347861
Validation loss: 2.479590537329403

Epoch: 139| Step: 0
Training loss: 2.81983821188357
Validation loss: 2.476415764185063

Epoch: 6| Step: 1
Training loss: 2.497544990569626
Validation loss: 2.4747961827366

Epoch: 6| Step: 2
Training loss: 3.0890291203502875
Validation loss: 2.484618584869364

Epoch: 6| Step: 3
Training loss: 3.1379504606130606
Validation loss: 2.476226093857875

Epoch: 6| Step: 4
Training loss: 2.2826477367308433
Validation loss: 2.478700759662804

Epoch: 6| Step: 5
Training loss: 2.1035061041741363
Validation loss: 2.4792980966003526

Epoch: 6| Step: 6
Training loss: 2.4085193188228877
Validation loss: 2.4783447623571893

Epoch: 6| Step: 7
Training loss: 2.414699334645931
Validation loss: 2.477165509767931

Epoch: 6| Step: 8
Training loss: 2.3086614969966566
Validation loss: 2.478203824278089

Epoch: 6| Step: 9
Training loss: 2.092639799563937
Validation loss: 2.474811010819529

Epoch: 6| Step: 10
Training loss: 2.0829802277460314
Validation loss: 2.475225205884217

Epoch: 6| Step: 11
Training loss: 2.7112257746471133
Validation loss: 2.477507851052828

Epoch: 6| Step: 12
Training loss: 2.1981447893932553
Validation loss: 2.473726624463041

Epoch: 6| Step: 13
Training loss: 2.4346795025090557
Validation loss: 2.466946824591223

Epoch: 140| Step: 0
Training loss: 2.513056990341951
Validation loss: 2.467274800504151

Epoch: 6| Step: 1
Training loss: 2.417072481305187
Validation loss: 2.458858778667158

Epoch: 6| Step: 2
Training loss: 2.3076336150163796
Validation loss: 2.4604891575517103

Epoch: 6| Step: 3
Training loss: 2.454345982406511
Validation loss: 2.460042978624621

Epoch: 6| Step: 4
Training loss: 1.980792318242327
Validation loss: 2.46152025215661

Epoch: 6| Step: 5
Training loss: 2.5158278105115928
Validation loss: 2.465995861892549

Epoch: 6| Step: 6
Training loss: 2.6761194614037884
Validation loss: 2.4706379395582023

Epoch: 6| Step: 7
Training loss: 2.2373576497236867
Validation loss: 2.472775360500861

Epoch: 6| Step: 8
Training loss: 2.4654636963658874
Validation loss: 2.4712451767412094

Epoch: 6| Step: 9
Training loss: 2.744786088178975
Validation loss: 2.476883507430888

Epoch: 6| Step: 10
Training loss: 2.946281455854864
Validation loss: 2.473747121260839

Epoch: 6| Step: 11
Training loss: 2.8306687859509165
Validation loss: 2.470032370969104

Epoch: 6| Step: 12
Training loss: 2.449062019942912
Validation loss: 2.4718074456591754

Epoch: 6| Step: 13
Training loss: 2.421416996133677
Validation loss: 2.467488380979361

Epoch: 141| Step: 0
Training loss: 2.600941626891419
Validation loss: 2.4710828647621015

Epoch: 6| Step: 1
Training loss: 2.2848400973207528
Validation loss: 2.4660819722453295

Epoch: 6| Step: 2
Training loss: 2.535920155877804
Validation loss: 2.470136196947804

Epoch: 6| Step: 3
Training loss: 2.207227850065437
Validation loss: 2.4662537247374594

Epoch: 6| Step: 4
Training loss: 1.8627714023366584
Validation loss: 2.4674572034407745

Epoch: 6| Step: 5
Training loss: 2.656517823124866
Validation loss: 2.4655153354097443

Epoch: 6| Step: 6
Training loss: 2.202928466688309
Validation loss: 2.465715031658195

Epoch: 6| Step: 7
Training loss: 2.2158234328495547
Validation loss: 2.4666415518263967

Epoch: 6| Step: 8
Training loss: 2.8441342943034886
Validation loss: 2.4748013047373907

Epoch: 6| Step: 9
Training loss: 1.8225648231647211
Validation loss: 2.4697427805665604

Epoch: 6| Step: 10
Training loss: 2.5713580477595555
Validation loss: 2.47235550741403

Epoch: 6| Step: 11
Training loss: 3.2159208437824027
Validation loss: 2.473491140054268

Epoch: 6| Step: 12
Training loss: 2.603437509817202
Validation loss: 2.467410114304066

Epoch: 6| Step: 13
Training loss: 2.6552277336943324
Validation loss: 2.464812087607818

Epoch: 142| Step: 0
Training loss: 2.343470849261388
Validation loss: 2.470610243668555

Epoch: 6| Step: 1
Training loss: 3.102056891484715
Validation loss: 2.4647169367697495

Epoch: 6| Step: 2
Training loss: 2.2417670197932513
Validation loss: 2.471509397325883

Epoch: 6| Step: 3
Training loss: 2.623464407677766
Validation loss: 2.4732312040715962

Epoch: 6| Step: 4
Training loss: 2.254341704881801
Validation loss: 2.477219118503838

Epoch: 6| Step: 5
Training loss: 2.29433939582718
Validation loss: 2.4750885051739493

Epoch: 6| Step: 6
Training loss: 2.42264569233178
Validation loss: 2.472338486793842

Epoch: 6| Step: 7
Training loss: 2.5999171463896347
Validation loss: 2.470681654041464

Epoch: 6| Step: 8
Training loss: 2.2655610174155125
Validation loss: 2.4781494511427877

Epoch: 6| Step: 9
Training loss: 2.487608143358263
Validation loss: 2.473080309943767

Epoch: 6| Step: 10
Training loss: 2.2730490231344036
Validation loss: 2.4731057448011526

Epoch: 6| Step: 11
Training loss: 2.3915100453983484
Validation loss: 2.469888400518087

Epoch: 6| Step: 12
Training loss: 2.648597284858923
Validation loss: 2.476371332566216

Epoch: 6| Step: 13
Training loss: 2.529289145439444
Validation loss: 2.47917129345203

Epoch: 143| Step: 0
Training loss: 2.323395604138757
Validation loss: 2.476203403050527

Epoch: 6| Step: 1
Training loss: 2.04601590131172
Validation loss: 2.4682406773285046

Epoch: 6| Step: 2
Training loss: 2.9527280833417886
Validation loss: 2.4719394892443702

Epoch: 6| Step: 3
Training loss: 3.0397780490462423
Validation loss: 2.468578187782505

Epoch: 6| Step: 4
Training loss: 2.829578679402587
Validation loss: 2.4652965712092145

Epoch: 6| Step: 5
Training loss: 2.003750741141046
Validation loss: 2.467206061730069

Epoch: 6| Step: 6
Training loss: 2.3714612396373456
Validation loss: 2.4718086674242152

Epoch: 6| Step: 7
Training loss: 2.2572091428291343
Validation loss: 2.4694052200959216

Epoch: 6| Step: 8
Training loss: 3.003006223618152
Validation loss: 2.4681976360349807

Epoch: 6| Step: 9
Training loss: 1.9215403319708768
Validation loss: 2.4704563665993455

Epoch: 6| Step: 10
Training loss: 2.3577095873842486
Validation loss: 2.4797699191668983

Epoch: 6| Step: 11
Training loss: 2.392611407612894
Validation loss: 2.4839587712646787

Epoch: 6| Step: 12
Training loss: 2.4181552993717923
Validation loss: 2.469664295719365

Epoch: 6| Step: 13
Training loss: 2.350171257434236
Validation loss: 2.473372144351747

Epoch: 144| Step: 0
Training loss: 2.114770163815482
Validation loss: 2.4758898987969484

Epoch: 6| Step: 1
Training loss: 1.991979371212999
Validation loss: 2.471708215423017

Epoch: 6| Step: 2
Training loss: 2.771951110551835
Validation loss: 2.476862090047695

Epoch: 6| Step: 3
Training loss: 2.5567762136386554
Validation loss: 2.4709408692175776

Epoch: 6| Step: 4
Training loss: 2.8366365438162617
Validation loss: 2.4814829517618993

Epoch: 6| Step: 5
Training loss: 2.215675695616796
Validation loss: 2.4844859196435434

Epoch: 6| Step: 6
Training loss: 2.193220016930261
Validation loss: 2.4863084511129596

Epoch: 6| Step: 7
Training loss: 2.8394046323264073
Validation loss: 2.476216489605886

Epoch: 6| Step: 8
Training loss: 2.99998442327906
Validation loss: 2.4841100683443518

Epoch: 6| Step: 9
Training loss: 2.426082967032918
Validation loss: 2.4760840722992987

Epoch: 6| Step: 10
Training loss: 2.7083367176523825
Validation loss: 2.471548787618083

Epoch: 6| Step: 11
Training loss: 1.8135856796904095
Validation loss: 2.474245385364984

Epoch: 6| Step: 12
Training loss: 2.364729306816965
Validation loss: 2.47894985522496

Epoch: 6| Step: 13
Training loss: 2.4784163507009622
Validation loss: 2.476221729022825

Epoch: 145| Step: 0
Training loss: 2.714439921910346
Validation loss: 2.472855369581612

Epoch: 6| Step: 1
Training loss: 2.1541941696959337
Validation loss: 2.4731773241234505

Epoch: 6| Step: 2
Training loss: 2.674281057556346
Validation loss: 2.479180140952885

Epoch: 6| Step: 3
Training loss: 2.403946207165077
Validation loss: 2.480925726660218

Epoch: 6| Step: 4
Training loss: 2.1976254045726815
Validation loss: 2.478035826519758

Epoch: 6| Step: 5
Training loss: 2.7281387276320483
Validation loss: 2.4773169169701577

Epoch: 6| Step: 6
Training loss: 2.564944706073572
Validation loss: 2.485853303178386

Epoch: 6| Step: 7
Training loss: 2.7052838298930415
Validation loss: 2.4810389226371403

Epoch: 6| Step: 8
Training loss: 2.425538178334723
Validation loss: 2.4820900812121893

Epoch: 6| Step: 9
Training loss: 2.471973294740392
Validation loss: 2.4820314145791067

Epoch: 6| Step: 10
Training loss: 2.253796659082883
Validation loss: 2.4822010949553475

Epoch: 6| Step: 11
Training loss: 2.250619167329857
Validation loss: 2.4839231212086434

Epoch: 6| Step: 12
Training loss: 2.186167065643385
Validation loss: 2.4815995009457668

Epoch: 6| Step: 13
Training loss: 2.544385852120593
Validation loss: 2.4848270444850757

Epoch: 146| Step: 0
Training loss: 3.068913031635101
Validation loss: 2.48237255656716

Epoch: 6| Step: 1
Training loss: 2.7850349474756846
Validation loss: 2.482057542174353

Epoch: 6| Step: 2
Training loss: 2.0004069391146655
Validation loss: 2.4864407633967844

Epoch: 6| Step: 3
Training loss: 2.7724444263553787
Validation loss: 2.4843195463185523

Epoch: 6| Step: 4
Training loss: 2.568212515109704
Validation loss: 2.484647707896585

Epoch: 6| Step: 5
Training loss: 2.6959935309222116
Validation loss: 2.4831261684960024

Epoch: 6| Step: 6
Training loss: 2.3825859587494587
Validation loss: 2.484129871615027

Epoch: 6| Step: 7
Training loss: 2.8693596618016386
Validation loss: 2.480158957211923

Epoch: 6| Step: 8
Training loss: 2.3488273048367727
Validation loss: 2.48331657591762

Epoch: 6| Step: 9
Training loss: 2.4822975925935635
Validation loss: 2.4856739287292275

Epoch: 6| Step: 10
Training loss: 2.116288898829294
Validation loss: 2.478895498453415

Epoch: 6| Step: 11
Training loss: 2.058335463590974
Validation loss: 2.478578390855304

Epoch: 6| Step: 12
Training loss: 1.7255715680994808
Validation loss: 2.4870371680295045

Epoch: 6| Step: 13
Training loss: 2.1744411320510313
Validation loss: 2.490401709425875

Epoch: 147| Step: 0
Training loss: 2.157410682429549
Validation loss: 2.4853406185166502

Epoch: 6| Step: 1
Training loss: 1.6819967320395712
Validation loss: 2.4830785603584973

Epoch: 6| Step: 2
Training loss: 2.4178109803132743
Validation loss: 2.4819562962106816

Epoch: 6| Step: 3
Training loss: 2.621397634704552
Validation loss: 2.479174635310683

Epoch: 6| Step: 4
Training loss: 1.8966831217064857
Validation loss: 2.4802374063577175

Epoch: 6| Step: 5
Training loss: 2.1975418663159583
Validation loss: 2.485887047339384

Epoch: 6| Step: 6
Training loss: 2.46783304689705
Validation loss: 2.485475196586209

Epoch: 6| Step: 7
Training loss: 2.299981747430441
Validation loss: 2.486003525914305

Epoch: 6| Step: 8
Training loss: 2.6013960684845654
Validation loss: 2.4854632379389963

Epoch: 6| Step: 9
Training loss: 2.9309764417198076
Validation loss: 2.490396555686993

Epoch: 6| Step: 10
Training loss: 2.1298240433131683
Validation loss: 2.4836233669457837

Epoch: 6| Step: 11
Training loss: 2.4691583802668555
Validation loss: 2.490931067652452

Epoch: 6| Step: 12
Training loss: 2.8793299038474958
Validation loss: 2.4886792242440325

Epoch: 6| Step: 13
Training loss: 3.273637351260576
Validation loss: 2.4870931922110913

Epoch: 148| Step: 0
Training loss: 3.0887117301518345
Validation loss: 2.48226964260186

Epoch: 6| Step: 1
Training loss: 2.9425048397675857
Validation loss: 2.4903259180733235

Epoch: 6| Step: 2
Training loss: 2.14751911301373
Validation loss: 2.4944964707416446

Epoch: 6| Step: 3
Training loss: 2.303166084492464
Validation loss: 2.492268623777623

Epoch: 6| Step: 4
Training loss: 1.9928867683611102
Validation loss: 2.49657620586549

Epoch: 6| Step: 5
Training loss: 3.0634396726839306
Validation loss: 2.4875120833597038

Epoch: 6| Step: 6
Training loss: 2.2884803005551637
Validation loss: 2.4847076481215877

Epoch: 6| Step: 7
Training loss: 2.264767820066462
Validation loss: 2.50244869473024

Epoch: 6| Step: 8
Training loss: 2.3028530255294064
Validation loss: 2.5053458119907734

Epoch: 6| Step: 9
Training loss: 3.1065919008658653
Validation loss: 2.5056137793158006

Epoch: 6| Step: 10
Training loss: 2.40911070961119
Validation loss: 2.502857577817821

Epoch: 6| Step: 11
Training loss: 1.9003352346316542
Validation loss: 2.499649055008229

Epoch: 6| Step: 12
Training loss: 2.242610240255151
Validation loss: 2.4992113617905782

Epoch: 6| Step: 13
Training loss: 2.2670839019178275
Validation loss: 2.4997213049359863

Epoch: 149| Step: 0
Training loss: 2.463742356194145
Validation loss: 2.4968959054720243

Epoch: 6| Step: 1
Training loss: 3.301609057392908
Validation loss: 2.485820134028006

Epoch: 6| Step: 2
Training loss: 2.0671927500317167
Validation loss: 2.487031200457107

Epoch: 6| Step: 3
Training loss: 2.2198425611738606
Validation loss: 2.479945554648364

Epoch: 6| Step: 4
Training loss: 2.2159888050884518
Validation loss: 2.478039755202908

Epoch: 6| Step: 5
Training loss: 2.8526328390418354
Validation loss: 2.475770889987618

Epoch: 6| Step: 6
Training loss: 2.528099265515749
Validation loss: 2.4744933235878483

Epoch: 6| Step: 7
Training loss: 2.620427645369492
Validation loss: 2.470664597765013

Epoch: 6| Step: 8
Training loss: 2.134507173212955
Validation loss: 2.4806166797491036

Epoch: 6| Step: 9
Training loss: 1.9994259845020097
Validation loss: 2.47914845329027

Epoch: 6| Step: 10
Training loss: 2.6950188075950443
Validation loss: 2.485689131539535

Epoch: 6| Step: 11
Training loss: 2.526612448685162
Validation loss: 2.479294835044671

Epoch: 6| Step: 12
Training loss: 2.3320375886508287
Validation loss: 2.48298751025388

Epoch: 6| Step: 13
Training loss: 2.3860258854231704
Validation loss: 2.482248351732631

Epoch: 150| Step: 0
Training loss: 2.9248258816010066
Validation loss: 2.478311476680559

Epoch: 6| Step: 1
Training loss: 2.205231004927877
Validation loss: 2.4822338962489114

Epoch: 6| Step: 2
Training loss: 2.902456946238491
Validation loss: 2.488844412049564

Epoch: 6| Step: 3
Training loss: 2.081176124155142
Validation loss: 2.4759729528033447

Epoch: 6| Step: 4
Training loss: 2.609630275277519
Validation loss: 2.489073135790678

Epoch: 6| Step: 5
Training loss: 2.3773037629113247
Validation loss: 2.4857586940012406

Epoch: 6| Step: 6
Training loss: 2.715724094281709
Validation loss: 2.483316735931164

Epoch: 6| Step: 7
Training loss: 1.6443458144506042
Validation loss: 2.4832708116209297

Epoch: 6| Step: 8
Training loss: 2.4892881742521165
Validation loss: 2.477935963716915

Epoch: 6| Step: 9
Training loss: 2.4175576398224745
Validation loss: 2.476750596341293

Epoch: 6| Step: 10
Training loss: 1.766061779449345
Validation loss: 2.4854369223175095

Epoch: 6| Step: 11
Training loss: 2.800303653872923
Validation loss: 2.481330877950944

Epoch: 6| Step: 12
Training loss: 2.565103278506879
Validation loss: 2.476532832628848

Epoch: 6| Step: 13
Training loss: 2.6524769632991196
Validation loss: 2.4747416785324066

Epoch: 151| Step: 0
Training loss: 2.1925015627639057
Validation loss: 2.4808646699615338

Epoch: 6| Step: 1
Training loss: 2.394010851319975
Validation loss: 2.4751377841217375

Epoch: 6| Step: 2
Training loss: 2.8745554704740055
Validation loss: 2.4838057531618083

Epoch: 6| Step: 3
Training loss: 2.7719189422117636
Validation loss: 2.4861037759181333

Epoch: 6| Step: 4
Training loss: 2.013182468677681
Validation loss: 2.4758121705624667

Epoch: 6| Step: 5
Training loss: 2.1500949084603134
Validation loss: 2.477079479919294

Epoch: 6| Step: 6
Training loss: 2.3559751962544535
Validation loss: 2.4820924906049164

Epoch: 6| Step: 7
Training loss: 3.129681856604529
Validation loss: 2.4788460297097052

Epoch: 6| Step: 8
Training loss: 3.187759089692321
Validation loss: 2.4805637611755613

Epoch: 6| Step: 9
Training loss: 2.0250141378780437
Validation loss: 2.4734155213340823

Epoch: 6| Step: 10
Training loss: 2.312862986351339
Validation loss: 2.480592146880425

Epoch: 6| Step: 11
Training loss: 2.4194053609761665
Validation loss: 2.4860742543742598

Epoch: 6| Step: 12
Training loss: 2.368914386611249
Validation loss: 2.483711777936767

Epoch: 6| Step: 13
Training loss: 1.9057898044104893
Validation loss: 2.4860750215872

Epoch: 152| Step: 0
Training loss: 2.70480382747385
Validation loss: 2.481749372733088

Epoch: 6| Step: 1
Training loss: 2.857714728616873
Validation loss: 2.4804367744207068

Epoch: 6| Step: 2
Training loss: 2.2460693358048136
Validation loss: 2.4802967882998472

Epoch: 6| Step: 3
Training loss: 2.2811321071313575
Validation loss: 2.4785220699962993

Epoch: 6| Step: 4
Training loss: 1.3880297843639717
Validation loss: 2.4846576873726907

Epoch: 6| Step: 5
Training loss: 2.4753688498874595
Validation loss: 2.4855527825080244

Epoch: 6| Step: 6
Training loss: 1.9339191817959043
Validation loss: 2.4858479162187646

Epoch: 6| Step: 7
Training loss: 2.453177093147129
Validation loss: 2.4945137384112432

Epoch: 6| Step: 8
Training loss: 2.2346421728923715
Validation loss: 2.4911121850782276

Epoch: 6| Step: 9
Training loss: 2.4397284273760724
Validation loss: 2.4905903081898897

Epoch: 6| Step: 10
Training loss: 3.1222873358160776
Validation loss: 2.485646895952528

Epoch: 6| Step: 11
Training loss: 2.4833919091538257
Validation loss: 2.4948875605258745

Epoch: 6| Step: 12
Training loss: 2.8401100422131327
Validation loss: 2.4893771342885245

Epoch: 6| Step: 13
Training loss: 2.2544638540653317
Validation loss: 2.4930650527286775

Epoch: 153| Step: 0
Training loss: 2.3199626003736715
Validation loss: 2.4917271905478087

Epoch: 6| Step: 1
Training loss: 2.1778928964165614
Validation loss: 2.4878052116893916

Epoch: 6| Step: 2
Training loss: 2.189128596460432
Validation loss: 2.49449433616902

Epoch: 6| Step: 3
Training loss: 2.545064645482039
Validation loss: 2.4991670015476264

Epoch: 6| Step: 4
Training loss: 2.4038170739395666
Validation loss: 2.493286034200006

Epoch: 6| Step: 5
Training loss: 2.2188875397510572
Validation loss: 2.48873434128586

Epoch: 6| Step: 6
Training loss: 2.491812555216233
Validation loss: 2.4944747904078866

Epoch: 6| Step: 7
Training loss: 2.7138377569304253
Validation loss: 2.4923133619010924

Epoch: 6| Step: 8
Training loss: 2.5366140914394446
Validation loss: 2.490425212254658

Epoch: 6| Step: 9
Training loss: 2.7665219334198783
Validation loss: 2.491770678574511

Epoch: 6| Step: 10
Training loss: 2.4766663731112333
Validation loss: 2.4939968034804845

Epoch: 6| Step: 11
Training loss: 1.961141021015338
Validation loss: 2.49598387156476

Epoch: 6| Step: 12
Training loss: 2.6893478960271167
Validation loss: 2.488140579311565

Epoch: 6| Step: 13
Training loss: 2.5073528878746796
Validation loss: 2.486274560839315

Epoch: 154| Step: 0
Training loss: 2.376373094865058
Validation loss: 2.490912323464243

Epoch: 6| Step: 1
Training loss: 2.0148363566623515
Validation loss: 2.4962513952962904

Epoch: 6| Step: 2
Training loss: 2.8912549131543823
Validation loss: 2.4906750577062717

Epoch: 6| Step: 3
Training loss: 1.5991309338914803
Validation loss: 2.497777348170841

Epoch: 6| Step: 4
Training loss: 2.897328784218716
Validation loss: 2.5026939817911686

Epoch: 6| Step: 5
Training loss: 2.5542785130500167
Validation loss: 2.4930129482934267

Epoch: 6| Step: 6
Training loss: 2.7135325387128795
Validation loss: 2.4988170209086027

Epoch: 6| Step: 7
Training loss: 2.697433477505992
Validation loss: 2.502465415281167

Epoch: 6| Step: 8
Training loss: 2.989227344615637
Validation loss: 2.5067001839013434

Epoch: 6| Step: 9
Training loss: 1.9752716553648495
Validation loss: 2.5078380579453188

Epoch: 6| Step: 10
Training loss: 2.1949839498849837
Validation loss: 2.5078141241177283

Epoch: 6| Step: 11
Training loss: 2.2814962175828226
Validation loss: 2.512172659937571

Epoch: 6| Step: 12
Training loss: 2.2850212383326656
Validation loss: 2.5139340864395643

Epoch: 6| Step: 13
Training loss: 2.1326144060077796
Validation loss: 2.5070688287857363

Epoch: 155| Step: 0
Training loss: 2.980821341160842
Validation loss: 2.507662094216837

Epoch: 6| Step: 1
Training loss: 2.3464048481053217
Validation loss: 2.5106388062349234

Epoch: 6| Step: 2
Training loss: 2.4543156741058434
Validation loss: 2.513816625798766

Epoch: 6| Step: 3
Training loss: 2.2691039636834955
Validation loss: 2.510563261782776

Epoch: 6| Step: 4
Training loss: 1.4890961105860494
Validation loss: 2.5119408429696146

Epoch: 6| Step: 5
Training loss: 2.185148664781146
Validation loss: 2.5040929509471965

Epoch: 6| Step: 6
Training loss: 2.8625227481654445
Validation loss: 2.499692818525166

Epoch: 6| Step: 7
Training loss: 1.7223791474798282
Validation loss: 2.5011931433213537

Epoch: 6| Step: 8
Training loss: 2.6070380796366472
Validation loss: 2.4995415187678094

Epoch: 6| Step: 9
Training loss: 2.4426676428902576
Validation loss: 2.491680703607356

Epoch: 6| Step: 10
Training loss: 2.2672354400634998
Validation loss: 2.5012655075128847

Epoch: 6| Step: 11
Training loss: 2.797851221640468
Validation loss: 2.502723680408567

Epoch: 6| Step: 12
Training loss: 2.494213464639693
Validation loss: 2.4961325772269936

Epoch: 6| Step: 13
Training loss: 2.7586450805901186
Validation loss: 2.497249019525228

Epoch: 156| Step: 0
Training loss: 2.7897551715583084
Validation loss: 2.5039579293903236

Epoch: 6| Step: 1
Training loss: 2.3543546708467047
Validation loss: 2.4965746142280136

Epoch: 6| Step: 2
Training loss: 2.460620774974495
Validation loss: 2.492848530860002

Epoch: 6| Step: 3
Training loss: 2.378834289564843
Validation loss: 2.494404037295103

Epoch: 6| Step: 4
Training loss: 2.29966898070285
Validation loss: 2.495828931886319

Epoch: 6| Step: 5
Training loss: 2.512012802638091
Validation loss: 2.499296796763985

Epoch: 6| Step: 6
Training loss: 2.1328274792714597
Validation loss: 2.498372326911983

Epoch: 6| Step: 7
Training loss: 2.829977703748024
Validation loss: 2.5017881991731707

Epoch: 6| Step: 8
Training loss: 2.031091537163312
Validation loss: 2.501175159184293

Epoch: 6| Step: 9
Training loss: 2.198484362527751
Validation loss: 2.495656866247045

Epoch: 6| Step: 10
Training loss: 2.326250179071435
Validation loss: 2.4930349202720326

Epoch: 6| Step: 11
Training loss: 2.085087635201976
Validation loss: 2.498654687032748

Epoch: 6| Step: 12
Training loss: 2.8211766659962505
Validation loss: 2.4963256059638135

Epoch: 6| Step: 13
Training loss: 2.6862717416628112
Validation loss: 2.490396571642857

Epoch: 157| Step: 0
Training loss: 2.1209098497338923
Validation loss: 2.4908634842210966

Epoch: 6| Step: 1
Training loss: 2.265849766598598
Validation loss: 2.4946255930586565

Epoch: 6| Step: 2
Training loss: 2.739048217805837
Validation loss: 2.496901881296455

Epoch: 6| Step: 3
Training loss: 2.7318389467100213
Validation loss: 2.5003856361505066

Epoch: 6| Step: 4
Training loss: 2.315921108654708
Validation loss: 2.4994647406731234

Epoch: 6| Step: 5
Training loss: 2.096403689224034
Validation loss: 2.5046936955239496

Epoch: 6| Step: 6
Training loss: 2.8443421805727853
Validation loss: 2.5081885700549114

Epoch: 6| Step: 7
Training loss: 2.426146843676219
Validation loss: 2.519993544953773

Epoch: 6| Step: 8
Training loss: 2.095932008557785
Validation loss: 2.5133164042586538

Epoch: 6| Step: 9
Training loss: 1.9497256183765281
Validation loss: 2.5143436620018766

Epoch: 6| Step: 10
Training loss: 2.90012937454506
Validation loss: 2.5149070157430793

Epoch: 6| Step: 11
Training loss: 2.9275542363486102
Validation loss: 2.5128559328571645

Epoch: 6| Step: 12
Training loss: 1.990324877477208
Validation loss: 2.509237453036972

Epoch: 6| Step: 13
Training loss: 2.395279286770814
Validation loss: 2.511904727898772

Epoch: 158| Step: 0
Training loss: 2.4691578974736004
Validation loss: 2.5049717104717315

Epoch: 6| Step: 1
Training loss: 2.4579209019448296
Validation loss: 2.507551708505988

Epoch: 6| Step: 2
Training loss: 2.105839004941709
Validation loss: 2.502209005341632

Epoch: 6| Step: 3
Training loss: 2.502444216842934
Validation loss: 2.500863053440675

Epoch: 6| Step: 4
Training loss: 2.230836427116695
Validation loss: 2.5008797369260485

Epoch: 6| Step: 5
Training loss: 2.2468282808797353
Validation loss: 2.507224278375795

Epoch: 6| Step: 6
Training loss: 2.3368377481793465
Validation loss: 2.497429249168341

Epoch: 6| Step: 7
Training loss: 2.150213222132811
Validation loss: 2.498295902568136

Epoch: 6| Step: 8
Training loss: 2.0163083359757
Validation loss: 2.498749801841831

Epoch: 6| Step: 9
Training loss: 3.2789644546559913
Validation loss: 2.495894430577065

Epoch: 6| Step: 10
Training loss: 2.10521553512718
Validation loss: 2.4953468411160102

Epoch: 6| Step: 11
Training loss: 1.9940107790886141
Validation loss: 2.500500914935254

Epoch: 6| Step: 12
Training loss: 2.8326627461343508
Validation loss: 2.4892003205021633

Epoch: 6| Step: 13
Training loss: 2.809999159408932
Validation loss: 2.4942937658061175

Epoch: 159| Step: 0
Training loss: 1.884855056775584
Validation loss: 2.4928123304706458

Epoch: 6| Step: 1
Training loss: 1.9893200152507873
Validation loss: 2.494770381786254

Epoch: 6| Step: 2
Training loss: 2.3672249668291143
Validation loss: 2.4986682682687

Epoch: 6| Step: 3
Training loss: 2.7577820687060393
Validation loss: 2.5000067075003605

Epoch: 6| Step: 4
Training loss: 2.2274093356021556
Validation loss: 2.4888101012762793

Epoch: 6| Step: 5
Training loss: 3.150078963243685
Validation loss: 2.4897875416107347

Epoch: 6| Step: 6
Training loss: 2.779312058686784
Validation loss: 2.4919871346379887

Epoch: 6| Step: 7
Training loss: 2.6202632310269567
Validation loss: 2.4911085481835613

Epoch: 6| Step: 8
Training loss: 3.0364792541167067
Validation loss: 2.4903320612478024

Epoch: 6| Step: 9
Training loss: 2.043339011955564
Validation loss: 2.4986599986724607

Epoch: 6| Step: 10
Training loss: 2.7583688493576135
Validation loss: 2.5025063507832805

Epoch: 6| Step: 11
Training loss: 1.8552714995894053
Validation loss: 2.5038095218504917

Epoch: 6| Step: 12
Training loss: 2.191464129276869
Validation loss: 2.507878937440357

Epoch: 6| Step: 13
Training loss: 1.9236900628601212
Validation loss: 2.521783071841185

Epoch: 160| Step: 0
Training loss: 2.4542911940512995
Validation loss: 2.5238387002483775

Epoch: 6| Step: 1
Training loss: 2.010256456174755
Validation loss: 2.5357194851848224

Epoch: 6| Step: 2
Training loss: 2.510024096764633
Validation loss: 2.5275079672839085

Epoch: 6| Step: 3
Training loss: 2.7533573117570582
Validation loss: 2.5267905839092917

Epoch: 6| Step: 4
Training loss: 2.4949808281293775
Validation loss: 2.52865500535228

Epoch: 6| Step: 5
Training loss: 2.1075630600297477
Validation loss: 2.511564733550059

Epoch: 6| Step: 6
Training loss: 2.0028573129598275
Validation loss: 2.5173077690933154

Epoch: 6| Step: 7
Training loss: 2.567383834008688
Validation loss: 2.5138347170866706

Epoch: 6| Step: 8
Training loss: 2.01948544359923
Validation loss: 2.5056999633542025

Epoch: 6| Step: 9
Training loss: 2.545873901576724
Validation loss: 2.5025958253931186

Epoch: 6| Step: 10
Training loss: 2.549306820170279
Validation loss: 2.4953336160236512

Epoch: 6| Step: 11
Training loss: 2.6856093742727443
Validation loss: 2.4935076972695245

Epoch: 6| Step: 12
Training loss: 2.419495133157192
Validation loss: 2.4987645116336616

Epoch: 6| Step: 13
Training loss: 2.761747411339076
Validation loss: 2.499558203125173

Epoch: 161| Step: 0
Training loss: 2.429851563241007
Validation loss: 2.50428384283524

Epoch: 6| Step: 1
Training loss: 2.627733260815553
Validation loss: 2.5016071081304294

Epoch: 6| Step: 2
Training loss: 2.637127879861428
Validation loss: 2.5134478639399025

Epoch: 6| Step: 3
Training loss: 2.801691096386744
Validation loss: 2.5139974854010867

Epoch: 6| Step: 4
Training loss: 2.1846825029864134
Validation loss: 2.5186930521418835

Epoch: 6| Step: 5
Training loss: 2.319469979679259
Validation loss: 2.5172430643634023

Epoch: 6| Step: 6
Training loss: 2.8592088995045217
Validation loss: 2.5129171768446867

Epoch: 6| Step: 7
Training loss: 2.2448111147528578
Validation loss: 2.5147960236827944

Epoch: 6| Step: 8
Training loss: 2.4610515265311808
Validation loss: 2.5387018818179286

Epoch: 6| Step: 9
Training loss: 2.1273690649817576
Validation loss: 2.5107492619655534

Epoch: 6| Step: 10
Training loss: 2.4944549099656146
Validation loss: 2.5151181470574975

Epoch: 6| Step: 11
Training loss: 1.7443710807119341
Validation loss: 2.5040513431527924

Epoch: 6| Step: 12
Training loss: 2.4459401260621165
Validation loss: 2.5037051242584614

Epoch: 6| Step: 13
Training loss: 2.5620163251727455
Validation loss: 2.5068272351603187

Epoch: 162| Step: 0
Training loss: 2.5020113483357598
Validation loss: 2.513925946093079

Epoch: 6| Step: 1
Training loss: 1.631282107450123
Validation loss: 2.5019317951628275

Epoch: 6| Step: 2
Training loss: 2.496481613088413
Validation loss: 2.5082320023871336

Epoch: 6| Step: 3
Training loss: 2.223308876375869
Validation loss: 2.510893010154999

Epoch: 6| Step: 4
Training loss: 2.4376988452109147
Validation loss: 2.5117812873170227

Epoch: 6| Step: 5
Training loss: 2.553338957731395
Validation loss: 2.5146750004917826

Epoch: 6| Step: 6
Training loss: 2.18744615761025
Validation loss: 2.507584194038893

Epoch: 6| Step: 7
Training loss: 1.7633283413610243
Validation loss: 2.5023621843405146

Epoch: 6| Step: 8
Training loss: 2.8185270369286775
Validation loss: 2.503093791994134

Epoch: 6| Step: 9
Training loss: 2.579586100534976
Validation loss: 2.499077499578054

Epoch: 6| Step: 10
Training loss: 2.4721901018815906
Validation loss: 2.5018799230352577

Epoch: 6| Step: 11
Training loss: 2.720617420300775
Validation loss: 2.490710292043374

Epoch: 6| Step: 12
Training loss: 2.7829552898153223
Validation loss: 2.490642287809776

Epoch: 6| Step: 13
Training loss: 2.438183419692112
Validation loss: 2.48447346042362

Epoch: 163| Step: 0
Training loss: 2.3644545487834905
Validation loss: 2.493662685564311

Epoch: 6| Step: 1
Training loss: 2.678610092973945
Validation loss: 2.48996219917825

Epoch: 6| Step: 2
Training loss: 2.5825431189394767
Validation loss: 2.4818364815503613

Epoch: 6| Step: 3
Training loss: 2.331436771550704
Validation loss: 2.487069066737916

Epoch: 6| Step: 4
Training loss: 2.424422173627473
Validation loss: 2.4786011080157824

Epoch: 6| Step: 5
Training loss: 2.1165787500861293
Validation loss: 2.4839836148199224

Epoch: 6| Step: 6
Training loss: 2.940243677433969
Validation loss: 2.4901039558117466

Epoch: 6| Step: 7
Training loss: 2.570273170054337
Validation loss: 2.4872670644454082

Epoch: 6| Step: 8
Training loss: 2.3693890799041415
Validation loss: 2.5046090237290928

Epoch: 6| Step: 9
Training loss: 2.0081835452158336
Validation loss: 2.512215762405867

Epoch: 6| Step: 10
Training loss: 2.401990017783635
Validation loss: 2.519800634054118

Epoch: 6| Step: 11
Training loss: 1.8678232810424282
Validation loss: 2.525798429333762

Epoch: 6| Step: 12
Training loss: 2.9285788918110987
Validation loss: 2.5344422387525984

Epoch: 6| Step: 13
Training loss: 2.5215128358494945
Validation loss: 2.5342220550307957

Epoch: 164| Step: 0
Training loss: 2.1549139997842293
Validation loss: 2.524423711624249

Epoch: 6| Step: 1
Training loss: 2.0517585097125184
Validation loss: 2.5111563346057624

Epoch: 6| Step: 2
Training loss: 2.554837563683187
Validation loss: 2.50805789622315

Epoch: 6| Step: 3
Training loss: 1.787483151229733
Validation loss: 2.5088447514133545

Epoch: 6| Step: 4
Training loss: 2.734079573884602
Validation loss: 2.49292384702641

Epoch: 6| Step: 5
Training loss: 2.9768812754787346
Validation loss: 2.483225334515819

Epoch: 6| Step: 6
Training loss: 2.483867761424488
Validation loss: 2.4877899339611846

Epoch: 6| Step: 7
Training loss: 1.9662500282282744
Validation loss: 2.490412718925221

Epoch: 6| Step: 8
Training loss: 2.163508705863954
Validation loss: 2.4998241283225995

Epoch: 6| Step: 9
Training loss: 2.5099192294009094
Validation loss: 2.49581178476481

Epoch: 6| Step: 10
Training loss: 2.940218540035993
Validation loss: 2.4850908603597928

Epoch: 6| Step: 11
Training loss: 2.74879793424562
Validation loss: 2.495157526913187

Epoch: 6| Step: 12
Training loss: 2.702270019795893
Validation loss: 2.492415781438049

Epoch: 6| Step: 13
Training loss: 2.432822507863417
Validation loss: 2.4945305280786925

Epoch: 165| Step: 0
Training loss: 2.4163578318429555
Validation loss: 2.5001215587308927

Epoch: 6| Step: 1
Training loss: 2.067744667124752
Validation loss: 2.496499599202849

Epoch: 6| Step: 2
Training loss: 2.587026407143171
Validation loss: 2.4925726071836536

Epoch: 6| Step: 3
Training loss: 2.6329923392885974
Validation loss: 2.4981185270506656

Epoch: 6| Step: 4
Training loss: 1.6901360162477956
Validation loss: 2.495242758301614

Epoch: 6| Step: 5
Training loss: 1.755232957012595
Validation loss: 2.5031460358318784

Epoch: 6| Step: 6
Training loss: 2.9472855250632843
Validation loss: 2.5040786136331064

Epoch: 6| Step: 7
Training loss: 2.364649050523378
Validation loss: 2.505165913963581

Epoch: 6| Step: 8
Training loss: 2.2231807257548084
Validation loss: 2.5164824499408476

Epoch: 6| Step: 9
Training loss: 2.4225931394956213
Validation loss: 2.5133827594514555

Epoch: 6| Step: 10
Training loss: 2.5825416418302165
Validation loss: 2.5037225347400556

Epoch: 6| Step: 11
Training loss: 3.194834479878543
Validation loss: 2.51316194813411

Epoch: 6| Step: 12
Training loss: 2.467581170475602
Validation loss: 2.4991022405389884

Epoch: 6| Step: 13
Training loss: 2.2292884603247645
Validation loss: 2.5042815579311046

Epoch: 166| Step: 0
Training loss: 1.9833542007929956
Validation loss: 2.502237050217863

Epoch: 6| Step: 1
Training loss: 2.6315994864214414
Validation loss: 2.496110322088351

Epoch: 6| Step: 2
Training loss: 2.3257915913047933
Validation loss: 2.4944119625719026

Epoch: 6| Step: 3
Training loss: 2.2847568260697813
Validation loss: 2.488033815354967

Epoch: 6| Step: 4
Training loss: 2.520579606415281
Validation loss: 2.5041342486178353

Epoch: 6| Step: 5
Training loss: 2.3711649398548955
Validation loss: 2.489646389427389

Epoch: 6| Step: 6
Training loss: 2.334611599331389
Validation loss: 2.478467367156857

Epoch: 6| Step: 7
Training loss: 2.09190378352212
Validation loss: 2.494928556654001

Epoch: 6| Step: 8
Training loss: 3.180545325635277
Validation loss: 2.490279484757888

Epoch: 6| Step: 9
Training loss: 1.9896873793100927
Validation loss: 2.492176067840281

Epoch: 6| Step: 10
Training loss: 2.1346168570933086
Validation loss: 2.4978834570511017

Epoch: 6| Step: 11
Training loss: 2.769349946408252
Validation loss: 2.494041653996767

Epoch: 6| Step: 12
Training loss: 2.4806746269753788
Validation loss: 2.4997558315567825

Epoch: 6| Step: 13
Training loss: 2.582471847454587
Validation loss: 2.5039496455248282

Epoch: 167| Step: 0
Training loss: 2.3724132304106798
Validation loss: 2.4984470709990556

Epoch: 6| Step: 1
Training loss: 2.802814846677943
Validation loss: 2.503633957457675

Epoch: 6| Step: 2
Training loss: 2.921583028474965
Validation loss: 2.50638768808032

Epoch: 6| Step: 3
Training loss: 1.841290789720176
Validation loss: 2.505074326281173

Epoch: 6| Step: 4
Training loss: 2.6719447790481587
Validation loss: 2.5060583616890835

Epoch: 6| Step: 5
Training loss: 2.403324677464545
Validation loss: 2.4986981976170832

Epoch: 6| Step: 6
Training loss: 2.1868444277841452
Validation loss: 2.503029688220278

Epoch: 6| Step: 7
Training loss: 2.1804232979072298
Validation loss: 2.4996192165299647

Epoch: 6| Step: 8
Training loss: 1.7899630083492075
Validation loss: 2.501062826893011

Epoch: 6| Step: 9
Training loss: 2.1752179442203943
Validation loss: 2.501744424660681

Epoch: 6| Step: 10
Training loss: 2.240986040254867
Validation loss: 2.50654506642886

Epoch: 6| Step: 11
Training loss: 3.2959448781450376
Validation loss: 2.5056618156465653

Epoch: 6| Step: 12
Training loss: 2.4015973179811754
Validation loss: 2.5063027643498352

Epoch: 6| Step: 13
Training loss: 2.0311160703668536
Validation loss: 2.5186942827169108

Epoch: 168| Step: 0
Training loss: 2.925575727876237
Validation loss: 2.5193081069427614

Epoch: 6| Step: 1
Training loss: 2.529500097410129
Validation loss: 2.535546647446334

Epoch: 6| Step: 2
Training loss: 2.688935894288168
Validation loss: 2.528753658762818

Epoch: 6| Step: 3
Training loss: 2.348057361935386
Validation loss: 2.53931750459746

Epoch: 6| Step: 4
Training loss: 2.079135735026236
Validation loss: 2.5342763148550915

Epoch: 6| Step: 5
Training loss: 2.3685584803636037
Validation loss: 2.540325034788671

Epoch: 6| Step: 6
Training loss: 3.2150800207926546
Validation loss: 2.524034616469737

Epoch: 6| Step: 7
Training loss: 2.6216976646859056
Validation loss: 2.515810918157425

Epoch: 6| Step: 8
Training loss: 2.331433090097392
Validation loss: 2.5070947430032824

Epoch: 6| Step: 9
Training loss: 2.032209668508588
Validation loss: 2.511315692620243

Epoch: 6| Step: 10
Training loss: 1.5397643991556718
Validation loss: 2.503853950608925

Epoch: 6| Step: 11
Training loss: 2.0088352314896736
Validation loss: 2.504308262617986

Epoch: 6| Step: 12
Training loss: 2.632706274951628
Validation loss: 2.501549097772231

Epoch: 6| Step: 13
Training loss: 2.21262707533916
Validation loss: 2.5024187149631785

Epoch: 169| Step: 0
Training loss: 1.9542214939692621
Validation loss: 2.505577715780185

Epoch: 6| Step: 1
Training loss: 2.173487222680023
Validation loss: 2.5050640157158197

Epoch: 6| Step: 2
Training loss: 2.3504187758644277
Validation loss: 2.5073962158246785

Epoch: 6| Step: 3
Training loss: 3.516764138363961
Validation loss: 2.5154333416765895

Epoch: 6| Step: 4
Training loss: 2.5871064923474996
Validation loss: 2.5080201567083718

Epoch: 6| Step: 5
Training loss: 2.3261105828013444
Validation loss: 2.509882087825561

Epoch: 6| Step: 6
Training loss: 2.0378044603034455
Validation loss: 2.511869608935079

Epoch: 6| Step: 7
Training loss: 2.370553824022283
Validation loss: 2.5067237082883356

Epoch: 6| Step: 8
Training loss: 2.3424102005494127
Validation loss: 2.5043137209384234

Epoch: 6| Step: 9
Training loss: 2.5074634725053295
Validation loss: 2.498047081790982

Epoch: 6| Step: 10
Training loss: 2.3823822133268155
Validation loss: 2.5033046815081645

Epoch: 6| Step: 11
Training loss: 2.8541640864079825
Validation loss: 2.501668643387283

Epoch: 6| Step: 12
Training loss: 1.8186843204764804
Validation loss: 2.501593098084985

Epoch: 6| Step: 13
Training loss: 2.110494810906389
Validation loss: 2.5044569499963396

Epoch: 170| Step: 0
Training loss: 1.814395242513074
Validation loss: 2.5009169486419816

Epoch: 6| Step: 1
Training loss: 2.5193120816739167
Validation loss: 2.514492340674966

Epoch: 6| Step: 2
Training loss: 2.2454161044688914
Validation loss: 2.5054315849539712

Epoch: 6| Step: 3
Training loss: 2.661435529657205
Validation loss: 2.512349462348648

Epoch: 6| Step: 4
Training loss: 2.3151798700771713
Validation loss: 2.5128960349500438

Epoch: 6| Step: 5
Training loss: 2.7483770609982514
Validation loss: 2.5331094450480487

Epoch: 6| Step: 6
Training loss: 2.5446679785690676
Validation loss: 2.524449565743552

Epoch: 6| Step: 7
Training loss: 2.3942633972207394
Validation loss: 2.5315700689708933

Epoch: 6| Step: 8
Training loss: 2.7029264520482026
Validation loss: 2.5361155775109085

Epoch: 6| Step: 9
Training loss: 2.0772138620250122
Validation loss: 2.526865721849166

Epoch: 6| Step: 10
Training loss: 2.062083577975479
Validation loss: 2.528487373727366

Epoch: 6| Step: 11
Training loss: 1.9850896314471924
Validation loss: 2.5253673059695325

Epoch: 6| Step: 12
Training loss: 2.924686160734848
Validation loss: 2.517670820338421

Epoch: 6| Step: 13
Training loss: 2.4597693198680464
Validation loss: 2.5125056923063207

Epoch: 171| Step: 0
Training loss: 2.608193958284073
Validation loss: 2.502467916208667

Epoch: 6| Step: 1
Training loss: 1.9420194520928797
Validation loss: 2.4975945503378645

Epoch: 6| Step: 2
Training loss: 2.4445031139769826
Validation loss: 2.489163532270006

Epoch: 6| Step: 3
Training loss: 2.497597207286429
Validation loss: 2.496180254771012

Epoch: 6| Step: 4
Training loss: 2.241098066159706
Validation loss: 2.507131910022026

Epoch: 6| Step: 5
Training loss: 2.8657109670941745
Validation loss: 2.506707269774298

Epoch: 6| Step: 6
Training loss: 2.0065292829500847
Validation loss: 2.5085172762124754

Epoch: 6| Step: 7
Training loss: 2.4819227867934353
Validation loss: 2.5029976754065344

Epoch: 6| Step: 8
Training loss: 2.8531850718664025
Validation loss: 2.503441270015819

Epoch: 6| Step: 9
Training loss: 2.702654670855576
Validation loss: 2.5010015706623387

Epoch: 6| Step: 10
Training loss: 2.1793379964878765
Validation loss: 2.5018143269188347

Epoch: 6| Step: 11
Training loss: 2.5222586603468775
Validation loss: 2.5036820952586316

Epoch: 6| Step: 12
Training loss: 2.1292576491095443
Validation loss: 2.5090035277202847

Epoch: 6| Step: 13
Training loss: 2.0028814777763997
Validation loss: 2.50421938869771

Epoch: 172| Step: 0
Training loss: 2.6449187092106476
Validation loss: 2.5153622223456966

Epoch: 6| Step: 1
Training loss: 2.1382841133207218
Validation loss: 2.51480999177647

Epoch: 6| Step: 2
Training loss: 2.2076363333295674
Validation loss: 2.5043849953563906

Epoch: 6| Step: 3
Training loss: 2.1180146913460183
Validation loss: 2.5002278065204555

Epoch: 6| Step: 4
Training loss: 2.491457362830438
Validation loss: 2.499099378486627

Epoch: 6| Step: 5
Training loss: 2.9695120385563936
Validation loss: 2.494445782113324

Epoch: 6| Step: 6
Training loss: 1.9461449370204942
Validation loss: 2.4943799427059647

Epoch: 6| Step: 7
Training loss: 2.251921786696518
Validation loss: 2.4920722273074363

Epoch: 6| Step: 8
Training loss: 2.12983120764369
Validation loss: 2.491184220020597

Epoch: 6| Step: 9
Training loss: 1.9874359312467276
Validation loss: 2.485639606164662

Epoch: 6| Step: 10
Training loss: 2.7525594245115816
Validation loss: 2.4892893874374615

Epoch: 6| Step: 11
Training loss: 2.5629745602217735
Validation loss: 2.500579496613387

Epoch: 6| Step: 12
Training loss: 2.7214312431456786
Validation loss: 2.5055014795001957

Epoch: 6| Step: 13
Training loss: 2.3294649300540162
Validation loss: 2.5096484125971266

Epoch: 173| Step: 0
Training loss: 2.6497371039351627
Validation loss: 2.503570232568578

Epoch: 6| Step: 1
Training loss: 2.748378015235555
Validation loss: 2.5152970884178547

Epoch: 6| Step: 2
Training loss: 3.0448183601210714
Validation loss: 2.5232903247663536

Epoch: 6| Step: 3
Training loss: 2.2390837237782386
Validation loss: 2.5270316684491165

Epoch: 6| Step: 4
Training loss: 1.6275805743732845
Validation loss: 2.5116061694126994

Epoch: 6| Step: 5
Training loss: 1.8260581567617775
Validation loss: 2.5189219603040605

Epoch: 6| Step: 6
Training loss: 2.782723454416731
Validation loss: 2.502996572056535

Epoch: 6| Step: 7
Training loss: 2.232700173693905
Validation loss: 2.5102097411500934

Epoch: 6| Step: 8
Training loss: 2.5924989371817166
Validation loss: 2.5105477901631374

Epoch: 6| Step: 9
Training loss: 2.463709647410913
Validation loss: 2.4986166226016002

Epoch: 6| Step: 10
Training loss: 2.117234908695739
Validation loss: 2.5058332260008336

Epoch: 6| Step: 11
Training loss: 2.4031604898161154
Validation loss: 2.4948489687609734

Epoch: 6| Step: 12
Training loss: 2.301727359458603
Validation loss: 2.489595522245525

Epoch: 6| Step: 13
Training loss: 2.486842627380537
Validation loss: 2.5000496541496338

Epoch: 174| Step: 0
Training loss: 2.366009208087303
Validation loss: 2.4919493271434923

Epoch: 6| Step: 1
Training loss: 2.0839752225665937
Validation loss: 2.4968752724556262

Epoch: 6| Step: 2
Training loss: 2.635599805979708
Validation loss: 2.4950323181250713

Epoch: 6| Step: 3
Training loss: 2.396466367820234
Validation loss: 2.50326110812692

Epoch: 6| Step: 4
Training loss: 2.456494392486452
Validation loss: 2.4955052182935287

Epoch: 6| Step: 5
Training loss: 1.9423031490938114
Validation loss: 2.4934206216835864

Epoch: 6| Step: 6
Training loss: 2.083980714031461
Validation loss: 2.490938373859523

Epoch: 6| Step: 7
Training loss: 2.8972968558718524
Validation loss: 2.4988741087835677

Epoch: 6| Step: 8
Training loss: 2.7230983468240417
Validation loss: 2.4980892827001253

Epoch: 6| Step: 9
Training loss: 2.191869241420294
Validation loss: 2.505693802352406

Epoch: 6| Step: 10
Training loss: 1.7796881001700042
Validation loss: 2.5135503787477163

Epoch: 6| Step: 11
Training loss: 2.6123486780758665
Validation loss: 2.5199283099699685

Epoch: 6| Step: 12
Training loss: 2.8141073084625754
Validation loss: 2.5230176515368723

Epoch: 6| Step: 13
Training loss: 2.514043654518786
Validation loss: 2.537978158883381

Epoch: 175| Step: 0
Training loss: 2.9112232274830485
Validation loss: 2.5381312144263757

Epoch: 6| Step: 1
Training loss: 2.2614250453594096
Validation loss: 2.5318174236389446

Epoch: 6| Step: 2
Training loss: 2.103787857050502
Validation loss: 2.530799252600168

Epoch: 6| Step: 3
Training loss: 2.7138034940742233
Validation loss: 2.5365888547638504

Epoch: 6| Step: 4
Training loss: 2.1391885211790678
Validation loss: 2.5147782158309533

Epoch: 6| Step: 5
Training loss: 2.9599266239041273
Validation loss: 2.521581827649765

Epoch: 6| Step: 6
Training loss: 2.553634006369897
Validation loss: 2.5176118069633207

Epoch: 6| Step: 7
Training loss: 1.6907419922235885
Validation loss: 2.4996585294851603

Epoch: 6| Step: 8
Training loss: 2.8859039519486864
Validation loss: 2.501329227573601

Epoch: 6| Step: 9
Training loss: 2.1799473761410253
Validation loss: 2.502901023276921

Epoch: 6| Step: 10
Training loss: 1.8575860401213875
Validation loss: 2.5107894293585216

Epoch: 6| Step: 11
Training loss: 1.956997503724453
Validation loss: 2.5021209779607863

Epoch: 6| Step: 12
Training loss: 2.318200174214792
Validation loss: 2.495560192537609

Epoch: 6| Step: 13
Training loss: 2.6740553141474313
Validation loss: 2.5091604569416455

Epoch: 176| Step: 0
Training loss: 2.6038308092342857
Validation loss: 2.5155194973196013

Epoch: 6| Step: 1
Training loss: 1.3431876136808492
Validation loss: 2.5161094120153074

Epoch: 6| Step: 2
Training loss: 2.2190364598996046
Validation loss: 2.5239867566300824

Epoch: 6| Step: 3
Training loss: 2.582533794673104
Validation loss: 2.5169726093172455

Epoch: 6| Step: 4
Training loss: 2.5012051538567737
Validation loss: 2.5215069262310923

Epoch: 6| Step: 5
Training loss: 2.468578284363839
Validation loss: 2.506931534437739

Epoch: 6| Step: 6
Training loss: 2.2961707040949175
Validation loss: 2.506514929565066

Epoch: 6| Step: 7
Training loss: 2.227716514947914
Validation loss: 2.5079194835370906

Epoch: 6| Step: 8
Training loss: 3.2245588015605606
Validation loss: 2.5122090005079136

Epoch: 6| Step: 9
Training loss: 1.6955564121276394
Validation loss: 2.5059000727023837

Epoch: 6| Step: 10
Training loss: 2.421418768456602
Validation loss: 2.504689634135403

Epoch: 6| Step: 11
Training loss: 2.214561807761691
Validation loss: 2.4997111948407365

Epoch: 6| Step: 12
Training loss: 2.0781150186628836
Validation loss: 2.5106158170942856

Epoch: 6| Step: 13
Training loss: 3.0100365281027233
Validation loss: 2.5225974496569097

Epoch: 177| Step: 0
Training loss: 2.4787564833224907
Validation loss: 2.521242649696188

Epoch: 6| Step: 1
Training loss: 2.4604232977493257
Validation loss: 2.5165237021944096

Epoch: 6| Step: 2
Training loss: 2.319112242502021
Validation loss: 2.513973175542008

Epoch: 6| Step: 3
Training loss: 2.343079331126696
Validation loss: 2.521114803920201

Epoch: 6| Step: 4
Training loss: 2.601837235340932
Validation loss: 2.518503930856286

Epoch: 6| Step: 5
Training loss: 2.2765668063885576
Validation loss: 2.511880587618826

Epoch: 6| Step: 6
Training loss: 1.840805935993264
Validation loss: 2.510160256319384

Epoch: 6| Step: 7
Training loss: 2.3899408495937475
Validation loss: 2.5057102157985165

Epoch: 6| Step: 8
Training loss: 2.333942492759682
Validation loss: 2.505372315007945

Epoch: 6| Step: 9
Training loss: 1.7103075235030605
Validation loss: 2.5034029926516523

Epoch: 6| Step: 10
Training loss: 2.6212767581183347
Validation loss: 2.4934505821477995

Epoch: 6| Step: 11
Training loss: 2.1227692507647147
Validation loss: 2.4943161884952136

Epoch: 6| Step: 12
Training loss: 2.9069498511556384
Validation loss: 2.4873168449768728

Epoch: 6| Step: 13
Training loss: 2.6743914259521815
Validation loss: 2.491973341586465

Epoch: 178| Step: 0
Training loss: 2.180601851126424
Validation loss: 2.4876423908418874

Epoch: 6| Step: 1
Training loss: 2.0733383235482923
Validation loss: 2.4970032851167394

Epoch: 6| Step: 2
Training loss: 2.4122373724579353
Validation loss: 2.504768814159922

Epoch: 6| Step: 3
Training loss: 2.0715924606884317
Validation loss: 2.5132604507820453

Epoch: 6| Step: 4
Training loss: 1.6969940705788673
Validation loss: 2.5204795058389076

Epoch: 6| Step: 5
Training loss: 2.823339386054903
Validation loss: 2.519081126771512

Epoch: 6| Step: 6
Training loss: 2.7562836037315206
Validation loss: 2.5384254164930393

Epoch: 6| Step: 7
Training loss: 2.749080330783387
Validation loss: 2.53839817844285

Epoch: 6| Step: 8
Training loss: 2.498376223616096
Validation loss: 2.547301477091126

Epoch: 6| Step: 9
Training loss: 2.1211562454824073
Validation loss: 2.5406029200171174

Epoch: 6| Step: 10
Training loss: 2.266663096462505
Validation loss: 2.5294609654834246

Epoch: 6| Step: 11
Training loss: 2.4905552795683814
Validation loss: 2.52849387993379

Epoch: 6| Step: 12
Training loss: 2.387360182258124
Validation loss: 2.511553658556908

Epoch: 6| Step: 13
Training loss: 2.6801063499415596
Validation loss: 2.5218042574086974

Epoch: 179| Step: 0
Training loss: 2.0879301347553825
Validation loss: 2.505700145725968

Epoch: 6| Step: 1
Training loss: 1.7877202225121474
Validation loss: 2.5080003677937768

Epoch: 6| Step: 2
Training loss: 2.1048698635150784
Validation loss: 2.497027728359517

Epoch: 6| Step: 3
Training loss: 2.3887912474004978
Validation loss: 2.5120732841811644

Epoch: 6| Step: 4
Training loss: 2.080280190266068
Validation loss: 2.501525334104564

Epoch: 6| Step: 5
Training loss: 2.406515527912501
Validation loss: 2.5054453752848973

Epoch: 6| Step: 6
Training loss: 2.7183512252727113
Validation loss: 2.500747473553288

Epoch: 6| Step: 7
Training loss: 2.3716232990509516
Validation loss: 2.498970948463476

Epoch: 6| Step: 8
Training loss: 2.737177867312815
Validation loss: 2.511325605680652

Epoch: 6| Step: 9
Training loss: 2.448782801425461
Validation loss: 2.495718404918464

Epoch: 6| Step: 10
Training loss: 1.9520239205888086
Validation loss: 2.508675114949511

Epoch: 6| Step: 11
Training loss: 2.728597936023585
Validation loss: 2.5153150505741455

Epoch: 6| Step: 12
Training loss: 2.3998968300896735
Validation loss: 2.5078093389093077

Epoch: 6| Step: 13
Training loss: 2.853594664641564
Validation loss: 2.5218466831588664

Epoch: 180| Step: 0
Training loss: 2.540973589679213
Validation loss: 2.512109483827519

Epoch: 6| Step: 1
Training loss: 2.464446844436689
Validation loss: 2.5312026219584682

Epoch: 6| Step: 2
Training loss: 3.0411877886598115
Validation loss: 2.522637806440333

Epoch: 6| Step: 3
Training loss: 2.679181554425662
Validation loss: 2.525780927172521

Epoch: 6| Step: 4
Training loss: 2.360514788651799
Validation loss: 2.520810644714986

Epoch: 6| Step: 5
Training loss: 2.113762256083721
Validation loss: 2.5229598342222324

Epoch: 6| Step: 6
Training loss: 1.9218277343892518
Validation loss: 2.528779523610828

Epoch: 6| Step: 7
Training loss: 2.651767044405332
Validation loss: 2.5401899446217975

Epoch: 6| Step: 8
Training loss: 1.9580149966747877
Validation loss: 2.534398871457165

Epoch: 6| Step: 9
Training loss: 2.260881601735356
Validation loss: 2.538596375545959

Epoch: 6| Step: 10
Training loss: 1.9331552952422295
Validation loss: 2.5273626013342136

Epoch: 6| Step: 11
Training loss: 2.536265267316309
Validation loss: 2.532473170498282

Epoch: 6| Step: 12
Training loss: 2.395778909700868
Validation loss: 2.5275147275561634

Epoch: 6| Step: 13
Training loss: 2.3107495255329984
Validation loss: 2.5285503920756875

Epoch: 181| Step: 0
Training loss: 2.82164836324068
Validation loss: 2.518587819976424

Epoch: 6| Step: 1
Training loss: 1.7909291619882366
Validation loss: 2.5165682380788015

Epoch: 6| Step: 2
Training loss: 2.0222262140847143
Validation loss: 2.5131098334540938

Epoch: 6| Step: 3
Training loss: 2.2631584684588337
Validation loss: 2.509980070103403

Epoch: 6| Step: 4
Training loss: 2.031933713432525
Validation loss: 2.504604311723883

Epoch: 6| Step: 5
Training loss: 1.9644940104831374
Validation loss: 2.5112009023851507

Epoch: 6| Step: 6
Training loss: 2.630732498564593
Validation loss: 2.513727898357496

Epoch: 6| Step: 7
Training loss: 2.54929475568701
Validation loss: 2.505204426107446

Epoch: 6| Step: 8
Training loss: 2.541804221344751
Validation loss: 2.5040890710734

Epoch: 6| Step: 9
Training loss: 2.7149614267436757
Validation loss: 2.4998103387733344

Epoch: 6| Step: 10
Training loss: 2.312362254396279
Validation loss: 2.493334722399537

Epoch: 6| Step: 11
Training loss: 2.4064921467801734
Validation loss: 2.4963649707870523

Epoch: 6| Step: 12
Training loss: 2.4643830898151164
Validation loss: 2.512006728303002

Epoch: 6| Step: 13
Training loss: 2.619954300692996
Validation loss: 2.5299542489645823

Epoch: 182| Step: 0
Training loss: 2.2704355667269422
Validation loss: 2.531581856908231

Epoch: 6| Step: 1
Training loss: 2.6173642226948783
Validation loss: 2.545942732671097

Epoch: 6| Step: 2
Training loss: 1.888454736419146
Validation loss: 2.5488516659094076

Epoch: 6| Step: 3
Training loss: 2.4630490886583787
Validation loss: 2.5688593350026374

Epoch: 6| Step: 4
Training loss: 2.7330155835340726
Validation loss: 2.5791111302803174

Epoch: 6| Step: 5
Training loss: 2.2156470724063637
Validation loss: 2.586054911641905

Epoch: 6| Step: 6
Training loss: 3.0559035902543927
Validation loss: 2.5574861648051113

Epoch: 6| Step: 7
Training loss: 2.146166235522786
Validation loss: 2.541496440523477

Epoch: 6| Step: 8
Training loss: 2.1536110471955094
Validation loss: 2.523656317924665

Epoch: 6| Step: 9
Training loss: 2.2860779558107693
Validation loss: 2.5167242771990406

Epoch: 6| Step: 10
Training loss: 2.462014389566225
Validation loss: 2.503515458023908

Epoch: 6| Step: 11
Training loss: 2.1065013384630293
Validation loss: 2.502794960415541

Epoch: 6| Step: 12
Training loss: 2.3862807750765627
Validation loss: 2.497230465969311

Epoch: 6| Step: 13
Training loss: 2.3689141853219238
Validation loss: 2.4913303730924703

Epoch: 183| Step: 0
Training loss: 2.7858686351983266
Validation loss: 2.4974744755863356

Epoch: 6| Step: 1
Training loss: 2.092220601852005
Validation loss: 2.5014182756646277

Epoch: 6| Step: 2
Training loss: 1.9465267574098801
Validation loss: 2.4979102380928078

Epoch: 6| Step: 3
Training loss: 2.9795179537869
Validation loss: 2.4985364285609264

Epoch: 6| Step: 4
Training loss: 2.132922718148559
Validation loss: 2.49613935879632

Epoch: 6| Step: 5
Training loss: 2.1052196121731614
Validation loss: 2.4986774284048936

Epoch: 6| Step: 6
Training loss: 2.5317919115733623
Validation loss: 2.5035757401136878

Epoch: 6| Step: 7
Training loss: 2.4024914207662573
Validation loss: 2.499158208904178

Epoch: 6| Step: 8
Training loss: 1.8618872204110943
Validation loss: 2.506971699597911

Epoch: 6| Step: 9
Training loss: 2.2196120615678367
Validation loss: 2.5127710458743704

Epoch: 6| Step: 10
Training loss: 2.9223580190663774
Validation loss: 2.5276667660194985

Epoch: 6| Step: 11
Training loss: 2.4124341491250587
Validation loss: 2.520673767798523

Epoch: 6| Step: 12
Training loss: 2.071080709478938
Validation loss: 2.5332599085490384

Epoch: 6| Step: 13
Training loss: 2.6577652143771875
Validation loss: 2.5312895595143683

Epoch: 184| Step: 0
Training loss: 2.1863404606751784
Validation loss: 2.525270219702332

Epoch: 6| Step: 1
Training loss: 2.7976869225118888
Validation loss: 2.516554319219281

Epoch: 6| Step: 2
Training loss: 2.155073204124797
Validation loss: 2.5213275824231927

Epoch: 6| Step: 3
Training loss: 2.5748427333768436
Validation loss: 2.5243721127790675

Epoch: 6| Step: 4
Training loss: 2.2599078424619217
Validation loss: 2.515157431041561

Epoch: 6| Step: 5
Training loss: 2.070926675925081
Validation loss: 2.5023345537400776

Epoch: 6| Step: 6
Training loss: 2.3198999108724636
Validation loss: 2.5057135381206597

Epoch: 6| Step: 7
Training loss: 1.7423573227296345
Validation loss: 2.5070021321242355

Epoch: 6| Step: 8
Training loss: 2.676859528405339
Validation loss: 2.5102016520458097

Epoch: 6| Step: 9
Training loss: 2.1562860458235993
Validation loss: 2.5124998880262965

Epoch: 6| Step: 10
Training loss: 2.184357702271349
Validation loss: 2.508683810879107

Epoch: 6| Step: 11
Training loss: 2.9933776878803324
Validation loss: 2.5238288284644796

Epoch: 6| Step: 12
Training loss: 2.170381979657514
Validation loss: 2.527455283705486

Epoch: 6| Step: 13
Training loss: 2.675464828605075
Validation loss: 2.517543953288058

Epoch: 185| Step: 0
Training loss: 1.818191012445958
Validation loss: 2.5202129220575187

Epoch: 6| Step: 1
Training loss: 1.9909342095978515
Validation loss: 2.5344169961293197

Epoch: 6| Step: 2
Training loss: 2.103860385875069
Validation loss: 2.539128417113106

Epoch: 6| Step: 3
Training loss: 2.7787948230006045
Validation loss: 2.5303661859951134

Epoch: 6| Step: 4
Training loss: 2.9040377821342953
Validation loss: 2.531901491570067

Epoch: 6| Step: 5
Training loss: 2.404516908817407
Validation loss: 2.528741559077236

Epoch: 6| Step: 6
Training loss: 3.126790258680192
Validation loss: 2.524669869876774

Epoch: 6| Step: 7
Training loss: 2.4686303411529615
Validation loss: 2.5283247445584465

Epoch: 6| Step: 8
Training loss: 2.711305005230946
Validation loss: 2.5285005747084304

Epoch: 6| Step: 9
Training loss: 2.043945079207464
Validation loss: 2.5239546239061816

Epoch: 6| Step: 10
Training loss: 1.8225771197209522
Validation loss: 2.5114017996535685

Epoch: 6| Step: 11
Training loss: 2.457243942006439
Validation loss: 2.5095611528555084

Epoch: 6| Step: 12
Training loss: 2.3707472219622856
Validation loss: 2.503574994135665

Epoch: 6| Step: 13
Training loss: 2.0089286344013506
Validation loss: 2.5125772641449733

Epoch: 186| Step: 0
Training loss: 2.345877330451003
Validation loss: 2.525239912916727

Epoch: 6| Step: 1
Training loss: 2.711770405190814
Validation loss: 2.534864701805614

Epoch: 6| Step: 2
Training loss: 2.448368003847294
Validation loss: 2.533982030942815

Epoch: 6| Step: 3
Training loss: 1.8286636732667758
Validation loss: 2.5451533421384607

Epoch: 6| Step: 4
Training loss: 2.6563326654473656
Validation loss: 2.538643858215441

Epoch: 6| Step: 5
Training loss: 2.7337684176521866
Validation loss: 2.5410922657352555

Epoch: 6| Step: 6
Training loss: 2.1552879288069127
Validation loss: 2.5409141322828455

Epoch: 6| Step: 7
Training loss: 1.9915306654055343
Validation loss: 2.5291001409069582

Epoch: 6| Step: 8
Training loss: 2.197003348061915
Validation loss: 2.534624409348764

Epoch: 6| Step: 9
Training loss: 1.703381300373369
Validation loss: 2.5318663674757245

Epoch: 6| Step: 10
Training loss: 2.7947731005127427
Validation loss: 2.543679664882875

Epoch: 6| Step: 11
Training loss: 2.8064722529632875
Validation loss: 2.5502979079613843

Epoch: 6| Step: 12
Training loss: 2.6282615381214547
Validation loss: 2.542545000076286

Epoch: 6| Step: 13
Training loss: 1.6823259789084584
Validation loss: 2.5372969881287957

Epoch: 187| Step: 0
Training loss: 2.1662048312242064
Validation loss: 2.5286145717418322

Epoch: 6| Step: 1
Training loss: 2.3398597474737457
Validation loss: 2.5280679080962534

Epoch: 6| Step: 2
Training loss: 2.4338114290562016
Validation loss: 2.5192866401315803

Epoch: 6| Step: 3
Training loss: 2.277009968973283
Validation loss: 2.52087632975415

Epoch: 6| Step: 4
Training loss: 1.9019767516888433
Validation loss: 2.523323804500566

Epoch: 6| Step: 5
Training loss: 2.502503095657309
Validation loss: 2.5191435444139074

Epoch: 6| Step: 6
Training loss: 2.412939310346922
Validation loss: 2.522221180579054

Epoch: 6| Step: 7
Training loss: 1.5188793362777
Validation loss: 2.518203109296066

Epoch: 6| Step: 8
Training loss: 3.1239066690919666
Validation loss: 2.52332043450039

Epoch: 6| Step: 9
Training loss: 2.466338319661609
Validation loss: 2.510908724943006

Epoch: 6| Step: 10
Training loss: 2.6466291437283713
Validation loss: 2.515498092956973

Epoch: 6| Step: 11
Training loss: 2.1230802278960756
Validation loss: 2.522485677529119

Epoch: 6| Step: 12
Training loss: 2.7429504202695028
Validation loss: 2.5238729599197596

Epoch: 6| Step: 13
Training loss: 1.935772648797697
Validation loss: 2.530579050252556

Epoch: 188| Step: 0
Training loss: 3.071632004651122
Validation loss: 2.538387564916576

Epoch: 6| Step: 1
Training loss: 2.7662799296804774
Validation loss: 2.531234293759444

Epoch: 6| Step: 2
Training loss: 2.3928700794447764
Validation loss: 2.533238654082356

Epoch: 6| Step: 3
Training loss: 1.3304414630988028
Validation loss: 2.5306916111553166

Epoch: 6| Step: 4
Training loss: 2.2011731747722427
Validation loss: 2.5300954532584496

Epoch: 6| Step: 5
Training loss: 2.036402344645415
Validation loss: 2.5295529740338716

Epoch: 6| Step: 6
Training loss: 2.5253135864119525
Validation loss: 2.5323477354528494

Epoch: 6| Step: 7
Training loss: 2.3237822307056675
Validation loss: 2.520188940195971

Epoch: 6| Step: 8
Training loss: 2.0553456691891845
Validation loss: 2.530234600217147

Epoch: 6| Step: 9
Training loss: 2.1356301053694784
Validation loss: 2.5277311882038647

Epoch: 6| Step: 10
Training loss: 2.260977457216731
Validation loss: 2.530756867021565

Epoch: 6| Step: 11
Training loss: 1.8858528124513623
Validation loss: 2.520931641314267

Epoch: 6| Step: 12
Training loss: 2.807761290459515
Validation loss: 2.5290121382168995

Epoch: 6| Step: 13
Training loss: 2.653227938215348
Validation loss: 2.519161778843923

Epoch: 189| Step: 0
Training loss: 2.2592385616234547
Validation loss: 2.517675192229068

Epoch: 6| Step: 1
Training loss: 1.6224763053257154
Validation loss: 2.5340595116415185

Epoch: 6| Step: 2
Training loss: 2.163690858734591
Validation loss: 2.533334768340892

Epoch: 6| Step: 3
Training loss: 2.5099995901099854
Validation loss: 2.54495589769544

Epoch: 6| Step: 4
Training loss: 2.507036986423205
Validation loss: 2.5425330597945255

Epoch: 6| Step: 5
Training loss: 1.7592263194489766
Validation loss: 2.5569842063740285

Epoch: 6| Step: 6
Training loss: 2.7475356417453685
Validation loss: 2.5433751810346608

Epoch: 6| Step: 7
Training loss: 1.8067862457148791
Validation loss: 2.546169362677291

Epoch: 6| Step: 8
Training loss: 2.8653640145667567
Validation loss: 2.5500935848989856

Epoch: 6| Step: 9
Training loss: 1.9210755460977316
Validation loss: 2.5435891046650934

Epoch: 6| Step: 10
Training loss: 2.5024889953554244
Validation loss: 2.5335969131109644

Epoch: 6| Step: 11
Training loss: 3.0442239819204513
Validation loss: 2.5254184911163575

Epoch: 6| Step: 12
Training loss: 2.3989350737817428
Validation loss: 2.5051958132699967

Epoch: 6| Step: 13
Training loss: 2.353915738486415
Validation loss: 2.509774807963907

Epoch: 190| Step: 0
Training loss: 2.269475676862361
Validation loss: 2.504668200682853

Epoch: 6| Step: 1
Training loss: 2.2602469970966714
Validation loss: 2.4967422399130674

Epoch: 6| Step: 2
Training loss: 2.7095624531068436
Validation loss: 2.5036367905190717

Epoch: 6| Step: 3
Training loss: 1.6618025212947218
Validation loss: 2.498630673191333

Epoch: 6| Step: 4
Training loss: 2.346269194616414
Validation loss: 2.5013323730244585

Epoch: 6| Step: 5
Training loss: 2.91701719811633
Validation loss: 2.504855162112862

Epoch: 6| Step: 6
Training loss: 3.1687495425372574
Validation loss: 2.504470809158677

Epoch: 6| Step: 7
Training loss: 1.831785401073149
Validation loss: 2.4920279871357396

Epoch: 6| Step: 8
Training loss: 3.0136721914492703
Validation loss: 2.4985355697511222

Epoch: 6| Step: 9
Training loss: 2.29331850571977
Validation loss: 2.505060652876096

Epoch: 6| Step: 10
Training loss: 2.333356368995672
Validation loss: 2.4957030402952896

Epoch: 6| Step: 11
Training loss: 2.0168196811897503
Validation loss: 2.4991178545669306

Epoch: 6| Step: 12
Training loss: 1.7486458716431617
Validation loss: 2.5053543608701516

Epoch: 6| Step: 13
Training loss: 2.6337356533679093
Validation loss: 2.5137876826287817

Epoch: 191| Step: 0
Training loss: 1.9354601550956534
Validation loss: 2.5043614490010087

Epoch: 6| Step: 1
Training loss: 1.951663637862012
Validation loss: 2.5212131771033195

Epoch: 6| Step: 2
Training loss: 2.5858248314413963
Validation loss: 2.520410917425533

Epoch: 6| Step: 3
Training loss: 2.0594542006225023
Validation loss: 2.5371002596485117

Epoch: 6| Step: 4
Training loss: 2.1271047827087206
Validation loss: 2.529778433459912

Epoch: 6| Step: 5
Training loss: 1.9910599453464817
Validation loss: 2.545171889825106

Epoch: 6| Step: 6
Training loss: 2.559788828127135
Validation loss: 2.545325980278586

Epoch: 6| Step: 7
Training loss: 2.3603044914757225
Validation loss: 2.5518749048147527

Epoch: 6| Step: 8
Training loss: 2.7245677220158404
Validation loss: 2.5618075699070277

Epoch: 6| Step: 9
Training loss: 2.3626318677803715
Validation loss: 2.560053890674323

Epoch: 6| Step: 10
Training loss: 2.8902945664705593
Validation loss: 2.5494838217100844

Epoch: 6| Step: 11
Training loss: 2.6187544501728857
Validation loss: 2.5589521705457785

Epoch: 6| Step: 12
Training loss: 2.2929114573402942
Validation loss: 2.548563890657798

Epoch: 6| Step: 13
Training loss: 2.148217984169047
Validation loss: 2.5359329107638278

Epoch: 192| Step: 0
Training loss: 2.8411135346802596
Validation loss: 2.5379868013816838

Epoch: 6| Step: 1
Training loss: 2.5509478060453294
Validation loss: 2.5206938986139193

Epoch: 6| Step: 2
Training loss: 2.390843200698688
Validation loss: 2.5172197172130515

Epoch: 6| Step: 3
Training loss: 2.190225048259636
Validation loss: 2.503345841386263

Epoch: 6| Step: 4
Training loss: 2.1390018295701143
Validation loss: 2.5010528572676347

Epoch: 6| Step: 5
Training loss: 1.871528845672523
Validation loss: 2.493656614334914

Epoch: 6| Step: 6
Training loss: 2.9733510552578104
Validation loss: 2.5031297801936905

Epoch: 6| Step: 7
Training loss: 2.399696938930447
Validation loss: 2.4981496161955694

Epoch: 6| Step: 8
Training loss: 1.9607535956117657
Validation loss: 2.503407048191105

Epoch: 6| Step: 9
Training loss: 2.28865750736871
Validation loss: 2.5025577494550455

Epoch: 6| Step: 10
Training loss: 2.3529922346577905
Validation loss: 2.503198961172501

Epoch: 6| Step: 11
Training loss: 2.0224950060882967
Validation loss: 2.502096219205642

Epoch: 6| Step: 12
Training loss: 2.771175611957559
Validation loss: 2.501199156539749

Epoch: 6| Step: 13
Training loss: 2.2575813359914507
Validation loss: 2.5146535099311706

Epoch: 193| Step: 0
Training loss: 2.4865689936350894
Validation loss: 2.525557250672041

Epoch: 6| Step: 1
Training loss: 2.4042802154682774
Validation loss: 2.513906266894145

Epoch: 6| Step: 2
Training loss: 1.9763489860437682
Validation loss: 2.5237598193656066

Epoch: 6| Step: 3
Training loss: 2.0532618461071155
Validation loss: 2.534151337550159

Epoch: 6| Step: 4
Training loss: 2.4501092925314825
Validation loss: 2.546096401909673

Epoch: 6| Step: 5
Training loss: 1.5528499152423547
Validation loss: 2.549503623733394

Epoch: 6| Step: 6
Training loss: 2.0989654263233777
Validation loss: 2.552312324267408

Epoch: 6| Step: 7
Training loss: 2.5579751235074415
Validation loss: 2.550995829866042

Epoch: 6| Step: 8
Training loss: 2.5541554868203487
Validation loss: 2.537505031135971

Epoch: 6| Step: 9
Training loss: 2.318794139020382
Validation loss: 2.5226691841021527

Epoch: 6| Step: 10
Training loss: 2.4818454556422602
Validation loss: 2.524552625423304

Epoch: 6| Step: 11
Training loss: 2.928104064280312
Validation loss: 2.517837704380886

Epoch: 6| Step: 12
Training loss: 1.950242501854587
Validation loss: 2.5209770214229485

Epoch: 6| Step: 13
Training loss: 2.774606549662876
Validation loss: 2.5271001793744627

Epoch: 194| Step: 0
Training loss: 1.5280276277251366
Validation loss: 2.51801492173498

Epoch: 6| Step: 1
Training loss: 2.1826429668499943
Validation loss: 2.5178704675298027

Epoch: 6| Step: 2
Training loss: 2.392595862498027
Validation loss: 2.512547128466266

Epoch: 6| Step: 3
Training loss: 1.9731410875410742
Validation loss: 2.516720258908455

Epoch: 6| Step: 4
Training loss: 2.40567128542037
Validation loss: 2.5128449584347257

Epoch: 6| Step: 5
Training loss: 2.3574270328948854
Validation loss: 2.531525702826529

Epoch: 6| Step: 6
Training loss: 2.7304780056732434
Validation loss: 2.5346688623487394

Epoch: 6| Step: 7
Training loss: 2.8539383697164253
Validation loss: 2.5279288147830976

Epoch: 6| Step: 8
Training loss: 2.331371118094072
Validation loss: 2.533975295765101

Epoch: 6| Step: 9
Training loss: 2.51710210995132
Validation loss: 2.5200720549177027

Epoch: 6| Step: 10
Training loss: 2.083480359293616
Validation loss: 2.5185503329135486

Epoch: 6| Step: 11
Training loss: 2.9471090084298477
Validation loss: 2.5298013662685155

Epoch: 6| Step: 12
Training loss: 2.1492758485065693
Validation loss: 2.5227863428259383

Epoch: 6| Step: 13
Training loss: 2.0841634113947802
Validation loss: 2.527564147741413

Epoch: 195| Step: 0
Training loss: 1.514252896930102
Validation loss: 2.535258035913693

Epoch: 6| Step: 1
Training loss: 2.2501968721513994
Validation loss: 2.5276651782387316

Epoch: 6| Step: 2
Training loss: 2.7880811487480766
Validation loss: 2.5288761294644

Epoch: 6| Step: 3
Training loss: 2.487497730349938
Validation loss: 2.525184955369641

Epoch: 6| Step: 4
Training loss: 2.395322186773313
Validation loss: 2.5237740999796454

Epoch: 6| Step: 5
Training loss: 2.597612010607783
Validation loss: 2.516745102735869

Epoch: 6| Step: 6
Training loss: 2.762171685227161
Validation loss: 2.510657482283708

Epoch: 6| Step: 7
Training loss: 2.431520610743152
Validation loss: 2.5001618094531763

Epoch: 6| Step: 8
Training loss: 1.927426701103212
Validation loss: 2.507950063004479

Epoch: 6| Step: 9
Training loss: 2.237711089848477
Validation loss: 2.492570215892295

Epoch: 6| Step: 10
Training loss: 2.1037053524726255
Validation loss: 2.4988840314455016

Epoch: 6| Step: 11
Training loss: 2.6200691414948154
Validation loss: 2.4995222747852077

Epoch: 6| Step: 12
Training loss: 1.9588290730128224
Validation loss: 2.505798608682872

Epoch: 6| Step: 13
Training loss: 2.4537295428767574
Validation loss: 2.51644665270046

Epoch: 196| Step: 0
Training loss: 1.9109390620601878
Validation loss: 2.520834463029929

Epoch: 6| Step: 1
Training loss: 2.1966198052640276
Validation loss: 2.52974847912899

Epoch: 6| Step: 2
Training loss: 2.1490203621646518
Validation loss: 2.5638356643319318

Epoch: 6| Step: 3
Training loss: 2.185273263285279
Validation loss: 2.568446199716675

Epoch: 6| Step: 4
Training loss: 2.525419985902165
Validation loss: 2.581382296714884

Epoch: 6| Step: 5
Training loss: 1.621565196413102
Validation loss: 2.5805242606588763

Epoch: 6| Step: 6
Training loss: 3.450038168875704
Validation loss: 2.580359182515692

Epoch: 6| Step: 7
Training loss: 2.289305169584183
Validation loss: 2.5896582290077244

Epoch: 6| Step: 8
Training loss: 2.664541251829785
Validation loss: 2.5853881713460853

Epoch: 6| Step: 9
Training loss: 2.10803406090336
Validation loss: 2.5866911251920706

Epoch: 6| Step: 10
Training loss: 2.301374116168599
Validation loss: 2.5880564664088217

Epoch: 6| Step: 11
Training loss: 2.556404679895211
Validation loss: 2.546453491778919

Epoch: 6| Step: 12
Training loss: 1.9210056726867386
Validation loss: 2.5205721811842032

Epoch: 6| Step: 13
Training loss: 2.6796146305063497
Validation loss: 2.5079219869479155

Epoch: 197| Step: 0
Training loss: 2.836062594090204
Validation loss: 2.503563074329017

Epoch: 6| Step: 1
Training loss: 1.8244321645188424
Validation loss: 2.498420804659608

Epoch: 6| Step: 2
Training loss: 2.4854626464001406
Validation loss: 2.4965695209812706

Epoch: 6| Step: 3
Training loss: 2.5794810110222492
Validation loss: 2.503068645984326

Epoch: 6| Step: 4
Training loss: 2.6343194740751734
Validation loss: 2.505730022799506

Epoch: 6| Step: 5
Training loss: 2.266106074329334
Validation loss: 2.5084270385863676

Epoch: 6| Step: 6
Training loss: 2.093854417616963
Validation loss: 2.502290105944403

Epoch: 6| Step: 7
Training loss: 1.9293963872961728
Validation loss: 2.5069346253075686

Epoch: 6| Step: 8
Training loss: 1.83895690666683
Validation loss: 2.51494985804744

Epoch: 6| Step: 9
Training loss: 1.8053089739669483
Validation loss: 2.514865942378434

Epoch: 6| Step: 10
Training loss: 2.775214858801424
Validation loss: 2.5159865567717974

Epoch: 6| Step: 11
Training loss: 2.6140028067167314
Validation loss: 2.5101156858935623

Epoch: 6| Step: 12
Training loss: 2.673163209418657
Validation loss: 2.5228466133411116

Epoch: 6| Step: 13
Training loss: 2.6100304060293915
Validation loss: 2.53090555492657

Epoch: 198| Step: 0
Training loss: 2.0283421757217206
Validation loss: 2.5438948906351477

Epoch: 6| Step: 1
Training loss: 2.1688268114718565
Validation loss: 2.5628735029736576

Epoch: 6| Step: 2
Training loss: 2.430727524501741
Validation loss: 2.5824300560922384

Epoch: 6| Step: 3
Training loss: 2.5655706662408155
Validation loss: 2.5687878385481073

Epoch: 6| Step: 4
Training loss: 2.04666905422672
Validation loss: 2.583319407599867

Epoch: 6| Step: 5
Training loss: 2.9267723126413414
Validation loss: 2.5704600128544137

Epoch: 6| Step: 6
Training loss: 2.716439504038616
Validation loss: 2.550057464774897

Epoch: 6| Step: 7
Training loss: 2.2473448876138877
Validation loss: 2.5415887403788884

Epoch: 6| Step: 8
Training loss: 2.308079386306115
Validation loss: 2.5335474145514216

Epoch: 6| Step: 9
Training loss: 1.6514084786566001
Validation loss: 2.5416068763162403

Epoch: 6| Step: 10
Training loss: 2.332571404806401
Validation loss: 2.5281090420351737

Epoch: 6| Step: 11
Training loss: 2.188778530873865
Validation loss: 2.526715239290299

Epoch: 6| Step: 12
Training loss: 2.68172882001729
Validation loss: 2.5266448464202114

Epoch: 6| Step: 13
Training loss: 2.2957322787864043
Validation loss: 2.5270571263635064

Epoch: 199| Step: 0
Training loss: 2.7758290470044007
Validation loss: 2.531293366300106

Epoch: 6| Step: 1
Training loss: 2.2845965360206297
Validation loss: 2.5319081224045146

Epoch: 6| Step: 2
Training loss: 2.303287611128944
Validation loss: 2.530003150314762

Epoch: 6| Step: 3
Training loss: 2.1934645942593947
Validation loss: 2.5426207664212828

Epoch: 6| Step: 4
Training loss: 2.3324453730590227
Validation loss: 2.5348812320482823

Epoch: 6| Step: 5
Training loss: 2.2777897968853855
Validation loss: 2.5517288480823628

Epoch: 6| Step: 6
Training loss: 2.4303572243804292
Validation loss: 2.551165331305127

Epoch: 6| Step: 7
Training loss: 1.9272246918940885
Validation loss: 2.5457494389955664

Epoch: 6| Step: 8
Training loss: 3.3747391776568323
Validation loss: 2.5404458058230275

Epoch: 6| Step: 9
Training loss: 2.0069524800786143
Validation loss: 2.5584960142304243

Epoch: 6| Step: 10
Training loss: 2.102709942653953
Validation loss: 2.5567427056985816

Epoch: 6| Step: 11
Training loss: 1.7975635038785345
Validation loss: 2.568544809974465

Epoch: 6| Step: 12
Training loss: 1.984796073873712
Validation loss: 2.557042816132843

Epoch: 6| Step: 13
Training loss: 2.4041691489732995
Validation loss: 2.560934891388119

Epoch: 200| Step: 0
Training loss: 2.2486571437288356
Validation loss: 2.561387324476875

Epoch: 6| Step: 1
Training loss: 2.350759578261375
Validation loss: 2.5735243158263286

Epoch: 6| Step: 2
Training loss: 1.884216734659465
Validation loss: 2.565402519315523

Epoch: 6| Step: 3
Training loss: 2.0693107052570325
Validation loss: 2.5633271983395276

Epoch: 6| Step: 4
Training loss: 3.1188330262777426
Validation loss: 2.5569667467310455

Epoch: 6| Step: 5
Training loss: 1.7171089661180001
Validation loss: 2.540569840036136

Epoch: 6| Step: 6
Training loss: 2.2304410648799013
Validation loss: 2.5306726747058956

Epoch: 6| Step: 7
Training loss: 2.491821453513266
Validation loss: 2.531493375404486

Epoch: 6| Step: 8
Training loss: 2.4114891583070253
Validation loss: 2.5236997359851867

Epoch: 6| Step: 9
Training loss: 2.661842920594158
Validation loss: 2.533161477692897

Epoch: 6| Step: 10
Training loss: 2.0263802475106245
Validation loss: 2.5129435051334665

Epoch: 6| Step: 11
Training loss: 2.4017235924642972
Validation loss: 2.5217804324962083

Epoch: 6| Step: 12
Training loss: 2.418069914394718
Validation loss: 2.524753215740531

Epoch: 6| Step: 13
Training loss: 2.1701424913164544
Validation loss: 2.5238139656101497

Epoch: 201| Step: 0
Training loss: 2.1653622466484
Validation loss: 2.5282348916996664

Epoch: 6| Step: 1
Training loss: 2.0109335542890583
Validation loss: 2.519069643144978

Epoch: 6| Step: 2
Training loss: 2.837447003781318
Validation loss: 2.5444690597191233

Epoch: 6| Step: 3
Training loss: 2.6213824458535613
Validation loss: 2.5258190935271108

Epoch: 6| Step: 4
Training loss: 2.3932435896933173
Validation loss: 2.54835258325259

Epoch: 6| Step: 5
Training loss: 1.9652247277578256
Validation loss: 2.5544648846333056

Epoch: 6| Step: 6
Training loss: 3.05579030454905
Validation loss: 2.5490021783830152

Epoch: 6| Step: 7
Training loss: 2.084795121114179
Validation loss: 2.5591583638463864

Epoch: 6| Step: 8
Training loss: 2.6956165086987047
Validation loss: 2.5548105550482156

Epoch: 6| Step: 9
Training loss: 1.8037640739838252
Validation loss: 2.5545420551796796

Epoch: 6| Step: 10
Training loss: 2.0934598351582716
Validation loss: 2.5442078711776457

Epoch: 6| Step: 11
Training loss: 1.9235501935779438
Validation loss: 2.5398416898357854

Epoch: 6| Step: 12
Training loss: 2.4042482843764796
Validation loss: 2.5122098151000936

Epoch: 6| Step: 13
Training loss: 2.204775577464714
Validation loss: 2.508800054664433

Epoch: 202| Step: 0
Training loss: 2.1214174476761256
Validation loss: 2.490938732788358

Epoch: 6| Step: 1
Training loss: 2.270691776821484
Validation loss: 2.4986891011686736

Epoch: 6| Step: 2
Training loss: 2.5628077624588497
Validation loss: 2.498850526401676

Epoch: 6| Step: 3
Training loss: 2.0608969729981625
Validation loss: 2.5062086575999363

Epoch: 6| Step: 4
Training loss: 1.212032880960252
Validation loss: 2.5115397198175446

Epoch: 6| Step: 5
Training loss: 1.9592038580272753
Validation loss: 2.512184475623557

Epoch: 6| Step: 6
Training loss: 1.5722879159425276
Validation loss: 2.5145780386838714

Epoch: 6| Step: 7
Training loss: 2.8146397398391483
Validation loss: 2.5214250884115015

Epoch: 6| Step: 8
Training loss: 2.198275050252748
Validation loss: 2.515968425678961

Epoch: 6| Step: 9
Training loss: 3.0917586265795873
Validation loss: 2.5092969800729215

Epoch: 6| Step: 10
Training loss: 1.9770126131819858
Validation loss: 2.5061590779111746

Epoch: 6| Step: 11
Training loss: 2.836033338708592
Validation loss: 2.5122489468482505

Epoch: 6| Step: 12
Training loss: 2.9322854691886566
Validation loss: 2.5180784941092127

Epoch: 6| Step: 13
Training loss: 2.5372578472482554
Validation loss: 2.5125093852131983

Epoch: 203| Step: 0
Training loss: 2.766667573614623
Validation loss: 2.5276983642213855

Epoch: 6| Step: 1
Training loss: 1.8692489162154688
Validation loss: 2.524558307552838

Epoch: 6| Step: 2
Training loss: 1.9122571254921137
Validation loss: 2.536966955638097

Epoch: 6| Step: 3
Training loss: 2.686010258317731
Validation loss: 2.528449239791982

Epoch: 6| Step: 4
Training loss: 2.193908024935184
Validation loss: 2.5354279939204645

Epoch: 6| Step: 5
Training loss: 2.2276181579488195
Validation loss: 2.5391350838483446

Epoch: 6| Step: 6
Training loss: 2.4186385649016255
Validation loss: 2.548238377653414

Epoch: 6| Step: 7
Training loss: 1.6359623365147349
Validation loss: 2.5424999736684613

Epoch: 6| Step: 8
Training loss: 3.1850642453216187
Validation loss: 2.5502940126850646

Epoch: 6| Step: 9
Training loss: 2.01014200287806
Validation loss: 2.534270395800528

Epoch: 6| Step: 10
Training loss: 2.7808927670914905
Validation loss: 2.548209669515245

Epoch: 6| Step: 11
Training loss: 2.3925732421825177
Validation loss: 2.5414050363638796

Epoch: 6| Step: 12
Training loss: 2.2144909666888757
Validation loss: 2.521633286613436

Epoch: 6| Step: 13
Training loss: 2.209528605558878
Validation loss: 2.5157829219303256

Epoch: 204| Step: 0
Training loss: 2.744514803643036
Validation loss: 2.5131264198272016

Epoch: 6| Step: 1
Training loss: 1.9434215133164037
Validation loss: 2.5034114291187097

Epoch: 6| Step: 2
Training loss: 2.2712691935776403
Validation loss: 2.51810224358527

Epoch: 6| Step: 3
Training loss: 2.4299006230633933
Validation loss: 2.5181319892908127

Epoch: 6| Step: 4
Training loss: 2.214180122002476
Validation loss: 2.51329295738971

Epoch: 6| Step: 5
Training loss: 2.638551518697577
Validation loss: 2.5384326329619586

Epoch: 6| Step: 6
Training loss: 2.108759133184041
Validation loss: 2.5405810544325567

Epoch: 6| Step: 7
Training loss: 2.471858903950636
Validation loss: 2.5462505300499765

Epoch: 6| Step: 8
Training loss: 2.1140302363807457
Validation loss: 2.5328791363857794

Epoch: 6| Step: 9
Training loss: 1.6214008086452254
Validation loss: 2.5042444834834217

Epoch: 6| Step: 10
Training loss: 1.9090082194019975
Validation loss: 2.503435873284179

Epoch: 6| Step: 11
Training loss: 3.184009361052051
Validation loss: 2.5194232296520713

Epoch: 6| Step: 12
Training loss: 2.397128167142306
Validation loss: 2.5092801783577183

Epoch: 6| Step: 13
Training loss: 2.42816565834283
Validation loss: 2.5135120972402385

Epoch: 205| Step: 0
Training loss: 2.1135771538951516
Validation loss: 2.5144240867506866

Epoch: 6| Step: 1
Training loss: 2.506033102719569
Validation loss: 2.507807366196556

Epoch: 6| Step: 2
Training loss: 2.132248353230917
Validation loss: 2.5029411499221372

Epoch: 6| Step: 3
Training loss: 2.75757742682288
Validation loss: 2.5130980695540006

Epoch: 6| Step: 4
Training loss: 2.310253805113838
Validation loss: 2.517001105396067

Epoch: 6| Step: 5
Training loss: 2.5559427986132075
Validation loss: 2.510338419305518

Epoch: 6| Step: 6
Training loss: 2.212141160906688
Validation loss: 2.5234295320335858

Epoch: 6| Step: 7
Training loss: 2.6281013333483108
Validation loss: 2.5356668781912117

Epoch: 6| Step: 8
Training loss: 1.896021431894333
Validation loss: 2.544796631962141

Epoch: 6| Step: 9
Training loss: 2.6087626578184304
Validation loss: 2.5570039736229897

Epoch: 6| Step: 10
Training loss: 1.9148331939518362
Validation loss: 2.5716876957153687

Epoch: 6| Step: 11
Training loss: 2.5186860788720393
Validation loss: 2.5799126178522354

Epoch: 6| Step: 12
Training loss: 1.727559280924118
Validation loss: 2.5725931332272522

Epoch: 6| Step: 13
Training loss: 2.409786251608715
Validation loss: 2.569932965642552

Epoch: 206| Step: 0
Training loss: 2.0293835794909545
Validation loss: 2.5575207972123764

Epoch: 6| Step: 1
Training loss: 1.4707293869044686
Validation loss: 2.523571975321507

Epoch: 6| Step: 2
Training loss: 2.0488475584084913
Validation loss: 2.4989658441996525

Epoch: 6| Step: 3
Training loss: 2.0179238627865566
Validation loss: 2.5083660968486847

Epoch: 6| Step: 4
Training loss: 2.410755843354339
Validation loss: 2.5214996534417016

Epoch: 6| Step: 5
Training loss: 2.247906240510375
Validation loss: 2.5293649632385415

Epoch: 6| Step: 6
Training loss: 2.627243990199484
Validation loss: 2.514200585245763

Epoch: 6| Step: 7
Training loss: 2.2929175921944354
Validation loss: 2.5401154276509774

Epoch: 6| Step: 8
Training loss: 2.20091764645584
Validation loss: 2.5529751575315704

Epoch: 6| Step: 9
Training loss: 2.227006620317613
Validation loss: 2.5364330428871176

Epoch: 6| Step: 10
Training loss: 2.198121252677702
Validation loss: 2.546032397598222

Epoch: 6| Step: 11
Training loss: 2.8241498630084183
Validation loss: 2.5375017817573995

Epoch: 6| Step: 12
Training loss: 2.465422887217806
Validation loss: 2.528190412016997

Epoch: 6| Step: 13
Training loss: 2.7875512567434826
Validation loss: 2.5153424753955984

Epoch: 207| Step: 0
Training loss: 2.0075273719527225
Validation loss: 2.5329958699309802

Epoch: 6| Step: 1
Training loss: 1.403876441974526
Validation loss: 2.5239955887279866

Epoch: 6| Step: 2
Training loss: 2.249446058960755
Validation loss: 2.541851855134265

Epoch: 6| Step: 3
Training loss: 2.658134868790967
Validation loss: 2.5319829593876486

Epoch: 6| Step: 4
Training loss: 2.202448639633485
Validation loss: 2.534193940756521

Epoch: 6| Step: 5
Training loss: 2.2767820107138723
Validation loss: 2.522017292859867

Epoch: 6| Step: 6
Training loss: 2.6108776037718506
Validation loss: 2.534391408319191

Epoch: 6| Step: 7
Training loss: 2.2554502173925246
Validation loss: 2.533326502108984

Epoch: 6| Step: 8
Training loss: 2.9989221543972704
Validation loss: 2.5261936391098674

Epoch: 6| Step: 9
Training loss: 1.9905559964998263
Validation loss: 2.545236228017102

Epoch: 6| Step: 10
Training loss: 1.2257751075683119
Validation loss: 2.5281978463081782

Epoch: 6| Step: 11
Training loss: 2.9220050640023154
Validation loss: 2.5528656882709426

Epoch: 6| Step: 12
Training loss: 2.8176619736858646
Validation loss: 2.536748197208595

Epoch: 6| Step: 13
Training loss: 1.9230164650436827
Validation loss: 2.560829641643842

Epoch: 208| Step: 0
Training loss: 2.7175262152311888
Validation loss: 2.5766436241554005

Epoch: 6| Step: 1
Training loss: 1.9099516651768358
Validation loss: 2.5546588176707594

Epoch: 6| Step: 2
Training loss: 2.3472715243466804
Validation loss: 2.5411687634254414

Epoch: 6| Step: 3
Training loss: 2.952484545816647
Validation loss: 2.5727398048391383

Epoch: 6| Step: 4
Training loss: 2.3252119234365716
Validation loss: 2.5596263869167677

Epoch: 6| Step: 5
Training loss: 2.1503296444152182
Validation loss: 2.5550739178848643

Epoch: 6| Step: 6
Training loss: 2.571964556222888
Validation loss: 2.5533373158833026

Epoch: 6| Step: 7
Training loss: 2.730956201878897
Validation loss: 2.535923266258259

Epoch: 6| Step: 8
Training loss: 2.079582563657573
Validation loss: 2.5375030423601825

Epoch: 6| Step: 9
Training loss: 2.5074348521873637
Validation loss: 2.5179876207068084

Epoch: 6| Step: 10
Training loss: 2.0078106000720584
Validation loss: 2.5061884738539666

Epoch: 6| Step: 11
Training loss: 2.26196603954938
Validation loss: 2.5113024408622495

Epoch: 6| Step: 12
Training loss: 1.434210787413466
Validation loss: 2.507479398952758

Epoch: 6| Step: 13
Training loss: 2.0073132320948726
Validation loss: 2.496989535687526

Epoch: 209| Step: 0
Training loss: 2.410606107353412
Validation loss: 2.5067345509907626

Epoch: 6| Step: 1
Training loss: 1.8176542199358856
Validation loss: 2.517979722290562

Epoch: 6| Step: 2
Training loss: 3.2117510505152542
Validation loss: 2.533315859491752

Epoch: 6| Step: 3
Training loss: 2.6818383485009374
Validation loss: 2.545998108354951

Epoch: 6| Step: 4
Training loss: 1.9868625458323719
Validation loss: 2.5453320687675367

Epoch: 6| Step: 5
Training loss: 2.4007072519256156
Validation loss: 2.5541136521961505

Epoch: 6| Step: 6
Training loss: 1.4570620127030642
Validation loss: 2.544443604229932

Epoch: 6| Step: 7
Training loss: 1.6091348413329296
Validation loss: 2.553476340104659

Epoch: 6| Step: 8
Training loss: 2.1223473541402162
Validation loss: 2.562147503930835

Epoch: 6| Step: 9
Training loss: 2.0080639870923744
Validation loss: 2.5724152965830145

Epoch: 6| Step: 10
Training loss: 2.8196301255576754
Validation loss: 2.5775938161160536

Epoch: 6| Step: 11
Training loss: 2.3178447097488526
Validation loss: 2.585613649186769

Epoch: 6| Step: 12
Training loss: 2.378356769912326
Validation loss: 2.5665641592867203

Epoch: 6| Step: 13
Training loss: 2.317854481636147
Validation loss: 2.5686448241990805

Epoch: 210| Step: 0
Training loss: 2.5113181451767406
Validation loss: 2.561912414979891

Epoch: 6| Step: 1
Training loss: 2.1217561534020613
Validation loss: 2.5554727481012685

Epoch: 6| Step: 2
Training loss: 2.393233527898014
Validation loss: 2.5496696008795117

Epoch: 6| Step: 3
Training loss: 2.110592977898219
Validation loss: 2.5471337699878314

Epoch: 6| Step: 4
Training loss: 2.942946234794913
Validation loss: 2.5630888533692517

Epoch: 6| Step: 5
Training loss: 2.4367570967621304
Validation loss: 2.567719246078319

Epoch: 6| Step: 6
Training loss: 2.3057749106401513
Validation loss: 2.5636349622440586

Epoch: 6| Step: 7
Training loss: 2.33515769164627
Validation loss: 2.55321026009523

Epoch: 6| Step: 8
Training loss: 1.647050898096106
Validation loss: 2.5741574362600343

Epoch: 6| Step: 9
Training loss: 2.097046719155722
Validation loss: 2.5799559747897307

Epoch: 6| Step: 10
Training loss: 2.391302174917749
Validation loss: 2.557237921083322

Epoch: 6| Step: 11
Training loss: 2.385924061835417
Validation loss: 2.5692559943526865

Epoch: 6| Step: 12
Training loss: 1.7910789886215084
Validation loss: 2.554263982946564

Epoch: 6| Step: 13
Training loss: 2.205513167060701
Validation loss: 2.5575092997402082

Epoch: 211| Step: 0
Training loss: 2.8320280509141416
Validation loss: 2.5264650652012937

Epoch: 6| Step: 1
Training loss: 1.856909327181699
Validation loss: 2.5143394502596297

Epoch: 6| Step: 2
Training loss: 2.325162295347796
Validation loss: 2.5234506014236775

Epoch: 6| Step: 3
Training loss: 2.658838065930275
Validation loss: 2.5002243259239387

Epoch: 6| Step: 4
Training loss: 2.9448206159430166
Validation loss: 2.5095955599350264

Epoch: 6| Step: 5
Training loss: 2.692880788527993
Validation loss: 2.507222947078463

Epoch: 6| Step: 6
Training loss: 1.9549722709542954
Validation loss: 2.5106943354181888

Epoch: 6| Step: 7
Training loss: 2.2172203701343647
Validation loss: 2.508336726426103

Epoch: 6| Step: 8
Training loss: 2.2041610554249327
Validation loss: 2.524503673583786

Epoch: 6| Step: 9
Training loss: 2.5965199215141457
Validation loss: 2.5463410892464164

Epoch: 6| Step: 10
Training loss: 1.6471069172641508
Validation loss: 2.567680301990412

Epoch: 6| Step: 11
Training loss: 2.767511360262304
Validation loss: 2.5549627499935044

Epoch: 6| Step: 12
Training loss: 1.6660679298052237
Validation loss: 2.5771959422576756

Epoch: 6| Step: 13
Training loss: 1.317929934035769
Validation loss: 2.5629249468513415

Epoch: 212| Step: 0
Training loss: 2.3421316026935672
Validation loss: 2.545772571327674

Epoch: 6| Step: 1
Training loss: 2.5993970501958046
Validation loss: 2.552502412187742

Epoch: 6| Step: 2
Training loss: 1.8911552631378057
Validation loss: 2.553741458785801

Epoch: 6| Step: 3
Training loss: 2.400211634841563
Validation loss: 2.5644832472764416

Epoch: 6| Step: 4
Training loss: 2.2462727085636316
Validation loss: 2.5481277770332236

Epoch: 6| Step: 5
Training loss: 1.67327415887276
Validation loss: 2.555604270514515

Epoch: 6| Step: 6
Training loss: 2.026452958463381
Validation loss: 2.5502917066786797

Epoch: 6| Step: 7
Training loss: 2.169736728958595
Validation loss: 2.5457182989857965

Epoch: 6| Step: 8
Training loss: 1.918149733696227
Validation loss: 2.528528909438629

Epoch: 6| Step: 9
Training loss: 2.815839353270661
Validation loss: 2.530057571293879

Epoch: 6| Step: 10
Training loss: 1.5498037644727876
Validation loss: 2.5317801560041473

Epoch: 6| Step: 11
Training loss: 1.8192159599840445
Validation loss: 2.5296906114464472

Epoch: 6| Step: 12
Training loss: 3.254833002450407
Validation loss: 2.534985881894015

Epoch: 6| Step: 13
Training loss: 2.5846928946432186
Validation loss: 2.539460308505076

Epoch: 213| Step: 0
Training loss: 1.629360510699865
Validation loss: 2.5476179307015028

Epoch: 6| Step: 1
Training loss: 2.527742758241681
Validation loss: 2.554395295365769

Epoch: 6| Step: 2
Training loss: 2.5693593214443307
Validation loss: 2.536152515082686

Epoch: 6| Step: 3
Training loss: 1.909624708364037
Validation loss: 2.558539485598623

Epoch: 6| Step: 4
Training loss: 2.7610722369146625
Validation loss: 2.5384531708263025

Epoch: 6| Step: 5
Training loss: 2.8071616478266455
Validation loss: 2.534680871031062

Epoch: 6| Step: 6
Training loss: 2.311685057688162
Validation loss: 2.534753078696733

Epoch: 6| Step: 7
Training loss: 2.813358938664107
Validation loss: 2.5311358076797337

Epoch: 6| Step: 8
Training loss: 2.0014839627464176
Validation loss: 2.5205229155619926

Epoch: 6| Step: 9
Training loss: 1.7672568013358092
Validation loss: 2.5360965953851133

Epoch: 6| Step: 10
Training loss: 1.609811223732742
Validation loss: 2.532631187216896

Epoch: 6| Step: 11
Training loss: 2.2973181887345357
Validation loss: 2.5343760116079674

Epoch: 6| Step: 12
Training loss: 1.3299036569764346
Validation loss: 2.5601942962684667

Epoch: 6| Step: 13
Training loss: 2.793400316307786
Validation loss: 2.566740946087094

Epoch: 214| Step: 0
Training loss: 2.428710348499627
Validation loss: 2.6014614601103223

Epoch: 6| Step: 1
Training loss: 1.8815238626565036
Validation loss: 2.5953463578776406

Epoch: 6| Step: 2
Training loss: 2.5066829050667647
Validation loss: 2.6055453402172795

Epoch: 6| Step: 3
Training loss: 2.600767271829927
Validation loss: 2.621915049014025

Epoch: 6| Step: 4
Training loss: 1.9281074758070256
Validation loss: 2.6152110213893414

Epoch: 6| Step: 5
Training loss: 1.7971788895755103
Validation loss: 2.5918061199468925

Epoch: 6| Step: 6
Training loss: 2.1575911400773964
Validation loss: 2.580657200943834

Epoch: 6| Step: 7
Training loss: 2.936979207075353
Validation loss: 2.5763130679517023

Epoch: 6| Step: 8
Training loss: 1.7458109445281937
Validation loss: 2.5366710022761034

Epoch: 6| Step: 9
Training loss: 2.510205229617651
Validation loss: 2.5344084512092024

Epoch: 6| Step: 10
Training loss: 2.1085324335387665
Validation loss: 2.5028484012275256

Epoch: 6| Step: 11
Training loss: 2.1510570855007565
Validation loss: 2.501250717109604

Epoch: 6| Step: 12
Training loss: 2.556306378551951
Validation loss: 2.493453426779545

Epoch: 6| Step: 13
Training loss: 2.4696152534908467
Validation loss: 2.4907397666153495

Epoch: 215| Step: 0
Training loss: 2.4444841925924727
Validation loss: 2.505954596914695

Epoch: 6| Step: 1
Training loss: 2.512392229644124
Validation loss: 2.5048025335246282

Epoch: 6| Step: 2
Training loss: 2.0349670439354943
Validation loss: 2.5008875542923303

Epoch: 6| Step: 3
Training loss: 1.9231898454377427
Validation loss: 2.503960492304844

Epoch: 6| Step: 4
Training loss: 2.369619498793272
Validation loss: 2.5148516427807306

Epoch: 6| Step: 5
Training loss: 2.4762063718030562
Validation loss: 2.5263079447190515

Epoch: 6| Step: 6
Training loss: 1.7290878124718032
Validation loss: 2.542151988445174

Epoch: 6| Step: 7
Training loss: 2.7970773634346573
Validation loss: 2.5568189371795054

Epoch: 6| Step: 8
Training loss: 2.165432823208472
Validation loss: 2.5640976895078147

Epoch: 6| Step: 9
Training loss: 2.322551225275938
Validation loss: 2.583565368281128

Epoch: 6| Step: 10
Training loss: 2.038105356355141
Validation loss: 2.587438096121408

Epoch: 6| Step: 11
Training loss: 2.125974768172187
Validation loss: 2.571002175852348

Epoch: 6| Step: 12
Training loss: 2.894457776247815
Validation loss: 2.570943969332641

Epoch: 6| Step: 13
Training loss: 2.4384344217236253
Validation loss: 2.5541014548394023

Epoch: 216| Step: 0
Training loss: 1.661062195368471
Validation loss: 2.5496845623712754

Epoch: 6| Step: 1
Training loss: 2.9190946191740546
Validation loss: 2.5410718899400195

Epoch: 6| Step: 2
Training loss: 2.3116284351813263
Validation loss: 2.5186169367524256

Epoch: 6| Step: 3
Training loss: 2.297270033724621
Validation loss: 2.50173222611145

Epoch: 6| Step: 4
Training loss: 1.8519496593430844
Validation loss: 2.509070163261686

Epoch: 6| Step: 5
Training loss: 2.3282808597288653
Validation loss: 2.5013716034542326

Epoch: 6| Step: 6
Training loss: 2.0313318089370007
Validation loss: 2.505274771102186

Epoch: 6| Step: 7
Training loss: 2.042550213685638
Validation loss: 2.493310083580075

Epoch: 6| Step: 8
Training loss: 2.2031420984348684
Validation loss: 2.5043226541523085

Epoch: 6| Step: 9
Training loss: 2.843596234199197
Validation loss: 2.503970331333128

Epoch: 6| Step: 10
Training loss: 2.3436083941596944
Validation loss: 2.5012975424957493

Epoch: 6| Step: 11
Training loss: 2.9047251977469863
Validation loss: 2.496484438349481

Epoch: 6| Step: 12
Training loss: 2.5615040774382756
Validation loss: 2.5210104845921735

Epoch: 6| Step: 13
Training loss: 1.6462791016250518
Validation loss: 2.5154159332656825

Epoch: 217| Step: 0
Training loss: 3.0024831349886236
Validation loss: 2.5281449413416865

Epoch: 6| Step: 1
Training loss: 2.1940633131644294
Validation loss: 2.5243454708026016

Epoch: 6| Step: 2
Training loss: 2.235770903218227
Validation loss: 2.5475430694772707

Epoch: 6| Step: 3
Training loss: 2.3674934617529297
Validation loss: 2.56104980309404

Epoch: 6| Step: 4
Training loss: 1.8265888900743088
Validation loss: 2.5728931940735205

Epoch: 6| Step: 5
Training loss: 2.60491196203558
Validation loss: 2.5614766969729668

Epoch: 6| Step: 6
Training loss: 2.408952854643693
Validation loss: 2.5387780445878274

Epoch: 6| Step: 7
Training loss: 1.761152155197649
Validation loss: 2.5418573891628613

Epoch: 6| Step: 8
Training loss: 2.4890459403752154
Validation loss: 2.5271767153760805

Epoch: 6| Step: 9
Training loss: 2.326029506525717
Validation loss: 2.5272743337414885

Epoch: 6| Step: 10
Training loss: 2.41850617434108
Validation loss: 2.5214034111090653

Epoch: 6| Step: 11
Training loss: 1.7956147127955544
Validation loss: 2.5240156615628306

Epoch: 6| Step: 12
Training loss: 2.114940844851619
Validation loss: 2.5319668104177047

Epoch: 6| Step: 13
Training loss: 2.1309368004093567
Validation loss: 2.537852972439369

Epoch: 218| Step: 0
Training loss: 1.52620652732828
Validation loss: 2.556496091778361

Epoch: 6| Step: 1
Training loss: 1.8072197393199712
Validation loss: 2.5523300959861457

Epoch: 6| Step: 2
Training loss: 1.7011921264984669
Validation loss: 2.5517463669226426

Epoch: 6| Step: 3
Training loss: 2.1843079301527126
Validation loss: 2.5635441304339293

Epoch: 6| Step: 4
Training loss: 1.9070364158526023
Validation loss: 2.5575838459449365

Epoch: 6| Step: 5
Training loss: 2.600363698610498
Validation loss: 2.5585330557964956

Epoch: 6| Step: 6
Training loss: 1.7042192216276022
Validation loss: 2.54458583936812

Epoch: 6| Step: 7
Training loss: 2.4759308885040467
Validation loss: 2.5424107858940195

Epoch: 6| Step: 8
Training loss: 3.1914459935752046
Validation loss: 2.5308130695644246

Epoch: 6| Step: 9
Training loss: 2.767189057757361
Validation loss: 2.527574311499381

Epoch: 6| Step: 10
Training loss: 3.0239571216005707
Validation loss: 2.524941263050743

Epoch: 6| Step: 11
Training loss: 2.090175595185073
Validation loss: 2.5473817972469757

Epoch: 6| Step: 12
Training loss: 2.2746771614813484
Validation loss: 2.5546138414502373

Epoch: 6| Step: 13
Training loss: 1.8375790014605866
Validation loss: 2.547990769072639

Epoch: 219| Step: 0
Training loss: 2.7875591254699374
Validation loss: 2.5678963324774218

Epoch: 6| Step: 1
Training loss: 2.2320175004908807
Validation loss: 2.577287156338505

Epoch: 6| Step: 2
Training loss: 2.468010127586223
Validation loss: 2.5656210957790564

Epoch: 6| Step: 3
Training loss: 1.4631878661639637
Validation loss: 2.5793839588568916

Epoch: 6| Step: 4
Training loss: 2.439269963787894
Validation loss: 2.5770916187479047

Epoch: 6| Step: 5
Training loss: 2.2998998537236797
Validation loss: 2.5887247451933044

Epoch: 6| Step: 6
Training loss: 2.312044665898428
Validation loss: 2.5851216176813283

Epoch: 6| Step: 7
Training loss: 2.323794850393181
Validation loss: 2.5842538137133153

Epoch: 6| Step: 8
Training loss: 2.0820057135585106
Validation loss: 2.574724424609568

Epoch: 6| Step: 9
Training loss: 1.953602968859467
Validation loss: 2.5628473775228735

Epoch: 6| Step: 10
Training loss: 2.439868558720282
Validation loss: 2.5427711046704675

Epoch: 6| Step: 11
Training loss: 1.9866742007968228
Validation loss: 2.5290242051836245

Epoch: 6| Step: 12
Training loss: 2.440799045584563
Validation loss: 2.524761423479154

Epoch: 6| Step: 13
Training loss: 2.5328134488498764
Validation loss: 2.517575875836915

Epoch: 220| Step: 0
Training loss: 1.9629942302026355
Validation loss: 2.4964725403974497

Epoch: 6| Step: 1
Training loss: 1.92020070407816
Validation loss: 2.49831595921429

Epoch: 6| Step: 2
Training loss: 1.9512398128500188
Validation loss: 2.5024616202181553

Epoch: 6| Step: 3
Training loss: 2.2809721895133874
Validation loss: 2.4915110149268926

Epoch: 6| Step: 4
Training loss: 2.6393293102446047
Validation loss: 2.4889417537210337

Epoch: 6| Step: 5
Training loss: 2.1168464864607475
Validation loss: 2.4969669778662236

Epoch: 6| Step: 6
Training loss: 2.9852285712316164
Validation loss: 2.502197023445619

Epoch: 6| Step: 7
Training loss: 2.728521392095283
Validation loss: 2.517937523339214

Epoch: 6| Step: 8
Training loss: 1.979483756380047
Validation loss: 2.5300172386285773

Epoch: 6| Step: 9
Training loss: 2.550789194839513
Validation loss: 2.5551583947828758

Epoch: 6| Step: 10
Training loss: 1.877054043060417
Validation loss: 2.5893628041609906

Epoch: 6| Step: 11
Training loss: 2.3963589188522336
Validation loss: 2.564514345366573

Epoch: 6| Step: 12
Training loss: 2.0732288476961327
Validation loss: 2.5709398812256357

Epoch: 6| Step: 13
Training loss: 2.060030065150441
Validation loss: 2.5580982301108057

Epoch: 221| Step: 0
Training loss: 3.0389567457298554
Validation loss: 2.5729809545807156

Epoch: 6| Step: 1
Training loss: 2.499663521057556
Validation loss: 2.5704469346096617

Epoch: 6| Step: 2
Training loss: 2.1810077784144637
Validation loss: 2.5663324710299307

Epoch: 6| Step: 3
Training loss: 2.084870826507056
Validation loss: 2.5822134410545066

Epoch: 6| Step: 4
Training loss: 2.6639819538547678
Validation loss: 2.559847816076447

Epoch: 6| Step: 5
Training loss: 2.028154685063294
Validation loss: 2.5568503460643113

Epoch: 6| Step: 6
Training loss: 2.296231757160582
Validation loss: 2.5637501869096195

Epoch: 6| Step: 7
Training loss: 2.570036992203884
Validation loss: 2.5459231448733575

Epoch: 6| Step: 8
Training loss: 2.454367839121833
Validation loss: 2.563318160718635

Epoch: 6| Step: 9
Training loss: 1.6933690899104976
Validation loss: 2.544352938454022

Epoch: 6| Step: 10
Training loss: 1.3526023436798318
Validation loss: 2.5375551649965553

Epoch: 6| Step: 11
Training loss: 1.9294443324773343
Validation loss: 2.5353076813176068

Epoch: 6| Step: 12
Training loss: 1.7580802204980701
Validation loss: 2.502958145009593

Epoch: 6| Step: 13
Training loss: 2.1771383932594963
Validation loss: 2.5130947332766125

Epoch: 222| Step: 0
Training loss: 1.7044082147084725
Validation loss: 2.5060301296602714

Epoch: 6| Step: 1
Training loss: 1.4090840075203586
Validation loss: 2.499349072274102

Epoch: 6| Step: 2
Training loss: 2.3059312470932
Validation loss: 2.515350887615294

Epoch: 6| Step: 3
Training loss: 2.7087992829758427
Validation loss: 2.4994647883670504

Epoch: 6| Step: 4
Training loss: 1.9248883574177331
Validation loss: 2.5051551992976915

Epoch: 6| Step: 5
Training loss: 2.5504849365483535
Validation loss: 2.5085232085118156

Epoch: 6| Step: 6
Training loss: 1.5252597962761867
Validation loss: 2.5230056345903553

Epoch: 6| Step: 7
Training loss: 2.072313946332236
Validation loss: 2.524722068585531

Epoch: 6| Step: 8
Training loss: 2.3593288189745194
Validation loss: 2.5553699013634383

Epoch: 6| Step: 9
Training loss: 2.826030566855395
Validation loss: 2.58676254157048

Epoch: 6| Step: 10
Training loss: 2.432990573449302
Validation loss: 2.617351166271699

Epoch: 6| Step: 11
Training loss: 2.7578892683631686
Validation loss: 2.6514305524004347

Epoch: 6| Step: 12
Training loss: 2.8338144305307944
Validation loss: 2.6831856629706854

Epoch: 6| Step: 13
Training loss: 1.9727137793282044
Validation loss: 2.664794209844681

Epoch: 223| Step: 0
Training loss: 2.805808010849994
Validation loss: 2.6011011823924295

Epoch: 6| Step: 1
Training loss: 2.449840801282736
Validation loss: 2.5693487275541202

Epoch: 6| Step: 2
Training loss: 1.7547353301488748
Validation loss: 2.538891736670561

Epoch: 6| Step: 3
Training loss: 2.4674402939704705
Validation loss: 2.529058378898066

Epoch: 6| Step: 4
Training loss: 1.6512887170195818
Validation loss: 2.5037958891496537

Epoch: 6| Step: 5
Training loss: 2.668762267752331
Validation loss: 2.5172469949982497

Epoch: 6| Step: 6
Training loss: 1.82320504950125
Validation loss: 2.5134259202162283

Epoch: 6| Step: 7
Training loss: 2.035376362969347
Validation loss: 2.509842380878821

Epoch: 6| Step: 8
Training loss: 2.8485693703832706
Validation loss: 2.527784227588888

Epoch: 6| Step: 9
Training loss: 1.6952656682309615
Validation loss: 2.5242267236610223

Epoch: 6| Step: 10
Training loss: 1.9563803437413292
Validation loss: 2.518228893155093

Epoch: 6| Step: 11
Training loss: 2.072847361979573
Validation loss: 2.534086702241968

Epoch: 6| Step: 12
Training loss: 2.2837054480772867
Validation loss: 2.5466331882007194

Epoch: 6| Step: 13
Training loss: 2.3173330167427038
Validation loss: 2.5291823116951906

Epoch: 224| Step: 0
Training loss: 1.6406991851019683
Validation loss: 2.5291051686418062

Epoch: 6| Step: 1
Training loss: 1.8613418946852625
Validation loss: 2.53747822168084

Epoch: 6| Step: 2
Training loss: 1.8357092532862354
Validation loss: 2.509564485913529

Epoch: 6| Step: 3
Training loss: 1.64364708988061
Validation loss: 2.5285818535161626

Epoch: 6| Step: 4
Training loss: 2.3362900075655597
Validation loss: 2.511595529685022

Epoch: 6| Step: 5
Training loss: 2.4650075044962643
Validation loss: 2.521164617496977

Epoch: 6| Step: 6
Training loss: 2.3117606553394934
Validation loss: 2.515537884390484

Epoch: 6| Step: 7
Training loss: 1.8289665828173631
Validation loss: 2.5448541951835164

Epoch: 6| Step: 8
Training loss: 1.606716144770738
Validation loss: 2.5551717845502293

Epoch: 6| Step: 9
Training loss: 2.600835108521636
Validation loss: 2.5393652163295255

Epoch: 6| Step: 10
Training loss: 2.2026689206143377
Validation loss: 2.5669238895689097

Epoch: 6| Step: 11
Training loss: 2.906406029235231
Validation loss: 2.5599228064253357

Epoch: 6| Step: 12
Training loss: 2.911258606494648
Validation loss: 2.554099284512805

Epoch: 6| Step: 13
Training loss: 2.543191691996254
Validation loss: 2.572709254091344

Epoch: 225| Step: 0
Training loss: 1.8847407047818208
Validation loss: 2.5583702086815725

Epoch: 6| Step: 1
Training loss: 2.812030837876161
Validation loss: 2.5831892732219726

Epoch: 6| Step: 2
Training loss: 2.536007683817538
Validation loss: 2.5858878201018

Epoch: 6| Step: 3
Training loss: 2.1306702751078186
Validation loss: 2.63078928407806

Epoch: 6| Step: 4
Training loss: 2.1962480282543972
Validation loss: 2.6394117980554985

Epoch: 6| Step: 5
Training loss: 2.2892785084328127
Validation loss: 2.6560505960453864

Epoch: 6| Step: 6
Training loss: 2.1226800708746887
Validation loss: 2.595316433047125

Epoch: 6| Step: 7
Training loss: 2.388628456301272
Validation loss: 2.6101427300354323

Epoch: 6| Step: 8
Training loss: 2.2559719305321324
Validation loss: 2.5721651181701826

Epoch: 6| Step: 9
Training loss: 1.717317226740631
Validation loss: 2.533290652701915

Epoch: 6| Step: 10
Training loss: 2.787110059346447
Validation loss: 2.518616076901225

Epoch: 6| Step: 11
Training loss: 2.093441954769002
Validation loss: 2.5119448609962087

Epoch: 6| Step: 12
Training loss: 2.532674694607188
Validation loss: 2.524952704235326

Epoch: 6| Step: 13
Training loss: 1.7941011995501521
Validation loss: 2.5205919502223595

Epoch: 226| Step: 0
Training loss: 1.6791852333171964
Validation loss: 2.5212618224573347

Epoch: 6| Step: 1
Training loss: 2.9013277434419096
Validation loss: 2.5235907367361343

Epoch: 6| Step: 2
Training loss: 2.5045350902351107
Validation loss: 2.51885411037092

Epoch: 6| Step: 3
Training loss: 2.562008787385759
Validation loss: 2.5167983104893743

Epoch: 6| Step: 4
Training loss: 1.948955510468905
Validation loss: 2.5200373809050234

Epoch: 6| Step: 5
Training loss: 2.596789957024268
Validation loss: 2.5266053635911434

Epoch: 6| Step: 6
Training loss: 1.3648549263403216
Validation loss: 2.5363599195455184

Epoch: 6| Step: 7
Training loss: 2.5302580785487634
Validation loss: 2.552693279843278

Epoch: 6| Step: 8
Training loss: 1.9391380276906003
Validation loss: 2.5669471793858554

Epoch: 6| Step: 9
Training loss: 2.3501860686965017
Validation loss: 2.578083215240026

Epoch: 6| Step: 10
Training loss: 2.317214490305028
Validation loss: 2.5827417824370467

Epoch: 6| Step: 11
Training loss: 2.3151848131400095
Validation loss: 2.5913003591087125

Epoch: 6| Step: 12
Training loss: 2.01876905213805
Validation loss: 2.591470605378685

Epoch: 6| Step: 13
Training loss: 1.5060557671514496
Validation loss: 2.5919389491750398

Epoch: 227| Step: 0
Training loss: 2.2610858565390366
Validation loss: 2.585532426560805

Epoch: 6| Step: 1
Training loss: 1.694947515479672
Validation loss: 2.583719468227805

Epoch: 6| Step: 2
Training loss: 2.679651376908948
Validation loss: 2.554207759690485

Epoch: 6| Step: 3
Training loss: 2.2513846269562365
Validation loss: 2.5835814638848293

Epoch: 6| Step: 4
Training loss: 1.8559046825482028
Validation loss: 2.592416849657517

Epoch: 6| Step: 5
Training loss: 1.8155527386098107
Validation loss: 2.5706122164690894

Epoch: 6| Step: 6
Training loss: 2.1632412340204135
Validation loss: 2.546820485910463

Epoch: 6| Step: 7
Training loss: 2.3282203398774968
Validation loss: 2.5613387818507727

Epoch: 6| Step: 8
Training loss: 2.08219923304367
Validation loss: 2.5757326219662326

Epoch: 6| Step: 9
Training loss: 2.6328978029462666
Validation loss: 2.587735245556543

Epoch: 6| Step: 10
Training loss: 2.3509633260938863
Validation loss: 2.574191288664103

Epoch: 6| Step: 11
Training loss: 2.091944699090766
Validation loss: 2.5666194461425595

Epoch: 6| Step: 12
Training loss: 2.4773673786346553
Validation loss: 2.5946215961412715

Epoch: 6| Step: 13
Training loss: 2.341641405813279
Validation loss: 2.5888354609965383

Epoch: 228| Step: 0
Training loss: 1.6913770712787006
Validation loss: 2.571107921022293

Epoch: 6| Step: 1
Training loss: 2.2624446250925363
Validation loss: 2.5585227587608776

Epoch: 6| Step: 2
Training loss: 1.8313879254057954
Validation loss: 2.5507240775819837

Epoch: 6| Step: 3
Training loss: 2.209113888776218
Validation loss: 2.5427163385069615

Epoch: 6| Step: 4
Training loss: 2.0161217365748163
Validation loss: 2.5490075137173664

Epoch: 6| Step: 5
Training loss: 2.398923147531248
Validation loss: 2.5453561415735297

Epoch: 6| Step: 6
Training loss: 2.8723080513003723
Validation loss: 2.56134860214946

Epoch: 6| Step: 7
Training loss: 1.959813255444462
Validation loss: 2.561674900112021

Epoch: 6| Step: 8
Training loss: 2.6221024097488437
Validation loss: 2.578200845855029

Epoch: 6| Step: 9
Training loss: 1.9794488270719661
Validation loss: 2.5717746089285582

Epoch: 6| Step: 10
Training loss: 2.478039226033704
Validation loss: 2.5692356408538797

Epoch: 6| Step: 11
Training loss: 2.3141088302064685
Validation loss: 2.576266564900984

Epoch: 6| Step: 12
Training loss: 1.73034695095484
Validation loss: 2.560008147768128

Epoch: 6| Step: 13
Training loss: 2.6383978124640692
Validation loss: 2.526221158182157

Epoch: 229| Step: 0
Training loss: 1.8492168263730357
Validation loss: 2.509290796231352

Epoch: 6| Step: 1
Training loss: 1.5444852305972236
Validation loss: 2.4987154998611216

Epoch: 6| Step: 2
Training loss: 2.2526711397009014
Validation loss: 2.4926045705578765

Epoch: 6| Step: 3
Training loss: 3.1430423979222297
Validation loss: 2.498958871535805

Epoch: 6| Step: 4
Training loss: 2.235166502858726
Validation loss: 2.5048035726227527

Epoch: 6| Step: 5
Training loss: 2.429786999005194
Validation loss: 2.4941702263175047

Epoch: 6| Step: 6
Training loss: 1.7596218715129643
Validation loss: 2.483289869512694

Epoch: 6| Step: 7
Training loss: 2.354292998398532
Validation loss: 2.4830657500130435

Epoch: 6| Step: 8
Training loss: 2.057584627434302
Validation loss: 2.497656025358032

Epoch: 6| Step: 9
Training loss: 2.8959204754422125
Validation loss: 2.498070035483591

Epoch: 6| Step: 10
Training loss: 2.4972054120852185
Validation loss: 2.527729176017969

Epoch: 6| Step: 11
Training loss: 2.7904733033508613
Validation loss: 2.56776947093137

Epoch: 6| Step: 12
Training loss: 2.358408951192921
Validation loss: 2.6063034268642666

Epoch: 6| Step: 13
Training loss: 1.8113796454681939
Validation loss: 2.6127983373136385

Epoch: 230| Step: 0
Training loss: 1.428635423793643
Validation loss: 2.6000417516486074

Epoch: 6| Step: 1
Training loss: 2.0706399910496707
Validation loss: 2.6317610334260078

Epoch: 6| Step: 2
Training loss: 2.6975999054602156
Validation loss: 2.6485798965327945

Epoch: 6| Step: 3
Training loss: 2.5472325735137216
Validation loss: 2.6395202974431586

Epoch: 6| Step: 4
Training loss: 2.720847975578069
Validation loss: 2.620118142951396

Epoch: 6| Step: 5
Training loss: 2.2144930122835422
Validation loss: 2.6134281620836624

Epoch: 6| Step: 6
Training loss: 1.6683957984858608
Validation loss: 2.5734494747708583

Epoch: 6| Step: 7
Training loss: 2.5796199279105334
Validation loss: 2.556242474433746

Epoch: 6| Step: 8
Training loss: 2.435355979700662
Validation loss: 2.543380742995658

Epoch: 6| Step: 9
Training loss: 2.362008551288988
Validation loss: 2.5363916836127642

Epoch: 6| Step: 10
Training loss: 1.7723814386871921
Validation loss: 2.5263447425689685

Epoch: 6| Step: 11
Training loss: 1.7832069355149935
Validation loss: 2.51381910752967

Epoch: 6| Step: 12
Training loss: 2.299646275727908
Validation loss: 2.537369540263742

Epoch: 6| Step: 13
Training loss: 2.090421165485292
Validation loss: 2.5241832910516906

Epoch: 231| Step: 0
Training loss: 2.359793922672679
Validation loss: 2.5341086552243874

Epoch: 6| Step: 1
Training loss: 1.565561728046042
Validation loss: 2.5382552521590327

Epoch: 6| Step: 2
Training loss: 1.9705555825630336
Validation loss: 2.5435441748525762

Epoch: 6| Step: 3
Training loss: 1.6587565905879162
Validation loss: 2.5616135420799497

Epoch: 6| Step: 4
Training loss: 2.8271550997060966
Validation loss: 2.5554311993883005

Epoch: 6| Step: 5
Training loss: 2.306056970307797
Validation loss: 2.5728690931938765

Epoch: 6| Step: 6
Training loss: 2.4837044824692396
Validation loss: 2.5717426174820894

Epoch: 6| Step: 7
Training loss: 1.9205364745395024
Validation loss: 2.5506423515135306

Epoch: 6| Step: 8
Training loss: 2.1315999479294176
Validation loss: 2.5501220848428714

Epoch: 6| Step: 9
Training loss: 2.1810084343090796
Validation loss: 2.5591173718482128

Epoch: 6| Step: 10
Training loss: 2.476982971502485
Validation loss: 2.5697558804233918

Epoch: 6| Step: 11
Training loss: 1.883684898015968
Validation loss: 2.5788205528254045

Epoch: 6| Step: 12
Training loss: 2.5091029379547534
Validation loss: 2.6044603690783297

Epoch: 6| Step: 13
Training loss: 2.49553892748124
Validation loss: 2.597854170752417

Epoch: 232| Step: 0
Training loss: 2.6755419102014883
Validation loss: 2.5830423796275164

Epoch: 6| Step: 1
Training loss: 2.823989120159858
Validation loss: 2.567998166907578

Epoch: 6| Step: 2
Training loss: 1.8138715881774037
Validation loss: 2.5531164037652356

Epoch: 6| Step: 3
Training loss: 1.9894749743394484
Validation loss: 2.554545687317876

Epoch: 6| Step: 4
Training loss: 2.492041317470181
Validation loss: 2.5779447550332923

Epoch: 6| Step: 5
Training loss: 2.15207810328963
Validation loss: 2.5737092937519215

Epoch: 6| Step: 6
Training loss: 1.4212984026850581
Validation loss: 2.584133490856201

Epoch: 6| Step: 7
Training loss: 2.1295887264371753
Validation loss: 2.6117051736134758

Epoch: 6| Step: 8
Training loss: 1.959994328646337
Validation loss: 2.599291401061693

Epoch: 6| Step: 9
Training loss: 2.392095475074383
Validation loss: 2.5693211677694148

Epoch: 6| Step: 10
Training loss: 2.437674589506851
Validation loss: 2.5761999322010727

Epoch: 6| Step: 11
Training loss: 2.384594660448839
Validation loss: 2.5975060441035867

Epoch: 6| Step: 12
Training loss: 1.8668103335929702
Validation loss: 2.5550519273063497

Epoch: 6| Step: 13
Training loss: 1.557766572969717
Validation loss: 2.553667088284707

Epoch: 233| Step: 0
Training loss: 1.6404217548725855
Validation loss: 2.527144662522218

Epoch: 6| Step: 1
Training loss: 2.8758049542922475
Validation loss: 2.522455187633586

Epoch: 6| Step: 2
Training loss: 2.784966204179658
Validation loss: 2.5026127751917184

Epoch: 6| Step: 3
Training loss: 2.295708392482684
Validation loss: 2.493648017385064

Epoch: 6| Step: 4
Training loss: 2.1534434311458055
Validation loss: 2.504951889543086

Epoch: 6| Step: 5
Training loss: 2.8806938511770013
Validation loss: 2.502861610426444

Epoch: 6| Step: 6
Training loss: 2.281001247273547
Validation loss: 2.5034285559324028

Epoch: 6| Step: 7
Training loss: 1.9071143645193591
Validation loss: 2.498639976594367

Epoch: 6| Step: 8
Training loss: 2.4542803139486806
Validation loss: 2.5187213867682585

Epoch: 6| Step: 9
Training loss: 1.7043434474194086
Validation loss: 2.5081275749937952

Epoch: 6| Step: 10
Training loss: 2.4603007143645144
Validation loss: 2.521760412777652

Epoch: 6| Step: 11
Training loss: 1.9498545616883995
Validation loss: 2.511619696436341

Epoch: 6| Step: 12
Training loss: 2.3251161525794446
Validation loss: 2.5249619736027014

Epoch: 6| Step: 13
Training loss: 1.7569164111380822
Validation loss: 2.5186031712094072

Epoch: 234| Step: 0
Training loss: 2.9417434235699735
Validation loss: 2.516740223986443

Epoch: 6| Step: 1
Training loss: 1.9575951652730612
Validation loss: 2.5342480992642513

Epoch: 6| Step: 2
Training loss: 1.5691341704847646
Validation loss: 2.5194007544028003

Epoch: 6| Step: 3
Training loss: 2.7292953829708693
Validation loss: 2.5320010464255813

Epoch: 6| Step: 4
Training loss: 2.168418493961351
Validation loss: 2.5089692075483634

Epoch: 6| Step: 5
Training loss: 2.7065600140547734
Validation loss: 2.5203456459459397

Epoch: 6| Step: 6
Training loss: 2.2326155984816323
Validation loss: 2.516069803344074

Epoch: 6| Step: 7
Training loss: 1.5337992098623328
Validation loss: 2.5151631817924884

Epoch: 6| Step: 8
Training loss: 2.0429598806272575
Validation loss: 2.508215035112865

Epoch: 6| Step: 9
Training loss: 1.6750482409917806
Validation loss: 2.4786279611303232

Epoch: 6| Step: 10
Training loss: 2.831284754794532
Validation loss: 2.491033926865616

Epoch: 6| Step: 11
Training loss: 2.092289885222923
Validation loss: 2.4809058017117582

Epoch: 6| Step: 12
Training loss: 2.516916358215773
Validation loss: 2.480245376902003

Epoch: 6| Step: 13
Training loss: 1.9485106625009478
Validation loss: 2.481780979153101

Epoch: 235| Step: 0
Training loss: 2.266776903594654
Validation loss: 2.491576778636173

Epoch: 6| Step: 1
Training loss: 2.626415416041809
Validation loss: 2.5108285199395737

Epoch: 6| Step: 2
Training loss: 2.0168912000688186
Validation loss: 2.533420856327521

Epoch: 6| Step: 3
Training loss: 1.4572161437018643
Validation loss: 2.5338718509089633

Epoch: 6| Step: 4
Training loss: 2.5539029751228908
Validation loss: 2.5328321182774527

Epoch: 6| Step: 5
Training loss: 2.3920108543073177
Validation loss: 2.5448232315943593

Epoch: 6| Step: 6
Training loss: 2.2250309545528264
Validation loss: 2.575121939651421

Epoch: 6| Step: 7
Training loss: 1.6493824063070115
Validation loss: 2.579921320102399

Epoch: 6| Step: 8
Training loss: 2.8060571413101787
Validation loss: 2.5747032037691224

Epoch: 6| Step: 9
Training loss: 1.9524831098541537
Validation loss: 2.5707127840125072

Epoch: 6| Step: 10
Training loss: 1.4329266984164502
Validation loss: 2.5742881198271217

Epoch: 6| Step: 11
Training loss: 2.4770999168908183
Validation loss: 2.5489684786099063

Epoch: 6| Step: 12
Training loss: 2.5271710155482934
Validation loss: 2.558558262392054

Epoch: 6| Step: 13
Training loss: 2.208481249863751
Validation loss: 2.547993248708495

Epoch: 236| Step: 0
Training loss: 2.0125017438608515
Validation loss: 2.5666815746997362

Epoch: 6| Step: 1
Training loss: 2.3557144973121593
Validation loss: 2.560348553497776

Epoch: 6| Step: 2
Training loss: 2.2431806431690213
Validation loss: 2.588725604782454

Epoch: 6| Step: 3
Training loss: 1.6148402184021917
Validation loss: 2.628519574882014

Epoch: 6| Step: 4
Training loss: 2.188129770360354
Validation loss: 2.6129454438316917

Epoch: 6| Step: 5
Training loss: 2.0559415870042574
Validation loss: 2.5970363097082947

Epoch: 6| Step: 6
Training loss: 2.106665672692334
Validation loss: 2.5867531403444803

Epoch: 6| Step: 7
Training loss: 2.14464064355552
Validation loss: 2.563388786629676

Epoch: 6| Step: 8
Training loss: 2.5412644448458517
Validation loss: 2.564896083595722

Epoch: 6| Step: 9
Training loss: 2.7970664528899425
Validation loss: 2.5564004675021397

Epoch: 6| Step: 10
Training loss: 1.646517245325433
Validation loss: 2.577569504820379

Epoch: 6| Step: 11
Training loss: 2.3810464286394994
Validation loss: 2.565460665694516

Epoch: 6| Step: 12
Training loss: 1.8799497755930719
Validation loss: 2.5499766679082825

Epoch: 6| Step: 13
Training loss: 2.4618991486681354
Validation loss: 2.574497823295826

Epoch: 237| Step: 0
Training loss: 1.7626474981612312
Validation loss: 2.5628877516977857

Epoch: 6| Step: 1
Training loss: 1.5838119469430134
Validation loss: 2.5696454636809163

Epoch: 6| Step: 2
Training loss: 2.2615542969680753
Validation loss: 2.5539111280778815

Epoch: 6| Step: 3
Training loss: 2.0217242554683184
Validation loss: 2.5763044614802424

Epoch: 6| Step: 4
Training loss: 1.8607270910556188
Validation loss: 2.5432779072446245

Epoch: 6| Step: 5
Training loss: 2.2327864541949864
Validation loss: 2.5412521545431046

Epoch: 6| Step: 6
Training loss: 1.9974692545447508
Validation loss: 2.5492201541386663

Epoch: 6| Step: 7
Training loss: 2.117484096570965
Validation loss: 2.5574357768447573

Epoch: 6| Step: 8
Training loss: 2.4025132530394653
Validation loss: 2.5540753796824194

Epoch: 6| Step: 9
Training loss: 2.1465034796408675
Validation loss: 2.5433828365396245

Epoch: 6| Step: 10
Training loss: 2.6280115200585685
Validation loss: 2.5373615690659164

Epoch: 6| Step: 11
Training loss: 2.248351871007796
Validation loss: 2.5747940277385917

Epoch: 6| Step: 12
Training loss: 2.131928984026468
Validation loss: 2.5711042890986646

Epoch: 6| Step: 13
Training loss: 2.8718370370773645
Validation loss: 2.5853374049977815

Epoch: 238| Step: 0
Training loss: 1.4464481325525624
Validation loss: 2.607770590257792

Epoch: 6| Step: 1
Training loss: 2.6964816446413455
Validation loss: 2.61403372612512

Epoch: 6| Step: 2
Training loss: 2.409218777392391
Validation loss: 2.6363638330527284

Epoch: 6| Step: 3
Training loss: 1.9786699842997566
Validation loss: 2.64010307977749

Epoch: 6| Step: 4
Training loss: 1.8644459281317338
Validation loss: 2.6179355975550394

Epoch: 6| Step: 5
Training loss: 1.707717164110514
Validation loss: 2.5997514807697537

Epoch: 6| Step: 6
Training loss: 2.0293126183671073
Validation loss: 2.5866220419105197

Epoch: 6| Step: 7
Training loss: 2.6726377413503832
Validation loss: 2.6057107442239804

Epoch: 6| Step: 8
Training loss: 2.461744291269287
Validation loss: 2.567956898221592

Epoch: 6| Step: 9
Training loss: 2.2317497997264617
Validation loss: 2.559301644354223

Epoch: 6| Step: 10
Training loss: 1.8096102335973576
Validation loss: 2.554558504757868

Epoch: 6| Step: 11
Training loss: 2.5250005929776242
Validation loss: 2.5767882918077545

Epoch: 6| Step: 12
Training loss: 2.315915446528381
Validation loss: 2.5624538820660265

Epoch: 6| Step: 13
Training loss: 1.9476278842370696
Validation loss: 2.5606200913107617

Epoch: 239| Step: 0
Training loss: 1.9529636163794386
Validation loss: 2.5874532615506953

Epoch: 6| Step: 1
Training loss: 1.9863614329918453
Validation loss: 2.597700978135441

Epoch: 6| Step: 2
Training loss: 1.9862378605350988
Validation loss: 2.5975760005324338

Epoch: 6| Step: 3
Training loss: 2.2560926176430667
Validation loss: 2.5926827529211356

Epoch: 6| Step: 4
Training loss: 2.058981466246048
Validation loss: 2.620162942614567

Epoch: 6| Step: 5
Training loss: 2.7933279380048237
Validation loss: 2.6121359436104803

Epoch: 6| Step: 6
Training loss: 1.3204175918558205
Validation loss: 2.5859608567518952

Epoch: 6| Step: 7
Training loss: 1.8444972706063878
Validation loss: 2.5828238774499233

Epoch: 6| Step: 8
Training loss: 2.7883732475651133
Validation loss: 2.5719254523914366

Epoch: 6| Step: 9
Training loss: 2.3801652054388756
Validation loss: 2.5591043753844303

Epoch: 6| Step: 10
Training loss: 2.530431356033041
Validation loss: 2.5643678386110045

Epoch: 6| Step: 11
Training loss: 2.028328540621852
Validation loss: 2.546298611251344

Epoch: 6| Step: 12
Training loss: 2.1501126503818995
Validation loss: 2.5654497072009637

Epoch: 6| Step: 13
Training loss: 1.8216172155361685
Validation loss: 2.582209717031231

Epoch: 240| Step: 0
Training loss: 1.8179424393819195
Validation loss: 2.6021712834745587

Epoch: 6| Step: 1
Training loss: 2.2455149559961827
Validation loss: 2.616770545047631

Epoch: 6| Step: 2
Training loss: 1.8345796799072835
Validation loss: 2.6079395632742566

Epoch: 6| Step: 3
Training loss: 2.0301076170860215
Validation loss: 2.6018170909010108

Epoch: 6| Step: 4
Training loss: 1.36604178242433
Validation loss: 2.5701924211924205

Epoch: 6| Step: 5
Training loss: 2.7421598514565013
Validation loss: 2.597290946495458

Epoch: 6| Step: 6
Training loss: 1.8977044342444311
Validation loss: 2.59279250277438

Epoch: 6| Step: 7
Training loss: 1.8376794221434096
Validation loss: 2.5824263939303194

Epoch: 6| Step: 8
Training loss: 2.573529303093916
Validation loss: 2.5737354710573186

Epoch: 6| Step: 9
Training loss: 2.3869670732494104
Validation loss: 2.571024030004606

Epoch: 6| Step: 10
Training loss: 2.3172387722565246
Validation loss: 2.543304671188111

Epoch: 6| Step: 11
Training loss: 1.7869744922202855
Validation loss: 2.556761853146682

Epoch: 6| Step: 12
Training loss: 2.930655601766361
Validation loss: 2.5715848021251557

Epoch: 6| Step: 13
Training loss: 2.13647124759138
Validation loss: 2.5734030898263613

Epoch: 241| Step: 0
Training loss: 2.422317759742226
Validation loss: 2.578235600728958

Epoch: 6| Step: 1
Training loss: 2.4873517514626173
Validation loss: 2.6008094331530756

Epoch: 6| Step: 2
Training loss: 1.6088921276227366
Validation loss: 2.576537088300082

Epoch: 6| Step: 3
Training loss: 1.8150043943577894
Validation loss: 2.6105519303584885

Epoch: 6| Step: 4
Training loss: 2.418069125604893
Validation loss: 2.612858075147178

Epoch: 6| Step: 5
Training loss: 1.5898133071121738
Validation loss: 2.5921987007915455

Epoch: 6| Step: 6
Training loss: 2.4027924901650284
Validation loss: 2.5897856447386483

Epoch: 6| Step: 7
Training loss: 1.9575835950401799
Validation loss: 2.5579592784417065

Epoch: 6| Step: 8
Training loss: 2.409105662371051
Validation loss: 2.575611438192511

Epoch: 6| Step: 9
Training loss: 2.0104634044004257
Validation loss: 2.597124256546236

Epoch: 6| Step: 10
Training loss: 2.1116663038237915
Validation loss: 2.63115921709596

Epoch: 6| Step: 11
Training loss: 1.6772409763841147
Validation loss: 2.627921507128162

Epoch: 6| Step: 12
Training loss: 2.6772850544453326
Validation loss: 2.6236292272368273

Epoch: 6| Step: 13
Training loss: 2.1877509926806895
Validation loss: 2.628314982898282

Epoch: 242| Step: 0
Training loss: 1.6531993193046521
Validation loss: 2.5992915539357755

Epoch: 6| Step: 1
Training loss: 2.019969427802761
Validation loss: 2.5616019156104333

Epoch: 6| Step: 2
Training loss: 1.7527551760713398
Validation loss: 2.5537664870571586

Epoch: 6| Step: 3
Training loss: 2.5614197477702825
Validation loss: 2.5461080445595234

Epoch: 6| Step: 4
Training loss: 2.2447992193415094
Validation loss: 2.5548053445962906

Epoch: 6| Step: 5
Training loss: 1.905790555023799
Validation loss: 2.5128163519699602

Epoch: 6| Step: 6
Training loss: 1.9783625793009285
Validation loss: 2.527891324768589

Epoch: 6| Step: 7
Training loss: 2.1857611148066884
Validation loss: 2.5342063593701183

Epoch: 6| Step: 8
Training loss: 1.8655563316295636
Validation loss: 2.5156397058914024

Epoch: 6| Step: 9
Training loss: 2.5396893006378582
Validation loss: 2.5372413403199796

Epoch: 6| Step: 10
Training loss: 2.55678703057935
Validation loss: 2.551864526412465

Epoch: 6| Step: 11
Training loss: 1.6030543380542017
Validation loss: 2.607109700730537

Epoch: 6| Step: 12
Training loss: 2.7352236057629638
Validation loss: 2.609194081139185

Epoch: 6| Step: 13
Training loss: 2.3943199574778755
Validation loss: 2.6190020898890984

Epoch: 243| Step: 0
Training loss: 2.2332518629140843
Validation loss: 2.637186328260711

Epoch: 6| Step: 1
Training loss: 2.0026444595179127
Validation loss: 2.6067999280181775

Epoch: 6| Step: 2
Training loss: 2.250605501717067
Validation loss: 2.596009675756839

Epoch: 6| Step: 3
Training loss: 2.4948874649630173
Validation loss: 2.5844404914181016

Epoch: 6| Step: 4
Training loss: 2.2740407451445086
Validation loss: 2.566910615284916

Epoch: 6| Step: 5
Training loss: 1.684374351713661
Validation loss: 2.552487965380139

Epoch: 6| Step: 6
Training loss: 1.8224615418990464
Validation loss: 2.5420095077004694

Epoch: 6| Step: 7
Training loss: 2.405607459741969
Validation loss: 2.5400945512439566

Epoch: 6| Step: 8
Training loss: 1.8395618133611036
Validation loss: 2.5174107502102734

Epoch: 6| Step: 9
Training loss: 1.9829141240572221
Validation loss: 2.51946560875208

Epoch: 6| Step: 10
Training loss: 1.5899423479628376
Validation loss: 2.5475842633098797

Epoch: 6| Step: 11
Training loss: 1.460954472244328
Validation loss: 2.5564045089126015

Epoch: 6| Step: 12
Training loss: 2.7665626100328784
Validation loss: 2.55166444000539

Epoch: 6| Step: 13
Training loss: 2.7854818659369993
Validation loss: 2.5967897427943725

Epoch: 244| Step: 0
Training loss: 2.302476035292642
Validation loss: 2.5909609449101354

Epoch: 6| Step: 1
Training loss: 2.715464130022116
Validation loss: 2.6517461853604103

Epoch: 6| Step: 2
Training loss: 1.6687544461880433
Validation loss: 2.666462090711621

Epoch: 6| Step: 3
Training loss: 2.2172459622203444
Validation loss: 2.6267909343808764

Epoch: 6| Step: 4
Training loss: 2.2156026303731795
Validation loss: 2.64758282489557

Epoch: 6| Step: 5
Training loss: 2.1839462841889907
Validation loss: 2.6586328477251793

Epoch: 6| Step: 6
Training loss: 1.7746253383824508
Validation loss: 2.60544036743017

Epoch: 6| Step: 7
Training loss: 1.6984818186939294
Validation loss: 2.5629509552301424

Epoch: 6| Step: 8
Training loss: 2.187948998283963
Validation loss: 2.563304402701127

Epoch: 6| Step: 9
Training loss: 1.8771568608534086
Validation loss: 2.5174590507543386

Epoch: 6| Step: 10
Training loss: 2.156468698219134
Validation loss: 2.5098312428724503

Epoch: 6| Step: 11
Training loss: 2.3824653747860522
Validation loss: 2.5026317254863626

Epoch: 6| Step: 12
Training loss: 1.875966141059679
Validation loss: 2.5122160154823963

Epoch: 6| Step: 13
Training loss: 3.137195897657773
Validation loss: 2.5086632827346014

Epoch: 245| Step: 0
Training loss: 1.8986565106438174
Validation loss: 2.53548794042565

Epoch: 6| Step: 1
Training loss: 2.074633081006587
Validation loss: 2.547645467910637

Epoch: 6| Step: 2
Training loss: 1.7952609566908115
Validation loss: 2.5489141028312945

Epoch: 6| Step: 3
Training loss: 2.2750385323080415
Validation loss: 2.5660917572296813

Epoch: 6| Step: 4
Training loss: 1.8789021894446767
Validation loss: 2.571553271886635

Epoch: 6| Step: 5
Training loss: 2.4855649005932303
Validation loss: 2.561132469304254

Epoch: 6| Step: 6
Training loss: 2.1357713234252342
Validation loss: 2.5990527077908125

Epoch: 6| Step: 7
Training loss: 2.4797466037871976
Validation loss: 2.577239622425699

Epoch: 6| Step: 8
Training loss: 2.300377698652445
Validation loss: 2.61413897706303

Epoch: 6| Step: 9
Training loss: 2.0691544658881402
Validation loss: 2.6526689962038272

Epoch: 6| Step: 10
Training loss: 1.5082953277914117
Validation loss: 2.657826258888939

Epoch: 6| Step: 11
Training loss: 2.266233901709954
Validation loss: 2.66300831630209

Epoch: 6| Step: 12
Training loss: 2.5082032086488657
Validation loss: 2.6607406504572304

Epoch: 6| Step: 13
Training loss: 2.6435795794450536
Validation loss: 2.630191921271055

Epoch: 246| Step: 0
Training loss: 2.122522143640471
Validation loss: 2.5965482026460727

Epoch: 6| Step: 1
Training loss: 2.3885004913157086
Validation loss: 2.582907477523163

Epoch: 6| Step: 2
Training loss: 1.8784110513137837
Validation loss: 2.5585698017426464

Epoch: 6| Step: 3
Training loss: 3.0441685320283436
Validation loss: 2.538552304385039

Epoch: 6| Step: 4
Training loss: 2.396093459451146
Validation loss: 2.5275505409759274

Epoch: 6| Step: 5
Training loss: 1.904246418602385
Validation loss: 2.5629044810562385

Epoch: 6| Step: 6
Training loss: 2.2821030785351417
Validation loss: 2.5550785990231843

Epoch: 6| Step: 7
Training loss: 2.010888263422707
Validation loss: 2.562563437940422

Epoch: 6| Step: 8
Training loss: 1.7502634667569237
Validation loss: 2.577870288943656

Epoch: 6| Step: 9
Training loss: 1.6750592007779426
Validation loss: 2.5930797982599456

Epoch: 6| Step: 10
Training loss: 2.27697080826842
Validation loss: 2.5659659524260854

Epoch: 6| Step: 11
Training loss: 2.1545643506393914
Validation loss: 2.5675627001046553

Epoch: 6| Step: 12
Training loss: 1.8373852804275126
Validation loss: 2.5474092668142596

Epoch: 6| Step: 13
Training loss: 2.150571339122644
Validation loss: 2.5306513671054094

Epoch: 247| Step: 0
Training loss: 1.4318011559469068
Validation loss: 2.5343179516813663

Epoch: 6| Step: 1
Training loss: 1.8378746688750112
Validation loss: 2.5322669855126168

Epoch: 6| Step: 2
Training loss: 2.0087424176873587
Validation loss: 2.528850312744184

Epoch: 6| Step: 3
Training loss: 1.7104618334488797
Validation loss: 2.5394500906092468

Epoch: 6| Step: 4
Training loss: 2.379549587809577
Validation loss: 2.5401239377294536

Epoch: 6| Step: 5
Training loss: 3.0877541132459347
Validation loss: 2.549678297257284

Epoch: 6| Step: 6
Training loss: 1.9839062475003322
Validation loss: 2.55523997641149

Epoch: 6| Step: 7
Training loss: 1.5813095141885052
Validation loss: 2.588382053379328

Epoch: 6| Step: 8
Training loss: 1.6006510304125907
Validation loss: 2.5788135264207646

Epoch: 6| Step: 9
Training loss: 2.1748420701841593
Validation loss: 2.6037600441414037

Epoch: 6| Step: 10
Training loss: 2.3858824917810604
Validation loss: 2.5969931614232107

Epoch: 6| Step: 11
Training loss: 1.9096976823867706
Validation loss: 2.5789373794059003

Epoch: 6| Step: 12
Training loss: 1.9959734079772138
Validation loss: 2.5772968696153393

Epoch: 6| Step: 13
Training loss: 3.0338757340915707
Validation loss: 2.5832089168572683

Epoch: 248| Step: 0
Training loss: 1.6516836304215288
Validation loss: 2.6059578699066868

Epoch: 6| Step: 1
Training loss: 1.8312163991091306
Validation loss: 2.576027743472491

Epoch: 6| Step: 2
Training loss: 2.654113089491305
Validation loss: 2.584008110785082

Epoch: 6| Step: 3
Training loss: 1.6133167179817889
Validation loss: 2.560196857209898

Epoch: 6| Step: 4
Training loss: 1.8957066615897236
Validation loss: 2.555158301474146

Epoch: 6| Step: 5
Training loss: 2.8905806254512063
Validation loss: 2.5590072647116826

Epoch: 6| Step: 6
Training loss: 1.3667731828971983
Validation loss: 2.5405668213686714

Epoch: 6| Step: 7
Training loss: 2.30270621272007
Validation loss: 2.53957694295111

Epoch: 6| Step: 8
Training loss: 2.815085346019032
Validation loss: 2.5170816031024175

Epoch: 6| Step: 9
Training loss: 1.5527392885142384
Validation loss: 2.5337983556849646

Epoch: 6| Step: 10
Training loss: 1.2653358034874214
Validation loss: 2.5394009878043233

Epoch: 6| Step: 11
Training loss: 1.7251867967168901
Validation loss: 2.5484914506151757

Epoch: 6| Step: 12
Training loss: 2.8918738064702665
Validation loss: 2.5394933951153593

Epoch: 6| Step: 13
Training loss: 2.5643627560476876
Validation loss: 2.5364286719956755

Epoch: 249| Step: 0
Training loss: 1.86830482411249
Validation loss: 2.571625595391111

Epoch: 6| Step: 1
Training loss: 2.476783525971029
Validation loss: 2.5874234604380244

Epoch: 6| Step: 2
Training loss: 1.7726959829303328
Validation loss: 2.599057982425816

Epoch: 6| Step: 3
Training loss: 1.7273018061092935
Validation loss: 2.6094695814583853

Epoch: 6| Step: 4
Training loss: 1.8174568009522638
Validation loss: 2.6384756380944068

Epoch: 6| Step: 5
Training loss: 2.261956237025596
Validation loss: 2.655326727682765

Epoch: 6| Step: 6
Training loss: 2.4580741573287095
Validation loss: 2.6318754949292185

Epoch: 6| Step: 7
Training loss: 2.001354235877752
Validation loss: 2.583445528629401

Epoch: 6| Step: 8
Training loss: 1.667965748268303
Validation loss: 2.551163376542025

Epoch: 6| Step: 9
Training loss: 1.6669310439549991
Validation loss: 2.5266787692344645

Epoch: 6| Step: 10
Training loss: 3.2352168512552595
Validation loss: 2.507677702484667

Epoch: 6| Step: 11
Training loss: 2.43224609680835
Validation loss: 2.49587573958487

Epoch: 6| Step: 12
Training loss: 1.9301045696807062
Validation loss: 2.4965413487725336

Epoch: 6| Step: 13
Training loss: 2.4376899449604394
Validation loss: 2.4916836459454204

Epoch: 250| Step: 0
Training loss: 1.357732767413317
Validation loss: 2.4933172075069723

Epoch: 6| Step: 1
Training loss: 2.548782944552871
Validation loss: 2.4996615498645527

Epoch: 6| Step: 2
Training loss: 1.7938469624646503
Validation loss: 2.4860444128038965

Epoch: 6| Step: 3
Training loss: 2.295255128729055
Validation loss: 2.492059335631874

Epoch: 6| Step: 4
Training loss: 2.4351300186443097
Validation loss: 2.502407424820091

Epoch: 6| Step: 5
Training loss: 2.258539102711973
Validation loss: 2.5065332954980932

Epoch: 6| Step: 6
Training loss: 2.0896647439033953
Validation loss: 2.5342533363023536

Epoch: 6| Step: 7
Training loss: 2.1662214506439503
Validation loss: 2.567087192475743

Epoch: 6| Step: 8
Training loss: 2.323398682629833
Validation loss: 2.6164494323052576

Epoch: 6| Step: 9
Training loss: 2.4824969792803837
Validation loss: 2.634455310748264

Epoch: 6| Step: 10
Training loss: 1.7530838497452628
Validation loss: 2.6249805782750095

Epoch: 6| Step: 11
Training loss: 1.3966127990146013
Validation loss: 2.614866512409601

Epoch: 6| Step: 12
Training loss: 1.9691092753700563
Validation loss: 2.602102618811562

Epoch: 6| Step: 13
Training loss: 2.3816893885573944
Validation loss: 2.60505766821234

Epoch: 251| Step: 0
Training loss: 2.3150371345853777
Validation loss: 2.6116036284271305

Epoch: 6| Step: 1
Training loss: 1.855982337945725
Validation loss: 2.6065699334460306

Epoch: 6| Step: 2
Training loss: 2.2963615414478022
Validation loss: 2.61566140389945

Epoch: 6| Step: 3
Training loss: 1.756736052781711
Validation loss: 2.6107860108035976

Epoch: 6| Step: 4
Training loss: 2.2299267432663505
Validation loss: 2.626955772124402

Epoch: 6| Step: 5
Training loss: 1.8585342301486942
Validation loss: 2.6071834383753094

Epoch: 6| Step: 6
Training loss: 1.7580159387484389
Validation loss: 2.575839684745028

Epoch: 6| Step: 7
Training loss: 2.2460228419513864
Validation loss: 2.5789517859046516

Epoch: 6| Step: 8
Training loss: 2.633350351334964
Validation loss: 2.559505977547376

Epoch: 6| Step: 9
Training loss: 1.8850360577521796
Validation loss: 2.563384515956573

Epoch: 6| Step: 10
Training loss: 2.364476026433264
Validation loss: 2.569508002471686

Epoch: 6| Step: 11
Training loss: 2.2609143976324337
Validation loss: 2.561003472853747

Epoch: 6| Step: 12
Training loss: 2.0037129031892227
Validation loss: 2.5778719228738995

Epoch: 6| Step: 13
Training loss: 1.7983693419001767
Validation loss: 2.580868927333778

Epoch: 252| Step: 0
Training loss: 1.9730943250038881
Validation loss: 2.5642498833566187

Epoch: 6| Step: 1
Training loss: 2.512884697002082
Validation loss: 2.532289181803137

Epoch: 6| Step: 2
Training loss: 2.0556656862374822
Validation loss: 2.5708845249893018

Epoch: 6| Step: 3
Training loss: 1.9918489654726015
Validation loss: 2.5767923937675317

Epoch: 6| Step: 4
Training loss: 1.4571075828540816
Validation loss: 2.588533494860967

Epoch: 6| Step: 5
Training loss: 1.7652759038096693
Validation loss: 2.610748843049514

Epoch: 6| Step: 6
Training loss: 2.019612471166537
Validation loss: 2.633599832384993

Epoch: 6| Step: 7
Training loss: 2.8277474673015917
Validation loss: 2.6440386254629225

Epoch: 6| Step: 8
Training loss: 1.4427697986863126
Validation loss: 2.638652328015975

Epoch: 6| Step: 9
Training loss: 2.272818254903858
Validation loss: 2.624071713964015

Epoch: 6| Step: 10
Training loss: 2.1109979108387176
Validation loss: 2.6197983354264935

Epoch: 6| Step: 11
Training loss: 2.3229115119728636
Validation loss: 2.599325629344298

Epoch: 6| Step: 12
Training loss: 2.0625478565559385
Validation loss: 2.6007500068038483

Epoch: 6| Step: 13
Training loss: 1.7529976239229106
Validation loss: 2.6046554462769524

Epoch: 253| Step: 0
Training loss: 1.8350361011290486
Validation loss: 2.590400678112734

Epoch: 6| Step: 1
Training loss: 2.682642516859169
Validation loss: 2.5686006575313103

Epoch: 6| Step: 2
Training loss: 1.6143031543749313
Validation loss: 2.556383011644326

Epoch: 6| Step: 3
Training loss: 2.462346524330763
Validation loss: 2.586541112117193

Epoch: 6| Step: 4
Training loss: 2.0702632106455785
Validation loss: 2.6246830885185033

Epoch: 6| Step: 5
Training loss: 2.011442946999597
Validation loss: 2.6345947602343123

Epoch: 6| Step: 6
Training loss: 2.4340437814352986
Validation loss: 2.6456383360446933

Epoch: 6| Step: 7
Training loss: 2.2885521850436823
Validation loss: 2.6094069488457814

Epoch: 6| Step: 8
Training loss: 1.9280397121170103
Validation loss: 2.6078508688525126

Epoch: 6| Step: 9
Training loss: 1.8202143957854953
Validation loss: 2.5882078194711187

Epoch: 6| Step: 10
Training loss: 1.9377469551457212
Validation loss: 2.547492750018394

Epoch: 6| Step: 11
Training loss: 1.6271466967772918
Validation loss: 2.525898995581679

Epoch: 6| Step: 12
Training loss: 2.247052168990474
Validation loss: 2.5172732937867472

Epoch: 6| Step: 13
Training loss: 1.9317167168760596
Validation loss: 2.5124101809362123

Epoch: 254| Step: 0
Training loss: 1.663508578237941
Validation loss: 2.5216583184076535

Epoch: 6| Step: 1
Training loss: 1.728961641343951
Validation loss: 2.538420188062394

Epoch: 6| Step: 2
Training loss: 2.2237179437892465
Validation loss: 2.5424464754455247

Epoch: 6| Step: 3
Training loss: 2.0439282820748934
Validation loss: 2.5643236757578647

Epoch: 6| Step: 4
Training loss: 2.2625349347699997
Validation loss: 2.563300356667279

Epoch: 6| Step: 5
Training loss: 2.041652977826167
Validation loss: 2.5748819858087058

Epoch: 6| Step: 6
Training loss: 1.8846585416268968
Validation loss: 2.5946607407890676

Epoch: 6| Step: 7
Training loss: 2.791836425022869
Validation loss: 2.5702713148533576

Epoch: 6| Step: 8
Training loss: 2.7114299579727645
Validation loss: 2.6207986694938454

Epoch: 6| Step: 9
Training loss: 1.5877891967961377
Validation loss: 2.571473575379874

Epoch: 6| Step: 10
Training loss: 1.6675107090275851
Validation loss: 2.6084704782508012

Epoch: 6| Step: 11
Training loss: 2.1373482008900995
Validation loss: 2.6065060953976014

Epoch: 6| Step: 12
Training loss: 2.1904592932963576
Validation loss: 2.6065051730692645

Epoch: 6| Step: 13
Training loss: 2.249305087966873
Validation loss: 2.5935050205221097

Epoch: 255| Step: 0
Training loss: 2.5340833465550414
Validation loss: 2.5618517451127762

Epoch: 6| Step: 1
Training loss: 1.385670698390513
Validation loss: 2.525685886353058

Epoch: 6| Step: 2
Training loss: 1.8140700544648498
Validation loss: 2.533645442247501

Epoch: 6| Step: 3
Training loss: 2.5911403534542137
Validation loss: 2.535123428108748

Epoch: 6| Step: 4
Training loss: 1.6248016970020336
Validation loss: 2.5096257548066894

Epoch: 6| Step: 5
Training loss: 1.8313476328162492
Validation loss: 2.498552650468443

Epoch: 6| Step: 6
Training loss: 2.322862655855647
Validation loss: 2.483607655506579

Epoch: 6| Step: 7
Training loss: 2.09789605785603
Validation loss: 2.521870160797405

Epoch: 6| Step: 8
Training loss: 2.1588620936145055
Validation loss: 2.535303896232647

Epoch: 6| Step: 9
Training loss: 1.4417761351345026
Validation loss: 2.567050274342636

Epoch: 6| Step: 10
Training loss: 1.5936864204440482
Validation loss: 2.5868671355857975

Epoch: 6| Step: 11
Training loss: 1.4037433748437078
Validation loss: 2.595956882294084

Epoch: 6| Step: 12
Training loss: 2.913746343648835
Validation loss: 2.594020990210309

Epoch: 6| Step: 13
Training loss: 2.629179034881599
Validation loss: 2.5966818757972714

Epoch: 256| Step: 0
Training loss: 1.894363490277058
Validation loss: 2.5909240832242326

Epoch: 6| Step: 1
Training loss: 2.2863769400902627
Validation loss: 2.5975712888968583

Epoch: 6| Step: 2
Training loss: 2.210824485020114
Validation loss: 2.6099494560628798

Epoch: 6| Step: 3
Training loss: 1.5293894772610208
Validation loss: 2.6135709304559875

Epoch: 6| Step: 4
Training loss: 1.911427080971273
Validation loss: 2.62997715503745

Epoch: 6| Step: 5
Training loss: 2.093471223861632
Validation loss: 2.6090454761508526

Epoch: 6| Step: 6
Training loss: 1.8581447859197286
Validation loss: 2.570212937178509

Epoch: 6| Step: 7
Training loss: 2.1123015271011956
Validation loss: 2.558936875027234

Epoch: 6| Step: 8
Training loss: 1.922525125346798
Validation loss: 2.5531569318202494

Epoch: 6| Step: 9
Training loss: 1.8544151768255057
Validation loss: 2.516329869940234

Epoch: 6| Step: 10
Training loss: 2.499732098530282
Validation loss: 2.5012412645504205

Epoch: 6| Step: 11
Training loss: 1.9517952015957432
Validation loss: 2.514731206920593

Epoch: 6| Step: 12
Training loss: 2.889188667377173
Validation loss: 2.5218487630658695

Epoch: 6| Step: 13
Training loss: 2.2018692008729053
Validation loss: 2.518907636406195

Epoch: 257| Step: 0
Training loss: 1.7233798006139873
Validation loss: 2.562824166735771

Epoch: 6| Step: 1
Training loss: 2.3917223836365675
Validation loss: 2.5750022394361913

Epoch: 6| Step: 2
Training loss: 2.1111547802987287
Validation loss: 2.6565398114245977

Epoch: 6| Step: 3
Training loss: 2.2632806685120714
Validation loss: 2.7190601858867125

Epoch: 6| Step: 4
Training loss: 2.3417121674629744
Validation loss: 2.7102532892933544

Epoch: 6| Step: 5
Training loss: 2.101431576646188
Validation loss: 2.6437125279241194

Epoch: 6| Step: 6
Training loss: 2.236280575709018
Validation loss: 2.631893597539175

Epoch: 6| Step: 7
Training loss: 1.6497042159635305
Validation loss: 2.5614274579380245

Epoch: 6| Step: 8
Training loss: 2.3630630266305572
Validation loss: 2.521576060020177

Epoch: 6| Step: 9
Training loss: 1.8342007477901565
Validation loss: 2.4964599022431533

Epoch: 6| Step: 10
Training loss: 1.4686956192662937
Validation loss: 2.4922459195902382

Epoch: 6| Step: 11
Training loss: 2.5877983105586826
Validation loss: 2.4966215830230922

Epoch: 6| Step: 12
Training loss: 2.1313554307024587
Validation loss: 2.487558512422824

Epoch: 6| Step: 13
Training loss: 1.4415507257105984
Validation loss: 2.4946923100086127

Epoch: 258| Step: 0
Training loss: 2.621657013953163
Validation loss: 2.4922074304180373

Epoch: 6| Step: 1
Training loss: 1.7319932684822625
Validation loss: 2.4971756557959766

Epoch: 6| Step: 2
Training loss: 1.5479178718298647
Validation loss: 2.483548680724827

Epoch: 6| Step: 3
Training loss: 1.9572015562592757
Validation loss: 2.4966872041602004

Epoch: 6| Step: 4
Training loss: 1.7829952056101441
Validation loss: 2.52101868875404

Epoch: 6| Step: 5
Training loss: 1.9416555325212077
Validation loss: 2.5404079374247113

Epoch: 6| Step: 6
Training loss: 2.260615420649458
Validation loss: 2.5686628155171625

Epoch: 6| Step: 7
Training loss: 2.4629372842650996
Validation loss: 2.5808878111106317

Epoch: 6| Step: 8
Training loss: 2.1511459756334266
Validation loss: 2.6056587115673824

Epoch: 6| Step: 9
Training loss: 2.127901788732613
Validation loss: 2.6212458180309453

Epoch: 6| Step: 10
Training loss: 1.9632505475947857
Validation loss: 2.5730306365888356

Epoch: 6| Step: 11
Training loss: 2.5743124775472896
Validation loss: 2.5411138923599035

Epoch: 6| Step: 12
Training loss: 1.8403251002083265
Validation loss: 2.5193137693554872

Epoch: 6| Step: 13
Training loss: 2.2340113203808625
Validation loss: 2.528312084881541

Epoch: 259| Step: 0
Training loss: 2.1013185721151646
Validation loss: 2.5460443214690045

Epoch: 6| Step: 1
Training loss: 2.361628182832809
Validation loss: 2.547137880702761

Epoch: 6| Step: 2
Training loss: 2.345277822341064
Validation loss: 2.5667178169537213

Epoch: 6| Step: 3
Training loss: 2.08714516644897
Validation loss: 2.574293059307382

Epoch: 6| Step: 4
Training loss: 1.6893900424006734
Validation loss: 2.5952893633713563

Epoch: 6| Step: 5
Training loss: 1.984397347392005
Validation loss: 2.592579665668998

Epoch: 6| Step: 6
Training loss: 1.902436616420713
Validation loss: 2.584637548540263

Epoch: 6| Step: 7
Training loss: 1.6695279197677508
Validation loss: 2.5897725720259515

Epoch: 6| Step: 8
Training loss: 1.4054930451070757
Validation loss: 2.5681554522379555

Epoch: 6| Step: 9
Training loss: 2.7011399229287893
Validation loss: 2.5769988789105103

Epoch: 6| Step: 10
Training loss: 2.42133861877828
Validation loss: 2.5673316436810887

Epoch: 6| Step: 11
Training loss: 1.6815789507146468
Validation loss: 2.5688106706048957

Epoch: 6| Step: 12
Training loss: 2.2323408137144827
Validation loss: 2.561418987611643

Epoch: 6| Step: 13
Training loss: 2.053565353479344
Validation loss: 2.524493772919489

Epoch: 260| Step: 0
Training loss: 1.7957422417758946
Validation loss: 2.5394771061357466

Epoch: 6| Step: 1
Training loss: 1.8328824211240413
Validation loss: 2.5217279522901617

Epoch: 6| Step: 2
Training loss: 1.9178009270549925
Validation loss: 2.5350111188525575

Epoch: 6| Step: 3
Training loss: 2.968334449997752
Validation loss: 2.5282163926475434

Epoch: 6| Step: 4
Training loss: 1.1411049238167423
Validation loss: 2.5318116557844115

Epoch: 6| Step: 5
Training loss: 1.9989824686851243
Validation loss: 2.522585525222237

Epoch: 6| Step: 6
Training loss: 1.6657023342136597
Validation loss: 2.525412197271673

Epoch: 6| Step: 7
Training loss: 2.2105089183352216
Validation loss: 2.5576875824311913

Epoch: 6| Step: 8
Training loss: 1.869837010364208
Validation loss: 2.584297620605858

Epoch: 6| Step: 9
Training loss: 2.0150170407391084
Validation loss: 2.6283026158584484

Epoch: 6| Step: 10
Training loss: 1.7812078370575304
Validation loss: 2.6510540275560355

Epoch: 6| Step: 11
Training loss: 2.7275721038882144
Validation loss: 2.6293292675933135

Epoch: 6| Step: 12
Training loss: 1.7461145045606572
Validation loss: 2.619496100698356

Epoch: 6| Step: 13
Training loss: 2.140975589304797
Validation loss: 2.6321423108674056

Epoch: 261| Step: 0
Training loss: 1.3516153755208695
Validation loss: 2.629988562337858

Epoch: 6| Step: 1
Training loss: 1.8373808685921138
Validation loss: 2.608328832271052

Epoch: 6| Step: 2
Training loss: 2.1875483916243414
Validation loss: 2.597871500911038

Epoch: 6| Step: 3
Training loss: 1.5728201510226045
Validation loss: 2.5531903000585343

Epoch: 6| Step: 4
Training loss: 2.827442234302563
Validation loss: 2.5560457078028755

Epoch: 6| Step: 5
Training loss: 1.7199053955674855
Validation loss: 2.5461819257642495

Epoch: 6| Step: 6
Training loss: 2.049487594205857
Validation loss: 2.546349687755066

Epoch: 6| Step: 7
Training loss: 2.3350480341412307
Validation loss: 2.5639327316099116

Epoch: 6| Step: 8
Training loss: 1.3978677793198802
Validation loss: 2.5636717358116923

Epoch: 6| Step: 9
Training loss: 1.88453418318711
Validation loss: 2.585912929083961

Epoch: 6| Step: 10
Training loss: 2.8195373653473443
Validation loss: 2.567699630959848

Epoch: 6| Step: 11
Training loss: 1.9825512773345213
Validation loss: 2.616484559964953

Epoch: 6| Step: 12
Training loss: 2.2341084354623004
Validation loss: 2.599696027275022

Epoch: 6| Step: 13
Training loss: 1.9158065012938494
Validation loss: 2.602969486984416

Epoch: 262| Step: 0
Training loss: 2.1542264869790615
Validation loss: 2.586949406890368

Epoch: 6| Step: 1
Training loss: 1.7004700712033927
Validation loss: 2.5808715986306185

Epoch: 6| Step: 2
Training loss: 1.9756333651391211
Validation loss: 2.561266765176574

Epoch: 6| Step: 3
Training loss: 1.434823820749846
Validation loss: 2.5283735752696086

Epoch: 6| Step: 4
Training loss: 2.231884188241881
Validation loss: 2.5215062170759537

Epoch: 6| Step: 5
Training loss: 2.387161838090445
Validation loss: 2.5343368922518876

Epoch: 6| Step: 6
Training loss: 2.534997591247016
Validation loss: 2.5366830171449966

Epoch: 6| Step: 7
Training loss: 1.7536890112018875
Validation loss: 2.5278501872869077

Epoch: 6| Step: 8
Training loss: 2.292169642882684
Validation loss: 2.5284179888663854

Epoch: 6| Step: 9
Training loss: 2.4943772026784448
Validation loss: 2.538571056831877

Epoch: 6| Step: 10
Training loss: 1.8976315643978994
Validation loss: 2.5634210838490716

Epoch: 6| Step: 11
Training loss: 1.6701471544864424
Validation loss: 2.6205007959723834

Epoch: 6| Step: 12
Training loss: 1.8268831387683406
Validation loss: 2.653868591322896

Epoch: 6| Step: 13
Training loss: 2.1356865937123124
Validation loss: 2.675553123235213

Epoch: 263| Step: 0
Training loss: 2.0562513078957894
Validation loss: 2.659210126452554

Epoch: 6| Step: 1
Training loss: 2.0435142591112894
Validation loss: 2.6939412337513153

Epoch: 6| Step: 2
Training loss: 1.7346791868400633
Validation loss: 2.6420735706661733

Epoch: 6| Step: 3
Training loss: 1.6341644238980686
Validation loss: 2.5886648955969886

Epoch: 6| Step: 4
Training loss: 1.6005081800247607
Validation loss: 2.576964916899828

Epoch: 6| Step: 5
Training loss: 2.1916510297364904
Validation loss: 2.526867687545941

Epoch: 6| Step: 6
Training loss: 2.8835969183363623
Validation loss: 2.552147274124598

Epoch: 6| Step: 7
Training loss: 1.9304989487043205
Validation loss: 2.551306210486932

Epoch: 6| Step: 8
Training loss: 1.9983482692861338
Validation loss: 2.52957867362177

Epoch: 6| Step: 9
Training loss: 2.2540542315954575
Validation loss: 2.541461488123643

Epoch: 6| Step: 10
Training loss: 1.8625723651934374
Validation loss: 2.5410962220295863

Epoch: 6| Step: 11
Training loss: 2.3928260394517036
Validation loss: 2.552232019154404

Epoch: 6| Step: 12
Training loss: 1.9237069183740783
Validation loss: 2.5358008930221874

Epoch: 6| Step: 13
Training loss: 1.928508197413917
Validation loss: 2.5719112382871945

Epoch: 264| Step: 0
Training loss: 1.535506579778468
Validation loss: 2.578088717735149

Epoch: 6| Step: 1
Training loss: 1.5597184408852922
Validation loss: 2.5772341797907083

Epoch: 6| Step: 2
Training loss: 1.4057277557414962
Validation loss: 2.5862813453993416

Epoch: 6| Step: 3
Training loss: 1.6959512799210852
Validation loss: 2.602734428740494

Epoch: 6| Step: 4
Training loss: 1.945547679488437
Validation loss: 2.570909023149612

Epoch: 6| Step: 5
Training loss: 2.112862423838881
Validation loss: 2.5841574328603145

Epoch: 6| Step: 6
Training loss: 1.6167074034497215
Validation loss: 2.5886366511417394

Epoch: 6| Step: 7
Training loss: 2.463163598200295
Validation loss: 2.5761055329259017

Epoch: 6| Step: 8
Training loss: 2.0286522319596485
Validation loss: 2.597004774808748

Epoch: 6| Step: 9
Training loss: 2.355119011821902
Validation loss: 2.5844787601427934

Epoch: 6| Step: 10
Training loss: 1.9931228536245584
Validation loss: 2.590593738620377

Epoch: 6| Step: 11
Training loss: 1.8689386942336967
Validation loss: 2.6230573580587557

Epoch: 6| Step: 12
Training loss: 2.6067765140884394
Validation loss: 2.592980665221867

Epoch: 6| Step: 13
Training loss: 2.300602593472158
Validation loss: 2.5747983913754102

Epoch: 265| Step: 0
Training loss: 1.8542052775731184
Validation loss: 2.5580081648140793

Epoch: 6| Step: 1
Training loss: 1.9750433953261965
Validation loss: 2.523686092638855

Epoch: 6| Step: 2
Training loss: 1.5701660543449418
Validation loss: 2.5044026153110694

Epoch: 6| Step: 3
Training loss: 2.7825622891619886
Validation loss: 2.492639865298915

Epoch: 6| Step: 4
Training loss: 2.104635381584303
Validation loss: 2.527089762122606

Epoch: 6| Step: 5
Training loss: 2.217006159242601
Validation loss: 2.5152861088484237

Epoch: 6| Step: 6
Training loss: 1.8541953766846748
Validation loss: 2.5270985755135773

Epoch: 6| Step: 7
Training loss: 1.9575304319858935
Validation loss: 2.5929538240201406

Epoch: 6| Step: 8
Training loss: 2.257869204960776
Validation loss: 2.585972258458101

Epoch: 6| Step: 9
Training loss: 2.0020826939777963
Validation loss: 2.629630561041431

Epoch: 6| Step: 10
Training loss: 1.4769728963194966
Validation loss: 2.6226757295423164

Epoch: 6| Step: 11
Training loss: 2.067509895494759
Validation loss: 2.6649262938049456

Epoch: 6| Step: 12
Training loss: 2.134385531442779
Validation loss: 2.6342035801187844

Epoch: 6| Step: 13
Training loss: 1.6515305414058097
Validation loss: 2.569762892936326

Epoch: 266| Step: 0
Training loss: 1.583778828973482
Validation loss: 2.559294843835247

Epoch: 6| Step: 1
Training loss: 1.6481523312330242
Validation loss: 2.5614399927285993

Epoch: 6| Step: 2
Training loss: 1.5772393640343088
Validation loss: 2.534648058661287

Epoch: 6| Step: 3
Training loss: 2.1639631227887297
Validation loss: 2.5292201360699225

Epoch: 6| Step: 4
Training loss: 2.0515074978941743
Validation loss: 2.5361194318913642

Epoch: 6| Step: 5
Training loss: 2.9178494552881897
Validation loss: 2.534077858272453

Epoch: 6| Step: 6
Training loss: 1.8953050429283176
Validation loss: 2.561185235885984

Epoch: 6| Step: 7
Training loss: 2.0677038492174957
Validation loss: 2.5914463092635303

Epoch: 6| Step: 8
Training loss: 2.147940505370625
Validation loss: 2.587185146691498

Epoch: 6| Step: 9
Training loss: 2.5230882715968406
Validation loss: 2.5897061333934026

Epoch: 6| Step: 10
Training loss: 2.0069193356302497
Validation loss: 2.6033496388825488

Epoch: 6| Step: 11
Training loss: 2.282659434905733
Validation loss: 2.5813647634934918

Epoch: 6| Step: 12
Training loss: 1.8224213136031147
Validation loss: 2.5295069151949283

Epoch: 6| Step: 13
Training loss: 1.5998626620239178
Validation loss: 2.5247391059223188

Epoch: 267| Step: 0
Training loss: 2.2635609662958998
Validation loss: 2.5484092475390017

Epoch: 6| Step: 1
Training loss: 1.8218800094823522
Validation loss: 2.532629524099515

Epoch: 6| Step: 2
Training loss: 1.9239173519917434
Validation loss: 2.527157225842792

Epoch: 6| Step: 3
Training loss: 1.8315222710274122
Validation loss: 2.535033314628317

Epoch: 6| Step: 4
Training loss: 2.084965968963484
Validation loss: 2.5506742103476405

Epoch: 6| Step: 5
Training loss: 1.807601096041964
Validation loss: 2.5542987057117843

Epoch: 6| Step: 6
Training loss: 2.4016805089921824
Validation loss: 2.5709227327437607

Epoch: 6| Step: 7
Training loss: 1.8285759915673852
Validation loss: 2.575723188195373

Epoch: 6| Step: 8
Training loss: 1.8440421568009122
Validation loss: 2.5774615965904317

Epoch: 6| Step: 9
Training loss: 1.351150096972557
Validation loss: 2.578500616281024

Epoch: 6| Step: 10
Training loss: 2.7052284832422955
Validation loss: 2.5988375700043105

Epoch: 6| Step: 11
Training loss: 1.5478752832370102
Validation loss: 2.584017760353545

Epoch: 6| Step: 12
Training loss: 1.9289885579467425
Validation loss: 2.6039883260059953

Epoch: 6| Step: 13
Training loss: 2.528795347236135
Validation loss: 2.5976057846024116

Epoch: 268| Step: 0
Training loss: 2.6966476892747413
Validation loss: 2.6069327706498044

Epoch: 6| Step: 1
Training loss: 1.6027137154408173
Validation loss: 2.5981548089030415

Epoch: 6| Step: 2
Training loss: 2.1931724027053323
Validation loss: 2.5917805314477005

Epoch: 6| Step: 3
Training loss: 1.6896686747204084
Validation loss: 2.590335513492201

Epoch: 6| Step: 4
Training loss: 1.9795438574364561
Validation loss: 2.57697228758081

Epoch: 6| Step: 5
Training loss: 1.6264419760194435
Validation loss: 2.5659037523393042

Epoch: 6| Step: 6
Training loss: 1.6442008875929963
Validation loss: 2.5599340136537254

Epoch: 6| Step: 7
Training loss: 2.328791887661149
Validation loss: 2.548509740127173

Epoch: 6| Step: 8
Training loss: 2.0714858850527214
Validation loss: 2.560757114092527

Epoch: 6| Step: 9
Training loss: 1.8494330929433613
Validation loss: 2.542728504526491

Epoch: 6| Step: 10
Training loss: 1.6290762467264432
Validation loss: 2.5438640559539656

Epoch: 6| Step: 11
Training loss: 2.337629541081711
Validation loss: 2.544019803197026

Epoch: 6| Step: 12
Training loss: 1.919566683350973
Validation loss: 2.5494018220842656

Epoch: 6| Step: 13
Training loss: 2.2537839648098883
Validation loss: 2.554680516100251

Epoch: 269| Step: 0
Training loss: 2.306781192795612
Validation loss: 2.60654512254549

Epoch: 6| Step: 1
Training loss: 2.0172819675395055
Validation loss: 2.6309951562163887

Epoch: 6| Step: 2
Training loss: 1.9580697294800258
Validation loss: 2.6748998076549775

Epoch: 6| Step: 3
Training loss: 2.331486061560099
Validation loss: 2.6404393900208074

Epoch: 6| Step: 4
Training loss: 2.027253430069009
Validation loss: 2.607562930212405

Epoch: 6| Step: 5
Training loss: 1.4578845105473033
Validation loss: 2.5558811397287515

Epoch: 6| Step: 6
Training loss: 1.6019130416204928
Validation loss: 2.5001339240760356

Epoch: 6| Step: 7
Training loss: 1.8737168053758944
Validation loss: 2.4913528942265413

Epoch: 6| Step: 8
Training loss: 1.7638048225387946
Validation loss: 2.4886961969741788

Epoch: 6| Step: 9
Training loss: 2.0378992262942646
Validation loss: 2.4924597357300753

Epoch: 6| Step: 10
Training loss: 2.383817267026406
Validation loss: 2.514184559130535

Epoch: 6| Step: 11
Training loss: 2.1277508601430184
Validation loss: 2.516625420651323

Epoch: 6| Step: 12
Training loss: 2.3630848196064695
Validation loss: 2.5052393212784443

Epoch: 6| Step: 13
Training loss: 2.097475523595572
Validation loss: 2.561320599460605

Epoch: 270| Step: 0
Training loss: 2.081091921189965
Validation loss: 2.5917390895017873

Epoch: 6| Step: 1
Training loss: 1.7397199870208269
Validation loss: 2.6095381055706492

Epoch: 6| Step: 2
Training loss: 1.2326494541819835
Validation loss: 2.6771696104008047

Epoch: 6| Step: 3
Training loss: 1.9920062412754012
Validation loss: 2.7020024521094435

Epoch: 6| Step: 4
Training loss: 2.448956683921069
Validation loss: 2.704146704773974

Epoch: 6| Step: 5
Training loss: 2.1409388402606964
Validation loss: 2.639812096064198

Epoch: 6| Step: 6
Training loss: 1.300222053270038
Validation loss: 2.63871848297934

Epoch: 6| Step: 7
Training loss: 2.39370529093212
Validation loss: 2.5679378187736264

Epoch: 6| Step: 8
Training loss: 1.5934377626223215
Validation loss: 2.5143787148024903

Epoch: 6| Step: 9
Training loss: 2.162927433174021
Validation loss: 2.507533896747359

Epoch: 6| Step: 10
Training loss: 1.796096633172096
Validation loss: 2.503361452755757

Epoch: 6| Step: 11
Training loss: 1.6492877954787222
Validation loss: 2.492134213251592

Epoch: 6| Step: 12
Training loss: 2.614717599124033
Validation loss: 2.4932903850990744

Epoch: 6| Step: 13
Training loss: 2.036171218912361
Validation loss: 2.4902420821725095

Epoch: 271| Step: 0
Training loss: 2.0807957517229276
Validation loss: 2.533327537350131

Epoch: 6| Step: 1
Training loss: 1.7024054450890933
Validation loss: 2.548761102372516

Epoch: 6| Step: 2
Training loss: 2.4790719492366873
Validation loss: 2.5682303702055638

Epoch: 6| Step: 3
Training loss: 1.6180332939060922
Validation loss: 2.6300826593470723

Epoch: 6| Step: 4
Training loss: 2.303908808135342
Validation loss: 2.6438012517195295

Epoch: 6| Step: 5
Training loss: 1.9019023532009864
Validation loss: 2.705432267309772

Epoch: 6| Step: 6
Training loss: 1.9537855328375209
Validation loss: 2.713369709406839

Epoch: 6| Step: 7
Training loss: 2.2459775148253
Validation loss: 2.6610981099610393

Epoch: 6| Step: 8
Training loss: 1.710668952106863
Validation loss: 2.649962879616685

Epoch: 6| Step: 9
Training loss: 2.3985651336408154
Validation loss: 2.587815631283673

Epoch: 6| Step: 10
Training loss: 1.6681962226650204
Validation loss: 2.563119611804988

Epoch: 6| Step: 11
Training loss: 1.8321279406703854
Validation loss: 2.537158537817353

Epoch: 6| Step: 12
Training loss: 1.6001191869689282
Validation loss: 2.501025927164572

Epoch: 6| Step: 13
Training loss: 1.6758320407239626
Validation loss: 2.5150306347017044

Epoch: 272| Step: 0
Training loss: 2.4417961602705023
Validation loss: 2.494860484236595

Epoch: 6| Step: 1
Training loss: 2.290396135874429
Validation loss: 2.5033580003260476

Epoch: 6| Step: 2
Training loss: 1.8566048125688221
Validation loss: 2.5119473287573877

Epoch: 6| Step: 3
Training loss: 2.683592683883522
Validation loss: 2.5290872572907883

Epoch: 6| Step: 4
Training loss: 1.6579155374877694
Validation loss: 2.5260711406023852

Epoch: 6| Step: 5
Training loss: 1.3970876391069817
Validation loss: 2.5450200227600552

Epoch: 6| Step: 6
Training loss: 1.6166475288333293
Validation loss: 2.572946082396187

Epoch: 6| Step: 7
Training loss: 1.8070223678192454
Validation loss: 2.590935677803149

Epoch: 6| Step: 8
Training loss: 1.5672820347031036
Validation loss: 2.5911708862524856

Epoch: 6| Step: 9
Training loss: 1.829287623908082
Validation loss: 2.630146975163539

Epoch: 6| Step: 10
Training loss: 1.7733238956850406
Validation loss: 2.6085058123768943

Epoch: 6| Step: 11
Training loss: 1.6853478447907049
Validation loss: 2.62332791858229

Epoch: 6| Step: 12
Training loss: 2.522685880891615
Validation loss: 2.566065107071637

Epoch: 6| Step: 13
Training loss: 1.548238596377269
Validation loss: 2.5858249082765106

Epoch: 273| Step: 0
Training loss: 1.861771713828914
Validation loss: 2.5628030799333192

Epoch: 6| Step: 1
Training loss: 1.9505212136146437
Validation loss: 2.5540850178755754

Epoch: 6| Step: 2
Training loss: 1.8235515542468477
Validation loss: 2.546635107432375

Epoch: 6| Step: 3
Training loss: 2.2827591803013836
Validation loss: 2.5214318965116505

Epoch: 6| Step: 4
Training loss: 2.481718646551883
Validation loss: 2.515737542898775

Epoch: 6| Step: 5
Training loss: 1.861980824147445
Validation loss: 2.5477188522226113

Epoch: 6| Step: 6
Training loss: 1.7063825758406133
Validation loss: 2.5520655702764254

Epoch: 6| Step: 7
Training loss: 1.8529965283793144
Validation loss: 2.588271180008661

Epoch: 6| Step: 8
Training loss: 1.3331093550352893
Validation loss: 2.571653037769581

Epoch: 6| Step: 9
Training loss: 2.2130423188298143
Validation loss: 2.554702292116603

Epoch: 6| Step: 10
Training loss: 1.7622066930113627
Validation loss: 2.517544797721633

Epoch: 6| Step: 11
Training loss: 2.2371397186560733
Validation loss: 2.5051014666587905

Epoch: 6| Step: 12
Training loss: 2.087327701059445
Validation loss: 2.516541039781829

Epoch: 6| Step: 13
Training loss: 1.7262702798170084
Validation loss: 2.518732004282789

Epoch: 274| Step: 0
Training loss: 1.6571333347009378
Validation loss: 2.523586540426802

Epoch: 6| Step: 1
Training loss: 2.3458417586270723
Validation loss: 2.5326891759853036

Epoch: 6| Step: 2
Training loss: 2.017389752142193
Validation loss: 2.553009905608012

Epoch: 6| Step: 3
Training loss: 2.2628574700135107
Validation loss: 2.5352557475780313

Epoch: 6| Step: 4
Training loss: 1.7845564821752575
Validation loss: 2.5715124851996496

Epoch: 6| Step: 5
Training loss: 1.923284556477204
Validation loss: 2.5582230704669695

Epoch: 6| Step: 6
Training loss: 2.110388166329941
Validation loss: 2.5476147878065434

Epoch: 6| Step: 7
Training loss: 2.014211824621378
Validation loss: 2.5758810585345517

Epoch: 6| Step: 8
Training loss: 1.2980638593032643
Validation loss: 2.5692014138240173

Epoch: 6| Step: 9
Training loss: 1.4722382536601069
Validation loss: 2.584110379000194

Epoch: 6| Step: 10
Training loss: 1.8767336142452105
Validation loss: 2.58984588270066

Epoch: 6| Step: 11
Training loss: 2.3439745986134986
Validation loss: 2.5571320296817137

Epoch: 6| Step: 12
Training loss: 2.2286222868660066
Validation loss: 2.5838859695069587

Epoch: 6| Step: 13
Training loss: 1.942494507613696
Validation loss: 2.619805615933381

Epoch: 275| Step: 0
Training loss: 2.1992932268070233
Validation loss: 2.621986445595832

Epoch: 6| Step: 1
Training loss: 1.6020675235095534
Validation loss: 2.611985459831976

Epoch: 6| Step: 2
Training loss: 2.6392503580069833
Validation loss: 2.564825382993827

Epoch: 6| Step: 3
Training loss: 2.0765335758396386
Validation loss: 2.5692098275600235

Epoch: 6| Step: 4
Training loss: 1.894760275299884
Validation loss: 2.544618945220546

Epoch: 6| Step: 5
Training loss: 1.8015776422663252
Validation loss: 2.5387766046224116

Epoch: 6| Step: 6
Training loss: 1.3854522509295342
Validation loss: 2.529651718090789

Epoch: 6| Step: 7
Training loss: 1.5464903227943925
Validation loss: 2.531090766701988

Epoch: 6| Step: 8
Training loss: 2.185848811806565
Validation loss: 2.53554396757724

Epoch: 6| Step: 9
Training loss: 2.2087295344753333
Validation loss: 2.556341586535847

Epoch: 6| Step: 10
Training loss: 1.590888952152555
Validation loss: 2.5634544114866378

Epoch: 6| Step: 11
Training loss: 1.9132431456391858
Validation loss: 2.559342152094008

Epoch: 6| Step: 12
Training loss: 1.2644398167392703
Validation loss: 2.5790592080831773

Epoch: 6| Step: 13
Training loss: 2.29557929828786
Validation loss: 2.575887460459765

Epoch: 276| Step: 0
Training loss: 2.01646618700421
Validation loss: 2.59090138469201

Epoch: 6| Step: 1
Training loss: 1.460945578160111
Validation loss: 2.593664405360272

Epoch: 6| Step: 2
Training loss: 2.0691303836971633
Validation loss: 2.6459874886687675

Epoch: 6| Step: 3
Training loss: 2.2294115544031454
Validation loss: 2.6767305272783166

Epoch: 6| Step: 4
Training loss: 1.9942585072435768
Validation loss: 2.696630345545146

Epoch: 6| Step: 5
Training loss: 1.960068589976098
Validation loss: 2.6971050106902004

Epoch: 6| Step: 6
Training loss: 1.835673081856393
Validation loss: 2.5995504256514157

Epoch: 6| Step: 7
Training loss: 1.8229507515763363
Validation loss: 2.5494410843516584

Epoch: 6| Step: 8
Training loss: 1.862613710350156
Validation loss: 2.5183305111794994

Epoch: 6| Step: 9
Training loss: 1.849460229227936
Validation loss: 2.47939945912459

Epoch: 6| Step: 10
Training loss: 2.07510558169974
Validation loss: 2.495560948872855

Epoch: 6| Step: 11
Training loss: 2.1918545568691408
Validation loss: 2.5047495389486683

Epoch: 6| Step: 12
Training loss: 1.8401396365669698
Validation loss: 2.4909248461928555

Epoch: 6| Step: 13
Training loss: 2.363009552273228
Validation loss: 2.4631894097033107

Epoch: 277| Step: 0
Training loss: 2.974287149631305
Validation loss: 2.466614068819418

Epoch: 6| Step: 1
Training loss: 1.7626696132995014
Validation loss: 2.5150547368468006

Epoch: 6| Step: 2
Training loss: 1.6628723186536396
Validation loss: 2.6074966477091848

Epoch: 6| Step: 3
Training loss: 1.5540056890140515
Validation loss: 2.6664825962036836

Epoch: 6| Step: 4
Training loss: 2.1325211657852243
Validation loss: 2.7262374553015754

Epoch: 6| Step: 5
Training loss: 2.4132590330218235
Validation loss: 2.7145371371417846

Epoch: 6| Step: 6
Training loss: 1.1986027231926093
Validation loss: 2.6926626106871376

Epoch: 6| Step: 7
Training loss: 1.4256339219151548
Validation loss: 2.575505044783955

Epoch: 6| Step: 8
Training loss: 2.127735508973961
Validation loss: 2.5380552905743388

Epoch: 6| Step: 9
Training loss: 1.7997636215981059
Validation loss: 2.5162929966969334

Epoch: 6| Step: 10
Training loss: 2.1344326698476666
Validation loss: 2.5292967807372086

Epoch: 6| Step: 11
Training loss: 1.9074248148848427
Validation loss: 2.5329633651756795

Epoch: 6| Step: 12
Training loss: 1.751735916196495
Validation loss: 2.5283800189042194

Epoch: 6| Step: 13
Training loss: 2.1959972467596307
Validation loss: 2.545472193657809

Epoch: 278| Step: 0
Training loss: 2.099442671434409
Validation loss: 2.5329815628700016

Epoch: 6| Step: 1
Training loss: 2.2341280714052445
Validation loss: 2.5533479528614493

Epoch: 6| Step: 2
Training loss: 2.3115690264700604
Validation loss: 2.534375462843621

Epoch: 6| Step: 3
Training loss: 1.9950825318973726
Validation loss: 2.5396478535751896

Epoch: 6| Step: 4
Training loss: 1.8937255404564053
Validation loss: 2.5676268950902403

Epoch: 6| Step: 5
Training loss: 2.0538531447807866
Validation loss: 2.563019599027956

Epoch: 6| Step: 6
Training loss: 1.5902208635491308
Validation loss: 2.5623181751531194

Epoch: 6| Step: 7
Training loss: 1.3768001390245401
Validation loss: 2.5448612763144904

Epoch: 6| Step: 8
Training loss: 1.1850293206559106
Validation loss: 2.564130853380746

Epoch: 6| Step: 9
Training loss: 2.0356512657487844
Validation loss: 2.5309134522552523

Epoch: 6| Step: 10
Training loss: 1.6891743865524407
Validation loss: 2.530200143996882

Epoch: 6| Step: 11
Training loss: 1.8931541235601972
Validation loss: 2.568000155277089

Epoch: 6| Step: 12
Training loss: 2.4173319876355515
Validation loss: 2.518887783159764

Epoch: 6| Step: 13
Training loss: 2.1476897446957826
Validation loss: 2.4998967626236577

Epoch: 279| Step: 0
Training loss: 1.7614651178116159
Validation loss: 2.4800838782625836

Epoch: 6| Step: 1
Training loss: 1.9872399621869077
Validation loss: 2.4878949674461714

Epoch: 6| Step: 2
Training loss: 1.8441601959657408
Validation loss: 2.49979100943272

Epoch: 6| Step: 3
Training loss: 1.8264659950731212
Validation loss: 2.491337582429497

Epoch: 6| Step: 4
Training loss: 2.3065186548245626
Validation loss: 2.5125234688189417

Epoch: 6| Step: 5
Training loss: 1.7193481098209145
Validation loss: 2.569094167208778

Epoch: 6| Step: 6
Training loss: 1.3929928968457959
Validation loss: 2.5776969323095873

Epoch: 6| Step: 7
Training loss: 2.1772653117318748
Validation loss: 2.585814935059599

Epoch: 6| Step: 8
Training loss: 1.7226444858140681
Validation loss: 2.6049138154473575

Epoch: 6| Step: 9
Training loss: 1.967323149472573
Validation loss: 2.576851593880912

Epoch: 6| Step: 10
Training loss: 2.2217877506342516
Validation loss: 2.5944531418352565

Epoch: 6| Step: 11
Training loss: 2.061220986258658
Validation loss: 2.547769814472958

Epoch: 6| Step: 12
Training loss: 1.7611827500163286
Validation loss: 2.5751671054777088

Epoch: 6| Step: 13
Training loss: 1.7383484559515339
Validation loss: 2.5589942832168378

Epoch: 280| Step: 0
Training loss: 1.3944806856450267
Validation loss: 2.589443338854932

Epoch: 6| Step: 1
Training loss: 1.7841172815526216
Validation loss: 2.558287732797932

Epoch: 6| Step: 2
Training loss: 1.9783046116574483
Validation loss: 2.5700482171726913

Epoch: 6| Step: 3
Training loss: 1.9626758666721276
Validation loss: 2.564896455413611

Epoch: 6| Step: 4
Training loss: 2.2786184312898503
Validation loss: 2.564464172974782

Epoch: 6| Step: 5
Training loss: 1.2804877176794274
Validation loss: 2.5586275908971885

Epoch: 6| Step: 6
Training loss: 1.8818040101728546
Validation loss: 2.565185349369014

Epoch: 6| Step: 7
Training loss: 2.00340243841851
Validation loss: 2.6154823631975943

Epoch: 6| Step: 8
Training loss: 1.7685453855963964
Validation loss: 2.608517656323694

Epoch: 6| Step: 9
Training loss: 1.7838133721432192
Validation loss: 2.567071929949242

Epoch: 6| Step: 10
Training loss: 1.8705950173862953
Validation loss: 2.5867198210183764

Epoch: 6| Step: 11
Training loss: 2.0359973304371297
Validation loss: 2.5967742646376633

Epoch: 6| Step: 12
Training loss: 2.163880378413682
Validation loss: 2.595538484065516

Epoch: 6| Step: 13
Training loss: 2.02852847372357
Validation loss: 2.5953498410473137

Epoch: 281| Step: 0
Training loss: 1.5201873539602766
Validation loss: 2.6182668633242265

Epoch: 6| Step: 1
Training loss: 2.4724055399656293
Validation loss: 2.5841061271957892

Epoch: 6| Step: 2
Training loss: 2.006421627891518
Validation loss: 2.5187711451347288

Epoch: 6| Step: 3
Training loss: 1.8243470238752109
Validation loss: 2.4989812364651063

Epoch: 6| Step: 4
Training loss: 2.062408676437582
Validation loss: 2.505220160717449

Epoch: 6| Step: 5
Training loss: 2.2598116250990077
Validation loss: 2.502259616110332

Epoch: 6| Step: 6
Training loss: 1.8431938755105841
Validation loss: 2.508341098743809

Epoch: 6| Step: 7
Training loss: 1.9996102072432154
Validation loss: 2.481716420930444

Epoch: 6| Step: 8
Training loss: 2.233855714009565
Validation loss: 2.466684563889743

Epoch: 6| Step: 9
Training loss: 2.0338331963064102
Validation loss: 2.4545800658021713

Epoch: 6| Step: 10
Training loss: 1.6893539840627327
Validation loss: 2.473771537287353

Epoch: 6| Step: 11
Training loss: 1.5405167423615018
Validation loss: 2.509460161473439

Epoch: 6| Step: 12
Training loss: 2.075755324253852
Validation loss: 2.5423759554720466

Epoch: 6| Step: 13
Training loss: 1.7429441852967331
Validation loss: 2.615308111479366

Epoch: 282| Step: 0
Training loss: 2.482519836653855
Validation loss: 2.6131595798027085

Epoch: 6| Step: 1
Training loss: 1.5860397230756322
Validation loss: 2.5583392688877034

Epoch: 6| Step: 2
Training loss: 1.7113789028217676
Validation loss: 2.525939315347846

Epoch: 6| Step: 3
Training loss: 1.3986701132535213
Validation loss: 2.5300288767416883

Epoch: 6| Step: 4
Training loss: 2.1135628278214105
Validation loss: 2.5183963713549913

Epoch: 6| Step: 5
Training loss: 1.748460773930148
Validation loss: 2.5589580092170716

Epoch: 6| Step: 6
Training loss: 1.316018474753542
Validation loss: 2.556810234006095

Epoch: 6| Step: 7
Training loss: 1.6207284538770415
Validation loss: 2.55333663113118

Epoch: 6| Step: 8
Training loss: 2.429158536484092
Validation loss: 2.600508712250322

Epoch: 6| Step: 9
Training loss: 2.497370099573871
Validation loss: 2.6040621444071386

Epoch: 6| Step: 10
Training loss: 2.370831696610872
Validation loss: 2.608285124295653

Epoch: 6| Step: 11
Training loss: 1.449553335386921
Validation loss: 2.636939190727246

Epoch: 6| Step: 12
Training loss: 1.6869312316861742
Validation loss: 2.637067335657578

Epoch: 6| Step: 13
Training loss: 2.419078566046091
Validation loss: 2.6678236944738196

Epoch: 283| Step: 0
Training loss: 1.3984563815584385
Validation loss: 2.7099364500113614

Epoch: 6| Step: 1
Training loss: 1.5178764374091664
Validation loss: 2.6930630940259723

Epoch: 6| Step: 2
Training loss: 2.872983474083761
Validation loss: 2.7406159522945

Epoch: 6| Step: 3
Training loss: 2.2858095979402764
Validation loss: 2.7414782585948454

Epoch: 6| Step: 4
Training loss: 1.8320181059213319
Validation loss: 2.709977169503752

Epoch: 6| Step: 5
Training loss: 1.7214394075542174
Validation loss: 2.6371121638166555

Epoch: 6| Step: 6
Training loss: 1.498961725114065
Validation loss: 2.6215497078444967

Epoch: 6| Step: 7
Training loss: 2.184699964022587
Validation loss: 2.5997427226200513

Epoch: 6| Step: 8
Training loss: 2.118406388318378
Validation loss: 2.5525807317656763

Epoch: 6| Step: 9
Training loss: 1.7141106848259813
Validation loss: 2.519378452448497

Epoch: 6| Step: 10
Training loss: 1.755108325799444
Validation loss: 2.485035878375943

Epoch: 6| Step: 11
Training loss: 1.9160220955866785
Validation loss: 2.4583436324555774

Epoch: 6| Step: 12
Training loss: 1.374914340038625
Validation loss: 2.4639434540574756

Epoch: 6| Step: 13
Training loss: 2.077870518297063
Validation loss: 2.4559701509380742

Epoch: 284| Step: 0
Training loss: 2.4466092994609876
Validation loss: 2.4697722238080777

Epoch: 6| Step: 1
Training loss: 1.781835091852123
Validation loss: 2.448777089510296

Epoch: 6| Step: 2
Training loss: 1.032034257859865
Validation loss: 2.4853502194863757

Epoch: 6| Step: 3
Training loss: 1.8958451895989332
Validation loss: 2.492659959484455

Epoch: 6| Step: 4
Training loss: 1.8768440715059278
Validation loss: 2.4951268543670775

Epoch: 6| Step: 5
Training loss: 1.366281787052312
Validation loss: 2.5227504696483765

Epoch: 6| Step: 6
Training loss: 2.0212153306392864
Validation loss: 2.533075922093622

Epoch: 6| Step: 7
Training loss: 2.282638545265658
Validation loss: 2.574907564769488

Epoch: 6| Step: 8
Training loss: 2.0618199469971787
Validation loss: 2.5715423934397093

Epoch: 6| Step: 9
Training loss: 2.090617099171123
Validation loss: 2.556893394725435

Epoch: 6| Step: 10
Training loss: 1.9901796881862002
Validation loss: 2.5019378621938424

Epoch: 6| Step: 11
Training loss: 1.4891767235864437
Validation loss: 2.491119107924455

Epoch: 6| Step: 12
Training loss: 1.619136281116949
Validation loss: 2.4871087857699

Epoch: 6| Step: 13
Training loss: 2.2540953770033623
Validation loss: 2.508597943193465

Epoch: 285| Step: 0
Training loss: 1.9487811191660522
Validation loss: 2.501440555063168

Epoch: 6| Step: 1
Training loss: 1.887489872077902
Validation loss: 2.509327526918207

Epoch: 6| Step: 2
Training loss: 1.673719013089662
Validation loss: 2.5156567336582585

Epoch: 6| Step: 3
Training loss: 2.371960552215633
Validation loss: 2.5109219550407422

Epoch: 6| Step: 4
Training loss: 1.668519262013466
Validation loss: 2.5487317920861985

Epoch: 6| Step: 5
Training loss: 2.138061547830654
Validation loss: 2.550780977382519

Epoch: 6| Step: 6
Training loss: 2.3290807823037882
Validation loss: 2.584532210870273

Epoch: 6| Step: 7
Training loss: 2.146846001441708
Validation loss: 2.6388015094032267

Epoch: 6| Step: 8
Training loss: 1.8194216402418844
Validation loss: 2.65287398673703

Epoch: 6| Step: 9
Training loss: 1.7343521803995687
Validation loss: 2.7167155374527105

Epoch: 6| Step: 10
Training loss: 1.470252222493747
Validation loss: 2.722825886546694

Epoch: 6| Step: 11
Training loss: 2.0188752221164106
Validation loss: 2.6925634398051397

Epoch: 6| Step: 12
Training loss: 1.7098151580001206
Validation loss: 2.63932061567741

Epoch: 6| Step: 13
Training loss: 1.3162300150369353
Validation loss: 2.59421516751361

Epoch: 286| Step: 0
Training loss: 1.7985274967640086
Validation loss: 2.558689696087881

Epoch: 6| Step: 1
Training loss: 2.402511764481685
Validation loss: 2.5839144350535723

Epoch: 6| Step: 2
Training loss: 2.0231249947204684
Validation loss: 2.549544037775169

Epoch: 6| Step: 3
Training loss: 2.3958806129987287
Validation loss: 2.5587613970551315

Epoch: 6| Step: 4
Training loss: 0.921618603757504
Validation loss: 2.586782373129607

Epoch: 6| Step: 5
Training loss: 1.3308743013889073
Validation loss: 2.5954112206197415

Epoch: 6| Step: 6
Training loss: 1.9921487841864551
Validation loss: 2.5966454549452735

Epoch: 6| Step: 7
Training loss: 1.754760670006792
Validation loss: 2.5969728569998765

Epoch: 6| Step: 8
Training loss: 1.4241264041293367
Validation loss: 2.5754799577627714

Epoch: 6| Step: 9
Training loss: 1.588373727728455
Validation loss: 2.576512905836463

Epoch: 6| Step: 10
Training loss: 1.6234516690235263
Validation loss: 2.599265977976778

Epoch: 6| Step: 11
Training loss: 1.792132080604799
Validation loss: 2.6418550323894108

Epoch: 6| Step: 12
Training loss: 2.1604326012764674
Validation loss: 2.62053571768976

Epoch: 6| Step: 13
Training loss: 1.8772117920788656
Validation loss: 2.646042054621841

Epoch: 287| Step: 0
Training loss: 2.0498861048623445
Validation loss: 2.658481842086145

Epoch: 6| Step: 1
Training loss: 1.4847385965048432
Validation loss: 2.607853779162284

Epoch: 6| Step: 2
Training loss: 1.3346960534688277
Validation loss: 2.5759064964518275

Epoch: 6| Step: 3
Training loss: 1.5778509223054058
Validation loss: 2.5233705745990864

Epoch: 6| Step: 4
Training loss: 2.4318059290574814
Validation loss: 2.5377741122214674

Epoch: 6| Step: 5
Training loss: 1.605834622239904
Validation loss: 2.5568741239342487

Epoch: 6| Step: 6
Training loss: 2.0228382534094975
Validation loss: 2.5689760268020745

Epoch: 6| Step: 7
Training loss: 1.5092485141870053
Validation loss: 2.565022676725825

Epoch: 6| Step: 8
Training loss: 2.067731061245196
Validation loss: 2.591170364851617

Epoch: 6| Step: 9
Training loss: 1.4055164543228202
Validation loss: 2.591856046689665

Epoch: 6| Step: 10
Training loss: 1.481400410544389
Validation loss: 2.5837613540791193

Epoch: 6| Step: 11
Training loss: 2.4554426579632054
Validation loss: 2.559470890718983

Epoch: 6| Step: 12
Training loss: 1.6847712034880038
Validation loss: 2.600227830759388

Epoch: 6| Step: 13
Training loss: 2.1135885470025872
Validation loss: 2.6079525144491926

Epoch: 288| Step: 0
Training loss: 1.5094387001512053
Validation loss: 2.5821523787056537

Epoch: 6| Step: 1
Training loss: 1.6519261186349172
Validation loss: 2.5589606024524425

Epoch: 6| Step: 2
Training loss: 1.8401274573713498
Validation loss: 2.563870334959923

Epoch: 6| Step: 3
Training loss: 1.6982029476535092
Validation loss: 2.5961127798703334

Epoch: 6| Step: 4
Training loss: 1.4530314753799465
Validation loss: 2.584058872493612

Epoch: 6| Step: 5
Training loss: 1.716126329449129
Validation loss: 2.5456444511541463

Epoch: 6| Step: 6
Training loss: 1.6398008910707933
Validation loss: 2.5356660319571938

Epoch: 6| Step: 7
Training loss: 1.9066363083927909
Validation loss: 2.5391290430983804

Epoch: 6| Step: 8
Training loss: 2.1388427666099115
Validation loss: 2.5144983773996508

Epoch: 6| Step: 9
Training loss: 1.9221209236911028
Validation loss: 2.5296064386227344

Epoch: 6| Step: 10
Training loss: 1.3460492711791403
Validation loss: 2.510808990551269

Epoch: 6| Step: 11
Training loss: 2.7622012913283345
Validation loss: 2.5305909056159592

Epoch: 6| Step: 12
Training loss: 1.751117621897574
Validation loss: 2.545425650132783

Epoch: 6| Step: 13
Training loss: 2.183946502526382
Validation loss: 2.544496826213872

Epoch: 289| Step: 0
Training loss: 1.7926414706321576
Validation loss: 2.5411924534736903

Epoch: 6| Step: 1
Training loss: 1.7980222273949504
Validation loss: 2.5291017670660416

Epoch: 6| Step: 2
Training loss: 1.6729791150565159
Validation loss: 2.561295373507585

Epoch: 6| Step: 3
Training loss: 2.0143406050796635
Validation loss: 2.6680314525349775

Epoch: 6| Step: 4
Training loss: 1.417511164707034
Validation loss: 2.63917254769389

Epoch: 6| Step: 5
Training loss: 2.7059767129182233
Validation loss: 2.6173805279505085

Epoch: 6| Step: 6
Training loss: 1.1990131114882319
Validation loss: 2.6219323262255023

Epoch: 6| Step: 7
Training loss: 1.8238115203291103
Validation loss: 2.633676283471142

Epoch: 6| Step: 8
Training loss: 1.7801602024679706
Validation loss: 2.618118211742424

Epoch: 6| Step: 9
Training loss: 2.203867036564583
Validation loss: 2.5250872562301137

Epoch: 6| Step: 10
Training loss: 1.9602602210812823
Validation loss: 2.5758829251216184

Epoch: 6| Step: 11
Training loss: 1.4855484991794468
Validation loss: 2.554373827856915

Epoch: 6| Step: 12
Training loss: 1.2061397877681215
Validation loss: 2.540570512588502

Epoch: 6| Step: 13
Training loss: 1.881788489748717
Validation loss: 2.5564788230945523

Epoch: 290| Step: 0
Training loss: 1.9425966232403988
Validation loss: 2.550108949041712

Epoch: 6| Step: 1
Training loss: 1.3053113165574466
Validation loss: 2.5636061940189823

Epoch: 6| Step: 2
Training loss: 2.132796738115694
Validation loss: 2.54610393998529

Epoch: 6| Step: 3
Training loss: 1.3255192944630783
Validation loss: 2.563231084786744

Epoch: 6| Step: 4
Training loss: 1.6404429016780107
Validation loss: 2.583288935823297

Epoch: 6| Step: 5
Training loss: 2.2778554246688616
Validation loss: 2.5529242914093335

Epoch: 6| Step: 6
Training loss: 1.9740485688237752
Validation loss: 2.599503016045585

Epoch: 6| Step: 7
Training loss: 1.9443024613752395
Validation loss: 2.5787485312702523

Epoch: 6| Step: 8
Training loss: 1.519900789411174
Validation loss: 2.630901303295872

Epoch: 6| Step: 9
Training loss: 2.3976801070899887
Validation loss: 2.6728207288270704

Epoch: 6| Step: 10
Training loss: 1.411617335786571
Validation loss: 2.688607719483971

Epoch: 6| Step: 11
Training loss: 1.702484570403908
Validation loss: 2.663688752776875

Epoch: 6| Step: 12
Training loss: 1.8896253480905256
Validation loss: 2.6451829251022514

Epoch: 6| Step: 13
Training loss: 1.702177011378066
Validation loss: 2.627353929765929

Epoch: 291| Step: 0
Training loss: 1.9424150329034828
Validation loss: 2.5585294681462556

Epoch: 6| Step: 1
Training loss: 1.8021223986439472
Validation loss: 2.4782133085880758

Epoch: 6| Step: 2
Training loss: 1.474002859928043
Validation loss: 2.4835819682093514

Epoch: 6| Step: 3
Training loss: 1.9766877025409109
Validation loss: 2.4927957364572704

Epoch: 6| Step: 4
Training loss: 1.3455328536032602
Validation loss: 2.4616222660095555

Epoch: 6| Step: 5
Training loss: 1.6649532888922485
Validation loss: 2.454694808537906

Epoch: 6| Step: 6
Training loss: 2.2609691267035776
Validation loss: 2.4968676812451

Epoch: 6| Step: 7
Training loss: 1.539156528447084
Validation loss: 2.5200605758067147

Epoch: 6| Step: 8
Training loss: 1.7590194966340125
Validation loss: 2.508002031399494

Epoch: 6| Step: 9
Training loss: 1.5627246695165
Validation loss: 2.556196671095175

Epoch: 6| Step: 10
Training loss: 1.4965184657177648
Validation loss: 2.586817104874217

Epoch: 6| Step: 11
Training loss: 2.2496993605773588
Validation loss: 2.5853058657289583

Epoch: 6| Step: 12
Training loss: 1.1255346193518154
Validation loss: 2.591390034016584

Epoch: 6| Step: 13
Training loss: 2.2935652988503143
Validation loss: 2.606512117202686

Epoch: 292| Step: 0
Training loss: 1.426085055656926
Validation loss: 2.5944080666989793

Epoch: 6| Step: 1
Training loss: 1.7663796761566737
Validation loss: 2.5662592473694206

Epoch: 6| Step: 2
Training loss: 1.6607937654617098
Validation loss: 2.578376973487051

Epoch: 6| Step: 3
Training loss: 1.7320253419409695
Validation loss: 2.5496330539497425

Epoch: 6| Step: 4
Training loss: 1.4795076577161481
Validation loss: 2.5085444664626007

Epoch: 6| Step: 5
Training loss: 1.9192758988857495
Validation loss: 2.531116387879287

Epoch: 6| Step: 6
Training loss: 1.7456906939422647
Validation loss: 2.482710242561318

Epoch: 6| Step: 7
Training loss: 1.299851735536808
Validation loss: 2.4909683242988083

Epoch: 6| Step: 8
Training loss: 1.5823307460289366
Validation loss: 2.4932622874009542

Epoch: 6| Step: 9
Training loss: 1.8471082072179077
Validation loss: 2.4895417809842755

Epoch: 6| Step: 10
Training loss: 2.384093993740597
Validation loss: 2.5114418458549035

Epoch: 6| Step: 11
Training loss: 2.3045325275624258
Validation loss: 2.505006529570475

Epoch: 6| Step: 12
Training loss: 1.7475217573915247
Validation loss: 2.5558997961291015

Epoch: 6| Step: 13
Training loss: 1.5159080477031535
Validation loss: 2.6007339028620544

Epoch: 293| Step: 0
Training loss: 1.7735623891270982
Validation loss: 2.599652204726773

Epoch: 6| Step: 1
Training loss: 1.4720571093468864
Validation loss: 2.5792188847627027

Epoch: 6| Step: 2
Training loss: 1.815390157038351
Validation loss: 2.571670807171511

Epoch: 6| Step: 3
Training loss: 2.130311386737082
Validation loss: 2.534777722266395

Epoch: 6| Step: 4
Training loss: 1.169872913386859
Validation loss: 2.538644014741645

Epoch: 6| Step: 5
Training loss: 2.132654652326266
Validation loss: 2.5619190612016762

Epoch: 6| Step: 6
Training loss: 1.8355309868267204
Validation loss: 2.545991561039106

Epoch: 6| Step: 7
Training loss: 1.7166434817307088
Validation loss: 2.5437751268900097

Epoch: 6| Step: 8
Training loss: 1.8823429012732067
Validation loss: 2.549983898436131

Epoch: 6| Step: 9
Training loss: 1.5888755905970169
Validation loss: 2.5703021110162383

Epoch: 6| Step: 10
Training loss: 1.7654641677387792
Validation loss: 2.6339708113958746

Epoch: 6| Step: 11
Training loss: 1.4659457118142445
Validation loss: 2.632322437472346

Epoch: 6| Step: 12
Training loss: 2.187817577742487
Validation loss: 2.6071407476119273

Epoch: 6| Step: 13
Training loss: 1.741157398267248
Validation loss: 2.56198455309523

Epoch: 294| Step: 0
Training loss: 1.6869182290258404
Validation loss: 2.5267260669739677

Epoch: 6| Step: 1
Training loss: 1.3814427547681944
Validation loss: 2.5213151318962126

Epoch: 6| Step: 2
Training loss: 2.198565913003752
Validation loss: 2.513153046340239

Epoch: 6| Step: 3
Training loss: 1.0009671541097478
Validation loss: 2.562657622785154

Epoch: 6| Step: 4
Training loss: 1.6640432293989456
Validation loss: 2.5490500946634733

Epoch: 6| Step: 5
Training loss: 1.8992695809846643
Validation loss: 2.5348201581826713

Epoch: 6| Step: 6
Training loss: 2.0724301430187873
Validation loss: 2.5564507981506055

Epoch: 6| Step: 7
Training loss: 1.8851719551681136
Validation loss: 2.5461078806888158

Epoch: 6| Step: 8
Training loss: 1.8647659752188703
Validation loss: 2.5430067521482034

Epoch: 6| Step: 9
Training loss: 2.0540392182941707
Validation loss: 2.5844187968431895

Epoch: 6| Step: 10
Training loss: 1.5701744056826503
Validation loss: 2.595095503782439

Epoch: 6| Step: 11
Training loss: 1.566160796381221
Validation loss: 2.6069744435813496

Epoch: 6| Step: 12
Training loss: 2.1777520012249125
Validation loss: 2.5582980618442575

Epoch: 6| Step: 13
Training loss: 1.7100589534568964
Validation loss: 2.5192946369738762

Epoch: 295| Step: 0
Training loss: 1.5290356409273775
Validation loss: 2.5378923429146982

Epoch: 6| Step: 1
Training loss: 1.376100749793582
Validation loss: 2.5647942421959375

Epoch: 6| Step: 2
Training loss: 1.579480184200712
Validation loss: 2.547857208265193

Epoch: 6| Step: 3
Training loss: 1.7403567150196295
Validation loss: 2.5402640448768494

Epoch: 6| Step: 4
Training loss: 2.161824194649458
Validation loss: 2.5103544224874867

Epoch: 6| Step: 5
Training loss: 1.4340239251028324
Validation loss: 2.4962524220355053

Epoch: 6| Step: 6
Training loss: 1.4973009781578668
Validation loss: 2.5120229897712565

Epoch: 6| Step: 7
Training loss: 2.1974188314643213
Validation loss: 2.5201067284533036

Epoch: 6| Step: 8
Training loss: 1.9865642696058892
Validation loss: 2.5322902410061987

Epoch: 6| Step: 9
Training loss: 1.668551269584905
Validation loss: 2.5501071259180543

Epoch: 6| Step: 10
Training loss: 2.207197605041333
Validation loss: 2.549449002194962

Epoch: 6| Step: 11
Training loss: 1.3621044599719538
Validation loss: 2.5864400692214375

Epoch: 6| Step: 12
Training loss: 2.102050497695248
Validation loss: 2.5757030323614827

Epoch: 6| Step: 13
Training loss: 1.511687837821868
Validation loss: 2.5737508021423365

Epoch: 296| Step: 0
Training loss: 1.950542420971072
Validation loss: 2.602214910897983

Epoch: 6| Step: 1
Training loss: 2.017644063161982
Validation loss: 2.6183169001479016

Epoch: 6| Step: 2
Training loss: 1.9707059680627101
Validation loss: 2.618560157759353

Epoch: 6| Step: 3
Training loss: 1.7961685118644368
Validation loss: 2.590975138858201

Epoch: 6| Step: 4
Training loss: 1.625549663600527
Validation loss: 2.566900019028774

Epoch: 6| Step: 5
Training loss: 1.782435106591599
Validation loss: 2.556806659479862

Epoch: 6| Step: 6
Training loss: 1.8680745974314312
Validation loss: 2.5195082079402997

Epoch: 6| Step: 7
Training loss: 1.1620194087746636
Validation loss: 2.538298428329492

Epoch: 6| Step: 8
Training loss: 1.4948781306373318
Validation loss: 2.5328467948610904

Epoch: 6| Step: 9
Training loss: 1.4396592384712603
Validation loss: 2.5367966699768036

Epoch: 6| Step: 10
Training loss: 2.0060459781903726
Validation loss: 2.5323103422425355

Epoch: 6| Step: 11
Training loss: 2.198296633113512
Validation loss: 2.5027903878866553

Epoch: 6| Step: 12
Training loss: 1.0880675249077376
Validation loss: 2.5042100584192273

Epoch: 6| Step: 13
Training loss: 1.751934821161874
Validation loss: 2.5266727930647255

Epoch: 297| Step: 0
Training loss: 1.989420746023541
Validation loss: 2.599128753232303

Epoch: 6| Step: 1
Training loss: 2.0318775088043353
Validation loss: 2.7183337934397347

Epoch: 6| Step: 2
Training loss: 1.3242436859573745
Validation loss: 2.6602269189889243

Epoch: 6| Step: 3
Training loss: 2.2741438040510777
Validation loss: 2.626858946141336

Epoch: 6| Step: 4
Training loss: 1.572436741586024
Validation loss: 2.5940646321610723

Epoch: 6| Step: 5
Training loss: 1.3715499162563856
Validation loss: 2.58256022872684

Epoch: 6| Step: 6
Training loss: 1.7010254123500606
Validation loss: 2.555001304710737

Epoch: 6| Step: 7
Training loss: 1.6159328440413037
Validation loss: 2.5603923503651207

Epoch: 6| Step: 8
Training loss: 1.9608345156675644
Validation loss: 2.556351954534045

Epoch: 6| Step: 9
Training loss: 1.1852072617397513
Validation loss: 2.5589901371992267

Epoch: 6| Step: 10
Training loss: 1.7028363184419062
Validation loss: 2.563666078374082

Epoch: 6| Step: 11
Training loss: 2.530104012744855
Validation loss: 2.5674377876626466

Epoch: 6| Step: 12
Training loss: 2.099678073912428
Validation loss: 2.539301637000877

Epoch: 6| Step: 13
Training loss: 1.0712369838355607
Validation loss: 2.5600887832544683

Epoch: 298| Step: 0
Training loss: 1.252994574325761
Validation loss: 2.5753231351991017

Epoch: 6| Step: 1
Training loss: 1.8288211638136318
Validation loss: 2.5792532407644067

Epoch: 6| Step: 2
Training loss: 1.8288134721234728
Validation loss: 2.6251634667981927

Epoch: 6| Step: 3
Training loss: 1.2687877179632512
Validation loss: 2.5798713395224144

Epoch: 6| Step: 4
Training loss: 1.6145996913286356
Validation loss: 2.59777227539384

Epoch: 6| Step: 5
Training loss: 1.6527941655789968
Validation loss: 2.5639397600494704

Epoch: 6| Step: 6
Training loss: 1.8591529008306422
Validation loss: 2.580412110305608

Epoch: 6| Step: 7
Training loss: 1.8744874889559657
Validation loss: 2.5513037496459248

Epoch: 6| Step: 8
Training loss: 1.2981535342831283
Validation loss: 2.557242481719493

Epoch: 6| Step: 9
Training loss: 1.571512247929314
Validation loss: 2.495135294928792

Epoch: 6| Step: 10
Training loss: 1.7078003013014624
Validation loss: 2.5450758869121373

Epoch: 6| Step: 11
Training loss: 1.712575050435818
Validation loss: 2.540018052490041

Epoch: 6| Step: 12
Training loss: 1.751650372631149
Validation loss: 2.541775221669149

Epoch: 6| Step: 13
Training loss: 2.419102613981105
Validation loss: 2.5410229592164923

Epoch: 299| Step: 0
Training loss: 1.619935653845012
Validation loss: 2.5471997044311125

Epoch: 6| Step: 1
Training loss: 1.8883593516677073
Validation loss: 2.561445267250851

Epoch: 6| Step: 2
Training loss: 1.8522152937002
Validation loss: 2.556464056800759

Epoch: 6| Step: 3
Training loss: 1.6368742438770134
Validation loss: 2.6195731605933763

Epoch: 6| Step: 4
Training loss: 1.6249854747416477
Validation loss: 2.5947773442331874

Epoch: 6| Step: 5
Training loss: 1.3743703007151509
Validation loss: 2.619615057167687

Epoch: 6| Step: 6
Training loss: 1.5274934427023834
Validation loss: 2.558015566816031

Epoch: 6| Step: 7
Training loss: 1.5501997695902994
Validation loss: 2.554874720503623

Epoch: 6| Step: 8
Training loss: 1.4659414018990935
Validation loss: 2.5129657535084062

Epoch: 6| Step: 9
Training loss: 1.649270809766842
Validation loss: 2.4930497673862413

Epoch: 6| Step: 10
Training loss: 2.0666418391961665
Validation loss: 2.49951330851719

Epoch: 6| Step: 11
Training loss: 2.4011755607381833
Validation loss: 2.4821706465145335

Epoch: 6| Step: 12
Training loss: 1.8079320632315308
Validation loss: 2.490270150120884

Epoch: 6| Step: 13
Training loss: 1.3291986949892436
Validation loss: 2.473845185486505

Epoch: 300| Step: 0
Training loss: 1.4229961628114887
Validation loss: 2.489015575668258

Epoch: 6| Step: 1
Training loss: 1.9949390034923447
Validation loss: 2.4772189580964246

Epoch: 6| Step: 2
Training loss: 1.6497026984816645
Validation loss: 2.542102218788707

Epoch: 6| Step: 3
Training loss: 1.6833191402076157
Validation loss: 2.639805442740595

Epoch: 6| Step: 4
Training loss: 1.60766977876007
Validation loss: 2.562133716363518

Epoch: 6| Step: 5
Training loss: 1.161968113624237
Validation loss: 2.5283692061616763

Epoch: 6| Step: 6
Training loss: 2.0340969382022838
Validation loss: 2.4781686606615825

Epoch: 6| Step: 7
Training loss: 1.7580621838730568
Validation loss: 2.508605641467845

Epoch: 6| Step: 8
Training loss: 1.5444420070461247
Validation loss: 2.530615699633524

Epoch: 6| Step: 9
Training loss: 1.9323692066301466
Validation loss: 2.537910755780838

Epoch: 6| Step: 10
Training loss: 2.0431241911766618
Validation loss: 2.53555241464039

Epoch: 6| Step: 11
Training loss: 1.4666106693819747
Validation loss: 2.5439512949535783

Epoch: 6| Step: 12
Training loss: 1.9523090336564877
Validation loss: 2.5361405682068794

Epoch: 6| Step: 13
Training loss: 1.678852814276217
Validation loss: 2.5307371695366374

Epoch: 301| Step: 0
Training loss: 1.515149307321616
Validation loss: 2.501833164139437

Epoch: 6| Step: 1
Training loss: 1.5071800368106645
Validation loss: 2.5052985309269915

Epoch: 6| Step: 2
Training loss: 1.2505771258340295
Validation loss: 2.45965037114996

Epoch: 6| Step: 3
Training loss: 1.707853141224311
Validation loss: 2.4871486479578935

Epoch: 6| Step: 4
Training loss: 2.0489524025403756
Validation loss: 2.5139376270868974

Epoch: 6| Step: 5
Training loss: 1.9051126307635398
Validation loss: 2.533757870848064

Epoch: 6| Step: 6
Training loss: 2.198629351109361
Validation loss: 2.5427661742794667

Epoch: 6| Step: 7
Training loss: 1.4131036531910408
Validation loss: 2.5280414701100438

Epoch: 6| Step: 8
Training loss: 1.5046270847570737
Validation loss: 2.555167678984423

Epoch: 6| Step: 9
Training loss: 1.8894502757652114
Validation loss: 2.574377754483467

Epoch: 6| Step: 10
Training loss: 1.4713183733432085
Validation loss: 2.6374842909937204

Epoch: 6| Step: 11
Training loss: 1.8297329213720936
Validation loss: 2.705448335546145

Epoch: 6| Step: 12
Training loss: 1.9603954645105561
Validation loss: 2.7007341340501263

Epoch: 6| Step: 13
Training loss: 1.9509872333885148
Validation loss: 2.6221411138408186

Epoch: 302| Step: 0
Training loss: 1.8216971832446265
Validation loss: 2.615653944747877

Epoch: 6| Step: 1
Training loss: 1.5891406404830837
Validation loss: 2.583201871623888

Epoch: 6| Step: 2
Training loss: 1.3044256530051204
Validation loss: 2.5531067230056004

Epoch: 6| Step: 3
Training loss: 2.2844289290589423
Validation loss: 2.545277131336221

Epoch: 6| Step: 4
Training loss: 1.7615491019905618
Validation loss: 2.5448929733075634

Epoch: 6| Step: 5
Training loss: 1.4940897216104272
Validation loss: 2.5786801751909545

Epoch: 6| Step: 6
Training loss: 1.27959395591892
Validation loss: 2.5834922485284495

Epoch: 6| Step: 7
Training loss: 1.7944061567842915
Validation loss: 2.6079239760690203

Epoch: 6| Step: 8
Training loss: 1.6526993172808095
Validation loss: 2.6321634309421458

Epoch: 6| Step: 9
Training loss: 1.6328748481199662
Validation loss: 2.660672309997903

Epoch: 6| Step: 10
Training loss: 2.2655929036991065
Validation loss: 2.6934548725978744

Epoch: 6| Step: 11
Training loss: 2.0834610200535355
Validation loss: 2.6546162835788896

Epoch: 6| Step: 12
Training loss: 1.7554986941844197
Validation loss: 2.639817244099461

Epoch: 6| Step: 13
Training loss: 1.6294196255231612
Validation loss: 2.6117718133491072

Epoch: 303| Step: 0
Training loss: 2.162618437594185
Validation loss: 2.575892875087707

Epoch: 6| Step: 1
Training loss: 1.7131243103760783
Validation loss: 2.5538998010646723

Epoch: 6| Step: 2
Training loss: 1.2429737026228622
Validation loss: 2.4981556605993864

Epoch: 6| Step: 3
Training loss: 1.2791209791558855
Validation loss: 2.4602735804577187

Epoch: 6| Step: 4
Training loss: 1.4364413634089228
Validation loss: 2.443627879155684

Epoch: 6| Step: 5
Training loss: 2.096408124588652
Validation loss: 2.4650544219106116

Epoch: 6| Step: 6
Training loss: 1.7238994791946762
Validation loss: 2.4740080470393977

Epoch: 6| Step: 7
Training loss: 1.5444185423260806
Validation loss: 2.500073177538222

Epoch: 6| Step: 8
Training loss: 1.9356905578803936
Validation loss: 2.5462655584490155

Epoch: 6| Step: 9
Training loss: 1.8524311458543408
Validation loss: 2.5559446408943582

Epoch: 6| Step: 10
Training loss: 1.8036519832508073
Validation loss: 2.573730129086805

Epoch: 6| Step: 11
Training loss: 1.5187840524631397
Validation loss: 2.59147487576731

Epoch: 6| Step: 12
Training loss: 1.6103653314393924
Validation loss: 2.546966753908048

Epoch: 6| Step: 13
Training loss: 1.3679752369306948
Validation loss: 2.548205849016199

Epoch: 304| Step: 0
Training loss: 1.5922178495769588
Validation loss: 2.522903385857157

Epoch: 6| Step: 1
Training loss: 1.7560525179028486
Validation loss: 2.5520295014185943

Epoch: 6| Step: 2
Training loss: 1.5156176852020247
Validation loss: 2.536998860901369

Epoch: 6| Step: 3
Training loss: 1.196913899319936
Validation loss: 2.5361557505219907

Epoch: 6| Step: 4
Training loss: 1.6472114233842712
Validation loss: 2.535885964945474

Epoch: 6| Step: 5
Training loss: 2.137597274797667
Validation loss: 2.561322973107602

Epoch: 6| Step: 6
Training loss: 1.630747826695986
Validation loss: 2.6091910809479626

Epoch: 6| Step: 7
Training loss: 1.9742273702610638
Validation loss: 2.6344358983963336

Epoch: 6| Step: 8
Training loss: 1.7399692526106654
Validation loss: 2.640909078090968

Epoch: 6| Step: 9
Training loss: 1.6207816317565287
Validation loss: 2.6058625967808027

Epoch: 6| Step: 10
Training loss: 1.5968618493182514
Validation loss: 2.5343195078552667

Epoch: 6| Step: 11
Training loss: 1.4727289399438364
Validation loss: 2.495435609051865

Epoch: 6| Step: 12
Training loss: 2.0064159241511357
Validation loss: 2.5418936179931277

Epoch: 6| Step: 13
Training loss: 1.2800953942752955
Validation loss: 2.507939906860031

Epoch: 305| Step: 0
Training loss: 1.4737061014019472
Validation loss: 2.5214466473322448

Epoch: 6| Step: 1
Training loss: 1.7235781047665322
Validation loss: 2.5525501109804614

Epoch: 6| Step: 2
Training loss: 1.6969450372394568
Validation loss: 2.5571086426998506

Epoch: 6| Step: 3
Training loss: 1.7202230903196103
Validation loss: 2.568930257148278

Epoch: 6| Step: 4
Training loss: 1.9313265985896642
Validation loss: 2.544401688010596

Epoch: 6| Step: 5
Training loss: 1.4051577246704983
Validation loss: 2.569468606084913

Epoch: 6| Step: 6
Training loss: 1.6930155157469935
Validation loss: 2.5982103870545497

Epoch: 6| Step: 7
Training loss: 1.461795330641086
Validation loss: 2.621326510104551

Epoch: 6| Step: 8
Training loss: 1.8601514333176363
Validation loss: 2.5984082197205347

Epoch: 6| Step: 9
Training loss: 1.691589345558658
Validation loss: 2.5988835621527735

Epoch: 6| Step: 10
Training loss: 1.748811727092893
Validation loss: 2.630796889120255

Epoch: 6| Step: 11
Training loss: 1.723782748436169
Validation loss: 2.6090402140921864

Epoch: 6| Step: 12
Training loss: 1.5078746407309276
Validation loss: 2.5441109884620925

Epoch: 6| Step: 13
Training loss: 1.6652126009271673
Validation loss: 2.5327284776830434

Epoch: 306| Step: 0
Training loss: 1.9066548152146219
Validation loss: 2.5067844363288074

Epoch: 6| Step: 1
Training loss: 1.2869977656643672
Validation loss: 2.5274352067439714

Epoch: 6| Step: 2
Training loss: 2.0743040365440524
Validation loss: 2.5115906883962436

Epoch: 6| Step: 3
Training loss: 1.4218583158415463
Validation loss: 2.4729982514221613

Epoch: 6| Step: 4
Training loss: 2.2384627503309367
Validation loss: 2.4748931216272934

Epoch: 6| Step: 5
Training loss: 1.4154703287338377
Validation loss: 2.44373167247355

Epoch: 6| Step: 6
Training loss: 1.8279819269518096
Validation loss: 2.463828238876035

Epoch: 6| Step: 7
Training loss: 1.4954764185621054
Validation loss: 2.4440921423608266

Epoch: 6| Step: 8
Training loss: 1.6289119583139637
Validation loss: 2.4784155650842234

Epoch: 6| Step: 9
Training loss: 1.1869674793631606
Validation loss: 2.5266908630715585

Epoch: 6| Step: 10
Training loss: 1.8318096100021264
Validation loss: 2.5994141560545243

Epoch: 6| Step: 11
Training loss: 1.5569164457742473
Validation loss: 2.629367842637689

Epoch: 6| Step: 12
Training loss: 1.5397058681648992
Validation loss: 2.5928849152608042

Epoch: 6| Step: 13
Training loss: 1.8603255462829822
Validation loss: 2.598366439988505

Epoch: 307| Step: 0
Training loss: 2.097398681739734
Validation loss: 2.596643710404248

Epoch: 6| Step: 1
Training loss: 1.2719906503645646
Validation loss: 2.5582386032442614

Epoch: 6| Step: 2
Training loss: 1.7066334276141435
Validation loss: 2.6086255365891167

Epoch: 6| Step: 3
Training loss: 1.7743767087255664
Validation loss: 2.6166660985115877

Epoch: 6| Step: 4
Training loss: 1.868809972712937
Validation loss: 2.581444116148472

Epoch: 6| Step: 5
Training loss: 1.5729186792760776
Validation loss: 2.5952952580928983

Epoch: 6| Step: 6
Training loss: 2.317977603886444
Validation loss: 2.548632695877276

Epoch: 6| Step: 7
Training loss: 0.9847086991740267
Validation loss: 2.507008266135588

Epoch: 6| Step: 8
Training loss: 1.292493473530862
Validation loss: 2.495594115938315

Epoch: 6| Step: 9
Training loss: 1.7552583576020262
Validation loss: 2.472207139596638

Epoch: 6| Step: 10
Training loss: 2.3442648767139826
Validation loss: 2.465844315515909

Epoch: 6| Step: 11
Training loss: 1.6660975517709675
Validation loss: 2.4926677627758314

Epoch: 6| Step: 12
Training loss: 1.0886921694930418
Validation loss: 2.5041939366316206

Epoch: 6| Step: 13
Training loss: 2.0152192409691714
Validation loss: 2.4921812657325124

Epoch: 308| Step: 0
Training loss: 1.351351991698397
Validation loss: 2.497922622338439

Epoch: 6| Step: 1
Training loss: 1.324766647735307
Validation loss: 2.504772986470072

Epoch: 6| Step: 2
Training loss: 1.5580862648407188
Validation loss: 2.5170211708624346

Epoch: 6| Step: 3
Training loss: 1.7581782659821283
Validation loss: 2.5314016257504157

Epoch: 6| Step: 4
Training loss: 2.118738261052473
Validation loss: 2.5741117741725663

Epoch: 6| Step: 5
Training loss: 1.3424765740735816
Validation loss: 2.6137108328542276

Epoch: 6| Step: 6
Training loss: 1.2928901487125186
Validation loss: 2.5761448818023687

Epoch: 6| Step: 7
Training loss: 1.8640498529406468
Validation loss: 2.568826000144334

Epoch: 6| Step: 8
Training loss: 1.28326318330308
Validation loss: 2.6085988030504197

Epoch: 6| Step: 9
Training loss: 1.9802063536763685
Validation loss: 2.647707243010247

Epoch: 6| Step: 10
Training loss: 1.7341199120239505
Validation loss: 2.6187258550096812

Epoch: 6| Step: 11
Training loss: 1.4008581426550282
Validation loss: 2.598864159314397

Epoch: 6| Step: 12
Training loss: 1.6041421351683234
Validation loss: 2.5983810752053422

Epoch: 6| Step: 13
Training loss: 1.6356404469292325
Validation loss: 2.57577589499407

Epoch: 309| Step: 0
Training loss: 1.2305075018699412
Validation loss: 2.589427149250041

Epoch: 6| Step: 1
Training loss: 1.9275379022812587
Validation loss: 2.582121493041303

Epoch: 6| Step: 2
Training loss: 1.6493623137049414
Validation loss: 2.5987350785886845

Epoch: 6| Step: 3
Training loss: 1.811333050452753
Validation loss: 2.6234557286913462

Epoch: 6| Step: 4
Training loss: 1.8270372594448923
Validation loss: 2.63852210646913

Epoch: 6| Step: 5
Training loss: 1.3284789567399917
Validation loss: 2.613619111121008

Epoch: 6| Step: 6
Training loss: 1.1681604132430252
Validation loss: 2.562036596436376

Epoch: 6| Step: 7
Training loss: 1.7182264050656832
Validation loss: 2.536401318503976

Epoch: 6| Step: 8
Training loss: 1.7951760262591903
Validation loss: 2.524303417621764

Epoch: 6| Step: 9
Training loss: 1.191136914436544
Validation loss: 2.488260856956064

Epoch: 6| Step: 10
Training loss: 1.9362339066882652
Validation loss: 2.4919436264698205

Epoch: 6| Step: 11
Training loss: 1.45476349366822
Validation loss: 2.4902472043174426

Epoch: 6| Step: 12
Training loss: 1.5809994947708934
Validation loss: 2.4864415065247685

Epoch: 6| Step: 13
Training loss: 1.8439661966067913
Validation loss: 2.474243377861696

Epoch: 310| Step: 0
Training loss: 1.5969456069177363
Validation loss: 2.4987340741956405

Epoch: 6| Step: 1
Training loss: 1.2534283354107238
Validation loss: 2.4954902345169083

Epoch: 6| Step: 2
Training loss: 1.423371502113617
Validation loss: 2.467776110453555

Epoch: 6| Step: 3
Training loss: 1.6978757966472264
Validation loss: 2.4709496577404293

Epoch: 6| Step: 4
Training loss: 1.4400130157412294
Validation loss: 2.4600202516171894

Epoch: 6| Step: 5
Training loss: 1.163720509517053
Validation loss: 2.4671347923519344

Epoch: 6| Step: 6
Training loss: 1.5875315054823471
Validation loss: 2.494787217509869

Epoch: 6| Step: 7
Training loss: 1.7724701515988122
Validation loss: 2.5350203514410805

Epoch: 6| Step: 8
Training loss: 1.5150142107507953
Validation loss: 2.574227780223515

Epoch: 6| Step: 9
Training loss: 1.3673413435346256
Validation loss: 2.5889914420580586

Epoch: 6| Step: 10
Training loss: 1.486114847568715
Validation loss: 2.6134843961163403

Epoch: 6| Step: 11
Training loss: 2.291820544076259
Validation loss: 2.6120246941556324

Epoch: 6| Step: 12
Training loss: 1.1760162422849099
Validation loss: 2.5645155074702553

Epoch: 6| Step: 13
Training loss: 1.98127570631998
Validation loss: 2.582275802257864

Epoch: 311| Step: 0
Training loss: 1.513821974664717
Validation loss: 2.6118693812007794

Epoch: 6| Step: 1
Training loss: 1.2595245840437848
Validation loss: 2.567337958581417

Epoch: 6| Step: 2
Training loss: 1.5532554280032573
Validation loss: 2.5906711060424925

Epoch: 6| Step: 3
Training loss: 2.3569030949413454
Validation loss: 2.5990292240685284

Epoch: 6| Step: 4
Training loss: 1.673171636866946
Validation loss: 2.5482732604908866

Epoch: 6| Step: 5
Training loss: 1.5761724044250582
Validation loss: 2.608769177066425

Epoch: 6| Step: 6
Training loss: 1.39900933194269
Validation loss: 2.5674216837145294

Epoch: 6| Step: 7
Training loss: 0.9953016535049696
Validation loss: 2.6033272929086917

Epoch: 6| Step: 8
Training loss: 1.1535033517630915
Validation loss: 2.5529225636866504

Epoch: 6| Step: 9
Training loss: 1.715501524437294
Validation loss: 2.524705298697413

Epoch: 6| Step: 10
Training loss: 1.308883999192201
Validation loss: 2.5612827759521757

Epoch: 6| Step: 11
Training loss: 1.8976305592770035
Validation loss: 2.5725719952062587

Epoch: 6| Step: 12
Training loss: 1.7834186402829788
Validation loss: 2.547441805623143

Epoch: 6| Step: 13
Training loss: 1.552413504213544
Validation loss: 2.5214162630691335

Epoch: 312| Step: 0
Training loss: 1.2909711175076743
Validation loss: 2.545815900960406

Epoch: 6| Step: 1
Training loss: 1.508962479288586
Validation loss: 2.4983811620833922

Epoch: 6| Step: 2
Training loss: 1.6060627304927892
Validation loss: 2.560901406828823

Epoch: 6| Step: 3
Training loss: 1.9791752731403813
Validation loss: 2.534075694317765

Epoch: 6| Step: 4
Training loss: 1.2401806917361728
Validation loss: 2.55685305022537

Epoch: 6| Step: 5
Training loss: 1.4012864571421837
Validation loss: 2.53723471559276

Epoch: 6| Step: 6
Training loss: 1.8553226453578595
Validation loss: 2.550604455340587

Epoch: 6| Step: 7
Training loss: 1.744626993028268
Validation loss: 2.5319280932743573

Epoch: 6| Step: 8
Training loss: 1.6906881239524205
Validation loss: 2.5491646847733316

Epoch: 6| Step: 9
Training loss: 1.3618637191634373
Validation loss: 2.570751859918545

Epoch: 6| Step: 10
Training loss: 1.6521710244662002
Validation loss: 2.560689286404295

Epoch: 6| Step: 11
Training loss: 1.4274098748986754
Validation loss: 2.575287338076516

Epoch: 6| Step: 12
Training loss: 1.4185778778126041
Validation loss: 2.574767899777929

Epoch: 6| Step: 13
Training loss: 1.3307174960804773
Validation loss: 2.574615417081356

Epoch: 313| Step: 0
Training loss: 1.1408327514409173
Validation loss: 2.5649223043709757

Epoch: 6| Step: 1
Training loss: 1.1030960770832654
Validation loss: 2.541706652926062

Epoch: 6| Step: 2
Training loss: 1.3195278386760227
Validation loss: 2.5725565566953508

Epoch: 6| Step: 3
Training loss: 1.605233056804056
Validation loss: 2.5218124589881987

Epoch: 6| Step: 4
Training loss: 1.3712306810129167
Validation loss: 2.545781281017682

Epoch: 6| Step: 5
Training loss: 1.5079865034040765
Validation loss: 2.5402996472705284

Epoch: 6| Step: 6
Training loss: 2.1412171150528305
Validation loss: 2.5614087176911715

Epoch: 6| Step: 7
Training loss: 1.647353190825846
Validation loss: 2.586111011043027

Epoch: 6| Step: 8
Training loss: 1.3922887985760863
Validation loss: 2.545426875589513

Epoch: 6| Step: 9
Training loss: 1.9404807388816259
Validation loss: 2.5542215278131066

Epoch: 6| Step: 10
Training loss: 1.2551524306811066
Validation loss: 2.56379428989562

Epoch: 6| Step: 11
Training loss: 1.3984614961579267
Validation loss: 2.5971882104488277

Epoch: 6| Step: 12
Training loss: 1.55797884099889
Validation loss: 2.5430515352008216

Epoch: 6| Step: 13
Training loss: 1.8855182627357676
Validation loss: 2.571784791102121

Epoch: 314| Step: 0
Training loss: 1.7233894154679035
Validation loss: 2.5825333484614927

Epoch: 6| Step: 1
Training loss: 1.1477960365084734
Validation loss: 2.5155726046269016

Epoch: 6| Step: 2
Training loss: 1.3512303820799518
Validation loss: 2.5486703563205806

Epoch: 6| Step: 3
Training loss: 1.3417515642936377
Validation loss: 2.5494108544855556

Epoch: 6| Step: 4
Training loss: 1.5770097323149403
Validation loss: 2.547111484649296

Epoch: 6| Step: 5
Training loss: 1.6301060198607722
Validation loss: 2.5314823562034334

Epoch: 6| Step: 6
Training loss: 0.8808386688167068
Validation loss: 2.5296580720744513

Epoch: 6| Step: 7
Training loss: 2.0007260911898395
Validation loss: 2.5122863381351412

Epoch: 6| Step: 8
Training loss: 2.139223739978191
Validation loss: 2.483972272879937

Epoch: 6| Step: 9
Training loss: 1.3698880798678905
Validation loss: 2.4977395646851517

Epoch: 6| Step: 10
Training loss: 1.4231683905901134
Validation loss: 2.506314266836332

Epoch: 6| Step: 11
Training loss: 1.2494399723564533
Validation loss: 2.5281867655913444

Epoch: 6| Step: 12
Training loss: 1.9188272765065202
Validation loss: 2.5277986190854302

Epoch: 6| Step: 13
Training loss: 1.402571805723968
Validation loss: 2.5049798323275656

Epoch: 315| Step: 0
Training loss: 1.2335407963235177
Validation loss: 2.5276310642922337

Epoch: 6| Step: 1
Training loss: 1.6649543628795962
Validation loss: 2.5145330803839863

Epoch: 6| Step: 2
Training loss: 1.7188513292440586
Validation loss: 2.5442219276894886

Epoch: 6| Step: 3
Training loss: 1.2402649883186594
Validation loss: 2.535930340988512

Epoch: 6| Step: 4
Training loss: 1.5797509607987366
Validation loss: 2.506101410758523

Epoch: 6| Step: 5
Training loss: 1.3576154172949184
Validation loss: 2.545571334851384

Epoch: 6| Step: 6
Training loss: 1.4259848253370984
Validation loss: 2.501863579756953

Epoch: 6| Step: 7
Training loss: 1.6033159287288559
Validation loss: 2.5373898753180515

Epoch: 6| Step: 8
Training loss: 1.7383255513578755
Validation loss: 2.5237776425670906

Epoch: 6| Step: 9
Training loss: 1.3959530546552745
Validation loss: 2.5658396071625447

Epoch: 6| Step: 10
Training loss: 1.530255286541803
Validation loss: 2.52911280449499

Epoch: 6| Step: 11
Training loss: 1.3808651590833156
Validation loss: 2.517018889627465

Epoch: 6| Step: 12
Training loss: 2.0053984977088812
Validation loss: 2.5083367343469756

Epoch: 6| Step: 13
Training loss: 1.6962026904599028
Validation loss: 2.465358045701031

Epoch: 316| Step: 0
Training loss: 1.931571874368974
Validation loss: 2.5095954332646366

Epoch: 6| Step: 1
Training loss: 1.701564248664735
Validation loss: 2.503117382023681

Epoch: 6| Step: 2
Training loss: 1.4772230820216752
Validation loss: 2.485834456761211

Epoch: 6| Step: 3
Training loss: 1.5196564532086878
Validation loss: 2.525860004512872

Epoch: 6| Step: 4
Training loss: 2.016044395639141
Validation loss: 2.54631025297662

Epoch: 6| Step: 5
Training loss: 2.203396827756273
Validation loss: 2.5531718261857197

Epoch: 6| Step: 6
Training loss: 1.5338838463217996
Validation loss: 2.583205740351583

Epoch: 6| Step: 7
Training loss: 0.9420928983499446
Validation loss: 2.595668404994938

Epoch: 6| Step: 8
Training loss: 1.360795079519177
Validation loss: 2.627236276561524

Epoch: 6| Step: 9
Training loss: 1.2818573233410004
Validation loss: 2.674117502474034

Epoch: 6| Step: 10
Training loss: 1.7734106792824917
Validation loss: 2.6547873864589295

Epoch: 6| Step: 11
Training loss: 1.126527702651248
Validation loss: 2.675559776774731

Epoch: 6| Step: 12
Training loss: 1.5959566584942826
Validation loss: 2.6037419748510717

Epoch: 6| Step: 13
Training loss: 1.742953897410349
Validation loss: 2.5360028107875245

Epoch: 317| Step: 0
Training loss: 1.2908764647306243
Validation loss: 2.553515757583631

Epoch: 6| Step: 1
Training loss: 1.0422530558269791
Validation loss: 2.5317520381562315

Epoch: 6| Step: 2
Training loss: 1.8249297298332738
Validation loss: 2.4700404548807

Epoch: 6| Step: 3
Training loss: 1.1865773381050662
Validation loss: 2.5110289326961563

Epoch: 6| Step: 4
Training loss: 1.4165445536922638
Validation loss: 2.4700110711430043

Epoch: 6| Step: 5
Training loss: 1.9405003358663235
Validation loss: 2.4956408484293493

Epoch: 6| Step: 6
Training loss: 1.3692608615903434
Validation loss: 2.489545061038066

Epoch: 6| Step: 7
Training loss: 1.2739716328227966
Validation loss: 2.5534414505374574

Epoch: 6| Step: 8
Training loss: 1.6959531074735008
Validation loss: 2.5657701018387646

Epoch: 6| Step: 9
Training loss: 1.5335849942439814
Validation loss: 2.6079753845433964

Epoch: 6| Step: 10
Training loss: 2.0882266624386068
Validation loss: 2.6263211422507484

Epoch: 6| Step: 11
Training loss: 1.5162204477271626
Validation loss: 2.5691062933845634

Epoch: 6| Step: 12
Training loss: 1.6458656533202511
Validation loss: 2.5640900648558236

Epoch: 6| Step: 13
Training loss: 1.594421095830351
Validation loss: 2.4970650133920356

Epoch: 318| Step: 0
Training loss: 1.5897402717975355
Validation loss: 2.4775055254153813

Epoch: 6| Step: 1
Training loss: 1.4537751578911844
Validation loss: 2.4929896292533873

Epoch: 6| Step: 2
Training loss: 0.8373792817524081
Validation loss: 2.519262617906308

Epoch: 6| Step: 3
Training loss: 1.5091267130783648
Validation loss: 2.491917945371198

Epoch: 6| Step: 4
Training loss: 1.087397136427389
Validation loss: 2.4958810332574295

Epoch: 6| Step: 5
Training loss: 1.2290629758041007
Validation loss: 2.5100010149220395

Epoch: 6| Step: 6
Training loss: 2.3805555317167886
Validation loss: 2.570793091465727

Epoch: 6| Step: 7
Training loss: 1.6161127619587208
Validation loss: 2.579113086971759

Epoch: 6| Step: 8
Training loss: 1.4112110367051443
Validation loss: 2.612167463174426

Epoch: 6| Step: 9
Training loss: 1.8029055033720862
Validation loss: 2.6433197807727846

Epoch: 6| Step: 10
Training loss: 1.375392814359301
Validation loss: 2.644457178848746

Epoch: 6| Step: 11
Training loss: 0.946224686801823
Validation loss: 2.6264296377611545

Epoch: 6| Step: 12
Training loss: 1.450635356479871
Validation loss: 2.6065280177502594

Epoch: 6| Step: 13
Training loss: 1.7325663027936478
Validation loss: 2.6053396609544133

Epoch: 319| Step: 0
Training loss: 1.491894758179149
Validation loss: 2.5819167488322297

Epoch: 6| Step: 1
Training loss: 1.5484828107038082
Validation loss: 2.571240637265648

Epoch: 6| Step: 2
Training loss: 1.468894058629793
Validation loss: 2.582647083767861

Epoch: 6| Step: 3
Training loss: 1.272663091614226
Validation loss: 2.589038338142694

Epoch: 6| Step: 4
Training loss: 1.4995873201442138
Validation loss: 2.630343795662098

Epoch: 6| Step: 5
Training loss: 1.6597375678395365
Validation loss: 2.5917349192063828

Epoch: 6| Step: 6
Training loss: 1.8796585702294997
Validation loss: 2.6078331936029864

Epoch: 6| Step: 7
Training loss: 1.0443534659831464
Validation loss: 2.575845762815407

Epoch: 6| Step: 8
Training loss: 1.3009041851248797
Validation loss: 2.5652610201570267

Epoch: 6| Step: 9
Training loss: 1.0216451193843452
Validation loss: 2.57600757459599

Epoch: 6| Step: 10
Training loss: 2.2978565428388444
Validation loss: 2.578912333477726

Epoch: 6| Step: 11
Training loss: 1.197790830333068
Validation loss: 2.5871025756949333

Epoch: 6| Step: 12
Training loss: 2.1918202925338526
Validation loss: 2.570254409272733

Epoch: 6| Step: 13
Training loss: 1.2459098656323535
Validation loss: 2.5684925388098847

Epoch: 320| Step: 0
Training loss: 1.585496662676525
Validation loss: 2.5610282672393048

Epoch: 6| Step: 1
Training loss: 1.4790994960237034
Validation loss: 2.5736549543432004

Epoch: 6| Step: 2
Training loss: 2.204769738040306
Validation loss: 2.5924829812443093

Epoch: 6| Step: 3
Training loss: 1.8610659691885596
Validation loss: 2.5255772638942684

Epoch: 6| Step: 4
Training loss: 1.3198675274843787
Validation loss: 2.508795461402732

Epoch: 6| Step: 5
Training loss: 1.3579011139745236
Validation loss: 2.484876713985357

Epoch: 6| Step: 6
Training loss: 1.0444555079661018
Validation loss: 2.4847374737620176

Epoch: 6| Step: 7
Training loss: 1.5985199102522623
Validation loss: 2.5610467309875076

Epoch: 6| Step: 8
Training loss: 1.4048906750076497
Validation loss: 2.5241518534992546

Epoch: 6| Step: 9
Training loss: 1.686655186298688
Validation loss: 2.588068703336466

Epoch: 6| Step: 10
Training loss: 1.8697472428027226
Validation loss: 2.5916635325209465

Epoch: 6| Step: 11
Training loss: 1.1107361730470078
Validation loss: 2.6054176657271277

Epoch: 6| Step: 12
Training loss: 1.9243853541433573
Validation loss: 2.5976043160584292

Epoch: 6| Step: 13
Training loss: 1.5580804500645309
Validation loss: 2.6297724346876095

Epoch: 321| Step: 0
Training loss: 1.1876331053974072
Validation loss: 2.6146535724663464

Epoch: 6| Step: 1
Training loss: 1.5190426548436673
Validation loss: 2.5529442457433307

Epoch: 6| Step: 2
Training loss: 1.466901143072277
Validation loss: 2.6020984269481433

Epoch: 6| Step: 3
Training loss: 1.5674065418764493
Validation loss: 2.5522227554125134

Epoch: 6| Step: 4
Training loss: 1.284262859711544
Validation loss: 2.4905973282141933

Epoch: 6| Step: 5
Training loss: 1.9263177399108422
Validation loss: 2.4624748796708253

Epoch: 6| Step: 6
Training loss: 1.4299129454250494
Validation loss: 2.4440123785488983

Epoch: 6| Step: 7
Training loss: 1.9277866901383462
Validation loss: 2.438852888407382

Epoch: 6| Step: 8
Training loss: 1.1691659768488383
Validation loss: 2.4135529722152835

Epoch: 6| Step: 9
Training loss: 1.59370325057335
Validation loss: 2.3934162607764327

Epoch: 6| Step: 10
Training loss: 1.54119794610721
Validation loss: 2.4293860179957796

Epoch: 6| Step: 11
Training loss: 1.0598478314201483
Validation loss: 2.4823964315491636

Epoch: 6| Step: 12
Training loss: 1.6444976875704138
Validation loss: 2.5412594880769594

Epoch: 6| Step: 13
Training loss: 1.7743543363942087
Validation loss: 2.550129984989632

Epoch: 322| Step: 0
Training loss: 1.1217127031757648
Validation loss: 2.5752581136773367

Epoch: 6| Step: 1
Training loss: 0.7821893004496904
Validation loss: 2.556043228205732

Epoch: 6| Step: 2
Training loss: 2.16272261691989
Validation loss: 2.618720172357144

Epoch: 6| Step: 3
Training loss: 2.03980905013154
Validation loss: 2.64290917374785

Epoch: 6| Step: 4
Training loss: 1.0547944756403351
Validation loss: 2.6736419144764687

Epoch: 6| Step: 5
Training loss: 1.2431388906371201
Validation loss: 2.646225402097842

Epoch: 6| Step: 6
Training loss: 1.6786291292239046
Validation loss: 2.63277383204287

Epoch: 6| Step: 7
Training loss: 1.5955553488316545
Validation loss: 2.6107272377174966

Epoch: 6| Step: 8
Training loss: 1.253303929822704
Validation loss: 2.7279231657719216

Epoch: 6| Step: 9
Training loss: 1.825199492538017
Validation loss: 2.736225061792381

Epoch: 6| Step: 10
Training loss: 1.284868573395843
Validation loss: 2.807410375082251

Epoch: 6| Step: 11
Training loss: 2.3501172868395006
Validation loss: 2.7778960446506384

Epoch: 6| Step: 12
Training loss: 1.3305931046633348
Validation loss: 2.6380094557451206

Epoch: 6| Step: 13
Training loss: 1.593584089432231
Validation loss: 2.601153856169131

Epoch: 323| Step: 0
Training loss: 1.8032300604454676
Validation loss: 2.567877562067977

Epoch: 6| Step: 1
Training loss: 0.9464493843062504
Validation loss: 2.541778942400747

Epoch: 6| Step: 2
Training loss: 0.9889824230688016
Validation loss: 2.533871960683656

Epoch: 6| Step: 3
Training loss: 1.3010948192692369
Validation loss: 2.540226126840321

Epoch: 6| Step: 4
Training loss: 1.2590714308856785
Validation loss: 2.5257437513930445

Epoch: 6| Step: 5
Training loss: 1.5874518319579405
Validation loss: 2.5318356295697786

Epoch: 6| Step: 6
Training loss: 1.5327247213414197
Validation loss: 2.543856979857381

Epoch: 6| Step: 7
Training loss: 1.4345998949255878
Validation loss: 2.506014265356234

Epoch: 6| Step: 8
Training loss: 1.3553495766966839
Validation loss: 2.5230317709821564

Epoch: 6| Step: 9
Training loss: 1.9577312017246333
Validation loss: 2.5327823459054764

Epoch: 6| Step: 10
Training loss: 1.8359815876313847
Validation loss: 2.5514678887702544

Epoch: 6| Step: 11
Training loss: 1.509701745975392
Validation loss: 2.6023132493449492

Epoch: 6| Step: 12
Training loss: 1.2608634955375908
Validation loss: 2.6286386520885263

Epoch: 6| Step: 13
Training loss: 2.0060535845764176
Validation loss: 2.6373776891108784

Epoch: 324| Step: 0
Training loss: 1.5814216852278171
Validation loss: 2.534413523289114

Epoch: 6| Step: 1
Training loss: 1.5860364159616096
Validation loss: 2.5684180114009196

Epoch: 6| Step: 2
Training loss: 1.4223020142947642
Validation loss: 2.569279394490591

Epoch: 6| Step: 3
Training loss: 1.4496190425680981
Validation loss: 2.582909631335449

Epoch: 6| Step: 4
Training loss: 1.3130253694005276
Validation loss: 2.56380224865625

Epoch: 6| Step: 5
Training loss: 1.9083570498307365
Validation loss: 2.6124733064130403

Epoch: 6| Step: 6
Training loss: 1.7677978379071597
Validation loss: 2.6102723274806885

Epoch: 6| Step: 7
Training loss: 1.3013233052034099
Validation loss: 2.620627576415972

Epoch: 6| Step: 8
Training loss: 1.4805193970403823
Validation loss: 2.637295521889699

Epoch: 6| Step: 9
Training loss: 1.2374412985085954
Validation loss: 2.604137280616264

Epoch: 6| Step: 10
Training loss: 1.4042708138500142
Validation loss: 2.601976073482245

Epoch: 6| Step: 11
Training loss: 1.236657796238415
Validation loss: 2.6284141287745184

Epoch: 6| Step: 12
Training loss: 1.3428002039235643
Validation loss: 2.5972862955396203

Epoch: 6| Step: 13
Training loss: 1.1699774574488244
Validation loss: 2.568726967540485

Epoch: 325| Step: 0
Training loss: 1.2265496708873262
Validation loss: 2.595863798482151

Epoch: 6| Step: 1
Training loss: 1.4639592055906288
Validation loss: 2.578248177100049

Epoch: 6| Step: 2
Training loss: 1.2982716221440342
Validation loss: 2.5757854828410705

Epoch: 6| Step: 3
Training loss: 1.7731154229191552
Validation loss: 2.5849270493539405

Epoch: 6| Step: 4
Training loss: 1.482780965905883
Validation loss: 2.5448098264138137

Epoch: 6| Step: 5
Training loss: 2.152607370283904
Validation loss: 2.5442417550483305

Epoch: 6| Step: 6
Training loss: 1.5900604325331997
Validation loss: 2.6002527707057066

Epoch: 6| Step: 7
Training loss: 1.2914863224671371
Validation loss: 2.532620926079033

Epoch: 6| Step: 8
Training loss: 1.374278225893919
Validation loss: 2.610123243430548

Epoch: 6| Step: 9
Training loss: 1.6441686234975708
Validation loss: 2.5963937774871018

Epoch: 6| Step: 10
Training loss: 1.310915353653887
Validation loss: 2.597380705251954

Epoch: 6| Step: 11
Training loss: 1.1564198961961694
Validation loss: 2.5774273631692384

Epoch: 6| Step: 12
Training loss: 1.3277375048661946
Validation loss: 2.5558705366138614

Epoch: 6| Step: 13
Training loss: 1.0532969031693753
Validation loss: 2.527051591372437

Epoch: 326| Step: 0
Training loss: 0.9655643505814776
Validation loss: 2.5296021266241864

Epoch: 6| Step: 1
Training loss: 1.963945308518153
Validation loss: 2.5481780293728815

Epoch: 6| Step: 2
Training loss: 1.9943057299197806
Validation loss: 2.548405224634516

Epoch: 6| Step: 3
Training loss: 1.5638532500481486
Validation loss: 2.5895311599430975

Epoch: 6| Step: 4
Training loss: 1.4455025212923358
Validation loss: 2.5719481175451566

Epoch: 6| Step: 5
Training loss: 1.3600700618424468
Validation loss: 2.551401776501755

Epoch: 6| Step: 6
Training loss: 1.1263852597727064
Validation loss: 2.5402535330026357

Epoch: 6| Step: 7
Training loss: 1.452977080661247
Validation loss: 2.657575613114245

Epoch: 6| Step: 8
Training loss: 1.4850036093157437
Validation loss: 2.6811545223851785

Epoch: 6| Step: 9
Training loss: 1.249583031727567
Validation loss: 2.7010360613753863

Epoch: 6| Step: 10
Training loss: 1.4749486267712444
Validation loss: 2.6285251834382093

Epoch: 6| Step: 11
Training loss: 1.266920015864901
Validation loss: 2.6926706534036073

Epoch: 6| Step: 12
Training loss: 0.8231089202422526
Validation loss: 2.6249110494407994

Epoch: 6| Step: 13
Training loss: 1.3908014078439779
Validation loss: 2.5958448016881315

Epoch: 327| Step: 0
Training loss: 1.2004360519339274
Validation loss: 2.567047147499427

Epoch: 6| Step: 1
Training loss: 1.9222785091917962
Validation loss: 2.596092453255159

Epoch: 6| Step: 2
Training loss: 1.430490653819833
Validation loss: 2.574622447226117

Epoch: 6| Step: 3
Training loss: 1.792096892164188
Validation loss: 2.614084740829328

Epoch: 6| Step: 4
Training loss: 1.8952418931355686
Validation loss: 2.5989895948060107

Epoch: 6| Step: 5
Training loss: 1.4684443866043013
Validation loss: 2.5638562621822034

Epoch: 6| Step: 6
Training loss: 1.3581639299285937
Validation loss: 2.539499614943122

Epoch: 6| Step: 7
Training loss: 1.2206369610975347
Validation loss: 2.614979840541908

Epoch: 6| Step: 8
Training loss: 1.2666644313859456
Validation loss: 2.6531973857013873

Epoch: 6| Step: 9
Training loss: 1.1678991392691473
Validation loss: 2.6587407644948695

Epoch: 6| Step: 10
Training loss: 1.6625889804518499
Validation loss: 2.7106588698670775

Epoch: 6| Step: 11
Training loss: 1.539433313613483
Validation loss: 2.613814728572539

Epoch: 6| Step: 12
Training loss: 1.509636284937227
Validation loss: 2.5861208755612943

Epoch: 6| Step: 13
Training loss: 1.2724725542687305
Validation loss: 2.543205144767321

Epoch: 328| Step: 0
Training loss: 1.2954199107953506
Validation loss: 2.557587046504496

Epoch: 6| Step: 1
Training loss: 1.2884618110963026
Validation loss: 2.574726816766067

Epoch: 6| Step: 2
Training loss: 1.6954872990511891
Validation loss: 2.5820447004759504

Epoch: 6| Step: 3
Training loss: 2.259540886283023
Validation loss: 2.62761946573835

Epoch: 6| Step: 4
Training loss: 1.628512840424168
Validation loss: 2.5840689293753765

Epoch: 6| Step: 5
Training loss: 1.493560319293521
Validation loss: 2.5651344155530595

Epoch: 6| Step: 6
Training loss: 1.5290043771605026
Validation loss: 2.573681680304587

Epoch: 6| Step: 7
Training loss: 0.9544489685852371
Validation loss: 2.570708595064862

Epoch: 6| Step: 8
Training loss: 1.717906883829324
Validation loss: 2.5724773469501527

Epoch: 6| Step: 9
Training loss: 1.5440387347704188
Validation loss: 2.5976362567027036

Epoch: 6| Step: 10
Training loss: 1.2495584661780892
Validation loss: 2.606199513776551

Epoch: 6| Step: 11
Training loss: 1.2577583822609106
Validation loss: 2.598513598922937

Epoch: 6| Step: 12
Training loss: 1.3788053999809184
Validation loss: 2.5607061387498904

Epoch: 6| Step: 13
Training loss: 1.1436534027832173
Validation loss: 2.5497700827549155

Epoch: 329| Step: 0
Training loss: 1.6702614957553445
Validation loss: 2.532776242937387

Epoch: 6| Step: 1
Training loss: 1.3696549302618972
Validation loss: 2.550793805950705

Epoch: 6| Step: 2
Training loss: 1.2471322542369376
Validation loss: 2.5500836745103466

Epoch: 6| Step: 3
Training loss: 0.9827895035956775
Validation loss: 2.6092344082478

Epoch: 6| Step: 4
Training loss: 1.2768737674955524
Validation loss: 2.5969417038608604

Epoch: 6| Step: 5
Training loss: 0.8783613423134843
Validation loss: 2.5672785545665797

Epoch: 6| Step: 6
Training loss: 1.5516238289781554
Validation loss: 2.6092929103829614

Epoch: 6| Step: 7
Training loss: 1.7892196119861228
Validation loss: 2.6273231671151227

Epoch: 6| Step: 8
Training loss: 1.4807977235398397
Validation loss: 2.625993116919355

Epoch: 6| Step: 9
Training loss: 1.2208707892668589
Validation loss: 2.648945042412692

Epoch: 6| Step: 10
Training loss: 1.4720422086883773
Validation loss: 2.6126257012895002

Epoch: 6| Step: 11
Training loss: 1.5645089014518798
Validation loss: 2.6439636913659372

Epoch: 6| Step: 12
Training loss: 1.4840597520659424
Validation loss: 2.6189859464534635

Epoch: 6| Step: 13
Training loss: 1.2036989502663507
Validation loss: 2.6588893418533757

Epoch: 330| Step: 0
Training loss: 1.405940509223982
Validation loss: 2.5719356185178075

Epoch: 6| Step: 1
Training loss: 1.2964895204060953
Validation loss: 2.5599140672367415

Epoch: 6| Step: 2
Training loss: 1.3275019811267044
Validation loss: 2.592635141097964

Epoch: 6| Step: 3
Training loss: 1.3834421911649095
Validation loss: 2.5971535561970844

Epoch: 6| Step: 4
Training loss: 1.682662600160714
Validation loss: 2.621638552674014

Epoch: 6| Step: 5
Training loss: 1.1073772011009566
Validation loss: 2.588532896174125

Epoch: 6| Step: 6
Training loss: 1.258458984282547
Validation loss: 2.5704303625538287

Epoch: 6| Step: 7
Training loss: 1.57493313844238
Validation loss: 2.5629225126706388

Epoch: 6| Step: 8
Training loss: 1.756045525753614
Validation loss: 2.5860334457315552

Epoch: 6| Step: 9
Training loss: 1.135348933354839
Validation loss: 2.6067383592979265

Epoch: 6| Step: 10
Training loss: 1.003695098401611
Validation loss: 2.6455755083114156

Epoch: 6| Step: 11
Training loss: 1.1621500472957458
Validation loss: 2.657495049788708

Epoch: 6| Step: 12
Training loss: 1.5121573666973633
Validation loss: 2.6263788174546443

Epoch: 6| Step: 13
Training loss: 1.5203204226311908
Validation loss: 2.616996947985803

Epoch: 331| Step: 0
Training loss: 1.195487813621833
Validation loss: 2.587560077405929

Epoch: 6| Step: 1
Training loss: 1.5155542888073616
Validation loss: 2.62323771464459

Epoch: 6| Step: 2
Training loss: 1.409170635826135
Validation loss: 2.624477016485693

Epoch: 6| Step: 3
Training loss: 1.0611279548408852
Validation loss: 2.610492428966202

Epoch: 6| Step: 4
Training loss: 1.4477137233567734
Validation loss: 2.602179071412665

Epoch: 6| Step: 5
Training loss: 1.9549176343655301
Validation loss: 2.60486119481998

Epoch: 6| Step: 6
Training loss: 1.6114373927203467
Validation loss: 2.6008877265748245

Epoch: 6| Step: 7
Training loss: 1.1792129673758545
Validation loss: 2.607208403231834

Epoch: 6| Step: 8
Training loss: 1.0200839828062414
Validation loss: 2.625713312022462

Epoch: 6| Step: 9
Training loss: 1.1679841617855984
Validation loss: 2.5675241792475716

Epoch: 6| Step: 10
Training loss: 1.027822636722209
Validation loss: 2.6023467354865666

Epoch: 6| Step: 11
Training loss: 1.7779229530358627
Validation loss: 2.6201409371885322

Epoch: 6| Step: 12
Training loss: 1.3573048932281768
Validation loss: 2.545664337675954

Epoch: 6| Step: 13
Training loss: 1.2989264200058575
Validation loss: 2.5413908000968557

Epoch: 332| Step: 0
Training loss: 1.1265770137449813
Validation loss: 2.5232538682005985

Epoch: 6| Step: 1
Training loss: 1.1353527132740813
Validation loss: 2.519333895265399

Epoch: 6| Step: 2
Training loss: 1.147296520384748
Validation loss: 2.5390111673496896

Epoch: 6| Step: 3
Training loss: 1.4974427677483653
Validation loss: 2.4965220020800967

Epoch: 6| Step: 4
Training loss: 1.7153518375911383
Validation loss: 2.5306321791200563

Epoch: 6| Step: 5
Training loss: 2.2391793411553014
Validation loss: 2.505604509736266

Epoch: 6| Step: 6
Training loss: 1.0985314623390534
Validation loss: 2.520484716306384

Epoch: 6| Step: 7
Training loss: 1.345677878000423
Validation loss: 2.5000434076991227

Epoch: 6| Step: 8
Training loss: 1.167660930986081
Validation loss: 2.585517603348355

Epoch: 6| Step: 9
Training loss: 1.559549368548708
Validation loss: 2.521290687708068

Epoch: 6| Step: 10
Training loss: 1.336783514900767
Validation loss: 2.5084377155150994

Epoch: 6| Step: 11
Training loss: 1.1450472244785412
Validation loss: 2.51143243956432

Epoch: 6| Step: 12
Training loss: 1.0695801617157152
Validation loss: 2.524389585355422

Epoch: 6| Step: 13
Training loss: 1.1508868819661588
Validation loss: 2.505768542131341

Epoch: 333| Step: 0
Training loss: 0.860305906160348
Validation loss: 2.5407580695469085

Epoch: 6| Step: 1
Training loss: 1.0899291739945036
Validation loss: 2.5754490383672684

Epoch: 6| Step: 2
Training loss: 1.507989902634548
Validation loss: 2.563612068591174

Epoch: 6| Step: 3
Training loss: 1.0143210623662582
Validation loss: 2.5436684172823454

Epoch: 6| Step: 4
Training loss: 1.2478964271666062
Validation loss: 2.5543696743398066

Epoch: 6| Step: 5
Training loss: 1.2959384523953483
Validation loss: 2.6053329348493888

Epoch: 6| Step: 6
Training loss: 1.283323331686572
Validation loss: 2.592681618769088

Epoch: 6| Step: 7
Training loss: 1.1737937477904667
Validation loss: 2.603845306913295

Epoch: 6| Step: 8
Training loss: 1.236862235984076
Validation loss: 2.630482534084114

Epoch: 6| Step: 9
Training loss: 1.7492676973841987
Validation loss: 2.628014241718506

Epoch: 6| Step: 10
Training loss: 1.2606291893892743
Validation loss: 2.559388822922662

Epoch: 6| Step: 11
Training loss: 1.961174331284812
Validation loss: 2.5823778928759005

Epoch: 6| Step: 12
Training loss: 1.840250087825616
Validation loss: 2.6082901669750145

Epoch: 6| Step: 13
Training loss: 0.8600694451460216
Validation loss: 2.6132489987879337

Epoch: 334| Step: 0
Training loss: 1.1488376361514172
Validation loss: 2.596500133720819

Epoch: 6| Step: 1
Training loss: 1.3735263904192823
Validation loss: 2.5770147688144798

Epoch: 6| Step: 2
Training loss: 1.524856923379956
Validation loss: 2.611150202447266

Epoch: 6| Step: 3
Training loss: 1.8543346914674643
Validation loss: 2.59805726132563

Epoch: 6| Step: 4
Training loss: 1.1038431137398903
Validation loss: 2.5817328283978127

Epoch: 6| Step: 5
Training loss: 1.100540498677273
Validation loss: 2.5953537605645205

Epoch: 6| Step: 6
Training loss: 1.3168179465356011
Validation loss: 2.5875069272598195

Epoch: 6| Step: 7
Training loss: 1.3454827071389512
Validation loss: 2.618671250961173

Epoch: 6| Step: 8
Training loss: 1.1142493606233463
Validation loss: 2.594306686900062

Epoch: 6| Step: 9
Training loss: 1.2734517289753364
Validation loss: 2.5278236212666343

Epoch: 6| Step: 10
Training loss: 1.3985457991109904
Validation loss: 2.5682900925878003

Epoch: 6| Step: 11
Training loss: 1.2006913379172788
Validation loss: 2.6047490854654374

Epoch: 6| Step: 12
Training loss: 1.1368050558878435
Validation loss: 2.5721318416036985

Epoch: 6| Step: 13
Training loss: 1.5924702910761648
Validation loss: 2.5596082078868783

Epoch: 335| Step: 0
Training loss: 1.2466926689972138
Validation loss: 2.541447666509713

Epoch: 6| Step: 1
Training loss: 1.4273257734130274
Validation loss: 2.5902859179448687

Epoch: 6| Step: 2
Training loss: 1.6959982333354027
Validation loss: 2.580790011204827

Epoch: 6| Step: 3
Training loss: 0.9995062920628514
Validation loss: 2.5664492312721854

Epoch: 6| Step: 4
Training loss: 1.151954404067671
Validation loss: 2.570626731455849

Epoch: 6| Step: 5
Training loss: 1.6408006846504142
Validation loss: 2.635583538054648

Epoch: 6| Step: 6
Training loss: 1.028307734427912
Validation loss: 2.5559371396147017

Epoch: 6| Step: 7
Training loss: 1.3920771699594072
Validation loss: 2.575287307216713

Epoch: 6| Step: 8
Training loss: 1.2049121711506914
Validation loss: 2.549487764982402

Epoch: 6| Step: 9
Training loss: 1.0097414231489787
Validation loss: 2.5609476303015044

Epoch: 6| Step: 10
Training loss: 1.1583000258361345
Validation loss: 2.569101970347593

Epoch: 6| Step: 11
Training loss: 1.3291539413815605
Validation loss: 2.6153731856520714

Epoch: 6| Step: 12
Training loss: 1.2068063964784235
Validation loss: 2.546151750841711

Epoch: 6| Step: 13
Training loss: 1.6372895258397522
Validation loss: 2.5941984562611498

Epoch: 336| Step: 0
Training loss: 1.3686133225016226
Validation loss: 2.5720397803729007

Epoch: 6| Step: 1
Training loss: 1.433731030951468
Validation loss: 2.601885648557944

Epoch: 6| Step: 2
Training loss: 1.1345189888526326
Validation loss: 2.5538061178934313

Epoch: 6| Step: 3
Training loss: 1.0719684126384985
Validation loss: 2.5563236950337678

Epoch: 6| Step: 4
Training loss: 1.0794610852943782
Validation loss: 2.5987535649566147

Epoch: 6| Step: 5
Training loss: 1.9294337673400141
Validation loss: 2.5592043858982945

Epoch: 6| Step: 6
Training loss: 1.293930940368296
Validation loss: 2.603155234696685

Epoch: 6| Step: 7
Training loss: 1.2922594597002153
Validation loss: 2.6404210224409645

Epoch: 6| Step: 8
Training loss: 1.341614778869813
Validation loss: 2.5861601488777355

Epoch: 6| Step: 9
Training loss: 1.44131576957082
Validation loss: 2.526830653561725

Epoch: 6| Step: 10
Training loss: 1.012114164045893
Validation loss: 2.5264625172519986

Epoch: 6| Step: 11
Training loss: 1.3569532724486164
Validation loss: 2.5569658143035006

Epoch: 6| Step: 12
Training loss: 1.5949922843674738
Validation loss: 2.547071297224668

Epoch: 6| Step: 13
Training loss: 0.9759642332472752
Validation loss: 2.555496492141011

Epoch: 337| Step: 0
Training loss: 1.0301220823361674
Validation loss: 2.5555525471029217

Epoch: 6| Step: 1
Training loss: 2.0157030667113185
Validation loss: 2.6205041774703597

Epoch: 6| Step: 2
Training loss: 1.2125090215288372
Validation loss: 2.5895544535918273

Epoch: 6| Step: 3
Training loss: 1.1555091443329317
Validation loss: 2.5480637847605965

Epoch: 6| Step: 4
Training loss: 1.19392194458284
Validation loss: 2.5537111086629563

Epoch: 6| Step: 5
Training loss: 1.1869194719882745
Validation loss: 2.553369522369471

Epoch: 6| Step: 6
Training loss: 1.1492980535492214
Validation loss: 2.5737609147415816

Epoch: 6| Step: 7
Training loss: 0.9981279732140942
Validation loss: 2.566192323854438

Epoch: 6| Step: 8
Training loss: 1.1923466207524451
Validation loss: 2.5886417934975703

Epoch: 6| Step: 9
Training loss: 1.7651294249071294
Validation loss: 2.6095128889065844

Epoch: 6| Step: 10
Training loss: 1.4463386810466448
Validation loss: 2.574320380636379

Epoch: 6| Step: 11
Training loss: 1.0001063290333476
Validation loss: 2.5733049436923734

Epoch: 6| Step: 12
Training loss: 1.1541165954984547
Validation loss: 2.55938031479777

Epoch: 6| Step: 13
Training loss: 0.9795517603822707
Validation loss: 2.556983188480892

Epoch: 338| Step: 0
Training loss: 0.926026967593157
Validation loss: 2.5801084344832113

Epoch: 6| Step: 1
Training loss: 1.3148443991556906
Validation loss: 2.593138044239751

Epoch: 6| Step: 2
Training loss: 0.9945834209845358
Validation loss: 2.546111618498999

Epoch: 6| Step: 3
Training loss: 1.3996322472396534
Validation loss: 2.579965878243745

Epoch: 6| Step: 4
Training loss: 1.3923079347589997
Validation loss: 2.555601712745279

Epoch: 6| Step: 5
Training loss: 1.6780473375020095
Validation loss: 2.576303196727533

Epoch: 6| Step: 6
Training loss: 1.2718879305395476
Validation loss: 2.561421733489747

Epoch: 6| Step: 7
Training loss: 1.1739264270922543
Validation loss: 2.5828625085892907

Epoch: 6| Step: 8
Training loss: 1.3065332844754005
Validation loss: 2.5906174982113392

Epoch: 6| Step: 9
Training loss: 1.358984397807043
Validation loss: 2.6166918688570813

Epoch: 6| Step: 10
Training loss: 1.034002733806191
Validation loss: 2.587529271646684

Epoch: 6| Step: 11
Training loss: 1.1446463881766102
Validation loss: 2.603585542053387

Epoch: 6| Step: 12
Training loss: 1.2637462092945513
Validation loss: 2.6353720308124955

Epoch: 6| Step: 13
Training loss: 1.4980356546750189
Validation loss: 2.6635246740780545

Epoch: 339| Step: 0
Training loss: 1.5943267377115744
Validation loss: 2.657545977817059

Epoch: 6| Step: 1
Training loss: 1.0620472448260552
Validation loss: 2.6943575729270206

Epoch: 6| Step: 2
Training loss: 1.2364018856662378
Validation loss: 2.603981398032098

Epoch: 6| Step: 3
Training loss: 1.1542560809006035
Validation loss: 2.579043785294477

Epoch: 6| Step: 4
Training loss: 1.6629064421632938
Validation loss: 2.578121023464026

Epoch: 6| Step: 5
Training loss: 1.1959543437185285
Validation loss: 2.5240571213010363

Epoch: 6| Step: 6
Training loss: 1.7792229076969073
Validation loss: 2.5090116048498623

Epoch: 6| Step: 7
Training loss: 1.199556880834613
Validation loss: 2.559140274655409

Epoch: 6| Step: 8
Training loss: 1.4581852247323333
Validation loss: 2.5617380792777182

Epoch: 6| Step: 9
Training loss: 1.2630910585157176
Validation loss: 2.5679107854444543

Epoch: 6| Step: 10
Training loss: 1.00876330096281
Validation loss: 2.585066949418874

Epoch: 6| Step: 11
Training loss: 1.03022159970301
Validation loss: 2.596847936165594

Epoch: 6| Step: 12
Training loss: 1.321384333455509
Validation loss: 2.580663413946529

Epoch: 6| Step: 13
Training loss: 0.8201156379992135
Validation loss: 2.5890426969567026

Epoch: 340| Step: 0
Training loss: 1.8894461747775702
Validation loss: 2.6067939678515892

Epoch: 6| Step: 1
Training loss: 1.4251947738313957
Validation loss: 2.5822534047182897

Epoch: 6| Step: 2
Training loss: 1.368638494818223
Validation loss: 2.583066054843132

Epoch: 6| Step: 3
Training loss: 1.075666970337962
Validation loss: 2.6148977863133416

Epoch: 6| Step: 4
Training loss: 1.1446458153785275
Validation loss: 2.6247189462156193

Epoch: 6| Step: 5
Training loss: 1.270333702595508
Validation loss: 2.655421902096568

Epoch: 6| Step: 6
Training loss: 0.9913446646245643
Validation loss: 2.6206086833193285

Epoch: 6| Step: 7
Training loss: 1.5574328848643635
Validation loss: 2.6061556938545234

Epoch: 6| Step: 8
Training loss: 1.2950041731837132
Validation loss: 2.5991803356649834

Epoch: 6| Step: 9
Training loss: 1.4958294268940502
Validation loss: 2.554882520412163

Epoch: 6| Step: 10
Training loss: 1.0614830648119777
Validation loss: 2.596071055034998

Epoch: 6| Step: 11
Training loss: 0.8776835774491117
Validation loss: 2.526774024326551

Epoch: 6| Step: 12
Training loss: 1.180102445875196
Validation loss: 2.599112211168404

Epoch: 6| Step: 13
Training loss: 1.1185731630846039
Validation loss: 2.543944890759922

Epoch: 341| Step: 0
Training loss: 1.3086797885223964
Validation loss: 2.6276795320064856

Epoch: 6| Step: 1
Training loss: 1.4434892030793782
Validation loss: 2.5966684399289828

Epoch: 6| Step: 2
Training loss: 1.3493039880100912
Validation loss: 2.5896860480301584

Epoch: 6| Step: 3
Training loss: 1.1564757152568932
Validation loss: 2.601207903732641

Epoch: 6| Step: 4
Training loss: 0.8767920943076071
Validation loss: 2.6004105042128507

Epoch: 6| Step: 5
Training loss: 1.4980389173313742
Validation loss: 2.6424567736768623

Epoch: 6| Step: 6
Training loss: 1.1188183598438168
Validation loss: 2.5793803539918425

Epoch: 6| Step: 7
Training loss: 0.966964984496528
Validation loss: 2.5631578267868163

Epoch: 6| Step: 8
Training loss: 1.1528512645314286
Validation loss: 2.56741330281161

Epoch: 6| Step: 9
Training loss: 1.6660957630198614
Validation loss: 2.565431267396973

Epoch: 6| Step: 10
Training loss: 0.9208217358326332
Validation loss: 2.5236630176596244

Epoch: 6| Step: 11
Training loss: 1.3839454104897702
Validation loss: 2.5461092618844496

Epoch: 6| Step: 12
Training loss: 1.6330033332244063
Validation loss: 2.534866308590688

Epoch: 6| Step: 13
Training loss: 1.1590015560531375
Validation loss: 2.494019443930722

Epoch: 342| Step: 0
Training loss: 1.4412537367442275
Validation loss: 2.527603906431931

Epoch: 6| Step: 1
Training loss: 1.396205804956967
Validation loss: 2.5177519752803525

Epoch: 6| Step: 2
Training loss: 1.2912695284434887
Validation loss: 2.536983793271808

Epoch: 6| Step: 3
Training loss: 1.100629641486827
Validation loss: 2.504625420486205

Epoch: 6| Step: 4
Training loss: 1.4598742200939343
Validation loss: 2.543649249381844

Epoch: 6| Step: 5
Training loss: 1.369273833625479
Validation loss: 2.5757068120744573

Epoch: 6| Step: 6
Training loss: 1.5584730517468823
Validation loss: 2.5266402698721557

Epoch: 6| Step: 7
Training loss: 1.0875129523547324
Validation loss: 2.570338364058423

Epoch: 6| Step: 8
Training loss: 1.1197785428483162
Validation loss: 2.548759738204435

Epoch: 6| Step: 9
Training loss: 1.181792446503166
Validation loss: 2.523110761245567

Epoch: 6| Step: 10
Training loss: 1.2172724252242404
Validation loss: 2.599925200902496

Epoch: 6| Step: 11
Training loss: 0.9219483168591125
Validation loss: 2.586393886525781

Epoch: 6| Step: 12
Training loss: 1.2015554420452403
Validation loss: 2.571613805585655

Epoch: 6| Step: 13
Training loss: 1.1975152158467333
Validation loss: 2.5760392662702505

Epoch: 343| Step: 0
Training loss: 1.309780027251751
Validation loss: 2.583171613820136

Epoch: 6| Step: 1
Training loss: 1.7868083762910851
Validation loss: 2.5757387157164495

Epoch: 6| Step: 2
Training loss: 1.087518707202184
Validation loss: 2.6258857080516043

Epoch: 6| Step: 3
Training loss: 1.3754585108516206
Validation loss: 2.5363354401840597

Epoch: 6| Step: 4
Training loss: 1.5454923056513068
Validation loss: 2.577725288925039

Epoch: 6| Step: 5
Training loss: 1.0049167994320838
Validation loss: 2.588978756716888

Epoch: 6| Step: 6
Training loss: 1.2936260938050939
Validation loss: 2.5303400546940162

Epoch: 6| Step: 7
Training loss: 1.0096613167874684
Validation loss: 2.55350987534549

Epoch: 6| Step: 8
Training loss: 0.9687041302557969
Validation loss: 2.550219557229771

Epoch: 6| Step: 9
Training loss: 0.8624588514270206
Validation loss: 2.6142458045597246

Epoch: 6| Step: 10
Training loss: 1.3742892422360307
Validation loss: 2.5389712508017426

Epoch: 6| Step: 11
Training loss: 1.325627210903887
Validation loss: 2.5780470556941926

Epoch: 6| Step: 12
Training loss: 0.8823890007822384
Validation loss: 2.532056389605092

Epoch: 6| Step: 13
Training loss: 1.4004800892959979
Validation loss: 2.539652774373584

Epoch: 344| Step: 0
Training loss: 1.235644400043461
Validation loss: 2.5639020914178907

Epoch: 6| Step: 1
Training loss: 1.2448365377641208
Validation loss: 2.611889326402099

Epoch: 6| Step: 2
Training loss: 1.4295358212583777
Validation loss: 2.6344875663096614

Epoch: 6| Step: 3
Training loss: 1.124740888637955
Validation loss: 2.5530201081448936

Epoch: 6| Step: 4
Training loss: 1.206531063007199
Validation loss: 2.5749276882499412

Epoch: 6| Step: 5
Training loss: 1.029669735745143
Validation loss: 2.6166286194418404

Epoch: 6| Step: 6
Training loss: 1.0922742424438
Validation loss: 2.6133650009351532

Epoch: 6| Step: 7
Training loss: 0.7723884017974384
Validation loss: 2.6589269575167616

Epoch: 6| Step: 8
Training loss: 1.7953950177411138
Validation loss: 2.6477872412200263

Epoch: 6| Step: 9
Training loss: 1.4197796484069343
Validation loss: 2.5999809093263533

Epoch: 6| Step: 10
Training loss: 1.4465277434298338
Validation loss: 2.649134256389253

Epoch: 6| Step: 11
Training loss: 1.114266424789378
Validation loss: 2.613360165714517

Epoch: 6| Step: 12
Training loss: 1.0314950362884425
Validation loss: 2.5565384780531737

Epoch: 6| Step: 13
Training loss: 0.9523666366568421
Validation loss: 2.5338770416784984

Epoch: 345| Step: 0
Training loss: 1.7791345985018059
Validation loss: 2.598126514670822

Epoch: 6| Step: 1
Training loss: 0.8582107286632961
Validation loss: 2.644559708878367

Epoch: 6| Step: 2
Training loss: 1.4063106947622337
Validation loss: 2.5472036200393817

Epoch: 6| Step: 3
Training loss: 1.5987877604638563
Validation loss: 2.607079156456978

Epoch: 6| Step: 4
Training loss: 0.855418303931432
Validation loss: 2.564781166046695

Epoch: 6| Step: 5
Training loss: 1.1587941814999438
Validation loss: 2.541298391416503

Epoch: 6| Step: 6
Training loss: 1.5266554274138366
Validation loss: 2.572527756944389

Epoch: 6| Step: 7
Training loss: 1.2973062189005895
Validation loss: 2.59463851141854

Epoch: 6| Step: 8
Training loss: 1.053813430849975
Validation loss: 2.569478573157212

Epoch: 6| Step: 9
Training loss: 0.9576371124142908
Validation loss: 2.5512443928187354

Epoch: 6| Step: 10
Training loss: 1.2346152542593196
Validation loss: 2.577145168721086

Epoch: 6| Step: 11
Training loss: 1.2605681945681235
Validation loss: 2.577083647061583

Epoch: 6| Step: 12
Training loss: 1.36865234375
Validation loss: 2.586946626666816

Epoch: 6| Step: 13
Training loss: 1.0804198898775388
Validation loss: 2.6214177802603613

Epoch: 346| Step: 0
Training loss: 1.083779475461348
Validation loss: 2.627958114472163

Epoch: 6| Step: 1
Training loss: 0.7613084910930537
Validation loss: 2.6003801104651196

Epoch: 6| Step: 2
Training loss: 1.6199876803647895
Validation loss: 2.6095027473534165

Epoch: 6| Step: 3
Training loss: 0.8480570676130447
Validation loss: 2.627566694906747

Epoch: 6| Step: 4
Training loss: 1.2175064589624798
Validation loss: 2.676331875989033

Epoch: 6| Step: 5
Training loss: 1.0885228728842473
Validation loss: 2.678261817870685

Epoch: 6| Step: 6
Training loss: 1.2814808614271382
Validation loss: 2.7515587001747583

Epoch: 6| Step: 7
Training loss: 1.1208646852629793
Validation loss: 2.675072688009399

Epoch: 6| Step: 8
Training loss: 1.3218591423075496
Validation loss: 2.654989152743684

Epoch: 6| Step: 9
Training loss: 1.4657413428355257
Validation loss: 2.650433758558257

Epoch: 6| Step: 10
Training loss: 1.1094690739678161
Validation loss: 2.6336459567812773

Epoch: 6| Step: 11
Training loss: 1.3170259641377662
Validation loss: 2.614204809948048

Epoch: 6| Step: 12
Training loss: 1.4353718138369305
Validation loss: 2.5930482458924122

Epoch: 6| Step: 13
Training loss: 1.1476670360123256
Validation loss: 2.584307076892724

Epoch: 347| Step: 0
Training loss: 1.5240108878129728
Validation loss: 2.5800804428871786

Epoch: 6| Step: 1
Training loss: 0.9711416930856775
Validation loss: 2.585508043906553

Epoch: 6| Step: 2
Training loss: 1.2617089238684713
Validation loss: 2.585542370130033

Epoch: 6| Step: 3
Training loss: 1.489995974848898
Validation loss: 2.5382357146222665

Epoch: 6| Step: 4
Training loss: 1.511601248814879
Validation loss: 2.543023956058984

Epoch: 6| Step: 5
Training loss: 0.7978029271293718
Validation loss: 2.5126888760858503

Epoch: 6| Step: 6
Training loss: 1.668406873422977
Validation loss: 2.572791931794178

Epoch: 6| Step: 7
Training loss: 0.9654327324617228
Validation loss: 2.609991568019493

Epoch: 6| Step: 8
Training loss: 0.9651735799949477
Validation loss: 2.586783563632773

Epoch: 6| Step: 9
Training loss: 0.9755598490513617
Validation loss: 2.5863817338563755

Epoch: 6| Step: 10
Training loss: 1.6419112476751931
Validation loss: 2.63159777260204

Epoch: 6| Step: 11
Training loss: 1.1164063610506636
Validation loss: 2.6148202315124713

Epoch: 6| Step: 12
Training loss: 1.0433290694965178
Validation loss: 2.6326134792309026

Epoch: 6| Step: 13
Training loss: 1.1324122280777114
Validation loss: 2.6267255530880895

Epoch: 348| Step: 0
Training loss: 1.513315781576964
Validation loss: 2.652741737076515

Epoch: 6| Step: 1
Training loss: 0.9229800503208359
Validation loss: 2.6341277326606707

Epoch: 6| Step: 2
Training loss: 1.1644437024932743
Validation loss: 2.614265959628072

Epoch: 6| Step: 3
Training loss: 1.1097316974420517
Validation loss: 2.649973571093742

Epoch: 6| Step: 4
Training loss: 1.093543496392298
Validation loss: 2.643266789711973

Epoch: 6| Step: 5
Training loss: 1.2691075953268247
Validation loss: 2.7288497323394796

Epoch: 6| Step: 6
Training loss: 1.3595922888366254
Validation loss: 2.6354175060004503

Epoch: 6| Step: 7
Training loss: 1.177842775736583
Validation loss: 2.655736791361993

Epoch: 6| Step: 8
Training loss: 0.9202897617918362
Validation loss: 2.5885450310688425

Epoch: 6| Step: 9
Training loss: 1.5940271024469976
Validation loss: 2.6521720100275012

Epoch: 6| Step: 10
Training loss: 1.2344300463027817
Validation loss: 2.644207016542541

Epoch: 6| Step: 11
Training loss: 1.1447156946290862
Validation loss: 2.6054168345222886

Epoch: 6| Step: 12
Training loss: 1.1078604447033726
Validation loss: 2.5821628585108107

Epoch: 6| Step: 13
Training loss: 1.059649233361959
Validation loss: 2.529769951409544

Epoch: 349| Step: 0
Training loss: 1.0819433293617737
Validation loss: 2.550473625478985

Epoch: 6| Step: 1
Training loss: 1.2904436515143793
Validation loss: 2.5683678533803342

Epoch: 6| Step: 2
Training loss: 1.3827697402463708
Validation loss: 2.556592427443698

Epoch: 6| Step: 3
Training loss: 1.2235971066561981
Validation loss: 2.561650298129791

Epoch: 6| Step: 4
Training loss: 1.1979374206514284
Validation loss: 2.563306914029269

Epoch: 6| Step: 5
Training loss: 1.1180846873266634
Validation loss: 2.5119987952625316

Epoch: 6| Step: 6
Training loss: 0.8611216741002897
Validation loss: 2.517186898235973

Epoch: 6| Step: 7
Training loss: 0.9100259843197589
Validation loss: 2.5391496535773395

Epoch: 6| Step: 8
Training loss: 1.4403591746512232
Validation loss: 2.5301460715986135

Epoch: 6| Step: 9
Training loss: 1.2813064748831617
Validation loss: 2.5869364888097692

Epoch: 6| Step: 10
Training loss: 1.0034207606218764
Validation loss: 2.596702901720423

Epoch: 6| Step: 11
Training loss: 1.173826550880938
Validation loss: 2.5708387738566483

Epoch: 6| Step: 12
Training loss: 0.9325601130891463
Validation loss: 2.646288664878759

Epoch: 6| Step: 13
Training loss: 1.1270466307882703
Validation loss: 2.6210820159422052

Epoch: 350| Step: 0
Training loss: 1.3223877347518138
Validation loss: 2.619594063457512

Epoch: 6| Step: 1
Training loss: 0.9396703393635917
Validation loss: 2.5939967333014002

Epoch: 6| Step: 2
Training loss: 0.766249732659995
Validation loss: 2.6997395595872997

Epoch: 6| Step: 3
Training loss: 1.5893325171153856
Validation loss: 2.7236073099417073

Epoch: 6| Step: 4
Training loss: 1.2912693438045804
Validation loss: 2.6236441607525545

Epoch: 6| Step: 5
Training loss: 1.0095101186350064
Validation loss: 2.6519812297319807

Epoch: 6| Step: 6
Training loss: 1.3672483594155316
Validation loss: 2.6902132162989565

Epoch: 6| Step: 7
Training loss: 1.4153439948144149
Validation loss: 2.658610622648778

Epoch: 6| Step: 8
Training loss: 0.8815557260668868
Validation loss: 2.630569332515952

Epoch: 6| Step: 9
Training loss: 1.4871431740160672
Validation loss: 2.621477109462913

Epoch: 6| Step: 10
Training loss: 0.9678953153696878
Validation loss: 2.560930073548698

Epoch: 6| Step: 11
Training loss: 1.1350975404746508
Validation loss: 2.655333641410744

Epoch: 6| Step: 12
Training loss: 0.9131113956594664
Validation loss: 2.574354022518571

Epoch: 6| Step: 13
Training loss: 1.0510889900273264
Validation loss: 2.5953236903669548

Epoch: 351| Step: 0
Training loss: 0.7790221683790448
Validation loss: 2.5658837594105948

Epoch: 6| Step: 1
Training loss: 1.1284435868501836
Validation loss: 2.5765446452734166

Epoch: 6| Step: 2
Training loss: 0.7868378125796995
Validation loss: 2.5664221512966208

Epoch: 6| Step: 3
Training loss: 0.8533948380748869
Validation loss: 2.641166631463384

Epoch: 6| Step: 4
Training loss: 0.9288871910764407
Validation loss: 2.6177264972810006

Epoch: 6| Step: 5
Training loss: 2.0453275698929163
Validation loss: 2.578837255868357

Epoch: 6| Step: 6
Training loss: 1.1892170789298653
Validation loss: 2.5819956997777234

Epoch: 6| Step: 7
Training loss: 1.2667837607486852
Validation loss: 2.6516530968754237

Epoch: 6| Step: 8
Training loss: 1.1071042205731476
Validation loss: 2.6186584134955915

Epoch: 6| Step: 9
Training loss: 1.0286896450836884
Validation loss: 2.644893544415828

Epoch: 6| Step: 10
Training loss: 1.1487517154087215
Validation loss: 2.6579710601927564

Epoch: 6| Step: 11
Training loss: 1.1394475843251046
Validation loss: 2.73050764981176

Epoch: 6| Step: 12
Training loss: 1.134318330888823
Validation loss: 2.662445174057192

Epoch: 6| Step: 13
Training loss: 1.2864851183039836
Validation loss: 2.5982335723051264

Epoch: 352| Step: 0
Training loss: 1.0647701246370984
Validation loss: 2.6227015923474464

Epoch: 6| Step: 1
Training loss: 1.4868876823791992
Validation loss: 2.625918636342791

Epoch: 6| Step: 2
Training loss: 1.20052512520487
Validation loss: 2.591762991911071

Epoch: 6| Step: 3
Training loss: 1.1975627984641386
Validation loss: 2.5586087680210885

Epoch: 6| Step: 4
Training loss: 1.0699286782033444
Validation loss: 2.524500557003664

Epoch: 6| Step: 5
Training loss: 1.1903421621715384
Validation loss: 2.5756033693568723

Epoch: 6| Step: 6
Training loss: 1.1672116380516582
Validation loss: 2.5540381334415843

Epoch: 6| Step: 7
Training loss: 1.0580347140481645
Validation loss: 2.5582610945386315

Epoch: 6| Step: 8
Training loss: 1.1899240247531577
Validation loss: 2.5666243074893305

Epoch: 6| Step: 9
Training loss: 1.105768870669405
Validation loss: 2.608160531979456

Epoch: 6| Step: 10
Training loss: 1.2121954505937
Validation loss: 2.607085916161128

Epoch: 6| Step: 11
Training loss: 0.8370327414691078
Validation loss: 2.6338305217236524

Epoch: 6| Step: 12
Training loss: 1.039155769464357
Validation loss: 2.626566237992186

Epoch: 6| Step: 13
Training loss: 1.230499800032964
Validation loss: 2.5717946564928353

Epoch: 353| Step: 0
Training loss: 1.3666418240002798
Validation loss: 2.6574705423831966

Epoch: 6| Step: 1
Training loss: 1.0919936110341062
Validation loss: 2.61635612074513

Epoch: 6| Step: 2
Training loss: 1.341062697515861
Validation loss: 2.629838495722771

Epoch: 6| Step: 3
Training loss: 0.7694858595730566
Validation loss: 2.5691465692005258

Epoch: 6| Step: 4
Training loss: 1.1740115208101125
Validation loss: 2.5533024944488205

Epoch: 6| Step: 5
Training loss: 1.0309907992051406
Validation loss: 2.5524185713041514

Epoch: 6| Step: 6
Training loss: 0.9787920411046296
Validation loss: 2.6005967555750393

Epoch: 6| Step: 7
Training loss: 1.135178613934683
Validation loss: 2.6038440707985484

Epoch: 6| Step: 8
Training loss: 0.85638705917819
Validation loss: 2.569528910534448

Epoch: 6| Step: 9
Training loss: 0.6942272288963537
Validation loss: 2.5616112462635994

Epoch: 6| Step: 10
Training loss: 0.9042705095373537
Validation loss: 2.5391855063353477

Epoch: 6| Step: 11
Training loss: 1.4382556090382306
Validation loss: 2.598828594712869

Epoch: 6| Step: 12
Training loss: 1.5625778178864191
Validation loss: 2.554743603820389

Epoch: 6| Step: 13
Training loss: 1.3540602519943061
Validation loss: 2.531181946769769

Epoch: 354| Step: 0
Training loss: 1.2788725404019419
Validation loss: 2.621679794810561

Epoch: 6| Step: 1
Training loss: 1.1217804510286578
Validation loss: 2.6021739252679406

Epoch: 6| Step: 2
Training loss: 1.3569429060268803
Validation loss: 2.6289984359562437

Epoch: 6| Step: 3
Training loss: 1.0298058194384059
Validation loss: 2.627672870646406

Epoch: 6| Step: 4
Training loss: 1.529538502124082
Validation loss: 2.710467573582615

Epoch: 6| Step: 5
Training loss: 1.0478589572272277
Validation loss: 2.722685162004437

Epoch: 6| Step: 6
Training loss: 0.8674749293263732
Validation loss: 2.62019876359509

Epoch: 6| Step: 7
Training loss: 1.1879760390347436
Validation loss: 2.7156683019559233

Epoch: 6| Step: 8
Training loss: 1.3071401693195877
Validation loss: 2.655180263158901

Epoch: 6| Step: 9
Training loss: 1.1826693509959134
Validation loss: 2.6346462666684443

Epoch: 6| Step: 10
Training loss: 1.1466652306743619
Validation loss: 2.6570870370905353

Epoch: 6| Step: 11
Training loss: 1.2163302535644192
Validation loss: 2.662092104786049

Epoch: 6| Step: 12
Training loss: 0.877010386069465
Validation loss: 2.6648776092957895

Epoch: 6| Step: 13
Training loss: 1.145994533412604
Validation loss: 2.612582582327533

Epoch: 355| Step: 0
Training loss: 1.0031823542945806
Validation loss: 2.5925415625040915

Epoch: 6| Step: 1
Training loss: 1.3880512551510011
Validation loss: 2.5941110076308806

Epoch: 6| Step: 2
Training loss: 1.2202459104688659
Validation loss: 2.598325821859755

Epoch: 6| Step: 3
Training loss: 1.388920972241606
Validation loss: 2.6137187460404028

Epoch: 6| Step: 4
Training loss: 1.0602164693440137
Validation loss: 2.6129261454128083

Epoch: 6| Step: 5
Training loss: 1.1648309206751795
Validation loss: 2.635953356007944

Epoch: 6| Step: 6
Training loss: 1.4227278949560023
Validation loss: 2.586838287783632

Epoch: 6| Step: 7
Training loss: 1.1147350790287514
Validation loss: 2.6095502569920535

Epoch: 6| Step: 8
Training loss: 1.230813259760853
Validation loss: 2.573531480195312

Epoch: 6| Step: 9
Training loss: 1.182145595629685
Validation loss: 2.5858612817632225

Epoch: 6| Step: 10
Training loss: 0.8367556196080479
Validation loss: 2.5816000435517377

Epoch: 6| Step: 11
Training loss: 1.1467522433325326
Validation loss: 2.577180862945525

Epoch: 6| Step: 12
Training loss: 1.0607118144609766
Validation loss: 2.5967723442074364

Epoch: 6| Step: 13
Training loss: 1.5273987743095545
Validation loss: 2.559173114594171

Epoch: 356| Step: 0
Training loss: 1.1100985893936755
Validation loss: 2.5476998863628157

Epoch: 6| Step: 1
Training loss: 1.2771309491605436
Validation loss: 2.5826987799786547

Epoch: 6| Step: 2
Training loss: 0.7411360671435827
Validation loss: 2.542487955030469

Epoch: 6| Step: 3
Training loss: 0.8567490425160169
Validation loss: 2.5310078728808487

Epoch: 6| Step: 4
Training loss: 1.2277976456401627
Validation loss: 2.5205222691906295

Epoch: 6| Step: 5
Training loss: 0.8394681578613029
Validation loss: 2.547711006986874

Epoch: 6| Step: 6
Training loss: 1.1603371835513419
Validation loss: 2.524649755025221

Epoch: 6| Step: 7
Training loss: 1.225576794350855
Validation loss: 2.5860731659766603

Epoch: 6| Step: 8
Training loss: 1.042559654212289
Validation loss: 2.513608151655417

Epoch: 6| Step: 9
Training loss: 1.8426694774969683
Validation loss: 2.526269195901483

Epoch: 6| Step: 10
Training loss: 1.0337299237037314
Validation loss: 2.5110414737870244

Epoch: 6| Step: 11
Training loss: 1.1211777499426898
Validation loss: 2.562394504391441

Epoch: 6| Step: 12
Training loss: 0.8205472337841305
Validation loss: 2.5279558984183135

Epoch: 6| Step: 13
Training loss: 1.2133119990670487
Validation loss: 2.5490695415183042

Epoch: 357| Step: 0
Training loss: 1.271047350054764
Validation loss: 2.520471851713595

Epoch: 6| Step: 1
Training loss: 0.855609586087831
Validation loss: 2.5199411142624304

Epoch: 6| Step: 2
Training loss: 1.061922365134742
Validation loss: 2.566938169990203

Epoch: 6| Step: 3
Training loss: 1.0697598109320274
Validation loss: 2.5678800379748523

Epoch: 6| Step: 4
Training loss: 0.8089420471464439
Validation loss: 2.572106412702353

Epoch: 6| Step: 5
Training loss: 1.026149214838162
Validation loss: 2.617828548740888

Epoch: 6| Step: 6
Training loss: 1.7807727642883036
Validation loss: 2.5769243623574836

Epoch: 6| Step: 7
Training loss: 1.0124929404306962
Validation loss: 2.5727736450063636

Epoch: 6| Step: 8
Training loss: 1.6126054359682216
Validation loss: 2.658442142456062

Epoch: 6| Step: 9
Training loss: 1.2767968363091704
Validation loss: 2.6303662369166725

Epoch: 6| Step: 10
Training loss: 1.1973048043491337
Validation loss: 2.6177194538682245

Epoch: 6| Step: 11
Training loss: 0.7506167339724231
Validation loss: 2.694242963653511

Epoch: 6| Step: 12
Training loss: 1.3337001246357099
Validation loss: 2.6516797859719325

Epoch: 6| Step: 13
Training loss: 0.8259689767290287
Validation loss: 2.6180361534251926

Epoch: 358| Step: 0
Training loss: 1.0844624332940602
Validation loss: 2.616867030626396

Epoch: 6| Step: 1
Training loss: 1.0431777801783066
Validation loss: 2.60912216697652

Epoch: 6| Step: 2
Training loss: 1.3182191675300028
Validation loss: 2.663359548354567

Epoch: 6| Step: 3
Training loss: 1.0964241035728965
Validation loss: 2.6150215865752227

Epoch: 6| Step: 4
Training loss: 1.5227280750039625
Validation loss: 2.6447865500493917

Epoch: 6| Step: 5
Training loss: 0.9875772252850885
Validation loss: 2.6192223528789222

Epoch: 6| Step: 6
Training loss: 0.9399243479580356
Validation loss: 2.6056800310523265

Epoch: 6| Step: 7
Training loss: 1.4548103649400534
Validation loss: 2.6214978152507356

Epoch: 6| Step: 8
Training loss: 0.8649304202655769
Validation loss: 2.687513247908239

Epoch: 6| Step: 9
Training loss: 1.3393038893783378
Validation loss: 2.683198991417738

Epoch: 6| Step: 10
Training loss: 1.01085310617613
Validation loss: 2.655433693909076

Epoch: 6| Step: 11
Training loss: 1.084785179371292
Validation loss: 2.571338854465915

Epoch: 6| Step: 12
Training loss: 1.2820862622868643
Validation loss: 2.4977204420463495

Epoch: 6| Step: 13
Training loss: 1.1166573180096762
Validation loss: 2.541150819826065

Epoch: 359| Step: 0
Training loss: 1.0971014718250043
Validation loss: 2.531226279693104

Epoch: 6| Step: 1
Training loss: 0.9442035065411092
Validation loss: 2.554028938483996

Epoch: 6| Step: 2
Training loss: 1.4766118278539153
Validation loss: 2.604100750406817

Epoch: 6| Step: 3
Training loss: 1.1135017042896398
Validation loss: 2.57042977510959

Epoch: 6| Step: 4
Training loss: 1.1263456773498284
Validation loss: 2.60456448886002

Epoch: 6| Step: 5
Training loss: 1.5813649976325215
Validation loss: 2.6241124635753508

Epoch: 6| Step: 6
Training loss: 1.488584953018643
Validation loss: 2.6463250106369607

Epoch: 6| Step: 7
Training loss: 1.1521084820081768
Validation loss: 2.579990937047018

Epoch: 6| Step: 8
Training loss: 0.9220171673308053
Validation loss: 2.6169174738266654

Epoch: 6| Step: 9
Training loss: 0.9293697679753339
Validation loss: 2.584669188207551

Epoch: 6| Step: 10
Training loss: 1.1711259609727014
Validation loss: 2.646171613279161

Epoch: 6| Step: 11
Training loss: 1.0321410981944432
Validation loss: 2.6537728221533072

Epoch: 6| Step: 12
Training loss: 1.0591071316253922
Validation loss: 2.627371776173086

Epoch: 6| Step: 13
Training loss: 1.202404599202282
Validation loss: 2.641342238732136

Epoch: 360| Step: 0
Training loss: 1.3114507204803905
Validation loss: 2.630112211277637

Epoch: 6| Step: 1
Training loss: 1.2559670124824505
Validation loss: 2.603991408490659

Epoch: 6| Step: 2
Training loss: 1.2754502567295039
Validation loss: 2.615343087339173

Epoch: 6| Step: 3
Training loss: 1.0192442742215662
Validation loss: 2.6123255116235806

Epoch: 6| Step: 4
Training loss: 1.153921308270695
Validation loss: 2.578939182148652

Epoch: 6| Step: 5
Training loss: 1.2293290445865976
Validation loss: 2.5431454114203413

Epoch: 6| Step: 6
Training loss: 0.8227020337876377
Validation loss: 2.586326531442039

Epoch: 6| Step: 7
Training loss: 1.1376842056190672
Validation loss: 2.5128169054425173

Epoch: 6| Step: 8
Training loss: 1.2937072304553006
Validation loss: 2.523689470023437

Epoch: 6| Step: 9
Training loss: 1.0664209497577466
Validation loss: 2.553615411220223

Epoch: 6| Step: 10
Training loss: 1.2625947633436192
Validation loss: 2.4957646096712756

Epoch: 6| Step: 11
Training loss: 0.9520401956703604
Validation loss: 2.5465167052952347

Epoch: 6| Step: 12
Training loss: 0.7768056722873898
Validation loss: 2.4998373137628307

Epoch: 6| Step: 13
Training loss: 1.0272954777157137
Validation loss: 2.645830414737884

Epoch: 361| Step: 0
Training loss: 1.064422550987234
Validation loss: 2.5496270380722836

Epoch: 6| Step: 1
Training loss: 1.0575762711744228
Validation loss: 2.6268164692518456

Epoch: 6| Step: 2
Training loss: 1.401724676065034
Validation loss: 2.5847950204660584

Epoch: 6| Step: 3
Training loss: 0.87873638630899
Validation loss: 2.6137959078517254

Epoch: 6| Step: 4
Training loss: 0.975461018214089
Validation loss: 2.6053179726351186

Epoch: 6| Step: 5
Training loss: 1.1028589505979178
Validation loss: 2.55528910141596

Epoch: 6| Step: 6
Training loss: 1.3596384955035659
Validation loss: 2.652842516439261

Epoch: 6| Step: 7
Training loss: 0.8526472130132802
Validation loss: 2.5893345673185264

Epoch: 6| Step: 8
Training loss: 1.2791399444539127
Validation loss: 2.61825800775402

Epoch: 6| Step: 9
Training loss: 1.053315464081473
Validation loss: 2.6119812001568734

Epoch: 6| Step: 10
Training loss: 1.2189624307802962
Validation loss: 2.6643252574105127

Epoch: 6| Step: 11
Training loss: 1.2576677701149703
Validation loss: 2.6420916184425445

Epoch: 6| Step: 12
Training loss: 1.172211052076524
Validation loss: 2.586957179212179

Epoch: 6| Step: 13
Training loss: 0.8615021821701212
Validation loss: 2.7171087901827926

Epoch: 362| Step: 0
Training loss: 0.746589136682383
Validation loss: 2.5983585335727

Epoch: 6| Step: 1
Training loss: 1.0366935399202024
Validation loss: 2.6099024256740533

Epoch: 6| Step: 2
Training loss: 0.8622210452338288
Validation loss: 2.656363436202793

Epoch: 6| Step: 3
Training loss: 1.3412374471341872
Validation loss: 2.6418687799273872

Epoch: 6| Step: 4
Training loss: 0.9460284461770996
Validation loss: 2.6619917054547466

Epoch: 6| Step: 5
Training loss: 1.409292320989748
Validation loss: 2.6229837788264367

Epoch: 6| Step: 6
Training loss: 1.0821038507556429
Validation loss: 2.6276782919815975

Epoch: 6| Step: 7
Training loss: 1.064037780922725
Validation loss: 2.678112571862553

Epoch: 6| Step: 8
Training loss: 0.7484747556839092
Validation loss: 2.6345727999374717

Epoch: 6| Step: 9
Training loss: 1.1641268104351543
Validation loss: 2.69796591361523

Epoch: 6| Step: 10
Training loss: 1.0531909638978856
Validation loss: 2.695873051094807

Epoch: 6| Step: 11
Training loss: 1.0918618935211635
Validation loss: 2.6790805347968334

Epoch: 6| Step: 12
Training loss: 1.1343356711555699
Validation loss: 2.7662020151395326

Epoch: 6| Step: 13
Training loss: 1.0633032511299518
Validation loss: 2.6735398011929474

Epoch: 363| Step: 0
Training loss: 0.945412118249888
Validation loss: 2.6254589648386886

Epoch: 6| Step: 1
Training loss: 1.1752065477029108
Validation loss: 2.635261943230711

Epoch: 6| Step: 2
Training loss: 1.2299530401802274
Validation loss: 2.6643727887214768

Epoch: 6| Step: 3
Training loss: 0.8336845055382013
Validation loss: 2.5848899325236117

Epoch: 6| Step: 4
Training loss: 1.3027225705459842
Validation loss: 2.6598185783796215

Epoch: 6| Step: 5
Training loss: 1.0638365473431013
Validation loss: 2.662528214282772

Epoch: 6| Step: 6
Training loss: 1.1561634959261315
Validation loss: 2.608221282522519

Epoch: 6| Step: 7
Training loss: 0.7601910260705292
Validation loss: 2.63107269487101

Epoch: 6| Step: 8
Training loss: 0.7452278105085444
Validation loss: 2.591580521561414

Epoch: 6| Step: 9
Training loss: 1.1208775541145202
Validation loss: 2.6160121119293676

Epoch: 6| Step: 10
Training loss: 0.8489991901762283
Validation loss: 2.616394811122854

Epoch: 6| Step: 11
Training loss: 1.165532559981258
Validation loss: 2.5876427259411

Epoch: 6| Step: 12
Training loss: 1.0345217505593447
Validation loss: 2.624781402689741

Epoch: 6| Step: 13
Training loss: 1.2768402507159573
Validation loss: 2.610182189964747

Epoch: 364| Step: 0
Training loss: 1.221242166140682
Validation loss: 2.578781360343694

Epoch: 6| Step: 1
Training loss: 0.973425013674872
Validation loss: 2.587937963280679

Epoch: 6| Step: 2
Training loss: 1.449307009741876
Validation loss: 2.561998147591073

Epoch: 6| Step: 3
Training loss: 0.8906146266400073
Validation loss: 2.581530654711426

Epoch: 6| Step: 4
Training loss: 1.0413981981817562
Validation loss: 2.5594615600256914

Epoch: 6| Step: 5
Training loss: 1.2491616775806664
Validation loss: 2.565790281497281

Epoch: 6| Step: 6
Training loss: 1.4194204082473667
Validation loss: 2.5729900818104943

Epoch: 6| Step: 7
Training loss: 0.7272728759456613
Validation loss: 2.5987621735346864

Epoch: 6| Step: 8
Training loss: 1.1649149391326512
Validation loss: 2.582951545703419

Epoch: 6| Step: 9
Training loss: 0.6666466193363856
Validation loss: 2.6206889401329296

Epoch: 6| Step: 10
Training loss: 0.8461487897475091
Validation loss: 2.634055835460348

Epoch: 6| Step: 11
Training loss: 1.0811189186153618
Validation loss: 2.6793748471154952

Epoch: 6| Step: 12
Training loss: 0.9318682954215697
Validation loss: 2.6960535624745985

Epoch: 6| Step: 13
Training loss: 0.9979407446285244
Validation loss: 2.686717096779135

Epoch: 365| Step: 0
Training loss: 0.9630654197647126
Validation loss: 2.664771081803527

Epoch: 6| Step: 1
Training loss: 1.0574070659230366
Validation loss: 2.639384186981855

Epoch: 6| Step: 2
Training loss: 1.1437983851803437
Validation loss: 2.668277906878265

Epoch: 6| Step: 3
Training loss: 0.7281852975526689
Validation loss: 2.629437147838252

Epoch: 6| Step: 4
Training loss: 1.016639906630075
Validation loss: 2.6064571353191135

Epoch: 6| Step: 5
Training loss: 1.1432720457245853
Validation loss: 2.585024977120026

Epoch: 6| Step: 6
Training loss: 1.03339284730595
Validation loss: 2.5979221599880735

Epoch: 6| Step: 7
Training loss: 0.864605056918743
Validation loss: 2.579251037680271

Epoch: 6| Step: 8
Training loss: 0.7062513781846365
Validation loss: 2.5902345572494423

Epoch: 6| Step: 9
Training loss: 1.2719215309573075
Validation loss: 2.612807766492194

Epoch: 6| Step: 10
Training loss: 1.0984524591547844
Validation loss: 2.6694558329167823

Epoch: 6| Step: 11
Training loss: 0.9110823082700196
Validation loss: 2.605696988915795

Epoch: 6| Step: 12
Training loss: 1.124898164166643
Validation loss: 2.621659257186763

Epoch: 6| Step: 13
Training loss: 1.2001304019170291
Validation loss: 2.5838572422084383

Epoch: 366| Step: 0
Training loss: 0.9981892702529914
Validation loss: 2.6629268727897593

Epoch: 6| Step: 1
Training loss: 0.7599091382046105
Validation loss: 2.659928867146663

Epoch: 6| Step: 2
Training loss: 1.4335418608627035
Validation loss: 2.6176614967909466

Epoch: 6| Step: 3
Training loss: 1.0540508467988292
Validation loss: 2.636062216319233

Epoch: 6| Step: 4
Training loss: 0.9641930552019847
Validation loss: 2.6575409687911926

Epoch: 6| Step: 5
Training loss: 1.0782921702936554
Validation loss: 2.598762334085161

Epoch: 6| Step: 6
Training loss: 1.0376227593470697
Validation loss: 2.6600651886488285

Epoch: 6| Step: 7
Training loss: 0.9355688550433692
Validation loss: 2.6552478919531333

Epoch: 6| Step: 8
Training loss: 1.0920443723487563
Validation loss: 2.6484024210569417

Epoch: 6| Step: 9
Training loss: 1.0244821356746678
Validation loss: 2.684609877377033

Epoch: 6| Step: 10
Training loss: 1.1060574854351088
Validation loss: 2.673933578354827

Epoch: 6| Step: 11
Training loss: 0.9226001538335877
Validation loss: 2.629956485789605

Epoch: 6| Step: 12
Training loss: 0.5961888318705296
Validation loss: 2.5920731512950073

Epoch: 6| Step: 13
Training loss: 1.032826461351363
Validation loss: 2.593278819110207

Epoch: 367| Step: 0
Training loss: 1.0889250461961169
Validation loss: 2.652090915470317

Epoch: 6| Step: 1
Training loss: 1.116638101857681
Validation loss: 2.662500484747089

Epoch: 6| Step: 2
Training loss: 1.0296369710978657
Validation loss: 2.6957742046807387

Epoch: 6| Step: 3
Training loss: 1.0990821563724429
Validation loss: 2.6478243017607093

Epoch: 6| Step: 4
Training loss: 0.9567083631515803
Validation loss: 2.7209857429669233

Epoch: 6| Step: 5
Training loss: 1.021708534984217
Validation loss: 2.598222048527353

Epoch: 6| Step: 6
Training loss: 0.9869466522953919
Validation loss: 2.6088145524089827

Epoch: 6| Step: 7
Training loss: 0.9537349062783942
Validation loss: 2.5587699305322342

Epoch: 6| Step: 8
Training loss: 1.044230123409726
Validation loss: 2.5690306121192203

Epoch: 6| Step: 9
Training loss: 0.9462462613373324
Validation loss: 2.5658780449042817

Epoch: 6| Step: 10
Training loss: 1.4958444093738672
Validation loss: 2.5872288732334208

Epoch: 6| Step: 11
Training loss: 1.21857744609297
Validation loss: 2.5535950108625998

Epoch: 6| Step: 12
Training loss: 1.098736214751996
Validation loss: 2.616471711770583

Epoch: 6| Step: 13
Training loss: 0.8175876957697247
Validation loss: 2.5577911282848365

Epoch: 368| Step: 0
Training loss: 0.8988468730219611
Validation loss: 2.635130950960101

Epoch: 6| Step: 1
Training loss: 1.0513489051404228
Validation loss: 2.6114435886067735

Epoch: 6| Step: 2
Training loss: 1.169926613111884
Validation loss: 2.649629892739117

Epoch: 6| Step: 3
Training loss: 0.6839197525877287
Validation loss: 2.650763286571309

Epoch: 6| Step: 4
Training loss: 1.0944827758597884
Validation loss: 2.593490411415023

Epoch: 6| Step: 5
Training loss: 1.1294668317148988
Validation loss: 2.6394457770446627

Epoch: 6| Step: 6
Training loss: 0.7903502880397814
Validation loss: 2.640842752300433

Epoch: 6| Step: 7
Training loss: 0.8438942397417242
Validation loss: 2.543932004223827

Epoch: 6| Step: 8
Training loss: 1.2609608739036064
Validation loss: 2.564188021311719

Epoch: 6| Step: 9
Training loss: 1.3414654940284547
Validation loss: 2.5654580325625287

Epoch: 6| Step: 10
Training loss: 1.0011884065082546
Validation loss: 2.516588535948654

Epoch: 6| Step: 11
Training loss: 0.9253065928560805
Validation loss: 2.596247546813619

Epoch: 6| Step: 12
Training loss: 1.2203874103446903
Validation loss: 2.6251593117584155

Epoch: 6| Step: 13
Training loss: 0.9651498656442304
Validation loss: 2.575477404303802

Epoch: 369| Step: 0
Training loss: 0.9513899848789359
Validation loss: 2.6086188494219402

Epoch: 6| Step: 1
Training loss: 0.9896762335822281
Validation loss: 2.661095093626035

Epoch: 6| Step: 2
Training loss: 1.0877145182934143
Validation loss: 2.6050880760269366

Epoch: 6| Step: 3
Training loss: 0.7522837518870599
Validation loss: 2.606823143575509

Epoch: 6| Step: 4
Training loss: 0.8663841169056761
Validation loss: 2.678531245278385

Epoch: 6| Step: 5
Training loss: 0.7981809125417405
Validation loss: 2.6000288374842135

Epoch: 6| Step: 6
Training loss: 1.2769837411668434
Validation loss: 2.6714261516397864

Epoch: 6| Step: 7
Training loss: 1.1317026950192972
Validation loss: 2.6117192852519135

Epoch: 6| Step: 8
Training loss: 1.015455378526402
Validation loss: 2.6484597654353834

Epoch: 6| Step: 9
Training loss: 1.1577666362373615
Validation loss: 2.6520919268264844

Epoch: 6| Step: 10
Training loss: 0.9243867568273655
Validation loss: 2.6243389144903366

Epoch: 6| Step: 11
Training loss: 1.023193563262402
Validation loss: 2.649766166734869

Epoch: 6| Step: 12
Training loss: 1.091500393869606
Validation loss: 2.6724574177427094

Epoch: 6| Step: 13
Training loss: 1.093633700045906
Validation loss: 2.5956032195334404

Epoch: 370| Step: 0
Training loss: 1.0228784213455826
Validation loss: 2.6168476624264665

Epoch: 6| Step: 1
Training loss: 1.5409328501315371
Validation loss: 2.6351996371401962

Epoch: 6| Step: 2
Training loss: 0.6485559516172514
Validation loss: 2.5932756932463334

Epoch: 6| Step: 3
Training loss: 1.1609093376430157
Validation loss: 2.629435621511379

Epoch: 6| Step: 4
Training loss: 1.0687429795954833
Validation loss: 2.5700825798061846

Epoch: 6| Step: 5
Training loss: 0.8299613601238952
Validation loss: 2.6185926925766605

Epoch: 6| Step: 6
Training loss: 1.1002256248736721
Validation loss: 2.573453551170754

Epoch: 6| Step: 7
Training loss: 0.9522961624185153
Validation loss: 2.5895542694531337

Epoch: 6| Step: 8
Training loss: 0.977436407074353
Validation loss: 2.58226354557271

Epoch: 6| Step: 9
Training loss: 1.227237685663387
Validation loss: 2.614268946395343

Epoch: 6| Step: 10
Training loss: 0.5195278081564797
Validation loss: 2.5848932068812895

Epoch: 6| Step: 11
Training loss: 1.017133033337232
Validation loss: 2.598133121783975

Epoch: 6| Step: 12
Training loss: 0.9279243676240467
Validation loss: 2.5935615946045765

Epoch: 6| Step: 13
Training loss: 0.7773299862970604
Validation loss: 2.662975861554934

Epoch: 371| Step: 0
Training loss: 0.7986436551599506
Validation loss: 2.6911988642149263

Epoch: 6| Step: 1
Training loss: 0.7618533284560682
Validation loss: 2.611617748221886

Epoch: 6| Step: 2
Training loss: 1.1152754206544748
Validation loss: 2.6667912473982875

Epoch: 6| Step: 3
Training loss: 0.8202664316956259
Validation loss: 2.6799518836622256

Epoch: 6| Step: 4
Training loss: 1.1323938582745288
Validation loss: 2.646154749613672

Epoch: 6| Step: 5
Training loss: 0.7787286890827649
Validation loss: 2.706414163850742

Epoch: 6| Step: 6
Training loss: 1.0867977988413513
Validation loss: 2.711255556003851

Epoch: 6| Step: 7
Training loss: 1.0272188872255754
Validation loss: 2.655523522457367

Epoch: 6| Step: 8
Training loss: 1.2725445009255816
Validation loss: 2.6759894148517938

Epoch: 6| Step: 9
Training loss: 0.7587468001723965
Validation loss: 2.6783438261910995

Epoch: 6| Step: 10
Training loss: 0.7454043893529787
Validation loss: 2.6725102165890458

Epoch: 6| Step: 11
Training loss: 1.1625025492814527
Validation loss: 2.6795718999456715

Epoch: 6| Step: 12
Training loss: 1.1893055390498013
Validation loss: 2.6745622888788922

Epoch: 6| Step: 13
Training loss: 0.7119899965665785
Validation loss: 2.6127545672295156

Epoch: 372| Step: 0
Training loss: 1.498893011426963
Validation loss: 2.6327066070059137

Epoch: 6| Step: 1
Training loss: 1.1014140143995457
Validation loss: 2.6060940641717907

Epoch: 6| Step: 2
Training loss: 0.8981646247782042
Validation loss: 2.572386070449715

Epoch: 6| Step: 3
Training loss: 0.8717086742726173
Validation loss: 2.586959729020176

Epoch: 6| Step: 4
Training loss: 1.084366464718694
Validation loss: 2.5644236996568437

Epoch: 6| Step: 5
Training loss: 0.7404604040811733
Validation loss: 2.6001698276490863

Epoch: 6| Step: 6
Training loss: 1.1484500598869423
Validation loss: 2.5688796296093983

Epoch: 6| Step: 7
Training loss: 1.7810330175116218
Validation loss: 2.594201872043779

Epoch: 6| Step: 8
Training loss: 0.9854709639856288
Validation loss: 2.617131368310337

Epoch: 6| Step: 9
Training loss: 1.0111230694642384
Validation loss: 2.647862614866074

Epoch: 6| Step: 10
Training loss: 1.2225210584297264
Validation loss: 2.7358612962034097

Epoch: 6| Step: 11
Training loss: 1.020058740252128
Validation loss: 2.8026182781989744

Epoch: 6| Step: 12
Training loss: 1.1993472748017318
Validation loss: 2.697545284990633

Epoch: 6| Step: 13
Training loss: 0.961893892802894
Validation loss: 2.6910145718650034

Epoch: 373| Step: 0
Training loss: 0.8686892248068361
Validation loss: 2.585531512119365

Epoch: 6| Step: 1
Training loss: 0.9416680822671248
Validation loss: 2.5741306998013584

Epoch: 6| Step: 2
Training loss: 0.9848030612825153
Validation loss: 2.574316104944708

Epoch: 6| Step: 3
Training loss: 1.3259864194298254
Validation loss: 2.5687904682668856

Epoch: 6| Step: 4
Training loss: 0.7686753523645491
Validation loss: 2.585108459897848

Epoch: 6| Step: 5
Training loss: 0.7775271788749978
Validation loss: 2.5433724469201606

Epoch: 6| Step: 6
Training loss: 1.0578896971894933
Validation loss: 2.5673390729739802

Epoch: 6| Step: 7
Training loss: 1.2850762896026355
Validation loss: 2.621410913508166

Epoch: 6| Step: 8
Training loss: 0.9312668536408479
Validation loss: 2.6013045999350144

Epoch: 6| Step: 9
Training loss: 0.9965590942075805
Validation loss: 2.662828683638701

Epoch: 6| Step: 10
Training loss: 1.0994361212451074
Validation loss: 2.715170992881315

Epoch: 6| Step: 11
Training loss: 1.0637600663601985
Validation loss: 2.6859601067018293

Epoch: 6| Step: 12
Training loss: 0.981017791096759
Validation loss: 2.683638452475016

Epoch: 6| Step: 13
Training loss: 1.2063775128579601
Validation loss: 2.6287935486924674

Epoch: 374| Step: 0
Training loss: 0.9881136303512369
Validation loss: 2.676815217441848

Epoch: 6| Step: 1
Training loss: 1.054898106775439
Validation loss: 2.692237898992665

Epoch: 6| Step: 2
Training loss: 0.8468615062806948
Validation loss: 2.7005140303866644

Epoch: 6| Step: 3
Training loss: 1.1745662558239844
Validation loss: 2.6793599720972368

Epoch: 6| Step: 4
Training loss: 1.0274397076368906
Validation loss: 2.7347089000468037

Epoch: 6| Step: 5
Training loss: 0.9012919319122696
Validation loss: 2.6643693734155156

Epoch: 6| Step: 6
Training loss: 0.8907483667963062
Validation loss: 2.7192054016350307

Epoch: 6| Step: 7
Training loss: 1.030605692870579
Validation loss: 2.7048195982786125

Epoch: 6| Step: 8
Training loss: 0.8812976770152013
Validation loss: 2.711615485904297

Epoch: 6| Step: 9
Training loss: 1.1448342504845226
Validation loss: 2.66715069689367

Epoch: 6| Step: 10
Training loss: 1.240355766543231
Validation loss: 2.6782808754781993

Epoch: 6| Step: 11
Training loss: 1.091212080201629
Validation loss: 2.681225364115419

Epoch: 6| Step: 12
Training loss: 0.7311123954872141
Validation loss: 2.6327553128786665

Epoch: 6| Step: 13
Training loss: 0.776070400107198
Validation loss: 2.7035014454521624

Epoch: 375| Step: 0
Training loss: 1.2349006402822977
Validation loss: 2.6781276541139976

Epoch: 6| Step: 1
Training loss: 0.6670173651437915
Validation loss: 2.6676330802061874

Epoch: 6| Step: 2
Training loss: 1.2836005351745736
Validation loss: 2.7595604822325397

Epoch: 6| Step: 3
Training loss: 0.8492061315755363
Validation loss: 2.7122257187748855

Epoch: 6| Step: 4
Training loss: 0.7744110607651865
Validation loss: 2.6781802818263563

Epoch: 6| Step: 5
Training loss: 0.741878324660297
Validation loss: 2.6811514100486673

Epoch: 6| Step: 6
Training loss: 0.9582898019495819
Validation loss: 2.672212114687296

Epoch: 6| Step: 7
Training loss: 1.0952720406061933
Validation loss: 2.647347615160812

Epoch: 6| Step: 8
Training loss: 1.073625546438256
Validation loss: 2.7030347393746976

Epoch: 6| Step: 9
Training loss: 0.866098321348263
Validation loss: 2.64049221209058

Epoch: 6| Step: 10
Training loss: 0.7855254486667395
Validation loss: 2.6132909967519176

Epoch: 6| Step: 11
Training loss: 0.7797988384004342
Validation loss: 2.6596500551831945

Epoch: 6| Step: 12
Training loss: 1.006374071895241
Validation loss: 2.605332172251351

Epoch: 6| Step: 13
Training loss: 0.8015787015173602
Validation loss: 2.61216572899981

Epoch: 376| Step: 0
Training loss: 0.9628700114862183
Validation loss: 2.5982633641307715

Epoch: 6| Step: 1
Training loss: 0.6585462677515419
Validation loss: 2.6704973532211174

Epoch: 6| Step: 2
Training loss: 0.6715677135295336
Validation loss: 2.637621930695313

Epoch: 6| Step: 3
Training loss: 0.8230404499167078
Validation loss: 2.607553954476022

Epoch: 6| Step: 4
Training loss: 0.7537027192983708
Validation loss: 2.6079969974361092

Epoch: 6| Step: 5
Training loss: 1.3681301246153248
Validation loss: 2.664280335291723

Epoch: 6| Step: 6
Training loss: 1.207116528310178
Validation loss: 2.617038141799881

Epoch: 6| Step: 7
Training loss: 0.7712568889291707
Validation loss: 2.6537259095713117

Epoch: 6| Step: 8
Training loss: 0.7389145814002841
Validation loss: 2.622706546704559

Epoch: 6| Step: 9
Training loss: 0.9111458306236059
Validation loss: 2.6525324369047762

Epoch: 6| Step: 10
Training loss: 1.0331544918736375
Validation loss: 2.6816584213047885

Epoch: 6| Step: 11
Training loss: 0.6564420237482935
Validation loss: 2.6591401626651217

Epoch: 6| Step: 12
Training loss: 1.0509225970075642
Validation loss: 2.670303551852533

Epoch: 6| Step: 13
Training loss: 0.915252041941295
Validation loss: 2.6529832835815714

Epoch: 377| Step: 0
Training loss: 0.98244241196267
Validation loss: 2.6217231430676824

Epoch: 6| Step: 1
Training loss: 1.0683693615099696
Validation loss: 2.65784796725318

Epoch: 6| Step: 2
Training loss: 0.8482928017437342
Validation loss: 2.665607932640971

Epoch: 6| Step: 3
Training loss: 0.9313965163724601
Validation loss: 2.6846071982922792

Epoch: 6| Step: 4
Training loss: 0.7287146984075884
Validation loss: 2.707137516315779

Epoch: 6| Step: 5
Training loss: 0.8513723738622425
Validation loss: 2.7136056835118416

Epoch: 6| Step: 6
Training loss: 0.8985715683129709
Validation loss: 2.6266848515794403

Epoch: 6| Step: 7
Training loss: 0.730063096285174
Validation loss: 2.7123977290267898

Epoch: 6| Step: 8
Training loss: 0.8258885829034321
Validation loss: 2.702561292138534

Epoch: 6| Step: 9
Training loss: 0.7149400489855731
Validation loss: 2.630979826429975

Epoch: 6| Step: 10
Training loss: 1.0355567013602769
Validation loss: 2.6544757227915285

Epoch: 6| Step: 11
Training loss: 1.3314304283264795
Validation loss: 2.6493977444131334

Epoch: 6| Step: 12
Training loss: 0.78874910381768
Validation loss: 2.6930388365234164

Epoch: 6| Step: 13
Training loss: 1.009294942509543
Validation loss: 2.679662350313225

Epoch: 378| Step: 0
Training loss: 0.9583679828737677
Validation loss: 2.6250707525981545

Epoch: 6| Step: 1
Training loss: 1.0664609119532902
Validation loss: 2.6650590272656283

Epoch: 6| Step: 2
Training loss: 0.8724243538972364
Validation loss: 2.667898152033091

Epoch: 6| Step: 3
Training loss: 0.9393607746501471
Validation loss: 2.672371533752446

Epoch: 6| Step: 4
Training loss: 0.9591372614732656
Validation loss: 2.6605342572143162

Epoch: 6| Step: 5
Training loss: 0.6989454662391265
Validation loss: 2.6416227272864004

Epoch: 6| Step: 6
Training loss: 0.9268298427619182
Validation loss: 2.6501345978149193

Epoch: 6| Step: 7
Training loss: 0.786014789701806
Validation loss: 2.619503928145461

Epoch: 6| Step: 8
Training loss: 0.9891631522647822
Validation loss: 2.630503909181292

Epoch: 6| Step: 9
Training loss: 1.2103005980072146
Validation loss: 2.6330572933266363

Epoch: 6| Step: 10
Training loss: 0.924414096028714
Validation loss: 2.631545927150092

Epoch: 6| Step: 11
Training loss: 0.7471338581659748
Validation loss: 2.656671154069481

Epoch: 6| Step: 12
Training loss: 1.0065443946988906
Validation loss: 2.7126305210336312

Epoch: 6| Step: 13
Training loss: 1.0306853858371365
Validation loss: 2.7098408587088265

Epoch: 379| Step: 0
Training loss: 0.7793464358065638
Validation loss: 2.733108532391671

Epoch: 6| Step: 1
Training loss: 0.8116846395013154
Validation loss: 2.710572495746924

Epoch: 6| Step: 2
Training loss: 0.7787526460360766
Validation loss: 2.7525553246347974

Epoch: 6| Step: 3
Training loss: 1.179112932353533
Validation loss: 2.7426028322027793

Epoch: 6| Step: 4
Training loss: 0.948884127940201
Validation loss: 2.660330603772568

Epoch: 6| Step: 5
Training loss: 1.2522858699718789
Validation loss: 2.6664595722209814

Epoch: 6| Step: 6
Training loss: 1.1715618986838958
Validation loss: 2.603784339813858

Epoch: 6| Step: 7
Training loss: 1.331910024367701
Validation loss: 2.7121846374620855

Epoch: 6| Step: 8
Training loss: 0.7801694263558032
Validation loss: 2.6582335003928224

Epoch: 6| Step: 9
Training loss: 0.8136075613872656
Validation loss: 2.613238005002333

Epoch: 6| Step: 10
Training loss: 0.6402526796993138
Validation loss: 2.6331877096770224

Epoch: 6| Step: 11
Training loss: 0.9171597426209336
Validation loss: 2.555620588866485

Epoch: 6| Step: 12
Training loss: 0.6425559321226367
Validation loss: 2.5706304258856134

Epoch: 6| Step: 13
Training loss: 1.4464873616483649
Validation loss: 2.56808667493879

Epoch: 380| Step: 0
Training loss: 0.910477839290826
Validation loss: 2.5722543942595646

Epoch: 6| Step: 1
Training loss: 0.827428560889981
Validation loss: 2.560908016883089

Epoch: 6| Step: 2
Training loss: 1.0336197876479922
Validation loss: 2.5442983781357587

Epoch: 6| Step: 3
Training loss: 0.7362171362648668
Validation loss: 2.5855616270417605

Epoch: 6| Step: 4
Training loss: 1.1324891779974102
Validation loss: 2.6193623326865363

Epoch: 6| Step: 5
Training loss: 0.874792210565955
Validation loss: 2.6507238536061966

Epoch: 6| Step: 6
Training loss: 0.8733846194615308
Validation loss: 2.598374484015485

Epoch: 6| Step: 7
Training loss: 0.9687401555699402
Validation loss: 2.685598365983645

Epoch: 6| Step: 8
Training loss: 0.7054244271482594
Validation loss: 2.65932473636856

Epoch: 6| Step: 9
Training loss: 0.7784533225480172
Validation loss: 2.641356086724743

Epoch: 6| Step: 10
Training loss: 0.8871629585400267
Validation loss: 2.6393232880366098

Epoch: 6| Step: 11
Training loss: 1.0148889074931366
Validation loss: 2.7306875596898705

Epoch: 6| Step: 12
Training loss: 1.1825669370097949
Validation loss: 2.698923200591872

Epoch: 6| Step: 13
Training loss: 1.059650020853414
Validation loss: 2.7033115535741454

Epoch: 381| Step: 0
Training loss: 1.0514062773928028
Validation loss: 2.6271756707788003

Epoch: 6| Step: 1
Training loss: 1.041579904121874
Validation loss: 2.6457267249148524

Epoch: 6| Step: 2
Training loss: 0.9932293565680261
Validation loss: 2.6477942046493075

Epoch: 6| Step: 3
Training loss: 0.9481702437447055
Validation loss: 2.6117649440577013

Epoch: 6| Step: 4
Training loss: 0.8266758745460016
Validation loss: 2.609662236224744

Epoch: 6| Step: 5
Training loss: 0.9569025069854614
Validation loss: 2.5950958329931315

Epoch: 6| Step: 6
Training loss: 1.3885679139014857
Validation loss: 2.6169702847807375

Epoch: 6| Step: 7
Training loss: 0.9524498721571482
Validation loss: 2.6091306347360694

Epoch: 6| Step: 8
Training loss: 0.8186382100904407
Validation loss: 2.5851453660812895

Epoch: 6| Step: 9
Training loss: 0.8683669858282361
Validation loss: 2.613745457617767

Epoch: 6| Step: 10
Training loss: 1.093714795227234
Validation loss: 2.605205516872132

Epoch: 6| Step: 11
Training loss: 0.8703006161438283
Validation loss: 2.5905049411638448

Epoch: 6| Step: 12
Training loss: 0.7518839618532454
Validation loss: 2.671984932405852

Epoch: 6| Step: 13
Training loss: 1.1967400397561
Validation loss: 2.6189885561133353

Epoch: 382| Step: 0
Training loss: 0.8194722549834266
Validation loss: 2.7085020501819908

Epoch: 6| Step: 1
Training loss: 0.8100368871649056
Validation loss: 2.6607794794816773

Epoch: 6| Step: 2
Training loss: 1.1017548954463023
Validation loss: 2.6767297553311113

Epoch: 6| Step: 3
Training loss: 0.9009686515786617
Validation loss: 2.6929164833077834

Epoch: 6| Step: 4
Training loss: 1.1675792031715497
Validation loss: 2.6490699065534162

Epoch: 6| Step: 5
Training loss: 0.8006336355227548
Validation loss: 2.681630000505287

Epoch: 6| Step: 6
Training loss: 0.7837125115805877
Validation loss: 2.6810341612543596

Epoch: 6| Step: 7
Training loss: 1.1804483751499018
Validation loss: 2.626998072810459

Epoch: 6| Step: 8
Training loss: 0.6350024911125761
Validation loss: 2.680773812359451

Epoch: 6| Step: 9
Training loss: 1.228053650469969
Validation loss: 2.70423974955764

Epoch: 6| Step: 10
Training loss: 2.0965746145656055
Validation loss: 2.762581280049108

Epoch: 6| Step: 11
Training loss: 0.9025408707026662
Validation loss: 2.6426257467290344

Epoch: 6| Step: 12
Training loss: 0.7402855042687959
Validation loss: 2.6949965287176174

Epoch: 6| Step: 13
Training loss: 1.1080911218721807
Validation loss: 2.727505569079361

Epoch: 383| Step: 0
Training loss: 2.562252497932079
Validation loss: 2.786799619695664

Epoch: 6| Step: 1
Training loss: 1.091545935984826
Validation loss: 2.691650054770151

Epoch: 6| Step: 2
Training loss: 0.9756602888060666
Validation loss: 2.637816430947473

Epoch: 6| Step: 3
Training loss: 1.3345306305726998
Validation loss: 2.697950831802042

Epoch: 6| Step: 4
Training loss: 1.4669979277676104
Validation loss: 2.860627072220815

Epoch: 6| Step: 5
Training loss: 1.527910600533505
Validation loss: 2.9350534626360556

Epoch: 6| Step: 6
Training loss: 1.3280366756016808
Validation loss: 2.88024248835275

Epoch: 6| Step: 7
Training loss: 1.0757761814549318
Validation loss: 2.712851267511523

Epoch: 6| Step: 8
Training loss: 1.2584728616236818
Validation loss: 2.6116667865281684

Epoch: 6| Step: 9
Training loss: 0.9098845637117963
Validation loss: 2.6842447867321404

Epoch: 6| Step: 10
Training loss: 0.9154400348994155
Validation loss: 2.6564598150226475

Epoch: 6| Step: 11
Training loss: 1.0168291436320447
Validation loss: 2.608973580738029

Epoch: 6| Step: 12
Training loss: 0.9010897423298051
Validation loss: 2.642704222218212

Epoch: 6| Step: 13
Training loss: 0.7911846969196842
Validation loss: 2.656348851178418

Epoch: 384| Step: 0
Training loss: 1.1490751299917423
Validation loss: 2.652746185949017

Epoch: 6| Step: 1
Training loss: 1.0034186221675183
Validation loss: 2.6152561482175303

Epoch: 6| Step: 2
Training loss: 1.2191058886369759
Validation loss: 2.6545282131618317

Epoch: 6| Step: 3
Training loss: 1.2506741613117411
Validation loss: 2.644499304769589

Epoch: 6| Step: 4
Training loss: 0.9615957905111513
Validation loss: 2.6724229514729223

Epoch: 6| Step: 5
Training loss: 0.9317514285687426
Validation loss: 2.72096358177846

Epoch: 6| Step: 6
Training loss: 1.7889904024347538
Validation loss: 2.798538537316319

Epoch: 6| Step: 7
Training loss: 1.0897826584404957
Validation loss: 2.7782972713648046

Epoch: 6| Step: 8
Training loss: 1.383406430729899
Validation loss: 2.7390332171276057

Epoch: 6| Step: 9
Training loss: 0.9504205450513733
Validation loss: 2.732561814544625

Epoch: 6| Step: 10
Training loss: 0.7457227333652088
Validation loss: 2.762897489900464

Epoch: 6| Step: 11
Training loss: 1.179113387307155
Validation loss: 2.797577114525299

Epoch: 6| Step: 12
Training loss: 0.9563825627612413
Validation loss: 2.795066660914674

Epoch: 6| Step: 13
Training loss: 0.8529727003373273
Validation loss: 2.802019569966683

Epoch: 385| Step: 0
Training loss: 0.7899453162932305
Validation loss: 2.8149053954539274

Epoch: 6| Step: 1
Training loss: 1.1251824548904115
Validation loss: 2.7883163864645293

Epoch: 6| Step: 2
Training loss: 1.5623434369803855
Validation loss: 2.797966997873159

Epoch: 6| Step: 3
Training loss: 1.6295086595200425
Validation loss: 2.7592104933689505

Epoch: 6| Step: 4
Training loss: 1.2622729994396777
Validation loss: 2.739541047402064

Epoch: 6| Step: 5
Training loss: 1.0881530883424118
Validation loss: 2.6775489481379573

Epoch: 6| Step: 6
Training loss: 1.113431257882984
Validation loss: 2.664297680807835

Epoch: 6| Step: 7
Training loss: 0.9274514499717753
Validation loss: 2.592290322025642

Epoch: 6| Step: 8
Training loss: 1.1894917098177775
Validation loss: 2.5863591183701526

Epoch: 6| Step: 9
Training loss: 0.9755003989965267
Validation loss: 2.601258390902848

Epoch: 6| Step: 10
Training loss: 0.8835139230949058
Validation loss: 2.5058447147851357

Epoch: 6| Step: 11
Training loss: 0.8071345186586478
Validation loss: 2.5433614948091816

Epoch: 6| Step: 12
Training loss: 0.839865715271899
Validation loss: 2.5332833274707776

Epoch: 6| Step: 13
Training loss: 0.7862608621693002
Validation loss: 2.5240528627946612

Epoch: 386| Step: 0
Training loss: 0.9563872369759417
Validation loss: 2.5646740754531745

Epoch: 6| Step: 1
Training loss: 0.8931334456304073
Validation loss: 2.583298503476862

Epoch: 6| Step: 2
Training loss: 0.6260615869823712
Validation loss: 2.5150207204451807

Epoch: 6| Step: 3
Training loss: 1.1471582670963305
Validation loss: 2.5657606314377808

Epoch: 6| Step: 4
Training loss: 0.8966106251099178
Validation loss: 2.5794902692999337

Epoch: 6| Step: 5
Training loss: 0.9699071003483384
Validation loss: 2.559366023257904

Epoch: 6| Step: 6
Training loss: 0.7672725001094026
Validation loss: 2.5804378731343487

Epoch: 6| Step: 7
Training loss: 1.0953757056965656
Validation loss: 2.6190822897304775

Epoch: 6| Step: 8
Training loss: 1.2699952202053686
Validation loss: 2.63513473590928

Epoch: 6| Step: 9
Training loss: 0.670003457843341
Validation loss: 2.648297211448906

Epoch: 6| Step: 10
Training loss: 0.7741098275344716
Validation loss: 2.668178685996667

Epoch: 6| Step: 11
Training loss: 0.7070747067073789
Validation loss: 2.598783090884423

Epoch: 6| Step: 12
Training loss: 0.8394411763387712
Validation loss: 2.605132790962092

Epoch: 6| Step: 13
Training loss: 1.0453204669278153
Validation loss: 2.653767416692197

Epoch: 387| Step: 0
Training loss: 0.7335098527377908
Validation loss: 2.6512049316815443

Epoch: 6| Step: 1
Training loss: 0.9453119640506454
Validation loss: 2.6281462388422145

Epoch: 6| Step: 2
Training loss: 0.7725793721183859
Validation loss: 2.529023309590416

Epoch: 6| Step: 3
Training loss: 0.8048860990017037
Validation loss: 2.590117120291707

Epoch: 6| Step: 4
Training loss: 1.0050191091741976
Validation loss: 2.5994759517510437

Epoch: 6| Step: 5
Training loss: 0.824221425707483
Validation loss: 2.6725042468478244

Epoch: 6| Step: 6
Training loss: 1.0526279261174316
Validation loss: 2.6016816960580234

Epoch: 6| Step: 7
Training loss: 0.8229199341012977
Validation loss: 2.595961964228182

Epoch: 6| Step: 8
Training loss: 1.070232973137518
Validation loss: 2.6316085009421206

Epoch: 6| Step: 9
Training loss: 0.9323835309905776
Validation loss: 2.633031305867097

Epoch: 6| Step: 10
Training loss: 1.042019415573847
Validation loss: 2.6550549081319805

Epoch: 6| Step: 11
Training loss: 0.924000052650252
Validation loss: 2.612708575913311

Epoch: 6| Step: 12
Training loss: 0.7176837891108425
Validation loss: 2.6552316845455315

Epoch: 6| Step: 13
Training loss: 1.1328389131821013
Validation loss: 2.6941800747022624

Epoch: 388| Step: 0
Training loss: 1.0218334877844886
Validation loss: 2.732482967643553

Epoch: 6| Step: 1
Training loss: 1.1441683665904516
Validation loss: 2.753955149836429

Epoch: 6| Step: 2
Training loss: 0.8720419474364086
Validation loss: 2.722808483361178

Epoch: 6| Step: 3
Training loss: 0.8050723590672116
Validation loss: 2.6921889777612127

Epoch: 6| Step: 4
Training loss: 0.7363275583604003
Validation loss: 2.663847645199538

Epoch: 6| Step: 5
Training loss: 1.0865623816862309
Validation loss: 2.7034472969796903

Epoch: 6| Step: 6
Training loss: 1.082257408992638
Validation loss: 2.7173912628560823

Epoch: 6| Step: 7
Training loss: 0.7700100875788216
Validation loss: 2.7681660302547084

Epoch: 6| Step: 8
Training loss: 0.8847381385424186
Validation loss: 2.709424009543505

Epoch: 6| Step: 9
Training loss: 0.838039038258683
Validation loss: 2.672588364698801

Epoch: 6| Step: 10
Training loss: 1.0262689806615173
Validation loss: 2.7211427500005088

Epoch: 6| Step: 11
Training loss: 0.7036694643884202
Validation loss: 2.695585412108371

Epoch: 6| Step: 12
Training loss: 0.9329999367978646
Validation loss: 2.7503748407079374

Epoch: 6| Step: 13
Training loss: 0.7348678233871255
Validation loss: 2.6870695996703726

Epoch: 389| Step: 0
Training loss: 0.8836133582033202
Validation loss: 2.6953654113588597

Epoch: 6| Step: 1
Training loss: 0.7325756674472382
Validation loss: 2.7058329900379707

Epoch: 6| Step: 2
Training loss: 0.6762230592039723
Validation loss: 2.6941508125509683

Epoch: 6| Step: 3
Training loss: 0.9986543243854703
Validation loss: 2.734066740552961

Epoch: 6| Step: 4
Training loss: 0.9201019823522101
Validation loss: 2.691602680363017

Epoch: 6| Step: 5
Training loss: 0.7401900466891884
Validation loss: 2.668451015213179

Epoch: 6| Step: 6
Training loss: 0.9419776796745913
Validation loss: 2.7115929916852113

Epoch: 6| Step: 7
Training loss: 1.1931647658677744
Validation loss: 2.6600754212559883

Epoch: 6| Step: 8
Training loss: 0.6845926452563724
Validation loss: 2.6605152218416728

Epoch: 6| Step: 9
Training loss: 1.1653137139098968
Validation loss: 2.698694232448699

Epoch: 6| Step: 10
Training loss: 0.8788515540163991
Validation loss: 2.6924125071094007

Epoch: 6| Step: 11
Training loss: 1.1047871243933012
Validation loss: 2.676237697605707

Epoch: 6| Step: 12
Training loss: 0.8867013400212999
Validation loss: 2.705880702710116

Epoch: 6| Step: 13
Training loss: 0.7404230929045552
Validation loss: 2.6662946431612906

Epoch: 390| Step: 0
Training loss: 0.7527202309911306
Validation loss: 2.676899682263036

Epoch: 6| Step: 1
Training loss: 1.002360300238158
Validation loss: 2.6777112251688955

Epoch: 6| Step: 2
Training loss: 1.1165452725106115
Validation loss: 2.6816864120897628

Epoch: 6| Step: 3
Training loss: 0.8119201792068351
Validation loss: 2.6400112514785903

Epoch: 6| Step: 4
Training loss: 0.7038559399237564
Validation loss: 2.6315608308402756

Epoch: 6| Step: 5
Training loss: 0.730588444169721
Validation loss: 2.6868562666683693

Epoch: 6| Step: 6
Training loss: 0.8676538673943839
Validation loss: 2.640321431966025

Epoch: 6| Step: 7
Training loss: 0.8098826432866132
Validation loss: 2.6504204302587495

Epoch: 6| Step: 8
Training loss: 0.909498378079034
Validation loss: 2.634456223291202

Epoch: 6| Step: 9
Training loss: 0.8618323824431009
Validation loss: 2.6416707723768162

Epoch: 6| Step: 10
Training loss: 0.6465274531368975
Validation loss: 2.656579345032259

Epoch: 6| Step: 11
Training loss: 0.9764648083460683
Validation loss: 2.6114359195956034

Epoch: 6| Step: 12
Training loss: 1.1539894895289815
Validation loss: 2.648404431582055

Epoch: 6| Step: 13
Training loss: 0.8820396348607074
Validation loss: 2.6993654894839745

Epoch: 391| Step: 0
Training loss: 0.6895796359866808
Validation loss: 2.639801107534292

Epoch: 6| Step: 1
Training loss: 1.0904686889560964
Validation loss: 2.601376409433383

Epoch: 6| Step: 2
Training loss: 0.9071039254499011
Validation loss: 2.6709422515306764

Epoch: 6| Step: 3
Training loss: 0.9424432132319333
Validation loss: 2.668858839044617

Epoch: 6| Step: 4
Training loss: 1.2115767729643896
Validation loss: 2.6334337959762952

Epoch: 6| Step: 5
Training loss: 0.5529987525184316
Validation loss: 2.6709916288586726

Epoch: 6| Step: 6
Training loss: 1.020877636058436
Validation loss: 2.6689958582722464

Epoch: 6| Step: 7
Training loss: 0.572425064946446
Validation loss: 2.670139247154032

Epoch: 6| Step: 8
Training loss: 0.6460943745583556
Validation loss: 2.6334792141002024

Epoch: 6| Step: 9
Training loss: 0.8901631345611569
Validation loss: 2.6529961421783694

Epoch: 6| Step: 10
Training loss: 0.44798926570924036
Validation loss: 2.6372701487492183

Epoch: 6| Step: 11
Training loss: 0.8717880561164465
Validation loss: 2.6614384261629107

Epoch: 6| Step: 12
Training loss: 1.0662136812274359
Validation loss: 2.6791132542421168

Epoch: 6| Step: 13
Training loss: 0.7394124402251043
Validation loss: 2.6674209561087685

Epoch: 392| Step: 0
Training loss: 0.6386709417400482
Validation loss: 2.6938252644302287

Epoch: 6| Step: 1
Training loss: 0.7948332791082111
Validation loss: 2.6721025633991182

Epoch: 6| Step: 2
Training loss: 1.1635866664744117
Validation loss: 2.6574427451194986

Epoch: 6| Step: 3
Training loss: 0.9351315781120126
Validation loss: 2.7007041042507485

Epoch: 6| Step: 4
Training loss: 0.6748715490403804
Validation loss: 2.7282630987415404

Epoch: 6| Step: 5
Training loss: 0.5950414766553038
Validation loss: 2.718945580240346

Epoch: 6| Step: 6
Training loss: 0.9958288102200203
Validation loss: 2.7284525211130317

Epoch: 6| Step: 7
Training loss: 0.71713178330954
Validation loss: 2.7338139421601317

Epoch: 6| Step: 8
Training loss: 0.6375260646951942
Validation loss: 2.7647653166708883

Epoch: 6| Step: 9
Training loss: 0.9502789890812242
Validation loss: 2.7212761802389416

Epoch: 6| Step: 10
Training loss: 1.0740573831213809
Validation loss: 2.7246144794885727

Epoch: 6| Step: 11
Training loss: 0.7010753427005765
Validation loss: 2.704487921897213

Epoch: 6| Step: 12
Training loss: 0.7272570991733492
Validation loss: 2.726732381722082

Epoch: 6| Step: 13
Training loss: 0.7236305061746311
Validation loss: 2.655591329551314

Epoch: 393| Step: 0
Training loss: 0.8715328598043157
Validation loss: 2.6614088338788884

Epoch: 6| Step: 1
Training loss: 1.1131044481662382
Validation loss: 2.690903585782344

Epoch: 6| Step: 2
Training loss: 0.6126662894693333
Validation loss: 2.7110974413973583

Epoch: 6| Step: 3
Training loss: 0.933010669406017
Validation loss: 2.761651642167042

Epoch: 6| Step: 4
Training loss: 0.6608438015077012
Validation loss: 2.748902361898557

Epoch: 6| Step: 5
Training loss: 0.7520132858188309
Validation loss: 2.6956133098718813

Epoch: 6| Step: 6
Training loss: 0.9275989955705845
Validation loss: 2.7078068930715897

Epoch: 6| Step: 7
Training loss: 0.691475643835089
Validation loss: 2.756834921328242

Epoch: 6| Step: 8
Training loss: 0.5147795247841185
Validation loss: 2.6967754134926927

Epoch: 6| Step: 9
Training loss: 0.7978440918216643
Validation loss: 2.736930365207517

Epoch: 6| Step: 10
Training loss: 1.1699316568873197
Validation loss: 2.729788910689398

Epoch: 6| Step: 11
Training loss: 0.7043900870845785
Validation loss: 2.7548498823110514

Epoch: 6| Step: 12
Training loss: 0.8172780178258349
Validation loss: 2.716027383729947

Epoch: 6| Step: 13
Training loss: 0.7370848473216527
Validation loss: 2.6839937358987767

Epoch: 394| Step: 0
Training loss: 0.6882922636053724
Validation loss: 2.6788539053303975

Epoch: 6| Step: 1
Training loss: 0.9487585828289875
Validation loss: 2.689292546476311

Epoch: 6| Step: 2
Training loss: 0.9709081912888907
Validation loss: 2.652792756358451

Epoch: 6| Step: 3
Training loss: 0.7167973739248094
Validation loss: 2.6398395822414416

Epoch: 6| Step: 4
Training loss: 1.0239258976737535
Validation loss: 2.63915732563254

Epoch: 6| Step: 5
Training loss: 0.8875042297369945
Validation loss: 2.6264431029350934

Epoch: 6| Step: 6
Training loss: 0.7520487935032896
Validation loss: 2.6354756455487576

Epoch: 6| Step: 7
Training loss: 0.9137651660876486
Validation loss: 2.6197941491258714

Epoch: 6| Step: 8
Training loss: 0.7137157942396991
Validation loss: 2.6095960907916367

Epoch: 6| Step: 9
Training loss: 0.9463016599716176
Validation loss: 2.663357288024496

Epoch: 6| Step: 10
Training loss: 0.9521454013873869
Validation loss: 2.705461099004103

Epoch: 6| Step: 11
Training loss: 0.7399329223388105
Validation loss: 2.6878378603981816

Epoch: 6| Step: 12
Training loss: 0.7582852177149633
Validation loss: 2.718462742505092

Epoch: 6| Step: 13
Training loss: 0.7483228766922165
Validation loss: 2.6878529693888558

Epoch: 395| Step: 0
Training loss: 0.5924974330009513
Validation loss: 2.6471141858742016

Epoch: 6| Step: 1
Training loss: 0.9095630267840351
Validation loss: 2.6916404293738108

Epoch: 6| Step: 2
Training loss: 0.9619608756355477
Validation loss: 2.652447046320001

Epoch: 6| Step: 3
Training loss: 0.6593875359523221
Validation loss: 2.644855443709603

Epoch: 6| Step: 4
Training loss: 0.8923151810069995
Validation loss: 2.707418629652566

Epoch: 6| Step: 5
Training loss: 0.7046858946111624
Validation loss: 2.6521273465236446

Epoch: 6| Step: 6
Training loss: 0.6120499319731708
Validation loss: 2.649176195440908

Epoch: 6| Step: 7
Training loss: 0.757425897832519
Validation loss: 2.695984274772114

Epoch: 6| Step: 8
Training loss: 0.9512833798200047
Validation loss: 2.6569443786172635

Epoch: 6| Step: 9
Training loss: 0.8757154400861675
Validation loss: 2.7273915659897043

Epoch: 6| Step: 10
Training loss: 0.8051793345320323
Validation loss: 2.7044083887420456

Epoch: 6| Step: 11
Training loss: 0.6165710461000549
Validation loss: 2.6704567608556653

Epoch: 6| Step: 12
Training loss: 0.9981079082900739
Validation loss: 2.6964846066559502

Epoch: 6| Step: 13
Training loss: 0.8029259223450702
Validation loss: 2.7259951550474932

Epoch: 396| Step: 0
Training loss: 0.7249192965741516
Validation loss: 2.7550858588781484

Epoch: 6| Step: 1
Training loss: 0.898430600347148
Validation loss: 2.7417403795793485

Epoch: 6| Step: 2
Training loss: 0.7976909274970835
Validation loss: 2.699404233971598

Epoch: 6| Step: 3
Training loss: 0.9431510995498182
Validation loss: 2.695439285023811

Epoch: 6| Step: 4
Training loss: 0.6775544996968947
Validation loss: 2.6995809029636275

Epoch: 6| Step: 5
Training loss: 0.6958489224025843
Validation loss: 2.6971310879621435

Epoch: 6| Step: 6
Training loss: 0.9959259191006715
Validation loss: 2.7231994845891134

Epoch: 6| Step: 7
Training loss: 0.8332963021315699
Validation loss: 2.666118510849556

Epoch: 6| Step: 8
Training loss: 0.7828840333459156
Validation loss: 2.7120714921488163

Epoch: 6| Step: 9
Training loss: 0.8773370594778426
Validation loss: 2.7130382654210154

Epoch: 6| Step: 10
Training loss: 0.8506262996307692
Validation loss: 2.7463580493162856

Epoch: 6| Step: 11
Training loss: 0.6633996235568956
Validation loss: 2.7565380750351793

Epoch: 6| Step: 12
Training loss: 0.8028353513893305
Validation loss: 2.737735318386021

Epoch: 6| Step: 13
Training loss: 0.6010609306893295
Validation loss: 2.68440133001569

Epoch: 397| Step: 0
Training loss: 0.684520333243758
Validation loss: 2.7061019997950333

Epoch: 6| Step: 1
Training loss: 0.7687894857547042
Validation loss: 2.687708380848752

Epoch: 6| Step: 2
Training loss: 1.0664295012346177
Validation loss: 2.6953155812416343

Epoch: 6| Step: 3
Training loss: 0.5794390102116211
Validation loss: 2.7353088382833137

Epoch: 6| Step: 4
Training loss: 0.9898645436452052
Validation loss: 2.802756506359522

Epoch: 6| Step: 5
Training loss: 0.9737998031004909
Validation loss: 2.7695515662821477

Epoch: 6| Step: 6
Training loss: 0.8960002181870331
Validation loss: 2.7454211956601853

Epoch: 6| Step: 7
Training loss: 0.7370078594611673
Validation loss: 2.7382875479618045

Epoch: 6| Step: 8
Training loss: 0.6824075052094597
Validation loss: 2.723252569103719

Epoch: 6| Step: 9
Training loss: 0.4820231283978237
Validation loss: 2.711688623798603

Epoch: 6| Step: 10
Training loss: 0.9169970299996105
Validation loss: 2.715382050129725

Epoch: 6| Step: 11
Training loss: 0.9946118270463856
Validation loss: 2.749338287156961

Epoch: 6| Step: 12
Training loss: 0.7092799891900876
Validation loss: 2.7075212630555026

Epoch: 6| Step: 13
Training loss: 0.6671301502174082
Validation loss: 2.7151539650472576

Epoch: 398| Step: 0
Training loss: 0.7163273159458959
Validation loss: 2.750338562440723

Epoch: 6| Step: 1
Training loss: 0.7980895417058165
Validation loss: 2.739118882371653

Epoch: 6| Step: 2
Training loss: 0.8505175417392355
Validation loss: 2.7109025995094886

Epoch: 6| Step: 3
Training loss: 0.7246571239769019
Validation loss: 2.6451448060306664

Epoch: 6| Step: 4
Training loss: 0.8149010320848142
Validation loss: 2.707953739463257

Epoch: 6| Step: 5
Training loss: 0.872209390483778
Validation loss: 2.7089758086487365

Epoch: 6| Step: 6
Training loss: 0.8643301895784207
Validation loss: 2.705689318268336

Epoch: 6| Step: 7
Training loss: 0.7735128654983255
Validation loss: 2.67032175108987

Epoch: 6| Step: 8
Training loss: 0.8764098253753579
Validation loss: 2.653770456329578

Epoch: 6| Step: 9
Training loss: 1.0120096267197087
Validation loss: 2.6836457226647132

Epoch: 6| Step: 10
Training loss: 0.7539937260136522
Validation loss: 2.7227274129681

Epoch: 6| Step: 11
Training loss: 0.4616968720960348
Validation loss: 2.7221551814441813

Epoch: 6| Step: 12
Training loss: 1.0216659472049672
Validation loss: 2.725811954295109

Epoch: 6| Step: 13
Training loss: 0.7951419909850295
Validation loss: 2.710318019126358

Epoch: 399| Step: 0
Training loss: 0.7705918956369038
Validation loss: 2.732854133173956

Epoch: 6| Step: 1
Training loss: 0.8505057681435839
Validation loss: 2.7258931151687706

Epoch: 6| Step: 2
Training loss: 0.7750557048835958
Validation loss: 2.7122041086754303

Epoch: 6| Step: 3
Training loss: 0.6973808471193879
Validation loss: 2.7066377589564365

Epoch: 6| Step: 4
Training loss: 1.057103476978358
Validation loss: 2.7018986972461154

Epoch: 6| Step: 5
Training loss: 0.6204106394968383
Validation loss: 2.683797474124246

Epoch: 6| Step: 6
Training loss: 0.7110655533043623
Validation loss: 2.6796377342355617

Epoch: 6| Step: 7
Training loss: 0.7625886302779735
Validation loss: 2.669479411590057

Epoch: 6| Step: 8
Training loss: 0.7038944908116717
Validation loss: 2.721573061862515

Epoch: 6| Step: 9
Training loss: 0.708015557608499
Validation loss: 2.7120326575673217

Epoch: 6| Step: 10
Training loss: 0.6455651516054334
Validation loss: 2.6975563771010513

Epoch: 6| Step: 11
Training loss: 0.658962864007449
Validation loss: 2.6734523170070994

Epoch: 6| Step: 12
Training loss: 1.2511553670060327
Validation loss: 2.747460334105057

Epoch: 6| Step: 13
Training loss: 0.9617608117729661
Validation loss: 2.7255991460793796

Epoch: 400| Step: 0
Training loss: 0.7961629042009146
Validation loss: 2.699023536435341

Epoch: 6| Step: 1
Training loss: 0.7745654426001074
Validation loss: 2.699283067274641

Epoch: 6| Step: 2
Training loss: 1.0118596041511285
Validation loss: 2.644258764025409

Epoch: 6| Step: 3
Training loss: 0.6445189503738833
Validation loss: 2.6598923113901516

Epoch: 6| Step: 4
Training loss: 0.9893223401608771
Validation loss: 2.686494668806305

Epoch: 6| Step: 5
Training loss: 0.7494428074871247
Validation loss: 2.664898171713052

Epoch: 6| Step: 6
Training loss: 0.6220809240948202
Validation loss: 2.672062248227292

Epoch: 6| Step: 7
Training loss: 0.7633745243863701
Validation loss: 2.6772369212067018

Epoch: 6| Step: 8
Training loss: 0.8417956712895613
Validation loss: 2.641365459089189

Epoch: 6| Step: 9
Training loss: 0.8371984294706214
Validation loss: 2.674746971997919

Epoch: 6| Step: 10
Training loss: 0.5087144910525253
Validation loss: 2.7781531276358864

Epoch: 6| Step: 11
Training loss: 0.7333786881755432
Validation loss: 2.7165493590726295

Epoch: 6| Step: 12
Training loss: 0.7838171171808702
Validation loss: 2.6794313358393387

Epoch: 6| Step: 13
Training loss: 0.7462249161228167
Validation loss: 2.679995786915025

Epoch: 401| Step: 0
Training loss: 0.6287401347211141
Validation loss: 2.7392555857857297

Epoch: 6| Step: 1
Training loss: 0.6641201218681313
Validation loss: 2.7376270102150735

Epoch: 6| Step: 2
Training loss: 0.9543178785575882
Validation loss: 2.7351280555989876

Epoch: 6| Step: 3
Training loss: 0.8168674243321795
Validation loss: 2.742584880789205

Epoch: 6| Step: 4
Training loss: 1.0368658954572445
Validation loss: 2.7027209794010756

Epoch: 6| Step: 5
Training loss: 0.7671568202082233
Validation loss: 2.7464392323989495

Epoch: 6| Step: 6
Training loss: 0.8030584196405202
Validation loss: 2.8045467104060515

Epoch: 6| Step: 7
Training loss: 0.7788900972487866
Validation loss: 2.7362344432171906

Epoch: 6| Step: 8
Training loss: 0.5536898923504219
Validation loss: 2.746590306700496

Epoch: 6| Step: 9
Training loss: 0.7480368750478996
Validation loss: 2.764673848935375

Epoch: 6| Step: 10
Training loss: 0.655100110207707
Validation loss: 2.831364878161761

Epoch: 6| Step: 11
Training loss: 0.7546877590518609
Validation loss: 2.8294733251148023

Epoch: 6| Step: 12
Training loss: 0.987705379568298
Validation loss: 2.7876931184891762

Epoch: 6| Step: 13
Training loss: 0.774710368826421
Validation loss: 2.7383927827288073

Epoch: 402| Step: 0
Training loss: 0.7669276230469614
Validation loss: 2.788641277173334

Epoch: 6| Step: 1
Training loss: 0.6293397676896991
Validation loss: 2.7548971571307126

Epoch: 6| Step: 2
Training loss: 0.4448349382970181
Validation loss: 2.7411703630630706

Epoch: 6| Step: 3
Training loss: 0.9335385549661277
Validation loss: 2.663467713722896

Epoch: 6| Step: 4
Training loss: 0.7809414063379253
Validation loss: 2.730299639251495

Epoch: 6| Step: 5
Training loss: 0.863141976423658
Validation loss: 2.7204514072338597

Epoch: 6| Step: 6
Training loss: 0.9388230842149627
Validation loss: 2.7293134800294947

Epoch: 6| Step: 7
Training loss: 0.6429967936707285
Validation loss: 2.7116096828532594

Epoch: 6| Step: 8
Training loss: 0.6048111328380759
Validation loss: 2.7201036613009175

Epoch: 6| Step: 9
Training loss: 0.8893159984284158
Validation loss: 2.6981061674946356

Epoch: 6| Step: 10
Training loss: 0.7007826465945749
Validation loss: 2.751901604896849

Epoch: 6| Step: 11
Training loss: 0.7936490152354221
Validation loss: 2.7187644695028483

Epoch: 6| Step: 12
Training loss: 0.829765135155517
Validation loss: 2.7004993012372114

Epoch: 6| Step: 13
Training loss: 0.8478193697455964
Validation loss: 2.7478747391894323

Epoch: 403| Step: 0
Training loss: 0.6853003642846774
Validation loss: 2.7262677722918904

Epoch: 6| Step: 1
Training loss: 0.9736085695483571
Validation loss: 2.700365249041469

Epoch: 6| Step: 2
Training loss: 0.6495521111862855
Validation loss: 2.695382335697971

Epoch: 6| Step: 3
Training loss: 0.43753445012832437
Validation loss: 2.7098021021394905

Epoch: 6| Step: 4
Training loss: 0.6002999221699398
Validation loss: 2.7069825007024884

Epoch: 6| Step: 5
Training loss: 0.7674589574196785
Validation loss: 2.6687293916214783

Epoch: 6| Step: 6
Training loss: 0.9733693829211847
Validation loss: 2.7146890939255766

Epoch: 6| Step: 7
Training loss: 0.7903920294046062
Validation loss: 2.728224021276885

Epoch: 6| Step: 8
Training loss: 0.7294511285586828
Validation loss: 2.7324844654941165

Epoch: 6| Step: 9
Training loss: 0.6345060786233392
Validation loss: 2.67301609442095

Epoch: 6| Step: 10
Training loss: 0.9463554492886462
Validation loss: 2.7132208860920772

Epoch: 6| Step: 11
Training loss: 0.8170044090310778
Validation loss: 2.6966913354481696

Epoch: 6| Step: 12
Training loss: 0.8307080560152365
Validation loss: 2.71525110349266

Epoch: 6| Step: 13
Training loss: 0.9528405750075759
Validation loss: 2.728841810815272

Epoch: 404| Step: 0
Training loss: 0.6971886856841876
Validation loss: 2.6706321904402337

Epoch: 6| Step: 1
Training loss: 0.6238641908810244
Validation loss: 2.742570942645332

Epoch: 6| Step: 2
Training loss: 0.43809803891995797
Validation loss: 2.756050115878949

Epoch: 6| Step: 3
Training loss: 0.7474256680124094
Validation loss: 2.7235282329853545

Epoch: 6| Step: 4
Training loss: 0.38377011473185835
Validation loss: 2.7391996272090187

Epoch: 6| Step: 5
Training loss: 0.7240261805368948
Validation loss: 2.819779843288098

Epoch: 6| Step: 6
Training loss: 0.8386962858644305
Validation loss: 2.802594380532074

Epoch: 6| Step: 7
Training loss: 1.1091455571558757
Validation loss: 2.8053157814621152

Epoch: 6| Step: 8
Training loss: 1.1278673295127304
Validation loss: 2.780053985263636

Epoch: 6| Step: 9
Training loss: 0.9479338815544195
Validation loss: 2.7422718205398326

Epoch: 6| Step: 10
Training loss: 0.5440930588765877
Validation loss: 2.7747818961363975

Epoch: 6| Step: 11
Training loss: 0.5255059608444431
Validation loss: 2.799332233683416

Epoch: 6| Step: 12
Training loss: 0.6842556609873247
Validation loss: 2.7835981764585562

Epoch: 6| Step: 13
Training loss: 0.7651726690536224
Validation loss: 2.749721599705143

Epoch: 405| Step: 0
Training loss: 0.6552792362689934
Validation loss: 2.727046963590285

Epoch: 6| Step: 1
Training loss: 0.5046876570757454
Validation loss: 2.73007900820043

Epoch: 6| Step: 2
Training loss: 0.6209431351673315
Validation loss: 2.7130502462059023

Epoch: 6| Step: 3
Training loss: 0.8848424208703652
Validation loss: 2.7360006967417254

Epoch: 6| Step: 4
Training loss: 0.9044106661098016
Validation loss: 2.707306275885455

Epoch: 6| Step: 5
Training loss: 1.042420089366784
Validation loss: 2.635722814778248

Epoch: 6| Step: 6
Training loss: 0.7208387459200767
Validation loss: 2.6562005431115003

Epoch: 6| Step: 7
Training loss: 0.8734433086932297
Validation loss: 2.6925376060761677

Epoch: 6| Step: 8
Training loss: 0.8478711115216332
Validation loss: 2.7170278714720384

Epoch: 6| Step: 9
Training loss: 0.8197491482506015
Validation loss: 2.7249884374764024

Epoch: 6| Step: 10
Training loss: 0.8484313515006553
Validation loss: 2.7093812944631708

Epoch: 6| Step: 11
Training loss: 0.7091151765747802
Validation loss: 2.6411710546983493

Epoch: 6| Step: 12
Training loss: 0.7478711193174673
Validation loss: 2.65652989427521

Epoch: 6| Step: 13
Training loss: 0.584662002831231
Validation loss: 2.732791871039713

Epoch: 406| Step: 0
Training loss: 0.8584566237656304
Validation loss: 2.7492051709883953

Epoch: 6| Step: 1
Training loss: 0.8200497160936246
Validation loss: 2.719896761615622

Epoch: 6| Step: 2
Training loss: 0.5588512227412528
Validation loss: 2.7002691276076964

Epoch: 6| Step: 3
Training loss: 0.6054359427146853
Validation loss: 2.680352094293404

Epoch: 6| Step: 4
Training loss: 0.7243224858757507
Validation loss: 2.7014408046655514

Epoch: 6| Step: 5
Training loss: 0.634815249337292
Validation loss: 2.7372127811945326

Epoch: 6| Step: 6
Training loss: 0.619116893999442
Validation loss: 2.6605092923960902

Epoch: 6| Step: 7
Training loss: 0.6803867426441845
Validation loss: 2.6928001304538034

Epoch: 6| Step: 8
Training loss: 0.74203481609478
Validation loss: 2.7074524302719833

Epoch: 6| Step: 9
Training loss: 0.5776865301638919
Validation loss: 2.6912045931555024

Epoch: 6| Step: 10
Training loss: 1.0157944171159503
Validation loss: 2.717718754596451

Epoch: 6| Step: 11
Training loss: 0.6816078768408225
Validation loss: 2.7195511876103895

Epoch: 6| Step: 12
Training loss: 0.7426790717639548
Validation loss: 2.749560133116491

Epoch: 6| Step: 13
Training loss: 1.0675583648807019
Validation loss: 2.6673239603202883

Epoch: 407| Step: 0
Training loss: 0.6055652172394995
Validation loss: 2.731281383342829

Epoch: 6| Step: 1
Training loss: 0.7107791095398687
Validation loss: 2.7100868026326292

Epoch: 6| Step: 2
Training loss: 0.6462633383165777
Validation loss: 2.702393272896768

Epoch: 6| Step: 3
Training loss: 0.9688170009946774
Validation loss: 2.734348013608461

Epoch: 6| Step: 4
Training loss: 0.5415366793209603
Validation loss: 2.7044546719452343

Epoch: 6| Step: 5
Training loss: 0.8690179631118272
Validation loss: 2.7169841863588293

Epoch: 6| Step: 6
Training loss: 0.8030747483262258
Validation loss: 2.7327135542530594

Epoch: 6| Step: 7
Training loss: 0.9993147290194381
Validation loss: 2.6907275358682003

Epoch: 6| Step: 8
Training loss: 0.7992480976462731
Validation loss: 2.6796986956867603

Epoch: 6| Step: 9
Training loss: 0.517982670293437
Validation loss: 2.725653291838412

Epoch: 6| Step: 10
Training loss: 0.8140069484976487
Validation loss: 2.785660179600183

Epoch: 6| Step: 11
Training loss: 0.8195239318579097
Validation loss: 2.695257154992995

Epoch: 6| Step: 12
Training loss: 0.6396423805474201
Validation loss: 2.719401898915554

Epoch: 6| Step: 13
Training loss: 0.4696322086604425
Validation loss: 2.7486822410050973

Epoch: 408| Step: 0
Training loss: 0.6395433878358413
Validation loss: 2.7292538888597297

Epoch: 6| Step: 1
Training loss: 0.5184683000407307
Validation loss: 2.717866659079142

Epoch: 6| Step: 2
Training loss: 0.8039261632886754
Validation loss: 2.6823943677085955

Epoch: 6| Step: 3
Training loss: 0.711265739709239
Validation loss: 2.7237811909267315

Epoch: 6| Step: 4
Training loss: 0.7066092311787369
Validation loss: 2.6987774824539756

Epoch: 6| Step: 5
Training loss: 0.5652237222190963
Validation loss: 2.6688247580856124

Epoch: 6| Step: 6
Training loss: 0.8830762486051388
Validation loss: 2.703623804659024

Epoch: 6| Step: 7
Training loss: 0.932014118558339
Validation loss: 2.728752473651524

Epoch: 6| Step: 8
Training loss: 0.748980067065547
Validation loss: 2.695639187829789

Epoch: 6| Step: 9
Training loss: 0.7621893578288141
Validation loss: 2.777161454067555

Epoch: 6| Step: 10
Training loss: 0.7730762909800138
Validation loss: 2.7047393696889266

Epoch: 6| Step: 11
Training loss: 0.8652894839955477
Validation loss: 2.6627908544813796

Epoch: 6| Step: 12
Training loss: 0.7594327221819728
Validation loss: 2.713851088578723

Epoch: 6| Step: 13
Training loss: 0.7792245166810722
Validation loss: 2.755335472553136

Epoch: 409| Step: 0
Training loss: 0.9739414288418864
Validation loss: 2.7298258987450663

Epoch: 6| Step: 1
Training loss: 0.8189939528580875
Validation loss: 2.785422007047507

Epoch: 6| Step: 2
Training loss: 0.6030790113793493
Validation loss: 2.738795908234544

Epoch: 6| Step: 3
Training loss: 0.7859192741813787
Validation loss: 2.702134937822034

Epoch: 6| Step: 4
Training loss: 0.7372907826710368
Validation loss: 2.7622747441624176

Epoch: 6| Step: 5
Training loss: 0.6516090870400999
Validation loss: 2.761310192860644

Epoch: 6| Step: 6
Training loss: 0.5133466379910308
Validation loss: 2.7217566720299042

Epoch: 6| Step: 7
Training loss: 0.6644974350101173
Validation loss: 2.7556744898061365

Epoch: 6| Step: 8
Training loss: 0.6992137418599561
Validation loss: 2.776382229773524

Epoch: 6| Step: 9
Training loss: 0.6631911676025213
Validation loss: 2.7976231062878014

Epoch: 6| Step: 10
Training loss: 0.7618486342589431
Validation loss: 2.7974123589517568

Epoch: 6| Step: 11
Training loss: 0.687644618169366
Validation loss: 2.7423410254935066

Epoch: 6| Step: 12
Training loss: 0.707019869043631
Validation loss: 2.760742432187563

Epoch: 6| Step: 13
Training loss: 0.7106154833905429
Validation loss: 2.749044382344167

Epoch: 410| Step: 0
Training loss: 0.8302759271448427
Validation loss: 2.75122537188532

Epoch: 6| Step: 1
Training loss: 0.8735839420723922
Validation loss: 2.7079106490097726

Epoch: 6| Step: 2
Training loss: 0.8161468823946938
Validation loss: 2.779438371735776

Epoch: 6| Step: 3
Training loss: 0.7168729154494957
Validation loss: 2.733847721669052

Epoch: 6| Step: 4
Training loss: 0.7829561295916735
Validation loss: 2.7112220666108

Epoch: 6| Step: 5
Training loss: 0.6309472132138714
Validation loss: 2.7231219279747845

Epoch: 6| Step: 6
Training loss: 0.8488264312937903
Validation loss: 2.680999256849631

Epoch: 6| Step: 7
Training loss: 0.5570526204550802
Validation loss: 2.7404683113616164

Epoch: 6| Step: 8
Training loss: 0.9408883217306484
Validation loss: 2.67358373542631

Epoch: 6| Step: 9
Training loss: 0.5637152049117424
Validation loss: 2.7867724280235815

Epoch: 6| Step: 10
Training loss: 0.6788952913266822
Validation loss: 2.699478409271654

Epoch: 6| Step: 11
Training loss: 1.018360386399095
Validation loss: 2.7617364475487145

Epoch: 6| Step: 12
Training loss: 0.6180448974685752
Validation loss: 2.732064729826665

Epoch: 6| Step: 13
Training loss: 0.6652530544344206
Validation loss: 2.767061553679424

Epoch: 411| Step: 0
Training loss: 0.6174591046277934
Validation loss: 2.75444011879303

Epoch: 6| Step: 1
Training loss: 0.4801333427488963
Validation loss: 2.753543954379621

Epoch: 6| Step: 2
Training loss: 0.8172901242296955
Validation loss: 2.743266126273744

Epoch: 6| Step: 3
Training loss: 0.7149484276345347
Validation loss: 2.70010992815385

Epoch: 6| Step: 4
Training loss: 0.7498228738163675
Validation loss: 2.7394548731711783

Epoch: 6| Step: 5
Training loss: 0.6955430152337789
Validation loss: 2.746554499283305

Epoch: 6| Step: 6
Training loss: 0.5904650163696505
Validation loss: 2.754325780634347

Epoch: 6| Step: 7
Training loss: 0.753188666347455
Validation loss: 2.7721235431197666

Epoch: 6| Step: 8
Training loss: 0.715964434219892
Validation loss: 2.740141203808312

Epoch: 6| Step: 9
Training loss: 0.7594155336087811
Validation loss: 2.746730450272295

Epoch: 6| Step: 10
Training loss: 0.7421058208293322
Validation loss: 2.78981062172312

Epoch: 6| Step: 11
Training loss: 0.4907327983054864
Validation loss: 2.786057492715662

Epoch: 6| Step: 12
Training loss: 0.8026862211240249
Validation loss: 2.791727554074828

Epoch: 6| Step: 13
Training loss: 0.8242516533670455
Validation loss: 2.806970501270769

Epoch: 412| Step: 0
Training loss: 0.8788620323078449
Validation loss: 2.792387290485491

Epoch: 6| Step: 1
Training loss: 0.822231156086571
Validation loss: 2.8232144038054807

Epoch: 6| Step: 2
Training loss: 0.717078670646881
Validation loss: 2.808150750364855

Epoch: 6| Step: 3
Training loss: 0.7665912991948322
Validation loss: 2.75840366068346

Epoch: 6| Step: 4
Training loss: 0.681947873886646
Validation loss: 2.6828755209320554

Epoch: 6| Step: 5
Training loss: 0.772889646450292
Validation loss: 2.7750858906464293

Epoch: 6| Step: 6
Training loss: 0.4911177681448476
Validation loss: 2.7557166675627114

Epoch: 6| Step: 7
Training loss: 0.5373544307356048
Validation loss: 2.702299841033035

Epoch: 6| Step: 8
Training loss: 0.7380388457353252
Validation loss: 2.730166045997505

Epoch: 6| Step: 9
Training loss: 0.6726280693858974
Validation loss: 2.7079686555118996

Epoch: 6| Step: 10
Training loss: 0.5525728400792206
Validation loss: 2.702578891869498

Epoch: 6| Step: 11
Training loss: 0.4918783215867457
Validation loss: 2.7290094247806445

Epoch: 6| Step: 12
Training loss: 0.6872024759323494
Validation loss: 2.7416638257399413

Epoch: 6| Step: 13
Training loss: 0.8303017707679939
Validation loss: 2.722368047229547

Epoch: 413| Step: 0
Training loss: 0.8090290243296554
Validation loss: 2.721783593471859

Epoch: 6| Step: 1
Training loss: 0.7267539479686791
Validation loss: 2.7377000628195183

Epoch: 6| Step: 2
Training loss: 0.617037960237215
Validation loss: 2.748697058916824

Epoch: 6| Step: 3
Training loss: 0.6952710514358786
Validation loss: 2.727220821970407

Epoch: 6| Step: 4
Training loss: 0.5831334986583585
Validation loss: 2.7091227236887656

Epoch: 6| Step: 5
Training loss: 0.7452129337494771
Validation loss: 2.6840322729426473

Epoch: 6| Step: 6
Training loss: 0.41573173615188785
Validation loss: 2.7589084799698242

Epoch: 6| Step: 7
Training loss: 0.6603463706100431
Validation loss: 2.739496285296945

Epoch: 6| Step: 8
Training loss: 0.8753462515074113
Validation loss: 2.7336609989022693

Epoch: 6| Step: 9
Training loss: 0.5765712323858504
Validation loss: 2.736416227386802

Epoch: 6| Step: 10
Training loss: 0.484571862977456
Validation loss: 2.6626854672256113

Epoch: 6| Step: 11
Training loss: 0.6015003717219979
Validation loss: 2.7560161759548207

Epoch: 6| Step: 12
Training loss: 0.6773908772512863
Validation loss: 2.73350474723393

Epoch: 6| Step: 13
Training loss: 0.557794813201632
Validation loss: 2.732408321293374

Epoch: 414| Step: 0
Training loss: 0.534216424491219
Validation loss: 2.7753158870676784

Epoch: 6| Step: 1
Training loss: 0.5015606366179366
Validation loss: 2.756331740570746

Epoch: 6| Step: 2
Training loss: 0.6621968709472539
Validation loss: 2.7267599389585935

Epoch: 6| Step: 3
Training loss: 0.6335126041703031
Validation loss: 2.7429341081434346

Epoch: 6| Step: 4
Training loss: 0.6417673671855633
Validation loss: 2.73931099199159

Epoch: 6| Step: 5
Training loss: 0.8225232805708259
Validation loss: 2.734792550313185

Epoch: 6| Step: 6
Training loss: 0.54830408022147
Validation loss: 2.696148743571081

Epoch: 6| Step: 7
Training loss: 0.849715057464912
Validation loss: 2.702429738973756

Epoch: 6| Step: 8
Training loss: 0.7482259351796963
Validation loss: 2.752291764811406

Epoch: 6| Step: 9
Training loss: 0.5055352428160929
Validation loss: 2.7898032436245064

Epoch: 6| Step: 10
Training loss: 0.7444840887609848
Validation loss: 2.771723386796238

Epoch: 6| Step: 11
Training loss: 0.6507673117803926
Validation loss: 2.7783194829652396

Epoch: 6| Step: 12
Training loss: 0.5100762016738059
Validation loss: 2.7743580038316766

Epoch: 6| Step: 13
Training loss: 0.6421886991689211
Validation loss: 2.808857459296196

Epoch: 415| Step: 0
Training loss: 0.6743470778177875
Validation loss: 2.811510773930899

Epoch: 6| Step: 1
Training loss: 0.4984862539908053
Validation loss: 2.8170976711570908

Epoch: 6| Step: 2
Training loss: 0.5804576980544992
Validation loss: 2.729893657932707

Epoch: 6| Step: 3
Training loss: 0.8445835587837308
Validation loss: 2.75757337763649

Epoch: 6| Step: 4
Training loss: 0.7318582629628195
Validation loss: 2.7497295622352946

Epoch: 6| Step: 5
Training loss: 0.5596026665885794
Validation loss: 2.708593067528164

Epoch: 6| Step: 6
Training loss: 0.7161024092022317
Validation loss: 2.7758968141325395

Epoch: 6| Step: 7
Training loss: 0.6732054556223801
Validation loss: 2.6850903080174167

Epoch: 6| Step: 8
Training loss: 0.6178403853672658
Validation loss: 2.704334907020021

Epoch: 6| Step: 9
Training loss: 0.7868437969756645
Validation loss: 2.636001903905649

Epoch: 6| Step: 10
Training loss: 0.7902416068635736
Validation loss: 2.645197624270391

Epoch: 6| Step: 11
Training loss: 0.7450404696385499
Validation loss: 2.6967098428627834

Epoch: 6| Step: 12
Training loss: 0.6846463192525944
Validation loss: 2.7248341311564572

Epoch: 6| Step: 13
Training loss: 0.6548939272480316
Validation loss: 2.7050477614919326

Epoch: 416| Step: 0
Training loss: 0.6144685611131881
Validation loss: 2.7176414948433925

Epoch: 6| Step: 1
Training loss: 0.7474590810847896
Validation loss: 2.747429036064859

Epoch: 6| Step: 2
Training loss: 0.8177756182612134
Validation loss: 2.744843402256747

Epoch: 6| Step: 3
Training loss: 0.8595158201495962
Validation loss: 2.7630958558928302

Epoch: 6| Step: 4
Training loss: 0.5957485494335858
Validation loss: 2.8293543579660874

Epoch: 6| Step: 5
Training loss: 0.6004689668709102
Validation loss: 2.740032831213437

Epoch: 6| Step: 6
Training loss: 0.797659730670146
Validation loss: 2.78023972182113

Epoch: 6| Step: 7
Training loss: 0.6033445936894466
Validation loss: 2.782000094072097

Epoch: 6| Step: 8
Training loss: 0.9476862966329452
Validation loss: 2.778942551124173

Epoch: 6| Step: 9
Training loss: 0.6796234363750511
Validation loss: 2.7674515290740933

Epoch: 6| Step: 10
Training loss: 0.5470127204779335
Validation loss: 2.7404011471481793

Epoch: 6| Step: 11
Training loss: 0.6885572886654548
Validation loss: 2.786113886474194

Epoch: 6| Step: 12
Training loss: 0.42779247986656255
Validation loss: 2.719190057678654

Epoch: 6| Step: 13
Training loss: 0.7881526800584278
Validation loss: 2.739814985414519

Epoch: 417| Step: 0
Training loss: 0.6621830992037118
Validation loss: 2.7730235475901575

Epoch: 6| Step: 1
Training loss: 0.6000727500123534
Validation loss: 2.722620011046974

Epoch: 6| Step: 2
Training loss: 0.7428732665245683
Validation loss: 2.667139984881608

Epoch: 6| Step: 3
Training loss: 0.6745292443693421
Validation loss: 2.743323674893749

Epoch: 6| Step: 4
Training loss: 0.7522367264631016
Validation loss: 2.734540429333571

Epoch: 6| Step: 5
Training loss: 0.7736930425013819
Validation loss: 2.734888678847509

Epoch: 6| Step: 6
Training loss: 0.6272421197529267
Validation loss: 2.7533499658634875

Epoch: 6| Step: 7
Training loss: 0.5290407638005313
Validation loss: 2.7515367057958873

Epoch: 6| Step: 8
Training loss: 0.6250163076180598
Validation loss: 2.7679160877988815

Epoch: 6| Step: 9
Training loss: 0.8901301565257974
Validation loss: 2.8121012228368794

Epoch: 6| Step: 10
Training loss: 0.474140972188237
Validation loss: 2.7527837968365505

Epoch: 6| Step: 11
Training loss: 0.7111437990785229
Validation loss: 2.7644730519824434

Epoch: 6| Step: 12
Training loss: 0.7476926119102772
Validation loss: 2.74819087717848

Epoch: 6| Step: 13
Training loss: 0.6711731283118217
Validation loss: 2.7516479467367105

Epoch: 418| Step: 0
Training loss: 0.5914026086410433
Validation loss: 2.744888164023188

Epoch: 6| Step: 1
Training loss: 0.5872472239559032
Validation loss: 2.7674681130823333

Epoch: 6| Step: 2
Training loss: 0.7708496959771045
Validation loss: 2.774904405820323

Epoch: 6| Step: 3
Training loss: 0.7171031079474038
Validation loss: 2.7628194655884424

Epoch: 6| Step: 4
Training loss: 0.6747620012884522
Validation loss: 2.7689406209502634

Epoch: 6| Step: 5
Training loss: 0.9561872224832895
Validation loss: 2.7698646850448965

Epoch: 6| Step: 6
Training loss: 0.7126415496895783
Validation loss: 2.770571550513006

Epoch: 6| Step: 7
Training loss: 0.36805602089634554
Validation loss: 2.7565978259662964

Epoch: 6| Step: 8
Training loss: 0.7020888853749727
Validation loss: 2.7720761535435345

Epoch: 6| Step: 9
Training loss: 0.9324301966602269
Validation loss: 2.8582295275672105

Epoch: 6| Step: 10
Training loss: 0.8455942625674884
Validation loss: 2.782878527535353

Epoch: 6| Step: 11
Training loss: 0.7038875048107011
Validation loss: 2.780271908226258

Epoch: 6| Step: 12
Training loss: 0.6518323801359293
Validation loss: 2.769148455351477

Epoch: 6| Step: 13
Training loss: 0.6674034001605307
Validation loss: 2.8018311643521914

Epoch: 419| Step: 0
Training loss: 0.7449480617263191
Validation loss: 2.7490053690107064

Epoch: 6| Step: 1
Training loss: 0.819570550985362
Validation loss: 2.8011121496769182

Epoch: 6| Step: 2
Training loss: 0.8064764562364196
Validation loss: 2.783335200516613

Epoch: 6| Step: 3
Training loss: 0.4888230179246615
Validation loss: 2.76698815611214

Epoch: 6| Step: 4
Training loss: 0.7532283126438641
Validation loss: 2.7829224062332734

Epoch: 6| Step: 5
Training loss: 0.5454628286310744
Validation loss: 2.7845960555717575

Epoch: 6| Step: 6
Training loss: 0.6390698327574182
Validation loss: 2.790346678111057

Epoch: 6| Step: 7
Training loss: 0.5738128473106092
Validation loss: 2.74855820110846

Epoch: 6| Step: 8
Training loss: 0.609415493133276
Validation loss: 2.75911822220528

Epoch: 6| Step: 9
Training loss: 0.5419922974732434
Validation loss: 2.8002507954630884

Epoch: 6| Step: 10
Training loss: 0.6274204117049323
Validation loss: 2.7456046872220123

Epoch: 6| Step: 11
Training loss: 0.3525943871197958
Validation loss: 2.719535524152513

Epoch: 6| Step: 12
Training loss: 0.6765209846004985
Validation loss: 2.724624455090063

Epoch: 6| Step: 13
Training loss: 0.7565940027244789
Validation loss: 2.746361746085174

Epoch: 420| Step: 0
Training loss: 0.6816988594953284
Validation loss: 2.694342987099256

Epoch: 6| Step: 1
Training loss: 0.5999619630836748
Validation loss: 2.7224130617662947

Epoch: 6| Step: 2
Training loss: 0.5856827754423547
Validation loss: 2.7223198353097353

Epoch: 6| Step: 3
Training loss: 0.5331254839699305
Validation loss: 2.6927068084377987

Epoch: 6| Step: 4
Training loss: 0.8486194675392768
Validation loss: 2.7227166423183853

Epoch: 6| Step: 5
Training loss: 0.777826897076786
Validation loss: 2.721562491052756

Epoch: 6| Step: 6
Training loss: 0.6115965330140399
Validation loss: 2.6713218636932536

Epoch: 6| Step: 7
Training loss: 0.49851611602620327
Validation loss: 2.6870886317803384

Epoch: 6| Step: 8
Training loss: 0.565355707840122
Validation loss: 2.7005325116034076

Epoch: 6| Step: 9
Training loss: 0.4556062768822776
Validation loss: 2.722531462208219

Epoch: 6| Step: 10
Training loss: 0.742529619570173
Validation loss: 2.7455029709030563

Epoch: 6| Step: 11
Training loss: 0.4967352556652386
Validation loss: 2.729086799520681

Epoch: 6| Step: 12
Training loss: 0.668488239147785
Validation loss: 2.7167810640256658

Epoch: 6| Step: 13
Training loss: 0.6831537192852564
Validation loss: 2.78075032978444

Epoch: 421| Step: 0
Training loss: 0.37106228745248654
Validation loss: 2.7585022291661128

Epoch: 6| Step: 1
Training loss: 0.570542485098657
Validation loss: 2.8074053928267735

Epoch: 6| Step: 2
Training loss: 0.6363832490858807
Validation loss: 2.723443317534784

Epoch: 6| Step: 3
Training loss: 0.5942943988466135
Validation loss: 2.719059776693814

Epoch: 6| Step: 4
Training loss: 0.798378442420305
Validation loss: 2.7896525010946447

Epoch: 6| Step: 5
Training loss: 0.7261454297811893
Validation loss: 2.7693505060054995

Epoch: 6| Step: 6
Training loss: 0.49887933908791593
Validation loss: 2.820411447918535

Epoch: 6| Step: 7
Training loss: 0.5956791356994098
Validation loss: 2.788309802472715

Epoch: 6| Step: 8
Training loss: 0.5815508351086227
Validation loss: 2.783503601630126

Epoch: 6| Step: 9
Training loss: 0.6378793261076879
Validation loss: 2.7695763588313396

Epoch: 6| Step: 10
Training loss: 0.6156006706581155
Validation loss: 2.7764185971028765

Epoch: 6| Step: 11
Training loss: 0.5616244548656569
Validation loss: 2.8262576547367453

Epoch: 6| Step: 12
Training loss: 0.7249126776362473
Validation loss: 2.7605273146615805

Epoch: 6| Step: 13
Training loss: 0.698077778700506
Validation loss: 2.7577590288808596

Epoch: 422| Step: 0
Training loss: 0.5888935798057324
Validation loss: 2.7686384633534757

Epoch: 6| Step: 1
Training loss: 0.525509902290959
Validation loss: 2.773474636635171

Epoch: 6| Step: 2
Training loss: 0.6666445182061631
Validation loss: 2.753874808779037

Epoch: 6| Step: 3
Training loss: 0.7783909170944016
Validation loss: 2.772759038475062

Epoch: 6| Step: 4
Training loss: 0.6661362077396862
Validation loss: 2.7970331669417234

Epoch: 6| Step: 5
Training loss: 0.42578013008740334
Validation loss: 2.753225789875506

Epoch: 6| Step: 6
Training loss: 0.6810709805586774
Validation loss: 2.779206550365339

Epoch: 6| Step: 7
Training loss: 0.8592656152642083
Validation loss: 2.7269270542983945

Epoch: 6| Step: 8
Training loss: 0.616728044260571
Validation loss: 2.781511144486476

Epoch: 6| Step: 9
Training loss: 0.7227334471014069
Validation loss: 2.768575807521129

Epoch: 6| Step: 10
Training loss: 0.46877800539916925
Validation loss: 2.7991615056040198

Epoch: 6| Step: 11
Training loss: 0.5035353485813737
Validation loss: 2.7327010925744557

Epoch: 6| Step: 12
Training loss: 0.5642962386217348
Validation loss: 2.754374896635869

Epoch: 6| Step: 13
Training loss: 0.6147670363539564
Validation loss: 2.7532142437064073

Epoch: 423| Step: 0
Training loss: 0.5853799328756035
Validation loss: 2.7414515740412995

Epoch: 6| Step: 1
Training loss: 0.6911032492295063
Validation loss: 2.8048767479367305

Epoch: 6| Step: 2
Training loss: 0.5219262069432382
Validation loss: 2.7210150889219316

Epoch: 6| Step: 3
Training loss: 0.5090993275677854
Validation loss: 2.7204711990472497

Epoch: 6| Step: 4
Training loss: 0.6798551944513742
Validation loss: 2.695616847744643

Epoch: 6| Step: 5
Training loss: 0.8740288931393976
Validation loss: 2.7323864636184143

Epoch: 6| Step: 6
Training loss: 0.6294669501026969
Validation loss: 2.6841478807545376

Epoch: 6| Step: 7
Training loss: 0.5544970548119854
Validation loss: 2.675249493333817

Epoch: 6| Step: 8
Training loss: 0.6054171632509586
Validation loss: 2.7422941210705183

Epoch: 6| Step: 9
Training loss: 0.5095241749449805
Validation loss: 2.7437849038234954

Epoch: 6| Step: 10
Training loss: 0.6409177808922616
Validation loss: 2.7547996280357703

Epoch: 6| Step: 11
Training loss: 0.5413963548160605
Validation loss: 2.7276613340322964

Epoch: 6| Step: 12
Training loss: 0.5109953681302898
Validation loss: 2.757638754698298

Epoch: 6| Step: 13
Training loss: 0.48729072810725904
Validation loss: 2.704008939127282

Epoch: 424| Step: 0
Training loss: 0.5920719728536543
Validation loss: 2.743561707381276

Epoch: 6| Step: 1
Training loss: 0.7719233169568449
Validation loss: 2.7534944916367525

Epoch: 6| Step: 2
Training loss: 0.5731899101165892
Validation loss: 2.7719208201420553

Epoch: 6| Step: 3
Training loss: 0.8014488972550567
Validation loss: 2.8136510683436344

Epoch: 6| Step: 4
Training loss: 0.465955670601767
Validation loss: 2.7537984479722257

Epoch: 6| Step: 5
Training loss: 0.43294579832269803
Validation loss: 2.7380593682046364

Epoch: 6| Step: 6
Training loss: 0.5221009342162596
Validation loss: 2.81661784046974

Epoch: 6| Step: 7
Training loss: 0.5239428457874536
Validation loss: 2.758079768009565

Epoch: 6| Step: 8
Training loss: 0.5520031948826425
Validation loss: 2.762147991486106

Epoch: 6| Step: 9
Training loss: 0.6415818674440984
Validation loss: 2.7945329176453706

Epoch: 6| Step: 10
Training loss: 0.6522265346088667
Validation loss: 2.767880972599985

Epoch: 6| Step: 11
Training loss: 0.9198212781195529
Validation loss: 2.779482905188515

Epoch: 6| Step: 12
Training loss: 0.9404254410153672
Validation loss: 2.7320224487290914

Epoch: 6| Step: 13
Training loss: 0.598461008232669
Validation loss: 2.6061681659880636

Epoch: 425| Step: 0
Training loss: 0.49449735889944507
Validation loss: 2.6442712593090794

Epoch: 6| Step: 1
Training loss: 0.7105419190219807
Validation loss: 2.684810238696972

Epoch: 6| Step: 2
Training loss: 0.7849214117231622
Validation loss: 2.7119543420339087

Epoch: 6| Step: 3
Training loss: 0.8415675016722727
Validation loss: 2.625747142911866

Epoch: 6| Step: 4
Training loss: 0.7215290660885407
Validation loss: 2.652447181149407

Epoch: 6| Step: 5
Training loss: 0.7788734911244519
Validation loss: 2.698604088673399

Epoch: 6| Step: 6
Training loss: 0.7139847811217634
Validation loss: 2.6060707811290698

Epoch: 6| Step: 7
Training loss: 0.5374357029804628
Validation loss: 2.6490165505041623

Epoch: 6| Step: 8
Training loss: 0.7764572379231861
Validation loss: 2.63444653976159

Epoch: 6| Step: 9
Training loss: 0.9273844812023957
Validation loss: 2.6359323039867637

Epoch: 6| Step: 10
Training loss: 0.5882825337227522
Validation loss: 2.668826857449532

Epoch: 6| Step: 11
Training loss: 0.7374395992308339
Validation loss: 2.729927602397184

Epoch: 6| Step: 12
Training loss: 0.5849447359570307
Validation loss: 2.691686474478229

Epoch: 6| Step: 13
Training loss: 0.6661417106240366
Validation loss: 2.7249896623841163

Epoch: 426| Step: 0
Training loss: 0.5730604049239926
Validation loss: 2.7539412548104028

Epoch: 6| Step: 1
Training loss: 0.6707876188880868
Validation loss: 2.7166479176379434

Epoch: 6| Step: 2
Training loss: 0.7244765578953614
Validation loss: 2.776507316503234

Epoch: 6| Step: 3
Training loss: 0.7329574051277662
Validation loss: 2.7757144947508627

Epoch: 6| Step: 4
Training loss: 0.8045517890339894
Validation loss: 2.803657675617759

Epoch: 6| Step: 5
Training loss: 0.4920422475923752
Validation loss: 2.7373742502904417

Epoch: 6| Step: 6
Training loss: 0.6973660607757326
Validation loss: 2.738187054561694

Epoch: 6| Step: 7
Training loss: 0.6734760636265353
Validation loss: 2.744739001141031

Epoch: 6| Step: 8
Training loss: 0.5077675432699023
Validation loss: 2.750175672757695

Epoch: 6| Step: 9
Training loss: 0.46250339197513024
Validation loss: 2.773325585628043

Epoch: 6| Step: 10
Training loss: 0.6034875264462916
Validation loss: 2.801808486751458

Epoch: 6| Step: 11
Training loss: 0.6957202530154866
Validation loss: 2.854844177656949

Epoch: 6| Step: 12
Training loss: 0.755751609512821
Validation loss: 2.8029565455053005

Epoch: 6| Step: 13
Training loss: 0.666158755855372
Validation loss: 2.875379095100607

Epoch: 427| Step: 0
Training loss: 0.6133739134159107
Validation loss: 2.7899996254349873

Epoch: 6| Step: 1
Training loss: 0.7411741868308044
Validation loss: 2.7601321859540744

Epoch: 6| Step: 2
Training loss: 0.6509047300648918
Validation loss: 2.787617384715542

Epoch: 6| Step: 3
Training loss: 0.6137096099615778
Validation loss: 2.7372067130341753

Epoch: 6| Step: 4
Training loss: 0.45034484696805566
Validation loss: 2.742132101196734

Epoch: 6| Step: 5
Training loss: 0.4694262077650404
Validation loss: 2.7699844570618986

Epoch: 6| Step: 6
Training loss: 0.47983152109982935
Validation loss: 2.749040262770447

Epoch: 6| Step: 7
Training loss: 0.5417999751546184
Validation loss: 2.7488288119381514

Epoch: 6| Step: 8
Training loss: 0.5480469000144077
Validation loss: 2.812168709352019

Epoch: 6| Step: 9
Training loss: 0.4078627997469672
Validation loss: 2.7382549986621707

Epoch: 6| Step: 10
Training loss: 0.5235340826403869
Validation loss: 2.7641038752467852

Epoch: 6| Step: 11
Training loss: 0.35218666618133376
Validation loss: 2.769740144772394

Epoch: 6| Step: 12
Training loss: 0.6834652807226068
Validation loss: 2.8009977873267182

Epoch: 6| Step: 13
Training loss: 0.5765027663966005
Validation loss: 2.777226141090661

Epoch: 428| Step: 0
Training loss: 0.7060397029146642
Validation loss: 2.7808063453261713

Epoch: 6| Step: 1
Training loss: 0.5347977432848894
Validation loss: 2.753706341785698

Epoch: 6| Step: 2
Training loss: 0.5651407244645653
Validation loss: 2.713775395280843

Epoch: 6| Step: 3
Training loss: 0.650860224553727
Validation loss: 2.70320773135906

Epoch: 6| Step: 4
Training loss: 0.5664577329192136
Validation loss: 2.7114431915466155

Epoch: 6| Step: 5
Training loss: 0.6477178693846264
Validation loss: 2.7103345568742556

Epoch: 6| Step: 6
Training loss: 0.6120905402815058
Validation loss: 2.778170463038403

Epoch: 6| Step: 7
Training loss: 0.5932990921869988
Validation loss: 2.702106085343015

Epoch: 6| Step: 8
Training loss: 0.5085612718844625
Validation loss: 2.7725467738020444

Epoch: 6| Step: 9
Training loss: 0.6267296936631802
Validation loss: 2.7421328982055004

Epoch: 6| Step: 10
Training loss: 0.4805341536503708
Validation loss: 2.769470458087613

Epoch: 6| Step: 11
Training loss: 0.5429466297940507
Validation loss: 2.791873936051951

Epoch: 6| Step: 12
Training loss: 0.6265255905277055
Validation loss: 2.7988229712939945

Epoch: 6| Step: 13
Training loss: 0.7754731026319215
Validation loss: 2.7711914280454533

Epoch: 429| Step: 0
Training loss: 0.7847276723066658
Validation loss: 2.8374506308900322

Epoch: 6| Step: 1
Training loss: 0.5425908811537642
Validation loss: 2.7150585501242928

Epoch: 6| Step: 2
Training loss: 0.5193323887721341
Validation loss: 2.8159208192431096

Epoch: 6| Step: 3
Training loss: 0.6815657478895288
Validation loss: 2.705299715406507

Epoch: 6| Step: 4
Training loss: 0.6503015634771069
Validation loss: 2.7701332288163427

Epoch: 6| Step: 5
Training loss: 0.415519561874014
Validation loss: 2.795077444208083

Epoch: 6| Step: 6
Training loss: 0.5483516919426213
Validation loss: 2.796954972528563

Epoch: 6| Step: 7
Training loss: 0.5330304994713709
Validation loss: 2.760684872439257

Epoch: 6| Step: 8
Training loss: 0.5421563527067947
Validation loss: 2.816007863728695

Epoch: 6| Step: 9
Training loss: 0.6542692719515656
Validation loss: 2.773739765154657

Epoch: 6| Step: 10
Training loss: 0.5427313910166576
Validation loss: 2.7821472806514698

Epoch: 6| Step: 11
Training loss: 0.4887943318693529
Validation loss: 2.7924059605395537

Epoch: 6| Step: 12
Training loss: 0.6805501046146242
Validation loss: 2.8076519897073093

Epoch: 6| Step: 13
Training loss: 0.6207295915687858
Validation loss: 2.810224276424453

Epoch: 430| Step: 0
Training loss: 0.7220270665503045
Validation loss: 2.8568735489625654

Epoch: 6| Step: 1
Training loss: 0.6785690927823816
Validation loss: 2.8749855980996135

Epoch: 6| Step: 2
Training loss: 0.6758856279325266
Validation loss: 2.7665886071311707

Epoch: 6| Step: 3
Training loss: 0.7021654363068036
Validation loss: 2.784091697862616

Epoch: 6| Step: 4
Training loss: 0.7867103114049621
Validation loss: 2.818599374359732

Epoch: 6| Step: 5
Training loss: 0.5682429033734997
Validation loss: 2.7468002083483465

Epoch: 6| Step: 6
Training loss: 0.6973780907293884
Validation loss: 2.742282833170244

Epoch: 6| Step: 7
Training loss: 0.9324046586824059
Validation loss: 2.758684101639945

Epoch: 6| Step: 8
Training loss: 0.6119944198547231
Validation loss: 2.7439158789935303

Epoch: 6| Step: 9
Training loss: 0.7272062423644811
Validation loss: 2.6716006995195865

Epoch: 6| Step: 10
Training loss: 0.5315577793528445
Validation loss: 2.651545678413007

Epoch: 6| Step: 11
Training loss: 0.8288788872749762
Validation loss: 2.7059457280444015

Epoch: 6| Step: 12
Training loss: 0.556421015735537
Validation loss: 2.7142563584659536

Epoch: 6| Step: 13
Training loss: 0.4970179082380372
Validation loss: 2.7114435432686275

Epoch: 431| Step: 0
Training loss: 0.8884371940190945
Validation loss: 2.6931354078267464

Epoch: 6| Step: 1
Training loss: 0.4648014818737074
Validation loss: 2.6076496381971257

Epoch: 6| Step: 2
Training loss: 0.7371190121520536
Validation loss: 2.7118329887831463

Epoch: 6| Step: 3
Training loss: 0.44408636105541394
Validation loss: 2.79243534569954

Epoch: 6| Step: 4
Training loss: 0.5865455270139617
Validation loss: 2.74589513980226

Epoch: 6| Step: 5
Training loss: 0.5808441550050791
Validation loss: 2.676904536311496

Epoch: 6| Step: 6
Training loss: 0.4557795542154815
Validation loss: 2.7430815801445587

Epoch: 6| Step: 7
Training loss: 0.5401678500862345
Validation loss: 2.731949164306704

Epoch: 6| Step: 8
Training loss: 0.5835779619443179
Validation loss: 2.7646220484545045

Epoch: 6| Step: 9
Training loss: 0.7392542648734229
Validation loss: 2.816240916908405

Epoch: 6| Step: 10
Training loss: 0.7501524929150392
Validation loss: 2.833445874017346

Epoch: 6| Step: 11
Training loss: 0.81148730035741
Validation loss: 2.869248400508325

Epoch: 6| Step: 12
Training loss: 0.512106479197214
Validation loss: 2.787532939060533

Epoch: 6| Step: 13
Training loss: 0.5413064003118333
Validation loss: 2.7873741475021343

Epoch: 432| Step: 0
Training loss: 0.6166314142907743
Validation loss: 2.768473880223201

Epoch: 6| Step: 1
Training loss: 0.503517651609333
Validation loss: 2.784022346081701

Epoch: 6| Step: 2
Training loss: 0.5510691979014086
Validation loss: 2.7779780511714494

Epoch: 6| Step: 3
Training loss: 0.8437529669815456
Validation loss: 2.7930957827544742

Epoch: 6| Step: 4
Training loss: 0.6607922982956266
Validation loss: 2.7944708637314175

Epoch: 6| Step: 5
Training loss: 0.6112423187584536
Validation loss: 2.8182380634299733

Epoch: 6| Step: 6
Training loss: 0.6002943121772654
Validation loss: 2.7123722819835017

Epoch: 6| Step: 7
Training loss: 0.7715264803828484
Validation loss: 2.756844340721599

Epoch: 6| Step: 8
Training loss: 0.47238018706745166
Validation loss: 2.7400314607577556

Epoch: 6| Step: 9
Training loss: 0.7547286691750268
Validation loss: 2.768731278355481

Epoch: 6| Step: 10
Training loss: 0.7128034564510289
Validation loss: 2.7253507674188993

Epoch: 6| Step: 11
Training loss: 0.5608720534034491
Validation loss: 2.744847339931719

Epoch: 6| Step: 12
Training loss: 0.5273740406520424
Validation loss: 2.8024869980228306

Epoch: 6| Step: 13
Training loss: 0.39104122874513686
Validation loss: 2.706316979851686

Epoch: 433| Step: 0
Training loss: 0.8443410710450724
Validation loss: 2.801978656463329

Epoch: 6| Step: 1
Training loss: 0.5656504620042612
Validation loss: 2.8235024880137694

Epoch: 6| Step: 2
Training loss: 0.46734951935283564
Validation loss: 2.8152350372656665

Epoch: 6| Step: 3
Training loss: 0.4057784828735059
Validation loss: 2.8237169874382775

Epoch: 6| Step: 4
Training loss: 0.5769521311633229
Validation loss: 2.740956203002699

Epoch: 6| Step: 5
Training loss: 0.6594363016857561
Validation loss: 2.7772740580224453

Epoch: 6| Step: 6
Training loss: 0.7254733875002373
Validation loss: 2.7751482634702134

Epoch: 6| Step: 7
Training loss: 0.6415149972891534
Validation loss: 2.756796486698738

Epoch: 6| Step: 8
Training loss: 0.5669707017928146
Validation loss: 2.7512000239962093

Epoch: 6| Step: 9
Training loss: 0.727919429198076
Validation loss: 2.813885947758689

Epoch: 6| Step: 10
Training loss: 0.658592222309264
Validation loss: 2.7909162471191125

Epoch: 6| Step: 11
Training loss: 0.8435976809307435
Validation loss: 2.741689377741874

Epoch: 6| Step: 12
Training loss: 0.6883457140659647
Validation loss: 2.74841643024094

Epoch: 6| Step: 13
Training loss: 0.6244095874634371
Validation loss: 2.7431337294458125

Epoch: 434| Step: 0
Training loss: 0.6704918796992019
Validation loss: 2.6921423508453577

Epoch: 6| Step: 1
Training loss: 0.5097505121438979
Validation loss: 2.7523286525786155

Epoch: 6| Step: 2
Training loss: 0.749884318331207
Validation loss: 2.714677017910089

Epoch: 6| Step: 3
Training loss: 0.5978102142880539
Validation loss: 2.760168148345884

Epoch: 6| Step: 4
Training loss: 0.45804815379040215
Validation loss: 2.7697109492317624

Epoch: 6| Step: 5
Training loss: 0.7147579871255442
Validation loss: 2.703505134681589

Epoch: 6| Step: 6
Training loss: 0.48270508333587536
Validation loss: 2.7401225691898072

Epoch: 6| Step: 7
Training loss: 0.4507983093736048
Validation loss: 2.8181227110791887

Epoch: 6| Step: 8
Training loss: 0.47247000248362814
Validation loss: 2.818926892647359

Epoch: 6| Step: 9
Training loss: 0.551384831847867
Validation loss: 2.8193701158527906

Epoch: 6| Step: 10
Training loss: 0.6264058514215767
Validation loss: 2.8147053231646693

Epoch: 6| Step: 11
Training loss: 0.534647762665776
Validation loss: 2.7840019355763546

Epoch: 6| Step: 12
Training loss: 0.5880315364632803
Validation loss: 2.766091158386452

Epoch: 6| Step: 13
Training loss: 0.5873895074546914
Validation loss: 2.744730495709841

Epoch: 435| Step: 0
Training loss: 0.5354999079236719
Validation loss: 2.7761031544205568

Epoch: 6| Step: 1
Training loss: 0.6655233135367242
Validation loss: 2.764959452804889

Epoch: 6| Step: 2
Training loss: 0.4895807293220691
Validation loss: 2.744964179179917

Epoch: 6| Step: 3
Training loss: 0.8284417032648181
Validation loss: 2.73637479769075

Epoch: 6| Step: 4
Training loss: 0.7158955408302994
Validation loss: 2.7449353136455934

Epoch: 6| Step: 5
Training loss: 0.49910544302056475
Validation loss: 2.738032396357541

Epoch: 6| Step: 6
Training loss: 0.43930863442201185
Validation loss: 2.762387178168362

Epoch: 6| Step: 7
Training loss: 0.5257073904593752
Validation loss: 2.7399311981009196

Epoch: 6| Step: 8
Training loss: 0.5116781553517348
Validation loss: 2.691871178438822

Epoch: 6| Step: 9
Training loss: 0.5850139205450118
Validation loss: 2.7146127726045917

Epoch: 6| Step: 10
Training loss: 0.4810602222639977
Validation loss: 2.7337503936911487

Epoch: 6| Step: 11
Training loss: 0.6443002228958074
Validation loss: 2.7025057868060403

Epoch: 6| Step: 12
Training loss: 0.6701144950810387
Validation loss: 2.7424066062981582

Epoch: 6| Step: 13
Training loss: 0.4174275325653769
Validation loss: 2.734354582210786

Epoch: 436| Step: 0
Training loss: 0.6795899989910034
Validation loss: 2.7609590009633997

Epoch: 6| Step: 1
Training loss: 0.581772509930778
Validation loss: 2.774729969300982

Epoch: 6| Step: 2
Training loss: 0.7057088635516543
Validation loss: 2.8058745299410686

Epoch: 6| Step: 3
Training loss: 0.5471217552439198
Validation loss: 2.748517605017391

Epoch: 6| Step: 4
Training loss: 0.5912508822186524
Validation loss: 2.7823579131684752

Epoch: 6| Step: 5
Training loss: 0.7245249326297658
Validation loss: 2.7601853231739297

Epoch: 6| Step: 6
Training loss: 0.41697006702936984
Validation loss: 2.7177168830765366

Epoch: 6| Step: 7
Training loss: 0.6079712618714901
Validation loss: 2.767616589372461

Epoch: 6| Step: 8
Training loss: 0.43537971470591247
Validation loss: 2.7587948239246622

Epoch: 6| Step: 9
Training loss: 0.3490490925842794
Validation loss: 2.7959835258502452

Epoch: 6| Step: 10
Training loss: 0.4532199464177349
Validation loss: 2.811994365875511

Epoch: 6| Step: 11
Training loss: 0.516718168024751
Validation loss: 2.8123343524895597

Epoch: 6| Step: 12
Training loss: 0.5212960921292721
Validation loss: 2.832465366108016

Epoch: 6| Step: 13
Training loss: 0.5924243684776821
Validation loss: 2.762679577222259

Epoch: 437| Step: 0
Training loss: 0.5615587306333969
Validation loss: 2.7518722634204775

Epoch: 6| Step: 1
Training loss: 0.5299881928406293
Validation loss: 2.79436988809053

Epoch: 6| Step: 2
Training loss: 0.5643079102308715
Validation loss: 2.736103550555718

Epoch: 6| Step: 3
Training loss: 0.643298548201078
Validation loss: 2.715746232382351

Epoch: 6| Step: 4
Training loss: 0.387585833487645
Validation loss: 2.75126887438486

Epoch: 6| Step: 5
Training loss: 0.5553190370259724
Validation loss: 2.732199059236908

Epoch: 6| Step: 6
Training loss: 0.48551910394626435
Validation loss: 2.764166050235134

Epoch: 6| Step: 7
Training loss: 0.6809087721151038
Validation loss: 2.750499766627338

Epoch: 6| Step: 8
Training loss: 0.7056399191604537
Validation loss: 2.717435263126136

Epoch: 6| Step: 9
Training loss: 0.5126878719698189
Validation loss: 2.7047274769679337

Epoch: 6| Step: 10
Training loss: 0.5733060005191355
Validation loss: 2.6749738825654976

Epoch: 6| Step: 11
Training loss: 0.522366324441018
Validation loss: 2.7508629831979077

Epoch: 6| Step: 12
Training loss: 0.6258763130361635
Validation loss: 2.7698670234390304

Epoch: 6| Step: 13
Training loss: 0.5853077365174276
Validation loss: 2.6924819236226507

Epoch: 438| Step: 0
Training loss: 0.6438694648630656
Validation loss: 2.7614161259492875

Epoch: 6| Step: 1
Training loss: 0.5610424071159628
Validation loss: 2.7902639527835733

Epoch: 6| Step: 2
Training loss: 0.543339444966648
Validation loss: 2.8009204342218745

Epoch: 6| Step: 3
Training loss: 0.4577506834094844
Validation loss: 2.728000163469841

Epoch: 6| Step: 4
Training loss: 0.6866321504777185
Validation loss: 2.759669729457863

Epoch: 6| Step: 5
Training loss: 0.6995826711835184
Validation loss: 2.786992655829389

Epoch: 6| Step: 6
Training loss: 0.5426610170655309
Validation loss: 2.8243570254337

Epoch: 6| Step: 7
Training loss: 0.4527176966651959
Validation loss: 2.7384155937031673

Epoch: 6| Step: 8
Training loss: 0.5428774365821245
Validation loss: 2.783837475680543

Epoch: 6| Step: 9
Training loss: 0.5835142252511107
Validation loss: 2.6936339675683474

Epoch: 6| Step: 10
Training loss: 0.5544236321175378
Validation loss: 2.763385764185611

Epoch: 6| Step: 11
Training loss: 0.655163842486351
Validation loss: 2.689141319371378

Epoch: 6| Step: 12
Training loss: 0.7308599067331293
Validation loss: 2.7291399005615964

Epoch: 6| Step: 13
Training loss: 0.4707785265033794
Validation loss: 2.7395925968917663

Epoch: 439| Step: 0
Training loss: 0.7252444545740291
Validation loss: 2.7467545952734627

Epoch: 6| Step: 1
Training loss: 0.6658579843952608
Validation loss: 2.7236810595357324

Epoch: 6| Step: 2
Training loss: 0.5353222332017772
Validation loss: 2.7618155239906788

Epoch: 6| Step: 3
Training loss: 0.5411798110981377
Validation loss: 2.7567110680860116

Epoch: 6| Step: 4
Training loss: 0.6369751490052707
Validation loss: 2.7123565477682074

Epoch: 6| Step: 5
Training loss: 0.5423749517215268
Validation loss: 2.7100479029542566

Epoch: 6| Step: 6
Training loss: 0.2937171278477631
Validation loss: 2.752431170543952

Epoch: 6| Step: 7
Training loss: 0.3397020504948827
Validation loss: 2.7363734036206684

Epoch: 6| Step: 8
Training loss: 0.5291757761804448
Validation loss: 2.7411485897521235

Epoch: 6| Step: 9
Training loss: 0.3811028313737551
Validation loss: 2.7115580117047564

Epoch: 6| Step: 10
Training loss: 0.47196926287002045
Validation loss: 2.707639522204005

Epoch: 6| Step: 11
Training loss: 0.6267124557844791
Validation loss: 2.7973053812391715

Epoch: 6| Step: 12
Training loss: 0.5947922042425591
Validation loss: 2.7759540584593836

Epoch: 6| Step: 13
Training loss: 0.7184862814026954
Validation loss: 2.739028299092392

Epoch: 440| Step: 0
Training loss: 0.5979841242982544
Validation loss: 2.7721215219837805

Epoch: 6| Step: 1
Training loss: 0.5696328960706025
Validation loss: 2.7538862367448402

Epoch: 6| Step: 2
Training loss: 0.6520053876861932
Validation loss: 2.771161545170722

Epoch: 6| Step: 3
Training loss: 0.642781836965711
Validation loss: 2.765197304164029

Epoch: 6| Step: 4
Training loss: 0.5159620859352164
Validation loss: 2.804647319651107

Epoch: 6| Step: 5
Training loss: 0.4409468124941872
Validation loss: 2.8010819405388547

Epoch: 6| Step: 6
Training loss: 0.48259761250348393
Validation loss: 2.7696524065828734

Epoch: 6| Step: 7
Training loss: 0.3823589635580765
Validation loss: 2.7878871831293193

Epoch: 6| Step: 8
Training loss: 0.7260030828336936
Validation loss: 2.7273524031897485

Epoch: 6| Step: 9
Training loss: 0.4193708663770822
Validation loss: 2.768427289378488

Epoch: 6| Step: 10
Training loss: 0.46272303770707446
Validation loss: 2.715199062597255

Epoch: 6| Step: 11
Training loss: 0.690192973822571
Validation loss: 2.6686504455627404

Epoch: 6| Step: 12
Training loss: 0.43746413356357083
Validation loss: 2.8011386134369394

Epoch: 6| Step: 13
Training loss: 0.5867918271246453
Validation loss: 2.718996234134986

Epoch: 441| Step: 0
Training loss: 0.6147849485012391
Validation loss: 2.739906079290628

Epoch: 6| Step: 1
Training loss: 0.34142730351179573
Validation loss: 2.8093327242931014

Epoch: 6| Step: 2
Training loss: 0.5385453881357122
Validation loss: 2.7443639770694177

Epoch: 6| Step: 3
Training loss: 0.44438960830670354
Validation loss: 2.705448937735964

Epoch: 6| Step: 4
Training loss: 0.4575840793539392
Validation loss: 2.703488834422718

Epoch: 6| Step: 5
Training loss: 0.6378674588782729
Validation loss: 2.788072818295444

Epoch: 6| Step: 6
Training loss: 0.5847849382104713
Validation loss: 2.721975306149226

Epoch: 6| Step: 7
Training loss: 0.508961243883332
Validation loss: 2.72870256879879

Epoch: 6| Step: 8
Training loss: 0.5187178245585359
Validation loss: 2.7542406821489043

Epoch: 6| Step: 9
Training loss: 0.7657384982937485
Validation loss: 2.7762243605587265

Epoch: 6| Step: 10
Training loss: 0.5327482134387646
Validation loss: 2.7283311297719077

Epoch: 6| Step: 11
Training loss: 0.5642667680546616
Validation loss: 2.782720498519215

Epoch: 6| Step: 12
Training loss: 0.7053458426744768
Validation loss: 2.808438278655994

Epoch: 6| Step: 13
Training loss: 0.57678882736385
Validation loss: 2.765109242194921

Epoch: 442| Step: 0
Training loss: 0.6809535895342269
Validation loss: 2.708310484178455

Epoch: 6| Step: 1
Training loss: 0.5141807617231922
Validation loss: 2.8267384426732773

Epoch: 6| Step: 2
Training loss: 0.614638678973577
Validation loss: 2.7855283712406327

Epoch: 6| Step: 3
Training loss: 0.590734150806707
Validation loss: 2.7568426975550677

Epoch: 6| Step: 4
Training loss: 0.4958693229479178
Validation loss: 2.753740800798023

Epoch: 6| Step: 5
Training loss: 0.5752377972027642
Validation loss: 2.7800619037971974

Epoch: 6| Step: 6
Training loss: 0.38351543271869465
Validation loss: 2.8230900212698784

Epoch: 6| Step: 7
Training loss: 0.600264399605623
Validation loss: 2.7390182889049446

Epoch: 6| Step: 8
Training loss: 0.48676504095631035
Validation loss: 2.790304617950213

Epoch: 6| Step: 9
Training loss: 0.5930133064025078
Validation loss: 2.7630206703428075

Epoch: 6| Step: 10
Training loss: 0.6325126219986522
Validation loss: 2.7429348904323345

Epoch: 6| Step: 11
Training loss: 0.5336097592008985
Validation loss: 2.7170350376940537

Epoch: 6| Step: 12
Training loss: 0.4697220260813463
Validation loss: 2.7635771071290427

Epoch: 6| Step: 13
Training loss: 0.5942152609711419
Validation loss: 2.733843085005579

Epoch: 443| Step: 0
Training loss: 0.6553500225946957
Validation loss: 2.708008260047088

Epoch: 6| Step: 1
Training loss: 0.38352885658812236
Validation loss: 2.714897407715018

Epoch: 6| Step: 2
Training loss: 0.5361662195911545
Validation loss: 2.695368927443283

Epoch: 6| Step: 3
Training loss: 0.4687525431246118
Validation loss: 2.7319247866372973

Epoch: 6| Step: 4
Training loss: 0.30930820283431126
Validation loss: 2.804440755802227

Epoch: 6| Step: 5
Training loss: 0.4743785218219926
Validation loss: 2.7662585982074006

Epoch: 6| Step: 6
Training loss: 0.5646526155742766
Validation loss: 2.720517617953192

Epoch: 6| Step: 7
Training loss: 0.5674232297805271
Validation loss: 2.67845330023275

Epoch: 6| Step: 8
Training loss: 0.6195669541527377
Validation loss: 2.752737532277735

Epoch: 6| Step: 9
Training loss: 0.6418339556652464
Validation loss: 2.7504946090487303

Epoch: 6| Step: 10
Training loss: 0.643621415194013
Validation loss: 2.7699686197369444

Epoch: 6| Step: 11
Training loss: 0.6380177218821944
Validation loss: 2.7113408604861244

Epoch: 6| Step: 12
Training loss: 0.4815974739836194
Validation loss: 2.732829908981112

Epoch: 6| Step: 13
Training loss: 0.6781981362839483
Validation loss: 2.7726134459501295

Epoch: 444| Step: 0
Training loss: 0.7748726909422743
Validation loss: 2.7805823907140517

Epoch: 6| Step: 1
Training loss: 0.5119756970784417
Validation loss: 2.7489689931678485

Epoch: 6| Step: 2
Training loss: 0.4650413029283101
Validation loss: 2.721859684524047

Epoch: 6| Step: 3
Training loss: 0.5182164987776166
Validation loss: 2.718192529343119

Epoch: 6| Step: 4
Training loss: 0.5751365022758967
Validation loss: 2.76110365374313

Epoch: 6| Step: 5
Training loss: 0.4418904509803853
Validation loss: 2.8007326144044007

Epoch: 6| Step: 6
Training loss: 0.3757570096324663
Validation loss: 2.7460215646328137

Epoch: 6| Step: 7
Training loss: 0.3989445881513435
Validation loss: 2.761076813460705

Epoch: 6| Step: 8
Training loss: 0.5268461069259902
Validation loss: 2.7090718998483547

Epoch: 6| Step: 9
Training loss: 0.2940605672677523
Validation loss: 2.7057629100664626

Epoch: 6| Step: 10
Training loss: 0.7307184781855988
Validation loss: 2.750017317804081

Epoch: 6| Step: 11
Training loss: 0.4841170393163454
Validation loss: 2.7381090372144596

Epoch: 6| Step: 12
Training loss: 0.6496459776291785
Validation loss: 2.730057190096931

Epoch: 6| Step: 13
Training loss: 0.5498135499934441
Validation loss: 2.7271478820653052

Epoch: 445| Step: 0
Training loss: 0.6036524447807805
Validation loss: 2.761086729284442

Epoch: 6| Step: 1
Training loss: 0.5506966708559065
Validation loss: 2.7604520303632234

Epoch: 6| Step: 2
Training loss: 0.44371398322927885
Validation loss: 2.8223475108867544

Epoch: 6| Step: 3
Training loss: 0.4922194243477271
Validation loss: 2.7444763050683876

Epoch: 6| Step: 4
Training loss: 0.4743395536797419
Validation loss: 2.7404618009129744

Epoch: 6| Step: 5
Training loss: 0.5098806960210212
Validation loss: 2.7489818002947835

Epoch: 6| Step: 6
Training loss: 0.4595641350158717
Validation loss: 2.749991705910862

Epoch: 6| Step: 7
Training loss: 0.6507191787554903
Validation loss: 2.7453206594306465

Epoch: 6| Step: 8
Training loss: 0.6274710919077963
Validation loss: 2.7754799928891836

Epoch: 6| Step: 9
Training loss: 0.6734267656572712
Validation loss: 2.772194511293763

Epoch: 6| Step: 10
Training loss: 0.5168595994640773
Validation loss: 2.751730980986992

Epoch: 6| Step: 11
Training loss: 0.5430199578377741
Validation loss: 2.813542137630856

Epoch: 6| Step: 12
Training loss: 0.5713494162998104
Validation loss: 2.7459439941783264

Epoch: 6| Step: 13
Training loss: 0.5859945142345986
Validation loss: 2.779296303108105

Epoch: 446| Step: 0
Training loss: 0.5180776524738774
Validation loss: 2.8076073086329822

Epoch: 6| Step: 1
Training loss: 0.6163490007742874
Validation loss: 2.8066886910127873

Epoch: 6| Step: 2
Training loss: 0.4356488506185955
Validation loss: 2.8165580578091127

Epoch: 6| Step: 3
Training loss: 0.34565832634441807
Validation loss: 2.8188665739484438

Epoch: 6| Step: 4
Training loss: 0.5886448176189627
Validation loss: 2.7164247734718963

Epoch: 6| Step: 5
Training loss: 0.34668722010206277
Validation loss: 2.768970499092095

Epoch: 6| Step: 6
Training loss: 0.6798481148553585
Validation loss: 2.8295729638013913

Epoch: 6| Step: 7
Training loss: 0.4111447366539254
Validation loss: 2.7611137997336788

Epoch: 6| Step: 8
Training loss: 0.45419861771538256
Validation loss: 2.8108746671271705

Epoch: 6| Step: 9
Training loss: 0.6310890653568111
Validation loss: 2.715089050481152

Epoch: 6| Step: 10
Training loss: 0.6126670434453897
Validation loss: 2.8141041172416115

Epoch: 6| Step: 11
Training loss: 0.6622382744643557
Validation loss: 2.7315952667655607

Epoch: 6| Step: 12
Training loss: 0.7019145719356621
Validation loss: 2.751615887625273

Epoch: 6| Step: 13
Training loss: 0.5074979247910488
Validation loss: 2.7625839554355034

Epoch: 447| Step: 0
Training loss: 0.43324152068586474
Validation loss: 2.7323996393236536

Epoch: 6| Step: 1
Training loss: 0.6465908320153089
Validation loss: 2.768818765881348

Epoch: 6| Step: 2
Training loss: 0.5591086302181079
Validation loss: 2.794227803596082

Epoch: 6| Step: 3
Training loss: 0.5657893010714675
Validation loss: 2.794470437141539

Epoch: 6| Step: 4
Training loss: 0.3979726959979446
Validation loss: 2.8215701890852567

Epoch: 6| Step: 5
Training loss: 0.28861835226165666
Validation loss: 2.7943210129203644

Epoch: 6| Step: 6
Training loss: 0.5813849528347985
Validation loss: 2.71683787194516

Epoch: 6| Step: 7
Training loss: 0.5277018708582467
Validation loss: 2.803585377867605

Epoch: 6| Step: 8
Training loss: 0.743103746731075
Validation loss: 2.8158846516339007

Epoch: 6| Step: 9
Training loss: 0.6581016937795167
Validation loss: 2.753951571477135

Epoch: 6| Step: 10
Training loss: 0.40275215975456413
Validation loss: 2.742182370259848

Epoch: 6| Step: 11
Training loss: 0.5186144260975264
Validation loss: 2.752697546369587

Epoch: 6| Step: 12
Training loss: 0.4409513577041633
Validation loss: 2.7407752636349954

Epoch: 6| Step: 13
Training loss: 0.5947468570948488
Validation loss: 2.749125934178435

Epoch: 448| Step: 0
Training loss: 0.5440084807667511
Validation loss: 2.7152744015680534

Epoch: 6| Step: 1
Training loss: 0.7938052871553014
Validation loss: 2.795032995730987

Epoch: 6| Step: 2
Training loss: 0.4619313210616177
Validation loss: 2.78748002380147

Epoch: 6| Step: 3
Training loss: 0.6913536612128676
Validation loss: 2.669114663122365

Epoch: 6| Step: 4
Training loss: 0.4524266682527186
Validation loss: 2.7053979861281694

Epoch: 6| Step: 5
Training loss: 0.5511771057875601
Validation loss: 2.7526590611888686

Epoch: 6| Step: 6
Training loss: 0.5203077780019579
Validation loss: 2.8034719597616307

Epoch: 6| Step: 7
Training loss: 0.6446459119125828
Validation loss: 2.78892841604506

Epoch: 6| Step: 8
Training loss: 0.6187265738474201
Validation loss: 2.7752467025747785

Epoch: 6| Step: 9
Training loss: 0.5597362971159835
Validation loss: 2.815702169576638

Epoch: 6| Step: 10
Training loss: 0.7928783571935091
Validation loss: 2.7586199593268996

Epoch: 6| Step: 11
Training loss: 0.5722273465526886
Validation loss: 2.7634737948008086

Epoch: 6| Step: 12
Training loss: 0.5718704265140614
Validation loss: 2.7719930478160664

Epoch: 6| Step: 13
Training loss: 0.37864798169617553
Validation loss: 2.7449777866986453

Epoch: 449| Step: 0
Training loss: 0.5959674436410778
Validation loss: 2.6885421270118584

Epoch: 6| Step: 1
Training loss: 0.6660144615722517
Validation loss: 2.748437423084367

Epoch: 6| Step: 2
Training loss: 0.5296797827774556
Validation loss: 2.738390185283926

Epoch: 6| Step: 3
Training loss: 0.4577335764846569
Validation loss: 2.72568048823213

Epoch: 6| Step: 4
Training loss: 0.4994964149793212
Validation loss: 2.7271512478929125

Epoch: 6| Step: 5
Training loss: 0.6245978253545047
Validation loss: 2.743204042517486

Epoch: 6| Step: 6
Training loss: 0.5352952873994564
Validation loss: 2.708373353124483

Epoch: 6| Step: 7
Training loss: 0.7387081304777934
Validation loss: 2.7580167354355383

Epoch: 6| Step: 8
Training loss: 0.6743465032911545
Validation loss: 2.772554298146651

Epoch: 6| Step: 9
Training loss: 0.4760531063778204
Validation loss: 2.7521062067906845

Epoch: 6| Step: 10
Training loss: 0.6056218107629662
Validation loss: 2.743443084791065

Epoch: 6| Step: 11
Training loss: 0.38756699444398324
Validation loss: 2.786395567190036

Epoch: 6| Step: 12
Training loss: 0.4313173248425783
Validation loss: 2.7393386185185733

Epoch: 6| Step: 13
Training loss: 0.48297220570103316
Validation loss: 2.7163908065577784

Epoch: 450| Step: 0
Training loss: 0.5552726131061415
Validation loss: 2.7544170798663767

Epoch: 6| Step: 1
Training loss: 0.5163069752248782
Validation loss: 2.785155294096267

Epoch: 6| Step: 2
Training loss: 0.37938514413107505
Validation loss: 2.7800341745375503

Epoch: 6| Step: 3
Training loss: 0.5890697934131751
Validation loss: 2.827730857403229

Epoch: 6| Step: 4
Training loss: 0.5833761051936661
Validation loss: 2.7670051019178312

Epoch: 6| Step: 5
Training loss: 0.5831994743258458
Validation loss: 2.7881496014650176

Epoch: 6| Step: 6
Training loss: 0.4650195614740526
Validation loss: 2.7846040967545513

Epoch: 6| Step: 7
Training loss: 0.5070493686066091
Validation loss: 2.8431976955778007

Epoch: 6| Step: 8
Training loss: 0.3803521324201241
Validation loss: 2.7816551142049453

Epoch: 6| Step: 9
Training loss: 0.717555961619634
Validation loss: 2.8149616347702997

Epoch: 6| Step: 10
Training loss: 0.5208891139359977
Validation loss: 2.812926493202675

Epoch: 6| Step: 11
Training loss: 0.5624006501516923
Validation loss: 2.8617366355943177

Epoch: 6| Step: 12
Training loss: 0.6192915097809444
Validation loss: 2.795197067023851

Epoch: 6| Step: 13
Training loss: 0.4246267713476679
Validation loss: 2.7651712221335694

Testing loss: 2.422845708863597
