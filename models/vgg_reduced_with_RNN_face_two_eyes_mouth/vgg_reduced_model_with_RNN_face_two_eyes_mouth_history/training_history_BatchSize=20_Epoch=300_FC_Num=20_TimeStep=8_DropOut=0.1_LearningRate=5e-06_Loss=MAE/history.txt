Epoch: 1| Step: 0
Training loss: 5.396578788757324
Validation loss: 5.303211669127147

Epoch: 5| Step: 1
Training loss: 5.084395408630371
Validation loss: 5.300622582435608

Epoch: 5| Step: 2
Training loss: 4.676934719085693
Validation loss: 5.298129657904307

Epoch: 5| Step: 3
Training loss: 4.409316062927246
Validation loss: 5.29553884267807

Epoch: 5| Step: 4
Training loss: 5.646638870239258
Validation loss: 5.293052653471629

Epoch: 5| Step: 5
Training loss: 6.559307098388672
Validation loss: 5.290399293104808

Epoch: 5| Step: 6
Training loss: 5.3593974113464355
Validation loss: 5.2876977523167925

Epoch: 5| Step: 7
Training loss: 4.949164390563965
Validation loss: 5.285069425900777

Epoch: 5| Step: 8
Training loss: 5.374577522277832
Validation loss: 5.282300730546315

Epoch: 5| Step: 9
Training loss: 5.719551086425781
Validation loss: 5.279604772726695

Epoch: 5| Step: 10
Training loss: 5.548880100250244
Validation loss: 5.276791870594025

Epoch: 5| Step: 11
Training loss: 6.486880302429199
Validation loss: 5.2738218903541565

Epoch: 2| Step: 0
Training loss: 5.920557498931885
Validation loss: 5.270763635635376

Epoch: 5| Step: 1
Training loss: 5.282696723937988
Validation loss: 5.267876426378886

Epoch: 5| Step: 2
Training loss: 5.097326755523682
Validation loss: 5.264623800913493

Epoch: 5| Step: 3
Training loss: 6.109193801879883
Validation loss: 5.261209309101105

Epoch: 5| Step: 4
Training loss: 5.533369541168213
Validation loss: 5.2577500740687055

Epoch: 5| Step: 5
Training loss: 5.067380905151367
Validation loss: 5.254108428955078

Epoch: 5| Step: 6
Training loss: 5.1782426834106445
Validation loss: 5.250277082125346

Epoch: 5| Step: 7
Training loss: 5.870388031005859
Validation loss: 5.246214052041371

Epoch: 5| Step: 8
Training loss: 4.5007781982421875
Validation loss: 5.242234468460083

Epoch: 5| Step: 9
Training loss: 5.049807071685791
Validation loss: 5.237750728925069

Epoch: 5| Step: 10
Training loss: 4.71068000793457
Validation loss: 5.233196516831716

Epoch: 5| Step: 11
Training loss: 6.464601516723633
Validation loss: 5.228502631187439

Epoch: 3| Step: 0
Training loss: 7.18667459487915
Validation loss: 5.223509808381398

Epoch: 5| Step: 1
Training loss: 5.42452335357666
Validation loss: 5.218279997507731

Epoch: 5| Step: 2
Training loss: 4.82070779800415
Validation loss: 5.2127365072568255

Epoch: 5| Step: 3
Training loss: 4.387884616851807
Validation loss: 5.206945637861888

Epoch: 5| Step: 4
Training loss: 5.49302864074707
Validation loss: 5.201021651426951

Epoch: 5| Step: 5
Training loss: 5.326953411102295
Validation loss: 5.194757839043935

Epoch: 5| Step: 6
Training loss: 5.075654029846191
Validation loss: 5.188125908374786

Epoch: 5| Step: 7
Training loss: 4.784714698791504
Validation loss: 5.1812490820884705

Epoch: 5| Step: 8
Training loss: 5.750335693359375
Validation loss: 5.174228231112163

Epoch: 5| Step: 9
Training loss: 5.025730609893799
Validation loss: 5.16686083873113

Epoch: 5| Step: 10
Training loss: 5.028002738952637
Validation loss: 5.159203092257182

Epoch: 5| Step: 11
Training loss: 3.265270471572876
Validation loss: 5.151077429453532

Epoch: 4| Step: 0
Training loss: 5.689420223236084
Validation loss: 5.142626106739044

Epoch: 5| Step: 1
Training loss: 6.179224967956543
Validation loss: 5.134232838948567

Epoch: 5| Step: 2
Training loss: 6.422611236572266
Validation loss: 5.125448286533356

Epoch: 5| Step: 3
Training loss: 4.823264122009277
Validation loss: 5.115746239821116

Epoch: 5| Step: 4
Training loss: 4.833107948303223
Validation loss: 5.106166104475657

Epoch: 5| Step: 5
Training loss: 5.057912826538086
Validation loss: 5.096558918555577

Epoch: 5| Step: 6
Training loss: 4.3714399337768555
Validation loss: 5.086519678433736

Epoch: 5| Step: 7
Training loss: 4.6379594802856445
Validation loss: 5.076007644335429

Epoch: 5| Step: 8
Training loss: 6.246731758117676
Validation loss: 5.065177957216899

Epoch: 5| Step: 9
Training loss: 4.498740196228027
Validation loss: 5.054022669792175

Epoch: 5| Step: 10
Training loss: 4.172369956970215
Validation loss: 5.04281469186147

Epoch: 5| Step: 11
Training loss: 4.785336494445801
Validation loss: 5.031307677427928

Epoch: 5| Step: 0
Training loss: 4.798018455505371
Validation loss: 5.019881089528401

Epoch: 5| Step: 1
Training loss: 4.80668830871582
Validation loss: 5.007802426815033

Epoch: 5| Step: 2
Training loss: 4.616799831390381
Validation loss: 4.995610634485881

Epoch: 5| Step: 3
Training loss: 5.727252960205078
Validation loss: 4.983667870362599

Epoch: 5| Step: 4
Training loss: 4.905153274536133
Validation loss: 4.971267342567444

Epoch: 5| Step: 5
Training loss: 5.6825032234191895
Validation loss: 4.958753526210785

Epoch: 5| Step: 6
Training loss: 4.427149772644043
Validation loss: 4.946173230806987

Epoch: 5| Step: 7
Training loss: 5.563851356506348
Validation loss: 4.9335975249608355

Epoch: 5| Step: 8
Training loss: 4.833750247955322
Validation loss: 4.920672456423442

Epoch: 5| Step: 9
Training loss: 4.264279365539551
Validation loss: 4.9080555737018585

Epoch: 5| Step: 10
Training loss: 5.789628028869629
Validation loss: 4.895096639792125

Epoch: 5| Step: 11
Training loss: 5.113825798034668
Validation loss: 4.883017619450887

Epoch: 6| Step: 0
Training loss: 4.020132541656494
Validation loss: 4.870830049117406

Epoch: 5| Step: 1
Training loss: 6.028815746307373
Validation loss: 4.858942011992137

Epoch: 5| Step: 2
Training loss: 4.7208685874938965
Validation loss: 4.847043355305989

Epoch: 5| Step: 3
Training loss: 5.402552127838135
Validation loss: 4.8349349200725555

Epoch: 5| Step: 4
Training loss: 5.236197471618652
Validation loss: 4.82319974899292

Epoch: 5| Step: 5
Training loss: 5.666287899017334
Validation loss: 4.811135232448578

Epoch: 5| Step: 6
Training loss: 4.348564624786377
Validation loss: 4.799388110637665

Epoch: 5| Step: 7
Training loss: 4.230619430541992
Validation loss: 4.787225186824799

Epoch: 5| Step: 8
Training loss: 5.664051055908203
Validation loss: 4.775821089744568

Epoch: 5| Step: 9
Training loss: 4.387852668762207
Validation loss: 4.764573077360789

Epoch: 5| Step: 10
Training loss: 4.578891277313232
Validation loss: 4.7533633907636

Epoch: 5| Step: 11
Training loss: 2.9073212146759033
Validation loss: 4.742470363775889

Epoch: 7| Step: 0
Training loss: 5.197871208190918
Validation loss: 4.731564263502757

Epoch: 5| Step: 1
Training loss: 4.246179580688477
Validation loss: 4.721011300881703

Epoch: 5| Step: 2
Training loss: 4.242393493652344
Validation loss: 4.710546493530273

Epoch: 5| Step: 3
Training loss: 4.393721580505371
Validation loss: 4.699837168057759

Epoch: 5| Step: 4
Training loss: 5.6330156326293945
Validation loss: 4.689596553643544

Epoch: 5| Step: 5
Training loss: 4.954946041107178
Validation loss: 4.679547429084778

Epoch: 5| Step: 6
Training loss: 4.510538578033447
Validation loss: 4.669035037358602

Epoch: 5| Step: 7
Training loss: 5.450833797454834
Validation loss: 4.659209658702214

Epoch: 5| Step: 8
Training loss: 4.939136505126953
Validation loss: 4.648433307806651

Epoch: 5| Step: 9
Training loss: 5.283743858337402
Validation loss: 4.637822171052297

Epoch: 5| Step: 10
Training loss: 3.347795009613037
Validation loss: 4.6274305780728655

Epoch: 5| Step: 11
Training loss: 6.350583076477051
Validation loss: 4.616512010494868

Epoch: 8| Step: 0
Training loss: 4.4739508628845215
Validation loss: 4.605708360671997

Epoch: 5| Step: 1
Training loss: 4.402468204498291
Validation loss: 4.594927628835042

Epoch: 5| Step: 2
Training loss: 5.38482141494751
Validation loss: 4.584341466426849

Epoch: 5| Step: 3
Training loss: 4.859055519104004
Validation loss: 4.573014795780182

Epoch: 5| Step: 4
Training loss: 4.281836032867432
Validation loss: 4.561389625072479

Epoch: 5| Step: 5
Training loss: 5.189047813415527
Validation loss: 4.550248126188914

Epoch: 5| Step: 6
Training loss: 4.968232154846191
Validation loss: 4.5390645662943525

Epoch: 5| Step: 7
Training loss: 3.7681491374969482
Validation loss: 4.5282389124234514

Epoch: 5| Step: 8
Training loss: 5.975248336791992
Validation loss: 4.517332047224045

Epoch: 5| Step: 9
Training loss: 2.717406749725342
Validation loss: 4.506162603696187

Epoch: 5| Step: 10
Training loss: 4.949818134307861
Validation loss: 4.494991471370061

Epoch: 5| Step: 11
Training loss: 5.706099033355713
Validation loss: 4.484283049901326

Epoch: 9| Step: 0
Training loss: 3.257234573364258
Validation loss: 4.47342308362325

Epoch: 5| Step: 1
Training loss: 5.195350646972656
Validation loss: 4.463151017824809

Epoch: 5| Step: 2
Training loss: 4.815305233001709
Validation loss: 4.452974657217662

Epoch: 5| Step: 3
Training loss: 4.463756561279297
Validation loss: 4.443689942359924

Epoch: 5| Step: 4
Training loss: 4.158617973327637
Validation loss: 4.435043176015218

Epoch: 5| Step: 5
Training loss: 3.5252654552459717
Validation loss: 4.424541562795639

Epoch: 5| Step: 6
Training loss: 4.747107982635498
Validation loss: 4.415550688902537

Epoch: 5| Step: 7
Training loss: 4.607617378234863
Validation loss: 4.406537453333537

Epoch: 5| Step: 8
Training loss: 5.3115410804748535
Validation loss: 4.397799720366796

Epoch: 5| Step: 9
Training loss: 4.036292552947998
Validation loss: 4.38897971312205

Epoch: 5| Step: 10
Training loss: 5.609550952911377
Validation loss: 4.38097549478213

Epoch: 5| Step: 11
Training loss: 5.5201263427734375
Validation loss: 4.372798750797908

Epoch: 10| Step: 0
Training loss: 4.998841285705566
Validation loss: 4.36476194858551

Epoch: 5| Step: 1
Training loss: 3.8469669818878174
Validation loss: 4.356013496716817

Epoch: 5| Step: 2
Training loss: 4.6022539138793945
Validation loss: 4.348061184088389

Epoch: 5| Step: 3
Training loss: 3.698740005493164
Validation loss: 4.340322722991307

Epoch: 5| Step: 4
Training loss: 4.952496528625488
Validation loss: 4.33261650800705

Epoch: 5| Step: 5
Training loss: 4.346531867980957
Validation loss: 4.3248945871988935

Epoch: 5| Step: 6
Training loss: 3.5648117065429688
Validation loss: 4.317191580931346

Epoch: 5| Step: 7
Training loss: 4.61081600189209
Validation loss: 4.309561828772227

Epoch: 5| Step: 8
Training loss: 4.320032596588135
Validation loss: 4.301647553841273

Epoch: 5| Step: 9
Training loss: 4.597322940826416
Validation loss: 4.294433693091075

Epoch: 5| Step: 10
Training loss: 5.710661888122559
Validation loss: 4.2870094776153564

Epoch: 5| Step: 11
Training loss: 2.8668394088745117
Validation loss: 4.279522319634755

Epoch: 11| Step: 0
Training loss: 3.9445128440856934
Validation loss: 4.272158116102219

Epoch: 5| Step: 1
Training loss: 5.1592535972595215
Validation loss: 4.264924536148707

Epoch: 5| Step: 2
Training loss: 4.794610500335693
Validation loss: 4.257621546586354

Epoch: 5| Step: 3
Training loss: 4.28993558883667
Validation loss: 4.250755389531453

Epoch: 5| Step: 4
Training loss: 4.047879695892334
Validation loss: 4.24367035428683

Epoch: 5| Step: 5
Training loss: 3.9503607749938965
Validation loss: 4.236987253030141

Epoch: 5| Step: 6
Training loss: 5.138749122619629
Validation loss: 4.2295399606227875

Epoch: 5| Step: 7
Training loss: 4.186336517333984
Validation loss: 4.223020017147064

Epoch: 5| Step: 8
Training loss: 4.023877143859863
Validation loss: 4.215170224507649

Epoch: 5| Step: 9
Training loss: 5.029757499694824
Validation loss: 4.208203752835591

Epoch: 5| Step: 10
Training loss: 3.0965054035186768
Validation loss: 4.200917899608612

Epoch: 5| Step: 11
Training loss: 6.237915515899658
Validation loss: 4.1937776903311415

Epoch: 12| Step: 0
Training loss: 4.59227991104126
Validation loss: 4.186370621124904

Epoch: 5| Step: 1
Training loss: 3.743330717086792
Validation loss: 4.178619424502055

Epoch: 5| Step: 2
Training loss: 3.736316204071045
Validation loss: 4.171371301015218

Epoch: 5| Step: 3
Training loss: 4.9776482582092285
Validation loss: 4.164300322532654

Epoch: 5| Step: 4
Training loss: 3.2573630809783936
Validation loss: 4.155698895454407

Epoch: 5| Step: 5
Training loss: 4.107293128967285
Validation loss: 4.148188471794128

Epoch: 5| Step: 6
Training loss: 3.9021124839782715
Validation loss: 4.140909453233083

Epoch: 5| Step: 7
Training loss: 4.307607173919678
Validation loss: 4.133208066225052

Epoch: 5| Step: 8
Training loss: 4.5497636795043945
Validation loss: 4.1264524559179945

Epoch: 5| Step: 9
Training loss: 5.238744735717773
Validation loss: 4.118204355239868

Epoch: 5| Step: 10
Training loss: 4.492022514343262
Validation loss: 4.110177507003148

Epoch: 5| Step: 11
Training loss: 5.422123432159424
Validation loss: 4.10145781437556

Epoch: 13| Step: 0
Training loss: 4.671297073364258
Validation loss: 4.092865427335103

Epoch: 5| Step: 1
Training loss: 4.3893842697143555
Validation loss: 4.084772298733394

Epoch: 5| Step: 2
Training loss: 4.032413005828857
Validation loss: 4.074980904658635

Epoch: 5| Step: 3
Training loss: 4.616633415222168
Validation loss: 4.066114813089371

Epoch: 5| Step: 4
Training loss: 4.145876407623291
Validation loss: 4.056898891925812

Epoch: 5| Step: 5
Training loss: 3.9759247303009033
Validation loss: 4.048037211100261

Epoch: 5| Step: 6
Training loss: 3.8851935863494873
Validation loss: 4.039740413427353

Epoch: 5| Step: 7
Training loss: 3.635648727416992
Validation loss: 4.030962824821472

Epoch: 5| Step: 8
Training loss: 3.9111342430114746
Validation loss: 4.022778073946635

Epoch: 5| Step: 9
Training loss: 4.06889009475708
Validation loss: 4.01556329925855

Epoch: 5| Step: 10
Training loss: 4.6174492835998535
Validation loss: 4.007632444302241

Epoch: 5| Step: 11
Training loss: 4.986215114593506
Validation loss: 4.000392119089763

Epoch: 14| Step: 0
Training loss: 4.5241804122924805
Validation loss: 3.992616136868795

Epoch: 5| Step: 1
Training loss: 4.144170761108398
Validation loss: 3.9854991833368936

Epoch: 5| Step: 2
Training loss: 4.2636895179748535
Validation loss: 3.977886656920115

Epoch: 5| Step: 3
Training loss: 3.6144325733184814
Validation loss: 3.9703959226608276

Epoch: 5| Step: 4
Training loss: 4.019436836242676
Validation loss: 3.9627451399962106

Epoch: 5| Step: 5
Training loss: 3.6772918701171875
Validation loss: 3.956377496321996

Epoch: 5| Step: 6
Training loss: 3.949059009552002
Validation loss: 3.9505446354548135

Epoch: 5| Step: 7
Training loss: 3.543238401412964
Validation loss: 3.943690915902456

Epoch: 5| Step: 8
Training loss: 4.1060309410095215
Validation loss: 3.9358905951182046

Epoch: 5| Step: 9
Training loss: 4.409497261047363
Validation loss: 3.928505460421244

Epoch: 5| Step: 10
Training loss: 4.987818717956543
Validation loss: 3.921771059433619

Epoch: 5| Step: 11
Training loss: 3.552126407623291
Validation loss: 3.9146624306837716

Epoch: 15| Step: 0
Training loss: 3.5514559745788574
Validation loss: 3.9069662988185883

Epoch: 5| Step: 1
Training loss: 4.35342264175415
Validation loss: 3.9006577829519906

Epoch: 5| Step: 2
Training loss: 3.7568039894104004
Validation loss: 3.8934809068838754

Epoch: 5| Step: 3
Training loss: 4.075186729431152
Validation loss: 3.887539635101954

Epoch: 5| Step: 4
Training loss: 3.826306104660034
Validation loss: 3.880615880091985

Epoch: 5| Step: 5
Training loss: 4.2456254959106445
Validation loss: 3.8740819493929544

Epoch: 5| Step: 6
Training loss: 4.235391139984131
Validation loss: 3.86721600095431

Epoch: 5| Step: 7
Training loss: 4.272557258605957
Validation loss: 3.8604156573613486

Epoch: 5| Step: 8
Training loss: 3.8268399238586426
Validation loss: 3.8542746206124625

Epoch: 5| Step: 9
Training loss: 3.886950969696045
Validation loss: 3.8466134071350098

Epoch: 5| Step: 10
Training loss: 4.011385917663574
Validation loss: 3.841085056463877

Epoch: 5| Step: 11
Training loss: 5.131472110748291
Validation loss: 3.8355784515539804

Epoch: 16| Step: 0
Training loss: 4.042594909667969
Validation loss: 3.8286752700805664

Epoch: 5| Step: 1
Training loss: 4.256960868835449
Validation loss: 3.8231881658236184

Epoch: 5| Step: 2
Training loss: 3.5675010681152344
Validation loss: 3.816263794898987

Epoch: 5| Step: 3
Training loss: 3.165447950363159
Validation loss: 3.8103493253389993

Epoch: 5| Step: 4
Training loss: 3.896214246749878
Validation loss: 3.805293699105581

Epoch: 5| Step: 5
Training loss: 4.508242130279541
Validation loss: 3.7993725339571633

Epoch: 5| Step: 6
Training loss: 3.5542616844177246
Validation loss: 3.793407748142878

Epoch: 5| Step: 7
Training loss: 4.274603366851807
Validation loss: 3.7868303259213767

Epoch: 5| Step: 8
Training loss: 4.57919979095459
Validation loss: 3.7818649311860404

Epoch: 5| Step: 9
Training loss: 3.773397445678711
Validation loss: 3.7751985490322113

Epoch: 5| Step: 10
Training loss: 4.034842491149902
Validation loss: 3.769406259059906

Epoch: 5| Step: 11
Training loss: 3.185621738433838
Validation loss: 3.7636178036530814

Epoch: 17| Step: 0
Training loss: 4.821345806121826
Validation loss: 3.7621500293413797

Epoch: 5| Step: 1
Training loss: 4.582102298736572
Validation loss: 3.757048656543096

Epoch: 5| Step: 2
Training loss: 3.2159104347229004
Validation loss: 3.7481982707977295

Epoch: 5| Step: 3
Training loss: 4.599989891052246
Validation loss: 3.7442610561847687

Epoch: 5| Step: 4
Training loss: 4.084303855895996
Validation loss: 3.740070015192032

Epoch: 5| Step: 5
Training loss: 3.6279101371765137
Validation loss: 3.7332783639431

Epoch: 5| Step: 6
Training loss: 3.8060154914855957
Validation loss: 3.729019284248352

Epoch: 5| Step: 7
Training loss: 3.3739724159240723
Validation loss: 3.7242923378944397

Epoch: 5| Step: 8
Training loss: 3.6293997764587402
Validation loss: 3.717744916677475

Epoch: 5| Step: 9
Training loss: 4.549454689025879
Validation loss: 3.711936662594477

Epoch: 5| Step: 10
Training loss: 2.6599490642547607
Validation loss: 3.7069425185521445

Epoch: 5| Step: 11
Training loss: 3.35673189163208
Validation loss: 3.7019219199816384

Epoch: 18| Step: 0
Training loss: 3.7977051734924316
Validation loss: 3.6967046658198037

Epoch: 5| Step: 1
Training loss: 3.647122621536255
Validation loss: 3.6922956109046936

Epoch: 5| Step: 2
Training loss: 4.219622611999512
Validation loss: 3.6875337262948356

Epoch: 5| Step: 3
Training loss: 3.6386356353759766
Validation loss: 3.6817834178606668

Epoch: 5| Step: 4
Training loss: 3.8549816608428955
Validation loss: 3.6769366562366486

Epoch: 5| Step: 5
Training loss: 3.724578857421875
Validation loss: 3.670829951763153

Epoch: 5| Step: 6
Training loss: 3.4663479328155518
Validation loss: 3.666294405857722

Epoch: 5| Step: 7
Training loss: 3.9937243461608887
Validation loss: 3.6605138182640076

Epoch: 5| Step: 8
Training loss: 3.4500720500946045
Validation loss: 3.6553733249505362

Epoch: 5| Step: 9
Training loss: 4.186348915100098
Validation loss: 3.650286535422007

Epoch: 5| Step: 10
Training loss: 3.9262709617614746
Validation loss: 3.6455608308315277

Epoch: 5| Step: 11
Training loss: 5.129824638366699
Validation loss: 3.639777888854345

Epoch: 19| Step: 0
Training loss: 3.770629405975342
Validation loss: 3.635317732890447

Epoch: 5| Step: 1
Training loss: 4.762572765350342
Validation loss: 3.63053893049558

Epoch: 5| Step: 2
Training loss: 4.3807268142700195
Validation loss: 3.6255887548128762

Epoch: 5| Step: 3
Training loss: 3.2897045612335205
Validation loss: 3.620746692021688

Epoch: 5| Step: 4
Training loss: 3.2316322326660156
Validation loss: 3.6156701147556305

Epoch: 5| Step: 5
Training loss: 4.198241233825684
Validation loss: 3.6102299193541207

Epoch: 5| Step: 6
Training loss: 3.370436191558838
Validation loss: 3.6041890680789948

Epoch: 5| Step: 7
Training loss: 4.1217546463012695
Validation loss: 3.599662055571874

Epoch: 5| Step: 8
Training loss: 3.4938175678253174
Validation loss: 3.594432681798935

Epoch: 5| Step: 9
Training loss: 4.070775032043457
Validation loss: 3.589186122020086

Epoch: 5| Step: 10
Training loss: 3.3311781883239746
Validation loss: 3.5835727949937186

Epoch: 5| Step: 11
Training loss: 1.1257169246673584
Validation loss: 3.5783290962378183

Epoch: 20| Step: 0
Training loss: 3.50593638420105
Validation loss: 3.5744986832141876

Epoch: 5| Step: 1
Training loss: 4.1591339111328125
Validation loss: 3.5698633193969727

Epoch: 5| Step: 2
Training loss: 3.3813610076904297
Validation loss: 3.5655893882115683

Epoch: 5| Step: 3
Training loss: 4.03749418258667
Validation loss: 3.560861269632975

Epoch: 5| Step: 4
Training loss: 3.9016380310058594
Validation loss: 3.5563336312770844

Epoch: 5| Step: 5
Training loss: 3.1622397899627686
Validation loss: 3.551739583412806

Epoch: 5| Step: 6
Training loss: 3.7890212535858154
Validation loss: 3.54684516787529

Epoch: 5| Step: 7
Training loss: 4.038019180297852
Validation loss: 3.5424319307009378

Epoch: 5| Step: 8
Training loss: 3.5115866661071777
Validation loss: 3.5378635227680206

Epoch: 5| Step: 9
Training loss: 3.5567092895507812
Validation loss: 3.5326991379261017

Epoch: 5| Step: 10
Training loss: 3.6834716796875
Validation loss: 3.5285177528858185

Epoch: 5| Step: 11
Training loss: 4.428835868835449
Validation loss: 3.5237499475479126

Epoch: 21| Step: 0
Training loss: 3.3718299865722656
Validation loss: 3.5187108516693115

Epoch: 5| Step: 1
Training loss: 3.1632585525512695
Validation loss: 3.5141967833042145

Epoch: 5| Step: 2
Training loss: 2.963496208190918
Validation loss: 3.509767254193624

Epoch: 5| Step: 3
Training loss: 4.037863254547119
Validation loss: 3.504958152770996

Epoch: 5| Step: 4
Training loss: 2.7814242839813232
Validation loss: 3.500738541285197

Epoch: 5| Step: 5
Training loss: 3.9078056812286377
Validation loss: 3.4955743650595346

Epoch: 5| Step: 6
Training loss: 4.44208288192749
Validation loss: 3.490346610546112

Epoch: 5| Step: 7
Training loss: 4.161627769470215
Validation loss: 3.486353615919749

Epoch: 5| Step: 8
Training loss: 4.431885242462158
Validation loss: 3.481969873110453

Epoch: 5| Step: 9
Training loss: 4.094603061676025
Validation loss: 3.4767670234044394

Epoch: 5| Step: 10
Training loss: 2.7646682262420654
Validation loss: 3.472005009651184

Epoch: 5| Step: 11
Training loss: 4.382900238037109
Validation loss: 3.466199040412903

Epoch: 22| Step: 0
Training loss: 3.5980172157287598
Validation loss: 3.461358924706777

Epoch: 5| Step: 1
Training loss: 3.4187443256378174
Validation loss: 3.4559469521045685

Epoch: 5| Step: 2
Training loss: 3.9934074878692627
Validation loss: 3.4505849877993264

Epoch: 5| Step: 3
Training loss: 3.1480016708374023
Validation loss: 3.4458275536696115

Epoch: 5| Step: 4
Training loss: 3.7050178050994873
Validation loss: 3.4407819310824075

Epoch: 5| Step: 5
Training loss: 4.609420299530029
Validation loss: 3.4359903832276664

Epoch: 5| Step: 6
Training loss: 2.7866387367248535
Validation loss: 3.4305999179681144

Epoch: 5| Step: 7
Training loss: 3.0758185386657715
Validation loss: 3.4254734814167023

Epoch: 5| Step: 8
Training loss: 4.217217445373535
Validation loss: 3.420726795991262

Epoch: 5| Step: 9
Training loss: 3.7193665504455566
Validation loss: 3.4165951311588287

Epoch: 5| Step: 10
Training loss: 3.326428174972534
Validation loss: 3.411627401908239

Epoch: 5| Step: 11
Training loss: 3.7899551391601562
Validation loss: 3.40753972530365

Epoch: 23| Step: 0
Training loss: 3.9099020957946777
Validation loss: 3.4026781419912973

Epoch: 5| Step: 1
Training loss: 3.0430877208709717
Validation loss: 3.397377838691076

Epoch: 5| Step: 2
Training loss: 3.810800552368164
Validation loss: 3.3926440676053367

Epoch: 5| Step: 3
Training loss: 4.307075023651123
Validation loss: 3.3883268733819327

Epoch: 5| Step: 4
Training loss: 2.753194570541382
Validation loss: 3.3842840592066445

Epoch: 5| Step: 5
Training loss: 3.709946870803833
Validation loss: 3.3791364431381226

Epoch: 5| Step: 6
Training loss: 3.398974657058716
Validation loss: 3.3743283649285636

Epoch: 5| Step: 7
Training loss: 3.737104892730713
Validation loss: 3.3699268301328025

Epoch: 5| Step: 8
Training loss: 3.1853244304656982
Validation loss: 3.364417632420858

Epoch: 5| Step: 9
Training loss: 3.8565375804901123
Validation loss: 3.3599682052930198

Epoch: 5| Step: 10
Training loss: 2.9269676208496094
Validation loss: 3.35527170697848

Epoch: 5| Step: 11
Training loss: 5.438945770263672
Validation loss: 3.351033757130305

Epoch: 24| Step: 0
Training loss: 3.697472095489502
Validation loss: 3.34627628326416

Epoch: 5| Step: 1
Training loss: 3.1655943393707275
Validation loss: 3.3415974378585815

Epoch: 5| Step: 2
Training loss: 4.090175628662109
Validation loss: 3.3364459574222565

Epoch: 5| Step: 3
Training loss: 3.111154556274414
Validation loss: 3.3317036231358848

Epoch: 5| Step: 4
Training loss: 3.1594977378845215
Validation loss: 3.327190031607946

Epoch: 5| Step: 5
Training loss: 3.8712317943573
Validation loss: 3.322385956843694

Epoch: 5| Step: 6
Training loss: 4.1418609619140625
Validation loss: 3.318398803472519

Epoch: 5| Step: 7
Training loss: 2.806793451309204
Validation loss: 3.3138336837291718

Epoch: 5| Step: 8
Training loss: 3.7828078269958496
Validation loss: 3.3092066943645477

Epoch: 5| Step: 9
Training loss: 3.5082473754882812
Validation loss: 3.3042580783367157

Epoch: 5| Step: 10
Training loss: 3.059558391571045
Validation loss: 3.29980738957723

Epoch: 5| Step: 11
Training loss: 3.768387794494629
Validation loss: 3.296130587657293

Epoch: 25| Step: 0
Training loss: 3.5193443298339844
Validation loss: 3.2919205327828727

Epoch: 5| Step: 1
Training loss: 2.5611462593078613
Validation loss: 3.288229316473007

Epoch: 5| Step: 2
Training loss: 3.843782901763916
Validation loss: 3.2843898236751556

Epoch: 5| Step: 3
Training loss: 3.767993211746216
Validation loss: 3.2804783980051675

Epoch: 5| Step: 4
Training loss: 3.8869712352752686
Validation loss: 3.2760830521583557

Epoch: 5| Step: 5
Training loss: 2.743950366973877
Validation loss: 3.2721495032310486

Epoch: 5| Step: 6
Training loss: 3.61047101020813
Validation loss: 3.268442531426748

Epoch: 5| Step: 7
Training loss: 3.0758166313171387
Validation loss: 3.2645616630713143

Epoch: 5| Step: 8
Training loss: 4.280532360076904
Validation loss: 3.2601851423581443

Epoch: 5| Step: 9
Training loss: 3.219879627227783
Validation loss: 3.2563249866167703

Epoch: 5| Step: 10
Training loss: 3.3262546062469482
Validation loss: 3.251826137304306

Epoch: 5| Step: 11
Training loss: 3.854092597961426
Validation loss: 3.2476038138071694

Epoch: 26| Step: 0
Training loss: 3.772951602935791
Validation loss: 3.2435012062390647

Epoch: 5| Step: 1
Training loss: 4.334954261779785
Validation loss: 3.2394651969273887

Epoch: 5| Step: 2
Training loss: 2.779716968536377
Validation loss: 3.23496945699056

Epoch: 5| Step: 3
Training loss: 2.8852832317352295
Validation loss: 3.2310121953487396

Epoch: 5| Step: 4
Training loss: 3.448617935180664
Validation loss: 3.2275334099928537

Epoch: 5| Step: 5
Training loss: 3.5657272338867188
Validation loss: 3.2266071240107217

Epoch: 5| Step: 6
Training loss: 3.6085166931152344
Validation loss: 3.218939224878947

Epoch: 5| Step: 7
Training loss: 3.553007125854492
Validation loss: 3.2155858973662057

Epoch: 5| Step: 8
Training loss: 3.7810254096984863
Validation loss: 3.2126604616642

Epoch: 5| Step: 9
Training loss: 2.286311388015747
Validation loss: 3.210316220919291

Epoch: 5| Step: 10
Training loss: 3.4244608879089355
Validation loss: 3.207283149162928

Epoch: 5| Step: 11
Training loss: 3.474280834197998
Validation loss: 3.2039018968741098

Epoch: 27| Step: 0
Training loss: 3.4617676734924316
Validation loss: 3.2000789642333984

Epoch: 5| Step: 1
Training loss: 3.663145065307617
Validation loss: 3.1954981287320456

Epoch: 5| Step: 2
Training loss: 3.7212347984313965
Validation loss: 3.190893699725469

Epoch: 5| Step: 3
Training loss: 2.9859697818756104
Validation loss: 3.1857136388619742

Epoch: 5| Step: 4
Training loss: 3.6137535572052
Validation loss: 3.181047350168228

Epoch: 5| Step: 5
Training loss: 3.5246078968048096
Validation loss: 3.176848361889521

Epoch: 5| Step: 6
Training loss: 3.6132149696350098
Validation loss: 3.1728088359038034

Epoch: 5| Step: 7
Training loss: 3.4231667518615723
Validation loss: 3.1689926087856293

Epoch: 5| Step: 8
Training loss: 2.8723959922790527
Validation loss: 3.1650427480538688

Epoch: 5| Step: 9
Training loss: 3.2835419178009033
Validation loss: 3.160885602235794

Epoch: 5| Step: 10
Training loss: 2.7990293502807617
Validation loss: 3.157095452149709

Epoch: 5| Step: 11
Training loss: 3.5118513107299805
Validation loss: 3.1533649961153665

Epoch: 28| Step: 0
Training loss: 3.3074073791503906
Validation loss: 3.149581323067347

Epoch: 5| Step: 1
Training loss: 3.1259007453918457
Validation loss: 3.146052360534668

Epoch: 5| Step: 2
Training loss: 3.854309558868408
Validation loss: 3.142340471347173

Epoch: 5| Step: 3
Training loss: 2.749213218688965
Validation loss: 3.1383362114429474

Epoch: 5| Step: 4
Training loss: 3.8499763011932373
Validation loss: 3.1342446903387704

Epoch: 5| Step: 5
Training loss: 3.546168088912964
Validation loss: 3.1305494705835977

Epoch: 5| Step: 6
Training loss: 3.692554473876953
Validation loss: 3.126336087783178

Epoch: 5| Step: 7
Training loss: 2.881941556930542
Validation loss: 3.1222703556219735

Epoch: 5| Step: 8
Training loss: 2.7503631114959717
Validation loss: 3.1184830963611603

Epoch: 5| Step: 9
Training loss: 3.4559264183044434
Validation loss: 3.114722857872645

Epoch: 5| Step: 10
Training loss: 3.344966173171997
Validation loss: 3.11070986588796

Epoch: 5| Step: 11
Training loss: 2.980976104736328
Validation loss: 3.1070109705130258

Epoch: 29| Step: 0
Training loss: 3.72869873046875
Validation loss: 3.1031523247559867

Epoch: 5| Step: 1
Training loss: 3.287041425704956
Validation loss: 3.0994524359703064

Epoch: 5| Step: 2
Training loss: 3.2083001136779785
Validation loss: 3.095955550670624

Epoch: 5| Step: 3
Training loss: 2.8405213356018066
Validation loss: 3.0926543176174164

Epoch: 5| Step: 4
Training loss: 3.557298183441162
Validation loss: 3.089071979125341

Epoch: 5| Step: 5
Training loss: 3.806360960006714
Validation loss: 3.0855317215124765

Epoch: 5| Step: 6
Training loss: 2.6029086112976074
Validation loss: 3.081570476293564

Epoch: 5| Step: 7
Training loss: 3.1994168758392334
Validation loss: 3.0781861742337546

Epoch: 5| Step: 8
Training loss: 3.625256299972534
Validation loss: 3.0748502810796103

Epoch: 5| Step: 9
Training loss: 2.748708486557007
Validation loss: 3.071654200553894

Epoch: 5| Step: 10
Training loss: 3.191434860229492
Validation loss: 3.0679666697978973

Epoch: 5| Step: 11
Training loss: 4.437280178070068
Validation loss: 3.0646880070368447

Epoch: 30| Step: 0
Training loss: 3.9248859882354736
Validation loss: 3.0606114069620767

Epoch: 5| Step: 1
Training loss: 3.8307766914367676
Validation loss: 3.0571257372697196

Epoch: 5| Step: 2
Training loss: 2.732844114303589
Validation loss: 3.0533869167168937

Epoch: 5| Step: 3
Training loss: 3.8363540172576904
Validation loss: 3.0496378242969513

Epoch: 5| Step: 4
Training loss: 2.783478021621704
Validation loss: 3.0459353725115457

Epoch: 5| Step: 5
Training loss: 3.384594678878784
Validation loss: 3.0420331557591758

Epoch: 5| Step: 6
Training loss: 3.739530563354492
Validation loss: 3.0383604168891907

Epoch: 5| Step: 7
Training loss: 2.572920560836792
Validation loss: 3.0344352424144745

Epoch: 5| Step: 8
Training loss: 2.5079338550567627
Validation loss: 3.030475447575251

Epoch: 5| Step: 9
Training loss: 3.409158706665039
Validation loss: 3.027614802122116

Epoch: 5| Step: 10
Training loss: 3.3227744102478027
Validation loss: 3.0241870681444802

Epoch: 5| Step: 11
Training loss: 0.9589425325393677
Validation loss: 3.0207555989424386

Epoch: 31| Step: 0
Training loss: 3.307786464691162
Validation loss: 3.017534444729487

Epoch: 5| Step: 1
Training loss: 2.7137229442596436
Validation loss: 3.0147048830986023

Epoch: 5| Step: 2
Training loss: 3.860520124435425
Validation loss: 3.01153372724851

Epoch: 5| Step: 3
Training loss: 3.4139816761016846
Validation loss: 3.008795420328776

Epoch: 5| Step: 4
Training loss: 3.455108165740967
Validation loss: 3.006063242753347

Epoch: 5| Step: 5
Training loss: 3.246009111404419
Validation loss: 3.0027759075164795

Epoch: 5| Step: 6
Training loss: 3.152776002883911
Validation loss: 2.9985495706399283

Epoch: 5| Step: 7
Training loss: 2.9172470569610596
Validation loss: 2.996456185976664

Epoch: 5| Step: 8
Training loss: 3.4474968910217285
Validation loss: 2.9941137731075287

Epoch: 5| Step: 9
Training loss: 3.1827359199523926
Validation loss: 2.993570953607559

Epoch: 5| Step: 10
Training loss: 2.6457679271698
Validation loss: 2.987238049507141

Epoch: 5| Step: 11
Training loss: 2.244486093521118
Validation loss: 2.9828412532806396

Epoch: 32| Step: 0
Training loss: 3.119062900543213
Validation loss: 2.979319920142492

Epoch: 5| Step: 1
Training loss: 2.375117301940918
Validation loss: 2.976097842057546

Epoch: 5| Step: 2
Training loss: 3.4174532890319824
Validation loss: 2.972952743371328

Epoch: 5| Step: 3
Training loss: 3.342442035675049
Validation loss: 2.9700361092885337

Epoch: 5| Step: 4
Training loss: 2.844236135482788
Validation loss: 2.9664653142293296

Epoch: 5| Step: 5
Training loss: 3.5825531482696533
Validation loss: 2.963199953238169

Epoch: 5| Step: 6
Training loss: 3.943230152130127
Validation loss: 2.959795201818148

Epoch: 5| Step: 7
Training loss: 2.4646048545837402
Validation loss: 2.9561643103758493

Epoch: 5| Step: 8
Training loss: 2.8965260982513428
Validation loss: 2.952857941389084

Epoch: 5| Step: 9
Training loss: 2.988888740539551
Validation loss: 2.949579437573751

Epoch: 5| Step: 10
Training loss: 3.5483222007751465
Validation loss: 2.9460013707478843

Epoch: 5| Step: 11
Training loss: 4.385366439819336
Validation loss: 2.9424680968125663

Epoch: 33| Step: 0
Training loss: 4.033625602722168
Validation loss: 2.939125488201777

Epoch: 5| Step: 1
Training loss: 2.8605217933654785
Validation loss: 2.9355876247088113

Epoch: 5| Step: 2
Training loss: 2.3217055797576904
Validation loss: 2.9320061802864075

Epoch: 5| Step: 3
Training loss: 3.1745080947875977
Validation loss: 2.9290144642194114

Epoch: 5| Step: 4
Training loss: 2.9186911582946777
Validation loss: 2.925877014795939

Epoch: 5| Step: 5
Training loss: 3.0879933834075928
Validation loss: 2.92274272441864

Epoch: 5| Step: 6
Training loss: 2.724137783050537
Validation loss: 2.9192230304082236

Epoch: 5| Step: 7
Training loss: 3.3874573707580566
Validation loss: 2.9162230690320334

Epoch: 5| Step: 8
Training loss: 3.047274351119995
Validation loss: 2.9130169451236725

Epoch: 5| Step: 9
Training loss: 3.053863763809204
Validation loss: 2.9095055063565574

Epoch: 5| Step: 10
Training loss: 3.672595977783203
Validation loss: 2.906191736459732

Epoch: 5| Step: 11
Training loss: 3.590667963027954
Validation loss: 2.903959115346273

Epoch: 34| Step: 0
Training loss: 3.0461790561676025
Validation loss: 2.9008103211720786

Epoch: 5| Step: 1
Training loss: 3.5014026165008545
Validation loss: 2.8975571990013123

Epoch: 5| Step: 2
Training loss: 2.9634573459625244
Validation loss: 2.895958041151365

Epoch: 5| Step: 3
Training loss: 3.4224514961242676
Validation loss: 2.891915738582611

Epoch: 5| Step: 4
Training loss: 3.2813363075256348
Validation loss: 2.890412837266922

Epoch: 5| Step: 5
Training loss: 2.817754030227661
Validation loss: 2.885281523068746

Epoch: 5| Step: 6
Training loss: 2.86279296875
Validation loss: 2.8812798460324607

Epoch: 5| Step: 7
Training loss: 2.8270580768585205
Validation loss: 2.8786524534225464

Epoch: 5| Step: 8
Training loss: 3.387908458709717
Validation loss: 2.8756043215592704

Epoch: 5| Step: 9
Training loss: 3.554306745529175
Validation loss: 2.8732032775878906

Epoch: 5| Step: 10
Training loss: 2.524901866912842
Validation loss: 2.870606998602549

Epoch: 5| Step: 11
Training loss: 2.125335216522217
Validation loss: 2.8676774203777313

Epoch: 35| Step: 0
Training loss: 3.06259822845459
Validation loss: 2.864385634660721

Epoch: 5| Step: 1
Training loss: 3.008500814437866
Validation loss: 2.8608727554480233

Epoch: 5| Step: 2
Training loss: 2.752990245819092
Validation loss: 2.8576532304286957

Epoch: 5| Step: 3
Training loss: 3.1306848526000977
Validation loss: 2.854560067256292

Epoch: 5| Step: 4
Training loss: 3.7068207263946533
Validation loss: 2.851447025934855

Epoch: 5| Step: 5
Training loss: 2.7191214561462402
Validation loss: 2.8479332625865936

Epoch: 5| Step: 6
Training loss: 2.812307834625244
Validation loss: 2.8448511958122253

Epoch: 5| Step: 7
Training loss: 3.4234719276428223
Validation loss: 2.8412336508433023

Epoch: 5| Step: 8
Training loss: 2.775871515274048
Validation loss: 2.837934762239456

Epoch: 5| Step: 9
Training loss: 2.827788829803467
Validation loss: 2.834612717231115

Epoch: 5| Step: 10
Training loss: 3.6168549060821533
Validation loss: 2.8313985963662467

Epoch: 5| Step: 11
Training loss: 2.1056771278381348
Validation loss: 2.8283979098002114

Epoch: 36| Step: 0
Training loss: 3.2977681159973145
Validation loss: 2.825214773416519

Epoch: 5| Step: 1
Training loss: 3.087792158126831
Validation loss: 2.8223909040292106

Epoch: 5| Step: 2
Training loss: 3.3977935314178467
Validation loss: 2.8193115989367166

Epoch: 5| Step: 3
Training loss: 2.8081257343292236
Validation loss: 2.816196918487549

Epoch: 5| Step: 4
Training loss: 2.814392566680908
Validation loss: 2.813468019167582

Epoch: 5| Step: 5
Training loss: 3.194756269454956
Validation loss: 2.810775806506475

Epoch: 5| Step: 6
Training loss: 3.3526434898376465
Validation loss: 2.8084381024042764

Epoch: 5| Step: 7
Training loss: 3.0526068210601807
Validation loss: 2.8055149018764496

Epoch: 5| Step: 8
Training loss: 3.3871376514434814
Validation loss: 2.802670101324717

Epoch: 5| Step: 9
Training loss: 2.6439428329467773
Validation loss: 2.8002285758654275

Epoch: 5| Step: 10
Training loss: 2.3729827404022217
Validation loss: 2.800091336170832

Epoch: 5| Step: 11
Training loss: 2.3269829750061035
Validation loss: 2.7982599437236786

Epoch: 37| Step: 0
Training loss: 3.213228225708008
Validation loss: 2.8135315775871277

Epoch: 5| Step: 1
Training loss: 2.77903413772583
Validation loss: 2.789178361495336

Epoch: 5| Step: 2
Training loss: 3.1778831481933594
Validation loss: 2.786297937234243

Epoch: 5| Step: 3
Training loss: 3.149010419845581
Validation loss: 2.7843456168969474

Epoch: 5| Step: 4
Training loss: 3.5568039417266846
Validation loss: 2.782814453045527

Epoch: 5| Step: 5
Training loss: 3.1397337913513184
Validation loss: 2.783107280731201

Epoch: 5| Step: 6
Training loss: 2.441723585128784
Validation loss: 2.7787610987822213

Epoch: 5| Step: 7
Training loss: 2.746798276901245
Validation loss: 2.7754392524560294

Epoch: 5| Step: 8
Training loss: 3.124199628829956
Validation loss: 2.772339383761088

Epoch: 5| Step: 9
Training loss: 2.7725813388824463
Validation loss: 2.769183744986852

Epoch: 5| Step: 10
Training loss: 2.93898344039917
Validation loss: 2.7662708361943564

Epoch: 5| Step: 11
Training loss: 2.418482780456543
Validation loss: 2.7628855109214783

Epoch: 38| Step: 0
Training loss: 2.5253806114196777
Validation loss: 2.7597966293493905

Epoch: 5| Step: 1
Training loss: 2.853454113006592
Validation loss: 2.7589971323808036

Epoch: 5| Step: 2
Training loss: 2.819310188293457
Validation loss: 2.7551516195138297

Epoch: 5| Step: 3
Training loss: 3.4921443462371826
Validation loss: 2.7525232831637063

Epoch: 5| Step: 4
Training loss: 2.863690137863159
Validation loss: 2.7477694054444632

Epoch: 5| Step: 5
Training loss: 2.8043372631073
Validation loss: 2.7460656066735587

Epoch: 5| Step: 6
Training loss: 3.3334708213806152
Validation loss: 2.742889185746511

Epoch: 5| Step: 7
Training loss: 2.926069736480713
Validation loss: 2.738557130098343

Epoch: 5| Step: 8
Training loss: 3.3814644813537598
Validation loss: 2.7340782980124154

Epoch: 5| Step: 9
Training loss: 3.0069336891174316
Validation loss: 2.732742895682653

Epoch: 5| Step: 10
Training loss: 2.6546664237976074
Validation loss: 2.736837695042292

Epoch: 5| Step: 11
Training loss: 2.235863208770752
Validation loss: 2.7323468228181205

Epoch: 39| Step: 0
Training loss: 2.4444661140441895
Validation loss: 2.733113477627436

Epoch: 5| Step: 1
Training loss: 2.991377592086792
Validation loss: 2.729779695471128

Epoch: 5| Step: 2
Training loss: 2.9804000854492188
Validation loss: 2.7207334438959756

Epoch: 5| Step: 3
Training loss: 3.438976287841797
Validation loss: 2.7147942980130515

Epoch: 5| Step: 4
Training loss: 2.4150795936584473
Validation loss: 2.714245488246282

Epoch: 5| Step: 5
Training loss: 3.1499836444854736
Validation loss: 2.7136918803056083

Epoch: 5| Step: 6
Training loss: 3.1221277713775635
Validation loss: 2.7111663619677224

Epoch: 5| Step: 7
Training loss: 2.9135372638702393
Validation loss: 2.70894001921018

Epoch: 5| Step: 8
Training loss: 2.864192247390747
Validation loss: 2.7059424022833505

Epoch: 5| Step: 9
Training loss: 2.384894371032715
Validation loss: 2.7032418747742972

Epoch: 5| Step: 10
Training loss: 3.297288179397583
Validation loss: 2.699961930513382

Epoch: 5| Step: 11
Training loss: 3.541419506072998
Validation loss: 2.696782390276591

Epoch: 40| Step: 0
Training loss: 2.642345905303955
Validation loss: 2.6926634212334952

Epoch: 5| Step: 1
Training loss: 3.001962900161743
Validation loss: 2.6888530353705087

Epoch: 5| Step: 2
Training loss: 3.1038002967834473
Validation loss: 2.6852092941602073

Epoch: 5| Step: 3
Training loss: 3.735640048980713
Validation loss: 2.6820264756679535

Epoch: 5| Step: 4
Training loss: 2.6512746810913086
Validation loss: 2.6772571206092834

Epoch: 5| Step: 5
Training loss: 2.751039505004883
Validation loss: 2.674467076857885

Epoch: 5| Step: 6
Training loss: 2.7394044399261475
Validation loss: 2.6701826055844626

Epoch: 5| Step: 7
Training loss: 2.9408462047576904
Validation loss: 2.667189965645472

Epoch: 5| Step: 8
Training loss: 3.0800130367279053
Validation loss: 2.664707362651825

Epoch: 5| Step: 9
Training loss: 2.0007007122039795
Validation loss: 2.660616770386696

Epoch: 5| Step: 10
Training loss: 2.9393978118896484
Validation loss: 2.658426250020663

Epoch: 5| Step: 11
Training loss: 3.4844064712524414
Validation loss: 2.6545215944449105

Epoch: 41| Step: 0
Training loss: 2.5846519470214844
Validation loss: 2.65259250998497

Epoch: 5| Step: 1
Training loss: 3.43986439704895
Validation loss: 2.65207647283872

Epoch: 5| Step: 2
Training loss: 2.8877360820770264
Validation loss: 2.647865414619446

Epoch: 5| Step: 3
Training loss: 2.9021973609924316
Validation loss: 2.6434201300144196

Epoch: 5| Step: 4
Training loss: 3.0615994930267334
Validation loss: 2.639867732922236

Epoch: 5| Step: 5
Training loss: 2.6642518043518066
Validation loss: 2.6378100216388702

Epoch: 5| Step: 6
Training loss: 2.6034934520721436
Validation loss: 2.6343746980031333

Epoch: 5| Step: 7
Training loss: 2.9961445331573486
Validation loss: 2.6306720872720084

Epoch: 5| Step: 8
Training loss: 2.6373305320739746
Validation loss: 2.6284719904263816

Epoch: 5| Step: 9
Training loss: 3.099762439727783
Validation loss: 2.6263626416524253

Epoch: 5| Step: 10
Training loss: 2.4273762702941895
Validation loss: 2.6226025025049844

Epoch: 5| Step: 11
Training loss: 2.6771483421325684
Validation loss: 2.6218303640683494

Epoch: 42| Step: 0
Training loss: 2.797651767730713
Validation loss: 2.616982360680898

Epoch: 5| Step: 1
Training loss: 2.9401135444641113
Validation loss: 2.6123183965682983

Epoch: 5| Step: 2
Training loss: 2.789680004119873
Validation loss: 2.609003891547521

Epoch: 5| Step: 3
Training loss: 3.1890170574188232
Validation loss: 2.6072390725215278

Epoch: 5| Step: 4
Training loss: 3.134599447250366
Validation loss: 2.603827734788259

Epoch: 5| Step: 5
Training loss: 2.7057297229766846
Validation loss: 2.5991061528523765

Epoch: 5| Step: 6
Training loss: 2.2514939308166504
Validation loss: 2.596226751804352

Epoch: 5| Step: 7
Training loss: 2.796607494354248
Validation loss: 2.5932666659355164

Epoch: 5| Step: 8
Training loss: 2.6949877738952637
Validation loss: 2.5909679929415383

Epoch: 5| Step: 9
Training loss: 2.873769998550415
Validation loss: 2.5873279571533203

Epoch: 5| Step: 10
Training loss: 2.7144274711608887
Validation loss: 2.583062618970871

Epoch: 5| Step: 11
Training loss: 2.582587718963623
Validation loss: 2.5807773768901825

Epoch: 43| Step: 0
Training loss: 2.8311851024627686
Validation loss: 2.5777830382188163

Epoch: 5| Step: 1
Training loss: 3.0168397426605225
Validation loss: 2.5746873219807944

Epoch: 5| Step: 2
Training loss: 2.9052281379699707
Validation loss: 2.570963829755783

Epoch: 5| Step: 3
Training loss: 2.398538589477539
Validation loss: 2.5696626702944436

Epoch: 5| Step: 4
Training loss: 2.7171661853790283
Validation loss: 2.5644271870454154

Epoch: 5| Step: 5
Training loss: 2.5710151195526123
Validation loss: 2.5610224505265555

Epoch: 5| Step: 6
Training loss: 3.0131232738494873
Validation loss: 2.559154520432154

Epoch: 5| Step: 7
Training loss: 2.6639933586120605
Validation loss: 2.5596819519996643

Epoch: 5| Step: 8
Training loss: 2.7601447105407715
Validation loss: 2.5546573400497437

Epoch: 5| Step: 9
Training loss: 2.481062173843384
Validation loss: 2.551661103963852

Epoch: 5| Step: 10
Training loss: 3.1395111083984375
Validation loss: 2.5505574345588684

Epoch: 5| Step: 11
Training loss: 2.3251876831054688
Validation loss: 2.5477613508701324

Epoch: 44| Step: 0
Training loss: 3.2002415657043457
Validation loss: 2.5452861736218133

Epoch: 5| Step: 1
Training loss: 2.6004860401153564
Validation loss: 2.5430628259976706

Epoch: 5| Step: 2
Training loss: 2.4141745567321777
Validation loss: 2.5406382282574973

Epoch: 5| Step: 3
Training loss: 2.886522054672241
Validation loss: 2.5377018451690674

Epoch: 5| Step: 4
Training loss: 2.773677349090576
Validation loss: 2.535809636116028

Epoch: 5| Step: 5
Training loss: 2.476428985595703
Validation loss: 2.532066057125727

Epoch: 5| Step: 6
Training loss: 2.985908031463623
Validation loss: 2.5308782756328583

Epoch: 5| Step: 7
Training loss: 3.3106555938720703
Validation loss: 2.529183675845464

Epoch: 5| Step: 8
Training loss: 2.44329571723938
Validation loss: 2.5243491927782693

Epoch: 5| Step: 9
Training loss: 2.456308364868164
Validation loss: 2.5229903757572174

Epoch: 5| Step: 10
Training loss: 2.4379024505615234
Validation loss: 2.5195891757806144

Epoch: 5| Step: 11
Training loss: 2.9564733505249023
Validation loss: 2.5178383191426597

Epoch: 45| Step: 0
Training loss: 2.822011947631836
Validation loss: 2.5173597832520804

Epoch: 5| Step: 1
Training loss: 2.9237968921661377
Validation loss: 2.5189762711524963

Epoch: 5| Step: 2
Training loss: 3.015068531036377
Validation loss: 2.5250730017820993

Epoch: 5| Step: 3
Training loss: 3.604475498199463
Validation loss: 2.5224527617295585

Epoch: 5| Step: 4
Training loss: 1.887211561203003
Validation loss: 2.514730523029963

Epoch: 5| Step: 5
Training loss: 3.0101118087768555
Validation loss: 2.50983918706576

Epoch: 5| Step: 6
Training loss: 2.532461643218994
Validation loss: 2.5080257852872214

Epoch: 5| Step: 7
Training loss: 1.8878288269042969
Validation loss: 2.503915180762609

Epoch: 5| Step: 8
Training loss: 2.708400249481201
Validation loss: 2.500904748837153

Epoch: 5| Step: 9
Training loss: 2.6985957622528076
Validation loss: 2.4963581264019012

Epoch: 5| Step: 10
Training loss: 2.4683690071105957
Validation loss: 2.492872248093287

Epoch: 5| Step: 11
Training loss: 3.575064182281494
Validation loss: 2.4895682632923126

Epoch: 46| Step: 0
Training loss: 2.2143938541412354
Validation loss: 2.4859984715779624

Epoch: 5| Step: 1
Training loss: 2.5082249641418457
Validation loss: 2.4827336370944977

Epoch: 5| Step: 2
Training loss: 2.7307639122009277
Validation loss: 2.4784397582213082

Epoch: 5| Step: 3
Training loss: 2.962590456008911
Validation loss: 2.478794649243355

Epoch: 5| Step: 4
Training loss: 2.5931081771850586
Validation loss: 2.4764878849188485

Epoch: 5| Step: 5
Training loss: 2.615140199661255
Validation loss: 2.471103156606356

Epoch: 5| Step: 6
Training loss: 3.221193313598633
Validation loss: 2.4670549631118774

Epoch: 5| Step: 7
Training loss: 2.7716522216796875
Validation loss: 2.4646238634983697

Epoch: 5| Step: 8
Training loss: 2.3343448638916016
Validation loss: 2.462081183989843

Epoch: 5| Step: 9
Training loss: 2.792365312576294
Validation loss: 2.4592977662881217

Epoch: 5| Step: 10
Training loss: 2.442203998565674
Validation loss: 2.458366274833679

Epoch: 5| Step: 11
Training loss: 3.249687671661377
Validation loss: 2.45579727490743

Epoch: 47| Step: 0
Training loss: 1.8986682891845703
Validation loss: 2.452307422955831

Epoch: 5| Step: 1
Training loss: 3.0308191776275635
Validation loss: 2.4507309099038443

Epoch: 5| Step: 2
Training loss: 2.6163060665130615
Validation loss: 2.4469295144081116

Epoch: 5| Step: 3
Training loss: 2.5621604919433594
Validation loss: 2.444062133630117

Epoch: 5| Step: 4
Training loss: 2.869645357131958
Validation loss: 2.4418276250362396

Epoch: 5| Step: 5
Training loss: 2.3118910789489746
Validation loss: 2.4401532212893167

Epoch: 5| Step: 6
Training loss: 2.9446640014648438
Validation loss: 2.4329084058602652

Epoch: 5| Step: 7
Training loss: 2.427241563796997
Validation loss: 2.4299056281646094

Epoch: 5| Step: 8
Training loss: 2.8557140827178955
Validation loss: 2.427241096893946

Epoch: 5| Step: 9
Training loss: 2.9100356101989746
Validation loss: 2.4256917536258698

Epoch: 5| Step: 10
Training loss: 2.502119779586792
Validation loss: 2.4218631585439048

Epoch: 5| Step: 11
Training loss: 2.430903434753418
Validation loss: 2.4177474677562714

Epoch: 48| Step: 0
Training loss: 2.8128578662872314
Validation loss: 2.415256083011627

Epoch: 5| Step: 1
Training loss: 3.008446216583252
Validation loss: 2.4174212912718454

Epoch: 5| Step: 2
Training loss: 3.138505697250366
Validation loss: 2.4129083255926767

Epoch: 5| Step: 3
Training loss: 2.8551056385040283
Validation loss: 2.409839560588201

Epoch: 5| Step: 4
Training loss: 2.4426987171173096
Validation loss: 2.4047207732995353

Epoch: 5| Step: 5
Training loss: 2.0412259101867676
Validation loss: 2.404081165790558

Epoch: 5| Step: 6
Training loss: 2.728959560394287
Validation loss: 2.4034770925839744

Epoch: 5| Step: 7
Training loss: 2.346574544906616
Validation loss: 2.4021479984124503

Epoch: 5| Step: 8
Training loss: 2.15820050239563
Validation loss: 2.399687707424164

Epoch: 5| Step: 9
Training loss: 2.5804643630981445
Validation loss: 2.3966505428155265

Epoch: 5| Step: 10
Training loss: 2.3078994750976562
Validation loss: 2.3959460953871408

Epoch: 5| Step: 11
Training loss: 3.2848336696624756
Validation loss: 2.393189698457718

Epoch: 49| Step: 0
Training loss: 2.5416817665100098
Validation loss: 2.395325154066086

Epoch: 5| Step: 1
Training loss: 2.4173080921173096
Validation loss: 2.393145670493444

Epoch: 5| Step: 2
Training loss: 2.8207335472106934
Validation loss: 2.3921153843402863

Epoch: 5| Step: 3
Training loss: 2.1570992469787598
Validation loss: 2.3909279108047485

Epoch: 5| Step: 4
Training loss: 2.659142017364502
Validation loss: 2.388855462272962

Epoch: 5| Step: 5
Training loss: 2.9249143600463867
Validation loss: 2.3865602215131125

Epoch: 5| Step: 6
Training loss: 2.5210278034210205
Validation loss: 2.383958170811335

Epoch: 5| Step: 7
Training loss: 2.633687973022461
Validation loss: 2.3789948423703513

Epoch: 5| Step: 8
Training loss: 2.486358404159546
Validation loss: 2.37661005059878

Epoch: 5| Step: 9
Training loss: 2.5677454471588135
Validation loss: 2.37270217637221

Epoch: 5| Step: 10
Training loss: 2.5450165271759033
Validation loss: 2.36964883406957

Epoch: 5| Step: 11
Training loss: 2.0328705310821533
Validation loss: 2.366751968860626

Epoch: 50| Step: 0
Training loss: 2.4204955101013184
Validation loss: 2.3636930684248605

Epoch: 5| Step: 1
Training loss: 2.726823091506958
Validation loss: 2.3593774338563285

Epoch: 5| Step: 2
Training loss: 2.5972647666931152
Validation loss: 2.357240150372187

Epoch: 5| Step: 3
Training loss: 2.4504787921905518
Validation loss: 2.3522840440273285

Epoch: 5| Step: 4
Training loss: 3.2339987754821777
Validation loss: 2.351266920566559

Epoch: 5| Step: 5
Training loss: 2.4072580337524414
Validation loss: 2.348742206891378

Epoch: 5| Step: 6
Training loss: 2.6790249347686768
Validation loss: 2.345799595117569

Epoch: 5| Step: 7
Training loss: 1.958085060119629
Validation loss: 2.3400514721870422

Epoch: 5| Step: 8
Training loss: 3.213113784790039
Validation loss: 2.340568780899048

Epoch: 5| Step: 9
Training loss: 1.8856149911880493
Validation loss: 2.337305267651876

Epoch: 5| Step: 10
Training loss: 2.1285560131073
Validation loss: 2.341655413309733

Epoch: 5| Step: 11
Training loss: 2.6687841415405273
Validation loss: 2.3491284449895224

Epoch: 51| Step: 0
Training loss: 2.9123454093933105
Validation loss: 2.3855348378419876

Epoch: 5| Step: 1
Training loss: 2.678581476211548
Validation loss: 2.3846755822499595

Epoch: 5| Step: 2
Training loss: 2.0781521797180176
Validation loss: 2.372958188255628

Epoch: 5| Step: 3
Training loss: 2.1236367225646973
Validation loss: 2.349156156182289

Epoch: 5| Step: 4
Training loss: 2.808488368988037
Validation loss: 2.3404418925444284

Epoch: 5| Step: 5
Training loss: 2.5185132026672363
Validation loss: 2.339491297801336

Epoch: 5| Step: 6
Training loss: 2.6580018997192383
Validation loss: 2.342003027598063

Epoch: 5| Step: 7
Training loss: 2.9338009357452393
Validation loss: 2.3448826471964517

Epoch: 5| Step: 8
Training loss: 1.9075849056243896
Validation loss: 2.3419275085131326

Epoch: 5| Step: 9
Training loss: 2.498845338821411
Validation loss: 2.340319881836573

Epoch: 5| Step: 10
Training loss: 2.848301649093628
Validation loss: 2.3402841289838157

Epoch: 5| Step: 11
Training loss: 2.250612735748291
Validation loss: 2.337622046470642

Epoch: 52| Step: 0
Training loss: 2.455472230911255
Validation loss: 2.3357507785161338

Epoch: 5| Step: 1
Training loss: 2.2914955615997314
Validation loss: 2.334812179207802

Epoch: 5| Step: 2
Training loss: 2.445568561553955
Validation loss: 2.331956853469213

Epoch: 5| Step: 3
Training loss: 2.2246956825256348
Validation loss: 2.3284541169802346

Epoch: 5| Step: 4
Training loss: 2.6546812057495117
Validation loss: 2.3244008819262185

Epoch: 5| Step: 5
Training loss: 2.7386474609375
Validation loss: 2.3236752251784005

Epoch: 5| Step: 6
Training loss: 2.6460609436035156
Validation loss: 2.320294310649236

Epoch: 5| Step: 7
Training loss: 2.2973010540008545
Validation loss: 2.31706311305364

Epoch: 5| Step: 8
Training loss: 2.566765308380127
Validation loss: 2.310502211252848

Epoch: 5| Step: 9
Training loss: 2.5754950046539307
Validation loss: 2.3072449465592704

Epoch: 5| Step: 10
Training loss: 2.5295748710632324
Validation loss: 2.303814028700193

Epoch: 5| Step: 11
Training loss: 2.3225207328796387
Validation loss: 2.29910010099411

Epoch: 53| Step: 0
Training loss: 2.0625765323638916
Validation loss: 2.300312434633573

Epoch: 5| Step: 1
Training loss: 2.517277240753174
Validation loss: 2.3040613581736884

Epoch: 5| Step: 2
Training loss: 2.937981128692627
Validation loss: 2.310527980327606

Epoch: 5| Step: 3
Training loss: 2.101902484893799
Validation loss: 2.304800550142924

Epoch: 5| Step: 4
Training loss: 2.263848066329956
Validation loss: 2.2991679161787033

Epoch: 5| Step: 5
Training loss: 2.634751081466675
Validation loss: 2.2857720057169595

Epoch: 5| Step: 6
Training loss: 2.619584560394287
Validation loss: 2.277123595277468

Epoch: 5| Step: 7
Training loss: 2.2732338905334473
Validation loss: 2.27804301182429

Epoch: 5| Step: 8
Training loss: 2.6075809001922607
Validation loss: 2.2800715068976083

Epoch: 5| Step: 9
Training loss: 2.72298264503479
Validation loss: 2.2802788515885672

Epoch: 5| Step: 10
Training loss: 2.2896807193756104
Validation loss: 2.2840538322925568

Epoch: 5| Step: 11
Training loss: 2.858299970626831
Validation loss: 2.285188525915146

Epoch: 54| Step: 0
Training loss: 2.4900238513946533
Validation loss: 2.2770367165406546

Epoch: 5| Step: 1
Training loss: 2.6435935497283936
Validation loss: 2.274001215895017

Epoch: 5| Step: 2
Training loss: 2.45444393157959
Validation loss: 2.2701283196608224

Epoch: 5| Step: 3
Training loss: 2.3427116870880127
Validation loss: 2.2666720847288766

Epoch: 5| Step: 4
Training loss: 2.126812219619751
Validation loss: 2.263528739412626

Epoch: 5| Step: 5
Training loss: 2.6994805335998535
Validation loss: 2.257774313290914

Epoch: 5| Step: 6
Training loss: 2.097994089126587
Validation loss: 2.2561983118454614

Epoch: 5| Step: 7
Training loss: 2.7796859741210938
Validation loss: 2.254691710074743

Epoch: 5| Step: 8
Training loss: 2.1778404712677
Validation loss: 2.251144846280416

Epoch: 5| Step: 9
Training loss: 2.308156967163086
Validation loss: 2.250348538160324

Epoch: 5| Step: 10
Training loss: 2.5184972286224365
Validation loss: 2.245343178510666

Epoch: 5| Step: 11
Training loss: 2.5739269256591797
Validation loss: 2.242561767498652

Epoch: 55| Step: 0
Training loss: 2.9214353561401367
Validation loss: 2.238698422908783

Epoch: 5| Step: 1
Training loss: 2.092611789703369
Validation loss: 2.2333632012208304

Epoch: 5| Step: 2
Training loss: 2.105203151702881
Validation loss: 2.2333228091398873

Epoch: 5| Step: 3
Training loss: 2.440186023712158
Validation loss: 2.2397764921188354

Epoch: 5| Step: 4
Training loss: 2.0147242546081543
Validation loss: 2.2400060991446176

Epoch: 5| Step: 5
Training loss: 2.746027708053589
Validation loss: 2.2358822375535965

Epoch: 5| Step: 6
Training loss: 2.6068837642669678
Validation loss: 2.223222533861796

Epoch: 5| Step: 7
Training loss: 2.472982406616211
Validation loss: 2.2164993286132812

Epoch: 5| Step: 8
Training loss: 2.5497982501983643
Validation loss: 2.216419219970703

Epoch: 5| Step: 9
Training loss: 2.1048779487609863
Validation loss: 2.2188566277424493

Epoch: 5| Step: 10
Training loss: 2.4993717670440674
Validation loss: 2.2205910235643387

Epoch: 5| Step: 11
Training loss: 1.5443345308303833
Validation loss: 2.2180562118689218

Epoch: 56| Step: 0
Training loss: 2.381110668182373
Validation loss: 2.2194683055082955

Epoch: 5| Step: 1
Training loss: 2.888611078262329
Validation loss: 2.219886993368467

Epoch: 5| Step: 2
Training loss: 2.5632424354553223
Validation loss: 2.221968948841095

Epoch: 5| Step: 3
Training loss: 2.029276132583618
Validation loss: 2.2211458732684455

Epoch: 5| Step: 4
Training loss: 2.2366085052490234
Validation loss: 2.2197172145048776

Epoch: 5| Step: 5
Training loss: 2.1955060958862305
Validation loss: 2.2178876847028732

Epoch: 5| Step: 6
Training loss: 2.0285987854003906
Validation loss: 2.216297671198845

Epoch: 5| Step: 7
Training loss: 2.157484531402588
Validation loss: 2.2132443487644196

Epoch: 5| Step: 8
Training loss: 2.4054489135742188
Validation loss: 2.2103421886761985

Epoch: 5| Step: 9
Training loss: 2.688476085662842
Validation loss: 2.2108341505130134

Epoch: 5| Step: 10
Training loss: 2.4046807289123535
Validation loss: 2.2050708880027137

Epoch: 5| Step: 11
Training loss: 3.231529712677002
Validation loss: 2.204269821445147

Epoch: 57| Step: 0
Training loss: 2.0536413192749023
Validation loss: 2.201271558801333

Epoch: 5| Step: 1
Training loss: 2.480883836746216
Validation loss: 2.199395681420962

Epoch: 5| Step: 2
Training loss: 2.6900687217712402
Validation loss: 2.1936478515466056

Epoch: 5| Step: 3
Training loss: 2.615615129470825
Validation loss: 2.1915393670399985

Epoch: 5| Step: 4
Training loss: 1.764264702796936
Validation loss: 2.19158743818601

Epoch: 5| Step: 5
Training loss: 2.4149680137634277
Validation loss: 2.186062435309092

Epoch: 5| Step: 6
Training loss: 2.2290666103363037
Validation loss: 2.1843978265921273

Epoch: 5| Step: 7
Training loss: 2.676378011703491
Validation loss: 2.184117799003919

Epoch: 5| Step: 8
Training loss: 2.5816810131073
Validation loss: 2.1796647856632867

Epoch: 5| Step: 9
Training loss: 2.618525505065918
Validation loss: 2.176598866780599

Epoch: 5| Step: 10
Training loss: 1.8936208486557007
Validation loss: 2.1729699124892554

Epoch: 5| Step: 11
Training loss: 1.7935839891433716
Validation loss: 2.170164172848066

Epoch: 58| Step: 0
Training loss: 2.229097366333008
Validation loss: 2.16994771361351

Epoch: 5| Step: 1
Training loss: 2.596752405166626
Validation loss: 2.1713397999604545

Epoch: 5| Step: 2
Training loss: 2.322662591934204
Validation loss: 2.1701022386550903

Epoch: 5| Step: 3
Training loss: 2.3975067138671875
Validation loss: 2.169951856136322

Epoch: 5| Step: 4
Training loss: 1.744594931602478
Validation loss: 2.169929563999176

Epoch: 5| Step: 5
Training loss: 2.547868013381958
Validation loss: 2.1699715157349906

Epoch: 5| Step: 6
Training loss: 2.1136767864227295
Validation loss: 2.1689224541187286

Epoch: 5| Step: 7
Training loss: 2.2374565601348877
Validation loss: 2.1665112425883613

Epoch: 5| Step: 8
Training loss: 1.8958991765975952
Validation loss: 2.165231058994929

Epoch: 5| Step: 9
Training loss: 2.8719310760498047
Validation loss: 2.164135073622068

Epoch: 5| Step: 10
Training loss: 2.5860366821289062
Validation loss: 2.1617864668369293

Epoch: 5| Step: 11
Training loss: 3.3644556999206543
Validation loss: 2.159441908200582

Epoch: 59| Step: 0
Training loss: 2.0841152667999268
Validation loss: 2.1536884854237237

Epoch: 5| Step: 1
Training loss: 2.6232428550720215
Validation loss: 2.154306173324585

Epoch: 5| Step: 2
Training loss: 1.86785888671875
Validation loss: 2.1539741456508636

Epoch: 5| Step: 3
Training loss: 2.2231669425964355
Validation loss: 2.1620604395866394

Epoch: 5| Step: 4
Training loss: 2.6312294006347656
Validation loss: 2.163175036509832

Epoch: 5| Step: 5
Training loss: 2.4467060565948486
Validation loss: 2.1671567857265472

Epoch: 5| Step: 6
Training loss: 2.612334966659546
Validation loss: 2.1660930812358856

Epoch: 5| Step: 7
Training loss: 1.8491185903549194
Validation loss: 2.164487694700559

Epoch: 5| Step: 8
Training loss: 1.977717638015747
Validation loss: 2.1507653991381326

Epoch: 5| Step: 9
Training loss: 2.272911548614502
Validation loss: 2.1476166943709054

Epoch: 5| Step: 10
Training loss: 2.9374136924743652
Validation loss: 2.143061896165212

Epoch: 5| Step: 11
Training loss: 2.8249034881591797
Validation loss: 2.1431963791449866

Epoch: 60| Step: 0
Training loss: 2.500769853591919
Validation loss: 2.149143546819687

Epoch: 5| Step: 1
Training loss: 2.026578187942505
Validation loss: 2.149561951557795

Epoch: 5| Step: 2
Training loss: 2.8594813346862793
Validation loss: 2.150659124056498

Epoch: 5| Step: 3
Training loss: 2.7921175956726074
Validation loss: 2.149254853526751

Epoch: 5| Step: 4
Training loss: 2.037550449371338
Validation loss: 2.149505093693733

Epoch: 5| Step: 5
Training loss: 2.9173996448516846
Validation loss: 2.14828522503376

Epoch: 5| Step: 6
Training loss: 2.291516065597534
Validation loss: 2.1459885090589523

Epoch: 5| Step: 7
Training loss: 2.071213960647583
Validation loss: 2.1417949348688126

Epoch: 5| Step: 8
Training loss: 1.6162912845611572
Validation loss: 2.143016993999481

Epoch: 5| Step: 9
Training loss: 2.510962963104248
Validation loss: 2.137464558084806

Epoch: 5| Step: 10
Training loss: 1.7131716012954712
Validation loss: 2.1372174123922982

Epoch: 5| Step: 11
Training loss: 2.9910926818847656
Validation loss: 2.1320641934871674

Epoch: 61| Step: 0
Training loss: 2.6097118854522705
Validation loss: 2.146525740623474

Epoch: 5| Step: 1
Training loss: 1.3461049795150757
Validation loss: 2.1799103220303855

Epoch: 5| Step: 2
Training loss: 2.430772066116333
Validation loss: 2.191503038009008

Epoch: 5| Step: 3
Training loss: 2.9266622066497803
Validation loss: 2.195164700349172

Epoch: 5| Step: 4
Training loss: 2.181324005126953
Validation loss: 2.1532007853190103

Epoch: 5| Step: 5
Training loss: 2.197746992111206
Validation loss: 2.12487863500913

Epoch: 5| Step: 6
Training loss: 1.9686599969863892
Validation loss: 2.1159087171157203

Epoch: 5| Step: 7
Training loss: 1.9388008117675781
Validation loss: 2.1158193002144494

Epoch: 5| Step: 8
Training loss: 1.9270473718643188
Validation loss: 2.118200898170471

Epoch: 5| Step: 9
Training loss: 2.602816581726074
Validation loss: 2.129069074988365

Epoch: 5| Step: 10
Training loss: 3.238948106765747
Validation loss: 2.1292721033096313

Epoch: 5| Step: 11
Training loss: 3.1606364250183105
Validation loss: 2.13145849108696

Epoch: 62| Step: 0
Training loss: 2.141023635864258
Validation loss: 2.12625444928805

Epoch: 5| Step: 1
Training loss: 2.188668727874756
Validation loss: 2.1293557584285736

Epoch: 5| Step: 2
Training loss: 2.3565688133239746
Validation loss: 2.1293029884497323

Epoch: 5| Step: 3
Training loss: 2.26023006439209
Validation loss: 2.1297290523846946

Epoch: 5| Step: 4
Training loss: 2.4228522777557373
Validation loss: 2.128037318587303

Epoch: 5| Step: 5
Training loss: 2.5754752159118652
Validation loss: 2.125633622209231

Epoch: 5| Step: 6
Training loss: 2.3333351612091064
Validation loss: 2.122528667251269

Epoch: 5| Step: 7
Training loss: 2.324493408203125
Validation loss: 2.1247232109308243

Epoch: 5| Step: 8
Training loss: 2.5790252685546875
Validation loss: 2.117878476778666

Epoch: 5| Step: 9
Training loss: 1.9303436279296875
Validation loss: 2.1167063961426416

Epoch: 5| Step: 10
Training loss: 2.3115081787109375
Validation loss: 2.1121940513451896

Epoch: 5| Step: 11
Training loss: 2.065917491912842
Validation loss: 2.104019125302633

Epoch: 63| Step: 0
Training loss: 2.3650031089782715
Validation loss: 2.098892162243525

Epoch: 5| Step: 1
Training loss: 2.3449339866638184
Validation loss: 2.1034080237150192

Epoch: 5| Step: 2
Training loss: 2.352965831756592
Validation loss: 2.109555577238401

Epoch: 5| Step: 3
Training loss: 2.6530823707580566
Validation loss: 2.112549831469854

Epoch: 5| Step: 4
Training loss: 1.9474194049835205
Validation loss: 2.107592542966207

Epoch: 5| Step: 5
Training loss: 2.4633724689483643
Validation loss: 2.105918824672699

Epoch: 5| Step: 6
Training loss: 2.3533527851104736
Validation loss: 2.1054412523905435

Epoch: 5| Step: 7
Training loss: 2.1248579025268555
Validation loss: 2.098497981826464

Epoch: 5| Step: 8
Training loss: 2.4065499305725098
Validation loss: 2.095610568920771

Epoch: 5| Step: 9
Training loss: 2.3757266998291016
Validation loss: 2.0850216497977576

Epoch: 5| Step: 10
Training loss: 2.1527676582336426
Validation loss: 2.089540476600329

Epoch: 5| Step: 11
Training loss: 0.2983659505844116
Validation loss: 2.08721861243248

Epoch: 64| Step: 0
Training loss: 2.631038188934326
Validation loss: 2.0862686038017273

Epoch: 5| Step: 1
Training loss: 2.6822350025177
Validation loss: 2.0871980786323547

Epoch: 5| Step: 2
Training loss: 2.050262451171875
Validation loss: 2.086868276198705

Epoch: 5| Step: 3
Training loss: 1.7245842218399048
Validation loss: 2.0863687048355737

Epoch: 5| Step: 4
Training loss: 2.4295694828033447
Validation loss: 2.086333140730858

Epoch: 5| Step: 5
Training loss: 2.979435682296753
Validation loss: 2.0828739603360495

Epoch: 5| Step: 6
Training loss: 2.325282096862793
Validation loss: 2.0758332262436547

Epoch: 5| Step: 7
Training loss: 2.1689248085021973
Validation loss: 2.078474616010984

Epoch: 5| Step: 8
Training loss: 2.3945841789245605
Validation loss: 2.0729062408208847

Epoch: 5| Step: 9
Training loss: 1.963855504989624
Validation loss: 2.074839929739634

Epoch: 5| Step: 10
Training loss: 1.7497336864471436
Validation loss: 2.073413466413816

Epoch: 5| Step: 11
Training loss: 1.330080270767212
Validation loss: 2.0736299008131027

Epoch: 65| Step: 0
Training loss: 2.2315688133239746
Validation loss: 2.0750041951735816

Epoch: 5| Step: 1
Training loss: 2.4803264141082764
Validation loss: 2.0804560830195746

Epoch: 5| Step: 2
Training loss: 1.598787546157837
Validation loss: 2.0789178758859634

Epoch: 5| Step: 3
Training loss: 2.571460247039795
Validation loss: 2.099742040038109

Epoch: 5| Step: 4
Training loss: 2.9496941566467285
Validation loss: 2.1142962872982025

Epoch: 5| Step: 5
Training loss: 2.337076425552368
Validation loss: 2.0999472041924796

Epoch: 5| Step: 6
Training loss: 1.9753659963607788
Validation loss: 2.0776080091794333

Epoch: 5| Step: 7
Training loss: 2.271545886993408
Validation loss: 2.0643856525421143

Epoch: 5| Step: 8
Training loss: 2.7242584228515625
Validation loss: 2.0636269748210907

Epoch: 5| Step: 9
Training loss: 2.070403575897217
Validation loss: 2.06766606370608

Epoch: 5| Step: 10
Training loss: 1.7341248989105225
Validation loss: 2.0711418439944587

Epoch: 5| Step: 11
Training loss: 2.1494638919830322
Validation loss: 2.0687504559755325

Epoch: 66| Step: 0
Training loss: 2.2524123191833496
Validation loss: 2.0725039492050805

Epoch: 5| Step: 1
Training loss: 2.150308132171631
Validation loss: 2.0729630390803018

Epoch: 5| Step: 2
Training loss: 2.4355416297912598
Validation loss: 2.077964633703232

Epoch: 5| Step: 3
Training loss: 2.671661376953125
Validation loss: 2.0754359662532806

Epoch: 5| Step: 4
Training loss: 2.5458037853240967
Validation loss: 2.0725365728139877

Epoch: 5| Step: 5
Training loss: 1.8723680973052979
Validation loss: 2.072517270843188

Epoch: 5| Step: 6
Training loss: 2.38859486579895
Validation loss: 2.068751722574234

Epoch: 5| Step: 7
Training loss: 2.3124706745147705
Validation loss: 2.0682426442702613

Epoch: 5| Step: 8
Training loss: 2.012871742248535
Validation loss: 2.0668172587951026

Epoch: 5| Step: 9
Training loss: 2.230534315109253
Validation loss: 2.069102277358373

Epoch: 5| Step: 10
Training loss: 2.2388341426849365
Validation loss: 2.0656478106975555

Epoch: 5| Step: 11
Training loss: 1.3289803266525269
Validation loss: 2.0624358703692756

Epoch: 67| Step: 0
Training loss: 2.0605039596557617
Validation loss: 2.056389664610227

Epoch: 5| Step: 1
Training loss: 1.943185806274414
Validation loss: 2.055053244034449

Epoch: 5| Step: 2
Training loss: 2.0355160236358643
Validation loss: 2.049724966287613

Epoch: 5| Step: 3
Training loss: 2.178182601928711
Validation loss: 2.054278994599978

Epoch: 5| Step: 4
Training loss: 2.4545786380767822
Validation loss: 2.0627244214216867

Epoch: 5| Step: 5
Training loss: 2.2450108528137207
Validation loss: 2.0787822107474008

Epoch: 5| Step: 6
Training loss: 3.075214147567749
Validation loss: 2.1015153378248215

Epoch: 5| Step: 7
Training loss: 2.613638401031494
Validation loss: 2.0797713100910187

Epoch: 5| Step: 8
Training loss: 1.7948545217514038
Validation loss: 2.071693708499273

Epoch: 5| Step: 9
Training loss: 1.8607673645019531
Validation loss: 2.0667067021131516

Epoch: 5| Step: 10
Training loss: 2.5914173126220703
Validation loss: 2.061610092719396

Epoch: 5| Step: 11
Training loss: 2.7256011962890625
Validation loss: 2.0527098874251046

Epoch: 68| Step: 0
Training loss: 2.302792549133301
Validation loss: 2.04949056605498

Epoch: 5| Step: 1
Training loss: 2.03423810005188
Validation loss: 2.0485458274682364

Epoch: 5| Step: 2
Training loss: 2.0373427867889404
Validation loss: 2.0541958858569465

Epoch: 5| Step: 3
Training loss: 2.8305609226226807
Validation loss: 2.051830301682154

Epoch: 5| Step: 4
Training loss: 1.926288366317749
Validation loss: 2.05367673933506

Epoch: 5| Step: 5
Training loss: 2.520907163619995
Validation loss: 2.055584346254667

Epoch: 5| Step: 6
Training loss: 1.9649614095687866
Validation loss: 2.0576519270737967

Epoch: 5| Step: 7
Training loss: 2.127194881439209
Validation loss: 2.0566457360982895

Epoch: 5| Step: 8
Training loss: 2.3651907444000244
Validation loss: 2.060540090004603

Epoch: 5| Step: 9
Training loss: 2.406982421875
Validation loss: 2.064715246359507

Epoch: 5| Step: 10
Training loss: 2.2995383739471436
Validation loss: 2.057146673401197

Epoch: 5| Step: 11
Training loss: 1.4314544200897217
Validation loss: 2.0591552754243216

Epoch: 69| Step: 0
Training loss: 2.284146785736084
Validation loss: 2.056275690595309

Epoch: 5| Step: 1
Training loss: 2.0072641372680664
Validation loss: 2.0554951330025992

Epoch: 5| Step: 2
Training loss: 2.624525785446167
Validation loss: 2.049140453338623

Epoch: 5| Step: 3
Training loss: 1.7685807943344116
Validation loss: 2.0508205890655518

Epoch: 5| Step: 4
Training loss: 2.208055019378662
Validation loss: 2.051031465331713

Epoch: 5| Step: 5
Training loss: 2.157604217529297
Validation loss: 2.0515299091736474

Epoch: 5| Step: 6
Training loss: 1.9044843912124634
Validation loss: 2.046290715535482

Epoch: 5| Step: 7
Training loss: 2.314025402069092
Validation loss: 2.0436015874147415

Epoch: 5| Step: 8
Training loss: 2.6091384887695312
Validation loss: 2.0426463236411414

Epoch: 5| Step: 9
Training loss: 2.4448883533477783
Validation loss: 2.0386155545711517

Epoch: 5| Step: 10
Training loss: 2.0952930450439453
Validation loss: 2.03382670879364

Epoch: 5| Step: 11
Training loss: 3.0143604278564453
Validation loss: 2.036587506532669

Epoch: 70| Step: 0
Training loss: 2.460986852645874
Validation loss: 2.0339986930290856

Epoch: 5| Step: 1
Training loss: 2.3083767890930176
Validation loss: 2.0305665085713067

Epoch: 5| Step: 2
Training loss: 2.3890724182128906
Validation loss: 2.039900556206703

Epoch: 5| Step: 3
Training loss: 2.1573574542999268
Validation loss: 2.049171487490336

Epoch: 5| Step: 4
Training loss: 2.0624887943267822
Validation loss: 2.0434613625208535

Epoch: 5| Step: 5
Training loss: 2.056642770767212
Validation loss: 2.0391882161299386

Epoch: 5| Step: 6
Training loss: 1.8040199279785156
Validation loss: 2.031835729877154

Epoch: 5| Step: 7
Training loss: 1.7202765941619873
Validation loss: 2.036045119166374

Epoch: 5| Step: 8
Training loss: 2.3033900260925293
Validation loss: 2.031154935558637

Epoch: 5| Step: 9
Training loss: 2.32338285446167
Validation loss: 2.0293791194756827

Epoch: 5| Step: 10
Training loss: 2.706216335296631
Validation loss: 2.03065225481987

Epoch: 5| Step: 11
Training loss: 3.4431891441345215
Validation loss: 2.0210868269205093

Epoch: 71| Step: 0
Training loss: 2.2850985527038574
Validation loss: 2.0257488787174225

Epoch: 5| Step: 1
Training loss: 1.9194238185882568
Validation loss: 2.028954192996025

Epoch: 5| Step: 2
Training loss: 2.178717851638794
Validation loss: 2.037706514199575

Epoch: 5| Step: 3
Training loss: 1.8830311298370361
Validation loss: 2.0398750801881156

Epoch: 5| Step: 4
Training loss: 2.2246203422546387
Validation loss: 2.0359752227862677

Epoch: 5| Step: 5
Training loss: 2.6316211223602295
Validation loss: 2.0383643408616385

Epoch: 5| Step: 6
Training loss: 2.688062906265259
Validation loss: 2.0402319629987082

Epoch: 5| Step: 7
Training loss: 2.011565923690796
Validation loss: 2.0365926722685495

Epoch: 5| Step: 8
Training loss: 2.3975369930267334
Validation loss: 2.0391053209702172

Epoch: 5| Step: 9
Training loss: 1.8440519571304321
Validation loss: 2.041128938396772

Epoch: 5| Step: 10
Training loss: 2.350693702697754
Validation loss: 2.0323452750841775

Epoch: 5| Step: 11
Training loss: 2.19384503364563
Validation loss: 2.0354784429073334

Epoch: 72| Step: 0
Training loss: 2.38853120803833
Validation loss: 2.0297691424687705

Epoch: 5| Step: 1
Training loss: 2.442286968231201
Validation loss: 2.0259004334608712

Epoch: 5| Step: 2
Training loss: 1.7631829977035522
Validation loss: 2.0223112801710763

Epoch: 5| Step: 3
Training loss: 1.894749641418457
Validation loss: 2.0241589695215225

Epoch: 5| Step: 4
Training loss: 1.9558279514312744
Validation loss: 2.033852204680443

Epoch: 5| Step: 5
Training loss: 2.6577882766723633
Validation loss: 2.050230165322622

Epoch: 5| Step: 6
Training loss: 1.7745392322540283
Validation loss: 2.0723659694194794

Epoch: 5| Step: 7
Training loss: 1.9596216678619385
Validation loss: 2.1013491799434028

Epoch: 5| Step: 8
Training loss: 2.930908679962158
Validation loss: 2.143739491701126

Epoch: 5| Step: 9
Training loss: 3.251682996749878
Validation loss: 2.179715394973755

Epoch: 5| Step: 10
Training loss: 2.0416181087493896
Validation loss: 2.1679131040970483

Epoch: 5| Step: 11
Training loss: 2.6073644161224365
Validation loss: 2.1088173339764276

Epoch: 73| Step: 0
Training loss: 2.138002872467041
Validation loss: 2.0479670067628226

Epoch: 5| Step: 1
Training loss: 1.904014229774475
Validation loss: 2.024227663874626

Epoch: 5| Step: 2
Training loss: 2.350128650665283
Validation loss: 2.0244184682766595

Epoch: 5| Step: 3
Training loss: 2.2520060539245605
Validation loss: 2.0506400962670646

Epoch: 5| Step: 4
Training loss: 2.013953924179077
Validation loss: 2.0735221405824027

Epoch: 5| Step: 5
Training loss: 2.5757007598876953
Validation loss: 2.0909718722105026

Epoch: 5| Step: 6
Training loss: 2.3667044639587402
Validation loss: 2.1161728898684182

Epoch: 5| Step: 7
Training loss: 2.342432975769043
Validation loss: 2.1440578599770865

Epoch: 5| Step: 8
Training loss: 2.2545008659362793
Validation loss: 2.149900585412979

Epoch: 5| Step: 9
Training loss: 2.464843273162842
Validation loss: 2.1613117704788842

Epoch: 5| Step: 10
Training loss: 2.6656007766723633
Validation loss: 2.143747548262278

Epoch: 5| Step: 11
Training loss: 1.5086181163787842
Validation loss: 2.130003328124682

Epoch: 74| Step: 0
Training loss: 2.2390055656433105
Validation loss: 2.118713011344274

Epoch: 5| Step: 1
Training loss: 2.3144443035125732
Validation loss: 2.1059177269538245

Epoch: 5| Step: 2
Training loss: 2.4934799671173096
Validation loss: 2.0876715928316116

Epoch: 5| Step: 3
Training loss: 2.484649181365967
Validation loss: 2.079807847738266

Epoch: 5| Step: 4
Training loss: 1.9084594249725342
Validation loss: 2.070342098673185

Epoch: 5| Step: 5
Training loss: 2.1966593265533447
Validation loss: 2.0693614532550177

Epoch: 5| Step: 6
Training loss: 2.080214738845825
Validation loss: 2.064558436473211

Epoch: 5| Step: 7
Training loss: 2.4680347442626953
Validation loss: 2.060666263103485

Epoch: 5| Step: 8
Training loss: 2.2276947498321533
Validation loss: 2.0472448070844016

Epoch: 5| Step: 9
Training loss: 1.8801109790802002
Validation loss: 2.0442401419083276

Epoch: 5| Step: 10
Training loss: 2.5085067749023438
Validation loss: 2.040020381410917

Epoch: 5| Step: 11
Training loss: 2.6139028072357178
Validation loss: 2.0405066261688867

Epoch: 75| Step: 0
Training loss: 2.5145463943481445
Validation loss: 2.0369818260272345

Epoch: 5| Step: 1
Training loss: 3.010500907897949
Validation loss: 2.044309079647064

Epoch: 5| Step: 2
Training loss: 1.917544960975647
Validation loss: 2.0522300402323403

Epoch: 5| Step: 3
Training loss: 1.7063192129135132
Validation loss: 2.0511355300744376

Epoch: 5| Step: 4
Training loss: 2.0928211212158203
Validation loss: 2.0626168151696525

Epoch: 5| Step: 5
Training loss: 1.9737831354141235
Validation loss: 2.06253453095754

Epoch: 5| Step: 6
Training loss: 1.6084064245224
Validation loss: 2.067410488923391

Epoch: 5| Step: 7
Training loss: 2.8361191749572754
Validation loss: 2.065247878432274

Epoch: 5| Step: 8
Training loss: 3.315641403198242
Validation loss: 2.0546030749877295

Epoch: 5| Step: 9
Training loss: 1.7478107213974
Validation loss: 2.0552434225877128

Epoch: 5| Step: 10
Training loss: 1.7709579467773438
Validation loss: 2.0356240471204123

Epoch: 5| Step: 11
Training loss: 2.6872568130493164
Validation loss: 2.0276312977075577

Epoch: 76| Step: 0
Training loss: 2.0454001426696777
Validation loss: 2.0236231684684753

Epoch: 5| Step: 1
Training loss: 2.439879894256592
Validation loss: 2.0308684955040612

Epoch: 5| Step: 2
Training loss: 2.6398510932922363
Validation loss: 2.0303612053394318

Epoch: 5| Step: 3
Training loss: 2.225480318069458
Validation loss: 2.0322513530651727

Epoch: 5| Step: 4
Training loss: 1.757531762123108
Validation loss: 2.0317749977111816

Epoch: 5| Step: 5
Training loss: 1.8848673105239868
Validation loss: 2.0340069085359573

Epoch: 5| Step: 6
Training loss: 2.9129786491394043
Validation loss: 2.034979219237963

Epoch: 5| Step: 7
Training loss: 2.0377416610717773
Validation loss: 2.041392927368482

Epoch: 5| Step: 8
Training loss: 2.3791513442993164
Validation loss: 2.033006325364113

Epoch: 5| Step: 9
Training loss: 2.155745267868042
Validation loss: 2.030745322505633

Epoch: 5| Step: 10
Training loss: 1.7460527420043945
Validation loss: 2.029481609662374

Epoch: 5| Step: 11
Training loss: 2.7955195903778076
Validation loss: 2.024777039885521

Epoch: 77| Step: 0
Training loss: 1.979744553565979
Validation loss: 2.0283124993244805

Epoch: 5| Step: 1
Training loss: 2.1827197074890137
Validation loss: 2.026170944174131

Epoch: 5| Step: 2
Training loss: 2.2593741416931152
Validation loss: 2.019729415575663

Epoch: 5| Step: 3
Training loss: 2.301081895828247
Validation loss: 2.0178536822398505

Epoch: 5| Step: 4
Training loss: 2.2422237396240234
Validation loss: 2.0141355097293854

Epoch: 5| Step: 5
Training loss: 2.4103951454162598
Validation loss: 2.0150621285041175

Epoch: 5| Step: 6
Training loss: 2.0810132026672363
Validation loss: 2.010645270347595

Epoch: 5| Step: 7
Training loss: 1.8176136016845703
Validation loss: 2.0150454292694726

Epoch: 5| Step: 8
Training loss: 2.1756458282470703
Validation loss: 2.0123780916134515

Epoch: 5| Step: 9
Training loss: 2.5985279083251953
Validation loss: 2.0197469840447106

Epoch: 5| Step: 10
Training loss: 2.4183168411254883
Validation loss: 2.016554524501165

Epoch: 5| Step: 11
Training loss: 1.1197938919067383
Validation loss: 2.0140903939803443

Epoch: 78| Step: 0
Training loss: 2.220252513885498
Validation loss: 2.017468417684237

Epoch: 5| Step: 1
Training loss: 2.2233405113220215
Validation loss: 2.0121861497561135

Epoch: 5| Step: 2
Training loss: 2.204864025115967
Validation loss: 2.0128727356592813

Epoch: 5| Step: 3
Training loss: 2.4421536922454834
Validation loss: 2.0144695043563843

Epoch: 5| Step: 4
Training loss: 2.079850435256958
Validation loss: 2.020159641901652

Epoch: 5| Step: 5
Training loss: 1.872619390487671
Validation loss: 2.018968845407168

Epoch: 5| Step: 6
Training loss: 2.1004538536071777
Validation loss: 2.019370342294375

Epoch: 5| Step: 7
Training loss: 2.626615285873413
Validation loss: 2.0181425511837006

Epoch: 5| Step: 8
Training loss: 2.1821045875549316
Validation loss: 2.016075680653254

Epoch: 5| Step: 9
Training loss: 2.086620330810547
Validation loss: 2.015534073114395

Epoch: 5| Step: 10
Training loss: 1.936636209487915
Validation loss: 2.0121000508467355

Epoch: 5| Step: 11
Training loss: 2.7796716690063477
Validation loss: 2.0139616429805756

Epoch: 79| Step: 0
Training loss: 2.0317423343658447
Validation loss: 2.009812891483307

Epoch: 5| Step: 1
Training loss: 2.2498669624328613
Validation loss: 2.015482251842817

Epoch: 5| Step: 2
Training loss: 2.4620766639709473
Validation loss: 2.016572097937266

Epoch: 5| Step: 3
Training loss: 2.018117666244507
Validation loss: 2.016322980324427

Epoch: 5| Step: 4
Training loss: 1.8909122943878174
Validation loss: 2.0133795142173767

Epoch: 5| Step: 5
Training loss: 2.131678342819214
Validation loss: 2.014400233825048

Epoch: 5| Step: 6
Training loss: 2.46722674369812
Validation loss: 2.0124277621507645

Epoch: 5| Step: 7
Training loss: 1.950405478477478
Validation loss: 2.014022837082545

Epoch: 5| Step: 8
Training loss: 2.5896248817443848
Validation loss: 2.0172090282042823

Epoch: 5| Step: 9
Training loss: 2.7117061614990234
Validation loss: 2.0159946382045746

Epoch: 5| Step: 10
Training loss: 1.7125619649887085
Validation loss: 2.0135266234477363

Epoch: 5| Step: 11
Training loss: 1.0573675632476807
Validation loss: 2.013405924042066

Epoch: 80| Step: 0
Training loss: 2.046656847000122
Validation loss: 2.010475605726242

Epoch: 5| Step: 1
Training loss: 2.47577166557312
Validation loss: 2.010463853677114

Epoch: 5| Step: 2
Training loss: 2.427044153213501
Validation loss: 2.0090987334648767

Epoch: 5| Step: 3
Training loss: 2.1602883338928223
Validation loss: 2.0072467724482217

Epoch: 5| Step: 4
Training loss: 2.2705509662628174
Validation loss: 2.0058952371279397

Epoch: 5| Step: 5
Training loss: 1.9275106191635132
Validation loss: 2.012181912859281

Epoch: 5| Step: 6
Training loss: 1.5556769371032715
Validation loss: 2.011713318526745

Epoch: 5| Step: 7
Training loss: 2.4764552116394043
Validation loss: 2.0145549972852073

Epoch: 5| Step: 8
Training loss: 1.7849702835083008
Validation loss: 2.0123624304930368

Epoch: 5| Step: 9
Training loss: 2.769962787628174
Validation loss: 2.017271175980568

Epoch: 5| Step: 10
Training loss: 1.9957538843154907
Validation loss: 2.0170792241891227

Epoch: 5| Step: 11
Training loss: 2.885662078857422
Validation loss: 2.0139759431282678

Epoch: 81| Step: 0
Training loss: 1.883099913597107
Validation loss: 2.0237641582886376

Epoch: 5| Step: 1
Training loss: 2.838536500930786
Validation loss: 2.0153143107891083

Epoch: 5| Step: 2
Training loss: 2.395090341567993
Validation loss: 2.016535520553589

Epoch: 5| Step: 3
Training loss: 1.9365119934082031
Validation loss: 2.00980410973231

Epoch: 5| Step: 4
Training loss: 1.3434503078460693
Validation loss: 2.0136991192897162

Epoch: 5| Step: 5
Training loss: 2.1544971466064453
Validation loss: 2.022670497496923

Epoch: 5| Step: 6
Training loss: 2.4587454795837402
Validation loss: 2.0330984940131507

Epoch: 5| Step: 7
Training loss: 2.2457222938537598
Validation loss: 2.0314907133579254

Epoch: 5| Step: 8
Training loss: 2.5572962760925293
Validation loss: 2.038470208644867

Epoch: 5| Step: 9
Training loss: 1.7113975286483765
Validation loss: 2.0435639222462973

Epoch: 5| Step: 10
Training loss: 2.464305877685547
Validation loss: 2.034176359574

Epoch: 5| Step: 11
Training loss: 2.7523937225341797
Validation loss: 2.032249520222346

Epoch: 82| Step: 0
Training loss: 1.9062395095825195
Validation loss: 2.0416798839966455

Epoch: 5| Step: 1
Training loss: 2.306807518005371
Validation loss: 2.034659887353579

Epoch: 5| Step: 2
Training loss: 1.8203502893447876
Validation loss: 2.029780020316442

Epoch: 5| Step: 3
Training loss: 1.678971529006958
Validation loss: 2.0352258533239365

Epoch: 5| Step: 4
Training loss: 2.333311080932617
Validation loss: 2.033648590246836

Epoch: 5| Step: 5
Training loss: 3.0057523250579834
Validation loss: 2.0271418342987695

Epoch: 5| Step: 6
Training loss: 2.1671500205993652
Validation loss: 2.029879868030548

Epoch: 5| Step: 7
Training loss: 2.5129096508026123
Validation loss: 2.0315036127964654

Epoch: 5| Step: 8
Training loss: 1.9687821865081787
Validation loss: 2.0221777657667794

Epoch: 5| Step: 9
Training loss: 2.3500773906707764
Validation loss: 2.020406484603882

Epoch: 5| Step: 10
Training loss: 1.8718875646591187
Validation loss: 2.0163905769586563

Epoch: 5| Step: 11
Training loss: 2.787881851196289
Validation loss: 2.012406369050344

Epoch: 83| Step: 0
Training loss: 2.3371357917785645
Validation loss: 2.0115209817886353

Epoch: 5| Step: 1
Training loss: 2.085728883743286
Validation loss: 2.0111229519049325

Epoch: 5| Step: 2
Training loss: 2.497849225997925
Validation loss: 2.0142297595739365

Epoch: 5| Step: 3
Training loss: 2.382887125015259
Validation loss: 2.0126626789569855

Epoch: 5| Step: 4
Training loss: 2.051604747772217
Validation loss: 2.013512740532557

Epoch: 5| Step: 5
Training loss: 2.135378122329712
Validation loss: 2.017899975180626

Epoch: 5| Step: 6
Training loss: 2.3040859699249268
Validation loss: 2.0241235295931497

Epoch: 5| Step: 7
Training loss: 1.8098865747451782
Validation loss: 2.025443280736605

Epoch: 5| Step: 8
Training loss: 2.643991470336914
Validation loss: 2.02478917936484

Epoch: 5| Step: 9
Training loss: 1.567845344543457
Validation loss: 2.0172018806139627

Epoch: 5| Step: 10
Training loss: 2.3402435779571533
Validation loss: 2.020865539709727

Epoch: 5| Step: 11
Training loss: 0.7168910503387451
Validation loss: 2.0254077861706414

Epoch: 84| Step: 0
Training loss: 2.1610305309295654
Validation loss: 2.0144433081150055

Epoch: 5| Step: 1
Training loss: 2.1262383460998535
Validation loss: 2.0056644827127457

Epoch: 5| Step: 2
Training loss: 2.20198655128479
Validation loss: 2.002896929780642

Epoch: 5| Step: 3
Training loss: 2.4532406330108643
Validation loss: 2.009294013182322

Epoch: 5| Step: 4
Training loss: 2.3664727210998535
Validation loss: 2.0206198344628015

Epoch: 5| Step: 5
Training loss: 2.8185102939605713
Validation loss: 2.025037929415703

Epoch: 5| Step: 6
Training loss: 2.193774938583374
Validation loss: 2.0273973097403846

Epoch: 5| Step: 7
Training loss: 1.9337327480316162
Validation loss: 2.0281314700841904

Epoch: 5| Step: 8
Training loss: 2.1302413940429688
Validation loss: 2.0248896231253943

Epoch: 5| Step: 9
Training loss: 1.782891869544983
Validation loss: 2.0247156073649726

Epoch: 5| Step: 10
Training loss: 1.8117988109588623
Validation loss: 2.019404331843058

Epoch: 5| Step: 11
Training loss: 2.7760238647460938
Validation loss: 2.0137555499871573

Epoch: 85| Step: 0
Training loss: 1.8438701629638672
Validation loss: 2.013385683298111

Epoch: 5| Step: 1
Training loss: 1.781312346458435
Validation loss: 2.0046365360418954

Epoch: 5| Step: 2
Training loss: 2.137249708175659
Validation loss: 2.004837309320768

Epoch: 5| Step: 3
Training loss: 2.5549492835998535
Validation loss: 2.0073785185813904

Epoch: 5| Step: 4
Training loss: 2.138200044631958
Validation loss: 1.999858592947324

Epoch: 5| Step: 5
Training loss: 2.330883026123047
Validation loss: 2.00145360827446

Epoch: 5| Step: 6
Training loss: 2.526582717895508
Validation loss: 2.004079540570577

Epoch: 5| Step: 7
Training loss: 2.0081851482391357
Validation loss: 2.0015423645575843

Epoch: 5| Step: 8
Training loss: 1.944437026977539
Validation loss: 2.0034638891617456

Epoch: 5| Step: 9
Training loss: 2.738187074661255
Validation loss: 2.011981944243113

Epoch: 5| Step: 10
Training loss: 1.9657503366470337
Validation loss: 1.999370316664378

Epoch: 5| Step: 11
Training loss: 1.6071478128433228
Validation loss: 2.0040178894996643

Epoch: 86| Step: 0
Training loss: 1.8479392528533936
Validation loss: 2.005884716908137

Epoch: 5| Step: 1
Training loss: 2.2269954681396484
Validation loss: 2.0111352503299713

Epoch: 5| Step: 2
Training loss: 2.140439510345459
Validation loss: 2.0093372215827308

Epoch: 5| Step: 3
Training loss: 1.8368949890136719
Validation loss: 2.0161990970373154

Epoch: 5| Step: 4
Training loss: 2.5532257556915283
Validation loss: 2.006965532898903

Epoch: 5| Step: 5
Training loss: 2.2576794624328613
Validation loss: 2.0088533560434976

Epoch: 5| Step: 6
Training loss: 1.926797866821289
Validation loss: 2.0082043459018073

Epoch: 5| Step: 7
Training loss: 2.002110481262207
Validation loss: 2.0043931156396866

Epoch: 5| Step: 8
Training loss: 2.017146348953247
Validation loss: 2.006354793906212

Epoch: 5| Step: 9
Training loss: 2.507625102996826
Validation loss: 2.0037205268939338

Epoch: 5| Step: 10
Training loss: 2.2341816425323486
Validation loss: 2.007497027516365

Epoch: 5| Step: 11
Training loss: 3.2823567390441895
Validation loss: 2.0081448207298913

Epoch: 87| Step: 0
Training loss: 2.4615635871887207
Validation loss: 2.007107069094976

Epoch: 5| Step: 1
Training loss: 2.1832242012023926
Validation loss: 2.008246233065923

Epoch: 5| Step: 2
Training loss: 2.4678354263305664
Validation loss: 2.0102423429489136

Epoch: 5| Step: 3
Training loss: 2.0767829418182373
Validation loss: 2.0113172133763633

Epoch: 5| Step: 4
Training loss: 1.928537368774414
Validation loss: 2.004877209663391

Epoch: 5| Step: 5
Training loss: 2.0129103660583496
Validation loss: 2.0172780752182007

Epoch: 5| Step: 6
Training loss: 2.0111682415008545
Validation loss: 2.0097851554552713

Epoch: 5| Step: 7
Training loss: 2.0472640991210938
Validation loss: 2.0080648561318717

Epoch: 5| Step: 8
Training loss: 2.359142303466797
Validation loss: 2.0125223994255066

Epoch: 5| Step: 9
Training loss: 1.9691683053970337
Validation loss: 2.013720472653707

Epoch: 5| Step: 10
Training loss: 2.249758243560791
Validation loss: 2.0277971973021827

Epoch: 5| Step: 11
Training loss: 2.1490609645843506
Validation loss: 2.0202956398328147

Epoch: 88| Step: 0
Training loss: 1.923753023147583
Validation loss: 2.0285318394502005

Epoch: 5| Step: 1
Training loss: 2.310950994491577
Validation loss: 2.0352575530608497

Epoch: 5| Step: 2
Training loss: 1.6195560693740845
Validation loss: 2.049416810274124

Epoch: 5| Step: 3
Training loss: 2.0080435276031494
Validation loss: 2.0373300512631736

Epoch: 5| Step: 4
Training loss: 2.0626614093780518
Validation loss: 2.041762168208758

Epoch: 5| Step: 5
Training loss: 1.7603946924209595
Validation loss: 2.0288301706314087

Epoch: 5| Step: 6
Training loss: 2.6210455894470215
Validation loss: 2.0263311862945557

Epoch: 5| Step: 7
Training loss: 2.49857234954834
Validation loss: 2.0262575844923654

Epoch: 5| Step: 8
Training loss: 2.256748676300049
Validation loss: 2.0240904092788696

Epoch: 5| Step: 9
Training loss: 1.8244549036026
Validation loss: 2.02290286620458

Epoch: 5| Step: 10
Training loss: 2.6371989250183105
Validation loss: 2.015293305118879

Epoch: 5| Step: 11
Training loss: 3.3166399002075195
Validation loss: 2.0181199610233307

Epoch: 89| Step: 0
Training loss: 2.2520103454589844
Validation loss: 1.9991190334161122

Epoch: 5| Step: 1
Training loss: 2.3476274013519287
Validation loss: 2.0124156028032303

Epoch: 5| Step: 2
Training loss: 2.3042402267456055
Validation loss: 2.020072430372238

Epoch: 5| Step: 3
Training loss: 1.799095869064331
Validation loss: 2.0338069001833596

Epoch: 5| Step: 4
Training loss: 1.9601638317108154
Validation loss: 2.0323493033647537

Epoch: 5| Step: 5
Training loss: 2.300605297088623
Validation loss: 2.0351216395696006

Epoch: 5| Step: 6
Training loss: 2.6688079833984375
Validation loss: 2.033027003208796

Epoch: 5| Step: 7
Training loss: 2.7041049003601074
Validation loss: 2.0383282750844955

Epoch: 5| Step: 8
Training loss: 1.9092543125152588
Validation loss: 2.0376578072706857

Epoch: 5| Step: 9
Training loss: 2.170010805130005
Validation loss: 2.0370405515034995

Epoch: 5| Step: 10
Training loss: 1.725902795791626
Validation loss: 2.0434604982535043

Epoch: 5| Step: 11
Training loss: 2.7920966148376465
Validation loss: 2.036351894338926

Epoch: 90| Step: 0
Training loss: 2.6018731594085693
Validation loss: 2.041440024971962

Epoch: 5| Step: 1
Training loss: 2.116570234298706
Validation loss: 2.037416860461235

Epoch: 5| Step: 2
Training loss: 2.2062294483184814
Validation loss: 2.0350117087364197

Epoch: 5| Step: 3
Training loss: 2.1738064289093018
Validation loss: 2.0304035395383835

Epoch: 5| Step: 4
Training loss: 1.547844409942627
Validation loss: 2.029952878753344

Epoch: 5| Step: 5
Training loss: 2.0613691806793213
Validation loss: 2.0301742255687714

Epoch: 5| Step: 6
Training loss: 2.091618061065674
Validation loss: 2.026109422246615

Epoch: 5| Step: 7
Training loss: 2.359154224395752
Validation loss: 2.020862653851509

Epoch: 5| Step: 8
Training loss: 2.1568710803985596
Validation loss: 2.0232029358545938

Epoch: 5| Step: 9
Training loss: 2.2321712970733643
Validation loss: 2.0168383618195853

Epoch: 5| Step: 10
Training loss: 2.5575995445251465
Validation loss: 2.011685788631439

Epoch: 5| Step: 11
Training loss: 2.066194534301758
Validation loss: 2.0105110158522925

Epoch: 91| Step: 0
Training loss: 2.643873691558838
Validation loss: 2.007003997762998

Epoch: 5| Step: 1
Training loss: 2.4380030632019043
Validation loss: 2.0085784246524176

Epoch: 5| Step: 2
Training loss: 1.9176881313323975
Validation loss: 2.009777237971624

Epoch: 5| Step: 3
Training loss: 1.9222522974014282
Validation loss: 2.0231656481822333

Epoch: 5| Step: 4
Training loss: 2.450012683868408
Validation loss: 2.0169182866811752

Epoch: 5| Step: 5
Training loss: 2.1631219387054443
Validation loss: 2.0076167583465576

Epoch: 5| Step: 6
Training loss: 1.8785133361816406
Validation loss: 2.014148642619451

Epoch: 5| Step: 7
Training loss: 2.4028968811035156
Validation loss: 2.0107885350783667

Epoch: 5| Step: 8
Training loss: 2.0470480918884277
Validation loss: 2.0105667610963187

Epoch: 5| Step: 9
Training loss: 1.914891004562378
Validation loss: 2.0070183177789054

Epoch: 5| Step: 10
Training loss: 2.0216643810272217
Validation loss: 2.008552834391594

Epoch: 5| Step: 11
Training loss: 1.5595214366912842
Validation loss: 2.0104819933573403

Epoch: 92| Step: 0
Training loss: 1.9045318365097046
Validation loss: 2.0241089910268784

Epoch: 5| Step: 1
Training loss: 2.385680913925171
Validation loss: 2.0314061443010965

Epoch: 5| Step: 2
Training loss: 2.382263660430908
Validation loss: 2.039121607939402

Epoch: 5| Step: 3
Training loss: 2.133075714111328
Validation loss: 2.040176918109258

Epoch: 5| Step: 4
Training loss: 2.13075590133667
Validation loss: 2.0354669988155365

Epoch: 5| Step: 5
Training loss: 1.9424991607666016
Validation loss: 2.03080478310585

Epoch: 5| Step: 6
Training loss: 2.3687641620635986
Validation loss: 2.035300229986509

Epoch: 5| Step: 7
Training loss: 1.9279426336288452
Validation loss: 2.033626819650332

Epoch: 5| Step: 8
Training loss: 2.227815866470337
Validation loss: 2.019986321528753

Epoch: 5| Step: 9
Training loss: 1.7057063579559326
Validation loss: 2.019190102815628

Epoch: 5| Step: 10
Training loss: 2.438931941986084
Validation loss: 2.017664283514023

Epoch: 5| Step: 11
Training loss: 3.0127956867218018
Validation loss: 2.015286530057589

Epoch: 93| Step: 0
Training loss: 2.2145206928253174
Validation loss: 2.013305207093557

Epoch: 5| Step: 1
Training loss: 2.318916082382202
Validation loss: 2.0080631325642266

Epoch: 5| Step: 2
Training loss: 1.7723057270050049
Validation loss: 2.007899964849154

Epoch: 5| Step: 3
Training loss: 1.8899879455566406
Validation loss: 2.0023193359375

Epoch: 5| Step: 4
Training loss: 1.9333568811416626
Validation loss: 2.0044843753178916

Epoch: 5| Step: 5
Training loss: 2.6205666065216064
Validation loss: 2.0074917475382485

Epoch: 5| Step: 6
Training loss: 2.12318754196167
Validation loss: 2.0027921547492347

Epoch: 5| Step: 7
Training loss: 1.8769773244857788
Validation loss: 2.0017643173535666

Epoch: 5| Step: 8
Training loss: 2.420762777328491
Validation loss: 1.998007853825887

Epoch: 5| Step: 9
Training loss: 2.244978666305542
Validation loss: 2.010591904322306

Epoch: 5| Step: 10
Training loss: 2.3884105682373047
Validation loss: 2.006519690155983

Epoch: 5| Step: 11
Training loss: 1.852439522743225
Validation loss: 2.0103209565083184

Epoch: 94| Step: 0
Training loss: 2.2836527824401855
Validation loss: 2.0148203670978546

Epoch: 5| Step: 1
Training loss: 2.0813794136047363
Validation loss: 2.025492548942566

Epoch: 5| Step: 2
Training loss: 1.987012267112732
Validation loss: 2.0327871441841125

Epoch: 5| Step: 3
Training loss: 2.2864198684692383
Validation loss: 2.0475208510955176

Epoch: 5| Step: 4
Training loss: 1.4712698459625244
Validation loss: 2.0325895299514136

Epoch: 5| Step: 5
Training loss: 2.289545774459839
Validation loss: 2.035349354147911

Epoch: 5| Step: 6
Training loss: 1.9482835531234741
Validation loss: 2.0276184330383935

Epoch: 5| Step: 7
Training loss: 2.531522274017334
Validation loss: 2.017770325144132

Epoch: 5| Step: 8
Training loss: 2.099647045135498
Validation loss: 2.012418041626612

Epoch: 5| Step: 9
Training loss: 2.214745044708252
Validation loss: 2.006463254491488

Epoch: 5| Step: 10
Training loss: 2.5338282585144043
Validation loss: 2.0018132825692496

Epoch: 5| Step: 11
Training loss: 2.653775453567505
Validation loss: 2.011392042040825

Epoch: 95| Step: 0
Training loss: 2.138237476348877
Validation loss: 2.0156096468369165

Epoch: 5| Step: 1
Training loss: 1.9812122583389282
Validation loss: 2.022110347946485

Epoch: 5| Step: 2
Training loss: 2.303995370864868
Validation loss: 2.0273769249518714

Epoch: 5| Step: 3
Training loss: 2.842296600341797
Validation loss: 2.0363712956508

Epoch: 5| Step: 4
Training loss: 1.861846685409546
Validation loss: 2.0422565937042236

Epoch: 5| Step: 5
Training loss: 2.1704821586608887
Validation loss: 2.0416990419228873

Epoch: 5| Step: 6
Training loss: 2.0758442878723145
Validation loss: 2.0367394338051477

Epoch: 5| Step: 7
Training loss: 2.0527291297912598
Validation loss: 2.0429833134015403

Epoch: 5| Step: 8
Training loss: 2.6395764350891113
Validation loss: 2.0433057844638824

Epoch: 5| Step: 9
Training loss: 2.006413221359253
Validation loss: 2.03795263171196

Epoch: 5| Step: 10
Training loss: 2.111536741256714
Validation loss: 2.0426117181777954

Epoch: 5| Step: 11
Training loss: 1.9004077911376953
Validation loss: 2.042181372642517

Epoch: 96| Step: 0
Training loss: 2.18357253074646
Validation loss: 2.0438973158597946

Epoch: 5| Step: 1
Training loss: 2.474156618118286
Validation loss: 2.0421633472045264

Epoch: 5| Step: 2
Training loss: 2.077399730682373
Validation loss: 2.041700462500254

Epoch: 5| Step: 3
Training loss: 2.103156566619873
Validation loss: 2.0357153515021005

Epoch: 5| Step: 4
Training loss: 2.117704391479492
Validation loss: 2.035529206196467

Epoch: 5| Step: 5
Training loss: 2.0129740238189697
Validation loss: 2.036656007170677

Epoch: 5| Step: 6
Training loss: 2.6320996284484863
Validation loss: 2.0337411711613336

Epoch: 5| Step: 7
Training loss: 1.9051185846328735
Validation loss: 2.0349187503258386

Epoch: 5| Step: 8
Training loss: 2.105027914047241
Validation loss: 2.0231252163648605

Epoch: 5| Step: 9
Training loss: 2.0249063968658447
Validation loss: 2.024364471435547

Epoch: 5| Step: 10
Training loss: 2.475879669189453
Validation loss: 2.020215928554535

Epoch: 5| Step: 11
Training loss: 2.224581241607666
Validation loss: 2.0090008775393167

Epoch: 97| Step: 0
Training loss: 2.143179416656494
Validation loss: 2.0109247962633767

Epoch: 5| Step: 1
Training loss: 2.01861834526062
Validation loss: 2.0123135646184287

Epoch: 5| Step: 2
Training loss: 1.7278143167495728
Validation loss: 1.9954022914171219

Epoch: 5| Step: 3
Training loss: 2.571786880493164
Validation loss: 2.007026955485344

Epoch: 5| Step: 4
Training loss: 1.7999950647354126
Validation loss: 2.0059567391872406

Epoch: 5| Step: 5
Training loss: 2.260120153427124
Validation loss: 2.0165732155243554

Epoch: 5| Step: 6
Training loss: 1.4923899173736572
Validation loss: 2.0165303299824395

Epoch: 5| Step: 7
Training loss: 2.0752313137054443
Validation loss: 2.0298217982053757

Epoch: 5| Step: 8
Training loss: 2.60609769821167
Validation loss: 2.039669136206309

Epoch: 5| Step: 9
Training loss: 2.386660099029541
Validation loss: 2.0422396014134088

Epoch: 5| Step: 10
Training loss: 2.4194607734680176
Validation loss: 2.036180093884468

Epoch: 5| Step: 11
Training loss: 2.7683892250061035
Validation loss: 2.043523242076238

Epoch: 98| Step: 0
Training loss: 2.187410354614258
Validation loss: 2.036770467956861

Epoch: 5| Step: 1
Training loss: 2.12560772895813
Validation loss: 2.042023996512095

Epoch: 5| Step: 2
Training loss: 1.7163331508636475
Validation loss: 2.0369127144416175

Epoch: 5| Step: 3
Training loss: 2.341430902481079
Validation loss: 2.035754303137461

Epoch: 5| Step: 4
Training loss: 2.096100330352783
Validation loss: 2.0197437604268393

Epoch: 5| Step: 5
Training loss: 1.755380630493164
Validation loss: 2.020932520429293

Epoch: 5| Step: 6
Training loss: 2.1151204109191895
Validation loss: 2.0165763944387436

Epoch: 5| Step: 7
Training loss: 2.298098087310791
Validation loss: 2.01450514793396

Epoch: 5| Step: 8
Training loss: 2.5803277492523193
Validation loss: 2.0217773417631784

Epoch: 5| Step: 9
Training loss: 1.886461615562439
Validation loss: 2.0165383517742157

Epoch: 5| Step: 10
Training loss: 2.3015191555023193
Validation loss: 2.0160797238349915

Epoch: 5| Step: 11
Training loss: 2.488332986831665
Validation loss: 2.0134718070427575

Epoch: 99| Step: 0
Training loss: 1.8222020864486694
Validation loss: 2.0192627857128778

Epoch: 5| Step: 1
Training loss: 2.288003921508789
Validation loss: 2.0177734146515527

Epoch: 5| Step: 2
Training loss: 2.331857204437256
Validation loss: 2.023969739675522

Epoch: 5| Step: 3
Training loss: 1.9060747623443604
Validation loss: 2.0264987349510193

Epoch: 5| Step: 4
Training loss: 1.8170744180679321
Validation loss: 2.03214701016744

Epoch: 5| Step: 5
Training loss: 2.6899971961975098
Validation loss: 2.0401103496551514

Epoch: 5| Step: 6
Training loss: 2.0971157550811768
Validation loss: 2.0339292188485465

Epoch: 5| Step: 7
Training loss: 2.04113507270813
Validation loss: 2.0263145516316095

Epoch: 5| Step: 8
Training loss: 1.567082166671753
Validation loss: 2.0234465301036835

Epoch: 5| Step: 9
Training loss: 2.7526357173919678
Validation loss: 2.0412745972474418

Epoch: 5| Step: 10
Training loss: 2.0854406356811523
Validation loss: 2.0282054046789804

Epoch: 5| Step: 11
Training loss: 2.2464945316314697
Validation loss: 2.026979307333628

Epoch: 100| Step: 0
Training loss: 2.2163889408111572
Validation loss: 2.025261258085569

Epoch: 5| Step: 1
Training loss: 2.192399501800537
Validation loss: 2.01959157983462

Epoch: 5| Step: 2
Training loss: 1.9554109573364258
Validation loss: 2.011629710594813

Epoch: 5| Step: 3
Training loss: 2.7297096252441406
Validation loss: 2.0067551781733832

Epoch: 5| Step: 4
Training loss: 1.934084177017212
Validation loss: 2.0056472420692444

Epoch: 5| Step: 5
Training loss: 1.824581503868103
Validation loss: 2.003724386294683

Epoch: 5| Step: 6
Training loss: 1.887981653213501
Validation loss: 2.0142798324426017

Epoch: 5| Step: 7
Training loss: 2.1879169940948486
Validation loss: 2.0030330618222556

Epoch: 5| Step: 8
Training loss: 2.479970932006836
Validation loss: 2.004260783394178

Epoch: 5| Step: 9
Training loss: 1.8179250955581665
Validation loss: 2.0029444495836892

Epoch: 5| Step: 10
Training loss: 2.44981050491333
Validation loss: 2.0034368385871253

Epoch: 5| Step: 11
Training loss: 1.589841365814209
Validation loss: 2.0092513114213943

Epoch: 101| Step: 0
Training loss: 2.0051841735839844
Validation loss: 1.9982346445322037

Epoch: 5| Step: 1
Training loss: 1.979006052017212
Validation loss: 1.9994612038135529

Epoch: 5| Step: 2
Training loss: 2.042086601257324
Validation loss: 2.0042680501937866

Epoch: 5| Step: 3
Training loss: 2.0648040771484375
Validation loss: 2.0001895427703857

Epoch: 5| Step: 4
Training loss: 2.5041568279266357
Validation loss: 2.0007026692231498

Epoch: 5| Step: 5
Training loss: 1.7601234912872314
Validation loss: 2.0097301254669824

Epoch: 5| Step: 6
Training loss: 2.220878839492798
Validation loss: 2.004675810535749

Epoch: 5| Step: 7
Training loss: 2.6933789253234863
Validation loss: 2.0014197727044425

Epoch: 5| Step: 8
Training loss: 2.1723735332489014
Validation loss: 2.0078552961349487

Epoch: 5| Step: 9
Training loss: 2.1848833560943604
Validation loss: 2.0010385513305664

Epoch: 5| Step: 10
Training loss: 1.9307960271835327
Validation loss: 2.0130173712968826

Epoch: 5| Step: 11
Training loss: 1.2226167917251587
Validation loss: 2.0158043056726456

Epoch: 102| Step: 0
Training loss: 2.6439313888549805
Validation loss: 2.022208020091057

Epoch: 5| Step: 1
Training loss: 1.8096987009048462
Validation loss: 2.02841280400753

Epoch: 5| Step: 2
Training loss: 2.181872844696045
Validation loss: 2.028691286842028

Epoch: 5| Step: 3
Training loss: 2.5745296478271484
Validation loss: 2.0333258509635925

Epoch: 5| Step: 4
Training loss: 2.2035441398620605
Validation loss: 2.0381342321634293

Epoch: 5| Step: 5
Training loss: 1.6825759410858154
Validation loss: 2.0313776284456253

Epoch: 5| Step: 6
Training loss: 2.096879243850708
Validation loss: 2.0314738353093467

Epoch: 5| Step: 7
Training loss: 2.227598190307617
Validation loss: 2.0230713884035745

Epoch: 5| Step: 8
Training loss: 1.7173992395401
Validation loss: 2.020850881934166

Epoch: 5| Step: 9
Training loss: 1.6842657327651978
Validation loss: 2.0117238759994507

Epoch: 5| Step: 10
Training loss: 2.532953977584839
Validation loss: 2.0208925902843475

Epoch: 5| Step: 11
Training loss: 2.181612014770508
Validation loss: 2.01326185464859

Epoch: 103| Step: 0
Training loss: 1.874879240989685
Validation loss: 2.0222115765015283

Epoch: 5| Step: 1
Training loss: 1.998443603515625
Validation loss: 2.025520791610082

Epoch: 5| Step: 2
Training loss: 1.88101327419281
Validation loss: 2.026370053490003

Epoch: 5| Step: 3
Training loss: 2.0904412269592285
Validation loss: 2.022600238521894

Epoch: 5| Step: 4
Training loss: 2.4087014198303223
Validation loss: 2.027970463037491

Epoch: 5| Step: 5
Training loss: 2.0842318534851074
Validation loss: 2.0329029659430184

Epoch: 5| Step: 6
Training loss: 1.9694023132324219
Validation loss: 2.0537503957748413

Epoch: 5| Step: 7
Training loss: 2.887725353240967
Validation loss: 2.055868481596311

Epoch: 5| Step: 8
Training loss: 2.4416346549987793
Validation loss: 2.0624186793963113

Epoch: 5| Step: 9
Training loss: 2.1530299186706543
Validation loss: 2.0478051751852036

Epoch: 5| Step: 10
Training loss: 2.022338390350342
Validation loss: 2.045324077208837

Epoch: 5| Step: 11
Training loss: 1.6924254894256592
Validation loss: 2.039037346839905

Epoch: 104| Step: 0
Training loss: 2.5390055179595947
Validation loss: 2.0363071064154306

Epoch: 5| Step: 1
Training loss: 1.699584722518921
Validation loss: 2.0288982590039573

Epoch: 5| Step: 2
Training loss: 2.1602814197540283
Validation loss: 2.0140315343936286

Epoch: 5| Step: 3
Training loss: 2.1706795692443848
Validation loss: 2.0167790899674096

Epoch: 5| Step: 4
Training loss: 1.8840879201889038
Validation loss: 2.001419792572657

Epoch: 5| Step: 5
Training loss: 2.0768303871154785
Validation loss: 2.00719645122687

Epoch: 5| Step: 6
Training loss: 2.444230794906616
Validation loss: 2.002634972333908

Epoch: 5| Step: 7
Training loss: 1.4537808895111084
Validation loss: 2.0054066131512323

Epoch: 5| Step: 8
Training loss: 1.9260218143463135
Validation loss: 2.004099170366923

Epoch: 5| Step: 9
Training loss: 2.6773338317871094
Validation loss: 2.0078252653280892

Epoch: 5| Step: 10
Training loss: 2.4318408966064453
Validation loss: 2.0100825081268945

Epoch: 5| Step: 11
Training loss: 2.900749683380127
Validation loss: 2.0087289909521737

Epoch: 105| Step: 0
Training loss: 2.5297627449035645
Validation loss: 2.0094039688507714

Epoch: 5| Step: 1
Training loss: 2.491067409515381
Validation loss: 2.0066283543904624

Epoch: 5| Step: 2
Training loss: 2.0025649070739746
Validation loss: 2.01204622288545

Epoch: 5| Step: 3
Training loss: 2.7741997241973877
Validation loss: 2.010712116956711

Epoch: 5| Step: 4
Training loss: 1.8287261724472046
Validation loss: 2.0109048386414847

Epoch: 5| Step: 5
Training loss: 2.038095474243164
Validation loss: 2.0086999038855233

Epoch: 5| Step: 6
Training loss: 1.389884352684021
Validation loss: 2.0177038609981537

Epoch: 5| Step: 7
Training loss: 1.6181926727294922
Validation loss: 2.020087331533432

Epoch: 5| Step: 8
Training loss: 1.8388092517852783
Validation loss: 2.0281454076369605

Epoch: 5| Step: 9
Training loss: 2.546921491622925
Validation loss: 2.041526938478152

Epoch: 5| Step: 10
Training loss: 2.3725125789642334
Validation loss: 2.0414323012034097

Epoch: 5| Step: 11
Training loss: 1.6383095979690552
Validation loss: 2.0442413836717606

Epoch: 106| Step: 0
Training loss: 1.9029312133789062
Validation loss: 2.076062321662903

Epoch: 5| Step: 1
Training loss: 2.3390121459960938
Validation loss: 2.080075984199842

Epoch: 5| Step: 2
Training loss: 2.21655535697937
Validation loss: 2.0807348241408667

Epoch: 5| Step: 3
Training loss: 1.953016996383667
Validation loss: 2.0727587888638177

Epoch: 5| Step: 4
Training loss: 2.4417824745178223
Validation loss: 2.0711390574773154

Epoch: 5| Step: 5
Training loss: 2.0310006141662598
Validation loss: 2.0529004683097205

Epoch: 5| Step: 6
Training loss: 1.595888376235962
Validation loss: 2.05280693868796

Epoch: 5| Step: 7
Training loss: 2.7672278881073
Validation loss: 2.0367675920327506

Epoch: 5| Step: 8
Training loss: 2.0578322410583496
Validation loss: 2.0399297177791595

Epoch: 5| Step: 9
Training loss: 2.300635814666748
Validation loss: 2.0370342234770455

Epoch: 5| Step: 10
Training loss: 2.098646879196167
Validation loss: 2.042570968468984

Epoch: 5| Step: 11
Training loss: 1.7927496433258057
Validation loss: 2.0336900701125464

Epoch: 107| Step: 0
Training loss: 1.9865535497665405
Validation loss: 2.019663746158282

Epoch: 5| Step: 1
Training loss: 1.9113298654556274
Validation loss: 2.0146873792012534

Epoch: 5| Step: 2
Training loss: 1.381656289100647
Validation loss: 2.010508651534716

Epoch: 5| Step: 3
Training loss: 2.56398606300354
Validation loss: 2.0153973748286567

Epoch: 5| Step: 4
Training loss: 2.1102023124694824
Validation loss: 2.006981208920479

Epoch: 5| Step: 5
Training loss: 2.1488068103790283
Validation loss: 2.012305865685145

Epoch: 5| Step: 6
Training loss: 1.9022483825683594
Validation loss: 2.005190630753835

Epoch: 5| Step: 7
Training loss: 2.468515634536743
Validation loss: 2.017889271179835

Epoch: 5| Step: 8
Training loss: 2.2189297676086426
Validation loss: 2.013750116030375

Epoch: 5| Step: 9
Training loss: 2.408142328262329
Validation loss: 2.020111491282781

Epoch: 5| Step: 10
Training loss: 2.3023669719696045
Validation loss: 2.008238101998965

Epoch: 5| Step: 11
Training loss: 1.8229516744613647
Validation loss: 2.0102196435133615

Epoch: 108| Step: 0
Training loss: 2.183872699737549
Validation loss: 2.005914921561877

Epoch: 5| Step: 1
Training loss: 1.9976682662963867
Validation loss: 1.9967783043781917

Epoch: 5| Step: 2
Training loss: 2.1391830444335938
Validation loss: 2.0021022309859595

Epoch: 5| Step: 3
Training loss: 2.0189220905303955
Validation loss: 1.9931171437104542

Epoch: 5| Step: 4
Training loss: 2.1949379444122314
Validation loss: 1.998585174481074

Epoch: 5| Step: 5
Training loss: 2.520625352859497
Validation loss: 2.0004514704147973

Epoch: 5| Step: 6
Training loss: 2.3737282752990723
Validation loss: 2.000772774219513

Epoch: 5| Step: 7
Training loss: 1.5999815464019775
Validation loss: 2.0028157780567803

Epoch: 5| Step: 8
Training loss: 2.18766450881958
Validation loss: 2.001174196600914

Epoch: 5| Step: 9
Training loss: 2.0994789600372314
Validation loss: 2.0049543927113214

Epoch: 5| Step: 10
Training loss: 2.2082793712615967
Validation loss: 2.0029336164395013

Epoch: 5| Step: 11
Training loss: 1.1299374103546143
Validation loss: 1.9990976651509602

Epoch: 109| Step: 0
Training loss: 2.4132351875305176
Validation loss: 2.0094389667113624

Epoch: 5| Step: 1
Training loss: 2.1415257453918457
Validation loss: 2.0083922147750854

Epoch: 5| Step: 2
Training loss: 1.693367600440979
Validation loss: 2.001905530691147

Epoch: 5| Step: 3
Training loss: 2.2825608253479004
Validation loss: 2.0136296649773917

Epoch: 5| Step: 4
Training loss: 2.226656436920166
Validation loss: 2.0176442364851632

Epoch: 5| Step: 5
Training loss: 1.9257034063339233
Validation loss: 2.0277235905329385

Epoch: 5| Step: 6
Training loss: 1.602717638015747
Validation loss: 2.0247026880582175

Epoch: 5| Step: 7
Training loss: 2.5668981075286865
Validation loss: 2.0262422213951745

Epoch: 5| Step: 8
Training loss: 1.747915506362915
Validation loss: 2.023800348242124

Epoch: 5| Step: 9
Training loss: 2.1596639156341553
Validation loss: 2.020797520875931

Epoch: 5| Step: 10
Training loss: 2.0397722721099854
Validation loss: 2.015123099088669

Epoch: 5| Step: 11
Training loss: 4.319967269897461
Validation loss: 2.012222116192182

Epoch: 110| Step: 0
Training loss: 2.23665452003479
Validation loss: 2.022460088133812

Epoch: 5| Step: 1
Training loss: 1.9730408191680908
Validation loss: 2.0146081497271857

Epoch: 5| Step: 2
Training loss: 2.4578378200531006
Validation loss: 2.0179994851350784

Epoch: 5| Step: 3
Training loss: 1.9487104415893555
Validation loss: 2.0199140856663385

Epoch: 5| Step: 4
Training loss: 2.7772955894470215
Validation loss: 2.021732618411382

Epoch: 5| Step: 5
Training loss: 1.725888967514038
Validation loss: 2.01492507259051

Epoch: 5| Step: 6
Training loss: 2.2337212562561035
Validation loss: 2.0192566017309823

Epoch: 5| Step: 7
Training loss: 2.04929780960083
Validation loss: 2.0185612539450326

Epoch: 5| Step: 8
Training loss: 1.639626145362854
Validation loss: 2.0199067443609238

Epoch: 5| Step: 9
Training loss: 2.087571382522583
Validation loss: 2.021156723300616

Epoch: 5| Step: 10
Training loss: 2.1145215034484863
Validation loss: 2.025780066847801

Epoch: 5| Step: 11
Training loss: 2.050356388092041
Validation loss: 2.020981043577194

Epoch: 111| Step: 0
Training loss: 2.060878276824951
Validation loss: 2.0304869264364243

Epoch: 5| Step: 1
Training loss: 2.1567561626434326
Validation loss: 2.027008225520452

Epoch: 5| Step: 2
Training loss: 2.081709384918213
Validation loss: 2.0462217579285302

Epoch: 5| Step: 3
Training loss: 2.360124111175537
Validation loss: 2.0487554421027503

Epoch: 5| Step: 4
Training loss: 2.1707329750061035
Validation loss: 2.0457695027192435

Epoch: 5| Step: 5
Training loss: 2.069850206375122
Validation loss: 2.0522016982237496

Epoch: 5| Step: 6
Training loss: 2.018301486968994
Validation loss: 2.045420835415522

Epoch: 5| Step: 7
Training loss: 1.8088271617889404
Validation loss: 2.039720411101977

Epoch: 5| Step: 8
Training loss: 2.060459852218628
Validation loss: 2.03551917274793

Epoch: 5| Step: 9
Training loss: 1.8709224462509155
Validation loss: 2.023246705532074

Epoch: 5| Step: 10
Training loss: 2.214663028717041
Validation loss: 2.0219589322805405

Epoch: 5| Step: 11
Training loss: 3.4156346321105957
Validation loss: 2.017391860485077

Epoch: 112| Step: 0
Training loss: 1.9426872730255127
Validation loss: 2.0216128130753837

Epoch: 5| Step: 1
Training loss: 2.1193642616271973
Validation loss: 2.02709653476874

Epoch: 5| Step: 2
Training loss: 2.544809579849243
Validation loss: 2.021476298570633

Epoch: 5| Step: 3
Training loss: 1.6781435012817383
Validation loss: 2.023692081371943

Epoch: 5| Step: 4
Training loss: 1.7608039379119873
Validation loss: 2.036978378891945

Epoch: 5| Step: 5
Training loss: 2.481980800628662
Validation loss: 2.031812200943629

Epoch: 5| Step: 6
Training loss: 2.062279462814331
Validation loss: 2.040510043501854

Epoch: 5| Step: 7
Training loss: 2.019470691680908
Validation loss: 2.0433276693026223

Epoch: 5| Step: 8
Training loss: 2.0464866161346436
Validation loss: 2.050708701213201

Epoch: 5| Step: 9
Training loss: 2.35282826423645
Validation loss: 2.047128270069758

Epoch: 5| Step: 10
Training loss: 2.288822889328003
Validation loss: 2.04437388976415

Epoch: 5| Step: 11
Training loss: 2.521501064300537
Validation loss: 2.035604720314344

Epoch: 113| Step: 0
Training loss: 2.182770252227783
Validation loss: 2.0217517664035163

Epoch: 5| Step: 1
Training loss: 1.8362919092178345
Validation loss: 2.0254939049482346

Epoch: 5| Step: 2
Training loss: 1.96517014503479
Validation loss: 2.021455466747284

Epoch: 5| Step: 3
Training loss: 2.1263680458068848
Validation loss: 2.0205535093943277

Epoch: 5| Step: 4
Training loss: 2.1642332077026367
Validation loss: 2.0180804828802743

Epoch: 5| Step: 5
Training loss: 2.1922502517700195
Validation loss: 2.0147301455338797

Epoch: 5| Step: 6
Training loss: 1.85199773311615
Validation loss: 2.0055257131656012

Epoch: 5| Step: 7
Training loss: 2.43005633354187
Validation loss: 2.016264940301577

Epoch: 5| Step: 8
Training loss: 2.1970086097717285
Validation loss: 2.0175234923760095

Epoch: 5| Step: 9
Training loss: 1.902661681175232
Validation loss: 2.0249765465656915

Epoch: 5| Step: 10
Training loss: 2.179386615753174
Validation loss: 2.0291427075862885

Epoch: 5| Step: 11
Training loss: 2.045588731765747
Validation loss: 2.0187927881876626

Epoch: 114| Step: 0
Training loss: 1.899557113647461
Validation loss: 2.0156318744023642

Epoch: 5| Step: 1
Training loss: 1.9243217706680298
Validation loss: 2.021648327509562

Epoch: 5| Step: 2
Training loss: 2.097313404083252
Validation loss: 2.021745671828588

Epoch: 5| Step: 3
Training loss: 2.2814345359802246
Validation loss: 2.0239866226911545

Epoch: 5| Step: 4
Training loss: 2.4089112281799316
Validation loss: 2.0288649797439575

Epoch: 5| Step: 5
Training loss: 1.9284255504608154
Validation loss: 2.0247758825620017

Epoch: 5| Step: 6
Training loss: 1.9470020532608032
Validation loss: 2.029410163561503

Epoch: 5| Step: 7
Training loss: 2.2994039058685303
Validation loss: 2.0344652583201728

Epoch: 5| Step: 8
Training loss: 2.0413548946380615
Validation loss: 2.029815917213758

Epoch: 5| Step: 9
Training loss: 2.034125804901123
Validation loss: 2.0308436105648675

Epoch: 5| Step: 10
Training loss: 2.26396107673645
Validation loss: 2.0330964028835297

Epoch: 5| Step: 11
Training loss: 1.6118775606155396
Validation loss: 2.0333058585723243

Epoch: 115| Step: 0
Training loss: 2.6495814323425293
Validation loss: 2.0365910877784095

Epoch: 5| Step: 1
Training loss: 2.432126998901367
Validation loss: 2.0265514055887857

Epoch: 5| Step: 2
Training loss: 2.0228426456451416
Validation loss: 2.030407885710398

Epoch: 5| Step: 3
Training loss: 2.864203691482544
Validation loss: 2.033002262314161

Epoch: 5| Step: 4
Training loss: 1.7578407526016235
Validation loss: 2.0314249992370605

Epoch: 5| Step: 5
Training loss: 1.784521460533142
Validation loss: 2.037302459279696

Epoch: 5| Step: 6
Training loss: 1.6200851202011108
Validation loss: 2.0300151109695435

Epoch: 5| Step: 7
Training loss: 1.9244134426116943
Validation loss: 2.029271016518275

Epoch: 5| Step: 8
Training loss: 1.8104867935180664
Validation loss: 2.03619118531545

Epoch: 5| Step: 9
Training loss: 2.1027960777282715
Validation loss: 2.0271735191345215

Epoch: 5| Step: 10
Training loss: 1.8353099822998047
Validation loss: 2.018702745437622

Epoch: 5| Step: 11
Training loss: 2.629625082015991
Validation loss: 2.0318450878063836

Epoch: 116| Step: 0
Training loss: 1.8642933368682861
Validation loss: 2.0214380621910095

Epoch: 5| Step: 1
Training loss: 1.8700225353240967
Validation loss: 2.0176437149445214

Epoch: 5| Step: 2
Training loss: 2.2290432453155518
Validation loss: 2.0099048217137656

Epoch: 5| Step: 3
Training loss: 2.1671249866485596
Validation loss: 2.0172526786724725

Epoch: 5| Step: 4
Training loss: 1.6899150609970093
Validation loss: 2.0171846449375153

Epoch: 5| Step: 5
Training loss: 2.6908621788024902
Validation loss: 2.0294951597849527

Epoch: 5| Step: 6
Training loss: 2.058720111846924
Validation loss: 2.0223321517308555

Epoch: 5| Step: 7
Training loss: 2.1075685024261475
Validation loss: 2.028501013914744

Epoch: 5| Step: 8
Training loss: 1.9344536066055298
Validation loss: 2.030326465765635

Epoch: 5| Step: 9
Training loss: 1.7910276651382446
Validation loss: 2.029357378681501

Epoch: 5| Step: 10
Training loss: 2.5802369117736816
Validation loss: 2.0306280503670373

Epoch: 5| Step: 11
Training loss: 2.095696449279785
Validation loss: 2.0243017027775445

Epoch: 117| Step: 0
Training loss: 1.8842414617538452
Validation loss: 2.0145437121391296

Epoch: 5| Step: 1
Training loss: 1.868303894996643
Validation loss: 2.009017343322436

Epoch: 5| Step: 2
Training loss: 2.221282958984375
Validation loss: 2.0131878753503165

Epoch: 5| Step: 3
Training loss: 2.42021107673645
Validation loss: 2.0035579055547714

Epoch: 5| Step: 4
Training loss: 2.419985294342041
Validation loss: 2.0084816416104636

Epoch: 5| Step: 5
Training loss: 1.7913463115692139
Validation loss: 2.009408483902613

Epoch: 5| Step: 6
Training loss: 2.0792953968048096
Validation loss: 2.0108471562465033

Epoch: 5| Step: 7
Training loss: 2.5314860343933105
Validation loss: 2.0099742313226066

Epoch: 5| Step: 8
Training loss: 2.169269323348999
Validation loss: 2.0095170785983405

Epoch: 5| Step: 9
Training loss: 1.6412122249603271
Validation loss: 2.0036513954401016

Epoch: 5| Step: 10
Training loss: 2.1042704582214355
Validation loss: 2.0024441381295524

Epoch: 5| Step: 11
Training loss: 3.1237311363220215
Validation loss: 2.005471641818682

Epoch: 118| Step: 0
Training loss: 1.8285465240478516
Validation loss: 1.992462694644928

Epoch: 5| Step: 1
Training loss: 1.6608951091766357
Validation loss: 1.9940153459707897

Epoch: 5| Step: 2
Training loss: 1.4717336893081665
Validation loss: 2.0009221682945886

Epoch: 5| Step: 3
Training loss: 2.158822536468506
Validation loss: 2.0022829174995422

Epoch: 5| Step: 4
Training loss: 2.356733798980713
Validation loss: 2.0167346199353537

Epoch: 5| Step: 5
Training loss: 2.0835049152374268
Validation loss: 2.017179807027181

Epoch: 5| Step: 6
Training loss: 2.6559383869171143
Validation loss: 2.022560482223829

Epoch: 5| Step: 7
Training loss: 1.9640445709228516
Validation loss: 2.024610032637914

Epoch: 5| Step: 8
Training loss: 2.4566378593444824
Validation loss: 2.0260743697484336

Epoch: 5| Step: 9
Training loss: 2.414032459259033
Validation loss: 2.035290156801542

Epoch: 5| Step: 10
Training loss: 2.1443467140197754
Validation loss: 2.0294995605945587

Epoch: 5| Step: 11
Training loss: 2.026944637298584
Validation loss: 2.036107301712036

Epoch: 119| Step: 0
Training loss: 2.2308926582336426
Validation loss: 2.0298323730627694

Epoch: 5| Step: 1
Training loss: 1.6638996601104736
Validation loss: 2.0291270514329276

Epoch: 5| Step: 2
Training loss: 2.9220235347747803
Validation loss: 2.025217672189077

Epoch: 5| Step: 3
Training loss: 2.2557177543640137
Validation loss: 2.0134626229604087

Epoch: 5| Step: 4
Training loss: 1.9301786422729492
Validation loss: 2.0061736355225244

Epoch: 5| Step: 5
Training loss: 1.743295669555664
Validation loss: 1.9989506949981053

Epoch: 5| Step: 6
Training loss: 1.9354671239852905
Validation loss: 2.0026684254407883

Epoch: 5| Step: 7
Training loss: 1.8079051971435547
Validation loss: 1.9909077286720276

Epoch: 5| Step: 8
Training loss: 2.4061105251312256
Validation loss: 2.0025233328342438

Epoch: 5| Step: 9
Training loss: 1.949032187461853
Validation loss: 2.0005200505256653

Epoch: 5| Step: 10
Training loss: 2.449990749359131
Validation loss: 2.003725290298462

Epoch: 5| Step: 11
Training loss: 1.8559540510177612
Validation loss: 1.99919031560421

Epoch: 120| Step: 0
Training loss: 2.163562297821045
Validation loss: 1.9962006856997807

Epoch: 5| Step: 1
Training loss: 2.0857582092285156
Validation loss: 1.9991228530804317

Epoch: 5| Step: 2
Training loss: 2.2426164150238037
Validation loss: 1.9980598042408626

Epoch: 5| Step: 3
Training loss: 1.9173305034637451
Validation loss: 1.9990678677956264

Epoch: 5| Step: 4
Training loss: 1.830780267715454
Validation loss: 2.0034804393847785

Epoch: 5| Step: 5
Training loss: 2.3733417987823486
Validation loss: 2.000359450777372

Epoch: 5| Step: 6
Training loss: 2.128401279449463
Validation loss: 1.9980757683515549

Epoch: 5| Step: 7
Training loss: 2.003936767578125
Validation loss: 2.008152743180593

Epoch: 5| Step: 8
Training loss: 1.8814373016357422
Validation loss: 1.99842265745004

Epoch: 5| Step: 9
Training loss: 1.85421621799469
Validation loss: 2.007962162295977

Epoch: 5| Step: 10
Training loss: 2.3529036045074463
Validation loss: 2.012360284725825

Epoch: 5| Step: 11
Training loss: 2.8498694896698
Validation loss: 2.009214093287786

Epoch: 121| Step: 0
Training loss: 2.3860063552856445
Validation loss: 2.005351444085439

Epoch: 5| Step: 1
Training loss: 1.8599990606307983
Validation loss: 2.010028044382731

Epoch: 5| Step: 2
Training loss: 2.3228325843811035
Validation loss: 2.009494041403135

Epoch: 5| Step: 3
Training loss: 2.272947311401367
Validation loss: 2.0108869473139444

Epoch: 5| Step: 4
Training loss: 1.9009835720062256
Validation loss: 2.0044040034214654

Epoch: 5| Step: 5
Training loss: 2.442751169204712
Validation loss: 2.00980281829834

Epoch: 5| Step: 6
Training loss: 2.2382583618164062
Validation loss: 2.0094981094201407

Epoch: 5| Step: 7
Training loss: 2.069202423095703
Validation loss: 2.0138839036226273

Epoch: 5| Step: 8
Training loss: 1.9906316995620728
Validation loss: 2.0152322252591452

Epoch: 5| Step: 9
Training loss: 2.129415988922119
Validation loss: 2.0163207749525704

Epoch: 5| Step: 10
Training loss: 1.3768036365509033
Validation loss: 2.0250914047161737

Epoch: 5| Step: 11
Training loss: 1.5923715829849243
Validation loss: 2.0266824712355933

Epoch: 122| Step: 0
Training loss: 2.207036256790161
Validation loss: 2.0305292258659997

Epoch: 5| Step: 1
Training loss: 1.7080962657928467
Validation loss: 2.0394328832626343

Epoch: 5| Step: 2
Training loss: 2.0429985523223877
Validation loss: 2.037359833717346

Epoch: 5| Step: 3
Training loss: 2.0569217205047607
Validation loss: 2.028846964240074

Epoch: 5| Step: 4
Training loss: 2.2519571781158447
Validation loss: 2.030980333685875

Epoch: 5| Step: 5
Training loss: 2.05267071723938
Validation loss: 2.038174867630005

Epoch: 5| Step: 6
Training loss: 2.047553539276123
Validation loss: 2.0284731090068817

Epoch: 5| Step: 7
Training loss: 1.9357128143310547
Validation loss: 2.038001611828804

Epoch: 5| Step: 8
Training loss: 2.077838659286499
Validation loss: 2.03437776863575

Epoch: 5| Step: 9
Training loss: 2.312232255935669
Validation loss: 2.037919913729032

Epoch: 5| Step: 10
Training loss: 2.0062618255615234
Validation loss: 2.039075334866842

Epoch: 5| Step: 11
Training loss: 1.8961408138275146
Validation loss: 2.041709288954735

Epoch: 123| Step: 0
Training loss: 1.7289454936981201
Validation loss: 2.035658741990725

Epoch: 5| Step: 1
Training loss: 1.9201629161834717
Validation loss: 2.0399747292200723

Epoch: 5| Step: 2
Training loss: 2.1741561889648438
Validation loss: 2.042199785510699

Epoch: 5| Step: 3
Training loss: 1.4493968486785889
Validation loss: 2.02717188000679

Epoch: 5| Step: 4
Training loss: 2.36720609664917
Validation loss: 2.0382739355166755

Epoch: 5| Step: 5
Training loss: 1.4722392559051514
Validation loss: 2.052435869971911

Epoch: 5| Step: 6
Training loss: 2.3212876319885254
Validation loss: 2.0408400297164917

Epoch: 5| Step: 7
Training loss: 1.933828592300415
Validation loss: 2.045157010356585

Epoch: 5| Step: 8
Training loss: 2.7142913341522217
Validation loss: 2.0460678339004517

Epoch: 5| Step: 9
Training loss: 2.3245251178741455
Validation loss: 2.0526708513498306

Epoch: 5| Step: 10
Training loss: 2.300812005996704
Validation loss: 2.0470680395762124

Epoch: 5| Step: 11
Training loss: 1.934948205947876
Validation loss: 2.0480901847283044

Epoch: 124| Step: 0
Training loss: 2.0650267601013184
Validation loss: 2.0434039384126663

Epoch: 5| Step: 1
Training loss: 1.6804659366607666
Validation loss: 2.0308199524879456

Epoch: 5| Step: 2
Training loss: 1.4518845081329346
Validation loss: 2.027414306998253

Epoch: 5| Step: 3
Training loss: 2.1525096893310547
Validation loss: 2.0187431077162423

Epoch: 5| Step: 4
Training loss: 1.8339817523956299
Validation loss: 2.009637013077736

Epoch: 5| Step: 5
Training loss: 2.0756256580352783
Validation loss: 2.012899781266848

Epoch: 5| Step: 6
Training loss: 2.249807357788086
Validation loss: 2.0009237229824066

Epoch: 5| Step: 7
Training loss: 2.0402793884277344
Validation loss: 2.0075481683015823

Epoch: 5| Step: 8
Training loss: 2.087780475616455
Validation loss: 2.013727590441704

Epoch: 5| Step: 9
Training loss: 2.380164384841919
Validation loss: 2.0134946356217065

Epoch: 5| Step: 10
Training loss: 2.92939829826355
Validation loss: 2.0086121608813605

Epoch: 5| Step: 11
Training loss: 2.7076408863067627
Validation loss: 2.0084566374619803

Epoch: 125| Step: 0
Training loss: 2.596294403076172
Validation loss: 2.013767038782438

Epoch: 5| Step: 1
Training loss: 2.066347360610962
Validation loss: 2.0088341534137726

Epoch: 5| Step: 2
Training loss: 1.8187053203582764
Validation loss: 2.0122780948877335

Epoch: 5| Step: 3
Training loss: 2.3237969875335693
Validation loss: 2.016330743829409

Epoch: 5| Step: 4
Training loss: 2.290978193283081
Validation loss: 2.0189256221055984

Epoch: 5| Step: 5
Training loss: 1.8762891292572021
Validation loss: 2.0176490594943366

Epoch: 5| Step: 6
Training loss: 2.075392246246338
Validation loss: 2.022152215242386

Epoch: 5| Step: 7
Training loss: 2.0865979194641113
Validation loss: 2.021470660964648

Epoch: 5| Step: 8
Training loss: 1.833148717880249
Validation loss: 2.018274555603663

Epoch: 5| Step: 9
Training loss: 2.4101014137268066
Validation loss: 2.0267715454101562

Epoch: 5| Step: 10
Training loss: 1.6923625469207764
Validation loss: 2.0241428365310035

Epoch: 5| Step: 11
Training loss: 1.092897653579712
Validation loss: 2.0268691380818686

Epoch: 126| Step: 0
Training loss: 2.038771152496338
Validation loss: 2.02377687394619

Epoch: 5| Step: 1
Training loss: 1.900579810142517
Validation loss: 2.0328118205070496

Epoch: 5| Step: 2
Training loss: 2.7245917320251465
Validation loss: 2.037178019682566

Epoch: 5| Step: 3
Training loss: 1.3724576234817505
Validation loss: 2.0262019832928977

Epoch: 5| Step: 4
Training loss: 2.620938777923584
Validation loss: 2.023137812813123

Epoch: 5| Step: 5
Training loss: 2.1259078979492188
Validation loss: 2.035366411010424

Epoch: 5| Step: 6
Training loss: 1.6622295379638672
Validation loss: 2.037668431798617

Epoch: 5| Step: 7
Training loss: 2.25093412399292
Validation loss: 2.0288235942522683

Epoch: 5| Step: 8
Training loss: 2.1866047382354736
Validation loss: 2.0311128050088882

Epoch: 5| Step: 9
Training loss: 2.2973179817199707
Validation loss: 2.0315962731838226

Epoch: 5| Step: 10
Training loss: 1.9289219379425049
Validation loss: 2.0270348340272903

Epoch: 5| Step: 11
Training loss: 1.506917953491211
Validation loss: 2.0283836871385574

Epoch: 127| Step: 0
Training loss: 1.9672515392303467
Validation loss: 2.0194335132837296

Epoch: 5| Step: 1
Training loss: 1.7857792377471924
Validation loss: 2.021049603819847

Epoch: 5| Step: 2
Training loss: 2.259699583053589
Validation loss: 2.0272541691859565

Epoch: 5| Step: 3
Training loss: 2.102207660675049
Validation loss: 2.0306661625703177

Epoch: 5| Step: 4
Training loss: 1.7735286951065063
Validation loss: 2.023966838916143

Epoch: 5| Step: 5
Training loss: 2.205461025238037
Validation loss: 2.0230262527863183

Epoch: 5| Step: 6
Training loss: 2.133983850479126
Validation loss: 2.0201011846462884

Epoch: 5| Step: 7
Training loss: 2.6628639698028564
Validation loss: 2.016823043425878

Epoch: 5| Step: 8
Training loss: 2.00272274017334
Validation loss: 2.0306762804587684

Epoch: 5| Step: 9
Training loss: 2.0183451175689697
Validation loss: 2.0265462895234427

Epoch: 5| Step: 10
Training loss: 1.8273096084594727
Validation loss: 2.0301256825526557

Epoch: 5| Step: 11
Training loss: 2.371922016143799
Validation loss: 2.0241728127002716

Epoch: 128| Step: 0
Training loss: 2.4597015380859375
Validation loss: 2.024938518802325

Epoch: 5| Step: 1
Training loss: 1.8229938745498657
Validation loss: 2.0284437338511148

Epoch: 5| Step: 2
Training loss: 2.4896650314331055
Validation loss: 2.019461174805959

Epoch: 5| Step: 3
Training loss: 2.265717029571533
Validation loss: 2.0271154244740806

Epoch: 5| Step: 4
Training loss: 1.929560899734497
Validation loss: 2.013868674635887

Epoch: 5| Step: 5
Training loss: 2.0943400859832764
Validation loss: 2.022283131877581

Epoch: 5| Step: 6
Training loss: 1.9832124710083008
Validation loss: 2.0232015202442803

Epoch: 5| Step: 7
Training loss: 2.3071935176849365
Validation loss: 2.0168448636929193

Epoch: 5| Step: 8
Training loss: 1.8089015483856201
Validation loss: 2.0267313619454703

Epoch: 5| Step: 9
Training loss: 1.6395893096923828
Validation loss: 2.025712177157402

Epoch: 5| Step: 10
Training loss: 2.061913013458252
Validation loss: 2.0224312245845795

Epoch: 5| Step: 11
Training loss: 1.5105431079864502
Validation loss: 2.0277707874774933

Epoch: 129| Step: 0
Training loss: 2.5390372276306152
Validation loss: 2.032939702272415

Epoch: 5| Step: 1
Training loss: 1.6559619903564453
Validation loss: 2.0340991069873176

Epoch: 5| Step: 2
Training loss: 2.289574146270752
Validation loss: 2.0344864378372827

Epoch: 5| Step: 3
Training loss: 2.5080971717834473
Validation loss: 2.0305185317993164

Epoch: 5| Step: 4
Training loss: 1.8065955638885498
Validation loss: 2.0436024020115533

Epoch: 5| Step: 5
Training loss: 2.246842622756958
Validation loss: 2.0294920206069946

Epoch: 5| Step: 6
Training loss: 1.652029037475586
Validation loss: 2.039391979575157

Epoch: 5| Step: 7
Training loss: 2.152830123901367
Validation loss: 2.0386208295822144

Epoch: 5| Step: 8
Training loss: 2.131258010864258
Validation loss: 2.026381487647692

Epoch: 5| Step: 9
Training loss: 1.824156403541565
Validation loss: 2.0313001771767936

Epoch: 5| Step: 10
Training loss: 2.1151113510131836
Validation loss: 2.026593322555224

Epoch: 5| Step: 11
Training loss: 1.7470201253890991
Validation loss: 2.024836520353953

Epoch: 130| Step: 0
Training loss: 1.9606975317001343
Validation loss: 2.022730881969134

Epoch: 5| Step: 1
Training loss: 2.6560111045837402
Validation loss: 2.0191490600506463

Epoch: 5| Step: 2
Training loss: 2.5427963733673096
Validation loss: 2.021107494831085

Epoch: 5| Step: 3
Training loss: 1.6634461879730225
Validation loss: 2.027063712477684

Epoch: 5| Step: 4
Training loss: 1.7006021738052368
Validation loss: 2.0182931373516717

Epoch: 5| Step: 5
Training loss: 1.6305153369903564
Validation loss: 2.0220419615507126

Epoch: 5| Step: 6
Training loss: 2.295325756072998
Validation loss: 2.01665922999382

Epoch: 5| Step: 7
Training loss: 2.256659746170044
Validation loss: 2.017957096298536

Epoch: 5| Step: 8
Training loss: 2.0107710361480713
Validation loss: 2.0274981359640756

Epoch: 5| Step: 9
Training loss: 1.9105663299560547
Validation loss: 2.015362486243248

Epoch: 5| Step: 10
Training loss: 2.42747163772583
Validation loss: 2.020338679353396

Epoch: 5| Step: 11
Training loss: 1.329323410987854
Validation loss: 2.0145975102980933

Epoch: 131| Step: 0
Training loss: 2.2215569019317627
Validation loss: 2.0235239068667092

Epoch: 5| Step: 1
Training loss: 2.138969898223877
Validation loss: 2.029910529653231

Epoch: 5| Step: 2
Training loss: 2.1705079078674316
Validation loss: 2.025418962041537

Epoch: 5| Step: 3
Training loss: 2.0349459648132324
Validation loss: 2.0201425552368164

Epoch: 5| Step: 4
Training loss: 2.37243390083313
Validation loss: 2.0279377599557242

Epoch: 5| Step: 5
Training loss: 2.414215326309204
Validation loss: 2.0302468786636987

Epoch: 5| Step: 6
Training loss: 1.9452526569366455
Validation loss: 2.035179282228152

Epoch: 5| Step: 7
Training loss: 1.7736310958862305
Validation loss: 2.0301740368207297

Epoch: 5| Step: 8
Training loss: 1.8975512981414795
Validation loss: 2.0349557797114053

Epoch: 5| Step: 9
Training loss: 1.948568344116211
Validation loss: 2.0341126372416816

Epoch: 5| Step: 10
Training loss: 1.6871963739395142
Validation loss: 2.0396481305360794

Epoch: 5| Step: 11
Training loss: 1.6552209854125977
Validation loss: 2.0467518965403237

Epoch: 132| Step: 0
Training loss: 2.039637565612793
Validation loss: 2.04076520105203

Epoch: 5| Step: 1
Training loss: 1.8005520105361938
Validation loss: 2.0345634669065475

Epoch: 5| Step: 2
Training loss: 2.339994430541992
Validation loss: 2.048076699177424

Epoch: 5| Step: 3
Training loss: 2.3254051208496094
Validation loss: 2.0460718323787055

Epoch: 5| Step: 4
Training loss: 2.08298921585083
Validation loss: 2.046581342816353

Epoch: 5| Step: 5
Training loss: 1.9752938747406006
Validation loss: 2.055553659796715

Epoch: 5| Step: 6
Training loss: 2.1544837951660156
Validation loss: 2.0437296678622565

Epoch: 5| Step: 7
Training loss: 1.7408803701400757
Validation loss: 2.0526600976785025

Epoch: 5| Step: 8
Training loss: 2.068815231323242
Validation loss: 2.044439742962519

Epoch: 5| Step: 9
Training loss: 1.9737396240234375
Validation loss: 2.0491299529870353

Epoch: 5| Step: 10
Training loss: 1.804843544960022
Validation loss: 2.0428173591693244

Epoch: 5| Step: 11
Training loss: 2.278520107269287
Validation loss: 2.041598300139109

Epoch: 133| Step: 0
Training loss: 2.106873035430908
Validation loss: 2.0314531922340393

Epoch: 5| Step: 1
Training loss: 2.2156784534454346
Validation loss: 2.0301147053639093

Epoch: 5| Step: 2
Training loss: 2.037996768951416
Validation loss: 2.030418892701467

Epoch: 5| Step: 3
Training loss: 1.6964502334594727
Validation loss: 2.019313926498095

Epoch: 5| Step: 4
Training loss: 2.145904302597046
Validation loss: 2.022698611021042

Epoch: 5| Step: 5
Training loss: 2.549475908279419
Validation loss: 2.034434954325358

Epoch: 5| Step: 6
Training loss: 2.145272731781006
Validation loss: 2.0239228208859763

Epoch: 5| Step: 7
Training loss: 2.1806087493896484
Validation loss: 2.020820235212644

Epoch: 5| Step: 8
Training loss: 2.075859785079956
Validation loss: 2.020524486899376

Epoch: 5| Step: 9
Training loss: 1.8631788492202759
Validation loss: 2.0155337502559028

Epoch: 5| Step: 10
Training loss: 2.331779718399048
Validation loss: 2.007429376244545

Epoch: 5| Step: 11
Training loss: 1.334439754486084
Validation loss: 2.011632576584816

Epoch: 134| Step: 0
Training loss: 2.2634637355804443
Validation loss: 2.0140778372685113

Epoch: 5| Step: 1
Training loss: 2.1515114307403564
Validation loss: 2.007559135556221

Epoch: 5| Step: 2
Training loss: 1.8261315822601318
Validation loss: 2.0088443706432977

Epoch: 5| Step: 3
Training loss: 2.3247427940368652
Validation loss: 2.0090879599253335

Epoch: 5| Step: 4
Training loss: 2.413945436477661
Validation loss: 2.003674512108167

Epoch: 5| Step: 5
Training loss: 1.7689898014068604
Validation loss: 1.9981455206871033

Epoch: 5| Step: 6
Training loss: 2.0251784324645996
Validation loss: 1.9956286152203877

Epoch: 5| Step: 7
Training loss: 2.265820026397705
Validation loss: 2.004549190402031

Epoch: 5| Step: 8
Training loss: 2.2807743549346924
Validation loss: 2.0162801891565323

Epoch: 5| Step: 9
Training loss: 1.9482589960098267
Validation loss: 2.0235241850217185

Epoch: 5| Step: 10
Training loss: 1.8397448062896729
Validation loss: 2.023954540491104

Epoch: 5| Step: 11
Training loss: 1.2555922269821167
Validation loss: 2.0275843838850656

Epoch: 135| Step: 0
Training loss: 2.0612711906433105
Validation loss: 2.026756520072619

Epoch: 5| Step: 1
Training loss: 2.3866496086120605
Validation loss: 2.023280084133148

Epoch: 5| Step: 2
Training loss: 2.5393590927124023
Validation loss: 2.016899049282074

Epoch: 5| Step: 3
Training loss: 1.7385120391845703
Validation loss: 2.0224900990724564

Epoch: 5| Step: 4
Training loss: 2.0066304206848145
Validation loss: 2.0156763096650443

Epoch: 5| Step: 5
Training loss: 1.9767017364501953
Validation loss: 2.0244691471258798

Epoch: 5| Step: 6
Training loss: 1.7270427942276
Validation loss: 2.029599820574125

Epoch: 5| Step: 7
Training loss: 1.691631555557251
Validation loss: 2.0252640694379807

Epoch: 5| Step: 8
Training loss: 2.338125705718994
Validation loss: 2.029765655597051

Epoch: 5| Step: 9
Training loss: 2.2250499725341797
Validation loss: 2.035388966401418

Epoch: 5| Step: 10
Training loss: 1.99147629737854
Validation loss: 2.0467413614193597

Epoch: 5| Step: 11
Training loss: 1.489662528038025
Validation loss: 2.0555225114027658

Epoch: 136| Step: 0
Training loss: 2.135958194732666
Validation loss: 2.0488254924615226

Epoch: 5| Step: 1
Training loss: 1.7558006048202515
Validation loss: 2.065268248319626

Epoch: 5| Step: 2
Training loss: 2.311755657196045
Validation loss: 2.065201088786125

Epoch: 5| Step: 3
Training loss: 1.8706610202789307
Validation loss: 2.0608245929082236

Epoch: 5| Step: 4
Training loss: 1.7440840005874634
Validation loss: 2.0478119403123856

Epoch: 5| Step: 5
Training loss: 1.8486995697021484
Validation loss: 2.056282470623652

Epoch: 5| Step: 6
Training loss: 2.2704319953918457
Validation loss: 2.051602308948835

Epoch: 5| Step: 7
Training loss: 2.413726329803467
Validation loss: 2.049605111281077

Epoch: 5| Step: 8
Training loss: 2.3403587341308594
Validation loss: 2.046650712688764

Epoch: 5| Step: 9
Training loss: 1.766029953956604
Validation loss: 2.042338048418363

Epoch: 5| Step: 10
Training loss: 2.144240140914917
Validation loss: 2.0491236994663873

Epoch: 5| Step: 11
Training loss: 1.4793026447296143
Validation loss: 2.0485412875811257

Epoch: 137| Step: 0
Training loss: 2.0008435249328613
Validation loss: 2.0452824930349984

Epoch: 5| Step: 1
Training loss: 2.360764980316162
Validation loss: 2.0620178232590356

Epoch: 5| Step: 2
Training loss: 2.5829806327819824
Validation loss: 2.0550450483957925

Epoch: 5| Step: 3
Training loss: 1.6628137826919556
Validation loss: 2.052521824836731

Epoch: 5| Step: 4
Training loss: 2.430950880050659
Validation loss: 2.056932951013247

Epoch: 5| Step: 5
Training loss: 2.0914504528045654
Validation loss: 2.047341207663218

Epoch: 5| Step: 6
Training loss: 2.077610731124878
Validation loss: 2.059900869925817

Epoch: 5| Step: 7
Training loss: 1.6737200021743774
Validation loss: 2.0681897004445395

Epoch: 5| Step: 8
Training loss: 1.0539048910140991
Validation loss: 2.0830082148313522

Epoch: 5| Step: 9
Training loss: 2.0449059009552
Validation loss: 2.0785146752993264

Epoch: 5| Step: 10
Training loss: 2.419421672821045
Validation loss: 2.070540726184845

Epoch: 5| Step: 11
Training loss: 2.2836878299713135
Validation loss: 2.079461952050527

Epoch: 138| Step: 0
Training loss: 2.15103816986084
Validation loss: 2.064260169863701

Epoch: 5| Step: 1
Training loss: 1.7826659679412842
Validation loss: 2.0436214208602905

Epoch: 5| Step: 2
Training loss: 2.3470072746276855
Validation loss: 2.0434412906567254

Epoch: 5| Step: 3
Training loss: 1.816344976425171
Validation loss: 2.0431731194257736

Epoch: 5| Step: 4
Training loss: 1.8044564723968506
Validation loss: 2.042608658472697

Epoch: 5| Step: 5
Training loss: 2.219651699066162
Validation loss: 2.0459023118019104

Epoch: 5| Step: 6
Training loss: 2.450915575027466
Validation loss: 2.03826113541921

Epoch: 5| Step: 7
Training loss: 2.2312071323394775
Validation loss: 2.0432825734217963

Epoch: 5| Step: 8
Training loss: 2.016044855117798
Validation loss: 2.0521134734153748

Epoch: 5| Step: 9
Training loss: 1.718197226524353
Validation loss: 2.060123493274053

Epoch: 5| Step: 10
Training loss: 1.8714933395385742
Validation loss: 2.062773029009501

Epoch: 5| Step: 11
Training loss: 2.623316526412964
Validation loss: 2.0578869382540383

Epoch: 139| Step: 0
Training loss: 2.7876434326171875
Validation loss: 2.071116656064987

Epoch: 5| Step: 1
Training loss: 2.754106044769287
Validation loss: 2.0744909942150116

Epoch: 5| Step: 2
Training loss: 2.1027486324310303
Validation loss: 2.065658852458

Epoch: 5| Step: 3
Training loss: 1.9009281396865845
Validation loss: 2.0748583177725473

Epoch: 5| Step: 4
Training loss: 1.8313658237457275
Validation loss: 2.069553335507711

Epoch: 5| Step: 5
Training loss: 1.7766284942626953
Validation loss: 2.0644765396912894

Epoch: 5| Step: 6
Training loss: 2.1971850395202637
Validation loss: 2.0596041133006415

Epoch: 5| Step: 7
Training loss: 1.7708966732025146
Validation loss: 2.0540989389022193

Epoch: 5| Step: 8
Training loss: 1.686676025390625
Validation loss: 2.038669923941294

Epoch: 5| Step: 9
Training loss: 1.8578815460205078
Validation loss: 2.0421811242898307

Epoch: 5| Step: 10
Training loss: 1.832437515258789
Validation loss: 2.0393460939327874

Epoch: 5| Step: 11
Training loss: 1.9412686824798584
Validation loss: 2.04292864104112

Epoch: 140| Step: 0
Training loss: 2.0057029724121094
Validation loss: 2.0374657660722733

Epoch: 5| Step: 1
Training loss: 2.2706515789031982
Validation loss: 2.0401916603247323

Epoch: 5| Step: 2
Training loss: 1.9749805927276611
Validation loss: 2.043128028512001

Epoch: 5| Step: 3
Training loss: 1.821599006652832
Validation loss: 2.0392102797826133

Epoch: 5| Step: 4
Training loss: 2.1353466510772705
Validation loss: 2.0484064469734826

Epoch: 5| Step: 5
Training loss: 1.6008551120758057
Validation loss: 2.051980515321096

Epoch: 5| Step: 6
Training loss: 2.2786781787872314
Validation loss: 2.0552369256814322

Epoch: 5| Step: 7
Training loss: 2.076526641845703
Validation loss: 2.0684777845939

Epoch: 5| Step: 8
Training loss: 2.3576626777648926
Validation loss: 2.0677447766065598

Epoch: 5| Step: 9
Training loss: 1.5727074146270752
Validation loss: 2.0691550026337304

Epoch: 5| Step: 10
Training loss: 2.3363919258117676
Validation loss: 2.0697253247102103

Epoch: 5| Step: 11
Training loss: 1.5267529487609863
Validation loss: 2.0678337117036185

Epoch: 141| Step: 0
Training loss: 2.3432674407958984
Validation loss: 2.0597897469997406

Epoch: 5| Step: 1
Training loss: 1.71832275390625
Validation loss: 2.063065225879351

Epoch: 5| Step: 2
Training loss: 1.7311569452285767
Validation loss: 2.0695694188276925

Epoch: 5| Step: 3
Training loss: 2.216895341873169
Validation loss: 2.064506803949674

Epoch: 5| Step: 4
Training loss: 1.8007266521453857
Validation loss: 2.060647522409757

Epoch: 5| Step: 5
Training loss: 1.9544118642807007
Validation loss: 2.0580907315015793

Epoch: 5| Step: 6
Training loss: 2.4644041061401367
Validation loss: 2.067479362090429

Epoch: 5| Step: 7
Training loss: 1.6954025030136108
Validation loss: 2.076776683330536

Epoch: 5| Step: 8
Training loss: 1.908837080001831
Validation loss: 2.084904834628105

Epoch: 5| Step: 9
Training loss: 2.3027687072753906
Validation loss: 2.083216001590093

Epoch: 5| Step: 10
Training loss: 2.1242992877960205
Validation loss: 2.093418742219607

Epoch: 5| Step: 11
Training loss: 2.1599888801574707
Validation loss: 2.0750933488210044

Epoch: 142| Step: 0
Training loss: 1.8837074041366577
Validation loss: 2.0880584567785263

Epoch: 5| Step: 1
Training loss: 1.6029564142227173
Validation loss: 2.07010510067145

Epoch: 5| Step: 2
Training loss: 1.7992817163467407
Validation loss: 2.0730124016602836

Epoch: 5| Step: 3
Training loss: 1.7833582162857056
Validation loss: 2.082636217276255

Epoch: 5| Step: 4
Training loss: 1.7196590900421143
Validation loss: 2.0809647341569266

Epoch: 5| Step: 5
Training loss: 1.6004054546356201
Validation loss: 2.0761988013982773

Epoch: 5| Step: 6
Training loss: 2.8242082595825195
Validation loss: 2.066554327805837

Epoch: 5| Step: 7
Training loss: 1.9877948760986328
Validation loss: 2.0641393810510635

Epoch: 5| Step: 8
Training loss: 2.5834403038024902
Validation loss: 2.049182484547297

Epoch: 5| Step: 9
Training loss: 2.246152400970459
Validation loss: 2.045113836725553

Epoch: 5| Step: 10
Training loss: 2.2175230979919434
Validation loss: 2.0405925114949546

Epoch: 5| Step: 11
Training loss: 1.962806224822998
Validation loss: 2.043510620792707

Epoch: 143| Step: 0
Training loss: 2.142652988433838
Validation loss: 2.039582739273707

Epoch: 5| Step: 1
Training loss: 2.0436394214630127
Validation loss: 2.048731421430906

Epoch: 5| Step: 2
Training loss: 1.8884817361831665
Validation loss: 2.035294542709986

Epoch: 5| Step: 3
Training loss: 2.1081199645996094
Validation loss: 2.0468652844429016

Epoch: 5| Step: 4
Training loss: 2.092193603515625
Validation loss: 2.0464174151420593

Epoch: 5| Step: 5
Training loss: 1.9895212650299072
Validation loss: 2.059119919935862

Epoch: 5| Step: 6
Training loss: 1.755475401878357
Validation loss: 2.0701994945605597

Epoch: 5| Step: 7
Training loss: 2.189892292022705
Validation loss: 2.0727251966794333

Epoch: 5| Step: 8
Training loss: 2.3611626625061035
Validation loss: 2.0816483994325004

Epoch: 5| Step: 9
Training loss: 2.050952672958374
Validation loss: 2.0810196548700333

Epoch: 5| Step: 10
Training loss: 1.9201234579086304
Validation loss: 2.087505668401718

Epoch: 5| Step: 11
Training loss: 2.398850440979004
Validation loss: 2.083204577366511

Epoch: 144| Step: 0
Training loss: 1.7119743824005127
Validation loss: 2.08201535542806

Epoch: 5| Step: 1
Training loss: 1.7195062637329102
Validation loss: 2.08075679341952

Epoch: 5| Step: 2
Training loss: 1.881737470626831
Validation loss: 2.0756119241317115

Epoch: 5| Step: 3
Training loss: 2.4138989448547363
Validation loss: 2.071635161836942

Epoch: 5| Step: 4
Training loss: 1.7924734354019165
Validation loss: 2.065094699462255

Epoch: 5| Step: 5
Training loss: 2.2546257972717285
Validation loss: 2.0502192825078964

Epoch: 5| Step: 6
Training loss: 2.288841724395752
Validation loss: 2.0627519388993583

Epoch: 5| Step: 7
Training loss: 2.764766216278076
Validation loss: 2.051577150821686

Epoch: 5| Step: 8
Training loss: 1.7696453332901
Validation loss: 2.058002586166064

Epoch: 5| Step: 9
Training loss: 1.9259402751922607
Validation loss: 2.0608139683802924

Epoch: 5| Step: 10
Training loss: 2.1174468994140625
Validation loss: 2.066820631424586

Epoch: 5| Step: 11
Training loss: 1.140129804611206
Validation loss: 2.074781149625778

Epoch: 145| Step: 0
Training loss: 1.8473228216171265
Validation loss: 2.065751080711683

Epoch: 5| Step: 1
Training loss: 2.0225257873535156
Validation loss: 2.0693936546643577

Epoch: 5| Step: 2
Training loss: 1.9647395610809326
Validation loss: 2.0750297158956528

Epoch: 5| Step: 3
Training loss: 2.200373888015747
Validation loss: 2.0661285370588303

Epoch: 5| Step: 4
Training loss: 1.7745506763458252
Validation loss: 2.0694004644950232

Epoch: 5| Step: 5
Training loss: 2.105699062347412
Validation loss: 2.078711435198784

Epoch: 5| Step: 6
Training loss: 1.7868878841400146
Validation loss: 2.077539548277855

Epoch: 5| Step: 7
Training loss: 2.236401319503784
Validation loss: 2.0753766695658364

Epoch: 5| Step: 8
Training loss: 1.7198187112808228
Validation loss: 2.0718473941087723

Epoch: 5| Step: 9
Training loss: 1.8774627447128296
Validation loss: 2.081866050759951

Epoch: 5| Step: 10
Training loss: 2.536318302154541
Validation loss: 2.0787431796391806

Epoch: 5| Step: 11
Training loss: 1.9201619625091553
Validation loss: 2.0796617368857064

Epoch: 146| Step: 0
Training loss: 2.04772686958313
Validation loss: 2.0683434953292212

Epoch: 5| Step: 1
Training loss: 1.280584692955017
Validation loss: 2.0532958805561066

Epoch: 5| Step: 2
Training loss: 2.083890914916992
Validation loss: 2.056822031736374

Epoch: 5| Step: 3
Training loss: 2.1389458179473877
Validation loss: 2.056729813416799

Epoch: 5| Step: 4
Training loss: 2.510939121246338
Validation loss: 2.0585571080446243

Epoch: 5| Step: 5
Training loss: 2.0448689460754395
Validation loss: 2.05573641260465

Epoch: 5| Step: 6
Training loss: 2.469977855682373
Validation loss: 2.0654054333766303

Epoch: 5| Step: 7
Training loss: 2.041771650314331
Validation loss: 2.064984435836474

Epoch: 5| Step: 8
Training loss: 1.8609689474105835
Validation loss: 2.0611195166905723

Epoch: 5| Step: 9
Training loss: 1.9252903461456299
Validation loss: 2.071986640493075

Epoch: 5| Step: 10
Training loss: 1.8501670360565186
Validation loss: 2.068602661291758

Epoch: 5| Step: 11
Training loss: 1.5205316543579102
Validation loss: 2.0761673202117286

Epoch: 147| Step: 0
Training loss: 1.857629418373108
Validation loss: 2.066410794854164

Epoch: 5| Step: 1
Training loss: 1.9546922445297241
Validation loss: 2.0665498028198876

Epoch: 5| Step: 2
Training loss: 1.7707040309906006
Validation loss: 2.0541785111029944

Epoch: 5| Step: 3
Training loss: 2.391608238220215
Validation loss: 2.0660183827082315

Epoch: 5| Step: 4
Training loss: 2.6873254776000977
Validation loss: 2.0587842166423798

Epoch: 5| Step: 5
Training loss: 2.0686068534851074
Validation loss: 2.047863006591797

Epoch: 5| Step: 6
Training loss: 2.0099127292633057
Validation loss: 2.0683167229096093

Epoch: 5| Step: 7
Training loss: 1.9113773107528687
Validation loss: 2.0672805110613504

Epoch: 5| Step: 8
Training loss: 1.6876678466796875
Validation loss: 2.081315358479818

Epoch: 5| Step: 9
Training loss: 1.6253488063812256
Validation loss: 2.0746887922286987

Epoch: 5| Step: 10
Training loss: 2.0616414546966553
Validation loss: 2.0794062366088233

Epoch: 5| Step: 11
Training loss: 2.444927215576172
Validation loss: 2.0750589619080224

Epoch: 148| Step: 0
Training loss: 1.5735739469528198
Validation loss: 2.0641033152739205

Epoch: 5| Step: 1
Training loss: 2.5520987510681152
Validation loss: 2.055266350507736

Epoch: 5| Step: 2
Training loss: 1.8986294269561768
Validation loss: 2.0557589580615363

Epoch: 5| Step: 3
Training loss: 1.7262487411499023
Validation loss: 2.055838723977407

Epoch: 5| Step: 4
Training loss: 2.189831256866455
Validation loss: 2.048998167117437

Epoch: 5| Step: 5
Training loss: 2.1717162132263184
Validation loss: 2.046932970484098

Epoch: 5| Step: 6
Training loss: 1.7440147399902344
Validation loss: 2.048868308464686

Epoch: 5| Step: 7
Training loss: 1.7459018230438232
Validation loss: 2.0557070473829904

Epoch: 5| Step: 8
Training loss: 2.0143821239471436
Validation loss: 2.058006778359413

Epoch: 5| Step: 9
Training loss: 2.1110141277313232
Validation loss: 2.065526326497396

Epoch: 5| Step: 10
Training loss: 2.30137300491333
Validation loss: 2.0766938577095666

Epoch: 5| Step: 11
Training loss: 2.3660690784454346
Validation loss: 2.080423424641291

Epoch: 149| Step: 0
Training loss: 1.933898687362671
Validation loss: 2.0780766854683557

Epoch: 5| Step: 1
Training loss: 1.4513094425201416
Validation loss: 2.0766628434260688

Epoch: 5| Step: 2
Training loss: 1.6492042541503906
Validation loss: 2.071139857172966

Epoch: 5| Step: 3
Training loss: 2.2040107250213623
Validation loss: 2.0617875208457312

Epoch: 5| Step: 4
Training loss: 2.357468605041504
Validation loss: 2.0527388552824655

Epoch: 5| Step: 5
Training loss: 2.179257869720459
Validation loss: 2.0432586123545966

Epoch: 5| Step: 6
Training loss: 2.3285694122314453
Validation loss: 2.0429116785526276

Epoch: 5| Step: 7
Training loss: 1.471451997756958
Validation loss: 2.0518901497125626

Epoch: 5| Step: 8
Training loss: 2.0113492012023926
Validation loss: 2.0574408074220023

Epoch: 5| Step: 9
Training loss: 2.1024749279022217
Validation loss: 2.0645213574171066

Epoch: 5| Step: 10
Training loss: 2.6049866676330566
Validation loss: 2.066896920402845

Epoch: 5| Step: 11
Training loss: 2.351400375366211
Validation loss: 2.080622206131617

Epoch: 150| Step: 0
Training loss: 1.7513186931610107
Validation loss: 2.0727995733420053

Epoch: 5| Step: 1
Training loss: 2.0158448219299316
Validation loss: 2.0738361328840256

Epoch: 5| Step: 2
Training loss: 2.0253639221191406
Validation loss: 2.0718000382184982

Epoch: 5| Step: 3
Training loss: 2.5796446800231934
Validation loss: 2.0691000322500863

Epoch: 5| Step: 4
Training loss: 1.6691538095474243
Validation loss: 2.0627881288528442

Epoch: 5| Step: 5
Training loss: 2.139470338821411
Validation loss: 2.0582412779331207

Epoch: 5| Step: 6
Training loss: 1.8855457305908203
Validation loss: 2.053424666325251

Epoch: 5| Step: 7
Training loss: 1.6812855005264282
Validation loss: 2.052567849556605

Epoch: 5| Step: 8
Training loss: 1.7897918224334717
Validation loss: 2.056913157304128

Epoch: 5| Step: 9
Training loss: 1.9723827838897705
Validation loss: 2.0483715335528054

Epoch: 5| Step: 10
Training loss: 2.2000575065612793
Validation loss: 2.0674650371074677

Epoch: 5| Step: 11
Training loss: 3.387232780456543
Validation loss: 2.0556560158729553

Epoch: 151| Step: 0
Training loss: 1.763523817062378
Validation loss: 2.058690160512924

Epoch: 5| Step: 1
Training loss: 2.0020523071289062
Validation loss: 2.0584899336099625

Epoch: 5| Step: 2
Training loss: 2.3380470275878906
Validation loss: 2.068102498849233

Epoch: 5| Step: 3
Training loss: 2.1948294639587402
Validation loss: 2.062658707300822

Epoch: 5| Step: 4
Training loss: 1.4951121807098389
Validation loss: 2.0669553875923157

Epoch: 5| Step: 5
Training loss: 1.9736801385879517
Validation loss: 2.060668999950091

Epoch: 5| Step: 6
Training loss: 1.9566476345062256
Validation loss: 2.0730582575003305

Epoch: 5| Step: 7
Training loss: 1.6110923290252686
Validation loss: 2.072935918966929

Epoch: 5| Step: 8
Training loss: 2.3478798866271973
Validation loss: 2.075894132256508

Epoch: 5| Step: 9
Training loss: 2.282853603363037
Validation loss: 2.077116777499517

Epoch: 5| Step: 10
Training loss: 2.069885730743408
Validation loss: 2.0626810739437738

Epoch: 5| Step: 11
Training loss: 1.6944910287857056
Validation loss: 2.0728687594334283

Epoch: 152| Step: 0
Training loss: 1.8306916952133179
Validation loss: 2.073490192492803

Epoch: 5| Step: 1
Training loss: 2.3830904960632324
Validation loss: 2.0717490712801614

Epoch: 5| Step: 2
Training loss: 2.1217570304870605
Validation loss: 2.0895208567380905

Epoch: 5| Step: 3
Training loss: 2.121976375579834
Validation loss: 2.0844833304484687

Epoch: 5| Step: 4
Training loss: 2.217970132827759
Validation loss: 2.075412447253863

Epoch: 5| Step: 5
Training loss: 1.9673383235931396
Validation loss: 2.0840226908524833

Epoch: 5| Step: 6
Training loss: 1.6363954544067383
Validation loss: 2.0670436024665833

Epoch: 5| Step: 7
Training loss: 2.019968271255493
Validation loss: 2.06782029569149

Epoch: 5| Step: 8
Training loss: 1.607641577720642
Validation loss: 2.0794922709465027

Epoch: 5| Step: 9
Training loss: 1.8707962036132812
Validation loss: 2.0614007661739984

Epoch: 5| Step: 10
Training loss: 2.169599771499634
Validation loss: 2.0732918133338294

Epoch: 5| Step: 11
Training loss: 1.4217278957366943
Validation loss: 2.06703449289004

Epoch: 153| Step: 0
Training loss: 1.9986902475357056
Validation loss: 2.077032193541527

Epoch: 5| Step: 1
Training loss: 2.0228495597839355
Validation loss: 2.084559291601181

Epoch: 5| Step: 2
Training loss: 1.9530279636383057
Validation loss: 2.076161672671636

Epoch: 5| Step: 3
Training loss: 2.530977725982666
Validation loss: 2.080395440260569

Epoch: 5| Step: 4
Training loss: 2.1862406730651855
Validation loss: 2.0749719738960266

Epoch: 5| Step: 5
Training loss: 1.7175464630126953
Validation loss: 2.0788167119026184

Epoch: 5| Step: 6
Training loss: 2.4485585689544678
Validation loss: 2.076467052102089

Epoch: 5| Step: 7
Training loss: 2.2121753692626953
Validation loss: 2.0741031964619956

Epoch: 5| Step: 8
Training loss: 1.735395073890686
Validation loss: 2.075552428762118

Epoch: 5| Step: 9
Training loss: 1.332096815109253
Validation loss: 2.0789097448190055

Epoch: 5| Step: 10
Training loss: 1.8607323169708252
Validation loss: 2.0712737441062927

Epoch: 5| Step: 11
Training loss: 1.3794331550598145
Validation loss: 2.082520067691803

Epoch: 154| Step: 0
Training loss: 1.7419112920761108
Validation loss: 2.104326536258062

Epoch: 5| Step: 1
Training loss: 1.9331516027450562
Validation loss: 2.1173974126577377

Epoch: 5| Step: 2
Training loss: 1.8235061168670654
Validation loss: 2.1166484455267587

Epoch: 5| Step: 3
Training loss: 1.6470909118652344
Validation loss: 2.118732218941053

Epoch: 5| Step: 4
Training loss: 1.9917528629302979
Validation loss: 2.1134740710258484

Epoch: 5| Step: 5
Training loss: 2.0860815048217773
Validation loss: 2.11734306315581

Epoch: 5| Step: 6
Training loss: 2.124093532562256
Validation loss: 2.109537571668625

Epoch: 5| Step: 7
Training loss: 1.8071092367172241
Validation loss: 2.0916989892721176

Epoch: 5| Step: 8
Training loss: 2.530639171600342
Validation loss: 2.084285577138265

Epoch: 5| Step: 9
Training loss: 1.967715859413147
Validation loss: 2.07217246790727

Epoch: 5| Step: 10
Training loss: 2.4270520210266113
Validation loss: 2.0600569397211075

Epoch: 5| Step: 11
Training loss: 3.249368906021118
Validation loss: 2.0579286764065423

Epoch: 155| Step: 0
Training loss: 2.1746649742126465
Validation loss: 2.0594152957201004

Epoch: 5| Step: 1
Training loss: 1.938734769821167
Validation loss: 2.0607342620690665

Epoch: 5| Step: 2
Training loss: 1.3445600271224976
Validation loss: 2.0536377231280007

Epoch: 5| Step: 3
Training loss: 1.971623182296753
Validation loss: 2.0650834838549295

Epoch: 5| Step: 4
Training loss: 1.9926328659057617
Validation loss: 2.0708643396695456

Epoch: 5| Step: 5
Training loss: 2.381324291229248
Validation loss: 2.070784106850624

Epoch: 5| Step: 6
Training loss: 2.0778956413269043
Validation loss: 2.083214888970057

Epoch: 5| Step: 7
Training loss: 2.3695809841156006
Validation loss: 2.096217453479767

Epoch: 5| Step: 8
Training loss: 1.444658637046814
Validation loss: 2.089671328663826

Epoch: 5| Step: 9
Training loss: 1.9152902364730835
Validation loss: 2.078446830312411

Epoch: 5| Step: 10
Training loss: 2.224076747894287
Validation loss: 2.0730893313884735

Epoch: 5| Step: 11
Training loss: 2.857713222503662
Validation loss: 2.0650130410989127

Epoch: 156| Step: 0
Training loss: 2.2125797271728516
Validation loss: 2.062771131594976

Epoch: 5| Step: 1
Training loss: 1.8211290836334229
Validation loss: 2.0654700001080832

Epoch: 5| Step: 2
Training loss: 2.2683613300323486
Validation loss: 2.06297704577446

Epoch: 5| Step: 3
Training loss: 1.3723955154418945
Validation loss: 2.0631412665049234

Epoch: 5| Step: 4
Training loss: 1.716292381286621
Validation loss: 2.060535122950872

Epoch: 5| Step: 5
Training loss: 1.7904555797576904
Validation loss: 2.0601528187592826

Epoch: 5| Step: 6
Training loss: 2.120295524597168
Validation loss: 2.074591984351476

Epoch: 5| Step: 7
Training loss: 2.8173623085021973
Validation loss: 2.0746043076117835

Epoch: 5| Step: 8
Training loss: 1.730425477027893
Validation loss: 2.0800294876098633

Epoch: 5| Step: 9
Training loss: 2.2260775566101074
Validation loss: 2.0971584618091583

Epoch: 5| Step: 10
Training loss: 1.9896981716156006
Validation loss: 2.1037996262311935

Epoch: 5| Step: 11
Training loss: 2.08610200881958
Validation loss: 2.1150097052256265

Epoch: 157| Step: 0
Training loss: 2.53924298286438
Validation loss: 2.131210202972094

Epoch: 5| Step: 1
Training loss: 1.8576714992523193
Validation loss: 2.1250771830479303

Epoch: 5| Step: 2
Training loss: 2.382784128189087
Validation loss: 2.110344409942627

Epoch: 5| Step: 3
Training loss: 1.9898430109024048
Validation loss: 2.1192843864361444

Epoch: 5| Step: 4
Training loss: 2.019087553024292
Validation loss: 2.105244735876719

Epoch: 5| Step: 5
Training loss: 1.8968900442123413
Validation loss: 2.1079184313615165

Epoch: 5| Step: 6
Training loss: 1.6476144790649414
Validation loss: 2.0898385643959045

Epoch: 5| Step: 7
Training loss: 1.7701702117919922
Validation loss: 2.0836164305607476

Epoch: 5| Step: 8
Training loss: 2.1072564125061035
Validation loss: 2.0711542069911957

Epoch: 5| Step: 9
Training loss: 1.6795463562011719
Validation loss: 2.0876649916172028

Epoch: 5| Step: 10
Training loss: 2.13771915435791
Validation loss: 2.0810059159994125

Epoch: 5| Step: 11
Training loss: 1.724655270576477
Validation loss: 2.097907602787018

Epoch: 158| Step: 0
Training loss: 1.5651551485061646
Validation loss: 2.091113885243734

Epoch: 5| Step: 1
Training loss: 2.084672212600708
Validation loss: 2.091042215625445

Epoch: 5| Step: 2
Training loss: 2.1245436668395996
Validation loss: 2.0942417879899344

Epoch: 5| Step: 3
Training loss: 2.1859867572784424
Validation loss: 2.1107552647590637

Epoch: 5| Step: 4
Training loss: 1.5701462030410767
Validation loss: 2.107253988583883

Epoch: 5| Step: 5
Training loss: 1.6836786270141602
Validation loss: 2.1198011388381324

Epoch: 5| Step: 6
Training loss: 1.6184463500976562
Validation loss: 2.097634047269821

Epoch: 5| Step: 7
Training loss: 1.6554648876190186
Validation loss: 2.111628328760465

Epoch: 5| Step: 8
Training loss: 2.4244942665100098
Validation loss: 2.1013461500406265

Epoch: 5| Step: 9
Training loss: 2.825644016265869
Validation loss: 2.0950344602266946

Epoch: 5| Step: 10
Training loss: 2.1575775146484375
Validation loss: 2.0950288573900857

Epoch: 5| Step: 11
Training loss: 1.5959715843200684
Validation loss: 2.0984091460704803

Epoch: 159| Step: 0
Training loss: 2.2527594566345215
Validation loss: 2.1002197364966073

Epoch: 5| Step: 1
Training loss: 1.613111138343811
Validation loss: 2.0943163285652795

Epoch: 5| Step: 2
Training loss: 2.1863203048706055
Validation loss: 2.0895358324050903

Epoch: 5| Step: 3
Training loss: 1.7198302745819092
Validation loss: 2.089459935824076

Epoch: 5| Step: 4
Training loss: 2.1588759422302246
Validation loss: 2.095364863673846

Epoch: 5| Step: 5
Training loss: 1.650973916053772
Validation loss: 2.0922064830859504

Epoch: 5| Step: 6
Training loss: 2.28094744682312
Validation loss: 2.0795436998208365

Epoch: 5| Step: 7
Training loss: 2.0969772338867188
Validation loss: 2.0831773529450097

Epoch: 5| Step: 8
Training loss: 1.7323999404907227
Validation loss: 2.076943283279737

Epoch: 5| Step: 9
Training loss: 2.112637758255005
Validation loss: 2.0934228748083115

Epoch: 5| Step: 10
Training loss: 1.9830595254898071
Validation loss: 2.0993304600318274

Epoch: 5| Step: 11
Training loss: 2.218608856201172
Validation loss: 2.095443700750669

Epoch: 160| Step: 0
Training loss: 1.851483702659607
Validation loss: 2.0970868517955146

Epoch: 5| Step: 1
Training loss: 2.130373477935791
Validation loss: 2.1003278692563376

Epoch: 5| Step: 2
Training loss: 1.8864113092422485
Validation loss: 2.085637077689171

Epoch: 5| Step: 3
Training loss: 2.4208879470825195
Validation loss: 2.0963528951009116

Epoch: 5| Step: 4
Training loss: 2.294313669204712
Validation loss: 2.083959942062696

Epoch: 5| Step: 5
Training loss: 2.002809762954712
Validation loss: 2.088644435008367

Epoch: 5| Step: 6
Training loss: 1.914757490158081
Validation loss: 2.080195426940918

Epoch: 5| Step: 7
Training loss: 2.2472071647644043
Validation loss: 2.079931845267614

Epoch: 5| Step: 8
Training loss: 1.5445358753204346
Validation loss: 2.088470215598742

Epoch: 5| Step: 9
Training loss: 1.6709884405136108
Validation loss: 2.0851232210795083

Epoch: 5| Step: 10
Training loss: 2.120473623275757
Validation loss: 2.100355635086695

Epoch: 5| Step: 11
Training loss: 1.4558923244476318
Validation loss: 2.101642986138662

Epoch: 161| Step: 0
Training loss: 1.7095056772232056
Validation loss: 2.1089617709318795

Epoch: 5| Step: 1
Training loss: 1.8765945434570312
Validation loss: 2.13129852215449

Epoch: 5| Step: 2
Training loss: 2.5291991233825684
Validation loss: 2.1382461339235306

Epoch: 5| Step: 3
Training loss: 1.8272931575775146
Validation loss: 2.1276014745235443

Epoch: 5| Step: 4
Training loss: 2.3144612312316895
Validation loss: 2.1300632705291114

Epoch: 5| Step: 5
Training loss: 1.979132890701294
Validation loss: 2.132535050312678

Epoch: 5| Step: 6
Training loss: 2.0346016883850098
Validation loss: 2.1215978066126504

Epoch: 5| Step: 7
Training loss: 2.7510406970977783
Validation loss: 2.1037523398796716

Epoch: 5| Step: 8
Training loss: 1.6725273132324219
Validation loss: 2.0964628358682

Epoch: 5| Step: 9
Training loss: 2.237745761871338
Validation loss: 2.089083254337311

Epoch: 5| Step: 10
Training loss: 1.2758713960647583
Validation loss: 2.0747970640659332

Epoch: 5| Step: 11
Training loss: 1.1800050735473633
Validation loss: 2.075041025876999

Epoch: 162| Step: 0
Training loss: 2.2165467739105225
Validation loss: 2.092649911840757

Epoch: 5| Step: 1
Training loss: 2.2693467140197754
Validation loss: 2.0792730947335563

Epoch: 5| Step: 2
Training loss: 1.8655211925506592
Validation loss: 2.0865600605805716

Epoch: 5| Step: 3
Training loss: 1.8637253046035767
Validation loss: 2.092901661992073

Epoch: 5| Step: 4
Training loss: 2.1609725952148438
Validation loss: 2.0999355763196945

Epoch: 5| Step: 5
Training loss: 1.8246574401855469
Validation loss: 2.103022118409475

Epoch: 5| Step: 6
Training loss: 1.961907148361206
Validation loss: 2.1045793195565543

Epoch: 5| Step: 7
Training loss: 1.6617202758789062
Validation loss: 2.117655704418818

Epoch: 5| Step: 8
Training loss: 1.5834921598434448
Validation loss: 2.1331210831801095

Epoch: 5| Step: 9
Training loss: 2.019726514816284
Validation loss: 2.122794727484385

Epoch: 5| Step: 10
Training loss: 2.3574280738830566
Validation loss: 2.14001793662707

Epoch: 5| Step: 11
Training loss: 1.3775405883789062
Validation loss: 2.121448869506518

Epoch: 163| Step: 0
Training loss: 2.190166711807251
Validation loss: 2.120923727750778

Epoch: 5| Step: 1
Training loss: 2.080169439315796
Validation loss: 2.119781648119291

Epoch: 5| Step: 2
Training loss: 1.3850858211517334
Validation loss: 2.1017858584721885

Epoch: 5| Step: 3
Training loss: 1.8477814197540283
Validation loss: 2.0895224461952844

Epoch: 5| Step: 4
Training loss: 2.0071287155151367
Validation loss: 2.0759712755680084

Epoch: 5| Step: 5
Training loss: 2.3318629264831543
Validation loss: 2.0748753249645233

Epoch: 5| Step: 6
Training loss: 1.687648057937622
Validation loss: 2.072416305541992

Epoch: 5| Step: 7
Training loss: 2.552025318145752
Validation loss: 2.053597922126452

Epoch: 5| Step: 8
Training loss: 2.1173040866851807
Validation loss: 2.0500537206729255

Epoch: 5| Step: 9
Training loss: 2.2960991859436035
Validation loss: 2.0508996844291687

Epoch: 5| Step: 10
Training loss: 1.5467994213104248
Validation loss: 2.048093855381012

Epoch: 5| Step: 11
Training loss: 0.9896254539489746
Validation loss: 2.0469659815231958

Epoch: 164| Step: 0
Training loss: 1.8509830236434937
Validation loss: 2.0579990098873773

Epoch: 5| Step: 1
Training loss: 2.205517530441284
Validation loss: 2.0606351494789124

Epoch: 5| Step: 2
Training loss: 2.0477335453033447
Validation loss: 2.0599229584137597

Epoch: 5| Step: 3
Training loss: 2.2350993156433105
Validation loss: 2.0519588589668274

Epoch: 5| Step: 4
Training loss: 2.0571799278259277
Validation loss: 2.0691563735405603

Epoch: 5| Step: 5
Training loss: 1.6603549718856812
Validation loss: 2.0552360316117606

Epoch: 5| Step: 6
Training loss: 1.7372039556503296
Validation loss: 2.0687308261791864

Epoch: 5| Step: 7
Training loss: 2.061903953552246
Validation loss: 2.07551176349322

Epoch: 5| Step: 8
Training loss: 1.756164789199829
Validation loss: 2.0766638815402985

Epoch: 5| Step: 9
Training loss: 2.336343765258789
Validation loss: 2.084231212735176

Epoch: 5| Step: 10
Training loss: 2.111262321472168
Validation loss: 2.08880345026652

Epoch: 5| Step: 11
Training loss: 1.97800612449646
Validation loss: 2.079765200614929

Epoch: 165| Step: 0
Training loss: 1.7008603811264038
Validation loss: 2.0772008945544562

Epoch: 5| Step: 1
Training loss: 2.4766077995300293
Validation loss: 2.0793247371912003

Epoch: 5| Step: 2
Training loss: 1.9717947244644165
Validation loss: 2.0768083234628043

Epoch: 5| Step: 3
Training loss: 1.955145239830017
Validation loss: 2.089801679054896

Epoch: 5| Step: 4
Training loss: 1.5329281091690063
Validation loss: 2.081810732682546

Epoch: 5| Step: 5
Training loss: 2.093620538711548
Validation loss: 2.086051960786184

Epoch: 5| Step: 6
Training loss: 1.7988895177841187
Validation loss: 2.091619372367859

Epoch: 5| Step: 7
Training loss: 1.8441448211669922
Validation loss: 2.087103029092153

Epoch: 5| Step: 8
Training loss: 1.7403894662857056
Validation loss: 2.0819912354151406

Epoch: 5| Step: 9
Training loss: 2.2035346031188965
Validation loss: 2.0847573578357697

Epoch: 5| Step: 10
Training loss: 2.508225917816162
Validation loss: 2.0944295128186545

Epoch: 5| Step: 11
Training loss: 1.7014352083206177
Validation loss: 2.087745726108551

Epoch: 166| Step: 0
Training loss: 1.5918166637420654
Validation loss: 2.08665739496549

Epoch: 5| Step: 1
Training loss: 1.943145990371704
Validation loss: 2.108459750811259

Epoch: 5| Step: 2
Training loss: 1.9822819232940674
Validation loss: 2.0933730949958167

Epoch: 5| Step: 3
Training loss: 1.949633002281189
Validation loss: 2.0855658451716104

Epoch: 5| Step: 4
Training loss: 1.966210961341858
Validation loss: 2.0894400825103125

Epoch: 5| Step: 5
Training loss: 1.512625813484192
Validation loss: 2.091950679818789

Epoch: 5| Step: 6
Training loss: 2.1153676509857178
Validation loss: 2.094566375017166

Epoch: 5| Step: 7
Training loss: 2.023098945617676
Validation loss: 2.0810842166344323

Epoch: 5| Step: 8
Training loss: 1.900156021118164
Validation loss: 2.089027062058449

Epoch: 5| Step: 9
Training loss: 1.869012475013733
Validation loss: 2.0890104273955026

Epoch: 5| Step: 10
Training loss: 2.1551647186279297
Validation loss: 2.084826717774073

Epoch: 5| Step: 11
Training loss: 4.1527814865112305
Validation loss: 2.0852084706226983

Epoch: 167| Step: 0
Training loss: 2.293348789215088
Validation loss: 2.08166633049647

Epoch: 5| Step: 1
Training loss: 1.645085096359253
Validation loss: 2.0968808233737946

Epoch: 5| Step: 2
Training loss: 2.114856004714966
Validation loss: 2.081933086117109

Epoch: 5| Step: 3
Training loss: 1.434674859046936
Validation loss: 2.093607892592748

Epoch: 5| Step: 4
Training loss: 1.8005335330963135
Validation loss: 2.099156936009725

Epoch: 5| Step: 5
Training loss: 2.1414268016815186
Validation loss: 2.1040747116009393

Epoch: 5| Step: 6
Training loss: 2.1741859912872314
Validation loss: 2.095178092519442

Epoch: 5| Step: 7
Training loss: 1.871777892112732
Validation loss: 2.0845172057549157

Epoch: 5| Step: 8
Training loss: 2.544921875
Validation loss: 2.0853713850180307

Epoch: 5| Step: 9
Training loss: 1.754891037940979
Validation loss: 2.0857655107975006

Epoch: 5| Step: 10
Training loss: 2.045274257659912
Validation loss: 2.076425020893415

Epoch: 5| Step: 11
Training loss: 1.9348725080490112
Validation loss: 2.0763248999913535

Epoch: 168| Step: 0
Training loss: 1.8344295024871826
Validation loss: 2.0789952923854194

Epoch: 5| Step: 1
Training loss: 2.108935832977295
Validation loss: 2.060417210062345

Epoch: 5| Step: 2
Training loss: 1.7998580932617188
Validation loss: 2.065258045991262

Epoch: 5| Step: 3
Training loss: 1.9896020889282227
Validation loss: 2.065279478828112

Epoch: 5| Step: 4
Training loss: 1.5805004835128784
Validation loss: 2.064358174800873

Epoch: 5| Step: 5
Training loss: 2.0230512619018555
Validation loss: 2.077004919449488

Epoch: 5| Step: 6
Training loss: 2.264291763305664
Validation loss: 2.085525502761205

Epoch: 5| Step: 7
Training loss: 2.5492420196533203
Validation loss: 2.082936172684034

Epoch: 5| Step: 8
Training loss: 1.9575016498565674
Validation loss: 2.0915554960568747

Epoch: 5| Step: 9
Training loss: 1.9439713954925537
Validation loss: 2.0965431382258735

Epoch: 5| Step: 10
Training loss: 1.5807559490203857
Validation loss: 2.1030442267656326

Epoch: 5| Step: 11
Training loss: 1.4934568405151367
Validation loss: 2.0988625486691794

Epoch: 169| Step: 0
Training loss: 2.0424625873565674
Validation loss: 2.1075262129306793

Epoch: 5| Step: 1
Training loss: 2.2502427101135254
Validation loss: 2.0943379352490106

Epoch: 5| Step: 2
Training loss: 2.2515265941619873
Validation loss: 2.0982980926831565

Epoch: 5| Step: 3
Training loss: 1.8954519033432007
Validation loss: 2.0999854505062103

Epoch: 5| Step: 4
Training loss: 2.402766466140747
Validation loss: 2.0893530547618866

Epoch: 5| Step: 5
Training loss: 1.4965215921401978
Validation loss: 2.0844856748978295

Epoch: 5| Step: 6
Training loss: 1.9554342031478882
Validation loss: 2.0844146509965262

Epoch: 5| Step: 7
Training loss: 2.0151824951171875
Validation loss: 2.093854457139969

Epoch: 5| Step: 8
Training loss: 1.9207996129989624
Validation loss: 2.1026833901802697

Epoch: 5| Step: 9
Training loss: 1.9132108688354492
Validation loss: 2.092599168419838

Epoch: 5| Step: 10
Training loss: 1.9443401098251343
Validation loss: 2.1034566164016724

Epoch: 5| Step: 11
Training loss: 0.9571515321731567
Validation loss: 2.10488128165404

Epoch: 170| Step: 0
Training loss: 1.982778787612915
Validation loss: 2.114283929268519

Epoch: 5| Step: 1
Training loss: 2.0047123432159424
Validation loss: 2.127256656686465

Epoch: 5| Step: 2
Training loss: 2.061406135559082
Validation loss: 2.1280318895975747

Epoch: 5| Step: 3
Training loss: 1.80130934715271
Validation loss: 2.1135939955711365

Epoch: 5| Step: 4
Training loss: 1.8213064670562744
Validation loss: 2.1140780597925186

Epoch: 5| Step: 5
Training loss: 2.20401668548584
Validation loss: 2.1087726205587387

Epoch: 5| Step: 6
Training loss: 2.2559542655944824
Validation loss: 2.110687201221784

Epoch: 5| Step: 7
Training loss: 1.653965711593628
Validation loss: 2.1130187809467316

Epoch: 5| Step: 8
Training loss: 1.9401870965957642
Validation loss: 2.1214822083711624

Epoch: 5| Step: 9
Training loss: 2.0528547763824463
Validation loss: 2.112669656674067

Epoch: 5| Step: 10
Training loss: 2.1599957942962646
Validation loss: 2.088262294729551

Epoch: 5| Step: 11
Training loss: 3.3968558311462402
Validation loss: 2.074993739525477

Epoch: 171| Step: 0
Training loss: 1.6113907098770142
Validation loss: 2.082965835928917

Epoch: 5| Step: 1
Training loss: 1.9091408252716064
Validation loss: 2.0778922686974206

Epoch: 5| Step: 2
Training loss: 2.2185020446777344
Validation loss: 2.0779190162817636

Epoch: 5| Step: 3
Training loss: 1.9134384393692017
Validation loss: 2.0838011354207993

Epoch: 5| Step: 4
Training loss: 2.228309154510498
Validation loss: 2.0796234558025994

Epoch: 5| Step: 5
Training loss: 2.2344329357147217
Validation loss: 2.083487311999003

Epoch: 5| Step: 6
Training loss: 1.5525178909301758
Validation loss: 2.0752658396959305

Epoch: 5| Step: 7
Training loss: 2.3272273540496826
Validation loss: 2.079526429375013

Epoch: 5| Step: 8
Training loss: 2.4880850315093994
Validation loss: 2.0723601579666138

Epoch: 5| Step: 9
Training loss: 2.584548234939575
Validation loss: 2.078601857026418

Epoch: 5| Step: 10
Training loss: 2.1819872856140137
Validation loss: 2.075468202431997

Epoch: 5| Step: 11
Training loss: 2.321539878845215
Validation loss: 2.058596427241961

Epoch: 172| Step: 0
Training loss: 2.2540483474731445
Validation loss: 2.058153768380483

Epoch: 5| Step: 1
Training loss: 2.3263766765594482
Validation loss: 2.0498670488595963

Epoch: 5| Step: 2
Training loss: 2.166050910949707
Validation loss: 2.0342702915271125

Epoch: 5| Step: 3
Training loss: 1.82929265499115
Validation loss: 2.036134178439776

Epoch: 5| Step: 4
Training loss: 1.5412248373031616
Validation loss: 2.0284534196058908

Epoch: 5| Step: 5
Training loss: 1.8821386098861694
Validation loss: 2.0413565138975778

Epoch: 5| Step: 6
Training loss: 2.2652227878570557
Validation loss: 2.0517933716376624

Epoch: 5| Step: 7
Training loss: 2.4658782482147217
Validation loss: 2.0596581449111304

Epoch: 5| Step: 8
Training loss: 1.9530439376831055
Validation loss: 2.058025320370992

Epoch: 5| Step: 9
Training loss: 2.3215456008911133
Validation loss: 2.0570135017236075

Epoch: 5| Step: 10
Training loss: 2.129854202270508
Validation loss: 2.0607147018114724

Epoch: 5| Step: 11
Training loss: 2.8429155349731445
Validation loss: 2.0490455627441406

Epoch: 173| Step: 0
Training loss: 1.9709457159042358
Validation loss: 2.064733232061068

Epoch: 5| Step: 1
Training loss: 2.2714242935180664
Validation loss: 2.0547008315722146

Epoch: 5| Step: 2
Training loss: 2.52213716506958
Validation loss: 2.0591283291578293

Epoch: 5| Step: 3
Training loss: 1.395024299621582
Validation loss: 2.068045144279798

Epoch: 5| Step: 4
Training loss: 1.5821759700775146
Validation loss: 2.063251867890358

Epoch: 5| Step: 5
Training loss: 2.2948076725006104
Validation loss: 2.081868529319763

Epoch: 5| Step: 6
Training loss: 1.841594934463501
Validation loss: 2.0665852427482605

Epoch: 5| Step: 7
Training loss: 2.1920199394226074
Validation loss: 2.065058941642443

Epoch: 5| Step: 8
Training loss: 1.9237251281738281
Validation loss: 2.074203575650851

Epoch: 5| Step: 9
Training loss: 1.7622226476669312
Validation loss: 2.0855174909035363

Epoch: 5| Step: 10
Training loss: 2.302401065826416
Validation loss: 2.0864435732364655

Epoch: 5| Step: 11
Training loss: 2.6114554405212402
Validation loss: 2.0867191751797995

Epoch: 174| Step: 0
Training loss: 2.080350875854492
Validation loss: 2.0809372613827386

Epoch: 5| Step: 1
Training loss: 2.170384407043457
Validation loss: 2.0879749258359275

Epoch: 5| Step: 2
Training loss: 1.8864864110946655
Validation loss: 2.0837945540746055

Epoch: 5| Step: 3
Training loss: 2.174229621887207
Validation loss: 2.081576392054558

Epoch: 5| Step: 4
Training loss: 1.9124305248260498
Validation loss: 2.07646677394708

Epoch: 5| Step: 5
Training loss: 1.8134071826934814
Validation loss: 2.063383092482885

Epoch: 5| Step: 6
Training loss: 1.6615188121795654
Validation loss: 2.0846102784077325

Epoch: 5| Step: 7
Training loss: 2.1872286796569824
Validation loss: 2.0884135961532593

Epoch: 5| Step: 8
Training loss: 1.861325979232788
Validation loss: 2.1003432174523673

Epoch: 5| Step: 9
Training loss: 2.1350913047790527
Validation loss: 2.083515947063764

Epoch: 5| Step: 10
Training loss: 1.8501338958740234
Validation loss: 2.110212524731954

Epoch: 5| Step: 11
Training loss: 0.8129251599311829
Validation loss: 2.101804703474045

Epoch: 175| Step: 0
Training loss: 1.474374771118164
Validation loss: 2.106970503926277

Epoch: 5| Step: 1
Training loss: 2.1252753734588623
Validation loss: 2.1221425980329514

Epoch: 5| Step: 2
Training loss: 1.651590347290039
Validation loss: 2.1172299683094025

Epoch: 5| Step: 3
Training loss: 2.0203402042388916
Validation loss: 2.127449949582418

Epoch: 5| Step: 4
Training loss: 2.435472249984741
Validation loss: 2.135895296931267

Epoch: 5| Step: 5
Training loss: 1.7571172714233398
Validation loss: 2.1349893560012183

Epoch: 5| Step: 6
Training loss: 1.3882004022598267
Validation loss: 2.12468791504701

Epoch: 5| Step: 7
Training loss: 1.805625319480896
Validation loss: 2.1188226441542306

Epoch: 5| Step: 8
Training loss: 2.4316599369049072
Validation loss: 2.117751350005468

Epoch: 5| Step: 9
Training loss: 2.409928798675537
Validation loss: 2.118038132786751

Epoch: 5| Step: 10
Training loss: 2.29974102973938
Validation loss: 2.09747880200545

Epoch: 5| Step: 11
Training loss: 0.745424747467041
Validation loss: 2.100574940443039

Epoch: 176| Step: 0
Training loss: 1.5471813678741455
Validation loss: 2.0986368308464685

Epoch: 5| Step: 1
Training loss: 1.811536431312561
Validation loss: 2.101657062768936

Epoch: 5| Step: 2
Training loss: 1.7269119024276733
Validation loss: 2.105508416891098

Epoch: 5| Step: 3
Training loss: 1.712404489517212
Validation loss: 2.111028090119362

Epoch: 5| Step: 4
Training loss: 1.7554914951324463
Validation loss: 2.0911630938450494

Epoch: 5| Step: 5
Training loss: 2.565291404724121
Validation loss: 2.0791498124599457

Epoch: 5| Step: 6
Training loss: 2.1151680946350098
Validation loss: 2.097278823455175

Epoch: 5| Step: 7
Training loss: 2.678981304168701
Validation loss: 2.0834837804238

Epoch: 5| Step: 8
Training loss: 1.3267762660980225
Validation loss: 2.074317902326584

Epoch: 5| Step: 9
Training loss: 1.9949792623519897
Validation loss: 2.0833244919776917

Epoch: 5| Step: 10
Training loss: 2.1920864582061768
Validation loss: 2.088744302590688

Epoch: 5| Step: 11
Training loss: 1.5982075929641724
Validation loss: 2.0860566943883896

Epoch: 177| Step: 0
Training loss: 2.0467309951782227
Validation loss: 2.1020794908205667

Epoch: 5| Step: 1
Training loss: 1.7348302602767944
Validation loss: 2.1185945570468903

Epoch: 5| Step: 2
Training loss: 1.9222599267959595
Validation loss: 2.1278245598077774

Epoch: 5| Step: 3
Training loss: 1.6683084964752197
Validation loss: 2.1080583135286965

Epoch: 5| Step: 4
Training loss: 2.0262796878814697
Validation loss: 2.115041106939316

Epoch: 5| Step: 5
Training loss: 2.086679697036743
Validation loss: 2.1030746897061667

Epoch: 5| Step: 6
Training loss: 2.3247694969177246
Validation loss: 2.113879462083181

Epoch: 5| Step: 7
Training loss: 1.8637964725494385
Validation loss: 2.100584477186203

Epoch: 5| Step: 8
Training loss: 2.3231942653656006
Validation loss: 2.1026724030574164

Epoch: 5| Step: 9
Training loss: 1.9973052740097046
Validation loss: 2.102234880129496

Epoch: 5| Step: 10
Training loss: 1.454829454421997
Validation loss: 2.102496092518171

Epoch: 5| Step: 11
Training loss: 2.9667129516601562
Validation loss: 2.0840683976809182

Epoch: 178| Step: 0
Training loss: 1.862306833267212
Validation loss: 2.1024504800637565

Epoch: 5| Step: 1
Training loss: 2.437936782836914
Validation loss: 2.101820175846418

Epoch: 5| Step: 2
Training loss: 1.5640957355499268
Validation loss: 2.09894468386968

Epoch: 5| Step: 3
Training loss: 2.3157737255096436
Validation loss: 2.097854420542717

Epoch: 5| Step: 4
Training loss: 2.349137783050537
Validation loss: 2.1028641810019812

Epoch: 5| Step: 5
Training loss: 2.1244397163391113
Validation loss: 2.093039949735006

Epoch: 5| Step: 6
Training loss: 1.5513426065444946
Validation loss: 2.0897857546806335

Epoch: 5| Step: 7
Training loss: 1.7391258478164673
Validation loss: 2.0931092451016107

Epoch: 5| Step: 8
Training loss: 2.00931453704834
Validation loss: 2.104495291908582

Epoch: 5| Step: 9
Training loss: 1.9854681491851807
Validation loss: 2.0982427497704825

Epoch: 5| Step: 10
Training loss: 1.8240184783935547
Validation loss: 2.098809167742729

Epoch: 5| Step: 11
Training loss: 1.8599941730499268
Validation loss: 2.0978176494439444

Epoch: 179| Step: 0
Training loss: 1.7376807928085327
Validation loss: 2.1021192421515784

Epoch: 5| Step: 1
Training loss: 2.0354790687561035
Validation loss: 2.086204340060552

Epoch: 5| Step: 2
Training loss: 1.661696434020996
Validation loss: 2.090036690235138

Epoch: 5| Step: 3
Training loss: 2.3513216972351074
Validation loss: 2.085947016874949

Epoch: 5| Step: 4
Training loss: 1.868607759475708
Validation loss: 2.0834583143393197

Epoch: 5| Step: 5
Training loss: 2.4044699668884277
Validation loss: 2.091176927089691

Epoch: 5| Step: 6
Training loss: 1.9448267221450806
Validation loss: 2.092211971680323

Epoch: 5| Step: 7
Training loss: 1.8129444122314453
Validation loss: 2.0876028885444007

Epoch: 5| Step: 8
Training loss: 1.6233609914779663
Validation loss: 2.1005547990401587

Epoch: 5| Step: 9
Training loss: 2.352360486984253
Validation loss: 2.089596559604009

Epoch: 5| Step: 10
Training loss: 1.519624948501587
Validation loss: 2.0990222096443176

Epoch: 5| Step: 11
Training loss: 2.7817745208740234
Validation loss: 2.1048252433538437

Epoch: 180| Step: 0
Training loss: 1.7166277170181274
Validation loss: 2.1013633708159127

Epoch: 5| Step: 1
Training loss: 1.9388710260391235
Validation loss: 2.108230859041214

Epoch: 5| Step: 2
Training loss: 1.3832933902740479
Validation loss: 2.1110828816890717

Epoch: 5| Step: 3
Training loss: 1.7190395593643188
Validation loss: 2.1027338951826096

Epoch: 5| Step: 4
Training loss: 2.021075487136841
Validation loss: 2.111945331096649

Epoch: 5| Step: 5
Training loss: 2.2166225910186768
Validation loss: 2.1235224654277167

Epoch: 5| Step: 6
Training loss: 1.66531240940094
Validation loss: 2.124024430910746

Epoch: 5| Step: 7
Training loss: 2.3015389442443848
Validation loss: 2.134203871091207

Epoch: 5| Step: 8
Training loss: 2.238166570663452
Validation loss: 2.128826623161634

Epoch: 5| Step: 9
Training loss: 1.9612998962402344
Validation loss: 2.1335836052894592

Epoch: 5| Step: 10
Training loss: 2.249600648880005
Validation loss: 2.1287409961223602

Epoch: 5| Step: 11
Training loss: 2.0086255073547363
Validation loss: 2.114184861381849

Epoch: 181| Step: 0
Training loss: 2.3793327808380127
Validation loss: 2.103736932078997

Epoch: 5| Step: 1
Training loss: 1.9772632122039795
Validation loss: 2.1010926018158593

Epoch: 5| Step: 2
Training loss: 1.4322245121002197
Validation loss: 2.1019806315501532

Epoch: 5| Step: 3
Training loss: 2.271483898162842
Validation loss: 2.0924839228391647

Epoch: 5| Step: 4
Training loss: 1.7829561233520508
Validation loss: 2.082568416992823

Epoch: 5| Step: 5
Training loss: 2.493180274963379
Validation loss: 2.085647518436114

Epoch: 5| Step: 6
Training loss: 2.135439395904541
Validation loss: 2.090878481666247

Epoch: 5| Step: 7
Training loss: 1.6018301248550415
Validation loss: 2.0862779716650643

Epoch: 5| Step: 8
Training loss: 1.6847913265228271
Validation loss: 2.0886141459147134

Epoch: 5| Step: 9
Training loss: 1.7236149311065674
Validation loss: 2.079584682981173

Epoch: 5| Step: 10
Training loss: 1.9776452779769897
Validation loss: 2.080918923020363

Epoch: 5| Step: 11
Training loss: 2.2794809341430664
Validation loss: 2.093186487754186

Epoch: 182| Step: 0
Training loss: 1.8471425771713257
Validation loss: 2.0936098098754883

Epoch: 5| Step: 1
Training loss: 1.6732574701309204
Validation loss: 2.091006244222323

Epoch: 5| Step: 2
Training loss: 1.5300915241241455
Validation loss: 2.114242121577263

Epoch: 5| Step: 3
Training loss: 1.542256474494934
Validation loss: 2.103377173344294

Epoch: 5| Step: 4
Training loss: 2.4887003898620605
Validation loss: 2.102757434050242

Epoch: 5| Step: 5
Training loss: 2.4226672649383545
Validation loss: 2.10387892027696

Epoch: 5| Step: 6
Training loss: 1.891681432723999
Validation loss: 2.119158739844958

Epoch: 5| Step: 7
Training loss: 2.6017208099365234
Validation loss: 2.110959827899933

Epoch: 5| Step: 8
Training loss: 1.8180660009384155
Validation loss: 2.1204705437024436

Epoch: 5| Step: 9
Training loss: 1.8013101816177368
Validation loss: 2.127803295850754

Epoch: 5| Step: 10
Training loss: 1.7639375925064087
Validation loss: 2.1194593558708825

Epoch: 5| Step: 11
Training loss: 2.1019744873046875
Validation loss: 2.1177706172068915

Epoch: 183| Step: 0
Training loss: 1.6342113018035889
Validation loss: 2.1065070579449334

Epoch: 5| Step: 1
Training loss: 1.2717832326889038
Validation loss: 2.115344832340876

Epoch: 5| Step: 2
Training loss: 2.3812434673309326
Validation loss: 2.1074359913667045

Epoch: 5| Step: 3
Training loss: 2.3676140308380127
Validation loss: 2.1130924125512442

Epoch: 5| Step: 4
Training loss: 2.033979892730713
Validation loss: 2.1007477939128876

Epoch: 5| Step: 5
Training loss: 2.3803343772888184
Validation loss: 2.104786068201065

Epoch: 5| Step: 6
Training loss: 1.565274953842163
Validation loss: 2.1184475322564444

Epoch: 5| Step: 7
Training loss: 1.6907821893692017
Validation loss: 2.110226631164551

Epoch: 5| Step: 8
Training loss: 2.5631422996520996
Validation loss: 2.117375115553538

Epoch: 5| Step: 9
Training loss: 2.409677028656006
Validation loss: 2.1207482715447745

Epoch: 5| Step: 10
Training loss: 1.3247357606887817
Validation loss: 2.1203283617893853

Epoch: 5| Step: 11
Training loss: 1.1700607538223267
Validation loss: 2.1174326092004776

Epoch: 184| Step: 0
Training loss: 1.6267856359481812
Validation loss: 2.1331437826156616

Epoch: 5| Step: 1
Training loss: 1.7666040658950806
Validation loss: 2.1182580987612405

Epoch: 5| Step: 2
Training loss: 1.9523910284042358
Validation loss: 2.106321061650912

Epoch: 5| Step: 3
Training loss: 1.497493028640747
Validation loss: 2.1150546073913574

Epoch: 5| Step: 4
Training loss: 1.937765121459961
Validation loss: 2.119590977827708

Epoch: 5| Step: 5
Training loss: 2.1986336708068848
Validation loss: 2.1150562316179276

Epoch: 5| Step: 6
Training loss: 2.2268741130828857
Validation loss: 2.100060671567917

Epoch: 5| Step: 7
Training loss: 1.8688151836395264
Validation loss: 2.1135731637477875

Epoch: 5| Step: 8
Training loss: 2.0520992279052734
Validation loss: 2.1189370105663934

Epoch: 5| Step: 9
Training loss: 1.9711815118789673
Validation loss: 2.0986052254835763

Epoch: 5| Step: 10
Training loss: 2.035460948944092
Validation loss: 2.0977924714485803

Epoch: 5| Step: 11
Training loss: 1.9407036304473877
Validation loss: 2.107372244199117

Epoch: 185| Step: 0
Training loss: 2.2357630729675293
Validation loss: 2.105860104163488

Epoch: 5| Step: 1
Training loss: 1.7168614864349365
Validation loss: 2.0874290664990744

Epoch: 5| Step: 2
Training loss: 1.9315054416656494
Validation loss: 2.0901014506816864

Epoch: 5| Step: 3
Training loss: 1.914122223854065
Validation loss: 2.104333976904551

Epoch: 5| Step: 4
Training loss: 2.230971574783325
Validation loss: 2.1004732847213745

Epoch: 5| Step: 5
Training loss: 1.7922872304916382
Validation loss: 2.1169664512077966

Epoch: 5| Step: 6
Training loss: 2.6089706420898438
Validation loss: 2.117352624734243

Epoch: 5| Step: 7
Training loss: 2.060741901397705
Validation loss: 2.121574064095815

Epoch: 5| Step: 8
Training loss: 1.800044298171997
Validation loss: 2.1030344665050507

Epoch: 5| Step: 9
Training loss: 1.7031093835830688
Validation loss: 2.09383387863636

Epoch: 5| Step: 10
Training loss: 1.4078105688095093
Validation loss: 2.092706874012947

Epoch: 5| Step: 11
Training loss: 2.2649953365325928
Validation loss: 2.083918939034144

Epoch: 186| Step: 0
Training loss: 1.7966045141220093
Validation loss: 2.0962249437967935

Epoch: 5| Step: 1
Training loss: 1.5468275547027588
Validation loss: 2.089615046977997

Epoch: 5| Step: 2
Training loss: 2.6404201984405518
Validation loss: 2.097418616215388

Epoch: 5| Step: 3
Training loss: 2.2056849002838135
Validation loss: 2.0869032045205436

Epoch: 5| Step: 4
Training loss: 2.829035997390747
Validation loss: 2.0822980354229608

Epoch: 5| Step: 5
Training loss: 1.5755689144134521
Validation loss: 2.094661990801493

Epoch: 5| Step: 6
Training loss: 1.8132623434066772
Validation loss: 2.0918434907992682

Epoch: 5| Step: 7
Training loss: 1.5461994409561157
Validation loss: 2.088941896955172

Epoch: 5| Step: 8
Training loss: 2.0228495597839355
Validation loss: 2.097971946001053

Epoch: 5| Step: 9
Training loss: 1.9682893753051758
Validation loss: 2.0993295262257257

Epoch: 5| Step: 10
Training loss: 1.526877522468567
Validation loss: 2.0911470701297126

Epoch: 5| Step: 11
Training loss: 1.472601056098938
Validation loss: 2.1048134167989097

Epoch: 187| Step: 0
Training loss: 2.8525614738464355
Validation loss: 2.1062850455443063

Epoch: 5| Step: 1
Training loss: 1.2619831562042236
Validation loss: 2.1092264155546823

Epoch: 5| Step: 2
Training loss: 1.2943744659423828
Validation loss: 2.105605885386467

Epoch: 5| Step: 3
Training loss: 2.2036571502685547
Validation loss: 2.114898830652237

Epoch: 5| Step: 4
Training loss: 1.2554231882095337
Validation loss: 2.109161853790283

Epoch: 5| Step: 5
Training loss: 2.041252613067627
Validation loss: 2.124380240837733

Epoch: 5| Step: 6
Training loss: 2.1968703269958496
Validation loss: 2.1240944067637124

Epoch: 5| Step: 7
Training loss: 1.8435752391815186
Validation loss: 2.133598287900289

Epoch: 5| Step: 8
Training loss: 2.129873752593994
Validation loss: 2.1163981358210244

Epoch: 5| Step: 9
Training loss: 2.4155402183532715
Validation loss: 2.1147895753383636

Epoch: 5| Step: 10
Training loss: 1.7111485004425049
Validation loss: 2.1041986445585885

Epoch: 5| Step: 11
Training loss: 1.6394014358520508
Validation loss: 2.106049736340841

Epoch: 188| Step: 0
Training loss: 2.2187435626983643
Validation loss: 2.098409950733185

Epoch: 5| Step: 1
Training loss: 1.9833265542984009
Validation loss: 2.0941406587759652

Epoch: 5| Step: 2
Training loss: 1.4365071058273315
Validation loss: 2.0973680863777795

Epoch: 5| Step: 3
Training loss: 1.7094100713729858
Validation loss: 2.0857357879479728

Epoch: 5| Step: 4
Training loss: 1.9375436305999756
Validation loss: 2.0837370455265045

Epoch: 5| Step: 5
Training loss: 2.1154751777648926
Validation loss: 2.0924171805381775

Epoch: 5| Step: 6
Training loss: 1.6371755599975586
Validation loss: 2.086203912893931

Epoch: 5| Step: 7
Training loss: 1.9862279891967773
Validation loss: 2.085402101278305

Epoch: 5| Step: 8
Training loss: 1.365271806716919
Validation loss: 2.0885508060455322

Epoch: 5| Step: 9
Training loss: 2.225799560546875
Validation loss: 2.1036754796902337

Epoch: 5| Step: 10
Training loss: 2.803035259246826
Validation loss: 2.1061021834611893

Epoch: 5| Step: 11
Training loss: 2.053966522216797
Validation loss: 2.100896547238032

Epoch: 189| Step: 0
Training loss: 1.470338225364685
Validation loss: 2.105784997344017

Epoch: 5| Step: 1
Training loss: 2.373823642730713
Validation loss: 2.1181125789880753

Epoch: 5| Step: 2
Training loss: 1.3658618927001953
Validation loss: 2.114280049999555

Epoch: 5| Step: 3
Training loss: 1.648898720741272
Validation loss: 2.1205140898625054

Epoch: 5| Step: 4
Training loss: 2.4128122329711914
Validation loss: 2.1128641217947006

Epoch: 5| Step: 5
Training loss: 2.047985076904297
Validation loss: 2.0983065366744995

Epoch: 5| Step: 6
Training loss: 2.0117201805114746
Validation loss: 2.114580124616623

Epoch: 5| Step: 7
Training loss: 1.776036024093628
Validation loss: 2.106798450152079

Epoch: 5| Step: 8
Training loss: 2.1179585456848145
Validation loss: 2.109303598602613

Epoch: 5| Step: 9
Training loss: 1.5853090286254883
Validation loss: 2.1136558254559836

Epoch: 5| Step: 10
Training loss: 2.0944223403930664
Validation loss: 2.118968923886617

Epoch: 5| Step: 11
Training loss: 2.2809267044067383
Validation loss: 2.108927677075068

Epoch: 190| Step: 0
Training loss: 1.768273115158081
Validation loss: 2.108267515897751

Epoch: 5| Step: 1
Training loss: 1.9571815729141235
Validation loss: 2.1134288907051086

Epoch: 5| Step: 2
Training loss: 2.5270285606384277
Validation loss: 2.11794746418794

Epoch: 5| Step: 3
Training loss: 2.10705828666687
Validation loss: 2.120527684688568

Epoch: 5| Step: 4
Training loss: 2.092209815979004
Validation loss: 2.1237230698267617

Epoch: 5| Step: 5
Training loss: 1.6226012706756592
Validation loss: 2.1235299706459045

Epoch: 5| Step: 6
Training loss: 1.4575437307357788
Validation loss: 2.1234533240397773

Epoch: 5| Step: 7
Training loss: 2.034986972808838
Validation loss: 2.1388348440329232

Epoch: 5| Step: 8
Training loss: 2.2778427600860596
Validation loss: 2.1343334217866263

Epoch: 5| Step: 9
Training loss: 1.824487328529358
Validation loss: 2.1527457237243652

Epoch: 5| Step: 10
Training loss: 1.655264139175415
Validation loss: 2.1418847739696503

Epoch: 5| Step: 11
Training loss: 1.7199126482009888
Validation loss: 2.1256935944159827

Epoch: 191| Step: 0
Training loss: 2.165147066116333
Validation loss: 2.125344301263491

Epoch: 5| Step: 1
Training loss: 1.50581955909729
Validation loss: 2.1283339063326516

Epoch: 5| Step: 2
Training loss: 2.3065850734710693
Validation loss: 2.11287792523702

Epoch: 5| Step: 3
Training loss: 1.6135890483856201
Validation loss: 2.1165965845187507

Epoch: 5| Step: 4
Training loss: 2.454430103302002
Validation loss: 2.123147507508596

Epoch: 5| Step: 5
Training loss: 2.133702278137207
Validation loss: 2.1214530368645987

Epoch: 5| Step: 6
Training loss: 2.2888107299804688
Validation loss: 2.0993032455444336

Epoch: 5| Step: 7
Training loss: 1.8842986822128296
Validation loss: 2.1164797445138297

Epoch: 5| Step: 8
Training loss: 1.7010427713394165
Validation loss: 2.093263477087021

Epoch: 5| Step: 9
Training loss: 1.7642759084701538
Validation loss: 2.106933598717054

Epoch: 5| Step: 10
Training loss: 1.583816409111023
Validation loss: 2.1099385023117065

Epoch: 5| Step: 11
Training loss: 0.7671200037002563
Validation loss: 2.114659547805786

Epoch: 192| Step: 0
Training loss: 1.7648578882217407
Validation loss: 2.14569428563118

Epoch: 5| Step: 1
Training loss: 2.145416736602783
Validation loss: 2.1300271252791085

Epoch: 5| Step: 2
Training loss: 2.428549289703369
Validation loss: 2.1267062226931253

Epoch: 5| Step: 3
Training loss: 2.0443952083587646
Validation loss: 2.13310573498408

Epoch: 5| Step: 4
Training loss: 1.7211167812347412
Validation loss: 2.1335208167632422

Epoch: 5| Step: 5
Training loss: 1.4217050075531006
Validation loss: 2.153573215007782

Epoch: 5| Step: 6
Training loss: 2.5163352489471436
Validation loss: 2.1326298465331397

Epoch: 5| Step: 7
Training loss: 1.5097436904907227
Validation loss: 2.1315271804730096

Epoch: 5| Step: 8
Training loss: 2.00408673286438
Validation loss: 2.1336418936649957

Epoch: 5| Step: 9
Training loss: 2.1331324577331543
Validation loss: 2.1169795294602713

Epoch: 5| Step: 10
Training loss: 2.026655435562134
Validation loss: 2.1069421768188477

Epoch: 5| Step: 11
Training loss: 1.3710589408874512
Validation loss: 2.102396930257479

Epoch: 193| Step: 0
Training loss: 1.8172439336776733
Validation loss: 2.106341635187467

Epoch: 5| Step: 1
Training loss: 1.9356998205184937
Validation loss: 2.1119080086549125

Epoch: 5| Step: 2
Training loss: 2.0625016689300537
Validation loss: 2.103746677438418

Epoch: 5| Step: 3
Training loss: 2.0455617904663086
Validation loss: 2.111265550057093

Epoch: 5| Step: 4
Training loss: 1.6352399587631226
Validation loss: 2.116485913594564

Epoch: 5| Step: 5
Training loss: 2.234278917312622
Validation loss: 2.1078726847966514

Epoch: 5| Step: 6
Training loss: 2.1028401851654053
Validation loss: 2.1127335081497827

Epoch: 5| Step: 7
Training loss: 2.3734617233276367
Validation loss: 2.1155977100133896

Epoch: 5| Step: 8
Training loss: 1.916612982749939
Validation loss: 2.1126382599274316

Epoch: 5| Step: 9
Training loss: 1.638654112815857
Validation loss: 2.1209533711274466

Epoch: 5| Step: 10
Training loss: 1.360957384109497
Validation loss: 2.10491514702638

Epoch: 5| Step: 11
Training loss: 2.1109402179718018
Validation loss: 2.1428244610627494

Epoch: 194| Step: 0
Training loss: 2.169524908065796
Validation loss: 2.1267244021097818

Epoch: 5| Step: 1
Training loss: 1.8583593368530273
Validation loss: 2.1173875431219735

Epoch: 5| Step: 2
Training loss: 1.6373380422592163
Validation loss: 2.1223829040924707

Epoch: 5| Step: 3
Training loss: 1.7032124996185303
Validation loss: 2.125156586368879

Epoch: 5| Step: 4
Training loss: 2.097318410873413
Validation loss: 2.100918253262838

Epoch: 5| Step: 5
Training loss: 1.7560389041900635
Validation loss: 2.089826315641403

Epoch: 5| Step: 6
Training loss: 1.961406946182251
Validation loss: 2.102736974755923

Epoch: 5| Step: 7
Training loss: 2.387157440185547
Validation loss: 2.093530058860779

Epoch: 5| Step: 8
Training loss: 1.6797206401824951
Validation loss: 2.121311073501905

Epoch: 5| Step: 9
Training loss: 1.5875540971755981
Validation loss: 2.0894621163606644

Epoch: 5| Step: 10
Training loss: 2.493100166320801
Validation loss: 2.094433764616648

Epoch: 5| Step: 11
Training loss: 1.7524827718734741
Validation loss: 2.0971072564522424

Epoch: 195| Step: 0
Training loss: 1.9906129837036133
Validation loss: 2.1117106825113297

Epoch: 5| Step: 1
Training loss: 1.7773158550262451
Validation loss: 2.120467652877172

Epoch: 5| Step: 2
Training loss: 1.6956440210342407
Validation loss: 2.1036556710799537

Epoch: 5| Step: 3
Training loss: 1.7201694250106812
Validation loss: 2.121657356619835

Epoch: 5| Step: 4
Training loss: 1.6888681650161743
Validation loss: 2.113197589914004

Epoch: 5| Step: 5
Training loss: 1.74738347530365
Validation loss: 2.117058257261912

Epoch: 5| Step: 6
Training loss: 1.8796937465667725
Validation loss: 2.118830442428589

Epoch: 5| Step: 7
Training loss: 2.537538766860962
Validation loss: 2.1310778309901557

Epoch: 5| Step: 8
Training loss: 1.687432050704956
Validation loss: 2.1221729268630347

Epoch: 5| Step: 9
Training loss: 2.377838373184204
Validation loss: 2.1221038599809012

Epoch: 5| Step: 10
Training loss: 1.8615859746932983
Validation loss: 2.141185089945793

Epoch: 5| Step: 11
Training loss: 1.1694424152374268
Validation loss: 2.1253465364376702

Epoch: 196| Step: 0
Training loss: 1.805469274520874
Validation loss: 2.1353131930033364

Epoch: 5| Step: 1
Training loss: 2.0580692291259766
Validation loss: 2.124756316343943

Epoch: 5| Step: 2
Training loss: 2.3773868083953857
Validation loss: 2.121275062362353

Epoch: 5| Step: 3
Training loss: 1.5812104940414429
Validation loss: 2.1254843920469284

Epoch: 5| Step: 4
Training loss: 2.114440679550171
Validation loss: 2.118634889523188

Epoch: 5| Step: 5
Training loss: 2.1600496768951416
Validation loss: 2.1169379502534866

Epoch: 5| Step: 6
Training loss: 1.0646402835845947
Validation loss: 2.1223119348287582

Epoch: 5| Step: 7
Training loss: 2.539918899536133
Validation loss: 2.1293949435154595

Epoch: 5| Step: 8
Training loss: 1.2999598979949951
Validation loss: 2.1250675121943154

Epoch: 5| Step: 9
Training loss: 2.084876298904419
Validation loss: 2.1114281912644706

Epoch: 5| Step: 10
Training loss: 1.8698192834854126
Validation loss: 2.11232990026474

Epoch: 5| Step: 11
Training loss: 1.6678582429885864
Validation loss: 2.1164315392573676

Epoch: 197| Step: 0
Training loss: 2.1725354194641113
Validation loss: 2.1222081979115806

Epoch: 5| Step: 1
Training loss: 1.8207499980926514
Validation loss: 2.1159306863943734

Epoch: 5| Step: 2
Training loss: 1.7697973251342773
Validation loss: 2.1284082432587943

Epoch: 5| Step: 3
Training loss: 1.6524856090545654
Validation loss: 2.130622069040934

Epoch: 5| Step: 4
Training loss: 1.720193862915039
Validation loss: 2.117282291253408

Epoch: 5| Step: 5
Training loss: 1.7934058904647827
Validation loss: 2.126836205522219

Epoch: 5| Step: 6
Training loss: 2.0596654415130615
Validation loss: 2.123932972550392

Epoch: 5| Step: 7
Training loss: 2.4285964965820312
Validation loss: 2.1361766358216605

Epoch: 5| Step: 8
Training loss: 1.5860298871994019
Validation loss: 2.1332451899846396

Epoch: 5| Step: 9
Training loss: 2.124005079269409
Validation loss: 2.133048231403033

Epoch: 5| Step: 10
Training loss: 1.8804099559783936
Validation loss: 2.14623486995697

Epoch: 5| Step: 11
Training loss: 1.3311116695404053
Validation loss: 2.1291977862517038

Epoch: 198| Step: 0
Training loss: 2.443021774291992
Validation loss: 2.1337214509646096

Epoch: 5| Step: 1
Training loss: 1.6711804866790771
Validation loss: 2.129286895195643

Epoch: 5| Step: 2
Training loss: 1.8152644634246826
Validation loss: 2.1166284133990607

Epoch: 5| Step: 3
Training loss: 2.4060721397399902
Validation loss: 2.111320892969767

Epoch: 5| Step: 4
Training loss: 1.9820406436920166
Validation loss: 2.105462744832039

Epoch: 5| Step: 5
Training loss: 1.9696630239486694
Validation loss: 2.1140249917904534

Epoch: 5| Step: 6
Training loss: 2.074427843093872
Validation loss: 2.1152972827355065

Epoch: 5| Step: 7
Training loss: 1.562639594078064
Validation loss: 2.1159101029237113

Epoch: 5| Step: 8
Training loss: 1.56460702419281
Validation loss: 2.11715537806352

Epoch: 5| Step: 9
Training loss: 1.7735583782196045
Validation loss: 2.126265694697698

Epoch: 5| Step: 10
Training loss: 1.7865711450576782
Validation loss: 2.148295298218727

Epoch: 5| Step: 11
Training loss: 0.9963480830192566
Validation loss: 2.1618691782156625

Epoch: 199| Step: 0
Training loss: 1.3751323223114014
Validation loss: 2.168223112821579

Epoch: 5| Step: 1
Training loss: 2.1203980445861816
Validation loss: 2.166141599416733

Epoch: 5| Step: 2
Training loss: 1.9698655605316162
Validation loss: 2.1656623780727386

Epoch: 5| Step: 3
Training loss: 2.2892844676971436
Validation loss: 2.1654125402371087

Epoch: 5| Step: 4
Training loss: 1.8340270519256592
Validation loss: 2.1596512695153556

Epoch: 5| Step: 5
Training loss: 1.764256477355957
Validation loss: 2.156110778450966

Epoch: 5| Step: 6
Training loss: 1.8920522928237915
Validation loss: 2.146852066119512

Epoch: 5| Step: 7
Training loss: 2.1408915519714355
Validation loss: 2.1488469392061234

Epoch: 5| Step: 8
Training loss: 1.935669183731079
Validation loss: 2.129296451807022

Epoch: 5| Step: 9
Training loss: 1.5940431356430054
Validation loss: 2.1349046677351

Epoch: 5| Step: 10
Training loss: 2.016634464263916
Validation loss: 2.114365662137667

Epoch: 5| Step: 11
Training loss: 2.112272262573242
Validation loss: 2.1143079002698264

Epoch: 200| Step: 0
Training loss: 1.6507660150527954
Validation loss: 2.1204260289669037

Epoch: 5| Step: 1
Training loss: 2.2722079753875732
Validation loss: 2.1151715566714606

Epoch: 5| Step: 2
Training loss: 2.1885929107666016
Validation loss: 2.1300431340932846

Epoch: 5| Step: 3
Training loss: 1.4759730100631714
Validation loss: 2.124715397755305

Epoch: 5| Step: 4
Training loss: 2.3446602821350098
Validation loss: 2.139850825071335

Epoch: 5| Step: 5
Training loss: 1.5557546615600586
Validation loss: 2.13840588927269

Epoch: 5| Step: 6
Training loss: 1.7500661611557007
Validation loss: 2.167202979326248

Epoch: 5| Step: 7
Training loss: 2.1367766857147217
Validation loss: 2.169191668430964

Epoch: 5| Step: 8
Training loss: 2.185688018798828
Validation loss: 2.162188167373339

Epoch: 5| Step: 9
Training loss: 1.7913278341293335
Validation loss: 2.1734677205483117

Epoch: 5| Step: 10
Training loss: 1.8375247716903687
Validation loss: 2.1639643212159476

Epoch: 5| Step: 11
Training loss: 2.587637424468994
Validation loss: 2.1368395686149597

Epoch: 201| Step: 0
Training loss: 2.045726776123047
Validation loss: 2.117469439903895

Epoch: 5| Step: 1
Training loss: 1.4952882528305054
Validation loss: 2.117605154712995

Epoch: 5| Step: 2
Training loss: 2.640136957168579
Validation loss: 2.1049877802530923

Epoch: 5| Step: 3
Training loss: 2.1518397331237793
Validation loss: 2.0991601943969727

Epoch: 5| Step: 4
Training loss: 1.6477524042129517
Validation loss: 2.089473247528076

Epoch: 5| Step: 5
Training loss: 2.0398616790771484
Validation loss: 2.0975970526536307

Epoch: 5| Step: 6
Training loss: 2.385061740875244
Validation loss: 2.093671386440595

Epoch: 5| Step: 7
Training loss: 2.3701634407043457
Validation loss: 2.0954173803329468

Epoch: 5| Step: 8
Training loss: 1.9849765300750732
Validation loss: 2.104967008034388

Epoch: 5| Step: 9
Training loss: 1.4954936504364014
Validation loss: 2.0998065123955407

Epoch: 5| Step: 10
Training loss: 1.8782360553741455
Validation loss: 2.1198469350735345

Epoch: 5| Step: 11
Training loss: 1.5881882905960083
Validation loss: 2.125777781009674

Epoch: 202| Step: 0
Training loss: 1.5858293771743774
Validation loss: 2.1377843221028647

Epoch: 5| Step: 1
Training loss: 1.6782108545303345
Validation loss: 2.152832676966985

Epoch: 5| Step: 2
Training loss: 1.466191053390503
Validation loss: 2.1621054907639823

Epoch: 5| Step: 3
Training loss: 1.8980156183242798
Validation loss: 2.155677611629168

Epoch: 5| Step: 4
Training loss: 2.444932460784912
Validation loss: 2.1659673104683557

Epoch: 5| Step: 5
Training loss: 2.028698444366455
Validation loss: 2.159129540125529

Epoch: 5| Step: 6
Training loss: 2.6927409172058105
Validation loss: 2.139570434888204

Epoch: 5| Step: 7
Training loss: 2.2313153743743896
Validation loss: 2.1466878255208335

Epoch: 5| Step: 8
Training loss: 1.7445423603057861
Validation loss: 2.132381021976471

Epoch: 5| Step: 9
Training loss: 1.8861522674560547
Validation loss: 2.128264918923378

Epoch: 5| Step: 10
Training loss: 1.6684497594833374
Validation loss: 2.1203587551911673

Epoch: 5| Step: 11
Training loss: 1.8184921741485596
Validation loss: 2.1262174397706985

Epoch: 203| Step: 0
Training loss: 1.91994309425354
Validation loss: 2.0909849206606546

Epoch: 5| Step: 1
Training loss: 1.591414451599121
Validation loss: 2.111717849969864

Epoch: 5| Step: 2
Training loss: 2.1482203006744385
Validation loss: 2.0984147787094116

Epoch: 5| Step: 3
Training loss: 1.96024489402771
Validation loss: 2.106311559677124

Epoch: 5| Step: 4
Training loss: 1.9558178186416626
Validation loss: 2.1009128342072168

Epoch: 5| Step: 5
Training loss: 1.896158218383789
Validation loss: 2.1083204398552575

Epoch: 5| Step: 6
Training loss: 2.347703218460083
Validation loss: 2.100260928273201

Epoch: 5| Step: 7
Training loss: 2.7453646659851074
Validation loss: 2.098368843396505

Epoch: 5| Step: 8
Training loss: 2.316214084625244
Validation loss: 2.1081819434960685

Epoch: 5| Step: 9
Training loss: 1.4928629398345947
Validation loss: 2.1023962249358497

Epoch: 5| Step: 10
Training loss: 2.2446842193603516
Validation loss: 2.1030462980270386

Epoch: 5| Step: 11
Training loss: 1.2559423446655273
Validation loss: 2.10523288945357

Epoch: 204| Step: 0
Training loss: 2.7096476554870605
Validation loss: 2.0995938231547675

Epoch: 5| Step: 1
Training loss: 1.5158555507659912
Validation loss: 2.097366993625959

Epoch: 5| Step: 2
Training loss: 1.3868305683135986
Validation loss: 2.112307757139206

Epoch: 5| Step: 3
Training loss: 1.6338106393814087
Validation loss: 2.135791768630346

Epoch: 5| Step: 4
Training loss: 1.8864927291870117
Validation loss: 2.1462961037953696

Epoch: 5| Step: 5
Training loss: 2.2436251640319824
Validation loss: 2.1476302792628608

Epoch: 5| Step: 6
Training loss: 2.2435407638549805
Validation loss: 2.163196553786596

Epoch: 5| Step: 7
Training loss: 1.8420625925064087
Validation loss: 2.1669523318608603

Epoch: 5| Step: 8
Training loss: 1.5205987691879272
Validation loss: 2.168735941251119

Epoch: 5| Step: 9
Training loss: 2.4100124835968018
Validation loss: 2.153758242726326

Epoch: 5| Step: 10
Training loss: 2.0276191234588623
Validation loss: 2.1475390046834946

Epoch: 5| Step: 11
Training loss: 1.2638344764709473
Validation loss: 2.14176407456398

Epoch: 205| Step: 0
Training loss: 2.5657527446746826
Validation loss: 2.144974629084269

Epoch: 5| Step: 1
Training loss: 2.0357253551483154
Validation loss: 2.1354215343793235

Epoch: 5| Step: 2
Training loss: 2.11285138130188
Validation loss: 2.133896619081497

Epoch: 5| Step: 3
Training loss: 1.7900203466415405
Validation loss: 2.1164861967166266

Epoch: 5| Step: 4
Training loss: 2.048973798751831
Validation loss: 2.126444468895594

Epoch: 5| Step: 5
Training loss: 1.5253351926803589
Validation loss: 2.1220395316680274

Epoch: 5| Step: 6
Training loss: 1.614183783531189
Validation loss: 2.1287793616453805

Epoch: 5| Step: 7
Training loss: 1.6852794885635376
Validation loss: 2.1225184549887977

Epoch: 5| Step: 8
Training loss: 1.8413578271865845
Validation loss: 2.113109221061071

Epoch: 5| Step: 9
Training loss: 1.4348444938659668
Validation loss: 2.1209911604722342

Epoch: 5| Step: 10
Training loss: 2.2383475303649902
Validation loss: 2.123254895210266

Epoch: 5| Step: 11
Training loss: 1.5442695617675781
Validation loss: 2.126894861459732

Epoch: 206| Step: 0
Training loss: 1.640779733657837
Validation loss: 2.111591229836146

Epoch: 5| Step: 1
Training loss: 1.250034213066101
Validation loss: 2.140264148513476

Epoch: 5| Step: 2
Training loss: 2.4927797317504883
Validation loss: 2.119908094406128

Epoch: 5| Step: 3
Training loss: 2.0688576698303223
Validation loss: 2.1301347513993583

Epoch: 5| Step: 4
Training loss: 2.077648401260376
Validation loss: 2.1290534238020578

Epoch: 5| Step: 5
Training loss: 1.9523273706436157
Validation loss: 2.151859258611997

Epoch: 5| Step: 6
Training loss: 1.698113203048706
Validation loss: 2.1406815350055695

Epoch: 5| Step: 7
Training loss: 1.9844753742218018
Validation loss: 2.125112240513166

Epoch: 5| Step: 8
Training loss: 1.8277130126953125
Validation loss: 2.1423736413319907

Epoch: 5| Step: 9
Training loss: 2.066582679748535
Validation loss: 2.1447346756855645

Epoch: 5| Step: 10
Training loss: 1.7755016088485718
Validation loss: 2.162163416544596

Epoch: 5| Step: 11
Training loss: 0.7563235759735107
Validation loss: 2.14950263996919

Epoch: 207| Step: 0
Training loss: 2.1033105850219727
Validation loss: 2.139005661010742

Epoch: 5| Step: 1
Training loss: 2.0481300354003906
Validation loss: 2.1410030821959176

Epoch: 5| Step: 2
Training loss: 2.316905975341797
Validation loss: 2.10365854203701

Epoch: 5| Step: 3
Training loss: 1.2460678815841675
Validation loss: 2.115760544935862

Epoch: 5| Step: 4
Training loss: 1.8346389532089233
Validation loss: 2.1224841276804605

Epoch: 5| Step: 5
Training loss: 1.765207052230835
Validation loss: 2.1055836975574493

Epoch: 5| Step: 6
Training loss: 2.2079710960388184
Validation loss: 2.114784081776937

Epoch: 5| Step: 7
Training loss: 2.2166943550109863
Validation loss: 2.1195038755734763

Epoch: 5| Step: 8
Training loss: 1.612358808517456
Validation loss: 2.118484099706014

Epoch: 5| Step: 9
Training loss: 1.8601897954940796
Validation loss: 2.1298403441905975

Epoch: 5| Step: 10
Training loss: 1.4731563329696655
Validation loss: 2.113692800203959

Epoch: 5| Step: 11
Training loss: 1.332002878189087
Validation loss: 2.1323201755682626

Epoch: 208| Step: 0
Training loss: 1.6703948974609375
Validation loss: 2.1413816809654236

Epoch: 5| Step: 1
Training loss: 2.6683480739593506
Validation loss: 2.1447359124819436

Epoch: 5| Step: 2
Training loss: 1.4110604524612427
Validation loss: 2.157444874445597

Epoch: 5| Step: 3
Training loss: 1.567007303237915
Validation loss: 2.1756369123856225

Epoch: 5| Step: 4
Training loss: 1.5063416957855225
Validation loss: 2.1606015861034393

Epoch: 5| Step: 5
Training loss: 1.72654128074646
Validation loss: 2.1629715263843536

Epoch: 5| Step: 6
Training loss: 1.946702241897583
Validation loss: 2.1559184988339744

Epoch: 5| Step: 7
Training loss: 1.8799266815185547
Validation loss: 2.163044889767965

Epoch: 5| Step: 8
Training loss: 1.6502456665039062
Validation loss: 2.1281596024831138

Epoch: 5| Step: 9
Training loss: 2.4377105236053467
Validation loss: 2.1241974333922067

Epoch: 5| Step: 10
Training loss: 2.213496446609497
Validation loss: 2.122483859459559

Epoch: 5| Step: 11
Training loss: 1.212999939918518
Validation loss: 2.1199890971183777

Epoch: 209| Step: 0
Training loss: 1.9725099802017212
Validation loss: 2.117191861073176

Epoch: 5| Step: 1
Training loss: 1.8543611764907837
Validation loss: 2.1095529248317084

Epoch: 5| Step: 2
Training loss: 1.5126876831054688
Validation loss: 2.1037388344605765

Epoch: 5| Step: 3
Training loss: 1.6241413354873657
Validation loss: 2.109327256679535

Epoch: 5| Step: 4
Training loss: 2.0062546730041504
Validation loss: 2.1026573876539865

Epoch: 5| Step: 5
Training loss: 2.2819647789001465
Validation loss: 2.101520076394081

Epoch: 5| Step: 6
Training loss: 1.949394941329956
Validation loss: 2.106606140732765

Epoch: 5| Step: 7
Training loss: 2.1001992225646973
Validation loss: 2.1069875905911126

Epoch: 5| Step: 8
Training loss: 2.2264792919158936
Validation loss: 2.1115776101748147

Epoch: 5| Step: 9
Training loss: 1.6635509729385376
Validation loss: 2.133432467778524

Epoch: 5| Step: 10
Training loss: 2.3218865394592285
Validation loss: 2.119628136356672

Epoch: 5| Step: 11
Training loss: 1.5310544967651367
Validation loss: 2.1362344324588776

Epoch: 210| Step: 0
Training loss: 1.8127609491348267
Validation loss: 2.132122283180555

Epoch: 5| Step: 1
Training loss: 3.2237067222595215
Validation loss: 2.132604812582334

Epoch: 5| Step: 2
Training loss: 1.9800646305084229
Validation loss: 2.1306676169236503

Epoch: 5| Step: 3
Training loss: 1.48348069190979
Validation loss: 2.144709358612696

Epoch: 5| Step: 4
Training loss: 1.8064415454864502
Validation loss: 2.1463916848103204

Epoch: 5| Step: 5
Training loss: 2.00345516204834
Validation loss: 2.154880275328954

Epoch: 5| Step: 6
Training loss: 1.6830488443374634
Validation loss: 2.1287595331668854

Epoch: 5| Step: 7
Training loss: 1.6013816595077515
Validation loss: 2.1296382397413254

Epoch: 5| Step: 8
Training loss: 2.1103644371032715
Validation loss: 2.1404473384221396

Epoch: 5| Step: 9
Training loss: 1.6977676153182983
Validation loss: 2.1219462951024375

Epoch: 5| Step: 10
Training loss: 1.5485814809799194
Validation loss: 2.1298022071520486

Epoch: 5| Step: 11
Training loss: 2.384665012359619
Validation loss: 2.129626293977102

Epoch: 211| Step: 0
Training loss: 2.0953879356384277
Validation loss: 2.1371934364239373

Epoch: 5| Step: 1
Training loss: 1.4937915802001953
Validation loss: 2.1271045953035355

Epoch: 5| Step: 2
Training loss: 2.1781134605407715
Validation loss: 2.122407207886378

Epoch: 5| Step: 3
Training loss: 1.2761151790618896
Validation loss: 2.1364644169807434

Epoch: 5| Step: 4
Training loss: 2.006808042526245
Validation loss: 2.140993118286133

Epoch: 5| Step: 5
Training loss: 2.2399754524230957
Validation loss: 2.1422082980473838

Epoch: 5| Step: 6
Training loss: 1.7124449014663696
Validation loss: 2.144593040148417

Epoch: 5| Step: 7
Training loss: 2.1339290142059326
Validation loss: 2.150602161884308

Epoch: 5| Step: 8
Training loss: 1.8282372951507568
Validation loss: 2.1601608246564865

Epoch: 5| Step: 9
Training loss: 1.6976242065429688
Validation loss: 2.149124557773272

Epoch: 5| Step: 10
Training loss: 2.2287700176239014
Validation loss: 2.160302087664604

Epoch: 5| Step: 11
Training loss: 1.5071865320205688
Validation loss: 2.1557735751072564

Epoch: 212| Step: 0
Training loss: 2.4836788177490234
Validation loss: 2.1546878765026727

Epoch: 5| Step: 1
Training loss: 1.7977339029312134
Validation loss: 2.1389534374078116

Epoch: 5| Step: 2
Training loss: 1.4721295833587646
Validation loss: 2.134685695171356

Epoch: 5| Step: 3
Training loss: 1.6279598474502563
Validation loss: 2.1434162805477777

Epoch: 5| Step: 4
Training loss: 1.6303017139434814
Validation loss: 2.138318250576655

Epoch: 5| Step: 5
Training loss: 2.2741496562957764
Validation loss: 2.1429510017236075

Epoch: 5| Step: 6
Training loss: 1.308030366897583
Validation loss: 2.1346796452999115

Epoch: 5| Step: 7
Training loss: 1.9541351795196533
Validation loss: 2.1432087322076163

Epoch: 5| Step: 8
Training loss: 1.8518680334091187
Validation loss: 2.1480150719483695

Epoch: 5| Step: 9
Training loss: 1.7467483282089233
Validation loss: 2.1294220785299935

Epoch: 5| Step: 10
Training loss: 2.3566486835479736
Validation loss: 2.1470690766970315

Epoch: 5| Step: 11
Training loss: 1.3465458154678345
Validation loss: 2.1379912992318473

Epoch: 213| Step: 0
Training loss: 1.4104598760604858
Validation loss: 2.136424019932747

Epoch: 5| Step: 1
Training loss: 2.189546585083008
Validation loss: 2.144085148970286

Epoch: 5| Step: 2
Training loss: 1.9782073497772217
Validation loss: 2.1397061248620353

Epoch: 5| Step: 3
Training loss: 2.2998979091644287
Validation loss: 2.1334278037150702

Epoch: 5| Step: 4
Training loss: 1.4369516372680664
Validation loss: 2.1387024174133935

Epoch: 5| Step: 5
Training loss: 1.855385184288025
Validation loss: 2.1327520658572516

Epoch: 5| Step: 6
Training loss: 2.2474513053894043
Validation loss: 2.1125524093707404

Epoch: 5| Step: 7
Training loss: 1.5384790897369385
Validation loss: 2.1221596201260886

Epoch: 5| Step: 8
Training loss: 2.26161527633667
Validation loss: 2.132459302743276

Epoch: 5| Step: 9
Training loss: 1.6305713653564453
Validation loss: 2.133902207016945

Epoch: 5| Step: 10
Training loss: 1.9626104831695557
Validation loss: 2.129382570584615

Epoch: 5| Step: 11
Training loss: 0.8719443082809448
Validation loss: 2.131355235973994

Epoch: 214| Step: 0
Training loss: 1.7106873989105225
Validation loss: 2.1236713280280433

Epoch: 5| Step: 1
Training loss: 1.6566991806030273
Validation loss: 2.123801519473394

Epoch: 5| Step: 2
Training loss: 1.4942725896835327
Validation loss: 2.148625766237577

Epoch: 5| Step: 3
Training loss: 1.4675053358078003
Validation loss: 2.132495110233625

Epoch: 5| Step: 4
Training loss: 1.5157673358917236
Validation loss: 2.148335501551628

Epoch: 5| Step: 5
Training loss: 1.9672527313232422
Validation loss: 2.1628388315439224

Epoch: 5| Step: 6
Training loss: 2.0718374252319336
Validation loss: 2.1684285551309586

Epoch: 5| Step: 7
Training loss: 2.1504547595977783
Validation loss: 2.188190052906672

Epoch: 5| Step: 8
Training loss: 1.8897771835327148
Validation loss: 2.1704802811145782

Epoch: 5| Step: 9
Training loss: 2.2180206775665283
Validation loss: 2.167162165045738

Epoch: 5| Step: 10
Training loss: 1.9865930080413818
Validation loss: 2.1702192574739456

Epoch: 5| Step: 11
Training loss: 1.6524819135665894
Validation loss: 2.170806417862574

Epoch: 215| Step: 0
Training loss: 2.3103854656219482
Validation loss: 2.168666367729505

Epoch: 5| Step: 1
Training loss: 1.819963812828064
Validation loss: 2.162393515308698

Epoch: 5| Step: 2
Training loss: 1.3238567113876343
Validation loss: 2.1618849535783133

Epoch: 5| Step: 3
Training loss: 2.990064859390259
Validation loss: 2.152140418688456

Epoch: 5| Step: 4
Training loss: 1.399751901626587
Validation loss: 2.1313460369904837

Epoch: 5| Step: 5
Training loss: 1.6714540719985962
Validation loss: 2.1218513399362564

Epoch: 5| Step: 6
Training loss: 1.8585563898086548
Validation loss: 2.1242990444103875

Epoch: 5| Step: 7
Training loss: 1.7914361953735352
Validation loss: 2.1186026533444724

Epoch: 5| Step: 8
Training loss: 2.369472026824951
Validation loss: 2.121261258920034

Epoch: 5| Step: 9
Training loss: 1.9562160968780518
Validation loss: 2.117904916405678

Epoch: 5| Step: 10
Training loss: 1.7383781671524048
Validation loss: 2.1214470018943152

Epoch: 5| Step: 11
Training loss: 2.1671805381774902
Validation loss: 2.1241412113110223

Epoch: 216| Step: 0
Training loss: 2.151601791381836
Validation loss: 2.113000273704529

Epoch: 5| Step: 1
Training loss: 1.8503509759902954
Validation loss: 2.1202539801597595

Epoch: 5| Step: 2
Training loss: 1.6332159042358398
Validation loss: 2.1273535887400308

Epoch: 5| Step: 3
Training loss: 2.2919204235076904
Validation loss: 2.1512654523054757

Epoch: 5| Step: 4
Training loss: 2.61728572845459
Validation loss: 2.137496511141459

Epoch: 5| Step: 5
Training loss: 1.892057180404663
Validation loss: 2.1395117938518524

Epoch: 5| Step: 6
Training loss: 1.4929773807525635
Validation loss: 2.1423122634490332

Epoch: 5| Step: 7
Training loss: 1.5795762538909912
Validation loss: 2.1288067400455475

Epoch: 5| Step: 8
Training loss: 1.8979551792144775
Validation loss: 2.1216388791799545

Epoch: 5| Step: 9
Training loss: 1.2503447532653809
Validation loss: 2.1226660857597985

Epoch: 5| Step: 10
Training loss: 1.8246040344238281
Validation loss: 2.1339473028977713

Epoch: 5| Step: 11
Training loss: 1.2093312740325928
Validation loss: 2.134699285030365

Epoch: 217| Step: 0
Training loss: 2.0028767585754395
Validation loss: 2.1362824738025665

Epoch: 5| Step: 1
Training loss: 1.7367286682128906
Validation loss: 2.1367842853069305

Epoch: 5| Step: 2
Training loss: 1.4087984561920166
Validation loss: 2.1387452284495034

Epoch: 5| Step: 3
Training loss: 2.33872652053833
Validation loss: 2.1210276186466217

Epoch: 5| Step: 4
Training loss: 2.130535364151001
Validation loss: 2.1352948397397995

Epoch: 5| Step: 5
Training loss: 1.7926620244979858
Validation loss: 2.1319347570339837

Epoch: 5| Step: 6
Training loss: 1.6064815521240234
Validation loss: 2.1358900517225266

Epoch: 5| Step: 7
Training loss: 1.3856515884399414
Validation loss: 2.1371729920307794

Epoch: 5| Step: 8
Training loss: 1.8416532278060913
Validation loss: 2.1345365891853967

Epoch: 5| Step: 9
Training loss: 2.3908839225769043
Validation loss: 2.1476801186800003

Epoch: 5| Step: 10
Training loss: 1.9036182165145874
Validation loss: 2.1529435316721597

Epoch: 5| Step: 11
Training loss: 1.3828233480453491
Validation loss: 2.1509568442900977

Epoch: 218| Step: 0
Training loss: 1.771761178970337
Validation loss: 2.138493518034617

Epoch: 5| Step: 1
Training loss: 1.9281139373779297
Validation loss: 2.1329284012317657

Epoch: 5| Step: 2
Training loss: 2.5590529441833496
Validation loss: 2.143212432662646

Epoch: 5| Step: 3
Training loss: 1.8522002696990967
Validation loss: 2.1368299076954522

Epoch: 5| Step: 4
Training loss: 1.4818745851516724
Validation loss: 2.137652039527893

Epoch: 5| Step: 5
Training loss: 1.8333889245986938
Validation loss: 2.150948385397593

Epoch: 5| Step: 6
Training loss: 1.5473918914794922
Validation loss: 2.1377642999092736

Epoch: 5| Step: 7
Training loss: 1.8875420093536377
Validation loss: 2.1499931812286377

Epoch: 5| Step: 8
Training loss: 1.537435531616211
Validation loss: 2.1534862319628396

Epoch: 5| Step: 9
Training loss: 1.8292162418365479
Validation loss: 2.144867484768232

Epoch: 5| Step: 10
Training loss: 1.905752420425415
Validation loss: 2.1491981893777847

Epoch: 5| Step: 11
Training loss: 2.0317366123199463
Validation loss: 2.1400489608446756

Epoch: 219| Step: 0
Training loss: 1.7154051065444946
Validation loss: 2.1497016797463098

Epoch: 5| Step: 1
Training loss: 2.063189744949341
Validation loss: 2.1697089970111847

Epoch: 5| Step: 2
Training loss: 1.8833134174346924
Validation loss: 2.1525341918071113

Epoch: 5| Step: 3
Training loss: 1.8263463973999023
Validation loss: 2.1409007906913757

Epoch: 5| Step: 4
Training loss: 1.4758703708648682
Validation loss: 2.149166817466418

Epoch: 5| Step: 5
Training loss: 2.3719725608825684
Validation loss: 2.150560289621353

Epoch: 5| Step: 6
Training loss: 1.3392460346221924
Validation loss: 2.1347426772117615

Epoch: 5| Step: 7
Training loss: 1.910271406173706
Validation loss: 2.123645549019178

Epoch: 5| Step: 8
Training loss: 2.1286792755126953
Validation loss: 2.1151761015256247

Epoch: 5| Step: 9
Training loss: 2.055743932723999
Validation loss: 2.1219264765580497

Epoch: 5| Step: 10
Training loss: 1.5126957893371582
Validation loss: 2.1203653514385223

Epoch: 5| Step: 11
Training loss: 2.102436065673828
Validation loss: 2.1251077155272164

Epoch: 220| Step: 0
Training loss: 1.6561800241470337
Validation loss: 2.125854561726252

Epoch: 5| Step: 1
Training loss: 2.1643147468566895
Validation loss: 2.142730509241422

Epoch: 5| Step: 2
Training loss: 1.3821492195129395
Validation loss: 2.14757647116979

Epoch: 5| Step: 3
Training loss: 1.5010089874267578
Validation loss: 2.1284080743789673

Epoch: 5| Step: 4
Training loss: 1.541216492652893
Validation loss: 2.1466593792041144

Epoch: 5| Step: 5
Training loss: 2.0364954471588135
Validation loss: 2.1649674077828727

Epoch: 5| Step: 6
Training loss: 1.2230980396270752
Validation loss: 2.16771266857783

Epoch: 5| Step: 7
Training loss: 1.8437535762786865
Validation loss: 2.191855266690254

Epoch: 5| Step: 8
Training loss: 2.142543315887451
Validation loss: 2.2007612586021423

Epoch: 5| Step: 9
Training loss: 2.7691144943237305
Validation loss: 2.199230268597603

Epoch: 5| Step: 10
Training loss: 2.1507668495178223
Validation loss: 2.179166927933693

Epoch: 5| Step: 11
Training loss: 3.0317840576171875
Validation loss: 2.1859633276859918

Epoch: 221| Step: 0
Training loss: 2.077610492706299
Validation loss: 2.1910148362318673

Epoch: 5| Step: 1
Training loss: 1.7772388458251953
Validation loss: 2.1839584658543267

Epoch: 5| Step: 2
Training loss: 1.5748646259307861
Validation loss: 2.146617293357849

Epoch: 5| Step: 3
Training loss: 1.6520999670028687
Validation loss: 2.1609793653090796

Epoch: 5| Step: 4
Training loss: 1.477327823638916
Validation loss: 2.147363086541494

Epoch: 5| Step: 5
Training loss: 1.499036431312561
Validation loss: 2.1423844198385873

Epoch: 5| Step: 6
Training loss: 2.1123530864715576
Validation loss: 2.15495258073012

Epoch: 5| Step: 7
Training loss: 1.8637282848358154
Validation loss: 2.1363855749368668

Epoch: 5| Step: 8
Training loss: 2.112792491912842
Validation loss: 2.1299032916625342

Epoch: 5| Step: 9
Training loss: 1.7869117259979248
Validation loss: 2.1317408780256906

Epoch: 5| Step: 10
Training loss: 2.3427891731262207
Validation loss: 2.139098679025968

Epoch: 5| Step: 11
Training loss: 1.4719984531402588
Validation loss: 2.1455667167901993

Epoch: 222| Step: 0
Training loss: 1.892892837524414
Validation loss: 2.137925828496615

Epoch: 5| Step: 1
Training loss: 1.7369903326034546
Validation loss: 2.1550405422846475

Epoch: 5| Step: 2
Training loss: 2.267096519470215
Validation loss: 2.1460788398981094

Epoch: 5| Step: 3
Training loss: 1.3667051792144775
Validation loss: 2.1426099836826324

Epoch: 5| Step: 4
Training loss: 2.1082193851470947
Validation loss: 2.1456842670838037

Epoch: 5| Step: 5
Training loss: 1.6540071964263916
Validation loss: 2.1359865764776864

Epoch: 5| Step: 6
Training loss: 1.8689152002334595
Validation loss: 2.1277877489725747

Epoch: 5| Step: 7
Training loss: 1.5721111297607422
Validation loss: 2.1358602245648703

Epoch: 5| Step: 8
Training loss: 1.818447470664978
Validation loss: 2.1426349679629006

Epoch: 5| Step: 9
Training loss: 2.410545825958252
Validation loss: 2.1445303857326508

Epoch: 5| Step: 10
Training loss: 1.3970134258270264
Validation loss: 2.148770332336426

Epoch: 5| Step: 11
Training loss: 1.2535598278045654
Validation loss: 2.1536695063114166

Epoch: 223| Step: 0
Training loss: 1.6355161666870117
Validation loss: 2.1633041401704154

Epoch: 5| Step: 1
Training loss: 2.1096925735473633
Validation loss: 2.156170278787613

Epoch: 5| Step: 2
Training loss: 1.6234800815582275
Validation loss: 2.155598590771357

Epoch: 5| Step: 3
Training loss: 1.8902950286865234
Validation loss: 2.1583133141199746

Epoch: 5| Step: 4
Training loss: 1.8057372570037842
Validation loss: 2.1533689747254052

Epoch: 5| Step: 5
Training loss: 2.008256435394287
Validation loss: 2.1408345252275467

Epoch: 5| Step: 6
Training loss: 1.745753526687622
Validation loss: 2.1518424352010093

Epoch: 5| Step: 7
Training loss: 2.101489305496216
Validation loss: 2.1559782326221466

Epoch: 5| Step: 8
Training loss: 1.6772619485855103
Validation loss: 2.1341572304566703

Epoch: 5| Step: 9
Training loss: 1.975234031677246
Validation loss: 2.1470222175121307

Epoch: 5| Step: 10
Training loss: 1.5740102529525757
Validation loss: 2.1339914401372275

Epoch: 5| Step: 11
Training loss: 0.939423680305481
Validation loss: 2.152926484743754

Epoch: 224| Step: 0
Training loss: 1.8704421520233154
Validation loss: 2.1570191333691278

Epoch: 5| Step: 1
Training loss: 1.2947639226913452
Validation loss: 2.1673242350419364

Epoch: 5| Step: 2
Training loss: 1.7733291387557983
Validation loss: 2.1740583131710687

Epoch: 5| Step: 3
Training loss: 2.5716214179992676
Validation loss: 2.188479498028755

Epoch: 5| Step: 4
Training loss: 2.153498888015747
Validation loss: 2.1893148918946586

Epoch: 5| Step: 5
Training loss: 1.966139793395996
Validation loss: 2.192852889498075

Epoch: 5| Step: 6
Training loss: 1.6345335245132446
Validation loss: 2.1985598305861154

Epoch: 5| Step: 7
Training loss: 1.68994140625
Validation loss: 2.167469799518585

Epoch: 5| Step: 8
Training loss: 1.7712539434432983
Validation loss: 2.156503548224767

Epoch: 5| Step: 9
Training loss: 1.1923434734344482
Validation loss: 2.1670087476571402

Epoch: 5| Step: 10
Training loss: 2.049564838409424
Validation loss: 2.1657635817925134

Epoch: 5| Step: 11
Training loss: 1.147174596786499
Validation loss: 2.1553313732147217

Epoch: 225| Step: 0
Training loss: 2.2293741703033447
Validation loss: 2.1542556633551917

Epoch: 5| Step: 1
Training loss: 1.6761735677719116
Validation loss: 2.1497307866811752

Epoch: 5| Step: 2
Training loss: 1.3660578727722168
Validation loss: 2.148206129670143

Epoch: 5| Step: 3
Training loss: 1.4833958148956299
Validation loss: 2.1641526917616525

Epoch: 5| Step: 4
Training loss: 1.854265809059143
Validation loss: 2.1560686031977334

Epoch: 5| Step: 5
Training loss: 1.9981905221939087
Validation loss: 2.1627316772937775

Epoch: 5| Step: 6
Training loss: 1.4572970867156982
Validation loss: 2.1523247907559075

Epoch: 5| Step: 7
Training loss: 1.9800965785980225
Validation loss: 2.1598624140024185

Epoch: 5| Step: 8
Training loss: 1.8828115463256836
Validation loss: 2.1690291861693063

Epoch: 5| Step: 9
Training loss: 2.0256028175354004
Validation loss: 2.1746550599733987

Epoch: 5| Step: 10
Training loss: 1.817403793334961
Validation loss: 2.1809410403172174

Epoch: 5| Step: 11
Training loss: 1.8087421655654907
Validation loss: 2.1559934417406716

Epoch: 226| Step: 0
Training loss: 2.008570671081543
Validation loss: 2.1783077816168466

Epoch: 5| Step: 1
Training loss: 2.594467878341675
Validation loss: 2.1724093159039817

Epoch: 5| Step: 2
Training loss: 1.189989447593689
Validation loss: 2.1730055809020996

Epoch: 5| Step: 3
Training loss: 1.894396185874939
Validation loss: 2.1619651913642883

Epoch: 5| Step: 4
Training loss: 1.5303752422332764
Validation loss: 2.154465431968371

Epoch: 5| Step: 5
Training loss: 1.7378103733062744
Validation loss: 2.1540058652559915

Epoch: 5| Step: 6
Training loss: 1.8123195171356201
Validation loss: 2.158903181552887

Epoch: 5| Step: 7
Training loss: 2.086040735244751
Validation loss: 2.139404316743215

Epoch: 5| Step: 8
Training loss: 1.6570870876312256
Validation loss: 2.1553136110305786

Epoch: 5| Step: 9
Training loss: 1.341652512550354
Validation loss: 2.152567063768705

Epoch: 5| Step: 10
Training loss: 2.123849868774414
Validation loss: 2.155236765742302

Epoch: 5| Step: 11
Training loss: 1.0097403526306152
Validation loss: 2.1424910922845206

Epoch: 227| Step: 0
Training loss: 1.5172189474105835
Validation loss: 2.1580203821261725

Epoch: 5| Step: 1
Training loss: 2.0868005752563477
Validation loss: 2.149106959501902

Epoch: 5| Step: 2
Training loss: 2.154522180557251
Validation loss: 2.140899216135343

Epoch: 5| Step: 3
Training loss: 1.512986660003662
Validation loss: 2.1430244892835617

Epoch: 5| Step: 4
Training loss: 1.4528852701187134
Validation loss: 2.1769230564435325

Epoch: 5| Step: 5
Training loss: 2.4546234607696533
Validation loss: 2.186551253000895

Epoch: 5| Step: 6
Training loss: 1.7167068719863892
Validation loss: 2.202373762925466

Epoch: 5| Step: 7
Training loss: 2.1264522075653076
Validation loss: 2.184045116106669

Epoch: 5| Step: 8
Training loss: 1.7171614170074463
Validation loss: 2.190446456273397

Epoch: 5| Step: 9
Training loss: 1.3716844320297241
Validation loss: 2.1911428372065225

Epoch: 5| Step: 10
Training loss: 2.0502071380615234
Validation loss: 2.175799240668615

Epoch: 5| Step: 11
Training loss: 1.4802170991897583
Validation loss: 2.16842512289683

Epoch: 228| Step: 0
Training loss: 1.849923849105835
Validation loss: 2.1663542687892914

Epoch: 5| Step: 1
Training loss: 1.5116338729858398
Validation loss: 2.1610312710205712

Epoch: 5| Step: 2
Training loss: 2.180922269821167
Validation loss: 2.1487887700398765

Epoch: 5| Step: 3
Training loss: 2.2445855140686035
Validation loss: 2.134478062391281

Epoch: 5| Step: 4
Training loss: 1.8104482889175415
Validation loss: 2.1373778879642487

Epoch: 5| Step: 5
Training loss: 2.12947416305542
Validation loss: 2.139838293194771

Epoch: 5| Step: 6
Training loss: 2.1616768836975098
Validation loss: 2.134643872578939

Epoch: 5| Step: 7
Training loss: 1.8261533975601196
Validation loss: 2.1593324691057205

Epoch: 5| Step: 8
Training loss: 1.3845676183700562
Validation loss: 2.1465586870908737

Epoch: 5| Step: 9
Training loss: 1.6001535654067993
Validation loss: 2.14377028743426

Epoch: 5| Step: 10
Training loss: 1.7159512042999268
Validation loss: 2.165366436044375

Epoch: 5| Step: 11
Training loss: 1.2093074321746826
Validation loss: 2.1563237508138022

Epoch: 229| Step: 0
Training loss: 2.0615105628967285
Validation loss: 2.1625697712103524

Epoch: 5| Step: 1
Training loss: 1.6683664321899414
Validation loss: 2.172201231122017

Epoch: 5| Step: 2
Training loss: 1.9524199962615967
Validation loss: 2.1591679006814957

Epoch: 5| Step: 3
Training loss: 1.8067123889923096
Validation loss: 2.1574987173080444

Epoch: 5| Step: 4
Training loss: 1.7552350759506226
Validation loss: 2.1568928758303323

Epoch: 5| Step: 5
Training loss: 1.8782857656478882
Validation loss: 2.1833707888921103

Epoch: 5| Step: 6
Training loss: 1.4969725608825684
Validation loss: 2.1710559825102487

Epoch: 5| Step: 7
Training loss: 1.7786718606948853
Validation loss: 2.184364140033722

Epoch: 5| Step: 8
Training loss: 1.8472068309783936
Validation loss: 2.1659090717633567

Epoch: 5| Step: 9
Training loss: 2.1518895626068115
Validation loss: 2.1758438100417457

Epoch: 5| Step: 10
Training loss: 1.3864567279815674
Validation loss: 2.1654071112473807

Epoch: 5| Step: 11
Training loss: 1.681821584701538
Validation loss: 2.1674108505249023

Epoch: 230| Step: 0
Training loss: 1.4021075963974
Validation loss: 2.191258649031321

Epoch: 5| Step: 1
Training loss: 1.9315052032470703
Validation loss: 2.187956601381302

Epoch: 5| Step: 2
Training loss: 1.3084490299224854
Validation loss: 2.1942468682924905

Epoch: 5| Step: 3
Training loss: 1.6350631713867188
Validation loss: 2.183058500289917

Epoch: 5| Step: 4
Training loss: 2.2492594718933105
Validation loss: 2.1392906308174133

Epoch: 5| Step: 5
Training loss: 1.7961689233779907
Validation loss: 2.113861545920372

Epoch: 5| Step: 6
Training loss: 1.5970951318740845
Validation loss: 2.1143054415782294

Epoch: 5| Step: 7
Training loss: 1.8093059062957764
Validation loss: 2.11512083808581

Epoch: 5| Step: 8
Training loss: 2.642350912094116
Validation loss: 2.1260042836268744

Epoch: 5| Step: 9
Training loss: 1.9662363529205322
Validation loss: 2.124642491340637

Epoch: 5| Step: 10
Training loss: 2.527174472808838
Validation loss: 2.124358276526133

Epoch: 5| Step: 11
Training loss: 1.4766429662704468
Validation loss: 2.130133638779322

Epoch: 231| Step: 0
Training loss: 1.687146544456482
Validation loss: 2.118826006849607

Epoch: 5| Step: 1
Training loss: 1.9256436824798584
Validation loss: 2.129236181577047

Epoch: 5| Step: 2
Training loss: 1.8731645345687866
Validation loss: 2.1378178149461746

Epoch: 5| Step: 3
Training loss: 1.8391942977905273
Validation loss: 2.1360581119855246

Epoch: 5| Step: 4
Training loss: 1.6961441040039062
Validation loss: 2.148489569624265

Epoch: 5| Step: 5
Training loss: 1.8308576345443726
Validation loss: 2.149590775370598

Epoch: 5| Step: 6
Training loss: 1.5878826379776
Validation loss: 2.142059803009033

Epoch: 5| Step: 7
Training loss: 1.9087975025177002
Validation loss: 2.1509483257929483

Epoch: 5| Step: 8
Training loss: 1.8051700592041016
Validation loss: 2.1590407540400824

Epoch: 5| Step: 9
Training loss: 2.0703251361846924
Validation loss: 2.1375494400660195

Epoch: 5| Step: 10
Training loss: 1.7630321979522705
Validation loss: 2.144224002957344

Epoch: 5| Step: 11
Training loss: 2.2438948154449463
Validation loss: 2.173308342695236

Epoch: 232| Step: 0
Training loss: 2.0477142333984375
Validation loss: 2.1479732443888984

Epoch: 5| Step: 1
Training loss: 2.1499054431915283
Validation loss: 2.1518306583166122

Epoch: 5| Step: 2
Training loss: 1.9246371984481812
Validation loss: 2.137201026082039

Epoch: 5| Step: 3
Training loss: 1.751805067062378
Validation loss: 2.145555466413498

Epoch: 5| Step: 4
Training loss: 1.7772048711776733
Validation loss: 2.143540233373642

Epoch: 5| Step: 5
Training loss: 1.7879711389541626
Validation loss: 2.1433918327093124

Epoch: 5| Step: 6
Training loss: 2.1087424755096436
Validation loss: 2.1422429184118905

Epoch: 5| Step: 7
Training loss: 1.843183159828186
Validation loss: 2.1413753231366477

Epoch: 5| Step: 8
Training loss: 1.1981881856918335
Validation loss: 2.149814267953237

Epoch: 5| Step: 9
Training loss: 1.3643028736114502
Validation loss: 2.137874116500219

Epoch: 5| Step: 10
Training loss: 2.3130710124969482
Validation loss: 2.137032444278399

Epoch: 5| Step: 11
Training loss: 0.8735196590423584
Validation loss: 2.163021003206571

Epoch: 233| Step: 0
Training loss: 2.076288938522339
Validation loss: 2.1433361023664474

Epoch: 5| Step: 1
Training loss: 1.4004671573638916
Validation loss: 2.1550311793883643

Epoch: 5| Step: 2
Training loss: 2.17093563079834
Validation loss: 2.146248698234558

Epoch: 5| Step: 3
Training loss: 1.5008363723754883
Validation loss: 2.175822526216507

Epoch: 5| Step: 4
Training loss: 2.1465322971343994
Validation loss: 2.165971875190735

Epoch: 5| Step: 5
Training loss: 1.3647639751434326
Validation loss: 2.162425105770429

Epoch: 5| Step: 6
Training loss: 1.6704914569854736
Validation loss: 2.182639574011167

Epoch: 5| Step: 7
Training loss: 2.167924165725708
Validation loss: 2.1651378770669303

Epoch: 5| Step: 8
Training loss: 1.3765650987625122
Validation loss: 2.1897013187408447

Epoch: 5| Step: 9
Training loss: 2.0667316913604736
Validation loss: 2.1827695071697235

Epoch: 5| Step: 10
Training loss: 1.832279920578003
Validation loss: 2.1695919235547385

Epoch: 5| Step: 11
Training loss: 1.633798599243164
Validation loss: 2.18218757212162

Epoch: 234| Step: 0
Training loss: 1.955265998840332
Validation loss: 2.1982162296772003

Epoch: 5| Step: 1
Training loss: 1.7259432077407837
Validation loss: 2.2258702317873635

Epoch: 5| Step: 2
Training loss: 2.016976833343506
Validation loss: 2.1941106816132865

Epoch: 5| Step: 3
Training loss: 1.7216047048568726
Validation loss: 2.197842607895533

Epoch: 5| Step: 4
Training loss: 1.8433704376220703
Validation loss: 2.1696130683024726

Epoch: 5| Step: 5
Training loss: 1.5855391025543213
Validation loss: 2.168289373318354

Epoch: 5| Step: 6
Training loss: 1.7423168420791626
Validation loss: 2.1886122624079385

Epoch: 5| Step: 7
Training loss: 1.9229371547698975
Validation loss: 2.1616306006908417

Epoch: 5| Step: 8
Training loss: 1.5987696647644043
Validation loss: 2.1826110631227493

Epoch: 5| Step: 9
Training loss: 2.035655975341797
Validation loss: 2.1799083401759467

Epoch: 5| Step: 10
Training loss: 1.5636866092681885
Validation loss: 2.177270770072937

Epoch: 5| Step: 11
Training loss: 1.555850625038147
Validation loss: 2.1802319437265396

Epoch: 235| Step: 0
Training loss: 1.7478744983673096
Validation loss: 2.201080391804377

Epoch: 5| Step: 1
Training loss: 1.5928748846054077
Validation loss: 2.176574945449829

Epoch: 5| Step: 2
Training loss: 2.056675672531128
Validation loss: 2.1572285344203315

Epoch: 5| Step: 3
Training loss: 2.2463676929473877
Validation loss: 2.155452330907186

Epoch: 5| Step: 4
Training loss: 1.7947933673858643
Validation loss: 2.1756704598665237

Epoch: 5| Step: 5
Training loss: 1.9748090505599976
Validation loss: 2.166916693250338

Epoch: 5| Step: 6
Training loss: 1.3532741069793701
Validation loss: 2.1859658459822335

Epoch: 5| Step: 7
Training loss: 1.8140058517456055
Validation loss: 2.1764995058377585

Epoch: 5| Step: 8
Training loss: 1.5869176387786865
Validation loss: 2.178150181969007

Epoch: 5| Step: 9
Training loss: 1.7789980173110962
Validation loss: 2.169244666894277

Epoch: 5| Step: 10
Training loss: 1.5749623775482178
Validation loss: 2.173388401667277

Epoch: 5| Step: 11
Training loss: 2.1332104206085205
Validation loss: 2.1705822894970574

Epoch: 236| Step: 0
Training loss: 1.4922412633895874
Validation loss: 2.183501496911049

Epoch: 5| Step: 1
Training loss: 2.1942903995513916
Validation loss: 2.174036572376887

Epoch: 5| Step: 2
Training loss: 1.7199475765228271
Validation loss: 2.1762165973583856

Epoch: 5| Step: 3
Training loss: 1.6618759632110596
Validation loss: 2.19975679119428

Epoch: 5| Step: 4
Training loss: 1.722521185874939
Validation loss: 2.192095955212911

Epoch: 5| Step: 5
Training loss: 1.7032134532928467
Validation loss: 2.199875464042028

Epoch: 5| Step: 6
Training loss: 2.0156993865966797
Validation loss: 2.2009586294492087

Epoch: 5| Step: 7
Training loss: 1.302555799484253
Validation loss: 2.1770676374435425

Epoch: 5| Step: 8
Training loss: 1.8530677556991577
Validation loss: 2.1720828910668692

Epoch: 5| Step: 9
Training loss: 1.891474962234497
Validation loss: 2.186957617600759

Epoch: 5| Step: 10
Training loss: 2.149116277694702
Validation loss: 2.1679320335388184

Epoch: 5| Step: 11
Training loss: 1.6281697750091553
Validation loss: 2.178225119908651

Epoch: 237| Step: 0
Training loss: 1.7448170185089111
Validation loss: 2.160985514521599

Epoch: 5| Step: 1
Training loss: 1.5517994165420532
Validation loss: 2.1746056030193963

Epoch: 5| Step: 2
Training loss: 2.0533053874969482
Validation loss: 2.160913184285164

Epoch: 5| Step: 3
Training loss: 1.5508198738098145
Validation loss: 2.192606767018636

Epoch: 5| Step: 4
Training loss: 1.931082010269165
Validation loss: 2.1951251327991486

Epoch: 5| Step: 5
Training loss: 2.1911444664001465
Validation loss: 2.219349205493927

Epoch: 5| Step: 6
Training loss: 1.2386839389801025
Validation loss: 2.1956389596064887

Epoch: 5| Step: 7
Training loss: 2.183939218521118
Validation loss: 2.2199349204699197

Epoch: 5| Step: 8
Training loss: 1.783496618270874
Validation loss: 2.197377825776736

Epoch: 5| Step: 9
Training loss: 1.6868807077407837
Validation loss: 2.196175972620646

Epoch: 5| Step: 10
Training loss: 1.7086604833602905
Validation loss: 2.1860054035981498

Epoch: 5| Step: 11
Training loss: 2.4957034587860107
Validation loss: 2.1814066817363105

Epoch: 238| Step: 0
Training loss: 1.7630904912948608
Validation loss: 2.168813164035479

Epoch: 5| Step: 1
Training loss: 1.4842264652252197
Validation loss: 2.162393808364868

Epoch: 5| Step: 2
Training loss: 1.5817792415618896
Validation loss: 2.154569923877716

Epoch: 5| Step: 3
Training loss: 2.10390043258667
Validation loss: 2.142020270228386

Epoch: 5| Step: 4
Training loss: 2.055178165435791
Validation loss: 2.142302304506302

Epoch: 5| Step: 5
Training loss: 2.2307212352752686
Validation loss: 2.1447315365076065

Epoch: 5| Step: 6
Training loss: 2.4077091217041016
Validation loss: 2.146277149518331

Epoch: 5| Step: 7
Training loss: 1.8707435131072998
Validation loss: 2.1671288162469864

Epoch: 5| Step: 8
Training loss: 1.283019781112671
Validation loss: 2.1690044651428857

Epoch: 5| Step: 9
Training loss: 2.0529592037200928
Validation loss: 2.1741512368122735

Epoch: 5| Step: 10
Training loss: 1.525724172592163
Validation loss: 2.1582642992337546

Epoch: 5| Step: 11
Training loss: 0.6962388753890991
Validation loss: 2.167694936196009

Epoch: 239| Step: 0
Training loss: 1.7014272212982178
Validation loss: 2.1733019749323526

Epoch: 5| Step: 1
Training loss: 1.1777766942977905
Validation loss: 2.1732501884301505

Epoch: 5| Step: 2
Training loss: 2.0837786197662354
Validation loss: 2.2015721102555594

Epoch: 5| Step: 3
Training loss: 1.7288572788238525
Validation loss: 2.180968761444092

Epoch: 5| Step: 4
Training loss: 1.6049911975860596
Validation loss: 2.1817437559366226

Epoch: 5| Step: 5
Training loss: 2.223489284515381
Validation loss: 2.172782301902771

Epoch: 5| Step: 6
Training loss: 2.1321473121643066
Validation loss: 2.147797400752703

Epoch: 5| Step: 7
Training loss: 1.3943783044815063
Validation loss: 2.1636201441287994

Epoch: 5| Step: 8
Training loss: 1.7566521167755127
Validation loss: 2.176534414291382

Epoch: 5| Step: 9
Training loss: 1.7230851650238037
Validation loss: 2.176951805750529

Epoch: 5| Step: 10
Training loss: 2.207313060760498
Validation loss: 2.1528172294298806

Epoch: 5| Step: 11
Training loss: 0.8538296222686768
Validation loss: 2.159009357293447

Epoch: 240| Step: 0
Training loss: 1.3812164068222046
Validation loss: 2.1641099750995636

Epoch: 5| Step: 1
Training loss: 2.2753067016601562
Validation loss: 2.1600183496872583

Epoch: 5| Step: 2
Training loss: 1.5796090364456177
Validation loss: 2.1868129620949426

Epoch: 5| Step: 3
Training loss: 1.886268973350525
Validation loss: 2.184984182318052

Epoch: 5| Step: 4
Training loss: 1.6415246725082397
Validation loss: 2.177753378947576

Epoch: 5| Step: 5
Training loss: 1.643872857093811
Validation loss: 2.1762962539990744

Epoch: 5| Step: 6
Training loss: 2.3701767921447754
Validation loss: 2.1980717976888022

Epoch: 5| Step: 7
Training loss: 2.459953784942627
Validation loss: 2.1699845840533576

Epoch: 5| Step: 8
Training loss: 1.425506830215454
Validation loss: 2.1568385461966195

Epoch: 5| Step: 9
Training loss: 1.2606852054595947
Validation loss: 2.156397874156634

Epoch: 5| Step: 10
Training loss: 1.4125359058380127
Validation loss: 2.1565488626559577

Epoch: 5| Step: 11
Training loss: 1.3469429016113281
Validation loss: 2.149661978085836

Epoch: 241| Step: 0
Training loss: 1.7656456232070923
Validation loss: 2.167694866657257

Epoch: 5| Step: 1
Training loss: 1.350306510925293
Validation loss: 2.167201062043508

Epoch: 5| Step: 2
Training loss: 1.7588584423065186
Validation loss: 2.1771704157193503

Epoch: 5| Step: 3
Training loss: 1.446903944015503
Validation loss: 2.1755259732405343

Epoch: 5| Step: 4
Training loss: 1.5655014514923096
Validation loss: 2.1693029403686523

Epoch: 5| Step: 5
Training loss: 1.923760175704956
Validation loss: 2.1826178232828775

Epoch: 5| Step: 6
Training loss: 2.2240443229675293
Validation loss: 2.1867381681998572

Epoch: 5| Step: 7
Training loss: 2.265512228012085
Validation loss: 2.1730232735474906

Epoch: 5| Step: 8
Training loss: 1.7482414245605469
Validation loss: 2.1846641898155212

Epoch: 5| Step: 9
Training loss: 1.8959083557128906
Validation loss: 2.1836808870236077

Epoch: 5| Step: 10
Training loss: 1.6181461811065674
Validation loss: 2.1822048723697662

Epoch: 5| Step: 11
Training loss: 1.767134666442871
Validation loss: 2.1785750836133957

Epoch: 242| Step: 0
Training loss: 2.744734048843384
Validation loss: 2.171099682648977

Epoch: 5| Step: 1
Training loss: 1.8510414361953735
Validation loss: 2.1721932093302407

Epoch: 5| Step: 2
Training loss: 0.8844562768936157
Validation loss: 2.177242731054624

Epoch: 5| Step: 3
Training loss: 1.5516743659973145
Validation loss: 2.1744413475195565

Epoch: 5| Step: 4
Training loss: 1.5485910177230835
Validation loss: 2.20257302125295

Epoch: 5| Step: 5
Training loss: 1.2373920679092407
Validation loss: 2.1994393865267434

Epoch: 5| Step: 6
Training loss: 1.817547082901001
Validation loss: 2.1798197428385415

Epoch: 5| Step: 7
Training loss: 1.7016900777816772
Validation loss: 2.1815866927305856

Epoch: 5| Step: 8
Training loss: 2.021775722503662
Validation loss: 2.1877702673276267

Epoch: 5| Step: 9
Training loss: 1.8126287460327148
Validation loss: 2.1765578190485635

Epoch: 5| Step: 10
Training loss: 2.2766776084899902
Validation loss: 2.188269297281901

Epoch: 5| Step: 11
Training loss: 1.0578081607818604
Validation loss: 2.17161563038826

Epoch: 243| Step: 0
Training loss: 2.1232192516326904
Validation loss: 2.1608566641807556

Epoch: 5| Step: 1
Training loss: 1.4824440479278564
Validation loss: 2.1933334271113076

Epoch: 5| Step: 2
Training loss: 2.207127094268799
Validation loss: 2.1621906061967215

Epoch: 5| Step: 3
Training loss: 1.448958396911621
Validation loss: 2.1553448190291724

Epoch: 5| Step: 4
Training loss: 1.4141064882278442
Validation loss: 2.192938302954038

Epoch: 5| Step: 5
Training loss: 1.828774094581604
Validation loss: 2.184540887673696

Epoch: 5| Step: 6
Training loss: 2.10383677482605
Validation loss: 2.1838416308164597

Epoch: 5| Step: 7
Training loss: 1.580450177192688
Validation loss: 2.1792975713809333

Epoch: 5| Step: 8
Training loss: 1.8965160846710205
Validation loss: 2.1954039931297302

Epoch: 5| Step: 9
Training loss: 1.9631643295288086
Validation loss: 2.191127965847651

Epoch: 5| Step: 10
Training loss: 1.3887779712677002
Validation loss: 2.198496455947558

Epoch: 5| Step: 11
Training loss: 2.6874606609344482
Validation loss: 2.1818332175413766

Epoch: 244| Step: 0
Training loss: 1.7899773120880127
Validation loss: 2.190617322921753

Epoch: 5| Step: 1
Training loss: 2.2971854209899902
Validation loss: 2.193277284502983

Epoch: 5| Step: 2
Training loss: 2.179893970489502
Validation loss: 2.172119528055191

Epoch: 5| Step: 3
Training loss: 1.6248019933700562
Validation loss: 2.200517018636068

Epoch: 5| Step: 4
Training loss: 1.4776476621627808
Validation loss: 2.2058920562267303

Epoch: 5| Step: 5
Training loss: 1.8576942682266235
Validation loss: 2.2079851975043616

Epoch: 5| Step: 6
Training loss: 1.6718528270721436
Validation loss: 2.2028987308343253

Epoch: 5| Step: 7
Training loss: 1.8359215259552002
Validation loss: 2.220149487257004

Epoch: 5| Step: 8
Training loss: 1.575119137763977
Validation loss: 2.2122580210367837

Epoch: 5| Step: 9
Training loss: 1.5852197408676147
Validation loss: 2.1822884182135263

Epoch: 5| Step: 10
Training loss: 1.606022834777832
Validation loss: 2.1825275868177414

Epoch: 5| Step: 11
Training loss: 1.3742420673370361
Validation loss: 2.164544632037481

Epoch: 245| Step: 0
Training loss: 1.6962543725967407
Validation loss: 2.1920318603515625

Epoch: 5| Step: 1
Training loss: 1.5734059810638428
Validation loss: 2.178090587258339

Epoch: 5| Step: 2
Training loss: 1.886789083480835
Validation loss: 2.138063222169876

Epoch: 5| Step: 3
Training loss: 1.7300548553466797
Validation loss: 2.140979881087939

Epoch: 5| Step: 4
Training loss: 2.0855395793914795
Validation loss: 2.1670929292837777

Epoch: 5| Step: 5
Training loss: 2.0898189544677734
Validation loss: 2.1829978823661804

Epoch: 5| Step: 6
Training loss: 1.5862643718719482
Validation loss: 2.182201862335205

Epoch: 5| Step: 7
Training loss: 1.7641149759292603
Validation loss: 2.1911463886499405

Epoch: 5| Step: 8
Training loss: 1.993353247642517
Validation loss: 2.1834767560164132

Epoch: 5| Step: 9
Training loss: 1.8077738285064697
Validation loss: 2.226590245962143

Epoch: 5| Step: 10
Training loss: 1.0563701391220093
Validation loss: 2.212319031357765

Epoch: 5| Step: 11
Training loss: 2.498774528503418
Validation loss: 2.2032095144192376

Epoch: 246| Step: 0
Training loss: 1.249538540840149
Validation loss: 2.1936137825250626

Epoch: 5| Step: 1
Training loss: 2.0067601203918457
Validation loss: 2.189221973220507

Epoch: 5| Step: 2
Training loss: 1.981292963027954
Validation loss: 2.1944696803887687

Epoch: 5| Step: 3
Training loss: 1.5925618410110474
Validation loss: 2.2082054764032364

Epoch: 5| Step: 4
Training loss: 1.8576281070709229
Validation loss: 2.1721137960751853

Epoch: 5| Step: 5
Training loss: 1.6972205638885498
Validation loss: 2.166407893101374

Epoch: 5| Step: 6
Training loss: 2.050264835357666
Validation loss: 2.1640676160653434

Epoch: 5| Step: 7
Training loss: 1.5336134433746338
Validation loss: 2.168844530979792

Epoch: 5| Step: 8
Training loss: 1.8935859203338623
Validation loss: 2.1648499816656113

Epoch: 5| Step: 9
Training loss: 1.964999794960022
Validation loss: 2.1722314804792404

Epoch: 5| Step: 10
Training loss: 1.5346252918243408
Validation loss: 2.188593174020449

Epoch: 5| Step: 11
Training loss: 1.9304698705673218
Validation loss: 2.1841482867797217

Epoch: 247| Step: 0
Training loss: 1.5793163776397705
Validation loss: 2.197220206260681

Epoch: 5| Step: 1
Training loss: 1.6459077596664429
Validation loss: 2.191429982582728

Epoch: 5| Step: 2
Training loss: 2.169670820236206
Validation loss: 2.19266344110171

Epoch: 5| Step: 3
Training loss: 1.3730531930923462
Validation loss: 2.1849268774191537

Epoch: 5| Step: 4
Training loss: 1.6133610010147095
Validation loss: 2.194421281417211

Epoch: 5| Step: 5
Training loss: 2.0037968158721924
Validation loss: 2.1987392008304596

Epoch: 5| Step: 6
Training loss: 1.7651447057724
Validation loss: 2.201791067918142

Epoch: 5| Step: 7
Training loss: 1.3732115030288696
Validation loss: 2.2071670591831207

Epoch: 5| Step: 8
Training loss: 1.7335052490234375
Validation loss: 2.1881402979294458

Epoch: 5| Step: 9
Training loss: 2.109945774078369
Validation loss: 2.198197821776072

Epoch: 5| Step: 10
Training loss: 1.8665030002593994
Validation loss: 2.174706220626831

Epoch: 5| Step: 11
Training loss: 1.0673648118972778
Validation loss: 2.1607397198677063

Epoch: 248| Step: 0
Training loss: 1.3572239875793457
Validation loss: 2.153559615214666

Epoch: 5| Step: 1
Training loss: 1.5086276531219482
Validation loss: 2.1680110096931458

Epoch: 5| Step: 2
Training loss: 1.2693315744400024
Validation loss: 2.1760019411643348

Epoch: 5| Step: 3
Training loss: 1.860704779624939
Validation loss: 2.1831011871496835

Epoch: 5| Step: 4
Training loss: 1.4629443883895874
Validation loss: 2.1738486289978027

Epoch: 5| Step: 5
Training loss: 2.5444440841674805
Validation loss: 2.211276412010193

Epoch: 5| Step: 6
Training loss: 1.7451140880584717
Validation loss: 2.1846953133742013

Epoch: 5| Step: 7
Training loss: 1.7778332233428955
Validation loss: 2.192166725794474

Epoch: 5| Step: 8
Training loss: 1.7072120904922485
Validation loss: 2.2311749259630838

Epoch: 5| Step: 9
Training loss: 1.5360349416732788
Validation loss: 2.2273204922676086

Epoch: 5| Step: 10
Training loss: 2.0622754096984863
Validation loss: 2.2040174901485443

Epoch: 5| Step: 11
Training loss: 2.680931568145752
Validation loss: 2.2288591464360556

Epoch: 249| Step: 0
Training loss: 1.8084630966186523
Validation loss: 2.2287466625372567

Epoch: 5| Step: 1
Training loss: 1.3223589658737183
Validation loss: 2.2200959771871567

Epoch: 5| Step: 2
Training loss: 1.8756145238876343
Validation loss: 2.2179667254288993

Epoch: 5| Step: 3
Training loss: 1.9103128910064697
Validation loss: 2.20380961894989

Epoch: 5| Step: 4
Training loss: 2.1599438190460205
Validation loss: 2.201651727159818

Epoch: 5| Step: 5
Training loss: 2.3057198524475098
Validation loss: 2.1839452385902405

Epoch: 5| Step: 6
Training loss: 1.24382483959198
Validation loss: 2.1758063534895578

Epoch: 5| Step: 7
Training loss: 1.6837739944458008
Validation loss: 2.1594234704971313

Epoch: 5| Step: 8
Training loss: 1.711108922958374
Validation loss: 2.151907126108805

Epoch: 5| Step: 9
Training loss: 1.781383752822876
Validation loss: 2.174710194269816

Epoch: 5| Step: 10
Training loss: 1.6363433599472046
Validation loss: 2.1655769298473992

Epoch: 5| Step: 11
Training loss: 1.4770011901855469
Validation loss: 2.1788697987794876

Epoch: 250| Step: 0
Training loss: 2.4233055114746094
Validation loss: 2.172555814186732

Epoch: 5| Step: 1
Training loss: 1.6802154779434204
Validation loss: 2.1795734614133835

Epoch: 5| Step: 2
Training loss: 1.485044240951538
Validation loss: 2.1878667573134103

Epoch: 5| Step: 3
Training loss: 1.5591624975204468
Validation loss: 2.1806445817152658

Epoch: 5| Step: 4
Training loss: 1.4960331916809082
Validation loss: 2.1733525097370148

Epoch: 5| Step: 5
Training loss: 1.4126203060150146
Validation loss: 2.192823757727941

Epoch: 5| Step: 6
Training loss: 1.8813492059707642
Validation loss: 2.196817467610041

Epoch: 5| Step: 7
Training loss: 2.031379461288452
Validation loss: 2.2126651952664056

Epoch: 5| Step: 8
Training loss: 2.5243546962738037
Validation loss: 2.2272568941116333

Epoch: 5| Step: 9
Training loss: 1.2541275024414062
Validation loss: 2.2154327034950256

Epoch: 5| Step: 10
Training loss: 1.5356347560882568
Validation loss: 2.1954424480597177

Epoch: 5| Step: 11
Training loss: 0.8390316367149353
Validation loss: 2.1942710926135383

Epoch: 251| Step: 0
Training loss: 1.9506323337554932
Validation loss: 2.184679994980494

Epoch: 5| Step: 1
Training loss: 2.4563231468200684
Validation loss: 2.1919272343317666

Epoch: 5| Step: 2
Training loss: 1.4763628244400024
Validation loss: 2.1676328778266907

Epoch: 5| Step: 3
Training loss: 1.9967501163482666
Validation loss: 2.1682941019535065

Epoch: 5| Step: 4
Training loss: 2.3045244216918945
Validation loss: 2.1743924568096795

Epoch: 5| Step: 5
Training loss: 1.986427664756775
Validation loss: 2.209090158343315

Epoch: 5| Step: 6
Training loss: 1.7710678577423096
Validation loss: 2.184034431974093

Epoch: 5| Step: 7
Training loss: 1.2423042058944702
Validation loss: 2.165668005744616

Epoch: 5| Step: 8
Training loss: 1.3093221187591553
Validation loss: 2.160406763354937

Epoch: 5| Step: 9
Training loss: 1.3265488147735596
Validation loss: 2.15542541941007

Epoch: 5| Step: 10
Training loss: 1.1000328063964844
Validation loss: 2.17250157892704

Epoch: 5| Step: 11
Training loss: 1.2350213527679443
Validation loss: 2.1975020666917167

Epoch: 252| Step: 0
Training loss: 1.8094165325164795
Validation loss: 2.1743632008632026

Epoch: 5| Step: 1
Training loss: 2.0085976123809814
Validation loss: 2.178087587157885

Epoch: 5| Step: 2
Training loss: 1.7772964239120483
Validation loss: 2.1972112506628036

Epoch: 5| Step: 3
Training loss: 1.348103642463684
Validation loss: 2.186796153585116

Epoch: 5| Step: 4
Training loss: 1.849708914756775
Validation loss: 2.177830328543981

Epoch: 5| Step: 5
Training loss: 1.520128846168518
Validation loss: 2.1868833899497986

Epoch: 5| Step: 6
Training loss: 1.664221167564392
Validation loss: 2.1732738663752875

Epoch: 5| Step: 7
Training loss: 1.6689426898956299
Validation loss: 2.1743732591470084

Epoch: 5| Step: 8
Training loss: 1.6336336135864258
Validation loss: 2.1844057540098825

Epoch: 5| Step: 9
Training loss: 1.7084674835205078
Validation loss: 2.1731380025545755

Epoch: 5| Step: 10
Training loss: 1.8831936120986938
Validation loss: 2.158959378798803

Epoch: 5| Step: 11
Training loss: 1.5144423246383667
Validation loss: 2.1699683467547097

Epoch: 253| Step: 0
Training loss: 1.7061389684677124
Validation loss: 2.1687363584836326

Epoch: 5| Step: 1
Training loss: 1.323105812072754
Validation loss: 2.160284772515297

Epoch: 5| Step: 2
Training loss: 1.590494155883789
Validation loss: 2.165831873814265

Epoch: 5| Step: 3
Training loss: 1.9920928478240967
Validation loss: 2.1236919462680817

Epoch: 5| Step: 4
Training loss: 2.0325512886047363
Validation loss: 2.127107928196589

Epoch: 5| Step: 5
Training loss: 1.1010264158248901
Validation loss: 2.1479067901770272

Epoch: 5| Step: 6
Training loss: 2.5751662254333496
Validation loss: 2.1491468797127404

Epoch: 5| Step: 7
Training loss: 1.9041850566864014
Validation loss: 2.135029415289561

Epoch: 5| Step: 8
Training loss: 1.8591550588607788
Validation loss: 2.150225520133972

Epoch: 5| Step: 9
Training loss: 2.0135271549224854
Validation loss: 2.1234013438224792

Epoch: 5| Step: 10
Training loss: 2.0293166637420654
Validation loss: 2.130285620689392

Epoch: 5| Step: 11
Training loss: 1.4283032417297363
Validation loss: 2.146671478947004

Epoch: 254| Step: 0
Training loss: 2.2318010330200195
Validation loss: 2.1377308666706085

Epoch: 5| Step: 1
Training loss: 1.8912395238876343
Validation loss: 2.133487050731977

Epoch: 5| Step: 2
Training loss: 1.2445780038833618
Validation loss: 2.148355613152186

Epoch: 5| Step: 3
Training loss: 2.36287260055542
Validation loss: 2.1408173640569053

Epoch: 5| Step: 4
Training loss: 1.5011690855026245
Validation loss: 2.1383430610100427

Epoch: 5| Step: 5
Training loss: 1.5682827234268188
Validation loss: 2.1609408209721246

Epoch: 5| Step: 6
Training loss: 1.3766710758209229
Validation loss: 2.1619301587343216

Epoch: 5| Step: 7
Training loss: 2.533158302307129
Validation loss: 2.1354363908370337

Epoch: 5| Step: 8
Training loss: 1.2850733995437622
Validation loss: 2.166642735401789

Epoch: 5| Step: 9
Training loss: 1.633347511291504
Validation loss: 2.142706592877706

Epoch: 5| Step: 10
Training loss: 1.632891297340393
Validation loss: 2.1483954588572183

Epoch: 5| Step: 11
Training loss: 1.608819842338562
Validation loss: 2.138342926899592

Epoch: 255| Step: 0
Training loss: 1.3966505527496338
Validation loss: 2.160609096288681

Epoch: 5| Step: 1
Training loss: 2.0801053047180176
Validation loss: 2.1596877425909042

Epoch: 5| Step: 2
Training loss: 1.8429396152496338
Validation loss: 2.1686317374308905

Epoch: 5| Step: 3
Training loss: 1.0768944025039673
Validation loss: 2.167257343729337

Epoch: 5| Step: 4
Training loss: 1.8944175243377686
Validation loss: 2.1818386813004813

Epoch: 5| Step: 5
Training loss: 1.5412989854812622
Validation loss: 2.1667459160089493

Epoch: 5| Step: 6
Training loss: 1.3883891105651855
Validation loss: 2.14689372976621

Epoch: 5| Step: 7
Training loss: 2.1189181804656982
Validation loss: 2.1625859141349792

Epoch: 5| Step: 8
Training loss: 1.9120784997940063
Validation loss: 2.180946499109268

Epoch: 5| Step: 9
Training loss: 1.653717041015625
Validation loss: 2.148846740523974

Epoch: 5| Step: 10
Training loss: 2.216655969619751
Validation loss: 2.165109242002169

Epoch: 5| Step: 11
Training loss: 0.9413120746612549
Validation loss: 2.156164199113846

Epoch: 256| Step: 0
Training loss: 1.734824776649475
Validation loss: 2.164445385336876

Epoch: 5| Step: 1
Training loss: 1.6684215068817139
Validation loss: 2.158368577559789

Epoch: 5| Step: 2
Training loss: 1.8626857995986938
Validation loss: 2.1771299044291177

Epoch: 5| Step: 3
Training loss: 1.7665069103240967
Validation loss: 2.1659272660811744

Epoch: 5| Step: 4
Training loss: 1.8919817209243774
Validation loss: 2.1680589268604913

Epoch: 5| Step: 5
Training loss: 1.8128540515899658
Validation loss: 2.1557134886582694

Epoch: 5| Step: 6
Training loss: 1.43905770778656
Validation loss: 2.177555486559868

Epoch: 5| Step: 7
Training loss: 1.8405015468597412
Validation loss: 2.1433948477109275

Epoch: 5| Step: 8
Training loss: 1.295649528503418
Validation loss: 2.151584987839063

Epoch: 5| Step: 9
Training loss: 1.371363878250122
Validation loss: 2.14892041683197

Epoch: 5| Step: 10
Training loss: 2.3150618076324463
Validation loss: 2.174882233142853

Epoch: 5| Step: 11
Training loss: 1.4697439670562744
Validation loss: 2.176590313514074

Epoch: 257| Step: 0
Training loss: 1.6741918325424194
Validation loss: 2.2008129308621087

Epoch: 5| Step: 1
Training loss: 2.0697579383850098
Validation loss: 2.20174403488636

Epoch: 5| Step: 2
Training loss: 1.7077572345733643
Validation loss: 2.204962879419327

Epoch: 5| Step: 3
Training loss: 1.4402003288269043
Validation loss: 2.2055537899335227

Epoch: 5| Step: 4
Training loss: 1.4565179347991943
Validation loss: 2.1764828662077584

Epoch: 5| Step: 5
Training loss: 1.4983457326889038
Validation loss: 2.1467936436335244

Epoch: 5| Step: 6
Training loss: 2.2496144771575928
Validation loss: 2.171081632375717

Epoch: 5| Step: 7
Training loss: 1.5906660556793213
Validation loss: 2.1579099545876184

Epoch: 5| Step: 8
Training loss: 2.1818747520446777
Validation loss: 2.1622704615195594

Epoch: 5| Step: 9
Training loss: 1.1567556858062744
Validation loss: 2.16620867451032

Epoch: 5| Step: 10
Training loss: 2.289961338043213
Validation loss: 2.1658154129981995

Epoch: 5| Step: 11
Training loss: 1.168926477432251
Validation loss: 2.1496741274992623

Epoch: 258| Step: 0
Training loss: 1.118288278579712
Validation loss: 2.164451996485392

Epoch: 5| Step: 1
Training loss: 2.178288221359253
Validation loss: 2.1708515137434006

Epoch: 5| Step: 2
Training loss: 2.139599323272705
Validation loss: 2.186180849870046

Epoch: 5| Step: 3
Training loss: 1.45989191532135
Validation loss: 2.1907022098700204

Epoch: 5| Step: 4
Training loss: 1.3854687213897705
Validation loss: 2.194100817044576

Epoch: 5| Step: 5
Training loss: 1.5117411613464355
Validation loss: 2.1884930382172265

Epoch: 5| Step: 6
Training loss: 2.031843423843384
Validation loss: 2.1983112593491874

Epoch: 5| Step: 7
Training loss: 1.752471923828125
Validation loss: 2.1791811188062034

Epoch: 5| Step: 8
Training loss: 2.052309989929199
Validation loss: 2.1712283988793692

Epoch: 5| Step: 9
Training loss: 1.6905845403671265
Validation loss: 2.2040782819191613

Epoch: 5| Step: 10
Training loss: 1.8096641302108765
Validation loss: 2.193040912350019

Epoch: 5| Step: 11
Training loss: 1.0333632230758667
Validation loss: 2.1840432435274124

Epoch: 259| Step: 0
Training loss: 1.6891906261444092
Validation loss: 2.179679582516352

Epoch: 5| Step: 1
Training loss: 1.679043173789978
Validation loss: 2.1489771207173667

Epoch: 5| Step: 2
Training loss: 1.4295231103897095
Validation loss: 2.154120087623596

Epoch: 5| Step: 3
Training loss: 1.5499056577682495
Validation loss: 2.1722731242577233

Epoch: 5| Step: 4
Training loss: 1.7011951208114624
Validation loss: 2.1975888311862946

Epoch: 5| Step: 5
Training loss: 2.762026309967041
Validation loss: 2.2364321053028107

Epoch: 5| Step: 6
Training loss: 2.3027865886688232
Validation loss: 2.240379422903061

Epoch: 5| Step: 7
Training loss: 2.0501203536987305
Validation loss: 2.251049200693766

Epoch: 5| Step: 8
Training loss: 1.2574784755706787
Validation loss: 2.2359211444854736

Epoch: 5| Step: 9
Training loss: 1.7903693914413452
Validation loss: 2.239617874224981

Epoch: 5| Step: 10
Training loss: 1.3802891969680786
Validation loss: 2.2503412663936615

Epoch: 5| Step: 11
Training loss: 1.4693362712860107
Validation loss: 2.2266539533933005

Epoch: 260| Step: 0
Training loss: 1.6667200326919556
Validation loss: 2.2077940503756204

Epoch: 5| Step: 1
Training loss: 1.509913682937622
Validation loss: 2.1827622254689536

Epoch: 5| Step: 2
Training loss: 1.6812000274658203
Validation loss: 2.1666834950447083

Epoch: 5| Step: 3
Training loss: 1.0245726108551025
Validation loss: 2.1517898639043174

Epoch: 5| Step: 4
Training loss: 1.5726553201675415
Validation loss: 2.134654700756073

Epoch: 5| Step: 5
Training loss: 1.9733011722564697
Validation loss: 2.1383185436328254

Epoch: 5| Step: 6
Training loss: 1.819584608078003
Validation loss: 2.141280030210813

Epoch: 5| Step: 7
Training loss: 1.897174596786499
Validation loss: 2.132837325334549

Epoch: 5| Step: 8
Training loss: 2.2112205028533936
Validation loss: 2.1423054138819375

Epoch: 5| Step: 9
Training loss: 1.891885757446289
Validation loss: 2.1861928900082908

Epoch: 5| Step: 10
Training loss: 1.4447641372680664
Validation loss: 2.179317851861318

Epoch: 5| Step: 11
Training loss: 2.975761890411377
Validation loss: 2.200445741415024

Epoch: 261| Step: 0
Training loss: 1.5598218441009521
Validation loss: 2.1687012712160745

Epoch: 5| Step: 1
Training loss: 1.5402950048446655
Validation loss: 2.171068628629049

Epoch: 5| Step: 2
Training loss: 2.021763324737549
Validation loss: 2.1753268341223397

Epoch: 5| Step: 3
Training loss: 2.051395893096924
Validation loss: 2.167459631959597

Epoch: 5| Step: 4
Training loss: 1.837568998336792
Validation loss: 2.1916851798693338

Epoch: 5| Step: 5
Training loss: 1.4621150493621826
Validation loss: 2.1855225463708243

Epoch: 5| Step: 6
Training loss: 1.511393427848816
Validation loss: 2.1764815350373587

Epoch: 5| Step: 7
Training loss: 1.8268064260482788
Validation loss: 2.191842476526896

Epoch: 5| Step: 8
Training loss: 1.5343841314315796
Validation loss: 2.1743122388919196

Epoch: 5| Step: 9
Training loss: 1.8654121160507202
Validation loss: 2.190831849972407

Epoch: 5| Step: 10
Training loss: 1.6332203149795532
Validation loss: 2.181311031182607

Epoch: 5| Step: 11
Training loss: 1.9343650341033936
Validation loss: 2.200568517049154

Epoch: 262| Step: 0
Training loss: 1.4978598356246948
Validation loss: 2.1910729706287384

Epoch: 5| Step: 1
Training loss: 0.9036760330200195
Validation loss: 2.209539214769999

Epoch: 5| Step: 2
Training loss: 1.2203086614608765
Validation loss: 2.195728436112404

Epoch: 5| Step: 3
Training loss: 1.5821731090545654
Validation loss: 2.184051180879275

Epoch: 5| Step: 4
Training loss: 1.7883697748184204
Validation loss: 2.170698970556259

Epoch: 5| Step: 5
Training loss: 1.9625600576400757
Validation loss: 2.190661311149597

Epoch: 5| Step: 6
Training loss: 1.5727269649505615
Validation loss: 2.1907089054584503

Epoch: 5| Step: 7
Training loss: 2.471595525741577
Validation loss: 2.1588958501815796

Epoch: 5| Step: 8
Training loss: 2.216752529144287
Validation loss: 2.1639687518278756

Epoch: 5| Step: 9
Training loss: 1.7720868587493896
Validation loss: 2.1611037254333496

Epoch: 5| Step: 10
Training loss: 1.461665391921997
Validation loss: 2.1373157054185867

Epoch: 5| Step: 11
Training loss: 1.8959778547286987
Validation loss: 2.157596548398336

Epoch: 263| Step: 0
Training loss: 1.3978967666625977
Validation loss: 2.162836804986

Epoch: 5| Step: 1
Training loss: 1.991790771484375
Validation loss: 2.1598391930262246

Epoch: 5| Step: 2
Training loss: 2.242840528488159
Validation loss: 2.1892474244038262

Epoch: 5| Step: 3
Training loss: 1.5007781982421875
Validation loss: 2.1832648466030755

Epoch: 5| Step: 4
Training loss: 1.55599045753479
Validation loss: 2.175319939851761

Epoch: 5| Step: 5
Training loss: 1.36624276638031
Validation loss: 2.1878983030716577

Epoch: 5| Step: 6
Training loss: 1.3562371730804443
Validation loss: 2.194293583432833

Epoch: 5| Step: 7
Training loss: 1.71134352684021
Validation loss: 2.19192166129748

Epoch: 5| Step: 8
Training loss: 2.218475818634033
Validation loss: 2.1878576229015985

Epoch: 5| Step: 9
Training loss: 1.4154844284057617
Validation loss: 2.183258533477783

Epoch: 5| Step: 10
Training loss: 1.8886381387710571
Validation loss: 2.183691839377085

Epoch: 5| Step: 11
Training loss: 1.1409605741500854
Validation loss: 2.2038817405700684

Epoch: 264| Step: 0
Training loss: 1.023874044418335
Validation loss: 2.162591204047203

Epoch: 5| Step: 1
Training loss: 1.6114543676376343
Validation loss: 2.178572873274485

Epoch: 5| Step: 2
Training loss: 1.7959508895874023
Validation loss: 2.1773625065883

Epoch: 5| Step: 3
Training loss: 1.9415909051895142
Validation loss: 2.159456009666125

Epoch: 5| Step: 4
Training loss: 2.3177733421325684
Validation loss: 2.1835246086120605

Epoch: 5| Step: 5
Training loss: 1.907915472984314
Validation loss: 2.1791704495747886

Epoch: 5| Step: 6
Training loss: 1.3764142990112305
Validation loss: 2.167868345975876

Epoch: 5| Step: 7
Training loss: 1.6160398721694946
Validation loss: 2.155343845486641

Epoch: 5| Step: 8
Training loss: 2.006636142730713
Validation loss: 2.166226034363111

Epoch: 5| Step: 9
Training loss: 1.2613046169281006
Validation loss: 2.1860161225001016

Epoch: 5| Step: 10
Training loss: 1.7320533990859985
Validation loss: 2.1844134827454886

Epoch: 5| Step: 11
Training loss: 1.8218774795532227
Validation loss: 2.197316219409307

Epoch: 265| Step: 0
Training loss: 1.5904271602630615
Validation loss: 2.1865917444229126

Epoch: 5| Step: 1
Training loss: 1.318142294883728
Validation loss: 2.217559660474459

Epoch: 5| Step: 2
Training loss: 1.1309621334075928
Validation loss: 2.2262576123078666

Epoch: 5| Step: 3
Training loss: 1.8841739892959595
Validation loss: 2.2248734533786774

Epoch: 5| Step: 4
Training loss: 1.278247594833374
Validation loss: 2.198763430118561

Epoch: 5| Step: 5
Training loss: 2.1527581214904785
Validation loss: 2.2240863045056662

Epoch: 5| Step: 6
Training loss: 1.6341311931610107
Validation loss: 2.2094168762365975

Epoch: 5| Step: 7
Training loss: 2.222989559173584
Validation loss: 2.196046585838

Epoch: 5| Step: 8
Training loss: 1.7056586742401123
Validation loss: 2.1908122450113297

Epoch: 5| Step: 9
Training loss: 1.789471983909607
Validation loss: 2.204043706258138

Epoch: 5| Step: 10
Training loss: 1.8221523761749268
Validation loss: 2.147045537829399

Epoch: 5| Step: 11
Training loss: 0.4843064546585083
Validation loss: 2.164190466205279

Epoch: 266| Step: 0
Training loss: 2.5115206241607666
Validation loss: 2.169306442141533

Epoch: 5| Step: 1
Training loss: 1.7499462366104126
Validation loss: 2.173379754026731

Epoch: 5| Step: 2
Training loss: 1.433547019958496
Validation loss: 2.1942407687505088

Epoch: 5| Step: 3
Training loss: 1.3663833141326904
Validation loss: 2.1952503422896066

Epoch: 5| Step: 4
Training loss: 1.4723727703094482
Validation loss: 2.219682385524114

Epoch: 5| Step: 5
Training loss: 1.7289807796478271
Validation loss: 2.2317899962266288

Epoch: 5| Step: 6
Training loss: 2.292119264602661
Validation loss: 2.2297402123610177

Epoch: 5| Step: 7
Training loss: 1.7820351123809814
Validation loss: 2.2209100425243378

Epoch: 5| Step: 8
Training loss: 1.6092150211334229
Validation loss: 2.228096902370453

Epoch: 5| Step: 9
Training loss: 1.6133171319961548
Validation loss: 2.2050897032022476

Epoch: 5| Step: 10
Training loss: 1.3409042358398438
Validation loss: 2.1605193465948105

Epoch: 5| Step: 11
Training loss: 1.7018061876296997
Validation loss: 2.1437017718950906

Epoch: 267| Step: 0
Training loss: 1.4568469524383545
Validation loss: 2.181476722160975

Epoch: 5| Step: 1
Training loss: 1.8010261058807373
Validation loss: 2.1975085139274597

Epoch: 5| Step: 2
Training loss: 1.4410438537597656
Validation loss: 2.2157228787740073

Epoch: 5| Step: 3
Training loss: 1.183203935623169
Validation loss: 2.2048691511154175

Epoch: 5| Step: 4
Training loss: 2.0235559940338135
Validation loss: 2.2176600793997445

Epoch: 5| Step: 5
Training loss: 2.0687108039855957
Validation loss: 2.2167797784010568

Epoch: 5| Step: 6
Training loss: 1.7486774921417236
Validation loss: 2.216393321752548

Epoch: 5| Step: 7
Training loss: 2.194626808166504
Validation loss: 2.2455713351567588

Epoch: 5| Step: 8
Training loss: 1.523162841796875
Validation loss: 2.2339216570059457

Epoch: 5| Step: 9
Training loss: 1.9731454849243164
Validation loss: 2.202324002981186

Epoch: 5| Step: 10
Training loss: 1.3694921731948853
Validation loss: 2.1990216920773187

Epoch: 5| Step: 11
Training loss: 1.0590777397155762
Validation loss: 2.2169605791568756

Epoch: 268| Step: 0
Training loss: 1.4249422550201416
Validation loss: 2.172326440612475

Epoch: 5| Step: 1
Training loss: 1.19479238986969
Validation loss: 2.2029362519582114

Epoch: 5| Step: 2
Training loss: 1.521498441696167
Validation loss: 2.1889116714398065

Epoch: 5| Step: 3
Training loss: 1.6728366613388062
Validation loss: 2.2002116590738297

Epoch: 5| Step: 4
Training loss: 1.4470975399017334
Validation loss: 2.20136566956838

Epoch: 5| Step: 5
Training loss: 1.3383535146713257
Validation loss: 2.2147051841020584

Epoch: 5| Step: 6
Training loss: 1.8801368474960327
Validation loss: 2.211267277598381

Epoch: 5| Step: 7
Training loss: 2.3652026653289795
Validation loss: 2.1972568283478418

Epoch: 5| Step: 8
Training loss: 1.983218789100647
Validation loss: 2.1913602550824485

Epoch: 5| Step: 9
Training loss: 1.4946327209472656
Validation loss: 2.183295061190923

Epoch: 5| Step: 10
Training loss: 2.00606107711792
Validation loss: 2.169197216629982

Epoch: 5| Step: 11
Training loss: 2.3088231086730957
Validation loss: 2.1997981468836465

Epoch: 269| Step: 0
Training loss: 1.4789369106292725
Validation loss: 2.2020898163318634

Epoch: 5| Step: 1
Training loss: 1.8612276315689087
Validation loss: 2.19465970993042

Epoch: 5| Step: 2
Training loss: 1.9208958148956299
Validation loss: 2.1676975091298423

Epoch: 5| Step: 3
Training loss: 1.5950413942337036
Validation loss: 2.191136196255684

Epoch: 5| Step: 4
Training loss: 1.450537919998169
Validation loss: 2.1971626728773117

Epoch: 5| Step: 5
Training loss: 2.0426878929138184
Validation loss: 2.182057331005732

Epoch: 5| Step: 6
Training loss: 1.9051463603973389
Validation loss: 2.2104019622008004

Epoch: 5| Step: 7
Training loss: 1.4660041332244873
Validation loss: 2.2106280823548636

Epoch: 5| Step: 8
Training loss: 1.1647236347198486
Validation loss: 2.190765435496966

Epoch: 5| Step: 9
Training loss: 1.8377870321273804
Validation loss: 2.2146849234898887

Epoch: 5| Step: 10
Training loss: 1.39084792137146
Validation loss: 2.198111484448115

Epoch: 5| Step: 11
Training loss: 1.6616535186767578
Validation loss: 2.2231141130129495

Epoch: 270| Step: 0
Training loss: 1.7044134140014648
Validation loss: 2.2245908776919046

Epoch: 5| Step: 1
Training loss: 1.2340368032455444
Validation loss: 2.207568188508352

Epoch: 5| Step: 2
Training loss: 1.1982966661453247
Validation loss: 2.170299227039019

Epoch: 5| Step: 3
Training loss: 1.9862362146377563
Validation loss: 2.169639656941096

Epoch: 5| Step: 4
Training loss: 1.4367048740386963
Validation loss: 2.1749982833862305

Epoch: 5| Step: 5
Training loss: 1.7073646783828735
Validation loss: 2.1771601885557175

Epoch: 5| Step: 6
Training loss: 1.2423092126846313
Validation loss: 2.162957042455673

Epoch: 5| Step: 7
Training loss: 1.8392174243927002
Validation loss: 2.1600439896186194

Epoch: 5| Step: 8
Training loss: 1.9644386768341064
Validation loss: 2.178320065140724

Epoch: 5| Step: 9
Training loss: 2.2484865188598633
Validation loss: 2.1603738268216452

Epoch: 5| Step: 10
Training loss: 2.071270704269409
Validation loss: 2.171052952607473

Epoch: 5| Step: 11
Training loss: 1.2891947031021118
Validation loss: 2.1676554133494697

Epoch: 271| Step: 0
Training loss: 1.6456973552703857
Validation loss: 2.1580246537923813

Epoch: 5| Step: 1
Training loss: 1.6350456476211548
Validation loss: 2.1866696079572043

Epoch: 5| Step: 2
Training loss: 2.0606372356414795
Validation loss: 2.1681544880072274

Epoch: 5| Step: 3
Training loss: 1.2393935918807983
Validation loss: 2.1759767482678094

Epoch: 5| Step: 4
Training loss: 1.3143532276153564
Validation loss: 2.1656682242949805

Epoch: 5| Step: 5
Training loss: 1.8879356384277344
Validation loss: 2.1614972750345864

Epoch: 5| Step: 6
Training loss: 1.932661771774292
Validation loss: 2.169137626886368

Epoch: 5| Step: 7
Training loss: 1.3340728282928467
Validation loss: 2.154603516062101

Epoch: 5| Step: 8
Training loss: 2.0034239292144775
Validation loss: 2.1568025896946588

Epoch: 5| Step: 9
Training loss: 2.0235540866851807
Validation loss: 2.1776186178127923

Epoch: 5| Step: 10
Training loss: 1.532099962234497
Validation loss: 2.1744858721892038

Epoch: 5| Step: 11
Training loss: 2.2124907970428467
Validation loss: 2.169376234213511

Epoch: 272| Step: 0
Training loss: 1.85834538936615
Validation loss: 2.1398593336343765

Epoch: 5| Step: 1
Training loss: 1.8006798028945923
Validation loss: 2.1738714377085366

Epoch: 5| Step: 2
Training loss: 1.3515217304229736
Validation loss: 2.17275300125281

Epoch: 5| Step: 3
Training loss: 1.8057420253753662
Validation loss: 2.1658995350201926

Epoch: 5| Step: 4
Training loss: 2.0003466606140137
Validation loss: 2.1791087985038757

Epoch: 5| Step: 5
Training loss: 1.4583237171173096
Validation loss: 2.181408022840818

Epoch: 5| Step: 6
Training loss: 1.62400221824646
Validation loss: 2.151732931534449

Epoch: 5| Step: 7
Training loss: 1.4133541584014893
Validation loss: 2.1575760493675866

Epoch: 5| Step: 8
Training loss: 1.4334635734558105
Validation loss: 2.129937236507734

Epoch: 5| Step: 9
Training loss: 1.7403242588043213
Validation loss: 2.1927758852640786

Epoch: 5| Step: 10
Training loss: 1.81412672996521
Validation loss: 2.181320602695147

Epoch: 5| Step: 11
Training loss: 1.3314688205718994
Validation loss: 2.2030343065659204

Epoch: 273| Step: 0
Training loss: 2.0730834007263184
Validation loss: 2.160269637902578

Epoch: 5| Step: 1
Training loss: 1.8655118942260742
Validation loss: 2.1573897699515023

Epoch: 5| Step: 2
Training loss: 2.1157662868499756
Validation loss: 2.217475006977717

Epoch: 5| Step: 3
Training loss: 2.3035881519317627
Validation loss: 2.2365686198075614

Epoch: 5| Step: 4
Training loss: 1.9447282552719116
Validation loss: 2.2185111840566

Epoch: 5| Step: 5
Training loss: 1.6466811895370483
Validation loss: 2.1957104404767356

Epoch: 5| Step: 6
Training loss: 1.7323768138885498
Validation loss: 2.1439825892448425

Epoch: 5| Step: 7
Training loss: 1.4750216007232666
Validation loss: 2.127531404296557

Epoch: 5| Step: 8
Training loss: 2.0673420429229736
Validation loss: 2.1038742313782373

Epoch: 5| Step: 9
Training loss: 1.9609695672988892
Validation loss: 2.126129671931267

Epoch: 5| Step: 10
Training loss: 1.3405582904815674
Validation loss: 2.134951094786326

Epoch: 5| Step: 11
Training loss: 2.471895694732666
Validation loss: 2.142600322763125

Epoch: 274| Step: 0
Training loss: 2.016146421432495
Validation loss: 2.1600227306286492

Epoch: 5| Step: 1
Training loss: 1.7677333354949951
Validation loss: 2.1841099907954535

Epoch: 5| Step: 2
Training loss: 2.578779935836792
Validation loss: 2.1729323714971542

Epoch: 5| Step: 3
Training loss: 2.1097464561462402
Validation loss: 2.174246236681938

Epoch: 5| Step: 4
Training loss: 1.4219549894332886
Validation loss: 2.1752718736728034

Epoch: 5| Step: 5
Training loss: 2.407449722290039
Validation loss: 2.1382278203964233

Epoch: 5| Step: 6
Training loss: 1.8140833377838135
Validation loss: 2.1480339666207633

Epoch: 5| Step: 7
Training loss: 1.5299068689346313
Validation loss: 2.122796207666397

Epoch: 5| Step: 8
Training loss: 1.4546765089035034
Validation loss: 2.1305411010980606

Epoch: 5| Step: 9
Training loss: 1.519070029258728
Validation loss: 2.135768080751101

Epoch: 5| Step: 10
Training loss: 1.8026784658432007
Validation loss: 2.1208661744991937

Epoch: 5| Step: 11
Training loss: 0.41000381112098694
Validation loss: 2.129164218902588

Epoch: 275| Step: 0
Training loss: 1.4837672710418701
Validation loss: 2.119077409307162

Epoch: 5| Step: 1
Training loss: 1.202170491218567
Validation loss: 2.1008631885051727

Epoch: 5| Step: 2
Training loss: 1.8507236242294312
Validation loss: 2.1364484330018363

Epoch: 5| Step: 3
Training loss: 1.4054583311080933
Validation loss: 2.1096629003683725

Epoch: 5| Step: 4
Training loss: 1.918047547340393
Validation loss: 2.144565542538961

Epoch: 5| Step: 5
Training loss: 2.0725150108337402
Validation loss: 2.14693974951903

Epoch: 5| Step: 6
Training loss: 1.6110576391220093
Validation loss: 2.1409385999043784

Epoch: 5| Step: 7
Training loss: 2.1882121562957764
Validation loss: 2.1482299268245697

Epoch: 5| Step: 8
Training loss: 1.9047702550888062
Validation loss: 2.150526151061058

Epoch: 5| Step: 9
Training loss: 1.868342399597168
Validation loss: 2.143668840328852

Epoch: 5| Step: 10
Training loss: 1.5827213525772095
Validation loss: 2.169683277606964

Epoch: 5| Step: 11
Training loss: 1.626222848892212
Validation loss: 2.162373731533686

Epoch: 276| Step: 0
Training loss: 1.5633530616760254
Validation loss: 2.1659312546253204

Epoch: 5| Step: 1
Training loss: 2.389429807662964
Validation loss: 2.151536156733831

Epoch: 5| Step: 2
Training loss: 1.676783561706543
Validation loss: 2.1506367971499762

Epoch: 5| Step: 3
Training loss: 2.1787054538726807
Validation loss: 2.142473489046097

Epoch: 5| Step: 4
Training loss: 1.2415874004364014
Validation loss: 2.13443731268247

Epoch: 5| Step: 5
Training loss: 1.981602668762207
Validation loss: 2.1363376726706824

Epoch: 5| Step: 6
Training loss: 1.6690118312835693
Validation loss: 2.150480568408966

Epoch: 5| Step: 7
Training loss: 1.460228443145752
Validation loss: 2.181001752614975

Epoch: 5| Step: 8
Training loss: 1.727081298828125
Validation loss: 2.180005053679148

Epoch: 5| Step: 9
Training loss: 1.152642011642456
Validation loss: 2.194735109806061

Epoch: 5| Step: 10
Training loss: 1.8589140176773071
Validation loss: 2.206227312485377

Epoch: 5| Step: 11
Training loss: 1.5226624011993408
Validation loss: 2.207749808828036

Epoch: 277| Step: 0
Training loss: 1.7360889911651611
Validation loss: 2.1972729663054147

Epoch: 5| Step: 1
Training loss: 1.6259294748306274
Validation loss: 2.1906541039546332

Epoch: 5| Step: 2
Training loss: 1.5827207565307617
Validation loss: 2.1699892381827035

Epoch: 5| Step: 3
Training loss: 1.329164743423462
Validation loss: 2.1988168358802795

Epoch: 5| Step: 4
Training loss: 1.1364319324493408
Validation loss: 2.181570738554001

Epoch: 5| Step: 5
Training loss: 2.219493865966797
Validation loss: 2.218160251776377

Epoch: 5| Step: 6
Training loss: 1.760406255722046
Validation loss: 2.2028854191303253

Epoch: 5| Step: 7
Training loss: 1.6580091714859009
Validation loss: 2.2140614291032157

Epoch: 5| Step: 8
Training loss: 1.6482210159301758
Validation loss: 2.2061761915683746

Epoch: 5| Step: 9
Training loss: 1.5403612852096558
Validation loss: 2.217758138974508

Epoch: 5| Step: 10
Training loss: 2.3352742195129395
Validation loss: 2.2033143242200217

Epoch: 5| Step: 11
Training loss: 1.6072065830230713
Validation loss: 2.2129133294026055

Epoch: 278| Step: 0
Training loss: 2.0534064769744873
Validation loss: 2.202171524365743

Epoch: 5| Step: 1
Training loss: 1.588041067123413
Validation loss: 2.190679465730985

Epoch: 5| Step: 2
Training loss: 1.3876655101776123
Validation loss: 2.1755424489577613

Epoch: 5| Step: 3
Training loss: 1.4109699726104736
Validation loss: 2.1985567857821784

Epoch: 5| Step: 4
Training loss: 1.5168476104736328
Validation loss: 2.179665873448054

Epoch: 5| Step: 5
Training loss: 2.517561435699463
Validation loss: 2.21523018181324

Epoch: 5| Step: 6
Training loss: 1.575321912765503
Validation loss: 2.2002762655417123

Epoch: 5| Step: 7
Training loss: 1.5341811180114746
Validation loss: 2.1886230458815894

Epoch: 5| Step: 8
Training loss: 1.216040849685669
Validation loss: 2.212964082757632

Epoch: 5| Step: 9
Training loss: 2.0870184898376465
Validation loss: 2.2088977793852487

Epoch: 5| Step: 10
Training loss: 1.8567943572998047
Validation loss: 2.2052941670020423

Epoch: 5| Step: 11
Training loss: 1.0582275390625
Validation loss: 2.2047215600808463

Epoch: 279| Step: 0
Training loss: 1.6809402704238892
Validation loss: 2.1918575167655945

Epoch: 5| Step: 1
Training loss: 1.1586008071899414
Validation loss: 2.2003258069356284

Epoch: 5| Step: 2
Training loss: 1.7781347036361694
Validation loss: 2.196032469471296

Epoch: 5| Step: 3
Training loss: 1.2324330806732178
Validation loss: 2.1713691850503287

Epoch: 5| Step: 4
Training loss: 1.9059398174285889
Validation loss: 2.1825565695762634

Epoch: 5| Step: 5
Training loss: 1.499314546585083
Validation loss: 2.2071473697821298

Epoch: 5| Step: 6
Training loss: 1.1975276470184326
Validation loss: 2.2070873975753784

Epoch: 5| Step: 7
Training loss: 1.4383705854415894
Validation loss: 2.240487113595009

Epoch: 5| Step: 8
Training loss: 1.80377197265625
Validation loss: 2.208202133576075

Epoch: 5| Step: 9
Training loss: 1.699313759803772
Validation loss: 2.213052605589231

Epoch: 5| Step: 10
Training loss: 2.3693952560424805
Validation loss: 2.224352796872457

Epoch: 5| Step: 11
Training loss: 1.8598508834838867
Validation loss: 2.207078536351522

Epoch: 280| Step: 0
Training loss: 1.8134769201278687
Validation loss: 2.2249514212210975

Epoch: 5| Step: 1
Training loss: 1.0944430828094482
Validation loss: 2.212042421102524

Epoch: 5| Step: 2
Training loss: 1.955767273902893
Validation loss: 2.2046220352252326

Epoch: 5| Step: 3
Training loss: 1.7896673679351807
Validation loss: 2.2171095609664917

Epoch: 5| Step: 4
Training loss: 1.5477858781814575
Validation loss: 2.2319711595773697

Epoch: 5| Step: 5
Training loss: 1.4654321670532227
Validation loss: 2.2119803925355277

Epoch: 5| Step: 6
Training loss: 1.427514672279358
Validation loss: 2.227506379286448

Epoch: 5| Step: 7
Training loss: 2.242428779602051
Validation loss: 2.232720901568731

Epoch: 5| Step: 8
Training loss: 1.7977893352508545
Validation loss: 2.2222246726353965

Epoch: 5| Step: 9
Training loss: 1.5501185655593872
Validation loss: 2.197095200419426

Epoch: 5| Step: 10
Training loss: 1.0695797204971313
Validation loss: 2.1994400719801583

Epoch: 5| Step: 11
Training loss: 1.7868375778198242
Validation loss: 2.202696164449056

Epoch: 281| Step: 0
Training loss: 1.771284818649292
Validation loss: 2.198916867375374

Epoch: 5| Step: 1
Training loss: 1.8004398345947266
Validation loss: 2.2206863860289254

Epoch: 5| Step: 2
Training loss: 1.7948055267333984
Validation loss: 2.230641628305117

Epoch: 5| Step: 3
Training loss: 1.6914207935333252
Validation loss: 2.214501738548279

Epoch: 5| Step: 4
Training loss: 1.5512865781784058
Validation loss: 2.246277759472529

Epoch: 5| Step: 5
Training loss: 1.6004011631011963
Validation loss: 2.230913738409678

Epoch: 5| Step: 6
Training loss: 1.3313853740692139
Validation loss: 2.217009191711744

Epoch: 5| Step: 7
Training loss: 1.7960155010223389
Validation loss: 2.2299741754929223

Epoch: 5| Step: 8
Training loss: 1.5053575038909912
Validation loss: 2.229946807026863

Epoch: 5| Step: 9
Training loss: 1.5544666051864624
Validation loss: 2.2261626919110618

Epoch: 5| Step: 10
Training loss: 1.3000568151474
Validation loss: 2.2321522335211434

Epoch: 5| Step: 11
Training loss: 2.2802934646606445
Validation loss: 2.2230648398399353

Epoch: 282| Step: 0
Training loss: 2.0308823585510254
Validation loss: 2.2120388646920524

Epoch: 5| Step: 1
Training loss: 1.3558655977249146
Validation loss: 2.256151701013247

Epoch: 5| Step: 2
Training loss: 2.145953416824341
Validation loss: 2.277928734819094

Epoch: 5| Step: 3
Training loss: 1.291720986366272
Validation loss: 2.26613387465477

Epoch: 5| Step: 4
Training loss: 1.1881370544433594
Validation loss: 2.2513164033492408

Epoch: 5| Step: 5
Training loss: 1.9275871515274048
Validation loss: 2.2435758461554847

Epoch: 5| Step: 6
Training loss: 1.6643149852752686
Validation loss: 2.2449918389320374

Epoch: 5| Step: 7
Training loss: 1.6715023517608643
Validation loss: 2.2079951067765555

Epoch: 5| Step: 8
Training loss: 1.5429432392120361
Validation loss: 2.2318211247523627

Epoch: 5| Step: 9
Training loss: 1.7434771060943604
Validation loss: 2.2158687512079873

Epoch: 5| Step: 10
Training loss: 1.4804856777191162
Validation loss: 2.199637765685717

Epoch: 5| Step: 11
Training loss: 1.1067315340042114
Validation loss: 2.191009074449539

Epoch: 283| Step: 0
Training loss: 1.8683109283447266
Validation loss: 2.179607391357422

Epoch: 5| Step: 1
Training loss: 1.2005763053894043
Validation loss: 2.1703330179055533

Epoch: 5| Step: 2
Training loss: 1.5835015773773193
Validation loss: 2.1725087761878967

Epoch: 5| Step: 3
Training loss: 1.7816413640975952
Validation loss: 2.1871665020783744

Epoch: 5| Step: 4
Training loss: 0.934069037437439
Validation loss: 2.192700356245041

Epoch: 5| Step: 5
Training loss: 1.910569429397583
Validation loss: 2.2097987631956735

Epoch: 5| Step: 6
Training loss: 1.5170310735702515
Validation loss: 2.195062388976415

Epoch: 5| Step: 7
Training loss: 1.769247055053711
Validation loss: 2.206112489104271

Epoch: 5| Step: 8
Training loss: 1.9540525674819946
Validation loss: 2.2043197751045227

Epoch: 5| Step: 9
Training loss: 1.169621229171753
Validation loss: 2.2467622508605323

Epoch: 5| Step: 10
Training loss: 1.952771782875061
Validation loss: 2.2339567889769874

Epoch: 5| Step: 11
Training loss: 1.8141889572143555
Validation loss: 2.2417006691296897

Epoch: 284| Step: 0
Training loss: 1.6672189235687256
Validation loss: 2.264343172311783

Epoch: 5| Step: 1
Training loss: 1.7020981311798096
Validation loss: 2.2280770937601724

Epoch: 5| Step: 2
Training loss: 1.4822494983673096
Validation loss: 2.246154859662056

Epoch: 5| Step: 3
Training loss: 1.5364296436309814
Validation loss: 2.235972285270691

Epoch: 5| Step: 4
Training loss: 1.5623104572296143
Validation loss: 2.232175901532173

Epoch: 5| Step: 5
Training loss: 1.598885416984558
Validation loss: 2.2263103822867074

Epoch: 5| Step: 6
Training loss: 1.4863440990447998
Validation loss: 2.2060302048921585

Epoch: 5| Step: 7
Training loss: 1.2909770011901855
Validation loss: 2.222914139429728

Epoch: 5| Step: 8
Training loss: 1.9315515756607056
Validation loss: 2.191469301780065

Epoch: 5| Step: 9
Training loss: 2.0530219078063965
Validation loss: 2.1806300381819406

Epoch: 5| Step: 10
Training loss: 1.6058835983276367
Validation loss: 2.188921054204305

Epoch: 5| Step: 11
Training loss: 1.684420108795166
Validation loss: 2.217634732524554

Epoch: 285| Step: 0
Training loss: 1.4161040782928467
Validation loss: 2.2208431164423623

Epoch: 5| Step: 1
Training loss: 1.6885387897491455
Validation loss: 2.2228803435961404

Epoch: 5| Step: 2
Training loss: 1.4387924671173096
Validation loss: 2.2182064205408096

Epoch: 5| Step: 3
Training loss: 1.700624704360962
Validation loss: 2.2116150508324304

Epoch: 5| Step: 4
Training loss: 2.037588357925415
Validation loss: 2.2083599319060645

Epoch: 5| Step: 5
Training loss: 1.7367303371429443
Validation loss: 2.1745643814404807

Epoch: 5| Step: 6
Training loss: 1.5790767669677734
Validation loss: 2.209007292985916

Epoch: 5| Step: 7
Training loss: 1.6048122644424438
Validation loss: 2.1949179420868554

Epoch: 5| Step: 8
Training loss: 1.842874526977539
Validation loss: 2.1718396842479706

Epoch: 5| Step: 9
Training loss: 1.789010763168335
Validation loss: 2.192655007044474

Epoch: 5| Step: 10
Training loss: 1.2112197875976562
Validation loss: 2.1527821719646454

Epoch: 5| Step: 11
Training loss: 2.0232934951782227
Validation loss: 2.170154000322024

Epoch: 286| Step: 0
Training loss: 1.3903090953826904
Validation loss: 2.177597681681315

Epoch: 5| Step: 1
Training loss: 1.8192201852798462
Validation loss: 2.175843338171641

Epoch: 5| Step: 2
Training loss: 1.6538950204849243
Validation loss: 2.186963831384977

Epoch: 5| Step: 3
Training loss: 2.0422682762145996
Validation loss: 2.1941085308790207

Epoch: 5| Step: 4
Training loss: 1.6243865489959717
Validation loss: 2.237774059176445

Epoch: 5| Step: 5
Training loss: 1.5835020542144775
Validation loss: 2.228612040479978

Epoch: 5| Step: 6
Training loss: 1.2137640714645386
Validation loss: 2.186514566342036

Epoch: 5| Step: 7
Training loss: 1.8270072937011719
Validation loss: 2.2097777972618737

Epoch: 5| Step: 8
Training loss: 1.0698206424713135
Validation loss: 2.1926921804745994

Epoch: 5| Step: 9
Training loss: 2.8102540969848633
Validation loss: 2.1722133805354438

Epoch: 5| Step: 10
Training loss: 1.3422492742538452
Validation loss: 2.1825212438901267

Epoch: 5| Step: 11
Training loss: 0.6973835229873657
Validation loss: 2.138881648580233

Epoch: 287| Step: 0
Training loss: 1.7108023166656494
Validation loss: 2.1549538671970367

Epoch: 5| Step: 1
Training loss: 1.8127145767211914
Validation loss: 2.161516477664312

Epoch: 5| Step: 2
Training loss: 1.4891108274459839
Validation loss: 2.149197886387507

Epoch: 5| Step: 3
Training loss: 1.8855788707733154
Validation loss: 2.1540396163860955

Epoch: 5| Step: 4
Training loss: 1.9043601751327515
Validation loss: 2.161330292622248

Epoch: 5| Step: 5
Training loss: 2.056716203689575
Validation loss: 2.1707185357809067

Epoch: 5| Step: 6
Training loss: 1.3168071508407593
Validation loss: 2.1839600205421448

Epoch: 5| Step: 7
Training loss: 1.8100054264068604
Validation loss: 2.2093629936377206

Epoch: 5| Step: 8
Training loss: 1.4389599561691284
Validation loss: 2.166023696462313

Epoch: 5| Step: 9
Training loss: 1.1965209245681763
Validation loss: 2.1772858848174415

Epoch: 5| Step: 10
Training loss: 1.6160800457000732
Validation loss: 2.2107173204421997

Epoch: 5| Step: 11
Training loss: 0.6045882701873779
Validation loss: 2.197353104750315

Epoch: 288| Step: 0
Training loss: 1.855486273765564
Validation loss: 2.208863894144694

Epoch: 5| Step: 1
Training loss: 1.2980607748031616
Validation loss: 2.1786337544520697

Epoch: 5| Step: 2
Training loss: 1.8158763647079468
Validation loss: 2.1843331257502236

Epoch: 5| Step: 3
Training loss: 1.8493534326553345
Validation loss: 2.2101372877756753

Epoch: 5| Step: 4
Training loss: 1.8402023315429688
Validation loss: 2.185105855266253

Epoch: 5| Step: 5
Training loss: 1.5905847549438477
Validation loss: 2.1897370169560113

Epoch: 5| Step: 6
Training loss: 1.2329362630844116
Validation loss: 2.1969431092341742

Epoch: 5| Step: 7
Training loss: 1.9068933725357056
Validation loss: 2.1851049115260444

Epoch: 5| Step: 8
Training loss: 1.4089516401290894
Validation loss: 2.205489014585813

Epoch: 5| Step: 9
Training loss: 1.3870385885238647
Validation loss: 2.2101883788903556

Epoch: 5| Step: 10
Training loss: 1.6828933954238892
Validation loss: 2.2150542934735618

Epoch: 5| Step: 11
Training loss: 0.9363608956336975
Validation loss: 2.2313813318808875

Epoch: 289| Step: 0
Training loss: 1.8356845378875732
Validation loss: 2.1935511032740274

Epoch: 5| Step: 1
Training loss: 2.1868038177490234
Validation loss: 2.1901634633541107

Epoch: 5| Step: 2
Training loss: 1.5883917808532715
Validation loss: 2.19841963549455

Epoch: 5| Step: 3
Training loss: 1.241228461265564
Validation loss: 2.1751161267360053

Epoch: 5| Step: 4
Training loss: 1.8803828954696655
Validation loss: 2.196845203638077

Epoch: 5| Step: 5
Training loss: 1.3655530214309692
Validation loss: 2.171743929386139

Epoch: 5| Step: 6
Training loss: 1.7626193761825562
Validation loss: 2.1665747116009393

Epoch: 5| Step: 7
Training loss: 1.9781444072723389
Validation loss: 2.1913801630338035

Epoch: 5| Step: 8
Training loss: 1.0828701257705688
Validation loss: 2.1848209500312805

Epoch: 5| Step: 9
Training loss: 1.4257032871246338
Validation loss: 2.1869327425956726

Epoch: 5| Step: 10
Training loss: 1.8043506145477295
Validation loss: 2.1748127142588296

Epoch: 5| Step: 11
Training loss: 1.4232734441757202
Validation loss: 2.1705780227979026

Epoch: 290| Step: 0
Training loss: 1.327666997909546
Validation loss: 2.164653172095617

Epoch: 5| Step: 1
Training loss: 1.2190394401550293
Validation loss: 2.1565264066060386

Epoch: 5| Step: 2
Training loss: 1.4204200506210327
Validation loss: 2.140151912967364

Epoch: 5| Step: 3
Training loss: 1.4442059993743896
Validation loss: 2.1497193773587546

Epoch: 5| Step: 4
Training loss: 1.6177841424942017
Validation loss: 2.161916603644689

Epoch: 5| Step: 5
Training loss: 1.8587467670440674
Validation loss: 2.1882767925659814

Epoch: 5| Step: 6
Training loss: 1.3304916620254517
Validation loss: 2.1535070637861886

Epoch: 5| Step: 7
Training loss: 1.8613369464874268
Validation loss: 2.1507900257905326

Epoch: 5| Step: 8
Training loss: 1.2626237869262695
Validation loss: 2.1566405097643533

Epoch: 5| Step: 9
Training loss: 1.9176158905029297
Validation loss: 2.151202475031217

Epoch: 5| Step: 10
Training loss: 2.1179211139678955
Validation loss: 2.1625943879286447

Epoch: 5| Step: 11
Training loss: 1.5005619525909424
Validation loss: 2.1635538836320243

Epoch: 291| Step: 0
Training loss: 1.356054425239563
Validation loss: 2.178292711575826

Epoch: 5| Step: 1
Training loss: 1.2165381908416748
Validation loss: 2.188810795545578

Epoch: 5| Step: 2
Training loss: 1.8391748666763306
Validation loss: 2.197473590572675

Epoch: 5| Step: 3
Training loss: 1.874963402748108
Validation loss: 2.2181223432223

Epoch: 5| Step: 4
Training loss: 1.6390386819839478
Validation loss: 2.210968315601349

Epoch: 5| Step: 5
Training loss: 1.891263723373413
Validation loss: 2.204457471768061

Epoch: 5| Step: 6
Training loss: 1.6043593883514404
Validation loss: 2.194465378920237

Epoch: 5| Step: 7
Training loss: 1.5980594158172607
Validation loss: 2.2017065982023873

Epoch: 5| Step: 8
Training loss: 1.603642463684082
Validation loss: 2.1847321540117264

Epoch: 5| Step: 9
Training loss: 1.4098478555679321
Validation loss: 2.161810020605723

Epoch: 5| Step: 10
Training loss: 0.9577406644821167
Validation loss: 2.2004019021987915

Epoch: 5| Step: 11
Training loss: 3.6889352798461914
Validation loss: 2.189221809307734

Epoch: 292| Step: 0
Training loss: 1.6826635599136353
Validation loss: 2.157670055826505

Epoch: 5| Step: 1
Training loss: 1.6041266918182373
Validation loss: 2.1983123371998468

Epoch: 5| Step: 2
Training loss: 1.9194221496582031
Validation loss: 2.2274163266023

Epoch: 5| Step: 3
Training loss: 2.468432903289795
Validation loss: 2.20336606601874

Epoch: 5| Step: 4
Training loss: 1.8300399780273438
Validation loss: 2.2244944721460342

Epoch: 5| Step: 5
Training loss: 1.7488152980804443
Validation loss: 2.185050571958224

Epoch: 5| Step: 6
Training loss: 1.9073045253753662
Validation loss: 2.1692176510890326

Epoch: 5| Step: 7
Training loss: 1.738703966140747
Validation loss: 2.1516494899988174

Epoch: 5| Step: 8
Training loss: 1.7877426147460938
Validation loss: 2.1391661018133163

Epoch: 5| Step: 9
Training loss: 1.8861900568008423
Validation loss: 2.1543517460425696

Epoch: 5| Step: 10
Training loss: 1.48984694480896
Validation loss: 2.171132802963257

Epoch: 5| Step: 11
Training loss: 2.275092363357544
Validation loss: 2.1855142017205558

Epoch: 293| Step: 0
Training loss: 1.9293568134307861
Validation loss: 2.2054937928915024

Epoch: 5| Step: 1
Training loss: 1.7524001598358154
Validation loss: 2.2000055611133575

Epoch: 5| Step: 2
Training loss: 2.1128780841827393
Validation loss: 2.182983929912249

Epoch: 5| Step: 3
Training loss: 1.2713353633880615
Validation loss: 2.216297214229902

Epoch: 5| Step: 4
Training loss: 1.5394788980484009
Validation loss: 2.1618737826744714

Epoch: 5| Step: 5
Training loss: 1.3975481986999512
Validation loss: 2.1840270509322486

Epoch: 5| Step: 6
Training loss: 1.2774158716201782
Validation loss: 2.1860663245121636

Epoch: 5| Step: 7
Training loss: 1.40636146068573
Validation loss: 2.17886583507061

Epoch: 5| Step: 8
Training loss: 1.103091835975647
Validation loss: 2.191271801789602

Epoch: 5| Step: 9
Training loss: 2.641620635986328
Validation loss: 2.193135296305021

Epoch: 5| Step: 10
Training loss: 1.932918906211853
Validation loss: 2.19041375319163

Epoch: 5| Step: 11
Training loss: 1.2669748067855835
Validation loss: 2.217575713992119

Epoch: 294| Step: 0
Training loss: 1.0439084768295288
Validation loss: 2.2451741993427277

Epoch: 5| Step: 1
Training loss: 1.8416900634765625
Validation loss: 2.2209887554248176

Epoch: 5| Step: 2
Training loss: 1.966914415359497
Validation loss: 2.229839657743772

Epoch: 5| Step: 3
Training loss: 1.432149052619934
Validation loss: 2.239730417728424

Epoch: 5| Step: 4
Training loss: 1.514876365661621
Validation loss: 2.2324138085047402

Epoch: 5| Step: 5
Training loss: 1.4556914567947388
Validation loss: 2.2226484368244805

Epoch: 5| Step: 6
Training loss: 1.1345322132110596
Validation loss: 2.2197057654460273

Epoch: 5| Step: 7
Training loss: 1.8392530679702759
Validation loss: 2.199685583511988

Epoch: 5| Step: 8
Training loss: 1.535489559173584
Validation loss: 2.214270383119583

Epoch: 5| Step: 9
Training loss: 1.9173368215560913
Validation loss: 2.2117505967617035

Epoch: 5| Step: 10
Training loss: 1.6157058477401733
Validation loss: 2.2174228628476462

Epoch: 5| Step: 11
Training loss: 2.8385183811187744
Validation loss: 2.2466813077529273

Epoch: 295| Step: 0
Training loss: 1.5392277240753174
Validation loss: 2.2403831481933594

Epoch: 5| Step: 1
Training loss: 1.4388638734817505
Validation loss: 2.2223650316397348

Epoch: 5| Step: 2
Training loss: 1.1049476861953735
Validation loss: 2.1976585437854133

Epoch: 5| Step: 3
Training loss: 1.488504409790039
Validation loss: 2.1757158835728965

Epoch: 5| Step: 4
Training loss: 1.8885574340820312
Validation loss: 2.172718365987142

Epoch: 5| Step: 5
Training loss: 1.566776990890503
Validation loss: 2.168422748645147

Epoch: 5| Step: 6
Training loss: 1.7221637964248657
Validation loss: 2.1937900384267173

Epoch: 5| Step: 7
Training loss: 2.3293323516845703
Validation loss: 2.1598448157310486

Epoch: 5| Step: 8
Training loss: 1.4559608697891235
Validation loss: 2.1824797292550406

Epoch: 5| Step: 9
Training loss: 2.3203039169311523
Validation loss: 2.158012251059214

Epoch: 5| Step: 10
Training loss: 1.3007866144180298
Validation loss: 2.1825125416119895

Epoch: 5| Step: 11
Training loss: 0.8095928430557251
Validation loss: 2.165739059448242

Epoch: 296| Step: 0
Training loss: 1.6113471984863281
Validation loss: 2.225242833296458

Epoch: 5| Step: 1
Training loss: 2.340571641921997
Validation loss: 2.2002848188082376

Epoch: 5| Step: 2
Training loss: 2.1448795795440674
Validation loss: 2.236211289962133

Epoch: 5| Step: 3
Training loss: 1.5775331258773804
Validation loss: 2.1902638177076974

Epoch: 5| Step: 4
Training loss: 1.4578231573104858
Validation loss: 2.1954915523529053

Epoch: 5| Step: 5
Training loss: 1.675023078918457
Validation loss: 2.164512053132057

Epoch: 5| Step: 6
Training loss: 1.5496834516525269
Validation loss: 2.1537931710481644

Epoch: 5| Step: 7
Training loss: 2.44039249420166
Validation loss: 2.160439888636271

Epoch: 5| Step: 8
Training loss: 1.2362432479858398
Validation loss: 2.1609176993370056

Epoch: 5| Step: 9
Training loss: 1.3553550243377686
Validation loss: 2.1880930910507836

Epoch: 5| Step: 10
Training loss: 1.8537228107452393
Validation loss: 2.188992659250895

Epoch: 5| Step: 11
Training loss: 1.5576159954071045
Validation loss: 2.2041461219390235

Epoch: 297| Step: 0
Training loss: 1.5852158069610596
Validation loss: 2.2196269432703652

Epoch: 5| Step: 1
Training loss: 1.74093496799469
Validation loss: 2.220384036501249

Epoch: 5| Step: 2
Training loss: 0.9850759506225586
Validation loss: 2.216147651274999

Epoch: 5| Step: 3
Training loss: 2.0780177116394043
Validation loss: 2.224083657066027

Epoch: 5| Step: 4
Training loss: 1.875348687171936
Validation loss: 2.213681787252426

Epoch: 5| Step: 5
Training loss: 1.6771847009658813
Validation loss: 2.1938613653182983

Epoch: 5| Step: 6
Training loss: 2.689419746398926
Validation loss: 2.1724864145119986

Epoch: 5| Step: 7
Training loss: 1.5784015655517578
Validation loss: 2.146259754896164

Epoch: 5| Step: 8
Training loss: 1.7406151294708252
Validation loss: 2.1471794744332633

Epoch: 5| Step: 9
Training loss: 1.5978361368179321
Validation loss: 2.175062214334806

Epoch: 5| Step: 10
Training loss: 1.941683053970337
Validation loss: 2.1763918101787567

Epoch: 5| Step: 11
Training loss: 0.9109634757041931
Validation loss: 2.1763513137896857

Epoch: 298| Step: 0
Training loss: 1.9222595691680908
Validation loss: 2.1624581118424735

Epoch: 5| Step: 1
Training loss: 2.127816677093506
Validation loss: 2.159670198957125

Epoch: 5| Step: 2
Training loss: 2.050917148590088
Validation loss: 2.1592776676019034

Epoch: 5| Step: 3
Training loss: 1.7118027210235596
Validation loss: 2.170133809248606

Epoch: 5| Step: 4
Training loss: 1.1088650226593018
Validation loss: 2.1626476446787515

Epoch: 5| Step: 5
Training loss: 1.4594799280166626
Validation loss: 2.160406102736791

Epoch: 5| Step: 6
Training loss: 1.2633132934570312
Validation loss: 2.1639230251312256

Epoch: 5| Step: 7
Training loss: 1.2793934345245361
Validation loss: 2.160712788502375

Epoch: 5| Step: 8
Training loss: 1.2968405485153198
Validation loss: 2.1565555334091187

Epoch: 5| Step: 9
Training loss: 1.3386976718902588
Validation loss: 2.163825218876203

Epoch: 5| Step: 10
Training loss: 1.3030414581298828
Validation loss: 2.172603448232015

Epoch: 5| Step: 11
Training loss: 2.467242956161499
Validation loss: 2.18422361711661

Epoch: 299| Step: 0
Training loss: 1.7111774682998657
Validation loss: 2.181028589606285

Epoch: 5| Step: 1
Training loss: 1.9052091836929321
Validation loss: 2.202555408080419

Epoch: 5| Step: 2
Training loss: 1.1223043203353882
Validation loss: 2.175879289706548

Epoch: 5| Step: 3
Training loss: 1.2455880641937256
Validation loss: 2.1678173492352166

Epoch: 5| Step: 4
Training loss: 1.588123083114624
Validation loss: 2.1923205653826394

Epoch: 5| Step: 5
Training loss: 1.9267610311508179
Validation loss: 2.1769050657749176

Epoch: 5| Step: 6
Training loss: 0.9058220982551575
Validation loss: 2.1809041599432626

Epoch: 5| Step: 7
Training loss: 1.6441876888275146
Validation loss: 2.1825298815965652

Epoch: 5| Step: 8
Training loss: 1.7402989864349365
Validation loss: 2.1982979824145636

Epoch: 5| Step: 9
Training loss: 1.6470386981964111
Validation loss: 2.178231403231621

Epoch: 5| Step: 10
Training loss: 2.0753440856933594
Validation loss: 2.1771527181069055

Epoch: 5| Step: 11
Training loss: 2.7265162467956543
Validation loss: 2.2053406834602356

Epoch: 300| Step: 0
Training loss: 1.3099920749664307
Validation loss: 2.169683963060379

Epoch: 5| Step: 1
Training loss: 2.193221092224121
Validation loss: 2.2205617676178613

Epoch: 5| Step: 2
Training loss: 1.5163671970367432
Validation loss: 2.239220917224884

Epoch: 5| Step: 3
Training loss: 1.6514984369277954
Validation loss: 2.266428232192993

Epoch: 5| Step: 4
Training loss: 1.5810972452163696
Validation loss: 2.245862439274788

Epoch: 5| Step: 5
Training loss: 1.6787856817245483
Validation loss: 2.2285708089669547

Epoch: 5| Step: 6
Training loss: 1.3756660223007202
Validation loss: 2.1937038550774255

Epoch: 5| Step: 7
Training loss: 1.8174867630004883
Validation loss: 2.176143820087115

Epoch: 5| Step: 8
Training loss: 1.6710675954818726
Validation loss: 2.1627495090166726

Epoch: 5| Step: 9
Training loss: 1.5731990337371826
Validation loss: 2.167397598425547

Epoch: 5| Step: 10
Training loss: 1.8928508758544922
Validation loss: 2.1600242257118225

Epoch: 5| Step: 11
Training loss: 2.104149341583252
Validation loss: 2.1539524296919503

Testing loss: 2.0867814897633283
