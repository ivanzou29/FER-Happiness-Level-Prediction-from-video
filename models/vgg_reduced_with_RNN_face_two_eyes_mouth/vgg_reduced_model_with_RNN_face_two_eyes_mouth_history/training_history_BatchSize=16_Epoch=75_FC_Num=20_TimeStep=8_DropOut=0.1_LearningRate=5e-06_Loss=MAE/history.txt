Epoch: 1| Step: 0
Training loss: 5.981228828430176
Validation loss: 5.292864084243774

Epoch: 6| Step: 1
Training loss: 5.660933494567871
Validation loss: 5.290860176086426

Epoch: 6| Step: 2
Training loss: 5.395740032196045
Validation loss: 5.2888853549957275

Epoch: 6| Step: 3
Training loss: 3.919984817504883
Validation loss: 5.286995490392049

Epoch: 6| Step: 4
Training loss: 5.661150932312012
Validation loss: 5.285185813903809

Epoch: 6| Step: 5
Training loss: 5.7774763107299805
Validation loss: 5.283326784769694

Epoch: 6| Step: 6
Training loss: 4.9695916175842285
Validation loss: 5.281464020411174

Epoch: 6| Step: 7
Training loss: 3.9373209476470947
Validation loss: 5.279659748077393

Epoch: 6| Step: 8
Training loss: 5.886378765106201
Validation loss: 5.277818123499553

Epoch: 6| Step: 9
Training loss: 4.363644123077393
Validation loss: 5.275887330373128

Epoch: 6| Step: 10
Training loss: 4.994100093841553
Validation loss: 5.273967583974202

Epoch: 6| Step: 11
Training loss: 5.847862243652344
Validation loss: 5.272018671035767

Epoch: 6| Step: 12
Training loss: 5.626718521118164
Validation loss: 5.2699573040008545

Epoch: 6| Step: 13
Training loss: 6.872603416442871
Validation loss: 5.267861445744832

Epoch: 2| Step: 0
Training loss: 5.1295084953308105
Validation loss: 5.26553217569987

Epoch: 6| Step: 1
Training loss: 5.953359603881836
Validation loss: 5.263257185618083

Epoch: 6| Step: 2
Training loss: 6.453238487243652
Validation loss: 5.260682821273804

Epoch: 6| Step: 3
Training loss: 5.303350448608398
Validation loss: 5.258003234863281

Epoch: 6| Step: 4
Training loss: 5.1757988929748535
Validation loss: 5.255322615305583

Epoch: 6| Step: 5
Training loss: 4.5769171714782715
Validation loss: 5.252463738123576

Epoch: 6| Step: 6
Training loss: 5.747358798980713
Validation loss: 5.249288241068522

Epoch: 6| Step: 7
Training loss: 4.824425220489502
Validation loss: 5.245906750361125

Epoch: 6| Step: 8
Training loss: 5.595972061157227
Validation loss: 5.242618560791016

Epoch: 6| Step: 9
Training loss: 4.832266807556152
Validation loss: 5.238983949025472

Epoch: 6| Step: 10
Training loss: 4.482370376586914
Validation loss: 5.235065301259358

Epoch: 6| Step: 11
Training loss: 5.3921942710876465
Validation loss: 5.231019894282023

Epoch: 6| Step: 12
Training loss: 5.15724515914917
Validation loss: 5.22671111424764

Epoch: 6| Step: 13
Training loss: 5.796414375305176
Validation loss: 5.222307443618774

Epoch: 3| Step: 0
Training loss: 5.650707244873047
Validation loss: 5.217501878738403

Epoch: 6| Step: 1
Training loss: 4.9659833908081055
Validation loss: 5.212450742721558

Epoch: 6| Step: 2
Training loss: 4.831086158752441
Validation loss: 5.20722492535909

Epoch: 6| Step: 3
Training loss: 4.217021942138672
Validation loss: 5.201746384302775

Epoch: 6| Step: 4
Training loss: 5.685050010681152
Validation loss: 5.195972323417664

Epoch: 6| Step: 5
Training loss: 5.908979415893555
Validation loss: 5.190160195032756

Epoch: 6| Step: 6
Training loss: 4.889768123626709
Validation loss: 5.183908383051555

Epoch: 6| Step: 7
Training loss: 5.82826566696167
Validation loss: 5.177263339360555

Epoch: 6| Step: 8
Training loss: 3.3839221000671387
Validation loss: 5.170357545216878

Epoch: 6| Step: 9
Training loss: 5.7391180992126465
Validation loss: 5.163465976715088

Epoch: 6| Step: 10
Training loss: 6.8207902908325195
Validation loss: 5.156421661376953

Epoch: 6| Step: 11
Training loss: 5.562180519104004
Validation loss: 5.148760954538981

Epoch: 6| Step: 12
Training loss: 4.881893634796143
Validation loss: 5.140959580739339

Epoch: 6| Step: 13
Training loss: 5.1363701820373535
Validation loss: 5.132721583048503

Epoch: 4| Step: 0
Training loss: 5.335906982421875
Validation loss: 5.124484539031982

Epoch: 6| Step: 1
Training loss: 5.598835468292236
Validation loss: 5.115827242533366

Epoch: 6| Step: 2
Training loss: 5.178500652313232
Validation loss: 5.106841484705607

Epoch: 6| Step: 3
Training loss: 5.59073543548584
Validation loss: 5.097867250442505

Epoch: 6| Step: 4
Training loss: 4.320559978485107
Validation loss: 5.088333924611409

Epoch: 6| Step: 5
Training loss: 5.438628196716309
Validation loss: 5.079068541526794

Epoch: 6| Step: 6
Training loss: 5.167032241821289
Validation loss: 5.069329341252645

Epoch: 6| Step: 7
Training loss: 5.116010665893555
Validation loss: 5.059591611226399

Epoch: 6| Step: 8
Training loss: 4.591416358947754
Validation loss: 5.049440622329712

Epoch: 6| Step: 9
Training loss: 5.096014976501465
Validation loss: 5.0393311977386475

Epoch: 6| Step: 10
Training loss: 4.8152852058410645
Validation loss: 5.028954982757568

Epoch: 6| Step: 11
Training loss: 4.867166519165039
Validation loss: 5.018806378046672

Epoch: 6| Step: 12
Training loss: 5.058018207550049
Validation loss: 5.008558750152588

Epoch: 6| Step: 13
Training loss: 5.79825496673584
Validation loss: 4.9982039133707685

Epoch: 5| Step: 0
Training loss: 4.974246025085449
Validation loss: 4.9876768589019775

Epoch: 6| Step: 1
Training loss: 5.071906089782715
Validation loss: 4.977153380711873

Epoch: 6| Step: 2
Training loss: 4.269774436950684
Validation loss: 4.966695149739583

Epoch: 6| Step: 3
Training loss: 5.2574567794799805
Validation loss: 4.9560008843739825

Epoch: 6| Step: 4
Training loss: 6.946771621704102
Validation loss: 4.945196787516276

Epoch: 6| Step: 5
Training loss: 5.961115837097168
Validation loss: 4.934511820475261

Epoch: 6| Step: 6
Training loss: 4.118511199951172
Validation loss: 4.923785130182902

Epoch: 6| Step: 7
Training loss: 3.830044984817505
Validation loss: 4.912671089172363

Epoch: 6| Step: 8
Training loss: 5.319130897521973
Validation loss: 4.9020248254140215

Epoch: 6| Step: 9
Training loss: 5.346877574920654
Validation loss: 4.891125679016113

Epoch: 6| Step: 10
Training loss: 4.4192681312561035
Validation loss: 4.88040026028951

Epoch: 6| Step: 11
Training loss: 5.1346611976623535
Validation loss: 4.869537194569905

Epoch: 6| Step: 12
Training loss: 4.257275104522705
Validation loss: 4.85893185933431

Epoch: 6| Step: 13
Training loss: 5.109264373779297
Validation loss: 4.847868124643962

Epoch: 6| Step: 0
Training loss: 5.302484035491943
Validation loss: 4.8370803991953535

Epoch: 6| Step: 1
Training loss: 4.824626922607422
Validation loss: 4.826294342676799

Epoch: 6| Step: 2
Training loss: 4.097426414489746
Validation loss: 4.815181334813436

Epoch: 6| Step: 3
Training loss: 5.148794174194336
Validation loss: 4.804566780726115

Epoch: 6| Step: 4
Training loss: 6.415352821350098
Validation loss: 4.793283621470134

Epoch: 6| Step: 5
Training loss: 4.402731895446777
Validation loss: 4.782725890477498

Epoch: 6| Step: 6
Training loss: 4.224837303161621
Validation loss: 4.772157192230225

Epoch: 6| Step: 7
Training loss: 5.0094828605651855
Validation loss: 4.761621395746867

Epoch: 6| Step: 8
Training loss: 4.842098236083984
Validation loss: 4.7514381011327105

Epoch: 6| Step: 9
Training loss: 4.387096405029297
Validation loss: 4.7408952713012695

Epoch: 6| Step: 10
Training loss: 4.2090301513671875
Validation loss: 4.730173587799072

Epoch: 6| Step: 11
Training loss: 5.498002052307129
Validation loss: 4.7198905150095625

Epoch: 6| Step: 12
Training loss: 4.8607282638549805
Validation loss: 4.709845225016276

Epoch: 6| Step: 13
Training loss: 4.765276908874512
Validation loss: 4.699049790700276

Epoch: 7| Step: 0
Training loss: 4.634416103363037
Validation loss: 4.689244786898295

Epoch: 6| Step: 1
Training loss: 6.065701961517334
Validation loss: 4.678677320480347

Epoch: 6| Step: 2
Training loss: 5.141574382781982
Validation loss: 4.668757677078247

Epoch: 6| Step: 3
Training loss: 4.991456508636475
Validation loss: 4.658928195635478

Epoch: 6| Step: 4
Training loss: 4.703194618225098
Validation loss: 4.648999929428101

Epoch: 6| Step: 5
Training loss: 4.852642059326172
Validation loss: 4.638959884643555

Epoch: 6| Step: 6
Training loss: 3.872882604598999
Validation loss: 4.629830519358317

Epoch: 6| Step: 7
Training loss: 5.017328262329102
Validation loss: 4.62004550298055

Epoch: 6| Step: 8
Training loss: 4.415726661682129
Validation loss: 4.610539436340332

Epoch: 6| Step: 9
Training loss: 4.716315269470215
Validation loss: 4.601446866989136

Epoch: 6| Step: 10
Training loss: 4.026641368865967
Validation loss: 4.592791716257731

Epoch: 6| Step: 11
Training loss: 4.043230056762695
Validation loss: 4.584251721700032

Epoch: 6| Step: 12
Training loss: 4.393064498901367
Validation loss: 4.575005769729614

Epoch: 6| Step: 13
Training loss: 5.265265464782715
Validation loss: 4.566985845565796

Epoch: 8| Step: 0
Training loss: 5.03875732421875
Validation loss: 4.558063983917236

Epoch: 6| Step: 1
Training loss: 5.813628673553467
Validation loss: 4.549586216608684

Epoch: 6| Step: 2
Training loss: 4.627823352813721
Validation loss: 4.541355053583781

Epoch: 6| Step: 3
Training loss: 4.438143730163574
Validation loss: 4.5327943960825605

Epoch: 6| Step: 4
Training loss: 4.167196750640869
Validation loss: 4.524845997492473

Epoch: 6| Step: 5
Training loss: 4.754607200622559
Validation loss: 4.517079313596089

Epoch: 6| Step: 6
Training loss: 3.9487767219543457
Validation loss: 4.509657780329387

Epoch: 6| Step: 7
Training loss: 4.95160436630249
Validation loss: 4.502301772435506

Epoch: 6| Step: 8
Training loss: 4.784483909606934
Validation loss: 4.494484066963196

Epoch: 6| Step: 9
Training loss: 4.551852703094482
Validation loss: 4.487195213635762

Epoch: 6| Step: 10
Training loss: 4.0005083084106445
Validation loss: 4.4796187082926435

Epoch: 6| Step: 11
Training loss: 4.976315975189209
Validation loss: 4.472791790962219

Epoch: 6| Step: 12
Training loss: 4.330356121063232
Validation loss: 4.4652150472005205

Epoch: 6| Step: 13
Training loss: 4.21351432800293
Validation loss: 4.458301146825154

Epoch: 9| Step: 0
Training loss: 5.107937812805176
Validation loss: 4.451342423756917

Epoch: 6| Step: 1
Training loss: 4.390215873718262
Validation loss: 4.445285161336263

Epoch: 6| Step: 2
Training loss: 4.470995903015137
Validation loss: 4.438814401626587

Epoch: 6| Step: 3
Training loss: 4.809239864349365
Validation loss: 4.433089812596639

Epoch: 6| Step: 4
Training loss: 4.589052200317383
Validation loss: 4.426829973856608

Epoch: 6| Step: 5
Training loss: 4.498227119445801
Validation loss: 4.420920968055725

Epoch: 6| Step: 6
Training loss: 3.7212109565734863
Validation loss: 4.415080110232036

Epoch: 6| Step: 7
Training loss: 3.3349623680114746
Validation loss: 4.409108559290568

Epoch: 6| Step: 8
Training loss: 4.541596412658691
Validation loss: 4.403920451800029

Epoch: 6| Step: 9
Training loss: 4.822413444519043
Validation loss: 4.398073514302571

Epoch: 6| Step: 10
Training loss: 3.6747639179229736
Validation loss: 4.392231980959575

Epoch: 6| Step: 11
Training loss: 5.405649185180664
Validation loss: 4.387645880381267

Epoch: 6| Step: 12
Training loss: 5.119840621948242
Validation loss: 4.380879282951355

Epoch: 6| Step: 13
Training loss: 4.898815631866455
Validation loss: 4.37519896030426

Epoch: 10| Step: 0
Training loss: 4.406830787658691
Validation loss: 4.36949888865153

Epoch: 6| Step: 1
Training loss: 4.850072860717773
Validation loss: 4.3638360897699995

Epoch: 6| Step: 2
Training loss: 3.990966558456421
Validation loss: 4.35795255502065

Epoch: 6| Step: 3
Training loss: 5.2442946434021
Validation loss: 4.351849595705668

Epoch: 6| Step: 4
Training loss: 4.414427757263184
Validation loss: 4.345600048700969

Epoch: 6| Step: 5
Training loss: 4.280551910400391
Validation loss: 4.339266578356425

Epoch: 6| Step: 6
Training loss: 4.804754257202148
Validation loss: 4.333399931589763

Epoch: 6| Step: 7
Training loss: 3.639465808868408
Validation loss: 4.327341238657634

Epoch: 6| Step: 8
Training loss: 4.722481727600098
Validation loss: 4.320920904477437

Epoch: 6| Step: 9
Training loss: 3.3632261753082275
Validation loss: 4.314041614532471

Epoch: 6| Step: 10
Training loss: 4.097569465637207
Validation loss: 4.3080776532491045

Epoch: 6| Step: 11
Training loss: 5.016143798828125
Validation loss: 4.301962614059448

Epoch: 6| Step: 12
Training loss: 4.62540864944458
Validation loss: 4.2951832214991255

Epoch: 6| Step: 13
Training loss: 4.904767990112305
Validation loss: 4.288061777750651

Epoch: 11| Step: 0
Training loss: 3.608436107635498
Validation loss: 4.281428297360738

Epoch: 6| Step: 1
Training loss: 4.19964075088501
Validation loss: 4.2745044231414795

Epoch: 6| Step: 2
Training loss: 4.425779342651367
Validation loss: 4.269289016723633

Epoch: 6| Step: 3
Training loss: 4.011956691741943
Validation loss: 4.2615940173467

Epoch: 6| Step: 4
Training loss: 3.6929433345794678
Validation loss: 4.255123138427734

Epoch: 6| Step: 5
Training loss: 4.822646141052246
Validation loss: 4.249176025390625

Epoch: 6| Step: 6
Training loss: 4.56752872467041
Validation loss: 4.242234428723653

Epoch: 6| Step: 7
Training loss: 5.296994209289551
Validation loss: 4.235990285873413

Epoch: 6| Step: 8
Training loss: 3.1749424934387207
Validation loss: 4.228954474131267

Epoch: 6| Step: 9
Training loss: 5.259217739105225
Validation loss: 4.222417593002319

Epoch: 6| Step: 10
Training loss: 5.021334648132324
Validation loss: 4.2182743946711225

Epoch: 6| Step: 11
Training loss: 4.561666965484619
Validation loss: 4.209827820460002

Epoch: 6| Step: 12
Training loss: 3.598912239074707
Validation loss: 4.204131126403809

Epoch: 6| Step: 13
Training loss: 4.931764602661133
Validation loss: 4.198681076367696

Epoch: 12| Step: 0
Training loss: 3.5205817222595215
Validation loss: 4.191756010055542

Epoch: 6| Step: 1
Training loss: 4.553309440612793
Validation loss: 4.186099847157796

Epoch: 6| Step: 2
Training loss: 4.378017425537109
Validation loss: 4.178678234418233

Epoch: 6| Step: 3
Training loss: 4.289209365844727
Validation loss: 4.172663966814677

Epoch: 6| Step: 4
Training loss: 3.912609100341797
Validation loss: 4.1668180624643965

Epoch: 6| Step: 5
Training loss: 4.30854606628418
Validation loss: 4.161064823468526

Epoch: 6| Step: 6
Training loss: 4.755101203918457
Validation loss: 4.154531081517537

Epoch: 6| Step: 7
Training loss: 5.597456932067871
Validation loss: 4.147427121798198

Epoch: 6| Step: 8
Training loss: 3.512383222579956
Validation loss: 4.141364733378093

Epoch: 6| Step: 9
Training loss: 3.702526092529297
Validation loss: 4.135304053624471

Epoch: 6| Step: 10
Training loss: 4.293933868408203
Validation loss: 4.12852128346761

Epoch: 6| Step: 11
Training loss: 5.340875625610352
Validation loss: 4.122012615203857

Epoch: 6| Step: 12
Training loss: 3.465000867843628
Validation loss: 4.116190075874329

Epoch: 6| Step: 13
Training loss: 4.394510269165039
Validation loss: 4.109696427981059

Epoch: 13| Step: 0
Training loss: 3.7845053672790527
Validation loss: 4.104115923245748

Epoch: 6| Step: 1
Training loss: 4.098675727844238
Validation loss: 4.098623752593994

Epoch: 6| Step: 2
Training loss: 4.645061492919922
Validation loss: 4.092719316482544

Epoch: 6| Step: 3
Training loss: 4.314748764038086
Validation loss: 4.086426059405009

Epoch: 6| Step: 4
Training loss: 3.8282880783081055
Validation loss: 4.080394903818767

Epoch: 6| Step: 5
Training loss: 3.7194128036499023
Validation loss: 4.07451053460439

Epoch: 6| Step: 6
Training loss: 3.8221566677093506
Validation loss: 4.068897207578023

Epoch: 6| Step: 7
Training loss: 5.612664222717285
Validation loss: 4.063627918561299

Epoch: 6| Step: 8
Training loss: 3.9357478618621826
Validation loss: 4.058589855829875

Epoch: 6| Step: 9
Training loss: 4.811092376708984
Validation loss: 4.0526498556137085

Epoch: 6| Step: 10
Training loss: 5.524458885192871
Validation loss: 4.047715783119202

Epoch: 6| Step: 11
Training loss: 3.949061632156372
Validation loss: 4.041488130887349

Epoch: 6| Step: 12
Training loss: 3.450110912322998
Validation loss: 4.035466273625691

Epoch: 6| Step: 13
Training loss: 3.4444730281829834
Validation loss: 4.030998587608337

Epoch: 14| Step: 0
Training loss: 4.243289947509766
Validation loss: 4.02502179145813

Epoch: 6| Step: 1
Training loss: 4.5804643630981445
Validation loss: 4.018572449684143

Epoch: 6| Step: 2
Training loss: 3.4169299602508545
Validation loss: 4.016039212544759

Epoch: 6| Step: 3
Training loss: 4.152801990509033
Validation loss: 4.0152749220530195

Epoch: 6| Step: 4
Training loss: 2.8828160762786865
Validation loss: 4.003458897272746

Epoch: 6| Step: 5
Training loss: 4.421245574951172
Validation loss: 3.998710791269938

Epoch: 6| Step: 6
Training loss: 4.5643086433410645
Validation loss: 3.9960830211639404

Epoch: 6| Step: 7
Training loss: 2.7336699962615967
Validation loss: 3.9913723866144815

Epoch: 6| Step: 8
Training loss: 4.588475704193115
Validation loss: 3.9850127696990967

Epoch: 6| Step: 9
Training loss: 4.833803176879883
Validation loss: 3.9795544147491455

Epoch: 6| Step: 10
Training loss: 4.815018653869629
Validation loss: 3.9721957445144653

Epoch: 6| Step: 11
Training loss: 3.7580103874206543
Validation loss: 3.9667557875315347

Epoch: 6| Step: 12
Training loss: 4.077511310577393
Validation loss: 3.9614487489064536

Epoch: 6| Step: 13
Training loss: 4.848625183105469
Validation loss: 3.95661191145579

Epoch: 15| Step: 0
Training loss: 5.499241828918457
Validation loss: 3.951887091000875

Epoch: 6| Step: 1
Training loss: 4.477044582366943
Validation loss: 3.945629596710205

Epoch: 6| Step: 2
Training loss: 3.1224493980407715
Validation loss: 3.940954883893331

Epoch: 6| Step: 3
Training loss: 4.060937881469727
Validation loss: 3.9367173115412393

Epoch: 6| Step: 4
Training loss: 5.1735100746154785
Validation loss: 3.9312469561894736

Epoch: 6| Step: 5
Training loss: 4.51226806640625
Validation loss: 3.926648656527201

Epoch: 6| Step: 6
Training loss: 2.7721962928771973
Validation loss: 3.921465198198954

Epoch: 6| Step: 7
Training loss: 4.515690326690674
Validation loss: 3.916023055712382

Epoch: 6| Step: 8
Training loss: 3.604679822921753
Validation loss: 3.9111071030298867

Epoch: 6| Step: 9
Training loss: 3.633741855621338
Validation loss: 3.9055312474568686

Epoch: 6| Step: 10
Training loss: 3.6871848106384277
Validation loss: 3.900443951288859

Epoch: 6| Step: 11
Training loss: 3.7373759746551514
Validation loss: 3.8970830043156943

Epoch: 6| Step: 12
Training loss: 4.263671875
Validation loss: 3.8929473956425986

Epoch: 6| Step: 13
Training loss: 3.894207000732422
Validation loss: 3.886366883913676

Epoch: 16| Step: 0
Training loss: 4.975803375244141
Validation loss: 3.8838243881861367

Epoch: 6| Step: 1
Training loss: 3.3948111534118652
Validation loss: 3.883688767751058

Epoch: 6| Step: 2
Training loss: 3.844705820083618
Validation loss: 3.875626802444458

Epoch: 6| Step: 3
Training loss: 4.812252044677734
Validation loss: 3.869986136754354

Epoch: 6| Step: 4
Training loss: 3.900435209274292
Validation loss: 3.8656400442123413

Epoch: 6| Step: 5
Training loss: 4.037615776062012
Validation loss: 3.86176590124766

Epoch: 6| Step: 6
Training loss: 4.024980068206787
Validation loss: 3.8576403061548867

Epoch: 6| Step: 7
Training loss: 4.078540325164795
Validation loss: 3.8527281284332275

Epoch: 6| Step: 8
Training loss: 4.670783042907715
Validation loss: 3.847718596458435

Epoch: 6| Step: 9
Training loss: 2.810781478881836
Validation loss: 3.84290877978007

Epoch: 6| Step: 10
Training loss: 3.655557155609131
Validation loss: 3.838310122489929

Epoch: 6| Step: 11
Training loss: 4.54352331161499
Validation loss: 3.834130843480428

Epoch: 6| Step: 12
Training loss: 3.2710161209106445
Validation loss: 3.829049030939738

Epoch: 6| Step: 13
Training loss: 4.061168193817139
Validation loss: 3.823580185572306

Epoch: 17| Step: 0
Training loss: 4.321473121643066
Validation loss: 3.8182523250579834

Epoch: 6| Step: 1
Training loss: 4.488820552825928
Validation loss: 3.814109126726786

Epoch: 6| Step: 2
Training loss: 3.3334102630615234
Validation loss: 3.809685468673706

Epoch: 6| Step: 3
Training loss: 3.7942914962768555
Validation loss: 3.804653286933899

Epoch: 6| Step: 4
Training loss: 3.944788932800293
Validation loss: 3.8000092109044394

Epoch: 6| Step: 5
Training loss: 3.1127047538757324
Validation loss: 3.7951473395029702

Epoch: 6| Step: 6
Training loss: 4.302438259124756
Validation loss: 3.7911254167556763

Epoch: 6| Step: 7
Training loss: 3.768165111541748
Validation loss: 3.7872517108917236

Epoch: 6| Step: 8
Training loss: 3.631072998046875
Validation loss: 3.7823070685068765

Epoch: 6| Step: 9
Training loss: 3.656309127807617
Validation loss: 3.7778180042902627

Epoch: 6| Step: 10
Training loss: 4.759572505950928
Validation loss: 3.773074229558309

Epoch: 6| Step: 11
Training loss: 4.522779941558838
Validation loss: 3.7686829964319863

Epoch: 6| Step: 12
Training loss: 2.9900171756744385
Validation loss: 3.764190117518107

Epoch: 6| Step: 13
Training loss: 4.6150736808776855
Validation loss: 3.7597166299819946

Epoch: 18| Step: 0
Training loss: 3.165616512298584
Validation loss: 3.7549994389216104

Epoch: 6| Step: 1
Training loss: 3.1964452266693115
Validation loss: 3.750994165738424

Epoch: 6| Step: 2
Training loss: 2.8722100257873535
Validation loss: 3.7469120025634766

Epoch: 6| Step: 3
Training loss: 3.913583278656006
Validation loss: 3.742704470952352

Epoch: 6| Step: 4
Training loss: 3.7661166191101074
Validation loss: 3.7384897470474243

Epoch: 6| Step: 5
Training loss: 3.8049869537353516
Validation loss: 3.7341037591298423

Epoch: 6| Step: 6
Training loss: 3.9163365364074707
Validation loss: 3.7295695543289185

Epoch: 6| Step: 7
Training loss: 3.7276382446289062
Validation loss: 3.725358724594116

Epoch: 6| Step: 8
Training loss: 4.6944966316223145
Validation loss: 3.720772703488668

Epoch: 6| Step: 9
Training loss: 3.4485507011413574
Validation loss: 3.716784358024597

Epoch: 6| Step: 10
Training loss: 5.665674209594727
Validation loss: 3.7124534845352173

Epoch: 6| Step: 11
Training loss: 4.242919445037842
Validation loss: 3.7083374659220376

Epoch: 6| Step: 12
Training loss: 4.0558319091796875
Validation loss: 3.7042317390441895

Epoch: 6| Step: 13
Training loss: 3.9667932987213135
Validation loss: 3.7001397609710693

Epoch: 19| Step: 0
Training loss: 3.227919340133667
Validation loss: 3.696306586265564

Epoch: 6| Step: 1
Training loss: 4.444971084594727
Validation loss: 3.6915766398111978

Epoch: 6| Step: 2
Training loss: 4.1082682609558105
Validation loss: 3.6876182158788047

Epoch: 6| Step: 3
Training loss: 3.715667724609375
Validation loss: 3.683544675509135

Epoch: 6| Step: 4
Training loss: 4.0860700607299805
Validation loss: 3.679798404375712

Epoch: 6| Step: 5
Training loss: 2.6681594848632812
Validation loss: 3.6755443811416626

Epoch: 6| Step: 6
Training loss: 4.242598533630371
Validation loss: 3.671505014101664

Epoch: 6| Step: 7
Training loss: 4.208031177520752
Validation loss: 3.667280157407125

Epoch: 6| Step: 8
Training loss: 4.202415466308594
Validation loss: 3.6634035110473633

Epoch: 6| Step: 9
Training loss: 4.099270343780518
Validation loss: 3.6595720450083413

Epoch: 6| Step: 10
Training loss: 4.584528923034668
Validation loss: 3.6554712851842246

Epoch: 6| Step: 11
Training loss: 3.079906463623047
Validation loss: 3.6514041423797607

Epoch: 6| Step: 12
Training loss: 3.5720255374908447
Validation loss: 3.6487335364023843

Epoch: 6| Step: 13
Training loss: 3.3957605361938477
Validation loss: 3.642729083697001

Epoch: 20| Step: 0
Training loss: 3.718371868133545
Validation loss: 3.6386818488438926

Epoch: 6| Step: 1
Training loss: 3.3123483657836914
Validation loss: 3.634792963663737

Epoch: 6| Step: 2
Training loss: 3.162105083465576
Validation loss: 3.6308294932047525

Epoch: 6| Step: 3
Training loss: 4.327461242675781
Validation loss: 3.626944382985433

Epoch: 6| Step: 4
Training loss: 3.643979549407959
Validation loss: 3.622520367304484

Epoch: 6| Step: 5
Training loss: 4.39160680770874
Validation loss: 3.6183974742889404

Epoch: 6| Step: 6
Training loss: 4.636343002319336
Validation loss: 3.6142762502034507

Epoch: 6| Step: 7
Training loss: 3.5446760654449463
Validation loss: 3.6107543309529624

Epoch: 6| Step: 8
Training loss: 3.921751022338867
Validation loss: 3.606430768966675

Epoch: 6| Step: 9
Training loss: 3.0450282096862793
Validation loss: 3.6026917695999146

Epoch: 6| Step: 10
Training loss: 3.3920867443084717
Validation loss: 3.5982075532277427

Epoch: 6| Step: 11
Training loss: 3.5957188606262207
Validation loss: 3.5941821734110513

Epoch: 6| Step: 12
Training loss: 4.077815532684326
Validation loss: 3.5899070501327515

Epoch: 6| Step: 13
Training loss: 4.084740161895752
Validation loss: 3.5856690804163613

Epoch: 21| Step: 0
Training loss: 3.5276026725769043
Validation loss: 3.5814889669418335

Epoch: 6| Step: 1
Training loss: 4.355627059936523
Validation loss: 3.5772642294565835

Epoch: 6| Step: 2
Training loss: 4.301935195922852
Validation loss: 3.5730047623316445

Epoch: 6| Step: 3
Training loss: 3.103778600692749
Validation loss: 3.5687185525894165

Epoch: 6| Step: 4
Training loss: 3.2869274616241455
Validation loss: 3.564371426900228

Epoch: 6| Step: 5
Training loss: 3.8502566814422607
Validation loss: 3.5605159997940063

Epoch: 6| Step: 6
Training loss: 3.91180419921875
Validation loss: 3.5563711722691855

Epoch: 6| Step: 7
Training loss: 3.6977264881134033
Validation loss: 3.552116354306539

Epoch: 6| Step: 8
Training loss: 3.6316046714782715
Validation loss: 3.5479456981023154

Epoch: 6| Step: 9
Training loss: 3.571617841720581
Validation loss: 3.54365066687266

Epoch: 6| Step: 10
Training loss: 4.169738292694092
Validation loss: 3.5396662950515747

Epoch: 6| Step: 11
Training loss: 3.855553388595581
Validation loss: 3.5350519021352134

Epoch: 6| Step: 12
Training loss: 3.8858463764190674
Validation loss: 3.531276981035868

Epoch: 6| Step: 13
Training loss: 2.9286487102508545
Validation loss: 3.526953935623169

Epoch: 22| Step: 0
Training loss: 4.03513240814209
Validation loss: 3.522886594136556

Epoch: 6| Step: 1
Training loss: 3.374267101287842
Validation loss: 3.5187437931696572

Epoch: 6| Step: 2
Training loss: 3.6503968238830566
Validation loss: 3.5147758324941

Epoch: 6| Step: 3
Training loss: 4.175363540649414
Validation loss: 3.5102666219075522

Epoch: 6| Step: 4
Training loss: 4.347908020019531
Validation loss: 3.505953232447306

Epoch: 6| Step: 5
Training loss: 3.0313127040863037
Validation loss: 3.501532713572184

Epoch: 6| Step: 6
Training loss: 4.248798370361328
Validation loss: 3.4968965450922647

Epoch: 6| Step: 7
Training loss: 2.1536989212036133
Validation loss: 3.493155002593994

Epoch: 6| Step: 8
Training loss: 3.6594486236572266
Validation loss: 3.4889387687047324

Epoch: 6| Step: 9
Training loss: 3.888998508453369
Validation loss: 3.4845542510350547

Epoch: 6| Step: 10
Training loss: 4.232624053955078
Validation loss: 3.4804592529932656

Epoch: 6| Step: 11
Training loss: 2.9716148376464844
Validation loss: 3.4762595494588218

Epoch: 6| Step: 12
Training loss: 4.130194664001465
Validation loss: 3.472117304801941

Epoch: 6| Step: 13
Training loss: 3.386495590209961
Validation loss: 3.468187093734741

Epoch: 23| Step: 0
Training loss: 3.463245391845703
Validation loss: 3.4635794957478843

Epoch: 6| Step: 1
Training loss: 3.0560145378112793
Validation loss: 3.4596723318099976

Epoch: 6| Step: 2
Training loss: 3.2078118324279785
Validation loss: 3.456066091855367

Epoch: 6| Step: 3
Training loss: 4.28785514831543
Validation loss: 3.4520101149876914

Epoch: 6| Step: 4
Training loss: 3.316593647003174
Validation loss: 3.44752828280131

Epoch: 6| Step: 5
Training loss: 3.8106467723846436
Validation loss: 3.442710598309835

Epoch: 6| Step: 6
Training loss: 3.3558998107910156
Validation loss: 3.438530365626017

Epoch: 6| Step: 7
Training loss: 3.071699380874634
Validation loss: 3.434725006421407

Epoch: 6| Step: 8
Training loss: 4.214169025421143
Validation loss: 3.4306199153264365

Epoch: 6| Step: 9
Training loss: 2.6604437828063965
Validation loss: 3.426319201787313

Epoch: 6| Step: 10
Training loss: 3.860100030899048
Validation loss: 3.42255691687266

Epoch: 6| Step: 11
Training loss: 4.012852668762207
Validation loss: 3.418555657068888

Epoch: 6| Step: 12
Training loss: 3.6877458095550537
Validation loss: 3.414576848347982

Epoch: 6| Step: 13
Training loss: 4.458494186401367
Validation loss: 3.410739302635193

Epoch: 24| Step: 0
Training loss: 3.1530957221984863
Validation loss: 3.4062097469965615

Epoch: 6| Step: 1
Training loss: 4.339730739593506
Validation loss: 3.4021153847376504

Epoch: 6| Step: 2
Training loss: 3.7764408588409424
Validation loss: 3.398208498954773

Epoch: 6| Step: 3
Training loss: 3.532712936401367
Validation loss: 3.3948185046513877

Epoch: 6| Step: 4
Training loss: 3.91092848777771
Validation loss: 3.3906861941019693

Epoch: 6| Step: 5
Training loss: 4.213261604309082
Validation loss: 3.3860889673233032

Epoch: 6| Step: 6
Training loss: 2.62284517288208
Validation loss: 3.381358027458191

Epoch: 6| Step: 7
Training loss: 3.0961923599243164
Validation loss: 3.3765963315963745

Epoch: 6| Step: 8
Training loss: 2.7640700340270996
Validation loss: 3.3723934094111123

Epoch: 6| Step: 9
Training loss: 3.5576014518737793
Validation loss: 3.3682490587234497

Epoch: 6| Step: 10
Training loss: 3.86395263671875
Validation loss: 3.363781770070394

Epoch: 6| Step: 11
Training loss: 3.713235855102539
Validation loss: 3.3597002029418945

Epoch: 6| Step: 12
Training loss: 3.4593405723571777
Validation loss: 3.3553444544474282

Epoch: 6| Step: 13
Training loss: 3.6846418380737305
Validation loss: 3.3515168031056723

Epoch: 25| Step: 0
Training loss: 3.486177444458008
Validation loss: 3.3490817546844482

Epoch: 6| Step: 1
Training loss: 3.4841225147247314
Validation loss: 3.343490203221639

Epoch: 6| Step: 2
Training loss: 3.7637009620666504
Validation loss: 3.339642643928528

Epoch: 6| Step: 3
Training loss: 4.26314115524292
Validation loss: 3.336085001627604

Epoch: 6| Step: 4
Training loss: 3.5265183448791504
Validation loss: 3.332366625467936

Epoch: 6| Step: 5
Training loss: 3.443812847137451
Validation loss: 3.3284390767415366

Epoch: 6| Step: 6
Training loss: 4.329362392425537
Validation loss: 3.3242314656575522

Epoch: 6| Step: 7
Training loss: 3.3759262561798096
Validation loss: 3.3205388387044272

Epoch: 6| Step: 8
Training loss: 4.28608512878418
Validation loss: 3.3160321712493896

Epoch: 6| Step: 9
Training loss: 2.524439573287964
Validation loss: 3.311988592147827

Epoch: 6| Step: 10
Training loss: 3.2179558277130127
Validation loss: 3.3082324663798013

Epoch: 6| Step: 11
Training loss: 2.6573598384857178
Validation loss: 3.3040579160054526

Epoch: 6| Step: 12
Training loss: 3.57212495803833
Validation loss: 3.300039450327555

Epoch: 6| Step: 13
Training loss: 2.9812495708465576
Validation loss: 3.2960058450698853

Epoch: 26| Step: 0
Training loss: 3.7770676612854004
Validation loss: 3.29202671845754

Epoch: 6| Step: 1
Training loss: 2.948620557785034
Validation loss: 3.288078546524048

Epoch: 6| Step: 2
Training loss: 4.413166046142578
Validation loss: 3.2841829856236777

Epoch: 6| Step: 3
Training loss: 4.046154022216797
Validation loss: 3.280445615450541

Epoch: 6| Step: 4
Training loss: 3.040943145751953
Validation loss: 3.2761974732081094

Epoch: 6| Step: 5
Training loss: 3.5315654277801514
Validation loss: 3.2721036275227866

Epoch: 6| Step: 6
Training loss: 3.370211362838745
Validation loss: 3.267927130063375

Epoch: 6| Step: 7
Training loss: 2.7689342498779297
Validation loss: 3.2640726963678994

Epoch: 6| Step: 8
Training loss: 2.7969398498535156
Validation loss: 3.2600341041882834

Epoch: 6| Step: 9
Training loss: 3.491600513458252
Validation loss: 3.256226976712545

Epoch: 6| Step: 10
Training loss: 3.0042190551757812
Validation loss: 3.2529341777165732

Epoch: 6| Step: 11
Training loss: 4.105541706085205
Validation loss: 3.2491177320480347

Epoch: 6| Step: 12
Training loss: 3.4777798652648926
Validation loss: 3.245341738065084

Epoch: 6| Step: 13
Training loss: 3.435457229614258
Validation loss: 3.2415990829467773

Epoch: 27| Step: 0
Training loss: 4.102165222167969
Validation loss: 3.2381736834843955

Epoch: 6| Step: 1
Training loss: 3.400733470916748
Validation loss: 3.233869512875875

Epoch: 6| Step: 2
Training loss: 3.6351075172424316
Validation loss: 3.2302252451578775

Epoch: 6| Step: 3
Training loss: 3.338564157485962
Validation loss: 3.226358930269877

Epoch: 6| Step: 4
Training loss: 2.979724407196045
Validation loss: 3.2226744492848716

Epoch: 6| Step: 5
Training loss: 3.3927457332611084
Validation loss: 3.2190237045288086

Epoch: 6| Step: 6
Training loss: 3.113192558288574
Validation loss: 3.214281757672628

Epoch: 6| Step: 7
Training loss: 4.116734981536865
Validation loss: 3.2102848291397095

Epoch: 6| Step: 8
Training loss: 3.9200844764709473
Validation loss: 3.207009275754293

Epoch: 6| Step: 9
Training loss: 3.2525522708892822
Validation loss: 3.2032848993937173

Epoch: 6| Step: 10
Training loss: 2.6947059631347656
Validation loss: 3.198673645655314

Epoch: 6| Step: 11
Training loss: 2.932807207107544
Validation loss: 3.194836179415385

Epoch: 6| Step: 12
Training loss: 3.126267671585083
Validation loss: 3.190889358520508

Epoch: 6| Step: 13
Training loss: 3.5041110515594482
Validation loss: 3.1869048277537027

Epoch: 28| Step: 0
Training loss: 4.1199727058410645
Validation loss: 3.1829710404078164

Epoch: 6| Step: 1
Training loss: 3.365980625152588
Validation loss: 3.1789734760920205

Epoch: 6| Step: 2
Training loss: 2.8154194355010986
Validation loss: 3.1755895217259726

Epoch: 6| Step: 3
Training loss: 4.1510796546936035
Validation loss: 3.1702394485473633

Epoch: 6| Step: 4
Training loss: 3.715083122253418
Validation loss: 3.1655829747517905

Epoch: 6| Step: 5
Training loss: 3.4202284812927246
Validation loss: 3.1604964335759482

Epoch: 6| Step: 6
Training loss: 3.8305044174194336
Validation loss: 3.1556379000345864

Epoch: 6| Step: 7
Training loss: 2.9480419158935547
Validation loss: 3.151918649673462

Epoch: 6| Step: 8
Training loss: 3.081336259841919
Validation loss: 3.1478269894917807

Epoch: 6| Step: 9
Training loss: 4.231454849243164
Validation loss: 3.1444772481918335

Epoch: 6| Step: 10
Training loss: 3.322399616241455
Validation loss: 3.139062523841858

Epoch: 6| Step: 11
Training loss: 2.309535503387451
Validation loss: 3.136088490486145

Epoch: 6| Step: 12
Training loss: 2.808572769165039
Validation loss: 3.134729266166687

Epoch: 6| Step: 13
Training loss: 2.700939178466797
Validation loss: 3.1312224864959717

Epoch: 29| Step: 0
Training loss: 2.3636441230773926
Validation loss: 3.126198410987854

Epoch: 6| Step: 1
Training loss: 3.588646411895752
Validation loss: 3.1233291228612265

Epoch: 6| Step: 2
Training loss: 3.1898159980773926
Validation loss: 3.1198214292526245

Epoch: 6| Step: 3
Training loss: 4.101282119750977
Validation loss: 3.1156524817148843

Epoch: 6| Step: 4
Training loss: 3.4169206619262695
Validation loss: 3.1114478508631387

Epoch: 6| Step: 5
Training loss: 3.282209873199463
Validation loss: 3.107567230860392

Epoch: 6| Step: 6
Training loss: 4.077945709228516
Validation loss: 3.104354818662008

Epoch: 6| Step: 7
Training loss: 2.710442066192627
Validation loss: 3.100406368573507

Epoch: 6| Step: 8
Training loss: 3.068633556365967
Validation loss: 3.096542259057363

Epoch: 6| Step: 9
Training loss: 3.62229061126709
Validation loss: 3.0933835903803506

Epoch: 6| Step: 10
Training loss: 3.0118908882141113
Validation loss: 3.0897533893585205

Epoch: 6| Step: 11
Training loss: 3.6853718757629395
Validation loss: 3.0857903957366943

Epoch: 6| Step: 12
Training loss: 3.0252327919006348
Validation loss: 3.082471172014872

Epoch: 6| Step: 13
Training loss: 2.9389662742614746
Validation loss: 3.0789623260498047

Epoch: 30| Step: 0
Training loss: 3.506765365600586
Validation loss: 3.0757505098978677

Epoch: 6| Step: 1
Training loss: 2.95342755317688
Validation loss: 3.0723450978597007

Epoch: 6| Step: 2
Training loss: 2.4599640369415283
Validation loss: 3.068942983945211

Epoch: 6| Step: 3
Training loss: 3.2108688354492188
Validation loss: 3.065709710121155

Epoch: 6| Step: 4
Training loss: 2.2010717391967773
Validation loss: 3.0626516342163086

Epoch: 6| Step: 5
Training loss: 3.84559965133667
Validation loss: 3.059067209561666

Epoch: 6| Step: 6
Training loss: 3.457845449447632
Validation loss: 3.0560962359110513

Epoch: 6| Step: 7
Training loss: 3.3867533206939697
Validation loss: 3.0522907177607217

Epoch: 6| Step: 8
Training loss: 3.7747390270233154
Validation loss: 3.0487724939982095

Epoch: 6| Step: 9
Training loss: 3.6128251552581787
Validation loss: 3.044988433519999

Epoch: 6| Step: 10
Training loss: 4.029657363891602
Validation loss: 3.041464845339457

Epoch: 6| Step: 11
Training loss: 3.0808990001678467
Validation loss: 3.0378558238347373

Epoch: 6| Step: 12
Training loss: 3.4483754634857178
Validation loss: 3.0345741907755532

Epoch: 6| Step: 13
Training loss: 2.476626396179199
Validation loss: 3.0311519702275596

Epoch: 31| Step: 0
Training loss: 3.0203042030334473
Validation loss: 3.0282661517461142

Epoch: 6| Step: 1
Training loss: 2.5716910362243652
Validation loss: 3.0256489912668862

Epoch: 6| Step: 2
Training loss: 3.773386240005493
Validation loss: 3.0222591559092202

Epoch: 6| Step: 3
Training loss: 4.405540943145752
Validation loss: 3.019525090853373

Epoch: 6| Step: 4
Training loss: 2.8887898921966553
Validation loss: 3.01639993985494

Epoch: 6| Step: 5
Training loss: 3.19352388381958
Validation loss: 3.0128702322642007

Epoch: 6| Step: 6
Training loss: 3.318272113800049
Validation loss: 3.0098613103230796

Epoch: 6| Step: 7
Training loss: 2.479687213897705
Validation loss: 3.007166028022766

Epoch: 6| Step: 8
Training loss: 3.7521190643310547
Validation loss: 3.003766973813375

Epoch: 6| Step: 9
Training loss: 3.0692028999328613
Validation loss: 3.001005530357361

Epoch: 6| Step: 10
Training loss: 2.783703327178955
Validation loss: 2.997147043546041

Epoch: 6| Step: 11
Training loss: 3.1520068645477295
Validation loss: 2.994308829307556

Epoch: 6| Step: 12
Training loss: 3.3485753536224365
Validation loss: 2.990152279535929

Epoch: 6| Step: 13
Training loss: 3.057039737701416
Validation loss: 2.987559954325358

Epoch: 32| Step: 0
Training loss: 3.6940717697143555
Validation loss: 2.9837992191314697

Epoch: 6| Step: 1
Training loss: 2.6450157165527344
Validation loss: 2.9806788762410483

Epoch: 6| Step: 2
Training loss: 3.266833543777466
Validation loss: 2.977503776550293

Epoch: 6| Step: 3
Training loss: 3.5001072883605957
Validation loss: 2.9743037621180215

Epoch: 6| Step: 4
Training loss: 3.021493911743164
Validation loss: 2.9708162943522134

Epoch: 6| Step: 5
Training loss: 3.1594436168670654
Validation loss: 2.9676835934321084

Epoch: 6| Step: 6
Training loss: 3.322383403778076
Validation loss: 2.96494460105896

Epoch: 6| Step: 7
Training loss: 2.4665818214416504
Validation loss: 2.9622477690378823

Epoch: 6| Step: 8
Training loss: 3.374997138977051
Validation loss: 2.960154175758362

Epoch: 6| Step: 9
Training loss: 2.8323395252227783
Validation loss: 2.955862045288086

Epoch: 6| Step: 10
Training loss: 2.8036255836486816
Validation loss: 2.953817089398702

Epoch: 6| Step: 11
Training loss: 3.670327663421631
Validation loss: 2.9508432348569236

Epoch: 6| Step: 12
Training loss: 2.87846040725708
Validation loss: 2.9459778467814126

Epoch: 6| Step: 13
Training loss: 3.6187784671783447
Validation loss: 2.941767772038778

Epoch: 33| Step: 0
Training loss: 4.0659565925598145
Validation loss: 2.9389917850494385

Epoch: 6| Step: 1
Training loss: 3.9014792442321777
Validation loss: 2.935625990231832

Epoch: 6| Step: 2
Training loss: 3.0061097145080566
Validation loss: 2.932351311047872

Epoch: 6| Step: 3
Training loss: 2.812192678451538
Validation loss: 2.9290258089701333

Epoch: 6| Step: 4
Training loss: 3.6503477096557617
Validation loss: 2.9252081314722695

Epoch: 6| Step: 5
Training loss: 2.995239019393921
Validation loss: 2.9226367076238

Epoch: 6| Step: 6
Training loss: 3.4272913932800293
Validation loss: 2.919652064641317

Epoch: 6| Step: 7
Training loss: 3.357600212097168
Validation loss: 2.916664640108744

Epoch: 6| Step: 8
Training loss: 3.1752994060516357
Validation loss: 2.913485844930013

Epoch: 6| Step: 9
Training loss: 2.559650182723999
Validation loss: 2.9103751182556152

Epoch: 6| Step: 10
Training loss: 2.9198226928710938
Validation loss: 2.9075135389963784

Epoch: 6| Step: 11
Training loss: 2.5411465167999268
Validation loss: 2.903842329978943

Epoch: 6| Step: 12
Training loss: 2.664296865463257
Validation loss: 2.9003905852635703

Epoch: 6| Step: 13
Training loss: 2.6297900676727295
Validation loss: 2.897007783253988

Epoch: 34| Step: 0
Training loss: 3.028563976287842
Validation loss: 2.8943052689234414

Epoch: 6| Step: 1
Training loss: 3.3225479125976562
Validation loss: 2.890954335530599

Epoch: 6| Step: 2
Training loss: 2.6442904472351074
Validation loss: 2.8882270654042563

Epoch: 6| Step: 3
Training loss: 2.6933846473693848
Validation loss: 2.885110100110372

Epoch: 6| Step: 4
Training loss: 3.038750410079956
Validation loss: 2.884256919225057

Epoch: 6| Step: 5
Training loss: 2.2474474906921387
Validation loss: 2.87948207060496

Epoch: 6| Step: 6
Training loss: 3.1808414459228516
Validation loss: 2.878212054570516

Epoch: 6| Step: 7
Training loss: 3.771122932434082
Validation loss: 2.87877349058787

Epoch: 6| Step: 8
Training loss: 2.834078311920166
Validation loss: 2.8759348392486572

Epoch: 6| Step: 9
Training loss: 3.3943724632263184
Validation loss: 2.8689302603403726

Epoch: 6| Step: 10
Training loss: 2.554940700531006
Validation loss: 2.8662719329198203

Epoch: 6| Step: 11
Training loss: 2.939500570297241
Validation loss: 2.8634353081385293

Epoch: 6| Step: 12
Training loss: 3.9646332263946533
Validation loss: 2.8594287633895874

Epoch: 6| Step: 13
Training loss: 3.528898000717163
Validation loss: 2.857491970062256

Epoch: 35| Step: 0
Training loss: 2.814401388168335
Validation loss: 2.8550087213516235

Epoch: 6| Step: 1
Training loss: 3.22538423538208
Validation loss: 2.8508344888687134

Epoch: 6| Step: 2
Training loss: 3.6433048248291016
Validation loss: 2.847205718358358

Epoch: 6| Step: 3
Training loss: 3.1550116539001465
Validation loss: 2.843759854634603

Epoch: 6| Step: 4
Training loss: 2.3210983276367188
Validation loss: 2.840539534886678

Epoch: 6| Step: 5
Training loss: 3.361017942428589
Validation loss: 2.8368855714797974

Epoch: 6| Step: 6
Training loss: 2.670085906982422
Validation loss: 2.8335934480031333

Epoch: 6| Step: 7
Training loss: 2.1756694316864014
Validation loss: 2.8308351039886475

Epoch: 6| Step: 8
Training loss: 3.2626969814300537
Validation loss: 2.8289023637771606

Epoch: 6| Step: 9
Training loss: 3.501678943634033
Validation loss: 2.8273783524831138

Epoch: 6| Step: 10
Training loss: 3.056702136993408
Validation loss: 2.8232187628746033

Epoch: 6| Step: 11
Training loss: 3.524458646774292
Validation loss: 2.820117155710856

Epoch: 6| Step: 12
Training loss: 3.182662010192871
Validation loss: 2.8184243043263755

Epoch: 6| Step: 13
Training loss: 2.728811264038086
Validation loss: 2.8153600692749023

Epoch: 36| Step: 0
Training loss: 2.4681200981140137
Validation loss: 2.811846295992533

Epoch: 6| Step: 1
Training loss: 2.840397596359253
Validation loss: 2.809236208597819

Epoch: 6| Step: 2
Training loss: 3.387908697128296
Validation loss: 2.805206576983134

Epoch: 6| Step: 3
Training loss: 2.8743185997009277
Validation loss: 2.804383178551992

Epoch: 6| Step: 4
Training loss: 2.6711556911468506
Validation loss: 2.8005144596099854

Epoch: 6| Step: 5
Training loss: 3.3757247924804688
Validation loss: 2.7990612586339316

Epoch: 6| Step: 6
Training loss: 3.0386829376220703
Validation loss: 2.795007507006327

Epoch: 6| Step: 7
Training loss: 2.266430377960205
Validation loss: 2.79322357972463

Epoch: 6| Step: 8
Training loss: 2.901315212249756
Validation loss: 2.7902660767237344

Epoch: 6| Step: 9
Training loss: 3.733071804046631
Validation loss: 2.7877978881200156

Epoch: 6| Step: 10
Training loss: 4.233991622924805
Validation loss: 2.7835645278294883

Epoch: 6| Step: 11
Training loss: 2.9214274883270264
Validation loss: 2.782567024230957

Epoch: 6| Step: 12
Training loss: 2.6240861415863037
Validation loss: 2.781241536140442

Epoch: 6| Step: 13
Training loss: 2.7231605052948
Validation loss: 2.783077597618103

Epoch: 37| Step: 0
Training loss: 2.905803680419922
Validation loss: 2.7833202282587686

Epoch: 6| Step: 1
Training loss: 2.5079121589660645
Validation loss: 2.774436434110006

Epoch: 6| Step: 2
Training loss: 2.9926843643188477
Validation loss: 2.7689611514409385

Epoch: 6| Step: 3
Training loss: 3.1264071464538574
Validation loss: 2.763079126675924

Epoch: 6| Step: 4
Training loss: 2.881528377532959
Validation loss: 2.7613481283187866

Epoch: 6| Step: 5
Training loss: 3.3800463676452637
Validation loss: 2.7609510819117227

Epoch: 6| Step: 6
Training loss: 3.247762680053711
Validation loss: 2.7578674952189126

Epoch: 6| Step: 7
Training loss: 2.732724905014038
Validation loss: 2.755700469017029

Epoch: 6| Step: 8
Training loss: 2.709620952606201
Validation loss: 2.7528283993403115

Epoch: 6| Step: 9
Training loss: 3.485299825668335
Validation loss: 2.7496692736943564

Epoch: 6| Step: 10
Training loss: 2.5191025733947754
Validation loss: 2.7457765340805054

Epoch: 6| Step: 11
Training loss: 2.8909192085266113
Validation loss: 2.742145617802938

Epoch: 6| Step: 12
Training loss: 3.5181891918182373
Validation loss: 2.7383657693862915

Epoch: 6| Step: 13
Training loss: 2.629546642303467
Validation loss: 2.736019810040792

Epoch: 38| Step: 0
Training loss: 4.151060104370117
Validation loss: 2.7331844568252563

Epoch: 6| Step: 1
Training loss: 2.897822856903076
Validation loss: 2.7307477394739785

Epoch: 6| Step: 2
Training loss: 3.165196418762207
Validation loss: 2.728571613629659

Epoch: 6| Step: 3
Training loss: 2.82073974609375
Validation loss: 2.7237348159154258

Epoch: 6| Step: 4
Training loss: 3.2217931747436523
Validation loss: 2.7251266638437905

Epoch: 6| Step: 5
Training loss: 2.904506206512451
Validation loss: 2.7219502925872803

Epoch: 6| Step: 6
Training loss: 3.8871138095855713
Validation loss: 2.7158493598302207

Epoch: 6| Step: 7
Training loss: 2.9610989093780518
Validation loss: 2.713724215825399

Epoch: 6| Step: 8
Training loss: 1.9275786876678467
Validation loss: 2.7121148109436035

Epoch: 6| Step: 9
Training loss: 3.0457777976989746
Validation loss: 2.7085295915603638

Epoch: 6| Step: 10
Training loss: 2.5416979789733887
Validation loss: 2.707615693410238

Epoch: 6| Step: 11
Training loss: 2.727931499481201
Validation loss: 2.703200022379557

Epoch: 6| Step: 12
Training loss: 2.2505414485931396
Validation loss: 2.7021213372548423

Epoch: 6| Step: 13
Training loss: 2.4052915573120117
Validation loss: 2.697608311971029

Epoch: 39| Step: 0
Training loss: 2.9978268146514893
Validation loss: 2.698557138442993

Epoch: 6| Step: 1
Training loss: 2.0928659439086914
Validation loss: 2.693806290626526

Epoch: 6| Step: 2
Training loss: 2.767500400543213
Validation loss: 2.690452297528585

Epoch: 6| Step: 3
Training loss: 2.8562965393066406
Validation loss: 2.6869428952534995

Epoch: 6| Step: 4
Training loss: 3.188098907470703
Validation loss: 2.683576504389445

Epoch: 6| Step: 5
Training loss: 2.5498952865600586
Validation loss: 2.6821358601252236

Epoch: 6| Step: 6
Training loss: 2.959953784942627
Validation loss: 2.6986773014068604

Epoch: 6| Step: 7
Training loss: 2.7862155437469482
Validation loss: 2.7239154974619546

Epoch: 6| Step: 8
Training loss: 2.812683582305908
Validation loss: 2.68784765402476

Epoch: 6| Step: 9
Training loss: 3.1100668907165527
Validation loss: 2.671592950820923

Epoch: 6| Step: 10
Training loss: 3.1522655487060547
Validation loss: 2.668111801147461

Epoch: 6| Step: 11
Training loss: 2.9923062324523926
Validation loss: 2.6720351775487265

Epoch: 6| Step: 12
Training loss: 3.380218029022217
Validation loss: 2.6932156880696616

Epoch: 6| Step: 13
Training loss: 2.8815994262695312
Validation loss: 2.687217871348063

Epoch: 40| Step: 0
Training loss: 2.8473103046417236
Validation loss: 2.6604034900665283

Epoch: 6| Step: 1
Training loss: 3.071413993835449
Validation loss: 2.655263344446818

Epoch: 6| Step: 2
Training loss: 2.896214723587036
Validation loss: 2.6521894534428916

Epoch: 6| Step: 3
Training loss: 2.6452183723449707
Validation loss: 2.651801268259684

Epoch: 6| Step: 4
Training loss: 2.6580591201782227
Validation loss: 2.6547305583953857

Epoch: 6| Step: 5
Training loss: 3.1371936798095703
Validation loss: 2.659384290377299

Epoch: 6| Step: 6
Training loss: 2.494445323944092
Validation loss: 2.654413342475891

Epoch: 6| Step: 7
Training loss: 2.889395236968994
Validation loss: 2.6456781228383384

Epoch: 6| Step: 8
Training loss: 2.574592113494873
Validation loss: 2.642586588859558

Epoch: 6| Step: 9
Training loss: 2.572756290435791
Validation loss: 2.636927088101705

Epoch: 6| Step: 10
Training loss: 3.1307897567749023
Validation loss: 2.6328993240992227

Epoch: 6| Step: 11
Training loss: 3.4410953521728516
Validation loss: 2.629276911417643

Epoch: 6| Step: 12
Training loss: 3.0701327323913574
Validation loss: 2.623983462651571

Epoch: 6| Step: 13
Training loss: 2.408428192138672
Validation loss: 2.621015707651774

Epoch: 41| Step: 0
Training loss: 2.6663403511047363
Validation loss: 2.6190458138783774

Epoch: 6| Step: 1
Training loss: 2.521183490753174
Validation loss: 2.6159965991973877

Epoch: 6| Step: 2
Training loss: 3.0241177082061768
Validation loss: 2.614041248957316

Epoch: 6| Step: 3
Training loss: 2.661214828491211
Validation loss: 2.6142489314079285

Epoch: 6| Step: 4
Training loss: 2.724733352661133
Validation loss: 2.6081629196802774

Epoch: 6| Step: 5
Training loss: 2.624164342880249
Validation loss: 2.6078238487243652

Epoch: 6| Step: 6
Training loss: 3.6439285278320312
Validation loss: 2.6057408253351846

Epoch: 6| Step: 7
Training loss: 2.2876205444335938
Validation loss: 2.6003806591033936

Epoch: 6| Step: 8
Training loss: 2.7639307975769043
Validation loss: 2.596822222073873

Epoch: 6| Step: 9
Training loss: 2.7595691680908203
Validation loss: 2.594054341316223

Epoch: 6| Step: 10
Training loss: 3.165809154510498
Validation loss: 2.5917371114095054

Epoch: 6| Step: 11
Training loss: 2.987886428833008
Validation loss: 2.5892921487490335

Epoch: 6| Step: 12
Training loss: 3.083552598953247
Validation loss: 2.5865993102391562

Epoch: 6| Step: 13
Training loss: 2.2890496253967285
Validation loss: 2.584028681119283

Epoch: 42| Step: 0
Training loss: 3.0851891040802
Validation loss: 2.580546418825785

Epoch: 6| Step: 1
Training loss: 2.387387275695801
Validation loss: 2.5781471331914267

Epoch: 6| Step: 2
Training loss: 3.151073932647705
Validation loss: 2.5722020864486694

Epoch: 6| Step: 3
Training loss: 2.578925132751465
Validation loss: 2.571098963419596

Epoch: 6| Step: 4
Training loss: 2.4435243606567383
Validation loss: 2.5685197909673056

Epoch: 6| Step: 5
Training loss: 2.990663528442383
Validation loss: 2.56413068373998

Epoch: 6| Step: 6
Training loss: 2.927206516265869
Validation loss: 2.5630635817845664

Epoch: 6| Step: 7
Training loss: 3.1273193359375
Validation loss: 2.5609525044759116

Epoch: 6| Step: 8
Training loss: 2.9567298889160156
Validation loss: 2.557166576385498

Epoch: 6| Step: 9
Training loss: 2.4319117069244385
Validation loss: 2.557674209276835

Epoch: 6| Step: 10
Training loss: 2.5303726196289062
Validation loss: 2.552667737007141

Epoch: 6| Step: 11
Training loss: 2.218165636062622
Validation loss: 2.552388588587443

Epoch: 6| Step: 12
Training loss: 2.7969861030578613
Validation loss: 2.5489347775777182

Epoch: 6| Step: 13
Training loss: 3.0274252891540527
Validation loss: 2.54722261428833

Epoch: 43| Step: 0
Training loss: 2.613004684448242
Validation loss: 2.5411318937937417

Epoch: 6| Step: 1
Training loss: 2.859314203262329
Validation loss: 2.5370708306630454

Epoch: 6| Step: 2
Training loss: 2.458496332168579
Validation loss: 2.5340250730514526

Epoch: 6| Step: 3
Training loss: 3.4904613494873047
Validation loss: 2.534359335899353

Epoch: 6| Step: 4
Training loss: 2.8070709705352783
Validation loss: 2.5304569800694785

Epoch: 6| Step: 5
Training loss: 2.463254690170288
Validation loss: 2.526737074057261

Epoch: 6| Step: 6
Training loss: 2.9253106117248535
Validation loss: 2.526723583539327

Epoch: 6| Step: 7
Training loss: 2.161381721496582
Validation loss: 2.522191047668457

Epoch: 6| Step: 8
Training loss: 3.5721676349639893
Validation loss: 2.5188657442728677

Epoch: 6| Step: 9
Training loss: 2.460387945175171
Validation loss: 2.516379793485006

Epoch: 6| Step: 10
Training loss: 2.6621785163879395
Validation loss: 2.5132826964060464

Epoch: 6| Step: 11
Training loss: 2.5831096172332764
Validation loss: 2.509789307912191

Epoch: 6| Step: 12
Training loss: 2.5529887676239014
Validation loss: 2.508019049962362

Epoch: 6| Step: 13
Training loss: 2.524716854095459
Validation loss: 2.5016117095947266

Epoch: 44| Step: 0
Training loss: 2.7747790813446045
Validation loss: 2.502440611521403

Epoch: 6| Step: 1
Training loss: 2.939377784729004
Validation loss: 2.50117035706838

Epoch: 6| Step: 2
Training loss: 2.6187965869903564
Validation loss: 2.495368719100952

Epoch: 6| Step: 3
Training loss: 2.8550219535827637
Validation loss: 2.4971084197362265

Epoch: 6| Step: 4
Training loss: 3.188633441925049
Validation loss: 2.5012876192728677

Epoch: 6| Step: 5
Training loss: 1.9769785404205322
Validation loss: 2.4975784619649253

Epoch: 6| Step: 6
Training loss: 2.6904497146606445
Validation loss: 2.491477052370707

Epoch: 6| Step: 7
Training loss: 2.6982030868530273
Validation loss: 2.493607481320699

Epoch: 6| Step: 8
Training loss: 2.599064588546753
Validation loss: 2.4868362744649253

Epoch: 6| Step: 9
Training loss: 2.4381937980651855
Validation loss: 2.4812134504318237

Epoch: 6| Step: 10
Training loss: 2.5467262268066406
Validation loss: 2.4777262806892395

Epoch: 6| Step: 11
Training loss: 2.250735282897949
Validation loss: 2.4751134514808655

Epoch: 6| Step: 12
Training loss: 3.1164791584014893
Validation loss: 2.475104808807373

Epoch: 6| Step: 13
Training loss: 2.7926690578460693
Validation loss: 2.473269065221151

Epoch: 45| Step: 0
Training loss: 2.4132535457611084
Validation loss: 2.4718327124913535

Epoch: 6| Step: 1
Training loss: 2.2409238815307617
Validation loss: 2.4718841314315796

Epoch: 6| Step: 2
Training loss: 2.9284632205963135
Validation loss: 2.4713579018910727

Epoch: 6| Step: 3
Training loss: 2.942218065261841
Validation loss: 2.467361330986023

Epoch: 6| Step: 4
Training loss: 3.6199498176574707
Validation loss: 2.464354077974955

Epoch: 6| Step: 5
Training loss: 2.5285658836364746
Validation loss: 2.460781693458557

Epoch: 6| Step: 6
Training loss: 2.47080397605896
Validation loss: 2.4554127852121987

Epoch: 6| Step: 7
Training loss: 2.168339490890503
Validation loss: 2.4523661732673645

Epoch: 6| Step: 8
Training loss: 2.136817455291748
Validation loss: 2.44628369808197

Epoch: 6| Step: 9
Training loss: 2.3421592712402344
Validation loss: 2.44348798195521

Epoch: 6| Step: 10
Training loss: 2.814361572265625
Validation loss: 2.4416695833206177

Epoch: 6| Step: 11
Training loss: 2.7396438121795654
Validation loss: 2.437916954358419

Epoch: 6| Step: 12
Training loss: 3.1400740146636963
Validation loss: 2.435175140698751

Epoch: 6| Step: 13
Training loss: 2.5681235790252686
Validation loss: 2.430784602959951

Epoch: 46| Step: 0
Training loss: 3.0635461807250977
Validation loss: 2.433930277824402

Epoch: 6| Step: 1
Training loss: 2.9026551246643066
Validation loss: 2.4317055145899453

Epoch: 6| Step: 2
Training loss: 1.7169092893600464
Validation loss: 2.426640431086222

Epoch: 6| Step: 3
Training loss: 2.509979724884033
Validation loss: 2.4227751096089682

Epoch: 6| Step: 4
Training loss: 2.149907350540161
Validation loss: 2.4193105697631836

Epoch: 6| Step: 5
Training loss: 2.1393065452575684
Validation loss: 2.416935463746389

Epoch: 6| Step: 6
Training loss: 3.4063961505889893
Validation loss: 2.4158748785654702

Epoch: 6| Step: 7
Training loss: 3.4549002647399902
Validation loss: 2.4106787045796714

Epoch: 6| Step: 8
Training loss: 2.0795183181762695
Validation loss: 2.4096368153889975

Epoch: 6| Step: 9
Training loss: 2.1788957118988037
Validation loss: 2.407105326652527

Epoch: 6| Step: 10
Training loss: 3.0019004344940186
Validation loss: 2.4050679206848145

Epoch: 6| Step: 11
Training loss: 2.4062130451202393
Validation loss: 2.4038681785265603

Epoch: 6| Step: 12
Training loss: 2.754086494445801
Validation loss: 2.400997002919515

Epoch: 6| Step: 13
Training loss: 2.708697557449341
Validation loss: 2.4006694555282593

Epoch: 47| Step: 0
Training loss: 2.461463451385498
Validation loss: 2.398153781890869

Epoch: 6| Step: 1
Training loss: 2.7282021045684814
Validation loss: 2.392756541570028

Epoch: 6| Step: 2
Training loss: 2.3148155212402344
Validation loss: 2.389987031618754

Epoch: 6| Step: 3
Training loss: 2.248091459274292
Validation loss: 2.3908098936080933

Epoch: 6| Step: 4
Training loss: 2.8597795963287354
Validation loss: 2.39160426457723

Epoch: 6| Step: 5
Training loss: 2.4729361534118652
Validation loss: 2.3998449643452964

Epoch: 6| Step: 6
Training loss: 2.3496172428131104
Validation loss: 2.3842315673828125

Epoch: 6| Step: 7
Training loss: 2.7205817699432373
Validation loss: 2.383110523223877

Epoch: 6| Step: 8
Training loss: 2.7144899368286133
Validation loss: 2.376262644926707

Epoch: 6| Step: 9
Training loss: 2.5972402095794678
Validation loss: 2.375152111053467

Epoch: 6| Step: 10
Training loss: 3.2148070335388184
Validation loss: 2.375544548034668

Epoch: 6| Step: 11
Training loss: 2.3492603302001953
Validation loss: 2.3729437987009683

Epoch: 6| Step: 12
Training loss: 2.14872670173645
Validation loss: 2.3707204262415567

Epoch: 6| Step: 13
Training loss: 2.800333023071289
Validation loss: 2.370065371195475

Epoch: 48| Step: 0
Training loss: 3.1708035469055176
Validation loss: 2.3732945124308267

Epoch: 6| Step: 1
Training loss: 2.6330227851867676
Validation loss: 2.37162184715271

Epoch: 6| Step: 2
Training loss: 2.543402671813965
Validation loss: 2.3639459212621055

Epoch: 6| Step: 3
Training loss: 2.4184327125549316
Validation loss: 2.364129424095154

Epoch: 6| Step: 4
Training loss: 1.8191412687301636
Validation loss: 2.357215325037638

Epoch: 6| Step: 5
Training loss: 3.0478503704071045
Validation loss: 2.3725318113962808

Epoch: 6| Step: 6
Training loss: 2.2081105709075928
Validation loss: 2.3747213085492453

Epoch: 6| Step: 7
Training loss: 2.3180503845214844
Validation loss: 2.379571557044983

Epoch: 6| Step: 8
Training loss: 3.005829334259033
Validation loss: 2.359491984049479

Epoch: 6| Step: 9
Training loss: 2.7825465202331543
Validation loss: 2.3429410258928933

Epoch: 6| Step: 10
Training loss: 2.3020925521850586
Validation loss: 2.3392575780550637

Epoch: 6| Step: 11
Training loss: 1.8203810453414917
Validation loss: 2.3445162773132324

Epoch: 6| Step: 12
Training loss: 3.287306308746338
Validation loss: 2.35106768210729

Epoch: 6| Step: 13
Training loss: 2.1331613063812256
Validation loss: 2.362943251927694

Epoch: 49| Step: 0
Training loss: 2.4009156227111816
Validation loss: 2.365976393222809

Epoch: 6| Step: 1
Training loss: 2.0371718406677246
Validation loss: 2.3624903758366904

Epoch: 6| Step: 2
Training loss: 2.7296125888824463
Validation loss: 2.3519952297210693

Epoch: 6| Step: 3
Training loss: 3.0605826377868652
Validation loss: 2.342211604118347

Epoch: 6| Step: 4
Training loss: 1.6247456073760986
Validation loss: 2.340549031893412

Epoch: 6| Step: 5
Training loss: 2.903871536254883
Validation loss: 2.3351862033208213

Epoch: 6| Step: 6
Training loss: 1.9601320028305054
Validation loss: 2.332827866077423

Epoch: 6| Step: 7
Training loss: 2.7484781742095947
Validation loss: 2.324793497721354

Epoch: 6| Step: 8
Training loss: 2.329855442047119
Validation loss: 2.3209736545880637

Epoch: 6| Step: 9
Training loss: 3.091648578643799
Validation loss: 2.3158835768699646

Epoch: 6| Step: 10
Training loss: 3.211777925491333
Validation loss: 2.312860608100891

Epoch: 6| Step: 11
Training loss: 2.4339494705200195
Validation loss: 2.309545656045278

Epoch: 6| Step: 12
Training loss: 2.0931010246276855
Validation loss: 2.3063051104545593

Epoch: 6| Step: 13
Training loss: 2.514059066772461
Validation loss: 2.306318700313568

Epoch: 50| Step: 0
Training loss: 2.5450470447540283
Validation loss: 2.303543984889984

Epoch: 6| Step: 1
Training loss: 2.5786328315734863
Validation loss: 2.303063372770945

Epoch: 6| Step: 2
Training loss: 3.0086798667907715
Validation loss: 2.304725090662638

Epoch: 6| Step: 3
Training loss: 2.266824245452881
Validation loss: 2.303005854288737

Epoch: 6| Step: 4
Training loss: 3.09405517578125
Validation loss: 2.297427256902059

Epoch: 6| Step: 5
Training loss: 2.756229877471924
Validation loss: 2.2979756196339927

Epoch: 6| Step: 6
Training loss: 2.1563773155212402
Validation loss: 2.2950450579325357

Epoch: 6| Step: 7
Training loss: 1.6470775604248047
Validation loss: 2.2884693145751953

Epoch: 6| Step: 8
Training loss: 2.0195703506469727
Validation loss: 2.287824193636576

Epoch: 6| Step: 9
Training loss: 3.1461830139160156
Validation loss: 2.289859632651011

Epoch: 6| Step: 10
Training loss: 2.278306722640991
Validation loss: 2.2876970370610556

Epoch: 6| Step: 11
Training loss: 2.5186259746551514
Validation loss: 2.2786938548088074

Epoch: 6| Step: 12
Training loss: 2.39047908782959
Validation loss: 2.276567002137502

Epoch: 6| Step: 13
Training loss: 2.0875585079193115
Validation loss: 2.277680814266205

Epoch: 51| Step: 0
Training loss: 2.2762577533721924
Validation loss: 2.2748047709465027

Epoch: 6| Step: 1
Training loss: 2.5549540519714355
Validation loss: 2.2713034550348916

Epoch: 6| Step: 2
Training loss: 2.9481098651885986
Validation loss: 2.270746648311615

Epoch: 6| Step: 3
Training loss: 2.6591711044311523
Validation loss: 2.269979238510132

Epoch: 6| Step: 4
Training loss: 2.7955269813537598
Validation loss: 2.2680935064951577

Epoch: 6| Step: 5
Training loss: 2.713444232940674
Validation loss: 2.267277479171753

Epoch: 6| Step: 6
Training loss: 2.26127552986145
Validation loss: 2.267077883084615

Epoch: 6| Step: 7
Training loss: 1.6551854610443115
Validation loss: 2.2613108158111572

Epoch: 6| Step: 8
Training loss: 2.452877998352051
Validation loss: 2.26062403122584

Epoch: 6| Step: 9
Training loss: 2.3683643341064453
Validation loss: 2.257876714070638

Epoch: 6| Step: 10
Training loss: 2.846404790878296
Validation loss: 2.2551322182019553

Epoch: 6| Step: 11
Training loss: 2.1152191162109375
Validation loss: 2.2556868195533752

Epoch: 6| Step: 12
Training loss: 2.181649923324585
Validation loss: 2.252432346343994

Epoch: 6| Step: 13
Training loss: 2.17905592918396
Validation loss: 2.245170215765635

Epoch: 52| Step: 0
Training loss: 2.8807177543640137
Validation loss: 2.2434240778287253

Epoch: 6| Step: 1
Training loss: 2.699025869369507
Validation loss: 2.241470734278361

Epoch: 6| Step: 2
Training loss: 2.0419235229492188
Validation loss: 2.2377444903055825

Epoch: 6| Step: 3
Training loss: 1.6281590461730957
Validation loss: 2.2334455649058023

Epoch: 6| Step: 4
Training loss: 2.6767778396606445
Validation loss: 2.230508248011271

Epoch: 6| Step: 5
Training loss: 2.642000198364258
Validation loss: 2.227049926916758

Epoch: 6| Step: 6
Training loss: 2.134385585784912
Validation loss: 2.221904476483663

Epoch: 6| Step: 7
Training loss: 2.508251428604126
Validation loss: 2.2220218976338706

Epoch: 6| Step: 8
Training loss: 2.5725226402282715
Validation loss: 2.2219319343566895

Epoch: 6| Step: 9
Training loss: 2.1530747413635254
Validation loss: 2.217200299104055

Epoch: 6| Step: 10
Training loss: 2.1800389289855957
Validation loss: 2.216442286968231

Epoch: 6| Step: 11
Training loss: 2.719409465789795
Validation loss: 2.214766482512156

Epoch: 6| Step: 12
Training loss: 2.219454288482666
Validation loss: 2.215450326601664

Epoch: 6| Step: 13
Training loss: 2.30490779876709
Validation loss: 2.215889016787211

Epoch: 53| Step: 0
Training loss: 2.7227628231048584
Validation loss: 2.2121981183687844

Epoch: 6| Step: 1
Training loss: 2.083677291870117
Validation loss: 2.2215649286905923

Epoch: 6| Step: 2
Training loss: 2.730030059814453
Validation loss: 2.2430770794550576

Epoch: 6| Step: 3
Training loss: 2.716275215148926
Validation loss: 2.26592355966568

Epoch: 6| Step: 4
Training loss: 2.718757152557373
Validation loss: 2.231295963128408

Epoch: 6| Step: 5
Training loss: 1.8117523193359375
Validation loss: 2.19912858804067

Epoch: 6| Step: 6
Training loss: 2.221186637878418
Validation loss: 2.2011167208353677

Epoch: 6| Step: 7
Training loss: 1.4814460277557373
Validation loss: 2.202639619509379

Epoch: 6| Step: 8
Training loss: 2.2703747749328613
Validation loss: 2.2028871178627014

Epoch: 6| Step: 9
Training loss: 1.9818531274795532
Validation loss: 2.201987624168396

Epoch: 6| Step: 10
Training loss: 2.857326030731201
Validation loss: 2.2081539233525596

Epoch: 6| Step: 11
Training loss: 2.0796573162078857
Validation loss: 2.208831528822581

Epoch: 6| Step: 12
Training loss: 2.9998507499694824
Validation loss: 2.20667827129364

Epoch: 6| Step: 13
Training loss: 2.4623045921325684
Validation loss: 2.2068387468655906

Epoch: 54| Step: 0
Training loss: 2.695574998855591
Validation loss: 2.207006653149923

Epoch: 6| Step: 1
Training loss: 2.059674024581909
Validation loss: 2.2003437678019204

Epoch: 6| Step: 2
Training loss: 2.117366313934326
Validation loss: 2.194701095422109

Epoch: 6| Step: 3
Training loss: 2.3647449016571045
Validation loss: 2.1963805556297302

Epoch: 6| Step: 4
Training loss: 2.081165075302124
Validation loss: 2.1902312437693277

Epoch: 6| Step: 5
Training loss: 2.258078098297119
Validation loss: 2.18775882323583

Epoch: 6| Step: 6
Training loss: 2.7038931846618652
Validation loss: 2.187898814678192

Epoch: 6| Step: 7
Training loss: 1.8993903398513794
Validation loss: 2.1812041799227395

Epoch: 6| Step: 8
Training loss: 2.1447110176086426
Validation loss: 2.1807929476102195

Epoch: 6| Step: 9
Training loss: 2.2728288173675537
Validation loss: 2.178511122862498

Epoch: 6| Step: 10
Training loss: 2.348233699798584
Validation loss: 2.1789933244387307

Epoch: 6| Step: 11
Training loss: 2.884582042694092
Validation loss: 2.181024710337321

Epoch: 6| Step: 12
Training loss: 2.310757637023926
Validation loss: 2.1760730743408203

Epoch: 6| Step: 13
Training loss: 2.7743043899536133
Validation loss: 2.176521976788839

Epoch: 55| Step: 0
Training loss: 2.1902289390563965
Validation loss: 2.1788462003072104

Epoch: 6| Step: 1
Training loss: 1.9455666542053223
Validation loss: 2.1737335324287415

Epoch: 6| Step: 2
Training loss: 1.9466524124145508
Validation loss: 2.174905240535736

Epoch: 6| Step: 3
Training loss: 2.3310816287994385
Validation loss: 2.177942673365275

Epoch: 6| Step: 4
Training loss: 3.1353297233581543
Validation loss: 2.186050534248352

Epoch: 6| Step: 5
Training loss: 1.9994065761566162
Validation loss: 2.175058960914612

Epoch: 6| Step: 6
Training loss: 2.0378494262695312
Validation loss: 2.166789432366689

Epoch: 6| Step: 7
Training loss: 2.413167953491211
Validation loss: 2.155856649080912

Epoch: 6| Step: 8
Training loss: 2.689756393432617
Validation loss: 2.1550320585568747

Epoch: 6| Step: 9
Training loss: 2.091398000717163
Validation loss: 2.1588341991106668

Epoch: 6| Step: 10
Training loss: 2.2409815788269043
Validation loss: 2.156486928462982

Epoch: 6| Step: 11
Training loss: 2.6338391304016113
Validation loss: 2.1597273548444114

Epoch: 6| Step: 12
Training loss: 2.44397234916687
Validation loss: 2.1616709232330322

Epoch: 6| Step: 13
Training loss: 2.4987449645996094
Validation loss: 2.168343742688497

Epoch: 56| Step: 0
Training loss: 2.6881966590881348
Validation loss: 2.174245814482371

Epoch: 6| Step: 1
Training loss: 2.423466920852661
Validation loss: 2.1746015350023904

Epoch: 6| Step: 2
Training loss: 1.7542576789855957
Validation loss: 2.17653626203537

Epoch: 6| Step: 3
Training loss: 2.6082346439361572
Validation loss: 2.175156315167745

Epoch: 6| Step: 4
Training loss: 1.8269062042236328
Validation loss: 2.1724952260653176

Epoch: 6| Step: 5
Training loss: 2.1065423488616943
Validation loss: 2.165117104848226

Epoch: 6| Step: 6
Training loss: 2.9127326011657715
Validation loss: 2.1530678272247314

Epoch: 6| Step: 7
Training loss: 1.7437593936920166
Validation loss: 2.150478780269623

Epoch: 6| Step: 8
Training loss: 1.881608247756958
Validation loss: 2.1451451579729715

Epoch: 6| Step: 9
Training loss: 3.1359643936157227
Validation loss: 2.148541251818339

Epoch: 6| Step: 10
Training loss: 2.4135138988494873
Validation loss: 2.1431346337000527

Epoch: 6| Step: 11
Training loss: 2.2186264991760254
Validation loss: 2.13944806655248

Epoch: 6| Step: 12
Training loss: 2.6827144622802734
Validation loss: 2.136842727661133

Epoch: 6| Step: 13
Training loss: 2.054804801940918
Validation loss: 2.1434484322865806

Epoch: 57| Step: 0
Training loss: 2.718336343765259
Validation loss: 2.1562710801760354

Epoch: 6| Step: 1
Training loss: 2.459750175476074
Validation loss: 2.1419979333877563

Epoch: 6| Step: 2
Training loss: 1.5807228088378906
Validation loss: 2.150251487890879

Epoch: 6| Step: 3
Training loss: 2.4264774322509766
Validation loss: 2.147938052813212

Epoch: 6| Step: 4
Training loss: 2.577815055847168
Validation loss: 2.141583720842997

Epoch: 6| Step: 5
Training loss: 2.1459856033325195
Validation loss: 2.1373899579048157

Epoch: 6| Step: 6
Training loss: 2.492345094680786
Validation loss: 2.1372728745142617

Epoch: 6| Step: 7
Training loss: 1.7887158393859863
Validation loss: 2.131795028845469

Epoch: 6| Step: 8
Training loss: 2.285869598388672
Validation loss: 2.1273628870646157

Epoch: 6| Step: 9
Training loss: 2.6549317836761475
Validation loss: 2.1283313433329263

Epoch: 6| Step: 10
Training loss: 2.400787830352783
Validation loss: 2.1262956062952676

Epoch: 6| Step: 11
Training loss: 1.9005259275436401
Validation loss: 2.1212969422340393

Epoch: 6| Step: 12
Training loss: 2.36393666267395
Validation loss: 2.122241040070852

Epoch: 6| Step: 13
Training loss: 2.4512810707092285
Validation loss: 2.118714193503062

Epoch: 58| Step: 0
Training loss: 2.5380523204803467
Validation loss: 2.121327579021454

Epoch: 6| Step: 1
Training loss: 1.8230997323989868
Validation loss: 2.1206347942352295

Epoch: 6| Step: 2
Training loss: 2.3213253021240234
Validation loss: 2.1206711530685425

Epoch: 6| Step: 3
Training loss: 2.907804489135742
Validation loss: 2.1168951789538064

Epoch: 6| Step: 4
Training loss: 2.305473804473877
Validation loss: 2.117521504561106

Epoch: 6| Step: 5
Training loss: 2.5945003032684326
Validation loss: 2.11883415778478

Epoch: 6| Step: 6
Training loss: 2.3752009868621826
Validation loss: 2.1125665307044983

Epoch: 6| Step: 7
Training loss: 2.2212066650390625
Validation loss: 2.114558478196462

Epoch: 6| Step: 8
Training loss: 2.434511661529541
Validation loss: 2.1090232531229653

Epoch: 6| Step: 9
Training loss: 2.1563384532928467
Validation loss: 2.1033722162246704

Epoch: 6| Step: 10
Training loss: 2.2887654304504395
Validation loss: 2.1087639729181924

Epoch: 6| Step: 11
Training loss: 1.970207929611206
Validation loss: 2.1058156490325928

Epoch: 6| Step: 12
Training loss: 1.729100227355957
Validation loss: 2.1002731124560037

Epoch: 6| Step: 13
Training loss: 2.3506171703338623
Validation loss: 2.100342055161794

Epoch: 59| Step: 0
Training loss: 2.5908701419830322
Validation loss: 2.094099521636963

Epoch: 6| Step: 1
Training loss: 2.506535530090332
Validation loss: 2.094702978928884

Epoch: 6| Step: 2
Training loss: 2.1482605934143066
Validation loss: 2.0964153011639914

Epoch: 6| Step: 3
Training loss: 2.9387738704681396
Validation loss: 2.0936946670214334

Epoch: 6| Step: 4
Training loss: 2.092528820037842
Validation loss: 2.099610984325409

Epoch: 6| Step: 5
Training loss: 2.4646964073181152
Validation loss: 2.1030293504397073

Epoch: 6| Step: 6
Training loss: 1.6433206796646118
Validation loss: 2.1001081665356955

Epoch: 6| Step: 7
Training loss: 2.3316662311553955
Validation loss: 2.0966091553370156

Epoch: 6| Step: 8
Training loss: 2.714002847671509
Validation loss: 2.0971333583196006

Epoch: 6| Step: 9
Training loss: 2.346750259399414
Validation loss: 2.095917582511902

Epoch: 6| Step: 10
Training loss: 2.4043235778808594
Validation loss: 2.0918853878974915

Epoch: 6| Step: 11
Training loss: 1.969728946685791
Validation loss: 2.094294865926107

Epoch: 6| Step: 12
Training loss: 1.802588701248169
Validation loss: 2.0929239789644876

Epoch: 6| Step: 13
Training loss: 1.8986945152282715
Validation loss: 2.0883912245432534

Epoch: 60| Step: 0
Training loss: 2.284885883331299
Validation loss: 2.0943939487139382

Epoch: 6| Step: 1
Training loss: 1.8000388145446777
Validation loss: 2.099118709564209

Epoch: 6| Step: 2
Training loss: 2.556532144546509
Validation loss: 2.0979957580566406

Epoch: 6| Step: 3
Training loss: 2.4357542991638184
Validation loss: 2.0926895141601562

Epoch: 6| Step: 4
Training loss: 2.3615214824676514
Validation loss: 2.093626777331034

Epoch: 6| Step: 5
Training loss: 3.080221652984619
Validation loss: 2.088171660900116

Epoch: 6| Step: 6
Training loss: 1.7593659162521362
Validation loss: 2.0764438112576804

Epoch: 6| Step: 7
Training loss: 1.918418526649475
Validation loss: 2.0802464485168457

Epoch: 6| Step: 8
Training loss: 2.0143496990203857
Validation loss: 2.0793870290120444

Epoch: 6| Step: 9
Training loss: 1.7768248319625854
Validation loss: 2.0824685096740723

Epoch: 6| Step: 10
Training loss: 2.2819652557373047
Validation loss: 2.087252755959829

Epoch: 6| Step: 11
Training loss: 1.9821555614471436
Validation loss: 2.1043377916018167

Epoch: 6| Step: 12
Training loss: 2.4444451332092285
Validation loss: 2.113584021727244

Epoch: 6| Step: 13
Training loss: 2.9916391372680664
Validation loss: 2.1259422103563943

Epoch: 61| Step: 0
Training loss: 1.9014379978179932
Validation loss: 2.108636220296224

Epoch: 6| Step: 1
Training loss: 2.4592881202697754
Validation loss: 2.0991989374160767

Epoch: 6| Step: 2
Training loss: 2.2258529663085938
Validation loss: 2.0955043832461038

Epoch: 6| Step: 3
Training loss: 2.428358554840088
Validation loss: 2.0877424478530884

Epoch: 6| Step: 4
Training loss: 2.3145194053649902
Validation loss: 2.0892926454544067

Epoch: 6| Step: 5
Training loss: 2.796095371246338
Validation loss: 2.0824934045473733

Epoch: 6| Step: 6
Training loss: 2.4458961486816406
Validation loss: 2.078285872936249

Epoch: 6| Step: 7
Training loss: 1.8298542499542236
Validation loss: 2.077560623486837

Epoch: 6| Step: 8
Training loss: 2.1432952880859375
Validation loss: 2.0770208636919656

Epoch: 6| Step: 9
Training loss: 2.157961845397949
Validation loss: 2.0792165795962014

Epoch: 6| Step: 10
Training loss: 2.1065280437469482
Validation loss: 2.070958971977234

Epoch: 6| Step: 11
Training loss: 1.56235671043396
Validation loss: 2.072150945663452

Epoch: 6| Step: 12
Training loss: 2.8163228034973145
Validation loss: 2.089452862739563

Epoch: 6| Step: 13
Training loss: 2.5296833515167236
Validation loss: 2.078909397125244

Epoch: 62| Step: 0
Training loss: 2.415876865386963
Validation loss: 2.076691448688507

Epoch: 6| Step: 1
Training loss: 1.6446057558059692
Validation loss: 2.0814872781435647

Epoch: 6| Step: 2
Training loss: 2.588322639465332
Validation loss: 2.071187416712443

Epoch: 6| Step: 3
Training loss: 2.6153810024261475
Validation loss: 2.059574544429779

Epoch: 6| Step: 4
Training loss: 2.003117561340332
Validation loss: 2.0596850713094077

Epoch: 6| Step: 5
Training loss: 2.7537503242492676
Validation loss: 2.0600123206774392

Epoch: 6| Step: 6
Training loss: 2.4264488220214844
Validation loss: 2.0583036144574485

Epoch: 6| Step: 7
Training loss: 2.2949295043945312
Validation loss: 2.0602691968282065

Epoch: 6| Step: 8
Training loss: 1.982954740524292
Validation loss: 2.059297283490499

Epoch: 6| Step: 9
Training loss: 2.159796953201294
Validation loss: 2.061048130194346

Epoch: 6| Step: 10
Training loss: 2.1526479721069336
Validation loss: 2.0651747783025107

Epoch: 6| Step: 11
Training loss: 2.1702818870544434
Validation loss: 2.06491086880366

Epoch: 6| Step: 12
Training loss: 2.238786220550537
Validation loss: 2.065179685751597

Epoch: 6| Step: 13
Training loss: 2.04661226272583
Validation loss: 2.064639230569204

Epoch: 63| Step: 0
Training loss: 2.444263458251953
Validation loss: 2.062885105609894

Epoch: 6| Step: 1
Training loss: 2.2844715118408203
Validation loss: 2.0595401525497437

Epoch: 6| Step: 2
Training loss: 2.351569652557373
Validation loss: 2.0613275369008384

Epoch: 6| Step: 3
Training loss: 2.0631484985351562
Validation loss: 2.0582075119018555

Epoch: 6| Step: 4
Training loss: 2.0207126140594482
Validation loss: 2.057069023450216

Epoch: 6| Step: 5
Training loss: 2.3328099250793457
Validation loss: 2.068517247835795

Epoch: 6| Step: 6
Training loss: 1.9870383739471436
Validation loss: 2.0644715229670205

Epoch: 6| Step: 7
Training loss: 2.638334274291992
Validation loss: 2.0645379424095154

Epoch: 6| Step: 8
Training loss: 2.6910219192504883
Validation loss: 2.0520814657211304

Epoch: 6| Step: 9
Training loss: 2.540299892425537
Validation loss: 2.058444062868754

Epoch: 6| Step: 10
Training loss: 1.6569033861160278
Validation loss: 2.0526572465896606

Epoch: 6| Step: 11
Training loss: 1.8989394903182983
Validation loss: 2.047554075717926

Epoch: 6| Step: 12
Training loss: 2.340181589126587
Validation loss: 2.0510754386583963

Epoch: 6| Step: 13
Training loss: 2.3073337078094482
Validation loss: 2.052293916543325

Epoch: 64| Step: 0
Training loss: 2.085129737854004
Validation loss: 2.0525447527567544

Epoch: 6| Step: 1
Training loss: 2.3069159984588623
Validation loss: 2.045411984125773

Epoch: 6| Step: 2
Training loss: 2.630496025085449
Validation loss: 2.0445187290509543

Epoch: 6| Step: 3
Training loss: 2.613961696624756
Validation loss: 2.0467686653137207

Epoch: 6| Step: 4
Training loss: 2.739887237548828
Validation loss: 2.048702577749888

Epoch: 6| Step: 5
Training loss: 2.1064624786376953
Validation loss: 2.0513588984807334

Epoch: 6| Step: 6
Training loss: 1.5743619203567505
Validation loss: 2.0554367701212564

Epoch: 6| Step: 7
Training loss: 1.9785748720169067
Validation loss: 2.056905965010325

Epoch: 6| Step: 8
Training loss: 2.369230270385742
Validation loss: 2.06059068441391

Epoch: 6| Step: 9
Training loss: 1.9192726612091064
Validation loss: 2.060046434402466

Epoch: 6| Step: 10
Training loss: 2.4080278873443604
Validation loss: 2.059058944384257

Epoch: 6| Step: 11
Training loss: 2.033867835998535
Validation loss: 2.0575489600499473

Epoch: 6| Step: 12
Training loss: 2.1784796714782715
Validation loss: 2.0531236131985984

Epoch: 6| Step: 13
Training loss: 2.4427499771118164
Validation loss: 2.0553822120030723

Epoch: 65| Step: 0
Training loss: 2.1467409133911133
Validation loss: 2.0481626192728677

Epoch: 6| Step: 1
Training loss: 2.093153715133667
Validation loss: 2.036769608656565

Epoch: 6| Step: 2
Training loss: 2.6492390632629395
Validation loss: 2.034663200378418

Epoch: 6| Step: 3
Training loss: 2.831226348876953
Validation loss: 2.0271482865015664

Epoch: 6| Step: 4
Training loss: 2.300499439239502
Validation loss: 2.0402826269467673

Epoch: 6| Step: 5
Training loss: 2.286862850189209
Validation loss: 2.0449570218722024

Epoch: 6| Step: 6
Training loss: 2.249556064605713
Validation loss: 2.041831652323405

Epoch: 6| Step: 7
Training loss: 2.5191266536712646
Validation loss: 2.0375454227129617

Epoch: 6| Step: 8
Training loss: 2.181504249572754
Validation loss: 2.0333385070165

Epoch: 6| Step: 9
Training loss: 2.1604490280151367
Validation loss: 2.0281014243761697

Epoch: 6| Step: 10
Training loss: 2.3781521320343018
Validation loss: 2.029724419116974

Epoch: 6| Step: 11
Training loss: 1.5593183040618896
Validation loss: 2.032854199409485

Epoch: 6| Step: 12
Training loss: 1.5480647087097168
Validation loss: 2.03761225938797

Epoch: 6| Step: 13
Training loss: 2.3441147804260254
Validation loss: 2.0361374815305076

Epoch: 66| Step: 0
Training loss: 2.3220176696777344
Validation loss: 2.0330841342608132

Epoch: 6| Step: 1
Training loss: 2.1597282886505127
Validation loss: 2.032598833243052

Epoch: 6| Step: 2
Training loss: 1.999410629272461
Validation loss: 2.0375024676322937

Epoch: 6| Step: 3
Training loss: 2.6885251998901367
Validation loss: 2.0367948015530906

Epoch: 6| Step: 4
Training loss: 2.640364170074463
Validation loss: 2.036253829797109

Epoch: 6| Step: 5
Training loss: 2.301830291748047
Validation loss: 2.0334004958470664

Epoch: 6| Step: 6
Training loss: 2.367985725402832
Validation loss: 2.0339179039001465

Epoch: 6| Step: 7
Training loss: 2.063530921936035
Validation loss: 2.036570350329081

Epoch: 6| Step: 8
Training loss: 2.068528413772583
Validation loss: 2.0324623783429465

Epoch: 6| Step: 9
Training loss: 1.6589596271514893
Validation loss: 2.0285159150759378

Epoch: 6| Step: 10
Training loss: 2.0530636310577393
Validation loss: 2.0344324310620627

Epoch: 6| Step: 11
Training loss: 2.3861255645751953
Validation loss: 2.0399847428003945

Epoch: 6| Step: 12
Training loss: 2.9282402992248535
Validation loss: 2.0401606957117715

Epoch: 6| Step: 13
Training loss: 1.398425817489624
Validation loss: 2.034086008866628

Epoch: 67| Step: 0
Training loss: 3.290492534637451
Validation loss: 2.0337776144345603

Epoch: 6| Step: 1
Training loss: 2.298990249633789
Validation loss: 2.0277036825815835

Epoch: 6| Step: 2
Training loss: 2.349630832672119
Validation loss: 2.028825124104818

Epoch: 6| Step: 3
Training loss: 1.9427261352539062
Validation loss: 2.025169094403585

Epoch: 6| Step: 4
Training loss: 1.2946237325668335
Validation loss: 2.02705055475235

Epoch: 6| Step: 5
Training loss: 2.348806858062744
Validation loss: 2.028447230656942

Epoch: 6| Step: 6
Training loss: 2.0129854679107666
Validation loss: 2.0236395796140036

Epoch: 6| Step: 7
Training loss: 1.9102612733840942
Validation loss: 2.0288098653157554

Epoch: 6| Step: 8
Training loss: 2.562887668609619
Validation loss: 2.028292973836263

Epoch: 6| Step: 9
Training loss: 2.2910289764404297
Validation loss: 2.0176859895388284

Epoch: 6| Step: 10
Training loss: 2.6063809394836426
Validation loss: 2.0205073157946267

Epoch: 6| Step: 11
Training loss: 2.2757463455200195
Validation loss: 2.0233856042226157

Epoch: 6| Step: 12
Training loss: 1.6607056856155396
Validation loss: 2.024051785469055

Epoch: 6| Step: 13
Training loss: 1.9324676990509033
Validation loss: 2.022926092147827

Epoch: 68| Step: 0
Training loss: 1.8371354341506958
Validation loss: 2.012593984603882

Epoch: 6| Step: 1
Training loss: 2.2285025119781494
Validation loss: 2.0258694092432656

Epoch: 6| Step: 2
Training loss: 1.6881437301635742
Validation loss: 2.0182939370473227

Epoch: 6| Step: 3
Training loss: 2.2753851413726807
Validation loss: 2.023537576198578

Epoch: 6| Step: 4
Training loss: 2.1681737899780273
Validation loss: 2.0303888519605002

Epoch: 6| Step: 5
Training loss: 2.838440418243408
Validation loss: 2.03471702337265

Epoch: 6| Step: 6
Training loss: 2.938157796859741
Validation loss: 2.0330724318822226

Epoch: 6| Step: 7
Training loss: 1.9997161626815796
Validation loss: 2.0381514032681785

Epoch: 6| Step: 8
Training loss: 1.7580671310424805
Validation loss: 2.0376998583475747

Epoch: 6| Step: 9
Training loss: 1.793654441833496
Validation loss: 2.0253102580706277

Epoch: 6| Step: 10
Training loss: 2.5889320373535156
Validation loss: 2.016915818055471

Epoch: 6| Step: 11
Training loss: 2.389930486679077
Validation loss: 2.0206781228383384

Epoch: 6| Step: 12
Training loss: 1.896649956703186
Validation loss: 2.0193649530410767

Epoch: 6| Step: 13
Training loss: 2.41930890083313
Validation loss: 2.0150387287139893

Epoch: 69| Step: 0
Training loss: 2.403088331222534
Validation loss: 2.0193741718928018

Epoch: 6| Step: 1
Training loss: 1.720350742340088
Validation loss: 2.0143853227297464

Epoch: 6| Step: 2
Training loss: 2.2949442863464355
Validation loss: 2.0195792516072593

Epoch: 6| Step: 3
Training loss: 2.216643810272217
Validation loss: 2.0221251249313354

Epoch: 6| Step: 4
Training loss: 1.651493787765503
Validation loss: 2.0276620785395303

Epoch: 6| Step: 5
Training loss: 1.6674602031707764
Validation loss: 2.0249945918718972

Epoch: 6| Step: 6
Training loss: 1.6877237558364868
Validation loss: 2.0133375326792398

Epoch: 6| Step: 7
Training loss: 2.4316811561584473
Validation loss: 2.02642160654068

Epoch: 6| Step: 8
Training loss: 2.3178231716156006
Validation loss: 2.026914954185486

Epoch: 6| Step: 9
Training loss: 2.240436553955078
Validation loss: 2.0140910943349204

Epoch: 6| Step: 10
Training loss: 2.5246143341064453
Validation loss: 2.019766390323639

Epoch: 6| Step: 11
Training loss: 2.8593454360961914
Validation loss: 2.028853714466095

Epoch: 6| Step: 12
Training loss: 1.8862271308898926
Validation loss: 2.0269004702568054

Epoch: 6| Step: 13
Training loss: 2.6553075313568115
Validation loss: 2.02571972211202

Epoch: 70| Step: 0
Training loss: 2.0855469703674316
Validation loss: 2.0182909766832986

Epoch: 6| Step: 1
Training loss: 2.216421127319336
Validation loss: 2.027404467264811

Epoch: 6| Step: 2
Training loss: 2.1893863677978516
Validation loss: 2.0275047421455383

Epoch: 6| Step: 3
Training loss: 2.3830089569091797
Validation loss: 2.0403053760528564

Epoch: 6| Step: 4
Training loss: 1.6242420673370361
Validation loss: 2.03609307607015

Epoch: 6| Step: 5
Training loss: 1.7798517942428589
Validation loss: 2.0362399021784463

Epoch: 6| Step: 6
Training loss: 1.8496943712234497
Validation loss: 2.0442528327306113

Epoch: 6| Step: 7
Training loss: 2.2952380180358887
Validation loss: 2.046826402346293

Epoch: 6| Step: 8
Training loss: 2.2684693336486816
Validation loss: 2.0444332559903464

Epoch: 6| Step: 9
Training loss: 1.908896565437317
Validation loss: 2.030601441860199

Epoch: 6| Step: 10
Training loss: 2.9896388053894043
Validation loss: 2.0155300895373025

Epoch: 6| Step: 11
Training loss: 2.7544779777526855
Validation loss: 2.007686277230581

Epoch: 6| Step: 12
Training loss: 2.455718994140625
Validation loss: 2.014403144518534

Epoch: 6| Step: 13
Training loss: 1.920480728149414
Validation loss: 2.0203792452812195

Epoch: 71| Step: 0
Training loss: 2.5609474182128906
Validation loss: 2.0221951007843018

Epoch: 6| Step: 1
Training loss: 2.145139694213867
Validation loss: 2.0170853535334268

Epoch: 6| Step: 2
Training loss: 2.3138508796691895
Validation loss: 2.0245860815048218

Epoch: 6| Step: 3
Training loss: 1.9579010009765625
Validation loss: 2.0168513456980386

Epoch: 6| Step: 4
Training loss: 2.779393196105957
Validation loss: 2.013768454392751

Epoch: 6| Step: 5
Training loss: 2.3214480876922607
Validation loss: 2.0115738908449807

Epoch: 6| Step: 6
Training loss: 2.294750213623047
Validation loss: 2.0143579840660095

Epoch: 6| Step: 7
Training loss: 2.3449158668518066
Validation loss: 2.0077866514523826

Epoch: 6| Step: 8
Training loss: 1.8938348293304443
Validation loss: 2.0069987773895264

Epoch: 6| Step: 9
Training loss: 1.8026459217071533
Validation loss: 2.010403116544088

Epoch: 6| Step: 10
Training loss: 1.4822998046875
Validation loss: 2.0200979510943093

Epoch: 6| Step: 11
Training loss: 2.182342052459717
Validation loss: 2.0171868801116943

Epoch: 6| Step: 12
Training loss: 2.1688647270202637
Validation loss: 2.023343284924825

Epoch: 6| Step: 13
Training loss: 2.389282464981079
Validation loss: 2.0210759043693542

Epoch: 72| Step: 0
Training loss: 1.4612131118774414
Validation loss: 2.020702838897705

Epoch: 6| Step: 1
Training loss: 1.7674401998519897
Validation loss: 2.0235265096028647

Epoch: 6| Step: 2
Training loss: 1.5881409645080566
Validation loss: 2.0229382316271463

Epoch: 6| Step: 3
Training loss: 2.1948628425598145
Validation loss: 2.031252125898997

Epoch: 6| Step: 4
Training loss: 1.8536125421524048
Validation loss: 2.033336957295736

Epoch: 6| Step: 5
Training loss: 1.9054434299468994
Validation loss: 2.034963289896647

Epoch: 6| Step: 6
Training loss: 2.310939073562622
Validation loss: 2.032383918762207

Epoch: 6| Step: 7
Training loss: 2.903801918029785
Validation loss: 2.0257780154546103

Epoch: 6| Step: 8
Training loss: 2.3007330894470215
Validation loss: 2.0139641761779785

Epoch: 6| Step: 9
Training loss: 2.5290160179138184
Validation loss: 2.0145427783330283

Epoch: 6| Step: 10
Training loss: 2.032855272293091
Validation loss: 2.0148393313090005

Epoch: 6| Step: 11
Training loss: 2.600519895553589
Validation loss: 2.016297002633413

Epoch: 6| Step: 12
Training loss: 2.2682766914367676
Validation loss: 2.0175156593322754

Epoch: 6| Step: 13
Training loss: 2.7112767696380615
Validation loss: 2.0203377405802407

Epoch: 73| Step: 0
Training loss: 2.052508592605591
Validation loss: 2.027830481529236

Epoch: 6| Step: 1
Training loss: 2.3123841285705566
Validation loss: 2.026489237944285

Epoch: 6| Step: 2
Training loss: 2.528916358947754
Validation loss: 2.018878479798635

Epoch: 6| Step: 3
Training loss: 2.3777129650115967
Validation loss: 2.0291627446810403

Epoch: 6| Step: 4
Training loss: 2.156524658203125
Validation loss: 2.0274245738983154

Epoch: 6| Step: 5
Training loss: 2.0917420387268066
Validation loss: 2.0200154185295105

Epoch: 6| Step: 6
Training loss: 2.0083274841308594
Validation loss: 2.014548043409983

Epoch: 6| Step: 7
Training loss: 2.7959275245666504
Validation loss: 2.018520991007487

Epoch: 6| Step: 8
Training loss: 2.0060534477233887
Validation loss: 2.019679307937622

Epoch: 6| Step: 9
Training loss: 1.728170394897461
Validation loss: 2.015456259250641

Epoch: 6| Step: 10
Training loss: 1.6572626829147339
Validation loss: 2.0239532192548118

Epoch: 6| Step: 11
Training loss: 1.985453486442566
Validation loss: 2.0418037374814353

Epoch: 6| Step: 12
Training loss: 2.577484607696533
Validation loss: 2.048731565475464

Epoch: 6| Step: 13
Training loss: 2.2984869480133057
Validation loss: 2.0495211680730185

Epoch: 74| Step: 0
Training loss: 2.2678680419921875
Validation loss: 2.0470696290334067

Epoch: 6| Step: 1
Training loss: 2.9559569358825684
Validation loss: 2.030597448348999

Epoch: 6| Step: 2
Training loss: 2.2125437259674072
Validation loss: 2.024267315864563

Epoch: 6| Step: 3
Training loss: 1.6058104038238525
Validation loss: 2.022887090841929

Epoch: 6| Step: 4
Training loss: 2.3818421363830566
Validation loss: 2.0207332571347556

Epoch: 6| Step: 5
Training loss: 1.8478991985321045
Validation loss: 2.018363376458486

Epoch: 6| Step: 6
Training loss: 2.4059412479400635
Validation loss: 2.0161351362864175

Epoch: 6| Step: 7
Training loss: 1.5568437576293945
Validation loss: 2.005879044532776

Epoch: 6| Step: 8
Training loss: 2.747063636779785
Validation loss: 2.0187458197275796

Epoch: 6| Step: 9
Training loss: 2.445974826812744
Validation loss: 2.0091394186019897

Epoch: 6| Step: 10
Training loss: 2.0586583614349365
Validation loss: 2.0136860609054565

Epoch: 6| Step: 11
Training loss: 1.9097039699554443
Validation loss: 2.0100220441818237

Epoch: 6| Step: 12
Training loss: 1.732973337173462
Validation loss: 2.016804873943329

Epoch: 6| Step: 13
Training loss: 2.260470151901245
Validation loss: 2.011976877848307

Epoch: 75| Step: 0
Training loss: 2.748288631439209
Validation loss: 2.009015460809072

Epoch: 6| Step: 1
Training loss: 1.684655785560608
Validation loss: 2.0170661012331643

Epoch: 6| Step: 2
Training loss: 2.0970897674560547
Validation loss: 2.0114080707232156

Epoch: 6| Step: 3
Training loss: 2.340985059738159
Validation loss: 2.0154406428337097

Epoch: 6| Step: 4
Training loss: 2.529453992843628
Validation loss: 2.0235547622044883

Epoch: 6| Step: 5
Training loss: 1.9630898237228394
Validation loss: 2.027022361755371

Epoch: 6| Step: 6
Training loss: 1.7804152965545654
Validation loss: 2.022479852040609

Epoch: 6| Step: 7
Training loss: 1.9319524765014648
Validation loss: 2.0284850200017295

Epoch: 6| Step: 8
Training loss: 1.7221509218215942
Validation loss: 2.0312577883402505

Epoch: 6| Step: 9
Training loss: 3.0117580890655518
Validation loss: 2.034257968266805

Epoch: 6| Step: 10
Training loss: 2.521055221557617
Validation loss: 2.035805583000183

Epoch: 6| Step: 11
Training loss: 2.444796085357666
Validation loss: 2.018567125002543

Epoch: 6| Step: 12
Training loss: 2.0210585594177246
Validation loss: 2.0163268049558005

Epoch: 6| Step: 13
Training loss: 1.5181220769882202
Validation loss: 2.0188898841540017

Testing loss: 1.6400015002531971
