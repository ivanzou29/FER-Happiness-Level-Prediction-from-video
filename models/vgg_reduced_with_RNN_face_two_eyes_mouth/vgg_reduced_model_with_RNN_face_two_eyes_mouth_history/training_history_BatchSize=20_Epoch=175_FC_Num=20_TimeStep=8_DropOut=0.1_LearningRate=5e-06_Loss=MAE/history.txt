Epoch: 1| Step: 0
Training loss: 4.936933517456055
Validation loss: 5.235694189866384

Epoch: 5| Step: 1
Training loss: 5.487173557281494
Validation loss: 5.23330803712209

Epoch: 5| Step: 2
Training loss: 5.764681816101074
Validation loss: 5.230839490890503

Epoch: 5| Step: 3
Training loss: 5.771582126617432
Validation loss: 5.228495478630066

Epoch: 5| Step: 4
Training loss: 4.914593696594238
Validation loss: 5.226041654745738

Epoch: 5| Step: 5
Training loss: 4.877316474914551
Validation loss: 5.223696768283844

Epoch: 5| Step: 6
Training loss: 4.680403709411621
Validation loss: 5.221286952495575

Epoch: 5| Step: 7
Training loss: 4.8686652183532715
Validation loss: 5.218806266784668

Epoch: 5| Step: 8
Training loss: 5.285988807678223
Validation loss: 5.216405808925629

Epoch: 5| Step: 9
Training loss: 6.066222190856934
Validation loss: 5.2138296365737915

Epoch: 5| Step: 10
Training loss: 6.023241996765137
Validation loss: 5.21110995610555

Epoch: 5| Step: 11
Training loss: 3.0264549255371094
Validation loss: 5.208505044380824

Epoch: 2| Step: 0
Training loss: 5.241703987121582
Validation loss: 5.205839614073436

Epoch: 5| Step: 1
Training loss: 4.593494892120361
Validation loss: 5.202936470508575

Epoch: 5| Step: 2
Training loss: 5.286276340484619
Validation loss: 5.200091063976288

Epoch: 5| Step: 3
Training loss: 4.3061089515686035
Validation loss: 5.197021941343944

Epoch: 5| Step: 4
Training loss: 6.199446678161621
Validation loss: 5.1939208308855696

Epoch: 5| Step: 5
Training loss: 4.26876163482666
Validation loss: 5.190709749857585

Epoch: 5| Step: 6
Training loss: 4.868991851806641
Validation loss: 5.187155067920685

Epoch: 5| Step: 7
Training loss: 5.858246326446533
Validation loss: 5.183501601219177

Epoch: 5| Step: 8
Training loss: 5.318819046020508
Validation loss: 5.179820636908214

Epoch: 5| Step: 9
Training loss: 6.2118916511535645
Validation loss: 5.175747374693553

Epoch: 5| Step: 10
Training loss: 5.445489406585693
Validation loss: 5.171823541323344

Epoch: 5| Step: 11
Training loss: 6.541875839233398
Validation loss: 5.167430559794108

Epoch: 3| Step: 0
Training loss: 5.587062358856201
Validation loss: 5.162854830423991

Epoch: 5| Step: 1
Training loss: 5.0089006423950195
Validation loss: 5.158087948958079

Epoch: 5| Step: 2
Training loss: 5.901246070861816
Validation loss: 5.153228918711345

Epoch: 5| Step: 3
Training loss: 6.177846431732178
Validation loss: 5.148062864939372

Epoch: 5| Step: 4
Training loss: 4.823694229125977
Validation loss: 5.142998615900676

Epoch: 5| Step: 5
Training loss: 5.0811052322387695
Validation loss: 5.137419323126475

Epoch: 5| Step: 6
Training loss: 4.634936809539795
Validation loss: 5.131831447283427

Epoch: 5| Step: 7
Training loss: 4.787878513336182
Validation loss: 5.126147369543712

Epoch: 5| Step: 8
Training loss: 5.195812225341797
Validation loss: 5.120335419972737

Epoch: 5| Step: 9
Training loss: 5.638796329498291
Validation loss: 5.114492177963257

Epoch: 5| Step: 10
Training loss: 4.495400905609131
Validation loss: 5.107958992322286

Epoch: 5| Step: 11
Training loss: 5.060556411743164
Validation loss: 5.101594150066376

Epoch: 4| Step: 0
Training loss: 5.7859039306640625
Validation loss: 5.095264375209808

Epoch: 5| Step: 1
Training loss: 5.298194885253906
Validation loss: 5.088607947031657

Epoch: 5| Step: 2
Training loss: 5.604587554931641
Validation loss: 5.081965506076813

Epoch: 5| Step: 3
Training loss: 5.666611671447754
Validation loss: 5.074972867965698

Epoch: 5| Step: 4
Training loss: 5.218008041381836
Validation loss: 5.067812114953995

Epoch: 5| Step: 5
Training loss: 5.359058380126953
Validation loss: 5.060772478580475

Epoch: 5| Step: 6
Training loss: 4.570511817932129
Validation loss: 5.053364495436351

Epoch: 5| Step: 7
Training loss: 4.493807315826416
Validation loss: 5.046032210191091

Epoch: 5| Step: 8
Training loss: 4.337543487548828
Validation loss: 5.038388133049011

Epoch: 5| Step: 9
Training loss: 5.347152233123779
Validation loss: 5.031000892321269

Epoch: 5| Step: 10
Training loss: 4.923450469970703
Validation loss: 5.022981385389964

Epoch: 5| Step: 11
Training loss: 4.572140693664551
Validation loss: 5.015034695466359

Epoch: 5| Step: 0
Training loss: 5.789518356323242
Validation loss: 5.007277150948842

Epoch: 5| Step: 1
Training loss: 5.13490629196167
Validation loss: 4.999265491962433

Epoch: 5| Step: 2
Training loss: 4.539198398590088
Validation loss: 4.991352200508118

Epoch: 5| Step: 3
Training loss: 5.963139057159424
Validation loss: 4.9831440051396685

Epoch: 5| Step: 4
Training loss: 5.3340911865234375
Validation loss: 4.974685211976369

Epoch: 5| Step: 5
Training loss: 4.875083923339844
Validation loss: 4.9662245114644366

Epoch: 5| Step: 6
Training loss: 5.288949489593506
Validation loss: 4.957767724990845

Epoch: 5| Step: 7
Training loss: 4.966132164001465
Validation loss: 4.949480891227722

Epoch: 5| Step: 8
Training loss: 5.379799842834473
Validation loss: 4.940692325433095

Epoch: 5| Step: 9
Training loss: 4.4106035232543945
Validation loss: 4.9316388964653015

Epoch: 5| Step: 10
Training loss: 4.222586631774902
Validation loss: 4.923277854919434

Epoch: 5| Step: 11
Training loss: 3.0844647884368896
Validation loss: 4.9143248200416565

Epoch: 6| Step: 0
Training loss: 4.398435115814209
Validation loss: 4.90547247727712

Epoch: 5| Step: 1
Training loss: 4.201249122619629
Validation loss: 4.896538972854614

Epoch: 5| Step: 2
Training loss: 4.273479461669922
Validation loss: 4.887942016124725

Epoch: 5| Step: 3
Training loss: 5.064521789550781
Validation loss: 4.879007617632548

Epoch: 5| Step: 4
Training loss: 5.4367995262146
Validation loss: 4.869908730189006

Epoch: 5| Step: 5
Training loss: 5.701938152313232
Validation loss: 4.860835651556651

Epoch: 5| Step: 6
Training loss: 5.7451043128967285
Validation loss: 4.8521707852681475

Epoch: 5| Step: 7
Training loss: 4.641625881195068
Validation loss: 4.843639065821965

Epoch: 5| Step: 8
Training loss: 4.937417507171631
Validation loss: 4.835134824117024

Epoch: 5| Step: 9
Training loss: 4.2698869705200195
Validation loss: 4.826621830463409

Epoch: 5| Step: 10
Training loss: 5.694868564605713
Validation loss: 4.818321367104848

Epoch: 5| Step: 11
Training loss: 5.196686744689941
Validation loss: 4.810033788283666

Epoch: 7| Step: 0
Training loss: 6.000138282775879
Validation loss: 4.802262445290883

Epoch: 5| Step: 1
Training loss: 4.140384674072266
Validation loss: 4.794116318225861

Epoch: 5| Step: 2
Training loss: 5.393485069274902
Validation loss: 4.78625084956487

Epoch: 5| Step: 3
Training loss: 3.88954496383667
Validation loss: 4.778489490350087

Epoch: 5| Step: 4
Training loss: 4.547891139984131
Validation loss: 4.770929396152496

Epoch: 5| Step: 5
Training loss: 3.813615322113037
Validation loss: 4.763588507970174

Epoch: 5| Step: 6
Training loss: 5.412116050720215
Validation loss: 4.756432553132375

Epoch: 5| Step: 7
Training loss: 4.683754920959473
Validation loss: 4.74917209148407

Epoch: 5| Step: 8
Training loss: 4.890048503875732
Validation loss: 4.741709768772125

Epoch: 5| Step: 9
Training loss: 5.292550086975098
Validation loss: 4.73461256424586

Epoch: 5| Step: 10
Training loss: 5.532637596130371
Validation loss: 4.727362175782521

Epoch: 5| Step: 11
Training loss: 3.83740234375
Validation loss: 4.720013082027435

Epoch: 8| Step: 0
Training loss: 4.403426170349121
Validation loss: 4.712925652662913

Epoch: 5| Step: 1
Training loss: 5.214665412902832
Validation loss: 4.705592036247253

Epoch: 5| Step: 2
Training loss: 4.24235725402832
Validation loss: 4.698161423206329

Epoch: 5| Step: 3
Training loss: 4.077004432678223
Validation loss: 4.690619796514511

Epoch: 5| Step: 4
Training loss: 5.798140048980713
Validation loss: 4.683168152968089

Epoch: 5| Step: 5
Training loss: 4.401193618774414
Validation loss: 4.675562342007955

Epoch: 5| Step: 6
Training loss: 4.897747993469238
Validation loss: 4.668104648590088

Epoch: 5| Step: 7
Training loss: 5.887741565704346
Validation loss: 4.6606736580530805

Epoch: 5| Step: 8
Training loss: 4.324305057525635
Validation loss: 4.653278052806854

Epoch: 5| Step: 9
Training loss: 3.937342882156372
Validation loss: 4.646095176537831

Epoch: 5| Step: 10
Training loss: 5.193031311035156
Validation loss: 4.639430632193883

Epoch: 5| Step: 11
Training loss: 5.269949913024902
Validation loss: 4.632788976033528

Epoch: 9| Step: 0
Training loss: 3.794316530227661
Validation loss: 4.626291662454605

Epoch: 5| Step: 1
Training loss: 4.886004447937012
Validation loss: 4.620087305704753

Epoch: 5| Step: 2
Training loss: 5.146620273590088
Validation loss: 4.612938125928243

Epoch: 5| Step: 3
Training loss: 5.247904300689697
Validation loss: 4.605678498744965

Epoch: 5| Step: 4
Training loss: 4.231752395629883
Validation loss: 4.598647554715474

Epoch: 5| Step: 5
Training loss: 4.955084323883057
Validation loss: 4.592002908388774

Epoch: 5| Step: 6
Training loss: 4.111181735992432
Validation loss: 4.585581024487813

Epoch: 5| Step: 7
Training loss: 5.095427513122559
Validation loss: 4.5791298647721606

Epoch: 5| Step: 8
Training loss: 4.339850902557373
Validation loss: 4.572276373704274

Epoch: 5| Step: 9
Training loss: 4.434514045715332
Validation loss: 4.565161267916362

Epoch: 5| Step: 10
Training loss: 4.746337890625
Validation loss: 4.558628976345062

Epoch: 5| Step: 11
Training loss: 7.7405805587768555
Validation loss: 4.551852842171987

Epoch: 10| Step: 0
Training loss: 4.704516887664795
Validation loss: 4.545457144578298

Epoch: 5| Step: 1
Training loss: 4.326364517211914
Validation loss: 4.539240976174672

Epoch: 5| Step: 2
Training loss: 4.026913166046143
Validation loss: 4.532312611738841

Epoch: 5| Step: 3
Training loss: 3.8208916187286377
Validation loss: 4.525688648223877

Epoch: 5| Step: 4
Training loss: 5.832800388336182
Validation loss: 4.51928065220515

Epoch: 5| Step: 5
Training loss: 4.441367149353027
Validation loss: 4.513262987136841

Epoch: 5| Step: 6
Training loss: 3.494530439376831
Validation loss: 4.506901542345683

Epoch: 5| Step: 7
Training loss: 5.527663230895996
Validation loss: 4.501209696133931

Epoch: 5| Step: 8
Training loss: 4.388373374938965
Validation loss: 4.4951456387837725

Epoch: 5| Step: 9
Training loss: 5.575638771057129
Validation loss: 4.489314496517181

Epoch: 5| Step: 10
Training loss: 4.711312770843506
Validation loss: 4.483611037333806

Epoch: 5| Step: 11
Training loss: 4.386178970336914
Validation loss: 4.4777912100156145

Epoch: 11| Step: 0
Training loss: 5.641458988189697
Validation loss: 4.472363710403442

Epoch: 5| Step: 1
Training loss: 4.930798530578613
Validation loss: 4.466380874315898

Epoch: 5| Step: 2
Training loss: 4.316699504852295
Validation loss: 4.460536042849223

Epoch: 5| Step: 3
Training loss: 5.40447998046875
Validation loss: 4.454776177803676

Epoch: 5| Step: 4
Training loss: 3.9772942066192627
Validation loss: 4.4492137134075165

Epoch: 5| Step: 5
Training loss: 4.53226375579834
Validation loss: 4.443377157052358

Epoch: 5| Step: 6
Training loss: 4.859066963195801
Validation loss: 4.437669336795807

Epoch: 5| Step: 7
Training loss: 4.62355899810791
Validation loss: 4.431690623362859

Epoch: 5| Step: 8
Training loss: 4.858428955078125
Validation loss: 4.426293273766835

Epoch: 5| Step: 9
Training loss: 3.0045340061187744
Validation loss: 4.420491993427277

Epoch: 5| Step: 10
Training loss: 4.533790111541748
Validation loss: 4.415101408958435

Epoch: 5| Step: 11
Training loss: 1.7589893341064453
Validation loss: 4.409756322701772

Epoch: 12| Step: 0
Training loss: 5.542109966278076
Validation loss: 4.405180960893631

Epoch: 5| Step: 1
Training loss: 4.873429775238037
Validation loss: 4.400131473938624

Epoch: 5| Step: 2
Training loss: 4.355216979980469
Validation loss: 4.395197848478953

Epoch: 5| Step: 3
Training loss: 5.0996527671813965
Validation loss: 4.389181236426036

Epoch: 5| Step: 4
Training loss: 3.541533946990967
Validation loss: 4.383746325969696

Epoch: 5| Step: 5
Training loss: 4.151620388031006
Validation loss: 4.378447790940602

Epoch: 5| Step: 6
Training loss: 4.580496311187744
Validation loss: 4.373252272605896

Epoch: 5| Step: 7
Training loss: 4.670973777770996
Validation loss: 4.367933948834737

Epoch: 5| Step: 8
Training loss: 3.956735134124756
Validation loss: 4.362857123215993

Epoch: 5| Step: 9
Training loss: 4.3279218673706055
Validation loss: 4.357449054718018

Epoch: 5| Step: 10
Training loss: 4.429772853851318
Validation loss: 4.352434645096461

Epoch: 5| Step: 11
Training loss: 4.173849105834961
Validation loss: 4.3471712072690325

Epoch: 13| Step: 0
Training loss: 4.9990339279174805
Validation loss: 4.341517200072606

Epoch: 5| Step: 1
Training loss: 4.8257060050964355
Validation loss: 4.33620282014211

Epoch: 5| Step: 2
Training loss: 4.43427038192749
Validation loss: 4.331353763739268

Epoch: 5| Step: 3
Training loss: 3.5177924633026123
Validation loss: 4.326269070307414

Epoch: 5| Step: 4
Training loss: 4.546946048736572
Validation loss: 4.3208658794562025

Epoch: 5| Step: 5
Training loss: 4.057574272155762
Validation loss: 4.315968692302704

Epoch: 5| Step: 6
Training loss: 4.310904026031494
Validation loss: 4.310385137796402

Epoch: 5| Step: 7
Training loss: 3.6720213890075684
Validation loss: 4.304820160071055

Epoch: 5| Step: 8
Training loss: 5.228157043457031
Validation loss: 4.299442907174428

Epoch: 5| Step: 9
Training loss: 5.01961612701416
Validation loss: 4.293758610884349

Epoch: 5| Step: 10
Training loss: 4.43195104598999
Validation loss: 4.288317581017812

Epoch: 5| Step: 11
Training loss: 3.3299124240875244
Validation loss: 4.283075501521428

Epoch: 14| Step: 0
Training loss: 3.857090473175049
Validation loss: 4.277297397454579

Epoch: 5| Step: 1
Training loss: 4.176002025604248
Validation loss: 4.271788736184438

Epoch: 5| Step: 2
Training loss: 4.942264556884766
Validation loss: 4.26654467980067

Epoch: 5| Step: 3
Training loss: 5.1624932289123535
Validation loss: 4.2612318595250445

Epoch: 5| Step: 4
Training loss: 4.164914131164551
Validation loss: 4.255539874235789

Epoch: 5| Step: 5
Training loss: 4.82006311416626
Validation loss: 4.250219434499741

Epoch: 5| Step: 6
Training loss: 5.1781721115112305
Validation loss: 4.244444042444229

Epoch: 5| Step: 7
Training loss: 4.616570472717285
Validation loss: 4.238535801569621

Epoch: 5| Step: 8
Training loss: 4.303740501403809
Validation loss: 4.2330708503723145

Epoch: 5| Step: 9
Training loss: 2.4865074157714844
Validation loss: 4.227052330970764

Epoch: 5| Step: 10
Training loss: 4.704823970794678
Validation loss: 4.221757998069127

Epoch: 5| Step: 11
Training loss: 3.1406350135803223
Validation loss: 4.216342369715373

Epoch: 15| Step: 0
Training loss: 4.466648578643799
Validation loss: 4.210733205080032

Epoch: 5| Step: 1
Training loss: 4.269659042358398
Validation loss: 4.204915424187978

Epoch: 5| Step: 2
Training loss: 3.8946754932403564
Validation loss: 4.199757397174835

Epoch: 5| Step: 3
Training loss: 4.868401527404785
Validation loss: 4.193741927544276

Epoch: 5| Step: 4
Training loss: 3.6790270805358887
Validation loss: 4.188629964987437

Epoch: 5| Step: 5
Training loss: 4.886014461517334
Validation loss: 4.183099379142125

Epoch: 5| Step: 6
Training loss: 4.598649024963379
Validation loss: 4.1777757207552595

Epoch: 5| Step: 7
Training loss: 4.0280280113220215
Validation loss: 4.171921372413635

Epoch: 5| Step: 8
Training loss: 4.684675216674805
Validation loss: 4.166088571151097

Epoch: 5| Step: 9
Training loss: 4.872702598571777
Validation loss: 4.160678585370381

Epoch: 5| Step: 10
Training loss: 3.6229825019836426
Validation loss: 4.155245323975881

Epoch: 5| Step: 11
Training loss: 2.376680374145508
Validation loss: 4.149442146221797

Epoch: 16| Step: 0
Training loss: 3.974377155303955
Validation loss: 4.143704831600189

Epoch: 5| Step: 1
Training loss: 3.905513286590576
Validation loss: 4.1382254759470625

Epoch: 5| Step: 2
Training loss: 4.610596656799316
Validation loss: 4.133544693390529

Epoch: 5| Step: 3
Training loss: 4.372316837310791
Validation loss: 4.126957734425862

Epoch: 5| Step: 4
Training loss: 3.932982921600342
Validation loss: 4.121238847573598

Epoch: 5| Step: 5
Training loss: 4.581752300262451
Validation loss: 4.116272111733754

Epoch: 5| Step: 6
Training loss: 3.7283339500427246
Validation loss: 4.110930651426315

Epoch: 5| Step: 7
Training loss: 4.871910095214844
Validation loss: 4.105756272872289

Epoch: 5| Step: 8
Training loss: 4.460268497467041
Validation loss: 4.099864363670349

Epoch: 5| Step: 9
Training loss: 3.94197154045105
Validation loss: 4.095798661311467

Epoch: 5| Step: 10
Training loss: 4.658837795257568
Validation loss: 4.090193688869476

Epoch: 5| Step: 11
Training loss: 3.1439733505249023
Validation loss: 4.084429224332173

Epoch: 17| Step: 0
Training loss: 3.750396728515625
Validation loss: 4.081353654464086

Epoch: 5| Step: 1
Training loss: 4.429078102111816
Validation loss: 4.075610796610515

Epoch: 5| Step: 2
Training loss: 4.986809730529785
Validation loss: 4.07058600584666

Epoch: 5| Step: 3
Training loss: 4.480234146118164
Validation loss: 4.064351836840312

Epoch: 5| Step: 4
Training loss: 4.7865800857543945
Validation loss: 4.059977958599727

Epoch: 5| Step: 5
Training loss: 4.041237831115723
Validation loss: 4.055058687925339

Epoch: 5| Step: 6
Training loss: 3.4171433448791504
Validation loss: 4.04991231362025

Epoch: 5| Step: 7
Training loss: 4.6925368309021
Validation loss: 4.04457504550616

Epoch: 5| Step: 8
Training loss: 4.077887535095215
Validation loss: 4.039501190185547

Epoch: 5| Step: 9
Training loss: 3.3691391944885254
Validation loss: 4.034419894218445

Epoch: 5| Step: 10
Training loss: 3.856032133102417
Validation loss: 4.030158440272014

Epoch: 5| Step: 11
Training loss: 5.667953014373779
Validation loss: 4.025419821341832

Epoch: 18| Step: 0
Training loss: 3.878661632537842
Validation loss: 4.0200298229853315

Epoch: 5| Step: 1
Training loss: 4.256274223327637
Validation loss: 4.0167632301648455

Epoch: 5| Step: 2
Training loss: 4.8044633865356445
Validation loss: 4.0116544763247175

Epoch: 5| Step: 3
Training loss: 5.539792060852051
Validation loss: 4.006082048018773

Epoch: 5| Step: 4
Training loss: 3.457981586456299
Validation loss: 4.000878572463989

Epoch: 5| Step: 5
Training loss: 4.368033409118652
Validation loss: 3.9954370061556497

Epoch: 5| Step: 6
Training loss: 3.8829333782196045
Validation loss: 3.990697463353475

Epoch: 5| Step: 7
Training loss: 4.408486366271973
Validation loss: 3.985585073630015

Epoch: 5| Step: 8
Training loss: 3.6110920906066895
Validation loss: 3.980588068564733

Epoch: 5| Step: 9
Training loss: 3.695277452468872
Validation loss: 3.976273685693741

Epoch: 5| Step: 10
Training loss: 3.219482421875
Validation loss: 3.971541851758957

Epoch: 5| Step: 11
Training loss: 6.278594017028809
Validation loss: 3.9664922753969827

Epoch: 19| Step: 0
Training loss: 4.128518104553223
Validation loss: 3.9617452720801034

Epoch: 5| Step: 1
Training loss: 4.827014923095703
Validation loss: 3.9566151003042855

Epoch: 5| Step: 2
Training loss: 4.866197109222412
Validation loss: 3.952066014210383

Epoch: 5| Step: 3
Training loss: 3.7439332008361816
Validation loss: 3.9451270699501038

Epoch: 5| Step: 4
Training loss: 3.155646800994873
Validation loss: 3.940146575371424

Epoch: 5| Step: 5
Training loss: 3.5772852897644043
Validation loss: 3.9370464384555817

Epoch: 5| Step: 6
Training loss: 4.479439735412598
Validation loss: 3.931912591060003

Epoch: 5| Step: 7
Training loss: 4.717528820037842
Validation loss: 3.9266910751660666

Epoch: 5| Step: 8
Training loss: 3.964754581451416
Validation loss: 3.921292314926783

Epoch: 5| Step: 9
Training loss: 3.995868682861328
Validation loss: 3.915814151366552

Epoch: 5| Step: 10
Training loss: 3.500342607498169
Validation loss: 3.9115514556566873

Epoch: 5| Step: 11
Training loss: 3.866611957550049
Validation loss: 3.9071211020151773

Epoch: 20| Step: 0
Training loss: 4.051295280456543
Validation loss: 3.901531765858332

Epoch: 5| Step: 1
Training loss: 3.866727113723755
Validation loss: 3.8967307806015015

Epoch: 5| Step: 2
Training loss: 3.9699645042419434
Validation loss: 3.891908178726832

Epoch: 5| Step: 3
Training loss: 4.393537998199463
Validation loss: 3.8866951366265616

Epoch: 5| Step: 4
Training loss: 3.37434720993042
Validation loss: 3.882399986187617

Epoch: 5| Step: 5
Training loss: 3.911940097808838
Validation loss: 3.8769326508045197

Epoch: 5| Step: 6
Training loss: 3.5690274238586426
Validation loss: 3.872532397508621

Epoch: 5| Step: 7
Training loss: 3.6629855632781982
Validation loss: 3.867779473463694

Epoch: 5| Step: 8
Training loss: 5.080650329589844
Validation loss: 3.8623983959356942

Epoch: 5| Step: 9
Training loss: 4.717881679534912
Validation loss: 3.8575968543688455

Epoch: 5| Step: 10
Training loss: 3.8663437366485596
Validation loss: 3.8530387779076896

Epoch: 5| Step: 11
Training loss: 3.2428536415100098
Validation loss: 3.8482417464256287

Epoch: 21| Step: 0
Training loss: 3.9436097145080566
Validation loss: 3.8448909918467202

Epoch: 5| Step: 1
Training loss: 4.5143022537231445
Validation loss: 3.8404512206713357

Epoch: 5| Step: 2
Training loss: 4.35044002532959
Validation loss: 3.8352131942907968

Epoch: 5| Step: 3
Training loss: 3.345196485519409
Validation loss: 3.8297070960203805

Epoch: 5| Step: 4
Training loss: 4.199743270874023
Validation loss: 3.8252059320608773

Epoch: 5| Step: 5
Training loss: 3.6503772735595703
Validation loss: 3.821233650048574

Epoch: 5| Step: 6
Training loss: 4.469076633453369
Validation loss: 3.81705704331398

Epoch: 5| Step: 7
Training loss: 4.065586090087891
Validation loss: 3.8133294781049094

Epoch: 5| Step: 8
Training loss: 4.254315376281738
Validation loss: 3.8085029224554696

Epoch: 5| Step: 9
Training loss: 2.999849796295166
Validation loss: 3.803505311409632

Epoch: 5| Step: 10
Training loss: 3.5774168968200684
Validation loss: 3.7987120350201926

Epoch: 5| Step: 11
Training loss: 5.793992042541504
Validation loss: 3.7939452628294625

Epoch: 22| Step: 0
Training loss: 3.9685370922088623
Validation loss: 3.7901508708794913

Epoch: 5| Step: 1
Training loss: 4.073077201843262
Validation loss: 3.786530097325643

Epoch: 5| Step: 2
Training loss: 4.692180156707764
Validation loss: 3.782902250687281

Epoch: 5| Step: 3
Training loss: 3.6030259132385254
Validation loss: 3.7789167563120523

Epoch: 5| Step: 4
Training loss: 4.504586219787598
Validation loss: 3.7738570272922516

Epoch: 5| Step: 5
Training loss: 4.9795637130737305
Validation loss: 3.768293877442678

Epoch: 5| Step: 6
Training loss: 3.374925136566162
Validation loss: 3.7639853060245514

Epoch: 5| Step: 7
Training loss: 4.000500679016113
Validation loss: 3.7596872548262277

Epoch: 5| Step: 8
Training loss: 3.8212852478027344
Validation loss: 3.755674034357071

Epoch: 5| Step: 9
Training loss: 3.5361900329589844
Validation loss: 3.7523817121982574

Epoch: 5| Step: 10
Training loss: 2.8288700580596924
Validation loss: 3.7497617602348328

Epoch: 5| Step: 11
Training loss: 3.0014514923095703
Validation loss: 3.74332324663798

Epoch: 23| Step: 0
Training loss: 4.084802627563477
Validation loss: 3.7389027078946433

Epoch: 5| Step: 1
Training loss: 3.7242932319641113
Validation loss: 3.7347584466139474

Epoch: 5| Step: 2
Training loss: 4.171789646148682
Validation loss: 3.730399876832962

Epoch: 5| Step: 3
Training loss: 4.582074165344238
Validation loss: 3.726534773906072

Epoch: 5| Step: 4
Training loss: 3.331861972808838
Validation loss: 3.7226579089959464

Epoch: 5| Step: 5
Training loss: 3.5197014808654785
Validation loss: 3.7189688682556152

Epoch: 5| Step: 6
Training loss: 3.749899387359619
Validation loss: 3.7152631183465323

Epoch: 5| Step: 7
Training loss: 4.270491600036621
Validation loss: 3.710933635632197

Epoch: 5| Step: 8
Training loss: 3.3434410095214844
Validation loss: 3.707208037376404

Epoch: 5| Step: 9
Training loss: 4.015538692474365
Validation loss: 3.703667273124059

Epoch: 5| Step: 10
Training loss: 3.86352276802063
Validation loss: 3.6992133458455405

Epoch: 5| Step: 11
Training loss: 3.9394407272338867
Validation loss: 3.695586343606313

Epoch: 24| Step: 0
Training loss: 3.7896018028259277
Validation loss: 3.691293219725291

Epoch: 5| Step: 1
Training loss: 4.104457855224609
Validation loss: 3.6874998013178506

Epoch: 5| Step: 2
Training loss: 2.5459516048431396
Validation loss: 3.6834429800510406

Epoch: 5| Step: 3
Training loss: 3.4802780151367188
Validation loss: 3.679538538058599

Epoch: 5| Step: 4
Training loss: 2.8560738563537598
Validation loss: 3.676403741041819

Epoch: 5| Step: 5
Training loss: 3.603048324584961
Validation loss: 3.6726565659046173

Epoch: 5| Step: 6
Training loss: 4.013009071350098
Validation loss: 3.66938653588295

Epoch: 5| Step: 7
Training loss: 4.335616111755371
Validation loss: 3.664405266443888

Epoch: 5| Step: 8
Training loss: 4.6962432861328125
Validation loss: 3.6601260900497437

Epoch: 5| Step: 9
Training loss: 4.106912136077881
Validation loss: 3.656267633040746

Epoch: 5| Step: 10
Training loss: 4.590161323547363
Validation loss: 3.6520844399929047

Epoch: 5| Step: 11
Training loss: 3.978409767150879
Validation loss: 3.648421416680018

Epoch: 25| Step: 0
Training loss: 4.082828521728516
Validation loss: 3.6449373364448547

Epoch: 5| Step: 1
Training loss: 3.827491283416748
Validation loss: 3.639932612578074

Epoch: 5| Step: 2
Training loss: 2.6745288372039795
Validation loss: 3.635564605394999

Epoch: 5| Step: 3
Training loss: 3.8721091747283936
Validation loss: 3.63136026263237

Epoch: 5| Step: 4
Training loss: 4.042726516723633
Validation loss: 3.6270387768745422

Epoch: 5| Step: 5
Training loss: 3.813828229904175
Validation loss: 3.6234469016393027

Epoch: 5| Step: 6
Training loss: 3.9007210731506348
Validation loss: 3.6193703015645347

Epoch: 5| Step: 7
Training loss: 4.1901140213012695
Validation loss: 3.6159229775269828

Epoch: 5| Step: 8
Training loss: 3.759199857711792
Validation loss: 3.6113233069578805

Epoch: 5| Step: 9
Training loss: 3.8845512866973877
Validation loss: 3.6070423622926078

Epoch: 5| Step: 10
Training loss: 3.6118011474609375
Validation loss: 3.602314015229543

Epoch: 5| Step: 11
Training loss: 3.7152185440063477
Validation loss: 3.5986958940823874

Epoch: 26| Step: 0
Training loss: 4.0612921714782715
Validation loss: 3.594681908686956

Epoch: 5| Step: 1
Training loss: 4.270300388336182
Validation loss: 3.5902644296487174

Epoch: 5| Step: 2
Training loss: 4.4529218673706055
Validation loss: 3.586397190888723

Epoch: 5| Step: 3
Training loss: 3.605144500732422
Validation loss: 3.5815851986408234

Epoch: 5| Step: 4
Training loss: 3.6871936321258545
Validation loss: 3.577536235253016

Epoch: 5| Step: 5
Training loss: 4.104739665985107
Validation loss: 3.5737701257069907

Epoch: 5| Step: 6
Training loss: 3.8070647716522217
Validation loss: 3.570716917514801

Epoch: 5| Step: 7
Training loss: 3.1497464179992676
Validation loss: 3.5657630960146585

Epoch: 5| Step: 8
Training loss: 3.0986666679382324
Validation loss: 3.5613644123077393

Epoch: 5| Step: 9
Training loss: 3.190763473510742
Validation loss: 3.5573126475016275

Epoch: 5| Step: 10
Training loss: 3.6531200408935547
Validation loss: 3.5530003805955253

Epoch: 5| Step: 11
Training loss: 3.906857967376709
Validation loss: 3.5497024854024253

Epoch: 27| Step: 0
Training loss: 3.547253131866455
Validation loss: 3.5453188916047416

Epoch: 5| Step: 1
Training loss: 4.13250207901001
Validation loss: 3.541704664627711

Epoch: 5| Step: 2
Training loss: 3.70662260055542
Validation loss: 3.5369258423646293

Epoch: 5| Step: 3
Training loss: 4.362736701965332
Validation loss: 3.5329286257425943

Epoch: 5| Step: 4
Training loss: 3.4788756370544434
Validation loss: 3.5289115607738495

Epoch: 5| Step: 5
Training loss: 2.773308753967285
Validation loss: 3.523943622907003

Epoch: 5| Step: 6
Training loss: 3.8234145641326904
Validation loss: 3.5197865068912506

Epoch: 5| Step: 7
Training loss: 3.167282819747925
Validation loss: 3.5158973733584085

Epoch: 5| Step: 8
Training loss: 4.300868988037109
Validation loss: 3.5118354062239328

Epoch: 5| Step: 9
Training loss: 3.510706663131714
Validation loss: 3.507763147354126

Epoch: 5| Step: 10
Training loss: 3.9523346424102783
Validation loss: 3.5036986768245697

Epoch: 5| Step: 11
Training loss: 2.8673934936523438
Validation loss: 3.49989253282547

Epoch: 28| Step: 0
Training loss: 3.3878140449523926
Validation loss: 3.4958016872406006

Epoch: 5| Step: 1
Training loss: 3.7135512828826904
Validation loss: 3.49203222990036

Epoch: 5| Step: 2
Training loss: 3.509972333908081
Validation loss: 3.4881001313527427

Epoch: 5| Step: 3
Training loss: 3.7073287963867188
Validation loss: 3.4841847519079843

Epoch: 5| Step: 4
Training loss: 3.547856092453003
Validation loss: 3.479693353176117

Epoch: 5| Step: 5
Training loss: 4.509091854095459
Validation loss: 3.4756573537985482

Epoch: 5| Step: 6
Training loss: 3.3406729698181152
Validation loss: 3.470990300178528

Epoch: 5| Step: 7
Training loss: 3.5595240592956543
Validation loss: 3.4669069747130075

Epoch: 5| Step: 8
Training loss: 2.876981735229492
Validation loss: 3.463325967391332

Epoch: 5| Step: 9
Training loss: 4.1209797859191895
Validation loss: 3.4589952528476715

Epoch: 5| Step: 10
Training loss: 3.3043036460876465
Validation loss: 3.4546779493490853

Epoch: 5| Step: 11
Training loss: 6.008238792419434
Validation loss: 3.450105388959249

Epoch: 29| Step: 0
Training loss: 3.187225580215454
Validation loss: 3.4462658564249673

Epoch: 5| Step: 1
Training loss: 3.3369128704071045
Validation loss: 3.4417066077391305

Epoch: 5| Step: 2
Training loss: 3.823880672454834
Validation loss: 3.4377870857715607

Epoch: 5| Step: 3
Training loss: 3.9393069744110107
Validation loss: 3.432945966720581

Epoch: 5| Step: 4
Training loss: 3.629455089569092
Validation loss: 3.4285297195116677

Epoch: 5| Step: 5
Training loss: 3.7861976623535156
Validation loss: 3.4245035350322723

Epoch: 5| Step: 6
Training loss: 4.435356140136719
Validation loss: 3.4205898443857827

Epoch: 5| Step: 7
Training loss: 3.2496981620788574
Validation loss: 3.416608194510142

Epoch: 5| Step: 8
Training loss: 3.8696811199188232
Validation loss: 3.412326842546463

Epoch: 5| Step: 9
Training loss: 3.2385730743408203
Validation loss: 3.4082683424154916

Epoch: 5| Step: 10
Training loss: 3.0931785106658936
Validation loss: 3.404043028752009

Epoch: 5| Step: 11
Training loss: 3.2461225986480713
Validation loss: 3.3997788429260254

Epoch: 30| Step: 0
Training loss: 2.461190700531006
Validation loss: 3.395866245031357

Epoch: 5| Step: 1
Training loss: 3.7540957927703857
Validation loss: 3.392997165520986

Epoch: 5| Step: 2
Training loss: 3.2491774559020996
Validation loss: 3.3892532090346017

Epoch: 5| Step: 3
Training loss: 4.0808939933776855
Validation loss: 3.3867612381776175

Epoch: 5| Step: 4
Training loss: 3.4660048484802246
Validation loss: 3.381065607070923

Epoch: 5| Step: 5
Training loss: 3.509350299835205
Validation loss: 3.375819524129232

Epoch: 5| Step: 6
Training loss: 3.9716217517852783
Validation loss: 3.372774511575699

Epoch: 5| Step: 7
Training loss: 4.1732497215271
Validation loss: 3.368781268596649

Epoch: 5| Step: 8
Training loss: 4.108285427093506
Validation loss: 3.36499160528183

Epoch: 5| Step: 9
Training loss: 2.9288625717163086
Validation loss: 3.3608179787794747

Epoch: 5| Step: 10
Training loss: 3.755556583404541
Validation loss: 3.3571423391501107

Epoch: 5| Step: 11
Training loss: 1.2876063585281372
Validation loss: 3.3531800508499146

Epoch: 31| Step: 0
Training loss: 3.5991902351379395
Validation loss: 3.349832991758982

Epoch: 5| Step: 1
Training loss: 3.25641131401062
Validation loss: 3.3468376199404397

Epoch: 5| Step: 2
Training loss: 3.201342821121216
Validation loss: 3.3429005444049835

Epoch: 5| Step: 3
Training loss: 3.1915037631988525
Validation loss: 3.3394402166207633

Epoch: 5| Step: 4
Training loss: 3.404801845550537
Validation loss: 3.33601912856102

Epoch: 5| Step: 5
Training loss: 3.3069984912872314
Validation loss: 3.3320749203364053

Epoch: 5| Step: 6
Training loss: 4.114150047302246
Validation loss: 3.3285082578659058

Epoch: 5| Step: 7
Training loss: 2.845503568649292
Validation loss: 3.324627071619034

Epoch: 5| Step: 8
Training loss: 2.969210147857666
Validation loss: 3.321433107058207

Epoch: 5| Step: 9
Training loss: 4.419097423553467
Validation loss: 3.3175801932811737

Epoch: 5| Step: 10
Training loss: 4.139657020568848
Validation loss: 3.314158866802851

Epoch: 5| Step: 11
Training loss: 3.963914394378662
Validation loss: 3.311186581850052

Epoch: 32| Step: 0
Training loss: 3.091204881668091
Validation loss: 3.30791707833608

Epoch: 5| Step: 1
Training loss: 4.493271827697754
Validation loss: 3.303731322288513

Epoch: 5| Step: 2
Training loss: 3.2863121032714844
Validation loss: 3.299655248721441

Epoch: 5| Step: 3
Training loss: 3.078597068786621
Validation loss: 3.2951000233491263

Epoch: 5| Step: 4
Training loss: 3.4145729541778564
Validation loss: 3.291575809319814

Epoch: 5| Step: 5
Training loss: 2.47334361076355
Validation loss: 3.2869706054528556

Epoch: 5| Step: 6
Training loss: 3.2249348163604736
Validation loss: 3.2832068105538688

Epoch: 5| Step: 7
Training loss: 4.40596342086792
Validation loss: 3.280626873175303

Epoch: 5| Step: 8
Training loss: 3.291426181793213
Validation loss: 3.2765731712182364

Epoch: 5| Step: 9
Training loss: 3.2893550395965576
Validation loss: 3.2732116281986237

Epoch: 5| Step: 10
Training loss: 4.117827415466309
Validation loss: 3.2697739799817405

Epoch: 5| Step: 11
Training loss: 3.0972251892089844
Validation loss: 3.269894599914551

Epoch: 33| Step: 0
Training loss: 3.5987141132354736
Validation loss: 3.2725737194220224

Epoch: 5| Step: 1
Training loss: 3.729154109954834
Validation loss: 3.2587261299292245

Epoch: 5| Step: 2
Training loss: 2.7777209281921387
Validation loss: 3.25541161497434

Epoch: 5| Step: 3
Training loss: 4.293610095977783
Validation loss: 3.251811444759369

Epoch: 5| Step: 4
Training loss: 3.2353718280792236
Validation loss: 3.2476582527160645

Epoch: 5| Step: 5
Training loss: 2.8984084129333496
Validation loss: 3.244211971759796

Epoch: 5| Step: 6
Training loss: 3.0365402698516846
Validation loss: 3.24016934633255

Epoch: 5| Step: 7
Training loss: 3.1625351905822754
Validation loss: 3.2362665931383767

Epoch: 5| Step: 8
Training loss: 3.70375394821167
Validation loss: 3.2322005530198417

Epoch: 5| Step: 9
Training loss: 3.5484280586242676
Validation loss: 3.2280116776625314

Epoch: 5| Step: 10
Training loss: 3.7324745655059814
Validation loss: 3.22455370426178

Epoch: 5| Step: 11
Training loss: 3.072183132171631
Validation loss: 3.2213115990161896

Epoch: 34| Step: 0
Training loss: 3.096041440963745
Validation loss: 3.2180255154768624

Epoch: 5| Step: 1
Training loss: 3.040910243988037
Validation loss: 3.215057283639908

Epoch: 5| Step: 2
Training loss: 4.223325729370117
Validation loss: 3.2109776039918265

Epoch: 5| Step: 3
Training loss: 3.6208713054656982
Validation loss: 3.207111338774363

Epoch: 5| Step: 4
Training loss: 3.392965316772461
Validation loss: 3.203548143307368

Epoch: 5| Step: 5
Training loss: 3.1807217597961426
Validation loss: 3.2007069885730743

Epoch: 5| Step: 6
Training loss: 3.3048202991485596
Validation loss: 3.1972894271214805

Epoch: 5| Step: 7
Training loss: 3.394231081008911
Validation loss: 3.19404407342275

Epoch: 5| Step: 8
Training loss: 3.3598029613494873
Validation loss: 3.1907092233498893

Epoch: 5| Step: 9
Training loss: 3.251328945159912
Validation loss: 3.1880185504754386

Epoch: 5| Step: 10
Training loss: 3.2658028602600098
Validation loss: 3.1827818055947623

Epoch: 5| Step: 11
Training loss: 3.6442599296569824
Validation loss: 3.17860742410024

Epoch: 35| Step: 0
Training loss: 3.3746514320373535
Validation loss: 3.175117313861847

Epoch: 5| Step: 1
Training loss: 4.0059051513671875
Validation loss: 3.1709634761015573

Epoch: 5| Step: 2
Training loss: 3.7813994884490967
Validation loss: 3.168012499809265

Epoch: 5| Step: 3
Training loss: 3.40144681930542
Validation loss: 3.1653206745783486

Epoch: 5| Step: 4
Training loss: 3.334794521331787
Validation loss: 3.161315123240153

Epoch: 5| Step: 5
Training loss: 2.667198896408081
Validation loss: 3.1575553913911185

Epoch: 5| Step: 6
Training loss: 3.763098955154419
Validation loss: 3.1531825562318168

Epoch: 5| Step: 7
Training loss: 3.1618688106536865
Validation loss: 3.149162987867991

Epoch: 5| Step: 8
Training loss: 3.480288028717041
Validation loss: 3.1462141573429108

Epoch: 5| Step: 9
Training loss: 2.3505494594573975
Validation loss: 3.141794582207998

Epoch: 5| Step: 10
Training loss: 3.582256317138672
Validation loss: 3.1376406848430634

Epoch: 5| Step: 11
Training loss: 2.6323390007019043
Validation loss: 3.133799731731415

Epoch: 36| Step: 0
Training loss: 3.004517078399658
Validation loss: 3.1304397583007812

Epoch: 5| Step: 1
Training loss: 3.7289092540740967
Validation loss: 3.1269811491171517

Epoch: 5| Step: 2
Training loss: 3.090080976486206
Validation loss: 3.1237847606341043

Epoch: 5| Step: 3
Training loss: 3.591599702835083
Validation loss: 3.1194093922773996

Epoch: 5| Step: 4
Training loss: 3.3023934364318848
Validation loss: 3.116856853167216

Epoch: 5| Step: 5
Training loss: 3.2791199684143066
Validation loss: 3.1129204630851746

Epoch: 5| Step: 6
Training loss: 3.577127456665039
Validation loss: 3.109149863322576

Epoch: 5| Step: 7
Training loss: 3.8355743885040283
Validation loss: 3.105689505736033

Epoch: 5| Step: 8
Training loss: 3.464768886566162
Validation loss: 3.103308250506719

Epoch: 5| Step: 9
Training loss: 2.8465497493743896
Validation loss: 3.1003369788328805

Epoch: 5| Step: 10
Training loss: 2.7852282524108887
Validation loss: 3.097424487272898

Epoch: 5| Step: 11
Training loss: 2.255505084991455
Validation loss: 3.0953483879566193

Epoch: 37| Step: 0
Training loss: 3.367673397064209
Validation loss: 3.1206995646158853

Epoch: 5| Step: 1
Training loss: 3.252178192138672
Validation loss: 3.124544233083725

Epoch: 5| Step: 2
Training loss: 3.8408432006835938
Validation loss: 3.1117910146713257

Epoch: 5| Step: 3
Training loss: 3.529885768890381
Validation loss: 3.085077633460363

Epoch: 5| Step: 4
Training loss: 2.890101432800293
Validation loss: 3.075100223223368

Epoch: 5| Step: 5
Training loss: 2.8282790184020996
Validation loss: 3.0841495295365653

Epoch: 5| Step: 6
Training loss: 3.3664698600769043
Validation loss: 3.0866661866505942

Epoch: 5| Step: 7
Training loss: 3.4808907508850098
Validation loss: 3.071457177400589

Epoch: 5| Step: 8
Training loss: 2.636709451675415
Validation loss: 3.0693583389123282

Epoch: 5| Step: 9
Training loss: 3.0408220291137695
Validation loss: 3.0777732829252877

Epoch: 5| Step: 10
Training loss: 3.972019910812378
Validation loss: 3.078826983769735

Epoch: 5| Step: 11
Training loss: 2.560478448867798
Validation loss: 3.058064262072245

Epoch: 38| Step: 0
Training loss: 3.375932216644287
Validation loss: 3.051710476477941

Epoch: 5| Step: 1
Training loss: 3.842545747756958
Validation loss: 3.0486042400201163

Epoch: 5| Step: 2
Training loss: 3.131704330444336
Validation loss: 3.046290397644043

Epoch: 5| Step: 3
Training loss: 2.9482076168060303
Validation loss: 3.0441423853238425

Epoch: 5| Step: 4
Training loss: 2.948840856552124
Validation loss: 3.0436094105243683

Epoch: 5| Step: 5
Training loss: 3.046470880508423
Validation loss: 3.048069794972738

Epoch: 5| Step: 6
Training loss: 3.038750648498535
Validation loss: 3.0358566542466483

Epoch: 5| Step: 7
Training loss: 3.2157695293426514
Validation loss: 3.029348055521647

Epoch: 5| Step: 8
Training loss: 2.831536054611206
Validation loss: 3.024260252714157

Epoch: 5| Step: 9
Training loss: 3.1696009635925293
Validation loss: 3.021191497643789

Epoch: 5| Step: 10
Training loss: 3.744689464569092
Validation loss: 3.017076462507248

Epoch: 5| Step: 11
Training loss: 4.300607681274414
Validation loss: 3.0153719584147134

Epoch: 39| Step: 0
Training loss: 3.218188524246216
Validation loss: 3.0118722319602966

Epoch: 5| Step: 1
Training loss: 2.905069351196289
Validation loss: 3.008862962325414

Epoch: 5| Step: 2
Training loss: 2.93202805519104
Validation loss: 3.0060385862986245

Epoch: 5| Step: 3
Training loss: 3.231558322906494
Validation loss: 3.002351293961207

Epoch: 5| Step: 4
Training loss: 3.106266975402832
Validation loss: 2.998964269955953

Epoch: 5| Step: 5
Training loss: 3.547753095626831
Validation loss: 2.9940525194009147

Epoch: 5| Step: 6
Training loss: 3.1103577613830566
Validation loss: 2.990524778763453

Epoch: 5| Step: 7
Training loss: 3.1355814933776855
Validation loss: 2.9873551627000174

Epoch: 5| Step: 8
Training loss: 3.5657455921173096
Validation loss: 2.9834300577640533

Epoch: 5| Step: 9
Training loss: 3.778395891189575
Validation loss: 2.980661223332087

Epoch: 5| Step: 10
Training loss: 2.8748068809509277
Validation loss: 2.975553572177887

Epoch: 5| Step: 11
Training loss: 1.4768774509429932
Validation loss: 2.972098797559738

Epoch: 40| Step: 0
Training loss: 3.1495201587677
Validation loss: 2.9690235257148743

Epoch: 5| Step: 1
Training loss: 3.0949745178222656
Validation loss: 2.9663208723068237

Epoch: 5| Step: 2
Training loss: 3.1206376552581787
Validation loss: 2.9639762341976166

Epoch: 5| Step: 3
Training loss: 2.9857699871063232
Validation loss: 2.9597092270851135

Epoch: 5| Step: 4
Training loss: 3.184011697769165
Validation loss: 2.9581619103749595

Epoch: 5| Step: 5
Training loss: 2.848771333694458
Validation loss: 2.9547248780727386

Epoch: 5| Step: 6
Training loss: 3.242833375930786
Validation loss: 2.9546841581662497

Epoch: 5| Step: 7
Training loss: 3.005497694015503
Validation loss: 2.949386457602183

Epoch: 5| Step: 8
Training loss: 3.4077868461608887
Validation loss: 2.9455430706342063

Epoch: 5| Step: 9
Training loss: 3.231889247894287
Validation loss: 2.9426248570283255

Epoch: 5| Step: 10
Training loss: 3.2458443641662598
Validation loss: 2.9394807318846383

Epoch: 5| Step: 11
Training loss: 3.8298988342285156
Validation loss: 2.93642728527387

Epoch: 41| Step: 0
Training loss: 3.3742599487304688
Validation loss: 2.9331824680169425

Epoch: 5| Step: 1
Training loss: 2.75242280960083
Validation loss: 2.9301403065522513

Epoch: 5| Step: 2
Training loss: 3.6126320362091064
Validation loss: 2.9266503949960074

Epoch: 5| Step: 3
Training loss: 3.1355502605438232
Validation loss: 2.922542949517568

Epoch: 5| Step: 4
Training loss: 3.0819408893585205
Validation loss: 2.9193369646867118

Epoch: 5| Step: 5
Training loss: 2.8437047004699707
Validation loss: 2.916652719179789

Epoch: 5| Step: 6
Training loss: 3.3217415809631348
Validation loss: 2.913605888684591

Epoch: 5| Step: 7
Training loss: 3.1584384441375732
Validation loss: 2.909655819336573

Epoch: 5| Step: 8
Training loss: 3.3561606407165527
Validation loss: 2.906872401634852

Epoch: 5| Step: 9
Training loss: 2.816333293914795
Validation loss: 2.9034077326456704

Epoch: 5| Step: 10
Training loss: 3.105056047439575
Validation loss: 2.900722086429596

Epoch: 5| Step: 11
Training loss: 1.924203634262085
Validation loss: 2.899118016163508

Epoch: 42| Step: 0
Training loss: 3.1334228515625
Validation loss: 2.895636429389318

Epoch: 5| Step: 1
Training loss: 3.2651264667510986
Validation loss: 2.8923936684926352

Epoch: 5| Step: 2
Training loss: 3.259334087371826
Validation loss: 2.88995827237765

Epoch: 5| Step: 3
Training loss: 2.794321298599243
Validation loss: 2.8908690412839255

Epoch: 5| Step: 4
Training loss: 3.1317827701568604
Validation loss: 2.885119875272115

Epoch: 5| Step: 5
Training loss: 3.4979758262634277
Validation loss: 2.8806863029797873

Epoch: 5| Step: 6
Training loss: 2.6199002265930176
Validation loss: 2.8750871419906616

Epoch: 5| Step: 7
Training loss: 3.0400898456573486
Validation loss: 2.869717985391617

Epoch: 5| Step: 8
Training loss: 3.421283006668091
Validation loss: 2.8685740729173026

Epoch: 5| Step: 9
Training loss: 3.376155138015747
Validation loss: 2.8655544817447662

Epoch: 5| Step: 10
Training loss: 2.644035816192627
Validation loss: 2.8626726468404136

Epoch: 5| Step: 11
Training loss: 1.9439657926559448
Validation loss: 2.859330495198568

Epoch: 43| Step: 0
Training loss: 3.2863662242889404
Validation loss: 2.856585075457891

Epoch: 5| Step: 1
Training loss: 2.6230661869049072
Validation loss: 2.8533999224503837

Epoch: 5| Step: 2
Training loss: 2.563439130783081
Validation loss: 2.8505362470944724

Epoch: 5| Step: 3
Training loss: 2.787224054336548
Validation loss: 2.8483497351408005

Epoch: 5| Step: 4
Training loss: 3.3841652870178223
Validation loss: 2.8448374370733895

Epoch: 5| Step: 5
Training loss: 2.7875077724456787
Validation loss: 2.842189610004425

Epoch: 5| Step: 6
Training loss: 2.9543404579162598
Validation loss: 2.839195817708969

Epoch: 5| Step: 7
Training loss: 3.4310479164123535
Validation loss: 2.8367386758327484

Epoch: 5| Step: 8
Training loss: 3.516179323196411
Validation loss: 2.833738466103872

Epoch: 5| Step: 9
Training loss: 3.037675380706787
Validation loss: 2.8310276369253793

Epoch: 5| Step: 10
Training loss: 3.106506824493408
Validation loss: 2.8280438284079232

Epoch: 5| Step: 11
Training loss: 3.5577447414398193
Validation loss: 2.824442813793818

Epoch: 44| Step: 0
Training loss: 3.4375369548797607
Validation loss: 2.822049379348755

Epoch: 5| Step: 1
Training loss: 2.8722143173217773
Validation loss: 2.818806846936544

Epoch: 5| Step: 2
Training loss: 3.0997543334960938
Validation loss: 2.816467523574829

Epoch: 5| Step: 3
Training loss: 2.7585606575012207
Validation loss: 2.8125896751880646

Epoch: 5| Step: 4
Training loss: 3.126805067062378
Validation loss: 2.809883644183477

Epoch: 5| Step: 5
Training loss: 2.8397574424743652
Validation loss: 2.80703858534495

Epoch: 5| Step: 6
Training loss: 3.7686705589294434
Validation loss: 2.805083562930425

Epoch: 5| Step: 7
Training loss: 2.5443406105041504
Validation loss: 2.801873137553533

Epoch: 5| Step: 8
Training loss: 2.968703508377075
Validation loss: 2.7993297576904297

Epoch: 5| Step: 9
Training loss: 3.023651599884033
Validation loss: 2.796613405148188

Epoch: 5| Step: 10
Training loss: 2.604367256164551
Validation loss: 2.7922508815924325

Epoch: 5| Step: 11
Training loss: 3.8466062545776367
Validation loss: 2.7903904020786285

Epoch: 45| Step: 0
Training loss: 2.8071627616882324
Validation loss: 2.7890935639540353

Epoch: 5| Step: 1
Training loss: 2.929903268814087
Validation loss: 2.786441832780838

Epoch: 5| Step: 2
Training loss: 3.200899124145508
Validation loss: 2.783935099840164

Epoch: 5| Step: 3
Training loss: 2.2682313919067383
Validation loss: 2.780381361643473

Epoch: 5| Step: 4
Training loss: 3.0595524311065674
Validation loss: 2.775913337866465

Epoch: 5| Step: 5
Training loss: 3.45295786857605
Validation loss: 2.7734945813814798

Epoch: 5| Step: 6
Training loss: 3.0523293018341064
Validation loss: 2.7714325288931527

Epoch: 5| Step: 7
Training loss: 3.0860953330993652
Validation loss: 2.769892781972885

Epoch: 5| Step: 8
Training loss: 3.2899768352508545
Validation loss: 2.7656873365243277

Epoch: 5| Step: 9
Training loss: 3.0278563499450684
Validation loss: 2.763029267390569

Epoch: 5| Step: 10
Training loss: 2.4749436378479004
Validation loss: 2.7628902594248452

Epoch: 5| Step: 11
Training loss: 3.7657999992370605
Validation loss: 2.758219619592031

Epoch: 46| Step: 0
Training loss: 2.4315922260284424
Validation loss: 2.7603730956713357

Epoch: 5| Step: 1
Training loss: 2.5682029724121094
Validation loss: 2.7860978543758392

Epoch: 5| Step: 2
Training loss: 3.7852330207824707
Validation loss: 2.8380297223726907

Epoch: 5| Step: 3
Training loss: 2.4919593334198
Validation loss: 2.8223711450894675

Epoch: 5| Step: 4
Training loss: 2.47875714302063
Validation loss: 2.8114232818285623

Epoch: 5| Step: 5
Training loss: 2.8578124046325684
Validation loss: 2.803680499394735

Epoch: 5| Step: 6
Training loss: 2.824570655822754
Validation loss: 2.798266420761744

Epoch: 5| Step: 7
Training loss: 3.295030117034912
Validation loss: 2.7957850197950997

Epoch: 5| Step: 8
Training loss: 3.487250566482544
Validation loss: 2.7867557207743325

Epoch: 5| Step: 9
Training loss: 3.1711108684539795
Validation loss: 2.783090124527613

Epoch: 5| Step: 10
Training loss: 3.447089672088623
Validation loss: 2.779934883117676

Epoch: 5| Step: 11
Training loss: 3.8109383583068848
Validation loss: 2.77389720082283

Epoch: 47| Step: 0
Training loss: 3.003035068511963
Validation loss: 2.7729937930901847

Epoch: 5| Step: 1
Training loss: 3.6213538646698
Validation loss: 2.7638439734776816

Epoch: 5| Step: 2
Training loss: 3.1525208950042725
Validation loss: 2.7396747867266336

Epoch: 5| Step: 3
Training loss: 2.4487826824188232
Validation loss: 2.720165212949117

Epoch: 5| Step: 4
Training loss: 2.691376209259033
Validation loss: 2.7151317099730172

Epoch: 5| Step: 5
Training loss: 2.8918116092681885
Validation loss: 2.7135625183582306

Epoch: 5| Step: 6
Training loss: 2.79980206489563
Validation loss: 2.7128292620182037

Epoch: 5| Step: 7
Training loss: 3.40594744682312
Validation loss: 2.708643317222595

Epoch: 5| Step: 8
Training loss: 2.5486607551574707
Validation loss: 2.706817885239919

Epoch: 5| Step: 9
Training loss: 2.309128522872925
Validation loss: 2.7052893340587616

Epoch: 5| Step: 10
Training loss: 3.1060149669647217
Validation loss: 2.702168713013331

Epoch: 5| Step: 11
Training loss: 4.374675750732422
Validation loss: 2.6968681613604226

Epoch: 48| Step: 0
Training loss: 3.549283504486084
Validation loss: 2.693783402442932

Epoch: 5| Step: 1
Training loss: 2.8245129585266113
Validation loss: 2.689021944999695

Epoch: 5| Step: 2
Training loss: 2.525447130203247
Validation loss: 2.6844200988610587

Epoch: 5| Step: 3
Training loss: 2.3712377548217773
Validation loss: 2.6808707217375436

Epoch: 5| Step: 4
Training loss: 3.046823024749756
Validation loss: 2.6786029835542045

Epoch: 5| Step: 5
Training loss: 3.0312857627868652
Validation loss: 2.676640202601751

Epoch: 5| Step: 6
Training loss: 2.584751605987549
Validation loss: 2.674924224615097

Epoch: 5| Step: 7
Training loss: 2.6004741191864014
Validation loss: 2.67283903559049

Epoch: 5| Step: 8
Training loss: 2.7696659564971924
Validation loss: 2.672862082719803

Epoch: 5| Step: 9
Training loss: 3.3908798694610596
Validation loss: 2.666556159655253

Epoch: 5| Step: 10
Training loss: 3.264228343963623
Validation loss: 2.66565011938413

Epoch: 5| Step: 11
Training loss: 1.6064016819000244
Validation loss: 2.6609253585338593

Epoch: 49| Step: 0
Training loss: 3.144568681716919
Validation loss: 2.6561860839525857

Epoch: 5| Step: 1
Training loss: 2.9949305057525635
Validation loss: 2.6496562361717224

Epoch: 5| Step: 2
Training loss: 3.52447509765625
Validation loss: 2.6469249427318573

Epoch: 5| Step: 3
Training loss: 3.0342822074890137
Validation loss: 2.6451446811358132

Epoch: 5| Step: 4
Training loss: 2.5887503623962402
Validation loss: 2.64395405848821

Epoch: 5| Step: 5
Training loss: 2.5877134799957275
Validation loss: 2.6420279244581857

Epoch: 5| Step: 6
Training loss: 2.848027229309082
Validation loss: 2.6391242345174155

Epoch: 5| Step: 7
Training loss: 3.0022034645080566
Validation loss: 2.635492126146952

Epoch: 5| Step: 8
Training loss: 1.9621083736419678
Validation loss: 2.633784602085749

Epoch: 5| Step: 9
Training loss: 3.0368270874023438
Validation loss: 2.63138077656428

Epoch: 5| Step: 10
Training loss: 2.793804168701172
Validation loss: 2.6279236376285553

Epoch: 5| Step: 11
Training loss: 1.6439385414123535
Validation loss: 2.625334252913793

Epoch: 50| Step: 0
Training loss: 2.6687817573547363
Validation loss: 2.620583802461624

Epoch: 5| Step: 1
Training loss: 2.868471145629883
Validation loss: 2.61707404255867

Epoch: 5| Step: 2
Training loss: 3.114830255508423
Validation loss: 2.6131846010684967

Epoch: 5| Step: 3
Training loss: 3.1300995349884033
Validation loss: 2.610105276107788

Epoch: 5| Step: 4
Training loss: 2.5083370208740234
Validation loss: 2.6067309379577637

Epoch: 5| Step: 5
Training loss: 2.2735695838928223
Validation loss: 2.602870096762975

Epoch: 5| Step: 6
Training loss: 3.051499605178833
Validation loss: 2.5993709564208984

Epoch: 5| Step: 7
Training loss: 2.641937732696533
Validation loss: 2.5961911578973136

Epoch: 5| Step: 8
Training loss: 2.879457950592041
Validation loss: 2.591491252183914

Epoch: 5| Step: 9
Training loss: 2.1703715324401855
Validation loss: 2.5864647130171456

Epoch: 5| Step: 10
Training loss: 3.4707820415496826
Validation loss: 2.584497610727946

Epoch: 5| Step: 11
Training loss: 3.2699530124664307
Validation loss: 2.5825565258661904

Epoch: 51| Step: 0
Training loss: 2.399296760559082
Validation loss: 2.5764629443486533

Epoch: 5| Step: 1
Training loss: 2.527728319168091
Validation loss: 2.5746978720029197

Epoch: 5| Step: 2
Training loss: 2.5403716564178467
Validation loss: 2.571736067533493

Epoch: 5| Step: 3
Training loss: 3.0762524604797363
Validation loss: 2.5682927866776786

Epoch: 5| Step: 4
Training loss: 3.5246434211730957
Validation loss: 2.5674850841363273

Epoch: 5| Step: 5
Training loss: 3.6221225261688232
Validation loss: 2.5656892359256744

Epoch: 5| Step: 6
Training loss: 2.6750988960266113
Validation loss: 2.5608633359273276

Epoch: 5| Step: 7
Training loss: 2.903066635131836
Validation loss: 2.556800772746404

Epoch: 5| Step: 8
Training loss: 2.5228593349456787
Validation loss: 2.5568032960096994

Epoch: 5| Step: 9
Training loss: 1.93914794921875
Validation loss: 2.5579580763975778

Epoch: 5| Step: 10
Training loss: 2.898451566696167
Validation loss: 2.5513839522997537

Epoch: 5| Step: 11
Training loss: 1.6383458375930786
Validation loss: 2.5535243650277457

Epoch: 52| Step: 0
Training loss: 2.74586820602417
Validation loss: 2.5489462415377298

Epoch: 5| Step: 1
Training loss: 2.7691092491149902
Validation loss: 2.5493857065836587

Epoch: 5| Step: 2
Training loss: 3.0822207927703857
Validation loss: 2.542200510700544

Epoch: 5| Step: 3
Training loss: 2.689213991165161
Validation loss: 2.5427610178788504

Epoch: 5| Step: 4
Training loss: 3.1286351680755615
Validation loss: 2.5354257822036743

Epoch: 5| Step: 5
Training loss: 2.302074432373047
Validation loss: 2.532369683186213

Epoch: 5| Step: 6
Training loss: 2.3405959606170654
Validation loss: 2.529717435439428

Epoch: 5| Step: 7
Training loss: 2.4754669666290283
Validation loss: 2.5282257298628488

Epoch: 5| Step: 8
Training loss: 3.0568909645080566
Validation loss: 2.526242862145106

Epoch: 5| Step: 9
Training loss: 2.4088079929351807
Validation loss: 2.5218027234077454

Epoch: 5| Step: 10
Training loss: 2.971642017364502
Validation loss: 2.5208961963653564

Epoch: 5| Step: 11
Training loss: 2.849729061126709
Validation loss: 2.5197485089302063

Epoch: 53| Step: 0
Training loss: 2.840735912322998
Validation loss: 2.5182626048723855

Epoch: 5| Step: 1
Training loss: 2.9670002460479736
Validation loss: 2.5106554329395294

Epoch: 5| Step: 2
Training loss: 2.335275173187256
Validation loss: 2.5066508452097573

Epoch: 5| Step: 3
Training loss: 2.906738758087158
Validation loss: 2.5024859607219696

Epoch: 5| Step: 4
Training loss: 2.6065585613250732
Validation loss: 2.4997897843519845

Epoch: 5| Step: 5
Training loss: 2.867157459259033
Validation loss: 2.497615486383438

Epoch: 5| Step: 6
Training loss: 2.565424919128418
Validation loss: 2.4962297777334848

Epoch: 5| Step: 7
Training loss: 2.5471720695495605
Validation loss: 2.4940529068311057

Epoch: 5| Step: 8
Training loss: 2.3976259231567383
Validation loss: 2.4910913904507956

Epoch: 5| Step: 9
Training loss: 2.5307140350341797
Validation loss: 2.4903108278910318

Epoch: 5| Step: 10
Training loss: 3.2777862548828125
Validation loss: 2.49111141761144

Epoch: 5| Step: 11
Training loss: 1.6714646816253662
Validation loss: 2.489628424247106

Epoch: 54| Step: 0
Training loss: 2.520246744155884
Validation loss: 2.4872033298015594

Epoch: 5| Step: 1
Training loss: 2.4714648723602295
Validation loss: 2.491650422414144

Epoch: 5| Step: 2
Training loss: 2.5554943084716797
Validation loss: 2.47698766986529

Epoch: 5| Step: 3
Training loss: 2.8066048622131348
Validation loss: 2.475262622038523

Epoch: 5| Step: 4
Training loss: 1.9604370594024658
Validation loss: 2.472280422846476

Epoch: 5| Step: 5
Training loss: 2.5506930351257324
Validation loss: 2.464661657810211

Epoch: 5| Step: 6
Training loss: 2.222811222076416
Validation loss: 2.4671516517798104

Epoch: 5| Step: 7
Training loss: 3.1055049896240234
Validation loss: 2.4668748478094735

Epoch: 5| Step: 8
Training loss: 3.147336483001709
Validation loss: 2.46536256869634

Epoch: 5| Step: 9
Training loss: 3.349287748336792
Validation loss: 2.45925572514534

Epoch: 5| Step: 10
Training loss: 2.5042991638183594
Validation loss: 2.454650898774465

Epoch: 5| Step: 11
Training loss: 2.9175310134887695
Validation loss: 2.4528742730617523

Epoch: 55| Step: 0
Training loss: 2.7909176349639893
Validation loss: 2.4519691467285156

Epoch: 5| Step: 1
Training loss: 3.1469948291778564
Validation loss: 2.447908043861389

Epoch: 5| Step: 2
Training loss: 2.928015947341919
Validation loss: 2.4465279380480447

Epoch: 5| Step: 3
Training loss: 2.769922971725464
Validation loss: 2.443879634141922

Epoch: 5| Step: 4
Training loss: 2.053372383117676
Validation loss: 2.4400373647610345

Epoch: 5| Step: 5
Training loss: 2.5342965126037598
Validation loss: 2.4347908198833466

Epoch: 5| Step: 6
Training loss: 2.715507984161377
Validation loss: 2.4353154997030892

Epoch: 5| Step: 7
Training loss: 3.024200201034546
Validation loss: 2.430287261803945

Epoch: 5| Step: 8
Training loss: 2.069990396499634
Validation loss: 2.4281188448270163

Epoch: 5| Step: 9
Training loss: 2.492091655731201
Validation loss: 2.425581971804301

Epoch: 5| Step: 10
Training loss: 2.3690221309661865
Validation loss: 2.4241219063599906

Epoch: 5| Step: 11
Training loss: 2.7382395267486572
Validation loss: 2.422729770342509

Epoch: 56| Step: 0
Training loss: 3.1049373149871826
Validation loss: 2.420630623896917

Epoch: 5| Step: 1
Training loss: 2.2965610027313232
Validation loss: 2.4161373674869537

Epoch: 5| Step: 2
Training loss: 2.4685568809509277
Validation loss: 2.413629690806071

Epoch: 5| Step: 3
Training loss: 2.082803249359131
Validation loss: 2.411926547686259

Epoch: 5| Step: 4
Training loss: 3.048118829727173
Validation loss: 2.4091263314088187

Epoch: 5| Step: 5
Training loss: 2.359988212585449
Validation loss: 2.409521679083506

Epoch: 5| Step: 6
Training loss: 2.2405731678009033
Validation loss: 2.410757213830948

Epoch: 5| Step: 7
Training loss: 2.861023426055908
Validation loss: 2.403745323419571

Epoch: 5| Step: 8
Training loss: 2.3047306537628174
Validation loss: 2.3986133684714637

Epoch: 5| Step: 9
Training loss: 2.3611550331115723
Validation loss: 2.4001485308011374

Epoch: 5| Step: 10
Training loss: 3.109612226486206
Validation loss: 2.395523652434349

Epoch: 5| Step: 11
Training loss: 3.7545814514160156
Validation loss: 2.3950526813666024

Epoch: 57| Step: 0
Training loss: 2.2545037269592285
Validation loss: 2.387500454982122

Epoch: 5| Step: 1
Training loss: 3.13165020942688
Validation loss: 2.389878431955973

Epoch: 5| Step: 2
Training loss: 2.218475818634033
Validation loss: 2.39119287331899

Epoch: 5| Step: 3
Training loss: 2.12847638130188
Validation loss: 2.3874708314736686

Epoch: 5| Step: 4
Training loss: 2.4784603118896484
Validation loss: 2.3838774859905243

Epoch: 5| Step: 5
Training loss: 2.3762519359588623
Validation loss: 2.3836700320243835

Epoch: 5| Step: 6
Training loss: 2.996643543243408
Validation loss: 2.377480993668238

Epoch: 5| Step: 7
Training loss: 2.5585989952087402
Validation loss: 2.3737851083278656

Epoch: 5| Step: 8
Training loss: 2.541749954223633
Validation loss: 2.3730469842751822

Epoch: 5| Step: 9
Training loss: 2.3428797721862793
Validation loss: 2.369860291481018

Epoch: 5| Step: 10
Training loss: 3.036963939666748
Validation loss: 2.369912266731262

Epoch: 5| Step: 11
Training loss: 2.9098377227783203
Validation loss: 2.367724279562632

Epoch: 58| Step: 0
Training loss: 2.9359874725341797
Validation loss: 2.366011460622152

Epoch: 5| Step: 1
Training loss: 2.2434141635894775
Validation loss: 2.3639197945594788

Epoch: 5| Step: 2
Training loss: 2.770895004272461
Validation loss: 2.3606702983379364

Epoch: 5| Step: 3
Training loss: 2.46942400932312
Validation loss: 2.358365769187609

Epoch: 5| Step: 4
Training loss: 2.1459708213806152
Validation loss: 2.3563631922006607

Epoch: 5| Step: 5
Training loss: 2.5279018878936768
Validation loss: 2.3543247183163962

Epoch: 5| Step: 6
Training loss: 2.494020462036133
Validation loss: 2.3465065956115723

Epoch: 5| Step: 7
Training loss: 3.11500883102417
Validation loss: 2.347766195734342

Epoch: 5| Step: 8
Training loss: 2.336801528930664
Validation loss: 2.3373421877622604

Epoch: 5| Step: 9
Training loss: 2.6392481327056885
Validation loss: 2.343552549680074

Epoch: 5| Step: 10
Training loss: 2.2001545429229736
Validation loss: 2.3348384499549866

Epoch: 5| Step: 11
Training loss: 2.483123302459717
Validation loss: 2.3348699510097504

Epoch: 59| Step: 0
Training loss: 2.6460251808166504
Validation loss: 2.3374022940794625

Epoch: 5| Step: 1
Training loss: 2.8222060203552246
Validation loss: 2.33522895971934

Epoch: 5| Step: 2
Training loss: 1.9362808465957642
Validation loss: 2.327947755654653

Epoch: 5| Step: 3
Training loss: 2.0463128089904785
Validation loss: 2.325627009073893

Epoch: 5| Step: 4
Training loss: 2.7413458824157715
Validation loss: 2.3214717308680215

Epoch: 5| Step: 5
Training loss: 2.9555938243865967
Validation loss: 2.3244330336650214

Epoch: 5| Step: 6
Training loss: 2.1202950477600098
Validation loss: 2.3217749198277793

Epoch: 5| Step: 7
Training loss: 2.597137451171875
Validation loss: 2.3212217589219413

Epoch: 5| Step: 8
Training loss: 2.628075122833252
Validation loss: 2.3158700366814933

Epoch: 5| Step: 9
Training loss: 2.3786227703094482
Validation loss: 2.3171862761179605

Epoch: 5| Step: 10
Training loss: 2.3833165168762207
Validation loss: 2.3106316228707633

Epoch: 5| Step: 11
Training loss: 3.501702070236206
Validation loss: 2.311969762047132

Epoch: 60| Step: 0
Training loss: 2.398066997528076
Validation loss: 2.311134691039721

Epoch: 5| Step: 1
Training loss: 3.4000842571258545
Validation loss: 2.3141038715839386

Epoch: 5| Step: 2
Training loss: 2.331200122833252
Validation loss: 2.3091812133789062

Epoch: 5| Step: 3
Training loss: 2.116037368774414
Validation loss: 2.2985675235589347

Epoch: 5| Step: 4
Training loss: 2.057671308517456
Validation loss: 2.295012046893438

Epoch: 5| Step: 5
Training loss: 1.8824069499969482
Validation loss: 2.2955826421578727

Epoch: 5| Step: 6
Training loss: 2.8283004760742188
Validation loss: 2.294314573208491

Epoch: 5| Step: 7
Training loss: 2.040592670440674
Validation loss: 2.2892458190520606

Epoch: 5| Step: 8
Training loss: 2.7010252475738525
Validation loss: 2.286493102709452

Epoch: 5| Step: 9
Training loss: 2.4062275886535645
Validation loss: 2.2852490097284317

Epoch: 5| Step: 10
Training loss: 2.835235595703125
Validation loss: 2.285020589828491

Epoch: 5| Step: 11
Training loss: 2.991178035736084
Validation loss: 2.281937832633654

Epoch: 61| Step: 0
Training loss: 2.498509645462036
Validation loss: 2.2774810045957565

Epoch: 5| Step: 1
Training loss: 2.9219000339508057
Validation loss: 2.2821580469608307

Epoch: 5| Step: 2
Training loss: 2.038048267364502
Validation loss: 2.2707508156696954

Epoch: 5| Step: 3
Training loss: 2.19232439994812
Validation loss: 2.2715676029523215

Epoch: 5| Step: 4
Training loss: 2.274078845977783
Validation loss: 2.272146373987198

Epoch: 5| Step: 5
Training loss: 2.5922043323516846
Validation loss: 2.270332376162211

Epoch: 5| Step: 6
Training loss: 2.14780330657959
Validation loss: 2.272383059064547

Epoch: 5| Step: 7
Training loss: 2.3206944465637207
Validation loss: 2.2635463575522103

Epoch: 5| Step: 8
Training loss: 2.1979613304138184
Validation loss: 2.2617045789957047

Epoch: 5| Step: 9
Training loss: 2.470238447189331
Validation loss: 2.2542585730552673

Epoch: 5| Step: 10
Training loss: 2.831909656524658
Validation loss: 2.2471764534711838

Epoch: 5| Step: 11
Training loss: 3.4895431995391846
Validation loss: 2.2549690206845603

Epoch: 62| Step: 0
Training loss: 3.239577531814575
Validation loss: 2.248766710360845

Epoch: 5| Step: 1
Training loss: 2.164498805999756
Validation loss: 2.2468212793270745

Epoch: 5| Step: 2
Training loss: 2.0437350273132324
Validation loss: 2.2452115962902703

Epoch: 5| Step: 3
Training loss: 2.900251865386963
Validation loss: 2.248372217019399

Epoch: 5| Step: 4
Training loss: 2.547694444656372
Validation loss: 2.244738832116127

Epoch: 5| Step: 5
Training loss: 2.296004295349121
Validation loss: 2.2494543145100274

Epoch: 5| Step: 6
Training loss: 2.4743194580078125
Validation loss: 2.2505011608203254

Epoch: 5| Step: 7
Training loss: 1.9233185052871704
Validation loss: 2.2460658897956214

Epoch: 5| Step: 8
Training loss: 2.2763736248016357
Validation loss: 2.2440837621688843

Epoch: 5| Step: 9
Training loss: 2.894918918609619
Validation loss: 2.23564974963665

Epoch: 5| Step: 10
Training loss: 1.8394495248794556
Validation loss: 2.2299711207548776

Epoch: 5| Step: 11
Training loss: 1.3023638725280762
Validation loss: 2.22622741262118

Epoch: 63| Step: 0
Training loss: 2.4772696495056152
Validation loss: 2.2304158906141915

Epoch: 5| Step: 1
Training loss: 1.977670431137085
Validation loss: 2.2309933404127755

Epoch: 5| Step: 2
Training loss: 1.9294469356536865
Validation loss: 2.232062414288521

Epoch: 5| Step: 3
Training loss: 2.628509521484375
Validation loss: 2.2351597050825753

Epoch: 5| Step: 4
Training loss: 2.99967360496521
Validation loss: 2.2403157452742257

Epoch: 5| Step: 5
Training loss: 2.0272796154022217
Validation loss: 2.243152692914009

Epoch: 5| Step: 6
Training loss: 2.485753059387207
Validation loss: 2.240259279807409

Epoch: 5| Step: 7
Training loss: 2.3635458946228027
Validation loss: 2.2394477675358453

Epoch: 5| Step: 8
Training loss: 2.5642199516296387
Validation loss: 2.2322010646263757

Epoch: 5| Step: 9
Training loss: 2.514244794845581
Validation loss: 2.2262798150380454

Epoch: 5| Step: 10
Training loss: 2.1205551624298096
Validation loss: 2.224185695250829

Epoch: 5| Step: 11
Training loss: 3.327505588531494
Validation loss: 2.21191568672657

Epoch: 64| Step: 0
Training loss: 2.5270068645477295
Validation loss: 2.210120831926664

Epoch: 5| Step: 1
Training loss: 2.9464588165283203
Validation loss: 2.204483131567637

Epoch: 5| Step: 2
Training loss: 2.0902457237243652
Validation loss: 2.1964219758907952

Epoch: 5| Step: 3
Training loss: 2.605680465698242
Validation loss: 2.1950936516126

Epoch: 5| Step: 4
Training loss: 2.046797275543213
Validation loss: 2.192536309361458

Epoch: 5| Step: 5
Training loss: 2.438755512237549
Validation loss: 2.1984031101067862

Epoch: 5| Step: 6
Training loss: 2.445272922515869
Validation loss: 2.1897812883059182

Epoch: 5| Step: 7
Training loss: 2.4453322887420654
Validation loss: 2.1886611928542457

Epoch: 5| Step: 8
Training loss: 2.3468964099884033
Validation loss: 2.1820337772369385

Epoch: 5| Step: 9
Training loss: 2.252669095993042
Validation loss: 2.184147526820501

Epoch: 5| Step: 10
Training loss: 1.7477061748504639
Validation loss: 2.1752361158529916

Epoch: 5| Step: 11
Training loss: 2.0710372924804688
Validation loss: 2.1782037715117135

Epoch: 65| Step: 0
Training loss: 2.822679042816162
Validation loss: 2.177230884631475

Epoch: 5| Step: 1
Training loss: 2.3153343200683594
Validation loss: 2.1790714313586554

Epoch: 5| Step: 2
Training loss: 2.956880569458008
Validation loss: 2.1696740041176477

Epoch: 5| Step: 3
Training loss: 2.7301197052001953
Validation loss: 2.1711383213599524

Epoch: 5| Step: 4
Training loss: 2.1741855144500732
Validation loss: 2.172909771402677

Epoch: 5| Step: 5
Training loss: 1.6752183437347412
Validation loss: 2.1729443868001304

Epoch: 5| Step: 6
Training loss: 1.5628137588500977
Validation loss: 2.1775799095630646

Epoch: 5| Step: 7
Training loss: 2.848862886428833
Validation loss: 2.174930284420649

Epoch: 5| Step: 8
Training loss: 2.2475852966308594
Validation loss: 2.1827031075954437

Epoch: 5| Step: 9
Training loss: 2.0030059814453125
Validation loss: 2.1861353317896524

Epoch: 5| Step: 10
Training loss: 2.3257670402526855
Validation loss: 2.177157630523046

Epoch: 5| Step: 11
Training loss: 2.5727829933166504
Validation loss: 2.1694918225208917

Epoch: 66| Step: 0
Training loss: 2.365741491317749
Validation loss: 2.1653863737980523

Epoch: 5| Step: 1
Training loss: 2.122131824493408
Validation loss: 2.1660176217556

Epoch: 5| Step: 2
Training loss: 2.1872270107269287
Validation loss: 2.1610948791106543

Epoch: 5| Step: 3
Training loss: 2.4028677940368652
Validation loss: 2.1602749725182853

Epoch: 5| Step: 4
Training loss: 2.666016101837158
Validation loss: 2.151655529936155

Epoch: 5| Step: 5
Training loss: 1.8728981018066406
Validation loss: 2.1522917598485947

Epoch: 5| Step: 6
Training loss: 2.220837116241455
Validation loss: 2.1477615982294083

Epoch: 5| Step: 7
Training loss: 2.217780113220215
Validation loss: 2.153546929359436

Epoch: 5| Step: 8
Training loss: 2.751370906829834
Validation loss: 2.151084209481875

Epoch: 5| Step: 9
Training loss: 2.4156765937805176
Validation loss: 2.1506437212228775

Epoch: 5| Step: 10
Training loss: 2.3244223594665527
Validation loss: 2.1502171009778976

Epoch: 5| Step: 11
Training loss: 2.3647680282592773
Validation loss: 2.142636423309644

Epoch: 67| Step: 0
Training loss: 2.5699732303619385
Validation loss: 2.1412188708782196

Epoch: 5| Step: 1
Training loss: 2.2023048400878906
Validation loss: 2.142594983180364

Epoch: 5| Step: 2
Training loss: 2.6451826095581055
Validation loss: 2.1408182928959527

Epoch: 5| Step: 3
Training loss: 1.8790090084075928
Validation loss: 2.1408512790997825

Epoch: 5| Step: 4
Training loss: 2.277534008026123
Validation loss: 2.1412740349769592

Epoch: 5| Step: 5
Training loss: 2.2038309574127197
Validation loss: 2.140497237443924

Epoch: 5| Step: 6
Training loss: 2.3744864463806152
Validation loss: 2.142203062772751

Epoch: 5| Step: 7
Training loss: 2.2735061645507812
Validation loss: 2.145959426959356

Epoch: 5| Step: 8
Training loss: 2.7846338748931885
Validation loss: 2.145840769012769

Epoch: 5| Step: 9
Training loss: 1.8402096033096313
Validation loss: 2.1464371234178543

Epoch: 5| Step: 10
Training loss: 2.4958293437957764
Validation loss: 2.138840690255165

Epoch: 5| Step: 11
Training loss: 1.8241020441055298
Validation loss: 2.142983009417852

Epoch: 68| Step: 0
Training loss: 2.3635268211364746
Validation loss: 2.1382273882627487

Epoch: 5| Step: 1
Training loss: 1.8684158325195312
Validation loss: 2.1436622937520347

Epoch: 5| Step: 2
Training loss: 2.0004584789276123
Validation loss: 2.1428138812383017

Epoch: 5| Step: 3
Training loss: 2.1971919536590576
Validation loss: 2.1398886144161224

Epoch: 5| Step: 4
Training loss: 2.1520919799804688
Validation loss: 2.139112204313278

Epoch: 5| Step: 5
Training loss: 2.121455669403076
Validation loss: 2.1387800524632135

Epoch: 5| Step: 6
Training loss: 2.5704290866851807
Validation loss: 2.129472201069196

Epoch: 5| Step: 7
Training loss: 2.2715611457824707
Validation loss: 2.1391583184401193

Epoch: 5| Step: 8
Training loss: 2.8953888416290283
Validation loss: 2.136234978834788

Epoch: 5| Step: 9
Training loss: 2.2707178592681885
Validation loss: 2.1245209674040475

Epoch: 5| Step: 10
Training loss: 2.698556900024414
Validation loss: 2.1261023730039597

Epoch: 5| Step: 11
Training loss: 2.0177578926086426
Validation loss: 2.128632133205732

Epoch: 69| Step: 0
Training loss: 1.9979770183563232
Validation loss: 2.138309588034948

Epoch: 5| Step: 1
Training loss: 2.4950387477874756
Validation loss: 2.13706802825133

Epoch: 5| Step: 2
Training loss: 2.1790740489959717
Validation loss: 2.138753096262614

Epoch: 5| Step: 3
Training loss: 2.2416675090789795
Validation loss: 2.1354886492093406

Epoch: 5| Step: 4
Training loss: 1.9475841522216797
Validation loss: 2.129309207201004

Epoch: 5| Step: 5
Training loss: 2.708266019821167
Validation loss: 2.126360913117727

Epoch: 5| Step: 6
Training loss: 2.090585708618164
Validation loss: 2.126419554154078

Epoch: 5| Step: 7
Training loss: 2.4881346225738525
Validation loss: 2.13018865386645

Epoch: 5| Step: 8
Training loss: 2.662219285964966
Validation loss: 2.1331885208686194

Epoch: 5| Step: 9
Training loss: 2.5535976886749268
Validation loss: 2.132280170917511

Epoch: 5| Step: 10
Training loss: 1.9316718578338623
Validation loss: 2.13198917110761

Epoch: 5| Step: 11
Training loss: 2.030604839324951
Validation loss: 2.128160923719406

Epoch: 70| Step: 0
Training loss: 2.3538107872009277
Validation loss: 2.123678674300512

Epoch: 5| Step: 1
Training loss: 2.608685255050659
Validation loss: 2.1260613401730857

Epoch: 5| Step: 2
Training loss: 2.44884991645813
Validation loss: 2.130888730287552

Epoch: 5| Step: 3
Training loss: 2.334052324295044
Validation loss: 2.130252495408058

Epoch: 5| Step: 4
Training loss: 2.0454695224761963
Validation loss: 2.126784692207972

Epoch: 5| Step: 5
Training loss: 2.316662073135376
Validation loss: 2.1365932722886405

Epoch: 5| Step: 6
Training loss: 2.0993130207061768
Validation loss: 2.1434664924939475

Epoch: 5| Step: 7
Training loss: 2.0234944820404053
Validation loss: 2.1298590103785195

Epoch: 5| Step: 8
Training loss: 2.348940372467041
Validation loss: 2.110470548272133

Epoch: 5| Step: 9
Training loss: 2.4866042137145996
Validation loss: 2.112093046307564

Epoch: 5| Step: 10
Training loss: 2.0775439739227295
Validation loss: 2.113205591837565

Epoch: 5| Step: 11
Training loss: 2.6242313385009766
Validation loss: 2.118511055906614

Epoch: 71| Step: 0
Training loss: 2.443204879760742
Validation loss: 2.1241298019886017

Epoch: 5| Step: 1
Training loss: 2.303086280822754
Validation loss: 2.130183676878611

Epoch: 5| Step: 2
Training loss: 2.5741333961486816
Validation loss: 2.137384459376335

Epoch: 5| Step: 3
Training loss: 2.4207003116607666
Validation loss: 2.139474257826805

Epoch: 5| Step: 4
Training loss: 2.0788378715515137
Validation loss: 2.1444393197695413

Epoch: 5| Step: 5
Training loss: 2.451028347015381
Validation loss: 2.1424056688944497

Epoch: 5| Step: 6
Training loss: 2.2609410285949707
Validation loss: 2.1426895459493003

Epoch: 5| Step: 7
Training loss: 2.4000258445739746
Validation loss: 2.138664429386457

Epoch: 5| Step: 8
Training loss: 2.3584890365600586
Validation loss: 2.125694697101911

Epoch: 5| Step: 9
Training loss: 2.4747793674468994
Validation loss: 2.120616525411606

Epoch: 5| Step: 10
Training loss: 1.7479150295257568
Validation loss: 2.1109210352102914

Epoch: 5| Step: 11
Training loss: 1.3482705354690552
Validation loss: 2.1016149322191873

Epoch: 72| Step: 0
Training loss: 1.952918291091919
Validation loss: 2.094114730755488

Epoch: 5| Step: 1
Training loss: 2.3633620738983154
Validation loss: 2.0959323942661285

Epoch: 5| Step: 2
Training loss: 2.433253765106201
Validation loss: 2.0920114566882453

Epoch: 5| Step: 3
Training loss: 2.207674980163574
Validation loss: 2.093633934855461

Epoch: 5| Step: 4
Training loss: 1.9156051874160767
Validation loss: 2.0959182530641556

Epoch: 5| Step: 5
Training loss: 1.9603688716888428
Validation loss: 2.098370522260666

Epoch: 5| Step: 6
Training loss: 2.4815683364868164
Validation loss: 2.095325936873754

Epoch: 5| Step: 7
Training loss: 2.3528473377227783
Validation loss: 2.09867125749588

Epoch: 5| Step: 8
Training loss: 2.2936251163482666
Validation loss: 2.0949664562940598

Epoch: 5| Step: 9
Training loss: 2.181680202484131
Validation loss: 2.0808409502108893

Epoch: 5| Step: 10
Training loss: 2.86299467086792
Validation loss: 2.0892863223950067

Epoch: 5| Step: 11
Training loss: 2.0501790046691895
Validation loss: 2.0804894963900247

Epoch: 73| Step: 0
Training loss: 2.5191638469696045
Validation loss: 2.0814298490683236

Epoch: 5| Step: 1
Training loss: 2.2989425659179688
Validation loss: 2.0856271535158157

Epoch: 5| Step: 2
Training loss: 1.915066123008728
Validation loss: 2.089396357536316

Epoch: 5| Step: 3
Training loss: 1.9483712911605835
Validation loss: 2.093856414159139

Epoch: 5| Step: 4
Training loss: 2.3133158683776855
Validation loss: 2.0883335868517556

Epoch: 5| Step: 5
Training loss: 2.0814993381500244
Validation loss: 2.0877831677595773

Epoch: 5| Step: 6
Training loss: 3.012800693511963
Validation loss: 2.084854265054067

Epoch: 5| Step: 7
Training loss: 2.0193450450897217
Validation loss: 2.0875088373819985

Epoch: 5| Step: 8
Training loss: 2.0312089920043945
Validation loss: 2.0951718439658484

Epoch: 5| Step: 9
Training loss: 2.1605172157287598
Validation loss: 2.0916551301876702

Epoch: 5| Step: 10
Training loss: 2.3534398078918457
Validation loss: 2.08936308324337

Epoch: 5| Step: 11
Training loss: 3.399883985519409
Validation loss: 2.093464563290278

Epoch: 74| Step: 0
Training loss: 2.506025791168213
Validation loss: 2.085470497608185

Epoch: 5| Step: 1
Training loss: 2.606781244277954
Validation loss: 2.0821100572745004

Epoch: 5| Step: 2
Training loss: 2.2074179649353027
Validation loss: 2.083223263422648

Epoch: 5| Step: 3
Training loss: 2.1666934490203857
Validation loss: 2.079845075805982

Epoch: 5| Step: 4
Training loss: 1.8079357147216797
Validation loss: 2.080962374806404

Epoch: 5| Step: 5
Training loss: 2.118238687515259
Validation loss: 2.0785130808750787

Epoch: 5| Step: 6
Training loss: 2.89943528175354
Validation loss: 2.0732288360595703

Epoch: 5| Step: 7
Training loss: 2.4172732830047607
Validation loss: 2.076747333010038

Epoch: 5| Step: 8
Training loss: 2.4676928520202637
Validation loss: 2.0718296815951667

Epoch: 5| Step: 9
Training loss: 1.8637313842773438
Validation loss: 2.0781062990427017

Epoch: 5| Step: 10
Training loss: 1.9858038425445557
Validation loss: 2.0840575248003006

Epoch: 5| Step: 11
Training loss: 1.9309900999069214
Validation loss: 2.079045703013738

Epoch: 75| Step: 0
Training loss: 2.3548197746276855
Validation loss: 2.082748676339785

Epoch: 5| Step: 1
Training loss: 2.3057665824890137
Validation loss: 2.0752201030651727

Epoch: 5| Step: 2
Training loss: 2.4854323863983154
Validation loss: 2.0778984824816384

Epoch: 5| Step: 3
Training loss: 2.2593488693237305
Validation loss: 2.0869483947753906

Epoch: 5| Step: 4
Training loss: 2.3751955032348633
Validation loss: 2.0898393044869104

Epoch: 5| Step: 5
Training loss: 2.094275951385498
Validation loss: 2.094821626941363

Epoch: 5| Step: 6
Training loss: 1.658628225326538
Validation loss: 2.099010785420736

Epoch: 5| Step: 7
Training loss: 2.3259241580963135
Validation loss: 2.0952949225902557

Epoch: 5| Step: 8
Training loss: 2.4111125469207764
Validation loss: 2.0947217792272568

Epoch: 5| Step: 9
Training loss: 2.490283489227295
Validation loss: 2.0955058932304382

Epoch: 5| Step: 10
Training loss: 2.5190396308898926
Validation loss: 2.092683811982473

Epoch: 5| Step: 11
Training loss: 1.009161353111267
Validation loss: 2.08853809038798

Epoch: 76| Step: 0
Training loss: 2.0487685203552246
Validation loss: 2.083474616209666

Epoch: 5| Step: 1
Training loss: 2.8539936542510986
Validation loss: 2.0787518123785653

Epoch: 5| Step: 2
Training loss: 1.948674201965332
Validation loss: 2.0769671698411307

Epoch: 5| Step: 3
Training loss: 1.9692045450210571
Validation loss: 2.0694811791181564

Epoch: 5| Step: 4
Training loss: 2.522284507751465
Validation loss: 2.0691781689723334

Epoch: 5| Step: 5
Training loss: 2.375092029571533
Validation loss: 2.061959649125735

Epoch: 5| Step: 6
Training loss: 1.777099847793579
Validation loss: 2.0640388230482736

Epoch: 5| Step: 7
Training loss: 2.2510643005371094
Validation loss: 2.06217260658741

Epoch: 5| Step: 8
Training loss: 2.33349609375
Validation loss: 2.0549988001585007

Epoch: 5| Step: 9
Training loss: 2.743041515350342
Validation loss: 2.0529830157756805

Epoch: 5| Step: 10
Training loss: 1.7884328365325928
Validation loss: 2.0501276900370917

Epoch: 5| Step: 11
Training loss: 3.366171360015869
Validation loss: 2.0527872989575067

Epoch: 77| Step: 0
Training loss: 1.8800439834594727
Validation loss: 2.0672850559155145

Epoch: 5| Step: 1
Training loss: 2.642338275909424
Validation loss: 2.0688661138216653

Epoch: 5| Step: 2
Training loss: 2.420820713043213
Validation loss: 2.070008491476377

Epoch: 5| Step: 3
Training loss: 2.3892745971679688
Validation loss: 2.0722008297840753

Epoch: 5| Step: 4
Training loss: 1.9841201305389404
Validation loss: 2.077073266108831

Epoch: 5| Step: 5
Training loss: 1.9433765411376953
Validation loss: 2.06650381286939

Epoch: 5| Step: 6
Training loss: 2.5088019371032715
Validation loss: 2.0683868477741876

Epoch: 5| Step: 7
Training loss: 2.525228500366211
Validation loss: 2.0724709182977676

Epoch: 5| Step: 8
Training loss: 2.483922243118286
Validation loss: 2.069516176978747

Epoch: 5| Step: 9
Training loss: 1.5995153188705444
Validation loss: 2.062672942876816

Epoch: 5| Step: 10
Training loss: 2.2650771141052246
Validation loss: 2.0701740930477777

Epoch: 5| Step: 11
Training loss: 2.5307962894439697
Validation loss: 2.0603906909624734

Epoch: 78| Step: 0
Training loss: 2.200096607208252
Validation loss: 2.0657818615436554

Epoch: 5| Step: 1
Training loss: 2.4644007682800293
Validation loss: 2.0543997635444007

Epoch: 5| Step: 2
Training loss: 2.509315013885498
Validation loss: 2.0581258138020835

Epoch: 5| Step: 3
Training loss: 2.267695188522339
Validation loss: 2.05549888809522

Epoch: 5| Step: 4
Training loss: 1.8740007877349854
Validation loss: 2.05772772928079

Epoch: 5| Step: 5
Training loss: 1.8352779150009155
Validation loss: 2.0547999093929925

Epoch: 5| Step: 6
Training loss: 2.463493824005127
Validation loss: 2.0581532468398414

Epoch: 5| Step: 7
Training loss: 2.323500156402588
Validation loss: 2.053579797347387

Epoch: 5| Step: 8
Training loss: 2.3416080474853516
Validation loss: 2.0523864229520163

Epoch: 5| Step: 9
Training loss: 2.1841378211975098
Validation loss: 2.043603708346685

Epoch: 5| Step: 10
Training loss: 2.1953938007354736
Validation loss: 2.050800164540609

Epoch: 5| Step: 11
Training loss: 1.9635190963745117
Validation loss: 2.044111654162407

Epoch: 79| Step: 0
Training loss: 1.9462486505508423
Validation loss: 2.0533546010653176

Epoch: 5| Step: 1
Training loss: 2.329792022705078
Validation loss: 2.0501355628172555

Epoch: 5| Step: 2
Training loss: 2.285383939743042
Validation loss: 2.048673540353775

Epoch: 5| Step: 3
Training loss: 2.301831007003784
Validation loss: 2.0503692279259362

Epoch: 5| Step: 4
Training loss: 2.0498266220092773
Validation loss: 2.048811291654905

Epoch: 5| Step: 5
Training loss: 2.3423678874969482
Validation loss: 2.037290791670481

Epoch: 5| Step: 6
Training loss: 2.273561716079712
Validation loss: 2.0411684016386666

Epoch: 5| Step: 7
Training loss: 2.344682455062866
Validation loss: 2.0366706351439157

Epoch: 5| Step: 8
Training loss: 2.226405382156372
Validation loss: 2.037530561288198

Epoch: 5| Step: 9
Training loss: 2.1301519870758057
Validation loss: 2.032249907652537

Epoch: 5| Step: 10
Training loss: 2.1759531497955322
Validation loss: 2.038697049021721

Epoch: 5| Step: 11
Training loss: 2.69281268119812
Validation loss: 2.041321416695913

Epoch: 80| Step: 0
Training loss: 1.9842040538787842
Validation loss: 2.0348788698514304

Epoch: 5| Step: 1
Training loss: 1.9375778436660767
Validation loss: 2.047360380490621

Epoch: 5| Step: 2
Training loss: 2.001518487930298
Validation loss: 2.045742630958557

Epoch: 5| Step: 3
Training loss: 2.7400527000427246
Validation loss: 2.0420077989498773

Epoch: 5| Step: 4
Training loss: 2.394737958908081
Validation loss: 2.047071491678556

Epoch: 5| Step: 5
Training loss: 2.0544228553771973
Validation loss: 2.0511778046687446

Epoch: 5| Step: 6
Training loss: 2.0054237842559814
Validation loss: 2.053911328315735

Epoch: 5| Step: 7
Training loss: 1.8941919803619385
Validation loss: 2.0494471987088523

Epoch: 5| Step: 8
Training loss: 2.143500804901123
Validation loss: 2.0501300195852914

Epoch: 5| Step: 9
Training loss: 2.4824368953704834
Validation loss: 2.0468753278255463

Epoch: 5| Step: 10
Training loss: 2.5861401557922363
Validation loss: 2.0344225764274597

Epoch: 5| Step: 11
Training loss: 2.85619854927063
Validation loss: 2.0481305619080863

Epoch: 81| Step: 0
Training loss: 2.240959405899048
Validation loss: 2.0353665898243585

Epoch: 5| Step: 1
Training loss: 2.447047233581543
Validation loss: 2.034330000480016

Epoch: 5| Step: 2
Training loss: 2.3396952152252197
Validation loss: 2.0349945475657782

Epoch: 5| Step: 3
Training loss: 1.931483507156372
Validation loss: 2.043008734782537

Epoch: 5| Step: 4
Training loss: 2.292495012283325
Validation loss: 2.0438277473052344

Epoch: 5| Step: 5
Training loss: 2.423379421234131
Validation loss: 2.0430029233296714

Epoch: 5| Step: 6
Training loss: 2.163715124130249
Validation loss: 2.0475815534591675

Epoch: 5| Step: 7
Training loss: 2.152475357055664
Validation loss: 2.0397875805695853

Epoch: 5| Step: 8
Training loss: 1.8243820667266846
Validation loss: 2.0279190440972648

Epoch: 5| Step: 9
Training loss: 2.2416980266571045
Validation loss: 2.030864010254542

Epoch: 5| Step: 10
Training loss: 2.5211684703826904
Validation loss: 2.03363806505998

Epoch: 5| Step: 11
Training loss: 0.9455944299697876
Validation loss: 2.031283880273501

Epoch: 82| Step: 0
Training loss: 2.461909532546997
Validation loss: 2.0235268970330558

Epoch: 5| Step: 1
Training loss: 1.8105926513671875
Validation loss: 2.040761614839236

Epoch: 5| Step: 2
Training loss: 2.4556708335876465
Validation loss: 2.024210308988889

Epoch: 5| Step: 3
Training loss: 2.2806925773620605
Validation loss: 2.023743599653244

Epoch: 5| Step: 4
Training loss: 1.9056421518325806
Validation loss: 2.026437441507975

Epoch: 5| Step: 5
Training loss: 1.8959598541259766
Validation loss: 2.034083048502604

Epoch: 5| Step: 6
Training loss: 2.3666961193084717
Validation loss: 2.0397372941176095

Epoch: 5| Step: 7
Training loss: 2.016383647918701
Validation loss: 2.047739232579867

Epoch: 5| Step: 8
Training loss: 2.016000270843506
Validation loss: 2.0599581748247147

Epoch: 5| Step: 9
Training loss: 2.617697238922119
Validation loss: 2.0563755482435226

Epoch: 5| Step: 10
Training loss: 2.153172254562378
Validation loss: 2.044418434302012

Epoch: 5| Step: 11
Training loss: 2.5818681716918945
Validation loss: 2.0422319571177163

Epoch: 83| Step: 0
Training loss: 2.124178886413574
Validation loss: 2.0361162523428598

Epoch: 5| Step: 1
Training loss: 2.248157024383545
Validation loss: 2.037952959537506

Epoch: 5| Step: 2
Training loss: 2.175607204437256
Validation loss: 2.0381401230891547

Epoch: 5| Step: 3
Training loss: 2.237536907196045
Validation loss: 2.0279805858929953

Epoch: 5| Step: 4
Training loss: 2.5681252479553223
Validation loss: 2.038286119699478

Epoch: 5| Step: 5
Training loss: 1.8163646459579468
Validation loss: 2.042484497030576

Epoch: 5| Step: 6
Training loss: 2.453047275543213
Validation loss: 2.041507378220558

Epoch: 5| Step: 7
Training loss: 1.892693281173706
Validation loss: 2.034597838918368

Epoch: 5| Step: 8
Training loss: 2.46651029586792
Validation loss: 2.029309074083964

Epoch: 5| Step: 9
Training loss: 2.0635037422180176
Validation loss: 2.0335108786821365

Epoch: 5| Step: 10
Training loss: 2.33111310005188
Validation loss: 2.028871903816859

Epoch: 5| Step: 11
Training loss: 1.5227845907211304
Validation loss: 2.0282364586989083

Epoch: 84| Step: 0
Training loss: 2.220350503921509
Validation loss: 2.0400961488485336

Epoch: 5| Step: 1
Training loss: 2.4309120178222656
Validation loss: 2.022750978668531

Epoch: 5| Step: 2
Training loss: 2.268292188644409
Validation loss: 2.026577447851499

Epoch: 5| Step: 3
Training loss: 1.8250839710235596
Validation loss: 2.0269615203142166

Epoch: 5| Step: 4
Training loss: 2.2478063106536865
Validation loss: 2.018574287494024

Epoch: 5| Step: 5
Training loss: 2.049293041229248
Validation loss: 2.0282695094744363

Epoch: 5| Step: 6
Training loss: 2.2902755737304688
Validation loss: 2.014188602566719

Epoch: 5| Step: 7
Training loss: 2.460415840148926
Validation loss: 2.0183072835206985

Epoch: 5| Step: 8
Training loss: 2.2054152488708496
Validation loss: 2.016438772281011

Epoch: 5| Step: 9
Training loss: 1.8640682697296143
Validation loss: 2.018679067492485

Epoch: 5| Step: 10
Training loss: 2.047642230987549
Validation loss: 2.0175032168626785

Epoch: 5| Step: 11
Training loss: 3.0689945220947266
Validation loss: 2.0129465957482657

Epoch: 85| Step: 0
Training loss: 1.6673533916473389
Validation loss: 2.030100097258886

Epoch: 5| Step: 1
Training loss: 2.4574620723724365
Validation loss: 2.0525728364785514

Epoch: 5| Step: 2
Training loss: 1.944762945175171
Validation loss: 2.069379140933355

Epoch: 5| Step: 3
Training loss: 2.316570281982422
Validation loss: 2.0915981332461038

Epoch: 5| Step: 4
Training loss: 2.4438838958740234
Validation loss: 2.1089966793855033

Epoch: 5| Step: 5
Training loss: 2.052618980407715
Validation loss: 2.1086859107017517

Epoch: 5| Step: 6
Training loss: 2.567134141921997
Validation loss: 2.0909268309672675

Epoch: 5| Step: 7
Training loss: 2.8088955879211426
Validation loss: 2.0700592696666718

Epoch: 5| Step: 8
Training loss: 2.4925429821014404
Validation loss: 2.0509806325038276

Epoch: 5| Step: 9
Training loss: 1.8164876699447632
Validation loss: 2.0257047613461814

Epoch: 5| Step: 10
Training loss: 1.9656908512115479
Validation loss: 2.018590355912844

Epoch: 5| Step: 11
Training loss: 2.589552640914917
Validation loss: 2.0075770765542984

Epoch: 86| Step: 0
Training loss: 1.6775779724121094
Validation loss: 2.0117451697587967

Epoch: 5| Step: 1
Training loss: 2.3656697273254395
Validation loss: 2.02891614039739

Epoch: 5| Step: 2
Training loss: 2.3302664756774902
Validation loss: 2.03361506263415

Epoch: 5| Step: 3
Training loss: 2.25449538230896
Validation loss: 2.041558509071668

Epoch: 5| Step: 4
Training loss: 2.337186574935913
Validation loss: 2.048419867952665

Epoch: 5| Step: 5
Training loss: 2.5532312393188477
Validation loss: 2.045213465889295

Epoch: 5| Step: 6
Training loss: 2.258260726928711
Validation loss: 2.0491646577914557

Epoch: 5| Step: 7
Training loss: 1.9026737213134766
Validation loss: 2.051724746823311

Epoch: 5| Step: 8
Training loss: 2.4608168601989746
Validation loss: 2.050016462802887

Epoch: 5| Step: 9
Training loss: 2.243213176727295
Validation loss: 2.055771619081497

Epoch: 5| Step: 10
Training loss: 2.1994736194610596
Validation loss: 2.051821614305178

Epoch: 5| Step: 11
Training loss: 1.6802315711975098
Validation loss: 2.046612267692884

Epoch: 87| Step: 0
Training loss: 2.3387932777404785
Validation loss: 2.046098753809929

Epoch: 5| Step: 1
Training loss: 2.37908673286438
Validation loss: 2.0404973179101944

Epoch: 5| Step: 2
Training loss: 2.40716814994812
Validation loss: 2.0454585949579873

Epoch: 5| Step: 3
Training loss: 2.135091543197632
Validation loss: 2.040106246868769

Epoch: 5| Step: 4
Training loss: 2.3269734382629395
Validation loss: 2.0370246320962906

Epoch: 5| Step: 5
Training loss: 2.19010591506958
Validation loss: 2.0358284612496695

Epoch: 5| Step: 6
Training loss: 2.173560857772827
Validation loss: 2.0316074838240943

Epoch: 5| Step: 7
Training loss: 2.033527374267578
Validation loss: 2.024426057934761

Epoch: 5| Step: 8
Training loss: 2.100860595703125
Validation loss: 2.0175407975912094

Epoch: 5| Step: 9
Training loss: 2.199657917022705
Validation loss: 2.0076402872800827

Epoch: 5| Step: 10
Training loss: 1.8954311609268188
Validation loss: 2.008525242408117

Epoch: 5| Step: 11
Training loss: 2.1654934883117676
Validation loss: 2.011379763484001

Epoch: 88| Step: 0
Training loss: 2.273160457611084
Validation loss: 2.017839476466179

Epoch: 5| Step: 1
Training loss: 2.7520804405212402
Validation loss: 2.013186290860176

Epoch: 5| Step: 2
Training loss: 1.4063352346420288
Validation loss: 2.0134546806414924

Epoch: 5| Step: 3
Training loss: 1.7300376892089844
Validation loss: 2.0088271299997964

Epoch: 5| Step: 4
Training loss: 2.234372615814209
Validation loss: 2.009250650803248

Epoch: 5| Step: 5
Training loss: 2.1710011959075928
Validation loss: 2.0163404842217765

Epoch: 5| Step: 6
Training loss: 1.8892902135849
Validation loss: 2.013673876722654

Epoch: 5| Step: 7
Training loss: 1.851387619972229
Validation loss: 2.006469185153643

Epoch: 5| Step: 8
Training loss: 2.344359874725342
Validation loss: 2.0090019404888153

Epoch: 5| Step: 9
Training loss: 2.16850209236145
Validation loss: 2.0097265243530273

Epoch: 5| Step: 10
Training loss: 3.035770893096924
Validation loss: 2.0078058342138925

Epoch: 5| Step: 11
Training loss: 2.2305421829223633
Validation loss: 2.006825238466263

Epoch: 89| Step: 0
Training loss: 1.8526033163070679
Validation loss: 2.0055045783519745

Epoch: 5| Step: 1
Training loss: 1.4002419710159302
Validation loss: 2.0106233855088553

Epoch: 5| Step: 2
Training loss: 2.5478298664093018
Validation loss: 2.0240994642178216

Epoch: 5| Step: 3
Training loss: 2.5780651569366455
Validation loss: 2.0276036908229194

Epoch: 5| Step: 4
Training loss: 2.575572967529297
Validation loss: 2.0296987344821296

Epoch: 5| Step: 5
Training loss: 2.175779342651367
Validation loss: 2.0365309913953147

Epoch: 5| Step: 6
Training loss: 1.959930419921875
Validation loss: 2.035908584793409

Epoch: 5| Step: 7
Training loss: 2.439152479171753
Validation loss: 2.038215473294258

Epoch: 5| Step: 8
Training loss: 2.324465751647949
Validation loss: 2.0247330317894616

Epoch: 5| Step: 9
Training loss: 2.24312424659729
Validation loss: 2.016716072956721

Epoch: 5| Step: 10
Training loss: 2.0462851524353027
Validation loss: 2.016819879412651

Epoch: 5| Step: 11
Training loss: 1.2231669425964355
Validation loss: 2.015645166238149

Epoch: 90| Step: 0
Training loss: 2.3499817848205566
Validation loss: 2.0137471357981362

Epoch: 5| Step: 1
Training loss: 1.8860584497451782
Validation loss: 2.0176334381103516

Epoch: 5| Step: 2
Training loss: 1.9503905773162842
Validation loss: 2.004628519217173

Epoch: 5| Step: 3
Training loss: 2.2058606147766113
Validation loss: 2.0089690536260605

Epoch: 5| Step: 4
Training loss: 2.3389785289764404
Validation loss: 2.0111155062913895

Epoch: 5| Step: 5
Training loss: 2.1969761848449707
Validation loss: 2.0068446348110833

Epoch: 5| Step: 6
Training loss: 2.7739815711975098
Validation loss: 2.008329689502716

Epoch: 5| Step: 7
Training loss: 1.6887719631195068
Validation loss: 2.0068900187810264

Epoch: 5| Step: 8
Training loss: 1.5293208360671997
Validation loss: 2.0138616263866425

Epoch: 5| Step: 9
Training loss: 2.717644691467285
Validation loss: 2.007564142346382

Epoch: 5| Step: 10
Training loss: 2.10660982131958
Validation loss: 2.0145744929711022

Epoch: 5| Step: 11
Training loss: 2.2230472564697266
Validation loss: 2.022154981891314

Epoch: 91| Step: 0
Training loss: 2.0087809562683105
Validation loss: 2.0350821117560067

Epoch: 5| Step: 1
Training loss: 3.155371904373169
Validation loss: 2.049063980579376

Epoch: 5| Step: 2
Training loss: 2.1884922981262207
Validation loss: 2.0446737706661224

Epoch: 5| Step: 3
Training loss: 2.264448642730713
Validation loss: 2.0449065963427224

Epoch: 5| Step: 4
Training loss: 1.7669817209243774
Validation loss: 2.0337258726358414

Epoch: 5| Step: 5
Training loss: 1.9960130453109741
Validation loss: 2.0333668490250907

Epoch: 5| Step: 6
Training loss: 1.6720819473266602
Validation loss: 2.0296963453292847

Epoch: 5| Step: 7
Training loss: 2.4279255867004395
Validation loss: 2.0315048694610596

Epoch: 5| Step: 8
Training loss: 1.516100287437439
Validation loss: 2.0284192909797034

Epoch: 5| Step: 9
Training loss: 2.3952829837799072
Validation loss: 2.0303693612416587

Epoch: 5| Step: 10
Training loss: 2.3706188201904297
Validation loss: 2.040111765265465

Epoch: 5| Step: 11
Training loss: 2.7246828079223633
Validation loss: 2.0313455214103064

Epoch: 92| Step: 0
Training loss: 2.347255229949951
Validation loss: 2.0445672372976937

Epoch: 5| Step: 1
Training loss: 1.6425762176513672
Validation loss: 2.0428307751814523

Epoch: 5| Step: 2
Training loss: 2.757242441177368
Validation loss: 2.0482901682456336

Epoch: 5| Step: 3
Training loss: 1.7286441326141357
Validation loss: 2.0382453997929892

Epoch: 5| Step: 4
Training loss: 2.024536609649658
Validation loss: 2.0312757839759192

Epoch: 5| Step: 5
Training loss: 2.5585906505584717
Validation loss: 2.003602941830953

Epoch: 5| Step: 6
Training loss: 2.39618182182312
Validation loss: 2.012256070971489

Epoch: 5| Step: 7
Training loss: 1.9804408550262451
Validation loss: 2.008331775665283

Epoch: 5| Step: 8
Training loss: 2.45615553855896
Validation loss: 2.0135359913110733

Epoch: 5| Step: 9
Training loss: 2.13962984085083
Validation loss: 2.012758433818817

Epoch: 5| Step: 10
Training loss: 1.983778715133667
Validation loss: 2.0190144131580987

Epoch: 5| Step: 11
Training loss: 1.9057419300079346
Validation loss: 2.0151299834251404

Epoch: 93| Step: 0
Training loss: 2.132399797439575
Validation loss: 2.014292558034261

Epoch: 5| Step: 1
Training loss: 2.3988747596740723
Validation loss: 2.00992813706398

Epoch: 5| Step: 2
Training loss: 2.316978931427002
Validation loss: 2.008398840824763

Epoch: 5| Step: 3
Training loss: 1.990128517150879
Validation loss: 2.007075180610021

Epoch: 5| Step: 4
Training loss: 2.242342710494995
Validation loss: 2.0073988984028497

Epoch: 5| Step: 5
Training loss: 2.666414737701416
Validation loss: 2.006521597504616

Epoch: 5| Step: 6
Training loss: 1.9419355392456055
Validation loss: 2.005520502726237

Epoch: 5| Step: 7
Training loss: 2.216512680053711
Validation loss: 2.0110306292772293

Epoch: 5| Step: 8
Training loss: 1.9389270544052124
Validation loss: 2.0080795288085938

Epoch: 5| Step: 9
Training loss: 2.091344118118286
Validation loss: 2.0201139201720557

Epoch: 5| Step: 10
Training loss: 1.7096712589263916
Validation loss: 2.02448870241642

Epoch: 5| Step: 11
Training loss: 2.2968904972076416
Validation loss: 2.0301390141248703

Epoch: 94| Step: 0
Training loss: 1.8467323780059814
Validation loss: 2.041140248378118

Epoch: 5| Step: 1
Training loss: 1.9401925802230835
Validation loss: 2.0376469641923904

Epoch: 5| Step: 2
Training loss: 2.3910062313079834
Validation loss: 2.021605754892031

Epoch: 5| Step: 3
Training loss: 2.0687475204467773
Validation loss: 2.0306518524885178

Epoch: 5| Step: 4
Training loss: 1.8672218322753906
Validation loss: 2.0140700340270996

Epoch: 5| Step: 5
Training loss: 2.5418972969055176
Validation loss: 2.0146226783593497

Epoch: 5| Step: 6
Training loss: 1.8833160400390625
Validation loss: 2.0033594518899918

Epoch: 5| Step: 7
Training loss: 1.9354711771011353
Validation loss: 2.002428417404493

Epoch: 5| Step: 8
Training loss: 2.3456320762634277
Validation loss: 2.0024356494347253

Epoch: 5| Step: 9
Training loss: 2.8187546730041504
Validation loss: 2.0119281709194183

Epoch: 5| Step: 10
Training loss: 2.075401782989502
Validation loss: 2.008353744943937

Epoch: 5| Step: 11
Training loss: 2.5823745727539062
Validation loss: 2.011973654230436

Epoch: 95| Step: 0
Training loss: 2.0750057697296143
Validation loss: 2.007957691947619

Epoch: 5| Step: 1
Training loss: 2.4716200828552246
Validation loss: 2.0178824067115784

Epoch: 5| Step: 2
Training loss: 1.9974253177642822
Validation loss: 2.0119928320248923

Epoch: 5| Step: 3
Training loss: 1.46354079246521
Validation loss: 1.9982332189877827

Epoch: 5| Step: 4
Training loss: 2.2737972736358643
Validation loss: 2.012971267104149

Epoch: 5| Step: 5
Training loss: 2.2554891109466553
Validation loss: 2.0251367886861167

Epoch: 5| Step: 6
Training loss: 2.165245532989502
Validation loss: 2.012746572494507

Epoch: 5| Step: 7
Training loss: 2.3895246982574463
Validation loss: 2.0143671234448752

Epoch: 5| Step: 8
Training loss: 2.21941876411438
Validation loss: 2.0258408884207406

Epoch: 5| Step: 9
Training loss: 2.2985548973083496
Validation loss: 2.03010160724322

Epoch: 5| Step: 10
Training loss: 2.1722540855407715
Validation loss: 2.0349061588446298

Epoch: 5| Step: 11
Training loss: 1.470930814743042
Validation loss: 2.009731357296308

Epoch: 96| Step: 0
Training loss: 2.0313491821289062
Validation loss: 2.0082085331281028

Epoch: 5| Step: 1
Training loss: 2.2266814708709717
Validation loss: 2.009940028190613

Epoch: 5| Step: 2
Training loss: 2.131655216217041
Validation loss: 2.015066315730413

Epoch: 5| Step: 3
Training loss: 2.0942413806915283
Validation loss: 2.011585995554924

Epoch: 5| Step: 4
Training loss: 2.0222506523132324
Validation loss: 2.0173252572615943

Epoch: 5| Step: 5
Training loss: 1.7540416717529297
Validation loss: 2.021772171060244

Epoch: 5| Step: 6
Training loss: 2.3788564205169678
Validation loss: 2.0135046541690826

Epoch: 5| Step: 7
Training loss: 2.4905025959014893
Validation loss: 2.01214433213075

Epoch: 5| Step: 8
Training loss: 2.12349271774292
Validation loss: 2.0097618798414865

Epoch: 5| Step: 9
Training loss: 2.1101250648498535
Validation loss: 2.010012870033582

Epoch: 5| Step: 10
Training loss: 2.321427583694458
Validation loss: 2.0059908578793206

Epoch: 5| Step: 11
Training loss: 2.4602131843566895
Validation loss: 2.0073026915391288

Epoch: 97| Step: 0
Training loss: 2.5154852867126465
Validation loss: 2.0090048809846244

Epoch: 5| Step: 1
Training loss: 1.8511371612548828
Validation loss: 2.0122292588154473

Epoch: 5| Step: 2
Training loss: 1.8546518087387085
Validation loss: 2.010256310304006

Epoch: 5| Step: 3
Training loss: 2.3982081413269043
Validation loss: 2.0208351016044617

Epoch: 5| Step: 4
Training loss: 2.506009101867676
Validation loss: 2.0110723028580346

Epoch: 5| Step: 5
Training loss: 1.5943645238876343
Validation loss: 2.0153194616238275

Epoch: 5| Step: 6
Training loss: 1.6714636087417603
Validation loss: 2.022082964579264

Epoch: 5| Step: 7
Training loss: 1.8192894458770752
Validation loss: 2.01985073586305

Epoch: 5| Step: 8
Training loss: 2.1718945503234863
Validation loss: 2.024646575252215

Epoch: 5| Step: 9
Training loss: 2.7515242099761963
Validation loss: 2.0079825967550278

Epoch: 5| Step: 10
Training loss: 2.2910399436950684
Validation loss: 2.019071792562803

Epoch: 5| Step: 11
Training loss: 2.8762989044189453
Validation loss: 2.0129725486040115

Epoch: 98| Step: 0
Training loss: 2.4825053215026855
Validation loss: 2.0252488801876702

Epoch: 5| Step: 1
Training loss: 1.8623955249786377
Validation loss: 2.0269186745087304

Epoch: 5| Step: 2
Training loss: 2.3053512573242188
Validation loss: 2.0161535094181695

Epoch: 5| Step: 3
Training loss: 2.0701773166656494
Validation loss: 2.012391060590744

Epoch: 5| Step: 4
Training loss: 1.3967655897140503
Validation loss: 2.007047032316526

Epoch: 5| Step: 5
Training loss: 1.9920192956924438
Validation loss: 2.0076967775821686

Epoch: 5| Step: 6
Training loss: 2.5382609367370605
Validation loss: 2.0035992711782455

Epoch: 5| Step: 7
Training loss: 2.543945789337158
Validation loss: 2.008170172572136

Epoch: 5| Step: 8
Training loss: 1.771803855895996
Validation loss: 2.0221766432126365

Epoch: 5| Step: 9
Training loss: 1.9865421056747437
Validation loss: 2.026443307598432

Epoch: 5| Step: 10
Training loss: 2.561818838119507
Validation loss: 2.0225586593151093

Epoch: 5| Step: 11
Training loss: 2.8466713428497314
Validation loss: 2.039647191762924

Epoch: 99| Step: 0
Training loss: 2.003380537033081
Validation loss: 2.043151373664538

Epoch: 5| Step: 1
Training loss: 2.3309526443481445
Validation loss: 2.0287863264481225

Epoch: 5| Step: 2
Training loss: 1.076303482055664
Validation loss: 2.0305429647366204

Epoch: 5| Step: 3
Training loss: 2.4108173847198486
Validation loss: 2.015689864754677

Epoch: 5| Step: 4
Training loss: 2.5901899337768555
Validation loss: 2.0163158575693765

Epoch: 5| Step: 5
Training loss: 2.4089462757110596
Validation loss: 2.0137686232725778

Epoch: 5| Step: 6
Training loss: 2.1354074478149414
Validation loss: 2.01532348493735

Epoch: 5| Step: 7
Training loss: 1.7173560857772827
Validation loss: 2.0130502084891

Epoch: 5| Step: 8
Training loss: 2.324031114578247
Validation loss: 2.011659011244774

Epoch: 5| Step: 9
Training loss: 2.6185381412506104
Validation loss: 2.011888767282168

Epoch: 5| Step: 10
Training loss: 2.0136361122131348
Validation loss: 2.0085033724705377

Epoch: 5| Step: 11
Training loss: 1.5656541585922241
Validation loss: 2.0091990729173026

Epoch: 100| Step: 0
Training loss: 2.2864437103271484
Validation loss: 2.0074016054471335

Epoch: 5| Step: 1
Training loss: 2.542590618133545
Validation loss: 2.0151596615711846

Epoch: 5| Step: 2
Training loss: 1.7416470050811768
Validation loss: 2.011313150326411

Epoch: 5| Step: 3
Training loss: 2.0883891582489014
Validation loss: 2.021401767929395

Epoch: 5| Step: 4
Training loss: 2.40930438041687
Validation loss: 2.0245308776696525

Epoch: 5| Step: 5
Training loss: 1.8731606006622314
Validation loss: 2.0117736558119454

Epoch: 5| Step: 6
Training loss: 2.154254674911499
Validation loss: 2.0140525152285895

Epoch: 5| Step: 7
Training loss: 1.6746025085449219
Validation loss: 2.0197304536898932

Epoch: 5| Step: 8
Training loss: 2.0260252952575684
Validation loss: 2.02569180727005

Epoch: 5| Step: 9
Training loss: 2.2872631549835205
Validation loss: 2.0263545165459314

Epoch: 5| Step: 10
Training loss: 2.433337450027466
Validation loss: 2.025472402572632

Epoch: 5| Step: 11
Training loss: 2.210878372192383
Validation loss: 2.0218054801225662

Epoch: 101| Step: 0
Training loss: 2.0429484844207764
Validation loss: 2.011582836508751

Epoch: 5| Step: 1
Training loss: 2.461822986602783
Validation loss: 2.0077124536037445

Epoch: 5| Step: 2
Training loss: 1.8618284463882446
Validation loss: 2.012602766354879

Epoch: 5| Step: 3
Training loss: 2.2465054988861084
Validation loss: 2.005738024910291

Epoch: 5| Step: 4
Training loss: 1.776811957359314
Validation loss: 2.004277298847834

Epoch: 5| Step: 5
Training loss: 2.2578933238983154
Validation loss: 2.002115567525228

Epoch: 5| Step: 6
Training loss: 1.763267159461975
Validation loss: 2.000798667470614

Epoch: 5| Step: 7
Training loss: 2.658055067062378
Validation loss: 2.0118632266918817

Epoch: 5| Step: 8
Training loss: 1.9276211261749268
Validation loss: 2.009066174427668

Epoch: 5| Step: 9
Training loss: 2.3258519172668457
Validation loss: 2.0028721441825232

Epoch: 5| Step: 10
Training loss: 2.028148651123047
Validation loss: 2.0155285596847534

Epoch: 5| Step: 11
Training loss: 3.616793155670166
Validation loss: 2.0122328847646713

Epoch: 102| Step: 0
Training loss: 1.956478476524353
Validation loss: 2.003511905670166

Epoch: 5| Step: 1
Training loss: 2.3303985595703125
Validation loss: 2.0061054627100625

Epoch: 5| Step: 2
Training loss: 2.345421314239502
Validation loss: 1.9963525831699371

Epoch: 5| Step: 3
Training loss: 2.247349977493286
Validation loss: 2.003036598364512

Epoch: 5| Step: 4
Training loss: 2.0276601314544678
Validation loss: 2.005476877093315

Epoch: 5| Step: 5
Training loss: 2.0411314964294434
Validation loss: 2.0040738582611084

Epoch: 5| Step: 6
Training loss: 1.8026056289672852
Validation loss: 1.9981144567330678

Epoch: 5| Step: 7
Training loss: 2.370483636856079
Validation loss: 2.005259469151497

Epoch: 5| Step: 8
Training loss: 2.1277966499328613
Validation loss: 2.0088060398896537

Epoch: 5| Step: 9
Training loss: 2.1040537357330322
Validation loss: 2.005005498727163

Epoch: 5| Step: 10
Training loss: 2.359166383743286
Validation loss: 2.01164477566878

Epoch: 5| Step: 11
Training loss: 1.1032367944717407
Validation loss: 2.0194134016831717

Epoch: 103| Step: 0
Training loss: 1.950635313987732
Validation loss: 2.017595504721006

Epoch: 5| Step: 1
Training loss: 2.1584982872009277
Validation loss: 2.0159083207448325

Epoch: 5| Step: 2
Training loss: 1.7820008993148804
Validation loss: 2.0153895964225135

Epoch: 5| Step: 3
Training loss: 1.788403868675232
Validation loss: 2.0235149463017783

Epoch: 5| Step: 4
Training loss: 2.5935378074645996
Validation loss: 2.027409846584002

Epoch: 5| Step: 5
Training loss: 1.952680230140686
Validation loss: 2.0106374671061835

Epoch: 5| Step: 6
Training loss: 1.5578333139419556
Validation loss: 2.0200837552547455

Epoch: 5| Step: 7
Training loss: 2.5904979705810547
Validation loss: 2.0190342168013253

Epoch: 5| Step: 8
Training loss: 1.6973581314086914
Validation loss: 2.034735212723414

Epoch: 5| Step: 9
Training loss: 2.3882596492767334
Validation loss: 2.019448071718216

Epoch: 5| Step: 10
Training loss: 2.827134609222412
Validation loss: 2.0269944965839386

Epoch: 5| Step: 11
Training loss: 3.180713176727295
Validation loss: 2.0083078195651374

Epoch: 104| Step: 0
Training loss: 1.838078498840332
Validation loss: 2.004806642731031

Epoch: 5| Step: 1
Training loss: 2.4293224811553955
Validation loss: 2.0052592953046164

Epoch: 5| Step: 2
Training loss: 1.8178821802139282
Validation loss: 2.008294925093651

Epoch: 5| Step: 3
Training loss: 2.364673376083374
Validation loss: 1.998339017232259

Epoch: 5| Step: 4
Training loss: 2.2601563930511475
Validation loss: 2.0071613589922586

Epoch: 5| Step: 5
Training loss: 1.9001190662384033
Validation loss: 2.0098549872636795

Epoch: 5| Step: 6
Training loss: 2.4707000255584717
Validation loss: 2.0141028066476188

Epoch: 5| Step: 7
Training loss: 2.1181085109710693
Validation loss: 2.0124759674072266

Epoch: 5| Step: 8
Training loss: 1.9193294048309326
Validation loss: 2.016556824247042

Epoch: 5| Step: 9
Training loss: 2.6072850227355957
Validation loss: 2.028460845351219

Epoch: 5| Step: 10
Training loss: 1.7941615581512451
Validation loss: 2.014107510447502

Epoch: 5| Step: 11
Training loss: 2.072366714477539
Validation loss: 2.0265488227208457

Epoch: 105| Step: 0
Training loss: 2.227029800415039
Validation loss: 2.018367648124695

Epoch: 5| Step: 1
Training loss: 1.8767904043197632
Validation loss: 2.0209942559401193

Epoch: 5| Step: 2
Training loss: 2.0303955078125
Validation loss: 2.021661952137947

Epoch: 5| Step: 3
Training loss: 2.3248119354248047
Validation loss: 2.022163430849711

Epoch: 5| Step: 4
Training loss: 1.624424695968628
Validation loss: 2.032258535424868

Epoch: 5| Step: 5
Training loss: 2.6672637462615967
Validation loss: 2.034850393732389

Epoch: 5| Step: 6
Training loss: 2.2577097415924072
Validation loss: 2.03881399333477

Epoch: 5| Step: 7
Training loss: 1.6806490421295166
Validation loss: 2.032198185722033

Epoch: 5| Step: 8
Training loss: 2.3147644996643066
Validation loss: 2.0276063978672028

Epoch: 5| Step: 9
Training loss: 2.2707436084747314
Validation loss: 2.0112613141536713

Epoch: 5| Step: 10
Training loss: 2.163422107696533
Validation loss: 2.0134002765019736

Epoch: 5| Step: 11
Training loss: 2.7574033737182617
Validation loss: 2.0036996553341546

Epoch: 106| Step: 0
Training loss: 2.0890910625457764
Validation loss: 2.010120620330175

Epoch: 5| Step: 1
Training loss: 2.2134923934936523
Validation loss: 2.0270606875419617

Epoch: 5| Step: 2
Training loss: 2.4799067974090576
Validation loss: 2.0220602055390677

Epoch: 5| Step: 3
Training loss: 2.1414101123809814
Validation loss: 2.02852763235569

Epoch: 5| Step: 4
Training loss: 2.7059073448181152
Validation loss: 2.0201244403918586

Epoch: 5| Step: 5
Training loss: 2.1639952659606934
Validation loss: 2.0324121614297233

Epoch: 5| Step: 6
Training loss: 1.8485898971557617
Validation loss: 2.030982921520869

Epoch: 5| Step: 7
Training loss: 1.7726608514785767
Validation loss: 2.030375967423121

Epoch: 5| Step: 8
Training loss: 2.2207512855529785
Validation loss: 2.018891990184784

Epoch: 5| Step: 9
Training loss: 2.0385189056396484
Validation loss: 2.015293300151825

Epoch: 5| Step: 10
Training loss: 2.1718032360076904
Validation loss: 2.015228475133578

Epoch: 5| Step: 11
Training loss: 2.1392040252685547
Validation loss: 2.010373110572497

Epoch: 107| Step: 0
Training loss: 2.4013431072235107
Validation loss: 2.0027581055959067

Epoch: 5| Step: 1
Training loss: 2.430243968963623
Validation loss: 1.993009939789772

Epoch: 5| Step: 2
Training loss: 1.9270284175872803
Validation loss: 1.9974986563126247

Epoch: 5| Step: 3
Training loss: 2.0679187774658203
Validation loss: 2.004945784807205

Epoch: 5| Step: 4
Training loss: 2.1649389266967773
Validation loss: 2.019257436196009

Epoch: 5| Step: 5
Training loss: 2.8273260593414307
Validation loss: 2.021800766388575

Epoch: 5| Step: 6
Training loss: 1.7804991006851196
Validation loss: 2.0263840605815253

Epoch: 5| Step: 7
Training loss: 2.0982749462127686
Validation loss: 2.037142018477122

Epoch: 5| Step: 8
Training loss: 1.9423401355743408
Validation loss: 2.0316054274638495

Epoch: 5| Step: 9
Training loss: 1.799425482749939
Validation loss: 2.041560545563698

Epoch: 5| Step: 10
Training loss: 1.842633843421936
Validation loss: 2.0230785608291626

Epoch: 5| Step: 11
Training loss: 3.158365249633789
Validation loss: 2.020675912499428

Epoch: 108| Step: 0
Training loss: 2.1204497814178467
Validation loss: 2.012007380525271

Epoch: 5| Step: 1
Training loss: 1.9249969720840454
Validation loss: 2.0037598560253778

Epoch: 5| Step: 2
Training loss: 2.0006179809570312
Validation loss: 1.9985939462979634

Epoch: 5| Step: 3
Training loss: 1.9560019969940186
Validation loss: 1.990917111436526

Epoch: 5| Step: 4
Training loss: 2.4579625129699707
Validation loss: 1.9951565364996593

Epoch: 5| Step: 5
Training loss: 2.4184772968292236
Validation loss: 2.007992093761762

Epoch: 5| Step: 6
Training loss: 2.19584321975708
Validation loss: 1.9970785975456238

Epoch: 5| Step: 7
Training loss: 2.4961133003234863
Validation loss: 1.998467708627383

Epoch: 5| Step: 8
Training loss: 1.8413594961166382
Validation loss: 2.004159986972809

Epoch: 5| Step: 9
Training loss: 1.5733264684677124
Validation loss: 1.995733176668485

Epoch: 5| Step: 10
Training loss: 2.4253904819488525
Validation loss: 1.9976015985012054

Epoch: 5| Step: 11
Training loss: 2.1974668502807617
Validation loss: 2.0018073121706643

Epoch: 109| Step: 0
Training loss: 2.046788454055786
Validation loss: 2.000720903277397

Epoch: 5| Step: 1
Training loss: 2.2486822605133057
Validation loss: 2.0032129734754562

Epoch: 5| Step: 2
Training loss: 2.2133002281188965
Validation loss: 1.9950105994939804

Epoch: 5| Step: 3
Training loss: 2.408141613006592
Validation loss: 2.0039360970258713

Epoch: 5| Step: 4
Training loss: 2.0685324668884277
Validation loss: 2.001753956079483

Epoch: 5| Step: 5
Training loss: 2.3908238410949707
Validation loss: 2.015193541844686

Epoch: 5| Step: 6
Training loss: 1.870051622390747
Validation loss: 2.0330069909493127

Epoch: 5| Step: 7
Training loss: 1.7553287744522095
Validation loss: 2.0240225295225778

Epoch: 5| Step: 8
Training loss: 2.085453987121582
Validation loss: 2.0313217441240945

Epoch: 5| Step: 9
Training loss: 2.2392611503601074
Validation loss: 2.0400696396827698

Epoch: 5| Step: 10
Training loss: 2.1512961387634277
Validation loss: 2.0504976361989975

Epoch: 5| Step: 11
Training loss: 2.168731689453125
Validation loss: 2.0446779231230416

Epoch: 110| Step: 0
Training loss: 2.130450487136841
Validation loss: 2.020781268676122

Epoch: 5| Step: 1
Training loss: 2.53143310546875
Validation loss: 2.016153931617737

Epoch: 5| Step: 2
Training loss: 2.4574453830718994
Validation loss: 2.0007610619068146

Epoch: 5| Step: 3
Training loss: 1.8488296270370483
Validation loss: 1.9896213014920552

Epoch: 5| Step: 4
Training loss: 2.0119872093200684
Validation loss: 1.9876588433980942

Epoch: 5| Step: 5
Training loss: 2.0572524070739746
Validation loss: 2.0027834127346673

Epoch: 5| Step: 6
Training loss: 2.6923069953918457
Validation loss: 2.003049597144127

Epoch: 5| Step: 7
Training loss: 2.3230323791503906
Validation loss: 2.012512038151423

Epoch: 5| Step: 8
Training loss: 2.2233052253723145
Validation loss: 2.009151796499888

Epoch: 5| Step: 9
Training loss: 1.4248616695404053
Validation loss: 2.0101251949866614

Epoch: 5| Step: 10
Training loss: 2.0806801319122314
Validation loss: 2.0109470983346305

Epoch: 5| Step: 11
Training loss: 2.1772632598876953
Validation loss: 2.0050982385873795

Epoch: 111| Step: 0
Training loss: 2.2523419857025146
Validation loss: 2.000946268439293

Epoch: 5| Step: 1
Training loss: 2.321012020111084
Validation loss: 2.002072046200434

Epoch: 5| Step: 2
Training loss: 2.422988176345825
Validation loss: 2.004752352833748

Epoch: 5| Step: 3
Training loss: 2.267683982849121
Validation loss: 1.9954577783743541

Epoch: 5| Step: 4
Training loss: 1.8833057880401611
Validation loss: 2.003048320611318

Epoch: 5| Step: 5
Training loss: 2.4833483695983887
Validation loss: 1.999587709705035

Epoch: 5| Step: 6
Training loss: 2.0038859844207764
Validation loss: 2.0023776392141976

Epoch: 5| Step: 7
Training loss: 2.090252637863159
Validation loss: 2.0063570191462836

Epoch: 5| Step: 8
Training loss: 1.5143208503723145
Validation loss: 2.0178120881319046

Epoch: 5| Step: 9
Training loss: 2.1421680450439453
Validation loss: 2.0135145535071692

Epoch: 5| Step: 10
Training loss: 2.099195957183838
Validation loss: 2.007906903823217

Epoch: 5| Step: 11
Training loss: 1.8878865242004395
Validation loss: 2.0208128094673157

Epoch: 112| Step: 0
Training loss: 1.9769399166107178
Validation loss: 2.023606354991595

Epoch: 5| Step: 1
Training loss: 2.1185379028320312
Validation loss: 2.0282959938049316

Epoch: 5| Step: 2
Training loss: 2.7117977142333984
Validation loss: 2.0277923345565796

Epoch: 5| Step: 3
Training loss: 2.026484727859497
Validation loss: 2.030220394333204

Epoch: 5| Step: 4
Training loss: 1.8292347192764282
Validation loss: 2.026187946399053

Epoch: 5| Step: 5
Training loss: 2.459233045578003
Validation loss: 2.0304684390624366

Epoch: 5| Step: 6
Training loss: 2.322727918624878
Validation loss: 2.0385663956403732

Epoch: 5| Step: 7
Training loss: 2.368269443511963
Validation loss: 2.00957782069842

Epoch: 5| Step: 8
Training loss: 1.7211698293685913
Validation loss: 2.008967086672783

Epoch: 5| Step: 9
Training loss: 2.035273790359497
Validation loss: 2.0061099181572595

Epoch: 5| Step: 10
Training loss: 1.7143608331680298
Validation loss: 2.000936875740687

Epoch: 5| Step: 11
Training loss: 2.7280969619750977
Validation loss: 2.0033184389273324

Epoch: 113| Step: 0
Training loss: 2.2302982807159424
Validation loss: 2.0044112503528595

Epoch: 5| Step: 1
Training loss: 2.420518398284912
Validation loss: 1.995918909708659

Epoch: 5| Step: 2
Training loss: 2.6159303188323975
Validation loss: 1.9926345596710842

Epoch: 5| Step: 3
Training loss: 1.6556155681610107
Validation loss: 1.9952289362748463

Epoch: 5| Step: 4
Training loss: 2.2973318099975586
Validation loss: 1.9960144062836964

Epoch: 5| Step: 5
Training loss: 1.7071497440338135
Validation loss: 2.0026773711045585

Epoch: 5| Step: 6
Training loss: 1.867913007736206
Validation loss: 2.000093678633372

Epoch: 5| Step: 7
Training loss: 2.13931941986084
Validation loss: 2.0011502454678216

Epoch: 5| Step: 8
Training loss: 2.4696121215820312
Validation loss: 2.008346304297447

Epoch: 5| Step: 9
Training loss: 1.8949005603790283
Validation loss: 2.0259578923384347

Epoch: 5| Step: 10
Training loss: 1.927161455154419
Validation loss: 2.0357573529084525

Epoch: 5| Step: 11
Training loss: 2.218625068664551
Validation loss: 2.042357256015142

Epoch: 114| Step: 0
Training loss: 2.2986063957214355
Validation loss: 2.0543203304211297

Epoch: 5| Step: 1
Training loss: 2.1858677864074707
Validation loss: 2.062655140956243

Epoch: 5| Step: 2
Training loss: 1.9038207530975342
Validation loss: 2.0524567613999047

Epoch: 5| Step: 3
Training loss: 1.6590583324432373
Validation loss: 2.0508931626876197

Epoch: 5| Step: 4
Training loss: 1.8724819421768188
Validation loss: 2.0492475032806396

Epoch: 5| Step: 5
Training loss: 2.571166515350342
Validation loss: 2.047889918088913

Epoch: 5| Step: 6
Training loss: 2.13131046295166
Validation loss: 2.0194192032019296

Epoch: 5| Step: 7
Training loss: 1.8861217498779297
Validation loss: 2.0168000012636185

Epoch: 5| Step: 8
Training loss: 2.239902973175049
Validation loss: 2.0177994668483734

Epoch: 5| Step: 9
Training loss: 2.6226508617401123
Validation loss: 2.012856433788935

Epoch: 5| Step: 10
Training loss: 2.100581645965576
Validation loss: 2.0165310551722846

Epoch: 5| Step: 11
Training loss: 2.4043030738830566
Validation loss: 2.004790539542834

Epoch: 115| Step: 0
Training loss: 2.2916553020477295
Validation loss: 2.019635866085688

Epoch: 5| Step: 1
Training loss: 2.4774787425994873
Validation loss: 2.0201483368873596

Epoch: 5| Step: 2
Training loss: 1.9592252969741821
Validation loss: 2.0060823609431586

Epoch: 5| Step: 3
Training loss: 1.690393090248108
Validation loss: 2.0038230568170547

Epoch: 5| Step: 4
Training loss: 1.9679882526397705
Validation loss: 2.0112354209025702

Epoch: 5| Step: 5
Training loss: 1.759572982788086
Validation loss: 2.0180980612834296

Epoch: 5| Step: 6
Training loss: 1.9633890390396118
Validation loss: 2.0191352516412735

Epoch: 5| Step: 7
Training loss: 2.470785140991211
Validation loss: 2.020498370130857

Epoch: 5| Step: 8
Training loss: 2.2611615657806396
Validation loss: 2.03418663640817

Epoch: 5| Step: 9
Training loss: 2.6191439628601074
Validation loss: 2.0374226172765098

Epoch: 5| Step: 10
Training loss: 2.190314769744873
Validation loss: 2.034037326773008

Epoch: 5| Step: 11
Training loss: 0.32825320959091187
Validation loss: 2.027629569172859

Epoch: 116| Step: 0
Training loss: 1.594684362411499
Validation loss: 2.029941663146019

Epoch: 5| Step: 1
Training loss: 2.385643482208252
Validation loss: 2.020599737763405

Epoch: 5| Step: 2
Training loss: 1.9181270599365234
Validation loss: 2.019616737961769

Epoch: 5| Step: 3
Training loss: 2.5618348121643066
Validation loss: 2.0230132937431335

Epoch: 5| Step: 4
Training loss: 2.091153621673584
Validation loss: 2.0220181246598563

Epoch: 5| Step: 5
Training loss: 2.1816210746765137
Validation loss: 2.006855602065722

Epoch: 5| Step: 6
Training loss: 1.8860301971435547
Validation loss: 2.008060574531555

Epoch: 5| Step: 7
Training loss: 1.899082899093628
Validation loss: 2.005970224738121

Epoch: 5| Step: 8
Training loss: 2.283566951751709
Validation loss: 2.02124352256457

Epoch: 5| Step: 9
Training loss: 2.235704183578491
Validation loss: 2.022175391515096

Epoch: 5| Step: 10
Training loss: 2.319326400756836
Validation loss: 2.02278770506382

Epoch: 5| Step: 11
Training loss: 1.7120208740234375
Validation loss: 2.0305918405453363

Epoch: 117| Step: 0
Training loss: 2.2159183025360107
Validation loss: 2.027817517518997

Epoch: 5| Step: 1
Training loss: 2.1341793537139893
Validation loss: 2.0312892347574234

Epoch: 5| Step: 2
Training loss: 2.7736644744873047
Validation loss: 2.0403245141108832

Epoch: 5| Step: 3
Training loss: 2.2047619819641113
Validation loss: 2.019976665576299

Epoch: 5| Step: 4
Training loss: 1.5719505548477173
Validation loss: 2.014455497264862

Epoch: 5| Step: 5
Training loss: 2.0233185291290283
Validation loss: 2.0098775128523507

Epoch: 5| Step: 6
Training loss: 2.046936511993408
Validation loss: 2.0065962920586267

Epoch: 5| Step: 7
Training loss: 1.6772260665893555
Validation loss: 2.004756679137548

Epoch: 5| Step: 8
Training loss: 2.2642669677734375
Validation loss: 2.0078578740358353

Epoch: 5| Step: 9
Training loss: 2.112859010696411
Validation loss: 2.0044105648994446

Epoch: 5| Step: 10
Training loss: 2.4703402519226074
Validation loss: 2.0096249183019004

Epoch: 5| Step: 11
Training loss: 1.7875170707702637
Validation loss: 2.0042373538017273

Epoch: 118| Step: 0
Training loss: 1.9916226863861084
Validation loss: 2.002444088459015

Epoch: 5| Step: 1
Training loss: 1.693593978881836
Validation loss: 2.0135763188203177

Epoch: 5| Step: 2
Training loss: 2.318336009979248
Validation loss: 2.0061023831367493

Epoch: 5| Step: 3
Training loss: 1.9334118366241455
Validation loss: 2.0116462111473083

Epoch: 5| Step: 4
Training loss: 2.2455310821533203
Validation loss: 2.0149007687966027

Epoch: 5| Step: 5
Training loss: 1.9280462265014648
Validation loss: 2.0172373404105506

Epoch: 5| Step: 6
Training loss: 2.7629916667938232
Validation loss: 2.0373770793279014

Epoch: 5| Step: 7
Training loss: 2.136340856552124
Validation loss: 2.0313240587711334

Epoch: 5| Step: 8
Training loss: 1.6568180322647095
Validation loss: 2.04439086218675

Epoch: 5| Step: 9
Training loss: 2.1303935050964355
Validation loss: 2.048604726791382

Epoch: 5| Step: 10
Training loss: 2.4622015953063965
Validation loss: 2.0507182528575263

Epoch: 5| Step: 11
Training loss: 2.5276873111724854
Validation loss: 2.0414078384637833

Epoch: 119| Step: 0
Training loss: 2.119436740875244
Validation loss: 2.036684031287829

Epoch: 5| Step: 1
Training loss: 2.2894339561462402
Validation loss: 2.0370548913876214

Epoch: 5| Step: 2
Training loss: 2.0809967517852783
Validation loss: 2.0316697508096695

Epoch: 5| Step: 3
Training loss: 2.1933646202087402
Validation loss: 2.0247617264588675

Epoch: 5| Step: 4
Training loss: 1.8060916662216187
Validation loss: 2.0251411894957223

Epoch: 5| Step: 5
Training loss: 1.7890926599502563
Validation loss: 2.011338328321775

Epoch: 5| Step: 6
Training loss: 2.044814348220825
Validation loss: 2.012812688946724

Epoch: 5| Step: 7
Training loss: 2.13433575630188
Validation loss: 2.011572783191999

Epoch: 5| Step: 8
Training loss: 2.407802104949951
Validation loss: 2.000437786181768

Epoch: 5| Step: 9
Training loss: 2.2750582695007324
Validation loss: 2.0137750009695687

Epoch: 5| Step: 10
Training loss: 1.9868711233139038
Validation loss: 2.0043755571047464

Epoch: 5| Step: 11
Training loss: 2.1751697063446045
Validation loss: 2.010972614089648

Epoch: 120| Step: 0
Training loss: 2.1417064666748047
Validation loss: 2.0100681136051812

Epoch: 5| Step: 1
Training loss: 2.2337639331817627
Validation loss: 2.0202639947334924

Epoch: 5| Step: 2
Training loss: 2.116299867630005
Validation loss: 2.0324837267398834

Epoch: 5| Step: 3
Training loss: 1.917903184890747
Validation loss: 2.0256113509337106

Epoch: 5| Step: 4
Training loss: 1.4417221546173096
Validation loss: 2.035911704103152

Epoch: 5| Step: 5
Training loss: 2.2099571228027344
Validation loss: 2.031832367181778

Epoch: 5| Step: 6
Training loss: 2.8944289684295654
Validation loss: 2.0508980254332223

Epoch: 5| Step: 7
Training loss: 2.414659261703491
Validation loss: 2.057008152206739

Epoch: 5| Step: 8
Training loss: 1.5678787231445312
Validation loss: 2.064106747508049

Epoch: 5| Step: 9
Training loss: 2.5718798637390137
Validation loss: 2.0666966885328293

Epoch: 5| Step: 10
Training loss: 1.8587195873260498
Validation loss: 2.050710697968801

Epoch: 5| Step: 11
Training loss: 2.1447322368621826
Validation loss: 2.0501774499813714

Epoch: 121| Step: 0
Training loss: 2.282538890838623
Validation loss: 2.0250930984814963

Epoch: 5| Step: 1
Training loss: 2.1467065811157227
Validation loss: 2.0076790849367776

Epoch: 5| Step: 2
Training loss: 1.7057664394378662
Validation loss: 2.011658718188604

Epoch: 5| Step: 3
Training loss: 1.926422119140625
Validation loss: 2.0152873595555625

Epoch: 5| Step: 4
Training loss: 2.1616241931915283
Validation loss: 2.0215237587690353

Epoch: 5| Step: 5
Training loss: 2.1628520488739014
Validation loss: 2.0375713805357614

Epoch: 5| Step: 6
Training loss: 2.142259120941162
Validation loss: 2.031588484843572

Epoch: 5| Step: 7
Training loss: 2.177032947540283
Validation loss: 2.047211155295372

Epoch: 5| Step: 8
Training loss: 2.6101815700531006
Validation loss: 2.0436590711275735

Epoch: 5| Step: 9
Training loss: 2.524024486541748
Validation loss: 2.0379275530576706

Epoch: 5| Step: 10
Training loss: 2.136821746826172
Validation loss: 2.0421445270379386

Epoch: 5| Step: 11
Training loss: 2.578489303588867
Validation loss: 2.0431086917718253

Epoch: 122| Step: 0
Training loss: 2.127326488494873
Validation loss: 2.042163610458374

Epoch: 5| Step: 1
Training loss: 2.776759386062622
Validation loss: 2.043615554769834

Epoch: 5| Step: 2
Training loss: 2.3567004203796387
Validation loss: 2.0437910904486976

Epoch: 5| Step: 3
Training loss: 1.8615615367889404
Validation loss: 2.0437936782836914

Epoch: 5| Step: 4
Training loss: 2.3685996532440186
Validation loss: 2.0450033297141395

Epoch: 5| Step: 5
Training loss: 2.0768496990203857
Validation loss: 2.0440885523955026

Epoch: 5| Step: 6
Training loss: 2.372431516647339
Validation loss: 2.0421560208002725

Epoch: 5| Step: 7
Training loss: 1.92035710811615
Validation loss: 2.03974249958992

Epoch: 5| Step: 8
Training loss: 1.8573637008666992
Validation loss: 2.035341337323189

Epoch: 5| Step: 9
Training loss: 2.310046672821045
Validation loss: 2.028336152434349

Epoch: 5| Step: 10
Training loss: 2.2053732872009277
Validation loss: 2.0333339969317117

Epoch: 5| Step: 11
Training loss: 1.970744013786316
Validation loss: 2.024934709072113

Epoch: 123| Step: 0
Training loss: 2.1576244831085205
Validation loss: 2.021604617436727

Epoch: 5| Step: 1
Training loss: 1.8542486429214478
Validation loss: 2.021715293327967

Epoch: 5| Step: 2
Training loss: 2.229196071624756
Validation loss: 2.0158924013376236

Epoch: 5| Step: 3
Training loss: 1.7404826879501343
Validation loss: 2.0079597532749176

Epoch: 5| Step: 4
Training loss: 2.2302894592285156
Validation loss: 2.0083273500204086

Epoch: 5| Step: 5
Training loss: 2.3991196155548096
Validation loss: 2.0064581433931985

Epoch: 5| Step: 6
Training loss: 2.3034088611602783
Validation loss: 2.001408651471138

Epoch: 5| Step: 7
Training loss: 2.5908095836639404
Validation loss: 2.007698198159536

Epoch: 5| Step: 8
Training loss: 1.9958326816558838
Validation loss: 1.9958406736453373

Epoch: 5| Step: 9
Training loss: 2.2496464252471924
Validation loss: 1.997203807036082

Epoch: 5| Step: 10
Training loss: 1.9660543203353882
Validation loss: 1.9867050498723984

Epoch: 5| Step: 11
Training loss: 1.4861609935760498
Validation loss: 1.9832025369008381

Epoch: 124| Step: 0
Training loss: 1.8837239742279053
Validation loss: 1.9923664430777233

Epoch: 5| Step: 1
Training loss: 2.274909019470215
Validation loss: 1.9930698523918788

Epoch: 5| Step: 2
Training loss: 2.4011728763580322
Validation loss: 2.0012301529447236

Epoch: 5| Step: 3
Training loss: 1.6409943103790283
Validation loss: 2.000609427690506

Epoch: 5| Step: 4
Training loss: 2.4165685176849365
Validation loss: 2.006500373284022

Epoch: 5| Step: 5
Training loss: 2.405264139175415
Validation loss: 2.002348373333613

Epoch: 5| Step: 6
Training loss: 2.616938352584839
Validation loss: 2.014978379011154

Epoch: 5| Step: 7
Training loss: 2.3153929710388184
Validation loss: 2.007596621910731

Epoch: 5| Step: 8
Training loss: 2.170626401901245
Validation loss: 2.015068218111992

Epoch: 5| Step: 9
Training loss: 1.763016700744629
Validation loss: 2.0042185386021933

Epoch: 5| Step: 10
Training loss: 1.4605309963226318
Validation loss: 2.0099460581938424

Epoch: 5| Step: 11
Training loss: 1.8041157722473145
Validation loss: 2.014886717001597

Epoch: 125| Step: 0
Training loss: 1.8138515949249268
Validation loss: 2.010426883896192

Epoch: 5| Step: 1
Training loss: 2.1739468574523926
Validation loss: 2.0109770198663077

Epoch: 5| Step: 2
Training loss: 2.5042805671691895
Validation loss: 2.0048842281103134

Epoch: 5| Step: 3
Training loss: 1.7416694164276123
Validation loss: 2.0155693093935647

Epoch: 5| Step: 4
Training loss: 1.9983222484588623
Validation loss: 2.0082391252120337

Epoch: 5| Step: 5
Training loss: 2.2279021739959717
Validation loss: 2.0119722733894982

Epoch: 5| Step: 6
Training loss: 2.2225558757781982
Validation loss: 1.99747567375501

Epoch: 5| Step: 7
Training loss: 2.1647300720214844
Validation loss: 2.0079862425724664

Epoch: 5| Step: 8
Training loss: 2.4624531269073486
Validation loss: 2.001429572701454

Epoch: 5| Step: 9
Training loss: 1.9574611186981201
Validation loss: 2.004002129038175

Epoch: 5| Step: 10
Training loss: 2.0741453170776367
Validation loss: 1.9920589576164882

Epoch: 5| Step: 11
Training loss: 1.2386760711669922
Validation loss: 2.0086079289515815

Epoch: 126| Step: 0
Training loss: 1.6267130374908447
Validation loss: 2.0129009187221527

Epoch: 5| Step: 1
Training loss: 1.8521283864974976
Validation loss: 2.0027409195899963

Epoch: 5| Step: 2
Training loss: 2.6292102336883545
Validation loss: 2.007087896267573

Epoch: 5| Step: 3
Training loss: 1.9266586303710938
Validation loss: 2.016019026438395

Epoch: 5| Step: 4
Training loss: 2.492259979248047
Validation loss: 2.0172794461250305

Epoch: 5| Step: 5
Training loss: 1.7585175037384033
Validation loss: 2.0242317616939545

Epoch: 5| Step: 6
Training loss: 2.471395492553711
Validation loss: 2.029348502556483

Epoch: 5| Step: 7
Training loss: 1.721880555152893
Validation loss: 2.036408394575119

Epoch: 5| Step: 8
Training loss: 2.764835834503174
Validation loss: 2.0441875408093133

Epoch: 5| Step: 9
Training loss: 2.335136890411377
Validation loss: 2.0367332249879837

Epoch: 5| Step: 10
Training loss: 2.096574068069458
Validation loss: 2.021974503993988

Epoch: 5| Step: 11
Training loss: 0.7497406601905823
Validation loss: 2.0193624049425125

Epoch: 127| Step: 0
Training loss: 2.2714550495147705
Validation loss: 2.010839894413948

Epoch: 5| Step: 1
Training loss: 2.216644048690796
Validation loss: 2.016551196575165

Epoch: 5| Step: 2
Training loss: 2.176210641860962
Validation loss: 2.0174387147029242

Epoch: 5| Step: 3
Training loss: 2.517467975616455
Validation loss: 2.0162270317475

Epoch: 5| Step: 4
Training loss: 1.4020230770111084
Validation loss: 2.0164558390776315

Epoch: 5| Step: 5
Training loss: 2.409578800201416
Validation loss: 2.020944053928057

Epoch: 5| Step: 6
Training loss: 2.5858492851257324
Validation loss: 2.0139175405104957

Epoch: 5| Step: 7
Training loss: 1.7373569011688232
Validation loss: 2.0226844996213913

Epoch: 5| Step: 8
Training loss: 2.2328009605407715
Validation loss: 2.0269000778595605

Epoch: 5| Step: 9
Training loss: 2.0992636680603027
Validation loss: 2.018047774831454

Epoch: 5| Step: 10
Training loss: 2.0138120651245117
Validation loss: 2.0207140197356543

Epoch: 5| Step: 11
Training loss: 2.0919594764709473
Validation loss: 2.0098607937494912

Epoch: 128| Step: 0
Training loss: 2.030388116836548
Validation loss: 2.019602378209432

Epoch: 5| Step: 1
Training loss: 2.2220044136047363
Validation loss: 2.0201989909013114

Epoch: 5| Step: 2
Training loss: 2.361208915710449
Validation loss: 2.0135879268248877

Epoch: 5| Step: 3
Training loss: 2.0349953174591064
Validation loss: 2.0133554289738336

Epoch: 5| Step: 4
Training loss: 2.0576155185699463
Validation loss: 2.002862880627314

Epoch: 5| Step: 5
Training loss: 2.022773265838623
Validation loss: 2.003124843041102

Epoch: 5| Step: 6
Training loss: 2.353454113006592
Validation loss: 2.0113289852937064

Epoch: 5| Step: 7
Training loss: 2.048271656036377
Validation loss: 2.0266628911097846

Epoch: 5| Step: 8
Training loss: 1.9631065130233765
Validation loss: 2.0147048930327096

Epoch: 5| Step: 9
Training loss: 2.0242443084716797
Validation loss: 2.0271100997924805

Epoch: 5| Step: 10
Training loss: 2.274895191192627
Validation loss: 2.0373345613479614

Epoch: 5| Step: 11
Training loss: 1.6031532287597656
Validation loss: 2.0299459795157113

Epoch: 129| Step: 0
Training loss: 2.0910048484802246
Validation loss: 2.029964864253998

Epoch: 5| Step: 1
Training loss: 1.9241816997528076
Validation loss: 2.0244296938180923

Epoch: 5| Step: 2
Training loss: 1.8268215656280518
Validation loss: 2.0321137408415475

Epoch: 5| Step: 3
Training loss: 2.6697781085968018
Validation loss: 2.02896981438001

Epoch: 5| Step: 4
Training loss: 2.352292537689209
Validation loss: 2.0309618711471558

Epoch: 5| Step: 5
Training loss: 1.925235390663147
Validation loss: 2.0354535430669785

Epoch: 5| Step: 6
Training loss: 2.2079200744628906
Validation loss: 2.014846553405126

Epoch: 5| Step: 7
Training loss: 1.7041473388671875
Validation loss: 2.029200106859207

Epoch: 5| Step: 8
Training loss: 2.1897788047790527
Validation loss: 2.028071035941442

Epoch: 5| Step: 9
Training loss: 1.9997541904449463
Validation loss: 2.0224189162254333

Epoch: 5| Step: 10
Training loss: 2.2509098052978516
Validation loss: 2.020932505528132

Epoch: 5| Step: 11
Training loss: 1.4677544832229614
Validation loss: 2.013007546464602

Epoch: 130| Step: 0
Training loss: 2.516512632369995
Validation loss: 2.006069779396057

Epoch: 5| Step: 1
Training loss: 1.5377204418182373
Validation loss: 2.0165072878201804

Epoch: 5| Step: 2
Training loss: 1.736840844154358
Validation loss: 2.0190268009901047

Epoch: 5| Step: 3
Training loss: 2.117215156555176
Validation loss: 2.017877216140429

Epoch: 5| Step: 4
Training loss: 2.0700109004974365
Validation loss: 2.010221709807714

Epoch: 5| Step: 5
Training loss: 2.115516185760498
Validation loss: 2.017668599883715

Epoch: 5| Step: 6
Training loss: 1.6933950185775757
Validation loss: 2.024157330393791

Epoch: 5| Step: 7
Training loss: 2.5902316570281982
Validation loss: 2.0360284000635147

Epoch: 5| Step: 8
Training loss: 1.7206745147705078
Validation loss: 2.034610946973165

Epoch: 5| Step: 9
Training loss: 2.2347052097320557
Validation loss: 2.0240347733100257

Epoch: 5| Step: 10
Training loss: 2.492685079574585
Validation loss: 2.021085873246193

Epoch: 5| Step: 11
Training loss: 2.4484848976135254
Validation loss: 2.0364172011613846

Epoch: 131| Step: 0
Training loss: 1.6003754138946533
Validation loss: 2.0294863283634186

Epoch: 5| Step: 1
Training loss: 2.088355541229248
Validation loss: 2.0454343060652413

Epoch: 5| Step: 2
Training loss: 2.352787494659424
Validation loss: 2.03076608479023

Epoch: 5| Step: 3
Training loss: 1.5927666425704956
Validation loss: 2.0259181757767997

Epoch: 5| Step: 4
Training loss: 2.091191291809082
Validation loss: 2.0256946434577308

Epoch: 5| Step: 5
Training loss: 2.008143663406372
Validation loss: 2.0289837221304574

Epoch: 5| Step: 6
Training loss: 2.828479290008545
Validation loss: 2.020702302455902

Epoch: 5| Step: 7
Training loss: 2.544433116912842
Validation loss: 2.0075573275486627

Epoch: 5| Step: 8
Training loss: 1.9713042974472046
Validation loss: 1.999735027551651

Epoch: 5| Step: 9
Training loss: 1.921094298362732
Validation loss: 2.0088549653689065

Epoch: 5| Step: 10
Training loss: 2.0430405139923096
Validation loss: 2.0079888006051383

Epoch: 5| Step: 11
Training loss: 2.798044443130493
Validation loss: 2.0093321402867637

Epoch: 132| Step: 0
Training loss: 1.6381006240844727
Validation loss: 2.0012411822875342

Epoch: 5| Step: 1
Training loss: 2.506932497024536
Validation loss: 2.006443962454796

Epoch: 5| Step: 2
Training loss: 2.033073902130127
Validation loss: 2.0054326355457306

Epoch: 5| Step: 3
Training loss: 2.295429229736328
Validation loss: 2.018467058738073

Epoch: 5| Step: 4
Training loss: 2.1088383197784424
Validation loss: 2.0105455021063485

Epoch: 5| Step: 5
Training loss: 2.160935878753662
Validation loss: 2.0089074671268463

Epoch: 5| Step: 6
Training loss: 2.1551575660705566
Validation loss: 2.020891949534416

Epoch: 5| Step: 7
Training loss: 1.83892023563385
Validation loss: 2.047458986441294

Epoch: 5| Step: 8
Training loss: 2.509065628051758
Validation loss: 2.0409816404183707

Epoch: 5| Step: 9
Training loss: 2.089810371398926
Validation loss: 2.0365995268026986

Epoch: 5| Step: 10
Training loss: 1.9185949563980103
Validation loss: 2.053918798764547

Epoch: 5| Step: 11
Training loss: 2.549910306930542
Validation loss: 2.0440595845381417

Epoch: 133| Step: 0
Training loss: 2.2511119842529297
Validation loss: 2.0449773321549096

Epoch: 5| Step: 1
Training loss: 2.3720366954803467
Validation loss: 2.0403161495923996

Epoch: 5| Step: 2
Training loss: 2.319427490234375
Validation loss: 2.040086363752683

Epoch: 5| Step: 3
Training loss: 2.341153621673584
Validation loss: 2.0291304538647332

Epoch: 5| Step: 4
Training loss: 2.0117390155792236
Validation loss: 2.033861289421717

Epoch: 5| Step: 5
Training loss: 1.3095992803573608
Validation loss: 2.035826787352562

Epoch: 5| Step: 6
Training loss: 2.23529052734375
Validation loss: 2.0226103315750756

Epoch: 5| Step: 7
Training loss: 1.8680330514907837
Validation loss: 2.0064480900764465

Epoch: 5| Step: 8
Training loss: 2.0888493061065674
Validation loss: 2.016753077507019

Epoch: 5| Step: 9
Training loss: 2.4313066005706787
Validation loss: 2.016269197066625

Epoch: 5| Step: 10
Training loss: 1.5763130187988281
Validation loss: 2.0167956550916037

Epoch: 5| Step: 11
Training loss: 2.613152265548706
Validation loss: 2.0295608739058175

Epoch: 134| Step: 0
Training loss: 1.982757806777954
Validation loss: 2.0255503008762994

Epoch: 5| Step: 1
Training loss: 1.868394136428833
Validation loss: 2.031235635280609

Epoch: 5| Step: 2
Training loss: 2.5156993865966797
Validation loss: 2.034980610013008

Epoch: 5| Step: 3
Training loss: 1.9770981073379517
Validation loss: 2.039041648308436

Epoch: 5| Step: 4
Training loss: 2.0423083305358887
Validation loss: 2.0396377742290497

Epoch: 5| Step: 5
Training loss: 1.5423051118850708
Validation loss: 2.029505024353663

Epoch: 5| Step: 6
Training loss: 2.1067121028900146
Validation loss: 2.0475180794795356

Epoch: 5| Step: 7
Training loss: 2.1981453895568848
Validation loss: 2.0383797585964203

Epoch: 5| Step: 8
Training loss: 2.072382926940918
Validation loss: 2.0544281750917435

Epoch: 5| Step: 9
Training loss: 2.0435688495635986
Validation loss: 2.049477423230807

Epoch: 5| Step: 10
Training loss: 2.3603475093841553
Validation loss: 2.0527412990729013

Epoch: 5| Step: 11
Training loss: 2.8182425498962402
Validation loss: 2.043937901655833

Epoch: 135| Step: 0
Training loss: 2.235105037689209
Validation loss: 2.0461695343255997

Epoch: 5| Step: 1
Training loss: 2.148937702178955
Validation loss: 2.042606924970945

Epoch: 5| Step: 2
Training loss: 2.60310959815979
Validation loss: 2.0307464450597763

Epoch: 5| Step: 3
Training loss: 1.9340131282806396
Validation loss: 2.0357401420672736

Epoch: 5| Step: 4
Training loss: 2.8610434532165527
Validation loss: 2.0326330264409385

Epoch: 5| Step: 5
Training loss: 1.4866209030151367
Validation loss: 2.0224099655946097

Epoch: 5| Step: 6
Training loss: 1.5259106159210205
Validation loss: 2.0231880098581314

Epoch: 5| Step: 7
Training loss: 2.5071053504943848
Validation loss: 2.023631274700165

Epoch: 5| Step: 8
Training loss: 1.983588457107544
Validation loss: 2.033783569931984

Epoch: 5| Step: 9
Training loss: 1.6622724533081055
Validation loss: 2.030575921138128

Epoch: 5| Step: 10
Training loss: 1.9823068380355835
Validation loss: 2.030520165959994

Epoch: 5| Step: 11
Training loss: 2.0634241104125977
Validation loss: 2.028383657336235

Epoch: 136| Step: 0
Training loss: 2.1583046913146973
Validation loss: 2.0498684545358024

Epoch: 5| Step: 1
Training loss: 2.0277538299560547
Validation loss: 2.0485521405935287

Epoch: 5| Step: 2
Training loss: 1.9472370147705078
Validation loss: 2.0324467569589615

Epoch: 5| Step: 3
Training loss: 1.789768934249878
Validation loss: 2.024947981039683

Epoch: 5| Step: 4
Training loss: 2.148906707763672
Validation loss: 2.029175122578939

Epoch: 5| Step: 5
Training loss: 2.541337013244629
Validation loss: 2.0416352351506553

Epoch: 5| Step: 6
Training loss: 2.1632230281829834
Validation loss: 2.0352941006422043

Epoch: 5| Step: 7
Training loss: 2.0426814556121826
Validation loss: 2.0253067215283713

Epoch: 5| Step: 8
Training loss: 1.9778451919555664
Validation loss: 2.030681093533834

Epoch: 5| Step: 9
Training loss: 1.8558114767074585
Validation loss: 2.0282330363988876

Epoch: 5| Step: 10
Training loss: 2.1990790367126465
Validation loss: 2.022923360268275

Epoch: 5| Step: 11
Training loss: 2.29524302482605
Validation loss: 2.016401529312134

Epoch: 137| Step: 0
Training loss: 1.7619106769561768
Validation loss: 2.024187907576561

Epoch: 5| Step: 1
Training loss: 2.271374225616455
Validation loss: 2.0462788542111716

Epoch: 5| Step: 2
Training loss: 1.6866543292999268
Validation loss: 2.061011850833893

Epoch: 5| Step: 3
Training loss: 2.0227627754211426
Validation loss: 2.0561892837285995

Epoch: 5| Step: 4
Training loss: 2.376661539077759
Validation loss: 2.044583315650622

Epoch: 5| Step: 5
Training loss: 1.460145354270935
Validation loss: 2.037591909368833

Epoch: 5| Step: 6
Training loss: 2.080941915512085
Validation loss: 2.043320059776306

Epoch: 5| Step: 7
Training loss: 2.7258243560791016
Validation loss: 2.056732048590978

Epoch: 5| Step: 8
Training loss: 2.2789394855499268
Validation loss: 2.0558630724747977

Epoch: 5| Step: 9
Training loss: 2.386786937713623
Validation loss: 2.051060229539871

Epoch: 5| Step: 10
Training loss: 1.6844907999038696
Validation loss: 2.0230367481708527

Epoch: 5| Step: 11
Training loss: 2.82185697555542
Validation loss: 2.032607172926267

Epoch: 138| Step: 0
Training loss: 2.453742742538452
Validation loss: 2.0189196368058524

Epoch: 5| Step: 1
Training loss: 2.2319908142089844
Validation loss: 2.0162306924661

Epoch: 5| Step: 2
Training loss: 2.0011227130889893
Validation loss: 2.021189327041308

Epoch: 5| Step: 3
Training loss: 1.8956716060638428
Validation loss: 2.027986561258634

Epoch: 5| Step: 4
Training loss: 2.1280035972595215
Validation loss: 2.023107906182607

Epoch: 5| Step: 5
Training loss: 1.6261409521102905
Validation loss: 2.0317000349362693

Epoch: 5| Step: 6
Training loss: 1.9077816009521484
Validation loss: 2.0358748684326806

Epoch: 5| Step: 7
Training loss: 2.5585930347442627
Validation loss: 2.024963393807411

Epoch: 5| Step: 8
Training loss: 1.9464185237884521
Validation loss: 2.0393045792977014

Epoch: 5| Step: 9
Training loss: 2.6873345375061035
Validation loss: 2.027498871088028

Epoch: 5| Step: 10
Training loss: 1.726340651512146
Validation loss: 2.0346859892209372

Epoch: 5| Step: 11
Training loss: 1.707187294960022
Validation loss: 2.0228750507036843

Epoch: 139| Step: 0
Training loss: 1.9492073059082031
Validation loss: 2.0215863982836404

Epoch: 5| Step: 1
Training loss: 2.003896713256836
Validation loss: 2.023346652587255

Epoch: 5| Step: 2
Training loss: 2.455432653427124
Validation loss: 2.022567242383957

Epoch: 5| Step: 3
Training loss: 1.8644607067108154
Validation loss: 2.0177956968545914

Epoch: 5| Step: 4
Training loss: 1.6380929946899414
Validation loss: 2.0176746944586434

Epoch: 5| Step: 5
Training loss: 2.4167511463165283
Validation loss: 2.0092390924692154

Epoch: 5| Step: 6
Training loss: 2.4472432136535645
Validation loss: 2.023167242606481

Epoch: 5| Step: 7
Training loss: 2.1736621856689453
Validation loss: 2.022358482082685

Epoch: 5| Step: 8
Training loss: 2.4120559692382812
Validation loss: 2.0249418367942176

Epoch: 5| Step: 9
Training loss: 1.4739294052124023
Validation loss: 2.0171878884236016

Epoch: 5| Step: 10
Training loss: 1.9224685430526733
Validation loss: 2.020445088545481

Epoch: 5| Step: 11
Training loss: 2.8188138008117676
Validation loss: 2.0230423162380853

Epoch: 140| Step: 0
Training loss: 1.5218188762664795
Validation loss: 2.02885140478611

Epoch: 5| Step: 1
Training loss: 1.5005664825439453
Validation loss: 2.023391137520472

Epoch: 5| Step: 2
Training loss: 1.6921424865722656
Validation loss: 2.033858706553777

Epoch: 5| Step: 3
Training loss: 2.3269834518432617
Validation loss: 2.0463927735884986

Epoch: 5| Step: 4
Training loss: 1.953226089477539
Validation loss: 2.0554140210151672

Epoch: 5| Step: 5
Training loss: 2.5171897411346436
Validation loss: 2.0566577315330505

Epoch: 5| Step: 6
Training loss: 2.4470183849334717
Validation loss: 2.065039426088333

Epoch: 5| Step: 7
Training loss: 1.625531792640686
Validation loss: 2.0528583228588104

Epoch: 5| Step: 8
Training loss: 2.5561583042144775
Validation loss: 2.046320458253225

Epoch: 5| Step: 9
Training loss: 2.3774514198303223
Validation loss: 2.0328099876642227

Epoch: 5| Step: 10
Training loss: 2.0136706829071045
Validation loss: 2.020472144087156

Epoch: 5| Step: 11
Training loss: 3.4712963104248047
Validation loss: 2.0103227396806083

Epoch: 141| Step: 0
Training loss: 2.119072437286377
Validation loss: 2.0134755969047546

Epoch: 5| Step: 1
Training loss: 2.829720973968506
Validation loss: 2.011295939485232

Epoch: 5| Step: 2
Training loss: 1.618546485900879
Validation loss: 2.033217882116636

Epoch: 5| Step: 3
Training loss: 1.8921102285385132
Validation loss: 2.0363816618919373

Epoch: 5| Step: 4
Training loss: 2.224437713623047
Validation loss: 2.0392273416121802

Epoch: 5| Step: 5
Training loss: 2.5186424255371094
Validation loss: 2.0465656220912933

Epoch: 5| Step: 6
Training loss: 2.496504306793213
Validation loss: 2.038927987217903

Epoch: 5| Step: 7
Training loss: 1.9031684398651123
Validation loss: 2.044317533572515

Epoch: 5| Step: 8
Training loss: 2.1011695861816406
Validation loss: 2.04731193681558

Epoch: 5| Step: 9
Training loss: 2.1534953117370605
Validation loss: 2.048290510972341

Epoch: 5| Step: 10
Training loss: 1.6163628101348877
Validation loss: 2.0393658181031546

Epoch: 5| Step: 11
Training loss: 2.838618278503418
Validation loss: 2.037626097599665

Epoch: 142| Step: 0
Training loss: 2.1484878063201904
Validation loss: 2.032420724630356

Epoch: 5| Step: 1
Training loss: 1.9468719959259033
Validation loss: 2.025029261906942

Epoch: 5| Step: 2
Training loss: 1.7238337993621826
Validation loss: 2.0175518145163855

Epoch: 5| Step: 3
Training loss: 2.168351411819458
Validation loss: 2.013986681898435

Epoch: 5| Step: 4
Training loss: 1.9185079336166382
Validation loss: 2.0122511138518653

Epoch: 5| Step: 5
Training loss: 2.157107353210449
Validation loss: 2.018157343069712

Epoch: 5| Step: 6
Training loss: 2.463484287261963
Validation loss: 2.0242227017879486

Epoch: 5| Step: 7
Training loss: 2.3935320377349854
Validation loss: 2.0293434858322144

Epoch: 5| Step: 8
Training loss: 1.781203031539917
Validation loss: 2.0377276043097177

Epoch: 5| Step: 9
Training loss: 2.276111364364624
Validation loss: 2.0311806549628577

Epoch: 5| Step: 10
Training loss: 2.4716732501983643
Validation loss: 2.0437387277682624

Epoch: 5| Step: 11
Training loss: 0.7460383176803589
Validation loss: 2.040883724888166

Epoch: 143| Step: 0
Training loss: 1.914799451828003
Validation loss: 2.0412552108367286

Epoch: 5| Step: 1
Training loss: 1.6838855743408203
Validation loss: 2.042263299226761

Epoch: 5| Step: 2
Training loss: 2.3100943565368652
Validation loss: 2.0328798989454904

Epoch: 5| Step: 3
Training loss: 2.1907944679260254
Validation loss: 2.053431361913681

Epoch: 5| Step: 4
Training loss: 2.1182756423950195
Validation loss: 2.0389198462168374

Epoch: 5| Step: 5
Training loss: 2.154641628265381
Validation loss: 2.044674495855967

Epoch: 5| Step: 6
Training loss: 1.7044671773910522
Validation loss: 2.047621116042137

Epoch: 5| Step: 7
Training loss: 2.164102554321289
Validation loss: 2.056319077809652

Epoch: 5| Step: 8
Training loss: 2.136425018310547
Validation loss: 2.048280254006386

Epoch: 5| Step: 9
Training loss: 2.5797436237335205
Validation loss: 2.0472581883271537

Epoch: 5| Step: 10
Training loss: 1.6339530944824219
Validation loss: 2.047668327887853

Epoch: 5| Step: 11
Training loss: 2.629777431488037
Validation loss: 2.0254821280638375

Epoch: 144| Step: 0
Training loss: 2.125690460205078
Validation loss: 2.0103714863459268

Epoch: 5| Step: 1
Training loss: 2.3738837242126465
Validation loss: 2.0095437665780387

Epoch: 5| Step: 2
Training loss: 1.786482810974121
Validation loss: 2.024979660908381

Epoch: 5| Step: 3
Training loss: 1.9377250671386719
Validation loss: 2.0378366311391196

Epoch: 5| Step: 4
Training loss: 2.5654900074005127
Validation loss: 2.045974021156629

Epoch: 5| Step: 5
Training loss: 2.0632522106170654
Validation loss: 2.0541157722473145

Epoch: 5| Step: 6
Training loss: 2.830430269241333
Validation loss: 2.0582155734300613

Epoch: 5| Step: 7
Training loss: 1.9941844940185547
Validation loss: 2.074289242426554

Epoch: 5| Step: 8
Training loss: 1.9393819570541382
Validation loss: 2.0609657764434814

Epoch: 5| Step: 9
Training loss: 2.3253014087677
Validation loss: 2.068301464120547

Epoch: 5| Step: 10
Training loss: 2.1343493461608887
Validation loss: 2.070220117767652

Epoch: 5| Step: 11
Training loss: 1.3008453845977783
Validation loss: 2.0689725279808044

Epoch: 145| Step: 0
Training loss: 2.0679259300231934
Validation loss: 2.0673682490984597

Epoch: 5| Step: 1
Training loss: 2.9314961433410645
Validation loss: 2.0661205798387527

Epoch: 5| Step: 2
Training loss: 2.149036407470703
Validation loss: 2.0644461661577225

Epoch: 5| Step: 3
Training loss: 2.338463544845581
Validation loss: 2.061827148000399

Epoch: 5| Step: 4
Training loss: 2.4460320472717285
Validation loss: 2.054867058992386

Epoch: 5| Step: 5
Training loss: 1.9440946578979492
Validation loss: 2.045007507006327

Epoch: 5| Step: 6
Training loss: 1.8471133708953857
Validation loss: 2.045749475558599

Epoch: 5| Step: 7
Training loss: 2.3138463497161865
Validation loss: 2.0269722243150077

Epoch: 5| Step: 8
Training loss: 1.9552867412567139
Validation loss: 2.0262863089640937

Epoch: 5| Step: 9
Training loss: 1.7728283405303955
Validation loss: 2.0219609439373016

Epoch: 5| Step: 10
Training loss: 2.0723907947540283
Validation loss: 2.032205040256182

Epoch: 5| Step: 11
Training loss: 2.2820982933044434
Validation loss: 2.02974534034729

Epoch: 146| Step: 0
Training loss: 2.5633113384246826
Validation loss: 2.043248559037844

Epoch: 5| Step: 1
Training loss: 2.1705241203308105
Validation loss: 2.0351786414782205

Epoch: 5| Step: 2
Training loss: 1.839516282081604
Validation loss: 2.0382479478915534

Epoch: 5| Step: 3
Training loss: 2.220522165298462
Validation loss: 2.0391127914190292

Epoch: 5| Step: 4
Training loss: 2.125150203704834
Validation loss: 2.034865806500117

Epoch: 5| Step: 5
Training loss: 1.5945810079574585
Validation loss: 2.0382989048957825

Epoch: 5| Step: 6
Training loss: 1.87301766872406
Validation loss: 2.0557471215724945

Epoch: 5| Step: 7
Training loss: 1.8962637186050415
Validation loss: 2.0587325940529504

Epoch: 5| Step: 8
Training loss: 1.9679386615753174
Validation loss: 2.0613030145565667

Epoch: 5| Step: 9
Training loss: 1.8043842315673828
Validation loss: 2.0640616367260614

Epoch: 5| Step: 10
Training loss: 2.8230063915252686
Validation loss: 2.0688678175210953

Epoch: 5| Step: 11
Training loss: 1.4331765174865723
Validation loss: 2.070761039853096

Epoch: 147| Step: 0
Training loss: 2.4680583477020264
Validation loss: 2.0725354005893073

Epoch: 5| Step: 1
Training loss: 2.1840806007385254
Validation loss: 2.0692695577939353

Epoch: 5| Step: 2
Training loss: 1.501240611076355
Validation loss: 2.057947983344396

Epoch: 5| Step: 3
Training loss: 1.8362773656845093
Validation loss: 2.061056911945343

Epoch: 5| Step: 4
Training loss: 2.024939775466919
Validation loss: 2.0567249109347663

Epoch: 5| Step: 5
Training loss: 2.379659652709961
Validation loss: 2.0546868642171225

Epoch: 5| Step: 6
Training loss: 2.2826766967773438
Validation loss: 2.0400777558485665

Epoch: 5| Step: 7
Training loss: 1.7856451272964478
Validation loss: 2.040778865416845

Epoch: 5| Step: 8
Training loss: 2.3000285625457764
Validation loss: 2.0472907374302545

Epoch: 5| Step: 9
Training loss: 2.084076404571533
Validation loss: 2.043434739112854

Epoch: 5| Step: 10
Training loss: 1.8640320301055908
Validation loss: 2.028522710005442

Epoch: 5| Step: 11
Training loss: 1.5854235887527466
Validation loss: 2.041961039106051

Epoch: 148| Step: 0
Training loss: 1.7326679229736328
Validation loss: 2.041249101360639

Epoch: 5| Step: 1
Training loss: 2.0090103149414062
Validation loss: 2.0401715288559594

Epoch: 5| Step: 2
Training loss: 1.9026439189910889
Validation loss: 2.039643794298172

Epoch: 5| Step: 3
Training loss: 2.630096435546875
Validation loss: 2.03923791150252

Epoch: 5| Step: 4
Training loss: 2.3927409648895264
Validation loss: 2.032457172870636

Epoch: 5| Step: 5
Training loss: 2.293609142303467
Validation loss: 2.0220788617928824

Epoch: 5| Step: 6
Training loss: 1.947871446609497
Validation loss: 2.033555423219999

Epoch: 5| Step: 7
Training loss: 1.5669262409210205
Validation loss: 2.038597991069158

Epoch: 5| Step: 8
Training loss: 2.1238152980804443
Validation loss: 2.0341504166523614

Epoch: 5| Step: 9
Training loss: 1.738477349281311
Validation loss: 2.0394915839036307

Epoch: 5| Step: 10
Training loss: 2.2762880325317383
Validation loss: 2.048075497150421

Epoch: 5| Step: 11
Training loss: 1.9762983322143555
Validation loss: 2.055205578605334

Epoch: 149| Step: 0
Training loss: 2.1179661750793457
Validation loss: 2.0492977599302926

Epoch: 5| Step: 1
Training loss: 2.393480062484741
Validation loss: 2.0535203168789544

Epoch: 5| Step: 2
Training loss: 2.00667667388916
Validation loss: 2.0662444134553275

Epoch: 5| Step: 3
Training loss: 2.089123249053955
Validation loss: 2.058144877354304

Epoch: 5| Step: 4
Training loss: 1.654909372329712
Validation loss: 2.0571124851703644

Epoch: 5| Step: 5
Training loss: 1.8272672891616821
Validation loss: 2.0484598775704703

Epoch: 5| Step: 6
Training loss: 2.183004379272461
Validation loss: 2.0527913868427277

Epoch: 5| Step: 7
Training loss: 1.5440295934677124
Validation loss: 2.046611582239469

Epoch: 5| Step: 8
Training loss: 2.3548667430877686
Validation loss: 2.0349330256382623

Epoch: 5| Step: 9
Training loss: 1.791751503944397
Validation loss: 2.0322308441003165

Epoch: 5| Step: 10
Training loss: 2.3918821811676025
Validation loss: 2.0459147741397223

Epoch: 5| Step: 11
Training loss: 2.87644624710083
Validation loss: 2.030227323373159

Epoch: 150| Step: 0
Training loss: 2.0076866149902344
Validation loss: 2.037927806377411

Epoch: 5| Step: 1
Training loss: 2.7271008491516113
Validation loss: 2.038511877258619

Epoch: 5| Step: 2
Training loss: 1.7240426540374756
Validation loss: 2.0352852443854013

Epoch: 5| Step: 3
Training loss: 2.0185554027557373
Validation loss: 2.0456874519586563

Epoch: 5| Step: 4
Training loss: 2.303412914276123
Validation loss: 2.0424151619275412

Epoch: 5| Step: 5
Training loss: 2.0120368003845215
Validation loss: 2.026317114631335

Epoch: 5| Step: 6
Training loss: 2.1800312995910645
Validation loss: 2.0162871330976486

Epoch: 5| Step: 7
Training loss: 1.8890037536621094
Validation loss: 2.0262456238269806

Epoch: 5| Step: 8
Training loss: 2.2691397666931152
Validation loss: 2.0264823138713837

Epoch: 5| Step: 9
Training loss: 1.5334925651550293
Validation loss: 2.0218873967727027

Epoch: 5| Step: 10
Training loss: 2.447030544281006
Validation loss: 2.0251326858997345

Epoch: 5| Step: 11
Training loss: 2.1814730167388916
Validation loss: 2.035207122564316

Epoch: 151| Step: 0
Training loss: 2.104552984237671
Validation loss: 2.0403093000253043

Epoch: 5| Step: 1
Training loss: 1.6992683410644531
Validation loss: 2.0259854743878045

Epoch: 5| Step: 2
Training loss: 2.0860395431518555
Validation loss: 2.0342228760321936

Epoch: 5| Step: 3
Training loss: 2.1351044178009033
Validation loss: 2.0323359618584314

Epoch: 5| Step: 4
Training loss: 2.4110043048858643
Validation loss: 2.0276740193367004

Epoch: 5| Step: 5
Training loss: 1.5069630146026611
Validation loss: 2.0280100405216217

Epoch: 5| Step: 6
Training loss: 2.244187831878662
Validation loss: 2.0293853183587394

Epoch: 5| Step: 7
Training loss: 2.0290870666503906
Validation loss: 2.033286233743032

Epoch: 5| Step: 8
Training loss: 2.341620922088623
Validation loss: 2.0410095304250717

Epoch: 5| Step: 9
Training loss: 1.7774502038955688
Validation loss: 2.029055898388227

Epoch: 5| Step: 10
Training loss: 2.271602153778076
Validation loss: 2.0489261746406555

Epoch: 5| Step: 11
Training loss: 2.887251138687134
Validation loss: 2.065029665827751

Epoch: 152| Step: 0
Training loss: 1.9271150827407837
Validation loss: 2.0463997970024743

Epoch: 5| Step: 1
Training loss: 2.478712797164917
Validation loss: 2.061691184838613

Epoch: 5| Step: 2
Training loss: 2.187788963317871
Validation loss: 2.0655225614706674

Epoch: 5| Step: 3
Training loss: 1.5453495979309082
Validation loss: 2.0646465867757797

Epoch: 5| Step: 4
Training loss: 2.399325132369995
Validation loss: 2.0500588168700538

Epoch: 5| Step: 5
Training loss: 1.973333716392517
Validation loss: 2.054882764816284

Epoch: 5| Step: 6
Training loss: 2.366455078125
Validation loss: 2.0520992974440255

Epoch: 5| Step: 7
Training loss: 1.7225110530853271
Validation loss: 2.0470667332410812

Epoch: 5| Step: 8
Training loss: 1.975961685180664
Validation loss: 2.054207354784012

Epoch: 5| Step: 9
Training loss: 1.646744966506958
Validation loss: 2.0525345553954444

Epoch: 5| Step: 10
Training loss: 1.833978295326233
Validation loss: 2.0512169897556305

Epoch: 5| Step: 11
Training loss: 4.035767555236816
Validation loss: 2.06469072898229

Epoch: 153| Step: 0
Training loss: 1.72848641872406
Validation loss: 2.062743286291758

Epoch: 5| Step: 1
Training loss: 1.9848034381866455
Validation loss: 2.065844868620237

Epoch: 5| Step: 2
Training loss: 2.3807373046875
Validation loss: 2.070724238952001

Epoch: 5| Step: 3
Training loss: 2.5569777488708496
Validation loss: 2.0835162103176117

Epoch: 5| Step: 4
Training loss: 2.4995086193084717
Validation loss: 2.082370991508166

Epoch: 5| Step: 5
Training loss: 2.2521793842315674
Validation loss: 2.0851099689801535

Epoch: 5| Step: 6
Training loss: 1.5563400983810425
Validation loss: 2.083167776465416

Epoch: 5| Step: 7
Training loss: 1.8261311054229736
Validation loss: 2.0795695881048837

Epoch: 5| Step: 8
Training loss: 1.6663634777069092
Validation loss: 2.0519712418317795

Epoch: 5| Step: 9
Training loss: 1.464758276939392
Validation loss: 2.0579304695129395

Epoch: 5| Step: 10
Training loss: 2.5567331314086914
Validation loss: 2.0469969511032104

Epoch: 5| Step: 11
Training loss: 2.2933285236358643
Validation loss: 2.03802456955115

Epoch: 154| Step: 0
Training loss: 1.8600256443023682
Validation loss: 2.0438650995492935

Epoch: 5| Step: 1
Training loss: 2.2345714569091797
Validation loss: 2.030058150490125

Epoch: 5| Step: 2
Training loss: 2.1140036582946777
Validation loss: 2.0287514527638755

Epoch: 5| Step: 3
Training loss: 1.9363765716552734
Validation loss: 2.0329179912805557

Epoch: 5| Step: 4
Training loss: 2.1891026496887207
Validation loss: 2.027185926834742

Epoch: 5| Step: 5
Training loss: 1.9182933568954468
Validation loss: 2.0265297243992486

Epoch: 5| Step: 6
Training loss: 2.384490966796875
Validation loss: 2.0270447929700217

Epoch: 5| Step: 7
Training loss: 2.444000244140625
Validation loss: 2.0347349296013513

Epoch: 5| Step: 8
Training loss: 1.932464599609375
Validation loss: 2.03328346212705

Epoch: 5| Step: 9
Training loss: 2.330629348754883
Validation loss: 2.0404052436351776

Epoch: 5| Step: 10
Training loss: 1.6738214492797852
Validation loss: 2.0470636934041977

Epoch: 5| Step: 11
Training loss: 1.4114247560501099
Validation loss: 2.050934389233589

Epoch: 155| Step: 0
Training loss: 1.7733198404312134
Validation loss: 2.0668986439704895

Epoch: 5| Step: 1
Training loss: 2.1928508281707764
Validation loss: 2.0576888024806976

Epoch: 5| Step: 2
Training loss: 2.0822033882141113
Validation loss: 2.0655961682399115

Epoch: 5| Step: 3
Training loss: 1.9618847370147705
Validation loss: 2.0695402373870215

Epoch: 5| Step: 4
Training loss: 1.9209398031234741
Validation loss: 2.0567698925733566

Epoch: 5| Step: 5
Training loss: 2.6354501247406006
Validation loss: 2.06261815627416

Epoch: 5| Step: 6
Training loss: 2.0870282649993896
Validation loss: 2.049522191286087

Epoch: 5| Step: 7
Training loss: 1.2123923301696777
Validation loss: 2.0619830141464868

Epoch: 5| Step: 8
Training loss: 2.8489439487457275
Validation loss: 2.0562382141749063

Epoch: 5| Step: 9
Training loss: 1.9068437814712524
Validation loss: 2.0671667406956353

Epoch: 5| Step: 10
Training loss: 1.8715307712554932
Validation loss: 2.0669198781251907

Epoch: 5| Step: 11
Training loss: 2.010897159576416
Validation loss: 2.0680459390083947

Epoch: 156| Step: 0
Training loss: 2.1718266010284424
Validation loss: 2.066112940510114

Epoch: 5| Step: 1
Training loss: 1.9878613948822021
Validation loss: 2.0830701887607574

Epoch: 5| Step: 2
Training loss: 1.7742278575897217
Validation loss: 2.079294259349505

Epoch: 5| Step: 3
Training loss: 2.111175060272217
Validation loss: 2.0943972816069922

Epoch: 5| Step: 4
Training loss: 2.0583040714263916
Validation loss: 2.0938669393459954

Epoch: 5| Step: 5
Training loss: 1.9927978515625
Validation loss: 2.092810089389483

Epoch: 5| Step: 6
Training loss: 2.0630204677581787
Validation loss: 2.074053928256035

Epoch: 5| Step: 7
Training loss: 1.997732162475586
Validation loss: 2.0608682284752526

Epoch: 5| Step: 8
Training loss: 2.791285514831543
Validation loss: 2.0438769410053887

Epoch: 5| Step: 9
Training loss: 1.9127050638198853
Validation loss: 2.0280978928009668

Epoch: 5| Step: 10
Training loss: 1.8115692138671875
Validation loss: 2.0348453323046365

Epoch: 5| Step: 11
Training loss: 2.263049602508545
Validation loss: 2.0263720055421195

Epoch: 157| Step: 0
Training loss: 2.3403680324554443
Validation loss: 2.0268802692492804

Epoch: 5| Step: 1
Training loss: 1.9896656274795532
Validation loss: 2.0259099354346595

Epoch: 5| Step: 2
Training loss: 2.038829803466797
Validation loss: 2.0222347329060235

Epoch: 5| Step: 3
Training loss: 2.176001787185669
Validation loss: 2.0331085125605264

Epoch: 5| Step: 4
Training loss: 2.3370230197906494
Validation loss: 2.0335001796483994

Epoch: 5| Step: 5
Training loss: 2.3613040447235107
Validation loss: 2.040991256634394

Epoch: 5| Step: 6
Training loss: 1.8687092065811157
Validation loss: 2.0540761798620224

Epoch: 5| Step: 7
Training loss: 1.9511560201644897
Validation loss: 2.0821204682191214

Epoch: 5| Step: 8
Training loss: 1.9365341663360596
Validation loss: 2.0744601041078568

Epoch: 5| Step: 9
Training loss: 2.1751415729522705
Validation loss: 2.066787004470825

Epoch: 5| Step: 10
Training loss: 1.751420021057129
Validation loss: 2.065282419323921

Epoch: 5| Step: 11
Training loss: 1.731679916381836
Validation loss: 2.0704548557599387

Epoch: 158| Step: 0
Training loss: 2.2261908054351807
Validation loss: 2.070622911055883

Epoch: 5| Step: 1
Training loss: 2.0495972633361816
Validation loss: 2.0816726436217627

Epoch: 5| Step: 2
Training loss: 2.48716402053833
Validation loss: 2.083169400691986

Epoch: 5| Step: 3
Training loss: 1.5801836252212524
Validation loss: 2.0819433530171714

Epoch: 5| Step: 4
Training loss: 2.216508150100708
Validation loss: 2.076636552810669

Epoch: 5| Step: 5
Training loss: 2.146146297454834
Validation loss: 2.058754493792852

Epoch: 5| Step: 6
Training loss: 2.0203070640563965
Validation loss: 2.0667604506015778

Epoch: 5| Step: 7
Training loss: 2.2375123500823975
Validation loss: 2.067183112104734

Epoch: 5| Step: 8
Training loss: 1.7042121887207031
Validation loss: 2.043044944604238

Epoch: 5| Step: 9
Training loss: 1.9841629266738892
Validation loss: 2.038013885418574

Epoch: 5| Step: 10
Training loss: 1.8680740594863892
Validation loss: 2.0459558069705963

Epoch: 5| Step: 11
Training loss: 2.1034297943115234
Validation loss: 2.0422488997379937

Epoch: 159| Step: 0
Training loss: 1.9108409881591797
Validation loss: 2.047142361601194

Epoch: 5| Step: 1
Training loss: 1.5908746719360352
Validation loss: 2.0514188508192697

Epoch: 5| Step: 2
Training loss: 2.4302775859832764
Validation loss: 2.0740028023719788

Epoch: 5| Step: 3
Training loss: 2.081247568130493
Validation loss: 2.076655089855194

Epoch: 5| Step: 4
Training loss: 1.4728076457977295
Validation loss: 2.068265969554583

Epoch: 5| Step: 5
Training loss: 2.2474021911621094
Validation loss: 2.073215588927269

Epoch: 5| Step: 6
Training loss: 1.6759674549102783
Validation loss: 2.067803288499514

Epoch: 5| Step: 7
Training loss: 2.3063430786132812
Validation loss: 2.072383403778076

Epoch: 5| Step: 8
Training loss: 2.4629085063934326
Validation loss: 2.0543675273656845

Epoch: 5| Step: 9
Training loss: 2.3037219047546387
Validation loss: 2.0476113806168237

Epoch: 5| Step: 10
Training loss: 1.9281508922576904
Validation loss: 2.0446008443832397

Epoch: 5| Step: 11
Training loss: 1.3989204168319702
Validation loss: 2.033732458949089

Epoch: 160| Step: 0
Training loss: 1.6737949848175049
Validation loss: 2.034818703929583

Epoch: 5| Step: 1
Training loss: 1.8858989477157593
Validation loss: 2.0452562967936196

Epoch: 5| Step: 2
Training loss: 2.292475938796997
Validation loss: 2.051568721731504

Epoch: 5| Step: 3
Training loss: 1.8859739303588867
Validation loss: 2.0478370090325675

Epoch: 5| Step: 4
Training loss: 2.5275824069976807
Validation loss: 2.0546812266111374

Epoch: 5| Step: 5
Training loss: 1.8329092264175415
Validation loss: 2.0475521236658096

Epoch: 5| Step: 6
Training loss: 1.735744833946228
Validation loss: 2.063714176416397

Epoch: 5| Step: 7
Training loss: 1.654330849647522
Validation loss: 2.0559406081835427

Epoch: 5| Step: 8
Training loss: 2.3472213745117188
Validation loss: 2.0590299665927887

Epoch: 5| Step: 9
Training loss: 1.8510500192642212
Validation loss: 2.0631674329439798

Epoch: 5| Step: 10
Training loss: 2.5851221084594727
Validation loss: 2.053289756178856

Epoch: 5| Step: 11
Training loss: 1.6398147344589233
Validation loss: 2.060893883307775

Epoch: 161| Step: 0
Training loss: 2.0861172676086426
Validation loss: 2.0561109483242035

Epoch: 5| Step: 1
Training loss: 2.182457685470581
Validation loss: 2.047533944249153

Epoch: 5| Step: 2
Training loss: 2.252354145050049
Validation loss: 2.044575889905294

Epoch: 5| Step: 3
Training loss: 1.9842296838760376
Validation loss: 2.041550040245056

Epoch: 5| Step: 4
Training loss: 1.6719424724578857
Validation loss: 2.0357453574736915

Epoch: 5| Step: 5
Training loss: 1.8062702417373657
Validation loss: 2.0451287825902305

Epoch: 5| Step: 6
Training loss: 1.8348724842071533
Validation loss: 2.035520931084951

Epoch: 5| Step: 7
Training loss: 2.444047451019287
Validation loss: 2.0453868955373764

Epoch: 5| Step: 8
Training loss: 1.9080381393432617
Validation loss: 2.050104930996895

Epoch: 5| Step: 9
Training loss: 2.1591427326202393
Validation loss: 2.0445436586936316

Epoch: 5| Step: 10
Training loss: 2.1447012424468994
Validation loss: 2.054997464021047

Epoch: 5| Step: 11
Training loss: 1.9387906789779663
Validation loss: 2.066479131579399

Epoch: 162| Step: 0
Training loss: 1.8425849676132202
Validation loss: 2.0789821445941925

Epoch: 5| Step: 1
Training loss: 1.376741647720337
Validation loss: 2.0880278050899506

Epoch: 5| Step: 2
Training loss: 1.861475944519043
Validation loss: 2.0747880190610886

Epoch: 5| Step: 3
Training loss: 2.284029483795166
Validation loss: 2.0784129897753396

Epoch: 5| Step: 4
Training loss: 1.9737638235092163
Validation loss: 2.082191144426664

Epoch: 5| Step: 5
Training loss: 2.1134800910949707
Validation loss: 2.0731348395347595

Epoch: 5| Step: 6
Training loss: 1.753147840499878
Validation loss: 2.0615824659665427

Epoch: 5| Step: 7
Training loss: 2.375530481338501
Validation loss: 2.042469705144564

Epoch: 5| Step: 8
Training loss: 2.173056125640869
Validation loss: 2.0483008374770484

Epoch: 5| Step: 9
Training loss: 2.627122640609741
Validation loss: 2.0484933654467263

Epoch: 5| Step: 10
Training loss: 1.936610460281372
Validation loss: 2.044262930750847

Epoch: 5| Step: 11
Training loss: 2.3583436012268066
Validation loss: 2.034266178806623

Epoch: 163| Step: 0
Training loss: 2.1068007946014404
Validation loss: 2.046283170580864

Epoch: 5| Step: 1
Training loss: 1.8303585052490234
Validation loss: 2.035139799118042

Epoch: 5| Step: 2
Training loss: 1.699562430381775
Validation loss: 2.035510669151942

Epoch: 5| Step: 3
Training loss: 1.9106254577636719
Validation loss: 2.04500542084376

Epoch: 5| Step: 4
Training loss: 1.8898811340332031
Validation loss: 2.040940726796786

Epoch: 5| Step: 5
Training loss: 2.1844425201416016
Validation loss: 2.0545804500579834

Epoch: 5| Step: 6
Training loss: 1.9998657703399658
Validation loss: 2.0722912549972534

Epoch: 5| Step: 7
Training loss: 2.159405469894409
Validation loss: 2.060183251897494

Epoch: 5| Step: 8
Training loss: 2.4362595081329346
Validation loss: 2.063486417134603

Epoch: 5| Step: 9
Training loss: 2.298328399658203
Validation loss: 2.0582078645626702

Epoch: 5| Step: 10
Training loss: 1.7504476308822632
Validation loss: 2.0512368977069855

Epoch: 5| Step: 11
Training loss: 2.0658020973205566
Validation loss: 2.074886073668798

Epoch: 164| Step: 0
Training loss: 1.9721908569335938
Validation loss: 2.066129649678866

Epoch: 5| Step: 1
Training loss: 1.8870702981948853
Validation loss: 2.065226584672928

Epoch: 5| Step: 2
Training loss: 1.843886137008667
Validation loss: 2.063374564051628

Epoch: 5| Step: 3
Training loss: 2.451852321624756
Validation loss: 2.070368523399035

Epoch: 5| Step: 4
Training loss: 1.9041630029678345
Validation loss: 2.0680379370848336

Epoch: 5| Step: 5
Training loss: 2.031154155731201
Validation loss: 2.071569795409838

Epoch: 5| Step: 6
Training loss: 2.3013815879821777
Validation loss: 2.0732414722442627

Epoch: 5| Step: 7
Training loss: 2.110625743865967
Validation loss: 2.094759131471316

Epoch: 5| Step: 8
Training loss: 1.6261974573135376
Validation loss: 2.0953640043735504

Epoch: 5| Step: 9
Training loss: 2.2926535606384277
Validation loss: 2.080628126859665

Epoch: 5| Step: 10
Training loss: 1.8342304229736328
Validation loss: 2.079856221874555

Epoch: 5| Step: 11
Training loss: 1.341525673866272
Validation loss: 2.0716330309708915

Epoch: 165| Step: 0
Training loss: 1.9307886362075806
Validation loss: 2.0627288818359375

Epoch: 5| Step: 1
Training loss: 2.3908655643463135
Validation loss: 2.0482559551795325

Epoch: 5| Step: 2
Training loss: 1.8304383754730225
Validation loss: 2.0541669925053916

Epoch: 5| Step: 3
Training loss: 2.626465320587158
Validation loss: 2.0383370916048684

Epoch: 5| Step: 4
Training loss: 2.1654465198516846
Validation loss: 2.0494622786839805

Epoch: 5| Step: 5
Training loss: 1.64212965965271
Validation loss: 2.0523437559604645

Epoch: 5| Step: 6
Training loss: 1.5695244073867798
Validation loss: 2.049642657240232

Epoch: 5| Step: 7
Training loss: 2.529367446899414
Validation loss: 2.0689072410265603

Epoch: 5| Step: 8
Training loss: 2.0316529273986816
Validation loss: 2.074659446875254

Epoch: 5| Step: 9
Training loss: 2.031137466430664
Validation loss: 2.077800159653028

Epoch: 5| Step: 10
Training loss: 1.8288551568984985
Validation loss: 2.0766413112481437

Epoch: 5| Step: 11
Training loss: 1.9593976736068726
Validation loss: 2.1085824966430664

Epoch: 166| Step: 0
Training loss: 2.206169843673706
Validation loss: 2.086915006240209

Epoch: 5| Step: 1
Training loss: 2.0014071464538574
Validation loss: 2.0628217856089273

Epoch: 5| Step: 2
Training loss: 1.5810844898223877
Validation loss: 2.0552455385526023

Epoch: 5| Step: 3
Training loss: 1.6527156829833984
Validation loss: 2.0570548276106515

Epoch: 5| Step: 4
Training loss: 2.1644887924194336
Validation loss: 2.0523236890633902

Epoch: 5| Step: 5
Training loss: 2.0170035362243652
Validation loss: 2.051889752348264

Epoch: 5| Step: 6
Training loss: 2.6977083683013916
Validation loss: 2.0632944852113724

Epoch: 5| Step: 7
Training loss: 1.798340082168579
Validation loss: 2.0568560560544333

Epoch: 5| Step: 8
Training loss: 2.3892173767089844
Validation loss: 2.0699412127335868

Epoch: 5| Step: 9
Training loss: 2.2390406131744385
Validation loss: 2.0830308894316354

Epoch: 5| Step: 10
Training loss: 1.6859852075576782
Validation loss: 2.079813708861669

Epoch: 5| Step: 11
Training loss: 1.1394634246826172
Validation loss: 2.084819624821345

Epoch: 167| Step: 0
Training loss: 2.5838818550109863
Validation loss: 2.0885703514019647

Epoch: 5| Step: 1
Training loss: 1.6641355752944946
Validation loss: 2.092352112134298

Epoch: 5| Step: 2
Training loss: 2.2381865978240967
Validation loss: 2.0976370871067047

Epoch: 5| Step: 3
Training loss: 2.1143171787261963
Validation loss: 2.0913396924734116

Epoch: 5| Step: 4
Training loss: 2.364912748336792
Validation loss: 2.0890795091787973

Epoch: 5| Step: 5
Training loss: 1.6043546199798584
Validation loss: 2.0867658903201423

Epoch: 5| Step: 6
Training loss: 1.503871202468872
Validation loss: 2.0733824372291565

Epoch: 5| Step: 7
Training loss: 2.105654239654541
Validation loss: 2.0644660194714866

Epoch: 5| Step: 8
Training loss: 2.1768476963043213
Validation loss: 2.0561601469914117

Epoch: 5| Step: 9
Training loss: 2.359607219696045
Validation loss: 2.0650235414505005

Epoch: 5| Step: 10
Training loss: 1.8723052740097046
Validation loss: 2.054122452934583

Epoch: 5| Step: 11
Training loss: 1.0877326726913452
Validation loss: 2.0526989797751107

Epoch: 168| Step: 0
Training loss: 1.946302056312561
Validation loss: 2.0397911419471106

Epoch: 5| Step: 1
Training loss: 2.616828441619873
Validation loss: 2.056075190504392

Epoch: 5| Step: 2
Training loss: 2.224118709564209
Validation loss: 2.0525647749503455

Epoch: 5| Step: 3
Training loss: 1.8588340282440186
Validation loss: 2.053929641842842

Epoch: 5| Step: 4
Training loss: 1.6732162237167358
Validation loss: 2.084145193298658

Epoch: 5| Step: 5
Training loss: 1.6630128622055054
Validation loss: 2.082160731156667

Epoch: 5| Step: 6
Training loss: 1.6389309167861938
Validation loss: 2.08332921564579

Epoch: 5| Step: 7
Training loss: 1.8405253887176514
Validation loss: 2.0738492657740912

Epoch: 5| Step: 8
Training loss: 2.5403809547424316
Validation loss: 2.063494324684143

Epoch: 5| Step: 9
Training loss: 2.024055004119873
Validation loss: 2.064858545859655

Epoch: 5| Step: 10
Training loss: 2.1410746574401855
Validation loss: 2.060679629445076

Epoch: 5| Step: 11
Training loss: 2.5451419353485107
Validation loss: 2.0528345306714377

Epoch: 169| Step: 0
Training loss: 1.9391437768936157
Validation loss: 2.0569241493940353

Epoch: 5| Step: 1
Training loss: 2.0243923664093018
Validation loss: 2.0490101724863052

Epoch: 5| Step: 2
Training loss: 2.385004997253418
Validation loss: 2.0521658758322396

Epoch: 5| Step: 3
Training loss: 2.351207733154297
Validation loss: 2.04103747010231

Epoch: 5| Step: 4
Training loss: 2.0054636001586914
Validation loss: 2.0474456449349723

Epoch: 5| Step: 5
Training loss: 1.7065349817276
Validation loss: 2.054007336497307

Epoch: 5| Step: 6
Training loss: 2.1176345348358154
Validation loss: 2.065565451979637

Epoch: 5| Step: 7
Training loss: 2.082113027572632
Validation loss: 2.062582030892372

Epoch: 5| Step: 8
Training loss: 2.1756911277770996
Validation loss: 2.0708099653323493

Epoch: 5| Step: 9
Training loss: 1.4724942445755005
Validation loss: 2.0790381332238517

Epoch: 5| Step: 10
Training loss: 1.9106391668319702
Validation loss: 2.09397824605306

Epoch: 5| Step: 11
Training loss: 2.4822499752044678
Validation loss: 2.1151004234949746

Epoch: 170| Step: 0
Training loss: 2.0447418689727783
Validation loss: 2.1423858255147934

Epoch: 5| Step: 1
Training loss: 1.7592958211898804
Validation loss: 2.1258262594540915

Epoch: 5| Step: 2
Training loss: 2.2365293502807617
Validation loss: 2.124479035536448

Epoch: 5| Step: 3
Training loss: 2.409365177154541
Validation loss: 2.1238666673501334

Epoch: 5| Step: 4
Training loss: 1.9412829875946045
Validation loss: 2.105378886063894

Epoch: 5| Step: 5
Training loss: 2.539686679840088
Validation loss: 2.106803461909294

Epoch: 5| Step: 6
Training loss: 1.5224915742874146
Validation loss: 2.0786148061354957

Epoch: 5| Step: 7
Training loss: 1.9648698568344116
Validation loss: 2.057386721173922

Epoch: 5| Step: 8
Training loss: 2.4730114936828613
Validation loss: 2.0430290599664054

Epoch: 5| Step: 9
Training loss: 2.0310115814208984
Validation loss: 2.051350658138593

Epoch: 5| Step: 10
Training loss: 2.0785396099090576
Validation loss: 2.053769990801811

Epoch: 5| Step: 11
Training loss: 2.535111904144287
Validation loss: 2.0487305323282876

Epoch: 171| Step: 0
Training loss: 2.2060670852661133
Validation loss: 2.056457132101059

Epoch: 5| Step: 1
Training loss: 2.1230952739715576
Validation loss: 2.0554355333248773

Epoch: 5| Step: 2
Training loss: 2.80000376701355
Validation loss: 2.06018919746081

Epoch: 5| Step: 3
Training loss: 1.7743699550628662
Validation loss: 2.065060039361318

Epoch: 5| Step: 4
Training loss: 2.1682839393615723
Validation loss: 2.064141462246577

Epoch: 5| Step: 5
Training loss: 2.0478856563568115
Validation loss: 2.0872465074062347

Epoch: 5| Step: 6
Training loss: 1.7829105854034424
Validation loss: 2.090047766764959

Epoch: 5| Step: 7
Training loss: 1.746929407119751
Validation loss: 2.098173752427101

Epoch: 5| Step: 8
Training loss: 1.6401195526123047
Validation loss: 2.113029196858406

Epoch: 5| Step: 9
Training loss: 1.916614294052124
Validation loss: 2.1223408579826355

Epoch: 5| Step: 10
Training loss: 1.913941740989685
Validation loss: 2.0938364366690316

Epoch: 5| Step: 11
Training loss: 2.200697183609009
Validation loss: 2.104282885789871

Epoch: 172| Step: 0
Training loss: 2.283573627471924
Validation loss: 2.101319213708242

Epoch: 5| Step: 1
Training loss: 2.1087303161621094
Validation loss: 2.0926524102687836

Epoch: 5| Step: 2
Training loss: 2.248365879058838
Validation loss: 2.090114936232567

Epoch: 5| Step: 3
Training loss: 1.881986379623413
Validation loss: 2.0893281400203705

Epoch: 5| Step: 4
Training loss: 1.9743868112564087
Validation loss: 2.0715571343898773

Epoch: 5| Step: 5
Training loss: 1.9956448078155518
Validation loss: 2.068053831656774

Epoch: 5| Step: 6
Training loss: 2.365361213684082
Validation loss: 2.08216621975104

Epoch: 5| Step: 7
Training loss: 1.7843830585479736
Validation loss: 2.0776791721582413

Epoch: 5| Step: 8
Training loss: 2.075176954269409
Validation loss: 2.083971713980039

Epoch: 5| Step: 9
Training loss: 1.9012205600738525
Validation loss: 2.083740090330442

Epoch: 5| Step: 10
Training loss: 1.5745484828948975
Validation loss: 2.064817731579145

Epoch: 5| Step: 11
Training loss: 1.3209075927734375
Validation loss: 2.0592797001202903

Epoch: 173| Step: 0
Training loss: 2.275763750076294
Validation loss: 2.0676721980174384

Epoch: 5| Step: 1
Training loss: 2.41575026512146
Validation loss: 2.0722136944532394

Epoch: 5| Step: 2
Training loss: 1.7360725402832031
Validation loss: 2.071963702638944

Epoch: 5| Step: 3
Training loss: 2.1515393257141113
Validation loss: 2.0817407816648483

Epoch: 5| Step: 4
Training loss: 1.4350711107254028
Validation loss: 2.0885274012883506

Epoch: 5| Step: 5
Training loss: 2.3794522285461426
Validation loss: 2.1128194828828177

Epoch: 5| Step: 6
Training loss: 1.866188406944275
Validation loss: 2.113747462630272

Epoch: 5| Step: 7
Training loss: 1.6803390979766846
Validation loss: 2.130694275101026

Epoch: 5| Step: 8
Training loss: 1.5817081928253174
Validation loss: 2.1059038738409677

Epoch: 5| Step: 9
Training loss: 2.639059066772461
Validation loss: 2.1298634310563407

Epoch: 5| Step: 10
Training loss: 1.8772472143173218
Validation loss: 2.1299468874931335

Epoch: 5| Step: 11
Training loss: 2.554340124130249
Validation loss: 2.105750302473704

Epoch: 174| Step: 0
Training loss: 2.0592494010925293
Validation loss: 2.0763680835564933

Epoch: 5| Step: 1
Training loss: 2.1016921997070312
Validation loss: 2.068789154291153

Epoch: 5| Step: 2
Training loss: 2.271482229232788
Validation loss: 2.06672111650308

Epoch: 5| Step: 3
Training loss: 2.047759771347046
Validation loss: 2.0511128902435303

Epoch: 5| Step: 4
Training loss: 2.032118797302246
Validation loss: 2.0585524340470633

Epoch: 5| Step: 5
Training loss: 2.294133424758911
Validation loss: 2.058029274145762

Epoch: 5| Step: 6
Training loss: 1.894586205482483
Validation loss: 2.063046023249626

Epoch: 5| Step: 7
Training loss: 1.9814636707305908
Validation loss: 2.056750237941742

Epoch: 5| Step: 8
Training loss: 1.833404541015625
Validation loss: 2.063927412033081

Epoch: 5| Step: 9
Training loss: 1.933550238609314
Validation loss: 2.0647179881731668

Epoch: 5| Step: 10
Training loss: 2.033921003341675
Validation loss: 2.079641064008077

Epoch: 5| Step: 11
Training loss: 1.466839075088501
Validation loss: 2.092909559607506

Epoch: 175| Step: 0
Training loss: 2.4609057903289795
Validation loss: 2.0789254556099572

Epoch: 5| Step: 1
Training loss: 2.01753306388855
Validation loss: 2.093932876984278

Epoch: 5| Step: 2
Training loss: 2.014444351196289
Validation loss: 2.106602887312571

Epoch: 5| Step: 3
Training loss: 1.746307373046875
Validation loss: 2.0958238343397775

Epoch: 5| Step: 4
Training loss: 2.1269214153289795
Validation loss: 2.0910732547442117

Epoch: 5| Step: 5
Training loss: 2.415822982788086
Validation loss: 2.103902613123258

Epoch: 5| Step: 6
Training loss: 2.1669020652770996
Validation loss: 2.106595888733864

Epoch: 5| Step: 7
Training loss: 2.185333728790283
Validation loss: 2.108512128392855

Epoch: 5| Step: 8
Training loss: 1.3150619268417358
Validation loss: 2.0900560170412064

Epoch: 5| Step: 9
Training loss: 1.703635811805725
Validation loss: 2.0757236232360206

Epoch: 5| Step: 10
Training loss: 1.868281364440918
Validation loss: 2.0687689582506814

Epoch: 5| Step: 11
Training loss: 2.4448275566101074
Validation loss: 2.0646281143029532

Testing loss: 1.6924070299958154
