Epoch: 1| Step: 0
Training loss: 4.808218955993652
Validation loss: 5.344745099544525

Epoch: 5| Step: 1
Training loss: 6.636404991149902
Validation loss: 5.342658718427022

Epoch: 5| Step: 2
Training loss: 5.2844557762146
Validation loss: 5.340722461541493

Epoch: 5| Step: 3
Training loss: 6.0573649406433105
Validation loss: 5.338698208332062

Epoch: 5| Step: 4
Training loss: 4.185107231140137
Validation loss: 5.336681008338928

Epoch: 5| Step: 5
Training loss: 6.0331315994262695
Validation loss: 5.334734857082367

Epoch: 5| Step: 6
Training loss: 5.406516075134277
Validation loss: 5.33278892437617

Epoch: 5| Step: 7
Training loss: 5.535345554351807
Validation loss: 5.330934941768646

Epoch: 5| Step: 8
Training loss: 4.20296573638916
Validation loss: 5.3290396730105085

Epoch: 5| Step: 9
Training loss: 6.1568450927734375
Validation loss: 5.327077825864156

Epoch: 5| Step: 10
Training loss: 5.318116188049316
Validation loss: 5.325164844592412

Epoch: 5| Step: 11
Training loss: 4.487392902374268
Validation loss: 5.323173741499583

Epoch: 2| Step: 0
Training loss: 5.011017799377441
Validation loss: 5.321088592211406

Epoch: 5| Step: 1
Training loss: 4.2533369064331055
Validation loss: 5.319097618261973

Epoch: 5| Step: 2
Training loss: 5.733419418334961
Validation loss: 5.3168096741040545

Epoch: 5| Step: 3
Training loss: 5.804296970367432
Validation loss: 5.314666271209717

Epoch: 5| Step: 4
Training loss: 5.200894355773926
Validation loss: 5.312354425589244

Epoch: 5| Step: 5
Training loss: 5.0655999183654785
Validation loss: 5.3099298278490705

Epoch: 5| Step: 6
Training loss: 6.211503028869629
Validation loss: 5.307550549507141

Epoch: 5| Step: 7
Training loss: 5.193610191345215
Validation loss: 5.304825882116954

Epoch: 5| Step: 8
Training loss: 5.314683437347412
Validation loss: 5.3020264108975725

Epoch: 5| Step: 9
Training loss: 5.4298415184021
Validation loss: 5.299200614293416

Epoch: 5| Step: 10
Training loss: 5.606224060058594
Validation loss: 5.296239733695984

Epoch: 5| Step: 11
Training loss: 7.049894332885742
Validation loss: 5.293086131413777

Epoch: 3| Step: 0
Training loss: 5.448216915130615
Validation loss: 5.289835433165233

Epoch: 5| Step: 1
Training loss: 5.504465103149414
Validation loss: 5.286366105079651

Epoch: 5| Step: 2
Training loss: 5.318130016326904
Validation loss: 5.2827368179957075

Epoch: 5| Step: 3
Training loss: 5.148494243621826
Validation loss: 5.27875828742981

Epoch: 5| Step: 4
Training loss: 5.070137023925781
Validation loss: 5.27474311987559

Epoch: 5| Step: 5
Training loss: 6.058547019958496
Validation loss: 5.27083835999171

Epoch: 5| Step: 6
Training loss: 4.422036647796631
Validation loss: 5.266416271527608

Epoch: 5| Step: 7
Training loss: 4.426901817321777
Validation loss: 5.2617407242457075

Epoch: 5| Step: 8
Training loss: 5.5272369384765625
Validation loss: 5.257054885228475

Epoch: 5| Step: 9
Training loss: 6.749868869781494
Validation loss: 5.251873095830281

Epoch: 5| Step: 10
Training loss: 5.406866550445557
Validation loss: 5.246655305226644

Epoch: 5| Step: 11
Training loss: 3.5878381729125977
Validation loss: 5.2410094539324446

Epoch: 4| Step: 0
Training loss: 4.418407440185547
Validation loss: 5.235228916009267

Epoch: 5| Step: 1
Training loss: 5.507129669189453
Validation loss: 5.229028383890788

Epoch: 5| Step: 2
Training loss: 5.469459533691406
Validation loss: 5.222669859727223

Epoch: 5| Step: 3
Training loss: 5.786070346832275
Validation loss: 5.216417928536733

Epoch: 5| Step: 4
Training loss: 4.350998878479004
Validation loss: 5.209355076154073

Epoch: 5| Step: 5
Training loss: 5.369683265686035
Validation loss: 5.202153285344441

Epoch: 5| Step: 6
Training loss: 5.445769309997559
Validation loss: 5.194785753885905

Epoch: 5| Step: 7
Training loss: 5.247001647949219
Validation loss: 5.1873839894930525

Epoch: 5| Step: 8
Training loss: 5.466468334197998
Validation loss: 5.179374595483144

Epoch: 5| Step: 9
Training loss: 4.986256122589111
Validation loss: 5.171314338843028

Epoch: 5| Step: 10
Training loss: 6.098453521728516
Validation loss: 5.162935137748718

Epoch: 5| Step: 11
Training loss: 4.499167442321777
Validation loss: 5.154511710007985

Epoch: 5| Step: 0
Training loss: 5.139462947845459
Validation loss: 5.145799060662587

Epoch: 5| Step: 1
Training loss: 5.25725793838501
Validation loss: 5.136891643206279

Epoch: 5| Step: 2
Training loss: 5.739283561706543
Validation loss: 5.127735694249471

Epoch: 5| Step: 3
Training loss: 4.696218490600586
Validation loss: 5.118323822816213

Epoch: 5| Step: 4
Training loss: 5.134387969970703
Validation loss: 5.10873927672704

Epoch: 5| Step: 5
Training loss: 4.142277240753174
Validation loss: 5.0993662277857466

Epoch: 5| Step: 6
Training loss: 4.7991943359375
Validation loss: 5.089984059333801

Epoch: 5| Step: 7
Training loss: 5.1940484046936035
Validation loss: 5.08028906583786

Epoch: 5| Step: 8
Training loss: 5.2523393630981445
Validation loss: 5.070558468500773

Epoch: 5| Step: 9
Training loss: 5.493760585784912
Validation loss: 5.060734649499257

Epoch: 5| Step: 10
Training loss: 5.895596027374268
Validation loss: 5.050756831963857

Epoch: 5| Step: 11
Training loss: 6.018155097961426
Validation loss: 5.040826658407847

Epoch: 6| Step: 0
Training loss: 5.2194294929504395
Validation loss: 5.030666371186574

Epoch: 5| Step: 1
Training loss: 4.484286308288574
Validation loss: 5.020630399386088

Epoch: 5| Step: 2
Training loss: 4.338974952697754
Validation loss: 5.0099848707516985

Epoch: 5| Step: 3
Training loss: 5.037005424499512
Validation loss: 4.999561071395874

Epoch: 5| Step: 4
Training loss: 6.073677062988281
Validation loss: 4.9891817172368365

Epoch: 5| Step: 5
Training loss: 5.324632167816162
Validation loss: 4.978464921315511

Epoch: 5| Step: 6
Training loss: 5.354475975036621
Validation loss: 4.967594405015309

Epoch: 5| Step: 7
Training loss: 4.822237014770508
Validation loss: 4.957171658674876

Epoch: 5| Step: 8
Training loss: 4.903063774108887
Validation loss: 4.947120229403178

Epoch: 5| Step: 9
Training loss: 5.059247016906738
Validation loss: 4.936499973138173

Epoch: 5| Step: 10
Training loss: 5.060099124908447
Validation loss: 4.92679629723231

Epoch: 5| Step: 11
Training loss: 5.02473258972168
Validation loss: 4.916939457257588

Epoch: 7| Step: 0
Training loss: 5.438201904296875
Validation loss: 4.907466073830922

Epoch: 5| Step: 1
Training loss: 4.841014385223389
Validation loss: 4.897877832253774

Epoch: 5| Step: 2
Training loss: 5.087658882141113
Validation loss: 4.8884836832682295

Epoch: 5| Step: 3
Training loss: 4.918885231018066
Validation loss: 4.879163106282552

Epoch: 5| Step: 4
Training loss: 5.317587852478027
Validation loss: 4.870070358117421

Epoch: 5| Step: 5
Training loss: 5.017926216125488
Validation loss: 4.861431062221527

Epoch: 5| Step: 6
Training loss: 5.1910929679870605
Validation loss: 4.852252304553986

Epoch: 5| Step: 7
Training loss: 3.2362403869628906
Validation loss: 4.843434154987335

Epoch: 5| Step: 8
Training loss: 5.094834327697754
Validation loss: 4.834946354230245

Epoch: 5| Step: 9
Training loss: 5.064748764038086
Validation loss: 4.826589028040568

Epoch: 5| Step: 10
Training loss: 5.354892730712891
Validation loss: 4.818446854750316

Epoch: 5| Step: 11
Training loss: 4.230147838592529
Validation loss: 4.810386737187703

Epoch: 8| Step: 0
Training loss: 4.344222068786621
Validation loss: 4.802150209744771

Epoch: 5| Step: 1
Training loss: 4.701279640197754
Validation loss: 4.794073402881622

Epoch: 5| Step: 2
Training loss: 5.090949058532715
Validation loss: 4.786340057849884

Epoch: 5| Step: 3
Training loss: 5.0022478103637695
Validation loss: 4.778007825215657

Epoch: 5| Step: 4
Training loss: 4.422276496887207
Validation loss: 4.770252267519633

Epoch: 5| Step: 5
Training loss: 5.54973840713501
Validation loss: 4.762576123078664

Epoch: 5| Step: 6
Training loss: 5.0168938636779785
Validation loss: 4.754629969596863

Epoch: 5| Step: 7
Training loss: 5.495480060577393
Validation loss: 4.747144589821498

Epoch: 5| Step: 8
Training loss: 5.125234127044678
Validation loss: 4.7394200166066485

Epoch: 5| Step: 9
Training loss: 5.307788848876953
Validation loss: 4.731546958287557

Epoch: 5| Step: 10
Training loss: 3.842862367630005
Validation loss: 4.723616361618042

Epoch: 5| Step: 11
Training loss: 2.293842077255249
Validation loss: 4.715925435225169

Epoch: 9| Step: 0
Training loss: 4.163938999176025
Validation loss: 4.708021720250447

Epoch: 5| Step: 1
Training loss: 4.431604862213135
Validation loss: 4.700751562913259

Epoch: 5| Step: 2
Training loss: 4.586617946624756
Validation loss: 4.6932434141635895

Epoch: 5| Step: 3
Training loss: 4.308608055114746
Validation loss: 4.68572731812795

Epoch: 5| Step: 4
Training loss: 4.38942813873291
Validation loss: 4.678040723005931

Epoch: 5| Step: 5
Training loss: 5.523152828216553
Validation loss: 4.6701989869276685

Epoch: 5| Step: 6
Training loss: 5.221704959869385
Validation loss: 4.662506500879924

Epoch: 5| Step: 7
Training loss: 4.531617164611816
Validation loss: 4.65462185939153

Epoch: 5| Step: 8
Training loss: 5.286386966705322
Validation loss: 4.646728177865346

Epoch: 5| Step: 9
Training loss: 4.665825843811035
Validation loss: 4.6388964255650835

Epoch: 5| Step: 10
Training loss: 5.050273895263672
Validation loss: 4.631352444489797

Epoch: 5| Step: 11
Training loss: 6.01213264465332
Validation loss: 4.622943003972371

Epoch: 10| Step: 0
Training loss: 4.986732006072998
Validation loss: 4.615083734194438

Epoch: 5| Step: 1
Training loss: 4.434439659118652
Validation loss: 4.607291986544927

Epoch: 5| Step: 2
Training loss: 4.937087059020996
Validation loss: 4.5990594029426575

Epoch: 5| Step: 3
Training loss: 5.270586967468262
Validation loss: 4.590962469577789

Epoch: 5| Step: 4
Training loss: 5.716717720031738
Validation loss: 4.582952857017517

Epoch: 5| Step: 5
Training loss: 4.927407741546631
Validation loss: 4.574564496676127

Epoch: 5| Step: 6
Training loss: 4.908277988433838
Validation loss: 4.565986414750417

Epoch: 5| Step: 7
Training loss: 3.8504586219787598
Validation loss: 4.558115830024083

Epoch: 5| Step: 8
Training loss: 4.076855182647705
Validation loss: 4.55029300848643

Epoch: 5| Step: 9
Training loss: 4.1502790451049805
Validation loss: 4.542409698168437

Epoch: 5| Step: 10
Training loss: 4.477643966674805
Validation loss: 4.534605483214061

Epoch: 5| Step: 11
Training loss: 3.194286823272705
Validation loss: 4.526925305525462

Epoch: 11| Step: 0
Training loss: 3.946366786956787
Validation loss: 4.519861181577046

Epoch: 5| Step: 1
Training loss: 4.90244722366333
Validation loss: 4.512414912382762

Epoch: 5| Step: 2
Training loss: 4.385066032409668
Validation loss: 4.505273212989171

Epoch: 5| Step: 3
Training loss: 4.049819469451904
Validation loss: 4.498263498147328

Epoch: 5| Step: 4
Training loss: 4.355432033538818
Validation loss: 4.491014361381531

Epoch: 5| Step: 5
Training loss: 4.434708118438721
Validation loss: 4.484186818202336

Epoch: 5| Step: 6
Training loss: 5.769223213195801
Validation loss: 4.476432224114736

Epoch: 5| Step: 7
Training loss: 5.7229413986206055
Validation loss: 4.469126383463542

Epoch: 5| Step: 8
Training loss: 4.215832233428955
Validation loss: 4.4613543550173445

Epoch: 5| Step: 9
Training loss: 4.003630638122559
Validation loss: 4.453569918870926

Epoch: 5| Step: 10
Training loss: 4.7132768630981445
Validation loss: 4.4464127123355865

Epoch: 5| Step: 11
Training loss: 4.548144340515137
Validation loss: 4.438634872436523

Epoch: 12| Step: 0
Training loss: 4.993191719055176
Validation loss: 4.4312610526879626

Epoch: 5| Step: 1
Training loss: 3.9833130836486816
Validation loss: 4.424111525217692

Epoch: 5| Step: 2
Training loss: 4.5453200340271
Validation loss: 4.4165060718854265

Epoch: 5| Step: 3
Training loss: 4.728174209594727
Validation loss: 4.408733348051707

Epoch: 5| Step: 4
Training loss: 4.884709358215332
Validation loss: 4.400757332642873

Epoch: 5| Step: 5
Training loss: 3.7149505615234375
Validation loss: 4.392932703097661

Epoch: 5| Step: 6
Training loss: 5.43767786026001
Validation loss: 4.384998420874278

Epoch: 5| Step: 7
Training loss: 5.164575576782227
Validation loss: 4.3766210079193115

Epoch: 5| Step: 8
Training loss: 4.302987098693848
Validation loss: 4.369085391362508

Epoch: 5| Step: 9
Training loss: 3.753326416015625
Validation loss: 4.361211508512497

Epoch: 5| Step: 10
Training loss: 4.394205093383789
Validation loss: 4.353460311889648

Epoch: 5| Step: 11
Training loss: 3.0432844161987305
Validation loss: 4.345344593127568

Epoch: 13| Step: 0
Training loss: 4.230507850646973
Validation loss: 4.3377439975738525

Epoch: 5| Step: 1
Training loss: 5.343894004821777
Validation loss: 4.331018298864365

Epoch: 5| Step: 2
Training loss: 5.175922393798828
Validation loss: 4.324134469032288

Epoch: 5| Step: 3
Training loss: 4.910398006439209
Validation loss: 4.317022085189819

Epoch: 5| Step: 4
Training loss: 3.7106075286865234
Validation loss: 4.309470295906067

Epoch: 5| Step: 5
Training loss: 4.121131896972656
Validation loss: 4.301746139923732

Epoch: 5| Step: 6
Training loss: 5.2658514976501465
Validation loss: 4.294530948003133

Epoch: 5| Step: 7
Training loss: 3.6650688648223877
Validation loss: 4.287787655989329

Epoch: 5| Step: 8
Training loss: 4.233743667602539
Validation loss: 4.281138112147649

Epoch: 5| Step: 9
Training loss: 4.268994331359863
Validation loss: 4.274658193190892

Epoch: 5| Step: 10
Training loss: 3.783076524734497
Validation loss: 4.267737170060475

Epoch: 5| Step: 11
Training loss: 4.3382744789123535
Validation loss: 4.261835118134816

Epoch: 14| Step: 0
Training loss: 3.615832567214966
Validation loss: 4.254875590403874

Epoch: 5| Step: 1
Training loss: 4.28040075302124
Validation loss: 4.24886953830719

Epoch: 5| Step: 2
Training loss: 3.1473381519317627
Validation loss: 4.241705417633057

Epoch: 5| Step: 3
Training loss: 4.481912136077881
Validation loss: 4.234459449847539

Epoch: 5| Step: 4
Training loss: 4.077408313751221
Validation loss: 4.228170941273372

Epoch: 5| Step: 5
Training loss: 3.712057590484619
Validation loss: 4.222898940245311

Epoch: 5| Step: 6
Training loss: 5.179884433746338
Validation loss: 4.215679297844569

Epoch: 5| Step: 7
Training loss: 4.2889933586120605
Validation loss: 4.210341195265452

Epoch: 5| Step: 8
Training loss: 5.361466407775879
Validation loss: 4.205430696407954

Epoch: 5| Step: 9
Training loss: 5.427675247192383
Validation loss: 4.19984491666158

Epoch: 5| Step: 10
Training loss: 3.999682664871216
Validation loss: 4.1917828023433685

Epoch: 5| Step: 11
Training loss: 5.819204807281494
Validation loss: 4.184786359469096

Epoch: 15| Step: 0
Training loss: 5.215376853942871
Validation loss: 4.177454928557078

Epoch: 5| Step: 1
Training loss: 4.239008903503418
Validation loss: 4.171187927325566

Epoch: 5| Step: 2
Training loss: 5.041612148284912
Validation loss: 4.166047006845474

Epoch: 5| Step: 3
Training loss: 3.5143680572509766
Validation loss: 4.15872676173846

Epoch: 5| Step: 4
Training loss: 4.026862144470215
Validation loss: 4.15241676568985

Epoch: 5| Step: 5
Training loss: 3.748460054397583
Validation loss: 4.146984418233235

Epoch: 5| Step: 6
Training loss: 4.667145729064941
Validation loss: 4.1405472954114275

Epoch: 5| Step: 7
Training loss: 4.530490398406982
Validation loss: 4.134825934966405

Epoch: 5| Step: 8
Training loss: 3.4527125358581543
Validation loss: 4.129045118888219

Epoch: 5| Step: 9
Training loss: 4.605278015136719
Validation loss: 4.1239559054374695

Epoch: 5| Step: 10
Training loss: 4.255553245544434
Validation loss: 4.11744037270546

Epoch: 5| Step: 11
Training loss: 3.3247530460357666
Validation loss: 4.111490150292714

Epoch: 16| Step: 0
Training loss: 4.513354778289795
Validation loss: 4.106951316197713

Epoch: 5| Step: 1
Training loss: 4.555797100067139
Validation loss: 4.100530763467153

Epoch: 5| Step: 2
Training loss: 3.7539432048797607
Validation loss: 4.093636304140091

Epoch: 5| Step: 3
Training loss: 4.069726943969727
Validation loss: 4.087162146965663

Epoch: 5| Step: 4
Training loss: 4.2541913986206055
Validation loss: 4.0807219843069715

Epoch: 5| Step: 5
Training loss: 3.9874510765075684
Validation loss: 4.0744896829128265

Epoch: 5| Step: 6
Training loss: 4.9771928787231445
Validation loss: 4.068141241868337

Epoch: 5| Step: 7
Training loss: 5.052587032318115
Validation loss: 4.06204883257548

Epoch: 5| Step: 8
Training loss: 3.6856064796447754
Validation loss: 4.055630564689636

Epoch: 5| Step: 9
Training loss: 4.120117664337158
Validation loss: 4.049283703168233

Epoch: 5| Step: 10
Training loss: 3.5366806983947754
Validation loss: 4.044876913229625

Epoch: 5| Step: 11
Training loss: 3.456418514251709
Validation loss: 4.039023021856944

Epoch: 17| Step: 0
Training loss: 4.623115539550781
Validation loss: 4.035329093535741

Epoch: 5| Step: 1
Training loss: 4.92032527923584
Validation loss: 4.028385082880656

Epoch: 5| Step: 2
Training loss: 3.835002899169922
Validation loss: 4.022617379824321

Epoch: 5| Step: 3
Training loss: 4.012084007263184
Validation loss: 4.0166541536649065

Epoch: 5| Step: 4
Training loss: 4.850186347961426
Validation loss: 4.011807719866435

Epoch: 5| Step: 5
Training loss: 3.385711193084717
Validation loss: 4.006639351447423

Epoch: 5| Step: 6
Training loss: 4.171709060668945
Validation loss: 4.0005727509657545

Epoch: 5| Step: 7
Training loss: 4.287708282470703
Validation loss: 3.995030293862025

Epoch: 5| Step: 8
Training loss: 3.9874751567840576
Validation loss: 3.989184965689977

Epoch: 5| Step: 9
Training loss: 3.295922040939331
Validation loss: 3.9839939077695212

Epoch: 5| Step: 10
Training loss: 4.2437310218811035
Validation loss: 3.9780633449554443

Epoch: 5| Step: 11
Training loss: 4.371204376220703
Validation loss: 3.9735519190629325

Epoch: 18| Step: 0
Training loss: 4.638526916503906
Validation loss: 3.9694579541683197

Epoch: 5| Step: 1
Training loss: 4.032909870147705
Validation loss: 3.9628297487894693

Epoch: 5| Step: 2
Training loss: 4.077645301818848
Validation loss: 3.9568898578484855

Epoch: 5| Step: 3
Training loss: 4.003188610076904
Validation loss: 3.9505746265252433

Epoch: 5| Step: 4
Training loss: 3.962777614593506
Validation loss: 3.945795178413391

Epoch: 5| Step: 5
Training loss: 4.646003723144531
Validation loss: 3.940259794394175

Epoch: 5| Step: 6
Training loss: 4.530997276306152
Validation loss: 3.934871733188629

Epoch: 5| Step: 7
Training loss: 2.5525131225585938
Validation loss: 3.9288689295450845

Epoch: 5| Step: 8
Training loss: 3.792933225631714
Validation loss: 3.9234198232491813

Epoch: 5| Step: 9
Training loss: 4.172019004821777
Validation loss: 3.918185939391454

Epoch: 5| Step: 10
Training loss: 4.612724781036377
Validation loss: 3.9130868216355643

Epoch: 5| Step: 11
Training loss: 3.755254030227661
Validation loss: 3.9072931508223214

Epoch: 19| Step: 0
Training loss: 4.182459831237793
Validation loss: 3.9015844066937766

Epoch: 5| Step: 1
Training loss: 4.614889621734619
Validation loss: 3.896198590596517

Epoch: 5| Step: 2
Training loss: 3.506038188934326
Validation loss: 3.8904771407445273

Epoch: 5| Step: 3
Training loss: 4.024581432342529
Validation loss: 3.885304053624471

Epoch: 5| Step: 4
Training loss: 4.38344669342041
Validation loss: 3.881365269422531

Epoch: 5| Step: 5
Training loss: 3.1191725730895996
Validation loss: 3.8770349323749542

Epoch: 5| Step: 6
Training loss: 4.328921794891357
Validation loss: 3.871851156155268

Epoch: 5| Step: 7
Training loss: 4.205523490905762
Validation loss: 3.8659875988960266

Epoch: 5| Step: 8
Training loss: 4.462937355041504
Validation loss: 3.8612064123153687

Epoch: 5| Step: 9
Training loss: 3.7853660583496094
Validation loss: 3.8552838265895844

Epoch: 5| Step: 10
Training loss: 3.978151321411133
Validation loss: 3.8505589266618094

Epoch: 5| Step: 11
Training loss: 2.4593257904052734
Validation loss: 3.8464015324910483

Epoch: 20| Step: 0
Training loss: 3.981950283050537
Validation loss: 3.841862370570501

Epoch: 5| Step: 1
Training loss: 4.192806243896484
Validation loss: 3.835366358359655

Epoch: 5| Step: 2
Training loss: 3.2993197441101074
Validation loss: 3.829712599515915

Epoch: 5| Step: 3
Training loss: 3.7954463958740234
Validation loss: 3.825831482807795

Epoch: 5| Step: 4
Training loss: 4.775608539581299
Validation loss: 3.820846517880758

Epoch: 5| Step: 5
Training loss: 3.943453311920166
Validation loss: 3.815165420373281

Epoch: 5| Step: 6
Training loss: 4.352686882019043
Validation loss: 3.8106710414091745

Epoch: 5| Step: 7
Training loss: 3.5563883781433105
Validation loss: 3.8051688273747764

Epoch: 5| Step: 8
Training loss: 4.326249122619629
Validation loss: 3.7995210886001587

Epoch: 5| Step: 9
Training loss: 3.5395455360412598
Validation loss: 3.7945013642311096

Epoch: 5| Step: 10
Training loss: 4.3799614906311035
Validation loss: 3.7895738383134208

Epoch: 5| Step: 11
Training loss: 1.5507609844207764
Validation loss: 3.7845998307069144

Epoch: 21| Step: 0
Training loss: 3.718182325363159
Validation loss: 3.780743439992269

Epoch: 5| Step: 1
Training loss: 5.041408538818359
Validation loss: 3.7767961025238037

Epoch: 5| Step: 2
Training loss: 3.8957762718200684
Validation loss: 3.773469756046931

Epoch: 5| Step: 3
Training loss: 4.060426235198975
Validation loss: 3.769220103820165

Epoch: 5| Step: 4
Training loss: 3.0167341232299805
Validation loss: 3.7638414800167084

Epoch: 5| Step: 5
Training loss: 3.6341986656188965
Validation loss: 3.7590352098147073

Epoch: 5| Step: 6
Training loss: 3.6694107055664062
Validation loss: 3.7547053496042886

Epoch: 5| Step: 7
Training loss: 3.955218553543091
Validation loss: 3.749725172917048

Epoch: 5| Step: 8
Training loss: 3.4325904846191406
Validation loss: 3.745452404022217

Epoch: 5| Step: 9
Training loss: 4.360328674316406
Validation loss: 3.7413225571314492

Epoch: 5| Step: 10
Training loss: 4.036618709564209
Validation loss: 3.736081520716349

Epoch: 5| Step: 11
Training loss: 5.144440650939941
Validation loss: 3.7316748102506003

Epoch: 22| Step: 0
Training loss: 4.270175933837891
Validation loss: 3.727031648159027

Epoch: 5| Step: 1
Training loss: 4.61160135269165
Validation loss: 3.723192115624746

Epoch: 5| Step: 2
Training loss: 3.835693836212158
Validation loss: 3.7204757928848267

Epoch: 5| Step: 3
Training loss: 3.760758638381958
Validation loss: 3.715743750333786

Epoch: 5| Step: 4
Training loss: 3.5886969566345215
Validation loss: 3.712436020374298

Epoch: 5| Step: 5
Training loss: 4.25235652923584
Validation loss: 3.705792119105657

Epoch: 5| Step: 6
Training loss: 4.030040740966797
Validation loss: 3.700346291065216

Epoch: 5| Step: 7
Training loss: 3.4132587909698486
Validation loss: 3.6970946888128915

Epoch: 5| Step: 8
Training loss: 2.981572151184082
Validation loss: 3.692602684100469

Epoch: 5| Step: 9
Training loss: 4.17257022857666
Validation loss: 3.687933454910914

Epoch: 5| Step: 10
Training loss: 3.7213730812072754
Validation loss: 3.683692127466202

Epoch: 5| Step: 11
Training loss: 3.246265411376953
Validation loss: 3.67966494957606

Epoch: 23| Step: 0
Training loss: 2.9195902347564697
Validation loss: 3.674727221330007

Epoch: 5| Step: 1
Training loss: 3.3245673179626465
Validation loss: 3.669647445281347

Epoch: 5| Step: 2
Training loss: 4.11863374710083
Validation loss: 3.6649854481220245

Epoch: 5| Step: 3
Training loss: 3.8781776428222656
Validation loss: 3.661334921916326

Epoch: 5| Step: 4
Training loss: 2.9864635467529297
Validation loss: 3.6568394800027213

Epoch: 5| Step: 5
Training loss: 4.170977592468262
Validation loss: 3.653630097707113

Epoch: 5| Step: 6
Training loss: 3.564297914505005
Validation loss: 3.6488452653090158

Epoch: 5| Step: 7
Training loss: 5.0038838386535645
Validation loss: 3.6440444886684418

Epoch: 5| Step: 8
Training loss: 3.7719242572784424
Validation loss: 3.6386526922384896

Epoch: 5| Step: 9
Training loss: 3.2925808429718018
Validation loss: 3.6339948376019797

Epoch: 5| Step: 10
Training loss: 4.846980094909668
Validation loss: 3.629360407590866

Epoch: 5| Step: 11
Training loss: 4.1722211837768555
Validation loss: 3.6249530017375946

Epoch: 24| Step: 0
Training loss: 2.90238618850708
Validation loss: 3.620547185341517

Epoch: 5| Step: 1
Training loss: 3.988161087036133
Validation loss: 3.617363750934601

Epoch: 5| Step: 2
Training loss: 4.215546607971191
Validation loss: 3.6133333841959634

Epoch: 5| Step: 3
Training loss: 4.323958396911621
Validation loss: 3.609469930330912

Epoch: 5| Step: 4
Training loss: 3.4178671836853027
Validation loss: 3.60528701543808

Epoch: 5| Step: 5
Training loss: 3.156723737716675
Validation loss: 3.5996089577674866

Epoch: 5| Step: 6
Training loss: 4.321904182434082
Validation loss: 3.5950017174084983

Epoch: 5| Step: 7
Training loss: 3.6067287921905518
Validation loss: 3.590870370467504

Epoch: 5| Step: 8
Training loss: 4.00139856338501
Validation loss: 3.5867498417695365

Epoch: 5| Step: 9
Training loss: 3.517091751098633
Validation loss: 3.5825670063495636

Epoch: 5| Step: 10
Training loss: 3.7510852813720703
Validation loss: 3.5787792106469474

Epoch: 5| Step: 11
Training loss: 4.652615547180176
Validation loss: 3.574578106403351

Epoch: 25| Step: 0
Training loss: 3.199559211730957
Validation loss: 3.569616138935089

Epoch: 5| Step: 1
Training loss: 3.8623404502868652
Validation loss: 3.5641930301984153

Epoch: 5| Step: 2
Training loss: 4.22119665145874
Validation loss: 3.560015549262365

Epoch: 5| Step: 3
Training loss: 3.9339516162872314
Validation loss: 3.5550416807333627

Epoch: 5| Step: 4
Training loss: 3.383136749267578
Validation loss: 3.5504285196463266

Epoch: 5| Step: 5
Training loss: 3.294590473175049
Validation loss: 3.5465857783953347

Epoch: 5| Step: 6
Training loss: 4.229090213775635
Validation loss: 3.541709780693054

Epoch: 5| Step: 7
Training loss: 3.2322189807891846
Validation loss: 3.5367663403352103

Epoch: 5| Step: 8
Training loss: 4.475794792175293
Validation loss: 3.5322757164637246

Epoch: 5| Step: 9
Training loss: 4.1772685050964355
Validation loss: 3.5274245540301004

Epoch: 5| Step: 10
Training loss: 3.0659403800964355
Validation loss: 3.5231424073378244

Epoch: 5| Step: 11
Training loss: 2.483482599258423
Validation loss: 3.5191310544808707

Epoch: 26| Step: 0
Training loss: 2.8349592685699463
Validation loss: 3.51405077179273

Epoch: 5| Step: 1
Training loss: 4.219511032104492
Validation loss: 3.510587831338247

Epoch: 5| Step: 2
Training loss: 3.4233851432800293
Validation loss: 3.5061594446500144

Epoch: 5| Step: 3
Training loss: 2.9214324951171875
Validation loss: 3.5026981830596924

Epoch: 5| Step: 4
Training loss: 3.0712926387786865
Validation loss: 3.4989686409632363

Epoch: 5| Step: 5
Training loss: 4.443040370941162
Validation loss: 3.493390510479609

Epoch: 5| Step: 6
Training loss: 3.296095371246338
Validation loss: 3.4877635836601257

Epoch: 5| Step: 7
Training loss: 3.763340711593628
Validation loss: 3.4851593573888144

Epoch: 5| Step: 8
Training loss: 3.8500702381134033
Validation loss: 3.4805925488471985

Epoch: 5| Step: 9
Training loss: 4.167954921722412
Validation loss: 3.4768716593583426

Epoch: 5| Step: 10
Training loss: 3.806391477584839
Validation loss: 3.4725875655810037

Epoch: 5| Step: 11
Training loss: 5.932723045349121
Validation loss: 3.4680394331614175

Epoch: 27| Step: 0
Training loss: 3.1708755493164062
Validation loss: 3.463179270426432

Epoch: 5| Step: 1
Training loss: 4.019886016845703
Validation loss: 3.4585314095020294

Epoch: 5| Step: 2
Training loss: 3.5958023071289062
Validation loss: 3.4536694288253784

Epoch: 5| Step: 3
Training loss: 4.05290412902832
Validation loss: 3.4481523633003235

Epoch: 5| Step: 4
Training loss: 3.5348594188690186
Validation loss: 3.4438501596450806

Epoch: 5| Step: 5
Training loss: 3.46075439453125
Validation loss: 3.4394240975379944

Epoch: 5| Step: 6
Training loss: 3.731370210647583
Validation loss: 3.436538110176722

Epoch: 5| Step: 7
Training loss: 3.864760637283325
Validation loss: 3.4331173102060952

Epoch: 5| Step: 8
Training loss: 3.7621207237243652
Validation loss: 3.4284060498078666

Epoch: 5| Step: 9
Training loss: 3.0096213817596436
Validation loss: 3.4241237143675485

Epoch: 5| Step: 10
Training loss: 3.4859001636505127
Validation loss: 3.4161672393480935

Epoch: 5| Step: 11
Training loss: 3.5083694458007812
Validation loss: 3.4134643574555716

Epoch: 28| Step: 0
Training loss: 4.244382858276367
Validation loss: 3.4096436500549316

Epoch: 5| Step: 1
Training loss: 3.602815628051758
Validation loss: 3.4048410952091217

Epoch: 5| Step: 2
Training loss: 2.996387481689453
Validation loss: 3.400440216064453

Epoch: 5| Step: 3
Training loss: 3.225212574005127
Validation loss: 3.398398240407308

Epoch: 5| Step: 4
Training loss: 4.272544860839844
Validation loss: 3.3953640460968018

Epoch: 5| Step: 5
Training loss: 2.6825110912323
Validation loss: 3.390077422062556

Epoch: 5| Step: 6
Training loss: 3.7278029918670654
Validation loss: 3.3876845439275107

Epoch: 5| Step: 7
Training loss: 3.6771435737609863
Validation loss: 3.3816838363806405

Epoch: 5| Step: 8
Training loss: 3.915888547897339
Validation loss: 3.3766851325829825

Epoch: 5| Step: 9
Training loss: 3.362805128097534
Validation loss: 3.370576043923696

Epoch: 5| Step: 10
Training loss: 3.4892051219940186
Validation loss: 3.3668531080087027

Epoch: 5| Step: 11
Training loss: 3.116943597793579
Validation loss: 3.361867129802704

Epoch: 29| Step: 0
Training loss: 4.721925258636475
Validation loss: 3.360498756170273

Epoch: 5| Step: 1
Training loss: 2.964996099472046
Validation loss: 3.3536942303180695

Epoch: 5| Step: 2
Training loss: 3.261373996734619
Validation loss: 3.3497149546941123

Epoch: 5| Step: 3
Training loss: 2.9712421894073486
Validation loss: 3.3475817243258157

Epoch: 5| Step: 4
Training loss: 2.779564380645752
Validation loss: 3.344204624493917

Epoch: 5| Step: 5
Training loss: 3.590927839279175
Validation loss: 3.338273366292318

Epoch: 5| Step: 6
Training loss: 3.4319686889648438
Validation loss: 3.33367391427358

Epoch: 5| Step: 7
Training loss: 3.9706130027770996
Validation loss: 3.32734223206838

Epoch: 5| Step: 8
Training loss: 4.58232307434082
Validation loss: 3.324747771024704

Epoch: 5| Step: 9
Training loss: 3.3683395385742188
Validation loss: 3.3207539121309915

Epoch: 5| Step: 10
Training loss: 3.145597457885742
Validation loss: 3.316265344619751

Epoch: 5| Step: 11
Training loss: 2.4941272735595703
Validation loss: 3.3121126194794974

Epoch: 30| Step: 0
Training loss: 3.189739942550659
Validation loss: 3.308007230361303

Epoch: 5| Step: 1
Training loss: 3.585594892501831
Validation loss: 3.305080473423004

Epoch: 5| Step: 2
Training loss: 3.9056365489959717
Validation loss: 3.300318787495295

Epoch: 5| Step: 3
Training loss: 3.361250638961792
Validation loss: 3.2959673206011453

Epoch: 5| Step: 4
Training loss: 3.67071270942688
Validation loss: 3.292273918787638

Epoch: 5| Step: 5
Training loss: 3.4205195903778076
Validation loss: 3.288517266511917

Epoch: 5| Step: 6
Training loss: 3.829846143722534
Validation loss: 3.2855754097302756

Epoch: 5| Step: 7
Training loss: 3.1507089138031006
Validation loss: 3.281875322262446

Epoch: 5| Step: 8
Training loss: 3.4555981159210205
Validation loss: 3.2774488826592765

Epoch: 5| Step: 9
Training loss: 3.2690396308898926
Validation loss: 3.2738909920056662

Epoch: 5| Step: 10
Training loss: 3.2653191089630127
Validation loss: 3.269487718741099

Epoch: 5| Step: 11
Training loss: 3.4671998023986816
Validation loss: 3.26554274559021

Epoch: 31| Step: 0
Training loss: 3.2868828773498535
Validation loss: 3.2614499578873315

Epoch: 5| Step: 1
Training loss: 2.998807668685913
Validation loss: 3.2573616007963815

Epoch: 5| Step: 2
Training loss: 3.6976311206817627
Validation loss: 3.2534428238868713

Epoch: 5| Step: 3
Training loss: 2.854628086090088
Validation loss: 3.249677747488022

Epoch: 5| Step: 4
Training loss: 4.28249454498291
Validation loss: 3.246537705262502

Epoch: 5| Step: 5
Training loss: 3.441939115524292
Validation loss: 3.2424310048421225

Epoch: 5| Step: 6
Training loss: 2.7573065757751465
Validation loss: 3.239837865034739

Epoch: 5| Step: 7
Training loss: 3.693556308746338
Validation loss: 3.2365229427814484

Epoch: 5| Step: 8
Training loss: 3.199672222137451
Validation loss: 3.231890539328257

Epoch: 5| Step: 9
Training loss: 3.1286678314208984
Validation loss: 3.226699968179067

Epoch: 5| Step: 10
Training loss: 4.196511268615723
Validation loss: 3.2241904040177665

Epoch: 5| Step: 11
Training loss: 3.803593873977661
Validation loss: 3.219057490428289

Epoch: 32| Step: 0
Training loss: 3.687028408050537
Validation loss: 3.215158631404241

Epoch: 5| Step: 1
Training loss: 3.088954448699951
Validation loss: 3.2113732397556305

Epoch: 5| Step: 2
Training loss: 3.2425029277801514
Validation loss: 3.20787384112676

Epoch: 5| Step: 3
Training loss: 3.540245771408081
Validation loss: 3.2038008073965707

Epoch: 5| Step: 4
Training loss: 3.7356021404266357
Validation loss: 3.19962614774704

Epoch: 5| Step: 5
Training loss: 3.1788785457611084
Validation loss: 3.1955867310365043

Epoch: 5| Step: 6
Training loss: 2.9658427238464355
Validation loss: 3.1913303434848785

Epoch: 5| Step: 7
Training loss: 3.3009963035583496
Validation loss: 3.1872510810693107

Epoch: 5| Step: 8
Training loss: 3.9940826892852783
Validation loss: 3.1833463410536447

Epoch: 5| Step: 9
Training loss: 3.4851608276367188
Validation loss: 3.1787593960762024

Epoch: 5| Step: 10
Training loss: 3.2423954010009766
Validation loss: 3.175029913584391

Epoch: 5| Step: 11
Training loss: 1.756385087966919
Validation loss: 3.1706535617510476

Epoch: 33| Step: 0
Training loss: 3.3588058948516846
Validation loss: 3.1669484972953796

Epoch: 5| Step: 1
Training loss: 3.0758373737335205
Validation loss: 3.163067102432251

Epoch: 5| Step: 2
Training loss: 3.9139294624328613
Validation loss: 3.158478597799937

Epoch: 5| Step: 3
Training loss: 3.4404964447021484
Validation loss: 3.1546413600444794

Epoch: 5| Step: 4
Training loss: 3.305933713912964
Validation loss: 3.1524002055327096

Epoch: 5| Step: 5
Training loss: 3.9734549522399902
Validation loss: 3.1512458324432373

Epoch: 5| Step: 6
Training loss: 2.6117167472839355
Validation loss: 3.1529519259929657

Epoch: 5| Step: 7
Training loss: 2.9824907779693604
Validation loss: 3.1600037117799125

Epoch: 5| Step: 8
Training loss: 3.6292967796325684
Validation loss: 3.1404969692230225

Epoch: 5| Step: 9
Training loss: 3.2207846641540527
Validation loss: 3.13248543938001

Epoch: 5| Step: 10
Training loss: 3.1014552116394043
Validation loss: 3.128282050291697

Epoch: 5| Step: 11
Training loss: 3.583801746368408
Validation loss: 3.128101239601771

Epoch: 34| Step: 0
Training loss: 3.002140760421753
Validation loss: 3.1617447634538016

Epoch: 5| Step: 1
Training loss: 3.894629716873169
Validation loss: 3.1620037853717804

Epoch: 5| Step: 2
Training loss: 2.898026704788208
Validation loss: 3.161728411912918

Epoch: 5| Step: 3
Training loss: 3.2647757530212402
Validation loss: 3.1554206907749176

Epoch: 5| Step: 4
Training loss: 2.6023550033569336
Validation loss: 3.148472915093104

Epoch: 5| Step: 5
Training loss: 3.9031612873077393
Validation loss: 3.1437587340672812

Epoch: 5| Step: 6
Training loss: 4.232572555541992
Validation loss: 3.139897267023722

Epoch: 5| Step: 7
Training loss: 2.8609237670898438
Validation loss: 3.1352929969628653

Epoch: 5| Step: 8
Training loss: 3.17460560798645
Validation loss: 3.132096072038015

Epoch: 5| Step: 9
Training loss: 3.8043084144592285
Validation loss: 3.1264871060848236

Epoch: 5| Step: 10
Training loss: 3.0394644737243652
Validation loss: 3.1229931910832724

Epoch: 5| Step: 11
Training loss: 3.22012996673584
Validation loss: 3.119311740001043

Epoch: 35| Step: 0
Training loss: 4.066250801086426
Validation loss: 3.116165558497111

Epoch: 5| Step: 1
Training loss: 2.7925143241882324
Validation loss: 3.1148200631141663

Epoch: 5| Step: 2
Training loss: 2.8556549549102783
Validation loss: 3.1091341376304626

Epoch: 5| Step: 3
Training loss: 3.2973201274871826
Validation loss: 3.103968689839045

Epoch: 5| Step: 4
Training loss: 3.319828748703003
Validation loss: 3.100369026263555

Epoch: 5| Step: 5
Training loss: 3.092372417449951
Validation loss: 3.097269038359324

Epoch: 5| Step: 6
Training loss: 3.603212833404541
Validation loss: 3.093812415997187

Epoch: 5| Step: 7
Training loss: 2.6495418548583984
Validation loss: 3.090050329764684

Epoch: 5| Step: 8
Training loss: 3.3011043071746826
Validation loss: 3.086929529905319

Epoch: 5| Step: 9
Training loss: 3.4485721588134766
Validation loss: 3.083551049232483

Epoch: 5| Step: 10
Training loss: 3.8403427600860596
Validation loss: 3.0801639755566916

Epoch: 5| Step: 11
Training loss: 2.728404998779297
Validation loss: 3.076527218023936

Epoch: 36| Step: 0
Training loss: 2.50455904006958
Validation loss: 3.0725073715051017

Epoch: 5| Step: 1
Training loss: 2.5236518383026123
Validation loss: 3.0695410867532096

Epoch: 5| Step: 2
Training loss: 2.952208995819092
Validation loss: 3.0659999350706735

Epoch: 5| Step: 3
Training loss: 3.5647099018096924
Validation loss: 3.0626067419846854

Epoch: 5| Step: 4
Training loss: 3.323160171508789
Validation loss: 3.0589589178562164

Epoch: 5| Step: 5
Training loss: 3.6810505390167236
Validation loss: 3.0556355118751526

Epoch: 5| Step: 6
Training loss: 3.5047097206115723
Validation loss: 3.0522682766119638

Epoch: 5| Step: 7
Training loss: 3.4403862953186035
Validation loss: 3.0488125681877136

Epoch: 5| Step: 8
Training loss: 2.912139415740967
Validation loss: 3.045269171396891

Epoch: 5| Step: 9
Training loss: 3.566439390182495
Validation loss: 3.0419564247131348

Epoch: 5| Step: 10
Training loss: 3.4884822368621826
Validation loss: 3.0388380587100983

Epoch: 5| Step: 11
Training loss: 4.359403610229492
Validation loss: 3.034712384144465

Epoch: 37| Step: 0
Training loss: 3.075892925262451
Validation loss: 3.0304283996423087

Epoch: 5| Step: 1
Training loss: 3.6137282848358154
Validation loss: 3.026613970597585

Epoch: 5| Step: 2
Training loss: 3.1471354961395264
Validation loss: 3.0230471591154733

Epoch: 5| Step: 3
Training loss: 3.1368649005889893
Validation loss: 3.0183732310930886

Epoch: 5| Step: 4
Training loss: 3.4209110736846924
Validation loss: 3.0148821274439492

Epoch: 5| Step: 5
Training loss: 2.303173542022705
Validation loss: 3.011174122492472

Epoch: 5| Step: 6
Training loss: 2.9018168449401855
Validation loss: 3.0077996850013733

Epoch: 5| Step: 7
Training loss: 3.033036231994629
Validation loss: 3.0048765937487283

Epoch: 5| Step: 8
Training loss: 2.9688339233398438
Validation loss: 3.002077708641688

Epoch: 5| Step: 9
Training loss: 3.805640459060669
Validation loss: 3.0052227278550467

Epoch: 5| Step: 10
Training loss: 3.631911516189575
Validation loss: 2.995701551437378

Epoch: 5| Step: 11
Training loss: 4.201996803283691
Validation loss: 2.9901051620642343

Epoch: 38| Step: 0
Training loss: 3.0465281009674072
Validation loss: 2.9860009054342904

Epoch: 5| Step: 1
Training loss: 3.754185199737549
Validation loss: 2.982481320699056

Epoch: 5| Step: 2
Training loss: 3.439189910888672
Validation loss: 2.978116770585378

Epoch: 5| Step: 3
Training loss: 3.6962733268737793
Validation loss: 2.9756462375322976

Epoch: 5| Step: 4
Training loss: 2.8447425365448
Validation loss: 2.970279276371002

Epoch: 5| Step: 5
Training loss: 3.46569561958313
Validation loss: 2.966050148010254

Epoch: 5| Step: 6
Training loss: 2.8761391639709473
Validation loss: 2.962170163790385

Epoch: 5| Step: 7
Training loss: 2.7985453605651855
Validation loss: 2.9585302968819938

Epoch: 5| Step: 8
Training loss: 3.9649949073791504
Validation loss: 2.955606589714686

Epoch: 5| Step: 9
Training loss: 2.301685094833374
Validation loss: 2.95187055071195

Epoch: 5| Step: 10
Training loss: 2.7693967819213867
Validation loss: 2.94821505745252

Epoch: 5| Step: 11
Training loss: 2.467017650604248
Validation loss: 2.944686621427536

Epoch: 39| Step: 0
Training loss: 3.1080727577209473
Validation loss: 2.9413929184277854

Epoch: 5| Step: 1
Training loss: 2.835615873336792
Validation loss: 2.937895745038986

Epoch: 5| Step: 2
Training loss: 3.0042033195495605
Validation loss: 2.9355549414952598

Epoch: 5| Step: 3
Training loss: 3.232748508453369
Validation loss: 2.93259197473526

Epoch: 5| Step: 4
Training loss: 4.107580184936523
Validation loss: 2.932279179493586

Epoch: 5| Step: 5
Training loss: 2.583528518676758
Validation loss: 2.931213448445002

Epoch: 5| Step: 6
Training loss: 2.5589396953582764
Validation loss: 2.9449106256167092

Epoch: 5| Step: 7
Training loss: 3.207258701324463
Validation loss: 2.9748356540997825

Epoch: 5| Step: 8
Training loss: 3.161806583404541
Validation loss: 2.919553279876709

Epoch: 5| Step: 9
Training loss: 2.983833074569702
Validation loss: 2.9123917321364083

Epoch: 5| Step: 10
Training loss: 3.514544725418091
Validation loss: 2.9098654687404633

Epoch: 5| Step: 11
Training loss: 3.8567771911621094
Validation loss: 2.908371319373449

Epoch: 40| Step: 0
Training loss: 3.1420271396636963
Validation loss: 2.907809446255366

Epoch: 5| Step: 1
Training loss: 2.130662441253662
Validation loss: 2.908333112796148

Epoch: 5| Step: 2
Training loss: 3.758610248565674
Validation loss: 2.911408176024755

Epoch: 5| Step: 3
Training loss: 3.0645079612731934
Validation loss: 2.907748540242513

Epoch: 5| Step: 4
Training loss: 3.7061119079589844
Validation loss: 2.9002327919006348

Epoch: 5| Step: 5
Training loss: 2.700396776199341
Validation loss: 2.897098114093145

Epoch: 5| Step: 6
Training loss: 3.5116543769836426
Validation loss: 2.891172081232071

Epoch: 5| Step: 7
Training loss: 2.6324219703674316
Validation loss: 2.8867953022321067

Epoch: 5| Step: 8
Training loss: 3.093108654022217
Validation loss: 2.8808550933996835

Epoch: 5| Step: 9
Training loss: 2.8552322387695312
Validation loss: 2.8771244982878366

Epoch: 5| Step: 10
Training loss: 3.425206422805786
Validation loss: 2.8731433749198914

Epoch: 5| Step: 11
Training loss: 3.467698097229004
Validation loss: 2.8694756627082825

Epoch: 41| Step: 0
Training loss: 2.961857318878174
Validation loss: 2.866493970155716

Epoch: 5| Step: 1
Training loss: 3.500948429107666
Validation loss: 2.8625372846921286

Epoch: 5| Step: 2
Training loss: 3.3261427879333496
Validation loss: 2.8597600360711417

Epoch: 5| Step: 3
Training loss: 3.093904972076416
Validation loss: 2.8562215864658356

Epoch: 5| Step: 4
Training loss: 2.179783821105957
Validation loss: 2.8543823758761087

Epoch: 5| Step: 5
Training loss: 2.5837936401367188
Validation loss: 2.851213882366816

Epoch: 5| Step: 6
Training loss: 3.3822999000549316
Validation loss: 2.849920228123665

Epoch: 5| Step: 7
Training loss: 2.9171576499938965
Validation loss: 2.847638060649236

Epoch: 5| Step: 8
Training loss: 2.8517708778381348
Validation loss: 2.843977709611257

Epoch: 5| Step: 9
Training loss: 3.2997589111328125
Validation loss: 2.841371943553289

Epoch: 5| Step: 10
Training loss: 3.681363582611084
Validation loss: 2.8381615380446115

Epoch: 5| Step: 11
Training loss: 2.4554946422576904
Validation loss: 2.8347080051898956

Epoch: 42| Step: 0
Training loss: 2.6664347648620605
Validation loss: 2.829405198494593

Epoch: 5| Step: 1
Training loss: 2.8472986221313477
Validation loss: 2.826278865337372

Epoch: 5| Step: 2
Training loss: 2.9594626426696777
Validation loss: 2.8238156735897064

Epoch: 5| Step: 3
Training loss: 3.365478992462158
Validation loss: 2.82076632976532

Epoch: 5| Step: 4
Training loss: 3.1636223793029785
Validation loss: 2.8168354829152427

Epoch: 5| Step: 5
Training loss: 2.5102145671844482
Validation loss: 2.8127593398094177

Epoch: 5| Step: 6
Training loss: 2.899446964263916
Validation loss: 2.809089740117391

Epoch: 5| Step: 7
Training loss: 3.431959629058838
Validation loss: 2.80639319618543

Epoch: 5| Step: 8
Training loss: 3.006351947784424
Validation loss: 2.8046451210975647

Epoch: 5| Step: 9
Training loss: 3.0333690643310547
Validation loss: 2.7994739214579263

Epoch: 5| Step: 10
Training loss: 3.0837931632995605
Validation loss: 2.7972246507803598

Epoch: 5| Step: 11
Training loss: 4.453366279602051
Validation loss: 2.7942089239756265

Epoch: 43| Step: 0
Training loss: 3.3549320697784424
Validation loss: 2.791553258895874

Epoch: 5| Step: 1
Training loss: 2.4868741035461426
Validation loss: 2.789554158846537

Epoch: 5| Step: 2
Training loss: 2.8137612342834473
Validation loss: 2.7865542272726693

Epoch: 5| Step: 3
Training loss: 3.0266013145446777
Validation loss: 2.7819196780522666

Epoch: 5| Step: 4
Training loss: 3.1352226734161377
Validation loss: 2.7783075074354806

Epoch: 5| Step: 5
Training loss: 2.9061217308044434
Validation loss: 2.775698353846868

Epoch: 5| Step: 6
Training loss: 3.442096710205078
Validation loss: 2.771843602259954

Epoch: 5| Step: 7
Training loss: 3.1132965087890625
Validation loss: 2.7689462304115295

Epoch: 5| Step: 8
Training loss: 2.504117727279663
Validation loss: 2.7658095161120095

Epoch: 5| Step: 9
Training loss: 3.2781691551208496
Validation loss: 2.762013634045919

Epoch: 5| Step: 10
Training loss: 2.878131151199341
Validation loss: 2.7603738208611808

Epoch: 5| Step: 11
Training loss: 2.587581157684326
Validation loss: 2.757151315609614

Epoch: 44| Step: 0
Training loss: 2.906834125518799
Validation loss: 2.7539785305658975

Epoch: 5| Step: 1
Training loss: 2.7853000164031982
Validation loss: 2.7515162924925485

Epoch: 5| Step: 2
Training loss: 2.77547287940979
Validation loss: 2.7478581766287484

Epoch: 5| Step: 3
Training loss: 3.281702756881714
Validation loss: 2.7454350292682648

Epoch: 5| Step: 4
Training loss: 3.191673994064331
Validation loss: 2.741597612698873

Epoch: 5| Step: 5
Training loss: 3.3253350257873535
Validation loss: 2.7386188308397927

Epoch: 5| Step: 6
Training loss: 3.085827589035034
Validation loss: 2.7353645861148834

Epoch: 5| Step: 7
Training loss: 2.5707004070281982
Validation loss: 2.7339685757954917

Epoch: 5| Step: 8
Training loss: 3.3199849128723145
Validation loss: 2.730868915716807

Epoch: 5| Step: 9
Training loss: 2.7087483406066895
Validation loss: 2.728569577137629

Epoch: 5| Step: 10
Training loss: 2.5259950160980225
Validation loss: 2.7250106235345206

Epoch: 5| Step: 11
Training loss: 2.7177555561065674
Validation loss: 2.7225074966748557

Epoch: 45| Step: 0
Training loss: 2.6712889671325684
Validation loss: 2.7204441130161285

Epoch: 5| Step: 1
Training loss: 3.272183895111084
Validation loss: 2.7194411953290305

Epoch: 5| Step: 2
Training loss: 3.4280242919921875
Validation loss: 2.716077287991842

Epoch: 5| Step: 3
Training loss: 3.569269895553589
Validation loss: 2.710550626118978

Epoch: 5| Step: 4
Training loss: 2.4017319679260254
Validation loss: 2.7081017841895423

Epoch: 5| Step: 5
Training loss: 2.597454786300659
Validation loss: 2.7049376169840493

Epoch: 5| Step: 6
Training loss: 2.658933162689209
Validation loss: 2.704078992207845

Epoch: 5| Step: 7
Training loss: 2.114208221435547
Validation loss: 2.69970366358757

Epoch: 5| Step: 8
Training loss: 3.3952319622039795
Validation loss: 2.7043527364730835

Epoch: 5| Step: 9
Training loss: 2.7877261638641357
Validation loss: 2.6984643836816153

Epoch: 5| Step: 10
Training loss: 3.0902113914489746
Validation loss: 2.694012612104416

Epoch: 5| Step: 11
Training loss: 3.285966396331787
Validation loss: 2.6928944985071817

Epoch: 46| Step: 0
Training loss: 2.605290174484253
Validation loss: 2.688666601975759

Epoch: 5| Step: 1
Training loss: 3.125767230987549
Validation loss: 2.6866799692312875

Epoch: 5| Step: 2
Training loss: 3.7366766929626465
Validation loss: 2.6826499005158744

Epoch: 5| Step: 3
Training loss: 2.404630661010742
Validation loss: 2.6807929823795953

Epoch: 5| Step: 4
Training loss: 3.2750492095947266
Validation loss: 2.677573879559835

Epoch: 5| Step: 5
Training loss: 2.6391849517822266
Validation loss: 2.671906888484955

Epoch: 5| Step: 6
Training loss: 2.7186193466186523
Validation loss: 2.6693919797738395

Epoch: 5| Step: 7
Training loss: 3.677736759185791
Validation loss: 2.668175846338272

Epoch: 5| Step: 8
Training loss: 2.456047534942627
Validation loss: 2.665917754173279

Epoch: 5| Step: 9
Training loss: 3.0611448287963867
Validation loss: 2.6625062624613443

Epoch: 5| Step: 10
Training loss: 2.2059998512268066
Validation loss: 2.6578840712706246

Epoch: 5| Step: 11
Training loss: 1.7295329570770264
Validation loss: 2.654928962389628

Epoch: 47| Step: 0
Training loss: 2.6589882373809814
Validation loss: 2.6529548267523446

Epoch: 5| Step: 1
Training loss: 3.046673536300659
Validation loss: 2.6509246230125427

Epoch: 5| Step: 2
Training loss: 2.853724718093872
Validation loss: 2.6505483190218606

Epoch: 5| Step: 3
Training loss: 3.0661447048187256
Validation loss: 2.645376910765966

Epoch: 5| Step: 4
Training loss: 2.579375743865967
Validation loss: 2.644145061572393

Epoch: 5| Step: 5
Training loss: 2.3644003868103027
Validation loss: 2.6375109255313873

Epoch: 5| Step: 6
Training loss: 2.8618342876434326
Validation loss: 2.637980490922928

Epoch: 5| Step: 7
Training loss: 3.159282684326172
Validation loss: 2.6324627796808877

Epoch: 5| Step: 8
Training loss: 2.838388681411743
Validation loss: 2.62853134671847

Epoch: 5| Step: 9
Training loss: 2.7931973934173584
Validation loss: 2.625726451476415

Epoch: 5| Step: 10
Training loss: 3.1445024013519287
Validation loss: 2.6212318738301597

Epoch: 5| Step: 11
Training loss: 2.3790950775146484
Validation loss: 2.617861251036326

Epoch: 48| Step: 0
Training loss: 3.071415662765503
Validation loss: 2.617220570643743

Epoch: 5| Step: 1
Training loss: 3.1639184951782227
Validation loss: 2.6125474174817405

Epoch: 5| Step: 2
Training loss: 2.9507851600646973
Validation loss: 2.610821376244227

Epoch: 5| Step: 3
Training loss: 2.675632953643799
Validation loss: 2.6072711745897927

Epoch: 5| Step: 4
Training loss: 2.0901293754577637
Validation loss: 2.6060637136300406

Epoch: 5| Step: 5
Training loss: 2.5375304222106934
Validation loss: 2.603979488213857

Epoch: 5| Step: 6
Training loss: 2.8287549018859863
Validation loss: 2.6026228765646615

Epoch: 5| Step: 7
Training loss: 3.1257832050323486
Validation loss: 2.599755341808001

Epoch: 5| Step: 8
Training loss: 2.883636951446533
Validation loss: 2.5985934138298035

Epoch: 5| Step: 9
Training loss: 3.0357825756073
Validation loss: 2.5985315640767417

Epoch: 5| Step: 10
Training loss: 2.6127824783325195
Validation loss: 2.5909529328346252

Epoch: 5| Step: 11
Training loss: 2.2668862342834473
Validation loss: 2.583539138237635

Epoch: 49| Step: 0
Training loss: 2.9135046005249023
Validation loss: 2.5810958544413247

Epoch: 5| Step: 1
Training loss: 2.343578815460205
Validation loss: 2.580863823493322

Epoch: 5| Step: 2
Training loss: 2.5744338035583496
Validation loss: 2.5799487431844077

Epoch: 5| Step: 3
Training loss: 2.6884257793426514
Validation loss: 2.5774552822113037

Epoch: 5| Step: 4
Training loss: 3.144836902618408
Validation loss: 2.578002691268921

Epoch: 5| Step: 5
Training loss: 2.7289772033691406
Validation loss: 2.5741226077079773

Epoch: 5| Step: 6
Training loss: 2.5790417194366455
Validation loss: 2.571200837691625

Epoch: 5| Step: 7
Training loss: 2.847379207611084
Validation loss: 2.566768934329351

Epoch: 5| Step: 8
Training loss: 2.403200387954712
Validation loss: 2.5630401372909546

Epoch: 5| Step: 9
Training loss: 3.0693395137786865
Validation loss: 2.558779160181681

Epoch: 5| Step: 10
Training loss: 3.0072085857391357
Validation loss: 2.5586585799853006

Epoch: 5| Step: 11
Training loss: 3.7726855278015137
Validation loss: 2.556192914644877

Epoch: 50| Step: 0
Training loss: 1.9339452981948853
Validation loss: 2.5501020153363547

Epoch: 5| Step: 1
Training loss: 3.343848705291748
Validation loss: 2.548864334821701

Epoch: 5| Step: 2
Training loss: 2.975407361984253
Validation loss: 2.5453732907772064

Epoch: 5| Step: 3
Training loss: 2.5334529876708984
Validation loss: 2.5439060628414154

Epoch: 5| Step: 4
Training loss: 3.065001964569092
Validation loss: 2.5402444998423257

Epoch: 5| Step: 5
Training loss: 2.3241050243377686
Validation loss: 2.536253700653712

Epoch: 5| Step: 6
Training loss: 2.4301247596740723
Validation loss: 2.532798399527868

Epoch: 5| Step: 7
Training loss: 2.2771947383880615
Validation loss: 2.531421651442846

Epoch: 5| Step: 8
Training loss: 2.6320128440856934
Validation loss: 2.5275497088829675

Epoch: 5| Step: 9
Training loss: 3.190295457839966
Validation loss: 2.526162564754486

Epoch: 5| Step: 10
Training loss: 3.0386803150177
Validation loss: 2.5231318175792694

Epoch: 5| Step: 11
Training loss: 4.519131660461426
Validation loss: 2.5213657716910043

Epoch: 51| Step: 0
Training loss: 2.3652262687683105
Validation loss: 2.5175326267878213

Epoch: 5| Step: 1
Training loss: 3.13468599319458
Validation loss: 2.515493015448252

Epoch: 5| Step: 2
Training loss: 2.9841578006744385
Validation loss: 2.5110185692707696

Epoch: 5| Step: 3
Training loss: 3.010723352432251
Validation loss: 2.509181092182795

Epoch: 5| Step: 4
Training loss: 2.261993885040283
Validation loss: 2.506881674130758

Epoch: 5| Step: 5
Training loss: 2.5424563884735107
Validation loss: 2.5030160347620645

Epoch: 5| Step: 6
Training loss: 2.6139683723449707
Validation loss: 2.50035497546196

Epoch: 5| Step: 7
Training loss: 2.7181477546691895
Validation loss: 2.498202254374822

Epoch: 5| Step: 8
Training loss: 2.8210906982421875
Validation loss: 2.4961081544558206

Epoch: 5| Step: 9
Training loss: 2.338548183441162
Validation loss: 2.4932386577129364

Epoch: 5| Step: 10
Training loss: 2.8375048637390137
Validation loss: 2.4894657532374063

Epoch: 5| Step: 11
Training loss: 3.065708637237549
Validation loss: 2.4871186912059784

Epoch: 52| Step: 0
Training loss: 2.4894871711730957
Validation loss: 2.484146843353907

Epoch: 5| Step: 1
Training loss: 2.780768394470215
Validation loss: 2.480730046828588

Epoch: 5| Step: 2
Training loss: 2.781691789627075
Validation loss: 2.4791579842567444

Epoch: 5| Step: 3
Training loss: 2.2762537002563477
Validation loss: 2.4751185178756714

Epoch: 5| Step: 4
Training loss: 2.684171199798584
Validation loss: 2.4746178885300956

Epoch: 5| Step: 5
Training loss: 2.287916898727417
Validation loss: 2.470738639434179

Epoch: 5| Step: 6
Training loss: 3.0310468673706055
Validation loss: 2.467309763034185

Epoch: 5| Step: 7
Training loss: 2.3813912868499756
Validation loss: 2.467683345079422

Epoch: 5| Step: 8
Training loss: 2.9406237602233887
Validation loss: 2.4617013335227966

Epoch: 5| Step: 9
Training loss: 3.1029305458068848
Validation loss: 2.4605687906344733

Epoch: 5| Step: 10
Training loss: 2.631669282913208
Validation loss: 2.4572794983784356

Epoch: 5| Step: 11
Training loss: 2.1403732299804688
Validation loss: 2.4552283684412637

Epoch: 53| Step: 0
Training loss: 2.630227565765381
Validation loss: 2.4609018862247467

Epoch: 5| Step: 1
Training loss: 2.686389446258545
Validation loss: 2.465118169784546

Epoch: 5| Step: 2
Training loss: 2.7365753650665283
Validation loss: 2.486037482817968

Epoch: 5| Step: 3
Training loss: 2.7909164428710938
Validation loss: 2.4988439877827964

Epoch: 5| Step: 4
Training loss: 3.1025729179382324
Validation loss: 2.495628078778585

Epoch: 5| Step: 5
Training loss: 2.449916362762451
Validation loss: 2.4651112059752145

Epoch: 5| Step: 6
Training loss: 2.6331169605255127
Validation loss: 2.4492719570795694

Epoch: 5| Step: 7
Training loss: 2.2094502449035645
Validation loss: 2.4332770705223083

Epoch: 5| Step: 8
Training loss: 2.6742594242095947
Validation loss: 2.4316730201244354

Epoch: 5| Step: 9
Training loss: 2.655395269393921
Validation loss: 2.4317123790582023

Epoch: 5| Step: 10
Training loss: 2.7951319217681885
Validation loss: 2.433447072903315

Epoch: 5| Step: 11
Training loss: 1.0318784713745117
Validation loss: 2.4345832069714866

Epoch: 54| Step: 0
Training loss: 2.3242239952087402
Validation loss: 2.4380892316500344

Epoch: 5| Step: 1
Training loss: 2.8654654026031494
Validation loss: 2.4401995042959848

Epoch: 5| Step: 2
Training loss: 2.775068521499634
Validation loss: 2.442796220382055

Epoch: 5| Step: 3
Training loss: 3.0221107006073
Validation loss: 2.4427551527818046

Epoch: 5| Step: 4
Training loss: 2.4653751850128174
Validation loss: 2.440831551949183

Epoch: 5| Step: 5
Training loss: 2.2959282398223877
Validation loss: 2.4362579782803855

Epoch: 5| Step: 6
Training loss: 2.6967508792877197
Validation loss: 2.4295009026924768

Epoch: 5| Step: 7
Training loss: 2.1782097816467285
Validation loss: 2.4242247144381204

Epoch: 5| Step: 8
Training loss: 2.957146167755127
Validation loss: 2.41999144355456

Epoch: 5| Step: 9
Training loss: 2.6695427894592285
Validation loss: 2.4159025649229684

Epoch: 5| Step: 10
Training loss: 2.4940407276153564
Validation loss: 2.4100151459376016

Epoch: 5| Step: 11
Training loss: 2.5412492752075195
Validation loss: 2.406102160612742

Epoch: 55| Step: 0
Training loss: 2.147731304168701
Validation loss: 2.4006111919879913

Epoch: 5| Step: 1
Training loss: 2.6498913764953613
Validation loss: 2.3977274348338447

Epoch: 5| Step: 2
Training loss: 2.636206865310669
Validation loss: 2.3966120382150016

Epoch: 5| Step: 3
Training loss: 2.0305724143981934
Validation loss: 2.3923207422097525

Epoch: 5| Step: 4
Training loss: 2.5853912830352783
Validation loss: 2.3993419110774994

Epoch: 5| Step: 5
Training loss: 2.886221408843994
Validation loss: 2.398721178372701

Epoch: 5| Step: 6
Training loss: 3.2201850414276123
Validation loss: 2.3796707888444266

Epoch: 5| Step: 7
Training loss: 2.8511054515838623
Validation loss: 2.377983828385671

Epoch: 5| Step: 8
Training loss: 2.4875266551971436
Validation loss: 2.3743648131688437

Epoch: 5| Step: 9
Training loss: 2.144535779953003
Validation loss: 2.3739890456199646

Epoch: 5| Step: 10
Training loss: 2.4659101963043213
Validation loss: 2.368404805660248

Epoch: 5| Step: 11
Training loss: 3.208397626876831
Validation loss: 2.3707223584254584

Epoch: 56| Step: 0
Training loss: 2.5595014095306396
Validation loss: 2.3705707589785256

Epoch: 5| Step: 1
Training loss: 2.5781009197235107
Validation loss: 2.3710222442944846

Epoch: 5| Step: 2
Training loss: 2.2866597175598145
Validation loss: 2.3742104868094125

Epoch: 5| Step: 3
Training loss: 2.6249184608459473
Validation loss: 2.361323376496633

Epoch: 5| Step: 4
Training loss: 2.649857997894287
Validation loss: 2.36972339451313

Epoch: 5| Step: 5
Training loss: 2.6187312602996826
Validation loss: 2.3557540575663247

Epoch: 5| Step: 6
Training loss: 2.5843842029571533
Validation loss: 2.347939893603325

Epoch: 5| Step: 7
Training loss: 2.354694366455078
Validation loss: 2.346025307973226

Epoch: 5| Step: 8
Training loss: 2.543092727661133
Validation loss: 2.340574403603872

Epoch: 5| Step: 9
Training loss: 2.5612616539001465
Validation loss: 2.3448932518561683

Epoch: 5| Step: 10
Training loss: 2.4902076721191406
Validation loss: 2.3414837767680488

Epoch: 5| Step: 11
Training loss: 2.239924907684326
Validation loss: 2.3357472717761993

Epoch: 57| Step: 0
Training loss: 2.820958375930786
Validation loss: 2.336051031947136

Epoch: 5| Step: 1
Training loss: 2.348240375518799
Validation loss: 2.3350938111543655

Epoch: 5| Step: 2
Training loss: 2.4583702087402344
Validation loss: 2.3326094349225364

Epoch: 5| Step: 3
Training loss: 2.7598679065704346
Validation loss: 2.334550589323044

Epoch: 5| Step: 4
Training loss: 1.9920463562011719
Validation loss: 2.334639976421992

Epoch: 5| Step: 5
Training loss: 2.693466901779175
Validation loss: 2.331638664007187

Epoch: 5| Step: 6
Training loss: 2.460681438446045
Validation loss: 2.3312976708014808

Epoch: 5| Step: 7
Training loss: 3.031064987182617
Validation loss: 2.327561895052592

Epoch: 5| Step: 8
Training loss: 2.6588454246520996
Validation loss: 2.325085381666819

Epoch: 5| Step: 9
Training loss: 2.1709768772125244
Validation loss: 2.323293924331665

Epoch: 5| Step: 10
Training loss: 2.448986530303955
Validation loss: 2.3199030458927155

Epoch: 5| Step: 11
Training loss: 1.1561028957366943
Validation loss: 2.317481646935145

Epoch: 58| Step: 0
Training loss: 2.0843799114227295
Validation loss: 2.3150167763233185

Epoch: 5| Step: 1
Training loss: 2.625861644744873
Validation loss: 2.3113674571116767

Epoch: 5| Step: 2
Training loss: 2.8090403079986572
Validation loss: 2.3087818125883737

Epoch: 5| Step: 3
Training loss: 2.312699794769287
Validation loss: 2.305519829193751

Epoch: 5| Step: 4
Training loss: 2.534893274307251
Validation loss: 2.300980548063914

Epoch: 5| Step: 5
Training loss: 2.3719513416290283
Validation loss: 2.295834799607595

Epoch: 5| Step: 6
Training loss: 2.225632667541504
Validation loss: 2.2971132894357047

Epoch: 5| Step: 7
Training loss: 2.2554306983947754
Validation loss: 2.292251487572988

Epoch: 5| Step: 8
Training loss: 2.8777875900268555
Validation loss: 2.2907214959462485

Epoch: 5| Step: 9
Training loss: 2.6127562522888184
Validation loss: 2.2855816086133323

Epoch: 5| Step: 10
Training loss: 2.550046443939209
Validation loss: 2.283910016218821

Epoch: 5| Step: 11
Training loss: 2.001431703567505
Validation loss: 2.280821477373441

Epoch: 59| Step: 0
Training loss: 2.9261744022369385
Validation loss: 2.2786807964245477

Epoch: 5| Step: 1
Training loss: 2.8053956031799316
Validation loss: 2.2766947597265244

Epoch: 5| Step: 2
Training loss: 2.0505123138427734
Validation loss: 2.278227304418882

Epoch: 5| Step: 3
Training loss: 2.0260024070739746
Validation loss: 2.2807649026314416

Epoch: 5| Step: 4
Training loss: 1.9953968524932861
Validation loss: 2.285480504234632

Epoch: 5| Step: 5
Training loss: 2.6248202323913574
Validation loss: 2.2877747267484665

Epoch: 5| Step: 6
Training loss: 2.1631689071655273
Validation loss: 2.2842432210842767

Epoch: 5| Step: 7
Training loss: 2.5272841453552246
Validation loss: 2.2732101877530417

Epoch: 5| Step: 8
Training loss: 2.5786123275756836
Validation loss: 2.2668008307615914

Epoch: 5| Step: 9
Training loss: 2.551483631134033
Validation loss: 2.2603076895078025

Epoch: 5| Step: 10
Training loss: 2.5025734901428223
Validation loss: 2.2607684483130774

Epoch: 5| Step: 11
Training loss: 2.667222023010254
Validation loss: 2.258229305346807

Epoch: 60| Step: 0
Training loss: 1.7564833164215088
Validation loss: 2.2611973683039346

Epoch: 5| Step: 1
Training loss: 2.07651948928833
Validation loss: 2.262239178021749

Epoch: 5| Step: 2
Training loss: 3.109076976776123
Validation loss: 2.2648573418458304

Epoch: 5| Step: 3
Training loss: 1.9665447473526
Validation loss: 2.2687891721725464

Epoch: 5| Step: 4
Training loss: 2.507384777069092
Validation loss: 2.271474381287893

Epoch: 5| Step: 5
Training loss: 2.4857916831970215
Validation loss: 2.276562422513962

Epoch: 5| Step: 6
Training loss: 1.9967384338378906
Validation loss: 2.2735258042812347

Epoch: 5| Step: 7
Training loss: 1.982301115989685
Validation loss: 2.2721675833066306

Epoch: 5| Step: 8
Training loss: 3.0157063007354736
Validation loss: 2.269645909468333

Epoch: 5| Step: 9
Training loss: 2.601365804672241
Validation loss: 2.265386313199997

Epoch: 5| Step: 10
Training loss: 3.114098072052002
Validation loss: 2.2613668541113534

Epoch: 5| Step: 11
Training loss: 2.8895883560180664
Validation loss: 2.2544428209463754

Epoch: 61| Step: 0
Training loss: 2.2487645149230957
Validation loss: 2.251578077673912

Epoch: 5| Step: 1
Training loss: 2.3669610023498535
Validation loss: 2.248588596781095

Epoch: 5| Step: 2
Training loss: 2.492750644683838
Validation loss: 2.2442323168118796

Epoch: 5| Step: 3
Training loss: 2.5589003562927246
Validation loss: 2.2425119380156198

Epoch: 5| Step: 4
Training loss: 2.808997392654419
Validation loss: 2.2375056445598602

Epoch: 5| Step: 5
Training loss: 2.0544238090515137
Validation loss: 2.235699196656545

Epoch: 5| Step: 6
Training loss: 2.046525239944458
Validation loss: 2.2330977767705917

Epoch: 5| Step: 7
Training loss: 2.3301825523376465
Validation loss: 2.2290437867244086

Epoch: 5| Step: 8
Training loss: 2.7525253295898438
Validation loss: 2.2234777559836707

Epoch: 5| Step: 9
Training loss: 2.3514368534088135
Validation loss: 2.2217184205849967

Epoch: 5| Step: 10
Training loss: 2.3253884315490723
Validation loss: 2.21821728348732

Epoch: 5| Step: 11
Training loss: 2.5253355503082275
Validation loss: 2.216408148407936

Epoch: 62| Step: 0
Training loss: 3.0981979370117188
Validation loss: 2.212972472111384

Epoch: 5| Step: 1
Training loss: 2.4015612602233887
Validation loss: 2.2101038694381714

Epoch: 5| Step: 2
Training loss: 2.4872355461120605
Validation loss: 2.2092286199331284

Epoch: 5| Step: 3
Training loss: 2.7274155616760254
Validation loss: 2.2037514646848044

Epoch: 5| Step: 4
Training loss: 2.475372076034546
Validation loss: 2.2017833342154822

Epoch: 5| Step: 5
Training loss: 2.1286091804504395
Validation loss: 2.200791130463282

Epoch: 5| Step: 6
Training loss: 2.3638997077941895
Validation loss: 2.1939651568730674

Epoch: 5| Step: 7
Training loss: 2.2025094032287598
Validation loss: 2.1926944802204766

Epoch: 5| Step: 8
Training loss: 1.754224181175232
Validation loss: 2.1962189128001532

Epoch: 5| Step: 9
Training loss: 1.7426369190216064
Validation loss: 2.1902356445789337

Epoch: 5| Step: 10
Training loss: 2.62786865234375
Validation loss: 2.1882664461930594

Epoch: 5| Step: 11
Training loss: 2.122298240661621
Validation loss: 2.1929513812065125

Epoch: 63| Step: 0
Training loss: 2.3841519355773926
Validation loss: 2.201360081632932

Epoch: 5| Step: 1
Training loss: 2.699221134185791
Validation loss: 2.263162856300672

Epoch: 5| Step: 2
Training loss: 2.6533265113830566
Validation loss: 2.310297961036364

Epoch: 5| Step: 3
Training loss: 2.387754201889038
Validation loss: 2.307337537407875

Epoch: 5| Step: 4
Training loss: 2.1387991905212402
Validation loss: 2.285895203550657

Epoch: 5| Step: 5
Training loss: 2.592072010040283
Validation loss: 2.252967288096746

Epoch: 5| Step: 6
Training loss: 2.248654842376709
Validation loss: 2.2379462718963623

Epoch: 5| Step: 7
Training loss: 2.288304090499878
Validation loss: 2.2324966738621392

Epoch: 5| Step: 8
Training loss: 2.2495486736297607
Validation loss: 2.2256815830866494

Epoch: 5| Step: 9
Training loss: 2.9185709953308105
Validation loss: 2.223566621541977

Epoch: 5| Step: 10
Training loss: 2.1037700176239014
Validation loss: 2.220912426710129

Epoch: 5| Step: 11
Training loss: 2.229126453399658
Validation loss: 2.220481922229131

Epoch: 64| Step: 0
Training loss: 2.7123498916625977
Validation loss: 2.224071055650711

Epoch: 5| Step: 1
Training loss: 2.729459285736084
Validation loss: 2.2189707259337106

Epoch: 5| Step: 2
Training loss: 2.2602503299713135
Validation loss: 2.2186968276898065

Epoch: 5| Step: 3
Training loss: 2.763364791870117
Validation loss: 2.2176298995812735

Epoch: 5| Step: 4
Training loss: 2.454927921295166
Validation loss: 2.2146554390589395

Epoch: 5| Step: 5
Training loss: 2.1278398036956787
Validation loss: 2.2153860131899514

Epoch: 5| Step: 6
Training loss: 1.9875562191009521
Validation loss: 2.2143348306417465

Epoch: 5| Step: 7
Training loss: 2.383107900619507
Validation loss: 2.208217203617096

Epoch: 5| Step: 8
Training loss: 1.8553955554962158
Validation loss: 2.2096770803133645

Epoch: 5| Step: 9
Training loss: 2.3900694847106934
Validation loss: 2.205141454935074

Epoch: 5| Step: 10
Training loss: 2.4517712593078613
Validation loss: 2.203437546888987

Epoch: 5| Step: 11
Training loss: 2.358928680419922
Validation loss: 2.201470057169596

Epoch: 65| Step: 0
Training loss: 2.6632332801818848
Validation loss: 2.194770152370135

Epoch: 5| Step: 1
Training loss: 1.3304959535598755
Validation loss: 2.192549059788386

Epoch: 5| Step: 2
Training loss: 2.7632205486297607
Validation loss: 2.1948505292336145

Epoch: 5| Step: 3
Training loss: 2.7208473682403564
Validation loss: 2.1908173809448876

Epoch: 5| Step: 4
Training loss: 2.128416061401367
Validation loss: 2.191262180606524

Epoch: 5| Step: 5
Training loss: 2.5324196815490723
Validation loss: 2.18898539741834

Epoch: 5| Step: 6
Training loss: 2.680121898651123
Validation loss: 2.1923790723085403

Epoch: 5| Step: 7
Training loss: 2.627095937728882
Validation loss: 2.1833696415026984

Epoch: 5| Step: 8
Training loss: 1.9970121383666992
Validation loss: 2.1803085803985596

Epoch: 5| Step: 9
Training loss: 2.1782164573669434
Validation loss: 2.1802449077367783

Epoch: 5| Step: 10
Training loss: 2.293353319168091
Validation loss: 2.1757581929365792

Epoch: 5| Step: 11
Training loss: 1.8970754146575928
Validation loss: 2.1813791394233704

Epoch: 66| Step: 0
Training loss: 2.7338690757751465
Validation loss: 2.173471281925837

Epoch: 5| Step: 1
Training loss: 2.375584125518799
Validation loss: 2.1675676157077155

Epoch: 5| Step: 2
Training loss: 2.3637194633483887
Validation loss: 2.1729281544685364

Epoch: 5| Step: 3
Training loss: 2.1991522312164307
Validation loss: 2.171317552526792

Epoch: 5| Step: 4
Training loss: 2.3580260276794434
Validation loss: 2.1703936209281287

Epoch: 5| Step: 5
Training loss: 2.5695528984069824
Validation loss: 2.1687514781951904

Epoch: 5| Step: 6
Training loss: 2.576093912124634
Validation loss: 2.1664001742998757

Epoch: 5| Step: 7
Training loss: 2.221245288848877
Validation loss: 2.1727649619181952

Epoch: 5| Step: 8
Training loss: 1.8468687534332275
Validation loss: 2.1674369970957437

Epoch: 5| Step: 9
Training loss: 2.318197011947632
Validation loss: 2.1608658879995346

Epoch: 5| Step: 10
Training loss: 2.186082601547241
Validation loss: 2.1550293465455375

Epoch: 5| Step: 11
Training loss: 1.8808228969573975
Validation loss: 2.154813528060913

Epoch: 67| Step: 0
Training loss: 2.6588478088378906
Validation loss: 2.155953665574392

Epoch: 5| Step: 1
Training loss: 2.113368272781372
Validation loss: 2.1478691349426904

Epoch: 5| Step: 2
Training loss: 2.2192044258117676
Validation loss: 2.1474466572205224

Epoch: 5| Step: 3
Training loss: 2.600882053375244
Validation loss: 2.1501156985759735

Epoch: 5| Step: 4
Training loss: 2.0775723457336426
Validation loss: 2.1475758651892343

Epoch: 5| Step: 5
Training loss: 2.515320062637329
Validation loss: 2.1469116657972336

Epoch: 5| Step: 6
Training loss: 2.16259503364563
Validation loss: 2.1446115722258887

Epoch: 5| Step: 7
Training loss: 2.1640477180480957
Validation loss: 2.1489941626787186

Epoch: 5| Step: 8
Training loss: 2.22774076461792
Validation loss: 2.1463535328706107

Epoch: 5| Step: 9
Training loss: 2.29603910446167
Validation loss: 2.1405271192391715

Epoch: 5| Step: 10
Training loss: 2.6799044609069824
Validation loss: 2.1401204566160836

Epoch: 5| Step: 11
Training loss: 0.7886952757835388
Validation loss: 2.1414101670185723

Epoch: 68| Step: 0
Training loss: 2.847219467163086
Validation loss: 2.1292797178030014

Epoch: 5| Step: 1
Training loss: 2.3436381816864014
Validation loss: 2.131511236230532

Epoch: 5| Step: 2
Training loss: 2.321807384490967
Validation loss: 2.1328203678131104

Epoch: 5| Step: 3
Training loss: 2.6812679767608643
Validation loss: 2.1289051920175552

Epoch: 5| Step: 4
Training loss: 2.0145888328552246
Validation loss: 2.1272824108600616

Epoch: 5| Step: 5
Training loss: 2.2269444465637207
Validation loss: 2.127430354555448

Epoch: 5| Step: 6
Training loss: 1.8646259307861328
Validation loss: 2.12673082947731

Epoch: 5| Step: 7
Training loss: 2.4158170223236084
Validation loss: 2.120789592464765

Epoch: 5| Step: 8
Training loss: 2.4865283966064453
Validation loss: 2.1211996525526047

Epoch: 5| Step: 9
Training loss: 1.932546615600586
Validation loss: 2.1196119636297226

Epoch: 5| Step: 10
Training loss: 2.237962007522583
Validation loss: 2.1213463644186654

Epoch: 5| Step: 11
Training loss: 2.1310601234436035
Validation loss: 2.1142310202121735

Epoch: 69| Step: 0
Training loss: 2.4638755321502686
Validation loss: 2.118124688665072

Epoch: 5| Step: 1
Training loss: 2.221628189086914
Validation loss: 2.1145863185326257

Epoch: 5| Step: 2
Training loss: 2.492516040802002
Validation loss: 2.1116007218758264

Epoch: 5| Step: 3
Training loss: 2.0139896869659424
Validation loss: 2.1189431101083755

Epoch: 5| Step: 4
Training loss: 2.047362804412842
Validation loss: 2.121676797668139

Epoch: 5| Step: 5
Training loss: 1.5011659860610962
Validation loss: 2.12359881401062

Epoch: 5| Step: 6
Training loss: 2.5160701274871826
Validation loss: 2.1198517829179764

Epoch: 5| Step: 7
Training loss: 2.363504648208618
Validation loss: 2.1197271198034286

Epoch: 5| Step: 8
Training loss: 2.01509952545166
Validation loss: 2.1147593210140863

Epoch: 5| Step: 9
Training loss: 2.5108180046081543
Validation loss: 2.1133508533239365

Epoch: 5| Step: 10
Training loss: 3.0520997047424316
Validation loss: 2.114335278669993

Epoch: 5| Step: 11
Training loss: 2.2112088203430176
Validation loss: 2.1133189300696054

Epoch: 70| Step: 0
Training loss: 2.3385329246520996
Validation loss: 2.1155454268058143

Epoch: 5| Step: 1
Training loss: 2.621123790740967
Validation loss: 2.113786439100901

Epoch: 5| Step: 2
Training loss: 2.104971408843994
Validation loss: 2.1103959381580353

Epoch: 5| Step: 3
Training loss: 1.9837557077407837
Validation loss: 2.115913212299347

Epoch: 5| Step: 4
Training loss: 2.3555383682250977
Validation loss: 2.108784963687261

Epoch: 5| Step: 5
Training loss: 2.228713035583496
Validation loss: 2.104529728492101

Epoch: 5| Step: 6
Training loss: 2.025630235671997
Validation loss: 2.102768152952194

Epoch: 5| Step: 7
Training loss: 1.9462108612060547
Validation loss: 2.106942728161812

Epoch: 5| Step: 8
Training loss: 2.2156498432159424
Validation loss: 2.1110817342996597

Epoch: 5| Step: 9
Training loss: 3.0304112434387207
Validation loss: 2.125100056330363

Epoch: 5| Step: 10
Training loss: 2.514819383621216
Validation loss: 2.119095871845881

Epoch: 5| Step: 11
Training loss: 0.7816609144210815
Validation loss: 2.1152599106232324

Epoch: 71| Step: 0
Training loss: 1.7266614437103271
Validation loss: 2.1232557694117227

Epoch: 5| Step: 1
Training loss: 2.0123586654663086
Validation loss: 2.156145751476288

Epoch: 5| Step: 2
Training loss: 2.6701714992523193
Validation loss: 2.159056310852369

Epoch: 5| Step: 3
Training loss: 2.29392671585083
Validation loss: 2.1760002970695496

Epoch: 5| Step: 4
Training loss: 2.866565227508545
Validation loss: 2.154637555281321

Epoch: 5| Step: 5
Training loss: 2.4984030723571777
Validation loss: 2.136009802420934

Epoch: 5| Step: 6
Training loss: 1.7627623081207275
Validation loss: 2.113098348180453

Epoch: 5| Step: 7
Training loss: 2.43798565864563
Validation loss: 2.115163038174311

Epoch: 5| Step: 8
Training loss: 2.1560702323913574
Validation loss: 2.1220893363157907

Epoch: 5| Step: 9
Training loss: 2.444793224334717
Validation loss: 2.1235155761241913

Epoch: 5| Step: 10
Training loss: 2.451263427734375
Validation loss: 2.131517931818962

Epoch: 5| Step: 11
Training loss: 3.7195420265197754
Validation loss: 2.1327828665574393

Epoch: 72| Step: 0
Training loss: 2.6339855194091797
Validation loss: 2.132057766119639

Epoch: 5| Step: 1
Training loss: 2.366596221923828
Validation loss: 2.1247263799111047

Epoch: 5| Step: 2
Training loss: 1.5914242267608643
Validation loss: 2.1244524667660394

Epoch: 5| Step: 3
Training loss: 2.3518459796905518
Validation loss: 2.1132746785879135

Epoch: 5| Step: 4
Training loss: 2.0147554874420166
Validation loss: 2.117941533525785

Epoch: 5| Step: 5
Training loss: 2.561880111694336
Validation loss: 2.112847795089086

Epoch: 5| Step: 6
Training loss: 2.0864994525909424
Validation loss: 2.109717220067978

Epoch: 5| Step: 7
Training loss: 2.935433864593506
Validation loss: 2.108415166536967

Epoch: 5| Step: 8
Training loss: 2.0867111682891846
Validation loss: 2.1047497540712357

Epoch: 5| Step: 9
Training loss: 2.427521228790283
Validation loss: 2.107747217019399

Epoch: 5| Step: 10
Training loss: 2.0400378704071045
Validation loss: 2.1021576623121896

Epoch: 5| Step: 11
Training loss: 2.8009705543518066
Validation loss: 2.096385399500529

Epoch: 73| Step: 0
Training loss: 2.0604405403137207
Validation loss: 2.089797869324684

Epoch: 5| Step: 1
Training loss: 2.023733615875244
Validation loss: 2.0896564573049545

Epoch: 5| Step: 2
Training loss: 2.7390878200531006
Validation loss: 2.085522179802259

Epoch: 5| Step: 3
Training loss: 2.6355605125427246
Validation loss: 2.0792753299077353

Epoch: 5| Step: 4
Training loss: 2.46822190284729
Validation loss: 2.081980129082998

Epoch: 5| Step: 5
Training loss: 2.255924701690674
Validation loss: 2.0771124412616095

Epoch: 5| Step: 6
Training loss: 2.263676166534424
Validation loss: 2.0747813880443573

Epoch: 5| Step: 7
Training loss: 2.2679519653320312
Validation loss: 2.0698357174793878

Epoch: 5| Step: 8
Training loss: 1.7962510585784912
Validation loss: 2.0646120458841324

Epoch: 5| Step: 9
Training loss: 2.328381061553955
Validation loss: 2.0677045782407126

Epoch: 5| Step: 10
Training loss: 2.0256094932556152
Validation loss: 2.0648867189884186

Epoch: 5| Step: 11
Training loss: 2.1882283687591553
Validation loss: 2.0613894214232764

Epoch: 74| Step: 0
Training loss: 2.5630712509155273
Validation loss: 2.0594286719957986

Epoch: 5| Step: 1
Training loss: 2.7464423179626465
Validation loss: 2.070416788260142

Epoch: 5| Step: 2
Training loss: 1.8573375940322876
Validation loss: 2.0540496905644736

Epoch: 5| Step: 3
Training loss: 1.745473861694336
Validation loss: 2.055065835515658

Epoch: 5| Step: 4
Training loss: 2.5170562267303467
Validation loss: 2.059110715985298

Epoch: 5| Step: 5
Training loss: 2.2567882537841797
Validation loss: 2.0637834519147873

Epoch: 5| Step: 6
Training loss: 2.263049364089966
Validation loss: 2.05878709256649

Epoch: 5| Step: 7
Training loss: 2.158362627029419
Validation loss: 2.0654411911964417

Epoch: 5| Step: 8
Training loss: 1.9847252368927002
Validation loss: 2.0662665317455926

Epoch: 5| Step: 9
Training loss: 2.4144482612609863
Validation loss: 2.0601400633653006

Epoch: 5| Step: 10
Training loss: 1.9318596124649048
Validation loss: 2.04911399881045

Epoch: 5| Step: 11
Training loss: 3.528794050216675
Validation loss: 2.0577696561813354

Epoch: 75| Step: 0
Training loss: 2.874450206756592
Validation loss: 2.051933800180753

Epoch: 5| Step: 1
Training loss: 1.7107092142105103
Validation loss: 2.0511062840620675

Epoch: 5| Step: 2
Training loss: 2.6871743202209473
Validation loss: 2.051903630296389

Epoch: 5| Step: 3
Training loss: 2.78279185295105
Validation loss: 2.049371192852656

Epoch: 5| Step: 4
Training loss: 1.9634405374526978
Validation loss: 2.0507312268018723

Epoch: 5| Step: 5
Training loss: 2.0007617473602295
Validation loss: 2.0588197310765586

Epoch: 5| Step: 6
Training loss: 1.8492876291275024
Validation loss: 2.051404729485512

Epoch: 5| Step: 7
Training loss: 2.716276168823242
Validation loss: 2.042457660039266

Epoch: 5| Step: 8
Training loss: 2.2093589305877686
Validation loss: 2.0365385562181473

Epoch: 5| Step: 9
Training loss: 1.5685598850250244
Validation loss: 2.033350497484207

Epoch: 5| Step: 10
Training loss: 2.392638683319092
Validation loss: 2.026481121778488

Epoch: 5| Step: 11
Training loss: 1.5924254655838013
Validation loss: 2.0331368992726007

Epoch: 76| Step: 0
Training loss: 2.0503358840942383
Validation loss: 2.0323055535554886

Epoch: 5| Step: 1
Training loss: 2.0342235565185547
Validation loss: 2.0302759061257043

Epoch: 5| Step: 2
Training loss: 2.1213185787200928
Validation loss: 2.0414052108923593

Epoch: 5| Step: 3
Training loss: 1.974887490272522
Validation loss: 2.0414770344893136

Epoch: 5| Step: 4
Training loss: 2.9876813888549805
Validation loss: 2.049873391787211

Epoch: 5| Step: 5
Training loss: 2.1442952156066895
Validation loss: 2.0407145967086158

Epoch: 5| Step: 6
Training loss: 2.4900662899017334
Validation loss: 2.038358837366104

Epoch: 5| Step: 7
Training loss: 1.6753886938095093
Validation loss: 2.0299229472875595

Epoch: 5| Step: 8
Training loss: 2.13712739944458
Validation loss: 2.033628910779953

Epoch: 5| Step: 9
Training loss: 3.079279661178589
Validation loss: 2.039365738630295

Epoch: 5| Step: 10
Training loss: 1.7759872674942017
Validation loss: 2.042310208082199

Epoch: 5| Step: 11
Training loss: 2.351778745651245
Validation loss: 2.0369164596001306

Epoch: 77| Step: 0
Training loss: 2.1101090908050537
Validation loss: 2.038863812883695

Epoch: 5| Step: 1
Training loss: 1.6237446069717407
Validation loss: 2.036217917998632

Epoch: 5| Step: 2
Training loss: 2.513105869293213
Validation loss: 2.0297141522169113

Epoch: 5| Step: 3
Training loss: 2.3241851329803467
Validation loss: 2.025507261355718

Epoch: 5| Step: 4
Training loss: 2.2901806831359863
Validation loss: 2.0261914432048798

Epoch: 5| Step: 5
Training loss: 2.4748857021331787
Validation loss: 2.0297776758670807

Epoch: 5| Step: 6
Training loss: 2.368370532989502
Validation loss: 2.028854469458262

Epoch: 5| Step: 7
Training loss: 2.22691011428833
Validation loss: 2.030119260152181

Epoch: 5| Step: 8
Training loss: 2.071697235107422
Validation loss: 2.0247061947981515

Epoch: 5| Step: 9
Training loss: 2.173457622528076
Validation loss: 2.0274762709935508

Epoch: 5| Step: 10
Training loss: 2.08321213722229
Validation loss: 2.0264981786410012

Epoch: 5| Step: 11
Training loss: 2.612729549407959
Validation loss: 2.027862553795179

Epoch: 78| Step: 0
Training loss: 2.1429476737976074
Validation loss: 2.032555510600408

Epoch: 5| Step: 1
Training loss: 2.3913025856018066
Validation loss: 2.0308168033758798

Epoch: 5| Step: 2
Training loss: 2.2186026573181152
Validation loss: 2.024323652187983

Epoch: 5| Step: 3
Training loss: 2.069857358932495
Validation loss: 2.0304653545220694

Epoch: 5| Step: 4
Training loss: 1.9428703784942627
Validation loss: 2.035799195369085

Epoch: 5| Step: 5
Training loss: 1.8742854595184326
Validation loss: 2.032414694627126

Epoch: 5| Step: 6
Training loss: 1.7629085779190063
Validation loss: 2.0331720113754272

Epoch: 5| Step: 7
Training loss: 2.0699615478515625
Validation loss: 2.026587267716726

Epoch: 5| Step: 8
Training loss: 3.153162956237793
Validation loss: 2.0395522514979043

Epoch: 5| Step: 9
Training loss: 2.628333568572998
Validation loss: 2.0347395290931067

Epoch: 5| Step: 10
Training loss: 2.079293727874756
Validation loss: 2.0307752192020416

Epoch: 5| Step: 11
Training loss: 1.8991845846176147
Validation loss: 2.0327781289815903

Epoch: 79| Step: 0
Training loss: 1.97933828830719
Validation loss: 2.0337790797154107

Epoch: 5| Step: 1
Training loss: 2.3437085151672363
Validation loss: 2.026711647709211

Epoch: 5| Step: 2
Training loss: 2.246379852294922
Validation loss: 2.0369733522335687

Epoch: 5| Step: 3
Training loss: 2.361241102218628
Validation loss: 2.0272882928450904

Epoch: 5| Step: 4
Training loss: 2.1801648139953613
Validation loss: 2.0242587278286615

Epoch: 5| Step: 5
Training loss: 1.9891303777694702
Validation loss: 2.0284666270017624

Epoch: 5| Step: 6
Training loss: 2.214313507080078
Validation loss: 2.0241623322168985

Epoch: 5| Step: 7
Training loss: 2.1201977729797363
Validation loss: 2.0253891746203103

Epoch: 5| Step: 8
Training loss: 2.1978259086608887
Validation loss: 2.0249938666820526

Epoch: 5| Step: 9
Training loss: 2.540567398071289
Validation loss: 2.0230820775032043

Epoch: 5| Step: 10
Training loss: 2.242352247238159
Validation loss: 2.028588811556498

Epoch: 5| Step: 11
Training loss: 1.508183479309082
Validation loss: 2.025270705421766

Epoch: 80| Step: 0
Training loss: 2.53320050239563
Validation loss: 2.0381998916467032

Epoch: 5| Step: 1
Training loss: 1.9754842519760132
Validation loss: 2.0446276466051736

Epoch: 5| Step: 2
Training loss: 2.550658941268921
Validation loss: 2.0368109891812005

Epoch: 5| Step: 3
Training loss: 2.3237733840942383
Validation loss: 2.035845865805944

Epoch: 5| Step: 4
Training loss: 2.3911044597625732
Validation loss: 2.0476480374733605

Epoch: 5| Step: 5
Training loss: 1.9425163269042969
Validation loss: 2.032547657688459

Epoch: 5| Step: 6
Training loss: 2.486609697341919
Validation loss: 2.029193103313446

Epoch: 5| Step: 7
Training loss: 1.5426971912384033
Validation loss: 2.027863552172979

Epoch: 5| Step: 8
Training loss: 1.8351688385009766
Validation loss: 2.0318788091341653

Epoch: 5| Step: 9
Training loss: 2.4690988063812256
Validation loss: 2.032368704676628

Epoch: 5| Step: 10
Training loss: 2.1814982891082764
Validation loss: 2.0286303758621216

Epoch: 5| Step: 11
Training loss: 2.5293304920196533
Validation loss: 2.0256805469592414

Epoch: 81| Step: 0
Training loss: 2.2504265308380127
Validation loss: 2.0240651965141296

Epoch: 5| Step: 1
Training loss: 2.1557528972625732
Validation loss: 2.033678814768791

Epoch: 5| Step: 2
Training loss: 2.3108553886413574
Validation loss: 2.0198516299327216

Epoch: 5| Step: 3
Training loss: 1.6489298343658447
Validation loss: 2.027950639526049

Epoch: 5| Step: 4
Training loss: 2.737269878387451
Validation loss: 2.0268927067518234

Epoch: 5| Step: 5
Training loss: 2.7245283126831055
Validation loss: 2.019099106391271

Epoch: 5| Step: 6
Training loss: 2.0875391960144043
Validation loss: 2.0276418974002204

Epoch: 5| Step: 7
Training loss: 1.778249740600586
Validation loss: 2.0204113175471625

Epoch: 5| Step: 8
Training loss: 2.1844539642333984
Validation loss: 2.0234400779008865

Epoch: 5| Step: 9
Training loss: 1.5756585597991943
Validation loss: 2.0148136963446936

Epoch: 5| Step: 10
Training loss: 2.5726075172424316
Validation loss: 2.0230607986450195

Epoch: 5| Step: 11
Training loss: 2.9412097930908203
Validation loss: 2.017933631936709

Epoch: 82| Step: 0
Training loss: 2.1789238452911377
Validation loss: 2.0187571297089257

Epoch: 5| Step: 1
Training loss: 1.8847780227661133
Validation loss: 2.017265965541204

Epoch: 5| Step: 2
Training loss: 2.333073139190674
Validation loss: 2.016847014427185

Epoch: 5| Step: 3
Training loss: 2.408935546875
Validation loss: 2.0108898977438607

Epoch: 5| Step: 4
Training loss: 1.9755926132202148
Validation loss: 2.015852317214012

Epoch: 5| Step: 5
Training loss: 1.916869878768921
Validation loss: 2.0195408115784326

Epoch: 5| Step: 6
Training loss: 2.310167074203491
Validation loss: 2.0182068844636283

Epoch: 5| Step: 7
Training loss: 2.5271027088165283
Validation loss: 2.019610991080602

Epoch: 5| Step: 8
Training loss: 2.1223361492156982
Validation loss: 2.0212353318929672

Epoch: 5| Step: 9
Training loss: 2.1587326526641846
Validation loss: 2.0205053091049194

Epoch: 5| Step: 10
Training loss: 2.2918009757995605
Validation loss: 2.025078852971395

Epoch: 5| Step: 11
Training loss: 2.093245029449463
Validation loss: 2.0294711341460547

Epoch: 83| Step: 0
Training loss: 2.502251386642456
Validation loss: 2.0088523675998053

Epoch: 5| Step: 1
Training loss: 2.3050405979156494
Validation loss: 2.014595478773117

Epoch: 5| Step: 2
Training loss: 2.5560803413391113
Validation loss: 2.016098439693451

Epoch: 5| Step: 3
Training loss: 2.5782923698425293
Validation loss: 2.0155445287624993

Epoch: 5| Step: 4
Training loss: 2.7697086334228516
Validation loss: 2.022202561299006

Epoch: 5| Step: 5
Training loss: 2.020923614501953
Validation loss: 2.0170004268487296

Epoch: 5| Step: 6
Training loss: 2.1219818592071533
Validation loss: 2.012376695871353

Epoch: 5| Step: 7
Training loss: 1.7832107543945312
Validation loss: 2.0135951141516366

Epoch: 5| Step: 8
Training loss: 1.7471415996551514
Validation loss: 2.0252755184968314

Epoch: 5| Step: 9
Training loss: 1.7884585857391357
Validation loss: 2.0199798991282782

Epoch: 5| Step: 10
Training loss: 1.9659297466278076
Validation loss: 2.0234865248203278

Epoch: 5| Step: 11
Training loss: 1.5832575559616089
Validation loss: 2.023408368229866

Epoch: 84| Step: 0
Training loss: 2.7128310203552246
Validation loss: 2.0148565024137497

Epoch: 5| Step: 1
Training loss: 2.102522373199463
Validation loss: 2.02106074988842

Epoch: 5| Step: 2
Training loss: 2.315798282623291
Validation loss: 2.0201697647571564

Epoch: 5| Step: 3
Training loss: 1.9224246740341187
Validation loss: 2.024468923608462

Epoch: 5| Step: 4
Training loss: 2.1077139377593994
Validation loss: 2.0247583985328674

Epoch: 5| Step: 5
Training loss: 2.363532543182373
Validation loss: 2.0230068316062293

Epoch: 5| Step: 6
Training loss: 2.026505947113037
Validation loss: 2.0307755867640176

Epoch: 5| Step: 7
Training loss: 2.356673240661621
Validation loss: 2.033812955021858

Epoch: 5| Step: 8
Training loss: 2.094722270965576
Validation loss: 2.020745431383451

Epoch: 5| Step: 9
Training loss: 1.770245909690857
Validation loss: 2.023288751641909

Epoch: 5| Step: 10
Training loss: 2.1602745056152344
Validation loss: 2.025371884306272

Epoch: 5| Step: 11
Training loss: 2.9107587337493896
Validation loss: 2.027326246102651

Epoch: 85| Step: 0
Training loss: 2.60058856010437
Validation loss: 2.021743878722191

Epoch: 5| Step: 1
Training loss: 2.2448441982269287
Validation loss: 2.0264335175355277

Epoch: 5| Step: 2
Training loss: 1.410768747329712
Validation loss: 2.0227892895539603

Epoch: 5| Step: 3
Training loss: 1.404320478439331
Validation loss: 2.014550065000852

Epoch: 5| Step: 4
Training loss: 2.114551305770874
Validation loss: 2.022200400630633

Epoch: 5| Step: 5
Training loss: 2.5451722145080566
Validation loss: 2.031360611319542

Epoch: 5| Step: 6
Training loss: 2.7382004261016846
Validation loss: 2.0176833172639212

Epoch: 5| Step: 7
Training loss: 1.7786028385162354
Validation loss: 2.020891413092613

Epoch: 5| Step: 8
Training loss: 2.5391879081726074
Validation loss: 2.0252205530802407

Epoch: 5| Step: 9
Training loss: 2.427816867828369
Validation loss: 2.0191226800282798

Epoch: 5| Step: 10
Training loss: 2.15729022026062
Validation loss: 2.0140784084796906

Epoch: 5| Step: 11
Training loss: 2.3140227794647217
Validation loss: 2.0054679811000824

Epoch: 86| Step: 0
Training loss: 2.283651828765869
Validation loss: 2.010442624489466

Epoch: 5| Step: 1
Training loss: 2.150601863861084
Validation loss: 2.0165333449840546

Epoch: 5| Step: 2
Training loss: 1.9739888906478882
Validation loss: 2.018462007244428

Epoch: 5| Step: 3
Training loss: 2.167229175567627
Validation loss: 2.0146453579266868

Epoch: 5| Step: 4
Training loss: 2.2738404273986816
Validation loss: 2.0208068192005157

Epoch: 5| Step: 5
Training loss: 2.0069141387939453
Validation loss: 2.0231914867957435

Epoch: 5| Step: 6
Training loss: 1.930983304977417
Validation loss: 2.008423795302709

Epoch: 5| Step: 7
Training loss: 2.188476324081421
Validation loss: 2.0102116564909616

Epoch: 5| Step: 8
Training loss: 2.509255886077881
Validation loss: 2.013688420255979

Epoch: 5| Step: 9
Training loss: 2.2971463203430176
Validation loss: 2.0153796474138894

Epoch: 5| Step: 10
Training loss: 2.3365044593811035
Validation loss: 2.008250211675962

Epoch: 5| Step: 11
Training loss: 1.2212412357330322
Validation loss: 2.015128622452418

Epoch: 87| Step: 0
Training loss: 1.8588025569915771
Validation loss: 2.0162006666262946

Epoch: 5| Step: 1
Training loss: 2.0828075408935547
Validation loss: 2.0062177826960883

Epoch: 5| Step: 2
Training loss: 2.290597677230835
Validation loss: 2.01502433915933

Epoch: 5| Step: 3
Training loss: 2.606348752975464
Validation loss: 2.022479678193728

Epoch: 5| Step: 4
Training loss: 2.6194515228271484
Validation loss: 2.0231279333432517

Epoch: 5| Step: 5
Training loss: 1.892356514930725
Validation loss: 2.029660393794378

Epoch: 5| Step: 6
Training loss: 1.852304458618164
Validation loss: 2.0197602013746896

Epoch: 5| Step: 7
Training loss: 2.3793015480041504
Validation loss: 2.024947618444761

Epoch: 5| Step: 8
Training loss: 1.6822597980499268
Validation loss: 2.032250553369522

Epoch: 5| Step: 9
Training loss: 2.510559558868408
Validation loss: 2.0177353968222937

Epoch: 5| Step: 10
Training loss: 2.2754364013671875
Validation loss: 2.021434023976326

Epoch: 5| Step: 11
Training loss: 1.7027987241744995
Validation loss: 2.0175768633683524

Epoch: 88| Step: 0
Training loss: 2.241705894470215
Validation loss: 2.0129344165325165

Epoch: 5| Step: 1
Training loss: 1.909925103187561
Validation loss: 2.0191991478204727

Epoch: 5| Step: 2
Training loss: 2.0669572353363037
Validation loss: 2.01343309879303

Epoch: 5| Step: 3
Training loss: 1.6349903345108032
Validation loss: 2.0174370060364404

Epoch: 5| Step: 4
Training loss: 2.501887559890747
Validation loss: 2.0240421344836554

Epoch: 5| Step: 5
Training loss: 2.172384262084961
Validation loss: 2.022546887397766

Epoch: 5| Step: 6
Training loss: 2.53328275680542
Validation loss: 2.009919280807177

Epoch: 5| Step: 7
Training loss: 1.8537648916244507
Validation loss: 2.0119531800349555

Epoch: 5| Step: 8
Training loss: 2.120434522628784
Validation loss: 2.0114602893590927

Epoch: 5| Step: 9
Training loss: 2.364227533340454
Validation loss: 2.0095391472180686

Epoch: 5| Step: 10
Training loss: 2.5832982063293457
Validation loss: 2.010975480079651

Epoch: 5| Step: 11
Training loss: 2.1046204566955566
Validation loss: 2.0095491260290146

Epoch: 89| Step: 0
Training loss: 1.7005075216293335
Validation loss: 2.0108187596003213

Epoch: 5| Step: 1
Training loss: 2.1683318614959717
Validation loss: 2.017282317082087

Epoch: 5| Step: 2
Training loss: 2.341426372528076
Validation loss: 2.012395679950714

Epoch: 5| Step: 3
Training loss: 2.0854573249816895
Validation loss: 2.0184227327505746

Epoch: 5| Step: 4
Training loss: 2.0938267707824707
Validation loss: 2.0216379314661026

Epoch: 5| Step: 5
Training loss: 2.8392176628112793
Validation loss: 2.0217161575953164

Epoch: 5| Step: 6
Training loss: 2.053041696548462
Validation loss: 2.016638457775116

Epoch: 5| Step: 7
Training loss: 2.3822431564331055
Validation loss: 2.012464761734009

Epoch: 5| Step: 8
Training loss: 2.0887134075164795
Validation loss: 2.008156324426333

Epoch: 5| Step: 9
Training loss: 2.6108784675598145
Validation loss: 2.01135416328907

Epoch: 5| Step: 10
Training loss: 1.3629083633422852
Validation loss: 2.017920176188151

Epoch: 5| Step: 11
Training loss: 3.0005335807800293
Validation loss: 2.0230420331160226

Epoch: 90| Step: 0
Training loss: 2.352966785430908
Validation loss: 2.031159078081449

Epoch: 5| Step: 1
Training loss: 1.86893630027771
Validation loss: 2.0303301165501275

Epoch: 5| Step: 2
Training loss: 2.351402759552002
Validation loss: 2.027263586719831

Epoch: 5| Step: 3
Training loss: 2.3265490531921387
Validation loss: 2.0335661619901657

Epoch: 5| Step: 4
Training loss: 2.044301986694336
Validation loss: 2.0253976384798684

Epoch: 5| Step: 5
Training loss: 1.8478691577911377
Validation loss: 2.0289776821931205

Epoch: 5| Step: 6
Training loss: 2.172297954559326
Validation loss: 2.026173705856005

Epoch: 5| Step: 7
Training loss: 2.052581548690796
Validation loss: 2.026626631617546

Epoch: 5| Step: 8
Training loss: 2.3824760913848877
Validation loss: 2.012603744864464

Epoch: 5| Step: 9
Training loss: 2.218951463699341
Validation loss: 2.0140411158402762

Epoch: 5| Step: 10
Training loss: 2.351121425628662
Validation loss: 2.0140498131513596

Epoch: 5| Step: 11
Training loss: 2.3372960090637207
Validation loss: 2.013086497783661

Epoch: 91| Step: 0
Training loss: 2.467202663421631
Validation loss: 2.0208125859498978

Epoch: 5| Step: 1
Training loss: 2.173727512359619
Validation loss: 2.0227385411659875

Epoch: 5| Step: 2
Training loss: 2.0401649475097656
Validation loss: 2.0302678048610687

Epoch: 5| Step: 3
Training loss: 2.264831781387329
Validation loss: 2.041663487752279

Epoch: 5| Step: 4
Training loss: 2.282024621963501
Validation loss: 2.037690664331118

Epoch: 5| Step: 5
Training loss: 3.0218729972839355
Validation loss: 2.0411569078763327

Epoch: 5| Step: 6
Training loss: 1.6562111377716064
Validation loss: 2.0202109118302665

Epoch: 5| Step: 7
Training loss: 2.5593791007995605
Validation loss: 2.0238670806090036

Epoch: 5| Step: 8
Training loss: 2.2509353160858154
Validation loss: 2.011872554818789

Epoch: 5| Step: 9
Training loss: 1.468563437461853
Validation loss: 2.025085985660553

Epoch: 5| Step: 10
Training loss: 2.0457041263580322
Validation loss: 2.0295493602752686

Epoch: 5| Step: 11
Training loss: 1.317650318145752
Validation loss: 2.033461476365725

Epoch: 92| Step: 0
Training loss: 2.1433253288269043
Validation loss: 2.0321074525515237

Epoch: 5| Step: 1
Training loss: 2.183271884918213
Validation loss: 2.0386085361242294

Epoch: 5| Step: 2
Training loss: 2.413928508758545
Validation loss: 2.0384239554405212

Epoch: 5| Step: 3
Training loss: 2.2203280925750732
Validation loss: 2.0443571358919144

Epoch: 5| Step: 4
Training loss: 2.617081880569458
Validation loss: 2.037911131978035

Epoch: 5| Step: 5
Training loss: 2.424616575241089
Validation loss: 2.0438937743504844

Epoch: 5| Step: 6
Training loss: 1.8134574890136719
Validation loss: 2.0383694022893906

Epoch: 5| Step: 7
Training loss: 2.0715548992156982
Validation loss: 2.0459658851226172

Epoch: 5| Step: 8
Training loss: 2.11877703666687
Validation loss: 2.0406963229179382

Epoch: 5| Step: 9
Training loss: 2.050588846206665
Validation loss: 2.0384047081073127

Epoch: 5| Step: 10
Training loss: 2.351299285888672
Validation loss: 2.0360190669695535

Epoch: 5| Step: 11
Training loss: 2.0077178478240967
Validation loss: 2.0328882187604904

Epoch: 93| Step: 0
Training loss: 2.490021228790283
Validation loss: 2.03732867538929

Epoch: 5| Step: 1
Training loss: 2.3481249809265137
Validation loss: 2.0325601597627005

Epoch: 5| Step: 2
Training loss: 2.06561541557312
Validation loss: 2.0302316695451736

Epoch: 5| Step: 3
Training loss: 2.28753924369812
Validation loss: 2.0239085455735526

Epoch: 5| Step: 4
Training loss: 2.0230371952056885
Validation loss: 2.0269582023223243

Epoch: 5| Step: 5
Training loss: 2.076573610305786
Validation loss: 2.016000285744667

Epoch: 5| Step: 6
Training loss: 2.709853172302246
Validation loss: 2.018125663201014

Epoch: 5| Step: 7
Training loss: 1.9469211101531982
Validation loss: 2.0172797540823617

Epoch: 5| Step: 8
Training loss: 2.279686450958252
Validation loss: 2.021894554297129

Epoch: 5| Step: 9
Training loss: 2.015432834625244
Validation loss: 2.0157518088817596

Epoch: 5| Step: 10
Training loss: 1.645251989364624
Validation loss: 2.025092070301374

Epoch: 5| Step: 11
Training loss: 2.764770030975342
Validation loss: 2.0166231840848923

Epoch: 94| Step: 0
Training loss: 2.241974353790283
Validation loss: 2.0126226345698037

Epoch: 5| Step: 1
Training loss: 2.1381053924560547
Validation loss: 2.010715514421463

Epoch: 5| Step: 2
Training loss: 1.9209461212158203
Validation loss: 2.007306625445684

Epoch: 5| Step: 3
Training loss: 2.753481149673462
Validation loss: 2.0072087397178016

Epoch: 5| Step: 4
Training loss: 1.774131417274475
Validation loss: 2.010340710481008

Epoch: 5| Step: 5
Training loss: 2.1514530181884766
Validation loss: 2.0158670097589493

Epoch: 5| Step: 6
Training loss: 2.1140925884246826
Validation loss: 2.0149951030810676

Epoch: 5| Step: 7
Training loss: 2.7172913551330566
Validation loss: 2.0220431039730706

Epoch: 5| Step: 8
Training loss: 2.2669177055358887
Validation loss: 2.026576121648153

Epoch: 5| Step: 9
Training loss: 2.0044829845428467
Validation loss: 2.0229745904604592

Epoch: 5| Step: 10
Training loss: 2.029454469680786
Validation loss: 2.0275300244490304

Epoch: 5| Step: 11
Training loss: 1.7103633880615234
Validation loss: 2.0183240870634713

Epoch: 95| Step: 0
Training loss: 1.8042638301849365
Validation loss: 2.0170444597800574

Epoch: 5| Step: 1
Training loss: 2.1473143100738525
Validation loss: 2.0161041766405106

Epoch: 5| Step: 2
Training loss: 1.9720633029937744
Validation loss: 2.0106733590364456

Epoch: 5| Step: 3
Training loss: 2.2304577827453613
Validation loss: 2.0057395299275718

Epoch: 5| Step: 4
Training loss: 2.6891942024230957
Validation loss: 2.0057062109311423

Epoch: 5| Step: 5
Training loss: 3.0135879516601562
Validation loss: 2.0046016524235406

Epoch: 5| Step: 6
Training loss: 1.8932478427886963
Validation loss: 2.002137174208959

Epoch: 5| Step: 7
Training loss: 1.838831901550293
Validation loss: 2.0051063100496926

Epoch: 5| Step: 8
Training loss: 2.3579087257385254
Validation loss: 2.0112626552581787

Epoch: 5| Step: 9
Training loss: 1.9383163452148438
Validation loss: 1.9980653127034504

Epoch: 5| Step: 10
Training loss: 2.1095759868621826
Validation loss: 2.0050554871559143

Epoch: 5| Step: 11
Training loss: 2.186798334121704
Validation loss: 2.0026682217915854

Epoch: 96| Step: 0
Training loss: 2.305070400238037
Validation loss: 2.01698100566864

Epoch: 5| Step: 1
Training loss: 2.359196424484253
Validation loss: 2.0234712858994803

Epoch: 5| Step: 2
Training loss: 2.389310359954834
Validation loss: 2.0188517967859902

Epoch: 5| Step: 3
Training loss: 2.4072563648223877
Validation loss: 2.0290329406658807

Epoch: 5| Step: 4
Training loss: 1.9834458827972412
Validation loss: 2.0203457524379096

Epoch: 5| Step: 5
Training loss: 1.8360636234283447
Validation loss: 2.0270837048689523

Epoch: 5| Step: 6
Training loss: 2.2316126823425293
Validation loss: 2.022148331006368

Epoch: 5| Step: 7
Training loss: 1.9241958856582642
Validation loss: 2.0108538965384164

Epoch: 5| Step: 8
Training loss: 2.2013542652130127
Validation loss: 2.01184776922067

Epoch: 5| Step: 9
Training loss: 2.474607467651367
Validation loss: 2.0129759907722473

Epoch: 5| Step: 10
Training loss: 1.848899483680725
Validation loss: 2.0178420394659042

Epoch: 5| Step: 11
Training loss: 2.134702444076538
Validation loss: 2.0227746913830438

Epoch: 97| Step: 0
Training loss: 2.287900447845459
Validation loss: 2.023460919658343

Epoch: 5| Step: 1
Training loss: 2.095379590988159
Validation loss: 2.0289768278598785

Epoch: 5| Step: 2
Training loss: 1.6120504140853882
Validation loss: 2.0332078586022058

Epoch: 5| Step: 3
Training loss: 2.167767286300659
Validation loss: 2.029197876652082

Epoch: 5| Step: 4
Training loss: 2.630730152130127
Validation loss: 2.0334345748027167

Epoch: 5| Step: 5
Training loss: 2.266411304473877
Validation loss: 2.0353605399529138

Epoch: 5| Step: 6
Training loss: 2.0838608741760254
Validation loss: 2.0355794429779053

Epoch: 5| Step: 7
Training loss: 1.967694878578186
Validation loss: 2.033116638660431

Epoch: 5| Step: 8
Training loss: 2.3908779621124268
Validation loss: 2.0378428995609283

Epoch: 5| Step: 9
Training loss: 2.105623245239258
Validation loss: 2.0262089669704437

Epoch: 5| Step: 10
Training loss: 2.3290629386901855
Validation loss: 2.0207592149575553

Epoch: 5| Step: 11
Training loss: 1.822994351387024
Validation loss: 2.0110082427660623

Epoch: 98| Step: 0
Training loss: 2.131732940673828
Validation loss: 2.0067047079404197

Epoch: 5| Step: 1
Training loss: 2.234262704849243
Validation loss: 2.010725220044454

Epoch: 5| Step: 2
Training loss: 2.3196520805358887
Validation loss: 2.0142078896363578

Epoch: 5| Step: 3
Training loss: 2.4400360584259033
Validation loss: 2.015491152803103

Epoch: 5| Step: 4
Training loss: 2.078676223754883
Validation loss: 2.012451469898224

Epoch: 5| Step: 5
Training loss: 2.3007025718688965
Validation loss: 2.015933891137441

Epoch: 5| Step: 6
Training loss: 1.768158197402954
Validation loss: 2.0146176864703498

Epoch: 5| Step: 7
Training loss: 1.9717988967895508
Validation loss: 2.0159595559040704

Epoch: 5| Step: 8
Training loss: 2.0317423343658447
Validation loss: 2.0174200336138406

Epoch: 5| Step: 9
Training loss: 2.2115261554718018
Validation loss: 2.010750929514567

Epoch: 5| Step: 10
Training loss: 2.436286449432373
Validation loss: 2.009560465812683

Epoch: 5| Step: 11
Training loss: 1.9748187065124512
Validation loss: 2.0069815119107566

Epoch: 99| Step: 0
Training loss: 2.0881850719451904
Validation loss: 2.010119597117106

Epoch: 5| Step: 1
Training loss: 2.024801254272461
Validation loss: 2.0065899193286896

Epoch: 5| Step: 2
Training loss: 2.1524293422698975
Validation loss: 2.0044793287913003

Epoch: 5| Step: 3
Training loss: 2.404665470123291
Validation loss: 2.016819084684054

Epoch: 5| Step: 4
Training loss: 2.3921310901641846
Validation loss: 2.0154147148132324

Epoch: 5| Step: 5
Training loss: 2.062420129776001
Validation loss: 2.021521285176277

Epoch: 5| Step: 6
Training loss: 2.882967472076416
Validation loss: 2.0188209066788354

Epoch: 5| Step: 7
Training loss: 2.0203754901885986
Validation loss: 2.014477625489235

Epoch: 5| Step: 8
Training loss: 1.908251166343689
Validation loss: 2.0130026737848916

Epoch: 5| Step: 9
Training loss: 1.995098352432251
Validation loss: 2.01838086048762

Epoch: 5| Step: 10
Training loss: 1.613398790359497
Validation loss: 2.026984602212906

Epoch: 5| Step: 11
Training loss: 2.714250087738037
Validation loss: 2.0160862108071647

Epoch: 100| Step: 0
Training loss: 2.278890609741211
Validation loss: 2.0192640274763107

Epoch: 5| Step: 1
Training loss: 1.8184044361114502
Validation loss: 2.018145943681399

Epoch: 5| Step: 2
Training loss: 2.1893362998962402
Validation loss: 2.0334328611691794

Epoch: 5| Step: 3
Training loss: 1.8126920461654663
Validation loss: 2.0215343832969666

Epoch: 5| Step: 4
Training loss: 2.719269275665283
Validation loss: 2.027645523349444

Epoch: 5| Step: 5
Training loss: 2.2947537899017334
Validation loss: 2.017257183790207

Epoch: 5| Step: 6
Training loss: 2.115724563598633
Validation loss: 2.0341278115908303

Epoch: 5| Step: 7
Training loss: 2.5003576278686523
Validation loss: 2.016091595093409

Epoch: 5| Step: 8
Training loss: 2.357816219329834
Validation loss: 2.030069058140119

Epoch: 5| Step: 9
Training loss: 1.4914394617080688
Validation loss: 2.030182500680288

Epoch: 5| Step: 10
Training loss: 2.1009480953216553
Validation loss: 2.0217166344324746

Epoch: 5| Step: 11
Training loss: 1.9333279132843018
Validation loss: 2.0179625749588013

Epoch: 101| Step: 0
Training loss: 2.1598150730133057
Validation loss: 2.0033531486988068

Epoch: 5| Step: 1
Training loss: 2.019541025161743
Validation loss: 2.0038069089253745

Epoch: 5| Step: 2
Training loss: 2.068948984146118
Validation loss: 2.0139980564514794

Epoch: 5| Step: 3
Training loss: 1.9378101825714111
Validation loss: 2.0125268598397574

Epoch: 5| Step: 4
Training loss: 1.8307815790176392
Validation loss: 2.0223031093676886

Epoch: 5| Step: 5
Training loss: 2.1418333053588867
Validation loss: 2.0162550459305444

Epoch: 5| Step: 6
Training loss: 2.530724287033081
Validation loss: 2.027708739042282

Epoch: 5| Step: 7
Training loss: 1.7765283584594727
Validation loss: 2.0218071937561035

Epoch: 5| Step: 8
Training loss: 2.5276503562927246
Validation loss: 2.0112975984811783

Epoch: 5| Step: 9
Training loss: 2.5169520378112793
Validation loss: 2.012608046332995

Epoch: 5| Step: 10
Training loss: 2.399521589279175
Validation loss: 2.0084710667530694

Epoch: 5| Step: 11
Training loss: 1.988379716873169
Validation loss: 1.9997450510660808

Epoch: 102| Step: 0
Training loss: 1.7521024942398071
Validation loss: 2.002758135398229

Epoch: 5| Step: 1
Training loss: 2.180755853652954
Validation loss: 2.003898079196612

Epoch: 5| Step: 2
Training loss: 2.457487106323242
Validation loss: 2.008978838721911

Epoch: 5| Step: 3
Training loss: 1.7703895568847656
Validation loss: 2.011263221502304

Epoch: 5| Step: 4
Training loss: 1.8758243322372437
Validation loss: 2.0304034849007926

Epoch: 5| Step: 5
Training loss: 2.460355520248413
Validation loss: 2.024340803424517

Epoch: 5| Step: 6
Training loss: 2.283566474914551
Validation loss: 2.0308886716763177

Epoch: 5| Step: 7
Training loss: 1.840907096862793
Validation loss: 2.0213144769271216

Epoch: 5| Step: 8
Training loss: 2.4999732971191406
Validation loss: 2.0215563227732978

Epoch: 5| Step: 9
Training loss: 2.0011072158813477
Validation loss: 2.028507282336553

Epoch: 5| Step: 10
Training loss: 2.552312135696411
Validation loss: 2.0371495435635247

Epoch: 5| Step: 11
Training loss: 2.6333417892456055
Validation loss: 2.015829861164093

Epoch: 103| Step: 0
Training loss: 1.8010971546173096
Validation loss: 2.0153001497189202

Epoch: 5| Step: 1
Training loss: 1.9437404870986938
Validation loss: 2.007005527615547

Epoch: 5| Step: 2
Training loss: 2.371188163757324
Validation loss: 2.0022188623746238

Epoch: 5| Step: 3
Training loss: 2.5434088706970215
Validation loss: 2.0049491226673126

Epoch: 5| Step: 4
Training loss: 2.696476697921753
Validation loss: 2.002957652012507

Epoch: 5| Step: 5
Training loss: 2.1935839653015137
Validation loss: 2.0124484101931253

Epoch: 5| Step: 6
Training loss: 2.223069667816162
Validation loss: 2.009504407644272

Epoch: 5| Step: 7
Training loss: 2.3225340843200684
Validation loss: 2.0129322012265525

Epoch: 5| Step: 8
Training loss: 1.623353362083435
Validation loss: 2.0094032138586044

Epoch: 5| Step: 9
Training loss: 1.860560655593872
Validation loss: 2.0051613996426263

Epoch: 5| Step: 10
Training loss: 2.3949179649353027
Validation loss: 2.0075925141572952

Epoch: 5| Step: 11
Training loss: 0.8244507312774658
Validation loss: 1.9992458422978718

Epoch: 104| Step: 0
Training loss: 2.3395884037017822
Validation loss: 2.0151213804880777

Epoch: 5| Step: 1
Training loss: 2.2878646850585938
Validation loss: 2.0176476339499154

Epoch: 5| Step: 2
Training loss: 2.060220241546631
Validation loss: 2.0251658956209817

Epoch: 5| Step: 3
Training loss: 1.5317394733428955
Validation loss: 2.0256245732307434

Epoch: 5| Step: 4
Training loss: 1.9272044897079468
Validation loss: 2.051341081658999

Epoch: 5| Step: 5
Training loss: 2.537548780441284
Validation loss: 2.0387152979771295

Epoch: 5| Step: 6
Training loss: 2.479907512664795
Validation loss: 2.043382560213407

Epoch: 5| Step: 7
Training loss: 1.8240530490875244
Validation loss: 2.0308644423882165

Epoch: 5| Step: 8
Training loss: 2.594478130340576
Validation loss: 2.035103360811869

Epoch: 5| Step: 9
Training loss: 2.034862518310547
Validation loss: 2.022477075457573

Epoch: 5| Step: 10
Training loss: 1.9793975353240967
Validation loss: 2.0218034585316977

Epoch: 5| Step: 11
Training loss: 2.3406834602355957
Validation loss: 2.027075116833051

Epoch: 105| Step: 0
Training loss: 1.4723353385925293
Validation loss: 2.014793927470843

Epoch: 5| Step: 1
Training loss: 2.175532579421997
Validation loss: 2.0206944743792215

Epoch: 5| Step: 2
Training loss: 2.377246141433716
Validation loss: 2.0077165067195892

Epoch: 5| Step: 3
Training loss: 2.0454647541046143
Validation loss: 2.0126808087031045

Epoch: 5| Step: 4
Training loss: 1.7131128311157227
Validation loss: 2.0068196853001914

Epoch: 5| Step: 5
Training loss: 2.479443073272705
Validation loss: 2.0049804051717124

Epoch: 5| Step: 6
Training loss: 2.7528343200683594
Validation loss: 2.0166668941577277

Epoch: 5| Step: 7
Training loss: 1.9792016744613647
Validation loss: 2.006934573252996

Epoch: 5| Step: 8
Training loss: 2.451951265335083
Validation loss: 2.012530525525411

Epoch: 5| Step: 9
Training loss: 2.1107354164123535
Validation loss: 2.0143976708253226

Epoch: 5| Step: 10
Training loss: 1.9428958892822266
Validation loss: 2.0216312309106192

Epoch: 5| Step: 11
Training loss: 2.40576171875
Validation loss: 2.019490366180738

Epoch: 106| Step: 0
Training loss: 2.319596767425537
Validation loss: 2.0137313405672708

Epoch: 5| Step: 1
Training loss: 1.893479585647583
Validation loss: 2.0164209753274918

Epoch: 5| Step: 2
Training loss: 2.0654616355895996
Validation loss: 2.0120166490475335

Epoch: 5| Step: 3
Training loss: 2.0620832443237305
Validation loss: 2.0133197704950967

Epoch: 5| Step: 4
Training loss: 1.9054079055786133
Validation loss: 2.003941352168719

Epoch: 5| Step: 5
Training loss: 2.267754316329956
Validation loss: 2.005309214194616

Epoch: 5| Step: 6
Training loss: 2.0892281532287598
Validation loss: 2.0111914525429406

Epoch: 5| Step: 7
Training loss: 2.322181224822998
Validation loss: 2.0075314342975616

Epoch: 5| Step: 8
Training loss: 2.2497379779815674
Validation loss: 2.013104021549225

Epoch: 5| Step: 9
Training loss: 2.1745221614837646
Validation loss: 2.0133957117795944

Epoch: 5| Step: 10
Training loss: 2.1557650566101074
Validation loss: 2.0207078754901886

Epoch: 5| Step: 11
Training loss: 2.243656635284424
Validation loss: 2.0218245635430017

Epoch: 107| Step: 0
Training loss: 2.2109503746032715
Validation loss: 2.033415118853251

Epoch: 5| Step: 1
Training loss: 1.4302124977111816
Validation loss: 2.0280908991893134

Epoch: 5| Step: 2
Training loss: 2.1349658966064453
Validation loss: 2.043950860699018

Epoch: 5| Step: 3
Training loss: 1.9743016958236694
Validation loss: 2.050949051976204

Epoch: 5| Step: 4
Training loss: 2.3116588592529297
Validation loss: 2.039555331071218

Epoch: 5| Step: 5
Training loss: 2.451646327972412
Validation loss: 2.0349437842766442

Epoch: 5| Step: 6
Training loss: 2.2499608993530273
Validation loss: 2.0363182028134665

Epoch: 5| Step: 7
Training loss: 2.560960054397583
Validation loss: 2.0212554136912027

Epoch: 5| Step: 8
Training loss: 1.9725993871688843
Validation loss: 2.020844722787539

Epoch: 5| Step: 9
Training loss: 1.9532854557037354
Validation loss: 2.016823023557663

Epoch: 5| Step: 10
Training loss: 2.5948119163513184
Validation loss: 2.018394003311793

Epoch: 5| Step: 11
Training loss: 1.632576584815979
Validation loss: 2.013272816936175

Epoch: 108| Step: 0
Training loss: 2.286674976348877
Validation loss: 2.0055767595767975

Epoch: 5| Step: 1
Training loss: 2.152653217315674
Validation loss: 2.0002925197283425

Epoch: 5| Step: 2
Training loss: 1.7535520792007446
Validation loss: 2.001751035451889

Epoch: 5| Step: 3
Training loss: 2.2142086029052734
Validation loss: 2.0043477366367974

Epoch: 5| Step: 4
Training loss: 2.244659423828125
Validation loss: 2.0154448797305426

Epoch: 5| Step: 5
Training loss: 2.1183481216430664
Validation loss: 2.0110756903886795

Epoch: 5| Step: 6
Training loss: 2.4427387714385986
Validation loss: 2.004243219892184

Epoch: 5| Step: 7
Training loss: 2.2760672569274902
Validation loss: 2.0077243745326996

Epoch: 5| Step: 8
Training loss: 1.8527024984359741
Validation loss: 2.0062335729599

Epoch: 5| Step: 9
Training loss: 2.2660343647003174
Validation loss: 1.999452734986941

Epoch: 5| Step: 10
Training loss: 2.1489593982696533
Validation loss: 2.0025987774133682

Epoch: 5| Step: 11
Training loss: 1.623038411140442
Validation loss: 2.0158148060242334

Epoch: 109| Step: 0
Training loss: 1.6600719690322876
Validation loss: 2.012171263496081

Epoch: 5| Step: 1
Training loss: 2.090668201446533
Validation loss: 2.0091968973477683

Epoch: 5| Step: 2
Training loss: 1.925966501235962
Validation loss: 2.0038454880317054

Epoch: 5| Step: 3
Training loss: 2.2565178871154785
Validation loss: 2.0065886676311493

Epoch: 5| Step: 4
Training loss: 2.3274097442626953
Validation loss: 2.012508283058802

Epoch: 5| Step: 5
Training loss: 2.4719746112823486
Validation loss: 2.026108125845591

Epoch: 5| Step: 6
Training loss: 2.245553970336914
Validation loss: 2.020961826046308

Epoch: 5| Step: 7
Training loss: 2.2565274238586426
Validation loss: 2.031258702278137

Epoch: 5| Step: 8
Training loss: 2.5648903846740723
Validation loss: 2.023542876044909

Epoch: 5| Step: 9
Training loss: 2.080570697784424
Validation loss: 2.0189207196235657

Epoch: 5| Step: 10
Training loss: 1.6121772527694702
Validation loss: 2.008671020468076

Epoch: 5| Step: 11
Training loss: 1.8532049655914307
Validation loss: 2.017852599422137

Epoch: 110| Step: 0
Training loss: 1.5558178424835205
Validation loss: 2.010555475950241

Epoch: 5| Step: 1
Training loss: 2.5941293239593506
Validation loss: 2.0154426246881485

Epoch: 5| Step: 2
Training loss: 2.1636178493499756
Validation loss: 2.0116446564594903

Epoch: 5| Step: 3
Training loss: 2.2658963203430176
Validation loss: 2.009743129213651

Epoch: 5| Step: 4
Training loss: 2.473623752593994
Validation loss: 2.0136753022670746

Epoch: 5| Step: 5
Training loss: 1.997222900390625
Validation loss: 2.011839836835861

Epoch: 5| Step: 6
Training loss: 1.8620274066925049
Validation loss: 2.0175989866256714

Epoch: 5| Step: 7
Training loss: 2.423966884613037
Validation loss: 2.0212197999159494

Epoch: 5| Step: 8
Training loss: 2.2740092277526855
Validation loss: 2.0240769336620965

Epoch: 5| Step: 9
Training loss: 2.161440849304199
Validation loss: 2.0139948228995004

Epoch: 5| Step: 10
Training loss: 1.6060590744018555
Validation loss: 2.0140560269355774

Epoch: 5| Step: 11
Training loss: 2.3350753784179688
Validation loss: 2.023771663506826

Epoch: 111| Step: 0
Training loss: 2.29203462600708
Validation loss: 2.0194114645322165

Epoch: 5| Step: 1
Training loss: 2.0274767875671387
Validation loss: 2.021700903773308

Epoch: 5| Step: 2
Training loss: 2.167571544647217
Validation loss: 2.023966828982035

Epoch: 5| Step: 3
Training loss: 2.119442939758301
Validation loss: 2.0178900162378945

Epoch: 5| Step: 4
Training loss: 2.0245213508605957
Validation loss: 2.0148534029722214

Epoch: 5| Step: 5
Training loss: 2.2133915424346924
Validation loss: 2.0083966900904975

Epoch: 5| Step: 6
Training loss: 2.0318093299865723
Validation loss: 2.0060366143782935

Epoch: 5| Step: 7
Training loss: 1.6325428485870361
Validation loss: 2.0056111961603165

Epoch: 5| Step: 8
Training loss: 2.3271684646606445
Validation loss: 2.004739676912626

Epoch: 5| Step: 9
Training loss: 2.448683977127075
Validation loss: 2.0035049269596734

Epoch: 5| Step: 10
Training loss: 2.1585707664489746
Validation loss: 2.0097816487153373

Epoch: 5| Step: 11
Training loss: 2.3807010650634766
Validation loss: 2.008959690729777

Epoch: 112| Step: 0
Training loss: 2.0259127616882324
Validation loss: 2.010991647839546

Epoch: 5| Step: 1
Training loss: 2.0108096599578857
Validation loss: 2.0096579243739447

Epoch: 5| Step: 2
Training loss: 1.770249605178833
Validation loss: 2.01312289138635

Epoch: 5| Step: 3
Training loss: 2.152568817138672
Validation loss: 2.0140540848175683

Epoch: 5| Step: 4
Training loss: 1.9606949090957642
Validation loss: 2.014340271552404

Epoch: 5| Step: 5
Training loss: 2.2560675144195557
Validation loss: 2.0202340881029763

Epoch: 5| Step: 6
Training loss: 2.0619490146636963
Validation loss: 2.011767183740934

Epoch: 5| Step: 7
Training loss: 2.548367500305176
Validation loss: 2.0232431391874948

Epoch: 5| Step: 8
Training loss: 2.7894105911254883
Validation loss: 2.0156120508909225

Epoch: 5| Step: 9
Training loss: 1.646304726600647
Validation loss: 2.0171317557493844

Epoch: 5| Step: 10
Training loss: 2.311917781829834
Validation loss: 2.0289298593997955

Epoch: 5| Step: 11
Training loss: 2.3871076107025146
Validation loss: 2.0241902420918145

Epoch: 113| Step: 0
Training loss: 2.2582802772521973
Validation loss: 2.0218338121970496

Epoch: 5| Step: 1
Training loss: 2.0179905891418457
Validation loss: 2.026159147421519

Epoch: 5| Step: 2
Training loss: 1.9660221338272095
Validation loss: 2.0248026748498282

Epoch: 5| Step: 3
Training loss: 1.937119483947754
Validation loss: 2.019415477911631

Epoch: 5| Step: 4
Training loss: 2.025343418121338
Validation loss: 2.0173824528853097

Epoch: 5| Step: 5
Training loss: 2.4068145751953125
Validation loss: 2.013650675614675

Epoch: 5| Step: 6
Training loss: 1.9110558032989502
Validation loss: 2.0072346379359565

Epoch: 5| Step: 7
Training loss: 1.919966459274292
Validation loss: 2.005330428481102

Epoch: 5| Step: 8
Training loss: 2.1536171436309814
Validation loss: 2.0147343973318734

Epoch: 5| Step: 9
Training loss: 2.172694206237793
Validation loss: 2.019003455837568

Epoch: 5| Step: 10
Training loss: 2.4903669357299805
Validation loss: 2.019503504037857

Epoch: 5| Step: 11
Training loss: 2.7807891368865967
Validation loss: 2.006534015138944

Epoch: 114| Step: 0
Training loss: 1.9412453174591064
Validation loss: 2.0098612308502197

Epoch: 5| Step: 1
Training loss: 2.276862621307373
Validation loss: 2.016453648606936

Epoch: 5| Step: 2
Training loss: 2.381798028945923
Validation loss: 2.0178577502568564

Epoch: 5| Step: 3
Training loss: 1.393811583518982
Validation loss: 2.012961665789286

Epoch: 5| Step: 4
Training loss: 1.7930433750152588
Validation loss: 2.020768110950788

Epoch: 5| Step: 5
Training loss: 1.8033565282821655
Validation loss: 2.0141184081633887

Epoch: 5| Step: 6
Training loss: 2.0706164836883545
Validation loss: 2.023309886455536

Epoch: 5| Step: 7
Training loss: 2.218410015106201
Validation loss: 2.012305368979772

Epoch: 5| Step: 8
Training loss: 2.6949963569641113
Validation loss: 2.0074796080589294

Epoch: 5| Step: 9
Training loss: 2.361483097076416
Validation loss: 2.0038180500268936

Epoch: 5| Step: 10
Training loss: 2.558417558670044
Validation loss: 2.0047063529491425

Epoch: 5| Step: 11
Training loss: 1.413497805595398
Validation loss: 2.0030506501595178

Epoch: 115| Step: 0
Training loss: 2.1855416297912598
Validation loss: 2.00594532986482

Epoch: 5| Step: 1
Training loss: 1.9686921834945679
Validation loss: 2.0027818183104196

Epoch: 5| Step: 2
Training loss: 1.8066688776016235
Validation loss: 2.0119664867719016

Epoch: 5| Step: 3
Training loss: 2.097630023956299
Validation loss: 2.0105195144812265

Epoch: 5| Step: 4
Training loss: 2.3662009239196777
Validation loss: 2.0070104797681174

Epoch: 5| Step: 5
Training loss: 1.9316003322601318
Validation loss: 2.0079843600591025

Epoch: 5| Step: 6
Training loss: 2.1781458854675293
Validation loss: 2.0081149439016976

Epoch: 5| Step: 7
Training loss: 2.1896605491638184
Validation loss: 2.006487866242727

Epoch: 5| Step: 8
Training loss: 2.2446815967559814
Validation loss: 2.013122866551081

Epoch: 5| Step: 9
Training loss: 2.1753878593444824
Validation loss: 2.004674047231674

Epoch: 5| Step: 10
Training loss: 2.1808738708496094
Validation loss: 2.014331633845965

Epoch: 5| Step: 11
Training loss: 2.9624581336975098
Validation loss: 2.024109517534574

Epoch: 116| Step: 0
Training loss: 2.4586617946624756
Validation loss: 2.0257529566685357

Epoch: 5| Step: 1
Training loss: 1.9328320026397705
Validation loss: 2.0258204539616904

Epoch: 5| Step: 2
Training loss: 1.648463249206543
Validation loss: 2.0312637935082116

Epoch: 5| Step: 3
Training loss: 2.1693115234375
Validation loss: 2.0238687892754874

Epoch: 5| Step: 4
Training loss: 1.7913614511489868
Validation loss: 2.022795890768369

Epoch: 5| Step: 5
Training loss: 1.785154104232788
Validation loss: 2.0173045297463736

Epoch: 5| Step: 6
Training loss: 1.797428846359253
Validation loss: 2.008350044488907

Epoch: 5| Step: 7
Training loss: 2.5533628463745117
Validation loss: 2.003736769159635

Epoch: 5| Step: 8
Training loss: 2.3355488777160645
Validation loss: 2.0013515998919806

Epoch: 5| Step: 9
Training loss: 2.363504648208618
Validation loss: 2.00236784418424

Epoch: 5| Step: 10
Training loss: 2.6902661323547363
Validation loss: 2.0099684993426004

Epoch: 5| Step: 11
Training loss: 1.5030359029769897
Validation loss: 1.9968221783638

Epoch: 117| Step: 0
Training loss: 2.1873202323913574
Validation loss: 1.998058333992958

Epoch: 5| Step: 1
Training loss: 2.322662353515625
Validation loss: 2.018041287859281

Epoch: 5| Step: 2
Training loss: 2.2098920345306396
Validation loss: 2.0212791661421456

Epoch: 5| Step: 3
Training loss: 1.6141093969345093
Validation loss: 2.017992854118347

Epoch: 5| Step: 4
Training loss: 2.4187984466552734
Validation loss: 2.043084035317103

Epoch: 5| Step: 5
Training loss: 2.537848711013794
Validation loss: 2.039881100257238

Epoch: 5| Step: 6
Training loss: 2.0303449630737305
Validation loss: 2.02797960738341

Epoch: 5| Step: 7
Training loss: 2.100058078765869
Validation loss: 2.012867197394371

Epoch: 5| Step: 8
Training loss: 1.9876091480255127
Validation loss: 2.006050611535708

Epoch: 5| Step: 9
Training loss: 2.5417447090148926
Validation loss: 2.0167774508396783

Epoch: 5| Step: 10
Training loss: 1.5010770559310913
Validation loss: 2.0170696675777435

Epoch: 5| Step: 11
Training loss: 2.219139575958252
Validation loss: 1.997848466038704

Epoch: 118| Step: 0
Training loss: 1.9950624704360962
Validation loss: 1.9984509199857712

Epoch: 5| Step: 1
Training loss: 2.0670104026794434
Validation loss: 1.9973736902077992

Epoch: 5| Step: 2
Training loss: 2.3251452445983887
Validation loss: 2.0080839097499847

Epoch: 5| Step: 3
Training loss: 1.9949235916137695
Validation loss: 2.013518547018369

Epoch: 5| Step: 4
Training loss: 2.4847216606140137
Validation loss: 2.0210271229346595

Epoch: 5| Step: 5
Training loss: 2.6478397846221924
Validation loss: 2.0220363636811576

Epoch: 5| Step: 6
Training loss: 2.179769992828369
Validation loss: 2.0170376847187677

Epoch: 5| Step: 7
Training loss: 1.858498215675354
Validation loss: 2.0152334918578467

Epoch: 5| Step: 8
Training loss: 1.8850771188735962
Validation loss: 2.012977381547292

Epoch: 5| Step: 9
Training loss: 2.148892402648926
Validation loss: 2.0197215725978217

Epoch: 5| Step: 10
Training loss: 2.1665310859680176
Validation loss: 2.0082405457894006

Epoch: 5| Step: 11
Training loss: 2.236876964569092
Validation loss: 2.0070477028687796

Epoch: 119| Step: 0
Training loss: 1.5705443620681763
Validation loss: 2.001231849193573

Epoch: 5| Step: 1
Training loss: 2.1023430824279785
Validation loss: 1.9992806911468506

Epoch: 5| Step: 2
Training loss: 2.4772419929504395
Validation loss: 1.997386857867241

Epoch: 5| Step: 3
Training loss: 1.7576196193695068
Validation loss: 1.9964094559351604

Epoch: 5| Step: 4
Training loss: 1.821768045425415
Validation loss: 2.0025138358275094

Epoch: 5| Step: 5
Training loss: 2.1737325191497803
Validation loss: 2.0094488064448037

Epoch: 5| Step: 6
Training loss: 2.3921151161193848
Validation loss: 2.0385213692982993

Epoch: 5| Step: 7
Training loss: 1.8171088695526123
Validation loss: 2.0391097168127694

Epoch: 5| Step: 8
Training loss: 2.4519877433776855
Validation loss: 2.060135076443354

Epoch: 5| Step: 9
Training loss: 2.226527452468872
Validation loss: 2.0655230234066644

Epoch: 5| Step: 10
Training loss: 2.8880176544189453
Validation loss: 2.0546183536450067

Epoch: 5| Step: 11
Training loss: 3.5057930946350098
Validation loss: 2.05904313425223

Epoch: 120| Step: 0
Training loss: 1.591012954711914
Validation loss: 2.0246065159638724

Epoch: 5| Step: 1
Training loss: 2.3451905250549316
Validation loss: 2.0041278898715973

Epoch: 5| Step: 2
Training loss: 2.1217703819274902
Validation loss: 2.0051578283309937

Epoch: 5| Step: 3
Training loss: 2.162949562072754
Validation loss: 1.9990208446979523

Epoch: 5| Step: 4
Training loss: 2.039048671722412
Validation loss: 2.006009891629219

Epoch: 5| Step: 5
Training loss: 2.0115933418273926
Validation loss: 1.996308629711469

Epoch: 5| Step: 6
Training loss: 1.9721136093139648
Validation loss: 2.0008206963539124

Epoch: 5| Step: 7
Training loss: 1.9664205312728882
Validation loss: 2.0024158358573914

Epoch: 5| Step: 8
Training loss: 2.2483294010162354
Validation loss: 2.006229196985563

Epoch: 5| Step: 9
Training loss: 2.2980780601501465
Validation loss: 2.003615622719129

Epoch: 5| Step: 10
Training loss: 2.6953136920928955
Validation loss: 2.0104604164759317

Epoch: 5| Step: 11
Training loss: 1.883410096168518
Validation loss: 2.0069357057412467

Epoch: 121| Step: 0
Training loss: 1.8780437707901
Validation loss: 2.0042976289987564

Epoch: 5| Step: 1
Training loss: 2.2409090995788574
Validation loss: 2.000114932656288

Epoch: 5| Step: 2
Training loss: 2.2655818462371826
Validation loss: 1.9956834415594737

Epoch: 5| Step: 3
Training loss: 2.0447630882263184
Validation loss: 1.9873098780711491

Epoch: 5| Step: 4
Training loss: 1.979697585105896
Validation loss: 2.005355770389239

Epoch: 5| Step: 5
Training loss: 2.6737987995147705
Validation loss: 1.9990483125050862

Epoch: 5| Step: 6
Training loss: 2.4412178993225098
Validation loss: 2.0014265278975167

Epoch: 5| Step: 7
Training loss: 1.8066107034683228
Validation loss: 1.9933745016654332

Epoch: 5| Step: 8
Training loss: 2.42695689201355
Validation loss: 1.9972175310055416

Epoch: 5| Step: 9
Training loss: 1.846993088722229
Validation loss: 2.00554388264815

Epoch: 5| Step: 10
Training loss: 1.716071367263794
Validation loss: 2.005712072054545

Epoch: 5| Step: 11
Training loss: 2.660367250442505
Validation loss: 2.0016570587952933

Epoch: 122| Step: 0
Training loss: 2.045743465423584
Validation loss: 2.0103520105282464

Epoch: 5| Step: 1
Training loss: 2.0556674003601074
Validation loss: 1.9995325555404027

Epoch: 5| Step: 2
Training loss: 2.4553303718566895
Validation loss: 1.999802480141322

Epoch: 5| Step: 3
Training loss: 2.358153820037842
Validation loss: 1.9984346131483715

Epoch: 5| Step: 4
Training loss: 2.2416534423828125
Validation loss: 2.00446480512619

Epoch: 5| Step: 5
Training loss: 1.7974653244018555
Validation loss: 1.9980567942063014

Epoch: 5| Step: 6
Training loss: 2.0122456550598145
Validation loss: 2.0005106925964355

Epoch: 5| Step: 7
Training loss: 1.8094104528427124
Validation loss: 1.9996586988369625

Epoch: 5| Step: 8
Training loss: 2.0569779872894287
Validation loss: 1.9966686765352886

Epoch: 5| Step: 9
Training loss: 2.011671781539917
Validation loss: 2.0120530327161155

Epoch: 5| Step: 10
Training loss: 2.512126922607422
Validation loss: 2.0006821751594543

Epoch: 5| Step: 11
Training loss: 1.3340773582458496
Validation loss: 2.00197567542394

Epoch: 123| Step: 0
Training loss: 1.6237941980361938
Validation loss: 2.0016348908344903

Epoch: 5| Step: 1
Training loss: 1.9489425420761108
Validation loss: 2.0009311636288962

Epoch: 5| Step: 2
Training loss: 2.5559628009796143
Validation loss: 2.005052149295807

Epoch: 5| Step: 3
Training loss: 2.1793880462646484
Validation loss: 2.010270540912946

Epoch: 5| Step: 4
Training loss: 1.7594716548919678
Validation loss: 2.0011384089787803

Epoch: 5| Step: 5
Training loss: 2.6098287105560303
Validation loss: 2.016479507088661

Epoch: 5| Step: 6
Training loss: 2.4226057529449463
Validation loss: 2.0054119477669397

Epoch: 5| Step: 7
Training loss: 2.0676608085632324
Validation loss: 2.0152443846066794

Epoch: 5| Step: 8
Training loss: 1.899797797203064
Validation loss: 2.0131420294443765

Epoch: 5| Step: 9
Training loss: 1.9540656805038452
Validation loss: 1.99605593085289

Epoch: 5| Step: 10
Training loss: 2.328824520111084
Validation loss: 1.9930376261472702

Epoch: 5| Step: 11
Training loss: 1.530285358428955
Validation loss: 1.9977667331695557

Epoch: 124| Step: 0
Training loss: 1.979882001876831
Validation loss: 2.0066145906845727

Epoch: 5| Step: 1
Training loss: 2.595457077026367
Validation loss: 2.00510935485363

Epoch: 5| Step: 2
Training loss: 1.807794213294983
Validation loss: 2.0127311646938324

Epoch: 5| Step: 3
Training loss: 1.8196769952774048
Validation loss: 2.0065838346878686

Epoch: 5| Step: 4
Training loss: 2.1249611377716064
Validation loss: 2.0096267660458884

Epoch: 5| Step: 5
Training loss: 2.5998806953430176
Validation loss: 2.007384637991587

Epoch: 5| Step: 6
Training loss: 1.8569473028182983
Validation loss: 2.0076430638631186

Epoch: 5| Step: 7
Training loss: 2.110400438308716
Validation loss: 2.0170326630274453

Epoch: 5| Step: 8
Training loss: 2.143899440765381
Validation loss: 2.013722851872444

Epoch: 5| Step: 9
Training loss: 2.350189685821533
Validation loss: 2.007894520958265

Epoch: 5| Step: 10
Training loss: 2.2612478733062744
Validation loss: 2.013065829873085

Epoch: 5| Step: 11
Training loss: 0.7802183628082275
Validation loss: 2.011783147851626

Epoch: 125| Step: 0
Training loss: 2.1060500144958496
Validation loss: 2.01716078321139

Epoch: 5| Step: 1
Training loss: 2.411935329437256
Validation loss: 2.017064074675242

Epoch: 5| Step: 2
Training loss: 2.276207447052002
Validation loss: 2.016214152177175

Epoch: 5| Step: 3
Training loss: 1.852349042892456
Validation loss: 2.0191825379927955

Epoch: 5| Step: 4
Training loss: 1.8571189641952515
Validation loss: 2.019021679957708

Epoch: 5| Step: 5
Training loss: 2.22515869140625
Validation loss: 2.017497718334198

Epoch: 5| Step: 6
Training loss: 2.599097728729248
Validation loss: 2.0122917890548706

Epoch: 5| Step: 7
Training loss: 2.235058546066284
Validation loss: 2.0147071182727814

Epoch: 5| Step: 8
Training loss: 2.0819993019104004
Validation loss: 2.0190096447865167

Epoch: 5| Step: 9
Training loss: 1.3952927589416504
Validation loss: 2.0137443592151008

Epoch: 5| Step: 10
Training loss: 2.2383923530578613
Validation loss: 2.0259763995806375

Epoch: 5| Step: 11
Training loss: 1.3360798358917236
Validation loss: 2.0134820292393365

Epoch: 126| Step: 0
Training loss: 1.853581190109253
Validation loss: 2.0117535094420114

Epoch: 5| Step: 1
Training loss: 1.584212064743042
Validation loss: 2.0182267328103385

Epoch: 5| Step: 2
Training loss: 2.3605659008026123
Validation loss: 2.0191478927930198

Epoch: 5| Step: 3
Training loss: 2.185084342956543
Validation loss: 2.01817025244236

Epoch: 5| Step: 4
Training loss: 2.445247173309326
Validation loss: 2.024981518586477

Epoch: 5| Step: 5
Training loss: 1.9648059606552124
Validation loss: 2.012168601155281

Epoch: 5| Step: 6
Training loss: 2.384160280227661
Validation loss: 2.006184861063957

Epoch: 5| Step: 7
Training loss: 2.544712543487549
Validation loss: 2.0220038493474326

Epoch: 5| Step: 8
Training loss: 1.5809943675994873
Validation loss: 2.0255493372678757

Epoch: 5| Step: 9
Training loss: 2.338000774383545
Validation loss: 2.0139038463433585

Epoch: 5| Step: 10
Training loss: 1.6895902156829834
Validation loss: 2.011093889673551

Epoch: 5| Step: 11
Training loss: 2.9276390075683594
Validation loss: 2.028082783023516

Epoch: 127| Step: 0
Training loss: 1.7153337001800537
Validation loss: 2.0181830525398254

Epoch: 5| Step: 1
Training loss: 2.2306933403015137
Validation loss: 2.020008236169815

Epoch: 5| Step: 2
Training loss: 1.8292453289031982
Validation loss: 2.029408281048139

Epoch: 5| Step: 3
Training loss: 2.3453361988067627
Validation loss: 2.0282051811615625

Epoch: 5| Step: 4
Training loss: 2.3004872798919678
Validation loss: 2.006801664829254

Epoch: 5| Step: 5
Training loss: 2.324021577835083
Validation loss: 2.015283783276876

Epoch: 5| Step: 6
Training loss: 2.0004043579101562
Validation loss: 2.0207840502262115

Epoch: 5| Step: 7
Training loss: 1.8257560729980469
Validation loss: 2.0221212059259415

Epoch: 5| Step: 8
Training loss: 2.525588274002075
Validation loss: 2.0213501254717507

Epoch: 5| Step: 9
Training loss: 1.994576096534729
Validation loss: 2.015483170747757

Epoch: 5| Step: 10
Training loss: 2.482943534851074
Validation loss: 2.0155425320068994

Epoch: 5| Step: 11
Training loss: 1.2095201015472412
Validation loss: 2.0158669501543045

Epoch: 128| Step: 0
Training loss: 2.027522325515747
Validation loss: 2.022176826993624

Epoch: 5| Step: 1
Training loss: 2.2696633338928223
Validation loss: 2.016071101029714

Epoch: 5| Step: 2
Training loss: 1.7438938617706299
Validation loss: 2.0158063719669976

Epoch: 5| Step: 3
Training loss: 2.0548689365386963
Validation loss: 2.0177495976289115

Epoch: 5| Step: 4
Training loss: 2.2788805961608887
Validation loss: 2.0224204709132514

Epoch: 5| Step: 5
Training loss: 2.0803215503692627
Validation loss: 2.023023009300232

Epoch: 5| Step: 6
Training loss: 1.7561581134796143
Validation loss: 2.033179526527723

Epoch: 5| Step: 7
Training loss: 2.142387866973877
Validation loss: 2.024247402946154

Epoch: 5| Step: 8
Training loss: 2.5614733695983887
Validation loss: 2.029226923982302

Epoch: 5| Step: 9
Training loss: 2.787914991378784
Validation loss: 2.032407214244207

Epoch: 5| Step: 10
Training loss: 2.103823184967041
Validation loss: 2.0275560369094214

Epoch: 5| Step: 11
Training loss: 0.48581621050834656
Validation loss: 2.0268100102742515

Epoch: 129| Step: 0
Training loss: 2.019482135772705
Validation loss: 2.0205136040846505

Epoch: 5| Step: 1
Training loss: 1.949448823928833
Validation loss: 2.0226623564958572

Epoch: 5| Step: 2
Training loss: 1.909069299697876
Validation loss: 2.0302647749582925

Epoch: 5| Step: 3
Training loss: 2.361900806427002
Validation loss: 2.0199360698461533

Epoch: 5| Step: 4
Training loss: 2.1557040214538574
Validation loss: 2.017347206672033

Epoch: 5| Step: 5
Training loss: 2.2670693397521973
Validation loss: 2.017252877354622

Epoch: 5| Step: 6
Training loss: 2.0468997955322266
Validation loss: 2.008111740152041

Epoch: 5| Step: 7
Training loss: 2.551976442337036
Validation loss: 2.018574963013331

Epoch: 5| Step: 8
Training loss: 1.6589733362197876
Validation loss: 2.015648201107979

Epoch: 5| Step: 9
Training loss: 1.887730360031128
Validation loss: 2.0171208878358207

Epoch: 5| Step: 10
Training loss: 2.2631442546844482
Validation loss: 2.0207227567831674

Epoch: 5| Step: 11
Training loss: 3.5491433143615723
Validation loss: 2.0152532209952674

Epoch: 130| Step: 0
Training loss: 2.3570456504821777
Validation loss: 2.0203725695610046

Epoch: 5| Step: 1
Training loss: 1.9875061511993408
Validation loss: 2.022127648194631

Epoch: 5| Step: 2
Training loss: 1.8299076557159424
Validation loss: 2.0305187900861106

Epoch: 5| Step: 3
Training loss: 2.1290276050567627
Validation loss: 2.0310832609732947

Epoch: 5| Step: 4
Training loss: 2.128915309906006
Validation loss: 2.0334760497013726

Epoch: 5| Step: 5
Training loss: 1.9222866296768188
Validation loss: 2.045601467291514

Epoch: 5| Step: 6
Training loss: 1.8084218502044678
Validation loss: 2.0670188814401627

Epoch: 5| Step: 7
Training loss: 2.694836378097534
Validation loss: 2.0628844102223716

Epoch: 5| Step: 8
Training loss: 1.9388923645019531
Validation loss: 2.0467098504304886

Epoch: 5| Step: 9
Training loss: 2.0994815826416016
Validation loss: 2.029711147149404

Epoch: 5| Step: 10
Training loss: 2.5803399085998535
Validation loss: 2.046626086036364

Epoch: 5| Step: 11
Training loss: 1.5280592441558838
Validation loss: 2.0338173558314643

Epoch: 131| Step: 0
Training loss: 2.108346939086914
Validation loss: 2.0264796316623688

Epoch: 5| Step: 1
Training loss: 2.2201006412506104
Validation loss: 2.016730065147082

Epoch: 5| Step: 2
Training loss: 2.3118109703063965
Validation loss: 2.0177483608325324

Epoch: 5| Step: 3
Training loss: 1.8608402013778687
Validation loss: 2.013677885135015

Epoch: 5| Step: 4
Training loss: 2.308433771133423
Validation loss: 2.01881343126297

Epoch: 5| Step: 5
Training loss: 2.5115113258361816
Validation loss: 2.0092970530192056

Epoch: 5| Step: 6
Training loss: 2.1500649452209473
Validation loss: 2.025222902496656

Epoch: 5| Step: 7
Training loss: 2.130932331085205
Validation loss: 2.008891468246778

Epoch: 5| Step: 8
Training loss: 1.2795687913894653
Validation loss: 2.0197693010171256

Epoch: 5| Step: 9
Training loss: 2.1333680152893066
Validation loss: 2.0200165609518685

Epoch: 5| Step: 10
Training loss: 2.29783296585083
Validation loss: 2.024375100930532

Epoch: 5| Step: 11
Training loss: 1.7366451025009155
Validation loss: 2.0261073112487793

Epoch: 132| Step: 0
Training loss: 1.934535264968872
Validation loss: 2.0258672535419464

Epoch: 5| Step: 1
Training loss: 2.071413516998291
Validation loss: 2.0307315587997437

Epoch: 5| Step: 2
Training loss: 2.0008482933044434
Validation loss: 2.030940850575765

Epoch: 5| Step: 3
Training loss: 1.7508800029754639
Validation loss: 2.038652499516805

Epoch: 5| Step: 4
Training loss: 2.143629312515259
Validation loss: 2.0365017354488373

Epoch: 5| Step: 5
Training loss: 2.1447713375091553
Validation loss: 2.0505615770816803

Epoch: 5| Step: 6
Training loss: 2.141883373260498
Validation loss: 2.0502160489559174

Epoch: 5| Step: 7
Training loss: 2.5071041584014893
Validation loss: 2.062913050254186

Epoch: 5| Step: 8
Training loss: 2.1538186073303223
Validation loss: 2.061890592177709

Epoch: 5| Step: 9
Training loss: 2.0588908195495605
Validation loss: 2.0606134633223214

Epoch: 5| Step: 10
Training loss: 2.2590885162353516
Validation loss: 2.0534357329209647

Epoch: 5| Step: 11
Training loss: 3.603367805480957
Validation loss: 2.044718489050865

Epoch: 133| Step: 0
Training loss: 1.398797631263733
Validation loss: 2.0437816381454468

Epoch: 5| Step: 1
Training loss: 2.134871482849121
Validation loss: 2.030393679936727

Epoch: 5| Step: 2
Training loss: 2.0740156173706055
Validation loss: 2.0369509359200797

Epoch: 5| Step: 3
Training loss: 1.7270381450653076
Validation loss: 2.033579334616661

Epoch: 5| Step: 4
Training loss: 2.0735437870025635
Validation loss: 2.0270199527343116

Epoch: 5| Step: 5
Training loss: 1.3509107828140259
Validation loss: 2.0240455319484076

Epoch: 5| Step: 6
Training loss: 2.6507370471954346
Validation loss: 2.0280136168003082

Epoch: 5| Step: 7
Training loss: 2.4342074394226074
Validation loss: 2.0217531273762384

Epoch: 5| Step: 8
Training loss: 2.6282949447631836
Validation loss: 2.0252189387877784

Epoch: 5| Step: 9
Training loss: 1.962686538696289
Validation loss: 2.023098518451055

Epoch: 5| Step: 10
Training loss: 2.9239180088043213
Validation loss: 2.027003919084867

Epoch: 5| Step: 11
Training loss: 1.6912713050842285
Validation loss: 2.0242075622081757

Epoch: 134| Step: 0
Training loss: 2.1348090171813965
Validation loss: 2.025245820482572

Epoch: 5| Step: 1
Training loss: 2.3364338874816895
Validation loss: 2.0231009473403296

Epoch: 5| Step: 2
Training loss: 2.0685532093048096
Validation loss: 2.0306158115466437

Epoch: 5| Step: 3
Training loss: 2.3845951557159424
Validation loss: 2.0277140786250434

Epoch: 5| Step: 4
Training loss: 2.222419261932373
Validation loss: 2.0337954312562943

Epoch: 5| Step: 5
Training loss: 2.001516342163086
Validation loss: 2.0229883193969727

Epoch: 5| Step: 6
Training loss: 1.826350212097168
Validation loss: 2.0338954577843347

Epoch: 5| Step: 7
Training loss: 2.4742496013641357
Validation loss: 2.033590023716291

Epoch: 5| Step: 8
Training loss: 1.868963599205017
Validation loss: 2.031389186779658

Epoch: 5| Step: 9
Training loss: 2.167543411254883
Validation loss: 2.033915718396505

Epoch: 5| Step: 10
Training loss: 1.865593671798706
Validation loss: 2.0176489651203156

Epoch: 5| Step: 11
Training loss: 1.1351178884506226
Validation loss: 2.022446940342585

Epoch: 135| Step: 0
Training loss: 2.4129223823547363
Validation loss: 2.0344854642947516

Epoch: 5| Step: 1
Training loss: 2.0233113765716553
Validation loss: 2.0127486834923425

Epoch: 5| Step: 2
Training loss: 1.8227421045303345
Validation loss: 2.020606974760691

Epoch: 5| Step: 3
Training loss: 2.445026397705078
Validation loss: 2.022136544187864

Epoch: 5| Step: 4
Training loss: 1.3732129335403442
Validation loss: 2.0180367728074393

Epoch: 5| Step: 5
Training loss: 2.228912830352783
Validation loss: 2.0301005442937217

Epoch: 5| Step: 6
Training loss: 2.1277236938476562
Validation loss: 2.024361789226532

Epoch: 5| Step: 7
Training loss: 1.7657873630523682
Validation loss: 2.028596594929695

Epoch: 5| Step: 8
Training loss: 1.6698071956634521
Validation loss: 2.0294058322906494

Epoch: 5| Step: 9
Training loss: 2.0444111824035645
Validation loss: 2.029468427101771

Epoch: 5| Step: 10
Training loss: 3.016566753387451
Validation loss: 2.0272740374008813

Epoch: 5| Step: 11
Training loss: 2.2717485427856445
Validation loss: 2.02523102859656

Epoch: 136| Step: 0
Training loss: 2.249001979827881
Validation loss: 2.016239032149315

Epoch: 5| Step: 1
Training loss: 2.2310492992401123
Validation loss: 2.0129855970541635

Epoch: 5| Step: 2
Training loss: 2.496995687484741
Validation loss: 2.0015196800231934

Epoch: 5| Step: 3
Training loss: 1.818611741065979
Validation loss: 2.0104077061017356

Epoch: 5| Step: 4
Training loss: 2.3491721153259277
Validation loss: 1.9991468687852223

Epoch: 5| Step: 5
Training loss: 1.7789652347564697
Validation loss: 1.9991949299971263

Epoch: 5| Step: 6
Training loss: 2.692580461502075
Validation loss: 2.0062439093987146

Epoch: 5| Step: 7
Training loss: 1.870734453201294
Validation loss: 2.0122821033000946

Epoch: 5| Step: 8
Training loss: 1.8263423442840576
Validation loss: 2.011495739221573

Epoch: 5| Step: 9
Training loss: 1.8216145038604736
Validation loss: 2.001664862036705

Epoch: 5| Step: 10
Training loss: 2.0769457817077637
Validation loss: 2.023250018556913

Epoch: 5| Step: 11
Training loss: 1.8759806156158447
Validation loss: 2.0254306942224503

Epoch: 137| Step: 0
Training loss: 1.977480173110962
Validation loss: 2.031142363945643

Epoch: 5| Step: 1
Training loss: 2.6111092567443848
Validation loss: 2.046794826785723

Epoch: 5| Step: 2
Training loss: 1.8092520236968994
Validation loss: 2.0548616449038186

Epoch: 5| Step: 3
Training loss: 2.620088815689087
Validation loss: 2.0554057210683823

Epoch: 5| Step: 4
Training loss: 2.4812979698181152
Validation loss: 2.059439276655515

Epoch: 5| Step: 5
Training loss: 1.682214379310608
Validation loss: 2.041244715452194

Epoch: 5| Step: 6
Training loss: 1.9929816722869873
Validation loss: 2.020534927646319

Epoch: 5| Step: 7
Training loss: 1.774600625038147
Validation loss: 2.011410022775332

Epoch: 5| Step: 8
Training loss: 2.376093626022339
Validation loss: 2.011164312561353

Epoch: 5| Step: 9
Training loss: 2.108804941177368
Validation loss: 2.006528784831365

Epoch: 5| Step: 10
Training loss: 2.087509870529175
Validation loss: 2.0077034135659537

Epoch: 5| Step: 11
Training loss: 1.6007543802261353
Validation loss: 2.00229445596536

Epoch: 138| Step: 0
Training loss: 2.5006136894226074
Validation loss: 2.0044037103652954

Epoch: 5| Step: 1
Training loss: 2.4028213024139404
Validation loss: 2.016293262441953

Epoch: 5| Step: 2
Training loss: 1.5801734924316406
Validation loss: 2.008899057904879

Epoch: 5| Step: 3
Training loss: 2.030766725540161
Validation loss: 2.022004788120588

Epoch: 5| Step: 4
Training loss: 2.048048973083496
Validation loss: 2.024450739224752

Epoch: 5| Step: 5
Training loss: 2.2462141513824463
Validation loss: 2.016767387588819

Epoch: 5| Step: 6
Training loss: 2.1350836753845215
Validation loss: 2.0259353667497635

Epoch: 5| Step: 7
Training loss: 2.348850965499878
Validation loss: 2.017795041203499

Epoch: 5| Step: 8
Training loss: 1.5393508672714233
Validation loss: 2.014676501353582

Epoch: 5| Step: 9
Training loss: 2.410592555999756
Validation loss: 2.0167297273874283

Epoch: 5| Step: 10
Training loss: 2.119478702545166
Validation loss: 2.0116784820954003

Epoch: 5| Step: 11
Training loss: 2.2336173057556152
Validation loss: 2.0295983155568442

Epoch: 139| Step: 0
Training loss: 1.960081696510315
Validation loss: 2.029695898294449

Epoch: 5| Step: 1
Training loss: 2.4874629974365234
Validation loss: 2.0349778781334558

Epoch: 5| Step: 2
Training loss: 2.819950819015503
Validation loss: 2.0559258510669074

Epoch: 5| Step: 3
Training loss: 1.9272162914276123
Validation loss: 2.0575411866108575

Epoch: 5| Step: 4
Training loss: 1.9911562204360962
Validation loss: 2.062718321879705

Epoch: 5| Step: 5
Training loss: 1.7334445714950562
Validation loss: 2.049881229797999

Epoch: 5| Step: 6
Training loss: 1.7638696432113647
Validation loss: 2.052076737085978

Epoch: 5| Step: 7
Training loss: 1.8658679723739624
Validation loss: 2.04428231716156

Epoch: 5| Step: 8
Training loss: 2.1293745040893555
Validation loss: 2.0259155382712684

Epoch: 5| Step: 9
Training loss: 2.0895915031433105
Validation loss: 2.0102593153715134

Epoch: 5| Step: 10
Training loss: 2.2526233196258545
Validation loss: 2.013182351986567

Epoch: 5| Step: 11
Training loss: 2.7613396644592285
Validation loss: 2.010641947388649

Epoch: 140| Step: 0
Training loss: 2.1345558166503906
Validation loss: 2.007266109188398

Epoch: 5| Step: 1
Training loss: 1.9338840246200562
Validation loss: 2.0051951507727304

Epoch: 5| Step: 2
Training loss: 1.8924118280410767
Validation loss: 2.0021042823791504

Epoch: 5| Step: 3
Training loss: 2.217719793319702
Validation loss: 2.0027477045853934

Epoch: 5| Step: 4
Training loss: 2.4186713695526123
Validation loss: 2.0058401922384896

Epoch: 5| Step: 5
Training loss: 2.013415813446045
Validation loss: 2.011369893948237

Epoch: 5| Step: 6
Training loss: 2.157517910003662
Validation loss: 2.011618490020434

Epoch: 5| Step: 7
Training loss: 2.207366466522217
Validation loss: 2.0092160453399024

Epoch: 5| Step: 8
Training loss: 1.7237911224365234
Validation loss: 2.0062454442183175

Epoch: 5| Step: 9
Training loss: 2.2329142093658447
Validation loss: 2.0097035566965737

Epoch: 5| Step: 10
Training loss: 2.1843559741973877
Validation loss: 2.0240073800086975

Epoch: 5| Step: 11
Training loss: 2.5392844676971436
Validation loss: 2.027718558907509

Epoch: 141| Step: 0
Training loss: 1.6175587177276611
Validation loss: 2.0267828702926636

Epoch: 5| Step: 1
Training loss: 2.7078394889831543
Validation loss: 2.026285062233607

Epoch: 5| Step: 2
Training loss: 1.5733702182769775
Validation loss: 2.031553328037262

Epoch: 5| Step: 3
Training loss: 2.087873935699463
Validation loss: 2.023289382457733

Epoch: 5| Step: 4
Training loss: 2.4611012935638428
Validation loss: 2.0440144588549933

Epoch: 5| Step: 5
Training loss: 1.9659452438354492
Validation loss: 2.035408372680346

Epoch: 5| Step: 6
Training loss: 1.3533557653427124
Validation loss: 2.037051782011986

Epoch: 5| Step: 7
Training loss: 2.4059410095214844
Validation loss: 2.0331172744433084

Epoch: 5| Step: 8
Training loss: 1.9249637126922607
Validation loss: 2.0338160494963327

Epoch: 5| Step: 9
Training loss: 2.183067798614502
Validation loss: 2.028065179785093

Epoch: 5| Step: 10
Training loss: 2.715031385421753
Validation loss: 2.0168088922897973

Epoch: 5| Step: 11
Training loss: 2.0890378952026367
Validation loss: 2.0222701827685037

Epoch: 142| Step: 0
Training loss: 1.9829013347625732
Validation loss: 2.0197611898183823

Epoch: 5| Step: 1
Training loss: 2.5725741386413574
Validation loss: 2.0213778962691626

Epoch: 5| Step: 2
Training loss: 1.6618810892105103
Validation loss: 2.021691014369329

Epoch: 5| Step: 3
Training loss: 2.2985572814941406
Validation loss: 2.0242646584908166

Epoch: 5| Step: 4
Training loss: 2.2693076133728027
Validation loss: 2.0265368024508157

Epoch: 5| Step: 5
Training loss: 2.019141674041748
Validation loss: 2.0291985869407654

Epoch: 5| Step: 6
Training loss: 2.1296591758728027
Validation loss: 2.0277587274710336

Epoch: 5| Step: 7
Training loss: 2.1589012145996094
Validation loss: 2.0334599018096924

Epoch: 5| Step: 8
Training loss: 1.984466552734375
Validation loss: 2.0398358205954232

Epoch: 5| Step: 9
Training loss: 1.9329721927642822
Validation loss: 2.0280264417330423

Epoch: 5| Step: 10
Training loss: 2.625007152557373
Validation loss: 2.01426928738753

Epoch: 5| Step: 11
Training loss: 1.430134892463684
Validation loss: 2.01620060702165

Epoch: 143| Step: 0
Training loss: 2.0463509559631348
Validation loss: 2.0187381505966187

Epoch: 5| Step: 1
Training loss: 2.609567165374756
Validation loss: 2.017611642678579

Epoch: 5| Step: 2
Training loss: 2.047142744064331
Validation loss: 2.018421247601509

Epoch: 5| Step: 3
Training loss: 2.4612762928009033
Validation loss: 2.0214113146066666

Epoch: 5| Step: 4
Training loss: 1.4478288888931274
Validation loss: 2.015844538807869

Epoch: 5| Step: 5
Training loss: 1.835232138633728
Validation loss: 2.020554299155871

Epoch: 5| Step: 6
Training loss: 1.5924022197723389
Validation loss: 2.0244395782550177

Epoch: 5| Step: 7
Training loss: 1.6363242864608765
Validation loss: 2.0411044160525003

Epoch: 5| Step: 8
Training loss: 2.269425392150879
Validation loss: 2.0479982992013297

Epoch: 5| Step: 9
Training loss: 2.3327484130859375
Validation loss: 2.0500351389249167

Epoch: 5| Step: 10
Training loss: 2.242448329925537
Validation loss: 2.052869642774264

Epoch: 5| Step: 11
Training loss: 3.561211585998535
Validation loss: 2.077033445239067

Epoch: 144| Step: 0
Training loss: 2.3693041801452637
Validation loss: 2.117715751131376

Epoch: 5| Step: 1
Training loss: 2.094460964202881
Validation loss: 2.1521431704362235

Epoch: 5| Step: 2
Training loss: 1.9896538257598877
Validation loss: 2.1612660586833954

Epoch: 5| Step: 3
Training loss: 2.1238150596618652
Validation loss: 2.1436970134576163

Epoch: 5| Step: 4
Training loss: 2.8156042098999023
Validation loss: 2.127625122666359

Epoch: 5| Step: 5
Training loss: 2.0998051166534424
Validation loss: 2.104888086517652

Epoch: 5| Step: 6
Training loss: 1.807556390762329
Validation loss: 2.057338615258535

Epoch: 5| Step: 7
Training loss: 2.6227378845214844
Validation loss: 2.0267509073019028

Epoch: 5| Step: 8
Training loss: 2.339986801147461
Validation loss: 2.009447475274404

Epoch: 5| Step: 9
Training loss: 2.074463367462158
Validation loss: 2.0078188478946686

Epoch: 5| Step: 10
Training loss: 2.029282569885254
Validation loss: 2.0059536149104438

Epoch: 5| Step: 11
Training loss: 1.8607139587402344
Validation loss: 2.0117427110671997

Epoch: 145| Step: 0
Training loss: 2.221886157989502
Validation loss: 2.0130188862482705

Epoch: 5| Step: 1
Training loss: 1.8021962642669678
Validation loss: 2.008851225177447

Epoch: 5| Step: 2
Training loss: 1.8663911819458008
Validation loss: 2.0149036049842834

Epoch: 5| Step: 3
Training loss: 1.7809474468231201
Validation loss: 2.0161489943663278

Epoch: 5| Step: 4
Training loss: 2.2399094104766846
Validation loss: 2.02299165725708

Epoch: 5| Step: 5
Training loss: 2.146857500076294
Validation loss: 2.0115176240603128

Epoch: 5| Step: 6
Training loss: 2.9793972969055176
Validation loss: 2.013243392109871

Epoch: 5| Step: 7
Training loss: 2.0949854850769043
Validation loss: 2.013475318749746

Epoch: 5| Step: 8
Training loss: 2.1880805492401123
Validation loss: 2.012067606051763

Epoch: 5| Step: 9
Training loss: 1.5413440465927124
Validation loss: 2.0090603729089103

Epoch: 5| Step: 10
Training loss: 2.4541287422180176
Validation loss: 2.00894695520401

Epoch: 5| Step: 11
Training loss: 2.3522253036499023
Validation loss: 1.9997878670692444

Epoch: 146| Step: 0
Training loss: 2.1135494709014893
Validation loss: 2.006980915864309

Epoch: 5| Step: 1
Training loss: 1.945810317993164
Validation loss: 2.003018091122309

Epoch: 5| Step: 2
Training loss: 2.127784252166748
Validation loss: 2.003692770997683

Epoch: 5| Step: 3
Training loss: 1.7390573024749756
Validation loss: 2.004679357012113

Epoch: 5| Step: 4
Training loss: 2.2111973762512207
Validation loss: 2.0053417831659317

Epoch: 5| Step: 5
Training loss: 2.862320899963379
Validation loss: 2.0039727886517844

Epoch: 5| Step: 6
Training loss: 2.2235023975372314
Validation loss: 2.0052079310019812

Epoch: 5| Step: 7
Training loss: 2.1076714992523193
Validation loss: 2.008434926470121

Epoch: 5| Step: 8
Training loss: 1.5437946319580078
Validation loss: 2.0026263246933618

Epoch: 5| Step: 9
Training loss: 2.3833348751068115
Validation loss: 2.00660806397597

Epoch: 5| Step: 10
Training loss: 2.0398478507995605
Validation loss: 2.013069912791252

Epoch: 5| Step: 11
Training loss: 1.4849982261657715
Validation loss: 2.0086668531099954

Epoch: 147| Step: 0
Training loss: 1.9393961429595947
Validation loss: 2.01545279721419

Epoch: 5| Step: 1
Training loss: 2.527282238006592
Validation loss: 2.012695958216985

Epoch: 5| Step: 2
Training loss: 1.6453800201416016
Validation loss: 2.0298849791288376

Epoch: 5| Step: 3
Training loss: 1.9775253534317017
Validation loss: 2.031135340531667

Epoch: 5| Step: 4
Training loss: 2.4039676189422607
Validation loss: 2.026295781135559

Epoch: 5| Step: 5
Training loss: 2.5473222732543945
Validation loss: 2.0192672312259674

Epoch: 5| Step: 6
Training loss: 2.220782995223999
Validation loss: 2.0277888774871826

Epoch: 5| Step: 7
Training loss: 1.8441520929336548
Validation loss: 2.023251950740814

Epoch: 5| Step: 8
Training loss: 1.718422532081604
Validation loss: 2.0245404789845147

Epoch: 5| Step: 9
Training loss: 2.0728695392608643
Validation loss: 2.0219989816347756

Epoch: 5| Step: 10
Training loss: 2.173982858657837
Validation loss: 2.0350962976614633

Epoch: 5| Step: 11
Training loss: 1.4107475280761719
Validation loss: 2.017385557293892

Epoch: 148| Step: 0
Training loss: 1.9176334142684937
Validation loss: 2.0334724386533103

Epoch: 5| Step: 1
Training loss: 2.552506923675537
Validation loss: 2.0250689337650933

Epoch: 5| Step: 2
Training loss: 1.9864177703857422
Validation loss: 2.0172149737675986

Epoch: 5| Step: 3
Training loss: 2.4345996379852295
Validation loss: 2.0240989178419113

Epoch: 5| Step: 4
Training loss: 1.7501161098480225
Validation loss: 2.0315311749776206

Epoch: 5| Step: 5
Training loss: 2.1958208084106445
Validation loss: 2.0251577347517014

Epoch: 5| Step: 6
Training loss: 2.066105365753174
Validation loss: 2.023814782500267

Epoch: 5| Step: 7
Training loss: 1.550758957862854
Validation loss: 2.025237873196602

Epoch: 5| Step: 8
Training loss: 2.1825194358825684
Validation loss: 2.0331563353538513

Epoch: 5| Step: 9
Training loss: 1.7212215662002563
Validation loss: 2.0353417694568634

Epoch: 5| Step: 10
Training loss: 2.2505507469177246
Validation loss: 2.0345860520998635

Epoch: 5| Step: 11
Training loss: 3.4132113456726074
Validation loss: 2.0372002323468528

Epoch: 149| Step: 0
Training loss: 1.8575003147125244
Validation loss: 2.0456975549459457

Epoch: 5| Step: 1
Training loss: 1.801539659500122
Validation loss: 2.0405640552441278

Epoch: 5| Step: 2
Training loss: 2.2252750396728516
Validation loss: 2.0576085348924003

Epoch: 5| Step: 3
Training loss: 2.274244785308838
Validation loss: 2.047116905450821

Epoch: 5| Step: 4
Training loss: 1.9335801601409912
Validation loss: 2.056919366121292

Epoch: 5| Step: 5
Training loss: 2.2259955406188965
Validation loss: 2.0533852825562158

Epoch: 5| Step: 6
Training loss: 2.334209680557251
Validation loss: 2.0432825883229575

Epoch: 5| Step: 7
Training loss: 2.181717872619629
Validation loss: 2.045111522078514

Epoch: 5| Step: 8
Training loss: 2.356318950653076
Validation loss: 2.0322971493005753

Epoch: 5| Step: 9
Training loss: 1.62191641330719
Validation loss: 2.0245519975821176

Epoch: 5| Step: 10
Training loss: 1.8153622150421143
Validation loss: 2.030774553616842

Epoch: 5| Step: 11
Training loss: 2.2227730751037598
Validation loss: 2.027185767889023

Epoch: 150| Step: 0
Training loss: 2.1504178047180176
Validation loss: 2.0261989583571753

Epoch: 5| Step: 1
Training loss: 2.0143160820007324
Validation loss: 2.0211128840843835

Epoch: 5| Step: 2
Training loss: 2.4794068336486816
Validation loss: 2.019887000322342

Epoch: 5| Step: 3
Training loss: 2.3818259239196777
Validation loss: 2.0208411564429603

Epoch: 5| Step: 4
Training loss: 2.072389602661133
Validation loss: 2.014011099934578

Epoch: 5| Step: 5
Training loss: 2.397627353668213
Validation loss: 2.022084812323252

Epoch: 5| Step: 6
Training loss: 1.8808542490005493
Validation loss: 2.016477664311727

Epoch: 5| Step: 7
Training loss: 1.5538618564605713
Validation loss: 2.0203801840543747

Epoch: 5| Step: 8
Training loss: 2.2081336975097656
Validation loss: 2.027144422133764

Epoch: 5| Step: 9
Training loss: 1.848806381225586
Validation loss: 2.0206041087706885

Epoch: 5| Step: 10
Training loss: 2.050015687942505
Validation loss: 2.0155618687470755

Epoch: 5| Step: 11
Training loss: 1.4523919820785522
Validation loss: 2.013031159838041

Epoch: 151| Step: 0
Training loss: 2.305119752883911
Validation loss: 2.021351625521978

Epoch: 5| Step: 1
Training loss: 2.0759873390197754
Validation loss: 2.0283596217632294

Epoch: 5| Step: 2
Training loss: 1.7421925067901611
Validation loss: 2.0213230500618615

Epoch: 5| Step: 3
Training loss: 2.0764243602752686
Validation loss: 2.021736443042755

Epoch: 5| Step: 4
Training loss: 2.2887930870056152
Validation loss: 2.009632796049118

Epoch: 5| Step: 5
Training loss: 2.1343321800231934
Validation loss: 2.015614370505015

Epoch: 5| Step: 6
Training loss: 2.2459864616394043
Validation loss: 2.0233359932899475

Epoch: 5| Step: 7
Training loss: 2.0994467735290527
Validation loss: 2.022512306769689

Epoch: 5| Step: 8
Training loss: 1.9065377712249756
Validation loss: 2.0201484809319177

Epoch: 5| Step: 9
Training loss: 2.0957634449005127
Validation loss: 2.015317459901174

Epoch: 5| Step: 10
Training loss: 1.9236705303192139
Validation loss: 2.0160092612107596

Epoch: 5| Step: 11
Training loss: 1.546776533126831
Validation loss: 2.024106656511625

Epoch: 152| Step: 0
Training loss: 2.4360098838806152
Validation loss: 2.032808875044187

Epoch: 5| Step: 1
Training loss: 1.546539068222046
Validation loss: 2.038562019666036

Epoch: 5| Step: 2
Training loss: 2.1573596000671387
Validation loss: 2.0459987819194794

Epoch: 5| Step: 3
Training loss: 2.5687153339385986
Validation loss: 2.0440382758776345

Epoch: 5| Step: 4
Training loss: 2.079061985015869
Validation loss: 2.0416989574829736

Epoch: 5| Step: 5
Training loss: 1.7404820919036865
Validation loss: 2.0276320626338324

Epoch: 5| Step: 6
Training loss: 1.850358009338379
Validation loss: 2.022670348485311

Epoch: 5| Step: 7
Training loss: 2.295771837234497
Validation loss: 2.0273032039403915

Epoch: 5| Step: 8
Training loss: 2.177431344985962
Validation loss: 2.0267456422249475

Epoch: 5| Step: 9
Training loss: 2.1670329570770264
Validation loss: 2.032423049211502

Epoch: 5| Step: 10
Training loss: 1.8388359546661377
Validation loss: 2.0359245191017785

Epoch: 5| Step: 11
Training loss: 1.8015910387039185
Validation loss: 2.03428020576636

Epoch: 153| Step: 0
Training loss: 1.9426357746124268
Validation loss: 2.0308074603478112

Epoch: 5| Step: 1
Training loss: 1.6635329723358154
Validation loss: 2.0405161132415137

Epoch: 5| Step: 2
Training loss: 2.5910897254943848
Validation loss: 2.0260672022898993

Epoch: 5| Step: 3
Training loss: 2.6692588329315186
Validation loss: 2.0394774923721948

Epoch: 5| Step: 4
Training loss: 2.5058727264404297
Validation loss: 2.0398159523804984

Epoch: 5| Step: 5
Training loss: 1.519999384880066
Validation loss: 2.037549212574959

Epoch: 5| Step: 6
Training loss: 2.3359196186065674
Validation loss: 2.040861129760742

Epoch: 5| Step: 7
Training loss: 2.350123882293701
Validation loss: 2.039078732331594

Epoch: 5| Step: 8
Training loss: 1.5315256118774414
Validation loss: 2.047605281074842

Epoch: 5| Step: 9
Training loss: 1.7975273132324219
Validation loss: 2.03106160958608

Epoch: 5| Step: 10
Training loss: 2.2405593395233154
Validation loss: 2.039314995209376

Epoch: 5| Step: 11
Training loss: 0.8138115406036377
Validation loss: 2.046663815776507

Epoch: 154| Step: 0
Training loss: 2.022490978240967
Validation loss: 2.055356338620186

Epoch: 5| Step: 1
Training loss: 2.554572343826294
Validation loss: 2.0522539565960565

Epoch: 5| Step: 2
Training loss: 2.5492005348205566
Validation loss: 2.055187592903773

Epoch: 5| Step: 3
Training loss: 2.122816324234009
Validation loss: 2.052584633231163

Epoch: 5| Step: 4
Training loss: 1.7958364486694336
Validation loss: 2.0475889444351196

Epoch: 5| Step: 5
Training loss: 2.2648372650146484
Validation loss: 2.048759708801905

Epoch: 5| Step: 6
Training loss: 2.1682193279266357
Validation loss: 2.0522887210051217

Epoch: 5| Step: 7
Training loss: 1.620404601097107
Validation loss: 2.050392583012581

Epoch: 5| Step: 8
Training loss: 2.1301205158233643
Validation loss: 2.0397661129633584

Epoch: 5| Step: 9
Training loss: 1.872823715209961
Validation loss: 2.0369219531615577

Epoch: 5| Step: 10
Training loss: 1.6475998163223267
Validation loss: 2.043786187966665

Epoch: 5| Step: 11
Training loss: 2.554300308227539
Validation loss: 2.0433714042107263

Epoch: 155| Step: 0
Training loss: 1.9355404376983643
Validation loss: 2.0400164822737374

Epoch: 5| Step: 1
Training loss: 2.2383346557617188
Validation loss: 2.045750414331754

Epoch: 5| Step: 2
Training loss: 2.3758673667907715
Validation loss: 2.0456795543432236

Epoch: 5| Step: 3
Training loss: 1.9922558069229126
Validation loss: 2.0463275214036307

Epoch: 5| Step: 4
Training loss: 2.579559326171875
Validation loss: 2.0641886591911316

Epoch: 5| Step: 5
Training loss: 2.3846242427825928
Validation loss: 2.055094843109449

Epoch: 5| Step: 6
Training loss: 1.899423599243164
Validation loss: 2.0557825515667596

Epoch: 5| Step: 7
Training loss: 1.4938170909881592
Validation loss: 2.0490568975607553

Epoch: 5| Step: 8
Training loss: 1.9780757427215576
Validation loss: 2.0530790438254676

Epoch: 5| Step: 9
Training loss: 1.8127950429916382
Validation loss: 2.05204143623511

Epoch: 5| Step: 10
Training loss: 1.9556833505630493
Validation loss: 2.0565008968114853

Epoch: 5| Step: 11
Training loss: 1.946664810180664
Validation loss: 2.0585526128609977

Epoch: 156| Step: 0
Training loss: 2.089517831802368
Validation loss: 2.057707443833351

Epoch: 5| Step: 1
Training loss: 2.0494930744171143
Validation loss: 2.046366254488627

Epoch: 5| Step: 2
Training loss: 1.953884482383728
Validation loss: 2.0514849026997886

Epoch: 5| Step: 3
Training loss: 2.0156431198120117
Validation loss: 2.0394332508246102

Epoch: 5| Step: 4
Training loss: 2.405717611312866
Validation loss: 2.037522946794828

Epoch: 5| Step: 5
Training loss: 1.947988510131836
Validation loss: 2.0432284275690713

Epoch: 5| Step: 6
Training loss: 2.119716167449951
Validation loss: 2.038693497578303

Epoch: 5| Step: 7
Training loss: 1.9643474817276
Validation loss: 2.0388660530249276

Epoch: 5| Step: 8
Training loss: 2.382251262664795
Validation loss: 2.0400248567263284

Epoch: 5| Step: 9
Training loss: 1.7183936834335327
Validation loss: 2.0350771993398666

Epoch: 5| Step: 10
Training loss: 1.8513824939727783
Validation loss: 2.0434017976125083

Epoch: 5| Step: 11
Training loss: 2.8042092323303223
Validation loss: 2.038117195169131

Epoch: 157| Step: 0
Training loss: 1.979440450668335
Validation loss: 2.0438939978679023

Epoch: 5| Step: 1
Training loss: 2.104463577270508
Validation loss: 2.051597982645035

Epoch: 5| Step: 2
Training loss: 2.2246508598327637
Validation loss: 2.03264327843984

Epoch: 5| Step: 3
Training loss: 1.849671721458435
Validation loss: 2.032725249727567

Epoch: 5| Step: 4
Training loss: 1.6253163814544678
Validation loss: 2.0331558287143707

Epoch: 5| Step: 5
Training loss: 1.8109004497528076
Validation loss: 2.037720416982969

Epoch: 5| Step: 6
Training loss: 2.392585515975952
Validation loss: 2.0347067415714264

Epoch: 5| Step: 7
Training loss: 2.2812750339508057
Validation loss: 2.034157579143842

Epoch: 5| Step: 8
Training loss: 1.3760106563568115
Validation loss: 2.0344199935595193

Epoch: 5| Step: 9
Training loss: 2.540215253829956
Validation loss: 2.029806678493818

Epoch: 5| Step: 10
Training loss: 2.3095905780792236
Validation loss: 2.0379343976577124

Epoch: 5| Step: 11
Training loss: 2.0658655166625977
Validation loss: 2.0409861306349435

Epoch: 158| Step: 0
Training loss: 1.6613378524780273
Validation loss: 2.026929885149002

Epoch: 5| Step: 1
Training loss: 2.161882162094116
Validation loss: 2.03312378625075

Epoch: 5| Step: 2
Training loss: 2.302389621734619
Validation loss: 2.03074645002683

Epoch: 5| Step: 3
Training loss: 2.065786838531494
Validation loss: 2.0336667001247406

Epoch: 5| Step: 4
Training loss: 1.87289297580719
Validation loss: 2.027827804287275

Epoch: 5| Step: 5
Training loss: 1.8592731952667236
Validation loss: 2.0276896754900613

Epoch: 5| Step: 6
Training loss: 1.9804996252059937
Validation loss: 2.0248975654443107

Epoch: 5| Step: 7
Training loss: 2.1275546550750732
Validation loss: 2.0309234907229743

Epoch: 5| Step: 8
Training loss: 2.4046711921691895
Validation loss: 2.031254435578982

Epoch: 5| Step: 9
Training loss: 1.9666740894317627
Validation loss: 2.028003086646398

Epoch: 5| Step: 10
Training loss: 2.177666425704956
Validation loss: 2.038215766350428

Epoch: 5| Step: 11
Training loss: 1.6457326412200928
Validation loss: 2.0415493845939636

Epoch: 159| Step: 0
Training loss: 1.9936259984970093
Validation loss: 2.041614219546318

Epoch: 5| Step: 1
Training loss: 1.7821954488754272
Validation loss: 2.025039315223694

Epoch: 5| Step: 2
Training loss: 2.129626750946045
Validation loss: 2.0506520768006644

Epoch: 5| Step: 3
Training loss: 1.6881816387176514
Validation loss: 2.033824935555458

Epoch: 5| Step: 4
Training loss: 1.944281816482544
Validation loss: 2.0443795323371887

Epoch: 5| Step: 5
Training loss: 1.8455917835235596
Validation loss: 2.0411431789398193

Epoch: 5| Step: 6
Training loss: 1.8531116247177124
Validation loss: 2.028917834162712

Epoch: 5| Step: 7
Training loss: 2.66023588180542
Validation loss: 2.041665260990461

Epoch: 5| Step: 8
Training loss: 1.983297348022461
Validation loss: 2.0335168093442917

Epoch: 5| Step: 9
Training loss: 2.350395917892456
Validation loss: 2.037439207235972

Epoch: 5| Step: 10
Training loss: 2.2024054527282715
Validation loss: 2.041227380434672

Epoch: 5| Step: 11
Training loss: 2.1681482791900635
Validation loss: 2.0398526787757874

Epoch: 160| Step: 0
Training loss: 2.5487990379333496
Validation loss: 2.032868057489395

Epoch: 5| Step: 1
Training loss: 2.026092529296875
Validation loss: 2.043185512224833

Epoch: 5| Step: 2
Training loss: 1.7948611974716187
Validation loss: 2.0383256326119104

Epoch: 5| Step: 3
Training loss: 2.251621961593628
Validation loss: 2.037432014942169

Epoch: 5| Step: 4
Training loss: 2.3060660362243652
Validation loss: 2.0354058047135672

Epoch: 5| Step: 5
Training loss: 1.9848706722259521
Validation loss: 2.0266473392645517

Epoch: 5| Step: 6
Training loss: 1.9247658252716064
Validation loss: 2.0349383602539697

Epoch: 5| Step: 7
Training loss: 2.2723894119262695
Validation loss: 2.037185942133268

Epoch: 5| Step: 8
Training loss: 1.9838413000106812
Validation loss: 2.0429444213708243

Epoch: 5| Step: 9
Training loss: 1.7859175205230713
Validation loss: 2.042646959424019

Epoch: 5| Step: 10
Training loss: 1.572041630744934
Validation loss: 2.044347494840622

Epoch: 5| Step: 11
Training loss: 2.3228931427001953
Validation loss: 2.0398939152558646

Epoch: 161| Step: 0
Training loss: 2.0084140300750732
Validation loss: 2.0350024650494256

Epoch: 5| Step: 1
Training loss: 2.3942744731903076
Validation loss: 2.049527252713839

Epoch: 5| Step: 2
Training loss: 2.083984851837158
Validation loss: 2.049865633249283

Epoch: 5| Step: 3
Training loss: 1.7336267232894897
Validation loss: 2.0436950673659644

Epoch: 5| Step: 4
Training loss: 2.3599772453308105
Validation loss: 2.0324645191431046

Epoch: 5| Step: 5
Training loss: 2.4707577228546143
Validation loss: 2.044063260157903

Epoch: 5| Step: 6
Training loss: 1.9161837100982666
Validation loss: 2.0274014373620353

Epoch: 5| Step: 7
Training loss: 1.713616132736206
Validation loss: 2.0300297935803733

Epoch: 5| Step: 8
Training loss: 2.119198799133301
Validation loss: 2.0343411366144815

Epoch: 5| Step: 9
Training loss: 1.8639259338378906
Validation loss: 2.0301998406648636

Epoch: 5| Step: 10
Training loss: 2.1805801391601562
Validation loss: 2.030873879790306

Epoch: 5| Step: 11
Training loss: 1.8723071813583374
Validation loss: 2.0373641351858773

Epoch: 162| Step: 0
Training loss: 1.5482836961746216
Validation loss: 2.046620120604833

Epoch: 5| Step: 1
Training loss: 1.5703678131103516
Validation loss: 2.0388021220763526

Epoch: 5| Step: 2
Training loss: 1.946692705154419
Validation loss: 2.0348709324995675

Epoch: 5| Step: 3
Training loss: 2.051771640777588
Validation loss: 2.0471834739049277

Epoch: 5| Step: 4
Training loss: 1.84018075466156
Validation loss: 2.068622887134552

Epoch: 5| Step: 5
Training loss: 2.403109073638916
Validation loss: 2.077729086081187

Epoch: 5| Step: 6
Training loss: 2.0378577709198
Validation loss: 2.0912715047597885

Epoch: 5| Step: 7
Training loss: 3.030653476715088
Validation loss: 2.1127593517303467

Epoch: 5| Step: 8
Training loss: 1.7821693420410156
Validation loss: 2.0952316373586655

Epoch: 5| Step: 9
Training loss: 2.2810862064361572
Validation loss: 2.094473898410797

Epoch: 5| Step: 10
Training loss: 2.2385809421539307
Validation loss: 2.0639055967330933

Epoch: 5| Step: 11
Training loss: 2.550846576690674
Validation loss: 2.0535689691702523

Epoch: 163| Step: 0
Training loss: 2.093393325805664
Validation loss: 2.0479595909516015

Epoch: 5| Step: 1
Training loss: 2.1585798263549805
Validation loss: 2.0384269754091897

Epoch: 5| Step: 2
Training loss: 1.66305410861969
Validation loss: 2.0403219809134803

Epoch: 5| Step: 3
Training loss: 2.068690538406372
Validation loss: 2.0457022190093994

Epoch: 5| Step: 4
Training loss: 2.5424671173095703
Validation loss: 2.0376675128936768

Epoch: 5| Step: 5
Training loss: 1.7413352727890015
Validation loss: 2.0474605162938437

Epoch: 5| Step: 6
Training loss: 1.876868486404419
Validation loss: 2.047389348347982

Epoch: 5| Step: 7
Training loss: 2.2709078788757324
Validation loss: 2.042304495970408

Epoch: 5| Step: 8
Training loss: 2.2876992225646973
Validation loss: 2.046019365390142

Epoch: 5| Step: 9
Training loss: 2.1205062866210938
Validation loss: 2.050840829809507

Epoch: 5| Step: 10
Training loss: 2.140359878540039
Validation loss: 2.0487899283568063

Epoch: 5| Step: 11
Training loss: 1.226552128791809
Validation loss: 2.055820405483246

Epoch: 164| Step: 0
Training loss: 2.228889226913452
Validation loss: 2.050119563937187

Epoch: 5| Step: 1
Training loss: 1.5516077280044556
Validation loss: 2.0556454906860986

Epoch: 5| Step: 2
Training loss: 1.8063102960586548
Validation loss: 2.0705945243438086

Epoch: 5| Step: 3
Training loss: 1.547008752822876
Validation loss: 2.069509655237198

Epoch: 5| Step: 4
Training loss: 2.1328036785125732
Validation loss: 2.065227592984835

Epoch: 5| Step: 5
Training loss: 2.199354648590088
Validation loss: 2.0737340599298477

Epoch: 5| Step: 6
Training loss: 2.1641077995300293
Validation loss: 2.06743523478508

Epoch: 5| Step: 7
Training loss: 2.5081028938293457
Validation loss: 2.06878063082695

Epoch: 5| Step: 8
Training loss: 2.2634425163269043
Validation loss: 2.0647282848755517

Epoch: 5| Step: 9
Training loss: 2.281439781188965
Validation loss: 2.0669528444608054

Epoch: 5| Step: 10
Training loss: 1.8900216817855835
Validation loss: 2.063227171699206

Epoch: 5| Step: 11
Training loss: 1.6091619729995728
Validation loss: 2.0608543008565903

Epoch: 165| Step: 0
Training loss: 2.380089521408081
Validation loss: 2.0542307794094086

Epoch: 5| Step: 1
Training loss: 1.8690173625946045
Validation loss: 2.054190049568812

Epoch: 5| Step: 2
Training loss: 2.322727918624878
Validation loss: 2.053936536113421

Epoch: 5| Step: 3
Training loss: 1.9254363775253296
Validation loss: 2.0497663021087646

Epoch: 5| Step: 4
Training loss: 2.3918025493621826
Validation loss: 2.0451972583929696

Epoch: 5| Step: 5
Training loss: 1.8666400909423828
Validation loss: 2.047010531028112

Epoch: 5| Step: 6
Training loss: 1.9568191766738892
Validation loss: 2.041266158223152

Epoch: 5| Step: 7
Training loss: 1.898607850074768
Validation loss: 2.0403997798760733

Epoch: 5| Step: 8
Training loss: 1.457596778869629
Validation loss: 2.044158786535263

Epoch: 5| Step: 9
Training loss: 1.99309504032135
Validation loss: 2.0361324499050775

Epoch: 5| Step: 10
Training loss: 2.2371368408203125
Validation loss: 2.0351545761028924

Epoch: 5| Step: 11
Training loss: 2.5044069290161133
Validation loss: 2.0333854655424752

Epoch: 166| Step: 0
Training loss: 2.43778657913208
Validation loss: 2.028010383248329

Epoch: 5| Step: 1
Training loss: 1.791252851486206
Validation loss: 2.039387678106626

Epoch: 5| Step: 2
Training loss: 2.5202536582946777
Validation loss: 2.0328070918718972

Epoch: 5| Step: 3
Training loss: 1.7492201328277588
Validation loss: 2.0367555916309357

Epoch: 5| Step: 4
Training loss: 2.258293390274048
Validation loss: 2.042220408717791

Epoch: 5| Step: 5
Training loss: 1.9458671808242798
Validation loss: 2.040503387649854

Epoch: 5| Step: 6
Training loss: 1.5110301971435547
Validation loss: 2.0379449228445687

Epoch: 5| Step: 7
Training loss: 2.094331741333008
Validation loss: 2.0431326081355414

Epoch: 5| Step: 8
Training loss: 2.1359469890594482
Validation loss: 2.045075704654058

Epoch: 5| Step: 9
Training loss: 1.8289623260498047
Validation loss: 2.044114336371422

Epoch: 5| Step: 10
Training loss: 2.0167412757873535
Validation loss: 2.049148201942444

Epoch: 5| Step: 11
Training loss: 2.7031898498535156
Validation loss: 2.041801964243253

Epoch: 167| Step: 0
Training loss: 1.904266357421875
Validation loss: 2.035413235425949

Epoch: 5| Step: 1
Training loss: 2.290836811065674
Validation loss: 2.0326850016911826

Epoch: 5| Step: 2
Training loss: 1.751989722251892
Validation loss: 2.0289464791615806

Epoch: 5| Step: 3
Training loss: 2.433506488800049
Validation loss: 2.033329422275225

Epoch: 5| Step: 4
Training loss: 1.890247106552124
Validation loss: 2.0278431425491967

Epoch: 5| Step: 5
Training loss: 1.788857102394104
Validation loss: 2.0385326196750007

Epoch: 5| Step: 6
Training loss: 2.2773609161376953
Validation loss: 2.035869906346003

Epoch: 5| Step: 7
Training loss: 1.8850691318511963
Validation loss: 2.0424273113409677

Epoch: 5| Step: 8
Training loss: 1.9629242420196533
Validation loss: 2.0399336218833923

Epoch: 5| Step: 9
Training loss: 2.11232852935791
Validation loss: 2.0423539827267327

Epoch: 5| Step: 10
Training loss: 2.0333681106567383
Validation loss: 2.0570436865091324

Epoch: 5| Step: 11
Training loss: 3.240274667739868
Validation loss: 2.047312244772911

Epoch: 168| Step: 0
Training loss: 1.8471157550811768
Validation loss: 2.048613061507543

Epoch: 5| Step: 1
Training loss: 2.193561553955078
Validation loss: 2.0388708164294562

Epoch: 5| Step: 2
Training loss: 2.4968459606170654
Validation loss: 2.047445093592008

Epoch: 5| Step: 3
Training loss: 1.7523248195648193
Validation loss: 2.050267602006594

Epoch: 5| Step: 4
Training loss: 2.0540590286254883
Validation loss: 2.0558412075042725

Epoch: 5| Step: 5
Training loss: 1.7976253032684326
Validation loss: 2.049602140982946

Epoch: 5| Step: 6
Training loss: 2.227633237838745
Validation loss: 2.0586410562197366

Epoch: 5| Step: 7
Training loss: 2.3839831352233887
Validation loss: 2.054169957836469

Epoch: 5| Step: 8
Training loss: 1.6600452661514282
Validation loss: 2.0517348647117615

Epoch: 5| Step: 9
Training loss: 2.261244297027588
Validation loss: 2.048927739262581

Epoch: 5| Step: 10
Training loss: 1.4292852878570557
Validation loss: 2.0644441644350686

Epoch: 5| Step: 11
Training loss: 2.907125473022461
Validation loss: 2.0556091417868934

Epoch: 169| Step: 0
Training loss: 1.9702205657958984
Validation loss: 2.0619890888532004

Epoch: 5| Step: 1
Training loss: 1.8646408319473267
Validation loss: 2.057435800631841

Epoch: 5| Step: 2
Training loss: 1.9883276224136353
Validation loss: 2.0507036298513412

Epoch: 5| Step: 3
Training loss: 2.0744545459747314
Validation loss: 2.052683785557747

Epoch: 5| Step: 4
Training loss: 1.959181785583496
Validation loss: 2.0569688081741333

Epoch: 5| Step: 5
Training loss: 1.8408892154693604
Validation loss: 2.0453318059444427

Epoch: 5| Step: 6
Training loss: 1.8044544458389282
Validation loss: 2.047301655014356

Epoch: 5| Step: 7
Training loss: 2.254695415496826
Validation loss: 2.0461199084917703

Epoch: 5| Step: 8
Training loss: 2.269683837890625
Validation loss: 2.05464660624663

Epoch: 5| Step: 9
Training loss: 2.4339840412139893
Validation loss: 2.0507371922334037

Epoch: 5| Step: 10
Training loss: 1.7532413005828857
Validation loss: 2.03626312315464

Epoch: 5| Step: 11
Training loss: 2.7608375549316406
Validation loss: 2.050060341755549

Epoch: 170| Step: 0
Training loss: 1.8367338180541992
Validation loss: 2.044132813811302

Epoch: 5| Step: 1
Training loss: 1.7072293758392334
Validation loss: 2.042922779917717

Epoch: 5| Step: 2
Training loss: 1.877328634262085
Validation loss: 2.021043136715889

Epoch: 5| Step: 3
Training loss: 2.5210680961608887
Validation loss: 2.0365311255057654

Epoch: 5| Step: 4
Training loss: 2.3320047855377197
Validation loss: 2.036016136407852

Epoch: 5| Step: 5
Training loss: 1.8831768035888672
Validation loss: 2.0276642193396888

Epoch: 5| Step: 6
Training loss: 2.204942226409912
Validation loss: 2.041977514823278

Epoch: 5| Step: 7
Training loss: 2.1697981357574463
Validation loss: 2.0554598718881607

Epoch: 5| Step: 8
Training loss: 2.0179858207702637
Validation loss: 2.065683270494143

Epoch: 5| Step: 9
Training loss: 2.0143699645996094
Validation loss: 2.056242421269417

Epoch: 5| Step: 10
Training loss: 1.957201361656189
Validation loss: 2.0486981123685837

Epoch: 5| Step: 11
Training loss: 2.2513303756713867
Validation loss: 2.0388671904802322

Epoch: 171| Step: 0
Training loss: 1.9623950719833374
Validation loss: 2.034236947695414

Epoch: 5| Step: 1
Training loss: 1.7365198135375977
Validation loss: 2.026646042863528

Epoch: 5| Step: 2
Training loss: 1.6717115640640259
Validation loss: 2.031141151984533

Epoch: 5| Step: 3
Training loss: 1.6991360187530518
Validation loss: 2.0249982426563897

Epoch: 5| Step: 4
Training loss: 1.7217031717300415
Validation loss: 2.0136979023615518

Epoch: 5| Step: 5
Training loss: 2.239654064178467
Validation loss: 2.0319124658902488

Epoch: 5| Step: 6
Training loss: 1.8234481811523438
Validation loss: 2.023530120650927

Epoch: 5| Step: 7
Training loss: 1.9289920330047607
Validation loss: 2.014109432697296

Epoch: 5| Step: 8
Training loss: 2.389270544052124
Validation loss: 2.0295478453238807

Epoch: 5| Step: 9
Training loss: 2.640247106552124
Validation loss: 2.0356001456578574

Epoch: 5| Step: 10
Training loss: 2.192164659500122
Validation loss: 2.033136412501335

Epoch: 5| Step: 11
Training loss: 3.0200886726379395
Validation loss: 2.0448511640230813

Epoch: 172| Step: 0
Training loss: 2.434069871902466
Validation loss: 2.047709738214811

Epoch: 5| Step: 1
Training loss: 1.8616759777069092
Validation loss: 2.06174003581206

Epoch: 5| Step: 2
Training loss: 2.1640477180480957
Validation loss: 2.056531603137652

Epoch: 5| Step: 3
Training loss: 2.026705503463745
Validation loss: 2.0569951782623925

Epoch: 5| Step: 4
Training loss: 2.3364460468292236
Validation loss: 2.056389590104421

Epoch: 5| Step: 5
Training loss: 1.9629566669464111
Validation loss: 2.055211087067922

Epoch: 5| Step: 6
Training loss: 1.9711717367172241
Validation loss: 2.050789788365364

Epoch: 5| Step: 7
Training loss: 1.3174140453338623
Validation loss: 2.048206855853399

Epoch: 5| Step: 8
Training loss: 2.1525940895080566
Validation loss: 2.0515006631612778

Epoch: 5| Step: 9
Training loss: 2.0599517822265625
Validation loss: 2.0483109851678214

Epoch: 5| Step: 10
Training loss: 2.1470322608947754
Validation loss: 2.0497824450333915

Epoch: 5| Step: 11
Training loss: 2.32869553565979
Validation loss: 2.0439587334791818

Epoch: 173| Step: 0
Training loss: 2.0608294010162354
Validation loss: 2.028716191649437

Epoch: 5| Step: 1
Training loss: 2.055609941482544
Validation loss: 2.0440594106912613

Epoch: 5| Step: 2
Training loss: 2.1070685386657715
Validation loss: 2.0393072366714478

Epoch: 5| Step: 3
Training loss: 2.1507654190063477
Validation loss: 2.0363393078247705

Epoch: 5| Step: 4
Training loss: 2.241542100906372
Validation loss: 2.042983422676722

Epoch: 5| Step: 5
Training loss: 2.200387954711914
Validation loss: 2.046363721291224

Epoch: 5| Step: 6
Training loss: 1.9888025522232056
Validation loss: 2.0445101112127304

Epoch: 5| Step: 7
Training loss: 1.1507456302642822
Validation loss: 2.04508804778258

Epoch: 5| Step: 8
Training loss: 1.914881944656372
Validation loss: 2.0577393571535745

Epoch: 5| Step: 9
Training loss: 2.2000608444213867
Validation loss: 2.0492586543162665

Epoch: 5| Step: 10
Training loss: 2.329801082611084
Validation loss: 2.0648908416430154

Epoch: 5| Step: 11
Training loss: 2.4287452697753906
Validation loss: 2.0652186572551727

Epoch: 174| Step: 0
Training loss: 1.6945356130599976
Validation loss: 2.0670330623785653

Epoch: 5| Step: 1
Training loss: 2.3813018798828125
Validation loss: 2.0653102099895477

Epoch: 5| Step: 2
Training loss: 1.906943917274475
Validation loss: 2.064898525675138

Epoch: 5| Step: 3
Training loss: 2.4926483631134033
Validation loss: 2.0541657706101737

Epoch: 5| Step: 4
Training loss: 1.9135820865631104
Validation loss: 2.0529144008954368

Epoch: 5| Step: 5
Training loss: 1.8662331104278564
Validation loss: 2.053544898827871

Epoch: 5| Step: 6
Training loss: 2.294290542602539
Validation loss: 2.050567924976349

Epoch: 5| Step: 7
Training loss: 2.253805160522461
Validation loss: 2.0561898251374564

Epoch: 5| Step: 8
Training loss: 1.8373132944107056
Validation loss: 2.0536990265051522

Epoch: 5| Step: 9
Training loss: 1.592504858970642
Validation loss: 2.0381350169579187

Epoch: 5| Step: 10
Training loss: 1.9593795537948608
Validation loss: 2.051204944650332

Epoch: 5| Step: 11
Training loss: 2.1071019172668457
Validation loss: 2.029959484934807

Epoch: 175| Step: 0
Training loss: 2.8324007987976074
Validation loss: 2.040832827488581

Epoch: 5| Step: 1
Training loss: 2.143375873565674
Validation loss: 2.0269050945838294

Epoch: 5| Step: 2
Training loss: 1.99733567237854
Validation loss: 2.0322547306617103

Epoch: 5| Step: 3
Training loss: 2.20417857170105
Validation loss: 2.033468102415403

Epoch: 5| Step: 4
Training loss: 2.048841953277588
Validation loss: 2.030715157588323

Epoch: 5| Step: 5
Training loss: 2.2089428901672363
Validation loss: 2.03625717262427

Epoch: 5| Step: 6
Training loss: 1.4713269472122192
Validation loss: 2.038056418299675

Epoch: 5| Step: 7
Training loss: 2.037113904953003
Validation loss: 2.038943444689115

Epoch: 5| Step: 8
Training loss: 1.967825174331665
Validation loss: 2.0406780739625296

Epoch: 5| Step: 9
Training loss: 1.4857937097549438
Validation loss: 2.047318850954374

Epoch: 5| Step: 10
Training loss: 1.9616096019744873
Validation loss: 2.047132899363836

Epoch: 5| Step: 11
Training loss: 2.4341983795166016
Validation loss: 2.0404715687036514

Epoch: 176| Step: 0
Training loss: 1.669147253036499
Validation loss: 2.0468449095884957

Epoch: 5| Step: 1
Training loss: 1.9934966564178467
Validation loss: 2.0321884155273438

Epoch: 5| Step: 2
Training loss: 1.5340125560760498
Validation loss: 2.0455493380626044

Epoch: 5| Step: 3
Training loss: 2.3754563331604004
Validation loss: 2.033325657248497

Epoch: 5| Step: 4
Training loss: 2.1312637329101562
Validation loss: 2.030160074432691

Epoch: 5| Step: 5
Training loss: 1.8386799097061157
Validation loss: 2.027679627140363

Epoch: 5| Step: 6
Training loss: 1.754473328590393
Validation loss: 2.0359835823376975

Epoch: 5| Step: 7
Training loss: 1.8326470851898193
Validation loss: 2.0319180438915887

Epoch: 5| Step: 8
Training loss: 2.565654754638672
Validation loss: 2.0282857716083527

Epoch: 5| Step: 9
Training loss: 2.5612800121307373
Validation loss: 2.029768710335096

Epoch: 5| Step: 10
Training loss: 2.139561176300049
Validation loss: 2.036781887213389

Epoch: 5| Step: 11
Training loss: 1.4904088973999023
Validation loss: 2.0346192866563797

Epoch: 177| Step: 0
Training loss: 1.8511158227920532
Validation loss: 2.043925330042839

Epoch: 5| Step: 1
Training loss: 2.4233219623565674
Validation loss: 2.0545269499222436

Epoch: 5| Step: 2
Training loss: 2.4957377910614014
Validation loss: 2.054588183760643

Epoch: 5| Step: 3
Training loss: 1.8881229162216187
Validation loss: 2.072398473819097

Epoch: 5| Step: 4
Training loss: 2.2051329612731934
Validation loss: 2.0693653325239816

Epoch: 5| Step: 5
Training loss: 1.8358796834945679
Validation loss: 2.072323570648829

Epoch: 5| Step: 6
Training loss: 1.97052800655365
Validation loss: 2.0583655685186386

Epoch: 5| Step: 7
Training loss: 2.1498265266418457
Validation loss: 2.0505570669968924

Epoch: 5| Step: 8
Training loss: 1.872260332107544
Validation loss: 2.043644890189171

Epoch: 5| Step: 9
Training loss: 1.448986530303955
Validation loss: 2.041230395436287

Epoch: 5| Step: 10
Training loss: 2.1034069061279297
Validation loss: 2.0336717665195465

Epoch: 5| Step: 11
Training loss: 2.9756217002868652
Validation loss: 2.0239221155643463

Epoch: 178| Step: 0
Training loss: 1.818477988243103
Validation loss: 2.0259837011496225

Epoch: 5| Step: 1
Training loss: 1.9411897659301758
Validation loss: 2.0248869210481644

Epoch: 5| Step: 2
Training loss: 2.0190742015838623
Validation loss: 2.033393065134684

Epoch: 5| Step: 3
Training loss: 2.1706573963165283
Validation loss: 2.0320957402388253

Epoch: 5| Step: 4
Training loss: 1.9552406072616577
Validation loss: 2.0403880377610526

Epoch: 5| Step: 5
Training loss: 1.6494786739349365
Validation loss: 2.035961295167605

Epoch: 5| Step: 6
Training loss: 1.8985376358032227
Validation loss: 2.025926540295283

Epoch: 5| Step: 7
Training loss: 2.4010632038116455
Validation loss: 2.0314484586318335

Epoch: 5| Step: 8
Training loss: 2.7054474353790283
Validation loss: 2.031582554181417

Epoch: 5| Step: 9
Training loss: 2.00334095954895
Validation loss: 2.0351243813832602

Epoch: 5| Step: 10
Training loss: 2.1447219848632812
Validation loss: 2.040327866872152

Epoch: 5| Step: 11
Training loss: 1.13076651096344
Validation loss: 2.042155941327413

Epoch: 179| Step: 0
Training loss: 1.956003189086914
Validation loss: 2.0541463047266006

Epoch: 5| Step: 1
Training loss: 2.1182596683502197
Validation loss: 2.063914398352305

Epoch: 5| Step: 2
Training loss: 2.0603737831115723
Validation loss: 2.112981175382932

Epoch: 5| Step: 3
Training loss: 2.6039178371429443
Validation loss: 2.1239063292741776

Epoch: 5| Step: 4
Training loss: 1.8795455694198608
Validation loss: 2.110072289903959

Epoch: 5| Step: 5
Training loss: 2.0880844593048096
Validation loss: 2.0888867477575936

Epoch: 5| Step: 6
Training loss: 2.1341214179992676
Validation loss: 2.0927531669537225

Epoch: 5| Step: 7
Training loss: 1.7908885478973389
Validation loss: 2.0782501697540283

Epoch: 5| Step: 8
Training loss: 2.109888792037964
Validation loss: 2.055149346590042

Epoch: 5| Step: 9
Training loss: 2.663881778717041
Validation loss: 2.049598549803098

Epoch: 5| Step: 10
Training loss: 1.5195977687835693
Validation loss: 2.0467379142840705

Epoch: 5| Step: 11
Training loss: 2.043534278869629
Validation loss: 2.0463628570238748

Epoch: 180| Step: 0
Training loss: 1.7157609462738037
Validation loss: 2.038286010424296

Epoch: 5| Step: 1
Training loss: 2.561873435974121
Validation loss: 2.043274770180384

Epoch: 5| Step: 2
Training loss: 1.9979556798934937
Validation loss: 2.0409903724988303

Epoch: 5| Step: 3
Training loss: 2.0776665210723877
Validation loss: 2.036823719739914

Epoch: 5| Step: 4
Training loss: 1.754390001296997
Validation loss: 2.027771999438604

Epoch: 5| Step: 5
Training loss: 2.249864101409912
Validation loss: 2.042485083142916

Epoch: 5| Step: 6
Training loss: 1.722522497177124
Validation loss: 2.0350530793269477

Epoch: 5| Step: 7
Training loss: 2.236783027648926
Validation loss: 2.034869283437729

Epoch: 5| Step: 8
Training loss: 2.0679900646209717
Validation loss: 2.0272956093152366

Epoch: 5| Step: 9
Training loss: 1.9931004047393799
Validation loss: 2.035428360104561

Epoch: 5| Step: 10
Training loss: 2.3382015228271484
Validation loss: 2.0176277110973992

Epoch: 5| Step: 11
Training loss: 1.9360393285751343
Validation loss: 2.0252817968527475

Epoch: 181| Step: 0
Training loss: 2.416538953781128
Validation loss: 2.018990551431974

Epoch: 5| Step: 1
Training loss: 1.952056646347046
Validation loss: 2.023779571056366

Epoch: 5| Step: 2
Training loss: 1.4903086423873901
Validation loss: 2.0197594364484153

Epoch: 5| Step: 3
Training loss: 1.9387247562408447
Validation loss: 2.033387507001559

Epoch: 5| Step: 4
Training loss: 2.38195538520813
Validation loss: 2.0358410676320395

Epoch: 5| Step: 5
Training loss: 1.5350233316421509
Validation loss: 2.0209421614805856

Epoch: 5| Step: 6
Training loss: 2.503490686416626
Validation loss: 2.033905496199926

Epoch: 5| Step: 7
Training loss: 1.7116906642913818
Validation loss: 2.0486262689034143

Epoch: 5| Step: 8
Training loss: 1.4547779560089111
Validation loss: 2.054814805587133

Epoch: 5| Step: 9
Training loss: 2.758700132369995
Validation loss: 2.0426126470168433

Epoch: 5| Step: 10
Training loss: 1.9836552143096924
Validation loss: 2.0563162167867026

Epoch: 5| Step: 11
Training loss: 2.8342602252960205
Validation loss: 2.0551865994930267

Epoch: 182| Step: 0
Training loss: 2.4848358631134033
Validation loss: 2.0512037674585977

Epoch: 5| Step: 1
Training loss: 1.5585829019546509
Validation loss: 2.037938584884008

Epoch: 5| Step: 2
Training loss: 1.7019199132919312
Validation loss: 2.0318729877471924

Epoch: 5| Step: 3
Training loss: 2.0012738704681396
Validation loss: 2.045499697327614

Epoch: 5| Step: 4
Training loss: 2.0353121757507324
Validation loss: 2.037172108888626

Epoch: 5| Step: 5
Training loss: 2.138349771499634
Validation loss: 2.0376743177572885

Epoch: 5| Step: 6
Training loss: 2.0889105796813965
Validation loss: 2.034097279111544

Epoch: 5| Step: 7
Training loss: 2.065018653869629
Validation loss: 2.0426238427559533

Epoch: 5| Step: 8
Training loss: 2.1775245666503906
Validation loss: 2.048240050673485

Epoch: 5| Step: 9
Training loss: 1.9265588521957397
Validation loss: 2.049194172024727

Epoch: 5| Step: 10
Training loss: 2.1022024154663086
Validation loss: 2.0649085293213525

Epoch: 5| Step: 11
Training loss: 2.0453402996063232
Validation loss: 2.052113061149915

Epoch: 183| Step: 0
Training loss: 1.9515202045440674
Validation loss: 2.074368894100189

Epoch: 5| Step: 1
Training loss: 1.8305377960205078
Validation loss: 2.069872180620829

Epoch: 5| Step: 2
Training loss: 2.206355571746826
Validation loss: 2.0552124977111816

Epoch: 5| Step: 3
Training loss: 1.6783220767974854
Validation loss: 2.069314176837603

Epoch: 5| Step: 4
Training loss: 2.170602321624756
Validation loss: 2.0626883705457053

Epoch: 5| Step: 5
Training loss: 2.2097744941711426
Validation loss: 2.0676547090212503

Epoch: 5| Step: 6
Training loss: 1.9468574523925781
Validation loss: 2.077865814169248

Epoch: 5| Step: 7
Training loss: 1.9914802312850952
Validation loss: 2.068546732266744

Epoch: 5| Step: 8
Training loss: 2.1455349922180176
Validation loss: 2.0603788693745932

Epoch: 5| Step: 9
Training loss: 2.2627384662628174
Validation loss: 2.0482915143171945

Epoch: 5| Step: 10
Training loss: 1.757938027381897
Validation loss: 2.026621162891388

Epoch: 5| Step: 11
Training loss: 2.8972134590148926
Validation loss: 2.0208811511596045

Epoch: 184| Step: 0
Training loss: 2.1812918186187744
Validation loss: 2.0292950123548508

Epoch: 5| Step: 1
Training loss: 1.7028898000717163
Validation loss: 2.0486094504594803

Epoch: 5| Step: 2
Training loss: 1.9913551807403564
Validation loss: 2.053536886970202

Epoch: 5| Step: 3
Training loss: 1.9526140689849854
Validation loss: 2.0474792818228402

Epoch: 5| Step: 4
Training loss: 1.6147714853286743
Validation loss: 2.058909371495247

Epoch: 5| Step: 5
Training loss: 2.196208953857422
Validation loss: 2.075099249680837

Epoch: 5| Step: 6
Training loss: 1.8856662511825562
Validation loss: 2.0853997667630515

Epoch: 5| Step: 7
Training loss: 2.5491058826446533
Validation loss: 2.0867968599001565

Epoch: 5| Step: 8
Training loss: 1.9163010120391846
Validation loss: 2.086789379517237

Epoch: 5| Step: 9
Training loss: 2.1961960792541504
Validation loss: 2.082436293363571

Epoch: 5| Step: 10
Training loss: 2.340919017791748
Validation loss: 2.0674355924129486

Epoch: 5| Step: 11
Training loss: 1.6618025302886963
Validation loss: 2.061116779843966

Epoch: 185| Step: 0
Training loss: 2.3103530406951904
Validation loss: 2.054853156208992

Epoch: 5| Step: 1
Training loss: 1.5946427583694458
Validation loss: 2.059817135334015

Epoch: 5| Step: 2
Training loss: 2.268857717514038
Validation loss: 2.0570865124464035

Epoch: 5| Step: 3
Training loss: 1.9618349075317383
Validation loss: 2.0644915799299874

Epoch: 5| Step: 4
Training loss: 1.8583152294158936
Validation loss: 2.0764265805482864

Epoch: 5| Step: 5
Training loss: 2.6846516132354736
Validation loss: 2.0596014658610025

Epoch: 5| Step: 6
Training loss: 1.5566847324371338
Validation loss: 2.0501836438973746

Epoch: 5| Step: 7
Training loss: 2.3118698596954346
Validation loss: 2.046277994910876

Epoch: 5| Step: 8
Training loss: 2.1687960624694824
Validation loss: 2.0448082089424133

Epoch: 5| Step: 9
Training loss: 1.6900451183319092
Validation loss: 2.0385734538237252

Epoch: 5| Step: 10
Training loss: 1.6921970844268799
Validation loss: 2.0468644897143045

Epoch: 5| Step: 11
Training loss: 2.539140224456787
Validation loss: 2.044399286309878

Epoch: 186| Step: 0
Training loss: 1.6104332208633423
Validation loss: 2.048713634411494

Epoch: 5| Step: 1
Training loss: 1.693738341331482
Validation loss: 2.040071780482928

Epoch: 5| Step: 2
Training loss: 1.6631090641021729
Validation loss: 2.0531331102053323

Epoch: 5| Step: 3
Training loss: 2.2601284980773926
Validation loss: 2.050408363342285

Epoch: 5| Step: 4
Training loss: 1.9007360935211182
Validation loss: 2.039221778512001

Epoch: 5| Step: 5
Training loss: 2.679063558578491
Validation loss: 2.0511892437934875

Epoch: 5| Step: 6
Training loss: 2.2612366676330566
Validation loss: 2.048954317967097

Epoch: 5| Step: 7
Training loss: 1.692296028137207
Validation loss: 2.0525671939055123

Epoch: 5| Step: 8
Training loss: 2.0536513328552246
Validation loss: 2.0598889937003455

Epoch: 5| Step: 9
Training loss: 1.9980583190917969
Validation loss: 2.056867152452469

Epoch: 5| Step: 10
Training loss: 2.064950466156006
Validation loss: 2.0780717531840005

Epoch: 5| Step: 11
Training loss: 2.970925807952881
Validation loss: 2.0699769059816995

Epoch: 187| Step: 0
Training loss: 2.2815463542938232
Validation loss: 2.0844945957263312

Epoch: 5| Step: 1
Training loss: 1.8145248889923096
Validation loss: 2.076281353831291

Epoch: 5| Step: 2
Training loss: 2.054258346557617
Validation loss: 2.07526034116745

Epoch: 5| Step: 3
Training loss: 1.6684421300888062
Validation loss: 2.0819632013638816

Epoch: 5| Step: 4
Training loss: 2.266108751296997
Validation loss: 2.0598756025234857

Epoch: 5| Step: 5
Training loss: 1.6580225229263306
Validation loss: 2.07198536892732

Epoch: 5| Step: 6
Training loss: 1.7762069702148438
Validation loss: 2.0572024385134378

Epoch: 5| Step: 7
Training loss: 1.5524896383285522
Validation loss: 2.06425071756045

Epoch: 5| Step: 8
Training loss: 2.1949241161346436
Validation loss: 2.064612537622452

Epoch: 5| Step: 9
Training loss: 2.102530002593994
Validation loss: 2.0686631153027215

Epoch: 5| Step: 10
Training loss: 2.6891140937805176
Validation loss: 2.0716518660386405

Epoch: 5| Step: 11
Training loss: 1.7475045919418335
Validation loss: 2.057941640416781

Epoch: 188| Step: 0
Training loss: 1.6840190887451172
Validation loss: 2.061355928579966

Epoch: 5| Step: 1
Training loss: 2.4865365028381348
Validation loss: 2.0645671635866165

Epoch: 5| Step: 2
Training loss: 1.9162706136703491
Validation loss: 2.0472420205672583

Epoch: 5| Step: 3
Training loss: 2.0747923851013184
Validation loss: 2.057256370782852

Epoch: 5| Step: 4
Training loss: 2.382093667984009
Validation loss: 2.056448221206665

Epoch: 5| Step: 5
Training loss: 1.4737478494644165
Validation loss: 2.050017237663269

Epoch: 5| Step: 6
Training loss: 2.0923218727111816
Validation loss: 2.045823703209559

Epoch: 5| Step: 7
Training loss: 2.248246669769287
Validation loss: 2.0577635914087296

Epoch: 5| Step: 8
Training loss: 1.9184211492538452
Validation loss: 2.0475714008013406

Epoch: 5| Step: 9
Training loss: 2.1305134296417236
Validation loss: 2.050603692730268

Epoch: 5| Step: 10
Training loss: 1.8220999240875244
Validation loss: 2.053774043917656

Epoch: 5| Step: 11
Training loss: 1.8201497793197632
Validation loss: 2.0651677548885345

Epoch: 189| Step: 0
Training loss: 2.270439386367798
Validation loss: 2.0614811728398004

Epoch: 5| Step: 1
Training loss: 2.060922622680664
Validation loss: 2.0692757964134216

Epoch: 5| Step: 2
Training loss: 1.991567611694336
Validation loss: 2.063181777795156

Epoch: 5| Step: 3
Training loss: 1.906862497329712
Validation loss: 2.0791770170132318

Epoch: 5| Step: 4
Training loss: 1.6814587116241455
Validation loss: 2.0687932819128036

Epoch: 5| Step: 5
Training loss: 1.967657446861267
Validation loss: 2.073207567135493

Epoch: 5| Step: 6
Training loss: 1.387897253036499
Validation loss: 2.063096761703491

Epoch: 5| Step: 7
Training loss: 2.3476176261901855
Validation loss: 2.0555239220460257

Epoch: 5| Step: 8
Training loss: 2.3177430629730225
Validation loss: 2.064878225326538

Epoch: 5| Step: 9
Training loss: 1.6714887619018555
Validation loss: 2.0815407236417136

Epoch: 5| Step: 10
Training loss: 2.361536979675293
Validation loss: 2.0572288980086646

Epoch: 5| Step: 11
Training loss: 2.0700230598449707
Validation loss: 2.0675617704788842

Epoch: 190| Step: 0
Training loss: 2.453336715698242
Validation loss: 2.0628523528575897

Epoch: 5| Step: 1
Training loss: 2.4345703125
Validation loss: 2.0554379920164743

Epoch: 5| Step: 2
Training loss: 1.9702198505401611
Validation loss: 2.0615662386020026

Epoch: 5| Step: 3
Training loss: 2.3822853565216064
Validation loss: 2.0550242513418198

Epoch: 5| Step: 4
Training loss: 1.8741371631622314
Validation loss: 2.063975269595782

Epoch: 5| Step: 5
Training loss: 2.466045618057251
Validation loss: 2.0581476390361786

Epoch: 5| Step: 6
Training loss: 1.9111064672470093
Validation loss: 2.070004125436147

Epoch: 5| Step: 7
Training loss: 1.3180091381072998
Validation loss: 2.050708914796511

Epoch: 5| Step: 8
Training loss: 1.945493459701538
Validation loss: 2.062504897514979

Epoch: 5| Step: 9
Training loss: 1.7865049839019775
Validation loss: 2.0701941748460135

Epoch: 5| Step: 10
Training loss: 1.7278482913970947
Validation loss: 2.052852769692739

Epoch: 5| Step: 11
Training loss: 0.47117334604263306
Validation loss: 2.0640705476204553

Epoch: 191| Step: 0
Training loss: 1.333215355873108
Validation loss: 2.061502128839493

Epoch: 5| Step: 1
Training loss: 2.876451015472412
Validation loss: 2.059567868709564

Epoch: 5| Step: 2
Training loss: 1.8637571334838867
Validation loss: 2.071415588259697

Epoch: 5| Step: 3
Training loss: 2.147179365158081
Validation loss: 2.083523472150167

Epoch: 5| Step: 4
Training loss: 1.6515171527862549
Validation loss: 2.101582561930021

Epoch: 5| Step: 5
Training loss: 2.147571086883545
Validation loss: 2.104384327928225

Epoch: 5| Step: 6
Training loss: 2.0960140228271484
Validation loss: 2.105556363860766

Epoch: 5| Step: 7
Training loss: 2.4539992809295654
Validation loss: 2.100252995888392

Epoch: 5| Step: 8
Training loss: 1.177437424659729
Validation loss: 2.085937132438024

Epoch: 5| Step: 9
Training loss: 2.649832248687744
Validation loss: 2.0742561419804892

Epoch: 5| Step: 10
Training loss: 2.038421630859375
Validation loss: 2.0679120620091758

Epoch: 5| Step: 11
Training loss: 2.094585418701172
Validation loss: 2.0529018392165503

Epoch: 192| Step: 0
Training loss: 2.879218101501465
Validation loss: 2.0525042563676834

Epoch: 5| Step: 1
Training loss: 1.9780315160751343
Validation loss: 2.0389919131994247

Epoch: 5| Step: 2
Training loss: 2.1017963886260986
Validation loss: 2.040155678987503

Epoch: 5| Step: 3
Training loss: 2.259150266647339
Validation loss: 2.043601209918658

Epoch: 5| Step: 4
Training loss: 2.455380916595459
Validation loss: 2.058182934919993

Epoch: 5| Step: 5
Training loss: 1.7877626419067383
Validation loss: 2.056108921766281

Epoch: 5| Step: 6
Training loss: 2.126927375793457
Validation loss: 2.053105726838112

Epoch: 5| Step: 7
Training loss: 1.7648147344589233
Validation loss: 2.062652205427488

Epoch: 5| Step: 8
Training loss: 1.8756059408187866
Validation loss: 2.064118891954422

Epoch: 5| Step: 9
Training loss: 1.930946707725525
Validation loss: 2.0643123785654702

Epoch: 5| Step: 10
Training loss: 1.8303877115249634
Validation loss: 2.0611499349276223

Epoch: 5| Step: 11
Training loss: 1.728839635848999
Validation loss: 2.056829805175463

Epoch: 193| Step: 0
Training loss: 2.257080078125
Validation loss: 2.054218143224716

Epoch: 5| Step: 1
Training loss: 2.005725860595703
Validation loss: 2.036243513226509

Epoch: 5| Step: 2
Training loss: 2.0920987129211426
Validation loss: 2.041620890299479

Epoch: 5| Step: 3
Training loss: 2.2214016914367676
Validation loss: 2.0675762593746185

Epoch: 5| Step: 4
Training loss: 1.2843153476715088
Validation loss: 2.0824869026740394

Epoch: 5| Step: 5
Training loss: 2.2282819747924805
Validation loss: 2.081041311224302

Epoch: 5| Step: 6
Training loss: 1.6844764947891235
Validation loss: 2.080635075767835

Epoch: 5| Step: 7
Training loss: 2.258967399597168
Validation loss: 2.094603250424067

Epoch: 5| Step: 8
Training loss: 2.622776508331299
Validation loss: 2.094284623861313

Epoch: 5| Step: 9
Training loss: 1.9498214721679688
Validation loss: 2.1110038459300995

Epoch: 5| Step: 10
Training loss: 1.8287544250488281
Validation loss: 2.114830950895945

Epoch: 5| Step: 11
Training loss: 0.8567121624946594
Validation loss: 2.0980768154064813

Epoch: 194| Step: 0
Training loss: 2.2208588123321533
Validation loss: 2.088911031683286

Epoch: 5| Step: 1
Training loss: 1.776071548461914
Validation loss: 2.089959964156151

Epoch: 5| Step: 2
Training loss: 1.6457369327545166
Validation loss: 2.066980168223381

Epoch: 5| Step: 3
Training loss: 2.0675148963928223
Validation loss: 2.0684835016727448

Epoch: 5| Step: 4
Training loss: 2.2135634422302246
Validation loss: 2.0838682949543

Epoch: 5| Step: 5
Training loss: 2.134770154953003
Validation loss: 2.0758482118447623

Epoch: 5| Step: 6
Training loss: 1.9140708446502686
Validation loss: 2.0815506180127463

Epoch: 5| Step: 7
Training loss: 1.8766613006591797
Validation loss: 2.0716892033815384

Epoch: 5| Step: 8
Training loss: 2.243760585784912
Validation loss: 2.074097067117691

Epoch: 5| Step: 9
Training loss: 1.9114549160003662
Validation loss: 2.0827725380659103

Epoch: 5| Step: 10
Training loss: 2.0549278259277344
Validation loss: 2.0784985572099686

Epoch: 5| Step: 11
Training loss: 2.6360974311828613
Validation loss: 2.068867176771164

Epoch: 195| Step: 0
Training loss: 1.8187938928604126
Validation loss: 2.090667635202408

Epoch: 5| Step: 1
Training loss: 1.3663432598114014
Validation loss: 2.0952732612689338

Epoch: 5| Step: 2
Training loss: 1.6055800914764404
Validation loss: 2.063397914171219

Epoch: 5| Step: 3
Training loss: 2.398923397064209
Validation loss: 2.075509856144587

Epoch: 5| Step: 4
Training loss: 2.1033108234405518
Validation loss: 2.0831248809893927

Epoch: 5| Step: 5
Training loss: 1.99114990234375
Validation loss: 2.081943308313688

Epoch: 5| Step: 6
Training loss: 1.9442451000213623
Validation loss: 2.0815408676862717

Epoch: 5| Step: 7
Training loss: 2.5335912704467773
Validation loss: 2.074490964412689

Epoch: 5| Step: 8
Training loss: 2.4852709770202637
Validation loss: 2.0612625181674957

Epoch: 5| Step: 9
Training loss: 1.9642738103866577
Validation loss: 2.0737343430519104

Epoch: 5| Step: 10
Training loss: 1.8748527765274048
Validation loss: 2.072370414932569

Epoch: 5| Step: 11
Training loss: 2.1983649730682373
Validation loss: 2.05622590581576

Epoch: 196| Step: 0
Training loss: 2.1123263835906982
Validation loss: 2.047629495461782

Epoch: 5| Step: 1
Training loss: 1.834734320640564
Validation loss: 2.0418190360069275

Epoch: 5| Step: 2
Training loss: 1.437138557434082
Validation loss: 2.04781540731589

Epoch: 5| Step: 3
Training loss: 2.3599941730499268
Validation loss: 2.04126284023126

Epoch: 5| Step: 4
Training loss: 2.17570161819458
Validation loss: 2.040146787961324

Epoch: 5| Step: 5
Training loss: 1.8458219766616821
Validation loss: 2.0423256208499274

Epoch: 5| Step: 6
Training loss: 2.0096263885498047
Validation loss: 2.035916810234388

Epoch: 5| Step: 7
Training loss: 2.1740424633026123
Validation loss: 2.0333041896422706

Epoch: 5| Step: 8
Training loss: 1.7578527927398682
Validation loss: 2.034150242805481

Epoch: 5| Step: 9
Training loss: 1.895768404006958
Validation loss: 2.034675190846125

Epoch: 5| Step: 10
Training loss: 2.450371265411377
Validation loss: 2.0434999565283456

Epoch: 5| Step: 11
Training loss: 1.8250036239624023
Validation loss: 2.0402471125125885

Epoch: 197| Step: 0
Training loss: 2.146472692489624
Validation loss: 2.0520760218302407

Epoch: 5| Step: 1
Training loss: 1.8148361444473267
Validation loss: 2.0402905642986298

Epoch: 5| Step: 2
Training loss: 2.2511134147644043
Validation loss: 2.050216386715571

Epoch: 5| Step: 3
Training loss: 1.4478405714035034
Validation loss: 2.050610805551211

Epoch: 5| Step: 4
Training loss: 2.230145215988159
Validation loss: 2.049560238917669

Epoch: 5| Step: 5
Training loss: 1.6914727687835693
Validation loss: 2.052403931816419

Epoch: 5| Step: 6
Training loss: 2.337573528289795
Validation loss: 2.03924323618412

Epoch: 5| Step: 7
Training loss: 1.4997851848602295
Validation loss: 2.0442688117424646

Epoch: 5| Step: 8
Training loss: 2.161396026611328
Validation loss: 2.050686980287234

Epoch: 5| Step: 9
Training loss: 2.3094000816345215
Validation loss: 2.069586917757988

Epoch: 5| Step: 10
Training loss: 1.7601693868637085
Validation loss: 2.0697964280843735

Epoch: 5| Step: 11
Training loss: 3.3140931129455566
Validation loss: 2.0684229036172233

Epoch: 198| Step: 0
Training loss: 1.6576719284057617
Validation loss: 2.068517744541168

Epoch: 5| Step: 1
Training loss: 1.9600296020507812
Validation loss: 2.0931354761123657

Epoch: 5| Step: 2
Training loss: 2.171931266784668
Validation loss: 2.0976864397525787

Epoch: 5| Step: 3
Training loss: 2.0070180892944336
Validation loss: 2.0968389958143234

Epoch: 5| Step: 4
Training loss: 2.8944263458251953
Validation loss: 2.078828364610672

Epoch: 5| Step: 5
Training loss: 1.7910373210906982
Validation loss: 2.079551334182421

Epoch: 5| Step: 6
Training loss: 1.6945346593856812
Validation loss: 2.0623269925514855

Epoch: 5| Step: 7
Training loss: 1.9674841165542603
Validation loss: 2.0475694040457406

Epoch: 5| Step: 8
Training loss: 2.198355197906494
Validation loss: 2.05123840769132

Epoch: 5| Step: 9
Training loss: 2.2784619331359863
Validation loss: 2.04391743739446

Epoch: 5| Step: 10
Training loss: 1.7307941913604736
Validation loss: 2.0548947552839913

Epoch: 5| Step: 11
Training loss: 0.8445577621459961
Validation loss: 2.0480118145545325

Epoch: 199| Step: 0
Training loss: 2.4750189781188965
Validation loss: 2.0472946067651114

Epoch: 5| Step: 1
Training loss: 2.2020602226257324
Validation loss: 2.042360151807467

Epoch: 5| Step: 2
Training loss: 2.187708616256714
Validation loss: 2.0583492815494537

Epoch: 5| Step: 3
Training loss: 1.6883914470672607
Validation loss: 2.066413164138794

Epoch: 5| Step: 4
Training loss: 1.6334117650985718
Validation loss: 2.0742186456918716

Epoch: 5| Step: 5
Training loss: 1.3812875747680664
Validation loss: 2.0817619264125824

Epoch: 5| Step: 6
Training loss: 1.9138199090957642
Validation loss: 2.084177886446317

Epoch: 5| Step: 7
Training loss: 2.0403342247009277
Validation loss: 2.106610601147016

Epoch: 5| Step: 8
Training loss: 2.05206298828125
Validation loss: 2.1064220666885376

Epoch: 5| Step: 9
Training loss: 2.026925563812256
Validation loss: 2.122600813706716

Epoch: 5| Step: 10
Training loss: 2.4267845153808594
Validation loss: 2.1061700880527496

Epoch: 5| Step: 11
Training loss: 2.005472183227539
Validation loss: 2.1059890588124595

Epoch: 200| Step: 0
Training loss: 1.8997141122817993
Validation loss: 2.073110525806745

Epoch: 5| Step: 1
Training loss: 1.8731333017349243
Validation loss: 2.0770393262306848

Epoch: 5| Step: 2
Training loss: 2.086087465286255
Validation loss: 2.067745635906855

Epoch: 5| Step: 3
Training loss: 1.840998649597168
Validation loss: 2.0629577984412513

Epoch: 5| Step: 4
Training loss: 2.000922918319702
Validation loss: 2.0469739784797034

Epoch: 5| Step: 5
Training loss: 2.405006170272827
Validation loss: 2.055670887231827

Epoch: 5| Step: 6
Training loss: 2.289663076400757
Validation loss: 2.0629482865333557

Epoch: 5| Step: 7
Training loss: 2.0757992267608643
Validation loss: 2.0632385909557343

Epoch: 5| Step: 8
Training loss: 2.485668182373047
Validation loss: 2.073024014631907

Epoch: 5| Step: 9
Training loss: 2.1931447982788086
Validation loss: 2.0663470129172006

Epoch: 5| Step: 10
Training loss: 1.6199169158935547
Validation loss: 2.0595448364814124

Epoch: 5| Step: 11
Training loss: 2.2212016582489014
Validation loss: 2.0587165306011834

Epoch: 201| Step: 0
Training loss: 1.7983577251434326
Validation loss: 2.052931179602941

Epoch: 5| Step: 1
Training loss: 1.6577129364013672
Validation loss: 2.054911255836487

Epoch: 5| Step: 2
Training loss: 2.2983391284942627
Validation loss: 2.060429205497106

Epoch: 5| Step: 3
Training loss: 1.7726919651031494
Validation loss: 2.0517196456591287

Epoch: 5| Step: 4
Training loss: 1.8139785528182983
Validation loss: 2.0484464317560196

Epoch: 5| Step: 5
Training loss: 2.621342658996582
Validation loss: 2.0599889755249023

Epoch: 5| Step: 6
Training loss: 1.4097366333007812
Validation loss: 2.0683545768260956

Epoch: 5| Step: 7
Training loss: 2.819317579269409
Validation loss: 2.069233477115631

Epoch: 5| Step: 8
Training loss: 1.635162115097046
Validation loss: 2.067579915126165

Epoch: 5| Step: 9
Training loss: 2.6912314891815186
Validation loss: 2.093363324801127

Epoch: 5| Step: 10
Training loss: 1.3723256587982178
Validation loss: 2.0876764555772147

Epoch: 5| Step: 11
Training loss: 1.665720820426941
Validation loss: 2.0958732614914575

Epoch: 202| Step: 0
Training loss: 2.6162872314453125
Validation loss: 2.1114371915658317

Epoch: 5| Step: 1
Training loss: 2.0839645862579346
Validation loss: 2.1047047128280005

Epoch: 5| Step: 2
Training loss: 2.4399657249450684
Validation loss: 2.0940575699011483

Epoch: 5| Step: 3
Training loss: 1.5358104705810547
Validation loss: 2.084571033716202

Epoch: 5| Step: 4
Training loss: 1.9054197072982788
Validation loss: 2.0823739568392434

Epoch: 5| Step: 5
Training loss: 1.891116738319397
Validation loss: 2.0839651773373284

Epoch: 5| Step: 6
Training loss: 2.074094295501709
Validation loss: 2.0801528791586557

Epoch: 5| Step: 7
Training loss: 1.6654393672943115
Validation loss: 2.077956885099411

Epoch: 5| Step: 8
Training loss: 2.15815806388855
Validation loss: 2.0737431943416595

Epoch: 5| Step: 9
Training loss: 1.8288896083831787
Validation loss: 2.076121280590693

Epoch: 5| Step: 10
Training loss: 2.066892147064209
Validation loss: 2.077233915527662

Epoch: 5| Step: 11
Training loss: 1.8386467695236206
Validation loss: 2.087271278103193

Epoch: 203| Step: 0
Training loss: 2.378011703491211
Validation loss: 2.0946212808291116

Epoch: 5| Step: 1
Training loss: 2.079789876937866
Validation loss: 2.114940961201986

Epoch: 5| Step: 2
Training loss: 1.9974186420440674
Validation loss: 2.1272678126891456

Epoch: 5| Step: 3
Training loss: 1.9820568561553955
Validation loss: 2.1396137724320092

Epoch: 5| Step: 4
Training loss: 2.4942240715026855
Validation loss: 2.1337902545928955

Epoch: 5| Step: 5
Training loss: 1.6567027568817139
Validation loss: 2.1215290476878486

Epoch: 5| Step: 6
Training loss: 2.0879123210906982
Validation loss: 2.118644376595815

Epoch: 5| Step: 7
Training loss: 1.808612585067749
Validation loss: 2.1167194098234177

Epoch: 5| Step: 8
Training loss: 1.7716268301010132
Validation loss: 2.106405188639959

Epoch: 5| Step: 9
Training loss: 2.2350845336914062
Validation loss: 2.1031520466009774

Epoch: 5| Step: 10
Training loss: 1.8040955066680908
Validation loss: 2.090864290793737

Epoch: 5| Step: 11
Training loss: 0.824379563331604
Validation loss: 2.074853092432022

Epoch: 204| Step: 0
Training loss: 1.361495018005371
Validation loss: 2.0674023926258087

Epoch: 5| Step: 1
Training loss: 2.1036152839660645
Validation loss: 2.076910828550657

Epoch: 5| Step: 2
Training loss: 2.298764705657959
Validation loss: 2.0597293923298516

Epoch: 5| Step: 3
Training loss: 2.0432841777801514
Validation loss: 2.062074452638626

Epoch: 5| Step: 4
Training loss: 2.6042990684509277
Validation loss: 2.072320501009623

Epoch: 5| Step: 5
Training loss: 1.9960416555404663
Validation loss: 2.0720037519931793

Epoch: 5| Step: 6
Training loss: 2.2651636600494385
Validation loss: 2.0711722870667777

Epoch: 5| Step: 7
Training loss: 1.5199846029281616
Validation loss: 2.068855141599973

Epoch: 5| Step: 8
Training loss: 1.654264211654663
Validation loss: 2.0625998427470527

Epoch: 5| Step: 9
Training loss: 2.0159811973571777
Validation loss: 2.073390622933706

Epoch: 5| Step: 10
Training loss: 1.9854614734649658
Validation loss: 2.081957623362541

Epoch: 5| Step: 11
Training loss: 1.456224799156189
Validation loss: 2.0746803879737854

Epoch: 205| Step: 0
Training loss: 2.0370936393737793
Validation loss: 2.0805648366610208

Epoch: 5| Step: 1
Training loss: 1.8540477752685547
Validation loss: 2.0935108015934625

Epoch: 5| Step: 2
Training loss: 1.6193691492080688
Validation loss: 2.0932004501422248

Epoch: 5| Step: 3
Training loss: 1.770817756652832
Validation loss: 2.10533806681633

Epoch: 5| Step: 4
Training loss: 1.6658728122711182
Validation loss: 2.1031035284201303

Epoch: 5| Step: 5
Training loss: 1.9002256393432617
Validation loss: 2.118943601846695

Epoch: 5| Step: 6
Training loss: 1.6794859170913696
Validation loss: 2.0965619534254074

Epoch: 5| Step: 7
Training loss: 2.4525394439697266
Validation loss: 2.0862407237291336

Epoch: 5| Step: 8
Training loss: 2.2146236896514893
Validation loss: 2.0902412037054696

Epoch: 5| Step: 9
Training loss: 2.087364435195923
Validation loss: 2.085589955250422

Epoch: 5| Step: 10
Training loss: 2.7504305839538574
Validation loss: 2.0854705522457757

Epoch: 5| Step: 11
Training loss: 1.5283079147338867
Validation loss: 2.063214600086212

Epoch: 206| Step: 0
Training loss: 1.598056435585022
Validation loss: 2.0716063926617303

Epoch: 5| Step: 1
Training loss: 2.121645450592041
Validation loss: 2.0701503654321036

Epoch: 5| Step: 2
Training loss: 1.519573450088501
Validation loss: 2.0695992708206177

Epoch: 5| Step: 3
Training loss: 1.7991828918457031
Validation loss: 2.0642607659101486

Epoch: 5| Step: 4
Training loss: 1.9326435327529907
Validation loss: 2.062456632653872

Epoch: 5| Step: 5
Training loss: 2.0179941654205322
Validation loss: 2.0758529553810754

Epoch: 5| Step: 6
Training loss: 2.8668994903564453
Validation loss: 2.0710114588340125

Epoch: 5| Step: 7
Training loss: 2.398616313934326
Validation loss: 2.0857645322879157

Epoch: 5| Step: 8
Training loss: 1.7646591663360596
Validation loss: 2.0794972827037177

Epoch: 5| Step: 9
Training loss: 1.7270673513412476
Validation loss: 2.0905702859163284

Epoch: 5| Step: 10
Training loss: 2.095425605773926
Validation loss: 2.0856484721104303

Epoch: 5| Step: 11
Training loss: 3.0292739868164062
Validation loss: 2.083695928255717

Epoch: 207| Step: 0
Training loss: 1.7333014011383057
Validation loss: 2.084461952249209

Epoch: 5| Step: 1
Training loss: 2.022688388824463
Validation loss: 2.0651411712169647

Epoch: 5| Step: 2
Training loss: 2.0998566150665283
Validation loss: 2.063842629392942

Epoch: 5| Step: 3
Training loss: 1.959326982498169
Validation loss: 2.057060167193413

Epoch: 5| Step: 4
Training loss: 2.223417282104492
Validation loss: 2.050328011314074

Epoch: 5| Step: 5
Training loss: 1.7773841619491577
Validation loss: 2.05605178574721

Epoch: 5| Step: 6
Training loss: 2.296410083770752
Validation loss: 2.045146862665812

Epoch: 5| Step: 7
Training loss: 2.15539813041687
Validation loss: 2.0767555981874466

Epoch: 5| Step: 8
Training loss: 2.1392674446105957
Validation loss: 2.0714218467473984

Epoch: 5| Step: 9
Training loss: 1.5091817378997803
Validation loss: 2.065566837787628

Epoch: 5| Step: 10
Training loss: 2.172667980194092
Validation loss: 2.0875397324562073

Epoch: 5| Step: 11
Training loss: 1.8012888431549072
Validation loss: 2.0737228790918985

Epoch: 208| Step: 0
Training loss: 2.2414469718933105
Validation loss: 2.0817313541968665

Epoch: 5| Step: 1
Training loss: 1.7106704711914062
Validation loss: 2.105880399545034

Epoch: 5| Step: 2
Training loss: 1.5868009328842163
Validation loss: 2.1049843629201255

Epoch: 5| Step: 3
Training loss: 1.8155800104141235
Validation loss: 2.1026588628689447

Epoch: 5| Step: 4
Training loss: 2.1129937171936035
Validation loss: 2.1003603438536325

Epoch: 5| Step: 5
Training loss: 2.309767007827759
Validation loss: 2.105922977129618

Epoch: 5| Step: 6
Training loss: 1.8931372165679932
Validation loss: 2.103076775868734

Epoch: 5| Step: 7
Training loss: 2.2527029514312744
Validation loss: 2.1040087987979255

Epoch: 5| Step: 8
Training loss: 2.01409912109375
Validation loss: 2.095259507497152

Epoch: 5| Step: 9
Training loss: 1.9287303686141968
Validation loss: 2.089470083514849

Epoch: 5| Step: 10
Training loss: 2.0393729209899902
Validation loss: 2.075984155138334

Epoch: 5| Step: 11
Training loss: 1.9473313093185425
Validation loss: 2.079016700387001

Epoch: 209| Step: 0
Training loss: 1.923137903213501
Validation loss: 2.054728349049886

Epoch: 5| Step: 1
Training loss: 2.1009597778320312
Validation loss: 2.054794947306315

Epoch: 5| Step: 2
Training loss: 1.7957950830459595
Validation loss: 2.058136522769928

Epoch: 5| Step: 3
Training loss: 1.9649232625961304
Validation loss: 2.064703196287155

Epoch: 5| Step: 4
Training loss: 2.6302413940429688
Validation loss: 2.069959878921509

Epoch: 5| Step: 5
Training loss: 1.7524341344833374
Validation loss: 2.061866576472918

Epoch: 5| Step: 6
Training loss: 1.7957435846328735
Validation loss: 2.0552574545145035

Epoch: 5| Step: 7
Training loss: 2.1586904525756836
Validation loss: 2.0771213273207345

Epoch: 5| Step: 8
Training loss: 1.9139328002929688
Validation loss: 2.073585346341133

Epoch: 5| Step: 9
Training loss: 2.1383776664733887
Validation loss: 2.0895163863897324

Epoch: 5| Step: 10
Training loss: 1.775763750076294
Validation loss: 2.0862804551919303

Epoch: 5| Step: 11
Training loss: 2.1740427017211914
Validation loss: 2.082678332924843

Epoch: 210| Step: 0
Training loss: 1.91603684425354
Validation loss: 2.083381618062655

Epoch: 5| Step: 1
Training loss: 1.810091257095337
Validation loss: 2.08705173432827

Epoch: 5| Step: 2
Training loss: 1.9009945392608643
Validation loss: 2.077625801165899

Epoch: 5| Step: 3
Training loss: 2.0418121814727783
Validation loss: 2.0843778600295386

Epoch: 5| Step: 4
Training loss: 2.17447566986084
Validation loss: 2.0699751327435174

Epoch: 5| Step: 5
Training loss: 2.314753293991089
Validation loss: 2.087544093529383

Epoch: 5| Step: 6
Training loss: 2.069809913635254
Validation loss: 2.0868759800990424

Epoch: 5| Step: 7
Training loss: 1.993475317955017
Validation loss: 2.0785955687363944

Epoch: 5| Step: 8
Training loss: 1.8336445093154907
Validation loss: 2.0625185122092566

Epoch: 5| Step: 9
Training loss: 1.9042609930038452
Validation loss: 2.059108962615331

Epoch: 5| Step: 10
Training loss: 1.9688516855239868
Validation loss: 2.068236847718557

Epoch: 5| Step: 11
Training loss: 2.598902463912964
Validation loss: 2.0665649473667145

Epoch: 211| Step: 0
Training loss: 1.86465322971344
Validation loss: 2.0736765563488007

Epoch: 5| Step: 1
Training loss: 1.7169342041015625
Validation loss: 2.0860716899236045

Epoch: 5| Step: 2
Training loss: 1.355554461479187
Validation loss: 2.086215486129125

Epoch: 5| Step: 3
Training loss: 2.2960288524627686
Validation loss: 2.0868955751260123

Epoch: 5| Step: 4
Training loss: 2.032069444656372
Validation loss: 2.078229750196139

Epoch: 5| Step: 5
Training loss: 2.4325942993164062
Validation loss: 2.097554718454679

Epoch: 5| Step: 6
Training loss: 2.2555510997772217
Validation loss: 2.1054683725039163

Epoch: 5| Step: 7
Training loss: 1.2981880903244019
Validation loss: 2.0872645576794944

Epoch: 5| Step: 8
Training loss: 2.1728644371032715
Validation loss: 2.0891918937365213

Epoch: 5| Step: 9
Training loss: 2.2159206867218018
Validation loss: 2.0822498152653375

Epoch: 5| Step: 10
Training loss: 2.1561291217803955
Validation loss: 2.0924366861581802

Epoch: 5| Step: 11
Training loss: 2.470276117324829
Validation loss: 2.100619852542877

Epoch: 212| Step: 0
Training loss: 2.361309051513672
Validation loss: 2.0868734469016395

Epoch: 5| Step: 1
Training loss: 1.7442054748535156
Validation loss: 2.088062822818756

Epoch: 5| Step: 2
Training loss: 1.5095422267913818
Validation loss: 2.0965712865193686

Epoch: 5| Step: 3
Training loss: 1.7618417739868164
Validation loss: 2.092501958211263

Epoch: 5| Step: 4
Training loss: 1.6849753856658936
Validation loss: 2.1000230560700097

Epoch: 5| Step: 5
Training loss: 1.75711190700531
Validation loss: 2.1012283315261207

Epoch: 5| Step: 6
Training loss: 2.5646166801452637
Validation loss: 2.108588288227717

Epoch: 5| Step: 7
Training loss: 1.451756477355957
Validation loss: 2.102098340789477

Epoch: 5| Step: 8
Training loss: 2.682492733001709
Validation loss: 2.1092671702305474

Epoch: 5| Step: 9
Training loss: 1.7138011455535889
Validation loss: 2.0894018560647964

Epoch: 5| Step: 10
Training loss: 2.0938220024108887
Validation loss: 2.0920542627573013

Epoch: 5| Step: 11
Training loss: 2.738375186920166
Validation loss: 2.085034415125847

Epoch: 213| Step: 0
Training loss: 2.0254929065704346
Validation loss: 2.0860197643438974

Epoch: 5| Step: 1
Training loss: 2.2975807189941406
Validation loss: 2.0885261644919715

Epoch: 5| Step: 2
Training loss: 1.9603230953216553
Validation loss: 2.07994481921196

Epoch: 5| Step: 3
Training loss: 1.1018173694610596
Validation loss: 2.0776911278565726

Epoch: 5| Step: 4
Training loss: 2.3063197135925293
Validation loss: 2.0747444232304892

Epoch: 5| Step: 5
Training loss: 1.7167940139770508
Validation loss: 2.0870906114578247

Epoch: 5| Step: 6
Training loss: 1.8791491985321045
Validation loss: 2.0830322355031967

Epoch: 5| Step: 7
Training loss: 1.7264560461044312
Validation loss: 2.0789845238129296

Epoch: 5| Step: 8
Training loss: 2.2131664752960205
Validation loss: 2.085789978504181

Epoch: 5| Step: 9
Training loss: 2.5422987937927246
Validation loss: 2.0850116312503815

Epoch: 5| Step: 10
Training loss: 2.0262787342071533
Validation loss: 2.1045177578926086

Epoch: 5| Step: 11
Training loss: 1.9046661853790283
Validation loss: 2.0929893106222153

Epoch: 214| Step: 0
Training loss: 1.8171765804290771
Validation loss: 2.0955986082553864

Epoch: 5| Step: 1
Training loss: 1.8766844272613525
Validation loss: 2.0759656677643457

Epoch: 5| Step: 2
Training loss: 1.7176437377929688
Validation loss: 2.0821381360292435

Epoch: 5| Step: 3
Training loss: 2.3523569107055664
Validation loss: 2.0814648419618607

Epoch: 5| Step: 4
Training loss: 1.8337364196777344
Validation loss: 2.0754785190025964

Epoch: 5| Step: 5
Training loss: 2.304227113723755
Validation loss: 2.0764967600504556

Epoch: 5| Step: 6
Training loss: 2.2945854663848877
Validation loss: 2.070288081963857

Epoch: 5| Step: 7
Training loss: 2.002892017364502
Validation loss: 2.0720612853765488

Epoch: 5| Step: 8
Training loss: 1.8559370040893555
Validation loss: 2.074275940656662

Epoch: 5| Step: 9
Training loss: 1.7680457830429077
Validation loss: 2.0634475549062095

Epoch: 5| Step: 10
Training loss: 1.8854042291641235
Validation loss: 2.06942850848039

Epoch: 5| Step: 11
Training loss: 2.826054573059082
Validation loss: 2.077036445339521

Epoch: 215| Step: 0
Training loss: 1.9738187789916992
Validation loss: 2.079916760325432

Epoch: 5| Step: 1
Training loss: 1.9680086374282837
Validation loss: 2.086503138144811

Epoch: 5| Step: 2
Training loss: 1.6436164379119873
Validation loss: 2.079312483469645

Epoch: 5| Step: 3
Training loss: 1.645451545715332
Validation loss: 2.0800016671419144

Epoch: 5| Step: 4
Training loss: 2.4328694343566895
Validation loss: 2.091110944747925

Epoch: 5| Step: 5
Training loss: 2.3716986179351807
Validation loss: 2.092532674471537

Epoch: 5| Step: 6
Training loss: 1.7263381481170654
Validation loss: 2.101597194870313

Epoch: 5| Step: 7
Training loss: 2.040283679962158
Validation loss: 2.085779845714569

Epoch: 5| Step: 8
Training loss: 2.0550577640533447
Validation loss: 2.0945375760396323

Epoch: 5| Step: 9
Training loss: 2.0431294441223145
Validation loss: 2.0859440515438714

Epoch: 5| Step: 10
Training loss: 1.7638143301010132
Validation loss: 2.0898479223251343

Epoch: 5| Step: 11
Training loss: 0.8617401123046875
Validation loss: 2.0769131630659103

Epoch: 216| Step: 0
Training loss: 2.2048709392547607
Validation loss: 2.099688326319059

Epoch: 5| Step: 1
Training loss: 2.227429151535034
Validation loss: 2.09463203450044

Epoch: 5| Step: 2
Training loss: 2.122368574142456
Validation loss: 2.0886271943648658

Epoch: 5| Step: 3
Training loss: 1.8776204586029053
Validation loss: 2.1030057768026986

Epoch: 5| Step: 4
Training loss: 2.006211042404175
Validation loss: 2.083409905433655

Epoch: 5| Step: 5
Training loss: 1.572234034538269
Validation loss: 2.096097081899643

Epoch: 5| Step: 6
Training loss: 1.3984688520431519
Validation loss: 2.0905775129795074

Epoch: 5| Step: 7
Training loss: 1.5128947496414185
Validation loss: 2.0848076144854226

Epoch: 5| Step: 8
Training loss: 2.0305721759796143
Validation loss: 2.098596235116323

Epoch: 5| Step: 9
Training loss: 2.4467897415161133
Validation loss: 2.087780957420667

Epoch: 5| Step: 10
Training loss: 2.039738893508911
Validation loss: 2.0758102536201477

Epoch: 5| Step: 11
Training loss: 2.420745372772217
Validation loss: 2.0743020474910736

Epoch: 217| Step: 0
Training loss: 1.4186427593231201
Validation loss: 2.06867578625679

Epoch: 5| Step: 1
Training loss: 2.1881206035614014
Validation loss: 2.0847797989845276

Epoch: 5| Step: 2
Training loss: 2.2153265476226807
Validation loss: 2.0873632232348123

Epoch: 5| Step: 3
Training loss: 1.8734689950942993
Validation loss: 2.0911878546079

Epoch: 5| Step: 4
Training loss: 1.762128472328186
Validation loss: 2.0910470485687256

Epoch: 5| Step: 5
Training loss: 2.0400779247283936
Validation loss: 2.098011960585912

Epoch: 5| Step: 6
Training loss: 1.8176677227020264
Validation loss: 2.085977464914322

Epoch: 5| Step: 7
Training loss: 1.922204613685608
Validation loss: 2.0911929607391357

Epoch: 5| Step: 8
Training loss: 2.0466716289520264
Validation loss: 2.0862448712189994

Epoch: 5| Step: 9
Training loss: 2.3439996242523193
Validation loss: 2.09607403477033

Epoch: 5| Step: 10
Training loss: 1.7500801086425781
Validation loss: 2.1002474327882132

Epoch: 5| Step: 11
Training loss: 1.847665786743164
Validation loss: 2.1047930270433426

Epoch: 218| Step: 0
Training loss: 2.661350727081299
Validation loss: 2.1127833177646003

Epoch: 5| Step: 1
Training loss: 2.047731876373291
Validation loss: 2.123263036211332

Epoch: 5| Step: 2
Training loss: 2.0400583744049072
Validation loss: 2.1206635733445487

Epoch: 5| Step: 3
Training loss: 1.9575159549713135
Validation loss: 2.121191163857778

Epoch: 5| Step: 4
Training loss: 2.6134092807769775
Validation loss: 2.117208023866018

Epoch: 5| Step: 5
Training loss: 1.6121530532836914
Validation loss: 2.1285809377829232

Epoch: 5| Step: 6
Training loss: 2.1026365756988525
Validation loss: 2.10912948846817

Epoch: 5| Step: 7
Training loss: 1.9673948287963867
Validation loss: 2.1012069632609687

Epoch: 5| Step: 8
Training loss: 1.5272800922393799
Validation loss: 2.093695655465126

Epoch: 5| Step: 9
Training loss: 1.5905683040618896
Validation loss: 2.0813207228978476

Epoch: 5| Step: 10
Training loss: 2.0121731758117676
Validation loss: 2.085678125421206

Epoch: 5| Step: 11
Training loss: 0.8785767555236816
Validation loss: 2.081779569387436

Epoch: 219| Step: 0
Training loss: 1.49988853931427
Validation loss: 2.0873591055472693

Epoch: 5| Step: 1
Training loss: 2.605346441268921
Validation loss: 2.085411086678505

Epoch: 5| Step: 2
Training loss: 1.5623955726623535
Validation loss: 2.096953719854355

Epoch: 5| Step: 3
Training loss: 1.8758131265640259
Validation loss: 2.0997631400823593

Epoch: 5| Step: 4
Training loss: 2.0961532592773438
Validation loss: 2.092251424988111

Epoch: 5| Step: 5
Training loss: 2.0506978034973145
Validation loss: 2.099981874227524

Epoch: 5| Step: 6
Training loss: 2.1513619422912598
Validation loss: 2.109460880359014

Epoch: 5| Step: 7
Training loss: 1.5764210224151611
Validation loss: 2.0811895628770194

Epoch: 5| Step: 8
Training loss: 1.6721004247665405
Validation loss: 2.091351186235746

Epoch: 5| Step: 9
Training loss: 2.161040782928467
Validation loss: 2.0884525229533515

Epoch: 5| Step: 10
Training loss: 2.2628347873687744
Validation loss: 2.0782198756933212

Epoch: 5| Step: 11
Training loss: 2.324375629425049
Validation loss: 2.075852612654368

Epoch: 220| Step: 0
Training loss: 1.9435497522354126
Validation loss: 2.0659618824720383

Epoch: 5| Step: 1
Training loss: 1.4932621717453003
Validation loss: 2.0866974592208862

Epoch: 5| Step: 2
Training loss: 2.1339597702026367
Validation loss: 2.087562491496404

Epoch: 5| Step: 3
Training loss: 2.3405261039733887
Validation loss: 2.0873833944400153

Epoch: 5| Step: 4
Training loss: 2.1984188556671143
Validation loss: 2.093568116426468

Epoch: 5| Step: 5
Training loss: 2.1243033409118652
Validation loss: 2.0997232298056283

Epoch: 5| Step: 6
Training loss: 2.114799737930298
Validation loss: 2.1071427712837854

Epoch: 5| Step: 7
Training loss: 1.9373308420181274
Validation loss: 2.110518659154574

Epoch: 5| Step: 8
Training loss: 2.1412899494171143
Validation loss: 2.102101137240728

Epoch: 5| Step: 9
Training loss: 1.3820194005966187
Validation loss: 2.0967400868733725

Epoch: 5| Step: 10
Training loss: 1.6632322072982788
Validation loss: 2.099977970123291

Epoch: 5| Step: 11
Training loss: 3.2841970920562744
Validation loss: 2.08927720785141

Epoch: 221| Step: 0
Training loss: 1.7755310535430908
Validation loss: 2.0933543294668198

Epoch: 5| Step: 1
Training loss: 1.628363847732544
Validation loss: 2.0801974534988403

Epoch: 5| Step: 2
Training loss: 2.1414904594421387
Validation loss: 2.0742175032695136

Epoch: 5| Step: 3
Training loss: 2.0520405769348145
Validation loss: 2.0691066781679788

Epoch: 5| Step: 4
Training loss: 2.329153060913086
Validation loss: 2.0632580717404685

Epoch: 5| Step: 5
Training loss: 1.7376514673233032
Validation loss: 2.0697132647037506

Epoch: 5| Step: 6
Training loss: 1.6980422735214233
Validation loss: 2.0603175163269043

Epoch: 5| Step: 7
Training loss: 1.7483408451080322
Validation loss: 2.064070910215378

Epoch: 5| Step: 8
Training loss: 2.1621813774108887
Validation loss: 2.0618701775868735

Epoch: 5| Step: 9
Training loss: 2.4841339588165283
Validation loss: 2.0631014506022134

Epoch: 5| Step: 10
Training loss: 2.2065625190734863
Validation loss: 2.0578249245882034

Epoch: 5| Step: 11
Training loss: 1.0712450742721558
Validation loss: 2.065517634153366

Epoch: 222| Step: 0
Training loss: 2.2431986331939697
Validation loss: 2.0631957054138184

Epoch: 5| Step: 1
Training loss: 1.5215564966201782
Validation loss: 2.0682208935419717

Epoch: 5| Step: 2
Training loss: 1.584139108657837
Validation loss: 2.0833535144726434

Epoch: 5| Step: 3
Training loss: 1.708713173866272
Validation loss: 2.0956154813369117

Epoch: 5| Step: 4
Training loss: 1.7739803791046143
Validation loss: 2.0909147411584854

Epoch: 5| Step: 5
Training loss: 2.0508580207824707
Validation loss: 2.0905901541312537

Epoch: 5| Step: 6
Training loss: 2.247281789779663
Validation loss: 2.0915398051341376

Epoch: 5| Step: 7
Training loss: 1.6622645854949951
Validation loss: 2.0770581861337027

Epoch: 5| Step: 8
Training loss: 1.9866971969604492
Validation loss: 2.0800436586141586

Epoch: 5| Step: 9
Training loss: 2.5497260093688965
Validation loss: 2.0813961923122406

Epoch: 5| Step: 10
Training loss: 2.2661404609680176
Validation loss: 2.072952156265577

Epoch: 5| Step: 11
Training loss: 2.5025148391723633
Validation loss: 2.0779110193252563

Epoch: 223| Step: 0
Training loss: 1.6838937997817993
Validation loss: 2.077235316236814

Epoch: 5| Step: 1
Training loss: 2.3545870780944824
Validation loss: 2.066257586081823

Epoch: 5| Step: 2
Training loss: 2.2357852458953857
Validation loss: 2.0525940159956613

Epoch: 5| Step: 3
Training loss: 1.8935123682022095
Validation loss: 2.0544739166895547

Epoch: 5| Step: 4
Training loss: 1.8079931735992432
Validation loss: 2.0695164501667023

Epoch: 5| Step: 5
Training loss: 2.42136812210083
Validation loss: 2.0659501353899636

Epoch: 5| Step: 6
Training loss: 1.9236938953399658
Validation loss: 2.066574196020762

Epoch: 5| Step: 7
Training loss: 1.7577946186065674
Validation loss: 2.067254309852918

Epoch: 5| Step: 8
Training loss: 2.234114408493042
Validation loss: 2.064463719725609

Epoch: 5| Step: 9
Training loss: 2.4811151027679443
Validation loss: 2.068309336900711

Epoch: 5| Step: 10
Training loss: 1.9098857641220093
Validation loss: 2.0562628308931985

Epoch: 5| Step: 11
Training loss: 1.8216242790222168
Validation loss: 2.0656498819589615

Epoch: 224| Step: 0
Training loss: 1.9153261184692383
Validation loss: 2.050353025396665

Epoch: 5| Step: 1
Training loss: 1.8801155090332031
Validation loss: 2.0423025290171304

Epoch: 5| Step: 2
Training loss: 2.0002858638763428
Validation loss: 2.0333898961544037

Epoch: 5| Step: 3
Training loss: 1.8549970388412476
Validation loss: 2.0368734151124954

Epoch: 5| Step: 4
Training loss: 2.4525256156921387
Validation loss: 2.052965139349302

Epoch: 5| Step: 5
Training loss: 2.041273832321167
Validation loss: 2.045520454645157

Epoch: 5| Step: 6
Training loss: 1.9804627895355225
Validation loss: 2.0380028734604516

Epoch: 5| Step: 7
Training loss: 1.9845752716064453
Validation loss: 2.0746338864167533

Epoch: 5| Step: 8
Training loss: 1.4370880126953125
Validation loss: 2.0876980225245156

Epoch: 5| Step: 9
Training loss: 2.5328621864318848
Validation loss: 2.0984529554843903

Epoch: 5| Step: 10
Training loss: 2.1787824630737305
Validation loss: 2.1129714846611023

Epoch: 5| Step: 11
Training loss: 1.513814926147461
Validation loss: 2.0990053762992225

Epoch: 225| Step: 0
Training loss: 1.849717378616333
Validation loss: 2.095589036742846

Epoch: 5| Step: 1
Training loss: 2.211489200592041
Validation loss: 2.068653871615728

Epoch: 5| Step: 2
Training loss: 2.155888557434082
Validation loss: 2.0495612025260925

Epoch: 5| Step: 3
Training loss: 2.1942930221557617
Validation loss: 2.0454048415025077

Epoch: 5| Step: 4
Training loss: 1.7984603643417358
Validation loss: 2.041337172190348

Epoch: 5| Step: 5
Training loss: 2.2726521492004395
Validation loss: 2.031531279285749

Epoch: 5| Step: 6
Training loss: 2.355764865875244
Validation loss: 2.0309138099352517

Epoch: 5| Step: 7
Training loss: 1.4662249088287354
Validation loss: 2.036612848440806

Epoch: 5| Step: 8
Training loss: 2.1453113555908203
Validation loss: 2.0407992055018744

Epoch: 5| Step: 9
Training loss: 2.0354456901550293
Validation loss: 2.0280180672804513

Epoch: 5| Step: 10
Training loss: 1.999475121498108
Validation loss: 2.0420903166135154

Epoch: 5| Step: 11
Training loss: 0.7650012969970703
Validation loss: 2.0354015827178955

Epoch: 226| Step: 0
Training loss: 1.5979007482528687
Validation loss: 2.038726563254992

Epoch: 5| Step: 1
Training loss: 1.9885079860687256
Validation loss: 2.0352596243222556

Epoch: 5| Step: 2
Training loss: 1.6499214172363281
Validation loss: 2.0435850620269775

Epoch: 5| Step: 3
Training loss: 2.1968541145324707
Validation loss: 2.036879782875379

Epoch: 5| Step: 4
Training loss: 1.9835458993911743
Validation loss: 2.0358101377884545

Epoch: 5| Step: 5
Training loss: 1.9865920543670654
Validation loss: 2.0416946609814963

Epoch: 5| Step: 6
Training loss: 1.818509817123413
Validation loss: 2.056959589322408

Epoch: 5| Step: 7
Training loss: 2.4812445640563965
Validation loss: 2.063291067878405

Epoch: 5| Step: 8
Training loss: 2.0189571380615234
Validation loss: 2.0624978691339493

Epoch: 5| Step: 9
Training loss: 1.8687280416488647
Validation loss: 2.0837346017360687

Epoch: 5| Step: 10
Training loss: 2.2656235694885254
Validation loss: 2.0819534957408905

Epoch: 5| Step: 11
Training loss: 2.5216450691223145
Validation loss: 2.0755123098691306

Epoch: 227| Step: 0
Training loss: 2.2017369270324707
Validation loss: 2.081421732902527

Epoch: 5| Step: 1
Training loss: 1.9934002161026
Validation loss: 2.068218390146891

Epoch: 5| Step: 2
Training loss: 1.6326786279678345
Validation loss: 2.080880641937256

Epoch: 5| Step: 3
Training loss: 1.9442081451416016
Validation loss: 2.0818803906440735

Epoch: 5| Step: 4
Training loss: 1.9211227893829346
Validation loss: 2.0987864236036935

Epoch: 5| Step: 5
Training loss: 2.0480103492736816
Validation loss: 2.0970334808031716

Epoch: 5| Step: 6
Training loss: 1.9974311590194702
Validation loss: 2.0901641796032586

Epoch: 5| Step: 7
Training loss: 1.5993009805679321
Validation loss: 2.0735925187667212

Epoch: 5| Step: 8
Training loss: 2.3910789489746094
Validation loss: 2.073498715957006

Epoch: 5| Step: 9
Training loss: 1.9720332622528076
Validation loss: 2.057704125841459

Epoch: 5| Step: 10
Training loss: 2.1111979484558105
Validation loss: 2.0637101382017136

Epoch: 5| Step: 11
Training loss: 0.8719288110733032
Validation loss: 2.0752468407154083

Epoch: 228| Step: 0
Training loss: 2.1411852836608887
Validation loss: 2.0646358033021293

Epoch: 5| Step: 1
Training loss: 1.5679162740707397
Validation loss: 2.0525603890419006

Epoch: 5| Step: 2
Training loss: 1.9303500652313232
Validation loss: 2.061493366956711

Epoch: 5| Step: 3
Training loss: 2.362583637237549
Validation loss: 2.074177766839663

Epoch: 5| Step: 4
Training loss: 2.0661380290985107
Validation loss: 2.067864100138346

Epoch: 5| Step: 5
Training loss: 1.2661182880401611
Validation loss: 2.083056633671125

Epoch: 5| Step: 6
Training loss: 2.1771938800811768
Validation loss: 2.089361766974131

Epoch: 5| Step: 7
Training loss: 1.8779277801513672
Validation loss: 2.075636143485705

Epoch: 5| Step: 8
Training loss: 2.389293670654297
Validation loss: 2.0877548356850943

Epoch: 5| Step: 9
Training loss: 2.0452234745025635
Validation loss: 2.0993723620971045

Epoch: 5| Step: 10
Training loss: 1.9492508172988892
Validation loss: 2.090891261895498

Epoch: 5| Step: 11
Training loss: 2.6339900493621826
Validation loss: 2.094357118010521

Epoch: 229| Step: 0
Training loss: 1.8746881484985352
Validation loss: 2.1136212746302285

Epoch: 5| Step: 1
Training loss: 1.3365005254745483
Validation loss: 2.1140465835730233

Epoch: 5| Step: 2
Training loss: 1.912384271621704
Validation loss: 2.1193551967541375

Epoch: 5| Step: 3
Training loss: 1.6457113027572632
Validation loss: 2.119238336881002

Epoch: 5| Step: 4
Training loss: 2.372067928314209
Validation loss: 2.1180957704782486

Epoch: 5| Step: 5
Training loss: 2.112948417663574
Validation loss: 2.137726758917173

Epoch: 5| Step: 6
Training loss: 2.3175618648529053
Validation loss: 2.1328503489494324

Epoch: 5| Step: 7
Training loss: 2.0459702014923096
Validation loss: 2.12916706999143

Epoch: 5| Step: 8
Training loss: 1.5453128814697266
Validation loss: 2.1209826668103537

Epoch: 5| Step: 9
Training loss: 2.1468052864074707
Validation loss: 2.112229824066162

Epoch: 5| Step: 10
Training loss: 1.922400712966919
Validation loss: 2.117863858739535

Epoch: 5| Step: 11
Training loss: 3.3475685119628906
Validation loss: 2.1049163142840066

Epoch: 230| Step: 0
Training loss: 1.7095234394073486
Validation loss: 2.105716193715731

Epoch: 5| Step: 1
Training loss: 1.665768027305603
Validation loss: 2.0982737640539804

Epoch: 5| Step: 2
Training loss: 1.6836020946502686
Validation loss: 2.09809917708238

Epoch: 5| Step: 3
Training loss: 2.503333568572998
Validation loss: 2.087370047966639

Epoch: 5| Step: 4
Training loss: 2.052570343017578
Validation loss: 2.0978238781293235

Epoch: 5| Step: 5
Training loss: 1.6049652099609375
Validation loss: 2.084760437409083

Epoch: 5| Step: 6
Training loss: 2.3791916370391846
Validation loss: 2.110035037000974

Epoch: 5| Step: 7
Training loss: 2.3621559143066406
Validation loss: 2.092489937941233

Epoch: 5| Step: 8
Training loss: 1.7369464635849
Validation loss: 2.1008774240811667

Epoch: 5| Step: 9
Training loss: 1.6608175039291382
Validation loss: 2.1151986122131348

Epoch: 5| Step: 10
Training loss: 2.091012477874756
Validation loss: 2.1177493184804916

Epoch: 5| Step: 11
Training loss: 1.4041788578033447
Validation loss: 2.1335725535949073

Epoch: 231| Step: 0
Training loss: 1.9787613153457642
Validation loss: 2.1277842024962106

Epoch: 5| Step: 1
Training loss: 2.1029794216156006
Validation loss: 2.114933893084526

Epoch: 5| Step: 2
Training loss: 1.5699108839035034
Validation loss: 2.119841903448105

Epoch: 5| Step: 3
Training loss: 2.0088136196136475
Validation loss: 2.1305285344521203

Epoch: 5| Step: 4
Training loss: 1.6161457300186157
Validation loss: 2.121558114886284

Epoch: 5| Step: 5
Training loss: 1.5829684734344482
Validation loss: 2.119843011101087

Epoch: 5| Step: 6
Training loss: 2.4682793617248535
Validation loss: 2.1104441533486047

Epoch: 5| Step: 7
Training loss: 2.20349383354187
Validation loss: 2.10734715561072

Epoch: 5| Step: 8
Training loss: 1.9405367374420166
Validation loss: 2.101167246699333

Epoch: 5| Step: 9
Training loss: 1.822766661643982
Validation loss: 2.0986817379792533

Epoch: 5| Step: 10
Training loss: 1.7586030960083008
Validation loss: 2.086319883664449

Epoch: 5| Step: 11
Training loss: 2.725536346435547
Validation loss: 2.084087997674942

Epoch: 232| Step: 0
Training loss: 1.7379369735717773
Validation loss: 2.100844293832779

Epoch: 5| Step: 1
Training loss: 2.0055766105651855
Validation loss: 2.0861638287703195

Epoch: 5| Step: 2
Training loss: 2.1859779357910156
Validation loss: 2.099096109469732

Epoch: 5| Step: 3
Training loss: 1.9993282556533813
Validation loss: 2.1165039340655007

Epoch: 5| Step: 4
Training loss: 1.5092118978500366
Validation loss: 2.1083813110987344

Epoch: 5| Step: 5
Training loss: 1.6848751306533813
Validation loss: 2.1062767108281455

Epoch: 5| Step: 6
Training loss: 2.1815121173858643
Validation loss: 2.1124591877063117

Epoch: 5| Step: 7
Training loss: 2.0860724449157715
Validation loss: 2.113435079654058

Epoch: 5| Step: 8
Training loss: 1.9914472103118896
Validation loss: 2.1189450323581696

Epoch: 5| Step: 9
Training loss: 2.3083977699279785
Validation loss: 2.1146142035722733

Epoch: 5| Step: 10
Training loss: 1.646410346031189
Validation loss: 2.1094040671984353

Epoch: 5| Step: 11
Training loss: 1.795060157775879
Validation loss: 2.121347447236379

Epoch: 233| Step: 0
Training loss: 1.990807294845581
Validation loss: 2.1336068908373513

Epoch: 5| Step: 1
Training loss: 2.0252983570098877
Validation loss: 2.1211383243401847

Epoch: 5| Step: 2
Training loss: 1.9254993200302124
Validation loss: 2.1159295390049615

Epoch: 5| Step: 3
Training loss: 1.7737499475479126
Validation loss: 2.096015344063441

Epoch: 5| Step: 4
Training loss: 1.332696557044983
Validation loss: 2.1107968538999557

Epoch: 5| Step: 5
Training loss: 1.8528358936309814
Validation loss: 2.1062786827484765

Epoch: 5| Step: 6
Training loss: 2.4529826641082764
Validation loss: 2.097504829367002

Epoch: 5| Step: 7
Training loss: 1.9076019525527954
Validation loss: 2.10715322693189

Epoch: 5| Step: 8
Training loss: 1.8457263708114624
Validation loss: 2.1012360056241355

Epoch: 5| Step: 9
Training loss: 1.7581431865692139
Validation loss: 2.109739209214846

Epoch: 5| Step: 10
Training loss: 1.9218924045562744
Validation loss: 2.099885016679764

Epoch: 5| Step: 11
Training loss: 3.2712466716766357
Validation loss: 2.108980273207029

Epoch: 234| Step: 0
Training loss: 1.5322364568710327
Validation loss: 2.1161458094914756

Epoch: 5| Step: 1
Training loss: 2.1670284271240234
Validation loss: 2.1272619465986886

Epoch: 5| Step: 2
Training loss: 1.7289167642593384
Validation loss: 2.121267239252726

Epoch: 5| Step: 3
Training loss: 1.732163667678833
Validation loss: 2.1329201757907867

Epoch: 5| Step: 4
Training loss: 1.621530532836914
Validation loss: 2.115870878100395

Epoch: 5| Step: 5
Training loss: 1.9847276210784912
Validation loss: 2.128460148970286

Epoch: 5| Step: 6
Training loss: 2.0555081367492676
Validation loss: 2.1198337574799857

Epoch: 5| Step: 7
Training loss: 1.8147575855255127
Validation loss: 2.113172416885694

Epoch: 5| Step: 8
Training loss: 1.4669058322906494
Validation loss: 2.101403777798017

Epoch: 5| Step: 9
Training loss: 1.9785945415496826
Validation loss: 2.1175381491581597

Epoch: 5| Step: 10
Training loss: 2.846111297607422
Validation loss: 2.1189439594745636

Epoch: 5| Step: 11
Training loss: 3.7587456703186035
Validation loss: 2.1037266155083976

Epoch: 235| Step: 0
Training loss: 1.9830865859985352
Validation loss: 2.113074312607447

Epoch: 5| Step: 1
Training loss: 1.13202702999115
Validation loss: 2.10957403977712

Epoch: 5| Step: 2
Training loss: 1.8985373973846436
Validation loss: 2.106209307909012

Epoch: 5| Step: 3
Training loss: 2.334636926651001
Validation loss: 2.1143452872832618

Epoch: 5| Step: 4
Training loss: 1.5195763111114502
Validation loss: 2.10104538500309

Epoch: 5| Step: 5
Training loss: 1.804953932762146
Validation loss: 2.115007594227791

Epoch: 5| Step: 6
Training loss: 1.9294646978378296
Validation loss: 2.1305847515662513

Epoch: 5| Step: 7
Training loss: 2.322275161743164
Validation loss: 2.1407377123832703

Epoch: 5| Step: 8
Training loss: 2.3523879051208496
Validation loss: 2.1326902359724045

Epoch: 5| Step: 9
Training loss: 1.4485803842544556
Validation loss: 2.1330143064260483

Epoch: 5| Step: 10
Training loss: 2.334249973297119
Validation loss: 2.1218786785999932

Epoch: 5| Step: 11
Training loss: 2.128262519836426
Validation loss: 2.123264029622078

Epoch: 236| Step: 0
Training loss: 2.1021735668182373
Validation loss: 2.1321991781393685

Epoch: 5| Step: 1
Training loss: 1.7895698547363281
Validation loss: 2.124999533096949

Epoch: 5| Step: 2
Training loss: 1.9808216094970703
Validation loss: 2.1130981693665185

Epoch: 5| Step: 3
Training loss: 1.7793794870376587
Validation loss: 2.13899472852548

Epoch: 5| Step: 4
Training loss: 2.3325905799865723
Validation loss: 2.124928504228592

Epoch: 5| Step: 5
Training loss: 1.5859906673431396
Validation loss: 2.14414282143116

Epoch: 5| Step: 6
Training loss: 1.849696159362793
Validation loss: 2.1284417609373727

Epoch: 5| Step: 7
Training loss: 1.934566855430603
Validation loss: 2.128192057212194

Epoch: 5| Step: 8
Training loss: 1.8298444747924805
Validation loss: 2.1168616116046906

Epoch: 5| Step: 9
Training loss: 2.073251724243164
Validation loss: 2.114266981681188

Epoch: 5| Step: 10
Training loss: 1.7669566869735718
Validation loss: 2.1065249194701514

Epoch: 5| Step: 11
Training loss: 2.3356199264526367
Validation loss: 2.1127013017733893

Epoch: 237| Step: 0
Training loss: 2.2831828594207764
Validation loss: 2.100493386387825

Epoch: 5| Step: 1
Training loss: 1.8683061599731445
Validation loss: 2.106649706761042

Epoch: 5| Step: 2
Training loss: 2.516913652420044
Validation loss: 2.1093073040246964

Epoch: 5| Step: 3
Training loss: 1.9928748607635498
Validation loss: 2.1129685988028846

Epoch: 5| Step: 4
Training loss: 1.8814220428466797
Validation loss: 2.1280850569407144

Epoch: 5| Step: 5
Training loss: 1.3719491958618164
Validation loss: 2.111317977309227

Epoch: 5| Step: 6
Training loss: 1.7470569610595703
Validation loss: 2.1321786642074585

Epoch: 5| Step: 7
Training loss: 1.6874462366104126
Validation loss: 2.1271481662988663

Epoch: 5| Step: 8
Training loss: 1.6261060237884521
Validation loss: 2.125655064980189

Epoch: 5| Step: 9
Training loss: 2.356106996536255
Validation loss: 2.113627920548121

Epoch: 5| Step: 10
Training loss: 1.7813243865966797
Validation loss: 2.112905358274778

Epoch: 5| Step: 11
Training loss: 2.1054935455322266
Validation loss: 2.110365683833758

Epoch: 238| Step: 0
Training loss: 2.0263400077819824
Validation loss: 2.107449104388555

Epoch: 5| Step: 1
Training loss: 1.5797879695892334
Validation loss: 2.1104808300733566

Epoch: 5| Step: 2
Training loss: 1.8105928897857666
Validation loss: 2.119984601934751

Epoch: 5| Step: 3
Training loss: 2.1053597927093506
Validation loss: 2.1233708361784616

Epoch: 5| Step: 4
Training loss: 2.1150238513946533
Validation loss: 2.128381446003914

Epoch: 5| Step: 5
Training loss: 2.127514123916626
Validation loss: 2.1235771775245667

Epoch: 5| Step: 6
Training loss: 2.027223587036133
Validation loss: 2.1404469112555184

Epoch: 5| Step: 7
Training loss: 1.592008352279663
Validation loss: 2.1292243897914886

Epoch: 5| Step: 8
Training loss: 2.2724945545196533
Validation loss: 2.1371298879384995

Epoch: 5| Step: 9
Training loss: 1.5669373273849487
Validation loss: 2.140609304110209

Epoch: 5| Step: 10
Training loss: 2.0806703567504883
Validation loss: 2.1333391120036445

Epoch: 5| Step: 11
Training loss: 0.9956610202789307
Validation loss: 2.1355223755041757

Epoch: 239| Step: 0
Training loss: 2.512807846069336
Validation loss: 2.131619398792585

Epoch: 5| Step: 1
Training loss: 1.4015886783599854
Validation loss: 2.1436413129170737

Epoch: 5| Step: 2
Training loss: 1.7042160034179688
Validation loss: 2.1463266015052795

Epoch: 5| Step: 3
Training loss: 1.7032215595245361
Validation loss: 2.126184711853663

Epoch: 5| Step: 4
Training loss: 1.5628563165664673
Validation loss: 2.117286110917727

Epoch: 5| Step: 5
Training loss: 2.143929958343506
Validation loss: 2.1218450367450714

Epoch: 5| Step: 6
Training loss: 2.726073980331421
Validation loss: 2.119541903336843

Epoch: 5| Step: 7
Training loss: 1.9912700653076172
Validation loss: 2.129077265659968

Epoch: 5| Step: 8
Training loss: 1.940345048904419
Validation loss: 2.112678418556849

Epoch: 5| Step: 9
Training loss: 1.5041348934173584
Validation loss: 2.1260855297247567

Epoch: 5| Step: 10
Training loss: 1.8822708129882812
Validation loss: 2.117844879627228

Epoch: 5| Step: 11
Training loss: 0.6988146305084229
Validation loss: 2.1173397501309714

Epoch: 240| Step: 0
Training loss: 2.038698434829712
Validation loss: 2.124399001399676

Epoch: 5| Step: 1
Training loss: 2.235560655593872
Validation loss: 2.1269092162450156

Epoch: 5| Step: 2
Training loss: 2.2866692543029785
Validation loss: 2.1122384468714395

Epoch: 5| Step: 3
Training loss: 1.8546116352081299
Validation loss: 2.1258562753597894

Epoch: 5| Step: 4
Training loss: 1.7232109308242798
Validation loss: 2.1249637504418692

Epoch: 5| Step: 5
Training loss: 1.6804161071777344
Validation loss: 2.1218186914920807

Epoch: 5| Step: 6
Training loss: 2.327425479888916
Validation loss: 2.1308133651812873

Epoch: 5| Step: 7
Training loss: 1.7947221994400024
Validation loss: 2.12459804614385

Epoch: 5| Step: 8
Training loss: 1.6005226373672485
Validation loss: 2.1228064596652985

Epoch: 5| Step: 9
Training loss: 2.096503973007202
Validation loss: 2.1249462912480035

Epoch: 5| Step: 10
Training loss: 1.8293901681900024
Validation loss: 2.1295360922813416

Epoch: 5| Step: 11
Training loss: 0.6422779560089111
Validation loss: 2.1243431319793067

Epoch: 241| Step: 0
Training loss: 2.362823009490967
Validation loss: 2.135549714167913

Epoch: 5| Step: 1
Training loss: 1.9359500408172607
Validation loss: 2.1358674416939416

Epoch: 5| Step: 2
Training loss: 2.4010891914367676
Validation loss: 2.12106121579806

Epoch: 5| Step: 3
Training loss: 1.9803073406219482
Validation loss: 2.1351337085167565

Epoch: 5| Step: 4
Training loss: 1.8568652868270874
Validation loss: 2.1221229632695517

Epoch: 5| Step: 5
Training loss: 2.147472381591797
Validation loss: 2.1337936917940774

Epoch: 5| Step: 6
Training loss: 1.5716890096664429
Validation loss: 2.118123044570287

Epoch: 5| Step: 7
Training loss: 1.5132546424865723
Validation loss: 2.116176798939705

Epoch: 5| Step: 8
Training loss: 1.834984540939331
Validation loss: 2.089498604337374

Epoch: 5| Step: 9
Training loss: 1.561679482460022
Validation loss: 2.098629280924797

Epoch: 5| Step: 10
Training loss: 2.010979175567627
Validation loss: 2.099149689078331

Epoch: 5| Step: 11
Training loss: 1.7949849367141724
Validation loss: 2.0888823668162027

Epoch: 242| Step: 0
Training loss: 1.357970952987671
Validation loss: 2.1053996682167053

Epoch: 5| Step: 1
Training loss: 2.2118866443634033
Validation loss: 2.0997706602017083

Epoch: 5| Step: 2
Training loss: 2.022219181060791
Validation loss: 2.1089990188678107

Epoch: 5| Step: 3
Training loss: 2.023378849029541
Validation loss: 2.0964720298846564

Epoch: 5| Step: 4
Training loss: 2.137587547302246
Validation loss: 2.0943629841009774

Epoch: 5| Step: 5
Training loss: 2.535438299179077
Validation loss: 2.1106921235720315

Epoch: 5| Step: 6
Training loss: 2.0660886764526367
Validation loss: 2.1324784755706787

Epoch: 5| Step: 7
Training loss: 1.5616556406021118
Validation loss: 2.1177738904953003

Epoch: 5| Step: 8
Training loss: 1.66513991355896
Validation loss: 2.1349569459756217

Epoch: 5| Step: 9
Training loss: 1.8066520690917969
Validation loss: 2.1259740591049194

Epoch: 5| Step: 10
Training loss: 1.8231281042099
Validation loss: 2.1298775573571525

Epoch: 5| Step: 11
Training loss: 1.9092204570770264
Validation loss: 2.1360724568367004

Epoch: 243| Step: 0
Training loss: 1.6796824932098389
Validation loss: 2.1308097541332245

Epoch: 5| Step: 1
Training loss: 1.9716523885726929
Validation loss: 2.1198909878730774

Epoch: 5| Step: 2
Training loss: 2.118725299835205
Validation loss: 2.1483666698137918

Epoch: 5| Step: 3
Training loss: 1.8354562520980835
Validation loss: 2.1388526558876038

Epoch: 5| Step: 4
Training loss: 1.726647138595581
Validation loss: 2.126900613307953

Epoch: 5| Step: 5
Training loss: 2.1473076343536377
Validation loss: 2.1305760741233826

Epoch: 5| Step: 6
Training loss: 2.458040952682495
Validation loss: 2.1186955124139786

Epoch: 5| Step: 7
Training loss: 2.0784738063812256
Validation loss: 2.1210186978181205

Epoch: 5| Step: 8
Training loss: 1.7609875202178955
Validation loss: 2.121261457602183

Epoch: 5| Step: 9
Training loss: 1.3612905740737915
Validation loss: 2.12559050321579

Epoch: 5| Step: 10
Training loss: 1.7967325448989868
Validation loss: 2.1349398543437323

Epoch: 5| Step: 11
Training loss: 1.8235771656036377
Validation loss: 2.1236302057902017

Epoch: 244| Step: 0
Training loss: 1.306931734085083
Validation loss: 2.122269704937935

Epoch: 5| Step: 1
Training loss: 2.320540428161621
Validation loss: 2.109416827559471

Epoch: 5| Step: 2
Training loss: 1.757947325706482
Validation loss: 2.1213127126296363

Epoch: 5| Step: 3
Training loss: 1.528826355934143
Validation loss: 2.121189812819163

Epoch: 5| Step: 4
Training loss: 1.7958955764770508
Validation loss: 2.1172453314065933

Epoch: 5| Step: 5
Training loss: 2.199991226196289
Validation loss: 2.135248879591624

Epoch: 5| Step: 6
Training loss: 2.1117746829986572
Validation loss: 2.1205303271611533

Epoch: 5| Step: 7
Training loss: 2.242628574371338
Validation loss: 2.1132969756921134

Epoch: 5| Step: 8
Training loss: 1.6876140832901
Validation loss: 2.11131459971269

Epoch: 5| Step: 9
Training loss: 1.8433424234390259
Validation loss: 2.1006876776615777

Epoch: 5| Step: 10
Training loss: 2.347135066986084
Validation loss: 2.0979407529036203

Epoch: 5| Step: 11
Training loss: 0.8726937770843506
Validation loss: 2.0904881060123444

Epoch: 245| Step: 0
Training loss: 1.7278454303741455
Validation loss: 2.0966592828432717

Epoch: 5| Step: 1
Training loss: 2.049994707107544
Validation loss: 2.101533591747284

Epoch: 5| Step: 2
Training loss: 1.670706033706665
Validation loss: 2.0933674027522406

Epoch: 5| Step: 3
Training loss: 1.9851386547088623
Validation loss: 2.086956044038137

Epoch: 5| Step: 4
Training loss: 1.4065544605255127
Validation loss: 2.0875054746866226

Epoch: 5| Step: 5
Training loss: 1.474226951599121
Validation loss: 2.0912733525037766

Epoch: 5| Step: 6
Training loss: 2.31152081489563
Validation loss: 2.1054681738217673

Epoch: 5| Step: 7
Training loss: 2.195978879928589
Validation loss: 2.1145287503798804

Epoch: 5| Step: 8
Training loss: 2.3207578659057617
Validation loss: 2.1195563773314157

Epoch: 5| Step: 9
Training loss: 2.1672024726867676
Validation loss: 2.1197612981001535

Epoch: 5| Step: 10
Training loss: 2.131028175354004
Validation loss: 2.118984008828799

Epoch: 5| Step: 11
Training loss: 1.2063168287277222
Validation loss: 2.139106715718905

Epoch: 246| Step: 0
Training loss: 1.5296156406402588
Validation loss: 2.1283007065455117

Epoch: 5| Step: 1
Training loss: 1.713212013244629
Validation loss: 2.1283248960971832

Epoch: 5| Step: 2
Training loss: 2.2879738807678223
Validation loss: 2.1358663787444434

Epoch: 5| Step: 3
Training loss: 1.8322311639785767
Validation loss: 2.1412231624126434

Epoch: 5| Step: 4
Training loss: 1.6296945810317993
Validation loss: 2.1344206233819327

Epoch: 5| Step: 5
Training loss: 1.7755016088485718
Validation loss: 2.1231180330117545

Epoch: 5| Step: 6
Training loss: 2.064671516418457
Validation loss: 2.117077191670736

Epoch: 5| Step: 7
Training loss: 1.9157222509384155
Validation loss: 2.0825021266937256

Epoch: 5| Step: 8
Training loss: 1.8764102458953857
Validation loss: 2.1026558627684913

Epoch: 5| Step: 9
Training loss: 2.8005032539367676
Validation loss: 2.090722769498825

Epoch: 5| Step: 10
Training loss: 1.9542938470840454
Validation loss: 2.1064325173695884

Epoch: 5| Step: 11
Training loss: 1.0751644372940063
Validation loss: 2.103449374437332

Epoch: 247| Step: 0
Training loss: 1.3892284631729126
Validation loss: 2.0972558160622916

Epoch: 5| Step: 1
Training loss: 1.652130365371704
Validation loss: 2.117905080318451

Epoch: 5| Step: 2
Training loss: 2.0812385082244873
Validation loss: 2.114907522996267

Epoch: 5| Step: 3
Training loss: 2.053766965866089
Validation loss: 2.1191255499919257

Epoch: 5| Step: 4
Training loss: 2.4344348907470703
Validation loss: 2.116876815756162

Epoch: 5| Step: 5
Training loss: 1.658357858657837
Validation loss: 2.1066084454456964

Epoch: 5| Step: 6
Training loss: 1.8022596836090088
Validation loss: 2.1191139618555703

Epoch: 5| Step: 7
Training loss: 1.785693883895874
Validation loss: 2.1148562083641687

Epoch: 5| Step: 8
Training loss: 2.0463788509368896
Validation loss: 2.1303241600592933

Epoch: 5| Step: 9
Training loss: 1.487704873085022
Validation loss: 2.129962349931399

Epoch: 5| Step: 10
Training loss: 2.194826602935791
Validation loss: 2.1160092453161874

Epoch: 5| Step: 11
Training loss: 3.1404030323028564
Validation loss: 2.1377794643243155

Epoch: 248| Step: 0
Training loss: 1.4189847707748413
Validation loss: 2.1243405242760978

Epoch: 5| Step: 1
Training loss: 1.817613959312439
Validation loss: 2.114702900250753

Epoch: 5| Step: 2
Training loss: 1.8415149450302124
Validation loss: 2.109340856472651

Epoch: 5| Step: 3
Training loss: 1.8712562322616577
Validation loss: 2.1125749548276267

Epoch: 5| Step: 4
Training loss: 2.201822280883789
Validation loss: 2.0976148744424186

Epoch: 5| Step: 5
Training loss: 1.8019237518310547
Validation loss: 2.110702539483706

Epoch: 5| Step: 6
Training loss: 1.8314311504364014
Validation loss: 2.1135086913903556

Epoch: 5| Step: 7
Training loss: 2.0670597553253174
Validation loss: 2.1157981057961783

Epoch: 5| Step: 8
Training loss: 1.5664417743682861
Validation loss: 2.1006310482819877

Epoch: 5| Step: 9
Training loss: 2.1222763061523438
Validation loss: 2.116596316297849

Epoch: 5| Step: 10
Training loss: 1.6988732814788818
Validation loss: 2.122685874501864

Epoch: 5| Step: 11
Training loss: 4.016327857971191
Validation loss: 2.11374831199646

Epoch: 249| Step: 0
Training loss: 1.5433763265609741
Validation loss: 2.126568709810575

Epoch: 5| Step: 1
Training loss: 2.5873897075653076
Validation loss: 2.131715695063273

Epoch: 5| Step: 2
Training loss: 1.355333685874939
Validation loss: 2.138145864009857

Epoch: 5| Step: 3
Training loss: 1.6166374683380127
Validation loss: 2.130749056736628

Epoch: 5| Step: 4
Training loss: 1.5471434593200684
Validation loss: 2.1388051013151803

Epoch: 5| Step: 5
Training loss: 2.0511984825134277
Validation loss: 2.150058309237162

Epoch: 5| Step: 6
Training loss: 2.1873486042022705
Validation loss: 2.1489770660797753

Epoch: 5| Step: 7
Training loss: 1.9574840068817139
Validation loss: 2.1397618452707925

Epoch: 5| Step: 8
Training loss: 2.4927077293395996
Validation loss: 2.166635125875473

Epoch: 5| Step: 9
Training loss: 1.5718202590942383
Validation loss: 2.1409605890512466

Epoch: 5| Step: 10
Training loss: 1.8976962566375732
Validation loss: 2.130610009034475

Epoch: 5| Step: 11
Training loss: 1.387392520904541
Validation loss: 2.1249416520198188

Epoch: 250| Step: 0
Training loss: 1.6595827341079712
Validation loss: 2.1256348292032876

Epoch: 5| Step: 1
Training loss: 1.9593414068222046
Validation loss: 2.1346020102500916

Epoch: 5| Step: 2
Training loss: 1.697752594947815
Validation loss: 2.13131582736969

Epoch: 5| Step: 3
Training loss: 2.32861328125
Validation loss: 2.1290770520766578

Epoch: 5| Step: 4
Training loss: 2.026123523712158
Validation loss: 2.120285928249359

Epoch: 5| Step: 5
Training loss: 2.617819309234619
Validation loss: 2.1118383705615997

Epoch: 5| Step: 6
Training loss: 1.64249587059021
Validation loss: 2.1214277098576226

Epoch: 5| Step: 7
Training loss: 1.8434823751449585
Validation loss: 2.1136560142040253

Epoch: 5| Step: 8
Training loss: 1.748356580734253
Validation loss: 2.119740510980288

Epoch: 5| Step: 9
Training loss: 1.8275253772735596
Validation loss: 2.1180533270041146

Epoch: 5| Step: 10
Training loss: 1.5504953861236572
Validation loss: 2.12528462211291

Epoch: 5| Step: 11
Training loss: 0.9859896898269653
Validation loss: 2.127749592065811

Epoch: 251| Step: 0
Training loss: 2.4555983543395996
Validation loss: 2.137003635366758

Epoch: 5| Step: 1
Training loss: 2.277003526687622
Validation loss: 2.139461507399877

Epoch: 5| Step: 2
Training loss: 1.7519928216934204
Validation loss: 2.147405723730723

Epoch: 5| Step: 3
Training loss: 2.125953197479248
Validation loss: 2.1286169489224753

Epoch: 5| Step: 4
Training loss: 1.3765498399734497
Validation loss: 2.134661922852198

Epoch: 5| Step: 5
Training loss: 2.1616623401641846
Validation loss: 2.1452730745077133

Epoch: 5| Step: 6
Training loss: 1.645301103591919
Validation loss: 2.1296030233303704

Epoch: 5| Step: 7
Training loss: 2.0034196376800537
Validation loss: 2.1225050588448844

Epoch: 5| Step: 8
Training loss: 1.9535109996795654
Validation loss: 2.125247528155645

Epoch: 5| Step: 9
Training loss: 1.1088573932647705
Validation loss: 2.1231428533792496

Epoch: 5| Step: 10
Training loss: 1.8955507278442383
Validation loss: 2.133005360762278

Epoch: 5| Step: 11
Training loss: 2.205355405807495
Validation loss: 2.118248904744784

Epoch: 252| Step: 0
Training loss: 1.3325111865997314
Validation loss: 2.107577527562777

Epoch: 5| Step: 1
Training loss: 2.3472933769226074
Validation loss: 2.1149163295825324

Epoch: 5| Step: 2
Training loss: 1.559541940689087
Validation loss: 2.117237130800883

Epoch: 5| Step: 3
Training loss: 1.8955957889556885
Validation loss: 2.12857423722744

Epoch: 5| Step: 4
Training loss: 2.0320723056793213
Validation loss: 2.1311665972073874

Epoch: 5| Step: 5
Training loss: 2.0137746334075928
Validation loss: 2.112878998120626

Epoch: 5| Step: 6
Training loss: 2.2686190605163574
Validation loss: 2.118488679329554

Epoch: 5| Step: 7
Training loss: 2.0607216358184814
Validation loss: 2.1177272498607635

Epoch: 5| Step: 8
Training loss: 1.5843172073364258
Validation loss: 2.1339942812919617

Epoch: 5| Step: 9
Training loss: 2.1138992309570312
Validation loss: 2.120668684442838

Epoch: 5| Step: 10
Training loss: 1.348631501197815
Validation loss: 2.112290784716606

Epoch: 5| Step: 11
Training loss: 1.9731272459030151
Validation loss: 2.1123678783575692

Epoch: 253| Step: 0
Training loss: 2.464890956878662
Validation loss: 2.1186817983786264

Epoch: 5| Step: 1
Training loss: 2.2047581672668457
Validation loss: 2.1334387958049774

Epoch: 5| Step: 2
Training loss: 2.267029285430908
Validation loss: 2.1366229405005774

Epoch: 5| Step: 3
Training loss: 1.5291361808776855
Validation loss: 2.1234283298254013

Epoch: 5| Step: 4
Training loss: 1.4633214473724365
Validation loss: 2.1339381635189056

Epoch: 5| Step: 5
Training loss: 1.9824600219726562
Validation loss: 2.116033578912417

Epoch: 5| Step: 6
Training loss: 2.369854211807251
Validation loss: 2.122064729531606

Epoch: 5| Step: 7
Training loss: 1.4286484718322754
Validation loss: 2.1174652924140296

Epoch: 5| Step: 8
Training loss: 1.6927562952041626
Validation loss: 2.118879089752833

Epoch: 5| Step: 9
Training loss: 1.846207857131958
Validation loss: 2.1108701825141907

Epoch: 5| Step: 10
Training loss: 1.7720998525619507
Validation loss: 2.1118384897708893

Epoch: 5| Step: 11
Training loss: 0.8417195677757263
Validation loss: 2.125798483689626

Epoch: 254| Step: 0
Training loss: 2.274773359298706
Validation loss: 2.126526042819023

Epoch: 5| Step: 1
Training loss: 1.8095684051513672
Validation loss: 2.1164320558309555

Epoch: 5| Step: 2
Training loss: 1.6025009155273438
Validation loss: 2.126328950126966

Epoch: 5| Step: 3
Training loss: 2.3244071006774902
Validation loss: 2.1163157721360526

Epoch: 5| Step: 4
Training loss: 1.753232717514038
Validation loss: 2.1248559951782227

Epoch: 5| Step: 5
Training loss: 2.1174209117889404
Validation loss: 2.111216425895691

Epoch: 5| Step: 6
Training loss: 2.143831491470337
Validation loss: 2.1137832502524057

Epoch: 5| Step: 7
Training loss: 1.9565494060516357
Validation loss: 2.133814200758934

Epoch: 5| Step: 8
Training loss: 1.5060821771621704
Validation loss: 2.136032611131668

Epoch: 5| Step: 9
Training loss: 1.6289047002792358
Validation loss: 2.1331165184577308

Epoch: 5| Step: 10
Training loss: 1.6616843938827515
Validation loss: 2.1400644729534783

Epoch: 5| Step: 11
Training loss: 1.6142923831939697
Validation loss: 2.1282167385021844

Epoch: 255| Step: 0
Training loss: 1.60659658908844
Validation loss: 2.1379377792278924

Epoch: 5| Step: 1
Training loss: 2.429414749145508
Validation loss: 2.1413662185271582

Epoch: 5| Step: 2
Training loss: 2.1827709674835205
Validation loss: 2.1335875342289605

Epoch: 5| Step: 3
Training loss: 1.7076784372329712
Validation loss: 2.1340270588795343

Epoch: 5| Step: 4
Training loss: 1.8705222606658936
Validation loss: 2.131343041857084

Epoch: 5| Step: 5
Training loss: 1.7808668613433838
Validation loss: 2.1177514543135962

Epoch: 5| Step: 6
Training loss: 1.8800077438354492
Validation loss: 2.099615087111791

Epoch: 5| Step: 7
Training loss: 1.812609314918518
Validation loss: 2.099683463573456

Epoch: 5| Step: 8
Training loss: 2.3219540119171143
Validation loss: 2.1059132367372513

Epoch: 5| Step: 9
Training loss: 1.5777297019958496
Validation loss: 2.1022857328255973

Epoch: 5| Step: 10
Training loss: 1.835458755493164
Validation loss: 2.11166475713253

Epoch: 5| Step: 11
Training loss: 1.752504825592041
Validation loss: 2.12578413883845

Epoch: 256| Step: 0
Training loss: 1.7789281606674194
Validation loss: 2.120658834775289

Epoch: 5| Step: 1
Training loss: 1.5883508920669556
Validation loss: 2.1235115031401315

Epoch: 5| Step: 2
Training loss: 1.704196572303772
Validation loss: 2.13713176548481

Epoch: 5| Step: 3
Training loss: 2.170647621154785
Validation loss: 2.1486611564954123

Epoch: 5| Step: 4
Training loss: 1.9218212366104126
Validation loss: 2.1469723880290985

Epoch: 5| Step: 5
Training loss: 1.9200671911239624
Validation loss: 2.148076524337133

Epoch: 5| Step: 6
Training loss: 1.9930530786514282
Validation loss: 2.1505251427491507

Epoch: 5| Step: 7
Training loss: 2.044569492340088
Validation loss: 2.1484214067459106

Epoch: 5| Step: 8
Training loss: 2.0442557334899902
Validation loss: 2.157506063580513

Epoch: 5| Step: 9
Training loss: 2.035102367401123
Validation loss: 2.1343216796716056

Epoch: 5| Step: 10
Training loss: 1.4040124416351318
Validation loss: 2.112322991093

Epoch: 5| Step: 11
Training loss: 2.3765177726745605
Validation loss: 2.102389474709829

Epoch: 257| Step: 0
Training loss: 1.5586150884628296
Validation loss: 2.0888651609420776

Epoch: 5| Step: 1
Training loss: 1.9501224756240845
Validation loss: 2.1025860756635666

Epoch: 5| Step: 2
Training loss: 1.8958982229232788
Validation loss: 2.101120576262474

Epoch: 5| Step: 3
Training loss: 1.9768670797348022
Validation loss: 2.10101555287838

Epoch: 5| Step: 4
Training loss: 1.7519466876983643
Validation loss: 2.0990243206421533

Epoch: 5| Step: 5
Training loss: 2.3460373878479004
Validation loss: 2.1060754557450614

Epoch: 5| Step: 6
Training loss: 1.6423254013061523
Validation loss: 2.110499213139216

Epoch: 5| Step: 7
Training loss: 1.8784748315811157
Validation loss: 2.1033905247847238

Epoch: 5| Step: 8
Training loss: 1.878483533859253
Validation loss: 2.104823276400566

Epoch: 5| Step: 9
Training loss: 1.9687786102294922
Validation loss: 2.1137279520432153

Epoch: 5| Step: 10
Training loss: 2.8844075202941895
Validation loss: 2.1233928352594376

Epoch: 5| Step: 11
Training loss: 1.5037000179290771
Validation loss: 2.1323385536670685

Epoch: 258| Step: 0
Training loss: 2.042494297027588
Validation loss: 2.1565882364908853

Epoch: 5| Step: 1
Training loss: 1.8323885202407837
Validation loss: 2.154373606046041

Epoch: 5| Step: 2
Training loss: 1.3536655902862549
Validation loss: 2.16820627450943

Epoch: 5| Step: 3
Training loss: 2.2876408100128174
Validation loss: 2.171842406193415

Epoch: 5| Step: 4
Training loss: 2.07780385017395
Validation loss: 2.1794054756561914

Epoch: 5| Step: 5
Training loss: 2.0330557823181152
Validation loss: 2.1715162048737207

Epoch: 5| Step: 6
Training loss: 1.511863112449646
Validation loss: 2.168245106935501

Epoch: 5| Step: 7
Training loss: 2.556960344314575
Validation loss: 2.131852542360624

Epoch: 5| Step: 8
Training loss: 1.9596278667449951
Validation loss: 2.1065669556458793

Epoch: 5| Step: 9
Training loss: 2.021677017211914
Validation loss: 2.1318850815296173

Epoch: 5| Step: 10
Training loss: 1.8952503204345703
Validation loss: 2.1155275851488113

Epoch: 5| Step: 11
Training loss: 1.2786710262298584
Validation loss: 2.1333615680535636

Epoch: 259| Step: 0
Training loss: 1.4368830919265747
Validation loss: 2.136241535345713

Epoch: 5| Step: 1
Training loss: 1.6802921295166016
Validation loss: 2.140938878059387

Epoch: 5| Step: 2
Training loss: 1.7735595703125
Validation loss: 2.135605106751124

Epoch: 5| Step: 3
Training loss: 1.74204421043396
Validation loss: 2.1432715406020484

Epoch: 5| Step: 4
Training loss: 1.6821273565292358
Validation loss: 2.1242893238862357

Epoch: 5| Step: 5
Training loss: 1.9280602931976318
Validation loss: 2.150582810242971

Epoch: 5| Step: 6
Training loss: 1.870911955833435
Validation loss: 2.1430380990107856

Epoch: 5| Step: 7
Training loss: 2.1619954109191895
Validation loss: 2.137816826502482

Epoch: 5| Step: 8
Training loss: 1.9433597326278687
Validation loss: 2.131982366243998

Epoch: 5| Step: 9
Training loss: 1.8764642477035522
Validation loss: 2.140516623854637

Epoch: 5| Step: 10
Training loss: 2.096683979034424
Validation loss: 2.1288554966449738

Epoch: 5| Step: 11
Training loss: 2.830786943435669
Validation loss: 2.1335765967766442

Epoch: 260| Step: 0
Training loss: 1.862858533859253
Validation loss: 2.142831136782964

Epoch: 5| Step: 1
Training loss: 1.5638049840927124
Validation loss: 2.1187569548686347

Epoch: 5| Step: 2
Training loss: 1.4836972951889038
Validation loss: 2.1204395095507302

Epoch: 5| Step: 3
Training loss: 1.6542997360229492
Validation loss: 2.1124657094478607

Epoch: 5| Step: 4
Training loss: 2.144709587097168
Validation loss: 2.106434474388758

Epoch: 5| Step: 5
Training loss: 1.8116881847381592
Validation loss: 2.113908146818479

Epoch: 5| Step: 6
Training loss: 2.1475322246551514
Validation loss: 2.1152311066786447

Epoch: 5| Step: 7
Training loss: 2.068988800048828
Validation loss: 2.1266767432292304

Epoch: 5| Step: 8
Training loss: 2.0759854316711426
Validation loss: 2.127026230096817

Epoch: 5| Step: 9
Training loss: 1.9069381952285767
Validation loss: 2.126902004082998

Epoch: 5| Step: 10
Training loss: 1.9887090921401978
Validation loss: 2.135521655281385

Epoch: 5| Step: 11
Training loss: 2.659088611602783
Validation loss: 2.1271982987721763

Epoch: 261| Step: 0
Training loss: 1.5298614501953125
Validation loss: 2.1329183876514435

Epoch: 5| Step: 1
Training loss: 1.607386589050293
Validation loss: 2.1646244575579963

Epoch: 5| Step: 2
Training loss: 1.3300367593765259
Validation loss: 2.148079658548037

Epoch: 5| Step: 3
Training loss: 2.021030902862549
Validation loss: 2.124397704998652

Epoch: 5| Step: 4
Training loss: 1.6807324886322021
Validation loss: 2.13437827428182

Epoch: 5| Step: 5
Training loss: 1.9253240823745728
Validation loss: 2.1465274542570114

Epoch: 5| Step: 6
Training loss: 2.255659818649292
Validation loss: 2.1304084608952203

Epoch: 5| Step: 7
Training loss: 2.1340088844299316
Validation loss: 2.1453809440135956

Epoch: 5| Step: 8
Training loss: 1.6484992504119873
Validation loss: 2.1460414131482444

Epoch: 5| Step: 9
Training loss: 2.5612010955810547
Validation loss: 2.1200551986694336

Epoch: 5| Step: 10
Training loss: 1.7527210712432861
Validation loss: 2.1249432067076364

Epoch: 5| Step: 11
Training loss: 2.2202093601226807
Validation loss: 2.131011813879013

Epoch: 262| Step: 0
Training loss: 1.572873592376709
Validation loss: 2.1335955212513604

Epoch: 5| Step: 1
Training loss: 2.143895387649536
Validation loss: 2.1226976017157235

Epoch: 5| Step: 2
Training loss: 1.2698540687561035
Validation loss: 2.143055041631063

Epoch: 5| Step: 3
Training loss: 1.753023386001587
Validation loss: 2.1489692678054175

Epoch: 5| Step: 4
Training loss: 2.283872604370117
Validation loss: 2.144356926282247

Epoch: 5| Step: 5
Training loss: 1.8549582958221436
Validation loss: 2.143888900677363

Epoch: 5| Step: 6
Training loss: 2.115553617477417
Validation loss: 2.1453950703144073

Epoch: 5| Step: 7
Training loss: 2.5250613689422607
Validation loss: 2.117320085565249

Epoch: 5| Step: 8
Training loss: 1.6399524211883545
Validation loss: 2.1323057363430657

Epoch: 5| Step: 9
Training loss: 1.6921179294586182
Validation loss: 2.13678606847922

Epoch: 5| Step: 10
Training loss: 1.585960030555725
Validation loss: 2.1489676237106323

Epoch: 5| Step: 11
Training loss: 0.8501105904579163
Validation loss: 2.121783584356308

Epoch: 263| Step: 0
Training loss: 2.1615958213806152
Validation loss: 2.136623074611028

Epoch: 5| Step: 1
Training loss: 1.7182782888412476
Validation loss: 2.1400786340236664

Epoch: 5| Step: 2
Training loss: 1.9931949377059937
Validation loss: 2.1666431228319802

Epoch: 5| Step: 3
Training loss: 1.8774515390396118
Validation loss: 2.14757447441419

Epoch: 5| Step: 4
Training loss: 1.7619781494140625
Validation loss: 2.136750211318334

Epoch: 5| Step: 5
Training loss: 1.4768918752670288
Validation loss: 2.135383501648903

Epoch: 5| Step: 6
Training loss: 2.1739048957824707
Validation loss: 2.12793297568957

Epoch: 5| Step: 7
Training loss: 2.0131969451904297
Validation loss: 2.142334500948588

Epoch: 5| Step: 8
Training loss: 1.7976150512695312
Validation loss: 2.1262334485848746

Epoch: 5| Step: 9
Training loss: 1.6265754699707031
Validation loss: 2.1153505742549896

Epoch: 5| Step: 10
Training loss: 1.987696886062622
Validation loss: 2.1247755785783133

Epoch: 5| Step: 11
Training loss: 3.0345230102539062
Validation loss: 2.1148897061745324

Epoch: 264| Step: 0
Training loss: 2.018205404281616
Validation loss: 2.116761341691017

Epoch: 5| Step: 1
Training loss: 1.2269585132598877
Validation loss: 2.119662115971247

Epoch: 5| Step: 2
Training loss: 1.9191268682479858
Validation loss: 2.116283486286799

Epoch: 5| Step: 3
Training loss: 2.163304567337036
Validation loss: 2.1296628514925637

Epoch: 5| Step: 4
Training loss: 2.101208209991455
Validation loss: 2.1305562953154245

Epoch: 5| Step: 5
Training loss: 1.9412891864776611
Validation loss: 2.1269489427407584

Epoch: 5| Step: 6
Training loss: 1.642066240310669
Validation loss: 2.136664738257726

Epoch: 5| Step: 7
Training loss: 2.0889792442321777
Validation loss: 2.1496587296326957

Epoch: 5| Step: 8
Training loss: 1.2713853120803833
Validation loss: 2.1485746602217355

Epoch: 5| Step: 9
Training loss: 2.0757765769958496
Validation loss: 2.1389769911766052

Epoch: 5| Step: 10
Training loss: 1.7430311441421509
Validation loss: 2.168489476044973

Epoch: 5| Step: 11
Training loss: 2.812161922454834
Validation loss: 2.1431034753719964

Epoch: 265| Step: 0
Training loss: 1.897939682006836
Validation loss: 2.1457087298234305

Epoch: 5| Step: 1
Training loss: 1.8030643463134766
Validation loss: 2.130360707640648

Epoch: 5| Step: 2
Training loss: 1.4240362644195557
Validation loss: 2.1277649104595184

Epoch: 5| Step: 3
Training loss: 2.0577452182769775
Validation loss: 2.119801864027977

Epoch: 5| Step: 4
Training loss: 1.5161564350128174
Validation loss: 2.117187331120173

Epoch: 5| Step: 5
Training loss: 2.855421304702759
Validation loss: 2.1116805324951806

Epoch: 5| Step: 6
Training loss: 2.0178279876708984
Validation loss: 2.120956098039945

Epoch: 5| Step: 7
Training loss: 2.557037830352783
Validation loss: 2.1238385091225305

Epoch: 5| Step: 8
Training loss: 1.9322497844696045
Validation loss: 2.1414951980113983

Epoch: 5| Step: 9
Training loss: 1.522904872894287
Validation loss: 2.1558968275785446

Epoch: 5| Step: 10
Training loss: 1.4700063467025757
Validation loss: 2.149813190102577

Epoch: 5| Step: 11
Training loss: 1.545806884765625
Validation loss: 2.1621705442667007

Epoch: 266| Step: 0
Training loss: 1.636922836303711
Validation loss: 2.172068104147911

Epoch: 5| Step: 1
Training loss: 1.881445288658142
Validation loss: 2.1726077993710837

Epoch: 5| Step: 2
Training loss: 1.469312310218811
Validation loss: 2.171999623378118

Epoch: 5| Step: 3
Training loss: 1.9876320362091064
Validation loss: 2.154561916987101

Epoch: 5| Step: 4
Training loss: 2.0339250564575195
Validation loss: 2.1458795219659805

Epoch: 5| Step: 5
Training loss: 1.420734167098999
Validation loss: 2.1556211163600287

Epoch: 5| Step: 6
Training loss: 2.363096237182617
Validation loss: 2.156499440471331

Epoch: 5| Step: 7
Training loss: 1.7857166528701782
Validation loss: 2.142427076896032

Epoch: 5| Step: 8
Training loss: 1.9298431873321533
Validation loss: 2.1534907619158425

Epoch: 5| Step: 9
Training loss: 2.153287887573242
Validation loss: 2.129823625087738

Epoch: 5| Step: 10
Training loss: 1.8360259532928467
Validation loss: 2.1345102339982986

Epoch: 5| Step: 11
Training loss: 2.9572815895080566
Validation loss: 2.133507490158081

Epoch: 267| Step: 0
Training loss: 1.706857681274414
Validation loss: 2.132380952437719

Epoch: 5| Step: 1
Training loss: 1.5136712789535522
Validation loss: 2.1337957431872687

Epoch: 5| Step: 2
Training loss: 2.232595920562744
Validation loss: 2.1354796389738717

Epoch: 5| Step: 3
Training loss: 2.359199047088623
Validation loss: 2.1310990353425345

Epoch: 5| Step: 4
Training loss: 1.6024181842803955
Validation loss: 2.126802533864975

Epoch: 5| Step: 5
Training loss: 1.2009880542755127
Validation loss: 2.126574546098709

Epoch: 5| Step: 6
Training loss: 2.391451597213745
Validation loss: 2.131429359316826

Epoch: 5| Step: 7
Training loss: 2.008244037628174
Validation loss: 2.158577168981234

Epoch: 5| Step: 8
Training loss: 2.3285324573516846
Validation loss: 2.152830203374227

Epoch: 5| Step: 9
Training loss: 1.7837272882461548
Validation loss: 2.13838829100132

Epoch: 5| Step: 10
Training loss: 1.966213583946228
Validation loss: 2.1340903689463935

Epoch: 5| Step: 11
Training loss: 1.6072700023651123
Validation loss: 2.159307281176249

Epoch: 268| Step: 0
Training loss: 2.5125844478607178
Validation loss: 2.1315482407808304

Epoch: 5| Step: 1
Training loss: 2.1123244762420654
Validation loss: 2.1251277724901834

Epoch: 5| Step: 2
Training loss: 1.3955432176589966
Validation loss: 2.1090786159038544

Epoch: 5| Step: 3
Training loss: 2.1031174659729004
Validation loss: 2.1178371608257294

Epoch: 5| Step: 4
Training loss: 1.5583784580230713
Validation loss: 2.1103221277395883

Epoch: 5| Step: 5
Training loss: 1.8309218883514404
Validation loss: 2.1061004300912223

Epoch: 5| Step: 6
Training loss: 2.2599635124206543
Validation loss: 2.111341287692388

Epoch: 5| Step: 7
Training loss: 1.8514366149902344
Validation loss: 2.1293108562628427

Epoch: 5| Step: 8
Training loss: 1.9172589778900146
Validation loss: 2.1164835691452026

Epoch: 5| Step: 9
Training loss: 1.4403117895126343
Validation loss: 2.117946356534958

Epoch: 5| Step: 10
Training loss: 1.7877788543701172
Validation loss: 2.1251453210910163

Epoch: 5| Step: 11
Training loss: 1.1270452737808228
Validation loss: 2.118559946616491

Epoch: 269| Step: 0
Training loss: 1.583979606628418
Validation loss: 2.132387399673462

Epoch: 5| Step: 1
Training loss: 2.3305742740631104
Validation loss: 2.1328405986229577

Epoch: 5| Step: 2
Training loss: 1.5209448337554932
Validation loss: 2.1239528258641562

Epoch: 5| Step: 3
Training loss: 2.0737221240997314
Validation loss: 2.121543755133947

Epoch: 5| Step: 4
Training loss: 2.00161075592041
Validation loss: 2.1059458553791046

Epoch: 5| Step: 5
Training loss: 1.7378456592559814
Validation loss: 2.1099164386590323

Epoch: 5| Step: 6
Training loss: 2.2599596977233887
Validation loss: 2.1236127614974976

Epoch: 5| Step: 7
Training loss: 1.4198089838027954
Validation loss: 2.1209667921066284

Epoch: 5| Step: 8
Training loss: 1.9459686279296875
Validation loss: 2.114901969830195

Epoch: 5| Step: 9
Training loss: 2.145724058151245
Validation loss: 2.136511122186979

Epoch: 5| Step: 10
Training loss: 1.540208101272583
Validation loss: 2.1488960832357407

Epoch: 5| Step: 11
Training loss: 1.4227368831634521
Validation loss: 2.152407040198644

Epoch: 270| Step: 0
Training loss: 1.7024462223052979
Validation loss: 2.152161886294683

Epoch: 5| Step: 1
Training loss: 2.024348735809326
Validation loss: 2.145828535159429

Epoch: 5| Step: 2
Training loss: 1.6330276727676392
Validation loss: 2.1451190610726676

Epoch: 5| Step: 3
Training loss: 1.7980530261993408
Validation loss: 2.159079059958458

Epoch: 5| Step: 4
Training loss: 2.0972790718078613
Validation loss: 2.1421182652314505

Epoch: 5| Step: 5
Training loss: 2.0404164791107178
Validation loss: 2.1503453254699707

Epoch: 5| Step: 6
Training loss: 1.9464359283447266
Validation loss: 2.154863307873408

Epoch: 5| Step: 7
Training loss: 1.299317717552185
Validation loss: 2.1492123355468116

Epoch: 5| Step: 8
Training loss: 2.479656457901001
Validation loss: 2.147305761774381

Epoch: 5| Step: 9
Training loss: 1.404167890548706
Validation loss: 2.1368585526943207

Epoch: 5| Step: 10
Training loss: 2.1319026947021484
Validation loss: 2.132387101650238

Epoch: 5| Step: 11
Training loss: 2.1035728454589844
Validation loss: 2.118037392695745

Epoch: 271| Step: 0
Training loss: 1.496483564376831
Validation loss: 2.1218193769454956

Epoch: 5| Step: 1
Training loss: 1.2725528478622437
Validation loss: 2.1381341964006424

Epoch: 5| Step: 2
Training loss: 2.233841896057129
Validation loss: 2.1353458960851035

Epoch: 5| Step: 3
Training loss: 1.8382346630096436
Validation loss: 2.128905937075615

Epoch: 5| Step: 4
Training loss: 2.6753623485565186
Validation loss: 2.138735627134641

Epoch: 5| Step: 5
Training loss: 1.1695929765701294
Validation loss: 2.1413569698731103

Epoch: 5| Step: 6
Training loss: 2.2888264656066895
Validation loss: 2.1431309978167215

Epoch: 5| Step: 7
Training loss: 1.9777336120605469
Validation loss: 2.1534911394119263

Epoch: 5| Step: 8
Training loss: 1.5319626331329346
Validation loss: 2.1233558555444083

Epoch: 5| Step: 9
Training loss: 2.0561776161193848
Validation loss: 2.149901216228803

Epoch: 5| Step: 10
Training loss: 1.7082315683364868
Validation loss: 2.146847834189733

Epoch: 5| Step: 11
Training loss: 1.393587589263916
Validation loss: 2.152469207843145

Epoch: 272| Step: 0
Training loss: 1.7717281579971313
Validation loss: 2.1470950643221536

Epoch: 5| Step: 1
Training loss: 1.7794735431671143
Validation loss: 2.148203323284785

Epoch: 5| Step: 2
Training loss: 1.761696457862854
Validation loss: 2.1540728906790414

Epoch: 5| Step: 3
Training loss: 1.8949772119522095
Validation loss: 2.1317453185717263

Epoch: 5| Step: 4
Training loss: 2.2045986652374268
Validation loss: 2.158432980378469

Epoch: 5| Step: 5
Training loss: 1.7632873058319092
Validation loss: 2.1467977265516915

Epoch: 5| Step: 6
Training loss: 2.545884609222412
Validation loss: 2.139612386624018

Epoch: 5| Step: 7
Training loss: 1.899773359298706
Validation loss: 2.112017884850502

Epoch: 5| Step: 8
Training loss: 1.8638579845428467
Validation loss: 2.1236761113007865

Epoch: 5| Step: 9
Training loss: 1.9319292306900024
Validation loss: 2.114641696214676

Epoch: 5| Step: 10
Training loss: 1.3927279710769653
Validation loss: 2.11339341600736

Epoch: 5| Step: 11
Training loss: 1.037868618965149
Validation loss: 2.119735543926557

Epoch: 273| Step: 0
Training loss: 2.3486902713775635
Validation loss: 2.1159784297148385

Epoch: 5| Step: 1
Training loss: 1.2027190923690796
Validation loss: 2.124543229738871

Epoch: 5| Step: 2
Training loss: 2.422663927078247
Validation loss: 2.134646942218145

Epoch: 5| Step: 3
Training loss: 1.2316482067108154
Validation loss: 2.143821895122528

Epoch: 5| Step: 4
Training loss: 1.6611645221710205
Validation loss: 2.1512919664382935

Epoch: 5| Step: 5
Training loss: 1.8334115743637085
Validation loss: 2.148739476998647

Epoch: 5| Step: 6
Training loss: 2.349700450897217
Validation loss: 2.127195810278257

Epoch: 5| Step: 7
Training loss: 1.8672561645507812
Validation loss: 2.1486207246780396

Epoch: 5| Step: 8
Training loss: 1.8600177764892578
Validation loss: 2.1409182051817575

Epoch: 5| Step: 9
Training loss: 1.5057976245880127
Validation loss: 2.1441139578819275

Epoch: 5| Step: 10
Training loss: 1.94232976436615
Validation loss: 2.1740389466285706

Epoch: 5| Step: 11
Training loss: 1.6577749252319336
Validation loss: 2.140083968639374

Epoch: 274| Step: 0
Training loss: 3.0634236335754395
Validation loss: 2.141131947437922

Epoch: 5| Step: 1
Training loss: 1.4108713865280151
Validation loss: 2.1462847193082175

Epoch: 5| Step: 2
Training loss: 1.7142969369888306
Validation loss: 2.134539951880773

Epoch: 5| Step: 3
Training loss: 1.9992542266845703
Validation loss: 2.1463326116402945

Epoch: 5| Step: 4
Training loss: 1.54708731174469
Validation loss: 2.146555259823799

Epoch: 5| Step: 5
Training loss: 1.383669137954712
Validation loss: 2.1327750980854034

Epoch: 5| Step: 6
Training loss: 1.8073298931121826
Validation loss: 2.1356942107280097

Epoch: 5| Step: 7
Training loss: 1.53746497631073
Validation loss: 2.123316302895546

Epoch: 5| Step: 8
Training loss: 1.7908236980438232
Validation loss: 2.1272277534008026

Epoch: 5| Step: 9
Training loss: 2.1735849380493164
Validation loss: 2.1255207558472953

Epoch: 5| Step: 10
Training loss: 1.845010757446289
Validation loss: 2.122526923815409

Epoch: 5| Step: 11
Training loss: 1.940879464149475
Validation loss: 2.127672404050827

Epoch: 275| Step: 0
Training loss: 1.891303300857544
Validation loss: 2.1233235796292624

Epoch: 5| Step: 1
Training loss: 1.8721719980239868
Validation loss: 2.124817192554474

Epoch: 5| Step: 2
Training loss: 2.0644898414611816
Validation loss: 2.1292725801467896

Epoch: 5| Step: 3
Training loss: 2.254478931427002
Validation loss: 2.1381173382202783

Epoch: 5| Step: 4
Training loss: 1.8782031536102295
Validation loss: 2.1479393392801285

Epoch: 5| Step: 5
Training loss: 1.8065483570098877
Validation loss: 2.1507267703612647

Epoch: 5| Step: 6
Training loss: 1.6694180965423584
Validation loss: 2.1575735807418823

Epoch: 5| Step: 7
Training loss: 1.629817008972168
Validation loss: 2.1506784558296204

Epoch: 5| Step: 8
Training loss: 1.8534595966339111
Validation loss: 2.164056067665418

Epoch: 5| Step: 9
Training loss: 2.2291641235351562
Validation loss: 2.14309931298097

Epoch: 5| Step: 10
Training loss: 1.619466781616211
Validation loss: 2.1279581586519876

Epoch: 5| Step: 11
Training loss: 1.037238359451294
Validation loss: 2.120719869931539

Epoch: 276| Step: 0
Training loss: 1.5986521244049072
Validation loss: 2.1300255159536996

Epoch: 5| Step: 1
Training loss: 1.8977082967758179
Validation loss: 2.1261768291393914

Epoch: 5| Step: 2
Training loss: 1.7054436206817627
Validation loss: 2.1314391642808914

Epoch: 5| Step: 3
Training loss: 2.064589023590088
Validation loss: 2.1267350018024445

Epoch: 5| Step: 4
Training loss: 2.476750612258911
Validation loss: 2.144463673233986

Epoch: 5| Step: 5
Training loss: 1.565360426902771
Validation loss: 2.1455874840418496

Epoch: 5| Step: 6
Training loss: 1.6279770135879517
Validation loss: 2.159523233771324

Epoch: 5| Step: 7
Training loss: 1.878028154373169
Validation loss: 2.1618116050958633

Epoch: 5| Step: 8
Training loss: 2.1462020874023438
Validation loss: 2.1513189723094306

Epoch: 5| Step: 9
Training loss: 1.8412517309188843
Validation loss: 2.1802621632814407

Epoch: 5| Step: 10
Training loss: 1.5664629936218262
Validation loss: 2.156607707341512

Epoch: 5| Step: 11
Training loss: 0.8785308003425598
Validation loss: 2.1609684973955154

Epoch: 277| Step: 0
Training loss: 2.0602543354034424
Validation loss: 2.1562462945779166

Epoch: 5| Step: 1
Training loss: 1.9187204837799072
Validation loss: 2.15528796116511

Epoch: 5| Step: 2
Training loss: 1.9401108026504517
Validation loss: 2.1564422845840454

Epoch: 5| Step: 3
Training loss: 1.9637314081192017
Validation loss: 2.1549527744452157

Epoch: 5| Step: 4
Training loss: 1.3876999616622925
Validation loss: 2.142780284086863

Epoch: 5| Step: 5
Training loss: 1.5260194540023804
Validation loss: 2.1325180530548096

Epoch: 5| Step: 6
Training loss: 1.7181987762451172
Validation loss: 2.1587299903233848

Epoch: 5| Step: 7
Training loss: 2.020512819290161
Validation loss: 2.15970242023468

Epoch: 5| Step: 8
Training loss: 1.8218259811401367
Validation loss: 2.159263630708059

Epoch: 5| Step: 9
Training loss: 1.9263160228729248
Validation loss: 2.1541493435700736

Epoch: 5| Step: 10
Training loss: 1.7076327800750732
Validation loss: 2.165410359700521

Epoch: 5| Step: 11
Training loss: 1.4914922714233398
Validation loss: 2.1701408376296363

Epoch: 278| Step: 0
Training loss: 1.663112998008728
Validation loss: 2.1709923992554345

Epoch: 5| Step: 1
Training loss: 1.8531358242034912
Validation loss: 2.15657905737559

Epoch: 5| Step: 2
Training loss: 1.7557592391967773
Validation loss: 2.1593808780113855

Epoch: 5| Step: 3
Training loss: 1.9642550945281982
Validation loss: 2.1465342044830322

Epoch: 5| Step: 4
Training loss: 1.945833444595337
Validation loss: 2.1453466763099036

Epoch: 5| Step: 5
Training loss: 1.2910161018371582
Validation loss: 2.1436753968397775

Epoch: 5| Step: 6
Training loss: 2.065716028213501
Validation loss: 2.1456486781438193

Epoch: 5| Step: 7
Training loss: 1.8138716220855713
Validation loss: 2.1474194526672363

Epoch: 5| Step: 8
Training loss: 2.0504441261291504
Validation loss: 2.1302676051855087

Epoch: 5| Step: 9
Training loss: 1.8374872207641602
Validation loss: 2.1309235195318856

Epoch: 5| Step: 10
Training loss: 1.8363155126571655
Validation loss: 2.1291890988747277

Epoch: 5| Step: 11
Training loss: 0.9181234836578369
Validation loss: 2.1246980329354606

Epoch: 279| Step: 0
Training loss: 1.6954246759414673
Validation loss: 2.143566201130549

Epoch: 5| Step: 1
Training loss: 1.723912000656128
Validation loss: 2.1288435806830726

Epoch: 5| Step: 2
Training loss: 1.4221434593200684
Validation loss: 2.136071110765139

Epoch: 5| Step: 3
Training loss: 1.0352957248687744
Validation loss: 2.1389933923880258

Epoch: 5| Step: 4
Training loss: 2.2363228797912598
Validation loss: 2.1471281150976815

Epoch: 5| Step: 5
Training loss: 1.7815558910369873
Validation loss: 2.1419042696555457

Epoch: 5| Step: 6
Training loss: 1.544048547744751
Validation loss: 2.155951847632726

Epoch: 5| Step: 7
Training loss: 2.3707098960876465
Validation loss: 2.132497320572535

Epoch: 5| Step: 8
Training loss: 2.0685696601867676
Validation loss: 2.154665450255076

Epoch: 5| Step: 9
Training loss: 1.9481518268585205
Validation loss: 2.17253985007604

Epoch: 5| Step: 10
Training loss: 2.487734317779541
Validation loss: 2.152669280767441

Epoch: 5| Step: 11
Training loss: 0.8136594295501709
Validation loss: 2.148085445165634

Epoch: 280| Step: 0
Training loss: 1.6889320611953735
Validation loss: 2.182458092768987

Epoch: 5| Step: 1
Training loss: 1.5979145765304565
Validation loss: 2.173436293999354

Epoch: 5| Step: 2
Training loss: 2.1634738445281982
Validation loss: 2.1515399465958276

Epoch: 5| Step: 3
Training loss: 1.9160922765731812
Validation loss: 2.169038583834966

Epoch: 5| Step: 4
Training loss: 2.149237632751465
Validation loss: 2.1689564933379493

Epoch: 5| Step: 5
Training loss: 1.4516117572784424
Validation loss: 2.1640969713528952

Epoch: 5| Step: 6
Training loss: 1.829441785812378
Validation loss: 2.1581798791885376

Epoch: 5| Step: 7
Training loss: 1.6349513530731201
Validation loss: 2.15597727894783

Epoch: 5| Step: 8
Training loss: 2.0090060234069824
Validation loss: 2.1740428706010184

Epoch: 5| Step: 9
Training loss: 1.4707759618759155
Validation loss: 2.1595843732357025

Epoch: 5| Step: 10
Training loss: 2.255855083465576
Validation loss: 2.152561823527018

Epoch: 5| Step: 11
Training loss: 1.3404629230499268
Validation loss: 2.13635283211867

Epoch: 281| Step: 0
Training loss: 2.1592190265655518
Validation loss: 2.154843509197235

Epoch: 5| Step: 1
Training loss: 1.847882628440857
Validation loss: 2.1605194807052612

Epoch: 5| Step: 2
Training loss: 1.5377922058105469
Validation loss: 2.17343699435393

Epoch: 5| Step: 3
Training loss: 1.4203386306762695
Validation loss: 2.164094850420952

Epoch: 5| Step: 4
Training loss: 1.941678762435913
Validation loss: 2.1730488588412604

Epoch: 5| Step: 5
Training loss: 1.7515007257461548
Validation loss: 2.1665332913398743

Epoch: 5| Step: 6
Training loss: 2.075106143951416
Validation loss: 2.1776081770658493

Epoch: 5| Step: 7
Training loss: 1.5068533420562744
Validation loss: 2.1745359698931375

Epoch: 5| Step: 8
Training loss: 1.7085669040679932
Validation loss: 2.16053498784701

Epoch: 5| Step: 9
Training loss: 2.3829338550567627
Validation loss: 2.1647445261478424

Epoch: 5| Step: 10
Training loss: 1.731311559677124
Validation loss: 2.161294932166735

Epoch: 5| Step: 11
Training loss: 1.67299222946167
Validation loss: 2.154051721096039

Epoch: 282| Step: 0
Training loss: 1.8552461862564087
Validation loss: 2.130424425005913

Epoch: 5| Step: 1
Training loss: 1.629001259803772
Validation loss: 2.135443389415741

Epoch: 5| Step: 2
Training loss: 2.466063976287842
Validation loss: 2.1278854807217917

Epoch: 5| Step: 3
Training loss: 1.1486625671386719
Validation loss: 2.145380953947703

Epoch: 5| Step: 4
Training loss: 1.9367374181747437
Validation loss: 2.1488615373770394

Epoch: 5| Step: 5
Training loss: 2.345611810684204
Validation loss: 2.1333723664283752

Epoch: 5| Step: 6
Training loss: 1.640054702758789
Validation loss: 2.1385499785343804

Epoch: 5| Step: 7
Training loss: 2.0373005867004395
Validation loss: 2.1251277277867

Epoch: 5| Step: 8
Training loss: 1.7674214839935303
Validation loss: 2.145635907848676

Epoch: 5| Step: 9
Training loss: 1.523189663887024
Validation loss: 2.1295011242230735

Epoch: 5| Step: 10
Training loss: 2.0283942222595215
Validation loss: 2.1293185651302338

Epoch: 5| Step: 11
Training loss: 0.8474880456924438
Validation loss: 2.112219293912252

Epoch: 283| Step: 0
Training loss: 1.6805546283721924
Validation loss: 2.1384901205698648

Epoch: 5| Step: 1
Training loss: 1.7101036310195923
Validation loss: 2.1359811623891196

Epoch: 5| Step: 2
Training loss: 1.857367753982544
Validation loss: 2.1178990304470062

Epoch: 5| Step: 3
Training loss: 1.9698034524917603
Validation loss: 2.130111277103424

Epoch: 5| Step: 4
Training loss: 2.332913875579834
Validation loss: 2.127388204137484

Epoch: 5| Step: 5
Training loss: 2.038464069366455
Validation loss: 2.138229101896286

Epoch: 5| Step: 6
Training loss: 1.930220365524292
Validation loss: 2.1446052541335425

Epoch: 5| Step: 7
Training loss: 1.2220101356506348
Validation loss: 2.154678533474604

Epoch: 5| Step: 8
Training loss: 2.3122146129608154
Validation loss: 2.14127916097641

Epoch: 5| Step: 9
Training loss: 1.3104032278060913
Validation loss: 2.137954701979955

Epoch: 5| Step: 10
Training loss: 1.7451072931289673
Validation loss: 2.140494614839554

Epoch: 5| Step: 11
Training loss: 1.645380973815918
Validation loss: 2.1454428136348724

Epoch: 284| Step: 0
Training loss: 1.5337563753128052
Validation loss: 2.1364417374134064

Epoch: 5| Step: 1
Training loss: 1.4387013912200928
Validation loss: 2.16768279671669

Epoch: 5| Step: 2
Training loss: 1.5814794301986694
Validation loss: 2.155554215113322

Epoch: 5| Step: 3
Training loss: 2.1487631797790527
Validation loss: 2.177674119671186

Epoch: 5| Step: 4
Training loss: 1.6160223484039307
Validation loss: 2.164879009127617

Epoch: 5| Step: 5
Training loss: 1.4149537086486816
Validation loss: 2.1624179681142173

Epoch: 5| Step: 6
Training loss: 2.2353403568267822
Validation loss: 2.164561157425245

Epoch: 5| Step: 7
Training loss: 2.0296242237091064
Validation loss: 2.1717491348584494

Epoch: 5| Step: 8
Training loss: 1.76897394657135
Validation loss: 2.1620297928651175

Epoch: 5| Step: 9
Training loss: 2.4005818367004395
Validation loss: 2.1741006871064505

Epoch: 5| Step: 10
Training loss: 1.872093915939331
Validation loss: 2.158170163631439

Epoch: 5| Step: 11
Training loss: 0.7394678592681885
Validation loss: 2.1574992140134177

Epoch: 285| Step: 0
Training loss: 1.747206449508667
Validation loss: 2.1743601113557816

Epoch: 5| Step: 1
Training loss: 1.9477145671844482
Validation loss: 2.1492857982714972

Epoch: 5| Step: 2
Training loss: 1.981561303138733
Validation loss: 2.1740661362806954

Epoch: 5| Step: 3
Training loss: 2.0309700965881348
Validation loss: 2.1816526055336

Epoch: 5| Step: 4
Training loss: 1.755997896194458
Validation loss: 2.169065942366918

Epoch: 5| Step: 5
Training loss: 1.833998680114746
Validation loss: 2.184583768248558

Epoch: 5| Step: 6
Training loss: 1.5506622791290283
Validation loss: 2.162971943616867

Epoch: 5| Step: 7
Training loss: 1.6255834102630615
Validation loss: 2.1763652861118317

Epoch: 5| Step: 8
Training loss: 2.1722183227539062
Validation loss: 2.1782496869564056

Epoch: 5| Step: 9
Training loss: 1.303890347480774
Validation loss: 2.1790734926859536

Epoch: 5| Step: 10
Training loss: 2.0169544219970703
Validation loss: 2.1727260053157806

Epoch: 5| Step: 11
Training loss: 0.8876469135284424
Validation loss: 2.181014433503151

Epoch: 286| Step: 0
Training loss: 2.132023334503174
Validation loss: 2.1498989313840866

Epoch: 5| Step: 1
Training loss: 2.041055679321289
Validation loss: 2.1453094134728112

Epoch: 5| Step: 2
Training loss: 1.3216674327850342
Validation loss: 2.1570932616790137

Epoch: 5| Step: 3
Training loss: 1.856896996498108
Validation loss: 2.143641402324041

Epoch: 5| Step: 4
Training loss: 2.1634602546691895
Validation loss: 2.1450795382261276

Epoch: 5| Step: 5
Training loss: 2.0371572971343994
Validation loss: 2.147556483745575

Epoch: 5| Step: 6
Training loss: 2.0198445320129395
Validation loss: 2.1600222488244376

Epoch: 5| Step: 7
Training loss: 1.448199987411499
Validation loss: 2.135629857579867

Epoch: 5| Step: 8
Training loss: 1.5032007694244385
Validation loss: 2.140248437722524

Epoch: 5| Step: 9
Training loss: 1.7763264179229736
Validation loss: 2.163862645626068

Epoch: 5| Step: 10
Training loss: 1.6779518127441406
Validation loss: 2.148456255594889

Epoch: 5| Step: 11
Training loss: 0.6374086141586304
Validation loss: 2.178659831484159

Epoch: 287| Step: 0
Training loss: 1.8732439279556274
Validation loss: 2.161315302054087

Epoch: 5| Step: 1
Training loss: 2.106757640838623
Validation loss: 2.1758247216542563

Epoch: 5| Step: 2
Training loss: 2.5940163135528564
Validation loss: 2.1775462528069816

Epoch: 5| Step: 3
Training loss: 1.10494863986969
Validation loss: 2.181884398063024

Epoch: 5| Step: 4
Training loss: 1.7814483642578125
Validation loss: 2.185220718383789

Epoch: 5| Step: 5
Training loss: 1.9113655090332031
Validation loss: 2.1634145428737006

Epoch: 5| Step: 6
Training loss: 1.4363967180252075
Validation loss: 2.1803674648205438

Epoch: 5| Step: 7
Training loss: 1.4260733127593994
Validation loss: 2.1554254442453384

Epoch: 5| Step: 8
Training loss: 1.7635600566864014
Validation loss: 2.1622803807258606

Epoch: 5| Step: 9
Training loss: 2.228668212890625
Validation loss: 2.149893174568812

Epoch: 5| Step: 10
Training loss: 1.7713409662246704
Validation loss: 2.1443359653155007

Epoch: 5| Step: 11
Training loss: 1.2405340671539307
Validation loss: 2.1632358779509864

Epoch: 288| Step: 0
Training loss: 1.4316002130508423
Validation loss: 2.1698487401008606

Epoch: 5| Step: 1
Training loss: 1.8986413478851318
Validation loss: 2.1565776815017066

Epoch: 5| Step: 2
Training loss: 1.442384958267212
Validation loss: 2.140385443965594

Epoch: 5| Step: 3
Training loss: 1.6554315090179443
Validation loss: 2.157820239663124

Epoch: 5| Step: 4
Training loss: 1.693263292312622
Validation loss: 2.184941738843918

Epoch: 5| Step: 5
Training loss: 1.8890912532806396
Validation loss: 2.161913196245829

Epoch: 5| Step: 6
Training loss: 1.3470866680145264
Validation loss: 2.17276564737161

Epoch: 5| Step: 7
Training loss: 1.9675400257110596
Validation loss: 2.1751939356327057

Epoch: 5| Step: 8
Training loss: 2.0531582832336426
Validation loss: 2.1862027694781623

Epoch: 5| Step: 9
Training loss: 2.8515465259552
Validation loss: 2.171272640426954

Epoch: 5| Step: 10
Training loss: 1.7382423877716064
Validation loss: 2.174738879005114

Epoch: 5| Step: 11
Training loss: 2.805948257446289
Validation loss: 2.1834195057551065

Epoch: 289| Step: 0
Training loss: 2.229191541671753
Validation loss: 2.1710121631622314

Epoch: 5| Step: 1
Training loss: 2.176352024078369
Validation loss: 2.1881281981865564

Epoch: 5| Step: 2
Training loss: 1.757948637008667
Validation loss: 2.161908889810244

Epoch: 5| Step: 3
Training loss: 2.4185051918029785
Validation loss: 2.162281389037768

Epoch: 5| Step: 4
Training loss: 1.659968376159668
Validation loss: 2.14709310233593

Epoch: 5| Step: 5
Training loss: 1.2425644397735596
Validation loss: 2.1369663874308267

Epoch: 5| Step: 6
Training loss: 1.1835483312606812
Validation loss: 2.1461310386657715

Epoch: 5| Step: 7
Training loss: 2.4304704666137695
Validation loss: 2.1566380113363266

Epoch: 5| Step: 8
Training loss: 1.6645565032958984
Validation loss: 2.1553178975979486

Epoch: 5| Step: 9
Training loss: 1.6939951181411743
Validation loss: 2.1539349059263864

Epoch: 5| Step: 10
Training loss: 1.2746708393096924
Validation loss: 2.16849721968174

Epoch: 5| Step: 11
Training loss: 2.384080648422241
Validation loss: 2.167218029499054

Epoch: 290| Step: 0
Training loss: 1.7766170501708984
Validation loss: 2.1827259957790375

Epoch: 5| Step: 1
Training loss: 1.8154863119125366
Validation loss: 2.17391803363959

Epoch: 5| Step: 2
Training loss: 1.4689161777496338
Validation loss: 2.181321690479914

Epoch: 5| Step: 3
Training loss: 1.7178680896759033
Validation loss: 2.166168143351873

Epoch: 5| Step: 4
Training loss: 1.5327547788619995
Validation loss: 2.1621459474166236

Epoch: 5| Step: 5
Training loss: 2.0816423892974854
Validation loss: 2.1439143419265747

Epoch: 5| Step: 6
Training loss: 1.703091025352478
Validation loss: 2.1490767002105713

Epoch: 5| Step: 7
Training loss: 1.7385227680206299
Validation loss: 2.1405192812283835

Epoch: 5| Step: 8
Training loss: 2.0031933784484863
Validation loss: 2.1498378415902457

Epoch: 5| Step: 9
Training loss: 1.9911426305770874
Validation loss: 2.1394390761852264

Epoch: 5| Step: 10
Training loss: 2.2198147773742676
Validation loss: 2.15316574772199

Epoch: 5| Step: 11
Training loss: 1.2429523468017578
Validation loss: 2.1631317337354026

Epoch: 291| Step: 0
Training loss: 1.614696741104126
Validation loss: 2.1573498050371804

Epoch: 5| Step: 1
Training loss: 1.7258354425430298
Validation loss: 2.1453205347061157

Epoch: 5| Step: 2
Training loss: 2.5427775382995605
Validation loss: 2.1727664520343146

Epoch: 5| Step: 3
Training loss: 1.6716480255126953
Validation loss: 2.1754913379748664

Epoch: 5| Step: 4
Training loss: 1.8197517395019531
Validation loss: 2.15436851978302

Epoch: 5| Step: 5
Training loss: 1.4636476039886475
Validation loss: 2.1645007332166037

Epoch: 5| Step: 6
Training loss: 1.393990159034729
Validation loss: 2.158211370309194

Epoch: 5| Step: 7
Training loss: 2.008739471435547
Validation loss: 2.1716777632633844

Epoch: 5| Step: 8
Training loss: 2.1146769523620605
Validation loss: 2.163584202528

Epoch: 5| Step: 9
Training loss: 1.521847128868103
Validation loss: 2.1610607504844666

Epoch: 5| Step: 10
Training loss: 1.6455856561660767
Validation loss: 2.158988187710444

Epoch: 5| Step: 11
Training loss: 1.9544007778167725
Validation loss: 2.16842582821846

Epoch: 292| Step: 0
Training loss: 1.804168462753296
Validation loss: 2.1790154178937278

Epoch: 5| Step: 1
Training loss: 1.5320861339569092
Validation loss: 2.161385734875997

Epoch: 5| Step: 2
Training loss: 1.413547158241272
Validation loss: 2.170491556326548

Epoch: 5| Step: 3
Training loss: 1.5875003337860107
Validation loss: 2.1601570347944894

Epoch: 5| Step: 4
Training loss: 2.3402419090270996
Validation loss: 2.162388116121292

Epoch: 5| Step: 5
Training loss: 2.143705368041992
Validation loss: 2.17010664443175

Epoch: 5| Step: 6
Training loss: 1.8088667392730713
Validation loss: 2.1651173333326974

Epoch: 5| Step: 7
Training loss: 1.591331124305725
Validation loss: 2.157398357987404

Epoch: 5| Step: 8
Training loss: 1.9927467107772827
Validation loss: 2.158407673239708

Epoch: 5| Step: 9
Training loss: 1.726417899131775
Validation loss: 2.1662561744451523

Epoch: 5| Step: 10
Training loss: 1.6815249919891357
Validation loss: 2.180162419875463

Epoch: 5| Step: 11
Training loss: 1.5826162099838257
Validation loss: 2.1720919410387673

Epoch: 293| Step: 0
Training loss: 1.2527014017105103
Validation loss: 2.183811902999878

Epoch: 5| Step: 1
Training loss: 1.2024873495101929
Validation loss: 2.1783791730801263

Epoch: 5| Step: 2
Training loss: 2.01676082611084
Validation loss: 2.1789527932802835

Epoch: 5| Step: 3
Training loss: 1.902905821800232
Validation loss: 2.162945439418157

Epoch: 5| Step: 4
Training loss: 2.1932666301727295
Validation loss: 2.1509269575277963

Epoch: 5| Step: 5
Training loss: 2.5694193840026855
Validation loss: 2.1598649670680365

Epoch: 5| Step: 6
Training loss: 1.8738040924072266
Validation loss: 2.146871050198873

Epoch: 5| Step: 7
Training loss: 1.5290064811706543
Validation loss: 2.147906109690666

Epoch: 5| Step: 8
Training loss: 1.562971591949463
Validation loss: 2.1486739118893943

Epoch: 5| Step: 9
Training loss: 1.7252458333969116
Validation loss: 2.1361186852057776

Epoch: 5| Step: 10
Training loss: 2.1060545444488525
Validation loss: 2.146886726220449

Epoch: 5| Step: 11
Training loss: 1.017907977104187
Validation loss: 2.1674763411283493

Epoch: 294| Step: 0
Training loss: 1.786298394203186
Validation loss: 2.169438680013021

Epoch: 5| Step: 1
Training loss: 1.6062473058700562
Validation loss: 2.168552796045939

Epoch: 5| Step: 2
Training loss: 1.5507014989852905
Validation loss: 2.159522627790769

Epoch: 5| Step: 3
Training loss: 1.3419086933135986
Validation loss: 2.1883599112431207

Epoch: 5| Step: 4
Training loss: 1.7020381689071655
Validation loss: 2.163628190755844

Epoch: 5| Step: 5
Training loss: 2.061274290084839
Validation loss: 2.169360597928365

Epoch: 5| Step: 6
Training loss: 1.8655074834823608
Validation loss: 2.151888847351074

Epoch: 5| Step: 7
Training loss: 1.3064887523651123
Validation loss: 2.1448558568954468

Epoch: 5| Step: 8
Training loss: 2.1861348152160645
Validation loss: 2.153566464781761

Epoch: 5| Step: 9
Training loss: 2.466644763946533
Validation loss: 2.153535400827726

Epoch: 5| Step: 10
Training loss: 1.6617857217788696
Validation loss: 2.1462984631458917

Epoch: 5| Step: 11
Training loss: 1.0982630252838135
Validation loss: 2.134221459428469

Epoch: 295| Step: 0
Training loss: 2.1787962913513184
Validation loss: 2.1280571470657983

Epoch: 5| Step: 1
Training loss: 2.0711371898651123
Validation loss: 2.1229757964611053

Epoch: 5| Step: 2
Training loss: 1.9492145776748657
Validation loss: 2.1193421880404153

Epoch: 5| Step: 3
Training loss: 2.049901247024536
Validation loss: 2.136661017934481

Epoch: 5| Step: 4
Training loss: 2.4822440147399902
Validation loss: 2.128885785738627

Epoch: 5| Step: 5
Training loss: 1.8768504858016968
Validation loss: 2.1387902001539865

Epoch: 5| Step: 6
Training loss: 1.9809024333953857
Validation loss: 2.15615909298261

Epoch: 5| Step: 7
Training loss: 1.5628082752227783
Validation loss: 2.1402229567368827

Epoch: 5| Step: 8
Training loss: 1.6352407932281494
Validation loss: 2.162313381830851

Epoch: 5| Step: 9
Training loss: 1.2707575559616089
Validation loss: 2.1676263958215714

Epoch: 5| Step: 10
Training loss: 1.2929885387420654
Validation loss: 2.174517502387365

Epoch: 5| Step: 11
Training loss: 1.4160380363464355
Validation loss: 2.172176937262217

Epoch: 296| Step: 0
Training loss: 1.3972244262695312
Validation loss: 2.177077293395996

Epoch: 5| Step: 1
Training loss: 2.2265055179595947
Validation loss: 2.165513753890991

Epoch: 5| Step: 2
Training loss: 1.4986671209335327
Validation loss: 2.17022014160951

Epoch: 5| Step: 3
Training loss: 2.477008581161499
Validation loss: 2.1869377543528876

Epoch: 5| Step: 4
Training loss: 0.8772830963134766
Validation loss: 2.165670474370321

Epoch: 5| Step: 5
Training loss: 1.628535270690918
Validation loss: 2.1747544606526694

Epoch: 5| Step: 6
Training loss: 2.0904877185821533
Validation loss: 2.194567014773687

Epoch: 5| Step: 7
Training loss: 1.5549840927124023
Validation loss: 2.168211057782173

Epoch: 5| Step: 8
Training loss: 1.751837134361267
Validation loss: 2.1607039123773575

Epoch: 5| Step: 9
Training loss: 2.049129009246826
Validation loss: 2.1613137076298394

Epoch: 5| Step: 10
Training loss: 1.4828705787658691
Validation loss: 2.1585040042797723

Epoch: 5| Step: 11
Training loss: 2.556222438812256
Validation loss: 2.177689249316851

Epoch: 297| Step: 0
Training loss: 1.437150239944458
Validation loss: 2.144893084963163

Epoch: 5| Step: 1
Training loss: 1.572220802307129
Validation loss: 2.168889135122299

Epoch: 5| Step: 2
Training loss: 2.256727695465088
Validation loss: 2.1514317790667215

Epoch: 5| Step: 3
Training loss: 1.843243956565857
Validation loss: 2.1751199861367545

Epoch: 5| Step: 4
Training loss: 1.904730200767517
Validation loss: 2.1463609536488852

Epoch: 5| Step: 5
Training loss: 1.366496205329895
Validation loss: 2.1476825127998986

Epoch: 5| Step: 6
Training loss: 1.9700616598129272
Validation loss: 2.1687582631905875

Epoch: 5| Step: 7
Training loss: 1.306156873703003
Validation loss: 2.169953227043152

Epoch: 5| Step: 8
Training loss: 2.126530170440674
Validation loss: 2.1473459750413895

Epoch: 5| Step: 9
Training loss: 2.040660858154297
Validation loss: 2.1656191051006317

Epoch: 5| Step: 10
Training loss: 1.7611901760101318
Validation loss: 2.1495202680428824

Epoch: 5| Step: 11
Training loss: 0.4347810447216034
Validation loss: 2.162352532148361

Epoch: 298| Step: 0
Training loss: 1.782713532447815
Validation loss: 2.1667009790738425

Epoch: 5| Step: 1
Training loss: 1.7830798625946045
Validation loss: 2.185003161430359

Epoch: 5| Step: 2
Training loss: 1.42593252658844
Validation loss: 2.194934219121933

Epoch: 5| Step: 3
Training loss: 2.2358736991882324
Validation loss: 2.164326290289561

Epoch: 5| Step: 4
Training loss: 1.09633469581604
Validation loss: 2.1644862294197083

Epoch: 5| Step: 5
Training loss: 1.5416589975357056
Validation loss: 2.171660929918289

Epoch: 5| Step: 6
Training loss: 1.8955795764923096
Validation loss: 2.155602221687635

Epoch: 5| Step: 7
Training loss: 2.35874605178833
Validation loss: 2.159793178240458

Epoch: 5| Step: 8
Training loss: 1.7013404369354248
Validation loss: 2.1685727536678314

Epoch: 5| Step: 9
Training loss: 1.2124226093292236
Validation loss: 2.1864342590173087

Epoch: 5| Step: 10
Training loss: 2.0568482875823975
Validation loss: 2.179171313842138

Epoch: 5| Step: 11
Training loss: 2.976219654083252
Validation loss: 2.195879101753235

Epoch: 299| Step: 0
Training loss: 1.6976661682128906
Validation loss: 2.176002115011215

Epoch: 5| Step: 1
Training loss: 1.5590345859527588
Validation loss: 2.1905654271443686

Epoch: 5| Step: 2
Training loss: 1.637526512145996
Validation loss: 2.1616399735212326

Epoch: 5| Step: 3
Training loss: 1.7470085620880127
Validation loss: 2.1786964933077493

Epoch: 5| Step: 4
Training loss: 1.7630527019500732
Validation loss: 2.1631516168514886

Epoch: 5| Step: 5
Training loss: 1.6593097448349
Validation loss: 2.1834914088249207

Epoch: 5| Step: 6
Training loss: 1.9402786493301392
Validation loss: 2.1659273902575173

Epoch: 5| Step: 7
Training loss: 2.187422275543213
Validation loss: 2.1596053888400397

Epoch: 5| Step: 8
Training loss: 1.889642357826233
Validation loss: 2.166770656903585

Epoch: 5| Step: 9
Training loss: 1.70986807346344
Validation loss: 2.1686421732107797

Epoch: 5| Step: 10
Training loss: 1.8041419982910156
Validation loss: 2.1665472785631814

Epoch: 5| Step: 11
Training loss: 0.6379116773605347
Validation loss: 2.1804802119731903

Epoch: 300| Step: 0
Training loss: 1.6886279582977295
Validation loss: 2.1656022866566977

Epoch: 5| Step: 1
Training loss: 1.5539582967758179
Validation loss: 2.164855102698008

Epoch: 5| Step: 2
Training loss: 1.624548316001892
Validation loss: 2.1699532717466354

Epoch: 5| Step: 3
Training loss: 2.081392288208008
Validation loss: 2.17495267589887

Epoch: 5| Step: 4
Training loss: 2.2053427696228027
Validation loss: 2.191559061408043

Epoch: 5| Step: 5
Training loss: 1.5893017053604126
Validation loss: 2.212468147277832

Epoch: 5| Step: 6
Training loss: 1.757106065750122
Validation loss: 2.1910483737786612

Epoch: 5| Step: 7
Training loss: 1.4212592840194702
Validation loss: 2.1908660729726157

Epoch: 5| Step: 8
Training loss: 2.088771104812622
Validation loss: 2.1886277298132577

Epoch: 5| Step: 9
Training loss: 1.6275514364242554
Validation loss: 2.2027425865332284

Epoch: 5| Step: 10
Training loss: 2.251569986343384
Validation loss: 2.186909551421801

Epoch: 5| Step: 11
Training loss: 1.80126953125
Validation loss: 2.1823290636142096

Epoch: 301| Step: 0
Training loss: 2.292142391204834
Validation loss: 2.140776644150416

Epoch: 5| Step: 1
Training loss: 1.7765432596206665
Validation loss: 2.1427026937405267

Epoch: 5| Step: 2
Training loss: 2.4679346084594727
Validation loss: 2.1311371475458145

Epoch: 5| Step: 3
Training loss: 1.7931644916534424
Validation loss: 2.1518030365308127

Epoch: 5| Step: 4
Training loss: 1.5179754495620728
Validation loss: 2.1605597188075385

Epoch: 5| Step: 5
Training loss: 2.2149689197540283
Validation loss: 2.169218137860298

Epoch: 5| Step: 6
Training loss: 2.369270086288452
Validation loss: 2.1771145512660346

Epoch: 5| Step: 7
Training loss: 1.4939602613449097
Validation loss: 2.1600481073061624

Epoch: 5| Step: 8
Training loss: 2.540494441986084
Validation loss: 2.1450816839933395

Epoch: 5| Step: 9
Training loss: 1.7319682836532593
Validation loss: 2.1445824404557547

Epoch: 5| Step: 10
Training loss: 1.5780360698699951
Validation loss: 2.1369925489028296

Epoch: 5| Step: 11
Training loss: 2.4575133323669434
Validation loss: 2.1251814365386963

Epoch: 302| Step: 0
Training loss: 1.6134172677993774
Validation loss: 2.121939703822136

Epoch: 5| Step: 1
Training loss: 1.8721659183502197
Validation loss: 2.127907191713651

Epoch: 5| Step: 2
Training loss: 1.686341643333435
Validation loss: 2.113580877582232

Epoch: 5| Step: 3
Training loss: 2.3089423179626465
Validation loss: 2.110697935024897

Epoch: 5| Step: 4
Training loss: 2.0268003940582275
Validation loss: 2.1124966144561768

Epoch: 5| Step: 5
Training loss: 2.1147098541259766
Validation loss: 2.122946406404177

Epoch: 5| Step: 6
Training loss: 1.8319215774536133
Validation loss: 2.1352407534917197

Epoch: 5| Step: 7
Training loss: 1.726072072982788
Validation loss: 2.135450522104899

Epoch: 5| Step: 8
Training loss: 2.5798897743225098
Validation loss: 2.1551464001337686

Epoch: 5| Step: 9
Training loss: 1.6180686950683594
Validation loss: 2.1704629560311637

Epoch: 5| Step: 10
Training loss: 1.6894140243530273
Validation loss: 2.145899087190628

Epoch: 5| Step: 11
Training loss: 1.9006990194320679
Validation loss: 2.1319940934578576

Epoch: 303| Step: 0
Training loss: 2.0365185737609863
Validation loss: 2.118089944124222

Epoch: 5| Step: 1
Training loss: 1.5211937427520752
Validation loss: 2.105099687973658

Epoch: 5| Step: 2
Training loss: 1.6678615808486938
Validation loss: 2.134106998642286

Epoch: 5| Step: 3
Training loss: 2.260929822921753
Validation loss: 2.13396147886912

Epoch: 5| Step: 4
Training loss: 2.4048500061035156
Validation loss: 2.120384857058525

Epoch: 5| Step: 5
Training loss: 1.4896835088729858
Validation loss: 2.13477815190951

Epoch: 5| Step: 6
Training loss: 1.5472956895828247
Validation loss: 2.137301877140999

Epoch: 5| Step: 7
Training loss: 2.0948688983917236
Validation loss: 2.1252775142590203

Epoch: 5| Step: 8
Training loss: 2.606034517288208
Validation loss: 2.146748493115107

Epoch: 5| Step: 9
Training loss: 1.7094357013702393
Validation loss: 2.1546147565046945

Epoch: 5| Step: 10
Training loss: 1.8054651021957397
Validation loss: 2.1387802809476852

Epoch: 5| Step: 11
Training loss: 1.0345553159713745
Validation loss: 2.146568571527799

Epoch: 304| Step: 0
Training loss: 1.9283663034439087
Validation loss: 2.1505493571360907

Epoch: 5| Step: 1
Training loss: 1.8016026020050049
Validation loss: 2.142033725976944

Epoch: 5| Step: 2
Training loss: 1.938759207725525
Validation loss: 2.1324071238438287

Epoch: 5| Step: 3
Training loss: 1.7578344345092773
Validation loss: 2.156775658329328

Epoch: 5| Step: 4
Training loss: 1.8844019174575806
Validation loss: 2.1606052766243615

Epoch: 5| Step: 5
Training loss: 1.8576040267944336
Validation loss: 2.1449879904588065

Epoch: 5| Step: 6
Training loss: 1.4566571712493896
Validation loss: 2.13632699350516

Epoch: 5| Step: 7
Training loss: 1.6855220794677734
Validation loss: 2.1417151192824044

Epoch: 5| Step: 8
Training loss: 1.7815049886703491
Validation loss: 2.1463052332401276

Epoch: 5| Step: 9
Training loss: 1.715673804283142
Validation loss: 2.166727587580681

Epoch: 5| Step: 10
Training loss: 1.402366280555725
Validation loss: 2.1719747881094613

Epoch: 5| Step: 11
Training loss: 2.424224853515625
Validation loss: 2.1699639161427817

Epoch: 305| Step: 0
Training loss: 1.8219293355941772
Validation loss: 2.2075092494487762

Epoch: 5| Step: 1
Training loss: 2.1472079753875732
Validation loss: 2.2069514244794846

Epoch: 5| Step: 2
Training loss: 1.8682228326797485
Validation loss: 2.2084685315688453

Epoch: 5| Step: 3
Training loss: 1.774505376815796
Validation loss: 2.1919734179973602

Epoch: 5| Step: 4
Training loss: 1.9907162189483643
Validation loss: 2.1922702491283417

Epoch: 5| Step: 5
Training loss: 1.3190534114837646
Validation loss: 2.1789463559786477

Epoch: 5| Step: 6
Training loss: 1.9962447881698608
Validation loss: 2.1922802925109863

Epoch: 5| Step: 7
Training loss: 2.1441562175750732
Validation loss: 2.1793995648622513

Epoch: 5| Step: 8
Training loss: 1.0516279935836792
Validation loss: 2.152419110139211

Epoch: 5| Step: 9
Training loss: 1.8229049444198608
Validation loss: 2.177003969748815

Epoch: 5| Step: 10
Training loss: 1.8245632648468018
Validation loss: 2.171652431289355

Epoch: 5| Step: 11
Training loss: 1.4845143556594849
Validation loss: 2.1787095765272775

Epoch: 306| Step: 0
Training loss: 1.273798942565918
Validation loss: 2.234581937392553

Epoch: 5| Step: 1
Training loss: 2.172008514404297
Validation loss: 2.2041259109973907

Epoch: 5| Step: 2
Training loss: 1.928410291671753
Validation loss: 2.234273393948873

Epoch: 5| Step: 3
Training loss: 1.8649332523345947
Validation loss: 2.2437402506669364

Epoch: 5| Step: 4
Training loss: 2.1399624347686768
Validation loss: 2.2242798854907355

Epoch: 5| Step: 5
Training loss: 1.7711172103881836
Validation loss: 2.232539842526118

Epoch: 5| Step: 6
Training loss: 2.2598094940185547
Validation loss: 2.199166168769201

Epoch: 5| Step: 7
Training loss: 2.1154839992523193
Validation loss: 2.197311749060949

Epoch: 5| Step: 8
Training loss: 1.342336893081665
Validation loss: 2.1709513713916144

Epoch: 5| Step: 9
Training loss: 1.2303415536880493
Validation loss: 2.170059939225515

Epoch: 5| Step: 10
Training loss: 1.792069673538208
Validation loss: 2.1664247512817383

Epoch: 5| Step: 11
Training loss: 2.3463432788848877
Validation loss: 2.15560474495093

Epoch: 307| Step: 0
Training loss: 1.4504023790359497
Validation loss: 2.161557520429293

Epoch: 5| Step: 1
Training loss: 2.3615598678588867
Validation loss: 2.153431927164396

Epoch: 5| Step: 2
Training loss: 1.435807466506958
Validation loss: 2.1590599020322165

Epoch: 5| Step: 3
Training loss: 1.737818717956543
Validation loss: 2.1653071145216622

Epoch: 5| Step: 4
Training loss: 1.318164587020874
Validation loss: 2.1842683056990304

Epoch: 5| Step: 5
Training loss: 1.7782360315322876
Validation loss: 2.1873384217421212

Epoch: 5| Step: 6
Training loss: 2.3756322860717773
Validation loss: 2.1760250329971313

Epoch: 5| Step: 7
Training loss: 1.7954248189926147
Validation loss: 2.1944031566381454

Epoch: 5| Step: 8
Training loss: 1.624481201171875
Validation loss: 2.184476931889852

Epoch: 5| Step: 9
Training loss: 1.8536624908447266
Validation loss: 2.2142537981271744

Epoch: 5| Step: 10
Training loss: 1.9313385486602783
Validation loss: 2.178467487295469

Epoch: 5| Step: 11
Training loss: 1.6236340999603271
Validation loss: 2.1861975391705832

Epoch: 308| Step: 0
Training loss: 2.3437507152557373
Validation loss: 2.173529177904129

Epoch: 5| Step: 1
Training loss: 1.6561015844345093
Validation loss: 2.1976564129193625

Epoch: 5| Step: 2
Training loss: 1.2885738611221313
Validation loss: 2.1880234281222024

Epoch: 5| Step: 3
Training loss: 1.5870848894119263
Validation loss: 2.1879426737626395

Epoch: 5| Step: 4
Training loss: 1.7354131937026978
Validation loss: 2.1941089431444802

Epoch: 5| Step: 5
Training loss: 1.2724279165267944
Validation loss: 2.2030762185653052

Epoch: 5| Step: 6
Training loss: 1.876098871231079
Validation loss: 2.1913276563088098

Epoch: 5| Step: 7
Training loss: 2.396050453186035
Validation loss: 2.175056899587313

Epoch: 5| Step: 8
Training loss: 1.2391456365585327
Validation loss: 2.1622981329758963

Epoch: 5| Step: 9
Training loss: 1.9638198614120483
Validation loss: 2.1771187583605447

Epoch: 5| Step: 10
Training loss: 1.7869840860366821
Validation loss: 2.1758397966623306

Epoch: 5| Step: 11
Training loss: 2.3576974868774414
Validation loss: 2.1708414057890573

Epoch: 309| Step: 0
Training loss: 1.920301079750061
Validation loss: 2.1783524056275687

Epoch: 5| Step: 1
Training loss: 2.185015916824341
Validation loss: 2.163496365149816

Epoch: 5| Step: 2
Training loss: 1.7774293422698975
Validation loss: 2.1641776661078134

Epoch: 5| Step: 3
Training loss: 1.6473844051361084
Validation loss: 2.165543129046758

Epoch: 5| Step: 4
Training loss: 2.140000820159912
Validation loss: 2.1624848743279776

Epoch: 5| Step: 5
Training loss: 1.4822298288345337
Validation loss: 2.171054869890213

Epoch: 5| Step: 6
Training loss: 1.5422090291976929
Validation loss: 2.163419802983602

Epoch: 5| Step: 7
Training loss: 1.57292902469635
Validation loss: 2.187934786081314

Epoch: 5| Step: 8
Training loss: 1.7402503490447998
Validation loss: 2.1745933343966803

Epoch: 5| Step: 9
Training loss: 2.0500197410583496
Validation loss: 2.1747867166996

Epoch: 5| Step: 10
Training loss: 1.1585298776626587
Validation loss: 2.195608973503113

Epoch: 5| Step: 11
Training loss: 1.9258220195770264
Validation loss: 2.163817102710406

Epoch: 310| Step: 0
Training loss: 2.45387601852417
Validation loss: 2.1905391265948615

Epoch: 5| Step: 1
Training loss: 1.4369932413101196
Validation loss: 2.1836985299984613

Epoch: 5| Step: 2
Training loss: 1.748692512512207
Validation loss: 2.2019422550996146

Epoch: 5| Step: 3
Training loss: 1.4988113641738892
Validation loss: 2.184552182753881

Epoch: 5| Step: 4
Training loss: 1.8884004354476929
Validation loss: 2.1680768678585687

Epoch: 5| Step: 5
Training loss: 1.512233018875122
Validation loss: 2.182227502266566

Epoch: 5| Step: 6
Training loss: 1.5872470140457153
Validation loss: 2.1785572320222855

Epoch: 5| Step: 7
Training loss: 1.9586375951766968
Validation loss: 2.1565843522548676

Epoch: 5| Step: 8
Training loss: 2.099276065826416
Validation loss: 2.1608053743839264

Epoch: 5| Step: 9
Training loss: 1.6123250722885132
Validation loss: 2.175628493229548

Epoch: 5| Step: 10
Training loss: 1.7056316137313843
Validation loss: 2.1805532723665237

Epoch: 5| Step: 11
Training loss: 0.5805072784423828
Validation loss: 2.1800840695699057

Epoch: 311| Step: 0
Training loss: 2.198793888092041
Validation loss: 2.1766996731360755

Epoch: 5| Step: 1
Training loss: 1.97006094455719
Validation loss: 2.1819620033105216

Epoch: 5| Step: 2
Training loss: 1.2342808246612549
Validation loss: 2.1766274670759835

Epoch: 5| Step: 3
Training loss: 1.42986261844635
Validation loss: 2.1938533087571463

Epoch: 5| Step: 4
Training loss: 1.999258279800415
Validation loss: 2.2001153429349265

Epoch: 5| Step: 5
Training loss: 1.07589852809906
Validation loss: 2.20676917831103

Epoch: 5| Step: 6
Training loss: 1.1138279438018799
Validation loss: 2.214444319407145

Epoch: 5| Step: 7
Training loss: 2.2577970027923584
Validation loss: 2.2216531137625375

Epoch: 5| Step: 8
Training loss: 2.1597485542297363
Validation loss: 2.210188632210096

Epoch: 5| Step: 9
Training loss: 2.1839308738708496
Validation loss: 2.197945008675257

Epoch: 5| Step: 10
Training loss: 1.701470136642456
Validation loss: 2.195677096645037

Epoch: 5| Step: 11
Training loss: 1.8177002668380737
Validation loss: 2.201631406943003

Epoch: 312| Step: 0
Training loss: 1.4960752725601196
Validation loss: 2.177739138404528

Epoch: 5| Step: 1
Training loss: 1.8651243448257446
Validation loss: 2.1423496504624686

Epoch: 5| Step: 2
Training loss: 1.5870287418365479
Validation loss: 2.144293268521627

Epoch: 5| Step: 3
Training loss: 1.4750065803527832
Validation loss: 2.151974375049273

Epoch: 5| Step: 4
Training loss: 2.0859215259552
Validation loss: 2.1360622942447662

Epoch: 5| Step: 5
Training loss: 1.735774278640747
Validation loss: 2.149603843688965

Epoch: 5| Step: 6
Training loss: 2.2480955123901367
Validation loss: 2.15738046169281

Epoch: 5| Step: 7
Training loss: 1.9256904125213623
Validation loss: 2.148326446612676

Epoch: 5| Step: 8
Training loss: 2.6429717540740967
Validation loss: 2.164604445298513

Epoch: 5| Step: 9
Training loss: 2.7037527561187744
Validation loss: 2.154521013299624

Epoch: 5| Step: 10
Training loss: 2.3766026496887207
Validation loss: 2.1514360308647156

Epoch: 5| Step: 11
Training loss: 1.3524812459945679
Validation loss: 2.1490261952082315

Epoch: 313| Step: 0
Training loss: 2.07489013671875
Validation loss: 2.144860948125521

Epoch: 5| Step: 1
Training loss: 1.5471869707107544
Validation loss: 2.141626328229904

Epoch: 5| Step: 2
Training loss: 1.8184754848480225
Validation loss: 2.137380992372831

Epoch: 5| Step: 3
Training loss: 1.7895195484161377
Validation loss: 2.126541182398796

Epoch: 5| Step: 4
Training loss: 2.249788761138916
Validation loss: 2.1442421873410544

Epoch: 5| Step: 5
Training loss: 2.3165392875671387
Validation loss: 2.140538881222407

Epoch: 5| Step: 6
Training loss: 2.3705925941467285
Validation loss: 2.1334323783715567

Epoch: 5| Step: 7
Training loss: 1.9981540441513062
Validation loss: 2.1439030468463898

Epoch: 5| Step: 8
Training loss: 1.6858808994293213
Validation loss: 2.127674693862597

Epoch: 5| Step: 9
Training loss: 2.0157105922698975
Validation loss: 2.1460144072771072

Epoch: 5| Step: 10
Training loss: 2.2495036125183105
Validation loss: 2.1223366359869638

Epoch: 5| Step: 11
Training loss: 2.480759620666504
Validation loss: 2.1102169106403985

Epoch: 314| Step: 0
Training loss: 2.1737117767333984
Validation loss: 2.1608016043901443

Epoch: 5| Step: 1
Training loss: 1.717832326889038
Validation loss: 2.160687247912089

Epoch: 5| Step: 2
Training loss: 2.04900860786438
Validation loss: 2.1634766658147178

Epoch: 5| Step: 3
Training loss: 1.5656784772872925
Validation loss: 2.166689395904541

Epoch: 5| Step: 4
Training loss: 1.1831772327423096
Validation loss: 2.170628766218821

Epoch: 5| Step: 5
Training loss: 1.694470763206482
Validation loss: 2.1821665366490683

Epoch: 5| Step: 6
Training loss: 1.4239039421081543
Validation loss: 2.1799121300379434

Epoch: 5| Step: 7
Training loss: 2.343170166015625
Validation loss: 2.1788700371980667

Epoch: 5| Step: 8
Training loss: 2.1923539638519287
Validation loss: 2.1880727062622705

Epoch: 5| Step: 9
Training loss: 1.7795432806015015
Validation loss: 2.1860554218292236

Epoch: 5| Step: 10
Training loss: 1.8468739986419678
Validation loss: 2.175319790840149

Epoch: 5| Step: 11
Training loss: 3.3217759132385254
Validation loss: 2.174992779890696

Epoch: 315| Step: 0
Training loss: 2.2574524879455566
Validation loss: 2.1857959926128387

Epoch: 5| Step: 1
Training loss: 2.123825788497925
Validation loss: 2.1784164855877557

Epoch: 5| Step: 2
Training loss: 1.953070044517517
Validation loss: 2.204122543334961

Epoch: 5| Step: 3
Training loss: 1.6287028789520264
Validation loss: 2.1851474394400916

Epoch: 5| Step: 4
Training loss: 1.4639440774917603
Validation loss: 2.188137302796046

Epoch: 5| Step: 5
Training loss: 1.228574514389038
Validation loss: 2.180431693792343

Epoch: 5| Step: 6
Training loss: 1.9212276935577393
Validation loss: 2.1613819350798926

Epoch: 5| Step: 7
Training loss: 1.6085011959075928
Validation loss: 2.1735829412937164

Epoch: 5| Step: 8
Training loss: 1.972002387046814
Validation loss: 2.1678653756777444

Epoch: 5| Step: 9
Training loss: 1.957784652709961
Validation loss: 2.178668717543284

Epoch: 5| Step: 10
Training loss: 1.5297266244888306
Validation loss: 2.184594069917997

Epoch: 5| Step: 11
Training loss: 2.0913026332855225
Validation loss: 2.189281443754832

Epoch: 316| Step: 0
Training loss: 1.4904619455337524
Validation loss: 2.2018270194530487

Epoch: 5| Step: 1
Training loss: 1.9921696186065674
Validation loss: 2.2109620620807013

Epoch: 5| Step: 2
Training loss: 1.5860044956207275
Validation loss: 2.2008338620265326

Epoch: 5| Step: 3
Training loss: 1.575688362121582
Validation loss: 2.204566260178884

Epoch: 5| Step: 4
Training loss: 1.9448277950286865
Validation loss: 2.2182303965091705

Epoch: 5| Step: 5
Training loss: 1.79633367061615
Validation loss: 2.1992945075035095

Epoch: 5| Step: 6
Training loss: 1.3947139978408813
Validation loss: 2.16733326514562

Epoch: 5| Step: 7
Training loss: 1.9567972421646118
Validation loss: 2.175098871191343

Epoch: 5| Step: 8
Training loss: 1.3609592914581299
Validation loss: 2.1593792736530304

Epoch: 5| Step: 9
Training loss: 2.0894789695739746
Validation loss: 2.1630883514881134

Epoch: 5| Step: 10
Training loss: 2.282256603240967
Validation loss: 2.175983930627505

Epoch: 5| Step: 11
Training loss: 1.0557955503463745
Validation loss: 2.1566753635803857

Epoch: 317| Step: 0
Training loss: 1.7677090167999268
Validation loss: 2.1451940486828485

Epoch: 5| Step: 1
Training loss: 1.3222755193710327
Validation loss: 2.161650225520134

Epoch: 5| Step: 2
Training loss: 1.9483121633529663
Validation loss: 2.146364395817121

Epoch: 5| Step: 3
Training loss: 1.6294538974761963
Validation loss: 2.1592881878217063

Epoch: 5| Step: 4
Training loss: 2.024435043334961
Validation loss: 2.173770770430565

Epoch: 5| Step: 5
Training loss: 2.4355087280273438
Validation loss: 2.166095639268557

Epoch: 5| Step: 6
Training loss: 1.6164748668670654
Validation loss: 2.178211917479833

Epoch: 5| Step: 7
Training loss: 1.6237300634384155
Validation loss: 2.1728173394997916

Epoch: 5| Step: 8
Training loss: 1.5630576610565186
Validation loss: 2.1876876205205917

Epoch: 5| Step: 9
Training loss: 1.5983176231384277
Validation loss: 2.175360227624575

Epoch: 5| Step: 10
Training loss: 1.752121925354004
Validation loss: 2.1906133691469827

Epoch: 5| Step: 11
Training loss: 2.4588730335235596
Validation loss: 2.1860719422499337

Epoch: 318| Step: 0
Training loss: 1.459608793258667
Validation loss: 2.191400036215782

Epoch: 5| Step: 1
Training loss: 1.4340667724609375
Validation loss: 2.177326813340187

Epoch: 5| Step: 2
Training loss: 1.9996236562728882
Validation loss: 2.174169510602951

Epoch: 5| Step: 3
Training loss: 1.3694913387298584
Validation loss: 2.16032745440801

Epoch: 5| Step: 4
Training loss: 2.0595662593841553
Validation loss: 2.151020899415016

Epoch: 5| Step: 5
Training loss: 2.2063345909118652
Validation loss: 2.15668116013209

Epoch: 5| Step: 6
Training loss: 1.884159803390503
Validation loss: 2.177699998021126

Epoch: 5| Step: 7
Training loss: 1.948250412940979
Validation loss: 2.165221164623896

Epoch: 5| Step: 8
Training loss: 1.3595020771026611
Validation loss: 2.15150477985541

Epoch: 5| Step: 9
Training loss: 1.639500379562378
Validation loss: 2.184167757630348

Epoch: 5| Step: 10
Training loss: 1.6656417846679688
Validation loss: 2.157642354567846

Epoch: 5| Step: 11
Training loss: 1.683281660079956
Validation loss: 2.187876204649607

Epoch: 319| Step: 0
Training loss: 1.9449489116668701
Validation loss: 2.1872692306836448

Epoch: 5| Step: 1
Training loss: 2.2825441360473633
Validation loss: 2.1831078231334686

Epoch: 5| Step: 2
Training loss: 1.6412273645401
Validation loss: 2.188910777370135

Epoch: 5| Step: 3
Training loss: 1.6064332723617554
Validation loss: 2.1850921909014382

Epoch: 5| Step: 4
Training loss: 1.8578180074691772
Validation loss: 2.16812701523304

Epoch: 5| Step: 5
Training loss: 1.6643584966659546
Validation loss: 2.1622181236743927

Epoch: 5| Step: 6
Training loss: 1.7296661138534546
Validation loss: 2.1779548972845078

Epoch: 5| Step: 7
Training loss: 1.0768225193023682
Validation loss: 2.1586992343266806

Epoch: 5| Step: 8
Training loss: 1.957951307296753
Validation loss: 2.1605156461397805

Epoch: 5| Step: 9
Training loss: 2.011807680130005
Validation loss: 2.17280620833238

Epoch: 5| Step: 10
Training loss: 1.266814947128296
Validation loss: 2.167824516693751

Epoch: 5| Step: 11
Training loss: 0.8266873359680176
Validation loss: 2.171639477213224

Epoch: 320| Step: 0
Training loss: 1.176378846168518
Validation loss: 2.1871345539887748

Epoch: 5| Step: 1
Training loss: 1.6781256198883057
Validation loss: 2.180785616238912

Epoch: 5| Step: 2
Training loss: 1.367961049079895
Validation loss: 2.1872466454903283

Epoch: 5| Step: 3
Training loss: 1.6020981073379517
Validation loss: 2.181931654612223

Epoch: 5| Step: 4
Training loss: 1.7106157541275024
Validation loss: 2.191648488243421

Epoch: 5| Step: 5
Training loss: 2.0014445781707764
Validation loss: 2.2275040398041406

Epoch: 5| Step: 6
Training loss: 1.7473655939102173
Validation loss: 2.1970114509264627

Epoch: 5| Step: 7
Training loss: 1.8102213144302368
Validation loss: 2.2185456454753876

Epoch: 5| Step: 8
Training loss: 1.9812332391738892
Validation loss: 2.1900272220373154

Epoch: 5| Step: 9
Training loss: 2.1526107788085938
Validation loss: 2.1697714626789093

Epoch: 5| Step: 10
Training loss: 1.7292811870574951
Validation loss: 2.1692856351534524

Epoch: 5| Step: 11
Training loss: 2.4755191802978516
Validation loss: 2.1801555206378302

Epoch: 321| Step: 0
Training loss: 1.9640982151031494
Validation loss: 2.1970041692256927

Epoch: 5| Step: 1
Training loss: 1.7096474170684814
Validation loss: 2.180091048280398

Epoch: 5| Step: 2
Training loss: 1.7985633611679077
Validation loss: 2.1955801447232566

Epoch: 5| Step: 3
Training loss: 1.7624351978302002
Validation loss: 2.1830430825551352

Epoch: 5| Step: 4
Training loss: 1.7278140783309937
Validation loss: 2.1834002981583276

Epoch: 5| Step: 5
Training loss: 1.667215347290039
Validation loss: 2.177666192253431

Epoch: 5| Step: 6
Training loss: 2.103175640106201
Validation loss: 2.1830860674381256

Epoch: 5| Step: 7
Training loss: 1.8083155155181885
Validation loss: 2.168442020813624

Epoch: 5| Step: 8
Training loss: 1.1453921794891357
Validation loss: 2.172113388776779

Epoch: 5| Step: 9
Training loss: 1.683858871459961
Validation loss: 2.1496481200059256

Epoch: 5| Step: 10
Training loss: 1.6011898517608643
Validation loss: 2.151733840505282

Epoch: 5| Step: 11
Training loss: 1.3245882987976074
Validation loss: 2.162780374288559

Epoch: 322| Step: 0
Training loss: 2.1383118629455566
Validation loss: 2.1564576625823975

Epoch: 5| Step: 1
Training loss: 2.3229079246520996
Validation loss: 2.1651600152254105

Epoch: 5| Step: 2
Training loss: 1.4539369344711304
Validation loss: 2.1790468394756317

Epoch: 5| Step: 3
Training loss: 2.0925354957580566
Validation loss: 2.1632641901572547

Epoch: 5| Step: 4
Training loss: 1.9477936029434204
Validation loss: 2.175012836853663

Epoch: 5| Step: 5
Training loss: 1.4619392156600952
Validation loss: 2.2029621601104736

Epoch: 5| Step: 6
Training loss: 1.4678394794464111
Validation loss: 2.209859147667885

Epoch: 5| Step: 7
Training loss: 1.6988534927368164
Validation loss: 2.197163720925649

Epoch: 5| Step: 8
Training loss: 1.8835073709487915
Validation loss: 2.2143370310465493

Epoch: 5| Step: 9
Training loss: 1.7022302150726318
Validation loss: 2.1870978573958078

Epoch: 5| Step: 10
Training loss: 1.3561601638793945
Validation loss: 2.176729202270508

Epoch: 5| Step: 11
Training loss: 1.541915774345398
Validation loss: 2.150136560201645

Epoch: 323| Step: 0
Training loss: 1.7598402500152588
Validation loss: 2.1839889883995056

Epoch: 5| Step: 1
Training loss: 1.8162720203399658
Validation loss: 2.1474639773368835

Epoch: 5| Step: 2
Training loss: 1.7619863748550415
Validation loss: 2.1574606647094092

Epoch: 5| Step: 3
Training loss: 2.92747163772583
Validation loss: 2.1478555301825204

Epoch: 5| Step: 4
Training loss: 1.072892189025879
Validation loss: 2.17157174150149

Epoch: 5| Step: 5
Training loss: 1.7060880661010742
Validation loss: 2.1687785188357034

Epoch: 5| Step: 6
Training loss: 1.6470649242401123
Validation loss: 2.1772776345411935

Epoch: 5| Step: 7
Training loss: 1.7883914709091187
Validation loss: 2.1808938930432

Epoch: 5| Step: 8
Training loss: 1.3170902729034424
Validation loss: 2.2185210585594177

Epoch: 5| Step: 9
Training loss: 1.4532592296600342
Validation loss: 2.1931932965914407

Epoch: 5| Step: 10
Training loss: 1.37107515335083
Validation loss: 2.2062946955362954

Epoch: 5| Step: 11
Training loss: 2.671908378601074
Validation loss: 2.195348491271337

Epoch: 324| Step: 0
Training loss: 1.350804090499878
Validation loss: 2.1900805085897446

Epoch: 5| Step: 1
Training loss: 1.9973676204681396
Validation loss: 2.2248201419909797

Epoch: 5| Step: 2
Training loss: 1.6903388500213623
Validation loss: 2.242290496826172

Epoch: 5| Step: 3
Training loss: 1.930015206336975
Validation loss: 2.2381998548905053

Epoch: 5| Step: 4
Training loss: 1.2371164560317993
Validation loss: 2.2194864253203073

Epoch: 5| Step: 5
Training loss: 1.337287187576294
Validation loss: 2.226765811443329

Epoch: 5| Step: 6
Training loss: 2.730855941772461
Validation loss: 2.2332178751627603

Epoch: 5| Step: 7
Training loss: 1.4901211261749268
Validation loss: 2.221036672592163

Epoch: 5| Step: 8
Training loss: 1.643578290939331
Validation loss: 2.206755891442299

Epoch: 5| Step: 9
Training loss: 1.7405612468719482
Validation loss: 2.1954733630021415

Epoch: 5| Step: 10
Training loss: 1.9355061054229736
Validation loss: 2.1912482380867004

Epoch: 5| Step: 11
Training loss: 1.5133295059204102
Validation loss: 2.1868750105301538

Epoch: 325| Step: 0
Training loss: 1.322157859802246
Validation loss: 2.1949022511641183

Epoch: 5| Step: 1
Training loss: 1.9549354314804077
Validation loss: 2.2181003292401633

Epoch: 5| Step: 2
Training loss: 2.2405261993408203
Validation loss: 2.178256720304489

Epoch: 5| Step: 3
Training loss: 1.7319685220718384
Validation loss: 2.1857985655466714

Epoch: 5| Step: 4
Training loss: 1.6924108266830444
Validation loss: 2.1808493932088218

Epoch: 5| Step: 5
Training loss: 1.724541425704956
Validation loss: 2.184966042637825

Epoch: 5| Step: 6
Training loss: 1.6240208148956299
Validation loss: 2.1792045483986535

Epoch: 5| Step: 7
Training loss: 1.575134038925171
Validation loss: 2.208714505036672

Epoch: 5| Step: 8
Training loss: 1.774513602256775
Validation loss: 2.1890552093585334

Epoch: 5| Step: 9
Training loss: 1.4794315099716187
Validation loss: 2.1907848715782166

Epoch: 5| Step: 10
Training loss: 1.3259527683258057
Validation loss: 2.1874175618092218

Epoch: 5| Step: 11
Training loss: 2.06927490234375
Validation loss: 2.2122730761766434

Epoch: 326| Step: 0
Training loss: 1.699634313583374
Validation loss: 2.1639905671278634

Epoch: 5| Step: 1
Training loss: 1.9682047367095947
Validation loss: 2.2106289317210517

Epoch: 5| Step: 2
Training loss: 1.1605738401412964
Validation loss: 2.2133963902791343

Epoch: 5| Step: 3
Training loss: 1.6243019104003906
Validation loss: 2.1944614748160043

Epoch: 5| Step: 4
Training loss: 1.7892353534698486
Validation loss: 2.183135171731313

Epoch: 5| Step: 5
Training loss: 1.8530616760253906
Validation loss: 2.1901173144578934

Epoch: 5| Step: 6
Training loss: 1.7031482458114624
Validation loss: 2.1987169136603675

Epoch: 5| Step: 7
Training loss: 1.8984237909317017
Validation loss: 2.1798940300941467

Epoch: 5| Step: 8
Training loss: 1.7185828685760498
Validation loss: 2.201770474513372

Epoch: 5| Step: 9
Training loss: 1.5746583938598633
Validation loss: 2.1890424291292825

Epoch: 5| Step: 10
Training loss: 1.3861424922943115
Validation loss: 2.197178597251574

Epoch: 5| Step: 11
Training loss: 2.500312328338623
Validation loss: 2.1796155820290246

Epoch: 327| Step: 0
Training loss: 1.8835227489471436
Validation loss: 2.1771540145079293

Epoch: 5| Step: 1
Training loss: 1.5792925357818604
Validation loss: 2.1742795507113137

Epoch: 5| Step: 2
Training loss: 2.167724370956421
Validation loss: 2.1485107243061066

Epoch: 5| Step: 3
Training loss: 2.156696319580078
Validation loss: 2.153465131918589

Epoch: 5| Step: 4
Training loss: 1.9560048580169678
Validation loss: 2.1432691713174186

Epoch: 5| Step: 5
Training loss: 1.7591350078582764
Validation loss: 2.165945842862129

Epoch: 5| Step: 6
Training loss: 1.9844744205474854
Validation loss: 2.1957941353321075

Epoch: 5| Step: 7
Training loss: 1.7286123037338257
Validation loss: 2.1575422137975693

Epoch: 5| Step: 8
Training loss: 1.2546056509017944
Validation loss: 2.170197919011116

Epoch: 5| Step: 9
Training loss: 1.8395869731903076
Validation loss: 2.1892469227313995

Epoch: 5| Step: 10
Training loss: 1.2760975360870361
Validation loss: 2.1602283318837485

Epoch: 5| Step: 11
Training loss: 0.7523088455200195
Validation loss: 2.17684871951739

Epoch: 328| Step: 0
Training loss: 1.6682021617889404
Validation loss: 2.209460437297821

Epoch: 5| Step: 1
Training loss: 1.9740571975708008
Validation loss: 2.163185258706411

Epoch: 5| Step: 2
Training loss: 1.9384028911590576
Validation loss: 2.1781498988469443

Epoch: 5| Step: 3
Training loss: 1.449145793914795
Validation loss: 2.191288282473882

Epoch: 5| Step: 4
Training loss: 1.6167547702789307
Validation loss: 2.1965223848819733

Epoch: 5| Step: 5
Training loss: 1.47207510471344
Validation loss: 2.164845814307531

Epoch: 5| Step: 6
Training loss: 1.7251421213150024
Validation loss: 2.137763390938441

Epoch: 5| Step: 7
Training loss: 1.5776331424713135
Validation loss: 2.1482906341552734

Epoch: 5| Step: 8
Training loss: 2.123049736022949
Validation loss: 2.145555963118871

Epoch: 5| Step: 9
Training loss: 1.8622000217437744
Validation loss: 2.145994404951731

Epoch: 5| Step: 10
Training loss: 1.725703239440918
Validation loss: 2.138035833835602

Epoch: 5| Step: 11
Training loss: 1.92619788646698
Validation loss: 2.1494087328513465

Epoch: 329| Step: 0
Training loss: 1.5468379259109497
Validation loss: 2.1533223390579224

Epoch: 5| Step: 1
Training loss: 1.3986942768096924
Validation loss: 2.1529376109441123

Epoch: 5| Step: 2
Training loss: 1.5641109943389893
Validation loss: 2.16408434510231

Epoch: 5| Step: 3
Training loss: 1.5219848155975342
Validation loss: 2.175120954712232

Epoch: 5| Step: 4
Training loss: 1.5310413837432861
Validation loss: 2.1838090419769287

Epoch: 5| Step: 5
Training loss: 3.0815067291259766
Validation loss: 2.202402969201406

Epoch: 5| Step: 6
Training loss: 1.3549741506576538
Validation loss: 2.212975194056829

Epoch: 5| Step: 7
Training loss: 1.7990392446517944
Validation loss: 2.199777806798617

Epoch: 5| Step: 8
Training loss: 1.7880477905273438
Validation loss: 2.2213178674379983

Epoch: 5| Step: 9
Training loss: 1.3924981355667114
Validation loss: 2.2192874054114022

Epoch: 5| Step: 10
Training loss: 1.797306776046753
Validation loss: 2.1851638505856195

Epoch: 5| Step: 11
Training loss: 2.508272409439087
Validation loss: 2.180117438236872

Epoch: 330| Step: 0
Training loss: 1.8051702976226807
Validation loss: 2.1807040522495904

Epoch: 5| Step: 1
Training loss: 1.9786186218261719
Validation loss: 2.181878720720609

Epoch: 5| Step: 2
Training loss: 1.583716630935669
Validation loss: 2.207907790939013

Epoch: 5| Step: 3
Training loss: 1.3508859872817993
Validation loss: 2.1716105540593467

Epoch: 5| Step: 4
Training loss: 1.2024949789047241
Validation loss: 2.1788388987382254

Epoch: 5| Step: 5
Training loss: 1.4084784984588623
Validation loss: 2.176473468542099

Epoch: 5| Step: 6
Training loss: 1.7640457153320312
Validation loss: 2.2016304979721704

Epoch: 5| Step: 7
Training loss: 2.2007248401641846
Validation loss: 2.1978713423013687

Epoch: 5| Step: 8
Training loss: 1.6134223937988281
Validation loss: 2.20316673318545

Epoch: 5| Step: 9
Training loss: 1.7547184228897095
Validation loss: 2.2100788603226342

Epoch: 5| Step: 10
Training loss: 1.8171865940093994
Validation loss: 2.225705479582151

Epoch: 5| Step: 11
Training loss: 1.2942057847976685
Validation loss: 2.218908096353213

Epoch: 331| Step: 0
Training loss: 1.4871361255645752
Validation loss: 2.218791643778483

Epoch: 5| Step: 1
Training loss: 1.468117594718933
Validation loss: 2.2420229067405066

Epoch: 5| Step: 2
Training loss: 1.5672012567520142
Validation loss: 2.213712155818939

Epoch: 5| Step: 3
Training loss: 1.5896235704421997
Validation loss: 2.2224684059619904

Epoch: 5| Step: 4
Training loss: 1.6186025142669678
Validation loss: 2.202867776155472

Epoch: 5| Step: 5
Training loss: 1.9015674591064453
Validation loss: 2.200131277243296

Epoch: 5| Step: 6
Training loss: 1.5935802459716797
Validation loss: 2.2056699693202972

Epoch: 5| Step: 7
Training loss: 2.484833240509033
Validation loss: 2.186205262939135

Epoch: 5| Step: 8
Training loss: 1.3478450775146484
Validation loss: 2.186282902956009

Epoch: 5| Step: 9
Training loss: 2.266944408416748
Validation loss: 2.1706310162941613

Epoch: 5| Step: 10
Training loss: 1.2598278522491455
Validation loss: 2.173835282524427

Epoch: 5| Step: 11
Training loss: 2.031069040298462
Validation loss: 2.1858352025349936

Epoch: 332| Step: 0
Training loss: 1.5444982051849365
Validation loss: 2.1943054099877677

Epoch: 5| Step: 1
Training loss: 2.092545747756958
Validation loss: 2.201147144039472

Epoch: 5| Step: 2
Training loss: 0.9209362268447876
Validation loss: 2.19503191113472

Epoch: 5| Step: 3
Training loss: 1.1180834770202637
Validation loss: 2.1927256186803183

Epoch: 5| Step: 4
Training loss: 1.5913679599761963
Validation loss: 2.2010895907878876

Epoch: 5| Step: 5
Training loss: 1.9374603033065796
Validation loss: 2.234601065516472

Epoch: 5| Step: 6
Training loss: 2.627401828765869
Validation loss: 2.2321041971445084

Epoch: 5| Step: 7
Training loss: 1.8443492650985718
Validation loss: 2.2275076111157737

Epoch: 5| Step: 8
Training loss: 1.2847248315811157
Validation loss: 2.2344225148359933

Epoch: 5| Step: 9
Training loss: 1.5332671403884888
Validation loss: 2.2161248375972114

Epoch: 5| Step: 10
Training loss: 2.104123592376709
Validation loss: 2.204221874475479

Epoch: 5| Step: 11
Training loss: 1.14703369140625
Validation loss: 2.1774593194325766

Epoch: 333| Step: 0
Training loss: 1.808274269104004
Validation loss: 2.1962827841440835

Epoch: 5| Step: 1
Training loss: 1.544128179550171
Validation loss: 2.1800606896479926

Epoch: 5| Step: 2
Training loss: 1.9783337116241455
Validation loss: 2.1683842837810516

Epoch: 5| Step: 3
Training loss: 1.5265939235687256
Validation loss: 2.1580299387375512

Epoch: 5| Step: 4
Training loss: 1.229313611984253
Validation loss: 2.152007112900416

Epoch: 5| Step: 5
Training loss: 1.632880449295044
Validation loss: 2.164376730720202

Epoch: 5| Step: 6
Training loss: 1.7899729013442993
Validation loss: 2.172086253762245

Epoch: 5| Step: 7
Training loss: 1.598044991493225
Validation loss: 2.1767469396193824

Epoch: 5| Step: 8
Training loss: 1.789939284324646
Validation loss: 2.201942577958107

Epoch: 5| Step: 9
Training loss: 1.8931639194488525
Validation loss: 2.199749772747358

Epoch: 5| Step: 10
Training loss: 1.8348039388656616
Validation loss: 2.235272337992986

Epoch: 5| Step: 11
Training loss: 1.7883985042572021
Validation loss: 2.273127088944117

Epoch: 334| Step: 0
Training loss: 1.5360472202301025
Validation loss: 2.215830902258555

Epoch: 5| Step: 1
Training loss: 1.6975812911987305
Validation loss: 2.216183379292488

Epoch: 5| Step: 2
Training loss: 2.3657782077789307
Validation loss: 2.1608033776283264

Epoch: 5| Step: 3
Training loss: 1.6103134155273438
Validation loss: 2.1501783033212027

Epoch: 5| Step: 4
Training loss: 1.7093374729156494
Validation loss: 2.1571668287118277

Epoch: 5| Step: 5
Training loss: 1.7172714471817017
Validation loss: 2.1600093146165213

Epoch: 5| Step: 6
Training loss: 2.720686674118042
Validation loss: 2.1527790129184723

Epoch: 5| Step: 7
Training loss: 1.3628343343734741
Validation loss: 2.147287850578626

Epoch: 5| Step: 8
Training loss: 1.8152519464492798
Validation loss: 2.156514267126719

Epoch: 5| Step: 9
Training loss: 1.1836583614349365
Validation loss: 2.1682647118965783

Epoch: 5| Step: 10
Training loss: 1.2304540872573853
Validation loss: 2.1557717472314835

Epoch: 5| Step: 11
Training loss: 1.3190773725509644
Validation loss: 2.1784249991178513

Epoch: 335| Step: 0
Training loss: 1.678160309791565
Validation loss: 2.159205342332522

Epoch: 5| Step: 1
Training loss: 1.2200891971588135
Validation loss: 2.1865953505039215

Epoch: 5| Step: 2
Training loss: 1.4107189178466797
Validation loss: 2.173061430454254

Epoch: 5| Step: 3
Training loss: 1.5979204177856445
Validation loss: 2.165305236975352

Epoch: 5| Step: 4
Training loss: 0.9529078602790833
Validation loss: 2.1614073713620505

Epoch: 5| Step: 5
Training loss: 1.9129911661148071
Validation loss: 2.2024841010570526

Epoch: 5| Step: 6
Training loss: 2.028777837753296
Validation loss: 2.1808838695287704

Epoch: 5| Step: 7
Training loss: 1.778894066810608
Validation loss: 2.2023880879084268

Epoch: 5| Step: 8
Training loss: 2.2119691371917725
Validation loss: 2.1899955719709396

Epoch: 5| Step: 9
Training loss: 1.4042537212371826
Validation loss: 2.1866292506456375

Epoch: 5| Step: 10
Training loss: 1.846732497215271
Validation loss: 2.2064992239077887

Epoch: 5| Step: 11
Training loss: 2.2479352951049805
Validation loss: 2.1905003488063812

Epoch: 336| Step: 0
Training loss: 1.9425548315048218
Validation loss: 2.1818140943845115

Epoch: 5| Step: 1
Training loss: 1.5253877639770508
Validation loss: 2.1958238780498505

Epoch: 5| Step: 2
Training loss: 1.4951647520065308
Validation loss: 2.1965187092622123

Epoch: 5| Step: 3
Training loss: 1.7596555948257446
Validation loss: 2.202485258380572

Epoch: 5| Step: 4
Training loss: 1.880744218826294
Validation loss: 2.2114122758309045

Epoch: 5| Step: 5
Training loss: 2.449187994003296
Validation loss: 2.176818052927653

Epoch: 5| Step: 6
Training loss: 1.5614023208618164
Validation loss: 2.176169435183207

Epoch: 5| Step: 7
Training loss: 1.853061318397522
Validation loss: 2.202146997054418

Epoch: 5| Step: 8
Training loss: 1.1871072053909302
Validation loss: 2.1906013439098992

Epoch: 5| Step: 9
Training loss: 0.8424432873725891
Validation loss: 2.1802991976340613

Epoch: 5| Step: 10
Training loss: 1.4053471088409424
Validation loss: 2.2143910974264145

Epoch: 5| Step: 11
Training loss: 2.92097806930542
Validation loss: 2.1752423544724784

Epoch: 337| Step: 0
Training loss: 1.6056022644042969
Validation loss: 2.183458536863327

Epoch: 5| Step: 1
Training loss: 1.4673289060592651
Validation loss: 2.1970187723636627

Epoch: 5| Step: 2
Training loss: 1.0810883045196533
Validation loss: 2.1917077402273812

Epoch: 5| Step: 3
Training loss: 1.9646422863006592
Validation loss: 2.1753856341044107

Epoch: 5| Step: 4
Training loss: 1.9394258260726929
Validation loss: 2.1881717493136725

Epoch: 5| Step: 5
Training loss: 2.1881277561187744
Validation loss: 2.1765197068452835

Epoch: 5| Step: 6
Training loss: 2.0767874717712402
Validation loss: 2.193969448407491

Epoch: 5| Step: 7
Training loss: 1.882910966873169
Validation loss: 2.155415117740631

Epoch: 5| Step: 8
Training loss: 1.1213968992233276
Validation loss: 2.172437051932017

Epoch: 5| Step: 9
Training loss: 1.0024961233139038
Validation loss: 2.2199811786413193

Epoch: 5| Step: 10
Training loss: 2.0112109184265137
Validation loss: 2.186140159765879

Epoch: 5| Step: 11
Training loss: 0.9458397030830383
Validation loss: 2.218785176674525

Epoch: 338| Step: 0
Training loss: 2.156977415084839
Validation loss: 2.1878807892402015

Epoch: 5| Step: 1
Training loss: 1.072948694229126
Validation loss: 2.197764068841934

Epoch: 5| Step: 2
Training loss: 1.6642221212387085
Validation loss: 2.159671892722448

Epoch: 5| Step: 3
Training loss: 1.9064887762069702
Validation loss: 2.1437754333019257

Epoch: 5| Step: 4
Training loss: 1.2664930820465088
Validation loss: 2.1848652015129724

Epoch: 5| Step: 5
Training loss: 1.6342027187347412
Validation loss: 2.1528873443603516

Epoch: 5| Step: 6
Training loss: 1.6760841608047485
Validation loss: 2.179462492465973

Epoch: 5| Step: 7
Training loss: 1.0479332208633423
Validation loss: 2.1790364732344947

Epoch: 5| Step: 8
Training loss: 1.9777250289916992
Validation loss: 2.1979381442070007

Epoch: 5| Step: 9
Training loss: 1.9940468072891235
Validation loss: 2.2104942401250205

Epoch: 5| Step: 10
Training loss: 1.7182286977767944
Validation loss: 2.1984211206436157

Epoch: 5| Step: 11
Training loss: 1.0152069330215454
Validation loss: 2.202773849169413

Epoch: 339| Step: 0
Training loss: 1.7635917663574219
Validation loss: 2.20204588274161

Epoch: 5| Step: 1
Training loss: 0.8463989496231079
Validation loss: 2.1938014030456543

Epoch: 5| Step: 2
Training loss: 1.5832687616348267
Validation loss: 2.2351967046658197

Epoch: 5| Step: 3
Training loss: 1.5405184030532837
Validation loss: 2.1982000271479287

Epoch: 5| Step: 4
Training loss: 2.1411526203155518
Validation loss: 2.240384504199028

Epoch: 5| Step: 5
Training loss: 1.1063416004180908
Validation loss: 2.2041215697924295

Epoch: 5| Step: 6
Training loss: 1.8452907800674438
Validation loss: 2.191622575124105

Epoch: 5| Step: 7
Training loss: 2.1972250938415527
Validation loss: 2.1873116294542947

Epoch: 5| Step: 8
Training loss: 1.5148646831512451
Validation loss: 2.1825487514336905

Epoch: 5| Step: 9
Training loss: 1.7188565731048584
Validation loss: 2.2083154022693634

Epoch: 5| Step: 10
Training loss: 1.2880041599273682
Validation loss: 2.190848936637243

Epoch: 5| Step: 11
Training loss: 3.0458381175994873
Validation loss: 2.183535392085711

Epoch: 340| Step: 0
Training loss: 1.4890923500061035
Validation loss: 2.1737174739440284

Epoch: 5| Step: 1
Training loss: 1.175082802772522
Validation loss: 2.169944941997528

Epoch: 5| Step: 2
Training loss: 1.9479258060455322
Validation loss: 2.1825063824653625

Epoch: 5| Step: 3
Training loss: 1.361492395401001
Validation loss: 2.2007450312376022

Epoch: 5| Step: 4
Training loss: 1.8931653499603271
Validation loss: 2.1822557598352432

Epoch: 5| Step: 5
Training loss: 1.7905763387680054
Validation loss: 2.172321230173111

Epoch: 5| Step: 6
Training loss: 1.4897053241729736
Validation loss: 2.179151266813278

Epoch: 5| Step: 7
Training loss: 2.2672061920166016
Validation loss: 2.187418649593989

Epoch: 5| Step: 8
Training loss: 1.535902738571167
Validation loss: 2.1736158629258475

Epoch: 5| Step: 9
Training loss: 1.8403797149658203
Validation loss: 2.176621302962303

Epoch: 5| Step: 10
Training loss: 1.399351954460144
Validation loss: 2.179490099350611

Epoch: 5| Step: 11
Training loss: 1.1962066888809204
Validation loss: 2.1913404762744904

Epoch: 341| Step: 0
Training loss: 1.386457085609436
Validation loss: 2.182332535584768

Epoch: 5| Step: 1
Training loss: 1.5154732465744019
Validation loss: 2.1924523562192917

Epoch: 5| Step: 2
Training loss: 2.0237927436828613
Validation loss: 2.19170473019282

Epoch: 5| Step: 3
Training loss: 1.5616036653518677
Validation loss: 2.2009967863559723

Epoch: 5| Step: 4
Training loss: 2.12058687210083
Validation loss: 2.2037317554155984

Epoch: 5| Step: 5
Training loss: 1.4366775751113892
Validation loss: 2.2050477862358093

Epoch: 5| Step: 6
Training loss: 1.6731560230255127
Validation loss: 2.21530049542586

Epoch: 5| Step: 7
Training loss: 1.9268970489501953
Validation loss: 2.216427763303121

Epoch: 5| Step: 8
Training loss: 1.4390909671783447
Validation loss: 2.239003757635752

Epoch: 5| Step: 9
Training loss: 1.340203881263733
Validation loss: 2.2055830359458923

Epoch: 5| Step: 10
Training loss: 1.5400803089141846
Validation loss: 2.196707546710968

Epoch: 5| Step: 11
Training loss: 0.9983333945274353
Validation loss: 2.2216973155736923

Epoch: 342| Step: 0
Training loss: 1.3326976299285889
Validation loss: 2.235381692647934

Epoch: 5| Step: 1
Training loss: 1.4797258377075195
Validation loss: 2.227099041144053

Epoch: 5| Step: 2
Training loss: 1.4243074655532837
Validation loss: 2.22903303305308

Epoch: 5| Step: 3
Training loss: 1.6868854761123657
Validation loss: 2.2316337128480277

Epoch: 5| Step: 4
Training loss: 1.4771397113800049
Validation loss: 2.1964065929253898

Epoch: 5| Step: 5
Training loss: 1.7550971508026123
Validation loss: 2.201070621609688

Epoch: 5| Step: 6
Training loss: 1.6498998403549194
Validation loss: 2.218904515107473

Epoch: 5| Step: 7
Training loss: 1.3846967220306396
Validation loss: 2.204848806063334

Epoch: 5| Step: 8
Training loss: 1.8359966278076172
Validation loss: 2.2010295391082764

Epoch: 5| Step: 9
Training loss: 1.4657138586044312
Validation loss: 2.2063663601875305

Epoch: 5| Step: 10
Training loss: 1.8510643243789673
Validation loss: 2.1804416676362357

Epoch: 5| Step: 11
Training loss: 1.5882281064987183
Validation loss: 2.193361351887385

Epoch: 343| Step: 0
Training loss: 1.3499491214752197
Validation loss: 2.2095137238502502

Epoch: 5| Step: 1
Training loss: 1.2704169750213623
Validation loss: 2.1744492053985596

Epoch: 5| Step: 2
Training loss: 1.4713592529296875
Validation loss: 2.1841729283332825

Epoch: 5| Step: 3
Training loss: 1.9528844356536865
Validation loss: 2.149916628996531

Epoch: 5| Step: 4
Training loss: 1.7632617950439453
Validation loss: 2.187448427081108

Epoch: 5| Step: 5
Training loss: 1.4038069248199463
Validation loss: 2.183955818414688

Epoch: 5| Step: 6
Training loss: 1.946918249130249
Validation loss: 2.2003526290257773

Epoch: 5| Step: 7
Training loss: 1.534649133682251
Validation loss: 2.231047992904981

Epoch: 5| Step: 8
Training loss: 1.617946982383728
Validation loss: 2.2186391750971475

Epoch: 5| Step: 9
Training loss: 1.6843897104263306
Validation loss: 2.225071370601654

Epoch: 5| Step: 10
Training loss: 2.0209481716156006
Validation loss: 2.253733823696772

Epoch: 5| Step: 11
Training loss: 0.965355634689331
Validation loss: 2.2351096471150718

Epoch: 344| Step: 0
Training loss: 2.1709647178649902
Validation loss: 2.1922981590032578

Epoch: 5| Step: 1
Training loss: 1.2072384357452393
Validation loss: 2.2103726466496787

Epoch: 5| Step: 2
Training loss: 1.4708505868911743
Validation loss: 2.1695380260547004

Epoch: 5| Step: 3
Training loss: 1.6274423599243164
Validation loss: 2.1845297614733377

Epoch: 5| Step: 4
Training loss: 1.3366526365280151
Validation loss: 2.179179127017657

Epoch: 5| Step: 5
Training loss: 1.827335000038147
Validation loss: 2.181891992688179

Epoch: 5| Step: 6
Training loss: 2.2612953186035156
Validation loss: 2.182270437479019

Epoch: 5| Step: 7
Training loss: 1.7375307083129883
Validation loss: 2.1727938751379647

Epoch: 5| Step: 8
Training loss: 1.5582568645477295
Validation loss: 2.1844068517287574

Epoch: 5| Step: 9
Training loss: 1.247159719467163
Validation loss: 2.215029944976171

Epoch: 5| Step: 10
Training loss: 1.4709497690200806
Validation loss: 2.1915924151738486

Epoch: 5| Step: 11
Training loss: 0.8470847606658936
Validation loss: 2.2142876784006753

Epoch: 345| Step: 0
Training loss: 1.2558059692382812
Validation loss: 2.2048018475373587

Epoch: 5| Step: 1
Training loss: 1.6709434986114502
Validation loss: 2.183125853538513

Epoch: 5| Step: 2
Training loss: 1.4578279256820679
Validation loss: 2.207434117794037

Epoch: 5| Step: 3
Training loss: 1.3712551593780518
Validation loss: 2.205836276213328

Epoch: 5| Step: 4
Training loss: 2.308121919631958
Validation loss: 2.220199485619863

Epoch: 5| Step: 5
Training loss: 1.4097630977630615
Validation loss: 2.18065836528937

Epoch: 5| Step: 6
Training loss: 1.4021334648132324
Validation loss: 2.1988593439261117

Epoch: 5| Step: 7
Training loss: 1.7473151683807373
Validation loss: 2.1883411357800164

Epoch: 5| Step: 8
Training loss: 1.9504162073135376
Validation loss: 2.209358443816503

Epoch: 5| Step: 9
Training loss: 1.732782006263733
Validation loss: 2.190114135543505

Epoch: 5| Step: 10
Training loss: 1.5683648586273193
Validation loss: 2.2153726617495217

Epoch: 5| Step: 11
Training loss: 0.7452061176300049
Validation loss: 2.2208118538061776

Epoch: 346| Step: 0
Training loss: 0.9426520466804504
Validation loss: 2.1944238990545273

Epoch: 5| Step: 1
Training loss: 1.7388732433319092
Validation loss: 2.1976952801148095

Epoch: 5| Step: 2
Training loss: 1.3800218105316162
Validation loss: 2.2236788272857666

Epoch: 5| Step: 3
Training loss: 1.7956466674804688
Validation loss: 2.2187473674615226

Epoch: 5| Step: 4
Training loss: 1.6949741840362549
Validation loss: 2.2166957507530847

Epoch: 5| Step: 5
Training loss: 1.5534240007400513
Validation loss: 2.2154083400964737

Epoch: 5| Step: 6
Training loss: 1.4620100259780884
Validation loss: 2.199133033553759

Epoch: 5| Step: 7
Training loss: 1.7968498468399048
Validation loss: 2.1974234779675803

Epoch: 5| Step: 8
Training loss: 1.7834306955337524
Validation loss: 2.1879993875821433

Epoch: 5| Step: 9
Training loss: 2.0849416255950928
Validation loss: 2.2022969871759415

Epoch: 5| Step: 10
Training loss: 1.6493148803710938
Validation loss: 2.207032491763433

Epoch: 5| Step: 11
Training loss: 1.2815775871276855
Validation loss: 2.20439646144708

Epoch: 347| Step: 0
Training loss: 1.4203966856002808
Validation loss: 2.2072036315997443

Epoch: 5| Step: 1
Training loss: 1.7629308700561523
Validation loss: 2.1949377258618674

Epoch: 5| Step: 2
Training loss: 1.3262282609939575
Validation loss: 2.239450067281723

Epoch: 5| Step: 3
Training loss: 1.434696078300476
Validation loss: 2.2296517193317413

Epoch: 5| Step: 4
Training loss: 1.5362331867218018
Validation loss: 2.249733418226242

Epoch: 5| Step: 5
Training loss: 2.2206201553344727
Validation loss: 2.2160189747810364

Epoch: 5| Step: 6
Training loss: 1.3793481588363647
Validation loss: 2.1986917654673257

Epoch: 5| Step: 7
Training loss: 1.4468538761138916
Validation loss: 2.215931862592697

Epoch: 5| Step: 8
Training loss: 1.722692847251892
Validation loss: 2.22046368320783

Epoch: 5| Step: 9
Training loss: 1.7276197671890259
Validation loss: 2.2077545324961343

Epoch: 5| Step: 10
Training loss: 1.8926193714141846
Validation loss: 2.2178308765093484

Epoch: 5| Step: 11
Training loss: 1.1783475875854492
Validation loss: 2.2314919233322144

Epoch: 348| Step: 0
Training loss: 1.4157381057739258
Validation loss: 2.24863538146019

Epoch: 5| Step: 1
Training loss: 1.3469245433807373
Validation loss: 2.221494972705841

Epoch: 5| Step: 2
Training loss: 1.4333746433258057
Validation loss: 2.239228074749311

Epoch: 5| Step: 3
Training loss: 1.1732592582702637
Validation loss: 2.2300280332565308

Epoch: 5| Step: 4
Training loss: 1.4704339504241943
Validation loss: 2.197139541308085

Epoch: 5| Step: 5
Training loss: 1.2955732345581055
Validation loss: 2.209506332874298

Epoch: 5| Step: 6
Training loss: 1.8181251287460327
Validation loss: 2.205724914868673

Epoch: 5| Step: 7
Training loss: 2.386807680130005
Validation loss: 2.198087513446808

Epoch: 5| Step: 8
Training loss: 1.387336015701294
Validation loss: 2.1940536747376123

Epoch: 5| Step: 9
Training loss: 1.9501044750213623
Validation loss: 2.196593756477038

Epoch: 5| Step: 10
Training loss: 1.621996283531189
Validation loss: 2.1913335820039115

Epoch: 5| Step: 11
Training loss: 1.5161300897598267
Validation loss: 2.1954446882009506

Epoch: 349| Step: 0
Training loss: 1.8027803897857666
Validation loss: 2.1829977184534073

Epoch: 5| Step: 1
Training loss: 2.458935260772705
Validation loss: 2.1741570134957633

Epoch: 5| Step: 2
Training loss: 1.6448675394058228
Validation loss: 2.185011158386866

Epoch: 5| Step: 3
Training loss: 1.0970510244369507
Validation loss: 2.180104504028956

Epoch: 5| Step: 4
Training loss: 1.2689329385757446
Validation loss: 2.1761903762817383

Epoch: 5| Step: 5
Training loss: 2.0778326988220215
Validation loss: 2.2010904401540756

Epoch: 5| Step: 6
Training loss: 1.3008047342300415
Validation loss: 2.20588510731856

Epoch: 5| Step: 7
Training loss: 1.400612473487854
Validation loss: 2.201003963748614

Epoch: 5| Step: 8
Training loss: 2.0167882442474365
Validation loss: 2.2189468691746392

Epoch: 5| Step: 9
Training loss: 1.0154685974121094
Validation loss: 2.2382365067799888

Epoch: 5| Step: 10
Training loss: 1.4270546436309814
Validation loss: 2.236686646938324

Epoch: 5| Step: 11
Training loss: 1.8018220663070679
Validation loss: 2.2371433675289154

Epoch: 350| Step: 0
Training loss: 1.5573674440383911
Validation loss: 2.2259150445461273

Epoch: 5| Step: 1
Training loss: 1.3975610733032227
Validation loss: 2.233541319767634

Epoch: 5| Step: 2
Training loss: 1.6851959228515625
Validation loss: 2.1963810374339423

Epoch: 5| Step: 3
Training loss: 1.193623423576355
Validation loss: 2.2107723901669183

Epoch: 5| Step: 4
Training loss: 1.0829885005950928
Validation loss: 2.203097070256869

Epoch: 5| Step: 5
Training loss: 2.178524971008301
Validation loss: 2.1913580745458603

Epoch: 5| Step: 6
Training loss: 1.3841216564178467
Validation loss: 2.189621681968371

Epoch: 5| Step: 7
Training loss: 1.8172636032104492
Validation loss: 2.187402904033661

Epoch: 5| Step: 8
Training loss: 2.0148231983184814
Validation loss: 2.2122498601675034

Epoch: 5| Step: 9
Training loss: 1.8350683450698853
Validation loss: 2.1749220937490463

Epoch: 5| Step: 10
Training loss: 1.2793828248977661
Validation loss: 2.1882271468639374

Epoch: 5| Step: 11
Training loss: 2.1071619987487793
Validation loss: 2.213618536790212

Testing loss: 1.9848601706594013
