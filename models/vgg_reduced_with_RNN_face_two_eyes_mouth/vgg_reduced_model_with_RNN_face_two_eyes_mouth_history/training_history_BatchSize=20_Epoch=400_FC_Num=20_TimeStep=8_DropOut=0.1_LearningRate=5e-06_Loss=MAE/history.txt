Epoch: 1| Step: 0
Training loss: 5.377151966094971
Validation loss: 5.268598993619283

Epoch: 5| Step: 1
Training loss: 6.050401210784912
Validation loss: 5.266869445641835

Epoch: 5| Step: 2
Training loss: 4.278925895690918
Validation loss: 5.265169441699982

Epoch: 5| Step: 3
Training loss: 4.886954307556152
Validation loss: 5.263499577840169

Epoch: 5| Step: 4
Training loss: 5.470528602600098
Validation loss: 5.261860013008118

Epoch: 5| Step: 5
Training loss: 5.149060249328613
Validation loss: 5.260144094626109

Epoch: 5| Step: 6
Training loss: 5.757338047027588
Validation loss: 5.258483409881592

Epoch: 5| Step: 7
Training loss: 5.904959678649902
Validation loss: 5.256812155246735

Epoch: 5| Step: 8
Training loss: 5.638572692871094
Validation loss: 5.255008578300476

Epoch: 5| Step: 9
Training loss: 5.000980377197266
Validation loss: 5.253182977437973

Epoch: 5| Step: 10
Training loss: 4.8493332862854
Validation loss: 5.251358886559804

Epoch: 5| Step: 11
Training loss: 6.612079620361328
Validation loss: 5.249422907829285

Epoch: 2| Step: 0
Training loss: 4.889633655548096
Validation loss: 5.247428635756175

Epoch: 5| Step: 1
Training loss: 5.502780914306641
Validation loss: 5.245391170183818

Epoch: 5| Step: 2
Training loss: 5.505393981933594
Validation loss: 5.243240058422089

Epoch: 5| Step: 3
Training loss: 5.908067226409912
Validation loss: 5.240943471590678

Epoch: 5| Step: 4
Training loss: 6.023889541625977
Validation loss: 5.238536397616069

Epoch: 5| Step: 5
Training loss: 4.494277477264404
Validation loss: 5.236132065455119

Epoch: 5| Step: 6
Training loss: 5.688418388366699
Validation loss: 5.23357371489207

Epoch: 5| Step: 7
Training loss: 5.226925373077393
Validation loss: 5.230852484703064

Epoch: 5| Step: 8
Training loss: 4.519091606140137
Validation loss: 5.228146453698476

Epoch: 5| Step: 9
Training loss: 4.849296569824219
Validation loss: 5.225078841050466

Epoch: 5| Step: 10
Training loss: 6.185312271118164
Validation loss: 5.222099383672078

Epoch: 5| Step: 11
Training loss: 3.1144495010375977
Validation loss: 5.218857944011688

Epoch: 3| Step: 0
Training loss: 5.628345489501953
Validation loss: 5.215440432230632

Epoch: 5| Step: 1
Training loss: 4.711043834686279
Validation loss: 5.21190345287323

Epoch: 5| Step: 2
Training loss: 4.383360385894775
Validation loss: 5.208056588967641

Epoch: 5| Step: 3
Training loss: 6.0989203453063965
Validation loss: 5.204173783461253

Epoch: 5| Step: 4
Training loss: 4.274178504943848
Validation loss: 5.199987391630809

Epoch: 5| Step: 5
Training loss: 5.915707588195801
Validation loss: 5.195649325847626

Epoch: 5| Step: 6
Training loss: 4.776576995849609
Validation loss: 5.190953870614369

Epoch: 5| Step: 7
Training loss: 4.571673393249512
Validation loss: 5.186124602953593

Epoch: 5| Step: 8
Training loss: 6.442537784576416
Validation loss: 5.180955350399017

Epoch: 5| Step: 9
Training loss: 4.24389123916626
Validation loss: 5.175623933474223

Epoch: 5| Step: 10
Training loss: 6.3444647789001465
Validation loss: 5.170075595378876

Epoch: 5| Step: 11
Training loss: 7.854569911956787
Validation loss: 5.164127767086029

Epoch: 4| Step: 0
Training loss: 3.6537060737609863
Validation loss: 5.157965898513794

Epoch: 5| Step: 1
Training loss: 5.28061056137085
Validation loss: 5.15165901184082

Epoch: 5| Step: 2
Training loss: 4.725529193878174
Validation loss: 5.144793709119161

Epoch: 5| Step: 3
Training loss: 5.794003963470459
Validation loss: 5.137951175371806

Epoch: 5| Step: 4
Training loss: 5.3747663497924805
Validation loss: 5.130625128746033

Epoch: 5| Step: 5
Training loss: 5.531606197357178
Validation loss: 5.12324321269989

Epoch: 5| Step: 6
Training loss: 5.509312152862549
Validation loss: 5.115093032519023

Epoch: 5| Step: 7
Training loss: 5.633626461029053
Validation loss: 5.107224106788635

Epoch: 5| Step: 8
Training loss: 4.430142402648926
Validation loss: 5.099005103111267

Epoch: 5| Step: 9
Training loss: 5.160327434539795
Validation loss: 5.090620239575704

Epoch: 5| Step: 10
Training loss: 6.207365989685059
Validation loss: 5.081840554873149

Epoch: 5| Step: 11
Training loss: 4.384321689605713
Validation loss: 5.073113977909088

Epoch: 5| Step: 0
Training loss: 4.245020389556885
Validation loss: 5.064121226469676

Epoch: 5| Step: 1
Training loss: 5.314936637878418
Validation loss: 5.055113712946574

Epoch: 5| Step: 2
Training loss: 4.653691291809082
Validation loss: 5.046018540859222

Epoch: 5| Step: 3
Training loss: 5.683943271636963
Validation loss: 5.036762555440267

Epoch: 5| Step: 4
Training loss: 5.016107559204102
Validation loss: 5.027184903621674

Epoch: 5| Step: 5
Training loss: 5.316577434539795
Validation loss: 5.0177796681722

Epoch: 5| Step: 6
Training loss: 6.658881187438965
Validation loss: 5.008214354515076

Epoch: 5| Step: 7
Training loss: 4.884922981262207
Validation loss: 4.998029450575511

Epoch: 5| Step: 8
Training loss: 3.8899986743927
Validation loss: 4.988091746966044

Epoch: 5| Step: 9
Training loss: 5.387986660003662
Validation loss: 4.978124777475993

Epoch: 5| Step: 10
Training loss: 4.728309154510498
Validation loss: 4.967642664909363

Epoch: 5| Step: 11
Training loss: 6.378809928894043
Validation loss: 4.956942637761434

Epoch: 6| Step: 0
Training loss: 4.433902740478516
Validation loss: 4.9465444684028625

Epoch: 5| Step: 1
Training loss: 5.186739444732666
Validation loss: 4.935829937458038

Epoch: 5| Step: 2
Training loss: 4.853332042694092
Validation loss: 4.924859821796417

Epoch: 5| Step: 3
Training loss: 4.9661478996276855
Validation loss: 4.913825035095215

Epoch: 5| Step: 4
Training loss: 4.650667190551758
Validation loss: 4.902967751026154

Epoch: 5| Step: 5
Training loss: 4.8668975830078125
Validation loss: 4.892222623030345

Epoch: 5| Step: 6
Training loss: 5.435135841369629
Validation loss: 4.881650388240814

Epoch: 5| Step: 7
Training loss: 4.585021018981934
Validation loss: 4.870662689208984

Epoch: 5| Step: 8
Training loss: 5.252795219421387
Validation loss: 4.859410643577576

Epoch: 5| Step: 9
Training loss: 5.638270378112793
Validation loss: 4.8483889897664385

Epoch: 5| Step: 10
Training loss: 4.6293439865112305
Validation loss: 4.8369148174921675

Epoch: 5| Step: 11
Training loss: 6.119029521942139
Validation loss: 4.8256911138693495

Epoch: 7| Step: 0
Training loss: 5.027662754058838
Validation loss: 4.814205189545949

Epoch: 5| Step: 1
Training loss: 4.5449419021606445
Validation loss: 4.802682777245839

Epoch: 5| Step: 2
Training loss: 3.8057098388671875
Validation loss: 4.791021466255188

Epoch: 5| Step: 3
Training loss: 5.5209245681762695
Validation loss: 4.780248125394185

Epoch: 5| Step: 4
Training loss: 5.249382495880127
Validation loss: 4.769204318523407

Epoch: 5| Step: 5
Training loss: 4.620907306671143
Validation loss: 4.758214940627416

Epoch: 5| Step: 6
Training loss: 4.263841152191162
Validation loss: 4.746845801671346

Epoch: 5| Step: 7
Training loss: 4.914389610290527
Validation loss: 4.735601782798767

Epoch: 5| Step: 8
Training loss: 4.738785743713379
Validation loss: 4.7241432666778564

Epoch: 5| Step: 9
Training loss: 4.604616165161133
Validation loss: 4.71249137322108

Epoch: 5| Step: 10
Training loss: 5.485787391662598
Validation loss: 4.701106508572896

Epoch: 5| Step: 11
Training loss: 7.467658042907715
Validation loss: 4.689448734124501

Epoch: 8| Step: 0
Training loss: 4.5613579750061035
Validation loss: 4.678512414296468

Epoch: 5| Step: 1
Training loss: 4.189805030822754
Validation loss: 4.667366286118825

Epoch: 5| Step: 2
Training loss: 4.786378383636475
Validation loss: 4.655993481477101

Epoch: 5| Step: 3
Training loss: 5.202540397644043
Validation loss: 4.645544071992238

Epoch: 5| Step: 4
Training loss: 4.383459568023682
Validation loss: 4.635276923576991

Epoch: 5| Step: 5
Training loss: 4.9577836990356445
Validation loss: 4.624566674232483

Epoch: 5| Step: 6
Training loss: 3.666024684906006
Validation loss: 4.614456752936046

Epoch: 5| Step: 7
Training loss: 5.888484001159668
Validation loss: 4.604726622502009

Epoch: 5| Step: 8
Training loss: 5.004617214202881
Validation loss: 4.594493796428044

Epoch: 5| Step: 9
Training loss: 4.6796464920043945
Validation loss: 4.584435085455577

Epoch: 5| Step: 10
Training loss: 4.403139591217041
Validation loss: 4.574784417947133

Epoch: 5| Step: 11
Training loss: 5.725311279296875
Validation loss: 4.5645206570625305

Epoch: 9| Step: 0
Training loss: 4.791663646697998
Validation loss: 4.555020908514659

Epoch: 5| Step: 1
Training loss: 5.02245569229126
Validation loss: 4.544989228248596

Epoch: 5| Step: 2
Training loss: 4.967519760131836
Validation loss: 4.535197973251343

Epoch: 5| Step: 3
Training loss: 5.010683059692383
Validation loss: 4.5259443918863935

Epoch: 5| Step: 4
Training loss: 5.360416889190674
Validation loss: 4.516735732555389

Epoch: 5| Step: 5
Training loss: 4.567742347717285
Validation loss: 4.507039566834767

Epoch: 5| Step: 6
Training loss: 3.6481449604034424
Validation loss: 4.497439245382945

Epoch: 5| Step: 7
Training loss: 5.206180095672607
Validation loss: 4.487625976403554

Epoch: 5| Step: 8
Training loss: 3.4419169425964355
Validation loss: 4.478565613428752

Epoch: 5| Step: 9
Training loss: 4.756935119628906
Validation loss: 4.468922634919484

Epoch: 5| Step: 10
Training loss: 3.8897106647491455
Validation loss: 4.459734201431274

Epoch: 5| Step: 11
Training loss: 4.94224739074707
Validation loss: 4.45091587305069

Epoch: 10| Step: 0
Training loss: 4.814270496368408
Validation loss: 4.441551208496094

Epoch: 5| Step: 1
Training loss: 4.40618896484375
Validation loss: 4.432764609654744

Epoch: 5| Step: 2
Training loss: 4.808961868286133
Validation loss: 4.424581517775853

Epoch: 5| Step: 3
Training loss: 4.354937553405762
Validation loss: 4.415831506252289

Epoch: 5| Step: 4
Training loss: 5.824524879455566
Validation loss: 4.407537937164307

Epoch: 5| Step: 5
Training loss: 4.595449924468994
Validation loss: 4.399669369061788

Epoch: 5| Step: 6
Training loss: 4.299961566925049
Validation loss: 4.391535898049672

Epoch: 5| Step: 7
Training loss: 4.816782474517822
Validation loss: 4.383606215318044

Epoch: 5| Step: 8
Training loss: 3.3351657390594482
Validation loss: 4.375430345535278

Epoch: 5| Step: 9
Training loss: 4.1841278076171875
Validation loss: 4.367095500230789

Epoch: 5| Step: 10
Training loss: 4.5301408767700195
Validation loss: 4.359558502833049

Epoch: 5| Step: 11
Training loss: 2.9231014251708984
Validation loss: 4.35173562169075

Epoch: 11| Step: 0
Training loss: 3.812547206878662
Validation loss: 4.344298621018727

Epoch: 5| Step: 1
Training loss: 4.465951442718506
Validation loss: 4.337763587633769

Epoch: 5| Step: 2
Training loss: 4.255713939666748
Validation loss: 4.330100039641063

Epoch: 5| Step: 3
Training loss: 4.096378803253174
Validation loss: 4.323249449332555

Epoch: 5| Step: 4
Training loss: 4.058886528015137
Validation loss: 4.316003799438477

Epoch: 5| Step: 5
Training loss: 5.181186676025391
Validation loss: 4.3095466295878095

Epoch: 5| Step: 6
Training loss: 4.382077693939209
Validation loss: 4.302770962317784

Epoch: 5| Step: 7
Training loss: 3.98475980758667
Validation loss: 4.296083678801854

Epoch: 5| Step: 8
Training loss: 4.326397895812988
Validation loss: 4.290312955776851

Epoch: 5| Step: 9
Training loss: 5.351974964141846
Validation loss: 4.28343003988266

Epoch: 5| Step: 10
Training loss: 4.626721382141113
Validation loss: 4.276624977588654

Epoch: 5| Step: 11
Training loss: 5.521632194519043
Validation loss: 4.269786735375722

Epoch: 12| Step: 0
Training loss: 3.8700225353240967
Validation loss: 4.263005445400874

Epoch: 5| Step: 1
Training loss: 4.583368301391602
Validation loss: 4.256866733233134

Epoch: 5| Step: 2
Training loss: 4.9340667724609375
Validation loss: 4.250548909107844

Epoch: 5| Step: 3
Training loss: 4.590160369873047
Validation loss: 4.243444085121155

Epoch: 5| Step: 4
Training loss: 4.613896369934082
Validation loss: 4.236503154039383

Epoch: 5| Step: 5
Training loss: 4.124798774719238
Validation loss: 4.2304518322149915

Epoch: 5| Step: 6
Training loss: 4.6552042961120605
Validation loss: 4.224291423956553

Epoch: 5| Step: 7
Training loss: 4.0891642570495605
Validation loss: 4.2177431881427765

Epoch: 5| Step: 8
Training loss: 4.23090124130249
Validation loss: 4.211271504561107

Epoch: 5| Step: 9
Training loss: 4.284574031829834
Validation loss: 4.203244109948476

Epoch: 5| Step: 10
Training loss: 4.143784999847412
Validation loss: 4.196092863877614

Epoch: 5| Step: 11
Training loss: 3.5800273418426514
Validation loss: 4.189391215642293

Epoch: 13| Step: 0
Training loss: 4.3585309982299805
Validation loss: 4.182299325863521

Epoch: 5| Step: 1
Training loss: 4.3221755027771
Validation loss: 4.17649124066035

Epoch: 5| Step: 2
Training loss: 5.00687313079834
Validation loss: 4.169333130121231

Epoch: 5| Step: 3
Training loss: 4.166851997375488
Validation loss: 4.163184483846028

Epoch: 5| Step: 4
Training loss: 4.277331829071045
Validation loss: 4.1573509474595385

Epoch: 5| Step: 5
Training loss: 4.352809906005859
Validation loss: 4.1508833567301435

Epoch: 5| Step: 6
Training loss: 3.5449650287628174
Validation loss: 4.145228217045466

Epoch: 5| Step: 7
Training loss: 4.215970516204834
Validation loss: 4.139295647541682

Epoch: 5| Step: 8
Training loss: 5.384326934814453
Validation loss: 4.133392135302226

Epoch: 5| Step: 9
Training loss: 3.123880386352539
Validation loss: 4.127378314733505

Epoch: 5| Step: 10
Training loss: 4.728146553039551
Validation loss: 4.121550937493642

Epoch: 5| Step: 11
Training loss: 2.7396793365478516
Validation loss: 4.115736951430638

Epoch: 14| Step: 0
Training loss: 3.498924970626831
Validation loss: 4.110327064990997

Epoch: 5| Step: 1
Training loss: 4.08269739151001
Validation loss: 4.104550063610077

Epoch: 5| Step: 2
Training loss: 5.093815803527832
Validation loss: 4.098845471938451

Epoch: 5| Step: 3
Training loss: 3.38562273979187
Validation loss: 4.092342396577199

Epoch: 5| Step: 4
Training loss: 4.749958038330078
Validation loss: 4.086259722709656

Epoch: 5| Step: 5
Training loss: 4.668281078338623
Validation loss: 4.08056452870369

Epoch: 5| Step: 6
Training loss: 4.19393253326416
Validation loss: 4.0744429131348925

Epoch: 5| Step: 7
Training loss: 3.923140048980713
Validation loss: 4.068195869525273

Epoch: 5| Step: 8
Training loss: 4.040310859680176
Validation loss: 4.062448233366013

Epoch: 5| Step: 9
Training loss: 4.922940731048584
Validation loss: 4.057170271873474

Epoch: 5| Step: 10
Training loss: 4.014695644378662
Validation loss: 4.051179786523183

Epoch: 5| Step: 11
Training loss: 3.623317241668701
Validation loss: 4.045533706744512

Epoch: 15| Step: 0
Training loss: 4.34428596496582
Validation loss: 4.04104745388031

Epoch: 5| Step: 1
Training loss: 4.002178192138672
Validation loss: 4.035512864589691

Epoch: 5| Step: 2
Training loss: 3.9479527473449707
Validation loss: 4.029366999864578

Epoch: 5| Step: 3
Training loss: 4.310304164886475
Validation loss: 4.024162173271179

Epoch: 5| Step: 4
Training loss: 4.441259860992432
Validation loss: 4.018440206845601

Epoch: 5| Step: 5
Training loss: 4.41318416595459
Validation loss: 4.013036032517751

Epoch: 5| Step: 6
Training loss: 4.470515251159668
Validation loss: 4.008035322030385

Epoch: 5| Step: 7
Training loss: 4.164837837219238
Validation loss: 4.0020193457603455

Epoch: 5| Step: 8
Training loss: 4.906050205230713
Validation loss: 3.995599110921224

Epoch: 5| Step: 9
Training loss: 3.1245181560516357
Validation loss: 3.9911773403485618

Epoch: 5| Step: 10
Training loss: 3.7172436714172363
Validation loss: 3.986131250858307

Epoch: 5| Step: 11
Training loss: 3.57450532913208
Validation loss: 3.9809163312117257

Epoch: 16| Step: 0
Training loss: 4.799136161804199
Validation loss: 3.975181967020035

Epoch: 5| Step: 1
Training loss: 4.053055763244629
Validation loss: 3.9699124693870544

Epoch: 5| Step: 2
Training loss: 4.060656547546387
Validation loss: 3.9643557369709015

Epoch: 5| Step: 3
Training loss: 4.212058067321777
Validation loss: 3.959911992152532

Epoch: 5| Step: 4
Training loss: 3.770371675491333
Validation loss: 3.954308956861496

Epoch: 5| Step: 5
Training loss: 3.758115291595459
Validation loss: 3.9493331412474313

Epoch: 5| Step: 6
Training loss: 3.8953616619110107
Validation loss: 3.9434196849664054

Epoch: 5| Step: 7
Training loss: 3.910752058029175
Validation loss: 3.937894582748413

Epoch: 5| Step: 8
Training loss: 3.974656581878662
Validation loss: 3.9328816135724387

Epoch: 5| Step: 9
Training loss: 3.8040356636047363
Validation loss: 3.9276408354441323

Epoch: 5| Step: 10
Training loss: 5.373475074768066
Validation loss: 3.9226919412612915

Epoch: 5| Step: 11
Training loss: 1.2776540517807007
Validation loss: 3.917517195145289

Epoch: 17| Step: 0
Training loss: 4.148621082305908
Validation loss: 3.912825574477514

Epoch: 5| Step: 1
Training loss: 3.9236550331115723
Validation loss: 3.9083478649457297

Epoch: 5| Step: 2
Training loss: 3.971890687942505
Validation loss: 3.903416891892751

Epoch: 5| Step: 3
Training loss: 4.368772029876709
Validation loss: 3.898496150970459

Epoch: 5| Step: 4
Training loss: 4.278250694274902
Validation loss: 3.8936870396137238

Epoch: 5| Step: 5
Training loss: 4.0644636154174805
Validation loss: 3.8886223336060843

Epoch: 5| Step: 6
Training loss: 4.178655624389648
Validation loss: 3.8841261665026345

Epoch: 5| Step: 7
Training loss: 3.404984951019287
Validation loss: 3.87971959511439

Epoch: 5| Step: 8
Training loss: 4.6744537353515625
Validation loss: 3.874889075756073

Epoch: 5| Step: 9
Training loss: 4.623315334320068
Validation loss: 3.8704486191272736

Epoch: 5| Step: 10
Training loss: 3.04081392288208
Validation loss: 3.8658157289028168

Epoch: 5| Step: 11
Training loss: 2.7430849075317383
Validation loss: 3.8611861069997153

Epoch: 18| Step: 0
Training loss: 3.1761438846588135
Validation loss: 3.8563410341739655

Epoch: 5| Step: 1
Training loss: 3.3989861011505127
Validation loss: 3.851037879784902

Epoch: 5| Step: 2
Training loss: 4.438187599182129
Validation loss: 3.846892684698105

Epoch: 5| Step: 3
Training loss: 4.2655029296875
Validation loss: 3.8418112794558206

Epoch: 5| Step: 4
Training loss: 3.9905037879943848
Validation loss: 3.837145427862803

Epoch: 5| Step: 5
Training loss: 4.4839982986450195
Validation loss: 3.831263482570648

Epoch: 5| Step: 6
Training loss: 5.092588901519775
Validation loss: 3.82691956559817

Epoch: 5| Step: 7
Training loss: 3.0350513458251953
Validation loss: 3.8218793670336404

Epoch: 5| Step: 8
Training loss: 4.165358543395996
Validation loss: 3.8174811700979867

Epoch: 5| Step: 9
Training loss: 3.376481294631958
Validation loss: 3.8129236102104187

Epoch: 5| Step: 10
Training loss: 4.6669087409973145
Validation loss: 3.807471086581548

Epoch: 5| Step: 11
Training loss: 2.7052087783813477
Validation loss: 3.8029935359954834

Epoch: 19| Step: 0
Training loss: 3.7317917346954346
Validation loss: 3.7983768781026206

Epoch: 5| Step: 1
Training loss: 2.884578227996826
Validation loss: 3.7944062848885856

Epoch: 5| Step: 2
Training loss: 4.9415764808654785
Validation loss: 3.7916751702626548

Epoch: 5| Step: 3
Training loss: 4.375034332275391
Validation loss: 3.78848859667778

Epoch: 5| Step: 4
Training loss: 3.3103890419006348
Validation loss: 3.7814069390296936

Epoch: 5| Step: 5
Training loss: 4.8784894943237305
Validation loss: 3.776491572459539

Epoch: 5| Step: 6
Training loss: 3.7450547218322754
Validation loss: 3.772064576546351

Epoch: 5| Step: 7
Training loss: 3.4998512268066406
Validation loss: 3.767501493295034

Epoch: 5| Step: 8
Training loss: 4.109120845794678
Validation loss: 3.762614736954371

Epoch: 5| Step: 9
Training loss: 4.095468997955322
Validation loss: 3.7569081783294678

Epoch: 5| Step: 10
Training loss: 3.81274676322937
Validation loss: 3.752525826295217

Epoch: 5| Step: 11
Training loss: 3.264590263366699
Validation loss: 3.74718909462293

Epoch: 20| Step: 0
Training loss: 3.9193382263183594
Validation loss: 3.7425502041975656

Epoch: 5| Step: 1
Training loss: 3.776453733444214
Validation loss: 3.7383788029352822

Epoch: 5| Step: 2
Training loss: 3.667795181274414
Validation loss: 3.7328612009684243

Epoch: 5| Step: 3
Training loss: 3.9588732719421387
Validation loss: 3.7279076278209686

Epoch: 5| Step: 4
Training loss: 4.105433940887451
Validation loss: 3.7236631711324057

Epoch: 5| Step: 5
Training loss: 3.8956046104431152
Validation loss: 3.7187959253787994

Epoch: 5| Step: 6
Training loss: 4.133227825164795
Validation loss: 3.714215556780497

Epoch: 5| Step: 7
Training loss: 3.799863338470459
Validation loss: 3.7095493276913962

Epoch: 5| Step: 8
Training loss: 3.699732542037964
Validation loss: 3.7042165100574493

Epoch: 5| Step: 9
Training loss: 3.8162193298339844
Validation loss: 3.6998391648133597

Epoch: 5| Step: 10
Training loss: 3.9638328552246094
Validation loss: 3.695064495007197

Epoch: 5| Step: 11
Training loss: 3.527858257293701
Validation loss: 3.6916113197803497

Epoch: 21| Step: 0
Training loss: 3.6156725883483887
Validation loss: 3.6885040402412415

Epoch: 5| Step: 1
Training loss: 3.130706310272217
Validation loss: 3.6812201937039695

Epoch: 5| Step: 2
Training loss: 3.951345920562744
Validation loss: 3.6765581170717874

Epoch: 5| Step: 3
Training loss: 4.4155426025390625
Validation loss: 3.6738717754681907

Epoch: 5| Step: 4
Training loss: 4.132601737976074
Validation loss: 3.6693361898263297

Epoch: 5| Step: 5
Training loss: 3.8149819374084473
Validation loss: 3.6644161442915597

Epoch: 5| Step: 6
Training loss: 2.861097812652588
Validation loss: 3.6586762766043344

Epoch: 5| Step: 7
Training loss: 4.267678737640381
Validation loss: 3.655149151881536

Epoch: 5| Step: 8
Training loss: 4.124454975128174
Validation loss: 3.6511140863100686

Epoch: 5| Step: 9
Training loss: 4.068927764892578
Validation loss: 3.6456783413887024

Epoch: 5| Step: 10
Training loss: 3.6832802295684814
Validation loss: 3.641059637069702

Epoch: 5| Step: 11
Training loss: 3.871492862701416
Validation loss: 3.636793573697408

Epoch: 22| Step: 0
Training loss: 4.4232964515686035
Validation loss: 3.6324386397997537

Epoch: 5| Step: 1
Training loss: 3.3078322410583496
Validation loss: 3.6279543936252594

Epoch: 5| Step: 2
Training loss: 4.642819404602051
Validation loss: 3.6235366066296897

Epoch: 5| Step: 3
Training loss: 3.371539354324341
Validation loss: 3.6199301282564798

Epoch: 5| Step: 4
Training loss: 3.357600688934326
Validation loss: 3.615856726964315

Epoch: 5| Step: 5
Training loss: 3.7741997241973877
Validation loss: 3.6106550792853036

Epoch: 5| Step: 6
Training loss: 3.8100876808166504
Validation loss: 3.606498052676519

Epoch: 5| Step: 7
Training loss: 3.761990785598755
Validation loss: 3.602647324403127

Epoch: 5| Step: 8
Training loss: 4.346591472625732
Validation loss: 3.6002026398976645

Epoch: 5| Step: 9
Training loss: 3.1477763652801514
Validation loss: 3.5948313772678375

Epoch: 5| Step: 10
Training loss: 3.404846668243408
Validation loss: 3.589381088813146

Epoch: 5| Step: 11
Training loss: 4.526141166687012
Validation loss: 3.5841527382532754

Epoch: 23| Step: 0
Training loss: 3.4299182891845703
Validation loss: 3.5799600581328073

Epoch: 5| Step: 1
Training loss: 3.809556484222412
Validation loss: 3.574771990378698

Epoch: 5| Step: 2
Training loss: 3.5299313068389893
Validation loss: 3.571357160806656

Epoch: 5| Step: 3
Training loss: 3.9219040870666504
Validation loss: 3.566226730744044

Epoch: 5| Step: 4
Training loss: 4.396693706512451
Validation loss: 3.561633209387461

Epoch: 5| Step: 5
Training loss: 3.585137128829956
Validation loss: 3.556645522514979

Epoch: 5| Step: 6
Training loss: 3.891564130783081
Validation loss: 3.552509367465973

Epoch: 5| Step: 7
Training loss: 4.310799598693848
Validation loss: 3.5467438201109567

Epoch: 5| Step: 8
Training loss: 3.8392341136932373
Validation loss: 3.5432472030321756

Epoch: 5| Step: 9
Training loss: 2.8922624588012695
Validation loss: 3.5379709899425507

Epoch: 5| Step: 10
Training loss: 3.3221230506896973
Validation loss: 3.5336148540178933

Epoch: 5| Step: 11
Training loss: 3.722118377685547
Validation loss: 3.5286176999409995

Epoch: 24| Step: 0
Training loss: 3.4626803398132324
Validation loss: 3.5243861277898154

Epoch: 5| Step: 1
Training loss: 4.024428367614746
Validation loss: 3.5196950435638428

Epoch: 5| Step: 2
Training loss: 3.70678448677063
Validation loss: 3.5156383017698922

Epoch: 5| Step: 3
Training loss: 3.6661324501037598
Validation loss: 3.5111239552497864

Epoch: 5| Step: 4
Training loss: 3.658208131790161
Validation loss: 3.5062738259633384

Epoch: 5| Step: 5
Training loss: 2.4082725048065186
Validation loss: 3.5010961989561715

Epoch: 5| Step: 6
Training loss: 3.505692720413208
Validation loss: 3.497694750626882

Epoch: 5| Step: 7
Training loss: 3.0095181465148926
Validation loss: 3.493157227834066

Epoch: 5| Step: 8
Training loss: 5.621715545654297
Validation loss: 3.4885254999001822

Epoch: 5| Step: 9
Training loss: 4.2248125076293945
Validation loss: 3.483299414316813

Epoch: 5| Step: 10
Training loss: 2.9501843452453613
Validation loss: 3.4791502257188163

Epoch: 5| Step: 11
Training loss: 4.215214729309082
Validation loss: 3.474625180164973

Epoch: 25| Step: 0
Training loss: 3.3024299144744873
Validation loss: 3.4703157444794974

Epoch: 5| Step: 1
Training loss: 3.427532911300659
Validation loss: 3.4653841157754264

Epoch: 5| Step: 2
Training loss: 4.473845481872559
Validation loss: 3.4612613717714944

Epoch: 5| Step: 3
Training loss: 4.064802646636963
Validation loss: 3.45579527815183

Epoch: 5| Step: 4
Training loss: 3.722212314605713
Validation loss: 3.452542801698049

Epoch: 5| Step: 5
Training loss: 4.574202060699463
Validation loss: 3.446980426708857

Epoch: 5| Step: 6
Training loss: 2.619555711746216
Validation loss: 3.4429399271806083

Epoch: 5| Step: 7
Training loss: 3.302323818206787
Validation loss: 3.4382048348585763

Epoch: 5| Step: 8
Training loss: 3.7750937938690186
Validation loss: 3.4346643686294556

Epoch: 5| Step: 9
Training loss: 3.33948016166687
Validation loss: 3.4296956260999045

Epoch: 5| Step: 10
Training loss: 3.0233969688415527
Validation loss: 3.424657553434372

Epoch: 5| Step: 11
Training loss: 4.258472442626953
Validation loss: 3.419966717561086

Epoch: 26| Step: 0
Training loss: 3.214946746826172
Validation loss: 3.417263944943746

Epoch: 5| Step: 1
Training loss: 4.063388824462891
Validation loss: 3.4283907413482666

Epoch: 5| Step: 2
Training loss: 3.786656141281128
Validation loss: 3.407556176185608

Epoch: 5| Step: 3
Training loss: 4.114871025085449
Validation loss: 3.4059190849463143

Epoch: 5| Step: 4
Training loss: 3.437213897705078
Validation loss: 3.4065386156241098

Epoch: 5| Step: 5
Training loss: 3.608940601348877
Validation loss: 3.4061696529388428

Epoch: 5| Step: 6
Training loss: 3.8802807331085205
Validation loss: 3.4005455871423087

Epoch: 5| Step: 7
Training loss: 3.1731390953063965
Validation loss: 3.3943903942902884

Epoch: 5| Step: 8
Training loss: 2.940477132797241
Validation loss: 3.387002537647883

Epoch: 5| Step: 9
Training loss: 4.063780784606934
Validation loss: 3.3810792764027915

Epoch: 5| Step: 10
Training loss: 2.6408658027648926
Validation loss: 3.3763499160607657

Epoch: 5| Step: 11
Training loss: 5.299463272094727
Validation loss: 3.372582823038101

Epoch: 27| Step: 0
Training loss: 4.194012641906738
Validation loss: 3.3684946099917092

Epoch: 5| Step: 1
Training loss: 3.375753879547119
Validation loss: 3.364963392416636

Epoch: 5| Step: 2
Training loss: 3.3498921394348145
Validation loss: 3.360711097717285

Epoch: 5| Step: 3
Training loss: 3.936173677444458
Validation loss: 3.357384334007899

Epoch: 5| Step: 4
Training loss: 3.794694185256958
Validation loss: 3.3528589407602944

Epoch: 5| Step: 5
Training loss: 2.9662959575653076
Validation loss: 3.3488186796506247

Epoch: 5| Step: 6
Training loss: 2.635965347290039
Validation loss: 3.3428721328576407

Epoch: 5| Step: 7
Training loss: 3.3459808826446533
Validation loss: 3.338614990313848

Epoch: 5| Step: 8
Training loss: 3.8352596759796143
Validation loss: 3.3334722816944122

Epoch: 5| Step: 9
Training loss: 2.9831669330596924
Validation loss: 3.3281338214874268

Epoch: 5| Step: 10
Training loss: 3.9332098960876465
Validation loss: 3.32401833931605

Epoch: 5| Step: 11
Training loss: 5.211662292480469
Validation loss: 3.3192119101683297

Epoch: 28| Step: 0
Training loss: 3.6551578044891357
Validation loss: 3.314226617415746

Epoch: 5| Step: 1
Training loss: 3.0889267921447754
Validation loss: 3.3097194532553353

Epoch: 5| Step: 2
Training loss: 3.5283684730529785
Validation loss: 3.3052015701929727

Epoch: 5| Step: 3
Training loss: 3.642768383026123
Validation loss: 3.3005326191584268

Epoch: 5| Step: 4
Training loss: 3.2063801288604736
Validation loss: 3.296844075123469

Epoch: 5| Step: 5
Training loss: 3.611278533935547
Validation loss: 3.292222539583842

Epoch: 5| Step: 6
Training loss: 3.5119032859802246
Validation loss: 3.288015534480413

Epoch: 5| Step: 7
Training loss: 3.163017749786377
Validation loss: 3.28348238269488

Epoch: 5| Step: 8
Training loss: 3.5414822101593018
Validation loss: 3.2797557413578033

Epoch: 5| Step: 9
Training loss: 3.8344688415527344
Validation loss: 3.275393625100454

Epoch: 5| Step: 10
Training loss: 3.3199362754821777
Validation loss: 3.2710735301176705

Epoch: 5| Step: 11
Training loss: 3.599041700363159
Validation loss: 3.2666980425516763

Epoch: 29| Step: 0
Training loss: 3.50331449508667
Validation loss: 3.262818783521652

Epoch: 5| Step: 1
Training loss: 3.342003583908081
Validation loss: 3.2582889099915824

Epoch: 5| Step: 2
Training loss: 3.153538942337036
Validation loss: 3.25340802470843

Epoch: 5| Step: 3
Training loss: 3.140148878097534
Validation loss: 3.2495263318220773

Epoch: 5| Step: 4
Training loss: 3.303504467010498
Validation loss: 3.246472716331482

Epoch: 5| Step: 5
Training loss: 3.5154032707214355
Validation loss: 3.2416893939177194

Epoch: 5| Step: 6
Training loss: 3.237027645111084
Validation loss: 3.237919420003891

Epoch: 5| Step: 7
Training loss: 4.665590286254883
Validation loss: 3.2336431443691254

Epoch: 5| Step: 8
Training loss: 3.1042912006378174
Validation loss: 3.229711929957072

Epoch: 5| Step: 9
Training loss: 3.00215220451355
Validation loss: 3.2253951132297516

Epoch: 5| Step: 10
Training loss: 3.3454413414001465
Validation loss: 3.220782905817032

Epoch: 5| Step: 11
Training loss: 4.845822811126709
Validation loss: 3.21644389629364

Epoch: 30| Step: 0
Training loss: 3.623713254928589
Validation loss: 3.2116220792134604

Epoch: 5| Step: 1
Training loss: 3.806519031524658
Validation loss: 3.207180211941401

Epoch: 5| Step: 2
Training loss: 2.6921961307525635
Validation loss: 3.203513115644455

Epoch: 5| Step: 3
Training loss: 4.18004846572876
Validation loss: 3.1994801461696625

Epoch: 5| Step: 4
Training loss: 3.836519718170166
Validation loss: 3.1939649482568107

Epoch: 5| Step: 5
Training loss: 2.94073486328125
Validation loss: 3.1901616553465524

Epoch: 5| Step: 6
Training loss: 2.838810443878174
Validation loss: 3.186474492152532

Epoch: 5| Step: 7
Training loss: 3.8877053260803223
Validation loss: 3.1817917625109353

Epoch: 5| Step: 8
Training loss: 2.5644824504852295
Validation loss: 3.1771609584490457

Epoch: 5| Step: 9
Training loss: 2.8831191062927246
Validation loss: 3.17262010773023

Epoch: 5| Step: 10
Training loss: 3.7173988819122314
Validation loss: 3.1683897972106934

Epoch: 5| Step: 11
Training loss: 3.9481794834136963
Validation loss: 3.1645875374476113

Epoch: 31| Step: 0
Training loss: 3.684828281402588
Validation loss: 3.160187433163325

Epoch: 5| Step: 1
Training loss: 3.3078930377960205
Validation loss: 3.1560460229714713

Epoch: 5| Step: 2
Training loss: 3.298593521118164
Validation loss: 3.1515000561873117

Epoch: 5| Step: 3
Training loss: 3.0844626426696777
Validation loss: 3.146995613972346

Epoch: 5| Step: 4
Training loss: 3.802727222442627
Validation loss: 3.14240433772405

Epoch: 5| Step: 5
Training loss: 3.6015307903289795
Validation loss: 3.13811864455541

Epoch: 5| Step: 6
Training loss: 3.164689779281616
Validation loss: 3.1337679823239646

Epoch: 5| Step: 7
Training loss: 3.0110790729522705
Validation loss: 3.1293234825134277

Epoch: 5| Step: 8
Training loss: 2.8215484619140625
Validation loss: 3.125338892141978

Epoch: 5| Step: 9
Training loss: 3.381868362426758
Validation loss: 3.1213370064894357

Epoch: 5| Step: 10
Training loss: 3.2503039836883545
Validation loss: 3.117478519678116

Epoch: 5| Step: 11
Training loss: 4.164791107177734
Validation loss: 3.112953712542852

Epoch: 32| Step: 0
Training loss: 3.2044670581817627
Validation loss: 3.109387516975403

Epoch: 5| Step: 1
Training loss: 2.558743953704834
Validation loss: 3.1045045852661133

Epoch: 5| Step: 2
Training loss: 3.714865207672119
Validation loss: 3.101099749406179

Epoch: 5| Step: 3
Training loss: 3.751776933670044
Validation loss: 3.096830894549688

Epoch: 5| Step: 4
Training loss: 3.661346912384033
Validation loss: 3.092942933241526

Epoch: 5| Step: 5
Training loss: 3.356295108795166
Validation loss: 3.0898480216662088

Epoch: 5| Step: 6
Training loss: 2.949249267578125
Validation loss: 3.085468719402949

Epoch: 5| Step: 7
Training loss: 3.0303261280059814
Validation loss: 3.081857055425644

Epoch: 5| Step: 8
Training loss: 3.21301531791687
Validation loss: 3.0777330100536346

Epoch: 5| Step: 9
Training loss: 3.6072769165039062
Validation loss: 3.074004511038462

Epoch: 5| Step: 10
Training loss: 2.9944939613342285
Validation loss: 3.07030658920606

Epoch: 5| Step: 11
Training loss: 3.300459384918213
Validation loss: 3.0664010842641196

Epoch: 33| Step: 0
Training loss: 2.935554027557373
Validation loss: 3.062633122007052

Epoch: 5| Step: 1
Training loss: 2.9112915992736816
Validation loss: 3.059391667445501

Epoch: 5| Step: 2
Training loss: 2.568547010421753
Validation loss: 3.055919965108236

Epoch: 5| Step: 3
Training loss: 3.9338440895080566
Validation loss: 3.0521269539992013

Epoch: 5| Step: 4
Training loss: 2.7711567878723145
Validation loss: 3.048684060573578

Epoch: 5| Step: 5
Training loss: 3.65132474899292
Validation loss: 3.0451799432436624

Epoch: 5| Step: 6
Training loss: 3.568373203277588
Validation loss: 3.0410516460736594

Epoch: 5| Step: 7
Training loss: 3.5758438110351562
Validation loss: 3.0381253361701965

Epoch: 5| Step: 8
Training loss: 2.8900043964385986
Validation loss: 3.0340595642725625

Epoch: 5| Step: 9
Training loss: 2.937941074371338
Validation loss: 3.031016161044439

Epoch: 5| Step: 10
Training loss: 3.691361904144287
Validation loss: 3.027346988519033

Epoch: 5| Step: 11
Training loss: 3.8882150650024414
Validation loss: 3.0232813556989035

Epoch: 34| Step: 0
Training loss: 3.1935389041900635
Validation loss: 3.019313633441925

Epoch: 5| Step: 1
Training loss: 3.2164955139160156
Validation loss: 3.015422284603119

Epoch: 5| Step: 2
Training loss: 2.8830082416534424
Validation loss: 3.010709365208944

Epoch: 5| Step: 3
Training loss: 3.6492037773132324
Validation loss: 3.007196396589279

Epoch: 5| Step: 4
Training loss: 3.132699728012085
Validation loss: 3.0032400290171304

Epoch: 5| Step: 5
Training loss: 3.6207804679870605
Validation loss: 2.999539931615194

Epoch: 5| Step: 6
Training loss: 3.0022664070129395
Validation loss: 2.9950149257977805

Epoch: 5| Step: 7
Training loss: 2.706409454345703
Validation loss: 2.9908952713012695

Epoch: 5| Step: 8
Training loss: 3.2491164207458496
Validation loss: 2.9875753819942474

Epoch: 5| Step: 9
Training loss: 3.31685209274292
Validation loss: 2.982692281405131

Epoch: 5| Step: 10
Training loss: 3.1496851444244385
Validation loss: 2.9791095654169717

Epoch: 5| Step: 11
Training loss: 3.2440648078918457
Validation loss: 2.975563814242681

Epoch: 35| Step: 0
Training loss: 2.9195239543914795
Validation loss: 2.9718310137589774

Epoch: 5| Step: 1
Training loss: 3.640277147293091
Validation loss: 2.967630833387375

Epoch: 5| Step: 2
Training loss: 2.644273281097412
Validation loss: 2.964355687300364

Epoch: 5| Step: 3
Training loss: 2.4645209312438965
Validation loss: 2.959959944089254

Epoch: 5| Step: 4
Training loss: 3.3212456703186035
Validation loss: 2.955926467974981

Epoch: 5| Step: 5
Training loss: 3.660252094268799
Validation loss: 2.9539612332979837

Epoch: 5| Step: 6
Training loss: 3.158402442932129
Validation loss: 2.950003057718277

Epoch: 5| Step: 7
Training loss: 4.001128196716309
Validation loss: 2.9458166857560477

Epoch: 5| Step: 8
Training loss: 2.9379496574401855
Validation loss: 2.9412916004657745

Epoch: 5| Step: 9
Training loss: 2.815638303756714
Validation loss: 2.9384663899739585

Epoch: 5| Step: 10
Training loss: 3.095472812652588
Validation loss: 2.938011368115743

Epoch: 5| Step: 11
Training loss: 3.152238368988037
Validation loss: 2.933659086624781

Epoch: 36| Step: 0
Training loss: 3.185516834259033
Validation loss: 2.9297159810860953

Epoch: 5| Step: 1
Training loss: 3.237473249435425
Validation loss: 2.9243784050146737

Epoch: 5| Step: 2
Training loss: 3.601975679397583
Validation loss: 2.9219617744286857

Epoch: 5| Step: 3
Training loss: 2.9095377922058105
Validation loss: 2.9175087014834085

Epoch: 5| Step: 4
Training loss: 2.9022412300109863
Validation loss: 2.914240966240565

Epoch: 5| Step: 5
Training loss: 3.3218226432800293
Validation loss: 2.9121991991996765

Epoch: 5| Step: 6
Training loss: 3.093094825744629
Validation loss: 2.908491462469101

Epoch: 5| Step: 7
Training loss: 2.8664262294769287
Validation loss: 2.905653784672419

Epoch: 5| Step: 8
Training loss: 2.9464564323425293
Validation loss: 2.903535316387812

Epoch: 5| Step: 9
Training loss: 2.602315902709961
Validation loss: 2.8979038099447885

Epoch: 5| Step: 10
Training loss: 3.448690891265869
Validation loss: 2.8940111895402274

Epoch: 5| Step: 11
Training loss: 3.6635470390319824
Validation loss: 2.890646666288376

Epoch: 37| Step: 0
Training loss: 3.7550597190856934
Validation loss: 2.8879726032416024

Epoch: 5| Step: 1
Training loss: 2.546391010284424
Validation loss: 2.8857898811499276

Epoch: 5| Step: 2
Training loss: 2.561324119567871
Validation loss: 2.8837505280971527

Epoch: 5| Step: 3
Training loss: 2.3782105445861816
Validation loss: 2.877415587504705

Epoch: 5| Step: 4
Training loss: 3.9204368591308594
Validation loss: 2.871462196111679

Epoch: 5| Step: 5
Training loss: 3.2586703300476074
Validation loss: 2.868089437484741

Epoch: 5| Step: 6
Training loss: 2.5356037616729736
Validation loss: 2.8660404483477273

Epoch: 5| Step: 7
Training loss: 2.8528168201446533
Validation loss: 2.8618835707505546

Epoch: 5| Step: 8
Training loss: 3.640821933746338
Validation loss: 2.8596986134847007

Epoch: 5| Step: 9
Training loss: 3.4361681938171387
Validation loss: 2.8544282416502633

Epoch: 5| Step: 10
Training loss: 3.151987314224243
Validation loss: 2.8517609238624573

Epoch: 5| Step: 11
Training loss: 1.8455034494400024
Validation loss: 2.8471706310908

Epoch: 38| Step: 0
Training loss: 3.0700459480285645
Validation loss: 2.8434502283732095

Epoch: 5| Step: 1
Training loss: 2.942446231842041
Validation loss: 2.8396721283594766

Epoch: 5| Step: 2
Training loss: 3.6680121421813965
Validation loss: 2.8368972837924957

Epoch: 5| Step: 3
Training loss: 2.680004596710205
Validation loss: 2.8324995934963226

Epoch: 5| Step: 4
Training loss: 3.07658052444458
Validation loss: 2.83043764034907

Epoch: 5| Step: 5
Training loss: 2.901499032974243
Validation loss: 2.826075325409571

Epoch: 5| Step: 6
Training loss: 2.9751136302948
Validation loss: 2.823700855175654

Epoch: 5| Step: 7
Training loss: 3.947526454925537
Validation loss: 2.819705625375112

Epoch: 5| Step: 8
Training loss: 2.1760406494140625
Validation loss: 2.8157923916975656

Epoch: 5| Step: 9
Training loss: 2.968966245651245
Validation loss: 2.8138671616713204

Epoch: 5| Step: 10
Training loss: 3.062239170074463
Validation loss: 2.814064164956411

Epoch: 5| Step: 11
Training loss: 2.598234176635742
Validation loss: 2.826345145702362

Epoch: 39| Step: 0
Training loss: 3.3283867835998535
Validation loss: 2.816411644220352

Epoch: 5| Step: 1
Training loss: 2.8340442180633545
Validation loss: 2.799389104048411

Epoch: 5| Step: 2
Training loss: 2.8064770698547363
Validation loss: 2.7966303626696267

Epoch: 5| Step: 3
Training loss: 3.425971269607544
Validation loss: 2.7937745650609336

Epoch: 5| Step: 4
Training loss: 2.5413308143615723
Validation loss: 2.7933687766393027

Epoch: 5| Step: 5
Training loss: 3.119535446166992
Validation loss: 2.7904209593931832

Epoch: 5| Step: 6
Training loss: 3.500920057296753
Validation loss: 2.7895186444123587

Epoch: 5| Step: 7
Training loss: 2.5606586933135986
Validation loss: 2.7847645779450736

Epoch: 5| Step: 8
Training loss: 3.3638083934783936
Validation loss: 2.782275209824244

Epoch: 5| Step: 9
Training loss: 3.1627864837646484
Validation loss: 2.776024987300237

Epoch: 5| Step: 10
Training loss: 2.5924453735351562
Validation loss: 2.7748744785785675

Epoch: 5| Step: 11
Training loss: 1.7829537391662598
Validation loss: 2.7691724002361298

Epoch: 40| Step: 0
Training loss: 2.656933069229126
Validation loss: 2.765489329894384

Epoch: 5| Step: 1
Training loss: 3.6481869220733643
Validation loss: 2.7607711056868234

Epoch: 5| Step: 2
Training loss: 2.852782726287842
Validation loss: 2.7576053937276206

Epoch: 5| Step: 3
Training loss: 2.777472734451294
Validation loss: 2.755445639292399

Epoch: 5| Step: 4
Training loss: 3.6160271167755127
Validation loss: 2.7547317445278168

Epoch: 5| Step: 5
Training loss: 2.3647472858428955
Validation loss: 2.7476286192735038

Epoch: 5| Step: 6
Training loss: 2.5562808513641357
Validation loss: 2.744508445262909

Epoch: 5| Step: 7
Training loss: 2.5393474102020264
Validation loss: 2.741689225037893

Epoch: 5| Step: 8
Training loss: 3.13647198677063
Validation loss: 2.7394053836663566

Epoch: 5| Step: 9
Training loss: 2.7765562534332275
Validation loss: 2.733884572982788

Epoch: 5| Step: 10
Training loss: 3.4287123680114746
Validation loss: 2.7343570391337075

Epoch: 5| Step: 11
Training loss: 3.7893919944763184
Validation loss: 2.729893167813619

Epoch: 41| Step: 0
Training loss: 2.634742021560669
Validation loss: 2.7268661161263785

Epoch: 5| Step: 1
Training loss: 3.375107526779175
Validation loss: 2.721892903248469

Epoch: 5| Step: 2
Training loss: 2.6314291954040527
Validation loss: 2.71784899632136

Epoch: 5| Step: 3
Training loss: 3.367356061935425
Validation loss: 2.714833547671636

Epoch: 5| Step: 4
Training loss: 2.8882882595062256
Validation loss: 2.710835814476013

Epoch: 5| Step: 5
Training loss: 2.9136157035827637
Validation loss: 2.7068972984949746

Epoch: 5| Step: 6
Training loss: 2.2976818084716797
Validation loss: 2.702070504426956

Epoch: 5| Step: 7
Training loss: 3.265643358230591
Validation loss: 2.699771006902059

Epoch: 5| Step: 8
Training loss: 2.8874385356903076
Validation loss: 2.6956294973691306

Epoch: 5| Step: 9
Training loss: 2.8376855850219727
Validation loss: 2.695020447174708

Epoch: 5| Step: 10
Training loss: 3.091787099838257
Validation loss: 2.692303250233332

Epoch: 5| Step: 11
Training loss: 2.1731786727905273
Validation loss: 2.6887871821721396

Epoch: 42| Step: 0
Training loss: 2.7841174602508545
Validation loss: 2.6832743883132935

Epoch: 5| Step: 1
Training loss: 2.8101303577423096
Validation loss: 2.684144755204519

Epoch: 5| Step: 2
Training loss: 2.9572765827178955
Validation loss: 2.677657256523768

Epoch: 5| Step: 3
Training loss: 4.1631059646606445
Validation loss: 2.6754286686579385

Epoch: 5| Step: 4
Training loss: 3.0622971057891846
Validation loss: 2.671947807073593

Epoch: 5| Step: 5
Training loss: 2.523937225341797
Validation loss: 2.6673782070477805

Epoch: 5| Step: 6
Training loss: 2.6501002311706543
Validation loss: 2.664750268061956

Epoch: 5| Step: 7
Training loss: 2.533874750137329
Validation loss: 2.665726453065872

Epoch: 5| Step: 8
Training loss: 2.6872596740722656
Validation loss: 2.6663192311922708

Epoch: 5| Step: 9
Training loss: 2.5609891414642334
Validation loss: 2.6664352218310037

Epoch: 5| Step: 10
Training loss: 2.843018054962158
Validation loss: 2.6651488840579987

Epoch: 5| Step: 11
Training loss: 3.1323776245117188
Validation loss: 2.658447782198588

Epoch: 43| Step: 0
Training loss: 2.0935821533203125
Validation loss: 2.65038408835729

Epoch: 5| Step: 1
Training loss: 3.3452670574188232
Validation loss: 2.6436605950196586

Epoch: 5| Step: 2
Training loss: 2.482828378677368
Validation loss: 2.638619154691696

Epoch: 5| Step: 3
Training loss: 2.9026410579681396
Validation loss: 2.634873539209366

Epoch: 5| Step: 4
Training loss: 3.436211347579956
Validation loss: 2.6321134865283966

Epoch: 5| Step: 5
Training loss: 2.996267557144165
Validation loss: 2.6294041772683463

Epoch: 5| Step: 6
Training loss: 2.8480074405670166
Validation loss: 2.6258780658245087

Epoch: 5| Step: 7
Training loss: 2.5286965370178223
Validation loss: 2.6232141653696694

Epoch: 5| Step: 8
Training loss: 2.831636667251587
Validation loss: 2.617552399635315

Epoch: 5| Step: 9
Training loss: 2.611313581466675
Validation loss: 2.617602194348971

Epoch: 5| Step: 10
Training loss: 2.7818455696105957
Validation loss: 2.613822797934214

Epoch: 5| Step: 11
Training loss: 4.204664707183838
Validation loss: 2.6092520356178284

Epoch: 44| Step: 0
Training loss: 2.8715968132019043
Validation loss: 2.6041118105252585

Epoch: 5| Step: 1
Training loss: 2.62870717048645
Validation loss: 2.599212189515432

Epoch: 5| Step: 2
Training loss: 3.3647823333740234
Validation loss: 2.5949823458989463

Epoch: 5| Step: 3
Training loss: 2.8993916511535645
Validation loss: 2.59267321228981

Epoch: 5| Step: 4
Training loss: 2.4410934448242188
Validation loss: 2.5879197220007577

Epoch: 5| Step: 5
Training loss: 3.011073589324951
Validation loss: 2.585503359635671

Epoch: 5| Step: 6
Training loss: 2.8698408603668213
Validation loss: 2.5816470086574554

Epoch: 5| Step: 7
Training loss: 2.753723621368408
Validation loss: 2.5786983221769333

Epoch: 5| Step: 8
Training loss: 2.4380173683166504
Validation loss: 2.573015958070755

Epoch: 5| Step: 9
Training loss: 2.346176862716675
Validation loss: 2.5696847240130105

Epoch: 5| Step: 10
Training loss: 2.9167604446411133
Validation loss: 2.568325092395147

Epoch: 5| Step: 11
Training loss: 3.3028969764709473
Validation loss: 2.56273290514946

Epoch: 45| Step: 0
Training loss: 2.9550652503967285
Validation loss: 2.563498849670092

Epoch: 5| Step: 1
Training loss: 3.026646614074707
Validation loss: 2.561109443505605

Epoch: 5| Step: 2
Training loss: 2.664356231689453
Validation loss: 2.5543845494588218

Epoch: 5| Step: 3
Training loss: 1.850563406944275
Validation loss: 2.5568867226441703

Epoch: 5| Step: 4
Training loss: 2.521711826324463
Validation loss: 2.549094259738922

Epoch: 5| Step: 5
Training loss: 2.611530303955078
Validation loss: 2.5463514029979706

Epoch: 5| Step: 6
Training loss: 2.131441831588745
Validation loss: 2.5497185587882996

Epoch: 5| Step: 7
Training loss: 3.2281670570373535
Validation loss: 2.5536363621552787

Epoch: 5| Step: 8
Training loss: 3.053896903991699
Validation loss: 2.575060894091924

Epoch: 5| Step: 9
Training loss: 3.1399383544921875
Validation loss: 2.5442216296990714

Epoch: 5| Step: 10
Training loss: 3.0662097930908203
Validation loss: 2.533611446619034

Epoch: 5| Step: 11
Training loss: 2.4289426803588867
Validation loss: 2.5279913445313773

Epoch: 46| Step: 0
Training loss: 2.176071882247925
Validation loss: 2.5247773826122284

Epoch: 5| Step: 1
Training loss: 2.557102918624878
Validation loss: 2.523460179567337

Epoch: 5| Step: 2
Training loss: 2.3846795558929443
Validation loss: 2.523914714654287

Epoch: 5| Step: 3
Training loss: 2.8726260662078857
Validation loss: 2.527216225862503

Epoch: 5| Step: 4
Training loss: 2.1817240715026855
Validation loss: 2.531564017136892

Epoch: 5| Step: 5
Training loss: 3.572319507598877
Validation loss: 2.523689786593119

Epoch: 5| Step: 6
Training loss: 2.9105961322784424
Validation loss: 2.5172705948352814

Epoch: 5| Step: 7
Training loss: 2.896800994873047
Validation loss: 2.5132232010364532

Epoch: 5| Step: 8
Training loss: 2.5122199058532715
Validation loss: 2.5083338618278503

Epoch: 5| Step: 9
Training loss: 2.5443828105926514
Validation loss: 2.5051296403010688

Epoch: 5| Step: 10
Training loss: 2.9102165699005127
Validation loss: 2.5030883053938546

Epoch: 5| Step: 11
Training loss: 4.136294364929199
Validation loss: 2.503901024659475

Epoch: 47| Step: 0
Training loss: 2.471277952194214
Validation loss: 2.505938102801641

Epoch: 5| Step: 1
Training loss: 2.405353307723999
Validation loss: 2.518538405497869

Epoch: 5| Step: 2
Training loss: 2.602048397064209
Validation loss: 2.508846660455068

Epoch: 5| Step: 3
Training loss: 2.676363468170166
Validation loss: 2.501456340154012

Epoch: 5| Step: 4
Training loss: 2.812000274658203
Validation loss: 2.490718533595403

Epoch: 5| Step: 5
Training loss: 2.9012680053710938
Validation loss: 2.4833306074142456

Epoch: 5| Step: 6
Training loss: 2.321953296661377
Validation loss: 2.477335900068283

Epoch: 5| Step: 7
Training loss: 2.6825461387634277
Validation loss: 2.474991420904795

Epoch: 5| Step: 8
Training loss: 2.250808000564575
Validation loss: 2.47160342335701

Epoch: 5| Step: 9
Training loss: 2.873473644256592
Validation loss: 2.4697230557600656

Epoch: 5| Step: 10
Training loss: 3.1679091453552246
Validation loss: 2.466620226701101

Epoch: 5| Step: 11
Training loss: 3.691506862640381
Validation loss: 2.466755598783493

Epoch: 48| Step: 0
Training loss: 2.325409412384033
Validation loss: 2.4631695548693338

Epoch: 5| Step: 1
Training loss: 2.8299808502197266
Validation loss: 2.459793835878372

Epoch: 5| Step: 2
Training loss: 2.475386142730713
Validation loss: 2.4557906687259674

Epoch: 5| Step: 3
Training loss: 2.4658474922180176
Validation loss: 2.452720671892166

Epoch: 5| Step: 4
Training loss: 2.854076862335205
Validation loss: 2.4497143526872

Epoch: 5| Step: 5
Training loss: 2.91325306892395
Validation loss: 2.4429549177487693

Epoch: 5| Step: 6
Training loss: 2.752995729446411
Validation loss: 2.4410589188337326

Epoch: 5| Step: 7
Training loss: 3.182091236114502
Validation loss: 2.4371194789807

Epoch: 5| Step: 8
Training loss: 2.262481927871704
Validation loss: 2.4334297676881156

Epoch: 5| Step: 9
Training loss: 2.5698189735412598
Validation loss: 2.4309848149617515

Epoch: 5| Step: 10
Training loss: 2.338670253753662
Validation loss: 2.425559083620707

Epoch: 5| Step: 11
Training loss: 2.49125337600708
Validation loss: 2.4216826458772025

Epoch: 49| Step: 0
Training loss: 2.7743940353393555
Validation loss: 2.4203243951002755

Epoch: 5| Step: 1
Training loss: 3.1197915077209473
Validation loss: 2.418321500221888

Epoch: 5| Step: 2
Training loss: 2.7249183654785156
Validation loss: 2.4147877792517343

Epoch: 5| Step: 3
Training loss: 2.174192190170288
Validation loss: 2.4138001203536987

Epoch: 5| Step: 4
Training loss: 2.0448851585388184
Validation loss: 2.4108851651350656

Epoch: 5| Step: 5
Training loss: 2.7884087562561035
Validation loss: 2.4071064392725625

Epoch: 5| Step: 6
Training loss: 2.1702322959899902
Validation loss: 2.402970016002655

Epoch: 5| Step: 7
Training loss: 2.5898962020874023
Validation loss: 2.3983218173185983

Epoch: 5| Step: 8
Training loss: 2.8830790519714355
Validation loss: 2.3957564334074655

Epoch: 5| Step: 9
Training loss: 3.1479575634002686
Validation loss: 2.393058414260546

Epoch: 5| Step: 10
Training loss: 2.193697214126587
Validation loss: 2.3903722167015076

Epoch: 5| Step: 11
Training loss: 1.8759348392486572
Validation loss: 2.391429285208384

Epoch: 50| Step: 0
Training loss: 2.581690788269043
Validation loss: 2.383640080690384

Epoch: 5| Step: 1
Training loss: 2.5489916801452637
Validation loss: 2.381024350722631

Epoch: 5| Step: 2
Training loss: 2.740558385848999
Validation loss: 2.381410226225853

Epoch: 5| Step: 3
Training loss: 2.5496859550476074
Validation loss: 2.384058097998301

Epoch: 5| Step: 4
Training loss: 2.095323324203491
Validation loss: 2.3792463143666587

Epoch: 5| Step: 5
Training loss: 3.0946831703186035
Validation loss: 2.3736936698357263

Epoch: 5| Step: 6
Training loss: 2.7541275024414062
Validation loss: 2.36435067653656

Epoch: 5| Step: 7
Training loss: 2.902686595916748
Validation loss: 2.363129198551178

Epoch: 5| Step: 8
Training loss: 2.1593809127807617
Validation loss: 2.3602141042550406

Epoch: 5| Step: 9
Training loss: 2.4526898860931396
Validation loss: 2.35738035539786

Epoch: 5| Step: 10
Training loss: 2.0644311904907227
Validation loss: 2.351421078046163

Epoch: 5| Step: 11
Training loss: 2.830064296722412
Validation loss: 2.3548546731472015

Epoch: 51| Step: 0
Training loss: 2.40759015083313
Validation loss: 2.346413900454839

Epoch: 5| Step: 1
Training loss: 2.4313087463378906
Validation loss: 2.3471805453300476

Epoch: 5| Step: 2
Training loss: 2.088972330093384
Validation loss: 2.3487803240617118

Epoch: 5| Step: 3
Training loss: 2.799436092376709
Validation loss: 2.361169382929802

Epoch: 5| Step: 4
Training loss: 2.5654022693634033
Validation loss: 2.3575855791568756

Epoch: 5| Step: 5
Training loss: 2.5599513053894043
Validation loss: 2.344029814004898

Epoch: 5| Step: 6
Training loss: 2.466683864593506
Validation loss: 2.328201179703077

Epoch: 5| Step: 7
Training loss: 2.070800304412842
Validation loss: 2.33254212141037

Epoch: 5| Step: 8
Training loss: 2.3007943630218506
Validation loss: 2.330320114890734

Epoch: 5| Step: 9
Training loss: 2.9025418758392334
Validation loss: 2.3326090971628823

Epoch: 5| Step: 10
Training loss: 2.833530902862549
Validation loss: 2.3322139382362366

Epoch: 5| Step: 11
Training loss: 3.422699213027954
Validation loss: 2.329099878668785

Epoch: 52| Step: 0
Training loss: 1.7893238067626953
Validation loss: 2.3272254268328347

Epoch: 5| Step: 1
Training loss: 2.871204137802124
Validation loss: 2.3246418833732605

Epoch: 5| Step: 2
Training loss: 2.8229522705078125
Validation loss: 2.32083394130071

Epoch: 5| Step: 3
Training loss: 2.4866364002227783
Validation loss: 2.318127249677976

Epoch: 5| Step: 4
Training loss: 2.4709784984588623
Validation loss: 2.3120184441407523

Epoch: 5| Step: 5
Training loss: 2.4963479042053223
Validation loss: 2.3096149365107217

Epoch: 5| Step: 6
Training loss: 2.723282814025879
Validation loss: 2.3077873388926187

Epoch: 5| Step: 7
Training loss: 1.890667200088501
Validation loss: 2.297304004430771

Epoch: 5| Step: 8
Training loss: 2.417921781539917
Validation loss: 2.2928929229577384

Epoch: 5| Step: 9
Training loss: 2.392996311187744
Validation loss: 2.2899570067723594

Epoch: 5| Step: 10
Training loss: 2.697803020477295
Validation loss: 2.291721910238266

Epoch: 5| Step: 11
Training loss: 2.846306800842285
Validation loss: 2.293447181582451

Epoch: 53| Step: 0
Training loss: 2.332280158996582
Validation loss: 2.2943288286527

Epoch: 5| Step: 1
Training loss: 2.3291850090026855
Validation loss: 2.2836115459601083

Epoch: 5| Step: 2
Training loss: 1.9525330066680908
Validation loss: 2.2814937283595405

Epoch: 5| Step: 3
Training loss: 2.1056628227233887
Validation loss: 2.2832978119452796

Epoch: 5| Step: 4
Training loss: 2.9864771366119385
Validation loss: 2.277601718902588

Epoch: 5| Step: 5
Training loss: 2.220468759536743
Validation loss: 2.2651491463184357

Epoch: 5| Step: 6
Training loss: 2.6662745475769043
Validation loss: 2.2689978082974753

Epoch: 5| Step: 7
Training loss: 3.010504961013794
Validation loss: 2.270849267641703

Epoch: 5| Step: 8
Training loss: 2.588658571243286
Validation loss: 2.2720214873552322

Epoch: 5| Step: 9
Training loss: 2.638843059539795
Validation loss: 2.270487815141678

Epoch: 5| Step: 10
Training loss: 2.146780490875244
Validation loss: 2.274746596813202

Epoch: 5| Step: 11
Training loss: 1.4085878133773804
Validation loss: 2.276810576518377

Epoch: 54| Step: 0
Training loss: 2.3669803142547607
Validation loss: 2.278119092186292

Epoch: 5| Step: 1
Training loss: 2.880579710006714
Validation loss: 2.2739958663781485

Epoch: 5| Step: 2
Training loss: 2.7066447734832764
Validation loss: 2.2723754743734994

Epoch: 5| Step: 3
Training loss: 2.2365124225616455
Validation loss: 2.2647433082262673

Epoch: 5| Step: 4
Training loss: 2.6563892364501953
Validation loss: 2.2583543558915458

Epoch: 5| Step: 5
Training loss: 2.2927730083465576
Validation loss: 2.250525693098704

Epoch: 5| Step: 6
Training loss: 1.6939712762832642
Validation loss: 2.2475400120019913

Epoch: 5| Step: 7
Training loss: 2.4411323070526123
Validation loss: 2.242246980468432

Epoch: 5| Step: 8
Training loss: 2.6645350456237793
Validation loss: 2.238012989362081

Epoch: 5| Step: 9
Training loss: 2.346886157989502
Validation loss: 2.234899878501892

Epoch: 5| Step: 10
Training loss: 2.162118911743164
Validation loss: 2.22892627120018

Epoch: 5| Step: 11
Training loss: 2.6184451580047607
Validation loss: 2.2228761663039527

Epoch: 55| Step: 0
Training loss: 2.929647445678711
Validation loss: 2.2247568517923355

Epoch: 5| Step: 1
Training loss: 2.135725736618042
Validation loss: 2.216209371884664

Epoch: 5| Step: 2
Training loss: 1.9480549097061157
Validation loss: 2.215883364280065

Epoch: 5| Step: 3
Training loss: 2.137019634246826
Validation loss: 2.22003381450971

Epoch: 5| Step: 4
Training loss: 2.169891357421875
Validation loss: 2.222262422243754

Epoch: 5| Step: 5
Training loss: 2.613478899002075
Validation loss: 2.2202332417170205

Epoch: 5| Step: 6
Training loss: 2.778998613357544
Validation loss: 2.204072336355845

Epoch: 5| Step: 7
Training loss: 2.2345519065856934
Validation loss: 2.201064387957255

Epoch: 5| Step: 8
Training loss: 1.7916362285614014
Validation loss: 2.20565402507782

Epoch: 5| Step: 9
Training loss: 2.503309726715088
Validation loss: 2.2075051118930182

Epoch: 5| Step: 10
Training loss: 2.747079372406006
Validation loss: 2.2103180487950644

Epoch: 5| Step: 11
Training loss: 2.9553866386413574
Validation loss: 2.2061147491137185

Epoch: 56| Step: 0
Training loss: 2.1469860076904297
Validation loss: 2.206739674011866

Epoch: 5| Step: 1
Training loss: 2.3934237957000732
Validation loss: 2.2040753265221915

Epoch: 5| Step: 2
Training loss: 2.672626256942749
Validation loss: 2.2015133748451867

Epoch: 5| Step: 3
Training loss: 2.577394962310791
Validation loss: 2.201670522491137

Epoch: 5| Step: 4
Training loss: 2.123141050338745
Validation loss: 2.1977314800024033

Epoch: 5| Step: 5
Training loss: 1.583573579788208
Validation loss: 2.1948261161645255

Epoch: 5| Step: 6
Training loss: 2.7022528648376465
Validation loss: 2.186955004930496

Epoch: 5| Step: 7
Training loss: 2.5563952922821045
Validation loss: 2.1808664898077645

Epoch: 5| Step: 8
Training loss: 2.7226638793945312
Validation loss: 2.179874926805496

Epoch: 5| Step: 9
Training loss: 2.09684419631958
Validation loss: 2.1812176406383514

Epoch: 5| Step: 10
Training loss: 2.189988613128662
Validation loss: 2.1775080462296805

Epoch: 5| Step: 11
Training loss: 2.5198426246643066
Validation loss: 2.1779369016488395

Epoch: 57| Step: 0
Training loss: 2.2364449501037598
Validation loss: 2.1685503721237183

Epoch: 5| Step: 1
Training loss: 2.520228147506714
Validation loss: 2.1668982903162637

Epoch: 5| Step: 2
Training loss: 2.0756278038024902
Validation loss: 2.1776557813088098

Epoch: 5| Step: 3
Training loss: 2.6057188510894775
Validation loss: 2.174563373128573

Epoch: 5| Step: 4
Training loss: 2.3240807056427
Validation loss: 2.1740845143795013

Epoch: 5| Step: 5
Training loss: 2.647432804107666
Validation loss: 2.17554863790671

Epoch: 5| Step: 6
Training loss: 2.133885622024536
Validation loss: 2.1754406889279685

Epoch: 5| Step: 7
Training loss: 2.4742214679718018
Validation loss: 2.1720776855945587

Epoch: 5| Step: 8
Training loss: 2.499427318572998
Validation loss: 2.1704239596923194

Epoch: 5| Step: 9
Training loss: 1.8122279644012451
Validation loss: 2.172942986090978

Epoch: 5| Step: 10
Training loss: 2.2121787071228027
Validation loss: 2.1722730100154877

Epoch: 5| Step: 11
Training loss: 2.8092446327209473
Validation loss: 2.168426364660263

Epoch: 58| Step: 0
Training loss: 3.0220301151275635
Validation loss: 2.165961061914762

Epoch: 5| Step: 1
Training loss: 1.728092908859253
Validation loss: 2.164389133453369

Epoch: 5| Step: 2
Training loss: 1.9937117099761963
Validation loss: 2.1642508258422217

Epoch: 5| Step: 3
Training loss: 2.8025965690612793
Validation loss: 2.1575190275907516

Epoch: 5| Step: 4
Training loss: 2.1338114738464355
Validation loss: 2.155765031774839

Epoch: 5| Step: 5
Training loss: 1.9777072668075562
Validation loss: 2.1509615778923035

Epoch: 5| Step: 6
Training loss: 2.155874252319336
Validation loss: 2.1472493211428323

Epoch: 5| Step: 7
Training loss: 2.590610980987549
Validation loss: 2.147331361969312

Epoch: 5| Step: 8
Training loss: 2.221411943435669
Validation loss: 2.144301106532415

Epoch: 5| Step: 9
Training loss: 2.881260395050049
Validation loss: 2.1476344565550485

Epoch: 5| Step: 10
Training loss: 1.7943751811981201
Validation loss: 2.146934370199839

Epoch: 5| Step: 11
Training loss: 2.9634933471679688
Validation loss: 2.144194006919861

Epoch: 59| Step: 0
Training loss: 2.8217170238494873
Validation loss: 2.1457028885682425

Epoch: 5| Step: 1
Training loss: 1.6923691034317017
Validation loss: 2.134807383020719

Epoch: 5| Step: 2
Training loss: 2.3720946311950684
Validation loss: 2.1308164298534393

Epoch: 5| Step: 3
Training loss: 2.7830166816711426
Validation loss: 2.132213761409124

Epoch: 5| Step: 4
Training loss: 2.1836135387420654
Validation loss: 2.13080803056558

Epoch: 5| Step: 5
Training loss: 2.149813652038574
Validation loss: 2.139923080801964

Epoch: 5| Step: 6
Training loss: 2.289008378982544
Validation loss: 2.1330626209576926

Epoch: 5| Step: 7
Training loss: 2.348874568939209
Validation loss: 2.1312883347272873

Epoch: 5| Step: 8
Training loss: 1.847556710243225
Validation loss: 2.1255386620759964

Epoch: 5| Step: 9
Training loss: 2.780578136444092
Validation loss: 2.1252536674340567

Epoch: 5| Step: 10
Training loss: 2.116025447845459
Validation loss: 2.1213402996460595

Epoch: 5| Step: 11
Training loss: 1.6551824808120728
Validation loss: 2.1208512286345163

Epoch: 60| Step: 0
Training loss: 2.5491783618927
Validation loss: 2.119484171271324

Epoch: 5| Step: 1
Training loss: 1.9249904155731201
Validation loss: 2.1153507779041925

Epoch: 5| Step: 2
Training loss: 2.1710383892059326
Validation loss: 2.119454964995384

Epoch: 5| Step: 3
Training loss: 2.0733017921447754
Validation loss: 2.1280827770630517

Epoch: 5| Step: 4
Training loss: 1.736602783203125
Validation loss: 2.1448435286680856

Epoch: 5| Step: 5
Training loss: 2.1856226921081543
Validation loss: 2.1394350479046502

Epoch: 5| Step: 6
Training loss: 2.6823201179504395
Validation loss: 2.1280796428521476

Epoch: 5| Step: 7
Training loss: 2.449012517929077
Validation loss: 2.1033496111631393

Epoch: 5| Step: 8
Training loss: 2.4716382026672363
Validation loss: 2.113358328739802

Epoch: 5| Step: 9
Training loss: 2.4708609580993652
Validation loss: 2.1165587653716407

Epoch: 5| Step: 10
Training loss: 2.3157832622528076
Validation loss: 2.119405801097552

Epoch: 5| Step: 11
Training loss: 2.670851230621338
Validation loss: 2.125360215703646

Epoch: 61| Step: 0
Training loss: 2.366769313812256
Validation loss: 2.1360767036676407

Epoch: 5| Step: 1
Training loss: 2.3102664947509766
Validation loss: 2.1583248525857925

Epoch: 5| Step: 2
Training loss: 1.760250449180603
Validation loss: 2.1777075976133347

Epoch: 5| Step: 3
Training loss: 2.258227825164795
Validation loss: 2.176827942331632

Epoch: 5| Step: 4
Training loss: 2.681856632232666
Validation loss: 2.1756605009237924

Epoch: 5| Step: 5
Training loss: 2.5407328605651855
Validation loss: 2.1684832076231637

Epoch: 5| Step: 6
Training loss: 2.1021718978881836
Validation loss: 2.1548349857330322

Epoch: 5| Step: 7
Training loss: 2.3722519874572754
Validation loss: 2.1426122883955636

Epoch: 5| Step: 8
Training loss: 2.0642025470733643
Validation loss: 2.138502925634384

Epoch: 5| Step: 9
Training loss: 2.428072929382324
Validation loss: 2.128471930821737

Epoch: 5| Step: 10
Training loss: 2.824570894241333
Validation loss: 2.122708340485891

Epoch: 5| Step: 11
Training loss: 1.3820757865905762
Validation loss: 2.1154707769552865

Epoch: 62| Step: 0
Training loss: 2.027998447418213
Validation loss: 2.112751384576162

Epoch: 5| Step: 1
Training loss: 2.533236026763916
Validation loss: 2.1114421288172402

Epoch: 5| Step: 2
Training loss: 1.8808610439300537
Validation loss: 2.1049610326687493

Epoch: 5| Step: 3
Training loss: 2.220430374145508
Validation loss: 2.1047136038541794

Epoch: 5| Step: 4
Training loss: 2.317412853240967
Validation loss: 2.0987749298413596

Epoch: 5| Step: 5
Training loss: 2.4634439945220947
Validation loss: 2.0979094952344894

Epoch: 5| Step: 6
Training loss: 2.805490016937256
Validation loss: 2.0918350915114083

Epoch: 5| Step: 7
Training loss: 1.8197906017303467
Validation loss: 2.081623360514641

Epoch: 5| Step: 8
Training loss: 2.3329741954803467
Validation loss: 2.085657522082329

Epoch: 5| Step: 9
Training loss: 2.6578495502471924
Validation loss: 2.0866569032271705

Epoch: 5| Step: 10
Training loss: 1.8858625888824463
Validation loss: 2.096548562248548

Epoch: 5| Step: 11
Training loss: 1.5313481092453003
Validation loss: 2.1249042749404907

Epoch: 63| Step: 0
Training loss: 2.3099300861358643
Validation loss: 2.091624607642492

Epoch: 5| Step: 1
Training loss: 1.581960678100586
Validation loss: 2.0777725825707116

Epoch: 5| Step: 2
Training loss: 2.8377649784088135
Validation loss: 2.0777809619903564

Epoch: 5| Step: 3
Training loss: 1.9480197429656982
Validation loss: 2.0902203420797982

Epoch: 5| Step: 4
Training loss: 2.9008467197418213
Validation loss: 2.091662108898163

Epoch: 5| Step: 5
Training loss: 2.15797758102417
Validation loss: 2.0932660152514777

Epoch: 5| Step: 6
Training loss: 1.9333865642547607
Validation loss: 2.097914050022761

Epoch: 5| Step: 7
Training loss: 2.781747817993164
Validation loss: 2.0999907851219177

Epoch: 5| Step: 8
Training loss: 2.649421215057373
Validation loss: 2.103592405716578

Epoch: 5| Step: 9
Training loss: 2.0826656818389893
Validation loss: 2.1103956451018653

Epoch: 5| Step: 10
Training loss: 2.034935474395752
Validation loss: 2.1036954671144485

Epoch: 5| Step: 11
Training loss: 1.3872246742248535
Validation loss: 2.106469770272573

Epoch: 64| Step: 0
Training loss: 2.3649866580963135
Validation loss: 2.1012414544820786

Epoch: 5| Step: 1
Training loss: 2.3403100967407227
Validation loss: 2.1028591642777124

Epoch: 5| Step: 2
Training loss: 2.3541653156280518
Validation loss: 2.101179525256157

Epoch: 5| Step: 3
Training loss: 2.0250511169433594
Validation loss: 2.0938664078712463

Epoch: 5| Step: 4
Training loss: 1.9516944885253906
Validation loss: 2.0880072563886642

Epoch: 5| Step: 5
Training loss: 2.2375826835632324
Validation loss: 2.0844787706931434

Epoch: 5| Step: 6
Training loss: 2.2324612140655518
Validation loss: 2.083411768078804

Epoch: 5| Step: 7
Training loss: 2.749077320098877
Validation loss: 2.091506689786911

Epoch: 5| Step: 8
Training loss: 2.038989543914795
Validation loss: 2.0867203374703727

Epoch: 5| Step: 9
Training loss: 2.4680042266845703
Validation loss: 2.076865086952845

Epoch: 5| Step: 10
Training loss: 2.129627227783203
Validation loss: 2.0775194466114044

Epoch: 5| Step: 11
Training loss: 2.9615705013275146
Validation loss: 2.0745740036169686

Epoch: 65| Step: 0
Training loss: 2.2715659141540527
Validation loss: 2.0628690322240195

Epoch: 5| Step: 1
Training loss: 1.7962251901626587
Validation loss: 2.067249337832133

Epoch: 5| Step: 2
Training loss: 2.5130298137664795
Validation loss: 2.072012131412824

Epoch: 5| Step: 3
Training loss: 1.4952032566070557
Validation loss: 2.0798187851905823

Epoch: 5| Step: 4
Training loss: 2.5587267875671387
Validation loss: 2.079038808743159

Epoch: 5| Step: 5
Training loss: 2.243530750274658
Validation loss: 2.0771944175163903

Epoch: 5| Step: 6
Training loss: 2.8935635089874268
Validation loss: 2.0787607729434967

Epoch: 5| Step: 7
Training loss: 1.9429610967636108
Validation loss: 2.078302318851153

Epoch: 5| Step: 8
Training loss: 2.410555601119995
Validation loss: 2.0733982225259147

Epoch: 5| Step: 9
Training loss: 2.3661789894104004
Validation loss: 2.0725026428699493

Epoch: 5| Step: 10
Training loss: 2.3323750495910645
Validation loss: 2.0732729931672416

Epoch: 5| Step: 11
Training loss: 2.3051087856292725
Validation loss: 2.0733918050924935

Epoch: 66| Step: 0
Training loss: 2.3535115718841553
Validation loss: 2.068935294946035

Epoch: 5| Step: 1
Training loss: 1.7482337951660156
Validation loss: 2.064340651035309

Epoch: 5| Step: 2
Training loss: 2.1549344062805176
Validation loss: 2.0618796745936074

Epoch: 5| Step: 3
Training loss: 2.9712605476379395
Validation loss: 2.0531912992397943

Epoch: 5| Step: 4
Training loss: 1.8737579584121704
Validation loss: 2.0458555668592453

Epoch: 5| Step: 5
Training loss: 2.3617889881134033
Validation loss: 2.0565447012583413

Epoch: 5| Step: 6
Training loss: 2.2436840534210205
Validation loss: 2.0533369133869805

Epoch: 5| Step: 7
Training loss: 2.0167064666748047
Validation loss: 2.0575924863417945

Epoch: 5| Step: 8
Training loss: 2.2682764530181885
Validation loss: 2.05921637515227

Epoch: 5| Step: 9
Training loss: 2.5019166469573975
Validation loss: 2.0746781875689826

Epoch: 5| Step: 10
Training loss: 2.1547553539276123
Validation loss: 2.0692292352517447

Epoch: 5| Step: 11
Training loss: 2.466017723083496
Validation loss: 2.053207829594612

Epoch: 67| Step: 0
Training loss: 2.2585182189941406
Validation loss: 2.0460556695858636

Epoch: 5| Step: 1
Training loss: 1.8118984699249268
Validation loss: 2.045797437429428

Epoch: 5| Step: 2
Training loss: 2.314861536026001
Validation loss: 2.0586637258529663

Epoch: 5| Step: 3
Training loss: 1.9352283477783203
Validation loss: 2.0646177530288696

Epoch: 5| Step: 4
Training loss: 2.2071499824523926
Validation loss: 2.072964698076248

Epoch: 5| Step: 5
Training loss: 2.1976287364959717
Validation loss: 2.084223061800003

Epoch: 5| Step: 6
Training loss: 2.93241548538208
Validation loss: 2.0869994858900704

Epoch: 5| Step: 7
Training loss: 2.614431858062744
Validation loss: 2.093003918727239

Epoch: 5| Step: 8
Training loss: 2.0417542457580566
Validation loss: 2.0931462347507477

Epoch: 5| Step: 9
Training loss: 2.129305601119995
Validation loss: 2.096956640481949

Epoch: 5| Step: 10
Training loss: 2.8217291831970215
Validation loss: 2.0936715404192605

Epoch: 5| Step: 11
Training loss: 1.592429757118225
Validation loss: 2.0917208244403205

Epoch: 68| Step: 0
Training loss: 2.478893756866455
Validation loss: 2.0904422402381897

Epoch: 5| Step: 1
Training loss: 2.253061056137085
Validation loss: 2.086834261814753

Epoch: 5| Step: 2
Training loss: 2.313138961791992
Validation loss: 2.081218217809995

Epoch: 5| Step: 3
Training loss: 2.0491743087768555
Validation loss: 2.0772934953371682

Epoch: 5| Step: 4
Training loss: 2.0072429180145264
Validation loss: 2.069633404413859

Epoch: 5| Step: 5
Training loss: 2.2112090587615967
Validation loss: 2.0674732277790704

Epoch: 5| Step: 6
Training loss: 1.6573158502578735
Validation loss: 2.0597818394502005

Epoch: 5| Step: 7
Training loss: 2.5316672325134277
Validation loss: 2.0612888733545938

Epoch: 5| Step: 8
Training loss: 2.3778727054595947
Validation loss: 2.0592527290185294

Epoch: 5| Step: 9
Training loss: 2.4876303672790527
Validation loss: 2.051955372095108

Epoch: 5| Step: 10
Training loss: 2.4906692504882812
Validation loss: 2.052359104156494

Epoch: 5| Step: 11
Training loss: 2.6245832443237305
Validation loss: 2.051609754562378

Epoch: 69| Step: 0
Training loss: 2.6276042461395264
Validation loss: 2.0498538315296173

Epoch: 5| Step: 1
Training loss: 2.7885632514953613
Validation loss: 2.045125350356102

Epoch: 5| Step: 2
Training loss: 1.8200061321258545
Validation loss: 2.0440936287244162

Epoch: 5| Step: 3
Training loss: 2.033006429672241
Validation loss: 2.0504434605439505

Epoch: 5| Step: 4
Training loss: 2.6444172859191895
Validation loss: 2.0430308332045874

Epoch: 5| Step: 5
Training loss: 2.214953899383545
Validation loss: 2.034341017405192

Epoch: 5| Step: 6
Training loss: 1.7416061162948608
Validation loss: 2.042934571703275

Epoch: 5| Step: 7
Training loss: 1.958391547203064
Validation loss: 2.0389577448368073

Epoch: 5| Step: 8
Training loss: 2.252005100250244
Validation loss: 2.035717328389486

Epoch: 5| Step: 9
Training loss: 2.1182048320770264
Validation loss: 2.039018084605535

Epoch: 5| Step: 10
Training loss: 2.361706256866455
Validation loss: 2.032917618751526

Epoch: 5| Step: 11
Training loss: 1.7008239030838013
Validation loss: 2.0333548237880072

Epoch: 70| Step: 0
Training loss: 2.194453477859497
Validation loss: 2.038327470421791

Epoch: 5| Step: 1
Training loss: 2.3351619243621826
Validation loss: 2.0324970285097756

Epoch: 5| Step: 2
Training loss: 2.5099432468414307
Validation loss: 2.033335641026497

Epoch: 5| Step: 3
Training loss: 2.1928625106811523
Validation loss: 2.0362483312686286

Epoch: 5| Step: 4
Training loss: 2.1774048805236816
Validation loss: 2.0407867431640625

Epoch: 5| Step: 5
Training loss: 1.7624810934066772
Validation loss: 2.046169196565946

Epoch: 5| Step: 6
Training loss: 2.115715980529785
Validation loss: 2.0261163463195166

Epoch: 5| Step: 7
Training loss: 2.905139684677124
Validation loss: 2.030199348926544

Epoch: 5| Step: 8
Training loss: 2.2193264961242676
Validation loss: 2.036464676260948

Epoch: 5| Step: 9
Training loss: 2.1538562774658203
Validation loss: 2.0360104093949

Epoch: 5| Step: 10
Training loss: 1.8953163623809814
Validation loss: 2.04009011387825

Epoch: 5| Step: 11
Training loss: 1.724031686782837
Validation loss: 2.04580911497275

Epoch: 71| Step: 0
Training loss: 2.5186779499053955
Validation loss: 2.0495053182045617

Epoch: 5| Step: 1
Training loss: 2.250941276550293
Validation loss: 2.0509046763181686

Epoch: 5| Step: 2
Training loss: 2.6449527740478516
Validation loss: 2.0421518087387085

Epoch: 5| Step: 3
Training loss: 2.20395565032959
Validation loss: 2.045181527733803

Epoch: 5| Step: 4
Training loss: 2.2694742679595947
Validation loss: 2.048677146434784

Epoch: 5| Step: 5
Training loss: 1.8921031951904297
Validation loss: 2.042402351895968

Epoch: 5| Step: 6
Training loss: 2.2189762592315674
Validation loss: 2.0413536727428436

Epoch: 5| Step: 7
Training loss: 1.8184515237808228
Validation loss: 2.0430775384108224

Epoch: 5| Step: 8
Training loss: 2.17227840423584
Validation loss: 2.0404168317715325

Epoch: 5| Step: 9
Training loss: 2.1259427070617676
Validation loss: 2.038701504468918

Epoch: 5| Step: 10
Training loss: 2.2744383811950684
Validation loss: 2.038645108540853

Epoch: 5| Step: 11
Training loss: 2.585818290710449
Validation loss: 2.0370559444030127

Epoch: 72| Step: 0
Training loss: 2.2092642784118652
Validation loss: 2.0338468650976815

Epoch: 5| Step: 1
Training loss: 2.073871612548828
Validation loss: 2.0330237646897635

Epoch: 5| Step: 2
Training loss: 2.4809932708740234
Validation loss: 2.029522866010666

Epoch: 5| Step: 3
Training loss: 1.9894897937774658
Validation loss: 2.0293988386789956

Epoch: 5| Step: 4
Training loss: 2.0473670959472656
Validation loss: 2.0283536463975906

Epoch: 5| Step: 5
Training loss: 1.8767194747924805
Validation loss: 2.028306722640991

Epoch: 5| Step: 6
Training loss: 2.07560658454895
Validation loss: 2.036305988828341

Epoch: 5| Step: 7
Training loss: 2.5689001083374023
Validation loss: 2.0337767551342645

Epoch: 5| Step: 8
Training loss: 2.085165500640869
Validation loss: 2.0332983831564584

Epoch: 5| Step: 9
Training loss: 1.9984585046768188
Validation loss: 2.030707210302353

Epoch: 5| Step: 10
Training loss: 3.0052762031555176
Validation loss: 2.0263678381840386

Epoch: 5| Step: 11
Training loss: 1.8107690811157227
Validation loss: 2.028072635332743

Epoch: 73| Step: 0
Training loss: 1.9233310222625732
Validation loss: 2.0249584217866263

Epoch: 5| Step: 1
Training loss: 2.481616258621216
Validation loss: 2.0447469701369605

Epoch: 5| Step: 2
Training loss: 1.8410189151763916
Validation loss: 2.0581905096769333

Epoch: 5| Step: 3
Training loss: 2.4749197959899902
Validation loss: 2.087908690174421

Epoch: 5| Step: 4
Training loss: 2.472832202911377
Validation loss: 2.1255403806765876

Epoch: 5| Step: 5
Training loss: 2.3410913944244385
Validation loss: 2.122677986820539

Epoch: 5| Step: 6
Training loss: 2.6002070903778076
Validation loss: 2.092881699403127

Epoch: 5| Step: 7
Training loss: 2.298360824584961
Validation loss: 2.0400108645359674

Epoch: 5| Step: 8
Training loss: 1.873852014541626
Validation loss: 2.0262231727441153

Epoch: 5| Step: 9
Training loss: 2.430051326751709
Validation loss: 2.020302414894104

Epoch: 5| Step: 10
Training loss: 2.261018991470337
Validation loss: 2.019557590285937

Epoch: 5| Step: 11
Training loss: 1.697304606437683
Validation loss: 2.0350998590389886

Epoch: 74| Step: 0
Training loss: 2.4375147819519043
Validation loss: 2.038478290041288

Epoch: 5| Step: 1
Training loss: 2.266788959503174
Validation loss: 2.043346956372261

Epoch: 5| Step: 2
Training loss: 2.1300270557403564
Validation loss: 2.044818306962649

Epoch: 5| Step: 3
Training loss: 2.3566932678222656
Validation loss: 2.045518085360527

Epoch: 5| Step: 4
Training loss: 1.9072678089141846
Validation loss: 2.0545484572649

Epoch: 5| Step: 5
Training loss: 1.9539382457733154
Validation loss: 2.050450180967649

Epoch: 5| Step: 6
Training loss: 2.7112691402435303
Validation loss: 2.0514796872933707

Epoch: 5| Step: 7
Training loss: 2.549034833908081
Validation loss: 2.0538496722777686

Epoch: 5| Step: 8
Training loss: 2.093235731124878
Validation loss: 2.050413966178894

Epoch: 5| Step: 9
Training loss: 2.4209108352661133
Validation loss: 2.0473132332166037

Epoch: 5| Step: 10
Training loss: 1.759509801864624
Validation loss: 2.045410151282946

Epoch: 5| Step: 11
Training loss: 2.2436985969543457
Validation loss: 2.04386705160141

Epoch: 75| Step: 0
Training loss: 2.40040922164917
Validation loss: 2.046530286471049

Epoch: 5| Step: 1
Training loss: 2.113579511642456
Validation loss: 2.0414419372876487

Epoch: 5| Step: 2
Training loss: 2.4790587425231934
Validation loss: 2.0425619880358377

Epoch: 5| Step: 3
Training loss: 2.5143468379974365
Validation loss: 2.039965867996216

Epoch: 5| Step: 4
Training loss: 2.251878261566162
Validation loss: 2.0385555624961853

Epoch: 5| Step: 5
Training loss: 2.201322317123413
Validation loss: 2.0449156860510507

Epoch: 5| Step: 6
Training loss: 1.6990835666656494
Validation loss: 2.0344546337922416

Epoch: 5| Step: 7
Training loss: 2.5433261394500732
Validation loss: 2.037375489870707

Epoch: 5| Step: 8
Training loss: 2.2123544216156006
Validation loss: 2.035767371455828

Epoch: 5| Step: 9
Training loss: 1.9888923168182373
Validation loss: 2.0347736229499183

Epoch: 5| Step: 10
Training loss: 1.8483340740203857
Validation loss: 2.034389704465866

Epoch: 5| Step: 11
Training loss: 2.793442487716675
Validation loss: 2.01918696363767

Epoch: 76| Step: 0
Training loss: 1.7864882946014404
Validation loss: 2.0278041611115136

Epoch: 5| Step: 1
Training loss: 2.546670913696289
Validation loss: 2.0329340746005378

Epoch: 5| Step: 2
Training loss: 2.308985471725464
Validation loss: 2.03354379038016

Epoch: 5| Step: 3
Training loss: 1.8778693675994873
Validation loss: 2.032631576061249

Epoch: 5| Step: 4
Training loss: 2.4893240928649902
Validation loss: 2.029349530736605

Epoch: 5| Step: 5
Training loss: 2.03037166595459
Validation loss: 2.0269777327775955

Epoch: 5| Step: 6
Training loss: 1.7510316371917725
Validation loss: 2.0338128904501596

Epoch: 5| Step: 7
Training loss: 2.4370744228363037
Validation loss: 2.0329826225837073

Epoch: 5| Step: 8
Training loss: 2.4549331665039062
Validation loss: 2.031506136059761

Epoch: 5| Step: 9
Training loss: 2.3795204162597656
Validation loss: 2.0341640263795853

Epoch: 5| Step: 10
Training loss: 2.3357317447662354
Validation loss: 2.0233640323082605

Epoch: 5| Step: 11
Training loss: 1.9036543369293213
Validation loss: 2.024199669559797

Epoch: 77| Step: 0
Training loss: 2.21598219871521
Validation loss: 2.0200752367575965

Epoch: 5| Step: 1
Training loss: 2.0955898761749268
Validation loss: 2.0199269453684487

Epoch: 5| Step: 2
Training loss: 1.8342750072479248
Validation loss: 2.024441753824552

Epoch: 5| Step: 3
Training loss: 1.983781099319458
Validation loss: 2.026673619945844

Epoch: 5| Step: 4
Training loss: 2.3023793697357178
Validation loss: 2.023076315720876

Epoch: 5| Step: 5
Training loss: 1.946630835533142
Validation loss: 2.024943391482035

Epoch: 5| Step: 6
Training loss: 2.462179183959961
Validation loss: 2.018735349178314

Epoch: 5| Step: 7
Training loss: 1.9848254919052124
Validation loss: 2.025342514117559

Epoch: 5| Step: 8
Training loss: 2.3688199520111084
Validation loss: 2.0265757540861764

Epoch: 5| Step: 9
Training loss: 2.5564773082733154
Validation loss: 2.0206051568190255

Epoch: 5| Step: 10
Training loss: 2.373342514038086
Validation loss: 2.0178135881821313

Epoch: 5| Step: 11
Training loss: 2.2349743843078613
Validation loss: 2.020887722571691

Epoch: 78| Step: 0
Training loss: 2.2900004386901855
Validation loss: 2.0233039458592734

Epoch: 5| Step: 1
Training loss: 2.333932638168335
Validation loss: 2.0289849241574607

Epoch: 5| Step: 2
Training loss: 1.9841196537017822
Validation loss: 2.0346174240112305

Epoch: 5| Step: 3
Training loss: 2.3623485565185547
Validation loss: 2.0435754656791687

Epoch: 5| Step: 4
Training loss: 1.6921281814575195
Validation loss: 2.050234024723371

Epoch: 5| Step: 5
Training loss: 1.8912086486816406
Validation loss: 2.0519101172685623

Epoch: 5| Step: 6
Training loss: 2.210172176361084
Validation loss: 2.056742856899897

Epoch: 5| Step: 7
Training loss: 2.2863070964813232
Validation loss: 2.0513010124365487

Epoch: 5| Step: 8
Training loss: 2.367290735244751
Validation loss: 2.0376501927773156

Epoch: 5| Step: 9
Training loss: 2.427515745162964
Validation loss: 2.0483085811138153

Epoch: 5| Step: 10
Training loss: 2.3412163257598877
Validation loss: 2.02288327117761

Epoch: 5| Step: 11
Training loss: 1.6552609205245972
Validation loss: 2.01787668466568

Epoch: 79| Step: 0
Training loss: 2.3696389198303223
Validation loss: 2.0221858421961465

Epoch: 5| Step: 1
Training loss: 2.0245718955993652
Validation loss: 2.028494114677111

Epoch: 5| Step: 2
Training loss: 1.6218856573104858
Validation loss: 2.034006421764692

Epoch: 5| Step: 3
Training loss: 2.3740155696868896
Validation loss: 2.0399175882339478

Epoch: 5| Step: 4
Training loss: 1.8874292373657227
Validation loss: 2.04895743727684

Epoch: 5| Step: 5
Training loss: 2.522143840789795
Validation loss: 2.0457447667916617

Epoch: 5| Step: 6
Training loss: 2.0181257724761963
Validation loss: 2.050505052010218

Epoch: 5| Step: 7
Training loss: 2.029125928878784
Validation loss: 2.055374657114347

Epoch: 5| Step: 8
Training loss: 3.051387071609497
Validation loss: 2.0559232781330743

Epoch: 5| Step: 9
Training loss: 2.237802028656006
Validation loss: 2.0538491110006967

Epoch: 5| Step: 10
Training loss: 2.350790500640869
Validation loss: 2.047789911429087

Epoch: 5| Step: 11
Training loss: 2.225642442703247
Validation loss: 2.0372342417637506

Epoch: 80| Step: 0
Training loss: 2.537447929382324
Validation loss: 2.031891097625097

Epoch: 5| Step: 1
Training loss: 1.9899654388427734
Validation loss: 2.0294156670570374

Epoch: 5| Step: 2
Training loss: 2.4486050605773926
Validation loss: 2.033606747786204

Epoch: 5| Step: 3
Training loss: 2.709009885787964
Validation loss: 2.0246730695168176

Epoch: 5| Step: 4
Training loss: 1.3791143894195557
Validation loss: 2.0191596001386642

Epoch: 5| Step: 5
Training loss: 2.215700149536133
Validation loss: 2.0172966172297797

Epoch: 5| Step: 6
Training loss: 1.9253132343292236
Validation loss: 2.01187693576018

Epoch: 5| Step: 7
Training loss: 2.548685312271118
Validation loss: 2.011620670557022

Epoch: 5| Step: 8
Training loss: 1.7339913845062256
Validation loss: 2.009955475727717

Epoch: 5| Step: 9
Training loss: 2.3896498680114746
Validation loss: 2.015764832496643

Epoch: 5| Step: 10
Training loss: 2.006352663040161
Validation loss: 2.0247483452161155

Epoch: 5| Step: 11
Training loss: 2.615016460418701
Validation loss: 2.0387089798847833

Epoch: 81| Step: 0
Training loss: 1.6830604076385498
Validation loss: 2.0422560473283133

Epoch: 5| Step: 1
Training loss: 2.523547410964966
Validation loss: 2.0563694834709167

Epoch: 5| Step: 2
Training loss: 2.331023931503296
Validation loss: 2.046652336915334

Epoch: 5| Step: 3
Training loss: 2.4639344215393066
Validation loss: 2.046601583560308

Epoch: 5| Step: 4
Training loss: 2.27752947807312
Validation loss: 2.0383810798327127

Epoch: 5| Step: 5
Training loss: 1.989999771118164
Validation loss: 2.0352892031272254

Epoch: 5| Step: 6
Training loss: 2.5399703979492188
Validation loss: 2.0270141065120697

Epoch: 5| Step: 7
Training loss: 2.360502243041992
Validation loss: 2.01354489227136

Epoch: 5| Step: 8
Training loss: 2.0629420280456543
Validation loss: 2.007959246635437

Epoch: 5| Step: 9
Training loss: 1.9504715204238892
Validation loss: 2.0040039817492166

Epoch: 5| Step: 10
Training loss: 1.839825987815857
Validation loss: 2.00816248357296

Epoch: 5| Step: 11
Training loss: 2.087862491607666
Validation loss: 2.0102985252936683

Epoch: 82| Step: 0
Training loss: 2.156557559967041
Validation loss: 2.0090008874734244

Epoch: 5| Step: 1
Training loss: 1.853830337524414
Validation loss: 2.006223291158676

Epoch: 5| Step: 2
Training loss: 2.400984764099121
Validation loss: 1.998586744070053

Epoch: 5| Step: 3
Training loss: 2.2003836631774902
Validation loss: 2.004485751191775

Epoch: 5| Step: 4
Training loss: 2.747497081756592
Validation loss: 2.0041384547948837

Epoch: 5| Step: 5
Training loss: 2.243959903717041
Validation loss: 2.0092687606811523

Epoch: 5| Step: 6
Training loss: 2.265442132949829
Validation loss: 2.0074993868668876

Epoch: 5| Step: 7
Training loss: 1.5694241523742676
Validation loss: 2.0050214529037476

Epoch: 5| Step: 8
Training loss: 2.162412643432617
Validation loss: 2.007338513930639

Epoch: 5| Step: 9
Training loss: 1.933580994606018
Validation loss: 2.009763012329737

Epoch: 5| Step: 10
Training loss: 2.236159563064575
Validation loss: 2.0046420445044837

Epoch: 5| Step: 11
Training loss: 2.5223898887634277
Validation loss: 2.0025855352481208

Epoch: 83| Step: 0
Training loss: 1.8307279348373413
Validation loss: 2.012840340534846

Epoch: 5| Step: 1
Training loss: 2.244325876235962
Validation loss: 2.015269935131073

Epoch: 5| Step: 2
Training loss: 2.6752238273620605
Validation loss: 2.0301510840654373

Epoch: 5| Step: 3
Training loss: 2.1533095836639404
Validation loss: 2.022657255331675

Epoch: 5| Step: 4
Training loss: 1.6985639333724976
Validation loss: 2.0221553842226663

Epoch: 5| Step: 5
Training loss: 2.4549100399017334
Validation loss: 2.023750593264898

Epoch: 5| Step: 6
Training loss: 2.1317763328552246
Validation loss: 2.0159091701110206

Epoch: 5| Step: 7
Training loss: 2.4004197120666504
Validation loss: 2.0159599979718528

Epoch: 5| Step: 8
Training loss: 2.071361541748047
Validation loss: 2.0151570985714593

Epoch: 5| Step: 9
Training loss: 1.8819797039031982
Validation loss: 2.016433998942375

Epoch: 5| Step: 10
Training loss: 2.2351999282836914
Validation loss: 2.0074088672796884

Epoch: 5| Step: 11
Training loss: 2.171647548675537
Validation loss: 2.010404720902443

Epoch: 84| Step: 0
Training loss: 1.858742117881775
Validation loss: 2.004531979560852

Epoch: 5| Step: 1
Training loss: 1.9936027526855469
Validation loss: 2.0140189081430435

Epoch: 5| Step: 2
Training loss: 1.5206328630447388
Validation loss: 2.013916085163752

Epoch: 5| Step: 3
Training loss: 2.5711398124694824
Validation loss: 2.016430343190829

Epoch: 5| Step: 4
Training loss: 2.773890972137451
Validation loss: 2.0218996653954187

Epoch: 5| Step: 5
Training loss: 1.7500349283218384
Validation loss: 2.0311226000388465

Epoch: 5| Step: 6
Training loss: 2.558438777923584
Validation loss: 2.025228758653005

Epoch: 5| Step: 7
Training loss: 2.074932336807251
Validation loss: 2.0258463819821677

Epoch: 5| Step: 8
Training loss: 1.6560261249542236
Validation loss: 2.0238535553216934

Epoch: 5| Step: 9
Training loss: 2.541755199432373
Validation loss: 2.024867961804072

Epoch: 5| Step: 10
Training loss: 2.3770523071289062
Validation loss: 2.0101780742406845

Epoch: 5| Step: 11
Training loss: 3.0510125160217285
Validation loss: 2.00959583123525

Epoch: 85| Step: 0
Training loss: 2.363024950027466
Validation loss: 2.0063385566075644

Epoch: 5| Step: 1
Training loss: 2.09993839263916
Validation loss: 2.0086138794819512

Epoch: 5| Step: 2
Training loss: 2.1684787273406982
Validation loss: 2.0079193810621896

Epoch: 5| Step: 3
Training loss: 1.583146333694458
Validation loss: 2.0120137482881546

Epoch: 5| Step: 4
Training loss: 2.094876527786255
Validation loss: 2.0117285400629044

Epoch: 5| Step: 5
Training loss: 2.3255839347839355
Validation loss: 2.024297128121058

Epoch: 5| Step: 6
Training loss: 2.3813986778259277
Validation loss: 2.0231078366438546

Epoch: 5| Step: 7
Training loss: 2.689296245574951
Validation loss: 2.0116777072350183

Epoch: 5| Step: 8
Training loss: 2.1309750080108643
Validation loss: 2.0170410623153052

Epoch: 5| Step: 9
Training loss: 1.568198561668396
Validation loss: 2.0160166372855506

Epoch: 5| Step: 10
Training loss: 2.1046338081359863
Validation loss: 2.0122630894184113

Epoch: 5| Step: 11
Training loss: 2.565913677215576
Validation loss: 1.9998482714096706

Epoch: 86| Step: 0
Training loss: 2.4254469871520996
Validation loss: 2.007008229692777

Epoch: 5| Step: 1
Training loss: 2.170907974243164
Validation loss: 2.011280596256256

Epoch: 5| Step: 2
Training loss: 2.0822246074676514
Validation loss: 2.003069261709849

Epoch: 5| Step: 3
Training loss: 1.677074670791626
Validation loss: 2.0103909373283386

Epoch: 5| Step: 4
Training loss: 2.6756129264831543
Validation loss: 1.9953183978796005

Epoch: 5| Step: 5
Training loss: 2.1354732513427734
Validation loss: 2.0012804865837097

Epoch: 5| Step: 6
Training loss: 1.8742440938949585
Validation loss: 2.004014124472936

Epoch: 5| Step: 7
Training loss: 2.181309700012207
Validation loss: 2.0002140253782272

Epoch: 5| Step: 8
Training loss: 2.4850006103515625
Validation loss: 1.9987509747346242

Epoch: 5| Step: 9
Training loss: 1.690704584121704
Validation loss: 2.0058652808268866

Epoch: 5| Step: 10
Training loss: 2.2295680046081543
Validation loss: 2.0200570871432624

Epoch: 5| Step: 11
Training loss: 3.018275499343872
Validation loss: 2.0260435342788696

Epoch: 87| Step: 0
Training loss: 1.8662006855010986
Validation loss: 2.029345949490865

Epoch: 5| Step: 1
Training loss: 2.115682601928711
Validation loss: 2.022411902745565

Epoch: 5| Step: 2
Training loss: 1.7318782806396484
Validation loss: 2.041169116894404

Epoch: 5| Step: 3
Training loss: 2.017198085784912
Validation loss: 2.051554630200068

Epoch: 5| Step: 4
Training loss: 2.210008382797241
Validation loss: 2.051709617177645

Epoch: 5| Step: 5
Training loss: 2.319650173187256
Validation loss: 2.0621337890625

Epoch: 5| Step: 6
Training loss: 2.427184581756592
Validation loss: 2.0594645490249

Epoch: 5| Step: 7
Training loss: 2.430879592895508
Validation loss: 2.0554996927579245

Epoch: 5| Step: 8
Training loss: 2.58339786529541
Validation loss: 2.030860314766566

Epoch: 5| Step: 9
Training loss: 2.101524829864502
Validation loss: 2.018084312478701

Epoch: 5| Step: 10
Training loss: 2.0752809047698975
Validation loss: 2.006633867820104

Epoch: 5| Step: 11
Training loss: 2.334122657775879
Validation loss: 2.001888250311216

Epoch: 88| Step: 0
Training loss: 2.2877860069274902
Validation loss: 2.01429113248984

Epoch: 5| Step: 1
Training loss: 1.8734833002090454
Validation loss: 2.0224051972230277

Epoch: 5| Step: 2
Training loss: 2.3354477882385254
Validation loss: 2.0284907718499503

Epoch: 5| Step: 3
Training loss: 2.5165350437164307
Validation loss: 2.0287148505449295

Epoch: 5| Step: 4
Training loss: 2.1640617847442627
Validation loss: 2.0325487603743873

Epoch: 5| Step: 5
Training loss: 2.472198724746704
Validation loss: 2.028920362393061

Epoch: 5| Step: 6
Training loss: 1.288927674293518
Validation loss: 2.0332355250914893

Epoch: 5| Step: 7
Training loss: 1.9089380502700806
Validation loss: 2.032595415910085

Epoch: 5| Step: 8
Training loss: 2.313934803009033
Validation loss: 2.0367760161558786

Epoch: 5| Step: 9
Training loss: 2.40360689163208
Validation loss: 2.0333731373151145

Epoch: 5| Step: 10
Training loss: 2.420492172241211
Validation loss: 2.031578173240026

Epoch: 5| Step: 11
Training loss: 2.956547260284424
Validation loss: 2.0300689985354743

Epoch: 89| Step: 0
Training loss: 2.2411911487579346
Validation loss: 2.031534572442373

Epoch: 5| Step: 1
Training loss: 2.3988595008850098
Validation loss: 2.0249420007069907

Epoch: 5| Step: 2
Training loss: 2.0375723838806152
Validation loss: 2.0129786332448325

Epoch: 5| Step: 3
Training loss: 2.1150240898132324
Validation loss: 2.008917599916458

Epoch: 5| Step: 4
Training loss: 2.0060551166534424
Validation loss: 2.0073708345492682

Epoch: 5| Step: 5
Training loss: 2.1819939613342285
Validation loss: 2.0011908064285913

Epoch: 5| Step: 6
Training loss: 1.8048919439315796
Validation loss: 2.00196901957194

Epoch: 5| Step: 7
Training loss: 1.6095987558364868
Validation loss: 2.005716308951378

Epoch: 5| Step: 8
Training loss: 2.2689433097839355
Validation loss: 2.0160435835520425

Epoch: 5| Step: 9
Training loss: 2.431893825531006
Validation loss: 2.010371928413709

Epoch: 5| Step: 10
Training loss: 2.6029298305511475
Validation loss: 2.0346225202083588

Epoch: 5| Step: 11
Training loss: 2.5234055519104004
Validation loss: 2.028736636042595

Epoch: 90| Step: 0
Training loss: 2.014474391937256
Validation loss: 2.0282996048529944

Epoch: 5| Step: 1
Training loss: 2.6646969318389893
Validation loss: 2.01498381793499

Epoch: 5| Step: 2
Training loss: 1.732175588607788
Validation loss: 2.0164443105459213

Epoch: 5| Step: 3
Training loss: 2.1763997077941895
Validation loss: 2.014311263958613

Epoch: 5| Step: 4
Training loss: 2.1746573448181152
Validation loss: 2.0070664137601852

Epoch: 5| Step: 5
Training loss: 2.3162150382995605
Validation loss: 2.0019338776667914

Epoch: 5| Step: 6
Training loss: 2.128835678100586
Validation loss: 2.0082517911990485

Epoch: 5| Step: 7
Training loss: 2.1403908729553223
Validation loss: 2.0116263926029205

Epoch: 5| Step: 8
Training loss: 2.128779649734497
Validation loss: 2.007912923892339

Epoch: 5| Step: 9
Training loss: 1.889195203781128
Validation loss: 2.0019352038701377

Epoch: 5| Step: 10
Training loss: 1.988924264907837
Validation loss: 2.0104635457197824

Epoch: 5| Step: 11
Training loss: 2.9859166145324707
Validation loss: 2.007338066895803

Epoch: 91| Step: 0
Training loss: 1.6059629917144775
Validation loss: 2.0006508777538934

Epoch: 5| Step: 1
Training loss: 2.1036579608917236
Validation loss: 2.0020683904488883

Epoch: 5| Step: 2
Training loss: 1.955344796180725
Validation loss: 2.0019953896601996

Epoch: 5| Step: 3
Training loss: 2.0252292156219482
Validation loss: 2.0041492333014808

Epoch: 5| Step: 4
Training loss: 2.5240657329559326
Validation loss: 2.0134731183449426

Epoch: 5| Step: 5
Training loss: 2.3607704639434814
Validation loss: 2.0056562622388205

Epoch: 5| Step: 6
Training loss: 2.081450939178467
Validation loss: 2.0213828484217324

Epoch: 5| Step: 7
Training loss: 2.600013256072998
Validation loss: 2.020921135942141

Epoch: 5| Step: 8
Training loss: 2.0153019428253174
Validation loss: 2.02242482205232

Epoch: 5| Step: 9
Training loss: 1.7343984842300415
Validation loss: 2.011566792925199

Epoch: 5| Step: 10
Training loss: 2.6065561771392822
Validation loss: 2.004190300901731

Epoch: 5| Step: 11
Training loss: 2.194916248321533
Validation loss: 2.007901057600975

Epoch: 92| Step: 0
Training loss: 2.54028582572937
Validation loss: 2.0145240873098373

Epoch: 5| Step: 1
Training loss: 2.4788942337036133
Validation loss: 2.0098477800687156

Epoch: 5| Step: 2
Training loss: 2.374525547027588
Validation loss: 2.027325913310051

Epoch: 5| Step: 3
Training loss: 2.172072172164917
Validation loss: 2.014787957072258

Epoch: 5| Step: 4
Training loss: 2.495680332183838
Validation loss: 2.0029046138127646

Epoch: 5| Step: 5
Training loss: 1.7029409408569336
Validation loss: 2.007617324590683

Epoch: 5| Step: 6
Training loss: 1.6911938190460205
Validation loss: 2.0141881654659906

Epoch: 5| Step: 7
Training loss: 1.7297518253326416
Validation loss: 2.0096268157164254

Epoch: 5| Step: 8
Training loss: 1.9879001379013062
Validation loss: 2.0174337029457092

Epoch: 5| Step: 9
Training loss: 1.6406707763671875
Validation loss: 2.020827775200208

Epoch: 5| Step: 10
Training loss: 2.465858221054077
Validation loss: 2.0285784949858985

Epoch: 5| Step: 11
Training loss: 2.991389751434326
Validation loss: 2.036770313978195

Epoch: 93| Step: 0
Training loss: 2.519636631011963
Validation loss: 2.0313195089499154

Epoch: 5| Step: 1
Training loss: 2.8942723274230957
Validation loss: 2.032676190137863

Epoch: 5| Step: 2
Training loss: 2.105349540710449
Validation loss: 2.0345075726509094

Epoch: 5| Step: 3
Training loss: 1.7505115270614624
Validation loss: 2.039314478635788

Epoch: 5| Step: 4
Training loss: 1.292939305305481
Validation loss: 2.042501543958982

Epoch: 5| Step: 5
Training loss: 1.64145827293396
Validation loss: 2.0351067930459976

Epoch: 5| Step: 6
Training loss: 2.3653054237365723
Validation loss: 2.0309028377135596

Epoch: 5| Step: 7
Training loss: 2.510244607925415
Validation loss: 2.024657264351845

Epoch: 5| Step: 8
Training loss: 2.266054630279541
Validation loss: 2.019732356071472

Epoch: 5| Step: 9
Training loss: 2.258985757827759
Validation loss: 2.01216288904349

Epoch: 5| Step: 10
Training loss: 2.0044302940368652
Validation loss: 2.007218380769094

Epoch: 5| Step: 11
Training loss: 2.221223831176758
Validation loss: 2.0070007791121802

Epoch: 94| Step: 0
Training loss: 1.996141791343689
Validation loss: 1.9983980655670166

Epoch: 5| Step: 1
Training loss: 2.5584380626678467
Validation loss: 2.007528985540072

Epoch: 5| Step: 2
Training loss: 1.9587242603302002
Validation loss: 2.014041225115458

Epoch: 5| Step: 3
Training loss: 2.299177885055542
Validation loss: 2.016313821077347

Epoch: 5| Step: 4
Training loss: 2.110652446746826
Validation loss: 2.014644136031469

Epoch: 5| Step: 5
Training loss: 1.7028381824493408
Validation loss: 2.011874253551165

Epoch: 5| Step: 6
Training loss: 2.118220090866089
Validation loss: 2.015708158413569

Epoch: 5| Step: 7
Training loss: 2.0254929065704346
Validation loss: 2.015130107601484

Epoch: 5| Step: 8
Training loss: 2.079514980316162
Validation loss: 2.015341411034266

Epoch: 5| Step: 9
Training loss: 2.4993839263916016
Validation loss: 2.026370386282603

Epoch: 5| Step: 10
Training loss: 2.1861701011657715
Validation loss: 2.0207254886627197

Epoch: 5| Step: 11
Training loss: 1.806985855102539
Validation loss: 2.0188050866127014

Epoch: 95| Step: 0
Training loss: 1.8832956552505493
Validation loss: 2.0109885334968567

Epoch: 5| Step: 1
Training loss: 2.6454951763153076
Validation loss: 2.0098639676968255

Epoch: 5| Step: 2
Training loss: 1.9374573230743408
Validation loss: 2.014423817396164

Epoch: 5| Step: 3
Training loss: 2.007991313934326
Validation loss: 2.0018337021271386

Epoch: 5| Step: 4
Training loss: 1.8115975856781006
Validation loss: 2.0106944292783737

Epoch: 5| Step: 5
Training loss: 1.7856042385101318
Validation loss: 2.0039028922716775

Epoch: 5| Step: 6
Training loss: 2.375962495803833
Validation loss: 2.006483023365339

Epoch: 5| Step: 7
Training loss: 2.129146099090576
Validation loss: 2.021668861309687

Epoch: 5| Step: 8
Training loss: 2.3758435249328613
Validation loss: 2.016773665944735

Epoch: 5| Step: 9
Training loss: 2.1467976570129395
Validation loss: 2.011671712001165

Epoch: 5| Step: 10
Training loss: 2.5046579837799072
Validation loss: 2.0139048794905343

Epoch: 5| Step: 11
Training loss: 1.5420773029327393
Validation loss: 2.005824198325475

Epoch: 96| Step: 0
Training loss: 2.5520713329315186
Validation loss: 1.9981279969215393

Epoch: 5| Step: 1
Training loss: 2.4996488094329834
Validation loss: 1.9983726342519124

Epoch: 5| Step: 2
Training loss: 2.2808268070220947
Validation loss: 1.9898105164368947

Epoch: 5| Step: 3
Training loss: 2.0678226947784424
Validation loss: 2.0023955553770065

Epoch: 5| Step: 4
Training loss: 2.4140772819519043
Validation loss: 2.012162854274114

Epoch: 5| Step: 5
Training loss: 1.7118282318115234
Validation loss: 2.0009746154149375

Epoch: 5| Step: 6
Training loss: 1.941918134689331
Validation loss: 2.0042760968208313

Epoch: 5| Step: 7
Training loss: 2.285457134246826
Validation loss: 2.0133372992277145

Epoch: 5| Step: 8
Training loss: 1.866398572921753
Validation loss: 2.0128470013538995

Epoch: 5| Step: 9
Training loss: 1.8046611547470093
Validation loss: 2.0094610353310904

Epoch: 5| Step: 10
Training loss: 2.097538471221924
Validation loss: 2.022291377186775

Epoch: 5| Step: 11
Training loss: 2.007840156555176
Validation loss: 2.0182794531186423

Epoch: 97| Step: 0
Training loss: 2.1592135429382324
Validation loss: 2.0173303137222924

Epoch: 5| Step: 1
Training loss: 2.0005180835723877
Validation loss: 2.0194963812828064

Epoch: 5| Step: 2
Training loss: 1.4730331897735596
Validation loss: 2.0223954816659293

Epoch: 5| Step: 3
Training loss: 2.04099702835083
Validation loss: 2.0385262072086334

Epoch: 5| Step: 4
Training loss: 2.6383378505706787
Validation loss: 2.0285352021455765

Epoch: 5| Step: 5
Training loss: 2.3447468280792236
Validation loss: 2.0374423364798226

Epoch: 5| Step: 6
Training loss: 2.4199228286743164
Validation loss: 2.031099572777748

Epoch: 5| Step: 7
Training loss: 1.950324296951294
Validation loss: 2.0210173527399697

Epoch: 5| Step: 8
Training loss: 2.1515040397644043
Validation loss: 2.00645782550176

Epoch: 5| Step: 9
Training loss: 1.9549366235733032
Validation loss: 2.0007128169139228

Epoch: 5| Step: 10
Training loss: 2.51094388961792
Validation loss: 2.0030145992835364

Epoch: 5| Step: 11
Training loss: 1.8707849979400635
Validation loss: 2.0075884759426117

Epoch: 98| Step: 0
Training loss: 2.12380313873291
Validation loss: 2.0010535369316735

Epoch: 5| Step: 1
Training loss: 2.101128101348877
Validation loss: 2.0042022665341697

Epoch: 5| Step: 2
Training loss: 2.288421154022217
Validation loss: 2.013098105788231

Epoch: 5| Step: 3
Training loss: 2.250487804412842
Validation loss: 2.012263278166453

Epoch: 5| Step: 4
Training loss: 1.9862596988677979
Validation loss: 2.013403072953224

Epoch: 5| Step: 5
Training loss: 1.8360702991485596
Validation loss: 2.023045008381208

Epoch: 5| Step: 6
Training loss: 2.397839307785034
Validation loss: 2.0177228351434073

Epoch: 5| Step: 7
Training loss: 2.280383586883545
Validation loss: 2.0245221058527627

Epoch: 5| Step: 8
Training loss: 2.2372610569000244
Validation loss: 2.018643041451772

Epoch: 5| Step: 9
Training loss: 1.7556889057159424
Validation loss: 2.0171732306480408

Epoch: 5| Step: 10
Training loss: 2.147665500640869
Validation loss: 2.0125909646352134

Epoch: 5| Step: 11
Training loss: 2.526503562927246
Validation loss: 2.0011052886644998

Epoch: 99| Step: 0
Training loss: 2.4547595977783203
Validation loss: 1.998489499092102

Epoch: 5| Step: 1
Training loss: 2.327044725418091
Validation loss: 1.9984262933333714

Epoch: 5| Step: 2
Training loss: 2.2318596839904785
Validation loss: 2.007081458965937

Epoch: 5| Step: 3
Training loss: 2.1206588745117188
Validation loss: 1.9998379151026409

Epoch: 5| Step: 4
Training loss: 2.2732439041137695
Validation loss: 2.0075005193551383

Epoch: 5| Step: 5
Training loss: 2.2952914237976074
Validation loss: 2.0043541391690574

Epoch: 5| Step: 6
Training loss: 2.0512566566467285
Validation loss: 2.0056534012158713

Epoch: 5| Step: 7
Training loss: 1.8721681833267212
Validation loss: 2.0070162266492844

Epoch: 5| Step: 8
Training loss: 2.0821573734283447
Validation loss: 2.011844346920649

Epoch: 5| Step: 9
Training loss: 1.8869507312774658
Validation loss: 1.9990260998408

Epoch: 5| Step: 10
Training loss: 1.9320024251937866
Validation loss: 2.0015326937039695

Epoch: 5| Step: 11
Training loss: 2.51425838470459
Validation loss: 1.996289998292923

Epoch: 100| Step: 0
Training loss: 1.6947799921035767
Validation loss: 1.9983792752027512

Epoch: 5| Step: 1
Training loss: 2.0810046195983887
Validation loss: 2.0149309635162354

Epoch: 5| Step: 2
Training loss: 1.8523435592651367
Validation loss: 2.0070330699284873

Epoch: 5| Step: 3
Training loss: 2.190068483352661
Validation loss: 2.0223097254832587

Epoch: 5| Step: 4
Training loss: 1.4112439155578613
Validation loss: 2.0194361160198846

Epoch: 5| Step: 5
Training loss: 2.586559772491455
Validation loss: 2.0313568313916526

Epoch: 5| Step: 6
Training loss: 2.3199782371520996
Validation loss: 2.0412173718214035

Epoch: 5| Step: 7
Training loss: 1.9824126958847046
Validation loss: 2.022612084945043

Epoch: 5| Step: 8
Training loss: 2.529876232147217
Validation loss: 2.0330064247051873

Epoch: 5| Step: 9
Training loss: 2.0313446521759033
Validation loss: 2.0298102597395578

Epoch: 5| Step: 10
Training loss: 2.50490403175354
Validation loss: 2.02071712911129

Epoch: 5| Step: 11
Training loss: 3.3910584449768066
Validation loss: 2.0210244556268058

Epoch: 101| Step: 0
Training loss: 2.1687216758728027
Validation loss: 2.0071285416682563

Epoch: 5| Step: 1
Training loss: 1.8705768585205078
Validation loss: 2.0022218078374863

Epoch: 5| Step: 2
Training loss: 2.4803051948547363
Validation loss: 2.005750755469004

Epoch: 5| Step: 3
Training loss: 1.7904994487762451
Validation loss: 2.0034017264842987

Epoch: 5| Step: 4
Training loss: 2.340209484100342
Validation loss: 2.002313017845154

Epoch: 5| Step: 5
Training loss: 1.9718444347381592
Validation loss: 1.998876377940178

Epoch: 5| Step: 6
Training loss: 2.526489734649658
Validation loss: 1.994139591852824

Epoch: 5| Step: 7
Training loss: 1.637345552444458
Validation loss: 1.9976357569297154

Epoch: 5| Step: 8
Training loss: 2.3224234580993652
Validation loss: 2.002445528904597

Epoch: 5| Step: 9
Training loss: 2.4016737937927246
Validation loss: 2.0073026021321616

Epoch: 5| Step: 10
Training loss: 1.7700687646865845
Validation loss: 1.9997925857702892

Epoch: 5| Step: 11
Training loss: 2.7486658096313477
Validation loss: 2.0167541404565177

Epoch: 102| Step: 0
Training loss: 2.5809831619262695
Validation loss: 2.015061135093371

Epoch: 5| Step: 1
Training loss: 2.368861198425293
Validation loss: 2.01146832605203

Epoch: 5| Step: 2
Training loss: 1.9362194538116455
Validation loss: 2.0143339236577353

Epoch: 5| Step: 3
Training loss: 2.283510684967041
Validation loss: 2.0077335238456726

Epoch: 5| Step: 4
Training loss: 2.150193691253662
Validation loss: 1.993448128302892

Epoch: 5| Step: 5
Training loss: 2.344151735305786
Validation loss: 2.011818448702494

Epoch: 5| Step: 6
Training loss: 2.034487009048462
Validation loss: 2.0089928756157556

Epoch: 5| Step: 7
Training loss: 2.2199552059173584
Validation loss: 2.004659732182821

Epoch: 5| Step: 8
Training loss: 1.6028201580047607
Validation loss: 2.0071053753296533

Epoch: 5| Step: 9
Training loss: 2.309080123901367
Validation loss: 1.9979128589232762

Epoch: 5| Step: 10
Training loss: 1.6073745489120483
Validation loss: 2.002189209063848

Epoch: 5| Step: 11
Training loss: 1.580277442932129
Validation loss: 2.0040713797012963

Epoch: 103| Step: 0
Training loss: 2.059495687484741
Validation loss: 2.0082636376221976

Epoch: 5| Step: 1
Training loss: 2.4228267669677734
Validation loss: 2.017338593800863

Epoch: 5| Step: 2
Training loss: 1.5692671537399292
Validation loss: 2.00424025952816

Epoch: 5| Step: 3
Training loss: 2.1287689208984375
Validation loss: 2.0092337131500244

Epoch: 5| Step: 4
Training loss: 2.521495819091797
Validation loss: 2.0217260817686715

Epoch: 5| Step: 5
Training loss: 2.082723617553711
Validation loss: 2.0229751567045846

Epoch: 5| Step: 6
Training loss: 1.8593482971191406
Validation loss: 2.0145813326040902

Epoch: 5| Step: 7
Training loss: 2.0295817852020264
Validation loss: 2.013647715250651

Epoch: 5| Step: 8
Training loss: 1.7541507482528687
Validation loss: 2.0009532322486243

Epoch: 5| Step: 9
Training loss: 2.2377359867095947
Validation loss: 2.0069235612948737

Epoch: 5| Step: 10
Training loss: 2.2986819744110107
Validation loss: 1.9932190080483754

Epoch: 5| Step: 11
Training loss: 3.934469223022461
Validation loss: 1.9980348298947017

Epoch: 104| Step: 0
Training loss: 2.027832269668579
Validation loss: 1.9930881311496098

Epoch: 5| Step: 1
Training loss: 2.3410487174987793
Validation loss: 2.006106734275818

Epoch: 5| Step: 2
Training loss: 1.7303721904754639
Validation loss: 2.00706547498703

Epoch: 5| Step: 3
Training loss: 1.923027753829956
Validation loss: 2.011567304531733

Epoch: 5| Step: 4
Training loss: 2.296217918395996
Validation loss: 2.0146217048168182

Epoch: 5| Step: 5
Training loss: 1.9464572668075562
Validation loss: 2.013244698445002

Epoch: 5| Step: 6
Training loss: 2.001721143722534
Validation loss: 2.0078789492448172

Epoch: 5| Step: 7
Training loss: 2.084496021270752
Validation loss: 1.9982168426116307

Epoch: 5| Step: 8
Training loss: 2.2000279426574707
Validation loss: 1.9955973774194717

Epoch: 5| Step: 9
Training loss: 2.549124240875244
Validation loss: 1.9945220400889714

Epoch: 5| Step: 10
Training loss: 2.5127837657928467
Validation loss: 1.9949180036783218

Epoch: 5| Step: 11
Training loss: 1.6398568153381348
Validation loss: 1.9983152846495311

Epoch: 105| Step: 0
Training loss: 2.214555025100708
Validation loss: 2.010954966147741

Epoch: 5| Step: 1
Training loss: 2.0694222450256348
Validation loss: 2.026697337627411

Epoch: 5| Step: 2
Training loss: 1.9541254043579102
Validation loss: 2.050536041458448

Epoch: 5| Step: 3
Training loss: 2.889070749282837
Validation loss: 2.073792482415835

Epoch: 5| Step: 4
Training loss: 2.915670156478882
Validation loss: 2.082788422703743

Epoch: 5| Step: 5
Training loss: 2.6070632934570312
Validation loss: 2.0869195560614267

Epoch: 5| Step: 6
Training loss: 2.23989200592041
Validation loss: 2.073280264933904

Epoch: 5| Step: 7
Training loss: 1.700948715209961
Validation loss: 2.048390398422877

Epoch: 5| Step: 8
Training loss: 1.59085214138031
Validation loss: 2.020872707168261

Epoch: 5| Step: 9
Training loss: 1.623572587966919
Validation loss: 2.0021410832802453

Epoch: 5| Step: 10
Training loss: 2.040381908416748
Validation loss: 1.9989760021368663

Epoch: 5| Step: 11
Training loss: 2.619598388671875
Validation loss: 1.9980679998795192

Epoch: 106| Step: 0
Training loss: 1.9600965976715088
Validation loss: 2.003801941871643

Epoch: 5| Step: 1
Training loss: 2.4386820793151855
Validation loss: 2.0189719249804816

Epoch: 5| Step: 2
Training loss: 2.0480659008026123
Validation loss: 2.0261336316665015

Epoch: 5| Step: 3
Training loss: 2.1010539531707764
Validation loss: 2.0209565460681915

Epoch: 5| Step: 4
Training loss: 2.141092538833618
Validation loss: 2.017216900984446

Epoch: 5| Step: 5
Training loss: 1.94972825050354
Validation loss: 2.019672537843386

Epoch: 5| Step: 6
Training loss: 2.2083356380462646
Validation loss: 2.017697274684906

Epoch: 5| Step: 7
Training loss: 1.9797232151031494
Validation loss: 2.021237164735794

Epoch: 5| Step: 8
Training loss: 2.243788003921509
Validation loss: 2.0186872283617654

Epoch: 5| Step: 9
Training loss: 2.1541805267333984
Validation loss: 2.0229470829168954

Epoch: 5| Step: 10
Training loss: 2.440094232559204
Validation loss: 2.016551454861959

Epoch: 5| Step: 11
Training loss: 2.7328476905822754
Validation loss: 2.015621155500412

Epoch: 107| Step: 0
Training loss: 2.0401313304901123
Validation loss: 2.0134194046258926

Epoch: 5| Step: 1
Training loss: 2.4627175331115723
Validation loss: 2.0077016999324164

Epoch: 5| Step: 2
Training loss: 2.0361313819885254
Validation loss: 2.007839580376943

Epoch: 5| Step: 3
Training loss: 2.2026047706604004
Validation loss: 2.007132033507029

Epoch: 5| Step: 4
Training loss: 2.388664484024048
Validation loss: 1.9993767788012822

Epoch: 5| Step: 5
Training loss: 1.9279088973999023
Validation loss: 2.007613644003868

Epoch: 5| Step: 6
Training loss: 2.2467501163482666
Validation loss: 2.0082486867904663

Epoch: 5| Step: 7
Training loss: 1.755834937095642
Validation loss: 2.008354182044665

Epoch: 5| Step: 8
Training loss: 1.9192613363265991
Validation loss: 2.0224827378988266

Epoch: 5| Step: 9
Training loss: 2.1337547302246094
Validation loss: 2.014927347501119

Epoch: 5| Step: 10
Training loss: 2.4756078720092773
Validation loss: 2.0237939059734344

Epoch: 5| Step: 11
Training loss: 2.058215618133545
Validation loss: 2.0301722387472787

Epoch: 108| Step: 0
Training loss: 2.0268843173980713
Validation loss: 2.028460423151652

Epoch: 5| Step: 1
Training loss: 2.732509136199951
Validation loss: 2.0149938563505807

Epoch: 5| Step: 2
Training loss: 2.4476029872894287
Validation loss: 2.011790156364441

Epoch: 5| Step: 3
Training loss: 2.287598133087158
Validation loss: 2.010560249288877

Epoch: 5| Step: 4
Training loss: 2.208472728729248
Validation loss: 2.009284163514773

Epoch: 5| Step: 5
Training loss: 2.5342977046966553
Validation loss: 2.0030935257673264

Epoch: 5| Step: 6
Training loss: 1.5508977174758911
Validation loss: 1.9993202835321426

Epoch: 5| Step: 7
Training loss: 2.054720401763916
Validation loss: 2.0061256140470505

Epoch: 5| Step: 8
Training loss: 2.0865519046783447
Validation loss: 2.007092207670212

Epoch: 5| Step: 9
Training loss: 1.6677579879760742
Validation loss: 2.0132513443628945

Epoch: 5| Step: 10
Training loss: 1.8965120315551758
Validation loss: 2.0115259488423667

Epoch: 5| Step: 11
Training loss: 2.4033043384552
Validation loss: 2.0111892968416214

Epoch: 109| Step: 0
Training loss: 2.190199375152588
Validation loss: 2.0067423035701117

Epoch: 5| Step: 1
Training loss: 2.491427183151245
Validation loss: 2.001796066761017

Epoch: 5| Step: 2
Training loss: 2.533357620239258
Validation loss: 1.9967761486768723

Epoch: 5| Step: 3
Training loss: 2.582770824432373
Validation loss: 2.005345712105433

Epoch: 5| Step: 4
Training loss: 1.9994194507598877
Validation loss: 2.0093947847684226

Epoch: 5| Step: 5
Training loss: 2.2054786682128906
Validation loss: 1.9981069912513096

Epoch: 5| Step: 6
Training loss: 1.556197166442871
Validation loss: 2.0198655823866525

Epoch: 5| Step: 7
Training loss: 1.9402077198028564
Validation loss: 2.0223176032304764

Epoch: 5| Step: 8
Training loss: 1.9209778308868408
Validation loss: 2.031255250175794

Epoch: 5| Step: 9
Training loss: 1.7311338186264038
Validation loss: 2.020795856912931

Epoch: 5| Step: 10
Training loss: 2.243504047393799
Validation loss: 2.0291905999183655

Epoch: 5| Step: 11
Training loss: 1.4072695970535278
Validation loss: 2.0266185899575553

Epoch: 110| Step: 0
Training loss: 2.6744208335876465
Validation loss: 2.022216478983561

Epoch: 5| Step: 1
Training loss: 2.314518690109253
Validation loss: 2.016272912422816

Epoch: 5| Step: 2
Training loss: 2.3703110218048096
Validation loss: 2.0163410107294717

Epoch: 5| Step: 3
Training loss: 1.7401187419891357
Validation loss: 2.0128696858882904

Epoch: 5| Step: 4
Training loss: 2.5254714488983154
Validation loss: 2.010446682572365

Epoch: 5| Step: 5
Training loss: 1.904014229774475
Validation loss: 2.0057819187641144

Epoch: 5| Step: 6
Training loss: 2.093628406524658
Validation loss: 2.010894929369291

Epoch: 5| Step: 7
Training loss: 2.040942668914795
Validation loss: 2.011173968513807

Epoch: 5| Step: 8
Training loss: 2.201998233795166
Validation loss: 2.012683351834615

Epoch: 5| Step: 9
Training loss: 1.580445647239685
Validation loss: 2.0211813102165856

Epoch: 5| Step: 10
Training loss: 1.8917338848114014
Validation loss: 2.007633393009504

Epoch: 5| Step: 11
Training loss: 1.9525057077407837
Validation loss: 2.0106088668107986

Epoch: 111| Step: 0
Training loss: 1.937740683555603
Validation loss: 2.008967583378156

Epoch: 5| Step: 1
Training loss: 2.469254732131958
Validation loss: 2.010257507363955

Epoch: 5| Step: 2
Training loss: 2.1736793518066406
Validation loss: 2.0210733115673065

Epoch: 5| Step: 3
Training loss: 2.1631217002868652
Validation loss: 2.021602675318718

Epoch: 5| Step: 4
Training loss: 2.0491786003112793
Validation loss: 2.024538497130076

Epoch: 5| Step: 5
Training loss: 2.1098618507385254
Validation loss: 2.0287310977776847

Epoch: 5| Step: 6
Training loss: 2.112717390060425
Validation loss: 2.0296569416920343

Epoch: 5| Step: 7
Training loss: 2.1070423126220703
Validation loss: 2.0192039410273233

Epoch: 5| Step: 8
Training loss: 1.8691132068634033
Validation loss: 2.0294431298971176

Epoch: 5| Step: 9
Training loss: 1.8343509435653687
Validation loss: 2.0244362503290176

Epoch: 5| Step: 10
Training loss: 2.197438955307007
Validation loss: 2.0266020099322

Epoch: 5| Step: 11
Training loss: 2.793724775314331
Validation loss: 2.037837644418081

Epoch: 112| Step: 0
Training loss: 2.2585463523864746
Validation loss: 2.037652293841044

Epoch: 5| Step: 1
Training loss: 2.652324914932251
Validation loss: 2.0222892661889396

Epoch: 5| Step: 2
Training loss: 1.9293180704116821
Validation loss: 2.0306779642899833

Epoch: 5| Step: 3
Training loss: 1.99357008934021
Validation loss: 2.0301050196091333

Epoch: 5| Step: 4
Training loss: 2.2577226161956787
Validation loss: 2.030827045440674

Epoch: 5| Step: 5
Training loss: 2.4321625232696533
Validation loss: 2.02004008491834

Epoch: 5| Step: 6
Training loss: 1.8074604272842407
Validation loss: 2.02459454536438

Epoch: 5| Step: 7
Training loss: 1.9356883764266968
Validation loss: 2.03194360435009

Epoch: 5| Step: 8
Training loss: 2.4848194122314453
Validation loss: 2.032830665508906

Epoch: 5| Step: 9
Training loss: 1.566007375717163
Validation loss: 2.0361048181851706

Epoch: 5| Step: 10
Training loss: 1.7195895910263062
Validation loss: 2.0333091219266257

Epoch: 5| Step: 11
Training loss: 2.8512256145477295
Validation loss: 2.0253529846668243

Epoch: 113| Step: 0
Training loss: 1.7064905166625977
Validation loss: 2.014291077852249

Epoch: 5| Step: 1
Training loss: 2.3051187992095947
Validation loss: 2.015982667605082

Epoch: 5| Step: 2
Training loss: 2.562206268310547
Validation loss: 2.0180249214172363

Epoch: 5| Step: 3
Training loss: 2.716566562652588
Validation loss: 2.025410920381546

Epoch: 5| Step: 4
Training loss: 2.0332705974578857
Validation loss: 2.028443897763888

Epoch: 5| Step: 5
Training loss: 2.2045528888702393
Validation loss: 2.024126028021177

Epoch: 5| Step: 6
Training loss: 2.3158915042877197
Validation loss: 2.03366619348526

Epoch: 5| Step: 7
Training loss: 2.2426037788391113
Validation loss: 2.0369282762209573

Epoch: 5| Step: 8
Training loss: 1.876308798789978
Validation loss: 2.0353440394004187

Epoch: 5| Step: 9
Training loss: 1.6843751668930054
Validation loss: 2.040007144212723

Epoch: 5| Step: 10
Training loss: 1.9935510158538818
Validation loss: 2.0363394965728125

Epoch: 5| Step: 11
Training loss: 1.6896716356277466
Validation loss: 2.035934627056122

Epoch: 114| Step: 0
Training loss: 1.9601995944976807
Validation loss: 2.0330672611792884

Epoch: 5| Step: 1
Training loss: 1.8201487064361572
Validation loss: 2.029971261819204

Epoch: 5| Step: 2
Training loss: 2.1795871257781982
Validation loss: 2.0392274111509323

Epoch: 5| Step: 3
Training loss: 1.812978982925415
Validation loss: 2.0317512502272925

Epoch: 5| Step: 4
Training loss: 2.733358144760132
Validation loss: 2.033042773604393

Epoch: 5| Step: 5
Training loss: 1.752448320388794
Validation loss: 2.028463805715243

Epoch: 5| Step: 6
Training loss: 2.326387405395508
Validation loss: 2.0381436745325723

Epoch: 5| Step: 7
Training loss: 1.650194525718689
Validation loss: 2.0257076174020767

Epoch: 5| Step: 8
Training loss: 2.427813768386841
Validation loss: 2.029700666666031

Epoch: 5| Step: 9
Training loss: 2.4260523319244385
Validation loss: 2.0164963056643805

Epoch: 5| Step: 10
Training loss: 2.390610456466675
Validation loss: 2.024945174654325

Epoch: 5| Step: 11
Training loss: 2.6088240146636963
Validation loss: 2.014385754863421

Epoch: 115| Step: 0
Training loss: 2.414844274520874
Validation loss: 2.0224098215500512

Epoch: 5| Step: 1
Training loss: 1.8145723342895508
Validation loss: 2.029165724913279

Epoch: 5| Step: 2
Training loss: 1.8296782970428467
Validation loss: 2.028536041577657

Epoch: 5| Step: 3
Training loss: 2.152733325958252
Validation loss: 2.0328299254179

Epoch: 5| Step: 4
Training loss: 2.13887882232666
Validation loss: 2.03704771399498

Epoch: 5| Step: 5
Training loss: 2.263864517211914
Validation loss: 2.0422186901172004

Epoch: 5| Step: 6
Training loss: 1.641819953918457
Validation loss: 2.038386652866999

Epoch: 5| Step: 7
Training loss: 2.1393041610717773
Validation loss: 2.035143941640854

Epoch: 5| Step: 8
Training loss: 2.3356244564056396
Validation loss: 2.0286307483911514

Epoch: 5| Step: 9
Training loss: 2.5110573768615723
Validation loss: 2.034800425171852

Epoch: 5| Step: 10
Training loss: 2.0110373497009277
Validation loss: 2.031882256269455

Epoch: 5| Step: 11
Training loss: 2.1509742736816406
Validation loss: 2.0317309200763702

Epoch: 116| Step: 0
Training loss: 1.9341471195220947
Validation loss: 2.0337845186392465

Epoch: 5| Step: 1
Training loss: 1.8041603565216064
Validation loss: 2.0418360233306885

Epoch: 5| Step: 2
Training loss: 2.0651984214782715
Validation loss: 2.0333115408817926

Epoch: 5| Step: 3
Training loss: 2.3709969520568848
Validation loss: 2.034414236744245

Epoch: 5| Step: 4
Training loss: 2.0215630531311035
Validation loss: 2.0202022145191827

Epoch: 5| Step: 5
Training loss: 2.178874969482422
Validation loss: 2.0282375514507294

Epoch: 5| Step: 6
Training loss: 2.511035919189453
Validation loss: 2.0217537631591163

Epoch: 5| Step: 7
Training loss: 1.7545671463012695
Validation loss: 2.015621840953827

Epoch: 5| Step: 8
Training loss: 2.6261985301971436
Validation loss: 2.021831676363945

Epoch: 5| Step: 9
Training loss: 1.794873833656311
Validation loss: 2.018219451109568

Epoch: 5| Step: 10
Training loss: 2.100264072418213
Validation loss: 2.0240700443585715

Epoch: 5| Step: 11
Training loss: 2.3431801795959473
Validation loss: 2.0169511089722314

Epoch: 117| Step: 0
Training loss: 1.5492993593215942
Validation loss: 2.0226345558961234

Epoch: 5| Step: 1
Training loss: 2.3997886180877686
Validation loss: 2.0129471023877463

Epoch: 5| Step: 2
Training loss: 2.5648140907287598
Validation loss: 2.0087070365746817

Epoch: 5| Step: 3
Training loss: 2.679068088531494
Validation loss: 2.0053148170312247

Epoch: 5| Step: 4
Training loss: 2.0838208198547363
Validation loss: 2.0062950352827706

Epoch: 5| Step: 5
Training loss: 1.7232859134674072
Validation loss: 2.0093694080909095

Epoch: 5| Step: 6
Training loss: 2.1960535049438477
Validation loss: 2.0060147096713385

Epoch: 5| Step: 7
Training loss: 2.1127495765686035
Validation loss: 2.027340287963549

Epoch: 5| Step: 8
Training loss: 1.8591575622558594
Validation loss: 2.023918946584066

Epoch: 5| Step: 9
Training loss: 1.9271752834320068
Validation loss: 2.0328662445147834

Epoch: 5| Step: 10
Training loss: 1.7622449398040771
Validation loss: 2.03591550886631

Epoch: 5| Step: 11
Training loss: 3.6223020553588867
Validation loss: 2.0237058947483697

Epoch: 118| Step: 0
Training loss: 2.127978801727295
Validation loss: 2.0164014299710593

Epoch: 5| Step: 1
Training loss: 1.7294410467147827
Validation loss: 2.0060193091630936

Epoch: 5| Step: 2
Training loss: 2.099682092666626
Validation loss: 2.018150821328163

Epoch: 5| Step: 3
Training loss: 2.677353620529175
Validation loss: 2.0362744480371475

Epoch: 5| Step: 4
Training loss: 2.2222321033477783
Validation loss: 2.028083781401316

Epoch: 5| Step: 5
Training loss: 2.61468243598938
Validation loss: 2.0326373130083084

Epoch: 5| Step: 6
Training loss: 1.584665060043335
Validation loss: 2.0272495448589325

Epoch: 5| Step: 7
Training loss: 1.945989966392517
Validation loss: 2.0303266694148383

Epoch: 5| Step: 8
Training loss: 2.7409794330596924
Validation loss: 2.0369633436203003

Epoch: 5| Step: 9
Training loss: 2.010110378265381
Validation loss: 2.039414664109548

Epoch: 5| Step: 10
Training loss: 2.053833484649658
Validation loss: 2.0447993675867715

Epoch: 5| Step: 11
Training loss: 2.912154197692871
Validation loss: 2.040318558613459

Epoch: 119| Step: 0
Training loss: 2.058037042617798
Validation loss: 2.040220777193705

Epoch: 5| Step: 1
Training loss: 2.1787056922912598
Validation loss: 2.0424438565969467

Epoch: 5| Step: 2
Training loss: 1.9851499795913696
Validation loss: 2.0346573293209076

Epoch: 5| Step: 3
Training loss: 2.1413040161132812
Validation loss: 2.0315878689289093

Epoch: 5| Step: 4
Training loss: 1.8660314083099365
Validation loss: 2.027269090215365

Epoch: 5| Step: 5
Training loss: 2.302487850189209
Validation loss: 2.029822697242101

Epoch: 5| Step: 6
Training loss: 1.869964838027954
Validation loss: 2.0224439104398093

Epoch: 5| Step: 7
Training loss: 2.4505767822265625
Validation loss: 2.025640601913134

Epoch: 5| Step: 8
Training loss: 2.194423198699951
Validation loss: 2.0222118943929672

Epoch: 5| Step: 9
Training loss: 2.728034496307373
Validation loss: 2.029745245973269

Epoch: 5| Step: 10
Training loss: 2.2009549140930176
Validation loss: 2.02824297050635

Epoch: 5| Step: 11
Training loss: 2.2782628536224365
Validation loss: 2.0233035683631897

Epoch: 120| Step: 0
Training loss: 2.6437606811523438
Validation loss: 2.0195877850055695

Epoch: 5| Step: 1
Training loss: 1.910273551940918
Validation loss: 2.014748697479566

Epoch: 5| Step: 2
Training loss: 2.7996420860290527
Validation loss: 2.012633686264356

Epoch: 5| Step: 3
Training loss: 2.089448928833008
Validation loss: 2.0048747112353644

Epoch: 5| Step: 4
Training loss: 2.318634510040283
Validation loss: 1.9981052925189335

Epoch: 5| Step: 5
Training loss: 1.811751127243042
Validation loss: 2.0024284571409225

Epoch: 5| Step: 6
Training loss: 2.2507567405700684
Validation loss: 2.0134854217370353

Epoch: 5| Step: 7
Training loss: 1.3447641134262085
Validation loss: 2.0101664066314697

Epoch: 5| Step: 8
Training loss: 2.388761043548584
Validation loss: 2.0145703305800757

Epoch: 5| Step: 9
Training loss: 2.2893130779266357
Validation loss: 2.015971859296163

Epoch: 5| Step: 10
Training loss: 1.3866913318634033
Validation loss: 2.0130101988712945

Epoch: 5| Step: 11
Training loss: 2.1798501014709473
Validation loss: 2.0129755785067878

Epoch: 121| Step: 0
Training loss: 2.2513153553009033
Validation loss: 2.0165695498387017

Epoch: 5| Step: 1
Training loss: 1.692283034324646
Validation loss: 2.0093885213136673

Epoch: 5| Step: 2
Training loss: 1.8776775598526
Validation loss: 2.0050810476144156

Epoch: 5| Step: 3
Training loss: 1.9337255954742432
Validation loss: 2.0131816466649375

Epoch: 5| Step: 4
Training loss: 1.9581772089004517
Validation loss: 2.0140560070673623

Epoch: 5| Step: 5
Training loss: 2.2636470794677734
Validation loss: 2.00321534772714

Epoch: 5| Step: 6
Training loss: 1.8152332305908203
Validation loss: 2.008365049958229

Epoch: 5| Step: 7
Training loss: 2.6794323921203613
Validation loss: 2.0092900693416595

Epoch: 5| Step: 8
Training loss: 1.8320649862289429
Validation loss: 2.005316639939944

Epoch: 5| Step: 9
Training loss: 2.171858310699463
Validation loss: 2.003951778014501

Epoch: 5| Step: 10
Training loss: 2.5021812915802
Validation loss: 2.0074756940205893

Epoch: 5| Step: 11
Training loss: 2.215104341506958
Validation loss: 2.005530888835589

Epoch: 122| Step: 0
Training loss: 1.8356902599334717
Validation loss: 2.0040930956602097

Epoch: 5| Step: 1
Training loss: 2.058605194091797
Validation loss: 2.014113833506902

Epoch: 5| Step: 2
Training loss: 1.6462293863296509
Validation loss: 2.0096219182014465

Epoch: 5| Step: 3
Training loss: 2.2611422538757324
Validation loss: 2.0086018592119217

Epoch: 5| Step: 4
Training loss: 1.9673347473144531
Validation loss: 2.0119262288014093

Epoch: 5| Step: 5
Training loss: 2.247112274169922
Validation loss: 2.00516406695048

Epoch: 5| Step: 6
Training loss: 2.305920124053955
Validation loss: 2.0114122281471887

Epoch: 5| Step: 7
Training loss: 1.8146798610687256
Validation loss: 2.0115592926740646

Epoch: 5| Step: 8
Training loss: 2.470320224761963
Validation loss: 2.012178043524424

Epoch: 5| Step: 9
Training loss: 2.2766079902648926
Validation loss: 2.0121792455514274

Epoch: 5| Step: 10
Training loss: 2.250373363494873
Validation loss: 2.0141140023867288

Epoch: 5| Step: 11
Training loss: 0.8556514978408813
Validation loss: 2.0147969722747803

Epoch: 123| Step: 0
Training loss: 2.4882311820983887
Validation loss: 2.028098687529564

Epoch: 5| Step: 1
Training loss: 2.1330928802490234
Validation loss: 2.031208018461863

Epoch: 5| Step: 2
Training loss: 2.817120313644409
Validation loss: 2.0381788512070975

Epoch: 5| Step: 3
Training loss: 2.001950740814209
Validation loss: 2.035520906249682

Epoch: 5| Step: 4
Training loss: 1.5011557340621948
Validation loss: 2.0308610747257867

Epoch: 5| Step: 5
Training loss: 2.2954518795013428
Validation loss: 2.0329644232988358

Epoch: 5| Step: 6
Training loss: 1.765252709388733
Validation loss: 2.0182774464289346

Epoch: 5| Step: 7
Training loss: 1.7458947896957397
Validation loss: 2.005953162908554

Epoch: 5| Step: 8
Training loss: 2.289350986480713
Validation loss: 2.0077897707621255

Epoch: 5| Step: 9
Training loss: 2.245007038116455
Validation loss: 2.0034957975149155

Epoch: 5| Step: 10
Training loss: 1.8457536697387695
Validation loss: 2.001687064766884

Epoch: 5| Step: 11
Training loss: 2.4930789470672607
Validation loss: 2.0062010188897452

Epoch: 124| Step: 0
Training loss: 2.657954216003418
Validation loss: 2.019058123230934

Epoch: 5| Step: 1
Training loss: 1.8761637210845947
Validation loss: 2.0273497154315314

Epoch: 5| Step: 2
Training loss: 1.718327283859253
Validation loss: 2.0178609689076743

Epoch: 5| Step: 3
Training loss: 2.3687751293182373
Validation loss: 2.0250724057356515

Epoch: 5| Step: 4
Training loss: 2.17389178276062
Validation loss: 2.02385284503301

Epoch: 5| Step: 5
Training loss: 2.3687500953674316
Validation loss: 2.0192061364650726

Epoch: 5| Step: 6
Training loss: 2.0859971046447754
Validation loss: 2.024332274993261

Epoch: 5| Step: 7
Training loss: 2.137155532836914
Validation loss: 2.0086480478445687

Epoch: 5| Step: 8
Training loss: 2.302623748779297
Validation loss: 2.015341599782308

Epoch: 5| Step: 9
Training loss: 1.8837430477142334
Validation loss: 2.010991632938385

Epoch: 5| Step: 10
Training loss: 1.9923479557037354
Validation loss: 2.00931208829085

Epoch: 5| Step: 11
Training loss: 1.5292824506759644
Validation loss: 2.014180362224579

Epoch: 125| Step: 0
Training loss: 1.5982942581176758
Validation loss: 2.0126180748144784

Epoch: 5| Step: 1
Training loss: 2.2184035778045654
Validation loss: 2.014816348751386

Epoch: 5| Step: 2
Training loss: 2.08514142036438
Validation loss: 2.0140827695528665

Epoch: 5| Step: 3
Training loss: 2.523139715194702
Validation loss: 2.022150387366613

Epoch: 5| Step: 4
Training loss: 2.0379977226257324
Validation loss: 2.025883028904597

Epoch: 5| Step: 5
Training loss: 2.1856026649475098
Validation loss: 2.0174809445937476

Epoch: 5| Step: 6
Training loss: 1.8324228525161743
Validation loss: 2.021523435910543

Epoch: 5| Step: 7
Training loss: 2.5375161170959473
Validation loss: 2.0261101027329764

Epoch: 5| Step: 8
Training loss: 1.850622534751892
Validation loss: 2.0280348559220633

Epoch: 5| Step: 9
Training loss: 2.413705348968506
Validation loss: 2.0205080757538476

Epoch: 5| Step: 10
Training loss: 1.749607801437378
Validation loss: 2.0227984537680945

Epoch: 5| Step: 11
Training loss: 1.7770922183990479
Validation loss: 2.027024284005165

Epoch: 126| Step: 0
Training loss: 1.5481477975845337
Validation loss: 2.0296331346035004

Epoch: 5| Step: 1
Training loss: 1.8364890813827515
Validation loss: 2.035061856110891

Epoch: 5| Step: 2
Training loss: 1.8449989557266235
Validation loss: 2.03439532717069

Epoch: 5| Step: 3
Training loss: 2.242462635040283
Validation loss: 2.033668423692385

Epoch: 5| Step: 4
Training loss: 1.8181705474853516
Validation loss: 2.032013008991877

Epoch: 5| Step: 5
Training loss: 2.316685676574707
Validation loss: 2.0379379838705063

Epoch: 5| Step: 6
Training loss: 2.167189836502075
Validation loss: 2.0247158110141754

Epoch: 5| Step: 7
Training loss: 2.1710333824157715
Validation loss: 2.03403847416242

Epoch: 5| Step: 8
Training loss: 2.7633378505706787
Validation loss: 2.0330679366985955

Epoch: 5| Step: 9
Training loss: 1.792787790298462
Validation loss: 2.034855922063192

Epoch: 5| Step: 10
Training loss: 2.262946605682373
Validation loss: 2.026455635825793

Epoch: 5| Step: 11
Training loss: 2.908681631088257
Validation loss: 2.0272951424121857

Epoch: 127| Step: 0
Training loss: 1.656375527381897
Validation loss: 2.033098349968592

Epoch: 5| Step: 1
Training loss: 1.9493675231933594
Validation loss: 2.021239697933197

Epoch: 5| Step: 2
Training loss: 2.031533718109131
Validation loss: 2.0226198633511863

Epoch: 5| Step: 3
Training loss: 2.051626682281494
Validation loss: 2.0222376883029938

Epoch: 5| Step: 4
Training loss: 2.109501361846924
Validation loss: 2.021487901608149

Epoch: 5| Step: 5
Training loss: 2.5709192752838135
Validation loss: 2.017953927318255

Epoch: 5| Step: 6
Training loss: 2.299440860748291
Validation loss: 2.024541219075521

Epoch: 5| Step: 7
Training loss: 2.4673752784729004
Validation loss: 2.0244690279165902

Epoch: 5| Step: 8
Training loss: 2.067986249923706
Validation loss: 2.019353230794271

Epoch: 5| Step: 9
Training loss: 1.9167171716690063
Validation loss: 2.0231675058603287

Epoch: 5| Step: 10
Training loss: 1.925794243812561
Validation loss: 2.023425832390785

Epoch: 5| Step: 11
Training loss: 2.09932279586792
Validation loss: 2.0389514168103537

Epoch: 128| Step: 0
Training loss: 1.9386084079742432
Validation loss: 2.038437614838282

Epoch: 5| Step: 1
Training loss: 1.9301974773406982
Validation loss: 2.041705548763275

Epoch: 5| Step: 2
Training loss: 2.640129566192627
Validation loss: 2.0546796321868896

Epoch: 5| Step: 3
Training loss: 2.0876612663269043
Validation loss: 2.051683157682419

Epoch: 5| Step: 4
Training loss: 2.1550023555755615
Validation loss: 2.0601754834254584

Epoch: 5| Step: 5
Training loss: 1.9691327810287476
Validation loss: 2.0459059526522956

Epoch: 5| Step: 6
Training loss: 1.901699423789978
Validation loss: 2.0583502302567163

Epoch: 5| Step: 7
Training loss: 2.3597776889801025
Validation loss: 2.0443367063999176

Epoch: 5| Step: 8
Training loss: 2.249541759490967
Validation loss: 2.044839253028234

Epoch: 5| Step: 9
Training loss: 1.7229130268096924
Validation loss: 2.034008959929148

Epoch: 5| Step: 10
Training loss: 1.8587528467178345
Validation loss: 2.030298391977946

Epoch: 5| Step: 11
Training loss: 2.9909069538116455
Validation loss: 2.030776078502337

Epoch: 129| Step: 0
Training loss: 2.0669407844543457
Validation loss: 2.0297454794247947

Epoch: 5| Step: 1
Training loss: 1.5841788053512573
Validation loss: 2.0238187859455743

Epoch: 5| Step: 2
Training loss: 2.2711353302001953
Validation loss: 2.0176964501539865

Epoch: 5| Step: 3
Training loss: 1.9077457189559937
Validation loss: 2.029450843731562

Epoch: 5| Step: 4
Training loss: 1.821049451828003
Validation loss: 2.026474490761757

Epoch: 5| Step: 5
Training loss: 2.51668381690979
Validation loss: 2.0251268595457077

Epoch: 5| Step: 6
Training loss: 2.1402454376220703
Validation loss: 2.028607577085495

Epoch: 5| Step: 7
Training loss: 1.923797369003296
Validation loss: 2.026104981700579

Epoch: 5| Step: 8
Training loss: 2.0402185916900635
Validation loss: 2.029879078269005

Epoch: 5| Step: 9
Training loss: 1.9457687139511108
Validation loss: 2.021950905521711

Epoch: 5| Step: 10
Training loss: 2.557741641998291
Validation loss: 2.0396947662035623

Epoch: 5| Step: 11
Training loss: 2.953838586807251
Validation loss: 2.0254108905792236

Epoch: 130| Step: 0
Training loss: 2.252171039581299
Validation loss: 2.030462458729744

Epoch: 5| Step: 1
Training loss: 2.123910903930664
Validation loss: 2.0286711951096854

Epoch: 5| Step: 2
Training loss: 1.448855996131897
Validation loss: 2.031965638200442

Epoch: 5| Step: 3
Training loss: 2.135711908340454
Validation loss: 2.0226349979639053

Epoch: 5| Step: 4
Training loss: 2.0662460327148438
Validation loss: 2.028585731983185

Epoch: 5| Step: 5
Training loss: 1.7677593231201172
Validation loss: 2.035803551475207

Epoch: 5| Step: 6
Training loss: 1.7623761892318726
Validation loss: 2.0327852219343185

Epoch: 5| Step: 7
Training loss: 2.1940958499908447
Validation loss: 2.0564215878645578

Epoch: 5| Step: 8
Training loss: 2.8600003719329834
Validation loss: 2.0483678728342056

Epoch: 5| Step: 9
Training loss: 2.0953211784362793
Validation loss: 2.0430587828159332

Epoch: 5| Step: 10
Training loss: 2.0171704292297363
Validation loss: 2.0399499336878457

Epoch: 5| Step: 11
Training loss: 3.5639517307281494
Validation loss: 2.030515179038048

Epoch: 131| Step: 0
Training loss: 2.2088539600372314
Validation loss: 2.0353647669156394

Epoch: 5| Step: 1
Training loss: 1.9627466201782227
Validation loss: 2.037905524174372

Epoch: 5| Step: 2
Training loss: 2.2943906784057617
Validation loss: 2.0349428902069726

Epoch: 5| Step: 3
Training loss: 1.7584558725357056
Validation loss: 2.0297674437363944

Epoch: 5| Step: 4
Training loss: 1.7776565551757812
Validation loss: 2.0273272643486657

Epoch: 5| Step: 5
Training loss: 2.7464029788970947
Validation loss: 2.034164180358251

Epoch: 5| Step: 6
Training loss: 1.9195200204849243
Validation loss: 2.0342990358670554

Epoch: 5| Step: 7
Training loss: 2.3594305515289307
Validation loss: 2.037432144085566

Epoch: 5| Step: 8
Training loss: 2.170335054397583
Validation loss: 2.03024227420489

Epoch: 5| Step: 9
Training loss: 1.6431798934936523
Validation loss: 2.0278898030519485

Epoch: 5| Step: 10
Training loss: 2.171555519104004
Validation loss: 2.0282716949780784

Epoch: 5| Step: 11
Training loss: 1.3379936218261719
Validation loss: 2.0372242430845895

Epoch: 132| Step: 0
Training loss: 1.7286202907562256
Validation loss: 2.045039335886637

Epoch: 5| Step: 1
Training loss: 1.7290796041488647
Validation loss: 2.0336376428604126

Epoch: 5| Step: 2
Training loss: 2.236591339111328
Validation loss: 2.039118602871895

Epoch: 5| Step: 3
Training loss: 2.0125033855438232
Validation loss: 2.042080561319987

Epoch: 5| Step: 4
Training loss: 1.9580371379852295
Validation loss: 2.0360605120658875

Epoch: 5| Step: 5
Training loss: 2.0102779865264893
Validation loss: 2.0295295864343643

Epoch: 5| Step: 6
Training loss: 2.5502471923828125
Validation loss: 2.025296742717425

Epoch: 5| Step: 7
Training loss: 2.2401528358459473
Validation loss: 2.0273989190657935

Epoch: 5| Step: 8
Training loss: 2.13187837600708
Validation loss: 2.031315967440605

Epoch: 5| Step: 9
Training loss: 2.324519634246826
Validation loss: 2.0237253655989966

Epoch: 5| Step: 10
Training loss: 1.9352893829345703
Validation loss: 2.0208983620007834

Epoch: 5| Step: 11
Training loss: 1.707078218460083
Validation loss: 2.0183324764172235

Epoch: 133| Step: 0
Training loss: 2.2031657695770264
Validation loss: 2.0305579155683517

Epoch: 5| Step: 1
Training loss: 2.1424365043640137
Validation loss: 2.035557503501574

Epoch: 5| Step: 2
Training loss: 1.9947004318237305
Validation loss: 2.034246936440468

Epoch: 5| Step: 3
Training loss: 2.0741512775421143
Validation loss: 2.032796452442805

Epoch: 5| Step: 4
Training loss: 1.9271968603134155
Validation loss: 2.0289438168207803

Epoch: 5| Step: 5
Training loss: 2.0056018829345703
Validation loss: 2.0397084057331085

Epoch: 5| Step: 6
Training loss: 2.114629030227661
Validation loss: 2.0448871552944183

Epoch: 5| Step: 7
Training loss: 1.9911209344863892
Validation loss: 2.0488176296154657

Epoch: 5| Step: 8
Training loss: 1.9645500183105469
Validation loss: 2.04728010793527

Epoch: 5| Step: 9
Training loss: 2.171247959136963
Validation loss: 2.046337922414144

Epoch: 5| Step: 10
Training loss: 2.017146110534668
Validation loss: 2.0417947669823966

Epoch: 5| Step: 11
Training loss: 2.7040159702301025
Validation loss: 2.0495715836683908

Epoch: 134| Step: 0
Training loss: 2.094435214996338
Validation loss: 2.0419145872195563

Epoch: 5| Step: 1
Training loss: 2.0974957942962646
Validation loss: 2.049234519402186

Epoch: 5| Step: 2
Training loss: 2.261458158493042
Validation loss: 2.0401617288589478

Epoch: 5| Step: 3
Training loss: 1.7193504571914673
Validation loss: 2.0220111111799874

Epoch: 5| Step: 4
Training loss: 1.8875840902328491
Validation loss: 2.0318278670310974

Epoch: 5| Step: 5
Training loss: 1.7432591915130615
Validation loss: 2.0303794940312705

Epoch: 5| Step: 6
Training loss: 2.261723756790161
Validation loss: 2.028213376800219

Epoch: 5| Step: 7
Training loss: 2.0837395191192627
Validation loss: 2.022874732812246

Epoch: 5| Step: 8
Training loss: 2.763962984085083
Validation loss: 2.026265397667885

Epoch: 5| Step: 9
Training loss: 1.9233671426773071
Validation loss: 2.0277009308338165

Epoch: 5| Step: 10
Training loss: 2.191129207611084
Validation loss: 2.035200367371241

Epoch: 5| Step: 11
Training loss: 1.9153985977172852
Validation loss: 2.041287198662758

Epoch: 135| Step: 0
Training loss: 1.3891175985336304
Validation loss: 2.0498070269823074

Epoch: 5| Step: 1
Training loss: 2.0458779335021973
Validation loss: 2.0476263960202536

Epoch: 5| Step: 2
Training loss: 1.6430995464324951
Validation loss: 2.0581227838993073

Epoch: 5| Step: 3
Training loss: 2.6070072650909424
Validation loss: 2.0466226985057197

Epoch: 5| Step: 4
Training loss: 2.026247024536133
Validation loss: 2.0601813246806464

Epoch: 5| Step: 5
Training loss: 2.4758081436157227
Validation loss: 2.0682751486698785

Epoch: 5| Step: 6
Training loss: 1.9957821369171143
Validation loss: 2.0661786645650864

Epoch: 5| Step: 7
Training loss: 1.5273405313491821
Validation loss: 2.0740045607089996

Epoch: 5| Step: 8
Training loss: 2.221390962600708
Validation loss: 2.0635873725016913

Epoch: 5| Step: 9
Training loss: 2.610713481903076
Validation loss: 2.0434646904468536

Epoch: 5| Step: 10
Training loss: 2.2797904014587402
Validation loss: 2.0376624862353006

Epoch: 5| Step: 11
Training loss: 2.458259105682373
Validation loss: 2.029908210039139

Epoch: 136| Step: 0
Training loss: 2.2468833923339844
Validation loss: 2.0280007173617682

Epoch: 5| Step: 1
Training loss: 2.24845027923584
Validation loss: 2.0321084956328073

Epoch: 5| Step: 2
Training loss: 1.7018606662750244
Validation loss: 2.0426000555356345

Epoch: 5| Step: 3
Training loss: 2.622314929962158
Validation loss: 2.045169765750567

Epoch: 5| Step: 4
Training loss: 1.919978141784668
Validation loss: 2.04473544160525

Epoch: 5| Step: 5
Training loss: 2.3668148517608643
Validation loss: 2.048524151245753

Epoch: 5| Step: 6
Training loss: 2.3869411945343018
Validation loss: 2.0455393890539804

Epoch: 5| Step: 7
Training loss: 1.8196640014648438
Validation loss: 2.0465486546357474

Epoch: 5| Step: 8
Training loss: 2.3939902782440186
Validation loss: 2.0553439805905023

Epoch: 5| Step: 9
Training loss: 2.299985408782959
Validation loss: 2.045260965824127

Epoch: 5| Step: 10
Training loss: 2.0233993530273438
Validation loss: 2.0458164662122726

Epoch: 5| Step: 11
Training loss: 0.9425737857818604
Validation loss: 2.0503394355376563

Epoch: 137| Step: 0
Training loss: 1.7315095663070679
Validation loss: 2.0423098653554916

Epoch: 5| Step: 1
Training loss: 1.8303569555282593
Validation loss: 2.043795426686605

Epoch: 5| Step: 2
Training loss: 2.0666232109069824
Validation loss: 2.043440043926239

Epoch: 5| Step: 3
Training loss: 2.405986785888672
Validation loss: 2.0389065543810525

Epoch: 5| Step: 4
Training loss: 1.9660625457763672
Validation loss: 2.0444937398036322

Epoch: 5| Step: 5
Training loss: 2.5384373664855957
Validation loss: 2.033698777357737

Epoch: 5| Step: 6
Training loss: 2.440668821334839
Validation loss: 2.0372970700263977

Epoch: 5| Step: 7
Training loss: 1.8019487857818604
Validation loss: 2.03434648613135

Epoch: 5| Step: 8
Training loss: 2.208531379699707
Validation loss: 2.0426891843477883

Epoch: 5| Step: 9
Training loss: 1.915236473083496
Validation loss: 2.0338013966878257

Epoch: 5| Step: 10
Training loss: 2.2885918617248535
Validation loss: 2.042162617047628

Epoch: 5| Step: 11
Training loss: 2.18994140625
Validation loss: 2.0405578513940177

Epoch: 138| Step: 0
Training loss: 2.2510123252868652
Validation loss: 2.043805941939354

Epoch: 5| Step: 1
Training loss: 2.438957452774048
Validation loss: 2.0512468119462333

Epoch: 5| Step: 2
Training loss: 1.946773886680603
Validation loss: 2.055160532395045

Epoch: 5| Step: 3
Training loss: 1.7626235485076904
Validation loss: 2.0527158230543137

Epoch: 5| Step: 4
Training loss: 2.2128725051879883
Validation loss: 2.04985045393308

Epoch: 5| Step: 5
Training loss: 1.8288379907608032
Validation loss: 2.0497160653273263

Epoch: 5| Step: 6
Training loss: 2.149366617202759
Validation loss: 2.0610946168502173

Epoch: 5| Step: 7
Training loss: 1.9338505268096924
Validation loss: 2.053887829184532

Epoch: 5| Step: 8
Training loss: 2.070401430130005
Validation loss: 2.0495858043432236

Epoch: 5| Step: 9
Training loss: 2.274052143096924
Validation loss: 2.0512786457935968

Epoch: 5| Step: 10
Training loss: 1.8267383575439453
Validation loss: 2.0517823845148087

Epoch: 5| Step: 11
Training loss: 2.5422754287719727
Validation loss: 2.0525413155555725

Epoch: 139| Step: 0
Training loss: 1.8307079076766968
Validation loss: 2.070908476909002

Epoch: 5| Step: 1
Training loss: 2.568960666656494
Validation loss: 2.0693772385517755

Epoch: 5| Step: 2
Training loss: 2.155393362045288
Validation loss: 2.098331019282341

Epoch: 5| Step: 3
Training loss: 1.7695032358169556
Validation loss: 2.1199454416831336

Epoch: 5| Step: 4
Training loss: 2.8202903270721436
Validation loss: 2.130194917321205

Epoch: 5| Step: 5
Training loss: 2.129040002822876
Validation loss: 2.1477584640185037

Epoch: 5| Step: 6
Training loss: 2.336061477661133
Validation loss: 2.1273597379525504

Epoch: 5| Step: 7
Training loss: 1.952919602394104
Validation loss: 2.0890607039133706

Epoch: 5| Step: 8
Training loss: 1.7490564584732056
Validation loss: 2.0682934373617172

Epoch: 5| Step: 9
Training loss: 2.0367751121520996
Validation loss: 2.0569248497486115

Epoch: 5| Step: 10
Training loss: 2.2876248359680176
Validation loss: 2.0403081327676773

Epoch: 5| Step: 11
Training loss: 1.2100131511688232
Validation loss: 2.0241135954856873

Epoch: 140| Step: 0
Training loss: 2.2727675437927246
Validation loss: 2.0308779031038284

Epoch: 5| Step: 1
Training loss: 2.2891528606414795
Validation loss: 2.0332250148057938

Epoch: 5| Step: 2
Training loss: 2.5545825958251953
Validation loss: 2.0385279059410095

Epoch: 5| Step: 3
Training loss: 1.9570209980010986
Validation loss: 2.0470366925001144

Epoch: 5| Step: 4
Training loss: 2.296687602996826
Validation loss: 2.0474777022997537

Epoch: 5| Step: 5
Training loss: 2.419140100479126
Validation loss: 2.0476487328608832

Epoch: 5| Step: 6
Training loss: 2.106478452682495
Validation loss: 2.0484868437051773

Epoch: 5| Step: 7
Training loss: 2.0345163345336914
Validation loss: 2.057565669218699

Epoch: 5| Step: 8
Training loss: 1.7701812982559204
Validation loss: 2.0519184122482934

Epoch: 5| Step: 9
Training loss: 2.0823042392730713
Validation loss: 2.0489948242902756

Epoch: 5| Step: 10
Training loss: 2.26582670211792
Validation loss: 2.048677151401838

Epoch: 5| Step: 11
Training loss: 1.8372737169265747
Validation loss: 2.043080692489942

Epoch: 141| Step: 0
Training loss: 2.1332955360412598
Validation loss: 2.050330251455307

Epoch: 5| Step: 1
Training loss: 1.9066638946533203
Validation loss: 2.049752046664556

Epoch: 5| Step: 2
Training loss: 2.1939454078674316
Validation loss: 2.045913169781367

Epoch: 5| Step: 3
Training loss: 2.494877338409424
Validation loss: 2.0442286481459937

Epoch: 5| Step: 4
Training loss: 1.8333377838134766
Validation loss: 2.0450013081232705

Epoch: 5| Step: 5
Training loss: 1.963994026184082
Validation loss: 2.039753869175911

Epoch: 5| Step: 6
Training loss: 1.8346410989761353
Validation loss: 2.0416529377301535

Epoch: 5| Step: 7
Training loss: 2.299293279647827
Validation loss: 2.0392350455125174

Epoch: 5| Step: 8
Training loss: 2.411489486694336
Validation loss: 2.0372929672400155

Epoch: 5| Step: 9
Training loss: 2.261467695236206
Validation loss: 2.034941926598549

Epoch: 5| Step: 10
Training loss: 2.634169101715088
Validation loss: 2.0325993299484253

Epoch: 5| Step: 11
Training loss: 1.373807430267334
Validation loss: 2.0354343205690384

Epoch: 142| Step: 0
Training loss: 1.8710548877716064
Validation loss: 2.028222476442655

Epoch: 5| Step: 1
Training loss: 2.308476686477661
Validation loss: 2.024448355038961

Epoch: 5| Step: 2
Training loss: 2.1785454750061035
Validation loss: 2.016723185777664

Epoch: 5| Step: 3
Training loss: 1.8655506372451782
Validation loss: 2.022271732489268

Epoch: 5| Step: 4
Training loss: 2.1807732582092285
Validation loss: 2.021734282374382

Epoch: 5| Step: 5
Training loss: 2.198835611343384
Validation loss: 2.023972829182943

Epoch: 5| Step: 6
Training loss: 2.0702924728393555
Validation loss: 2.0269955645004907

Epoch: 5| Step: 7
Training loss: 2.610269546508789
Validation loss: 2.038884699344635

Epoch: 5| Step: 8
Training loss: 2.1585144996643066
Validation loss: 2.0412325312693915

Epoch: 5| Step: 9
Training loss: 2.2076492309570312
Validation loss: 2.035090352098147

Epoch: 5| Step: 10
Training loss: 1.5718841552734375
Validation loss: 2.038757016261419

Epoch: 5| Step: 11
Training loss: 1.7665215730667114
Validation loss: 2.0557942986488342

Epoch: 143| Step: 0
Training loss: 2.1889381408691406
Validation loss: 2.05289189517498

Epoch: 5| Step: 1
Training loss: 2.04335355758667
Validation loss: 2.056013062596321

Epoch: 5| Step: 2
Training loss: 1.8577286005020142
Validation loss: 2.0555322021245956

Epoch: 5| Step: 3
Training loss: 1.8961060047149658
Validation loss: 2.0609759837388992

Epoch: 5| Step: 4
Training loss: 1.7130677700042725
Validation loss: 2.0555458068847656

Epoch: 5| Step: 5
Training loss: 2.326779365539551
Validation loss: 2.0493454237778983

Epoch: 5| Step: 6
Training loss: 1.6494190692901611
Validation loss: 2.038284659385681

Epoch: 5| Step: 7
Training loss: 1.8984708786010742
Validation loss: 2.0419371277093887

Epoch: 5| Step: 8
Training loss: 2.4875974655151367
Validation loss: 2.0373909076054892

Epoch: 5| Step: 9
Training loss: 1.86692214012146
Validation loss: 2.03561603029569

Epoch: 5| Step: 10
Training loss: 2.665189743041992
Validation loss: 2.0278460482756295

Epoch: 5| Step: 11
Training loss: 2.8577067852020264
Validation loss: 2.038788070281347

Epoch: 144| Step: 0
Training loss: 1.827235460281372
Validation loss: 2.0450855493545532

Epoch: 5| Step: 1
Training loss: 2.269885778427124
Validation loss: 2.0596602310736976

Epoch: 5| Step: 2
Training loss: 2.0719802379608154
Validation loss: 2.0533992499113083

Epoch: 5| Step: 3
Training loss: 2.0484681129455566
Validation loss: 2.067997713883718

Epoch: 5| Step: 4
Training loss: 2.356100559234619
Validation loss: 2.0580982019503913

Epoch: 5| Step: 5
Training loss: 2.2705254554748535
Validation loss: 2.05273607869943

Epoch: 5| Step: 6
Training loss: 1.985518217086792
Validation loss: 2.0562582661708197

Epoch: 5| Step: 7
Training loss: 2.189906120300293
Validation loss: 2.047942837079366

Epoch: 5| Step: 8
Training loss: 1.711033582687378
Validation loss: 2.0390172004699707

Epoch: 5| Step: 9
Training loss: 1.9411029815673828
Validation loss: 2.0316599011421204

Epoch: 5| Step: 10
Training loss: 2.353827953338623
Validation loss: 2.0281730691591897

Epoch: 5| Step: 11
Training loss: 1.6969836950302124
Validation loss: 2.0332007110118866

Epoch: 145| Step: 0
Training loss: 2.2341248989105225
Validation loss: 2.0285920749107995

Epoch: 5| Step: 1
Training loss: 2.08231520652771
Validation loss: 2.0223154375950494

Epoch: 5| Step: 2
Training loss: 2.0754857063293457
Validation loss: 2.0230497221151986

Epoch: 5| Step: 3
Training loss: 1.8979215621948242
Validation loss: 2.0247829357783

Epoch: 5| Step: 4
Training loss: 1.7968591451644897
Validation loss: 2.020703266064326

Epoch: 5| Step: 5
Training loss: 1.7400074005126953
Validation loss: 2.034566819667816

Epoch: 5| Step: 6
Training loss: 1.9942547082901
Validation loss: 2.0352398504813514

Epoch: 5| Step: 7
Training loss: 2.3753933906555176
Validation loss: 2.03743348022302

Epoch: 5| Step: 8
Training loss: 2.038026809692383
Validation loss: 2.0372097243865332

Epoch: 5| Step: 9
Training loss: 2.1710190773010254
Validation loss: 2.035987342397372

Epoch: 5| Step: 10
Training loss: 2.2803258895874023
Validation loss: 2.045798843105634

Epoch: 5| Step: 11
Training loss: 2.8155174255371094
Validation loss: 2.0497297793626785

Epoch: 146| Step: 0
Training loss: 2.2919156551361084
Validation loss: 2.0483417411645255

Epoch: 5| Step: 1
Training loss: 2.4919111728668213
Validation loss: 2.0457307746013007

Epoch: 5| Step: 2
Training loss: 2.3271546363830566
Validation loss: 2.039180114865303

Epoch: 5| Step: 3
Training loss: 1.5417897701263428
Validation loss: 2.0371565322081246

Epoch: 5| Step: 4
Training loss: 2.3256521224975586
Validation loss: 2.0420303344726562

Epoch: 5| Step: 5
Training loss: 1.945758581161499
Validation loss: 2.042404294013977

Epoch: 5| Step: 6
Training loss: 1.8074405193328857
Validation loss: 2.0496253122886023

Epoch: 5| Step: 7
Training loss: 1.8955786228179932
Validation loss: 2.0555185973644257

Epoch: 5| Step: 8
Training loss: 1.7801882028579712
Validation loss: 2.05204767982165

Epoch: 5| Step: 9
Training loss: 1.8139318227767944
Validation loss: 2.0546511809031167

Epoch: 5| Step: 10
Training loss: 2.4640517234802246
Validation loss: 2.0571283797423043

Epoch: 5| Step: 11
Training loss: 1.970947265625
Validation loss: 2.0495609641075134

Epoch: 147| Step: 0
Training loss: 1.6982128620147705
Validation loss: 2.0520384361346564

Epoch: 5| Step: 1
Training loss: 2.231309413909912
Validation loss: 2.0601813395818076

Epoch: 5| Step: 2
Training loss: 1.7154737710952759
Validation loss: 2.050905759135882

Epoch: 5| Step: 3
Training loss: 1.4882690906524658
Validation loss: 2.0446776499350867

Epoch: 5| Step: 4
Training loss: 2.5989878177642822
Validation loss: 2.047878712415695

Epoch: 5| Step: 5
Training loss: 1.8311700820922852
Validation loss: 2.0451153169075647

Epoch: 5| Step: 6
Training loss: 2.3667404651641846
Validation loss: 2.052059292793274

Epoch: 5| Step: 7
Training loss: 2.3102076053619385
Validation loss: 2.050124024351438

Epoch: 5| Step: 8
Training loss: 2.098452091217041
Validation loss: 2.054964358607928

Epoch: 5| Step: 9
Training loss: 1.8012218475341797
Validation loss: 2.06363774339358

Epoch: 5| Step: 10
Training loss: 2.304039716720581
Validation loss: 2.0529498755931854

Epoch: 5| Step: 11
Training loss: 2.689772129058838
Validation loss: 2.0541397531827292

Epoch: 148| Step: 0
Training loss: 1.7675052881240845
Validation loss: 2.0497234960397086

Epoch: 5| Step: 1
Training loss: 2.633204460144043
Validation loss: 2.0557785034179688

Epoch: 5| Step: 2
Training loss: 2.260042667388916
Validation loss: 2.059918373823166

Epoch: 5| Step: 3
Training loss: 2.0146470069885254
Validation loss: 2.0560195048650107

Epoch: 5| Step: 4
Training loss: 2.034728527069092
Validation loss: 2.066851183772087

Epoch: 5| Step: 5
Training loss: 1.9222805500030518
Validation loss: 2.0573055992523828

Epoch: 5| Step: 6
Training loss: 1.9772539138793945
Validation loss: 2.0560463716586432

Epoch: 5| Step: 7
Training loss: 2.040652275085449
Validation loss: 2.0497107108434043

Epoch: 5| Step: 8
Training loss: 2.222219944000244
Validation loss: 2.0503625770409903

Epoch: 5| Step: 9
Training loss: 1.8177087306976318
Validation loss: 2.0517420719067254

Epoch: 5| Step: 10
Training loss: 1.5606640577316284
Validation loss: 2.052957241733869

Epoch: 5| Step: 11
Training loss: 3.6082143783569336
Validation loss: 2.057245229681333

Epoch: 149| Step: 0
Training loss: 2.413489580154419
Validation loss: 2.0572781761487327

Epoch: 5| Step: 1
Training loss: 2.204193115234375
Validation loss: 2.0565763413906097

Epoch: 5| Step: 2
Training loss: 2.4950592517852783
Validation loss: 2.0527142137289047

Epoch: 5| Step: 3
Training loss: 2.2160470485687256
Validation loss: 2.0450402895609536

Epoch: 5| Step: 4
Training loss: 1.727522850036621
Validation loss: 2.056350459655126

Epoch: 5| Step: 5
Training loss: 1.9965238571166992
Validation loss: 2.0609937657912574

Epoch: 5| Step: 6
Training loss: 1.6160733699798584
Validation loss: 2.057031363248825

Epoch: 5| Step: 7
Training loss: 1.931626558303833
Validation loss: 2.062794884045919

Epoch: 5| Step: 8
Training loss: 1.9661571979522705
Validation loss: 2.072349260250727

Epoch: 5| Step: 9
Training loss: 1.9827667474746704
Validation loss: 2.0598031282424927

Epoch: 5| Step: 10
Training loss: 2.075383186340332
Validation loss: 2.064182092746099

Epoch: 5| Step: 11
Training loss: 1.9075566530227661
Validation loss: 2.070240780711174

Epoch: 150| Step: 0
Training loss: 2.3713018894195557
Validation loss: 2.0735740115245185

Epoch: 5| Step: 1
Training loss: 1.9492204189300537
Validation loss: 2.058830345670382

Epoch: 5| Step: 2
Training loss: 2.0773046016693115
Validation loss: 2.062338853875796

Epoch: 5| Step: 3
Training loss: 2.056222915649414
Validation loss: 2.0578753302494683

Epoch: 5| Step: 4
Training loss: 2.1122918128967285
Validation loss: 2.0513306309779487

Epoch: 5| Step: 5
Training loss: 2.2922682762145996
Validation loss: 2.057503287990888

Epoch: 5| Step: 6
Training loss: 2.0744426250457764
Validation loss: 2.0594482074181237

Epoch: 5| Step: 7
Training loss: 1.5563952922821045
Validation loss: 2.052655736605326

Epoch: 5| Step: 8
Training loss: 2.2800681591033936
Validation loss: 2.060577834645907

Epoch: 5| Step: 9
Training loss: 1.6576141119003296
Validation loss: 2.0479888319969177

Epoch: 5| Step: 10
Training loss: 2.0030689239501953
Validation loss: 2.0520750085512796

Epoch: 5| Step: 11
Training loss: 2.652595043182373
Validation loss: 2.0528096705675125

Epoch: 151| Step: 0
Training loss: 2.415980815887451
Validation loss: 2.052391454577446

Epoch: 5| Step: 1
Training loss: 1.9677326679229736
Validation loss: 2.058031196395556

Epoch: 5| Step: 2
Training loss: 1.9521795511245728
Validation loss: 2.062992960214615

Epoch: 5| Step: 3
Training loss: 1.820400595664978
Validation loss: 2.0643136302630105

Epoch: 5| Step: 4
Training loss: 2.2615537643432617
Validation loss: 2.0600391179323196

Epoch: 5| Step: 5
Training loss: 1.694757103919983
Validation loss: 2.0685365547736487

Epoch: 5| Step: 6
Training loss: 2.481785535812378
Validation loss: 2.0642621417840323

Epoch: 5| Step: 7
Training loss: 1.7657673358917236
Validation loss: 2.0592140356699624

Epoch: 5| Step: 8
Training loss: 1.8297061920166016
Validation loss: 2.061616505185763

Epoch: 5| Step: 9
Training loss: 1.91839599609375
Validation loss: 2.0549051066239676

Epoch: 5| Step: 10
Training loss: 2.259572982788086
Validation loss: 2.049343079328537

Epoch: 5| Step: 11
Training loss: 2.043107509613037
Validation loss: 2.046286925673485

Epoch: 152| Step: 0
Training loss: 2.213207960128784
Validation loss: 2.048751329382261

Epoch: 5| Step: 1
Training loss: 1.4573997259140015
Validation loss: 2.0421857237815857

Epoch: 5| Step: 2
Training loss: 2.0007944107055664
Validation loss: 2.047361354033152

Epoch: 5| Step: 3
Training loss: 2.1037001609802246
Validation loss: 2.048326551914215

Epoch: 5| Step: 4
Training loss: 1.9878580570220947
Validation loss: 2.044133186340332

Epoch: 5| Step: 5
Training loss: 2.2732932567596436
Validation loss: 2.035556217034658

Epoch: 5| Step: 6
Training loss: 2.552943706512451
Validation loss: 2.034218445420265

Epoch: 5| Step: 7
Training loss: 1.8221696615219116
Validation loss: 2.03242198129495

Epoch: 5| Step: 8
Training loss: 2.5652213096618652
Validation loss: 2.0315971920887628

Epoch: 5| Step: 9
Training loss: 1.8415504693984985
Validation loss: 2.017960970600446

Epoch: 5| Step: 10
Training loss: 1.6899261474609375
Validation loss: 2.041444882750511

Epoch: 5| Step: 11
Training loss: 2.469524621963501
Validation loss: 2.04006656507651

Epoch: 153| Step: 0
Training loss: 1.3835418224334717
Validation loss: 2.042804171641668

Epoch: 5| Step: 1
Training loss: 2.2021384239196777
Validation loss: 2.037724261482557

Epoch: 5| Step: 2
Training loss: 2.25637149810791
Validation loss: 2.0344030410051346

Epoch: 5| Step: 3
Training loss: 2.5019760131835938
Validation loss: 2.0410012304782867

Epoch: 5| Step: 4
Training loss: 2.394073486328125
Validation loss: 2.036773835619291

Epoch: 5| Step: 5
Training loss: 1.620091199874878
Validation loss: 2.0484545131524405

Epoch: 5| Step: 6
Training loss: 2.1155097484588623
Validation loss: 2.048232391476631

Epoch: 5| Step: 7
Training loss: 1.7793426513671875
Validation loss: 2.0466943134864173

Epoch: 5| Step: 8
Training loss: 2.2467453479766846
Validation loss: 2.0476182798544564

Epoch: 5| Step: 9
Training loss: 2.132035493850708
Validation loss: 2.047385886311531

Epoch: 5| Step: 10
Training loss: 2.09629487991333
Validation loss: 2.045124808947245

Epoch: 5| Step: 11
Training loss: 0.904308557510376
Validation loss: 2.0509327948093414

Epoch: 154| Step: 0
Training loss: 1.9795029163360596
Validation loss: 2.046700785557429

Epoch: 5| Step: 1
Training loss: 2.292471170425415
Validation loss: 2.0581751664479575

Epoch: 5| Step: 2
Training loss: 2.1423707008361816
Validation loss: 2.0514169335365295

Epoch: 5| Step: 3
Training loss: 1.9575824737548828
Validation loss: 2.0461238423983255

Epoch: 5| Step: 4
Training loss: 2.313575267791748
Validation loss: 2.0425483783086142

Epoch: 5| Step: 5
Training loss: 2.049865245819092
Validation loss: 2.0497630635897317

Epoch: 5| Step: 6
Training loss: 1.8088287115097046
Validation loss: 2.0562907656033835

Epoch: 5| Step: 7
Training loss: 1.645142912864685
Validation loss: 2.047219375769297

Epoch: 5| Step: 8
Training loss: 2.089653491973877
Validation loss: 2.0484320571025214

Epoch: 5| Step: 9
Training loss: 1.747115135192871
Validation loss: 2.047945812344551

Epoch: 5| Step: 10
Training loss: 2.8998234272003174
Validation loss: 2.0611082116762796

Epoch: 5| Step: 11
Training loss: 1.0859166383743286
Validation loss: 2.051670342683792

Epoch: 155| Step: 0
Training loss: 2.2024178504943848
Validation loss: 2.063153932491938

Epoch: 5| Step: 1
Training loss: 1.5559754371643066
Validation loss: 2.0723635852336884

Epoch: 5| Step: 2
Training loss: 1.6963632106781006
Validation loss: 2.091465617219607

Epoch: 5| Step: 3
Training loss: 1.9632606506347656
Validation loss: 2.1194798350334167

Epoch: 5| Step: 4
Training loss: 2.5534026622772217
Validation loss: 2.1268023004134498

Epoch: 5| Step: 5
Training loss: 2.0829761028289795
Validation loss: 2.1054750929276147

Epoch: 5| Step: 6
Training loss: 2.1305031776428223
Validation loss: 2.1131166567405066

Epoch: 5| Step: 7
Training loss: 1.671103835105896
Validation loss: 2.098940094312032

Epoch: 5| Step: 8
Training loss: 2.5945420265197754
Validation loss: 2.0743438998858132

Epoch: 5| Step: 9
Training loss: 2.0294151306152344
Validation loss: 2.0553591549396515

Epoch: 5| Step: 10
Training loss: 2.147491455078125
Validation loss: 2.047322556376457

Epoch: 5| Step: 11
Training loss: 3.065418243408203
Validation loss: 2.044183293978373

Epoch: 156| Step: 0
Training loss: 1.8459727764129639
Validation loss: 2.036044657230377

Epoch: 5| Step: 1
Training loss: 2.0505237579345703
Validation loss: 2.0351675550142923

Epoch: 5| Step: 2
Training loss: 2.7778735160827637
Validation loss: 2.037440856297811

Epoch: 5| Step: 3
Training loss: 2.236837863922119
Validation loss: 2.0286661187807717

Epoch: 5| Step: 4
Training loss: 1.7866567373275757
Validation loss: 2.0354967216650643

Epoch: 5| Step: 5
Training loss: 2.365605354309082
Validation loss: 2.037679359316826

Epoch: 5| Step: 6
Training loss: 2.4952540397644043
Validation loss: 2.0310414880514145

Epoch: 5| Step: 7
Training loss: 1.8772809505462646
Validation loss: 2.0184474835793176

Epoch: 5| Step: 8
Training loss: 1.7720634937286377
Validation loss: 2.0136022170384726

Epoch: 5| Step: 9
Training loss: 1.932790756225586
Validation loss: 2.0105083336432776

Epoch: 5| Step: 10
Training loss: 2.048225164413452
Validation loss: 2.0069029728571572

Epoch: 5| Step: 11
Training loss: 2.405977725982666
Validation loss: 2.011404663324356

Epoch: 157| Step: 0
Training loss: 1.3705507516860962
Validation loss: 2.0129410376151404

Epoch: 5| Step: 1
Training loss: 2.0648980140686035
Validation loss: 2.0311464120944343

Epoch: 5| Step: 2
Training loss: 1.9083821773529053
Validation loss: 2.0297287652889886

Epoch: 5| Step: 3
Training loss: 1.767266869544983
Validation loss: 2.045117204387983

Epoch: 5| Step: 4
Training loss: 2.0130507946014404
Validation loss: 2.0501242528359094

Epoch: 5| Step: 5
Training loss: 2.5259885787963867
Validation loss: 2.0745901614427567

Epoch: 5| Step: 6
Training loss: 1.9748023748397827
Validation loss: 2.0718262096246085

Epoch: 5| Step: 7
Training loss: 1.99856436252594
Validation loss: 2.072395538290342

Epoch: 5| Step: 8
Training loss: 2.6988353729248047
Validation loss: 2.0703818947076797

Epoch: 5| Step: 9
Training loss: 2.1366395950317383
Validation loss: 2.0448056757450104

Epoch: 5| Step: 10
Training loss: 2.5369906425476074
Validation loss: 2.030308415492376

Epoch: 5| Step: 11
Training loss: 2.3024191856384277
Validation loss: 2.020681028564771

Epoch: 158| Step: 0
Training loss: 1.7148462533950806
Validation loss: 2.0168866713841758

Epoch: 5| Step: 1
Training loss: 1.790069580078125
Validation loss: 2.0198573569456735

Epoch: 5| Step: 2
Training loss: 1.6342926025390625
Validation loss: 2.0340757220983505

Epoch: 5| Step: 3
Training loss: 2.116687774658203
Validation loss: 2.0353127171595893

Epoch: 5| Step: 4
Training loss: 2.619140863418579
Validation loss: 2.029922733704249

Epoch: 5| Step: 5
Training loss: 2.291776418685913
Validation loss: 2.0491407414277396

Epoch: 5| Step: 6
Training loss: 2.2689990997314453
Validation loss: 2.0614709804455438

Epoch: 5| Step: 7
Training loss: 2.151642322540283
Validation loss: 2.0605865716934204

Epoch: 5| Step: 8
Training loss: 1.9100732803344727
Validation loss: 2.0560154169797897

Epoch: 5| Step: 9
Training loss: 2.334747791290283
Validation loss: 2.0654755930105844

Epoch: 5| Step: 10
Training loss: 1.74493408203125
Validation loss: 2.062604864438375

Epoch: 5| Step: 11
Training loss: 2.385924816131592
Validation loss: 2.057689666748047

Epoch: 159| Step: 0
Training loss: 2.184004783630371
Validation loss: 2.049582918485006

Epoch: 5| Step: 1
Training loss: 1.8978792428970337
Validation loss: 2.0312886784474053

Epoch: 5| Step: 2
Training loss: 2.039414644241333
Validation loss: 2.0412321935097375

Epoch: 5| Step: 3
Training loss: 1.964463233947754
Validation loss: 2.04732616742452

Epoch: 5| Step: 4
Training loss: 2.212808132171631
Validation loss: 2.0472551633914313

Epoch: 5| Step: 5
Training loss: 1.999847412109375
Validation loss: 2.0443768302599588

Epoch: 5| Step: 6
Training loss: 2.6016695499420166
Validation loss: 2.042576173941294

Epoch: 5| Step: 7
Training loss: 1.8484758138656616
Validation loss: 2.0338857769966125

Epoch: 5| Step: 8
Training loss: 2.465796709060669
Validation loss: 2.0375347286462784

Epoch: 5| Step: 9
Training loss: 2.5468974113464355
Validation loss: 2.031000624100367

Epoch: 5| Step: 10
Training loss: 1.68593430519104
Validation loss: 2.040274222691854

Epoch: 5| Step: 11
Training loss: 1.8318794965744019
Validation loss: 2.0383368829886117

Epoch: 160| Step: 0
Training loss: 1.862278938293457
Validation loss: 2.0280242462952933

Epoch: 5| Step: 1
Training loss: 1.8816566467285156
Validation loss: 2.024524728457133

Epoch: 5| Step: 2
Training loss: 1.7211099863052368
Validation loss: 2.0207748115062714

Epoch: 5| Step: 3
Training loss: 2.784703493118286
Validation loss: 2.0257027397553125

Epoch: 5| Step: 4
Training loss: 2.149942636489868
Validation loss: 2.019253134727478

Epoch: 5| Step: 5
Training loss: 2.1359755992889404
Validation loss: 2.0249570657809577

Epoch: 5| Step: 6
Training loss: 2.196160078048706
Validation loss: 2.0133870442708335

Epoch: 5| Step: 7
Training loss: 1.8477694988250732
Validation loss: 2.0241167843341827

Epoch: 5| Step: 8
Training loss: 1.8476568460464478
Validation loss: 2.0234947204589844

Epoch: 5| Step: 9
Training loss: 2.082650661468506
Validation loss: 2.0247191290060678

Epoch: 5| Step: 10
Training loss: 2.4685311317443848
Validation loss: 2.0256498008966446

Epoch: 5| Step: 11
Training loss: 2.509970188140869
Validation loss: 2.0286577343940735

Epoch: 161| Step: 0
Training loss: 2.1153411865234375
Validation loss: 2.0295684983332953

Epoch: 5| Step: 1
Training loss: 1.7469873428344727
Validation loss: 2.054257353146871

Epoch: 5| Step: 2
Training loss: 1.8411798477172852
Validation loss: 2.05623459815979

Epoch: 5| Step: 3
Training loss: 2.0431554317474365
Validation loss: 2.0636798640092215

Epoch: 5| Step: 4
Training loss: 2.383774757385254
Validation loss: 2.0712030827999115

Epoch: 5| Step: 5
Training loss: 1.9315541982650757
Validation loss: 2.073105067014694

Epoch: 5| Step: 6
Training loss: 2.47180438041687
Validation loss: 2.0626079539457955

Epoch: 5| Step: 7
Training loss: 2.2925899028778076
Validation loss: 2.0524409661690393

Epoch: 5| Step: 8
Training loss: 1.9468915462493896
Validation loss: 2.049205183982849

Epoch: 5| Step: 9
Training loss: 2.183314323425293
Validation loss: 2.0216167320807776

Epoch: 5| Step: 10
Training loss: 2.2406938076019287
Validation loss: 2.027713214357694

Epoch: 5| Step: 11
Training loss: 1.4504449367523193
Validation loss: 2.023986076315244

Epoch: 162| Step: 0
Training loss: 1.968116044998169
Validation loss: 2.020674392580986

Epoch: 5| Step: 1
Training loss: 1.834551215171814
Validation loss: 2.027582714955012

Epoch: 5| Step: 2
Training loss: 2.227393388748169
Validation loss: 2.0048061311244965

Epoch: 5| Step: 3
Training loss: 2.0045828819274902
Validation loss: 2.0088929732640586

Epoch: 5| Step: 4
Training loss: 1.7171669006347656
Validation loss: 2.0125753531853356

Epoch: 5| Step: 5
Training loss: 2.410679340362549
Validation loss: 2.02108267446359

Epoch: 5| Step: 6
Training loss: 1.7877237796783447
Validation loss: 2.015702227751414

Epoch: 5| Step: 7
Training loss: 2.011369228363037
Validation loss: 2.0241972158352532

Epoch: 5| Step: 8
Training loss: 2.350938320159912
Validation loss: 2.0246553073326745

Epoch: 5| Step: 9
Training loss: 2.3582286834716797
Validation loss: 2.032801926136017

Epoch: 5| Step: 10
Training loss: 2.1145191192626953
Validation loss: 2.044815535346667

Epoch: 5| Step: 11
Training loss: 1.632753849029541
Validation loss: 2.0527803798516593

Epoch: 163| Step: 0
Training loss: 1.9606212377548218
Validation loss: 2.0320050766070685

Epoch: 5| Step: 1
Training loss: 2.265143394470215
Validation loss: 2.0499204844236374

Epoch: 5| Step: 2
Training loss: 2.419361114501953
Validation loss: 2.0406010101238885

Epoch: 5| Step: 3
Training loss: 1.8235676288604736
Validation loss: 2.0285110026597977

Epoch: 5| Step: 4
Training loss: 2.1893677711486816
Validation loss: 2.0308789958556495

Epoch: 5| Step: 5
Training loss: 1.6926780939102173
Validation loss: 2.0336693276961646

Epoch: 5| Step: 6
Training loss: 2.0000946521759033
Validation loss: 2.0330564429362616

Epoch: 5| Step: 7
Training loss: 2.174649715423584
Validation loss: 2.032753278811773

Epoch: 5| Step: 8
Training loss: 2.075110912322998
Validation loss: 2.037001738945643

Epoch: 5| Step: 9
Training loss: 2.2099449634552
Validation loss: 2.0356965313355126

Epoch: 5| Step: 10
Training loss: 1.6878232955932617
Validation loss: 2.032502035299937

Epoch: 5| Step: 11
Training loss: 2.180265426635742
Validation loss: 2.0412531246741614

Epoch: 164| Step: 0
Training loss: 1.968963384628296
Validation loss: 2.0476041038831077

Epoch: 5| Step: 1
Training loss: 1.8369147777557373
Validation loss: 2.0387237121661506

Epoch: 5| Step: 2
Training loss: 1.7247661352157593
Validation loss: 2.0359003444512687

Epoch: 5| Step: 3
Training loss: 2.3973655700683594
Validation loss: 2.0346505641937256

Epoch: 5| Step: 4
Training loss: 1.9908539056777954
Validation loss: 2.039685303966204

Epoch: 5| Step: 5
Training loss: 1.8849378824234009
Validation loss: 2.039310743411382

Epoch: 5| Step: 6
Training loss: 1.8099126815795898
Validation loss: 2.04267825682958

Epoch: 5| Step: 7
Training loss: 2.212742328643799
Validation loss: 2.0495371917883554

Epoch: 5| Step: 8
Training loss: 2.241137981414795
Validation loss: 2.0453583846489587

Epoch: 5| Step: 9
Training loss: 2.190176010131836
Validation loss: 2.0447469105323157

Epoch: 5| Step: 10
Training loss: 2.101982831954956
Validation loss: 2.0496021757523217

Epoch: 5| Step: 11
Training loss: 2.056274175643921
Validation loss: 2.055987522006035

Epoch: 165| Step: 0
Training loss: 1.9779417514801025
Validation loss: 2.0554294139146805

Epoch: 5| Step: 1
Training loss: 2.3721046447753906
Validation loss: 2.0607213924328485

Epoch: 5| Step: 2
Training loss: 2.1417171955108643
Validation loss: 2.0688540985186896

Epoch: 5| Step: 3
Training loss: 1.70223069190979
Validation loss: 2.0709315836429596

Epoch: 5| Step: 4
Training loss: 1.657281517982483
Validation loss: 2.07220950225989

Epoch: 5| Step: 5
Training loss: 1.7371342182159424
Validation loss: 2.065177798271179

Epoch: 5| Step: 6
Training loss: 2.0100648403167725
Validation loss: 2.078075403968493

Epoch: 5| Step: 7
Training loss: 2.386794328689575
Validation loss: 2.0697537511587143

Epoch: 5| Step: 8
Training loss: 2.3052704334259033
Validation loss: 2.0761013279358544

Epoch: 5| Step: 9
Training loss: 2.072110652923584
Validation loss: 2.060270383954048

Epoch: 5| Step: 10
Training loss: 2.3076329231262207
Validation loss: 2.052602862318357

Epoch: 5| Step: 11
Training loss: 1.1861071586608887
Validation loss: 2.0493019819259644

Epoch: 166| Step: 0
Training loss: 2.0680887699127197
Validation loss: 2.057450607419014

Epoch: 5| Step: 1
Training loss: 2.0184402465820312
Validation loss: 2.0584317992130914

Epoch: 5| Step: 2
Training loss: 2.565948009490967
Validation loss: 2.0674610833326974

Epoch: 5| Step: 3
Training loss: 2.4293997287750244
Validation loss: 2.0726174165805182

Epoch: 5| Step: 4
Training loss: 1.636185884475708
Validation loss: 2.087731962402662

Epoch: 5| Step: 5
Training loss: 2.6969857215881348
Validation loss: 2.0864934970935187

Epoch: 5| Step: 6
Training loss: 1.4468804597854614
Validation loss: 2.071499993403753

Epoch: 5| Step: 7
Training loss: 1.711816430091858
Validation loss: 2.070596178372701

Epoch: 5| Step: 8
Training loss: 1.758294701576233
Validation loss: 2.0685330778360367

Epoch: 5| Step: 9
Training loss: 1.9040000438690186
Validation loss: 2.0612793217102685

Epoch: 5| Step: 10
Training loss: 2.3054049015045166
Validation loss: 2.0859413345654807

Epoch: 5| Step: 11
Training loss: 1.4284857511520386
Validation loss: 2.07814388970534

Epoch: 167| Step: 0
Training loss: 1.6104059219360352
Validation loss: 2.073584258556366

Epoch: 5| Step: 1
Training loss: 2.4634010791778564
Validation loss: 2.0843100349108377

Epoch: 5| Step: 2
Training loss: 1.7070884704589844
Validation loss: 2.084486131866773

Epoch: 5| Step: 3
Training loss: 1.8949472904205322
Validation loss: 2.0859345346689224

Epoch: 5| Step: 4
Training loss: 2.024003505706787
Validation loss: 2.0887230982383094

Epoch: 5| Step: 5
Training loss: 2.5740180015563965
Validation loss: 2.1005664666493735

Epoch: 5| Step: 6
Training loss: 2.1400704383850098
Validation loss: 2.096222092707952

Epoch: 5| Step: 7
Training loss: 2.1285459995269775
Validation loss: 2.088475669423739

Epoch: 5| Step: 8
Training loss: 2.070207118988037
Validation loss: 2.0793654223283133

Epoch: 5| Step: 9
Training loss: 1.815182089805603
Validation loss: 2.085522621870041

Epoch: 5| Step: 10
Training loss: 2.2632415294647217
Validation loss: 2.0776054362456002

Epoch: 5| Step: 11
Training loss: 0.35935068130493164
Validation loss: 2.0724925845861435

Epoch: 168| Step: 0
Training loss: 2.247922897338867
Validation loss: 2.0669970562060676

Epoch: 5| Step: 1
Training loss: 2.1784794330596924
Validation loss: 2.0660778880119324

Epoch: 5| Step: 2
Training loss: 1.6052770614624023
Validation loss: 2.061169077952703

Epoch: 5| Step: 3
Training loss: 2.4221043586730957
Validation loss: 2.064587786793709

Epoch: 5| Step: 4
Training loss: 1.7640403509140015
Validation loss: 2.060397227605184

Epoch: 5| Step: 5
Training loss: 2.065525531768799
Validation loss: 2.068395435810089

Epoch: 5| Step: 6
Training loss: 2.101145029067993
Validation loss: 2.0579602420330048

Epoch: 5| Step: 7
Training loss: 1.452350378036499
Validation loss: 2.0665642569462457

Epoch: 5| Step: 8
Training loss: 2.2931599617004395
Validation loss: 2.0651925007502236

Epoch: 5| Step: 9
Training loss: 1.947770118713379
Validation loss: 2.0641351441542306

Epoch: 5| Step: 10
Training loss: 2.522125244140625
Validation loss: 2.0734324057896933

Epoch: 5| Step: 11
Training loss: 0.6102906465530396
Validation loss: 2.0716309249401093

Epoch: 169| Step: 0
Training loss: 2.00282883644104
Validation loss: 2.0748903999725976

Epoch: 5| Step: 1
Training loss: 2.1980016231536865
Validation loss: 2.071211819847425

Epoch: 5| Step: 2
Training loss: 1.3976343870162964
Validation loss: 2.0695123374462128

Epoch: 5| Step: 3
Training loss: 2.0727901458740234
Validation loss: 2.0591218223174415

Epoch: 5| Step: 4
Training loss: 1.7918274402618408
Validation loss: 2.060752044121424

Epoch: 5| Step: 5
Training loss: 2.2570719718933105
Validation loss: 2.0689739336570105

Epoch: 5| Step: 6
Training loss: 1.5764799118041992
Validation loss: 2.0722067107756934

Epoch: 5| Step: 7
Training loss: 2.2243006229400635
Validation loss: 2.068643535176913

Epoch: 5| Step: 8
Training loss: 2.3083810806274414
Validation loss: 2.0742007543643317

Epoch: 5| Step: 9
Training loss: 2.19012713432312
Validation loss: 2.078651691476504

Epoch: 5| Step: 10
Training loss: 2.421801805496216
Validation loss: 2.0615662783384323

Epoch: 5| Step: 11
Training loss: 1.081223487854004
Validation loss: 2.049121911327044

Epoch: 170| Step: 0
Training loss: 1.718518853187561
Validation loss: 2.0550669034322104

Epoch: 5| Step: 1
Training loss: 2.2811503410339355
Validation loss: 2.068299020330111

Epoch: 5| Step: 2
Training loss: 2.175105333328247
Validation loss: 2.0664529552062354

Epoch: 5| Step: 3
Training loss: 1.5170962810516357
Validation loss: 2.0626431107521057

Epoch: 5| Step: 4
Training loss: 2.8066775798797607
Validation loss: 2.0647119681040444

Epoch: 5| Step: 5
Training loss: 1.8744739294052124
Validation loss: 2.0647196223338447

Epoch: 5| Step: 6
Training loss: 2.0136818885803223
Validation loss: 2.055861925085386

Epoch: 5| Step: 7
Training loss: 1.6562217473983765
Validation loss: 2.0562635163466134

Epoch: 5| Step: 8
Training loss: 2.067802667617798
Validation loss: 2.0634454041719437

Epoch: 5| Step: 9
Training loss: 2.540320873260498
Validation loss: 2.055406868457794

Epoch: 5| Step: 10
Training loss: 1.6942096948623657
Validation loss: 2.0677422980467477

Epoch: 5| Step: 11
Training loss: 1.1102460622787476
Validation loss: 2.0599382321039834

Epoch: 171| Step: 0
Training loss: 1.7476898431777954
Validation loss: 2.064891497294108

Epoch: 5| Step: 1
Training loss: 2.0493617057800293
Validation loss: 2.049248824516932

Epoch: 5| Step: 2
Training loss: 2.2014973163604736
Validation loss: 2.047610272963842

Epoch: 5| Step: 3
Training loss: 2.7855746746063232
Validation loss: 2.0421487192312875

Epoch: 5| Step: 4
Training loss: 1.797576665878296
Validation loss: 2.0564482609430947

Epoch: 5| Step: 5
Training loss: 2.096611738204956
Validation loss: 2.045437460144361

Epoch: 5| Step: 6
Training loss: 1.5535485744476318
Validation loss: 2.0552812417348227

Epoch: 5| Step: 7
Training loss: 2.4024460315704346
Validation loss: 2.05384091536204

Epoch: 5| Step: 8
Training loss: 2.4021637439727783
Validation loss: 2.056937982638677

Epoch: 5| Step: 9
Training loss: 1.6203216314315796
Validation loss: 2.0672786931196847

Epoch: 5| Step: 10
Training loss: 1.7430216073989868
Validation loss: 2.080969567100207

Epoch: 5| Step: 11
Training loss: 1.5896201133728027
Validation loss: 2.0831385304530463

Epoch: 172| Step: 0
Training loss: 2.097628116607666
Validation loss: 2.079662705461184

Epoch: 5| Step: 1
Training loss: 1.8993009328842163
Validation loss: 2.0918977608283362

Epoch: 5| Step: 2
Training loss: 2.128255605697632
Validation loss: 2.107253243525823

Epoch: 5| Step: 3
Training loss: 1.8807048797607422
Validation loss: 2.116835335890452

Epoch: 5| Step: 4
Training loss: 2.1887574195861816
Validation loss: 2.098024452726046

Epoch: 5| Step: 5
Training loss: 1.868419885635376
Validation loss: 2.104968403776487

Epoch: 5| Step: 6
Training loss: 2.31972074508667
Validation loss: 2.1007153540849686

Epoch: 5| Step: 7
Training loss: 2.2651896476745605
Validation loss: 2.0929312904675803

Epoch: 5| Step: 8
Training loss: 1.7976105213165283
Validation loss: 2.0667332063118615

Epoch: 5| Step: 9
Training loss: 1.6945810317993164
Validation loss: 2.0652493139108024

Epoch: 5| Step: 10
Training loss: 2.177213430404663
Validation loss: 2.058521176377932

Epoch: 5| Step: 11
Training loss: 2.113997220993042
Validation loss: 2.050911913315455

Epoch: 173| Step: 0
Training loss: 2.2141895294189453
Validation loss: 2.0558058669169745

Epoch: 5| Step: 1
Training loss: 1.928270697593689
Validation loss: 2.059025893608729

Epoch: 5| Step: 2
Training loss: 2.3931069374084473
Validation loss: 2.0496772627035775

Epoch: 5| Step: 3
Training loss: 2.443303346633911
Validation loss: 2.0554793973763785

Epoch: 5| Step: 4
Training loss: 2.0926690101623535
Validation loss: 2.0645461678504944

Epoch: 5| Step: 5
Training loss: 2.410163164138794
Validation loss: 2.0698734323183694

Epoch: 5| Step: 6
Training loss: 1.7387367486953735
Validation loss: 2.073551674683889

Epoch: 5| Step: 7
Training loss: 2.1538405418395996
Validation loss: 2.0817278822263083

Epoch: 5| Step: 8
Training loss: 1.8121626377105713
Validation loss: 2.068117087086042

Epoch: 5| Step: 9
Training loss: 1.7599334716796875
Validation loss: 2.075356423854828

Epoch: 5| Step: 10
Training loss: 1.6006278991699219
Validation loss: 2.0791479696830115

Epoch: 5| Step: 11
Training loss: 1.3942288160324097
Validation loss: 2.0756134589513144

Epoch: 174| Step: 0
Training loss: 2.1942431926727295
Validation loss: 2.089748074611028

Epoch: 5| Step: 1
Training loss: 1.7961562871932983
Validation loss: 2.074705253044764

Epoch: 5| Step: 2
Training loss: 2.4898970127105713
Validation loss: 2.0698507030804953

Epoch: 5| Step: 3
Training loss: 2.08748459815979
Validation loss: 2.0664916932582855

Epoch: 5| Step: 4
Training loss: 1.9525893926620483
Validation loss: 2.064823324481646

Epoch: 5| Step: 5
Training loss: 1.9864509105682373
Validation loss: 2.061481922864914

Epoch: 5| Step: 6
Training loss: 1.6279428005218506
Validation loss: 2.051561956604322

Epoch: 5| Step: 7
Training loss: 1.6935949325561523
Validation loss: 2.0441530694564185

Epoch: 5| Step: 8
Training loss: 1.8275493383407593
Validation loss: 2.05194815993309

Epoch: 5| Step: 9
Training loss: 2.1995584964752197
Validation loss: 2.0518826693296432

Epoch: 5| Step: 10
Training loss: 2.6588714122772217
Validation loss: 2.0556991696357727

Epoch: 5| Step: 11
Training loss: 0.5455823540687561
Validation loss: 2.0627800275882087

Epoch: 175| Step: 0
Training loss: 2.431129217147827
Validation loss: 2.0551981379588447

Epoch: 5| Step: 1
Training loss: 1.8681656122207642
Validation loss: 2.0661340057849884

Epoch: 5| Step: 2
Training loss: 1.8843088150024414
Validation loss: 2.055918743213018

Epoch: 5| Step: 3
Training loss: 1.7852932214736938
Validation loss: 2.0683902154366174

Epoch: 5| Step: 4
Training loss: 2.2138359546661377
Validation loss: 2.0586245010296502

Epoch: 5| Step: 5
Training loss: 1.697365164756775
Validation loss: 2.0502153833707175

Epoch: 5| Step: 6
Training loss: 1.8312342166900635
Validation loss: 2.0610241144895554

Epoch: 5| Step: 7
Training loss: 1.9501384496688843
Validation loss: 2.066326359907786

Epoch: 5| Step: 8
Training loss: 2.249678134918213
Validation loss: 2.053344721595446

Epoch: 5| Step: 9
Training loss: 1.8880853652954102
Validation loss: 2.077226216594378

Epoch: 5| Step: 10
Training loss: 2.2405428886413574
Validation loss: 2.0590936789909997

Epoch: 5| Step: 11
Training loss: 2.0670254230499268
Validation loss: 2.0697858035564423

Epoch: 176| Step: 0
Training loss: 1.737363576889038
Validation loss: 2.0739401131868362

Epoch: 5| Step: 1
Training loss: 2.0261120796203613
Validation loss: 2.077471454938253

Epoch: 5| Step: 2
Training loss: 2.1728010177612305
Validation loss: 2.0889626940091452

Epoch: 5| Step: 3
Training loss: 2.789651393890381
Validation loss: 2.090972160299619

Epoch: 5| Step: 4
Training loss: 2.1911518573760986
Validation loss: 2.09608685473601

Epoch: 5| Step: 5
Training loss: 2.2148706912994385
Validation loss: 2.1022267589966455

Epoch: 5| Step: 6
Training loss: 2.345956325531006
Validation loss: 2.0972577879826226

Epoch: 5| Step: 7
Training loss: 1.2449431419372559
Validation loss: 2.0929572681585946

Epoch: 5| Step: 8
Training loss: 1.787095069885254
Validation loss: 2.0906977355480194

Epoch: 5| Step: 9
Training loss: 2.288656234741211
Validation loss: 2.086265429854393

Epoch: 5| Step: 10
Training loss: 1.483777403831482
Validation loss: 2.091857378681501

Epoch: 5| Step: 11
Training loss: 1.515927791595459
Validation loss: 2.08941983183225

Epoch: 177| Step: 0
Training loss: 2.4114036560058594
Validation loss: 2.091690873106321

Epoch: 5| Step: 1
Training loss: 1.5476408004760742
Validation loss: 2.074931134780248

Epoch: 5| Step: 2
Training loss: 1.9282296895980835
Validation loss: 2.0890440742174783

Epoch: 5| Step: 3
Training loss: 1.9198631048202515
Validation loss: 2.090746283531189

Epoch: 5| Step: 4
Training loss: 2.005241870880127
Validation loss: 2.096964806318283

Epoch: 5| Step: 5
Training loss: 1.5809959173202515
Validation loss: 2.0985553860664368

Epoch: 5| Step: 6
Training loss: 1.9260532855987549
Validation loss: 2.0967938204606376

Epoch: 5| Step: 7
Training loss: 2.4479994773864746
Validation loss: 2.0979308038949966

Epoch: 5| Step: 8
Training loss: 2.012186050415039
Validation loss: 2.0852274845043817

Epoch: 5| Step: 9
Training loss: 1.9818958044052124
Validation loss: 2.092015817761421

Epoch: 5| Step: 10
Training loss: 2.1990532875061035
Validation loss: 2.0974338948726654

Epoch: 5| Step: 11
Training loss: 1.7067129611968994
Validation loss: 2.093655228614807

Epoch: 178| Step: 0
Training loss: 1.8993263244628906
Validation loss: 2.1001080522934594

Epoch: 5| Step: 1
Training loss: 1.6791874170303345
Validation loss: 2.1077928990125656

Epoch: 5| Step: 2
Training loss: 1.797808051109314
Validation loss: 2.114798218011856

Epoch: 5| Step: 3
Training loss: 2.4462978839874268
Validation loss: 2.1103150298198066

Epoch: 5| Step: 4
Training loss: 1.8010473251342773
Validation loss: 2.1170835544665656

Epoch: 5| Step: 5
Training loss: 1.9014736413955688
Validation loss: 2.102156018217405

Epoch: 5| Step: 6
Training loss: 2.1409125328063965
Validation loss: 2.098562325040499

Epoch: 5| Step: 7
Training loss: 1.68363356590271
Validation loss: 2.098044986526171

Epoch: 5| Step: 8
Training loss: 2.539396047592163
Validation loss: 2.097323397795359

Epoch: 5| Step: 9
Training loss: 1.901127815246582
Validation loss: 2.0973057001829147

Epoch: 5| Step: 10
Training loss: 2.2665443420410156
Validation loss: 2.099989205598831

Epoch: 5| Step: 11
Training loss: 2.0178167819976807
Validation loss: 2.0899108052253723

Epoch: 179| Step: 0
Training loss: 1.8651084899902344
Validation loss: 2.091565186778704

Epoch: 5| Step: 1
Training loss: 1.7494319677352905
Validation loss: 2.093523010611534

Epoch: 5| Step: 2
Training loss: 2.193589687347412
Validation loss: 2.0813707063595452

Epoch: 5| Step: 3
Training loss: 1.6065261363983154
Validation loss: 2.097212548057238

Epoch: 5| Step: 4
Training loss: 1.9614568948745728
Validation loss: 2.093271861473719

Epoch: 5| Step: 5
Training loss: 2.376182794570923
Validation loss: 2.0942672242720923

Epoch: 5| Step: 6
Training loss: 2.3043572902679443
Validation loss: 2.0921636869510016

Epoch: 5| Step: 7
Training loss: 2.086212158203125
Validation loss: 2.1012642284234366

Epoch: 5| Step: 8
Training loss: 1.9654276371002197
Validation loss: 2.098553796609243

Epoch: 5| Step: 9
Training loss: 2.054105043411255
Validation loss: 2.103416790564855

Epoch: 5| Step: 10
Training loss: 1.7369426488876343
Validation loss: 2.0950314352909722

Epoch: 5| Step: 11
Training loss: 1.6459952592849731
Validation loss: 2.0890747606754303

Epoch: 180| Step: 0
Training loss: 2.209916591644287
Validation loss: 2.083274483680725

Epoch: 5| Step: 1
Training loss: 2.1266984939575195
Validation loss: 2.081090748310089

Epoch: 5| Step: 2
Training loss: 2.1765379905700684
Validation loss: 2.0767135272423425

Epoch: 5| Step: 3
Training loss: 1.8518272638320923
Validation loss: 2.081788182258606

Epoch: 5| Step: 4
Training loss: 1.967373251914978
Validation loss: 2.080497751633326

Epoch: 5| Step: 5
Training loss: 1.9514118432998657
Validation loss: 2.092152093847593

Epoch: 5| Step: 6
Training loss: 2.107903003692627
Validation loss: 2.0992493629455566

Epoch: 5| Step: 7
Training loss: 1.5137081146240234
Validation loss: 2.093871926267942

Epoch: 5| Step: 8
Training loss: 2.158830404281616
Validation loss: 2.1046726604302726

Epoch: 5| Step: 9
Training loss: 1.6624701023101807
Validation loss: 2.1022512912750244

Epoch: 5| Step: 10
Training loss: 2.205627918243408
Validation loss: 2.104941005508105

Epoch: 5| Step: 11
Training loss: 2.389791488647461
Validation loss: 2.120584194858869

Epoch: 181| Step: 0
Training loss: 1.991302728652954
Validation loss: 2.0858173271020255

Epoch: 5| Step: 1
Training loss: 2.1912078857421875
Validation loss: 2.093550463517507

Epoch: 5| Step: 2
Training loss: 2.4205310344696045
Validation loss: 2.074981148044268

Epoch: 5| Step: 3
Training loss: 1.553646206855774
Validation loss: 2.075283318758011

Epoch: 5| Step: 4
Training loss: 2.192389488220215
Validation loss: 2.072768822312355

Epoch: 5| Step: 5
Training loss: 1.902418851852417
Validation loss: 2.082894523938497

Epoch: 5| Step: 6
Training loss: 1.7757740020751953
Validation loss: 2.0791693031787872

Epoch: 5| Step: 7
Training loss: 2.003547191619873
Validation loss: 2.0764106065034866

Epoch: 5| Step: 8
Training loss: 2.0737876892089844
Validation loss: 2.0755916039148965

Epoch: 5| Step: 9
Training loss: 1.7422077655792236
Validation loss: 2.0796790371338525

Epoch: 5| Step: 10
Training loss: 2.5009236335754395
Validation loss: 2.0795323302348456

Epoch: 5| Step: 11
Training loss: 1.6823318004608154
Validation loss: 2.083630050222079

Epoch: 182| Step: 0
Training loss: 1.6401675939559937
Validation loss: 2.0841473092635474

Epoch: 5| Step: 1
Training loss: 1.350055456161499
Validation loss: 2.0856206814448037

Epoch: 5| Step: 2
Training loss: 2.343683958053589
Validation loss: 2.077768847346306

Epoch: 5| Step: 3
Training loss: 2.1820662021636963
Validation loss: 2.093045378724734

Epoch: 5| Step: 4
Training loss: 2.451245069503784
Validation loss: 2.100406358639399

Epoch: 5| Step: 5
Training loss: 1.4917325973510742
Validation loss: 2.1139665146668754

Epoch: 5| Step: 6
Training loss: 1.7795944213867188
Validation loss: 2.111483166615168

Epoch: 5| Step: 7
Training loss: 2.509735345840454
Validation loss: 2.1135810961325965

Epoch: 5| Step: 8
Training loss: 2.1136274337768555
Validation loss: 2.105611572662989

Epoch: 5| Step: 9
Training loss: 1.8227970600128174
Validation loss: 2.1055010805527368

Epoch: 5| Step: 10
Training loss: 2.5516772270202637
Validation loss: 2.1035478115081787

Epoch: 5| Step: 11
Training loss: 0.8214928507804871
Validation loss: 2.0927697271108627

Epoch: 183| Step: 0
Training loss: 2.4504332542419434
Validation loss: 2.081619461377462

Epoch: 5| Step: 1
Training loss: 1.6882717609405518
Validation loss: 2.0610156605641046

Epoch: 5| Step: 2
Training loss: 2.0286686420440674
Validation loss: 2.06600014368693

Epoch: 5| Step: 3
Training loss: 1.7335844039916992
Validation loss: 2.0557061384121575

Epoch: 5| Step: 4
Training loss: 1.8720775842666626
Validation loss: 2.0571162501970925

Epoch: 5| Step: 5
Training loss: 2.043978214263916
Validation loss: 2.0590679744879403

Epoch: 5| Step: 6
Training loss: 2.4297103881835938
Validation loss: 2.053198426961899

Epoch: 5| Step: 7
Training loss: 2.168104648590088
Validation loss: 2.057576894760132

Epoch: 5| Step: 8
Training loss: 1.8691365718841553
Validation loss: 2.0600410451491675

Epoch: 5| Step: 9
Training loss: 2.3033947944641113
Validation loss: 2.0602183640003204

Epoch: 5| Step: 10
Training loss: 1.7755050659179688
Validation loss: 2.065466528137525

Epoch: 5| Step: 11
Training loss: 2.061032772064209
Validation loss: 2.0689077576001487

Epoch: 184| Step: 0
Training loss: 1.7703415155410767
Validation loss: 2.069219489892324

Epoch: 5| Step: 1
Training loss: 1.8454726934432983
Validation loss: 2.085276941458384

Epoch: 5| Step: 2
Training loss: 1.872436761856079
Validation loss: 2.078554371992747

Epoch: 5| Step: 3
Training loss: 1.9844987392425537
Validation loss: 2.071782941619555

Epoch: 5| Step: 4
Training loss: 2.248709201812744
Validation loss: 2.084637771050135

Epoch: 5| Step: 5
Training loss: 2.005685329437256
Validation loss: 2.086401104927063

Epoch: 5| Step: 6
Training loss: 1.836956262588501
Validation loss: 2.0780220379432044

Epoch: 5| Step: 7
Training loss: 2.1967766284942627
Validation loss: 2.0750535329182944

Epoch: 5| Step: 8
Training loss: 1.800562858581543
Validation loss: 2.067776143550873

Epoch: 5| Step: 9
Training loss: 2.09729266166687
Validation loss: 2.082239051659902

Epoch: 5| Step: 10
Training loss: 2.1692473888397217
Validation loss: 2.0744154850641885

Epoch: 5| Step: 11
Training loss: 2.9424426555633545
Validation loss: 2.0826642513275146

Epoch: 185| Step: 0
Training loss: 2.2667250633239746
Validation loss: 2.078870261708895

Epoch: 5| Step: 1
Training loss: 1.9022443294525146
Validation loss: 2.072927857438723

Epoch: 5| Step: 2
Training loss: 2.0471339225769043
Validation loss: 2.086330682039261

Epoch: 5| Step: 3
Training loss: 1.857862114906311
Validation loss: 2.095530559619268

Epoch: 5| Step: 4
Training loss: 1.8941729068756104
Validation loss: 2.0992567936579385

Epoch: 5| Step: 5
Training loss: 2.6134233474731445
Validation loss: 2.0887241860230765

Epoch: 5| Step: 6
Training loss: 1.6794073581695557
Validation loss: 2.087495485941569

Epoch: 5| Step: 7
Training loss: 1.2964065074920654
Validation loss: 2.0946936508019767

Epoch: 5| Step: 8
Training loss: 1.9812896251678467
Validation loss: 2.1106602251529694

Epoch: 5| Step: 9
Training loss: 1.9504445791244507
Validation loss: 2.1069816847642264

Epoch: 5| Step: 10
Training loss: 2.130878448486328
Validation loss: 2.0943118582169213

Epoch: 5| Step: 11
Training loss: 2.0195207595825195
Validation loss: 2.1042428414026895

Epoch: 186| Step: 0
Training loss: 1.453521490097046
Validation loss: 2.099823380510012

Epoch: 5| Step: 1
Training loss: 1.7201197147369385
Validation loss: 2.0936869333187738

Epoch: 5| Step: 2
Training loss: 1.9750359058380127
Validation loss: 2.0989128202199936

Epoch: 5| Step: 3
Training loss: 1.8165868520736694
Validation loss: 2.1004925866921744

Epoch: 5| Step: 4
Training loss: 2.280644178390503
Validation loss: 2.0984338025252023

Epoch: 5| Step: 5
Training loss: 1.9924873113632202
Validation loss: 2.091946949561437

Epoch: 5| Step: 6
Training loss: 2.0062434673309326
Validation loss: 2.0914803743362427

Epoch: 5| Step: 7
Training loss: 2.7924437522888184
Validation loss: 2.0849421471357346

Epoch: 5| Step: 8
Training loss: 2.191131591796875
Validation loss: 2.0896102537711463

Epoch: 5| Step: 9
Training loss: 1.7759917974472046
Validation loss: 2.0875124682982764

Epoch: 5| Step: 10
Training loss: 1.9207489490509033
Validation loss: 2.097053994735082

Epoch: 5| Step: 11
Training loss: 1.3351173400878906
Validation loss: 2.101821541786194

Epoch: 187| Step: 0
Training loss: 2.005128860473633
Validation loss: 2.103058139483134

Epoch: 5| Step: 1
Training loss: 2.160395622253418
Validation loss: 2.105971485376358

Epoch: 5| Step: 2
Training loss: 1.4238619804382324
Validation loss: 2.1189659585555396

Epoch: 5| Step: 3
Training loss: 1.7719299793243408
Validation loss: 2.104225372274717

Epoch: 5| Step: 4
Training loss: 2.264030933380127
Validation loss: 2.1170367002487183

Epoch: 5| Step: 5
Training loss: 2.493711233139038
Validation loss: 2.1280208975076675

Epoch: 5| Step: 6
Training loss: 1.9804496765136719
Validation loss: 2.1313773741324744

Epoch: 5| Step: 7
Training loss: 1.850175142288208
Validation loss: 2.1313879688580832

Epoch: 5| Step: 8
Training loss: 2.2962453365325928
Validation loss: 2.119737813870112

Epoch: 5| Step: 9
Training loss: 1.7526061534881592
Validation loss: 2.128280738989512

Epoch: 5| Step: 10
Training loss: 1.8281714916229248
Validation loss: 2.109400396545728

Epoch: 5| Step: 11
Training loss: 1.0868555307388306
Validation loss: 2.1056587298711142

Epoch: 188| Step: 0
Training loss: 2.239837646484375
Validation loss: 2.0904793639977775

Epoch: 5| Step: 1
Training loss: 2.431577682495117
Validation loss: 2.0877883285284042

Epoch: 5| Step: 2
Training loss: 1.6608238220214844
Validation loss: 2.0752102931340537

Epoch: 5| Step: 3
Training loss: 2.199530601501465
Validation loss: 2.08699439962705

Epoch: 5| Step: 4
Training loss: 2.0582220554351807
Validation loss: 2.0812936077515283

Epoch: 5| Step: 5
Training loss: 2.293077230453491
Validation loss: 2.069355309009552

Epoch: 5| Step: 6
Training loss: 1.8660767078399658
Validation loss: 2.079828937848409

Epoch: 5| Step: 7
Training loss: 2.2117726802825928
Validation loss: 2.0861360281705856

Epoch: 5| Step: 8
Training loss: 1.64316725730896
Validation loss: 2.087443709373474

Epoch: 5| Step: 9
Training loss: 1.6716573238372803
Validation loss: 2.0906156996885934

Epoch: 5| Step: 10
Training loss: 1.5465344190597534
Validation loss: 2.092376177509626

Epoch: 5| Step: 11
Training loss: 2.774197578430176
Validation loss: 2.0966693808635077

Epoch: 189| Step: 0
Training loss: 2.2424426078796387
Validation loss: 2.110673646132151

Epoch: 5| Step: 1
Training loss: 2.3430962562561035
Validation loss: 2.1044834752877555

Epoch: 5| Step: 2
Training loss: 2.289958953857422
Validation loss: 2.1093747913837433

Epoch: 5| Step: 3
Training loss: 2.006399154663086
Validation loss: 2.099281594157219

Epoch: 5| Step: 4
Training loss: 2.4240474700927734
Validation loss: 2.100956459840139

Epoch: 5| Step: 5
Training loss: 1.9548885822296143
Validation loss: 2.080901011824608

Epoch: 5| Step: 6
Training loss: 1.7939796447753906
Validation loss: 2.0892205784718194

Epoch: 5| Step: 7
Training loss: 1.3925559520721436
Validation loss: 2.092887739340464

Epoch: 5| Step: 8
Training loss: 1.6494499444961548
Validation loss: 2.0872706522544227

Epoch: 5| Step: 9
Training loss: 2.420275926589966
Validation loss: 2.0994639297326407

Epoch: 5| Step: 10
Training loss: 1.4968546628952026
Validation loss: 2.096360146999359

Epoch: 5| Step: 11
Training loss: 1.4603694677352905
Validation loss: 2.1061797191699347

Epoch: 190| Step: 0
Training loss: 1.7425973415374756
Validation loss: 2.1039097756147385

Epoch: 5| Step: 1
Training loss: 1.8676782846450806
Validation loss: 2.1025672952334085

Epoch: 5| Step: 2
Training loss: 2.047107696533203
Validation loss: 2.1020598908265433

Epoch: 5| Step: 3
Training loss: 1.9777930974960327
Validation loss: 2.101144567131996

Epoch: 5| Step: 4
Training loss: 1.4713886976242065
Validation loss: 2.107002710302671

Epoch: 5| Step: 5
Training loss: 1.8632612228393555
Validation loss: 2.101374000310898

Epoch: 5| Step: 6
Training loss: 2.58107590675354
Validation loss: 2.0989912152290344

Epoch: 5| Step: 7
Training loss: 2.1033902168273926
Validation loss: 2.1127409636974335

Epoch: 5| Step: 8
Training loss: 1.9066555500030518
Validation loss: 2.112942785024643

Epoch: 5| Step: 9
Training loss: 2.4909605979919434
Validation loss: 2.115231583515803

Epoch: 5| Step: 10
Training loss: 1.8785699605941772
Validation loss: 2.114427089691162

Epoch: 5| Step: 11
Training loss: 0.6226071119308472
Validation loss: 2.1127429058154426

Epoch: 191| Step: 0
Training loss: 1.8266938924789429
Validation loss: 2.1077383756637573

Epoch: 5| Step: 1
Training loss: 2.362123489379883
Validation loss: 2.0974231958389282

Epoch: 5| Step: 2
Training loss: 1.8685176372528076
Validation loss: 2.103280300895373

Epoch: 5| Step: 3
Training loss: 1.3131214380264282
Validation loss: 2.089686701695124

Epoch: 5| Step: 4
Training loss: 2.20867919921875
Validation loss: 2.089670484264692

Epoch: 5| Step: 5
Training loss: 1.8998775482177734
Validation loss: 2.082401638229688

Epoch: 5| Step: 6
Training loss: 2.2702248096466064
Validation loss: 2.0857695092757544

Epoch: 5| Step: 7
Training loss: 1.8467166423797607
Validation loss: 2.089847798148791

Epoch: 5| Step: 8
Training loss: 1.8967316150665283
Validation loss: 2.091077799598376

Epoch: 5| Step: 9
Training loss: 2.303847074508667
Validation loss: 2.0995880365371704

Epoch: 5| Step: 10
Training loss: 1.7671597003936768
Validation loss: 2.0901295294364295

Epoch: 5| Step: 11
Training loss: 1.7993333339691162
Validation loss: 2.094438816110293

Epoch: 192| Step: 0
Training loss: 1.7716480493545532
Validation loss: 2.1052283545335135

Epoch: 5| Step: 1
Training loss: 1.9279835224151611
Validation loss: 2.1020464450120926

Epoch: 5| Step: 2
Training loss: 1.555319905281067
Validation loss: 2.0960500836372375

Epoch: 5| Step: 3
Training loss: 2.0628066062927246
Validation loss: 2.0967132846514382

Epoch: 5| Step: 4
Training loss: 1.8033654689788818
Validation loss: 2.0926261941591897

Epoch: 5| Step: 5
Training loss: 2.1191554069519043
Validation loss: 2.0883696377277374

Epoch: 5| Step: 6
Training loss: 1.8976236581802368
Validation loss: 2.097048650185267

Epoch: 5| Step: 7
Training loss: 2.1511950492858887
Validation loss: 2.0848267525434494

Epoch: 5| Step: 8
Training loss: 1.7609859704971313
Validation loss: 2.084544931848844

Epoch: 5| Step: 9
Training loss: 2.3823471069335938
Validation loss: 2.065314546227455

Epoch: 5| Step: 10
Training loss: 2.309906482696533
Validation loss: 2.0619252175092697

Epoch: 5| Step: 11
Training loss: 2.67057466506958
Validation loss: 2.0500940879185996

Epoch: 193| Step: 0
Training loss: 2.2324821949005127
Validation loss: 2.0592890282471976

Epoch: 5| Step: 1
Training loss: 2.585853099822998
Validation loss: 2.062765200932821

Epoch: 5| Step: 2
Training loss: 1.9676532745361328
Validation loss: 2.064533914128939

Epoch: 5| Step: 3
Training loss: 1.7894036769866943
Validation loss: 2.0554387221733728

Epoch: 5| Step: 4
Training loss: 2.332575559616089
Validation loss: 2.0660160879294076

Epoch: 5| Step: 5
Training loss: 1.6157872676849365
Validation loss: 2.0654863119125366

Epoch: 5| Step: 6
Training loss: 1.9035171270370483
Validation loss: 2.0777777334054313

Epoch: 5| Step: 7
Training loss: 1.4550870656967163
Validation loss: 2.0725898693005242

Epoch: 5| Step: 8
Training loss: 2.2248775959014893
Validation loss: 2.0818138470252356

Epoch: 5| Step: 9
Training loss: 2.155733108520508
Validation loss: 2.087621654073397

Epoch: 5| Step: 10
Training loss: 1.773850440979004
Validation loss: 2.0755212555329003

Epoch: 5| Step: 11
Training loss: 1.5814849138259888
Validation loss: 2.074379041790962

Epoch: 194| Step: 0
Training loss: 1.778076410293579
Validation loss: 2.0777959724267325

Epoch: 5| Step: 1
Training loss: 1.439054250717163
Validation loss: 2.0688349157571793

Epoch: 5| Step: 2
Training loss: 2.2234444618225098
Validation loss: 2.0564648608366647

Epoch: 5| Step: 3
Training loss: 2.202536106109619
Validation loss: 2.064858853816986

Epoch: 5| Step: 4
Training loss: 2.391200304031372
Validation loss: 2.0709417114655175

Epoch: 5| Step: 5
Training loss: 2.3790555000305176
Validation loss: 2.0580497086048126

Epoch: 5| Step: 6
Training loss: 1.658864974975586
Validation loss: 2.0660416384538016

Epoch: 5| Step: 7
Training loss: 1.6024049520492554
Validation loss: 2.0807689080635705

Epoch: 5| Step: 8
Training loss: 2.110961437225342
Validation loss: 2.0866732001304626

Epoch: 5| Step: 9
Training loss: 2.4894280433654785
Validation loss: 2.0911125242710114

Epoch: 5| Step: 10
Training loss: 1.5813511610031128
Validation loss: 2.087556133667628

Epoch: 5| Step: 11
Training loss: 1.5013110637664795
Validation loss: 2.0795562664667764

Epoch: 195| Step: 0
Training loss: 1.840417504310608
Validation loss: 2.092073659102122

Epoch: 5| Step: 1
Training loss: 1.8880388736724854
Validation loss: 2.0834768414497375

Epoch: 5| Step: 2
Training loss: 1.9783132076263428
Validation loss: 2.0727992256482444

Epoch: 5| Step: 3
Training loss: 1.937416434288025
Validation loss: 2.0726442535718284

Epoch: 5| Step: 4
Training loss: 2.0837535858154297
Validation loss: 2.072117785612742

Epoch: 5| Step: 5
Training loss: 2.1470894813537598
Validation loss: 2.0760340789953866

Epoch: 5| Step: 6
Training loss: 2.1319022178649902
Validation loss: 2.0801449020703635

Epoch: 5| Step: 7
Training loss: 2.0976719856262207
Validation loss: 2.0650240580240884

Epoch: 5| Step: 8
Training loss: 2.1974966526031494
Validation loss: 2.084441691637039

Epoch: 5| Step: 9
Training loss: 1.8360977172851562
Validation loss: 2.063788781563441

Epoch: 5| Step: 10
Training loss: 1.6678054332733154
Validation loss: 2.0708838601907096

Epoch: 5| Step: 11
Training loss: 2.376521587371826
Validation loss: 2.0704801827669144

Epoch: 196| Step: 0
Training loss: 1.9471123218536377
Validation loss: 2.0698337703943253

Epoch: 5| Step: 1
Training loss: 1.938846230506897
Validation loss: 2.0648329059282937

Epoch: 5| Step: 2
Training loss: 1.5483509302139282
Validation loss: 2.0728252877791724

Epoch: 5| Step: 3
Training loss: 2.1542158126831055
Validation loss: 2.0705111722151437

Epoch: 5| Step: 4
Training loss: 1.8362598419189453
Validation loss: 2.0818470617135367

Epoch: 5| Step: 5
Training loss: 1.9939899444580078
Validation loss: 2.0803856203953424

Epoch: 5| Step: 6
Training loss: 2.0517382621765137
Validation loss: 2.1060507794221244

Epoch: 5| Step: 7
Training loss: 2.1394965648651123
Validation loss: 2.096082871158918

Epoch: 5| Step: 8
Training loss: 1.6155723333358765
Validation loss: 2.114370067914327

Epoch: 5| Step: 9
Training loss: 2.481257438659668
Validation loss: 2.1145339012145996

Epoch: 5| Step: 10
Training loss: 2.008350372314453
Validation loss: 2.133575528860092

Epoch: 5| Step: 11
Training loss: 1.9185236692428589
Validation loss: 2.1515571922063828

Epoch: 197| Step: 0
Training loss: 1.2959703207015991
Validation loss: 2.1454625725746155

Epoch: 5| Step: 1
Training loss: 2.440812587738037
Validation loss: 2.1608210057020187

Epoch: 5| Step: 2
Training loss: 2.473627805709839
Validation loss: 2.1780996521313987

Epoch: 5| Step: 3
Training loss: 2.308767318725586
Validation loss: 2.182653417189916

Epoch: 5| Step: 4
Training loss: 2.3165993690490723
Validation loss: 2.1586101154486337

Epoch: 5| Step: 5
Training loss: 1.8884859085083008
Validation loss: 2.1564013808965683

Epoch: 5| Step: 6
Training loss: 2.365557909011841
Validation loss: 2.1246453473965325

Epoch: 5| Step: 7
Training loss: 2.408031940460205
Validation loss: 2.118171066045761

Epoch: 5| Step: 8
Training loss: 1.7884197235107422
Validation loss: 2.108082855741183

Epoch: 5| Step: 9
Training loss: 1.5787646770477295
Validation loss: 2.089515596628189

Epoch: 5| Step: 10
Training loss: 1.6055291891098022
Validation loss: 2.094021717707316

Epoch: 5| Step: 11
Training loss: 0.8781262636184692
Validation loss: 2.0916650195916495

Epoch: 198| Step: 0
Training loss: 2.0078392028808594
Validation loss: 2.0766506294409433

Epoch: 5| Step: 1
Training loss: 2.1434097290039062
Validation loss: 2.0887054055929184

Epoch: 5| Step: 2
Training loss: 2.0566182136535645
Validation loss: 2.0816298375527063

Epoch: 5| Step: 3
Training loss: 1.6563113927841187
Validation loss: 2.0967955191930137

Epoch: 5| Step: 4
Training loss: 2.5627026557922363
Validation loss: 2.101645121971766

Epoch: 5| Step: 5
Training loss: 2.3599209785461426
Validation loss: 2.110497052470843

Epoch: 5| Step: 6
Training loss: 2.113778591156006
Validation loss: 2.1158067484696708

Epoch: 5| Step: 7
Training loss: 1.3315708637237549
Validation loss: 2.1169606745243073

Epoch: 5| Step: 8
Training loss: 1.825975775718689
Validation loss: 2.130963613589605

Epoch: 5| Step: 9
Training loss: 1.9030749797821045
Validation loss: 2.1211503694454827

Epoch: 5| Step: 10
Training loss: 1.7518819570541382
Validation loss: 2.1299447417259216

Epoch: 5| Step: 11
Training loss: 2.2932167053222656
Validation loss: 2.141248474518458

Epoch: 199| Step: 0
Training loss: 1.757411003112793
Validation loss: 2.1183970471223197

Epoch: 5| Step: 1
Training loss: 1.55778169631958
Validation loss: 2.1093702216943107

Epoch: 5| Step: 2
Training loss: 2.0281167030334473
Validation loss: 2.110954319437345

Epoch: 5| Step: 3
Training loss: 2.111820697784424
Validation loss: 2.0976084570089975

Epoch: 5| Step: 4
Training loss: 2.459474563598633
Validation loss: 2.0948372731606164

Epoch: 5| Step: 5
Training loss: 1.8766930103302002
Validation loss: 2.0945950746536255

Epoch: 5| Step: 6
Training loss: 2.02923846244812
Validation loss: 2.0959602197011313

Epoch: 5| Step: 7
Training loss: 1.9764955043792725
Validation loss: 2.0958806524674096

Epoch: 5| Step: 8
Training loss: 2.454503059387207
Validation loss: 2.0951407750447593

Epoch: 5| Step: 9
Training loss: 1.832269310951233
Validation loss: 2.1011729339758554

Epoch: 5| Step: 10
Training loss: 1.6222655773162842
Validation loss: 2.094581479827563

Epoch: 5| Step: 11
Training loss: 1.689588189125061
Validation loss: 2.1147854924201965

Epoch: 200| Step: 0
Training loss: 1.5988973379135132
Validation loss: 2.101239427924156

Epoch: 5| Step: 1
Training loss: 1.5187705755233765
Validation loss: 2.10665292541186

Epoch: 5| Step: 2
Training loss: 1.906270980834961
Validation loss: 2.103853315114975

Epoch: 5| Step: 3
Training loss: 1.3962900638580322
Validation loss: 2.119438166419665

Epoch: 5| Step: 4
Training loss: 2.701035737991333
Validation loss: 2.10854709148407

Epoch: 5| Step: 5
Training loss: 2.4711639881134033
Validation loss: 2.1000397553046546

Epoch: 5| Step: 6
Training loss: 1.8727052211761475
Validation loss: 2.103848934173584

Epoch: 5| Step: 7
Training loss: 2.1897072792053223
Validation loss: 2.106931686401367

Epoch: 5| Step: 8
Training loss: 2.225985288619995
Validation loss: 2.1015291810035706

Epoch: 5| Step: 9
Training loss: 1.5519952774047852
Validation loss: 2.100650583704313

Epoch: 5| Step: 10
Training loss: 1.965187430381775
Validation loss: 2.1144088556369147

Epoch: 5| Step: 11
Training loss: 1.8084893226623535
Validation loss: 2.1254355957110724

Epoch: 201| Step: 0
Training loss: 2.4041614532470703
Validation loss: 2.119673644502958

Epoch: 5| Step: 1
Training loss: 1.5711480379104614
Validation loss: 2.1288533012072244

Epoch: 5| Step: 2
Training loss: 2.0416271686553955
Validation loss: 2.127296805381775

Epoch: 5| Step: 3
Training loss: 2.150315999984741
Validation loss: 2.134075482686361

Epoch: 5| Step: 4
Training loss: 2.030961513519287
Validation loss: 2.139444629351298

Epoch: 5| Step: 5
Training loss: 2.3324475288391113
Validation loss: 2.1381767988204956

Epoch: 5| Step: 6
Training loss: 2.3721282482147217
Validation loss: 2.135232756535212

Epoch: 5| Step: 7
Training loss: 1.4700301885604858
Validation loss: 2.1325522859891257

Epoch: 5| Step: 8
Training loss: 1.3279569149017334
Validation loss: 2.1101510723431907

Epoch: 5| Step: 9
Training loss: 1.3853437900543213
Validation loss: 2.114730417728424

Epoch: 5| Step: 10
Training loss: 2.334510326385498
Validation loss: 2.1229377736647925

Epoch: 5| Step: 11
Training loss: 2.379295825958252
Validation loss: 2.119740754365921

Epoch: 202| Step: 0
Training loss: 1.8756288290023804
Validation loss: 2.123647818962733

Epoch: 5| Step: 1
Training loss: 1.8825957775115967
Validation loss: 2.1236827919880548

Epoch: 5| Step: 2
Training loss: 2.0263705253601074
Validation loss: 2.1224409341812134

Epoch: 5| Step: 3
Training loss: 1.7509944438934326
Validation loss: 2.1225567559401193

Epoch: 5| Step: 4
Training loss: 1.5675971508026123
Validation loss: 2.1202066193024316

Epoch: 5| Step: 5
Training loss: 2.1076040267944336
Validation loss: 2.132018581032753

Epoch: 5| Step: 6
Training loss: 2.178865432739258
Validation loss: 2.1202807873487473

Epoch: 5| Step: 7
Training loss: 1.9033935070037842
Validation loss: 2.117487668991089

Epoch: 5| Step: 8
Training loss: 2.449553966522217
Validation loss: 2.1367013454437256

Epoch: 5| Step: 9
Training loss: 1.7209771871566772
Validation loss: 2.1139753411213555

Epoch: 5| Step: 10
Training loss: 1.681680679321289
Validation loss: 2.1305535386006036

Epoch: 5| Step: 11
Training loss: 3.5787816047668457
Validation loss: 2.1356039543946586

Epoch: 203| Step: 0
Training loss: 1.474316954612732
Validation loss: 2.1374506751696267

Epoch: 5| Step: 1
Training loss: 1.6508867740631104
Validation loss: 2.1177555521329245

Epoch: 5| Step: 2
Training loss: 1.9882338047027588
Validation loss: 2.115038141608238

Epoch: 5| Step: 3
Training loss: 1.6282198429107666
Validation loss: 2.1116069753964744

Epoch: 5| Step: 4
Training loss: 1.9624742269515991
Validation loss: 2.13966695467631

Epoch: 5| Step: 5
Training loss: 1.982377290725708
Validation loss: 2.119395683209101

Epoch: 5| Step: 6
Training loss: 1.9802871942520142
Validation loss: 2.1241054286559424

Epoch: 5| Step: 7
Training loss: 2.2732601165771484
Validation loss: 2.124596670269966

Epoch: 5| Step: 8
Training loss: 1.8357594013214111
Validation loss: 2.138105238477389

Epoch: 5| Step: 9
Training loss: 2.8696494102478027
Validation loss: 2.127031351129214

Epoch: 5| Step: 10
Training loss: 1.7292131185531616
Validation loss: 2.1323718478282294

Epoch: 5| Step: 11
Training loss: 1.9236665964126587
Validation loss: 2.1306790113449097

Epoch: 204| Step: 0
Training loss: 1.7235456705093384
Validation loss: 2.123010436693827

Epoch: 5| Step: 1
Training loss: 2.336071014404297
Validation loss: 2.1108530114094415

Epoch: 5| Step: 2
Training loss: 2.505016803741455
Validation loss: 2.1146283199389777

Epoch: 5| Step: 3
Training loss: 2.4521594047546387
Validation loss: 2.0888028889894485

Epoch: 5| Step: 4
Training loss: 1.8145034313201904
Validation loss: 2.092389315366745

Epoch: 5| Step: 5
Training loss: 2.0755600929260254
Validation loss: 2.0905573616425195

Epoch: 5| Step: 6
Training loss: 2.2114086151123047
Validation loss: 2.0751472214857736

Epoch: 5| Step: 7
Training loss: 1.638419508934021
Validation loss: 2.0909917751948037

Epoch: 5| Step: 8
Training loss: 1.7104761600494385
Validation loss: 2.0816135307153067

Epoch: 5| Step: 9
Training loss: 1.730802297592163
Validation loss: 2.091122845808665

Epoch: 5| Step: 10
Training loss: 1.4188578128814697
Validation loss: 2.093122750520706

Epoch: 5| Step: 11
Training loss: 1.8957583904266357
Validation loss: 2.0964532792568207

Epoch: 205| Step: 0
Training loss: 1.7592475414276123
Validation loss: 2.103006362915039

Epoch: 5| Step: 1
Training loss: 1.8125118017196655
Validation loss: 2.1025280555089316

Epoch: 5| Step: 2
Training loss: 1.6987375020980835
Validation loss: 2.129872371753057

Epoch: 5| Step: 3
Training loss: 2.278341054916382
Validation loss: 2.12217486401399

Epoch: 5| Step: 4
Training loss: 1.7476125955581665
Validation loss: 2.138208121061325

Epoch: 5| Step: 5
Training loss: 2.102367401123047
Validation loss: 2.13845386604468

Epoch: 5| Step: 6
Training loss: 1.8425514698028564
Validation loss: 2.1441771338383355

Epoch: 5| Step: 7
Training loss: 1.8539905548095703
Validation loss: 2.1446815530459085

Epoch: 5| Step: 8
Training loss: 1.8248910903930664
Validation loss: 2.139338264862696

Epoch: 5| Step: 9
Training loss: 2.3232429027557373
Validation loss: 2.112934708595276

Epoch: 5| Step: 10
Training loss: 2.2330081462860107
Validation loss: 2.1025287806987762

Epoch: 5| Step: 11
Training loss: 2.0672144889831543
Validation loss: 2.092783898115158

Epoch: 206| Step: 0
Training loss: 1.7478675842285156
Validation loss: 2.10002193848292

Epoch: 5| Step: 1
Training loss: 1.6489450931549072
Validation loss: 2.098112185796102

Epoch: 5| Step: 2
Training loss: 2.3786461353302
Validation loss: 2.09051975607872

Epoch: 5| Step: 3
Training loss: 2.4172005653381348
Validation loss: 2.0938809663057327

Epoch: 5| Step: 4
Training loss: 1.6148427724838257
Validation loss: 2.0823115011056266

Epoch: 5| Step: 5
Training loss: 1.554437279701233
Validation loss: 2.084740107258161

Epoch: 5| Step: 6
Training loss: 1.9489387273788452
Validation loss: 2.096796770890554

Epoch: 5| Step: 7
Training loss: 2.001018524169922
Validation loss: 2.101400007804235

Epoch: 5| Step: 8
Training loss: 1.942220687866211
Validation loss: 2.11436919371287

Epoch: 5| Step: 9
Training loss: 2.1225922107696533
Validation loss: 2.119014471769333

Epoch: 5| Step: 10
Training loss: 2.264472246170044
Validation loss: 2.1305039525032043

Epoch: 5| Step: 11
Training loss: 1.8839137554168701
Validation loss: 2.132877071698507

Epoch: 207| Step: 0
Training loss: 1.6998746395111084
Validation loss: 2.1324682285388312

Epoch: 5| Step: 1
Training loss: 1.4378530979156494
Validation loss: 2.1367084980010986

Epoch: 5| Step: 2
Training loss: 1.8677387237548828
Validation loss: 2.133478437860807

Epoch: 5| Step: 3
Training loss: 1.5676681995391846
Validation loss: 2.1470910211404166

Epoch: 5| Step: 4
Training loss: 1.9792518615722656
Validation loss: 2.1469475577274957

Epoch: 5| Step: 5
Training loss: 1.981529951095581
Validation loss: 2.132572924097379

Epoch: 5| Step: 6
Training loss: 1.7822444438934326
Validation loss: 2.1291615813970566

Epoch: 5| Step: 7
Training loss: 2.3124637603759766
Validation loss: 2.128777558604876

Epoch: 5| Step: 8
Training loss: 2.825556516647339
Validation loss: 2.128050282597542

Epoch: 5| Step: 9
Training loss: 2.0694451332092285
Validation loss: 2.1084892253081002

Epoch: 5| Step: 10
Training loss: 1.8792932033538818
Validation loss: 2.106963872909546

Epoch: 5| Step: 11
Training loss: 1.7190420627593994
Validation loss: 2.106292317310969

Epoch: 208| Step: 0
Training loss: 1.9874515533447266
Validation loss: 2.1058994432290397

Epoch: 5| Step: 1
Training loss: 1.8478409051895142
Validation loss: 2.1031463891267776

Epoch: 5| Step: 2
Training loss: 1.7480732202529907
Validation loss: 2.1190745532512665

Epoch: 5| Step: 3
Training loss: 1.7822071313858032
Validation loss: 2.10878058274587

Epoch: 5| Step: 4
Training loss: 1.8650610446929932
Validation loss: 2.1226022044817605

Epoch: 5| Step: 5
Training loss: 1.7541015148162842
Validation loss: 2.1221209168434143

Epoch: 5| Step: 6
Training loss: 2.303035020828247
Validation loss: 2.118152509133021

Epoch: 5| Step: 7
Training loss: 2.1874711513519287
Validation loss: 2.1227880120277405

Epoch: 5| Step: 8
Training loss: 2.072474956512451
Validation loss: 2.137743353843689

Epoch: 5| Step: 9
Training loss: 1.844172477722168
Validation loss: 2.131018723050753

Epoch: 5| Step: 10
Training loss: 2.309921979904175
Validation loss: 2.1347281436125436

Epoch: 5| Step: 11
Training loss: 0.945513129234314
Validation loss: 2.127157911658287

Epoch: 209| Step: 0
Training loss: 1.955440878868103
Validation loss: 2.1233797868092856

Epoch: 5| Step: 1
Training loss: 1.6212555170059204
Validation loss: 2.111139347155889

Epoch: 5| Step: 2
Training loss: 2.3039767742156982
Validation loss: 2.106019894282023

Epoch: 5| Step: 3
Training loss: 2.1930909156799316
Validation loss: 2.1121847381194434

Epoch: 5| Step: 4
Training loss: 1.9608843326568604
Validation loss: 2.099988177418709

Epoch: 5| Step: 5
Training loss: 1.763533353805542
Validation loss: 2.112336034576098

Epoch: 5| Step: 6
Training loss: 1.7452690601348877
Validation loss: 2.10353750983874

Epoch: 5| Step: 7
Training loss: 2.3685288429260254
Validation loss: 2.109895199537277

Epoch: 5| Step: 8
Training loss: 1.9365050792694092
Validation loss: 2.1254252145687738

Epoch: 5| Step: 9
Training loss: 1.6446659564971924
Validation loss: 2.1237052530050278

Epoch: 5| Step: 10
Training loss: 1.8126825094223022
Validation loss: 2.1284944812456765

Epoch: 5| Step: 11
Training loss: 1.4052894115447998
Validation loss: 2.134897177418073

Epoch: 210| Step: 0
Training loss: 1.9743940830230713
Validation loss: 2.1127273788054786

Epoch: 5| Step: 1
Training loss: 1.7128267288208008
Validation loss: 2.1234321892261505

Epoch: 5| Step: 2
Training loss: 1.1413061618804932
Validation loss: 2.11498594780763

Epoch: 5| Step: 3
Training loss: 1.503831386566162
Validation loss: 2.1190871000289917

Epoch: 5| Step: 4
Training loss: 1.955725908279419
Validation loss: 2.1143188973267875

Epoch: 5| Step: 5
Training loss: 2.4477317333221436
Validation loss: 2.1278091768423715

Epoch: 5| Step: 6
Training loss: 1.7596824169158936
Validation loss: 2.1280070592959723

Epoch: 5| Step: 7
Training loss: 1.7156779766082764
Validation loss: 2.1325267453988395

Epoch: 5| Step: 8
Training loss: 2.050463914871216
Validation loss: 2.1238538324832916

Epoch: 5| Step: 9
Training loss: 2.4930782318115234
Validation loss: 2.120321606596311

Epoch: 5| Step: 10
Training loss: 2.341139316558838
Validation loss: 2.1220332284768424

Epoch: 5| Step: 11
Training loss: 2.984523296356201
Validation loss: 2.130764380097389

Epoch: 211| Step: 0
Training loss: 2.1312010288238525
Validation loss: 2.128361627459526

Epoch: 5| Step: 1
Training loss: 2.028409242630005
Validation loss: 2.125651260217031

Epoch: 5| Step: 2
Training loss: 2.081102132797241
Validation loss: 2.144903987646103

Epoch: 5| Step: 3
Training loss: 1.7680766582489014
Validation loss: 2.123066892226537

Epoch: 5| Step: 4
Training loss: 1.6820958852767944
Validation loss: 2.1280774821837745

Epoch: 5| Step: 5
Training loss: 2.272993803024292
Validation loss: 2.1077640851338706

Epoch: 5| Step: 6
Training loss: 1.9621095657348633
Validation loss: 2.121159315109253

Epoch: 5| Step: 7
Training loss: 1.8824107646942139
Validation loss: 2.113542318344116

Epoch: 5| Step: 8
Training loss: 1.5006355047225952
Validation loss: 2.1094716489315033

Epoch: 5| Step: 9
Training loss: 1.8163337707519531
Validation loss: 2.115872452656428

Epoch: 5| Step: 10
Training loss: 1.849434494972229
Validation loss: 2.118456174929937

Epoch: 5| Step: 11
Training loss: 2.5537118911743164
Validation loss: 2.1157470047473907

Epoch: 212| Step: 0
Training loss: 3.136758804321289
Validation loss: 2.113161245981852

Epoch: 5| Step: 1
Training loss: 2.0502982139587402
Validation loss: 2.1120865841706595

Epoch: 5| Step: 2
Training loss: 1.9791162014007568
Validation loss: 2.130247488617897

Epoch: 5| Step: 3
Training loss: 1.860882043838501
Validation loss: 2.1301426589488983

Epoch: 5| Step: 4
Training loss: 1.5058783292770386
Validation loss: 2.1258134841918945

Epoch: 5| Step: 5
Training loss: 2.2393243312835693
Validation loss: 2.12747814754645

Epoch: 5| Step: 6
Training loss: 1.2162144184112549
Validation loss: 2.1409602661927543

Epoch: 5| Step: 7
Training loss: 1.6854215860366821
Validation loss: 2.1515024354060492

Epoch: 5| Step: 8
Training loss: 1.9375871419906616
Validation loss: 2.1415582299232483

Epoch: 5| Step: 9
Training loss: 1.9078718423843384
Validation loss: 2.138408730427424

Epoch: 5| Step: 10
Training loss: 1.7705352306365967
Validation loss: 2.142650713523229

Epoch: 5| Step: 11
Training loss: 1.029915452003479
Validation loss: 2.1293239196141562

Epoch: 213| Step: 0
Training loss: 2.3977179527282715
Validation loss: 2.123344918092092

Epoch: 5| Step: 1
Training loss: 2.0512795448303223
Validation loss: 2.1318055341641107

Epoch: 5| Step: 2
Training loss: 1.4240127801895142
Validation loss: 2.1258139411608377

Epoch: 5| Step: 3
Training loss: 1.6238352060317993
Validation loss: 2.1257278521855674

Epoch: 5| Step: 4
Training loss: 2.0853891372680664
Validation loss: 2.1233125229676566

Epoch: 5| Step: 5
Training loss: 1.7096948623657227
Validation loss: 2.121498559912046

Epoch: 5| Step: 6
Training loss: 2.3717243671417236
Validation loss: 2.145094861586889

Epoch: 5| Step: 7
Training loss: 1.9745200872421265
Validation loss: 2.1311438580354056

Epoch: 5| Step: 8
Training loss: 1.7284822463989258
Validation loss: 2.134701763590177

Epoch: 5| Step: 9
Training loss: 1.7768123149871826
Validation loss: 2.1412998735904694

Epoch: 5| Step: 10
Training loss: 1.890404462814331
Validation loss: 2.15311269958814

Epoch: 5| Step: 11
Training loss: 2.439296007156372
Validation loss: 2.149744898080826

Epoch: 214| Step: 0
Training loss: 1.8583076000213623
Validation loss: 2.1580505023399987

Epoch: 5| Step: 1
Training loss: 1.7978770732879639
Validation loss: 2.175380145510038

Epoch: 5| Step: 2
Training loss: 2.1295864582061768
Validation loss: 2.1755306124687195

Epoch: 5| Step: 3
Training loss: 1.4442222118377686
Validation loss: 2.1715389490127563

Epoch: 5| Step: 4
Training loss: 1.8343284130096436
Validation loss: 2.1569790144761405

Epoch: 5| Step: 5
Training loss: 1.8986165523529053
Validation loss: 2.1643701692422233

Epoch: 5| Step: 6
Training loss: 2.6790881156921387
Validation loss: 2.146248231331507

Epoch: 5| Step: 7
Training loss: 1.6422531604766846
Validation loss: 2.1317524015903473

Epoch: 5| Step: 8
Training loss: 2.542902708053589
Validation loss: 2.122261921564738

Epoch: 5| Step: 9
Training loss: 2.0094056129455566
Validation loss: 2.119412293036779

Epoch: 5| Step: 10
Training loss: 2.1040310859680176
Validation loss: 2.1219414522250495

Epoch: 5| Step: 11
Training loss: 1.811893105506897
Validation loss: 2.1325447956720986

Epoch: 215| Step: 0
Training loss: 2.0807487964630127
Validation loss: 2.12179263929526

Epoch: 5| Step: 1
Training loss: 2.1828408241271973
Validation loss: 2.1372251411279044

Epoch: 5| Step: 2
Training loss: 2.1583328247070312
Validation loss: 2.1275683492422104

Epoch: 5| Step: 3
Training loss: 1.9292869567871094
Validation loss: 2.129449725151062

Epoch: 5| Step: 4
Training loss: 1.6250064373016357
Validation loss: 2.128425657749176

Epoch: 5| Step: 5
Training loss: 1.87469482421875
Validation loss: 2.134149879217148

Epoch: 5| Step: 6
Training loss: 2.422602653503418
Validation loss: 2.145452340443929

Epoch: 5| Step: 7
Training loss: 1.5638954639434814
Validation loss: 2.172325705488523

Epoch: 5| Step: 8
Training loss: 1.978676199913025
Validation loss: 2.1842270642518997

Epoch: 5| Step: 9
Training loss: 1.6947662830352783
Validation loss: 2.1635922888914743

Epoch: 5| Step: 10
Training loss: 1.9958972930908203
Validation loss: 2.1710406839847565

Epoch: 5| Step: 11
Training loss: 2.160399913787842
Validation loss: 2.1567310194174447

Epoch: 216| Step: 0
Training loss: 2.0851798057556152
Validation loss: 2.152637074391047

Epoch: 5| Step: 1
Training loss: 2.0268588066101074
Validation loss: 2.1228468219439187

Epoch: 5| Step: 2
Training loss: 1.46793532371521
Validation loss: 2.098764662941297

Epoch: 5| Step: 3
Training loss: 2.725564956665039
Validation loss: 2.095628092686335

Epoch: 5| Step: 4
Training loss: 1.7744829654693604
Validation loss: 2.0927121539910636

Epoch: 5| Step: 5
Training loss: 2.366024971008301
Validation loss: 2.0881935954093933

Epoch: 5| Step: 6
Training loss: 1.4363746643066406
Validation loss: 2.09942327439785

Epoch: 5| Step: 7
Training loss: 2.2147326469421387
Validation loss: 2.087584892908732

Epoch: 5| Step: 8
Training loss: 1.8967479467391968
Validation loss: 2.0953685541947684

Epoch: 5| Step: 9
Training loss: 1.9210456609725952
Validation loss: 2.0965259969234467

Epoch: 5| Step: 10
Training loss: 1.900159478187561
Validation loss: 2.1072824647029242

Epoch: 5| Step: 11
Training loss: 2.0698401927948
Validation loss: 2.111702377597491

Epoch: 217| Step: 0
Training loss: 1.5955076217651367
Validation loss: 2.120509296655655

Epoch: 5| Step: 1
Training loss: 1.8696634769439697
Validation loss: 2.1262332101662955

Epoch: 5| Step: 2
Training loss: 2.1497557163238525
Validation loss: 2.129224260648092

Epoch: 5| Step: 3
Training loss: 2.0074050426483154
Validation loss: 2.143562744061152

Epoch: 5| Step: 4
Training loss: 2.1787972450256348
Validation loss: 2.1328365206718445

Epoch: 5| Step: 5
Training loss: 1.9804493188858032
Validation loss: 2.1357970585425696

Epoch: 5| Step: 6
Training loss: 1.9551061391830444
Validation loss: 2.135245834787687

Epoch: 5| Step: 7
Training loss: 1.5489842891693115
Validation loss: 2.1313703606526055

Epoch: 5| Step: 8
Training loss: 1.9018261432647705
Validation loss: 2.134947051604589

Epoch: 5| Step: 9
Training loss: 2.3588688373565674
Validation loss: 2.136297106742859

Epoch: 5| Step: 10
Training loss: 1.7409048080444336
Validation loss: 2.142192487915357

Epoch: 5| Step: 11
Training loss: 1.5051798820495605
Validation loss: 2.1352172046899796

Epoch: 218| Step: 0
Training loss: 1.5283712148666382
Validation loss: 2.128122463822365

Epoch: 5| Step: 1
Training loss: 2.2075467109680176
Validation loss: 2.126091703772545

Epoch: 5| Step: 2
Training loss: 2.4929275512695312
Validation loss: 2.1199420541524887

Epoch: 5| Step: 3
Training loss: 1.8616050481796265
Validation loss: 2.1072891106208167

Epoch: 5| Step: 4
Training loss: 1.270188570022583
Validation loss: 2.1208045532306037

Epoch: 5| Step: 5
Training loss: 1.737438440322876
Validation loss: 2.118239998817444

Epoch: 5| Step: 6
Training loss: 1.909131646156311
Validation loss: 2.114127183953921

Epoch: 5| Step: 7
Training loss: 1.9955902099609375
Validation loss: 2.1280760218699775

Epoch: 5| Step: 8
Training loss: 1.8151648044586182
Validation loss: 2.1184092511733374

Epoch: 5| Step: 9
Training loss: 2.1020255088806152
Validation loss: 2.130879128972689

Epoch: 5| Step: 10
Training loss: 1.896026611328125
Validation loss: 2.1382036904493966

Epoch: 5| Step: 11
Training loss: 2.5070340633392334
Validation loss: 2.144280140598615

Epoch: 219| Step: 0
Training loss: 2.1273560523986816
Validation loss: 2.137484242518743

Epoch: 5| Step: 1
Training loss: 2.2585461139678955
Validation loss: 2.1376361548900604

Epoch: 5| Step: 2
Training loss: 2.073359251022339
Validation loss: 2.1321090310811996

Epoch: 5| Step: 3
Training loss: 0.973733127117157
Validation loss: 2.1471895972887673

Epoch: 5| Step: 4
Training loss: 1.9683997631072998
Validation loss: 2.1530499259630838

Epoch: 5| Step: 5
Training loss: 1.6798216104507446
Validation loss: 2.1607189873854318

Epoch: 5| Step: 6
Training loss: 2.1268489360809326
Validation loss: 2.1580214500427246

Epoch: 5| Step: 7
Training loss: 2.2812604904174805
Validation loss: 2.145699684818586

Epoch: 5| Step: 8
Training loss: 2.26362943649292
Validation loss: 2.156104569633802

Epoch: 5| Step: 9
Training loss: 1.6140334606170654
Validation loss: 2.14927044014136

Epoch: 5| Step: 10
Training loss: 1.4459304809570312
Validation loss: 2.1412702600161233

Epoch: 5| Step: 11
Training loss: 1.7865909337997437
Validation loss: 2.1222843676805496

Epoch: 220| Step: 0
Training loss: 1.7146192789077759
Validation loss: 2.1179706752300262

Epoch: 5| Step: 1
Training loss: 1.926487684249878
Validation loss: 2.1076682060956955

Epoch: 5| Step: 2
Training loss: 2.063027858734131
Validation loss: 2.1025393505891166

Epoch: 5| Step: 3
Training loss: 1.7161699533462524
Validation loss: 2.098958189288775

Epoch: 5| Step: 4
Training loss: 1.6346797943115234
Validation loss: 2.102779135107994

Epoch: 5| Step: 5
Training loss: 2.369961977005005
Validation loss: 2.1002260794242225

Epoch: 5| Step: 6
Training loss: 2.47210431098938
Validation loss: 2.1019740800062814

Epoch: 5| Step: 7
Training loss: 1.9231071472167969
Validation loss: 2.1076017220815024

Epoch: 5| Step: 8
Training loss: 2.0388364791870117
Validation loss: 2.1086525171995163

Epoch: 5| Step: 9
Training loss: 2.0580968856811523
Validation loss: 2.10897325972716

Epoch: 5| Step: 10
Training loss: 1.9293187856674194
Validation loss: 2.128846397002538

Epoch: 5| Step: 11
Training loss: 2.2149009704589844
Validation loss: 2.1443022191524506

Epoch: 221| Step: 0
Training loss: 2.0615243911743164
Validation loss: 2.144071484605471

Epoch: 5| Step: 1
Training loss: 1.6367568969726562
Validation loss: 2.175500974059105

Epoch: 5| Step: 2
Training loss: 2.097623586654663
Validation loss: 2.210343395670255

Epoch: 5| Step: 3
Training loss: 2.5407044887542725
Validation loss: 2.232128103574117

Epoch: 5| Step: 4
Training loss: 2.3267555236816406
Validation loss: 2.245632141828537

Epoch: 5| Step: 5
Training loss: 2.26802134513855
Validation loss: 2.220931534965833

Epoch: 5| Step: 6
Training loss: 2.41558837890625
Validation loss: 2.2253688822189965

Epoch: 5| Step: 7
Training loss: 1.997327208518982
Validation loss: 2.194494277238846

Epoch: 5| Step: 8
Training loss: 2.1910009384155273
Validation loss: 2.1634027858575187

Epoch: 5| Step: 9
Training loss: 1.8447784185409546
Validation loss: 2.1511086970567703

Epoch: 5| Step: 10
Training loss: 2.023367404937744
Validation loss: 2.116123894850413

Epoch: 5| Step: 11
Training loss: 1.513147234916687
Validation loss: 2.105947653452555

Epoch: 222| Step: 0
Training loss: 1.6285150051116943
Validation loss: 2.097695827484131

Epoch: 5| Step: 1
Training loss: 2.2824018001556396
Validation loss: 2.0908495982488

Epoch: 5| Step: 2
Training loss: 2.3236124515533447
Validation loss: 2.1007425040006638

Epoch: 5| Step: 3
Training loss: 2.3449864387512207
Validation loss: 2.1032683153947196

Epoch: 5| Step: 4
Training loss: 1.9682319164276123
Validation loss: 2.1044125258922577

Epoch: 5| Step: 5
Training loss: 1.9196789264678955
Validation loss: 2.103318010767301

Epoch: 5| Step: 6
Training loss: 2.0348150730133057
Validation loss: 2.094019631544749

Epoch: 5| Step: 7
Training loss: 1.761823296546936
Validation loss: 2.107407808303833

Epoch: 5| Step: 8
Training loss: 2.232452392578125
Validation loss: 2.0983987152576447

Epoch: 5| Step: 9
Training loss: 1.7494442462921143
Validation loss: 2.0898250887791314

Epoch: 5| Step: 10
Training loss: 2.299569606781006
Validation loss: 2.0946050584316254

Epoch: 5| Step: 11
Training loss: 2.9725348949432373
Validation loss: 2.088466172417005

Epoch: 223| Step: 0
Training loss: 1.7301098108291626
Validation loss: 2.086297149459521

Epoch: 5| Step: 1
Training loss: 1.9215476512908936
Validation loss: 2.0847223103046417

Epoch: 5| Step: 2
Training loss: 2.0391955375671387
Validation loss: 2.0820634911457696

Epoch: 5| Step: 3
Training loss: 1.9058904647827148
Validation loss: 2.06252088646094

Epoch: 5| Step: 4
Training loss: 2.0001344680786133
Validation loss: 2.0703550229469934

Epoch: 5| Step: 5
Training loss: 2.182799816131592
Validation loss: 2.0702671706676483

Epoch: 5| Step: 6
Training loss: 2.4635796546936035
Validation loss: 2.0802361567815146

Epoch: 5| Step: 7
Training loss: 2.267569065093994
Validation loss: 2.0772454341252646

Epoch: 5| Step: 8
Training loss: 1.9460967779159546
Validation loss: 2.0834415604670844

Epoch: 5| Step: 9
Training loss: 1.6025409698486328
Validation loss: 2.0894816517829895

Epoch: 5| Step: 10
Training loss: 2.2599217891693115
Validation loss: 2.094340185324351

Epoch: 5| Step: 11
Training loss: 1.3930537700653076
Validation loss: 2.1083548019329705

Epoch: 224| Step: 0
Training loss: 2.57293701171875
Validation loss: 2.1141332338253656

Epoch: 5| Step: 1
Training loss: 1.9784387350082397
Validation loss: 2.0984497716029487

Epoch: 5| Step: 2
Training loss: 2.157531261444092
Validation loss: 2.1144387871026993

Epoch: 5| Step: 3
Training loss: 1.829787015914917
Validation loss: 2.109735975662867

Epoch: 5| Step: 4
Training loss: 1.6408027410507202
Validation loss: 2.104173958301544

Epoch: 5| Step: 5
Training loss: 1.7719287872314453
Validation loss: 2.128924861550331

Epoch: 5| Step: 6
Training loss: 1.6895191669464111
Validation loss: 2.1068202753861747

Epoch: 5| Step: 7
Training loss: 1.752306580543518
Validation loss: 2.133435611923536

Epoch: 5| Step: 8
Training loss: 1.4695379734039307
Validation loss: 2.1247724095980325

Epoch: 5| Step: 9
Training loss: 2.1355607509613037
Validation loss: 2.1239793996016183

Epoch: 5| Step: 10
Training loss: 2.1240296363830566
Validation loss: 2.1164806286493936

Epoch: 5| Step: 11
Training loss: 1.4556108713150024
Validation loss: 2.1172446509202323

Epoch: 225| Step: 0
Training loss: 1.7235428094863892
Validation loss: 2.1080800046523414

Epoch: 5| Step: 1
Training loss: 2.1034209728240967
Validation loss: 2.1256730556488037

Epoch: 5| Step: 2
Training loss: 1.744807243347168
Validation loss: 2.104447215795517

Epoch: 5| Step: 3
Training loss: 2.1648309230804443
Validation loss: 2.114550307393074

Epoch: 5| Step: 4
Training loss: 1.4101152420043945
Validation loss: 2.1071307758490243

Epoch: 5| Step: 5
Training loss: 1.9743120670318604
Validation loss: 2.127322867512703

Epoch: 5| Step: 6
Training loss: 1.5217983722686768
Validation loss: 2.12814794977506

Epoch: 5| Step: 7
Training loss: 2.4387731552124023
Validation loss: 2.1260537207126617

Epoch: 5| Step: 8
Training loss: 2.04178786277771
Validation loss: 2.1523222575585046

Epoch: 5| Step: 9
Training loss: 1.8257821798324585
Validation loss: 2.130742977062861

Epoch: 5| Step: 10
Training loss: 2.236158609390259
Validation loss: 2.144623597462972

Epoch: 5| Step: 11
Training loss: 1.5904054641723633
Validation loss: 2.1325794955094657

Epoch: 226| Step: 0
Training loss: 2.534377098083496
Validation loss: 2.136715898911158

Epoch: 5| Step: 1
Training loss: 1.3911882638931274
Validation loss: 2.1413278182347617

Epoch: 5| Step: 2
Training loss: 1.850992202758789
Validation loss: 2.137842799226443

Epoch: 5| Step: 3
Training loss: 2.172874927520752
Validation loss: 2.1409290929635367

Epoch: 5| Step: 4
Training loss: 2.0443859100341797
Validation loss: 2.15457151333491

Epoch: 5| Step: 5
Training loss: 1.8852646350860596
Validation loss: 2.136102572083473

Epoch: 5| Step: 6
Training loss: 1.5761302709579468
Validation loss: 2.1343006789684296

Epoch: 5| Step: 7
Training loss: 1.4516198635101318
Validation loss: 2.1315264801184335

Epoch: 5| Step: 8
Training loss: 1.6540569067001343
Validation loss: 2.1269448747237525

Epoch: 5| Step: 9
Training loss: 2.134486436843872
Validation loss: 2.1354547341664634

Epoch: 5| Step: 10
Training loss: 2.1097702980041504
Validation loss: 2.1322544117768607

Epoch: 5| Step: 11
Training loss: 2.567666530609131
Validation loss: 2.121518765886625

Epoch: 227| Step: 0
Training loss: 1.814975380897522
Validation loss: 2.144345283508301

Epoch: 5| Step: 1
Training loss: 1.8968265056610107
Validation loss: 2.128390888373057

Epoch: 5| Step: 2
Training loss: 1.4459478855133057
Validation loss: 2.140285516778628

Epoch: 5| Step: 3
Training loss: 1.699541449546814
Validation loss: 2.1479866057634354

Epoch: 5| Step: 4
Training loss: 1.6345767974853516
Validation loss: 2.1731865406036377

Epoch: 5| Step: 5
Training loss: 1.932060956954956
Validation loss: 2.1783692985773087

Epoch: 5| Step: 6
Training loss: 2.1660315990448
Validation loss: 2.176937237381935

Epoch: 5| Step: 7
Training loss: 1.4734059572219849
Validation loss: 2.170794000228246

Epoch: 5| Step: 8
Training loss: 2.593231439590454
Validation loss: 2.1680530110994973

Epoch: 5| Step: 9
Training loss: 2.2039599418640137
Validation loss: 2.153663699825605

Epoch: 5| Step: 10
Training loss: 2.032263994216919
Validation loss: 2.149425357580185

Epoch: 5| Step: 11
Training loss: 2.2371907234191895
Validation loss: 2.1379859695831933

Epoch: 228| Step: 0
Training loss: 2.2876462936401367
Validation loss: 2.125791589419047

Epoch: 5| Step: 1
Training loss: 1.834633231163025
Validation loss: 2.1279457757870355

Epoch: 5| Step: 2
Training loss: 1.5908844470977783
Validation loss: 2.128076354662577

Epoch: 5| Step: 3
Training loss: 2.3009941577911377
Validation loss: 2.136266847451528

Epoch: 5| Step: 4
Training loss: 1.9531891345977783
Validation loss: 2.138264069954554

Epoch: 5| Step: 5
Training loss: 2.0400500297546387
Validation loss: 2.138060058156649

Epoch: 5| Step: 6
Training loss: 1.7549930810928345
Validation loss: 2.146587610244751

Epoch: 5| Step: 7
Training loss: 1.4432125091552734
Validation loss: 2.144922117392222

Epoch: 5| Step: 8
Training loss: 1.9318821430206299
Validation loss: 2.147189289331436

Epoch: 5| Step: 9
Training loss: 2.014347553253174
Validation loss: 2.1624639282623925

Epoch: 5| Step: 10
Training loss: 2.0421671867370605
Validation loss: 2.1437289863824844

Epoch: 5| Step: 11
Training loss: 1.6800788640975952
Validation loss: 2.154855032761892

Epoch: 229| Step: 0
Training loss: 1.6573768854141235
Validation loss: 2.1524760772784552

Epoch: 5| Step: 1
Training loss: 2.2823233604431152
Validation loss: 2.129687567551931

Epoch: 5| Step: 2
Training loss: 1.7125288248062134
Validation loss: 2.138259212176005

Epoch: 5| Step: 3
Training loss: 1.7185865640640259
Validation loss: 2.1303626894950867

Epoch: 5| Step: 4
Training loss: 1.645833969116211
Validation loss: 2.129601831237475

Epoch: 5| Step: 5
Training loss: 2.320341110229492
Validation loss: 2.1338279247283936

Epoch: 5| Step: 6
Training loss: 1.943121314048767
Validation loss: 2.13044373691082

Epoch: 5| Step: 7
Training loss: 2.4212632179260254
Validation loss: 2.135053182641665

Epoch: 5| Step: 8
Training loss: 1.9555351734161377
Validation loss: 2.1413685282071433

Epoch: 5| Step: 9
Training loss: 1.5370651483535767
Validation loss: 2.135864441593488

Epoch: 5| Step: 10
Training loss: 1.6323407888412476
Validation loss: 2.142716407775879

Epoch: 5| Step: 11
Training loss: 2.483582019805908
Validation loss: 2.1493980437517166

Epoch: 230| Step: 0
Training loss: 1.3686703443527222
Validation loss: 2.1411462277173996

Epoch: 5| Step: 1
Training loss: 1.255419373512268
Validation loss: 2.15396640698115

Epoch: 5| Step: 2
Training loss: 1.5910072326660156
Validation loss: 2.1518481473128

Epoch: 5| Step: 3
Training loss: 2.947922945022583
Validation loss: 2.156418487429619

Epoch: 5| Step: 4
Training loss: 1.879768967628479
Validation loss: 2.144911433259646

Epoch: 5| Step: 5
Training loss: 2.033376693725586
Validation loss: 2.145737354954084

Epoch: 5| Step: 6
Training loss: 1.9671787023544312
Validation loss: 2.16073968509833

Epoch: 5| Step: 7
Training loss: 1.6271207332611084
Validation loss: 2.142728795607885

Epoch: 5| Step: 8
Training loss: 2.088488817214966
Validation loss: 2.1434955497582755

Epoch: 5| Step: 9
Training loss: 1.8801696300506592
Validation loss: 2.14080219467481

Epoch: 5| Step: 10
Training loss: 1.8323166370391846
Validation loss: 2.147667035460472

Epoch: 5| Step: 11
Training loss: 2.9630818367004395
Validation loss: 2.134242753187815

Epoch: 231| Step: 0
Training loss: 1.6414111852645874
Validation loss: 2.1423613131046295

Epoch: 5| Step: 1
Training loss: 1.5785404443740845
Validation loss: 2.136856426795324

Epoch: 5| Step: 2
Training loss: 2.441710948944092
Validation loss: 2.1384055515130362

Epoch: 5| Step: 3
Training loss: 2.5413947105407715
Validation loss: 2.14766101539135

Epoch: 5| Step: 4
Training loss: 2.0291874408721924
Validation loss: 2.159183685978254

Epoch: 5| Step: 5
Training loss: 1.7878820896148682
Validation loss: 2.1619269102811813

Epoch: 5| Step: 6
Training loss: 2.049888849258423
Validation loss: 2.1553636342287064

Epoch: 5| Step: 7
Training loss: 2.118969678878784
Validation loss: 2.1533116896947226

Epoch: 5| Step: 8
Training loss: 1.3574590682983398
Validation loss: 2.159464513262113

Epoch: 5| Step: 9
Training loss: 1.5594507455825806
Validation loss: 2.1655405263106027

Epoch: 5| Step: 10
Training loss: 1.3958555459976196
Validation loss: 2.158337712287903

Epoch: 5| Step: 11
Training loss: 2.825005054473877
Validation loss: 2.176758865515391

Epoch: 232| Step: 0
Training loss: 1.7489020824432373
Validation loss: 2.1710558086633682

Epoch: 5| Step: 1
Training loss: 1.8161529302597046
Validation loss: 2.138549799720446

Epoch: 5| Step: 2
Training loss: 2.034468650817871
Validation loss: 2.165842056274414

Epoch: 5| Step: 3
Training loss: 1.9122015237808228
Validation loss: 2.1691883901755014

Epoch: 5| Step: 4
Training loss: 1.2422115802764893
Validation loss: 2.1339564472436905

Epoch: 5| Step: 5
Training loss: 1.7412254810333252
Validation loss: 2.134975771109263

Epoch: 5| Step: 6
Training loss: 1.964190125465393
Validation loss: 2.1453486730655036

Epoch: 5| Step: 7
Training loss: 2.194528579711914
Validation loss: 2.138300041357676

Epoch: 5| Step: 8
Training loss: 1.8128772974014282
Validation loss: 2.145967960357666

Epoch: 5| Step: 9
Training loss: 2.0339157581329346
Validation loss: 2.1412720878918967

Epoch: 5| Step: 10
Training loss: 2.101703643798828
Validation loss: 2.144365295767784

Epoch: 5| Step: 11
Training loss: 1.8048292398452759
Validation loss: 2.159128040075302

Epoch: 233| Step: 0
Training loss: 1.619837760925293
Validation loss: 2.1567892531553903

Epoch: 5| Step: 1
Training loss: 2.1582674980163574
Validation loss: 2.163596431414286

Epoch: 5| Step: 2
Training loss: 1.6585004329681396
Validation loss: 2.153767724831899

Epoch: 5| Step: 3
Training loss: 1.5439990758895874
Validation loss: 2.1641380240519843

Epoch: 5| Step: 4
Training loss: 1.7230663299560547
Validation loss: 2.1558685849110284

Epoch: 5| Step: 5
Training loss: 2.121319532394409
Validation loss: 2.157844473918279

Epoch: 5| Step: 6
Training loss: 2.1895365715026855
Validation loss: 2.1488628685474396

Epoch: 5| Step: 7
Training loss: 1.9096250534057617
Validation loss: 2.163387397925059

Epoch: 5| Step: 8
Training loss: 1.7259814739227295
Validation loss: 2.1508299012978873

Epoch: 5| Step: 9
Training loss: 2.0991592407226562
Validation loss: 2.156735604008039

Epoch: 5| Step: 10
Training loss: 1.8894550800323486
Validation loss: 2.1510783533255258

Epoch: 5| Step: 11
Training loss: 1.686946988105774
Validation loss: 2.159250477949778

Epoch: 234| Step: 0
Training loss: 1.761814832687378
Validation loss: 2.1458754340807595

Epoch: 5| Step: 1
Training loss: 1.711290955543518
Validation loss: 2.159836083650589

Epoch: 5| Step: 2
Training loss: 1.5620027780532837
Validation loss: 2.129477471113205

Epoch: 5| Step: 3
Training loss: 1.6902201175689697
Validation loss: 2.1567671597003937

Epoch: 5| Step: 4
Training loss: 2.3877415657043457
Validation loss: 2.1428398539622626

Epoch: 5| Step: 5
Training loss: 1.6583473682403564
Validation loss: 2.1551428685585656

Epoch: 5| Step: 6
Training loss: 2.2661044597625732
Validation loss: 2.158066675066948

Epoch: 5| Step: 7
Training loss: 2.2415671348571777
Validation loss: 2.1687796115875244

Epoch: 5| Step: 8
Training loss: 1.7182172536849976
Validation loss: 2.171165779232979

Epoch: 5| Step: 9
Training loss: 1.996241807937622
Validation loss: 2.169621447722117

Epoch: 5| Step: 10
Training loss: 1.4912031888961792
Validation loss: 2.157271603743235

Epoch: 5| Step: 11
Training loss: 2.269835948944092
Validation loss: 2.159796858827273

Epoch: 235| Step: 0
Training loss: 1.4581358432769775
Validation loss: 2.167860766251882

Epoch: 5| Step: 1
Training loss: 1.7247623205184937
Validation loss: 2.1640791495641074

Epoch: 5| Step: 2
Training loss: 1.8460471630096436
Validation loss: 2.147254859407743

Epoch: 5| Step: 3
Training loss: 1.4968401193618774
Validation loss: 2.156636595726013

Epoch: 5| Step: 4
Training loss: 2.4159419536590576
Validation loss: 2.144353926181793

Epoch: 5| Step: 5
Training loss: 1.6550134420394897
Validation loss: 2.145720879236857

Epoch: 5| Step: 6
Training loss: 1.8675706386566162
Validation loss: 2.148505300283432

Epoch: 5| Step: 7
Training loss: 1.8290687799453735
Validation loss: 2.137663424015045

Epoch: 5| Step: 8
Training loss: 2.1367099285125732
Validation loss: 2.149458557367325

Epoch: 5| Step: 9
Training loss: 2.3732447624206543
Validation loss: 2.1559637586275735

Epoch: 5| Step: 10
Training loss: 1.6712392568588257
Validation loss: 2.161043405532837

Epoch: 5| Step: 11
Training loss: 1.9150727987289429
Validation loss: 2.1557142982880273

Epoch: 236| Step: 0
Training loss: 2.2405343055725098
Validation loss: 2.1603952944278717

Epoch: 5| Step: 1
Training loss: 1.611742615699768
Validation loss: 2.165024310350418

Epoch: 5| Step: 2
Training loss: 1.5494964122772217
Validation loss: 2.178461571534475

Epoch: 5| Step: 3
Training loss: 2.56054949760437
Validation loss: 2.1780950476725898

Epoch: 5| Step: 4
Training loss: 1.7672805786132812
Validation loss: 2.181151951352755

Epoch: 5| Step: 5
Training loss: 1.6704896688461304
Validation loss: 2.177171697219213

Epoch: 5| Step: 6
Training loss: 1.7054462432861328
Validation loss: 2.184433644016584

Epoch: 5| Step: 7
Training loss: 1.749935507774353
Validation loss: 2.174545461932818

Epoch: 5| Step: 8
Training loss: 1.9590003490447998
Validation loss: 2.1718528469403586

Epoch: 5| Step: 9
Training loss: 1.7399123907089233
Validation loss: 2.1728820552428565

Epoch: 5| Step: 10
Training loss: 1.8891994953155518
Validation loss: 2.168568362792333

Epoch: 5| Step: 11
Training loss: 2.60386061668396
Validation loss: 2.174152135848999

Epoch: 237| Step: 0
Training loss: 2.010436773300171
Validation loss: 2.1673366079727807

Epoch: 5| Step: 1
Training loss: 1.5453039407730103
Validation loss: 2.161336600780487

Epoch: 5| Step: 2
Training loss: 1.6001030206680298
Validation loss: 2.1852878828843436

Epoch: 5| Step: 3
Training loss: 1.6017735004425049
Validation loss: 2.1658914536237717

Epoch: 5| Step: 4
Training loss: 1.5857856273651123
Validation loss: 2.1903536319732666

Epoch: 5| Step: 5
Training loss: 1.850956678390503
Validation loss: 2.170363555351893

Epoch: 5| Step: 6
Training loss: 2.4446141719818115
Validation loss: 2.1813298960526786

Epoch: 5| Step: 7
Training loss: 1.9034435749053955
Validation loss: 2.1815417359272637

Epoch: 5| Step: 8
Training loss: 2.349029064178467
Validation loss: 2.1737761050462723

Epoch: 5| Step: 9
Training loss: 1.9624645709991455
Validation loss: 2.172305350502332

Epoch: 5| Step: 10
Training loss: 1.587238073348999
Validation loss: 2.172983502348264

Epoch: 5| Step: 11
Training loss: 1.82407546043396
Validation loss: 2.1716910749673843

Epoch: 238| Step: 0
Training loss: 1.595533847808838
Validation loss: 2.1680818448464074

Epoch: 5| Step: 1
Training loss: 1.4988843202590942
Validation loss: 2.1798008332649865

Epoch: 5| Step: 2
Training loss: 2.256688117980957
Validation loss: 2.160254249970118

Epoch: 5| Step: 3
Training loss: 1.819406509399414
Validation loss: 2.160395627220472

Epoch: 5| Step: 4
Training loss: 1.7779756784439087
Validation loss: 2.1517925560474396

Epoch: 5| Step: 5
Training loss: 1.766582727432251
Validation loss: 2.1581280132134757

Epoch: 5| Step: 6
Training loss: 2.5961196422576904
Validation loss: 2.145941734313965

Epoch: 5| Step: 7
Training loss: 2.1497368812561035
Validation loss: 2.171668062607447

Epoch: 5| Step: 8
Training loss: 1.7701879739761353
Validation loss: 2.176078016559283

Epoch: 5| Step: 9
Training loss: 1.5434671640396118
Validation loss: 2.146663581331571

Epoch: 5| Step: 10
Training loss: 1.7479546070098877
Validation loss: 2.162141169110934

Epoch: 5| Step: 11
Training loss: 1.7663631439208984
Validation loss: 2.1486716866493225

Epoch: 239| Step: 0
Training loss: 1.7074922323226929
Validation loss: 2.16158364713192

Epoch: 5| Step: 1
Training loss: 1.7149251699447632
Validation loss: 2.1649993310372033

Epoch: 5| Step: 2
Training loss: 1.7791740894317627
Validation loss: 2.163633460799853

Epoch: 5| Step: 3
Training loss: 1.8000177145004272
Validation loss: 2.154322177171707

Epoch: 5| Step: 4
Training loss: 1.45509934425354
Validation loss: 2.157962590456009

Epoch: 5| Step: 5
Training loss: 2.214689254760742
Validation loss: 2.155355175336202

Epoch: 5| Step: 6
Training loss: 1.8711204528808594
Validation loss: 2.1572504242261252

Epoch: 5| Step: 7
Training loss: 2.2324442863464355
Validation loss: 2.1427464534838996

Epoch: 5| Step: 8
Training loss: 1.352563500404358
Validation loss: 2.135421931743622

Epoch: 5| Step: 9
Training loss: 1.7858304977416992
Validation loss: 2.146093795696894

Epoch: 5| Step: 10
Training loss: 2.4286069869995117
Validation loss: 2.142131840189298

Epoch: 5| Step: 11
Training loss: 2.3664321899414062
Validation loss: 2.160384252667427

Epoch: 240| Step: 0
Training loss: 1.931820273399353
Validation loss: 2.1375528226296105

Epoch: 5| Step: 1
Training loss: 2.030611038208008
Validation loss: 2.1402034858862558

Epoch: 5| Step: 2
Training loss: 1.6187330484390259
Validation loss: 2.13759774963061

Epoch: 5| Step: 3
Training loss: 1.1455276012420654
Validation loss: 2.144239912430445

Epoch: 5| Step: 4
Training loss: 2.2124404907226562
Validation loss: 2.1465271562337875

Epoch: 5| Step: 5
Training loss: 1.995642900466919
Validation loss: 2.1452491680781045

Epoch: 5| Step: 6
Training loss: 2.5427496433258057
Validation loss: 2.1640769938627877

Epoch: 5| Step: 7
Training loss: 1.643837332725525
Validation loss: 2.175234859188398

Epoch: 5| Step: 8
Training loss: 1.4754058122634888
Validation loss: 2.1845272183418274

Epoch: 5| Step: 9
Training loss: 1.5402991771697998
Validation loss: 2.182925601800283

Epoch: 5| Step: 10
Training loss: 2.233654022216797
Validation loss: 2.1870179176330566

Epoch: 5| Step: 11
Training loss: 2.0323362350463867
Validation loss: 2.181879366437594

Epoch: 241| Step: 0
Training loss: 1.771261215209961
Validation loss: 2.164650728305181

Epoch: 5| Step: 1
Training loss: 1.892422080039978
Validation loss: 2.1755349338054657

Epoch: 5| Step: 2
Training loss: 2.5641846656799316
Validation loss: 2.1575906574726105

Epoch: 5| Step: 3
Training loss: 1.5252830982208252
Validation loss: 2.169471397995949

Epoch: 5| Step: 4
Training loss: 2.17301344871521
Validation loss: 2.1452021300792694

Epoch: 5| Step: 5
Training loss: 1.7312644720077515
Validation loss: 2.1526658634344735

Epoch: 5| Step: 6
Training loss: 2.268789768218994
Validation loss: 2.156984473268191

Epoch: 5| Step: 7
Training loss: 1.5484113693237305
Validation loss: 2.1558017979065576

Epoch: 5| Step: 8
Training loss: 1.6911659240722656
Validation loss: 2.156071091691653

Epoch: 5| Step: 9
Training loss: 1.4955030679702759
Validation loss: 2.144941965738932

Epoch: 5| Step: 10
Training loss: 1.6911323070526123
Validation loss: 2.1374534517526627

Epoch: 5| Step: 11
Training loss: 2.891632556915283
Validation loss: 2.1660658369461694

Epoch: 242| Step: 0
Training loss: 2.3082151412963867
Validation loss: 2.171455959479014

Epoch: 5| Step: 1
Training loss: 2.275158643722534
Validation loss: 2.1699655751387277

Epoch: 5| Step: 2
Training loss: 1.8225295543670654
Validation loss: 2.177497307459513

Epoch: 5| Step: 3
Training loss: 1.3619401454925537
Validation loss: 2.1469963242610297

Epoch: 5| Step: 4
Training loss: 1.439103364944458
Validation loss: 2.1433565616607666

Epoch: 5| Step: 5
Training loss: 2.552424192428589
Validation loss: 2.134340892235438

Epoch: 5| Step: 6
Training loss: 1.9265186786651611
Validation loss: 2.1342832446098328

Epoch: 5| Step: 7
Training loss: 2.311483860015869
Validation loss: 2.1243333369493484

Epoch: 5| Step: 8
Training loss: 1.7789115905761719
Validation loss: 2.1130067904790244

Epoch: 5| Step: 9
Training loss: 1.4424645900726318
Validation loss: 2.0940895775953927

Epoch: 5| Step: 10
Training loss: 2.3505711555480957
Validation loss: 2.0931120216846466

Epoch: 5| Step: 11
Training loss: 1.0381848812103271
Validation loss: 2.072932163874308

Epoch: 243| Step: 0
Training loss: 1.9213697910308838
Validation loss: 2.0664609322945275

Epoch: 5| Step: 1
Training loss: 1.7257614135742188
Validation loss: 2.066060428818067

Epoch: 5| Step: 2
Training loss: 1.742327094078064
Validation loss: 2.059548035264015

Epoch: 5| Step: 3
Training loss: 1.6025846004486084
Validation loss: 2.0633578995863595

Epoch: 5| Step: 4
Training loss: 2.1708571910858154
Validation loss: 2.0656500458717346

Epoch: 5| Step: 5
Training loss: 2.1273789405822754
Validation loss: 2.0703308631976447

Epoch: 5| Step: 6
Training loss: 3.060971975326538
Validation loss: 2.061264748374621

Epoch: 5| Step: 7
Training loss: 1.6400667428970337
Validation loss: 2.0691874027252197

Epoch: 5| Step: 8
Training loss: 1.8331438302993774
Validation loss: 2.079311177134514

Epoch: 5| Step: 9
Training loss: 1.7974992990493774
Validation loss: 2.0789935936530433

Epoch: 5| Step: 10
Training loss: 1.896357536315918
Validation loss: 2.087884853283564

Epoch: 5| Step: 11
Training loss: 1.598365306854248
Validation loss: 2.085565040508906

Epoch: 244| Step: 0
Training loss: 1.7967212200164795
Validation loss: 2.0827161371707916

Epoch: 5| Step: 1
Training loss: 1.9753484725952148
Validation loss: 2.097472459077835

Epoch: 5| Step: 2
Training loss: 1.766455888748169
Validation loss: 2.118666723370552

Epoch: 5| Step: 3
Training loss: 2.40266752243042
Validation loss: 2.1334362626075745

Epoch: 5| Step: 4
Training loss: 1.5345591306686401
Validation loss: 2.1416352738936744

Epoch: 5| Step: 5
Training loss: 1.6591320037841797
Validation loss: 2.1331474582354226

Epoch: 5| Step: 6
Training loss: 2.1641063690185547
Validation loss: 2.1460989018281302

Epoch: 5| Step: 7
Training loss: 2.0542097091674805
Validation loss: 2.1469845374425254

Epoch: 5| Step: 8
Training loss: 1.7988736629486084
Validation loss: 2.1378285934527717

Epoch: 5| Step: 9
Training loss: 2.2011361122131348
Validation loss: 2.1238610645135245

Epoch: 5| Step: 10
Training loss: 1.885362982749939
Validation loss: 2.1329577565193176

Epoch: 5| Step: 11
Training loss: 1.0022038221359253
Validation loss: 2.133724813659986

Epoch: 245| Step: 0
Training loss: 1.6424310207366943
Validation loss: 2.153654173016548

Epoch: 5| Step: 1
Training loss: 2.134368658065796
Validation loss: 2.176534061630567

Epoch: 5| Step: 2
Training loss: 2.025879383087158
Validation loss: 2.176835378011068

Epoch: 5| Step: 3
Training loss: 2.1177773475646973
Validation loss: 2.1620042622089386

Epoch: 5| Step: 4
Training loss: 1.3104478120803833
Validation loss: 2.159969081481298

Epoch: 5| Step: 5
Training loss: 2.283269166946411
Validation loss: 2.154733623067538

Epoch: 5| Step: 6
Training loss: 2.0140557289123535
Validation loss: 2.1469374696413674

Epoch: 5| Step: 7
Training loss: 1.5147649049758911
Validation loss: 2.122069299221039

Epoch: 5| Step: 8
Training loss: 2.539750576019287
Validation loss: 2.1287728250026703

Epoch: 5| Step: 9
Training loss: 1.6686452627182007
Validation loss: 2.125207632780075

Epoch: 5| Step: 10
Training loss: 1.737985610961914
Validation loss: 2.1179041812817254

Epoch: 5| Step: 11
Training loss: 2.3133559226989746
Validation loss: 2.1414417872826257

Epoch: 246| Step: 0
Training loss: 2.4057493209838867
Validation loss: 2.139166901508967

Epoch: 5| Step: 1
Training loss: 1.4800821542739868
Validation loss: 2.1411608109871545

Epoch: 5| Step: 2
Training loss: 1.4005019664764404
Validation loss: 2.132112681865692

Epoch: 5| Step: 3
Training loss: 1.719097375869751
Validation loss: 2.1338709791501365

Epoch: 5| Step: 4
Training loss: 1.934080719947815
Validation loss: 2.123663326104482

Epoch: 5| Step: 5
Training loss: 2.0862369537353516
Validation loss: 2.1495638887087503

Epoch: 5| Step: 6
Training loss: 2.388343572616577
Validation loss: 2.1444160640239716

Epoch: 5| Step: 7
Training loss: 1.4358266592025757
Validation loss: 2.1372479597727456

Epoch: 5| Step: 8
Training loss: 1.7010043859481812
Validation loss: 2.139718567331632

Epoch: 5| Step: 9
Training loss: 2.678130626678467
Validation loss: 2.1524333357810974

Epoch: 5| Step: 10
Training loss: 1.6816288232803345
Validation loss: 2.1529418379068375

Epoch: 5| Step: 11
Training loss: 1.133331537246704
Validation loss: 2.1441656599442163

Epoch: 247| Step: 0
Training loss: 1.8049873113632202
Validation loss: 2.142344484726588

Epoch: 5| Step: 1
Training loss: 1.8425474166870117
Validation loss: 2.161366358399391

Epoch: 5| Step: 2
Training loss: 1.5493310689926147
Validation loss: 2.161101460456848

Epoch: 5| Step: 3
Training loss: 1.9539928436279297
Validation loss: 2.1734404116868973

Epoch: 5| Step: 4
Training loss: 1.845165491104126
Validation loss: 2.1621740261713662

Epoch: 5| Step: 5
Training loss: 1.7609760761260986
Validation loss: 2.1783762872219086

Epoch: 5| Step: 6
Training loss: 1.7055435180664062
Validation loss: 2.1733124603827796

Epoch: 5| Step: 7
Training loss: 1.7991981506347656
Validation loss: 2.1776769359906516

Epoch: 5| Step: 8
Training loss: 2.2583796977996826
Validation loss: 2.194493676225344

Epoch: 5| Step: 9
Training loss: 2.180384874343872
Validation loss: 2.1884311636288962

Epoch: 5| Step: 10
Training loss: 1.763228178024292
Validation loss: 2.1812877655029297

Epoch: 5| Step: 11
Training loss: 2.358602523803711
Validation loss: 2.181330904364586

Epoch: 248| Step: 0
Training loss: 1.9440419673919678
Validation loss: 2.1915684094031653

Epoch: 5| Step: 1
Training loss: 1.6735528707504272
Validation loss: 2.189099798599879

Epoch: 5| Step: 2
Training loss: 1.7395038604736328
Validation loss: 2.1831700205802917

Epoch: 5| Step: 3
Training loss: 1.5215984582901
Validation loss: 2.1913472215334573

Epoch: 5| Step: 4
Training loss: 1.8256222009658813
Validation loss: 2.1882499754428864

Epoch: 5| Step: 5
Training loss: 2.2832159996032715
Validation loss: 2.197335501511892

Epoch: 5| Step: 6
Training loss: 1.7815828323364258
Validation loss: 2.190448855360349

Epoch: 5| Step: 7
Training loss: 2.1360957622528076
Validation loss: 2.1952893237272897

Epoch: 5| Step: 8
Training loss: 1.77138352394104
Validation loss: 2.1911893586317697

Epoch: 5| Step: 9
Training loss: 1.521740198135376
Validation loss: 2.177461932102839

Epoch: 5| Step: 10
Training loss: 2.271404504776001
Validation loss: 2.171692192554474

Epoch: 5| Step: 11
Training loss: 2.0820064544677734
Validation loss: 2.1730814476807914

Epoch: 249| Step: 0
Training loss: 2.654974937438965
Validation loss: 2.1608083893855414

Epoch: 5| Step: 1
Training loss: 1.7830007076263428
Validation loss: 2.142551268140475

Epoch: 5| Step: 2
Training loss: 1.6186424493789673
Validation loss: 2.142047663529714

Epoch: 5| Step: 3
Training loss: 1.8895574808120728
Validation loss: 2.141338105003039

Epoch: 5| Step: 4
Training loss: 1.6877877712249756
Validation loss: 2.148406912883123

Epoch: 5| Step: 5
Training loss: 1.3789372444152832
Validation loss: 2.1567742178837457

Epoch: 5| Step: 6
Training loss: 2.4655706882476807
Validation loss: 2.156007170677185

Epoch: 5| Step: 7
Training loss: 2.188814401626587
Validation loss: 2.1681380718946457

Epoch: 5| Step: 8
Training loss: 1.4837255477905273
Validation loss: 2.1764407952626548

Epoch: 5| Step: 9
Training loss: 1.847747802734375
Validation loss: 2.1793014903863273

Epoch: 5| Step: 10
Training loss: 1.8207275867462158
Validation loss: 2.169361541668574

Epoch: 5| Step: 11
Training loss: 1.544183373451233
Validation loss: 2.1728033820788064

Epoch: 250| Step: 0
Training loss: 1.476322054862976
Validation loss: 2.184778705239296

Epoch: 5| Step: 1
Training loss: 1.3824636936187744
Validation loss: 2.172574539979299

Epoch: 5| Step: 2
Training loss: 1.8978536128997803
Validation loss: 2.1599590877691903

Epoch: 5| Step: 3
Training loss: 2.3866610527038574
Validation loss: 2.164322778582573

Epoch: 5| Step: 4
Training loss: 1.8197351694107056
Validation loss: 2.156967823704084

Epoch: 5| Step: 5
Training loss: 1.767189383506775
Validation loss: 2.160212109486262

Epoch: 5| Step: 6
Training loss: 1.690970778465271
Validation loss: 2.1470434218645096

Epoch: 5| Step: 7
Training loss: 1.6915909051895142
Validation loss: 2.1519119143486023

Epoch: 5| Step: 8
Training loss: 2.748727798461914
Validation loss: 2.1471110781033835

Epoch: 5| Step: 9
Training loss: 1.6080515384674072
Validation loss: 2.151862934231758

Epoch: 5| Step: 10
Training loss: 1.8020639419555664
Validation loss: 2.147560934225718

Epoch: 5| Step: 11
Training loss: 2.6164512634277344
Validation loss: 2.1504954596360526

Epoch: 251| Step: 0
Training loss: 1.8398431539535522
Validation loss: 2.1616660952568054

Epoch: 5| Step: 1
Training loss: 1.414888620376587
Validation loss: 2.151730885108312

Epoch: 5| Step: 2
Training loss: 1.0542453527450562
Validation loss: 2.1606988112131753

Epoch: 5| Step: 3
Training loss: 1.703089952468872
Validation loss: 2.1772436449925103

Epoch: 5| Step: 4
Training loss: 2.363074779510498
Validation loss: 2.1828568081061044

Epoch: 5| Step: 5
Training loss: 1.7732616662979126
Validation loss: 2.195342943072319

Epoch: 5| Step: 6
Training loss: 2.464265823364258
Validation loss: 2.1880942434072495

Epoch: 5| Step: 7
Training loss: 2.0557093620300293
Validation loss: 2.1976883163054786

Epoch: 5| Step: 8
Training loss: 1.9317147731781006
Validation loss: 2.194599077105522

Epoch: 5| Step: 9
Training loss: 1.6189416646957397
Validation loss: 2.196528196334839

Epoch: 5| Step: 10
Training loss: 1.7609262466430664
Validation loss: 2.2180768499771752

Epoch: 5| Step: 11
Training loss: 2.563368558883667
Validation loss: 2.1957930574814477

Epoch: 252| Step: 0
Training loss: 1.7763519287109375
Validation loss: 2.184505964318911

Epoch: 5| Step: 1
Training loss: 1.6380656957626343
Validation loss: 2.186623906095823

Epoch: 5| Step: 2
Training loss: 1.976266622543335
Validation loss: 2.1873681296904883

Epoch: 5| Step: 3
Training loss: 1.8730512857437134
Validation loss: 2.1900248577197394

Epoch: 5| Step: 4
Training loss: 1.582383632659912
Validation loss: 2.1909113824367523

Epoch: 5| Step: 5
Training loss: 1.7586342096328735
Validation loss: 2.185886392990748

Epoch: 5| Step: 6
Training loss: 1.9052015542984009
Validation loss: 2.177037944396337

Epoch: 5| Step: 7
Training loss: 2.094498872756958
Validation loss: 2.1833195785681405

Epoch: 5| Step: 8
Training loss: 2.1011745929718018
Validation loss: 2.1759069661299386

Epoch: 5| Step: 9
Training loss: 1.5327768325805664
Validation loss: 2.18977198501428

Epoch: 5| Step: 10
Training loss: 1.9099104404449463
Validation loss: 2.1940071185429892

Epoch: 5| Step: 11
Training loss: 1.9947714805603027
Validation loss: 2.1789102802673974

Epoch: 253| Step: 0
Training loss: 1.9362674951553345
Validation loss: 2.189351116617521

Epoch: 5| Step: 1
Training loss: 2.185964584350586
Validation loss: 2.171732266743978

Epoch: 5| Step: 2
Training loss: 1.3191776275634766
Validation loss: 2.177152633666992

Epoch: 5| Step: 3
Training loss: 2.026064872741699
Validation loss: 2.1721260299285254

Epoch: 5| Step: 4
Training loss: 2.046485424041748
Validation loss: 2.1602950195471444

Epoch: 5| Step: 5
Training loss: 1.616739273071289
Validation loss: 2.1884301900863647

Epoch: 5| Step: 6
Training loss: 1.7438634634017944
Validation loss: 2.1822772522767386

Epoch: 5| Step: 7
Training loss: 2.0747714042663574
Validation loss: 2.1988426446914673

Epoch: 5| Step: 8
Training loss: 1.573464035987854
Validation loss: 2.198225205143293

Epoch: 5| Step: 9
Training loss: 1.994451880455017
Validation loss: 2.198179547985395

Epoch: 5| Step: 10
Training loss: 1.2647000551223755
Validation loss: 2.2045829196770987

Epoch: 5| Step: 11
Training loss: 3.4620232582092285
Validation loss: 2.2177541355292

Epoch: 254| Step: 0
Training loss: 1.832754135131836
Validation loss: 2.190841495990753

Epoch: 5| Step: 1
Training loss: 1.6402225494384766
Validation loss: 2.2038619915644326

Epoch: 5| Step: 2
Training loss: 2.0033063888549805
Validation loss: 2.1906495094299316

Epoch: 5| Step: 3
Training loss: 1.6046276092529297
Validation loss: 2.1806753277778625

Epoch: 5| Step: 4
Training loss: 1.5106172561645508
Validation loss: 2.173348233103752

Epoch: 5| Step: 5
Training loss: 1.4116588830947876
Validation loss: 2.1791325211524963

Epoch: 5| Step: 6
Training loss: 2.195380687713623
Validation loss: 2.164191404978434

Epoch: 5| Step: 7
Training loss: 2.223076105117798
Validation loss: 2.161424934864044

Epoch: 5| Step: 8
Training loss: 2.188129425048828
Validation loss: 2.1779142121473947

Epoch: 5| Step: 9
Training loss: 1.419861912727356
Validation loss: 2.164903442064921

Epoch: 5| Step: 10
Training loss: 2.4385504722595215
Validation loss: 2.1827160815397897

Epoch: 5| Step: 11
Training loss: 0.9112052321434021
Validation loss: 2.192107086380323

Epoch: 255| Step: 0
Training loss: 2.1349942684173584
Validation loss: 2.187425176302592

Epoch: 5| Step: 1
Training loss: 1.7639658451080322
Validation loss: 2.1867754757404327

Epoch: 5| Step: 2
Training loss: 1.7576528787612915
Validation loss: 2.1898794372876487

Epoch: 5| Step: 3
Training loss: 1.7419195175170898
Validation loss: 2.1874427249034247

Epoch: 5| Step: 4
Training loss: 1.887739896774292
Validation loss: 2.1776790817578635

Epoch: 5| Step: 5
Training loss: 1.5772874355316162
Validation loss: 2.1678747783104577

Epoch: 5| Step: 6
Training loss: 1.8136764764785767
Validation loss: 2.190309261282285

Epoch: 5| Step: 7
Training loss: 1.4655497074127197
Validation loss: 2.1759783079226813

Epoch: 5| Step: 8
Training loss: 1.5611045360565186
Validation loss: 2.1573739697535834

Epoch: 5| Step: 9
Training loss: 2.2731616497039795
Validation loss: 2.1589282751083374

Epoch: 5| Step: 10
Training loss: 2.5373783111572266
Validation loss: 2.1426972647507987

Epoch: 5| Step: 11
Training loss: 1.8353090286254883
Validation loss: 2.1498577296733856

Epoch: 256| Step: 0
Training loss: 1.940069556236267
Validation loss: 2.155976196130117

Epoch: 5| Step: 1
Training loss: 1.563463807106018
Validation loss: 2.1603025048971176

Epoch: 5| Step: 2
Training loss: 1.8580909967422485
Validation loss: 2.1701587438583374

Epoch: 5| Step: 3
Training loss: 2.2110683917999268
Validation loss: 2.1765255431334176

Epoch: 5| Step: 4
Training loss: 1.8308004140853882
Validation loss: 2.188611164689064

Epoch: 5| Step: 5
Training loss: 2.063384532928467
Validation loss: 2.2011302212874093

Epoch: 5| Step: 6
Training loss: 2.4447100162506104
Validation loss: 2.196217586596807

Epoch: 5| Step: 7
Training loss: 2.077491044998169
Validation loss: 2.192480077346166

Epoch: 5| Step: 8
Training loss: 1.7830250263214111
Validation loss: 2.1590859790643058

Epoch: 5| Step: 9
Training loss: 1.6666145324707031
Validation loss: 2.148277079065641

Epoch: 5| Step: 10
Training loss: 1.6802241802215576
Validation loss: 2.1343105187018714

Epoch: 5| Step: 11
Training loss: 3.063422203063965
Validation loss: 2.1364828695853553

Epoch: 257| Step: 0
Training loss: 2.2440266609191895
Validation loss: 2.1288388868172965

Epoch: 5| Step: 1
Training loss: 1.7918617725372314
Validation loss: 2.1188458998998008

Epoch: 5| Step: 2
Training loss: 1.786957025527954
Validation loss: 2.121964847048124

Epoch: 5| Step: 3
Training loss: 1.5452505350112915
Validation loss: 2.125107283393542

Epoch: 5| Step: 4
Training loss: 1.7483599185943604
Validation loss: 2.1222562988599143

Epoch: 5| Step: 5
Training loss: 2.1725659370422363
Validation loss: 2.1324422359466553

Epoch: 5| Step: 6
Training loss: 2.1082065105438232
Validation loss: 2.1189661224683127

Epoch: 5| Step: 7
Training loss: 1.7789089679718018
Validation loss: 2.1168872664372125

Epoch: 5| Step: 8
Training loss: 1.7880550622940063
Validation loss: 2.140623758236567

Epoch: 5| Step: 9
Training loss: 2.044975996017456
Validation loss: 2.1287103295326233

Epoch: 5| Step: 10
Training loss: 1.5881297588348389
Validation loss: 2.1308751751979194

Epoch: 5| Step: 11
Training loss: 1.0195105075836182
Validation loss: 2.1374790569146476

Epoch: 258| Step: 0
Training loss: 1.5314347743988037
Validation loss: 2.138804386059443

Epoch: 5| Step: 1
Training loss: 2.0324180126190186
Validation loss: 2.1431175768375397

Epoch: 5| Step: 2
Training loss: 1.7745006084442139
Validation loss: 2.140419473250707

Epoch: 5| Step: 3
Training loss: 2.05812668800354
Validation loss: 2.146281292041143

Epoch: 5| Step: 4
Training loss: 1.7525326013565063
Validation loss: 2.1280440787474313

Epoch: 5| Step: 5
Training loss: 1.1962101459503174
Validation loss: 2.1279554665088654

Epoch: 5| Step: 6
Training loss: 2.384101390838623
Validation loss: 2.140546585122744

Epoch: 5| Step: 7
Training loss: 2.0681586265563965
Validation loss: 2.155637880166372

Epoch: 5| Step: 8
Training loss: 1.489400029182434
Validation loss: 2.1686830719312034

Epoch: 5| Step: 9
Training loss: 2.453439235687256
Validation loss: 2.1696697572867074

Epoch: 5| Step: 10
Training loss: 1.5452951192855835
Validation loss: 2.1844933331012726

Epoch: 5| Step: 11
Training loss: 1.581602692604065
Validation loss: 2.181460897127787

Epoch: 259| Step: 0
Training loss: 1.3494433164596558
Validation loss: 2.194972982009252

Epoch: 5| Step: 1
Training loss: 1.6316273212432861
Validation loss: 2.1811726639668145

Epoch: 5| Step: 2
Training loss: 1.7238563299179077
Validation loss: 2.1759181221326194

Epoch: 5| Step: 3
Training loss: 1.8346103429794312
Validation loss: 2.176188478867213

Epoch: 5| Step: 4
Training loss: 1.9449669122695923
Validation loss: 2.1767235596974692

Epoch: 5| Step: 5
Training loss: 1.7922449111938477
Validation loss: 2.1795590668916702

Epoch: 5| Step: 6
Training loss: 1.8368422985076904
Validation loss: 2.1843400249878564

Epoch: 5| Step: 7
Training loss: 2.147189140319824
Validation loss: 2.1713616251945496

Epoch: 5| Step: 8
Training loss: 2.0601096153259277
Validation loss: 2.173984318971634

Epoch: 5| Step: 9
Training loss: 2.15097975730896
Validation loss: 2.1819883584976196

Epoch: 5| Step: 10
Training loss: 1.5259886980056763
Validation loss: 2.178140560785929

Epoch: 5| Step: 11
Training loss: 0.9893904328346252
Validation loss: 2.189491535226504

Epoch: 260| Step: 0
Training loss: 1.653616189956665
Validation loss: 2.1831285804510117

Epoch: 5| Step: 1
Training loss: 1.6323091983795166
Validation loss: 2.1854700396458306

Epoch: 5| Step: 2
Training loss: 1.8263591527938843
Validation loss: 2.1713923712571463

Epoch: 5| Step: 3
Training loss: 1.8744513988494873
Validation loss: 2.1793053398529687

Epoch: 5| Step: 4
Training loss: 2.311641216278076
Validation loss: 2.1738547484079995

Epoch: 5| Step: 5
Training loss: 1.8127954006195068
Validation loss: 2.167140151063601

Epoch: 5| Step: 6
Training loss: 1.451245665550232
Validation loss: 2.154877702395121

Epoch: 5| Step: 7
Training loss: 2.169595956802368
Validation loss: 2.159481560190519

Epoch: 5| Step: 8
Training loss: 1.8012101650238037
Validation loss: 2.1559356848398843

Epoch: 5| Step: 9
Training loss: 2.025463104248047
Validation loss: 2.161277487874031

Epoch: 5| Step: 10
Training loss: 1.4642326831817627
Validation loss: 2.174511507153511

Epoch: 5| Step: 11
Training loss: 1.7295500040054321
Validation loss: 2.158922384182612

Epoch: 261| Step: 0
Training loss: 2.0600249767303467
Validation loss: 2.160338540871938

Epoch: 5| Step: 1
Training loss: 1.9427309036254883
Validation loss: 2.161204939087232

Epoch: 5| Step: 2
Training loss: 1.8791253566741943
Validation loss: 2.1628475238879523

Epoch: 5| Step: 3
Training loss: 1.3388428688049316
Validation loss: 2.157313828667005

Epoch: 5| Step: 4
Training loss: 1.8009769916534424
Validation loss: 2.151610637704531

Epoch: 5| Step: 5
Training loss: 1.7029750347137451
Validation loss: 2.1516559521357217

Epoch: 5| Step: 6
Training loss: 1.872452735900879
Validation loss: 2.1597360223531723

Epoch: 5| Step: 7
Training loss: 1.7880268096923828
Validation loss: 2.165506894389788

Epoch: 5| Step: 8
Training loss: 1.5917739868164062
Validation loss: 2.1537136137485504

Epoch: 5| Step: 9
Training loss: 2.0332043170928955
Validation loss: 2.1466775834560394

Epoch: 5| Step: 10
Training loss: 1.9615055322647095
Validation loss: 2.149268547693888

Epoch: 5| Step: 11
Training loss: 2.5328783988952637
Validation loss: 2.142875830332438

Epoch: 262| Step: 0
Training loss: 1.5301761627197266
Validation loss: 2.1601135482390723

Epoch: 5| Step: 1
Training loss: 1.6306798458099365
Validation loss: 2.161567449569702

Epoch: 5| Step: 2
Training loss: 1.8947479724884033
Validation loss: 2.165352240204811

Epoch: 5| Step: 3
Training loss: 2.186957359313965
Validation loss: 2.1641784012317657

Epoch: 5| Step: 4
Training loss: 2.160332679748535
Validation loss: 2.1717764735221863

Epoch: 5| Step: 5
Training loss: 2.1286003589630127
Validation loss: 2.1620835065841675

Epoch: 5| Step: 6
Training loss: 1.7951183319091797
Validation loss: 2.152199938893318

Epoch: 5| Step: 7
Training loss: 1.6635990142822266
Validation loss: 2.1546429991722107

Epoch: 5| Step: 8
Training loss: 1.3516528606414795
Validation loss: 2.1735305388768515

Epoch: 5| Step: 9
Training loss: 1.4141876697540283
Validation loss: 2.181442196170489

Epoch: 5| Step: 10
Training loss: 2.1085808277130127
Validation loss: 2.176476667324702

Epoch: 5| Step: 11
Training loss: 2.2239136695861816
Validation loss: 2.1731976370016732

Epoch: 263| Step: 0
Training loss: 2.1447410583496094
Validation loss: 2.1800571580727897

Epoch: 5| Step: 1
Training loss: 2.032758951187134
Validation loss: 2.1725046982367835

Epoch: 5| Step: 2
Training loss: 1.3457320928573608
Validation loss: 2.175210083524386

Epoch: 5| Step: 3
Training loss: 2.0066423416137695
Validation loss: 2.1901611934105554

Epoch: 5| Step: 4
Training loss: 2.0896103382110596
Validation loss: 2.201002905766169

Epoch: 5| Step: 5
Training loss: 1.7535731792449951
Validation loss: 2.206810792287191

Epoch: 5| Step: 6
Training loss: 2.2057361602783203
Validation loss: 2.199734792113304

Epoch: 5| Step: 7
Training loss: 1.6879310607910156
Validation loss: 2.208218743403753

Epoch: 5| Step: 8
Training loss: 1.7968928813934326
Validation loss: 2.2103735506534576

Epoch: 5| Step: 9
Training loss: 1.1925432682037354
Validation loss: 2.185732071598371

Epoch: 5| Step: 10
Training loss: 1.5174381732940674
Validation loss: 2.190891077121099

Epoch: 5| Step: 11
Training loss: 1.0758121013641357
Validation loss: 2.168287992477417

Epoch: 264| Step: 0
Training loss: 2.032770872116089
Validation loss: 2.1695312758286796

Epoch: 5| Step: 1
Training loss: 1.8234164714813232
Validation loss: 2.164807309707006

Epoch: 5| Step: 2
Training loss: 1.4987123012542725
Validation loss: 2.15446138381958

Epoch: 5| Step: 3
Training loss: 2.065450668334961
Validation loss: 2.1400368014971414

Epoch: 5| Step: 4
Training loss: 1.8076906204223633
Validation loss: 2.141632636388143

Epoch: 5| Step: 5
Training loss: 1.7882531881332397
Validation loss: 2.151418685913086

Epoch: 5| Step: 6
Training loss: 1.9329274892807007
Validation loss: 2.1692892213662467

Epoch: 5| Step: 7
Training loss: 1.2398098707199097
Validation loss: 2.14985953271389

Epoch: 5| Step: 8
Training loss: 1.6181033849716187
Validation loss: 2.159110670288404

Epoch: 5| Step: 9
Training loss: 1.603960394859314
Validation loss: 2.1530098021030426

Epoch: 5| Step: 10
Training loss: 2.294279098510742
Validation loss: 2.1748615304629006

Epoch: 5| Step: 11
Training loss: 2.509459972381592
Validation loss: 2.1718203326066337

Epoch: 265| Step: 0
Training loss: 2.038865327835083
Validation loss: 2.166385695338249

Epoch: 5| Step: 1
Training loss: 1.4494407176971436
Validation loss: 2.140206277370453

Epoch: 5| Step: 2
Training loss: 1.4979588985443115
Validation loss: 2.164475202560425

Epoch: 5| Step: 3
Training loss: 1.8143947124481201
Validation loss: 2.1530799667040506

Epoch: 5| Step: 4
Training loss: 1.5263563394546509
Validation loss: 2.1434556444485984

Epoch: 5| Step: 5
Training loss: 2.1642708778381348
Validation loss: 2.1661214331785836

Epoch: 5| Step: 6
Training loss: 2.170206308364868
Validation loss: 2.1451875468095145

Epoch: 5| Step: 7
Training loss: 1.5451478958129883
Validation loss: 2.1487432519594827

Epoch: 5| Step: 8
Training loss: 1.2990714311599731
Validation loss: 2.1581499129533768

Epoch: 5| Step: 9
Training loss: 2.0803000926971436
Validation loss: 2.165445849299431

Epoch: 5| Step: 10
Training loss: 2.3237884044647217
Validation loss: 2.180995836853981

Epoch: 5| Step: 11
Training loss: 2.159109115600586
Validation loss: 2.1789563645919166

Epoch: 266| Step: 0
Training loss: 2.1707608699798584
Validation loss: 2.1720367123683295

Epoch: 5| Step: 1
Training loss: 1.9726728200912476
Validation loss: 2.190918803215027

Epoch: 5| Step: 2
Training loss: 1.3868038654327393
Validation loss: 2.188615918159485

Epoch: 5| Step: 3
Training loss: 1.5445221662521362
Validation loss: 2.178481236100197

Epoch: 5| Step: 4
Training loss: 2.10282826423645
Validation loss: 2.1713906973600388

Epoch: 5| Step: 5
Training loss: 1.4042004346847534
Validation loss: 2.1709755659103394

Epoch: 5| Step: 6
Training loss: 1.2365162372589111
Validation loss: 2.1681781262159348

Epoch: 5| Step: 7
Training loss: 2.485193967819214
Validation loss: 2.1594602316617966

Epoch: 5| Step: 8
Training loss: 1.576456069946289
Validation loss: 2.18417896827062

Epoch: 5| Step: 9
Training loss: 2.0620431900024414
Validation loss: 2.1518199344476066

Epoch: 5| Step: 10
Training loss: 2.059835910797119
Validation loss: 2.1748616695404053

Epoch: 5| Step: 11
Training loss: 1.5311241149902344
Validation loss: 2.158140699068705

Epoch: 267| Step: 0
Training loss: 1.8635432720184326
Validation loss: 2.1508529633283615

Epoch: 5| Step: 1
Training loss: 1.7968075275421143
Validation loss: 2.1556816597779593

Epoch: 5| Step: 2
Training loss: 1.6340806484222412
Validation loss: 2.1497379342714944

Epoch: 5| Step: 3
Training loss: 1.2366164922714233
Validation loss: 2.18458058933417

Epoch: 5| Step: 4
Training loss: 1.7328956127166748
Validation loss: 2.1807166387637458

Epoch: 5| Step: 5
Training loss: 2.538654088973999
Validation loss: 2.1867568492889404

Epoch: 5| Step: 6
Training loss: 1.899909257888794
Validation loss: 2.1708403329054513

Epoch: 5| Step: 7
Training loss: 1.5453615188598633
Validation loss: 2.1759713888168335

Epoch: 5| Step: 8
Training loss: 1.9441957473754883
Validation loss: 2.1879504521687827

Epoch: 5| Step: 9
Training loss: 1.5946952104568481
Validation loss: 2.1669703225294747

Epoch: 5| Step: 10
Training loss: 2.1307239532470703
Validation loss: 2.181349515914917

Epoch: 5| Step: 11
Training loss: 2.5899875164031982
Validation loss: 2.168629174431165

Epoch: 268| Step: 0
Training loss: 2.0475857257843018
Validation loss: 2.1828599721193314

Epoch: 5| Step: 1
Training loss: 1.8490502834320068
Validation loss: 2.181898077329

Epoch: 5| Step: 2
Training loss: 1.4422072172164917
Validation loss: 2.1829253236452737

Epoch: 5| Step: 3
Training loss: 1.891366958618164
Validation loss: 2.1749106496572495

Epoch: 5| Step: 4
Training loss: 2.1614296436309814
Validation loss: 2.1845562756061554

Epoch: 5| Step: 5
Training loss: 1.5872541666030884
Validation loss: 2.172031357884407

Epoch: 5| Step: 6
Training loss: 2.071502685546875
Validation loss: 2.1741160253683725

Epoch: 5| Step: 7
Training loss: 1.6679801940917969
Validation loss: 2.1911710103352866

Epoch: 5| Step: 8
Training loss: 1.6486972570419312
Validation loss: 2.1807117958863578

Epoch: 5| Step: 9
Training loss: 1.2784596681594849
Validation loss: 2.1763942688703537

Epoch: 5| Step: 10
Training loss: 2.2191665172576904
Validation loss: 2.1731396516164145

Epoch: 5| Step: 11
Training loss: 1.4652659893035889
Validation loss: 2.177405521273613

Epoch: 269| Step: 0
Training loss: 1.8737537860870361
Validation loss: 2.1853276789188385

Epoch: 5| Step: 1
Training loss: 1.1574561595916748
Validation loss: 2.181295226017634

Epoch: 5| Step: 2
Training loss: 1.3963195085525513
Validation loss: 2.1837356885274253

Epoch: 5| Step: 3
Training loss: 1.6534067392349243
Validation loss: 2.173559154073397

Epoch: 5| Step: 4
Training loss: 1.7889697551727295
Validation loss: 2.172227591276169

Epoch: 5| Step: 5
Training loss: 2.3702778816223145
Validation loss: 2.1746017734209695

Epoch: 5| Step: 6
Training loss: 1.8283450603485107
Validation loss: 2.1848488251368203

Epoch: 5| Step: 7
Training loss: 2.139338970184326
Validation loss: 2.172706365585327

Epoch: 5| Step: 8
Training loss: 2.182490825653076
Validation loss: 2.197977900505066

Epoch: 5| Step: 9
Training loss: 1.5758644342422485
Validation loss: 2.1700395345687866

Epoch: 5| Step: 10
Training loss: 1.4945485591888428
Validation loss: 2.173950826128324

Epoch: 5| Step: 11
Training loss: 2.271641969680786
Validation loss: 2.182372137904167

Epoch: 270| Step: 0
Training loss: 1.9054638147354126
Validation loss: 2.186000029246012

Epoch: 5| Step: 1
Training loss: 1.593009352684021
Validation loss: 2.1849627097447715

Epoch: 5| Step: 2
Training loss: 1.6255099773406982
Validation loss: 2.1803225378195443

Epoch: 5| Step: 3
Training loss: 1.7433446645736694
Validation loss: 2.1609472731749215

Epoch: 5| Step: 4
Training loss: 1.4956690073013306
Validation loss: 2.1728591521581015

Epoch: 5| Step: 5
Training loss: 1.7308037281036377
Validation loss: 2.1546068837245307

Epoch: 5| Step: 6
Training loss: 2.1519598960876465
Validation loss: 2.1802798559268317

Epoch: 5| Step: 7
Training loss: 2.5485668182373047
Validation loss: 2.1731526603301368

Epoch: 5| Step: 8
Training loss: 1.4660274982452393
Validation loss: 2.1685519069433212

Epoch: 5| Step: 9
Training loss: 1.539819598197937
Validation loss: 2.1704540898402533

Epoch: 5| Step: 10
Training loss: 1.6155204772949219
Validation loss: 2.1713145275910697

Epoch: 5| Step: 11
Training loss: 1.9577419757843018
Validation loss: 2.154908667008082

Epoch: 271| Step: 0
Training loss: 1.3324573040008545
Validation loss: 2.17864195505778

Epoch: 5| Step: 1
Training loss: 1.652899980545044
Validation loss: 2.18491338690122

Epoch: 5| Step: 2
Training loss: 1.9906387329101562
Validation loss: 2.1674599796533585

Epoch: 5| Step: 3
Training loss: 1.591921091079712
Validation loss: 2.1760711073875427

Epoch: 5| Step: 4
Training loss: 2.25030255317688
Validation loss: 2.2016375760237374

Epoch: 5| Step: 5
Training loss: 1.842337965965271
Validation loss: 2.195867821574211

Epoch: 5| Step: 6
Training loss: 1.920654296875
Validation loss: 2.2079843233029046

Epoch: 5| Step: 7
Training loss: 2.2511146068573
Validation loss: 2.179001266757647

Epoch: 5| Step: 8
Training loss: 2.33679461479187
Validation loss: 2.1654691100120544

Epoch: 5| Step: 9
Training loss: 1.7834179401397705
Validation loss: 2.1549032032489777

Epoch: 5| Step: 10
Training loss: 1.3656682968139648
Validation loss: 2.1573091447353363

Epoch: 5| Step: 11
Training loss: 1.2570871114730835
Validation loss: 2.146794021129608

Epoch: 272| Step: 0
Training loss: 2.005584239959717
Validation loss: 2.148526738087336

Epoch: 5| Step: 1
Training loss: 1.9748642444610596
Validation loss: 2.1555078079303107

Epoch: 5| Step: 2
Training loss: 1.2606395483016968
Validation loss: 2.1320605725049973

Epoch: 5| Step: 3
Training loss: 1.5526096820831299
Validation loss: 2.1355144133170447

Epoch: 5| Step: 4
Training loss: 1.473874807357788
Validation loss: 2.139626900355021

Epoch: 5| Step: 5
Training loss: 1.6818145513534546
Validation loss: 2.1269691387812295

Epoch: 5| Step: 6
Training loss: 2.008652448654175
Validation loss: 2.1305079758167267

Epoch: 5| Step: 7
Training loss: 2.2882349491119385
Validation loss: 2.1238934099674225

Epoch: 5| Step: 8
Training loss: 1.8172290325164795
Validation loss: 2.1232826113700867

Epoch: 5| Step: 9
Training loss: 2.510394811630249
Validation loss: 2.1414082000652948

Epoch: 5| Step: 10
Training loss: 1.2644248008728027
Validation loss: 2.1341939071814218

Epoch: 5| Step: 11
Training loss: 1.708884358406067
Validation loss: 2.128462160627047

Epoch: 273| Step: 0
Training loss: 1.9565868377685547
Validation loss: 2.139037529627482

Epoch: 5| Step: 1
Training loss: 2.365950107574463
Validation loss: 2.155290832122167

Epoch: 5| Step: 2
Training loss: 2.2810540199279785
Validation loss: 2.1421539932489395

Epoch: 5| Step: 3
Training loss: 1.9187818765640259
Validation loss: 2.150264466802279

Epoch: 5| Step: 4
Training loss: 1.5143136978149414
Validation loss: 2.148061881462733

Epoch: 5| Step: 5
Training loss: 1.6801551580429077
Validation loss: 2.144390106201172

Epoch: 5| Step: 6
Training loss: 1.8454402685165405
Validation loss: 2.1351071298122406

Epoch: 5| Step: 7
Training loss: 1.3037338256835938
Validation loss: 2.15774667263031

Epoch: 5| Step: 8
Training loss: 1.3944270610809326
Validation loss: 2.1534185856580734

Epoch: 5| Step: 9
Training loss: 1.649740219116211
Validation loss: 2.144163817167282

Epoch: 5| Step: 10
Training loss: 2.2802653312683105
Validation loss: 2.1723664651314416

Epoch: 5| Step: 11
Training loss: 0.6947477459907532
Validation loss: 2.167344098289808

Epoch: 274| Step: 0
Training loss: 1.1638469696044922
Validation loss: 2.1533224085966745

Epoch: 5| Step: 1
Training loss: 2.3190035820007324
Validation loss: 2.1526086131731668

Epoch: 5| Step: 2
Training loss: 1.8947134017944336
Validation loss: 2.1586732417345047

Epoch: 5| Step: 3
Training loss: 1.9007753133773804
Validation loss: 2.167245085040728

Epoch: 5| Step: 4
Training loss: 1.7866798639297485
Validation loss: 2.167299578587214

Epoch: 5| Step: 5
Training loss: 2.1676077842712402
Validation loss: 2.1887600471576056

Epoch: 5| Step: 6
Training loss: 1.3358056545257568
Validation loss: 2.193807447950045

Epoch: 5| Step: 7
Training loss: 1.9793037176132202
Validation loss: 2.1877532551685968

Epoch: 5| Step: 8
Training loss: 2.0079097747802734
Validation loss: 2.2181982497374215

Epoch: 5| Step: 9
Training loss: 1.7082643508911133
Validation loss: 2.213452324271202

Epoch: 5| Step: 10
Training loss: 1.435851812362671
Validation loss: 2.21374182899793

Epoch: 5| Step: 11
Training loss: 2.4357168674468994
Validation loss: 2.218251496553421

Epoch: 275| Step: 0
Training loss: 2.388716459274292
Validation loss: 2.2194244066874185

Epoch: 5| Step: 1
Training loss: 1.461061716079712
Validation loss: 2.195952524741491

Epoch: 5| Step: 2
Training loss: 1.629516839981079
Validation loss: 2.1761482059955597

Epoch: 5| Step: 3
Training loss: 1.7375285625457764
Validation loss: 2.1590778281291327

Epoch: 5| Step: 4
Training loss: 1.26499605178833
Validation loss: 2.178341339031855

Epoch: 5| Step: 5
Training loss: 2.346752643585205
Validation loss: 2.1674967755874

Epoch: 5| Step: 6
Training loss: 2.261955976486206
Validation loss: 2.164333005746206

Epoch: 5| Step: 7
Training loss: 1.8835182189941406
Validation loss: 2.1768674850463867

Epoch: 5| Step: 8
Training loss: 1.6363565921783447
Validation loss: 2.1573545833428702

Epoch: 5| Step: 9
Training loss: 1.6738407611846924
Validation loss: 2.189676264921824

Epoch: 5| Step: 10
Training loss: 1.7364521026611328
Validation loss: 2.185260777672132

Epoch: 5| Step: 11
Training loss: 0.7325451374053955
Validation loss: 2.183834264675776

Epoch: 276| Step: 0
Training loss: 1.5511318445205688
Validation loss: 2.199540222684542

Epoch: 5| Step: 1
Training loss: 1.592612385749817
Validation loss: 2.1702541957298913

Epoch: 5| Step: 2
Training loss: 1.945953369140625
Validation loss: 2.185797154903412

Epoch: 5| Step: 3
Training loss: 1.5574883222579956
Validation loss: 2.2053684840599694

Epoch: 5| Step: 4
Training loss: 2.118828535079956
Validation loss: 2.197218805551529

Epoch: 5| Step: 5
Training loss: 1.68096125125885
Validation loss: 2.180577630798022

Epoch: 5| Step: 6
Training loss: 1.9489405155181885
Validation loss: 2.185464695096016

Epoch: 5| Step: 7
Training loss: 1.464491605758667
Validation loss: 2.172469695409139

Epoch: 5| Step: 8
Training loss: 1.8834120035171509
Validation loss: 2.181456337372462

Epoch: 5| Step: 9
Training loss: 2.3011772632598877
Validation loss: 2.185716172059377

Epoch: 5| Step: 10
Training loss: 1.4645601511001587
Validation loss: 2.1810620377461114

Epoch: 5| Step: 11
Training loss: 1.2216897010803223
Validation loss: 2.204279234011968

Epoch: 277| Step: 0
Training loss: 1.502468466758728
Validation loss: 2.18206196029981

Epoch: 5| Step: 1
Training loss: 2.020672559738159
Validation loss: 2.1968727161486945

Epoch: 5| Step: 2
Training loss: 1.9854519367218018
Validation loss: 2.1928444703420005

Epoch: 5| Step: 3
Training loss: 1.3472826480865479
Validation loss: 2.1984685361385345

Epoch: 5| Step: 4
Training loss: 1.7424014806747437
Validation loss: 2.1710064063469567

Epoch: 5| Step: 5
Training loss: 1.7445487976074219
Validation loss: 2.178249880671501

Epoch: 5| Step: 6
Training loss: 2.2067081928253174
Validation loss: 2.1717841923236847

Epoch: 5| Step: 7
Training loss: 1.934464454650879
Validation loss: 2.1622265179951987

Epoch: 5| Step: 8
Training loss: 1.5529650449752808
Validation loss: 2.1693353752295175

Epoch: 5| Step: 9
Training loss: 1.8105055093765259
Validation loss: 2.1493141601483026

Epoch: 5| Step: 10
Training loss: 1.9293838739395142
Validation loss: 2.1514060298601785

Epoch: 5| Step: 11
Training loss: 0.38348478078842163
Validation loss: 2.145869870980581

Epoch: 278| Step: 0
Training loss: 1.7349021434783936
Validation loss: 2.147866576910019

Epoch: 5| Step: 1
Training loss: 1.518906593322754
Validation loss: 2.161705508828163

Epoch: 5| Step: 2
Training loss: 1.469071388244629
Validation loss: 2.1544254968563714

Epoch: 5| Step: 3
Training loss: 1.9932270050048828
Validation loss: 2.1548730929692588

Epoch: 5| Step: 4
Training loss: 2.431760787963867
Validation loss: 2.1662979225317636

Epoch: 5| Step: 5
Training loss: 1.4073331356048584
Validation loss: 2.1686696112155914

Epoch: 5| Step: 6
Training loss: 1.946292519569397
Validation loss: 2.1709994872411094

Epoch: 5| Step: 7
Training loss: 1.8853317499160767
Validation loss: 2.179143567879995

Epoch: 5| Step: 8
Training loss: 2.166308879852295
Validation loss: 2.1671966910362244

Epoch: 5| Step: 9
Training loss: 1.7292410135269165
Validation loss: 2.1840305775403976

Epoch: 5| Step: 10
Training loss: 1.421608328819275
Validation loss: 2.1987470239400864

Epoch: 5| Step: 11
Training loss: 0.868686318397522
Validation loss: 2.1975467105706534

Epoch: 279| Step: 0
Training loss: 2.198361873626709
Validation loss: 2.2221021304527917

Epoch: 5| Step: 1
Training loss: 2.054687261581421
Validation loss: 2.2244228969017663

Epoch: 5| Step: 2
Training loss: 1.6587789058685303
Validation loss: 2.216376706957817

Epoch: 5| Step: 3
Training loss: 1.98052179813385
Validation loss: 2.199552044272423

Epoch: 5| Step: 4
Training loss: 1.9969494342803955
Validation loss: 2.1622079412142434

Epoch: 5| Step: 5
Training loss: 2.0825388431549072
Validation loss: 2.1783557881911597

Epoch: 5| Step: 6
Training loss: 1.6771529912948608
Validation loss: 2.1445835332075753

Epoch: 5| Step: 7
Training loss: 1.5401241779327393
Validation loss: 2.1841817845900855

Epoch: 5| Step: 8
Training loss: 1.8556591272354126
Validation loss: 2.172319084405899

Epoch: 5| Step: 9
Training loss: 1.4640920162200928
Validation loss: 2.1690316100915275

Epoch: 5| Step: 10
Training loss: 1.1833442449569702
Validation loss: 2.1624201436837516

Epoch: 5| Step: 11
Training loss: 1.3224040269851685
Validation loss: 2.186853418747584

Epoch: 280| Step: 0
Training loss: 2.114070177078247
Validation loss: 2.1786255886157355

Epoch: 5| Step: 1
Training loss: 0.9030684232711792
Validation loss: 2.1795822580655417

Epoch: 5| Step: 2
Training loss: 1.560697317123413
Validation loss: 2.1584891974925995

Epoch: 5| Step: 3
Training loss: 1.2401303052902222
Validation loss: 2.17405312259992

Epoch: 5| Step: 4
Training loss: 2.165572166442871
Validation loss: 2.1895855019489923

Epoch: 5| Step: 5
Training loss: 1.5747196674346924
Validation loss: 2.1691939532756805

Epoch: 5| Step: 6
Training loss: 1.865009069442749
Validation loss: 2.183538188536962

Epoch: 5| Step: 7
Training loss: 1.881718397140503
Validation loss: 2.174593468507131

Epoch: 5| Step: 8
Training loss: 2.2364563941955566
Validation loss: 2.1813337206840515

Epoch: 5| Step: 9
Training loss: 1.5642167329788208
Validation loss: 2.1817444612582526

Epoch: 5| Step: 10
Training loss: 2.2954325675964355
Validation loss: 2.188804859916369

Epoch: 5| Step: 11
Training loss: 0.676333487033844
Validation loss: 2.181491951147715

Epoch: 281| Step: 0
Training loss: 1.4519296884536743
Validation loss: 2.1773046056429544

Epoch: 5| Step: 1
Training loss: 1.9476121664047241
Validation loss: 2.198844959338506

Epoch: 5| Step: 2
Training loss: 1.6061382293701172
Validation loss: 2.209754670659701

Epoch: 5| Step: 3
Training loss: 1.8337990045547485
Validation loss: 2.1829432994127274

Epoch: 5| Step: 4
Training loss: 1.4299551248550415
Validation loss: 2.1877601891756058

Epoch: 5| Step: 5
Training loss: 1.92839777469635
Validation loss: 2.193039685487747

Epoch: 5| Step: 6
Training loss: 2.0443994998931885
Validation loss: 2.187549591064453

Epoch: 5| Step: 7
Training loss: 2.01021409034729
Validation loss: 2.188039774696032

Epoch: 5| Step: 8
Training loss: 1.3995152711868286
Validation loss: 2.154090245564779

Epoch: 5| Step: 9
Training loss: 1.7686688899993896
Validation loss: 2.184977928797404

Epoch: 5| Step: 10
Training loss: 1.7918132543563843
Validation loss: 2.1809917787710824

Epoch: 5| Step: 11
Training loss: 1.2975184917449951
Validation loss: 2.186123033364614

Epoch: 282| Step: 0
Training loss: 2.4263319969177246
Validation loss: 2.204856942097346

Epoch: 5| Step: 1
Training loss: 1.7389535903930664
Validation loss: 2.1878302892049155

Epoch: 5| Step: 2
Training loss: 2.01855731010437
Validation loss: 2.190511003136635

Epoch: 5| Step: 3
Training loss: 1.8068689107894897
Validation loss: 2.1979709764321647

Epoch: 5| Step: 4
Training loss: 0.9908055067062378
Validation loss: 2.200718884666761

Epoch: 5| Step: 5
Training loss: 1.5544003248214722
Validation loss: 2.1834382116794586

Epoch: 5| Step: 6
Training loss: 1.7548103332519531
Validation loss: 2.1821745882431665

Epoch: 5| Step: 7
Training loss: 1.664965271949768
Validation loss: 2.2052418937285743

Epoch: 5| Step: 8
Training loss: 1.5397613048553467
Validation loss: 2.1495001216729483

Epoch: 5| Step: 9
Training loss: 1.7972629070281982
Validation loss: 2.189784819881121

Epoch: 5| Step: 10
Training loss: 2.2890279293060303
Validation loss: 2.1644772241512933

Epoch: 5| Step: 11
Training loss: 0.8476092219352722
Validation loss: 2.179065321882566

Epoch: 283| Step: 0
Training loss: 1.9201335906982422
Validation loss: 2.1539084712664285

Epoch: 5| Step: 1
Training loss: 1.7406857013702393
Validation loss: 2.160521482427915

Epoch: 5| Step: 2
Training loss: 1.8257471323013306
Validation loss: 2.1820915838082633

Epoch: 5| Step: 3
Training loss: 1.688105821609497
Validation loss: 2.159471874435743

Epoch: 5| Step: 4
Training loss: 1.335794448852539
Validation loss: 2.179126098752022

Epoch: 5| Step: 5
Training loss: 1.7153440713882446
Validation loss: 2.1723054548104606

Epoch: 5| Step: 6
Training loss: 1.9406391382217407
Validation loss: 2.1814718743165336

Epoch: 5| Step: 7
Training loss: 1.8480144739151
Validation loss: 2.169796039660772

Epoch: 5| Step: 8
Training loss: 1.8403240442276
Validation loss: 2.1412354509035745

Epoch: 5| Step: 9
Training loss: 1.955614686012268
Validation loss: 2.1613449305295944

Epoch: 5| Step: 10
Training loss: 1.2334789037704468
Validation loss: 2.1529738257328668

Epoch: 5| Step: 11
Training loss: 3.0770187377929688
Validation loss: 2.1533388793468475

Epoch: 284| Step: 0
Training loss: 1.8802820444107056
Validation loss: 2.147670477628708

Epoch: 5| Step: 1
Training loss: 1.3397914171218872
Validation loss: 2.143964762489001

Epoch: 5| Step: 2
Training loss: 1.949188470840454
Validation loss: 2.149915888905525

Epoch: 5| Step: 3
Training loss: 1.190443515777588
Validation loss: 2.152033264438311

Epoch: 5| Step: 4
Training loss: 1.5437602996826172
Validation loss: 2.14670866727829

Epoch: 5| Step: 5
Training loss: 1.506222128868103
Validation loss: 2.135485236843427

Epoch: 5| Step: 6
Training loss: 2.3915793895721436
Validation loss: 2.145295878251394

Epoch: 5| Step: 7
Training loss: 1.5784062147140503
Validation loss: 2.159210741519928

Epoch: 5| Step: 8
Training loss: 2.092933177947998
Validation loss: 2.161017030477524

Epoch: 5| Step: 9
Training loss: 2.0604746341705322
Validation loss: 2.1740658283233643

Epoch: 5| Step: 10
Training loss: 1.6260604858398438
Validation loss: 2.168642352024714

Epoch: 5| Step: 11
Training loss: 1.186078429222107
Validation loss: 2.1758635292450585

Epoch: 285| Step: 0
Training loss: 1.0312632322311401
Validation loss: 2.151028737425804

Epoch: 5| Step: 1
Training loss: 1.5387182235717773
Validation loss: 2.1786240140597024

Epoch: 5| Step: 2
Training loss: 1.8892738819122314
Validation loss: 2.1480505714813867

Epoch: 5| Step: 3
Training loss: 1.4647204875946045
Validation loss: 2.159734477599462

Epoch: 5| Step: 4
Training loss: 1.568943738937378
Validation loss: 2.1700652142365775

Epoch: 5| Step: 5
Training loss: 1.9681346416473389
Validation loss: 2.1715576450030007

Epoch: 5| Step: 6
Training loss: 1.8331880569458008
Validation loss: 2.166449268658956

Epoch: 5| Step: 7
Training loss: 1.7336698770523071
Validation loss: 2.1639936715364456

Epoch: 5| Step: 8
Training loss: 1.9624452590942383
Validation loss: 2.1861071040232978

Epoch: 5| Step: 9
Training loss: 2.034618377685547
Validation loss: 2.1713162114222846

Epoch: 5| Step: 10
Training loss: 1.8486181497573853
Validation loss: 2.155731499195099

Epoch: 5| Step: 11
Training loss: 2.7525153160095215
Validation loss: 2.1815755367279053

Epoch: 286| Step: 0
Training loss: 1.6544650793075562
Validation loss: 2.168625076611837

Epoch: 5| Step: 1
Training loss: 1.6106207370758057
Validation loss: 2.183654169241587

Epoch: 5| Step: 2
Training loss: 1.9428211450576782
Validation loss: 2.1884650886058807

Epoch: 5| Step: 3
Training loss: 2.0714306831359863
Validation loss: 2.176985184351603

Epoch: 5| Step: 4
Training loss: 1.8299529552459717
Validation loss: 2.1781553675731025

Epoch: 5| Step: 5
Training loss: 1.8240922689437866
Validation loss: 2.172135273615519

Epoch: 5| Step: 6
Training loss: 1.6769908666610718
Validation loss: 2.1833770722150803

Epoch: 5| Step: 7
Training loss: 1.1682078838348389
Validation loss: 2.1724884112675986

Epoch: 5| Step: 8
Training loss: 2.0477004051208496
Validation loss: 2.170503189166387

Epoch: 5| Step: 9
Training loss: 1.9139068126678467
Validation loss: 2.1764801839987435

Epoch: 5| Step: 10
Training loss: 1.8142402172088623
Validation loss: 2.1773721973101297

Epoch: 5| Step: 11
Training loss: 0.8515024185180664
Validation loss: 2.167108108599981

Epoch: 287| Step: 0
Training loss: 1.4625250101089478
Validation loss: 2.1760550240675607

Epoch: 5| Step: 1
Training loss: 2.1625423431396484
Validation loss: 2.1569364418586097

Epoch: 5| Step: 2
Training loss: 1.1385542154312134
Validation loss: 2.1326670547326407

Epoch: 5| Step: 3
Training loss: 1.7924476861953735
Validation loss: 2.142139489452044

Epoch: 5| Step: 4
Training loss: 1.5633981227874756
Validation loss: 2.1501474380493164

Epoch: 5| Step: 5
Training loss: 1.9410403966903687
Validation loss: 2.145220955212911

Epoch: 5| Step: 6
Training loss: 1.5357016324996948
Validation loss: 2.140076900521914

Epoch: 5| Step: 7
Training loss: 1.7482776641845703
Validation loss: 2.136499206225077

Epoch: 5| Step: 8
Training loss: 2.538207530975342
Validation loss: 2.135446324944496

Epoch: 5| Step: 9
Training loss: 1.4593727588653564
Validation loss: 2.152223120133082

Epoch: 5| Step: 10
Training loss: 1.8375349044799805
Validation loss: 2.1547627995411553

Epoch: 5| Step: 11
Training loss: 1.7722142934799194
Validation loss: 2.1743740191062293

Epoch: 288| Step: 0
Training loss: 1.5073870420455933
Validation loss: 2.172675927480062

Epoch: 5| Step: 1
Training loss: 1.4922151565551758
Validation loss: 2.174306864539782

Epoch: 5| Step: 2
Training loss: 1.2911092042922974
Validation loss: 2.168924182653427

Epoch: 5| Step: 3
Training loss: 1.7314653396606445
Validation loss: 2.1874678234259286

Epoch: 5| Step: 4
Training loss: 2.4013614654541016
Validation loss: 2.1781921088695526

Epoch: 5| Step: 5
Training loss: 1.6695537567138672
Validation loss: 2.172203024228414

Epoch: 5| Step: 6
Training loss: 2.0148587226867676
Validation loss: 2.200907915830612

Epoch: 5| Step: 7
Training loss: 1.5440971851348877
Validation loss: 2.190041035413742

Epoch: 5| Step: 8
Training loss: 1.5073192119598389
Validation loss: 2.1932436426480613

Epoch: 5| Step: 9
Training loss: 2.4951679706573486
Validation loss: 2.1951856513818107

Epoch: 5| Step: 10
Training loss: 1.762927770614624
Validation loss: 2.2004730502764382

Epoch: 5| Step: 11
Training loss: 0.9990842938423157
Validation loss: 2.186924248933792

Epoch: 289| Step: 0
Training loss: 1.376421570777893
Validation loss: 2.197488566239675

Epoch: 5| Step: 1
Training loss: 1.9808269739151
Validation loss: 2.1960094273090363

Epoch: 5| Step: 2
Training loss: 1.7829793691635132
Validation loss: 2.1943214734395347

Epoch: 5| Step: 3
Training loss: 2.104215145111084
Validation loss: 2.1991717517375946

Epoch: 5| Step: 4
Training loss: 1.2732874155044556
Validation loss: 2.1971154709657035

Epoch: 5| Step: 5
Training loss: 1.4720429182052612
Validation loss: 2.1908330768346786

Epoch: 5| Step: 6
Training loss: 1.166581392288208
Validation loss: 2.1824470857779183

Epoch: 5| Step: 7
Training loss: 1.8577884435653687
Validation loss: 2.177605470021566

Epoch: 5| Step: 8
Training loss: 2.0575313568115234
Validation loss: 2.182752768198649

Epoch: 5| Step: 9
Training loss: 1.4454399347305298
Validation loss: 2.1538533667723336

Epoch: 5| Step: 10
Training loss: 2.392728567123413
Validation loss: 2.1679336527983346

Epoch: 5| Step: 11
Training loss: 1.0187783241271973
Validation loss: 2.1750963727633157

Epoch: 290| Step: 0
Training loss: 2.480886697769165
Validation loss: 2.15212053557237

Epoch: 5| Step: 1
Training loss: 1.7117868661880493
Validation loss: 2.159976974129677

Epoch: 5| Step: 2
Training loss: 1.9072202444076538
Validation loss: 2.160745625694593

Epoch: 5| Step: 3
Training loss: 2.031027317047119
Validation loss: 2.1693503061930337

Epoch: 5| Step: 4
Training loss: 1.5038785934448242
Validation loss: 2.1650774776935577

Epoch: 5| Step: 5
Training loss: 1.6505634784698486
Validation loss: 2.15989787876606

Epoch: 5| Step: 6
Training loss: 2.025667667388916
Validation loss: 2.1431386222441993

Epoch: 5| Step: 7
Training loss: 1.6119798421859741
Validation loss: 2.1344806452592215

Epoch: 5| Step: 8
Training loss: 1.0685936212539673
Validation loss: 2.1489157676696777

Epoch: 5| Step: 9
Training loss: 0.7415445446968079
Validation loss: 2.133544926842054

Epoch: 5| Step: 10
Training loss: 2.0831847190856934
Validation loss: 2.123791148265203

Epoch: 5| Step: 11
Training loss: 1.8600938320159912
Validation loss: 2.1374348650376

Epoch: 291| Step: 0
Training loss: 1.9538034200668335
Validation loss: 2.148044024904569

Epoch: 5| Step: 1
Training loss: 1.8175761699676514
Validation loss: 2.166444962223371

Epoch: 5| Step: 2
Training loss: 1.4838900566101074
Validation loss: 2.152243663867315

Epoch: 5| Step: 3
Training loss: 1.5203577280044556
Validation loss: 2.180379072825114

Epoch: 5| Step: 4
Training loss: 2.1925830841064453
Validation loss: 2.1605286250511804

Epoch: 5| Step: 5
Training loss: 1.5052783489227295
Validation loss: 2.177390138308207

Epoch: 5| Step: 6
Training loss: 1.2770503759384155
Validation loss: 2.1757702430089316

Epoch: 5| Step: 7
Training loss: 1.618589162826538
Validation loss: 2.1672858198483786

Epoch: 5| Step: 8
Training loss: 2.344123125076294
Validation loss: 2.203612501422564

Epoch: 5| Step: 9
Training loss: 1.8550952672958374
Validation loss: 2.204325705766678

Epoch: 5| Step: 10
Training loss: 1.6344197988510132
Validation loss: 2.1981190194686255

Epoch: 5| Step: 11
Training loss: 1.7691593170166016
Validation loss: 2.2009847909212112

Epoch: 292| Step: 0
Training loss: 1.6042325496673584
Validation loss: 2.1941112677256265

Epoch: 5| Step: 1
Training loss: 2.1368136405944824
Validation loss: 2.1929475218057632

Epoch: 5| Step: 2
Training loss: 1.8885891437530518
Validation loss: 2.1931405564149222

Epoch: 5| Step: 3
Training loss: 1.9813005924224854
Validation loss: 2.184997464219729

Epoch: 5| Step: 4
Training loss: 1.8531198501586914
Validation loss: 2.178986440102259

Epoch: 5| Step: 5
Training loss: 1.4017056226730347
Validation loss: 2.1920825193325677

Epoch: 5| Step: 6
Training loss: 1.471922755241394
Validation loss: 2.171206514040629

Epoch: 5| Step: 7
Training loss: 1.2851334810256958
Validation loss: 2.17139063278834

Epoch: 5| Step: 8
Training loss: 1.586085319519043
Validation loss: 2.1732697784900665

Epoch: 5| Step: 9
Training loss: 1.5118502378463745
Validation loss: 2.180961713194847

Epoch: 5| Step: 10
Training loss: 1.7227550745010376
Validation loss: 2.1600436717271805

Epoch: 5| Step: 11
Training loss: 3.266662836074829
Validation loss: 2.167027826110522

Epoch: 293| Step: 0
Training loss: 1.7871662378311157
Validation loss: 2.165140430132548

Epoch: 5| Step: 1
Training loss: 1.245856523513794
Validation loss: 2.15819750726223

Epoch: 5| Step: 2
Training loss: 1.5803231000900269
Validation loss: 2.1564482897520065

Epoch: 5| Step: 3
Training loss: 2.376377820968628
Validation loss: 2.162039409081141

Epoch: 5| Step: 4
Training loss: 1.6267240047454834
Validation loss: 2.1573568085829415

Epoch: 5| Step: 5
Training loss: 2.1856582164764404
Validation loss: 2.1633600890636444

Epoch: 5| Step: 6
Training loss: 1.630098581314087
Validation loss: 2.1589713046948114

Epoch: 5| Step: 7
Training loss: 1.3270524740219116
Validation loss: 2.1422614604234695

Epoch: 5| Step: 8
Training loss: 1.5461716651916504
Validation loss: 2.158353795607885

Epoch: 5| Step: 9
Training loss: 1.6839783191680908
Validation loss: 2.1371034582455954

Epoch: 5| Step: 10
Training loss: 1.7764304876327515
Validation loss: 2.1529644628365836

Epoch: 5| Step: 11
Training loss: 1.1024537086486816
Validation loss: 2.16240028043588

Epoch: 294| Step: 0
Training loss: 1.50087308883667
Validation loss: 2.174270490805308

Epoch: 5| Step: 1
Training loss: 2.2468066215515137
Validation loss: 2.1823886384566626

Epoch: 5| Step: 2
Training loss: 1.6690361499786377
Validation loss: 2.214364250500997

Epoch: 5| Step: 3
Training loss: 2.0511953830718994
Validation loss: 2.2033969362576804

Epoch: 5| Step: 4
Training loss: 2.229027271270752
Validation loss: 2.21956966817379

Epoch: 5| Step: 5
Training loss: 1.543237566947937
Validation loss: 2.1916439880927405

Epoch: 5| Step: 6
Training loss: 1.5842134952545166
Validation loss: 2.213621293505033

Epoch: 5| Step: 7
Training loss: 1.5766404867172241
Validation loss: 2.198221335808436

Epoch: 5| Step: 8
Training loss: 1.2827376127243042
Validation loss: 2.1928785890340805

Epoch: 5| Step: 9
Training loss: 1.4488723278045654
Validation loss: 2.220338851213455

Epoch: 5| Step: 10
Training loss: 1.7598893642425537
Validation loss: 2.199840838710467

Epoch: 5| Step: 11
Training loss: 1.229091763496399
Validation loss: 2.2178022464116416

Epoch: 295| Step: 0
Training loss: 1.4927690029144287
Validation loss: 2.2005609522263208

Epoch: 5| Step: 1
Training loss: 1.6969400644302368
Validation loss: 2.2035879691441855

Epoch: 5| Step: 2
Training loss: 2.1275875568389893
Validation loss: 2.2347728312015533

Epoch: 5| Step: 3
Training loss: 1.5844568014144897
Validation loss: 2.217173849542936

Epoch: 5| Step: 4
Training loss: 2.208461046218872
Validation loss: 2.2219335635503135

Epoch: 5| Step: 5
Training loss: 1.644587516784668
Validation loss: 2.2251786291599274

Epoch: 5| Step: 6
Training loss: 1.6515932083129883
Validation loss: 2.2180640548467636

Epoch: 5| Step: 7
Training loss: 1.70476496219635
Validation loss: 2.2156518598397574

Epoch: 5| Step: 8
Training loss: 1.1836525201797485
Validation loss: 2.2208926677703857

Epoch: 5| Step: 9
Training loss: 2.336822986602783
Validation loss: 2.2095562368631363

Epoch: 5| Step: 10
Training loss: 1.303410530090332
Validation loss: 2.1991961002349854

Epoch: 5| Step: 11
Training loss: 1.505315899848938
Validation loss: 2.20970526834329

Epoch: 296| Step: 0
Training loss: 1.9209539890289307
Validation loss: 2.1735668977101645

Epoch: 5| Step: 1
Training loss: 1.7897796630859375
Validation loss: 2.1934985717137656

Epoch: 5| Step: 2
Training loss: 1.4351617097854614
Validation loss: 2.193496803442637

Epoch: 5| Step: 3
Training loss: 1.6234909296035767
Validation loss: 2.204632500807444

Epoch: 5| Step: 4
Training loss: 2.0227503776550293
Validation loss: 2.207355409860611

Epoch: 5| Step: 5
Training loss: 1.6098413467407227
Validation loss: 2.186297059059143

Epoch: 5| Step: 6
Training loss: 2.0336995124816895
Validation loss: 2.183740258216858

Epoch: 5| Step: 7
Training loss: 1.7344669103622437
Validation loss: 2.168073385953903

Epoch: 5| Step: 8
Training loss: 1.8101508617401123
Validation loss: 2.1713385432958603

Epoch: 5| Step: 9
Training loss: 1.4639172554016113
Validation loss: 2.1714107592900596

Epoch: 5| Step: 10
Training loss: 1.2308018207550049
Validation loss: 2.1749195804198584

Epoch: 5| Step: 11
Training loss: 1.1474659442901611
Validation loss: 2.1922555963198342

Epoch: 297| Step: 0
Training loss: 1.612451195716858
Validation loss: 2.184214264154434

Epoch: 5| Step: 1
Training loss: 2.291409969329834
Validation loss: 2.185082991917928

Epoch: 5| Step: 2
Training loss: 1.2821319103240967
Validation loss: 2.1775978406270347

Epoch: 5| Step: 3
Training loss: 1.9533336162567139
Validation loss: 2.198793644706408

Epoch: 5| Step: 4
Training loss: 1.2840975522994995
Validation loss: 2.2067710061868033

Epoch: 5| Step: 5
Training loss: 2.2066454887390137
Validation loss: 2.196708162625631

Epoch: 5| Step: 6
Training loss: 1.3552627563476562
Validation loss: 2.1881255408128104

Epoch: 5| Step: 7
Training loss: 1.866904854774475
Validation loss: 2.213758940498034

Epoch: 5| Step: 8
Training loss: 2.283864974975586
Validation loss: 2.2028913100560508

Epoch: 5| Step: 9
Training loss: 1.5739386081695557
Validation loss: 2.201910157998403

Epoch: 5| Step: 10
Training loss: 1.3074861764907837
Validation loss: 2.2124750912189484

Epoch: 5| Step: 11
Training loss: 0.9237920641899109
Validation loss: 2.202098007003466

Epoch: 298| Step: 0
Training loss: 1.7843248844146729
Validation loss: 2.2395319988330207

Epoch: 5| Step: 1
Training loss: 2.210721731185913
Validation loss: 2.2409311681985855

Epoch: 5| Step: 2
Training loss: 1.6133861541748047
Validation loss: 2.25519290069739

Epoch: 5| Step: 3
Training loss: 2.167509078979492
Validation loss: 2.2306092182795205

Epoch: 5| Step: 4
Training loss: 2.0313336849212646
Validation loss: 2.240425854921341

Epoch: 5| Step: 5
Training loss: 1.7713661193847656
Validation loss: 2.2469132443269095

Epoch: 5| Step: 6
Training loss: 1.3893463611602783
Validation loss: 2.24102055033048

Epoch: 5| Step: 7
Training loss: 1.5942124128341675
Validation loss: 2.2339036961396537

Epoch: 5| Step: 8
Training loss: 1.7425380945205688
Validation loss: 2.2085908750693

Epoch: 5| Step: 9
Training loss: 1.2253738641738892
Validation loss: 2.2096654872099557

Epoch: 5| Step: 10
Training loss: 1.5820900201797485
Validation loss: 2.2062676499287286

Epoch: 5| Step: 11
Training loss: 2.8124094009399414
Validation loss: 2.174679527680079

Epoch: 299| Step: 0
Training loss: 2.398446798324585
Validation loss: 2.159437750776609

Epoch: 5| Step: 1
Training loss: 1.9471676349639893
Validation loss: 2.147286002834638

Epoch: 5| Step: 2
Training loss: 1.3657410144805908
Validation loss: 2.167051667968432

Epoch: 5| Step: 3
Training loss: 1.7561619281768799
Validation loss: 2.175406187772751

Epoch: 5| Step: 4
Training loss: 1.530078649520874
Validation loss: 2.1709758887688317

Epoch: 5| Step: 5
Training loss: 1.86415696144104
Validation loss: 2.1883532057205834

Epoch: 5| Step: 6
Training loss: 1.6864051818847656
Validation loss: 2.184866279363632

Epoch: 5| Step: 7
Training loss: 2.229548692703247
Validation loss: 2.18602354824543

Epoch: 5| Step: 8
Training loss: 1.6652648448944092
Validation loss: 2.1563159624735513

Epoch: 5| Step: 9
Training loss: 1.3344173431396484
Validation loss: 2.1800239433844886

Epoch: 5| Step: 10
Training loss: 1.024348497390747
Validation loss: 2.1897012243668237

Epoch: 5| Step: 11
Training loss: 2.447472095489502
Validation loss: 2.196510225534439

Epoch: 300| Step: 0
Training loss: 2.0391998291015625
Validation loss: 2.194749807318052

Epoch: 5| Step: 1
Training loss: 1.3549330234527588
Validation loss: 2.222796549399694

Epoch: 5| Step: 2
Training loss: 2.335257053375244
Validation loss: 2.190430442492167

Epoch: 5| Step: 3
Training loss: 1.5304921865463257
Validation loss: 2.1969884634017944

Epoch: 5| Step: 4
Training loss: 1.8264997005462646
Validation loss: 2.226510470112165

Epoch: 5| Step: 5
Training loss: 1.8739845752716064
Validation loss: 2.2215381860733032

Epoch: 5| Step: 6
Training loss: 1.7510850429534912
Validation loss: 2.2216652433077493

Epoch: 5| Step: 7
Training loss: 1.605677604675293
Validation loss: 2.2075812369585037

Epoch: 5| Step: 8
Training loss: 1.5350371599197388
Validation loss: 2.21733458340168

Epoch: 5| Step: 9
Training loss: 1.5946661233901978
Validation loss: 2.216403822104136

Epoch: 5| Step: 10
Training loss: 1.1678612232208252
Validation loss: 2.2184093395868936

Epoch: 5| Step: 11
Training loss: 2.1742889881134033
Validation loss: 2.202628900607427

Epoch: 301| Step: 0
Training loss: 1.8164699077606201
Validation loss: 2.2083890537420907

Epoch: 5| Step: 1
Training loss: 1.3277842998504639
Validation loss: 2.1983076433340707

Epoch: 5| Step: 2
Training loss: 2.3445355892181396
Validation loss: 2.1967333555221558

Epoch: 5| Step: 3
Training loss: 1.992883324623108
Validation loss: 2.207537074883779

Epoch: 5| Step: 4
Training loss: 1.4578603506088257
Validation loss: 2.182976563771566

Epoch: 5| Step: 5
Training loss: 1.669862151145935
Validation loss: 2.2128461798032126

Epoch: 5| Step: 6
Training loss: 1.339470624923706
Validation loss: 2.202669153610865

Epoch: 5| Step: 7
Training loss: 1.541646957397461
Validation loss: 2.2307202418645224

Epoch: 5| Step: 8
Training loss: 1.3637440204620361
Validation loss: 2.229461451371511

Epoch: 5| Step: 9
Training loss: 2.3074607849121094
Validation loss: 2.212094167868296

Epoch: 5| Step: 10
Training loss: 1.7102601528167725
Validation loss: 2.2117871989806495

Epoch: 5| Step: 11
Training loss: 1.0228874683380127
Validation loss: 2.2316819429397583

Epoch: 302| Step: 0
Training loss: 1.5149016380310059
Validation loss: 2.207314133644104

Epoch: 5| Step: 1
Training loss: 1.7406361103057861
Validation loss: 2.214119945963224

Epoch: 5| Step: 2
Training loss: 1.9350589513778687
Validation loss: 2.1961324562629065

Epoch: 5| Step: 3
Training loss: 1.848610281944275
Validation loss: 2.2169145196676254

Epoch: 5| Step: 4
Training loss: 1.140174388885498
Validation loss: 2.1761895368496575

Epoch: 5| Step: 5
Training loss: 2.321775436401367
Validation loss: 2.1965799828370414

Epoch: 5| Step: 6
Training loss: 1.5388052463531494
Validation loss: 2.1611057966947556

Epoch: 5| Step: 7
Training loss: 1.622789740562439
Validation loss: 2.16975799202919

Epoch: 5| Step: 8
Training loss: 1.8267982006072998
Validation loss: 2.1789525945981345

Epoch: 5| Step: 9
Training loss: 1.5434985160827637
Validation loss: 2.1790037552515664

Epoch: 5| Step: 10
Training loss: 1.222768783569336
Validation loss: 2.161722252766291

Epoch: 5| Step: 11
Training loss: 1.813812494277954
Validation loss: 2.1519698202610016

Epoch: 303| Step: 0
Training loss: 1.4210447072982788
Validation loss: 2.152955114841461

Epoch: 5| Step: 1
Training loss: 1.580381989479065
Validation loss: 2.169223671158155

Epoch: 5| Step: 2
Training loss: 1.6317218542099
Validation loss: 2.1594929297765098

Epoch: 5| Step: 3
Training loss: 1.8336775302886963
Validation loss: 2.1803292532761893

Epoch: 5| Step: 4
Training loss: 1.7050994634628296
Validation loss: 2.1642429679632187

Epoch: 5| Step: 5
Training loss: 1.3309274911880493
Validation loss: 2.163733055194219

Epoch: 5| Step: 6
Training loss: 1.3308521509170532
Validation loss: 2.1609693616628647

Epoch: 5| Step: 7
Training loss: 1.9980947971343994
Validation loss: 2.1682229737440744

Epoch: 5| Step: 8
Training loss: 1.6171300411224365
Validation loss: 2.182254582643509

Epoch: 5| Step: 9
Training loss: 1.4453264474868774
Validation loss: 2.1803510189056396

Epoch: 5| Step: 10
Training loss: 2.5478515625
Validation loss: 2.17127455274264

Epoch: 5| Step: 11
Training loss: 0.6450294852256775
Validation loss: 2.1878503262996674

Epoch: 304| Step: 0
Training loss: 2.1872806549072266
Validation loss: 2.173321008682251

Epoch: 5| Step: 1
Training loss: 1.6084811687469482
Validation loss: 2.1964819878339767

Epoch: 5| Step: 2
Training loss: 2.030754566192627
Validation loss: 2.212908372282982

Epoch: 5| Step: 3
Training loss: 1.5945494174957275
Validation loss: 2.187540198365847

Epoch: 5| Step: 4
Training loss: 2.4489619731903076
Validation loss: 2.1968930761019387

Epoch: 5| Step: 5
Training loss: 1.2200340032577515
Validation loss: 2.1828790654738746

Epoch: 5| Step: 6
Training loss: 0.9561667442321777
Validation loss: 2.1970725506544113

Epoch: 5| Step: 7
Training loss: 1.9435749053955078
Validation loss: 2.18417397638162

Epoch: 5| Step: 8
Training loss: 1.5568870306015015
Validation loss: 2.188432181874911

Epoch: 5| Step: 9
Training loss: 1.4121989011764526
Validation loss: 2.1823266049226127

Epoch: 5| Step: 10
Training loss: 1.334824562072754
Validation loss: 2.1983889987071357

Epoch: 5| Step: 11
Training loss: 2.450150966644287
Validation loss: 2.204229031999906

Epoch: 305| Step: 0
Training loss: 1.120227575302124
Validation loss: 2.191928197940191

Epoch: 5| Step: 1
Training loss: 2.0919413566589355
Validation loss: 2.1827919483184814

Epoch: 5| Step: 2
Training loss: 1.8019733428955078
Validation loss: 2.1773042331139245

Epoch: 5| Step: 3
Training loss: 2.1500587463378906
Validation loss: 2.173454393943151

Epoch: 5| Step: 4
Training loss: 1.757961630821228
Validation loss: 2.1673560440540314

Epoch: 5| Step: 5
Training loss: 1.4849599599838257
Validation loss: 2.170101140936216

Epoch: 5| Step: 6
Training loss: 1.7098538875579834
Validation loss: 2.1711186518271766

Epoch: 5| Step: 7
Training loss: 1.776065468788147
Validation loss: 2.1820558359225593

Epoch: 5| Step: 8
Training loss: 1.621843934059143
Validation loss: 2.21744396785895

Epoch: 5| Step: 9
Training loss: 1.5671175718307495
Validation loss: 2.2101201166709266

Epoch: 5| Step: 10
Training loss: 1.8652164936065674
Validation loss: 2.194362680117289

Epoch: 5| Step: 11
Training loss: 1.0028574466705322
Validation loss: 2.1784664591153464

Epoch: 306| Step: 0
Training loss: 1.6798632144927979
Validation loss: 2.217081978917122

Epoch: 5| Step: 1
Training loss: 1.4090049266815186
Validation loss: 2.224147086342176

Epoch: 5| Step: 2
Training loss: 1.766577959060669
Validation loss: 2.2102440198262534

Epoch: 5| Step: 3
Training loss: 1.4949798583984375
Validation loss: 2.200668195883433

Epoch: 5| Step: 4
Training loss: 1.7279733419418335
Validation loss: 2.185146520535151

Epoch: 5| Step: 5
Training loss: 1.573226809501648
Validation loss: 2.1730450044075647

Epoch: 5| Step: 6
Training loss: 1.6107505559921265
Validation loss: 2.1652598083019257

Epoch: 5| Step: 7
Training loss: 2.0701422691345215
Validation loss: 2.16015188395977

Epoch: 5| Step: 8
Training loss: 2.221328020095825
Validation loss: 2.1650847693284354

Epoch: 5| Step: 9
Training loss: 2.12298321723938
Validation loss: 2.1671899457772574

Epoch: 5| Step: 10
Training loss: 1.4702322483062744
Validation loss: 2.1857639153798423

Epoch: 5| Step: 11
Training loss: 3.228658437728882
Validation loss: 2.204556410511335

Epoch: 307| Step: 0
Training loss: 1.586317539215088
Validation loss: 2.1937702198823295

Epoch: 5| Step: 1
Training loss: 1.7153745889663696
Validation loss: 2.1899245033661523

Epoch: 5| Step: 2
Training loss: 2.538822650909424
Validation loss: 2.20815102259318

Epoch: 5| Step: 3
Training loss: 1.3287746906280518
Validation loss: 2.183664302031199

Epoch: 5| Step: 4
Training loss: 1.5154547691345215
Validation loss: 2.1976556877295175

Epoch: 5| Step: 5
Training loss: 1.3287382125854492
Validation loss: 2.198571672042211

Epoch: 5| Step: 6
Training loss: 1.7782586812973022
Validation loss: 2.203403820594152

Epoch: 5| Step: 7
Training loss: 1.8182296752929688
Validation loss: 2.208873008688291

Epoch: 5| Step: 8
Training loss: 1.1154862642288208
Validation loss: 2.2047235866387687

Epoch: 5| Step: 9
Training loss: 2.2553844451904297
Validation loss: 2.203240990638733

Epoch: 5| Step: 10
Training loss: 1.919271469116211
Validation loss: 2.2108467717965445

Epoch: 5| Step: 11
Training loss: 3.525028705596924
Validation loss: 2.20027549068133

Epoch: 308| Step: 0
Training loss: 1.343072533607483
Validation loss: 2.2171694288651147

Epoch: 5| Step: 1
Training loss: 1.8908300399780273
Validation loss: 2.2616159419218698

Epoch: 5| Step: 2
Training loss: 1.9107284545898438
Validation loss: 2.246519053975741

Epoch: 5| Step: 3
Training loss: 2.069720506668091
Validation loss: 2.256768981615702

Epoch: 5| Step: 4
Training loss: 2.131702423095703
Validation loss: 2.2351898501316705

Epoch: 5| Step: 5
Training loss: 1.5597666501998901
Validation loss: 2.2075902173916497

Epoch: 5| Step: 6
Training loss: 1.4678161144256592
Validation loss: 2.1836429138978324

Epoch: 5| Step: 7
Training loss: 2.1151905059814453
Validation loss: 2.186563824613889

Epoch: 5| Step: 8
Training loss: 1.6868822574615479
Validation loss: 2.1818002462387085

Epoch: 5| Step: 9
Training loss: 1.78316330909729
Validation loss: 2.1919953425725303

Epoch: 5| Step: 10
Training loss: 1.6451709270477295
Validation loss: 2.1838665703932443

Epoch: 5| Step: 11
Training loss: 1.098031997680664
Validation loss: 2.2043662071228027

Epoch: 309| Step: 0
Training loss: 2.0413424968719482
Validation loss: 2.1846076299746833

Epoch: 5| Step: 1
Training loss: 1.6806490421295166
Validation loss: 2.1999950408935547

Epoch: 5| Step: 2
Training loss: 2.1372170448303223
Validation loss: 2.178277080257734

Epoch: 5| Step: 3
Training loss: 1.5114357471466064
Validation loss: 2.170193170507749

Epoch: 5| Step: 4
Training loss: 1.7203788757324219
Validation loss: 2.153602972626686

Epoch: 5| Step: 5
Training loss: 1.504300594329834
Validation loss: 2.1679006765286126

Epoch: 5| Step: 6
Training loss: 1.8916581869125366
Validation loss: 2.170343334476153

Epoch: 5| Step: 7
Training loss: 1.57595694065094
Validation loss: 2.171326071023941

Epoch: 5| Step: 8
Training loss: 1.505903959274292
Validation loss: 2.1731131275494895

Epoch: 5| Step: 9
Training loss: 1.4879363775253296
Validation loss: 2.184394359588623

Epoch: 5| Step: 10
Training loss: 2.0024235248565674
Validation loss: 2.1637286146481833

Epoch: 5| Step: 11
Training loss: 1.756758451461792
Validation loss: 2.180178234974543

Epoch: 310| Step: 0
Training loss: 1.5322339534759521
Validation loss: 2.1738714079062142

Epoch: 5| Step: 1
Training loss: 1.2232238054275513
Validation loss: 2.1794327199459076

Epoch: 5| Step: 2
Training loss: 1.8552091121673584
Validation loss: 2.169315924247106

Epoch: 5| Step: 3
Training loss: 1.5436229705810547
Validation loss: 2.1603054453929267

Epoch: 5| Step: 4
Training loss: 1.9065215587615967
Validation loss: 2.1733114073673883

Epoch: 5| Step: 5
Training loss: 1.7490642070770264
Validation loss: 2.1588380386432013

Epoch: 5| Step: 6
Training loss: 1.5361005067825317
Validation loss: 2.153155878186226

Epoch: 5| Step: 7
Training loss: 1.6170432567596436
Validation loss: 2.1665921062231064

Epoch: 5| Step: 8
Training loss: 1.568393349647522
Validation loss: 2.165970593690872

Epoch: 5| Step: 9
Training loss: 2.45560359954834
Validation loss: 2.1667181054751077

Epoch: 5| Step: 10
Training loss: 1.8664426803588867
Validation loss: 2.1698744893074036

Epoch: 5| Step: 11
Training loss: 1.6578750610351562
Validation loss: 2.1813456267118454

Epoch: 311| Step: 0
Training loss: 1.7584209442138672
Validation loss: 2.170000692208608

Epoch: 5| Step: 1
Training loss: 2.136127471923828
Validation loss: 2.188603247205416

Epoch: 5| Step: 2
Training loss: 2.024329900741577
Validation loss: 2.1769039233525596

Epoch: 5| Step: 3
Training loss: 1.6901071071624756
Validation loss: 2.192209099729856

Epoch: 5| Step: 4
Training loss: 2.124835729598999
Validation loss: 2.1888685623804727

Epoch: 5| Step: 5
Training loss: 1.8679664134979248
Validation loss: 2.2036077876885733

Epoch: 5| Step: 6
Training loss: 1.5885215997695923
Validation loss: 2.179147015015284

Epoch: 5| Step: 7
Training loss: 1.3457996845245361
Validation loss: 2.187662030259768

Epoch: 5| Step: 8
Training loss: 1.186814785003662
Validation loss: 2.177451421817144

Epoch: 5| Step: 9
Training loss: 1.5874085426330566
Validation loss: 2.145713359117508

Epoch: 5| Step: 10
Training loss: 1.7366549968719482
Validation loss: 2.1481792479753494

Epoch: 5| Step: 11
Training loss: 1.2347608804702759
Validation loss: 2.1434326569239297

Epoch: 312| Step: 0
Training loss: 2.240448474884033
Validation loss: 2.164104774594307

Epoch: 5| Step: 1
Training loss: 1.4600497484207153
Validation loss: 2.1509383072455726

Epoch: 5| Step: 2
Training loss: 1.6056108474731445
Validation loss: 2.1487585455179214

Epoch: 5| Step: 3
Training loss: 1.3693187236785889
Validation loss: 2.132855325937271

Epoch: 5| Step: 4
Training loss: 1.562852144241333
Validation loss: 2.1408833662668862

Epoch: 5| Step: 5
Training loss: 1.2127078771591187
Validation loss: 2.1459567795197168

Epoch: 5| Step: 6
Training loss: 1.4781423807144165
Validation loss: 2.123490557074547

Epoch: 5| Step: 7
Training loss: 1.7939140796661377
Validation loss: 2.13137623667717

Epoch: 5| Step: 8
Training loss: 1.9740934371948242
Validation loss: 2.1482345362504325

Epoch: 5| Step: 9
Training loss: 2.123542308807373
Validation loss: 2.135499288638433

Epoch: 5| Step: 10
Training loss: 1.6561607122421265
Validation loss: 2.163129225373268

Epoch: 5| Step: 11
Training loss: 2.2996063232421875
Validation loss: 2.1380369116862616

Epoch: 313| Step: 0
Training loss: 1.318549394607544
Validation loss: 2.1443649729092917

Epoch: 5| Step: 1
Training loss: 1.7915195226669312
Validation loss: 2.1415370603402457

Epoch: 5| Step: 2
Training loss: 1.6103750467300415
Validation loss: 2.153799613316854

Epoch: 5| Step: 3
Training loss: 2.1805472373962402
Validation loss: 2.1366779655218124

Epoch: 5| Step: 4
Training loss: 1.2975757122039795
Validation loss: 2.157463565468788

Epoch: 5| Step: 5
Training loss: 1.4423519372940063
Validation loss: 2.175094097852707

Epoch: 5| Step: 6
Training loss: 1.528805136680603
Validation loss: 2.167471627394358

Epoch: 5| Step: 7
Training loss: 1.6801221370697021
Validation loss: 2.146821210781733

Epoch: 5| Step: 8
Training loss: 1.9914286136627197
Validation loss: 2.175722450017929

Epoch: 5| Step: 9
Training loss: 2.0251078605651855
Validation loss: 2.165091613928477

Epoch: 5| Step: 10
Training loss: 1.5042186975479126
Validation loss: 2.2169726490974426

Epoch: 5| Step: 11
Training loss: 2.4381260871887207
Validation loss: 2.196436956524849

Epoch: 314| Step: 0
Training loss: 2.1948742866516113
Validation loss: 2.1814752320448556

Epoch: 5| Step: 1
Training loss: 1.5611937046051025
Validation loss: 2.212658186753591

Epoch: 5| Step: 2
Training loss: 1.563497543334961
Validation loss: 2.1789660155773163

Epoch: 5| Step: 3
Training loss: 2.1173949241638184
Validation loss: 2.1966828604539237

Epoch: 5| Step: 4
Training loss: 1.171223759651184
Validation loss: 2.2204999228318534

Epoch: 5| Step: 5
Training loss: 1.410419225692749
Validation loss: 2.211707184712092

Epoch: 5| Step: 6
Training loss: 2.3473258018493652
Validation loss: 2.189534902572632

Epoch: 5| Step: 7
Training loss: 1.481671929359436
Validation loss: 2.2302742103735604

Epoch: 5| Step: 8
Training loss: 1.2719577550888062
Validation loss: 2.2178330620129905

Epoch: 5| Step: 9
Training loss: 1.2913833856582642
Validation loss: 2.2018213272094727

Epoch: 5| Step: 10
Training loss: 1.295061707496643
Validation loss: 2.1996131241321564

Epoch: 5| Step: 11
Training loss: 2.462688684463501
Validation loss: 2.229997217655182

Epoch: 315| Step: 0
Training loss: 2.3889336585998535
Validation loss: 2.193156659603119

Epoch: 5| Step: 1
Training loss: 2.5567734241485596
Validation loss: 2.1786029934883118

Epoch: 5| Step: 2
Training loss: 1.5286617279052734
Validation loss: 2.1715980072816214

Epoch: 5| Step: 3
Training loss: 1.2661473751068115
Validation loss: 2.1684633741776147

Epoch: 5| Step: 4
Training loss: 1.5844910144805908
Validation loss: 2.1510054965813956

Epoch: 5| Step: 5
Training loss: 1.8524751663208008
Validation loss: 2.145599459608396

Epoch: 5| Step: 6
Training loss: 1.9977737665176392
Validation loss: 2.1508526702721915

Epoch: 5| Step: 7
Training loss: 1.2874391078948975
Validation loss: 2.1391616264979043

Epoch: 5| Step: 8
Training loss: 1.7963268756866455
Validation loss: 2.1640684505303702

Epoch: 5| Step: 9
Training loss: 1.3794622421264648
Validation loss: 2.1765900750954947

Epoch: 5| Step: 10
Training loss: 1.4858403205871582
Validation loss: 2.186295116941134

Epoch: 5| Step: 11
Training loss: 1.8704519271850586
Validation loss: 2.207524518171946

Epoch: 316| Step: 0
Training loss: 1.411797046661377
Validation loss: 2.19893808166186

Epoch: 5| Step: 1
Training loss: 1.912078857421875
Validation loss: 2.183754334847132

Epoch: 5| Step: 2
Training loss: 1.602543830871582
Validation loss: 2.1871767938137054

Epoch: 5| Step: 3
Training loss: 1.7320897579193115
Validation loss: 2.1773918916781745

Epoch: 5| Step: 4
Training loss: 1.5544313192367554
Validation loss: 2.179133971532186

Epoch: 5| Step: 5
Training loss: 1.8504642248153687
Validation loss: 2.165831580758095

Epoch: 5| Step: 6
Training loss: 1.4199047088623047
Validation loss: 2.1697236200173697

Epoch: 5| Step: 7
Training loss: 1.6355817317962646
Validation loss: 2.1773253778616586

Epoch: 5| Step: 8
Training loss: 1.9483486413955688
Validation loss: 2.1662784218788147

Epoch: 5| Step: 9
Training loss: 1.4077268838882446
Validation loss: 2.188404858112335

Epoch: 5| Step: 10
Training loss: 1.9794235229492188
Validation loss: 2.2139507830142975

Epoch: 5| Step: 11
Training loss: 1.2065975666046143
Validation loss: 2.1901406943798065

Epoch: 317| Step: 0
Training loss: 1.1797115802764893
Validation loss: 2.1910850256681442

Epoch: 5| Step: 1
Training loss: 1.778220534324646
Validation loss: 2.1867468456427255

Epoch: 5| Step: 2
Training loss: 1.8989241123199463
Validation loss: 2.1668296108643212

Epoch: 5| Step: 3
Training loss: 1.495910882949829
Validation loss: 2.1831737409035363

Epoch: 5| Step: 4
Training loss: 1.690150260925293
Validation loss: 2.2049675782521567

Epoch: 5| Step: 5
Training loss: 1.5469024181365967
Validation loss: 2.172358671824137

Epoch: 5| Step: 6
Training loss: 1.8062021732330322
Validation loss: 2.1542917092641196

Epoch: 5| Step: 7
Training loss: 1.4955848455429077
Validation loss: 2.1591781973838806

Epoch: 5| Step: 8
Training loss: 2.1424567699432373
Validation loss: 2.1535131136576333

Epoch: 5| Step: 9
Training loss: 1.5418027639389038
Validation loss: 2.185396268963814

Epoch: 5| Step: 10
Training loss: 1.2204679250717163
Validation loss: 2.176181212067604

Epoch: 5| Step: 11
Training loss: 3.2453808784484863
Validation loss: 2.164199953277906

Epoch: 318| Step: 0
Training loss: 1.9633830785751343
Validation loss: 2.1496420800685883

Epoch: 5| Step: 1
Training loss: 1.6811332702636719
Validation loss: 2.1031805723905563

Epoch: 5| Step: 2
Training loss: 1.8837611675262451
Validation loss: 2.1226165344317756

Epoch: 5| Step: 3
Training loss: 1.5842732191085815
Validation loss: 2.109324341018995

Epoch: 5| Step: 4
Training loss: 1.591670036315918
Validation loss: 2.128449887037277

Epoch: 5| Step: 5
Training loss: 1.4253172874450684
Validation loss: 2.1417799095312753

Epoch: 5| Step: 6
Training loss: 1.077620029449463
Validation loss: 2.130066394805908

Epoch: 5| Step: 7
Training loss: 1.7893966436386108
Validation loss: 2.1290618081887565

Epoch: 5| Step: 8
Training loss: 1.394675612449646
Validation loss: 2.136797934770584

Epoch: 5| Step: 9
Training loss: 1.9010684490203857
Validation loss: 2.1310040950775146

Epoch: 5| Step: 10
Training loss: 1.8291714191436768
Validation loss: 2.1486510088046393

Epoch: 5| Step: 11
Training loss: 1.168017029762268
Validation loss: 2.1558513889710107

Epoch: 319| Step: 0
Training loss: 1.9100192785263062
Validation loss: 2.1698035299777985

Epoch: 5| Step: 1
Training loss: 1.7992957830429077
Validation loss: 2.2053202390670776

Epoch: 5| Step: 2
Training loss: 1.047768235206604
Validation loss: 2.1704632888237634

Epoch: 5| Step: 3
Training loss: 1.459908366203308
Validation loss: 2.188362921277682

Epoch: 5| Step: 4
Training loss: 2.0231661796569824
Validation loss: 2.162953704595566

Epoch: 5| Step: 5
Training loss: 1.4971822500228882
Validation loss: 2.188279310862223

Epoch: 5| Step: 6
Training loss: 1.6572262048721313
Validation loss: 2.199512635668119

Epoch: 5| Step: 7
Training loss: 1.2108917236328125
Validation loss: 2.183064197500547

Epoch: 5| Step: 8
Training loss: 2.010183811187744
Validation loss: 2.201521078745524

Epoch: 5| Step: 9
Training loss: 1.7538783550262451
Validation loss: 2.2036645859479904

Epoch: 5| Step: 10
Training loss: 1.9834766387939453
Validation loss: 2.203820506731669

Epoch: 5| Step: 11
Training loss: 1.480939269065857
Validation loss: 2.199580396215121

Epoch: 320| Step: 0
Training loss: 1.9799537658691406
Validation loss: 2.1766652961572013

Epoch: 5| Step: 1
Training loss: 1.4837672710418701
Validation loss: 2.188773284355799

Epoch: 5| Step: 2
Training loss: 1.247880220413208
Validation loss: 2.1778233498334885

Epoch: 5| Step: 3
Training loss: 1.6350866556167603
Validation loss: 2.200794051090876

Epoch: 5| Step: 4
Training loss: 2.4170241355895996
Validation loss: 2.2051414797703424

Epoch: 5| Step: 5
Training loss: 1.1599671840667725
Validation loss: 2.199359958370527

Epoch: 5| Step: 6
Training loss: 1.258039951324463
Validation loss: 2.2068243424097695

Epoch: 5| Step: 7
Training loss: 1.5044673681259155
Validation loss: 2.1966844151417413

Epoch: 5| Step: 8
Training loss: 1.4283957481384277
Validation loss: 2.1999895373980203

Epoch: 5| Step: 9
Training loss: 1.2950410842895508
Validation loss: 2.174955894549688

Epoch: 5| Step: 10
Training loss: 2.0159029960632324
Validation loss: 2.1690354297558465

Epoch: 5| Step: 11
Training loss: 2.6271440982818604
Validation loss: 2.1538412819306054

Epoch: 321| Step: 0
Training loss: 1.4369304180145264
Validation loss: 2.158380607763926

Epoch: 5| Step: 1
Training loss: 2.2236852645874023
Validation loss: 2.1826580613851547

Epoch: 5| Step: 2
Training loss: 1.1791716814041138
Validation loss: 2.1493553866942725

Epoch: 5| Step: 3
Training loss: 1.501434564590454
Validation loss: 2.1329509913921356

Epoch: 5| Step: 4
Training loss: 1.9445537328720093
Validation loss: 2.1702486475308738

Epoch: 5| Step: 5
Training loss: 1.8823058605194092
Validation loss: 2.1087182660897574

Epoch: 5| Step: 6
Training loss: 1.1411330699920654
Validation loss: 2.138274058699608

Epoch: 5| Step: 7
Training loss: 1.9663841724395752
Validation loss: 2.087997242808342

Epoch: 5| Step: 8
Training loss: 1.483161211013794
Validation loss: 2.1105648279190063

Epoch: 5| Step: 9
Training loss: 1.6818844079971313
Validation loss: 2.117596392830213

Epoch: 5| Step: 10
Training loss: 1.6392446756362915
Validation loss: 2.1203683813412986

Epoch: 5| Step: 11
Training loss: 1.1134921312332153
Validation loss: 2.105990692973137

Epoch: 322| Step: 0
Training loss: 1.7652603387832642
Validation loss: 2.112646460533142

Epoch: 5| Step: 1
Training loss: 1.3029212951660156
Validation loss: 2.1056776891152063

Epoch: 5| Step: 2
Training loss: 1.7465364933013916
Validation loss: 2.1192601124445596

Epoch: 5| Step: 3
Training loss: 1.5870704650878906
Validation loss: 2.133004898826281

Epoch: 5| Step: 4
Training loss: 1.632711410522461
Validation loss: 2.113346909483274

Epoch: 5| Step: 5
Training loss: 0.9264594912528992
Validation loss: 2.1389979869127274

Epoch: 5| Step: 6
Training loss: 2.11149001121521
Validation loss: 2.140137920777003

Epoch: 5| Step: 7
Training loss: 1.8983138799667358
Validation loss: 2.1456208179394403

Epoch: 5| Step: 8
Training loss: 1.6132303476333618
Validation loss: 2.1553504914045334

Epoch: 5| Step: 9
Training loss: 2.453110933303833
Validation loss: 2.149669279654821

Epoch: 5| Step: 10
Training loss: 1.5417120456695557
Validation loss: 2.1585445950428643

Epoch: 5| Step: 11
Training loss: 1.2667393684387207
Validation loss: 2.16169506808122

Epoch: 323| Step: 0
Training loss: 1.7855119705200195
Validation loss: 2.1551103790601096

Epoch: 5| Step: 1
Training loss: 1.5871078968048096
Validation loss: 2.163637340068817

Epoch: 5| Step: 2
Training loss: 1.8462779521942139
Validation loss: 2.153440371155739

Epoch: 5| Step: 3
Training loss: 1.7861846685409546
Validation loss: 2.1872123926877975

Epoch: 5| Step: 4
Training loss: 1.6006218194961548
Validation loss: 2.173826187849045

Epoch: 5| Step: 5
Training loss: 1.2933210134506226
Validation loss: 2.1712431758642197

Epoch: 5| Step: 6
Training loss: 2.0148730278015137
Validation loss: 2.183678259452184

Epoch: 5| Step: 7
Training loss: 1.7210900783538818
Validation loss: 2.1653026839097342

Epoch: 5| Step: 8
Training loss: 0.9748052358627319
Validation loss: 2.1851576964060464

Epoch: 5| Step: 9
Training loss: 1.3733062744140625
Validation loss: 2.179071694612503

Epoch: 5| Step: 10
Training loss: 2.1780030727386475
Validation loss: 2.188730518023173

Epoch: 5| Step: 11
Training loss: 1.2401988506317139
Validation loss: 2.177017311255137

Epoch: 324| Step: 0
Training loss: 1.6822010278701782
Validation loss: 2.166344086329142

Epoch: 5| Step: 1
Training loss: 1.7971359491348267
Validation loss: 2.1685098906358085

Epoch: 5| Step: 2
Training loss: 1.6934839487075806
Validation loss: 2.191261976957321

Epoch: 5| Step: 3
Training loss: 1.8808361291885376
Validation loss: 2.177913099527359

Epoch: 5| Step: 4
Training loss: 1.2792385816574097
Validation loss: 2.1876024901866913

Epoch: 5| Step: 5
Training loss: 1.0932222604751587
Validation loss: 2.1868722389141717

Epoch: 5| Step: 6
Training loss: 1.9267724752426147
Validation loss: 2.198000614841779

Epoch: 5| Step: 7
Training loss: 1.6853173971176147
Validation loss: 2.1764385402202606

Epoch: 5| Step: 8
Training loss: 2.2074289321899414
Validation loss: 2.1865859727064767

Epoch: 5| Step: 9
Training loss: 1.3461240530014038
Validation loss: 2.187808891137441

Epoch: 5| Step: 10
Training loss: 1.2646591663360596
Validation loss: 2.1957639356454215

Epoch: 5| Step: 11
Training loss: 1.3321127891540527
Validation loss: 2.180624092618624

Epoch: 325| Step: 0
Training loss: 2.102738857269287
Validation loss: 2.1701394617557526

Epoch: 5| Step: 1
Training loss: 1.1248705387115479
Validation loss: 2.1858074267705283

Epoch: 5| Step: 2
Training loss: 1.6163917779922485
Validation loss: 2.1970386107762656

Epoch: 5| Step: 3
Training loss: 1.4707162380218506
Validation loss: 2.159302294254303

Epoch: 5| Step: 4
Training loss: 1.387519359588623
Validation loss: 2.1859312107165656

Epoch: 5| Step: 5
Training loss: 1.7695815563201904
Validation loss: 2.153125857313474

Epoch: 5| Step: 6
Training loss: 1.5892127752304077
Validation loss: 2.157570943236351

Epoch: 5| Step: 7
Training loss: 1.4329688549041748
Validation loss: 2.1465246975421906

Epoch: 5| Step: 8
Training loss: 1.3736711740493774
Validation loss: 2.1455846279859543

Epoch: 5| Step: 9
Training loss: 1.8172619342803955
Validation loss: 2.162793298562368

Epoch: 5| Step: 10
Training loss: 1.9455486536026
Validation loss: 2.1484589874744415

Epoch: 5| Step: 11
Training loss: 1.2278584241867065
Validation loss: 2.1435150504112244

Epoch: 326| Step: 0
Training loss: 1.4701865911483765
Validation loss: 2.173015425602595

Epoch: 5| Step: 1
Training loss: 2.4309706687927246
Validation loss: 2.1581435153881707

Epoch: 5| Step: 2
Training loss: 1.4257678985595703
Validation loss: 2.170684963464737

Epoch: 5| Step: 3
Training loss: 1.2515389919281006
Validation loss: 2.1813338895638785

Epoch: 5| Step: 4
Training loss: 1.282189130783081
Validation loss: 2.194478233655294

Epoch: 5| Step: 5
Training loss: 2.153477907180786
Validation loss: 2.1587587197621665

Epoch: 5| Step: 6
Training loss: 1.5621063709259033
Validation loss: 2.1716847916444144

Epoch: 5| Step: 7
Training loss: 1.8009774684906006
Validation loss: 2.1859716723362603

Epoch: 5| Step: 8
Training loss: 1.4903638362884521
Validation loss: 2.1661588301261268

Epoch: 5| Step: 9
Training loss: 1.4789875745773315
Validation loss: 2.160054420431455

Epoch: 5| Step: 10
Training loss: 1.2082077264785767
Validation loss: 2.189472327629725

Epoch: 5| Step: 11
Training loss: 0.6046839952468872
Validation loss: 2.1901289373636246

Epoch: 327| Step: 0
Training loss: 1.1607844829559326
Validation loss: 2.1790013710657754

Epoch: 5| Step: 1
Training loss: 1.865801215171814
Validation loss: 2.168444628516833

Epoch: 5| Step: 2
Training loss: 1.3409674167633057
Validation loss: 2.167977203925451

Epoch: 5| Step: 3
Training loss: 1.9678184986114502
Validation loss: 2.1560766994953156

Epoch: 5| Step: 4
Training loss: 1.3337386846542358
Validation loss: 2.167937934398651

Epoch: 5| Step: 5
Training loss: 1.869848608970642
Validation loss: 2.1813184122244516

Epoch: 5| Step: 6
Training loss: 1.896888017654419
Validation loss: 2.164351503054301

Epoch: 5| Step: 7
Training loss: 1.6047008037567139
Validation loss: 2.152085915207863

Epoch: 5| Step: 8
Training loss: 1.3700964450836182
Validation loss: 2.164228210846583

Epoch: 5| Step: 9
Training loss: 1.3858921527862549
Validation loss: 2.163976495464643

Epoch: 5| Step: 10
Training loss: 1.6818287372589111
Validation loss: 2.143957788745562

Epoch: 5| Step: 11
Training loss: 1.1317514181137085
Validation loss: 2.1585862239201865

Epoch: 328| Step: 0
Training loss: 1.9035136699676514
Validation loss: 2.128310044606527

Epoch: 5| Step: 1
Training loss: 1.9093010425567627
Validation loss: 2.1546594401200614

Epoch: 5| Step: 2
Training loss: 0.9184051752090454
Validation loss: 2.1578430930773416

Epoch: 5| Step: 3
Training loss: 1.405470609664917
Validation loss: 2.149508530894915

Epoch: 5| Step: 4
Training loss: 1.5800201892852783
Validation loss: 2.1649475495020547

Epoch: 5| Step: 5
Training loss: 1.0768417119979858
Validation loss: 2.161663462718328

Epoch: 5| Step: 6
Training loss: 1.4166334867477417
Validation loss: 2.1702357629934945

Epoch: 5| Step: 7
Training loss: 1.8720334768295288
Validation loss: 2.1666220873594284

Epoch: 5| Step: 8
Training loss: 1.865496277809143
Validation loss: 2.175336172183355

Epoch: 5| Step: 9
Training loss: 1.8528045415878296
Validation loss: 2.1983184218406677

Epoch: 5| Step: 10
Training loss: 1.711920976638794
Validation loss: 2.1949637730916343

Epoch: 5| Step: 11
Training loss: 1.411383032798767
Validation loss: 2.181090538700422

Epoch: 329| Step: 0
Training loss: 1.2401065826416016
Validation loss: 2.1588959445556006

Epoch: 5| Step: 1
Training loss: 1.2775390148162842
Validation loss: 2.1783370772997537

Epoch: 5| Step: 2
Training loss: 1.0138349533081055
Validation loss: 2.1884183386961618

Epoch: 5| Step: 3
Training loss: 2.0117850303649902
Validation loss: 2.1936788260936737

Epoch: 5| Step: 4
Training loss: 1.8069454431533813
Validation loss: 2.1871797243754068

Epoch: 5| Step: 5
Training loss: 1.4619733095169067
Validation loss: 2.1888286670049033

Epoch: 5| Step: 6
Training loss: 1.571160912513733
Validation loss: 2.1879704544941583

Epoch: 5| Step: 7
Training loss: 1.6584692001342773
Validation loss: 2.162470574180285

Epoch: 5| Step: 8
Training loss: 1.1731704473495483
Validation loss: 2.1665466129779816

Epoch: 5| Step: 9
Training loss: 2.100590229034424
Validation loss: 2.163738568623861

Epoch: 5| Step: 10
Training loss: 1.6934038400650024
Validation loss: 2.185901631911596

Epoch: 5| Step: 11
Training loss: 1.9065378904342651
Validation loss: 2.2067792216936746

Epoch: 330| Step: 0
Training loss: 1.4646655321121216
Validation loss: 2.1703810145457587

Epoch: 5| Step: 1
Training loss: 1.9807147979736328
Validation loss: 2.1820049981276193

Epoch: 5| Step: 2
Training loss: 1.0027974843978882
Validation loss: 2.194034074743589

Epoch: 5| Step: 3
Training loss: 1.8839056491851807
Validation loss: 2.167362074057261

Epoch: 5| Step: 4
Training loss: 1.7075965404510498
Validation loss: 2.1912450591723123

Epoch: 5| Step: 5
Training loss: 1.7995342016220093
Validation loss: 2.1657740424076715

Epoch: 5| Step: 6
Training loss: 1.630637526512146
Validation loss: 2.150896042585373

Epoch: 5| Step: 7
Training loss: 1.939282774925232
Validation loss: 2.156497692068418

Epoch: 5| Step: 8
Training loss: 1.1443852186203003
Validation loss: 2.137465630968412

Epoch: 5| Step: 9
Training loss: 1.1658433675765991
Validation loss: 2.1437116911013923

Epoch: 5| Step: 10
Training loss: 1.7489869594573975
Validation loss: 2.1672072211901345

Epoch: 5| Step: 11
Training loss: 2.0683693885803223
Validation loss: 2.13481139143308

Epoch: 331| Step: 0
Training loss: 1.4107649326324463
Validation loss: 2.1554382344086966

Epoch: 5| Step: 1
Training loss: 1.5703141689300537
Validation loss: 2.1502067744731903

Epoch: 5| Step: 2
Training loss: 2.1862874031066895
Validation loss: 2.182226220766703

Epoch: 5| Step: 3
Training loss: 1.7695906162261963
Validation loss: 2.1604349265495935

Epoch: 5| Step: 4
Training loss: 1.3165539503097534
Validation loss: 2.1763924608627954

Epoch: 5| Step: 5
Training loss: 1.789912223815918
Validation loss: 2.1922541658083596

Epoch: 5| Step: 6
Training loss: 1.8354339599609375
Validation loss: 2.2034841577212014

Epoch: 5| Step: 7
Training loss: 0.9939967393875122
Validation loss: 2.193593293428421

Epoch: 5| Step: 8
Training loss: 1.3201229572296143
Validation loss: 2.1889473348855972

Epoch: 5| Step: 9
Training loss: 1.304122805595398
Validation loss: 2.1756948630015054

Epoch: 5| Step: 10
Training loss: 1.6270732879638672
Validation loss: 2.1400578320026398

Epoch: 5| Step: 11
Training loss: 1.9289497137069702
Validation loss: 2.132901221513748

Epoch: 332| Step: 0
Training loss: 1.6093919277191162
Validation loss: 2.1494550009568534

Epoch: 5| Step: 1
Training loss: 1.6670652627944946
Validation loss: 2.162036433815956

Epoch: 5| Step: 2
Training loss: 1.210875391960144
Validation loss: 2.1405151784420013

Epoch: 5| Step: 3
Training loss: 1.1304701566696167
Validation loss: 2.1379349678754807

Epoch: 5| Step: 4
Training loss: 1.2480021715164185
Validation loss: 2.155195012688637

Epoch: 5| Step: 5
Training loss: 1.9668338298797607
Validation loss: 2.117808053890864

Epoch: 5| Step: 6
Training loss: 1.54651939868927
Validation loss: 2.1233913401762643

Epoch: 5| Step: 7
Training loss: 1.381687879562378
Validation loss: 2.1298838953177133

Epoch: 5| Step: 8
Training loss: 1.7048839330673218
Validation loss: 2.1100188891092935

Epoch: 5| Step: 9
Training loss: 1.7010109424591064
Validation loss: 2.1332250237464905

Epoch: 5| Step: 10
Training loss: 1.7853481769561768
Validation loss: 2.146704822778702

Epoch: 5| Step: 11
Training loss: 1.219681978225708
Validation loss: 2.135157103339831

Epoch: 333| Step: 0
Training loss: 1.494114637374878
Validation loss: 2.1491945485273996

Epoch: 5| Step: 1
Training loss: 1.4523392915725708
Validation loss: 2.1644738167524338

Epoch: 5| Step: 2
Training loss: 1.7707700729370117
Validation loss: 2.145813763141632

Epoch: 5| Step: 3
Training loss: 1.6085460186004639
Validation loss: 2.1684202402830124

Epoch: 5| Step: 4
Training loss: 1.3293176889419556
Validation loss: 2.150884394844373

Epoch: 5| Step: 5
Training loss: 1.8154094219207764
Validation loss: 2.160951832930247

Epoch: 5| Step: 6
Training loss: 1.792245864868164
Validation loss: 2.175936018427213

Epoch: 5| Step: 7
Training loss: 1.5660459995269775
Validation loss: 2.1518984834353128

Epoch: 5| Step: 8
Training loss: 0.9297583699226379
Validation loss: 2.1626273840665817

Epoch: 5| Step: 9
Training loss: 1.531783938407898
Validation loss: 2.167641580104828

Epoch: 5| Step: 10
Training loss: 1.4024747610092163
Validation loss: 2.1931727528572083

Epoch: 5| Step: 11
Training loss: 1.7190511226654053
Validation loss: 2.1945179353157678

Epoch: 334| Step: 0
Training loss: 1.2986948490142822
Validation loss: 2.249015952150027

Epoch: 5| Step: 1
Training loss: 2.00372576713562
Validation loss: 2.277699957291285

Epoch: 5| Step: 2
Training loss: 1.6793826818466187
Validation loss: 2.240181267261505

Epoch: 5| Step: 3
Training loss: 1.658515214920044
Validation loss: 2.258848970135053

Epoch: 5| Step: 4
Training loss: 1.0043705701828003
Validation loss: 2.2925550738970437

Epoch: 5| Step: 5
Training loss: 0.9652053713798523
Validation loss: 2.3246659686168036

Epoch: 5| Step: 6
Training loss: 1.933332085609436
Validation loss: 2.2677235106627145

Epoch: 5| Step: 7
Training loss: 1.6229803562164307
Validation loss: 2.248373488585154

Epoch: 5| Step: 8
Training loss: 1.4827258586883545
Validation loss: 2.2359290967384973

Epoch: 5| Step: 9
Training loss: 1.6017837524414062
Validation loss: 2.2258185694615045

Epoch: 5| Step: 10
Training loss: 2.865842342376709
Validation loss: 2.205011785030365

Epoch: 5| Step: 11
Training loss: 0.7552045583724976
Validation loss: 2.1687234242757163

Epoch: 335| Step: 0
Training loss: 1.7194093465805054
Validation loss: 2.1866366316874823

Epoch: 5| Step: 1
Training loss: 1.6357961893081665
Validation loss: 2.1866397062937417

Epoch: 5| Step: 2
Training loss: 1.2456117868423462
Validation loss: 2.1668294270833335

Epoch: 5| Step: 3
Training loss: 1.8074424266815186
Validation loss: 2.1865993539492288

Epoch: 5| Step: 4
Training loss: 1.1593046188354492
Validation loss: 2.179620330532392

Epoch: 5| Step: 5
Training loss: 1.2384662628173828
Validation loss: 2.192192713419596

Epoch: 5| Step: 6
Training loss: 1.666261076927185
Validation loss: 2.180928334593773

Epoch: 5| Step: 7
Training loss: 1.7558701038360596
Validation loss: 2.1864465723435083

Epoch: 5| Step: 8
Training loss: 1.6508514881134033
Validation loss: 2.168991913398107

Epoch: 5| Step: 9
Training loss: 1.4866085052490234
Validation loss: 2.1621512919664383

Epoch: 5| Step: 10
Training loss: 1.413580298423767
Validation loss: 2.158422494928042

Epoch: 5| Step: 11
Training loss: 1.9021337032318115
Validation loss: 2.190020670493444

Epoch: 336| Step: 0
Training loss: 1.2668585777282715
Validation loss: 2.1854639649391174

Epoch: 5| Step: 1
Training loss: 1.4968335628509521
Validation loss: 2.1981959342956543

Epoch: 5| Step: 2
Training loss: 1.6835975646972656
Validation loss: 2.2296066681543985

Epoch: 5| Step: 3
Training loss: 1.4952133893966675
Validation loss: 2.201727936665217

Epoch: 5| Step: 4
Training loss: 1.6300268173217773
Validation loss: 2.214483837286631

Epoch: 5| Step: 5
Training loss: 1.5157667398452759
Validation loss: 2.2131955673297248

Epoch: 5| Step: 6
Training loss: 1.6883728504180908
Validation loss: 2.1663988729317984

Epoch: 5| Step: 7
Training loss: 1.7724463939666748
Validation loss: 2.178742622335752

Epoch: 5| Step: 8
Training loss: 1.4842146635055542
Validation loss: 2.186780725916227

Epoch: 5| Step: 9
Training loss: 1.969470739364624
Validation loss: 2.1795931607484818

Epoch: 5| Step: 10
Training loss: 0.850685715675354
Validation loss: 2.1997749706109366

Epoch: 5| Step: 11
Training loss: 0.9704606533050537
Validation loss: 2.156891107559204

Epoch: 337| Step: 0
Training loss: 1.1648191213607788
Validation loss: 2.1892125407854715

Epoch: 5| Step: 1
Training loss: 2.3489861488342285
Validation loss: 2.188054626186689

Epoch: 5| Step: 2
Training loss: 0.9589822888374329
Validation loss: 2.1918806036313376

Epoch: 5| Step: 3
Training loss: 1.193129539489746
Validation loss: 2.174373428026835

Epoch: 5| Step: 4
Training loss: 1.5651012659072876
Validation loss: 2.17980765302976

Epoch: 5| Step: 5
Training loss: 1.1751084327697754
Validation loss: 2.1994718462228775

Epoch: 5| Step: 6
Training loss: 2.1403517723083496
Validation loss: 2.1907476683457694

Epoch: 5| Step: 7
Training loss: 2.0189082622528076
Validation loss: 2.2012227723995843

Epoch: 5| Step: 8
Training loss: 0.9897137880325317
Validation loss: 2.226570655902227

Epoch: 5| Step: 9
Training loss: 1.4742710590362549
Validation loss: 2.2014255076646805

Epoch: 5| Step: 10
Training loss: 1.8177802562713623
Validation loss: 2.176471491654714

Epoch: 5| Step: 11
Training loss: 0.8823375105857849
Validation loss: 2.21012448767821

Epoch: 338| Step: 0
Training loss: 1.3258877992630005
Validation loss: 2.213244785865148

Epoch: 5| Step: 1
Training loss: 1.1542174816131592
Validation loss: 2.2310683727264404

Epoch: 5| Step: 2
Training loss: 1.9463142156600952
Validation loss: 2.2620187352101007

Epoch: 5| Step: 3
Training loss: 1.8651626110076904
Validation loss: 2.2469162146250405

Epoch: 5| Step: 4
Training loss: 1.4675103425979614
Validation loss: 2.2644696881373725

Epoch: 5| Step: 5
Training loss: 1.8754764795303345
Validation loss: 2.192327400048574

Epoch: 5| Step: 6
Training loss: 1.8995606899261475
Validation loss: 2.191133285562197

Epoch: 5| Step: 7
Training loss: 1.0994428396224976
Validation loss: 2.2095776200294495

Epoch: 5| Step: 8
Training loss: 1.3722203969955444
Validation loss: 2.2174086620410285

Epoch: 5| Step: 9
Training loss: 2.012773036956787
Validation loss: 2.1944992740948996

Epoch: 5| Step: 10
Training loss: 1.3539974689483643
Validation loss: 2.1799801687399545

Epoch: 5| Step: 11
Training loss: 1.6277589797973633
Validation loss: 2.190430670976639

Epoch: 339| Step: 0
Training loss: 1.3336150646209717
Validation loss: 2.1624730875094733

Epoch: 5| Step: 1
Training loss: 1.7058916091918945
Validation loss: 2.16894394159317

Epoch: 5| Step: 2
Training loss: 1.9813547134399414
Validation loss: 2.197413588563601

Epoch: 5| Step: 3
Training loss: 1.5614793300628662
Validation loss: 2.2082595825195312

Epoch: 5| Step: 4
Training loss: 1.84529709815979
Validation loss: 2.219235902031263

Epoch: 5| Step: 5
Training loss: 1.2475974559783936
Validation loss: 2.1871863851944604

Epoch: 5| Step: 6
Training loss: 1.704375982284546
Validation loss: 2.2226687570412955

Epoch: 5| Step: 7
Training loss: 1.8745510578155518
Validation loss: 2.2338392436504364

Epoch: 5| Step: 8
Training loss: 1.4736354351043701
Validation loss: 2.2104285011688867

Epoch: 5| Step: 9
Training loss: 0.9081732034683228
Validation loss: 2.2126858234405518

Epoch: 5| Step: 10
Training loss: 1.7762477397918701
Validation loss: 2.185493975877762

Epoch: 5| Step: 11
Training loss: 0.9408664107322693
Validation loss: 2.1384270588556924

Epoch: 340| Step: 0
Training loss: 1.573495626449585
Validation loss: 2.181630785266558

Epoch: 5| Step: 1
Training loss: 2.4727671146392822
Validation loss: 2.199008842309316

Epoch: 5| Step: 2
Training loss: 1.3884806632995605
Validation loss: 2.238733480374018

Epoch: 5| Step: 3
Training loss: 1.5655317306518555
Validation loss: 2.2540091375509896

Epoch: 5| Step: 4
Training loss: 1.6222337484359741
Validation loss: 2.2636879732211432

Epoch: 5| Step: 5
Training loss: 1.8364222049713135
Validation loss: 2.2438016136487327

Epoch: 5| Step: 6
Training loss: 1.0934187173843384
Validation loss: 2.2825700640678406

Epoch: 5| Step: 7
Training loss: 1.702478051185608
Validation loss: 2.2494575530290604

Epoch: 5| Step: 8
Training loss: 1.7472407817840576
Validation loss: 2.259479835629463

Epoch: 5| Step: 9
Training loss: 2.0774829387664795
Validation loss: 2.2636001904805503

Epoch: 5| Step: 10
Training loss: 1.4944714307785034
Validation loss: 2.2512746453285217

Epoch: 5| Step: 11
Training loss: 0.6426999568939209
Validation loss: 2.2496645400921502

Epoch: 341| Step: 0
Training loss: 1.5313984155654907
Validation loss: 2.2468774020671844

Epoch: 5| Step: 1
Training loss: 1.4738985300064087
Validation loss: 2.231308172146479

Epoch: 5| Step: 2
Training loss: 2.3299145698547363
Validation loss: 2.20821505288283

Epoch: 5| Step: 3
Training loss: 2.236696720123291
Validation loss: 2.1855778892834983

Epoch: 5| Step: 4
Training loss: 1.268197774887085
Validation loss: 2.14795051018397

Epoch: 5| Step: 5
Training loss: 1.2766135931015015
Validation loss: 2.124629740913709

Epoch: 5| Step: 6
Training loss: 1.3426940441131592
Validation loss: 2.111187681555748

Epoch: 5| Step: 7
Training loss: 1.353265643119812
Validation loss: 2.1226120243469873

Epoch: 5| Step: 8
Training loss: 2.2727625370025635
Validation loss: 2.1216563284397125

Epoch: 5| Step: 9
Training loss: 1.5411465167999268
Validation loss: 2.1370170017083487

Epoch: 5| Step: 10
Training loss: 0.7900550961494446
Validation loss: 2.1362620691458383

Epoch: 5| Step: 11
Training loss: 0.9893811345100403
Validation loss: 2.1234095990657806

Epoch: 342| Step: 0
Training loss: 1.3525171279907227
Validation loss: 2.165509815017382

Epoch: 5| Step: 1
Training loss: 1.917768120765686
Validation loss: 2.1717281540234885

Epoch: 5| Step: 2
Training loss: 1.3498727083206177
Validation loss: 2.1906275202830634

Epoch: 5| Step: 3
Training loss: 1.6974411010742188
Validation loss: 2.1819730003674827

Epoch: 5| Step: 4
Training loss: 1.3351885080337524
Validation loss: 2.2252389391263327

Epoch: 5| Step: 5
Training loss: 1.9472459554672241
Validation loss: 2.198585649331411

Epoch: 5| Step: 6
Training loss: 1.3881628513336182
Validation loss: 2.210462917884191

Epoch: 5| Step: 7
Training loss: 1.772465467453003
Validation loss: 2.2141879896322885

Epoch: 5| Step: 8
Training loss: 1.8532540798187256
Validation loss: 2.21663307150205

Epoch: 5| Step: 9
Training loss: 1.5133880376815796
Validation loss: 2.2023311654726663

Epoch: 5| Step: 10
Training loss: 1.7181198596954346
Validation loss: 2.192300925652186

Epoch: 5| Step: 11
Training loss: 2.737104892730713
Validation loss: 2.1834713766972222

Epoch: 343| Step: 0
Training loss: 1.6238162517547607
Validation loss: 2.128299747904142

Epoch: 5| Step: 1
Training loss: 1.9073257446289062
Validation loss: 2.1250233153502145

Epoch: 5| Step: 2
Training loss: 0.9513095617294312
Validation loss: 2.1707581182320914

Epoch: 5| Step: 3
Training loss: 1.7837997674942017
Validation loss: 2.1926090866327286

Epoch: 5| Step: 4
Training loss: 1.4517067670822144
Validation loss: 2.214873934785525

Epoch: 5| Step: 5
Training loss: 1.2815067768096924
Validation loss: 2.191485141714414

Epoch: 5| Step: 6
Training loss: 1.6065447330474854
Validation loss: 2.217587649822235

Epoch: 5| Step: 7
Training loss: 1.7941970825195312
Validation loss: 2.2282673517862954

Epoch: 5| Step: 8
Training loss: 1.8911917209625244
Validation loss: 2.2334258953730264

Epoch: 5| Step: 9
Training loss: 1.4628785848617554
Validation loss: 2.2154373973608017

Epoch: 5| Step: 10
Training loss: 1.8912794589996338
Validation loss: 2.229168340563774

Epoch: 5| Step: 11
Training loss: 0.6311609745025635
Validation loss: 2.2556884239117303

Epoch: 344| Step: 0
Training loss: 1.8077386617660522
Validation loss: 2.268484428524971

Epoch: 5| Step: 1
Training loss: 1.5251967906951904
Validation loss: 2.2419863045215607

Epoch: 5| Step: 2
Training loss: 0.9441801309585571
Validation loss: 2.218550682067871

Epoch: 5| Step: 3
Training loss: 1.923802375793457
Validation loss: 2.2006839513778687

Epoch: 5| Step: 4
Training loss: 2.0799171924591064
Validation loss: 2.1940648357073465

Epoch: 5| Step: 5
Training loss: 1.7044156789779663
Validation loss: 2.1826553841431937

Epoch: 5| Step: 6
Training loss: 1.317972183227539
Validation loss: 2.1744661728541055

Epoch: 5| Step: 7
Training loss: 1.5407037734985352
Validation loss: 2.191706736882528

Epoch: 5| Step: 8
Training loss: 1.395448923110962
Validation loss: 2.1804110407829285

Epoch: 5| Step: 9
Training loss: 1.273206114768982
Validation loss: 2.1904188940922418

Epoch: 5| Step: 10
Training loss: 1.3105286359786987
Validation loss: 2.1791684528191886

Epoch: 5| Step: 11
Training loss: 2.557417631149292
Validation loss: 2.20737033089002

Epoch: 345| Step: 0
Training loss: 1.9003410339355469
Validation loss: 2.2205466826756797

Epoch: 5| Step: 1
Training loss: 1.011899709701538
Validation loss: 2.231971323490143

Epoch: 5| Step: 2
Training loss: 1.8284623622894287
Validation loss: 2.2444973289966583

Epoch: 5| Step: 3
Training loss: 1.429947018623352
Validation loss: 2.2303055822849274

Epoch: 5| Step: 4
Training loss: 1.574340581893921
Validation loss: 2.2088035941123962

Epoch: 5| Step: 5
Training loss: 1.5192785263061523
Validation loss: 2.20106969277064

Epoch: 5| Step: 6
Training loss: 1.9228109121322632
Validation loss: 2.209643696745237

Epoch: 5| Step: 7
Training loss: 1.119441270828247
Validation loss: 2.212825601299604

Epoch: 5| Step: 8
Training loss: 1.3947656154632568
Validation loss: 2.1935639480749765

Epoch: 5| Step: 9
Training loss: 1.6487884521484375
Validation loss: 2.217348421613375

Epoch: 5| Step: 10
Training loss: 1.2784780263900757
Validation loss: 2.2198714315891266

Epoch: 5| Step: 11
Training loss: 1.7950948476791382
Validation loss: 2.231488878528277

Epoch: 346| Step: 0
Training loss: 1.7363665103912354
Validation loss: 2.1795596530040107

Epoch: 5| Step: 1
Training loss: 1.6872764825820923
Validation loss: 2.172727217276891

Epoch: 5| Step: 2
Training loss: 1.7806313037872314
Validation loss: 2.2026240626970925

Epoch: 5| Step: 3
Training loss: 1.7273218631744385
Validation loss: 2.1712111830711365

Epoch: 5| Step: 4
Training loss: 1.8064857721328735
Validation loss: 2.176077534755071

Epoch: 5| Step: 5
Training loss: 1.095273733139038
Validation loss: 2.1868000626564026

Epoch: 5| Step: 6
Training loss: 0.9367853403091431
Validation loss: 2.166580766439438

Epoch: 5| Step: 7
Training loss: 1.5236685276031494
Validation loss: 2.178885171810786

Epoch: 5| Step: 8
Training loss: 1.475048303604126
Validation loss: 2.160361041625341

Epoch: 5| Step: 9
Training loss: 1.1788352727890015
Validation loss: 2.161874686678251

Epoch: 5| Step: 10
Training loss: 2.0658812522888184
Validation loss: 2.1579862733682

Epoch: 5| Step: 11
Training loss: 2.2032556533813477
Validation loss: 2.1911376814047494

Epoch: 347| Step: 0
Training loss: 1.127105474472046
Validation loss: 2.1486968795458474

Epoch: 5| Step: 1
Training loss: 1.4978352785110474
Validation loss: 2.143276651700338

Epoch: 5| Step: 2
Training loss: 0.8242037892341614
Validation loss: 2.141004428267479

Epoch: 5| Step: 3
Training loss: 1.5555206537246704
Validation loss: 2.165286729733149

Epoch: 5| Step: 4
Training loss: 1.8735631704330444
Validation loss: 2.134823908408483

Epoch: 5| Step: 5
Training loss: 1.3788212537765503
Validation loss: 2.156690468390783

Epoch: 5| Step: 6
Training loss: 1.2254003286361694
Validation loss: 2.172205542524656

Epoch: 5| Step: 7
Training loss: 1.47716224193573
Validation loss: 2.1535219649473825

Epoch: 5| Step: 8
Training loss: 2.344085693359375
Validation loss: 2.156660631299019

Epoch: 5| Step: 9
Training loss: 1.8242679834365845
Validation loss: 2.159534603357315

Epoch: 5| Step: 10
Training loss: 1.6039228439331055
Validation loss: 2.1783733665943146

Epoch: 5| Step: 11
Training loss: 1.4106419086456299
Validation loss: 2.159971763690313

Epoch: 348| Step: 0
Training loss: 1.9674932956695557
Validation loss: 2.156636103987694

Epoch: 5| Step: 1
Training loss: 1.3294997215270996
Validation loss: 2.152831514676412

Epoch: 5| Step: 2
Training loss: 1.4688174724578857
Validation loss: 2.1464117765426636

Epoch: 5| Step: 3
Training loss: 1.3949553966522217
Validation loss: 2.128131647904714

Epoch: 5| Step: 4
Training loss: 1.0724573135375977
Validation loss: 2.163019835948944

Epoch: 5| Step: 5
Training loss: 1.6983528137207031
Validation loss: 2.1563942631085715

Epoch: 5| Step: 6
Training loss: 0.8690683245658875
Validation loss: 2.1721886744101844

Epoch: 5| Step: 7
Training loss: 1.695503830909729
Validation loss: 2.2109880844751992

Epoch: 5| Step: 8
Training loss: 1.633350133895874
Validation loss: 2.2168627878030143

Epoch: 5| Step: 9
Training loss: 1.8612651824951172
Validation loss: 2.2321859498818717

Epoch: 5| Step: 10
Training loss: 1.827605962753296
Validation loss: 2.233706792195638

Epoch: 5| Step: 11
Training loss: 0.6973226070404053
Validation loss: 2.22525688012441

Epoch: 349| Step: 0
Training loss: 1.1380927562713623
Validation loss: 2.208988770842552

Epoch: 5| Step: 1
Training loss: 1.4622352123260498
Validation loss: 2.194879541794459

Epoch: 5| Step: 2
Training loss: 1.7418553829193115
Validation loss: 2.2166387836138406

Epoch: 5| Step: 3
Training loss: 1.580730676651001
Validation loss: 2.198729539910952

Epoch: 5| Step: 4
Training loss: 2.050076961517334
Validation loss: 2.2047494451204934

Epoch: 5| Step: 5
Training loss: 1.6098136901855469
Validation loss: 2.2061004290978112

Epoch: 5| Step: 6
Training loss: 1.4000904560089111
Validation loss: 2.2571641206741333

Epoch: 5| Step: 7
Training loss: 1.3869935274124146
Validation loss: 2.212078799804052

Epoch: 5| Step: 8
Training loss: 1.0817365646362305
Validation loss: 2.2187442779541016

Epoch: 5| Step: 9
Training loss: 0.6592000722885132
Validation loss: 2.234801933169365

Epoch: 5| Step: 10
Training loss: 2.1012935638427734
Validation loss: 2.2017245839039483

Epoch: 5| Step: 11
Training loss: 0.6281278133392334
Validation loss: 2.2253699600696564

Epoch: 350| Step: 0
Training loss: 0.8948023915290833
Validation loss: 2.229743560155233

Epoch: 5| Step: 1
Training loss: 1.1426539421081543
Validation loss: 2.233039895693461

Epoch: 5| Step: 2
Training loss: 1.3635902404785156
Validation loss: 2.2360684275627136

Epoch: 5| Step: 3
Training loss: 1.178489327430725
Validation loss: 2.256568734844526

Epoch: 5| Step: 4
Training loss: 1.7888103723526
Validation loss: 2.229500889778137

Epoch: 5| Step: 5
Training loss: 2.1138863563537598
Validation loss: 2.2348850270112357

Epoch: 5| Step: 6
Training loss: 1.8398536443710327
Validation loss: 2.228095536430677

Epoch: 5| Step: 7
Training loss: 1.3139753341674805
Validation loss: 2.1753342201312384

Epoch: 5| Step: 8
Training loss: 1.3904566764831543
Validation loss: 2.1880867977937064

Epoch: 5| Step: 9
Training loss: 1.5940077304840088
Validation loss: 2.1716485917568207

Epoch: 5| Step: 10
Training loss: 1.7217496633529663
Validation loss: 2.1779931088288627

Epoch: 5| Step: 11
Training loss: 1.290762186050415
Validation loss: 2.151751140753428

Epoch: 351| Step: 0
Training loss: 1.3236631155014038
Validation loss: 2.1593453089396157

Epoch: 5| Step: 1
Training loss: 1.7349159717559814
Validation loss: 2.1620833575725555

Epoch: 5| Step: 2
Training loss: 1.4534584283828735
Validation loss: 2.1448020388682685

Epoch: 5| Step: 3
Training loss: 1.7992302179336548
Validation loss: 2.165884017944336

Epoch: 5| Step: 4
Training loss: 1.0294253826141357
Validation loss: 2.187576418121656

Epoch: 5| Step: 5
Training loss: 1.3376630544662476
Validation loss: 2.168381248911222

Epoch: 5| Step: 6
Training loss: 1.4404551982879639
Validation loss: 2.1729684372742972

Epoch: 5| Step: 7
Training loss: 1.2249994277954102
Validation loss: 2.1857101917266846

Epoch: 5| Step: 8
Training loss: 1.1377601623535156
Validation loss: 2.210560421148936

Epoch: 5| Step: 9
Training loss: 1.7944653034210205
Validation loss: 2.2203512489795685

Epoch: 5| Step: 10
Training loss: 2.1553962230682373
Validation loss: 2.225212514400482

Epoch: 5| Step: 11
Training loss: 1.741257905960083
Validation loss: 2.1979333758354187

Epoch: 352| Step: 0
Training loss: 1.0543811321258545
Validation loss: 2.2080361197392144

Epoch: 5| Step: 1
Training loss: 1.4315537214279175
Validation loss: 2.209157516558965

Epoch: 5| Step: 2
Training loss: 2.1000866889953613
Validation loss: 2.205525904893875

Epoch: 5| Step: 3
Training loss: 1.7047626972198486
Validation loss: 2.2101271549860635

Epoch: 5| Step: 4
Training loss: 1.1288909912109375
Validation loss: 2.1839337100585303

Epoch: 5| Step: 5
Training loss: 1.566877007484436
Validation loss: 2.1728177865346274

Epoch: 5| Step: 6
Training loss: 2.0169947147369385
Validation loss: 2.176167458295822

Epoch: 5| Step: 7
Training loss: 1.7993577718734741
Validation loss: 2.1787161926428475

Epoch: 5| Step: 8
Training loss: 1.3051398992538452
Validation loss: 2.168883095184962

Epoch: 5| Step: 9
Training loss: 1.6332870721817017
Validation loss: 2.162448858221372

Epoch: 5| Step: 10
Training loss: 1.1315914392471313
Validation loss: 2.1640695283810296

Epoch: 5| Step: 11
Training loss: 0.4835430383682251
Validation loss: 2.127146894733111

Epoch: 353| Step: 0
Training loss: 1.333333134651184
Validation loss: 2.170874238014221

Epoch: 5| Step: 1
Training loss: 1.9957996606826782
Validation loss: 2.127886394659678

Epoch: 5| Step: 2
Training loss: 1.1329591274261475
Validation loss: 2.147268017133077

Epoch: 5| Step: 3
Training loss: 1.658612608909607
Validation loss: 2.1635862986246743

Epoch: 5| Step: 4
Training loss: 1.266145944595337
Validation loss: 2.1410685877005258

Epoch: 5| Step: 5
Training loss: 0.9764232635498047
Validation loss: 2.1458895852168403

Epoch: 5| Step: 6
Training loss: 1.35653555393219
Validation loss: 2.1716317931811013

Epoch: 5| Step: 7
Training loss: 1.8032753467559814
Validation loss: 2.170518775780996

Epoch: 5| Step: 8
Training loss: 1.2129839658737183
Validation loss: 2.149088606238365

Epoch: 5| Step: 9
Training loss: 1.9432640075683594
Validation loss: 2.165165742238363

Epoch: 5| Step: 10
Training loss: 1.5739517211914062
Validation loss: 2.1770269870758057

Epoch: 5| Step: 11
Training loss: 1.261620283126831
Validation loss: 2.1596076041460037

Epoch: 354| Step: 0
Training loss: 1.813144326210022
Validation loss: 2.164851059516271

Epoch: 5| Step: 1
Training loss: 1.2546035051345825
Validation loss: 2.181091472506523

Epoch: 5| Step: 2
Training loss: 1.633384346961975
Validation loss: 2.1851784735918045

Epoch: 5| Step: 3
Training loss: 1.2209398746490479
Validation loss: 2.1629240264495215

Epoch: 5| Step: 4
Training loss: 1.355699896812439
Validation loss: 2.1800966213146844

Epoch: 5| Step: 5
Training loss: 1.2119402885437012
Validation loss: 2.205863098303477

Epoch: 5| Step: 6
Training loss: 1.5428403615951538
Validation loss: 2.207013785839081

Epoch: 5| Step: 7
Training loss: 1.4521479606628418
Validation loss: 2.2034820119539895

Epoch: 5| Step: 8
Training loss: 1.7991836071014404
Validation loss: 2.1824175665775933

Epoch: 5| Step: 9
Training loss: 1.709638237953186
Validation loss: 2.1673456678787866

Epoch: 5| Step: 10
Training loss: 1.2057510614395142
Validation loss: 2.1676711241404214

Epoch: 5| Step: 11
Training loss: 1.2689855098724365
Validation loss: 2.185533066590627

Epoch: 355| Step: 0
Training loss: 1.4532625675201416
Validation loss: 2.1682984232902527

Epoch: 5| Step: 1
Training loss: 1.1511245965957642
Validation loss: 2.155193547407786

Epoch: 5| Step: 2
Training loss: 1.5436736345291138
Validation loss: 2.1728728612264

Epoch: 5| Step: 3
Training loss: 1.3543064594268799
Validation loss: 2.1412731210390725

Epoch: 5| Step: 4
Training loss: 1.4486277103424072
Validation loss: 2.1463698794444404

Epoch: 5| Step: 5
Training loss: 1.1934086084365845
Validation loss: 2.140116428335508

Epoch: 5| Step: 6
Training loss: 1.053736925125122
Validation loss: 2.159298613667488

Epoch: 5| Step: 7
Training loss: 1.3674100637435913
Validation loss: 2.1749279300371804

Epoch: 5| Step: 8
Training loss: 1.8564364910125732
Validation loss: 2.1573667426904044

Epoch: 5| Step: 9
Training loss: 1.7666490077972412
Validation loss: 2.15081587433815

Epoch: 5| Step: 10
Training loss: 1.7020114660263062
Validation loss: 2.1583380103111267

Epoch: 5| Step: 11
Training loss: 1.2405552864074707
Validation loss: 2.2006061375141144

Epoch: 356| Step: 0
Training loss: 1.8244125843048096
Validation loss: 2.1648148596286774

Epoch: 5| Step: 1
Training loss: 1.7806131839752197
Validation loss: 2.1954845587412515

Epoch: 5| Step: 2
Training loss: 1.2272350788116455
Validation loss: 2.1747994075218835

Epoch: 5| Step: 3
Training loss: 0.9957200288772583
Validation loss: 2.2196396787961326

Epoch: 5| Step: 4
Training loss: 1.2468481063842773
Validation loss: 2.187330186367035

Epoch: 5| Step: 5
Training loss: 1.8960990905761719
Validation loss: 2.233642409245173

Epoch: 5| Step: 6
Training loss: 1.4615886211395264
Validation loss: 2.217407137155533

Epoch: 5| Step: 7
Training loss: 1.3692667484283447
Validation loss: 2.210180883606275

Epoch: 5| Step: 8
Training loss: 1.9266116619110107
Validation loss: 2.230330968896548

Epoch: 5| Step: 9
Training loss: 1.65764582157135
Validation loss: 2.210205599665642

Epoch: 5| Step: 10
Training loss: 1.1164000034332275
Validation loss: 2.198288083076477

Epoch: 5| Step: 11
Training loss: 1.9924815893173218
Validation loss: 2.2362362444400787

Epoch: 357| Step: 0
Training loss: 1.4317986965179443
Validation loss: 2.1976716915766397

Epoch: 5| Step: 1
Training loss: 1.4062474966049194
Validation loss: 2.1831191877524057

Epoch: 5| Step: 2
Training loss: 1.3153101205825806
Validation loss: 2.2052292873462043

Epoch: 5| Step: 3
Training loss: 1.6175868511199951
Validation loss: 2.204886575539907

Epoch: 5| Step: 4
Training loss: 1.108502984046936
Validation loss: 2.186322326461474

Epoch: 5| Step: 5
Training loss: 1.2953999042510986
Validation loss: 2.185833603143692

Epoch: 5| Step: 6
Training loss: 1.9182151556015015
Validation loss: 2.177415043115616

Epoch: 5| Step: 7
Training loss: 1.2361078262329102
Validation loss: 2.181985025604566

Epoch: 5| Step: 8
Training loss: 2.0604944229125977
Validation loss: 2.197553724050522

Epoch: 5| Step: 9
Training loss: 1.4078967571258545
Validation loss: 2.1658610651890435

Epoch: 5| Step: 10
Training loss: 1.09150230884552
Validation loss: 2.1870496620734534

Epoch: 5| Step: 11
Training loss: 0.6757642030715942
Validation loss: 2.1670803229014077

Epoch: 358| Step: 0
Training loss: 1.300370454788208
Validation loss: 2.177573869625727

Epoch: 5| Step: 1
Training loss: 1.3005383014678955
Validation loss: 2.165791297952334

Epoch: 5| Step: 2
Training loss: 1.5415993928909302
Validation loss: 2.1460283597310386

Epoch: 5| Step: 3
Training loss: 1.2859365940093994
Validation loss: 2.1642262438933053

Epoch: 5| Step: 4
Training loss: 1.2387371063232422
Validation loss: 2.1610279927651086

Epoch: 5| Step: 5
Training loss: 1.7566248178482056
Validation loss: 2.146976371606191

Epoch: 5| Step: 6
Training loss: 1.3927557468414307
Validation loss: 2.150075430671374

Epoch: 5| Step: 7
Training loss: 0.8240596652030945
Validation loss: 2.167076920469602

Epoch: 5| Step: 8
Training loss: 1.9220359325408936
Validation loss: 2.1470656991004944

Epoch: 5| Step: 9
Training loss: 1.6821407079696655
Validation loss: 2.1535168985525766

Epoch: 5| Step: 10
Training loss: 1.9791291952133179
Validation loss: 2.1383922348419824

Epoch: 5| Step: 11
Training loss: 0.8833746910095215
Validation loss: 2.1308286438385644

Epoch: 359| Step: 0
Training loss: 1.5365314483642578
Validation loss: 2.1688282241423926

Epoch: 5| Step: 1
Training loss: 1.362953782081604
Validation loss: 2.156867270668348

Epoch: 5| Step: 2
Training loss: 1.6585181951522827
Validation loss: 2.121815343697866

Epoch: 5| Step: 3
Training loss: 0.6760200262069702
Validation loss: 2.131318067510923

Epoch: 5| Step: 4
Training loss: 1.64544677734375
Validation loss: 2.124941031138102

Epoch: 5| Step: 5
Training loss: 2.0494086742401123
Validation loss: 2.1116059720516205

Epoch: 5| Step: 6
Training loss: 1.4349021911621094
Validation loss: 2.152277504404386

Epoch: 5| Step: 7
Training loss: 1.6984220743179321
Validation loss: 2.132731462518374

Epoch: 5| Step: 8
Training loss: 1.1594791412353516
Validation loss: 2.158250868320465

Epoch: 5| Step: 9
Training loss: 1.13716459274292
Validation loss: 2.1560066044330597

Epoch: 5| Step: 10
Training loss: 1.7205604314804077
Validation loss: 2.188669224580129

Epoch: 5| Step: 11
Training loss: 1.6039245128631592
Validation loss: 2.171178142229716

Epoch: 360| Step: 0
Training loss: 1.6176153421401978
Validation loss: 2.2076727946599326

Epoch: 5| Step: 1
Training loss: 1.576476812362671
Validation loss: 2.1639671524365744

Epoch: 5| Step: 2
Training loss: 0.9830156564712524
Validation loss: 2.170859823624293

Epoch: 5| Step: 3
Training loss: 1.019788146018982
Validation loss: 2.1880494753519693

Epoch: 5| Step: 4
Training loss: 1.6909801959991455
Validation loss: 2.1795558035373688

Epoch: 5| Step: 5
Training loss: 1.4411885738372803
Validation loss: 2.1666033069292703

Epoch: 5| Step: 6
Training loss: 1.5137208700180054
Validation loss: 2.1479256749153137

Epoch: 5| Step: 7
Training loss: 1.241300106048584
Validation loss: 2.16529647509257

Epoch: 5| Step: 8
Training loss: 1.6693007946014404
Validation loss: 2.190786600112915

Epoch: 5| Step: 9
Training loss: 1.7056697607040405
Validation loss: 2.16730243464311

Epoch: 5| Step: 10
Training loss: 1.264267921447754
Validation loss: 2.174690624078115

Epoch: 5| Step: 11
Training loss: 1.2580152750015259
Validation loss: 2.1652243733406067

Epoch: 361| Step: 0
Training loss: 0.909101665019989
Validation loss: 2.1369321246941886

Epoch: 5| Step: 1
Training loss: 1.802654504776001
Validation loss: 2.140813405315081

Epoch: 5| Step: 2
Training loss: 1.6117782592773438
Validation loss: 2.1482255359490714

Epoch: 5| Step: 3
Training loss: 1.2584692239761353
Validation loss: 2.164433573683103

Epoch: 5| Step: 4
Training loss: 1.7712808847427368
Validation loss: 2.150110974907875

Epoch: 5| Step: 5
Training loss: 1.2724641561508179
Validation loss: 2.12017389635245

Epoch: 5| Step: 6
Training loss: 1.4657925367355347
Validation loss: 2.1628207564353943

Epoch: 5| Step: 7
Training loss: 1.7798702716827393
Validation loss: 2.144153113166491

Epoch: 5| Step: 8
Training loss: 0.8902227282524109
Validation loss: 2.171304613351822

Epoch: 5| Step: 9
Training loss: 1.1481088399887085
Validation loss: 2.2023724218209586

Epoch: 5| Step: 10
Training loss: 1.4679723978042603
Validation loss: 2.191309779882431

Epoch: 5| Step: 11
Training loss: 1.9315577745437622
Validation loss: 2.148063908020655

Epoch: 362| Step: 0
Training loss: 1.3007603883743286
Validation loss: 2.197424297531446

Epoch: 5| Step: 1
Training loss: 1.3832943439483643
Validation loss: 2.199263036251068

Epoch: 5| Step: 2
Training loss: 1.5634151697158813
Validation loss: 2.1938836773236594

Epoch: 5| Step: 3
Training loss: 1.794059157371521
Validation loss: 2.2128464430570602

Epoch: 5| Step: 4
Training loss: 1.283788800239563
Validation loss: 2.194489618142446

Epoch: 5| Step: 5
Training loss: 1.604879379272461
Validation loss: 2.1897469013929367

Epoch: 5| Step: 6
Training loss: 1.2633661031723022
Validation loss: 2.1579026679197946

Epoch: 5| Step: 7
Training loss: 1.4760545492172241
Validation loss: 2.127557357152303

Epoch: 5| Step: 8
Training loss: 2.2664780616760254
Validation loss: 2.165881857275963

Epoch: 5| Step: 9
Training loss: 1.0102460384368896
Validation loss: 2.1669597576061883

Epoch: 5| Step: 10
Training loss: 0.8013785481452942
Validation loss: 2.140915180246035

Epoch: 5| Step: 11
Training loss: 0.643729567527771
Validation loss: 2.16490039229393

Epoch: 363| Step: 0
Training loss: 1.1818751096725464
Validation loss: 2.146410286426544

Epoch: 5| Step: 1
Training loss: 1.4770848751068115
Validation loss: 2.201198011636734

Epoch: 5| Step: 2
Training loss: 1.4597145318984985
Validation loss: 2.1798323641220727

Epoch: 5| Step: 3
Training loss: 1.226845383644104
Validation loss: 2.2056539952754974

Epoch: 5| Step: 4
Training loss: 1.4430058002471924
Validation loss: 2.173484593629837

Epoch: 5| Step: 5
Training loss: 1.0508396625518799
Validation loss: 2.2113374322652817

Epoch: 5| Step: 6
Training loss: 1.8313935995101929
Validation loss: 2.202015608549118

Epoch: 5| Step: 7
Training loss: 1.5803934335708618
Validation loss: 2.175755575299263

Epoch: 5| Step: 8
Training loss: 1.9716672897338867
Validation loss: 2.1591386844714484

Epoch: 5| Step: 9
Training loss: 1.9302066564559937
Validation loss: 2.1584730396668115

Epoch: 5| Step: 10
Training loss: 1.1653060913085938
Validation loss: 2.1614160736401877

Epoch: 5| Step: 11
Training loss: 0.4959535598754883
Validation loss: 2.1808060308297477

Epoch: 364| Step: 0
Training loss: 1.4439334869384766
Validation loss: 2.1085710525512695

Epoch: 5| Step: 1
Training loss: 1.4414442777633667
Validation loss: 2.1193456997474036

Epoch: 5| Step: 2
Training loss: 1.7359946966171265
Validation loss: 2.1259577025969825

Epoch: 5| Step: 3
Training loss: 1.6664642095565796
Validation loss: 2.1276360899209976

Epoch: 5| Step: 4
Training loss: 1.0651099681854248
Validation loss: 2.1459580014149346

Epoch: 5| Step: 5
Training loss: 1.5672794580459595
Validation loss: 2.1751715193192163

Epoch: 5| Step: 6
Training loss: 0.9330925941467285
Validation loss: 2.160077432791392

Epoch: 5| Step: 7
Training loss: 1.3899598121643066
Validation loss: 2.204172303279241

Epoch: 5| Step: 8
Training loss: 1.7076938152313232
Validation loss: 2.1975427716970444

Epoch: 5| Step: 9
Training loss: 1.5437777042388916
Validation loss: 2.1774335702260337

Epoch: 5| Step: 10
Training loss: 1.3661655187606812
Validation loss: 2.1860777884721756

Epoch: 5| Step: 11
Training loss: 2.6525816917419434
Validation loss: 2.2057500978310904

Epoch: 365| Step: 0
Training loss: 1.2080351114273071
Validation loss: 2.1944474975268045

Epoch: 5| Step: 1
Training loss: 1.4563663005828857
Validation loss: 2.193270872036616

Epoch: 5| Step: 2
Training loss: 1.4708932638168335
Validation loss: 2.1710327665011087

Epoch: 5| Step: 3
Training loss: 1.1735260486602783
Validation loss: 2.2159749319156012

Epoch: 5| Step: 4
Training loss: 1.3986742496490479
Validation loss: 2.2092202405134835

Epoch: 5| Step: 5
Training loss: 1.630454659461975
Validation loss: 2.1802797317504883

Epoch: 5| Step: 6
Training loss: 1.0582183599472046
Validation loss: 2.19712304075559

Epoch: 5| Step: 7
Training loss: 1.6740820407867432
Validation loss: 2.2134031852086387

Epoch: 5| Step: 8
Training loss: 1.746169090270996
Validation loss: 2.2413010696570077

Epoch: 5| Step: 9
Training loss: 1.2779439687728882
Validation loss: 2.2176855504512787

Epoch: 5| Step: 10
Training loss: 1.3037221431732178
Validation loss: 2.187664210796356

Epoch: 5| Step: 11
Training loss: 2.884831428527832
Validation loss: 2.204816445708275

Epoch: 366| Step: 0
Training loss: 1.143498182296753
Validation loss: 2.1829123000303903

Epoch: 5| Step: 1
Training loss: 1.4454702138900757
Validation loss: 2.1764359970887504

Epoch: 5| Step: 2
Training loss: 1.3184646368026733
Validation loss: 2.1748197128375373

Epoch: 5| Step: 3
Training loss: 0.9627177119255066
Validation loss: 2.1550225665171943

Epoch: 5| Step: 4
Training loss: 0.963870644569397
Validation loss: 2.1509337524573007

Epoch: 5| Step: 5
Training loss: 1.6216404438018799
Validation loss: 2.143911918004354

Epoch: 5| Step: 6
Training loss: 1.7286535501480103
Validation loss: 2.1705015997091928

Epoch: 5| Step: 7
Training loss: 2.068159580230713
Validation loss: 2.1820010195175805

Epoch: 5| Step: 8
Training loss: 1.184136986732483
Validation loss: 2.2108221650123596

Epoch: 5| Step: 9
Training loss: 1.9124338626861572
Validation loss: 2.174774835507075

Epoch: 5| Step: 10
Training loss: 1.201695203781128
Validation loss: 2.171163578828176

Epoch: 5| Step: 11
Training loss: 1.354888677597046
Validation loss: 2.2080339988072715

Epoch: 367| Step: 0
Training loss: 2.4224846363067627
Validation loss: 2.1831103215614953

Epoch: 5| Step: 1
Training loss: 1.194904088973999
Validation loss: 2.1962971786657968

Epoch: 5| Step: 2
Training loss: 0.981549859046936
Validation loss: 2.2296140094598136

Epoch: 5| Step: 3
Training loss: 1.4846704006195068
Validation loss: 2.1880080848932266

Epoch: 5| Step: 4
Training loss: 1.0587522983551025
Validation loss: 2.170475502808889

Epoch: 5| Step: 5
Training loss: 2.0711820125579834
Validation loss: 2.1790262907743454

Epoch: 5| Step: 6
Training loss: 0.7611483335494995
Validation loss: 2.158233563105265

Epoch: 5| Step: 7
Training loss: 1.1728801727294922
Validation loss: 2.1119082321723304

Epoch: 5| Step: 8
Training loss: 1.3362960815429688
Validation loss: 2.145075539747874

Epoch: 5| Step: 9
Training loss: 1.0660358667373657
Validation loss: 2.146333778897921

Epoch: 5| Step: 10
Training loss: 2.0516152381896973
Validation loss: 2.137429783741633

Epoch: 5| Step: 11
Training loss: 0.9968249797821045
Validation loss: 2.1509000261624656

Epoch: 368| Step: 0
Training loss: 1.4805207252502441
Validation loss: 2.1335936536391578

Epoch: 5| Step: 1
Training loss: 1.2088481187820435
Validation loss: 2.1695114076137543

Epoch: 5| Step: 2
Training loss: 1.6807094812393188
Validation loss: 2.1803280413150787

Epoch: 5| Step: 3
Training loss: 1.3562614917755127
Validation loss: 2.2240341752767563

Epoch: 5| Step: 4
Training loss: 1.6322530508041382
Validation loss: 2.19857649008433

Epoch: 5| Step: 5
Training loss: 1.6311924457550049
Validation loss: 2.205345938603083

Epoch: 5| Step: 6
Training loss: 1.2165639400482178
Validation loss: 2.209238131841024

Epoch: 5| Step: 7
Training loss: 1.3557260036468506
Validation loss: 2.2170786559581757

Epoch: 5| Step: 8
Training loss: 1.089340090751648
Validation loss: 2.217441906531652

Epoch: 5| Step: 9
Training loss: 1.229400396347046
Validation loss: 2.2547417183717093

Epoch: 5| Step: 10
Training loss: 1.4072126150131226
Validation loss: 2.207743967572848

Epoch: 5| Step: 11
Training loss: 0.8325363397598267
Validation loss: 2.2063587655623755

Epoch: 369| Step: 0
Training loss: 1.1144537925720215
Validation loss: 2.170802349845568

Epoch: 5| Step: 1
Training loss: 1.3215687274932861
Validation loss: 2.1814830054839454

Epoch: 5| Step: 2
Training loss: 0.9959648251533508
Validation loss: 2.180583561460177

Epoch: 5| Step: 3
Training loss: 1.6334199905395508
Validation loss: 2.183159445722898

Epoch: 5| Step: 4
Training loss: 0.8716721534729004
Validation loss: 2.1454280565182366

Epoch: 5| Step: 5
Training loss: 1.5914031267166138
Validation loss: 2.1930523961782455

Epoch: 5| Step: 6
Training loss: 2.0473196506500244
Validation loss: 2.180304616689682

Epoch: 5| Step: 7
Training loss: 1.9913842678070068
Validation loss: 2.1768120725949607

Epoch: 5| Step: 8
Training loss: 1.777120590209961
Validation loss: 2.1545394410689673

Epoch: 5| Step: 9
Training loss: 1.015049934387207
Validation loss: 2.119483823577563

Epoch: 5| Step: 10
Training loss: 1.2694867849349976
Validation loss: 2.116365854938825

Epoch: 5| Step: 11
Training loss: 0.5329107046127319
Validation loss: 2.1219689746697745

Epoch: 370| Step: 0
Training loss: 1.329896330833435
Validation loss: 2.124405175447464

Epoch: 5| Step: 1
Training loss: 2.266624927520752
Validation loss: 2.1471821814775467

Epoch: 5| Step: 2
Training loss: 0.5797974467277527
Validation loss: 2.1711241006851196

Epoch: 5| Step: 3
Training loss: 2.042834520339966
Validation loss: 2.1811081767082214

Epoch: 5| Step: 4
Training loss: 1.3046290874481201
Validation loss: 2.1953695813814798

Epoch: 5| Step: 5
Training loss: 1.0446481704711914
Validation loss: 2.1668577591578164

Epoch: 5| Step: 6
Training loss: 1.4344536066055298
Validation loss: 2.18087337911129

Epoch: 5| Step: 7
Training loss: 1.8373024463653564
Validation loss: 2.183883716662725

Epoch: 5| Step: 8
Training loss: 0.6088645458221436
Validation loss: 2.1921739280223846

Epoch: 5| Step: 9
Training loss: 1.430972933769226
Validation loss: 2.1387330492337546

Epoch: 5| Step: 10
Training loss: 1.112444519996643
Validation loss: 2.1988487591346106

Epoch: 5| Step: 11
Training loss: 1.0044598579406738
Validation loss: 2.1695192058881125

Epoch: 371| Step: 0
Training loss: 1.6297290325164795
Validation loss: 2.137594992915789

Epoch: 5| Step: 1
Training loss: 1.4222590923309326
Validation loss: 2.1693478425343833

Epoch: 5| Step: 2
Training loss: 1.9530394077301025
Validation loss: 2.177691772580147

Epoch: 5| Step: 3
Training loss: 1.4090855121612549
Validation loss: 2.1800140937169394

Epoch: 5| Step: 4
Training loss: 1.3091456890106201
Validation loss: 2.1870017796754837

Epoch: 5| Step: 5
Training loss: 1.9767367839813232
Validation loss: 2.1840672691663108

Epoch: 5| Step: 6
Training loss: 1.374528169631958
Validation loss: 2.1829166412353516

Epoch: 5| Step: 7
Training loss: 0.9076633453369141
Validation loss: 2.1974456508954368

Epoch: 5| Step: 8
Training loss: 0.8608074188232422
Validation loss: 2.179143875837326

Epoch: 5| Step: 9
Training loss: 1.7947485446929932
Validation loss: 2.15711239973704

Epoch: 5| Step: 10
Training loss: 1.0976874828338623
Validation loss: 2.1505565295616784

Epoch: 5| Step: 11
Training loss: 1.855299711227417
Validation loss: 2.1512995113929114

Epoch: 372| Step: 0
Training loss: 0.9214693903923035
Validation loss: 2.105084851384163

Epoch: 5| Step: 1
Training loss: 1.023573875427246
Validation loss: 2.1373054881890616

Epoch: 5| Step: 2
Training loss: 0.9204033613204956
Validation loss: 2.1119475215673447

Epoch: 5| Step: 3
Training loss: 1.3142564296722412
Validation loss: 2.1436001559098563

Epoch: 5| Step: 4
Training loss: 1.79669189453125
Validation loss: 2.175310730934143

Epoch: 5| Step: 5
Training loss: 1.6878284215927124
Validation loss: 2.1694708466529846

Epoch: 5| Step: 6
Training loss: 1.5025136470794678
Validation loss: 2.171916882197062

Epoch: 5| Step: 7
Training loss: 2.0450427532196045
Validation loss: 2.1515697042147317

Epoch: 5| Step: 8
Training loss: 1.6621208190917969
Validation loss: 2.1606645037730536

Epoch: 5| Step: 9
Training loss: 1.0381598472595215
Validation loss: 2.166584089398384

Epoch: 5| Step: 10
Training loss: 1.4659311771392822
Validation loss: 2.1742700785398483

Epoch: 5| Step: 11
Training loss: 2.8946807384490967
Validation loss: 2.1710660556952157

Epoch: 373| Step: 0
Training loss: 2.145667552947998
Validation loss: 2.2011354168256125

Epoch: 5| Step: 1
Training loss: 1.4509671926498413
Validation loss: 2.1784874945878983

Epoch: 5| Step: 2
Training loss: 1.6401281356811523
Validation loss: 2.164181570212046

Epoch: 5| Step: 3
Training loss: 1.290231704711914
Validation loss: 2.147440940141678

Epoch: 5| Step: 4
Training loss: 1.3068214654922485
Validation loss: 2.1330504765113196

Epoch: 5| Step: 5
Training loss: 1.0556141138076782
Validation loss: 2.1276693493127823

Epoch: 5| Step: 6
Training loss: 1.1181418895721436
Validation loss: 2.1357643008232117

Epoch: 5| Step: 7
Training loss: 1.477325201034546
Validation loss: 2.120060369372368

Epoch: 5| Step: 8
Training loss: 1.4862329959869385
Validation loss: 2.1152018507321677

Epoch: 5| Step: 9
Training loss: 1.423863172531128
Validation loss: 2.155900771419207

Epoch: 5| Step: 10
Training loss: 0.9404042363166809
Validation loss: 2.1270996431509652

Epoch: 5| Step: 11
Training loss: 2.7880170345306396
Validation loss: 2.168701554338137

Epoch: 374| Step: 0
Training loss: 1.956608772277832
Validation loss: 2.1910217007001243

Epoch: 5| Step: 1
Training loss: 2.0139992237091064
Validation loss: 2.2009521822134652

Epoch: 5| Step: 2
Training loss: 1.5587397813796997
Validation loss: 2.236916651328405

Epoch: 5| Step: 3
Training loss: 1.0184324979782104
Validation loss: 2.2131084402402244

Epoch: 5| Step: 4
Training loss: 2.057227373123169
Validation loss: 2.1998854825894036

Epoch: 5| Step: 5
Training loss: 1.3829772472381592
Validation loss: 2.1740136990944543

Epoch: 5| Step: 6
Training loss: 0.8797113299369812
Validation loss: 2.131081153949102

Epoch: 5| Step: 7
Training loss: 1.3614399433135986
Validation loss: 2.15739543735981

Epoch: 5| Step: 8
Training loss: 0.7796796560287476
Validation loss: 2.1627775381008782

Epoch: 5| Step: 9
Training loss: 0.9776636958122253
Validation loss: 2.164187083641688

Epoch: 5| Step: 10
Training loss: 1.648904800415039
Validation loss: 2.157643367846807

Epoch: 5| Step: 11
Training loss: 1.7605347633361816
Validation loss: 2.1535033136606216

Epoch: 375| Step: 0
Training loss: 2.0234334468841553
Validation loss: 2.1727056801319122

Epoch: 5| Step: 1
Training loss: 1.0851792097091675
Validation loss: 2.184512143333753

Epoch: 5| Step: 2
Training loss: 0.8316053152084351
Validation loss: 2.1853215197722116

Epoch: 5| Step: 3
Training loss: 1.917724609375
Validation loss: 2.236220399538676

Epoch: 5| Step: 4
Training loss: 1.7758901119232178
Validation loss: 2.207069302598635

Epoch: 5| Step: 5
Training loss: 1.5991796255111694
Validation loss: 2.219045708576838

Epoch: 5| Step: 6
Training loss: 1.442621111869812
Validation loss: 2.1944808810949326

Epoch: 5| Step: 7
Training loss: 0.9194477796554565
Validation loss: 2.175326645374298

Epoch: 5| Step: 8
Training loss: 1.206713318824768
Validation loss: 2.1677899410327277

Epoch: 5| Step: 9
Training loss: 1.3570539951324463
Validation loss: 2.186285878221194

Epoch: 5| Step: 10
Training loss: 1.1038672924041748
Validation loss: 2.1785935113827386

Epoch: 5| Step: 11
Training loss: 0.9517773389816284
Validation loss: 2.175219714641571

Epoch: 376| Step: 0
Training loss: 1.7890064716339111
Validation loss: 2.1461139569679895

Epoch: 5| Step: 1
Training loss: 1.6340843439102173
Validation loss: 2.1540353149175644

Epoch: 5| Step: 2
Training loss: 1.1622623205184937
Validation loss: 2.114391048749288

Epoch: 5| Step: 3
Training loss: 1.032531499862671
Validation loss: 2.142092600464821

Epoch: 5| Step: 4
Training loss: 1.4701998233795166
Validation loss: 2.1557950476805368

Epoch: 5| Step: 5
Training loss: 1.1338393688201904
Validation loss: 2.1499326527118683

Epoch: 5| Step: 6
Training loss: 0.8938522338867188
Validation loss: 2.146779259045919

Epoch: 5| Step: 7
Training loss: 1.564536213874817
Validation loss: 2.1555349429448447

Epoch: 5| Step: 8
Training loss: 1.4921653270721436
Validation loss: 2.147480477889379

Epoch: 5| Step: 9
Training loss: 1.6736838817596436
Validation loss: 2.1834848572810492

Epoch: 5| Step: 10
Training loss: 0.8926113247871399
Validation loss: 2.1763307750225067

Epoch: 5| Step: 11
Training loss: 0.9237249493598938
Validation loss: 2.2004450062910714

Epoch: 377| Step: 0
Training loss: 1.3245511054992676
Validation loss: 2.1913761496543884

Epoch: 5| Step: 1
Training loss: 1.10927414894104
Validation loss: 2.2025457272926965

Epoch: 5| Step: 2
Training loss: 1.368882656097412
Validation loss: 2.234320268034935

Epoch: 5| Step: 3
Training loss: 1.535198450088501
Validation loss: 2.1813176969687142

Epoch: 5| Step: 4
Training loss: 0.9032727479934692
Validation loss: 2.2062885214885077

Epoch: 5| Step: 5
Training loss: 1.9166467189788818
Validation loss: 2.190712789694468

Epoch: 5| Step: 6
Training loss: 1.4602789878845215
Validation loss: 2.201652780175209

Epoch: 5| Step: 7
Training loss: 0.8001022338867188
Validation loss: 2.201119214296341

Epoch: 5| Step: 8
Training loss: 1.848340630531311
Validation loss: 2.1965833952029548

Epoch: 5| Step: 9
Training loss: 0.7347867488861084
Validation loss: 2.1916816582282386

Epoch: 5| Step: 10
Training loss: 1.526161789894104
Validation loss: 2.1572145571311316

Epoch: 5| Step: 11
Training loss: 0.8064748048782349
Validation loss: 2.1716708093881607

Epoch: 378| Step: 0
Training loss: 1.6531635522842407
Validation loss: 2.175525958339373

Epoch: 5| Step: 1
Training loss: 1.804909110069275
Validation loss: 2.1736772656440735

Epoch: 5| Step: 2
Training loss: 0.8131988644599915
Validation loss: 2.156317720810572

Epoch: 5| Step: 3
Training loss: 1.3775116205215454
Validation loss: 2.2187602569659552

Epoch: 5| Step: 4
Training loss: 0.9346968531608582
Validation loss: 2.1624927719434104

Epoch: 5| Step: 5
Training loss: 1.6073518991470337
Validation loss: 2.174349824587504

Epoch: 5| Step: 6
Training loss: 1.154033899307251
Validation loss: 2.1630770514408746

Epoch: 5| Step: 7
Training loss: 0.9705419540405273
Validation loss: 2.149903173247973

Epoch: 5| Step: 8
Training loss: 1.7371876239776611
Validation loss: 2.1544383466243744

Epoch: 5| Step: 9
Training loss: 1.5659153461456299
Validation loss: 2.1412968238194785

Epoch: 5| Step: 10
Training loss: 0.9991582036018372
Validation loss: 2.13279257218043

Epoch: 5| Step: 11
Training loss: 1.9761520624160767
Validation loss: 2.1570946176846824

Epoch: 379| Step: 0
Training loss: 1.4428319931030273
Validation loss: 2.1256801833709082

Epoch: 5| Step: 1
Training loss: 1.303948163986206
Validation loss: 2.123259569207827

Epoch: 5| Step: 2
Training loss: 1.2356960773468018
Validation loss: 2.100085328022639

Epoch: 5| Step: 3
Training loss: 1.1624151468276978
Validation loss: 2.1104623128970466

Epoch: 5| Step: 4
Training loss: 1.3576081991195679
Validation loss: 2.107434704899788

Epoch: 5| Step: 5
Training loss: 1.5995813608169556
Validation loss: 2.0792520344257355

Epoch: 5| Step: 6
Training loss: 1.821984887123108
Validation loss: 2.110028381148974

Epoch: 5| Step: 7
Training loss: 1.2468852996826172
Validation loss: 2.1309883197148642

Epoch: 5| Step: 8
Training loss: 1.3798959255218506
Validation loss: 2.1454267700513205

Epoch: 5| Step: 9
Training loss: 0.6425515413284302
Validation loss: 2.1168868939081826

Epoch: 5| Step: 10
Training loss: 1.5051863193511963
Validation loss: 2.1436331470807395

Epoch: 5| Step: 11
Training loss: 0.4394668936729431
Validation loss: 2.119320720434189

Epoch: 380| Step: 0
Training loss: 0.968826949596405
Validation loss: 2.154973412553469

Epoch: 5| Step: 1
Training loss: 1.692171335220337
Validation loss: 2.163049270709356

Epoch: 5| Step: 2
Training loss: 1.463120937347412
Validation loss: 2.1712972621122995

Epoch: 5| Step: 3
Training loss: 1.7805827856063843
Validation loss: 2.170233582456907

Epoch: 5| Step: 4
Training loss: 1.5709186792373657
Validation loss: 2.152238721648852

Epoch: 5| Step: 5
Training loss: 1.5656238794326782
Validation loss: 2.1495460867881775

Epoch: 5| Step: 6
Training loss: 0.9963709115982056
Validation loss: 2.15515099465847

Epoch: 5| Step: 7
Training loss: 1.0450069904327393
Validation loss: 2.127546856800715

Epoch: 5| Step: 8
Training loss: 1.6330751180648804
Validation loss: 2.123744860291481

Epoch: 5| Step: 9
Training loss: 1.0920257568359375
Validation loss: 2.116454695661863

Epoch: 5| Step: 10
Training loss: 0.894291877746582
Validation loss: 2.1451785961786904

Epoch: 5| Step: 11
Training loss: 2.7721986770629883
Validation loss: 2.1163074572881064

Epoch: 381| Step: 0
Training loss: 1.0972331762313843
Validation loss: 2.1157176742951074

Epoch: 5| Step: 1
Training loss: 1.8914763927459717
Validation loss: 2.1231896032889686

Epoch: 5| Step: 2
Training loss: 1.7252334356307983
Validation loss: 2.115818351507187

Epoch: 5| Step: 3
Training loss: 1.6045774221420288
Validation loss: 2.153116097052892

Epoch: 5| Step: 4
Training loss: 1.157379150390625
Validation loss: 2.119670699040095

Epoch: 5| Step: 5
Training loss: 1.0140290260314941
Validation loss: 2.1390106628338494

Epoch: 5| Step: 6
Training loss: 1.2579753398895264
Validation loss: 2.134118457635244

Epoch: 5| Step: 7
Training loss: 1.375784158706665
Validation loss: 2.131301869948705

Epoch: 5| Step: 8
Training loss: 1.5014150142669678
Validation loss: 2.1816565692424774

Epoch: 5| Step: 9
Training loss: 1.3124220371246338
Validation loss: 2.2108710010846457

Epoch: 5| Step: 10
Training loss: 0.6905518770217896
Validation loss: 2.218086908260981

Epoch: 5| Step: 11
Training loss: 0.964454174041748
Validation loss: 2.1787811617056527

Epoch: 382| Step: 0
Training loss: 1.5704669952392578
Validation loss: 2.1429714957873025

Epoch: 5| Step: 1
Training loss: 1.7090765237808228
Validation loss: 2.1522621711095176

Epoch: 5| Step: 2
Training loss: 1.8745505809783936
Validation loss: 2.1605106741189957

Epoch: 5| Step: 3
Training loss: 1.0571240186691284
Validation loss: 2.1613426357507706

Epoch: 5| Step: 4
Training loss: 1.312674880027771
Validation loss: 2.144693911075592

Epoch: 5| Step: 5
Training loss: 1.2650007009506226
Validation loss: 2.1766174882650375

Epoch: 5| Step: 6
Training loss: 0.8231993913650513
Validation loss: 2.191546673576037

Epoch: 5| Step: 7
Training loss: 1.1660598516464233
Validation loss: 2.172947585582733

Epoch: 5| Step: 8
Training loss: 1.5239169597625732
Validation loss: 2.171221762895584

Epoch: 5| Step: 9
Training loss: 1.318192958831787
Validation loss: 2.184352159500122

Epoch: 5| Step: 10
Training loss: 1.2597554922103882
Validation loss: 2.152329901854197

Epoch: 5| Step: 11
Training loss: 0.5813417434692383
Validation loss: 2.149675890803337

Epoch: 383| Step: 0
Training loss: 2.091599941253662
Validation loss: 2.1706162889798484

Epoch: 5| Step: 1
Training loss: 1.4262245893478394
Validation loss: 2.1808824141820273

Epoch: 5| Step: 2
Training loss: 1.220190405845642
Validation loss: 2.1825857361157737

Epoch: 5| Step: 3
Training loss: 1.314373254776001
Validation loss: 2.235351155201594

Epoch: 5| Step: 4
Training loss: 1.075697660446167
Validation loss: 2.224687397480011

Epoch: 5| Step: 5
Training loss: 1.1683177947998047
Validation loss: 2.205699145793915

Epoch: 5| Step: 6
Training loss: 1.28681480884552
Validation loss: 2.2269000560045242

Epoch: 5| Step: 7
Training loss: 1.2991360425949097
Validation loss: 2.2083155612150827

Epoch: 5| Step: 8
Training loss: 1.3683079481124878
Validation loss: 2.2064757446448007

Epoch: 5| Step: 9
Training loss: 1.396877646446228
Validation loss: 2.1928792099157968

Epoch: 5| Step: 10
Training loss: 1.1557564735412598
Validation loss: 2.186529020468394

Epoch: 5| Step: 11
Training loss: 0.6005703210830688
Validation loss: 2.163404176632563

Epoch: 384| Step: 0
Training loss: 1.5460078716278076
Validation loss: 2.145383814970652

Epoch: 5| Step: 1
Training loss: 1.2979398965835571
Validation loss: 2.177801698446274

Epoch: 5| Step: 2
Training loss: 0.9505969882011414
Validation loss: 2.1456979513168335

Epoch: 5| Step: 3
Training loss: 1.433345079421997
Validation loss: 2.169482265909513

Epoch: 5| Step: 4
Training loss: 1.7615501880645752
Validation loss: 2.1737128595511117

Epoch: 5| Step: 5
Training loss: 1.1062253713607788
Validation loss: 2.151637559135755

Epoch: 5| Step: 6
Training loss: 1.3345378637313843
Validation loss: 2.1683915903170905

Epoch: 5| Step: 7
Training loss: 1.6373720169067383
Validation loss: 2.1967412531375885

Epoch: 5| Step: 8
Training loss: 1.7226625680923462
Validation loss: 2.1530936608711877

Epoch: 5| Step: 9
Training loss: 1.08376944065094
Validation loss: 2.1771017660697303

Epoch: 5| Step: 10
Training loss: 0.8910537958145142
Validation loss: 2.2016309201717377

Epoch: 5| Step: 11
Training loss: 0.3217662274837494
Validation loss: 2.137720068295797

Epoch: 385| Step: 0
Training loss: 1.1121121644973755
Validation loss: 2.1416454762220383

Epoch: 5| Step: 1
Training loss: 2.1091256141662598
Validation loss: 2.1944142431020737

Epoch: 5| Step: 2
Training loss: 1.5936466455459595
Validation loss: 2.1884436706701913

Epoch: 5| Step: 3
Training loss: 1.197173833847046
Validation loss: 2.1836660653352737

Epoch: 5| Step: 4
Training loss: 1.5278594493865967
Validation loss: 2.1729498704274497

Epoch: 5| Step: 5
Training loss: 2.012955904006958
Validation loss: 2.1956409414609275

Epoch: 5| Step: 6
Training loss: 1.1728969812393188
Validation loss: 2.196261152625084

Epoch: 5| Step: 7
Training loss: 0.9171608090400696
Validation loss: 2.188545564810435

Epoch: 5| Step: 8
Training loss: 1.6220670938491821
Validation loss: 2.1847593088944754

Epoch: 5| Step: 9
Training loss: 1.4203118085861206
Validation loss: 2.1983721603949866

Epoch: 5| Step: 10
Training loss: 1.3882083892822266
Validation loss: 2.1563432017962136

Epoch: 5| Step: 11
Training loss: 1.0692342519760132
Validation loss: 2.1851171453793845

Epoch: 386| Step: 0
Training loss: 1.0544731616973877
Validation loss: 2.171476831038793

Epoch: 5| Step: 1
Training loss: 1.490953803062439
Validation loss: 2.1163105815649033

Epoch: 5| Step: 2
Training loss: 1.1389875411987305
Validation loss: 2.1359411478042603

Epoch: 5| Step: 3
Training loss: 1.755885362625122
Validation loss: 2.1037641068299613

Epoch: 5| Step: 4
Training loss: 0.9956409335136414
Validation loss: 2.1185044050216675

Epoch: 5| Step: 5
Training loss: 1.0560063123703003
Validation loss: 2.1290023028850555

Epoch: 5| Step: 6
Training loss: 1.447811245918274
Validation loss: 2.12781523168087

Epoch: 5| Step: 7
Training loss: 1.2195547819137573
Validation loss: 2.138142228126526

Epoch: 5| Step: 8
Training loss: 1.059849500656128
Validation loss: 2.135857194662094

Epoch: 5| Step: 9
Training loss: 1.8266122341156006
Validation loss: 2.1690599024295807

Epoch: 5| Step: 10
Training loss: 1.28725004196167
Validation loss: 2.1639150232076645

Epoch: 5| Step: 11
Training loss: 1.534826636314392
Validation loss: 2.144382521510124

Epoch: 387| Step: 0
Training loss: 1.1725780963897705
Validation loss: 2.1273993204037347

Epoch: 5| Step: 1
Training loss: 1.7707008123397827
Validation loss: 2.1612108846505484

Epoch: 5| Step: 2
Training loss: 1.4041796922683716
Validation loss: 2.168147921562195

Epoch: 5| Step: 3
Training loss: 1.1250684261322021
Validation loss: 2.1721281905968985

Epoch: 5| Step: 4
Training loss: 1.7186381816864014
Validation loss: 2.1779726992050805

Epoch: 5| Step: 5
Training loss: 1.079914927482605
Validation loss: 2.1135354737440744

Epoch: 5| Step: 6
Training loss: 1.6074020862579346
Validation loss: 2.129637822508812

Epoch: 5| Step: 7
Training loss: 1.4848212003707886
Validation loss: 2.1560826748609543

Epoch: 5| Step: 8
Training loss: 1.3610588312149048
Validation loss: 2.1486943314472833

Epoch: 5| Step: 9
Training loss: 1.4756836891174316
Validation loss: 2.182461222012838

Epoch: 5| Step: 10
Training loss: 0.7859433889389038
Validation loss: 2.1620737512906394

Epoch: 5| Step: 11
Training loss: 0.8474617004394531
Validation loss: 2.1538618306318917

Epoch: 388| Step: 0
Training loss: 1.6146701574325562
Validation loss: 2.188694124420484

Epoch: 5| Step: 1
Training loss: 1.3481578826904297
Validation loss: 2.187656824787458

Epoch: 5| Step: 2
Training loss: 1.3374865055084229
Validation loss: 2.1706350644429526

Epoch: 5| Step: 3
Training loss: 1.121738076210022
Validation loss: 2.1600725054740906

Epoch: 5| Step: 4
Training loss: 1.471690058708191
Validation loss: 2.12881068388621

Epoch: 5| Step: 5
Training loss: 1.0228644609451294
Validation loss: 2.1601467380921044

Epoch: 5| Step: 6
Training loss: 1.3864754438400269
Validation loss: 2.1724479595820108

Epoch: 5| Step: 7
Training loss: 1.7969049215316772
Validation loss: 2.1882442931334176

Epoch: 5| Step: 8
Training loss: 1.1864111423492432
Validation loss: 2.1113118529319763

Epoch: 5| Step: 9
Training loss: 0.6900504231452942
Validation loss: 2.1793832232554755

Epoch: 5| Step: 10
Training loss: 1.2440240383148193
Validation loss: 2.1890891244014106

Epoch: 5| Step: 11
Training loss: 0.6521851420402527
Validation loss: 2.1846558849016824

Epoch: 389| Step: 0
Training loss: 1.4692045450210571
Validation loss: 2.1701580584049225

Epoch: 5| Step: 1
Training loss: 0.8985586166381836
Validation loss: 2.2029585987329483

Epoch: 5| Step: 2
Training loss: 1.0384770631790161
Validation loss: 2.1760631601015725

Epoch: 5| Step: 3
Training loss: 1.5195109844207764
Validation loss: 2.189543863137563

Epoch: 5| Step: 4
Training loss: 1.0506117343902588
Validation loss: 2.2034541269143424

Epoch: 5| Step: 5
Training loss: 1.2950021028518677
Validation loss: 2.17604923248291

Epoch: 5| Step: 6
Training loss: 1.540440559387207
Validation loss: 2.1664199431737265

Epoch: 5| Step: 7
Training loss: 0.9840260744094849
Validation loss: 2.1678579449653625

Epoch: 5| Step: 8
Training loss: 1.4931199550628662
Validation loss: 2.153610443075498

Epoch: 5| Step: 9
Training loss: 1.6254810094833374
Validation loss: 2.159538611769676

Epoch: 5| Step: 10
Training loss: 1.6881757974624634
Validation loss: 2.1641307224829993

Epoch: 5| Step: 11
Training loss: 0.21247035264968872
Validation loss: 2.182585895061493

Epoch: 390| Step: 0
Training loss: 1.7853574752807617
Validation loss: 2.18631120522817

Epoch: 5| Step: 1
Training loss: 1.4588701725006104
Validation loss: 2.1721051235993705

Epoch: 5| Step: 2
Training loss: 1.3153626918792725
Validation loss: 2.162399629751841

Epoch: 5| Step: 3
Training loss: 1.68343985080719
Validation loss: 2.140114645163218

Epoch: 5| Step: 4
Training loss: 1.6581428050994873
Validation loss: 2.1875822842121124

Epoch: 5| Step: 5
Training loss: 1.1299101114273071
Validation loss: 2.1961724211772284

Epoch: 5| Step: 6
Training loss: 0.9796251058578491
Validation loss: 2.217472185691198

Epoch: 5| Step: 7
Training loss: 1.0283164978027344
Validation loss: 2.1674140791098275

Epoch: 5| Step: 8
Training loss: 0.8145629167556763
Validation loss: 2.156188969810804

Epoch: 5| Step: 9
Training loss: 1.3417311906814575
Validation loss: 2.1580916891495385

Epoch: 5| Step: 10
Training loss: 1.2605407238006592
Validation loss: 2.1654786268870034

Epoch: 5| Step: 11
Training loss: 1.1330019235610962
Validation loss: 2.1730032364527383

Epoch: 391| Step: 0
Training loss: 1.255977749824524
Validation loss: 2.152210235595703

Epoch: 5| Step: 1
Training loss: 2.224351644515991
Validation loss: 2.1938084413607917

Epoch: 5| Step: 2
Training loss: 1.492779016494751
Validation loss: 2.189172034462293

Epoch: 5| Step: 3
Training loss: 0.9012950658798218
Validation loss: 2.1575585355361304

Epoch: 5| Step: 4
Training loss: 1.2216384410858154
Validation loss: 2.1732590943574905

Epoch: 5| Step: 5
Training loss: 1.3878470659255981
Validation loss: 2.170314908027649

Epoch: 5| Step: 6
Training loss: 1.2610232830047607
Validation loss: 2.1371421019236245

Epoch: 5| Step: 7
Training loss: 0.9876421093940735
Validation loss: 2.1388584971427917

Epoch: 5| Step: 8
Training loss: 0.7967324256896973
Validation loss: 2.1563501010338464

Epoch: 5| Step: 9
Training loss: 1.4022390842437744
Validation loss: 2.1659202873706818

Epoch: 5| Step: 10
Training loss: 0.8884374499320984
Validation loss: 2.1491318941116333

Epoch: 5| Step: 11
Training loss: 1.1520500183105469
Validation loss: 2.136815403898557

Epoch: 392| Step: 0
Training loss: 1.0018938779830933
Validation loss: 2.1482592274745307

Epoch: 5| Step: 1
Training loss: 1.3778345584869385
Validation loss: 2.129914547006289

Epoch: 5| Step: 2
Training loss: 0.9826043844223022
Validation loss: 2.1647176891565323

Epoch: 5| Step: 3
Training loss: 0.9672904014587402
Validation loss: 2.1729205002387366

Epoch: 5| Step: 4
Training loss: 1.2772217988967896
Validation loss: 2.1271973848342896

Epoch: 5| Step: 5
Training loss: 1.131964087486267
Validation loss: 2.0631489803393683

Epoch: 5| Step: 6
Training loss: 1.7728313207626343
Validation loss: 2.149885892868042

Epoch: 5| Step: 7
Training loss: 1.5548983812332153
Validation loss: 2.1167942633231482

Epoch: 5| Step: 8
Training loss: 1.218837022781372
Validation loss: 2.110568796594938

Epoch: 5| Step: 9
Training loss: 1.4000656604766846
Validation loss: 2.2150154411792755

Epoch: 5| Step: 10
Training loss: 1.2120342254638672
Validation loss: 2.1789078215758004

Epoch: 5| Step: 11
Training loss: 1.624081015586853
Validation loss: 2.1779679656028748

Epoch: 393| Step: 0
Training loss: 0.8161287307739258
Validation loss: 2.196747342745463

Epoch: 5| Step: 1
Training loss: 1.2751011848449707
Validation loss: 2.2225201527277627

Epoch: 5| Step: 2
Training loss: 1.324518084526062
Validation loss: 2.2287137508392334

Epoch: 5| Step: 3
Training loss: 1.4449313879013062
Validation loss: 2.2260971665382385

Epoch: 5| Step: 4
Training loss: 1.126158356666565
Validation loss: 2.1866595844427743

Epoch: 5| Step: 5
Training loss: 1.8206329345703125
Validation loss: 2.215394695599874

Epoch: 5| Step: 6
Training loss: 1.4415826797485352
Validation loss: 2.200559397538503

Epoch: 5| Step: 7
Training loss: 1.203366756439209
Validation loss: 2.1971907218297324

Epoch: 5| Step: 8
Training loss: 1.6399297714233398
Validation loss: 2.2069410383701324

Epoch: 5| Step: 9
Training loss: 1.0386465787887573
Validation loss: 2.219155212243398

Epoch: 5| Step: 10
Training loss: 0.6325594186782837
Validation loss: 2.2519148687521615

Epoch: 5| Step: 11
Training loss: 2.2743663787841797
Validation loss: 2.1870291183392205

Epoch: 394| Step: 0
Training loss: 1.4940392971038818
Validation loss: 2.172022591034571

Epoch: 5| Step: 1
Training loss: 1.2193760871887207
Validation loss: 2.153963123758634

Epoch: 5| Step: 2
Training loss: 0.9795769453048706
Validation loss: 2.1585378448168435

Epoch: 5| Step: 3
Training loss: 1.4463647603988647
Validation loss: 2.151982307434082

Epoch: 5| Step: 4
Training loss: 1.1592904329299927
Validation loss: 2.198199287056923

Epoch: 5| Step: 5
Training loss: 1.260004997253418
Validation loss: 2.162483130892118

Epoch: 5| Step: 6
Training loss: 1.13002610206604
Validation loss: 2.1502551287412643

Epoch: 5| Step: 7
Training loss: 1.0147405862808228
Validation loss: 2.163918673992157

Epoch: 5| Step: 8
Training loss: 1.3638875484466553
Validation loss: 2.1457937558492026

Epoch: 5| Step: 9
Training loss: 1.323381781578064
Validation loss: 2.141650522748629

Epoch: 5| Step: 10
Training loss: 1.4091252088546753
Validation loss: 2.1517019818226495

Epoch: 5| Step: 11
Training loss: 1.7259283065795898
Validation loss: 2.1226175129413605

Epoch: 395| Step: 0
Training loss: 0.8706691861152649
Validation loss: 2.1599693497021994

Epoch: 5| Step: 1
Training loss: 1.3431272506713867
Validation loss: 2.1741010546684265

Epoch: 5| Step: 2
Training loss: 1.802554726600647
Validation loss: 2.1915832857290902

Epoch: 5| Step: 3
Training loss: 1.1702749729156494
Validation loss: 2.1846904307603836

Epoch: 5| Step: 4
Training loss: 1.842390775680542
Validation loss: 2.186704268058141

Epoch: 5| Step: 5
Training loss: 1.1160266399383545
Validation loss: 2.190918485323588

Epoch: 5| Step: 6
Training loss: 1.4240596294403076
Validation loss: 2.174972196420034

Epoch: 5| Step: 7
Training loss: 1.1353633403778076
Validation loss: 2.1686806430419288

Epoch: 5| Step: 8
Training loss: 1.0679305791854858
Validation loss: 2.204816867907842

Epoch: 5| Step: 9
Training loss: 1.2111772298812866
Validation loss: 2.170118739207586

Epoch: 5| Step: 10
Training loss: 0.7523161172866821
Validation loss: 2.1846883644660315

Epoch: 5| Step: 11
Training loss: 1.3169769048690796
Validation loss: 2.2102469007174173

Epoch: 396| Step: 0
Training loss: 1.754098892211914
Validation loss: 2.1794901341199875

Epoch: 5| Step: 1
Training loss: 1.0627939701080322
Validation loss: 2.1787241796652475

Epoch: 5| Step: 2
Training loss: 1.5696046352386475
Validation loss: 2.1449209252993264

Epoch: 5| Step: 3
Training loss: 1.7126739025115967
Validation loss: 2.175104727347692

Epoch: 5| Step: 4
Training loss: 1.180875539779663
Validation loss: 2.1848058650890985

Epoch: 5| Step: 5
Training loss: 1.105857014656067
Validation loss: 2.1980395913124084

Epoch: 5| Step: 6
Training loss: 0.9080179333686829
Validation loss: 2.1804803560177484

Epoch: 5| Step: 7
Training loss: 0.7374648451805115
Validation loss: 2.2230817675590515

Epoch: 5| Step: 8
Training loss: 1.1146239042282104
Validation loss: 2.1573940316836038

Epoch: 5| Step: 9
Training loss: 0.8659098744392395
Validation loss: 2.1801209847132363

Epoch: 5| Step: 10
Training loss: 1.427140474319458
Validation loss: 2.147704690694809

Epoch: 5| Step: 11
Training loss: 1.002213478088379
Validation loss: 2.170519232749939

Epoch: 397| Step: 0
Training loss: 0.8464847803115845
Validation loss: 2.1467919001976647

Epoch: 5| Step: 1
Training loss: 1.308371663093567
Validation loss: 2.155140444636345

Epoch: 5| Step: 2
Training loss: 1.3057544231414795
Validation loss: 2.1748484720786414

Epoch: 5| Step: 3
Training loss: 1.299125075340271
Validation loss: 2.2072385350863137

Epoch: 5| Step: 4
Training loss: 1.0437679290771484
Validation loss: 2.2330590933561325

Epoch: 5| Step: 5
Training loss: 1.1136308908462524
Validation loss: 2.1874331633249917

Epoch: 5| Step: 6
Training loss: 0.814160168170929
Validation loss: 2.2043852508068085

Epoch: 5| Step: 7
Training loss: 2.134553909301758
Validation loss: 2.202417254447937

Epoch: 5| Step: 8
Training loss: 1.085052490234375
Validation loss: 2.205606609582901

Epoch: 5| Step: 9
Training loss: 1.0834417343139648
Validation loss: 2.171111305554708

Epoch: 5| Step: 10
Training loss: 1.1433112621307373
Validation loss: 2.1433972318967185

Epoch: 5| Step: 11
Training loss: 0.9134693145751953
Validation loss: 2.1812329639991126

Epoch: 398| Step: 0
Training loss: 1.3025786876678467
Validation loss: 2.1697577834129333

Epoch: 5| Step: 1
Training loss: 1.5467250347137451
Validation loss: 2.177292058865229

Epoch: 5| Step: 2
Training loss: 1.510077714920044
Validation loss: 2.1820776661237082

Epoch: 5| Step: 3
Training loss: 1.0724060535430908
Validation loss: 2.163840964436531

Epoch: 5| Step: 4
Training loss: 1.2299103736877441
Validation loss: 2.1765024264653525

Epoch: 5| Step: 5
Training loss: 0.9354073405265808
Validation loss: 2.181147595246633

Epoch: 5| Step: 6
Training loss: 0.9871708750724792
Validation loss: 2.1916517863670983

Epoch: 5| Step: 7
Training loss: 1.34146249294281
Validation loss: 2.1645978689193726

Epoch: 5| Step: 8
Training loss: 1.347327470779419
Validation loss: 2.2033108174800873

Epoch: 5| Step: 9
Training loss: 0.6240980625152588
Validation loss: 2.20415789882342

Epoch: 5| Step: 10
Training loss: 1.386979341506958
Validation loss: 2.168604036172231

Epoch: 5| Step: 11
Training loss: 1.7021281719207764
Validation loss: 2.1478002220392227

Epoch: 399| Step: 0
Training loss: 1.5684232711791992
Validation loss: 2.193219860394796

Epoch: 5| Step: 1
Training loss: 0.9280300140380859
Validation loss: 2.1664255062739053

Epoch: 5| Step: 2
Training loss: 1.042691946029663
Validation loss: 2.179227958122889

Epoch: 5| Step: 3
Training loss: 1.4148664474487305
Validation loss: 2.1264495352904

Epoch: 5| Step: 4
Training loss: 1.5935027599334717
Validation loss: 2.1913707753022513

Epoch: 5| Step: 5
Training loss: 0.7820594906806946
Validation loss: 2.1715950667858124

Epoch: 5| Step: 6
Training loss: 0.9572919607162476
Validation loss: 2.16512364645799

Epoch: 5| Step: 7
Training loss: 1.0781208276748657
Validation loss: 2.2067901343107224

Epoch: 5| Step: 8
Training loss: 1.3343865871429443
Validation loss: 2.1573408047358194

Epoch: 5| Step: 9
Training loss: 1.461820363998413
Validation loss: 2.148550515373548

Epoch: 5| Step: 10
Training loss: 0.7834472060203552
Validation loss: 2.1651554902394614

Epoch: 5| Step: 11
Training loss: 0.6920615434646606
Validation loss: 2.1677932888269424

Epoch: 400| Step: 0
Training loss: 1.1920301914215088
Validation loss: 2.168737734357516

Epoch: 5| Step: 1
Training loss: 1.6499087810516357
Validation loss: 2.1922365874052048

Epoch: 5| Step: 2
Training loss: 1.0271154642105103
Validation loss: 2.182095378637314

Epoch: 5| Step: 3
Training loss: 1.4286868572235107
Validation loss: 2.1491293609142303

Epoch: 5| Step: 4
Training loss: 1.1897584199905396
Validation loss: 2.171834339698156

Epoch: 5| Step: 5
Training loss: 0.86884605884552
Validation loss: 2.1780137767394385

Epoch: 5| Step: 6
Training loss: 1.823512315750122
Validation loss: 2.1553700864315033

Epoch: 5| Step: 7
Training loss: 0.9892009496688843
Validation loss: 2.1238714257876077

Epoch: 5| Step: 8
Training loss: 1.1521401405334473
Validation loss: 2.167161469658216

Epoch: 5| Step: 9
Training loss: 1.2202798128128052
Validation loss: 2.12060676018397

Epoch: 5| Step: 10
Training loss: 0.8799623250961304
Validation loss: 2.116359685858091

Epoch: 5| Step: 11
Training loss: 1.174747109413147
Validation loss: 2.1595165679852166

Testing loss: 1.888080981995562
