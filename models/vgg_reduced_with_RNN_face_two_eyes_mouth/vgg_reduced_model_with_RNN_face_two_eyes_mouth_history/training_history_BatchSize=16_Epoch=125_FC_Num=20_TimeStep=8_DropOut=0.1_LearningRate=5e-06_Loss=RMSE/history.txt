Epoch: 1| Step: 0
Training loss: 7.083142925021989
Validation loss: 5.917010480893697

Epoch: 6| Step: 1
Training loss: 6.23285765575348
Validation loss: 5.914838893627893

Epoch: 6| Step: 2
Training loss: 5.768453426321532
Validation loss: 5.912718203109078

Epoch: 6| Step: 3
Training loss: 5.55863938678121
Validation loss: 5.910526187578076

Epoch: 6| Step: 4
Training loss: 5.3179458530247485
Validation loss: 5.908351840414843

Epoch: 6| Step: 5
Training loss: 6.884054152067916
Validation loss: 5.906098244414547

Epoch: 6| Step: 6
Training loss: 5.747046997749012
Validation loss: 5.903864787623611

Epoch: 6| Step: 7
Training loss: 6.5446488048264
Validation loss: 5.90169008692946

Epoch: 6| Step: 8
Training loss: 6.13181066409129
Validation loss: 5.899261888573553

Epoch: 6| Step: 9
Training loss: 5.097350550579982
Validation loss: 5.896918512590494

Epoch: 6| Step: 10
Training loss: 6.318740026690633
Validation loss: 5.894377898354847

Epoch: 6| Step: 11
Training loss: 5.490651942943107
Validation loss: 5.891837456515015

Epoch: 6| Step: 12
Training loss: 6.024693854060657
Validation loss: 5.889371703206779

Epoch: 6| Step: 13
Training loss: 5.7020225818070465
Validation loss: 5.886721153064719

Epoch: 2| Step: 0
Training loss: 5.759779533299586
Validation loss: 5.883826422988232

Epoch: 6| Step: 1
Training loss: 5.0729890644565465
Validation loss: 5.880936916772983

Epoch: 6| Step: 2
Training loss: 5.595501843838443
Validation loss: 5.87813216781382

Epoch: 6| Step: 3
Training loss: 6.245471381790306
Validation loss: 5.875026405221025

Epoch: 6| Step: 4
Training loss: 6.552596112084543
Validation loss: 5.871881076443492

Epoch: 6| Step: 5
Training loss: 6.52731803555677
Validation loss: 5.868511512793807

Epoch: 6| Step: 6
Training loss: 6.31414954661911
Validation loss: 5.865121503928033

Epoch: 6| Step: 7
Training loss: 6.567366185504045
Validation loss: 5.861403972707422

Epoch: 6| Step: 8
Training loss: 4.561028230084199
Validation loss: 5.857641182279512

Epoch: 6| Step: 9
Training loss: 6.780890529966881
Validation loss: 5.853593936294919

Epoch: 6| Step: 10
Training loss: 6.1714704549972765
Validation loss: 5.849538999037565

Epoch: 6| Step: 11
Training loss: 5.207876607578719
Validation loss: 5.844977890725548

Epoch: 6| Step: 12
Training loss: 5.838301622785778
Validation loss: 5.840455974693236

Epoch: 6| Step: 13
Training loss: 6.0290757445479235
Validation loss: 5.835715034735171

Epoch: 3| Step: 0
Training loss: 5.471963341662661
Validation loss: 5.8308508995016535

Epoch: 6| Step: 1
Training loss: 5.942052120138084
Validation loss: 5.825535803343482

Epoch: 6| Step: 2
Training loss: 5.458713236781725
Validation loss: 5.820193869386663

Epoch: 6| Step: 3
Training loss: 7.167839427477814
Validation loss: 5.81467648573579

Epoch: 6| Step: 4
Training loss: 5.169494818792118
Validation loss: 5.808490724041141

Epoch: 6| Step: 5
Training loss: 4.998511474290938
Validation loss: 5.802194435612823

Epoch: 6| Step: 6
Training loss: 5.959488478861881
Validation loss: 5.796054394709164

Epoch: 6| Step: 7
Training loss: 6.203428169740414
Validation loss: 5.78957151576709

Epoch: 6| Step: 8
Training loss: 5.982605196852476
Validation loss: 5.782563838647583

Epoch: 6| Step: 9
Training loss: 6.093337764001038
Validation loss: 5.775598626534946

Epoch: 6| Step: 10
Training loss: 6.222197377442909
Validation loss: 5.767955305660872

Epoch: 6| Step: 11
Training loss: 6.065223318141368
Validation loss: 5.760464034020846

Epoch: 6| Step: 12
Training loss: 6.643574138334197
Validation loss: 5.752258382489587

Epoch: 6| Step: 13
Training loss: 4.86155529112164
Validation loss: 5.744169319683867

Epoch: 4| Step: 0
Training loss: 5.6862026872928615
Validation loss: 5.735986522997457

Epoch: 6| Step: 1
Training loss: 5.575690585074487
Validation loss: 5.7272000168280774

Epoch: 6| Step: 2
Training loss: 6.067788246076057
Validation loss: 5.718762729540278

Epoch: 6| Step: 3
Training loss: 5.375755789205438
Validation loss: 5.709767108182916

Epoch: 6| Step: 4
Training loss: 5.624095250588784
Validation loss: 5.700849244503945

Epoch: 6| Step: 5
Training loss: 6.082655289718065
Validation loss: 5.691572610609479

Epoch: 6| Step: 6
Training loss: 5.7810718405825545
Validation loss: 5.6818879214544

Epoch: 6| Step: 7
Training loss: 5.399733480304857
Validation loss: 5.672316689015468

Epoch: 6| Step: 8
Training loss: 5.50613563929774
Validation loss: 5.662928142740406

Epoch: 6| Step: 9
Training loss: 6.227973270817057
Validation loss: 5.652991323892128

Epoch: 6| Step: 10
Training loss: 6.216175255601278
Validation loss: 5.643242141668815

Epoch: 6| Step: 11
Training loss: 5.765493334582331
Validation loss: 5.6331191065457045

Epoch: 6| Step: 12
Training loss: 5.814754254043081
Validation loss: 5.623235355074621

Epoch: 6| Step: 13
Training loss: 5.868741536972233
Validation loss: 5.613285695611569

Epoch: 5| Step: 0
Training loss: 5.377398288532813
Validation loss: 5.603115176950905

Epoch: 6| Step: 1
Training loss: 4.920498319371474
Validation loss: 5.593389403585415

Epoch: 6| Step: 2
Training loss: 4.822579269746458
Validation loss: 5.58399738329377

Epoch: 6| Step: 3
Training loss: 6.0445776229722386
Validation loss: 5.574693751797543

Epoch: 6| Step: 4
Training loss: 5.62780234149586
Validation loss: 5.565634626479822

Epoch: 6| Step: 5
Training loss: 5.004080061384129
Validation loss: 5.5563686454014425

Epoch: 6| Step: 6
Training loss: 6.184419115399754
Validation loss: 5.547675075945839

Epoch: 6| Step: 7
Training loss: 5.8033141697467325
Validation loss: 5.539177366571301

Epoch: 6| Step: 8
Training loss: 3.8297545409667153
Validation loss: 5.530492209844457

Epoch: 6| Step: 9
Training loss: 6.171575225116951
Validation loss: 5.5223203659717415

Epoch: 6| Step: 10
Training loss: 6.3974298561725895
Validation loss: 5.51415532085252

Epoch: 6| Step: 11
Training loss: 5.607875612955485
Validation loss: 5.505920749018667

Epoch: 6| Step: 12
Training loss: 6.9987895463962975
Validation loss: 5.497656351768627

Epoch: 6| Step: 13
Training loss: 5.729635249540187
Validation loss: 5.489324497246983

Epoch: 6| Step: 0
Training loss: 6.507314527860318
Validation loss: 5.4811568423002655

Epoch: 6| Step: 1
Training loss: 5.29684151157832
Validation loss: 5.472472052295853

Epoch: 6| Step: 2
Training loss: 6.76112127722118
Validation loss: 5.464305619418151

Epoch: 6| Step: 3
Training loss: 5.292456480341948
Validation loss: 5.456423340352979

Epoch: 6| Step: 4
Training loss: 6.640349833453395
Validation loss: 5.447905453536078

Epoch: 6| Step: 5
Training loss: 5.486975072549296
Validation loss: 5.439726596534794

Epoch: 6| Step: 6
Training loss: 5.099134162258522
Validation loss: 5.431569691194501

Epoch: 6| Step: 7
Training loss: 4.087588733328248
Validation loss: 5.423774203383989

Epoch: 6| Step: 8
Training loss: 5.724171221184216
Validation loss: 5.415900406068727

Epoch: 6| Step: 9
Training loss: 5.821196582394285
Validation loss: 5.408326589916161

Epoch: 6| Step: 10
Training loss: 5.6696218003181285
Validation loss: 5.400736030997411

Epoch: 6| Step: 11
Training loss: 5.180228042590614
Validation loss: 5.39343910662114

Epoch: 6| Step: 12
Training loss: 4.9709149328645115
Validation loss: 5.385926193640071

Epoch: 6| Step: 13
Training loss: 4.500438880711364
Validation loss: 5.378793043442647

Epoch: 7| Step: 0
Training loss: 6.131741919892582
Validation loss: 5.371313827167375

Epoch: 6| Step: 1
Training loss: 6.120001173829608
Validation loss: 5.364475118292512

Epoch: 6| Step: 2
Training loss: 4.638759045233577
Validation loss: 5.3570670894532695

Epoch: 6| Step: 3
Training loss: 5.204751799984172
Validation loss: 5.350049416144489

Epoch: 6| Step: 4
Training loss: 5.925873304945823
Validation loss: 5.343170372533848

Epoch: 6| Step: 5
Training loss: 6.1232325280865805
Validation loss: 5.336346500298911

Epoch: 6| Step: 6
Training loss: 5.590345998575496
Validation loss: 5.329218061535848

Epoch: 6| Step: 7
Training loss: 4.925901285958124
Validation loss: 5.322078701084867

Epoch: 6| Step: 8
Training loss: 5.484686948593535
Validation loss: 5.31531201905821

Epoch: 6| Step: 9
Training loss: 5.579592215291403
Validation loss: 5.308661027472186

Epoch: 6| Step: 10
Training loss: 6.130194504905106
Validation loss: 5.302081404749951

Epoch: 6| Step: 11
Training loss: 4.586911463599701
Validation loss: 5.295485202602828

Epoch: 6| Step: 12
Training loss: 4.881584220512141
Validation loss: 5.289469565687685

Epoch: 6| Step: 13
Training loss: 4.523871577226879
Validation loss: 5.283207758104099

Epoch: 8| Step: 0
Training loss: 4.1420037043548925
Validation loss: 5.27746840903186

Epoch: 6| Step: 1
Training loss: 5.323577999033356
Validation loss: 5.271729715995185

Epoch: 6| Step: 2
Training loss: 5.043667272860708
Validation loss: 5.2660913157163405

Epoch: 6| Step: 3
Training loss: 5.914261163274909
Validation loss: 5.260533045120323

Epoch: 6| Step: 4
Training loss: 4.544480994610493
Validation loss: 5.254672771444181

Epoch: 6| Step: 5
Training loss: 4.935313646114344
Validation loss: 5.248642094917073

Epoch: 6| Step: 6
Training loss: 5.972775045826427
Validation loss: 5.242691917805547

Epoch: 6| Step: 7
Training loss: 6.209626065358689
Validation loss: 5.236904766579241

Epoch: 6| Step: 8
Training loss: 5.906591980736802
Validation loss: 5.2310832590672325

Epoch: 6| Step: 9
Training loss: 5.8065187587068765
Validation loss: 5.22509367887731

Epoch: 6| Step: 10
Training loss: 5.5502618470153795
Validation loss: 5.21918883163291

Epoch: 6| Step: 11
Training loss: 5.056122707278245
Validation loss: 5.213204366905077

Epoch: 6| Step: 12
Training loss: 4.772659463111744
Validation loss: 5.207258383129522

Epoch: 6| Step: 13
Training loss: 5.436539137557041
Validation loss: 5.201636787939057

Epoch: 9| Step: 0
Training loss: 5.738682430985459
Validation loss: 5.195509644403318

Epoch: 6| Step: 1
Training loss: 5.840074658373886
Validation loss: 5.189568348539697

Epoch: 6| Step: 2
Training loss: 4.579557956202623
Validation loss: 5.18362521037693

Epoch: 6| Step: 3
Training loss: 4.8153064025804655
Validation loss: 5.1780021154095595

Epoch: 6| Step: 4
Training loss: 5.4929882784374096
Validation loss: 5.172229796933424

Epoch: 6| Step: 5
Training loss: 6.084462448612385
Validation loss: 5.1667012039178735

Epoch: 6| Step: 6
Training loss: 5.148571979346668
Validation loss: 5.160634929469869

Epoch: 6| Step: 7
Training loss: 4.527648336254386
Validation loss: 5.1548751385253375

Epoch: 6| Step: 8
Training loss: 4.7376580768069765
Validation loss: 5.149333870037439

Epoch: 6| Step: 9
Training loss: 5.086043255668905
Validation loss: 5.143402987733913

Epoch: 6| Step: 10
Training loss: 5.852179175198997
Validation loss: 5.137636005615451

Epoch: 6| Step: 11
Training loss: 5.435306150346827
Validation loss: 5.132026755441847

Epoch: 6| Step: 12
Training loss: 5.768417715832994
Validation loss: 5.126610386609393

Epoch: 6| Step: 13
Training loss: 4.449479173334833
Validation loss: 5.120450520413488

Epoch: 10| Step: 0
Training loss: 5.694109419398096
Validation loss: 5.114441485746084

Epoch: 6| Step: 1
Training loss: 5.728222282486786
Validation loss: 5.108608612227164

Epoch: 6| Step: 2
Training loss: 4.8860739107916435
Validation loss: 5.1027260544385005

Epoch: 6| Step: 3
Training loss: 5.039167914655626
Validation loss: 5.0969141394388835

Epoch: 6| Step: 4
Training loss: 5.826265831144014
Validation loss: 5.091056002111361

Epoch: 6| Step: 5
Training loss: 5.1288688757087435
Validation loss: 5.0846880165599835

Epoch: 6| Step: 6
Training loss: 4.663338200800884
Validation loss: 5.078903435928949

Epoch: 6| Step: 7
Training loss: 4.53399154335179
Validation loss: 5.072742916110816

Epoch: 6| Step: 8
Training loss: 5.436971178319053
Validation loss: 5.066685080913075

Epoch: 6| Step: 9
Training loss: 5.618185705378311
Validation loss: 5.06059040741359

Epoch: 6| Step: 10
Training loss: 4.8879670059039535
Validation loss: 5.054247688132544

Epoch: 6| Step: 11
Training loss: 5.059045814139317
Validation loss: 5.04805807098483

Epoch: 6| Step: 12
Training loss: 4.724047384155258
Validation loss: 5.041869272411884

Epoch: 6| Step: 13
Training loss: 5.350674431617844
Validation loss: 5.035967492923551

Epoch: 11| Step: 0
Training loss: 5.021505266025193
Validation loss: 5.02971099629977

Epoch: 6| Step: 1
Training loss: 4.576014947093213
Validation loss: 5.0234775254873325

Epoch: 6| Step: 2
Training loss: 5.5912302831399785
Validation loss: 5.017793750992805

Epoch: 6| Step: 3
Training loss: 5.356921999783792
Validation loss: 5.011495377599193

Epoch: 6| Step: 4
Training loss: 4.781042555753073
Validation loss: 5.005203464067719

Epoch: 6| Step: 5
Training loss: 5.146771220658903
Validation loss: 4.999714557129336

Epoch: 6| Step: 6
Training loss: 4.071431597371519
Validation loss: 4.9934406488665966

Epoch: 6| Step: 7
Training loss: 5.228847032887361
Validation loss: 4.987614932922971

Epoch: 6| Step: 8
Training loss: 5.9381495070325645
Validation loss: 4.981821233079343

Epoch: 6| Step: 9
Training loss: 5.157969425082693
Validation loss: 4.975531007552735

Epoch: 6| Step: 10
Training loss: 5.925006773095746
Validation loss: 4.969701967673879

Epoch: 6| Step: 11
Training loss: 5.249666839201076
Validation loss: 4.962997817686258

Epoch: 6| Step: 12
Training loss: 4.064127904005629
Validation loss: 4.956729672323742

Epoch: 6| Step: 13
Training loss: 5.089279178624749
Validation loss: 4.951355819746279

Epoch: 12| Step: 0
Training loss: 5.809986186183456
Validation loss: 4.94501625045508

Epoch: 6| Step: 1
Training loss: 5.484071554717421
Validation loss: 4.939183266134845

Epoch: 6| Step: 2
Training loss: 5.417059879213571
Validation loss: 4.933115722822804

Epoch: 6| Step: 3
Training loss: 4.607469481658458
Validation loss: 4.92718195530888

Epoch: 6| Step: 4
Training loss: 5.03455163893252
Validation loss: 4.921788581210571

Epoch: 6| Step: 5
Training loss: 5.603621483511244
Validation loss: 4.916019343204378

Epoch: 6| Step: 6
Training loss: 5.372719924280962
Validation loss: 4.910053924813455

Epoch: 6| Step: 7
Training loss: 5.544899516179824
Validation loss: 4.904836819650237

Epoch: 6| Step: 8
Training loss: 3.991322044728274
Validation loss: 4.898285899435043

Epoch: 6| Step: 9
Training loss: 5.31861399959698
Validation loss: 4.892990141656413

Epoch: 6| Step: 10
Training loss: 4.227145057905651
Validation loss: 4.887070799419132

Epoch: 6| Step: 11
Training loss: 3.908148464447841
Validation loss: 4.881218896848971

Epoch: 6| Step: 12
Training loss: 5.160843346453258
Validation loss: 4.875537076529837

Epoch: 6| Step: 13
Training loss: 4.4828143976419605
Validation loss: 4.869734634908633

Epoch: 13| Step: 0
Training loss: 4.7645934942837975
Validation loss: 4.864619786563626

Epoch: 6| Step: 1
Training loss: 4.77494685757609
Validation loss: 4.858989540831526

Epoch: 6| Step: 2
Training loss: 4.6889202763700615
Validation loss: 4.8541943899953806

Epoch: 6| Step: 3
Training loss: 5.245785247525787
Validation loss: 4.848856311985478

Epoch: 6| Step: 4
Training loss: 4.6495310803314105
Validation loss: 4.8433849894496515

Epoch: 6| Step: 5
Training loss: 4.285778017932583
Validation loss: 4.838321359120022

Epoch: 6| Step: 6
Training loss: 4.726825397841008
Validation loss: 4.832661461445857

Epoch: 6| Step: 7
Training loss: 5.501364452000997
Validation loss: 4.827660926152918

Epoch: 6| Step: 8
Training loss: 5.759780526748271
Validation loss: 4.822311934697729

Epoch: 6| Step: 9
Training loss: 5.437981069045736
Validation loss: 4.8167191213283695

Epoch: 6| Step: 10
Training loss: 4.506425297008653
Validation loss: 4.8116033304977

Epoch: 6| Step: 11
Training loss: 5.798143931723195
Validation loss: 4.806614732730699

Epoch: 6| Step: 12
Training loss: 4.112302252470485
Validation loss: 4.800954833693523

Epoch: 6| Step: 13
Training loss: 4.764673957357615
Validation loss: 4.795981490660757

Epoch: 14| Step: 0
Training loss: 3.7949633397277935
Validation loss: 4.790574997095381

Epoch: 6| Step: 1
Training loss: 5.174290764163662
Validation loss: 4.7854973039599225

Epoch: 6| Step: 2
Training loss: 5.34953307493963
Validation loss: 4.780581425482228

Epoch: 6| Step: 3
Training loss: 4.84839019014694
Validation loss: 4.775465980148465

Epoch: 6| Step: 4
Training loss: 5.65413175088123
Validation loss: 4.770057359693107

Epoch: 6| Step: 5
Training loss: 5.35044218713747
Validation loss: 4.764846955036804

Epoch: 6| Step: 6
Training loss: 4.517735394001066
Validation loss: 4.75949679891155

Epoch: 6| Step: 7
Training loss: 4.7997143819391335
Validation loss: 4.754410603333405

Epoch: 6| Step: 8
Training loss: 4.7402464462145435
Validation loss: 4.749419160097023

Epoch: 6| Step: 9
Training loss: 4.5420206381137
Validation loss: 4.744045222582032

Epoch: 6| Step: 10
Training loss: 5.242778170604493
Validation loss: 4.739318784380096

Epoch: 6| Step: 11
Training loss: 5.0584470749729835
Validation loss: 4.733879676146021

Epoch: 6| Step: 12
Training loss: 5.040503480679794
Validation loss: 4.72878757363394

Epoch: 6| Step: 13
Training loss: 3.88889136238625
Validation loss: 4.723955159324693

Epoch: 15| Step: 0
Training loss: 4.6728065608138705
Validation loss: 4.718478213939959

Epoch: 6| Step: 1
Training loss: 4.9756761177732916
Validation loss: 4.713877994347679

Epoch: 6| Step: 2
Training loss: 4.2485205375298
Validation loss: 4.709077804357956

Epoch: 6| Step: 3
Training loss: 4.92849528409847
Validation loss: 4.704070983580373

Epoch: 6| Step: 4
Training loss: 5.215229605926214
Validation loss: 4.699096542803007

Epoch: 6| Step: 5
Training loss: 3.9572626104624473
Validation loss: 4.694614284435133

Epoch: 6| Step: 6
Training loss: 4.913034595394874
Validation loss: 4.689408316524609

Epoch: 6| Step: 7
Training loss: 4.223651666323526
Validation loss: 4.684818348465574

Epoch: 6| Step: 8
Training loss: 4.664542168723403
Validation loss: 4.67998400530568

Epoch: 6| Step: 9
Training loss: 4.859909567913871
Validation loss: 4.674946195459395

Epoch: 6| Step: 10
Training loss: 5.3214459661270785
Validation loss: 4.669937463487331

Epoch: 6| Step: 11
Training loss: 5.287157355134157
Validation loss: 4.6645144143010135

Epoch: 6| Step: 12
Training loss: 5.129551053098863
Validation loss: 4.659335213040815

Epoch: 6| Step: 13
Training loss: 4.7577657963507205
Validation loss: 4.654229666688485

Epoch: 16| Step: 0
Training loss: 3.9846847114616057
Validation loss: 4.6495309094047945

Epoch: 6| Step: 1
Training loss: 5.280417653240259
Validation loss: 4.644091971167649

Epoch: 6| Step: 2
Training loss: 5.024829630074963
Validation loss: 4.639057995168833

Epoch: 6| Step: 3
Training loss: 4.626617148919476
Validation loss: 4.634487696225073

Epoch: 6| Step: 4
Training loss: 5.250753439472178
Validation loss: 4.62915220398565

Epoch: 6| Step: 5
Training loss: 3.2229678471518164
Validation loss: 4.6243025451447695

Epoch: 6| Step: 6
Training loss: 4.636878765272809
Validation loss: 4.619269334694853

Epoch: 6| Step: 7
Training loss: 4.179906536316781
Validation loss: 4.614569458032878

Epoch: 6| Step: 8
Training loss: 5.45118377148469
Validation loss: 4.60915868219238

Epoch: 6| Step: 9
Training loss: 4.866685869013558
Validation loss: 4.604133651868192

Epoch: 6| Step: 10
Training loss: 4.917608440310879
Validation loss: 4.599184865185748

Epoch: 6| Step: 11
Training loss: 4.761893390460288
Validation loss: 4.594673876945106

Epoch: 6| Step: 12
Training loss: 5.1971577285869
Validation loss: 4.589417419112876

Epoch: 6| Step: 13
Training loss: 4.525081250214732
Validation loss: 4.5845093287693635

Epoch: 17| Step: 0
Training loss: 5.4985212592303405
Validation loss: 4.57991921393874

Epoch: 6| Step: 1
Training loss: 4.547799032906046
Validation loss: 4.574706275557961

Epoch: 6| Step: 2
Training loss: 3.99756428946591
Validation loss: 4.569002090784247

Epoch: 6| Step: 3
Training loss: 4.707137819722026
Validation loss: 4.564341691604398

Epoch: 6| Step: 4
Training loss: 4.697588630721239
Validation loss: 4.55939886876936

Epoch: 6| Step: 5
Training loss: 3.723694407396081
Validation loss: 4.5544380307240955

Epoch: 6| Step: 6
Training loss: 4.412983180059193
Validation loss: 4.549549937084461

Epoch: 6| Step: 7
Training loss: 5.3286225654313535
Validation loss: 4.545036407369648

Epoch: 6| Step: 8
Training loss: 3.5715180413074727
Validation loss: 4.539719342030599

Epoch: 6| Step: 9
Training loss: 4.343404413101773
Validation loss: 4.534762369510094

Epoch: 6| Step: 10
Training loss: 5.000474144388827
Validation loss: 4.530134655717409

Epoch: 6| Step: 11
Training loss: 4.920659184530335
Validation loss: 4.525009136998627

Epoch: 6| Step: 12
Training loss: 4.7556476146387405
Validation loss: 4.520234638189204

Epoch: 6| Step: 13
Training loss: 5.439159973025081
Validation loss: 4.515198842567306

Epoch: 18| Step: 0
Training loss: 5.021698219022095
Validation loss: 4.51086280266728

Epoch: 6| Step: 1
Training loss: 5.051021042137444
Validation loss: 4.505705377873624

Epoch: 6| Step: 2
Training loss: 4.571464823681275
Validation loss: 4.500486559524529

Epoch: 6| Step: 3
Training loss: 4.660716532355374
Validation loss: 4.496034269936483

Epoch: 6| Step: 4
Training loss: 4.613661399120801
Validation loss: 4.491133378784412

Epoch: 6| Step: 5
Training loss: 4.708495055715495
Validation loss: 4.486207310787108

Epoch: 6| Step: 6
Training loss: 4.352501266277727
Validation loss: 4.481780432499283

Epoch: 6| Step: 7
Training loss: 4.815048335734946
Validation loss: 4.476513394657318

Epoch: 6| Step: 8
Training loss: 4.795920808305339
Validation loss: 4.471842871478787

Epoch: 6| Step: 9
Training loss: 4.875631829423135
Validation loss: 4.467352197241129

Epoch: 6| Step: 10
Training loss: 4.790076392725332
Validation loss: 4.462317650183241

Epoch: 6| Step: 11
Training loss: 4.20643434389821
Validation loss: 4.457561331009855

Epoch: 6| Step: 12
Training loss: 4.531675542383363
Validation loss: 4.45294712001386

Epoch: 6| Step: 13
Training loss: 3.257786446519773
Validation loss: 4.447821098688654

Epoch: 19| Step: 0
Training loss: 4.21574871540576
Validation loss: 4.443519020426464

Epoch: 6| Step: 1
Training loss: 3.7522535546363667
Validation loss: 4.439496374807658

Epoch: 6| Step: 2
Training loss: 4.506789701313479
Validation loss: 4.434823979952808

Epoch: 6| Step: 3
Training loss: 4.778426190420838
Validation loss: 4.430527918512505

Epoch: 6| Step: 4
Training loss: 4.898911156637757
Validation loss: 4.42615613615033

Epoch: 6| Step: 5
Training loss: 4.237278467199642
Validation loss: 4.421424438383071

Epoch: 6| Step: 6
Training loss: 4.425154585212515
Validation loss: 4.4173105898082685

Epoch: 6| Step: 7
Training loss: 4.9469895735754745
Validation loss: 4.412932646868374

Epoch: 6| Step: 8
Training loss: 4.244241515784831
Validation loss: 4.408762402677022

Epoch: 6| Step: 9
Training loss: 5.373547379905736
Validation loss: 4.404324500877651

Epoch: 6| Step: 10
Training loss: 3.9154828629569893
Validation loss: 4.399468309616301

Epoch: 6| Step: 11
Training loss: 4.548640691581748
Validation loss: 4.395216200960544

Epoch: 6| Step: 12
Training loss: 4.014973272137258
Validation loss: 4.390613433714052

Epoch: 6| Step: 13
Training loss: 5.3929618745881855
Validation loss: 4.386750399757588

Epoch: 20| Step: 0
Training loss: 4.099691956275805
Validation loss: 4.381808151702261

Epoch: 6| Step: 1
Training loss: 5.409355197916528
Validation loss: 4.3777419262809545

Epoch: 6| Step: 2
Training loss: 4.6931391047978135
Validation loss: 4.372759054371635

Epoch: 6| Step: 3
Training loss: 4.245810744076062
Validation loss: 4.368180509531038

Epoch: 6| Step: 4
Training loss: 4.912901239291925
Validation loss: 4.363774949309069

Epoch: 6| Step: 5
Training loss: 4.084177721391677
Validation loss: 4.359229683590399

Epoch: 6| Step: 6
Training loss: 5.331960421919687
Validation loss: 4.354773952108234

Epoch: 6| Step: 7
Training loss: 4.8994910462421535
Validation loss: 4.349790293290172

Epoch: 6| Step: 8
Training loss: 4.317042515322448
Validation loss: 4.3451262564801745

Epoch: 6| Step: 9
Training loss: 3.7268075282635897
Validation loss: 4.340662620606604

Epoch: 6| Step: 10
Training loss: 3.958993890089392
Validation loss: 4.336517038649731

Epoch: 6| Step: 11
Training loss: 4.507818846805541
Validation loss: 4.3318436274990635

Epoch: 6| Step: 12
Training loss: 4.240141260924883
Validation loss: 4.327370441274333

Epoch: 6| Step: 13
Training loss: 3.9570977675184142
Validation loss: 4.32325457742135

Epoch: 21| Step: 0
Training loss: 4.790073406318012
Validation loss: 4.319132730590012

Epoch: 6| Step: 1
Training loss: 4.578305393870205
Validation loss: 4.314335823910921

Epoch: 6| Step: 2
Training loss: 4.7280523300889525
Validation loss: 4.310511033635542

Epoch: 6| Step: 3
Training loss: 4.191545041533621
Validation loss: 4.305843560352045

Epoch: 6| Step: 4
Training loss: 4.703222128033091
Validation loss: 4.301501230879022

Epoch: 6| Step: 5
Training loss: 4.795979866730059
Validation loss: 4.297160912451525

Epoch: 6| Step: 6
Training loss: 4.455622243871009
Validation loss: 4.292524245913323

Epoch: 6| Step: 7
Training loss: 4.423001526665214
Validation loss: 4.287929846270395

Epoch: 6| Step: 8
Training loss: 4.870695316566341
Validation loss: 4.28340684899401

Epoch: 6| Step: 9
Training loss: 4.178585984014887
Validation loss: 4.27895618628049

Epoch: 6| Step: 10
Training loss: 4.044875899439947
Validation loss: 4.274604744885301

Epoch: 6| Step: 11
Training loss: 4.216434549770694
Validation loss: 4.270101134020503

Epoch: 6| Step: 12
Training loss: 3.6605091555871305
Validation loss: 4.2659480679381385

Epoch: 6| Step: 13
Training loss: 4.096474709003329
Validation loss: 4.261379024439299

Epoch: 22| Step: 0
Training loss: 4.417610187635105
Validation loss: 4.257351108948391

Epoch: 6| Step: 1
Training loss: 4.26272652211513
Validation loss: 4.253210313825641

Epoch: 6| Step: 2
Training loss: 4.868361623843559
Validation loss: 4.248879827341644

Epoch: 6| Step: 3
Training loss: 4.539125740805681
Validation loss: 4.244436025250547

Epoch: 6| Step: 4
Training loss: 3.748163154869657
Validation loss: 4.239828016763773

Epoch: 6| Step: 5
Training loss: 4.806524951942667
Validation loss: 4.235652529104622

Epoch: 6| Step: 6
Training loss: 4.285339407192722
Validation loss: 4.231408951373698

Epoch: 6| Step: 7
Training loss: 4.66736316024679
Validation loss: 4.226931816131735

Epoch: 6| Step: 8
Training loss: 4.386710271377047
Validation loss: 4.222394654589988

Epoch: 6| Step: 9
Training loss: 4.108765531533192
Validation loss: 4.218213836130863

Epoch: 6| Step: 10
Training loss: 4.029486455261966
Validation loss: 4.2140681154418544

Epoch: 6| Step: 11
Training loss: 4.741467894201969
Validation loss: 4.2094830116587385

Epoch: 6| Step: 12
Training loss: 4.472535564010407
Validation loss: 4.205176664580749

Epoch: 6| Step: 13
Training loss: 3.4871645311463517
Validation loss: 4.200847665835066

Epoch: 23| Step: 0
Training loss: 4.739719307873794
Validation loss: 4.196385763118113

Epoch: 6| Step: 1
Training loss: 4.879394506818835
Validation loss: 4.192227499106693

Epoch: 6| Step: 2
Training loss: 4.875727085765585
Validation loss: 4.1876953800606405

Epoch: 6| Step: 3
Training loss: 3.1426633985672625
Validation loss: 4.183206492219703

Epoch: 6| Step: 4
Training loss: 3.774092781240431
Validation loss: 4.178509241323738

Epoch: 6| Step: 5
Training loss: 3.9575763714783805
Validation loss: 4.174646797391998

Epoch: 6| Step: 6
Training loss: 3.7679399521288977
Validation loss: 4.170348975340195

Epoch: 6| Step: 7
Training loss: 3.9640936982968697
Validation loss: 4.16597916971201

Epoch: 6| Step: 8
Training loss: 4.3588707198110805
Validation loss: 4.161707571855001

Epoch: 6| Step: 9
Training loss: 4.762694211188872
Validation loss: 4.157478055485081

Epoch: 6| Step: 10
Training loss: 2.7552600319716682
Validation loss: 4.153283516160038

Epoch: 6| Step: 11
Training loss: 4.681235030472457
Validation loss: 4.149166888372156

Epoch: 6| Step: 12
Training loss: 4.7869671318371365
Validation loss: 4.145140636345233

Epoch: 6| Step: 13
Training loss: 5.005387646033077
Validation loss: 4.1407120989389785

Epoch: 24| Step: 0
Training loss: 4.305568487223138
Validation loss: 4.136333655376689

Epoch: 6| Step: 1
Training loss: 4.612087473215974
Validation loss: 4.131927049245824

Epoch: 6| Step: 2
Training loss: 3.895529845685371
Validation loss: 4.127625063613637

Epoch: 6| Step: 3
Training loss: 3.850079295345011
Validation loss: 4.123185326971094

Epoch: 6| Step: 4
Training loss: 5.204961595787528
Validation loss: 4.11857978110168

Epoch: 6| Step: 5
Training loss: 3.4010765615233876
Validation loss: 4.114225978865491

Epoch: 6| Step: 6
Training loss: 3.349811229796174
Validation loss: 4.109860022946438

Epoch: 6| Step: 7
Training loss: 3.7673863767058933
Validation loss: 4.1053478587336425

Epoch: 6| Step: 8
Training loss: 4.3175231869356026
Validation loss: 4.10110461388841

Epoch: 6| Step: 9
Training loss: 4.845395110310863
Validation loss: 4.096488696599515

Epoch: 6| Step: 10
Training loss: 4.632298458715729
Validation loss: 4.092467478423095

Epoch: 6| Step: 11
Training loss: 4.856973428736374
Validation loss: 4.087470385242936

Epoch: 6| Step: 12
Training loss: 3.7237822519924424
Validation loss: 4.082740889927487

Epoch: 6| Step: 13
Training loss: 4.092923612394863
Validation loss: 4.078137082292726

Epoch: 25| Step: 0
Training loss: 4.372321916795674
Validation loss: 4.073981410154397

Epoch: 6| Step: 1
Training loss: 3.8206244031274457
Validation loss: 4.069299455879988

Epoch: 6| Step: 2
Training loss: 4.185872686951574
Validation loss: 4.0650865781290735

Epoch: 6| Step: 3
Training loss: 4.547212673377377
Validation loss: 4.060363833907551

Epoch: 6| Step: 4
Training loss: 4.173603514151166
Validation loss: 4.055913486246503

Epoch: 6| Step: 5
Training loss: 4.429202852194036
Validation loss: 4.051487693385346

Epoch: 6| Step: 6
Training loss: 3.5499595639786925
Validation loss: 4.0469698704580725

Epoch: 6| Step: 7
Training loss: 4.730166134971235
Validation loss: 4.042379585128803

Epoch: 6| Step: 8
Training loss: 4.518903657403262
Validation loss: 4.038001820780983

Epoch: 6| Step: 9
Training loss: 3.674952479463967
Validation loss: 4.033704734810702

Epoch: 6| Step: 10
Training loss: 4.786666096303865
Validation loss: 4.0292630683440995

Epoch: 6| Step: 11
Training loss: 3.8880661972203208
Validation loss: 4.0246299186517165

Epoch: 6| Step: 12
Training loss: 3.8132741173456903
Validation loss: 4.019955883574826

Epoch: 6| Step: 13
Training loss: 3.740699551890289
Validation loss: 4.015427679812272

Epoch: 26| Step: 0
Training loss: 4.262705268280183
Validation loss: 4.011175973854442

Epoch: 6| Step: 1
Training loss: 3.432964870594276
Validation loss: 4.006731627461861

Epoch: 6| Step: 2
Training loss: 3.365376350476523
Validation loss: 4.002537597949845

Epoch: 6| Step: 3
Training loss: 4.093189463204635
Validation loss: 3.9983451917079442

Epoch: 6| Step: 4
Training loss: 4.90208228884436
Validation loss: 3.9943229005691094

Epoch: 6| Step: 5
Training loss: 4.377418067814598
Validation loss: 3.9896090965667557

Epoch: 6| Step: 6
Training loss: 4.658305898368358
Validation loss: 3.9847208508751795

Epoch: 6| Step: 7
Training loss: 4.273551311755714
Validation loss: 3.9803633296884

Epoch: 6| Step: 8
Training loss: 3.467247439911134
Validation loss: 3.975982723676986

Epoch: 6| Step: 9
Training loss: 3.884660308008689
Validation loss: 3.9712146305105716

Epoch: 6| Step: 10
Training loss: 4.184618741515267
Validation loss: 3.9669975156142416

Epoch: 6| Step: 11
Training loss: 3.793872038183979
Validation loss: 3.9623772827784967

Epoch: 6| Step: 12
Training loss: 4.243570288559542
Validation loss: 3.958140452186279

Epoch: 6| Step: 13
Training loss: 4.358237278732581
Validation loss: 3.9533343353934947

Epoch: 27| Step: 0
Training loss: 3.744913084195508
Validation loss: 3.9490638951580377

Epoch: 6| Step: 1
Training loss: 4.9296530648311965
Validation loss: 3.944506532034162

Epoch: 6| Step: 2
Training loss: 4.962462471692756
Validation loss: 3.939988051588398

Epoch: 6| Step: 3
Training loss: 4.1762779518523345
Validation loss: 3.935285904453506

Epoch: 6| Step: 4
Training loss: 3.650847919164756
Validation loss: 3.9306836139200603

Epoch: 6| Step: 5
Training loss: 4.145330555139958
Validation loss: 3.9260777907085678

Epoch: 6| Step: 6
Training loss: 4.28795571977612
Validation loss: 3.9214436165902105

Epoch: 6| Step: 7
Training loss: 4.341066258675054
Validation loss: 3.916770825455246

Epoch: 6| Step: 8
Training loss: 3.8602760900081834
Validation loss: 3.9121543715364

Epoch: 6| Step: 9
Training loss: 3.854765699418333
Validation loss: 3.9076866051325942

Epoch: 6| Step: 10
Training loss: 3.6716742278055983
Validation loss: 3.9031377575810655

Epoch: 6| Step: 11
Training loss: 3.128865559631251
Validation loss: 3.898728557926014

Epoch: 6| Step: 12
Training loss: 3.9407214353349316
Validation loss: 3.894512251715457

Epoch: 6| Step: 13
Training loss: 3.683904155383227
Validation loss: 3.8902085373722026

Epoch: 28| Step: 0
Training loss: 4.442143119941869
Validation loss: 3.8859136159643723

Epoch: 6| Step: 1
Training loss: 4.272528459287873
Validation loss: 3.8812210024591507

Epoch: 6| Step: 2
Training loss: 3.428709685853161
Validation loss: 3.8770196430127513

Epoch: 6| Step: 3
Training loss: 3.910667911859265
Validation loss: 3.8729151377778357

Epoch: 6| Step: 4
Training loss: 4.812541218370563
Validation loss: 3.868621786249563

Epoch: 6| Step: 5
Training loss: 4.47675039486237
Validation loss: 3.8641836708610064

Epoch: 6| Step: 6
Training loss: 4.179486250265947
Validation loss: 3.859693671080446

Epoch: 6| Step: 7
Training loss: 3.7767564539885465
Validation loss: 3.854924713369361

Epoch: 6| Step: 8
Training loss: 3.978622412617847
Validation loss: 3.8505726045794826

Epoch: 6| Step: 9
Training loss: 4.266086874748379
Validation loss: 3.8459632931480283

Epoch: 6| Step: 10
Training loss: 2.5603461168676356
Validation loss: 3.8414375358209027

Epoch: 6| Step: 11
Training loss: 3.8867145787509023
Validation loss: 3.83710732786014

Epoch: 6| Step: 12
Training loss: 3.3865185318736457
Validation loss: 3.832805258548001

Epoch: 6| Step: 13
Training loss: 4.015103436155456
Validation loss: 3.828490819773803

Epoch: 29| Step: 0
Training loss: 4.04807855685156
Validation loss: 3.8241418162508487

Epoch: 6| Step: 1
Training loss: 3.4304437520439683
Validation loss: 3.819730624642309

Epoch: 6| Step: 2
Training loss: 4.126548014235863
Validation loss: 3.8154499543882534

Epoch: 6| Step: 3
Training loss: 3.8836558479558057
Validation loss: 3.811427481457719

Epoch: 6| Step: 4
Training loss: 3.0926500927606475
Validation loss: 3.8072374429594418

Epoch: 6| Step: 5
Training loss: 4.191235143292152
Validation loss: 3.8031705512456284

Epoch: 6| Step: 6
Training loss: 3.5951079083669706
Validation loss: 3.7989632890545373

Epoch: 6| Step: 7
Training loss: 3.9963777353576213
Validation loss: 3.794608403752029

Epoch: 6| Step: 8
Training loss: 3.8756426616697506
Validation loss: 3.79039516019484

Epoch: 6| Step: 9
Training loss: 3.2034646947352234
Validation loss: 3.7862714732717624

Epoch: 6| Step: 10
Training loss: 4.6256047446296185
Validation loss: 3.7820310810532716

Epoch: 6| Step: 11
Training loss: 4.314525184012322
Validation loss: 3.777821775878303

Epoch: 6| Step: 12
Training loss: 4.178452239706329
Validation loss: 3.773340533309196

Epoch: 6| Step: 13
Training loss: 4.15773339438206
Validation loss: 3.76885944500654

Epoch: 30| Step: 0
Training loss: 4.413540915671525
Validation loss: 3.7643885185078765

Epoch: 6| Step: 1
Training loss: 2.1163955840288753
Validation loss: 3.759841910244759

Epoch: 6| Step: 2
Training loss: 4.707314485124744
Validation loss: 3.75548870223419

Epoch: 6| Step: 3
Training loss: 4.2005496165012115
Validation loss: 3.7510255047168277

Epoch: 6| Step: 4
Training loss: 3.9293611971183604
Validation loss: 3.746595999389526

Epoch: 6| Step: 5
Training loss: 4.416786959947304
Validation loss: 3.7420096995589716

Epoch: 6| Step: 6
Training loss: 3.638030212142677
Validation loss: 3.7375614930944856

Epoch: 6| Step: 7
Training loss: 3.8334125980530223
Validation loss: 3.7328006506277105

Epoch: 6| Step: 8
Training loss: 3.686241193665767
Validation loss: 3.7285092092158765

Epoch: 6| Step: 9
Training loss: 3.9461295613182132
Validation loss: 3.723804031412039

Epoch: 6| Step: 10
Training loss: 3.9371565411650415
Validation loss: 3.7193825234565847

Epoch: 6| Step: 11
Training loss: 3.4202350187696404
Validation loss: 3.7149086995669443

Epoch: 6| Step: 12
Training loss: 3.756366411839388
Validation loss: 3.7107002262754945

Epoch: 6| Step: 13
Training loss: 3.5834247370454615
Validation loss: 3.7064044665032974

Epoch: 31| Step: 0
Training loss: 3.94480919979696
Validation loss: 3.701884817204534

Epoch: 6| Step: 1
Training loss: 3.5325225967580796
Validation loss: 3.697575376996246

Epoch: 6| Step: 2
Training loss: 3.436772217435443
Validation loss: 3.693254625007372

Epoch: 6| Step: 3
Training loss: 2.9129600587222164
Validation loss: 3.6888021766922017

Epoch: 6| Step: 4
Training loss: 3.30069572744236
Validation loss: 3.6847432279045966

Epoch: 6| Step: 5
Training loss: 3.427179553566287
Validation loss: 3.6807342357968547

Epoch: 6| Step: 6
Training loss: 4.3538483620462
Validation loss: 3.6768189390115813

Epoch: 6| Step: 7
Training loss: 4.78921085395472
Validation loss: 3.6725924392952813

Epoch: 6| Step: 8
Training loss: 3.8456238931734577
Validation loss: 3.6683222472043417

Epoch: 6| Step: 9
Training loss: 3.9450530014055483
Validation loss: 3.664079840970842

Epoch: 6| Step: 10
Training loss: 3.6386742338458538
Validation loss: 3.659677295702619

Epoch: 6| Step: 11
Training loss: 4.454725760807719
Validation loss: 3.6551361995843887

Epoch: 6| Step: 12
Training loss: 3.8708067324695814
Validation loss: 3.650757427098393

Epoch: 6| Step: 13
Training loss: 3.467987526612691
Validation loss: 3.646228020512094

Epoch: 32| Step: 0
Training loss: 4.082121429177337
Validation loss: 3.64190686188113

Epoch: 6| Step: 1
Training loss: 3.8742556933860697
Validation loss: 3.637410131963281

Epoch: 6| Step: 2
Training loss: 3.0713874934545022
Validation loss: 3.633121206641534

Epoch: 6| Step: 3
Training loss: 3.5249308531993115
Validation loss: 3.628901366308216

Epoch: 6| Step: 4
Training loss: 3.1168321296982353
Validation loss: 3.624684988782287

Epoch: 6| Step: 5
Training loss: 4.187700864614633
Validation loss: 3.6205910694181522

Epoch: 6| Step: 6
Training loss: 4.197575078023564
Validation loss: 3.6162012457041675

Epoch: 6| Step: 7
Training loss: 3.8131528201649143
Validation loss: 3.611955807185621

Epoch: 6| Step: 8
Training loss: 3.954774173312789
Validation loss: 3.607506712979746

Epoch: 6| Step: 9
Training loss: 4.065320722964722
Validation loss: 3.603035163035147

Epoch: 6| Step: 10
Training loss: 4.067114219635529
Validation loss: 3.598590984817407

Epoch: 6| Step: 11
Training loss: 3.370002720319516
Validation loss: 3.5940838865999267

Epoch: 6| Step: 12
Training loss: 3.5857071812949584
Validation loss: 3.589785813731286

Epoch: 6| Step: 13
Training loss: 3.3542582023561827
Validation loss: 3.58548081536605

Epoch: 33| Step: 0
Training loss: 3.02030968347725
Validation loss: 3.581334303151575

Epoch: 6| Step: 1
Training loss: 3.9368509635669953
Validation loss: 3.5771488151859048

Epoch: 6| Step: 2
Training loss: 3.9363881312410482
Validation loss: 3.572872543433233

Epoch: 6| Step: 3
Training loss: 3.4524242674016117
Validation loss: 3.5686760622505753

Epoch: 6| Step: 4
Training loss: 4.10663284073147
Validation loss: 3.5647455577994327

Epoch: 6| Step: 5
Training loss: 3.776355949564673
Validation loss: 3.5605924529818465

Epoch: 6| Step: 6
Training loss: 3.3503649157008817
Validation loss: 3.556282842447583

Epoch: 6| Step: 7
Training loss: 3.805045673031079
Validation loss: 3.5522006883373876

Epoch: 6| Step: 8
Training loss: 3.9095630481601216
Validation loss: 3.547948778372638

Epoch: 6| Step: 9
Training loss: 3.8264462896904408
Validation loss: 3.5435942770928133

Epoch: 6| Step: 10
Training loss: 3.9310768659398834
Validation loss: 3.53945673640769

Epoch: 6| Step: 11
Training loss: 3.6219896115723316
Validation loss: 3.5350464974186617

Epoch: 6| Step: 12
Training loss: 3.644044637136577
Validation loss: 3.530817618666332

Epoch: 6| Step: 13
Training loss: 3.205920678788176
Validation loss: 3.526679307690219

Epoch: 34| Step: 0
Training loss: 2.996933323329437
Validation loss: 3.5225918834245875

Epoch: 6| Step: 1
Training loss: 3.6131883434001626
Validation loss: 3.518357363759903

Epoch: 6| Step: 2
Training loss: 2.855902893210695
Validation loss: 3.5145454161987435

Epoch: 6| Step: 3
Training loss: 3.787740260394369
Validation loss: 3.5105127308244355

Epoch: 6| Step: 4
Training loss: 3.8519987590466935
Validation loss: 3.506677434007869

Epoch: 6| Step: 5
Training loss: 4.033819281778359
Validation loss: 3.5026560423837156

Epoch: 6| Step: 6
Training loss: 3.2584808908077516
Validation loss: 3.498637479149598

Epoch: 6| Step: 7
Training loss: 3.833425161395169
Validation loss: 3.4945141397374706

Epoch: 6| Step: 8
Training loss: 3.835171065512672
Validation loss: 3.490346959765063

Epoch: 6| Step: 9
Training loss: 3.469868797438247
Validation loss: 3.4861127457397467

Epoch: 6| Step: 10
Training loss: 3.8549794482760684
Validation loss: 3.481973570363842

Epoch: 6| Step: 11
Training loss: 4.007202815925217
Validation loss: 3.477882117661987

Epoch: 6| Step: 12
Training loss: 3.8909913162530625
Validation loss: 3.4734591802714663

Epoch: 6| Step: 13
Training loss: 3.340408509450568
Validation loss: 3.4691647347536434

Epoch: 35| Step: 0
Training loss: 3.1039209119218585
Validation loss: 3.4649685360909794

Epoch: 6| Step: 1
Training loss: 3.8003431265661622
Validation loss: 3.4607827042176122

Epoch: 6| Step: 2
Training loss: 3.955070891197088
Validation loss: 3.4566549150186843

Epoch: 6| Step: 3
Training loss: 3.9098578309654455
Validation loss: 3.4520172367586497

Epoch: 6| Step: 4
Training loss: 3.4128331954436146
Validation loss: 3.447372512673187

Epoch: 6| Step: 5
Training loss: 3.1796467096585097
Validation loss: 3.442235286067534

Epoch: 6| Step: 6
Training loss: 4.021179869481669
Validation loss: 3.4371578161837237

Epoch: 6| Step: 7
Training loss: 3.6383898508525867
Validation loss: 3.4318818854463964

Epoch: 6| Step: 8
Training loss: 3.8740137137119586
Validation loss: 3.4277058802160223

Epoch: 6| Step: 9
Training loss: 2.4606824954686575
Validation loss: 3.423178298309602

Epoch: 6| Step: 10
Training loss: 4.027720244131937
Validation loss: 3.4189574927779796

Epoch: 6| Step: 11
Training loss: 3.6909650912394896
Validation loss: 3.4148867591971857

Epoch: 6| Step: 12
Training loss: 3.011768939321186
Validation loss: 3.4102438048447286

Epoch: 6| Step: 13
Training loss: 3.6060336942278077
Validation loss: 3.4066896767283974

Epoch: 36| Step: 0
Training loss: 3.9125809292451788
Validation loss: 3.4026601463970905

Epoch: 6| Step: 1
Training loss: 3.4035066528972613
Validation loss: 3.3990900341304164

Epoch: 6| Step: 2
Training loss: 3.2055229329330293
Validation loss: 3.395317451905292

Epoch: 6| Step: 3
Training loss: 3.195168191127391
Validation loss: 3.391361654627417

Epoch: 6| Step: 4
Training loss: 3.2617857052446713
Validation loss: 3.3876219780275996

Epoch: 6| Step: 5
Training loss: 2.7824290487423755
Validation loss: 3.3837288429586203

Epoch: 6| Step: 6
Training loss: 3.8646727737537314
Validation loss: 3.380156569042904

Epoch: 6| Step: 7
Training loss: 2.9131672892910747
Validation loss: 3.376353687029817

Epoch: 6| Step: 8
Training loss: 3.319871437846738
Validation loss: 3.37265074170343

Epoch: 6| Step: 9
Training loss: 3.8635046482583992
Validation loss: 3.368968377616852

Epoch: 6| Step: 10
Training loss: 3.8347156078025666
Validation loss: 3.365258959006801

Epoch: 6| Step: 11
Training loss: 3.5389082245537202
Validation loss: 3.361674339526499

Epoch: 6| Step: 12
Training loss: 4.222577654506764
Validation loss: 3.3577364215187644

Epoch: 6| Step: 13
Training loss: 3.5993619141404554
Validation loss: 3.3536215787459653

Epoch: 37| Step: 0
Training loss: 3.42264788534522
Validation loss: 3.349668891162977

Epoch: 6| Step: 1
Training loss: 2.90320862812853
Validation loss: 3.3456219338361968

Epoch: 6| Step: 2
Training loss: 3.231910245574468
Validation loss: 3.341793878532774

Epoch: 6| Step: 3
Training loss: 3.0626363918528057
Validation loss: 3.337966909145124

Epoch: 6| Step: 4
Training loss: 3.363471509844283
Validation loss: 3.334199594152188

Epoch: 6| Step: 5
Training loss: 3.924140184828461
Validation loss: 3.3306335165065604

Epoch: 6| Step: 6
Training loss: 4.2404358902483885
Validation loss: 3.3267428254740796

Epoch: 6| Step: 7
Training loss: 4.085606986512798
Validation loss: 3.322842460608946

Epoch: 6| Step: 8
Training loss: 3.309556336878503
Validation loss: 3.318927024052061

Epoch: 6| Step: 9
Training loss: 2.5469373449640185
Validation loss: 3.314965080625833

Epoch: 6| Step: 10
Training loss: 3.2905596227572613
Validation loss: 3.3109786660703286

Epoch: 6| Step: 11
Training loss: 3.2274799658924014
Validation loss: 3.3072135054996785

Epoch: 6| Step: 12
Training loss: 3.9979638639403743
Validation loss: 3.3035373114023328

Epoch: 6| Step: 13
Training loss: 3.4619015283182826
Validation loss: 3.299565355017731

Epoch: 38| Step: 0
Training loss: 3.524281605773295
Validation loss: 3.2958317894495948

Epoch: 6| Step: 1
Training loss: 3.7131217872542805
Validation loss: 3.2919548286785867

Epoch: 6| Step: 2
Training loss: 3.889439413673482
Validation loss: 3.287860013252695

Epoch: 6| Step: 3
Training loss: 3.5374784650922204
Validation loss: 3.284074155299373

Epoch: 6| Step: 4
Training loss: 3.6149030355320497
Validation loss: 3.2800722703105003

Epoch: 6| Step: 5
Training loss: 3.3854797983396416
Validation loss: 3.276072046637361

Epoch: 6| Step: 6
Training loss: 3.524286205988207
Validation loss: 3.272325373867593

Epoch: 6| Step: 7
Training loss: 3.7206739049049466
Validation loss: 3.2685363908826797

Epoch: 6| Step: 8
Training loss: 2.753790930098786
Validation loss: 3.264550112758346

Epoch: 6| Step: 9
Training loss: 2.5896947941585875
Validation loss: 3.261048244611926

Epoch: 6| Step: 10
Training loss: 3.8518013096683217
Validation loss: 3.2574318496472703

Epoch: 6| Step: 11
Training loss: 3.1232707007230607
Validation loss: 3.2536152026010514

Epoch: 6| Step: 12
Training loss: 2.5766636261257903
Validation loss: 3.2499219200340725

Epoch: 6| Step: 13
Training loss: 3.589515513293991
Validation loss: 3.246628718356736

Epoch: 39| Step: 0
Training loss: 2.8947434238194747
Validation loss: 3.2428008453050894

Epoch: 6| Step: 1
Training loss: 3.3270562833491772
Validation loss: 3.2393313409040654

Epoch: 6| Step: 2
Training loss: 3.3604362763134024
Validation loss: 3.23575814322771

Epoch: 6| Step: 3
Training loss: 3.7542505969714965
Validation loss: 3.2319736995956716

Epoch: 6| Step: 4
Training loss: 3.578793125991982
Validation loss: 3.22833676082158

Epoch: 6| Step: 5
Training loss: 3.4286701892070957
Validation loss: 3.224697161903796

Epoch: 6| Step: 6
Training loss: 3.290837694559486
Validation loss: 3.220952820299025

Epoch: 6| Step: 7
Training loss: 3.2097318664461647
Validation loss: 3.217280117070913

Epoch: 6| Step: 8
Training loss: 3.139141890270489
Validation loss: 3.2136391244182945

Epoch: 6| Step: 9
Training loss: 3.7368450854058395
Validation loss: 3.210094975604416

Epoch: 6| Step: 10
Training loss: 3.1707445958503593
Validation loss: 3.206377886724519

Epoch: 6| Step: 11
Training loss: 3.221397126182998
Validation loss: 3.2027888548094166

Epoch: 6| Step: 12
Training loss: 3.065198371280047
Validation loss: 3.199508063928801

Epoch: 6| Step: 13
Training loss: 3.745260422415759
Validation loss: 3.1960306891653643

Epoch: 40| Step: 0
Training loss: 3.7714558012090813
Validation loss: 3.19266173104174

Epoch: 6| Step: 1
Training loss: 2.893001095320293
Validation loss: 3.189130328745306

Epoch: 6| Step: 2
Training loss: 3.1112686601740536
Validation loss: 3.1855861178814306

Epoch: 6| Step: 3
Training loss: 3.8413336377111187
Validation loss: 3.1825533487184092

Epoch: 6| Step: 4
Training loss: 3.277381287497336
Validation loss: 3.1791233871400473

Epoch: 6| Step: 5
Training loss: 2.973764300766978
Validation loss: 3.1759850943733667

Epoch: 6| Step: 6
Training loss: 3.3122447653271356
Validation loss: 3.1722533903875196

Epoch: 6| Step: 7
Training loss: 3.338983007688833
Validation loss: 3.1689230300441245

Epoch: 6| Step: 8
Training loss: 3.6200714808198358
Validation loss: 3.165378199675803

Epoch: 6| Step: 9
Training loss: 3.3638854508645335
Validation loss: 3.1619393717490634

Epoch: 6| Step: 10
Training loss: 3.412298169996924
Validation loss: 3.1585824738995587

Epoch: 6| Step: 11
Training loss: 3.270852609241486
Validation loss: 3.1551846509724557

Epoch: 6| Step: 12
Training loss: 3.0106910307748427
Validation loss: 3.1516903464404282

Epoch: 6| Step: 13
Training loss: 3.0130522035874137
Validation loss: 3.1482691061140446

Epoch: 41| Step: 0
Training loss: 3.458592569830525
Validation loss: 3.1448934342524484

Epoch: 6| Step: 1
Training loss: 3.256137627769527
Validation loss: 3.1414258577926586

Epoch: 6| Step: 2
Training loss: 3.002197414527549
Validation loss: 3.1382457014163974

Epoch: 6| Step: 3
Training loss: 2.854310099392435
Validation loss: 3.135091788019524

Epoch: 6| Step: 4
Training loss: 3.399077537161766
Validation loss: 3.1320061284034115

Epoch: 6| Step: 5
Training loss: 3.6564638776253355
Validation loss: 3.1287884826975856

Epoch: 6| Step: 6
Training loss: 2.985299651219013
Validation loss: 3.1256896847375066

Epoch: 6| Step: 7
Training loss: 3.872929666027779
Validation loss: 3.122691535257248

Epoch: 6| Step: 8
Training loss: 3.658239622081686
Validation loss: 3.1193288843028473

Epoch: 6| Step: 9
Training loss: 3.4037389336335004
Validation loss: 3.1159009070940606

Epoch: 6| Step: 10
Training loss: 2.7116202338459083
Validation loss: 3.1127960707705133

Epoch: 6| Step: 11
Training loss: 3.2791686223245207
Validation loss: 3.1093740415332025

Epoch: 6| Step: 12
Training loss: 3.1475751656668898
Validation loss: 3.1060353527959723

Epoch: 6| Step: 13
Training loss: 2.7894660379954668
Validation loss: 3.1028116883083356

Epoch: 42| Step: 0
Training loss: 2.8042537598218704
Validation loss: 3.0995923502341736

Epoch: 6| Step: 1
Training loss: 2.824486937392909
Validation loss: 3.096629283201687

Epoch: 6| Step: 2
Training loss: 3.42166694461495
Validation loss: 3.0935620722865287

Epoch: 6| Step: 3
Training loss: 3.2216432771131354
Validation loss: 3.0907559533271045

Epoch: 6| Step: 4
Training loss: 2.834534689580127
Validation loss: 3.0876681082567488

Epoch: 6| Step: 5
Training loss: 3.183106330114261
Validation loss: 3.084762620000594

Epoch: 6| Step: 6
Training loss: 3.6629931225328085
Validation loss: 3.0816899035251506

Epoch: 6| Step: 7
Training loss: 3.479752009752626
Validation loss: 3.0786628059681305

Epoch: 6| Step: 8
Training loss: 3.415074109101338
Validation loss: 3.0752761230963537

Epoch: 6| Step: 9
Training loss: 2.977479968512068
Validation loss: 3.071960563412331

Epoch: 6| Step: 10
Training loss: 3.310089097682225
Validation loss: 3.0687418018860866

Epoch: 6| Step: 11
Training loss: 3.053947807960234
Validation loss: 3.0656644470601124

Epoch: 6| Step: 12
Training loss: 3.058166552022978
Validation loss: 3.0626463303672042

Epoch: 6| Step: 13
Training loss: 3.6715537072697453
Validation loss: 3.059633769182816

Epoch: 43| Step: 0
Training loss: 3.4755794892729592
Validation loss: 3.0565860503730904

Epoch: 6| Step: 1
Training loss: 3.1842898491283296
Validation loss: 3.0533718127806404

Epoch: 6| Step: 2
Training loss: 3.251473899561743
Validation loss: 3.0502675006898943

Epoch: 6| Step: 3
Training loss: 2.416994653565661
Validation loss: 3.0470446417117003

Epoch: 6| Step: 4
Training loss: 3.4327044241226354
Validation loss: 3.043793853297637

Epoch: 6| Step: 5
Training loss: 2.6470997000012724
Validation loss: 3.0405946610476953

Epoch: 6| Step: 6
Training loss: 3.135988371340931
Validation loss: 3.037588211369472

Epoch: 6| Step: 7
Training loss: 3.3982421818872495
Validation loss: 3.034414114734358

Epoch: 6| Step: 8
Training loss: 3.392129450037328
Validation loss: 3.0315252749323585

Epoch: 6| Step: 9
Training loss: 2.695490115298129
Validation loss: 3.02844664469977

Epoch: 6| Step: 10
Training loss: 3.7087948686941097
Validation loss: 3.025577467978632

Epoch: 6| Step: 11
Training loss: 3.1660227037147113
Validation loss: 3.022808117870734

Epoch: 6| Step: 12
Training loss: 3.094112490600849
Validation loss: 3.019767853949038

Epoch: 6| Step: 13
Training loss: 3.2615865897626466
Validation loss: 3.0169287648509804

Epoch: 44| Step: 0
Training loss: 4.081763036942014
Validation loss: 3.0143139744976817

Epoch: 6| Step: 1
Training loss: 3.0212342270300123
Validation loss: 3.011014969097536

Epoch: 6| Step: 2
Training loss: 3.1053729348426296
Validation loss: 3.008016696620656

Epoch: 6| Step: 3
Training loss: 2.9810745603494713
Validation loss: 3.005013052393134

Epoch: 6| Step: 4
Training loss: 3.483329581908133
Validation loss: 3.001866859151251

Epoch: 6| Step: 5
Training loss: 2.7166116131623967
Validation loss: 2.9988800978495416

Epoch: 6| Step: 6
Training loss: 3.2544919296307584
Validation loss: 2.995970258028673

Epoch: 6| Step: 7
Training loss: 2.7357298192142063
Validation loss: 2.992947978962718

Epoch: 6| Step: 8
Training loss: 2.9393272398293346
Validation loss: 2.990089059160415

Epoch: 6| Step: 9
Training loss: 3.0294465668104573
Validation loss: 2.9872778045086497

Epoch: 6| Step: 10
Training loss: 3.0295293584730447
Validation loss: 2.9846719191343594

Epoch: 6| Step: 11
Training loss: 2.926777200313245
Validation loss: 2.9821146848667843

Epoch: 6| Step: 12
Training loss: 3.418549336850566
Validation loss: 2.97937672992643

Epoch: 6| Step: 13
Training loss: 2.9785537267030193
Validation loss: 2.9767183678534512

Epoch: 45| Step: 0
Training loss: 2.408171839947842
Validation loss: 2.974027299944235

Epoch: 6| Step: 1
Training loss: 3.4756471264633397
Validation loss: 2.9715187947667743

Epoch: 6| Step: 2
Training loss: 2.648474048823677
Validation loss: 2.968900951094816

Epoch: 6| Step: 3
Training loss: 3.8201484878999783
Validation loss: 2.966124166398906

Epoch: 6| Step: 4
Training loss: 2.751414282130265
Validation loss: 2.9634135553238115

Epoch: 6| Step: 5
Training loss: 3.3348587042803852
Validation loss: 2.9608745719241663

Epoch: 6| Step: 6
Training loss: 3.3933614771886833
Validation loss: 2.958125944434963

Epoch: 6| Step: 7
Training loss: 3.0291761402539934
Validation loss: 2.955430384027333

Epoch: 6| Step: 8
Training loss: 3.0293653469352955
Validation loss: 2.952697359638569

Epoch: 6| Step: 9
Training loss: 3.011004609417689
Validation loss: 2.9500660872734707

Epoch: 6| Step: 10
Training loss: 3.6876546536358883
Validation loss: 2.9470569628580163

Epoch: 6| Step: 11
Training loss: 3.3313326712650877
Validation loss: 2.944309566415554

Epoch: 6| Step: 12
Training loss: 2.4640605183885502
Validation loss: 2.941343795700983

Epoch: 6| Step: 13
Training loss: 2.6130767879130588
Validation loss: 2.938968575420251

Epoch: 46| Step: 0
Training loss: 3.2178336014861033
Validation loss: 2.9366102562060656

Epoch: 6| Step: 1
Training loss: 2.755676739302784
Validation loss: 2.934372244533319

Epoch: 6| Step: 2
Training loss: 2.5675687203872717
Validation loss: 2.9318591940074343

Epoch: 6| Step: 3
Training loss: 3.0945330312830173
Validation loss: 2.929461050818657

Epoch: 6| Step: 4
Training loss: 3.1870595590312556
Validation loss: 2.9270874421621427

Epoch: 6| Step: 5
Training loss: 3.7151584752656097
Validation loss: 2.9245099784788233

Epoch: 6| Step: 6
Training loss: 3.21094878628643
Validation loss: 2.9218779511190327

Epoch: 6| Step: 7
Training loss: 3.7216020434369868
Validation loss: 2.9193914401582988

Epoch: 6| Step: 8
Training loss: 2.7171305075180423
Validation loss: 2.9167191273648885

Epoch: 6| Step: 9
Training loss: 3.273544127701024
Validation loss: 2.91435536130838

Epoch: 6| Step: 10
Training loss: 2.9703528644803074
Validation loss: 2.911673581668858

Epoch: 6| Step: 11
Training loss: 2.5793301626550598
Validation loss: 2.9090966123918776

Epoch: 6| Step: 12
Training loss: 2.6935026865142575
Validation loss: 2.9067077959793397

Epoch: 6| Step: 13
Training loss: 2.920649470384528
Validation loss: 2.904309311861296

Epoch: 47| Step: 0
Training loss: 3.0797506773965186
Validation loss: 2.9022540715679983

Epoch: 6| Step: 1
Training loss: 3.6733504557224923
Validation loss: 2.9000008506335186

Epoch: 6| Step: 2
Training loss: 2.2403850687655584
Validation loss: 2.8976403825712325

Epoch: 6| Step: 3
Training loss: 3.374387332267009
Validation loss: 2.8955033111966135

Epoch: 6| Step: 4
Training loss: 3.0488711347362694
Validation loss: 2.8931569188548547

Epoch: 6| Step: 5
Training loss: 3.0451786894585386
Validation loss: 2.8908667798351195

Epoch: 6| Step: 6
Training loss: 2.9175327286768167
Validation loss: 2.8886711665684173

Epoch: 6| Step: 7
Training loss: 3.1001656026599638
Validation loss: 2.88615546195994

Epoch: 6| Step: 8
Training loss: 2.7017045009661533
Validation loss: 2.883980670285712

Epoch: 6| Step: 9
Training loss: 3.087877344709741
Validation loss: 2.881861901282107

Epoch: 6| Step: 10
Training loss: 2.960799000100166
Validation loss: 2.8796528469683875

Epoch: 6| Step: 11
Training loss: 2.806529001074906
Validation loss: 2.8775865004789782

Epoch: 6| Step: 12
Training loss: 3.2343511165898087
Validation loss: 2.875437813746361

Epoch: 6| Step: 13
Training loss: 2.943250668042748
Validation loss: 2.873310905960545

Epoch: 48| Step: 0
Training loss: 2.8754633654491304
Validation loss: 2.8710917846949764

Epoch: 6| Step: 1
Training loss: 2.9835440392559462
Validation loss: 2.8691350297589815

Epoch: 6| Step: 2
Training loss: 2.7896092837899853
Validation loss: 2.867078233346689

Epoch: 6| Step: 3
Training loss: 3.279738595827114
Validation loss: 2.865168415776096

Epoch: 6| Step: 4
Training loss: 2.9534083639162216
Validation loss: 2.863047383373658

Epoch: 6| Step: 5
Training loss: 2.8047686806833703
Validation loss: 2.8609445846472674

Epoch: 6| Step: 6
Training loss: 3.2200862740278584
Validation loss: 2.8587740351716415

Epoch: 6| Step: 7
Training loss: 3.2243224859129804
Validation loss: 2.8565226713394063

Epoch: 6| Step: 8
Training loss: 2.7724664411930227
Validation loss: 2.854306688609867

Epoch: 6| Step: 9
Training loss: 2.6731997769385507
Validation loss: 2.852167603553011

Epoch: 6| Step: 10
Training loss: 3.596766524414998
Validation loss: 2.8499496567055393

Epoch: 6| Step: 11
Training loss: 2.7891251586372405
Validation loss: 2.847782196762196

Epoch: 6| Step: 12
Training loss: 3.077236453934018
Validation loss: 2.845594108621095

Epoch: 6| Step: 13
Training loss: 2.8274832150123825
Validation loss: 2.843608154001036

Epoch: 49| Step: 0
Training loss: 3.417702277559037
Validation loss: 2.8415451025667107

Epoch: 6| Step: 1
Training loss: 1.9386797358891354
Validation loss: 2.8394907260122433

Epoch: 6| Step: 2
Training loss: 3.492649534242302
Validation loss: 2.837483946857051

Epoch: 6| Step: 3
Training loss: 2.391354916908623
Validation loss: 2.835353388326639

Epoch: 6| Step: 4
Training loss: 3.1723450561394486
Validation loss: 2.833576925876519

Epoch: 6| Step: 5
Training loss: 3.19007141511674
Validation loss: 2.8312667060230052

Epoch: 6| Step: 6
Training loss: 2.7380721900791287
Validation loss: 2.829398793925979

Epoch: 6| Step: 7
Training loss: 2.444239371781615
Validation loss: 2.8274214485920512

Epoch: 6| Step: 8
Training loss: 2.9313484874845783
Validation loss: 2.825906491072737

Epoch: 6| Step: 9
Training loss: 2.797821737133787
Validation loss: 2.824097760476963

Epoch: 6| Step: 10
Training loss: 3.2754359006169382
Validation loss: 2.8223338821763218

Epoch: 6| Step: 11
Training loss: 3.0116981673867036
Validation loss: 2.820502714186793

Epoch: 6| Step: 12
Training loss: 3.1784371581887045
Validation loss: 2.8186648444079907

Epoch: 6| Step: 13
Training loss: 3.1974283315636396
Validation loss: 2.8167703351763262

Epoch: 50| Step: 0
Training loss: 2.442590045030536
Validation loss: 2.8147017443916846

Epoch: 6| Step: 1
Training loss: 2.9775824614027275
Validation loss: 2.8130817094325375

Epoch: 6| Step: 2
Training loss: 3.407372385995294
Validation loss: 2.811455172272797

Epoch: 6| Step: 3
Training loss: 2.85151266812195
Validation loss: 2.809452567551967

Epoch: 6| Step: 4
Training loss: 2.685439983668186
Validation loss: 2.808030893999038

Epoch: 6| Step: 5
Training loss: 3.359236461532916
Validation loss: 2.80621811835198

Epoch: 6| Step: 6
Training loss: 3.0822803314471536
Validation loss: 2.8042618367415564

Epoch: 6| Step: 7
Training loss: 2.648132486699685
Validation loss: 2.8023887571817334

Epoch: 6| Step: 8
Training loss: 2.69023348167275
Validation loss: 2.800589015292226

Epoch: 6| Step: 9
Training loss: 2.955993873517575
Validation loss: 2.7987674867175434

Epoch: 6| Step: 10
Training loss: 3.125354899281034
Validation loss: 2.796958964701812

Epoch: 6| Step: 11
Training loss: 2.718365872311354
Validation loss: 2.79506755656225

Epoch: 6| Step: 12
Training loss: 3.0691923859804953
Validation loss: 2.7931650941921227

Epoch: 6| Step: 13
Training loss: 3.0431078975727317
Validation loss: 2.791331275796447

Epoch: 51| Step: 0
Training loss: 3.507538306855687
Validation loss: 2.7893742263363226

Epoch: 6| Step: 1
Training loss: 3.1280213055872887
Validation loss: 2.7875121266054235

Epoch: 6| Step: 2
Training loss: 2.863052921116508
Validation loss: 2.7855304967712318

Epoch: 6| Step: 3
Training loss: 2.689524752813421
Validation loss: 2.7837102488234846

Epoch: 6| Step: 4
Training loss: 3.3411921049240547
Validation loss: 2.7821519225081457

Epoch: 6| Step: 5
Training loss: 2.7561869815187623
Validation loss: 2.780077569277291

Epoch: 6| Step: 6
Training loss: 3.1007804749503
Validation loss: 2.778321256453047

Epoch: 6| Step: 7
Training loss: 2.7521515145953632
Validation loss: 2.77648995640488

Epoch: 6| Step: 8
Training loss: 2.601572214286011
Validation loss: 2.774696372435761

Epoch: 6| Step: 9
Training loss: 2.2569965089188715
Validation loss: 2.7728676008951116

Epoch: 6| Step: 10
Training loss: 2.922021219603393
Validation loss: 2.771406377367341

Epoch: 6| Step: 11
Training loss: 3.1459930244654633
Validation loss: 2.7695157974737508

Epoch: 6| Step: 12
Training loss: 2.7667376332967035
Validation loss: 2.7678487425997487

Epoch: 6| Step: 13
Training loss: 2.829537897562978
Validation loss: 2.7659387356668406

Epoch: 52| Step: 0
Training loss: 3.1839022808702624
Validation loss: 2.7641902729445196

Epoch: 6| Step: 1
Training loss: 2.684931126142741
Validation loss: 2.7627333702144043

Epoch: 6| Step: 2
Training loss: 2.804553865527199
Validation loss: 2.761382388683828

Epoch: 6| Step: 3
Training loss: 2.8021364644247413
Validation loss: 2.7595788847964076

Epoch: 6| Step: 4
Training loss: 2.4950059600942365
Validation loss: 2.7578628146414976

Epoch: 6| Step: 5
Training loss: 2.7167314950739803
Validation loss: 2.756169334840157

Epoch: 6| Step: 6
Training loss: 2.908972664619071
Validation loss: 2.753982766533599

Epoch: 6| Step: 7
Training loss: 3.507851649280422
Validation loss: 2.7641875991128373

Epoch: 6| Step: 8
Training loss: 2.6978410000788675
Validation loss: 2.752810068408373

Epoch: 6| Step: 9
Training loss: 2.838301248897338
Validation loss: 2.751587481785158

Epoch: 6| Step: 10
Training loss: 2.915447161812457
Validation loss: 2.751568534767917

Epoch: 6| Step: 11
Training loss: 2.9186398144330936
Validation loss: 2.755926941084605

Epoch: 6| Step: 12
Training loss: 2.9071778487793956
Validation loss: 2.7583135882666845

Epoch: 6| Step: 13
Training loss: 3.07962170147873
Validation loss: 2.7500983278439812

Epoch: 53| Step: 0
Training loss: 3.2516566235888886
Validation loss: 2.7461622364372476

Epoch: 6| Step: 1
Training loss: 2.572492052219818
Validation loss: 2.743640641427778

Epoch: 6| Step: 2
Training loss: 2.8467505418390524
Validation loss: 2.741671869645984

Epoch: 6| Step: 3
Training loss: 3.282321573305013
Validation loss: 2.7387180750866666

Epoch: 6| Step: 4
Training loss: 3.0711603522811743
Validation loss: 2.7369292472741704

Epoch: 6| Step: 5
Training loss: 3.0335569746414843
Validation loss: 2.7362408475459934

Epoch: 6| Step: 6
Training loss: 2.632697309470083
Validation loss: 2.7332115531945185

Epoch: 6| Step: 7
Training loss: 2.5004435145835235
Validation loss: 2.7317335612927534

Epoch: 6| Step: 8
Training loss: 2.8101503517952247
Validation loss: 2.730282072672196

Epoch: 6| Step: 9
Training loss: 2.7046671971837815
Validation loss: 2.7301051780505423

Epoch: 6| Step: 10
Training loss: 2.418049602974738
Validation loss: 2.7296090289262107

Epoch: 6| Step: 11
Training loss: 3.202893355762672
Validation loss: 2.7278184156979726

Epoch: 6| Step: 12
Training loss: 2.786744508872881
Validation loss: 2.7242112100094085

Epoch: 6| Step: 13
Training loss: 2.9931251909180645
Validation loss: 2.7228889092273683

Epoch: 54| Step: 0
Training loss: 2.9282190330168723
Validation loss: 2.723866701256392

Epoch: 6| Step: 1
Training loss: 2.8466218971942756
Validation loss: 2.7209893281702366

Epoch: 6| Step: 2
Training loss: 3.096094649432906
Validation loss: 2.7210123580601513

Epoch: 6| Step: 3
Training loss: 2.534994111364624
Validation loss: 2.720926531665198

Epoch: 6| Step: 4
Training loss: 2.854432383696146
Validation loss: 2.721488771653606

Epoch: 6| Step: 5
Training loss: 2.3998566942345847
Validation loss: 2.7208519187709195

Epoch: 6| Step: 6
Training loss: 2.629580361716132
Validation loss: 2.7191110422389966

Epoch: 6| Step: 7
Training loss: 3.3269399046313297
Validation loss: 2.7172993995770756

Epoch: 6| Step: 8
Training loss: 3.20893860759359
Validation loss: 2.714356976603774

Epoch: 6| Step: 9
Training loss: 2.63889079735224
Validation loss: 2.711677589496105

Epoch: 6| Step: 10
Training loss: 3.0624799143852655
Validation loss: 2.7099692368022317

Epoch: 6| Step: 11
Training loss: 3.098806699147141
Validation loss: 2.7095264936579584

Epoch: 6| Step: 12
Training loss: 2.293125543643682
Validation loss: 2.7080539754919313

Epoch: 6| Step: 13
Training loss: 2.859274607078957
Validation loss: 2.708342967872111

Epoch: 55| Step: 0
Training loss: 3.1777553827286544
Validation loss: 2.706743409457859

Epoch: 6| Step: 1
Training loss: 2.6324420068335868
Validation loss: 2.7033976599271488

Epoch: 6| Step: 2
Training loss: 2.6921460113605233
Validation loss: 2.701453160488667

Epoch: 6| Step: 3
Training loss: 3.2353994617549198
Validation loss: 2.698445976404521

Epoch: 6| Step: 4
Training loss: 2.7210875360777727
Validation loss: 2.69746317544007

Epoch: 6| Step: 5
Training loss: 3.2615523792711794
Validation loss: 2.6964170837037336

Epoch: 6| Step: 6
Training loss: 2.8449035652322543
Validation loss: 2.694695207609207

Epoch: 6| Step: 7
Training loss: 2.3838452711905482
Validation loss: 2.6925545850844816

Epoch: 6| Step: 8
Training loss: 2.660335943619952
Validation loss: 2.691907949429758

Epoch: 6| Step: 9
Training loss: 2.710292596540511
Validation loss: 2.6908107443867806

Epoch: 6| Step: 10
Training loss: 2.7243506961656463
Validation loss: 2.688733645746614

Epoch: 6| Step: 11
Training loss: 2.537351248754911
Validation loss: 2.6869454218256448

Epoch: 6| Step: 12
Training loss: 2.829435771865015
Validation loss: 2.686084788694366

Epoch: 6| Step: 13
Training loss: 3.1540955092459253
Validation loss: 2.6846914475671384

Epoch: 56| Step: 0
Training loss: 3.084004165943464
Validation loss: 2.6826342811405555

Epoch: 6| Step: 1
Training loss: 2.6907605641026624
Validation loss: 2.680883468793131

Epoch: 6| Step: 2
Training loss: 2.4179299001700256
Validation loss: 2.679555179750763

Epoch: 6| Step: 3
Training loss: 2.999549831947444
Validation loss: 2.6773200963235793

Epoch: 6| Step: 4
Training loss: 2.9804111540142673
Validation loss: 2.6776104023525718

Epoch: 6| Step: 5
Training loss: 2.7535478940434754
Validation loss: 2.6746739233336254

Epoch: 6| Step: 6
Training loss: 2.6243750418626455
Validation loss: 2.6745483528159855

Epoch: 6| Step: 7
Training loss: 2.315770697289418
Validation loss: 2.6737001368465525

Epoch: 6| Step: 8
Training loss: 2.6990516268586346
Validation loss: 2.675672691352055

Epoch: 6| Step: 9
Training loss: 2.9161173348596496
Validation loss: 2.6732508665748353

Epoch: 6| Step: 10
Training loss: 2.9152616840766643
Validation loss: 2.6719476046745485

Epoch: 6| Step: 11
Training loss: 3.4135996070455716
Validation loss: 2.6732684065797723

Epoch: 6| Step: 12
Training loss: 2.9663706028112293
Validation loss: 2.6688273339006883

Epoch: 6| Step: 13
Training loss: 2.5080138508902468
Validation loss: 2.6692284904781167

Epoch: 57| Step: 0
Training loss: 2.6355279790919806
Validation loss: 2.6696080039845085

Epoch: 6| Step: 1
Training loss: 3.0795579082719633
Validation loss: 2.6727322398599407

Epoch: 6| Step: 2
Training loss: 2.5924101896556926
Validation loss: 2.6729284815974372

Epoch: 6| Step: 3
Training loss: 3.087551805316422
Validation loss: 2.6717339045281103

Epoch: 6| Step: 4
Training loss: 2.6566981218104004
Validation loss: 2.669181075409074

Epoch: 6| Step: 5
Training loss: 3.315895499539632
Validation loss: 2.666050263530319

Epoch: 6| Step: 6
Training loss: 2.897148730072406
Validation loss: 2.6638900238616334

Epoch: 6| Step: 7
Training loss: 2.6133385439580756
Validation loss: 2.6626183631269478

Epoch: 6| Step: 8
Training loss: 2.66096992764115
Validation loss: 2.661322145405393

Epoch: 6| Step: 9
Training loss: 2.8073263266457933
Validation loss: 2.6591734263271327

Epoch: 6| Step: 10
Training loss: 2.4139115863528464
Validation loss: 2.6583153567608186

Epoch: 6| Step: 11
Training loss: 2.489041725737714
Validation loss: 2.658188280993294

Epoch: 6| Step: 12
Training loss: 2.939355791577879
Validation loss: 2.656660280144201

Epoch: 6| Step: 13
Training loss: 2.9476273645218667
Validation loss: 2.6557223974095376

Epoch: 58| Step: 0
Training loss: 2.689722871792683
Validation loss: 2.654729430354188

Epoch: 6| Step: 1
Training loss: 2.8705522714309835
Validation loss: 2.6551413372851718

Epoch: 6| Step: 2
Training loss: 2.577911183131652
Validation loss: 2.6516306634405282

Epoch: 6| Step: 3
Training loss: 2.704238485862819
Validation loss: 2.6499354684517926

Epoch: 6| Step: 4
Training loss: 3.197943241037963
Validation loss: 2.652298879641821

Epoch: 6| Step: 5
Training loss: 2.9228249703831253
Validation loss: 2.6521017556900377

Epoch: 6| Step: 6
Training loss: 2.4593204089919785
Validation loss: 2.649166910708083

Epoch: 6| Step: 7
Training loss: 2.722159867210478
Validation loss: 2.6468586674606325

Epoch: 6| Step: 8
Training loss: 2.857514490072469
Validation loss: 2.6438503243339384

Epoch: 6| Step: 9
Training loss: 3.2440565489933135
Validation loss: 2.6434161391001916

Epoch: 6| Step: 10
Training loss: 2.757561604701361
Validation loss: 2.6445474703961374

Epoch: 6| Step: 11
Training loss: 2.5446001436477688
Validation loss: 2.6442268831273403

Epoch: 6| Step: 12
Training loss: 2.745426536453931
Validation loss: 2.6440671197006047

Epoch: 6| Step: 13
Training loss: 2.633834323628525
Validation loss: 2.6437166763502127

Epoch: 59| Step: 0
Training loss: 3.0248231694264094
Validation loss: 2.642619792180242

Epoch: 6| Step: 1
Training loss: 3.042371032539225
Validation loss: 2.6385393351772852

Epoch: 6| Step: 2
Training loss: 3.064384036625596
Validation loss: 2.634160859623411

Epoch: 6| Step: 3
Training loss: 2.8194034199687086
Validation loss: 2.632888445716275

Epoch: 6| Step: 4
Training loss: 2.7118557740686295
Validation loss: 2.632862894272087

Epoch: 6| Step: 5
Training loss: 2.8538630154621907
Validation loss: 2.6321898194750095

Epoch: 6| Step: 6
Training loss: 2.608393318859635
Validation loss: 2.6301679903971453

Epoch: 6| Step: 7
Training loss: 2.802656963488874
Validation loss: 2.6322021078662785

Epoch: 6| Step: 8
Training loss: 3.0291929835908338
Validation loss: 2.6315772897313567

Epoch: 6| Step: 9
Training loss: 2.4125746799433405
Validation loss: 2.6317116976390973

Epoch: 6| Step: 10
Training loss: 2.5604162350171324
Validation loss: 2.6316024761653907

Epoch: 6| Step: 11
Training loss: 2.392647978093814
Validation loss: 2.632112977987839

Epoch: 6| Step: 12
Training loss: 2.7233576698881157
Validation loss: 2.6310641315985346

Epoch: 6| Step: 13
Training loss: 2.7546953518171917
Validation loss: 2.630853137051617

Epoch: 60| Step: 0
Training loss: 2.563590027250813
Validation loss: 2.632044679270229

Epoch: 6| Step: 1
Training loss: 2.8895586676027305
Validation loss: 2.628564836042639

Epoch: 6| Step: 2
Training loss: 2.816199349304735
Validation loss: 2.6278446769218706

Epoch: 6| Step: 3
Training loss: 2.9585087862952895
Validation loss: 2.62572234675131

Epoch: 6| Step: 4
Training loss: 1.9676883196347252
Validation loss: 2.625252317987425

Epoch: 6| Step: 5
Training loss: 2.961074544105486
Validation loss: 2.6230405427274492

Epoch: 6| Step: 6
Training loss: 3.0767484578688014
Validation loss: 2.6222308554300695

Epoch: 6| Step: 7
Training loss: 2.5986569420326084
Validation loss: 2.6200868251964073

Epoch: 6| Step: 8
Training loss: 2.798160960614154
Validation loss: 2.618552190916451

Epoch: 6| Step: 9
Training loss: 2.95947744963572
Validation loss: 2.6171410855405073

Epoch: 6| Step: 10
Training loss: 2.990013029650618
Validation loss: 2.6168623689088966

Epoch: 6| Step: 11
Training loss: 2.642651654874787
Validation loss: 2.6153649508123924

Epoch: 6| Step: 12
Training loss: 2.3787370693639125
Validation loss: 2.6148401466073543

Epoch: 6| Step: 13
Training loss: 2.841744187118963
Validation loss: 2.6129687720689616

Epoch: 61| Step: 0
Training loss: 2.4518114205508055
Validation loss: 2.614085500874009

Epoch: 6| Step: 1
Training loss: 2.6495927749691925
Validation loss: 2.6182176982162284

Epoch: 6| Step: 2
Training loss: 2.526665291379019
Validation loss: 2.6236230326805132

Epoch: 6| Step: 3
Training loss: 3.1071657546378875
Validation loss: 2.6167939910364075

Epoch: 6| Step: 4
Training loss: 2.76881974177648
Validation loss: 2.608649238574353

Epoch: 6| Step: 5
Training loss: 2.5975621715518002
Validation loss: 2.6073464371987467

Epoch: 6| Step: 6
Training loss: 3.0428847569441353
Validation loss: 2.6075673190162316

Epoch: 6| Step: 7
Training loss: 2.3439780569383943
Validation loss: 2.609763126098977

Epoch: 6| Step: 8
Training loss: 2.8772478023941273
Validation loss: 2.609689248173169

Epoch: 6| Step: 9
Training loss: 2.7274974542565706
Validation loss: 2.61267967883886

Epoch: 6| Step: 10
Training loss: 2.8948829426925173
Validation loss: 2.6146625846209735

Epoch: 6| Step: 11
Training loss: 2.7488295058148977
Validation loss: 2.614310228793431

Epoch: 6| Step: 12
Training loss: 2.846955724716936
Validation loss: 2.616826638922152

Epoch: 6| Step: 13
Training loss: 2.853642956283817
Validation loss: 2.611927383127592

Epoch: 62| Step: 0
Training loss: 3.028940953411831
Validation loss: 2.6088537734941393

Epoch: 6| Step: 1
Training loss: 2.0215501857493963
Validation loss: 2.6083060643006695

Epoch: 6| Step: 2
Training loss: 2.4415954028287534
Validation loss: 2.6038750955751557

Epoch: 6| Step: 3
Training loss: 2.4662610798822264
Validation loss: 2.600109500290903

Epoch: 6| Step: 4
Training loss: 3.2587371172721658
Validation loss: 2.5989111142401677

Epoch: 6| Step: 5
Training loss: 2.8956854986058027
Validation loss: 2.5947912339973676

Epoch: 6| Step: 6
Training loss: 3.335314225659513
Validation loss: 2.592995223565048

Epoch: 6| Step: 7
Training loss: 2.6340018735573376
Validation loss: 2.594170777533787

Epoch: 6| Step: 8
Training loss: 2.712693582825786
Validation loss: 2.5923399711959805

Epoch: 6| Step: 9
Training loss: 2.756240872391792
Validation loss: 2.5932497361723414

Epoch: 6| Step: 10
Training loss: 2.98251300665041
Validation loss: 2.5921572961900528

Epoch: 6| Step: 11
Training loss: 2.95528966294039
Validation loss: 2.593828920136551

Epoch: 6| Step: 12
Training loss: 2.1053145145125205
Validation loss: 2.5877814657353273

Epoch: 6| Step: 13
Training loss: 2.433330001132025
Validation loss: 2.5878736118741084

Epoch: 63| Step: 0
Training loss: 2.5994813401744277
Validation loss: 2.5876375662435853

Epoch: 6| Step: 1
Training loss: 2.949814005015328
Validation loss: 2.5862969093991324

Epoch: 6| Step: 2
Training loss: 2.667898152033091
Validation loss: 2.5868407301819034

Epoch: 6| Step: 3
Training loss: 2.643084582554003
Validation loss: 2.582586170148652

Epoch: 6| Step: 4
Training loss: 2.3680102237403386
Validation loss: 2.5859830915690423

Epoch: 6| Step: 5
Training loss: 2.6419750125924897
Validation loss: 2.5823133567482843

Epoch: 6| Step: 6
Training loss: 2.2802252362076283
Validation loss: 2.5790459269259944

Epoch: 6| Step: 7
Training loss: 2.8588246300500595
Validation loss: 2.58151404605886

Epoch: 6| Step: 8
Training loss: 2.4720716704438477
Validation loss: 2.5831236190170728

Epoch: 6| Step: 9
Training loss: 3.328604650185469
Validation loss: 2.5834274479939756

Epoch: 6| Step: 10
Training loss: 2.7649239551372204
Validation loss: 2.5815669347791697

Epoch: 6| Step: 11
Training loss: 3.1966157601141334
Validation loss: 2.584466813719465

Epoch: 6| Step: 12
Training loss: 2.8521246369080733
Validation loss: 2.5825643522917345

Epoch: 6| Step: 13
Training loss: 2.3641079552233215
Validation loss: 2.581482937257136

Epoch: 64| Step: 0
Training loss: 2.466118484447472
Validation loss: 2.5785048696232664

Epoch: 6| Step: 1
Training loss: 2.6522043272967655
Validation loss: 2.5799590705858164

Epoch: 6| Step: 2
Training loss: 2.274627688617672
Validation loss: 2.5780632088702675

Epoch: 6| Step: 3
Training loss: 2.839082009684617
Validation loss: 2.5770657453705206

Epoch: 6| Step: 4
Training loss: 2.8229031908527715
Validation loss: 2.5749055277212904

Epoch: 6| Step: 5
Training loss: 2.1696303589834844
Validation loss: 2.5748475560491326

Epoch: 6| Step: 6
Training loss: 2.7674916320508864
Validation loss: 2.575475622281087

Epoch: 6| Step: 7
Training loss: 2.5593845688637513
Validation loss: 2.573101381989259

Epoch: 6| Step: 8
Training loss: 2.5493299202231112
Validation loss: 2.573250441323832

Epoch: 6| Step: 9
Training loss: 2.9233446963824137
Validation loss: 2.5737675380865763

Epoch: 6| Step: 10
Training loss: 3.101525140724699
Validation loss: 2.5774461565335383

Epoch: 6| Step: 11
Training loss: 3.220937633593975
Validation loss: 2.570534871385061

Epoch: 6| Step: 12
Training loss: 2.453815435935236
Validation loss: 2.5691234771912574

Epoch: 6| Step: 13
Training loss: 2.9779024086993355
Validation loss: 2.569705307809234

Epoch: 65| Step: 0
Training loss: 2.6641175384653253
Validation loss: 2.5674967082150166

Epoch: 6| Step: 1
Training loss: 3.140105702753156
Validation loss: 2.569334220813162

Epoch: 6| Step: 2
Training loss: 2.689086268495606
Validation loss: 2.5692277994553105

Epoch: 6| Step: 3
Training loss: 2.7854578997104893
Validation loss: 2.5699090457411846

Epoch: 6| Step: 4
Training loss: 3.023515409505722
Validation loss: 2.570982995357733

Epoch: 6| Step: 5
Training loss: 2.678170889925307
Validation loss: 2.571318347463274

Epoch: 6| Step: 6
Training loss: 2.4805289193612716
Validation loss: 2.5722556146587676

Epoch: 6| Step: 7
Training loss: 1.892418696220477
Validation loss: 2.566050202373895

Epoch: 6| Step: 8
Training loss: 2.58122824966836
Validation loss: 2.56572551398754

Epoch: 6| Step: 9
Training loss: 2.817743626700802
Validation loss: 2.5606874863313585

Epoch: 6| Step: 10
Training loss: 3.1874920714036654
Validation loss: 2.5596680382977715

Epoch: 6| Step: 11
Training loss: 2.2744482356411915
Validation loss: 2.560088550431889

Epoch: 6| Step: 12
Training loss: 2.3482112894862763
Validation loss: 2.558238277056908

Epoch: 6| Step: 13
Training loss: 3.033692624398697
Validation loss: 2.5572545087073912

Epoch: 66| Step: 0
Training loss: 2.742164285675643
Validation loss: 2.5585468938288676

Epoch: 6| Step: 1
Training loss: 2.437854154240949
Validation loss: 2.5535769834086453

Epoch: 6| Step: 2
Training loss: 2.9086577583378834
Validation loss: 2.556898383350133

Epoch: 6| Step: 3
Training loss: 2.6781173866190464
Validation loss: 2.5630653191958803

Epoch: 6| Step: 4
Training loss: 2.726285991474851
Validation loss: 2.5854159133586254

Epoch: 6| Step: 5
Training loss: 2.5791981630964815
Validation loss: 2.5567266354082467

Epoch: 6| Step: 6
Training loss: 2.5268712729729192
Validation loss: 2.5543180581592346

Epoch: 6| Step: 7
Training loss: 2.6900720043543145
Validation loss: 2.554090144228224

Epoch: 6| Step: 8
Training loss: 2.3313184508227804
Validation loss: 2.5567245838745505

Epoch: 6| Step: 9
Training loss: 2.50995694036138
Validation loss: 2.556581702936416

Epoch: 6| Step: 10
Training loss: 2.7541479559266175
Validation loss: 2.562069120079722

Epoch: 6| Step: 11
Training loss: 2.834298493047772
Validation loss: 2.559837539852526

Epoch: 6| Step: 12
Training loss: 2.96616114120396
Validation loss: 2.562758285407352

Epoch: 6| Step: 13
Training loss: 3.0321968408869444
Validation loss: 2.5621882923626083

Epoch: 67| Step: 0
Training loss: 2.807070089358701
Validation loss: 2.561951570826898

Epoch: 6| Step: 1
Training loss: 2.544071456505431
Validation loss: 2.5601174823556305

Epoch: 6| Step: 2
Training loss: 2.8636289544167934
Validation loss: 2.557698209085417

Epoch: 6| Step: 3
Training loss: 2.7428560229991716
Validation loss: 2.556804639093259

Epoch: 6| Step: 4
Training loss: 2.7970580994753793
Validation loss: 2.554745081448022

Epoch: 6| Step: 5
Training loss: 2.5644438279296438
Validation loss: 2.552283895487625

Epoch: 6| Step: 6
Training loss: 2.6813218718457192
Validation loss: 2.5509335062055762

Epoch: 6| Step: 7
Training loss: 3.1022737778068947
Validation loss: 2.547498552560941

Epoch: 6| Step: 8
Training loss: 2.222701945446905
Validation loss: 2.5486655152970425

Epoch: 6| Step: 9
Training loss: 2.7636451315512582
Validation loss: 2.5487488716051896

Epoch: 6| Step: 10
Training loss: 2.175803603874172
Validation loss: 2.5466621013503907

Epoch: 6| Step: 11
Training loss: 2.884982483809003
Validation loss: 2.5442883670844356

Epoch: 6| Step: 12
Training loss: 2.801812103266691
Validation loss: 2.538949793735023

Epoch: 6| Step: 13
Training loss: 2.6609992261481925
Validation loss: 2.5452103586702224

Epoch: 68| Step: 0
Training loss: 2.6143462743601398
Validation loss: 2.5422609968449943

Epoch: 6| Step: 1
Training loss: 2.8719972603128694
Validation loss: 2.546924707594633

Epoch: 6| Step: 2
Training loss: 2.4163765787991007
Validation loss: 2.5441998745495846

Epoch: 6| Step: 3
Training loss: 3.1803511693177318
Validation loss: 2.5429678593178404

Epoch: 6| Step: 4
Training loss: 2.832636654041312
Validation loss: 2.5419503559154095

Epoch: 6| Step: 5
Training loss: 2.330815750872248
Validation loss: 2.537193244094069

Epoch: 6| Step: 6
Training loss: 2.4754959842508315
Validation loss: 2.5404335428429943

Epoch: 6| Step: 7
Training loss: 2.862272201869133
Validation loss: 2.556189947814175

Epoch: 6| Step: 8
Training loss: 2.476042491338708
Validation loss: 2.5482185813917755

Epoch: 6| Step: 9
Training loss: 2.4701767673638106
Validation loss: 2.543175926695464

Epoch: 6| Step: 10
Training loss: 2.6682442429311646
Validation loss: 2.5435948067577043

Epoch: 6| Step: 11
Training loss: 2.9213403222775076
Validation loss: 2.542035378357742

Epoch: 6| Step: 12
Training loss: 2.6841584656748116
Validation loss: 2.539471731218971

Epoch: 6| Step: 13
Training loss: 2.7676642706688104
Validation loss: 2.535716852510459

Epoch: 69| Step: 0
Training loss: 2.76920548044379
Validation loss: 2.536460772022952

Epoch: 6| Step: 1
Training loss: 2.9958118768665543
Validation loss: 2.535825228678672

Epoch: 6| Step: 2
Training loss: 2.4370441499576434
Validation loss: 2.540195122480604

Epoch: 6| Step: 3
Training loss: 2.4676178859389593
Validation loss: 2.5374289241163424

Epoch: 6| Step: 4
Training loss: 2.521382821045077
Validation loss: 2.546298892151508

Epoch: 6| Step: 5
Training loss: 3.2816273790148247
Validation loss: 2.5536094280658648

Epoch: 6| Step: 6
Training loss: 2.8171985797378576
Validation loss: 2.5590671868109975

Epoch: 6| Step: 7
Training loss: 3.0035068360516486
Validation loss: 2.5757100826787593

Epoch: 6| Step: 8
Training loss: 2.7319058850666984
Validation loss: 2.5536829288616993

Epoch: 6| Step: 9
Training loss: 2.4089177193720905
Validation loss: 2.537705811170287

Epoch: 6| Step: 10
Training loss: 2.327474208733961
Validation loss: 2.530206488750901

Epoch: 6| Step: 11
Training loss: 2.5867889016886196
Validation loss: 2.5302681765200434

Epoch: 6| Step: 12
Training loss: 2.895632638540388
Validation loss: 2.538730869643739

Epoch: 6| Step: 13
Training loss: 2.368815551494965
Validation loss: 2.5453564694117286

Epoch: 70| Step: 0
Training loss: 2.6583515605082395
Validation loss: 2.554802583830143

Epoch: 6| Step: 1
Training loss: 2.4112598730253967
Validation loss: 2.559787415504315

Epoch: 6| Step: 2
Training loss: 2.866998733834239
Validation loss: 2.5659180616674577

Epoch: 6| Step: 3
Training loss: 2.6591590659203166
Validation loss: 2.565280026573302

Epoch: 6| Step: 4
Training loss: 2.426148022921515
Validation loss: 2.566997891476613

Epoch: 6| Step: 5
Training loss: 2.730540175042655
Validation loss: 2.569058437965212

Epoch: 6| Step: 6
Training loss: 2.9591851597513092
Validation loss: 2.5650865015238145

Epoch: 6| Step: 7
Training loss: 2.443329320733426
Validation loss: 2.565275689343195

Epoch: 6| Step: 8
Training loss: 2.7798537274856425
Validation loss: 2.5602777971600617

Epoch: 6| Step: 9
Training loss: 2.1775467180217927
Validation loss: 2.5569597768269197

Epoch: 6| Step: 10
Training loss: 3.214064066677426
Validation loss: 2.5519672341440627

Epoch: 6| Step: 11
Training loss: 2.460281720661179
Validation loss: 2.549312696519359

Epoch: 6| Step: 12
Training loss: 3.0813671407040326
Validation loss: 2.546639257960928

Epoch: 6| Step: 13
Training loss: 2.671074462892399
Validation loss: 2.5383702356566142

Epoch: 71| Step: 0
Training loss: 3.072076111397032
Validation loss: 2.5342297068261277

Epoch: 6| Step: 1
Training loss: 2.385063933789138
Validation loss: 2.5293977655935738

Epoch: 6| Step: 2
Training loss: 2.4325099632004257
Validation loss: 2.5252250898392883

Epoch: 6| Step: 3
Training loss: 2.8411257865797594
Validation loss: 2.524190438042037

Epoch: 6| Step: 4
Training loss: 2.697867953966575
Validation loss: 2.5214641401807176

Epoch: 6| Step: 5
Training loss: 2.7216917762446817
Validation loss: 2.5192350307084346

Epoch: 6| Step: 6
Training loss: 2.583467623593956
Validation loss: 2.5144352439207838

Epoch: 6| Step: 7
Training loss: 2.50856011676131
Validation loss: 2.517570722483743

Epoch: 6| Step: 8
Training loss: 2.592711091234869
Validation loss: 2.518899874964956

Epoch: 6| Step: 9
Training loss: 2.6850949548734793
Validation loss: 2.5179320156452953

Epoch: 6| Step: 10
Training loss: 2.0305089919420256
Validation loss: 2.5172352977897554

Epoch: 6| Step: 11
Training loss: 2.69346072951631
Validation loss: 2.516540502918437

Epoch: 6| Step: 12
Training loss: 3.117463905107162
Validation loss: 2.5146324853483706

Epoch: 6| Step: 13
Training loss: 2.738473577996332
Validation loss: 2.5171218588834496

Epoch: 72| Step: 0
Training loss: 2.295356715784663
Validation loss: 2.5119945321327277

Epoch: 6| Step: 1
Training loss: 2.312614025707051
Validation loss: 2.5159948799736194

Epoch: 6| Step: 2
Training loss: 2.919632157972338
Validation loss: 2.5202063787057045

Epoch: 6| Step: 3
Training loss: 2.35937156424367
Validation loss: 2.5165137859249582

Epoch: 6| Step: 4
Training loss: 2.198460178759846
Validation loss: 2.514190991715685

Epoch: 6| Step: 5
Training loss: 2.7128003670471985
Validation loss: 2.5120457524862942

Epoch: 6| Step: 6
Training loss: 2.759197805726862
Validation loss: 2.5125096936141693

Epoch: 6| Step: 7
Training loss: 2.610928193126553
Validation loss: 2.5164246324864363

Epoch: 6| Step: 8
Training loss: 2.927238559792744
Validation loss: 2.5145422143321206

Epoch: 6| Step: 9
Training loss: 2.810624408514034
Validation loss: 2.5111727439955533

Epoch: 6| Step: 10
Training loss: 2.806379312709128
Validation loss: 2.5097831042679264

Epoch: 6| Step: 11
Training loss: 2.78649279611732
Validation loss: 2.5179368289601287

Epoch: 6| Step: 12
Training loss: 2.5756050510092146
Validation loss: 2.513040830437088

Epoch: 6| Step: 13
Training loss: 2.9070285861693317
Validation loss: 2.5155439186061046

Epoch: 73| Step: 0
Training loss: 2.202356190830694
Validation loss: 2.5108471312736182

Epoch: 6| Step: 1
Training loss: 2.579964830912925
Validation loss: 2.511660174235066

Epoch: 6| Step: 2
Training loss: 2.799538308635214
Validation loss: 2.508924845615317

Epoch: 6| Step: 3
Training loss: 3.150239565988612
Validation loss: 2.5113134299369633

Epoch: 6| Step: 4
Training loss: 2.3779567583803036
Validation loss: 2.513725147804192

Epoch: 6| Step: 5
Training loss: 2.788208902991085
Validation loss: 2.5145510163926157

Epoch: 6| Step: 6
Training loss: 2.5938935757160726
Validation loss: 2.520999987008946

Epoch: 6| Step: 7
Training loss: 2.834221607166644
Validation loss: 2.5237801302477467

Epoch: 6| Step: 8
Training loss: 2.600082022033395
Validation loss: 2.528586033678094

Epoch: 6| Step: 9
Training loss: 2.6555808626970396
Validation loss: 2.5320412768705176

Epoch: 6| Step: 10
Training loss: 3.030824926401568
Validation loss: 2.5323218756667543

Epoch: 6| Step: 11
Training loss: 2.4626213005126814
Validation loss: 2.532496361336035

Epoch: 6| Step: 12
Training loss: 2.477161611780488
Validation loss: 2.530047802303891

Epoch: 6| Step: 13
Training loss: 2.5766029257578524
Validation loss: 2.5224469960204403

Epoch: 74| Step: 0
Training loss: 2.544164045598862
Validation loss: 2.5233411111128086

Epoch: 6| Step: 1
Training loss: 2.2720699851043133
Validation loss: 2.51649186893602

Epoch: 6| Step: 2
Training loss: 2.858735893825194
Validation loss: 2.515602222284221

Epoch: 6| Step: 3
Training loss: 2.751030988767605
Validation loss: 2.5168542958309423

Epoch: 6| Step: 4
Training loss: 2.2919771041991446
Validation loss: 2.516180944516914

Epoch: 6| Step: 5
Training loss: 2.3954224164991853
Validation loss: 2.5144801249547633

Epoch: 6| Step: 6
Training loss: 3.0524241460049844
Validation loss: 2.516611352106331

Epoch: 6| Step: 7
Training loss: 2.831632851826653
Validation loss: 2.518416252142844

Epoch: 6| Step: 8
Training loss: 2.882179914504005
Validation loss: 2.517935834735196

Epoch: 6| Step: 9
Training loss: 2.648945267425447
Validation loss: 2.5148803208974573

Epoch: 6| Step: 10
Training loss: 2.0481926557106944
Validation loss: 2.5137987635868613

Epoch: 6| Step: 11
Training loss: 3.2516234817909013
Validation loss: 2.5133103488845907

Epoch: 6| Step: 12
Training loss: 2.720710836537887
Validation loss: 2.5143972208405203

Epoch: 6| Step: 13
Training loss: 2.346129061915562
Validation loss: 2.5058164486338943

Epoch: 75| Step: 0
Training loss: 2.6447751089155958
Validation loss: 2.511432447475429

Epoch: 6| Step: 1
Training loss: 2.623970374765867
Validation loss: 2.50696851367145

Epoch: 6| Step: 2
Training loss: 2.6533533795556363
Validation loss: 2.5013564085865285

Epoch: 6| Step: 3
Training loss: 2.549317481759134
Validation loss: 2.505038318429791

Epoch: 6| Step: 4
Training loss: 2.755289193152478
Validation loss: 2.5036535745565462

Epoch: 6| Step: 5
Training loss: 3.18251021030703
Validation loss: 2.4988667144666015

Epoch: 6| Step: 6
Training loss: 2.1322787668508516
Validation loss: 2.5039820429002666

Epoch: 6| Step: 7
Training loss: 3.0394296301784385
Validation loss: 2.5011760647490564

Epoch: 6| Step: 8
Training loss: 3.04173400665014
Validation loss: 2.5087169786835526

Epoch: 6| Step: 9
Training loss: 2.04826983035515
Validation loss: 2.51707925088197

Epoch: 6| Step: 10
Training loss: 2.2658954327421164
Validation loss: 2.5134090828631965

Epoch: 6| Step: 11
Training loss: 3.0064196247298773
Validation loss: 2.5263149048151172

Epoch: 6| Step: 12
Training loss: 2.061498919205217
Validation loss: 2.516696504285493

Epoch: 6| Step: 13
Training loss: 2.798059308659377
Validation loss: 2.5039975154151413

Epoch: 76| Step: 0
Training loss: 2.3239015507026966
Validation loss: 2.500580672538856

Epoch: 6| Step: 1
Training loss: 2.843629436242793
Validation loss: 2.4972795784907165

Epoch: 6| Step: 2
Training loss: 2.512913919391584
Validation loss: 2.4986688089721163

Epoch: 6| Step: 3
Training loss: 2.5911543393913985
Validation loss: 2.4990630619375516

Epoch: 6| Step: 4
Training loss: 2.5874959162435696
Validation loss: 2.5008734131037382

Epoch: 6| Step: 5
Training loss: 2.677773640217449
Validation loss: 2.498702316452587

Epoch: 6| Step: 6
Training loss: 3.028519334499292
Validation loss: 2.4991423884280257

Epoch: 6| Step: 7
Training loss: 2.5735625615910043
Validation loss: 2.496487072604103

Epoch: 6| Step: 8
Training loss: 2.313065743191105
Validation loss: 2.5005797826493628

Epoch: 6| Step: 9
Training loss: 2.858508035939084
Validation loss: 2.4968406105140013

Epoch: 6| Step: 10
Training loss: 2.5626953794846994
Validation loss: 2.496700191306676

Epoch: 6| Step: 11
Training loss: 2.756881599980499
Validation loss: 2.4967832215031907

Epoch: 6| Step: 12
Training loss: 2.460462542522592
Validation loss: 2.4966808219715504

Epoch: 6| Step: 13
Training loss: 2.5018334341491566
Validation loss: 2.4987439815110988

Epoch: 77| Step: 0
Training loss: 2.288429875885316
Validation loss: 2.4996771762954397

Epoch: 6| Step: 1
Training loss: 2.5706523450291576
Validation loss: 2.498729955412486

Epoch: 6| Step: 2
Training loss: 2.2589745088771127
Validation loss: 2.4973610460220677

Epoch: 6| Step: 3
Training loss: 2.543096817471696
Validation loss: 2.492319133475073

Epoch: 6| Step: 4
Training loss: 2.5663562694310293
Validation loss: 2.490368951888526

Epoch: 6| Step: 5
Training loss: 2.660418123639653
Validation loss: 2.4895006003791864

Epoch: 6| Step: 6
Training loss: 2.5189389027829496
Validation loss: 2.498821823337185

Epoch: 6| Step: 7
Training loss: 3.0431878105320576
Validation loss: 2.5160250849102526

Epoch: 6| Step: 8
Training loss: 2.8998898057719567
Validation loss: 2.5106413702430688

Epoch: 6| Step: 9
Training loss: 3.1307768260522657
Validation loss: 2.5092451968573863

Epoch: 6| Step: 10
Training loss: 2.2113437885861074
Validation loss: 2.4924280335556577

Epoch: 6| Step: 11
Training loss: 3.1654028796702955
Validation loss: 2.493579041525503

Epoch: 6| Step: 12
Training loss: 2.438581080215283
Validation loss: 2.4913452383397825

Epoch: 6| Step: 13
Training loss: 2.694366377478465
Validation loss: 2.495772108707951

Epoch: 78| Step: 0
Training loss: 2.9113198635813786
Validation loss: 2.4985444441048625

Epoch: 6| Step: 1
Training loss: 2.511224724816613
Validation loss: 2.5013485926855386

Epoch: 6| Step: 2
Training loss: 2.0044052960087
Validation loss: 2.5000408963990988

Epoch: 6| Step: 3
Training loss: 2.0848936976862524
Validation loss: 2.501469577554243

Epoch: 6| Step: 4
Training loss: 2.6982958219142343
Validation loss: 2.4995594431206074

Epoch: 6| Step: 5
Training loss: 2.79682317078374
Validation loss: 2.497676771244897

Epoch: 6| Step: 6
Training loss: 2.7797460883293414
Validation loss: 2.4980570872726653

Epoch: 6| Step: 7
Training loss: 3.044978250760984
Validation loss: 2.4950869603823826

Epoch: 6| Step: 8
Training loss: 2.696688358925364
Validation loss: 2.4968387484952537

Epoch: 6| Step: 9
Training loss: 2.700155931844384
Validation loss: 2.497392168463337

Epoch: 6| Step: 10
Training loss: 2.5169096326280602
Validation loss: 2.4924926252138038

Epoch: 6| Step: 11
Training loss: 2.3127266025351396
Validation loss: 2.4928517667124517

Epoch: 6| Step: 12
Training loss: 3.071507500429604
Validation loss: 2.496081491996424

Epoch: 6| Step: 13
Training loss: 2.4389616667428005
Validation loss: 2.4960776872272277

Epoch: 79| Step: 0
Training loss: 2.7138802774119815
Validation loss: 2.4969570078012517

Epoch: 6| Step: 1
Training loss: 2.4378320516705205
Validation loss: 2.4964444466803433

Epoch: 6| Step: 2
Training loss: 2.6892098598677934
Validation loss: 2.492311432725594

Epoch: 6| Step: 3
Training loss: 2.5923586871075672
Validation loss: 2.4926911007680976

Epoch: 6| Step: 4
Training loss: 2.1067330098067423
Validation loss: 2.4915513329834

Epoch: 6| Step: 5
Training loss: 2.766628794430043
Validation loss: 2.4932035728677877

Epoch: 6| Step: 6
Training loss: 3.1050817860322484
Validation loss: 2.49650462892494

Epoch: 6| Step: 7
Training loss: 2.763809556530715
Validation loss: 2.490162296623329

Epoch: 6| Step: 8
Training loss: 2.951161534147998
Validation loss: 2.4860230104072514

Epoch: 6| Step: 9
Training loss: 2.5951752021754855
Validation loss: 2.485063533418521

Epoch: 6| Step: 10
Training loss: 2.658342860891395
Validation loss: 2.483210748702088

Epoch: 6| Step: 11
Training loss: 2.319090961568995
Validation loss: 2.4869924228707707

Epoch: 6| Step: 12
Training loss: 2.6378898224051976
Validation loss: 2.4822230745913823

Epoch: 6| Step: 13
Training loss: 2.127488306284593
Validation loss: 2.482722694624538

Epoch: 80| Step: 0
Training loss: 2.508868128984713
Validation loss: 2.4817456900946446

Epoch: 6| Step: 1
Training loss: 1.597384478670985
Validation loss: 2.4864231679789857

Epoch: 6| Step: 2
Training loss: 2.590884544706503
Validation loss: 2.4827750630294054

Epoch: 6| Step: 3
Training loss: 2.696861286504187
Validation loss: 2.4856136281283545

Epoch: 6| Step: 4
Training loss: 2.844922840433037
Validation loss: 2.4912245274154023

Epoch: 6| Step: 5
Training loss: 2.5395260431734696
Validation loss: 2.485899147810408

Epoch: 6| Step: 6
Training loss: 2.5116530627831715
Validation loss: 2.4918884129765617

Epoch: 6| Step: 7
Training loss: 3.0475566394978233
Validation loss: 2.4863987962818057

Epoch: 6| Step: 8
Training loss: 2.811519536674526
Validation loss: 2.485912447071253

Epoch: 6| Step: 9
Training loss: 2.572621893631626
Validation loss: 2.4809114636808314

Epoch: 6| Step: 10
Training loss: 2.711252331660153
Validation loss: 2.483520232811781

Epoch: 6| Step: 11
Training loss: 2.2791485448066857
Validation loss: 2.483794978348392

Epoch: 6| Step: 12
Training loss: 2.83089804240659
Validation loss: 2.484177203671659

Epoch: 6| Step: 13
Training loss: 2.6849875127690233
Validation loss: 2.4817297265943816

Epoch: 81| Step: 0
Training loss: 2.7697712480859558
Validation loss: 2.4837236170270627

Epoch: 6| Step: 1
Training loss: 3.1656890832528344
Validation loss: 2.48559489180072

Epoch: 6| Step: 2
Training loss: 2.61891103900312
Validation loss: 2.4834656320657538

Epoch: 6| Step: 3
Training loss: 2.5403465428079204
Validation loss: 2.486260720113687

Epoch: 6| Step: 4
Training loss: 2.3144527129482757
Validation loss: 2.487981932965964

Epoch: 6| Step: 5
Training loss: 2.555362343970885
Validation loss: 2.4858175284326247

Epoch: 6| Step: 6
Training loss: 2.844936584409488
Validation loss: 2.4862840143622456

Epoch: 6| Step: 7
Training loss: 2.5130325132635525
Validation loss: 2.4857602206288636

Epoch: 6| Step: 8
Training loss: 2.586540036723241
Validation loss: 2.4824576826736977

Epoch: 6| Step: 9
Training loss: 2.317118800476674
Validation loss: 2.4789519390644927

Epoch: 6| Step: 10
Training loss: 2.6812342858909965
Validation loss: 2.483535688804965

Epoch: 6| Step: 11
Training loss: 2.441181239631044
Validation loss: 2.4819856586057334

Epoch: 6| Step: 12
Training loss: 2.5106339314467836
Validation loss: 2.485006847845476

Epoch: 6| Step: 13
Training loss: 2.476087073291051
Validation loss: 2.4830069944088855

Epoch: 82| Step: 0
Training loss: 2.841064862228879
Validation loss: 2.4860119335157185

Epoch: 6| Step: 1
Training loss: 2.7695550097050297
Validation loss: 2.4889127128696455

Epoch: 6| Step: 2
Training loss: 2.198291752585649
Validation loss: 2.4847962604104006

Epoch: 6| Step: 3
Training loss: 2.217657545615198
Validation loss: 2.4828064163226298

Epoch: 6| Step: 4
Training loss: 2.925337102000273
Validation loss: 2.4802902517898544

Epoch: 6| Step: 5
Training loss: 2.504767259457024
Validation loss: 2.48518225712116

Epoch: 6| Step: 6
Training loss: 2.986278625836499
Validation loss: 2.4859354888313256

Epoch: 6| Step: 7
Training loss: 2.7416562166179093
Validation loss: 2.481415335193781

Epoch: 6| Step: 8
Training loss: 2.444795108939566
Validation loss: 2.484352191684397

Epoch: 6| Step: 9
Training loss: 2.270199071750849
Validation loss: 2.4852789587821507

Epoch: 6| Step: 10
Training loss: 2.4815825117029933
Validation loss: 2.48680988687664

Epoch: 6| Step: 11
Training loss: 2.787588461939098
Validation loss: 2.4846718568804818

Epoch: 6| Step: 12
Training loss: 2.4339867729134794
Validation loss: 2.4796169630729588

Epoch: 6| Step: 13
Training loss: 2.600488939528368
Validation loss: 2.4769139406523575

Epoch: 83| Step: 0
Training loss: 2.0208674424691337
Validation loss: 2.481858856678943

Epoch: 6| Step: 1
Training loss: 2.3645328958876557
Validation loss: 2.491231529702027

Epoch: 6| Step: 2
Training loss: 3.033962648386865
Validation loss: 2.499075901583403

Epoch: 6| Step: 3
Training loss: 2.490110865503293
Validation loss: 2.4991723915976647

Epoch: 6| Step: 4
Training loss: 3.4649817816625554
Validation loss: 2.497104796210167

Epoch: 6| Step: 5
Training loss: 1.7841128716279404
Validation loss: 2.4847495718352817

Epoch: 6| Step: 6
Training loss: 1.9513418373719342
Validation loss: 2.4822862269418917

Epoch: 6| Step: 7
Training loss: 2.8281396686321076
Validation loss: 2.4766523663795517

Epoch: 6| Step: 8
Training loss: 2.5118402478390345
Validation loss: 2.473085419430745

Epoch: 6| Step: 9
Training loss: 2.8229379031425363
Validation loss: 2.4797229676974166

Epoch: 6| Step: 10
Training loss: 2.9589739003011792
Validation loss: 2.478035762377941

Epoch: 6| Step: 11
Training loss: 2.5471116406551437
Validation loss: 2.4821115415348203

Epoch: 6| Step: 12
Training loss: 2.984356785264277
Validation loss: 2.480508278359069

Epoch: 6| Step: 13
Training loss: 2.5359165832446644
Validation loss: 2.477759472128851

Epoch: 84| Step: 0
Training loss: 2.4415795836906224
Validation loss: 2.481578028188802

Epoch: 6| Step: 1
Training loss: 2.722355961487877
Validation loss: 2.4799646380938754

Epoch: 6| Step: 2
Training loss: 2.8879408462679717
Validation loss: 2.47880539278666

Epoch: 6| Step: 3
Training loss: 2.3421564406765274
Validation loss: 2.479057956096563

Epoch: 6| Step: 4
Training loss: 2.4458048266992147
Validation loss: 2.4809707413987607

Epoch: 6| Step: 5
Training loss: 3.040819616254577
Validation loss: 2.47627928164335

Epoch: 6| Step: 6
Training loss: 2.4291513716236346
Validation loss: 2.4752261209428053

Epoch: 6| Step: 7
Training loss: 2.641522497661501
Validation loss: 2.4775407946756856

Epoch: 6| Step: 8
Training loss: 2.40468377998565
Validation loss: 2.481010029524581

Epoch: 6| Step: 9
Training loss: 2.9734548130222946
Validation loss: 2.483547752732805

Epoch: 6| Step: 10
Training loss: 2.5745578941878358
Validation loss: 2.475260074193383

Epoch: 6| Step: 11
Training loss: 2.5685392715633117
Validation loss: 2.476296868905329

Epoch: 6| Step: 12
Training loss: 2.6378836764008695
Validation loss: 2.478137344900445

Epoch: 6| Step: 13
Training loss: 2.179440173265041
Validation loss: 2.4741934788365616

Epoch: 85| Step: 0
Training loss: 2.8412122197121086
Validation loss: 2.4775728557458745

Epoch: 6| Step: 1
Training loss: 2.720190609255828
Validation loss: 2.474248179806849

Epoch: 6| Step: 2
Training loss: 2.8170275379875633
Validation loss: 2.4785716734616843

Epoch: 6| Step: 3
Training loss: 2.6172797798855036
Validation loss: 2.475306420030011

Epoch: 6| Step: 4
Training loss: 2.996024995136785
Validation loss: 2.4752519511413027

Epoch: 6| Step: 5
Training loss: 2.6754114494120373
Validation loss: 2.4738922003222177

Epoch: 6| Step: 6
Training loss: 3.0867504739060427
Validation loss: 2.474712735982862

Epoch: 6| Step: 7
Training loss: 2.2186841283341847
Validation loss: 2.4780109714411935

Epoch: 6| Step: 8
Training loss: 2.320698099174252
Validation loss: 2.4746251756845594

Epoch: 6| Step: 9
Training loss: 2.3079843507497326
Validation loss: 2.47441615369233

Epoch: 6| Step: 10
Training loss: 2.0535189130240465
Validation loss: 2.47183953286699

Epoch: 6| Step: 11
Training loss: 2.843807345640033
Validation loss: 2.4757985281469264

Epoch: 6| Step: 12
Training loss: 2.2646824421700478
Validation loss: 2.472786577033334

Epoch: 6| Step: 13
Training loss: 2.4168027861396313
Validation loss: 2.470648972793617

Epoch: 86| Step: 0
Training loss: 2.622528638510617
Validation loss: 2.4756437215889275

Epoch: 6| Step: 1
Training loss: 2.740583945372464
Validation loss: 2.4727128651642487

Epoch: 6| Step: 2
Training loss: 3.062814190376313
Validation loss: 2.4759357834706957

Epoch: 6| Step: 3
Training loss: 2.622375265960702
Validation loss: 2.474203741383218

Epoch: 6| Step: 4
Training loss: 2.0667119800563167
Validation loss: 2.4740515815160187

Epoch: 6| Step: 5
Training loss: 2.488898423816188
Validation loss: 2.4753539047499418

Epoch: 6| Step: 6
Training loss: 2.601105520992074
Validation loss: 2.4803468208682795

Epoch: 6| Step: 7
Training loss: 2.7423004387967334
Validation loss: 2.473554467146398

Epoch: 6| Step: 8
Training loss: 2.209697470002522
Validation loss: 2.4833130716184257

Epoch: 6| Step: 9
Training loss: 2.777157118652477
Validation loss: 2.4814236062121475

Epoch: 6| Step: 10
Training loss: 2.650095103014832
Validation loss: 2.472093707993628

Epoch: 6| Step: 11
Training loss: 2.2531941312006825
Validation loss: 2.4751485324050018

Epoch: 6| Step: 12
Training loss: 2.2837652684261425
Validation loss: 2.4708122942984585

Epoch: 6| Step: 13
Training loss: 3.08867236284894
Validation loss: 2.4708389747473745

Epoch: 87| Step: 0
Training loss: 2.339347366385859
Validation loss: 2.473556868788835

Epoch: 6| Step: 1
Training loss: 2.7104370358811276
Validation loss: 2.4669523172542016

Epoch: 6| Step: 2
Training loss: 2.749312054676009
Validation loss: 2.471074744059096

Epoch: 6| Step: 3
Training loss: 3.0771213192533247
Validation loss: 2.4707334091883695

Epoch: 6| Step: 4
Training loss: 2.1021636897122753
Validation loss: 2.4718581162497806

Epoch: 6| Step: 5
Training loss: 2.6864036275424517
Validation loss: 2.470523744285921

Epoch: 6| Step: 6
Training loss: 2.949275338343693
Validation loss: 2.473649679639246

Epoch: 6| Step: 7
Training loss: 2.5507530222524064
Validation loss: 2.478679325919257

Epoch: 6| Step: 8
Training loss: 2.628797871819933
Validation loss: 2.4768921064180285

Epoch: 6| Step: 9
Training loss: 2.0650673117762404
Validation loss: 2.4752717610673973

Epoch: 6| Step: 10
Training loss: 2.8826566824632787
Validation loss: 2.4764190375555724

Epoch: 6| Step: 11
Training loss: 2.722647843423177
Validation loss: 2.4723342276023774

Epoch: 6| Step: 12
Training loss: 2.073273466703516
Validation loss: 2.470854879953272

Epoch: 6| Step: 13
Training loss: 2.5180534819603606
Validation loss: 2.471495715081567

Epoch: 88| Step: 0
Training loss: 2.5287285950641514
Validation loss: 2.4696595974903084

Epoch: 6| Step: 1
Training loss: 2.6274199457431737
Validation loss: 2.4714864220451704

Epoch: 6| Step: 2
Training loss: 3.102102237504617
Validation loss: 2.4687873901883663

Epoch: 6| Step: 3
Training loss: 2.349288499949219
Validation loss: 2.468343950833039

Epoch: 6| Step: 4
Training loss: 2.5287939330134734
Validation loss: 2.467453418950343

Epoch: 6| Step: 5
Training loss: 2.491530280915035
Validation loss: 2.4738570557326223

Epoch: 6| Step: 6
Training loss: 2.880179673524245
Validation loss: 2.4746800276845033

Epoch: 6| Step: 7
Training loss: 2.372977449633887
Validation loss: 2.4874596948728933

Epoch: 6| Step: 8
Training loss: 2.784881107388177
Validation loss: 2.4842361475370933

Epoch: 6| Step: 9
Training loss: 2.2509301700072846
Validation loss: 2.4789022790889232

Epoch: 6| Step: 10
Training loss: 2.6367630566300573
Validation loss: 2.466046708292436

Epoch: 6| Step: 11
Training loss: 2.6164124209404402
Validation loss: 2.469045524775392

Epoch: 6| Step: 12
Training loss: 2.69691185423245
Validation loss: 2.4724228574536076

Epoch: 6| Step: 13
Training loss: 2.5539809250205163
Validation loss: 2.47741803174476

Epoch: 89| Step: 0
Training loss: 2.326993526500555
Validation loss: 2.483531848815639

Epoch: 6| Step: 1
Training loss: 2.916938732718699
Validation loss: 2.484715692283997

Epoch: 6| Step: 2
Training loss: 2.524715702179367
Validation loss: 2.4916499882610847

Epoch: 6| Step: 3
Training loss: 2.0545352545781945
Validation loss: 2.497413903026161

Epoch: 6| Step: 4
Training loss: 3.044573574931936
Validation loss: 2.500610563107333

Epoch: 6| Step: 5
Training loss: 2.5166566995924406
Validation loss: 2.5001121495841034

Epoch: 6| Step: 6
Training loss: 2.7710533532767903
Validation loss: 2.5070027185807504

Epoch: 6| Step: 7
Training loss: 2.777703670996676
Validation loss: 2.49868988041118

Epoch: 6| Step: 8
Training loss: 2.445665035490411
Validation loss: 2.49211603618272

Epoch: 6| Step: 9
Training loss: 2.6632273866908576
Validation loss: 2.4945398945613326

Epoch: 6| Step: 10
Training loss: 2.56924007966258
Validation loss: 2.491799813692575

Epoch: 6| Step: 11
Training loss: 2.7052357982308197
Validation loss: 2.4917068655754004

Epoch: 6| Step: 12
Training loss: 2.915599591470544
Validation loss: 2.4874726822725277

Epoch: 6| Step: 13
Training loss: 2.3375742609804173
Validation loss: 2.487886198853157

Epoch: 90| Step: 0
Training loss: 2.5491695248489177
Validation loss: 2.4837646214400846

Epoch: 6| Step: 1
Training loss: 2.4392551069926545
Validation loss: 2.479684652716659

Epoch: 6| Step: 2
Training loss: 2.9121390123093644
Validation loss: 2.4824417717729297

Epoch: 6| Step: 3
Training loss: 1.7425902033791083
Validation loss: 2.4758412848308207

Epoch: 6| Step: 4
Training loss: 2.5488236350535165
Validation loss: 2.4720907825242215

Epoch: 6| Step: 5
Training loss: 2.69174816689261
Validation loss: 2.472159546213597

Epoch: 6| Step: 6
Training loss: 2.17465843938834
Validation loss: 2.4732187122543405

Epoch: 6| Step: 7
Training loss: 2.371345720304722
Validation loss: 2.466447198830153

Epoch: 6| Step: 8
Training loss: 2.619187049539623
Validation loss: 2.4686152908335406

Epoch: 6| Step: 9
Training loss: 3.1928157985371897
Validation loss: 2.462661187952567

Epoch: 6| Step: 10
Training loss: 2.692697865645958
Validation loss: 2.4651955878895055

Epoch: 6| Step: 11
Training loss: 2.731607660754465
Validation loss: 2.46575918795424

Epoch: 6| Step: 12
Training loss: 2.6209766799547176
Validation loss: 2.463681889764598

Epoch: 6| Step: 13
Training loss: 2.6500942933202905
Validation loss: 2.4652930493545924

Epoch: 91| Step: 0
Training loss: 2.5585034536487856
Validation loss: 2.462351494714875

Epoch: 6| Step: 1
Training loss: 3.107249544689192
Validation loss: 2.46220174942254

Epoch: 6| Step: 2
Training loss: 2.823626824234286
Validation loss: 2.469550328963912

Epoch: 6| Step: 3
Training loss: 2.562263850053792
Validation loss: 2.471347488592603

Epoch: 6| Step: 4
Training loss: 2.859199393461363
Validation loss: 2.4720267508472884

Epoch: 6| Step: 5
Training loss: 2.404677037940712
Validation loss: 2.4721841547269934

Epoch: 6| Step: 6
Training loss: 1.9923563567761855
Validation loss: 2.4690201205142808

Epoch: 6| Step: 7
Training loss: 2.6352080814207546
Validation loss: 2.4694458105667314

Epoch: 6| Step: 8
Training loss: 2.37586828722798
Validation loss: 2.4694892967431388

Epoch: 6| Step: 9
Training loss: 2.004766387457658
Validation loss: 2.469761411904433

Epoch: 6| Step: 10
Training loss: 2.752235197795489
Validation loss: 2.470259563048548

Epoch: 6| Step: 11
Training loss: 2.1492990326940773
Validation loss: 2.4715988204228863

Epoch: 6| Step: 12
Training loss: 2.870470542481477
Validation loss: 2.469550618593845

Epoch: 6| Step: 13
Training loss: 2.7852594000720465
Validation loss: 2.4666617530911283

Epoch: 92| Step: 0
Training loss: 2.4770654594818162
Validation loss: 2.467532392815484

Epoch: 6| Step: 1
Training loss: 2.090974476888823
Validation loss: 2.4683327463094806

Epoch: 6| Step: 2
Training loss: 2.543625144799898
Validation loss: 2.4687788273540674

Epoch: 6| Step: 3
Training loss: 2.7725579384889025
Validation loss: 2.469085823428194

Epoch: 6| Step: 4
Training loss: 2.433751378227984
Validation loss: 2.468487504290924

Epoch: 6| Step: 5
Training loss: 2.351682235356233
Validation loss: 2.4702373321890954

Epoch: 6| Step: 6
Training loss: 3.1340144032705446
Validation loss: 2.467212793962643

Epoch: 6| Step: 7
Training loss: 3.070395432145705
Validation loss: 2.4722822327301373

Epoch: 6| Step: 8
Training loss: 2.1397067139984234
Validation loss: 2.4646570907824987

Epoch: 6| Step: 9
Training loss: 2.80195931274803
Validation loss: 2.4656437191818688

Epoch: 6| Step: 10
Training loss: 3.237624300776122
Validation loss: 2.468518451503494

Epoch: 6| Step: 11
Training loss: 2.4180342213975403
Validation loss: 2.4634118129925486

Epoch: 6| Step: 12
Training loss: 1.586703411499595
Validation loss: 2.4617725953581515

Epoch: 6| Step: 13
Training loss: 2.467505225704577
Validation loss: 2.4643126256564543

Epoch: 93| Step: 0
Training loss: 2.4504376896297644
Validation loss: 2.46414543855683

Epoch: 6| Step: 1
Training loss: 2.1910389203053806
Validation loss: 2.465741912300465

Epoch: 6| Step: 2
Training loss: 2.1510910016206704
Validation loss: 2.4684560898575305

Epoch: 6| Step: 3
Training loss: 2.9428627896353925
Validation loss: 2.4640757094121697

Epoch: 6| Step: 4
Training loss: 2.814790937069604
Validation loss: 2.469392588237464

Epoch: 6| Step: 5
Training loss: 2.808205780694512
Validation loss: 2.460709309973324

Epoch: 6| Step: 6
Training loss: 2.7512420970312754
Validation loss: 2.4632390315580386

Epoch: 6| Step: 7
Training loss: 2.702064438407989
Validation loss: 2.464578830933079

Epoch: 6| Step: 8
Training loss: 2.3492901237157118
Validation loss: 2.465838151621733

Epoch: 6| Step: 9
Training loss: 1.9698036644010595
Validation loss: 2.465556956916794

Epoch: 6| Step: 10
Training loss: 2.4566314323448615
Validation loss: 2.46590736361399

Epoch: 6| Step: 11
Training loss: 2.850119029453974
Validation loss: 2.4674765203557616

Epoch: 6| Step: 12
Training loss: 2.9336457635202504
Validation loss: 2.471496430547453

Epoch: 6| Step: 13
Training loss: 2.450831902624718
Validation loss: 2.4767004831024027

Epoch: 94| Step: 0
Training loss: 2.4654209531181928
Validation loss: 2.475493399892551

Epoch: 6| Step: 1
Training loss: 2.5307571496467776
Validation loss: 2.4735044899642635

Epoch: 6| Step: 2
Training loss: 2.73285445305982
Validation loss: 2.4750623361206285

Epoch: 6| Step: 3
Training loss: 2.5779258882332883
Validation loss: 2.4775011788733354

Epoch: 6| Step: 4
Training loss: 2.6165987633643684
Validation loss: 2.4756534805463737

Epoch: 6| Step: 5
Training loss: 3.0241132271877738
Validation loss: 2.4746642273501727

Epoch: 6| Step: 6
Training loss: 2.615872271846381
Validation loss: 2.4729709113667893

Epoch: 6| Step: 7
Training loss: 2.395919422316799
Validation loss: 2.472169495733489

Epoch: 6| Step: 8
Training loss: 2.758652858916522
Validation loss: 2.469498146750015

Epoch: 6| Step: 9
Training loss: 2.7727889041333036
Validation loss: 2.463190345365215

Epoch: 6| Step: 10
Training loss: 2.75954592424883
Validation loss: 2.4610779414394672

Epoch: 6| Step: 11
Training loss: 2.027505327963267
Validation loss: 2.4617946040440923

Epoch: 6| Step: 12
Training loss: 2.249348440138025
Validation loss: 2.460244298114235

Epoch: 6| Step: 13
Training loss: 2.2616803786954462
Validation loss: 2.467247356762161

Epoch: 95| Step: 0
Training loss: 3.0280537221922637
Validation loss: 2.461526838509769

Epoch: 6| Step: 1
Training loss: 2.356672950243453
Validation loss: 2.464522238517217

Epoch: 6| Step: 2
Training loss: 2.501517979394294
Validation loss: 2.466733583839974

Epoch: 6| Step: 3
Training loss: 2.3667199204950027
Validation loss: 2.4657737400201714

Epoch: 6| Step: 4
Training loss: 2.52711799474114
Validation loss: 2.461774621101676

Epoch: 6| Step: 5
Training loss: 2.722155838327793
Validation loss: 2.4605197289501537

Epoch: 6| Step: 6
Training loss: 2.4898864263654135
Validation loss: 2.459223995395832

Epoch: 6| Step: 7
Training loss: 2.586757011441677
Validation loss: 2.461421438600654

Epoch: 6| Step: 8
Training loss: 2.3289722718635213
Validation loss: 2.4661261541970463

Epoch: 6| Step: 9
Training loss: 2.6242955488736657
Validation loss: 2.465350712039089

Epoch: 6| Step: 10
Training loss: 2.8207168077961913
Validation loss: 2.4679138602552593

Epoch: 6| Step: 11
Training loss: 2.988286356204788
Validation loss: 2.465882176797178

Epoch: 6| Step: 12
Training loss: 2.522431825712769
Validation loss: 2.465892369190056

Epoch: 6| Step: 13
Training loss: 1.961221560386891
Validation loss: 2.467293772583947

Epoch: 96| Step: 0
Training loss: 2.8827301261732217
Validation loss: 2.4698077965677196

Epoch: 6| Step: 1
Training loss: 2.5364589077572233
Validation loss: 2.4686078863646417

Epoch: 6| Step: 2
Training loss: 2.274782392553556
Validation loss: 2.466468851646123

Epoch: 6| Step: 3
Training loss: 2.4038103294637496
Validation loss: 2.4660910761768604

Epoch: 6| Step: 4
Training loss: 2.75921854372681
Validation loss: 2.4614555176987745

Epoch: 6| Step: 5
Training loss: 2.2282368036712037
Validation loss: 2.465451511714682

Epoch: 6| Step: 6
Training loss: 2.767363782940166
Validation loss: 2.459051856947358

Epoch: 6| Step: 7
Training loss: 2.7668487944653437
Validation loss: 2.462037856729493

Epoch: 6| Step: 8
Training loss: 3.1711710632628423
Validation loss: 2.4545226195720304

Epoch: 6| Step: 9
Training loss: 2.3255824600261645
Validation loss: 2.4620958942276476

Epoch: 6| Step: 10
Training loss: 1.809226796565293
Validation loss: 2.449970638981525

Epoch: 6| Step: 11
Training loss: 2.3177436968787957
Validation loss: 2.4537586114712555

Epoch: 6| Step: 12
Training loss: 2.9123040587694646
Validation loss: 2.4604648035192653

Epoch: 6| Step: 13
Training loss: 2.4863388648629
Validation loss: 2.458441559515983

Epoch: 97| Step: 0
Training loss: 2.55618941927804
Validation loss: 2.458647664766605

Epoch: 6| Step: 1
Training loss: 2.3673985956825785
Validation loss: 2.4599554938397077

Epoch: 6| Step: 2
Training loss: 2.4234233213854757
Validation loss: 2.45922386613089

Epoch: 6| Step: 3
Training loss: 2.33736332784507
Validation loss: 2.468449586384014

Epoch: 6| Step: 4
Training loss: 2.2692525301838598
Validation loss: 2.4680562151071554

Epoch: 6| Step: 5
Training loss: 3.120718502551611
Validation loss: 2.462459404444547

Epoch: 6| Step: 6
Training loss: 3.2467329770731164
Validation loss: 2.4639602101279787

Epoch: 6| Step: 7
Training loss: 2.3943763172501518
Validation loss: 2.4657263770009847

Epoch: 6| Step: 8
Training loss: 2.0184957479980676
Validation loss: 2.4639418252129768

Epoch: 6| Step: 9
Training loss: 2.3972193703082545
Validation loss: 2.4612945943434417

Epoch: 6| Step: 10
Training loss: 2.492330038843566
Validation loss: 2.4630198715787803

Epoch: 6| Step: 11
Training loss: 2.5753243695737646
Validation loss: 2.4642262760968423

Epoch: 6| Step: 12
Training loss: 2.560674156441528
Validation loss: 2.462287443769396

Epoch: 6| Step: 13
Training loss: 2.8428209065621965
Validation loss: 2.4564568798893536

Epoch: 98| Step: 0
Training loss: 2.694608469249525
Validation loss: 2.4597809995692046

Epoch: 6| Step: 1
Training loss: 1.9225925253639173
Validation loss: 2.450040947967675

Epoch: 6| Step: 2
Training loss: 3.1296713437726553
Validation loss: 2.4579934084519106

Epoch: 6| Step: 3
Training loss: 3.0191168457547835
Validation loss: 2.4604854915423444

Epoch: 6| Step: 4
Training loss: 2.540752705159803
Validation loss: 2.4504156519133082

Epoch: 6| Step: 5
Training loss: 2.2550950113652473
Validation loss: 2.4480927640733676

Epoch: 6| Step: 6
Training loss: 2.0824313181969107
Validation loss: 2.453507946277513

Epoch: 6| Step: 7
Training loss: 2.614254346922899
Validation loss: 2.456657474229748

Epoch: 6| Step: 8
Training loss: 2.2561480977302004
Validation loss: 2.45434611192836

Epoch: 6| Step: 9
Training loss: 2.6149254887835043
Validation loss: 2.450087560010279

Epoch: 6| Step: 10
Training loss: 2.660115111448835
Validation loss: 2.4526961613870983

Epoch: 6| Step: 11
Training loss: 2.752727369849271
Validation loss: 2.453106193713368

Epoch: 6| Step: 12
Training loss: 2.6346482575265053
Validation loss: 2.457091006799129

Epoch: 6| Step: 13
Training loss: 2.3137860201891836
Validation loss: 2.4607277271136443

Epoch: 99| Step: 0
Training loss: 2.161813386610943
Validation loss: 2.4596298376571744

Epoch: 6| Step: 1
Training loss: 2.1093523942654437
Validation loss: 2.4619560596233625

Epoch: 6| Step: 2
Training loss: 2.66507949882295
Validation loss: 2.4625263554797323

Epoch: 6| Step: 3
Training loss: 2.118879142133814
Validation loss: 2.4570596488116028

Epoch: 6| Step: 4
Training loss: 2.572642004099308
Validation loss: 2.457699424566041

Epoch: 6| Step: 5
Training loss: 2.5961188104770536
Validation loss: 2.456491027861198

Epoch: 6| Step: 6
Training loss: 2.6408278708994803
Validation loss: 2.4582925782354548

Epoch: 6| Step: 7
Training loss: 2.2319325789451585
Validation loss: 2.462036888350289

Epoch: 6| Step: 8
Training loss: 2.0415764873077453
Validation loss: 2.463583622602719

Epoch: 6| Step: 9
Training loss: 2.294297205542124
Validation loss: 2.459501188434692

Epoch: 6| Step: 10
Training loss: 2.6552454226868947
Validation loss: 2.4587110186177443

Epoch: 6| Step: 11
Training loss: 2.8432160599357488
Validation loss: 2.466164373685972

Epoch: 6| Step: 12
Training loss: 3.254322552010168
Validation loss: 2.4544645082300227

Epoch: 6| Step: 13
Training loss: 3.2094901505328206
Validation loss: 2.457600926279723

Epoch: 100| Step: 0
Training loss: 2.761759583685262
Validation loss: 2.4565536123717604

Epoch: 6| Step: 1
Training loss: 2.4993793670852713
Validation loss: 2.4647118583008547

Epoch: 6| Step: 2
Training loss: 2.416263897535652
Validation loss: 2.458046659360415

Epoch: 6| Step: 3
Training loss: 2.4247155052128244
Validation loss: 2.4629892747459396

Epoch: 6| Step: 4
Training loss: 2.6946635031602133
Validation loss: 2.458789109690048

Epoch: 6| Step: 5
Training loss: 2.448966419418098
Validation loss: 2.463435282974184

Epoch: 6| Step: 6
Training loss: 2.388681157515948
Validation loss: 2.45650424369447

Epoch: 6| Step: 7
Training loss: 2.6431594513717815
Validation loss: 2.4572780305280055

Epoch: 6| Step: 8
Training loss: 3.0662435889381165
Validation loss: 2.4606870977982704

Epoch: 6| Step: 9
Training loss: 1.7101765512487417
Validation loss: 2.455179872430129

Epoch: 6| Step: 10
Training loss: 2.3329601897739947
Validation loss: 2.4537494132011592

Epoch: 6| Step: 11
Training loss: 3.0516845303701348
Validation loss: 2.4552127191253277

Epoch: 6| Step: 12
Training loss: 2.1437795742652996
Validation loss: 2.4546272877496365

Epoch: 6| Step: 13
Training loss: 2.916953445141531
Validation loss: 2.4635414193430822

Epoch: 101| Step: 0
Training loss: 3.131724484978986
Validation loss: 2.463935833958846

Epoch: 6| Step: 1
Training loss: 2.770456780873638
Validation loss: 2.466358507298656

Epoch: 6| Step: 2
Training loss: 2.734160322208905
Validation loss: 2.4595845050433085

Epoch: 6| Step: 3
Training loss: 2.5300555766639397
Validation loss: 2.467432306218485

Epoch: 6| Step: 4
Training loss: 2.9387710743176463
Validation loss: 2.4633987310019503

Epoch: 6| Step: 5
Training loss: 2.1448385160966863
Validation loss: 2.456927460548934

Epoch: 6| Step: 6
Training loss: 2.54380735290506
Validation loss: 2.4617487866937906

Epoch: 6| Step: 7
Training loss: 2.6410713495729636
Validation loss: 2.4586763196570893

Epoch: 6| Step: 8
Training loss: 2.7033297951797053
Validation loss: 2.455171998545067

Epoch: 6| Step: 9
Training loss: 2.5535444683134174
Validation loss: 2.4530097059624696

Epoch: 6| Step: 10
Training loss: 2.133597763879074
Validation loss: 2.4512718149913666

Epoch: 6| Step: 11
Training loss: 1.8259929385722438
Validation loss: 2.4507562333057265

Epoch: 6| Step: 12
Training loss: 2.452179355950539
Validation loss: 2.452424178070999

Epoch: 6| Step: 13
Training loss: 2.4438389247315295
Validation loss: 2.4499199211891107

Epoch: 102| Step: 0
Training loss: 2.339819498843962
Validation loss: 2.446956337932478

Epoch: 6| Step: 1
Training loss: 2.5596061741872043
Validation loss: 2.4466234944282625

Epoch: 6| Step: 2
Training loss: 3.264069985490235
Validation loss: 2.4503033845901645

Epoch: 6| Step: 3
Training loss: 2.5282007382886937
Validation loss: 2.448918650208402

Epoch: 6| Step: 4
Training loss: 2.6548515677762152
Validation loss: 2.455948162865506

Epoch: 6| Step: 5
Training loss: 2.460459441723776
Validation loss: 2.4566818821805505

Epoch: 6| Step: 6
Training loss: 2.4491866260228834
Validation loss: 2.453570193897692

Epoch: 6| Step: 7
Training loss: 2.8095333983986612
Validation loss: 2.456250679786077

Epoch: 6| Step: 8
Training loss: 2.8958699249224424
Validation loss: 2.457132116045557

Epoch: 6| Step: 9
Training loss: 2.7082414660400773
Validation loss: 2.458869493066789

Epoch: 6| Step: 10
Training loss: 1.9391649537296813
Validation loss: 2.457998824125236

Epoch: 6| Step: 11
Training loss: 2.201300981961257
Validation loss: 2.458044703290986

Epoch: 6| Step: 12
Training loss: 2.6304479105899716
Validation loss: 2.4608044785167387

Epoch: 6| Step: 13
Training loss: 1.94934301802025
Validation loss: 2.460138132564266

Epoch: 103| Step: 0
Training loss: 1.5401444867708403
Validation loss: 2.465446241350861

Epoch: 6| Step: 1
Training loss: 2.690043288382472
Validation loss: 2.460619160079453

Epoch: 6| Step: 2
Training loss: 2.8084937490346493
Validation loss: 2.463178907680658

Epoch: 6| Step: 3
Training loss: 2.998285439408976
Validation loss: 2.464707247364477

Epoch: 6| Step: 4
Training loss: 2.7330323328812747
Validation loss: 2.458239251831149

Epoch: 6| Step: 5
Training loss: 2.5565917591061527
Validation loss: 2.458315466691949

Epoch: 6| Step: 6
Training loss: 2.0076593125384017
Validation loss: 2.461181644661316

Epoch: 6| Step: 7
Training loss: 2.9678500769040697
Validation loss: 2.452889562756977

Epoch: 6| Step: 8
Training loss: 2.6491155515981166
Validation loss: 2.4556960625842708

Epoch: 6| Step: 9
Training loss: 2.405109581146056
Validation loss: 2.446128863319503

Epoch: 6| Step: 10
Training loss: 2.2683853697104372
Validation loss: 2.448614651345718

Epoch: 6| Step: 11
Training loss: 2.0173552427864916
Validation loss: 2.4539257775450407

Epoch: 6| Step: 12
Training loss: 2.668006282335746
Validation loss: 2.454366317253145

Epoch: 6| Step: 13
Training loss: 2.9699946956394494
Validation loss: 2.453963636496273

Epoch: 104| Step: 0
Training loss: 2.9918711522453942
Validation loss: 2.4518470107947725

Epoch: 6| Step: 1
Training loss: 2.3430630503697105
Validation loss: 2.4545227571790917

Epoch: 6| Step: 2
Training loss: 2.4957133736118613
Validation loss: 2.447692720166059

Epoch: 6| Step: 3
Training loss: 2.72629158838341
Validation loss: 2.4464158401582288

Epoch: 6| Step: 4
Training loss: 2.6530954815376084
Validation loss: 2.455627023966787

Epoch: 6| Step: 5
Training loss: 2.304513284596519
Validation loss: 2.446028843159374

Epoch: 6| Step: 6
Training loss: 2.526925808577138
Validation loss: 2.447752575075275

Epoch: 6| Step: 7
Training loss: 1.8389835493047912
Validation loss: 2.4524786354764987

Epoch: 6| Step: 8
Training loss: 2.4832455928928137
Validation loss: 2.4516308115479553

Epoch: 6| Step: 9
Training loss: 2.553931821529979
Validation loss: 2.4466306730874505

Epoch: 6| Step: 10
Training loss: 2.5197133079814744
Validation loss: 2.4500209340349466

Epoch: 6| Step: 11
Training loss: 2.402935073153204
Validation loss: 2.44921909070659

Epoch: 6| Step: 12
Training loss: 2.99063077824432
Validation loss: 2.446233330229456

Epoch: 6| Step: 13
Training loss: 2.610829479053557
Validation loss: 2.4524472833243833

Epoch: 105| Step: 0
Training loss: 2.2733692276918545
Validation loss: 2.4613541507722294

Epoch: 6| Step: 1
Training loss: 2.654465558416208
Validation loss: 2.469494622841986

Epoch: 6| Step: 2
Training loss: 2.3700344981326467
Validation loss: 2.470018889680568

Epoch: 6| Step: 3
Training loss: 2.7706516081988535
Validation loss: 2.4727080441675433

Epoch: 6| Step: 4
Training loss: 2.0282126385719974
Validation loss: 2.471889479410273

Epoch: 6| Step: 5
Training loss: 2.337938453229701
Validation loss: 2.4737246326021634

Epoch: 6| Step: 6
Training loss: 3.0628518661461706
Validation loss: 2.4724166215647188

Epoch: 6| Step: 7
Training loss: 2.1769972302021006
Validation loss: 2.4744398806202086

Epoch: 6| Step: 8
Training loss: 3.0382664282612084
Validation loss: 2.4668064917635935

Epoch: 6| Step: 9
Training loss: 2.73138464763813
Validation loss: 2.46332097963669

Epoch: 6| Step: 10
Training loss: 2.34589074597024
Validation loss: 2.4627448010313446

Epoch: 6| Step: 11
Training loss: 2.998823889028368
Validation loss: 2.4629325086686142

Epoch: 6| Step: 12
Training loss: 2.4596017270114237
Validation loss: 2.456389326652766

Epoch: 6| Step: 13
Training loss: 2.3737080724306767
Validation loss: 2.4511849249787487

Epoch: 106| Step: 0
Training loss: 2.148965444721013
Validation loss: 2.4522578818770486

Epoch: 6| Step: 1
Training loss: 2.8948901902424575
Validation loss: 2.4498109725120933

Epoch: 6| Step: 2
Training loss: 2.4614251516470382
Validation loss: 2.4601999459253037

Epoch: 6| Step: 3
Training loss: 2.9614009444161504
Validation loss: 2.4527490250786386

Epoch: 6| Step: 4
Training loss: 2.1827362505975962
Validation loss: 2.4553341890063085

Epoch: 6| Step: 5
Training loss: 2.5724180925117683
Validation loss: 2.4552653829759934

Epoch: 6| Step: 6
Training loss: 2.50678771759842
Validation loss: 2.4494954692588173

Epoch: 6| Step: 7
Training loss: 2.7075164932495355
Validation loss: 2.451798746668876

Epoch: 6| Step: 8
Training loss: 2.4948935809784984
Validation loss: 2.458544549650746

Epoch: 6| Step: 9
Training loss: 2.2738240231318225
Validation loss: 2.451366085550393

Epoch: 6| Step: 10
Training loss: 2.5291385085556275
Validation loss: 2.454033928235299

Epoch: 6| Step: 11
Training loss: 2.601547103698811
Validation loss: 2.447328071984843

Epoch: 6| Step: 12
Training loss: 2.6449756784168175
Validation loss: 2.455528766199223

Epoch: 6| Step: 13
Training loss: 2.546803104813464
Validation loss: 2.4595198004175605

Epoch: 107| Step: 0
Training loss: 2.440471109967587
Validation loss: 2.4607230683410632

Epoch: 6| Step: 1
Training loss: 2.221644058780248
Validation loss: 2.4594698773332357

Epoch: 6| Step: 2
Training loss: 1.9036648841109913
Validation loss: 2.4550372403305643

Epoch: 6| Step: 3
Training loss: 2.366783586040738
Validation loss: 2.454423661908397

Epoch: 6| Step: 4
Training loss: 2.778984089754016
Validation loss: 2.448975749233101

Epoch: 6| Step: 5
Training loss: 2.994995393319639
Validation loss: 2.446260116314523

Epoch: 6| Step: 6
Training loss: 2.3679391404141024
Validation loss: 2.445721211265243

Epoch: 6| Step: 7
Training loss: 2.686080735289187
Validation loss: 2.4486257513595144

Epoch: 6| Step: 8
Training loss: 2.78911122511929
Validation loss: 2.447974741361826

Epoch: 6| Step: 9
Training loss: 2.4281274626141287
Validation loss: 2.4459957025583257

Epoch: 6| Step: 10
Training loss: 2.7764312489861296
Validation loss: 2.4503258773866023

Epoch: 6| Step: 11
Training loss: 2.5321678098901437
Validation loss: 2.4584809652277824

Epoch: 6| Step: 12
Training loss: 2.331389730320951
Validation loss: 2.46011908914898

Epoch: 6| Step: 13
Training loss: 2.8823463455894083
Validation loss: 2.4551137649996133

Epoch: 108| Step: 0
Training loss: 3.113752953992351
Validation loss: 2.457393164733039

Epoch: 6| Step: 1
Training loss: 2.4130705242830293
Validation loss: 2.460610350808341

Epoch: 6| Step: 2
Training loss: 1.940333724468755
Validation loss: 2.459179156211473

Epoch: 6| Step: 3
Training loss: 3.14189691551492
Validation loss: 2.4567011786857176

Epoch: 6| Step: 4
Training loss: 2.2306571920930556
Validation loss: 2.4582210342706134

Epoch: 6| Step: 5
Training loss: 2.549610003399264
Validation loss: 2.456882991876432

Epoch: 6| Step: 6
Training loss: 2.4839336075133778
Validation loss: 2.4528466732933096

Epoch: 6| Step: 7
Training loss: 2.4125874281147035
Validation loss: 2.4548527329113217

Epoch: 6| Step: 8
Training loss: 2.4974177375816704
Validation loss: 2.446471949966099

Epoch: 6| Step: 9
Training loss: 2.9601081753630347
Validation loss: 2.4480085044569755

Epoch: 6| Step: 10
Training loss: 2.529682568927598
Validation loss: 2.4475694342464234

Epoch: 6| Step: 11
Training loss: 2.493132026606996
Validation loss: 2.4467938276121473

Epoch: 6| Step: 12
Training loss: 2.2948669167289037
Validation loss: 2.451768990340783

Epoch: 6| Step: 13
Training loss: 2.2356812186953663
Validation loss: 2.454044777045841

Epoch: 109| Step: 0
Training loss: 2.1822831207569346
Validation loss: 2.4500020552646036

Epoch: 6| Step: 1
Training loss: 2.408468239601559
Validation loss: 2.450185954893409

Epoch: 6| Step: 2
Training loss: 2.1266695083949956
Validation loss: 2.447028617210361

Epoch: 6| Step: 3
Training loss: 1.8639393410042504
Validation loss: 2.45147537844931

Epoch: 6| Step: 4
Training loss: 2.8990341353892086
Validation loss: 2.4551921808884587

Epoch: 6| Step: 5
Training loss: 1.9647612355313009
Validation loss: 2.4547357312860116

Epoch: 6| Step: 6
Training loss: 3.3220382693369825
Validation loss: 2.454453272726172

Epoch: 6| Step: 7
Training loss: 2.1406574107591427
Validation loss: 2.4587672437933614

Epoch: 6| Step: 8
Training loss: 2.5614592136558914
Validation loss: 2.459512142379163

Epoch: 6| Step: 9
Training loss: 2.677269203076558
Validation loss: 2.466969729398237

Epoch: 6| Step: 10
Training loss: 2.8194553414704737
Validation loss: 2.4591177534795094

Epoch: 6| Step: 11
Training loss: 2.75843263737384
Validation loss: 2.4616098767055266

Epoch: 6| Step: 12
Training loss: 2.7406050852070503
Validation loss: 2.459849921600419

Epoch: 6| Step: 13
Training loss: 2.6930645842912075
Validation loss: 2.461954526305172

Epoch: 110| Step: 0
Training loss: 2.1579918943576413
Validation loss: 2.457176572123752

Epoch: 6| Step: 1
Training loss: 2.12280586510066
Validation loss: 2.45839660907929

Epoch: 6| Step: 2
Training loss: 1.7526526101962099
Validation loss: 2.4534714245632196

Epoch: 6| Step: 3
Training loss: 2.0199665950619123
Validation loss: 2.456729411480312

Epoch: 6| Step: 4
Training loss: 2.540769032880081
Validation loss: 2.453343246049481

Epoch: 6| Step: 5
Training loss: 2.192483185167547
Validation loss: 2.4506147949711936

Epoch: 6| Step: 6
Training loss: 2.939701635051591
Validation loss: 2.4575330487677944

Epoch: 6| Step: 7
Training loss: 2.1871236204871285
Validation loss: 2.4585274495786757

Epoch: 6| Step: 8
Training loss: 2.610131433911887
Validation loss: 2.459497003950401

Epoch: 6| Step: 9
Training loss: 2.843223606897776
Validation loss: 2.4621591270746386

Epoch: 6| Step: 10
Training loss: 2.492685489467505
Validation loss: 2.4610919237883873

Epoch: 6| Step: 11
Training loss: 2.793801776995037
Validation loss: 2.4634503730057866

Epoch: 6| Step: 12
Training loss: 3.430820703663133
Validation loss: 2.4655540156329785

Epoch: 6| Step: 13
Training loss: 2.9723723146880547
Validation loss: 2.4653395745019773

Epoch: 111| Step: 0
Training loss: 2.8819709521278476
Validation loss: 2.4659630540883666

Epoch: 6| Step: 1
Training loss: 2.687269688873319
Validation loss: 2.4617377700643917

Epoch: 6| Step: 2
Training loss: 3.065902065935126
Validation loss: 2.4583075624397495

Epoch: 6| Step: 3
Training loss: 1.8675979099370652
Validation loss: 2.4527315119806476

Epoch: 6| Step: 4
Training loss: 2.801118072303731
Validation loss: 2.45534026598394

Epoch: 6| Step: 5
Training loss: 2.2770346796597205
Validation loss: 2.4576109994143795

Epoch: 6| Step: 6
Training loss: 2.7511564770773664
Validation loss: 2.4628599539573095

Epoch: 6| Step: 7
Training loss: 2.224501984828373
Validation loss: 2.463351644939178

Epoch: 6| Step: 8
Training loss: 2.467737207422265
Validation loss: 2.4550473077984964

Epoch: 6| Step: 9
Training loss: 2.298865461410904
Validation loss: 2.4589666315942944

Epoch: 6| Step: 10
Training loss: 3.030437557239891
Validation loss: 2.460861624703534

Epoch: 6| Step: 11
Training loss: 2.5150195038723653
Validation loss: 2.4452207342932297

Epoch: 6| Step: 12
Training loss: 2.2416149298879335
Validation loss: 2.4550941161264874

Epoch: 6| Step: 13
Training loss: 2.499317552879797
Validation loss: 2.4586691115209267

Epoch: 112| Step: 0
Training loss: 2.530927943710785
Validation loss: 2.463833883642296

Epoch: 6| Step: 1
Training loss: 2.4923989137527482
Validation loss: 2.466884487647056

Epoch: 6| Step: 2
Training loss: 2.724092167811675
Validation loss: 2.4692905333244815

Epoch: 6| Step: 3
Training loss: 2.0984302421211396
Validation loss: 2.4719531047327505

Epoch: 6| Step: 4
Training loss: 2.737236226233155
Validation loss: 2.472563144724799

Epoch: 6| Step: 5
Training loss: 2.868728431504227
Validation loss: 2.477134141221801

Epoch: 6| Step: 6
Training loss: 2.759962589176227
Validation loss: 2.476585171472406

Epoch: 6| Step: 7
Training loss: 2.9704804848050945
Validation loss: 2.474962537976485

Epoch: 6| Step: 8
Training loss: 3.046898161971258
Validation loss: 2.4765081790778996

Epoch: 6| Step: 9
Training loss: 2.8295215509581166
Validation loss: 2.4722377589686473

Epoch: 6| Step: 10
Training loss: 1.9259998746814468
Validation loss: 2.4699430761714907

Epoch: 6| Step: 11
Training loss: 2.01477221997641
Validation loss: 2.4648961274737786

Epoch: 6| Step: 12
Training loss: 2.3131837607225156
Validation loss: 2.45680851171856

Epoch: 6| Step: 13
Training loss: 2.2802458342815366
Validation loss: 2.459130728974051

Epoch: 113| Step: 0
Training loss: 2.07152835483467
Validation loss: 2.454616554832782

Epoch: 6| Step: 1
Training loss: 2.1901125973884317
Validation loss: 2.458876571332339

Epoch: 6| Step: 2
Training loss: 2.7618656793813896
Validation loss: 2.4478948930353672

Epoch: 6| Step: 3
Training loss: 2.388469247653162
Validation loss: 2.4476324741618325

Epoch: 6| Step: 4
Training loss: 2.1889899493004594
Validation loss: 2.449676292469386

Epoch: 6| Step: 5
Training loss: 1.7348908353206942
Validation loss: 2.449488071882664

Epoch: 6| Step: 6
Training loss: 1.9781310601164208
Validation loss: 2.449803981594878

Epoch: 6| Step: 7
Training loss: 2.9096228603573624
Validation loss: 2.451985282741768

Epoch: 6| Step: 8
Training loss: 2.732919185556037
Validation loss: 2.4431931936954907

Epoch: 6| Step: 9
Training loss: 2.716527622463721
Validation loss: 2.4468923874225497

Epoch: 6| Step: 10
Training loss: 3.1650488552282168
Validation loss: 2.4509729879678823

Epoch: 6| Step: 11
Training loss: 2.115389352406353
Validation loss: 2.4533475544075047

Epoch: 6| Step: 12
Training loss: 3.2750739693478232
Validation loss: 2.4624753799111367

Epoch: 6| Step: 13
Training loss: 2.9586788208574166
Validation loss: 2.4600927124023833

Epoch: 114| Step: 0
Training loss: 2.5113643793742857
Validation loss: 2.4502747939531937

Epoch: 6| Step: 1
Training loss: 2.311403994260332
Validation loss: 2.4516542079184545

Epoch: 6| Step: 2
Training loss: 2.0898063299804055
Validation loss: 2.459114893367518

Epoch: 6| Step: 3
Training loss: 2.453919688967996
Validation loss: 2.462617847443406

Epoch: 6| Step: 4
Training loss: 3.39737686618998
Validation loss: 2.4690499425312114

Epoch: 6| Step: 5
Training loss: 2.3368240766340795
Validation loss: 2.465567505218114

Epoch: 6| Step: 6
Training loss: 2.32745085306859
Validation loss: 2.470743959514127

Epoch: 6| Step: 7
Training loss: 2.7064256747625484
Validation loss: 2.4676573625042466

Epoch: 6| Step: 8
Training loss: 2.850161524428402
Validation loss: 2.469649694173416

Epoch: 6| Step: 9
Training loss: 2.4901951207077686
Validation loss: 2.4637073248772485

Epoch: 6| Step: 10
Training loss: 2.9401890235911363
Validation loss: 2.4615732169143003

Epoch: 6| Step: 11
Training loss: 2.3368984529553374
Validation loss: 2.459951164748146

Epoch: 6| Step: 12
Training loss: 2.244029707196905
Validation loss: 2.4622896788833546

Epoch: 6| Step: 13
Training loss: 2.3195691700164853
Validation loss: 2.4592307575586365

Epoch: 115| Step: 0
Training loss: 2.673907839560004
Validation loss: 2.458075143434734

Epoch: 6| Step: 1
Training loss: 2.641889100281932
Validation loss: 2.45813042940196

Epoch: 6| Step: 2
Training loss: 1.8765447610974328
Validation loss: 2.4567565117465

Epoch: 6| Step: 3
Training loss: 2.858382089123047
Validation loss: 2.452034515525831

Epoch: 6| Step: 4
Training loss: 3.0019543957381827
Validation loss: 2.45460899481642

Epoch: 6| Step: 5
Training loss: 2.2946742926623633
Validation loss: 2.4586797459386176

Epoch: 6| Step: 6
Training loss: 2.2922264340246383
Validation loss: 2.454205738613667

Epoch: 6| Step: 7
Training loss: 2.405589421743332
Validation loss: 2.4532925817829927

Epoch: 6| Step: 8
Training loss: 3.108704154332644
Validation loss: 2.4592800957393037

Epoch: 6| Step: 9
Training loss: 2.468638550379426
Validation loss: 2.4574033195697753

Epoch: 6| Step: 10
Training loss: 2.209001643942225
Validation loss: 2.459165857802486

Epoch: 6| Step: 11
Training loss: 2.5515473925393803
Validation loss: 2.4537755990308425

Epoch: 6| Step: 12
Training loss: 2.472701567947175
Validation loss: 2.452263375032859

Epoch: 6| Step: 13
Training loss: 2.570458683390491
Validation loss: 2.456298379203225

Epoch: 116| Step: 0
Training loss: 2.6273670423497797
Validation loss: 2.453607985457593

Epoch: 6| Step: 1
Training loss: 2.680774968533406
Validation loss: 2.4522371568509747

Epoch: 6| Step: 2
Training loss: 2.5846155942577935
Validation loss: 2.451201687209766

Epoch: 6| Step: 3
Training loss: 2.097723762661813
Validation loss: 2.453392273421215

Epoch: 6| Step: 4
Training loss: 2.40856841720835
Validation loss: 2.4477587114600583

Epoch: 6| Step: 5
Training loss: 2.6386645561924316
Validation loss: 2.4561130605223616

Epoch: 6| Step: 6
Training loss: 2.956810966964299
Validation loss: 2.455381647293214

Epoch: 6| Step: 7
Training loss: 2.234069910094511
Validation loss: 2.4560168365130264

Epoch: 6| Step: 8
Training loss: 2.639857524870884
Validation loss: 2.457868456663297

Epoch: 6| Step: 9
Training loss: 2.527798595505765
Validation loss: 2.4547156423165153

Epoch: 6| Step: 10
Training loss: 2.411559155679232
Validation loss: 2.454967236296995

Epoch: 6| Step: 11
Training loss: 2.661052177677427
Validation loss: 2.452676063812861

Epoch: 6| Step: 12
Training loss: 2.3012440965567422
Validation loss: 2.4559482923028595

Epoch: 6| Step: 13
Training loss: 2.598182292248733
Validation loss: 2.457094467635531

Epoch: 117| Step: 0
Training loss: 2.486170090224982
Validation loss: 2.455719031875641

Epoch: 6| Step: 1
Training loss: 2.4328982613110104
Validation loss: 2.4509750469560867

Epoch: 6| Step: 2
Training loss: 2.5725952029985617
Validation loss: 2.450634868912955

Epoch: 6| Step: 3
Training loss: 2.277989814420708
Validation loss: 2.4505779706973874

Epoch: 6| Step: 4
Training loss: 2.460841198202557
Validation loss: 2.4476854147473808

Epoch: 6| Step: 5
Training loss: 2.0642731875964926
Validation loss: 2.451280884769445

Epoch: 6| Step: 6
Training loss: 3.0221250381302474
Validation loss: 2.447034170820765

Epoch: 6| Step: 7
Training loss: 2.6968261891143843
Validation loss: 2.451338309707895

Epoch: 6| Step: 8
Training loss: 2.439788233369393
Validation loss: 2.450685604338104

Epoch: 6| Step: 9
Training loss: 2.6092735773351543
Validation loss: 2.445453619414263

Epoch: 6| Step: 10
Training loss: 2.4779888101221967
Validation loss: 2.451091595838429

Epoch: 6| Step: 11
Training loss: 3.070506004855632
Validation loss: 2.4508337509568254

Epoch: 6| Step: 12
Training loss: 2.1954877790207785
Validation loss: 2.4481616174957144

Epoch: 6| Step: 13
Training loss: 2.578888751100318
Validation loss: 2.4553524522612715

Epoch: 118| Step: 0
Training loss: 2.3154216558670275
Validation loss: 2.4501335224435246

Epoch: 6| Step: 1
Training loss: 2.6395610042632187
Validation loss: 2.450079661650708

Epoch: 6| Step: 2
Training loss: 2.699440269378883
Validation loss: 2.4498609951056336

Epoch: 6| Step: 3
Training loss: 2.6890343123204867
Validation loss: 2.44271385880898

Epoch: 6| Step: 4
Training loss: 2.0502169750108896
Validation loss: 2.453060967324417

Epoch: 6| Step: 5
Training loss: 2.5981638476982325
Validation loss: 2.4524882273726845

Epoch: 6| Step: 6
Training loss: 2.827216408131539
Validation loss: 2.452056060635027

Epoch: 6| Step: 7
Training loss: 2.6278170047956837
Validation loss: 2.4495474611517154

Epoch: 6| Step: 8
Training loss: 2.485319138111184
Validation loss: 2.451979367610673

Epoch: 6| Step: 9
Training loss: 2.455665876126498
Validation loss: 2.451830107113989

Epoch: 6| Step: 10
Training loss: 2.371551017095051
Validation loss: 2.4537759876866923

Epoch: 6| Step: 11
Training loss: 2.3639526422343073
Validation loss: 2.457383106875671

Epoch: 6| Step: 12
Training loss: 2.360936639610149
Validation loss: 2.4465861471952057

Epoch: 6| Step: 13
Training loss: 2.8325614064656968
Validation loss: 2.4537420286495095

Epoch: 119| Step: 0
Training loss: 2.8488761894662455
Validation loss: 2.449791913700121

Epoch: 6| Step: 1
Training loss: 2.5074186877438263
Validation loss: 2.4479520808695088

Epoch: 6| Step: 2
Training loss: 2.424268954485884
Validation loss: 2.4503818814444815

Epoch: 6| Step: 3
Training loss: 1.9571835883081832
Validation loss: 2.446453279324725

Epoch: 6| Step: 4
Training loss: 2.2857528559802405
Validation loss: 2.455260665286203

Epoch: 6| Step: 5
Training loss: 2.296066868622416
Validation loss: 2.4506811372631017

Epoch: 6| Step: 6
Training loss: 2.7153626309724976
Validation loss: 2.4467074606852806

Epoch: 6| Step: 7
Training loss: 2.8136160437592084
Validation loss: 2.452144580768655

Epoch: 6| Step: 8
Training loss: 2.5064400693591424
Validation loss: 2.447781844518355

Epoch: 6| Step: 9
Training loss: 2.785175082663362
Validation loss: 2.449300518222387

Epoch: 6| Step: 10
Training loss: 2.5599982912832755
Validation loss: 2.445713648123291

Epoch: 6| Step: 11
Training loss: 2.2435759920530214
Validation loss: 2.4546090271934133

Epoch: 6| Step: 12
Training loss: 2.5753378859376115
Validation loss: 2.4559596827632495

Epoch: 6| Step: 13
Training loss: 2.609729582856428
Validation loss: 2.449326337918381

Epoch: 120| Step: 0
Training loss: 2.4459211183181915
Validation loss: 2.449223828145694

Epoch: 6| Step: 1
Training loss: 3.1446615061822403
Validation loss: 2.454861117705747

Epoch: 6| Step: 2
Training loss: 2.426370202162208
Validation loss: 2.452376848888447

Epoch: 6| Step: 3
Training loss: 1.9186098849055149
Validation loss: 2.454959386009217

Epoch: 6| Step: 4
Training loss: 1.56089845595153
Validation loss: 2.4586961580841606

Epoch: 6| Step: 5
Training loss: 2.6319302402226
Validation loss: 2.4600233287402933

Epoch: 6| Step: 6
Training loss: 2.6586873260270574
Validation loss: 2.461524481630516

Epoch: 6| Step: 7
Training loss: 2.1237807422408936
Validation loss: 2.457415754336588

Epoch: 6| Step: 8
Training loss: 2.3161598318946655
Validation loss: 2.454859749917878

Epoch: 6| Step: 9
Training loss: 3.12584659552924
Validation loss: 2.4520437526398315

Epoch: 6| Step: 10
Training loss: 2.3624516315655684
Validation loss: 2.447655786992547

Epoch: 6| Step: 11
Training loss: 2.6377953711989495
Validation loss: 2.444108124075328

Epoch: 6| Step: 12
Training loss: 2.3220772245709957
Validation loss: 2.4500359931559585

Epoch: 6| Step: 13
Training loss: 3.154267850098659
Validation loss: 2.450674546083119

Epoch: 121| Step: 0
Training loss: 2.6847104521329657
Validation loss: 2.4552876199234746

Epoch: 6| Step: 1
Training loss: 2.1270460488554113
Validation loss: 2.4473638897911254

Epoch: 6| Step: 2
Training loss: 2.796024384961191
Validation loss: 2.4571339596384485

Epoch: 6| Step: 3
Training loss: 2.7410773396594683
Validation loss: 2.450802183198649

Epoch: 6| Step: 4
Training loss: 2.000738246087656
Validation loss: 2.4454123788409183

Epoch: 6| Step: 5
Training loss: 2.915669425143445
Validation loss: 2.455484571576868

Epoch: 6| Step: 6
Training loss: 2.76734793061729
Validation loss: 2.4538792546036396

Epoch: 6| Step: 7
Training loss: 2.762507691523689
Validation loss: 2.460438567755048

Epoch: 6| Step: 8
Training loss: 2.2890553132553033
Validation loss: 2.4601766065972988

Epoch: 6| Step: 9
Training loss: 2.8186588247232813
Validation loss: 2.458659656870828

Epoch: 6| Step: 10
Training loss: 2.400619260050638
Validation loss: 2.454783775793677

Epoch: 6| Step: 11
Training loss: 2.1801643533610067
Validation loss: 2.4568343010320333

Epoch: 6| Step: 12
Training loss: 2.7739711194394894
Validation loss: 2.4498385710310444

Epoch: 6| Step: 13
Training loss: 2.2319943209681847
Validation loss: 2.4518460059771208

Epoch: 122| Step: 0
Training loss: 1.9617108647572756
Validation loss: 2.450563109489615

Epoch: 6| Step: 1
Training loss: 3.495641583233352
Validation loss: 2.447110263757035

Epoch: 6| Step: 2
Training loss: 2.7320176780653744
Validation loss: 2.4608269076247846

Epoch: 6| Step: 3
Training loss: 2.4385437320231724
Validation loss: 2.467616879491654

Epoch: 6| Step: 4
Training loss: 2.617847325290433
Validation loss: 2.4612073881517125

Epoch: 6| Step: 5
Training loss: 2.441468358584989
Validation loss: 2.453493062327431

Epoch: 6| Step: 6
Training loss: 1.8330128852070857
Validation loss: 2.4623777020288196

Epoch: 6| Step: 7
Training loss: 2.675208260103186
Validation loss: 2.4501812030968306

Epoch: 6| Step: 8
Training loss: 2.5744651016652726
Validation loss: 2.45715113409524

Epoch: 6| Step: 9
Training loss: 2.201807588643855
Validation loss: 2.4620459910997696

Epoch: 6| Step: 10
Training loss: 2.4267676370525475
Validation loss: 2.4519265359438918

Epoch: 6| Step: 11
Training loss: 2.3590536340791224
Validation loss: 2.4581806544936753

Epoch: 6| Step: 12
Training loss: 2.4644638711885793
Validation loss: 2.460868487323914

Epoch: 6| Step: 13
Training loss: 2.8077934727265537
Validation loss: 2.470148937610168

Epoch: 123| Step: 0
Training loss: 1.9673712004560582
Validation loss: 2.473244900814784

Epoch: 6| Step: 1
Training loss: 2.6116724008457877
Validation loss: 2.4746579971093103

Epoch: 6| Step: 2
Training loss: 2.303139583795096
Validation loss: 2.4687573396597777

Epoch: 6| Step: 3
Training loss: 2.613782073471332
Validation loss: 2.46789716323118

Epoch: 6| Step: 4
Training loss: 1.9997273497702603
Validation loss: 2.469137233833793

Epoch: 6| Step: 5
Training loss: 2.81015204863331
Validation loss: 2.4746749616330095

Epoch: 6| Step: 6
Training loss: 2.8737299228413224
Validation loss: 2.469933704897099

Epoch: 6| Step: 7
Training loss: 2.314766778094284
Validation loss: 2.471683578056088

Epoch: 6| Step: 8
Training loss: 2.808932691132304
Validation loss: 2.467602942167167

Epoch: 6| Step: 9
Training loss: 2.7164139632037907
Validation loss: 2.471052633098825

Epoch: 6| Step: 10
Training loss: 2.9110800691297167
Validation loss: 2.47063941923695

Epoch: 6| Step: 11
Training loss: 2.913722777826571
Validation loss: 2.467815173890239

Epoch: 6| Step: 12
Training loss: 1.8949243511308806
Validation loss: 2.4586084233482417

Epoch: 6| Step: 13
Training loss: 2.8097769376520927
Validation loss: 2.461938757282682

Epoch: 124| Step: 0
Training loss: 2.392127568386828
Validation loss: 2.4686514436388247

Epoch: 6| Step: 1
Training loss: 2.5419272825943624
Validation loss: 2.460979449202238

Epoch: 6| Step: 2
Training loss: 2.868366383685942
Validation loss: 2.4573824277262624

Epoch: 6| Step: 3
Training loss: 2.5473894407111146
Validation loss: 2.4653082408425795

Epoch: 6| Step: 4
Training loss: 2.6284227309165247
Validation loss: 2.460379869367316

Epoch: 6| Step: 5
Training loss: 2.25107506393755
Validation loss: 2.463531063989858

Epoch: 6| Step: 6
Training loss: 2.17432095681157
Validation loss: 2.4621245896820874

Epoch: 6| Step: 7
Training loss: 1.790473747855649
Validation loss: 2.4596407587179505

Epoch: 6| Step: 8
Training loss: 2.1573611727326183
Validation loss: 2.4592567638394556

Epoch: 6| Step: 9
Training loss: 2.858165881383614
Validation loss: 2.4597758624460666

Epoch: 6| Step: 10
Training loss: 2.796265775510704
Validation loss: 2.459852578932934

Epoch: 6| Step: 11
Training loss: 2.6924449759893827
Validation loss: 2.4595088303509502

Epoch: 6| Step: 12
Training loss: 3.1895245872849936
Validation loss: 2.4638426410683567

Epoch: 6| Step: 13
Training loss: 2.3118668797853896
Validation loss: 2.4556521541511316

Epoch: 125| Step: 0
Training loss: 2.7927744551081264
Validation loss: 2.466040585187777

Epoch: 6| Step: 1
Training loss: 2.565073442355785
Validation loss: 2.4652334510746283

Epoch: 6| Step: 2
Training loss: 2.2008362914526156
Validation loss: 2.4680278462266716

Epoch: 6| Step: 3
Training loss: 2.42773142881207
Validation loss: 2.453912450666588

Epoch: 6| Step: 4
Training loss: 2.3955557842093325
Validation loss: 2.45833678703281

Epoch: 6| Step: 5
Training loss: 2.7052037178933412
Validation loss: 2.4658465796352598

Epoch: 6| Step: 6
Training loss: 3.109248019745452
Validation loss: 2.46598380878142

Epoch: 6| Step: 7
Training loss: 2.7017366228532267
Validation loss: 2.4613710697659235

Epoch: 6| Step: 8
Training loss: 2.4576521969735796
Validation loss: 2.4675481744023187

Epoch: 6| Step: 9
Training loss: 2.2154107553822784
Validation loss: 2.460533246135176

Epoch: 6| Step: 10
Training loss: 2.2908652435925903
Validation loss: 2.460918713048846

Epoch: 6| Step: 11
Training loss: 2.4130260625286217
Validation loss: 2.45838076874394

Epoch: 6| Step: 12
Training loss: 2.5607690314692064
Validation loss: 2.4538920472859593

Epoch: 6| Step: 13
Training loss: 2.220572032430968
Validation loss: 2.451169443319262

Testing loss: 2.003259909823744
