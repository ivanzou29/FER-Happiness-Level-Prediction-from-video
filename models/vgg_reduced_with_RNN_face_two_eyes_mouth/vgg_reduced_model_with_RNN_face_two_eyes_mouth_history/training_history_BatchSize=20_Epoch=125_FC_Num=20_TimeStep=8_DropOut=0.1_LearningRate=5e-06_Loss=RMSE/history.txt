Epoch: 1| Step: 0
Training loss: 5.820227295936748
Validation loss: 5.8545403909912626

Epoch: 5| Step: 1
Training loss: 5.0232168953067236
Validation loss: 5.85248223322828

Epoch: 5| Step: 2
Training loss: 5.61041913103894
Validation loss: 5.850443795479531

Epoch: 5| Step: 3
Training loss: 5.091344909157971
Validation loss: 5.848379045867483

Epoch: 5| Step: 4
Training loss: 6.141094316015132
Validation loss: 5.846267885337508

Epoch: 5| Step: 5
Training loss: 6.689776166926231
Validation loss: 5.844242517180438

Epoch: 5| Step: 6
Training loss: 6.076686345645904
Validation loss: 5.842037459979812

Epoch: 5| Step: 7
Training loss: 6.197162520317073
Validation loss: 5.839866075079696

Epoch: 5| Step: 8
Training loss: 7.381840265431493
Validation loss: 5.837730285545898

Epoch: 5| Step: 9
Training loss: 5.54814713625259
Validation loss: 5.835542487581536

Epoch: 5| Step: 10
Training loss: 6.005328673198872
Validation loss: 5.833312813404867

Epoch: 5| Step: 11
Training loss: 3.3737115166509137
Validation loss: 5.831021881820469

Epoch: 2| Step: 0
Training loss: 5.721246560053825
Validation loss: 5.8287809137512685

Epoch: 5| Step: 1
Training loss: 4.870840596807376
Validation loss: 5.826498648430964

Epoch: 5| Step: 2
Training loss: 6.335564504761525
Validation loss: 5.82403408604645

Epoch: 5| Step: 3
Training loss: 6.617634835824088
Validation loss: 5.821542958844463

Epoch: 5| Step: 4
Training loss: 6.033630217664621
Validation loss: 5.818888964224566

Epoch: 5| Step: 5
Training loss: 6.241312932515243
Validation loss: 5.815986394406286

Epoch: 5| Step: 6
Training loss: 5.903579996485382
Validation loss: 5.812997899213746

Epoch: 5| Step: 7
Training loss: 5.708832359312916
Validation loss: 5.809886153238856

Epoch: 5| Step: 8
Training loss: 5.64674717262884
Validation loss: 5.80652034637943

Epoch: 5| Step: 9
Training loss: 6.017657048228791
Validation loss: 5.8031691854065315

Epoch: 5| Step: 10
Training loss: 5.95085553341617
Validation loss: 5.799618355482933

Epoch: 5| Step: 11
Training loss: 6.070006452428163
Validation loss: 5.795579160505394

Epoch: 3| Step: 0
Training loss: 5.687182742482144
Validation loss: 5.791824292935555

Epoch: 5| Step: 1
Training loss: 5.881981455348567
Validation loss: 5.787875741525538

Epoch: 5| Step: 2
Training loss: 5.118246886106002
Validation loss: 5.783548740072865

Epoch: 5| Step: 3
Training loss: 5.7280058453492755
Validation loss: 5.779134566097131

Epoch: 5| Step: 4
Training loss: 5.904258109573369
Validation loss: 5.774581121415882

Epoch: 5| Step: 5
Training loss: 6.255799921177834
Validation loss: 5.76993214517205

Epoch: 5| Step: 6
Training loss: 5.9865298064517445
Validation loss: 5.764478871077196

Epoch: 5| Step: 7
Training loss: 5.661046139177156
Validation loss: 5.759406998659806

Epoch: 5| Step: 8
Training loss: 6.704607037230567
Validation loss: 5.753760069012939

Epoch: 5| Step: 9
Training loss: 5.705618702457432
Validation loss: 5.748048962735172

Epoch: 5| Step: 10
Training loss: 6.033247700851028
Validation loss: 5.741926461512328

Epoch: 5| Step: 11
Training loss: 5.450745333880883
Validation loss: 5.735512602429017

Epoch: 4| Step: 0
Training loss: 6.302220198561166
Validation loss: 5.72896690251578

Epoch: 5| Step: 1
Training loss: 6.139634069417139
Validation loss: 5.7222070372276095

Epoch: 5| Step: 2
Training loss: 5.01662580065806
Validation loss: 5.715303163972911

Epoch: 5| Step: 3
Training loss: 6.296576329571579
Validation loss: 5.708075485067641

Epoch: 5| Step: 4
Training loss: 5.468820625939041
Validation loss: 5.700380565531876

Epoch: 5| Step: 5
Training loss: 5.490188690722862
Validation loss: 5.693229179136875

Epoch: 5| Step: 6
Training loss: 5.463487109071569
Validation loss: 5.68516389148124

Epoch: 5| Step: 7
Training loss: 6.003240981562779
Validation loss: 5.677277163308467

Epoch: 5| Step: 8
Training loss: 6.494155016431423
Validation loss: 5.668980815468519

Epoch: 5| Step: 9
Training loss: 5.4898204233508086
Validation loss: 5.660683090722255

Epoch: 5| Step: 10
Training loss: 6.001685859347928
Validation loss: 5.652076003054309

Epoch: 5| Step: 11
Training loss: 2.529882084959702
Validation loss: 5.643486515849542

Epoch: 5| Step: 0
Training loss: 5.776815827489771
Validation loss: 5.63502779857026

Epoch: 5| Step: 1
Training loss: 5.9224949816662
Validation loss: 5.6262173430342495

Epoch: 5| Step: 2
Training loss: 6.033824311963079
Validation loss: 5.617430524737379

Epoch: 5| Step: 3
Training loss: 6.217381312361401
Validation loss: 5.6078771434936545

Epoch: 5| Step: 4
Training loss: 5.416649138593435
Validation loss: 5.598971723200438

Epoch: 5| Step: 5
Training loss: 5.1239861206533766
Validation loss: 5.589465612119004

Epoch: 5| Step: 6
Training loss: 5.467241351616569
Validation loss: 5.580116450759287

Epoch: 5| Step: 7
Training loss: 4.816983401082436
Validation loss: 5.5705865593717405

Epoch: 5| Step: 8
Training loss: 6.1029787263857305
Validation loss: 5.561533347442792

Epoch: 5| Step: 9
Training loss: 5.338947480447303
Validation loss: 5.552195995778988

Epoch: 5| Step: 10
Training loss: 6.212956629345243
Validation loss: 5.542509913523837

Epoch: 5| Step: 11
Training loss: 6.348925954742943
Validation loss: 5.532847595821729

Epoch: 6| Step: 0
Training loss: 5.943270158301787
Validation loss: 5.523191497806468

Epoch: 5| Step: 1
Training loss: 5.371103693172614
Validation loss: 5.513150965170309

Epoch: 5| Step: 2
Training loss: 4.999076758024144
Validation loss: 5.5033817442935264

Epoch: 5| Step: 3
Training loss: 6.699518829831701
Validation loss: 5.493541660922463

Epoch: 5| Step: 4
Training loss: 5.537885059204017
Validation loss: 5.48399288661309

Epoch: 5| Step: 5
Training loss: 5.833309863815324
Validation loss: 5.4740124115116195

Epoch: 5| Step: 6
Training loss: 4.93648219180964
Validation loss: 5.464395107915995

Epoch: 5| Step: 7
Training loss: 5.352118113835247
Validation loss: 5.454809582641786

Epoch: 5| Step: 8
Training loss: 5.420161699367468
Validation loss: 5.445147197591477

Epoch: 5| Step: 9
Training loss: 5.580098291987533
Validation loss: 5.435829446757976

Epoch: 5| Step: 10
Training loss: 5.774052278774204
Validation loss: 5.426777524136041

Epoch: 5| Step: 11
Training loss: 4.923482577869051
Validation loss: 5.417376906952442

Epoch: 7| Step: 0
Training loss: 4.753754386889801
Validation loss: 5.408532089123629

Epoch: 5| Step: 1
Training loss: 6.086933725326215
Validation loss: 5.399647931701768

Epoch: 5| Step: 2
Training loss: 5.536167351249421
Validation loss: 5.3913259299309075

Epoch: 5| Step: 3
Training loss: 5.08477329225146
Validation loss: 5.382450292735447

Epoch: 5| Step: 4
Training loss: 5.639293397238842
Validation loss: 5.3740915373518865

Epoch: 5| Step: 5
Training loss: 5.823379998605131
Validation loss: 5.365537905407398

Epoch: 5| Step: 6
Training loss: 5.6443403271127695
Validation loss: 5.356875861038805

Epoch: 5| Step: 7
Training loss: 5.71109881088443
Validation loss: 5.3490225451613505

Epoch: 5| Step: 8
Training loss: 5.418883452042615
Validation loss: 5.340259973898407

Epoch: 5| Step: 9
Training loss: 5.685015796112688
Validation loss: 5.3324920715998

Epoch: 5| Step: 10
Training loss: 5.029547930627027
Validation loss: 5.323812841035713

Epoch: 5| Step: 11
Training loss: 4.356564070163151
Validation loss: 5.315799122566874

Epoch: 8| Step: 0
Training loss: 4.975103574661866
Validation loss: 5.30757657210723

Epoch: 5| Step: 1
Training loss: 4.651985212294346
Validation loss: 5.29982212715848

Epoch: 5| Step: 2
Training loss: 5.2994598113385285
Validation loss: 5.291609886445519

Epoch: 5| Step: 3
Training loss: 5.657301325594583
Validation loss: 5.284253111158635

Epoch: 5| Step: 4
Training loss: 6.084984054607228
Validation loss: 5.275568808792751

Epoch: 5| Step: 5
Training loss: 5.03098045243113
Validation loss: 5.267760593647154

Epoch: 5| Step: 6
Training loss: 5.268300811335729
Validation loss: 5.259938876167968

Epoch: 5| Step: 7
Training loss: 5.230176101258054
Validation loss: 5.251834571552937

Epoch: 5| Step: 8
Training loss: 5.852708121228575
Validation loss: 5.2432312094574325

Epoch: 5| Step: 9
Training loss: 5.845107629729755
Validation loss: 5.235067748730791

Epoch: 5| Step: 10
Training loss: 5.251619724914154
Validation loss: 5.227171584421133

Epoch: 5| Step: 11
Training loss: 5.107096966242899
Validation loss: 5.218755185244605

Epoch: 9| Step: 0
Training loss: 5.310791638518573
Validation loss: 5.210606798528601

Epoch: 5| Step: 1
Training loss: 5.246484033264917
Validation loss: 5.202369688578251

Epoch: 5| Step: 2
Training loss: 5.437875142803996
Validation loss: 5.194751206291376

Epoch: 5| Step: 3
Training loss: 4.9659054849197695
Validation loss: 5.186573014680497

Epoch: 5| Step: 4
Training loss: 5.694240055706444
Validation loss: 5.1785489802195

Epoch: 5| Step: 5
Training loss: 5.36915341372613
Validation loss: 5.170627324408767

Epoch: 5| Step: 6
Training loss: 4.866629628253894
Validation loss: 5.16250335964189

Epoch: 5| Step: 7
Training loss: 5.33351001844201
Validation loss: 5.15534734820504

Epoch: 5| Step: 8
Training loss: 5.236276400807571
Validation loss: 5.147357485865493

Epoch: 5| Step: 9
Training loss: 5.394488467765727
Validation loss: 5.140020649951367

Epoch: 5| Step: 10
Training loss: 5.213213147747993
Validation loss: 5.132219308361526

Epoch: 5| Step: 11
Training loss: 5.833729358127351
Validation loss: 5.125044993071265

Epoch: 10| Step: 0
Training loss: 5.050487064252481
Validation loss: 5.1177302647804055

Epoch: 5| Step: 1
Training loss: 4.415126436006431
Validation loss: 5.110127415993897

Epoch: 5| Step: 2
Training loss: 5.589835902007943
Validation loss: 5.102947528071227

Epoch: 5| Step: 3
Training loss: 5.533744120382525
Validation loss: 5.095374458760595

Epoch: 5| Step: 4
Training loss: 5.444522225652587
Validation loss: 5.088156126859834

Epoch: 5| Step: 5
Training loss: 5.400451372850012
Validation loss: 5.0813987391099555

Epoch: 5| Step: 6
Training loss: 5.928432246296299
Validation loss: 5.0735781145048255

Epoch: 5| Step: 7
Training loss: 5.091744993682272
Validation loss: 5.066454673188625

Epoch: 5| Step: 8
Training loss: 5.157381430671533
Validation loss: 5.059290523974421

Epoch: 5| Step: 9
Training loss: 5.012581445503178
Validation loss: 5.052578973217436

Epoch: 5| Step: 10
Training loss: 4.227442848906592
Validation loss: 5.045508507758419

Epoch: 5| Step: 11
Training loss: 5.979738994503256
Validation loss: 5.039023844252774

Epoch: 11| Step: 0
Training loss: 5.383299519026212
Validation loss: 5.032780582295581

Epoch: 5| Step: 1
Training loss: 5.245015457465102
Validation loss: 5.02676187471049

Epoch: 5| Step: 2
Training loss: 4.496294615340985
Validation loss: 5.020752651574101

Epoch: 5| Step: 3
Training loss: 4.46721147849021
Validation loss: 5.014109722298255

Epoch: 5| Step: 4
Training loss: 5.1529463848668655
Validation loss: 5.007809587895364

Epoch: 5| Step: 5
Training loss: 4.850634205045987
Validation loss: 5.001596235745239

Epoch: 5| Step: 6
Training loss: 5.612836274605935
Validation loss: 4.994826318370707

Epoch: 5| Step: 7
Training loss: 5.11345637919869
Validation loss: 4.989099676891907

Epoch: 5| Step: 8
Training loss: 5.020891793360494
Validation loss: 4.982565341041868

Epoch: 5| Step: 9
Training loss: 5.777361577685475
Validation loss: 4.976864289096534

Epoch: 5| Step: 10
Training loss: 5.344689359139886
Validation loss: 4.970821360722609

Epoch: 5| Step: 11
Training loss: 3.638302303594872
Validation loss: 4.964244239081074

Epoch: 12| Step: 0
Training loss: 4.575038038418754
Validation loss: 4.9582979404030425

Epoch: 5| Step: 1
Training loss: 4.934438214854435
Validation loss: 4.952346435713041

Epoch: 5| Step: 2
Training loss: 4.257956966084135
Validation loss: 4.945852241169311

Epoch: 5| Step: 3
Training loss: 5.053231314046175
Validation loss: 4.940252398041808

Epoch: 5| Step: 4
Training loss: 5.02924340080795
Validation loss: 4.934211005718364

Epoch: 5| Step: 5
Training loss: 5.6160184574856356
Validation loss: 4.92800746528413

Epoch: 5| Step: 6
Training loss: 5.522468104134386
Validation loss: 4.922233536190371

Epoch: 5| Step: 7
Training loss: 5.612718526073589
Validation loss: 4.915816114962094

Epoch: 5| Step: 8
Training loss: 5.316490918227337
Validation loss: 4.909862419487629

Epoch: 5| Step: 9
Training loss: 4.931699798531135
Validation loss: 4.902908928905761

Epoch: 5| Step: 10
Training loss: 4.748691378575782
Validation loss: 4.896170197389134

Epoch: 5| Step: 11
Training loss: 3.8470691523453597
Validation loss: 4.889946107391882

Epoch: 13| Step: 0
Training loss: 5.048534203243389
Validation loss: 4.883339196853676

Epoch: 5| Step: 1
Training loss: 4.614134526296108
Validation loss: 4.876714250150344

Epoch: 5| Step: 2
Training loss: 4.383417587534195
Validation loss: 4.870879314630878

Epoch: 5| Step: 3
Training loss: 4.701043666459086
Validation loss: 4.8647284421441315

Epoch: 5| Step: 4
Training loss: 5.3575573388474425
Validation loss: 4.8575001664160835

Epoch: 5| Step: 5
Training loss: 5.027449789759198
Validation loss: 4.8508056033823514

Epoch: 5| Step: 6
Training loss: 4.667813478066109
Validation loss: 4.844579153978034

Epoch: 5| Step: 7
Training loss: 5.113435490834014
Validation loss: 4.838790356089919

Epoch: 5| Step: 8
Training loss: 5.499790534452341
Validation loss: 4.83113674970363

Epoch: 5| Step: 9
Training loss: 5.487176511088628
Validation loss: 4.823766936896619

Epoch: 5| Step: 10
Training loss: 4.722485610996537
Validation loss: 4.81722121241863

Epoch: 5| Step: 11
Training loss: 4.758732849202414
Validation loss: 4.8107822044180235

Epoch: 14| Step: 0
Training loss: 5.0604496324119
Validation loss: 4.803532986344452

Epoch: 5| Step: 1
Training loss: 5.703494877774572
Validation loss: 4.796114253420619

Epoch: 5| Step: 2
Training loss: 4.6886949160581075
Validation loss: 4.788767371488452

Epoch: 5| Step: 3
Training loss: 5.002243682990032
Validation loss: 4.781855401500167

Epoch: 5| Step: 4
Training loss: 4.403282519000872
Validation loss: 4.774772186903112

Epoch: 5| Step: 5
Training loss: 4.395351485951788
Validation loss: 4.7673145821969465

Epoch: 5| Step: 6
Training loss: 5.042660491764747
Validation loss: 4.761370392914112

Epoch: 5| Step: 7
Training loss: 5.056094980397981
Validation loss: 4.754591379187536

Epoch: 5| Step: 8
Training loss: 4.79476673628863
Validation loss: 4.747687052717372

Epoch: 5| Step: 9
Training loss: 4.969543201784186
Validation loss: 4.740483786035212

Epoch: 5| Step: 10
Training loss: 4.822735491234016
Validation loss: 4.7339663103589285

Epoch: 5| Step: 11
Training loss: 3.5315530022450483
Validation loss: 4.727408265666673

Epoch: 15| Step: 0
Training loss: 4.590061081955662
Validation loss: 4.7219217684786186

Epoch: 5| Step: 1
Training loss: 5.1079536350807615
Validation loss: 4.714420500823198

Epoch: 5| Step: 2
Training loss: 3.7764450945141363
Validation loss: 4.707676511147351

Epoch: 5| Step: 3
Training loss: 5.55479137039179
Validation loss: 4.702659330411711

Epoch: 5| Step: 4
Training loss: 5.398033645915116
Validation loss: 4.697151226043815

Epoch: 5| Step: 5
Training loss: 4.641754732146907
Validation loss: 4.6905004774114465

Epoch: 5| Step: 6
Training loss: 4.951104073746811
Validation loss: 4.684769424279594

Epoch: 5| Step: 7
Training loss: 4.843592881146289
Validation loss: 4.677752655779345

Epoch: 5| Step: 8
Training loss: 4.0446719502702235
Validation loss: 4.672597082975607

Epoch: 5| Step: 9
Training loss: 5.074538434466328
Validation loss: 4.665432999670237

Epoch: 5| Step: 10
Training loss: 4.926821980658684
Validation loss: 4.6586997310600164

Epoch: 5| Step: 11
Training loss: 3.536232058552724
Validation loss: 4.6532329880698855

Epoch: 16| Step: 0
Training loss: 5.113450411103203
Validation loss: 4.648149728282228

Epoch: 5| Step: 1
Training loss: 5.2660964166179305
Validation loss: 4.641488633887853

Epoch: 5| Step: 2
Training loss: 4.237043715135558
Validation loss: 4.6354555478412

Epoch: 5| Step: 3
Training loss: 4.914403469949746
Validation loss: 4.629146426980964

Epoch: 5| Step: 4
Training loss: 4.85468087590321
Validation loss: 4.624401242787968

Epoch: 5| Step: 5
Training loss: 5.572500433188037
Validation loss: 4.618855097241299

Epoch: 5| Step: 6
Training loss: 5.327630431191013
Validation loss: 4.611038959403391

Epoch: 5| Step: 7
Training loss: 4.376407941699216
Validation loss: 4.603910269293959

Epoch: 5| Step: 8
Training loss: 4.6279506034885545
Validation loss: 4.599113663339584

Epoch: 5| Step: 9
Training loss: 3.859046829417936
Validation loss: 4.593096420608205

Epoch: 5| Step: 10
Training loss: 3.9302541274978475
Validation loss: 4.588480273156107

Epoch: 5| Step: 11
Training loss: 3.4762393415466657
Validation loss: 4.58144470952941

Epoch: 17| Step: 0
Training loss: 3.645537765874466
Validation loss: 4.57576750030892

Epoch: 5| Step: 1
Training loss: 5.028904528081983
Validation loss: 4.5700141657213935

Epoch: 5| Step: 2
Training loss: 3.907300639957927
Validation loss: 4.564312805534872

Epoch: 5| Step: 3
Training loss: 4.298251954445155
Validation loss: 4.559435045745902

Epoch: 5| Step: 4
Training loss: 4.546812286468817
Validation loss: 4.554288568578288

Epoch: 5| Step: 5
Training loss: 5.266215577102461
Validation loss: 4.549091048154031

Epoch: 5| Step: 6
Training loss: 4.8376199633487165
Validation loss: 4.544224467947302

Epoch: 5| Step: 7
Training loss: 4.839576941672199
Validation loss: 4.538579042899646

Epoch: 5| Step: 8
Training loss: 5.2818937191480835
Validation loss: 4.532120658274473

Epoch: 5| Step: 9
Training loss: 5.072785090542384
Validation loss: 4.527532144071153

Epoch: 5| Step: 10
Training loss: 4.70195058562852
Validation loss: 4.521830675830144

Epoch: 5| Step: 11
Training loss: 2.717059607454615
Validation loss: 4.516701461099609

Epoch: 18| Step: 0
Training loss: 4.81500258337726
Validation loss: 4.510574975293317

Epoch: 5| Step: 1
Training loss: 3.7544695603217138
Validation loss: 4.506334693948743

Epoch: 5| Step: 2
Training loss: 5.206440187348595
Validation loss: 4.502638056818553

Epoch: 5| Step: 3
Training loss: 4.2236548274354
Validation loss: 4.498067944403203

Epoch: 5| Step: 4
Training loss: 4.6721681228592065
Validation loss: 4.492546451988645

Epoch: 5| Step: 5
Training loss: 3.754773344470631
Validation loss: 4.48743584143378

Epoch: 5| Step: 6
Training loss: 4.73810332389556
Validation loss: 4.482807572225701

Epoch: 5| Step: 7
Training loss: 4.655695735021739
Validation loss: 4.477089953458331

Epoch: 5| Step: 8
Training loss: 4.758740264185212
Validation loss: 4.47161072084053

Epoch: 5| Step: 9
Training loss: 5.292846227825464
Validation loss: 4.466571294539732

Epoch: 5| Step: 10
Training loss: 4.695557446683772
Validation loss: 4.461131357233089

Epoch: 5| Step: 11
Training loss: 4.174428551220879
Validation loss: 4.455712406640457

Epoch: 19| Step: 0
Training loss: 4.6284638913763185
Validation loss: 4.450866340572431

Epoch: 5| Step: 1
Training loss: 3.9957046095580266
Validation loss: 4.44502646224874

Epoch: 5| Step: 2
Training loss: 4.666891751083692
Validation loss: 4.439779224605949

Epoch: 5| Step: 3
Training loss: 4.509234384312487
Validation loss: 4.435208234761751

Epoch: 5| Step: 4
Training loss: 4.7533721999995455
Validation loss: 4.430391070754978

Epoch: 5| Step: 5
Training loss: 5.066409638226507
Validation loss: 4.425262977486964

Epoch: 5| Step: 6
Training loss: 4.220731142896362
Validation loss: 4.419416339421788

Epoch: 5| Step: 7
Training loss: 4.557058773811103
Validation loss: 4.414664762477144

Epoch: 5| Step: 8
Training loss: 4.490752785496474
Validation loss: 4.409607313900083

Epoch: 5| Step: 9
Training loss: 4.8768097868278
Validation loss: 4.4047900096507275

Epoch: 5| Step: 10
Training loss: 4.30332102609574
Validation loss: 4.399582722232686

Epoch: 5| Step: 11
Training loss: 4.139952637406112
Validation loss: 4.394811772188013

Epoch: 20| Step: 0
Training loss: 5.119439807286505
Validation loss: 4.38952563675939

Epoch: 5| Step: 1
Training loss: 4.279737664855227
Validation loss: 4.385264625843452

Epoch: 5| Step: 2
Training loss: 4.471308902547659
Validation loss: 4.380143194209428

Epoch: 5| Step: 3
Training loss: 4.464758097043143
Validation loss: 4.375027511146877

Epoch: 5| Step: 4
Training loss: 4.226497741315927
Validation loss: 4.370101202397441

Epoch: 5| Step: 5
Training loss: 4.309975147573948
Validation loss: 4.365568644606564

Epoch: 5| Step: 6
Training loss: 4.5914770199103945
Validation loss: 4.360685623204627

Epoch: 5| Step: 7
Training loss: 4.143278833359734
Validation loss: 4.356520311715775

Epoch: 5| Step: 8
Training loss: 4.296476588418597
Validation loss: 4.351606732913561

Epoch: 5| Step: 9
Training loss: 4.633754383596524
Validation loss: 4.346949727567671

Epoch: 5| Step: 10
Training loss: 4.749451455014058
Validation loss: 4.342453756333237

Epoch: 5| Step: 11
Training loss: 4.849293151943521
Validation loss: 4.337306121098966

Epoch: 21| Step: 0
Training loss: 4.156705673593545
Validation loss: 4.332480776194402

Epoch: 5| Step: 1
Training loss: 4.247845271796631
Validation loss: 4.3282410276723144

Epoch: 5| Step: 2
Training loss: 4.1079876664672055
Validation loss: 4.323448372126288

Epoch: 5| Step: 3
Training loss: 5.213490651351407
Validation loss: 4.318761849651651

Epoch: 5| Step: 4
Training loss: 4.788322254614667
Validation loss: 4.3139084989865255

Epoch: 5| Step: 5
Training loss: 3.904458573596304
Validation loss: 4.3090994000107345

Epoch: 5| Step: 6
Training loss: 4.694274076621998
Validation loss: 4.3042182366579755

Epoch: 5| Step: 7
Training loss: 4.38278530064811
Validation loss: 4.300066471325365

Epoch: 5| Step: 8
Training loss: 4.787787860552747
Validation loss: 4.294724526236357

Epoch: 5| Step: 9
Training loss: 4.529567221879955
Validation loss: 4.289975757567431

Epoch: 5| Step: 10
Training loss: 4.244106245186915
Validation loss: 4.285616641029742

Epoch: 5| Step: 11
Training loss: 1.5844775465785472
Validation loss: 4.280774008842524

Epoch: 22| Step: 0
Training loss: 2.8655908280959066
Validation loss: 4.277003026481808

Epoch: 5| Step: 1
Training loss: 4.850583086652323
Validation loss: 4.27268751259338

Epoch: 5| Step: 2
Training loss: 3.7179173410880955
Validation loss: 4.2685137923995935

Epoch: 5| Step: 3
Training loss: 4.572376795757096
Validation loss: 4.264400571936259

Epoch: 5| Step: 4
Training loss: 4.336833469507024
Validation loss: 4.260317452292907

Epoch: 5| Step: 5
Training loss: 4.651922275723768
Validation loss: 4.256545393333211

Epoch: 5| Step: 6
Training loss: 5.008916153004763
Validation loss: 4.252187166094127

Epoch: 5| Step: 7
Training loss: 4.5751506009354745
Validation loss: 4.248043778809336

Epoch: 5| Step: 8
Training loss: 4.587969821913827
Validation loss: 4.2434014163632305

Epoch: 5| Step: 9
Training loss: 5.015620436621756
Validation loss: 4.238441138467172

Epoch: 5| Step: 10
Training loss: 3.4271431002676143
Validation loss: 4.23407670175052

Epoch: 5| Step: 11
Training loss: 4.743394977618487
Validation loss: 4.230449320712431

Epoch: 23| Step: 0
Training loss: 4.6935694755044075
Validation loss: 4.22653596861498

Epoch: 5| Step: 1
Training loss: 4.617923787594618
Validation loss: 4.2214932129551705

Epoch: 5| Step: 2
Training loss: 4.610501426518667
Validation loss: 4.2166654169636155

Epoch: 5| Step: 3
Training loss: 4.004682184722624
Validation loss: 4.212131422993917

Epoch: 5| Step: 4
Training loss: 3.8681166024054505
Validation loss: 4.207615638506797

Epoch: 5| Step: 5
Training loss: 4.495390332409707
Validation loss: 4.203056523971833

Epoch: 5| Step: 6
Training loss: 4.864685689215532
Validation loss: 4.1984466741925655

Epoch: 5| Step: 7
Training loss: 4.223270735022081
Validation loss: 4.1936714661508105

Epoch: 5| Step: 8
Training loss: 5.023455914927853
Validation loss: 4.1891288863047285

Epoch: 5| Step: 9
Training loss: 3.7983632879567173
Validation loss: 4.1843207517473395

Epoch: 5| Step: 10
Training loss: 3.345492470473535
Validation loss: 4.179715631218002

Epoch: 5| Step: 11
Training loss: 3.403175296184082
Validation loss: 4.175448997704077

Epoch: 24| Step: 0
Training loss: 4.636853673268619
Validation loss: 4.172519353094487

Epoch: 5| Step: 1
Training loss: 4.170558535999377
Validation loss: 4.166957709956004

Epoch: 5| Step: 2
Training loss: 4.735829347126281
Validation loss: 4.162126478747497

Epoch: 5| Step: 3
Training loss: 3.5100570328472345
Validation loss: 4.157499875932494

Epoch: 5| Step: 4
Training loss: 4.133750650401796
Validation loss: 4.153421907358108

Epoch: 5| Step: 5
Training loss: 4.364791294627304
Validation loss: 4.149523729931189

Epoch: 5| Step: 6
Training loss: 4.6924225455198645
Validation loss: 4.145097656088949

Epoch: 5| Step: 7
Training loss: 3.9540568222262
Validation loss: 4.140703370894098

Epoch: 5| Step: 8
Training loss: 3.5165810874421286
Validation loss: 4.13671451384676

Epoch: 5| Step: 9
Training loss: 4.805720520618114
Validation loss: 4.132226177658566

Epoch: 5| Step: 10
Training loss: 4.7285357935340215
Validation loss: 4.127400484885956

Epoch: 5| Step: 11
Training loss: 0.4827443022231209
Validation loss: 4.122920234502579

Epoch: 25| Step: 0
Training loss: 4.493021322071145
Validation loss: 4.119725752093019

Epoch: 5| Step: 1
Training loss: 4.171035053406774
Validation loss: 4.115092333765483

Epoch: 5| Step: 2
Training loss: 4.288315782705054
Validation loss: 4.111308673924383

Epoch: 5| Step: 3
Training loss: 3.6896848509895235
Validation loss: 4.106632197266886

Epoch: 5| Step: 4
Training loss: 4.168177877397623
Validation loss: 4.103046683972899

Epoch: 5| Step: 5
Training loss: 4.303189828864986
Validation loss: 4.098301078260427

Epoch: 5| Step: 6
Training loss: 5.070765776276925
Validation loss: 4.094140157962522

Epoch: 5| Step: 7
Training loss: 4.742554300064734
Validation loss: 4.090910239652993

Epoch: 5| Step: 8
Training loss: 3.2333130498295772
Validation loss: 4.08643609354562

Epoch: 5| Step: 9
Training loss: 4.342231759596985
Validation loss: 4.082233921598805

Epoch: 5| Step: 10
Training loss: 4.059215450308284
Validation loss: 4.07779522728081

Epoch: 5| Step: 11
Training loss: 2.321574064034172
Validation loss: 4.073261854498792

Epoch: 26| Step: 0
Training loss: 4.327701479024718
Validation loss: 4.069212717952807

Epoch: 5| Step: 1
Training loss: 4.507647056783105
Validation loss: 4.064950228539288

Epoch: 5| Step: 2
Training loss: 3.655694120487035
Validation loss: 4.061023585703715

Epoch: 5| Step: 3
Training loss: 4.381585097184258
Validation loss: 4.0567334941530495

Epoch: 5| Step: 4
Training loss: 3.197857204882642
Validation loss: 4.052398466720545

Epoch: 5| Step: 5
Training loss: 4.02171914155074
Validation loss: 4.048189958478498

Epoch: 5| Step: 6
Training loss: 4.709047764051264
Validation loss: 4.0438695521421595

Epoch: 5| Step: 7
Training loss: 4.916422994146562
Validation loss: 4.039222478004185

Epoch: 5| Step: 8
Training loss: 4.121974876182873
Validation loss: 4.034529030063541

Epoch: 5| Step: 9
Training loss: 3.4720443340934106
Validation loss: 4.030005038528826

Epoch: 5| Step: 10
Training loss: 4.110444948563464
Validation loss: 4.025293745454211

Epoch: 5| Step: 11
Training loss: 5.216696695032114
Validation loss: 4.020620363488675

Epoch: 27| Step: 0
Training loss: 4.102163274453302
Validation loss: 4.01607642994586

Epoch: 5| Step: 1
Training loss: 4.483064573001179
Validation loss: 4.011122979062617

Epoch: 5| Step: 2
Training loss: 4.433707537430251
Validation loss: 4.007384517193245

Epoch: 5| Step: 3
Training loss: 4.171533692074919
Validation loss: 4.001777591706401

Epoch: 5| Step: 4
Training loss: 4.10996117418054
Validation loss: 3.997715854156946

Epoch: 5| Step: 5
Training loss: 4.1917900770056
Validation loss: 3.992558058370514

Epoch: 5| Step: 6
Training loss: 4.40732967054078
Validation loss: 3.9877047618721564

Epoch: 5| Step: 7
Training loss: 4.096346664987701
Validation loss: 3.982969756804996

Epoch: 5| Step: 8
Training loss: 3.605706137863222
Validation loss: 3.9786777229227903

Epoch: 5| Step: 9
Training loss: 3.921055681583858
Validation loss: 3.9743976508507566

Epoch: 5| Step: 10
Training loss: 3.706589506658921
Validation loss: 3.9703420114252364

Epoch: 5| Step: 11
Training loss: 4.488858311195429
Validation loss: 3.9661839817923408

Epoch: 28| Step: 0
Training loss: 4.184701696267389
Validation loss: 3.9613896851062935

Epoch: 5| Step: 1
Training loss: 4.580614057796659
Validation loss: 3.956858383575242

Epoch: 5| Step: 2
Training loss: 4.10568524197269
Validation loss: 3.9520156721169233

Epoch: 5| Step: 3
Training loss: 3.909410098716466
Validation loss: 3.9476435909927643

Epoch: 5| Step: 4
Training loss: 3.411469686164117
Validation loss: 3.9430774967744227

Epoch: 5| Step: 5
Training loss: 4.172015355638752
Validation loss: 3.9387715017429357

Epoch: 5| Step: 6
Training loss: 3.550746334227397
Validation loss: 3.934558001426637

Epoch: 5| Step: 7
Training loss: 4.040176562615116
Validation loss: 3.9304445370488357

Epoch: 5| Step: 8
Training loss: 4.220685952649009
Validation loss: 3.9261737127542995

Epoch: 5| Step: 9
Training loss: 4.503383424161732
Validation loss: 3.922175898667122

Epoch: 5| Step: 10
Training loss: 3.8878973166010433
Validation loss: 3.917703099117554

Epoch: 5| Step: 11
Training loss: 4.465766817994988
Validation loss: 3.9133882481173305

Epoch: 29| Step: 0
Training loss: 4.387010056834783
Validation loss: 3.909058123542478

Epoch: 5| Step: 1
Training loss: 4.195859166621083
Validation loss: 3.9050188438670728

Epoch: 5| Step: 2
Training loss: 4.027348959592897
Validation loss: 3.9005827164789073

Epoch: 5| Step: 3
Training loss: 3.913523867277855
Validation loss: 3.8958915801292404

Epoch: 5| Step: 4
Training loss: 4.300984806575872
Validation loss: 3.8914840801762454

Epoch: 5| Step: 5
Training loss: 3.8663503029630113
Validation loss: 3.8871619146021112

Epoch: 5| Step: 6
Training loss: 3.4459085446275286
Validation loss: 3.8829355405863266

Epoch: 5| Step: 7
Training loss: 4.177662011046374
Validation loss: 3.8789757872485757

Epoch: 5| Step: 8
Training loss: 4.3067976250435835
Validation loss: 3.8753515924898236

Epoch: 5| Step: 9
Training loss: 3.37158991586922
Validation loss: 3.870241442795398

Epoch: 5| Step: 10
Training loss: 4.301974956388126
Validation loss: 3.8664121576247243

Epoch: 5| Step: 11
Training loss: 2.852029673310972
Validation loss: 3.862226351824905

Epoch: 30| Step: 0
Training loss: 4.297395431906278
Validation loss: 3.857775836913023

Epoch: 5| Step: 1
Training loss: 4.073948618052183
Validation loss: 3.85383110475772

Epoch: 5| Step: 2
Training loss: 3.8666600956258077
Validation loss: 3.8496208739112996

Epoch: 5| Step: 3
Training loss: 4.267845386368086
Validation loss: 3.8453270796285386

Epoch: 5| Step: 4
Training loss: 4.18756194567055
Validation loss: 3.841222438587173

Epoch: 5| Step: 5
Training loss: 3.3074117483531635
Validation loss: 3.8369587240049525

Epoch: 5| Step: 6
Training loss: 3.341905316767702
Validation loss: 3.8327815273737365

Epoch: 5| Step: 7
Training loss: 4.250895686292735
Validation loss: 3.828333749074973

Epoch: 5| Step: 8
Training loss: 3.972660811130002
Validation loss: 3.8242469451457186

Epoch: 5| Step: 9
Training loss: 3.5074957553786184
Validation loss: 3.8201616097512163

Epoch: 5| Step: 10
Training loss: 4.167982249787768
Validation loss: 3.816236400436325

Epoch: 5| Step: 11
Training loss: 5.164734304708464
Validation loss: 3.8121667726734327

Epoch: 31| Step: 0
Training loss: 3.923600504963061
Validation loss: 3.807807280367703

Epoch: 5| Step: 1
Training loss: 4.622388360102527
Validation loss: 3.8034204701035152

Epoch: 5| Step: 2
Training loss: 3.7442181837379724
Validation loss: 3.799000980788765

Epoch: 5| Step: 3
Training loss: 3.2886468257690904
Validation loss: 3.794518350327025

Epoch: 5| Step: 4
Training loss: 3.7083926821184994
Validation loss: 3.7903385281581863

Epoch: 5| Step: 5
Training loss: 4.067754076880812
Validation loss: 3.786041602386579

Epoch: 5| Step: 6
Training loss: 4.117255599383441
Validation loss: 3.7820716154438037

Epoch: 5| Step: 7
Training loss: 3.759696757689087
Validation loss: 3.778095237671501

Epoch: 5| Step: 8
Training loss: 4.555387204375399
Validation loss: 3.7735421828971956

Epoch: 5| Step: 9
Training loss: 3.5815698291106792
Validation loss: 3.769351455538199

Epoch: 5| Step: 10
Training loss: 3.2829123509512588
Validation loss: 3.7652713456554876

Epoch: 5| Step: 11
Training loss: 4.975914737817293
Validation loss: 3.7610969491695436

Epoch: 32| Step: 0
Training loss: 3.748230834708395
Validation loss: 3.7567616379254805

Epoch: 5| Step: 1
Training loss: 4.208941097877859
Validation loss: 3.7524751230254365

Epoch: 5| Step: 2
Training loss: 3.689819382379707
Validation loss: 3.7480219127359833

Epoch: 5| Step: 3
Training loss: 4.175202260857237
Validation loss: 3.7439454368904252

Epoch: 5| Step: 4
Training loss: 4.446945024744582
Validation loss: 3.739598397283931

Epoch: 5| Step: 5
Training loss: 2.83838625607867
Validation loss: 3.735418517067418

Epoch: 5| Step: 6
Training loss: 4.15006777236936
Validation loss: 3.7313331334891737

Epoch: 5| Step: 7
Training loss: 3.373993193605406
Validation loss: 3.7269911769407345

Epoch: 5| Step: 8
Training loss: 4.143623849550944
Validation loss: 3.722861973781126

Epoch: 5| Step: 9
Training loss: 3.618610143511945
Validation loss: 3.7186467399472467

Epoch: 5| Step: 10
Training loss: 4.005557252974966
Validation loss: 3.714489443596723

Epoch: 5| Step: 11
Training loss: 3.389499037870076
Validation loss: 3.7098360106717334

Epoch: 33| Step: 0
Training loss: 3.798765614443914
Validation loss: 3.705525989373213

Epoch: 5| Step: 1
Training loss: 4.0078748434174
Validation loss: 3.7014593893418115

Epoch: 5| Step: 2
Training loss: 4.182525868903021
Validation loss: 3.696739346059479

Epoch: 5| Step: 3
Training loss: 4.2102797636827605
Validation loss: 3.692029913101924

Epoch: 5| Step: 4
Training loss: 4.199179233098946
Validation loss: 3.6875817564613462

Epoch: 5| Step: 5
Training loss: 3.730691409830856
Validation loss: 3.6827912196355252

Epoch: 5| Step: 6
Training loss: 3.7430351428197013
Validation loss: 3.6788382714504735

Epoch: 5| Step: 7
Training loss: 3.317304905068408
Validation loss: 3.6744762540499765

Epoch: 5| Step: 8
Training loss: 3.527826861209447
Validation loss: 3.6698769943419163

Epoch: 5| Step: 9
Training loss: 3.4748758746695327
Validation loss: 3.665117677149885

Epoch: 5| Step: 10
Training loss: 3.5500230976481615
Validation loss: 3.661366618469702

Epoch: 5| Step: 11
Training loss: 4.506432492268473
Validation loss: 3.656768984790301

Epoch: 34| Step: 0
Training loss: 3.7092187374530705
Validation loss: 3.652602373238136

Epoch: 5| Step: 1
Training loss: 3.0760895636309105
Validation loss: 3.648595377673505

Epoch: 5| Step: 2
Training loss: 4.009855051060771
Validation loss: 3.644800294115631

Epoch: 5| Step: 3
Training loss: 4.234890051341149
Validation loss: 3.640667370725642

Epoch: 5| Step: 4
Training loss: 3.71271583109565
Validation loss: 3.6357805713010998

Epoch: 5| Step: 5
Training loss: 4.227996639268418
Validation loss: 3.6319537935608706

Epoch: 5| Step: 6
Training loss: 3.31906097162095
Validation loss: 3.627591374309227

Epoch: 5| Step: 7
Training loss: 3.314708333482687
Validation loss: 3.623292142478326

Epoch: 5| Step: 8
Training loss: 3.664031656944746
Validation loss: 3.6189796451752656

Epoch: 5| Step: 9
Training loss: 3.99428245087441
Validation loss: 3.6151629577760027

Epoch: 5| Step: 10
Training loss: 3.833283976914371
Validation loss: 3.6114981270706505

Epoch: 5| Step: 11
Training loss: 4.5040616672827145
Validation loss: 3.6070798537243536

Epoch: 35| Step: 0
Training loss: 3.325139672350202
Validation loss: 3.603098587949523

Epoch: 5| Step: 1
Training loss: 4.361549190755939
Validation loss: 3.5992201761847773

Epoch: 5| Step: 2
Training loss: 3.5567945334972086
Validation loss: 3.594516882411358

Epoch: 5| Step: 3
Training loss: 3.828743771738833
Validation loss: 3.590526506197999

Epoch: 5| Step: 4
Training loss: 3.313549954978525
Validation loss: 3.5862559147392985

Epoch: 5| Step: 5
Training loss: 3.4182343646793734
Validation loss: 3.5822663696289174

Epoch: 5| Step: 6
Training loss: 4.020335244011768
Validation loss: 3.5782263906625675

Epoch: 5| Step: 7
Training loss: 3.611828915258604
Validation loss: 3.573808812603375

Epoch: 5| Step: 8
Training loss: 3.2576277792542454
Validation loss: 3.56983938497874

Epoch: 5| Step: 9
Training loss: 3.6831548920872774
Validation loss: 3.565955393643256

Epoch: 5| Step: 10
Training loss: 4.416384897900799
Validation loss: 3.5622435583429

Epoch: 5| Step: 11
Training loss: 3.1717248138801244
Validation loss: 3.558167896549344

Epoch: 36| Step: 0
Training loss: 3.8137035033705877
Validation loss: 3.554214317491298

Epoch: 5| Step: 1
Training loss: 3.292468556780413
Validation loss: 3.5501533683367925

Epoch: 5| Step: 2
Training loss: 3.7329494676335058
Validation loss: 3.546425262932205

Epoch: 5| Step: 3
Training loss: 3.4830288189624765
Validation loss: 3.5426449023098545

Epoch: 5| Step: 4
Training loss: 3.624076199385189
Validation loss: 3.538787370756402

Epoch: 5| Step: 5
Training loss: 3.952963603347449
Validation loss: 3.5349386748912206

Epoch: 5| Step: 6
Training loss: 3.8829359192297055
Validation loss: 3.5310456771028065

Epoch: 5| Step: 7
Training loss: 3.830045381879737
Validation loss: 3.5272344527943202

Epoch: 5| Step: 8
Training loss: 3.775500631925186
Validation loss: 3.5231082195689694

Epoch: 5| Step: 9
Training loss: 2.6958585766451097
Validation loss: 3.5189892248816377

Epoch: 5| Step: 10
Training loss: 4.103371299446123
Validation loss: 3.5153801698558396

Epoch: 5| Step: 11
Training loss: 3.7218312553185973
Validation loss: 3.511002515285094

Epoch: 37| Step: 0
Training loss: 3.2293130820931153
Validation loss: 3.5074998621397926

Epoch: 5| Step: 1
Training loss: 3.258354160278049
Validation loss: 3.503537967057872

Epoch: 5| Step: 2
Training loss: 2.938441348918701
Validation loss: 3.500021866321378

Epoch: 5| Step: 3
Training loss: 3.753896469119347
Validation loss: 3.496620919886265

Epoch: 5| Step: 4
Training loss: 2.9151825171464596
Validation loss: 3.49320459879994

Epoch: 5| Step: 5
Training loss: 4.189463823922819
Validation loss: 3.4895965272264955

Epoch: 5| Step: 6
Training loss: 3.79448810165657
Validation loss: 3.4857366948901958

Epoch: 5| Step: 7
Training loss: 3.9222799753170285
Validation loss: 3.4823302583023312

Epoch: 5| Step: 8
Training loss: 3.531120230391757
Validation loss: 3.4787263686811807

Epoch: 5| Step: 9
Training loss: 3.616085535523147
Validation loss: 3.474792284097591

Epoch: 5| Step: 10
Training loss: 4.162804733897985
Validation loss: 3.471347660975311

Epoch: 5| Step: 11
Training loss: 4.869095772644904
Validation loss: 3.467296507744776

Epoch: 38| Step: 0
Training loss: 3.9361829220049467
Validation loss: 3.4632332093216793

Epoch: 5| Step: 1
Training loss: 3.5609810251117677
Validation loss: 3.459174959578223

Epoch: 5| Step: 2
Training loss: 3.8463847736577743
Validation loss: 3.455191251528338

Epoch: 5| Step: 3
Training loss: 3.832250870721412
Validation loss: 3.4514189082852216

Epoch: 5| Step: 4
Training loss: 3.4774572014111813
Validation loss: 3.4470856501613265

Epoch: 5| Step: 5
Training loss: 3.688206491841915
Validation loss: 3.4431650760017365

Epoch: 5| Step: 6
Training loss: 3.359542345713779
Validation loss: 3.439211199843151

Epoch: 5| Step: 7
Training loss: 3.7817570370036027
Validation loss: 3.4353307439508813

Epoch: 5| Step: 8
Training loss: 3.1611055096615948
Validation loss: 3.4314632178129707

Epoch: 5| Step: 9
Training loss: 3.18784554796353
Validation loss: 3.427770398884406

Epoch: 5| Step: 10
Training loss: 3.333036997656429
Validation loss: 3.42408643242483

Epoch: 5| Step: 11
Training loss: 4.234138059849169
Validation loss: 3.4205345594067973

Epoch: 39| Step: 0
Training loss: 2.6914142226501108
Validation loss: 3.4168684025653033

Epoch: 5| Step: 1
Training loss: 3.6164924497584887
Validation loss: 3.4133248074122085

Epoch: 5| Step: 2
Training loss: 3.310761769389689
Validation loss: 3.409447030000903

Epoch: 5| Step: 3
Training loss: 3.940626689235921
Validation loss: 3.4060481417044888

Epoch: 5| Step: 4
Training loss: 3.460060025615072
Validation loss: 3.402149181737084

Epoch: 5| Step: 5
Training loss: 3.6026903484176978
Validation loss: 3.398996884432026

Epoch: 5| Step: 6
Training loss: 3.256228128019304
Validation loss: 3.3954747582122167

Epoch: 5| Step: 7
Training loss: 3.251411278291035
Validation loss: 3.39190374306564

Epoch: 5| Step: 8
Training loss: 3.7533744887901324
Validation loss: 3.388175061659482

Epoch: 5| Step: 9
Training loss: 3.8947265331164433
Validation loss: 3.3848455602705627

Epoch: 5| Step: 10
Training loss: 3.637648778016117
Validation loss: 3.381384662007942

Epoch: 5| Step: 11
Training loss: 4.8687577018627906
Validation loss: 3.3778501120586157

Epoch: 40| Step: 0
Training loss: 3.7303661072675545
Validation loss: 3.373994748204728

Epoch: 5| Step: 1
Training loss: 3.4947358461897453
Validation loss: 3.3700559395525165

Epoch: 5| Step: 2
Training loss: 3.825702383339707
Validation loss: 3.36637426057048

Epoch: 5| Step: 3
Training loss: 3.8397267693428407
Validation loss: 3.362677815024308

Epoch: 5| Step: 4
Training loss: 3.652141381843484
Validation loss: 3.3586307174282046

Epoch: 5| Step: 5
Training loss: 3.3943688602915265
Validation loss: 3.3548138845036863

Epoch: 5| Step: 6
Training loss: 3.3128198433254794
Validation loss: 3.35086387816419

Epoch: 5| Step: 7
Training loss: 3.7330230436352148
Validation loss: 3.3474934915617505

Epoch: 5| Step: 8
Training loss: 3.835998161753034
Validation loss: 3.3433571760031695

Epoch: 5| Step: 9
Training loss: 2.255415227854202
Validation loss: 3.339571204414323

Epoch: 5| Step: 10
Training loss: 3.0704494766081596
Validation loss: 3.336230769134738

Epoch: 5| Step: 11
Training loss: 3.493557859538659
Validation loss: 3.3330412389012563

Epoch: 41| Step: 0
Training loss: 3.5494808086000575
Validation loss: 3.329523923815925

Epoch: 5| Step: 1
Training loss: 3.3944795558491916
Validation loss: 3.3266804922812945

Epoch: 5| Step: 2
Training loss: 3.5396962387881006
Validation loss: 3.323117854964614

Epoch: 5| Step: 3
Training loss: 3.4641635575478222
Validation loss: 3.321060192220086

Epoch: 5| Step: 4
Training loss: 2.9674515946641495
Validation loss: 3.3163738870707884

Epoch: 5| Step: 5
Training loss: 3.6753851811971456
Validation loss: 3.313050866057107

Epoch: 5| Step: 6
Training loss: 3.7178266645208025
Validation loss: 3.309930605621928

Epoch: 5| Step: 7
Training loss: 3.304432527702625
Validation loss: 3.3068186784676556

Epoch: 5| Step: 8
Training loss: 2.7035373086642616
Validation loss: 3.303573823557296

Epoch: 5| Step: 9
Training loss: 4.003481780091598
Validation loss: 3.3003919684136878

Epoch: 5| Step: 10
Training loss: 3.35292576805015
Validation loss: 3.297006553206807

Epoch: 5| Step: 11
Training loss: 4.044894053954299
Validation loss: 3.294015264838023

Epoch: 42| Step: 0
Training loss: 3.7043149943453164
Validation loss: 3.290577386340736

Epoch: 5| Step: 1
Training loss: 2.972433756097385
Validation loss: 3.2867872806045226

Epoch: 5| Step: 2
Training loss: 3.7853278248168953
Validation loss: 3.2837256281131855

Epoch: 5| Step: 3
Training loss: 3.521369682555801
Validation loss: 3.2805447713691005

Epoch: 5| Step: 4
Training loss: 3.3825020945021635
Validation loss: 3.27729983446224

Epoch: 5| Step: 5
Training loss: 3.698003776849579
Validation loss: 3.2731212259848355

Epoch: 5| Step: 6
Training loss: 3.52069431609835
Validation loss: 3.2698884599465683

Epoch: 5| Step: 7
Training loss: 3.984010926610831
Validation loss: 3.2667260268390885

Epoch: 5| Step: 8
Training loss: 2.6644880117188565
Validation loss: 3.26275385043212

Epoch: 5| Step: 9
Training loss: 3.1319508877894924
Validation loss: 3.2589586835093387

Epoch: 5| Step: 10
Training loss: 3.0385525233864117
Validation loss: 3.255979417137554

Epoch: 5| Step: 11
Training loss: 2.971618872354626
Validation loss: 3.2525239674454545

Epoch: 43| Step: 0
Training loss: 2.6020598065117215
Validation loss: 3.2496595999154074

Epoch: 5| Step: 1
Training loss: 3.6479565060348342
Validation loss: 3.247230119716445

Epoch: 5| Step: 2
Training loss: 3.142646859924584
Validation loss: 3.244148378403118

Epoch: 5| Step: 3
Training loss: 4.1585191541191415
Validation loss: 3.24234771332667

Epoch: 5| Step: 4
Training loss: 3.744141771199942
Validation loss: 3.2391542087103056

Epoch: 5| Step: 5
Training loss: 3.086307397233744
Validation loss: 3.23575833971423

Epoch: 5| Step: 6
Training loss: 3.4376548038651453
Validation loss: 3.2322406329987174

Epoch: 5| Step: 7
Training loss: 2.9938217759736374
Validation loss: 3.2290158123752692

Epoch: 5| Step: 8
Training loss: 3.2991384537555164
Validation loss: 3.226073479713666

Epoch: 5| Step: 9
Training loss: 3.334983099532878
Validation loss: 3.223100610788329

Epoch: 5| Step: 10
Training loss: 3.549088782908205
Validation loss: 3.220001313883551

Epoch: 5| Step: 11
Training loss: 2.780723350467852
Validation loss: 3.217065845849249

Epoch: 44| Step: 0
Training loss: 2.3866794913851312
Validation loss: 3.2139204390426173

Epoch: 5| Step: 1
Training loss: 3.8477213123068275
Validation loss: 3.2112858963035755

Epoch: 5| Step: 2
Training loss: 3.2797634572124426
Validation loss: 3.2088965947440466

Epoch: 5| Step: 3
Training loss: 3.5934406976696383
Validation loss: 3.2058580787370676

Epoch: 5| Step: 4
Training loss: 3.141750001350185
Validation loss: 3.202683897582585

Epoch: 5| Step: 5
Training loss: 3.8027913031017477
Validation loss: 3.199895877932305

Epoch: 5| Step: 6
Training loss: 3.8348939179192865
Validation loss: 3.196323834758567

Epoch: 5| Step: 7
Training loss: 3.0253882608225915
Validation loss: 3.1930122272346146

Epoch: 5| Step: 8
Training loss: 3.222144549811186
Validation loss: 3.190109615191523

Epoch: 5| Step: 9
Training loss: 3.2988220540019624
Validation loss: 3.186773578919972

Epoch: 5| Step: 10
Training loss: 2.941695767727887
Validation loss: 3.184009404732043

Epoch: 5| Step: 11
Training loss: 3.6989774373509294
Validation loss: 3.1812560471762668

Epoch: 45| Step: 0
Training loss: 3.748532580322239
Validation loss: 3.1778520383740663

Epoch: 5| Step: 1
Training loss: 3.5174052838314065
Validation loss: 3.1753661012212873

Epoch: 5| Step: 2
Training loss: 3.590687118271828
Validation loss: 3.172497097952948

Epoch: 5| Step: 3
Training loss: 3.417896483611033
Validation loss: 3.1696951317522135

Epoch: 5| Step: 4
Training loss: 2.938572302361896
Validation loss: 3.1666198160236014

Epoch: 5| Step: 5
Training loss: 3.3084366546050386
Validation loss: 3.1636783759144573

Epoch: 5| Step: 6
Training loss: 2.6935829694965796
Validation loss: 3.16107019286405

Epoch: 5| Step: 7
Training loss: 3.262492890916584
Validation loss: 3.1582589633073344

Epoch: 5| Step: 8
Training loss: 3.609815034011154
Validation loss: 3.1556251776112116

Epoch: 5| Step: 9
Training loss: 3.2342738628699865
Validation loss: 3.1527087139392496

Epoch: 5| Step: 10
Training loss: 3.0366493195569717
Validation loss: 3.1500158841878045

Epoch: 5| Step: 11
Training loss: 2.482025090763181
Validation loss: 3.147823845037424

Epoch: 46| Step: 0
Training loss: 2.8939817990756866
Validation loss: 3.1474491710563237

Epoch: 5| Step: 1
Training loss: 3.9621057837747453
Validation loss: 3.1510694371200363

Epoch: 5| Step: 2
Training loss: 3.276808284623879
Validation loss: 3.1386543911199856

Epoch: 5| Step: 3
Training loss: 3.3294571910099067
Validation loss: 3.135707608324057

Epoch: 5| Step: 4
Training loss: 3.4101706523088624
Validation loss: 3.1333110726526194

Epoch: 5| Step: 5
Training loss: 3.16137520912824
Validation loss: 3.1313234597254773

Epoch: 5| Step: 6
Training loss: 2.957778896618498
Validation loss: 3.1295596110102095

Epoch: 5| Step: 7
Training loss: 3.3171178910170305
Validation loss: 3.128347060343305

Epoch: 5| Step: 8
Training loss: 3.170350558756125
Validation loss: 3.1252488450472202

Epoch: 5| Step: 9
Training loss: 3.2426255998719347
Validation loss: 3.122277081256684

Epoch: 5| Step: 10
Training loss: 3.2974283197000007
Validation loss: 3.118525862300255

Epoch: 5| Step: 11
Training loss: 2.704326120229749
Validation loss: 3.1150031279991612

Epoch: 47| Step: 0
Training loss: 3.387685318836153
Validation loss: 3.112201594406895

Epoch: 5| Step: 1
Training loss: 3.1190767227917195
Validation loss: 3.1093305396091457

Epoch: 5| Step: 2
Training loss: 3.339805201257797
Validation loss: 3.1062975978978304

Epoch: 5| Step: 3
Training loss: 3.5268935616474777
Validation loss: 3.1032926632602607

Epoch: 5| Step: 4
Training loss: 3.1841188337108877
Validation loss: 3.1004659602464057

Epoch: 5| Step: 5
Training loss: 3.3045495547819774
Validation loss: 3.097537698677958

Epoch: 5| Step: 6
Training loss: 3.1047449959977937
Validation loss: 3.095142837668157

Epoch: 5| Step: 7
Training loss: 3.4309088198610285
Validation loss: 3.0917705342786697

Epoch: 5| Step: 8
Training loss: 3.2659704582340634
Validation loss: 3.0894393559813564

Epoch: 5| Step: 9
Training loss: 2.954003258953221
Validation loss: 3.0864220283081947

Epoch: 5| Step: 10
Training loss: 3.0577165264024986
Validation loss: 3.0835128368930906

Epoch: 5| Step: 11
Training loss: 2.79485644591152
Validation loss: 3.0807048423668855

Epoch: 48| Step: 0
Training loss: 2.571762835257277
Validation loss: 3.0784641440497076

Epoch: 5| Step: 1
Training loss: 3.1688795556062797
Validation loss: 3.075941392448536

Epoch: 5| Step: 2
Training loss: 3.0108221676349585
Validation loss: 3.074574179745367

Epoch: 5| Step: 3
Training loss: 3.5407535647478228
Validation loss: 3.0704312451204987

Epoch: 5| Step: 4
Training loss: 3.338443716975923
Validation loss: 3.068407035277801

Epoch: 5| Step: 5
Training loss: 3.3714476363171815
Validation loss: 3.0654375137564607

Epoch: 5| Step: 6
Training loss: 2.8872137613151945
Validation loss: 3.0621413196017193

Epoch: 5| Step: 7
Training loss: 3.2666932325515576
Validation loss: 3.059271872460727

Epoch: 5| Step: 8
Training loss: 2.909967977078874
Validation loss: 3.0570373830157775

Epoch: 5| Step: 9
Training loss: 3.2920320203482296
Validation loss: 3.0549213290659756

Epoch: 5| Step: 10
Training loss: 3.639839447798421
Validation loss: 3.0525220332182332

Epoch: 5| Step: 11
Training loss: 3.7565705275285195
Validation loss: 3.050112166973919

Epoch: 49| Step: 0
Training loss: 3.2134566252021615
Validation loss: 3.0480902180223226

Epoch: 5| Step: 1
Training loss: 3.053385659592652
Validation loss: 3.0741316036941977

Epoch: 5| Step: 2
Training loss: 3.0213851074009286
Validation loss: 3.058283933470966

Epoch: 5| Step: 3
Training loss: 3.6050034508973003
Validation loss: 3.0516452843836968

Epoch: 5| Step: 4
Training loss: 2.6358709936339006
Validation loss: 3.0388003630958393

Epoch: 5| Step: 5
Training loss: 2.970565240934286
Validation loss: 3.035121856978996

Epoch: 5| Step: 6
Training loss: 3.0219983364683833
Validation loss: 3.0349942445988476

Epoch: 5| Step: 7
Training loss: 2.966260488614565
Validation loss: 3.0338092173028413

Epoch: 5| Step: 8
Training loss: 3.270118214048247
Validation loss: 3.031142131288791

Epoch: 5| Step: 9
Training loss: 3.0778019924412443
Validation loss: 3.0297789002629814

Epoch: 5| Step: 10
Training loss: 3.710814142686548
Validation loss: 3.025543708121588

Epoch: 5| Step: 11
Training loss: 4.391207076073837
Validation loss: 3.021952968592247

Epoch: 50| Step: 0
Training loss: 3.2259894871312804
Validation loss: 3.0181449777459775

Epoch: 5| Step: 1
Training loss: 2.9654125527439166
Validation loss: 3.015243954212312

Epoch: 5| Step: 2
Training loss: 3.034853808481552
Validation loss: 3.017207621489692

Epoch: 5| Step: 3
Training loss: 3.237190532253895
Validation loss: 3.0123395762327316

Epoch: 5| Step: 4
Training loss: 2.8908278935339924
Validation loss: 3.00639525543064

Epoch: 5| Step: 5
Training loss: 3.3088953810725568
Validation loss: 3.0046042337053485

Epoch: 5| Step: 6
Training loss: 3.09311091440061
Validation loss: 3.0013139747941224

Epoch: 5| Step: 7
Training loss: 3.574917884363758
Validation loss: 2.9990117544751764

Epoch: 5| Step: 8
Training loss: 3.232783713933962
Validation loss: 2.9957092847506672

Epoch: 5| Step: 9
Training loss: 3.209890970060019
Validation loss: 2.992710243823757

Epoch: 5| Step: 10
Training loss: 2.8570233456275673
Validation loss: 2.9893372774492297

Epoch: 5| Step: 11
Training loss: 2.6758764987894494
Validation loss: 2.987314494211362

Epoch: 51| Step: 0
Training loss: 3.1427196899923677
Validation loss: 2.9838296415271377

Epoch: 5| Step: 1
Training loss: 2.9507226608394435
Validation loss: 2.9822957783114523

Epoch: 5| Step: 2
Training loss: 3.591992819390203
Validation loss: 2.979121575759006

Epoch: 5| Step: 3
Training loss: 3.062368584752161
Validation loss: 2.977858093726133

Epoch: 5| Step: 4
Training loss: 3.3983281962037997
Validation loss: 2.974028956726582

Epoch: 5| Step: 5
Training loss: 2.702514844177865
Validation loss: 2.972694062549313

Epoch: 5| Step: 6
Training loss: 3.0222957535132298
Validation loss: 2.9702615269663983

Epoch: 5| Step: 7
Training loss: 2.9798407336692794
Validation loss: 2.9669423003861053

Epoch: 5| Step: 8
Training loss: 2.7934515262383486
Validation loss: 2.96381817462413

Epoch: 5| Step: 9
Training loss: 3.4727188636790545
Validation loss: 2.962875962980736

Epoch: 5| Step: 10
Training loss: 2.9220773555430295
Validation loss: 2.9598277855029256

Epoch: 5| Step: 11
Training loss: 3.377658503361764
Validation loss: 2.959106758364933

Epoch: 52| Step: 0
Training loss: 2.947389715071172
Validation loss: 2.955390626226221

Epoch: 5| Step: 1
Training loss: 3.0137517773857554
Validation loss: 2.9531012673744703

Epoch: 5| Step: 2
Training loss: 3.149389383381988
Validation loss: 2.9493075359529355

Epoch: 5| Step: 3
Training loss: 3.239782411074231
Validation loss: 2.946685727224656

Epoch: 5| Step: 4
Training loss: 2.7513923588084226
Validation loss: 2.945236167964172

Epoch: 5| Step: 5
Training loss: 3.0539396887759036
Validation loss: 2.9423105235419404

Epoch: 5| Step: 6
Training loss: 3.6115071658227484
Validation loss: 2.9395024021956657

Epoch: 5| Step: 7
Training loss: 3.1172489934606515
Validation loss: 2.9376865050446304

Epoch: 5| Step: 8
Training loss: 2.6325321218010718
Validation loss: 2.934537956579893

Epoch: 5| Step: 9
Training loss: 3.0733776371783548
Validation loss: 2.9323647164188955

Epoch: 5| Step: 10
Training loss: 3.190614263533295
Validation loss: 2.9311127141810838

Epoch: 5| Step: 11
Training loss: 3.261140655637915
Validation loss: 2.927200546949615

Epoch: 53| Step: 0
Training loss: 3.360863785975031
Validation loss: 2.925648494844249

Epoch: 5| Step: 1
Training loss: 3.1626817492703827
Validation loss: 2.923160851425722

Epoch: 5| Step: 2
Training loss: 2.8244589127064055
Validation loss: 2.9191042228384783

Epoch: 5| Step: 3
Training loss: 2.6364672731639587
Validation loss: 2.917321320134028

Epoch: 5| Step: 4
Training loss: 3.462109782681489
Validation loss: 2.9154170708689877

Epoch: 5| Step: 5
Training loss: 3.339036846285475
Validation loss: 2.9115761657418155

Epoch: 5| Step: 6
Training loss: 3.2555296879139592
Validation loss: 2.9112367540000554

Epoch: 5| Step: 7
Training loss: 2.8274970437598523
Validation loss: 2.9124937837831797

Epoch: 5| Step: 8
Training loss: 2.779527966883759
Validation loss: 2.91425939172612

Epoch: 5| Step: 9
Training loss: 3.1135145073671087
Validation loss: 2.9033091853159836

Epoch: 5| Step: 10
Training loss: 2.4683518873397867
Validation loss: 2.9011144315039576

Epoch: 5| Step: 11
Training loss: 3.9775639979730295
Validation loss: 2.9004354008944255

Epoch: 54| Step: 0
Training loss: 3.1040167719004446
Validation loss: 2.900778504539949

Epoch: 5| Step: 1
Training loss: 3.033336118200791
Validation loss: 2.904189185835571

Epoch: 5| Step: 2
Training loss: 2.8871551307724195
Validation loss: 2.903139972956124

Epoch: 5| Step: 3
Training loss: 2.923573209547603
Validation loss: 2.9017913073531245

Epoch: 5| Step: 4
Training loss: 3.256572533154496
Validation loss: 2.8948142479208783

Epoch: 5| Step: 5
Training loss: 2.6933860196572286
Validation loss: 2.8911941895827376

Epoch: 5| Step: 6
Training loss: 2.7732589449289913
Validation loss: 2.8875207677317287

Epoch: 5| Step: 7
Training loss: 2.9957652403017163
Validation loss: 2.8830818973916283

Epoch: 5| Step: 8
Training loss: 3.226206318774996
Validation loss: 2.8816965419106113

Epoch: 5| Step: 9
Training loss: 3.1462221894760956
Validation loss: 2.879985180994382

Epoch: 5| Step: 10
Training loss: 3.364784179613667
Validation loss: 2.8783263541609885

Epoch: 5| Step: 11
Training loss: 2.234138743040982
Validation loss: 2.876219729132018

Epoch: 55| Step: 0
Training loss: 3.1144850257149788
Validation loss: 2.8728234510857247

Epoch: 5| Step: 1
Training loss: 2.8485599962303803
Validation loss: 2.86929750197564

Epoch: 5| Step: 2
Training loss: 3.284157182637359
Validation loss: 2.871620060781814

Epoch: 5| Step: 3
Training loss: 3.0358577982855413
Validation loss: 2.8658786526914595

Epoch: 5| Step: 4
Training loss: 2.8879822893841274
Validation loss: 2.8662082479313757

Epoch: 5| Step: 5
Training loss: 3.5583686296795474
Validation loss: 2.863101806152525

Epoch: 5| Step: 6
Training loss: 3.5225864236814246
Validation loss: 2.858562145491104

Epoch: 5| Step: 7
Training loss: 2.640981074596513
Validation loss: 2.8587553780842487

Epoch: 5| Step: 8
Training loss: 2.2934268318382443
Validation loss: 2.854678620879854

Epoch: 5| Step: 9
Training loss: 3.01817538082109
Validation loss: 2.852709845080029

Epoch: 5| Step: 10
Training loss: 2.6612843993522826
Validation loss: 2.852716611259892

Epoch: 5| Step: 11
Training loss: 2.4577877171959077
Validation loss: 2.8527090928943486

Epoch: 56| Step: 0
Training loss: 2.987340123196171
Validation loss: 2.8512718888696447

Epoch: 5| Step: 1
Training loss: 3.0819387289067497
Validation loss: 2.84948001574057

Epoch: 5| Step: 2
Training loss: 3.1287889018061654
Validation loss: 2.84739586538414

Epoch: 5| Step: 3
Training loss: 3.230282170397909
Validation loss: 2.8446948329816077

Epoch: 5| Step: 4
Training loss: 3.016188178569109
Validation loss: 2.8415152393800334

Epoch: 5| Step: 5
Training loss: 2.481807029329407
Validation loss: 2.840081493110658

Epoch: 5| Step: 6
Training loss: 3.184802990004883
Validation loss: 2.8382408869328883

Epoch: 5| Step: 7
Training loss: 3.0791196813513046
Validation loss: 2.8351563497911054

Epoch: 5| Step: 8
Training loss: 2.6361218942525064
Validation loss: 2.832308672767045

Epoch: 5| Step: 9
Training loss: 3.425706364542842
Validation loss: 2.8292047957789728

Epoch: 5| Step: 10
Training loss: 2.3842694940385067
Validation loss: 2.8286430558821003

Epoch: 5| Step: 11
Training loss: 2.820728387575558
Validation loss: 2.825813427145061

Epoch: 57| Step: 0
Training loss: 2.788658561626672
Validation loss: 2.8243729868903698

Epoch: 5| Step: 1
Training loss: 3.227693890480783
Validation loss: 2.8212340655346577

Epoch: 5| Step: 2
Training loss: 3.0667346559810666
Validation loss: 2.8208366674819545

Epoch: 5| Step: 3
Training loss: 2.703754594281332
Validation loss: 2.8195193047964997

Epoch: 5| Step: 4
Training loss: 3.5314846804795734
Validation loss: 2.8162738594334673

Epoch: 5| Step: 5
Training loss: 2.94753191878077
Validation loss: 2.8164855938800404

Epoch: 5| Step: 6
Training loss: 3.171454791717934
Validation loss: 2.8124360041931595

Epoch: 5| Step: 7
Training loss: 2.5862900415845123
Validation loss: 2.811429134234701

Epoch: 5| Step: 8
Training loss: 2.2995218609266135
Validation loss: 2.8070831480890157

Epoch: 5| Step: 9
Training loss: 2.8400940922476186
Validation loss: 2.8062385619736823

Epoch: 5| Step: 10
Training loss: 3.08516140606764
Validation loss: 2.8034984792024087

Epoch: 5| Step: 11
Training loss: 3.21781152173024
Validation loss: 2.8034891138005458

Epoch: 58| Step: 0
Training loss: 3.1227243911832847
Validation loss: 2.8000456244293783

Epoch: 5| Step: 1
Training loss: 3.159515655435326
Validation loss: 2.798495318796844

Epoch: 5| Step: 2
Training loss: 3.1730165729252198
Validation loss: 2.795714334654924

Epoch: 5| Step: 3
Training loss: 3.5108284336155196
Validation loss: 2.7950411312839205

Epoch: 5| Step: 4
Training loss: 3.078600386880709
Validation loss: 2.7916550256476924

Epoch: 5| Step: 5
Training loss: 3.0016122300547514
Validation loss: 2.7914006132532836

Epoch: 5| Step: 6
Training loss: 2.188709469631832
Validation loss: 2.788990493543017

Epoch: 5| Step: 7
Training loss: 2.9553932480794254
Validation loss: 2.788025290057286

Epoch: 5| Step: 8
Training loss: 3.1090033994443216
Validation loss: 2.7857483942816383

Epoch: 5| Step: 9
Training loss: 2.136844164081083
Validation loss: 2.7823546712509675

Epoch: 5| Step: 10
Training loss: 2.704286182585752
Validation loss: 2.7824606064483866

Epoch: 5| Step: 11
Training loss: 1.699720707558631
Validation loss: 2.7851687195201373

Epoch: 59| Step: 0
Training loss: 2.2675678210225625
Validation loss: 2.8074865869194325

Epoch: 5| Step: 1
Training loss: 3.3497309448602137
Validation loss: 2.812136128517314

Epoch: 5| Step: 2
Training loss: 2.824902126000895
Validation loss: 2.832450144688983

Epoch: 5| Step: 3
Training loss: 3.1458572151001785
Validation loss: 2.8073963553890877

Epoch: 5| Step: 4
Training loss: 2.9934562204478277
Validation loss: 2.7936154592719435

Epoch: 5| Step: 5
Training loss: 3.068042954921294
Validation loss: 2.774052035164555

Epoch: 5| Step: 6
Training loss: 3.2024746862716866
Validation loss: 2.7696602006241373

Epoch: 5| Step: 7
Training loss: 3.130941312577995
Validation loss: 2.7702616744839546

Epoch: 5| Step: 8
Training loss: 2.856486377909942
Validation loss: 2.7712873012881167

Epoch: 5| Step: 9
Training loss: 2.5902669109244942
Validation loss: 2.7745741793833862

Epoch: 5| Step: 10
Training loss: 2.63377638924463
Validation loss: 2.7813141490381943

Epoch: 5| Step: 11
Training loss: 2.8989298523136524
Validation loss: 2.7792010814665375

Epoch: 60| Step: 0
Training loss: 2.7611679974006265
Validation loss: 2.780047746186559

Epoch: 5| Step: 1
Training loss: 2.8505983159631887
Validation loss: 2.7770438195517917

Epoch: 5| Step: 2
Training loss: 2.492147511128529
Validation loss: 2.770083990568072

Epoch: 5| Step: 3
Training loss: 3.1614454961492013
Validation loss: 2.767022665130649

Epoch: 5| Step: 4
Training loss: 2.9901914786582693
Validation loss: 2.764609403614272

Epoch: 5| Step: 5
Training loss: 2.6191806775927087
Validation loss: 2.7627264987214204

Epoch: 5| Step: 6
Training loss: 2.6195721594360464
Validation loss: 2.7615641146419834

Epoch: 5| Step: 7
Training loss: 3.0440018629953145
Validation loss: 2.7593881358334063

Epoch: 5| Step: 8
Training loss: 3.350357514847471
Validation loss: 2.7592403220593127

Epoch: 5| Step: 9
Training loss: 3.0018271604081996
Validation loss: 2.754184097450335

Epoch: 5| Step: 10
Training loss: 3.0063663325334495
Validation loss: 2.751499702708927

Epoch: 5| Step: 11
Training loss: 2.4880248316418005
Validation loss: 2.7487738722452266

Epoch: 61| Step: 0
Training loss: 2.744411251529769
Validation loss: 2.7494320355178123

Epoch: 5| Step: 1
Training loss: 2.6654913418210073
Validation loss: 2.7515606335199116

Epoch: 5| Step: 2
Training loss: 2.422515784370641
Validation loss: 2.749767878879634

Epoch: 5| Step: 3
Training loss: 2.685138729638751
Validation loss: 2.7505266487239726

Epoch: 5| Step: 4
Training loss: 3.190281570588055
Validation loss: 2.747797318663218

Epoch: 5| Step: 5
Training loss: 3.2556622404889466
Validation loss: 2.7447900367939484

Epoch: 5| Step: 6
Training loss: 3.0992047551163413
Validation loss: 2.7405895493294095

Epoch: 5| Step: 7
Training loss: 3.039707301755661
Validation loss: 2.7388241456901667

Epoch: 5| Step: 8
Training loss: 2.5372584110503604
Validation loss: 2.7353840482926155

Epoch: 5| Step: 9
Training loss: 2.835729502046494
Validation loss: 2.733104694115685

Epoch: 5| Step: 10
Training loss: 2.883027686381436
Validation loss: 2.7322451661826594

Epoch: 5| Step: 11
Training loss: 3.856350103281546
Validation loss: 2.728837846404128

Epoch: 62| Step: 0
Training loss: 3.3068272221974073
Validation loss: 2.7287439475150386

Epoch: 5| Step: 1
Training loss: 2.792153491563972
Validation loss: 2.727039109685744

Epoch: 5| Step: 2
Training loss: 2.615341583174115
Validation loss: 2.7226695202249105

Epoch: 5| Step: 3
Training loss: 2.943893131088992
Validation loss: 2.722801667995324

Epoch: 5| Step: 4
Training loss: 2.5044879683930774
Validation loss: 2.7207276871944694

Epoch: 5| Step: 5
Training loss: 2.892834288222575
Validation loss: 2.721695550316413

Epoch: 5| Step: 6
Training loss: 3.306499877025187
Validation loss: 2.7181695121090486

Epoch: 5| Step: 7
Training loss: 3.022270036378372
Validation loss: 2.716092144199899

Epoch: 5| Step: 8
Training loss: 2.4632382249689124
Validation loss: 2.7158188969053922

Epoch: 5| Step: 9
Training loss: 3.170385753373761
Validation loss: 2.7139066144456994

Epoch: 5| Step: 10
Training loss: 2.375908426921984
Validation loss: 2.711648168133422

Epoch: 5| Step: 11
Training loss: 2.1978829427967304
Validation loss: 2.710829411091524

Epoch: 63| Step: 0
Training loss: 3.0621686483691075
Validation loss: 2.7117411936471623

Epoch: 5| Step: 1
Training loss: 2.9509632736190627
Validation loss: 2.710675064708202

Epoch: 5| Step: 2
Training loss: 3.1031459350494406
Validation loss: 2.707625114324566

Epoch: 5| Step: 3
Training loss: 2.592976558221851
Validation loss: 2.70524310218306

Epoch: 5| Step: 4
Training loss: 2.2237928866474634
Validation loss: 2.703734430252702

Epoch: 5| Step: 5
Training loss: 3.137364151281936
Validation loss: 2.704400953969537

Epoch: 5| Step: 6
Training loss: 2.7160490804515804
Validation loss: 2.7034498104099884

Epoch: 5| Step: 7
Training loss: 2.4963000574952487
Validation loss: 2.701956965173648

Epoch: 5| Step: 8
Training loss: 3.0168010414783315
Validation loss: 2.699973056652892

Epoch: 5| Step: 9
Training loss: 2.7744302181859783
Validation loss: 2.69884339670261

Epoch: 5| Step: 10
Training loss: 3.1404374858997333
Validation loss: 2.6969927760958505

Epoch: 5| Step: 11
Training loss: 1.7979588432566185
Validation loss: 2.6926629353477174

Epoch: 64| Step: 0
Training loss: 2.7096428761829436
Validation loss: 2.6941781499586286

Epoch: 5| Step: 1
Training loss: 3.1644454159211275
Validation loss: 2.6916941252115882

Epoch: 5| Step: 2
Training loss: 2.394585613486171
Validation loss: 2.691350629035235

Epoch: 5| Step: 3
Training loss: 3.1617849936401905
Validation loss: 2.6897904593811406

Epoch: 5| Step: 4
Training loss: 2.7251110859198064
Validation loss: 2.689622953543174

Epoch: 5| Step: 5
Training loss: 2.8115695685908038
Validation loss: 2.68704788338024

Epoch: 5| Step: 6
Training loss: 2.838946467008757
Validation loss: 2.6843397870194825

Epoch: 5| Step: 7
Training loss: 2.746815137677403
Validation loss: 2.6853446079724272

Epoch: 5| Step: 8
Training loss: 2.4384925973141196
Validation loss: 2.68559901701275

Epoch: 5| Step: 9
Training loss: 2.8460072372569685
Validation loss: 2.6824438564247415

Epoch: 5| Step: 10
Training loss: 3.1960487170463154
Validation loss: 2.6821762961356193

Epoch: 5| Step: 11
Training loss: 2.146614105497288
Validation loss: 2.678263857909111

Epoch: 65| Step: 0
Training loss: 2.745907859967874
Validation loss: 2.680142159256009

Epoch: 5| Step: 1
Training loss: 2.7432795683952365
Validation loss: 2.6828711590494363

Epoch: 5| Step: 2
Training loss: 3.228189792333646
Validation loss: 2.6875495277690757

Epoch: 5| Step: 3
Training loss: 2.42923175425762
Validation loss: 2.675548430103637

Epoch: 5| Step: 4
Training loss: 2.4467753461906883
Validation loss: 2.6768711923837434

Epoch: 5| Step: 5
Training loss: 2.8402673544429504
Validation loss: 2.674179561193002

Epoch: 5| Step: 6
Training loss: 3.2259136591293367
Validation loss: 2.6696983416842976

Epoch: 5| Step: 7
Training loss: 2.8008749718726724
Validation loss: 2.672174871916962

Epoch: 5| Step: 8
Training loss: 2.739894505996846
Validation loss: 2.6731641459101634

Epoch: 5| Step: 9
Training loss: 2.978674912492796
Validation loss: 2.675083509371646

Epoch: 5| Step: 10
Training loss: 2.7420687310127994
Validation loss: 2.6743865376260967

Epoch: 5| Step: 11
Training loss: 2.62022455985734
Validation loss: 2.672988633494977

Epoch: 66| Step: 0
Training loss: 2.6792840681758543
Validation loss: 2.6718876338310555

Epoch: 5| Step: 1
Training loss: 2.7448114518689684
Validation loss: 2.671125288214891

Epoch: 5| Step: 2
Training loss: 2.9445307577025988
Validation loss: 2.669836270369914

Epoch: 5| Step: 3
Training loss: 2.849287907833477
Validation loss: 2.6682695486386208

Epoch: 5| Step: 4
Training loss: 2.6762533620628823
Validation loss: 2.6652393631560205

Epoch: 5| Step: 5
Training loss: 3.1937560975376753
Validation loss: 2.663167958056725

Epoch: 5| Step: 6
Training loss: 3.0359287923471046
Validation loss: 2.6622393682007677

Epoch: 5| Step: 7
Training loss: 2.548977224147205
Validation loss: 2.661363022672181

Epoch: 5| Step: 8
Training loss: 2.7837832625910868
Validation loss: 2.6593935335666266

Epoch: 5| Step: 9
Training loss: 2.6514164647814864
Validation loss: 2.656564690143595

Epoch: 5| Step: 10
Training loss: 2.8323920500235524
Validation loss: 2.655428493845928

Epoch: 5| Step: 11
Training loss: 1.8036031396497996
Validation loss: 2.655228481962056

Epoch: 67| Step: 0
Training loss: 3.056888967547253
Validation loss: 2.6590051685960643

Epoch: 5| Step: 1
Training loss: 2.9963741643750987
Validation loss: 2.652914271468678

Epoch: 5| Step: 2
Training loss: 2.6225410024748643
Validation loss: 2.649226957154899

Epoch: 5| Step: 3
Training loss: 2.737858237598691
Validation loss: 2.6478335161657056

Epoch: 5| Step: 4
Training loss: 2.2266338136194763
Validation loss: 2.6489924034260777

Epoch: 5| Step: 5
Training loss: 3.007168629085726
Validation loss: 2.646461330937544

Epoch: 5| Step: 6
Training loss: 2.7934071443527695
Validation loss: 2.6450215255676266

Epoch: 5| Step: 7
Training loss: 2.9480838436175834
Validation loss: 2.644542970166514

Epoch: 5| Step: 8
Training loss: 2.683938882947725
Validation loss: 2.6443966897513587

Epoch: 5| Step: 9
Training loss: 3.1575509591116986
Validation loss: 2.6464727122295004

Epoch: 5| Step: 10
Training loss: 2.394617275167631
Validation loss: 2.6450939021301147

Epoch: 5| Step: 11
Training loss: 1.9323586574845248
Validation loss: 2.646560787960551

Epoch: 68| Step: 0
Training loss: 3.1391084719871287
Validation loss: 2.6493244355177414

Epoch: 5| Step: 1
Training loss: 2.762050668067994
Validation loss: 2.6429561016679566

Epoch: 5| Step: 2
Training loss: 3.0196962693931995
Validation loss: 2.647445935702013

Epoch: 5| Step: 3
Training loss: 2.5199492824839758
Validation loss: 2.6451503361467927

Epoch: 5| Step: 4
Training loss: 2.7544994824530695
Validation loss: 2.6425621067942227

Epoch: 5| Step: 5
Training loss: 2.8739494394568252
Validation loss: 2.63798385975802

Epoch: 5| Step: 6
Training loss: 2.625691640653349
Validation loss: 2.638477501815029

Epoch: 5| Step: 7
Training loss: 2.9596002221130213
Validation loss: 2.6377632916666105

Epoch: 5| Step: 8
Training loss: 2.8676192039184074
Validation loss: 2.63373580047082

Epoch: 5| Step: 9
Training loss: 2.507563023027163
Validation loss: 2.6339675263887066

Epoch: 5| Step: 10
Training loss: 2.5344916414449266
Validation loss: 2.6358431004940157

Epoch: 5| Step: 11
Training loss: 1.1186848456307943
Validation loss: 2.628983264567778

Epoch: 69| Step: 0
Training loss: 2.483172143488155
Validation loss: 2.6357651839419707

Epoch: 5| Step: 1
Training loss: 3.191470198066478
Validation loss: 2.6432051608995275

Epoch: 5| Step: 2
Training loss: 2.9873273536243734
Validation loss: 2.6361665915216075

Epoch: 5| Step: 3
Training loss: 2.600084497839357
Validation loss: 2.6270591062134017

Epoch: 5| Step: 4
Training loss: 2.928518647040591
Validation loss: 2.6262371046998565

Epoch: 5| Step: 5
Training loss: 2.9470531874958077
Validation loss: 2.6243742583006475

Epoch: 5| Step: 6
Training loss: 2.291996660459792
Validation loss: 2.624531791196256

Epoch: 5| Step: 7
Training loss: 3.2182256771541424
Validation loss: 2.6285514648824098

Epoch: 5| Step: 8
Training loss: 2.4813156964807614
Validation loss: 2.6373457589330065

Epoch: 5| Step: 9
Training loss: 2.7052355338339886
Validation loss: 2.6413747035477053

Epoch: 5| Step: 10
Training loss: 2.5289188529647153
Validation loss: 2.6440450990620747

Epoch: 5| Step: 11
Training loss: 2.7286529834117483
Validation loss: 2.639476195170536

Epoch: 70| Step: 0
Training loss: 2.7283865612091103
Validation loss: 2.6314904377194783

Epoch: 5| Step: 1
Training loss: 2.3305775058497207
Validation loss: 2.6265988287076567

Epoch: 5| Step: 2
Training loss: 2.8511059539277843
Validation loss: 2.624411089246937

Epoch: 5| Step: 3
Training loss: 2.593123946411478
Validation loss: 2.6224980332816004

Epoch: 5| Step: 4
Training loss: 2.8654656918172035
Validation loss: 2.6193763879025798

Epoch: 5| Step: 5
Training loss: 2.9151794093098893
Validation loss: 2.6151194472411925

Epoch: 5| Step: 6
Training loss: 2.9338001732259986
Validation loss: 2.613020883466023

Epoch: 5| Step: 7
Training loss: 2.7039024690272613
Validation loss: 2.614682831460475

Epoch: 5| Step: 8
Training loss: 2.9201302444465127
Validation loss: 2.6087577531398076

Epoch: 5| Step: 9
Training loss: 2.630514709959392
Validation loss: 2.6101416491416285

Epoch: 5| Step: 10
Training loss: 2.687555356897178
Validation loss: 2.612701249014284

Epoch: 5| Step: 11
Training loss: 3.263492161513007
Validation loss: 2.611473914456127

Epoch: 71| Step: 0
Training loss: 2.3440189461577075
Validation loss: 2.6079804087760636

Epoch: 5| Step: 1
Training loss: 2.5534074942208047
Validation loss: 2.609382625576306

Epoch: 5| Step: 2
Training loss: 2.4553577928418377
Validation loss: 2.608478626316842

Epoch: 5| Step: 3
Training loss: 2.519618874142488
Validation loss: 2.6098136647346046

Epoch: 5| Step: 4
Training loss: 2.7826974938181928
Validation loss: 2.608962336667653

Epoch: 5| Step: 5
Training loss: 2.8469833604643253
Validation loss: 2.6045149926244564

Epoch: 5| Step: 6
Training loss: 3.242635305341892
Validation loss: 2.608282675317189

Epoch: 5| Step: 7
Training loss: 2.9203883994471505
Validation loss: 2.6092115377671448

Epoch: 5| Step: 8
Training loss: 2.7938558810180107
Validation loss: 2.604686854224534

Epoch: 5| Step: 9
Training loss: 2.809520160120025
Validation loss: 2.6032810014840964

Epoch: 5| Step: 10
Training loss: 2.627856017873009
Validation loss: 2.60045626607469

Epoch: 5| Step: 11
Training loss: 2.923108824660085
Validation loss: 2.5988316986076234

Epoch: 72| Step: 0
Training loss: 2.517871114581919
Validation loss: 2.598671246855692

Epoch: 5| Step: 1
Training loss: 2.8021562890596683
Validation loss: 2.5984259246733505

Epoch: 5| Step: 2
Training loss: 2.528385000922649
Validation loss: 2.596981230489849

Epoch: 5| Step: 3
Training loss: 3.0573433260260123
Validation loss: 2.5956356785156003

Epoch: 5| Step: 4
Training loss: 2.9164162301220546
Validation loss: 2.5927838092412117

Epoch: 5| Step: 5
Training loss: 2.951815844800656
Validation loss: 2.592810728831056

Epoch: 5| Step: 6
Training loss: 2.7892722684048756
Validation loss: 2.591753003214568

Epoch: 5| Step: 7
Training loss: 2.67159756117948
Validation loss: 2.5882581034848857

Epoch: 5| Step: 8
Training loss: 2.468451566403755
Validation loss: 2.585405331468184

Epoch: 5| Step: 9
Training loss: 2.7418789160139414
Validation loss: 2.5882264462790876

Epoch: 5| Step: 10
Training loss: 2.4409583573530176
Validation loss: 2.5931502456950115

Epoch: 5| Step: 11
Training loss: 2.348661642234698
Validation loss: 2.591241768957162

Epoch: 73| Step: 0
Training loss: 2.727712306807838
Validation loss: 2.594268969050311

Epoch: 5| Step: 1
Training loss: 2.8934220262050463
Validation loss: 2.5921149213217567

Epoch: 5| Step: 2
Training loss: 2.840120619509287
Validation loss: 2.5838749661281604

Epoch: 5| Step: 3
Training loss: 2.5814700533932524
Validation loss: 2.5796966578757914

Epoch: 5| Step: 4
Training loss: 3.4662533960005932
Validation loss: 2.579358801723475

Epoch: 5| Step: 5
Training loss: 2.8734070054925853
Validation loss: 2.581497849056351

Epoch: 5| Step: 6
Training loss: 2.287513078329086
Validation loss: 2.582004737429332

Epoch: 5| Step: 7
Training loss: 2.4609023318729704
Validation loss: 2.5814113555735183

Epoch: 5| Step: 8
Training loss: 2.506653324693655
Validation loss: 2.5800829571378605

Epoch: 5| Step: 9
Training loss: 2.8397309124762926
Validation loss: 2.5829106120886633

Epoch: 5| Step: 10
Training loss: 2.25252962962995
Validation loss: 2.5777889572155543

Epoch: 5| Step: 11
Training loss: 1.4571477521285214
Validation loss: 2.5784380828643476

Epoch: 74| Step: 0
Training loss: 2.8539908324791443
Validation loss: 2.579854200350195

Epoch: 5| Step: 1
Training loss: 2.7983692801981896
Validation loss: 2.5765041072498596

Epoch: 5| Step: 2
Training loss: 3.1389978853129263
Validation loss: 2.5759628052960797

Epoch: 5| Step: 3
Training loss: 2.610029127170372
Validation loss: 2.5752259880575643

Epoch: 5| Step: 4
Training loss: 2.278615292299047
Validation loss: 2.5756094634128934

Epoch: 5| Step: 5
Training loss: 2.683909035364933
Validation loss: 2.5773561390832143

Epoch: 5| Step: 6
Training loss: 2.328388788012975
Validation loss: 2.57383132357738

Epoch: 5| Step: 7
Training loss: 2.4899928076766598
Validation loss: 2.5733933811540215

Epoch: 5| Step: 8
Training loss: 2.7150322059702288
Validation loss: 2.576940946621038

Epoch: 5| Step: 9
Training loss: 2.6217673242076067
Validation loss: 2.5766173298871693

Epoch: 5| Step: 10
Training loss: 3.120042760018013
Validation loss: 2.5730869195699406

Epoch: 5| Step: 11
Training loss: 2.0443709103978676
Validation loss: 2.573877299407312

Epoch: 75| Step: 0
Training loss: 2.5801643397605742
Validation loss: 2.5764467267733053

Epoch: 5| Step: 1
Training loss: 2.075128905187466
Validation loss: 2.573881653019562

Epoch: 5| Step: 2
Training loss: 2.937691377939324
Validation loss: 2.5759402911616793

Epoch: 5| Step: 3
Training loss: 2.7077939498979164
Validation loss: 2.576719112660305

Epoch: 5| Step: 4
Training loss: 3.0031103858234913
Validation loss: 2.5700029768475066

Epoch: 5| Step: 5
Training loss: 2.5880112184461215
Validation loss: 2.5696890054480543

Epoch: 5| Step: 6
Training loss: 2.610443444709604
Validation loss: 2.569068251956288

Epoch: 5| Step: 7
Training loss: 2.7566461879549227
Validation loss: 2.566545030779119

Epoch: 5| Step: 8
Training loss: 2.1769292189762104
Validation loss: 2.5639392447345455

Epoch: 5| Step: 9
Training loss: 2.7055389562624597
Validation loss: 2.5649398609086282

Epoch: 5| Step: 10
Training loss: 3.100140685303936
Validation loss: 2.564617321203402

Epoch: 5| Step: 11
Training loss: 3.567897121511485
Validation loss: 2.5623611280756595

Epoch: 76| Step: 0
Training loss: 2.8419373153119682
Validation loss: 2.562130905334642

Epoch: 5| Step: 1
Training loss: 2.730763344432897
Validation loss: 2.5610237948029586

Epoch: 5| Step: 2
Training loss: 2.5746079933511217
Validation loss: 2.5571577473450726

Epoch: 5| Step: 3
Training loss: 2.6924128318001386
Validation loss: 2.5570045058758115

Epoch: 5| Step: 4
Training loss: 2.9875117090227197
Validation loss: 2.555135495163318

Epoch: 5| Step: 5
Training loss: 2.2907735529214057
Validation loss: 2.5529687292801477

Epoch: 5| Step: 6
Training loss: 2.6765735205107783
Validation loss: 2.559033755452596

Epoch: 5| Step: 7
Training loss: 2.626853651694718
Validation loss: 2.5560935075917834

Epoch: 5| Step: 8
Training loss: 2.3906368679175904
Validation loss: 2.5540696504244575

Epoch: 5| Step: 9
Training loss: 2.8040638179727067
Validation loss: 2.5575559923624867

Epoch: 5| Step: 10
Training loss: 2.837277938959325
Validation loss: 2.556274407261709

Epoch: 5| Step: 11
Training loss: 2.660063485700167
Validation loss: 2.5538362412743494

Epoch: 77| Step: 0
Training loss: 2.777716803411322
Validation loss: 2.5495375385297656

Epoch: 5| Step: 1
Training loss: 2.665335879460935
Validation loss: 2.553226597638765

Epoch: 5| Step: 2
Training loss: 2.4300484833766753
Validation loss: 2.550011156874291

Epoch: 5| Step: 3
Training loss: 2.485010893431337
Validation loss: 2.551722498446334

Epoch: 5| Step: 4
Training loss: 2.3921041462913153
Validation loss: 2.5549952800885056

Epoch: 5| Step: 5
Training loss: 2.8915372491581435
Validation loss: 2.5517444048185123

Epoch: 5| Step: 6
Training loss: 2.7534627787323993
Validation loss: 2.5517162733739687

Epoch: 5| Step: 7
Training loss: 2.723538533545519
Validation loss: 2.550181732683043

Epoch: 5| Step: 8
Training loss: 2.4207579959389465
Validation loss: 2.548082155315488

Epoch: 5| Step: 9
Training loss: 3.08185997548693
Validation loss: 2.5476145031520936

Epoch: 5| Step: 10
Training loss: 2.9272053287012434
Validation loss: 2.547292019924186

Epoch: 5| Step: 11
Training loss: 1.642046721110856
Validation loss: 2.5486498774029474

Epoch: 78| Step: 0
Training loss: 2.477336870783623
Validation loss: 2.549678203748003

Epoch: 5| Step: 1
Training loss: 2.2994074970509026
Validation loss: 2.5462676262124506

Epoch: 5| Step: 2
Training loss: 2.856318606965454
Validation loss: 2.551267899751522

Epoch: 5| Step: 3
Training loss: 2.6846349659138986
Validation loss: 2.550509350214425

Epoch: 5| Step: 4
Training loss: 2.9152795126961664
Validation loss: 2.5485468683683714

Epoch: 5| Step: 5
Training loss: 2.0864073263539944
Validation loss: 2.550332809371738

Epoch: 5| Step: 6
Training loss: 2.2815205661800615
Validation loss: 2.548563781515933

Epoch: 5| Step: 7
Training loss: 2.6932533248814274
Validation loss: 2.5447644575124126

Epoch: 5| Step: 8
Training loss: 2.975890556845672
Validation loss: 2.541843690856801

Epoch: 5| Step: 9
Training loss: 2.93140525813381
Validation loss: 2.5474274588050174

Epoch: 5| Step: 10
Training loss: 2.9862557920748656
Validation loss: 2.5382474168107874

Epoch: 5| Step: 11
Training loss: 2.7282482281062768
Validation loss: 2.5412405678292114

Epoch: 79| Step: 0
Training loss: 2.9235153081867296
Validation loss: 2.541074130034481

Epoch: 5| Step: 1
Training loss: 2.7858866072374537
Validation loss: 2.5653935509634125

Epoch: 5| Step: 2
Training loss: 2.3890960391617537
Validation loss: 2.5875725854223304

Epoch: 5| Step: 3
Training loss: 2.8223446950428857
Validation loss: 2.6223591091964895

Epoch: 5| Step: 4
Training loss: 2.748327700453199
Validation loss: 2.629585603449972

Epoch: 5| Step: 5
Training loss: 2.7905572897972157
Validation loss: 2.6223409710738883

Epoch: 5| Step: 6
Training loss: 2.6420306916630807
Validation loss: 2.5900178930346947

Epoch: 5| Step: 7
Training loss: 2.795567894362386
Validation loss: 2.5664812770891112

Epoch: 5| Step: 8
Training loss: 2.10418560158044
Validation loss: 2.544399724146948

Epoch: 5| Step: 9
Training loss: 2.7496099195386323
Validation loss: 2.5449456940573385

Epoch: 5| Step: 10
Training loss: 3.002010148846412
Validation loss: 2.5346705672401977

Epoch: 5| Step: 11
Training loss: 2.9476073049955094
Validation loss: 2.533656205026938

Epoch: 80| Step: 0
Training loss: 2.685394349361835
Validation loss: 2.5337078657318326

Epoch: 5| Step: 1
Training loss: 2.316103318784046
Validation loss: 2.530369570167315

Epoch: 5| Step: 2
Training loss: 2.9389291087112452
Validation loss: 2.532261599214833

Epoch: 5| Step: 3
Training loss: 2.6707290065661233
Validation loss: 2.5358947830222047

Epoch: 5| Step: 4
Training loss: 2.679686788219658
Validation loss: 2.536954906872077

Epoch: 5| Step: 5
Training loss: 2.3080308360216626
Validation loss: 2.54216787732786

Epoch: 5| Step: 6
Training loss: 2.948282136043112
Validation loss: 2.539187141684782

Epoch: 5| Step: 7
Training loss: 2.326960329944675
Validation loss: 2.5463137876186

Epoch: 5| Step: 8
Training loss: 2.7206579945388745
Validation loss: 2.5502180458168313

Epoch: 5| Step: 9
Training loss: 3.262120753202076
Validation loss: 2.5534200839435854

Epoch: 5| Step: 10
Training loss: 2.5879161444791277
Validation loss: 2.5460394988630703

Epoch: 5| Step: 11
Training loss: 0.3846121157452248
Validation loss: 2.5437429278038746

Epoch: 81| Step: 0
Training loss: 2.4661371431664194
Validation loss: 2.5453784227664644

Epoch: 5| Step: 1
Training loss: 2.80270060342785
Validation loss: 2.545128026201545

Epoch: 5| Step: 2
Training loss: 2.4249270988596616
Validation loss: 2.5409066257267363

Epoch: 5| Step: 3
Training loss: 3.13432112064624
Validation loss: 2.5354512165027767

Epoch: 5| Step: 4
Training loss: 2.31021768477293
Validation loss: 2.53615361967623

Epoch: 5| Step: 5
Training loss: 2.5964394838835045
Validation loss: 2.529346007038059

Epoch: 5| Step: 6
Training loss: 2.50116997998303
Validation loss: 2.5262817714404022

Epoch: 5| Step: 7
Training loss: 2.847885813309911
Validation loss: 2.5221922314490417

Epoch: 5| Step: 8
Training loss: 2.092046585636512
Validation loss: 2.5203922939420154

Epoch: 5| Step: 9
Training loss: 2.8088119910155616
Validation loss: 2.526863752219464

Epoch: 5| Step: 10
Training loss: 2.9114662857265516
Validation loss: 2.524350799220389

Epoch: 5| Step: 11
Training loss: 3.3929502890284673
Validation loss: 2.5271775487291346

Epoch: 82| Step: 0
Training loss: 2.616164369015599
Validation loss: 2.5250668260336435

Epoch: 5| Step: 1
Training loss: 2.9696682764647657
Validation loss: 2.5221859334922616

Epoch: 5| Step: 2
Training loss: 2.575473138247367
Validation loss: 2.5222679868776368

Epoch: 5| Step: 3
Training loss: 2.7570919143691572
Validation loss: 2.5224145916284537

Epoch: 5| Step: 4
Training loss: 2.2700738832658818
Validation loss: 2.5211261915435186

Epoch: 5| Step: 5
Training loss: 2.5992314890167236
Validation loss: 2.51819076561405

Epoch: 5| Step: 6
Training loss: 2.725829454926737
Validation loss: 2.5187702143436175

Epoch: 5| Step: 7
Training loss: 2.3512397620684475
Validation loss: 2.5189861644401765

Epoch: 5| Step: 8
Training loss: 2.87853521184305
Validation loss: 2.5218791303006007

Epoch: 5| Step: 9
Training loss: 2.3774225027006994
Validation loss: 2.512156245215981

Epoch: 5| Step: 10
Training loss: 3.037652715917666
Validation loss: 2.522550795181997

Epoch: 5| Step: 11
Training loss: 0.944356545319109
Validation loss: 2.525383780367634

Epoch: 83| Step: 0
Training loss: 2.485129571679736
Validation loss: 2.5229663546830325

Epoch: 5| Step: 1
Training loss: 2.751162716678193
Validation loss: 2.5176498051696634

Epoch: 5| Step: 2
Training loss: 2.736370818780513
Validation loss: 2.515729538698211

Epoch: 5| Step: 3
Training loss: 2.520684503202465
Validation loss: 2.516224669227755

Epoch: 5| Step: 4
Training loss: 2.7700499572105004
Validation loss: 2.5155501107704374

Epoch: 5| Step: 5
Training loss: 2.7969309199193284
Validation loss: 2.516704359361767

Epoch: 5| Step: 6
Training loss: 2.920329945095282
Validation loss: 2.517899856942632

Epoch: 5| Step: 7
Training loss: 2.59365633140472
Validation loss: 2.520334053775126

Epoch: 5| Step: 8
Training loss: 2.4049645495429046
Validation loss: 2.5179256675791217

Epoch: 5| Step: 9
Training loss: 2.809568360732073
Validation loss: 2.51738981968671

Epoch: 5| Step: 10
Training loss: 2.1438130494569085
Validation loss: 2.51659148469209

Epoch: 5| Step: 11
Training loss: 1.964327310146486
Validation loss: 2.5201212268639197

Epoch: 84| Step: 0
Training loss: 2.625055403351804
Validation loss: 2.519138157660408

Epoch: 5| Step: 1
Training loss: 2.940922630239229
Validation loss: 2.517820695309233

Epoch: 5| Step: 2
Training loss: 2.680308812127651
Validation loss: 2.512897790192645

Epoch: 5| Step: 3
Training loss: 2.5782051767540075
Validation loss: 2.5150468845181115

Epoch: 5| Step: 4
Training loss: 2.7501461683788246
Validation loss: 2.5144087890205586

Epoch: 5| Step: 5
Training loss: 2.1954641052244743
Validation loss: 2.5128075873204323

Epoch: 5| Step: 6
Training loss: 2.283824669630431
Validation loss: 2.5163787399725805

Epoch: 5| Step: 7
Training loss: 2.5369137166544533
Validation loss: 2.5140844054499634

Epoch: 5| Step: 8
Training loss: 2.8865571964054544
Validation loss: 2.5148827383766488

Epoch: 5| Step: 9
Training loss: 2.6871498234628772
Validation loss: 2.5151328282643077

Epoch: 5| Step: 10
Training loss: 2.689903160677808
Validation loss: 2.512240251396256

Epoch: 5| Step: 11
Training loss: 2.0299098362184145
Validation loss: 2.5130716756839604

Epoch: 85| Step: 0
Training loss: 2.894444267417754
Validation loss: 2.518075823265419

Epoch: 5| Step: 1
Training loss: 2.8548915712841114
Validation loss: 2.5140593930784965

Epoch: 5| Step: 2
Training loss: 2.541105979820104
Validation loss: 2.513053907002176

Epoch: 5| Step: 3
Training loss: 2.4905800732780934
Validation loss: 2.5110842079739446

Epoch: 5| Step: 4
Training loss: 3.065240373504708
Validation loss: 2.511067548769464

Epoch: 5| Step: 5
Training loss: 2.3834188721607705
Validation loss: 2.511959647753297

Epoch: 5| Step: 6
Training loss: 2.8363882500018462
Validation loss: 2.5113539482731686

Epoch: 5| Step: 7
Training loss: 2.2958292753964913
Validation loss: 2.510507417096419

Epoch: 5| Step: 8
Training loss: 2.429674743422601
Validation loss: 2.512281377573948

Epoch: 5| Step: 9
Training loss: 2.292174531552815
Validation loss: 2.5094879432176285

Epoch: 5| Step: 10
Training loss: 2.5643091095973998
Validation loss: 2.506744688241034

Epoch: 5| Step: 11
Training loss: 2.6460028967001725
Validation loss: 2.5132106267911647

Epoch: 86| Step: 0
Training loss: 2.8833381152986184
Validation loss: 2.504647909332632

Epoch: 5| Step: 1
Training loss: 2.549393046830277
Validation loss: 2.502330417063582

Epoch: 5| Step: 2
Training loss: 2.0038393838594333
Validation loss: 2.5150842124846258

Epoch: 5| Step: 3
Training loss: 2.259651253723049
Validation loss: 2.5068226541351257

Epoch: 5| Step: 4
Training loss: 3.247283533882785
Validation loss: 2.5116999552781456

Epoch: 5| Step: 5
Training loss: 2.6954152847815642
Validation loss: 2.5074700808047505

Epoch: 5| Step: 6
Training loss: 2.6718844586478228
Validation loss: 2.5067269103778504

Epoch: 5| Step: 7
Training loss: 2.605021883091015
Validation loss: 2.5064937534851794

Epoch: 5| Step: 8
Training loss: 2.334796333334421
Validation loss: 2.503288299910636

Epoch: 5| Step: 9
Training loss: 2.3111311495454276
Validation loss: 2.5062631632077883

Epoch: 5| Step: 10
Training loss: 2.9070080824648756
Validation loss: 2.506494546154691

Epoch: 5| Step: 11
Training loss: 2.904779862222546
Validation loss: 2.5044110206442456

Epoch: 87| Step: 0
Training loss: 2.9368308096429003
Validation loss: 2.5048250366448515

Epoch: 5| Step: 1
Training loss: 2.15209461023331
Validation loss: 2.50507120932243

Epoch: 5| Step: 2
Training loss: 2.714124230191769
Validation loss: 2.499127668935276

Epoch: 5| Step: 3
Training loss: 2.830859469327824
Validation loss: 2.501883881777327

Epoch: 5| Step: 4
Training loss: 3.1349680802516597
Validation loss: 2.502244938775189

Epoch: 5| Step: 5
Training loss: 2.5371496888937712
Validation loss: 2.500988240421413

Epoch: 5| Step: 6
Training loss: 2.723470163942818
Validation loss: 2.5016820454511284

Epoch: 5| Step: 7
Training loss: 2.37934217546095
Validation loss: 2.499573289694503

Epoch: 5| Step: 8
Training loss: 2.650858624827439
Validation loss: 2.504307588260711

Epoch: 5| Step: 9
Training loss: 2.276387715748279
Validation loss: 2.5068167336628293

Epoch: 5| Step: 10
Training loss: 2.2670790643084513
Validation loss: 2.5049976582811264

Epoch: 5| Step: 11
Training loss: 2.765638965636084
Validation loss: 2.5018926529297687

Epoch: 88| Step: 0
Training loss: 2.519004116065587
Validation loss: 2.5052499443822893

Epoch: 5| Step: 1
Training loss: 2.6586782688065
Validation loss: 2.503167605345068

Epoch: 5| Step: 2
Training loss: 2.784867666309076
Validation loss: 2.5055393441792537

Epoch: 5| Step: 3
Training loss: 3.053418766753282
Validation loss: 2.5031377453108465

Epoch: 5| Step: 4
Training loss: 2.966915165926832
Validation loss: 2.5033831513658917

Epoch: 5| Step: 5
Training loss: 2.6135189022462955
Validation loss: 2.502911932152104

Epoch: 5| Step: 6
Training loss: 2.406553274091654
Validation loss: 2.501953017795391

Epoch: 5| Step: 7
Training loss: 2.6767229859383894
Validation loss: 2.5027644171930326

Epoch: 5| Step: 8
Training loss: 2.209440445638829
Validation loss: 2.501928086643169

Epoch: 5| Step: 9
Training loss: 2.2556541184353067
Validation loss: 2.498289230238183

Epoch: 5| Step: 10
Training loss: 2.5316261671324742
Validation loss: 2.499546347624949

Epoch: 5| Step: 11
Training loss: 1.7830022257920952
Validation loss: 2.495736181589837

Epoch: 89| Step: 0
Training loss: 2.519206749179409
Validation loss: 2.496771969537475

Epoch: 5| Step: 1
Training loss: 2.49419788363577
Validation loss: 2.502272602125445

Epoch: 5| Step: 2
Training loss: 2.2750031104433366
Validation loss: 2.5008622232357576

Epoch: 5| Step: 3
Training loss: 2.857046711530148
Validation loss: 2.5008101541393457

Epoch: 5| Step: 4
Training loss: 2.6263302656687477
Validation loss: 2.4977773262963567

Epoch: 5| Step: 5
Training loss: 2.2020245773094147
Validation loss: 2.5000139633424543

Epoch: 5| Step: 6
Training loss: 2.423498679986889
Validation loss: 2.506592351721981

Epoch: 5| Step: 7
Training loss: 2.537789926737388
Validation loss: 2.5032903634898696

Epoch: 5| Step: 8
Training loss: 2.625663128607552
Validation loss: 2.50672987072182

Epoch: 5| Step: 9
Training loss: 3.2451346732996402
Validation loss: 2.5043353676633044

Epoch: 5| Step: 10
Training loss: 2.5753838040136996
Validation loss: 2.5050284201455884

Epoch: 5| Step: 11
Training loss: 2.5348759806315213
Validation loss: 2.500913314089088

Epoch: 90| Step: 0
Training loss: 2.8882079870720725
Validation loss: 2.5012602371509614

Epoch: 5| Step: 1
Training loss: 2.7549691820584483
Validation loss: 2.494866906918269

Epoch: 5| Step: 2
Training loss: 2.1386054320443795
Validation loss: 2.4986326571250568

Epoch: 5| Step: 3
Training loss: 2.350042517257137
Validation loss: 2.4995679124319476

Epoch: 5| Step: 4
Training loss: 2.6890883077106746
Validation loss: 2.4948165662686987

Epoch: 5| Step: 5
Training loss: 2.3997329046715654
Validation loss: 2.4958748798595454

Epoch: 5| Step: 6
Training loss: 2.8264937780997714
Validation loss: 2.4946733352429113

Epoch: 5| Step: 7
Training loss: 2.486576088933763
Validation loss: 2.4967958023185326

Epoch: 5| Step: 8
Training loss: 2.867283458299304
Validation loss: 2.495242260649211

Epoch: 5| Step: 9
Training loss: 2.8048768046043606
Validation loss: 2.4926332694926647

Epoch: 5| Step: 10
Training loss: 2.2779402041738286
Validation loss: 2.4943038659979484

Epoch: 5| Step: 11
Training loss: 2.471034477842435
Validation loss: 2.4944589601406837

Epoch: 91| Step: 0
Training loss: 2.3893982974988863
Validation loss: 2.4954059232207806

Epoch: 5| Step: 1
Training loss: 2.709890377741321
Validation loss: 2.4910947941336827

Epoch: 5| Step: 2
Training loss: 2.9455721712868903
Validation loss: 2.499949736884606

Epoch: 5| Step: 3
Training loss: 1.992972544655651
Validation loss: 2.4988089823858015

Epoch: 5| Step: 4
Training loss: 2.437809557698409
Validation loss: 2.4997342127340154

Epoch: 5| Step: 5
Training loss: 2.7485761424234663
Validation loss: 2.4980554647648447

Epoch: 5| Step: 6
Training loss: 2.4181695956379534
Validation loss: 2.496925490039529

Epoch: 5| Step: 7
Training loss: 2.8081051715869907
Validation loss: 2.4943938459096864

Epoch: 5| Step: 8
Training loss: 2.6830902293556074
Validation loss: 2.498079937479214

Epoch: 5| Step: 9
Training loss: 2.4795343997182187
Validation loss: 2.496005240290441

Epoch: 5| Step: 10
Training loss: 2.581597780901579
Validation loss: 2.498797017978681

Epoch: 5| Step: 11
Training loss: 3.3229620919466054
Validation loss: 2.4979657082175177

Epoch: 92| Step: 0
Training loss: 2.602991576513436
Validation loss: 2.493704781405154

Epoch: 5| Step: 1
Training loss: 2.3434380895967677
Validation loss: 2.4966960850838436

Epoch: 5| Step: 2
Training loss: 2.7042408663107107
Validation loss: 2.492246916091567

Epoch: 5| Step: 3
Training loss: 2.195262976254123
Validation loss: 2.4948896310535478

Epoch: 5| Step: 4
Training loss: 2.3205967995481243
Validation loss: 2.4942242302918323

Epoch: 5| Step: 5
Training loss: 2.6623844891774913
Validation loss: 2.493636213461706

Epoch: 5| Step: 6
Training loss: 2.6567301596692854
Validation loss: 2.4943899111237138

Epoch: 5| Step: 7
Training loss: 2.43159964040511
Validation loss: 2.49827235449219

Epoch: 5| Step: 8
Training loss: 3.1239582614235117
Validation loss: 2.4993053981320124

Epoch: 5| Step: 9
Training loss: 2.4965829384807905
Validation loss: 2.4935196651440314

Epoch: 5| Step: 10
Training loss: 2.7014832555070845
Validation loss: 2.4996277849946487

Epoch: 5| Step: 11
Training loss: 3.1962790671150616
Validation loss: 2.4959756667055752

Epoch: 93| Step: 0
Training loss: 2.4496608499390526
Validation loss: 2.4967232449168386

Epoch: 5| Step: 1
Training loss: 2.251335807152043
Validation loss: 2.511028030684683

Epoch: 5| Step: 2
Training loss: 2.702321897949376
Validation loss: 2.5044266452070305

Epoch: 5| Step: 3
Training loss: 2.6345639162214316
Validation loss: 2.498242264961029

Epoch: 5| Step: 4
Training loss: 2.7121108096730326
Validation loss: 2.5018272020791597

Epoch: 5| Step: 5
Training loss: 2.237904994690076
Validation loss: 2.49937793621817

Epoch: 5| Step: 6
Training loss: 2.3393576599505757
Validation loss: 2.49850683126024

Epoch: 5| Step: 7
Training loss: 2.7869723312378705
Validation loss: 2.504404531205918

Epoch: 5| Step: 8
Training loss: 2.3976214384284518
Validation loss: 2.5032893118583575

Epoch: 5| Step: 9
Training loss: 3.192697812302115
Validation loss: 2.5002646067775953

Epoch: 5| Step: 10
Training loss: 2.5488989341517203
Validation loss: 2.4996762622393542

Epoch: 5| Step: 11
Training loss: 3.1701535218425594
Validation loss: 2.498176736366717

Epoch: 94| Step: 0
Training loss: 2.6138646225901354
Validation loss: 2.5003078310909825

Epoch: 5| Step: 1
Training loss: 2.49541548944576
Validation loss: 2.5006670578484504

Epoch: 5| Step: 2
Training loss: 3.0103150100879703
Validation loss: 2.493755417374134

Epoch: 5| Step: 3
Training loss: 2.6223901763117565
Validation loss: 2.500082139811575

Epoch: 5| Step: 4
Training loss: 2.52869955543366
Validation loss: 2.497448743963105

Epoch: 5| Step: 5
Training loss: 2.63174860708541
Validation loss: 2.5031814200543114

Epoch: 5| Step: 6
Training loss: 2.5699624979867606
Validation loss: 2.502001354696668

Epoch: 5| Step: 7
Training loss: 2.2780742749504816
Validation loss: 2.5051166863970438

Epoch: 5| Step: 8
Training loss: 2.6974087289778264
Validation loss: 2.50384565846434

Epoch: 5| Step: 9
Training loss: 2.402667065705419
Validation loss: 2.505903654433266

Epoch: 5| Step: 10
Training loss: 2.874624808335218
Validation loss: 2.5027357351998893

Epoch: 5| Step: 11
Training loss: 2.866178662509936
Validation loss: 2.50412297017654

Epoch: 95| Step: 0
Training loss: 3.026647317827307
Validation loss: 2.5025816700400894

Epoch: 5| Step: 1
Training loss: 2.3945519600450247
Validation loss: 2.498909287145642

Epoch: 5| Step: 2
Training loss: 2.4696184393344813
Validation loss: 2.50020923136311

Epoch: 5| Step: 3
Training loss: 2.4885120614165555
Validation loss: 2.4987875939054263

Epoch: 5| Step: 4
Training loss: 2.92476066849179
Validation loss: 2.4956789741694974

Epoch: 5| Step: 5
Training loss: 2.137968433650252
Validation loss: 2.4959067014398246

Epoch: 5| Step: 6
Training loss: 2.9297099608514006
Validation loss: 2.495413682096867

Epoch: 5| Step: 7
Training loss: 2.8232124614701064
Validation loss: 2.4920740729562105

Epoch: 5| Step: 8
Training loss: 2.5576903633873664
Validation loss: 2.492451676704096

Epoch: 5| Step: 9
Training loss: 2.730835984055792
Validation loss: 2.486741320569237

Epoch: 5| Step: 10
Training loss: 2.1101420950388348
Validation loss: 2.4869702656904518

Epoch: 5| Step: 11
Training loss: 2.6195804417260846
Validation loss: 2.4851799766401643

Epoch: 96| Step: 0
Training loss: 2.7885875992144182
Validation loss: 2.4773059495223246

Epoch: 5| Step: 1
Training loss: 2.736952433408681
Validation loss: 2.4863334350049775

Epoch: 5| Step: 2
Training loss: 2.6076998330309134
Validation loss: 2.4834515876797663

Epoch: 5| Step: 3
Training loss: 2.245803310026107
Validation loss: 2.4818996397351727

Epoch: 5| Step: 4
Training loss: 2.7486209879701957
Validation loss: 2.4896559059599843

Epoch: 5| Step: 5
Training loss: 2.9613846816114435
Validation loss: 2.48177838933114

Epoch: 5| Step: 6
Training loss: 2.245126426382415
Validation loss: 2.487234237665686

Epoch: 5| Step: 7
Training loss: 2.375269222058481
Validation loss: 2.482098722196189

Epoch: 5| Step: 8
Training loss: 2.448110326587137
Validation loss: 2.485911092372156

Epoch: 5| Step: 9
Training loss: 2.631741087837454
Validation loss: 2.484490393911702

Epoch: 5| Step: 10
Training loss: 2.6235385641292077
Validation loss: 2.4930815572867373

Epoch: 5| Step: 11
Training loss: 2.2029344192211906
Validation loss: 2.4899068459929814

Epoch: 97| Step: 0
Training loss: 2.967362892949251
Validation loss: 2.4873453752744155

Epoch: 5| Step: 1
Training loss: 2.296352093399253
Validation loss: 2.485141479966356

Epoch: 5| Step: 2
Training loss: 2.4360238520577315
Validation loss: 2.4784010952619977

Epoch: 5| Step: 3
Training loss: 2.032689332859224
Validation loss: 2.4810935487596364

Epoch: 5| Step: 4
Training loss: 3.081576508406151
Validation loss: 2.488088571383518

Epoch: 5| Step: 5
Training loss: 2.5369690701377685
Validation loss: 2.480176420832923

Epoch: 5| Step: 6
Training loss: 2.2526387529896903
Validation loss: 2.4838148041289374

Epoch: 5| Step: 7
Training loss: 2.5774854386933064
Validation loss: 2.484501637524092

Epoch: 5| Step: 8
Training loss: 2.8366683144420795
Validation loss: 2.4853055998443665

Epoch: 5| Step: 9
Training loss: 2.189421327685028
Validation loss: 2.4912381611204744

Epoch: 5| Step: 10
Training loss: 2.9662751171593493
Validation loss: 2.4909247464898505

Epoch: 5| Step: 11
Training loss: 2.4758994962911687
Validation loss: 2.4871249703745693

Epoch: 98| Step: 0
Training loss: 2.116612655471185
Validation loss: 2.4846099806367437

Epoch: 5| Step: 1
Training loss: 2.334562375312001
Validation loss: 2.4858019367645428

Epoch: 5| Step: 2
Training loss: 2.4195858873770204
Validation loss: 2.486671669742351

Epoch: 5| Step: 3
Training loss: 2.7998599528302566
Validation loss: 2.489039291142724

Epoch: 5| Step: 4
Training loss: 2.0394713477880697
Validation loss: 2.4859389614610037

Epoch: 5| Step: 5
Training loss: 3.394895334329865
Validation loss: 2.4879670915448577

Epoch: 5| Step: 6
Training loss: 2.8240184158881023
Validation loss: 2.487326018959997

Epoch: 5| Step: 7
Training loss: 2.5362163848679793
Validation loss: 2.486995023240807

Epoch: 5| Step: 8
Training loss: 2.42913949557551
Validation loss: 2.480001554770649

Epoch: 5| Step: 9
Training loss: 2.8276809428067984
Validation loss: 2.4804798396305685

Epoch: 5| Step: 10
Training loss: 2.5592793019420763
Validation loss: 2.475328372595731

Epoch: 5| Step: 11
Training loss: 2.341745969395627
Validation loss: 2.475339718022765

Epoch: 99| Step: 0
Training loss: 2.1818257443701565
Validation loss: 2.4814561055226547

Epoch: 5| Step: 1
Training loss: 2.5353734844692037
Validation loss: 2.472099060629239

Epoch: 5| Step: 2
Training loss: 2.671182732384443
Validation loss: 2.473776854166437

Epoch: 5| Step: 3
Training loss: 2.259788519661734
Validation loss: 2.4732453185441763

Epoch: 5| Step: 4
Training loss: 2.6198042356721714
Validation loss: 2.4754942426183733

Epoch: 5| Step: 5
Training loss: 3.017126154461161
Validation loss: 2.482907687635767

Epoch: 5| Step: 6
Training loss: 2.4839085554899425
Validation loss: 2.473911808312613

Epoch: 5| Step: 7
Training loss: 2.775833685111538
Validation loss: 2.4817990357810302

Epoch: 5| Step: 8
Training loss: 2.8495764099682535
Validation loss: 2.4745187318775943

Epoch: 5| Step: 9
Training loss: 2.363861769318803
Validation loss: 2.478937893150673

Epoch: 5| Step: 10
Training loss: 2.5993017506167453
Validation loss: 2.4733035790533626

Epoch: 5| Step: 11
Training loss: 0.6204232009003892
Validation loss: 2.479834027318855

Epoch: 100| Step: 0
Training loss: 2.473640330439128
Validation loss: 2.4723705309471904

Epoch: 5| Step: 1
Training loss: 2.600941443558902
Validation loss: 2.4735575635779345

Epoch: 5| Step: 2
Training loss: 2.103821855248349
Validation loss: 2.4742354602528485

Epoch: 5| Step: 3
Training loss: 2.99822532296695
Validation loss: 2.4794292484532154

Epoch: 5| Step: 4
Training loss: 1.443916099868927
Validation loss: 2.4728409917597602

Epoch: 5| Step: 5
Training loss: 2.8435683978436903
Validation loss: 2.47092320362923

Epoch: 5| Step: 6
Training loss: 3.2303022459357664
Validation loss: 2.4735978810920827

Epoch: 5| Step: 7
Training loss: 2.8733120814671147
Validation loss: 2.4745274314169237

Epoch: 5| Step: 8
Training loss: 2.2193046199002615
Validation loss: 2.46851627434557

Epoch: 5| Step: 9
Training loss: 2.78628375971225
Validation loss: 2.4727195181242663

Epoch: 5| Step: 10
Training loss: 2.196016789203661
Validation loss: 2.467020986589898

Epoch: 5| Step: 11
Training loss: 2.3710746450141555
Validation loss: 2.474981904686177

Epoch: 101| Step: 0
Training loss: 2.757646766415883
Validation loss: 2.48189944360666

Epoch: 5| Step: 1
Training loss: 2.5503609794474746
Validation loss: 2.4729336708007

Epoch: 5| Step: 2
Training loss: 2.754263087752362
Validation loss: 2.4828497765225275

Epoch: 5| Step: 3
Training loss: 2.468533663385133
Validation loss: 2.481201203904994

Epoch: 5| Step: 4
Training loss: 2.212712845559011
Validation loss: 2.4796530756637103

Epoch: 5| Step: 5
Training loss: 2.3251282523272794
Validation loss: 2.482889326990331

Epoch: 5| Step: 6
Training loss: 2.7898715686292443
Validation loss: 2.4818437945170815

Epoch: 5| Step: 7
Training loss: 2.9154401289213103
Validation loss: 2.4795951326085546

Epoch: 5| Step: 8
Training loss: 2.533945414568686
Validation loss: 2.4793665482114404

Epoch: 5| Step: 9
Training loss: 2.458817601324269
Validation loss: 2.481743880796364

Epoch: 5| Step: 10
Training loss: 2.4652751176369034
Validation loss: 2.4859588700452324

Epoch: 5| Step: 11
Training loss: 1.7971225733828529
Validation loss: 2.483242648557607

Epoch: 102| Step: 0
Training loss: 2.7529009343567603
Validation loss: 2.486116850317707

Epoch: 5| Step: 1
Training loss: 2.693003851626107
Validation loss: 2.4864741839598965

Epoch: 5| Step: 2
Training loss: 2.6694862440075995
Validation loss: 2.486439229196373

Epoch: 5| Step: 3
Training loss: 2.5375837039765803
Validation loss: 2.482571929230204

Epoch: 5| Step: 4
Training loss: 2.7364607349313093
Validation loss: 2.4800043507378877

Epoch: 5| Step: 5
Training loss: 1.6791699698946563
Validation loss: 2.481897234157855

Epoch: 5| Step: 6
Training loss: 2.4956020772422414
Validation loss: 2.4823619716248677

Epoch: 5| Step: 7
Training loss: 2.7256093804975343
Validation loss: 2.486325352126076

Epoch: 5| Step: 8
Training loss: 2.5355728347899813
Validation loss: 2.4817667371002905

Epoch: 5| Step: 9
Training loss: 2.3459175767785565
Validation loss: 2.485285682029894

Epoch: 5| Step: 10
Training loss: 2.6895867164249747
Validation loss: 2.484804899979466

Epoch: 5| Step: 11
Training loss: 2.7762471326377796
Validation loss: 2.481774610667975

Epoch: 103| Step: 0
Training loss: 2.8596348045178708
Validation loss: 2.488602266708832

Epoch: 5| Step: 1
Training loss: 2.409508616580664
Validation loss: 2.4796495501621525

Epoch: 5| Step: 2
Training loss: 2.6334503940525993
Validation loss: 2.478918721652264

Epoch: 5| Step: 3
Training loss: 3.032695307720143
Validation loss: 2.480504706014516

Epoch: 5| Step: 4
Training loss: 2.5612420506724014
Validation loss: 2.472813744372929

Epoch: 5| Step: 5
Training loss: 2.508406048942649
Validation loss: 2.483784343473725

Epoch: 5| Step: 6
Training loss: 2.3647950423548743
Validation loss: 2.4863472353711984

Epoch: 5| Step: 7
Training loss: 2.515761282884069
Validation loss: 2.4891884675511706

Epoch: 5| Step: 8
Training loss: 2.3695087194079067
Validation loss: 2.474745672657949

Epoch: 5| Step: 9
Training loss: 2.3527417442007494
Validation loss: 2.470076570739717

Epoch: 5| Step: 10
Training loss: 2.4839171941472546
Validation loss: 2.4864910438941896

Epoch: 5| Step: 11
Training loss: 2.49365956230904
Validation loss: 2.4906302742002797

Epoch: 104| Step: 0
Training loss: 2.9384785097825055
Validation loss: 2.4902306929417732

Epoch: 5| Step: 1
Training loss: 2.8622167255547595
Validation loss: 2.492368573952069

Epoch: 5| Step: 2
Training loss: 2.628666360914906
Validation loss: 2.494699613164335

Epoch: 5| Step: 3
Training loss: 2.7775330297942276
Validation loss: 2.4776589446433954

Epoch: 5| Step: 4
Training loss: 2.408120456337819
Validation loss: 2.4907933783323153

Epoch: 5| Step: 5
Training loss: 2.501042244140694
Validation loss: 2.4873765611292686

Epoch: 5| Step: 6
Training loss: 2.5287247294182955
Validation loss: 2.4813590426951118

Epoch: 5| Step: 7
Training loss: 2.6809593274319248
Validation loss: 2.48361671519534

Epoch: 5| Step: 8
Training loss: 2.505725788649922
Validation loss: 2.4865470883707363

Epoch: 5| Step: 9
Training loss: 2.1756959963520823
Validation loss: 2.480225142083266

Epoch: 5| Step: 10
Training loss: 2.3532160524784658
Validation loss: 2.4808867094888267

Epoch: 5| Step: 11
Training loss: 2.75433666572183
Validation loss: 2.4792230196299565

Epoch: 105| Step: 0
Training loss: 2.1071536200112266
Validation loss: 2.4861052104292685

Epoch: 5| Step: 1
Training loss: 3.08406013651796
Validation loss: 2.4772120966595894

Epoch: 5| Step: 2
Training loss: 2.507605428257341
Validation loss: 2.4843085338090587

Epoch: 5| Step: 3
Training loss: 2.676754784121326
Validation loss: 2.48668960296938

Epoch: 5| Step: 4
Training loss: 2.226958443756256
Validation loss: 2.4839982880779945

Epoch: 5| Step: 5
Training loss: 3.048802318867002
Validation loss: 2.489310665973766

Epoch: 5| Step: 6
Training loss: 3.061896128382048
Validation loss: 2.4839243850066786

Epoch: 5| Step: 7
Training loss: 2.262696998407874
Validation loss: 2.4846908400560355

Epoch: 5| Step: 8
Training loss: 2.4206480794683456
Validation loss: 2.486260228654634

Epoch: 5| Step: 9
Training loss: 2.277972859141404
Validation loss: 2.4855826299808346

Epoch: 5| Step: 10
Training loss: 2.489772762822331
Validation loss: 2.4839838087842425

Epoch: 5| Step: 11
Training loss: 1.7646501263524361
Validation loss: 2.4790920572247175

Epoch: 106| Step: 0
Training loss: 2.2503828146901115
Validation loss: 2.4759864538314695

Epoch: 5| Step: 1
Training loss: 2.4861422796681243
Validation loss: 2.4743808679976023

Epoch: 5| Step: 2
Training loss: 2.3115998655576284
Validation loss: 2.4796809670118467

Epoch: 5| Step: 3
Training loss: 2.8672729812061637
Validation loss: 2.474210554951911

Epoch: 5| Step: 4
Training loss: 2.408063329149045
Validation loss: 2.4808693790048886

Epoch: 5| Step: 5
Training loss: 2.6345699794739947
Validation loss: 2.4819496159771526

Epoch: 5| Step: 6
Training loss: 2.9284128086318004
Validation loss: 2.4704831313145577

Epoch: 5| Step: 7
Training loss: 2.9425840818566913
Validation loss: 2.4710944829492067

Epoch: 5| Step: 8
Training loss: 2.582311017783473
Validation loss: 2.474973367297287

Epoch: 5| Step: 9
Training loss: 2.3120510593438857
Validation loss: 2.4781557447619655

Epoch: 5| Step: 10
Training loss: 2.214990143420331
Validation loss: 2.482459719549758

Epoch: 5| Step: 11
Training loss: 2.92907903837734
Validation loss: 2.478866239718359

Epoch: 107| Step: 0
Training loss: 2.404192751032798
Validation loss: 2.4705002391074933

Epoch: 5| Step: 1
Training loss: 2.1673011095429886
Validation loss: 2.4824409514143664

Epoch: 5| Step: 2
Training loss: 3.034283722468131
Validation loss: 2.4831139784993277

Epoch: 5| Step: 3
Training loss: 2.4601726009325837
Validation loss: 2.480515851552313

Epoch: 5| Step: 4
Training loss: 2.8318558000609544
Validation loss: 2.4804879495673657

Epoch: 5| Step: 5
Training loss: 2.6875203154040026
Validation loss: 2.4818552342433673

Epoch: 5| Step: 6
Training loss: 2.5582509983328827
Validation loss: 2.478500931307718

Epoch: 5| Step: 7
Training loss: 2.429352372292045
Validation loss: 2.471609688597486

Epoch: 5| Step: 8
Training loss: 2.7463776399643924
Validation loss: 2.474884842833057

Epoch: 5| Step: 9
Training loss: 2.9735159113413197
Validation loss: 2.475864837606112

Epoch: 5| Step: 10
Training loss: 1.6232770442146252
Validation loss: 2.470158698167846

Epoch: 5| Step: 11
Training loss: 1.617730754329288
Validation loss: 2.480120468719477

Epoch: 108| Step: 0
Training loss: 2.2299870440187988
Validation loss: 2.4774008494212487

Epoch: 5| Step: 1
Training loss: 2.4526148952126077
Validation loss: 2.4831605738087084

Epoch: 5| Step: 2
Training loss: 2.641973929681591
Validation loss: 2.4796127404215023

Epoch: 5| Step: 3
Training loss: 2.2005654475337457
Validation loss: 2.4835055447291188

Epoch: 5| Step: 4
Training loss: 2.7272395738840722
Validation loss: 2.4837153096712985

Epoch: 5| Step: 5
Training loss: 3.138260743822256
Validation loss: 2.4843983239252636

Epoch: 5| Step: 6
Training loss: 2.483648133859933
Validation loss: 2.476707454253977

Epoch: 5| Step: 7
Training loss: 2.4643998267722442
Validation loss: 2.4772000620304384

Epoch: 5| Step: 8
Training loss: 2.389491491928008
Validation loss: 2.4721881369111474

Epoch: 5| Step: 9
Training loss: 2.4935786750089663
Validation loss: 2.4733749036324464

Epoch: 5| Step: 10
Training loss: 2.8084886555115736
Validation loss: 2.4754517247362315

Epoch: 5| Step: 11
Training loss: 2.5499440056132006
Validation loss: 2.4791838314092627

Epoch: 109| Step: 0
Training loss: 2.628028757190569
Validation loss: 2.474661136317685

Epoch: 5| Step: 1
Training loss: 3.1089537061972847
Validation loss: 2.471186658664623

Epoch: 5| Step: 2
Training loss: 1.9899599674166253
Validation loss: 2.4716731121247566

Epoch: 5| Step: 3
Training loss: 2.6754852353941354
Validation loss: 2.4716366297280845

Epoch: 5| Step: 4
Training loss: 2.4228333576691616
Validation loss: 2.4769856726182398

Epoch: 5| Step: 5
Training loss: 1.8652357810449542
Validation loss: 2.480515699367801

Epoch: 5| Step: 6
Training loss: 2.483121831792524
Validation loss: 2.475234456789895

Epoch: 5| Step: 7
Training loss: 3.0062015331271255
Validation loss: 2.473525582996497

Epoch: 5| Step: 8
Training loss: 2.7484982464850503
Validation loss: 2.476370092994455

Epoch: 5| Step: 9
Training loss: 2.5573067493084585
Validation loss: 2.470630504963258

Epoch: 5| Step: 10
Training loss: 2.5224092354905143
Validation loss: 2.472844543037307

Epoch: 5| Step: 11
Training loss: 0.5090846047189115
Validation loss: 2.4780746280061305

Epoch: 110| Step: 0
Training loss: 2.2569563671351416
Validation loss: 2.47864363199259

Epoch: 5| Step: 1
Training loss: 2.8889427444948157
Validation loss: 2.4807476978195853

Epoch: 5| Step: 2
Training loss: 2.766296908553598
Validation loss: 2.477005127783678

Epoch: 5| Step: 3
Training loss: 2.2600650308755768
Validation loss: 2.4788781219883904

Epoch: 5| Step: 4
Training loss: 2.654213337709996
Validation loss: 2.4801802620119613

Epoch: 5| Step: 5
Training loss: 2.4635199666159653
Validation loss: 2.4825065592345896

Epoch: 5| Step: 6
Training loss: 1.853667595665835
Validation loss: 2.4808708906219277

Epoch: 5| Step: 7
Training loss: 2.7626951399014614
Validation loss: 2.476445248432517

Epoch: 5| Step: 8
Training loss: 2.8225244528806788
Validation loss: 2.480973163890885

Epoch: 5| Step: 9
Training loss: 2.3490766902858837
Validation loss: 2.472194180496236

Epoch: 5| Step: 10
Training loss: 2.921602287417349
Validation loss: 2.468997391646707

Epoch: 5| Step: 11
Training loss: 1.486012168315904
Validation loss: 2.4741128545322404

Epoch: 111| Step: 0
Training loss: 2.717832476255304
Validation loss: 2.4665853228935455

Epoch: 5| Step: 1
Training loss: 2.4096660393704283
Validation loss: 2.4668074260535353

Epoch: 5| Step: 2
Training loss: 2.414347906432181
Validation loss: 2.470966133121275

Epoch: 5| Step: 3
Training loss: 3.078778812275177
Validation loss: 2.4752785355762468

Epoch: 5| Step: 4
Training loss: 2.769601065074511
Validation loss: 2.4737809422122217

Epoch: 5| Step: 5
Training loss: 2.303350028195123
Validation loss: 2.469386348719206

Epoch: 5| Step: 6
Training loss: 2.596653244153623
Validation loss: 2.4713690180812953

Epoch: 5| Step: 7
Training loss: 2.0828394367968737
Validation loss: 2.475642256939445

Epoch: 5| Step: 8
Training loss: 2.760436800517425
Validation loss: 2.47122085635145

Epoch: 5| Step: 9
Training loss: 2.34319573524324
Validation loss: 2.4699121628972094

Epoch: 5| Step: 10
Training loss: 2.4963556429877647
Validation loss: 2.4711166880070934

Epoch: 5| Step: 11
Training loss: 1.391896042033094
Validation loss: 2.4739325083673003

Epoch: 112| Step: 0
Training loss: 2.331774929151814
Validation loss: 2.4657299989584467

Epoch: 5| Step: 1
Training loss: 2.7986109796423575
Validation loss: 2.4733207255767877

Epoch: 5| Step: 2
Training loss: 2.443867997152486
Validation loss: 2.46831904243189

Epoch: 5| Step: 3
Training loss: 1.931909555936332
Validation loss: 2.4746703572174655

Epoch: 5| Step: 4
Training loss: 2.27959476148971
Validation loss: 2.466307711634141

Epoch: 5| Step: 5
Training loss: 2.8859452590879386
Validation loss: 2.468402516178762

Epoch: 5| Step: 6
Training loss: 2.6457673512639315
Validation loss: 2.475141426422359

Epoch: 5| Step: 7
Training loss: 2.8148093173557087
Validation loss: 2.4714201759926326

Epoch: 5| Step: 8
Training loss: 2.5543497311411203
Validation loss: 2.4667598070192174

Epoch: 5| Step: 9
Training loss: 2.7054144364494728
Validation loss: 2.472828389504046

Epoch: 5| Step: 10
Training loss: 2.5011944778281374
Validation loss: 2.4792807670323627

Epoch: 5| Step: 11
Training loss: 2.728989359990419
Validation loss: 2.4808326754592094

Epoch: 113| Step: 0
Training loss: 2.7375103223074775
Validation loss: 2.46487227240502

Epoch: 5| Step: 1
Training loss: 2.171020120015296
Validation loss: 2.4724591916403047

Epoch: 5| Step: 2
Training loss: 2.736858526172874
Validation loss: 2.487899359717029

Epoch: 5| Step: 3
Training loss: 2.445456601123004
Validation loss: 2.489839797330523

Epoch: 5| Step: 4
Training loss: 2.9357473136202836
Validation loss: 2.494552339344618

Epoch: 5| Step: 5
Training loss: 2.708459518623045
Validation loss: 2.476771449150354

Epoch: 5| Step: 6
Training loss: 2.2015381637755134
Validation loss: 2.469187399991401

Epoch: 5| Step: 7
Training loss: 3.024929890726566
Validation loss: 2.474180140674358

Epoch: 5| Step: 8
Training loss: 2.4488586453087424
Validation loss: 2.477733736230073

Epoch: 5| Step: 9
Training loss: 2.444595475540275
Validation loss: 2.47916851257341

Epoch: 5| Step: 10
Training loss: 2.6238955036034812
Validation loss: 2.4785678939177718

Epoch: 5| Step: 11
Training loss: 2.24312090967145
Validation loss: 2.483890630180169

Epoch: 114| Step: 0
Training loss: 2.190599588853541
Validation loss: 2.482691792426088

Epoch: 5| Step: 1
Training loss: 2.647402941083676
Validation loss: 2.484896435188173

Epoch: 5| Step: 2
Training loss: 2.9816047633315987
Validation loss: 2.4896118223616583

Epoch: 5| Step: 3
Training loss: 2.4370328993613484
Validation loss: 2.4905574494267055

Epoch: 5| Step: 4
Training loss: 2.383440579044388
Validation loss: 2.497519538104182

Epoch: 5| Step: 5
Training loss: 2.582525116612768
Validation loss: 2.4958699841958

Epoch: 5| Step: 6
Training loss: 3.3872162872535525
Validation loss: 2.492780832037932

Epoch: 5| Step: 7
Training loss: 2.4664337301671813
Validation loss: 2.4951018390817987

Epoch: 5| Step: 8
Training loss: 2.3369734390309893
Validation loss: 2.4918302919784594

Epoch: 5| Step: 9
Training loss: 2.3022606437603588
Validation loss: 2.492319643668815

Epoch: 5| Step: 10
Training loss: 2.6706642843259005
Validation loss: 2.489672592723037

Epoch: 5| Step: 11
Training loss: 2.9899946897835927
Validation loss: 2.4846161099560633

Epoch: 115| Step: 0
Training loss: 2.870241622589621
Validation loss: 2.486360562201083

Epoch: 5| Step: 1
Training loss: 2.3307564220575263
Validation loss: 2.4810281598318755

Epoch: 5| Step: 2
Training loss: 2.475374821496125
Validation loss: 2.4778293614465903

Epoch: 5| Step: 3
Training loss: 2.4141449651860905
Validation loss: 2.4792028926692367

Epoch: 5| Step: 4
Training loss: 2.5033742068628455
Validation loss: 2.4712604120369948

Epoch: 5| Step: 5
Training loss: 2.585068755572822
Validation loss: 2.476958579110702

Epoch: 5| Step: 6
Training loss: 2.689685553852174
Validation loss: 2.4730512997476155

Epoch: 5| Step: 7
Training loss: 2.0496469612375807
Validation loss: 2.477700374184951

Epoch: 5| Step: 8
Training loss: 2.7338568496230664
Validation loss: 2.4698351153270264

Epoch: 5| Step: 9
Training loss: 2.8671412659121436
Validation loss: 2.473164060816174

Epoch: 5| Step: 10
Training loss: 2.478267239388573
Validation loss: 2.4677810215956124

Epoch: 5| Step: 11
Training loss: 2.968597890069041
Validation loss: 2.4712423507644083

Epoch: 116| Step: 0
Training loss: 2.8038140001956036
Validation loss: 2.4800151460259423

Epoch: 5| Step: 1
Training loss: 2.9256332624873314
Validation loss: 2.468346438037189

Epoch: 5| Step: 2
Training loss: 2.161760889655229
Validation loss: 2.4645921323806737

Epoch: 5| Step: 3
Training loss: 2.6674814072365867
Validation loss: 2.4712259455635555

Epoch: 5| Step: 4
Training loss: 2.77691501146434
Validation loss: 2.4698308357298044

Epoch: 5| Step: 5
Training loss: 2.6547306876798045
Validation loss: 2.4772967344225862

Epoch: 5| Step: 6
Training loss: 2.7278826558949114
Validation loss: 2.472773516517336

Epoch: 5| Step: 7
Training loss: 2.28544763516842
Validation loss: 2.4747752731422104

Epoch: 5| Step: 8
Training loss: 1.864718093122453
Validation loss: 2.480137596152346

Epoch: 5| Step: 9
Training loss: 2.452221163298292
Validation loss: 2.472430073707458

Epoch: 5| Step: 10
Training loss: 2.5528853006263907
Validation loss: 2.477661639008009

Epoch: 5| Step: 11
Training loss: 2.799343958701948
Validation loss: 2.472942896133148

Epoch: 117| Step: 0
Training loss: 2.11202395791857
Validation loss: 2.4646779975435464

Epoch: 5| Step: 1
Training loss: 2.8894916683987177
Validation loss: 2.468748225440824

Epoch: 5| Step: 2
Training loss: 3.130442191140535
Validation loss: 2.4637747742342593

Epoch: 5| Step: 3
Training loss: 2.6464538347234607
Validation loss: 2.463608945824411

Epoch: 5| Step: 4
Training loss: 2.101054644288466
Validation loss: 2.4686732903968647

Epoch: 5| Step: 5
Training loss: 3.0217595927500507
Validation loss: 2.4668665312544427

Epoch: 5| Step: 6
Training loss: 1.6345569108196423
Validation loss: 2.468609250559222

Epoch: 5| Step: 7
Training loss: 3.1448471005483936
Validation loss: 2.468422811692825

Epoch: 5| Step: 8
Training loss: 2.3770399869220267
Validation loss: 2.471721422236713

Epoch: 5| Step: 9
Training loss: 2.3156587832479443
Validation loss: 2.469243221669016

Epoch: 5| Step: 10
Training loss: 2.2021320892200817
Validation loss: 2.4722502436877405

Epoch: 5| Step: 11
Training loss: 1.6544826362738563
Validation loss: 2.472541870717938

Epoch: 118| Step: 0
Training loss: 2.615528457664723
Validation loss: 2.474326515239836

Epoch: 5| Step: 1
Training loss: 2.5096852567993064
Validation loss: 2.4687183233232806

Epoch: 5| Step: 2
Training loss: 2.530746315657713
Validation loss: 2.47284469569392

Epoch: 5| Step: 3
Training loss: 2.504669691987487
Validation loss: 2.4730832904791207

Epoch: 5| Step: 4
Training loss: 2.849863711662161
Validation loss: 2.4761315902495675

Epoch: 5| Step: 5
Training loss: 2.82693726273056
Validation loss: 2.4773648824425023

Epoch: 5| Step: 6
Training loss: 1.8820549164927303
Validation loss: 2.473457198668016

Epoch: 5| Step: 7
Training loss: 3.118392214386539
Validation loss: 2.4733274732976147

Epoch: 5| Step: 8
Training loss: 2.63397480921767
Validation loss: 2.4729371757481724

Epoch: 5| Step: 9
Training loss: 2.062523350438961
Validation loss: 2.4715957697691335

Epoch: 5| Step: 10
Training loss: 2.283199992312329
Validation loss: 2.476595841272594

Epoch: 5| Step: 11
Training loss: 1.3083859406765772
Validation loss: 2.47068622568254

Epoch: 119| Step: 0
Training loss: 3.233010266736971
Validation loss: 2.4654027201253923

Epoch: 5| Step: 1
Training loss: 2.6991986993025634
Validation loss: 2.469593338636899

Epoch: 5| Step: 2
Training loss: 2.428474638717138
Validation loss: 2.470039875735674

Epoch: 5| Step: 3
Training loss: 2.1975213609857187
Validation loss: 2.4626997677864617

Epoch: 5| Step: 4
Training loss: 2.679352230529637
Validation loss: 2.466010767062139

Epoch: 5| Step: 5
Training loss: 2.2987563544180882
Validation loss: 2.4624276791197794

Epoch: 5| Step: 6
Training loss: 2.9437039381825385
Validation loss: 2.4564599129472744

Epoch: 5| Step: 7
Training loss: 2.55334418673819
Validation loss: 2.473828408025262

Epoch: 5| Step: 8
Training loss: 1.853162243422188
Validation loss: 2.464991146462502

Epoch: 5| Step: 9
Training loss: 2.6415481308135926
Validation loss: 2.4688689609629035

Epoch: 5| Step: 10
Training loss: 2.2652853875649925
Validation loss: 2.4756197092535364

Epoch: 5| Step: 11
Training loss: 1.8353032741382946
Validation loss: 2.4795681657702766

Epoch: 120| Step: 0
Training loss: 2.41128785510528
Validation loss: 2.4789540148875173

Epoch: 5| Step: 1
Training loss: 2.47638853406758
Validation loss: 2.4776456973080943

Epoch: 5| Step: 2
Training loss: 2.7994838886073308
Validation loss: 2.48142008122439

Epoch: 5| Step: 3
Training loss: 3.128471277603494
Validation loss: 2.479248595820707

Epoch: 5| Step: 4
Training loss: 2.1685267924456095
Validation loss: 2.482937334850275

Epoch: 5| Step: 5
Training loss: 2.325709991337302
Validation loss: 2.479703866367377

Epoch: 5| Step: 6
Training loss: 2.1183426862140537
Validation loss: 2.484666217474039

Epoch: 5| Step: 7
Training loss: 2.398098502292343
Validation loss: 2.4802585182308974

Epoch: 5| Step: 8
Training loss: 2.5994591443842223
Validation loss: 2.476489040917873

Epoch: 5| Step: 9
Training loss: 2.533730410108222
Validation loss: 2.48125549415089

Epoch: 5| Step: 10
Training loss: 2.407127022377833
Validation loss: 2.4778291970694846

Epoch: 5| Step: 11
Training loss: 3.8629090965925665
Validation loss: 2.476428901767254

Epoch: 121| Step: 0
Training loss: 3.0265368758393527
Validation loss: 2.4744401656631365

Epoch: 5| Step: 1
Training loss: 2.326096438218454
Validation loss: 2.466873042928407

Epoch: 5| Step: 2
Training loss: 2.1677134870485935
Validation loss: 2.4703530205514483

Epoch: 5| Step: 3
Training loss: 1.9675578186186915
Validation loss: 2.4721226812056263

Epoch: 5| Step: 4
Training loss: 2.009349783684299
Validation loss: 2.4656247827540287

Epoch: 5| Step: 5
Training loss: 2.474928644866388
Validation loss: 2.461712704022262

Epoch: 5| Step: 6
Training loss: 2.3184896687994607
Validation loss: 2.462462125525662

Epoch: 5| Step: 7
Training loss: 2.882715239085922
Validation loss: 2.4662070275152823

Epoch: 5| Step: 8
Training loss: 2.2747435079335836
Validation loss: 2.4682385220618333

Epoch: 5| Step: 9
Training loss: 3.2578423587885275
Validation loss: 2.4597602248479626

Epoch: 5| Step: 10
Training loss: 3.045638865582776
Validation loss: 2.456346441677672

Epoch: 5| Step: 11
Training loss: 1.5900540599389827
Validation loss: 2.4555910232755287

Epoch: 122| Step: 0
Training loss: 2.2975729576041575
Validation loss: 2.463315517188398

Epoch: 5| Step: 1
Training loss: 2.363153224030935
Validation loss: 2.462459146254337

Epoch: 5| Step: 2
Training loss: 2.5529803717187773
Validation loss: 2.463551141560717

Epoch: 5| Step: 3
Training loss: 2.6456653411478697
Validation loss: 2.468995573006379

Epoch: 5| Step: 4
Training loss: 2.931785706978023
Validation loss: 2.472651868819322

Epoch: 5| Step: 5
Training loss: 2.5686387754989184
Validation loss: 2.464206433814393

Epoch: 5| Step: 6
Training loss: 2.5743284071864014
Validation loss: 2.4659337788778846

Epoch: 5| Step: 7
Training loss: 2.2516972180526156
Validation loss: 2.4661134974861594

Epoch: 5| Step: 8
Training loss: 2.1335569766160547
Validation loss: 2.464351264290435

Epoch: 5| Step: 9
Training loss: 2.845764620292565
Validation loss: 2.4642160929381194

Epoch: 5| Step: 10
Training loss: 2.466659433337079
Validation loss: 2.4723879531489406

Epoch: 5| Step: 11
Training loss: 2.90458779330621
Validation loss: 2.4626636647605604

Epoch: 123| Step: 0
Training loss: 2.117019477736615
Validation loss: 2.4727583025964326

Epoch: 5| Step: 1
Training loss: 2.458976424418739
Validation loss: 2.475965253372767

Epoch: 5| Step: 2
Training loss: 2.6063856716200067
Validation loss: 2.477545522065664

Epoch: 5| Step: 3
Training loss: 2.446162554425969
Validation loss: 2.4749835764375354

Epoch: 5| Step: 4
Training loss: 1.9868517460261739
Validation loss: 2.4784700726671116

Epoch: 5| Step: 5
Training loss: 2.1431426675490455
Validation loss: 2.483880471647323

Epoch: 5| Step: 6
Training loss: 2.859131182505345
Validation loss: 2.4798003890732265

Epoch: 5| Step: 7
Training loss: 2.8981245751099873
Validation loss: 2.4781420150307394

Epoch: 5| Step: 8
Training loss: 3.232532805875983
Validation loss: 2.479196982372013

Epoch: 5| Step: 9
Training loss: 2.5577726721065916
Validation loss: 2.4839219174004237

Epoch: 5| Step: 10
Training loss: 2.442386424333845
Validation loss: 2.4805124314033886

Epoch: 5| Step: 11
Training loss: 1.459179069877354
Validation loss: 2.4804278472972223

Epoch: 124| Step: 0
Training loss: 2.37022864256894
Validation loss: 2.482175032906006

Epoch: 5| Step: 1
Training loss: 2.7123247714070633
Validation loss: 2.480310962694629

Epoch: 5| Step: 2
Training loss: 2.38761383104835
Validation loss: 2.4752869956596046

Epoch: 5| Step: 3
Training loss: 2.405992271195299
Validation loss: 2.4755776630290915

Epoch: 5| Step: 4
Training loss: 2.2548230717982123
Validation loss: 2.468252948829674

Epoch: 5| Step: 5
Training loss: 2.7486233299805787
Validation loss: 2.4704604722032446

Epoch: 5| Step: 6
Training loss: 2.758086625866728
Validation loss: 2.4777775019332875

Epoch: 5| Step: 7
Training loss: 2.5157344628443448
Validation loss: 2.4738991733638462

Epoch: 5| Step: 8
Training loss: 2.733323772537754
Validation loss: 2.479610064202245

Epoch: 5| Step: 9
Training loss: 2.959522563473868
Validation loss: 2.46877177345557

Epoch: 5| Step: 10
Training loss: 2.121858855735251
Validation loss: 2.4804096445165458

Epoch: 5| Step: 11
Training loss: 1.2001873664810192
Validation loss: 2.471656207381703

Epoch: 125| Step: 0
Training loss: 2.4282754308970675
Validation loss: 2.475165437377449

Epoch: 5| Step: 1
Training loss: 2.738524073828052
Validation loss: 2.4744939900117986

Epoch: 5| Step: 2
Training loss: 2.6228310843502087
Validation loss: 2.473248069933121

Epoch: 5| Step: 3
Training loss: 2.3338089753327083
Validation loss: 2.465837958244412

Epoch: 5| Step: 4
Training loss: 2.362843874977937
Validation loss: 2.464706449316921

Epoch: 5| Step: 5
Training loss: 2.4693465658881055
Validation loss: 2.4639687493905282

Epoch: 5| Step: 6
Training loss: 2.171502060740119
Validation loss: 2.476096966909222

Epoch: 5| Step: 7
Training loss: 2.0958498772738583
Validation loss: 2.4687436824025633

Epoch: 5| Step: 8
Training loss: 2.4099198137294855
Validation loss: 2.474091192325406

Epoch: 5| Step: 9
Training loss: 2.8877630138749613
Validation loss: 2.473542097446076

Epoch: 5| Step: 10
Training loss: 3.0598858945428127
Validation loss: 2.4728115448840806

Epoch: 5| Step: 11
Training loss: 3.1674418922640304
Validation loss: 2.478417749579131

Testing loss: 2.040297576001608
