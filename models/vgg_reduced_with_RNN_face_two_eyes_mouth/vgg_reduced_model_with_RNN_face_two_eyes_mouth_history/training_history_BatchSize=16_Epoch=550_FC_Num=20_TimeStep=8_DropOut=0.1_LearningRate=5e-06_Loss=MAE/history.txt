Epoch: 1| Step: 0
Training loss: 5.698430061340332
Validation loss: 5.341157992680867

Epoch: 6| Step: 1
Training loss: 6.42766809463501
Validation loss: 5.339497645696004

Epoch: 6| Step: 2
Training loss: 5.426114082336426
Validation loss: 5.337819894154866

Epoch: 6| Step: 3
Training loss: 5.5622453689575195
Validation loss: 5.33621605237325

Epoch: 6| Step: 4
Training loss: 4.7922821044921875
Validation loss: 5.334643125534058

Epoch: 6| Step: 5
Training loss: 5.403822422027588
Validation loss: 5.332990248998006

Epoch: 6| Step: 6
Training loss: 6.126211643218994
Validation loss: 5.331300497055054

Epoch: 6| Step: 7
Training loss: 4.48061466217041
Validation loss: 5.329505046208699

Epoch: 6| Step: 8
Training loss: 6.142403602600098
Validation loss: 5.327622016270955

Epoch: 6| Step: 9
Training loss: 5.370648384094238
Validation loss: 5.325621048609416

Epoch: 6| Step: 10
Training loss: 5.676301956176758
Validation loss: 5.323522249857585

Epoch: 6| Step: 11
Training loss: 4.373837471008301
Validation loss: 5.321328957875569

Epoch: 6| Step: 12
Training loss: 4.943904876708984
Validation loss: 5.318988958994548

Epoch: 6| Step: 13
Training loss: 5.159677505493164
Validation loss: 5.316534638404846

Epoch: 2| Step: 0
Training loss: 5.6825432777404785
Validation loss: 5.313933451970418

Epoch: 6| Step: 1
Training loss: 5.881847381591797
Validation loss: 5.311365365982056

Epoch: 6| Step: 2
Training loss: 5.3995866775512695
Validation loss: 5.308591445287068

Epoch: 6| Step: 3
Training loss: 3.869565963745117
Validation loss: 5.305576244990031

Epoch: 6| Step: 4
Training loss: 5.744441032409668
Validation loss: 5.3025126457214355

Epoch: 6| Step: 5
Training loss: 5.760693550109863
Validation loss: 5.2992978890736895

Epoch: 6| Step: 6
Training loss: 6.017162799835205
Validation loss: 5.2957955201466875

Epoch: 6| Step: 7
Training loss: 5.890549182891846
Validation loss: 5.292313575744629

Epoch: 6| Step: 8
Training loss: 5.758915901184082
Validation loss: 5.288397550582886

Epoch: 6| Step: 9
Training loss: 4.954195022583008
Validation loss: 5.284461339314778

Epoch: 6| Step: 10
Training loss: 4.805193901062012
Validation loss: 5.280354340871175

Epoch: 6| Step: 11
Training loss: 6.078421592712402
Validation loss: 5.275895833969116

Epoch: 6| Step: 12
Training loss: 4.9070844650268555
Validation loss: 5.271259943644206

Epoch: 6| Step: 13
Training loss: 4.311375141143799
Validation loss: 5.266398270924886

Epoch: 3| Step: 0
Training loss: 4.838644027709961
Validation loss: 5.261181116104126

Epoch: 6| Step: 1
Training loss: 5.188781261444092
Validation loss: 5.2556807200113935

Epoch: 6| Step: 2
Training loss: 5.984623908996582
Validation loss: 5.249925533930461

Epoch: 6| Step: 3
Training loss: 5.350979804992676
Validation loss: 5.243983507156372

Epoch: 6| Step: 4
Training loss: 5.365700721740723
Validation loss: 5.2377504507700605

Epoch: 6| Step: 5
Training loss: 5.072958469390869
Validation loss: 5.2310614585876465

Epoch: 6| Step: 6
Training loss: 6.272118091583252
Validation loss: 5.224556605021159

Epoch: 6| Step: 7
Training loss: 5.523197174072266
Validation loss: 5.217333555221558

Epoch: 6| Step: 8
Training loss: 5.253217697143555
Validation loss: 5.209997812906901

Epoch: 6| Step: 9
Training loss: 4.793378829956055
Validation loss: 5.202365159988403

Epoch: 6| Step: 10
Training loss: 5.021478652954102
Validation loss: 5.194726943969727

Epoch: 6| Step: 11
Training loss: 4.148937702178955
Validation loss: 5.186661163965861

Epoch: 6| Step: 12
Training loss: 5.917869567871094
Validation loss: 5.178210020065308

Epoch: 6| Step: 13
Training loss: 5.321089744567871
Validation loss: 5.169721285502116

Epoch: 4| Step: 0
Training loss: 4.680554389953613
Validation loss: 5.161120255788167

Epoch: 6| Step: 1
Training loss: 5.6384735107421875
Validation loss: 5.152265151341756

Epoch: 6| Step: 2
Training loss: 5.0092692375183105
Validation loss: 5.143130858739217

Epoch: 6| Step: 3
Training loss: 5.040441513061523
Validation loss: 5.133683204650879

Epoch: 6| Step: 4
Training loss: 4.552632808685303
Validation loss: 5.124359051386516

Epoch: 6| Step: 5
Training loss: 4.5722551345825195
Validation loss: 5.114764213562012

Epoch: 6| Step: 6
Training loss: 5.871858596801758
Validation loss: 5.104566176732381

Epoch: 6| Step: 7
Training loss: 6.04824686050415
Validation loss: 5.09461251894633

Epoch: 6| Step: 8
Training loss: 5.4365668296813965
Validation loss: 5.084324200948079

Epoch: 6| Step: 9
Training loss: 6.587197303771973
Validation loss: 5.07365345954895

Epoch: 6| Step: 10
Training loss: 5.43515682220459
Validation loss: 5.06332802772522

Epoch: 6| Step: 11
Training loss: 4.662266254425049
Validation loss: 5.052317301432292

Epoch: 6| Step: 12
Training loss: 3.4442784786224365
Validation loss: 5.041344404220581

Epoch: 6| Step: 13
Training loss: 5.4498701095581055
Validation loss: 5.03033451239268

Epoch: 5| Step: 0
Training loss: 4.40772819519043
Validation loss: 5.019236405690511

Epoch: 6| Step: 1
Training loss: 4.83699369430542
Validation loss: 5.007991711298625

Epoch: 6| Step: 2
Training loss: 5.1717729568481445
Validation loss: 4.997232874234517

Epoch: 6| Step: 3
Training loss: 3.8961966037750244
Validation loss: 4.98576823870341

Epoch: 6| Step: 4
Training loss: 5.430575847625732
Validation loss: 4.974054217338562

Epoch: 6| Step: 5
Training loss: 5.9523138999938965
Validation loss: 4.962728977203369

Epoch: 6| Step: 6
Training loss: 4.005521774291992
Validation loss: 4.951455195744832

Epoch: 6| Step: 7
Training loss: 5.85855770111084
Validation loss: 4.940303484598796

Epoch: 6| Step: 8
Training loss: 5.244946479797363
Validation loss: 4.928928017616272

Epoch: 6| Step: 9
Training loss: 4.889557838439941
Validation loss: 4.91730268796285

Epoch: 6| Step: 10
Training loss: 6.110715389251709
Validation loss: 4.906026681264241

Epoch: 6| Step: 11
Training loss: 5.282702922821045
Validation loss: 4.894301096598308

Epoch: 6| Step: 12
Training loss: 4.73196268081665
Validation loss: 4.882914781570435

Epoch: 6| Step: 13
Training loss: 4.577259063720703
Validation loss: 4.871702750523885

Epoch: 6| Step: 0
Training loss: 4.321167945861816
Validation loss: 4.859935124715169

Epoch: 6| Step: 1
Training loss: 5.019812107086182
Validation loss: 4.848119258880615

Epoch: 6| Step: 2
Training loss: 4.950650215148926
Validation loss: 4.837207595507304

Epoch: 6| Step: 3
Training loss: 4.3049516677856445
Validation loss: 4.826317350069682

Epoch: 6| Step: 4
Training loss: 4.454288959503174
Validation loss: 4.815871795018514

Epoch: 6| Step: 5
Training loss: 4.882969856262207
Validation loss: 4.8057275613149

Epoch: 6| Step: 6
Training loss: 5.080124378204346
Validation loss: 4.795970598856608

Epoch: 6| Step: 7
Training loss: 5.048499584197998
Validation loss: 4.786202669143677

Epoch: 6| Step: 8
Training loss: 4.093936920166016
Validation loss: 4.776629050572713

Epoch: 6| Step: 9
Training loss: 5.444705486297607
Validation loss: 4.76772157351176

Epoch: 6| Step: 10
Training loss: 5.249469757080078
Validation loss: 4.758214712142944

Epoch: 6| Step: 11
Training loss: 4.190978050231934
Validation loss: 4.74942688147227

Epoch: 6| Step: 12
Training loss: 5.182284832000732
Validation loss: 4.740892728169759

Epoch: 6| Step: 13
Training loss: 6.113885879516602
Validation loss: 4.7319754759470625

Epoch: 7| Step: 0
Training loss: 5.194948196411133
Validation loss: 4.723326365152995

Epoch: 6| Step: 1
Training loss: 3.781747341156006
Validation loss: 4.714937647183736

Epoch: 6| Step: 2
Training loss: 4.103146076202393
Validation loss: 4.7068352699279785

Epoch: 6| Step: 3
Training loss: 5.158694267272949
Validation loss: 4.6983269055684405

Epoch: 6| Step: 4
Training loss: 5.625846862792969
Validation loss: 4.6905412673950195

Epoch: 6| Step: 5
Training loss: 5.062784671783447
Validation loss: 4.6828023592631025

Epoch: 6| Step: 6
Training loss: 5.063176155090332
Validation loss: 4.674906174341838

Epoch: 6| Step: 7
Training loss: 4.873235702514648
Validation loss: 4.667952219645183

Epoch: 6| Step: 8
Training loss: 4.725131988525391
Validation loss: 4.66042685508728

Epoch: 6| Step: 9
Training loss: 4.210934162139893
Validation loss: 4.653301954269409

Epoch: 6| Step: 10
Training loss: 4.231923580169678
Validation loss: 4.645960211753845

Epoch: 6| Step: 11
Training loss: 4.421408176422119
Validation loss: 4.6385752360026045

Epoch: 6| Step: 12
Training loss: 4.838415145874023
Validation loss: 4.631471832593282

Epoch: 6| Step: 13
Training loss: 5.453014373779297
Validation loss: 4.6238629420598345

Epoch: 8| Step: 0
Training loss: 4.2014479637146
Validation loss: 4.616962989171346

Epoch: 6| Step: 1
Training loss: 5.004156589508057
Validation loss: 4.60950752099355

Epoch: 6| Step: 2
Training loss: 4.982535362243652
Validation loss: 4.6023480494817095

Epoch: 6| Step: 3
Training loss: 5.226039409637451
Validation loss: 4.594367742538452

Epoch: 6| Step: 4
Training loss: 5.154019355773926
Validation loss: 4.587658246358235

Epoch: 6| Step: 5
Training loss: 4.430208206176758
Validation loss: 4.580178419748942

Epoch: 6| Step: 6
Training loss: 4.354673385620117
Validation loss: 4.57296097278595

Epoch: 6| Step: 7
Training loss: 5.089822769165039
Validation loss: 4.5650614102681475

Epoch: 6| Step: 8
Training loss: 5.084526062011719
Validation loss: 4.557318607966105

Epoch: 6| Step: 9
Training loss: 4.241440773010254
Validation loss: 4.549857338269551

Epoch: 6| Step: 10
Training loss: 4.716347694396973
Validation loss: 4.542100389798482

Epoch: 6| Step: 11
Training loss: 2.3877358436584473
Validation loss: 4.534093300501506

Epoch: 6| Step: 12
Training loss: 5.1889848709106445
Validation loss: 4.526605566342671

Epoch: 6| Step: 13
Training loss: 5.316067695617676
Validation loss: 4.518997589747111

Epoch: 9| Step: 0
Training loss: 4.2865495681762695
Validation loss: 4.510930180549622

Epoch: 6| Step: 1
Training loss: 4.984977722167969
Validation loss: 4.503832499186198

Epoch: 6| Step: 2
Training loss: 4.792699813842773
Validation loss: 4.496407310167949

Epoch: 6| Step: 3
Training loss: 4.408177375793457
Validation loss: 4.488792737325032

Epoch: 6| Step: 4
Training loss: 4.644100189208984
Validation loss: 4.482358733812968

Epoch: 6| Step: 5
Training loss: 4.121517181396484
Validation loss: 4.475821654001872

Epoch: 6| Step: 6
Training loss: 3.584507465362549
Validation loss: 4.469529589017232

Epoch: 6| Step: 7
Training loss: 4.654421806335449
Validation loss: 4.4630223115285235

Epoch: 6| Step: 8
Training loss: 3.9705817699432373
Validation loss: 4.45676867167155

Epoch: 6| Step: 9
Training loss: 5.923671722412109
Validation loss: 4.450296243031819

Epoch: 6| Step: 10
Training loss: 4.896459579467773
Validation loss: 4.444098711013794

Epoch: 6| Step: 11
Training loss: 4.5770263671875
Validation loss: 4.437059799830119

Epoch: 6| Step: 12
Training loss: 5.343790054321289
Validation loss: 4.431014696756999

Epoch: 6| Step: 13
Training loss: 3.879713773727417
Validation loss: 4.424071153004964

Epoch: 10| Step: 0
Training loss: 4.353626251220703
Validation loss: 4.418047825495402

Epoch: 6| Step: 1
Training loss: 4.787308692932129
Validation loss: 4.411084175109863

Epoch: 6| Step: 2
Training loss: 5.132400035858154
Validation loss: 4.404967745145162

Epoch: 6| Step: 3
Training loss: 4.225650787353516
Validation loss: 4.398404995600383

Epoch: 6| Step: 4
Training loss: 4.410425186157227
Validation loss: 4.392105142275493

Epoch: 6| Step: 5
Training loss: 4.014863014221191
Validation loss: 4.386067231496175

Epoch: 6| Step: 6
Training loss: 5.351993560791016
Validation loss: 4.37982972462972

Epoch: 6| Step: 7
Training loss: 3.7088816165924072
Validation loss: 4.373535792032878

Epoch: 6| Step: 8
Training loss: 4.993791580200195
Validation loss: 4.367323795954387

Epoch: 6| Step: 9
Training loss: 4.356042385101318
Validation loss: 4.360720753669739

Epoch: 6| Step: 10
Training loss: 4.400716781616211
Validation loss: 4.354495207468669

Epoch: 6| Step: 11
Training loss: 4.9156293869018555
Validation loss: 4.34812060991923

Epoch: 6| Step: 12
Training loss: 4.07174015045166
Validation loss: 4.341655691464742

Epoch: 6| Step: 13
Training loss: 4.210639953613281
Validation loss: 4.335450331370036

Epoch: 11| Step: 0
Training loss: 4.451533317565918
Validation loss: 4.329381227493286

Epoch: 6| Step: 1
Training loss: 3.575697898864746
Validation loss: 4.323570768038432

Epoch: 6| Step: 2
Training loss: 5.243467330932617
Validation loss: 4.317093729972839

Epoch: 6| Step: 3
Training loss: 4.125570297241211
Validation loss: 4.3110512892405195

Epoch: 6| Step: 4
Training loss: 3.0699384212493896
Validation loss: 4.305293520291646

Epoch: 6| Step: 5
Training loss: 4.425260543823242
Validation loss: 4.299433747927348

Epoch: 6| Step: 6
Training loss: 3.8207437992095947
Validation loss: 4.293328404426575

Epoch: 6| Step: 7
Training loss: 6.10078239440918
Validation loss: 4.28795329729716

Epoch: 6| Step: 8
Training loss: 4.947055816650391
Validation loss: 4.281606038411458

Epoch: 6| Step: 9
Training loss: 4.052192687988281
Validation loss: 4.27584179242452

Epoch: 6| Step: 10
Training loss: 4.548789978027344
Validation loss: 4.269817153612773

Epoch: 6| Step: 11
Training loss: 4.950690269470215
Validation loss: 4.263967514038086

Epoch: 6| Step: 12
Training loss: 4.239437103271484
Validation loss: 4.258272568384807

Epoch: 6| Step: 13
Training loss: 4.295957565307617
Validation loss: 4.252357920010884

Epoch: 12| Step: 0
Training loss: 4.630298614501953
Validation loss: 4.246925910313924

Epoch: 6| Step: 1
Training loss: 4.492908000946045
Validation loss: 4.241318424542745

Epoch: 6| Step: 2
Training loss: 3.8955016136169434
Validation loss: 4.2346885204315186

Epoch: 6| Step: 3
Training loss: 4.03989839553833
Validation loss: 4.228085478146871

Epoch: 6| Step: 4
Training loss: 4.441043376922607
Validation loss: 4.222115198771159

Epoch: 6| Step: 5
Training loss: 5.689753532409668
Validation loss: 4.215592741966248

Epoch: 6| Step: 6
Training loss: 3.8663740158081055
Validation loss: 4.208860397338867

Epoch: 6| Step: 7
Training loss: 3.795719623565674
Validation loss: 4.20232355594635

Epoch: 6| Step: 8
Training loss: 2.8758912086486816
Validation loss: 4.196201999982198

Epoch: 6| Step: 9
Training loss: 4.292805194854736
Validation loss: 4.188773075739543

Epoch: 6| Step: 10
Training loss: 4.975555419921875
Validation loss: 4.183053572972615

Epoch: 6| Step: 11
Training loss: 4.890913963317871
Validation loss: 4.176905433336894

Epoch: 6| Step: 12
Training loss: 4.416121482849121
Validation loss: 4.170164505640666

Epoch: 6| Step: 13
Training loss: 4.449187278747559
Validation loss: 4.165276726086934

Epoch: 13| Step: 0
Training loss: 4.711675643920898
Validation loss: 4.159124096234639

Epoch: 6| Step: 1
Training loss: 3.2853002548217773
Validation loss: 4.153981606165568

Epoch: 6| Step: 2
Training loss: 4.451547622680664
Validation loss: 4.146450916926066

Epoch: 6| Step: 3
Training loss: 4.50039005279541
Validation loss: 4.141551375389099

Epoch: 6| Step: 4
Training loss: 3.9708425998687744
Validation loss: 4.136150479316711

Epoch: 6| Step: 5
Training loss: 4.561263084411621
Validation loss: 4.130156993865967

Epoch: 6| Step: 6
Training loss: 5.361631393432617
Validation loss: 4.123388210932414

Epoch: 6| Step: 7
Training loss: 3.4685206413269043
Validation loss: 4.1177882353464765

Epoch: 6| Step: 8
Training loss: 4.746744632720947
Validation loss: 4.112834930419922

Epoch: 6| Step: 9
Training loss: 3.8319573402404785
Validation loss: 4.105793555577596

Epoch: 6| Step: 10
Training loss: 3.3462777137756348
Validation loss: 4.1002315282821655

Epoch: 6| Step: 11
Training loss: 4.244024276733398
Validation loss: 4.094037731488545

Epoch: 6| Step: 12
Training loss: 5.228542804718018
Validation loss: 4.088132460912068

Epoch: 6| Step: 13
Training loss: 3.9617178440093994
Validation loss: 4.082222739855449

Epoch: 14| Step: 0
Training loss: 4.683537483215332
Validation loss: 4.077497720718384

Epoch: 6| Step: 1
Training loss: 4.75141716003418
Validation loss: 4.07146143913269

Epoch: 6| Step: 2
Training loss: 4.392883777618408
Validation loss: 4.066087961196899

Epoch: 6| Step: 3
Training loss: 4.851442337036133
Validation loss: 4.060696363449097

Epoch: 6| Step: 4
Training loss: 4.199992656707764
Validation loss: 4.05484143892924

Epoch: 6| Step: 5
Training loss: 4.278482913970947
Validation loss: 4.048622528711955

Epoch: 6| Step: 6
Training loss: 5.151079177856445
Validation loss: 4.042809844017029

Epoch: 6| Step: 7
Training loss: 4.1533098220825195
Validation loss: 4.036234100659688

Epoch: 6| Step: 8
Training loss: 4.070061683654785
Validation loss: 4.031608502070109

Epoch: 6| Step: 9
Training loss: 4.505753993988037
Validation loss: 4.026567141215007

Epoch: 6| Step: 10
Training loss: 3.0667314529418945
Validation loss: 4.02191698551178

Epoch: 6| Step: 11
Training loss: 3.076975107192993
Validation loss: 4.015687505404155

Epoch: 6| Step: 12
Training loss: 3.29605770111084
Validation loss: 4.010947624842326

Epoch: 6| Step: 13
Training loss: 4.1317057609558105
Validation loss: 4.006718675295512

Epoch: 15| Step: 0
Training loss: 3.756967544555664
Validation loss: 4.00190806388855

Epoch: 6| Step: 1
Training loss: 3.693000078201294
Validation loss: 3.9990254640579224

Epoch: 6| Step: 2
Training loss: 3.9123144149780273
Validation loss: 3.9945203065872192

Epoch: 6| Step: 3
Training loss: 3.8640987873077393
Validation loss: 3.9880563020706177

Epoch: 6| Step: 4
Training loss: 5.588167667388916
Validation loss: 3.9830430348714194

Epoch: 6| Step: 5
Training loss: 4.602529525756836
Validation loss: 3.9774864514668784

Epoch: 6| Step: 6
Training loss: 4.61649227142334
Validation loss: 3.9729062716166177

Epoch: 6| Step: 7
Training loss: 4.105118751525879
Validation loss: 3.9670917987823486

Epoch: 6| Step: 8
Training loss: 3.8550186157226562
Validation loss: 3.963416258494059

Epoch: 6| Step: 9
Training loss: 4.287482261657715
Validation loss: 3.9586208264033

Epoch: 6| Step: 10
Training loss: 4.092033386230469
Validation loss: 3.9528776009877524

Epoch: 6| Step: 11
Training loss: 4.830106735229492
Validation loss: 3.949307839075724

Epoch: 6| Step: 12
Training loss: 2.551077127456665
Validation loss: 3.942951281865438

Epoch: 6| Step: 13
Training loss: 3.9024012088775635
Validation loss: 3.938465714454651

Epoch: 16| Step: 0
Training loss: 3.9908504486083984
Validation loss: 3.933921138445536

Epoch: 6| Step: 1
Training loss: 5.070433616638184
Validation loss: 3.929004987080892

Epoch: 6| Step: 2
Training loss: 3.5099501609802246
Validation loss: 3.9244256814320884

Epoch: 6| Step: 3
Training loss: 3.2001194953918457
Validation loss: 3.9201040267944336

Epoch: 6| Step: 4
Training loss: 4.155138969421387
Validation loss: 3.91430135567983

Epoch: 6| Step: 5
Training loss: 4.301148414611816
Validation loss: 3.9098492860794067

Epoch: 6| Step: 6
Training loss: 4.078326225280762
Validation loss: 3.905977408091227

Epoch: 6| Step: 7
Training loss: 3.9821112155914307
Validation loss: 3.9015508890151978

Epoch: 6| Step: 8
Training loss: 4.006289005279541
Validation loss: 3.8981955448786416

Epoch: 6| Step: 9
Training loss: 3.5649967193603516
Validation loss: 3.8931895097096763

Epoch: 6| Step: 10
Training loss: 3.350715398788452
Validation loss: 3.8885178168614707

Epoch: 6| Step: 11
Training loss: 4.216840744018555
Validation loss: 3.884715994199117

Epoch: 6| Step: 12
Training loss: 4.113307952880859
Validation loss: 3.8799899021784463

Epoch: 6| Step: 13
Training loss: 5.1980462074279785
Validation loss: 3.875027894973755

Epoch: 17| Step: 0
Training loss: 3.5043740272521973
Validation loss: 3.870712081591288

Epoch: 6| Step: 1
Training loss: 4.156013488769531
Validation loss: 3.866515278816223

Epoch: 6| Step: 2
Training loss: 3.6400253772735596
Validation loss: 3.8624459902445474

Epoch: 6| Step: 3
Training loss: 4.296572685241699
Validation loss: 3.858343760172526

Epoch: 6| Step: 4
Training loss: 3.785243034362793
Validation loss: 3.854013959566752

Epoch: 6| Step: 5
Training loss: 4.317454814910889
Validation loss: 3.849256078402201

Epoch: 6| Step: 6
Training loss: 4.305783271789551
Validation loss: 3.8451496760050454

Epoch: 6| Step: 7
Training loss: 3.350694417953491
Validation loss: 3.8407106399536133

Epoch: 6| Step: 8
Training loss: 4.233464241027832
Validation loss: 3.836143652598063

Epoch: 6| Step: 9
Training loss: 3.710630416870117
Validation loss: 3.831711014111837

Epoch: 6| Step: 10
Training loss: 3.3086578845977783
Validation loss: 3.8276936213175454

Epoch: 6| Step: 11
Training loss: 4.149586200714111
Validation loss: 3.8229504426320395

Epoch: 6| Step: 12
Training loss: 4.552402496337891
Validation loss: 3.8189518451690674

Epoch: 6| Step: 13
Training loss: 4.628837585449219
Validation loss: 3.814162532488505

Epoch: 18| Step: 0
Training loss: 3.797790050506592
Validation loss: 3.8099087874094644

Epoch: 6| Step: 1
Training loss: 2.965087890625
Validation loss: 3.8066780964533486

Epoch: 6| Step: 2
Training loss: 2.9904098510742188
Validation loss: 3.8018933137257895

Epoch: 6| Step: 3
Training loss: 3.6987075805664062
Validation loss: 3.79721999168396

Epoch: 6| Step: 4
Training loss: 3.596987724304199
Validation loss: 3.7943697770436606

Epoch: 6| Step: 5
Training loss: 4.424794673919678
Validation loss: 3.7904813289642334

Epoch: 6| Step: 6
Training loss: 4.590295314788818
Validation loss: 3.786649227142334

Epoch: 6| Step: 7
Training loss: 3.8009324073791504
Validation loss: 3.782685955365499

Epoch: 6| Step: 8
Training loss: 4.201767921447754
Validation loss: 3.778624693552653

Epoch: 6| Step: 9
Training loss: 4.903192520141602
Validation loss: 3.77423624197642

Epoch: 6| Step: 10
Training loss: 4.450925350189209
Validation loss: 3.7700080474217734

Epoch: 6| Step: 11
Training loss: 5.04094123840332
Validation loss: 3.7660939693450928

Epoch: 6| Step: 12
Training loss: 3.6401469707489014
Validation loss: 3.7616443634033203

Epoch: 6| Step: 13
Training loss: 3.0738754272460938
Validation loss: 3.7576167583465576

Epoch: 19| Step: 0
Training loss: 4.520543098449707
Validation loss: 3.753760576248169

Epoch: 6| Step: 1
Training loss: 4.716521263122559
Validation loss: 3.7494798501332602

Epoch: 6| Step: 2
Training loss: 3.0045032501220703
Validation loss: 3.7454183101654053

Epoch: 6| Step: 3
Training loss: 3.57535457611084
Validation loss: 3.7414005200068154

Epoch: 6| Step: 4
Training loss: 2.76008939743042
Validation loss: 3.7367743253707886

Epoch: 6| Step: 5
Training loss: 3.5998926162719727
Validation loss: 3.7329536279042563

Epoch: 6| Step: 6
Training loss: 4.601280212402344
Validation loss: 3.72909677028656

Epoch: 6| Step: 7
Training loss: 3.797658920288086
Validation loss: 3.7252126932144165

Epoch: 6| Step: 8
Training loss: 4.138389587402344
Validation loss: 3.72120467821757

Epoch: 6| Step: 9
Training loss: 3.796164035797119
Validation loss: 3.7175325552622476

Epoch: 6| Step: 10
Training loss: 3.8241376876831055
Validation loss: 3.713944355646769

Epoch: 6| Step: 11
Training loss: 4.424695014953613
Validation loss: 3.709902008374532

Epoch: 6| Step: 12
Training loss: 3.8952956199645996
Validation loss: 3.7057307958602905

Epoch: 6| Step: 13
Training loss: 3.7797164916992188
Validation loss: 3.701826055844625

Epoch: 20| Step: 0
Training loss: 3.7193081378936768
Validation loss: 3.6979187726974487

Epoch: 6| Step: 1
Training loss: 2.5072407722473145
Validation loss: 3.693012078603109

Epoch: 6| Step: 2
Training loss: 4.796964168548584
Validation loss: 3.689694126447042

Epoch: 6| Step: 3
Training loss: 3.6272811889648438
Validation loss: 3.6848367055257163

Epoch: 6| Step: 4
Training loss: 4.357486248016357
Validation loss: 3.6812636057535806

Epoch: 6| Step: 5
Training loss: 5.1395263671875
Validation loss: 3.677156090736389

Epoch: 6| Step: 6
Training loss: 3.439803123474121
Validation loss: 3.6725242932637534

Epoch: 6| Step: 7
Training loss: 3.646289348602295
Validation loss: 3.6685849825541177

Epoch: 6| Step: 8
Training loss: 3.3356127738952637
Validation loss: 3.6647132635116577

Epoch: 6| Step: 9
Training loss: 3.032819986343384
Validation loss: 3.660700877507528

Epoch: 6| Step: 10
Training loss: 3.985302448272705
Validation loss: 3.6576547225316367

Epoch: 6| Step: 11
Training loss: 3.9537901878356934
Validation loss: 3.6527123053868613

Epoch: 6| Step: 12
Training loss: 4.573067665100098
Validation loss: 3.649081508318583

Epoch: 6| Step: 13
Training loss: 3.523676872253418
Validation loss: 3.6447407404581704

Epoch: 21| Step: 0
Training loss: 4.925173759460449
Validation loss: 3.6413459380467734

Epoch: 6| Step: 1
Training loss: 2.3585143089294434
Validation loss: 3.6368221839269004

Epoch: 6| Step: 2
Training loss: 4.078375816345215
Validation loss: 3.632433454195658

Epoch: 6| Step: 3
Training loss: 3.3763787746429443
Validation loss: 3.628022034962972

Epoch: 6| Step: 4
Training loss: 4.304372787475586
Validation loss: 3.6233867406845093

Epoch: 6| Step: 5
Training loss: 3.7760069370269775
Validation loss: 3.6195529301961265

Epoch: 6| Step: 6
Training loss: 3.8785834312438965
Validation loss: 3.615544080734253

Epoch: 6| Step: 7
Training loss: 4.049022197723389
Validation loss: 3.6111380656560264

Epoch: 6| Step: 8
Training loss: 3.5504279136657715
Validation loss: 3.607126792271932

Epoch: 6| Step: 9
Training loss: 3.5374302864074707
Validation loss: 3.602626005808512

Epoch: 6| Step: 10
Training loss: 3.6353726387023926
Validation loss: 3.5984265406926474

Epoch: 6| Step: 11
Training loss: 4.543030738830566
Validation loss: 3.5941644509633384

Epoch: 6| Step: 12
Training loss: 3.438539743423462
Validation loss: 3.5901054541269937

Epoch: 6| Step: 13
Training loss: 3.4359676837921143
Validation loss: 3.5854055881500244

Epoch: 22| Step: 0
Training loss: 3.446866035461426
Validation loss: 3.581434408823649

Epoch: 6| Step: 1
Training loss: 4.067282676696777
Validation loss: 3.577287236849467

Epoch: 6| Step: 2
Training loss: 3.641277551651001
Validation loss: 3.573317766189575

Epoch: 6| Step: 3
Training loss: 3.781942129135132
Validation loss: 3.569244901339213

Epoch: 6| Step: 4
Training loss: 4.550500392913818
Validation loss: 3.5647046168645224

Epoch: 6| Step: 5
Training loss: 2.746480941772461
Validation loss: 3.560146689414978

Epoch: 6| Step: 6
Training loss: 4.381239891052246
Validation loss: 3.5559037129084268

Epoch: 6| Step: 7
Training loss: 4.385003089904785
Validation loss: 3.5516191720962524

Epoch: 6| Step: 8
Training loss: 3.0755727291107178
Validation loss: 3.5468920866648355

Epoch: 6| Step: 9
Training loss: 3.814568042755127
Validation loss: 3.5427932341893515

Epoch: 6| Step: 10
Training loss: 4.211338996887207
Validation loss: 3.537771701812744

Epoch: 6| Step: 11
Training loss: 3.5920941829681396
Validation loss: 3.533222238222758

Epoch: 6| Step: 12
Training loss: 3.1031854152679443
Validation loss: 3.529504974683126

Epoch: 6| Step: 13
Training loss: 3.282188892364502
Validation loss: 3.5258079767227173

Epoch: 23| Step: 0
Training loss: 3.559176445007324
Validation loss: 3.5215912659962973

Epoch: 6| Step: 1
Training loss: 4.080636024475098
Validation loss: 3.5171786149342856

Epoch: 6| Step: 2
Training loss: 3.909853935241699
Validation loss: 3.5132092237472534

Epoch: 6| Step: 3
Training loss: 3.9478988647460938
Validation loss: 3.5082688331604004

Epoch: 6| Step: 4
Training loss: 3.096595525741577
Validation loss: 3.5043461322784424

Epoch: 6| Step: 5
Training loss: 2.7693474292755127
Validation loss: 3.5001621643702188

Epoch: 6| Step: 6
Training loss: 3.6968181133270264
Validation loss: 3.4959905544916787

Epoch: 6| Step: 7
Training loss: 3.5136704444885254
Validation loss: 3.491787870724996

Epoch: 6| Step: 8
Training loss: 3.478245973587036
Validation loss: 3.4879859685897827

Epoch: 6| Step: 9
Training loss: 4.178998947143555
Validation loss: 3.4834091663360596

Epoch: 6| Step: 10
Training loss: 4.3554887771606445
Validation loss: 3.4796417951583862

Epoch: 6| Step: 11
Training loss: 3.1666972637176514
Validation loss: 3.4755523204803467

Epoch: 6| Step: 12
Training loss: 3.614323139190674
Validation loss: 3.471673607826233

Epoch: 6| Step: 13
Training loss: 3.8965282440185547
Validation loss: 3.4675954977671304

Epoch: 24| Step: 0
Training loss: 3.7025649547576904
Validation loss: 3.463826338450114

Epoch: 6| Step: 1
Training loss: 3.7336854934692383
Validation loss: 3.4591934283574424

Epoch: 6| Step: 2
Training loss: 2.833117723464966
Validation loss: 3.4553302526474

Epoch: 6| Step: 3
Training loss: 3.7830557823181152
Validation loss: 3.4510806798934937

Epoch: 6| Step: 4
Training loss: 3.698697805404663
Validation loss: 3.4472362995147705

Epoch: 6| Step: 5
Training loss: 3.8714675903320312
Validation loss: 3.443082332611084

Epoch: 6| Step: 6
Training loss: 3.7029032707214355
Validation loss: 3.4385250409444175

Epoch: 6| Step: 7
Training loss: 3.7355639934539795
Validation loss: 3.434156656265259

Epoch: 6| Step: 8
Training loss: 3.712334632873535
Validation loss: 3.430577357610067

Epoch: 6| Step: 9
Training loss: 3.1240906715393066
Validation loss: 3.42663037776947

Epoch: 6| Step: 10
Training loss: 3.769268035888672
Validation loss: 3.4226152102152505

Epoch: 6| Step: 11
Training loss: 3.3762454986572266
Validation loss: 3.4185533126195273

Epoch: 6| Step: 12
Training loss: 3.1001503467559814
Validation loss: 3.4145472844441733

Epoch: 6| Step: 13
Training loss: 4.336235523223877
Validation loss: 3.4104949633280435

Epoch: 25| Step: 0
Training loss: 2.9030518531799316
Validation loss: 3.4067782163619995

Epoch: 6| Step: 1
Training loss: 3.0048141479492188
Validation loss: 3.402875463167826

Epoch: 6| Step: 2
Training loss: 3.100233316421509
Validation loss: 3.398888270060221

Epoch: 6| Step: 3
Training loss: 4.487308979034424
Validation loss: 3.3953375816345215

Epoch: 6| Step: 4
Training loss: 3.1893386840820312
Validation loss: 3.391754150390625

Epoch: 6| Step: 5
Training loss: 4.120590686798096
Validation loss: 3.3882161378860474

Epoch: 6| Step: 6
Training loss: 3.432084798812866
Validation loss: 3.3844106594721475

Epoch: 6| Step: 7
Training loss: 4.087563514709473
Validation loss: 3.3803815046946206

Epoch: 6| Step: 8
Training loss: 3.7848706245422363
Validation loss: 3.3759889205296836

Epoch: 6| Step: 9
Training loss: 3.2188191413879395
Validation loss: 3.3720558087031045

Epoch: 6| Step: 10
Training loss: 5.313860893249512
Validation loss: 3.3679221471150718

Epoch: 6| Step: 11
Training loss: 3.025420904159546
Validation loss: 3.363782842954

Epoch: 6| Step: 12
Training loss: 2.6932802200317383
Validation loss: 3.3599493503570557

Epoch: 6| Step: 13
Training loss: 3.353290557861328
Validation loss: 3.355884591738383

Epoch: 26| Step: 0
Training loss: 2.484684467315674
Validation loss: 3.35245152314504

Epoch: 6| Step: 1
Training loss: 2.9119486808776855
Validation loss: 3.3484220107396445

Epoch: 6| Step: 2
Training loss: 2.9166975021362305
Validation loss: 3.344912608464559

Epoch: 6| Step: 3
Training loss: 3.4511566162109375
Validation loss: 3.3414625326792398

Epoch: 6| Step: 4
Training loss: 2.920872211456299
Validation loss: 3.3376402854919434

Epoch: 6| Step: 5
Training loss: 3.8720204830169678
Validation loss: 3.333734651406606

Epoch: 6| Step: 6
Training loss: 4.046309471130371
Validation loss: 3.330211361249288

Epoch: 6| Step: 7
Training loss: 4.150819778442383
Validation loss: 3.32666544119517

Epoch: 6| Step: 8
Training loss: 3.7851498126983643
Validation loss: 3.323254108428955

Epoch: 6| Step: 9
Training loss: 3.770559310913086
Validation loss: 3.3194984992345176

Epoch: 6| Step: 10
Training loss: 4.4814019203186035
Validation loss: 3.3159130811691284

Epoch: 6| Step: 11
Training loss: 3.0499486923217773
Validation loss: 3.311814546585083

Epoch: 6| Step: 12
Training loss: 4.030472278594971
Validation loss: 3.3074881633122764

Epoch: 6| Step: 13
Training loss: 3.1192851066589355
Validation loss: 3.303607702255249

Epoch: 27| Step: 0
Training loss: 3.570894241333008
Validation loss: 3.299526333808899

Epoch: 6| Step: 1
Training loss: 3.7737319469451904
Validation loss: 3.2961285511652627

Epoch: 6| Step: 2
Training loss: 3.6670782566070557
Validation loss: 3.29224685827891

Epoch: 6| Step: 3
Training loss: 2.7554454803466797
Validation loss: 3.2883097330729165

Epoch: 6| Step: 4
Training loss: 3.8787946701049805
Validation loss: 3.284460206826528

Epoch: 6| Step: 5
Training loss: 4.012297630310059
Validation loss: 3.2806028922398887

Epoch: 6| Step: 6
Training loss: 3.428720235824585
Validation loss: 3.276455044746399

Epoch: 6| Step: 7
Training loss: 3.9604716300964355
Validation loss: 3.2723468542099

Epoch: 6| Step: 8
Training loss: 2.286787748336792
Validation loss: 3.269043525060018

Epoch: 6| Step: 9
Training loss: 3.8175137042999268
Validation loss: 3.265414277712504

Epoch: 6| Step: 10
Training loss: 2.889871835708618
Validation loss: 3.2617686986923218

Epoch: 6| Step: 11
Training loss: 2.6456236839294434
Validation loss: 3.257776657740275

Epoch: 6| Step: 12
Training loss: 3.96810245513916
Validation loss: 3.25412650903066

Epoch: 6| Step: 13
Training loss: 3.6830592155456543
Validation loss: 3.250661293665568

Epoch: 28| Step: 0
Training loss: 3.4420127868652344
Validation loss: 3.2469644943873086

Epoch: 6| Step: 1
Training loss: 3.9860148429870605
Validation loss: 3.2431896130243936

Epoch: 6| Step: 2
Training loss: 2.7542731761932373
Validation loss: 3.239489436149597

Epoch: 6| Step: 3
Training loss: 4.080461502075195
Validation loss: 3.2361369927724204

Epoch: 6| Step: 4
Training loss: 3.1929140090942383
Validation loss: 3.232380469640096

Epoch: 6| Step: 5
Training loss: 3.93654203414917
Validation loss: 3.2288071314493814

Epoch: 6| Step: 6
Training loss: 2.9259819984436035
Validation loss: 3.225378473599752

Epoch: 6| Step: 7
Training loss: 1.7388535737991333
Validation loss: 3.2215023040771484

Epoch: 6| Step: 8
Training loss: 4.354177951812744
Validation loss: 3.218098004659017

Epoch: 6| Step: 9
Training loss: 3.5791451930999756
Validation loss: 3.21447761853536

Epoch: 6| Step: 10
Training loss: 3.6770167350769043
Validation loss: 3.2110243240992227

Epoch: 6| Step: 11
Training loss: 3.5700974464416504
Validation loss: 3.2074488004048667

Epoch: 6| Step: 12
Training loss: 3.1598854064941406
Validation loss: 3.20350714524587

Epoch: 6| Step: 13
Training loss: 3.244971752166748
Validation loss: 3.1997857093811035

Epoch: 29| Step: 0
Training loss: 3.0771708488464355
Validation loss: 3.1962496042251587

Epoch: 6| Step: 1
Training loss: 3.6827499866485596
Validation loss: 3.192544420560201

Epoch: 6| Step: 2
Training loss: 4.001059055328369
Validation loss: 3.1890834172566733

Epoch: 6| Step: 3
Training loss: 3.0081653594970703
Validation loss: 3.1851832071940103

Epoch: 6| Step: 4
Training loss: 3.592169761657715
Validation loss: 3.18167253335317

Epoch: 6| Step: 5
Training loss: 3.680385112762451
Validation loss: 3.177778204282125

Epoch: 6| Step: 6
Training loss: 2.933379888534546
Validation loss: 3.1739595333735147

Epoch: 6| Step: 7
Training loss: 3.249703884124756
Validation loss: 3.169864217440287

Epoch: 6| Step: 8
Training loss: 4.279195785522461
Validation loss: 3.1661070187886557

Epoch: 6| Step: 9
Training loss: 2.9514200687408447
Validation loss: 3.1620332400004068

Epoch: 6| Step: 10
Training loss: 3.1310172080993652
Validation loss: 3.1587021748224893

Epoch: 6| Step: 11
Training loss: 3.119439125061035
Validation loss: 3.154894391695658

Epoch: 6| Step: 12
Training loss: 3.049135446548462
Validation loss: 3.15116818745931

Epoch: 6| Step: 13
Training loss: 3.2422852516174316
Validation loss: 3.1475643316904702

Epoch: 30| Step: 0
Training loss: 3.3888468742370605
Validation loss: 3.1438910961151123

Epoch: 6| Step: 1
Training loss: 3.825273275375366
Validation loss: 3.1403074264526367

Epoch: 6| Step: 2
Training loss: 4.1072998046875
Validation loss: 3.136777480443319

Epoch: 6| Step: 3
Training loss: 3.5697314739227295
Validation loss: 3.1332077980041504

Epoch: 6| Step: 4
Training loss: 3.4211268424987793
Validation loss: 3.1297293504079184

Epoch: 6| Step: 5
Training loss: 3.0854334831237793
Validation loss: 3.1265602906545005

Epoch: 6| Step: 6
Training loss: 3.2833831310272217
Validation loss: 3.1228891213734946

Epoch: 6| Step: 7
Training loss: 3.3823695182800293
Validation loss: 3.1191505988438926

Epoch: 6| Step: 8
Training loss: 2.5261101722717285
Validation loss: 3.1149309873580933

Epoch: 6| Step: 9
Training loss: 3.193260431289673
Validation loss: 3.1114291747411094

Epoch: 6| Step: 10
Training loss: 3.4231951236724854
Validation loss: 3.107369581858317

Epoch: 6| Step: 11
Training loss: 2.432473659515381
Validation loss: 3.103598157564799

Epoch: 6| Step: 12
Training loss: 3.5915935039520264
Validation loss: 3.099840005238851

Epoch: 6| Step: 13
Training loss: 3.0981674194335938
Validation loss: 3.0966346661249795

Epoch: 31| Step: 0
Training loss: 3.46052885055542
Validation loss: 3.0929241379102073

Epoch: 6| Step: 1
Training loss: 3.453996419906616
Validation loss: 3.089764952659607

Epoch: 6| Step: 2
Training loss: 3.4217395782470703
Validation loss: 3.085792303085327

Epoch: 6| Step: 3
Training loss: 3.8098464012145996
Validation loss: 3.082234779993693

Epoch: 6| Step: 4
Training loss: 2.3728232383728027
Validation loss: 3.078648567199707

Epoch: 6| Step: 5
Training loss: 3.8374311923980713
Validation loss: 3.0752779642740884

Epoch: 6| Step: 6
Training loss: 2.9914841651916504
Validation loss: 3.0718644062678018

Epoch: 6| Step: 7
Training loss: 1.8473987579345703
Validation loss: 3.068675955136617

Epoch: 6| Step: 8
Training loss: 3.4632062911987305
Validation loss: 3.0657275915145874

Epoch: 6| Step: 9
Training loss: 3.5469417572021484
Validation loss: 3.0620612303415933

Epoch: 6| Step: 10
Training loss: 3.0655579566955566
Validation loss: 3.0591278870900473

Epoch: 6| Step: 11
Training loss: 4.231102466583252
Validation loss: 3.0558950901031494

Epoch: 6| Step: 12
Training loss: 2.7113144397735596
Validation loss: 3.052296837170919

Epoch: 6| Step: 13
Training loss: 3.453430652618408
Validation loss: 3.048649549484253

Epoch: 32| Step: 0
Training loss: 3.1159026622772217
Validation loss: 3.045262018839518

Epoch: 6| Step: 1
Training loss: 2.8676159381866455
Validation loss: 3.0417218605677285

Epoch: 6| Step: 2
Training loss: 3.630706787109375
Validation loss: 3.0384808778762817

Epoch: 6| Step: 3
Training loss: 3.4507198333740234
Validation loss: 3.0353779395421348

Epoch: 6| Step: 4
Training loss: 3.387737274169922
Validation loss: 3.032270590464274

Epoch: 6| Step: 5
Training loss: 2.812897205352783
Validation loss: 3.028940478960673

Epoch: 6| Step: 6
Training loss: 3.6646645069122314
Validation loss: 3.0256279706954956

Epoch: 6| Step: 7
Training loss: 2.6036787033081055
Validation loss: 3.022264758745829

Epoch: 6| Step: 8
Training loss: 3.51774263381958
Validation loss: 3.018713037172953

Epoch: 6| Step: 9
Training loss: 3.3381571769714355
Validation loss: 3.0153211752573648

Epoch: 6| Step: 10
Training loss: 2.8530116081237793
Validation loss: 3.011872092882792

Epoch: 6| Step: 11
Training loss: 3.4963901042938232
Validation loss: 3.008668541908264

Epoch: 6| Step: 12
Training loss: 2.9380557537078857
Validation loss: 3.005569418271383

Epoch: 6| Step: 13
Training loss: 3.3695333003997803
Validation loss: 3.0021392504374185

Epoch: 33| Step: 0
Training loss: 4.186967372894287
Validation loss: 2.9989842573801675

Epoch: 6| Step: 1
Training loss: 3.2690160274505615
Validation loss: 2.995609720547994

Epoch: 6| Step: 2
Training loss: 3.6165294647216797
Validation loss: 2.9921154578526816

Epoch: 6| Step: 3
Training loss: 2.678901433944702
Validation loss: 2.989285866419474

Epoch: 6| Step: 4
Training loss: 2.611764669418335
Validation loss: 2.985314885775248

Epoch: 6| Step: 5
Training loss: 3.463787078857422
Validation loss: 2.9822270472844443

Epoch: 6| Step: 6
Training loss: 2.5943548679351807
Validation loss: 2.978345771630605

Epoch: 6| Step: 7
Training loss: 3.005706787109375
Validation loss: 2.9750645955403647

Epoch: 6| Step: 8
Training loss: 4.315818786621094
Validation loss: 2.972001791000366

Epoch: 6| Step: 9
Training loss: 3.5039658546447754
Validation loss: 2.9680784940719604

Epoch: 6| Step: 10
Training loss: 2.267543315887451
Validation loss: 2.964531103769938

Epoch: 6| Step: 11
Training loss: 2.6215929985046387
Validation loss: 2.961309870084127

Epoch: 6| Step: 12
Training loss: 3.2705109119415283
Validation loss: 2.958259383837382

Epoch: 6| Step: 13
Training loss: 3.067788600921631
Validation loss: 2.9556782643000283

Epoch: 34| Step: 0
Training loss: 3.17991042137146
Validation loss: 2.954938371976217

Epoch: 6| Step: 1
Training loss: 3.014472007751465
Validation loss: 2.9487958351771035

Epoch: 6| Step: 2
Training loss: 3.5434587001800537
Validation loss: 2.9456739823023477

Epoch: 6| Step: 3
Training loss: 2.425323486328125
Validation loss: 2.9426870743433633

Epoch: 6| Step: 4
Training loss: 2.6027297973632812
Validation loss: 2.940273960431417

Epoch: 6| Step: 5
Training loss: 2.9309864044189453
Validation loss: 2.937922775745392

Epoch: 6| Step: 6
Training loss: 3.2945263385772705
Validation loss: 2.935906092325846

Epoch: 6| Step: 7
Training loss: 3.7802090644836426
Validation loss: 2.9327664375305176

Epoch: 6| Step: 8
Training loss: 3.658167839050293
Validation loss: 2.928885022799174

Epoch: 6| Step: 9
Training loss: 3.436573028564453
Validation loss: 2.925643563270569

Epoch: 6| Step: 10
Training loss: 2.4721274375915527
Validation loss: 2.92426065603892

Epoch: 6| Step: 11
Training loss: 3.148132801055908
Validation loss: 2.928954760233561

Epoch: 6| Step: 12
Training loss: 2.8111822605133057
Validation loss: 2.9158533811569214

Epoch: 6| Step: 13
Training loss: 3.6116838455200195
Validation loss: 2.9123240311940513

Epoch: 35| Step: 0
Training loss: 2.687340021133423
Validation loss: 2.9087818463643393

Epoch: 6| Step: 1
Training loss: 3.537883758544922
Validation loss: 2.9058400789896646

Epoch: 6| Step: 2
Training loss: 2.730837345123291
Validation loss: 2.902920126914978

Epoch: 6| Step: 3
Training loss: 3.081963539123535
Validation loss: 2.9015681743621826

Epoch: 6| Step: 4
Training loss: 2.8542799949645996
Validation loss: 2.899899125099182

Epoch: 6| Step: 5
Training loss: 2.8421266078948975
Validation loss: 2.8955620527267456

Epoch: 6| Step: 6
Training loss: 3.118893623352051
Validation loss: 2.891851782798767

Epoch: 6| Step: 7
Training loss: 3.6198618412017822
Validation loss: 2.888769785563151

Epoch: 6| Step: 8
Training loss: 2.8410804271698
Validation loss: 2.8861962954203286

Epoch: 6| Step: 9
Training loss: 3.3421027660369873
Validation loss: 2.8836615880330405

Epoch: 6| Step: 10
Training loss: 2.5819222927093506
Validation loss: 2.879140615463257

Epoch: 6| Step: 11
Training loss: 3.607487678527832
Validation loss: 2.8770789305369058

Epoch: 6| Step: 12
Training loss: 3.056795120239258
Validation loss: 2.87242583433787

Epoch: 6| Step: 13
Training loss: 3.457510471343994
Validation loss: 2.8690425952275596

Epoch: 36| Step: 0
Training loss: 2.555049419403076
Validation loss: 2.864471197128296

Epoch: 6| Step: 1
Training loss: 3.332551956176758
Validation loss: 2.8623780012130737

Epoch: 6| Step: 2
Training loss: 3.0308055877685547
Validation loss: 2.859289209047953

Epoch: 6| Step: 3
Training loss: 3.0754432678222656
Validation loss: 2.856640855471293

Epoch: 6| Step: 4
Training loss: 2.991440534591675
Validation loss: 2.8538965384165444

Epoch: 6| Step: 5
Training loss: 2.928699016571045
Validation loss: 2.849640170733134

Epoch: 6| Step: 6
Training loss: 3.4047346115112305
Validation loss: 2.846293489138285

Epoch: 6| Step: 7
Training loss: 2.945539712905884
Validation loss: 2.842269937197367

Epoch: 6| Step: 8
Training loss: 3.411536455154419
Validation loss: 2.8383717934290567

Epoch: 6| Step: 9
Training loss: 3.6580777168273926
Validation loss: 2.835178812344869

Epoch: 6| Step: 10
Training loss: 2.8298373222351074
Validation loss: 2.8316816886266074

Epoch: 6| Step: 11
Training loss: 2.663154125213623
Validation loss: 2.8279851277669272

Epoch: 6| Step: 12
Training loss: 2.59171199798584
Validation loss: 2.824877381324768

Epoch: 6| Step: 13
Training loss: 3.3662917613983154
Validation loss: 2.8225478331247964

Epoch: 37| Step: 0
Training loss: 2.886800765991211
Validation loss: 2.820087711016337

Epoch: 6| Step: 1
Training loss: 3.2178726196289062
Validation loss: 2.820147434870402

Epoch: 6| Step: 2
Training loss: 3.259356737136841
Validation loss: 2.8146025935808816

Epoch: 6| Step: 3
Training loss: 3.086785078048706
Validation loss: 2.810660799344381

Epoch: 6| Step: 4
Training loss: 3.1819820404052734
Validation loss: 2.8091166416803994

Epoch: 6| Step: 5
Training loss: 3.0722403526306152
Validation loss: 2.807621637980143

Epoch: 6| Step: 6
Training loss: 2.9945666790008545
Validation loss: 2.808289408683777

Epoch: 6| Step: 7
Training loss: 2.26407790184021
Validation loss: 2.804877003033956

Epoch: 6| Step: 8
Training loss: 3.2650012969970703
Validation loss: 2.8010482788085938

Epoch: 6| Step: 9
Training loss: 2.513463020324707
Validation loss: 2.7976851065953574

Epoch: 6| Step: 10
Training loss: 2.9535200595855713
Validation loss: 2.7954718271891275

Epoch: 6| Step: 11
Training loss: 3.053663492202759
Validation loss: 2.789122740427653

Epoch: 6| Step: 12
Training loss: 3.2069201469421387
Validation loss: 2.7856895128885903

Epoch: 6| Step: 13
Training loss: 3.2521581649780273
Validation loss: 2.7832545836766562

Epoch: 38| Step: 0
Training loss: 3.490832567214966
Validation loss: 2.778967499732971

Epoch: 6| Step: 1
Training loss: 3.457742691040039
Validation loss: 2.778988520304362

Epoch: 6| Step: 2
Training loss: 3.138597011566162
Validation loss: 2.773480693499247

Epoch: 6| Step: 3
Training loss: 2.87662410736084
Validation loss: 2.7743696769078574

Epoch: 6| Step: 4
Training loss: 2.0871431827545166
Validation loss: 2.7697423299153647

Epoch: 6| Step: 5
Training loss: 2.3384013175964355
Validation loss: 2.766687353452047

Epoch: 6| Step: 6
Training loss: 3.3724308013916016
Validation loss: 2.763414740562439

Epoch: 6| Step: 7
Training loss: 2.036618232727051
Validation loss: 2.7617317040761313

Epoch: 6| Step: 8
Training loss: 3.2438299655914307
Validation loss: 2.7597474654515586

Epoch: 6| Step: 9
Training loss: 2.5779454708099365
Validation loss: 2.7567166884740195

Epoch: 6| Step: 10
Training loss: 3.7321114540100098
Validation loss: 2.7537413835525513

Epoch: 6| Step: 11
Training loss: 2.9450838565826416
Validation loss: 2.75069260597229

Epoch: 6| Step: 12
Training loss: 3.2815804481506348
Validation loss: 2.7462918361028037

Epoch: 6| Step: 13
Training loss: 3.0514328479766846
Validation loss: 2.74234672387441

Epoch: 39| Step: 0
Training loss: 2.232948064804077
Validation loss: 2.7390695412953696

Epoch: 6| Step: 1
Training loss: 3.771261215209961
Validation loss: 2.73709503809611

Epoch: 6| Step: 2
Training loss: 3.222238302230835
Validation loss: 2.732586224873861

Epoch: 6| Step: 3
Training loss: 2.9237465858459473
Validation loss: 2.7315851052602134

Epoch: 6| Step: 4
Training loss: 2.5305988788604736
Validation loss: 2.729163885116577

Epoch: 6| Step: 5
Training loss: 2.575639009475708
Validation loss: 2.7272191047668457

Epoch: 6| Step: 6
Training loss: 3.4625494480133057
Validation loss: 2.7299454609553018

Epoch: 6| Step: 7
Training loss: 2.6120808124542236
Validation loss: 2.7281641960144043

Epoch: 6| Step: 8
Training loss: 2.237370014190674
Validation loss: 2.7191693782806396

Epoch: 6| Step: 9
Training loss: 2.4233241081237793
Validation loss: 2.71829883257548

Epoch: 6| Step: 10
Training loss: 3.4522130489349365
Validation loss: 2.711032509803772

Epoch: 6| Step: 11
Training loss: 3.3329896926879883
Validation loss: 2.707638700803121

Epoch: 6| Step: 12
Training loss: 3.4380605220794678
Validation loss: 2.7060991128285727

Epoch: 6| Step: 13
Training loss: 2.841818332672119
Validation loss: 2.7015371123949685

Epoch: 40| Step: 0
Training loss: 2.3898706436157227
Validation loss: 2.6998819510142007

Epoch: 6| Step: 1
Training loss: 2.767275810241699
Validation loss: 2.6975370248158774

Epoch: 6| Step: 2
Training loss: 3.3634591102600098
Validation loss: 2.694953362147013

Epoch: 6| Step: 3
Training loss: 2.938084602355957
Validation loss: 2.692329525947571

Epoch: 6| Step: 4
Training loss: 2.5978102684020996
Validation loss: 2.688376009464264

Epoch: 6| Step: 5
Training loss: 3.10957670211792
Validation loss: 2.684760888417562

Epoch: 6| Step: 6
Training loss: 2.9929933547973633
Validation loss: 2.68114181359609

Epoch: 6| Step: 7
Training loss: 2.593869686126709
Validation loss: 2.6780678033828735

Epoch: 6| Step: 8
Training loss: 2.597090482711792
Validation loss: 2.6738576094309487

Epoch: 6| Step: 9
Training loss: 2.6875343322753906
Validation loss: 2.6712377866109214

Epoch: 6| Step: 10
Training loss: 3.1688003540039062
Validation loss: 2.6674150228500366

Epoch: 6| Step: 11
Training loss: 3.8398165702819824
Validation loss: 2.667065461476644

Epoch: 6| Step: 12
Training loss: 2.3206076622009277
Validation loss: 2.6646419366200766

Epoch: 6| Step: 13
Training loss: 3.0540659427642822
Validation loss: 2.6599242289861045

Epoch: 41| Step: 0
Training loss: 3.0505566596984863
Validation loss: 2.6570507685343423

Epoch: 6| Step: 1
Training loss: 2.7221086025238037
Validation loss: 2.6548874775568643

Epoch: 6| Step: 2
Training loss: 3.0695114135742188
Validation loss: 2.649239460627238

Epoch: 6| Step: 3
Training loss: 3.536193370819092
Validation loss: 2.647664189338684

Epoch: 6| Step: 4
Training loss: 2.4637606143951416
Validation loss: 2.643355131149292

Epoch: 6| Step: 5
Training loss: 3.075221538543701
Validation loss: 2.6401822566986084

Epoch: 6| Step: 6
Training loss: 2.6833553314208984
Validation loss: 2.6384803454081216

Epoch: 6| Step: 7
Training loss: 2.6288652420043945
Validation loss: 2.636300961176554

Epoch: 6| Step: 8
Training loss: 3.0953369140625
Validation loss: 2.63259220123291

Epoch: 6| Step: 9
Training loss: 2.502213478088379
Validation loss: 2.6283106605211892

Epoch: 6| Step: 10
Training loss: 2.5104546546936035
Validation loss: 2.625529646873474

Epoch: 6| Step: 11
Training loss: 3.5098695755004883
Validation loss: 2.6219793558120728

Epoch: 6| Step: 12
Training loss: 2.3030338287353516
Validation loss: 2.6184640725453696

Epoch: 6| Step: 13
Training loss: 2.6175575256347656
Validation loss: 2.616783380508423

Epoch: 42| Step: 0
Training loss: 2.8706531524658203
Validation loss: 2.6133556365966797

Epoch: 6| Step: 1
Training loss: 3.3947744369506836
Validation loss: 2.611502726872762

Epoch: 6| Step: 2
Training loss: 2.5338187217712402
Validation loss: 2.606913765271505

Epoch: 6| Step: 3
Training loss: 2.989201307296753
Validation loss: 2.6064676443735757

Epoch: 6| Step: 4
Training loss: 3.0708627700805664
Validation loss: 2.6028900345166526

Epoch: 6| Step: 5
Training loss: 3.28995943069458
Validation loss: 2.6020800471305847

Epoch: 6| Step: 6
Training loss: 3.0526270866394043
Validation loss: 2.60063902537028

Epoch: 6| Step: 7
Training loss: 2.489429473876953
Validation loss: 2.591575503349304

Epoch: 6| Step: 8
Training loss: 2.4520938396453857
Validation loss: 2.590793490409851

Epoch: 6| Step: 9
Training loss: 2.401353120803833
Validation loss: 2.5880002975463867

Epoch: 6| Step: 10
Training loss: 2.827469825744629
Validation loss: 2.5869303544362388

Epoch: 6| Step: 11
Training loss: 2.7400412559509277
Validation loss: 2.5829237500826516

Epoch: 6| Step: 12
Training loss: 2.5902352333068848
Validation loss: 2.57939883073171

Epoch: 6| Step: 13
Training loss: 2.4055380821228027
Validation loss: 2.5737352768580117

Epoch: 43| Step: 0
Training loss: 2.7944934368133545
Validation loss: 2.5724802017211914

Epoch: 6| Step: 1
Training loss: 3.1340861320495605
Validation loss: 2.571747342745463

Epoch: 6| Step: 2
Training loss: 2.6924548149108887
Validation loss: 2.5653029680252075

Epoch: 6| Step: 3
Training loss: 3.38000750541687
Validation loss: 2.565809647242228

Epoch: 6| Step: 4
Training loss: 2.938422918319702
Validation loss: 2.564409156640371

Epoch: 6| Step: 5
Training loss: 2.7458252906799316
Validation loss: 2.558401584625244

Epoch: 6| Step: 6
Training loss: 2.2060532569885254
Validation loss: 2.554679791132609

Epoch: 6| Step: 7
Training loss: 3.0691018104553223
Validation loss: 2.554616173108419

Epoch: 6| Step: 8
Training loss: 3.0071587562561035
Validation loss: 2.556582729021708

Epoch: 6| Step: 9
Training loss: 2.230679512023926
Validation loss: 2.5491546392440796

Epoch: 6| Step: 10
Training loss: 3.0050389766693115
Validation loss: 2.544898748397827

Epoch: 6| Step: 11
Training loss: 2.495373487472534
Validation loss: 2.5432282288869223

Epoch: 6| Step: 12
Training loss: 2.6218771934509277
Validation loss: 2.542068123817444

Epoch: 6| Step: 13
Training loss: 2.283160448074341
Validation loss: 2.538097302118937

Epoch: 44| Step: 0
Training loss: 3.095303535461426
Validation loss: 2.537912607192993

Epoch: 6| Step: 1
Training loss: 2.415731906890869
Validation loss: 2.5344610611597695

Epoch: 6| Step: 2
Training loss: 2.003307819366455
Validation loss: 2.533591310183207

Epoch: 6| Step: 3
Training loss: 3.1752800941467285
Validation loss: 2.5287506182988486

Epoch: 6| Step: 4
Training loss: 2.7061338424682617
Validation loss: 2.5271560549736023

Epoch: 6| Step: 5
Training loss: 2.5802369117736816
Validation loss: 2.5210763613382974

Epoch: 6| Step: 6
Training loss: 2.5959882736206055
Validation loss: 2.520281712214152

Epoch: 6| Step: 7
Training loss: 2.787419557571411
Validation loss: 2.5174563924471536

Epoch: 6| Step: 8
Training loss: 2.818821907043457
Validation loss: 2.5138036608695984

Epoch: 6| Step: 9
Training loss: 3.6408486366271973
Validation loss: 2.515570282936096

Epoch: 6| Step: 10
Training loss: 2.081662178039551
Validation loss: 2.509051243464152

Epoch: 6| Step: 11
Training loss: 1.547316551208496
Validation loss: 2.5025773843129477

Epoch: 6| Step: 12
Training loss: 3.2719578742980957
Validation loss: 2.500246604283651

Epoch: 6| Step: 13
Training loss: 3.268137216567993
Validation loss: 2.496313234170278

Epoch: 45| Step: 0
Training loss: 2.4831769466400146
Validation loss: 2.4968437949816384

Epoch: 6| Step: 1
Training loss: 3.3181233406066895
Validation loss: 2.4937116305033364

Epoch: 6| Step: 2
Training loss: 2.748533010482788
Validation loss: 2.4918431838353476

Epoch: 6| Step: 3
Training loss: 3.0614726543426514
Validation loss: 2.48941437403361

Epoch: 6| Step: 4
Training loss: 2.9860177040100098
Validation loss: 2.4876786867777505

Epoch: 6| Step: 5
Training loss: 3.320181369781494
Validation loss: 2.484628995259603

Epoch: 6| Step: 6
Training loss: 2.898922920227051
Validation loss: 2.4815402825673423

Epoch: 6| Step: 7
Training loss: 1.814819097518921
Validation loss: 2.476484735806783

Epoch: 6| Step: 8
Training loss: 3.388955593109131
Validation loss: 2.475905696551005

Epoch: 6| Step: 9
Training loss: 2.30754017829895
Validation loss: 2.4720104932785034

Epoch: 6| Step: 10
Training loss: 2.12939715385437
Validation loss: 2.469010591506958

Epoch: 6| Step: 11
Training loss: 2.403407573699951
Validation loss: 2.46670663356781

Epoch: 6| Step: 12
Training loss: 2.557864189147949
Validation loss: 2.46358323097229

Epoch: 6| Step: 13
Training loss: 2.0213096141815186
Validation loss: 2.464691976706187

Epoch: 46| Step: 0
Training loss: 2.264309883117676
Validation loss: 2.4607863823572793

Epoch: 6| Step: 1
Training loss: 2.50976824760437
Validation loss: 2.4706327517827353

Epoch: 6| Step: 2
Training loss: 2.5603628158569336
Validation loss: 2.4691375494003296

Epoch: 6| Step: 3
Training loss: 2.204033851623535
Validation loss: 2.4503069321314492

Epoch: 6| Step: 4
Training loss: 2.6888885498046875
Validation loss: 2.446924606959025

Epoch: 6| Step: 5
Training loss: 2.185504913330078
Validation loss: 2.4456562201182046

Epoch: 6| Step: 6
Training loss: 2.540358543395996
Validation loss: 2.443130294481913

Epoch: 6| Step: 7
Training loss: 2.473592519760132
Validation loss: 2.438683032989502

Epoch: 6| Step: 8
Training loss: 2.521475076675415
Validation loss: 2.4431814750035605

Epoch: 6| Step: 9
Training loss: 2.696361541748047
Validation loss: 2.4404261112213135

Epoch: 6| Step: 10
Training loss: 3.2285265922546387
Validation loss: 2.4432080189387

Epoch: 6| Step: 11
Training loss: 3.5382418632507324
Validation loss: 2.465823173522949

Epoch: 6| Step: 12
Training loss: 3.0846669673919678
Validation loss: 2.462060888608297

Epoch: 6| Step: 13
Training loss: 2.575670003890991
Validation loss: 2.4536041418711343

Epoch: 47| Step: 0
Training loss: 2.7105891704559326
Validation loss: 2.426915685335795

Epoch: 6| Step: 1
Training loss: 2.5109353065490723
Validation loss: 2.4207958380381265

Epoch: 6| Step: 2
Training loss: 2.585857391357422
Validation loss: 2.4187184969584146

Epoch: 6| Step: 3
Training loss: 2.927098512649536
Validation loss: 2.414982557296753

Epoch: 6| Step: 4
Training loss: 2.5509841442108154
Validation loss: 2.4118457436561584

Epoch: 6| Step: 5
Training loss: 2.586441993713379
Validation loss: 2.408403436342875

Epoch: 6| Step: 6
Training loss: 2.2285163402557373
Validation loss: 2.4079391956329346

Epoch: 6| Step: 7
Training loss: 2.563170909881592
Validation loss: 2.4047877391179404

Epoch: 6| Step: 8
Training loss: 2.0290207862854004
Validation loss: 2.4085851113001504

Epoch: 6| Step: 9
Training loss: 3.0730340480804443
Validation loss: 2.420970877011617

Epoch: 6| Step: 10
Training loss: 2.6528918743133545
Validation loss: 2.412503242492676

Epoch: 6| Step: 11
Training loss: 3.0757339000701904
Validation loss: 2.3970019022623696

Epoch: 6| Step: 12
Training loss: 2.360992908477783
Validation loss: 2.3892688751220703

Epoch: 6| Step: 13
Training loss: 2.531597375869751
Validation loss: 2.391381879647573

Epoch: 48| Step: 0
Training loss: 2.5458009243011475
Validation loss: 2.389151076475779

Epoch: 6| Step: 1
Training loss: 1.89580500125885
Validation loss: 2.3901607592900596

Epoch: 6| Step: 2
Training loss: 2.2859396934509277
Validation loss: 2.3874342838923135

Epoch: 6| Step: 3
Training loss: 3.316904067993164
Validation loss: 2.3862714767456055

Epoch: 6| Step: 4
Training loss: 2.6690385341644287
Validation loss: 2.381445129712423

Epoch: 6| Step: 5
Training loss: 2.8989243507385254
Validation loss: 2.3789804180463157

Epoch: 6| Step: 6
Training loss: 2.4273951053619385
Validation loss: 2.3725244998931885

Epoch: 6| Step: 7
Training loss: 2.662843704223633
Validation loss: 2.3699690103530884

Epoch: 6| Step: 8
Training loss: 2.861210346221924
Validation loss: 2.3683839042981467

Epoch: 6| Step: 9
Training loss: 2.0817253589630127
Validation loss: 2.3639520406723022

Epoch: 6| Step: 10
Training loss: 1.9253313541412354
Validation loss: 2.360638360182444

Epoch: 6| Step: 11
Training loss: 3.1080055236816406
Validation loss: 2.3584001064300537

Epoch: 6| Step: 12
Training loss: 2.706235408782959
Validation loss: 2.355879465738932

Epoch: 6| Step: 13
Training loss: 2.3775105476379395
Validation loss: 2.349403182665507

Epoch: 49| Step: 0
Training loss: 2.228909492492676
Validation loss: 2.3473562002182007

Epoch: 6| Step: 1
Training loss: 2.4402694702148438
Validation loss: 2.346004545688629

Epoch: 6| Step: 2
Training loss: 2.392791986465454
Validation loss: 2.339811623096466

Epoch: 6| Step: 3
Training loss: 2.530251979827881
Validation loss: 2.3397944370905557

Epoch: 6| Step: 4
Training loss: 3.7040395736694336
Validation loss: 2.3371411760648093

Epoch: 6| Step: 5
Training loss: 2.5055835247039795
Validation loss: 2.335619648297628

Epoch: 6| Step: 6
Training loss: 2.974435806274414
Validation loss: 2.330874522527059

Epoch: 6| Step: 7
Training loss: 2.248608112335205
Validation loss: 2.33414226770401

Epoch: 6| Step: 8
Training loss: 2.3540382385253906
Validation loss: 2.3277427752812705

Epoch: 6| Step: 9
Training loss: 2.0840229988098145
Validation loss: 2.325925648212433

Epoch: 6| Step: 10
Training loss: 2.1791117191314697
Validation loss: 2.324176033337911

Epoch: 6| Step: 11
Training loss: 2.7254014015197754
Validation loss: 2.3269256949424744

Epoch: 6| Step: 12
Training loss: 2.7647013664245605
Validation loss: 2.328593611717224

Epoch: 6| Step: 13
Training loss: 1.9888256788253784
Validation loss: 2.336457113424937

Epoch: 50| Step: 0
Training loss: 2.1599740982055664
Validation loss: 2.3354544639587402

Epoch: 6| Step: 1
Training loss: 2.776402473449707
Validation loss: 2.3214725653330484

Epoch: 6| Step: 2
Training loss: 2.806772470474243
Validation loss: 2.31247611840566

Epoch: 6| Step: 3
Training loss: 2.1457815170288086
Validation loss: 2.313541074593862

Epoch: 6| Step: 4
Training loss: 2.908813953399658
Validation loss: 2.310148517290751

Epoch: 6| Step: 5
Training loss: 2.1321754455566406
Validation loss: 2.3150742053985596

Epoch: 6| Step: 6
Training loss: 2.0546579360961914
Validation loss: 2.3268855810165405

Epoch: 6| Step: 7
Training loss: 2.630302906036377
Validation loss: 2.334471583366394

Epoch: 6| Step: 8
Training loss: 2.371986150741577
Validation loss: 2.3234047094980874

Epoch: 6| Step: 9
Training loss: 3.0793569087982178
Validation loss: 2.3184269269307456

Epoch: 6| Step: 10
Training loss: 2.648629665374756
Validation loss: 2.3085389137268066

Epoch: 6| Step: 11
Training loss: 2.469036340713501
Validation loss: 2.3015207250912986

Epoch: 6| Step: 12
Training loss: 2.2102620601654053
Validation loss: 2.2897210121154785

Epoch: 6| Step: 13
Training loss: 2.4821598529815674
Validation loss: 2.2862802545229592

Epoch: 51| Step: 0
Training loss: 1.890989065170288
Validation loss: 2.2812871734301248

Epoch: 6| Step: 1
Training loss: 2.944099187850952
Validation loss: 2.276678681373596

Epoch: 6| Step: 2
Training loss: 2.570063591003418
Validation loss: 2.2739002307256064

Epoch: 6| Step: 3
Training loss: 2.1509623527526855
Validation loss: 2.2768218517303467

Epoch: 6| Step: 4
Training loss: 2.542351722717285
Validation loss: 2.275745709737142

Epoch: 6| Step: 5
Training loss: 3.3878045082092285
Validation loss: 2.2681551376978555

Epoch: 6| Step: 6
Training loss: 2.6201295852661133
Validation loss: 2.267513314882914

Epoch: 6| Step: 7
Training loss: 2.352088212966919
Validation loss: 2.259407619635264

Epoch: 6| Step: 8
Training loss: 2.3757364749908447
Validation loss: 2.2622799475987754

Epoch: 6| Step: 9
Training loss: 2.0931899547576904
Validation loss: 2.2582929929097495

Epoch: 6| Step: 10
Training loss: 2.416071891784668
Validation loss: 2.257734219233195

Epoch: 6| Step: 11
Training loss: 1.8759963512420654
Validation loss: 2.2527594367663064

Epoch: 6| Step: 12
Training loss: 2.5038838386535645
Validation loss: 2.251341541608175

Epoch: 6| Step: 13
Training loss: 2.3558340072631836
Validation loss: 2.252620816230774

Epoch: 52| Step: 0
Training loss: 2.869123935699463
Validation loss: 2.246369461218516

Epoch: 6| Step: 1
Training loss: 2.909461259841919
Validation loss: 2.240922510623932

Epoch: 6| Step: 2
Training loss: 2.203565835952759
Validation loss: 2.2411158084869385

Epoch: 6| Step: 3
Training loss: 1.8040361404418945
Validation loss: 2.2462469736735025

Epoch: 6| Step: 4
Training loss: 2.702277898788452
Validation loss: 2.237930198510488

Epoch: 6| Step: 5
Training loss: 2.1184287071228027
Validation loss: 2.2357592384020486

Epoch: 6| Step: 6
Training loss: 2.2645907402038574
Validation loss: 2.2353850603103638

Epoch: 6| Step: 7
Training loss: 2.1476688385009766
Validation loss: 2.2337944706281028

Epoch: 6| Step: 8
Training loss: 3.1892313957214355
Validation loss: 2.2284189462661743

Epoch: 6| Step: 9
Training loss: 1.8732671737670898
Validation loss: 2.2270699739456177

Epoch: 6| Step: 10
Training loss: 2.160172700881958
Validation loss: 2.2293255726496377

Epoch: 6| Step: 11
Training loss: 2.5247323513031006
Validation loss: 2.220722198486328

Epoch: 6| Step: 12
Training loss: 2.5214147567749023
Validation loss: 2.2226810852686563

Epoch: 6| Step: 13
Training loss: 2.2980189323425293
Validation loss: 2.221778472264608

Epoch: 53| Step: 0
Training loss: 1.6045523881912231
Validation loss: 2.2196295658747354

Epoch: 6| Step: 1
Training loss: 1.7971694469451904
Validation loss: 2.21807469924291

Epoch: 6| Step: 2
Training loss: 3.1390955448150635
Validation loss: 2.2189346154530845

Epoch: 6| Step: 3
Training loss: 2.1877083778381348
Validation loss: 2.215100963910421

Epoch: 6| Step: 4
Training loss: 2.317711353302002
Validation loss: 2.2159902254740396

Epoch: 6| Step: 5
Training loss: 2.7737858295440674
Validation loss: 2.2128227154413858

Epoch: 6| Step: 6
Training loss: 2.4837265014648438
Validation loss: 2.206024924914042

Epoch: 6| Step: 7
Training loss: 2.253445625305176
Validation loss: 2.203362782796224

Epoch: 6| Step: 8
Training loss: 2.3967244625091553
Validation loss: 2.209711790084839

Epoch: 6| Step: 9
Training loss: 2.7328908443450928
Validation loss: 2.2052285075187683

Epoch: 6| Step: 10
Training loss: 2.2782015800476074
Validation loss: 2.20231831073761

Epoch: 6| Step: 11
Training loss: 2.1969125270843506
Validation loss: 2.200604339440664

Epoch: 6| Step: 12
Training loss: 2.3782544136047363
Validation loss: 2.1971099972724915

Epoch: 6| Step: 13
Training loss: 2.5415782928466797
Validation loss: 2.2000956932703652

Epoch: 54| Step: 0
Training loss: 2.4280636310577393
Validation loss: 2.1982420285542807

Epoch: 6| Step: 1
Training loss: 1.9581220149993896
Validation loss: 2.198234518369039

Epoch: 6| Step: 2
Training loss: 2.568328619003296
Validation loss: 2.195788343747457

Epoch: 6| Step: 3
Training loss: 2.8858284950256348
Validation loss: 2.188883821169535

Epoch: 6| Step: 4
Training loss: 2.1460928916931152
Validation loss: 2.192100683848063

Epoch: 6| Step: 5
Training loss: 2.286510944366455
Validation loss: 2.1872703234354653

Epoch: 6| Step: 6
Training loss: 2.2572174072265625
Validation loss: 2.1904678543408713

Epoch: 6| Step: 7
Training loss: 2.3803582191467285
Validation loss: 2.177466928958893

Epoch: 6| Step: 8
Training loss: 2.2694342136383057
Validation loss: 2.1746161580085754

Epoch: 6| Step: 9
Training loss: 1.7652640342712402
Validation loss: 2.175394376118978

Epoch: 6| Step: 10
Training loss: 2.988168954849243
Validation loss: 2.177997907002767

Epoch: 6| Step: 11
Training loss: 2.4291329383850098
Validation loss: 2.176781932512919

Epoch: 6| Step: 12
Training loss: 2.046175003051758
Validation loss: 2.1682841380437217

Epoch: 6| Step: 13
Training loss: 2.284580707550049
Validation loss: 2.169809619585673

Epoch: 55| Step: 0
Training loss: 2.8991308212280273
Validation loss: 2.166900157928467

Epoch: 6| Step: 1
Training loss: 2.3644986152648926
Validation loss: 2.163302222887675

Epoch: 6| Step: 2
Training loss: 1.8730639219284058
Validation loss: 2.1667861541112265

Epoch: 6| Step: 3
Training loss: 2.056487798690796
Validation loss: 2.1659294962882996

Epoch: 6| Step: 4
Training loss: 2.133434772491455
Validation loss: 2.1624045372009277

Epoch: 6| Step: 5
Training loss: 2.6505000591278076
Validation loss: 2.1597307920455933

Epoch: 6| Step: 6
Training loss: 2.033823013305664
Validation loss: 2.160298466682434

Epoch: 6| Step: 7
Training loss: 2.6452102661132812
Validation loss: 2.159395178159078

Epoch: 6| Step: 8
Training loss: 2.2728381156921387
Validation loss: 2.1473529736200967

Epoch: 6| Step: 9
Training loss: 2.298689365386963
Validation loss: 2.148380180199941

Epoch: 6| Step: 10
Training loss: 2.1179113388061523
Validation loss: 2.1517706712086997

Epoch: 6| Step: 11
Training loss: 1.7028812170028687
Validation loss: 2.160083214441935

Epoch: 6| Step: 12
Training loss: 3.2380034923553467
Validation loss: 2.1653237541516623

Epoch: 6| Step: 13
Training loss: 2.148141860961914
Validation loss: 2.1662432154019675

Epoch: 56| Step: 0
Training loss: 2.472817897796631
Validation loss: 2.1760804653167725

Epoch: 6| Step: 1
Training loss: 2.329735517501831
Validation loss: 2.1642443339029946

Epoch: 6| Step: 2
Training loss: 2.4287877082824707
Validation loss: 2.140222728252411

Epoch: 6| Step: 3
Training loss: 1.929917812347412
Validation loss: 2.1417428652445474

Epoch: 6| Step: 4
Training loss: 2.482992172241211
Validation loss: 2.142703950405121

Epoch: 6| Step: 5
Training loss: 1.9651451110839844
Validation loss: 2.1413628260294595

Epoch: 6| Step: 6
Training loss: 2.6829631328582764
Validation loss: 2.1498796741167703

Epoch: 6| Step: 7
Training loss: 2.5990355014801025
Validation loss: 2.1511977513631186

Epoch: 6| Step: 8
Training loss: 2.8589277267456055
Validation loss: 2.1521840691566467

Epoch: 6| Step: 9
Training loss: 2.679929256439209
Validation loss: 2.1543217500050864

Epoch: 6| Step: 10
Training loss: 2.0325098037719727
Validation loss: 2.1464755535125732

Epoch: 6| Step: 11
Training loss: 2.542832374572754
Validation loss: 2.1468379894892373

Epoch: 6| Step: 12
Training loss: 1.9246522188186646
Validation loss: 2.1499198277791343

Epoch: 6| Step: 13
Training loss: 1.6593436002731323
Validation loss: 2.1443093021710715

Epoch: 57| Step: 0
Training loss: 2.4733338356018066
Validation loss: 2.1416892409324646

Epoch: 6| Step: 1
Training loss: 2.1802752017974854
Validation loss: 2.135034918785095

Epoch: 6| Step: 2
Training loss: 2.319446563720703
Validation loss: 2.132109840710958

Epoch: 6| Step: 3
Training loss: 1.947787880897522
Validation loss: 2.131201446056366

Epoch: 6| Step: 4
Training loss: 1.58870267868042
Validation loss: 2.1304479042689004

Epoch: 6| Step: 5
Training loss: 2.336275339126587
Validation loss: 2.133057653903961

Epoch: 6| Step: 6
Training loss: 2.1125359535217285
Validation loss: 2.134367803732554

Epoch: 6| Step: 7
Training loss: 2.48753023147583
Validation loss: 2.1350664496421814

Epoch: 6| Step: 8
Training loss: 2.449098587036133
Validation loss: 2.140077292919159

Epoch: 6| Step: 9
Training loss: 2.288090705871582
Validation loss: 2.144242207209269

Epoch: 6| Step: 10
Training loss: 2.2403721809387207
Validation loss: 2.141438643137614

Epoch: 6| Step: 11
Training loss: 2.932708263397217
Validation loss: 2.1372751792271933

Epoch: 6| Step: 12
Training loss: 2.4106688499450684
Validation loss: 2.1336575150489807

Epoch: 6| Step: 13
Training loss: 2.654599189758301
Validation loss: 2.1290686329205832

Epoch: 58| Step: 0
Training loss: 2.0925235748291016
Validation loss: 2.1256476839383445

Epoch: 6| Step: 1
Training loss: 1.8333854675292969
Validation loss: 2.1227176189422607

Epoch: 6| Step: 2
Training loss: 2.024336338043213
Validation loss: 2.1269270976384482

Epoch: 6| Step: 3
Training loss: 1.806738018989563
Validation loss: 2.127740661303202

Epoch: 6| Step: 4
Training loss: 2.389280319213867
Validation loss: 2.1285069386164346

Epoch: 6| Step: 5
Training loss: 2.540858030319214
Validation loss: 2.1283369859059653

Epoch: 6| Step: 6
Training loss: 2.694768190383911
Validation loss: 2.1256550947825112

Epoch: 6| Step: 7
Training loss: 2.431647300720215
Validation loss: 2.126269300778707

Epoch: 6| Step: 8
Training loss: 2.070441722869873
Validation loss: 2.11892960468928

Epoch: 6| Step: 9
Training loss: 2.353917121887207
Validation loss: 2.1169244249661765

Epoch: 6| Step: 10
Training loss: 2.5612778663635254
Validation loss: 2.1112486124038696

Epoch: 6| Step: 11
Training loss: 2.214568853378296
Validation loss: 2.103249728679657

Epoch: 6| Step: 12
Training loss: 2.415149211883545
Validation loss: 2.101393222808838

Epoch: 6| Step: 13
Training loss: 2.722360372543335
Validation loss: 2.097565213839213

Epoch: 59| Step: 0
Training loss: 2.4781923294067383
Validation loss: 2.0969651341438293

Epoch: 6| Step: 1
Training loss: 2.058563709259033
Validation loss: 2.0999101599057517

Epoch: 6| Step: 2
Training loss: 2.656489372253418
Validation loss: 2.0961469213167825

Epoch: 6| Step: 3
Training loss: 2.846817970275879
Validation loss: 2.0982160766919455

Epoch: 6| Step: 4
Training loss: 2.2134642601013184
Validation loss: 2.095586280028025

Epoch: 6| Step: 5
Training loss: 1.9603819847106934
Validation loss: 2.0975915789604187

Epoch: 6| Step: 6
Training loss: 2.042557716369629
Validation loss: 2.091716468334198

Epoch: 6| Step: 7
Training loss: 2.671861171722412
Validation loss: 2.091132164001465

Epoch: 6| Step: 8
Training loss: 2.4876346588134766
Validation loss: 2.097473601500193

Epoch: 6| Step: 9
Training loss: 1.3710672855377197
Validation loss: 2.091942230860392

Epoch: 6| Step: 10
Training loss: 1.6672987937927246
Validation loss: 2.092704951763153

Epoch: 6| Step: 11
Training loss: 1.855058193206787
Validation loss: 2.094228426615397

Epoch: 6| Step: 12
Training loss: 2.6966543197631836
Validation loss: 2.095572849114736

Epoch: 6| Step: 13
Training loss: 2.86348819732666
Validation loss: 2.093882381916046

Epoch: 60| Step: 0
Training loss: 2.511233329772949
Validation loss: 2.0948870380719504

Epoch: 6| Step: 1
Training loss: 2.3488776683807373
Validation loss: 2.091937998930613

Epoch: 6| Step: 2
Training loss: 1.958630084991455
Validation loss: 2.0899207989374795

Epoch: 6| Step: 3
Training loss: 2.4526729583740234
Validation loss: 2.0844478607177734

Epoch: 6| Step: 4
Training loss: 2.173166036605835
Validation loss: 2.0794291694959006

Epoch: 6| Step: 5
Training loss: 2.1278605461120605
Validation loss: 2.076053500175476

Epoch: 6| Step: 6
Training loss: 2.0033273696899414
Validation loss: 2.0842730601628623

Epoch: 6| Step: 7
Training loss: 2.3165478706359863
Validation loss: 2.0792851646741233

Epoch: 6| Step: 8
Training loss: 2.6065425872802734
Validation loss: 2.086482048034668

Epoch: 6| Step: 9
Training loss: 2.196307420730591
Validation loss: 2.0818211436271667

Epoch: 6| Step: 10
Training loss: 2.78745698928833
Validation loss: 2.0822611252466836

Epoch: 6| Step: 11
Training loss: 2.265071392059326
Validation loss: 2.076336840788523

Epoch: 6| Step: 12
Training loss: 1.8966560363769531
Validation loss: 2.075577119986216

Epoch: 6| Step: 13
Training loss: 2.1569604873657227
Validation loss: 2.073838492234548

Epoch: 61| Step: 0
Training loss: 2.2898335456848145
Validation loss: 2.064831038316091

Epoch: 6| Step: 1
Training loss: 2.4360854625701904
Validation loss: 2.0750340024630227

Epoch: 6| Step: 2
Training loss: 2.2010934352874756
Validation loss: 2.0834178924560547

Epoch: 6| Step: 3
Training loss: 2.2925291061401367
Validation loss: 2.087905248006185

Epoch: 6| Step: 4
Training loss: 2.883068799972534
Validation loss: 2.0966338515281677

Epoch: 6| Step: 5
Training loss: 1.935715675354004
Validation loss: 2.0986194411913552

Epoch: 6| Step: 6
Training loss: 1.5806398391723633
Validation loss: 2.1013830502827964

Epoch: 6| Step: 7
Training loss: 2.3770194053649902
Validation loss: 2.1052544911702475

Epoch: 6| Step: 8
Training loss: 1.9690033197402954
Validation loss: 2.1107061306635537

Epoch: 6| Step: 9
Training loss: 2.176128625869751
Validation loss: 2.1111998756726584

Epoch: 6| Step: 10
Training loss: 2.15802264213562
Validation loss: 2.1071258783340454

Epoch: 6| Step: 11
Training loss: 2.2208032608032227
Validation loss: 2.108034054438273

Epoch: 6| Step: 12
Training loss: 3.1180570125579834
Validation loss: 2.0998804171880088

Epoch: 6| Step: 13
Training loss: 2.391530752182007
Validation loss: 2.0941485365231833

Epoch: 62| Step: 0
Training loss: 2.2903881072998047
Validation loss: 2.08838814496994

Epoch: 6| Step: 1
Training loss: 1.3694424629211426
Validation loss: 2.0806155999501548

Epoch: 6| Step: 2
Training loss: 2.4632630348205566
Validation loss: 2.079150915145874

Epoch: 6| Step: 3
Training loss: 2.5306997299194336
Validation loss: 2.0699947675069175

Epoch: 6| Step: 4
Training loss: 2.4779272079467773
Validation loss: 2.0713553428649902

Epoch: 6| Step: 5
Training loss: 2.4417836666107178
Validation loss: 2.0672093629837036

Epoch: 6| Step: 6
Training loss: 2.4991044998168945
Validation loss: 2.06751940647761

Epoch: 6| Step: 7
Training loss: 2.5914411544799805
Validation loss: 2.061395208040873

Epoch: 6| Step: 8
Training loss: 2.28879451751709
Validation loss: 2.0620099703470864

Epoch: 6| Step: 9
Training loss: 1.7754545211791992
Validation loss: 2.057162642478943

Epoch: 6| Step: 10
Training loss: 2.281644344329834
Validation loss: 2.0549914836883545

Epoch: 6| Step: 11
Training loss: 2.2198104858398438
Validation loss: 2.0596206386884055

Epoch: 6| Step: 12
Training loss: 2.1063404083251953
Validation loss: 2.0620727141698203

Epoch: 6| Step: 13
Training loss: 2.1475348472595215
Validation loss: 2.058904449144999

Epoch: 63| Step: 0
Training loss: 2.7781691551208496
Validation loss: 2.049032727877299

Epoch: 6| Step: 1
Training loss: 2.1350669860839844
Validation loss: 2.058305005232493

Epoch: 6| Step: 2
Training loss: 1.8657487630844116
Validation loss: 2.0515679717063904

Epoch: 6| Step: 3
Training loss: 1.7542786598205566
Validation loss: 2.061118801434835

Epoch: 6| Step: 4
Training loss: 3.3678226470947266
Validation loss: 2.060176889101664

Epoch: 6| Step: 5
Training loss: 1.9443691968917847
Validation loss: 2.061786492665609

Epoch: 6| Step: 6
Training loss: 1.8998247385025024
Validation loss: 2.0654271245002747

Epoch: 6| Step: 7
Training loss: 2.2678728103637695
Validation loss: 2.0535693367322287

Epoch: 6| Step: 8
Training loss: 2.138021945953369
Validation loss: 2.0575214624404907

Epoch: 6| Step: 9
Training loss: 1.860245704650879
Validation loss: 2.0481267968813577

Epoch: 6| Step: 10
Training loss: 2.3135979175567627
Validation loss: 2.0593199133872986

Epoch: 6| Step: 11
Training loss: 2.5054805278778076
Validation loss: 2.053558965524038

Epoch: 6| Step: 12
Training loss: 2.4051318168640137
Validation loss: 2.054849366346995

Epoch: 6| Step: 13
Training loss: 2.138540267944336
Validation loss: 2.053307274977366

Epoch: 64| Step: 0
Training loss: 2.2752771377563477
Validation loss: 2.0514637231826782

Epoch: 6| Step: 1
Training loss: 2.384387254714966
Validation loss: 2.0529863437016806

Epoch: 6| Step: 2
Training loss: 2.1305594444274902
Validation loss: 2.0478725035985312

Epoch: 6| Step: 3
Training loss: 2.6372694969177246
Validation loss: 2.0497336983680725

Epoch: 6| Step: 4
Training loss: 1.6897315979003906
Validation loss: 2.0512969493865967

Epoch: 6| Step: 5
Training loss: 1.988463282585144
Validation loss: 2.052265167236328

Epoch: 6| Step: 6
Training loss: 2.3821513652801514
Validation loss: 2.051773428916931

Epoch: 6| Step: 7
Training loss: 2.4630794525146484
Validation loss: 2.04598339398702

Epoch: 6| Step: 8
Training loss: 1.7585391998291016
Validation loss: 2.0509002407391868

Epoch: 6| Step: 9
Training loss: 2.2483296394348145
Validation loss: 2.0608493288358054

Epoch: 6| Step: 10
Training loss: 1.8918917179107666
Validation loss: 2.0431670943895974

Epoch: 6| Step: 11
Training loss: 2.081448554992676
Validation loss: 2.0445587436358132

Epoch: 6| Step: 12
Training loss: 2.6017885208129883
Validation loss: 2.0420703093210855

Epoch: 6| Step: 13
Training loss: 2.6495766639709473
Validation loss: 2.043346722920736

Epoch: 65| Step: 0
Training loss: 1.6393053531646729
Validation loss: 2.047096868356069

Epoch: 6| Step: 1
Training loss: 2.336484909057617
Validation loss: 2.051242729028066

Epoch: 6| Step: 2
Training loss: 2.1835360527038574
Validation loss: 2.0567921797434487

Epoch: 6| Step: 3
Training loss: 1.9896626472473145
Validation loss: 2.0511780778566995

Epoch: 6| Step: 4
Training loss: 2.365546941757202
Validation loss: 2.054870287577311

Epoch: 6| Step: 5
Training loss: 2.4647622108459473
Validation loss: 2.053560654322306

Epoch: 6| Step: 6
Training loss: 2.2300260066986084
Validation loss: 2.05406524737676

Epoch: 6| Step: 7
Training loss: 2.1237807273864746
Validation loss: 2.0589152177174888

Epoch: 6| Step: 8
Training loss: 2.7484090328216553
Validation loss: 2.058036724726359

Epoch: 6| Step: 9
Training loss: 2.299968957901001
Validation loss: 2.053258955478668

Epoch: 6| Step: 10
Training loss: 1.9370399713516235
Validation loss: 2.0507771571477256

Epoch: 6| Step: 11
Training loss: 2.0081071853637695
Validation loss: 2.05314972003301

Epoch: 6| Step: 12
Training loss: 2.684682846069336
Validation loss: 2.0483136971791587

Epoch: 6| Step: 13
Training loss: 2.2870841026306152
Validation loss: 2.049806773662567

Epoch: 66| Step: 0
Training loss: 2.0405526161193848
Validation loss: 2.0438562432924905

Epoch: 6| Step: 1
Training loss: 2.2068638801574707
Validation loss: 2.0455625653266907

Epoch: 6| Step: 2
Training loss: 2.469496250152588
Validation loss: 2.0428062677383423

Epoch: 6| Step: 3
Training loss: 2.6116251945495605
Validation loss: 2.041740278402964

Epoch: 6| Step: 4
Training loss: 2.4596238136291504
Validation loss: 2.0414567987124124

Epoch: 6| Step: 5
Training loss: 1.8333516120910645
Validation loss: 2.0348329544067383

Epoch: 6| Step: 6
Training loss: 1.6886465549468994
Validation loss: 2.0360387166341147

Epoch: 6| Step: 7
Training loss: 1.9226138591766357
Validation loss: 2.032783587773641

Epoch: 6| Step: 8
Training loss: 2.257016897201538
Validation loss: 2.0369718074798584

Epoch: 6| Step: 9
Training loss: 3.036078929901123
Validation loss: 2.040053347746531

Epoch: 6| Step: 10
Training loss: 2.425685405731201
Validation loss: 2.037957787513733

Epoch: 6| Step: 11
Training loss: 1.911780834197998
Validation loss: 2.0413268407185874

Epoch: 6| Step: 12
Training loss: 2.150454521179199
Validation loss: 2.0356990893681846

Epoch: 6| Step: 13
Training loss: 2.2391717433929443
Validation loss: 2.037272036075592

Epoch: 67| Step: 0
Training loss: 1.9180395603179932
Validation loss: 2.0329835613568625

Epoch: 6| Step: 1
Training loss: 1.5590611696243286
Validation loss: 2.035230060418447

Epoch: 6| Step: 2
Training loss: 2.1140592098236084
Validation loss: 2.038055499394735

Epoch: 6| Step: 3
Training loss: 2.103118896484375
Validation loss: 2.039981722831726

Epoch: 6| Step: 4
Training loss: 2.161594867706299
Validation loss: 2.042065223058065

Epoch: 6| Step: 5
Training loss: 2.310124397277832
Validation loss: 2.038057883580526

Epoch: 6| Step: 6
Training loss: 1.6860758066177368
Validation loss: 2.0417917370796204

Epoch: 6| Step: 7
Training loss: 2.4410719871520996
Validation loss: 2.047866463661194

Epoch: 6| Step: 8
Training loss: 2.4463820457458496
Validation loss: 2.0512550671895347

Epoch: 6| Step: 9
Training loss: 2.735997200012207
Validation loss: 2.0474842389424643

Epoch: 6| Step: 10
Training loss: 2.1791348457336426
Validation loss: 2.0450689792633057

Epoch: 6| Step: 11
Training loss: 2.5604231357574463
Validation loss: 2.047465145587921

Epoch: 6| Step: 12
Training loss: 2.3071811199188232
Validation loss: 2.0398682753245034

Epoch: 6| Step: 13
Training loss: 2.5025277137756348
Validation loss: 2.027027746041616

Epoch: 68| Step: 0
Training loss: 2.8634567260742188
Validation loss: 2.027737557888031

Epoch: 6| Step: 1
Training loss: 2.6000852584838867
Validation loss: 2.0297662814458213

Epoch: 6| Step: 2
Training loss: 2.2722816467285156
Validation loss: 2.0303867856661477

Epoch: 6| Step: 3
Training loss: 1.4853670597076416
Validation loss: 2.0277905464172363

Epoch: 6| Step: 4
Training loss: 2.360264778137207
Validation loss: 2.0442154010136924

Epoch: 6| Step: 5
Training loss: 2.0820517539978027
Validation loss: 2.0613556504249573

Epoch: 6| Step: 6
Training loss: 1.9262189865112305
Validation loss: 2.054697314898173

Epoch: 6| Step: 7
Training loss: 2.432265281677246
Validation loss: 2.0450706481933594

Epoch: 6| Step: 8
Training loss: 2.162748336791992
Validation loss: 2.025462051232656

Epoch: 6| Step: 9
Training loss: 2.606663465499878
Validation loss: 2.025549074014028

Epoch: 6| Step: 10
Training loss: 2.0655782222747803
Validation loss: 2.0326759020487466

Epoch: 6| Step: 11
Training loss: 1.979642391204834
Validation loss: 2.0353853503863015

Epoch: 6| Step: 12
Training loss: 2.0372867584228516
Validation loss: 2.0377445220947266

Epoch: 6| Step: 13
Training loss: 2.2430741786956787
Validation loss: 2.046754479408264

Epoch: 69| Step: 0
Training loss: 2.5876152515411377
Validation loss: 2.0494958957036338

Epoch: 6| Step: 1
Training loss: 2.6166954040527344
Validation loss: 2.0501458644866943

Epoch: 6| Step: 2
Training loss: 1.9486362934112549
Validation loss: 2.0455963611602783

Epoch: 6| Step: 3
Training loss: 2.3775014877319336
Validation loss: 2.050005316734314

Epoch: 6| Step: 4
Training loss: 1.5203726291656494
Validation loss: 2.047486960887909

Epoch: 6| Step: 5
Training loss: 1.9298824071884155
Validation loss: 2.0442258715629578

Epoch: 6| Step: 6
Training loss: 2.5346319675445557
Validation loss: 2.047255357106527

Epoch: 6| Step: 7
Training loss: 2.30515718460083
Validation loss: 2.0435598889986673

Epoch: 6| Step: 8
Training loss: 2.1322078704833984
Validation loss: 2.0387689073880515

Epoch: 6| Step: 9
Training loss: 1.9372222423553467
Validation loss: 2.0359601775805154

Epoch: 6| Step: 10
Training loss: 1.6464580297470093
Validation loss: 2.0344349145889282

Epoch: 6| Step: 11
Training loss: 2.5401687622070312
Validation loss: 2.0264287988344827

Epoch: 6| Step: 12
Training loss: 2.453217029571533
Validation loss: 2.0260738929112754

Epoch: 6| Step: 13
Training loss: 2.6532373428344727
Validation loss: 2.025153617064158

Epoch: 70| Step: 0
Training loss: 1.9373555183410645
Validation loss: 2.0248408913612366

Epoch: 6| Step: 1
Training loss: 2.659420967102051
Validation loss: 2.020093242327372

Epoch: 6| Step: 2
Training loss: 1.9392645359039307
Validation loss: 2.0223525563875833

Epoch: 6| Step: 3
Training loss: 1.6337721347808838
Validation loss: 2.0168941418329873

Epoch: 6| Step: 4
Training loss: 2.557241678237915
Validation loss: 2.0158717036247253

Epoch: 6| Step: 5
Training loss: 3.138326644897461
Validation loss: 2.0169487794240317

Epoch: 6| Step: 6
Training loss: 2.223783016204834
Validation loss: 2.018749415874481

Epoch: 6| Step: 7
Training loss: 1.9577219486236572
Validation loss: 2.019627571105957

Epoch: 6| Step: 8
Training loss: 1.627032995223999
Validation loss: 2.0130122105280557

Epoch: 6| Step: 9
Training loss: 2.766528606414795
Validation loss: 2.0156614979108176

Epoch: 6| Step: 10
Training loss: 2.116154193878174
Validation loss: 2.017359813054403

Epoch: 6| Step: 11
Training loss: 2.569432258605957
Validation loss: 2.0134796102841697

Epoch: 6| Step: 12
Training loss: 1.5667850971221924
Validation loss: 2.0143971840540567

Epoch: 6| Step: 13
Training loss: 2.1817452907562256
Validation loss: 2.0191338260968528

Epoch: 71| Step: 0
Training loss: 1.36178457736969
Validation loss: 2.0197545687357583

Epoch: 6| Step: 1
Training loss: 1.6754412651062012
Validation loss: 2.021545946598053

Epoch: 6| Step: 2
Training loss: 1.6803638935089111
Validation loss: 2.0218676924705505

Epoch: 6| Step: 3
Training loss: 2.41141414642334
Validation loss: 2.021331250667572

Epoch: 6| Step: 4
Training loss: 1.9258776903152466
Validation loss: 2.022368828455607

Epoch: 6| Step: 5
Training loss: 2.6227166652679443
Validation loss: 2.0211138129234314

Epoch: 6| Step: 6
Training loss: 2.4848737716674805
Validation loss: 2.0102773904800415

Epoch: 6| Step: 7
Training loss: 2.0538673400878906
Validation loss: 2.0148956179618835

Epoch: 6| Step: 8
Training loss: 2.1844451427459717
Validation loss: 2.0229432384173074

Epoch: 6| Step: 9
Training loss: 2.934452533721924
Validation loss: 2.0187431971232095

Epoch: 6| Step: 10
Training loss: 3.112910509109497
Validation loss: 2.0323962966601052

Epoch: 6| Step: 11
Training loss: 2.42523193359375
Validation loss: 2.037118454774221

Epoch: 6| Step: 12
Training loss: 1.843945860862732
Validation loss: 2.023843010266622

Epoch: 6| Step: 13
Training loss: 2.2642195224761963
Validation loss: 2.0190695325533548

Epoch: 72| Step: 0
Training loss: 2.1526246070861816
Validation loss: 2.01427427927653

Epoch: 6| Step: 1
Training loss: 2.127255916595459
Validation loss: 2.0000796715418496

Epoch: 6| Step: 2
Training loss: 1.5674031972885132
Validation loss: 2.006813883781433

Epoch: 6| Step: 3
Training loss: 2.4831862449645996
Validation loss: 2.0176345308621726

Epoch: 6| Step: 4
Training loss: 1.6647571325302124
Validation loss: 2.01900843779246

Epoch: 6| Step: 5
Training loss: 2.0818872451782227
Validation loss: 2.045437196890513

Epoch: 6| Step: 6
Training loss: 2.3002943992614746
Validation loss: 2.0499621629714966

Epoch: 6| Step: 7
Training loss: 2.400242328643799
Validation loss: 2.04509045680364

Epoch: 6| Step: 8
Training loss: 2.204181671142578
Validation loss: 2.0521992842356362

Epoch: 6| Step: 9
Training loss: 2.6069912910461426
Validation loss: 2.0556875268618264

Epoch: 6| Step: 10
Training loss: 1.9942818880081177
Validation loss: 2.0495434006055198

Epoch: 6| Step: 11
Training loss: 2.4996092319488525
Validation loss: 2.042765418688456

Epoch: 6| Step: 12
Training loss: 2.886082172393799
Validation loss: 2.0155906279881797

Epoch: 6| Step: 13
Training loss: 2.111267328262329
Validation loss: 2.0093979040781655

Epoch: 73| Step: 0
Training loss: 1.8752429485321045
Validation loss: 2.0253262519836426

Epoch: 6| Step: 1
Training loss: 2.5412869453430176
Validation loss: 2.035323957602183

Epoch: 6| Step: 2
Training loss: 2.1937057971954346
Validation loss: 2.0394508441289267

Epoch: 6| Step: 3
Training loss: 2.508183717727661
Validation loss: 2.039066175619761

Epoch: 6| Step: 4
Training loss: 2.280468463897705
Validation loss: 2.037659009297689

Epoch: 6| Step: 5
Training loss: 1.8716074228286743
Validation loss: 2.046247144540151

Epoch: 6| Step: 6
Training loss: 2.6324622631073
Validation loss: 2.0342922608057656

Epoch: 6| Step: 7
Training loss: 1.791390061378479
Validation loss: 2.0392727057139077

Epoch: 6| Step: 8
Training loss: 2.169020175933838
Validation loss: 2.029491106669108

Epoch: 6| Step: 9
Training loss: 2.0684332847595215
Validation loss: 2.023299773534139

Epoch: 6| Step: 10
Training loss: 2.544268846511841
Validation loss: 2.0245493054389954

Epoch: 6| Step: 11
Training loss: 1.9849307537078857
Validation loss: 2.0156238873799643

Epoch: 6| Step: 12
Training loss: 2.747788190841675
Validation loss: 2.01101553440094

Epoch: 6| Step: 13
Training loss: 1.7550289630889893
Validation loss: 2.0126890937487283

Epoch: 74| Step: 0
Training loss: 2.426219940185547
Validation loss: 2.0123477975527444

Epoch: 6| Step: 1
Training loss: 1.697234869003296
Validation loss: 2.016583343346914

Epoch: 6| Step: 2
Training loss: 1.9784882068634033
Validation loss: 2.006208340326945

Epoch: 6| Step: 3
Training loss: 2.04232120513916
Validation loss: 2.0098162094751992

Epoch: 6| Step: 4
Training loss: 2.2754342555999756
Validation loss: 2.008092443148295

Epoch: 6| Step: 5
Training loss: 2.07684326171875
Validation loss: 2.0131232738494873

Epoch: 6| Step: 6
Training loss: 2.5289969444274902
Validation loss: 2.012852946917216

Epoch: 6| Step: 7
Training loss: 2.662277936935425
Validation loss: 2.0059053897857666

Epoch: 6| Step: 8
Training loss: 2.2665884494781494
Validation loss: 2.009355068206787

Epoch: 6| Step: 9
Training loss: 2.3653297424316406
Validation loss: 2.004423717657725

Epoch: 6| Step: 10
Training loss: 2.3594770431518555
Validation loss: 2.013453722000122

Epoch: 6| Step: 11
Training loss: 1.9104690551757812
Validation loss: 2.012457629044851

Epoch: 6| Step: 12
Training loss: 2.036771059036255
Validation loss: 2.0143285393714905

Epoch: 6| Step: 13
Training loss: 2.1027262210845947
Validation loss: 2.011616806189219

Epoch: 75| Step: 0
Training loss: 2.375410556793213
Validation loss: 2.004101653893789

Epoch: 6| Step: 1
Training loss: 2.0478923320770264
Validation loss: 2.0122286876042685

Epoch: 6| Step: 2
Training loss: 2.091702699661255
Validation loss: 2.0056735475858054

Epoch: 6| Step: 3
Training loss: 1.9963024854660034
Validation loss: 2.0087271332740784

Epoch: 6| Step: 4
Training loss: 2.359548568725586
Validation loss: 2.0116222898165383

Epoch: 6| Step: 5
Training loss: 2.1994338035583496
Validation loss: 2.0139344135920205

Epoch: 6| Step: 6
Training loss: 2.3455729484558105
Validation loss: 2.0108237862586975

Epoch: 6| Step: 7
Training loss: 1.5711361169815063
Validation loss: 2.0098979075749717

Epoch: 6| Step: 8
Training loss: 2.453786849975586
Validation loss: 2.014226416746775

Epoch: 6| Step: 9
Training loss: 2.814683437347412
Validation loss: 2.0112777749697366

Epoch: 6| Step: 10
Training loss: 2.3701887130737305
Validation loss: 2.010717789332072

Epoch: 6| Step: 11
Training loss: 2.359476089477539
Validation loss: 2.01401823759079

Epoch: 6| Step: 12
Training loss: 1.61317777633667
Validation loss: 2.01955384016037

Epoch: 6| Step: 13
Training loss: 1.9962728023529053
Validation loss: 2.0209790070851645

Epoch: 76| Step: 0
Training loss: 2.3192291259765625
Validation loss: 2.003190517425537

Epoch: 6| Step: 1
Training loss: 2.0948336124420166
Validation loss: 2.0097381869951882

Epoch: 6| Step: 2
Training loss: 2.3744680881500244
Validation loss: 2.0159796873728433

Epoch: 6| Step: 3
Training loss: 2.8745453357696533
Validation loss: 2.0073824524879456

Epoch: 6| Step: 4
Training loss: 2.036503791809082
Validation loss: 2.014548579851786

Epoch: 6| Step: 5
Training loss: 2.1479663848876953
Validation loss: 2.018839418888092

Epoch: 6| Step: 6
Training loss: 2.452451229095459
Validation loss: 2.0243762930234275

Epoch: 6| Step: 7
Training loss: 2.38718843460083
Validation loss: 2.020968516667684

Epoch: 6| Step: 8
Training loss: 1.2138774394989014
Validation loss: 2.029062290986379

Epoch: 6| Step: 9
Training loss: 2.0615978240966797
Validation loss: 2.0204638044039407

Epoch: 6| Step: 10
Training loss: 2.630756139755249
Validation loss: 2.011472741762797

Epoch: 6| Step: 11
Training loss: 1.837827444076538
Validation loss: 2.0074623624483743

Epoch: 6| Step: 12
Training loss: 2.351688861846924
Validation loss: 2.0014058351516724

Epoch: 6| Step: 13
Training loss: 1.924343466758728
Validation loss: 2.011156757672628

Epoch: 77| Step: 0
Training loss: 1.7184038162231445
Validation loss: 2.01033220688502

Epoch: 6| Step: 1
Training loss: 2.195030450820923
Validation loss: 2.0131662686665854

Epoch: 6| Step: 2
Training loss: 2.1278834342956543
Validation loss: 2.0181416273117065

Epoch: 6| Step: 3
Training loss: 1.8479304313659668
Validation loss: 2.0278146862983704

Epoch: 6| Step: 4
Training loss: 1.889296531677246
Validation loss: 2.0361449321111045

Epoch: 6| Step: 5
Training loss: 2.3338727951049805
Validation loss: 2.0267653266588845

Epoch: 6| Step: 6
Training loss: 2.2252156734466553
Validation loss: 2.0167020161946616

Epoch: 6| Step: 7
Training loss: 2.1253786087036133
Validation loss: 2.024047374725342

Epoch: 6| Step: 8
Training loss: 2.098890781402588
Validation loss: 2.0046472946802774

Epoch: 6| Step: 9
Training loss: 2.2954649925231934
Validation loss: 2.0170845985412598

Epoch: 6| Step: 10
Training loss: 1.7570877075195312
Validation loss: 2.021536707878113

Epoch: 6| Step: 11
Training loss: 2.3452441692352295
Validation loss: 2.02269713083903

Epoch: 6| Step: 12
Training loss: 2.846487522125244
Validation loss: 2.0280719995498657

Epoch: 6| Step: 13
Training loss: 2.781388282775879
Validation loss: 2.0281988183657327

Epoch: 78| Step: 0
Training loss: 2.114105701446533
Validation loss: 2.028473416964213

Epoch: 6| Step: 1
Training loss: 2.813471555709839
Validation loss: 2.029123683770498

Epoch: 6| Step: 2
Training loss: 1.7003731727600098
Validation loss: 2.0295753280321756

Epoch: 6| Step: 3
Training loss: 1.9429810047149658
Validation loss: 2.029006044069926

Epoch: 6| Step: 4
Training loss: 2.139657974243164
Validation loss: 2.025259494781494

Epoch: 6| Step: 5
Training loss: 2.1833372116088867
Validation loss: 2.020164132118225

Epoch: 6| Step: 6
Training loss: 2.1707653999328613
Validation loss: 2.0082523425420127

Epoch: 6| Step: 7
Training loss: 2.4698824882507324
Validation loss: 2.0071172515551248

Epoch: 6| Step: 8
Training loss: 2.253164529800415
Validation loss: 2.0022722681363425

Epoch: 6| Step: 9
Training loss: 2.1620256900787354
Validation loss: 2.0131536523501077

Epoch: 6| Step: 10
Training loss: 2.2856311798095703
Validation loss: 1.9997421701749165

Epoch: 6| Step: 11
Training loss: 2.1856398582458496
Validation loss: 2.0168352127075195

Epoch: 6| Step: 12
Training loss: 2.0336804389953613
Validation loss: 2.0136046409606934

Epoch: 6| Step: 13
Training loss: 2.375493049621582
Validation loss: 2.0126925110816956

Epoch: 79| Step: 0
Training loss: 2.053969383239746
Validation loss: 2.0198798179626465

Epoch: 6| Step: 1
Training loss: 2.181241273880005
Validation loss: 2.0285378098487854

Epoch: 6| Step: 2
Training loss: 1.9630619287490845
Validation loss: 2.027213215827942

Epoch: 6| Step: 3
Training loss: 2.5651495456695557
Validation loss: 2.031599462032318

Epoch: 6| Step: 4
Training loss: 2.4216248989105225
Validation loss: 2.027968645095825

Epoch: 6| Step: 5
Training loss: 2.251680850982666
Validation loss: 2.0210962295532227

Epoch: 6| Step: 6
Training loss: 1.912027359008789
Validation loss: 2.019176105658213

Epoch: 6| Step: 7
Training loss: 2.80529522895813
Validation loss: 2.0176558097203574

Epoch: 6| Step: 8
Training loss: 2.561677932739258
Validation loss: 2.0069442987442017

Epoch: 6| Step: 9
Training loss: 2.495032548904419
Validation loss: 2.009637792905172

Epoch: 6| Step: 10
Training loss: 1.2816267013549805
Validation loss: 2.0015393495559692

Epoch: 6| Step: 11
Training loss: 1.6529017686843872
Validation loss: 2.011241296927134

Epoch: 6| Step: 12
Training loss: 2.1392173767089844
Validation loss: 2.004906495412191

Epoch: 6| Step: 13
Training loss: 2.198436737060547
Validation loss: 2.0104741851488748

Epoch: 80| Step: 0
Training loss: 1.9819608926773071
Validation loss: 2.0206551551818848

Epoch: 6| Step: 1
Training loss: 1.94917631149292
Validation loss: 2.0093836188316345

Epoch: 6| Step: 2
Training loss: 2.3590896129608154
Validation loss: 2.016858915487925

Epoch: 6| Step: 3
Training loss: 2.1206135749816895
Validation loss: 2.004430611928304

Epoch: 6| Step: 4
Training loss: 2.733199119567871
Validation loss: 2.0079606572786965

Epoch: 6| Step: 5
Training loss: 2.4015185832977295
Validation loss: 2.0141761302948

Epoch: 6| Step: 6
Training loss: 2.277775287628174
Validation loss: 2.017151097456614

Epoch: 6| Step: 7
Training loss: 2.897674083709717
Validation loss: 2.011897246042887

Epoch: 6| Step: 8
Training loss: 2.5955214500427246
Validation loss: 2.010366956392924

Epoch: 6| Step: 9
Training loss: 2.0374391078948975
Validation loss: 2.0044206380844116

Epoch: 6| Step: 10
Training loss: 2.119751453399658
Validation loss: 2.012695829073588

Epoch: 6| Step: 11
Training loss: 1.796462059020996
Validation loss: 2.0066295067469277

Epoch: 6| Step: 12
Training loss: 1.037576675415039
Validation loss: 1.9987550576527913

Epoch: 6| Step: 13
Training loss: 1.8760044574737549
Validation loss: 2.0039507150650024

Epoch: 81| Step: 0
Training loss: 1.5094513893127441
Validation loss: 2.0054822166760764

Epoch: 6| Step: 1
Training loss: 2.683405876159668
Validation loss: 2.0104379653930664

Epoch: 6| Step: 2
Training loss: 2.1624560356140137
Validation loss: 2.01159805059433

Epoch: 6| Step: 3
Training loss: 2.0932953357696533
Validation loss: 2.0147024989128113

Epoch: 6| Step: 4
Training loss: 1.9002221822738647
Validation loss: 2.013970752557119

Epoch: 6| Step: 5
Training loss: 1.9880011081695557
Validation loss: 2.008127232392629

Epoch: 6| Step: 6
Training loss: 2.208775520324707
Validation loss: 2.009367803732554

Epoch: 6| Step: 7
Training loss: 2.6009268760681152
Validation loss: 2.0053940415382385

Epoch: 6| Step: 8
Training loss: 2.7816991806030273
Validation loss: 2.01447061697642

Epoch: 6| Step: 9
Training loss: 1.3975205421447754
Validation loss: 2.016165574391683

Epoch: 6| Step: 10
Training loss: 2.564034938812256
Validation loss: 2.0172189275423684

Epoch: 6| Step: 11
Training loss: 1.9766724109649658
Validation loss: 2.009179413318634

Epoch: 6| Step: 12
Training loss: 2.0250887870788574
Validation loss: 2.01742813984553

Epoch: 6| Step: 13
Training loss: 2.113865852355957
Validation loss: 2.0097407499949136

Epoch: 82| Step: 0
Training loss: 1.7237675189971924
Validation loss: 2.0055370132128396

Epoch: 6| Step: 1
Training loss: 2.497091770172119
Validation loss: 2.0051597356796265

Epoch: 6| Step: 2
Training loss: 2.4103822708129883
Validation loss: 2.0045737822850547

Epoch: 6| Step: 3
Training loss: 2.1717166900634766
Validation loss: 2.0053183237711587

Epoch: 6| Step: 4
Training loss: 2.789479970932007
Validation loss: 2.005800167719523

Epoch: 6| Step: 5
Training loss: 2.36565899848938
Validation loss: 2.0214590032895408

Epoch: 6| Step: 6
Training loss: 2.1210334300994873
Validation loss: 2.0146168073018393

Epoch: 6| Step: 7
Training loss: 1.8573743104934692
Validation loss: 2.010877092679342

Epoch: 6| Step: 8
Training loss: 2.260984420776367
Validation loss: 2.013090491294861

Epoch: 6| Step: 9
Training loss: 1.847556471824646
Validation loss: 2.010596513748169

Epoch: 6| Step: 10
Training loss: 2.1346445083618164
Validation loss: 2.016932467619578

Epoch: 6| Step: 11
Training loss: 2.0690205097198486
Validation loss: 2.0059165159861245

Epoch: 6| Step: 12
Training loss: 1.8490874767303467
Validation loss: 2.0071898698806763

Epoch: 6| Step: 13
Training loss: 2.061960220336914
Validation loss: 2.0153202017148337

Epoch: 83| Step: 0
Training loss: 1.659210205078125
Validation loss: 2.014758904774984

Epoch: 6| Step: 1
Training loss: 2.7237260341644287
Validation loss: 2.0119427839914956

Epoch: 6| Step: 2
Training loss: 1.640245795249939
Validation loss: 2.012366791566213

Epoch: 6| Step: 3
Training loss: 2.062760829925537
Validation loss: 2.016357958316803

Epoch: 6| Step: 4
Training loss: 2.2606306076049805
Validation loss: 2.0093302528063455

Epoch: 6| Step: 5
Training loss: 2.629836320877075
Validation loss: 2.015309830506643

Epoch: 6| Step: 6
Training loss: 2.616518020629883
Validation loss: 2.02839332818985

Epoch: 6| Step: 7
Training loss: 1.256415605545044
Validation loss: 2.021832903226217

Epoch: 6| Step: 8
Training loss: 2.0223093032836914
Validation loss: 2.0121878186861673

Epoch: 6| Step: 9
Training loss: 2.322723388671875
Validation loss: 2.0156784852345786

Epoch: 6| Step: 10
Training loss: 2.5007104873657227
Validation loss: 2.011969248453776

Epoch: 6| Step: 11
Training loss: 2.2170472145080566
Validation loss: 2.007985850175222

Epoch: 6| Step: 12
Training loss: 1.776737928390503
Validation loss: 2.0044485131899514

Epoch: 6| Step: 13
Training loss: 2.238335609436035
Validation loss: 2.0124831000963845

Epoch: 84| Step: 0
Training loss: 2.006344795227051
Validation loss: 2.0084063013394675

Epoch: 6| Step: 1
Training loss: 1.6690855026245117
Validation loss: 2.0119521021842957

Epoch: 6| Step: 2
Training loss: 2.0666260719299316
Validation loss: 2.013853112856547

Epoch: 6| Step: 3
Training loss: 2.0897812843322754
Validation loss: 2.0108630657196045

Epoch: 6| Step: 4
Training loss: 2.241441249847412
Validation loss: 2.011199414730072

Epoch: 6| Step: 5
Training loss: 2.124878406524658
Validation loss: 2.0164292653401694

Epoch: 6| Step: 6
Training loss: 2.264115810394287
Validation loss: 2.011271059513092

Epoch: 6| Step: 7
Training loss: 2.8999733924865723
Validation loss: 2.0209873716036477

Epoch: 6| Step: 8
Training loss: 1.5342605113983154
Validation loss: 2.0189737677574158

Epoch: 6| Step: 9
Training loss: 2.5417985916137695
Validation loss: 2.0213658809661865

Epoch: 6| Step: 10
Training loss: 2.4868416786193848
Validation loss: 2.017611503601074

Epoch: 6| Step: 11
Training loss: 2.0710597038269043
Validation loss: 2.021228849887848

Epoch: 6| Step: 12
Training loss: 1.7654496431350708
Validation loss: 2.0179983576138816

Epoch: 6| Step: 13
Training loss: 2.1480824947357178
Validation loss: 2.012596925099691

Epoch: 85| Step: 0
Training loss: 1.9993464946746826
Validation loss: 2.012343645095825

Epoch: 6| Step: 1
Training loss: 2.464756727218628
Validation loss: 2.010955035686493

Epoch: 6| Step: 2
Training loss: 1.9244358539581299
Validation loss: 2.0124425888061523

Epoch: 6| Step: 3
Training loss: 1.8351972103118896
Validation loss: 2.007782498995463

Epoch: 6| Step: 4
Training loss: 2.1228556632995605
Validation loss: 2.0182833274205527

Epoch: 6| Step: 5
Training loss: 2.27608060836792
Validation loss: 2.019842823346456

Epoch: 6| Step: 6
Training loss: 2.493647336959839
Validation loss: 2.0252819061279297

Epoch: 6| Step: 7
Training loss: 1.9656168222427368
Validation loss: 2.0170647899309793

Epoch: 6| Step: 8
Training loss: 2.245234966278076
Validation loss: 2.0130517284075418

Epoch: 6| Step: 9
Training loss: 2.555941581726074
Validation loss: 2.0121786991755166

Epoch: 6| Step: 10
Training loss: 2.1343326568603516
Validation loss: 2.029330770174662

Epoch: 6| Step: 11
Training loss: 1.9975181818008423
Validation loss: 2.0025304555892944

Epoch: 6| Step: 12
Training loss: 1.4246327877044678
Validation loss: 2.012306014696757

Epoch: 6| Step: 13
Training loss: 2.3975510597229004
Validation loss: 2.010636309782664

Epoch: 86| Step: 0
Training loss: 2.5461463928222656
Validation loss: 2.029550790786743

Epoch: 6| Step: 1
Training loss: 1.6166611909866333
Validation loss: 2.030730048815409

Epoch: 6| Step: 2
Training loss: 1.9650871753692627
Validation loss: 2.0452163418134055

Epoch: 6| Step: 3
Training loss: 2.117875576019287
Validation loss: 2.041080196698507

Epoch: 6| Step: 4
Training loss: 1.7952916622161865
Validation loss: 2.0515615145365396

Epoch: 6| Step: 5
Training loss: 2.78495192527771
Validation loss: 2.045636455217997

Epoch: 6| Step: 6
Training loss: 2.8218441009521484
Validation loss: 2.0435331662495932

Epoch: 6| Step: 7
Training loss: 1.3562965393066406
Validation loss: 2.0171505411465964

Epoch: 6| Step: 8
Training loss: 2.053924560546875
Validation loss: 2.0077558358510337

Epoch: 6| Step: 9
Training loss: 2.278299331665039
Validation loss: 2.0129289825757346

Epoch: 6| Step: 10
Training loss: 2.55106782913208
Validation loss: 2.0037750005722046

Epoch: 6| Step: 11
Training loss: 2.0816566944122314
Validation loss: 2.0022135178248086

Epoch: 6| Step: 12
Training loss: 2.0737404823303223
Validation loss: 2.007557511329651

Epoch: 6| Step: 13
Training loss: 2.030738353729248
Validation loss: 2.007144490877787

Epoch: 87| Step: 0
Training loss: 2.1470985412597656
Validation loss: 2.005760689576467

Epoch: 6| Step: 1
Training loss: 2.1339774131774902
Validation loss: 1.9999740918477376

Epoch: 6| Step: 2
Training loss: 1.5999455451965332
Validation loss: 2.0058641036351523

Epoch: 6| Step: 3
Training loss: 2.64792537689209
Validation loss: 2.0066107312838235

Epoch: 6| Step: 4
Training loss: 2.996455669403076
Validation loss: 2.0107741355895996

Epoch: 6| Step: 5
Training loss: 1.9817092418670654
Validation loss: 2.006633162498474

Epoch: 6| Step: 6
Training loss: 1.8488073348999023
Validation loss: 2.0041007002194724

Epoch: 6| Step: 7
Training loss: 1.932265043258667
Validation loss: 2.0060646533966064

Epoch: 6| Step: 8
Training loss: 1.968584656715393
Validation loss: 2.012312670548757

Epoch: 6| Step: 9
Training loss: 1.9010405540466309
Validation loss: 2.0128957629203796

Epoch: 6| Step: 10
Training loss: 2.4546427726745605
Validation loss: 2.0209434231122336

Epoch: 6| Step: 11
Training loss: 1.9807486534118652
Validation loss: 2.031307061513265

Epoch: 6| Step: 12
Training loss: 2.3379344940185547
Validation loss: 2.036797742048899

Epoch: 6| Step: 13
Training loss: 2.298198699951172
Validation loss: 2.0267671942710876

Epoch: 88| Step: 0
Training loss: 2.4087893962860107
Validation loss: 2.0207015673319497

Epoch: 6| Step: 1
Training loss: 2.825870990753174
Validation loss: 2.0160651008288064

Epoch: 6| Step: 2
Training loss: 2.169210195541382
Validation loss: 2.0024702151616416

Epoch: 6| Step: 3
Training loss: 2.4580576419830322
Validation loss: 1.9961832960446675

Epoch: 6| Step: 4
Training loss: 2.3845181465148926
Validation loss: 1.993668019771576

Epoch: 6| Step: 5
Training loss: 1.7526381015777588
Validation loss: 2.003078838189443

Epoch: 6| Step: 6
Training loss: 1.9514521360397339
Validation loss: 1.999910334746043

Epoch: 6| Step: 7
Training loss: 2.0423436164855957
Validation loss: 2.003217081228892

Epoch: 6| Step: 8
Training loss: 1.8786290884017944
Validation loss: 2.0046683152516684

Epoch: 6| Step: 9
Training loss: 1.8679604530334473
Validation loss: 2.015157461166382

Epoch: 6| Step: 10
Training loss: 2.1478824615478516
Validation loss: 2.006247421105703

Epoch: 6| Step: 11
Training loss: 2.4208786487579346
Validation loss: 2.006545623143514

Epoch: 6| Step: 12
Training loss: 1.943678855895996
Validation loss: 2.017118453979492

Epoch: 6| Step: 13
Training loss: 1.6423873901367188
Validation loss: 2.0283127228418985

Epoch: 89| Step: 0
Training loss: 1.7734766006469727
Validation loss: 2.024259348710378

Epoch: 6| Step: 1
Training loss: 3.330526828765869
Validation loss: 2.0179160237312317

Epoch: 6| Step: 2
Training loss: 2.276907444000244
Validation loss: 2.011933147907257

Epoch: 6| Step: 3
Training loss: 1.7797762155532837
Validation loss: 2.022906482219696

Epoch: 6| Step: 4
Training loss: 1.7526648044586182
Validation loss: 2.018520176410675

Epoch: 6| Step: 5
Training loss: 2.4543232917785645
Validation loss: 2.014902631441752

Epoch: 6| Step: 6
Training loss: 1.554858922958374
Validation loss: 2.0073836048444114

Epoch: 6| Step: 7
Training loss: 2.4006733894348145
Validation loss: 2.026167154312134

Epoch: 6| Step: 8
Training loss: 1.772874355316162
Validation loss: 2.0225924253463745

Epoch: 6| Step: 9
Training loss: 2.2777066230773926
Validation loss: 2.028972049554189

Epoch: 6| Step: 10
Training loss: 2.183245897293091
Validation loss: 2.0284932057062783

Epoch: 6| Step: 11
Training loss: 1.9601041078567505
Validation loss: 2.0265780488650003

Epoch: 6| Step: 12
Training loss: 2.3314809799194336
Validation loss: 2.028376499811808

Epoch: 6| Step: 13
Training loss: 2.0684499740600586
Validation loss: 2.019395371278127

Epoch: 90| Step: 0
Training loss: 2.337434768676758
Validation loss: 2.024963676929474

Epoch: 6| Step: 1
Training loss: 2.2103447914123535
Validation loss: 2.001658876736959

Epoch: 6| Step: 2
Training loss: 1.9091652631759644
Validation loss: 2.0084447065989175

Epoch: 6| Step: 3
Training loss: 2.0971577167510986
Validation loss: 2.0067506631215415

Epoch: 6| Step: 4
Training loss: 2.475553512573242
Validation loss: 2.0146520535151162

Epoch: 6| Step: 5
Training loss: 2.519803524017334
Validation loss: 2.0038079818089805

Epoch: 6| Step: 6
Training loss: 2.094353675842285
Validation loss: 2.0005717873573303

Epoch: 6| Step: 7
Training loss: 1.8373370170593262
Validation loss: 2.006197532018026

Epoch: 6| Step: 8
Training loss: 2.4742603302001953
Validation loss: 2.0217363437016806

Epoch: 6| Step: 9
Training loss: 2.268479585647583
Validation loss: 2.0177647471427917

Epoch: 6| Step: 10
Training loss: 1.7536182403564453
Validation loss: 2.007791578769684

Epoch: 6| Step: 11
Training loss: 1.9108434915542603
Validation loss: 2.0016610622406006

Epoch: 6| Step: 12
Training loss: 2.149489402770996
Validation loss: 1.9999064803123474

Epoch: 6| Step: 13
Training loss: 2.0148723125457764
Validation loss: 2.0090622305870056

Epoch: 91| Step: 0
Training loss: 1.458061933517456
Validation loss: 2.0184373458226523

Epoch: 6| Step: 1
Training loss: 2.1118834018707275
Validation loss: 2.020519733428955

Epoch: 6| Step: 2
Training loss: 1.626636266708374
Validation loss: 2.037969787915548

Epoch: 6| Step: 3
Training loss: 1.8516261577606201
Validation loss: 2.0418052077293396

Epoch: 6| Step: 4
Training loss: 2.0244431495666504
Validation loss: 2.0338740150133767

Epoch: 6| Step: 5
Training loss: 2.3794898986816406
Validation loss: 2.035337825616201

Epoch: 6| Step: 6
Training loss: 2.3733229637145996
Validation loss: 2.041317900021871

Epoch: 6| Step: 7
Training loss: 1.830284595489502
Validation loss: 2.048103392124176

Epoch: 6| Step: 8
Training loss: 2.5359530448913574
Validation loss: 2.043628732363383

Epoch: 6| Step: 9
Training loss: 2.2925539016723633
Validation loss: 2.0339062015215554

Epoch: 6| Step: 10
Training loss: 2.2769594192504883
Validation loss: 2.0335099498430886

Epoch: 6| Step: 11
Training loss: 2.876345157623291
Validation loss: 2.023834009965261

Epoch: 6| Step: 12
Training loss: 2.2356934547424316
Validation loss: 2.0220609505971274

Epoch: 6| Step: 13
Training loss: 1.8282318115234375
Validation loss: 2.0175950129826865

Epoch: 92| Step: 0
Training loss: 2.1795244216918945
Validation loss: 2.0151384472846985

Epoch: 6| Step: 1
Training loss: 2.4315285682678223
Validation loss: 2.027257223924001

Epoch: 6| Step: 2
Training loss: 1.928649663925171
Validation loss: 2.0417645970980325

Epoch: 6| Step: 3
Training loss: 2.42374324798584
Validation loss: 2.047053277492523

Epoch: 6| Step: 4
Training loss: 3.1392812728881836
Validation loss: 2.0534796714782715

Epoch: 6| Step: 5
Training loss: 2.3344955444335938
Validation loss: 2.054013808568319

Epoch: 6| Step: 6
Training loss: 2.530738353729248
Validation loss: 2.0559646487236023

Epoch: 6| Step: 7
Training loss: 2.2500221729278564
Validation loss: 2.0546312729517617

Epoch: 6| Step: 8
Training loss: 2.2507476806640625
Validation loss: 2.0603955388069153

Epoch: 6| Step: 9
Training loss: 2.1844680309295654
Validation loss: 2.0520758827527366

Epoch: 6| Step: 10
Training loss: 1.8599005937576294
Validation loss: 2.056210180123647

Epoch: 6| Step: 11
Training loss: 1.872266411781311
Validation loss: 2.0561137994130454

Epoch: 6| Step: 12
Training loss: 1.927413821220398
Validation loss: 2.0518792072931924

Epoch: 6| Step: 13
Training loss: 1.794155240058899
Validation loss: 2.0512470801671348

Epoch: 93| Step: 0
Training loss: 1.8953847885131836
Validation loss: 2.0513673424720764

Epoch: 6| Step: 1
Training loss: 2.3783841133117676
Validation loss: 2.0461746652921042

Epoch: 6| Step: 2
Training loss: 2.7587287425994873
Validation loss: 2.0459083716074624

Epoch: 6| Step: 3
Training loss: 2.2738819122314453
Validation loss: 2.044134040673574

Epoch: 6| Step: 4
Training loss: 2.587385416030884
Validation loss: 2.040537099043528

Epoch: 6| Step: 5
Training loss: 1.804395318031311
Validation loss: 2.0319651166598

Epoch: 6| Step: 6
Training loss: 1.838956594467163
Validation loss: 2.022671937942505

Epoch: 6| Step: 7
Training loss: 2.520700693130493
Validation loss: 2.018371343612671

Epoch: 6| Step: 8
Training loss: 2.2131199836730957
Validation loss: 2.0168413122495017

Epoch: 6| Step: 9
Training loss: 2.664487361907959
Validation loss: 2.0159844160079956

Epoch: 6| Step: 10
Training loss: 2.092578411102295
Validation loss: 2.0132863918940225

Epoch: 6| Step: 11
Training loss: 1.6817678213119507
Validation loss: 2.0250398317972818

Epoch: 6| Step: 12
Training loss: 1.5803172588348389
Validation loss: 2.0231186151504517

Epoch: 6| Step: 13
Training loss: 1.697324514389038
Validation loss: 2.025589724381765

Epoch: 94| Step: 0
Training loss: 1.6512349843978882
Validation loss: 2.028983155886332

Epoch: 6| Step: 1
Training loss: 2.0736587047576904
Validation loss: 2.041966517766317

Epoch: 6| Step: 2
Training loss: 2.3567752838134766
Validation loss: 2.039267619450887

Epoch: 6| Step: 3
Training loss: 2.7547950744628906
Validation loss: 2.0300485293070474

Epoch: 6| Step: 4
Training loss: 2.2125682830810547
Validation loss: 2.0273310939470925

Epoch: 6| Step: 5
Training loss: 2.041123151779175
Validation loss: 2.0186867316563926

Epoch: 6| Step: 6
Training loss: 2.2026920318603516
Validation loss: 2.021482268969218

Epoch: 6| Step: 7
Training loss: 2.4292240142822266
Validation loss: 2.0262282689412436

Epoch: 6| Step: 8
Training loss: 1.6364378929138184
Validation loss: 2.0221883058547974

Epoch: 6| Step: 9
Training loss: 2.3248918056488037
Validation loss: 2.0041113098462424

Epoch: 6| Step: 10
Training loss: 2.566450595855713
Validation loss: 2.0085629423459372

Epoch: 6| Step: 11
Training loss: 1.994057536125183
Validation loss: 2.0201114217440286

Epoch: 6| Step: 12
Training loss: 1.8198777437210083
Validation loss: 2.0248764753341675

Epoch: 6| Step: 13
Training loss: 1.6557445526123047
Validation loss: 2.0182465314865112

Epoch: 95| Step: 0
Training loss: 2.4580941200256348
Validation loss: 2.0111195842425027

Epoch: 6| Step: 1
Training loss: 2.3599257469177246
Validation loss: 2.007540206114451

Epoch: 6| Step: 2
Training loss: 2.154003143310547
Validation loss: 2.007531980673472

Epoch: 6| Step: 3
Training loss: 2.0882906913757324
Validation loss: 2.003777801990509

Epoch: 6| Step: 4
Training loss: 1.7710316181182861
Validation loss: 2.0084602435429892

Epoch: 6| Step: 5
Training loss: 2.0801522731781006
Validation loss: 2.0144055485725403

Epoch: 6| Step: 6
Training loss: 2.3359978199005127
Validation loss: 2.017292042573293

Epoch: 6| Step: 7
Training loss: 2.326747417449951
Validation loss: 2.0191254019737244

Epoch: 6| Step: 8
Training loss: 2.895193576812744
Validation loss: 2.0283655921618142

Epoch: 6| Step: 9
Training loss: 2.368931531906128
Validation loss: 2.020303964614868

Epoch: 6| Step: 10
Training loss: 1.6293073892593384
Validation loss: 2.0279708902041116

Epoch: 6| Step: 11
Training loss: 2.313408374786377
Validation loss: 2.021764318148295

Epoch: 6| Step: 12
Training loss: 1.4750127792358398
Validation loss: 2.0202014247576394

Epoch: 6| Step: 13
Training loss: 1.5395565032958984
Validation loss: 2.030185023943583

Epoch: 96| Step: 0
Training loss: 1.8359766006469727
Validation loss: 2.0186663468678794

Epoch: 6| Step: 1
Training loss: 2.4419775009155273
Validation loss: 2.023005207379659

Epoch: 6| Step: 2
Training loss: 2.4323439598083496
Validation loss: 2.040968378384908

Epoch: 6| Step: 3
Training loss: 2.487020492553711
Validation loss: 2.01822700103124

Epoch: 6| Step: 4
Training loss: 2.1154491901397705
Validation loss: 2.0200239022572837

Epoch: 6| Step: 5
Training loss: 2.4799535274505615
Validation loss: 2.019178052743276

Epoch: 6| Step: 6
Training loss: 1.7601089477539062
Validation loss: 2.015617390473684

Epoch: 6| Step: 7
Training loss: 2.185727119445801
Validation loss: 2.0153539180755615

Epoch: 6| Step: 8
Training loss: 2.373389959335327
Validation loss: 2.0110426942507424

Epoch: 6| Step: 9
Training loss: 1.8299940824508667
Validation loss: 2.0109218756357827

Epoch: 6| Step: 10
Training loss: 2.3750791549682617
Validation loss: 2.009634772936503

Epoch: 6| Step: 11
Training loss: 1.6248514652252197
Validation loss: 2.0172112186749778

Epoch: 6| Step: 12
Training loss: 1.8176414966583252
Validation loss: 2.0285165309906006

Epoch: 6| Step: 13
Training loss: 1.8888661861419678
Validation loss: 2.0307734409968057

Epoch: 97| Step: 0
Training loss: 2.2166733741760254
Validation loss: 2.03974316517512

Epoch: 6| Step: 1
Training loss: 2.9456772804260254
Validation loss: 2.0374762614568076

Epoch: 6| Step: 2
Training loss: 2.575925350189209
Validation loss: 2.034582793712616

Epoch: 6| Step: 3
Training loss: 2.0181174278259277
Validation loss: 2.038896302382151

Epoch: 6| Step: 4
Training loss: 2.2059764862060547
Validation loss: 2.0373276273409524

Epoch: 6| Step: 5
Training loss: 1.6814730167388916
Validation loss: 2.0224130153656006

Epoch: 6| Step: 6
Training loss: 2.3327696323394775
Validation loss: 2.027353604634603

Epoch: 6| Step: 7
Training loss: 2.168372631072998
Validation loss: 2.0372384786605835

Epoch: 6| Step: 8
Training loss: 2.4768800735473633
Validation loss: 2.028546174367269

Epoch: 6| Step: 9
Training loss: 1.9914791584014893
Validation loss: 2.037678082784017

Epoch: 6| Step: 10
Training loss: 1.6141865253448486
Validation loss: 2.041422208150228

Epoch: 6| Step: 11
Training loss: 1.9067847728729248
Validation loss: 2.0328158140182495

Epoch: 6| Step: 12
Training loss: 1.9427769184112549
Validation loss: 2.027763545513153

Epoch: 6| Step: 13
Training loss: 1.4597176313400269
Validation loss: 2.0239595770835876

Epoch: 98| Step: 0
Training loss: 1.8669688701629639
Validation loss: 2.020795782407125

Epoch: 6| Step: 1
Training loss: 2.0355725288391113
Validation loss: 2.0102373560269675

Epoch: 6| Step: 2
Training loss: 2.8106637001037598
Validation loss: 2.0156854391098022

Epoch: 6| Step: 3
Training loss: 1.4380658864974976
Validation loss: 2.0085732142130532

Epoch: 6| Step: 4
Training loss: 2.2371408939361572
Validation loss: 2.0075669089953103

Epoch: 6| Step: 5
Training loss: 2.2068381309509277
Validation loss: 2.012927532196045

Epoch: 6| Step: 6
Training loss: 2.1848597526550293
Validation loss: 2.0117467045783997

Epoch: 6| Step: 7
Training loss: 2.0599679946899414
Validation loss: 2.0182552337646484

Epoch: 6| Step: 8
Training loss: 1.6369602680206299
Validation loss: 2.0060288508733115

Epoch: 6| Step: 9
Training loss: 2.176452398300171
Validation loss: 2.0100181301434836

Epoch: 6| Step: 10
Training loss: 2.3457565307617188
Validation loss: 2.0117624203364053

Epoch: 6| Step: 11
Training loss: 2.0794243812561035
Validation loss: 2.0316326220830283

Epoch: 6| Step: 12
Training loss: 2.8137781620025635
Validation loss: 2.017400046189626

Epoch: 6| Step: 13
Training loss: 1.7973724603652954
Validation loss: 2.0263578295707703

Epoch: 99| Step: 0
Training loss: 2.261547088623047
Validation loss: 2.0198392470677695

Epoch: 6| Step: 1
Training loss: 1.5099372863769531
Validation loss: 2.032975355784098

Epoch: 6| Step: 2
Training loss: 2.708559989929199
Validation loss: 2.028024991353353

Epoch: 6| Step: 3
Training loss: 2.250675678253174
Validation loss: 2.036661525567373

Epoch: 6| Step: 4
Training loss: 2.430230140686035
Validation loss: 2.0393904646237693

Epoch: 6| Step: 5
Training loss: 1.789036512374878
Validation loss: 2.0218638976415

Epoch: 6| Step: 6
Training loss: 2.0579872131347656
Validation loss: 2.022605836391449

Epoch: 6| Step: 7
Training loss: 2.138582229614258
Validation loss: 2.0169410904248557

Epoch: 6| Step: 8
Training loss: 1.5183355808258057
Validation loss: 2.0149142742156982

Epoch: 6| Step: 9
Training loss: 1.7375481128692627
Validation loss: 2.0169785022735596

Epoch: 6| Step: 10
Training loss: 2.004218578338623
Validation loss: 2.012520889441172

Epoch: 6| Step: 11
Training loss: 1.9632118940353394
Validation loss: 2.0135414600372314

Epoch: 6| Step: 12
Training loss: 2.379659652709961
Validation loss: 2.0197396675745645

Epoch: 6| Step: 13
Training loss: 2.6825149059295654
Validation loss: 2.0230181018511453

Epoch: 100| Step: 0
Training loss: 2.125816583633423
Validation loss: 2.018487791220347

Epoch: 6| Step: 1
Training loss: 2.282158374786377
Validation loss: 2.0289222598075867

Epoch: 6| Step: 2
Training loss: 1.8949480056762695
Validation loss: 2.028683145840963

Epoch: 6| Step: 3
Training loss: 2.1466801166534424
Validation loss: 2.020416875680288

Epoch: 6| Step: 4
Training loss: 1.748472809791565
Validation loss: 2.026010493437449

Epoch: 6| Step: 5
Training loss: 2.245565414428711
Validation loss: 2.0222785472869873

Epoch: 6| Step: 6
Training loss: 1.7588032484054565
Validation loss: 2.026513934135437

Epoch: 6| Step: 7
Training loss: 2.0864782333374023
Validation loss: 2.035777429739634

Epoch: 6| Step: 8
Training loss: 2.0496158599853516
Validation loss: 2.0323191483815513

Epoch: 6| Step: 9
Training loss: 2.169754981994629
Validation loss: 2.036485572655996

Epoch: 6| Step: 10
Training loss: 2.4357776641845703
Validation loss: 2.031523128350576

Epoch: 6| Step: 11
Training loss: 2.2081995010375977
Validation loss: 2.0420970718065896

Epoch: 6| Step: 12
Training loss: 2.0856311321258545
Validation loss: 2.040104111035665

Epoch: 6| Step: 13
Training loss: 2.2927098274230957
Validation loss: 2.037635167439779

Epoch: 101| Step: 0
Training loss: 2.0398306846618652
Validation loss: 2.0267646312713623

Epoch: 6| Step: 1
Training loss: 2.355344772338867
Validation loss: 2.0332069396972656

Epoch: 6| Step: 2
Training loss: 2.0850319862365723
Validation loss: 2.0241132577260337

Epoch: 6| Step: 3
Training loss: 1.9721283912658691
Validation loss: 2.026455799738566

Epoch: 6| Step: 4
Training loss: 1.866224765777588
Validation loss: 2.016470114390055

Epoch: 6| Step: 5
Training loss: 2.3655471801757812
Validation loss: 2.020519216855367

Epoch: 6| Step: 6
Training loss: 1.8446980714797974
Validation loss: 2.0157631039619446

Epoch: 6| Step: 7
Training loss: 1.8360204696655273
Validation loss: 2.027070780595144

Epoch: 6| Step: 8
Training loss: 2.6073951721191406
Validation loss: 2.035346766312917

Epoch: 6| Step: 9
Training loss: 2.4001080989837646
Validation loss: 2.0521556536356607

Epoch: 6| Step: 10
Training loss: 2.164560317993164
Validation loss: 2.0437450210253396

Epoch: 6| Step: 11
Training loss: 1.4568029642105103
Validation loss: 2.0657631556193032

Epoch: 6| Step: 12
Training loss: 1.8915932178497314
Validation loss: 2.0760960976282754

Epoch: 6| Step: 13
Training loss: 2.632047176361084
Validation loss: 2.078490376472473

Epoch: 102| Step: 0
Training loss: 1.6872341632843018
Validation loss: 2.082868834336599

Epoch: 6| Step: 1
Training loss: 1.9462834596633911
Validation loss: 2.058066169420878

Epoch: 6| Step: 2
Training loss: 1.774592638015747
Validation loss: 2.0643774469693503

Epoch: 6| Step: 3
Training loss: 2.207204818725586
Validation loss: 2.0350545843442283

Epoch: 6| Step: 4
Training loss: 1.7712602615356445
Validation loss: 2.033352315425873

Epoch: 6| Step: 5
Training loss: 2.736391067504883
Validation loss: 2.025357206662496

Epoch: 6| Step: 6
Training loss: 2.3249173164367676
Validation loss: 2.025615394115448

Epoch: 6| Step: 7
Training loss: 2.2956643104553223
Validation loss: 2.0196406046549478

Epoch: 6| Step: 8
Training loss: 2.5374155044555664
Validation loss: 2.0221436421076455

Epoch: 6| Step: 9
Training loss: 1.8807497024536133
Validation loss: 2.0196704665819802

Epoch: 6| Step: 10
Training loss: 1.9677460193634033
Validation loss: 2.022346536318461

Epoch: 6| Step: 11
Training loss: 2.385324001312256
Validation loss: 2.0111589630444846

Epoch: 6| Step: 12
Training loss: 1.9548765420913696
Validation loss: 2.017829338709513

Epoch: 6| Step: 13
Training loss: 2.121551275253296
Validation loss: 2.0170591473579407

Epoch: 103| Step: 0
Training loss: 1.7458226680755615
Validation loss: 2.018970866998037

Epoch: 6| Step: 1
Training loss: 2.0382156372070312
Validation loss: 2.0177173813184104

Epoch: 6| Step: 2
Training loss: 1.6565849781036377
Validation loss: 2.0106943448384604

Epoch: 6| Step: 3
Training loss: 2.1138381958007812
Validation loss: 2.0166283448537192

Epoch: 6| Step: 4
Training loss: 2.2692480087280273
Validation loss: 2.0121324261029563

Epoch: 6| Step: 5
Training loss: 2.365109443664551
Validation loss: 2.0134530862172446

Epoch: 6| Step: 6
Training loss: 1.7835890054702759
Validation loss: 2.025401790936788

Epoch: 6| Step: 7
Training loss: 1.971086025238037
Validation loss: 2.021784802277883

Epoch: 6| Step: 8
Training loss: 2.1626009941101074
Validation loss: 2.0401039520899453

Epoch: 6| Step: 9
Training loss: 2.543548107147217
Validation loss: 2.0512908299764

Epoch: 6| Step: 10
Training loss: 2.1421093940734863
Validation loss: 2.05934605995814

Epoch: 6| Step: 11
Training loss: 2.2595009803771973
Validation loss: 2.0596161683400473

Epoch: 6| Step: 12
Training loss: 1.9988430738449097
Validation loss: 2.0511467456817627

Epoch: 6| Step: 13
Training loss: 2.7739651203155518
Validation loss: 2.037957191467285

Epoch: 104| Step: 0
Training loss: 2.247183084487915
Validation loss: 2.029339015483856

Epoch: 6| Step: 1
Training loss: 1.5144929885864258
Validation loss: 2.0244542360305786

Epoch: 6| Step: 2
Training loss: 1.5263034105300903
Validation loss: 2.0234831174214682

Epoch: 6| Step: 3
Training loss: 2.090435743331909
Validation loss: 2.018079181512197

Epoch: 6| Step: 4
Training loss: 1.8271119594573975
Validation loss: 2.0159825483957925

Epoch: 6| Step: 5
Training loss: 2.1882901191711426
Validation loss: 2.020277678966522

Epoch: 6| Step: 6
Training loss: 2.2495274543762207
Validation loss: 2.021713693936666

Epoch: 6| Step: 7
Training loss: 2.540156602859497
Validation loss: 2.018231987953186

Epoch: 6| Step: 8
Training loss: 2.1593070030212402
Validation loss: 2.020433723926544

Epoch: 6| Step: 9
Training loss: 2.723891019821167
Validation loss: 2.029591957728068

Epoch: 6| Step: 10
Training loss: 2.380563259124756
Validation loss: 2.0297621687253318

Epoch: 6| Step: 11
Training loss: 1.5633840560913086
Validation loss: 2.025569498538971

Epoch: 6| Step: 12
Training loss: 1.972474455833435
Validation loss: 2.0295771956443787

Epoch: 6| Step: 13
Training loss: 2.644942045211792
Validation loss: 2.0344550013542175

Epoch: 105| Step: 0
Training loss: 1.6318614482879639
Validation loss: 2.0387029449144998

Epoch: 6| Step: 1
Training loss: 1.7768315076828003
Validation loss: 2.041856904824575

Epoch: 6| Step: 2
Training loss: 1.804325819015503
Validation loss: 2.0447797179222107

Epoch: 6| Step: 3
Training loss: 2.0579097270965576
Validation loss: 2.0340873996416726

Epoch: 6| Step: 4
Training loss: 1.800787329673767
Validation loss: 2.045021971066793

Epoch: 6| Step: 5
Training loss: 2.556074619293213
Validation loss: 2.048457622528076

Epoch: 6| Step: 6
Training loss: 2.257188320159912
Validation loss: 2.03938752412796

Epoch: 6| Step: 7
Training loss: 2.158902645111084
Validation loss: 2.0354883869489035

Epoch: 6| Step: 8
Training loss: 2.1539416313171387
Validation loss: 2.033774514993032

Epoch: 6| Step: 9
Training loss: 1.697710633277893
Validation loss: 2.030522127946218

Epoch: 6| Step: 10
Training loss: 2.9328064918518066
Validation loss: 2.0268421173095703

Epoch: 6| Step: 11
Training loss: 1.8262330293655396
Validation loss: 2.0281826655069985

Epoch: 6| Step: 12
Training loss: 2.3425798416137695
Validation loss: 2.0323981642723083

Epoch: 6| Step: 13
Training loss: 2.1005516052246094
Validation loss: 2.030516743659973

Epoch: 106| Step: 0
Training loss: 2.529594659805298
Validation loss: 2.0214330355326333

Epoch: 6| Step: 1
Training loss: 1.8938658237457275
Validation loss: 2.023353656133016

Epoch: 6| Step: 2
Training loss: 1.4643585681915283
Validation loss: 2.0302727818489075

Epoch: 6| Step: 3
Training loss: 1.969671368598938
Validation loss: 2.029459993044535

Epoch: 6| Step: 4
Training loss: 2.63993501663208
Validation loss: 2.0340494910875955

Epoch: 6| Step: 5
Training loss: 2.6227638721466064
Validation loss: 2.0376323064168296

Epoch: 6| Step: 6
Training loss: 1.556875228881836
Validation loss: 2.036799689133962

Epoch: 6| Step: 7
Training loss: 2.0062055587768555
Validation loss: 2.0405009984970093

Epoch: 6| Step: 8
Training loss: 2.036860466003418
Validation loss: 2.03247606754303

Epoch: 6| Step: 9
Training loss: 2.428184986114502
Validation loss: 2.0331480701764426

Epoch: 6| Step: 10
Training loss: 2.657179117202759
Validation loss: 2.0332476695378623

Epoch: 6| Step: 11
Training loss: 1.4988635778427124
Validation loss: 2.027161796887716

Epoch: 6| Step: 12
Training loss: 1.8350532054901123
Validation loss: 2.0282782912254333

Epoch: 6| Step: 13
Training loss: 2.1339097023010254
Validation loss: 2.0253844459851584

Epoch: 107| Step: 0
Training loss: 2.204967975616455
Validation loss: 2.0228097240130105

Epoch: 6| Step: 1
Training loss: 2.416008472442627
Validation loss: 2.0267327626546225

Epoch: 6| Step: 2
Training loss: 1.7496827840805054
Validation loss: 2.0350484053293862

Epoch: 6| Step: 3
Training loss: 2.4019062519073486
Validation loss: 2.0232279300689697

Epoch: 6| Step: 4
Training loss: 1.7120072841644287
Validation loss: 2.022849222024282

Epoch: 6| Step: 5
Training loss: 2.193103313446045
Validation loss: 2.0222351948420205

Epoch: 6| Step: 6
Training loss: 2.6036407947540283
Validation loss: 2.0164644519488015

Epoch: 6| Step: 7
Training loss: 1.5781733989715576
Validation loss: 2.0203376015027366

Epoch: 6| Step: 8
Training loss: 2.7429184913635254
Validation loss: 2.0313111941019693

Epoch: 6| Step: 9
Training loss: 2.0074844360351562
Validation loss: 2.0279892484347024

Epoch: 6| Step: 10
Training loss: 2.0182995796203613
Validation loss: 2.0097368558247886

Epoch: 6| Step: 11
Training loss: 1.5492143630981445
Validation loss: 2.0250226259231567

Epoch: 6| Step: 12
Training loss: 1.9307897090911865
Validation loss: 2.026999215284983

Epoch: 6| Step: 13
Training loss: 1.9976460933685303
Validation loss: 2.0401136676470437

Epoch: 108| Step: 0
Training loss: 2.6083662509918213
Validation loss: 2.0382174253463745

Epoch: 6| Step: 1
Training loss: 1.7051634788513184
Validation loss: 2.044617454210917

Epoch: 6| Step: 2
Training loss: 1.8616430759429932
Validation loss: 2.041420261065165

Epoch: 6| Step: 3
Training loss: 1.8652335405349731
Validation loss: 2.0357343753178916

Epoch: 6| Step: 4
Training loss: 1.6303232908248901
Validation loss: 2.028669615586599

Epoch: 6| Step: 5
Training loss: 2.152848958969116
Validation loss: 2.0331480701764426

Epoch: 6| Step: 6
Training loss: 2.352534294128418
Validation loss: 2.022886276245117

Epoch: 6| Step: 7
Training loss: 2.045503854751587
Validation loss: 2.022586723168691

Epoch: 6| Step: 8
Training loss: 2.112546920776367
Validation loss: 2.0247328678766885

Epoch: 6| Step: 9
Training loss: 2.10707950592041
Validation loss: 2.0312581260999045

Epoch: 6| Step: 10
Training loss: 2.9136478900909424
Validation loss: 2.024311343828837

Epoch: 6| Step: 11
Training loss: 2.2378342151641846
Validation loss: 2.0247711141904197

Epoch: 6| Step: 12
Training loss: 1.7995325326919556
Validation loss: 2.019893685976664

Epoch: 6| Step: 13
Training loss: 2.071687936782837
Validation loss: 2.0252413352330527

Epoch: 109| Step: 0
Training loss: 1.8238669633865356
Validation loss: 2.020283659299215

Epoch: 6| Step: 1
Training loss: 1.9373071193695068
Validation loss: 2.02247017621994

Epoch: 6| Step: 2
Training loss: 2.0049917697906494
Validation loss: 2.022857924302419

Epoch: 6| Step: 3
Training loss: 1.7276959419250488
Validation loss: 2.0207258264223733

Epoch: 6| Step: 4
Training loss: 2.4300312995910645
Validation loss: 2.031885584195455

Epoch: 6| Step: 5
Training loss: 2.1228322982788086
Validation loss: 2.0347535610198975

Epoch: 6| Step: 6
Training loss: 2.4495251178741455
Validation loss: 2.04195507367452

Epoch: 6| Step: 7
Training loss: 2.045053005218506
Validation loss: 2.0546975135803223

Epoch: 6| Step: 8
Training loss: 2.126019239425659
Validation loss: 2.0529449780782065

Epoch: 6| Step: 9
Training loss: 1.9343311786651611
Validation loss: 2.0674519737561545

Epoch: 6| Step: 10
Training loss: 2.1963090896606445
Validation loss: 2.0619085828463235

Epoch: 6| Step: 11
Training loss: 2.002948760986328
Validation loss: 2.047435681025187

Epoch: 6| Step: 12
Training loss: 2.521317720413208
Validation loss: 2.046381632486979

Epoch: 6| Step: 13
Training loss: 1.9092519283294678
Validation loss: 2.038141985734304

Epoch: 110| Step: 0
Training loss: 1.935570478439331
Validation loss: 2.027729630470276

Epoch: 6| Step: 1
Training loss: 2.5146408081054688
Validation loss: 2.0355443159739175

Epoch: 6| Step: 2
Training loss: 1.2352052927017212
Validation loss: 2.025410989920298

Epoch: 6| Step: 3
Training loss: 1.6929200887680054
Validation loss: 2.0295532941818237

Epoch: 6| Step: 4
Training loss: 1.8503763675689697
Validation loss: 2.0406081279118857

Epoch: 6| Step: 5
Training loss: 2.1026673316955566
Validation loss: 2.031876544157664

Epoch: 6| Step: 6
Training loss: 2.800766944885254
Validation loss: 2.0280902783075967

Epoch: 6| Step: 7
Training loss: 2.7135236263275146
Validation loss: 2.0372109413146973

Epoch: 6| Step: 8
Training loss: 1.917812705039978
Validation loss: 2.0355915625890098

Epoch: 6| Step: 9
Training loss: 1.8571380376815796
Validation loss: 2.0381953914960227

Epoch: 6| Step: 10
Training loss: 2.061695098876953
Validation loss: 2.038675526777903

Epoch: 6| Step: 11
Training loss: 1.7452476024627686
Validation loss: 2.0366003712018332

Epoch: 6| Step: 12
Training loss: 2.0703020095825195
Validation loss: 2.0388357639312744

Epoch: 6| Step: 13
Training loss: 2.290098190307617
Validation loss: 2.0388887325922647

Epoch: 111| Step: 0
Training loss: 1.9609839916229248
Validation loss: 2.032599171002706

Epoch: 6| Step: 1
Training loss: 2.285841226577759
Validation loss: 2.0401750604311624

Epoch: 6| Step: 2
Training loss: 1.4955905675888062
Validation loss: 2.0441921750704446

Epoch: 6| Step: 3
Training loss: 2.627091884613037
Validation loss: 2.039064606030782

Epoch: 6| Step: 4
Training loss: 2.244330406188965
Validation loss: 2.036579191684723

Epoch: 6| Step: 5
Training loss: 1.7491779327392578
Validation loss: 2.040750821431478

Epoch: 6| Step: 6
Training loss: 1.6819502115249634
Validation loss: 2.044366737206777

Epoch: 6| Step: 7
Training loss: 2.002288818359375
Validation loss: 2.0416916012763977

Epoch: 6| Step: 8
Training loss: 1.9198429584503174
Validation loss: 2.0473119417826333

Epoch: 6| Step: 9
Training loss: 2.009561538696289
Validation loss: 2.0479714274406433

Epoch: 6| Step: 10
Training loss: 2.5062742233276367
Validation loss: 2.0666086673736572

Epoch: 6| Step: 11
Training loss: 2.2684245109558105
Validation loss: 2.062626043955485

Epoch: 6| Step: 12
Training loss: 2.051542282104492
Validation loss: 2.0461889505386353

Epoch: 6| Step: 13
Training loss: 1.973848581314087
Validation loss: 2.041865507761637

Epoch: 112| Step: 0
Training loss: 2.0493929386138916
Validation loss: 2.046193619569143

Epoch: 6| Step: 1
Training loss: 2.410531997680664
Validation loss: 2.04199888308843

Epoch: 6| Step: 2
Training loss: 1.6503636837005615
Validation loss: 2.036590655644735

Epoch: 6| Step: 3
Training loss: 2.233114004135132
Validation loss: 2.0288658340771994

Epoch: 6| Step: 4
Training loss: 2.1842000484466553
Validation loss: 2.025104284286499

Epoch: 6| Step: 5
Training loss: 1.9688022136688232
Validation loss: 2.0295937061309814

Epoch: 6| Step: 6
Training loss: 1.8358242511749268
Validation loss: 2.0308274229367576

Epoch: 6| Step: 7
Training loss: 2.3215975761413574
Validation loss: 2.031155606110891

Epoch: 6| Step: 8
Training loss: 2.1214282512664795
Validation loss: 2.040658930937449

Epoch: 6| Step: 9
Training loss: 2.5611789226531982
Validation loss: 2.0210747520128884

Epoch: 6| Step: 10
Training loss: 1.8270128965377808
Validation loss: 2.0413445035616555

Epoch: 6| Step: 11
Training loss: 1.9780290126800537
Validation loss: 2.033786118030548

Epoch: 6| Step: 12
Training loss: 1.923255443572998
Validation loss: 2.045634130636851

Epoch: 6| Step: 13
Training loss: 1.9450163841247559
Validation loss: 2.0386579632759094

Epoch: 113| Step: 0
Training loss: 2.1453988552093506
Validation loss: 2.0317132075627646

Epoch: 6| Step: 1
Training loss: 2.5758886337280273
Validation loss: 2.04210102558136

Epoch: 6| Step: 2
Training loss: 1.7341134548187256
Validation loss: 2.036303758621216

Epoch: 6| Step: 3
Training loss: 1.872363805770874
Validation loss: 2.0276629527409873

Epoch: 6| Step: 4
Training loss: 2.018076181411743
Validation loss: 2.0473915338516235

Epoch: 6| Step: 5
Training loss: 2.223395824432373
Validation loss: 2.0283089876174927

Epoch: 6| Step: 6
Training loss: 1.7353293895721436
Validation loss: 2.0386820634206138

Epoch: 6| Step: 7
Training loss: 2.0600643157958984
Validation loss: 2.042469799518585

Epoch: 6| Step: 8
Training loss: 1.9237778186798096
Validation loss: 2.0342749754587808

Epoch: 6| Step: 9
Training loss: 1.819518804550171
Validation loss: 2.0384135643641152

Epoch: 6| Step: 10
Training loss: 2.1107335090637207
Validation loss: 2.039422651131948

Epoch: 6| Step: 11
Training loss: 2.7608325481414795
Validation loss: 2.046271880467733

Epoch: 6| Step: 12
Training loss: 2.3832778930664062
Validation loss: 2.0501400232315063

Epoch: 6| Step: 13
Training loss: 1.7317743301391602
Validation loss: 2.0485893289248147

Epoch: 114| Step: 0
Training loss: 2.034191608428955
Validation loss: 2.050438483556112

Epoch: 6| Step: 1
Training loss: 2.059579610824585
Validation loss: 2.0503310561180115

Epoch: 6| Step: 2
Training loss: 2.1185531616210938
Validation loss: 2.0486231446266174

Epoch: 6| Step: 3
Training loss: 1.9070091247558594
Validation loss: 2.055586874485016

Epoch: 6| Step: 4
Training loss: 2.1997053623199463
Validation loss: 2.055627465248108

Epoch: 6| Step: 5
Training loss: 2.2198071479797363
Validation loss: 2.0621793071428933

Epoch: 6| Step: 6
Training loss: 2.0978527069091797
Validation loss: 2.0587682723999023

Epoch: 6| Step: 7
Training loss: 1.9634562730789185
Validation loss: 2.0668190717697144

Epoch: 6| Step: 8
Training loss: 2.484001636505127
Validation loss: 2.0635830760002136

Epoch: 6| Step: 9
Training loss: 1.9082930088043213
Validation loss: 2.065416773160299

Epoch: 6| Step: 10
Training loss: 1.7720952033996582
Validation loss: 2.057043433189392

Epoch: 6| Step: 11
Training loss: 2.0021567344665527
Validation loss: 2.0484625498453775

Epoch: 6| Step: 12
Training loss: 2.3942644596099854
Validation loss: 2.0420790712038674

Epoch: 6| Step: 13
Training loss: 1.6777774095535278
Validation loss: 2.0438451766967773

Epoch: 115| Step: 0
Training loss: 1.492760181427002
Validation loss: 2.043439209461212

Epoch: 6| Step: 1
Training loss: 1.6920887231826782
Validation loss: 2.0493361949920654

Epoch: 6| Step: 2
Training loss: 2.669981002807617
Validation loss: 2.0511943101882935

Epoch: 6| Step: 3
Training loss: 2.5496926307678223
Validation loss: 2.049458702405294

Epoch: 6| Step: 4
Training loss: 1.9879769086837769
Validation loss: 2.046692192554474

Epoch: 6| Step: 5
Training loss: 2.5280070304870605
Validation loss: 2.0546764135360718

Epoch: 6| Step: 6
Training loss: 1.889796257019043
Validation loss: 2.03571351369222

Epoch: 6| Step: 7
Training loss: 1.736161470413208
Validation loss: 2.0345592498779297

Epoch: 6| Step: 8
Training loss: 1.92940092086792
Validation loss: 2.0292814572652182

Epoch: 6| Step: 9
Training loss: 2.319105386734009
Validation loss: 2.037656863530477

Epoch: 6| Step: 10
Training loss: 2.539454221725464
Validation loss: 2.038786470890045

Epoch: 6| Step: 11
Training loss: 1.5446505546569824
Validation loss: 2.035827616850535

Epoch: 6| Step: 12
Training loss: 1.4326832294464111
Validation loss: 2.0398963689804077

Epoch: 6| Step: 13
Training loss: 2.558854579925537
Validation loss: 2.041247765223185

Epoch: 116| Step: 0
Training loss: 2.4418435096740723
Validation loss: 2.042955994606018

Epoch: 6| Step: 1
Training loss: 1.9490230083465576
Validation loss: 2.0500863989194236

Epoch: 6| Step: 2
Training loss: 1.7200841903686523
Validation loss: 2.037583827972412

Epoch: 6| Step: 3
Training loss: 2.461601495742798
Validation loss: 2.0300666093826294

Epoch: 6| Step: 4
Training loss: 2.2992844581604004
Validation loss: 2.0389517347017923

Epoch: 6| Step: 5
Training loss: 1.753710150718689
Validation loss: 2.0325127045313516

Epoch: 6| Step: 6
Training loss: 1.8480052947998047
Validation loss: 2.0435054898262024

Epoch: 6| Step: 7
Training loss: 1.71602201461792
Validation loss: 2.0449735720952353

Epoch: 6| Step: 8
Training loss: 2.1237425804138184
Validation loss: 2.0475812355677285

Epoch: 6| Step: 9
Training loss: 2.010383129119873
Validation loss: 2.0315340558687844

Epoch: 6| Step: 10
Training loss: 1.9768118858337402
Validation loss: 2.0277087489763894

Epoch: 6| Step: 11
Training loss: 2.435298442840576
Validation loss: 2.023642838001251

Epoch: 6| Step: 12
Training loss: 1.7205761671066284
Validation loss: 2.026236812273661

Epoch: 6| Step: 13
Training loss: 2.390115261077881
Validation loss: 2.0132041374842324

Epoch: 117| Step: 0
Training loss: 1.9079655408859253
Validation loss: 2.0199382106463113

Epoch: 6| Step: 1
Training loss: 1.574475646018982
Validation loss: 2.021298885345459

Epoch: 6| Step: 2
Training loss: 2.6840739250183105
Validation loss: 2.0148542126019797

Epoch: 6| Step: 3
Training loss: 1.8986858129501343
Validation loss: 2.0372310280799866

Epoch: 6| Step: 4
Training loss: 1.9928110837936401
Validation loss: 2.0291253129641214

Epoch: 6| Step: 5
Training loss: 1.5576996803283691
Validation loss: 2.0348336497942605

Epoch: 6| Step: 6
Training loss: 2.337846279144287
Validation loss: 2.031507054964701

Epoch: 6| Step: 7
Training loss: 1.9608566761016846
Validation loss: 2.0384281873703003

Epoch: 6| Step: 8
Training loss: 1.8467354774475098
Validation loss: 2.04286652803421

Epoch: 6| Step: 9
Training loss: 2.766171932220459
Validation loss: 2.0357468326886496

Epoch: 6| Step: 10
Training loss: 2.149092674255371
Validation loss: 2.0445361932118735

Epoch: 6| Step: 11
Training loss: 1.8474550247192383
Validation loss: 2.046181579430898

Epoch: 6| Step: 12
Training loss: 2.4698407649993896
Validation loss: 2.0534205436706543

Epoch: 6| Step: 13
Training loss: 2.2217869758605957
Validation loss: 2.029958426952362

Epoch: 118| Step: 0
Training loss: 1.5919108390808105
Validation loss: 2.031423648198446

Epoch: 6| Step: 1
Training loss: 2.4739274978637695
Validation loss: 2.0497393012046814

Epoch: 6| Step: 2
Training loss: 2.439476251602173
Validation loss: 2.0400293270746865

Epoch: 6| Step: 3
Training loss: 1.7614922523498535
Validation loss: 2.0500949025154114

Epoch: 6| Step: 4
Training loss: 2.354494094848633
Validation loss: 2.0459322929382324

Epoch: 6| Step: 5
Training loss: 1.4642109870910645
Validation loss: 2.0455572605133057

Epoch: 6| Step: 6
Training loss: 1.9669013023376465
Validation loss: 2.03743968407313

Epoch: 6| Step: 7
Training loss: 2.373931407928467
Validation loss: 2.039435029029846

Epoch: 6| Step: 8
Training loss: 1.910423755645752
Validation loss: 2.0457507570584617

Epoch: 6| Step: 9
Training loss: 2.145871162414551
Validation loss: 2.039861778418223

Epoch: 6| Step: 10
Training loss: 2.1167657375335693
Validation loss: 2.0389039516448975

Epoch: 6| Step: 11
Training loss: 2.038573980331421
Validation loss: 2.0477302074432373

Epoch: 6| Step: 12
Training loss: 2.1254537105560303
Validation loss: 2.0484511852264404

Epoch: 6| Step: 13
Training loss: 2.2141342163085938
Validation loss: 2.0350176294644675

Epoch: 119| Step: 0
Training loss: 2.3914382457733154
Validation loss: 2.0504541794459024

Epoch: 6| Step: 1
Training loss: 1.6809359788894653
Validation loss: 2.040792763233185

Epoch: 6| Step: 2
Training loss: 1.9577524662017822
Validation loss: 2.0528102914492288

Epoch: 6| Step: 3
Training loss: 2.0890607833862305
Validation loss: 2.0506805777549744

Epoch: 6| Step: 4
Training loss: 2.025033712387085
Validation loss: 2.04078201452891

Epoch: 6| Step: 5
Training loss: 1.9646470546722412
Validation loss: 2.044968565305074

Epoch: 6| Step: 6
Training loss: 1.914475440979004
Validation loss: 2.0604248444239297

Epoch: 6| Step: 7
Training loss: 2.512812852859497
Validation loss: 2.048597494761149

Epoch: 6| Step: 8
Training loss: 2.0884103775024414
Validation loss: 2.0496452252070108

Epoch: 6| Step: 9
Training loss: 2.0734825134277344
Validation loss: 2.0545860528945923

Epoch: 6| Step: 10
Training loss: 1.510486125946045
Validation loss: 2.0439762274424234

Epoch: 6| Step: 11
Training loss: 2.476940393447876
Validation loss: 2.0496157010396323

Epoch: 6| Step: 12
Training loss: 1.9699795246124268
Validation loss: 2.0645901560783386

Epoch: 6| Step: 13
Training loss: 2.031414031982422
Validation loss: 2.0548997124036155

Epoch: 120| Step: 0
Training loss: 1.6053030490875244
Validation loss: 2.070395847161611

Epoch: 6| Step: 1
Training loss: 2.44754695892334
Validation loss: 2.070113718509674

Epoch: 6| Step: 2
Training loss: 2.553061008453369
Validation loss: 2.0681813955307007

Epoch: 6| Step: 3
Training loss: 1.7706502676010132
Validation loss: 2.072061916192373

Epoch: 6| Step: 4
Training loss: 2.3999338150024414
Validation loss: 2.0771239201227822

Epoch: 6| Step: 5
Training loss: 1.6786091327667236
Validation loss: 2.0699788133303323

Epoch: 6| Step: 6
Training loss: 2.2332518100738525
Validation loss: 2.0787253975868225

Epoch: 6| Step: 7
Training loss: 2.0206241607666016
Validation loss: 2.0811549623807273

Epoch: 6| Step: 8
Training loss: 1.8812177181243896
Validation loss: 2.086312254269918

Epoch: 6| Step: 9
Training loss: 1.645748257637024
Validation loss: 2.073444128036499

Epoch: 6| Step: 10
Training loss: 2.2960119247436523
Validation loss: 2.0778908332188926

Epoch: 6| Step: 11
Training loss: 2.0401358604431152
Validation loss: 2.089238782723745

Epoch: 6| Step: 12
Training loss: 1.7205090522766113
Validation loss: 2.084949791431427

Epoch: 6| Step: 13
Training loss: 2.139387607574463
Validation loss: 2.074586788813273

Epoch: 121| Step: 0
Training loss: 2.056957960128784
Validation loss: 2.0758622884750366

Epoch: 6| Step: 1
Training loss: 1.7567110061645508
Validation loss: 2.0705148180325827

Epoch: 6| Step: 2
Training loss: 1.5953209400177002
Validation loss: 2.072676499684652

Epoch: 6| Step: 3
Training loss: 2.2764480113983154
Validation loss: 2.072376847267151

Epoch: 6| Step: 4
Training loss: 2.1220719814300537
Validation loss: 2.0855488975842795

Epoch: 6| Step: 5
Training loss: 1.924253225326538
Validation loss: 2.08250500758489

Epoch: 6| Step: 6
Training loss: 2.0501065254211426
Validation loss: 2.0942898790041604

Epoch: 6| Step: 7
Training loss: 2.1691222190856934
Validation loss: 2.0837830305099487

Epoch: 6| Step: 8
Training loss: 2.009371757507324
Validation loss: 2.0739587346712747

Epoch: 6| Step: 9
Training loss: 2.460171699523926
Validation loss: 2.0790703296661377

Epoch: 6| Step: 10
Training loss: 2.316772937774658
Validation loss: 2.076548973719279

Epoch: 6| Step: 11
Training loss: 1.9255447387695312
Validation loss: 2.0666930079460144

Epoch: 6| Step: 12
Training loss: 1.8690769672393799
Validation loss: 2.0721931060155234

Epoch: 6| Step: 13
Training loss: 2.0791592597961426
Validation loss: 2.0647957722345986

Epoch: 122| Step: 0
Training loss: 2.202746868133545
Validation loss: 2.0584733287493386

Epoch: 6| Step: 1
Training loss: 1.869753122329712
Validation loss: 2.057487984498342

Epoch: 6| Step: 2
Training loss: 2.059196949005127
Validation loss: 2.06629087527593

Epoch: 6| Step: 3
Training loss: 2.431673765182495
Validation loss: 2.072949687639872

Epoch: 6| Step: 4
Training loss: 1.6903295516967773
Validation loss: 2.0741596023241677

Epoch: 6| Step: 5
Training loss: 2.081137180328369
Validation loss: 2.0660731395085654

Epoch: 6| Step: 6
Training loss: 2.0307300090789795
Validation loss: 2.07939221461614

Epoch: 6| Step: 7
Training loss: 2.395740509033203
Validation loss: 2.0675545732180276

Epoch: 6| Step: 8
Training loss: 1.675280213356018
Validation loss: 2.0841225385665894

Epoch: 6| Step: 9
Training loss: 2.8143765926361084
Validation loss: 2.070464332898458

Epoch: 6| Step: 10
Training loss: 2.2642922401428223
Validation loss: 2.059451142946879

Epoch: 6| Step: 11
Training loss: 1.5357155799865723
Validation loss: 2.0655556519826255

Epoch: 6| Step: 12
Training loss: 1.589487910270691
Validation loss: 2.0619731545448303

Epoch: 6| Step: 13
Training loss: 1.8452831506729126
Validation loss: 2.07583757241567

Epoch: 123| Step: 0
Training loss: 2.7916030883789062
Validation loss: 2.070046583811442

Epoch: 6| Step: 1
Training loss: 1.9543015956878662
Validation loss: 2.064820170402527

Epoch: 6| Step: 2
Training loss: 2.181720495223999
Validation loss: 2.063830097516378

Epoch: 6| Step: 3
Training loss: 2.1282145977020264
Validation loss: 2.0774724086125693

Epoch: 6| Step: 4
Training loss: 2.1216156482696533
Validation loss: 2.0778403679529824

Epoch: 6| Step: 5
Training loss: 2.4040842056274414
Validation loss: 2.066777984301249

Epoch: 6| Step: 6
Training loss: 2.037628173828125
Validation loss: 2.05965922276179

Epoch: 6| Step: 7
Training loss: 2.214186191558838
Validation loss: 2.0626763502756753

Epoch: 6| Step: 8
Training loss: 1.6072535514831543
Validation loss: 2.068203608194987

Epoch: 6| Step: 9
Training loss: 1.8583743572235107
Validation loss: 2.0558164517084756

Epoch: 6| Step: 10
Training loss: 1.7088470458984375
Validation loss: 2.0646541515986123

Epoch: 6| Step: 11
Training loss: 1.8216383457183838
Validation loss: 2.066545248031616

Epoch: 6| Step: 12
Training loss: 1.5182075500488281
Validation loss: 2.075569967428843

Epoch: 6| Step: 13
Training loss: 2.1686854362487793
Validation loss: 2.066778302192688

Epoch: 124| Step: 0
Training loss: 1.880637526512146
Validation loss: 2.0662249326705933

Epoch: 6| Step: 1
Training loss: 2.122541904449463
Validation loss: 2.0672414104143777

Epoch: 6| Step: 2
Training loss: 2.08817458152771
Validation loss: 2.0733071764310202

Epoch: 6| Step: 3
Training loss: 2.005882740020752
Validation loss: 2.054433902104696

Epoch: 6| Step: 4
Training loss: 1.57741117477417
Validation loss: 2.0634623169898987

Epoch: 6| Step: 5
Training loss: 2.322340488433838
Validation loss: 2.0589742263158164

Epoch: 6| Step: 6
Training loss: 1.777578353881836
Validation loss: 2.062989870707194

Epoch: 6| Step: 7
Training loss: 2.778975486755371
Validation loss: 2.058652718861898

Epoch: 6| Step: 8
Training loss: 1.2675411701202393
Validation loss: 2.046388804912567

Epoch: 6| Step: 9
Training loss: 2.670907974243164
Validation loss: 2.0545979142189026

Epoch: 6| Step: 10
Training loss: 1.7887115478515625
Validation loss: 2.0384119153022766

Epoch: 6| Step: 11
Training loss: 2.0202524662017822
Validation loss: 2.043534060319265

Epoch: 6| Step: 12
Training loss: 2.135317087173462
Validation loss: 2.0425503849983215

Epoch: 6| Step: 13
Training loss: 2.146827459335327
Validation loss: 2.0362120270729065

Epoch: 125| Step: 0
Training loss: 1.982323408126831
Validation loss: 2.0483542482058206

Epoch: 6| Step: 1
Training loss: 1.4312236309051514
Validation loss: 2.051481068134308

Epoch: 6| Step: 2
Training loss: 2.515000104904175
Validation loss: 2.0423911809921265

Epoch: 6| Step: 3
Training loss: 2.8649654388427734
Validation loss: 2.052542567253113

Epoch: 6| Step: 4
Training loss: 2.357307195663452
Validation loss: 2.050709327061971

Epoch: 6| Step: 5
Training loss: 2.231203079223633
Validation loss: 2.057802657286326

Epoch: 6| Step: 6
Training loss: 1.6602551937103271
Validation loss: 2.06103523572286

Epoch: 6| Step: 7
Training loss: 2.0009665489196777
Validation loss: 2.0704093178113303

Epoch: 6| Step: 8
Training loss: 1.736415982246399
Validation loss: 2.0798880060513816

Epoch: 6| Step: 9
Training loss: 2.1349990367889404
Validation loss: 2.070037384827932

Epoch: 6| Step: 10
Training loss: 2.102215528488159
Validation loss: 2.090208411216736

Epoch: 6| Step: 11
Training loss: 1.9852319955825806
Validation loss: 2.0821760098139444

Epoch: 6| Step: 12
Training loss: 1.6308976411819458
Validation loss: 2.080380400021871

Epoch: 6| Step: 13
Training loss: 1.8382776975631714
Validation loss: 2.064095417658488

Epoch: 126| Step: 0
Training loss: 1.2017152309417725
Validation loss: 2.076555093129476

Epoch: 6| Step: 1
Training loss: 2.375765323638916
Validation loss: 2.067908982435862

Epoch: 6| Step: 2
Training loss: 2.1842732429504395
Validation loss: 2.0658119320869446

Epoch: 6| Step: 3
Training loss: 1.9306409358978271
Validation loss: 2.0625187953313193

Epoch: 6| Step: 4
Training loss: 1.8111903667449951
Validation loss: 2.0744387904802957

Epoch: 6| Step: 5
Training loss: 1.9425767660140991
Validation loss: 2.066663165887197

Epoch: 6| Step: 6
Training loss: 2.4039008617401123
Validation loss: 2.0590413411458335

Epoch: 6| Step: 7
Training loss: 2.199552536010742
Validation loss: 2.0590229829152427

Epoch: 6| Step: 8
Training loss: 1.9093552827835083
Validation loss: 2.0574099024136863

Epoch: 6| Step: 9
Training loss: 2.4318184852600098
Validation loss: 2.062463382879893

Epoch: 6| Step: 10
Training loss: 2.20883846282959
Validation loss: 2.0668959617614746

Epoch: 6| Step: 11
Training loss: 2.3241395950317383
Validation loss: 2.0646679600079856

Epoch: 6| Step: 12
Training loss: 1.8644570112228394
Validation loss: 2.0643176436424255

Epoch: 6| Step: 13
Training loss: 1.590641736984253
Validation loss: 2.062973697980245

Epoch: 127| Step: 0
Training loss: 2.285914421081543
Validation loss: 2.0715777476628623

Epoch: 6| Step: 1
Training loss: 1.3792357444763184
Validation loss: 2.0658515294392905

Epoch: 6| Step: 2
Training loss: 2.108942985534668
Validation loss: 2.0814055601755777

Epoch: 6| Step: 3
Training loss: 1.785886526107788
Validation loss: 2.0894917050997415

Epoch: 6| Step: 4
Training loss: 1.77675199508667
Validation loss: 2.0811700026194253

Epoch: 6| Step: 5
Training loss: 2.51595401763916
Validation loss: 2.0873708526293435

Epoch: 6| Step: 6
Training loss: 2.3800463676452637
Validation loss: 2.0807164708773294

Epoch: 6| Step: 7
Training loss: 2.469874382019043
Validation loss: 2.089819093545278

Epoch: 6| Step: 8
Training loss: 1.8664671182632446
Validation loss: 2.080471396446228

Epoch: 6| Step: 9
Training loss: 2.258929967880249
Validation loss: 2.0732317368189492

Epoch: 6| Step: 10
Training loss: 1.9257978200912476
Validation loss: 2.0595496892929077

Epoch: 6| Step: 11
Training loss: 2.3149874210357666
Validation loss: 2.0514447887738547

Epoch: 6| Step: 12
Training loss: 2.0404417514801025
Validation loss: 2.057203233242035

Epoch: 6| Step: 13
Training loss: 1.356916904449463
Validation loss: 2.0560195446014404

Epoch: 128| Step: 0
Training loss: 2.100552558898926
Validation loss: 2.0618223945299783

Epoch: 6| Step: 1
Training loss: 2.0930514335632324
Validation loss: 2.0608559250831604

Epoch: 6| Step: 2
Training loss: 2.4461255073547363
Validation loss: 2.059974511464437

Epoch: 6| Step: 3
Training loss: 1.6747479438781738
Validation loss: 2.0593207279841104

Epoch: 6| Step: 4
Training loss: 1.9697681665420532
Validation loss: 2.0662707487742105

Epoch: 6| Step: 5
Training loss: 2.0085196495056152
Validation loss: 2.069733719031016

Epoch: 6| Step: 6
Training loss: 1.781943678855896
Validation loss: 2.0749325354894004

Epoch: 6| Step: 7
Training loss: 2.3190693855285645
Validation loss: 2.0752660433451333

Epoch: 6| Step: 8
Training loss: 1.8590480089187622
Validation loss: 2.0723221699396768

Epoch: 6| Step: 9
Training loss: 1.7556946277618408
Validation loss: 2.0727104544639587

Epoch: 6| Step: 10
Training loss: 2.398277759552002
Validation loss: 2.0728441079457602

Epoch: 6| Step: 11
Training loss: 2.0003366470336914
Validation loss: 2.0800490379333496

Epoch: 6| Step: 12
Training loss: 1.9813389778137207
Validation loss: 2.0675893823305764

Epoch: 6| Step: 13
Training loss: 2.195976734161377
Validation loss: 2.0721476078033447

Epoch: 129| Step: 0
Training loss: 2.3888988494873047
Validation loss: 2.058545410633087

Epoch: 6| Step: 1
Training loss: 2.5086283683776855
Validation loss: 2.0459904074668884

Epoch: 6| Step: 2
Training loss: 1.5489013195037842
Validation loss: 2.0424216787020364

Epoch: 6| Step: 3
Training loss: 2.3136725425720215
Validation loss: 2.047930955886841

Epoch: 6| Step: 4
Training loss: 1.8198871612548828
Validation loss: 2.0429296692212424

Epoch: 6| Step: 5
Training loss: 1.2811592817306519
Validation loss: 2.03762678305308

Epoch: 6| Step: 6
Training loss: 2.7443394660949707
Validation loss: 2.050197501977285

Epoch: 6| Step: 7
Training loss: 1.8935284614562988
Validation loss: 2.0482141772905984

Epoch: 6| Step: 8
Training loss: 0.9416225552558899
Validation loss: 2.044918735822042

Epoch: 6| Step: 9
Training loss: 2.1701579093933105
Validation loss: 2.034022629261017

Epoch: 6| Step: 10
Training loss: 2.152623176574707
Validation loss: 2.0407601793607077

Epoch: 6| Step: 11
Training loss: 2.4627327919006348
Validation loss: 2.04025536775589

Epoch: 6| Step: 12
Training loss: 2.057699680328369
Validation loss: 2.0450024207433066

Epoch: 6| Step: 13
Training loss: 2.2308833599090576
Validation loss: 2.0384811957677207

Epoch: 130| Step: 0
Training loss: 2.343444347381592
Validation loss: 2.0526132186253867

Epoch: 6| Step: 1
Training loss: 2.0984339714050293
Validation loss: 2.0613179405530295

Epoch: 6| Step: 2
Training loss: 2.7670321464538574
Validation loss: 2.0795469085375466

Epoch: 6| Step: 3
Training loss: 1.6881282329559326
Validation loss: 2.0897274017333984

Epoch: 6| Step: 4
Training loss: 2.3568108081817627
Validation loss: 2.093561887741089

Epoch: 6| Step: 5
Training loss: 2.213009834289551
Validation loss: 2.099022686481476

Epoch: 6| Step: 6
Training loss: 1.6453564167022705
Validation loss: 2.082378606001536

Epoch: 6| Step: 7
Training loss: 1.933137059211731
Validation loss: 2.0857507387797036

Epoch: 6| Step: 8
Training loss: 2.503416061401367
Validation loss: 2.0707161029179892

Epoch: 6| Step: 9
Training loss: 1.8632861375808716
Validation loss: 2.0653121868769326

Epoch: 6| Step: 10
Training loss: 2.3785171508789062
Validation loss: 2.0592209696769714

Epoch: 6| Step: 11
Training loss: 1.856019139289856
Validation loss: 2.048012932141622

Epoch: 6| Step: 12
Training loss: 1.6217396259307861
Validation loss: 2.046342372894287

Epoch: 6| Step: 13
Training loss: 1.5908089876174927
Validation loss: 2.05001433690389

Epoch: 131| Step: 0
Training loss: 1.6811397075653076
Validation loss: 2.0426676074663797

Epoch: 6| Step: 1
Training loss: 1.759916067123413
Validation loss: 2.0504933993021646

Epoch: 6| Step: 2
Training loss: 1.6783448457717896
Validation loss: 2.0488751331965127

Epoch: 6| Step: 3
Training loss: 1.6646883487701416
Validation loss: 2.0589245557785034

Epoch: 6| Step: 4
Training loss: 2.6036434173583984
Validation loss: 2.055344839890798

Epoch: 6| Step: 5
Training loss: 1.9763593673706055
Validation loss: 2.062340021133423

Epoch: 6| Step: 6
Training loss: 2.708324432373047
Validation loss: 2.0552599827448526

Epoch: 6| Step: 7
Training loss: 1.8785940408706665
Validation loss: 2.053002973397573

Epoch: 6| Step: 8
Training loss: 2.212228298187256
Validation loss: 2.0645763079325357

Epoch: 6| Step: 9
Training loss: 2.235245704650879
Validation loss: 2.048195699850718

Epoch: 6| Step: 10
Training loss: 2.0032927989959717
Validation loss: 2.0544959704081216

Epoch: 6| Step: 11
Training loss: 1.9057868719100952
Validation loss: 2.065718690554301

Epoch: 6| Step: 12
Training loss: 2.405147075653076
Validation loss: 2.0744585196177163

Epoch: 6| Step: 13
Training loss: 1.6206539869308472
Validation loss: 2.0673550963401794

Epoch: 132| Step: 0
Training loss: 2.537550449371338
Validation loss: 2.059961199760437

Epoch: 6| Step: 1
Training loss: 2.4308338165283203
Validation loss: 2.0634992122650146

Epoch: 6| Step: 2
Training loss: 1.80516517162323
Validation loss: 2.0689563949902854

Epoch: 6| Step: 3
Training loss: 1.4951634407043457
Validation loss: 2.055204232533773

Epoch: 6| Step: 4
Training loss: 1.6907920837402344
Validation loss: 2.056140184402466

Epoch: 6| Step: 5
Training loss: 1.7990407943725586
Validation loss: 2.0548155109087625

Epoch: 6| Step: 6
Training loss: 1.4084553718566895
Validation loss: 2.066818197568258

Epoch: 6| Step: 7
Training loss: 2.9185264110565186
Validation loss: 2.06142650047938

Epoch: 6| Step: 8
Training loss: 2.023672580718994
Validation loss: 2.0717670718828836

Epoch: 6| Step: 9
Training loss: 2.0592639446258545
Validation loss: 2.05832709868749

Epoch: 6| Step: 10
Training loss: 1.8529959917068481
Validation loss: 2.061197658379873

Epoch: 6| Step: 11
Training loss: 2.366420269012451
Validation loss: 2.0738943020502725

Epoch: 6| Step: 12
Training loss: 2.33280611038208
Validation loss: 2.0746559699376426

Epoch: 6| Step: 13
Training loss: 1.7072207927703857
Validation loss: 2.0782440106074014

Epoch: 133| Step: 0
Training loss: 1.801303505897522
Validation loss: 2.073071281115214

Epoch: 6| Step: 1
Training loss: 1.7887096405029297
Validation loss: 2.0814677476882935

Epoch: 6| Step: 2
Training loss: 1.5743234157562256
Validation loss: 2.086954951286316

Epoch: 6| Step: 3
Training loss: 1.8942991495132446
Validation loss: 2.0894707441329956

Epoch: 6| Step: 4
Training loss: 2.3088364601135254
Validation loss: 2.0871143341064453

Epoch: 6| Step: 5
Training loss: 1.9778282642364502
Validation loss: 2.0905300974845886

Epoch: 6| Step: 6
Training loss: 2.349872589111328
Validation loss: 2.083586355050405

Epoch: 6| Step: 7
Training loss: 1.8543893098831177
Validation loss: 2.083695371945699

Epoch: 6| Step: 8
Training loss: 2.0972838401794434
Validation loss: 2.064804255962372

Epoch: 6| Step: 9
Training loss: 2.1642322540283203
Validation loss: 2.0594270626703897

Epoch: 6| Step: 10
Training loss: 2.109736442565918
Validation loss: 2.06831693649292

Epoch: 6| Step: 11
Training loss: 2.449580192565918
Validation loss: 2.0600564082463584

Epoch: 6| Step: 12
Training loss: 1.9309163093566895
Validation loss: 2.0641382733980813

Epoch: 6| Step: 13
Training loss: 1.968501091003418
Validation loss: 2.071482519308726

Epoch: 134| Step: 0
Training loss: 1.4179850816726685
Validation loss: 2.0675866405169168

Epoch: 6| Step: 1
Training loss: 2.080737590789795
Validation loss: 2.0605894327163696

Epoch: 6| Step: 2
Training loss: 1.4238250255584717
Validation loss: 2.061985492706299

Epoch: 6| Step: 3
Training loss: 2.188843250274658
Validation loss: 2.06301740805308

Epoch: 6| Step: 4
Training loss: 1.9767087697982788
Validation loss: 2.06131382783254

Epoch: 6| Step: 5
Training loss: 1.616072177886963
Validation loss: 2.0651386976242065

Epoch: 6| Step: 6
Training loss: 2.5291075706481934
Validation loss: 2.0689723889033

Epoch: 6| Step: 7
Training loss: 2.6411778926849365
Validation loss: 2.078824281692505

Epoch: 6| Step: 8
Training loss: 1.786110520362854
Validation loss: 2.074800451596578

Epoch: 6| Step: 9
Training loss: 2.595557451248169
Validation loss: 2.071495691935221

Epoch: 6| Step: 10
Training loss: 1.7313313484191895
Validation loss: 2.0651756525039673

Epoch: 6| Step: 11
Training loss: 1.801430344581604
Validation loss: 2.069503386815389

Epoch: 6| Step: 12
Training loss: 2.0979151725769043
Validation loss: 2.069800774256388

Epoch: 6| Step: 13
Training loss: 2.1505908966064453
Validation loss: 2.0572702884674072

Epoch: 135| Step: 0
Training loss: 1.6598377227783203
Validation loss: 2.0603425900141397

Epoch: 6| Step: 1
Training loss: 1.7745046615600586
Validation loss: 2.0603328545888266

Epoch: 6| Step: 2
Training loss: 2.086956739425659
Validation loss: 2.0578466256459556

Epoch: 6| Step: 3
Training loss: 2.2637243270874023
Validation loss: 2.0616663694381714

Epoch: 6| Step: 4
Training loss: 1.0145784616470337
Validation loss: 2.057997246583303

Epoch: 6| Step: 5
Training loss: 2.2227697372436523
Validation loss: 2.066755990187327

Epoch: 6| Step: 6
Training loss: 2.047919511795044
Validation loss: 2.053830166657766

Epoch: 6| Step: 7
Training loss: 2.1367616653442383
Validation loss: 2.059230546156565

Epoch: 6| Step: 8
Training loss: 2.7345733642578125
Validation loss: 2.0683525005976358

Epoch: 6| Step: 9
Training loss: 2.3781137466430664
Validation loss: 2.0657386779785156

Epoch: 6| Step: 10
Training loss: 2.1995105743408203
Validation loss: 2.0703428188959756

Epoch: 6| Step: 11
Training loss: 1.8134723901748657
Validation loss: 2.0734747648239136

Epoch: 6| Step: 12
Training loss: 1.7490754127502441
Validation loss: 2.0806347926457724

Epoch: 6| Step: 13
Training loss: 1.8891143798828125
Validation loss: 2.0871161421140036

Epoch: 136| Step: 0
Training loss: 2.0503430366516113
Validation loss: 2.086710770924886

Epoch: 6| Step: 1
Training loss: 1.82367742061615
Validation loss: 2.075166424115499

Epoch: 6| Step: 2
Training loss: 1.9441615343093872
Validation loss: 2.093528230985006

Epoch: 6| Step: 3
Training loss: 2.4826924800872803
Validation loss: 2.080551048119863

Epoch: 6| Step: 4
Training loss: 2.866194725036621
Validation loss: 2.0848254362742105

Epoch: 6| Step: 5
Training loss: 1.4394515752792358
Validation loss: 2.0731544295946756

Epoch: 6| Step: 6
Training loss: 1.688605546951294
Validation loss: 2.0753563046455383

Epoch: 6| Step: 7
Training loss: 2.024566173553467
Validation loss: 2.08338995774587

Epoch: 6| Step: 8
Training loss: 2.3327102661132812
Validation loss: 2.070822536945343

Epoch: 6| Step: 9
Training loss: 1.0845379829406738
Validation loss: 2.0801801880200705

Epoch: 6| Step: 10
Training loss: 1.7657873630523682
Validation loss: 2.0755381981531777

Epoch: 6| Step: 11
Training loss: 2.247542381286621
Validation loss: 2.08860053618749

Epoch: 6| Step: 12
Training loss: 1.634363055229187
Validation loss: 2.0992603103319802

Epoch: 6| Step: 13
Training loss: 2.5858511924743652
Validation loss: 2.1009355386098227

Epoch: 137| Step: 0
Training loss: 2.033524513244629
Validation loss: 2.0971578558286033

Epoch: 6| Step: 1
Training loss: 1.8173152208328247
Validation loss: 2.090773562590281

Epoch: 6| Step: 2
Training loss: 1.7234939336776733
Validation loss: 2.09755007425944

Epoch: 6| Step: 3
Training loss: 2.0540530681610107
Validation loss: 2.090519150098165

Epoch: 6| Step: 4
Training loss: 1.4052133560180664
Validation loss: 2.0775778889656067

Epoch: 6| Step: 5
Training loss: 1.6307721138000488
Validation loss: 2.078066051006317

Epoch: 6| Step: 6
Training loss: 2.455211639404297
Validation loss: 2.084859768549601

Epoch: 6| Step: 7
Training loss: 2.5666589736938477
Validation loss: 2.080080429712931

Epoch: 6| Step: 8
Training loss: 2.500744342803955
Validation loss: 2.082537849744161

Epoch: 6| Step: 9
Training loss: 1.8046672344207764
Validation loss: 2.085496187210083

Epoch: 6| Step: 10
Training loss: 2.1398959159851074
Validation loss: 2.0912131667137146

Epoch: 6| Step: 11
Training loss: 2.1399807929992676
Validation loss: 2.090199053287506

Epoch: 6| Step: 12
Training loss: 1.9397892951965332
Validation loss: 2.0905305544535318

Epoch: 6| Step: 13
Training loss: 1.7402722835540771
Validation loss: 2.0873514215151467

Epoch: 138| Step: 0
Training loss: 2.0392866134643555
Validation loss: 2.084013342857361

Epoch: 6| Step: 1
Training loss: 1.9774911403656006
Validation loss: 2.0707819859186807

Epoch: 6| Step: 2
Training loss: 2.079862356185913
Validation loss: 2.064498782157898

Epoch: 6| Step: 3
Training loss: 1.9650744199752808
Validation loss: 2.058622737725576

Epoch: 6| Step: 4
Training loss: 2.1889190673828125
Validation loss: 2.0526904463768005

Epoch: 6| Step: 5
Training loss: 2.048555850982666
Validation loss: 2.0525935689608255

Epoch: 6| Step: 6
Training loss: 1.7501784563064575
Validation loss: 2.0524582664171853

Epoch: 6| Step: 7
Training loss: 1.9601342678070068
Validation loss: 2.04185152053833

Epoch: 6| Step: 8
Training loss: 1.7098331451416016
Validation loss: 2.040102779865265

Epoch: 6| Step: 9
Training loss: 1.8783289194107056
Validation loss: 2.0401434898376465

Epoch: 6| Step: 10
Training loss: 1.6143434047698975
Validation loss: 2.046281099319458

Epoch: 6| Step: 11
Training loss: 2.7320308685302734
Validation loss: 2.045134127140045

Epoch: 6| Step: 12
Training loss: 2.5503315925598145
Validation loss: 2.0360199014345803

Epoch: 6| Step: 13
Training loss: 2.0600011348724365
Validation loss: 2.044420917828878

Epoch: 139| Step: 0
Training loss: 2.227539300918579
Validation loss: 2.0583232839902244

Epoch: 6| Step: 1
Training loss: 1.8873125314712524
Validation loss: 2.057105541229248

Epoch: 6| Step: 2
Training loss: 2.502626419067383
Validation loss: 2.080094556013743

Epoch: 6| Step: 3
Training loss: 2.173943519592285
Validation loss: 2.0934457778930664

Epoch: 6| Step: 4
Training loss: 2.358440637588501
Validation loss: 2.0880268216133118

Epoch: 6| Step: 5
Training loss: 1.4609558582305908
Validation loss: 2.107472578684489

Epoch: 6| Step: 6
Training loss: 1.6739184856414795
Validation loss: 2.103580335776011

Epoch: 6| Step: 7
Training loss: 1.5515763759613037
Validation loss: 2.1017810304959617

Epoch: 6| Step: 8
Training loss: 1.8764468431472778
Validation loss: 2.0978440841039023

Epoch: 6| Step: 9
Training loss: 2.255164623260498
Validation loss: 2.082618455092112

Epoch: 6| Step: 10
Training loss: 2.2867591381073
Validation loss: 2.0777589678764343

Epoch: 6| Step: 11
Training loss: 2.0873947143554688
Validation loss: 2.0673304994901023

Epoch: 6| Step: 12
Training loss: 2.356208562850952
Validation loss: 2.056087334950765

Epoch: 6| Step: 13
Training loss: 1.6964430809020996
Validation loss: 2.0474722186724343

Epoch: 140| Step: 0
Training loss: 1.5232491493225098
Validation loss: 2.047341008981069

Epoch: 6| Step: 1
Training loss: 2.134598731994629
Validation loss: 2.047053317228953

Epoch: 6| Step: 2
Training loss: 2.1698224544525146
Validation loss: 2.041603922843933

Epoch: 6| Step: 3
Training loss: 2.109461545944214
Validation loss: 2.0519698659578958

Epoch: 6| Step: 4
Training loss: 1.8345746994018555
Validation loss: 2.052026391029358

Epoch: 6| Step: 5
Training loss: 2.2634735107421875
Validation loss: 2.0491503278414407

Epoch: 6| Step: 6
Training loss: 2.4283790588378906
Validation loss: 2.0513416528701782

Epoch: 6| Step: 7
Training loss: 1.9753494262695312
Validation loss: 2.0531017978986106

Epoch: 6| Step: 8
Training loss: 2.426203727722168
Validation loss: 2.052524288495382

Epoch: 6| Step: 9
Training loss: 2.153930187225342
Validation loss: 2.061250150203705

Epoch: 6| Step: 10
Training loss: 2.10364031791687
Validation loss: 2.0561466018358865

Epoch: 6| Step: 11
Training loss: 1.5351927280426025
Validation loss: 2.0567796428998313

Epoch: 6| Step: 12
Training loss: 2.149265766143799
Validation loss: 2.06498646736145

Epoch: 6| Step: 13
Training loss: 1.7378973960876465
Validation loss: 2.0572580893834433

Epoch: 141| Step: 0
Training loss: 1.3586530685424805
Validation loss: 2.0748289426167807

Epoch: 6| Step: 1
Training loss: 2.2422714233398438
Validation loss: 2.073743780454

Epoch: 6| Step: 2
Training loss: 2.262260913848877
Validation loss: 2.0859448512395224

Epoch: 6| Step: 3
Training loss: 1.9833104610443115
Validation loss: 2.089571019013723

Epoch: 6| Step: 4
Training loss: 1.7849745750427246
Validation loss: 2.085752010345459

Epoch: 6| Step: 5
Training loss: 1.705918550491333
Validation loss: 2.0759222308794656

Epoch: 6| Step: 6
Training loss: 2.2069170475006104
Validation loss: 2.0654319524765015

Epoch: 6| Step: 7
Training loss: 1.9837952852249146
Validation loss: 2.055015961329142

Epoch: 6| Step: 8
Training loss: 2.183955430984497
Validation loss: 2.0390820503234863

Epoch: 6| Step: 9
Training loss: 1.7652907371520996
Validation loss: 2.0593560139338174

Epoch: 6| Step: 10
Training loss: 2.297642707824707
Validation loss: 2.04733806848526

Epoch: 6| Step: 11
Training loss: 2.2269287109375
Validation loss: 2.062647898991903

Epoch: 6| Step: 12
Training loss: 2.060382127761841
Validation loss: 2.049650947252909

Epoch: 6| Step: 13
Training loss: 2.0061769485473633
Validation loss: 2.0476877689361572

Epoch: 142| Step: 0
Training loss: 2.329329252243042
Validation loss: 2.062246342500051

Epoch: 6| Step: 1
Training loss: 2.0941622257232666
Validation loss: 2.055366098880768

Epoch: 6| Step: 2
Training loss: 2.535618305206299
Validation loss: 2.073487877845764

Epoch: 6| Step: 3
Training loss: 1.7215337753295898
Validation loss: 2.0683310826619468

Epoch: 6| Step: 4
Training loss: 1.3643404245376587
Validation loss: 2.076037605603536

Epoch: 6| Step: 5
Training loss: 2.165694236755371
Validation loss: 2.0805654327074685

Epoch: 6| Step: 6
Training loss: 2.2081809043884277
Validation loss: 2.0831632216771445

Epoch: 6| Step: 7
Training loss: 2.0621531009674072
Validation loss: 2.134491721789042

Epoch: 6| Step: 8
Training loss: 2.303860902786255
Validation loss: 2.113745172818502

Epoch: 6| Step: 9
Training loss: 2.3118228912353516
Validation loss: 2.113113582134247

Epoch: 6| Step: 10
Training loss: 1.3769488334655762
Validation loss: 2.1096481879552207

Epoch: 6| Step: 11
Training loss: 2.798892021179199
Validation loss: 2.1163724859555564

Epoch: 6| Step: 12
Training loss: 1.4933042526245117
Validation loss: 2.1012236873308816

Epoch: 6| Step: 13
Training loss: 1.8116552829742432
Validation loss: 2.0929744044939675

Epoch: 143| Step: 0
Training loss: 2.5017051696777344
Validation loss: 2.079884688059489

Epoch: 6| Step: 1
Training loss: 1.779388189315796
Validation loss: 2.068605641523997

Epoch: 6| Step: 2
Training loss: 1.789307951927185
Validation loss: 2.0701151688893638

Epoch: 6| Step: 3
Training loss: 2.4380550384521484
Validation loss: 2.063605487346649

Epoch: 6| Step: 4
Training loss: 1.2989482879638672
Validation loss: 2.0700806776682534

Epoch: 6| Step: 5
Training loss: 1.8814433813095093
Validation loss: 2.0666208267211914

Epoch: 6| Step: 6
Training loss: 1.546305775642395
Validation loss: 2.0553831458091736

Epoch: 6| Step: 7
Training loss: 1.39762282371521
Validation loss: 2.061006247997284

Epoch: 6| Step: 8
Training loss: 2.2729568481445312
Validation loss: 2.0764130353927612

Epoch: 6| Step: 9
Training loss: 2.264531135559082
Validation loss: 2.0817494988441467

Epoch: 6| Step: 10
Training loss: 2.391127109527588
Validation loss: 2.0851908524831138

Epoch: 6| Step: 11
Training loss: 2.451103448867798
Validation loss: 2.0869257847468057

Epoch: 6| Step: 12
Training loss: 1.46293306350708
Validation loss: 2.098798930644989

Epoch: 6| Step: 13
Training loss: 2.9977216720581055
Validation loss: 2.1063418785730996

Epoch: 144| Step: 0
Training loss: 1.8430931568145752
Validation loss: 2.109661360581716

Epoch: 6| Step: 1
Training loss: 1.7608846426010132
Validation loss: 2.107789476712545

Epoch: 6| Step: 2
Training loss: 2.151853561401367
Validation loss: 2.1023329496383667

Epoch: 6| Step: 3
Training loss: 1.6851327419281006
Validation loss: 2.1069324215253196

Epoch: 6| Step: 4
Training loss: 2.5419228076934814
Validation loss: 2.1054219206174216

Epoch: 6| Step: 5
Training loss: 2.2830514907836914
Validation loss: 2.102134386698405

Epoch: 6| Step: 6
Training loss: 2.2202506065368652
Validation loss: 2.0957091450691223

Epoch: 6| Step: 7
Training loss: 2.1983094215393066
Validation loss: 2.079410672187805

Epoch: 6| Step: 8
Training loss: 2.6273269653320312
Validation loss: 2.0799936056137085

Epoch: 6| Step: 9
Training loss: 2.181018352508545
Validation loss: 2.065017263094584

Epoch: 6| Step: 10
Training loss: 2.0775744915008545
Validation loss: 2.0669050415356955

Epoch: 6| Step: 11
Training loss: 1.637049913406372
Validation loss: 2.0584057569503784

Epoch: 6| Step: 12
Training loss: 1.4465714693069458
Validation loss: 2.0583468675613403

Epoch: 6| Step: 13
Training loss: 1.6821635961532593
Validation loss: 2.049872616926829

Epoch: 145| Step: 0
Training loss: 1.5536932945251465
Validation loss: 2.051203807195028

Epoch: 6| Step: 1
Training loss: 1.9107877016067505
Validation loss: 2.061027944087982

Epoch: 6| Step: 2
Training loss: 1.7482633590698242
Validation loss: 2.0623552997907004

Epoch: 6| Step: 3
Training loss: 2.8011045455932617
Validation loss: 2.0680863857269287

Epoch: 6| Step: 4
Training loss: 1.7794139385223389
Validation loss: 2.0788167913754783

Epoch: 6| Step: 5
Training loss: 2.181997537612915
Validation loss: 2.0811831752459207

Epoch: 6| Step: 6
Training loss: 2.6202640533447266
Validation loss: 2.084693749745687

Epoch: 6| Step: 7
Training loss: 2.2357864379882812
Validation loss: 2.1006483236948648

Epoch: 6| Step: 8
Training loss: 1.8660985231399536
Validation loss: 2.1174477140108743

Epoch: 6| Step: 9
Training loss: 1.8846153020858765
Validation loss: 2.106369157632192

Epoch: 6| Step: 10
Training loss: 1.8480197191238403
Validation loss: 2.1021011074384055

Epoch: 6| Step: 11
Training loss: 2.054655075073242
Validation loss: 2.0952606797218323

Epoch: 6| Step: 12
Training loss: 1.8983948230743408
Validation loss: 2.0938257773717246

Epoch: 6| Step: 13
Training loss: 1.8984065055847168
Validation loss: 2.08945498863856

Epoch: 146| Step: 0
Training loss: 2.1051201820373535
Validation loss: 2.094391644001007

Epoch: 6| Step: 1
Training loss: 2.366137981414795
Validation loss: 2.091384768486023

Epoch: 6| Step: 2
Training loss: 2.4370837211608887
Validation loss: 2.081290622552236

Epoch: 6| Step: 3
Training loss: 2.0800137519836426
Validation loss: 2.0760103662808738

Epoch: 6| Step: 4
Training loss: 1.7673797607421875
Validation loss: 2.0780088901519775

Epoch: 6| Step: 5
Training loss: 1.4316778182983398
Validation loss: 2.0694435040156045

Epoch: 6| Step: 6
Training loss: 2.469663143157959
Validation loss: 2.073267340660095

Epoch: 6| Step: 7
Training loss: 1.28023362159729
Validation loss: 2.0638487537701926

Epoch: 6| Step: 8
Training loss: 2.3375585079193115
Validation loss: 2.0807674129803977

Epoch: 6| Step: 9
Training loss: 1.2997362613677979
Validation loss: 2.087091604868571

Epoch: 6| Step: 10
Training loss: 2.338474750518799
Validation loss: 2.0912115573883057

Epoch: 6| Step: 11
Training loss: 1.953594446182251
Validation loss: 2.0923593044281006

Epoch: 6| Step: 12
Training loss: 2.0979909896850586
Validation loss: 2.103634238243103

Epoch: 6| Step: 13
Training loss: 1.8714679479599
Validation loss: 2.1116575797398887

Epoch: 147| Step: 0
Training loss: 2.36635422706604
Validation loss: 2.131433606147766

Epoch: 6| Step: 1
Training loss: 1.7665261030197144
Validation loss: 2.1228230595588684

Epoch: 6| Step: 2
Training loss: 1.8551985025405884
Validation loss: 2.114524165789286

Epoch: 6| Step: 3
Training loss: 2.172640323638916
Validation loss: 2.0984923044840493

Epoch: 6| Step: 4
Training loss: 2.033247232437134
Validation loss: 2.092547575632731

Epoch: 6| Step: 5
Training loss: 2.9211034774780273
Validation loss: 2.0835452477137246

Epoch: 6| Step: 6
Training loss: 2.0682742595672607
Validation loss: 2.0777868032455444

Epoch: 6| Step: 7
Training loss: 1.6453667879104614
Validation loss: 2.083318074544271

Epoch: 6| Step: 8
Training loss: 1.7723886966705322
Validation loss: 2.079013725121816

Epoch: 6| Step: 9
Training loss: 1.6157151460647583
Validation loss: 2.085141400496165

Epoch: 6| Step: 10
Training loss: 1.974165439605713
Validation loss: 2.0897370179494223

Epoch: 6| Step: 11
Training loss: 2.275024652481079
Validation loss: 2.0825690428415933

Epoch: 6| Step: 12
Training loss: 2.0859992504119873
Validation loss: 2.085722784201304

Epoch: 6| Step: 13
Training loss: 1.6889127492904663
Validation loss: 2.0942811369895935

Epoch: 148| Step: 0
Training loss: 1.3922784328460693
Validation loss: 2.1116767724355063

Epoch: 6| Step: 1
Training loss: 2.399214267730713
Validation loss: 2.1079489390055337

Epoch: 6| Step: 2
Training loss: 2.3977913856506348
Validation loss: 2.10780276854833

Epoch: 6| Step: 3
Training loss: 2.3877921104431152
Validation loss: 2.1217395464579263

Epoch: 6| Step: 4
Training loss: 1.8909865617752075
Validation loss: 2.1306299368540444

Epoch: 6| Step: 5
Training loss: 2.075838565826416
Validation loss: 2.136516789595286

Epoch: 6| Step: 6
Training loss: 1.8856710195541382
Validation loss: 2.114784896373749

Epoch: 6| Step: 7
Training loss: 1.776402473449707
Validation loss: 2.097367525100708

Epoch: 6| Step: 8
Training loss: 1.833831548690796
Validation loss: 2.112281243006388

Epoch: 6| Step: 9
Training loss: 1.5368534326553345
Validation loss: 2.0954366525014243

Epoch: 6| Step: 10
Training loss: 1.8830678462982178
Validation loss: 2.0880302588144937

Epoch: 6| Step: 11
Training loss: 1.8615959882736206
Validation loss: 2.0894347627957663

Epoch: 6| Step: 12
Training loss: 2.770991802215576
Validation loss: 2.077346404393514

Epoch: 6| Step: 13
Training loss: 1.9963045120239258
Validation loss: 2.085247735182444

Epoch: 149| Step: 0
Training loss: 1.7540063858032227
Validation loss: 2.08348548412323

Epoch: 6| Step: 1
Training loss: 2.6764907836914062
Validation loss: 2.0712414185206094

Epoch: 6| Step: 2
Training loss: 1.9258062839508057
Validation loss: 2.078054885069529

Epoch: 6| Step: 3
Training loss: 1.8331224918365479
Validation loss: 2.0668610334396362

Epoch: 6| Step: 4
Training loss: 2.0383219718933105
Validation loss: 2.0817483266194663

Epoch: 6| Step: 5
Training loss: 2.2053020000457764
Validation loss: 2.0739482641220093

Epoch: 6| Step: 6
Training loss: 2.165830373764038
Validation loss: 2.071929136912028

Epoch: 6| Step: 7
Training loss: 1.4278929233551025
Validation loss: 2.0818973580996194

Epoch: 6| Step: 8
Training loss: 1.6942518949508667
Validation loss: 2.074003438154856

Epoch: 6| Step: 9
Training loss: 2.170799970626831
Validation loss: 2.0889158844947815

Epoch: 6| Step: 10
Training loss: 1.644207239151001
Validation loss: 2.0802747011184692

Epoch: 6| Step: 11
Training loss: 1.7442071437835693
Validation loss: 2.1091687083244324

Epoch: 6| Step: 12
Training loss: 2.4984707832336426
Validation loss: 2.08486674229304

Epoch: 6| Step: 13
Training loss: 2.288536310195923
Validation loss: 2.083889683087667

Epoch: 150| Step: 0
Training loss: 1.826882004737854
Validation loss: 2.0722563664118447

Epoch: 6| Step: 1
Training loss: 2.0763444900512695
Validation loss: 2.068366984526316

Epoch: 6| Step: 2
Training loss: 2.535742998123169
Validation loss: 2.05894927183787

Epoch: 6| Step: 3
Training loss: 1.8724873065948486
Validation loss: 2.061038057009379

Epoch: 6| Step: 4
Training loss: 1.854669451713562
Validation loss: 2.0408011078834534

Epoch: 6| Step: 5
Training loss: 1.4686847925186157
Validation loss: 2.0370824337005615

Epoch: 6| Step: 6
Training loss: 2.14143705368042
Validation loss: 2.0294480125109353

Epoch: 6| Step: 7
Training loss: 2.3652968406677246
Validation loss: 2.0363193353017173

Epoch: 6| Step: 8
Training loss: 1.9688677787780762
Validation loss: 2.0327817797660828

Epoch: 6| Step: 9
Training loss: 1.7740534543991089
Validation loss: 2.030738592147827

Epoch: 6| Step: 10
Training loss: 1.83665132522583
Validation loss: 2.0415970285733542

Epoch: 6| Step: 11
Training loss: 2.761430263519287
Validation loss: 2.046949287255605

Epoch: 6| Step: 12
Training loss: 2.071146011352539
Validation loss: 2.042408267656962

Epoch: 6| Step: 13
Training loss: 1.9109781980514526
Validation loss: 2.0486174821853638

Epoch: 151| Step: 0
Training loss: 1.1724010705947876
Validation loss: 2.0605884194374084

Epoch: 6| Step: 1
Training loss: 2.1040539741516113
Validation loss: 2.060377597808838

Epoch: 6| Step: 2
Training loss: 1.7963913679122925
Validation loss: 2.053182363510132

Epoch: 6| Step: 3
Training loss: 2.178081750869751
Validation loss: 2.0640563567479453

Epoch: 6| Step: 4
Training loss: 1.968388319015503
Validation loss: 2.068781793117523

Epoch: 6| Step: 5
Training loss: 1.7412748336791992
Validation loss: 2.0731034874916077

Epoch: 6| Step: 6
Training loss: 2.7657883167266846
Validation loss: 2.066503624121348

Epoch: 6| Step: 7
Training loss: 2.26509952545166
Validation loss: 2.0777162313461304

Epoch: 6| Step: 8
Training loss: 1.6166577339172363
Validation loss: 2.0585533380508423

Epoch: 6| Step: 9
Training loss: 2.4282712936401367
Validation loss: 2.0626368323961892

Epoch: 6| Step: 10
Training loss: 2.0796988010406494
Validation loss: 2.067487269639969

Epoch: 6| Step: 11
Training loss: 1.9135326147079468
Validation loss: 2.0513930916786194

Epoch: 6| Step: 12
Training loss: 2.363846778869629
Validation loss: 2.0669357975323996

Epoch: 6| Step: 13
Training loss: 1.4428011178970337
Validation loss: 2.069766183694204

Epoch: 152| Step: 0
Training loss: 2.2079079151153564
Validation loss: 2.064233342806498

Epoch: 6| Step: 1
Training loss: 2.2206382751464844
Validation loss: 2.0659895141919455

Epoch: 6| Step: 2
Training loss: 1.5812947750091553
Validation loss: 2.0666958689689636

Epoch: 6| Step: 3
Training loss: 1.966673493385315
Validation loss: 2.073334594567617

Epoch: 6| Step: 4
Training loss: 1.5806927680969238
Validation loss: 2.0708656907081604

Epoch: 6| Step: 5
Training loss: 2.229031801223755
Validation loss: 2.074638863404592

Epoch: 6| Step: 6
Training loss: 1.9419794082641602
Validation loss: 2.0641461412111917

Epoch: 6| Step: 7
Training loss: 2.4430127143859863
Validation loss: 2.060657580693563

Epoch: 6| Step: 8
Training loss: 2.2019619941711426
Validation loss: 2.067376991113027

Epoch: 6| Step: 9
Training loss: 1.9345592260360718
Validation loss: 2.077117602030436

Epoch: 6| Step: 10
Training loss: 2.1590218544006348
Validation loss: 2.0692937771479287

Epoch: 6| Step: 11
Training loss: 1.8835716247558594
Validation loss: 2.0788960655530295

Epoch: 6| Step: 12
Training loss: 1.2131364345550537
Validation loss: 2.0824544429779053

Epoch: 6| Step: 13
Training loss: 2.026230812072754
Validation loss: 2.096762160460154

Epoch: 153| Step: 0
Training loss: 1.6701712608337402
Validation loss: 2.0908258159955344

Epoch: 6| Step: 1
Training loss: 2.365307092666626
Validation loss: 2.0988633831342063

Epoch: 6| Step: 2
Training loss: 1.769372582435608
Validation loss: 2.0923995772997537

Epoch: 6| Step: 3
Training loss: 2.1011300086975098
Validation loss: 2.089134991168976

Epoch: 6| Step: 4
Training loss: 1.9205491542816162
Validation loss: 2.0904948314030967

Epoch: 6| Step: 5
Training loss: 1.49345862865448
Validation loss: 2.0793897906939187

Epoch: 6| Step: 6
Training loss: 2.154123306274414
Validation loss: 2.0695862968762717

Epoch: 6| Step: 7
Training loss: 2.0695109367370605
Validation loss: 2.0723560452461243

Epoch: 6| Step: 8
Training loss: 2.7126755714416504
Validation loss: 2.077053666114807

Epoch: 6| Step: 9
Training loss: 1.7469079494476318
Validation loss: 2.082047959168752

Epoch: 6| Step: 10
Training loss: 1.861088514328003
Validation loss: 2.087781091531118

Epoch: 6| Step: 11
Training loss: 1.880813717842102
Validation loss: 2.0972153544425964

Epoch: 6| Step: 12
Training loss: 1.6006643772125244
Validation loss: 2.0917874773343406

Epoch: 6| Step: 13
Training loss: 2.403813600540161
Validation loss: 2.098332166671753

Epoch: 154| Step: 0
Training loss: 2.1778223514556885
Validation loss: 2.0876996914545694

Epoch: 6| Step: 1
Training loss: 1.3500406742095947
Validation loss: 2.0853185256322226

Epoch: 6| Step: 2
Training loss: 1.3747901916503906
Validation loss: 2.0870898962020874

Epoch: 6| Step: 3
Training loss: 1.7662887573242188
Validation loss: 2.086763004461924

Epoch: 6| Step: 4
Training loss: 2.278369903564453
Validation loss: 2.0907021959622702

Epoch: 6| Step: 5
Training loss: 1.9791195392608643
Validation loss: 2.075944940249125

Epoch: 6| Step: 6
Training loss: 2.459054946899414
Validation loss: 2.0728897054990134

Epoch: 6| Step: 7
Training loss: 1.761186122894287
Validation loss: 2.0714714328447976

Epoch: 6| Step: 8
Training loss: 1.0919386148452759
Validation loss: 2.073439915974935

Epoch: 6| Step: 9
Training loss: 2.4189414978027344
Validation loss: 2.062263568242391

Epoch: 6| Step: 10
Training loss: 1.7316340208053589
Validation loss: 2.0678873658180237

Epoch: 6| Step: 11
Training loss: 2.4175655841827393
Validation loss: 2.0757128993670144

Epoch: 6| Step: 12
Training loss: 2.3876805305480957
Validation loss: 2.0772252082824707

Epoch: 6| Step: 13
Training loss: 2.3282477855682373
Validation loss: 2.0959409872690835

Epoch: 155| Step: 0
Training loss: 2.7006068229675293
Validation loss: 2.112411359945933

Epoch: 6| Step: 1
Training loss: 1.7639989852905273
Validation loss: 2.1116397778193154

Epoch: 6| Step: 2
Training loss: 2.0642337799072266
Validation loss: 2.0983306169509888

Epoch: 6| Step: 3
Training loss: 1.9182486534118652
Validation loss: 2.0952685276667276

Epoch: 6| Step: 4
Training loss: 1.8961173295974731
Validation loss: 2.095797836780548

Epoch: 6| Step: 5
Training loss: 1.73028564453125
Validation loss: 2.0856335361798606

Epoch: 6| Step: 6
Training loss: 1.8412818908691406
Validation loss: 2.077332297960917

Epoch: 6| Step: 7
Training loss: 2.2187881469726562
Validation loss: 2.0661479036013284

Epoch: 6| Step: 8
Training loss: 2.607456684112549
Validation loss: 2.0779730478922525

Epoch: 6| Step: 9
Training loss: 2.0635318756103516
Validation loss: 2.072690804799398

Epoch: 6| Step: 10
Training loss: 1.7294329404830933
Validation loss: 2.0713403622309365

Epoch: 6| Step: 11
Training loss: 1.6437708139419556
Validation loss: 2.0859938065210977

Epoch: 6| Step: 12
Training loss: 1.8490902185440063
Validation loss: 2.089527448018392

Epoch: 6| Step: 13
Training loss: 1.5277503728866577
Validation loss: 2.1058862805366516

Epoch: 156| Step: 0
Training loss: 2.224984645843506
Validation loss: 2.1089256604512534

Epoch: 6| Step: 1
Training loss: 1.5316126346588135
Validation loss: 2.113425135612488

Epoch: 6| Step: 2
Training loss: 2.1418495178222656
Validation loss: 2.1139798164367676

Epoch: 6| Step: 3
Training loss: 1.5883960723876953
Validation loss: 2.125812073548635

Epoch: 6| Step: 4
Training loss: 1.9771075248718262
Validation loss: 2.1223471562067666

Epoch: 6| Step: 5
Training loss: 2.859074115753174
Validation loss: 2.1043933629989624

Epoch: 6| Step: 6
Training loss: 2.059479236602783
Validation loss: 2.094478726387024

Epoch: 6| Step: 7
Training loss: 1.4658372402191162
Validation loss: 2.0775339206059775

Epoch: 6| Step: 8
Training loss: 2.034226179122925
Validation loss: 2.0709301829338074

Epoch: 6| Step: 9
Training loss: 1.7617216110229492
Validation loss: 2.072834312915802

Epoch: 6| Step: 10
Training loss: 2.3251655101776123
Validation loss: 2.065308431784312

Epoch: 6| Step: 11
Training loss: 2.0820069313049316
Validation loss: 2.054185390472412

Epoch: 6| Step: 12
Training loss: 1.9342894554138184
Validation loss: 2.0572336514790854

Epoch: 6| Step: 13
Training loss: 1.9434908628463745
Validation loss: 2.056295077006022

Epoch: 157| Step: 0
Training loss: 2.730829954147339
Validation loss: 2.0708748499552407

Epoch: 6| Step: 1
Training loss: 2.0092363357543945
Validation loss: 2.0691062211990356

Epoch: 6| Step: 2
Training loss: 2.0513992309570312
Validation loss: 2.0680494705835977

Epoch: 6| Step: 3
Training loss: 2.0621018409729004
Validation loss: 2.0615690549214682

Epoch: 6| Step: 4
Training loss: 1.8521431684494019
Validation loss: 2.0673060417175293

Epoch: 6| Step: 5
Training loss: 2.0280442237854004
Validation loss: 2.06112547715505

Epoch: 6| Step: 6
Training loss: 2.398951530456543
Validation loss: 2.0685757398605347

Epoch: 6| Step: 7
Training loss: 2.343488931655884
Validation loss: 2.0673634012540183

Epoch: 6| Step: 8
Training loss: 1.3923349380493164
Validation loss: 2.0702587167421975

Epoch: 6| Step: 9
Training loss: 1.9499200582504272
Validation loss: 2.06688658396403

Epoch: 6| Step: 10
Training loss: 1.6667051315307617
Validation loss: 2.0709028840065002

Epoch: 6| Step: 11
Training loss: 1.5842537879943848
Validation loss: 2.0970351696014404

Epoch: 6| Step: 12
Training loss: 1.9518882036209106
Validation loss: 2.1085607210795083

Epoch: 6| Step: 13
Training loss: 1.6106630563735962
Validation loss: 2.1110650300979614

Epoch: 158| Step: 0
Training loss: 1.1861318349838257
Validation loss: 2.1265412171681723

Epoch: 6| Step: 1
Training loss: 1.773702621459961
Validation loss: 2.1266338427861533

Epoch: 6| Step: 2
Training loss: 1.6837608814239502
Validation loss: 2.124176303545634

Epoch: 6| Step: 3
Training loss: 1.6339788436889648
Validation loss: 2.122717241446177

Epoch: 6| Step: 4
Training loss: 2.5020315647125244
Validation loss: 2.119771162668864

Epoch: 6| Step: 5
Training loss: 2.053119421005249
Validation loss: 2.1193431417147317

Epoch: 6| Step: 6
Training loss: 2.7583701610565186
Validation loss: 2.1179433465003967

Epoch: 6| Step: 7
Training loss: 1.9627196788787842
Validation loss: 2.1068100134531655

Epoch: 6| Step: 8
Training loss: 1.7685675621032715
Validation loss: 2.1028892596562705

Epoch: 6| Step: 9
Training loss: 2.6473388671875
Validation loss: 2.093406001726786

Epoch: 6| Step: 10
Training loss: 1.8299477100372314
Validation loss: 2.090804477532705

Epoch: 6| Step: 11
Training loss: 2.0895986557006836
Validation loss: 2.0908340215682983

Epoch: 6| Step: 12
Training loss: 1.714625597000122
Validation loss: 2.0899184544881186

Epoch: 6| Step: 13
Training loss: 2.0128026008605957
Validation loss: 2.07661505540212

Epoch: 159| Step: 0
Training loss: 1.8947067260742188
Validation loss: 2.0714995861053467

Epoch: 6| Step: 1
Training loss: 1.9404187202453613
Validation loss: 2.0732919772466025

Epoch: 6| Step: 2
Training loss: 2.529520034790039
Validation loss: 2.0693389972050986

Epoch: 6| Step: 3
Training loss: 1.9732552766799927
Validation loss: 2.0799041191736856

Epoch: 6| Step: 4
Training loss: 2.7417409420013428
Validation loss: 2.079102615515391

Epoch: 6| Step: 5
Training loss: 1.6244961023330688
Validation loss: 2.087393343448639

Epoch: 6| Step: 6
Training loss: 2.0718789100646973
Validation loss: 2.092401305834452

Epoch: 6| Step: 7
Training loss: 1.862122893333435
Validation loss: 2.0988974571228027

Epoch: 6| Step: 8
Training loss: 1.4412879943847656
Validation loss: 2.0917285680770874

Epoch: 6| Step: 9
Training loss: 2.3771462440490723
Validation loss: 2.098107020060221

Epoch: 6| Step: 10
Training loss: 1.6583616733551025
Validation loss: 2.096329649289449

Epoch: 6| Step: 11
Training loss: 1.8716188669204712
Validation loss: 2.10369865099589

Epoch: 6| Step: 12
Training loss: 1.8976447582244873
Validation loss: 2.1117629011472068

Epoch: 6| Step: 13
Training loss: 1.8266894817352295
Validation loss: 2.1160463293393454

Epoch: 160| Step: 0
Training loss: 2.440021514892578
Validation loss: 2.102753301461538

Epoch: 6| Step: 1
Training loss: 2.247678279876709
Validation loss: 2.119189441204071

Epoch: 6| Step: 2
Training loss: 1.6416747570037842
Validation loss: 2.1123690803845725

Epoch: 6| Step: 3
Training loss: 1.8950295448303223
Validation loss: 2.119697550932566

Epoch: 6| Step: 4
Training loss: 2.109440803527832
Validation loss: 2.1094146768252053

Epoch: 6| Step: 5
Training loss: 1.9098714590072632
Validation loss: 2.114303628603617

Epoch: 6| Step: 6
Training loss: 1.8669785261154175
Validation loss: 2.098384459813436

Epoch: 6| Step: 7
Training loss: 2.083387851715088
Validation loss: 2.095778206984202

Epoch: 6| Step: 8
Training loss: 1.5571244955062866
Validation loss: 2.1119335095087686

Epoch: 6| Step: 9
Training loss: 1.438248634338379
Validation loss: 2.1034494241078696

Epoch: 6| Step: 10
Training loss: 2.017698287963867
Validation loss: 2.1051765282948813

Epoch: 6| Step: 11
Training loss: 2.222820520401001
Validation loss: 2.0883833169937134

Epoch: 6| Step: 12
Training loss: 1.783504605293274
Validation loss: 2.114153186480204

Epoch: 6| Step: 13
Training loss: 2.326343536376953
Validation loss: 2.1121654311815896

Epoch: 161| Step: 0
Training loss: 2.038130283355713
Validation loss: 2.1235559980074563

Epoch: 6| Step: 1
Training loss: 1.734032392501831
Validation loss: 2.115712026755015

Epoch: 6| Step: 2
Training loss: 2.0909976959228516
Validation loss: 2.114948034286499

Epoch: 6| Step: 3
Training loss: 2.9203431606292725
Validation loss: 2.1217636664708457

Epoch: 6| Step: 4
Training loss: 1.7477424144744873
Validation loss: 2.1339587966601052

Epoch: 6| Step: 5
Training loss: 1.6603221893310547
Validation loss: 2.1277403632799783

Epoch: 6| Step: 6
Training loss: 1.9769432544708252
Validation loss: 2.135576585928599

Epoch: 6| Step: 7
Training loss: 1.8846547603607178
Validation loss: 2.1344099044799805

Epoch: 6| Step: 8
Training loss: 2.126006603240967
Validation loss: 2.145190397898356

Epoch: 6| Step: 9
Training loss: 2.0616869926452637
Validation loss: 2.1376509070396423

Epoch: 6| Step: 10
Training loss: 1.68509840965271
Validation loss: 2.1338204542795816

Epoch: 6| Step: 11
Training loss: 1.693100929260254
Validation loss: 2.1360735297203064

Epoch: 6| Step: 12
Training loss: 2.0465188026428223
Validation loss: 2.097588042418162

Epoch: 6| Step: 13
Training loss: 1.6503769159317017
Validation loss: 2.085643450419108

Epoch: 162| Step: 0
Training loss: 2.0450611114501953
Validation loss: 2.0792124470074973

Epoch: 6| Step: 1
Training loss: 2.3138320446014404
Validation loss: 2.080132246017456

Epoch: 6| Step: 2
Training loss: 1.928851842880249
Validation loss: 2.07787557442983

Epoch: 6| Step: 3
Training loss: 2.03857159614563
Validation loss: 2.076695442199707

Epoch: 6| Step: 4
Training loss: 1.7338043451309204
Validation loss: 2.0656492908795676

Epoch: 6| Step: 5
Training loss: 1.7557662725448608
Validation loss: 2.078571836153666

Epoch: 6| Step: 6
Training loss: 1.8296531438827515
Validation loss: 2.0737740198771157

Epoch: 6| Step: 7
Training loss: 1.946999430656433
Validation loss: 2.0644273161888123

Epoch: 6| Step: 8
Training loss: 2.134403705596924
Validation loss: 2.0868711471557617

Epoch: 6| Step: 9
Training loss: 2.295076847076416
Validation loss: 2.1072465578715005

Epoch: 6| Step: 10
Training loss: 1.2468643188476562
Validation loss: 2.121275007724762

Epoch: 6| Step: 11
Training loss: 2.6559629440307617
Validation loss: 2.1062087019284568

Epoch: 6| Step: 12
Training loss: 1.9508798122406006
Validation loss: 2.1077612241109214

Epoch: 6| Step: 13
Training loss: 1.9596203565597534
Validation loss: 2.103270490964254

Epoch: 163| Step: 0
Training loss: 2.0297741889953613
Validation loss: 2.1024865905443826

Epoch: 6| Step: 1
Training loss: 1.8152292966842651
Validation loss: 2.10346253712972

Epoch: 6| Step: 2
Training loss: 2.475649356842041
Validation loss: 2.0863008896509805

Epoch: 6| Step: 3
Training loss: 2.161489725112915
Validation loss: 2.0730676651000977

Epoch: 6| Step: 4
Training loss: 2.220839262008667
Validation loss: 2.0783344507217407

Epoch: 6| Step: 5
Training loss: 2.163773775100708
Validation loss: 2.065449357032776

Epoch: 6| Step: 6
Training loss: 1.8593335151672363
Validation loss: 2.069405436515808

Epoch: 6| Step: 7
Training loss: 1.51063871383667
Validation loss: 2.056390404701233

Epoch: 6| Step: 8
Training loss: 2.1625266075134277
Validation loss: 2.070366541544596

Epoch: 6| Step: 9
Training loss: 1.6493606567382812
Validation loss: 2.079514225323995

Epoch: 6| Step: 10
Training loss: 1.4525275230407715
Validation loss: 2.069690386454264

Epoch: 6| Step: 11
Training loss: 2.3477213382720947
Validation loss: 2.0702876845995584

Epoch: 6| Step: 12
Training loss: 2.260524272918701
Validation loss: 2.0899014870325723

Epoch: 6| Step: 13
Training loss: 1.7371710538864136
Validation loss: 2.1035390297571817

Epoch: 164| Step: 0
Training loss: 1.90700101852417
Validation loss: 2.117013096809387

Epoch: 6| Step: 1
Training loss: 1.2031766176223755
Validation loss: 2.1325469414393106

Epoch: 6| Step: 2
Training loss: 2.567563772201538
Validation loss: 2.1293784181276956

Epoch: 6| Step: 3
Training loss: 2.260777235031128
Validation loss: 2.144740800062815

Epoch: 6| Step: 4
Training loss: 1.409590244293213
Validation loss: 2.1354245940844216

Epoch: 6| Step: 5
Training loss: 2.2274043560028076
Validation loss: 2.126867135365804

Epoch: 6| Step: 6
Training loss: 2.099888563156128
Validation loss: 2.1276762882868447

Epoch: 6| Step: 7
Training loss: 1.7280287742614746
Validation loss: 2.1251057982444763

Epoch: 6| Step: 8
Training loss: 2.0621068477630615
Validation loss: 2.113813797632853

Epoch: 6| Step: 9
Training loss: 1.981523036956787
Validation loss: 2.1009292602539062

Epoch: 6| Step: 10
Training loss: 1.8334107398986816
Validation loss: 2.101926624774933

Epoch: 6| Step: 11
Training loss: 1.9726040363311768
Validation loss: 2.0959271987279258

Epoch: 6| Step: 12
Training loss: 1.9513587951660156
Validation loss: 2.1016904711723328

Epoch: 6| Step: 13
Training loss: 2.151810646057129
Validation loss: 2.0908060868581138

Epoch: 165| Step: 0
Training loss: 2.3957369327545166
Validation loss: 2.0985589822133384

Epoch: 6| Step: 1
Training loss: 1.9599289894104004
Validation loss: 2.1058651208877563

Epoch: 6| Step: 2
Training loss: 1.6493659019470215
Validation loss: 2.10956742366155

Epoch: 6| Step: 3
Training loss: 1.8947111368179321
Validation loss: 2.102986693382263

Epoch: 6| Step: 4
Training loss: 2.0031962394714355
Validation loss: 2.114479939142863

Epoch: 6| Step: 5
Training loss: 1.6796036958694458
Validation loss: 2.114350438117981

Epoch: 6| Step: 6
Training loss: 1.8649578094482422
Validation loss: 2.116142531236013

Epoch: 6| Step: 7
Training loss: 2.2335503101348877
Validation loss: 2.1138590772946677

Epoch: 6| Step: 8
Training loss: 1.7789294719696045
Validation loss: 2.122326930363973

Epoch: 6| Step: 9
Training loss: 1.8936948776245117
Validation loss: 2.133921980857849

Epoch: 6| Step: 10
Training loss: 1.5088152885437012
Validation loss: 2.148678501447042

Epoch: 6| Step: 11
Training loss: 2.4437789916992188
Validation loss: 2.1375346581141152

Epoch: 6| Step: 12
Training loss: 1.6848608255386353
Validation loss: 2.142646392186483

Epoch: 6| Step: 13
Training loss: 2.11806058883667
Validation loss: 2.1561934550603232

Epoch: 166| Step: 0
Training loss: 1.8553125858306885
Validation loss: 2.146990696589152

Epoch: 6| Step: 1
Training loss: 1.759497880935669
Validation loss: 2.132542053858439

Epoch: 6| Step: 2
Training loss: 2.153756618499756
Validation loss: 2.139903744061788

Epoch: 6| Step: 3
Training loss: 1.8578413724899292
Validation loss: 2.1299465696016946

Epoch: 6| Step: 4
Training loss: 2.2521753311157227
Validation loss: 2.1125645637512207

Epoch: 6| Step: 5
Training loss: 1.931229829788208
Validation loss: 2.104406774044037

Epoch: 6| Step: 6
Training loss: 1.4127649068832397
Validation loss: 2.1107323368390403

Epoch: 6| Step: 7
Training loss: 1.8591864109039307
Validation loss: 2.1022563378016152

Epoch: 6| Step: 8
Training loss: 1.775341510772705
Validation loss: 2.101689656575521

Epoch: 6| Step: 9
Training loss: 1.2109758853912354
Validation loss: 2.0980810721715293

Epoch: 6| Step: 10
Training loss: 2.0746352672576904
Validation loss: 2.093107024828593

Epoch: 6| Step: 11
Training loss: 2.0151326656341553
Validation loss: 2.0928325057029724

Epoch: 6| Step: 12
Training loss: 2.1752431392669678
Validation loss: 2.095732092857361

Epoch: 6| Step: 13
Training loss: 2.686368465423584
Validation loss: 2.0877845287323

Epoch: 167| Step: 0
Training loss: 1.9848147630691528
Validation loss: 2.091889441013336

Epoch: 6| Step: 1
Training loss: 2.3711066246032715
Validation loss: 2.0888595382372537

Epoch: 6| Step: 2
Training loss: 2.2193450927734375
Validation loss: 2.087080657482147

Epoch: 6| Step: 3
Training loss: 2.2782983779907227
Validation loss: 2.1013227899869285

Epoch: 6| Step: 4
Training loss: 1.3890200853347778
Validation loss: 2.096669832865397

Epoch: 6| Step: 5
Training loss: 1.6218185424804688
Validation loss: 2.1071725885073342

Epoch: 6| Step: 6
Training loss: 1.6236155033111572
Validation loss: 2.115912437438965

Epoch: 6| Step: 7
Training loss: 2.240939140319824
Validation loss: 2.117482821146647

Epoch: 6| Step: 8
Training loss: 2.0473685264587402
Validation loss: 2.139749586582184

Epoch: 6| Step: 9
Training loss: 2.1218369007110596
Validation loss: 2.1391096711158752

Epoch: 6| Step: 10
Training loss: 2.546957015991211
Validation loss: 2.1484738985697427

Epoch: 6| Step: 11
Training loss: 2.1342716217041016
Validation loss: 2.130276918411255

Epoch: 6| Step: 12
Training loss: 1.7086358070373535
Validation loss: 2.121753672758738

Epoch: 6| Step: 13
Training loss: 1.3030251264572144
Validation loss: 2.1266547044118247

Epoch: 168| Step: 0
Training loss: 1.9852237701416016
Validation loss: 2.122804284095764

Epoch: 6| Step: 1
Training loss: 2.1115806102752686
Validation loss: 2.112425764401754

Epoch: 6| Step: 2
Training loss: 1.871027946472168
Validation loss: 2.09616490205129

Epoch: 6| Step: 3
Training loss: 1.7366464138031006
Validation loss: 2.0936798254648843

Epoch: 6| Step: 4
Training loss: 2.580681324005127
Validation loss: 2.0942468444506326

Epoch: 6| Step: 5
Training loss: 1.5866427421569824
Validation loss: 2.0934013525644937

Epoch: 6| Step: 6
Training loss: 1.9262993335723877
Validation loss: 2.090611477692922

Epoch: 6| Step: 7
Training loss: 1.6690069437026978
Validation loss: 2.0957334836324057

Epoch: 6| Step: 8
Training loss: 1.9064148664474487
Validation loss: 2.1018404364585876

Epoch: 6| Step: 9
Training loss: 1.6901673078536987
Validation loss: 2.09668763478597

Epoch: 6| Step: 10
Training loss: 2.3467164039611816
Validation loss: 2.1024617354075112

Epoch: 6| Step: 11
Training loss: 1.8238166570663452
Validation loss: 2.108100116252899

Epoch: 6| Step: 12
Training loss: 1.8748698234558105
Validation loss: 2.1006500720977783

Epoch: 6| Step: 13
Training loss: 2.098027229309082
Validation loss: 2.1113906701405845

Epoch: 169| Step: 0
Training loss: 1.2780879735946655
Validation loss: 2.11621755361557

Epoch: 6| Step: 1
Training loss: 1.760148048400879
Validation loss: 2.121720314025879

Epoch: 6| Step: 2
Training loss: 2.426448345184326
Validation loss: 2.1334022283554077

Epoch: 6| Step: 3
Training loss: 2.276869773864746
Validation loss: 2.1438422004381814

Epoch: 6| Step: 4
Training loss: 2.027143955230713
Validation loss: 2.119394063949585

Epoch: 6| Step: 5
Training loss: 2.5628488063812256
Validation loss: 2.1135427951812744

Epoch: 6| Step: 6
Training loss: 1.7295234203338623
Validation loss: 2.099547545115153

Epoch: 6| Step: 7
Training loss: 1.393895149230957
Validation loss: 2.100766440232595

Epoch: 6| Step: 8
Training loss: 2.096724033355713
Validation loss: 2.109001855055491

Epoch: 6| Step: 9
Training loss: 1.8008617162704468
Validation loss: 2.1090760032335916

Epoch: 6| Step: 10
Training loss: 2.239201068878174
Validation loss: 2.0958761970202127

Epoch: 6| Step: 11
Training loss: 1.768458604812622
Validation loss: 2.1003556847572327

Epoch: 6| Step: 12
Training loss: 1.725508689880371
Validation loss: 2.103510061899821

Epoch: 6| Step: 13
Training loss: 1.9472261667251587
Validation loss: 2.1190481781959534

Epoch: 170| Step: 0
Training loss: 2.1323509216308594
Validation loss: 2.1055151422818503

Epoch: 6| Step: 1
Training loss: 2.2760467529296875
Validation loss: 2.1078223983446756

Epoch: 6| Step: 2
Training loss: 1.2046465873718262
Validation loss: 2.1216898361841836

Epoch: 6| Step: 3
Training loss: 2.051142692565918
Validation loss: 2.1332412560780845

Epoch: 6| Step: 4
Training loss: 1.9316942691802979
Validation loss: 2.1186128656069436

Epoch: 6| Step: 5
Training loss: 1.5424351692199707
Validation loss: 2.1196837623914084

Epoch: 6| Step: 6
Training loss: 1.548913836479187
Validation loss: 2.1340023080507913

Epoch: 6| Step: 7
Training loss: 1.7294142246246338
Validation loss: 2.1347212394078574

Epoch: 6| Step: 8
Training loss: 2.3482751846313477
Validation loss: 2.1372432510058084

Epoch: 6| Step: 9
Training loss: 1.805788516998291
Validation loss: 2.1330865224202475

Epoch: 6| Step: 10
Training loss: 2.196223258972168
Validation loss: 2.131156047185262

Epoch: 6| Step: 11
Training loss: 2.372612476348877
Validation loss: 2.115249733130137

Epoch: 6| Step: 12
Training loss: 2.133277654647827
Validation loss: 2.1094266970952353

Epoch: 6| Step: 13
Training loss: 1.6359572410583496
Validation loss: 2.1073901851971946

Epoch: 171| Step: 0
Training loss: 1.7602729797363281
Validation loss: 2.0984879533449807

Epoch: 6| Step: 1
Training loss: 2.4008007049560547
Validation loss: 2.099169651667277

Epoch: 6| Step: 2
Training loss: 2.0865440368652344
Validation loss: 2.1040939887364707

Epoch: 6| Step: 3
Training loss: 2.350069522857666
Validation loss: 2.1098539630572

Epoch: 6| Step: 4
Training loss: 1.8189915418624878
Validation loss: 2.1093455155690513

Epoch: 6| Step: 5
Training loss: 1.727449893951416
Validation loss: 2.107776641845703

Epoch: 6| Step: 6
Training loss: 1.5232455730438232
Validation loss: 2.111611227194468

Epoch: 6| Step: 7
Training loss: 2.212665557861328
Validation loss: 2.1082627177238464

Epoch: 6| Step: 8
Training loss: 1.8769612312316895
Validation loss: 2.1160881320635476

Epoch: 6| Step: 9
Training loss: 2.0458803176879883
Validation loss: 2.11414627234141

Epoch: 6| Step: 10
Training loss: 2.1022958755493164
Validation loss: 2.1261627475420632

Epoch: 6| Step: 11
Training loss: 1.8443691730499268
Validation loss: 2.1419432163238525

Epoch: 6| Step: 12
Training loss: 1.6984962224960327
Validation loss: 2.1443893909454346

Epoch: 6| Step: 13
Training loss: 1.6076958179473877
Validation loss: 2.143611172835032

Epoch: 172| Step: 0
Training loss: 1.4585325717926025
Validation loss: 2.1460097432136536

Epoch: 6| Step: 1
Training loss: 1.8831963539123535
Validation loss: 2.1446139216423035

Epoch: 6| Step: 2
Training loss: 1.8903720378875732
Validation loss: 2.132764538129171

Epoch: 6| Step: 3
Training loss: 2.574176788330078
Validation loss: 2.1311544378598533

Epoch: 6| Step: 4
Training loss: 1.7972733974456787
Validation loss: 2.1267845829327903

Epoch: 6| Step: 5
Training loss: 2.2543063163757324
Validation loss: 2.110844095547994

Epoch: 6| Step: 6
Training loss: 1.6972570419311523
Validation loss: 2.1232528686523438

Epoch: 6| Step: 7
Training loss: 1.7504642009735107
Validation loss: 2.103389084339142

Epoch: 6| Step: 8
Training loss: 1.895438551902771
Validation loss: 2.0956817666689553

Epoch: 6| Step: 9
Training loss: 1.6345438957214355
Validation loss: 2.088352461655935

Epoch: 6| Step: 10
Training loss: 2.409627914428711
Validation loss: 2.0890003045399985

Epoch: 6| Step: 11
Training loss: 2.097757339477539
Validation loss: 2.0897286335627236

Epoch: 6| Step: 12
Training loss: 1.836211085319519
Validation loss: 2.085441986719767

Epoch: 6| Step: 13
Training loss: 1.8844475746154785
Validation loss: 2.0944814682006836

Epoch: 173| Step: 0
Training loss: 2.1689293384552
Validation loss: 2.096238831679026

Epoch: 6| Step: 1
Training loss: 2.404582977294922
Validation loss: 2.098858733971914

Epoch: 6| Step: 2
Training loss: 1.5890436172485352
Validation loss: 2.0976036389668784

Epoch: 6| Step: 3
Training loss: 2.4297661781311035
Validation loss: 2.109237233797709

Epoch: 6| Step: 4
Training loss: 2.369182825088501
Validation loss: 2.1126299301783242

Epoch: 6| Step: 5
Training loss: 1.5636658668518066
Validation loss: 2.115888774394989

Epoch: 6| Step: 6
Training loss: 1.5993539094924927
Validation loss: 2.123123208681742

Epoch: 6| Step: 7
Training loss: 2.1388096809387207
Validation loss: 2.1323660413424173

Epoch: 6| Step: 8
Training loss: 2.0829591751098633
Validation loss: 2.1343674461046853

Epoch: 6| Step: 9
Training loss: 1.835153341293335
Validation loss: 2.1233684619267783

Epoch: 6| Step: 10
Training loss: 1.8256257772445679
Validation loss: 2.124005973339081

Epoch: 6| Step: 11
Training loss: 1.934692621231079
Validation loss: 2.1329669753710427

Epoch: 6| Step: 12
Training loss: 1.8945941925048828
Validation loss: 2.1336345076560974

Epoch: 6| Step: 13
Training loss: 1.5683748722076416
Validation loss: 2.129091123739878

Epoch: 174| Step: 0
Training loss: 1.7114219665527344
Validation loss: 2.1231808066368103

Epoch: 6| Step: 1
Training loss: 2.4585483074188232
Validation loss: 2.1073787013689675

Epoch: 6| Step: 2
Training loss: 1.6890597343444824
Validation loss: 2.1366626421610513

Epoch: 6| Step: 3
Training loss: 2.1550068855285645
Validation loss: 2.121613105138143

Epoch: 6| Step: 4
Training loss: 1.8363966941833496
Validation loss: 2.1222113172213235

Epoch: 6| Step: 5
Training loss: 1.1947723627090454
Validation loss: 2.1086735129356384

Epoch: 6| Step: 6
Training loss: 1.9971814155578613
Validation loss: 2.12193500995636

Epoch: 6| Step: 7
Training loss: 1.9835155010223389
Validation loss: 2.1263797879219055

Epoch: 6| Step: 8
Training loss: 1.6070811748504639
Validation loss: 2.1198156476020813

Epoch: 6| Step: 9
Training loss: 2.1433074474334717
Validation loss: 2.137724240620931

Epoch: 6| Step: 10
Training loss: 2.4127721786499023
Validation loss: 2.1416275898615518

Epoch: 6| Step: 11
Training loss: 1.5048227310180664
Validation loss: 2.140782674153646

Epoch: 6| Step: 12
Training loss: 2.5173723697662354
Validation loss: 2.1457826296488443

Epoch: 6| Step: 13
Training loss: 1.66910719871521
Validation loss: 2.1525615652402244

Epoch: 175| Step: 0
Training loss: 1.881909966468811
Validation loss: 2.1385778387387595

Epoch: 6| Step: 1
Training loss: 1.3899602890014648
Validation loss: 2.134428640206655

Epoch: 6| Step: 2
Training loss: 1.706544280052185
Validation loss: 2.131536900997162

Epoch: 6| Step: 3
Training loss: 2.222391128540039
Validation loss: 2.1242074370384216

Epoch: 6| Step: 4
Training loss: 1.9703688621520996
Validation loss: 2.1140892704327903

Epoch: 6| Step: 5
Training loss: 2.117541551589966
Validation loss: 2.1201664209365845

Epoch: 6| Step: 6
Training loss: 1.8431445360183716
Validation loss: 2.1282952427864075

Epoch: 6| Step: 7
Training loss: 2.143815755844116
Validation loss: 2.112479031085968

Epoch: 6| Step: 8
Training loss: 1.5177052021026611
Validation loss: 2.1235134998957315

Epoch: 6| Step: 9
Training loss: 1.9048548936843872
Validation loss: 2.1318698724110923

Epoch: 6| Step: 10
Training loss: 1.9809930324554443
Validation loss: 2.121859053770701

Epoch: 6| Step: 11
Training loss: 2.3248236179351807
Validation loss: 2.1192368070284524

Epoch: 6| Step: 12
Training loss: 2.22780704498291
Validation loss: 2.1394609411557517

Epoch: 6| Step: 13
Training loss: 1.546461820602417
Validation loss: 2.1257681846618652

Epoch: 176| Step: 0
Training loss: 1.323926568031311
Validation loss: 2.1422199010849

Epoch: 6| Step: 1
Training loss: 1.482926368713379
Validation loss: 2.1275652050971985

Epoch: 6| Step: 2
Training loss: 2.269615411758423
Validation loss: 2.1399858395258584

Epoch: 6| Step: 3
Training loss: 2.0092763900756836
Validation loss: 2.1229125459988913

Epoch: 6| Step: 4
Training loss: 2.023738384246826
Validation loss: 2.1125486890474954

Epoch: 6| Step: 5
Training loss: 1.9200997352600098
Validation loss: 2.122447888056437

Epoch: 6| Step: 6
Training loss: 1.6338045597076416
Validation loss: 2.0994975566864014

Epoch: 6| Step: 7
Training loss: 3.0865602493286133
Validation loss: 2.1058623790740967

Epoch: 6| Step: 8
Training loss: 2.1042799949645996
Validation loss: 2.097162385781606

Epoch: 6| Step: 9
Training loss: 1.9251353740692139
Validation loss: 2.09979110956192

Epoch: 6| Step: 10
Training loss: 1.6554675102233887
Validation loss: 2.099523107210795

Epoch: 6| Step: 11
Training loss: 2.1281707286834717
Validation loss: 2.0937006076176963

Epoch: 6| Step: 12
Training loss: 1.8142778873443604
Validation loss: 2.1032184958457947

Epoch: 6| Step: 13
Training loss: 1.9105021953582764
Validation loss: 2.1115073362986245

Epoch: 177| Step: 0
Training loss: 1.9169113636016846
Validation loss: 2.1029822627703347

Epoch: 6| Step: 1
Training loss: 2.0594985485076904
Validation loss: 2.112255056699117

Epoch: 6| Step: 2
Training loss: 1.9308373928070068
Validation loss: 2.112314840157827

Epoch: 6| Step: 3
Training loss: 1.5445690155029297
Validation loss: 2.123735249042511

Epoch: 6| Step: 4
Training loss: 1.849508285522461
Validation loss: 2.1147413651148477

Epoch: 6| Step: 5
Training loss: 1.4364222288131714
Validation loss: 2.106113910675049

Epoch: 6| Step: 6
Training loss: 2.081817150115967
Validation loss: 2.1164580583572388

Epoch: 6| Step: 7
Training loss: 1.508013129234314
Validation loss: 2.111792008082072

Epoch: 6| Step: 8
Training loss: 2.519310474395752
Validation loss: 2.119672497113546

Epoch: 6| Step: 9
Training loss: 1.8476595878601074
Validation loss: 2.1188668608665466

Epoch: 6| Step: 10
Training loss: 1.8516267538070679
Validation loss: 2.127696673075358

Epoch: 6| Step: 11
Training loss: 2.1031455993652344
Validation loss: 2.1268826524416604

Epoch: 6| Step: 12
Training loss: 1.727607250213623
Validation loss: 2.1298285524050393

Epoch: 6| Step: 13
Training loss: 2.498880386352539
Validation loss: 2.124372919400533

Epoch: 178| Step: 0
Training loss: 1.8159656524658203
Validation loss: 2.1314748724301658

Epoch: 6| Step: 1
Training loss: 2.140042781829834
Validation loss: 2.150786737600962

Epoch: 6| Step: 2
Training loss: 1.7669475078582764
Validation loss: 2.1336971124013266

Epoch: 6| Step: 3
Training loss: 1.802960991859436
Validation loss: 2.1539142529169717

Epoch: 6| Step: 4
Training loss: 1.660071849822998
Validation loss: 2.1496171355247498

Epoch: 6| Step: 5
Training loss: 1.4146580696105957
Validation loss: 2.1325962940851846

Epoch: 6| Step: 6
Training loss: 1.8357770442962646
Validation loss: 2.13942813873291

Epoch: 6| Step: 7
Training loss: 2.173783779144287
Validation loss: 2.1456671555836997

Epoch: 6| Step: 8
Training loss: 2.624541759490967
Validation loss: 2.1327550411224365

Epoch: 6| Step: 9
Training loss: 1.7172517776489258
Validation loss: 2.1436288356781006

Epoch: 6| Step: 10
Training loss: 1.9738942384719849
Validation loss: 2.13625035683314

Epoch: 6| Step: 11
Training loss: 2.090730667114258
Validation loss: 2.1376835703849792

Epoch: 6| Step: 12
Training loss: 1.592513918876648
Validation loss: 2.1235146522521973

Epoch: 6| Step: 13
Training loss: 2.2051138877868652
Validation loss: 2.1264018019040427

Epoch: 179| Step: 0
Training loss: 1.3851476907730103
Validation loss: 2.115642031033834

Epoch: 6| Step: 1
Training loss: 1.9805142879486084
Validation loss: 2.1169447898864746

Epoch: 6| Step: 2
Training loss: 2.1526317596435547
Validation loss: 2.1284488240877786

Epoch: 6| Step: 3
Training loss: 1.9339905977249146
Validation loss: 2.1458128889401755

Epoch: 6| Step: 4
Training loss: 1.8518385887145996
Validation loss: 2.1543707251548767

Epoch: 6| Step: 5
Training loss: 1.6507152318954468
Validation loss: 2.164387842019399

Epoch: 6| Step: 6
Training loss: 2.5435400009155273
Validation loss: 2.157144844532013

Epoch: 6| Step: 7
Training loss: 1.7389734983444214
Validation loss: 2.166870355606079

Epoch: 6| Step: 8
Training loss: 1.9178760051727295
Validation loss: 2.15100751320521

Epoch: 6| Step: 9
Training loss: 1.3875656127929688
Validation loss: 2.1574273308118186

Epoch: 6| Step: 10
Training loss: 2.171480655670166
Validation loss: 2.1517303387324014

Epoch: 6| Step: 11
Training loss: 1.7926150560379028
Validation loss: 2.1435025533040366

Epoch: 6| Step: 12
Training loss: 2.487600564956665
Validation loss: 2.123873213926951

Epoch: 6| Step: 13
Training loss: 2.2447047233581543
Validation loss: 2.114839812119802

Epoch: 180| Step: 0
Training loss: 1.231990098953247
Validation loss: 2.110068221886953

Epoch: 6| Step: 1
Training loss: 1.0912935733795166
Validation loss: 2.1197097500165305

Epoch: 6| Step: 2
Training loss: 1.985442876815796
Validation loss: 2.101580500602722

Epoch: 6| Step: 3
Training loss: 1.8417819738388062
Validation loss: 2.1013343930244446

Epoch: 6| Step: 4
Training loss: 2.2059309482574463
Validation loss: 2.098624328772227

Epoch: 6| Step: 5
Training loss: 1.519722819328308
Validation loss: 2.1070095896720886

Epoch: 6| Step: 6
Training loss: 2.6090316772460938
Validation loss: 2.1089251041412354

Epoch: 6| Step: 7
Training loss: 1.9444552659988403
Validation loss: 2.1126819849014282

Epoch: 6| Step: 8
Training loss: 1.6897921562194824
Validation loss: 2.1223418513933816

Epoch: 6| Step: 9
Training loss: 2.8736841678619385
Validation loss: 2.122257928053538

Epoch: 6| Step: 10
Training loss: 1.6004074811935425
Validation loss: 2.1302995085716248

Epoch: 6| Step: 11
Training loss: 1.8471318483352661
Validation loss: 2.1416693925857544

Epoch: 6| Step: 12
Training loss: 2.255012035369873
Validation loss: 2.1319915850957236

Epoch: 6| Step: 13
Training loss: 2.331355571746826
Validation loss: 2.138135631879171

Epoch: 181| Step: 0
Training loss: 2.027081251144409
Validation loss: 2.1295557618141174

Epoch: 6| Step: 1
Training loss: 1.852460265159607
Validation loss: 2.13467945655187

Epoch: 6| Step: 2
Training loss: 1.7605421543121338
Validation loss: 2.114719569683075

Epoch: 6| Step: 3
Training loss: 2.0556294918060303
Validation loss: 2.125279347101847

Epoch: 6| Step: 4
Training loss: 1.9558268785476685
Validation loss: 2.1206470131874084

Epoch: 6| Step: 5
Training loss: 1.714522123336792
Validation loss: 2.1173110405604043

Epoch: 6| Step: 6
Training loss: 1.7788408994674683
Validation loss: 2.113968789577484

Epoch: 6| Step: 7
Training loss: 1.5158787965774536
Validation loss: 2.1133424043655396

Epoch: 6| Step: 8
Training loss: 1.6895346641540527
Validation loss: 2.1061551173528037

Epoch: 6| Step: 9
Training loss: 1.7649518251419067
Validation loss: 2.1086598833402

Epoch: 6| Step: 10
Training loss: 2.133342981338501
Validation loss: 2.120912174383799

Epoch: 6| Step: 11
Training loss: 1.9292975664138794
Validation loss: 2.117348869641622

Epoch: 6| Step: 12
Training loss: 1.712200403213501
Validation loss: 2.1191230614980063

Epoch: 6| Step: 13
Training loss: 2.645444393157959
Validation loss: 2.1185388962427774

Epoch: 182| Step: 0
Training loss: 2.005495309829712
Validation loss: 2.1236340006192527

Epoch: 6| Step: 1
Training loss: 1.6049343347549438
Validation loss: 2.120710551738739

Epoch: 6| Step: 2
Training loss: 2.21264910697937
Validation loss: 2.122041344642639

Epoch: 6| Step: 3
Training loss: 2.1799159049987793
Validation loss: 2.1346575220425925

Epoch: 6| Step: 4
Training loss: 1.9422208070755005
Validation loss: 2.125123838583628

Epoch: 6| Step: 5
Training loss: 2.0639686584472656
Validation loss: 2.1330052415529885

Epoch: 6| Step: 6
Training loss: 1.3281742334365845
Validation loss: 2.1231938203175864

Epoch: 6| Step: 7
Training loss: 1.7035772800445557
Validation loss: 2.135736604531606

Epoch: 6| Step: 8
Training loss: 2.201730251312256
Validation loss: 2.1415138641993203

Epoch: 6| Step: 9
Training loss: 2.0410513877868652
Validation loss: 2.143971105416616

Epoch: 6| Step: 10
Training loss: 1.1382317543029785
Validation loss: 2.1663371324539185

Epoch: 6| Step: 11
Training loss: 2.2053332328796387
Validation loss: 2.1524139841397605

Epoch: 6| Step: 12
Training loss: 2.178835868835449
Validation loss: 2.137105921904246

Epoch: 6| Step: 13
Training loss: 2.076976776123047
Validation loss: 2.140729566415151

Epoch: 183| Step: 0
Training loss: 2.0502548217773438
Validation loss: 2.1306390364964805

Epoch: 6| Step: 1
Training loss: 1.599024772644043
Validation loss: 2.122970620791117

Epoch: 6| Step: 2
Training loss: 2.2874209880828857
Validation loss: 2.1098371148109436

Epoch: 6| Step: 3
Training loss: 2.375426769256592
Validation loss: 2.108102281888326

Epoch: 6| Step: 4
Training loss: 2.0635979175567627
Validation loss: 2.111667493979136

Epoch: 6| Step: 5
Training loss: 2.576855182647705
Validation loss: 2.1208794315656028

Epoch: 6| Step: 6
Training loss: 1.192795991897583
Validation loss: 2.127030690511068

Epoch: 6| Step: 7
Training loss: 1.820227861404419
Validation loss: 2.1152167121569314

Epoch: 6| Step: 8
Training loss: 1.4846159219741821
Validation loss: 2.12643168369929

Epoch: 6| Step: 9
Training loss: 2.3766801357269287
Validation loss: 2.1312232414881387

Epoch: 6| Step: 10
Training loss: 1.7454757690429688
Validation loss: 2.137190361817678

Epoch: 6| Step: 11
Training loss: 2.0022835731506348
Validation loss: 2.126117984453837

Epoch: 6| Step: 12
Training loss: 1.813218593597412
Validation loss: 2.132484714190165

Epoch: 6| Step: 13
Training loss: 1.3118579387664795
Validation loss: 2.1382807890574136

Epoch: 184| Step: 0
Training loss: 1.772327184677124
Validation loss: 2.1368837356567383

Epoch: 6| Step: 1
Training loss: 1.868072509765625
Validation loss: 2.1353527307510376

Epoch: 6| Step: 2
Training loss: 1.944822072982788
Validation loss: 2.1451464692751565

Epoch: 6| Step: 3
Training loss: 2.6223621368408203
Validation loss: 2.1475273966789246

Epoch: 6| Step: 4
Training loss: 1.895462989807129
Validation loss: 2.142672518889109

Epoch: 6| Step: 5
Training loss: 1.1461125612258911
Validation loss: 2.153705676396688

Epoch: 6| Step: 6
Training loss: 2.6089959144592285
Validation loss: 2.1452455520629883

Epoch: 6| Step: 7
Training loss: 1.7121772766113281
Validation loss: 2.143205225467682

Epoch: 6| Step: 8
Training loss: 1.373298168182373
Validation loss: 2.1381980776786804

Epoch: 6| Step: 9
Training loss: 2.0488080978393555
Validation loss: 2.1513371070226035

Epoch: 6| Step: 10
Training loss: 2.003974437713623
Validation loss: 2.147854824860891

Epoch: 6| Step: 11
Training loss: 2.0819170475006104
Validation loss: 2.1412609219551086

Epoch: 6| Step: 12
Training loss: 1.8840100765228271
Validation loss: 2.1314542492230735

Epoch: 6| Step: 13
Training loss: 1.2846367359161377
Validation loss: 2.144193251927694

Epoch: 185| Step: 0
Training loss: 1.4750688076019287
Validation loss: 2.1385848124821982

Epoch: 6| Step: 1
Training loss: 2.363286256790161
Validation loss: 2.1385873556137085

Epoch: 6| Step: 2
Training loss: 1.968196153640747
Validation loss: 2.143945336341858

Epoch: 6| Step: 3
Training loss: 2.1337947845458984
Validation loss: 2.1439329783121743

Epoch: 6| Step: 4
Training loss: 1.5825929641723633
Validation loss: 2.1453693509101868

Epoch: 6| Step: 5
Training loss: 2.5005135536193848
Validation loss: 2.1331026752789817

Epoch: 6| Step: 6
Training loss: 1.871754765510559
Validation loss: 2.1392216086387634

Epoch: 6| Step: 7
Training loss: 1.6266255378723145
Validation loss: 2.1409409244855246

Epoch: 6| Step: 8
Training loss: 1.783299446105957
Validation loss: 2.14284747838974

Epoch: 6| Step: 9
Training loss: 2.2174365520477295
Validation loss: 2.1395298639933267

Epoch: 6| Step: 10
Training loss: 2.126540184020996
Validation loss: 2.137093404928843

Epoch: 6| Step: 11
Training loss: 1.333126425743103
Validation loss: 2.134242534637451

Epoch: 6| Step: 12
Training loss: 1.6990439891815186
Validation loss: 2.122190018494924

Epoch: 6| Step: 13
Training loss: 1.5606240034103394
Validation loss: 2.1479204893112183

Epoch: 186| Step: 0
Training loss: 1.7721920013427734
Validation loss: 2.152947028477987

Epoch: 6| Step: 1
Training loss: 2.0505995750427246
Validation loss: 2.1477357943852744

Epoch: 6| Step: 2
Training loss: 2.1512582302093506
Validation loss: 2.126211404800415

Epoch: 6| Step: 3
Training loss: 2.1668128967285156
Validation loss: 2.146096189816793

Epoch: 6| Step: 4
Training loss: 1.667344570159912
Validation loss: 2.146925767262777

Epoch: 6| Step: 5
Training loss: 1.793320894241333
Validation loss: 2.1467519203821817

Epoch: 6| Step: 6
Training loss: 2.1198928356170654
Validation loss: 2.1275498469670615

Epoch: 6| Step: 7
Training loss: 1.7062203884124756
Validation loss: 2.1506961981455484

Epoch: 6| Step: 8
Training loss: 2.165961980819702
Validation loss: 2.1431620717048645

Epoch: 6| Step: 9
Training loss: 1.3035478591918945
Validation loss: 2.142273704210917

Epoch: 6| Step: 10
Training loss: 2.46913480758667
Validation loss: 2.1569270690282187

Epoch: 6| Step: 11
Training loss: 1.57149076461792
Validation loss: 2.1561522285143533

Epoch: 6| Step: 12
Training loss: 1.5864735841751099
Validation loss: 2.152266561985016

Epoch: 6| Step: 13
Training loss: 1.7426376342773438
Validation loss: 2.165293514728546

Epoch: 187| Step: 0
Training loss: 1.8436834812164307
Validation loss: 2.1576480070749917

Epoch: 6| Step: 1
Training loss: 1.9303064346313477
Validation loss: 2.1617533365885415

Epoch: 6| Step: 2
Training loss: 1.8994892835617065
Validation loss: 2.1447380979855857

Epoch: 6| Step: 3
Training loss: 2.085540294647217
Validation loss: 2.154308636983236

Epoch: 6| Step: 4
Training loss: 1.7470017671585083
Validation loss: 2.150048633416494

Epoch: 6| Step: 5
Training loss: 2.315171241760254
Validation loss: 2.132192591826121

Epoch: 6| Step: 6
Training loss: 1.6468253135681152
Validation loss: 2.143903295199076

Epoch: 6| Step: 7
Training loss: 2.2470779418945312
Validation loss: 2.1525835196177163

Epoch: 6| Step: 8
Training loss: 1.756711483001709
Validation loss: 2.1368239919344583

Epoch: 6| Step: 9
Training loss: 1.483580231666565
Validation loss: 2.1482561429341636

Epoch: 6| Step: 10
Training loss: 1.3203189373016357
Validation loss: 2.1458486318588257

Epoch: 6| Step: 11
Training loss: 1.4348022937774658
Validation loss: 2.144675056139628

Epoch: 6| Step: 12
Training loss: 2.0482840538024902
Validation loss: 2.142803112665812

Epoch: 6| Step: 13
Training loss: 2.483968734741211
Validation loss: 2.1529399156570435

Epoch: 188| Step: 0
Training loss: 1.6423360109329224
Validation loss: 2.144517719745636

Epoch: 6| Step: 1
Training loss: 1.4343303442001343
Validation loss: 2.1452932357788086

Epoch: 6| Step: 2
Training loss: 2.0913350582122803
Validation loss: 2.1452093521753945

Epoch: 6| Step: 3
Training loss: 2.35478138923645
Validation loss: 2.145811120669047

Epoch: 6| Step: 4
Training loss: 1.5215213298797607
Validation loss: 2.1531684199968972

Epoch: 6| Step: 5
Training loss: 2.12937068939209
Validation loss: 2.1559981306393943

Epoch: 6| Step: 6
Training loss: 1.7605489492416382
Validation loss: 2.148481070995331

Epoch: 6| Step: 7
Training loss: 2.4395248889923096
Validation loss: 2.174881716569265

Epoch: 6| Step: 8
Training loss: 1.17649245262146
Validation loss: 2.150309960047404

Epoch: 6| Step: 9
Training loss: 1.320237398147583
Validation loss: 2.140449285507202

Epoch: 6| Step: 10
Training loss: 1.534372091293335
Validation loss: 2.1552396416664124

Epoch: 6| Step: 11
Training loss: 2.3887836933135986
Validation loss: 2.1486642559369407

Epoch: 6| Step: 12
Training loss: 2.063613176345825
Validation loss: 2.1466458837191262

Epoch: 6| Step: 13
Training loss: 2.317596197128296
Validation loss: 2.1538814703623452

Epoch: 189| Step: 0
Training loss: 2.103104829788208
Validation loss: 2.1409541964530945

Epoch: 6| Step: 1
Training loss: 1.393628478050232
Validation loss: 2.141183535257975

Epoch: 6| Step: 2
Training loss: 2.281304359436035
Validation loss: 2.1624303658803306

Epoch: 6| Step: 3
Training loss: 1.734593391418457
Validation loss: 2.1440057357152305

Epoch: 6| Step: 4
Training loss: 1.5393215417861938
Validation loss: 2.1515467762947083

Epoch: 6| Step: 5
Training loss: 1.7958840131759644
Validation loss: 2.1489718556404114

Epoch: 6| Step: 6
Training loss: 1.6174652576446533
Validation loss: 2.1464951634407043

Epoch: 6| Step: 7
Training loss: 1.9678142070770264
Validation loss: 2.157415767510732

Epoch: 6| Step: 8
Training loss: 2.816051959991455
Validation loss: 2.148959537347158

Epoch: 6| Step: 9
Training loss: 2.1804885864257812
Validation loss: 2.144860545794169

Epoch: 6| Step: 10
Training loss: 1.8065685033798218
Validation loss: 2.146040936311086

Epoch: 6| Step: 11
Training loss: 1.4576619863510132
Validation loss: 2.1390116214752197

Epoch: 6| Step: 12
Training loss: 1.5825064182281494
Validation loss: 2.1226510405540466

Epoch: 6| Step: 13
Training loss: 1.8199796676635742
Validation loss: 2.1337379813194275

Epoch: 190| Step: 0
Training loss: 1.4510784149169922
Validation loss: 2.138711134592692

Epoch: 6| Step: 1
Training loss: 1.3350481986999512
Validation loss: 2.1427970131238303

Epoch: 6| Step: 2
Training loss: 2.075282096862793
Validation loss: 2.1413614749908447

Epoch: 6| Step: 3
Training loss: 1.713162899017334
Validation loss: 2.1453251441319785

Epoch: 6| Step: 4
Training loss: 2.4190022945404053
Validation loss: 2.146212657292684

Epoch: 6| Step: 5
Training loss: 1.492039680480957
Validation loss: 2.143841008345286

Epoch: 6| Step: 6
Training loss: 1.615808129310608
Validation loss: 2.15229340394338

Epoch: 6| Step: 7
Training loss: 1.9274144172668457
Validation loss: 2.162437121073405

Epoch: 6| Step: 8
Training loss: 2.3384957313537598
Validation loss: 2.1710721254348755

Epoch: 6| Step: 9
Training loss: 2.472637176513672
Validation loss: 2.1841970880826316

Epoch: 6| Step: 10
Training loss: 1.9292418956756592
Validation loss: 2.1746097405751548

Epoch: 6| Step: 11
Training loss: 2.2026567459106445
Validation loss: 2.1773685216903687

Epoch: 6| Step: 12
Training loss: 1.7910518646240234
Validation loss: 2.158949851989746

Epoch: 6| Step: 13
Training loss: 1.537719488143921
Validation loss: 2.1561238169670105

Epoch: 191| Step: 0
Training loss: 2.2720437049865723
Validation loss: 2.163940111796061

Epoch: 6| Step: 1
Training loss: 1.846171259880066
Validation loss: 2.1393579641977944

Epoch: 6| Step: 2
Training loss: 2.486586570739746
Validation loss: 2.123233139514923

Epoch: 6| Step: 3
Training loss: 2.2196812629699707
Validation loss: 2.126290758450826

Epoch: 6| Step: 4
Training loss: 1.8536996841430664
Validation loss: 2.119103213151296

Epoch: 6| Step: 5
Training loss: 1.779007077217102
Validation loss: 2.120276312033335

Epoch: 6| Step: 6
Training loss: 1.50118887424469
Validation loss: 2.1196587880452475

Epoch: 6| Step: 7
Training loss: 2.148155450820923
Validation loss: 2.1365386843681335

Epoch: 6| Step: 8
Training loss: 2.127002239227295
Validation loss: 2.1425790190696716

Epoch: 6| Step: 9
Training loss: 1.9528822898864746
Validation loss: 2.14896023273468

Epoch: 6| Step: 10
Training loss: 1.1293160915374756
Validation loss: 2.1632811228434243

Epoch: 6| Step: 11
Training loss: 1.8656773567199707
Validation loss: 2.172092020511627

Epoch: 6| Step: 12
Training loss: 2.0132293701171875
Validation loss: 2.1731905341148376

Epoch: 6| Step: 13
Training loss: 1.5792845487594604
Validation loss: 2.170904835065206

Epoch: 192| Step: 0
Training loss: 2.0306243896484375
Validation loss: 2.179688513278961

Epoch: 6| Step: 1
Training loss: 1.8658756017684937
Validation loss: 2.187765061855316

Epoch: 6| Step: 2
Training loss: 2.0946121215820312
Validation loss: 2.1770161191622415

Epoch: 6| Step: 3
Training loss: 2.320873737335205
Validation loss: 2.1839252710342407

Epoch: 6| Step: 4
Training loss: 1.4525665044784546
Validation loss: 2.1731757720311484

Epoch: 6| Step: 5
Training loss: 2.1276183128356934
Validation loss: 2.1841333707173667

Epoch: 6| Step: 6
Training loss: 1.827032208442688
Validation loss: 2.1704097588857016

Epoch: 6| Step: 7
Training loss: 1.1738076210021973
Validation loss: 2.17688783009847

Epoch: 6| Step: 8
Training loss: 1.871113896369934
Validation loss: 2.166504720846812

Epoch: 6| Step: 9
Training loss: 1.777753472328186
Validation loss: 2.1498268047968545

Epoch: 6| Step: 10
Training loss: 1.7218222618103027
Validation loss: 2.146202882130941

Epoch: 6| Step: 11
Training loss: 2.0042848587036133
Validation loss: 2.1499643325805664

Epoch: 6| Step: 12
Training loss: 1.8827334642410278
Validation loss: 2.130415598551432

Epoch: 6| Step: 13
Training loss: 2.314923048019409
Validation loss: 2.133835017681122

Epoch: 193| Step: 0
Training loss: 1.5454288721084595
Validation loss: 2.135120471318563

Epoch: 6| Step: 1
Training loss: 2.3758463859558105
Validation loss: 2.1369581619898477

Epoch: 6| Step: 2
Training loss: 1.5418753623962402
Validation loss: 2.1371259093284607

Epoch: 6| Step: 3
Training loss: 1.8150634765625
Validation loss: 2.145382583141327

Epoch: 6| Step: 4
Training loss: 1.6514623165130615
Validation loss: 2.1516868472099304

Epoch: 6| Step: 5
Training loss: 1.9759407043457031
Validation loss: 2.1618793606758118

Epoch: 6| Step: 6
Training loss: 2.0860447883605957
Validation loss: 2.1677959163983664

Epoch: 6| Step: 7
Training loss: 2.2315855026245117
Validation loss: 2.1592309872309365

Epoch: 6| Step: 8
Training loss: 1.7258434295654297
Validation loss: 2.1627714236577353

Epoch: 6| Step: 9
Training loss: 1.7833901643753052
Validation loss: 2.1739365259806314

Epoch: 6| Step: 10
Training loss: 1.2098135948181152
Validation loss: 2.167177220185598

Epoch: 6| Step: 11
Training loss: 1.8276429176330566
Validation loss: 2.17014749844869

Epoch: 6| Step: 12
Training loss: 2.4928412437438965
Validation loss: 2.167452812194824

Epoch: 6| Step: 13
Training loss: 1.9985699653625488
Validation loss: 2.1722652316093445

Epoch: 194| Step: 0
Training loss: 1.582383394241333
Validation loss: 2.16740216811498

Epoch: 6| Step: 1
Training loss: 2.0284292697906494
Validation loss: 2.1707470417022705

Epoch: 6| Step: 2
Training loss: 2.03511643409729
Validation loss: 2.1428009271621704

Epoch: 6| Step: 3
Training loss: 1.2229030132293701
Validation loss: 2.1525745193163552

Epoch: 6| Step: 4
Training loss: 1.2584128379821777
Validation loss: 2.1512208382288613

Epoch: 6| Step: 5
Training loss: 1.9035451412200928
Validation loss: 2.1494813362757363

Epoch: 6| Step: 6
Training loss: 2.0303955078125
Validation loss: 2.1766856908798218

Epoch: 6| Step: 7
Training loss: 1.9374079704284668
Validation loss: 2.148963431517283

Epoch: 6| Step: 8
Training loss: 1.8772542476654053
Validation loss: 2.1767437855402627

Epoch: 6| Step: 9
Training loss: 2.9601943492889404
Validation loss: 2.1668830712636313

Epoch: 6| Step: 10
Training loss: 2.001922607421875
Validation loss: 2.1648866335550943

Epoch: 6| Step: 11
Training loss: 1.559064269065857
Validation loss: 2.170125106970469

Epoch: 6| Step: 12
Training loss: 1.9026744365692139
Validation loss: 2.1818788846333823

Epoch: 6| Step: 13
Training loss: 1.7549363374710083
Validation loss: 2.1789182225863137

Epoch: 195| Step: 0
Training loss: 1.9387332201004028
Validation loss: 2.17666095495224

Epoch: 6| Step: 1
Training loss: 2.0299105644226074
Validation loss: 2.1765605807304382

Epoch: 6| Step: 2
Training loss: 2.206987142562866
Validation loss: 2.1539900302886963

Epoch: 6| Step: 3
Training loss: 1.816819190979004
Validation loss: 2.1711459159851074

Epoch: 6| Step: 4
Training loss: 1.5996909141540527
Validation loss: 2.1553155382474265

Epoch: 6| Step: 5
Training loss: 1.6100049018859863
Validation loss: 2.1488815347353616

Epoch: 6| Step: 6
Training loss: 2.1920456886291504
Validation loss: 2.150625546773275

Epoch: 6| Step: 7
Training loss: 1.2915204763412476
Validation loss: 2.155077556769053

Epoch: 6| Step: 8
Training loss: 1.1068692207336426
Validation loss: 2.157238562901815

Epoch: 6| Step: 9
Training loss: 2.0123255252838135
Validation loss: 2.1451090574264526

Epoch: 6| Step: 10
Training loss: 2.1461753845214844
Validation loss: 2.145540237426758

Epoch: 6| Step: 11
Training loss: 2.4663023948669434
Validation loss: 2.153434157371521

Epoch: 6| Step: 12
Training loss: 1.9629220962524414
Validation loss: 2.1626386443773904

Epoch: 6| Step: 13
Training loss: 1.6952707767486572
Validation loss: 2.1557215253512063

Epoch: 196| Step: 0
Training loss: 1.4872593879699707
Validation loss: 2.1557460824648538

Epoch: 6| Step: 1
Training loss: 1.5659518241882324
Validation loss: 2.155874808629354

Epoch: 6| Step: 2
Training loss: 1.724502444267273
Validation loss: 2.152931193510691

Epoch: 6| Step: 3
Training loss: 1.8769712448120117
Validation loss: 2.1613437136014304

Epoch: 6| Step: 4
Training loss: 1.9392478466033936
Validation loss: 2.1509962479273477

Epoch: 6| Step: 5
Training loss: 2.204399824142456
Validation loss: 2.159663756688436

Epoch: 6| Step: 6
Training loss: 1.7184195518493652
Validation loss: 2.1497022906939187

Epoch: 6| Step: 7
Training loss: 1.6850050687789917
Validation loss: 2.1474605798721313

Epoch: 6| Step: 8
Training loss: 1.8329867124557495
Validation loss: 2.1474339962005615

Epoch: 6| Step: 9
Training loss: 2.5208630561828613
Validation loss: 2.151758849620819

Epoch: 6| Step: 10
Training loss: 1.525144338607788
Validation loss: 2.156282901763916

Epoch: 6| Step: 11
Training loss: 2.5159783363342285
Validation loss: 2.1447787284851074

Epoch: 6| Step: 12
Training loss: 1.6684972047805786
Validation loss: 2.1467410127321878

Epoch: 6| Step: 13
Training loss: 1.7774240970611572
Validation loss: 2.136858344078064

Epoch: 197| Step: 0
Training loss: 1.7296464443206787
Validation loss: 2.124295731385549

Epoch: 6| Step: 1
Training loss: 1.8888397216796875
Validation loss: 2.1371389826138816

Epoch: 6| Step: 2
Training loss: 1.5812478065490723
Validation loss: 2.1362590392430625

Epoch: 6| Step: 3
Training loss: 1.8418328762054443
Validation loss: 2.1463714241981506

Epoch: 6| Step: 4
Training loss: 2.614123821258545
Validation loss: 2.1431420048077903

Epoch: 6| Step: 5
Training loss: 2.0529963970184326
Validation loss: 2.1523133317629495

Epoch: 6| Step: 6
Training loss: 2.213777542114258
Validation loss: 2.149701734383901

Epoch: 6| Step: 7
Training loss: 2.0476913452148438
Validation loss: 2.148405651251475

Epoch: 6| Step: 8
Training loss: 1.8368257284164429
Validation loss: 2.1496867140134177

Epoch: 6| Step: 9
Training loss: 1.2719942331314087
Validation loss: 2.150915582974752

Epoch: 6| Step: 10
Training loss: 1.5190238952636719
Validation loss: 2.133308490117391

Epoch: 6| Step: 11
Training loss: 1.9871056079864502
Validation loss: 2.1554820934931436

Epoch: 6| Step: 12
Training loss: 1.5878679752349854
Validation loss: 2.1585840980211892

Epoch: 6| Step: 13
Training loss: 1.6268473863601685
Validation loss: 2.1466423074404397

Epoch: 198| Step: 0
Training loss: 2.192922353744507
Validation loss: 2.1574692726135254

Epoch: 6| Step: 1
Training loss: 1.9636762142181396
Validation loss: 2.1822173992792764

Epoch: 6| Step: 2
Training loss: 1.8493883609771729
Validation loss: 2.171550472577413

Epoch: 6| Step: 3
Training loss: 1.5460231304168701
Validation loss: 2.1675227085749307

Epoch: 6| Step: 4
Training loss: 1.5035426616668701
Validation loss: 2.1786017616589866

Epoch: 6| Step: 5
Training loss: 2.1883280277252197
Validation loss: 2.1614351669947305

Epoch: 6| Step: 6
Training loss: 2.0989580154418945
Validation loss: 2.167123099168142

Epoch: 6| Step: 7
Training loss: 1.5571702718734741
Validation loss: 2.18662557999293

Epoch: 6| Step: 8
Training loss: 1.337321162223816
Validation loss: 2.1723782618840537

Epoch: 6| Step: 9
Training loss: 1.9487935304641724
Validation loss: 2.16545706987381

Epoch: 6| Step: 10
Training loss: 2.43254017829895
Validation loss: 2.1696667869885764

Epoch: 6| Step: 11
Training loss: 1.956844449043274
Validation loss: 2.1812439958254495

Epoch: 6| Step: 12
Training loss: 1.9871363639831543
Validation loss: 2.157856543858846

Epoch: 6| Step: 13
Training loss: 1.7615734338760376
Validation loss: 2.174097001552582

Epoch: 199| Step: 0
Training loss: 1.8521394729614258
Validation loss: 2.1546814839045205

Epoch: 6| Step: 1
Training loss: 2.257366895675659
Validation loss: 2.146422346433004

Epoch: 6| Step: 2
Training loss: 1.5657342672348022
Validation loss: 2.1501255432764688

Epoch: 6| Step: 3
Training loss: 2.017475128173828
Validation loss: 2.142541309197744

Epoch: 6| Step: 4
Training loss: 2.6812641620635986
Validation loss: 2.144073228041331

Epoch: 6| Step: 5
Training loss: 1.5405642986297607
Validation loss: 2.1440197626749673

Epoch: 6| Step: 6
Training loss: 1.9422028064727783
Validation loss: 2.133866270383199

Epoch: 6| Step: 7
Training loss: 1.2630178928375244
Validation loss: 2.156144062678019

Epoch: 6| Step: 8
Training loss: 1.9732201099395752
Validation loss: 2.175934910774231

Epoch: 6| Step: 9
Training loss: 1.6272449493408203
Validation loss: 2.170888821283976

Epoch: 6| Step: 10
Training loss: 1.6398351192474365
Validation loss: 2.165422042210897

Epoch: 6| Step: 11
Training loss: 1.535402536392212
Validation loss: 2.1809801856676736

Epoch: 6| Step: 12
Training loss: 1.8836755752563477
Validation loss: 2.177587151527405

Epoch: 6| Step: 13
Training loss: 2.1891672611236572
Validation loss: 2.176825483640035

Epoch: 200| Step: 0
Training loss: 1.4235668182373047
Validation loss: 2.175222317377726

Epoch: 6| Step: 1
Training loss: 2.2806200981140137
Validation loss: 2.1788255174954734

Epoch: 6| Step: 2
Training loss: 1.9152721166610718
Validation loss: 2.1894431114196777

Epoch: 6| Step: 3
Training loss: 1.7833411693572998
Validation loss: 2.1720798214276633

Epoch: 6| Step: 4
Training loss: 1.8048224449157715
Validation loss: 2.1815538803736367

Epoch: 6| Step: 5
Training loss: 1.9028387069702148
Validation loss: 2.1731468041737876

Epoch: 6| Step: 6
Training loss: 1.6978744268417358
Validation loss: 2.1694738467534385

Epoch: 6| Step: 7
Training loss: 1.8057096004486084
Validation loss: 2.1643468936284385

Epoch: 6| Step: 8
Training loss: 2.0242419242858887
Validation loss: 2.174523731072744

Epoch: 6| Step: 9
Training loss: 1.770787239074707
Validation loss: 2.154810070991516

Epoch: 6| Step: 10
Training loss: 1.5893430709838867
Validation loss: 2.179533918698629

Epoch: 6| Step: 11
Training loss: 1.5404341220855713
Validation loss: 2.155529002348582

Epoch: 6| Step: 12
Training loss: 2.1867246627807617
Validation loss: 2.1511967380841575

Epoch: 6| Step: 13
Training loss: 1.9790823459625244
Validation loss: 2.1334866881370544

Epoch: 201| Step: 0
Training loss: 2.122675657272339
Validation loss: 2.135747770468394

Epoch: 6| Step: 1
Training loss: 1.6168876886367798
Validation loss: 2.1438459753990173

Epoch: 6| Step: 2
Training loss: 2.0138020515441895
Validation loss: 2.134541849295298

Epoch: 6| Step: 3
Training loss: 1.1654959917068481
Validation loss: 2.1406120657920837

Epoch: 6| Step: 4
Training loss: 1.9870644807815552
Validation loss: 2.1404782136281333

Epoch: 6| Step: 5
Training loss: 1.682155966758728
Validation loss: 2.1319433450698853

Epoch: 6| Step: 6
Training loss: 1.6060134172439575
Validation loss: 2.144044836362203

Epoch: 6| Step: 7
Training loss: 2.1276540756225586
Validation loss: 2.1341310143470764

Epoch: 6| Step: 8
Training loss: 2.1086034774780273
Validation loss: 2.1515075167020163

Epoch: 6| Step: 9
Training loss: 1.6641727685928345
Validation loss: 2.156118869781494

Epoch: 6| Step: 10
Training loss: 1.585593819618225
Validation loss: 2.1620709697405496

Epoch: 6| Step: 11
Training loss: 1.9464797973632812
Validation loss: 2.16481743256251

Epoch: 6| Step: 12
Training loss: 2.094082832336426
Validation loss: 2.174225330352783

Epoch: 6| Step: 13
Training loss: 2.1568527221679688
Validation loss: 2.1588053901990256

Epoch: 202| Step: 0
Training loss: 1.6666574478149414
Validation loss: 2.180024206638336

Epoch: 6| Step: 1
Training loss: 1.7555011510849
Validation loss: 2.159703274567922

Epoch: 6| Step: 2
Training loss: 1.5524580478668213
Validation loss: 2.1817358334859214

Epoch: 6| Step: 3
Training loss: 1.675011396408081
Validation loss: 2.188802937666575

Epoch: 6| Step: 4
Training loss: 1.688709020614624
Validation loss: 2.1835618019104004

Epoch: 6| Step: 5
Training loss: 2.184610366821289
Validation loss: 2.1857983271280923

Epoch: 6| Step: 6
Training loss: 1.2748451232910156
Validation loss: 2.1781842708587646

Epoch: 6| Step: 7
Training loss: 1.9774717092514038
Validation loss: 2.1882309317588806

Epoch: 6| Step: 8
Training loss: 2.076474189758301
Validation loss: 2.185573319594065

Epoch: 6| Step: 9
Training loss: 1.789615273475647
Validation loss: 2.186603546142578

Epoch: 6| Step: 10
Training loss: 1.7132148742675781
Validation loss: 2.207631826400757

Epoch: 6| Step: 11
Training loss: 2.4457435607910156
Validation loss: 2.200942794481913

Epoch: 6| Step: 12
Training loss: 2.4562480449676514
Validation loss: 2.1694862842559814

Epoch: 6| Step: 13
Training loss: 1.441356897354126
Validation loss: 2.179323216279348

Epoch: 203| Step: 0
Training loss: 1.3009133338928223
Validation loss: 2.1587920983632407

Epoch: 6| Step: 1
Training loss: 2.2114615440368652
Validation loss: 2.1539046367009482

Epoch: 6| Step: 2
Training loss: 1.6713758707046509
Validation loss: 2.1570403774579368

Epoch: 6| Step: 3
Training loss: 1.5864436626434326
Validation loss: 2.1807862520217896

Epoch: 6| Step: 4
Training loss: 2.747718334197998
Validation loss: 2.170010725657145

Epoch: 6| Step: 5
Training loss: 1.3552472591400146
Validation loss: 2.175312797228495

Epoch: 6| Step: 6
Training loss: 1.6399495601654053
Validation loss: 2.160140951474508

Epoch: 6| Step: 7
Training loss: 1.9708530902862549
Validation loss: 2.172966400782267

Epoch: 6| Step: 8
Training loss: 1.8677133321762085
Validation loss: 2.1632458567619324

Epoch: 6| Step: 9
Training loss: 1.737630009651184
Validation loss: 2.1662959456443787

Epoch: 6| Step: 10
Training loss: 1.7215803861618042
Validation loss: 2.181154410044352

Epoch: 6| Step: 11
Training loss: 1.7384806871414185
Validation loss: 2.200786312421163

Epoch: 6| Step: 12
Training loss: 2.2193150520324707
Validation loss: 2.1960344115893045

Epoch: 6| Step: 13
Training loss: 1.9913396835327148
Validation loss: 2.188642938931783

Epoch: 204| Step: 0
Training loss: 1.785158395767212
Validation loss: 2.1638998786608377

Epoch: 6| Step: 1
Training loss: 2.392343282699585
Validation loss: 2.180331607659658

Epoch: 6| Step: 2
Training loss: 1.6865534782409668
Validation loss: 2.1633612513542175

Epoch: 6| Step: 3
Training loss: 1.346212387084961
Validation loss: 2.1718314488728843

Epoch: 6| Step: 4
Training loss: 1.4337501525878906
Validation loss: 2.1785242358843484

Epoch: 6| Step: 5
Training loss: 2.5105655193328857
Validation loss: 2.1939849853515625

Epoch: 6| Step: 6
Training loss: 1.639492392539978
Validation loss: 2.195456107457479

Epoch: 6| Step: 7
Training loss: 1.5604819059371948
Validation loss: 2.184547781944275

Epoch: 6| Step: 8
Training loss: 2.11602783203125
Validation loss: 2.196820398171743

Epoch: 6| Step: 9
Training loss: 1.73538076877594
Validation loss: 2.1866816679636636

Epoch: 6| Step: 10
Training loss: 1.6471073627471924
Validation loss: 2.182427406311035

Epoch: 6| Step: 11
Training loss: 1.9996914863586426
Validation loss: 2.177863339583079

Epoch: 6| Step: 12
Training loss: 1.5845307111740112
Validation loss: 2.185917099316915

Epoch: 6| Step: 13
Training loss: 2.1185784339904785
Validation loss: 2.165514866511027

Epoch: 205| Step: 0
Training loss: 2.2223739624023438
Validation loss: 2.138006607691447

Epoch: 6| Step: 1
Training loss: 2.363712787628174
Validation loss: 2.1348384420077005

Epoch: 6| Step: 2
Training loss: 1.8635845184326172
Validation loss: 2.122839093208313

Epoch: 6| Step: 3
Training loss: 2.268153190612793
Validation loss: 2.111157854398092

Epoch: 6| Step: 4
Training loss: 2.0960946083068848
Validation loss: 2.100976268450419

Epoch: 6| Step: 5
Training loss: 1.470940351486206
Validation loss: 2.1154238184293113

Epoch: 6| Step: 6
Training loss: 2.02811861038208
Validation loss: 2.114942451318105

Epoch: 6| Step: 7
Training loss: 1.7605512142181396
Validation loss: 2.114848872025808

Epoch: 6| Step: 8
Training loss: 1.7493677139282227
Validation loss: 2.111794432004293

Epoch: 6| Step: 9
Training loss: 2.7387404441833496
Validation loss: 2.114639083544413

Epoch: 6| Step: 10
Training loss: 1.7462232112884521
Validation loss: 2.1184189915657043

Epoch: 6| Step: 11
Training loss: 1.5104068517684937
Validation loss: 2.1248536308606467

Epoch: 6| Step: 12
Training loss: 2.126253366470337
Validation loss: 2.129201889038086

Epoch: 6| Step: 13
Training loss: 1.4502949714660645
Validation loss: 2.144540806611379

Epoch: 206| Step: 0
Training loss: 1.6610814332962036
Validation loss: 2.1375120679537454

Epoch: 6| Step: 1
Training loss: 1.4641854763031006
Validation loss: 2.139022648334503

Epoch: 6| Step: 2
Training loss: 2.2578649520874023
Validation loss: 2.1629822850227356

Epoch: 6| Step: 3
Training loss: 1.4650863409042358
Validation loss: 2.1630027691523233

Epoch: 6| Step: 4
Training loss: 1.8775899410247803
Validation loss: 2.1579286058743796

Epoch: 6| Step: 5
Training loss: 1.7614071369171143
Validation loss: 2.1655999422073364

Epoch: 6| Step: 6
Training loss: 1.8271052837371826
Validation loss: 2.1537310083707175

Epoch: 6| Step: 7
Training loss: 1.7476110458374023
Validation loss: 2.1462039947509766

Epoch: 6| Step: 8
Training loss: 2.3838062286376953
Validation loss: 2.1290282011032104

Epoch: 6| Step: 9
Training loss: 1.7225160598754883
Validation loss: 2.1217107574144998

Epoch: 6| Step: 10
Training loss: 2.7181687355041504
Validation loss: 2.1274875601132712

Epoch: 6| Step: 11
Training loss: 2.2633349895477295
Validation loss: 2.1377660433451333

Epoch: 6| Step: 12
Training loss: 1.3465157747268677
Validation loss: 2.122334281603495

Epoch: 6| Step: 13
Training loss: 1.70503830909729
Validation loss: 2.1210578083992004

Epoch: 207| Step: 0
Training loss: 2.5420868396759033
Validation loss: 2.1215445597966514

Epoch: 6| Step: 1
Training loss: 1.6849133968353271
Validation loss: 2.109230915705363

Epoch: 6| Step: 2
Training loss: 2.015770673751831
Validation loss: 2.113398849964142

Epoch: 6| Step: 3
Training loss: 1.3114906549453735
Validation loss: 2.1077491641044617

Epoch: 6| Step: 4
Training loss: 1.350883960723877
Validation loss: 2.1298331022262573

Epoch: 6| Step: 5
Training loss: 2.378540515899658
Validation loss: 2.132561425367991

Epoch: 6| Step: 6
Training loss: 2.5319314002990723
Validation loss: 2.1303178866704306

Epoch: 6| Step: 7
Training loss: 1.7537449598312378
Validation loss: 2.139345129330953

Epoch: 6| Step: 8
Training loss: 1.8809607028961182
Validation loss: 2.155927538871765

Epoch: 6| Step: 9
Training loss: 1.7411859035491943
Validation loss: 2.154178559780121

Epoch: 6| Step: 10
Training loss: 1.7336028814315796
Validation loss: 2.156818389892578

Epoch: 6| Step: 11
Training loss: 2.0099916458129883
Validation loss: 2.1790798107783

Epoch: 6| Step: 12
Training loss: 1.5025653839111328
Validation loss: 2.1841477155685425

Epoch: 6| Step: 13
Training loss: 2.2786450386047363
Validation loss: 2.190373500188192

Epoch: 208| Step: 0
Training loss: 1.9986684322357178
Validation loss: 2.1882996757825217

Epoch: 6| Step: 1
Training loss: 2.359384536743164
Validation loss: 2.1909217635790506

Epoch: 6| Step: 2
Training loss: 2.2227163314819336
Validation loss: 2.189968983332316

Epoch: 6| Step: 3
Training loss: 1.5902668237686157
Validation loss: 2.1936688820521035

Epoch: 6| Step: 4
Training loss: 2.052293062210083
Validation loss: 2.1792489687601724

Epoch: 6| Step: 5
Training loss: 1.878539800643921
Validation loss: 2.1823763052622476

Epoch: 6| Step: 6
Training loss: 1.8363163471221924
Validation loss: 2.178149183591207

Epoch: 6| Step: 7
Training loss: 1.638243556022644
Validation loss: 2.1907330552736917

Epoch: 6| Step: 8
Training loss: 1.4790983200073242
Validation loss: 2.1776793599128723

Epoch: 6| Step: 9
Training loss: 1.504049301147461
Validation loss: 2.17869766553243

Epoch: 6| Step: 10
Training loss: 1.6794224977493286
Validation loss: 2.1844945748647056

Epoch: 6| Step: 11
Training loss: 1.7696884870529175
Validation loss: 2.1735201478004456

Epoch: 6| Step: 12
Training loss: 1.6922614574432373
Validation loss: 2.1683741211891174

Epoch: 6| Step: 13
Training loss: 1.5110188722610474
Validation loss: 2.171653668085734

Epoch: 209| Step: 0
Training loss: 2.1966536045074463
Validation loss: 2.1496581037839255

Epoch: 6| Step: 1
Training loss: 1.7518608570098877
Validation loss: 2.1662979125976562

Epoch: 6| Step: 2
Training loss: 1.33922278881073
Validation loss: 2.14739582935969

Epoch: 6| Step: 3
Training loss: 2.1817970275878906
Validation loss: 2.1544212102890015

Epoch: 6| Step: 4
Training loss: 1.8700594902038574
Validation loss: 2.1446480552355447

Epoch: 6| Step: 5
Training loss: 1.4585753679275513
Validation loss: 2.164652685324351

Epoch: 6| Step: 6
Training loss: 2.569425106048584
Validation loss: 2.1522385478019714

Epoch: 6| Step: 7
Training loss: 1.4859201908111572
Validation loss: 2.1527101596196494

Epoch: 6| Step: 8
Training loss: 1.680060625076294
Validation loss: 2.167476932207743

Epoch: 6| Step: 9
Training loss: 2.0000808238983154
Validation loss: 2.165942629178365

Epoch: 6| Step: 10
Training loss: 2.208660125732422
Validation loss: 2.1750925183296204

Epoch: 6| Step: 11
Training loss: 1.8066964149475098
Validation loss: 2.178472101688385

Epoch: 6| Step: 12
Training loss: 1.602493405342102
Validation loss: 2.1523467103640237

Epoch: 6| Step: 13
Training loss: 1.3691853284835815
Validation loss: 2.15587709347407

Epoch: 210| Step: 0
Training loss: 1.9404445886611938
Validation loss: 2.1759124398231506

Epoch: 6| Step: 1
Training loss: 1.6966919898986816
Validation loss: 2.1658591628074646

Epoch: 6| Step: 2
Training loss: 1.7712807655334473
Validation loss: 2.1870387395222983

Epoch: 6| Step: 3
Training loss: 1.3576138019561768
Validation loss: 2.169846494992574

Epoch: 6| Step: 4
Training loss: 1.3213417530059814
Validation loss: 2.1814501881599426

Epoch: 6| Step: 5
Training loss: 1.787005066871643
Validation loss: 2.1606485843658447

Epoch: 6| Step: 6
Training loss: 2.6497769355773926
Validation loss: 2.1701160669326782

Epoch: 6| Step: 7
Training loss: 2.1061627864837646
Validation loss: 2.175605535507202

Epoch: 6| Step: 8
Training loss: 2.2349395751953125
Validation loss: 2.19369508822759

Epoch: 6| Step: 9
Training loss: 1.7994728088378906
Validation loss: 2.1881230076154075

Epoch: 6| Step: 10
Training loss: 1.8749291896820068
Validation loss: 2.1813143690427146

Epoch: 6| Step: 11
Training loss: 1.3776943683624268
Validation loss: 2.1663401126861572

Epoch: 6| Step: 12
Training loss: 2.0619215965270996
Validation loss: 2.1745208303133645

Epoch: 6| Step: 13
Training loss: 1.3562160730361938
Validation loss: 2.1667742331822715

Epoch: 211| Step: 0
Training loss: 2.059469223022461
Validation loss: 2.1653188467025757

Epoch: 6| Step: 1
Training loss: 1.9970171451568604
Validation loss: 2.18741367260615

Epoch: 6| Step: 2
Training loss: 1.7952667474746704
Validation loss: 2.159246106942495

Epoch: 6| Step: 3
Training loss: 1.9270644187927246
Validation loss: 2.179430663585663

Epoch: 6| Step: 4
Training loss: 1.5122157335281372
Validation loss: 2.175256848335266

Epoch: 6| Step: 5
Training loss: 1.5982081890106201
Validation loss: 2.1925774614016214

Epoch: 6| Step: 6
Training loss: 2.153524398803711
Validation loss: 2.216526746749878

Epoch: 6| Step: 7
Training loss: 2.246293067932129
Validation loss: 2.210678537686666

Epoch: 6| Step: 8
Training loss: 1.8422431945800781
Validation loss: 2.192781647046407

Epoch: 6| Step: 9
Training loss: 1.4465053081512451
Validation loss: 2.2218370040257773

Epoch: 6| Step: 10
Training loss: 2.093222141265869
Validation loss: 2.2042752504348755

Epoch: 6| Step: 11
Training loss: 1.5392752885818481
Validation loss: 2.1888895630836487

Epoch: 6| Step: 12
Training loss: 1.4511058330535889
Validation loss: 2.1911489566167197

Epoch: 6| Step: 13
Training loss: 1.6947271823883057
Validation loss: 2.2035815119743347

Epoch: 212| Step: 0
Training loss: 1.4394214153289795
Validation loss: 2.1753209233283997

Epoch: 6| Step: 1
Training loss: 2.031571388244629
Validation loss: 2.162455677986145

Epoch: 6| Step: 2
Training loss: 1.7123230695724487
Validation loss: 2.15998367468516

Epoch: 6| Step: 3
Training loss: 1.730647325515747
Validation loss: 2.158145268758138

Epoch: 6| Step: 4
Training loss: 2.321653127670288
Validation loss: 2.154501179854075

Epoch: 6| Step: 5
Training loss: 1.3421732187271118
Validation loss: 2.167858064174652

Epoch: 6| Step: 6
Training loss: 2.0085105895996094
Validation loss: 2.162640651067098

Epoch: 6| Step: 7
Training loss: 1.9911054372787476
Validation loss: 2.1561339298884072

Epoch: 6| Step: 8
Training loss: 1.6597472429275513
Validation loss: 2.1947535276412964

Epoch: 6| Step: 9
Training loss: 2.0178258419036865
Validation loss: 2.177479108174642

Epoch: 6| Step: 10
Training loss: 1.7735836505889893
Validation loss: 2.175443450609843

Epoch: 6| Step: 11
Training loss: 1.8911688327789307
Validation loss: 2.1869990825653076

Epoch: 6| Step: 12
Training loss: 1.7934391498565674
Validation loss: 2.1779290636380515

Epoch: 6| Step: 13
Training loss: 1.792209506034851
Validation loss: 2.177932024002075

Epoch: 213| Step: 0
Training loss: 1.597062349319458
Validation loss: 2.191642959912618

Epoch: 6| Step: 1
Training loss: 1.9789236783981323
Validation loss: 2.189631621042887

Epoch: 6| Step: 2
Training loss: 1.2632200717926025
Validation loss: 2.191992918650309

Epoch: 6| Step: 3
Training loss: 1.3425778150558472
Validation loss: 2.2140886386235556

Epoch: 6| Step: 4
Training loss: 1.436241865158081
Validation loss: 2.1967936754226685

Epoch: 6| Step: 5
Training loss: 1.7631731033325195
Validation loss: 2.1877800822257996

Epoch: 6| Step: 6
Training loss: 2.2556800842285156
Validation loss: 2.1879666646321616

Epoch: 6| Step: 7
Training loss: 2.2370896339416504
Validation loss: 2.194250841935476

Epoch: 6| Step: 8
Training loss: 1.9120960235595703
Validation loss: 2.1608285903930664

Epoch: 6| Step: 9
Training loss: 1.60407555103302
Validation loss: 2.1936633785565696

Epoch: 6| Step: 10
Training loss: 2.256667375564575
Validation loss: 2.185192902882894

Epoch: 6| Step: 11
Training loss: 1.768496036529541
Validation loss: 2.1633620858192444

Epoch: 6| Step: 12
Training loss: 2.2177071571350098
Validation loss: 2.1597993572553

Epoch: 6| Step: 13
Training loss: 1.4983214139938354
Validation loss: 2.147287964820862

Epoch: 214| Step: 0
Training loss: 1.9636080265045166
Validation loss: 2.1515042781829834

Epoch: 6| Step: 1
Training loss: 1.8436939716339111
Validation loss: 2.149774452050527

Epoch: 6| Step: 2
Training loss: 2.0855250358581543
Validation loss: 2.127192954222361

Epoch: 6| Step: 3
Training loss: 1.9478291273117065
Validation loss: 2.145559330781301

Epoch: 6| Step: 4
Training loss: 1.4296586513519287
Validation loss: 2.143687605857849

Epoch: 6| Step: 5
Training loss: 2.290992259979248
Validation loss: 2.158763885498047

Epoch: 6| Step: 6
Training loss: 1.6139929294586182
Validation loss: 2.1698013146718345

Epoch: 6| Step: 7
Training loss: 1.6872721910476685
Validation loss: 2.20966770251592

Epoch: 6| Step: 8
Training loss: 1.9039522409439087
Validation loss: 2.1640387773513794

Epoch: 6| Step: 9
Training loss: 1.9638125896453857
Validation loss: 2.18109784523646

Epoch: 6| Step: 10
Training loss: 1.561385154724121
Validation loss: 2.190661052862803

Epoch: 6| Step: 11
Training loss: 1.9837312698364258
Validation loss: 2.165748139222463

Epoch: 6| Step: 12
Training loss: 1.639143466949463
Validation loss: 2.1833717823028564

Epoch: 6| Step: 13
Training loss: 2.6776998043060303
Validation loss: 2.1806422074635825

Epoch: 215| Step: 0
Training loss: 1.314300775527954
Validation loss: 2.134706179300944

Epoch: 6| Step: 1
Training loss: 1.5681560039520264
Validation loss: 2.1250338753064475

Epoch: 6| Step: 2
Training loss: 1.840390682220459
Validation loss: 2.111866593360901

Epoch: 6| Step: 3
Training loss: 2.1697897911071777
Validation loss: 2.1076818704605103

Epoch: 6| Step: 4
Training loss: 1.9217910766601562
Validation loss: 2.0903313159942627

Epoch: 6| Step: 5
Training loss: 2.0382471084594727
Validation loss: 2.0828044215838113

Epoch: 6| Step: 6
Training loss: 1.6103391647338867
Validation loss: 2.0974766612052917

Epoch: 6| Step: 7
Training loss: 1.8458863496780396
Validation loss: 2.091086765130361

Epoch: 6| Step: 8
Training loss: 1.8483725786209106
Validation loss: 2.1086650292078652

Epoch: 6| Step: 9
Training loss: 1.5653352737426758
Validation loss: 2.1143614848454795

Epoch: 6| Step: 10
Training loss: 2.6314332485198975
Validation loss: 2.112740973631541

Epoch: 6| Step: 11
Training loss: 1.9873170852661133
Validation loss: 2.1108839313189187

Epoch: 6| Step: 12
Training loss: 1.949519157409668
Validation loss: 2.119127035140991

Epoch: 6| Step: 13
Training loss: 1.6638765335083008
Validation loss: 2.117798407872518

Epoch: 216| Step: 0
Training loss: 1.6710528135299683
Validation loss: 2.131863792737325

Epoch: 6| Step: 1
Training loss: 1.253989338874817
Validation loss: 2.138253470261892

Epoch: 6| Step: 2
Training loss: 2.544167995452881
Validation loss: 2.161337455113729

Epoch: 6| Step: 3
Training loss: 1.6272746324539185
Validation loss: 2.159201165040334

Epoch: 6| Step: 4
Training loss: 1.609571933746338
Validation loss: 2.165701369444529

Epoch: 6| Step: 5
Training loss: 1.815454363822937
Validation loss: 2.1879327297210693

Epoch: 6| Step: 6
Training loss: 1.446576714515686
Validation loss: 2.1722790598869324

Epoch: 6| Step: 7
Training loss: 1.567575216293335
Validation loss: 2.168858071168264

Epoch: 6| Step: 8
Training loss: 1.8553707599639893
Validation loss: 2.1783732970555625

Epoch: 6| Step: 9
Training loss: 1.629722237586975
Validation loss: 2.18157551685969

Epoch: 6| Step: 10
Training loss: 2.2169227600097656
Validation loss: 2.168568174044291

Epoch: 6| Step: 11
Training loss: 2.462153911590576
Validation loss: 2.165272076924642

Epoch: 6| Step: 12
Training loss: 2.2086071968078613
Validation loss: 2.1643541852633157

Epoch: 6| Step: 13
Training loss: 1.40312922000885
Validation loss: 2.153311332066854

Epoch: 217| Step: 0
Training loss: 1.4754846096038818
Validation loss: 2.161738634109497

Epoch: 6| Step: 1
Training loss: 1.9390513896942139
Validation loss: 2.160482327143351

Epoch: 6| Step: 2
Training loss: 1.1921820640563965
Validation loss: 2.174008289972941

Epoch: 6| Step: 3
Training loss: 1.9736340045928955
Validation loss: 2.1496912837028503

Epoch: 6| Step: 4
Training loss: 1.842134952545166
Validation loss: 2.1543588836987815

Epoch: 6| Step: 5
Training loss: 1.8813252449035645
Validation loss: 2.1735111474990845

Epoch: 6| Step: 6
Training loss: 2.2156691551208496
Validation loss: 2.1688952843348184

Epoch: 6| Step: 7
Training loss: 2.1034348011016846
Validation loss: 2.1501236160596213

Epoch: 6| Step: 8
Training loss: 2.673461437225342
Validation loss: 2.1537782748540244

Epoch: 6| Step: 9
Training loss: 1.3402838706970215
Validation loss: 2.174560248851776

Epoch: 6| Step: 10
Training loss: 1.3688452243804932
Validation loss: 2.165619512399038

Epoch: 6| Step: 11
Training loss: 1.4706742763519287
Validation loss: 2.1678890585899353

Epoch: 6| Step: 12
Training loss: 2.177457332611084
Validation loss: 2.1803616881370544

Epoch: 6| Step: 13
Training loss: 1.5864019393920898
Validation loss: 2.1895092328389487

Epoch: 218| Step: 0
Training loss: 2.718430280685425
Validation loss: 2.1594636042912803

Epoch: 6| Step: 1
Training loss: 1.2418122291564941
Validation loss: 2.1735556920369468

Epoch: 6| Step: 2
Training loss: 1.6439062356948853
Validation loss: 2.160828868548075

Epoch: 6| Step: 3
Training loss: 1.6085667610168457
Validation loss: 2.1775858203570047

Epoch: 6| Step: 4
Training loss: 1.8624236583709717
Validation loss: 2.160805026690165

Epoch: 6| Step: 5
Training loss: 2.057265281677246
Validation loss: 2.1623565355936685

Epoch: 6| Step: 6
Training loss: 1.6228203773498535
Validation loss: 2.168745994567871

Epoch: 6| Step: 7
Training loss: 2.2628655433654785
Validation loss: 2.1609883109728494

Epoch: 6| Step: 8
Training loss: 1.0804872512817383
Validation loss: 2.1740635434786477

Epoch: 6| Step: 9
Training loss: 2.315127372741699
Validation loss: 2.160006364186605

Epoch: 6| Step: 10
Training loss: 1.7209112644195557
Validation loss: 2.17573618888855

Epoch: 6| Step: 11
Training loss: 0.9104379415512085
Validation loss: 2.1587474743525186

Epoch: 6| Step: 12
Training loss: 2.3341875076293945
Validation loss: 2.1575056513150535

Epoch: 6| Step: 13
Training loss: 1.8292884826660156
Validation loss: 2.174730976422628

Epoch: 219| Step: 0
Training loss: 1.9424166679382324
Validation loss: 2.17265248298645

Epoch: 6| Step: 1
Training loss: 2.1840429306030273
Validation loss: 2.1654266119003296

Epoch: 6| Step: 2
Training loss: 1.8014945983886719
Validation loss: 2.1637242833773294

Epoch: 6| Step: 3
Training loss: 2.060673713684082
Validation loss: 2.175339380900065

Epoch: 6| Step: 4
Training loss: 1.3711799383163452
Validation loss: 2.1650896469751992

Epoch: 6| Step: 5
Training loss: 1.743472933769226
Validation loss: 2.1897156635920205

Epoch: 6| Step: 6
Training loss: 1.6726572513580322
Validation loss: 2.183148821194967

Epoch: 6| Step: 7
Training loss: 2.4697909355163574
Validation loss: 2.1750547885894775

Epoch: 6| Step: 8
Training loss: 2.385641574859619
Validation loss: 2.198334495226542

Epoch: 6| Step: 9
Training loss: 1.2479307651519775
Validation loss: 2.1789924701054892

Epoch: 6| Step: 10
Training loss: 1.707721471786499
Validation loss: 2.1860976616541543

Epoch: 6| Step: 11
Training loss: 2.1081185340881348
Validation loss: 2.1994269688924155

Epoch: 6| Step: 12
Training loss: 1.7818855047225952
Validation loss: 2.1867762207984924

Epoch: 6| Step: 13
Training loss: 0.9552080631256104
Validation loss: 2.1782110134760537

Epoch: 220| Step: 0
Training loss: 1.5318374633789062
Validation loss: 2.1797079046567283

Epoch: 6| Step: 1
Training loss: 2.0325539112091064
Validation loss: 2.185133635997772

Epoch: 6| Step: 2
Training loss: 1.545022964477539
Validation loss: 2.159677724043528

Epoch: 6| Step: 3
Training loss: 1.8908746242523193
Validation loss: 2.160533308982849

Epoch: 6| Step: 4
Training loss: 2.0747694969177246
Validation loss: 2.1715557972590127

Epoch: 6| Step: 5
Training loss: 1.2662432193756104
Validation loss: 2.164698839187622

Epoch: 6| Step: 6
Training loss: 1.6539725065231323
Validation loss: 2.1889196634292603

Epoch: 6| Step: 7
Training loss: 2.489036798477173
Validation loss: 2.163553218046824

Epoch: 6| Step: 8
Training loss: 1.958828091621399
Validation loss: 2.174980560938517

Epoch: 6| Step: 9
Training loss: 1.570449948310852
Validation loss: 2.181540628274282

Epoch: 6| Step: 10
Training loss: 2.082254409790039
Validation loss: 2.1656622091929116

Epoch: 6| Step: 11
Training loss: 1.7950948476791382
Validation loss: 2.1579293608665466

Epoch: 6| Step: 12
Training loss: 1.7497117519378662
Validation loss: 2.142334798971812

Epoch: 6| Step: 13
Training loss: 1.504434585571289
Validation loss: 2.142363210519155

Epoch: 221| Step: 0
Training loss: 1.7512681484222412
Validation loss: 2.1670812567075095

Epoch: 6| Step: 1
Training loss: 1.5744363069534302
Validation loss: 2.1620986660321555

Epoch: 6| Step: 2
Training loss: 1.6608262062072754
Validation loss: 2.151970605055491

Epoch: 6| Step: 3
Training loss: 2.5846915245056152
Validation loss: 2.1742859284083047

Epoch: 6| Step: 4
Training loss: 1.606404423713684
Validation loss: 2.1884251832962036

Epoch: 6| Step: 5
Training loss: 1.3754547834396362
Validation loss: 2.1684765418370566

Epoch: 6| Step: 6
Training loss: 2.4769766330718994
Validation loss: 2.180897374947866

Epoch: 6| Step: 7
Training loss: 1.7722030878067017
Validation loss: 2.1774246096611023

Epoch: 6| Step: 8
Training loss: 2.04783296585083
Validation loss: 2.1877888441085815

Epoch: 6| Step: 9
Training loss: 1.7816505432128906
Validation loss: 2.1951748728752136

Epoch: 6| Step: 10
Training loss: 1.3998078107833862
Validation loss: 2.188666820526123

Epoch: 6| Step: 11
Training loss: 1.761134386062622
Validation loss: 2.2146401604016623

Epoch: 6| Step: 12
Training loss: 1.4745242595672607
Validation loss: 2.216370681921641

Epoch: 6| Step: 13
Training loss: 1.9496779441833496
Validation loss: 2.1880534291267395

Epoch: 222| Step: 0
Training loss: 1.8387997150421143
Validation loss: 2.1975914239883423

Epoch: 6| Step: 1
Training loss: 1.9570012092590332
Validation loss: 2.197104831536611

Epoch: 6| Step: 2
Training loss: 1.3068201541900635
Validation loss: 2.191208024819692

Epoch: 6| Step: 3
Training loss: 2.077543258666992
Validation loss: 2.179606239000956

Epoch: 6| Step: 4
Training loss: 1.449135422706604
Validation loss: 2.180869380633036

Epoch: 6| Step: 5
Training loss: 1.9011297225952148
Validation loss: 2.1815506418546042

Epoch: 6| Step: 6
Training loss: 1.9443168640136719
Validation loss: 2.1742368936538696

Epoch: 6| Step: 7
Training loss: 1.9262235164642334
Validation loss: 2.1665754914283752

Epoch: 6| Step: 8
Training loss: 1.707162618637085
Validation loss: 2.171005924542745

Epoch: 6| Step: 9
Training loss: 1.9433062076568604
Validation loss: 2.168301264444987

Epoch: 6| Step: 10
Training loss: 1.7237167358398438
Validation loss: 2.1626777251561484

Epoch: 6| Step: 11
Training loss: 1.8525047302246094
Validation loss: 2.172384818394979

Epoch: 6| Step: 12
Training loss: 1.7523490190505981
Validation loss: 2.172561228275299

Epoch: 6| Step: 13
Training loss: 1.9692227840423584
Validation loss: 2.1750005880991616

Epoch: 223| Step: 0
Training loss: 2.179241895675659
Validation loss: 2.153430084387461

Epoch: 6| Step: 1
Training loss: 1.6834810972213745
Validation loss: 2.171051283677419

Epoch: 6| Step: 2
Training loss: 2.2406044006347656
Validation loss: 2.179083247979482

Epoch: 6| Step: 3
Training loss: 1.968511939048767
Validation loss: 2.164200226465861

Epoch: 6| Step: 4
Training loss: 2.2472338676452637
Validation loss: 2.1609646479288735

Epoch: 6| Step: 5
Training loss: 2.3178935050964355
Validation loss: 2.1793686151504517

Epoch: 6| Step: 6
Training loss: 1.2430646419525146
Validation loss: 2.1682469050089517

Epoch: 6| Step: 7
Training loss: 1.237891435623169
Validation loss: 2.161336898803711

Epoch: 6| Step: 8
Training loss: 2.185769557952881
Validation loss: 2.17418505748113

Epoch: 6| Step: 9
Training loss: 1.351347804069519
Validation loss: 2.1932594974835715

Epoch: 6| Step: 10
Training loss: 1.507972240447998
Validation loss: 2.184487799803416

Epoch: 6| Step: 11
Training loss: 1.827985405921936
Validation loss: 2.188345710436503

Epoch: 6| Step: 12
Training loss: 1.567015528678894
Validation loss: 2.1938491662343345

Epoch: 6| Step: 13
Training loss: 1.5527048110961914
Validation loss: 2.196042458216349

Epoch: 224| Step: 0
Training loss: 1.7009152173995972
Validation loss: 2.192060708999634

Epoch: 6| Step: 1
Training loss: 1.8273403644561768
Validation loss: 2.1898112297058105

Epoch: 6| Step: 2
Training loss: 1.6625107526779175
Validation loss: 2.213156779607137

Epoch: 6| Step: 3
Training loss: 1.496671438217163
Validation loss: 2.2047842939694724

Epoch: 6| Step: 4
Training loss: 1.1549760103225708
Validation loss: 2.2005335688591003

Epoch: 6| Step: 5
Training loss: 1.8366039991378784
Validation loss: 2.182488282521566

Epoch: 6| Step: 6
Training loss: 1.8697508573532104
Validation loss: 2.1714012225468955

Epoch: 6| Step: 7
Training loss: 1.924025058746338
Validation loss: 2.1662582953770957

Epoch: 6| Step: 8
Training loss: 1.8937437534332275
Validation loss: 2.177963058153788

Epoch: 6| Step: 9
Training loss: 1.741288423538208
Validation loss: 2.189284880956014

Epoch: 6| Step: 10
Training loss: 2.4279260635375977
Validation loss: 2.1931875149408975

Epoch: 6| Step: 11
Training loss: 2.8495945930480957
Validation loss: 2.2068826158841452

Epoch: 6| Step: 12
Training loss: 1.6868560314178467
Validation loss: 2.1971456011136374

Epoch: 6| Step: 13
Training loss: 1.8313548564910889
Validation loss: 2.1894903977711997

Epoch: 225| Step: 0
Training loss: 1.460675597190857
Validation loss: 2.1849824587504068

Epoch: 6| Step: 1
Training loss: 2.4044270515441895
Validation loss: 2.181362827618917

Epoch: 6| Step: 2
Training loss: 2.137643814086914
Validation loss: 2.1590069929758706

Epoch: 6| Step: 3
Training loss: 1.901965856552124
Validation loss: 2.170099457105001

Epoch: 6| Step: 4
Training loss: 2.1752119064331055
Validation loss: 2.1907444397608438

Epoch: 6| Step: 5
Training loss: 1.1221261024475098
Validation loss: 2.180175224939982

Epoch: 6| Step: 6
Training loss: 1.5821685791015625
Validation loss: 2.169610599676768

Epoch: 6| Step: 7
Training loss: 1.6500861644744873
Validation loss: 2.165616750717163

Epoch: 6| Step: 8
Training loss: 1.3849635124206543
Validation loss: 2.154467821121216

Epoch: 6| Step: 9
Training loss: 1.5530191659927368
Validation loss: 2.160061299800873

Epoch: 6| Step: 10
Training loss: 2.6984946727752686
Validation loss: 2.1638938387235007

Epoch: 6| Step: 11
Training loss: 1.8977124691009521
Validation loss: 2.1560749610265098

Epoch: 6| Step: 12
Training loss: 1.5601093769073486
Validation loss: 2.1433709065119424

Epoch: 6| Step: 13
Training loss: 1.6813955307006836
Validation loss: 2.1513973077138266

Epoch: 226| Step: 0
Training loss: 1.7804431915283203
Validation loss: 2.1347158948580423

Epoch: 6| Step: 1
Training loss: 2.1677844524383545
Validation loss: 2.144400119781494

Epoch: 6| Step: 2
Training loss: 1.9188508987426758
Validation loss: 2.1325812339782715

Epoch: 6| Step: 3
Training loss: 1.55962336063385
Validation loss: 2.1409278512001038

Epoch: 6| Step: 4
Training loss: 1.8598170280456543
Validation loss: 2.138772507508596

Epoch: 6| Step: 5
Training loss: 2.3970189094543457
Validation loss: 2.1384801268577576

Epoch: 6| Step: 6
Training loss: 1.7672706842422485
Validation loss: 2.1381828784942627

Epoch: 6| Step: 7
Training loss: 1.6058423519134521
Validation loss: 2.1483353773752847

Epoch: 6| Step: 8
Training loss: 1.905521273612976
Validation loss: 2.159248689810435

Epoch: 6| Step: 9
Training loss: 1.8032021522521973
Validation loss: 2.1520519256591797

Epoch: 6| Step: 10
Training loss: 1.329628825187683
Validation loss: 2.135467529296875

Epoch: 6| Step: 11
Training loss: 2.02996826171875
Validation loss: 2.1599419514338174

Epoch: 6| Step: 12
Training loss: 1.788323998451233
Validation loss: 2.161504030227661

Epoch: 6| Step: 13
Training loss: 1.4378691911697388
Validation loss: 2.1703612009684243

Epoch: 227| Step: 0
Training loss: 1.0500130653381348
Validation loss: 2.162642558415731

Epoch: 6| Step: 1
Training loss: 1.9799058437347412
Validation loss: 2.190136710802714

Epoch: 6| Step: 2
Training loss: 1.9300252199172974
Validation loss: 2.1807029843330383

Epoch: 6| Step: 3
Training loss: 2.279351234436035
Validation loss: 2.1961711645126343

Epoch: 6| Step: 4
Training loss: 1.6039865016937256
Validation loss: 2.1925954023996987

Epoch: 6| Step: 5
Training loss: 2.425327777862549
Validation loss: 2.178347726662954

Epoch: 6| Step: 6
Training loss: 1.3743541240692139
Validation loss: 2.1950267354647317

Epoch: 6| Step: 7
Training loss: 2.1678006649017334
Validation loss: 2.190950949986776

Epoch: 6| Step: 8
Training loss: 2.0275070667266846
Validation loss: 2.206472913424174

Epoch: 6| Step: 9
Training loss: 1.646741509437561
Validation loss: 2.1884014209111533

Epoch: 6| Step: 10
Training loss: 1.778630018234253
Validation loss: 2.193177858988444

Epoch: 6| Step: 11
Training loss: 1.680717945098877
Validation loss: 2.185336391131083

Epoch: 6| Step: 12
Training loss: 1.3443608283996582
Validation loss: 2.1793221831321716

Epoch: 6| Step: 13
Training loss: 1.6351001262664795
Validation loss: 2.1956725120544434

Epoch: 228| Step: 0
Training loss: 1.7487536668777466
Validation loss: 2.1853206157684326

Epoch: 6| Step: 1
Training loss: 1.643820881843567
Validation loss: 2.182516177495321

Epoch: 6| Step: 2
Training loss: 2.8546600341796875
Validation loss: 2.1734984715779624

Epoch: 6| Step: 3
Training loss: 0.8003515005111694
Validation loss: 2.1836419304211936

Epoch: 6| Step: 4
Training loss: 1.2133899927139282
Validation loss: 2.202423890431722

Epoch: 6| Step: 5
Training loss: 1.7029060125350952
Validation loss: 2.1849158803621926

Epoch: 6| Step: 6
Training loss: 1.827793002128601
Validation loss: 2.187483092149099

Epoch: 6| Step: 7
Training loss: 2.129275321960449
Validation loss: 2.209434529145559

Epoch: 6| Step: 8
Training loss: 1.1787384748458862
Validation loss: 2.2014732162157693

Epoch: 6| Step: 9
Training loss: 1.5427111387252808
Validation loss: 2.1994841496149697

Epoch: 6| Step: 10
Training loss: 1.5720218420028687
Validation loss: 2.216701944669088

Epoch: 6| Step: 11
Training loss: 1.8105833530426025
Validation loss: 2.1966771483421326

Epoch: 6| Step: 12
Training loss: 2.948423147201538
Validation loss: 2.2161134481430054

Epoch: 6| Step: 13
Training loss: 1.749412178993225
Validation loss: 2.1937652230262756

Epoch: 229| Step: 0
Training loss: 1.87096107006073
Validation loss: 2.191068629423777

Epoch: 6| Step: 1
Training loss: 1.2535887956619263
Validation loss: 2.1724000175793967

Epoch: 6| Step: 2
Training loss: 1.7668193578720093
Validation loss: 2.182013988494873

Epoch: 6| Step: 3
Training loss: 1.5277082920074463
Validation loss: 2.184394379456838

Epoch: 6| Step: 4
Training loss: 1.6440699100494385
Validation loss: 2.1584139664967856

Epoch: 6| Step: 5
Training loss: 2.1947436332702637
Validation loss: 2.1676180561383567

Epoch: 6| Step: 6
Training loss: 2.2087674140930176
Validation loss: 2.1572723388671875

Epoch: 6| Step: 7
Training loss: 2.1716058254241943
Validation loss: 2.167736609776815

Epoch: 6| Step: 8
Training loss: 1.8403788805007935
Validation loss: 2.1794371803601584

Epoch: 6| Step: 9
Training loss: 1.6612277030944824
Validation loss: 2.178449114163717

Epoch: 6| Step: 10
Training loss: 2.420898199081421
Validation loss: 2.1850141684214273

Epoch: 6| Step: 11
Training loss: 1.2982113361358643
Validation loss: 2.2096033294995627

Epoch: 6| Step: 12
Training loss: 1.657590627670288
Validation loss: 2.194455405076345

Epoch: 6| Step: 13
Training loss: 1.712475061416626
Validation loss: 2.19291361172994

Epoch: 230| Step: 0
Training loss: 1.6363606452941895
Validation loss: 2.1965321699778237

Epoch: 6| Step: 1
Training loss: 2.6208791732788086
Validation loss: 2.203242222468058

Epoch: 6| Step: 2
Training loss: 1.878925085067749
Validation loss: 2.200616717338562

Epoch: 6| Step: 3
Training loss: 1.479182243347168
Validation loss: 2.217935641606649

Epoch: 6| Step: 4
Training loss: 2.0428080558776855
Validation loss: 2.2236377000808716

Epoch: 6| Step: 5
Training loss: 1.614611029624939
Validation loss: 2.224824527899424

Epoch: 6| Step: 6
Training loss: 1.351660966873169
Validation loss: 2.2025800943374634

Epoch: 6| Step: 7
Training loss: 2.084151029586792
Validation loss: 2.2035143971443176

Epoch: 6| Step: 8
Training loss: 1.5943485498428345
Validation loss: 2.2099421620368958

Epoch: 6| Step: 9
Training loss: 1.516543984413147
Validation loss: 2.203523317972819

Epoch: 6| Step: 10
Training loss: 1.2870962619781494
Validation loss: 2.2050450444221497

Epoch: 6| Step: 11
Training loss: 1.5820153951644897
Validation loss: 2.20744780699412

Epoch: 6| Step: 12
Training loss: 1.6893759965896606
Validation loss: 2.1972217559814453

Epoch: 6| Step: 13
Training loss: 2.364687919616699
Validation loss: 2.206894357999166

Epoch: 231| Step: 0
Training loss: 1.6308355331420898
Validation loss: 2.2030077377955117

Epoch: 6| Step: 1
Training loss: 1.650676965713501
Validation loss: 2.1915852228800454

Epoch: 6| Step: 2
Training loss: 1.1857528686523438
Validation loss: 2.2027788360913596

Epoch: 6| Step: 3
Training loss: 1.4172890186309814
Validation loss: 2.2052879134813943

Epoch: 6| Step: 4
Training loss: 1.4815980195999146
Validation loss: 2.196846048037211

Epoch: 6| Step: 5
Training loss: 2.227839469909668
Validation loss: 2.1990990241368613

Epoch: 6| Step: 6
Training loss: 1.829922080039978
Validation loss: 2.19852747519811

Epoch: 6| Step: 7
Training loss: 1.6876970529556274
Validation loss: 2.194034298261007

Epoch: 6| Step: 8
Training loss: 1.5999841690063477
Validation loss: 2.203940431276957

Epoch: 6| Step: 9
Training loss: 2.2157578468322754
Validation loss: 2.2116045157114663

Epoch: 6| Step: 10
Training loss: 2.1098556518554688
Validation loss: 2.218898296356201

Epoch: 6| Step: 11
Training loss: 2.082749605178833
Validation loss: 2.2095006306966147

Epoch: 6| Step: 12
Training loss: 1.7906758785247803
Validation loss: 2.2201117873191833

Epoch: 6| Step: 13
Training loss: 1.707398772239685
Validation loss: 2.213126540184021

Epoch: 232| Step: 0
Training loss: 1.6257872581481934
Validation loss: 2.216292758782705

Epoch: 6| Step: 1
Training loss: 1.7170393466949463
Validation loss: 2.1941545009613037

Epoch: 6| Step: 2
Training loss: 1.6546450853347778
Validation loss: 2.220826288064321

Epoch: 6| Step: 3
Training loss: 1.5924426317214966
Validation loss: 2.2054126262664795

Epoch: 6| Step: 4
Training loss: 1.9000340700149536
Validation loss: 2.2092550794283548

Epoch: 6| Step: 5
Training loss: 1.725757360458374
Validation loss: 2.221691091855367

Epoch: 6| Step: 6
Training loss: 1.861169457435608
Validation loss: 2.209195872147878

Epoch: 6| Step: 7
Training loss: 1.7223215103149414
Validation loss: 2.18815279006958

Epoch: 6| Step: 8
Training loss: 2.3487467765808105
Validation loss: 2.1947788993517556

Epoch: 6| Step: 9
Training loss: 1.2442491054534912
Validation loss: 2.2104888558387756

Epoch: 6| Step: 10
Training loss: 1.806261420249939
Validation loss: 2.2012242674827576

Epoch: 6| Step: 11
Training loss: 1.4373855590820312
Validation loss: 2.2079248229662576

Epoch: 6| Step: 12
Training loss: 2.2537357807159424
Validation loss: 2.203726569811503

Epoch: 6| Step: 13
Training loss: 1.4069857597351074
Validation loss: 2.198565642038981

Epoch: 233| Step: 0
Training loss: 1.593172311782837
Validation loss: 2.1952001651128135

Epoch: 6| Step: 1
Training loss: 2.041294574737549
Validation loss: 2.1934698621431985

Epoch: 6| Step: 2
Training loss: 2.000554084777832
Validation loss: 2.2007905642191568

Epoch: 6| Step: 3
Training loss: 1.2639409303665161
Validation loss: 2.2141511042912803

Epoch: 6| Step: 4
Training loss: 1.4703673124313354
Validation loss: 2.20587956905365

Epoch: 6| Step: 5
Training loss: 2.052093982696533
Validation loss: 2.206244707107544

Epoch: 6| Step: 6
Training loss: 1.8742597103118896
Validation loss: 2.1991838812828064

Epoch: 6| Step: 7
Training loss: 2.1027419567108154
Validation loss: 2.21345184246699

Epoch: 6| Step: 8
Training loss: 1.494403600692749
Validation loss: 2.2257465521494546

Epoch: 6| Step: 9
Training loss: 1.5809568166732788
Validation loss: 2.215558707714081

Epoch: 6| Step: 10
Training loss: 1.6580491065979004
Validation loss: 2.2344571948051453

Epoch: 6| Step: 11
Training loss: 2.4699182510375977
Validation loss: 2.22033429145813

Epoch: 6| Step: 12
Training loss: 1.634187936782837
Validation loss: 2.214322030544281

Epoch: 6| Step: 13
Training loss: 1.347466230392456
Validation loss: 2.2340288758277893

Epoch: 234| Step: 0
Training loss: 1.4425181150436401
Validation loss: 2.2165501515070596

Epoch: 6| Step: 1
Training loss: 1.2860970497131348
Validation loss: 2.2126086155573526

Epoch: 6| Step: 2
Training loss: 2.049276113510132
Validation loss: 2.213316798210144

Epoch: 6| Step: 3
Training loss: 1.8843779563903809
Validation loss: 2.210950473944346

Epoch: 6| Step: 4
Training loss: 2.228605270385742
Validation loss: 2.215158681074778

Epoch: 6| Step: 5
Training loss: 2.1451170444488525
Validation loss: 2.218656341234843

Epoch: 6| Step: 6
Training loss: 1.8019245862960815
Validation loss: 2.2343334555625916

Epoch: 6| Step: 7
Training loss: 2.245410203933716
Validation loss: 2.2137115597724915

Epoch: 6| Step: 8
Training loss: 1.4801934957504272
Validation loss: 2.2293667793273926

Epoch: 6| Step: 9
Training loss: 1.4099642038345337
Validation loss: 2.2094916502634683

Epoch: 6| Step: 10
Training loss: 1.7558655738830566
Validation loss: 2.206206738948822

Epoch: 6| Step: 11
Training loss: 1.3393936157226562
Validation loss: 2.201308786869049

Epoch: 6| Step: 12
Training loss: 1.6348233222961426
Validation loss: 2.2018498380978904

Epoch: 6| Step: 13
Training loss: 1.8988786935806274
Validation loss: 2.1950342655181885

Epoch: 235| Step: 0
Training loss: 2.0242390632629395
Validation loss: 2.1939189434051514

Epoch: 6| Step: 1
Training loss: 1.982581615447998
Validation loss: 2.1999128262201944

Epoch: 6| Step: 2
Training loss: 1.4175199270248413
Validation loss: 2.1718005537986755

Epoch: 6| Step: 3
Training loss: 1.4783837795257568
Validation loss: 2.17639297246933

Epoch: 6| Step: 4
Training loss: 1.6170176267623901
Validation loss: 2.1807148655255637

Epoch: 6| Step: 5
Training loss: 1.8844372034072876
Validation loss: 2.1860840717951455

Epoch: 6| Step: 6
Training loss: 1.787733793258667
Validation loss: 2.1971799532572427

Epoch: 6| Step: 7
Training loss: 1.13971745967865
Validation loss: 2.193223297595978

Epoch: 6| Step: 8
Training loss: 1.43979811668396
Validation loss: 2.2082715034484863

Epoch: 6| Step: 9
Training loss: 2.4634461402893066
Validation loss: 2.2070608337720237

Epoch: 6| Step: 10
Training loss: 2.388737916946411
Validation loss: 2.1993117531140647

Epoch: 6| Step: 11
Training loss: 2.2392048835754395
Validation loss: 2.2134522000948587

Epoch: 6| Step: 12
Training loss: 1.2604467868804932
Validation loss: 2.2456958293914795

Epoch: 6| Step: 13
Training loss: 1.7570295333862305
Validation loss: 2.235237161318461

Epoch: 236| Step: 0
Training loss: 1.5551707744598389
Validation loss: 2.220030903816223

Epoch: 6| Step: 1
Training loss: 2.003336191177368
Validation loss: 2.240302880605062

Epoch: 6| Step: 2
Training loss: 2.2222349643707275
Validation loss: 2.2305587331453958

Epoch: 6| Step: 3
Training loss: 1.645453929901123
Validation loss: 2.21329402923584

Epoch: 6| Step: 4
Training loss: 1.068274736404419
Validation loss: 2.2213104963302612

Epoch: 6| Step: 5
Training loss: 2.040280818939209
Validation loss: 2.2177861531575522

Epoch: 6| Step: 6
Training loss: 1.1174993515014648
Validation loss: 2.2207113901774087

Epoch: 6| Step: 7
Training loss: 1.6487189531326294
Validation loss: 2.215924600760142

Epoch: 6| Step: 8
Training loss: 1.9227815866470337
Validation loss: 2.2245605190594993

Epoch: 6| Step: 9
Training loss: 1.6904027462005615
Validation loss: 2.2035795052846274

Epoch: 6| Step: 10
Training loss: 2.106112241744995
Validation loss: 2.2073896725972495

Epoch: 6| Step: 11
Training loss: 2.5353875160217285
Validation loss: 2.19928248723348

Epoch: 6| Step: 12
Training loss: 1.8408561944961548
Validation loss: 2.200516144434611

Epoch: 6| Step: 13
Training loss: 1.010784387588501
Validation loss: 2.1954198280970254

Epoch: 237| Step: 0
Training loss: 1.7392148971557617
Validation loss: 2.201203167438507

Epoch: 6| Step: 1
Training loss: 1.6247375011444092
Validation loss: 2.200029134750366

Epoch: 6| Step: 2
Training loss: 2.3222579956054688
Validation loss: 2.1974019606908164

Epoch: 6| Step: 3
Training loss: 2.145296573638916
Validation loss: 2.2022427717844644

Epoch: 6| Step: 4
Training loss: 1.7903738021850586
Validation loss: 2.1926193237304688

Epoch: 6| Step: 5
Training loss: 1.600449562072754
Validation loss: 2.1975227197011313

Epoch: 6| Step: 6
Training loss: 1.8445148468017578
Validation loss: 2.179301301638285

Epoch: 6| Step: 7
Training loss: 1.4311853647232056
Validation loss: 2.194806178410848

Epoch: 6| Step: 8
Training loss: 1.084621787071228
Validation loss: 2.1978649497032166

Epoch: 6| Step: 9
Training loss: 1.3966786861419678
Validation loss: 2.1943085392316184

Epoch: 6| Step: 10
Training loss: 1.897544026374817
Validation loss: 2.2064290046691895

Epoch: 6| Step: 11
Training loss: 1.8120087385177612
Validation loss: 2.1885615388552346

Epoch: 6| Step: 12
Training loss: 1.6646533012390137
Validation loss: 2.1808286905288696

Epoch: 6| Step: 13
Training loss: 2.1601648330688477
Validation loss: 2.1912825107574463

Epoch: 238| Step: 0
Training loss: 1.6320880651474
Validation loss: 2.205801804860433

Epoch: 6| Step: 1
Training loss: 1.9449639320373535
Validation loss: 2.2174907128016152

Epoch: 6| Step: 2
Training loss: 1.3206450939178467
Validation loss: 2.1976335446039834

Epoch: 6| Step: 3
Training loss: 1.5888526439666748
Validation loss: 2.212860902150472

Epoch: 6| Step: 4
Training loss: 1.8220356702804565
Validation loss: 2.2201056679089866

Epoch: 6| Step: 5
Training loss: 1.7781261205673218
Validation loss: 2.2084521651268005

Epoch: 6| Step: 6
Training loss: 1.2843319177627563
Validation loss: 2.224792718887329

Epoch: 6| Step: 7
Training loss: 1.9994759559631348
Validation loss: 2.209516982237498

Epoch: 6| Step: 8
Training loss: 1.466172456741333
Validation loss: 2.225917478402456

Epoch: 6| Step: 9
Training loss: 1.7433415651321411
Validation loss: 2.2049108743667603

Epoch: 6| Step: 10
Training loss: 1.9554787874221802
Validation loss: 2.207608242829641

Epoch: 6| Step: 11
Training loss: 1.7926750183105469
Validation loss: 2.2327709794044495

Epoch: 6| Step: 12
Training loss: 1.8613970279693604
Validation loss: 2.219781438509623

Epoch: 6| Step: 13
Training loss: 2.134894847869873
Validation loss: 2.2331109245618186

Epoch: 239| Step: 0
Training loss: 1.3397798538208008
Validation loss: 2.2209945718447366

Epoch: 6| Step: 1
Training loss: 2.485375165939331
Validation loss: 2.221197028954824

Epoch: 6| Step: 2
Training loss: 1.7542681694030762
Validation loss: 2.2095587054888406

Epoch: 6| Step: 3
Training loss: 1.5490496158599854
Validation loss: 2.2225839098294577

Epoch: 6| Step: 4
Training loss: 2.1020376682281494
Validation loss: 2.1986951430638633

Epoch: 6| Step: 5
Training loss: 1.470409631729126
Validation loss: 2.205853601296743

Epoch: 6| Step: 6
Training loss: 1.4627749919891357
Validation loss: 2.21940008799235

Epoch: 6| Step: 7
Training loss: 1.8419333696365356
Validation loss: 2.2089116970698037

Epoch: 6| Step: 8
Training loss: 1.5106745958328247
Validation loss: 2.2039445439974465

Epoch: 6| Step: 9
Training loss: 1.6203994750976562
Validation loss: 2.1981059511502585

Epoch: 6| Step: 10
Training loss: 2.5132241249084473
Validation loss: 2.2033549149831138

Epoch: 6| Step: 11
Training loss: 1.3225491046905518
Validation loss: 2.1987624168395996

Epoch: 6| Step: 12
Training loss: 1.9991308450698853
Validation loss: 2.201896150906881

Epoch: 6| Step: 13
Training loss: 1.3711470365524292
Validation loss: 2.2092325687408447

Epoch: 240| Step: 0
Training loss: 1.1811368465423584
Validation loss: 2.1957837343215942

Epoch: 6| Step: 1
Training loss: 2.0971553325653076
Validation loss: 2.212475379308065

Epoch: 6| Step: 2
Training loss: 2.1997835636138916
Validation loss: 2.216947396596273

Epoch: 6| Step: 3
Training loss: 1.9580470323562622
Validation loss: 2.1943881511688232

Epoch: 6| Step: 4
Training loss: 1.5213017463684082
Validation loss: 2.1970351934432983

Epoch: 6| Step: 5
Training loss: 1.137852430343628
Validation loss: 2.198908785978953

Epoch: 6| Step: 6
Training loss: 1.1021981239318848
Validation loss: 2.192143440246582

Epoch: 6| Step: 7
Training loss: 1.6798186302185059
Validation loss: 2.1888787349065146

Epoch: 6| Step: 8
Training loss: 1.5484812259674072
Validation loss: 2.2020873030026755

Epoch: 6| Step: 9
Training loss: 1.8351510763168335
Validation loss: 2.1705295642217

Epoch: 6| Step: 10
Training loss: 1.6076593399047852
Validation loss: 2.175058960914612

Epoch: 6| Step: 11
Training loss: 2.35428786277771
Validation loss: 2.211968998114268

Epoch: 6| Step: 12
Training loss: 2.0793232917785645
Validation loss: 2.189470092455546

Epoch: 6| Step: 13
Training loss: 1.8995689153671265
Validation loss: 2.1967124342918396

Epoch: 241| Step: 0
Training loss: 1.5806056261062622
Validation loss: 2.195036152998606

Epoch: 6| Step: 1
Training loss: 1.792076587677002
Validation loss: 2.2057994405428567

Epoch: 6| Step: 2
Training loss: 1.2898058891296387
Validation loss: 2.2054841121037803

Epoch: 6| Step: 3
Training loss: 1.1723942756652832
Validation loss: 2.203585763772329

Epoch: 6| Step: 4
Training loss: 1.4316692352294922
Validation loss: 2.204594393571218

Epoch: 6| Step: 5
Training loss: 1.4563038349151611
Validation loss: 2.2338164846102395

Epoch: 6| Step: 6
Training loss: 2.3696441650390625
Validation loss: 2.2268958489100137

Epoch: 6| Step: 7
Training loss: 1.8129868507385254
Validation loss: 2.2262295484542847

Epoch: 6| Step: 8
Training loss: 1.4416375160217285
Validation loss: 2.211376408735911

Epoch: 6| Step: 9
Training loss: 1.8726520538330078
Validation loss: 2.2121840914090476

Epoch: 6| Step: 10
Training loss: 1.6693227291107178
Validation loss: 2.210954010486603

Epoch: 6| Step: 11
Training loss: 2.0963659286499023
Validation loss: 2.226203719774882

Epoch: 6| Step: 12
Training loss: 1.454871416091919
Validation loss: 2.210165818532308

Epoch: 6| Step: 13
Training loss: 2.630626916885376
Validation loss: 2.258513867855072

Epoch: 242| Step: 0
Training loss: 1.7021812200546265
Validation loss: 2.227008879184723

Epoch: 6| Step: 1
Training loss: 1.848016381263733
Validation loss: 2.2145434617996216

Epoch: 6| Step: 2
Training loss: 1.2429654598236084
Validation loss: 2.229298154513041

Epoch: 6| Step: 3
Training loss: 1.5163164138793945
Validation loss: 2.239214817682902

Epoch: 6| Step: 4
Training loss: 2.0653183460235596
Validation loss: 2.2432565887769065

Epoch: 6| Step: 5
Training loss: 1.8419749736785889
Validation loss: 2.2518732150395713

Epoch: 6| Step: 6
Training loss: 1.7997199296951294
Validation loss: 2.2324761350949607

Epoch: 6| Step: 7
Training loss: 1.9847080707550049
Validation loss: 2.2382795810699463

Epoch: 6| Step: 8
Training loss: 1.4901390075683594
Validation loss: 2.2411587834358215

Epoch: 6| Step: 9
Training loss: 1.719807744026184
Validation loss: 2.2251415848731995

Epoch: 6| Step: 10
Training loss: 1.6359727382659912
Validation loss: 2.243395209312439

Epoch: 6| Step: 11
Training loss: 1.6279761791229248
Validation loss: 2.232600371042887

Epoch: 6| Step: 12
Training loss: 1.8819260597229004
Validation loss: 2.2390097181002298

Epoch: 6| Step: 13
Training loss: 1.5730843544006348
Validation loss: 2.2282917698224387

Epoch: 243| Step: 0
Training loss: 1.8220134973526
Validation loss: 2.226753850777944

Epoch: 6| Step: 1
Training loss: 2.3101720809936523
Validation loss: 2.235701779524485

Epoch: 6| Step: 2
Training loss: 1.2548828125
Validation loss: 2.2101157108942666

Epoch: 6| Step: 3
Training loss: 1.9294424057006836
Validation loss: 2.2226216991742453

Epoch: 6| Step: 4
Training loss: 2.0815248489379883
Validation loss: 2.2124984661738076

Epoch: 6| Step: 5
Training loss: 1.6473404169082642
Validation loss: 2.231427013874054

Epoch: 6| Step: 6
Training loss: 2.149439573287964
Validation loss: 2.1957996090253196

Epoch: 6| Step: 7
Training loss: 1.4941444396972656
Validation loss: 2.1996041735013327

Epoch: 6| Step: 8
Training loss: 1.0680968761444092
Validation loss: 2.2260873119036355

Epoch: 6| Step: 9
Training loss: 2.0516703128814697
Validation loss: 2.2071094314257302

Epoch: 6| Step: 10
Training loss: 1.3888299465179443
Validation loss: 2.2057813008626304

Epoch: 6| Step: 11
Training loss: 1.8320882320404053
Validation loss: 2.195880572001139

Epoch: 6| Step: 12
Training loss: 1.6608942747116089
Validation loss: 2.2145999670028687

Epoch: 6| Step: 13
Training loss: 1.3664981126785278
Validation loss: 2.196190615495046

Epoch: 244| Step: 0
Training loss: 2.126099109649658
Validation loss: 2.247194488843282

Epoch: 6| Step: 1
Training loss: 1.6223855018615723
Validation loss: 2.2359652717908225

Epoch: 6| Step: 2
Training loss: 2.0598413944244385
Validation loss: 2.2467647790908813

Epoch: 6| Step: 3
Training loss: 1.9965267181396484
Validation loss: 2.2359703381856284

Epoch: 6| Step: 4
Training loss: 1.4249082803726196
Validation loss: 2.2388180096944175

Epoch: 6| Step: 5
Training loss: 1.544696569442749
Validation loss: 2.242564857006073

Epoch: 6| Step: 6
Training loss: 1.6935760974884033
Validation loss: 2.2428505023320517

Epoch: 6| Step: 7
Training loss: 1.4211628437042236
Validation loss: 2.252512753009796

Epoch: 6| Step: 8
Training loss: 1.4335179328918457
Validation loss: 2.2472245693206787

Epoch: 6| Step: 9
Training loss: 2.233668088912964
Validation loss: 2.2198922435442605

Epoch: 6| Step: 10
Training loss: 1.3149559497833252
Validation loss: 2.2374815146128335

Epoch: 6| Step: 11
Training loss: 1.5066802501678467
Validation loss: 2.236026485761007

Epoch: 6| Step: 12
Training loss: 1.6931077241897583
Validation loss: 2.202665706475576

Epoch: 6| Step: 13
Training loss: 1.841286301612854
Validation loss: 2.220073084036509

Epoch: 245| Step: 0
Training loss: 2.231776237487793
Validation loss: 2.2076103488604226

Epoch: 6| Step: 1
Training loss: 1.8942798376083374
Validation loss: 2.1603167057037354

Epoch: 6| Step: 2
Training loss: 1.6175074577331543
Validation loss: 2.203006863594055

Epoch: 6| Step: 3
Training loss: 1.1426069736480713
Validation loss: 2.2027114431063333

Epoch: 6| Step: 4
Training loss: 2.4007997512817383
Validation loss: 2.185955842336019

Epoch: 6| Step: 5
Training loss: 1.2346447706222534
Validation loss: 2.214267690976461

Epoch: 6| Step: 6
Training loss: 1.7111091613769531
Validation loss: 2.2210536003112793

Epoch: 6| Step: 7
Training loss: 1.6473746299743652
Validation loss: 2.228329916795095

Epoch: 6| Step: 8
Training loss: 1.5574408769607544
Validation loss: 2.229715804258982

Epoch: 6| Step: 9
Training loss: 2.0592336654663086
Validation loss: 2.2394108374913535

Epoch: 6| Step: 10
Training loss: 1.7246657609939575
Validation loss: 2.2258700132369995

Epoch: 6| Step: 11
Training loss: 1.8101365566253662
Validation loss: 2.211414317289988

Epoch: 6| Step: 12
Training loss: 1.6012545824050903
Validation loss: 2.1928484638532004

Epoch: 6| Step: 13
Training loss: 1.5281782150268555
Validation loss: 2.2085788249969482

Epoch: 246| Step: 0
Training loss: 1.4185874462127686
Validation loss: 2.2189010779062905

Epoch: 6| Step: 1
Training loss: 1.7687246799468994
Validation loss: 2.2100674907366433

Epoch: 6| Step: 2
Training loss: 2.059487819671631
Validation loss: 2.204421023527781

Epoch: 6| Step: 3
Training loss: 2.40031099319458
Validation loss: 2.230426609516144

Epoch: 6| Step: 4
Training loss: 1.5016324520111084
Validation loss: 2.209424634774526

Epoch: 6| Step: 5
Training loss: 1.251570224761963
Validation loss: 2.2433019479115806

Epoch: 6| Step: 6
Training loss: 1.8023170232772827
Validation loss: 2.2261868715286255

Epoch: 6| Step: 7
Training loss: 2.1091771125793457
Validation loss: 2.247467517852783

Epoch: 6| Step: 8
Training loss: 1.3066542148590088
Validation loss: 2.2367248137791953

Epoch: 6| Step: 9
Training loss: 1.3833630084991455
Validation loss: 2.2427493731180825

Epoch: 6| Step: 10
Training loss: 1.9766230583190918
Validation loss: 2.255884806315104

Epoch: 6| Step: 11
Training loss: 1.7129658460617065
Validation loss: 2.2636760473251343

Epoch: 6| Step: 12
Training loss: 1.6439599990844727
Validation loss: 2.2553264498710632

Epoch: 6| Step: 13
Training loss: 1.5887582302093506
Validation loss: 2.2549981077512107

Epoch: 247| Step: 0
Training loss: 1.2574893236160278
Validation loss: 2.284077445665995

Epoch: 6| Step: 1
Training loss: 1.3714301586151123
Validation loss: 2.2580418984095254

Epoch: 6| Step: 2
Training loss: 2.2219090461730957
Validation loss: 2.252499540646871

Epoch: 6| Step: 3
Training loss: 1.6151655912399292
Validation loss: 2.2607527573903403

Epoch: 6| Step: 4
Training loss: 2.090627908706665
Validation loss: 2.237072308858236

Epoch: 6| Step: 5
Training loss: 1.8291184902191162
Validation loss: 2.2510894934336343

Epoch: 6| Step: 6
Training loss: 1.3099784851074219
Validation loss: 2.2611639300982156

Epoch: 6| Step: 7
Training loss: 1.460044026374817
Validation loss: 2.238315999507904

Epoch: 6| Step: 8
Training loss: 1.8938339948654175
Validation loss: 2.2348488569259644

Epoch: 6| Step: 9
Training loss: 2.3755412101745605
Validation loss: 2.2262062629063926

Epoch: 6| Step: 10
Training loss: 1.4470345973968506
Validation loss: 2.217412849267324

Epoch: 6| Step: 11
Training loss: 1.3640209436416626
Validation loss: 2.225209633509318

Epoch: 6| Step: 12
Training loss: 1.8606836795806885
Validation loss: 2.223385810852051

Epoch: 6| Step: 13
Training loss: 2.032982110977173
Validation loss: 2.224643031756083

Epoch: 248| Step: 0
Training loss: 1.3287856578826904
Validation loss: 2.2418292760849

Epoch: 6| Step: 1
Training loss: 1.8646031618118286
Validation loss: 2.253208637237549

Epoch: 6| Step: 2
Training loss: 2.01611065864563
Validation loss: 2.2532437245051065

Epoch: 6| Step: 3
Training loss: 1.697777271270752
Validation loss: 2.239461521307627

Epoch: 6| Step: 4
Training loss: 1.2559782266616821
Validation loss: 2.2552119493484497

Epoch: 6| Step: 5
Training loss: 1.6200090646743774
Validation loss: 2.2429307103157043

Epoch: 6| Step: 6
Training loss: 1.7374807596206665
Validation loss: 2.2145103216171265

Epoch: 6| Step: 7
Training loss: 1.4829356670379639
Validation loss: 2.2342032194137573

Epoch: 6| Step: 8
Training loss: 1.7975022792816162
Validation loss: 2.2289544542630515

Epoch: 6| Step: 9
Training loss: 1.567518949508667
Validation loss: 2.228930711746216

Epoch: 6| Step: 10
Training loss: 2.6486289501190186
Validation loss: 2.209003667036692

Epoch: 6| Step: 11
Training loss: 1.6684560775756836
Validation loss: 2.21528689066569

Epoch: 6| Step: 12
Training loss: 1.4224766492843628
Validation loss: 2.196152985095978

Epoch: 6| Step: 13
Training loss: 1.7751394510269165
Validation loss: 2.221182366212209

Epoch: 249| Step: 0
Training loss: 1.8571505546569824
Validation loss: 2.217292229334513

Epoch: 6| Step: 1
Training loss: 1.5075730085372925
Validation loss: 2.1932700077692666

Epoch: 6| Step: 2
Training loss: 1.827576756477356
Validation loss: 2.209676722685496

Epoch: 6| Step: 3
Training loss: 1.5579004287719727
Validation loss: 2.213436722755432

Epoch: 6| Step: 4
Training loss: 1.197251796722412
Validation loss: 2.244935472806295

Epoch: 6| Step: 5
Training loss: 1.9807714223861694
Validation loss: 2.22645898660024

Epoch: 6| Step: 6
Training loss: 1.3433102369308472
Validation loss: 2.2377963264783225

Epoch: 6| Step: 7
Training loss: 1.6875652074813843
Validation loss: 2.237979213396708

Epoch: 6| Step: 8
Training loss: 1.7996745109558105
Validation loss: 2.232410987218221

Epoch: 6| Step: 9
Training loss: 1.8971936702728271
Validation loss: 2.2662394046783447

Epoch: 6| Step: 10
Training loss: 1.0539114475250244
Validation loss: 2.260681966940562

Epoch: 6| Step: 11
Training loss: 1.853618860244751
Validation loss: 2.2421233654022217

Epoch: 6| Step: 12
Training loss: 2.049323797225952
Validation loss: 2.253182868162791

Epoch: 6| Step: 13
Training loss: 2.078826665878296
Validation loss: 2.2213499546051025

Epoch: 250| Step: 0
Training loss: 1.7410359382629395
Validation loss: 2.2236220836639404

Epoch: 6| Step: 1
Training loss: 1.891005516052246
Validation loss: 2.2290781140327454

Epoch: 6| Step: 2
Training loss: 1.3012843132019043
Validation loss: 2.211836338043213

Epoch: 6| Step: 3
Training loss: 1.3839399814605713
Validation loss: 2.2387470801671348

Epoch: 6| Step: 4
Training loss: 1.8597843647003174
Validation loss: 2.259651223818461

Epoch: 6| Step: 5
Training loss: 1.5263915061950684
Validation loss: 2.2791982293128967

Epoch: 6| Step: 6
Training loss: 1.760329246520996
Validation loss: 2.2656161387761435

Epoch: 6| Step: 7
Training loss: 1.3315755128860474
Validation loss: 2.250476817289988

Epoch: 6| Step: 8
Training loss: 1.7723002433776855
Validation loss: 2.2609105904897056

Epoch: 6| Step: 9
Training loss: 1.7736363410949707
Validation loss: 2.2316890557607016

Epoch: 6| Step: 10
Training loss: 1.5084675550460815
Validation loss: 2.225870966911316

Epoch: 6| Step: 11
Training loss: 2.495150566101074
Validation loss: 2.2078325152397156

Epoch: 6| Step: 12
Training loss: 2.0240321159362793
Validation loss: 2.211184084415436

Epoch: 6| Step: 13
Training loss: 1.7855284214019775
Validation loss: 2.198249022165934

Epoch: 251| Step: 0
Training loss: 1.923485517501831
Validation loss: 2.1937901775042215

Epoch: 6| Step: 1
Training loss: 1.294471025466919
Validation loss: 2.200150708357493

Epoch: 6| Step: 2
Training loss: 1.401569128036499
Validation loss: 2.1978965600331626

Epoch: 6| Step: 3
Training loss: 1.266921043395996
Validation loss: 2.22890035311381

Epoch: 6| Step: 4
Training loss: 1.8790276050567627
Validation loss: 2.2292350133260093

Epoch: 6| Step: 5
Training loss: 1.662264108657837
Validation loss: 2.2618561585744223

Epoch: 6| Step: 6
Training loss: 2.5030322074890137
Validation loss: 2.260983864466349

Epoch: 6| Step: 7
Training loss: 1.970562219619751
Validation loss: 2.2657291690508523

Epoch: 6| Step: 8
Training loss: 1.764710783958435
Validation loss: 2.2574563026428223

Epoch: 6| Step: 9
Training loss: 1.2690443992614746
Validation loss: 2.2462004820505777

Epoch: 6| Step: 10
Training loss: 1.5500109195709229
Validation loss: 2.207557042439779

Epoch: 6| Step: 11
Training loss: 1.8883023262023926
Validation loss: 2.2290385961532593

Epoch: 6| Step: 12
Training loss: 1.5536258220672607
Validation loss: 2.2298502326011658

Epoch: 6| Step: 13
Training loss: 2.1541643142700195
Validation loss: 2.23964387178421

Epoch: 252| Step: 0
Training loss: 1.2717548608779907
Validation loss: 2.2379624048868814

Epoch: 6| Step: 1
Training loss: 1.5594274997711182
Validation loss: 2.245101809501648

Epoch: 6| Step: 2
Training loss: 1.2958378791809082
Validation loss: 2.2277820110321045

Epoch: 6| Step: 3
Training loss: 1.3139004707336426
Validation loss: 2.2255125840504966

Epoch: 6| Step: 4
Training loss: 1.5578700304031372
Validation loss: 2.2558375795682273

Epoch: 6| Step: 5
Training loss: 2.2791552543640137
Validation loss: 2.23387618859609

Epoch: 6| Step: 6
Training loss: 2.28589129447937
Validation loss: 2.2683632373809814

Epoch: 6| Step: 7
Training loss: 2.2080078125
Validation loss: 2.286338488260905

Epoch: 6| Step: 8
Training loss: 1.7788113355636597
Validation loss: 2.2906080881754556

Epoch: 6| Step: 9
Training loss: 1.2607178688049316
Validation loss: 2.2790229121843972

Epoch: 6| Step: 10
Training loss: 2.114439010620117
Validation loss: 2.29234379529953

Epoch: 6| Step: 11
Training loss: 1.9713120460510254
Validation loss: 2.2908321420351663

Epoch: 6| Step: 12
Training loss: 1.3960371017456055
Validation loss: 2.2608858744303384

Epoch: 6| Step: 13
Training loss: 1.954099178314209
Validation loss: 2.2774903178215027

Epoch: 253| Step: 0
Training loss: 2.1390552520751953
Validation loss: 2.2824010054270425

Epoch: 6| Step: 1
Training loss: 1.8829305171966553
Validation loss: 2.2627817392349243

Epoch: 6| Step: 2
Training loss: 1.5085477828979492
Validation loss: 2.2775923212369285

Epoch: 6| Step: 3
Training loss: 1.754487156867981
Validation loss: 2.25236314535141

Epoch: 6| Step: 4
Training loss: 1.4308446645736694
Validation loss: 2.235934853553772

Epoch: 6| Step: 5
Training loss: 2.1749672889709473
Validation loss: 2.2542619109153748

Epoch: 6| Step: 6
Training loss: 1.4175182580947876
Validation loss: 2.2255723079045615

Epoch: 6| Step: 7
Training loss: 1.624910831451416
Validation loss: 2.2185102899869285

Epoch: 6| Step: 8
Training loss: 0.9260899424552917
Validation loss: 2.2218903501828513

Epoch: 6| Step: 9
Training loss: 2.350940704345703
Validation loss: 2.212856570879618

Epoch: 6| Step: 10
Training loss: 2.6147732734680176
Validation loss: 2.22789067029953

Epoch: 6| Step: 11
Training loss: 1.4779362678527832
Validation loss: 2.2253363728523254

Epoch: 6| Step: 12
Training loss: 1.4592013359069824
Validation loss: 2.232508818308512

Epoch: 6| Step: 13
Training loss: 1.483083724975586
Validation loss: 2.2187657554944358

Epoch: 254| Step: 0
Training loss: 1.9681496620178223
Validation loss: 2.2170024712880454

Epoch: 6| Step: 1
Training loss: 1.5182760953903198
Validation loss: 2.230901857217153

Epoch: 6| Step: 2
Training loss: 1.372451901435852
Validation loss: 2.2268805305163064

Epoch: 6| Step: 3
Training loss: 2.33632230758667
Validation loss: 2.2345223824183145

Epoch: 6| Step: 4
Training loss: 1.5493106842041016
Validation loss: 2.228570501009623

Epoch: 6| Step: 5
Training loss: 1.4466793537139893
Validation loss: 2.2049034039179483

Epoch: 6| Step: 6
Training loss: 1.6058878898620605
Validation loss: 2.2268035610516868

Epoch: 6| Step: 7
Training loss: 1.1894564628601074
Validation loss: 2.237520754337311

Epoch: 6| Step: 8
Training loss: 2.3836913108825684
Validation loss: 2.2276643911997476

Epoch: 6| Step: 9
Training loss: 1.7257192134857178
Validation loss: 2.238523483276367

Epoch: 6| Step: 10
Training loss: 1.8406288623809814
Validation loss: 2.2361526489257812

Epoch: 6| Step: 11
Training loss: 1.4451944828033447
Validation loss: 2.247589190800985

Epoch: 6| Step: 12
Training loss: 1.7188122272491455
Validation loss: 2.232327322165171

Epoch: 6| Step: 13
Training loss: 1.599747896194458
Validation loss: 2.2466920614242554

Epoch: 255| Step: 0
Training loss: 1.291137456893921
Validation loss: 2.228482981522878

Epoch: 6| Step: 1
Training loss: 0.8567180633544922
Validation loss: 2.246157705783844

Epoch: 6| Step: 2
Training loss: 2.4112281799316406
Validation loss: 2.26341579357783

Epoch: 6| Step: 3
Training loss: 2.1982290744781494
Validation loss: 2.244619290033976

Epoch: 6| Step: 4
Training loss: 1.817760705947876
Validation loss: 2.2329107324282327

Epoch: 6| Step: 5
Training loss: 1.8335765600204468
Validation loss: 2.2370827198028564

Epoch: 6| Step: 6
Training loss: 1.6644048690795898
Validation loss: 2.220284382502238

Epoch: 6| Step: 7
Training loss: 1.3491137027740479
Validation loss: 2.230849246184031

Epoch: 6| Step: 8
Training loss: 1.4272232055664062
Validation loss: 2.240355690320333

Epoch: 6| Step: 9
Training loss: 1.9640064239501953
Validation loss: 2.246131698290507

Epoch: 6| Step: 10
Training loss: 1.5520386695861816
Validation loss: 2.247950037320455

Epoch: 6| Step: 11
Training loss: 1.6477218866348267
Validation loss: 2.2549909551938376

Epoch: 6| Step: 12
Training loss: 1.389604091644287
Validation loss: 2.2641436656316123

Epoch: 6| Step: 13
Training loss: 2.2041015625
Validation loss: 2.2718759576479592

Epoch: 256| Step: 0
Training loss: 1.5841586589813232
Validation loss: 2.2651936610539756

Epoch: 6| Step: 1
Training loss: 1.694178581237793
Validation loss: 2.249333222707113

Epoch: 6| Step: 2
Training loss: 1.5314180850982666
Validation loss: 2.243108034133911

Epoch: 6| Step: 3
Training loss: 1.805198073387146
Validation loss: 2.2269189755121865

Epoch: 6| Step: 4
Training loss: 1.4873790740966797
Validation loss: 2.219794829686483

Epoch: 6| Step: 5
Training loss: 1.8410837650299072
Validation loss: 2.250417391459147

Epoch: 6| Step: 6
Training loss: 1.6391260623931885
Validation loss: 2.2305446664492288

Epoch: 6| Step: 7
Training loss: 1.7409029006958008
Validation loss: 2.2279199759165444

Epoch: 6| Step: 8
Training loss: 2.2027649879455566
Validation loss: 2.226217051347097

Epoch: 6| Step: 9
Training loss: 1.4823113679885864
Validation loss: 2.2214842438697815

Epoch: 6| Step: 10
Training loss: 1.4398531913757324
Validation loss: 2.230242649714152

Epoch: 6| Step: 11
Training loss: 1.8145567178726196
Validation loss: 2.2206132809321084

Epoch: 6| Step: 12
Training loss: 1.6712586879730225
Validation loss: 2.2312148014704385

Epoch: 6| Step: 13
Training loss: 1.7369518280029297
Validation loss: 2.228940765062968

Epoch: 257| Step: 0
Training loss: 1.1276830434799194
Validation loss: 2.2450684706370034

Epoch: 6| Step: 1
Training loss: 1.9104498624801636
Validation loss: 2.219372590382894

Epoch: 6| Step: 2
Training loss: 1.1989268064498901
Validation loss: 2.2226498325665793

Epoch: 6| Step: 3
Training loss: 1.7009334564208984
Validation loss: 2.2177664041519165

Epoch: 6| Step: 4
Training loss: 1.4727656841278076
Validation loss: 2.218365967273712

Epoch: 6| Step: 5
Training loss: 2.3982510566711426
Validation loss: 2.220998148123423

Epoch: 6| Step: 6
Training loss: 1.7383012771606445
Validation loss: 2.2083900372187295

Epoch: 6| Step: 7
Training loss: 1.4479018449783325
Validation loss: 2.2074977358182273

Epoch: 6| Step: 8
Training loss: 1.208175778388977
Validation loss: 2.2234886089960733

Epoch: 6| Step: 9
Training loss: 1.5303082466125488
Validation loss: 2.20534348487854

Epoch: 6| Step: 10
Training loss: 2.4404895305633545
Validation loss: 2.2347219387690225

Epoch: 6| Step: 11
Training loss: 2.012342691421509
Validation loss: 2.2205753326416016

Epoch: 6| Step: 12
Training loss: 1.8825712203979492
Validation loss: 2.2319045662879944

Epoch: 6| Step: 13
Training loss: 1.5280585289001465
Validation loss: 2.2395657499631247

Epoch: 258| Step: 0
Training loss: 1.6065701246261597
Validation loss: 2.2482327024141946

Epoch: 6| Step: 1
Training loss: 1.2884082794189453
Validation loss: 2.2391231060028076

Epoch: 6| Step: 2
Training loss: 1.613570213317871
Validation loss: 2.278817892074585

Epoch: 6| Step: 3
Training loss: 1.4146292209625244
Validation loss: 2.2324405113855996

Epoch: 6| Step: 4
Training loss: 2.0561418533325195
Validation loss: 2.232409397761027

Epoch: 6| Step: 5
Training loss: 1.7115070819854736
Validation loss: 2.289718528588613

Epoch: 6| Step: 6
Training loss: 2.761746406555176
Validation loss: 2.2681289116541543

Epoch: 6| Step: 7
Training loss: 1.3083887100219727
Validation loss: 2.2524309555689492

Epoch: 6| Step: 8
Training loss: 1.3805325031280518
Validation loss: 2.258941372235616

Epoch: 6| Step: 9
Training loss: 1.6163777112960815
Validation loss: 2.2285115718841553

Epoch: 6| Step: 10
Training loss: 1.5574848651885986
Validation loss: 2.21904855966568

Epoch: 6| Step: 11
Training loss: 2.1332521438598633
Validation loss: 2.196806232134501

Epoch: 6| Step: 12
Training loss: 1.9090765714645386
Validation loss: 2.2084209521611533

Epoch: 6| Step: 13
Training loss: 1.5250630378723145
Validation loss: 2.218770980834961

Epoch: 259| Step: 0
Training loss: 1.9677066802978516
Validation loss: 2.2091834346453347

Epoch: 6| Step: 1
Training loss: 1.5780426263809204
Validation loss: 2.2362947861353555

Epoch: 6| Step: 2
Training loss: 1.6839799880981445
Validation loss: 2.2346797982851663

Epoch: 6| Step: 3
Training loss: 1.2234121561050415
Validation loss: 2.2375484903653464

Epoch: 6| Step: 4
Training loss: 1.8980095386505127
Validation loss: 2.2348116437594094

Epoch: 6| Step: 5
Training loss: 2.196722984313965
Validation loss: 2.2352088491121926

Epoch: 6| Step: 6
Training loss: 1.5138449668884277
Validation loss: 2.2303441166877747

Epoch: 6| Step: 7
Training loss: 1.5909819602966309
Validation loss: 2.2380016247431436

Epoch: 6| Step: 8
Training loss: 2.183976173400879
Validation loss: 2.2310609817504883

Epoch: 6| Step: 9
Training loss: 1.0469096899032593
Validation loss: 2.2324403127034507

Epoch: 6| Step: 10
Training loss: 1.7145476341247559
Validation loss: 2.213546792666117

Epoch: 6| Step: 11
Training loss: 1.1154446601867676
Validation loss: 2.249436060587565

Epoch: 6| Step: 12
Training loss: 1.3898351192474365
Validation loss: 2.233892103036245

Epoch: 6| Step: 13
Training loss: 2.3651838302612305
Validation loss: 2.236963907877604

Epoch: 260| Step: 0
Training loss: 1.022836685180664
Validation loss: 2.2370410760243735

Epoch: 6| Step: 1
Training loss: 1.7516059875488281
Validation loss: 2.2432384490966797

Epoch: 6| Step: 2
Training loss: 1.757835865020752
Validation loss: 2.248649557431539

Epoch: 6| Step: 3
Training loss: 1.8360471725463867
Validation loss: 2.2474085291226706

Epoch: 6| Step: 4
Training loss: 2.2909936904907227
Validation loss: 2.236622174580892

Epoch: 6| Step: 5
Training loss: 1.3964303731918335
Validation loss: 2.2431417306264243

Epoch: 6| Step: 6
Training loss: 1.3942902088165283
Validation loss: 2.2309347788492837

Epoch: 6| Step: 7
Training loss: 1.7667187452316284
Validation loss: 2.2585182587305703

Epoch: 6| Step: 8
Training loss: 1.5427086353302002
Validation loss: 2.2342222134272256

Epoch: 6| Step: 9
Training loss: 1.392392873764038
Validation loss: 2.2519734700520835

Epoch: 6| Step: 10
Training loss: 2.5335376262664795
Validation loss: 2.23467618227005

Epoch: 6| Step: 11
Training loss: 1.0275683403015137
Validation loss: 2.2616724371910095

Epoch: 6| Step: 12
Training loss: 1.9265923500061035
Validation loss: 2.2435482343037925

Epoch: 6| Step: 13
Training loss: 1.3500382900238037
Validation loss: 2.267492731412252

Epoch: 261| Step: 0
Training loss: 1.9985072612762451
Validation loss: 2.2805092334747314

Epoch: 6| Step: 1
Training loss: 1.9480748176574707
Validation loss: 2.244629462560018

Epoch: 6| Step: 2
Training loss: 1.8108748197555542
Validation loss: 2.245528240998586

Epoch: 6| Step: 3
Training loss: 1.5167784690856934
Validation loss: 2.2290035088857016

Epoch: 6| Step: 4
Training loss: 2.4079270362854004
Validation loss: 2.2025373578071594

Epoch: 6| Step: 5
Training loss: 1.10786771774292
Validation loss: 2.2445430755615234

Epoch: 6| Step: 6
Training loss: 1.4626390933990479
Validation loss: 2.2239487767219543

Epoch: 6| Step: 7
Training loss: 1.5282762050628662
Validation loss: 2.2208043932914734

Epoch: 6| Step: 8
Training loss: 1.6463017463684082
Validation loss: 2.213503837585449

Epoch: 6| Step: 9
Training loss: 0.9652429819107056
Validation loss: 2.216463327407837

Epoch: 6| Step: 10
Training loss: 2.0347349643707275
Validation loss: 2.227593024571737

Epoch: 6| Step: 11
Training loss: 1.998122215270996
Validation loss: 2.219613711039225

Epoch: 6| Step: 12
Training loss: 1.4446735382080078
Validation loss: 2.2248108983039856

Epoch: 6| Step: 13
Training loss: 1.7499899864196777
Validation loss: 2.2088251312573752

Epoch: 262| Step: 0
Training loss: 1.0973646640777588
Validation loss: 2.2160361607869468

Epoch: 6| Step: 1
Training loss: 1.7276358604431152
Validation loss: 2.220929443836212

Epoch: 6| Step: 2
Training loss: 1.7804127931594849
Validation loss: 2.212668776512146

Epoch: 6| Step: 3
Training loss: 1.308718204498291
Validation loss: 2.211679756641388

Epoch: 6| Step: 4
Training loss: 1.988792061805725
Validation loss: 2.2109513878822327

Epoch: 6| Step: 5
Training loss: 1.9371955394744873
Validation loss: 2.225031097730001

Epoch: 6| Step: 6
Training loss: 1.8035225868225098
Validation loss: 2.243874947230021

Epoch: 6| Step: 7
Training loss: 1.8491618633270264
Validation loss: 2.234200338522593

Epoch: 6| Step: 8
Training loss: 1.2786977291107178
Validation loss: 2.225886086622874

Epoch: 6| Step: 9
Training loss: 2.1308889389038086
Validation loss: 2.237958550453186

Epoch: 6| Step: 10
Training loss: 1.7482826709747314
Validation loss: 2.204231878121694

Epoch: 6| Step: 11
Training loss: 1.4871782064437866
Validation loss: 2.202755630016327

Epoch: 6| Step: 12
Training loss: 1.7620775699615479
Validation loss: 2.2110336422920227

Epoch: 6| Step: 13
Training loss: 1.7031197547912598
Validation loss: 2.2282881339391074

Epoch: 263| Step: 0
Training loss: 2.530106544494629
Validation loss: 2.2055177688598633

Epoch: 6| Step: 1
Training loss: 1.7953636646270752
Validation loss: 2.2034310499827066

Epoch: 6| Step: 2
Training loss: 1.601752519607544
Validation loss: 2.2076119780540466

Epoch: 6| Step: 3
Training loss: 2.443164825439453
Validation loss: 2.2369746367136636

Epoch: 6| Step: 4
Training loss: 1.487503170967102
Validation loss: 2.234881341457367

Epoch: 6| Step: 5
Training loss: 1.3637025356292725
Validation loss: 2.2348732153574624

Epoch: 6| Step: 6
Training loss: 1.1646300554275513
Validation loss: 2.242319623629252

Epoch: 6| Step: 7
Training loss: 1.712454915046692
Validation loss: 2.2280138731002808

Epoch: 6| Step: 8
Training loss: 1.2670973539352417
Validation loss: 2.2491216460863748

Epoch: 6| Step: 9
Training loss: 2.3924577236175537
Validation loss: 2.2680212457974753

Epoch: 6| Step: 10
Training loss: 1.8374063968658447
Validation loss: 2.225718299547831

Epoch: 6| Step: 11
Training loss: 1.5970970392227173
Validation loss: 2.207268257935842

Epoch: 6| Step: 12
Training loss: 1.779719591140747
Validation loss: 2.1932562987009683

Epoch: 6| Step: 13
Training loss: 1.1200990676879883
Validation loss: 2.205923577149709

Epoch: 264| Step: 0
Training loss: 1.2883572578430176
Validation loss: 2.203363080819448

Epoch: 6| Step: 1
Training loss: 1.9884638786315918
Validation loss: 2.1970165570576987

Epoch: 6| Step: 2
Training loss: 1.427186369895935
Validation loss: 2.210076689720154

Epoch: 6| Step: 3
Training loss: 2.0893466472625732
Validation loss: 2.1974501411120095

Epoch: 6| Step: 4
Training loss: 1.4647666215896606
Validation loss: 2.208197553952535

Epoch: 6| Step: 5
Training loss: 1.6035115718841553
Validation loss: 2.2300997376441956

Epoch: 6| Step: 6
Training loss: 1.941559076309204
Validation loss: 2.224255402882894

Epoch: 6| Step: 7
Training loss: 1.9604642391204834
Validation loss: 2.22844926516215

Epoch: 6| Step: 8
Training loss: 2.3287034034729004
Validation loss: 2.238040645917257

Epoch: 6| Step: 9
Training loss: 1.461775779724121
Validation loss: 2.2316733797391257

Epoch: 6| Step: 10
Training loss: 2.4065375328063965
Validation loss: 2.2468395829200745

Epoch: 6| Step: 11
Training loss: 1.6446516513824463
Validation loss: 2.2459641297658286

Epoch: 6| Step: 12
Training loss: 0.9703120589256287
Validation loss: 2.250288248062134

Epoch: 6| Step: 13
Training loss: 1.1392107009887695
Validation loss: 2.2356177965799966

Epoch: 265| Step: 0
Training loss: 1.4316564798355103
Validation loss: 2.258385876814524

Epoch: 6| Step: 1
Training loss: 2.6104910373687744
Validation loss: 2.2475854555765786

Epoch: 6| Step: 2
Training loss: 1.4094042778015137
Validation loss: 2.214136819044749

Epoch: 6| Step: 3
Training loss: 1.4070439338684082
Validation loss: 2.2398237784703574

Epoch: 6| Step: 4
Training loss: 1.4673645496368408
Validation loss: 2.203569213549296

Epoch: 6| Step: 5
Training loss: 1.3136342763900757
Validation loss: 2.2116986314455667

Epoch: 6| Step: 6
Training loss: 2.4770431518554688
Validation loss: 2.2115122278531394

Epoch: 6| Step: 7
Training loss: 1.8955259323120117
Validation loss: 2.207428812980652

Epoch: 6| Step: 8
Training loss: 1.4205371141433716
Validation loss: 2.1907294193903604

Epoch: 6| Step: 9
Training loss: 1.7080236673355103
Validation loss: 2.196278731028239

Epoch: 6| Step: 10
Training loss: 2.0179283618927
Validation loss: 2.204913636048635

Epoch: 6| Step: 11
Training loss: 1.1071968078613281
Validation loss: 2.2124222119649253

Epoch: 6| Step: 12
Training loss: 1.9236655235290527
Validation loss: 2.2534462412198386

Epoch: 6| Step: 13
Training loss: 1.3918098211288452
Validation loss: 2.245716373125712

Epoch: 266| Step: 0
Training loss: 1.3895230293273926
Validation loss: 2.2663946946461997

Epoch: 6| Step: 1
Training loss: 1.2274527549743652
Validation loss: 2.241287410259247

Epoch: 6| Step: 2
Training loss: 1.9707214832305908
Validation loss: 2.229325453440348

Epoch: 6| Step: 3
Training loss: 1.5647889375686646
Validation loss: 2.2443140745162964

Epoch: 6| Step: 4
Training loss: 1.309787392616272
Validation loss: 2.2203396360079446

Epoch: 6| Step: 5
Training loss: 1.789604663848877
Validation loss: 2.241146981716156

Epoch: 6| Step: 6
Training loss: 1.8626699447631836
Validation loss: 2.209803303082784

Epoch: 6| Step: 7
Training loss: 1.3286526203155518
Validation loss: 2.222454528013865

Epoch: 6| Step: 8
Training loss: 2.1633317470550537
Validation loss: 2.2144893209139505

Epoch: 6| Step: 9
Training loss: 1.468380331993103
Validation loss: 2.2194009820620217

Epoch: 6| Step: 10
Training loss: 2.632047176361084
Validation loss: 2.2221308946609497

Epoch: 6| Step: 11
Training loss: 1.0122723579406738
Validation loss: 2.204615910847982

Epoch: 6| Step: 12
Training loss: 1.724609613418579
Validation loss: 2.213331123193105

Epoch: 6| Step: 13
Training loss: 1.7650971412658691
Validation loss: 2.234349171320597

Epoch: 267| Step: 0
Training loss: 1.3641958236694336
Validation loss: 2.2458314299583435

Epoch: 6| Step: 1
Training loss: 1.8622676134109497
Validation loss: 2.2294652859369912

Epoch: 6| Step: 2
Training loss: 1.8533265590667725
Validation loss: 2.212821046511332

Epoch: 6| Step: 3
Training loss: 1.0269887447357178
Validation loss: 2.2188223600387573

Epoch: 6| Step: 4
Training loss: 1.2520527839660645
Validation loss: 2.2383963465690613

Epoch: 6| Step: 5
Training loss: 2.0060372352600098
Validation loss: 2.2170873284339905

Epoch: 6| Step: 6
Training loss: 2.3508617877960205
Validation loss: 2.2584303816159568

Epoch: 6| Step: 7
Training loss: 1.5935945510864258
Validation loss: 2.236852208773295

Epoch: 6| Step: 8
Training loss: 1.0769981145858765
Validation loss: 2.251100699106852

Epoch: 6| Step: 9
Training loss: 2.80635666847229
Validation loss: 2.248181482156118

Epoch: 6| Step: 10
Training loss: 1.0371296405792236
Validation loss: 2.242276906967163

Epoch: 6| Step: 11
Training loss: 1.5381708145141602
Validation loss: 2.2776678800582886

Epoch: 6| Step: 12
Training loss: 1.6442739963531494
Validation loss: 2.266870141029358

Epoch: 6| Step: 13
Training loss: 1.8817394971847534
Validation loss: 2.261039217313131

Epoch: 268| Step: 0
Training loss: 1.6187851428985596
Validation loss: 2.2596894105275473

Epoch: 6| Step: 1
Training loss: 1.6672101020812988
Validation loss: 2.2902339100837708

Epoch: 6| Step: 2
Training loss: 1.545621633529663
Validation loss: 2.2799477179845176

Epoch: 6| Step: 3
Training loss: 1.2871837615966797
Validation loss: 2.274234433968862

Epoch: 6| Step: 4
Training loss: 1.734334111213684
Validation loss: 2.256022314230601

Epoch: 6| Step: 5
Training loss: 2.5688862800598145
Validation loss: 2.2678242921829224

Epoch: 6| Step: 6
Training loss: 2.1688292026519775
Validation loss: 2.257428467273712

Epoch: 6| Step: 7
Training loss: 1.3137366771697998
Validation loss: 2.238629678885142

Epoch: 6| Step: 8
Training loss: 1.4958001375198364
Validation loss: 2.2464282313982644

Epoch: 6| Step: 9
Training loss: 1.522141695022583
Validation loss: 2.252930740515391

Epoch: 6| Step: 10
Training loss: 1.5510547161102295
Validation loss: 2.242628733317057

Epoch: 6| Step: 11
Training loss: 1.3705426454544067
Validation loss: 2.225955903530121

Epoch: 6| Step: 12
Training loss: 1.5181134939193726
Validation loss: 2.2458941539128623

Epoch: 6| Step: 13
Training loss: 1.6621077060699463
Validation loss: 2.2332444985707602

Epoch: 269| Step: 0
Training loss: 1.826007604598999
Validation loss: 2.22075217962265

Epoch: 6| Step: 1
Training loss: 1.4749550819396973
Validation loss: 2.2547374765078225

Epoch: 6| Step: 2
Training loss: 1.4906961917877197
Validation loss: 2.248405476411184

Epoch: 6| Step: 3
Training loss: 1.270379662513733
Validation loss: 2.2404263416926065

Epoch: 6| Step: 4
Training loss: 1.6324540376663208
Validation loss: 2.237446387608846

Epoch: 6| Step: 5
Training loss: 1.1303576231002808
Validation loss: 2.262417991956075

Epoch: 6| Step: 6
Training loss: 2.0502982139587402
Validation loss: 2.250645418961843

Epoch: 6| Step: 7
Training loss: 1.991695523262024
Validation loss: 2.248915155728658

Epoch: 6| Step: 8
Training loss: 1.439239263534546
Validation loss: 2.236961086591085

Epoch: 6| Step: 9
Training loss: 1.7079858779907227
Validation loss: 2.2344457308451333

Epoch: 6| Step: 10
Training loss: 2.0885703563690186
Validation loss: 2.241947670777639

Epoch: 6| Step: 11
Training loss: 1.5558879375457764
Validation loss: 2.2473732431729636

Epoch: 6| Step: 12
Training loss: 1.5733751058578491
Validation loss: 2.2499778270721436

Epoch: 6| Step: 13
Training loss: 1.5559015274047852
Validation loss: 2.255203644434611

Epoch: 270| Step: 0
Training loss: 1.6277644634246826
Validation loss: 2.2518858909606934

Epoch: 6| Step: 1
Training loss: 1.7507915496826172
Validation loss: 2.2655075589815774

Epoch: 6| Step: 2
Training loss: 2.7986929416656494
Validation loss: 2.238815128803253

Epoch: 6| Step: 3
Training loss: 1.2654228210449219
Validation loss: 2.2609373927116394

Epoch: 6| Step: 4
Training loss: 0.9771753549575806
Validation loss: 2.28956667582194

Epoch: 6| Step: 5
Training loss: 1.2677061557769775
Validation loss: 2.278574287891388

Epoch: 6| Step: 6
Training loss: 1.6124584674835205
Validation loss: 2.248214761416117

Epoch: 6| Step: 7
Training loss: 1.715183973312378
Validation loss: 2.2602972785631814

Epoch: 6| Step: 8
Training loss: 1.9345555305480957
Validation loss: 2.2378648122151694

Epoch: 6| Step: 9
Training loss: 1.4399640560150146
Validation loss: 2.244447569052378

Epoch: 6| Step: 10
Training loss: 1.9096779823303223
Validation loss: 2.2441383600234985

Epoch: 6| Step: 11
Training loss: 2.1387510299682617
Validation loss: 2.267491618792216

Epoch: 6| Step: 12
Training loss: 1.2175720930099487
Validation loss: 2.223881204922994

Epoch: 6| Step: 13
Training loss: 1.0911808013916016
Validation loss: 2.2304311196009317

Epoch: 271| Step: 0
Training loss: 2.7662839889526367
Validation loss: 2.2691871523857117

Epoch: 6| Step: 1
Training loss: 1.979030728340149
Validation loss: 2.2524784803390503

Epoch: 6| Step: 2
Training loss: 1.0651332139968872
Validation loss: 2.2552846670150757

Epoch: 6| Step: 3
Training loss: 1.5868505239486694
Validation loss: 2.2466142177581787

Epoch: 6| Step: 4
Training loss: 1.6278733015060425
Validation loss: 2.2487877209981284

Epoch: 6| Step: 5
Training loss: 1.4559903144836426
Validation loss: 2.2576240499814353

Epoch: 6| Step: 6
Training loss: 1.754349946975708
Validation loss: 2.2748326857884726

Epoch: 6| Step: 7
Training loss: 1.3958334922790527
Validation loss: 2.2470337947209678

Epoch: 6| Step: 8
Training loss: 1.2679932117462158
Validation loss: 2.242060581843058

Epoch: 6| Step: 9
Training loss: 2.0904626846313477
Validation loss: 2.2331103483835855

Epoch: 6| Step: 10
Training loss: 0.8092176914215088
Validation loss: 2.2504377563794455

Epoch: 6| Step: 11
Training loss: 1.8775882720947266
Validation loss: 2.2443542877833047

Epoch: 6| Step: 12
Training loss: 1.7651951313018799
Validation loss: 2.2872523864110312

Epoch: 6| Step: 13
Training loss: 1.1666704416275024
Validation loss: 2.292440434296926

Epoch: 272| Step: 0
Training loss: 1.3408185243606567
Validation loss: 2.2462039788564048

Epoch: 6| Step: 1
Training loss: 2.137423515319824
Validation loss: 2.2289764086405435

Epoch: 6| Step: 2
Training loss: 1.8546221256256104
Validation loss: 2.2056535879770913

Epoch: 6| Step: 3
Training loss: 2.1508240699768066
Validation loss: 2.195790926615397

Epoch: 6| Step: 4
Training loss: 1.949803352355957
Validation loss: 2.2188892364501953

Epoch: 6| Step: 5
Training loss: 2.0822982788085938
Validation loss: 2.214865585168203

Epoch: 6| Step: 6
Training loss: 1.5591261386871338
Validation loss: 2.2028982241948447

Epoch: 6| Step: 7
Training loss: 1.1956183910369873
Validation loss: 2.22027717034022

Epoch: 6| Step: 8
Training loss: 1.3910799026489258
Validation loss: 2.202230970064799

Epoch: 6| Step: 9
Training loss: 1.3916740417480469
Validation loss: 2.245142618815104

Epoch: 6| Step: 10
Training loss: 2.2492923736572266
Validation loss: 2.2753870089848838

Epoch: 6| Step: 11
Training loss: 1.5195257663726807
Validation loss: 2.237842400868734

Epoch: 6| Step: 12
Training loss: 1.5312469005584717
Validation loss: 2.242867171764374

Epoch: 6| Step: 13
Training loss: 1.6766304969787598
Validation loss: 2.258762001991272

Epoch: 273| Step: 0
Training loss: 1.4938230514526367
Validation loss: 2.251660943031311

Epoch: 6| Step: 1
Training loss: 2.3070342540740967
Validation loss: 2.2285373210906982

Epoch: 6| Step: 2
Training loss: 1.342702865600586
Validation loss: 2.2204482356707254

Epoch: 6| Step: 3
Training loss: 1.5113142728805542
Validation loss: 2.2469939986864724

Epoch: 6| Step: 4
Training loss: 1.450700044631958
Validation loss: 2.2237077554066977

Epoch: 6| Step: 5
Training loss: 2.1627650260925293
Validation loss: 2.185786187648773

Epoch: 6| Step: 6
Training loss: 2.3642172813415527
Validation loss: 2.1982207894325256

Epoch: 6| Step: 7
Training loss: 2.610328197479248
Validation loss: 2.2299325466156006

Epoch: 6| Step: 8
Training loss: 1.054081678390503
Validation loss: 2.244283080101013

Epoch: 6| Step: 9
Training loss: 1.1999924182891846
Validation loss: 2.231925626595815

Epoch: 6| Step: 10
Training loss: 1.3344849348068237
Validation loss: 2.22586860259374

Epoch: 6| Step: 11
Training loss: 1.4726719856262207
Validation loss: 2.225204269091288

Epoch: 6| Step: 12
Training loss: 2.1861157417297363
Validation loss: 2.237300395965576

Epoch: 6| Step: 13
Training loss: 1.4250595569610596
Validation loss: 2.2462550004323325

Epoch: 274| Step: 0
Training loss: 1.742842197418213
Validation loss: 2.2405860225359597

Epoch: 6| Step: 1
Training loss: 1.2236886024475098
Validation loss: 2.22867759068807

Epoch: 6| Step: 2
Training loss: 1.7583441734313965
Validation loss: 2.235908269882202

Epoch: 6| Step: 3
Training loss: 1.4623690843582153
Validation loss: 2.216339031855265

Epoch: 6| Step: 4
Training loss: 1.7919868230819702
Validation loss: 2.2377771139144897

Epoch: 6| Step: 5
Training loss: 2.450615882873535
Validation loss: 2.2699439326922097

Epoch: 6| Step: 6
Training loss: 1.0539804697036743
Validation loss: 2.287336587905884

Epoch: 6| Step: 7
Training loss: 1.418790578842163
Validation loss: 2.268401106198629

Epoch: 6| Step: 8
Training loss: 1.4997704029083252
Validation loss: 2.2345677812894187

Epoch: 6| Step: 9
Training loss: 1.3122563362121582
Validation loss: 2.2434298992156982

Epoch: 6| Step: 10
Training loss: 1.2600672245025635
Validation loss: 2.2526780366897583

Epoch: 6| Step: 11
Training loss: 1.7177915573120117
Validation loss: 2.23187925418218

Epoch: 6| Step: 12
Training loss: 2.0689563751220703
Validation loss: 2.2307074069976807

Epoch: 6| Step: 13
Training loss: 2.116830825805664
Validation loss: 2.2336061000823975

Epoch: 275| Step: 0
Training loss: 1.676438331604004
Validation loss: 2.217832108338674

Epoch: 6| Step: 1
Training loss: 1.6006269454956055
Validation loss: 2.24380362033844

Epoch: 6| Step: 2
Training loss: 1.0997295379638672
Validation loss: 2.2483591636021933

Epoch: 6| Step: 3
Training loss: 1.4222900867462158
Validation loss: 2.2722111145655313

Epoch: 6| Step: 4
Training loss: 1.4616203308105469
Validation loss: 2.2751207749048867

Epoch: 6| Step: 5
Training loss: 2.0621259212493896
Validation loss: 2.2805713415145874

Epoch: 6| Step: 6
Training loss: 1.9343233108520508
Validation loss: 2.284113347530365

Epoch: 6| Step: 7
Training loss: 1.6751072406768799
Validation loss: 2.280911127726237

Epoch: 6| Step: 8
Training loss: 1.0978857278823853
Validation loss: 2.2767449816068015

Epoch: 6| Step: 9
Training loss: 2.4014768600463867
Validation loss: 2.265008052190145

Epoch: 6| Step: 10
Training loss: 1.5163707733154297
Validation loss: 2.27736896276474

Epoch: 6| Step: 11
Training loss: 2.2512331008911133
Validation loss: 2.2709749738375344

Epoch: 6| Step: 12
Training loss: 1.3266324996948242
Validation loss: 2.266495625178019

Epoch: 6| Step: 13
Training loss: 1.3863823413848877
Validation loss: 2.2684932549794516

Epoch: 276| Step: 0
Training loss: 2.0327844619750977
Validation loss: 2.2650250792503357

Epoch: 6| Step: 1
Training loss: 1.6557315587997437
Validation loss: 2.216803193092346

Epoch: 6| Step: 2
Training loss: 1.2075728178024292
Validation loss: 2.2377001841863

Epoch: 6| Step: 3
Training loss: 1.2923203706741333
Validation loss: 2.2184596061706543

Epoch: 6| Step: 4
Training loss: 1.9214686155319214
Validation loss: 2.2033883531888327

Epoch: 6| Step: 5
Training loss: 1.3487792015075684
Validation loss: 2.209516445795695

Epoch: 6| Step: 6
Training loss: 1.1996240615844727
Validation loss: 2.200061579545339

Epoch: 6| Step: 7
Training loss: 2.5372958183288574
Validation loss: 2.2066425681114197

Epoch: 6| Step: 8
Training loss: 1.5146903991699219
Validation loss: 2.2471834421157837

Epoch: 6| Step: 9
Training loss: 1.555936574935913
Validation loss: 2.2444008588790894

Epoch: 6| Step: 10
Training loss: 1.5353431701660156
Validation loss: 2.2482837438583374

Epoch: 6| Step: 11
Training loss: 1.3219826221466064
Validation loss: 2.2522842486699424

Epoch: 6| Step: 12
Training loss: 1.9102813005447388
Validation loss: 2.2611409425735474

Epoch: 6| Step: 13
Training loss: 2.3731367588043213
Validation loss: 2.2900213400522866

Epoch: 277| Step: 0
Training loss: 2.001204013824463
Validation loss: 2.2621962825457254

Epoch: 6| Step: 1
Training loss: 1.4595597982406616
Validation loss: 2.2712092796961465

Epoch: 6| Step: 2
Training loss: 3.317744016647339
Validation loss: 2.2608441909154258

Epoch: 6| Step: 3
Training loss: 1.403760552406311
Validation loss: 2.2853392958641052

Epoch: 6| Step: 4
Training loss: 1.927868366241455
Validation loss: 2.2923362056414285

Epoch: 6| Step: 5
Training loss: 1.2332472801208496
Validation loss: 2.235287586847941

Epoch: 6| Step: 6
Training loss: 1.5930356979370117
Validation loss: 2.2797876397768655

Epoch: 6| Step: 7
Training loss: 1.7317986488342285
Validation loss: 2.2609859108924866

Epoch: 6| Step: 8
Training loss: 1.1478075981140137
Validation loss: 2.2621998389561973

Epoch: 6| Step: 9
Training loss: 1.0081714391708374
Validation loss: 2.2442562778790793

Epoch: 6| Step: 10
Training loss: 1.2023346424102783
Validation loss: 2.243501921494802

Epoch: 6| Step: 11
Training loss: 1.3277138471603394
Validation loss: 2.245877265930176

Epoch: 6| Step: 12
Training loss: 1.5430030822753906
Validation loss: 2.23881067832311

Epoch: 6| Step: 13
Training loss: 1.4882434606552124
Validation loss: 2.264182527860006

Epoch: 278| Step: 0
Training loss: 1.8908826112747192
Validation loss: 2.23129149278005

Epoch: 6| Step: 1
Training loss: 1.82464599609375
Validation loss: 2.220291256904602

Epoch: 6| Step: 2
Training loss: 1.5924785137176514
Validation loss: 2.223556081453959

Epoch: 6| Step: 3
Training loss: 2.041114330291748
Validation loss: 2.214426636695862

Epoch: 6| Step: 4
Training loss: 2.108189582824707
Validation loss: 2.248191257317861

Epoch: 6| Step: 5
Training loss: 1.5403406620025635
Validation loss: 2.2579813400904336

Epoch: 6| Step: 6
Training loss: 1.127797245979309
Validation loss: 2.227987507979075

Epoch: 6| Step: 7
Training loss: 1.11862051486969
Validation loss: 2.255008339881897

Epoch: 6| Step: 8
Training loss: 2.099329710006714
Validation loss: 2.2457337180773416

Epoch: 6| Step: 9
Training loss: 1.2269216775894165
Validation loss: 2.26486744483312

Epoch: 6| Step: 10
Training loss: 1.1984765529632568
Validation loss: 2.2655904491742453

Epoch: 6| Step: 11
Training loss: 1.0526001453399658
Validation loss: 2.2702231804529824

Epoch: 6| Step: 12
Training loss: 2.313076972961426
Validation loss: 2.271007259686788

Epoch: 6| Step: 13
Training loss: 1.617100477218628
Validation loss: 2.2854594389597573

Epoch: 279| Step: 0
Training loss: 1.834503173828125
Validation loss: 2.2535599867502847

Epoch: 6| Step: 1
Training loss: 2.1127288341522217
Validation loss: 2.2554513613382974

Epoch: 6| Step: 2
Training loss: 1.8632242679595947
Validation loss: 2.2709728479385376

Epoch: 6| Step: 3
Training loss: 1.5206692218780518
Validation loss: 2.243383288383484

Epoch: 6| Step: 4
Training loss: 1.8779082298278809
Validation loss: 2.2476603984832764

Epoch: 6| Step: 5
Training loss: 1.0840022563934326
Validation loss: 2.265027940273285

Epoch: 6| Step: 6
Training loss: 1.0164384841918945
Validation loss: 2.2503989140192666

Epoch: 6| Step: 7
Training loss: 1.514167308807373
Validation loss: 2.2382278045018515

Epoch: 6| Step: 8
Training loss: 1.4271037578582764
Validation loss: 2.226439436276754

Epoch: 6| Step: 9
Training loss: 1.845101237297058
Validation loss: 2.250856022040049

Epoch: 6| Step: 10
Training loss: 2.3143410682678223
Validation loss: 2.2520021200180054

Epoch: 6| Step: 11
Training loss: 1.2524425983428955
Validation loss: 2.22835765282313

Epoch: 6| Step: 12
Training loss: 1.3737947940826416
Validation loss: 2.249770700931549

Epoch: 6| Step: 13
Training loss: 1.5134356021881104
Validation loss: 2.248703638712565

Epoch: 280| Step: 0
Training loss: 1.645337462425232
Validation loss: 2.2468507885932922

Epoch: 6| Step: 1
Training loss: 1.8888347148895264
Validation loss: 2.2391018867492676

Epoch: 6| Step: 2
Training loss: 1.2960808277130127
Validation loss: 2.2496262788772583

Epoch: 6| Step: 3
Training loss: 1.9745724201202393
Validation loss: 2.2576012015342712

Epoch: 6| Step: 4
Training loss: 0.921331524848938
Validation loss: 2.237265924612681

Epoch: 6| Step: 5
Training loss: 1.7807203531265259
Validation loss: 2.247737149397532

Epoch: 6| Step: 6
Training loss: 1.6749156713485718
Validation loss: 2.2363534371058145

Epoch: 6| Step: 7
Training loss: 2.268298625946045
Validation loss: 2.2576457858085632

Epoch: 6| Step: 8
Training loss: 1.0930531024932861
Validation loss: 2.2203410863876343

Epoch: 6| Step: 9
Training loss: 0.9896926879882812
Validation loss: 2.2321118911107383

Epoch: 6| Step: 10
Training loss: 1.8317033052444458
Validation loss: 2.245240847269694

Epoch: 6| Step: 11
Training loss: 1.4688395261764526
Validation loss: 2.243182599544525

Epoch: 6| Step: 12
Training loss: 1.428433895111084
Validation loss: 2.2388320366541543

Epoch: 6| Step: 13
Training loss: 2.2917730808258057
Validation loss: 2.242515583833059

Epoch: 281| Step: 0
Training loss: 1.7662402391433716
Validation loss: 2.233298361301422

Epoch: 6| Step: 1
Training loss: 1.4758274555206299
Validation loss: 2.2561277945836387

Epoch: 6| Step: 2
Training loss: 1.7412495613098145
Validation loss: 2.2641385793685913

Epoch: 6| Step: 3
Training loss: 1.5818684101104736
Validation loss: 2.270320196946462

Epoch: 6| Step: 4
Training loss: 2.52578067779541
Validation loss: 2.2278271317481995

Epoch: 6| Step: 5
Training loss: 1.623250961303711
Validation loss: 2.2418367862701416

Epoch: 6| Step: 6
Training loss: 1.3123912811279297
Validation loss: 2.2574071884155273

Epoch: 6| Step: 7
Training loss: 1.201228141784668
Validation loss: 2.2409768104553223

Epoch: 6| Step: 8
Training loss: 2.3756370544433594
Validation loss: 2.2603802482287088

Epoch: 6| Step: 9
Training loss: 1.7775822877883911
Validation loss: 2.2307907740275064

Epoch: 6| Step: 10
Training loss: 1.1190775632858276
Validation loss: 2.2247199416160583

Epoch: 6| Step: 11
Training loss: 1.50417160987854
Validation loss: 2.236176093419393

Epoch: 6| Step: 12
Training loss: 1.1992396116256714
Validation loss: 2.246870776017507

Epoch: 6| Step: 13
Training loss: 1.5101356506347656
Validation loss: 2.235085964202881

Epoch: 282| Step: 0
Training loss: 1.453366994857788
Validation loss: 2.238715489705404

Epoch: 6| Step: 1
Training loss: 1.4874260425567627
Validation loss: 2.234473983446757

Epoch: 6| Step: 2
Training loss: 2.103691577911377
Validation loss: 2.2238293091456094

Epoch: 6| Step: 3
Training loss: 1.7535367012023926
Validation loss: 2.2209914525349936

Epoch: 6| Step: 4
Training loss: 1.6218222379684448
Validation loss: 2.223173896471659

Epoch: 6| Step: 5
Training loss: 1.3964612483978271
Validation loss: 2.2292726039886475

Epoch: 6| Step: 6
Training loss: 1.8301873207092285
Validation loss: 2.2227763732274375

Epoch: 6| Step: 7
Training loss: 1.2789654731750488
Validation loss: 2.230550467967987

Epoch: 6| Step: 8
Training loss: 1.188002109527588
Validation loss: 2.227193772792816

Epoch: 6| Step: 9
Training loss: 2.0112051963806152
Validation loss: 2.2348119020462036

Epoch: 6| Step: 10
Training loss: 1.0040385723114014
Validation loss: 2.255661427974701

Epoch: 6| Step: 11
Training loss: 2.11112642288208
Validation loss: 2.283967157204946

Epoch: 6| Step: 12
Training loss: 1.9179420471191406
Validation loss: 2.2743598222732544

Epoch: 6| Step: 13
Training loss: 1.3250293731689453
Validation loss: 2.2481388648351035

Epoch: 283| Step: 0
Training loss: 1.4498357772827148
Validation loss: 2.2785266240437827

Epoch: 6| Step: 1
Training loss: 1.9435484409332275
Validation loss: 2.2907216946283975

Epoch: 6| Step: 2
Training loss: 1.6601454019546509
Validation loss: 2.3214484055836997

Epoch: 6| Step: 3
Training loss: 0.9518963098526001
Validation loss: 2.28710800409317

Epoch: 6| Step: 4
Training loss: 1.5676157474517822
Validation loss: 2.2870444456736245

Epoch: 6| Step: 5
Training loss: 1.534996509552002
Validation loss: 2.2655643026034036

Epoch: 6| Step: 6
Training loss: 1.2440786361694336
Validation loss: 2.270765999952952

Epoch: 6| Step: 7
Training loss: 1.4018712043762207
Validation loss: 2.263105273246765

Epoch: 6| Step: 8
Training loss: 1.4442057609558105
Validation loss: 2.2485286394755044

Epoch: 6| Step: 9
Training loss: 1.8709391355514526
Validation loss: 2.2362045447031655

Epoch: 6| Step: 10
Training loss: 1.848227858543396
Validation loss: 2.2369993925094604

Epoch: 6| Step: 11
Training loss: 1.9385932683944702
Validation loss: 2.2196534077326455

Epoch: 6| Step: 12
Training loss: 1.3974502086639404
Validation loss: 2.2671507596969604

Epoch: 6| Step: 13
Training loss: 1.8634493350982666
Validation loss: 2.2676525115966797

Epoch: 284| Step: 0
Training loss: 1.4713895320892334
Validation loss: 2.255413293838501

Epoch: 6| Step: 1
Training loss: 1.6222299337387085
Validation loss: 2.254397133986155

Epoch: 6| Step: 2
Training loss: 2.067178249359131
Validation loss: 2.257498880227407

Epoch: 6| Step: 3
Training loss: 1.8757952451705933
Validation loss: 2.268515487511953

Epoch: 6| Step: 4
Training loss: 1.7798385620117188
Validation loss: 2.2853244741757712

Epoch: 6| Step: 5
Training loss: 1.2296068668365479
Validation loss: 2.250292877356211

Epoch: 6| Step: 6
Training loss: 1.7993414402008057
Validation loss: 2.265566110610962

Epoch: 6| Step: 7
Training loss: 1.3044357299804688
Validation loss: 2.2574304739634194

Epoch: 6| Step: 8
Training loss: 1.1219664812088013
Validation loss: 2.2750593622525535

Epoch: 6| Step: 9
Training loss: 1.4695656299591064
Validation loss: 2.2709665099779763

Epoch: 6| Step: 10
Training loss: 1.5030863285064697
Validation loss: 2.2639149824778237

Epoch: 6| Step: 11
Training loss: 1.7232493162155151
Validation loss: 2.267791509628296

Epoch: 6| Step: 12
Training loss: 0.9289051294326782
Validation loss: 2.274303118387858

Epoch: 6| Step: 13
Training loss: 1.8411180973052979
Validation loss: 2.2771291732788086

Epoch: 285| Step: 0
Training loss: 1.7195271253585815
Validation loss: 2.2661027709643045

Epoch: 6| Step: 1
Training loss: 0.9923603534698486
Validation loss: 2.2944540778795877

Epoch: 6| Step: 2
Training loss: 1.5163631439208984
Validation loss: 2.2572299440701804

Epoch: 6| Step: 3
Training loss: 1.4581971168518066
Validation loss: 2.3039141098658242

Epoch: 6| Step: 4
Training loss: 1.8175643682479858
Validation loss: 2.2903836568196616

Epoch: 6| Step: 5
Training loss: 1.2649999856948853
Validation loss: 2.2961527506510415

Epoch: 6| Step: 6
Training loss: 1.5967135429382324
Validation loss: 2.2843908071517944

Epoch: 6| Step: 7
Training loss: 1.1936439275741577
Validation loss: 2.280843357245127

Epoch: 6| Step: 8
Training loss: 1.1535314321517944
Validation loss: 2.304514527320862

Epoch: 6| Step: 9
Training loss: 1.6672465801239014
Validation loss: 2.29379141330719

Epoch: 6| Step: 10
Training loss: 2.4341635704040527
Validation loss: 2.2840174436569214

Epoch: 6| Step: 11
Training loss: 1.1158764362335205
Validation loss: 2.280018130938212

Epoch: 6| Step: 12
Training loss: 1.4966535568237305
Validation loss: 2.2922608455022178

Epoch: 6| Step: 13
Training loss: 1.9509384632110596
Validation loss: 2.27139014005661

Epoch: 286| Step: 0
Training loss: 1.1827143430709839
Validation loss: 2.248249133427938

Epoch: 6| Step: 1
Training loss: 1.166976809501648
Validation loss: 2.2724084854125977

Epoch: 6| Step: 2
Training loss: 1.2355964183807373
Validation loss: 2.257216433684031

Epoch: 6| Step: 3
Training loss: 1.9770675897598267
Validation loss: 2.2637424071629844

Epoch: 6| Step: 4
Training loss: 2.1331019401550293
Validation loss: 2.2746262351671853

Epoch: 6| Step: 5
Training loss: 1.3343510627746582
Validation loss: 2.265436132748922

Epoch: 6| Step: 6
Training loss: 1.4972987174987793
Validation loss: 2.2768091559410095

Epoch: 6| Step: 7
Training loss: 1.056250810623169
Validation loss: 2.26214865843455

Epoch: 6| Step: 8
Training loss: 1.778735637664795
Validation loss: 2.272998094558716

Epoch: 6| Step: 9
Training loss: 1.5576339960098267
Validation loss: 2.275972763697306

Epoch: 6| Step: 10
Training loss: 1.8967574834823608
Validation loss: 2.258874535560608

Epoch: 6| Step: 11
Training loss: 1.6494336128234863
Validation loss: 2.24820069471995

Epoch: 6| Step: 12
Training loss: 1.75013267993927
Validation loss: 2.2536692221959433

Epoch: 6| Step: 13
Training loss: 1.6882315874099731
Validation loss: 2.2493554751078286

Epoch: 287| Step: 0
Training loss: 0.7347172498703003
Validation loss: 2.255877057711283

Epoch: 6| Step: 1
Training loss: 1.6176111698150635
Validation loss: 2.253237227598826

Epoch: 6| Step: 2
Training loss: 1.4625911712646484
Validation loss: 2.237446904182434

Epoch: 6| Step: 3
Training loss: 1.895373821258545
Validation loss: 2.258291025956472

Epoch: 6| Step: 4
Training loss: 1.8682748079299927
Validation loss: 2.239834646383921

Epoch: 6| Step: 5
Training loss: 1.7876313924789429
Validation loss: 2.2372039953867593

Epoch: 6| Step: 6
Training loss: 1.9205833673477173
Validation loss: 2.2557223041852317

Epoch: 6| Step: 7
Training loss: 1.3644554615020752
Validation loss: 2.24221400419871

Epoch: 6| Step: 8
Training loss: 1.5782384872436523
Validation loss: 2.2273412148157754

Epoch: 6| Step: 9
Training loss: 0.9803032279014587
Validation loss: 2.2382893760999045

Epoch: 6| Step: 10
Training loss: 2.6365771293640137
Validation loss: 2.254647374153137

Epoch: 6| Step: 11
Training loss: 1.463805913925171
Validation loss: 2.2576369047164917

Epoch: 6| Step: 12
Training loss: 1.1537892818450928
Validation loss: 2.2465223471323648

Epoch: 6| Step: 13
Training loss: 1.3819364309310913
Validation loss: 2.2291191021601358

Epoch: 288| Step: 0
Training loss: 1.2861980199813843
Validation loss: 2.2429293394088745

Epoch: 6| Step: 1
Training loss: 1.0253499746322632
Validation loss: 2.223607579867045

Epoch: 6| Step: 2
Training loss: 1.5948888063430786
Validation loss: 2.2442644238471985

Epoch: 6| Step: 3
Training loss: 1.451258897781372
Validation loss: 2.2412381966908774

Epoch: 6| Step: 4
Training loss: 1.3301966190338135
Validation loss: 2.221917708714803

Epoch: 6| Step: 5
Training loss: 1.3343554735183716
Validation loss: 2.2455150882403054

Epoch: 6| Step: 6
Training loss: 1.1097252368927002
Validation loss: 2.2282231052716575

Epoch: 6| Step: 7
Training loss: 1.6630879640579224
Validation loss: 2.240920841693878

Epoch: 6| Step: 8
Training loss: 1.8351942300796509
Validation loss: 2.213826616605123

Epoch: 6| Step: 9
Training loss: 1.8600457906723022
Validation loss: 2.2351492047309875

Epoch: 6| Step: 10
Training loss: 1.6832036972045898
Validation loss: 2.217400391896566

Epoch: 6| Step: 11
Training loss: 1.9860942363739014
Validation loss: 2.2274027268091836

Epoch: 6| Step: 12
Training loss: 1.6233339309692383
Validation loss: 2.243468225002289

Epoch: 6| Step: 13
Training loss: 2.022104024887085
Validation loss: 2.2323755621910095

Epoch: 289| Step: 0
Training loss: 1.418229103088379
Validation loss: 2.2357645432154336

Epoch: 6| Step: 1
Training loss: 1.3651788234710693
Validation loss: 2.2537910540898642

Epoch: 6| Step: 2
Training loss: 1.912431240081787
Validation loss: 2.245828409989675

Epoch: 6| Step: 3
Training loss: 1.4160752296447754
Validation loss: 2.2520736853281655

Epoch: 6| Step: 4
Training loss: 1.4921541213989258
Validation loss: 2.235483944416046

Epoch: 6| Step: 5
Training loss: 1.1999335289001465
Validation loss: 2.236257334550222

Epoch: 6| Step: 6
Training loss: 1.5250684022903442
Validation loss: 2.2719199856122336

Epoch: 6| Step: 7
Training loss: 1.3484344482421875
Validation loss: 2.254981815814972

Epoch: 6| Step: 8
Training loss: 1.5499310493469238
Validation loss: 2.2531694571177163

Epoch: 6| Step: 9
Training loss: 1.7717218399047852
Validation loss: 2.245754520098368

Epoch: 6| Step: 10
Training loss: 1.8269855976104736
Validation loss: 2.2685417930285134

Epoch: 6| Step: 11
Training loss: 1.2631609439849854
Validation loss: 2.2314067085584006

Epoch: 6| Step: 12
Training loss: 1.934805154800415
Validation loss: 2.244377613067627

Epoch: 6| Step: 13
Training loss: 1.5081844329833984
Validation loss: 2.2857521375020347

Epoch: 290| Step: 0
Training loss: 1.4843589067459106
Validation loss: 2.2857502698898315

Epoch: 6| Step: 1
Training loss: 0.9089579582214355
Validation loss: 2.266911506652832

Epoch: 6| Step: 2
Training loss: 1.7970093488693237
Validation loss: 2.2761733531951904

Epoch: 6| Step: 3
Training loss: 1.837375521659851
Validation loss: 2.2764389514923096

Epoch: 6| Step: 4
Training loss: 2.2343547344207764
Validation loss: 2.268078943093618

Epoch: 6| Step: 5
Training loss: 1.2561976909637451
Validation loss: 2.2594186663627625

Epoch: 6| Step: 6
Training loss: 1.6993741989135742
Validation loss: 2.267876068751017

Epoch: 6| Step: 7
Training loss: 1.64381742477417
Validation loss: 2.283698081970215

Epoch: 6| Step: 8
Training loss: 1.3444077968597412
Validation loss: 2.2635326186815896

Epoch: 6| Step: 9
Training loss: 1.2941820621490479
Validation loss: 2.27447775999705

Epoch: 6| Step: 10
Training loss: 1.9328926801681519
Validation loss: 2.26402747631073

Epoch: 6| Step: 11
Training loss: 1.2190959453582764
Validation loss: 2.2589170336723328

Epoch: 6| Step: 12
Training loss: 1.5161685943603516
Validation loss: 2.261344095071157

Epoch: 6| Step: 13
Training loss: 1.8826278448104858
Validation loss: 2.24750284353892

Epoch: 291| Step: 0
Training loss: 1.2436261177062988
Validation loss: 2.252620498339335

Epoch: 6| Step: 1
Training loss: 1.4577727317810059
Validation loss: 2.2789772748947144

Epoch: 6| Step: 2
Training loss: 1.601487398147583
Validation loss: 2.2619988322257996

Epoch: 6| Step: 3
Training loss: 1.50935959815979
Validation loss: 2.264394382635752

Epoch: 6| Step: 4
Training loss: 1.34828519821167
Validation loss: 2.275105436642965

Epoch: 6| Step: 5
Training loss: 2.2406198978424072
Validation loss: 2.2749706904093423

Epoch: 6| Step: 6
Training loss: 1.0886108875274658
Validation loss: 2.2381151914596558

Epoch: 6| Step: 7
Training loss: 1.5850460529327393
Validation loss: 2.2215293844540915

Epoch: 6| Step: 8
Training loss: 1.7792773246765137
Validation loss: 2.23878147204717

Epoch: 6| Step: 9
Training loss: 1.6373677253723145
Validation loss: 2.2186947663625083

Epoch: 6| Step: 10
Training loss: 1.71999192237854
Validation loss: 2.23654572168986

Epoch: 6| Step: 11
Training loss: 1.4953480958938599
Validation loss: 2.2162655194600425

Epoch: 6| Step: 12
Training loss: 1.4830909967422485
Validation loss: 2.225605765978495

Epoch: 6| Step: 13
Training loss: 1.6394625902175903
Validation loss: 2.2355832060178122

Epoch: 292| Step: 0
Training loss: 2.1348347663879395
Validation loss: 2.2105303009351096

Epoch: 6| Step: 1
Training loss: 1.3890788555145264
Validation loss: 2.2056140502293906

Epoch: 6| Step: 2
Training loss: 1.002072811126709
Validation loss: 2.264730910460154

Epoch: 6| Step: 3
Training loss: 1.423338532447815
Validation loss: 2.241587996482849

Epoch: 6| Step: 4
Training loss: 1.5652832984924316
Validation loss: 2.2692812283833823

Epoch: 6| Step: 5
Training loss: 1.6335978507995605
Validation loss: 2.2713306148846946

Epoch: 6| Step: 6
Training loss: 1.3087248802185059
Validation loss: 2.2674912214279175

Epoch: 6| Step: 7
Training loss: 1.9622364044189453
Validation loss: 2.250755568345388

Epoch: 6| Step: 8
Training loss: 1.882753610610962
Validation loss: 2.2639803489049277

Epoch: 6| Step: 9
Training loss: 1.5301357507705688
Validation loss: 2.2424834767977395

Epoch: 6| Step: 10
Training loss: 1.4960789680480957
Validation loss: 2.2456107338269553

Epoch: 6| Step: 11
Training loss: 1.3532310724258423
Validation loss: 2.2445565462112427

Epoch: 6| Step: 12
Training loss: 1.8050941228866577
Validation loss: 2.2340577046076455

Epoch: 6| Step: 13
Training loss: 1.8202412128448486
Validation loss: 2.254051705201467

Epoch: 293| Step: 0
Training loss: 1.2702805995941162
Validation loss: 2.2312527894973755

Epoch: 6| Step: 1
Training loss: 1.6910547018051147
Validation loss: 2.2216840187708535

Epoch: 6| Step: 2
Training loss: 2.0284273624420166
Validation loss: 2.245247006416321

Epoch: 6| Step: 3
Training loss: 1.508504033088684
Validation loss: 2.2172828316688538

Epoch: 6| Step: 4
Training loss: 1.27754545211792
Validation loss: 2.215431729952494

Epoch: 6| Step: 5
Training loss: 2.289598226547241
Validation loss: 2.2328158617019653

Epoch: 6| Step: 6
Training loss: 1.1827493906021118
Validation loss: 2.2404072284698486

Epoch: 6| Step: 7
Training loss: 0.9870134592056274
Validation loss: 2.245325247446696

Epoch: 6| Step: 8
Training loss: 1.82058846950531
Validation loss: 2.2484198808670044

Epoch: 6| Step: 9
Training loss: 1.13454008102417
Validation loss: 2.2582205732663474

Epoch: 6| Step: 10
Training loss: 2.2663865089416504
Validation loss: 2.2540932496388755

Epoch: 6| Step: 11
Training loss: 1.4302856922149658
Validation loss: 2.2763683001200357

Epoch: 6| Step: 12
Training loss: 0.6434165239334106
Validation loss: 2.2716370224952698

Epoch: 6| Step: 13
Training loss: 2.364644765853882
Validation loss: 2.2371214628219604

Epoch: 294| Step: 0
Training loss: 1.3736331462860107
Validation loss: 2.253394842147827

Epoch: 6| Step: 1
Training loss: 2.2771573066711426
Validation loss: 2.230448544025421

Epoch: 6| Step: 2
Training loss: 2.2507400512695312
Validation loss: 2.2665222883224487

Epoch: 6| Step: 3
Training loss: 1.3246711492538452
Validation loss: 2.2360298236211142

Epoch: 6| Step: 4
Training loss: 1.4584630727767944
Validation loss: 2.2673200964927673

Epoch: 6| Step: 5
Training loss: 0.9148060083389282
Validation loss: 2.2555034359296164

Epoch: 6| Step: 6
Training loss: 0.9568291306495667
Validation loss: 2.2749025026957193

Epoch: 6| Step: 7
Training loss: 2.032301902770996
Validation loss: 2.267153819402059

Epoch: 6| Step: 8
Training loss: 1.9603383541107178
Validation loss: 2.2591393987337747

Epoch: 6| Step: 9
Training loss: 1.3092236518859863
Validation loss: 2.2804872194925943

Epoch: 6| Step: 10
Training loss: 1.4939310550689697
Validation loss: 2.276081681251526

Epoch: 6| Step: 11
Training loss: 1.9957810640335083
Validation loss: 2.245348592599233

Epoch: 6| Step: 12
Training loss: 0.9669106006622314
Validation loss: 2.284601906935374

Epoch: 6| Step: 13
Training loss: 1.5769546031951904
Validation loss: 2.2903411984443665

Epoch: 295| Step: 0
Training loss: 2.167525053024292
Validation loss: 2.296878933906555

Epoch: 6| Step: 1
Training loss: 1.1624763011932373
Validation loss: 2.29098912080129

Epoch: 6| Step: 2
Training loss: 1.4669170379638672
Validation loss: 2.2983811696370444

Epoch: 6| Step: 3
Training loss: 1.8375461101531982
Validation loss: 2.2929940223693848

Epoch: 6| Step: 4
Training loss: 1.4690284729003906
Validation loss: 2.2873176534970603

Epoch: 6| Step: 5
Training loss: 1.4360389709472656
Validation loss: 2.301530738671621

Epoch: 6| Step: 6
Training loss: 2.3890771865844727
Validation loss: 2.27025306224823

Epoch: 6| Step: 7
Training loss: 1.3642523288726807
Validation loss: 2.2829792300860086

Epoch: 6| Step: 8
Training loss: 1.5146117210388184
Validation loss: 2.278177539507548

Epoch: 6| Step: 9
Training loss: 1.278672218322754
Validation loss: 2.259499251842499

Epoch: 6| Step: 10
Training loss: 1.6930937767028809
Validation loss: 2.274237593015035

Epoch: 6| Step: 11
Training loss: 1.2683534622192383
Validation loss: 2.2534860372543335

Epoch: 6| Step: 12
Training loss: 0.9062809944152832
Validation loss: 2.267550230026245

Epoch: 6| Step: 13
Training loss: 1.4166178703308105
Validation loss: 2.257530450820923

Epoch: 296| Step: 0
Training loss: 1.4527089595794678
Validation loss: 2.2542958656946817

Epoch: 6| Step: 1
Training loss: 1.453736662864685
Validation loss: 2.2812162240346274

Epoch: 6| Step: 2
Training loss: 1.535491943359375
Validation loss: 2.28447562456131

Epoch: 6| Step: 3
Training loss: 1.3717628717422485
Validation loss: 2.2567112048467

Epoch: 6| Step: 4
Training loss: 1.9829521179199219
Validation loss: 2.2844399412473044

Epoch: 6| Step: 5
Training loss: 1.8184075355529785
Validation loss: 2.288664937019348

Epoch: 6| Step: 6
Training loss: 1.1122545003890991
Validation loss: 2.2868213653564453

Epoch: 6| Step: 7
Training loss: 1.6837998628616333
Validation loss: 2.3009272813796997

Epoch: 6| Step: 8
Training loss: 1.2641522884368896
Validation loss: 2.298214852809906

Epoch: 6| Step: 9
Training loss: 1.5478111505508423
Validation loss: 2.308611730734507

Epoch: 6| Step: 10
Training loss: 1.8252202272415161
Validation loss: 2.3056777119636536

Epoch: 6| Step: 11
Training loss: 1.8507343530654907
Validation loss: 2.2644274830818176

Epoch: 6| Step: 12
Training loss: 0.9346632957458496
Validation loss: 2.263031482696533

Epoch: 6| Step: 13
Training loss: 1.5484559535980225
Validation loss: 2.27129590511322

Epoch: 297| Step: 0
Training loss: 1.4007341861724854
Validation loss: 2.256867210070292

Epoch: 6| Step: 1
Training loss: 1.6295547485351562
Validation loss: 2.270975132783254

Epoch: 6| Step: 2
Training loss: 1.4415205717086792
Validation loss: 2.2843910455703735

Epoch: 6| Step: 3
Training loss: 1.233260989189148
Validation loss: 2.255527436733246

Epoch: 6| Step: 4
Training loss: 1.2342443466186523
Validation loss: 2.258729636669159

Epoch: 6| Step: 5
Training loss: 1.7776968479156494
Validation loss: 2.234036644299825

Epoch: 6| Step: 6
Training loss: 1.66288423538208
Validation loss: 2.2194184064865112

Epoch: 6| Step: 7
Training loss: 1.5990285873413086
Validation loss: 2.2066003878911338

Epoch: 6| Step: 8
Training loss: 1.8412373065948486
Validation loss: 2.2305056850115457

Epoch: 6| Step: 9
Training loss: 1.4455063343048096
Validation loss: 2.2009107073148093

Epoch: 6| Step: 10
Training loss: 2.1833066940307617
Validation loss: 2.228512446085612

Epoch: 6| Step: 11
Training loss: 1.1340007781982422
Validation loss: 2.246478319168091

Epoch: 6| Step: 12
Training loss: 1.6922898292541504
Validation loss: 2.2339577873547873

Epoch: 6| Step: 13
Training loss: 1.4227869510650635
Validation loss: 2.2394447922706604

Epoch: 298| Step: 0
Training loss: 1.8299341201782227
Validation loss: 2.2784424424171448

Epoch: 6| Step: 1
Training loss: 1.847851037979126
Validation loss: 2.2328131198883057

Epoch: 6| Step: 2
Training loss: 1.6647672653198242
Validation loss: 2.2735094825426736

Epoch: 6| Step: 3
Training loss: 2.117913007736206
Validation loss: 2.2664737900098166

Epoch: 6| Step: 4
Training loss: 1.3277994394302368
Validation loss: 2.2855401833852134

Epoch: 6| Step: 5
Training loss: 2.597074508666992
Validation loss: 2.3037477930386863

Epoch: 6| Step: 6
Training loss: 1.388299822807312
Validation loss: 2.25887930393219

Epoch: 6| Step: 7
Training loss: 1.682784080505371
Validation loss: 2.2452457745869956

Epoch: 6| Step: 8
Training loss: 1.6455750465393066
Validation loss: 2.197408974170685

Epoch: 6| Step: 9
Training loss: 1.4185144901275635
Validation loss: 2.206404904524485

Epoch: 6| Step: 10
Training loss: 1.6955032348632812
Validation loss: 2.2503313223520913

Epoch: 6| Step: 11
Training loss: 1.552944540977478
Validation loss: 2.23530912399292

Epoch: 6| Step: 12
Training loss: 1.5961723327636719
Validation loss: 2.205866833527883

Epoch: 6| Step: 13
Training loss: 1.609222173690796
Validation loss: 2.212075710296631

Epoch: 299| Step: 0
Training loss: 2.744412899017334
Validation loss: 2.208117643992106

Epoch: 6| Step: 1
Training loss: 1.9639592170715332
Validation loss: 2.192543625831604

Epoch: 6| Step: 2
Training loss: 2.114278554916382
Validation loss: 2.198985278606415

Epoch: 6| Step: 3
Training loss: 1.6053881645202637
Validation loss: 2.193623344103495

Epoch: 6| Step: 4
Training loss: 1.7075597047805786
Validation loss: 2.184927999973297

Epoch: 6| Step: 5
Training loss: 2.1463911533355713
Validation loss: 2.196095565954844

Epoch: 6| Step: 6
Training loss: 1.1518093347549438
Validation loss: 2.166395346323649

Epoch: 6| Step: 7
Training loss: 0.9778826236724854
Validation loss: 2.179420749346415

Epoch: 6| Step: 8
Training loss: 1.0477285385131836
Validation loss: 2.177077372868856

Epoch: 6| Step: 9
Training loss: 1.7800157070159912
Validation loss: 2.161488632361094

Epoch: 6| Step: 10
Training loss: 1.2429485321044922
Validation loss: 2.16747119029363

Epoch: 6| Step: 11
Training loss: 1.9875338077545166
Validation loss: 2.168944319089254

Epoch: 6| Step: 12
Training loss: 1.8065578937530518
Validation loss: 2.182023028532664

Epoch: 6| Step: 13
Training loss: 1.3924204111099243
Validation loss: 2.2115434408187866

Epoch: 300| Step: 0
Training loss: 1.758766531944275
Validation loss: 2.2421698768933616

Epoch: 6| Step: 1
Training loss: 1.7021241188049316
Validation loss: 2.2556208968162537

Epoch: 6| Step: 2
Training loss: 1.5197901725769043
Validation loss: 2.24407035112381

Epoch: 6| Step: 3
Training loss: 1.4547079801559448
Validation loss: 2.254047234853109

Epoch: 6| Step: 4
Training loss: 1.9402861595153809
Validation loss: 2.2455142935117087

Epoch: 6| Step: 5
Training loss: 1.3106908798217773
Validation loss: 2.256323436896006

Epoch: 6| Step: 6
Training loss: 1.8318490982055664
Validation loss: 2.2420740127563477

Epoch: 6| Step: 7
Training loss: 1.3864065408706665
Validation loss: 2.260320007801056

Epoch: 6| Step: 8
Training loss: 2.0771920680999756
Validation loss: 2.2533253828684487

Epoch: 6| Step: 9
Training loss: 1.092545509338379
Validation loss: 2.226438522338867

Epoch: 6| Step: 10
Training loss: 2.3056726455688477
Validation loss: 2.243201971054077

Epoch: 6| Step: 11
Training loss: 1.0582619905471802
Validation loss: 2.252596120039622

Epoch: 6| Step: 12
Training loss: 1.3598456382751465
Validation loss: 2.306813895702362

Epoch: 6| Step: 13
Training loss: 1.2274147272109985
Validation loss: 2.33243465423584

Epoch: 301| Step: 0
Training loss: 1.1036268472671509
Validation loss: 2.3279293378194175

Epoch: 6| Step: 1
Training loss: 1.7686588764190674
Validation loss: 2.317768673102061

Epoch: 6| Step: 2
Training loss: 1.9211901426315308
Validation loss: 2.3623211781183877

Epoch: 6| Step: 3
Training loss: 1.9054739475250244
Validation loss: 2.352189302444458

Epoch: 6| Step: 4
Training loss: 1.9975371360778809
Validation loss: 2.3658772309621177

Epoch: 6| Step: 5
Training loss: 1.7837774753570557
Validation loss: 2.3409253358840942

Epoch: 6| Step: 6
Training loss: 1.817493200302124
Validation loss: 2.313050091266632

Epoch: 6| Step: 7
Training loss: 1.3048040866851807
Validation loss: 2.2823245525360107

Epoch: 6| Step: 8
Training loss: 1.990645170211792
Validation loss: 2.2333877086639404

Epoch: 6| Step: 9
Training loss: 1.0683337450027466
Validation loss: 2.2411189874013266

Epoch: 6| Step: 10
Training loss: 1.613788366317749
Validation loss: 2.2522212068239846

Epoch: 6| Step: 11
Training loss: 1.2790846824645996
Validation loss: 2.247477173805237

Epoch: 6| Step: 12
Training loss: 1.9180617332458496
Validation loss: 2.2483584682146707

Epoch: 6| Step: 13
Training loss: 2.2458791732788086
Validation loss: 2.270922859509786

Epoch: 302| Step: 0
Training loss: 1.0971095561981201
Validation loss: 2.239598532517751

Epoch: 6| Step: 1
Training loss: 1.9107856750488281
Validation loss: 2.22032638390859

Epoch: 6| Step: 2
Training loss: 1.5426517724990845
Validation loss: 2.235996127128601

Epoch: 6| Step: 3
Training loss: 2.100900173187256
Validation loss: 2.2245879968007407

Epoch: 6| Step: 4
Training loss: 1.9408615827560425
Validation loss: 2.217733323574066

Epoch: 6| Step: 5
Training loss: 1.5085076093673706
Validation loss: 2.210202991962433

Epoch: 6| Step: 6
Training loss: 1.4797217845916748
Validation loss: 2.2127883036931357

Epoch: 6| Step: 7
Training loss: 1.6188002824783325
Validation loss: 2.1892425219217935

Epoch: 6| Step: 8
Training loss: 1.8646719455718994
Validation loss: 2.1921253005663552

Epoch: 6| Step: 9
Training loss: 1.7616487741470337
Validation loss: 2.177520990371704

Epoch: 6| Step: 10
Training loss: 1.5650690793991089
Validation loss: 2.176643212636312

Epoch: 6| Step: 11
Training loss: 1.1393826007843018
Validation loss: 2.2130550146102905

Epoch: 6| Step: 12
Training loss: 1.8435615301132202
Validation loss: 2.19404544432958

Epoch: 6| Step: 13
Training loss: 1.8607325553894043
Validation loss: 2.2135307590166726

Epoch: 303| Step: 0
Training loss: 1.2005228996276855
Validation loss: 2.2053044637044272

Epoch: 6| Step: 1
Training loss: 1.9249029159545898
Validation loss: 2.201818287372589

Epoch: 6| Step: 2
Training loss: 1.2192864418029785
Validation loss: 2.2303762237230935

Epoch: 6| Step: 3
Training loss: 1.790968418121338
Validation loss: 2.2319466869036355

Epoch: 6| Step: 4
Training loss: 1.2946584224700928
Validation loss: 2.24673197666804

Epoch: 6| Step: 5
Training loss: 1.846506118774414
Validation loss: 2.2543081839879355

Epoch: 6| Step: 6
Training loss: 1.2343982458114624
Validation loss: 2.268093387285868

Epoch: 6| Step: 7
Training loss: 1.79646635055542
Validation loss: 2.2665181159973145

Epoch: 6| Step: 8
Training loss: 0.9915714859962463
Validation loss: 2.284870187441508

Epoch: 6| Step: 9
Training loss: 2.5621891021728516
Validation loss: 2.2823182344436646

Epoch: 6| Step: 10
Training loss: 1.4498801231384277
Validation loss: 2.2596261302630105

Epoch: 6| Step: 11
Training loss: 1.6243741512298584
Validation loss: 2.257089058558146

Epoch: 6| Step: 12
Training loss: 1.1779935359954834
Validation loss: 2.25882887840271

Epoch: 6| Step: 13
Training loss: 1.713019847869873
Validation loss: 2.2544447978337607

Epoch: 304| Step: 0
Training loss: 1.739891529083252
Validation loss: 2.234880248705546

Epoch: 6| Step: 1
Training loss: 2.4051339626312256
Validation loss: 2.250241776307424

Epoch: 6| Step: 2
Training loss: 0.8953148126602173
Validation loss: 2.2462220390637717

Epoch: 6| Step: 3
Training loss: 1.595212459564209
Validation loss: 2.2261762817700705

Epoch: 6| Step: 4
Training loss: 1.1881017684936523
Validation loss: 2.2664340138435364

Epoch: 6| Step: 5
Training loss: 1.8529921770095825
Validation loss: 2.2844691077868142

Epoch: 6| Step: 6
Training loss: 1.942751169204712
Validation loss: 2.271852175394694

Epoch: 6| Step: 7
Training loss: 1.5243501663208008
Validation loss: 2.2540142933527627

Epoch: 6| Step: 8
Training loss: 1.6025656461715698
Validation loss: 2.27366179227829

Epoch: 6| Step: 9
Training loss: 2.055481195449829
Validation loss: 2.264954706033071

Epoch: 6| Step: 10
Training loss: 1.1300753355026245
Validation loss: 2.2576090892155967

Epoch: 6| Step: 11
Training loss: 1.6774133443832397
Validation loss: 2.2880709369977317

Epoch: 6| Step: 12
Training loss: 1.1230427026748657
Validation loss: 2.2756174405415854

Epoch: 6| Step: 13
Training loss: 1.1528626680374146
Validation loss: 2.2464169462521872

Epoch: 305| Step: 0
Training loss: 1.760758638381958
Validation loss: 2.2540337642033896

Epoch: 6| Step: 1
Training loss: 2.0468618869781494
Validation loss: 2.2420104344685874

Epoch: 6| Step: 2
Training loss: 1.200480341911316
Validation loss: 2.2365722258885703

Epoch: 6| Step: 3
Training loss: 1.620332956314087
Validation loss: 2.238869547843933

Epoch: 6| Step: 4
Training loss: 0.9473009705543518
Validation loss: 2.244401693344116

Epoch: 6| Step: 5
Training loss: 1.807642936706543
Validation loss: 2.230392058690389

Epoch: 6| Step: 6
Training loss: 1.5977728366851807
Validation loss: 2.247092386086782

Epoch: 6| Step: 7
Training loss: 1.6960232257843018
Validation loss: 2.2256780664126077

Epoch: 6| Step: 8
Training loss: 1.5768470764160156
Validation loss: 2.250589887301127

Epoch: 6| Step: 9
Training loss: 1.5044167041778564
Validation loss: 2.230254610379537

Epoch: 6| Step: 10
Training loss: 1.594993233680725
Validation loss: 2.2398022015889487

Epoch: 6| Step: 11
Training loss: 1.4040536880493164
Validation loss: 2.2569490671157837

Epoch: 6| Step: 12
Training loss: 1.3013217449188232
Validation loss: 2.250401337941488

Epoch: 6| Step: 13
Training loss: 1.4438540935516357
Validation loss: 2.2135420044263205

Epoch: 306| Step: 0
Training loss: 1.572672963142395
Validation loss: 2.221798062324524

Epoch: 6| Step: 1
Training loss: 1.495098352432251
Validation loss: 2.220580061276754

Epoch: 6| Step: 2
Training loss: 1.5000369548797607
Validation loss: 2.233617385228475

Epoch: 6| Step: 3
Training loss: 1.1503520011901855
Validation loss: 2.2389756639798484

Epoch: 6| Step: 4
Training loss: 1.7080962657928467
Validation loss: 2.2533362905184426

Epoch: 6| Step: 5
Training loss: 1.4466073513031006
Validation loss: 2.250024437904358

Epoch: 6| Step: 6
Training loss: 1.422861099243164
Validation loss: 2.2302348017692566

Epoch: 6| Step: 7
Training loss: 1.731103777885437
Validation loss: 2.2745958169301352

Epoch: 6| Step: 8
Training loss: 0.6667782664299011
Validation loss: 2.2686957518259683

Epoch: 6| Step: 9
Training loss: 1.6601892709732056
Validation loss: 2.283766448497772

Epoch: 6| Step: 10
Training loss: 2.034113645553589
Validation loss: 2.2764061093330383

Epoch: 6| Step: 11
Training loss: 1.183620572090149
Validation loss: 2.256934881210327

Epoch: 6| Step: 12
Training loss: 2.1446523666381836
Validation loss: 2.2585567235946655

Epoch: 6| Step: 13
Training loss: 1.7411797046661377
Validation loss: 2.2535323897997537

Epoch: 307| Step: 0
Training loss: 1.2275514602661133
Validation loss: 2.2703744769096375

Epoch: 6| Step: 1
Training loss: 1.92409086227417
Validation loss: 2.2533549666404724

Epoch: 6| Step: 2
Training loss: 2.5895559787750244
Validation loss: 2.2749786972999573

Epoch: 6| Step: 3
Training loss: 1.466017484664917
Validation loss: 2.2534348169962564

Epoch: 6| Step: 4
Training loss: 1.3294297456741333
Validation loss: 2.2752602100372314

Epoch: 6| Step: 5
Training loss: 1.6071538925170898
Validation loss: 2.272534132003784

Epoch: 6| Step: 6
Training loss: 1.2777204513549805
Validation loss: 2.2702696522076926

Epoch: 6| Step: 7
Training loss: 1.1994640827178955
Validation loss: 2.284743070602417

Epoch: 6| Step: 8
Training loss: 1.3757054805755615
Validation loss: 2.2648061911265054

Epoch: 6| Step: 9
Training loss: 0.9770662188529968
Validation loss: 2.2940861185391745

Epoch: 6| Step: 10
Training loss: 1.629876732826233
Validation loss: 2.2785844008127847

Epoch: 6| Step: 11
Training loss: 1.4279674291610718
Validation loss: 2.286675453186035

Epoch: 6| Step: 12
Training loss: 1.3623793125152588
Validation loss: 2.2938897212346396

Epoch: 6| Step: 13
Training loss: 1.8478600978851318
Validation loss: 2.3023190100987754

Epoch: 308| Step: 0
Training loss: 1.249096155166626
Validation loss: 2.2828755378723145

Epoch: 6| Step: 1
Training loss: 2.0108585357666016
Validation loss: 2.288238823413849

Epoch: 6| Step: 2
Training loss: 1.363684892654419
Validation loss: 2.301410416762034

Epoch: 6| Step: 3
Training loss: 0.9672380089759827
Validation loss: 2.29910546541214

Epoch: 6| Step: 4
Training loss: 1.2878227233886719
Validation loss: 2.278753697872162

Epoch: 6| Step: 5
Training loss: 2.1127212047576904
Validation loss: 2.269276738166809

Epoch: 6| Step: 6
Training loss: 1.6682798862457275
Validation loss: 2.2897212505340576

Epoch: 6| Step: 7
Training loss: 1.4792497158050537
Validation loss: 2.2817439238230386

Epoch: 6| Step: 8
Training loss: 1.5451281070709229
Validation loss: 2.294596473375956

Epoch: 6| Step: 9
Training loss: 1.3399113416671753
Validation loss: 2.3114200631777444

Epoch: 6| Step: 10
Training loss: 1.4326330423355103
Validation loss: 2.292130430539449

Epoch: 6| Step: 11
Training loss: 1.410071849822998
Validation loss: 2.3061349391937256

Epoch: 6| Step: 12
Training loss: 1.7862882614135742
Validation loss: 2.323957602183024

Epoch: 6| Step: 13
Training loss: 1.2302721738815308
Validation loss: 2.2947201331456504

Epoch: 309| Step: 0
Training loss: 1.2220959663391113
Validation loss: 2.3223514358202615

Epoch: 6| Step: 1
Training loss: 1.8976048231124878
Validation loss: 2.3094135324160256

Epoch: 6| Step: 2
Training loss: 1.3718010187149048
Validation loss: 2.3181891242663064

Epoch: 6| Step: 3
Training loss: 1.5224685668945312
Validation loss: 2.3278183539708457

Epoch: 6| Step: 4
Training loss: 1.8382196426391602
Validation loss: 2.3351953426996865

Epoch: 6| Step: 5
Training loss: 1.6100668907165527
Validation loss: 2.3041359186172485

Epoch: 6| Step: 6
Training loss: 1.715782880783081
Validation loss: 2.3312349716822305

Epoch: 6| Step: 7
Training loss: 0.9659954309463501
Validation loss: 2.325268010298411

Epoch: 6| Step: 8
Training loss: 1.6458775997161865
Validation loss: 2.3401530186335244

Epoch: 6| Step: 9
Training loss: 1.156569242477417
Validation loss: 2.2846142252286277

Epoch: 6| Step: 10
Training loss: 1.8306320905685425
Validation loss: 2.3246877988179526

Epoch: 6| Step: 11
Training loss: 0.6202243566513062
Validation loss: 2.3208174308141074

Epoch: 6| Step: 12
Training loss: 1.6016038656234741
Validation loss: 2.309654116630554

Epoch: 6| Step: 13
Training loss: 1.634878158569336
Validation loss: 2.292597492535909

Epoch: 310| Step: 0
Training loss: 1.5670065879821777
Validation loss: 2.298806627591451

Epoch: 6| Step: 1
Training loss: 0.9034938812255859
Validation loss: 2.291088362534841

Epoch: 6| Step: 2
Training loss: 1.420055627822876
Validation loss: 2.341501851876577

Epoch: 6| Step: 3
Training loss: 2.1698803901672363
Validation loss: 2.319196105003357

Epoch: 6| Step: 4
Training loss: 1.2804911136627197
Validation loss: 2.309852341810862

Epoch: 6| Step: 5
Training loss: 1.407867431640625
Validation loss: 2.3042101860046387

Epoch: 6| Step: 6
Training loss: 1.7358424663543701
Validation loss: 2.3186668753623962

Epoch: 6| Step: 7
Training loss: 1.3421459197998047
Validation loss: 2.3247182766596475

Epoch: 6| Step: 8
Training loss: 0.8143090009689331
Validation loss: 2.3051822980244956

Epoch: 6| Step: 9
Training loss: 1.9171392917633057
Validation loss: 2.332952618598938

Epoch: 6| Step: 10
Training loss: 1.251906156539917
Validation loss: 2.2932433485984802

Epoch: 6| Step: 11
Training loss: 1.8173298835754395
Validation loss: 2.292605002721151

Epoch: 6| Step: 12
Training loss: 1.0240412950515747
Validation loss: 2.3321935335795083

Epoch: 6| Step: 13
Training loss: 1.523518443107605
Validation loss: 2.3184374968210855

Epoch: 311| Step: 0
Training loss: 0.8098790645599365
Validation loss: 2.2853631575902305

Epoch: 6| Step: 1
Training loss: 1.2999495267868042
Validation loss: 2.306502183278402

Epoch: 6| Step: 2
Training loss: 1.9246509075164795
Validation loss: 2.321546713511149

Epoch: 6| Step: 3
Training loss: 1.5237085819244385
Validation loss: 2.3016268809636435

Epoch: 6| Step: 4
Training loss: 1.8285553455352783
Validation loss: 2.2884660959243774

Epoch: 6| Step: 5
Training loss: 1.2883634567260742
Validation loss: 2.2629427115122476

Epoch: 6| Step: 6
Training loss: 1.3186149597167969
Validation loss: 2.2682961225509644

Epoch: 6| Step: 7
Training loss: 1.8201980590820312
Validation loss: 2.271558403968811

Epoch: 6| Step: 8
Training loss: 1.657308578491211
Validation loss: 2.2510305643081665

Epoch: 6| Step: 9
Training loss: 0.982559084892273
Validation loss: 2.2667441368103027

Epoch: 6| Step: 10
Training loss: 1.8414475917816162
Validation loss: 2.2627757787704468

Epoch: 6| Step: 11
Training loss: 1.45957350730896
Validation loss: 2.281536022822062

Epoch: 6| Step: 12
Training loss: 1.7228448390960693
Validation loss: 2.28990638256073

Epoch: 6| Step: 13
Training loss: 1.415634274482727
Validation loss: 2.2710365851720176

Epoch: 312| Step: 0
Training loss: 2.279627561569214
Validation loss: 2.2777798573176065

Epoch: 6| Step: 1
Training loss: 2.1500091552734375
Validation loss: 2.2586299777030945

Epoch: 6| Step: 2
Training loss: 1.2032660245895386
Validation loss: 2.258588453133901

Epoch: 6| Step: 3
Training loss: 1.777712106704712
Validation loss: 2.2274592320124307

Epoch: 6| Step: 4
Training loss: 1.9964427947998047
Validation loss: 2.217573622862498

Epoch: 6| Step: 5
Training loss: 1.4201750755310059
Validation loss: 2.2050830721855164

Epoch: 6| Step: 6
Training loss: 2.3002424240112305
Validation loss: 2.177876810232798

Epoch: 6| Step: 7
Training loss: 1.0457605123519897
Validation loss: 2.1748614509900412

Epoch: 6| Step: 8
Training loss: 1.2629951238632202
Validation loss: 2.158522129058838

Epoch: 6| Step: 9
Training loss: 1.1957393884658813
Validation loss: 2.1978079080581665

Epoch: 6| Step: 10
Training loss: 0.9939056634902954
Validation loss: 2.21255894502004

Epoch: 6| Step: 11
Training loss: 0.9690588712692261
Validation loss: 2.2098204692204795

Epoch: 6| Step: 12
Training loss: 1.3946536779403687
Validation loss: 2.2001782655715942

Epoch: 6| Step: 13
Training loss: 1.5032519102096558
Validation loss: 2.212613523006439

Epoch: 313| Step: 0
Training loss: 1.9419541358947754
Validation loss: 2.229074021180471

Epoch: 6| Step: 1
Training loss: 1.5451099872589111
Validation loss: 2.2281556129455566

Epoch: 6| Step: 2
Training loss: 1.6960519552230835
Validation loss: 2.2349162896474204

Epoch: 6| Step: 3
Training loss: 1.6483681201934814
Validation loss: 2.220988710721334

Epoch: 6| Step: 4
Training loss: 0.8963071703910828
Validation loss: 2.238519529501597

Epoch: 6| Step: 5
Training loss: 2.1585350036621094
Validation loss: 2.243552585442861

Epoch: 6| Step: 6
Training loss: 1.1913657188415527
Validation loss: 2.2242995699246726

Epoch: 6| Step: 7
Training loss: 1.7192277908325195
Validation loss: 2.2604383627573648

Epoch: 6| Step: 8
Training loss: 0.8513174057006836
Validation loss: 2.2392005920410156

Epoch: 6| Step: 9
Training loss: 2.075528621673584
Validation loss: 2.2528250217437744

Epoch: 6| Step: 10
Training loss: 2.0114340782165527
Validation loss: 2.249659021695455

Epoch: 6| Step: 11
Training loss: 1.418008804321289
Validation loss: 2.2410763104756675

Epoch: 6| Step: 12
Training loss: 0.7999753952026367
Validation loss: 2.2424280643463135

Epoch: 6| Step: 13
Training loss: 1.0381182432174683
Validation loss: 2.2249879240989685

Epoch: 314| Step: 0
Training loss: 1.0966005325317383
Validation loss: 2.2525214354197183

Epoch: 6| Step: 1
Training loss: 1.7339189052581787
Validation loss: 2.2216293811798096

Epoch: 6| Step: 2
Training loss: 1.6719026565551758
Validation loss: 2.2504854798316956

Epoch: 6| Step: 3
Training loss: 1.1455219984054565
Validation loss: 2.225384751955668

Epoch: 6| Step: 4
Training loss: 2.623688220977783
Validation loss: 2.2244258721669516

Epoch: 6| Step: 5
Training loss: 1.2925952672958374
Validation loss: 2.228385090827942

Epoch: 6| Step: 6
Training loss: 1.8108413219451904
Validation loss: 2.2378967801729837

Epoch: 6| Step: 7
Training loss: 1.440819501876831
Validation loss: 2.2118904987970986

Epoch: 6| Step: 8
Training loss: 1.4960912466049194
Validation loss: 2.250563303629557

Epoch: 6| Step: 9
Training loss: 1.3978976011276245
Validation loss: 2.2401586771011353

Epoch: 6| Step: 10
Training loss: 1.0422158241271973
Validation loss: 2.2210391759872437

Epoch: 6| Step: 11
Training loss: 1.3587852716445923
Validation loss: 2.2092620134353638

Epoch: 6| Step: 12
Training loss: 1.2401114702224731
Validation loss: 2.2241090138753257

Epoch: 6| Step: 13
Training loss: 1.5524195432662964
Validation loss: 2.2164355516433716

Epoch: 315| Step: 0
Training loss: 1.553421974182129
Validation loss: 2.218005577723185

Epoch: 6| Step: 1
Training loss: 1.240037441253662
Validation loss: 2.226102809111277

Epoch: 6| Step: 2
Training loss: 1.1465802192687988
Validation loss: 2.192082643508911

Epoch: 6| Step: 3
Training loss: 1.9235717058181763
Validation loss: 2.2100160717964172

Epoch: 6| Step: 4
Training loss: 1.7442618608474731
Validation loss: 2.2090609471003213

Epoch: 6| Step: 5
Training loss: 1.3696470260620117
Validation loss: 2.2099862098693848

Epoch: 6| Step: 6
Training loss: 1.4308462142944336
Validation loss: 2.212015450000763

Epoch: 6| Step: 7
Training loss: 1.5018113851547241
Validation loss: 2.2065080205599465

Epoch: 6| Step: 8
Training loss: 1.8705273866653442
Validation loss: 2.2396132548650107

Epoch: 6| Step: 9
Training loss: 1.3913531303405762
Validation loss: 2.232521096865336

Epoch: 6| Step: 10
Training loss: 1.039121150970459
Validation loss: 2.2293326258659363

Epoch: 6| Step: 11
Training loss: 0.9895523190498352
Validation loss: 2.2414653499921164

Epoch: 6| Step: 12
Training loss: 1.524728536605835
Validation loss: 2.219082852204641

Epoch: 6| Step: 13
Training loss: 1.8409889936447144
Validation loss: 2.2342722614606223

Epoch: 316| Step: 0
Training loss: 0.8718434572219849
Validation loss: 2.242699682712555

Epoch: 6| Step: 1
Training loss: 1.5701477527618408
Validation loss: 2.2488214572270713

Epoch: 6| Step: 2
Training loss: 1.7262208461761475
Validation loss: 2.2554229696591697

Epoch: 6| Step: 3
Training loss: 1.2881734371185303
Validation loss: 2.2422117392222085

Epoch: 6| Step: 4
Training loss: 0.9057328104972839
Validation loss: 2.230336089928945

Epoch: 6| Step: 5
Training loss: 1.6215962171554565
Validation loss: 2.2379964192708335

Epoch: 6| Step: 6
Training loss: 2.113253116607666
Validation loss: 2.230369826157888

Epoch: 6| Step: 7
Training loss: 2.2499117851257324
Validation loss: 2.219050923983256

Epoch: 6| Step: 8
Training loss: 1.809853196144104
Validation loss: 2.1777381102244058

Epoch: 6| Step: 9
Training loss: 0.9449369311332703
Validation loss: 2.2249786059061685

Epoch: 6| Step: 10
Training loss: 1.3036681413650513
Validation loss: 2.2233698964118958

Epoch: 6| Step: 11
Training loss: 1.3823485374450684
Validation loss: 2.204582929611206

Epoch: 6| Step: 12
Training loss: 1.6283371448516846
Validation loss: 2.212241291999817

Epoch: 6| Step: 13
Training loss: 1.8201329708099365
Validation loss: 2.224777261416117

Epoch: 317| Step: 0
Training loss: 2.5667266845703125
Validation loss: 2.222951571146647

Epoch: 6| Step: 1
Training loss: 1.3647540807724
Validation loss: 2.2298184037208557

Epoch: 6| Step: 2
Training loss: 1.6787400245666504
Validation loss: 2.2587737242380777

Epoch: 6| Step: 3
Training loss: 1.3443970680236816
Validation loss: 2.2374151150385537

Epoch: 6| Step: 4
Training loss: 1.2327693700790405
Validation loss: 2.251392404238383

Epoch: 6| Step: 5
Training loss: 1.656306266784668
Validation loss: 2.28238974014918

Epoch: 6| Step: 6
Training loss: 1.0619038343429565
Validation loss: 2.2409884333610535

Epoch: 6| Step: 7
Training loss: 1.1680762767791748
Validation loss: 2.243451694647471

Epoch: 6| Step: 8
Training loss: 1.4902372360229492
Validation loss: 2.2598978877067566

Epoch: 6| Step: 9
Training loss: 1.3083109855651855
Validation loss: 2.2459188302357993

Epoch: 6| Step: 10
Training loss: 1.577791452407837
Validation loss: 2.219248056411743

Epoch: 6| Step: 11
Training loss: 1.464930534362793
Validation loss: 2.212768574555715

Epoch: 6| Step: 12
Training loss: 1.313227653503418
Validation loss: 2.220250646273295

Epoch: 6| Step: 13
Training loss: 1.080570936203003
Validation loss: 2.2058470447858176

Epoch: 318| Step: 0
Training loss: 1.549930214881897
Validation loss: 2.202440917491913

Epoch: 6| Step: 1
Training loss: 0.7640043497085571
Validation loss: 2.2134143908818564

Epoch: 6| Step: 2
Training loss: 1.2981457710266113
Validation loss: 2.216265340646108

Epoch: 6| Step: 3
Training loss: 1.403179407119751
Validation loss: 2.2396565278371177

Epoch: 6| Step: 4
Training loss: 1.9971861839294434
Validation loss: 2.216430683930715

Epoch: 6| Step: 5
Training loss: 1.7255470752716064
Validation loss: 2.2335323890050254

Epoch: 6| Step: 6
Training loss: 1.1140570640563965
Validation loss: 2.2126583456993103

Epoch: 6| Step: 7
Training loss: 1.3956161737442017
Validation loss: 2.2026496728261313

Epoch: 6| Step: 8
Training loss: 1.95420241355896
Validation loss: 2.2071478764216104

Epoch: 6| Step: 9
Training loss: 0.9545475244522095
Validation loss: 2.1969013015429177

Epoch: 6| Step: 10
Training loss: 1.4431376457214355
Validation loss: 2.2190123796463013

Epoch: 6| Step: 11
Training loss: 1.5027015209197998
Validation loss: 2.193864365418752

Epoch: 6| Step: 12
Training loss: 1.720226526260376
Validation loss: 2.200643618901571

Epoch: 6| Step: 13
Training loss: 1.560075283050537
Validation loss: 2.190927584966024

Epoch: 319| Step: 0
Training loss: 1.7235511541366577
Validation loss: 2.202839513619741

Epoch: 6| Step: 1
Training loss: 1.8401758670806885
Validation loss: 2.2237364451090493

Epoch: 6| Step: 2
Training loss: 1.1671090126037598
Validation loss: 2.1963055531183877

Epoch: 6| Step: 3
Training loss: 1.5635946989059448
Validation loss: 2.190621336301168

Epoch: 6| Step: 4
Training loss: 1.3444322347640991
Validation loss: 2.1994290550549827

Epoch: 6| Step: 5
Training loss: 1.7374494075775146
Validation loss: 2.203765392303467

Epoch: 6| Step: 6
Training loss: 1.1974972486495972
Validation loss: 2.2093712290128074

Epoch: 6| Step: 7
Training loss: 1.122291088104248
Validation loss: 2.211066424846649

Epoch: 6| Step: 8
Training loss: 1.7212589979171753
Validation loss: 2.2235740423202515

Epoch: 6| Step: 9
Training loss: 1.5041519403457642
Validation loss: 2.2126212120056152

Epoch: 6| Step: 10
Training loss: 1.4360325336456299
Validation loss: 2.2391984462738037

Epoch: 6| Step: 11
Training loss: 1.226717472076416
Validation loss: 2.236000955104828

Epoch: 6| Step: 12
Training loss: 0.9590113162994385
Validation loss: 2.222338775793711

Epoch: 6| Step: 13
Training loss: 1.6126611232757568
Validation loss: 2.2486139138539634

Epoch: 320| Step: 0
Training loss: 1.1475772857666016
Validation loss: 2.2125533620516458

Epoch: 6| Step: 1
Training loss: 1.7093262672424316
Validation loss: 2.226053694883982

Epoch: 6| Step: 2
Training loss: 1.201805591583252
Validation loss: 2.232696274916331

Epoch: 6| Step: 3
Training loss: 1.4661732912063599
Validation loss: 2.222422023614248

Epoch: 6| Step: 4
Training loss: 2.163590669631958
Validation loss: 2.231886903444926

Epoch: 6| Step: 5
Training loss: 1.0163778066635132
Validation loss: 2.2352467974027

Epoch: 6| Step: 6
Training loss: 2.1218817234039307
Validation loss: 2.2190107107162476

Epoch: 6| Step: 7
Training loss: 1.6032260656356812
Validation loss: 2.2011881271998086

Epoch: 6| Step: 8
Training loss: 1.721604824066162
Validation loss: 2.219767610232035

Epoch: 6| Step: 9
Training loss: 0.6599915027618408
Validation loss: 2.195400337378184

Epoch: 6| Step: 10
Training loss: 1.2060283422470093
Validation loss: 2.2294710874557495

Epoch: 6| Step: 11
Training loss: 1.6664522886276245
Validation loss: 2.2362645665804544

Epoch: 6| Step: 12
Training loss: 1.5344328880310059
Validation loss: 2.229199846585592

Epoch: 6| Step: 13
Training loss: 1.7155410051345825
Validation loss: 2.217936416467031

Epoch: 321| Step: 0
Training loss: 1.5654730796813965
Validation loss: 2.222780406475067

Epoch: 6| Step: 1
Training loss: 1.727363109588623
Validation loss: 2.235876421133677

Epoch: 6| Step: 2
Training loss: 1.1149109601974487
Validation loss: 2.221770385901133

Epoch: 6| Step: 3
Training loss: 0.9653745889663696
Validation loss: 2.254839758078257

Epoch: 6| Step: 4
Training loss: 1.2483197450637817
Validation loss: 2.235420564810435

Epoch: 6| Step: 5
Training loss: 1.2048566341400146
Validation loss: 2.2649890184402466

Epoch: 6| Step: 6
Training loss: 1.3176507949829102
Validation loss: 2.264376481374105

Epoch: 6| Step: 7
Training loss: 1.7904053926467896
Validation loss: 2.2539011240005493

Epoch: 6| Step: 8
Training loss: 1.7459170818328857
Validation loss: 2.2522913217544556

Epoch: 6| Step: 9
Training loss: 1.6013039350509644
Validation loss: 2.2259159485499063

Epoch: 6| Step: 10
Training loss: 1.4363774061203003
Validation loss: 2.2462308009465537

Epoch: 6| Step: 11
Training loss: 1.6485588550567627
Validation loss: 2.2267717123031616

Epoch: 6| Step: 12
Training loss: 1.7913049459457397
Validation loss: 2.23467222849528

Epoch: 6| Step: 13
Training loss: 0.7529731392860413
Validation loss: 2.2193740208943686

Epoch: 322| Step: 0
Training loss: 1.9331367015838623
Validation loss: 2.2159379919370017

Epoch: 6| Step: 1
Training loss: 0.7899805903434753
Validation loss: 2.2448909680048623

Epoch: 6| Step: 2
Training loss: 2.4090659618377686
Validation loss: 2.2123838861783347

Epoch: 6| Step: 3
Training loss: 0.7236720323562622
Validation loss: 2.2277193665504456

Epoch: 6| Step: 4
Training loss: 0.8176305294036865
Validation loss: 2.2397621870040894

Epoch: 6| Step: 5
Training loss: 1.6452034711837769
Validation loss: 2.2327258388201394

Epoch: 6| Step: 6
Training loss: 1.567941427230835
Validation loss: 2.2604428927103677

Epoch: 6| Step: 7
Training loss: 1.7983787059783936
Validation loss: 2.237349510192871

Epoch: 6| Step: 8
Training loss: 1.814319133758545
Validation loss: 2.2310213446617126

Epoch: 6| Step: 9
Training loss: 1.4922109842300415
Validation loss: 2.2471386591593423

Epoch: 6| Step: 10
Training loss: 1.417278528213501
Validation loss: 2.234842618306478

Epoch: 6| Step: 11
Training loss: 2.0946102142333984
Validation loss: 2.2174824873606362

Epoch: 6| Step: 12
Training loss: 1.608197808265686
Validation loss: 2.204057057698568

Epoch: 6| Step: 13
Training loss: 0.6531052589416504
Validation loss: 2.2234437068303428

Epoch: 323| Step: 0
Training loss: 1.0715923309326172
Validation loss: 2.2020459373792014

Epoch: 6| Step: 1
Training loss: 1.2645468711853027
Validation loss: 2.2132128874460855

Epoch: 6| Step: 2
Training loss: 1.2108473777770996
Validation loss: 2.1766352454821267

Epoch: 6| Step: 3
Training loss: 1.6833555698394775
Validation loss: 2.1971124410629272

Epoch: 6| Step: 4
Training loss: 1.6006734371185303
Validation loss: 2.1741244196891785

Epoch: 6| Step: 5
Training loss: 1.1701560020446777
Validation loss: 2.180918594201406

Epoch: 6| Step: 6
Training loss: 1.4910439252853394
Validation loss: 2.16210945447286

Epoch: 6| Step: 7
Training loss: 2.5369338989257812
Validation loss: 2.176376978556315

Epoch: 6| Step: 8
Training loss: 1.1835962533950806
Validation loss: 2.177735984325409

Epoch: 6| Step: 9
Training loss: 1.5952924489974976
Validation loss: 2.2057316303253174

Epoch: 6| Step: 10
Training loss: 1.109721302986145
Validation loss: 2.196517507235209

Epoch: 6| Step: 11
Training loss: 1.5584595203399658
Validation loss: 2.2175239721934

Epoch: 6| Step: 12
Training loss: 1.7517949342727661
Validation loss: 2.2307808796564736

Epoch: 6| Step: 13
Training loss: 1.2585694789886475
Validation loss: 2.265224039554596

Epoch: 324| Step: 0
Training loss: 0.8351905345916748
Validation loss: 2.256105144818624

Epoch: 6| Step: 1
Training loss: 1.048313021659851
Validation loss: 2.3055747350056968

Epoch: 6| Step: 2
Training loss: 1.9301358461380005
Validation loss: 2.27314563592275

Epoch: 6| Step: 3
Training loss: 1.103312611579895
Validation loss: 2.272690176963806

Epoch: 6| Step: 4
Training loss: 2.0722033977508545
Validation loss: 2.2555933594703674

Epoch: 6| Step: 5
Training loss: 1.208882451057434
Validation loss: 2.26542462905248

Epoch: 6| Step: 6
Training loss: 0.9902356266975403
Validation loss: 2.2826391657193503

Epoch: 6| Step: 7
Training loss: 1.58228600025177
Validation loss: 2.2662340799967446

Epoch: 6| Step: 8
Training loss: 1.477286458015442
Validation loss: 2.2623894611994424

Epoch: 6| Step: 9
Training loss: 1.507469654083252
Validation loss: 2.273579994837443

Epoch: 6| Step: 10
Training loss: 1.2280348539352417
Validation loss: 2.2354877392450967

Epoch: 6| Step: 11
Training loss: 1.4874041080474854
Validation loss: 2.2503135601679483

Epoch: 6| Step: 12
Training loss: 1.4737420082092285
Validation loss: 2.254362324873606

Epoch: 6| Step: 13
Training loss: 1.8474032878875732
Validation loss: 2.2325868606567383

Epoch: 325| Step: 0
Training loss: 1.4971224069595337
Validation loss: 2.2261547247568765

Epoch: 6| Step: 1
Training loss: 1.6182982921600342
Validation loss: 2.237025280793508

Epoch: 6| Step: 2
Training loss: 1.348766565322876
Validation loss: 2.2561132510503135

Epoch: 6| Step: 3
Training loss: 1.1074665784835815
Validation loss: 2.2384361028671265

Epoch: 6| Step: 4
Training loss: 0.7043046355247498
Validation loss: 2.2410089572270713

Epoch: 6| Step: 5
Training loss: 2.0408599376678467
Validation loss: 2.2331505020459494

Epoch: 6| Step: 6
Training loss: 2.399423122406006
Validation loss: 2.2408154209454856

Epoch: 6| Step: 7
Training loss: 1.4619081020355225
Validation loss: 2.252078731854757

Epoch: 6| Step: 8
Training loss: 1.726035475730896
Validation loss: 2.233467181523641

Epoch: 6| Step: 9
Training loss: 0.928823709487915
Validation loss: 2.247563580671946

Epoch: 6| Step: 10
Training loss: 1.4257569313049316
Validation loss: 2.2410053809483848

Epoch: 6| Step: 11
Training loss: 1.1856434345245361
Validation loss: 2.2350063721338906

Epoch: 6| Step: 12
Training loss: 1.1523839235305786
Validation loss: 2.2727719942728677

Epoch: 6| Step: 13
Training loss: 0.9221270084381104
Validation loss: 2.2392525672912598

Epoch: 326| Step: 0
Training loss: 1.2948248386383057
Validation loss: 2.2151021162668862

Epoch: 6| Step: 1
Training loss: 1.8302555084228516
Validation loss: 2.1923205057779946

Epoch: 6| Step: 2
Training loss: 1.6396234035491943
Validation loss: 2.2028416792551675

Epoch: 6| Step: 3
Training loss: 1.8926961421966553
Validation loss: 2.2193998297055564

Epoch: 6| Step: 4
Training loss: 1.3039127588272095
Validation loss: 2.203997711340586

Epoch: 6| Step: 5
Training loss: 1.8325690031051636
Validation loss: 2.208525002002716

Epoch: 6| Step: 6
Training loss: 1.235560655593872
Validation loss: 2.19315896431605

Epoch: 6| Step: 7
Training loss: 1.0208821296691895
Validation loss: 2.1667255957921348

Epoch: 6| Step: 8
Training loss: 2.423682689666748
Validation loss: 2.190925180912018

Epoch: 6| Step: 9
Training loss: 1.1876366138458252
Validation loss: 2.217202285925547

Epoch: 6| Step: 10
Training loss: 1.0932316780090332
Validation loss: 2.218453069527944

Epoch: 6| Step: 11
Training loss: 1.1827561855316162
Validation loss: 2.165880560874939

Epoch: 6| Step: 12
Training loss: 1.5333733558654785
Validation loss: 2.161181926727295

Epoch: 6| Step: 13
Training loss: 0.7358555793762207
Validation loss: 2.1666886806488037

Epoch: 327| Step: 0
Training loss: 0.7821066379547119
Validation loss: 2.1908230781555176

Epoch: 6| Step: 1
Training loss: 1.1276804208755493
Validation loss: 2.1803804636001587

Epoch: 6| Step: 2
Training loss: 0.9161041975021362
Validation loss: 2.2156021197636924

Epoch: 6| Step: 3
Training loss: 2.016714572906494
Validation loss: 2.1873726646105447

Epoch: 6| Step: 4
Training loss: 1.2468187808990479
Validation loss: 2.1851930618286133

Epoch: 6| Step: 5
Training loss: 1.368914246559143
Validation loss: 2.166155676047007

Epoch: 6| Step: 6
Training loss: 1.409934401512146
Validation loss: 2.206684668858846

Epoch: 6| Step: 7
Training loss: 1.675328016281128
Validation loss: 2.183783710002899

Epoch: 6| Step: 8
Training loss: 1.316577672958374
Validation loss: 2.1740430990854898

Epoch: 6| Step: 9
Training loss: 1.3757435083389282
Validation loss: 2.2098746498425803

Epoch: 6| Step: 10
Training loss: 1.0814709663391113
Validation loss: 2.201811114947001

Epoch: 6| Step: 11
Training loss: 1.7669506072998047
Validation loss: 2.232210159301758

Epoch: 6| Step: 12
Training loss: 1.5602247714996338
Validation loss: 2.2153023878733316

Epoch: 6| Step: 13
Training loss: 2.223919630050659
Validation loss: 2.2228321631749473

Epoch: 328| Step: 0
Training loss: 1.3346154689788818
Validation loss: 2.2328925728797913

Epoch: 6| Step: 1
Training loss: 1.8122268915176392
Validation loss: 2.2405229210853577

Epoch: 6| Step: 2
Training loss: 0.833329439163208
Validation loss: 2.23381769657135

Epoch: 6| Step: 3
Training loss: 1.4706857204437256
Validation loss: 2.226740539073944

Epoch: 6| Step: 4
Training loss: 1.9668734073638916
Validation loss: 2.247136414051056

Epoch: 6| Step: 5
Training loss: 1.666980504989624
Validation loss: 2.224816679954529

Epoch: 6| Step: 6
Training loss: 0.951815128326416
Validation loss: 2.265014330546061

Epoch: 6| Step: 7
Training loss: 1.6241029500961304
Validation loss: 2.2254673838615417

Epoch: 6| Step: 8
Training loss: 0.9055789709091187
Validation loss: 2.216899275779724

Epoch: 6| Step: 9
Training loss: 0.8107396364212036
Validation loss: 2.2603135903676352

Epoch: 6| Step: 10
Training loss: 1.9936423301696777
Validation loss: 2.261762261390686

Epoch: 6| Step: 11
Training loss: 1.6458089351654053
Validation loss: 2.2725382645924888

Epoch: 6| Step: 12
Training loss: 0.8493963479995728
Validation loss: 2.2466567556063333

Epoch: 6| Step: 13
Training loss: 1.2618778944015503
Validation loss: 2.2378399769465127

Epoch: 329| Step: 0
Training loss: 1.7287704944610596
Validation loss: 2.2406109968821206

Epoch: 6| Step: 1
Training loss: 1.5538779497146606
Validation loss: 2.216401159763336

Epoch: 6| Step: 2
Training loss: 1.3740389347076416
Validation loss: 2.179290314515432

Epoch: 6| Step: 3
Training loss: 1.018263578414917
Validation loss: 2.170557975769043

Epoch: 6| Step: 4
Training loss: 0.8983098268508911
Validation loss: 2.2081023852030435

Epoch: 6| Step: 5
Training loss: 1.4626944065093994
Validation loss: 2.1853352586428323

Epoch: 6| Step: 6
Training loss: 1.6009786128997803
Validation loss: 2.197647452354431

Epoch: 6| Step: 7
Training loss: 1.8779200315475464
Validation loss: 2.166243612766266

Epoch: 6| Step: 8
Training loss: 0.9050782322883606
Validation loss: 2.188850382963816

Epoch: 6| Step: 9
Training loss: 0.8026190996170044
Validation loss: 2.2320507963498435

Epoch: 6| Step: 10
Training loss: 1.2050927877426147
Validation loss: 2.2328779896100364

Epoch: 6| Step: 11
Training loss: 1.5430011749267578
Validation loss: 2.2486403783162436

Epoch: 6| Step: 12
Training loss: 1.4314048290252686
Validation loss: 2.249779482682546

Epoch: 6| Step: 13
Training loss: 1.7906379699707031
Validation loss: 2.2401394049326577

Epoch: 330| Step: 0
Training loss: 1.576097846031189
Validation loss: 2.259291330973307

Epoch: 6| Step: 1
Training loss: 2.1324591636657715
Validation loss: 2.2765627106030784

Epoch: 6| Step: 2
Training loss: 1.1337181329727173
Validation loss: 2.2395706176757812

Epoch: 6| Step: 3
Training loss: 1.393103837966919
Validation loss: 2.2485656340916953

Epoch: 6| Step: 4
Training loss: 1.8439226150512695
Validation loss: 2.227372427781423

Epoch: 6| Step: 5
Training loss: 1.084333896636963
Validation loss: 2.2391210794448853

Epoch: 6| Step: 6
Training loss: 1.648730754852295
Validation loss: 2.2378705938657126

Epoch: 6| Step: 7
Training loss: 0.9484394788742065
Validation loss: 2.2460195819536843

Epoch: 6| Step: 8
Training loss: 1.2901616096496582
Validation loss: 2.2522042989730835

Epoch: 6| Step: 9
Training loss: 1.3210575580596924
Validation loss: 2.240053375562032

Epoch: 6| Step: 10
Training loss: 1.527660846710205
Validation loss: 2.2614713112513223

Epoch: 6| Step: 11
Training loss: 2.039609432220459
Validation loss: 2.2714932759602866

Epoch: 6| Step: 12
Training loss: 0.797531008720398
Validation loss: 2.2476011713345847

Epoch: 6| Step: 13
Training loss: 1.1399906873703003
Validation loss: 2.2493268251419067

Epoch: 331| Step: 0
Training loss: 1.3292323350906372
Validation loss: 2.2491790453592935

Epoch: 6| Step: 1
Training loss: 0.7376400232315063
Validation loss: 2.225606858730316

Epoch: 6| Step: 2
Training loss: 1.6259024143218994
Validation loss: 2.246306896209717

Epoch: 6| Step: 3
Training loss: 1.6311311721801758
Validation loss: 2.2365503112475076

Epoch: 6| Step: 4
Training loss: 1.2258872985839844
Validation loss: 2.2439757585525513

Epoch: 6| Step: 5
Training loss: 1.5106542110443115
Validation loss: 2.2219151655832925

Epoch: 6| Step: 6
Training loss: 1.0426616668701172
Validation loss: 2.2316671013832092

Epoch: 6| Step: 7
Training loss: 1.3482331037521362
Validation loss: 2.229395012060801

Epoch: 6| Step: 8
Training loss: 1.3383464813232422
Validation loss: 2.2376068035761514

Epoch: 6| Step: 9
Training loss: 1.8591898679733276
Validation loss: 2.275068203608195

Epoch: 6| Step: 10
Training loss: 1.3601218461990356
Validation loss: 2.257933815320333

Epoch: 6| Step: 11
Training loss: 1.77024507522583
Validation loss: 2.243508279323578

Epoch: 6| Step: 12
Training loss: 1.740272045135498
Validation loss: 2.218095382054647

Epoch: 6| Step: 13
Training loss: 0.912192702293396
Validation loss: 2.2046608527501426

Epoch: 332| Step: 0
Training loss: 1.6794202327728271
Validation loss: 2.2119257052739463

Epoch: 6| Step: 1
Training loss: 1.2678016424179077
Validation loss: 2.203834116458893

Epoch: 6| Step: 2
Training loss: 1.9336880445480347
Validation loss: 2.2119423349698386

Epoch: 6| Step: 3
Training loss: 1.4192036390304565
Validation loss: 2.215208431084951

Epoch: 6| Step: 4
Training loss: 1.1425482034683228
Validation loss: 2.241071085135142

Epoch: 6| Step: 5
Training loss: 1.2859561443328857
Validation loss: 2.2467224399248757

Epoch: 6| Step: 6
Training loss: 0.9809420108795166
Validation loss: 2.2164831360181174

Epoch: 6| Step: 7
Training loss: 1.269697904586792
Validation loss: 2.2307552893956504

Epoch: 6| Step: 8
Training loss: 1.7232468128204346
Validation loss: 2.222407341003418

Epoch: 6| Step: 9
Training loss: 2.068528175354004
Validation loss: 2.2541028459866843

Epoch: 6| Step: 10
Training loss: 0.8012231588363647
Validation loss: 2.2343358993530273

Epoch: 6| Step: 11
Training loss: 1.1472132205963135
Validation loss: 2.250009457270304

Epoch: 6| Step: 12
Training loss: 1.192042589187622
Validation loss: 2.2340672413508096

Epoch: 6| Step: 13
Training loss: 1.4919610023498535
Validation loss: 2.2563536564509072

Epoch: 333| Step: 0
Training loss: 2.009428024291992
Validation loss: 2.242947200934092

Epoch: 6| Step: 1
Training loss: 1.3625128269195557
Validation loss: 2.245191991329193

Epoch: 6| Step: 2
Training loss: 1.8563390970230103
Validation loss: 2.2693620522816977

Epoch: 6| Step: 3
Training loss: 1.2372288703918457
Validation loss: 2.273103952407837

Epoch: 6| Step: 4
Training loss: 1.3645577430725098
Validation loss: 2.3159605264663696

Epoch: 6| Step: 5
Training loss: 1.0508142709732056
Validation loss: 2.2695822715759277

Epoch: 6| Step: 6
Training loss: 1.525080919265747
Validation loss: 2.2509110371271768

Epoch: 6| Step: 7
Training loss: 0.8033615350723267
Validation loss: 2.2629254261652627

Epoch: 6| Step: 8
Training loss: 1.7167147397994995
Validation loss: 2.2269582947095237

Epoch: 6| Step: 9
Training loss: 0.9678491950035095
Validation loss: 2.2174710432688394

Epoch: 6| Step: 10
Training loss: 0.7374926805496216
Validation loss: 2.1797377665837607

Epoch: 6| Step: 11
Training loss: 0.8526325821876526
Validation loss: 2.1745206912358603

Epoch: 6| Step: 12
Training loss: 1.633955478668213
Validation loss: 2.2163860400517783

Epoch: 6| Step: 13
Training loss: 1.6966956853866577
Validation loss: 2.2123847007751465

Epoch: 334| Step: 0
Training loss: 1.5372974872589111
Validation loss: 2.2113301753997803

Epoch: 6| Step: 1
Training loss: 1.0310990810394287
Validation loss: 2.218827724456787

Epoch: 6| Step: 2
Training loss: 1.2591091394424438
Validation loss: 2.242569148540497

Epoch: 6| Step: 3
Training loss: 1.707916498184204
Validation loss: 2.237526059150696

Epoch: 6| Step: 4
Training loss: 1.218578577041626
Validation loss: 2.214330772558848

Epoch: 6| Step: 5
Training loss: 1.1570744514465332
Validation loss: 2.231464664141337

Epoch: 6| Step: 6
Training loss: 1.4078023433685303
Validation loss: 2.2406381964683533

Epoch: 6| Step: 7
Training loss: 1.065089225769043
Validation loss: 2.240453541278839

Epoch: 6| Step: 8
Training loss: 1.5531141757965088
Validation loss: 2.260430157184601

Epoch: 6| Step: 9
Training loss: 1.1800298690795898
Validation loss: 2.2740790049235025

Epoch: 6| Step: 10
Training loss: 1.862961769104004
Validation loss: 2.249711553255717

Epoch: 6| Step: 11
Training loss: 0.9903813600540161
Validation loss: 2.2852988640467324

Epoch: 6| Step: 12
Training loss: 1.295227289199829
Validation loss: 2.307975967725118

Epoch: 6| Step: 13
Training loss: 1.465121865272522
Validation loss: 2.2515636881192527

Epoch: 335| Step: 0
Training loss: 1.2586506605148315
Validation loss: 2.2782203753789267

Epoch: 6| Step: 1
Training loss: 1.3010468482971191
Validation loss: 2.253144383430481

Epoch: 6| Step: 2
Training loss: 1.4689304828643799
Validation loss: 2.2292016744613647

Epoch: 6| Step: 3
Training loss: 0.8283237814903259
Validation loss: 2.2544618447621665

Epoch: 6| Step: 4
Training loss: 1.4980298280715942
Validation loss: 2.2129942178726196

Epoch: 6| Step: 5
Training loss: 1.6229925155639648
Validation loss: 2.1678244272867837

Epoch: 6| Step: 6
Training loss: 1.5574226379394531
Validation loss: 2.156450629234314

Epoch: 6| Step: 7
Training loss: 1.8265851736068726
Validation loss: 2.1858335534731546

Epoch: 6| Step: 8
Training loss: 1.6086478233337402
Validation loss: 2.164555609226227

Epoch: 6| Step: 9
Training loss: 2.039661169052124
Validation loss: 2.1219311952590942

Epoch: 6| Step: 10
Training loss: 1.0067545175552368
Validation loss: 2.1218411723772683

Epoch: 6| Step: 11
Training loss: 1.596951961517334
Validation loss: 2.14202489455541

Epoch: 6| Step: 12
Training loss: 1.476651906967163
Validation loss: 2.125474274158478

Epoch: 6| Step: 13
Training loss: 1.2210437059402466
Validation loss: 2.1379199624061584

Epoch: 336| Step: 0
Training loss: 1.426504373550415
Validation loss: 2.159980535507202

Epoch: 6| Step: 1
Training loss: 1.3026789426803589
Validation loss: 2.1964995662371316

Epoch: 6| Step: 2
Training loss: 1.6383795738220215
Validation loss: 2.2274720668792725

Epoch: 6| Step: 3
Training loss: 1.4529197216033936
Validation loss: 2.208063324292501

Epoch: 6| Step: 4
Training loss: 1.2975513935089111
Validation loss: 2.2531781991322837

Epoch: 6| Step: 5
Training loss: 1.0748701095581055
Validation loss: 2.2261569102605185

Epoch: 6| Step: 6
Training loss: 1.082534909248352
Validation loss: 2.19542787472407

Epoch: 6| Step: 7
Training loss: 1.1368169784545898
Validation loss: 2.231450537840525

Epoch: 6| Step: 8
Training loss: 1.5359843969345093
Validation loss: 2.217436412970225

Epoch: 6| Step: 9
Training loss: 1.0780720710754395
Validation loss: 2.2191605965296426

Epoch: 6| Step: 10
Training loss: 1.0601531267166138
Validation loss: 2.1867300073305764

Epoch: 6| Step: 11
Training loss: 2.1136221885681152
Validation loss: 2.1997804840405784

Epoch: 6| Step: 12
Training loss: 2.386241912841797
Validation loss: 2.1945956349372864

Epoch: 6| Step: 13
Training loss: 1.7545690536499023
Validation loss: 2.209628244241079

Epoch: 337| Step: 0
Training loss: 1.34537672996521
Validation loss: 2.225037078062693

Epoch: 6| Step: 1
Training loss: 1.436842679977417
Validation loss: 2.2379963199297586

Epoch: 6| Step: 2
Training loss: 2.1628060340881348
Validation loss: 2.236816187699636

Epoch: 6| Step: 3
Training loss: 0.8066375851631165
Validation loss: 2.2794984579086304

Epoch: 6| Step: 4
Training loss: 1.69707190990448
Validation loss: 2.2641819516817727

Epoch: 6| Step: 5
Training loss: 1.8575066328048706
Validation loss: 2.2072934905687966

Epoch: 6| Step: 6
Training loss: 1.1699727773666382
Validation loss: 2.230551024278005

Epoch: 6| Step: 7
Training loss: 1.4957307577133179
Validation loss: 2.1935883363087973

Epoch: 6| Step: 8
Training loss: 1.4272129535675049
Validation loss: 2.1953919927279153

Epoch: 6| Step: 9
Training loss: 0.8082327842712402
Validation loss: 2.2010684410730996

Epoch: 6| Step: 10
Training loss: 1.2889978885650635
Validation loss: 2.204700251420339

Epoch: 6| Step: 11
Training loss: 1.2393311262130737
Validation loss: 2.1911187966664634

Epoch: 6| Step: 12
Training loss: 1.2834559679031372
Validation loss: 2.196611523628235

Epoch: 6| Step: 13
Training loss: 1.591800332069397
Validation loss: 2.175807555516561

Epoch: 338| Step: 0
Training loss: 1.4373047351837158
Validation loss: 2.188896377881368

Epoch: 6| Step: 1
Training loss: 1.531275749206543
Validation loss: 2.19725634654363

Epoch: 6| Step: 2
Training loss: 1.8140583038330078
Validation loss: 2.205141067504883

Epoch: 6| Step: 3
Training loss: 1.1036931276321411
Validation loss: 2.212728579839071

Epoch: 6| Step: 4
Training loss: 1.0173225402832031
Validation loss: 2.2091652154922485

Epoch: 6| Step: 5
Training loss: 1.4152005910873413
Validation loss: 2.1883253852526345

Epoch: 6| Step: 6
Training loss: 1.217126488685608
Validation loss: 2.2176899909973145

Epoch: 6| Step: 7
Training loss: 1.403764009475708
Validation loss: 2.2224541703859964

Epoch: 6| Step: 8
Training loss: 1.3115458488464355
Validation loss: 2.2090810338656106

Epoch: 6| Step: 9
Training loss: 1.045104742050171
Validation loss: 2.1928006410598755

Epoch: 6| Step: 10
Training loss: 1.4884337186813354
Validation loss: 2.2132882277170816

Epoch: 6| Step: 11
Training loss: 1.506471872329712
Validation loss: 2.2262271841367087

Epoch: 6| Step: 12
Training loss: 1.363216757774353
Validation loss: 2.2226144870122275

Epoch: 6| Step: 13
Training loss: 1.3015912771224976
Validation loss: 2.1624720295270285

Epoch: 339| Step: 0
Training loss: 1.133131980895996
Validation loss: 2.176866372426351

Epoch: 6| Step: 1
Training loss: 1.8855887651443481
Validation loss: 2.198728621006012

Epoch: 6| Step: 2
Training loss: 1.0779094696044922
Validation loss: 2.197788675626119

Epoch: 6| Step: 3
Training loss: 2.2026913166046143
Validation loss: 2.2172077695528665

Epoch: 6| Step: 4
Training loss: 1.7527674436569214
Validation loss: 2.21620245774587

Epoch: 6| Step: 5
Training loss: 1.3273255825042725
Validation loss: 2.233430027961731

Epoch: 6| Step: 6
Training loss: 1.1669518947601318
Validation loss: 2.2414828538894653

Epoch: 6| Step: 7
Training loss: 1.4020135402679443
Validation loss: 2.251488288243612

Epoch: 6| Step: 8
Training loss: 1.4790046215057373
Validation loss: 2.238962709903717

Epoch: 6| Step: 9
Training loss: 1.453107476234436
Validation loss: 2.2222920854886374

Epoch: 6| Step: 10
Training loss: 0.8801048994064331
Validation loss: 2.1995258927345276

Epoch: 6| Step: 11
Training loss: 1.3762484788894653
Validation loss: 2.196246643861135

Epoch: 6| Step: 12
Training loss: 1.2184144258499146
Validation loss: 2.1824444929758706

Epoch: 6| Step: 13
Training loss: 1.0235145092010498
Validation loss: 2.207584540049235

Epoch: 340| Step: 0
Training loss: 1.6209237575531006
Validation loss: 2.2294501066207886

Epoch: 6| Step: 1
Training loss: 1.5185751914978027
Validation loss: 2.2051812609036765

Epoch: 6| Step: 2
Training loss: 1.7381694316864014
Validation loss: 2.197559177875519

Epoch: 6| Step: 3
Training loss: 1.4358444213867188
Validation loss: 2.190327207247416

Epoch: 6| Step: 4
Training loss: 1.0232446193695068
Validation loss: 2.216538449128469

Epoch: 6| Step: 5
Training loss: 0.8281978964805603
Validation loss: 2.2163706024487815

Epoch: 6| Step: 6
Training loss: 0.7592325210571289
Validation loss: 2.202208856741587

Epoch: 6| Step: 7
Training loss: 1.1254948377609253
Validation loss: 2.2359719276428223

Epoch: 6| Step: 8
Training loss: 1.090627908706665
Validation loss: 2.2422359387079873

Epoch: 6| Step: 9
Training loss: 2.307312488555908
Validation loss: 2.2823543151219687

Epoch: 6| Step: 10
Training loss: 1.097528100013733
Validation loss: 2.2235060930252075

Epoch: 6| Step: 11
Training loss: 1.0620652437210083
Validation loss: 2.2122432788213096

Epoch: 6| Step: 12
Training loss: 1.8813450336456299
Validation loss: 2.247334122657776

Epoch: 6| Step: 13
Training loss: 1.5680654048919678
Validation loss: 2.2979111671447754

Epoch: 341| Step: 0
Training loss: 1.3834335803985596
Validation loss: 2.306854248046875

Epoch: 6| Step: 1
Training loss: 1.2644028663635254
Validation loss: 2.2642153898874917

Epoch: 6| Step: 2
Training loss: 1.5253766775131226
Validation loss: 2.299958904584249

Epoch: 6| Step: 3
Training loss: 1.0576932430267334
Validation loss: 2.266310155391693

Epoch: 6| Step: 4
Training loss: 1.75935697555542
Validation loss: 2.2539926568667092

Epoch: 6| Step: 5
Training loss: 1.2417569160461426
Validation loss: 2.2459627389907837

Epoch: 6| Step: 6
Training loss: 2.0514867305755615
Validation loss: 2.243101119995117

Epoch: 6| Step: 7
Training loss: 1.268574833869934
Validation loss: 2.256389935811361

Epoch: 6| Step: 8
Training loss: 0.8151479959487915
Validation loss: 2.2478265961011252

Epoch: 6| Step: 9
Training loss: 0.8937106132507324
Validation loss: 2.2351362307866416

Epoch: 6| Step: 10
Training loss: 1.4260375499725342
Validation loss: 2.2690398693084717

Epoch: 6| Step: 11
Training loss: 2.0254430770874023
Validation loss: 2.256926119327545

Epoch: 6| Step: 12
Training loss: 1.5928964614868164
Validation loss: 2.262017826239268

Epoch: 6| Step: 13
Training loss: 1.448017954826355
Validation loss: 2.278397798538208

Epoch: 342| Step: 0
Training loss: 1.1157993078231812
Validation loss: 2.2556286454200745

Epoch: 6| Step: 1
Training loss: 1.1245683431625366
Validation loss: 2.2581708629926047

Epoch: 6| Step: 2
Training loss: 1.2774484157562256
Validation loss: 2.256399909655253

Epoch: 6| Step: 3
Training loss: 1.0593702793121338
Validation loss: 2.2624221444129944

Epoch: 6| Step: 4
Training loss: 0.908195436000824
Validation loss: 2.234831611315409

Epoch: 6| Step: 5
Training loss: 2.0717854499816895
Validation loss: 2.2598417599995932

Epoch: 6| Step: 6
Training loss: 1.9965293407440186
Validation loss: 2.2618609269460044

Epoch: 6| Step: 7
Training loss: 0.9472025632858276
Validation loss: 2.2229167222976685

Epoch: 6| Step: 8
Training loss: 1.2741044759750366
Validation loss: 2.2621206839879355

Epoch: 6| Step: 9
Training loss: 1.3210980892181396
Validation loss: 2.235592305660248

Epoch: 6| Step: 10
Training loss: 1.6741738319396973
Validation loss: 2.2566782434781394

Epoch: 6| Step: 11
Training loss: 1.1607820987701416
Validation loss: 2.2637229760487876

Epoch: 6| Step: 12
Training loss: 1.0614380836486816
Validation loss: 2.251846889654795

Epoch: 6| Step: 13
Training loss: 1.6523902416229248
Validation loss: 2.2349149187405906

Epoch: 343| Step: 0
Training loss: 1.2183849811553955
Validation loss: 2.25890185435613

Epoch: 6| Step: 1
Training loss: 1.7342708110809326
Validation loss: 2.2619590759277344

Epoch: 6| Step: 2
Training loss: 0.8547393679618835
Validation loss: 2.225397845109304

Epoch: 6| Step: 3
Training loss: 0.9326820373535156
Validation loss: 2.207507312297821

Epoch: 6| Step: 4
Training loss: 1.6192872524261475
Validation loss: 2.2124433716138205

Epoch: 6| Step: 5
Training loss: 1.0553007125854492
Validation loss: 2.1846208771069846

Epoch: 6| Step: 6
Training loss: 0.7125362157821655
Validation loss: 2.21200038989385

Epoch: 6| Step: 7
Training loss: 2.08595871925354
Validation loss: 2.209464689095815

Epoch: 6| Step: 8
Training loss: 1.8576529026031494
Validation loss: 2.204520801703135

Epoch: 6| Step: 9
Training loss: 1.0670666694641113
Validation loss: 2.176350017388662

Epoch: 6| Step: 10
Training loss: 0.8750413656234741
Validation loss: 2.2332939902941384

Epoch: 6| Step: 11
Training loss: 2.119110107421875
Validation loss: 2.2538020809491477

Epoch: 6| Step: 12
Training loss: 1.6056870222091675
Validation loss: 2.224203566710154

Epoch: 6| Step: 13
Training loss: 1.2066752910614014
Validation loss: 2.260793685913086

Epoch: 344| Step: 0
Training loss: 1.713390588760376
Validation loss: 2.234965125719706

Epoch: 6| Step: 1
Training loss: 1.0307798385620117
Validation loss: 2.2224172751108804

Epoch: 6| Step: 2
Training loss: 1.9489874839782715
Validation loss: 2.192090074221293

Epoch: 6| Step: 3
Training loss: 1.687848448753357
Validation loss: 2.1920128663380942

Epoch: 6| Step: 4
Training loss: 1.0661723613739014
Validation loss: 2.1886515617370605

Epoch: 6| Step: 5
Training loss: 0.727263867855072
Validation loss: 2.203027844429016

Epoch: 6| Step: 6
Training loss: 1.1148213148117065
Validation loss: 2.209040323893229

Epoch: 6| Step: 7
Training loss: 1.5379260778427124
Validation loss: 2.2258021434148154

Epoch: 6| Step: 8
Training loss: 1.8893088102340698
Validation loss: 2.2193487683931985

Epoch: 6| Step: 9
Training loss: 1.3545863628387451
Validation loss: 2.2086226542790732

Epoch: 6| Step: 10
Training loss: 1.4244040250778198
Validation loss: 2.1997719407081604

Epoch: 6| Step: 11
Training loss: 1.4473520517349243
Validation loss: 2.2071622411410012

Epoch: 6| Step: 12
Training loss: 0.6962348222732544
Validation loss: 2.183543006579081

Epoch: 6| Step: 13
Training loss: 1.6018768548965454
Validation loss: 2.2252575556437173

Epoch: 345| Step: 0
Training loss: 1.422452449798584
Validation loss: 2.1910140117009482

Epoch: 6| Step: 1
Training loss: 0.8010619878768921
Validation loss: 2.1767670114835105

Epoch: 6| Step: 2
Training loss: 1.5188660621643066
Validation loss: 2.1778546571731567

Epoch: 6| Step: 3
Training loss: 1.2761433124542236
Validation loss: 2.143791834513346

Epoch: 6| Step: 4
Training loss: 1.024695873260498
Validation loss: 2.1746799548467

Epoch: 6| Step: 5
Training loss: 2.1822595596313477
Validation loss: 2.1173362135887146

Epoch: 6| Step: 6
Training loss: 1.0894553661346436
Validation loss: 2.1408650080362954

Epoch: 6| Step: 7
Training loss: 1.8191566467285156
Validation loss: 2.1593759457270303

Epoch: 6| Step: 8
Training loss: 1.4192900657653809
Validation loss: 2.16071883837382

Epoch: 6| Step: 9
Training loss: 1.298353910446167
Validation loss: 2.193905691305796

Epoch: 6| Step: 10
Training loss: 1.3722854852676392
Validation loss: 2.1720826824506125

Epoch: 6| Step: 11
Training loss: 1.5602344274520874
Validation loss: 2.1718561251958213

Epoch: 6| Step: 12
Training loss: 1.1268479824066162
Validation loss: 2.1441263357798257

Epoch: 6| Step: 13
Training loss: 1.3224543333053589
Validation loss: 2.170060137907664

Epoch: 346| Step: 0
Training loss: 1.3005988597869873
Validation loss: 2.163520574569702

Epoch: 6| Step: 1
Training loss: 1.7305340766906738
Validation loss: 2.1456634600957236

Epoch: 6| Step: 2
Training loss: 1.4902355670928955
Validation loss: 2.1463302175203958

Epoch: 6| Step: 3
Training loss: 1.227308750152588
Validation loss: 2.160313626130422

Epoch: 6| Step: 4
Training loss: 1.255820393562317
Validation loss: 2.155413250128428

Epoch: 6| Step: 5
Training loss: 1.3706307411193848
Validation loss: 2.2029753923416138

Epoch: 6| Step: 6
Training loss: 1.4389674663543701
Validation loss: 2.18925412495931

Epoch: 6| Step: 7
Training loss: 1.1473734378814697
Validation loss: 2.206968148549398

Epoch: 6| Step: 8
Training loss: 0.7643045783042908
Validation loss: 2.20084555943807

Epoch: 6| Step: 9
Training loss: 0.8136762380599976
Validation loss: 2.2137447198232016

Epoch: 6| Step: 10
Training loss: 1.5659922361373901
Validation loss: 2.1842146714528403

Epoch: 6| Step: 11
Training loss: 1.6307352781295776
Validation loss: 2.21222052971522

Epoch: 6| Step: 12
Training loss: 1.7746608257293701
Validation loss: 2.2101009289423623

Epoch: 6| Step: 13
Training loss: 1.029693603515625
Validation loss: 2.21780397494634

Epoch: 347| Step: 0
Training loss: 2.107487201690674
Validation loss: 2.2374282479286194

Epoch: 6| Step: 1
Training loss: 1.8237532377243042
Validation loss: 2.225258767604828

Epoch: 6| Step: 2
Training loss: 1.057051420211792
Validation loss: 2.2096136013666787

Epoch: 6| Step: 3
Training loss: 0.8173695206642151
Validation loss: 2.228243907292684

Epoch: 6| Step: 4
Training loss: 1.4811973571777344
Validation loss: 2.207700252532959

Epoch: 6| Step: 5
Training loss: 1.263258934020996
Validation loss: 2.2128751476605735

Epoch: 6| Step: 6
Training loss: 1.5095815658569336
Validation loss: 2.235332806905111

Epoch: 6| Step: 7
Training loss: 1.0078022480010986
Validation loss: 2.184022625287374

Epoch: 6| Step: 8
Training loss: 1.0376651287078857
Validation loss: 2.2308958172798157

Epoch: 6| Step: 9
Training loss: 1.3281071186065674
Validation loss: 2.2206320762634277

Epoch: 6| Step: 10
Training loss: 1.002356767654419
Validation loss: 2.183464070161184

Epoch: 6| Step: 11
Training loss: 1.2505698204040527
Validation loss: 2.2078603307406106

Epoch: 6| Step: 12
Training loss: 1.0759122371673584
Validation loss: 2.1828668117523193

Epoch: 6| Step: 13
Training loss: 1.200668215751648
Validation loss: 2.17563259601593

Epoch: 348| Step: 0
Training loss: 0.5617431402206421
Validation loss: 2.173757255077362

Epoch: 6| Step: 1
Training loss: 1.7963461875915527
Validation loss: 2.195866505304972

Epoch: 6| Step: 2
Training loss: 1.0487220287322998
Validation loss: 2.166496992111206

Epoch: 6| Step: 3
Training loss: 1.2025959491729736
Validation loss: 2.176717976729075

Epoch: 6| Step: 4
Training loss: 0.9096426367759705
Validation loss: 2.1679497957229614

Epoch: 6| Step: 5
Training loss: 2.0201261043548584
Validation loss: 2.199990232785543

Epoch: 6| Step: 6
Training loss: 1.0242207050323486
Validation loss: 2.181098461151123

Epoch: 6| Step: 7
Training loss: 1.5246288776397705
Validation loss: 2.19892026980718

Epoch: 6| Step: 8
Training loss: 1.133781909942627
Validation loss: 2.2130929629007974

Epoch: 6| Step: 9
Training loss: 1.875666856765747
Validation loss: 2.242888569831848

Epoch: 6| Step: 10
Training loss: 1.9060207605361938
Validation loss: 2.2435825864473977

Epoch: 6| Step: 11
Training loss: 0.8901499509811401
Validation loss: 2.25761087735494

Epoch: 6| Step: 12
Training loss: 0.8594104647636414
Validation loss: 2.189651091893514

Epoch: 6| Step: 13
Training loss: 1.8068797588348389
Validation loss: 2.191244383653005

Epoch: 349| Step: 0
Training loss: 1.1825993061065674
Validation loss: 2.213287631670634

Epoch: 6| Step: 1
Training loss: 1.6118452548980713
Validation loss: 2.19895871480306

Epoch: 6| Step: 2
Training loss: 1.9285811185836792
Validation loss: 2.207077701886495

Epoch: 6| Step: 3
Training loss: 1.1977381706237793
Validation loss: 2.197059611479441

Epoch: 6| Step: 4
Training loss: 1.5067501068115234
Validation loss: 2.210277716318766

Epoch: 6| Step: 5
Training loss: 1.04062819480896
Validation loss: 2.199392795562744

Epoch: 6| Step: 6
Training loss: 1.2489982843399048
Validation loss: 2.1899030804634094

Epoch: 6| Step: 7
Training loss: 1.99685800075531
Validation loss: 2.1913979848225913

Epoch: 6| Step: 8
Training loss: 1.6427738666534424
Validation loss: 2.1840869784355164

Epoch: 6| Step: 9
Training loss: 0.9149177670478821
Validation loss: 2.2232888539632163

Epoch: 6| Step: 10
Training loss: 1.0433223247528076
Validation loss: 2.1809462308883667

Epoch: 6| Step: 11
Training loss: 1.2674565315246582
Validation loss: 2.201129953066508

Epoch: 6| Step: 12
Training loss: 0.7065662145614624
Validation loss: 2.149810552597046

Epoch: 6| Step: 13
Training loss: 1.600902795791626
Validation loss: 2.1791484157244363

Epoch: 350| Step: 0
Training loss: 1.331319808959961
Validation loss: 2.1760021249453225

Epoch: 6| Step: 1
Training loss: 1.7310893535614014
Validation loss: 2.182978709538778

Epoch: 6| Step: 2
Training loss: 1.6686856746673584
Validation loss: 2.2132856051127114

Epoch: 6| Step: 3
Training loss: 1.300318956375122
Validation loss: 2.1851250926653543

Epoch: 6| Step: 4
Training loss: 1.37344491481781
Validation loss: 2.199834485848745

Epoch: 6| Step: 5
Training loss: 1.7026865482330322
Validation loss: 2.1652337114016214

Epoch: 6| Step: 6
Training loss: 1.001826524734497
Validation loss: 2.1695120334625244

Epoch: 6| Step: 7
Training loss: 0.9200038909912109
Validation loss: 2.1667017539342246

Epoch: 6| Step: 8
Training loss: 1.7290961742401123
Validation loss: 2.2256375551223755

Epoch: 6| Step: 9
Training loss: 1.2247599363327026
Validation loss: 2.2166815598805747

Epoch: 6| Step: 10
Training loss: 0.7933248281478882
Validation loss: 2.2092301845550537

Epoch: 6| Step: 11
Training loss: 1.310823678970337
Validation loss: 2.1994201143582663

Epoch: 6| Step: 12
Training loss: 1.2683337926864624
Validation loss: 2.2237650950749717

Epoch: 6| Step: 13
Training loss: 1.2064037322998047
Validation loss: 2.187570949395498

Epoch: 351| Step: 0
Training loss: 0.6204397678375244
Validation loss: 2.18741246064504

Epoch: 6| Step: 1
Training loss: 1.7922825813293457
Validation loss: 2.201786200205485

Epoch: 6| Step: 2
Training loss: 1.626103162765503
Validation loss: 2.186452865600586

Epoch: 6| Step: 3
Training loss: 1.2078800201416016
Validation loss: 2.2057008941968284

Epoch: 6| Step: 4
Training loss: 1.2160828113555908
Validation loss: 2.2357176740964255

Epoch: 6| Step: 5
Training loss: 1.1758592128753662
Validation loss: 2.2377955118815103

Epoch: 6| Step: 6
Training loss: 0.8063782453536987
Validation loss: 2.2506717244784036

Epoch: 6| Step: 7
Training loss: 1.1780002117156982
Validation loss: 2.244824171066284

Epoch: 6| Step: 8
Training loss: 0.7811842560768127
Validation loss: 2.266560713450114

Epoch: 6| Step: 9
Training loss: 2.403836965560913
Validation loss: 2.237719476222992

Epoch: 6| Step: 10
Training loss: 1.1684101819992065
Validation loss: 2.2249701023101807

Epoch: 6| Step: 11
Training loss: 1.445587396621704
Validation loss: 2.2286739548047385

Epoch: 6| Step: 12
Training loss: 1.4490127563476562
Validation loss: 2.2059080998102822

Epoch: 6| Step: 13
Training loss: 1.4588191509246826
Validation loss: 2.2330408096313477

Epoch: 352| Step: 0
Training loss: 0.8155373334884644
Validation loss: 2.219851553440094

Epoch: 6| Step: 1
Training loss: 0.8958483934402466
Validation loss: 2.2233696579933167

Epoch: 6| Step: 2
Training loss: 1.2077029943466187
Validation loss: 2.2232096592585244

Epoch: 6| Step: 3
Training loss: 0.8688055276870728
Validation loss: 2.221148351828257

Epoch: 6| Step: 4
Training loss: 1.4213796854019165
Validation loss: 2.2314887841542563

Epoch: 6| Step: 5
Training loss: 1.008378267288208
Validation loss: 2.2274422645568848

Epoch: 6| Step: 6
Training loss: 1.400256633758545
Validation loss: 2.2391114632288613

Epoch: 6| Step: 7
Training loss: 1.2577013969421387
Validation loss: 2.244947870572408

Epoch: 6| Step: 8
Training loss: 1.4841463565826416
Validation loss: 2.2433790961901345

Epoch: 6| Step: 9
Training loss: 1.400172472000122
Validation loss: 2.24666690826416

Epoch: 6| Step: 10
Training loss: 2.2313404083251953
Validation loss: 2.2440397143363953

Epoch: 6| Step: 11
Training loss: 1.4396812915802002
Validation loss: 2.248985528945923

Epoch: 6| Step: 12
Training loss: 0.9624027013778687
Validation loss: 2.232648491859436

Epoch: 6| Step: 13
Training loss: 1.137110710144043
Validation loss: 2.248447914918264

Epoch: 353| Step: 0
Training loss: 1.2058508396148682
Validation loss: 2.2470844785372415

Epoch: 6| Step: 1
Training loss: 1.89906644821167
Validation loss: 2.262977381547292

Epoch: 6| Step: 2
Training loss: 1.0515536069869995
Validation loss: 2.2251948714256287

Epoch: 6| Step: 3
Training loss: 1.2764990329742432
Validation loss: 2.2599136432011924

Epoch: 6| Step: 4
Training loss: 1.2991552352905273
Validation loss: 2.234448492527008

Epoch: 6| Step: 5
Training loss: 0.6509872674942017
Validation loss: 2.2521102825800576

Epoch: 6| Step: 6
Training loss: 1.487856388092041
Validation loss: 2.248355050881704

Epoch: 6| Step: 7
Training loss: 0.9189974665641785
Validation loss: 2.2681326866149902

Epoch: 6| Step: 8
Training loss: 1.1897999048233032
Validation loss: 2.2278338074684143

Epoch: 6| Step: 9
Training loss: 1.1778061389923096
Validation loss: 2.2262107729911804

Epoch: 6| Step: 10
Training loss: 1.479190468788147
Validation loss: 2.196856359640757

Epoch: 6| Step: 11
Training loss: 1.435481309890747
Validation loss: 2.2344290812810264

Epoch: 6| Step: 12
Training loss: 1.0064454078674316
Validation loss: 2.2241192857424417

Epoch: 6| Step: 13
Training loss: 1.5969642400741577
Validation loss: 2.2186311880747476

Epoch: 354| Step: 0
Training loss: 1.315765142440796
Validation loss: 2.2148830890655518

Epoch: 6| Step: 1
Training loss: 2.032454013824463
Validation loss: 2.2173247933387756

Epoch: 6| Step: 2
Training loss: 1.1958351135253906
Validation loss: 2.254774808883667

Epoch: 6| Step: 3
Training loss: 2.3456192016601562
Validation loss: 2.2285468777020774

Epoch: 6| Step: 4
Training loss: 1.3062788248062134
Validation loss: 2.2192887465159097

Epoch: 6| Step: 5
Training loss: 0.8304253220558167
Validation loss: 2.233840584754944

Epoch: 6| Step: 6
Training loss: 1.0855836868286133
Validation loss: 2.218371331691742

Epoch: 6| Step: 7
Training loss: 1.0674054622650146
Validation loss: 2.2312453786532083

Epoch: 6| Step: 8
Training loss: 0.958549976348877
Validation loss: 2.2047552267710366

Epoch: 6| Step: 9
Training loss: 0.8529667854309082
Validation loss: 2.1824925939242044

Epoch: 6| Step: 10
Training loss: 0.96636962890625
Validation loss: 2.1680778662363687

Epoch: 6| Step: 11
Training loss: 1.2784969806671143
Validation loss: 2.1583920319875083

Epoch: 6| Step: 12
Training loss: 1.4635944366455078
Validation loss: 2.168895343939463

Epoch: 6| Step: 13
Training loss: 1.3195981979370117
Validation loss: 2.1872701247533164

Epoch: 355| Step: 0
Training loss: 1.367542028427124
Validation loss: 2.214668393135071

Epoch: 6| Step: 1
Training loss: 1.4763628244400024
Validation loss: 2.201703906059265

Epoch: 6| Step: 2
Training loss: 0.9043569564819336
Validation loss: 2.180085062980652

Epoch: 6| Step: 3
Training loss: 0.7263413667678833
Validation loss: 2.2189205487569175

Epoch: 6| Step: 4
Training loss: 1.94919753074646
Validation loss: 2.1570266683896384

Epoch: 6| Step: 5
Training loss: 1.5250661373138428
Validation loss: 2.137949506441752

Epoch: 6| Step: 6
Training loss: 1.6936790943145752
Validation loss: 2.175803244113922

Epoch: 6| Step: 7
Training loss: 0.779679536819458
Validation loss: 2.1845742662747702

Epoch: 6| Step: 8
Training loss: 2.0211408138275146
Validation loss: 2.16532435019811

Epoch: 6| Step: 9
Training loss: 1.591400146484375
Validation loss: 2.157259225845337

Epoch: 6| Step: 10
Training loss: 0.8467281460762024
Validation loss: 2.1367409427960715

Epoch: 6| Step: 11
Training loss: 1.1348910331726074
Validation loss: 2.14207790295283

Epoch: 6| Step: 12
Training loss: 0.6726425886154175
Validation loss: 2.143748104572296

Epoch: 6| Step: 13
Training loss: 1.5916186571121216
Validation loss: 2.1423919200897217

Epoch: 356| Step: 0
Training loss: 1.6410608291625977
Validation loss: 2.1750700076421103

Epoch: 6| Step: 1
Training loss: 1.333503007888794
Validation loss: 2.2154157757759094

Epoch: 6| Step: 2
Training loss: 2.1617112159729004
Validation loss: 2.212457021077474

Epoch: 6| Step: 3
Training loss: 1.9021583795547485
Validation loss: 2.20086270570755

Epoch: 6| Step: 4
Training loss: 1.2698416709899902
Validation loss: 2.1973724365234375

Epoch: 6| Step: 5
Training loss: 1.3387871980667114
Validation loss: 2.1957454681396484

Epoch: 6| Step: 6
Training loss: 1.5128591060638428
Validation loss: 2.1727716525395713

Epoch: 6| Step: 7
Training loss: 1.3262708187103271
Validation loss: 2.1571171482404075

Epoch: 6| Step: 8
Training loss: 1.6445865631103516
Validation loss: 2.1969664891560874

Epoch: 6| Step: 9
Training loss: 1.1468513011932373
Validation loss: 2.2284966707229614

Epoch: 6| Step: 10
Training loss: 0.9643903970718384
Validation loss: 2.238042136033376

Epoch: 6| Step: 11
Training loss: 1.052648901939392
Validation loss: 2.2752909064292908

Epoch: 6| Step: 12
Training loss: 1.0244090557098389
Validation loss: 2.2941415309906006

Epoch: 6| Step: 13
Training loss: 1.4109796285629272
Validation loss: 2.294136563936869

Epoch: 357| Step: 0
Training loss: 1.6990514993667603
Validation loss: 2.285235265890757

Epoch: 6| Step: 1
Training loss: 1.3167603015899658
Validation loss: 2.2686646382013955

Epoch: 6| Step: 2
Training loss: 1.2256391048431396
Validation loss: 2.2302828629811606

Epoch: 6| Step: 3
Training loss: 0.8256669640541077
Validation loss: 2.2179927627245584

Epoch: 6| Step: 4
Training loss: 2.128070592880249
Validation loss: 2.187950054804484

Epoch: 6| Step: 5
Training loss: 1.2417957782745361
Validation loss: 2.21030322710673

Epoch: 6| Step: 6
Training loss: 1.7833523750305176
Validation loss: 2.190824270248413

Epoch: 6| Step: 7
Training loss: 2.2752652168273926
Validation loss: 2.2244487404823303

Epoch: 6| Step: 8
Training loss: 0.9675433039665222
Validation loss: 2.22866819302241

Epoch: 6| Step: 9
Training loss: 0.9487515687942505
Validation loss: 2.224881092707316

Epoch: 6| Step: 10
Training loss: 0.7889715433120728
Validation loss: 2.2191196282704673

Epoch: 6| Step: 11
Training loss: 1.4653452634811401
Validation loss: 2.2133793433507285

Epoch: 6| Step: 12
Training loss: 1.4450578689575195
Validation loss: 2.232970734437307

Epoch: 6| Step: 13
Training loss: 0.9153603315353394
Validation loss: 2.2563577691713967

Epoch: 358| Step: 0
Training loss: 1.4190714359283447
Validation loss: 2.2717125415802

Epoch: 6| Step: 1
Training loss: 1.5819224119186401
Validation loss: 2.265182097752889

Epoch: 6| Step: 2
Training loss: 1.6539454460144043
Validation loss: 2.2762572367986045

Epoch: 6| Step: 3
Training loss: 1.8707687854766846
Validation loss: 2.247698942820231

Epoch: 6| Step: 4
Training loss: 1.9533988237380981
Validation loss: 2.2723854382832847

Epoch: 6| Step: 5
Training loss: 0.9329321384429932
Validation loss: 2.2332997719446817

Epoch: 6| Step: 6
Training loss: 0.7688617706298828
Validation loss: 2.256114741166433

Epoch: 6| Step: 7
Training loss: 0.9845587015151978
Validation loss: 2.216160535812378

Epoch: 6| Step: 8
Training loss: 0.645505428314209
Validation loss: 2.2122457226117453

Epoch: 6| Step: 9
Training loss: 1.2554283142089844
Validation loss: 2.2302457888921103

Epoch: 6| Step: 10
Training loss: 1.2474031448364258
Validation loss: 2.2230459650357566

Epoch: 6| Step: 11
Training loss: 1.289944052696228
Validation loss: 2.205891410509745

Epoch: 6| Step: 12
Training loss: 1.6983752250671387
Validation loss: 2.204490065574646

Epoch: 6| Step: 13
Training loss: 1.741224765777588
Validation loss: 2.2019943396250405

Epoch: 359| Step: 0
Training loss: 2.019782304763794
Validation loss: 2.1936360597610474

Epoch: 6| Step: 1
Training loss: 0.8946835398674011
Validation loss: 2.208998680114746

Epoch: 6| Step: 2
Training loss: 1.1981830596923828
Validation loss: 2.203646103541056

Epoch: 6| Step: 3
Training loss: 0.6127947568893433
Validation loss: 2.2282095154126487

Epoch: 6| Step: 4
Training loss: 1.5436592102050781
Validation loss: 2.236303448677063

Epoch: 6| Step: 5
Training loss: 1.087406873703003
Validation loss: 2.221674919128418

Epoch: 6| Step: 6
Training loss: 0.7105224132537842
Validation loss: 2.226361552874247

Epoch: 6| Step: 7
Training loss: 1.8652570247650146
Validation loss: 2.246132751305898

Epoch: 6| Step: 8
Training loss: 1.3253090381622314
Validation loss: 2.2108930945396423

Epoch: 6| Step: 9
Training loss: 1.0800435543060303
Validation loss: 2.2050753434499106

Epoch: 6| Step: 10
Training loss: 0.9710512161254883
Validation loss: 2.216723362604777

Epoch: 6| Step: 11
Training loss: 2.0548572540283203
Validation loss: 2.2243682146072388

Epoch: 6| Step: 12
Training loss: 1.560437560081482
Validation loss: 2.207600017388662

Epoch: 6| Step: 13
Training loss: 1.0686675310134888
Validation loss: 2.21416038274765

Epoch: 360| Step: 0
Training loss: 1.0001686811447144
Validation loss: 2.1864638129870095

Epoch: 6| Step: 1
Training loss: 1.420630931854248
Validation loss: 2.180725375811259

Epoch: 6| Step: 2
Training loss: 0.9220349788665771
Validation loss: 2.169096807638804

Epoch: 6| Step: 3
Training loss: 1.519132375717163
Validation loss: 2.2311075925827026

Epoch: 6| Step: 4
Training loss: 1.889435887336731
Validation loss: 2.2082337935765586

Epoch: 6| Step: 5
Training loss: 1.8455815315246582
Validation loss: 2.2035709818204245

Epoch: 6| Step: 6
Training loss: 1.201690435409546
Validation loss: 2.199874997138977

Epoch: 6| Step: 7
Training loss: 1.4543042182922363
Validation loss: 2.191200931866964

Epoch: 6| Step: 8
Training loss: 1.1212983131408691
Validation loss: 2.254067122936249

Epoch: 6| Step: 9
Training loss: 1.3415641784667969
Validation loss: 2.2454910477002463

Epoch: 6| Step: 10
Training loss: 0.6068974137306213
Validation loss: 2.2578588724136353

Epoch: 6| Step: 11
Training loss: 0.8629772067070007
Validation loss: 2.2423646450042725

Epoch: 6| Step: 12
Training loss: 1.1202847957611084
Validation loss: 2.223686456680298

Epoch: 6| Step: 13
Training loss: 1.4352357387542725
Validation loss: 2.2113654613494873

Epoch: 361| Step: 0
Training loss: 1.1708968877792358
Validation loss: 2.2220925291379294

Epoch: 6| Step: 1
Training loss: 1.4357028007507324
Validation loss: 2.2185192505518594

Epoch: 6| Step: 2
Training loss: 0.8578450679779053
Validation loss: 2.213048497835795

Epoch: 6| Step: 3
Training loss: 1.148653268814087
Validation loss: 2.237727681795756

Epoch: 6| Step: 4
Training loss: 0.8766284584999084
Validation loss: 2.2125315268834433

Epoch: 6| Step: 5
Training loss: 1.6624995470046997
Validation loss: 2.2322192390759787

Epoch: 6| Step: 6
Training loss: 1.3506317138671875
Validation loss: 2.2487554947535195

Epoch: 6| Step: 7
Training loss: 1.393770456314087
Validation loss: 2.2488990227381387

Epoch: 6| Step: 8
Training loss: 0.6106140613555908
Validation loss: 2.264803091684977

Epoch: 6| Step: 9
Training loss: 1.9255605936050415
Validation loss: 2.311629851659139

Epoch: 6| Step: 10
Training loss: 1.1266945600509644
Validation loss: 2.2829299370447793

Epoch: 6| Step: 11
Training loss: 1.6819944381713867
Validation loss: 2.295683979988098

Epoch: 6| Step: 12
Training loss: 1.0941531658172607
Validation loss: 2.2754951318105063

Epoch: 6| Step: 13
Training loss: 1.2377569675445557
Validation loss: 2.280165751775106

Epoch: 362| Step: 0
Training loss: 0.9167979955673218
Validation loss: 2.2602892319361367

Epoch: 6| Step: 1
Training loss: 1.7129302024841309
Validation loss: 2.2011494239171348

Epoch: 6| Step: 2
Training loss: 0.9108452796936035
Validation loss: 2.2095005909601846

Epoch: 6| Step: 3
Training loss: 1.0355660915374756
Validation loss: 2.1931189695994058

Epoch: 6| Step: 4
Training loss: 0.7316967248916626
Validation loss: 2.1960219343503318

Epoch: 6| Step: 5
Training loss: 1.158969521522522
Validation loss: 2.17206863562266

Epoch: 6| Step: 6
Training loss: 1.8172996044158936
Validation loss: 2.1881059408187866

Epoch: 6| Step: 7
Training loss: 1.7142601013183594
Validation loss: 2.1898382703463235

Epoch: 6| Step: 8
Training loss: 0.9442386031150818
Validation loss: 2.1896767218907676

Epoch: 6| Step: 9
Training loss: 1.305092215538025
Validation loss: 2.179173549016317

Epoch: 6| Step: 10
Training loss: 1.0433595180511475
Validation loss: 2.1607781449953714

Epoch: 6| Step: 11
Training loss: 1.4591186046600342
Validation loss: 2.174471835295359

Epoch: 6| Step: 12
Training loss: 1.7238407135009766
Validation loss: 2.2022621432940164

Epoch: 6| Step: 13
Training loss: 1.225682258605957
Validation loss: 2.201221505800883

Epoch: 363| Step: 0
Training loss: 1.9312318563461304
Validation loss: 2.218184173107147

Epoch: 6| Step: 1
Training loss: 1.1828608512878418
Validation loss: 2.2576527198155723

Epoch: 6| Step: 2
Training loss: 1.0469623804092407
Validation loss: 2.264006793498993

Epoch: 6| Step: 3
Training loss: 1.5417907238006592
Validation loss: 2.3001997669537864

Epoch: 6| Step: 4
Training loss: 1.043748140335083
Validation loss: 2.2754663030306497

Epoch: 6| Step: 5
Training loss: 1.2033677101135254
Validation loss: 2.268212596575419

Epoch: 6| Step: 6
Training loss: 2.2039954662323
Validation loss: 2.2649588187535605

Epoch: 6| Step: 7
Training loss: 0.9371299147605896
Validation loss: 2.2227245767911277

Epoch: 6| Step: 8
Training loss: 0.854555070400238
Validation loss: 2.2308122913042703

Epoch: 6| Step: 9
Training loss: 1.1420772075653076
Validation loss: 2.168361186981201

Epoch: 6| Step: 10
Training loss: 1.1415410041809082
Validation loss: 2.1990996996561685

Epoch: 6| Step: 11
Training loss: 0.822924017906189
Validation loss: 2.1730669339497886

Epoch: 6| Step: 12
Training loss: 0.9136154651641846
Validation loss: 2.176900585492452

Epoch: 6| Step: 13
Training loss: 1.9952030181884766
Validation loss: 2.1997349858283997

Epoch: 364| Step: 0
Training loss: 1.1663594245910645
Validation loss: 2.1502880255381265

Epoch: 6| Step: 1
Training loss: 0.9893909096717834
Validation loss: 2.1663758556048074

Epoch: 6| Step: 2
Training loss: 1.8881100416183472
Validation loss: 2.1559002796808877

Epoch: 6| Step: 3
Training loss: 1.1625248193740845
Validation loss: 2.180407007535299

Epoch: 6| Step: 4
Training loss: 1.4185383319854736
Validation loss: 2.2141111691792807

Epoch: 6| Step: 5
Training loss: 0.6595269441604614
Validation loss: 2.2139776945114136

Epoch: 6| Step: 6
Training loss: 1.1240915060043335
Validation loss: 2.1968639294306436

Epoch: 6| Step: 7
Training loss: 1.4398574829101562
Validation loss: 2.1795663038889566

Epoch: 6| Step: 8
Training loss: 0.9167361855506897
Validation loss: 2.2636364897092185

Epoch: 6| Step: 9
Training loss: 1.2181569337844849
Validation loss: 2.203338861465454

Epoch: 6| Step: 10
Training loss: 1.5109834671020508
Validation loss: 2.1927398840586343

Epoch: 6| Step: 11
Training loss: 1.0696542263031006
Validation loss: 2.2049012382825217

Epoch: 6| Step: 12
Training loss: 0.7122717499732971
Validation loss: 2.2204399903615317

Epoch: 6| Step: 13
Training loss: 1.84175705909729
Validation loss: 2.163770775000254

Epoch: 365| Step: 0
Training loss: 0.9949801564216614
Validation loss: 2.20015279452006

Epoch: 6| Step: 1
Training loss: 0.8057441711425781
Validation loss: 2.213911294937134

Epoch: 6| Step: 2
Training loss: 2.704401969909668
Validation loss: 2.1848739186922708

Epoch: 6| Step: 3
Training loss: 1.2140133380889893
Validation loss: 2.184476137161255

Epoch: 6| Step: 4
Training loss: 1.2361834049224854
Validation loss: 2.1722217003504434

Epoch: 6| Step: 5
Training loss: 0.9487957954406738
Validation loss: 2.1583173076311746

Epoch: 6| Step: 6
Training loss: 1.0075589418411255
Validation loss: 2.1667213241259256

Epoch: 6| Step: 7
Training loss: 0.8543388247489929
Validation loss: 2.170463482538859

Epoch: 6| Step: 8
Training loss: 0.807502269744873
Validation loss: 2.20838725566864

Epoch: 6| Step: 9
Training loss: 1.909311056137085
Validation loss: 2.1904573837916055

Epoch: 6| Step: 10
Training loss: 0.9406268000602722
Validation loss: 2.2162808179855347

Epoch: 6| Step: 11
Training loss: 1.3218169212341309
Validation loss: 2.201981782913208

Epoch: 6| Step: 12
Training loss: 0.6534379720687866
Validation loss: 2.200198491414388

Epoch: 6| Step: 13
Training loss: 1.4404687881469727
Validation loss: 2.215375085671743

Epoch: 366| Step: 0
Training loss: 1.1575324535369873
Validation loss: 2.238515834013621

Epoch: 6| Step: 1
Training loss: 0.8560136556625366
Validation loss: 2.2077550093332925

Epoch: 6| Step: 2
Training loss: 1.688698172569275
Validation loss: 2.242416739463806

Epoch: 6| Step: 3
Training loss: 1.3038742542266846
Validation loss: 2.2679848273595176

Epoch: 6| Step: 4
Training loss: 0.8583579659461975
Validation loss: 2.2471919854482016

Epoch: 6| Step: 5
Training loss: 1.3163779973983765
Validation loss: 2.2805329958597818

Epoch: 6| Step: 6
Training loss: 0.9431939125061035
Validation loss: 2.228602568308512

Epoch: 6| Step: 7
Training loss: 1.2419217824935913
Validation loss: 2.2334574858347573

Epoch: 6| Step: 8
Training loss: 1.5714693069458008
Validation loss: 2.21704363822937

Epoch: 6| Step: 9
Training loss: 1.0913009643554688
Validation loss: 2.2150267362594604

Epoch: 6| Step: 10
Training loss: 1.3282573223114014
Validation loss: 2.2068814237912497

Epoch: 6| Step: 11
Training loss: 1.0587046146392822
Validation loss: 2.2220235665639243

Epoch: 6| Step: 12
Training loss: 1.1743724346160889
Validation loss: 2.232784072558085

Epoch: 6| Step: 13
Training loss: 1.1227307319641113
Validation loss: 2.23365851243337

Epoch: 367| Step: 0
Training loss: 1.0824713706970215
Validation loss: 2.246552606423696

Epoch: 6| Step: 1
Training loss: 1.8959505558013916
Validation loss: 2.2658274173736572

Epoch: 6| Step: 2
Training loss: 0.865082323551178
Validation loss: 2.2499489386876426

Epoch: 6| Step: 3
Training loss: 1.362149715423584
Validation loss: 2.2441582878430686

Epoch: 6| Step: 4
Training loss: 0.7787085771560669
Validation loss: 2.321153740088145

Epoch: 6| Step: 5
Training loss: 1.4145742654800415
Validation loss: 2.269565979639689

Epoch: 6| Step: 6
Training loss: 1.2186774015426636
Validation loss: 2.2763681610425315

Epoch: 6| Step: 7
Training loss: 0.9270045757293701
Validation loss: 2.2621934016545615

Epoch: 6| Step: 8
Training loss: 1.3676356077194214
Validation loss: 2.222415864467621

Epoch: 6| Step: 9
Training loss: 1.460194706916809
Validation loss: 2.24010576804479

Epoch: 6| Step: 10
Training loss: 0.6733871698379517
Validation loss: 2.2325186928113303

Epoch: 6| Step: 11
Training loss: 0.8276634812355042
Validation loss: 2.2218305468559265

Epoch: 6| Step: 12
Training loss: 1.7935163974761963
Validation loss: 2.1747028827667236

Epoch: 6| Step: 13
Training loss: 1.0271761417388916
Validation loss: 2.2293779651323953

Epoch: 368| Step: 0
Training loss: 1.7323155403137207
Validation loss: 2.179666976133982

Epoch: 6| Step: 1
Training loss: 1.6175620555877686
Validation loss: 2.213517884413401

Epoch: 6| Step: 2
Training loss: 0.7904971837997437
Validation loss: 2.190122127532959

Epoch: 6| Step: 3
Training loss: 2.052985668182373
Validation loss: 2.1955111821492515

Epoch: 6| Step: 4
Training loss: 0.8707317113876343
Validation loss: 2.208866020043691

Epoch: 6| Step: 5
Training loss: 1.0387458801269531
Validation loss: 2.205171585083008

Epoch: 6| Step: 6
Training loss: 0.9164695739746094
Validation loss: 2.2111304004987082

Epoch: 6| Step: 7
Training loss: 0.8952469825744629
Validation loss: 2.2151090701421103

Epoch: 6| Step: 8
Training loss: 1.3002337217330933
Validation loss: 2.187907258669535

Epoch: 6| Step: 9
Training loss: 1.3164074420928955
Validation loss: 2.232205808162689

Epoch: 6| Step: 10
Training loss: 1.2047431468963623
Validation loss: 2.262943923473358

Epoch: 6| Step: 11
Training loss: 1.3414957523345947
Validation loss: 2.261071741580963

Epoch: 6| Step: 12
Training loss: 0.7231661081314087
Validation loss: 2.2518312335014343

Epoch: 6| Step: 13
Training loss: 0.8123160600662231
Validation loss: 2.2547682921091714

Epoch: 369| Step: 0
Training loss: 0.6643022298812866
Validation loss: 2.262644370396932

Epoch: 6| Step: 1
Training loss: 0.9855589866638184
Validation loss: 2.253673772017161

Epoch: 6| Step: 2
Training loss: 0.7174424529075623
Validation loss: 2.2293609380722046

Epoch: 6| Step: 3
Training loss: 1.48704195022583
Validation loss: 2.2006067037582397

Epoch: 6| Step: 4
Training loss: 1.0759556293487549
Validation loss: 2.1820380290349326

Epoch: 6| Step: 5
Training loss: 1.2445799112319946
Validation loss: 2.1696178913116455

Epoch: 6| Step: 6
Training loss: 1.351050615310669
Validation loss: 2.1786810954411826

Epoch: 6| Step: 7
Training loss: 1.5957138538360596
Validation loss: 2.195406178633372

Epoch: 6| Step: 8
Training loss: 1.6667664051055908
Validation loss: 2.2010693351427713

Epoch: 6| Step: 9
Training loss: 1.2019915580749512
Validation loss: 2.193937917550405

Epoch: 6| Step: 10
Training loss: 1.1475846767425537
Validation loss: 2.2135257720947266

Epoch: 6| Step: 11
Training loss: 1.0625770092010498
Validation loss: 2.171224892139435

Epoch: 6| Step: 12
Training loss: 1.5407086610794067
Validation loss: 2.1925300558408103

Epoch: 6| Step: 13
Training loss: 1.2372491359710693
Validation loss: 2.201641043027242

Epoch: 370| Step: 0
Training loss: 0.7095892429351807
Validation loss: 2.2023114959398904

Epoch: 6| Step: 1
Training loss: 0.7803023457527161
Validation loss: 2.2254658341407776

Epoch: 6| Step: 2
Training loss: 2.077141761779785
Validation loss: 2.2386231422424316

Epoch: 6| Step: 3
Training loss: 1.5436420440673828
Validation loss: 2.241143981615702

Epoch: 6| Step: 4
Training loss: 0.8337306380271912
Validation loss: 2.2566041151682534

Epoch: 6| Step: 5
Training loss: 1.56111741065979
Validation loss: 2.2587711215019226

Epoch: 6| Step: 6
Training loss: 1.720930814743042
Validation loss: 2.2677438855171204

Epoch: 6| Step: 7
Training loss: 0.6334311962127686
Validation loss: 2.29228937625885

Epoch: 6| Step: 8
Training loss: 1.3881465196609497
Validation loss: 2.2513818740844727

Epoch: 6| Step: 9
Training loss: 1.2453244924545288
Validation loss: 2.1807928880055747

Epoch: 6| Step: 10
Training loss: 1.1844737529754639
Validation loss: 2.266727944215139

Epoch: 6| Step: 11
Training loss: 0.9428260922431946
Validation loss: 2.247432510058085

Epoch: 6| Step: 12
Training loss: 1.568328857421875
Validation loss: 2.2636926968892417

Epoch: 6| Step: 13
Training loss: 0.7109373807907104
Validation loss: 2.2598653634389243

Epoch: 371| Step: 0
Training loss: 1.0093556642532349
Validation loss: 2.215924878915151

Epoch: 6| Step: 1
Training loss: 1.1112929582595825
Validation loss: 2.2595446507136026

Epoch: 6| Step: 2
Training loss: 1.1073646545410156
Validation loss: 2.222163359324137

Epoch: 6| Step: 3
Training loss: 1.103386402130127
Validation loss: 2.24748686949412

Epoch: 6| Step: 4
Training loss: 1.0058872699737549
Validation loss: 2.2025784452756247

Epoch: 6| Step: 5
Training loss: 2.010254383087158
Validation loss: 2.193547089894613

Epoch: 6| Step: 6
Training loss: 1.1123614311218262
Validation loss: 2.2157483100891113

Epoch: 6| Step: 7
Training loss: 0.8086930513381958
Validation loss: 2.1982168753941855

Epoch: 6| Step: 8
Training loss: 0.947426438331604
Validation loss: 2.1928895910580954

Epoch: 6| Step: 9
Training loss: 0.9446597099304199
Validation loss: 2.218828002611796

Epoch: 6| Step: 10
Training loss: 1.3787949085235596
Validation loss: 2.216787874698639

Epoch: 6| Step: 11
Training loss: 1.1665250062942505
Validation loss: 2.205529510974884

Epoch: 6| Step: 12
Training loss: 1.0699186325073242
Validation loss: 2.2251217365264893

Epoch: 6| Step: 13
Training loss: 1.966602087020874
Validation loss: 2.208615163962046

Epoch: 372| Step: 0
Training loss: 0.933097243309021
Validation loss: 2.2186806201934814

Epoch: 6| Step: 1
Training loss: 1.2098479270935059
Validation loss: 2.2169888615608215

Epoch: 6| Step: 2
Training loss: 1.3622932434082031
Validation loss: 2.2410417397816977

Epoch: 6| Step: 3
Training loss: 0.8026865720748901
Validation loss: 2.2313526471455893

Epoch: 6| Step: 4
Training loss: 1.1500866413116455
Validation loss: 2.230746626853943

Epoch: 6| Step: 5
Training loss: 1.2459228038787842
Validation loss: 2.2492009003957114

Epoch: 6| Step: 6
Training loss: 1.1349159479141235
Validation loss: 2.2102906703948975

Epoch: 6| Step: 7
Training loss: 0.7399624586105347
Validation loss: 2.215563098589579

Epoch: 6| Step: 8
Training loss: 1.03102707862854
Validation loss: 2.2348554929097495

Epoch: 6| Step: 9
Training loss: 0.807581901550293
Validation loss: 2.2288061579068503

Epoch: 6| Step: 10
Training loss: 0.9803008437156677
Validation loss: 2.2508362531661987

Epoch: 6| Step: 11
Training loss: 1.3987176418304443
Validation loss: 2.2552412947018943

Epoch: 6| Step: 12
Training loss: 0.9375356435775757
Validation loss: 2.245046317577362

Epoch: 6| Step: 13
Training loss: 2.123777389526367
Validation loss: 2.2228025595347085

Epoch: 373| Step: 0
Training loss: 1.3683663606643677
Validation loss: 2.2243661880493164

Epoch: 6| Step: 1
Training loss: 0.4715612530708313
Validation loss: 2.207184612751007

Epoch: 6| Step: 2
Training loss: 0.7103978991508484
Validation loss: 2.1851874192555747

Epoch: 6| Step: 3
Training loss: 1.3703590631484985
Validation loss: 2.2029764652252197

Epoch: 6| Step: 4
Training loss: 0.970495343208313
Validation loss: 2.155742963155111

Epoch: 6| Step: 5
Training loss: 1.4955854415893555
Validation loss: 2.15106467405955

Epoch: 6| Step: 6
Training loss: 1.0255131721496582
Validation loss: 2.170125206311544

Epoch: 6| Step: 7
Training loss: 1.2256243228912354
Validation loss: 2.177425225575765

Epoch: 6| Step: 8
Training loss: 1.6983811855316162
Validation loss: 2.178593397140503

Epoch: 6| Step: 9
Training loss: 1.0431201457977295
Validation loss: 2.1930121779441833

Epoch: 6| Step: 10
Training loss: 0.7262694835662842
Validation loss: 2.206362009048462

Epoch: 6| Step: 11
Training loss: 1.8108819723129272
Validation loss: 2.181433379650116

Epoch: 6| Step: 12
Training loss: 0.8179436922073364
Validation loss: 2.2385329802831015

Epoch: 6| Step: 13
Training loss: 1.3492510318756104
Validation loss: 2.215108315149943

Epoch: 374| Step: 0
Training loss: 1.268729567527771
Validation loss: 2.215811570485433

Epoch: 6| Step: 1
Training loss: 1.452002763748169
Validation loss: 2.2284462253252664

Epoch: 6| Step: 2
Training loss: 0.8922555446624756
Validation loss: 2.2161585092544556

Epoch: 6| Step: 3
Training loss: 0.8737643361091614
Validation loss: 2.243395964304606

Epoch: 6| Step: 4
Training loss: 0.7915651202201843
Validation loss: 2.212620178858439

Epoch: 6| Step: 5
Training loss: 1.0690560340881348
Validation loss: 2.231291174888611

Epoch: 6| Step: 6
Training loss: 1.2135169506072998
Validation loss: 2.2838368018468223

Epoch: 6| Step: 7
Training loss: 0.7666752338409424
Validation loss: 2.2571969032287598

Epoch: 6| Step: 8
Training loss: 1.4459996223449707
Validation loss: 2.2798062364260354

Epoch: 6| Step: 9
Training loss: 1.6485555171966553
Validation loss: 2.24977312485377

Epoch: 6| Step: 10
Training loss: 0.8498987555503845
Validation loss: 2.2550792892773948

Epoch: 6| Step: 11
Training loss: 1.6507952213287354
Validation loss: 2.2565287351608276

Epoch: 6| Step: 12
Training loss: 1.0344221591949463
Validation loss: 2.225530525048574

Epoch: 6| Step: 13
Training loss: 1.5917671918869019
Validation loss: 2.2628939151763916

Epoch: 375| Step: 0
Training loss: 0.8972210884094238
Validation loss: 2.226390798886617

Epoch: 6| Step: 1
Training loss: 0.8715416789054871
Validation loss: 2.2007882595062256

Epoch: 6| Step: 2
Training loss: 1.238567590713501
Validation loss: 2.2344043254852295

Epoch: 6| Step: 3
Training loss: 2.1241226196289062
Validation loss: 2.257310628890991

Epoch: 6| Step: 4
Training loss: 1.1835980415344238
Validation loss: 2.2461554606755576

Epoch: 6| Step: 5
Training loss: 1.1416239738464355
Validation loss: 2.283202807108561

Epoch: 6| Step: 6
Training loss: 0.5843111872673035
Validation loss: 2.2716420888900757

Epoch: 6| Step: 7
Training loss: 1.1652027368545532
Validation loss: 2.2695144017537436

Epoch: 6| Step: 8
Training loss: 0.9582563042640686
Validation loss: 2.252590000629425

Epoch: 6| Step: 9
Training loss: 1.1944224834442139
Validation loss: 2.2713548143704734

Epoch: 6| Step: 10
Training loss: 1.1365501880645752
Validation loss: 2.2423702081044516

Epoch: 6| Step: 11
Training loss: 0.8944008946418762
Validation loss: 2.239812215169271

Epoch: 6| Step: 12
Training loss: 1.5299592018127441
Validation loss: 2.2224761247634888

Epoch: 6| Step: 13
Training loss: 1.6103047132492065
Validation loss: 2.1859586437543235

Epoch: 376| Step: 0
Training loss: 1.2086162567138672
Validation loss: 2.203226069609324

Epoch: 6| Step: 1
Training loss: 1.0526753664016724
Validation loss: 2.213015000025431

Epoch: 6| Step: 2
Training loss: 1.118910312652588
Validation loss: 2.199669520060221

Epoch: 6| Step: 3
Training loss: 1.3581039905548096
Validation loss: 2.181307395299276

Epoch: 6| Step: 4
Training loss: 1.025261640548706
Validation loss: 2.1814592281977334

Epoch: 6| Step: 5
Training loss: 1.3606680631637573
Validation loss: 2.1827757159868875

Epoch: 6| Step: 6
Training loss: 1.1999857425689697
Validation loss: 2.193447530269623

Epoch: 6| Step: 7
Training loss: 0.7708035707473755
Validation loss: 2.212728520234426

Epoch: 6| Step: 8
Training loss: 0.9098312854766846
Validation loss: 2.2321249643961587

Epoch: 6| Step: 9
Training loss: 1.1889758110046387
Validation loss: 2.251347601413727

Epoch: 6| Step: 10
Training loss: 0.7867854237556458
Validation loss: 2.2328646580378213

Epoch: 6| Step: 11
Training loss: 1.8669114112854004
Validation loss: 2.264868954817454

Epoch: 6| Step: 12
Training loss: 1.153036117553711
Validation loss: 2.2458279530207315

Epoch: 6| Step: 13
Training loss: 1.4757442474365234
Validation loss: 2.244302491346995

Epoch: 377| Step: 0
Training loss: 0.7144554257392883
Validation loss: 2.215388019879659

Epoch: 6| Step: 1
Training loss: 1.5969983339309692
Validation loss: 2.1929126183191934

Epoch: 6| Step: 2
Training loss: 0.9955745339393616
Validation loss: 2.246307094891866

Epoch: 6| Step: 3
Training loss: 1.2025415897369385
Validation loss: 2.1897725065549216

Epoch: 6| Step: 4
Training loss: 1.1303930282592773
Validation loss: 2.2164623538653054

Epoch: 6| Step: 5
Training loss: 1.3018081188201904
Validation loss: 2.2101544936498008

Epoch: 6| Step: 6
Training loss: 1.225250244140625
Validation loss: 2.22621750831604

Epoch: 6| Step: 7
Training loss: 1.044071078300476
Validation loss: 2.2314928571383157

Epoch: 6| Step: 8
Training loss: 0.7195461988449097
Validation loss: 2.2153303623199463

Epoch: 6| Step: 9
Training loss: 1.0482876300811768
Validation loss: 2.1937318046887717

Epoch: 6| Step: 10
Training loss: 1.1983530521392822
Validation loss: 2.2203065554300943

Epoch: 6| Step: 11
Training loss: 1.3595433235168457
Validation loss: 2.2017104824384055

Epoch: 6| Step: 12
Training loss: 1.3390326499938965
Validation loss: 2.1982629696528115

Epoch: 6| Step: 13
Training loss: 1.3577542304992676
Validation loss: 2.2118293841679892

Epoch: 378| Step: 0
Training loss: 0.8444656133651733
Validation loss: 2.1957234740257263

Epoch: 6| Step: 1
Training loss: 1.308614730834961
Validation loss: 2.1736404498418174

Epoch: 6| Step: 2
Training loss: 1.524928092956543
Validation loss: 2.1539403200149536

Epoch: 6| Step: 3
Training loss: 1.1225090026855469
Validation loss: 2.1574120918909707

Epoch: 6| Step: 4
Training loss: 0.9872746467590332
Validation loss: 2.138192574183146

Epoch: 6| Step: 5
Training loss: 1.0986778736114502
Validation loss: 2.1997753381729126

Epoch: 6| Step: 6
Training loss: 0.9680291414260864
Validation loss: 2.1868314941724143

Epoch: 6| Step: 7
Training loss: 1.396026611328125
Validation loss: 2.1904654105504355

Epoch: 6| Step: 8
Training loss: 1.6598639488220215
Validation loss: 2.181580980618795

Epoch: 6| Step: 9
Training loss: 1.1098605394363403
Validation loss: 2.189084748427073

Epoch: 6| Step: 10
Training loss: 1.0454970598220825
Validation loss: 2.2025742332140603

Epoch: 6| Step: 11
Training loss: 1.4288617372512817
Validation loss: 2.2105981508890786

Epoch: 6| Step: 12
Training loss: 0.8729807138442993
Validation loss: 2.247545520464579

Epoch: 6| Step: 13
Training loss: 0.9336227774620056
Validation loss: 2.222688317298889

Epoch: 379| Step: 0
Training loss: 0.9589690566062927
Validation loss: 2.2356217900911965

Epoch: 6| Step: 1
Training loss: 1.403570294380188
Validation loss: 2.255372087160746

Epoch: 6| Step: 2
Training loss: 1.0290707349777222
Validation loss: 2.213131388028463

Epoch: 6| Step: 3
Training loss: 1.6186555624008179
Validation loss: 2.263215263684591

Epoch: 6| Step: 4
Training loss: 1.1928725242614746
Validation loss: 2.2226986090342202

Epoch: 6| Step: 5
Training loss: 1.306596279144287
Validation loss: 2.2446483373641968

Epoch: 6| Step: 6
Training loss: 1.0262091159820557
Validation loss: 2.2230597535769143

Epoch: 6| Step: 7
Training loss: 0.628096342086792
Validation loss: 2.204708695411682

Epoch: 6| Step: 8
Training loss: 1.0190292596817017
Validation loss: 2.225748916467031

Epoch: 6| Step: 9
Training loss: 1.2003846168518066
Validation loss: 2.2175503373146057

Epoch: 6| Step: 10
Training loss: 2.0096042156219482
Validation loss: 2.180264711380005

Epoch: 6| Step: 11
Training loss: 1.0460097789764404
Validation loss: 2.157978971799215

Epoch: 6| Step: 12
Training loss: 0.9648757576942444
Validation loss: 2.1636963287989297

Epoch: 6| Step: 13
Training loss: 1.3680462837219238
Validation loss: 2.1729608178138733

Epoch: 380| Step: 0
Training loss: 1.4312384128570557
Validation loss: 2.166875640551249

Epoch: 6| Step: 1
Training loss: 0.9301470518112183
Validation loss: 2.189496318499247

Epoch: 6| Step: 2
Training loss: 1.0908112525939941
Validation loss: 2.1886218984921775

Epoch: 6| Step: 3
Training loss: 1.2755393981933594
Validation loss: 2.1993871529897056

Epoch: 6| Step: 4
Training loss: 2.082918167114258
Validation loss: 2.187959353129069

Epoch: 6| Step: 5
Training loss: 0.7078791856765747
Validation loss: 2.2259398301442466

Epoch: 6| Step: 6
Training loss: 0.8533968925476074
Validation loss: 2.1846735874811807

Epoch: 6| Step: 7
Training loss: 0.7815194129943848
Validation loss: 2.19861634572347

Epoch: 6| Step: 8
Training loss: 0.779843807220459
Validation loss: 2.224334200223287

Epoch: 6| Step: 9
Training loss: 0.7138693332672119
Validation loss: 2.213446001211802

Epoch: 6| Step: 10
Training loss: 1.2107000350952148
Validation loss: 2.217414061228434

Epoch: 6| Step: 11
Training loss: 1.6614224910736084
Validation loss: 2.2084786097208657

Epoch: 6| Step: 12
Training loss: 0.8562489748001099
Validation loss: 2.21398933728536

Epoch: 6| Step: 13
Training loss: 1.4639216661453247
Validation loss: 2.2313321431477866

Epoch: 381| Step: 0
Training loss: 1.0997636318206787
Validation loss: 2.1988754868507385

Epoch: 6| Step: 1
Training loss: 1.2665274143218994
Validation loss: 2.1758486231168113

Epoch: 6| Step: 2
Training loss: 1.564104437828064
Validation loss: 2.2230917612711587

Epoch: 6| Step: 3
Training loss: 0.6689965724945068
Validation loss: 2.209568719069163

Epoch: 6| Step: 4
Training loss: 1.0333362817764282
Validation loss: 2.209997574488322

Epoch: 6| Step: 5
Training loss: 1.28840970993042
Validation loss: 2.2245091597239175

Epoch: 6| Step: 6
Training loss: 1.43328857421875
Validation loss: 2.291556715965271

Epoch: 6| Step: 7
Training loss: 0.8423635959625244
Validation loss: 2.252796451250712

Epoch: 6| Step: 8
Training loss: 1.494764804840088
Validation loss: 2.247509221235911

Epoch: 6| Step: 9
Training loss: 1.3438822031021118
Validation loss: 2.250304102897644

Epoch: 6| Step: 10
Training loss: 0.7196627855300903
Validation loss: 2.2435402274131775

Epoch: 6| Step: 11
Training loss: 0.9626505374908447
Validation loss: 2.239056726296743

Epoch: 6| Step: 12
Training loss: 0.9597741365432739
Validation loss: 2.1927255193392434

Epoch: 6| Step: 13
Training loss: 1.2360676527023315
Validation loss: 2.2173352042833963

Epoch: 382| Step: 0
Training loss: 0.8210434913635254
Validation loss: 2.1883315245310464

Epoch: 6| Step: 1
Training loss: 1.035517930984497
Validation loss: 2.1891545255978904

Epoch: 6| Step: 2
Training loss: 1.0108791589736938
Validation loss: 2.1683456699053445

Epoch: 6| Step: 3
Training loss: 0.8720471858978271
Validation loss: 2.179752230644226

Epoch: 6| Step: 4
Training loss: 0.7042161822319031
Validation loss: 2.1760189135869346

Epoch: 6| Step: 5
Training loss: 1.0465351343154907
Validation loss: 2.2169246872266135

Epoch: 6| Step: 6
Training loss: 1.4525774717330933
Validation loss: 2.1814688046773276

Epoch: 6| Step: 7
Training loss: 0.892162561416626
Validation loss: 2.206269939740499

Epoch: 6| Step: 8
Training loss: 0.9955943822860718
Validation loss: 2.224047005176544

Epoch: 6| Step: 9
Training loss: 1.0685794353485107
Validation loss: 2.230195681254069

Epoch: 6| Step: 10
Training loss: 1.5772747993469238
Validation loss: 2.255676786104838

Epoch: 6| Step: 11
Training loss: 1.8061398267745972
Validation loss: 2.217117190361023

Epoch: 6| Step: 12
Training loss: 0.9086731672286987
Validation loss: 2.2438183625539145

Epoch: 6| Step: 13
Training loss: 1.3138866424560547
Validation loss: 2.2928725481033325

Epoch: 383| Step: 0
Training loss: 1.0483253002166748
Validation loss: 2.2352009614308677

Epoch: 6| Step: 1
Training loss: 1.1516571044921875
Validation loss: 2.2592302163441977

Epoch: 6| Step: 2
Training loss: 1.0741057395935059
Validation loss: 2.2159594297409058

Epoch: 6| Step: 3
Training loss: 1.0929123163223267
Validation loss: 2.2265149553616843

Epoch: 6| Step: 4
Training loss: 1.2915146350860596
Validation loss: 2.206266721089681

Epoch: 6| Step: 5
Training loss: 1.010158896446228
Validation loss: 2.182782153288523

Epoch: 6| Step: 6
Training loss: 1.199143648147583
Validation loss: 2.1991355816523233

Epoch: 6| Step: 7
Training loss: 0.7753044962882996
Validation loss: 2.207063853740692

Epoch: 6| Step: 8
Training loss: 0.9414856433868408
Validation loss: 2.197093923886617

Epoch: 6| Step: 9
Training loss: 1.2430086135864258
Validation loss: 2.1786644061406455

Epoch: 6| Step: 10
Training loss: 1.1073296070098877
Validation loss: 2.1799829999605813

Epoch: 6| Step: 11
Training loss: 0.9326213598251343
Validation loss: 2.170099675655365

Epoch: 6| Step: 12
Training loss: 0.9262313842773438
Validation loss: 2.168190042177836

Epoch: 6| Step: 13
Training loss: 1.323817253112793
Validation loss: 2.1806317369143167

Epoch: 384| Step: 0
Training loss: 1.1955143213272095
Validation loss: 2.1815075476964316

Epoch: 6| Step: 1
Training loss: 1.1547355651855469
Validation loss: 2.193656106789907

Epoch: 6| Step: 2
Training loss: 1.3339180946350098
Validation loss: 2.195034305254618

Epoch: 6| Step: 3
Training loss: 1.0073901414871216
Validation loss: 2.1814709504445395

Epoch: 6| Step: 4
Training loss: 0.5867733359336853
Validation loss: 2.209442138671875

Epoch: 6| Step: 5
Training loss: 1.744866967201233
Validation loss: 2.180020352204641

Epoch: 6| Step: 6
Training loss: 0.9803776741027832
Validation loss: 2.160562594731649

Epoch: 6| Step: 7
Training loss: 1.612914800643921
Validation loss: 2.1801793972651162

Epoch: 6| Step: 8
Training loss: 0.931529700756073
Validation loss: 2.186500132083893

Epoch: 6| Step: 9
Training loss: 1.6517044305801392
Validation loss: 2.2106539408365884

Epoch: 6| Step: 10
Training loss: 1.1514204740524292
Validation loss: 2.1737648447354636

Epoch: 6| Step: 11
Training loss: 0.5183455348014832
Validation loss: 2.1734020113945007

Epoch: 6| Step: 12
Training loss: 0.7200289964675903
Validation loss: 2.224653681119283

Epoch: 6| Step: 13
Training loss: 0.6395054459571838
Validation loss: 2.2263780434926352

Epoch: 385| Step: 0
Training loss: 2.0428147315979004
Validation loss: 2.2210597594579062

Epoch: 6| Step: 1
Training loss: 0.7113475799560547
Validation loss: 2.2168664932250977

Epoch: 6| Step: 2
Training loss: 1.189805030822754
Validation loss: 2.269404153029124

Epoch: 6| Step: 3
Training loss: 1.114022970199585
Validation loss: 2.2451327641805015

Epoch: 6| Step: 4
Training loss: 0.9397861957550049
Validation loss: 2.2356395721435547

Epoch: 6| Step: 5
Training loss: 1.2516274452209473
Validation loss: 2.230094393094381

Epoch: 6| Step: 6
Training loss: 1.403693437576294
Validation loss: 2.1957558194796243

Epoch: 6| Step: 7
Training loss: 1.0031113624572754
Validation loss: 2.2295124928156533

Epoch: 6| Step: 8
Training loss: 0.5979446172714233
Validation loss: 2.216183622678121

Epoch: 6| Step: 9
Training loss: 0.9487936496734619
Validation loss: 2.2386781374613443

Epoch: 6| Step: 10
Training loss: 1.3582481145858765
Validation loss: 2.266689578692118

Epoch: 6| Step: 11
Training loss: 0.8455585837364197
Validation loss: 2.241414805253347

Epoch: 6| Step: 12
Training loss: 0.885391354560852
Validation loss: 2.200378100077311

Epoch: 6| Step: 13
Training loss: 1.0961170196533203
Validation loss: 2.2435127099355063

Epoch: 386| Step: 0
Training loss: 0.717878520488739
Validation loss: 2.2267138361930847

Epoch: 6| Step: 1
Training loss: 1.1753873825073242
Validation loss: 2.2609636783599854

Epoch: 6| Step: 2
Training loss: 0.6451389193534851
Validation loss: 2.2593780954678855

Epoch: 6| Step: 3
Training loss: 1.0118135213851929
Validation loss: 2.241307854652405

Epoch: 6| Step: 4
Training loss: 1.3860571384429932
Validation loss: 2.246484617392222

Epoch: 6| Step: 5
Training loss: 0.5659945011138916
Validation loss: 2.237049619356791

Epoch: 6| Step: 6
Training loss: 1.4463956356048584
Validation loss: 2.275938332080841

Epoch: 6| Step: 7
Training loss: 1.784576177597046
Validation loss: 2.2688108682632446

Epoch: 6| Step: 8
Training loss: 1.0074028968811035
Validation loss: 2.2770859003067017

Epoch: 6| Step: 9
Training loss: 0.9963805675506592
Validation loss: 2.256488621234894

Epoch: 6| Step: 10
Training loss: 1.2931286096572876
Validation loss: 2.2760565082232156

Epoch: 6| Step: 11
Training loss: 0.7802720665931702
Validation loss: 2.2904507716496787

Epoch: 6| Step: 12
Training loss: 1.0215678215026855
Validation loss: 2.290282905101776

Epoch: 6| Step: 13
Training loss: 1.3396273851394653
Validation loss: 2.2907451589902244

Epoch: 387| Step: 0
Training loss: 0.7479123473167419
Validation loss: 2.2653764684995017

Epoch: 6| Step: 1
Training loss: 0.8555513024330139
Validation loss: 2.2413265705108643

Epoch: 6| Step: 2
Training loss: 0.6920702457427979
Validation loss: 2.265921433766683

Epoch: 6| Step: 3
Training loss: 1.4687319993972778
Validation loss: 2.236582855383555

Epoch: 6| Step: 4
Training loss: 1.2873179912567139
Validation loss: 2.214416186014811

Epoch: 6| Step: 5
Training loss: 1.5180121660232544
Validation loss: 2.1864949464797974

Epoch: 6| Step: 6
Training loss: 0.9213336110115051
Validation loss: 2.200512647628784

Epoch: 6| Step: 7
Training loss: 1.149557113647461
Validation loss: 2.2436935901641846

Epoch: 6| Step: 8
Training loss: 0.9842004776000977
Validation loss: 2.2196168104807534

Epoch: 6| Step: 9
Training loss: 1.1273565292358398
Validation loss: 2.2483049035072327

Epoch: 6| Step: 10
Training loss: 1.4801676273345947
Validation loss: 2.2574344476064048

Epoch: 6| Step: 11
Training loss: 1.3349027633666992
Validation loss: 2.2470356623331704

Epoch: 6| Step: 12
Training loss: 0.9353034496307373
Validation loss: 2.2430572311083474

Epoch: 6| Step: 13
Training loss: 0.5768256187438965
Validation loss: 2.2530078689257302

Epoch: 388| Step: 0
Training loss: 1.5355278253555298
Validation loss: 2.274024764696757

Epoch: 6| Step: 1
Training loss: 1.1028635501861572
Validation loss: 2.2754739920298257

Epoch: 6| Step: 2
Training loss: 1.0969678163528442
Validation loss: 2.2491897145907083

Epoch: 6| Step: 3
Training loss: 1.7899528741836548
Validation loss: 2.229801038901011

Epoch: 6| Step: 4
Training loss: 0.9286537170410156
Validation loss: 2.1852222283681235

Epoch: 6| Step: 5
Training loss: 0.6238558292388916
Validation loss: 2.2025333841641745

Epoch: 6| Step: 6
Training loss: 1.102541446685791
Validation loss: 2.15718283255895

Epoch: 6| Step: 7
Training loss: 1.1337794065475464
Validation loss: 2.1457299987475076

Epoch: 6| Step: 8
Training loss: 1.1036412715911865
Validation loss: 2.163685401280721

Epoch: 6| Step: 9
Training loss: 0.7544759511947632
Validation loss: 2.156545559565226

Epoch: 6| Step: 10
Training loss: 1.3937997817993164
Validation loss: 2.1591920256614685

Epoch: 6| Step: 11
Training loss: 0.8850600719451904
Validation loss: 2.2036484678586326

Epoch: 6| Step: 12
Training loss: 1.2913390398025513
Validation loss: 2.1785640915234885

Epoch: 6| Step: 13
Training loss: 1.096442461013794
Validation loss: 2.15582009156545

Epoch: 389| Step: 0
Training loss: 1.2231545448303223
Validation loss: 2.1732296546300254

Epoch: 6| Step: 1
Training loss: 0.7304785251617432
Validation loss: 2.1835522452990213

Epoch: 6| Step: 2
Training loss: 0.9186373353004456
Validation loss: 2.198739012082418

Epoch: 6| Step: 3
Training loss: 0.9047857522964478
Validation loss: 2.1994267106056213

Epoch: 6| Step: 4
Training loss: 0.8527824878692627
Validation loss: 2.2065577705701194

Epoch: 6| Step: 5
Training loss: 0.7941858768463135
Validation loss: 2.1933101812998452

Epoch: 6| Step: 6
Training loss: 1.0862767696380615
Validation loss: 2.1911583145459494

Epoch: 6| Step: 7
Training loss: 0.6057007312774658
Validation loss: 2.1905445059140525

Epoch: 6| Step: 8
Training loss: 1.8417996168136597
Validation loss: 2.190137962500254

Epoch: 6| Step: 9
Training loss: 1.1001572608947754
Validation loss: 2.2378000219662986

Epoch: 6| Step: 10
Training loss: 1.502382516860962
Validation loss: 2.1702537536621094

Epoch: 6| Step: 11
Training loss: 1.519337773323059
Validation loss: 2.183159510294596

Epoch: 6| Step: 12
Training loss: 0.8651437163352966
Validation loss: 2.188551902770996

Epoch: 6| Step: 13
Training loss: 0.9726369380950928
Validation loss: 2.2077457507451377

Epoch: 390| Step: 0
Training loss: 1.2331126928329468
Validation loss: 2.218592345714569

Epoch: 6| Step: 1
Training loss: 0.592487096786499
Validation loss: 2.204359312852224

Epoch: 6| Step: 2
Training loss: 1.0949232578277588
Validation loss: 2.18863578637441

Epoch: 6| Step: 3
Training loss: 0.845233678817749
Validation loss: 2.1847559213638306

Epoch: 6| Step: 4
Training loss: 0.7230545282363892
Validation loss: 2.201288640499115

Epoch: 6| Step: 5
Training loss: 0.6890939474105835
Validation loss: 2.1763896346092224

Epoch: 6| Step: 6
Training loss: 1.5084682703018188
Validation loss: 2.2092514038085938

Epoch: 6| Step: 7
Training loss: 1.0048906803131104
Validation loss: 2.1891003449757895

Epoch: 6| Step: 8
Training loss: 1.0684514045715332
Validation loss: 2.1782919565836587

Epoch: 6| Step: 9
Training loss: 0.565748929977417
Validation loss: 2.214598298072815

Epoch: 6| Step: 10
Training loss: 1.357908844947815
Validation loss: 2.252576231956482

Epoch: 6| Step: 11
Training loss: 2.054368019104004
Validation loss: 2.2162444988886514

Epoch: 6| Step: 12
Training loss: 0.7819604873657227
Validation loss: 2.2037909428278604

Epoch: 6| Step: 13
Training loss: 1.1666691303253174
Validation loss: 2.155954957008362

Epoch: 391| Step: 0
Training loss: 1.2730673551559448
Validation loss: 2.186012923717499

Epoch: 6| Step: 1
Training loss: 1.793999433517456
Validation loss: 2.1787590384483337

Epoch: 6| Step: 2
Training loss: 1.1044820547103882
Validation loss: 2.22806578874588

Epoch: 6| Step: 3
Training loss: 1.19256591796875
Validation loss: 2.1927561362584433

Epoch: 6| Step: 4
Training loss: 0.5641666650772095
Validation loss: 2.16874227921168

Epoch: 6| Step: 5
Training loss: 0.6416138410568237
Validation loss: 2.227621575196584

Epoch: 6| Step: 6
Training loss: 0.8364138603210449
Validation loss: 2.1715046167373657

Epoch: 6| Step: 7
Training loss: 1.0159859657287598
Validation loss: 2.2167787154515586

Epoch: 6| Step: 8
Training loss: 0.7682545781135559
Validation loss: 2.1649823983510337

Epoch: 6| Step: 9
Training loss: 1.1609437465667725
Validation loss: 2.1977032820383706

Epoch: 6| Step: 10
Training loss: 1.0695796012878418
Validation loss: 2.1917342940966287

Epoch: 6| Step: 11
Training loss: 0.9391539096832275
Validation loss: 2.249755601088206

Epoch: 6| Step: 12
Training loss: 0.7786757349967957
Validation loss: 2.229480564594269

Epoch: 6| Step: 13
Training loss: 1.4844528436660767
Validation loss: 2.228947083155314

Epoch: 392| Step: 0
Training loss: 1.2247023582458496
Validation loss: 2.261116365591685

Epoch: 6| Step: 1
Training loss: 0.9107781052589417
Validation loss: 2.2402241627375283

Epoch: 6| Step: 2
Training loss: 1.5758907794952393
Validation loss: 2.270509640375773

Epoch: 6| Step: 3
Training loss: 0.8950999975204468
Validation loss: 2.250819742679596

Epoch: 6| Step: 4
Training loss: 1.1785372495651245
Validation loss: 2.167077978452047

Epoch: 6| Step: 5
Training loss: 0.8065412044525146
Validation loss: 2.1950077414512634

Epoch: 6| Step: 6
Training loss: 1.2875198125839233
Validation loss: 2.2032119830449424

Epoch: 6| Step: 7
Training loss: 0.579378604888916
Validation loss: 2.16392982006073

Epoch: 6| Step: 8
Training loss: 1.2656521797180176
Validation loss: 2.175759017467499

Epoch: 6| Step: 9
Training loss: 0.7539269924163818
Validation loss: 2.212422490119934

Epoch: 6| Step: 10
Training loss: 1.2217886447906494
Validation loss: 2.2181926568349204

Epoch: 6| Step: 11
Training loss: 1.2670910358428955
Validation loss: 2.215219497680664

Epoch: 6| Step: 12
Training loss: 1.2089163064956665
Validation loss: 2.2189512054125466

Epoch: 6| Step: 13
Training loss: 0.7385605573654175
Validation loss: 2.215265929698944

Epoch: 393| Step: 0
Training loss: 1.135343074798584
Validation loss: 2.2303585211435952

Epoch: 6| Step: 1
Training loss: 1.2814812660217285
Validation loss: 2.2497079173723855

Epoch: 6| Step: 2
Training loss: 1.0029367208480835
Validation loss: 2.271976351737976

Epoch: 6| Step: 3
Training loss: 0.901999831199646
Validation loss: 2.2497839530309043

Epoch: 6| Step: 4
Training loss: 0.7735974788665771
Validation loss: 2.2331355611483255

Epoch: 6| Step: 5
Training loss: 0.6924178004264832
Validation loss: 2.202945093313853

Epoch: 6| Step: 6
Training loss: 0.7422753572463989
Validation loss: 2.219929297765096

Epoch: 6| Step: 7
Training loss: 1.0919764041900635
Validation loss: 2.2518962025642395

Epoch: 6| Step: 8
Training loss: 1.1237149238586426
Validation loss: 2.227451423803965

Epoch: 6| Step: 9
Training loss: 1.3657841682434082
Validation loss: 2.248354951540629

Epoch: 6| Step: 10
Training loss: 0.9501498341560364
Validation loss: 2.206808865070343

Epoch: 6| Step: 11
Training loss: 1.168750524520874
Validation loss: 2.183565934499105

Epoch: 6| Step: 12
Training loss: 0.981892466545105
Validation loss: 2.1768216689427695

Epoch: 6| Step: 13
Training loss: 1.359670877456665
Validation loss: 2.226770043373108

Epoch: 394| Step: 0
Training loss: 1.7165403366088867
Validation loss: 2.2379785776138306

Epoch: 6| Step: 1
Training loss: 1.3630510568618774
Validation loss: 2.2522512674331665

Epoch: 6| Step: 2
Training loss: 1.063515067100525
Validation loss: 2.245734214782715

Epoch: 6| Step: 3
Training loss: 1.215635061264038
Validation loss: 2.256028135617574

Epoch: 6| Step: 4
Training loss: 1.3456575870513916
Validation loss: 2.2106553316116333

Epoch: 6| Step: 5
Training loss: 0.6530057787895203
Validation loss: 2.247656603654226

Epoch: 6| Step: 6
Training loss: 0.9043523073196411
Validation loss: 2.239874462286631

Epoch: 6| Step: 7
Training loss: 1.914210319519043
Validation loss: 2.244467238585154

Epoch: 6| Step: 8
Training loss: 0.45031315088272095
Validation loss: 2.267208218574524

Epoch: 6| Step: 9
Training loss: 1.0579464435577393
Validation loss: 2.2817243536313376

Epoch: 6| Step: 10
Training loss: 1.0891544818878174
Validation loss: 2.2412607669830322

Epoch: 6| Step: 11
Training loss: 0.8313024640083313
Validation loss: 2.260815143585205

Epoch: 6| Step: 12
Training loss: 0.6874009966850281
Validation loss: 2.247150460879008

Epoch: 6| Step: 13
Training loss: 1.0182342529296875
Validation loss: 2.2745304107666016

Epoch: 395| Step: 0
Training loss: 0.5741340517997742
Validation loss: 2.2497515877087912

Epoch: 6| Step: 1
Training loss: 0.8910082578659058
Validation loss: 2.2543655236562095

Epoch: 6| Step: 2
Training loss: 1.0936411619186401
Validation loss: 2.2498262325922647

Epoch: 6| Step: 3
Training loss: 0.9071115255355835
Validation loss: 2.263757328192393

Epoch: 6| Step: 4
Training loss: 2.322611093521118
Validation loss: 2.244162857532501

Epoch: 6| Step: 5
Training loss: 0.7819411158561707
Validation loss: 2.2672942678133645

Epoch: 6| Step: 6
Training loss: 0.8468784093856812
Validation loss: 2.1982748905817666

Epoch: 6| Step: 7
Training loss: 1.3670839071273804
Validation loss: 2.235319197177887

Epoch: 6| Step: 8
Training loss: 0.5504173636436462
Validation loss: 2.237712860107422

Epoch: 6| Step: 9
Training loss: 0.9453694224357605
Validation loss: 2.2659831047058105

Epoch: 6| Step: 10
Training loss: 1.1919125318527222
Validation loss: 2.2493172685305276

Epoch: 6| Step: 11
Training loss: 0.694449782371521
Validation loss: 2.284261643886566

Epoch: 6| Step: 12
Training loss: 1.0367701053619385
Validation loss: 2.2302728494008384

Epoch: 6| Step: 13
Training loss: 1.3169775009155273
Validation loss: 2.2813923756281533

Epoch: 396| Step: 0
Training loss: 1.2849225997924805
Validation loss: 2.2496912082036338

Epoch: 6| Step: 1
Training loss: 0.9915896654129028
Validation loss: 2.2505303819974265

Epoch: 6| Step: 2
Training loss: 0.6323169469833374
Validation loss: 2.240104059378306

Epoch: 6| Step: 3
Training loss: 1.0439739227294922
Validation loss: 2.196170926094055

Epoch: 6| Step: 4
Training loss: 0.9194160103797913
Validation loss: 2.2108614643414817

Epoch: 6| Step: 5
Training loss: 0.8390493392944336
Validation loss: 2.191112240155538

Epoch: 6| Step: 6
Training loss: 0.7565264105796814
Validation loss: 2.1906145811080933

Epoch: 6| Step: 7
Training loss: 2.4124629497528076
Validation loss: 2.158191680908203

Epoch: 6| Step: 8
Training loss: 1.1033155918121338
Validation loss: 2.1778127948443093

Epoch: 6| Step: 9
Training loss: 0.9511926174163818
Validation loss: 2.185052434603373

Epoch: 6| Step: 10
Training loss: 1.2792863845825195
Validation loss: 2.204988976319631

Epoch: 6| Step: 11
Training loss: 0.7191137075424194
Validation loss: 2.1746781269709268

Epoch: 6| Step: 12
Training loss: 1.138875961303711
Validation loss: 2.1968284050623574

Epoch: 6| Step: 13
Training loss: 0.5210005044937134
Validation loss: 2.2190792163213096

Epoch: 397| Step: 0
Training loss: 0.9271489381790161
Validation loss: 2.225432892640432

Epoch: 6| Step: 1
Training loss: 1.1267197132110596
Validation loss: 2.230226198832194

Epoch: 6| Step: 2
Training loss: 1.0662882328033447
Validation loss: 2.2220078905423484

Epoch: 6| Step: 3
Training loss: 1.031632661819458
Validation loss: 2.2415075302124023

Epoch: 6| Step: 4
Training loss: 0.5745576024055481
Validation loss: 2.247985601425171

Epoch: 6| Step: 5
Training loss: 1.1300715208053589
Validation loss: 2.2307363152503967

Epoch: 6| Step: 6
Training loss: 0.7951499223709106
Validation loss: 2.215228279431661

Epoch: 6| Step: 7
Training loss: 1.3202183246612549
Validation loss: 2.226308286190033

Epoch: 6| Step: 8
Training loss: 1.2451558113098145
Validation loss: 2.176770289738973

Epoch: 6| Step: 9
Training loss: 0.9440230131149292
Validation loss: 2.2170718908309937

Epoch: 6| Step: 10
Training loss: 1.0756089687347412
Validation loss: 2.203022758165995

Epoch: 6| Step: 11
Training loss: 0.9738661050796509
Validation loss: 2.1984930435816445

Epoch: 6| Step: 12
Training loss: 0.8295294046401978
Validation loss: 2.2031521002451577

Epoch: 6| Step: 13
Training loss: 1.293665885925293
Validation loss: 2.2173011898994446

Epoch: 398| Step: 0
Training loss: 1.5198055505752563
Validation loss: 2.192215899626414

Epoch: 6| Step: 1
Training loss: 0.786034345626831
Validation loss: 2.2168165842692056

Epoch: 6| Step: 2
Training loss: 0.9071596264839172
Validation loss: 2.2398773034413657

Epoch: 6| Step: 3
Training loss: 0.7832881808280945
Validation loss: 2.1962492068608603

Epoch: 6| Step: 4
Training loss: 0.6310270428657532
Validation loss: 2.192013760407766

Epoch: 6| Step: 5
Training loss: 0.7393234968185425
Validation loss: 2.20408167441686

Epoch: 6| Step: 6
Training loss: 1.2177609205245972
Validation loss: 2.2216904958089194

Epoch: 6| Step: 7
Training loss: 0.7888281941413879
Validation loss: 2.1965622901916504

Epoch: 6| Step: 8
Training loss: 1.1169264316558838
Validation loss: 2.2123093406359353

Epoch: 6| Step: 9
Training loss: 1.3430733680725098
Validation loss: 2.1987631916999817

Epoch: 6| Step: 10
Training loss: 1.633147120475769
Validation loss: 2.2325080037117004

Epoch: 6| Step: 11
Training loss: 0.9023071527481079
Validation loss: 2.1893685261408486

Epoch: 6| Step: 12
Training loss: 1.1542965173721313
Validation loss: 2.197584549585978

Epoch: 6| Step: 13
Training loss: 0.7929077744483948
Validation loss: 2.1806832353274026

Epoch: 399| Step: 0
Training loss: 0.5775120854377747
Validation loss: 2.2084258993466697

Epoch: 6| Step: 1
Training loss: 0.8049263954162598
Validation loss: 2.168797334035238

Epoch: 6| Step: 2
Training loss: 1.0077890157699585
Validation loss: 2.2615690430005393

Epoch: 6| Step: 3
Training loss: 1.5868935585021973
Validation loss: 2.2494969169298806

Epoch: 6| Step: 4
Training loss: 0.7528148889541626
Validation loss: 2.2155759930610657

Epoch: 6| Step: 5
Training loss: 0.5046283006668091
Validation loss: 2.242205639680227

Epoch: 6| Step: 6
Training loss: 0.7251920700073242
Validation loss: 2.2400521834691367

Epoch: 6| Step: 7
Training loss: 1.0640839338302612
Validation loss: 2.241562803586324

Epoch: 6| Step: 8
Training loss: 0.8905417919158936
Validation loss: 2.2155819733937583

Epoch: 6| Step: 9
Training loss: 1.0110437870025635
Validation loss: 2.220642109711965

Epoch: 6| Step: 10
Training loss: 1.329214334487915
Validation loss: 2.2319998145103455

Epoch: 6| Step: 11
Training loss: 1.6464555263519287
Validation loss: 2.1979570786158242

Epoch: 6| Step: 12
Training loss: 1.5119022130966187
Validation loss: 2.2585777640342712

Epoch: 6| Step: 13
Training loss: 1.1723523139953613
Validation loss: 2.2427277167638144

Epoch: 400| Step: 0
Training loss: 1.2075577974319458
Validation loss: 2.227371414502462

Epoch: 6| Step: 1
Training loss: 1.1792643070220947
Validation loss: 2.2230849266052246

Epoch: 6| Step: 2
Training loss: 1.2177908420562744
Validation loss: 2.2693116267522178

Epoch: 6| Step: 3
Training loss: 0.7678210139274597
Validation loss: 2.261193851629893

Epoch: 6| Step: 4
Training loss: 0.7748758792877197
Validation loss: 2.260127305984497

Epoch: 6| Step: 5
Training loss: 1.5122591257095337
Validation loss: 2.2458208799362183

Epoch: 6| Step: 6
Training loss: 1.2333014011383057
Validation loss: 2.24532812833786

Epoch: 6| Step: 7
Training loss: 0.7372397780418396
Validation loss: 2.270483692487081

Epoch: 6| Step: 8
Training loss: 0.8318491578102112
Validation loss: 2.2191161115964255

Epoch: 6| Step: 9
Training loss: 1.2039976119995117
Validation loss: 2.259132365385691

Epoch: 6| Step: 10
Training loss: 0.5516718626022339
Validation loss: 2.2569249669710794

Epoch: 6| Step: 11
Training loss: 1.291532039642334
Validation loss: 2.217236498991648

Epoch: 6| Step: 12
Training loss: 1.105951189994812
Validation loss: 2.216087500254313

Epoch: 6| Step: 13
Training loss: 1.2696418762207031
Validation loss: 2.2121125062306723

Epoch: 401| Step: 0
Training loss: 1.0522030591964722
Validation loss: 2.1449942787488303

Epoch: 6| Step: 1
Training loss: 1.1809751987457275
Validation loss: 2.145389755566915

Epoch: 6| Step: 2
Training loss: 1.7439993619918823
Validation loss: 2.2081778844197593

Epoch: 6| Step: 3
Training loss: 1.115596055984497
Validation loss: 2.2006744146347046

Epoch: 6| Step: 4
Training loss: 0.4092259705066681
Validation loss: 2.2152928709983826

Epoch: 6| Step: 5
Training loss: 0.8210704326629639
Validation loss: 2.19758669535319

Epoch: 6| Step: 6
Training loss: 0.6192610263824463
Validation loss: 2.2293675343195596

Epoch: 6| Step: 7
Training loss: 0.7675906419754028
Validation loss: 2.253635803858439

Epoch: 6| Step: 8
Training loss: 0.9696106910705566
Validation loss: 2.2618300517400107

Epoch: 6| Step: 9
Training loss: 1.4298210144042969
Validation loss: 2.2445926666259766

Epoch: 6| Step: 10
Training loss: 0.5546217560768127
Validation loss: 2.2330654859542847

Epoch: 6| Step: 11
Training loss: 1.0436594486236572
Validation loss: 2.1903555591901145

Epoch: 6| Step: 12
Training loss: 1.244188904762268
Validation loss: 2.2193432251612344

Epoch: 6| Step: 13
Training loss: 1.1367613077163696
Validation loss: 2.1443690260251365

Epoch: 402| Step: 0
Training loss: 1.5633463859558105
Validation loss: 2.188396414120992

Epoch: 6| Step: 1
Training loss: 0.5163357853889465
Validation loss: 2.1324806809425354

Epoch: 6| Step: 2
Training loss: 1.0620225667953491
Validation loss: 2.203365902105967

Epoch: 6| Step: 3
Training loss: 1.474572777748108
Validation loss: 2.165246864159902

Epoch: 6| Step: 4
Training loss: 1.0636084079742432
Validation loss: 2.184262692928314

Epoch: 6| Step: 5
Training loss: 1.4630458354949951
Validation loss: 2.1701335310935974

Epoch: 6| Step: 6
Training loss: 1.2219359874725342
Validation loss: 2.155115862687429

Epoch: 6| Step: 7
Training loss: 0.8589419722557068
Validation loss: 2.173063417275747

Epoch: 6| Step: 8
Training loss: 0.8360732197761536
Validation loss: 2.200938860575358

Epoch: 6| Step: 9
Training loss: 0.9977730512619019
Validation loss: 2.165563404560089

Epoch: 6| Step: 10
Training loss: 0.8267689943313599
Validation loss: 2.194392363230387

Epoch: 6| Step: 11
Training loss: 1.0310896635055542
Validation loss: 2.1518956224123635

Epoch: 6| Step: 12
Training loss: 0.7473341822624207
Validation loss: 2.2171764771143594

Epoch: 6| Step: 13
Training loss: 1.3310966491699219
Validation loss: 2.211469213167826

Epoch: 403| Step: 0
Training loss: 1.1428505182266235
Validation loss: 2.230595827102661

Epoch: 6| Step: 1
Training loss: 0.8714935779571533
Validation loss: 2.25209108988444

Epoch: 6| Step: 2
Training loss: 1.1341267824172974
Validation loss: 2.2550861835479736

Epoch: 6| Step: 3
Training loss: 1.2436249256134033
Validation loss: 2.2665415604909263

Epoch: 6| Step: 4
Training loss: 1.2044885158538818
Validation loss: 2.215611775716146

Epoch: 6| Step: 5
Training loss: 0.7415304183959961
Validation loss: 2.2252877155939736

Epoch: 6| Step: 6
Training loss: 0.6222143173217773
Validation loss: 2.196652094523112

Epoch: 6| Step: 7
Training loss: 0.5527058839797974
Validation loss: 2.1776179869969687

Epoch: 6| Step: 8
Training loss: 1.3261299133300781
Validation loss: 2.2002893487612405

Epoch: 6| Step: 9
Training loss: 1.29453706741333
Validation loss: 2.172740320364634

Epoch: 6| Step: 10
Training loss: 2.2205348014831543
Validation loss: 2.1695540944735208

Epoch: 6| Step: 11
Training loss: 0.7931240797042847
Validation loss: 2.169917047023773

Epoch: 6| Step: 12
Training loss: 0.5612559914588928
Validation loss: 2.167912185192108

Epoch: 6| Step: 13
Training loss: 0.9458814263343811
Validation loss: 2.2225259145100913

Epoch: 404| Step: 0
Training loss: 1.3946410417556763
Validation loss: 2.180504083633423

Epoch: 6| Step: 1
Training loss: 0.6839159727096558
Validation loss: 2.2054874300956726

Epoch: 6| Step: 2
Training loss: 1.217816948890686
Validation loss: 2.1768226623535156

Epoch: 6| Step: 3
Training loss: 1.10386323928833
Validation loss: 2.194428642590841

Epoch: 6| Step: 4
Training loss: 1.3527936935424805
Validation loss: 2.1745611429214478

Epoch: 6| Step: 5
Training loss: 1.3437623977661133
Validation loss: 2.1627896825472512

Epoch: 6| Step: 6
Training loss: 1.1610186100006104
Validation loss: 2.228959043820699

Epoch: 6| Step: 7
Training loss: 0.7702115774154663
Validation loss: 2.201030751069387

Epoch: 6| Step: 8
Training loss: 1.228148102760315
Validation loss: 2.2053834597269693

Epoch: 6| Step: 9
Training loss: 0.8299248218536377
Validation loss: 2.1948903600374856

Epoch: 6| Step: 10
Training loss: 0.8918540477752686
Validation loss: 2.246878743171692

Epoch: 6| Step: 11
Training loss: 1.2482362985610962
Validation loss: 2.178349236647288

Epoch: 6| Step: 12
Training loss: 0.6390974521636963
Validation loss: 2.2061832348505654

Epoch: 6| Step: 13
Training loss: 0.8712561726570129
Validation loss: 2.167333702246348

Epoch: 405| Step: 0
Training loss: 1.160351276397705
Validation loss: 2.1748326619466147

Epoch: 6| Step: 1
Training loss: 0.9723074436187744
Validation loss: 2.1666837533315024

Epoch: 6| Step: 2
Training loss: 0.8657765984535217
Validation loss: 2.1746080915133157

Epoch: 6| Step: 3
Training loss: 0.5922937393188477
Validation loss: 2.1758616169293723

Epoch: 6| Step: 4
Training loss: 1.0192891359329224
Validation loss: 2.199604789415995

Epoch: 6| Step: 5
Training loss: 0.6063514947891235
Validation loss: 2.222917636235555

Epoch: 6| Step: 6
Training loss: 1.5535354614257812
Validation loss: 2.2193323969841003

Epoch: 6| Step: 7
Training loss: 1.0697591304779053
Validation loss: 2.2029624382654824

Epoch: 6| Step: 8
Training loss: 0.5655319690704346
Validation loss: 2.2349144220352173

Epoch: 6| Step: 9
Training loss: 1.6693403720855713
Validation loss: 2.24267848332723

Epoch: 6| Step: 10
Training loss: 1.0474247932434082
Validation loss: 2.26770027478536

Epoch: 6| Step: 11
Training loss: 1.7922120094299316
Validation loss: 2.256394545237223

Epoch: 6| Step: 12
Training loss: 0.6454347372055054
Validation loss: 2.2506236632665

Epoch: 6| Step: 13
Training loss: 0.8027470707893372
Validation loss: 2.255238652229309

Epoch: 406| Step: 0
Training loss: 0.9943839311599731
Validation loss: 2.2352691888809204

Epoch: 6| Step: 1
Training loss: 1.1390652656555176
Validation loss: 2.269058028856913

Epoch: 6| Step: 2
Training loss: 1.1393795013427734
Validation loss: 2.2911429603894553

Epoch: 6| Step: 3
Training loss: 1.1365675926208496
Validation loss: 2.2728049755096436

Epoch: 6| Step: 4
Training loss: 1.3390905857086182
Validation loss: 2.23965847492218

Epoch: 6| Step: 5
Training loss: 1.0135706663131714
Validation loss: 2.2329792380332947

Epoch: 6| Step: 6
Training loss: 1.5036518573760986
Validation loss: 2.21574334303538

Epoch: 6| Step: 7
Training loss: 1.10126531124115
Validation loss: 2.226586699485779

Epoch: 6| Step: 8
Training loss: 0.629450798034668
Validation loss: 2.216296374797821

Epoch: 6| Step: 9
Training loss: 0.6772351264953613
Validation loss: 2.2030109961827598

Epoch: 6| Step: 10
Training loss: 1.1393625736236572
Validation loss: 2.18960173924764

Epoch: 6| Step: 11
Training loss: 1.3110393285751343
Validation loss: 2.190294841925303

Epoch: 6| Step: 12
Training loss: 1.307543158531189
Validation loss: 2.213237782319387

Epoch: 6| Step: 13
Training loss: 0.5459891557693481
Validation loss: 2.1646815737088523

Epoch: 407| Step: 0
Training loss: 1.1196212768554688
Validation loss: 2.2006765604019165

Epoch: 6| Step: 1
Training loss: 1.1254751682281494
Validation loss: 2.1697065432866416

Epoch: 6| Step: 2
Training loss: 0.916748583316803
Validation loss: 2.170375029246012

Epoch: 6| Step: 3
Training loss: 1.1470680236816406
Validation loss: 2.1777490377426147

Epoch: 6| Step: 4
Training loss: 0.46312063932418823
Validation loss: 2.2045581142107644

Epoch: 6| Step: 5
Training loss: 0.4848036766052246
Validation loss: 2.1687620083491006

Epoch: 6| Step: 6
Training loss: 1.5508229732513428
Validation loss: 2.196075956026713

Epoch: 6| Step: 7
Training loss: 0.5324504375457764
Validation loss: 2.224315663178762

Epoch: 6| Step: 8
Training loss: 0.7878649234771729
Validation loss: 2.2032556732495627

Epoch: 6| Step: 9
Training loss: 1.014573335647583
Validation loss: 2.247533361117045

Epoch: 6| Step: 10
Training loss: 0.9111387133598328
Validation loss: 2.221426506837209

Epoch: 6| Step: 11
Training loss: 0.9458781480789185
Validation loss: 2.1675917704900107

Epoch: 6| Step: 12
Training loss: 1.1938049793243408
Validation loss: 2.1965485413869223

Epoch: 6| Step: 13
Training loss: 1.7065694332122803
Validation loss: 2.1831037998199463

Epoch: 408| Step: 0
Training loss: 0.7558727860450745
Validation loss: 2.2224376797676086

Epoch: 6| Step: 1
Training loss: 1.1190448999404907
Validation loss: 2.193623880545298

Epoch: 6| Step: 2
Training loss: 0.6781866550445557
Validation loss: 2.2100802659988403

Epoch: 6| Step: 3
Training loss: 0.8215179443359375
Validation loss: 2.1666974822680154

Epoch: 6| Step: 4
Training loss: 1.9166970252990723
Validation loss: 2.164135217666626

Epoch: 6| Step: 5
Training loss: 1.3389908075332642
Validation loss: 2.1944382985432944

Epoch: 6| Step: 6
Training loss: 1.2351182699203491
Validation loss: 2.212181011835734

Epoch: 6| Step: 7
Training loss: 0.7076461315155029
Validation loss: 2.2154113252957663

Epoch: 6| Step: 8
Training loss: 1.314720869064331
Validation loss: 2.2125505208969116

Epoch: 6| Step: 9
Training loss: 1.0124810934066772
Validation loss: 2.222920378049215

Epoch: 6| Step: 10
Training loss: 1.0806846618652344
Validation loss: 2.224767824014028

Epoch: 6| Step: 11
Training loss: 0.7654378414154053
Validation loss: 2.2086018323898315

Epoch: 6| Step: 12
Training loss: 0.628412127494812
Validation loss: 2.233736276626587

Epoch: 6| Step: 13
Training loss: 0.7010176181793213
Validation loss: 2.223660628000895

Epoch: 409| Step: 0
Training loss: 0.6382491588592529
Validation loss: 2.213553329308828

Epoch: 6| Step: 1
Training loss: 1.0620174407958984
Validation loss: 2.226623058319092

Epoch: 6| Step: 2
Training loss: 0.8200218677520752
Validation loss: 2.1939730644226074

Epoch: 6| Step: 3
Training loss: 0.8053615093231201
Validation loss: 2.2143152753512063

Epoch: 6| Step: 4
Training loss: 0.7970876693725586
Validation loss: 2.237906257311503

Epoch: 6| Step: 5
Training loss: 0.7177309393882751
Validation loss: 2.2197415630022683

Epoch: 6| Step: 6
Training loss: 1.5046734809875488
Validation loss: 2.2361793915430703

Epoch: 6| Step: 7
Training loss: 1.114234209060669
Validation loss: 2.261993924776713

Epoch: 6| Step: 8
Training loss: 1.1312373876571655
Validation loss: 2.23076856136322

Epoch: 6| Step: 9
Training loss: 1.1877191066741943
Validation loss: 2.2314956982930503

Epoch: 6| Step: 10
Training loss: 1.26755952835083
Validation loss: 2.2295835415522256

Epoch: 6| Step: 11
Training loss: 0.6702597141265869
Validation loss: 2.1940758426984153

Epoch: 6| Step: 12
Training loss: 1.0004955530166626
Validation loss: 2.21131161848704

Epoch: 6| Step: 13
Training loss: 0.8428261280059814
Validation loss: 2.252696951230367

Epoch: 410| Step: 0
Training loss: 0.6852965354919434
Validation loss: 2.2233425180117288

Epoch: 6| Step: 1
Training loss: 1.5002903938293457
Validation loss: 2.2360602815945945

Epoch: 6| Step: 2
Training loss: 1.2858757972717285
Validation loss: 2.211853345235189

Epoch: 6| Step: 3
Training loss: 0.5042080879211426
Validation loss: 2.1969399452209473

Epoch: 6| Step: 4
Training loss: 0.7764611840248108
Validation loss: 2.215480844179789

Epoch: 6| Step: 5
Training loss: 1.1422128677368164
Validation loss: 2.209893584251404

Epoch: 6| Step: 6
Training loss: 0.606598973274231
Validation loss: 2.178779204686483

Epoch: 6| Step: 7
Training loss: 0.8003615736961365
Validation loss: 2.2236479918162027

Epoch: 6| Step: 8
Training loss: 1.065876841545105
Validation loss: 2.211138983567556

Epoch: 6| Step: 9
Training loss: 0.8603708744049072
Validation loss: 2.2451120018959045

Epoch: 6| Step: 10
Training loss: 1.460397720336914
Validation loss: 2.238630016644796

Epoch: 6| Step: 11
Training loss: 1.0915567874908447
Validation loss: 2.258608043193817

Epoch: 6| Step: 12
Training loss: 1.0715441703796387
Validation loss: 2.237343986829122

Epoch: 6| Step: 13
Training loss: 0.5946365594863892
Validation loss: 2.2780244946479797

Epoch: 411| Step: 0
Training loss: 0.7457679510116577
Validation loss: 2.2398574550946555

Epoch: 6| Step: 1
Training loss: 0.9575227499008179
Validation loss: 2.276523232460022

Epoch: 6| Step: 2
Training loss: 0.8108954429626465
Validation loss: 2.2600692311922708

Epoch: 6| Step: 3
Training loss: 0.7787497639656067
Validation loss: 2.2236295342445374

Epoch: 6| Step: 4
Training loss: 1.181903600692749
Validation loss: 2.215658644835154

Epoch: 6| Step: 5
Training loss: 0.504608154296875
Validation loss: 2.1738874912261963

Epoch: 6| Step: 6
Training loss: 0.6464914679527283
Validation loss: 2.2030025919278464

Epoch: 6| Step: 7
Training loss: 0.8664525151252747
Validation loss: 2.226360261440277

Epoch: 6| Step: 8
Training loss: 0.8755844831466675
Validation loss: 2.1934877832730613

Epoch: 6| Step: 9
Training loss: 1.2320561408996582
Validation loss: 2.2100513577461243

Epoch: 6| Step: 10
Training loss: 0.8714476823806763
Validation loss: 2.2309290568033853

Epoch: 6| Step: 11
Training loss: 1.5096386671066284
Validation loss: 2.1926015416781106

Epoch: 6| Step: 12
Training loss: 1.1982076168060303
Validation loss: 2.2216220696767173

Epoch: 6| Step: 13
Training loss: 1.2035094499588013
Validation loss: 2.189379175504049

Epoch: 412| Step: 0
Training loss: 1.0366493463516235
Validation loss: 2.223776161670685

Epoch: 6| Step: 1
Training loss: 0.6683348417282104
Validation loss: 2.22089676062266

Epoch: 6| Step: 2
Training loss: 0.8777441382408142
Validation loss: 2.1819692850112915

Epoch: 6| Step: 3
Training loss: 1.69755220413208
Validation loss: 2.2279422680536904

Epoch: 6| Step: 4
Training loss: 0.788477897644043
Validation loss: 2.2256769140561423

Epoch: 6| Step: 5
Training loss: 0.8732447028160095
Validation loss: 2.204722980658213

Epoch: 6| Step: 6
Training loss: 0.9831889867782593
Validation loss: 2.2139051953951516

Epoch: 6| Step: 7
Training loss: 0.5804558992385864
Validation loss: 2.2249377767244973

Epoch: 6| Step: 8
Training loss: 0.9125605821609497
Validation loss: 2.221389651298523

Epoch: 6| Step: 9
Training loss: 0.8477978706359863
Validation loss: 2.2446682453155518

Epoch: 6| Step: 10
Training loss: 0.8493467569351196
Validation loss: 2.2633703152338662

Epoch: 6| Step: 11
Training loss: 0.881381094455719
Validation loss: 2.2397260864575705

Epoch: 6| Step: 12
Training loss: 1.0762279033660889
Validation loss: 2.215290645758311

Epoch: 6| Step: 13
Training loss: 1.0934669971466064
Validation loss: 2.2711362838745117

Epoch: 413| Step: 0
Training loss: 0.7759398818016052
Validation loss: 2.2224036852518716

Epoch: 6| Step: 1
Training loss: 0.7277302145957947
Validation loss: 2.2173629999160767

Epoch: 6| Step: 2
Training loss: 0.8447458744049072
Validation loss: 2.202537178993225

Epoch: 6| Step: 3
Training loss: 1.2537569999694824
Validation loss: 2.2042671839396157

Epoch: 6| Step: 4
Training loss: 0.9325684309005737
Validation loss: 2.2540907065073648

Epoch: 6| Step: 5
Training loss: 0.7291868329048157
Validation loss: 2.2137222290039062

Epoch: 6| Step: 6
Training loss: 0.9869709610939026
Validation loss: 2.2187898556391397

Epoch: 6| Step: 7
Training loss: 0.6191882491111755
Validation loss: 2.245371421178182

Epoch: 6| Step: 8
Training loss: 1.5682882070541382
Validation loss: 2.2358097632726035

Epoch: 6| Step: 9
Training loss: 0.4251755177974701
Validation loss: 2.226505994796753

Epoch: 6| Step: 10
Training loss: 1.520075798034668
Validation loss: 2.233610510826111

Epoch: 6| Step: 11
Training loss: 1.037265658378601
Validation loss: 2.2114461064338684

Epoch: 6| Step: 12
Training loss: 0.8703994154930115
Validation loss: 2.2224156061808267

Epoch: 6| Step: 13
Training loss: 0.9563176035881042
Validation loss: 2.226620634396871

Epoch: 414| Step: 0
Training loss: 1.2780709266662598
Validation loss: 2.2134719491004944

Epoch: 6| Step: 1
Training loss: 0.44834113121032715
Validation loss: 2.2214629451433816

Epoch: 6| Step: 2
Training loss: 0.9312261343002319
Validation loss: 2.226782480875651

Epoch: 6| Step: 3
Training loss: 0.7652248740196228
Validation loss: 2.2427081068356833

Epoch: 6| Step: 4
Training loss: 1.0323903560638428
Validation loss: 2.243031660715739

Epoch: 6| Step: 5
Training loss: 0.8319429755210876
Validation loss: 2.240327457586924

Epoch: 6| Step: 6
Training loss: 0.7323825359344482
Validation loss: 2.2314393122990928

Epoch: 6| Step: 7
Training loss: 0.9096778035163879
Validation loss: 2.2359477082888284

Epoch: 6| Step: 8
Training loss: 1.7268457412719727
Validation loss: 2.2396111289660134

Epoch: 6| Step: 9
Training loss: 0.7195287942886353
Validation loss: 2.181067963441213

Epoch: 6| Step: 10
Training loss: 1.547361135482788
Validation loss: 2.1824070811271667

Epoch: 6| Step: 11
Training loss: 1.0908191204071045
Validation loss: 2.1852535009384155

Epoch: 6| Step: 12
Training loss: 1.499128818511963
Validation loss: 2.200306157271067

Epoch: 6| Step: 13
Training loss: 0.8489678502082825
Validation loss: 2.2323662837346396

Epoch: 415| Step: 0
Training loss: 1.4142073392868042
Validation loss: 2.214154223601023

Epoch: 6| Step: 1
Training loss: 1.2447954416275024
Validation loss: 2.221848646799723

Epoch: 6| Step: 2
Training loss: 1.1841509342193604
Validation loss: 2.2604604959487915

Epoch: 6| Step: 3
Training loss: 1.0571637153625488
Validation loss: 2.264747659365336

Epoch: 6| Step: 4
Training loss: 0.6876182556152344
Validation loss: 2.2901575565338135

Epoch: 6| Step: 5
Training loss: 1.3916579484939575
Validation loss: 2.2967113256454468

Epoch: 6| Step: 6
Training loss: 1.025460958480835
Validation loss: 2.3067864576975503

Epoch: 6| Step: 7
Training loss: 0.897692084312439
Validation loss: 2.276522397994995

Epoch: 6| Step: 8
Training loss: 0.7558262944221497
Validation loss: 2.28683332602183

Epoch: 6| Step: 9
Training loss: 0.9468133449554443
Validation loss: 2.2619042793909707

Epoch: 6| Step: 10
Training loss: 1.0975698232650757
Validation loss: 2.259915908177694

Epoch: 6| Step: 11
Training loss: 0.7052289247512817
Validation loss: 2.271782636642456

Epoch: 6| Step: 12
Training loss: 0.35144931077957153
Validation loss: 2.196359713872274

Epoch: 6| Step: 13
Training loss: 0.9887893199920654
Validation loss: 2.2356296380360923

Epoch: 416| Step: 0
Training loss: 1.6923158168792725
Validation loss: 2.2174405455589294

Epoch: 6| Step: 1
Training loss: 0.8304497003555298
Validation loss: 2.24895187218984

Epoch: 6| Step: 2
Training loss: 0.9553734064102173
Validation loss: 2.247670272986094

Epoch: 6| Step: 3
Training loss: 1.0345542430877686
Validation loss: 2.233360250790914

Epoch: 6| Step: 4
Training loss: 0.5915725231170654
Validation loss: 2.2544588247934976

Epoch: 6| Step: 5
Training loss: 1.0029325485229492
Validation loss: 2.242061992486318

Epoch: 6| Step: 6
Training loss: 1.0417975187301636
Validation loss: 2.2350269754727683

Epoch: 6| Step: 7
Training loss: 1.0809296369552612
Validation loss: 2.2910014390945435

Epoch: 6| Step: 8
Training loss: 0.9857068061828613
Validation loss: 2.272051990032196

Epoch: 6| Step: 9
Training loss: 0.8114557266235352
Validation loss: 2.2577534914016724

Epoch: 6| Step: 10
Training loss: 1.50814950466156
Validation loss: 2.21774560213089

Epoch: 6| Step: 11
Training loss: 0.6149837374687195
Validation loss: 2.231061816215515

Epoch: 6| Step: 12
Training loss: 0.9586030840873718
Validation loss: 2.2150018016497293

Epoch: 6| Step: 13
Training loss: 0.5856912136077881
Validation loss: 2.2220651706059775

Epoch: 417| Step: 0
Training loss: 0.5608829259872437
Validation loss: 2.197428047657013

Epoch: 6| Step: 1
Training loss: 1.589465856552124
Validation loss: 2.2115302085876465

Epoch: 6| Step: 2
Training loss: 1.4100507497787476
Validation loss: 2.229514161745707

Epoch: 6| Step: 3
Training loss: 0.9604441523551941
Validation loss: 2.2144211729367576

Epoch: 6| Step: 4
Training loss: 0.9614412188529968
Validation loss: 2.2507670720418296

Epoch: 6| Step: 5
Training loss: 1.3085319995880127
Validation loss: 2.2332000931104026

Epoch: 6| Step: 6
Training loss: 0.9342800378799438
Validation loss: 2.2392531037330627

Epoch: 6| Step: 7
Training loss: 0.8793696761131287
Validation loss: 2.251249074935913

Epoch: 6| Step: 8
Training loss: 1.7450165748596191
Validation loss: 2.3004520734151206

Epoch: 6| Step: 9
Training loss: 0.757513165473938
Validation loss: 2.275603095690409

Epoch: 6| Step: 10
Training loss: 1.0864366292953491
Validation loss: 2.2848209738731384

Epoch: 6| Step: 11
Training loss: 0.8227085471153259
Validation loss: 2.3022244771321616

Epoch: 6| Step: 12
Training loss: 0.9351779222488403
Validation loss: 2.3055718342463174

Epoch: 6| Step: 13
Training loss: 1.1303614377975464
Validation loss: 2.2935887773831687

Epoch: 418| Step: 0
Training loss: 1.2982587814331055
Validation loss: 2.2685305078824363

Epoch: 6| Step: 1
Training loss: 0.8970296382904053
Validation loss: 2.2552103996276855

Epoch: 6| Step: 2
Training loss: 0.8836420774459839
Validation loss: 2.21973717212677

Epoch: 6| Step: 3
Training loss: 0.7440906167030334
Validation loss: 2.2657860120137534

Epoch: 6| Step: 4
Training loss: 1.0237948894500732
Validation loss: 2.1722466150919595

Epoch: 6| Step: 5
Training loss: 1.135117769241333
Validation loss: 2.2473082145055137

Epoch: 6| Step: 6
Training loss: 0.5411844849586487
Validation loss: 2.234655777613322

Epoch: 6| Step: 7
Training loss: 1.4157850742340088
Validation loss: 2.2120185494422913

Epoch: 6| Step: 8
Training loss: 0.5648877024650574
Validation loss: 2.211873153845469

Epoch: 6| Step: 9
Training loss: 0.6909877061843872
Validation loss: 2.2396795948346457

Epoch: 6| Step: 10
Training loss: 0.7896490693092346
Validation loss: 2.2100327809651694

Epoch: 6| Step: 11
Training loss: 1.2293148040771484
Validation loss: 2.2152392665545144

Epoch: 6| Step: 12
Training loss: 1.1471295356750488
Validation loss: 2.1569846669832864

Epoch: 6| Step: 13
Training loss: 0.7134143114089966
Validation loss: 2.236327588558197

Epoch: 419| Step: 0
Training loss: 0.9013751745223999
Validation loss: 2.220621089140574

Epoch: 6| Step: 1
Training loss: 0.5512251853942871
Validation loss: 2.2220099568367004

Epoch: 6| Step: 2
Training loss: 1.5545103549957275
Validation loss: 2.1915047566095986

Epoch: 6| Step: 3
Training loss: 1.2311816215515137
Validation loss: 2.1944595774014792

Epoch: 6| Step: 4
Training loss: 1.2842698097229004
Validation loss: 2.1944885651270547

Epoch: 6| Step: 5
Training loss: 1.2426371574401855
Validation loss: 2.2113992969195047

Epoch: 6| Step: 6
Training loss: 0.5837428569793701
Validation loss: 2.2370017568270364

Epoch: 6| Step: 7
Training loss: 1.341970443725586
Validation loss: 2.256524085998535

Epoch: 6| Step: 8
Training loss: 0.5490603446960449
Validation loss: 2.226376930872599

Epoch: 6| Step: 9
Training loss: 0.7695788145065308
Validation loss: 2.244685967763265

Epoch: 6| Step: 10
Training loss: 0.7030304074287415
Validation loss: 2.2337993582089744

Epoch: 6| Step: 11
Training loss: 0.9224616289138794
Validation loss: 2.2751158078511557

Epoch: 6| Step: 12
Training loss: 0.7766104340553284
Validation loss: 2.2602745294570923

Epoch: 6| Step: 13
Training loss: 0.6810591220855713
Validation loss: 2.2202633023262024

Epoch: 420| Step: 0
Training loss: 0.7044862508773804
Validation loss: 2.2140369415283203

Epoch: 6| Step: 1
Training loss: 1.0337252616882324
Validation loss: 2.2296930948893228

Epoch: 6| Step: 2
Training loss: 0.9058030247688293
Validation loss: 2.268571138381958

Epoch: 6| Step: 3
Training loss: 0.9744269251823425
Validation loss: 2.2236344615618386

Epoch: 6| Step: 4
Training loss: 0.7964447736740112
Validation loss: 2.2378233671188354

Epoch: 6| Step: 5
Training loss: 1.0382397174835205
Validation loss: 2.217140336831411

Epoch: 6| Step: 6
Training loss: 0.9201527237892151
Validation loss: 2.2559308608373008

Epoch: 6| Step: 7
Training loss: 1.0333256721496582
Validation loss: 2.2254364093144736

Epoch: 6| Step: 8
Training loss: 0.7415540218353271
Validation loss: 2.186911682287852

Epoch: 6| Step: 9
Training loss: 0.9695897102355957
Validation loss: 2.2325576146443686

Epoch: 6| Step: 10
Training loss: 0.9972396492958069
Validation loss: 2.205426653226217

Epoch: 6| Step: 11
Training loss: 1.063936710357666
Validation loss: 2.2030895948410034

Epoch: 6| Step: 12
Training loss: 0.5520899295806885
Validation loss: 2.1763497392336526

Epoch: 6| Step: 13
Training loss: 1.2461216449737549
Validation loss: 2.26376074552536

Epoch: 421| Step: 0
Training loss: 1.0251634120941162
Validation loss: 2.2466793060302734

Epoch: 6| Step: 1
Training loss: 1.2759034633636475
Validation loss: 2.2351080179214478

Epoch: 6| Step: 2
Training loss: 1.252139687538147
Validation loss: 2.2420787612597146

Epoch: 6| Step: 3
Training loss: 0.9540113210678101
Validation loss: 2.227413018544515

Epoch: 6| Step: 4
Training loss: 1.451905369758606
Validation loss: 2.198612113793691

Epoch: 6| Step: 5
Training loss: 0.8223621845245361
Validation loss: 2.197399457295736

Epoch: 6| Step: 6
Training loss: 1.1422511339187622
Validation loss: 2.207823713620504

Epoch: 6| Step: 7
Training loss: 0.9500701427459717
Validation loss: 2.213273545106252

Epoch: 6| Step: 8
Training loss: 0.5125302076339722
Validation loss: 2.1527175108591714

Epoch: 6| Step: 9
Training loss: 0.8745349645614624
Validation loss: 2.2204238772392273

Epoch: 6| Step: 10
Training loss: 0.6863025426864624
Validation loss: 2.2013321916262307

Epoch: 6| Step: 11
Training loss: 0.8448848724365234
Validation loss: 2.2237388094266257

Epoch: 6| Step: 12
Training loss: 0.754668116569519
Validation loss: 2.2098871866861978

Epoch: 6| Step: 13
Training loss: 0.9447466135025024
Validation loss: 2.2367019057273865

Epoch: 422| Step: 0
Training loss: 0.3603375554084778
Validation loss: 2.221806764602661

Epoch: 6| Step: 1
Training loss: 0.8190564513206482
Validation loss: 2.270475685596466

Epoch: 6| Step: 2
Training loss: 0.7812432050704956
Validation loss: 2.2684017419815063

Epoch: 6| Step: 3
Training loss: 1.2808892726898193
Validation loss: 2.2302252451578775

Epoch: 6| Step: 4
Training loss: 0.6787542104721069
Validation loss: 2.223382751146952

Epoch: 6| Step: 5
Training loss: 1.2067115306854248
Validation loss: 2.190636694431305

Epoch: 6| Step: 6
Training loss: 1.4441502094268799
Validation loss: 2.2208225329717

Epoch: 6| Step: 7
Training loss: 0.9056787490844727
Validation loss: 2.209969222545624

Epoch: 6| Step: 8
Training loss: 0.6304931640625
Validation loss: 2.184073050816854

Epoch: 6| Step: 9
Training loss: 1.2779512405395508
Validation loss: 2.1779144008954368

Epoch: 6| Step: 10
Training loss: 0.7815132141113281
Validation loss: 2.2039164702097573

Epoch: 6| Step: 11
Training loss: 0.6645927429199219
Validation loss: 2.2109667460123696

Epoch: 6| Step: 12
Training loss: 0.8049618005752563
Validation loss: 2.1941412885983786

Epoch: 6| Step: 13
Training loss: 1.2279844284057617
Validation loss: 2.2285983562469482

Epoch: 423| Step: 0
Training loss: 0.4298051595687866
Validation loss: 2.2805073459943137

Epoch: 6| Step: 1
Training loss: 0.7549383640289307
Validation loss: 2.268152952194214

Epoch: 6| Step: 2
Training loss: 1.0597295761108398
Validation loss: 2.276203195254008

Epoch: 6| Step: 3
Training loss: 0.8392963409423828
Validation loss: 2.2826696634292603

Epoch: 6| Step: 4
Training loss: 0.8800148367881775
Validation loss: 2.2873037457466125

Epoch: 6| Step: 5
Training loss: 1.1615490913391113
Validation loss: 2.2757874131202698

Epoch: 6| Step: 6
Training loss: 1.0784327983856201
Validation loss: 2.271355171998342

Epoch: 6| Step: 7
Training loss: 0.9861094951629639
Validation loss: 2.226548671722412

Epoch: 6| Step: 8
Training loss: 0.8042934536933899
Validation loss: 2.2777843674023948

Epoch: 6| Step: 9
Training loss: 1.1624282598495483
Validation loss: 2.245257318019867

Epoch: 6| Step: 10
Training loss: 1.0692166090011597
Validation loss: 2.2445251742998757

Epoch: 6| Step: 11
Training loss: 0.7450387477874756
Validation loss: 2.2192564407984414

Epoch: 6| Step: 12
Training loss: 0.702723503112793
Validation loss: 2.216881354649862

Epoch: 6| Step: 13
Training loss: 0.9028564691543579
Validation loss: 2.1980668703715005

Epoch: 424| Step: 0
Training loss: 0.7710070610046387
Validation loss: 2.211962083975474

Epoch: 6| Step: 1
Training loss: 1.0373170375823975
Validation loss: 2.2076295614242554

Epoch: 6| Step: 2
Training loss: 1.0967848300933838
Validation loss: 2.2220905224482217

Epoch: 6| Step: 3
Training loss: 1.23647141456604
Validation loss: 2.2408626278241477

Epoch: 6| Step: 4
Training loss: 1.0476588010787964
Validation loss: 2.2235942284266152

Epoch: 6| Step: 5
Training loss: 1.0336205959320068
Validation loss: 2.2086387475331626

Epoch: 6| Step: 6
Training loss: 0.7547956109046936
Validation loss: 2.249119738737742

Epoch: 6| Step: 7
Training loss: 0.6806848049163818
Validation loss: 2.1927953163782754

Epoch: 6| Step: 8
Training loss: 0.6450046896934509
Validation loss: 2.2209108670552573

Epoch: 6| Step: 9
Training loss: 1.0840425491333008
Validation loss: 2.234735051790873

Epoch: 6| Step: 10
Training loss: 0.9225565791130066
Validation loss: 2.218937655289968

Epoch: 6| Step: 11
Training loss: 0.8030503392219543
Validation loss: 2.2389164169629416

Epoch: 6| Step: 12
Training loss: 0.7240774631500244
Validation loss: 2.276206612586975

Epoch: 6| Step: 13
Training loss: 1.3906309604644775
Validation loss: 2.293115735054016

Epoch: 425| Step: 0
Training loss: 0.9800564646720886
Validation loss: 2.2436592181523642

Epoch: 6| Step: 1
Training loss: 0.47189638018608093
Validation loss: 2.199439982573191

Epoch: 6| Step: 2
Training loss: 1.249435544013977
Validation loss: 2.225031614303589

Epoch: 6| Step: 3
Training loss: 0.845819354057312
Validation loss: 2.2110461592674255

Epoch: 6| Step: 4
Training loss: 0.948282778263092
Validation loss: 2.2076538602511087

Epoch: 6| Step: 5
Training loss: 1.2000699043273926
Validation loss: 2.180148740609487

Epoch: 6| Step: 6
Training loss: 0.8081148266792297
Validation loss: 2.1749395728111267

Epoch: 6| Step: 7
Training loss: 1.0428296327590942
Validation loss: 2.192423681418101

Epoch: 6| Step: 8
Training loss: 0.6163572072982788
Validation loss: 2.1874916752179465

Epoch: 6| Step: 9
Training loss: 0.7327120304107666
Validation loss: 2.2233479022979736

Epoch: 6| Step: 10
Training loss: 0.713712751865387
Validation loss: 2.227035085360209

Epoch: 6| Step: 11
Training loss: 1.3478009700775146
Validation loss: 2.2233721017837524

Epoch: 6| Step: 12
Training loss: 0.628234326839447
Validation loss: 2.2369367281595864

Epoch: 6| Step: 13
Training loss: 1.1155774593353271
Validation loss: 2.246385097503662

Epoch: 426| Step: 0
Training loss: 0.948326051235199
Validation loss: 2.2557989160219827

Epoch: 6| Step: 1
Training loss: 0.8783166408538818
Validation loss: 2.2413493394851685

Epoch: 6| Step: 2
Training loss: 1.1176891326904297
Validation loss: 2.2625075578689575

Epoch: 6| Step: 3
Training loss: 1.3664634227752686
Validation loss: 2.256485879421234

Epoch: 6| Step: 4
Training loss: 1.1833233833312988
Validation loss: 2.2342529694239297

Epoch: 6| Step: 5
Training loss: 0.5933797359466553
Validation loss: 2.2285447915395102

Epoch: 6| Step: 6
Training loss: 1.1429505348205566
Validation loss: 2.2494231263796487

Epoch: 6| Step: 7
Training loss: 0.23409855365753174
Validation loss: 2.2301239569981894

Epoch: 6| Step: 8
Training loss: 0.7128417491912842
Validation loss: 2.269984463850657

Epoch: 6| Step: 9
Training loss: 0.644619345664978
Validation loss: 2.2486775318781533

Epoch: 6| Step: 10
Training loss: 1.2250401973724365
Validation loss: 2.248428304990133

Epoch: 6| Step: 11
Training loss: 0.9199388027191162
Validation loss: 2.214647730191549

Epoch: 6| Step: 12
Training loss: 0.7145223617553711
Validation loss: 2.2432143886884055

Epoch: 6| Step: 13
Training loss: 0.9860974550247192
Validation loss: 2.2126800815264382

Epoch: 427| Step: 0
Training loss: 0.8591448068618774
Validation loss: 2.24016680320104

Epoch: 6| Step: 1
Training loss: 0.938825786113739
Validation loss: 2.20897646745046

Epoch: 6| Step: 2
Training loss: 1.0589146614074707
Validation loss: 2.199139177799225

Epoch: 6| Step: 3
Training loss: 0.5470734238624573
Validation loss: 2.2356197237968445

Epoch: 6| Step: 4
Training loss: 0.5773285627365112
Validation loss: 2.242038905620575

Epoch: 6| Step: 5
Training loss: 0.5148904919624329
Validation loss: 2.261418104171753

Epoch: 6| Step: 6
Training loss: 1.0416711568832397
Validation loss: 2.2379563649495444

Epoch: 6| Step: 7
Training loss: 1.07286536693573
Validation loss: 2.253029187520345

Epoch: 6| Step: 8
Training loss: 1.421175241470337
Validation loss: 2.221812387307485

Epoch: 6| Step: 9
Training loss: 0.7650226354598999
Validation loss: 2.264826695124308

Epoch: 6| Step: 10
Training loss: 1.635448694229126
Validation loss: 2.297674814860026

Epoch: 6| Step: 11
Training loss: 1.4327812194824219
Validation loss: 2.2435119350751243

Epoch: 6| Step: 12
Training loss: 0.7318408489227295
Validation loss: 2.2393459479014077

Epoch: 6| Step: 13
Training loss: 0.5333471298217773
Validation loss: 2.2658276756604514

Epoch: 428| Step: 0
Training loss: 0.9338855147361755
Validation loss: 2.2187746365865073

Epoch: 6| Step: 1
Training loss: 1.0249083042144775
Validation loss: 2.172200342019399

Epoch: 6| Step: 2
Training loss: 0.6688915491104126
Validation loss: 2.2310785055160522

Epoch: 6| Step: 3
Training loss: 0.887255847454071
Validation loss: 2.2041176557540894

Epoch: 6| Step: 4
Training loss: 1.1501808166503906
Validation loss: 2.235719541708628

Epoch: 6| Step: 5
Training loss: 1.0054025650024414
Validation loss: 2.212061961491903

Epoch: 6| Step: 6
Training loss: 0.5024019479751587
Validation loss: 2.2010426918665567

Epoch: 6| Step: 7
Training loss: 1.0143287181854248
Validation loss: 2.2515490452448526

Epoch: 6| Step: 8
Training loss: 1.4647047519683838
Validation loss: 2.2792856693267822

Epoch: 6| Step: 9
Training loss: 0.5442919135093689
Validation loss: 2.271498958269755

Epoch: 6| Step: 10
Training loss: 1.7204327583312988
Validation loss: 2.2763067285219827

Epoch: 6| Step: 11
Training loss: 0.6308091878890991
Validation loss: 2.2576281229654946

Epoch: 6| Step: 12
Training loss: 0.5726845264434814
Validation loss: 2.287156899770101

Epoch: 6| Step: 13
Training loss: 0.8601011037826538
Validation loss: 2.2772613565127053

Epoch: 429| Step: 0
Training loss: 0.788766622543335
Validation loss: 2.3283989628156028

Epoch: 6| Step: 1
Training loss: 0.7565888166427612
Validation loss: 2.3573787808418274

Epoch: 6| Step: 2
Training loss: 0.8558871150016785
Validation loss: 2.3285465041796365

Epoch: 6| Step: 3
Training loss: 0.8457298278808594
Validation loss: 2.3294195532798767

Epoch: 6| Step: 4
Training loss: 0.4294331669807434
Validation loss: 2.3483392794926963

Epoch: 6| Step: 5
Training loss: 1.0073162317276
Validation loss: 2.3255035678545632

Epoch: 6| Step: 6
Training loss: 0.6552832722663879
Validation loss: 2.3081841667493186

Epoch: 6| Step: 7
Training loss: 1.2761520147323608
Validation loss: 2.252233405907949

Epoch: 6| Step: 8
Training loss: 0.8854467868804932
Validation loss: 2.2658387422561646

Epoch: 6| Step: 9
Training loss: 1.6348047256469727
Validation loss: 2.2274787624677024

Epoch: 6| Step: 10
Training loss: 0.6384916305541992
Validation loss: 2.2229881087938943

Epoch: 6| Step: 11
Training loss: 1.185117483139038
Validation loss: 2.1901944677035012

Epoch: 6| Step: 12
Training loss: 0.9382400512695312
Validation loss: 2.1814305782318115

Epoch: 6| Step: 13
Training loss: 1.4859180450439453
Validation loss: 2.173435926437378

Epoch: 430| Step: 0
Training loss: 0.4962483048439026
Validation loss: 2.1913854082425437

Epoch: 6| Step: 1
Training loss: 1.3335797786712646
Validation loss: 2.184486905733744

Epoch: 6| Step: 2
Training loss: 1.119205117225647
Validation loss: 2.191604495048523

Epoch: 6| Step: 3
Training loss: 1.0126118659973145
Validation loss: 2.211364229520162

Epoch: 6| Step: 4
Training loss: 0.760500431060791
Validation loss: 2.221262514591217

Epoch: 6| Step: 5
Training loss: 0.8972868323326111
Validation loss: 2.227869391441345

Epoch: 6| Step: 6
Training loss: 0.9630098342895508
Validation loss: 2.2445030212402344

Epoch: 6| Step: 7
Training loss: 0.6656790971755981
Validation loss: 2.2722386916478476

Epoch: 6| Step: 8
Training loss: 1.2721143960952759
Validation loss: 2.330353856086731

Epoch: 6| Step: 9
Training loss: 0.8697022795677185
Validation loss: 2.318128744761149

Epoch: 6| Step: 10
Training loss: 1.192535161972046
Validation loss: 2.2934050957361856

Epoch: 6| Step: 11
Training loss: 0.45326802134513855
Validation loss: 2.2313395341237388

Epoch: 6| Step: 12
Training loss: 0.8876444101333618
Validation loss: 2.265949547290802

Epoch: 6| Step: 13
Training loss: 0.8640362024307251
Validation loss: 2.2846171061197915

Epoch: 431| Step: 0
Training loss: 0.6867913007736206
Validation loss: 2.2811532020568848

Epoch: 6| Step: 1
Training loss: 0.8213677406311035
Validation loss: 2.2681081692377725

Epoch: 6| Step: 2
Training loss: 1.0468237400054932
Validation loss: 2.202203333377838

Epoch: 6| Step: 3
Training loss: 1.1380881071090698
Validation loss: 2.2215177019437156

Epoch: 6| Step: 4
Training loss: 0.560626745223999
Validation loss: 2.2302342653274536

Epoch: 6| Step: 5
Training loss: 0.7575982809066772
Validation loss: 2.248910148938497

Epoch: 6| Step: 6
Training loss: 0.9048000574111938
Validation loss: 2.2314771811167398

Epoch: 6| Step: 7
Training loss: 1.2881858348846436
Validation loss: 2.2502773801485696

Epoch: 6| Step: 8
Training loss: 0.9256781339645386
Validation loss: 2.233810285727183

Epoch: 6| Step: 9
Training loss: 1.1141183376312256
Validation loss: 2.267742415269216

Epoch: 6| Step: 10
Training loss: 1.733257532119751
Validation loss: 2.238344152768453

Epoch: 6| Step: 11
Training loss: 0.7397843599319458
Validation loss: 2.20387734969457

Epoch: 6| Step: 12
Training loss: 1.0002803802490234
Validation loss: 2.193220535914103

Epoch: 6| Step: 13
Training loss: 0.4002131521701813
Validation loss: 2.201907455921173

Epoch: 432| Step: 0
Training loss: 0.5597363710403442
Validation loss: 2.2261243065198264

Epoch: 6| Step: 1
Training loss: 1.3891507387161255
Validation loss: 2.302932063738505

Epoch: 6| Step: 2
Training loss: 0.6570673584938049
Validation loss: 2.269024133682251

Epoch: 6| Step: 3
Training loss: 0.7943333387374878
Validation loss: 2.2649415135383606

Epoch: 6| Step: 4
Training loss: 0.8033195734024048
Validation loss: 2.271929621696472

Epoch: 6| Step: 5
Training loss: 0.7909373044967651
Validation loss: 2.2429698506991067

Epoch: 6| Step: 6
Training loss: 0.5170124173164368
Validation loss: 2.252662718296051

Epoch: 6| Step: 7
Training loss: 0.7793822288513184
Validation loss: 2.281832695007324

Epoch: 6| Step: 8
Training loss: 1.2534074783325195
Validation loss: 2.2792609532674155

Epoch: 6| Step: 9
Training loss: 0.8072162866592407
Validation loss: 2.275494654973348

Epoch: 6| Step: 10
Training loss: 0.41370025277137756
Validation loss: 2.281490921974182

Epoch: 6| Step: 11
Training loss: 1.0380584001541138
Validation loss: 2.2270267605781555

Epoch: 6| Step: 12
Training loss: 1.423793077468872
Validation loss: 2.255943854649862

Epoch: 6| Step: 13
Training loss: 1.0746766328811646
Validation loss: 2.235472023487091

Epoch: 433| Step: 0
Training loss: 0.6207560896873474
Validation loss: 2.229462424914042

Epoch: 6| Step: 1
Training loss: 0.2808111310005188
Validation loss: 2.239323059717814

Epoch: 6| Step: 2
Training loss: 0.7321654558181763
Validation loss: 2.2471159299214682

Epoch: 6| Step: 3
Training loss: 0.5779910087585449
Validation loss: 2.2255763610204062

Epoch: 6| Step: 4
Training loss: 1.1295347213745117
Validation loss: 2.221361736456553

Epoch: 6| Step: 5
Training loss: 0.42324626445770264
Validation loss: 2.250658611456553

Epoch: 6| Step: 6
Training loss: 0.9997947812080383
Validation loss: 2.2421948512395224

Epoch: 6| Step: 7
Training loss: 1.0963916778564453
Validation loss: 2.2736311554908752

Epoch: 6| Step: 8
Training loss: 0.8656132817268372
Validation loss: 2.224571148554484

Epoch: 6| Step: 9
Training loss: 0.833592414855957
Validation loss: 2.259282430013021

Epoch: 6| Step: 10
Training loss: 1.384342074394226
Validation loss: 2.2570677995681763

Epoch: 6| Step: 11
Training loss: 0.8339711427688599
Validation loss: 2.25042070945104

Epoch: 6| Step: 12
Training loss: 0.5385789275169373
Validation loss: 2.2705421646436057

Epoch: 6| Step: 13
Training loss: 1.5398705005645752
Validation loss: 2.2159748872121177

Epoch: 434| Step: 0
Training loss: 0.3590695261955261
Validation loss: 2.2456276416778564

Epoch: 6| Step: 1
Training loss: 0.7507671117782593
Validation loss: 2.2689863046010337

Epoch: 6| Step: 2
Training loss: 0.7042189836502075
Validation loss: 2.2183413902918496

Epoch: 6| Step: 3
Training loss: 1.002983808517456
Validation loss: 2.22940061489741

Epoch: 6| Step: 4
Training loss: 0.639397382736206
Validation loss: 2.2120441993077598

Epoch: 6| Step: 5
Training loss: 0.8632014393806458
Validation loss: 2.219200054804484

Epoch: 6| Step: 6
Training loss: 1.2064610719680786
Validation loss: 2.1507909099260965

Epoch: 6| Step: 7
Training loss: 1.3019301891326904
Validation loss: 2.1651730140050254

Epoch: 6| Step: 8
Training loss: 1.1363426446914673
Validation loss: 2.197327971458435

Epoch: 6| Step: 9
Training loss: 1.5460724830627441
Validation loss: 2.16918553908666

Epoch: 6| Step: 10
Training loss: 0.8328749537467957
Validation loss: 2.1836955547332764

Epoch: 6| Step: 11
Training loss: 0.7559171915054321
Validation loss: 2.169351021448771

Epoch: 6| Step: 12
Training loss: 0.7057511806488037
Validation loss: 2.2336708704630532

Epoch: 6| Step: 13
Training loss: 1.117701530456543
Validation loss: 2.2103673418362937

Epoch: 435| Step: 0
Training loss: 0.7113667726516724
Validation loss: 2.2188888986905417

Epoch: 6| Step: 1
Training loss: 0.7994002103805542
Validation loss: 2.1908300717671714

Epoch: 6| Step: 2
Training loss: 0.8584557771682739
Validation loss: 2.2666714986165366

Epoch: 6| Step: 3
Training loss: 1.3612838983535767
Validation loss: 2.2100902994473777

Epoch: 6| Step: 4
Training loss: 0.885593831539154
Validation loss: 2.2484858632087708

Epoch: 6| Step: 5
Training loss: 0.8011773824691772
Validation loss: 2.2716203133265176

Epoch: 6| Step: 6
Training loss: 0.6309841275215149
Validation loss: 2.2348104119300842

Epoch: 6| Step: 7
Training loss: 1.5503891706466675
Validation loss: 2.26670902967453

Epoch: 6| Step: 8
Training loss: 0.7210140228271484
Validation loss: 2.2464585502942405

Epoch: 6| Step: 9
Training loss: 1.0953550338745117
Validation loss: 2.2514577507972717

Epoch: 6| Step: 10
Training loss: 1.1206305027008057
Validation loss: 2.2250435749689736

Epoch: 6| Step: 11
Training loss: 1.1569857597351074
Validation loss: 2.214981993039449

Epoch: 6| Step: 12
Training loss: 0.507646381855011
Validation loss: 2.214099665482839

Epoch: 6| Step: 13
Training loss: 0.64992356300354
Validation loss: 2.2305078705151877

Epoch: 436| Step: 0
Training loss: 1.1273114681243896
Validation loss: 2.198688546816508

Epoch: 6| Step: 1
Training loss: 0.5224176645278931
Validation loss: 2.2103397448857627

Epoch: 6| Step: 2
Training loss: 0.7608771324157715
Validation loss: 2.2349937558174133

Epoch: 6| Step: 3
Training loss: 0.8062152862548828
Validation loss: 2.242539902528127

Epoch: 6| Step: 4
Training loss: 0.9047985672950745
Validation loss: 2.2158738573392234

Epoch: 6| Step: 5
Training loss: 0.6308608055114746
Validation loss: 2.235282758871714

Epoch: 6| Step: 6
Training loss: 1.1591367721557617
Validation loss: 2.254320661226908

Epoch: 6| Step: 7
Training loss: 0.9337384700775146
Validation loss: 2.2613991300264993

Epoch: 6| Step: 8
Training loss: 1.5463711023330688
Validation loss: 2.276243189970652

Epoch: 6| Step: 9
Training loss: 0.8686050176620483
Validation loss: 2.3176141579945884

Epoch: 6| Step: 10
Training loss: 1.2944886684417725
Validation loss: 2.271883189678192

Epoch: 6| Step: 11
Training loss: 0.38968342542648315
Validation loss: 2.2210854291915894

Epoch: 6| Step: 12
Training loss: 0.7122886180877686
Validation loss: 2.233765165011088

Epoch: 6| Step: 13
Training loss: 0.7465764284133911
Validation loss: 2.225371162096659

Epoch: 437| Step: 0
Training loss: 0.846247136592865
Validation loss: 2.205771525700887

Epoch: 6| Step: 1
Training loss: 1.0885688066482544
Validation loss: 2.2093421618143716

Epoch: 6| Step: 2
Training loss: 1.5130743980407715
Validation loss: 2.2073587576548257

Epoch: 6| Step: 3
Training loss: 0.6338610649108887
Validation loss: 2.2278793454170227

Epoch: 6| Step: 4
Training loss: 0.7870544791221619
Validation loss: 2.2299309174219766

Epoch: 6| Step: 5
Training loss: 0.4809735119342804
Validation loss: 2.2160023053487143

Epoch: 6| Step: 6
Training loss: 1.147997260093689
Validation loss: 2.219076693058014

Epoch: 6| Step: 7
Training loss: 0.5034322738647461
Validation loss: 2.2311081290245056

Epoch: 6| Step: 8
Training loss: 1.0413724184036255
Validation loss: 2.2759705781936646

Epoch: 6| Step: 9
Training loss: 0.5189875364303589
Validation loss: 2.2657116651535034

Epoch: 6| Step: 10
Training loss: 0.9159765839576721
Validation loss: 2.244518001874288

Epoch: 6| Step: 11
Training loss: 0.9555873274803162
Validation loss: 2.2196189165115356

Epoch: 6| Step: 12
Training loss: 1.2325869798660278
Validation loss: 2.215432127316793

Epoch: 6| Step: 13
Training loss: 0.8097600936889648
Validation loss: 2.231508950392405

Epoch: 438| Step: 0
Training loss: 0.6983927488327026
Validation loss: 2.1862862507502236

Epoch: 6| Step: 1
Training loss: 0.8069628477096558
Validation loss: 2.220881541570028

Epoch: 6| Step: 2
Training loss: 1.4760392904281616
Validation loss: 2.2154635389645896

Epoch: 6| Step: 3
Training loss: 0.9926602840423584
Validation loss: 2.240346670150757

Epoch: 6| Step: 4
Training loss: 1.1403844356536865
Validation loss: 2.262895087401072

Epoch: 6| Step: 5
Training loss: 0.8240374326705933
Validation loss: 2.223584771156311

Epoch: 6| Step: 6
Training loss: 0.7586065530776978
Validation loss: 2.3126333753267923

Epoch: 6| Step: 7
Training loss: 1.04038667678833
Validation loss: 2.303618391354879

Epoch: 6| Step: 8
Training loss: 1.0486862659454346
Validation loss: 2.270922362804413

Epoch: 6| Step: 9
Training loss: 0.5625375509262085
Validation loss: 2.2158671617507935

Epoch: 6| Step: 10
Training loss: 1.2476571798324585
Validation loss: 2.2420667608579

Epoch: 6| Step: 11
Training loss: 0.6331126689910889
Validation loss: 2.2471824487050376

Epoch: 6| Step: 12
Training loss: 0.6014333963394165
Validation loss: 2.3041628201802573

Epoch: 6| Step: 13
Training loss: 1.0408809185028076
Validation loss: 2.291103720664978

Epoch: 439| Step: 0
Training loss: 0.9694830179214478
Validation loss: 2.3008208672205606

Epoch: 6| Step: 1
Training loss: 0.5073509216308594
Validation loss: 2.291787346204122

Epoch: 6| Step: 2
Training loss: 0.6758641004562378
Validation loss: 2.293318450450897

Epoch: 6| Step: 3
Training loss: 1.3022464513778687
Validation loss: 2.327571074167887

Epoch: 6| Step: 4
Training loss: 1.0623350143432617
Validation loss: 2.3251854181289673

Epoch: 6| Step: 5
Training loss: 1.150510549545288
Validation loss: 2.2565101782480874

Epoch: 6| Step: 6
Training loss: 1.1085755825042725
Validation loss: 2.2613834937413535

Epoch: 6| Step: 7
Training loss: 1.4122977256774902
Validation loss: 2.2539361119270325

Epoch: 6| Step: 8
Training loss: 0.4635968804359436
Validation loss: 2.246137777964274

Epoch: 6| Step: 9
Training loss: 0.8105049133300781
Validation loss: 2.215408444404602

Epoch: 6| Step: 10
Training loss: 0.7128188610076904
Validation loss: 2.2080831130345664

Epoch: 6| Step: 11
Training loss: 0.6453617811203003
Validation loss: 2.2242045799891152

Epoch: 6| Step: 12
Training loss: 0.7656254768371582
Validation loss: 2.219094196955363

Epoch: 6| Step: 13
Training loss: 0.806999921798706
Validation loss: 2.246370017528534

Epoch: 440| Step: 0
Training loss: 0.8989236354827881
Validation loss: 2.235418200492859

Epoch: 6| Step: 1
Training loss: 0.5269869565963745
Validation loss: 2.2831804354985556

Epoch: 6| Step: 2
Training loss: 1.134505033493042
Validation loss: 2.246518055597941

Epoch: 6| Step: 3
Training loss: 1.0395088195800781
Validation loss: 2.2281519969304404

Epoch: 6| Step: 4
Training loss: 0.8649505376815796
Validation loss: 2.2513766288757324

Epoch: 6| Step: 5
Training loss: 0.814775288105011
Validation loss: 2.24036568403244

Epoch: 6| Step: 6
Training loss: 0.6821287870407104
Validation loss: 2.264419595400492

Epoch: 6| Step: 7
Training loss: 1.2553553581237793
Validation loss: 2.2291555802027383

Epoch: 6| Step: 8
Training loss: 1.0897419452667236
Validation loss: 2.216611623764038

Epoch: 6| Step: 9
Training loss: 0.8124474287033081
Validation loss: 2.212532381216685

Epoch: 6| Step: 10
Training loss: 0.5033721923828125
Validation loss: 2.227098306020101

Epoch: 6| Step: 11
Training loss: 0.8486504554748535
Validation loss: 2.2097601294517517

Epoch: 6| Step: 12
Training loss: 0.8328741788864136
Validation loss: 2.174337406953176

Epoch: 6| Step: 13
Training loss: 0.5197256803512573
Validation loss: 2.2300008734067283

Epoch: 441| Step: 0
Training loss: 0.9914613962173462
Validation loss: 2.2241026957829795

Epoch: 6| Step: 1
Training loss: 1.052358865737915
Validation loss: 2.2642624974250793

Epoch: 6| Step: 2
Training loss: 0.9175041317939758
Validation loss: 2.2179982463518777

Epoch: 6| Step: 3
Training loss: 0.54780113697052
Validation loss: 2.3109699885050454

Epoch: 6| Step: 4
Training loss: 1.6925816535949707
Validation loss: 2.32516219218572

Epoch: 6| Step: 5
Training loss: 0.823615312576294
Validation loss: 2.3205076456069946

Epoch: 6| Step: 6
Training loss: 0.6901843547821045
Validation loss: 2.313870390256246

Epoch: 6| Step: 7
Training loss: 0.7449386119842529
Validation loss: 2.325419028600057

Epoch: 6| Step: 8
Training loss: 1.127973198890686
Validation loss: 2.2677899599075317

Epoch: 6| Step: 9
Training loss: 1.0763871669769287
Validation loss: 2.267944355805715

Epoch: 6| Step: 10
Training loss: 0.7672649621963501
Validation loss: 2.227911571661631

Epoch: 6| Step: 11
Training loss: 0.8643864393234253
Validation loss: 2.2281171083450317

Epoch: 6| Step: 12
Training loss: 0.4899240732192993
Validation loss: 2.1903409163157144

Epoch: 6| Step: 13
Training loss: 0.7003101110458374
Validation loss: 2.189748843510946

Epoch: 442| Step: 0
Training loss: 0.5201148986816406
Validation loss: 2.183364907900492

Epoch: 6| Step: 1
Training loss: 0.7676544189453125
Validation loss: 2.183946371078491

Epoch: 6| Step: 2
Training loss: 0.9378197193145752
Validation loss: 2.2303820053736367

Epoch: 6| Step: 3
Training loss: 0.5957945585250854
Validation loss: 2.2919722398122153

Epoch: 6| Step: 4
Training loss: 0.6355105638504028
Validation loss: 2.267384966214498

Epoch: 6| Step: 5
Training loss: 0.8514207601547241
Validation loss: 2.2647938330968223

Epoch: 6| Step: 6
Training loss: 0.72246915102005
Validation loss: 2.252569774786631

Epoch: 6| Step: 7
Training loss: 1.2968124151229858
Validation loss: 2.2972458600997925

Epoch: 6| Step: 8
Training loss: 1.4577264785766602
Validation loss: 2.2767173250516257

Epoch: 6| Step: 9
Training loss: 0.9694328308105469
Validation loss: 2.2436962922414145

Epoch: 6| Step: 10
Training loss: 1.033181071281433
Validation loss: 2.2706161936124167

Epoch: 6| Step: 11
Training loss: 1.2142689228057861
Validation loss: 2.2216240564982095

Epoch: 6| Step: 12
Training loss: 0.5888034701347351
Validation loss: 2.248267650604248

Epoch: 6| Step: 13
Training loss: 0.7144193649291992
Validation loss: 2.2541704773902893

Epoch: 443| Step: 0
Training loss: 1.0259233713150024
Validation loss: 2.220422883828481

Epoch: 6| Step: 1
Training loss: 1.1645097732543945
Validation loss: 2.2316168347994485

Epoch: 6| Step: 2
Training loss: 1.1238255500793457
Validation loss: 2.226433595021566

Epoch: 6| Step: 3
Training loss: 0.7771589159965515
Validation loss: 2.2365832527478537

Epoch: 6| Step: 4
Training loss: 0.43819206953048706
Validation loss: 2.2390488386154175

Epoch: 6| Step: 5
Training loss: 0.9025887250900269
Validation loss: 2.2147889335950217

Epoch: 6| Step: 6
Training loss: 1.1041399240493774
Validation loss: 2.2052555481592813

Epoch: 6| Step: 7
Training loss: 0.9748092889785767
Validation loss: 2.2554377714792886

Epoch: 6| Step: 8
Training loss: 0.9918597936630249
Validation loss: 2.2069797913233438

Epoch: 6| Step: 9
Training loss: 1.0238014459609985
Validation loss: 2.2126159071922302

Epoch: 6| Step: 10
Training loss: 0.9529534578323364
Validation loss: 2.2228781978289285

Epoch: 6| Step: 11
Training loss: 0.7949776649475098
Validation loss: 2.2042846282323203

Epoch: 6| Step: 12
Training loss: 0.5477278232574463
Validation loss: 2.2697585821151733

Epoch: 6| Step: 13
Training loss: 0.5935955047607422
Validation loss: 2.2588548262914023

Epoch: 444| Step: 0
Training loss: 0.6986263394355774
Validation loss: 2.2723496158917746

Epoch: 6| Step: 1
Training loss: 1.1878842115402222
Validation loss: 2.2999285459518433

Epoch: 6| Step: 2
Training loss: 0.772099494934082
Validation loss: 2.3249455293019614

Epoch: 6| Step: 3
Training loss: 0.9622557163238525
Validation loss: 2.2788403630256653

Epoch: 6| Step: 4
Training loss: 0.8640809059143066
Validation loss: 2.277689258257548

Epoch: 6| Step: 5
Training loss: 0.48576217889785767
Validation loss: 2.240842084089915

Epoch: 6| Step: 6
Training loss: 0.8852577209472656
Validation loss: 2.252303739388784

Epoch: 6| Step: 7
Training loss: 0.9856122732162476
Validation loss: 2.216118355592092

Epoch: 6| Step: 8
Training loss: 0.8840464353561401
Validation loss: 2.2132970094680786

Epoch: 6| Step: 9
Training loss: 0.653486967086792
Validation loss: 2.2179752588272095

Epoch: 6| Step: 10
Training loss: 1.154345989227295
Validation loss: 2.1938237150510154

Epoch: 6| Step: 11
Training loss: 0.6962524652481079
Validation loss: 2.2178677717844644

Epoch: 6| Step: 12
Training loss: 0.9253172278404236
Validation loss: 2.2185745239257812

Epoch: 6| Step: 13
Training loss: 0.5452559590339661
Validation loss: 2.2274059851964316

Epoch: 445| Step: 0
Training loss: 0.9278091192245483
Validation loss: 2.2540398438771567

Epoch: 6| Step: 1
Training loss: 0.7508138418197632
Validation loss: 2.259849786758423

Epoch: 6| Step: 2
Training loss: 1.1005562543869019
Validation loss: 2.276766816775004

Epoch: 6| Step: 3
Training loss: 0.7910120487213135
Validation loss: 2.2406495809555054

Epoch: 6| Step: 4
Training loss: 0.7986276149749756
Validation loss: 2.272870500882467

Epoch: 6| Step: 5
Training loss: 1.306565761566162
Validation loss: 2.180147667725881

Epoch: 6| Step: 6
Training loss: 0.8494740128517151
Validation loss: 2.1790961623191833

Epoch: 6| Step: 7
Training loss: 0.8555581569671631
Validation loss: 2.2254075407981873

Epoch: 6| Step: 8
Training loss: 0.9393498301506042
Validation loss: 2.200990875562032

Epoch: 6| Step: 9
Training loss: 0.720937967300415
Validation loss: 2.2090625564257302

Epoch: 6| Step: 10
Training loss: 0.5985240340232849
Validation loss: 2.1853078802426658

Epoch: 6| Step: 11
Training loss: 0.7968151569366455
Validation loss: 2.201232075691223

Epoch: 6| Step: 12
Training loss: 1.2250615358352661
Validation loss: 2.234830319881439

Epoch: 6| Step: 13
Training loss: 1.208471655845642
Validation loss: 2.194139758745829

Epoch: 446| Step: 0
Training loss: 1.379279375076294
Validation loss: 2.209904909133911

Epoch: 6| Step: 1
Training loss: 0.579046368598938
Validation loss: 2.2274177273114524

Epoch: 6| Step: 2
Training loss: 1.2228964567184448
Validation loss: 2.173214395840963

Epoch: 6| Step: 3
Training loss: 0.7894898653030396
Validation loss: 2.19504177570343

Epoch: 6| Step: 4
Training loss: 0.8016457557678223
Validation loss: 2.1748826106389365

Epoch: 6| Step: 5
Training loss: 0.4745502471923828
Validation loss: 2.1647710601488748

Epoch: 6| Step: 6
Training loss: 0.9649522304534912
Validation loss: 2.155424257119497

Epoch: 6| Step: 7
Training loss: 0.6887298822402954
Validation loss: 2.1642690300941467

Epoch: 6| Step: 8
Training loss: 0.5658944845199585
Validation loss: 2.1982876459757485

Epoch: 6| Step: 9
Training loss: 1.4407551288604736
Validation loss: 2.2018166383107505

Epoch: 6| Step: 10
Training loss: 1.348012924194336
Validation loss: 2.2210105657577515

Epoch: 6| Step: 11
Training loss: 0.5550038814544678
Validation loss: 2.2115292151769004

Epoch: 6| Step: 12
Training loss: 0.929652214050293
Validation loss: 2.24705038468043

Epoch: 6| Step: 13
Training loss: 1.2788619995117188
Validation loss: 2.273167908191681

Epoch: 447| Step: 0
Training loss: 0.8940554857254028
Validation loss: 2.286668340365092

Epoch: 6| Step: 1
Training loss: 0.5977822542190552
Validation loss: 2.274501919746399

Epoch: 6| Step: 2
Training loss: 0.894044041633606
Validation loss: 2.307849645614624

Epoch: 6| Step: 3
Training loss: 0.8808419108390808
Validation loss: 2.3073212107022605

Epoch: 6| Step: 4
Training loss: 0.9183622002601624
Validation loss: 2.2526261806488037

Epoch: 6| Step: 5
Training loss: 0.5199041366577148
Validation loss: 2.243647734324137

Epoch: 6| Step: 6
Training loss: 0.992148756980896
Validation loss: 2.1820677320162454

Epoch: 6| Step: 7
Training loss: 0.9722760915756226
Validation loss: 2.205709457397461

Epoch: 6| Step: 8
Training loss: 1.0721435546875
Validation loss: 2.2094579537709556

Epoch: 6| Step: 9
Training loss: 0.8466572761535645
Validation loss: 2.1968332529067993

Epoch: 6| Step: 10
Training loss: 0.8935397863388062
Validation loss: 2.183765729268392

Epoch: 6| Step: 11
Training loss: 0.7776092290878296
Validation loss: 2.1737637321154275

Epoch: 6| Step: 12
Training loss: 1.6204450130462646
Validation loss: 2.151299079259237

Epoch: 6| Step: 13
Training loss: 0.980689287185669
Validation loss: 2.1918512185414634

Epoch: 448| Step: 0
Training loss: 0.7128489017486572
Validation loss: 2.1829609672228494

Epoch: 6| Step: 1
Training loss: 0.8660734295845032
Validation loss: 2.196824312210083

Epoch: 6| Step: 2
Training loss: 1.1090449094772339
Validation loss: 2.214446783065796

Epoch: 6| Step: 3
Training loss: 0.32951194047927856
Validation loss: 2.2193467219670615

Epoch: 6| Step: 4
Training loss: 1.170817255973816
Validation loss: 2.214237074057261

Epoch: 6| Step: 5
Training loss: 0.9744462370872498
Validation loss: 2.269401470820109

Epoch: 6| Step: 6
Training loss: 0.9053219556808472
Validation loss: 2.270004232724508

Epoch: 6| Step: 7
Training loss: 0.7228959798812866
Validation loss: 2.2831652959187827

Epoch: 6| Step: 8
Training loss: 0.48260706663131714
Validation loss: 2.2683565616607666

Epoch: 6| Step: 9
Training loss: 0.5979267358779907
Validation loss: 2.289242068926493

Epoch: 6| Step: 10
Training loss: 0.8979023694992065
Validation loss: 2.2973822156588235

Epoch: 6| Step: 11
Training loss: 0.9628828763961792
Validation loss: 2.2941489815711975

Epoch: 6| Step: 12
Training loss: 0.9550749659538269
Validation loss: 2.312162439028422

Epoch: 6| Step: 13
Training loss: 1.4726366996765137
Validation loss: 2.3022910356521606

Epoch: 449| Step: 0
Training loss: 1.1610991954803467
Validation loss: 2.3859575986862183

Epoch: 6| Step: 1
Training loss: 0.5974158048629761
Validation loss: 2.3493244647979736

Epoch: 6| Step: 2
Training loss: 0.5783703923225403
Validation loss: 2.3238351543744407

Epoch: 6| Step: 3
Training loss: 0.7619683742523193
Validation loss: 2.2852739691734314

Epoch: 6| Step: 4
Training loss: 1.063295602798462
Validation loss: 2.304132878780365

Epoch: 6| Step: 5
Training loss: 0.8336392641067505
Validation loss: 2.303980569044749

Epoch: 6| Step: 6
Training loss: 1.0394635200500488
Validation loss: 2.294851303100586

Epoch: 6| Step: 7
Training loss: 1.446874976158142
Validation loss: 2.2869551181793213

Epoch: 6| Step: 8
Training loss: 0.6396653056144714
Validation loss: 2.323306361834208

Epoch: 6| Step: 9
Training loss: 1.20412015914917
Validation loss: 2.2689895232518515

Epoch: 6| Step: 10
Training loss: 0.5277208685874939
Validation loss: 2.2653074661890664

Epoch: 6| Step: 11
Training loss: 0.6920247077941895
Validation loss: 2.2188082933425903

Epoch: 6| Step: 12
Training loss: 0.5370634198188782
Validation loss: 2.2320022185643515

Epoch: 6| Step: 13
Training loss: 0.6448146104812622
Validation loss: 2.26493106285731

Epoch: 450| Step: 0
Training loss: 1.249955654144287
Validation loss: 2.228852311770121

Epoch: 6| Step: 1
Training loss: 0.7658506631851196
Validation loss: 2.2554341157277427

Epoch: 6| Step: 2
Training loss: 1.4855880737304688
Validation loss: 2.297646641731262

Epoch: 6| Step: 3
Training loss: 1.226452350616455
Validation loss: 2.28325754404068

Epoch: 6| Step: 4
Training loss: 0.39212796092033386
Validation loss: 2.3262608448664346

Epoch: 6| Step: 5
Training loss: 0.4427729845046997
Validation loss: 2.3088865081469216

Epoch: 6| Step: 6
Training loss: 0.7744596004486084
Validation loss: 2.284313519795736

Epoch: 6| Step: 7
Training loss: 0.7111130952835083
Validation loss: 2.305988828341166

Epoch: 6| Step: 8
Training loss: 0.9105896949768066
Validation loss: 2.325232724348704

Epoch: 6| Step: 9
Training loss: 0.642809271812439
Validation loss: 2.267313857873281

Epoch: 6| Step: 10
Training loss: 0.9976571202278137
Validation loss: 2.275660236676534

Epoch: 6| Step: 11
Training loss: 0.6548749208450317
Validation loss: 2.2758753101030984

Epoch: 6| Step: 12
Training loss: 0.8566221594810486
Validation loss: 2.236969828605652

Epoch: 6| Step: 13
Training loss: 0.6504387855529785
Validation loss: 2.265474339326223

Epoch: 451| Step: 0
Training loss: 1.0149147510528564
Validation loss: 2.229675769805908

Epoch: 6| Step: 1
Training loss: 0.7634828090667725
Validation loss: 2.2387468814849854

Epoch: 6| Step: 2
Training loss: 0.6921485066413879
Validation loss: 2.256231149037679

Epoch: 6| Step: 3
Training loss: 0.4875488579273224
Validation loss: 2.2801812887191772

Epoch: 6| Step: 4
Training loss: 0.7112152576446533
Validation loss: 2.2782121698061624

Epoch: 6| Step: 5
Training loss: 0.47495949268341064
Validation loss: 2.2922844092051187

Epoch: 6| Step: 6
Training loss: 0.8868451714515686
Validation loss: 2.2614585955937705

Epoch: 6| Step: 7
Training loss: 0.9030543565750122
Validation loss: 2.286406914393107

Epoch: 6| Step: 8
Training loss: 0.8942471742630005
Validation loss: 2.2328996658325195

Epoch: 6| Step: 9
Training loss: 0.3930472135543823
Validation loss: 2.270223100980123

Epoch: 6| Step: 10
Training loss: 0.8108792901039124
Validation loss: 2.3102464079856873

Epoch: 6| Step: 11
Training loss: 0.7074002623558044
Validation loss: 2.2621880571047464

Epoch: 6| Step: 12
Training loss: 1.1343003511428833
Validation loss: 2.2243592739105225

Epoch: 6| Step: 13
Training loss: 1.5780906677246094
Validation loss: 2.253332773844401

Epoch: 452| Step: 0
Training loss: 0.5682761073112488
Validation loss: 2.290023982524872

Epoch: 6| Step: 1
Training loss: 1.253750205039978
Validation loss: 2.3299394448598227

Epoch: 6| Step: 2
Training loss: 1.1829886436462402
Validation loss: 2.31138281027476

Epoch: 6| Step: 3
Training loss: 0.5990973711013794
Validation loss: 2.321603218714396

Epoch: 6| Step: 4
Training loss: 0.6599773168563843
Validation loss: 2.329111615816752

Epoch: 6| Step: 5
Training loss: 1.1328173875808716
Validation loss: 2.3671154975891113

Epoch: 6| Step: 6
Training loss: 2.007658004760742
Validation loss: 2.3480242093404136

Epoch: 6| Step: 7
Training loss: 0.521764874458313
Validation loss: 2.272000273068746

Epoch: 6| Step: 8
Training loss: 0.7000145316123962
Validation loss: 2.3047144015630088

Epoch: 6| Step: 9
Training loss: 0.5988826751708984
Validation loss: 2.2925352851549783

Epoch: 6| Step: 10
Training loss: 0.5435971021652222
Validation loss: 2.2789672215779624

Epoch: 6| Step: 11
Training loss: 0.5392950177192688
Validation loss: 2.278815984725952

Epoch: 6| Step: 12
Training loss: 0.6383020877838135
Validation loss: 2.2636908292770386

Epoch: 6| Step: 13
Training loss: 0.7898904085159302
Validation loss: 2.2753921945889792

Epoch: 453| Step: 0
Training loss: 1.3337657451629639
Validation loss: 2.2312289476394653

Epoch: 6| Step: 1
Training loss: 0.5271326303482056
Validation loss: 2.231981118520101

Epoch: 6| Step: 2
Training loss: 0.7604835033416748
Validation loss: 2.224560499191284

Epoch: 6| Step: 3
Training loss: 0.8520050644874573
Validation loss: 2.262701670328776

Epoch: 6| Step: 4
Training loss: 0.851759672164917
Validation loss: 2.220157285531362

Epoch: 6| Step: 5
Training loss: 1.1967675685882568
Validation loss: 2.2677234212557473

Epoch: 6| Step: 6
Training loss: 0.6864318251609802
Validation loss: 2.2766179045041404

Epoch: 6| Step: 7
Training loss: 0.684546709060669
Validation loss: 2.2620054483413696

Epoch: 6| Step: 8
Training loss: 1.24552321434021
Validation loss: 2.2809070150057473

Epoch: 6| Step: 9
Training loss: 0.9857177734375
Validation loss: 2.248718738555908

Epoch: 6| Step: 10
Training loss: 1.06982421875
Validation loss: 2.2685436010360718

Epoch: 6| Step: 11
Training loss: 0.7766350507736206
Validation loss: 2.274167776107788

Epoch: 6| Step: 12
Training loss: 0.307378888130188
Validation loss: 2.2552274465560913

Epoch: 6| Step: 13
Training loss: 0.7651841640472412
Validation loss: 2.2489776611328125

Epoch: 454| Step: 0
Training loss: 0.8774129152297974
Validation loss: 2.2741993268330893

Epoch: 6| Step: 1
Training loss: 1.0659406185150146
Validation loss: 2.266756236553192

Epoch: 6| Step: 2
Training loss: 1.4512286186218262
Validation loss: 2.2948808868726096

Epoch: 6| Step: 3
Training loss: 0.6231387853622437
Validation loss: 2.25594695409139

Epoch: 6| Step: 4
Training loss: 0.7510178089141846
Validation loss: 2.279083708922068

Epoch: 6| Step: 5
Training loss: 0.5510409474372864
Validation loss: 2.273155450820923

Epoch: 6| Step: 6
Training loss: 0.8426285982131958
Validation loss: 2.2725127935409546

Epoch: 6| Step: 7
Training loss: 0.47140929102897644
Validation loss: 2.2461961110432944

Epoch: 6| Step: 8
Training loss: 0.6850217580795288
Validation loss: 2.2811203797658286

Epoch: 6| Step: 9
Training loss: 0.47397708892822266
Validation loss: 2.252748688062032

Epoch: 6| Step: 10
Training loss: 0.7097742557525635
Validation loss: 2.2660520871480307

Epoch: 6| Step: 11
Training loss: 0.8954275846481323
Validation loss: 2.2035396099090576

Epoch: 6| Step: 12
Training loss: 1.081923007965088
Validation loss: 2.2447022596995034

Epoch: 6| Step: 13
Training loss: 0.6824039220809937
Validation loss: 2.206932862599691

Epoch: 455| Step: 0
Training loss: 0.7878063917160034
Validation loss: 2.239264190196991

Epoch: 6| Step: 1
Training loss: 1.2291854619979858
Validation loss: 2.264178196589152

Epoch: 6| Step: 2
Training loss: 0.8948360085487366
Validation loss: 2.293077011903127

Epoch: 6| Step: 3
Training loss: 0.758635401725769
Validation loss: 2.2567902406056723

Epoch: 6| Step: 4
Training loss: 0.5955115556716919
Validation loss: 2.2650304238001504

Epoch: 6| Step: 5
Training loss: 0.7281206846237183
Validation loss: 2.2984054485956826

Epoch: 6| Step: 6
Training loss: 1.2450703382492065
Validation loss: 2.268038888772329

Epoch: 6| Step: 7
Training loss: 1.0394113063812256
Validation loss: 2.3176404436429343

Epoch: 6| Step: 8
Training loss: 0.47094741463661194
Validation loss: 2.3077067534128823

Epoch: 6| Step: 9
Training loss: 0.5781781673431396
Validation loss: 2.3188023567199707

Epoch: 6| Step: 10
Training loss: 1.270007848739624
Validation loss: 2.3182344834009805

Epoch: 6| Step: 11
Training loss: 1.0816380977630615
Validation loss: 2.3392082254091897

Epoch: 6| Step: 12
Training loss: 0.6793646216392517
Validation loss: 2.3092522819836936

Epoch: 6| Step: 13
Training loss: 0.6277375221252441
Validation loss: 2.250618835290273

Epoch: 456| Step: 0
Training loss: 1.0391786098480225
Validation loss: 2.2756523489952087

Epoch: 6| Step: 1
Training loss: 0.6269547939300537
Validation loss: 2.2619773745536804

Epoch: 6| Step: 2
Training loss: 1.237809419631958
Validation loss: 2.250283737977346

Epoch: 6| Step: 3
Training loss: 1.0689988136291504
Validation loss: 2.268108864625295

Epoch: 6| Step: 4
Training loss: 0.5683643817901611
Validation loss: 2.2697152495384216

Epoch: 6| Step: 5
Training loss: 0.9860875606536865
Validation loss: 2.207345724105835

Epoch: 6| Step: 6
Training loss: 0.6040759086608887
Validation loss: 2.258884310722351

Epoch: 6| Step: 7
Training loss: 0.662742555141449
Validation loss: 2.2743879556655884

Epoch: 6| Step: 8
Training loss: 0.8107525706291199
Validation loss: 2.2981654008229575

Epoch: 6| Step: 9
Training loss: 0.639178991317749
Validation loss: 2.3327481349309287

Epoch: 6| Step: 10
Training loss: 1.2063469886779785
Validation loss: 2.3278048038482666

Epoch: 6| Step: 11
Training loss: 0.5081560015678406
Validation loss: 2.3223848740259805

Epoch: 6| Step: 12
Training loss: 0.8039919137954712
Validation loss: 2.2838489413261414

Epoch: 6| Step: 13
Training loss: 1.179140329360962
Validation loss: 2.2827165524164834

Epoch: 457| Step: 0
Training loss: 0.40700894594192505
Validation loss: 2.25822643438975

Epoch: 6| Step: 1
Training loss: 0.9251987934112549
Validation loss: 2.283639073371887

Epoch: 6| Step: 2
Training loss: 0.8782885670661926
Validation loss: 2.2399301330248513

Epoch: 6| Step: 3
Training loss: 1.2606205940246582
Validation loss: 2.287850578625997

Epoch: 6| Step: 4
Training loss: 0.8684636354446411
Validation loss: 2.289120674133301

Epoch: 6| Step: 5
Training loss: 1.299400806427002
Validation loss: 2.249448577562968

Epoch: 6| Step: 6
Training loss: 0.4600653052330017
Validation loss: 2.265403389930725

Epoch: 6| Step: 7
Training loss: 1.205512523651123
Validation loss: 2.230144957701365

Epoch: 6| Step: 8
Training loss: 1.102199912071228
Validation loss: 2.2189561327298484

Epoch: 6| Step: 9
Training loss: 0.5833009481430054
Validation loss: 2.256033738454183

Epoch: 6| Step: 10
Training loss: 0.6224237680435181
Validation loss: 2.2433324654897056

Epoch: 6| Step: 11
Training loss: 0.5742934942245483
Validation loss: 2.2856909036636353

Epoch: 6| Step: 12
Training loss: 1.0815837383270264
Validation loss: 2.271123468875885

Epoch: 6| Step: 13
Training loss: 0.3391270637512207
Validation loss: 2.2989521821339927

Epoch: 458| Step: 0
Training loss: 0.6104528903961182
Validation loss: 2.2642418146133423

Epoch: 6| Step: 1
Training loss: 0.6055445671081543
Validation loss: 2.261669397354126

Epoch: 6| Step: 2
Training loss: 0.43548423051834106
Validation loss: 2.288768788178762

Epoch: 6| Step: 3
Training loss: 0.4999617338180542
Validation loss: 2.244198520978292

Epoch: 6| Step: 4
Training loss: 0.9690574407577515
Validation loss: 2.267720103263855

Epoch: 6| Step: 5
Training loss: 0.941730260848999
Validation loss: 2.2818145950635276

Epoch: 6| Step: 6
Training loss: 1.1122474670410156
Validation loss: 2.261882265408834

Epoch: 6| Step: 7
Training loss: 0.6222240924835205
Validation loss: 2.3038554787635803

Epoch: 6| Step: 8
Training loss: 0.44402816891670227
Validation loss: 2.314551532268524

Epoch: 6| Step: 9
Training loss: 0.6104930639266968
Validation loss: 2.303592244784037

Epoch: 6| Step: 10
Training loss: 0.6051243543624878
Validation loss: 2.273548106352488

Epoch: 6| Step: 11
Training loss: 1.6021497249603271
Validation loss: 2.269307255744934

Epoch: 6| Step: 12
Training loss: 0.5887105464935303
Validation loss: 2.3065328001976013

Epoch: 6| Step: 13
Training loss: 1.3590137958526611
Validation loss: 2.2589244445165

Epoch: 459| Step: 0
Training loss: 0.9726032614707947
Validation loss: 2.2263296445210776

Epoch: 6| Step: 1
Training loss: 0.7357402443885803
Validation loss: 2.2205066283543906

Epoch: 6| Step: 2
Training loss: 0.6034311056137085
Validation loss: 2.223223646481832

Epoch: 6| Step: 3
Training loss: 0.890254557132721
Validation loss: 2.228688577810923

Epoch: 6| Step: 4
Training loss: 0.6981606483459473
Validation loss: 2.1879871487617493

Epoch: 6| Step: 5
Training loss: 0.6062990427017212
Validation loss: 2.200953722000122

Epoch: 6| Step: 6
Training loss: 0.44070813059806824
Validation loss: 2.1995529532432556

Epoch: 6| Step: 7
Training loss: 0.695418655872345
Validation loss: 2.2407501339912415

Epoch: 6| Step: 8
Training loss: 0.7760820388793945
Validation loss: 2.245917797088623

Epoch: 6| Step: 9
Training loss: 1.149258017539978
Validation loss: 2.2534499565760293

Epoch: 6| Step: 10
Training loss: 0.7893861532211304
Validation loss: 2.312081813812256

Epoch: 6| Step: 11
Training loss: 0.5091983079910278
Validation loss: 2.278087099393209

Epoch: 6| Step: 12
Training loss: 1.0762901306152344
Validation loss: 2.286851247151693

Epoch: 6| Step: 13
Training loss: 1.1772321462631226
Validation loss: 2.2827882170677185

Epoch: 460| Step: 0
Training loss: 1.0344829559326172
Validation loss: 2.260599692662557

Epoch: 6| Step: 1
Training loss: 0.965546727180481
Validation loss: 2.2230952779452005

Epoch: 6| Step: 2
Training loss: 0.48775577545166016
Validation loss: 2.244879146416982

Epoch: 6| Step: 3
Training loss: 0.6092522740364075
Validation loss: 2.2161009510358176

Epoch: 6| Step: 4
Training loss: 0.5302529335021973
Validation loss: 2.237521012624105

Epoch: 6| Step: 5
Training loss: 0.899918794631958
Validation loss: 2.274276375770569

Epoch: 6| Step: 6
Training loss: 1.0158743858337402
Validation loss: 2.2724234660466514

Epoch: 6| Step: 7
Training loss: 0.8157556056976318
Validation loss: 2.2409894267717996

Epoch: 6| Step: 8
Training loss: 1.151931881904602
Validation loss: 2.291828234990438

Epoch: 6| Step: 9
Training loss: 0.5817300081253052
Validation loss: 2.3257084290186563

Epoch: 6| Step: 10
Training loss: 1.1539504528045654
Validation loss: 2.316956043243408

Epoch: 6| Step: 11
Training loss: 0.5197741985321045
Validation loss: 2.2967331210772195

Epoch: 6| Step: 12
Training loss: 0.6987755298614502
Validation loss: 2.2877633968989053

Epoch: 6| Step: 13
Training loss: 0.354263037443161
Validation loss: 2.240850806236267

Epoch: 461| Step: 0
Training loss: 0.47565507888793945
Validation loss: 2.3068297306696572

Epoch: 6| Step: 1
Training loss: 0.7630383968353271
Validation loss: 2.2687761584917703

Epoch: 6| Step: 2
Training loss: 0.5251662731170654
Validation loss: 2.2836087743441262

Epoch: 6| Step: 3
Training loss: 0.5263175368309021
Validation loss: 2.2720897992451987

Epoch: 6| Step: 4
Training loss: 0.8262670040130615
Validation loss: 2.2757817109425864

Epoch: 6| Step: 5
Training loss: 1.23027765750885
Validation loss: 2.2709754705429077

Epoch: 6| Step: 6
Training loss: 1.508758306503296
Validation loss: 2.2985215981801352

Epoch: 6| Step: 7
Training loss: 0.5991572141647339
Validation loss: 2.2884759108225503

Epoch: 6| Step: 8
Training loss: 1.1268467903137207
Validation loss: 2.3163357973098755

Epoch: 6| Step: 9
Training loss: 1.0831013917922974
Validation loss: 2.298831582069397

Epoch: 6| Step: 10
Training loss: 0.6983984708786011
Validation loss: 2.3486279249191284

Epoch: 6| Step: 11
Training loss: 1.0572311878204346
Validation loss: 2.302689810593923

Epoch: 6| Step: 12
Training loss: 0.5274338126182556
Validation loss: 2.31766140460968

Epoch: 6| Step: 13
Training loss: 0.9086887836456299
Validation loss: 2.291426658630371

Epoch: 462| Step: 0
Training loss: 0.5341360569000244
Validation loss: 2.252927382787069

Epoch: 6| Step: 1
Training loss: 0.6583460569381714
Validation loss: 2.2091676791508994

Epoch: 6| Step: 2
Training loss: 0.5328052043914795
Validation loss: 2.214956005414327

Epoch: 6| Step: 3
Training loss: 0.8803204894065857
Validation loss: 2.1786362528800964

Epoch: 6| Step: 4
Training loss: 0.9308962821960449
Validation loss: 2.21886279185613

Epoch: 6| Step: 5
Training loss: 0.6311562061309814
Validation loss: 2.218940476576487

Epoch: 6| Step: 6
Training loss: 1.2704392671585083
Validation loss: 2.189647595087687

Epoch: 6| Step: 7
Training loss: 0.6709177494049072
Validation loss: 2.2064496278762817

Epoch: 6| Step: 8
Training loss: 0.7177747488021851
Validation loss: 2.21377424399058

Epoch: 6| Step: 9
Training loss: 0.5237133502960205
Validation loss: 2.214471220970154

Epoch: 6| Step: 10
Training loss: 1.3391666412353516
Validation loss: 2.2168099085489907

Epoch: 6| Step: 11
Training loss: 0.4845115840435028
Validation loss: 2.2329044143358865

Epoch: 6| Step: 12
Training loss: 1.367613434791565
Validation loss: 2.254152476787567

Epoch: 6| Step: 13
Training loss: 0.7288362383842468
Validation loss: 2.256738026936849

Epoch: 463| Step: 0
Training loss: 1.072465181350708
Validation loss: 2.2741279204686484

Epoch: 6| Step: 1
Training loss: 1.4326083660125732
Validation loss: 2.2560984094937644

Epoch: 6| Step: 2
Training loss: 0.8239741325378418
Validation loss: 2.2366470098495483

Epoch: 6| Step: 3
Training loss: 1.0702674388885498
Validation loss: 2.255805412928263

Epoch: 6| Step: 4
Training loss: 0.8452590703964233
Validation loss: 2.249987522761027

Epoch: 6| Step: 5
Training loss: 0.4687938392162323
Validation loss: 2.2600567738215127

Epoch: 6| Step: 6
Training loss: 0.4327790439128876
Validation loss: 2.2568586468696594

Epoch: 6| Step: 7
Training loss: 1.032748818397522
Validation loss: 2.284215748310089

Epoch: 6| Step: 8
Training loss: 0.5386472940444946
Validation loss: 2.264799336592356

Epoch: 6| Step: 9
Training loss: 0.3980989158153534
Validation loss: 2.244453012943268

Epoch: 6| Step: 10
Training loss: 0.5887593030929565
Validation loss: 2.2292906045913696

Epoch: 6| Step: 11
Training loss: 0.946086049079895
Validation loss: 2.281374176343282

Epoch: 6| Step: 12
Training loss: 0.6053749322891235
Validation loss: 2.2709009448687234

Epoch: 6| Step: 13
Training loss: 0.5588407516479492
Validation loss: 2.2265509764353433

Epoch: 464| Step: 0
Training loss: 0.9862821698188782
Validation loss: 2.2542466123898826

Epoch: 6| Step: 1
Training loss: 0.5724968910217285
Validation loss: 2.24697478612264

Epoch: 6| Step: 2
Training loss: 0.6931357383728027
Validation loss: 2.2536323070526123

Epoch: 6| Step: 3
Training loss: 0.4506441354751587
Validation loss: 2.2930339574813843

Epoch: 6| Step: 4
Training loss: 0.5459582805633545
Validation loss: 2.272863209247589

Epoch: 6| Step: 5
Training loss: 1.3183119297027588
Validation loss: 2.2573261658350625

Epoch: 6| Step: 6
Training loss: 1.537404179573059
Validation loss: 2.232278605302175

Epoch: 6| Step: 7
Training loss: 0.6717440485954285
Validation loss: 2.247284491856893

Epoch: 6| Step: 8
Training loss: 0.783186674118042
Validation loss: 2.2474748492240906

Epoch: 6| Step: 9
Training loss: 0.7020237445831299
Validation loss: 2.2326984802881875

Epoch: 6| Step: 10
Training loss: 0.3969595432281494
Validation loss: 2.2895913124084473

Epoch: 6| Step: 11
Training loss: 0.9974780678749084
Validation loss: 2.2606515685717263

Epoch: 6| Step: 12
Training loss: 0.6947952508926392
Validation loss: 2.2471253275871277

Epoch: 6| Step: 13
Training loss: 0.5371803045272827
Validation loss: 2.2341950138409934

Epoch: 465| Step: 0
Training loss: 0.756411612033844
Validation loss: 2.276105582714081

Epoch: 6| Step: 1
Training loss: 1.1050714254379272
Validation loss: 2.2384532690048218

Epoch: 6| Step: 2
Training loss: 0.7344969511032104
Validation loss: 2.301062305768331

Epoch: 6| Step: 3
Training loss: 1.0071306228637695
Validation loss: 2.185911854108175

Epoch: 6| Step: 4
Training loss: 0.5349276661872864
Validation loss: 2.2442624966303506

Epoch: 6| Step: 5
Training loss: 0.34596362709999084
Validation loss: 2.234697182973226

Epoch: 6| Step: 6
Training loss: 0.7037137746810913
Validation loss: 2.2383945981661477

Epoch: 6| Step: 7
Training loss: 0.43197017908096313
Validation loss: 2.229042371114095

Epoch: 6| Step: 8
Training loss: 0.6768510341644287
Validation loss: 2.274491548538208

Epoch: 6| Step: 9
Training loss: 0.8587948083877563
Validation loss: 2.277389705181122

Epoch: 6| Step: 10
Training loss: 1.6745574474334717
Validation loss: 2.3284455935160318

Epoch: 6| Step: 11
Training loss: 1.2746907472610474
Validation loss: 2.296016971270243

Epoch: 6| Step: 12
Training loss: 0.611177384853363
Validation loss: 2.2951385974884033

Epoch: 6| Step: 13
Training loss: 0.5997931361198425
Validation loss: 2.34569517771403

Epoch: 466| Step: 0
Training loss: 0.5529487133026123
Validation loss: 2.3183563152949014

Epoch: 6| Step: 1
Training loss: 0.38774341344833374
Validation loss: 2.279456595579783

Epoch: 6| Step: 2
Training loss: 0.8693881034851074
Validation loss: 2.290510416030884

Epoch: 6| Step: 3
Training loss: 0.48998379707336426
Validation loss: 2.249414642651876

Epoch: 6| Step: 4
Training loss: 0.7038595676422119
Validation loss: 2.2525859276453652

Epoch: 6| Step: 5
Training loss: 0.5084844827651978
Validation loss: 2.235460420449575

Epoch: 6| Step: 6
Training loss: 1.1602556705474854
Validation loss: 2.226700802644094

Epoch: 6| Step: 7
Training loss: 0.5041179656982422
Validation loss: 2.209975242614746

Epoch: 6| Step: 8
Training loss: 0.873058557510376
Validation loss: 2.2112852334976196

Epoch: 6| Step: 9
Training loss: 0.7843683958053589
Validation loss: 2.223173975944519

Epoch: 6| Step: 10
Training loss: 0.5705441236495972
Validation loss: 2.2083320021629333

Epoch: 6| Step: 11
Training loss: 0.48967698216438293
Validation loss: 2.2428147395451865

Epoch: 6| Step: 12
Training loss: 0.8060890436172485
Validation loss: 2.2036452690760293

Epoch: 6| Step: 13
Training loss: 2.1392035484313965
Validation loss: 2.239312390486399

Epoch: 467| Step: 0
Training loss: 0.518142819404602
Validation loss: 2.228008488814036

Epoch: 6| Step: 1
Training loss: 0.9343888163566589
Validation loss: 2.2569457292556763

Epoch: 6| Step: 2
Training loss: 0.8019150495529175
Validation loss: 2.264324347178141

Epoch: 6| Step: 3
Training loss: 0.6256752610206604
Validation loss: 2.225065549214681

Epoch: 6| Step: 4
Training loss: 0.9865908026695251
Validation loss: 2.2316870292027793

Epoch: 6| Step: 5
Training loss: 0.7853730916976929
Validation loss: 2.2650179664293923

Epoch: 6| Step: 6
Training loss: 0.3293190598487854
Validation loss: 2.2336897452672324

Epoch: 6| Step: 7
Training loss: 1.4116944074630737
Validation loss: 2.250858465830485

Epoch: 6| Step: 8
Training loss: 0.8152853846549988
Validation loss: 2.248314360777537

Epoch: 6| Step: 9
Training loss: 0.7923238277435303
Validation loss: 2.2730958064397178

Epoch: 6| Step: 10
Training loss: 0.5051945447921753
Validation loss: 2.273358325163523

Epoch: 6| Step: 11
Training loss: 0.7446783781051636
Validation loss: 2.2387359142303467

Epoch: 6| Step: 12
Training loss: 0.777357280254364
Validation loss: 2.221634805202484

Epoch: 6| Step: 13
Training loss: 0.4931098222732544
Validation loss: 2.2312874794006348

Epoch: 468| Step: 0
Training loss: 0.3205159306526184
Validation loss: 2.2505478064219155

Epoch: 6| Step: 1
Training loss: 1.1992311477661133
Validation loss: 2.2828362186749778

Epoch: 6| Step: 2
Training loss: 0.9124490022659302
Validation loss: 2.2753184835116067

Epoch: 6| Step: 3
Training loss: 0.6227434277534485
Validation loss: 2.287451605002085

Epoch: 6| Step: 4
Training loss: 1.0713932514190674
Validation loss: 2.2596245606740317

Epoch: 6| Step: 5
Training loss: 0.8291975855827332
Validation loss: 2.3075638016064963

Epoch: 6| Step: 6
Training loss: 0.9778319597244263
Validation loss: 2.2659273942311606

Epoch: 6| Step: 7
Training loss: 0.9583793878555298
Validation loss: 2.2449520428975425

Epoch: 6| Step: 8
Training loss: 0.8503520488739014
Validation loss: 2.270455777645111

Epoch: 6| Step: 9
Training loss: 0.38991019129753113
Validation loss: 2.2381268739700317

Epoch: 6| Step: 10
Training loss: 0.6230869293212891
Validation loss: 2.233531415462494

Epoch: 6| Step: 11
Training loss: 1.0482357740402222
Validation loss: 2.259190022945404

Epoch: 6| Step: 12
Training loss: 0.8798020482063293
Validation loss: 2.267526706059774

Epoch: 6| Step: 13
Training loss: 0.508514940738678
Validation loss: 2.2782408197720847

Epoch: 469| Step: 0
Training loss: 0.6620939373970032
Validation loss: 2.2477075258890786

Epoch: 6| Step: 1
Training loss: 0.42666396498680115
Validation loss: 2.2831615606943765

Epoch: 6| Step: 2
Training loss: 0.477012574672699
Validation loss: 2.27379834651947

Epoch: 6| Step: 3
Training loss: 0.4840388596057892
Validation loss: 2.302756110827128

Epoch: 6| Step: 4
Training loss: 0.8269931077957153
Validation loss: 2.351083517074585

Epoch: 6| Step: 5
Training loss: 1.1863856315612793
Validation loss: 2.302684168020884

Epoch: 6| Step: 6
Training loss: 0.9414647817611694
Validation loss: 2.375068247318268

Epoch: 6| Step: 7
Training loss: 0.6033689975738525
Validation loss: 2.3170669873555503

Epoch: 6| Step: 8
Training loss: 0.7212835550308228
Validation loss: 2.281842589378357

Epoch: 6| Step: 9
Training loss: 0.7988725304603577
Validation loss: 2.298249046007792

Epoch: 6| Step: 10
Training loss: 1.129800796508789
Validation loss: 2.2938870787620544

Epoch: 6| Step: 11
Training loss: 0.7104299068450928
Validation loss: 2.2215797901153564

Epoch: 6| Step: 12
Training loss: 0.924842357635498
Validation loss: 2.253035604953766

Epoch: 6| Step: 13
Training loss: 0.8466644883155823
Validation loss: 2.3066529432932534

Epoch: 470| Step: 0
Training loss: 0.4182155728340149
Validation loss: 2.2881404956181846

Epoch: 6| Step: 1
Training loss: 0.7012624740600586
Validation loss: 2.302308519681295

Epoch: 6| Step: 2
Training loss: 1.0390527248382568
Validation loss: 2.2468767364819846

Epoch: 6| Step: 3
Training loss: 0.8439615964889526
Validation loss: 2.265187939008077

Epoch: 6| Step: 4
Training loss: 0.8697409629821777
Validation loss: 2.284566660722097

Epoch: 6| Step: 5
Training loss: 0.4764430820941925
Validation loss: 2.23156076669693

Epoch: 6| Step: 6
Training loss: 0.6871604919433594
Validation loss: 2.2582348783810935

Epoch: 6| Step: 7
Training loss: 0.9561780691146851
Validation loss: 2.2295230627059937

Epoch: 6| Step: 8
Training loss: 0.8497617244720459
Validation loss: 2.2401573856671653

Epoch: 6| Step: 9
Training loss: 0.46329617500305176
Validation loss: 2.2496808767318726

Epoch: 6| Step: 10
Training loss: 1.534073829650879
Validation loss: 2.224264681339264

Epoch: 6| Step: 11
Training loss: 0.5962808728218079
Validation loss: 2.2681446274121604

Epoch: 6| Step: 12
Training loss: 0.33672916889190674
Validation loss: 2.267500082651774

Epoch: 6| Step: 13
Training loss: 0.38934656977653503
Validation loss: 2.3022934993108115

Epoch: 471| Step: 0
Training loss: 0.8244713544845581
Validation loss: 2.2823274731636047

Epoch: 6| Step: 1
Training loss: 1.1456230878829956
Validation loss: 2.286129812399546

Epoch: 6| Step: 2
Training loss: 0.7732374668121338
Validation loss: 2.329950968424479

Epoch: 6| Step: 3
Training loss: 0.7087297439575195
Validation loss: 2.3398945132891336

Epoch: 6| Step: 4
Training loss: 0.7690130472183228
Validation loss: 2.29492715994517

Epoch: 6| Step: 5
Training loss: 0.6759380102157593
Validation loss: 2.3075098196665444

Epoch: 6| Step: 6
Training loss: 0.33797508478164673
Validation loss: 2.2588090101877847

Epoch: 6| Step: 7
Training loss: 0.6650532484054565
Validation loss: 2.2405441204706826

Epoch: 6| Step: 8
Training loss: 0.43455028533935547
Validation loss: 2.2781327764193215

Epoch: 6| Step: 9
Training loss: 0.744152843952179
Validation loss: 2.2830119132995605

Epoch: 6| Step: 10
Training loss: 1.0284254550933838
Validation loss: 2.2960656881332397

Epoch: 6| Step: 11
Training loss: 0.3209337294101715
Validation loss: 2.297631581624349

Epoch: 6| Step: 12
Training loss: 0.8867883682250977
Validation loss: 2.2575888633728027

Epoch: 6| Step: 13
Training loss: 1.0843160152435303
Validation loss: 2.296119471391042

Epoch: 472| Step: 0
Training loss: 0.8105679750442505
Validation loss: 2.263572076956431

Epoch: 6| Step: 1
Training loss: 0.8211638331413269
Validation loss: 2.2728022734324136

Epoch: 6| Step: 2
Training loss: 0.6677951812744141
Validation loss: 2.2472561399141946

Epoch: 6| Step: 3
Training loss: 0.3739345073699951
Validation loss: 2.2468242247899375

Epoch: 6| Step: 4
Training loss: 0.6046274900436401
Validation loss: 2.2524418433507285

Epoch: 6| Step: 5
Training loss: 0.5080721378326416
Validation loss: 2.2473758260409036

Epoch: 6| Step: 6
Training loss: 0.5365101099014282
Validation loss: 2.257410208384196

Epoch: 6| Step: 7
Training loss: 1.0902189016342163
Validation loss: 2.2346683740615845

Epoch: 6| Step: 8
Training loss: 1.6015679836273193
Validation loss: 2.235994875431061

Epoch: 6| Step: 9
Training loss: 1.0423318147659302
Validation loss: 2.2350624998410544

Epoch: 6| Step: 10
Training loss: 0.7578232288360596
Validation loss: 2.206072668234507

Epoch: 6| Step: 11
Training loss: 0.5959665775299072
Validation loss: 2.2389034827550254

Epoch: 6| Step: 12
Training loss: 0.3536967635154724
Validation loss: 2.250307818253835

Epoch: 6| Step: 13
Training loss: 0.45467260479927063
Validation loss: 2.2851640383402505

Epoch: 473| Step: 0
Training loss: 0.5323126316070557
Validation loss: 2.2722513477007547

Epoch: 6| Step: 1
Training loss: 0.7379846572875977
Validation loss: 2.2467345794041953

Epoch: 6| Step: 2
Training loss: 0.8081542253494263
Validation loss: 2.28055469195048

Epoch: 6| Step: 3
Training loss: 0.6317049264907837
Validation loss: 2.2416882117589316

Epoch: 6| Step: 4
Training loss: 0.5369672775268555
Validation loss: 2.2482585310935974

Epoch: 6| Step: 5
Training loss: 0.9903964996337891
Validation loss: 2.2960526943206787

Epoch: 6| Step: 6
Training loss: 0.8878024220466614
Validation loss: 2.255079170068105

Epoch: 6| Step: 7
Training loss: 0.6872488260269165
Validation loss: 2.280204196770986

Epoch: 6| Step: 8
Training loss: 0.8215181231498718
Validation loss: 2.281344493230184

Epoch: 6| Step: 9
Training loss: 1.3312411308288574
Validation loss: 2.28914475440979

Epoch: 6| Step: 10
Training loss: 0.5185543298721313
Validation loss: 2.302270770072937

Epoch: 6| Step: 11
Training loss: 0.9031797647476196
Validation loss: 2.325301686922709

Epoch: 6| Step: 12
Training loss: 0.5700070261955261
Validation loss: 2.335642178853353

Epoch: 6| Step: 13
Training loss: 0.6289840936660767
Validation loss: 2.3241544167200723

Epoch: 474| Step: 0
Training loss: 0.5762204527854919
Validation loss: 2.3021836280822754

Epoch: 6| Step: 1
Training loss: 0.7818400859832764
Validation loss: 2.2375908891359964

Epoch: 6| Step: 2
Training loss: 0.9601681232452393
Validation loss: 2.2102571725845337

Epoch: 6| Step: 3
Training loss: 0.9768966436386108
Validation loss: 2.218648076057434

Epoch: 6| Step: 4
Training loss: 0.4727230966091156
Validation loss: 2.2034069895744324

Epoch: 6| Step: 5
Training loss: 0.4003041386604309
Validation loss: 2.244200269381205

Epoch: 6| Step: 6
Training loss: 0.6659817695617676
Validation loss: 2.197853684425354

Epoch: 6| Step: 7
Training loss: 0.9661166667938232
Validation loss: 2.234885573387146

Epoch: 6| Step: 8
Training loss: 0.9634734988212585
Validation loss: 2.232665995756785

Epoch: 6| Step: 9
Training loss: 0.4752870798110962
Validation loss: 2.234145760536194

Epoch: 6| Step: 10
Training loss: 0.928866982460022
Validation loss: 2.280894160270691

Epoch: 6| Step: 11
Training loss: 0.9166368246078491
Validation loss: 2.293030619621277

Epoch: 6| Step: 12
Training loss: 0.6725034713745117
Validation loss: 2.256664276123047

Epoch: 6| Step: 13
Training loss: 1.2101972103118896
Validation loss: 2.3223355213801065

Epoch: 475| Step: 0
Training loss: 0.40132325887680054
Validation loss: 2.235761026541392

Epoch: 6| Step: 1
Training loss: 0.9098376035690308
Validation loss: 2.2584775487581887

Epoch: 6| Step: 2
Training loss: 0.40813982486724854
Validation loss: 2.2666354179382324

Epoch: 6| Step: 3
Training loss: 0.8258771896362305
Validation loss: 2.2014381090799966

Epoch: 6| Step: 4
Training loss: 0.4278077185153961
Validation loss: 2.2749468286832175

Epoch: 6| Step: 5
Training loss: 0.4613695740699768
Validation loss: 2.2666874130566916

Epoch: 6| Step: 6
Training loss: 0.8669693470001221
Validation loss: 2.2649840911229453

Epoch: 6| Step: 7
Training loss: 0.6542902588844299
Validation loss: 2.275311549504598

Epoch: 6| Step: 8
Training loss: 0.912830114364624
Validation loss: 2.2281693816184998

Epoch: 6| Step: 9
Training loss: 0.7952514886856079
Validation loss: 2.213060895601908

Epoch: 6| Step: 10
Training loss: 0.96161949634552
Validation loss: 2.216209570566813

Epoch: 6| Step: 11
Training loss: 1.084390640258789
Validation loss: 2.2104068597157798

Epoch: 6| Step: 12
Training loss: 1.153506875038147
Validation loss: 2.2123247583707175

Epoch: 6| Step: 13
Training loss: 0.6547489166259766
Validation loss: 2.23874564965566

Epoch: 476| Step: 0
Training loss: 0.9392973780632019
Validation loss: 2.1841812133789062

Epoch: 6| Step: 1
Training loss: 0.7347844243049622
Validation loss: 2.223807434240977

Epoch: 6| Step: 2
Training loss: 0.5130845308303833
Validation loss: 2.2592947085698447

Epoch: 6| Step: 3
Training loss: 0.43663710355758667
Validation loss: 2.264761745929718

Epoch: 6| Step: 4
Training loss: 0.6424705982208252
Validation loss: 2.312551259994507

Epoch: 6| Step: 5
Training loss: 1.3993982076644897
Validation loss: 2.3176896373430886

Epoch: 6| Step: 6
Training loss: 0.8475290536880493
Validation loss: 2.324741303920746

Epoch: 6| Step: 7
Training loss: 0.3732886016368866
Validation loss: 2.353423078854879

Epoch: 6| Step: 8
Training loss: 0.8868371248245239
Validation loss: 2.3122046192487082

Epoch: 6| Step: 9
Training loss: 0.45853477716445923
Validation loss: 2.2952675819396973

Epoch: 6| Step: 10
Training loss: 0.9888330698013306
Validation loss: 2.2580354611078897

Epoch: 6| Step: 11
Training loss: 0.8657919764518738
Validation loss: 2.2286861737569175

Epoch: 6| Step: 12
Training loss: 0.7475339770317078
Validation loss: 2.2205061316490173

Epoch: 6| Step: 13
Training loss: 0.5340769290924072
Validation loss: 2.225028375784556

Epoch: 477| Step: 0
Training loss: 0.727067232131958
Validation loss: 2.2345214088757834

Epoch: 6| Step: 1
Training loss: 0.8958343267440796
Validation loss: 2.242194414138794

Epoch: 6| Step: 2
Training loss: 0.381696879863739
Validation loss: 2.2392747004826865

Epoch: 6| Step: 3
Training loss: 0.39100131392478943
Validation loss: 2.2075047890345254

Epoch: 6| Step: 4
Training loss: 0.9123666286468506
Validation loss: 2.26634818315506

Epoch: 6| Step: 5
Training loss: 0.5925964117050171
Validation loss: 2.2663520971934

Epoch: 6| Step: 6
Training loss: 0.4101569354534149
Validation loss: 2.2694122592608132

Epoch: 6| Step: 7
Training loss: 0.5847672820091248
Validation loss: 2.2705031633377075

Epoch: 6| Step: 8
Training loss: 0.5714628100395203
Validation loss: 2.255695343017578

Epoch: 6| Step: 9
Training loss: 0.8445546627044678
Validation loss: 2.22723780075709

Epoch: 6| Step: 10
Training loss: 0.4136000871658325
Validation loss: 2.2515222628911338

Epoch: 6| Step: 11
Training loss: 0.5828713178634644
Validation loss: 2.266343593597412

Epoch: 6| Step: 12
Training loss: 1.1886563301086426
Validation loss: 2.254026790459951

Epoch: 6| Step: 13
Training loss: 1.134877324104309
Validation loss: 2.305697520573934

Epoch: 478| Step: 0
Training loss: 0.5283358097076416
Validation loss: 2.299070398012797

Epoch: 6| Step: 1
Training loss: 0.7833787798881531
Validation loss: 2.301642040411631

Epoch: 6| Step: 2
Training loss: 0.565217137336731
Validation loss: 2.3028926452000937

Epoch: 6| Step: 3
Training loss: 0.7025679349899292
Validation loss: 2.253629525502523

Epoch: 6| Step: 4
Training loss: 0.5439947843551636
Validation loss: 2.2906883557637534

Epoch: 6| Step: 5
Training loss: 0.534134030342102
Validation loss: 2.3041549921035767

Epoch: 6| Step: 6
Training loss: 0.6709418296813965
Validation loss: 2.29765776793162

Epoch: 6| Step: 7
Training loss: 0.9501376152038574
Validation loss: 2.2856523791948953

Epoch: 6| Step: 8
Training loss: 1.235580325126648
Validation loss: 2.263966917991638

Epoch: 6| Step: 9
Training loss: 0.8867700099945068
Validation loss: 2.2718304793039956

Epoch: 6| Step: 10
Training loss: 0.5677750110626221
Validation loss: 2.257009963194529

Epoch: 6| Step: 11
Training loss: 0.4823278486728668
Validation loss: 2.2937516371409097

Epoch: 6| Step: 12
Training loss: 0.6956734657287598
Validation loss: 2.2585252126057944

Epoch: 6| Step: 13
Training loss: 0.9998652935028076
Validation loss: 2.3269604444503784

Epoch: 479| Step: 0
Training loss: 0.6203266382217407
Validation loss: 2.2802809476852417

Epoch: 6| Step: 1
Training loss: 0.43782973289489746
Validation loss: 2.2661598126093545

Epoch: 6| Step: 2
Training loss: 0.4555366635322571
Validation loss: 2.2704201539357505

Epoch: 6| Step: 3
Training loss: 0.655817449092865
Validation loss: 2.2093122005462646

Epoch: 6| Step: 4
Training loss: 0.8241952657699585
Validation loss: 2.2041130661964417

Epoch: 6| Step: 5
Training loss: 0.6317580938339233
Validation loss: 2.1947526137034097

Epoch: 6| Step: 6
Training loss: 1.2097996473312378
Validation loss: 2.2073861956596375

Epoch: 6| Step: 7
Training loss: 0.5918172001838684
Validation loss: 2.2192172010739646

Epoch: 6| Step: 8
Training loss: 1.0723507404327393
Validation loss: 2.2143521308898926

Epoch: 6| Step: 9
Training loss: 0.6756736040115356
Validation loss: 2.1997411449750266

Epoch: 6| Step: 10
Training loss: 0.833769679069519
Validation loss: 2.2286641796429953

Epoch: 6| Step: 11
Training loss: 0.6970723867416382
Validation loss: 2.2311211824417114

Epoch: 6| Step: 12
Training loss: 1.040366291999817
Validation loss: 2.2668262918790183

Epoch: 6| Step: 13
Training loss: 0.9318085312843323
Validation loss: 2.263236125310262

Epoch: 480| Step: 0
Training loss: 0.9728129506111145
Validation loss: 2.23881459236145

Epoch: 6| Step: 1
Training loss: 0.7338364124298096
Validation loss: 2.205135683218638

Epoch: 6| Step: 2
Training loss: 0.49373236298561096
Validation loss: 2.202878952026367

Epoch: 6| Step: 3
Training loss: 1.3514386415481567
Validation loss: 2.2088180780410767

Epoch: 6| Step: 4
Training loss: 0.7978706359863281
Validation loss: 2.2024970849355063

Epoch: 6| Step: 5
Training loss: 1.3038387298583984
Validation loss: 2.210947116216024

Epoch: 6| Step: 6
Training loss: 0.508255124092102
Validation loss: 2.2516016364097595

Epoch: 6| Step: 7
Training loss: 0.5986254811286926
Validation loss: 2.2330557902654014

Epoch: 6| Step: 8
Training loss: 0.8153937458992004
Validation loss: 2.2491416335105896

Epoch: 6| Step: 9
Training loss: 0.6571661829948425
Validation loss: 2.2836769024531045

Epoch: 6| Step: 10
Training loss: 0.7102481126785278
Validation loss: 2.2883267601331077

Epoch: 6| Step: 11
Training loss: 0.679105281829834
Validation loss: 2.263132909933726

Epoch: 6| Step: 12
Training loss: 0.7305657863616943
Validation loss: 2.2305190761884055

Epoch: 6| Step: 13
Training loss: 0.45515990257263184
Validation loss: 2.24241973956426

Epoch: 481| Step: 0
Training loss: 0.8196257948875427
Validation loss: 2.227297306060791

Epoch: 6| Step: 1
Training loss: 0.5549296140670776
Validation loss: 2.198409895102183

Epoch: 6| Step: 2
Training loss: 0.8762474656105042
Validation loss: 2.1869394779205322

Epoch: 6| Step: 3
Training loss: 1.165428876876831
Validation loss: 2.2276015480359397

Epoch: 6| Step: 4
Training loss: 0.41100138425827026
Validation loss: 2.2591503659884133

Epoch: 6| Step: 5
Training loss: 0.284533828496933
Validation loss: 2.2502709229787192

Epoch: 6| Step: 6
Training loss: 1.064026117324829
Validation loss: 2.2677637338638306

Epoch: 6| Step: 7
Training loss: 0.7723601460456848
Validation loss: 2.2767832477887473

Epoch: 6| Step: 8
Training loss: 0.5100274085998535
Validation loss: 2.2876396973927817

Epoch: 6| Step: 9
Training loss: 1.3308947086334229
Validation loss: 2.3169187704722085

Epoch: 6| Step: 10
Training loss: 0.6796194314956665
Validation loss: 2.3241435090700784

Epoch: 6| Step: 11
Training loss: 1.0423331260681152
Validation loss: 2.346866806348165

Epoch: 6| Step: 12
Training loss: 0.7241133451461792
Validation loss: 2.3485977252324424

Epoch: 6| Step: 13
Training loss: 0.5989404916763306
Validation loss: 2.2911601861317954

Epoch: 482| Step: 0
Training loss: 0.9673791527748108
Validation loss: 2.280195156733195

Epoch: 6| Step: 1
Training loss: 0.9334303140640259
Validation loss: 2.2187112172444663

Epoch: 6| Step: 2
Training loss: 1.4730947017669678
Validation loss: 2.2577751676241555

Epoch: 6| Step: 3
Training loss: 0.4597519040107727
Validation loss: 2.259460131327311

Epoch: 6| Step: 4
Training loss: 1.0527734756469727
Validation loss: 2.2108545303344727

Epoch: 6| Step: 5
Training loss: 0.5561901330947876
Validation loss: 2.226933002471924

Epoch: 6| Step: 6
Training loss: 0.6929826736450195
Validation loss: 2.201550046602885

Epoch: 6| Step: 7
Training loss: 0.6772580742835999
Validation loss: 2.2234781781832376

Epoch: 6| Step: 8
Training loss: 0.6742050051689148
Validation loss: 2.2601418097813926

Epoch: 6| Step: 9
Training loss: 0.6877751350402832
Validation loss: 2.2561664978663125

Epoch: 6| Step: 10
Training loss: 0.9581297636032104
Validation loss: 2.2667970259984336

Epoch: 6| Step: 11
Training loss: 0.8461486101150513
Validation loss: 2.2939172983169556

Epoch: 6| Step: 12
Training loss: 0.4935542643070221
Validation loss: 2.273181160291036

Epoch: 6| Step: 13
Training loss: 0.5291411876678467
Validation loss: 2.3087153236071267

Epoch: 483| Step: 0
Training loss: 0.8494027256965637
Validation loss: 2.322655518849691

Epoch: 6| Step: 1
Training loss: 0.9643094539642334
Validation loss: 2.2930404941240945

Epoch: 6| Step: 2
Training loss: 0.774882435798645
Validation loss: 2.2774034341176352

Epoch: 6| Step: 3
Training loss: 0.33803826570510864
Validation loss: 2.223917007446289

Epoch: 6| Step: 4
Training loss: 0.7372708320617676
Validation loss: 2.2984083890914917

Epoch: 6| Step: 5
Training loss: 0.8672393560409546
Validation loss: 2.2809574802716575

Epoch: 6| Step: 6
Training loss: 0.5983073711395264
Validation loss: 2.2467033863067627

Epoch: 6| Step: 7
Training loss: 1.0571614503860474
Validation loss: 2.2773580153783164

Epoch: 6| Step: 8
Training loss: 1.0324150323867798
Validation loss: 2.2558926343917847

Epoch: 6| Step: 9
Training loss: 0.6493556499481201
Validation loss: 2.303790509700775

Epoch: 6| Step: 10
Training loss: 0.6857497692108154
Validation loss: 2.3044175704320273

Epoch: 6| Step: 11
Training loss: 0.4573260247707367
Validation loss: 2.27488911151886

Epoch: 6| Step: 12
Training loss: 0.8027263879776001
Validation loss: 2.239344576994578

Epoch: 6| Step: 13
Training loss: 0.28616297245025635
Validation loss: 2.2700582345326743

Epoch: 484| Step: 0
Training loss: 0.9850121736526489
Validation loss: 2.2876479029655457

Epoch: 6| Step: 1
Training loss: 0.7406208515167236
Validation loss: 2.268047253290812

Epoch: 6| Step: 2
Training loss: 0.8074172735214233
Validation loss: 2.2630615631739297

Epoch: 6| Step: 3
Training loss: 0.40266844630241394
Validation loss: 2.283687641223272

Epoch: 6| Step: 4
Training loss: 0.6196444034576416
Validation loss: 2.2851674556732178

Epoch: 6| Step: 5
Training loss: 0.603326678276062
Validation loss: 2.323376019795736

Epoch: 6| Step: 6
Training loss: 0.503122091293335
Validation loss: 2.279775003592173

Epoch: 6| Step: 7
Training loss: 0.8915852308273315
Validation loss: 2.2843204140663147

Epoch: 6| Step: 8
Training loss: 0.7950723171234131
Validation loss: 2.273208498954773

Epoch: 6| Step: 9
Training loss: 0.7057135701179504
Validation loss: 2.234639346599579

Epoch: 6| Step: 10
Training loss: 0.6971085071563721
Validation loss: 2.217824379603068

Epoch: 6| Step: 11
Training loss: 0.765933096408844
Validation loss: 2.1784673929214478

Epoch: 6| Step: 12
Training loss: 0.5229123830795288
Validation loss: 2.196476419766744

Epoch: 6| Step: 13
Training loss: 1.0009965896606445
Validation loss: 2.2294647494951882

Epoch: 485| Step: 0
Training loss: 0.6747320890426636
Validation loss: 2.214157303174337

Epoch: 6| Step: 1
Training loss: 0.6155595779418945
Validation loss: 2.207191308339437

Epoch: 6| Step: 2
Training loss: 0.6556975841522217
Validation loss: 2.2577881614367166

Epoch: 6| Step: 3
Training loss: 0.5677011609077454
Validation loss: 2.2227797706921897

Epoch: 6| Step: 4
Training loss: 0.9182202816009521
Validation loss: 2.245203693707784

Epoch: 6| Step: 5
Training loss: 0.9262624979019165
Validation loss: 2.257675290107727

Epoch: 6| Step: 6
Training loss: 0.4663624167442322
Validation loss: 2.265191892782847

Epoch: 6| Step: 7
Training loss: 0.2602553963661194
Validation loss: 2.3088054259618125

Epoch: 6| Step: 8
Training loss: 0.9372346997261047
Validation loss: 2.3267390727996826

Epoch: 6| Step: 9
Training loss: 0.7992293238639832
Validation loss: 2.252225875854492

Epoch: 6| Step: 10
Training loss: 0.2975549101829529
Validation loss: 2.2429932951927185

Epoch: 6| Step: 11
Training loss: 1.18310546875
Validation loss: 2.2819619178771973

Epoch: 6| Step: 12
Training loss: 0.6174287796020508
Validation loss: 2.247609555721283

Epoch: 6| Step: 13
Training loss: 0.7768162488937378
Validation loss: 2.2459530234336853

Epoch: 486| Step: 0
Training loss: 0.29460543394088745
Validation loss: 2.2525483767191568

Epoch: 6| Step: 1
Training loss: 0.6210602521896362
Validation loss: 2.194264809290568

Epoch: 6| Step: 2
Training loss: 0.6783179640769958
Validation loss: 2.2730246980985007

Epoch: 6| Step: 3
Training loss: 0.8018454313278198
Validation loss: 2.228198448816935

Epoch: 6| Step: 4
Training loss: 0.6033591032028198
Validation loss: 2.2491289377212524

Epoch: 6| Step: 5
Training loss: 0.4549560248851776
Validation loss: 2.263854185740153

Epoch: 6| Step: 6
Training loss: 0.4158051311969757
Validation loss: 2.2221684654553733

Epoch: 6| Step: 7
Training loss: 0.4483310282230377
Validation loss: 2.2289835015932717

Epoch: 6| Step: 8
Training loss: 1.21632719039917
Validation loss: 2.2877931594848633

Epoch: 6| Step: 9
Training loss: 0.6071467995643616
Validation loss: 2.2911988894144693

Epoch: 6| Step: 10
Training loss: 0.7708069086074829
Validation loss: 2.305028239885966

Epoch: 6| Step: 11
Training loss: 0.857124924659729
Validation loss: 2.304395874341329

Epoch: 6| Step: 12
Training loss: 0.4835585057735443
Validation loss: 2.315940181414286

Epoch: 6| Step: 13
Training loss: 1.050934076309204
Validation loss: 2.2976693511009216

Epoch: 487| Step: 0
Training loss: 0.6410139799118042
Validation loss: 2.2849042614301047

Epoch: 6| Step: 1
Training loss: 1.2134475708007812
Validation loss: 2.286847988764445

Epoch: 6| Step: 2
Training loss: 0.8368397951126099
Validation loss: 2.2766926288604736

Epoch: 6| Step: 3
Training loss: 0.7766131162643433
Validation loss: 2.243256767590841

Epoch: 6| Step: 4
Training loss: 0.7227380871772766
Validation loss: 2.2725007136662803

Epoch: 6| Step: 5
Training loss: 0.48636695742607117
Validation loss: 2.2931721409161887

Epoch: 6| Step: 6
Training loss: 0.5184758901596069
Validation loss: 2.268075108528137

Epoch: 6| Step: 7
Training loss: 0.523563802242279
Validation loss: 2.2419326504071555

Epoch: 6| Step: 8
Training loss: 0.3193216621875763
Validation loss: 2.2127861976623535

Epoch: 6| Step: 9
Training loss: 1.0315574407577515
Validation loss: 2.216667652130127

Epoch: 6| Step: 10
Training loss: 0.6340760588645935
Validation loss: 2.2106037934621177

Epoch: 6| Step: 11
Training loss: 0.5889501571655273
Validation loss: 2.205191731452942

Epoch: 6| Step: 12
Training loss: 0.5575844049453735
Validation loss: 2.2160929640134177

Epoch: 6| Step: 13
Training loss: 0.5607320666313171
Validation loss: 2.1817979415257773

Epoch: 488| Step: 0
Training loss: 0.3580631911754608
Validation loss: 2.1870973308881125

Epoch: 6| Step: 1
Training loss: 0.4618767499923706
Validation loss: 2.2244895299275718

Epoch: 6| Step: 2
Training loss: 0.7276709675788879
Validation loss: 2.170831342538198

Epoch: 6| Step: 3
Training loss: 0.7675462365150452
Validation loss: 2.224091410636902

Epoch: 6| Step: 4
Training loss: 0.2603132128715515
Validation loss: 2.2233771880467734

Epoch: 6| Step: 5
Training loss: 0.7319085597991943
Validation loss: 2.279807170232137

Epoch: 6| Step: 6
Training loss: 0.48180967569351196
Validation loss: 2.2364198366800943

Epoch: 6| Step: 7
Training loss: 1.0486897230148315
Validation loss: 2.2899776299794516

Epoch: 6| Step: 8
Training loss: 1.1171135902404785
Validation loss: 2.286040107409159

Epoch: 6| Step: 9
Training loss: 0.8598077297210693
Validation loss: 2.246968984603882

Epoch: 6| Step: 10
Training loss: 0.42980876564979553
Validation loss: 2.259774923324585

Epoch: 6| Step: 11
Training loss: 0.9968568086624146
Validation loss: 2.2931209206581116

Epoch: 6| Step: 12
Training loss: 0.7951256632804871
Validation loss: 2.3378285566965737

Epoch: 6| Step: 13
Training loss: 0.39133089780807495
Validation loss: 2.270781934261322

Epoch: 489| Step: 0
Training loss: 0.7534650564193726
Validation loss: 2.3109596371650696

Epoch: 6| Step: 1
Training loss: 0.4184107780456543
Validation loss: 2.2866493463516235

Epoch: 6| Step: 2
Training loss: 0.4817678928375244
Validation loss: 2.2829678455988565

Epoch: 6| Step: 3
Training loss: 0.5548693537712097
Validation loss: 2.239902396996816

Epoch: 6| Step: 4
Training loss: 0.3857952356338501
Validation loss: 2.21467791001002

Epoch: 6| Step: 5
Training loss: 0.666425347328186
Validation loss: 2.2549455960591636

Epoch: 6| Step: 6
Training loss: 0.5736650228500366
Validation loss: 2.3084375460942588

Epoch: 6| Step: 7
Training loss: 1.134139895439148
Validation loss: 2.2829228043556213

Epoch: 6| Step: 8
Training loss: 0.9535285234451294
Validation loss: 2.2509546279907227

Epoch: 6| Step: 9
Training loss: 0.8489066362380981
Validation loss: 2.3216100931167603

Epoch: 6| Step: 10
Training loss: 0.6491594314575195
Validation loss: 2.282763123512268

Epoch: 6| Step: 11
Training loss: 0.5859586000442505
Validation loss: 2.28387842575709

Epoch: 6| Step: 12
Training loss: 1.005457878112793
Validation loss: 2.287462751070658

Epoch: 6| Step: 13
Training loss: 0.623188853263855
Validation loss: 2.2448129256566367

Epoch: 490| Step: 0
Training loss: 0.48586809635162354
Validation loss: 2.2491164803504944

Epoch: 6| Step: 1
Training loss: 0.8425958156585693
Validation loss: 2.21581236521403

Epoch: 6| Step: 2
Training loss: 0.9093648195266724
Validation loss: 2.1890902519226074

Epoch: 6| Step: 3
Training loss: 0.39836472272872925
Validation loss: 2.2115861972173056

Epoch: 6| Step: 4
Training loss: 0.49195998907089233
Validation loss: 2.27410622437795

Epoch: 6| Step: 5
Training loss: 0.6769071817398071
Validation loss: 2.259785016377767

Epoch: 6| Step: 6
Training loss: 0.45868539810180664
Validation loss: 2.236983378728231

Epoch: 6| Step: 7
Training loss: 0.5778524279594421
Validation loss: 2.247111896673838

Epoch: 6| Step: 8
Training loss: 1.0935131311416626
Validation loss: 2.2551626563072205

Epoch: 6| Step: 9
Training loss: 0.8047696352005005
Validation loss: 2.256618599096934

Epoch: 6| Step: 10
Training loss: 0.8700592517852783
Validation loss: 2.262392242749532

Epoch: 6| Step: 11
Training loss: 0.4398346543312073
Validation loss: 2.30636457602183

Epoch: 6| Step: 12
Training loss: 1.2138922214508057
Validation loss: 2.283047835032145

Epoch: 6| Step: 13
Training loss: 0.31474432349205017
Validation loss: 2.255319873491923

Epoch: 491| Step: 0
Training loss: 0.4391827881336212
Validation loss: 2.3181457916895547

Epoch: 6| Step: 1
Training loss: 0.6540870666503906
Validation loss: 2.293801029523214

Epoch: 6| Step: 2
Training loss: 0.65384840965271
Validation loss: 2.2683277130126953

Epoch: 6| Step: 3
Training loss: 0.3895663917064667
Validation loss: 2.2766972184181213

Epoch: 6| Step: 4
Training loss: 0.5920431017875671
Validation loss: 2.265834311644236

Epoch: 6| Step: 5
Training loss: 0.7538825273513794
Validation loss: 2.256991684436798

Epoch: 6| Step: 6
Training loss: 0.9412271976470947
Validation loss: 2.234642744064331

Epoch: 6| Step: 7
Training loss: 0.27946916222572327
Validation loss: 2.222468316555023

Epoch: 6| Step: 8
Training loss: 0.352263867855072
Validation loss: 2.2254523833592734

Epoch: 6| Step: 9
Training loss: 0.38022947311401367
Validation loss: 2.223357697327932

Epoch: 6| Step: 10
Training loss: 1.0212085247039795
Validation loss: 2.2206636667251587

Epoch: 6| Step: 11
Training loss: 0.5728386044502258
Validation loss: 2.237882057825724

Epoch: 6| Step: 12
Training loss: 1.2304439544677734
Validation loss: 2.2357752323150635

Epoch: 6| Step: 13
Training loss: 0.8792831897735596
Validation loss: 2.261385361353556

Epoch: 492| Step: 0
Training loss: 0.520332932472229
Validation loss: 2.2294276555379233

Epoch: 6| Step: 1
Training loss: 0.5937022566795349
Validation loss: 2.225849668184916

Epoch: 6| Step: 2
Training loss: 0.36027365922927856
Validation loss: 2.2295934756596885

Epoch: 6| Step: 3
Training loss: 0.5033045411109924
Validation loss: 2.2593600352605185

Epoch: 6| Step: 4
Training loss: 0.6896798014640808
Validation loss: 2.23579740524292

Epoch: 6| Step: 5
Training loss: 0.734144389629364
Validation loss: 2.2264760931332908

Epoch: 6| Step: 6
Training loss: 0.5952229499816895
Validation loss: 2.240845888853073

Epoch: 6| Step: 7
Training loss: 0.8375352621078491
Validation loss: 2.2767913341522217

Epoch: 6| Step: 8
Training loss: 0.5496519804000854
Validation loss: 2.2822209000587463

Epoch: 6| Step: 9
Training loss: 0.753768801689148
Validation loss: 2.250774403413137

Epoch: 6| Step: 10
Training loss: 0.3136207163333893
Validation loss: 2.254619777202606

Epoch: 6| Step: 11
Training loss: 1.3299133777618408
Validation loss: 2.2917360663414

Epoch: 6| Step: 12
Training loss: 0.9757277369499207
Validation loss: 2.233986775080363

Epoch: 6| Step: 13
Training loss: 0.4198879897594452
Validation loss: 2.238365431626638

Epoch: 493| Step: 0
Training loss: 0.4066948890686035
Validation loss: 2.2423426707585654

Epoch: 6| Step: 1
Training loss: 0.34440290927886963
Validation loss: 2.242750585079193

Epoch: 6| Step: 2
Training loss: 0.9153021574020386
Validation loss: 2.248298148314158

Epoch: 6| Step: 3
Training loss: 0.8609017133712769
Validation loss: 2.2241735061009726

Epoch: 6| Step: 4
Training loss: 0.6269351243972778
Validation loss: 2.2585052450497947

Epoch: 6| Step: 5
Training loss: 0.5702322721481323
Validation loss: 2.2598252296447754

Epoch: 6| Step: 6
Training loss: 0.8594558835029602
Validation loss: 2.2641274531682334

Epoch: 6| Step: 7
Training loss: 0.5544857978820801
Validation loss: 2.246464113394419

Epoch: 6| Step: 8
Training loss: 0.9813889861106873
Validation loss: 2.2971161206563315

Epoch: 6| Step: 9
Training loss: 0.44013655185699463
Validation loss: 2.28314342101415

Epoch: 6| Step: 10
Training loss: 0.7359813451766968
Validation loss: 2.3099565903345742

Epoch: 6| Step: 11
Training loss: 0.36216193437576294
Validation loss: 2.2849374214808145

Epoch: 6| Step: 12
Training loss: 1.1435174942016602
Validation loss: 2.285921275615692

Epoch: 6| Step: 13
Training loss: 0.679741382598877
Validation loss: 2.263453781604767

Epoch: 494| Step: 0
Training loss: 0.471466064453125
Validation loss: 2.2477022608121238

Epoch: 6| Step: 1
Training loss: 0.5421566367149353
Validation loss: 2.2446744044621787

Epoch: 6| Step: 2
Training loss: 0.588823676109314
Validation loss: 2.2380276918411255

Epoch: 6| Step: 3
Training loss: 1.1256719827651978
Validation loss: 2.247506777445475

Epoch: 6| Step: 4
Training loss: 1.2953224182128906
Validation loss: 2.255319356918335

Epoch: 6| Step: 5
Training loss: 0.7756091952323914
Validation loss: 2.2920567194620767

Epoch: 6| Step: 6
Training loss: 0.4351891875267029
Validation loss: 2.2725843389829

Epoch: 6| Step: 7
Training loss: 0.5875091552734375
Validation loss: 2.260834892590841

Epoch: 6| Step: 8
Training loss: 0.6819196939468384
Validation loss: 2.288019875685374

Epoch: 6| Step: 9
Training loss: 0.44074833393096924
Validation loss: 2.2852877378463745

Epoch: 6| Step: 10
Training loss: 0.4962462782859802
Validation loss: 2.2283777395884194

Epoch: 6| Step: 11
Training loss: 0.7186083793640137
Validation loss: 2.2172303597132363

Epoch: 6| Step: 12
Training loss: 1.0142436027526855
Validation loss: 2.2858688632647195

Epoch: 6| Step: 13
Training loss: 0.6406667828559875
Validation loss: 2.27770588795344

Epoch: 495| Step: 0
Training loss: 0.588217556476593
Validation loss: 2.25951619942983

Epoch: 6| Step: 1
Training loss: 0.5913834571838379
Validation loss: 2.258685032526652

Epoch: 6| Step: 2
Training loss: 0.8801645040512085
Validation loss: 2.282297690709432

Epoch: 6| Step: 3
Training loss: 0.43985530734062195
Validation loss: 2.260447879632314

Epoch: 6| Step: 4
Training loss: 0.5482469797134399
Validation loss: 2.2792587280273438

Epoch: 6| Step: 5
Training loss: 0.7954956293106079
Validation loss: 2.325082023938497

Epoch: 6| Step: 6
Training loss: 1.7585928440093994
Validation loss: 2.292909860610962

Epoch: 6| Step: 7
Training loss: 0.5632492303848267
Validation loss: 2.3323543270428977

Epoch: 6| Step: 8
Training loss: 1.1417193412780762
Validation loss: 2.3254451354344687

Epoch: 6| Step: 9
Training loss: 0.6677641868591309
Validation loss: 2.286261816819509

Epoch: 6| Step: 10
Training loss: 0.6241165399551392
Validation loss: 2.2597230672836304

Epoch: 6| Step: 11
Training loss: 0.3147904574871063
Validation loss: 2.259343425432841

Epoch: 6| Step: 12
Training loss: 0.4054149389266968
Validation loss: 2.2243518431981406

Epoch: 6| Step: 13
Training loss: 0.5649467706680298
Validation loss: 2.230074862639109

Epoch: 496| Step: 0
Training loss: 0.5089178085327148
Validation loss: 2.2228395144144693

Epoch: 6| Step: 1
Training loss: 0.7926116585731506
Validation loss: 2.2211700280507407

Epoch: 6| Step: 2
Training loss: 0.6701629757881165
Validation loss: 2.2299189964930215

Epoch: 6| Step: 3
Training loss: 0.5282207727432251
Validation loss: 2.2073195377985635

Epoch: 6| Step: 4
Training loss: 0.30242758989334106
Validation loss: 2.2295360565185547

Epoch: 6| Step: 5
Training loss: 1.0144041776657104
Validation loss: 2.2785616715749106

Epoch: 6| Step: 6
Training loss: 0.3308543562889099
Validation loss: 2.298502723375956

Epoch: 6| Step: 7
Training loss: 0.5772078037261963
Validation loss: 2.3167391220728555

Epoch: 6| Step: 8
Training loss: 1.0239698886871338
Validation loss: 2.307829737663269

Epoch: 6| Step: 9
Training loss: 0.49102330207824707
Validation loss: 2.3271112044652305

Epoch: 6| Step: 10
Training loss: 0.5956833362579346
Validation loss: 2.2603577971458435

Epoch: 6| Step: 11
Training loss: 0.6441650390625
Validation loss: 2.268348515033722

Epoch: 6| Step: 12
Training loss: 1.0133066177368164
Validation loss: 2.2416183749834695

Epoch: 6| Step: 13
Training loss: 1.141853928565979
Validation loss: 2.196565349896749

Epoch: 497| Step: 0
Training loss: 0.41520944237709045
Validation loss: 2.2315646012624106

Epoch: 6| Step: 1
Training loss: 0.8993070721626282
Validation loss: 2.2061743338902793

Epoch: 6| Step: 2
Training loss: 0.6184594035148621
Validation loss: 2.256214658419291

Epoch: 6| Step: 3
Training loss: 0.4171959161758423
Validation loss: 2.277460237344106

Epoch: 6| Step: 4
Training loss: 0.33147794008255005
Validation loss: 2.232843736807505

Epoch: 6| Step: 5
Training loss: 0.47526878118515015
Validation loss: 2.254959205786387

Epoch: 6| Step: 6
Training loss: 0.67058265209198
Validation loss: 2.257764995098114

Epoch: 6| Step: 7
Training loss: 1.0003560781478882
Validation loss: 2.2294832865397134

Epoch: 6| Step: 8
Training loss: 0.9654264450073242
Validation loss: 2.2590579986572266

Epoch: 6| Step: 9
Training loss: 1.2226598262786865
Validation loss: 2.30845445394516

Epoch: 6| Step: 10
Training loss: 0.4869731664657593
Validation loss: 2.3111724654833474

Epoch: 6| Step: 11
Training loss: 0.5366583466529846
Validation loss: 2.280492047468821

Epoch: 6| Step: 12
Training loss: 0.9534794688224792
Validation loss: 2.2832550605138144

Epoch: 6| Step: 13
Training loss: 0.4637078642845154
Validation loss: 2.260134279727936

Epoch: 498| Step: 0
Training loss: 0.5742193460464478
Validation loss: 2.2531461119651794

Epoch: 6| Step: 1
Training loss: 1.0021800994873047
Validation loss: 2.2142446438471475

Epoch: 6| Step: 2
Training loss: 0.4994480013847351
Validation loss: 2.2206810315450034

Epoch: 6| Step: 3
Training loss: 0.7852383255958557
Validation loss: 2.243719299634298

Epoch: 6| Step: 4
Training loss: 1.1040008068084717
Validation loss: 2.2663320700327554

Epoch: 6| Step: 5
Training loss: 0.6156656742095947
Validation loss: 2.2585739294687905

Epoch: 6| Step: 6
Training loss: 0.3772777020931244
Validation loss: 2.2718048890431723

Epoch: 6| Step: 7
Training loss: 0.5960000157356262
Validation loss: 2.3050097227096558

Epoch: 6| Step: 8
Training loss: 0.4663352370262146
Validation loss: 2.3590974609057107

Epoch: 6| Step: 9
Training loss: 0.6754356622695923
Validation loss: 2.343640128771464

Epoch: 6| Step: 10
Training loss: 0.7097537517547607
Validation loss: 2.352928181489309

Epoch: 6| Step: 11
Training loss: 0.8552384376525879
Validation loss: 2.312164922555288

Epoch: 6| Step: 12
Training loss: 1.2074830532073975
Validation loss: 2.2408077716827393

Epoch: 6| Step: 13
Training loss: 0.41403356194496155
Validation loss: 2.2266438206036887

Epoch: 499| Step: 0
Training loss: 0.617313027381897
Validation loss: 2.2262539068857827

Epoch: 6| Step: 1
Training loss: 0.49759790301322937
Validation loss: 2.2652668158213296

Epoch: 6| Step: 2
Training loss: 0.31799954175949097
Validation loss: 2.254952092965444

Epoch: 6| Step: 3
Training loss: 0.9515676498413086
Validation loss: 2.235022723674774

Epoch: 6| Step: 4
Training loss: 1.0752789974212646
Validation loss: 2.210396468639374

Epoch: 6| Step: 5
Training loss: 0.6432877779006958
Validation loss: 2.2262735962867737

Epoch: 6| Step: 6
Training loss: 0.7313159108161926
Validation loss: 2.231000820795695

Epoch: 6| Step: 7
Training loss: 0.6720203161239624
Validation loss: 2.2244296868642173

Epoch: 6| Step: 8
Training loss: 0.6690584421157837
Validation loss: 2.2602582971254983

Epoch: 6| Step: 9
Training loss: 1.0238640308380127
Validation loss: 2.270068605740865

Epoch: 6| Step: 10
Training loss: 0.6771677732467651
Validation loss: 2.3227913777033486

Epoch: 6| Step: 11
Training loss: 0.4285549223423004
Validation loss: 2.3222097953160605

Epoch: 6| Step: 12
Training loss: 0.7828741073608398
Validation loss: 2.295289675394694

Epoch: 6| Step: 13
Training loss: 0.561460018157959
Validation loss: 2.293095846970876

Epoch: 500| Step: 0
Training loss: 1.0825531482696533
Validation loss: 2.2927414973576865

Epoch: 6| Step: 1
Training loss: 0.57144695520401
Validation loss: 2.2676634391148887

Epoch: 6| Step: 2
Training loss: 0.8323819637298584
Validation loss: 2.318076729774475

Epoch: 6| Step: 3
Training loss: 0.42758509516716003
Validation loss: 2.3223149379094443

Epoch: 6| Step: 4
Training loss: 0.3910124897956848
Validation loss: 2.2909005681673684

Epoch: 6| Step: 5
Training loss: 0.41299474239349365
Validation loss: 2.2699147860209146

Epoch: 6| Step: 6
Training loss: 0.5958734154701233
Validation loss: 2.2834436694780984

Epoch: 6| Step: 7
Training loss: 0.7591034173965454
Validation loss: 2.263939360777537

Epoch: 6| Step: 8
Training loss: 0.5190379619598389
Validation loss: 2.3128796021143594

Epoch: 6| Step: 9
Training loss: 1.3483434915542603
Validation loss: 2.269882321357727

Epoch: 6| Step: 10
Training loss: 0.6107072234153748
Validation loss: 2.280340552330017

Epoch: 6| Step: 11
Training loss: 0.35627296566963196
Validation loss: 2.304043730099996

Epoch: 6| Step: 12
Training loss: 0.4679405689239502
Validation loss: 2.3018129467964172

Epoch: 6| Step: 13
Training loss: 0.6630934476852417
Validation loss: 2.3083085219065347

Epoch: 501| Step: 0
Training loss: 0.5634198188781738
Validation loss: 2.28963174422582

Epoch: 6| Step: 1
Training loss: 0.4049133062362671
Validation loss: 2.3130067388216653

Epoch: 6| Step: 2
Training loss: 0.9253408908843994
Validation loss: 2.298713763554891

Epoch: 6| Step: 3
Training loss: 0.7780119180679321
Validation loss: 2.2741656502087912

Epoch: 6| Step: 4
Training loss: 0.7409622669219971
Validation loss: 2.3580057422320047

Epoch: 6| Step: 5
Training loss: 0.2702312469482422
Validation loss: 2.3431522448857627

Epoch: 6| Step: 6
Training loss: 0.49906837940216064
Validation loss: 2.3365824619928994

Epoch: 6| Step: 7
Training loss: 0.6017568111419678
Validation loss: 2.3216509024302163

Epoch: 6| Step: 8
Training loss: 0.5686062574386597
Validation loss: 2.3275133967399597

Epoch: 6| Step: 9
Training loss: 0.9146969318389893
Validation loss: 2.290612777074178

Epoch: 6| Step: 10
Training loss: 1.10882568359375
Validation loss: 2.2591479818026223

Epoch: 6| Step: 11
Training loss: 0.5627638101577759
Validation loss: 2.2530539433161416

Epoch: 6| Step: 12
Training loss: 0.7934629917144775
Validation loss: 2.2365350921948752

Epoch: 6| Step: 13
Training loss: 0.4885724186897278
Validation loss: 2.2615209817886353

Epoch: 502| Step: 0
Training loss: 0.8579399585723877
Validation loss: 2.199614723523458

Epoch: 6| Step: 1
Training loss: 0.6244602203369141
Validation loss: 2.282867948214213

Epoch: 6| Step: 2
Training loss: 0.7417259216308594
Validation loss: 2.2659787933031716

Epoch: 6| Step: 3
Training loss: 0.5125707387924194
Validation loss: 2.2470122575759888

Epoch: 6| Step: 4
Training loss: 0.4278111457824707
Validation loss: 2.2162894010543823

Epoch: 6| Step: 5
Training loss: 0.9015874862670898
Validation loss: 2.239732841650645

Epoch: 6| Step: 6
Training loss: 0.8285230398178101
Validation loss: 2.2482761343320212

Epoch: 6| Step: 7
Training loss: 0.49834030866622925
Validation loss: 2.2484485109647117

Epoch: 6| Step: 8
Training loss: 0.3148384094238281
Validation loss: 2.2318909764289856

Epoch: 6| Step: 9
Training loss: 1.1071488857269287
Validation loss: 2.248830040295919

Epoch: 6| Step: 10
Training loss: 0.7526710033416748
Validation loss: 2.23374476035436

Epoch: 6| Step: 11
Training loss: 0.5620143413543701
Validation loss: 2.2086593906084695

Epoch: 6| Step: 12
Training loss: 0.401657372713089
Validation loss: 2.225428322950999

Epoch: 6| Step: 13
Training loss: 0.40334072709083557
Validation loss: 2.281984726587931

Epoch: 503| Step: 0
Training loss: 1.3098750114440918
Validation loss: 2.245443820953369

Epoch: 6| Step: 1
Training loss: 0.6721401214599609
Validation loss: 2.22307026386261

Epoch: 6| Step: 2
Training loss: 0.6909154057502747
Validation loss: 2.2790637214978537

Epoch: 6| Step: 3
Training loss: 0.8190180063247681
Validation loss: 2.30535089969635

Epoch: 6| Step: 4
Training loss: 0.36229580640792847
Validation loss: 2.2625472942988076

Epoch: 6| Step: 5
Training loss: 0.35090872645378113
Validation loss: 2.295844336350759

Epoch: 6| Step: 6
Training loss: 0.3853555917739868
Validation loss: 2.291320025920868

Epoch: 6| Step: 7
Training loss: 0.3428666591644287
Validation loss: 2.3017437855402627

Epoch: 6| Step: 8
Training loss: 0.7695773243904114
Validation loss: 2.2922167778015137

Epoch: 6| Step: 9
Training loss: 0.46900254487991333
Validation loss: 2.26371697584788

Epoch: 6| Step: 10
Training loss: 0.5290848016738892
Validation loss: 2.3182321190834045

Epoch: 6| Step: 11
Training loss: 1.1412079334259033
Validation loss: 2.311447282632192

Epoch: 6| Step: 12
Training loss: 0.6836798787117004
Validation loss: 2.2874571283658347

Epoch: 6| Step: 13
Training loss: 0.5861325263977051
Validation loss: 2.2308276096979776

Epoch: 504| Step: 0
Training loss: 0.8726913928985596
Validation loss: 2.2097334265708923

Epoch: 6| Step: 1
Training loss: 0.3246902823448181
Validation loss: 2.247158964474996

Epoch: 6| Step: 2
Training loss: 0.8126684427261353
Validation loss: 2.1928414901097617

Epoch: 6| Step: 3
Training loss: 0.7892091274261475
Validation loss: 2.2450679937998452

Epoch: 6| Step: 4
Training loss: 0.940984845161438
Validation loss: 2.2631197571754456

Epoch: 6| Step: 5
Training loss: 0.3187989592552185
Validation loss: 2.206900497277578

Epoch: 6| Step: 6
Training loss: 0.5870823860168457
Validation loss: 2.1818602085113525

Epoch: 6| Step: 7
Training loss: 0.23575317859649658
Validation loss: 2.240299185117086

Epoch: 6| Step: 8
Training loss: 0.6787428855895996
Validation loss: 2.201484183470408

Epoch: 6| Step: 9
Training loss: 0.4790187180042267
Validation loss: 2.26515922943751

Epoch: 6| Step: 10
Training loss: 0.8074595928192139
Validation loss: 2.211500326792399

Epoch: 6| Step: 11
Training loss: 0.3483541011810303
Validation loss: 2.2212988138198853

Epoch: 6| Step: 12
Training loss: 0.38450556993484497
Validation loss: 2.2375723918279014

Epoch: 6| Step: 13
Training loss: 0.9978551864624023
Validation loss: 2.2396865089734397

Epoch: 505| Step: 0
Training loss: 0.45858871936798096
Validation loss: 2.2345805168151855

Epoch: 6| Step: 1
Training loss: 0.34307050704956055
Validation loss: 2.236044466495514

Epoch: 6| Step: 2
Training loss: 0.7104955911636353
Validation loss: 2.208933194478353

Epoch: 6| Step: 3
Training loss: 0.43768662214279175
Validation loss: 2.2344228625297546

Epoch: 6| Step: 4
Training loss: 0.6216676235198975
Validation loss: 2.224494159221649

Epoch: 6| Step: 5
Training loss: 0.8643370270729065
Validation loss: 2.3089441855748496

Epoch: 6| Step: 6
Training loss: 0.38687369227409363
Validation loss: 2.31615940729777

Epoch: 6| Step: 7
Training loss: 0.6187167763710022
Validation loss: 2.3324225743611655

Epoch: 6| Step: 8
Training loss: 1.2493668794631958
Validation loss: 2.286259949207306

Epoch: 6| Step: 9
Training loss: 0.8516082763671875
Validation loss: 2.271285971005758

Epoch: 6| Step: 10
Training loss: 0.8383010625839233
Validation loss: 2.300451159477234

Epoch: 6| Step: 11
Training loss: 0.5297015309333801
Validation loss: 2.263870139916738

Epoch: 6| Step: 12
Training loss: 0.3173413872718811
Validation loss: 2.2717279195785522

Epoch: 6| Step: 13
Training loss: 0.44830167293548584
Validation loss: 2.2466772198677063

Epoch: 506| Step: 0
Training loss: 0.3665882647037506
Validation loss: 2.300525406996409

Epoch: 6| Step: 1
Training loss: 0.640101432800293
Validation loss: 2.2835094928741455

Epoch: 6| Step: 2
Training loss: 0.3579365015029907
Validation loss: 2.325644075870514

Epoch: 6| Step: 3
Training loss: 0.5032916069030762
Validation loss: 2.326906899611155

Epoch: 6| Step: 4
Training loss: 0.43042683601379395
Validation loss: 2.3058437506357827

Epoch: 6| Step: 5
Training loss: 0.5213406085968018
Validation loss: 2.3104124665260315

Epoch: 6| Step: 6
Training loss: 0.6639403700828552
Validation loss: 2.26182887951533

Epoch: 6| Step: 7
Training loss: 0.4277198314666748
Validation loss: 2.2819682359695435

Epoch: 6| Step: 8
Training loss: 0.23009291291236877
Validation loss: 2.2557098070780435

Epoch: 6| Step: 9
Training loss: 0.6476453542709351
Validation loss: 2.291983962059021

Epoch: 6| Step: 10
Training loss: 0.5649952292442322
Validation loss: 2.2841442823410034

Epoch: 6| Step: 11
Training loss: 1.0349336862564087
Validation loss: 2.311882813771566

Epoch: 6| Step: 12
Training loss: 0.5332752466201782
Validation loss: 2.2835400700569153

Epoch: 6| Step: 13
Training loss: 1.595001459121704
Validation loss: 2.253209888935089

Epoch: 507| Step: 0
Training loss: 0.32993584871292114
Validation loss: 2.263146241505941

Epoch: 6| Step: 1
Training loss: 0.8474161624908447
Validation loss: 2.3052463928858438

Epoch: 6| Step: 2
Training loss: 0.4041200876235962
Validation loss: 2.2833112875620523

Epoch: 6| Step: 3
Training loss: 1.01814603805542
Validation loss: 2.3322144150733948

Epoch: 6| Step: 4
Training loss: 0.6426955461502075
Validation loss: 2.3021682302157083

Epoch: 6| Step: 5
Training loss: 0.8542203307151794
Validation loss: 2.2560128768285117

Epoch: 6| Step: 6
Training loss: 0.9829311370849609
Validation loss: 2.226141333580017

Epoch: 6| Step: 7
Training loss: 0.3160242736339569
Validation loss: 2.3134485483169556

Epoch: 6| Step: 8
Training loss: 0.6083409190177917
Validation loss: 2.2552180687586465

Epoch: 6| Step: 9
Training loss: 1.002518892288208
Validation loss: 2.2530514001846313

Epoch: 6| Step: 10
Training loss: 0.29426729679107666
Validation loss: 2.2526139418284097

Epoch: 6| Step: 11
Training loss: 0.4791127145290375
Validation loss: 2.2900811235109964

Epoch: 6| Step: 12
Training loss: 0.7147990465164185
Validation loss: 2.24317059914271

Epoch: 6| Step: 13
Training loss: 0.31346073746681213
Validation loss: 2.27960995833079

Epoch: 508| Step: 0
Training loss: 0.9227495193481445
Validation loss: 2.2760705749193826

Epoch: 6| Step: 1
Training loss: 0.486529141664505
Validation loss: 2.257618506749471

Epoch: 6| Step: 2
Training loss: 0.6351783871650696
Validation loss: 2.282791276772817

Epoch: 6| Step: 3
Training loss: 0.34201356768608093
Validation loss: 2.3206392725308738

Epoch: 6| Step: 4
Training loss: 0.460723876953125
Validation loss: 2.2882777651151023

Epoch: 6| Step: 5
Training loss: 0.3556576371192932
Validation loss: 2.2940669457117715

Epoch: 6| Step: 6
Training loss: 0.6633589267730713
Validation loss: 2.2701646089553833

Epoch: 6| Step: 7
Training loss: 0.23155899345874786
Validation loss: 2.256603797276815

Epoch: 6| Step: 8
Training loss: 0.6662487983703613
Validation loss: 2.2470659613609314

Epoch: 6| Step: 9
Training loss: 0.6317298412322998
Validation loss: 2.25465460618337

Epoch: 6| Step: 10
Training loss: 0.7402937412261963
Validation loss: 2.2549033562342324

Epoch: 6| Step: 11
Training loss: 0.5397461652755737
Validation loss: 2.2485325932502747

Epoch: 6| Step: 12
Training loss: 1.0045487880706787
Validation loss: 2.2735803723335266

Epoch: 6| Step: 13
Training loss: 0.6581156253814697
Validation loss: 2.269849181175232

Epoch: 509| Step: 0
Training loss: 0.4966679513454437
Validation loss: 2.299736658732096

Epoch: 6| Step: 1
Training loss: 0.8713265657424927
Validation loss: 2.260387738545736

Epoch: 6| Step: 2
Training loss: 0.43797528743743896
Validation loss: 2.293835401535034

Epoch: 6| Step: 3
Training loss: 0.3958143889904022
Validation loss: 2.2779813011487327

Epoch: 6| Step: 4
Training loss: 0.37167367339134216
Validation loss: 2.268801669279734

Epoch: 6| Step: 5
Training loss: 0.3121255338191986
Validation loss: 2.2894893487294516

Epoch: 6| Step: 6
Training loss: 0.7739501595497131
Validation loss: 2.2363415956497192

Epoch: 6| Step: 7
Training loss: 0.870963454246521
Validation loss: 2.280095418294271

Epoch: 6| Step: 8
Training loss: 0.9922546148300171
Validation loss: 2.2646165688832602

Epoch: 6| Step: 9
Training loss: 0.5452195405960083
Validation loss: 2.2748186588287354

Epoch: 6| Step: 10
Training loss: 0.6540611982345581
Validation loss: 2.229694048563639

Epoch: 6| Step: 11
Training loss: 0.42991766333580017
Validation loss: 2.222625990708669

Epoch: 6| Step: 12
Training loss: 0.8397114276885986
Validation loss: 2.2610268195470176

Epoch: 6| Step: 13
Training loss: 0.6878235340118408
Validation loss: 2.2952723503112793

Epoch: 510| Step: 0
Training loss: 0.2369627058506012
Validation loss: 2.294835070768992

Epoch: 6| Step: 1
Training loss: 0.5466063022613525
Validation loss: 2.3023778597513833

Epoch: 6| Step: 2
Training loss: 0.5167006850242615
Validation loss: 2.2823713024457297

Epoch: 6| Step: 3
Training loss: 0.2985248863697052
Validation loss: 2.2637526392936707

Epoch: 6| Step: 4
Training loss: 0.5982685685157776
Validation loss: 2.230229437351227

Epoch: 6| Step: 5
Training loss: 0.48774272203445435
Validation loss: 2.2318052649497986

Epoch: 6| Step: 6
Training loss: 0.6316701173782349
Validation loss: 2.2572134534517923

Epoch: 6| Step: 7
Training loss: 0.9227439165115356
Validation loss: 2.2741166949272156

Epoch: 6| Step: 8
Training loss: 1.161818265914917
Validation loss: 2.2269734541575112

Epoch: 6| Step: 9
Training loss: 0.714232325553894
Validation loss: 2.2786413033803306

Epoch: 6| Step: 10
Training loss: 1.2442846298217773
Validation loss: 2.2159024477005005

Epoch: 6| Step: 11
Training loss: 0.37180447578430176
Validation loss: 2.261334180831909

Epoch: 6| Step: 12
Training loss: 0.6754195094108582
Validation loss: 2.3032586177190146

Epoch: 6| Step: 13
Training loss: 0.5884861946105957
Validation loss: 2.3182746966679892

Epoch: 511| Step: 0
Training loss: 0.626824140548706
Validation loss: 2.2539546489715576

Epoch: 6| Step: 1
Training loss: 0.3922523260116577
Validation loss: 2.2371543049812317

Epoch: 6| Step: 2
Training loss: 0.4068409204483032
Validation loss: 2.2485250433286033

Epoch: 6| Step: 3
Training loss: 0.3426222503185272
Validation loss: 2.2353292306264243

Epoch: 6| Step: 4
Training loss: 1.3519936800003052
Validation loss: 2.269355575243632

Epoch: 6| Step: 5
Training loss: 0.5483410358428955
Validation loss: 2.2764320174853006

Epoch: 6| Step: 6
Training loss: 0.9271343946456909
Validation loss: 2.278981367746989

Epoch: 6| Step: 7
Training loss: 1.0314719676971436
Validation loss: 2.2566521763801575

Epoch: 6| Step: 8
Training loss: 0.7156341671943665
Validation loss: 2.30267063776652

Epoch: 6| Step: 9
Training loss: 0.35726943612098694
Validation loss: 2.3165425856908164

Epoch: 6| Step: 10
Training loss: 0.6810312867164612
Validation loss: 2.342700163523356

Epoch: 6| Step: 11
Training loss: 0.553175151348114
Validation loss: 2.3228266636530557

Epoch: 6| Step: 12
Training loss: 0.4809815287590027
Validation loss: 2.3375528852144876

Epoch: 6| Step: 13
Training loss: 0.5099718570709229
Validation loss: 2.27083690961202

Epoch: 512| Step: 0
Training loss: 0.5164016485214233
Validation loss: 2.313101847966512

Epoch: 6| Step: 1
Training loss: 0.44333067536354065
Validation loss: 2.2720107237497964

Epoch: 6| Step: 2
Training loss: 0.5878321528434753
Validation loss: 2.270452380180359

Epoch: 6| Step: 3
Training loss: 0.4910767078399658
Validation loss: 2.2892712354660034

Epoch: 6| Step: 4
Training loss: 0.8738046884536743
Validation loss: 2.2763783931732178

Epoch: 6| Step: 5
Training loss: 0.5266849994659424
Validation loss: 2.247087279955546

Epoch: 6| Step: 6
Training loss: 0.24648822844028473
Validation loss: 2.2612015207608542

Epoch: 6| Step: 7
Training loss: 0.8177261352539062
Validation loss: 2.237848083178202

Epoch: 6| Step: 8
Training loss: 0.612796425819397
Validation loss: 2.2828112840652466

Epoch: 6| Step: 9
Training loss: 0.754610002040863
Validation loss: 2.2586994568506875

Epoch: 6| Step: 10
Training loss: 0.7584593296051025
Validation loss: 2.2269689043362937

Epoch: 6| Step: 11
Training loss: 0.6269619464874268
Validation loss: 2.2284375627835593

Epoch: 6| Step: 12
Training loss: 0.7434126138687134
Validation loss: 2.1928174098332724

Epoch: 6| Step: 13
Training loss: 0.6557720899581909
Validation loss: 2.218493938446045

Epoch: 513| Step: 0
Training loss: 0.6938114762306213
Validation loss: 2.20598312218984

Epoch: 6| Step: 1
Training loss: 0.644770085811615
Validation loss: 2.2641156117121377

Epoch: 6| Step: 2
Training loss: 0.6773266792297363
Validation loss: 2.2416818340619407

Epoch: 6| Step: 3
Training loss: 0.48979058861732483
Validation loss: 2.2606480518976846

Epoch: 6| Step: 4
Training loss: 0.6965245604515076
Validation loss: 2.2009156147638955

Epoch: 6| Step: 5
Training loss: 0.3116328716278076
Validation loss: 2.207365572452545

Epoch: 6| Step: 6
Training loss: 0.6841533184051514
Validation loss: 2.2620408733685813

Epoch: 6| Step: 7
Training loss: 0.5564205646514893
Validation loss: 2.2353009978930154

Epoch: 6| Step: 8
Training loss: 1.0282901525497437
Validation loss: 2.255668858687083

Epoch: 6| Step: 9
Training loss: 0.7298778295516968
Validation loss: 2.2301057974497476

Epoch: 6| Step: 10
Training loss: 0.46119269728660583
Validation loss: 2.2281187375386557

Epoch: 6| Step: 11
Training loss: 0.7140942811965942
Validation loss: 2.249114175637563

Epoch: 6| Step: 12
Training loss: 0.6184614896774292
Validation loss: 2.2324965397516885

Epoch: 6| Step: 13
Training loss: 0.42770588397979736
Validation loss: 2.236161192258199

Epoch: 514| Step: 0
Training loss: 0.4513853192329407
Validation loss: 2.274221201737722

Epoch: 6| Step: 1
Training loss: 0.714828372001648
Validation loss: 2.2884183327356973

Epoch: 6| Step: 2
Training loss: 1.0593680143356323
Validation loss: 2.321491539478302

Epoch: 6| Step: 3
Training loss: 0.5121709704399109
Validation loss: 2.373775919278463

Epoch: 6| Step: 4
Training loss: 0.6950374245643616
Validation loss: 2.4044405221939087

Epoch: 6| Step: 5
Training loss: 0.7582850456237793
Validation loss: 2.279066244761149

Epoch: 6| Step: 6
Training loss: 0.2745647132396698
Validation loss: 2.2921331326166787

Epoch: 6| Step: 7
Training loss: 0.3124654293060303
Validation loss: 2.2860939304033914

Epoch: 6| Step: 8
Training loss: 0.729258120059967
Validation loss: 2.2402436335881553

Epoch: 6| Step: 9
Training loss: 0.7790560126304626
Validation loss: 2.2449369033177695

Epoch: 6| Step: 10
Training loss: 0.8383496999740601
Validation loss: 2.2730913758277893

Epoch: 6| Step: 11
Training loss: 0.8744547367095947
Validation loss: 2.2865531841913858

Epoch: 6| Step: 12
Training loss: 0.3020634055137634
Validation loss: 2.262085278828939

Epoch: 6| Step: 13
Training loss: 0.6396757960319519
Validation loss: 2.2516629497210183

Epoch: 515| Step: 0
Training loss: 0.8168195486068726
Validation loss: 2.271791378657023

Epoch: 6| Step: 1
Training loss: 0.5897913575172424
Validation loss: 2.3222199082374573

Epoch: 6| Step: 2
Training loss: 0.42905721068382263
Validation loss: 2.3207093477249146

Epoch: 6| Step: 3
Training loss: 0.5120643973350525
Validation loss: 2.3355703353881836

Epoch: 6| Step: 4
Training loss: 0.40388375520706177
Validation loss: 2.35764741897583

Epoch: 6| Step: 5
Training loss: 0.36601459980010986
Validation loss: 2.289391835530599

Epoch: 6| Step: 6
Training loss: 1.1171637773513794
Validation loss: 2.2792092760403952

Epoch: 6| Step: 7
Training loss: 0.4450647830963135
Validation loss: 2.3497276107470193

Epoch: 6| Step: 8
Training loss: 0.6674109697341919
Validation loss: 2.357076625029246

Epoch: 6| Step: 9
Training loss: 0.4669268727302551
Validation loss: 2.3441842595736184

Epoch: 6| Step: 10
Training loss: 0.9091297388076782
Validation loss: 2.3437101244926453

Epoch: 6| Step: 11
Training loss: 0.5828753113746643
Validation loss: 2.3820831974347434

Epoch: 6| Step: 12
Training loss: 0.5233689546585083
Validation loss: 2.317114988962809

Epoch: 6| Step: 13
Training loss: 0.6189568042755127
Validation loss: 2.271399219830831

Epoch: 516| Step: 0
Training loss: 0.7335266470909119
Validation loss: 2.334760308265686

Epoch: 6| Step: 1
Training loss: 1.227405309677124
Validation loss: 2.320697764555613

Epoch: 6| Step: 2
Training loss: 0.5008995532989502
Validation loss: 2.2628707885742188

Epoch: 6| Step: 3
Training loss: 0.31452494859695435
Validation loss: 2.2607401609420776

Epoch: 6| Step: 4
Training loss: 0.4152069687843323
Validation loss: 2.2610737085342407

Epoch: 6| Step: 5
Training loss: 0.2496206909418106
Validation loss: 2.266058365503947

Epoch: 6| Step: 6
Training loss: 0.5359498262405396
Validation loss: 2.283995489279429

Epoch: 6| Step: 7
Training loss: 0.582215428352356
Validation loss: 2.278603990872701

Epoch: 6| Step: 8
Training loss: 0.4000779688358307
Validation loss: 2.2642885049184165

Epoch: 6| Step: 9
Training loss: 0.7580583095550537
Validation loss: 2.3008445501327515

Epoch: 6| Step: 10
Training loss: 0.9803165197372437
Validation loss: 2.2490525046984353

Epoch: 6| Step: 11
Training loss: 0.8797189593315125
Validation loss: 2.2403454780578613

Epoch: 6| Step: 12
Training loss: 0.7980282306671143
Validation loss: 2.271074116230011

Epoch: 6| Step: 13
Training loss: 0.3894481360912323
Validation loss: 2.2533584038416543

Epoch: 517| Step: 0
Training loss: 0.4550818204879761
Validation loss: 2.2869211236635842

Epoch: 6| Step: 1
Training loss: 0.5191724300384521
Validation loss: 2.262697994709015

Epoch: 6| Step: 2
Training loss: 0.32477590441703796
Validation loss: 2.293518046538035

Epoch: 6| Step: 3
Training loss: 0.5210468769073486
Validation loss: 2.3062933683395386

Epoch: 6| Step: 4
Training loss: 0.4375649690628052
Validation loss: 2.2729361057281494

Epoch: 6| Step: 5
Training loss: 0.245267853140831
Validation loss: 2.2638317743937173

Epoch: 6| Step: 6
Training loss: 0.8571990728378296
Validation loss: 2.2796034614245095

Epoch: 6| Step: 7
Training loss: 0.8058156967163086
Validation loss: 2.303685506184896

Epoch: 6| Step: 8
Training loss: 0.5025913119316101
Validation loss: 2.317406256993612

Epoch: 6| Step: 9
Training loss: 0.5205520391464233
Validation loss: 2.3308000564575195

Epoch: 6| Step: 10
Training loss: 0.5492145419120789
Validation loss: 2.2890970706939697

Epoch: 6| Step: 11
Training loss: 1.0172735452651978
Validation loss: 2.3136317133903503

Epoch: 6| Step: 12
Training loss: 1.1301394701004028
Validation loss: 2.3300426801045737

Epoch: 6| Step: 13
Training loss: 1.0277760028839111
Validation loss: 2.2636932929356894

Epoch: 518| Step: 0
Training loss: 0.5961689949035645
Validation loss: 2.29288379351298

Epoch: 6| Step: 1
Training loss: 0.5077781081199646
Validation loss: 2.3166940808296204

Epoch: 6| Step: 2
Training loss: 0.5678367018699646
Validation loss: 2.3092875281969705

Epoch: 6| Step: 3
Training loss: 0.504328191280365
Validation loss: 2.3275482654571533

Epoch: 6| Step: 4
Training loss: 0.3862898647785187
Validation loss: 2.283275524775187

Epoch: 6| Step: 5
Training loss: 0.6438107490539551
Validation loss: 2.2949695587158203

Epoch: 6| Step: 6
Training loss: 0.62087082862854
Validation loss: 2.308883527914683

Epoch: 6| Step: 7
Training loss: 0.7254012823104858
Validation loss: 2.2866293589274087

Epoch: 6| Step: 8
Training loss: 0.9811446666717529
Validation loss: 2.288021147251129

Epoch: 6| Step: 9
Training loss: 0.7210127115249634
Validation loss: 2.27664585908254

Epoch: 6| Step: 10
Training loss: 0.42862677574157715
Validation loss: 2.2287709514300027

Epoch: 6| Step: 11
Training loss: 0.3532315492630005
Validation loss: 2.2178821563720703

Epoch: 6| Step: 12
Training loss: 0.8067301511764526
Validation loss: 2.224623143672943

Epoch: 6| Step: 13
Training loss: 1.273381233215332
Validation loss: 2.2809253931045532

Epoch: 519| Step: 0
Training loss: 0.8356660008430481
Validation loss: 2.2938715616861978

Epoch: 6| Step: 1
Training loss: 0.611369252204895
Validation loss: 2.2878916263580322

Epoch: 6| Step: 2
Training loss: 0.44014376401901245
Validation loss: 2.276366432507833

Epoch: 6| Step: 3
Training loss: 0.5254940390586853
Validation loss: 2.2699740727742515

Epoch: 6| Step: 4
Training loss: 0.3982793092727661
Validation loss: 2.292441705862681

Epoch: 6| Step: 5
Training loss: 0.7093126177787781
Validation loss: 2.311712920665741

Epoch: 6| Step: 6
Training loss: 0.7451258897781372
Validation loss: 2.276116927464803

Epoch: 6| Step: 7
Training loss: 0.4802492558956146
Validation loss: 2.3181506792704263

Epoch: 6| Step: 8
Training loss: 0.7474859952926636
Validation loss: 2.2985138495763144

Epoch: 6| Step: 9
Training loss: 0.3929199278354645
Validation loss: 2.2775208950042725

Epoch: 6| Step: 10
Training loss: 0.4419938027858734
Validation loss: 2.347126384576162

Epoch: 6| Step: 11
Training loss: 0.770279049873352
Validation loss: 2.2652936379114785

Epoch: 6| Step: 12
Training loss: 1.1339671611785889
Validation loss: 2.2670806845029197

Epoch: 6| Step: 13
Training loss: 0.47728806734085083
Validation loss: 2.268882950146993

Epoch: 520| Step: 0
Training loss: 0.20986798405647278
Validation loss: 2.2621201872825623

Epoch: 6| Step: 1
Training loss: 0.5744473934173584
Validation loss: 2.257588565349579

Epoch: 6| Step: 2
Training loss: 0.7081450819969177
Validation loss: 2.294752915700277

Epoch: 6| Step: 3
Training loss: 0.7027182579040527
Validation loss: 2.302335739135742

Epoch: 6| Step: 4
Training loss: 0.7507013082504272
Validation loss: 2.2615193724632263

Epoch: 6| Step: 5
Training loss: 0.694982647895813
Validation loss: 2.286603331565857

Epoch: 6| Step: 6
Training loss: 0.5535660982131958
Validation loss: 2.257452408472697

Epoch: 6| Step: 7
Training loss: 0.7414969801902771
Validation loss: 2.31010240316391

Epoch: 6| Step: 8
Training loss: 0.7064712047576904
Validation loss: 2.272655447324117

Epoch: 6| Step: 9
Training loss: 0.45901060104370117
Validation loss: 2.2881686886151633

Epoch: 6| Step: 10
Training loss: 0.791537344455719
Validation loss: 2.286877234776815

Epoch: 6| Step: 11
Training loss: 0.2189757525920868
Validation loss: 2.277298013369242

Epoch: 6| Step: 12
Training loss: 0.7188109159469604
Validation loss: 2.2688673933347068

Epoch: 6| Step: 13
Training loss: 0.8280432224273682
Validation loss: 2.1836254596710205

Epoch: 521| Step: 0
Training loss: 0.844406008720398
Validation loss: 2.2036337653795877

Epoch: 6| Step: 1
Training loss: 0.8588675260543823
Validation loss: 2.1985753774642944

Epoch: 6| Step: 2
Training loss: 0.5152936577796936
Validation loss: 2.227224131425222

Epoch: 6| Step: 3
Training loss: 0.7067580223083496
Validation loss: 2.2212135195732117

Epoch: 6| Step: 4
Training loss: 1.1753120422363281
Validation loss: 2.2562289436658225

Epoch: 6| Step: 5
Training loss: 0.5346617698669434
Validation loss: 2.190947949886322

Epoch: 6| Step: 6
Training loss: 0.49289852380752563
Validation loss: 2.243029475212097

Epoch: 6| Step: 7
Training loss: 0.40489983558654785
Validation loss: 2.2073464592297873

Epoch: 6| Step: 8
Training loss: 0.821164071559906
Validation loss: 2.231892168521881

Epoch: 6| Step: 9
Training loss: 0.49959611892700195
Validation loss: 2.243464410305023

Epoch: 6| Step: 10
Training loss: 0.2802659571170807
Validation loss: 2.196425755818685

Epoch: 6| Step: 11
Training loss: 0.7978810667991638
Validation loss: 2.196861128012339

Epoch: 6| Step: 12
Training loss: 0.3623742163181305
Validation loss: 2.19262166817983

Epoch: 6| Step: 13
Training loss: 0.6020529866218567
Validation loss: 2.2539003690083823

Epoch: 522| Step: 0
Training loss: 0.574598491191864
Validation loss: 2.289605677127838

Epoch: 6| Step: 1
Training loss: 0.5461509227752686
Validation loss: 2.3025686939557395

Epoch: 6| Step: 2
Training loss: 0.8624823093414307
Validation loss: 2.294967790444692

Epoch: 6| Step: 3
Training loss: 0.5933791995048523
Validation loss: 2.2639254927635193

Epoch: 6| Step: 4
Training loss: 0.627600371837616
Validation loss: 2.272143761316935

Epoch: 6| Step: 5
Training loss: 1.0016865730285645
Validation loss: 2.292804539203644

Epoch: 6| Step: 6
Training loss: 0.3137800693511963
Validation loss: 2.2325389782587686

Epoch: 6| Step: 7
Training loss: 0.3691967725753784
Validation loss: 2.2333149313926697

Epoch: 6| Step: 8
Training loss: 0.6833164691925049
Validation loss: 2.2550635735193887

Epoch: 6| Step: 9
Training loss: 0.7990660667419434
Validation loss: 2.211583375930786

Epoch: 6| Step: 10
Training loss: 0.6735639572143555
Validation loss: 2.198816498120626

Epoch: 6| Step: 11
Training loss: 0.7675122022628784
Validation loss: 2.246452828248342

Epoch: 6| Step: 12
Training loss: 0.5592607855796814
Validation loss: 2.2682266235351562

Epoch: 6| Step: 13
Training loss: 0.42454856634140015
Validation loss: 2.25192391872406

Epoch: 523| Step: 0
Training loss: 0.38379359245300293
Validation loss: 2.2693426609039307

Epoch: 6| Step: 1
Training loss: 0.30787190794944763
Validation loss: 2.29567152261734

Epoch: 6| Step: 2
Training loss: 0.34474384784698486
Validation loss: 2.245534062385559

Epoch: 6| Step: 3
Training loss: 0.7526805400848389
Validation loss: 2.3367968797683716

Epoch: 6| Step: 4
Training loss: 0.40217745304107666
Validation loss: 2.252171814441681

Epoch: 6| Step: 5
Training loss: 0.5185832381248474
Validation loss: 2.2961330016454062

Epoch: 6| Step: 6
Training loss: 0.910834789276123
Validation loss: 2.2910565932591758

Epoch: 6| Step: 7
Training loss: 0.45617857575416565
Validation loss: 2.3269514441490173

Epoch: 6| Step: 8
Training loss: 0.35162490606307983
Validation loss: 2.272980272769928

Epoch: 6| Step: 9
Training loss: 0.9622321128845215
Validation loss: 2.280620356400808

Epoch: 6| Step: 10
Training loss: 1.1543622016906738
Validation loss: 2.3025829593340554

Epoch: 6| Step: 11
Training loss: 0.43807148933410645
Validation loss: 2.305863300959269

Epoch: 6| Step: 12
Training loss: 0.6240652799606323
Validation loss: 2.2648602724075317

Epoch: 6| Step: 13
Training loss: 0.8796552419662476
Validation loss: 2.2935980558395386

Epoch: 524| Step: 0
Training loss: 0.23719047009944916
Validation loss: 2.341634829839071

Epoch: 6| Step: 1
Training loss: 0.3178987503051758
Validation loss: 2.3167788982391357

Epoch: 6| Step: 2
Training loss: 0.6393148303031921
Validation loss: 2.3344388405481973

Epoch: 6| Step: 3
Training loss: 0.38930436968803406
Validation loss: 2.3109216690063477

Epoch: 6| Step: 4
Training loss: 1.45396089553833
Validation loss: 2.305026888847351

Epoch: 6| Step: 5
Training loss: 0.4270126223564148
Validation loss: 2.2564773758252463

Epoch: 6| Step: 6
Training loss: 0.320182204246521
Validation loss: 2.284184137980143

Epoch: 6| Step: 7
Training loss: 0.5151799917221069
Validation loss: 2.2773074905077615

Epoch: 6| Step: 8
Training loss: 0.425033837556839
Validation loss: 2.2516168554623923

Epoch: 6| Step: 9
Training loss: 0.5779737830162048
Validation loss: 2.26787531375885

Epoch: 6| Step: 10
Training loss: 0.7779609560966492
Validation loss: 2.2599409222602844

Epoch: 6| Step: 11
Training loss: 0.701189398765564
Validation loss: 2.279519736766815

Epoch: 6| Step: 12
Training loss: 0.7536811828613281
Validation loss: 2.278346319993337

Epoch: 6| Step: 13
Training loss: 0.8501123189926147
Validation loss: 2.3026477495829263

Epoch: 525| Step: 0
Training loss: 0.8503202199935913
Validation loss: 2.27319989601771

Epoch: 6| Step: 1
Training loss: 0.8603619337081909
Validation loss: 2.2941452264785767

Epoch: 6| Step: 2
Training loss: 0.5485484004020691
Validation loss: 2.2909547487894693

Epoch: 6| Step: 3
Training loss: 0.4155845642089844
Validation loss: 2.2601370016733804

Epoch: 6| Step: 4
Training loss: 0.3804195821285248
Validation loss: 2.2863203287124634

Epoch: 6| Step: 5
Training loss: 0.1708216816186905
Validation loss: 2.275045911471049

Epoch: 6| Step: 6
Training loss: 0.5700910687446594
Validation loss: 2.2306155959765115

Epoch: 6| Step: 7
Training loss: 0.5829176902770996
Validation loss: 2.253158768018087

Epoch: 6| Step: 8
Training loss: 0.6884716749191284
Validation loss: 2.225811541080475

Epoch: 6| Step: 9
Training loss: 0.7755398750305176
Validation loss: 2.2330920894940696

Epoch: 6| Step: 10
Training loss: 0.7875560522079468
Validation loss: 2.256945013999939

Epoch: 6| Step: 11
Training loss: 0.48298272490501404
Validation loss: 2.296535054842631

Epoch: 6| Step: 12
Training loss: 0.2623872756958008
Validation loss: 2.2282433907190957

Epoch: 6| Step: 13
Training loss: 0.8172511458396912
Validation loss: 2.239336828390757

Epoch: 526| Step: 0
Training loss: 0.48604947328567505
Validation loss: 2.2754066785176597

Epoch: 6| Step: 1
Training loss: 0.29142048954963684
Validation loss: 2.251716057459513

Epoch: 6| Step: 2
Training loss: 0.2668262720108032
Validation loss: 2.2964139382044473

Epoch: 6| Step: 3
Training loss: 0.6252384781837463
Validation loss: 2.28762016693751

Epoch: 6| Step: 4
Training loss: 0.4445522427558899
Validation loss: 2.3287480672200522

Epoch: 6| Step: 5
Training loss: 0.33933937549591064
Validation loss: 2.3541991909344993

Epoch: 6| Step: 6
Training loss: 0.3531395494937897
Validation loss: 2.3555596669514975

Epoch: 6| Step: 7
Training loss: 0.7524306774139404
Validation loss: 2.3654090563456216

Epoch: 6| Step: 8
Training loss: 0.399431049823761
Validation loss: 2.3377498984336853

Epoch: 6| Step: 9
Training loss: 0.7046183943748474
Validation loss: 2.265995979309082

Epoch: 6| Step: 10
Training loss: 1.1326842308044434
Validation loss: 2.326048036416372

Epoch: 6| Step: 11
Training loss: 1.1207787990570068
Validation loss: 2.3056558767954507

Epoch: 6| Step: 12
Training loss: 0.44150686264038086
Validation loss: 2.3187294006347656

Epoch: 6| Step: 13
Training loss: 0.734791100025177
Validation loss: 2.3311831951141357

Epoch: 527| Step: 0
Training loss: 0.882910966873169
Validation loss: 2.3352306286493936

Epoch: 6| Step: 1
Training loss: 0.3165779113769531
Validation loss: 2.367663582166036

Epoch: 6| Step: 2
Training loss: 0.9813151359558105
Validation loss: 2.30500590801239

Epoch: 6| Step: 3
Training loss: 0.28654706478118896
Validation loss: 2.2798768281936646

Epoch: 6| Step: 4
Training loss: 0.37620237469673157
Validation loss: 2.281794528166453

Epoch: 6| Step: 5
Training loss: 0.336694598197937
Validation loss: 2.308893342812856

Epoch: 6| Step: 6
Training loss: 0.8966033458709717
Validation loss: 2.2769630750020347

Epoch: 6| Step: 7
Training loss: 0.5393991470336914
Validation loss: 2.3110031684239707

Epoch: 6| Step: 8
Training loss: 0.38768690824508667
Validation loss: 2.265609383583069

Epoch: 6| Step: 9
Training loss: 1.2454898357391357
Validation loss: 2.3063493967056274

Epoch: 6| Step: 10
Training loss: 0.3727705478668213
Validation loss: 2.300603707631429

Epoch: 6| Step: 11
Training loss: 0.45106735825538635
Validation loss: 2.30558971563975

Epoch: 6| Step: 12
Training loss: 0.7092494964599609
Validation loss: 2.3231202761332193

Epoch: 6| Step: 13
Training loss: 0.5772650241851807
Validation loss: 2.3220661083857217

Epoch: 528| Step: 0
Training loss: 0.42764708399772644
Validation loss: 2.298644006252289

Epoch: 6| Step: 1
Training loss: 0.8745030164718628
Validation loss: 2.268704811731974

Epoch: 6| Step: 2
Training loss: 0.9927828311920166
Validation loss: 2.3078872760136924

Epoch: 6| Step: 3
Training loss: 0.21551603078842163
Validation loss: 2.278536001841227

Epoch: 6| Step: 4
Training loss: 0.7494761943817139
Validation loss: 2.2546953161557517

Epoch: 6| Step: 5
Training loss: 0.5927838683128357
Validation loss: 2.2573474446932473

Epoch: 6| Step: 6
Training loss: 0.32949572801589966
Validation loss: 2.3133764266967773

Epoch: 6| Step: 7
Training loss: 0.3716626465320587
Validation loss: 2.325277845064799

Epoch: 6| Step: 8
Training loss: 0.38939666748046875
Validation loss: 2.2348248759905496

Epoch: 6| Step: 9
Training loss: 0.467082142829895
Validation loss: 2.3413731257120767

Epoch: 6| Step: 10
Training loss: 0.4407700300216675
Validation loss: 2.343792716662089

Epoch: 6| Step: 11
Training loss: 0.9145212173461914
Validation loss: 2.3754975994428

Epoch: 6| Step: 12
Training loss: 0.7596549391746521
Validation loss: 2.3261707425117493

Epoch: 6| Step: 13
Training loss: 0.550416886806488
Validation loss: 2.275808036327362

Epoch: 529| Step: 0
Training loss: 0.42010536789894104
Validation loss: 2.3048173983891806

Epoch: 6| Step: 1
Training loss: 0.5842068195343018
Validation loss: 2.2473318775494895

Epoch: 6| Step: 2
Training loss: 0.7039901614189148
Validation loss: 2.2491063872973123

Epoch: 6| Step: 3
Training loss: 0.5770654678344727
Validation loss: 2.246602733929952

Epoch: 6| Step: 4
Training loss: 0.6791543960571289
Validation loss: 2.270696739355723

Epoch: 6| Step: 5
Training loss: 0.4341360032558441
Validation loss: 2.305578112602234

Epoch: 6| Step: 6
Training loss: 0.662844181060791
Validation loss: 2.2993544737497964

Epoch: 6| Step: 7
Training loss: 1.1407127380371094
Validation loss: 2.3433383901913962

Epoch: 6| Step: 8
Training loss: 0.6540396213531494
Validation loss: 2.337080438931783

Epoch: 6| Step: 9
Training loss: 0.6139422059059143
Validation loss: 2.312221884727478

Epoch: 6| Step: 10
Training loss: 0.7789347767829895
Validation loss: 2.3287808895111084

Epoch: 6| Step: 11
Training loss: 0.3792892396450043
Validation loss: 2.293006936709086

Epoch: 6| Step: 12
Training loss: 0.5125794410705566
Validation loss: 2.291365166505178

Epoch: 6| Step: 13
Training loss: 0.5352389812469482
Validation loss: 2.2827155788739524

Epoch: 530| Step: 0
Training loss: 0.6945012807846069
Validation loss: 2.292854110399882

Epoch: 6| Step: 1
Training loss: 0.4702944755554199
Validation loss: 2.2898290952046714

Epoch: 6| Step: 2
Training loss: 0.8907848596572876
Validation loss: 2.2884758909543357

Epoch: 6| Step: 3
Training loss: 0.18518555164337158
Validation loss: 2.301738222440084

Epoch: 6| Step: 4
Training loss: 0.9489908218383789
Validation loss: 2.3387696743011475

Epoch: 6| Step: 5
Training loss: 0.634824275970459
Validation loss: 2.3311863342920938

Epoch: 6| Step: 6
Training loss: 0.4786207675933838
Validation loss: 2.341970523198446

Epoch: 6| Step: 7
Training loss: 0.6381363868713379
Validation loss: 2.3167263070742288

Epoch: 6| Step: 8
Training loss: 1.0157064199447632
Validation loss: 2.3373055855433145

Epoch: 6| Step: 9
Training loss: 0.2738364338874817
Validation loss: 2.2955813805262246

Epoch: 6| Step: 10
Training loss: 0.8082807064056396
Validation loss: 2.273762583732605

Epoch: 6| Step: 11
Training loss: 0.3937300741672516
Validation loss: 2.284513612588247

Epoch: 6| Step: 12
Training loss: 0.6289891600608826
Validation loss: 2.2551604906717935

Epoch: 6| Step: 13
Training loss: 0.3626047968864441
Validation loss: 2.279894987742106

Epoch: 531| Step: 0
Training loss: 0.35013481974601746
Validation loss: 2.2975112994511924

Epoch: 6| Step: 1
Training loss: 0.5372527241706848
Validation loss: 2.3071749210357666

Epoch: 6| Step: 2
Training loss: 0.6433928608894348
Validation loss: 2.3503671089808145

Epoch: 6| Step: 3
Training loss: 0.678196907043457
Validation loss: 2.31811652580897

Epoch: 6| Step: 4
Training loss: 0.28725963830947876
Validation loss: 2.331959068775177

Epoch: 6| Step: 5
Training loss: 0.4196462333202362
Validation loss: 2.297479271888733

Epoch: 6| Step: 6
Training loss: 0.34969615936279297
Validation loss: 2.289561629295349

Epoch: 6| Step: 7
Training loss: 0.3989914655685425
Validation loss: 2.22458815574646

Epoch: 6| Step: 8
Training loss: 0.5604909658432007
Validation loss: 2.2600879669189453

Epoch: 6| Step: 9
Training loss: 1.2123451232910156
Validation loss: 2.309389352798462

Epoch: 6| Step: 10
Training loss: 0.8956277370452881
Validation loss: 2.308202544848124

Epoch: 6| Step: 11
Training loss: 0.3633230924606323
Validation loss: 2.2938249707221985

Epoch: 6| Step: 12
Training loss: 0.40291547775268555
Validation loss: 2.253852923711141

Epoch: 6| Step: 13
Training loss: 1.3330851793289185
Validation loss: 2.2645089626312256

Epoch: 532| Step: 0
Training loss: 0.3833886981010437
Validation loss: 2.2917388876279197

Epoch: 6| Step: 1
Training loss: 1.0041853189468384
Validation loss: 2.311866124471029

Epoch: 6| Step: 2
Training loss: 0.5090572237968445
Validation loss: 2.2594461838404336

Epoch: 6| Step: 3
Training loss: 0.3947213888168335
Validation loss: 2.340364654858907

Epoch: 6| Step: 4
Training loss: 0.35947489738464355
Validation loss: 2.2810813387235007

Epoch: 6| Step: 5
Training loss: 0.5578982830047607
Validation loss: 2.261293053627014

Epoch: 6| Step: 6
Training loss: 0.48987674713134766
Validation loss: 2.301789919535319

Epoch: 6| Step: 7
Training loss: 0.49795717000961304
Validation loss: 2.298464278380076

Epoch: 6| Step: 8
Training loss: 1.0955373048782349
Validation loss: 2.2561667760213218

Epoch: 6| Step: 9
Training loss: 0.7667956352233887
Validation loss: 2.291710615158081

Epoch: 6| Step: 10
Training loss: 0.7014423608779907
Validation loss: 2.290210008621216

Epoch: 6| Step: 11
Training loss: 0.46712297201156616
Validation loss: 2.349391976992289

Epoch: 6| Step: 12
Training loss: 0.4587160348892212
Validation loss: 2.303637901941935

Epoch: 6| Step: 13
Training loss: 0.97193443775177
Validation loss: 2.2446265618006387

Epoch: 533| Step: 0
Training loss: 0.3776293396949768
Validation loss: 2.3021497329076133

Epoch: 6| Step: 1
Training loss: 0.5665618181228638
Validation loss: 2.2524816393852234

Epoch: 6| Step: 2
Training loss: 0.3609340190887451
Validation loss: 2.284763276576996

Epoch: 6| Step: 3
Training loss: 0.35308587551116943
Validation loss: 2.2741647561391196

Epoch: 6| Step: 4
Training loss: 0.6497218608856201
Validation loss: 2.283047358194987

Epoch: 6| Step: 5
Training loss: 0.6427947282791138
Validation loss: 2.2294934590657554

Epoch: 6| Step: 6
Training loss: 0.9693629741668701
Validation loss: 2.238415459791819

Epoch: 6| Step: 7
Training loss: 0.5192272663116455
Validation loss: 2.255025029182434

Epoch: 6| Step: 8
Training loss: 0.8597143292427063
Validation loss: 2.2701064348220825

Epoch: 6| Step: 9
Training loss: 0.5445519089698792
Validation loss: 2.297120670477549

Epoch: 6| Step: 10
Training loss: 0.5256567001342773
Validation loss: 2.2732978661855063

Epoch: 6| Step: 11
Training loss: 0.39446523785591125
Validation loss: 2.2947694063186646

Epoch: 6| Step: 12
Training loss: 0.9069977402687073
Validation loss: 2.2461931705474854

Epoch: 6| Step: 13
Training loss: 0.9502121210098267
Validation loss: 2.2375648816426597

Epoch: 534| Step: 0
Training loss: 0.3580778241157532
Validation loss: 2.2091362476348877

Epoch: 6| Step: 1
Training loss: 0.7589898109436035
Validation loss: 2.266321897506714

Epoch: 6| Step: 2
Training loss: 0.3086455166339874
Validation loss: 2.241343379020691

Epoch: 6| Step: 3
Training loss: 0.7173131704330444
Validation loss: 2.2775355180104575

Epoch: 6| Step: 4
Training loss: 0.30599337816238403
Validation loss: 2.305432617664337

Epoch: 6| Step: 5
Training loss: 0.4043349027633667
Validation loss: 2.288122852643331

Epoch: 6| Step: 6
Training loss: 0.6714881658554077
Validation loss: 2.2777260541915894

Epoch: 6| Step: 7
Training loss: 0.7776821255683899
Validation loss: 2.286263346672058

Epoch: 6| Step: 8
Training loss: 0.7527519464492798
Validation loss: 2.2704363465309143

Epoch: 6| Step: 9
Training loss: 0.23935699462890625
Validation loss: 2.253952165444692

Epoch: 6| Step: 10
Training loss: 1.0966572761535645
Validation loss: 2.214945395787557

Epoch: 6| Step: 11
Training loss: 0.3314935266971588
Validation loss: 2.2557125091552734

Epoch: 6| Step: 12
Training loss: 0.29435908794403076
Validation loss: 2.2543267806371055

Epoch: 6| Step: 13
Training loss: 0.8413655757904053
Validation loss: 2.253935158252716

Epoch: 535| Step: 0
Training loss: 0.8817521333694458
Validation loss: 2.3145972887674966

Epoch: 6| Step: 1
Training loss: 1.0990477800369263
Validation loss: 2.2650739351908364

Epoch: 6| Step: 2
Training loss: 1.0488617420196533
Validation loss: 2.2964998881022134

Epoch: 6| Step: 3
Training loss: 0.49743086099624634
Validation loss: 2.2814658880233765

Epoch: 6| Step: 4
Training loss: 0.4289062023162842
Validation loss: 2.3398138086001077

Epoch: 6| Step: 5
Training loss: 0.18087926506996155
Validation loss: 2.3296008507410684

Epoch: 6| Step: 6
Training loss: 0.31040775775909424
Validation loss: 2.3075824975967407

Epoch: 6| Step: 7
Training loss: 0.444691002368927
Validation loss: 2.311996420224508

Epoch: 6| Step: 8
Training loss: 0.4741619825363159
Validation loss: 2.327838977177938

Epoch: 6| Step: 9
Training loss: 0.35941970348358154
Validation loss: 2.2994657158851624

Epoch: 6| Step: 10
Training loss: 0.5192192196846008
Validation loss: 2.2967759370803833

Epoch: 6| Step: 11
Training loss: 0.5292714834213257
Validation loss: 2.29157292842865

Epoch: 6| Step: 12
Training loss: 0.6489761471748352
Validation loss: 2.2537254095077515

Epoch: 6| Step: 13
Training loss: 0.2918927073478699
Validation loss: 2.3113103906313577

Epoch: 536| Step: 0
Training loss: 0.6272544860839844
Validation loss: 2.287954250971476

Epoch: 6| Step: 1
Training loss: 0.858821451663971
Validation loss: 2.2442060112953186

Epoch: 6| Step: 2
Training loss: 0.9675736427307129
Validation loss: 2.271533409754435

Epoch: 6| Step: 3
Training loss: 0.20795606076717377
Validation loss: 2.322420040766398

Epoch: 6| Step: 4
Training loss: 0.2815394103527069
Validation loss: 2.303405463695526

Epoch: 6| Step: 5
Training loss: 0.25641822814941406
Validation loss: 2.2599517504374185

Epoch: 6| Step: 6
Training loss: 0.46527528762817383
Validation loss: 2.2915961941083274

Epoch: 6| Step: 7
Training loss: 0.46476390957832336
Validation loss: 2.315254727999369

Epoch: 6| Step: 8
Training loss: 0.5751962661743164
Validation loss: 2.3150527477264404

Epoch: 6| Step: 9
Training loss: 0.6314257383346558
Validation loss: 2.334426204363505

Epoch: 6| Step: 10
Training loss: 0.6938071846961975
Validation loss: 2.253207504749298

Epoch: 6| Step: 11
Training loss: 0.45778483152389526
Validation loss: 2.259491046269735

Epoch: 6| Step: 12
Training loss: 0.6290138363838196
Validation loss: 2.314061681429545

Epoch: 6| Step: 13
Training loss: 0.669596791267395
Validation loss: 2.3103313048680625

Epoch: 537| Step: 0
Training loss: 0.44908106327056885
Validation loss: 2.3080606857935586

Epoch: 6| Step: 1
Training loss: 0.4932534694671631
Validation loss: 2.3178498347600303

Epoch: 6| Step: 2
Training loss: 0.7209287881851196
Validation loss: 2.3127505580584207

Epoch: 6| Step: 3
Training loss: 0.32486119866371155
Validation loss: 2.2948632637659707

Epoch: 6| Step: 4
Training loss: 0.65743088722229
Validation loss: 2.3196712136268616

Epoch: 6| Step: 5
Training loss: 0.3836691677570343
Validation loss: 2.331903636455536

Epoch: 6| Step: 6
Training loss: 0.7301602363586426
Validation loss: 2.332430044809977

Epoch: 6| Step: 7
Training loss: 0.623755693435669
Validation loss: 2.349896808465322

Epoch: 6| Step: 8
Training loss: 0.7614550590515137
Validation loss: 2.2961235443751016

Epoch: 6| Step: 9
Training loss: 0.4347497522830963
Validation loss: 2.2743616700172424

Epoch: 6| Step: 10
Training loss: 0.38407102227211
Validation loss: 2.2953128019968667

Epoch: 6| Step: 11
Training loss: 1.0198835134506226
Validation loss: 2.2566051681836448

Epoch: 6| Step: 12
Training loss: 0.593472957611084
Validation loss: 2.3058058818181357

Epoch: 6| Step: 13
Training loss: 0.27873122692108154
Validation loss: 2.268971542517344

Epoch: 538| Step: 0
Training loss: 0.4345821738243103
Validation loss: 2.2793049017588296

Epoch: 6| Step: 1
Training loss: 0.46603628993034363
Validation loss: 2.270164728164673

Epoch: 6| Step: 2
Training loss: 0.5268467664718628
Validation loss: 2.310120244820913

Epoch: 6| Step: 3
Training loss: 0.5692564249038696
Validation loss: 2.295024037361145

Epoch: 6| Step: 4
Training loss: 0.6110601425170898
Validation loss: 2.2910882234573364

Epoch: 6| Step: 5
Training loss: 0.5219403505325317
Validation loss: 2.3133803606033325

Epoch: 6| Step: 6
Training loss: 0.5787152051925659
Validation loss: 2.2885565757751465

Epoch: 6| Step: 7
Training loss: 0.4236828088760376
Validation loss: 2.276102821032206

Epoch: 6| Step: 8
Training loss: 0.6383576393127441
Validation loss: 2.2666109005610147

Epoch: 6| Step: 9
Training loss: 0.7931203246116638
Validation loss: 2.2730915347735086

Epoch: 6| Step: 10
Training loss: 0.42861053347587585
Validation loss: 2.20284104347229

Epoch: 6| Step: 11
Training loss: 0.7388929128646851
Validation loss: 2.267112056414286

Epoch: 6| Step: 12
Training loss: 0.3598331809043884
Validation loss: 2.2991730769475303

Epoch: 6| Step: 13
Training loss: 0.851569652557373
Validation loss: 2.2892239888509116

Epoch: 539| Step: 0
Training loss: 0.695871889591217
Validation loss: 2.2817326188087463

Epoch: 6| Step: 1
Training loss: 0.836462140083313
Validation loss: 2.262775460879008

Epoch: 6| Step: 2
Training loss: 0.7505749464035034
Validation loss: 2.263635834058126

Epoch: 6| Step: 3
Training loss: 0.27426856756210327
Validation loss: 2.2719263434410095

Epoch: 6| Step: 4
Training loss: 0.5291622877120972
Validation loss: 2.234809676806132

Epoch: 6| Step: 5
Training loss: 0.2580622732639313
Validation loss: 2.294864515463511

Epoch: 6| Step: 6
Training loss: 0.39735323190689087
Validation loss: 2.2455087900161743

Epoch: 6| Step: 7
Training loss: 0.8331185579299927
Validation loss: 2.2819425662358603

Epoch: 6| Step: 8
Training loss: 0.4367988109588623
Validation loss: 2.299927314122518

Epoch: 6| Step: 9
Training loss: 0.3247823119163513
Validation loss: 2.3377713362375894

Epoch: 6| Step: 10
Training loss: 0.5698744654655457
Validation loss: 2.2645596663157144

Epoch: 6| Step: 11
Training loss: 1.2714667320251465
Validation loss: 2.3224451144536338

Epoch: 6| Step: 12
Training loss: 0.45169538259506226
Validation loss: 2.279459774494171

Epoch: 6| Step: 13
Training loss: 0.4364588260650635
Validation loss: 2.276678204536438

Epoch: 540| Step: 0
Training loss: 0.8219515085220337
Validation loss: 2.310774803161621

Epoch: 6| Step: 1
Training loss: 0.3293705880641937
Validation loss: 2.2988472978274026

Epoch: 6| Step: 2
Training loss: 0.5171293616294861
Validation loss: 2.249558130900065

Epoch: 6| Step: 3
Training loss: 0.5234614610671997
Validation loss: 2.3147557973861694

Epoch: 6| Step: 4
Training loss: 0.7539731860160828
Validation loss: 2.3251072565714517

Epoch: 6| Step: 5
Training loss: 0.4001248776912689
Validation loss: 2.3083064953486123

Epoch: 6| Step: 6
Training loss: 0.9111239910125732
Validation loss: 2.3363685806592307

Epoch: 6| Step: 7
Training loss: 0.5085962414741516
Validation loss: 2.3304490645726523

Epoch: 6| Step: 8
Training loss: 0.9081079959869385
Validation loss: 2.3390088081359863

Epoch: 6| Step: 9
Training loss: 0.4451795816421509
Validation loss: 2.3704559803009033

Epoch: 6| Step: 10
Training loss: 0.34836071729660034
Validation loss: 2.350284238656362

Epoch: 6| Step: 11
Training loss: 0.42231109738349915
Validation loss: 2.2975972096125283

Epoch: 6| Step: 12
Training loss: 0.2894972264766693
Validation loss: 2.321466545263926

Epoch: 6| Step: 13
Training loss: 0.6972005367279053
Validation loss: 2.2807087103525796

Epoch: 541| Step: 0
Training loss: 0.7430284023284912
Validation loss: 2.3319454391797385

Epoch: 6| Step: 1
Training loss: 0.9854495525360107
Validation loss: 2.332932233810425

Epoch: 6| Step: 2
Training loss: 0.3607582449913025
Validation loss: 2.2937011321385703

Epoch: 6| Step: 3
Training loss: 0.4992585778236389
Validation loss: 2.2773706118265786

Epoch: 6| Step: 4
Training loss: 0.25163841247558594
Validation loss: 2.3101362784703574

Epoch: 6| Step: 5
Training loss: 0.629497766494751
Validation loss: 2.3282282749811807

Epoch: 6| Step: 6
Training loss: 0.7146793603897095
Validation loss: 2.359818418820699

Epoch: 6| Step: 7
Training loss: 0.9478673338890076
Validation loss: 2.3600431283315024

Epoch: 6| Step: 8
Training loss: 0.3781470060348511
Validation loss: 2.298893610636393

Epoch: 6| Step: 9
Training loss: 0.6733625531196594
Validation loss: 2.2515792846679688

Epoch: 6| Step: 10
Training loss: 0.34159964323043823
Validation loss: 2.2515007853507996

Epoch: 6| Step: 11
Training loss: 0.3380902111530304
Validation loss: 2.2598291635513306

Epoch: 6| Step: 12
Training loss: 0.6326591372489929
Validation loss: 2.2908862034479776

Epoch: 6| Step: 13
Training loss: 0.9243520498275757
Validation loss: 2.2831581234931946

Epoch: 542| Step: 0
Training loss: 1.037184715270996
Validation loss: 2.307341456413269

Epoch: 6| Step: 1
Training loss: 0.5641937255859375
Validation loss: 2.297297497590383

Epoch: 6| Step: 2
Training loss: 0.5906031131744385
Validation loss: 2.369806627432505

Epoch: 6| Step: 3
Training loss: 1.0069794654846191
Validation loss: 2.3172441124916077

Epoch: 6| Step: 4
Training loss: 0.644302248954773
Validation loss: 2.3413072427113852

Epoch: 6| Step: 5
Training loss: 0.5242545008659363
Validation loss: 2.3616549571355185

Epoch: 6| Step: 6
Training loss: 0.30476921796798706
Validation loss: 2.3070982694625854

Epoch: 6| Step: 7
Training loss: 0.42672520875930786
Validation loss: 2.3026506106058755

Epoch: 6| Step: 8
Training loss: 0.5870946645736694
Validation loss: 2.2926157315572104

Epoch: 6| Step: 9
Training loss: 0.3871515393257141
Validation loss: 2.3115795453389487

Epoch: 6| Step: 10
Training loss: 0.7432683110237122
Validation loss: 2.274697005748749

Epoch: 6| Step: 11
Training loss: 0.4285820722579956
Validation loss: 2.2738527258237204

Epoch: 6| Step: 12
Training loss: 0.803009569644928
Validation loss: 2.244406282901764

Epoch: 6| Step: 13
Training loss: 0.48706352710723877
Validation loss: 2.3174504240353904

Epoch: 543| Step: 0
Training loss: 0.7906572818756104
Validation loss: 2.30349995692571

Epoch: 6| Step: 1
Training loss: 0.700655996799469
Validation loss: 2.3283718824386597

Epoch: 6| Step: 2
Training loss: 0.5005428791046143
Validation loss: 2.355191628138224

Epoch: 6| Step: 3
Training loss: 0.36202266812324524
Validation loss: 2.323518176873525

Epoch: 6| Step: 4
Training loss: 0.5185032486915588
Validation loss: 2.290917615095774

Epoch: 6| Step: 5
Training loss: 0.9257711172103882
Validation loss: 2.301056166489919

Epoch: 6| Step: 6
Training loss: 0.20651666820049286
Validation loss: 2.290640731652578

Epoch: 6| Step: 7
Training loss: 0.48739588260650635
Validation loss: 2.3071237802505493

Epoch: 6| Step: 8
Training loss: 0.8323279619216919
Validation loss: 2.279987951119741

Epoch: 6| Step: 9
Training loss: 0.6125016212463379
Validation loss: 2.303764820098877

Epoch: 6| Step: 10
Training loss: 0.8547092080116272
Validation loss: 2.3263583183288574

Epoch: 6| Step: 11
Training loss: 0.37601783871650696
Validation loss: 2.2765984733899436

Epoch: 6| Step: 12
Training loss: 0.4699013829231262
Validation loss: 2.296186367670695

Epoch: 6| Step: 13
Training loss: 0.49618595838546753
Validation loss: 2.296414872010549

Epoch: 544| Step: 0
Training loss: 0.34021782875061035
Validation loss: 2.3128640254338584

Epoch: 6| Step: 1
Training loss: 0.3205597996711731
Validation loss: 2.3297080993652344

Epoch: 6| Step: 2
Training loss: 0.5890647172927856
Validation loss: 2.292212208112081

Epoch: 6| Step: 3
Training loss: 0.7902419567108154
Validation loss: 2.3142409324645996

Epoch: 6| Step: 4
Training loss: 0.24284400045871735
Validation loss: 2.2676974733670554

Epoch: 6| Step: 5
Training loss: 0.3245019316673279
Validation loss: 2.291938046614329

Epoch: 6| Step: 6
Training loss: 1.2134085893630981
Validation loss: 2.2880375385284424

Epoch: 6| Step: 7
Training loss: 0.2947445213794708
Validation loss: 2.30619740486145

Epoch: 6| Step: 8
Training loss: 0.2653830051422119
Validation loss: 2.322363575299581

Epoch: 6| Step: 9
Training loss: 0.45485544204711914
Validation loss: 2.2885583440462747

Epoch: 6| Step: 10
Training loss: 0.31263184547424316
Validation loss: 2.2773305575052896

Epoch: 6| Step: 11
Training loss: 0.8129502534866333
Validation loss: 2.3216360410054526

Epoch: 6| Step: 12
Training loss: 0.9329583048820496
Validation loss: 2.2198559443155923

Epoch: 6| Step: 13
Training loss: 0.3196306824684143
Validation loss: 2.275518258412679

Epoch: 545| Step: 0
Training loss: 1.0833436250686646
Validation loss: 2.258988857269287

Epoch: 6| Step: 1
Training loss: 0.3521561920642853
Validation loss: 2.243401308854421

Epoch: 6| Step: 2
Training loss: 0.2942732870578766
Validation loss: 2.2902950247128806

Epoch: 6| Step: 3
Training loss: 0.35639747977256775
Validation loss: 2.2568357785542807

Epoch: 6| Step: 4
Training loss: 0.27346891164779663
Validation loss: 2.30544114112854

Epoch: 6| Step: 5
Training loss: 0.4038179814815521
Validation loss: 2.254560629526774

Epoch: 6| Step: 6
Training loss: 0.516717791557312
Validation loss: 2.24930202960968

Epoch: 6| Step: 7
Training loss: 0.3136945962905884
Validation loss: 2.2545217474301658

Epoch: 6| Step: 8
Training loss: 0.3604881167411804
Validation loss: 2.248072703679403

Epoch: 6| Step: 9
Training loss: 0.7563807964324951
Validation loss: 2.2931144634882608

Epoch: 6| Step: 10
Training loss: 0.70835942029953
Validation loss: 2.2475900848706565

Epoch: 6| Step: 11
Training loss: 0.6303309798240662
Validation loss: 2.2494102319081626

Epoch: 6| Step: 12
Training loss: 0.47342413663864136
Validation loss: 2.2989556392033896

Epoch: 6| Step: 13
Training loss: 0.8393076062202454
Validation loss: 2.286567489306132

Epoch: 546| Step: 0
Training loss: 0.36572152376174927
Validation loss: 2.2837926745414734

Epoch: 6| Step: 1
Training loss: 0.6262310147285461
Validation loss: 2.3591289718945823

Epoch: 6| Step: 2
Training loss: 0.4046540856361389
Validation loss: 2.3213449716567993

Epoch: 6| Step: 3
Training loss: 0.8691399693489075
Validation loss: 2.3608372807502747

Epoch: 6| Step: 4
Training loss: 0.4883372485637665
Validation loss: 2.3115163246790567

Epoch: 6| Step: 5
Training loss: 0.2559516429901123
Validation loss: 2.3145920435587564

Epoch: 6| Step: 6
Training loss: 0.47447383403778076
Validation loss: 2.2614779074986777

Epoch: 6| Step: 7
Training loss: 0.43872135877609253
Validation loss: 2.3547966678937278

Epoch: 6| Step: 8
Training loss: 0.6135036945343018
Validation loss: 2.3264242808024087

Epoch: 6| Step: 9
Training loss: 0.518539547920227
Validation loss: 2.302546819051107

Epoch: 6| Step: 10
Training loss: 0.93122398853302
Validation loss: 2.2827464739481607

Epoch: 6| Step: 11
Training loss: 0.5248846411705017
Validation loss: 2.317371050516764

Epoch: 6| Step: 12
Training loss: 0.5471506118774414
Validation loss: 2.297102451324463

Epoch: 6| Step: 13
Training loss: 0.242004856467247
Validation loss: 2.2933457295099893

Epoch: 547| Step: 0
Training loss: 1.1230628490447998
Validation loss: 2.3164427876472473

Epoch: 6| Step: 1
Training loss: 0.6615894436836243
Validation loss: 2.3115206956863403

Epoch: 6| Step: 2
Training loss: 0.32397326827049255
Validation loss: 2.3189344803492227

Epoch: 6| Step: 3
Training loss: 0.6062965393066406
Validation loss: 2.3005133867263794

Epoch: 6| Step: 4
Training loss: 0.6200103759765625
Validation loss: 2.2862772742907205

Epoch: 6| Step: 5
Training loss: 0.33712512254714966
Validation loss: 2.2597004771232605

Epoch: 6| Step: 6
Training loss: 0.7599935531616211
Validation loss: 2.2847966154416404

Epoch: 6| Step: 7
Training loss: 0.44729816913604736
Validation loss: 2.2794297536214194

Epoch: 6| Step: 8
Training loss: 0.48337388038635254
Validation loss: 2.289062718550364

Epoch: 6| Step: 9
Training loss: 0.36902865767478943
Validation loss: 2.278186241785685

Epoch: 6| Step: 10
Training loss: 0.42167145013809204
Validation loss: 2.320364793141683

Epoch: 6| Step: 11
Training loss: 0.4626910984516144
Validation loss: 2.312593460083008

Epoch: 6| Step: 12
Training loss: 0.3692795932292938
Validation loss: 2.2899418473243713

Epoch: 6| Step: 13
Training loss: 0.6076864004135132
Validation loss: 2.3729881048202515

Epoch: 548| Step: 0
Training loss: 0.7816753387451172
Validation loss: 2.3861257632573447

Epoch: 6| Step: 1
Training loss: 0.8328495025634766
Validation loss: 2.372866074244181

Epoch: 6| Step: 2
Training loss: 0.379192590713501
Validation loss: 2.3520752588907876

Epoch: 6| Step: 3
Training loss: 0.2818874418735504
Validation loss: 2.2714683214823403

Epoch: 6| Step: 4
Training loss: 0.5410757660865784
Validation loss: 2.3075573245684304

Epoch: 6| Step: 5
Training loss: 0.2596536874771118
Validation loss: 2.2553470134735107

Epoch: 6| Step: 6
Training loss: 0.5094437003135681
Validation loss: 2.242004871368408

Epoch: 6| Step: 7
Training loss: 0.4406537711620331
Validation loss: 2.2246734301249185

Epoch: 6| Step: 8
Training loss: 1.0014472007751465
Validation loss: 2.257195293903351

Epoch: 6| Step: 9
Training loss: 0.46091899275779724
Validation loss: 2.246033509572347

Epoch: 6| Step: 10
Training loss: 0.38136523962020874
Validation loss: 2.315674285093943

Epoch: 6| Step: 11
Training loss: 1.1703215837478638
Validation loss: 2.323703090349833

Epoch: 6| Step: 12
Training loss: 0.35779649019241333
Validation loss: 2.3234892884890237

Epoch: 6| Step: 13
Training loss: 0.9410275220870972
Validation loss: 2.297931452592214

Epoch: 549| Step: 0
Training loss: 0.6137751340866089
Validation loss: 2.3572954535484314

Epoch: 6| Step: 1
Training loss: 1.271126627922058
Validation loss: 2.367409368356069

Epoch: 6| Step: 2
Training loss: 0.4343528151512146
Validation loss: 2.386765956878662

Epoch: 6| Step: 3
Training loss: 0.3430477976799011
Validation loss: 2.3884699741999307

Epoch: 6| Step: 4
Training loss: 0.8212977647781372
Validation loss: 2.386045753955841

Epoch: 6| Step: 5
Training loss: 0.29654771089553833
Validation loss: 2.320578873157501

Epoch: 6| Step: 6
Training loss: 0.6545808911323547
Validation loss: 2.298434317111969

Epoch: 6| Step: 7
Training loss: 0.355035662651062
Validation loss: 2.2974561055501304

Epoch: 6| Step: 8
Training loss: 0.3332718014717102
Validation loss: 2.3256299098332724

Epoch: 6| Step: 9
Training loss: 0.8378875255584717
Validation loss: 2.3284666538238525

Epoch: 6| Step: 10
Training loss: 0.4420511722564697
Validation loss: 2.3062775135040283

Epoch: 6| Step: 11
Training loss: 0.509283185005188
Validation loss: 2.3420912424723306

Epoch: 6| Step: 12
Training loss: 0.46253499388694763
Validation loss: 2.3423765897750854

Epoch: 6| Step: 13
Training loss: 0.6887202262878418
Validation loss: 2.4000402887662253

Epoch: 550| Step: 0
Training loss: 0.9453510046005249
Validation loss: 2.289179186026255

Epoch: 6| Step: 1
Training loss: 0.2674659192562103
Validation loss: 2.3679279486338296

Epoch: 6| Step: 2
Training loss: 0.6889117956161499
Validation loss: 2.393884301185608

Epoch: 6| Step: 3
Training loss: 0.39749211072921753
Validation loss: 2.343386093775431

Epoch: 6| Step: 4
Training loss: 0.5806670188903809
Validation loss: 2.2849164406458535

Epoch: 6| Step: 5
Training loss: 0.755933940410614
Validation loss: 2.3245502710342407

Epoch: 6| Step: 6
Training loss: 0.37282314896583557
Validation loss: 2.2717638413111367

Epoch: 6| Step: 7
Training loss: 0.27240216732025146
Validation loss: 2.277281184991201

Epoch: 6| Step: 8
Training loss: 0.7444039583206177
Validation loss: 2.248113512992859

Epoch: 6| Step: 9
Training loss: 0.5742530822753906
Validation loss: 2.223131477832794

Epoch: 6| Step: 10
Training loss: 0.4353361129760742
Validation loss: 2.2495279908180237

Epoch: 6| Step: 11
Training loss: 0.8944903016090393
Validation loss: 2.264652212460836

Epoch: 6| Step: 12
Training loss: 0.5673009753227234
Validation loss: 2.227581342061361

Epoch: 6| Step: 13
Training loss: 0.5593609809875488
Validation loss: 2.259751617908478

Testing loss: 1.9664997033935656
